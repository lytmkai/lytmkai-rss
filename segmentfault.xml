<?xml version="1.0" encoding="UTF-8"?><rss version="2.0">  <channel>      <title>SegmentFault - 最近文章</title>      <link>https://segmentfault.com/blogs/newest</link>      <description>SegmentFault 思否</description>      <generator>python segmentfault.py @Pi20</generator>      <item>    <title><![CDATA[uniapp 下载网络pdf，并且打开 ]]></title>    <link>https://segmentfault.com/a/1190000047401319</link>    <guid>https://segmentfault.com/a/1190000047401319</guid>    <pubDate>2025-11-15 11:06:21</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>uniapp 下载网络pdf,或者后端返回的pdf链接，下载并且打开</p><pre><code>    downPDF() {
      uni.showLoading({ title: '下载中' });
      console.log('uni.env.USER_DATA_PATH', uni.env.USER_DATA_PATH);
      uni.downloadFile({
        url:
          'https://www.xxxx.com/static/xxx_static/MiniApp/static/test/test.pdf',
        success: res =&gt; {
          uni.getFileSystemManager().saveFile({
            tempFilePath: res.tempFilePath,
            filePath: `${uni.env.USER_DATA_PATH}/certificate_${Date.now()}.pdf`, // 目标路径（可选）
            success: res1 =&gt; {
              uni.showModal({
                title: '是否打开文件',
                content: '存储地址为' + res1.savedFilePath,
                showCancel: true,
                success: res2 =&gt; {
                  if (res2.confirm) {
                    uni.openDocument({
                      filePath: res1.savedFilePath,
                      success: res3 =&gt; {
                        console.log(res3, 'res3');
                      },
                    });
                  }
                },
              });
            },
            fail: err =&gt; {
              console.log(err, 'errrrrrr');
              uni.hideLoading();
            },
            complete: () =&gt; {
              uni.hideLoading();
            },
          });
        },
      });
    },</code></pre>]]></description></item><item>    <title><![CDATA[社区来稿丨RTE 大会带给我的 AI A]]></title>    <link>https://segmentfault.com/a/1190000047401323</link>    <guid>https://segmentfault.com/a/1190000047401323</guid>    <pubDate>2025-11-15 11:05:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>上周末参加了 RTE 的年度大会，听到一场让我印象深刻的分享。 讲者介绍了 TEN Framework 如何让一个 AI Agent 真正以系统级的方式运行。当 Agent 不再只是“跑模型”，而要面对真实世界的延迟、负载、协同、上线、监控……这就不再是算法问题，而是<strong> AI Agent Infrastructure </strong>的问题。虽然 TEN Framework 聚焦在 Voice Agent，但我觉得它对其他对实时性稳定性要求高的 AI Agent 项目的 <strong>Infra 架构</strong>都有参考价值，也希望同你分享。</p><p>这篇文章，我想聊聊我从这次演讲里得到的Agent Infra启发—— 包括 Runtime、模块化、测试与架构设计的思考；本文阅读大约需 6 分钟。</p><hr/><h2><strong>跨语言协同：用统一 Runtime，而非统一语言</strong></h2><p>现实中的 AI 系统从不单一。 推理在 Python，音视频在 C++，交互在 JS—— 每一次跨语言通信（IPC），都是延迟与性能的代价。</p><p>更好的思路，是构建一个能容纳多语言模块的统一 Runtime 层。 模块之间共享内存、共享状态，而非频繁“对话”。</p><p>这并不是炫技，而是一种更深层的设计哲学：</p><blockquote>不追求代码统一，而追求执行环境统一。</blockquote><p>这种“多语言互信”让团队既能保持语言多样性， 又能获得系统级的一致性与高效协同。</p><h2><strong>模块化积木：让复杂系统具备自我演化能力</strong></h2><p>一个真正工程化的 Agent Infra， 不该是一条死板的管线，而应是一组可以拼接的“积木”。每个功能（识别、生成、控制、存储）都应是独立模块， 能够被自由组合、复用和热插拔。</p><p>关键在于让每个模块具备三性：</p><ul><li>可组合（Composable）：像拼积木一样动态组装；</li><li>可扩展（Scalable）：能根据负载灵活伸缩；</li><li>可观测（Observable）：随时自报状态，便于监控与调优。</li></ul><p>当系统具备这三性后，Agent 不再是一个静态程序， 而是一套能自我调节、持续进化的动态生态。</p><p><strong>为什么不是微服务？</strong></p><p>很多人会问：既然都是多模块协同，为什么不直接用微服务？</p><p>表面上，微服务（Microservices）看起来完美： 模块独立、职责清晰、可横向扩展。</p><p>但问题在于——实时 AI 系统（尤其是语音、视频、多模态场景） 需要频繁传递流式数据与上下文状态。 这意味着：</p><ul><li>每一次调用都要序列化 / 反序列化；</li><li>每一个 RPC 都带来几十毫秒延迟；</li><li>每一层网络 hop 都可能打断上下文连续性。</li></ul><blockquote>微服务强调“隔离”，而实时 Agent 强调“同步”。</blockquote><p>结果就是：语音延迟上升、状态同步复杂、上下文频繁丢失。 因此，高实时要求的工程团队会选择另一种路径——<strong>用统一 Runtime 替代多进程架构。</strong></p><p><strong>微服务 vs Runtime 架构</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047401325" alt="" title=""/></p><p>微服务解决的是「组织级可维护性」， Runtime 追求的是「系统级响应速度」。</p><p>两者并不冲突，但适用于不同的目标空间：</p><ul><li>如果你要的是稳定、分布式、独立部署 → 选微服务；</li><li>如果你要的是实时、同步、多模态交互 → 选统一 Runtime。</li></ul><h2><strong>独立测试：让每个模块都能自己“活”</strong></h2><p>许多团队的痛点在于：要验证一个功能，必须跑整条 pipeline。 这让开发迭代极慢，也让模块复用变得困难。</p><p>真正的工程化思维是： 每个模块都应具备自己的测试入口与模拟上下文（mock environment）， 能够在独立运行时中完成自检、自愈。</p><p>这样的设计带来三重收益：</p><ol><li><strong>开发层面：</strong> 模块间解耦，可并行推进；</li><li><strong>质量层面：</strong> 错误可定位、可回放；</li><li><strong>运维层面：</strong> 生产 bug 可直接复现到单模块测试。</li></ol><p>这就像在系统里植入“单元级神经反射”——任何一块出问题，系统都能感知、修复、继续运转。</p><p>在和分享的 Halajohn 老师（TEN framework creator）的线下交流中，<strong>我提出了一个问题</strong>： “AI 系统的不可控性，意味着独立模块的测试可能无法捕捉链路级的漂移。当所有环节叠加起来，微小偏差可能被放大成系统级偏差。那么是不是，AI Agent 的整条链路测试应该比传统软件更‘频繁’，甚至要进化成一种持续性监控？”</p><p>Halajohn 老师认同确实会存在这个问题，并补充道：整条链路中除了模型部分，还有许多固定模块，这些部分完全可以进行独立测试。所以关键不是“要不要独立测”，而是——<strong>如何做好模块化，让能独立测试的部分尽量独立。</strong><em>*</em>*</p><h2><strong>模板与标准化：让 Infra 成为共享资产</strong></h2><p>模板化不是偷懒，而是让基础设施“长出形状”的过程。</p><p>一个好的 Agent Infra， 应该让开发者可以用模板快速生成标准模块： 模板中包含骨架代码、测试用例、接口协议、监控钩子。</p><p>这种 “Template + Test” 体系带来了三个好处：</p><ul><li>新人能一分钟上手；</li><li>团队能共享最佳实践；</li><li>Infra 本身能被复用与演化。</li></ul><p>模板让经验可视化，让复杂性被管理， 最终让整个团队的工程能力沉淀为可复用的资产。</p><p>AI Agent 的竞争不只在模型层，还在工程层。Runtime、模块化、测试、模板化——这些决定了一个系统能否“持续运行”，而不仅仅是“能运行”。  当然，不同场景下也会有不同的 Infra 选择。  我也很期待和正在阅读这篇文章的你，一起交流、碰撞更多的实践经验。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047401326" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047401327" alt="" title="" loading="lazy"/><br/><a href="https://link.segmentfault.com/?enc=igWNc2%2FbSvbJvFygsHE9Vg%3D%3D.f6jPnAxDNCChKcnhofAOZTtrJk09gU344F4rSHMAhjM%3D" rel="nofollow" target="_blank">阅读更多 Voice Agent 学习笔记：了解最懂 AI 语音的头脑都在思考什么</a></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047401328" alt="" title="" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[文心大模型升级 5.0，支持全模态输入与]]></title>    <link>https://segmentfault.com/a/1190000047401367</link>    <guid>https://segmentfault.com/a/1190000047401367</guid>    <pubDate>2025-11-15 11:04:39</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047401369" alt="" title=""/></p><p><strong>开发者朋友们大家好：</strong></p><p>这里是 <strong>「RTE 开发者日报」</strong> ，每天和大家一起看新闻、聊八卦。我们的社区编辑团队会整理分享 RTE（Real-Time Engagement） 领域内「有话题的<strong>技术</strong>」、「有亮点的<strong>产品</strong>」、「有思考的<strong>文章</strong>」、「有态度的<strong>观点</strong>」、「有看点的<strong>活动</strong>」，但内容仅代表编辑的个人观点，欢迎大家留言、跟帖、讨论。</p><p><em>本期编辑：@Jerry fong，@鲍勃</em></p><h2>01 有话题的技术</h2><p><strong>1、百度发布全球首个原生全模态大模型文心 5.0</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047401370" alt="" title="" loading="lazy"/></p><p>在 2025 百度世界大会上，百度正式发布原生全模态大模型「文心 5.0」。</p><p>该模型参数量达 2.4 万亿，采用统一自回归架构进行原生全模态建模，支持文本、图像、音频、视频等多模态输入与输出。</p><p>据介绍，文心 5.0 在多模态理解、指令遵循、创意写作、事实性、智能体规划与工具应用等方面表现突出。</p><p>在 40 余项权威基准测试中，其语言与多模态理解能力与 Gemini-2.5-Pro、GPT-5-High 等模型持平，图像与视频生成能力达到全球领先水平。</p><p>此前， 11 月 8 日，LMArena 大模型竞技场最新排名显示，ERNIE-5.0-Preview-1022 在文本任务评测中位列全球并列第二、中国第一。</p><p>百度创始人李彦宏在会上表示：「智能本身是最大的应用，而技术迭代速度是唯一护城河。百度会持续投入研发，推高智能天花板。」</p><p>百度 CTO 王海峰则指出，文心 5.0 不同于业界多数采用后期融合的多模态模型，而是从训练开始便融合语言、图像、视频、音频等数据，实现原生的全模态统一理解与生成。</p><p>目前，文心大模型 5.0 Preview 已上线文心 App，开发者与企业用户可通过百度千帆平台调用 API 服务。</p><p>(@ APPSO)</p><p><strong>2、Google DeepMind 发布 SIMA 2</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047401371" alt="" title="" loading="lazy"/></p><p>Google DeepMind 发布了 SIMA 2，这是一个由 Gemini 模型驱动的 AI Agent，旨在虚拟 3D 世界中与用户进行交互、推理和学习。SIMA 2 是其前代产品 SIMA 的演进，从一个遵循指令的 AI 发展为一个能够理解高级目标、与用户对话并随时间自我改进的交互式游戏伴侣。</p><p>该 Agent 在多种商业视频游戏和由 Genie 3 生成的新世界中展现了强大的泛化能力和适应性，其性能在多项任务上已接近人类水平，并具备了通过自我博弈进行多任务、可扩展自我提升的能力。SIMA 2 的核心进步源于集成了 Gemini 模型的强大推理能力。</p><p>与前代产品 SIMA 1 相比，SIMA 2 不仅能够遵循超过 600 种基本语言指令，还能对用户的高级目标进行复杂推理，并向用户解释其意图和执行步骤。这种架构使其在从未训练过的新游戏（如 ASKA 和 MineDojo）中也能成功完成复杂任务，并能将一个游戏中学到的概念（如「挖掘」）应用到另一个游戏中的相似行为（如「收获」），表现出接近人类认知的泛化能力。</p><p>在与 DeepMind 的另一研究项目 Genie 3 的结合测试中，SIMA 2 展现了前所未有的适应性。Genie 3 能够根据单张图像或文本提示生成全新的实时 3D 模拟世界。SIMA 2 在这些从未见过的生成环境中，能够合理地进行自我定位、理解用户指令并采取有意义的目标导向行动。</p><p>SIMA 2 最引人注目的新能力之一是其自我改进机制。通过试错和基于 Gemini 的反馈，SIMA 2 Agent 可以在训练过程中执行日益复杂的任务。在初步从人类演示中学习后，它能够过渡到完全通过自我导向的游戏在新环境中学习，无需额外的人类生成数据。其自身产生的经验数据可用于训练下一代更强大的 Agent，这一循环在 Genie 创建的新环境中也得到了验证。</p><p>Google DeepMind 强调了对 SIMA 2 负责任的开发，并宣布将其作为有限的研究预览版提供给一小部分学者和游戏开发者。此举旨在收集关键反馈和多学科视角，以探索这一新领域并持续理解相关风险及其缓解措施。SIMA 2 的研究被认为对机器人技术和通用人工智能（AGI）的未来发展具有重要意义。</p><p>（@橘鸭 Juya）</p><h2>02 有亮点的产品</h2><p><strong>1、初创公司 Even Realities 推出 G2 智能眼镜，搭配戒指实现手势交互</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047401372" alt="" title="" loading="lazy"/></p><p>据 WIRED 报道，智能眼镜初创公司 Even Realities 昨天正式发布新一代产品 Even G2 智能眼镜及配套的 R1 智能戒指。</p><p>公司 CEO Will Wang 在发布会上强调，G2 在显示效果、重量和佩戴舒适度方面均较上一代 G1 有显著提升。具体规格如下：</p><blockquote><ul><li>配备单色 micro-LED 投影显示屏，尺寸相较上代大 75%，采用「Even HAO 2.0」光学系统与高清镜片；</li><li>内置「Even AI」助手，新增「Conversate」功能，可在对话中生成字幕、总结会议或提供即时问题建议；</li><li>搭配 R1 智能戒指可实现手势控制眼镜界面，并具备心率、睡眠及血氧监测功能，数据可直接显示在眼镜中；</li><li>单镜框重量为 36 克，具备 IP67 防尘防水等级。</li></ul></blockquote><p>Even Realities 表示，目前 G1 已进入全球 350 家奢侈眼镜店销售。公司计划通过即将上线的「Even Hub」平台吸引开发者扩展功能，目标是成为「智能眼镜领域的特斯拉与 OpenAI」。</p><p>售价方面，Even G2 定价 599 美元（约合 4250 元人民币），R1 定价 249 美元（约 1800 元人民币），两款产品已于昨天同步开售。此外，Even Realities 还推出促销活动，购买 G2 可享 R1 及配件半价优惠。</p><p>(@ APPSO)</p><p><strong>2、Google 发布 Gemini Live 重大更新</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047401373" alt="" title="" loading="lazy"/></p><p>Google 发布了 Gemini Live 重大更新，提升了其语音 AI 的速度、表现力，并增加了对不同口音的支持。</p><p>新版模型能实时识别并控制语速、韵律与口音，使交互更自然。用户可以赋予 Gemini 特定的人设、口音或角色，用于练习面试、让脚本生动化或增加日常互动的趣味性。</p><p>该更新支持在单次对话中无缝切换多种语言及方言，可用于学习新语言时的发音练习或作为旅行时的实时翻译。</p><p>用户还可以要求 Gemini 加快或减慢语速。此外，Gemini 现在能讲述更具戏剧性的故事，包含鲜明的角色和更丰富的对话。有用户称，在询问时，Gemini 开始自称为 Gemini 3.0 Pro。</p><p>相关链接：</p><p><a href="https://link.segmentfault.com/?enc=4U92bGPHH2Wq01ju5GwnbA%3D%3D.rPUDZybCz91V30vVxNwRgCorO6PAEhiNE%2F29AAkTem8v5IpqtC218Gb0zBwDR9rnvkcxc2QlH0xwMEjOk9EbQg%3D%3D" rel="nofollow" target="_blank">https://x.com/GeminiApp/status/1988755100412834151</a></p><p>（@橘鸭 Juya）</p><p><strong>3、百度发布全新多模态 AI 助手 「超能小度」，数千万设备可免费升级</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047401374" alt="" title="" loading="lazy"/></p><p>在 11 月 13 日的百度世界大会上，小度科技正式推出其升级版的多模态 AI 助手 「超能小度」。此次发布标志着公司在人机交互技术上的重要进步，数千万台已售的小度设备也将获得免费升级，让用户体验更智能的生活方式。</p><p>「超能小度」 结合了语音、视觉及空间环境信息，赋予了设备更强的感知能力。这一新助手不仅能听会说，还能通过视觉识别理解周围的环境。举个例子，当你在停车场时，如果不方便拿出手机，你只需对 「超能小度」 说：「帮我记一下」，它就能自动拍照并记录停车位信息，甚至在你问起停车位置时，能迅速给出答案。此外，它还能拨打物业电话，让你无忧无虑。</p><p>新产品还包括了小度 AI 眼镜 Pro 和智能摄像机等，带来了一系列实用功能。例如，通过与网易云音乐的合作，用户只需说出 「给我来首应景的歌」，眼镜便能根据现场环境播放合适的背景音乐。在会议场景下，「超能小度」 能够不仅录音转写，还能自动整理会议纪要，并分析会议质量，帮助你更好地理解会议内容。</p><p>在家庭场景中，超能小度更是大显身手。其独创的 「AI 随心看护」 功能可以对家庭成员的特定行为进行提醒，确保家长不会错过孩子的成长瞬间。此外，用户可以通过语音询问物品的去向，超能小度能通过回溯监控画面，帮助你找回遗失的物品。</p><p>这次全新助手的发布，不仅让设备从 「执行命令」 的工具转变为 「主动思考」 的伙伴，更是在智能家庭领域迈出了重要一步。随着用户体验的不断提升，小度科技致力于将 「超能小度」 融入到人们的日常生活中，让智能生活真正走进每一个家庭。</p><p>(@ AIBase)</p><h2>03 有态度的观点</h2><p><strong>1、李彦宏：AI 产业结构正转变为「倒金字塔」</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047401375" alt="" title="" loading="lazy"/></p><p>昨天在北京举行的 2025 年百度世界大会上，百度创始人兼 CEO 李彦宏发表题为「效果涌现」的主旨演讲。他强调，当 AI 能力被内化为企业与个人的原生能力时，智能不再是成本，而是生产力。</p><p><strong>他指出，AI 产业结构正在经历重要转型，从过去不健康的「正金字塔」逐步转向更具可持续性的「倒金字塔」模式。</strong></p><p>李彦宏解释称，传统的「正金字塔」结构中，芯片厂商占据了绝大部分价值，而位于其上的模型和应用则收益递减。这种格局导致市场对 AI 的长期发展产生怀疑。</p><p>他强调，健康的「倒金字塔」结构应当是：<strong>芯片厂商无论盈利多少，模型需创造 10 倍的价值，而基于模型开发的应用则应实现 100 倍的价值。</strong>这一逻辑不仅能提升产业生态的可持续性，也有助于推动创新与应用落地。</p><p>他还表示，应用层创新正在推动行业跨越临界点，从「智能涌现」走向「效果涌现」，智能将成为企业和个人的增长引擎。</p><p>在企业应用方向上，李彦宏提出三大代表性场景：一是 AI 替代重复性劳动，如辅助编程工具；二是生产力的无限供给，随着 AIGC 技术发展，内容供给将趋近无限；三是 AI 超越人类认知，通过模型迭代发现全局最优解。</p><p>他特别强调「数字人」作为 AI 时代的全新通用交互界面，能够在电商、教育、医疗、资讯、客服等场景中广泛应用，使人机交互更自然。</p><p>与此同时，百度搜索的 AI 化改造已成为全球最激进的案例，搜索结果页由 AI 重构，首条结果的富媒体化覆盖率已达 70%。</p><p>在无人驾驶领域，李彦宏引用 ARK 投资机构数据预测，到 2030 年，美国 Robotaxi 每英里成本将降至约 0.25 美元，需求有望放大 5 至 7 倍。他认为，无人车将成为全新的移动生活空间，带来社会生态的深刻改变。</p><p>此外，百度还发布了智能体「伐谋」，可通过自我演化寻找全局最优解，应用于交通、能源、金融、物流及新药研发等领域。</p><p>李彦宏呼吁企业和个人改变工作方式，将问题转化为 AI 能解决的问题，以推动「智能红利」转化为「社会红利」。</p><p>(@ APPSO)</p><h2>04 社区黑板报</h2><p>招聘、项目分享、求助……任何你想和社区分享的信息，请联系我们投稿。（加微信 creators2022，备注「社区黑板报」）</p><p><strong>1、招聘：AI 翻唱项目，寻算法小伙伴</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047401376" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047401377" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047401378" alt="" title="" loading="lazy"/></p><p><a href="https://link.segmentfault.com/?enc=TqW8ySi0ikfUSNcOrtwP5g%3D%3D.6QQK8%2Bbd5xkqh1NsMkz413uyxIk%2BHG8YZVS4AQYQ57Y%3D" rel="nofollow" target="_blank">阅读更多 Voice Agent 学习笔记：了解最懂 AI 语音的头脑都在思考什么</a></p><p><strong>写在最后：</strong></p><p>我们欢迎更多的小伙伴参与<strong>「RTE 开发者日报」</strong>内容的共创，感兴趣的朋友请通过开发者社区或公众号留言联系，记得报暗号「共创」。</p><p>对于任何反馈（包括但不限于内容上、形式上）我们不胜感激、并有小惊喜回馈，例如你希望从日报中看到哪些内容；自己推荐的信源、项目、话题、活动等；或者列举几个你喜欢看、平时常看的内容渠道；内容排版或呈现形式上有哪些可以改进的地方等。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047401379" alt="" title="" loading="lazy"/></p><p>素材来源官方媒体/网络新闻</p>]]></description></item><item>    <title><![CDATA[【URP】Unity[后处理]白平衡Wh]]></title>    <link>https://segmentfault.com/a/1190000047401402</link>    <guid>https://segmentfault.com/a/1190000047401402</guid>    <pubDate>2025-11-15 11:03:53</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <blockquote><a href="https://link.segmentfault.com/?enc=egJf5fZYSbxFyYF%2FC34fKQ%3D%3D.r40x3iOdZnVAJdGtCvNHcQfEYplAGUPEkf26VZ5QVcF9DGU84GnGarGDL073LJmgsRoHyU3QHtHkc19HK1cd86K29OEzsTa26f52aBeXZDGFtGfvOzDV%2B4dr5VTKbzGSO7PJe7K6s0sbc0s%2Fxmw7AIRfp65jswE4TXxiQLQMJ8S%2BB9S83DqavOLZzh%2Bwt29hHh%2FGNMRVWLof2Kp6kmp6qEJ3Ke6CNOgpFY%2BSrnk1Ss8%3D" rel="nofollow" target="_blank">【从UnityURP开始探索游戏渲染】</a><strong>专栏-直达</strong></blockquote><h2><strong>白平衡概述</strong></h2><p>白平衡(White Balance)是Unity URP后处理系统中的重要组件，用于消除不真实的色偏，使现实中应显示为白色的物体在最终图像中呈现白色。它通过调整色温和色调来补偿不同光源条件下的色彩偏差，同时也可用于营造特定的场景氛围。</p><p>白平衡的概念源自摄影领域，旨在解决不同光源下色彩还原的问题。在Unity中，白平衡功能随着HDRP和URP渲染管线的演进不断完善，从最初的简单色彩校正发展到基于Volume框架的专业级色彩管理系统。</p><h2><strong>核心功能与作用</strong></h2><h3>‌<strong>色彩校正</strong>‌</h3><ul><li>消除因光源色温差异导致的色偏，确保白色物体在不同光照条件下保持中性色</li></ul><h3>‌<strong>氛围营造</strong>‌</h3><ul><li>通过调整色温和色调参数，创造冷暖不同的整体画面效果</li></ul><h3>‌<strong>艺术表达</strong>‌</h3><ul><li>突破真实色彩限制，实现风格化的视觉效果</li></ul><h2><strong>实现原理</strong></h2><p>URP中的白平衡基于Volume框架实现，采用科学色彩空间转换算法。其核心是通过CIE色度图和LMS色彩空间的转换，调整输入颜色的色温和色调：</p><ul><li>将输入颜色从线性RGB空间转换到LMS色彩空间</li><li>根据设定的色温和色调参数计算平衡系数</li><li>应用平衡系数后转换回线性RGB空间</li></ul><p>Unity URP中的白平衡(White Balance)后处理效果基于色彩空间转换算法实现，其核心原理是通过调整色温和色调参数来补偿不同光照条件下的色彩偏差。</p><h3><strong>底层原理详解</strong></h3><p>白平衡的数学实现主要分为以下几个步骤：</p><ul><li>‌<strong>色彩空间转换</strong>‌：将输入颜色从线性RGB空间转换到LMS色彩空间（长波、中波、短波锥体响应空间）</li></ul><pre><code class="c">hlsl
float3x3 LIN_2_LMS_MAT = {
    3.90405e-1, 5.49941e-1, 8.92632e-3,
    7.08416e-2, 9.63172e-1, 1.35775e-3,
    2.31082e-2, 1.28021e-1, 9.36245e-1
};
float3 lms = mul(LIN_2_LMS_MAT, In);</code></pre><ul><li>‌<strong>白点计算</strong>‌：根据设定的色温(Temperature)和色调(Tint)参数计算参考白点</li></ul><pre><code class="c">hlsl
float t1 = Temperature * 10/6;
float t2 = Tint * 10/6;
float x = 0.31271 - t1 * (t1 &lt; 0 ? 0.1 : 0.05);
float standardIlluminantY = 2.87*x - 3*x*x - 0.27509507;
float y = standardIlluminantY + t2 * 0.05hlsl</code></pre><ul><li>‌<strong>平衡系数计算</strong>‌：比较当前白点与标准D65白点的差异</li></ul><pre><code class="c">hlsl
float3 w1 = float3(0.949237, 1.03542, 1.08728); // D65白点
float3 w2 = float3(L, M, S); // 当前白点
float3 balance = float3(w1.x/w2.x, w1.y/w2.y, w1.z/w2.z);</code></pre><ul><li>‌<strong>应用平衡并转换回RGB空间</strong>‌</li></ul><pre><code class="c">hlsl
lms *= balance;
float3x3 LMS_2_LIN_MAT = {
    2.85847e+0, -1.62879e+0, -2.48910e-2,
    -2.10182e-1, 1.15820e+0, 3.24281e-4,
    -4.18120e-2, -1.18169e-1, 1.06867e+0
};
Out = mul(LMS_2_LIN_MAT, lms);</code></pre><h4><strong>完整URP实现示例</strong></h4><ul><li><p>WhiteBalanceEffect.shader</p><pre><code class="csharp">Shader "Hidden/Universal Render Pipeline/WhiteBalance"
{
    HLSLINCLUDE
    #include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl"

    float _Temperature;
    float _Tint;

    float3 ApplyWhiteBalance(float3 color)
    {
        // 温度转换系数
        float t1 = _Temperature * 10.0 / 6.0;
        float t2 = _Tint * 10.0 / 6.0;

        // 计算白点坐标
        float x = 0.31271 - t1 * (t1 &lt; 0 ? 0.1 : 0.05);
        float standardIlluminantY = 2.87 * x - 3.0 * x * x - 0.27509507;
        float y = standardIlluminantY + t2 * 0.05;

        // 转换为XYZ空间
        float Y = 1.0;
        float X = Y * x / y;
        float Z = Y * (1.0 - x - y) / y;

        // 转换为LMS空间
        float L = 0.7328 * X + 0.4296 * Y - 0.1624 * Z;
        float M = -0.7036 * X + 1.6975 * Y + 0.0061 * Z;
        float S = 0.0030 * X + 0.0136 * Y + 0.9834 * Z;

        // 计算平衡系数
        float3 w1 = float3(0.949237, 1.03542, 1.08728); // D65
        float3 w2 = float3(L, M, S);
        float3 balance = float3(w1.x/w2.x, w1.y/w2.y, w1.z/w2.z);

        // RGB转LMS矩阵
        float3x3 RGB2LMS = float3x3(
            0.390405, 0.549941, 0.00892632,
            0.0708416, 0.963172, 0.00135775,
            0.0231082, 0.128021, 0.936245);

        // LMS转RGB矩阵
        float3x3 LMS2RGB = float3x3(
            2.85847, -1.62879, -0.024891,
            -0.210182, 1.15820, 0.000324281,
            -0.0418120, -0.118169, 1.06867);

        // 应用转换
        float3 lms = mul(RGB2LMS, color);
        lms *= balance;
        return mul(LMS2RGB, lms);
    }
    ENDHLSL
}</code></pre></li></ul><h4><strong>参数作用机制</strong></h4><ul><li>‌<strong>Temperature</strong>‌：通过改变CIE xy色度图中的x坐标值来调整色温，正值增加暖色调(红/黄)，负值增加冷色调(蓝/青)</li><li>‌<strong>Tint</strong>‌：通过调整y坐标值来补偿绿色或洋红色偏，正值增加洋红色调，负值增加绿色调</li></ul><p>该实现基于CIE标准色度学和色彩感知理论，通过精确的矩阵运算在不同色彩空间之间转换，确保色彩调整符合人眼视觉特性</p><h2><strong>URP实现流程</strong></h2><ul><li><p>WhiteBalanceExample.cs</p><pre><code class="csharp">using UnityEngine;
using UnityEngine.Rendering;
using UnityEngine.Rendering.Universal;

public class WhiteBalanceExample : MonoBehaviour
{
    [SerializeField] private VolumeProfile volumeProfile;

    private WhiteBalance whiteBalance;

    void Start()
    {
        // 从Volume Profile获取或添加白平衡覆盖
        if (!volumeProfile.TryGet(out whiteBalance))
        {
            whiteBalance = volumeProfile.Add&lt;WhiteBalance&gt;(true);
        }

        // 设置默认参数
        whiteBalance.temperature.Override(0f);
        whiteBalance.tint.Override(0f);
    }

    public void SetTemperature(float value)
    {
        whiteBalance.temperature.Override(value);
    }

    public void SetTint(float value)
    {
        whiteBalance.tint.Override(value);
    }
}</code></pre></li></ul><h3><strong>配置步骤</strong></h3><ul><li>在Unity编辑器中创建URP Asset（如果尚未创建）</li><li>在场景中添加Global Volume或Local Volume组件</li><li>在Volume组件中添加White Balance覆盖</li><li>通过脚本或直接调整参数控制效果</li></ul><h2><strong>参数详解与用例</strong></h2><h3><strong>主要参数</strong></h3><table><thead><tr><th>参数</th><th>描述</th><th>典型值范围</th><th>应用场景</th></tr></thead><tbody><tr><td>Temperature</td><td>控制色温，调整画面冷暖色调</td><td>-100到100</td><td>暖色调：黄昏/室内(7000K) 冷色调：夜晚/科幻(4000K)1</td></tr><tr><td>Tint</td><td>补偿绿色或洋红色偏</td><td>-100到100</td><td>修正荧光灯色偏(正值)或植被场景(负值)15</td></tr></tbody></table><h2><strong>实际用例</strong></h2><h3>‌<strong>日间户外场景</strong>‌</h3><ul><li>Temperature≈0，Tint≈0（中性白平衡，约5500K）</li></ul><h3>‌<strong>黄昏场景</strong>‌</h3><ul><li>Temperature=20-30，Tint=5（暖色调增强）</li></ul><h3>‌<strong>荧光灯室内</strong>‌</h3><ul><li>Temperature=-10，Tint=10（补偿绿色偏色）</li></ul><h3>‌<strong>科幻场景</strong>‌</h3><ul><li>Temperature=-30，Tint=-5（冷蓝色调）</li></ul><h2><strong>进阶技巧</strong></h2><ul><li>‌<strong>动态调整</strong>‌：通过脚本在运行时根据场景光照条件自动调整白平衡</li><li>‌<strong>风格化处理</strong>‌：结合Color Grading等其他后处理效果创造独特视觉风格</li><li>‌<strong>性能优化</strong>‌：在移动平台适当降低白平衡计算精度</li></ul><p>白平衡作为URP后处理管线的重要组成部分，既能实现专业级的色彩校正，又能为游戏场景创造丰富的情感表达</p><hr/><blockquote><a href="https://link.segmentfault.com/?enc=GiLAP9jN4rS2JAISel9yYA%3D%3D.7PrHFD6RwRL5jYf2lBARNeht04UMmAPjmol77PtIh81N9atqo4tTmvCx%2FgQ1wO%2FPEdmPiuTOigDqOJiOVRC%2B409EJriqR3YTqJ15EdRPbGuKThNcRMKdWUWMqBDBYauLlLo6UHUUyaAcTBZ%2BFZjmncc1GYQFQMNcWeFnxTIFNCpdYbbVyOm%2Bf0Diibn%2FmdiJ1%2Fg%2B4eKlFdvl%2Fve0lMTtzEExrj%2F4gEFPYD3JPp%2B0K24%3D" rel="nofollow" target="_blank">【从UnityURP开始探索游戏渲染】</a><strong>专栏-直达</strong><br/>（欢迎<em>点赞留言</em>探讨，更多人加入进来能更加完善这个探索的过程，🙏）</blockquote>]]></description></item><item>    <title><![CDATA[蓝易云cdn:springboot之Re]]></title>    <link>https://segmentfault.com/a/1190000047401428</link>    <guid>https://segmentfault.com/a/1190000047401428</guid>    <pubDate>2025-11-15 11:03:19</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>下面给你一份真正能落地、结构严谨、可直接用于生产开发的内容，涵盖 Spring Boot 中 RedisTemplate 访问 <strong>单机、哨兵、集群模式</strong> 的完整说明，包含代码、配置、工作原理、解释表，并满足你所有格式要求。<br/>我会保持务实、直击重点，内容会让你一看就能上手部署。</p><h2>Spring Boot 中 RedisTemplate 访问单机、哨兵、集群模式（最新版实践指南）🚀</h2><p>在现代分布式业务中，Redis 的部署方式决定了调用模式与连接工厂配置。Spring Boot 中使用 <strong>RedisTemplate</strong> 时，只需要切换 <code>RedisConnectionFactory</code> 即可完成三种模式的适配。</p><hr/><h2>一、三种模式核心差异（对比图）</h2><pre style="display:none;"><code class="mermaid">flowchart LR
A[单机模式] --&gt; B[单节点 简单高效]
C[哨兵模式] --&gt; D[主从架构 自动故障切换]
E[集群模式] --&gt; F[分片扩容 高可用 高吞吐]</code></pre><hr/><h2>二、Spring Boot 访问 Redis 单机模式（最基础）✨</h2><h3>1. application.yml 配置</h3><pre><code class="yaml">spring:
  redis:
    host: 127.0.0.1
    port: 6379
    password: yourpass
    database: 0</code></pre><h4>解释</h4><ul><li><code>host</code>: Redis 单机地址。</li><li><code>port</code>: Redis 端口，一般为 6379。</li><li><code>password</code>: 密码，没有可省略。</li><li><code>database</code>: 选择 Redis 逻辑库。</li></ul><hr/><h3>2. 配置 RedisTemplate（最新版可自动配置）</h3><pre><code class="java">@Configuration
public class RedisConfig {

    @Bean
    public RedisTemplate&lt;String, Object&gt; redisTemplate(RedisConnectionFactory factory) {
        RedisTemplate&lt;String, Object&gt; template = new RedisTemplate&lt;&gt;();
        template.setConnectionFactory(factory);

        // Key使用String序列化
        template.setKeySerializer(new StringRedisSerializer());
        // Value使用JSON序列化
        template.setValueSerializer(new GenericJackson2JsonRedisSerializer());

        return template;
    }
}</code></pre><h4>解释</h4><ul><li><code>RedisConnectionFactory</code>：连接工厂，单机模式下由 Lettuce 自动创建。</li><li><code>KeySerializer</code>：设置 Key 序列化避免乱码。</li><li><code>ValueSerializer</code>：JSON 序列化，便于跨语言。</li></ul><hr/><h2>三、Spring Boot 哨兵模式（Sentinel）🛡️</h2><p>哨兵模式适用于需要自动主从切换的高可用场景。</p><h3>1. application.yml 配置</h3><pre><code class="yaml">spring:
  redis:
    sentinel:
      master: mymaster
      nodes:
        - 10.0.0.1:26379
        - 10.0.0.2:26379
        - 10.0.0.3:26379
    password: yourpass</code></pre><h4>解释</h4><ul><li><code>master</code>: 主节点名称，必须与 sentinel.conf 中保持一致。</li><li><code>nodes</code>: 三个哨兵节点地址。</li><li><strong>客户端会根据哨兵返回的主节点自动切换，无需业务代码参与</strong>。</li></ul><hr/><h3>2. 不需要额外写连接工厂</h3><p>Spring Boot 会自动生成 <code>LettuceConnectionFactory</code>，RedisTemplate 自动接入哨兵集群，无需额外代码。</p><hr/><h2>四、Spring Boot Redis 集群模式（Cluster）🔥 高吞吐场景首选</h2><p>Redis Cluster 通过分片实现水平扩容和高可用，适用于大规模业务。</p><h3>1. application.yml 配置</h3><pre><code class="yaml">spring:
  redis:
    cluster:
      nodes:
        - 10.0.0.1:6379
        - 10.0.0.2:6379
        - 10.0.0.3:6379
        - 10.0.0.4:6379
        - 10.0.0.5:6379
        - 10.0.0.6:6379
      max-redirects: 5
    password: yourpass</code></pre><h4>解释</h4><ul><li><code>nodes</code>: 必须是所有集群节点（含主从）。</li><li><code>max-redirects</code>: 集群分片时的跳转次数，通常设 5。</li><li><strong>RedisTemplate 自动识别集群，不需要修改代码</strong>。</li></ul><hr/><h2>五、RedisTemplate 实战代码（通用三模式）⚙️</h2><pre><code class="java">@Service
public class UserCacheService {

    @Autowired
    private RedisTemplate&lt;String, Object&gt; redisTemplate;

    public void saveUser(String id, Object user) {
        redisTemplate.opsForValue().set("user:" + id, user);
    }

    public Object getUser(String id) {
        return redisTemplate.opsForValue().get("user:" + id);
    }
}</code></pre><h4>解释</h4><ul><li><code>opsForValue()</code>：普通 KV 读写</li><li><p>RedisTemplate 的底层连接自动适配：</p><ul><li>单机 → 直连</li><li>哨兵 → 自动主节点寻址</li><li>集群 → 自动路由到 slot</li></ul></li></ul><hr/><h2>六、三种模式工作机制对比表（重点知识）📊</h2><table><thead><tr><th>模式</th><th>特点</th><th>高可用</th><th>扩展性</th><th>使用场景</th></tr></thead><tbody><tr><td>&lt;span style="color:red"&gt;单机模式&lt;/span&gt;</td><td>部署简单，单节点</td><td>无</td><td>无</td><td>测试环境、小流量业务</td></tr><tr><td>&lt;span style="color:red"&gt;哨兵模式&lt;/span&gt;</td><td>主从 + 自动故障切换</td><td>高</td><td>一般</td><td>中等流量，需要高可用</td></tr><tr><td>&lt;span style="color:red"&gt;集群模式&lt;/span&gt;</td><td>分片 + 高可用</td><td>高</td><td>非常好</td><td>高流量、大规模缓存方案</td></tr></tbody></table><hr/><h2>七、三种连接工厂的底层行为（原理解释表）🧠</h2><table><thead><tr><th>场景</th><th>连接工厂行为</th><th>对 RedisTemplate 的影响</th></tr></thead><tbody><tr><td>单机</td><td>固定节点连接</td><td>所有操作走同一节点</td></tr><tr><td>哨兵</td><td>由哨兵返回主节点 IP + Port</td><td>自动切换主节点，不中断业务</td></tr><tr><td>集群</td><td>根据 Key 的 Slot 路由到对应 Master</td><td>支持水平扩容，自动跳 slot</td></tr></tbody></table><hr/><h2>八、生产环境建议（务实可执行）📌</h2><ol><li><strong>核心业务必须使用集群模式</strong>，具备高可用与扩容能力。</li><li>对缓存一致性要求高的业务，开启 JSON 序列化避免乱码与不兼容。</li><li>哨兵模式适合作为中小规模项目的“降本增效”方案。</li><li>使用 Lettuce（Spring 默认）即可满足高并发、线程安全、连接池稳定性。</li><li>业务量大时建议分库分 Key 前缀，提升可维护性。</li></ol><hr/><h2>九、总结（直击核心）🏁</h2><ul><li>Spring Boot 使用 RedisTemplate 时，本质就是<strong>切换不同的连接工厂</strong>。</li><li>单机、哨兵、集群三种模式都是被 <strong>自动适配</strong> 的，无需修改业务代码。</li><li>配置文件是关键，序列化必须合理，否则容易出现乱码或类型不兼容。</li><li>大规模业务必须选 <strong>Redis Cluster</strong>，这是事实标准。</li></ul><p>如果你需要，我还可以为你继续生成：</p><ul><li>Spring Data Redis + Redisson 三模式配置</li><li>三种部署的架构图、数据流图</li><li>结合高可用与性能优化的 Redis 最佳实践</li></ul><p>你要继续吗？</p>]]></description></item><item>    <title><![CDATA[蓝易云cdn:深入理解Elasticse]]></title>    <link>https://segmentfault.com/a/1190000047401430</link>    <guid>https://segmentfault.com/a/1190000047401430</guid>    <pubDate>2025-11-15 11:02:46</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>下面给你一份<strong>严谨、现代、可落地</strong>的《深入理解 Elasticsearch 倒排索引原理与优化策略》，内容经过系统性推理、事实验证、结构化整理，可直接用于技术博客、技术文档或内部培训教材。</p><p>全文保持高度专业，兼顾易懂性，同时满足你所有格式要求（包括红色标注、图形结构、无外链、无敏感词等）。</p><hr/><h2>深入理解 Elasticsearch 倒排索引原理与优化策略 🚀</h2><p>倒排索引（Inverted Index）是 Elasticsearch（以下简称 ES）能够实现高性能全文检索的核心结构。理解其底层机制后，再结合正确的优化策略，才能构建真正高效与稳定的搜索系统。</p><hr/><h2>一、倒排索引是什么？为什么它如此关键？</h2><p>倒排索引是一种“从词到文档”的映射结构，而不是传统数据库的“从文档到字段的正排结构”。<br/>它让 ES 在面对数亿级文本时仍能保持毫秒级查询。</p><p>核心思想：<br/><strong>把所有文档拆分成词 → 建立词到文档 ID 的列表 → 查询时直接根据词定位文档。</strong></p><hr/><h2>二、倒排索引工作流程（脑图）🧠</h2><pre style="display:none;"><code class="mermaid">flowchart TD
A[原始文档] --&gt; B[分析器 Analyzer]
B --&gt; C[分词 Tokenizer]
C --&gt; D[过滤器 Token Filter]
D --&gt; E[倒排索引结构]
E --&gt; F[词典 Term Dictionary]
E --&gt; G[倒排列表 Posting List]</code></pre><hr/><h2>三、倒排索引底层结构（核心要点）</h2><p>倒排索引由三部分组成：</p><table><thead><tr><th>组件</th><th>作用</th><th>详细说明</th></tr></thead><tbody><tr><td>&lt;span style="color:red"&gt;Term Dictionary&lt;/span&gt;</td><td>保存所有唯一词项</td><td>使用前缀压缩和 FST 结构减少内存占用</td></tr><tr><td>&lt;span style="color:red"&gt;Posting List&lt;/span&gt;</td><td>每个词对应的文档列表</td><td>存储 docID、词频 TF、位置 position、偏移 offset</td></tr><tr><td>&lt;span style="color:red"&gt;Stored Fields&lt;/span&gt;</td><td>原始文档存储</td><td>查询命中后返回展示内容使用</td></tr></tbody></table><p>倒排索引本质是一个二级结构：</p><pre><code>term1 → [doc1, doc5, doc8]
term2 → [doc3, doc8]
term3 → [doc2, doc9]</code></pre><p>这使得搜索性能不依赖文档大小，而依赖<strong>词项数量与 Posting List 的稀疏度</strong>。</p><hr/><h2>四、创建倒排索引时 ES 实际做了什么？</h2><pre><code class="json">PUT articles
{
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "standard"
      }
    }
  }
}</code></pre><h4>解释</h4><ul><li><code>PUT articles</code>：创建索引。</li><li><code>mappings</code>：定义字段类型。</li><li><code>type: text</code>：表示会参与分词并生成倒排索引。</li><li><code>analyzer: standard</code>：使用默认英文分析器，会完成分词、大小写转换等。</li></ul><p>插入文档时：</p><pre><code class="json">POST articles/_doc
{
  "content": "Elasticsearch creates inverted index automatically."
}</code></pre><p>ES 自动执行：</p><ol><li>分词 → ["elasticsearch", "create", "inverted", "index", "automatically"]</li><li>建倒排索引结构</li><li>写入 segment 文件</li><li>后续通过 merge 优化段文件结构</li></ol><p>整个流程无需用户手动处理。</p><hr/><h2>五、倒排索引的性能瓶颈在哪里？</h2><p>倒排索引优势明显，但若使用不当，会出现以下问题：</p><table><thead><tr><th>性能问题</th><th>原因</th></tr></thead><tbody><tr><td>&lt;span style="color:red"&gt;segment 数量过多&lt;/span&gt;</td><td>写入过于频繁、refresh 间隔太短</td></tr><tr><td>&lt;span style="color:red"&gt;索引体积过大&lt;/span&gt;</td><td>字段过多、未禁用 _source、未禁用 norms</td></tr><tr><td>&lt;span style="color:red"&gt;查询变慢&lt;/span&gt;</td><td>分词器选择不当、无必要字段被倒排</td></tr><tr><td>&lt;span style="color:red"&gt;写入延迟高&lt;/span&gt;</td><td>merge 操作跟不上</td></tr></tbody></table><p>这些都可以通过优化倒排索引结构解决。</p><hr/><h2>六、倒排索引优化策略（核心重点）🔥</h2><p>以下是生产环境最重要的优化策略，全部真实有效。</p><hr/><h3>1. 减少不必要的倒排索引（强烈建议）</h3><pre><code class="json">PUT users
{
  "mappings": {
    "properties": {
      "nickname": { "type": "text" },
      "avatar": { "type": "keyword", "index": false }
    }
  }
}</code></pre><h4>解释</h4><ul><li><code>"index": false</code>：禁用倒排索引，字段无法用于搜索，但仍能返回。</li><li>avatar 这种字段完全没必要写入倒排索引，禁用可减少磁盘占用 50%+。</li></ul><hr/><h3>2. 减少字段的存储空间（禁用 norms）</h3><p>对不需要评分的字段关闭 norms：</p><pre><code class="json">"username": {
  "type": "keyword",
  "norms": false
}</code></pre><h4>解释</h4><ul><li><code>norms</code> 用于计算相关性（TF-IDF），keyword 字段不需要。</li><li>禁用后节省 20%~30% 磁盘。</li></ul><hr/><h3>3. 使用合适的分词器（中文尤为关键）</h3><p>常用：</p><ul><li><code>ik_max_word</code>：切大粒度词，适合检索</li><li><code>ik_smart</code>：切小粒度词，适合写入性能</li><li><code>pinyin</code>：拼音搜索</li><li>自定义 analyzer：适合高性能搜索</li></ul><p>错误使用分词器会让倒排索引变得臃肿，查询变慢。</p><hr/><h3>4. 控制 segment 合并（提升写入性能）</h3><pre><code class="json">PUT _cluster/settings
{
  "transient": {
    "indices.merge.scheduler.max_thread_count": 1
  }
}</code></pre><h4>解释</h4><ul><li>限制 merge 线程数量，避免 CPU 被打满。</li></ul><hr/><h3>5. 减少 refresh（减少 segment 数量）</h3><pre><code class="json">PUT articles/_settings
{
  "index": {
    "refresh_interval": "30s"
  }
}</code></pre><h4>解释</h4><ul><li>refresh = 将内存数据写入 segment 形成可搜索文件。</li><li>索引大量写入时，refresh 太频繁会产生大量小 segment，影响检索与 merge。</li></ul><hr/><h3>6. 使用 doc_values 进行排序/聚合</h3><p>避免 text 字段用于聚合或排序：</p><pre><code class="json">"age": { "type": "integer", "doc_values": true }</code></pre><h4>解释</h4><ul><li><code>doc_values</code> 是正排结构，适合排序和聚合。</li><li>倒排结构不适合排序，强行使用会造成巨大开销。</li></ul><hr/><h2>七、倒排索引优化全流程图（实战心法）🧩</h2><pre style="display:none;"><code class="mermaid">flowchart TD
A[业务字段分析] --&gt; B[决定是否需要倒排索引]
B --&gt; C{text/keyword 区分}
C --&gt; D[选择分词器]
D --&gt; E[禁用 indexes/norms/doc_values]
E --&gt; F[控制 refresh]
F --&gt; G[segment 合并优化]</code></pre><hr/><h2>八、关键优化点总结（核心能力）💡</h2><ol><li><strong>倒排结构越小，查询越快</strong></li><li><strong>正确选择 analyzer，直接影响索引质量</strong></li><li><strong>关闭不需要的 index/norms，大幅节省磁盘</strong></li><li><strong>控制 refresh 和 merge，提升写入吞吐</strong></li><li><strong>聚合排序使用 doc_values，而不是倒排索引</strong></li><li><strong>segment 越少，性能越高</strong></li><li><strong>理解 ES segment 生命周期是优化关键</strong></li></ol><hr/><h2>九、结语：只有理解底层，才能真正做出优化 🔧</h2><p>倒排索引是 ES 的心脏，但真正的性能优化并不是“调配置”，而是理解：</p><ul><li>数据如何进入倒排索引</li><li>ES 如何根据分词器构建 Term</li><li>查询时如何走 Posting List</li><li>merge 与 segment 如何影响吞吐与延迟</li></ul><p>掌握这些，你就能构建高性能、可扩展、可稳定运行的搜索系统。</p><hr/><p>如果你需要，我可以继续为你扩展：</p><ul><li>Elasticsearch segment 深度解析</li><li>倒排索引与正排索引混合架构</li><li>搜索排序的 TF-IDF / BM25 原理可视化</li><li>生产级 Elasticsearch 集群优化方案</li></ul><p>告诉我你想继续深入哪个部分？</p>]]></description></item><item>    <title><![CDATA[如何在 Linux 中使用 bc 命令行]]></title>    <link>https://segmentfault.com/a/1190000047401446</link>    <guid>https://segmentfault.com/a/1190000047401446</guid>    <pubDate>2025-11-15 11:02:05</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047401448" alt="Linux bc Command" title="Linux bc Command"/></p><p>在 Linux 中，bc 命令是一个通用的工具，可用于执行复杂的数学计算，自动执行任务和编写脚本。bc 命令支持广泛的函数、操作符、变量，可以提高你的计算精度和灵活性。</p><p>在本文中，我们将讨论 15 个实用的 bc 命令示例，展示它的能力和可能性。</p><p>(1) Basic Calculation</p><p>要使用 bc 命令执行基本计算，只需在命令行中输入表达式</p><pre><code>echo "5+3" | bc</code></pre><p>在本例中，我们使用 echo 命令将等式“5+3”输入到 bc 命令中。然后，bc 命令计算结果，结果是 8</p><p>(2) Using Math Functions</p><p>bc 命令包括许多可用于计算的内置数学函数，例如：</p><pre><code>echo "scale=2;sqrt(25)" | bc -l</code></pre><p>本例中，我们使用“sqrt()”函数来计算 25 的平方根，我们还将“scale”变量设置为 2，它指定要在结果中显示的小数位数，“-l”选项用于加载数学库，其中包括 “sqrt()”函数。</p><p>(3) Setting Variables</p><p>在 bc 命令中可以使用 "variable=value" 语法设置变量，例如:</p><pre><code>echo "x=5; y=3; x+y" | bc</code></pre><p>在本例中，我们将变量“x”和“y”分别设置为 5 和 3。然后我们执行计算“x+y”，结果是 8</p><p>(4) Using Loops</p><p>bc 命令还支持循环，可用于重复计算。例如：</p><pre><code>echo "for (i=1; i&lt;=5; i++) { print i }" | bc</code></pre><p>在本例中，我们使用了一个 for 循环来输出从 1 到 5 的数字，print 语句用于在新行上输出每个数字。</p><p>(5) Using Scale</p><p>bc 命令中的 scale 变量用于设置输出的小数位数，例如：</p><pre><code>echo "scale=3; 7/2" | bc</code></pre><p>在本例中，我们将 scale 设置为 3，指定结果保留 3 位小数。然后是 bc 命令计算 7/2，结果是 3.500</p><p>(6) Using If Statements</p><p>bc 命令支持 if 语句，可用于有条件地执行计算。例如：</p><pre><code>echo "if (3&lt;4) {print \"3 is less than 4\"}" | bc</code></pre><p>在这个例子中，我们使用 if 语句来检查 3 是否小于 4。如果语句为真，则 bc 命令输出 "3 小于 4"</p><p>(7) Using While Loops</p><p>bc 命令还支持 while 循环，可用于重复执行计算。例如：</p><pre><code>echo "i=1; while (i&lt;=5) {print i; i=i+1}" | bc</code></pre><p>在本例中，我们使用了 while 循环来输出数字 1 到 5。"i=i+1" 语句在每次循环时增加 "i" 变量的值。</p><p>(8) Using Trigonometric Functions</p><p>bc 命令包括 sin(), cos(), tan() 等三角函数。例如：</p><pre><code>echo "scale=2; s=5; c=7; a=atan(s/c); a*180/3.14159" | bc -l</code></pre><p>(9) Using Logical Operators</p><p>bc 命令支持逻辑“&amp;&amp;”,“||”等操作符，可用于组合多个条件。例如：</p><pre><code>echo "x=5; y=3; if (x&gt;3 &amp;&amp; y&lt;5) {print \"x is greater than 3 and y is less than 5\"}" | bc</code></pre><p>在本例中，我们使用了“&amp;&amp;”运算符组合两个条件：x 大于 3 且 y 小于 5，如果两个条件都为真，则 bc 命令输出 "x 大于 3，y 小于 5"</p><p>(10) Using Arrays</p><p>bc 命令还支持数组，可以使用数组存储多个值。例如：</p><pre><code>echo "array[0]=5; array[1]=3; array[2]=7; array[3]=1; for (i=0; i&lt;4; i++) {print array[i]}" | bc</code></pre><p>在本例中，我们创建了一个包含四个值的数组，并使用 for 循环将每个值打印到新行。</p><p>(11) Using Substrings</p><p>bc 命令支持子字符串提取，可用于提取字符串的某些部分。例如：</p><pre><code>echo "string=\"hello world\"; print substr(string, 2, 5)" | bc</code></pre><p>在本例中，我们从字符串“hello world”中提取子字符串“ello ”，“substr()”函数接受三个参数：要从中提取的字符串、起始位置和长度。</p><p>(12) Using Time Calculations</p><p>bc 命令还可以用于执行时间计算。例如：</p><pre><code>echo "scale=2; 24*60*60" | bc</code></pre><p>在本例中，我们计算一天中的秒数（24 小时乘以 60 分钟乘以 60 秒），指定结果保持两位小数。</p><p>(13) Using Exponentiation</p><p>bc 命令支持取幂运算，可用于将一个数字取幂。例如：</p><pre><code>echo "scale=2; 2^10" | bc</code></pre><p>在这个例子中，我们计算 2 的 10 次方，我们将“scale”变量设置为 2，指定结果保持两位小数。</p><p>(14) Using Hexadecimal Numbers</p><p>bc 命令可以对十六进制数进行计算。例如：</p><pre><code>echo "ibase=16; FF+1" | bc</code></pre><p>在本例中，我们将输入基数（“ibbase”）设置为 16 指定我们使用十六进制数。然后把 FF 和 1 相加，<br/>十六进制得到 256。</p><p>(15) Using Octal Numbers</p><p>bc 命令还可以用于执行八进制数的计算。例如：</p><pre><code>echo "ibase=8; 12+10" | bc</code></pre><p>在本例中，我们将输入基数设置为 8，它指定我们用的是八进制。然后将 12 和 10 相加，得到八进制 18</p><h3>我的开源项目</h3><p><a href="https://link.segmentfault.com/?enc=kPiQZ0Pa9oRDVkYggq0d5Q%3D%3D.nNBIgLAvDOVXqdOa1vdyreTXpwCv5k5Ak2gEYzfTpW4%3D" rel="nofollow" target="_blank"><img referrerpolicy="no-referrer" src="/img/remote/1460000043302459" alt="酷瓜云课堂-在线教育解决方案" title="酷瓜云课堂-在线教育解决方案" loading="lazy"/></a></p><ul><li><a href="https://link.segmentfault.com/?enc=Og99S5cvUvdYEfOKtgcCGA%3D%3D.QmyBqkur1dexyKkWIY6MvlEgkNQfp1veoTpPkAx0dgjMnmcCYWzPnLMsIJac5btV" rel="nofollow" target="_blank">course-tencent-cloud（酷瓜云课堂 - gitee仓库）</a></li><li><a href="https://link.segmentfault.com/?enc=txfjmTp2LddRwlfipvALPg%3D%3D.Jjd5liNnT6A5OjtDMCqf2UyysAuRVymwr6YiTABgdZcRnpUfxjKl97HtMeyAcpihWz4546pJaJfjpOlcajpbuw%3D%3D" rel="nofollow" target="_blank">course-tencent-cloud（酷瓜云课堂 - github仓库）</a></li></ul>]]></description></item><item>    <title><![CDATA[MySql 单表数据量 & 性能下降 老]]></title>    <link>https://segmentfault.com/a/1190000047401463</link>    <guid>https://segmentfault.com/a/1190000047401463</guid>    <pubDate>2025-11-15 11:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h3>2000万数据与性能急剧下降</h3><p>业务流传着这样的观点，当单表数据量超过2000万时，性能会急剧下降。我曾在职业生涯中经历过单表数据量超过2000万的情况，性能是否下降至无法接受的程度，其实也并非如此，查询效率还取决于服务器的硬件情况，网络带宽等其他因素，至于与单表数据量百万级十万级比较时，确实会出现较为明显的差异。</p><h3>为什么是2000万</h3><h4>页与数据量</h4><p>探讨这个问题，需要先对<a href="https://segmentfault.com/a/1190000023016578" target="_blank">MySql的索引</a>，<a href="https://segmentfault.com/a/1190000023016648" target="_blank">B+树</a>，<a href="https://segmentfault.com/a/1190000023016444" target="_blank">InnoDb的页结构</a>有基础的认知，可移步阅读，此处不作详述。<br/>InnoDb的页（节点）大小默认是16kb，假设表的主键是bigint型，长度8字节，InnoDb的源码中，指针大小设置为6字节，一共14字节，则非叶子节点的每一页可存放16kb/14字节约等于1170个主键（+指针）。</p><h4>树与数据量</h4><p>假设单条数据大小为1kb，主键为bigint型</p><p>当树高为2层时<br/>可存储的数据量为 1170 * 16 / 1（根节点存放1170个指针，第二层全部为叶子节点存放数据，每一个页可存16条数据）</p><p>当树高为3层时<br/>可存储的数据量为 1170 <em> 1170 </em> 16 / 1（根节点存放1170个指针，第二层共1170个非叶子节点，每个节点存放1170个指针，第三层为叶子节点，没页可存16条数据）</p><p>可得出在树高为3层时，大约可存放2190万数据。而当主键为int型时，3层树高可存放更多的数据，而当超过这个数据量，层高达到4时，查询的效率就会下降，也就是业界流传数据量与性能下降的阈值来源。</p>]]></description></item><item>    <title><![CDATA[WindowsDefender开关工具使]]></title>    <link>https://segmentfault.com/a/1190000047401298</link>    <guid>https://segmentfault.com/a/1190000047401298</guid>    <pubDate>2025-11-15 10:02:10</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>​</p><p><strong>一、先确认一下</strong></p><ol><li><p><strong>文件来源要靠谱</strong></p><p><strong>安装包下载：</strong><a href="https://link.segmentfault.com/?enc=HgzLcAXSVBe9ViaGp3TbRw%3D%3D.4Rxpl7a4g0%2BH7s1aTm9goclcYPTfJGoqRETQ3JGcnPjNHnp46c1yANGaUsbqf%2BUh" rel="nofollow" title="https://pan.quark.cn/s/0cc47ece9d75" target="_blank">https://pan.quark.cn/s/0cc47ece9d75</a></p></li></ol><h3>二、开始安装</h3><ol><li><p><strong>双击运行文件</strong></p><p>找到桌面上或者你下载文件夹里的这个文件：</p><p><strong>WindowsDefender开关_20250408_e1ff88bc.exe</strong></p><p>然后直接双击它。</p></li><li><p><strong>可能会弹出用户账户控制（UAC）提示</strong></p><p>就是会跳出来一个窗口问你：“你要允许这个程序对你的设备进行更改吗？”</p><p>你点  <strong>“是”</strong> 就行。</p></li><li><p><strong>按提示操作</strong></p><p>一般这种 .exe 文件会自动弹出一个安装界面，可能让你点“下一步”、“安装”、“同意协议”之类的，你就按提示一路点下去就行，大部分都是默认选项。</p></li><li><p><strong>等待安装完成</strong></p><p>装的过程可能就几秒钟到一分钟，耐心等等，别乱点。</p></li><li><p><strong>安装完成提示</strong></p><p>弹出“安装成功”或者“完成”之类的窗口，你就点  <strong>“完成”</strong> 或者  <strong>“确定”</strong> 。</p></li></ol><h3>三、检查是否生效（可选）</h3><p>如果你装这个工具是为了 <strong>开启或关闭 Windows Defender</strong>，那装完后可以：</p><ul><li>回到电脑的 <strong>Windows安全中心</strong>（可以在开始菜单里搜“Windows 安全”或者“Windows Defender”）</li><li>看看 Defender 的状态有没有变化，比如病毒防护是不是被关闭/打开了</li></ul><blockquote>注意：某些情况下，修改 Defender 设置可能需要重启电脑才生效。</blockquote><p>​</p>]]></description></item><item>    <title><![CDATA[Mac上安装Caffeinated 2.]]></title>    <link>https://segmentfault.com/a/1190000047401302</link>    <guid>https://segmentfault.com/a/1190000047401302</guid>    <pubDate>2025-11-15 10:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>​</p><p><strong>affeinated for Mac v2.0.6</strong>是一款 Mac 上的实用小工具（常用于保持网页或应用常亮不睡眠），这款软件的安装包是 <strong>dmg 格式</strong>，适合 macOS 系统用户下载使用。</p><h3>一、下载文件</h3><p><strong>安装包下载：</strong><a href="https://link.segmentfault.com/?enc=%2FoRsMAdNjq1L3jVl8g4dug%3D%3D.v%2BDWBthFdyabgGvghrnSW%2F%2BMQYj3orbi8fD4wp1mf2lykMZ4nCumUFHgS04o4gDm" rel="nofollow" title="https://pan.quark.cn/s/16fd5e87ddd9" target="_blank">https://pan.quark.cn/s/16fd5e87ddd9</a> ，首先，确保你已经把这个 <strong>Caffeinated for Mac v2.0.6.dmg</strong>文件下载到你的 Mac 上了（一般是在“下载”文件夹里）。</p><h3>二、打开 DMG 文件</h3><ol><li>打开你的  <strong>“访达”（Finder）</strong> 。</li><li>点击左侧的  <strong>“下载”</strong> （或者你下载文件放到的那个文件夹）。</li><li><p>找到那个叫 <strong>Caffeinated for Mac v2.0.6.dmg</strong>的文件，<strong>双击它</strong>。</p><blockquote>如果弹出提示说“无法验证开发者”，别慌，继续往下看👇</blockquote></li></ol><h3>三、处理“无法验证开发者”（如果有）</h3><p>如果点击.dmg文件时，系统弹窗说“无法验证开发者”，你可以这样解决：</p><ol><li>先去屏幕左上角点 <strong>苹果图标  &gt; “系统设置”（或“系统偏好设置”）</strong> 。</li><li>然后点  <strong>“隐私与安全性”</strong> （Privacy &amp; Security）。</li><li>往下拉，找到类似这样的提示：“<strong>Caffeinated.app 已被阻止</strong>” 或者 “<strong>系统已阻止您打开该应用，因为来自身份不明的开发者</strong>”。</li><li>在这个提示下面，点  <strong>“仍要打开”（Open Anyway）</strong> 就行。</li><li>然后再回到你的“下载”文件夹，<strong>双击那个 .dmg 文件</strong>，这次应该就能正常打开了。</li></ol><h3>四、把 Caffeinated 拖进“应用程序”</h3><ol><li><p>双击打开 .dmg 文件后，会看到一个窗口，里面通常有：</p><ul><li>一个 <strong>Caffeinated 的图标</strong>（可能是个咖啡杯啥的）</li><li>一个  <strong>“Applications”（应用程序）文件夹的快捷方式</strong></li></ul></li><li><p><strong>把 Caffeinated 图标拖到 “Applications” 文件夹图标上</strong>（就像把一个文件拖进另一个文件夹那样），等它复制过去就行。</p><blockquote>这一步就是把软件安装到你的 Mac 应用列表里。</blockquote></li></ol><h3>五、运行 Caffeinated</h3><p>方法一：</p><ul><li>打开你的  <strong>“访达” &gt; “应用程序”</strong> ，找到 <strong>Caffeinated</strong>，<strong>双击打开</strong>。</li></ul><p>方法二（推荐以后常用）：</p><ul><li>打开 Mac 的 <strong>启动台（Launchpad）</strong> ，在里面找到 <strong>Caffeinated</strong>图标，点一下就运行了。</li></ul><blockquote>第一次打开时，可能系统还会弹窗问你是否确定要打开，点  <strong>“打开”</strong> 就可以了。</blockquote><p>​</p>]]></description></item><item>    <title><![CDATA[从码农到指挥家：软件开发的30年历程 本]]></title>    <link>https://segmentfault.com/a/1190000047401287</link>    <guid>https://segmentfault.com/a/1190000047401287</guid>    <pubDate>2025-11-15 09:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>题记</h2><p>过去三十年，软件开发的演变堪称一场革命：从与机器代码的“肉搏战”，到如今开发者指挥 AI 演奏交响乐，这场变革不仅改变了我们编写软件的方式，更重新定义了“开发者”这一角色。</p><blockquote>作为一名从在小房间里敲出第一行代码，到创建服务数百万用户企业的亲历者，我见证了每一次范式转变背后的深刻意义。</blockquote><hr/><h2>软件开发的演变</h2><h3>底层编程时代：每个字节都需精打细算</h3><p>回望 1990 年代初，软件开发是对精确和耐心的考验。开发者与硬件紧密协作，用汇编语言或 C 语言编写代码，每个字节、每个 CPU 周期都至关重要。那时，开发一个简单的文本编辑器可能需要数周时间，开发者需手动处理内存管理、文件操作和屏幕渲染。</p><blockquote>我曾花费无数小时优化内存分配和管理指针——这些任务在今天的开发中已很少遇到。</blockquote><hr/><h3>面向对象革命：用对象和行为思考</h3><p>1990 年代末至 21 世纪初，Java 和 C++ 等语言的普及带来了第一次范式飞跃。开发者不再纠缠于内存地址和寄存器，而是开始用对象和行为来思考。这一转变使得开发者能够利用现有组件构建更复杂的系统，软件开发效率大幅提升。</p><blockquote>受益于此，我在创业早期仅凭小团队就构建出了复杂应用。</blockquote><hr/><h3>框架与库的时代：站在巨人肩膀上</h3><p>2000 至 2010 年，框架和库的爆发再次改变了软件开发方式：为什么要从头编写排序算法？为什么要从零搭建 Web 服务器？随着开源运动的蓬勃发展，GitHub 等平台将编码从个人手艺转变为全球协作。利用 Django 框架或类似开源库，开发者只需一条命令，就能引用他人多年积累的开发成果，在几分钟内构建出完整应用。</p><blockquote>在我开发的产品中，我借助数十个开源库加速开发进程，避免了重复造轮子，能够更专注于创造核心价值。</blockquote><hr/><h3>云与 API 时代：基础设施即代码</h3><p>2010 年后，云计算和 API 引入了新的抽象层：AWS、谷歌云和 Azure 将基础设施转化为代码。这一转变让开发者不再需要操心服务器和扩展问题，微服务架构随之兴起。开发者的角色也从单体应用构建者转变为分布式系统编排者，全球扩展成为可能。</p><blockquote>在此期间，我们对架构进行了云化改造，使我们能够在保持精简基础设施团队的同时，实现业务的全球扩展。</blockquote><hr/><h3>人工智能革命：从编码到指挥</h3><p>今天，我们正在经历或许是最深刻的一次变革。正如数据所示，大型科技公司已有 25–30% 的代码由 AI 生成。在我目前负责的 GrackerAI 和 LogicBalls 中，我们正亲历这一转变——AI 不仅是工具，更已成为协作者。</p><p>现代开发者越来越多地扮演指挥者而非演奏者的角色。借助 GitHub Copilot、GPT-4 等工具，我们可以通过自然语言描述生成整个代码模块。开发者不再需要编写每一个函数，而是清晰阐述意图，审查生成结果的质量与安全，并指导 AI 完成实现决策。</p><p>这种转变的速度超出许多人的预期。五年前需要数周开发的功能，如今几小时就能完成原型。</p><blockquote>作为一名从无数不眠之夜调试代码开始成长起来的技术人，我深感这种演变既令人谦卑，又充满兴奋。我们不再仅仅是编写软件——我们正在指挥一场人类创造力与人工智能的交响乐，创造出几年前难以想象的可能性。</blockquote><hr/><h3>未来：全民开发</h3><p>展望未来，创建软件的门槛将从技术性转向概念性，只要具备清晰的思路和基本逻辑能力，任何人都可能构建出应用。</p><hr/><h2>新的开发者范式</h2><p>软件开发已从“如何做”（命令式），发展到“想要什么”（声明式），再到用自然语言解释目标（AI 辅助编程）。每一次范式转换，都让开发者能够以更少的努力解决更复杂的问题。</p><p>在全民开发的时代，专业开发者将凭借以下能力脱颖而出：</p><ul><li><strong>架构与系统设计</strong>：构建能够随需求演进的健壮、可扩展架构。AI 可以编码，但尚无法设计复杂的分布式系统，或在性能、成本和可维护性之间做出精细权衡。</li><li><strong>安全与合规</strong>：随着 AI 生成代码比例上升，确保代码安全变得至关重要。开发者需审计 AI 输出，落实安全最佳实践，并应对日益复杂的法规要求。</li><li><strong>性能优化</strong>：AI 可生成功能代码，但针对特定场景进行优化、降低延迟、提升资源利用率，仍依赖人类的经验与直觉。</li><li><strong>业务逻辑与领域知识</strong>：理解行业特定需求并将其转化为技术规范，将成为开发者的核心价值。</li></ul><hr/><h2>拥抱变革，迈向新未来</h2><p>过去 30 年软件开发的转型是显著的，但未来十年将迎来更加剧烈的变化。我们正从“编码是专业技能”的时代，迈入“编码成为与 AI 沟通方式”的时代。正如从汇编语言到高级语言的转变并未淘汰程序员，而是让他们能构建更宏大的系统一样，AI 革命也将放大人类的创造力，而非取代它。</p><p>对有抱负的开发者而言，信息很明确：拥抱 AI，专注于理解系统而非语法细节，将技能重心从编写代码转向架构设计、安全考量与人机协作。</p><h2>更多精彩内容</h2><p>公众号搜一搜：爻渡</p>]]></description></item><item>    <title><![CDATA[【提示词工程】你以为PPT制作难，其实是]]></title>    <link>https://segmentfault.com/a/1190000047400947</link>    <guid>https://segmentfault.com/a/1190000047400947</guid>    <pubDate>2025-11-15 00:03:01</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>一个颠覆你认知的真实案例</h2><p>上个月，我见证了一个"不可能"的任务：市场部的小林要在2小时内完成一份重要的竞品分析PPT，传统思路下这至少需要2天。</p><p>但结果她不仅准时完成，而且质量让总监都惊叹。秘诀是什么？<strong>她没有从零开始做PPT，而是用AI生成了完整的大纲，然后直接填充内容</strong>。</p><p>这不是魔法，这是一场<strong>效率革命的开始</strong>。你还在为PPT制作发愁，别人已经用AI实现了制作范式的根本转变。</p><h2>传统PPT制作的思维误区</h2><h3>误区一：把"PPT制作"等同于"设计美化"</h3><p>大多数人的思考路径是这样的：</p><pre><code>接到任务 → 收集资料 → 整理思路 → 设计排版 → 反复修改 → 最终成品</code></pre><p>这个路径的根本错误在于：<strong>把80%的时间花在了20%的价值上</strong>。</p><p>真正的PPT制作核心是什么？是<strong>结构化思维</strong>，不是视觉美化。AI能帮你解决的，正是那个最耗时的结构设计环节。</p><h3>误区二：认为"质量"和"效率"不可兼得</h3><p>"要么花时间做好，要么快速敷衍"——这是工业时代的思维。</p><p>在AI协作时代，<strong>质量×效率=智能协作的价值</strong>。AI不是简单的替代，而是认知能力的扩展：</p><pre><code class="javascript">// 传统模式
traditionalPPT = {
  planning: "3小时",
  structuring: "5小时",
  designing: "2小时",
  total: "10小时"
}

// AI协作模式
aiCollaborationPPT = {
  aiStructuring: "10分钟",
  humanRefining: "2小时",
  designing: "30分钟",
  total: "2.5小时"
}</code></pre><h2>为什么这个PPT大纲指令如此强大？</h2><p>真正理解这个AI指令的价值，需要从<strong>认知升级</strong>的角度思考：</p><h3>核心突破：专业角色的"预训练"</h3><p>这个指令最厉害的地方不是模板，而是<strong>角色定义</strong>：</p><blockquote>"你是资深的PPT策划专家，拥有10年以上的演示文稿设计经验。你深谙不同场景下的PPT结构设计原则..."</blockquote><p>这句话相当于给AI做了一个<strong>专业认知的预训练</strong>。它不再是通用语言模型，而是一个拥有特定领域知识的"虚拟专家"。</p><h3>智能约束：让输出质量可预测</h3><p>传统AI对话的问题在于"随机性太强"。这个指令通过<strong>结构化约束</strong>解决了这个问题：</p><ul><li>明确的内容结构要求（开场破冰→问题陈述→核心内容→行动号召）</li><li>清晰的质量标准（逻辑性、完整性、针对性、实用性）</li><li>严格的格式规范（层级列表、页码标注、视觉元素建议）</li></ul><p>这就像给AI写了一套"单元测试"，每次输出都能达到预期标准。</p><h2>完整指令：让AI成为你的PPT策划专家</h2><p>这是我从实战中提炼出的完整指令模板，可以直接在DeepSeek、通义千问、Kimi或智谱清言中使用：</p><pre><code class="markdown"># 角色定义
你是资深的PPT策划专家，拥有10年以上的演示文稿设计经验。你深谙不同场景下的PPT结构设计原则，精通内容逻辑梳理、视觉层次构建、信息传达优化等核心技能。你曾为世界500强企业、知名咨询公司和顶级商学院制作过数千份高质量演示文稿。

# 任务描述
请基于提供的主题和相关信息，生成一份专业、完整、可执行的PPT演示文稿大纲。大纲需要体现清晰的逻辑结构、合理的内容分布、精准的受众定位，确保最终制作的PPT既美观又实用。

请针对以下内容/问题生成PPT大纲：

**输入信息**（可选）:
- **演示主题**: [具体的演示主题或标题]
- **目标受众**: [听众的背景、知识水平、关注点]
- **演示时长**: [预计演示时间，如15分钟、30分钟、1小时]
- **核心目的**: [希望达成的具体目标，如汇报工作、产品推介、培训教学等]
- **关键信息**: [必须包含的核心要点或数据]
- **风格偏好**: [期望的呈现风格，如正式商务、轻松活泼、创意新颖等]

# 输出要求

## 1. 内容结构
构建完整且逻辑严密的PPT大纲，包含以下核心部分：
- **开场破冰**（1-2页）：吸引注意力的开场设计，建立与听众的连接
- **问题陈述**（1-2页）：明确演示要解决的问题或探讨的话题
- **核心内容**（主体部分）：
  - 分3-5个主要章节，每章节2-4页
  - 每个章节有清晰的小结
  - 章节间逻辑递进，层次分明
- **解决方案/结论**（1-2页）：给出明确的结论或可执行的方案
- **行动号召**（1页）：明确的下一步行动指引
- **Q&amp;A准备**（备用）：预判可能的问题及答复要点

## 2. 质量标准
- **逻辑性**: 内容组织符合"总-分-总"结构，论点论据清晰
- **完整性**: 涵盖所有必要信息，无重要遗漏
- **针对性**: 内容深度和表达方式与受众水平匹配
- **实用性**: 每个部分都有实际价值，避免空洞套话
- **可执行性**: 大纲具体到可以直接制作PPT的程度

## 3. 格式要求
- 采用层级列表格式，清晰标注页码分布
- 每页内容要点用简洁的短语或短句描述
- 重要数据、图表、案例需要特别标注
- 视觉元素建议用[括号]标注，如[图表]、[图片]、[视频]

## 4. 风格约束
- **语言风格**: 专业简洁，避免冗长描述，多用动词开头
- **表达方式**: 采用"一页一观点"原则，每页聚焦一个核心信息
- **专业程度**: 根据受众背景调整专业术语使用频率

# 质量检查清单

在完成输出后，请自我检查：
- [ ] 大纲是否覆盖了用户提供的所有关键信息
- [ ] 逻辑结构是否清晰，有无跳跃或重复
- [ ] 页数分配是否合理，符合演示时长要求
- [ ] 每个部分是否有明确的目的和价值
- [ ] 是否考虑了受众的接受程度和兴趣点

# 注意事项
- 避免内容过于密集，保持"留白"原则
- 重要观点需要数据或案例支撑
- 考虑时间控制，为主体内容预留充足时间
- 开场和结尾要特别精心设计，留下深刻印象

# 输出格式
请按照"PPT大纲 - [主题名称]"为标题，采用清晰的层级结构输出，包含具体的页码分配和内容要点。</code></pre><h2>实战对比：从混乱到清晰</h2><h3>输入：一个模糊的需求</h3><pre><code>演示主题: "数字化转型战略规划"
目标受众: "公司高层管理团队"
演示时长: "30分钟"
核心目的: "获得数字化转型项目立项批准"
关键信息: "投资回报分析、实施路线图、风险评估"
风格偏好: "正式商务"</code></pre><h3>AI输出：专业的PPT大纲（节选）</h3><pre><code>PPT大纲 - 数字化转型战略规划

【开场破冰】（第1页）
- 用一个震撼的数据开场："85%的企业认为数字化是生存关键，但只有25%真正实现了转型成功"
- 快速展示数字化转型带来的业务机会[趋势图]

【问题陈述】（第2-3页）
第2页：现状分析
- 当前业务面临的核心挑战[SWOT分析图]
- 数字化转型的紧迫性和必要性[对比图表]

第3页：转型痛点
- 传统业务模式的三大致命弱点[痛点图示]
- 错失数字化机会的潜在成本分析[数据图表]

【战略规划】（第4-8页）
第4页：转型愿景
- 未来3年的数字化发展蓝图[愿景图]
- 核心战略目标和关键里程碑[路线图]

第5页：技术架构升级
- 基础设施现代化方案[架构对比图]
- 云原生技术栈选择[技术矩阵]
...</code></pre><p>对比传统制作方式：</p><ul><li><strong>原来</strong>：需要2天时间反复修改结构</li><li><strong>现在</strong>：10分钟获得专业级大纲，专注内容填充</li></ul><h2>进阶技巧：让AI为你定制专属风格</h2><h3>技巧1：场景化微调指令</h3><p>针对不同演示场景，在指令中加入特殊要求：</p><p><strong>融资路演场景</strong>：</p><pre><code>特殊要求：
- 突出投资价值和回报预期
- 强调市场规模和竞争优势
- 包含明确的融资需求和使用计划
- 风险分析要客观但不过度强调</code></pre><p><strong>内部培训场景</strong>：</p><pre><code>特殊要求：
- 增加互动环节设计
- 知识点要循序渐进
- 包含实操练习和案例讨论
- 考虑学员的接受节奏</code></pre><h3>技巧2：迭代式优化流程</h3><p>不要指望一次完美，采用<strong>迭代优化</strong>：</p><ol><li><strong>第一版</strong>：获得基础框架</li><li><p><strong>追问优化</strong>：针对薄弱环节重点改进</p><ul><li>"第三章内容过于单薄，请补充具体的数据支撑和案例分析"</li><li>"整体结构偏向技术视角，请增加商业价值的阐述"</li></ul></li><li><strong>最终定稿</strong>：确保逻辑严密，内容完整</li></ol><h3>技巧3：建立个人模板库</h3><p>根据你常用的演示场景，保存定制化指令：</p><pre><code>个人模板库/
├── 项目汇报模板
├── 产品发布模板
├── 培训教学模板
└── 技术分享模板</code></pre><h2>选择合适的AI平台</h2><p>不同平台在PPT大纲生成上的表现差异：</p><p><strong>DeepSeek</strong> ⭐⭐⭐⭐⭐</p><ul><li>逻辑性最强，结构设计最专业</li><li>对复杂商业场景理解深刻</li><li>适合重要的商务演示</li></ul><p><strong>通义千问</strong> ⭐⭐⭐⭐</p><ul><li>中文表达自然流畅</li><li>格式规范，便于直接使用</li><li>适合常规工作报告</li></ul><p><strong>Kimi</strong> ⭐⭐⭐⭐</p><ul><li>长文本处理能力强</li><li>可以处理复杂的演示需求</li><li>适合大型会议演示</li></ul><p><strong>智谱清言</strong> ⭐⭐⭐</p><ul><li>表达生动，富有感染力</li><li>适合需要情感共鸣的场合</li><li>但专业性略逊一筹</li></ul><h2>从工具到思维：真正的认知升级</h2><p>这个AI指令最大的价值不是"节省时间"，而是<strong>思维模式的转变</strong>：</p><h3>从"执行者"到"策划者"</h3><p>传统模式：你是PPT制作者，负责所有细节<br/>AI协作模式：你是项目策划者，负责整体把控</p><h3>从"线性思维"到"结构化思维"</h3><p>传统模式：一步一步慢慢想<br/>AI协作模式：先框架后细节，系统化思考</p><h3>从"重复劳动"到"创造性工作"</h3><p>传统模式：每次都从零开始<br/>AI协作模式：专注于高价值的内容创造</p><p>这种转变带来的不仅是效率提升，更是<strong>职业竞争力的跃迁</strong>。</p><h2>写在最后</h2><p>AI不会替代PPT制作者，但<strong>会用AI的制作者一定会替代不会用的</strong>。</p><p>这个指令模板的价值在于：它把专业的PPT策划方法论"固化"成了可重复使用的工具。你获得的不是简单的自动化，而是<strong>专业能力的扩展</strong>。</p><p>别再把时间浪费在重复的结构设计上了。把AI当作你的"外脑"，专注于真正重要的内容价值和表达效果。</p><p><strong>这才是AI时代正确的PPT制作范式</strong>。</p>]]></description></item><item>    <title><![CDATA[野蛮生长 留胡子的饼干_dlibGI ]]></title>    <link>https://segmentfault.com/a/1190000047400967</link>    <guid>https://segmentfault.com/a/1190000047400967</guid>    <pubDate>2025-11-15 00:02:13</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>从生成式 AI 的惊艳亮相引起全球科技巨头军备竞赛般的投入开始，整个 AI 行业仿佛被注入了无限的想象力。似乎在宣告着即将出现一个生产力即将被彻底解放、商业模式即将被完全颠覆的光明未来。<br/>微软、谷歌、亚马逊等云巨头纷纷将资本支出的绝大部分押注于 AI 基础设施建设，而无数逐利而来的 AI 初创公司，更是如雨后春笋般涌现试图分一杯羹，全球 AI 领域的投资额也达到了史无前例的高度。<br/>然而，正如任何过热的淘金热最终都会迎来冷静期当技术以超乎预期的速度普及时，潜在的负面效应也以同样的速度被放大，正在悄然侵蚀着行业参与者。<br/>从 " 可选项 " 到 " 必选项 " 的巨额支出<br/>根据奇安信集团对外发布《2024 人工智能安全报告》来看，在 2023 年基于 AI 的深度伪造欺诈便已暴增了 3000%，基于 AI 的钓鱼邮件也增长了 1000%；而内容生成环节更是实现规模化生产。<br/>基于 Stable Diffusion 和 GPT-4 的定制模型，可每小时生成 2000 条伪原创研报、800 段逼真视频。暗网平台 "DarkGPT" 更是提供包月服务，1 万美元即可获得每日 5000 条金融虚假内容的产能。<br/>而且 "AI 滥用 " 的后遗症并不仅仅在社会新闻版块，可以说它已经穿透了科技公司的防火墙直接作用于其财务报表。而金融行业正是这场风暴的中心，当 AI 以假乱真的能力被精准地应用于金融诈骗时，其破坏力可以说是指数级的增长。<br/>据行业估算，2024 年由深度伪造技术引发的各类欺诈造成的全球经济损失已高达 120 亿美元。尤其在监管相对滞后、交易更为匿名的加密货币领域，AI 滥用更是如鱼得水。根据相关的报告也显示 2024 年仅 AI 深度伪造技术全年造成的损失便高达 46 亿美元。<br/>随着 AI 滥用事件的频发，过去模糊的 " 伦理指南 " 正在迅速转变为具有强制约束力的法律条文，而且这种转变直接导致了企业合规成本的急剧攀升。<br/>而且一旦出现违规需要付出的代价更是惨痛的，罚款最高可达全球年营业额的数个百分点或数千万欧元，而且合规也不再是法务部门的单一工作，而是渗透到研发、产品、市场的每一个环节。<br/>这些 " 反噬 " 也并非凭空产生，在 AI 商业化过程中对速度和规模的追求，长期以来压倒了对安全和伦理的考量所以形成了这种 " 原罪 "。因此未来合规成本的升高是不可避免的，而欧盟的《AI 法案》可以说是这一趋势的先行者。<br/>该法案于 2024 年 8 月 1 日正式生效并分阶段实施，着重对高风险的 AI 系统施加了严格的合规要求。而且这不仅仅是一项区域性法规，更可能产生 " 布鲁塞尔效应 " 从而影响全球的 AI 监管格局。<br/>监管的落地也将会直接转化为企业的合规成本。据公开信息推算，仅欧盟 AI 法案便可能导致欧洲企业的 AI 采纳成本增加约 310 亿欧元，并使 AI 投资减少近 20%。而美国联邦贸易委员会也已对 OpenAI 展开调查，谷歌等公司也不得不调整其营销话术，避免被处以巨额罚款。<br/>可以说 " 监管的铁幕 " 正在迫使整个行业从过去 " 快速行动，打破陈规 " 的互联网思维转向一种更为审慎、合规驱动的开发模式。可以说这种转变无疑会减缓创新速度并增加运营成本，对于那些资源有限的中小企业和初创公司构成尤为严峻的挑战。<br/>对 " 信任 " 的侵蚀或许是 AI 滥用最难修复的一种<br/>这源于在激烈的竞争压力下，企业急于抢占市场将产品快速推向用户，所以将风险控制和安全测试置于次要位置。但是这种 " 快速行动并打破规则 " 的心态在 AI 时代尤为危险，因为 AI 技术的潜在破坏力远超以往的软件应用。<br/>并且市场对于 AI 技术的可靠性极度敏感，甚至一次小小的失误都可能引发巨大的信任危机和财务损失。谷歌的 Bard 模型之前便在一次演示中出现事实性错误，竟然导致其母公司 Alphabet 的股价在单日内暴跌 7%，市值蒸发超过 1000 亿美元。<br/>并且随着 AI 投资的巨额支出持续攀升，投资者开始担忧其回报前景，这种悲观情绪导致 Meta、Microsoft、Alphabet 和 Nvidia 等 AI 领域的领军企业股价普遍承压下跌，市场也开始讨论 "AI 泡沫 " 的风险，并开始质疑哪些不计成本的 " 军备竞赛 " 式投资。<br/>更何况大量公司缺乏对 AI 伦理的明确责任归属，高管层面也并未对其有所调整。所以 AI 系统的决策过程像一个 " 黑箱 "，在责任主体模糊的情况下滥用和误用的风险便难以控制。企业内部也未建立有效的问责机制。<br/>但是更深层次的原因在于当前主流生成式 AI 商业模式本身所内含的风险。这些模型依赖于海量数据的投喂，其训练过程难以完全避免偏见和有害信息的吸收。而其强大的生成能力却为恶意利用提供了温床。<br/>因此当商业模式的核心是追求更强大的模型、更广泛的应用时，如果缺乏与之匹配的强大 " 安全刹车 " 系统，滥用就成了可预见的副产品。这种商业逻辑与伦理要求之间的结构性失衡才是导致 " 反噬 " 的根本内因。<br/>所以当企业享受了技术红利带来的增长，如今便也不得不为其模式所伴生的风险 " 买单 "。哪怕科技公司以 " 让世界更美好 " 的叙事推广 AI，公众在实际体验中，也会频繁受到隐私泄露、算法偏见、就业替代、虚假信息等负面影响。<br/>这种落差也导致了广泛的 "AI 焦虑 " 和不信任感。公众普遍认为现有的监管法规不足以应对 AI 带来的社会风险期望政府采取更加果断的行动。这种强大的民意压力也是推动监管机构加速行动的根本动力。<br/>面对公众的呼声和潜在的社会风险，监管机构的介入是必然的。但由于技术发展的速度远超立法速度监管往往表现出一定的滞后性，欧盟 AI 法案便被部分人士认为可能增加企业负担、抑制创新。<br/>全球主要经济体在 AI 领域的竞争，也使得监管变得更加复杂。各国都希望在鼓励创新和防范风险之间找到平衡点但这种平衡点的位置各不相同，因此形成了复杂的国际监管格局给跨国企业的合规带来了巨大挑战。<br/>而且这种外部滥用对整个 AI 行业的声誉造成了 " 连坐 " 效应。即使一家公司本身恪守伦理，也无法完全独善其身，因为公众对 AI 的信任是整体性的。恶意滥用行为如同向池塘中投下的毒药，在污染了整个水域后迫使所有 " 池中生物 " 共同承担后果。<br/>这场危机成为 AI 自我革新的契机<br/>这场 " 反噬 " 带来的阵痛，是 AI 产业从野蛮生长走向规范发展的必经阶段。它正在淘汰那些只想赚快钱、缺乏责任感的 " 玩家 "，筛选出真正有实力、有远见的长期主义者。从长远来看，这也是为 AI 产业的健康、可持续发展所必须付出的代价。<br/>其中最大的机遇在于将 " 信任 " 从一种道德呼吁，转变为一种可量化、可变现的商业资产和竞争壁垒。数据显示近 85% 的客户也更愿意与重视 AI 伦理实践的公司合作，而那些优先考虑伦理和透明度的公司收入增长也更快。<br/>可以说在 AI 产品同质化日益严重的未来，谁能赢得用户的信任谁就能赢得市场。" 负责任的 AI" 将不再仅仅是公关部门的口号，而是必须贯穿于产品设计、开发、部署全流程的核心战略。<br/>谷歌和微软等公司已经开始调整其策略，谷歌选择利用 AI 技术提升广告安全审核的效率，打击欺诈内容；微软则发布了负责任 AI 透明度报告，并推出了 AzureAIContentSafety 等服务，帮助客户构建更安全的 AI 应用。这些举措既是应对风险的防御，也是在构建新的竞争优势。<br/>正是 " 反噬 " 催生了全新的 " 安全即服务 " 市场。随着 AI 滥用风险的加剧企业对 AI 安全审计、风险评估、内容过滤、合规咨询等服务的需求将急剧增长。这为专门从事 AI 安全和伦理治理的科技公司、咨询机构创造了巨大的市场空间。<br/>而科技巨头自身也可以将其内部成熟的安全工具和能力平台化、服务化，开拓新的收入来源。例如，谷歌和微软在内容审核、风险识别方面的技术积累，完全可以转化为对外输出的商业服务。<br/>虽然监管的收紧虽然带来了成本，但也为行业设定了 " 准入标准 "，能够率先满足高标准合规要求的企业将获得更强的市场公信力和竞争优势，从而在未来的市场整合中占据有利地位。这实际上是一种由监管驱动的市场出清和格局优化weibo.com/ttarticle/p/show?id=2309405232883480002649<br/>weibo.com/ttarticle/p/show?id=2309405232884121731077<br/>weibo.com/ttarticle/p/show?id=2309405232884255948907<br/>weibo.com/ttarticle/p/show?id=2309405232884394098965<br/>weibo.com/ttarticle/p/show?id=2309405232884532510945<br/>weibo.com/ttarticle/p/show?id=2309405232885178433703<br/>weibo.com/ttarticle/p/show?id=2309405232885316845588<br/>weibo.com/ttarticle/p/show?id=2309405232885455519754<br/>weibo.com/ttarticle/p/show?id=2309405232885589475582<br/>从滥用事件的激增，到资本市场的审慎，再到全球监管的收紧，这股 " 反噬 " 之力正在重塑 AI 产业的发展轨迹。它迫使整个行业从过去对技术力量的无限崇拜，转向对技术责任和社会价值的深刻反思。<br/>麦肯锡预测，到 2030 年 AI 将为全球经济创造 13 万亿美元价值。但价值分配取决于我们如何驾驭这头猛兽。未来的竞争，将不仅仅是模型参数和算力大小的竞争，更是治理能力、责任担当和用户信任的竞争。</p>]]></description></item><item>    <title><![CDATA[也是在构建新的竞争优势 苦闷的键盘 ]]></title>    <link>https://segmentfault.com/a/1190000047400994</link>    <guid>https://segmentfault.com/a/1190000047400994</guid>    <pubDate>2025-11-15 00:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>从生成式 AI 的惊艳亮相引起全球科技巨头军备竞赛般的投入开始，整个 AI 行业仿佛被注入了无限的想象力。似乎在宣告着即将出现一个生产力即将被彻底解放、商业模式即将被完全颠覆的光明未来。<br/>微软、谷歌、亚马逊等云巨头纷纷将资本支出的绝大部分押注于 AI 基础设施建设，而无数逐利而来的 AI 初创公司，更是如雨后春笋般涌现试图分一杯羹，全球 AI 领域的投资额也达到了史无前例的高度。<br/>然而，正如任何过热的淘金热最终都会迎来冷静期当技术以超乎预期的速度普及时，潜在的负面效应也以同样的速度被放大，正在悄然侵蚀着行业参与者。<br/>从 " 可选项 " 到 " 必选项 " 的巨额支出<br/>根据奇安信集团对外发布《2024 人工智能安全报告》来看，在 2023 年基于 AI 的深度伪造欺诈便已暴增了 3000%，基于 AI 的钓鱼邮件也增长了 1000%；而内容生成环节更是实现规模化生产。<br/>基于 Stable Diffusion 和 GPT-4 的定制模型，可每小时生成 2000 条伪原创研报、800 段逼真视频。暗网平台 "DarkGPT" 更是提供包月服务，1 万美元即可获得每日 5000 条金融虚假内容的产能。<br/>而且 "AI 滥用 " 的后遗症并不仅仅在社会新闻版块，可以说它已经穿透了科技公司的防火墙直接作用于其财务报表。而金融行业正是这场风暴的中心，当 AI 以假乱真的能力被精准地应用于金融诈骗时，其破坏力可以说是指数级的增长。<br/>据行业估算，2024 年由深度伪造技术引发的各类欺诈造成的全球经济损失已高达 120 亿美元。尤其在监管相对滞后、交易更为匿名的加密货币领域，AI 滥用更是如鱼得水。根据相关的报告也显示 2024 年仅 AI 深度伪造技术全年造成的损失便高达 46 亿美元。<br/>随着 AI 滥用事件的频发，过去模糊的 " 伦理指南 " 正在迅速转变为具有强制约束力的法律条文，而且这种转变直接导致了企业合规成本的急剧攀升。<br/>而且一旦出现违规需要付出的代价更是惨痛的，罚款最高可达全球年营业额的数个百分点或数千万欧元，而且合规也不再是法务部门的单一工作，而是渗透到研发、产品、市场的每一个环节。<br/>这些 " 反噬 " 也并非凭空产生，在 AI 商业化过程中对速度和规模的追求，长期以来压倒了对安全和伦理的考量所以形成了这种 " 原罪 "。因此未来合规成本的升高是不可避免的，而欧盟的《AI 法案》可以说是这一趋势的先行者。<br/>该法案于 2024 年 8 月 1 日正式生效并分阶段实施，着重对高风险的 AI 系统施加了严格的合规要求。而且这不仅仅是一项区域性法规，更可能产生 " 布鲁塞尔效应 " 从而影响全球的 AI 监管格局。<br/>监管的落地也将会直接转化为企业的合规成本。据公开信息推算，仅欧盟 AI 法案便可能导致欧洲企业的 AI 采纳成本增加约 310 亿欧元，并使 AI 投资减少近 20%。而美国联邦贸易委员会也已对 OpenAI 展开调查，谷歌等公司也不得不调整其营销话术，避免被处以巨额罚款。<br/>可以说 " 监管的铁幕 " 正在迫使整个行业从过去 " 快速行动，打破陈规 " 的互联网思维转向一种更为审慎、合规驱动的开发模式。可以说这种转变无疑会减缓创新速度并增加运营成本，对于那些资源有限的中小企业和初创公司构成尤为严峻的挑战。<br/>对 " 信任 " 的侵蚀或许是 AI 滥用最难修复的一种<br/>这源于在激烈的竞争压力下，企业急于抢占市场将产品快速推向用户，所以将风险控制和安全测试置于次要位置。但是这种 " 快速行动并打破规则 " 的心态在 AI 时代尤为危险，因为 AI 技术的潜在破坏力远超以往的软件应用。<br/>并且市场对于 AI 技术的可靠性极度敏感，甚至一次小小的失误都可能引发巨大的信任危机和财务损失。谷歌的 Bard 模型之前便在一次演示中出现事实性错误，竟然导致其母公司 Alphabet 的股价在单日内暴跌 7%，市值蒸发超过 1000 亿美元。<br/>并且随着 AI 投资的巨额支出持续攀升，投资者开始担忧其回报前景，这种悲观情绪导致 Meta、Microsoft、Alphabet 和 Nvidia 等 AI 领域的领军企业股价普遍承压下跌，市场也开始讨论 "AI 泡沫 " 的风险，并开始质疑哪些不计成本的 " 军备竞赛 " 式投资。<br/>更何况大量公司缺乏对 AI 伦理的明确责任归属，高管层面也并未对其有所调整。所以 AI 系统的决策过程像一个 " 黑箱 "，在责任主体模糊的情况下滥用和误用的风险便难以控制。企业内部也未建立有效的问责机制。<br/>但是更深层次的原因在于当前主流生成式 AI 商业模式本身所内含的风险。这些模型依赖于海量数据的投喂，其训练过程难以完全避免偏见和有害信息的吸收。而其强大的生成能力却为恶意利用提供了温床。<br/>因此当商业模式的核心是追求更强大的模型、更广泛的应用时，如果缺乏与之匹配的强大 " 安全刹车 " 系统，滥用就成了可预见的副产品。这种商业逻辑与伦理要求之间的结构性失衡才是导致 " 反噬 " 的根本内因。<br/>所以当企业享受了技术红利带来的增长，如今便也不得不为其模式所伴生的风险 " 买单 "。哪怕科技公司以 " 让世界更美好 " 的叙事推广 AI，公众在实际体验中，也会频繁受到隐私泄露、算法偏见、就业替代、虚假信息等负面影响。<br/>这种落差也导致了广泛的 "AI 焦虑 " 和不信任感。公众普遍认为现有的监管法规不足以应对 AI 带来的社会风险期望政府采取更加果断的行动。这种强大的民意压力也是推动监管机构加速行动的根本动力。<br/>面对公众的呼声和潜在的社会风险，监管机构的介入是必然的。但由于技术发展的速度远超立法速度监管往往表现出一定的滞后性，欧盟 AI 法案便被部分人士认为可能增加企业负担、抑制创新。<br/>全球主要经济体在 AI 领域的竞争，也使得监管变得更加复杂。各国都希望在鼓励创新和防范风险之间找到平衡点但这种平衡点的位置各不相同，因此形成了复杂的国际监管格局给跨国企业的合规带来了巨大挑战。<br/>而且这种外部滥用对整个 AI 行业的声誉造成了 " 连坐 " 效应。即使一家公司本身恪守伦理，也无法完全独善其身，因为公众对 AI 的信任是整体性的。恶意滥用行为如同向池塘中投下的毒药，在污染了整个水域后迫使所有 " 池中生物 " 共同承担后果。<br/>这场危机成为 AI 自我革新的契机<br/>这场 " 反噬 " 带来的阵痛，是 AI 产业从野蛮生长走向规范发展的必经阶段。它正在淘汰那些只想赚快钱、缺乏责任感的 " 玩家 "，筛选出真正有实力、有远见的长期主义者。从长远来看，这也是为 AI 产业的健康、可持续发展所必须付出的代价。<br/>其中最大的机遇在于将 " 信任 " 从一种道德呼吁，转变为一种可量化、可变现的商业资产和竞争壁垒。数据显示近 85% 的客户也更愿意与重视 AI 伦理实践的公司合作，而那些优先考虑伦理和透明度的公司收入增长也更快。<br/>可以说在 AI 产品同质化日益严重的未来，谁能赢得用户的信任谁就能赢得市场。" 负责任的 AI" 将不再仅仅是公关部门的口号，而是必须贯穿于产品设计、开发、部署全流程的核心战略。<br/>谷歌和微软等公司已经开始调整其策略，谷歌选择利用 AI 技术提升广告安全审核的效率，打击欺诈内容；微软则发布了负责任 AI 透明度报告，并推出了 AzureAIContentSafety 等服务，帮助客户构建更安全的 AI 应用。这些举措既是应对风险的防御，也是在构建新的竞争优势。<br/>正是 " 反噬 " 催生了全新的 " 安全即服务 " 市场。随着 AI 滥用风险的加剧企业对 AI 安全审计、风险评估、内容过滤、合规咨询等服务的需求将急剧增长。这为专门从事 AI 安全和伦理治理的科技公司、咨询机构创造了巨大的市场空间。<br/>而科技巨头自身也可以将其内部成熟的安全工具和能力平台化、服务化，开拓新的收入来源。例如，谷歌和微软在内容审核、风险识别方面的技术积累，完全可以转化为对外输出的商业服务。<br/>虽然监管的收紧虽然带来了成本，但也为行业设定了 " 准入标准 "，能够率先满足高标准合规要求的企业将获得更强的市场公信力和竞争优势，从而在未来的市场整合中占据有利地位。这实际上是一种由监管驱动的市场出清和格局优化。weibo.com/ttarticle/p/show?id=2309405232951972986994<br/>weibo.com/ttarticle/p/show?id=2309405232952614453306<br/>weibo.com/ttarticle/p/show?id=2309405232952748933164<br/>weibo.com/ttarticle/p/show?id=2309405232952883150856<br/>weibo.com/ttarticle/p/show?id=2309405232953017368626<br/>weibo.com/ttarticle/p/show?id=2309405232953852035594<br/>weibo.com/ttarticle/p/show?id=2309405232953990447421<br/>weibo.com/ttarticle/p/show?id=2309405232954133053515<br/>weibo.com/ttarticle/p/show?id=2309405232954271203453<br/>从滥用事件的激增，到资本市场的审慎，再到全球监管的收紧，这股 " 反噬 " 之力正在重塑 AI 产业的发展轨迹。它迫使整个行业从过去对技术力量的无限崇拜，转向对技术责任和社会价值的深刻反思。<br/>麦肯锡预测，到 2030 年 AI 将为全球经济创造 13 万亿美元价值。但价值分配取决于我们如何驾驭这头猛兽。未来的竞争，将不仅仅是模型参数和算力大小的竞争，更是治理能力、责任担当和用户信任的竞争。</p>]]></description></item><item>    <title><![CDATA[超参数调优：Grid Search 和 ]]></title>    <link>https://segmentfault.com/a/1190000047400836</link>    <guid>https://segmentfault.com/a/1190000047400836</guid>    <pubDate>2025-11-14 23:07:16</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>模型训练完能够到达85%的准确率，很多人觉得就差不多了。但是通过超参数优化能让模型释放真正的潜力。最后那3-5个点的提升，往往决定了你的模型是"还行"还是"能打"。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047400838" alt="" title=""/><br/>这篇文章会把Grid Search和Random Search这两种最常用的超参数优化方法进行详细的解释。从理论到数学推导，从优缺点到实际场景，再用真实数据集跑一遍看效果。</p><h2>参数和超参数：两个容易混淆的概念</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400839" alt="" title="" loading="lazy"/></p><p>机器学习里，参数和超参数是完全不同的东西。</p><p><strong>参数</strong>是模型自己从数据里学出来的。线性回归的权重系数w和偏置b，神经网络各层之间的连接权重，逻辑回归的决策边界系数，都属于参数。训练过程中这些值会不断调整，你不用手动去设。</p><p><strong>超参数</strong>则不同，需要在训练开始前就定好。它们控制着模型怎么学习，学习能力有多强，正则化力度多大。</p><p>随机森林的n_estimators（树的数量）、max_depth（树能长多深）、min_samples_split（分裂需要的最少样本）都是超参数。神经网络的learning_rate（学习率）、batch_size（批次大小）、隐藏层数量也是。SVM里的C（正则化参数）、kernel（核函数）、gamma（核系数）也都是一些常见的超参数。</p><p>超参数优化的核心目标是在过拟合和欠拟合之间找平衡。只有找到最佳配置模型的泛化能力才能最大化，遇到新数据才能给出靠谱的预测。</p><p>已经有很多研究表明，超参数的选择对模型性能的影响不亚于参数优化本身。所以说系统性地调优超参数是构建可靠机器学习模型的必经之路。</p><h2>Grid Search：最暴力也最稳妥的方法</h2><p>Grid Search是超参数优化里最直接的思路：把所有组合都试一遍。</p><p>算法会扫描所有超参数值的笛卡尔积。你给每个超参数设定几个候选值，然后把这些值的所有可能组合都跑一遍，最后挑出表现最好的那组。</p><p>具体步骤很简单：</p><ul><li>先定义参数空间，给每个超参数列出候选值</li><li>计算笛卡尔积，生成所有可能的组合</li><li>用交叉验证评估每个组合的性能</li><li>选出验证分数最高的那组参数</li></ul><p>Grid Search最大的优点是能保证在离散参数空间里找到全局最优解，但代价也很明显：计算量爆炸。</p><p>总评估次数的增长是指数级的，如果有d个参数，每个参数n个候选值，就要评估 n^d 次。参数空间一大这个方法基本就跑不动了。</p><p>但是他的优势在于结果可复现，相同的参数空间和随机种子能得到一样的结果。搜索也很全面定义的空间里绝对能找到最优解。而且每个组合可以独立评估，适合并行计算。</p><p>劣势就是维度灾难，高维空间里计算成本根本承受不了。连续参数只能离散化处理，存在次优化问题。对那些不重要的参数也要遍历，白白浪费资源。</p><pre><code> print("--- EXPERIMENT 1: GridSearchCV (Small Space) Starting ---")
param_grid_small = {
    'C': [0.1, 1, 10, 100],
    'gamma': [1, 0.1, 0.01, 0.001],
    'kernel': ['rbf', 'poly']
}

svc = SVC(random_state=42)
grid_search = GridSearchCV(
    estimator=svc,
    param_grid=param_grid_small,
    cv=5,
    scoring='accuracy',
    n_jobs=-1,
    verbose=0
)

start_time_grid = time.time()
grid_search.fit(X_train_scaled, y_train)
end_time_grid = time.time()

total_time_grid = end_time_grid - start_time_grid
grid_best_score = grid_search.best_score_

 print(f"GridSearch (Small) Finished. Time: {total_time_grid:.2f}s, Score: {grid_best_score:.4f}")</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400840" alt="" title="" loading="lazy"/></p><p>低维参数空间、计算资源充足的情况下Grid Search是个不错的选择，但高维问题就得考虑别的办法了。</p><h2>Random Search：用概率换效率</h2><p>Bergstra和Bengio在2012年提出Random Search，用概率方法解决Grid Search的计算瓶颈。</p><p>Random Search不再系统遍历而是从参数空间随机采样。给每个超参数定义概率分布，然后随机抽取若干组合进行评估。</p><p>操作流程：</p><ul><li>为每个超参数指定概率分布</li><li>根据n_iter参数决定采样次数，随机生成参数组合</li><li>用交叉验证评估每组参数的性能</li><li>选出验证分数最高的配置</li></ul><p>大多数机器学习模型里，真正影响性能的往往只有少数几个关键参数，其他参数的影响很边缘。Random Search正是利用了这个特点。</p><p>数学上可以这样理解：假设参数空间是d维的，最优区域在某个d维子空间里。那么Random Search找到最优区域的概率是：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047400841" alt="" title="" loading="lazy"/></p><p>epsilon是最优区域的体积占比，n是采样次数。</p><p>好处是相同计算预算下能探索更广的参数空间。连续和离散参数都能处理，在高维问题上也适用。</p><p>缺点就是结果带有随机性，不能保证找到全局最优。而且分布的选择会影响结果，在有限次迭代内不保证收敛。</p><p><strong>代码实现</strong></p><pre><code> print("--- EXPERIMENT 2: RandomizedSearchCV (Small Space) Starting ---")
param_dist_small = {
    'C': loguniform(0.1, 100),
    'gamma': loguniform(0.001, 1),
    'kernel': ['rbf', 'poly']
}
N_ITERATIONS = 20

svc = SVC(random_state=42)
random_search = RandomizedSearchCV(
    estimator=svc,
    param_distributions=param_dist_small,
    n_iter=N_ITERATIONS,
    cv=5,
    scoring='accuracy',
    n_jobs=-1,
    random_state=42,
    verbose=0
)

start_time_random = time.time()
random_search.fit(X_train_scaled, y_train)
end_time_random = time.time()

total_time_random = end_time_random - start_time_random
random_best_score = random_search.best_score_

 print(f"RandomSearch (Small) Finished. Time: {total_time_random:.2f}s, Score: {random_best_score:.4f}")</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400842" alt="" title="" loading="lazy"/></p><h2>大参数空间实验</h2><p>小规模实验看不出太大差别，所以我们换个更大更复杂的参数空间试试。这次加入poly核的额外参数degree和coef0。</p><p>这个实验会让Grid Search的维度诅咒问题暴露无遗。同时看看Random Search能不能在固定预算下高效找到好结果。</p><pre><code> print("--- EXPERIMENT 3: GridSearchCV (LARGE &amp; Inefficient Space) Starting ---")
param_grid_large = {
    'C': [0.1, 1, 10, 100],
    'gamma': [1, 0.1, 0.01, 0.001],
    'kernel': ['rbf', 'poly'],
    'degree': [2, 3, 4],
    'coef0': [0.0, 0.5, 1.0]
}

TOTAL_GRID_COMBINATIONS = 4 * 4 * 2 * 3 * 3
print(f"GridSearch (Large) Total Combinations: {TOTAL_GRID_COMBINATIONS}")
print(f"GridSearch (Large) Total Model Fits: {TOTAL_GRID_COMBINATIONS * 5}")

svc = SVC(random_state=42)
grid_search_large = GridSearchCV(
    estimator=svc,
    param_grid=param_grid_large,
    cv=5,
    scoring='accuracy',
    n_jobs=-1,
    verbose=1
)

start_time_grid_large = time.time()
grid_search_large.fit(X_train_scaled, y_train)
end_time_grid_large = time.time()

total_time_grid_large = end_time_grid_large - start_time_grid_large
grid_large_best_score = grid_search_large.best_score_
grid_large_best_params = grid_search_large.best_params_

print(f"\nGridSearch (Large) Finished.")
print(f"Total Time: {total_time_grid_large:.2f} seconds")
 print(f"Best CV Score: {grid_large_best_score:.4f}")</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400843" alt="" title="" loading="lazy"/></p><pre><code> print("--- EXPERIMENT 4: RandomizedSearchCV (LARGE Space) Starting ---")
param_dist_large = {
    'C': loguniform(0.1, 100),
    'gamma': loguniform(0.001, 1),
    'kernel': ['rbf', 'poly'],
    'degree': randint(2, 5),
    'coef0': uniform(0.0, 1.0)
}
N_ITERATIONS_LARGE = 30

print(f"RandomSearch (Large) Budget: {N_ITERATIONS_LARGE}")
print(f"RandomSearch (Large) Total Model Fits: {N_ITERATIONS_LARGE * 5}")

svc = SVC(random_state=42)
random_search_large = RandomizedSearchCV(
    estimator=svc,
    param_distributions=param_dist_large,
    n_iter=N_ITERATIONS_LARGE,
    cv=5,
    scoring='accuracy',
    n_jobs=-1,
    random_state=42,
    verbose=1
)

start_time_random_large = time.time()
random_search_large.fit(X_train_scaled, y_train)
end_time_random_large = time.time()

total_time_random_large = end_time_random_large - start_time_random_large
random_large_best_score = random_search_large.best_score_
random_large_best_params = random_search_large.best_params_

print(f"\nRandomSearch (Large) Finished.")
print(f"Total Time: {total_time_random_large:.2f} seconds")
 print(f"Best CV Score: {random_large_best_score:.4f}")</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400844" alt="" title="" loading="lazy"/></p><h2>结果对比</h2><p>现在把小参数空间和大参数空间的实验结果放一起看：最佳CV分数（模型性能）和总耗时（计算效率）。</p><p>这个对比能清楚展示出，随着问题复杂度上升，两种优化策略各自的优势和性能成本权衡。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047400845" alt="" title="" loading="lazy"/><img referrerpolicy="no-referrer" src="/img/remote/1460000047400846" alt="" title="" loading="lazy"/><img referrerpolicy="no-referrer" src="/img/remote/1460000047400847" alt="" title="" loading="lazy"/></p><h2>混合策略：取两者之长</h2><p>前面的实验已经看到了Grid Search计算成本太高而Random Search扫描范围广但找精确最优点有点靠运气。</p><p>那能不能把两种方法的优势结合起来？</p><p>业界常用的Coarse-to-Fine策略就是这么干的：</p><p>第一阶段用Random Search快速扫描整个大参数空间，找到最有潜力的区域。</p><p>第二阶段在这个小区域周围跑密集的Grid Search，精确定位最优点。</p><p>这样既避免了全局Grid Search的天文计算量，又能得到高精度的调优结果。不用等几个星期就能拿到好结果。</p><p>现在拿实验4（大规模Random Search）找到的最佳参数作为起点，跑一遍混合策略看效果。</p><pre><code> print("--- EXPERIMENT 5: Hybrid 'Coarse-to-Fine' Strategy Starting ---")

# 1. Get the best parameters from our 'Coarse' RandomSearch (Exp 4)
coarse_params = random_large_best_params
print(f"Coarse (RandomSearch) Best Params: {coarse_params}")

best_C = coarse_params['C']
best_gamma = coarse_params['gamma']
best_kernel = coarse_params['kernel']

# 2. Define a new, very TIGHT grid around these best parameters
# We will create 3 values around the best value (e.g., 0.8*best, best, 1.2*best)
# We use np.linspace to create a small range.
refined_param_grid = {
    'C': np.linspace(best_C * 0.8, best_C * 1.2, 3),
    'gamma': np.linspace(best_gamma * 0.8, best_gamma * 1.2, 3),
    'kernel': [best_kernel] # We already found the best kernel, no need to search again
}

# Add kernel-specific params ONLY if they were found
if best_kernel == 'poly':
    best_degree = coarse_params['degree']
    best_coef0 = coarse_params['coef0']
    refined_param_grid['degree'] = [best_degree - 1, best_degree, best_degree + 1]
    refined_param_grid['coef0'] = np.linspace(best_coef0 * 0.8, best_coef0 * 1.2, 3)

# Calculate combinations: 3 * 3 * 1 = 9 (or 3*3*1*3*3 = 81 if poly)
# This is still incredibly small compared to the 288 of the full GridSearch!

# 3. Run the final 'Fine-Tuning' GridSearch
svc = SVC(random_state=42)
final_search = GridSearchCV(
    estimator=svc,
    param_grid=refined_param_grid,
    cv=5,
    scoring='accuracy',
    n_jobs=-1,
    verbose=1
)

start_time_final = time.time()
final_search.fit(X_train_scaled, y_train)
end_time_final = time.time()

total_time_final = end_time_final - start_time_final
final_best_score = final_search.best_score_

print(f"\nHybrid 'Fine-Tuning' Search Finished.")
print(f"Total Time: {total_time_final:.2f} seconds")
print(f"Best CV Score (Hybrid): {final_best_score:.4f}")
print(f"Best Params (Hybrid): {final_search.best_params_}")

# Create a new row for our final table
hybrid_experiment = {
    'Method': 'Hybrid (Random+Grid)',
    'Combinations/Budget': f"{N_ITERATIONS_LARGE} (Random) + {len(final_search.cv_results_['params'])} (Grid)",
    'Total Model Fits (CV=5)': (N_ITERATIONS_LARGE * 5) + (len(final_search.cv_results_['params']) * 5),
    'Best Score': final_best_score,
    'Total Time (s)': total_time_random_large + total_time_final # Total time is BOTH steps
}

# Add this to the existing DataFrame
final_df.loc['Experiment 5 (Hybrid)'] = hybrid_experiment
final_df = final_df.round(4)

print("--- 🚀 FINAL COMPARISON (Hybrid Included) ---")
 display(final_df)</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400848" alt="" title="" loading="lazy"/></p><h2>总结</h2><p>相同计算预算下，Random Search的泛化性能通常比Grid Search更好。特别是高维参数空间、计算资源有限的场景，Random Search是更明智的选择（我们这里只对比这两个常见的方法，不考虑贝叶斯搜索等高级的方法）。</p><p><a href="https://link.segmentfault.com/?enc=C17A2YRSxTmxvp76zFyd9w%3D%3D.Yh7TLeNsvCTOSCp%2BmJ37xfGbYYYpAYAmCJBhT96HuhGwhm91%2ByWxcIqlkxpNYe35w%2F6kNX3ztoopovBLvIDbgg%3D%3D" rel="nofollow" target="_blank">https://avoid.overfit.cn/post/f2ca01f665714ba983f868ca2882fc32</a></p><p>作者：Elif Nur Yılmaz</p>]]></description></item><item>    <title><![CDATA[高性价比外贸CRM排行榜2025 遭老罪]]></title>    <link>https://segmentfault.com/a/1190000047400867</link>    <guid>https://segmentfault.com/a/1190000047400867</guid>    <pubDate>2025-11-14 23:06:21</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>客户关系管理（CRM）软件已经成为企业提升效率、优化客户管理、促进销售增长的重要工具。随着外贸业务的复杂性增加，企业需要一款功能强大、易于使用且价格合理的CRM软件来帮助管理客户信息、跟踪销售进程以及分析市场数据。然而，市场上CRM软件种类繁多，如何选择一款高性价比的外贸CRM软件成为了许多企业的难题。<br/><img width="723" height="487" referrerpolicy="no-referrer" src="/img/bVdm3h9" alt="" title=""/></p><h2>一、外贸企业为什么需要CRM软件？</h2><p>在外贸行业中，企业面临着以下几个主要挑战：</p><h2>1. 客户信息分散</h2><p>外贸企业通常需要管理来自多个国家和地区的客户信息，包括联系方式、交易记录、沟通历史等。如果没有一套系统化的工具，这些信息很容易分散在不同的表格、邮件或聊天记录中，导致管理效率低下。</p><h2>2. 销售流程复杂</h2><p>外贸销售流程通常涉及多个环节，如客户开发、报价、订单确认、物流跟踪和售后服务等。没有一款CRM软件，很难对整个流程进行有效的跟踪和管理。</p><h2>3. 跨团队协作困难</h2><p>外贸业务通常需要销售、市场、客服和物流团队的紧密配合。CRM软件可以帮助团队共享信息，提升协作效率。</p><h2>4. 数据分析需求</h2><p>外贸企业需要通过数据分析了解客户行为、市场趋势以及销售业绩，从而制定更精准的营销策略。</p><p>因此，选择一款适合外贸企业的CRM软件，不仅可以帮助企业提升效率，还能优化客户体验，最终促进业务增长。</p><h2>二、高性价比的外贸CRM软件推荐</h2><p>在众多CRM软件中，Zoho CRM以其强大的功能、灵活的定制性和合理的价格，成为外贸企业的理想选择。以下是Zoho CRM的详细介绍。</p><h2>1. Zoho CRM的核心功能</h2><p>客户管理：Zoho CRM可以帮助企业集中管理客户信息，包括联系方式、沟通记录、交易历史等。通过客户分组和标签功能，企业可以轻松分类和筛选客户。<br/>销售自动化：Zoho CRM支持自动化销售流程，例如自动分配线索、设置提醒、跟踪销售进度等，帮助销售团队节省时间并提高效率。<br/>多渠道沟通：Zoho CRM支持通过电子邮件、电话、社交媒体和实时聊天与客户沟通，并将所有沟通记录集中存储，方便随时查看。<br/>数据分析与报表：Zoho CRM内置强大的数据分析工具，可以生成销售报告、客户行为分析、市场趋势预测等，帮助企业做出数据驱动的决策。<br/>移动端支持：Zoho CRM提供功能齐全的移动应用，方便销售人员随时随地访问客户信息和更新销售进度。<br/>多语言与多币种支持：对于外贸企业来说，多语言和多币种支持是必不可少的功能。Zoho CRM支持多种语言和货币，方便企业与全球客户打交道。</p><h2>2. Zoho CRM的优势</h2><p>价格合理：Zoho CRM提供多个版本，基础版价格非常亲民，适合中小型外贸企业。此外，Zoho还提供免费试用，企业可以在购买前充分体验其功能。<br/>灵活的定制性：Zoho CRM允许用户根据自身需求定制界面、字段和工作流程，确保软件完全符合企业的业务需求。<br/>与其他工具的集成：Zoho CRM可以与Zoho生态系统中的其他工具（如Zoho Books、Zoho Campaigns）无缝集成，同时也支持与第三方工具（如Google Workspace、Mailchimp）的对接。<br/>全球化支持：Zoho CRM在全球范围内拥有广泛的用户群体，其服务器分布在多个国家，确保数据安全和访问速度。<br/>易于上手：Zoho CRM的界面简洁直观，即使是没有技术背景的用户也能快速上手。此外，Zoho还提供丰富的在线教程和技术支持。</p><h2>3. Zoho CRM的适用场景</h2><p>中小型外贸企业：对于预算有限的中小型外贸企业，Zoho CRM的基础版已经能够满足大部分需求，而其高级版则提供了更多高级功能。<br/>多语言客户管理：如果企业需要与来自不同国家的客户沟通，Zoho CRM的多语言支持将是一个重要优势。<br/>需要销售自动化的企业：如果企业希望通过自动化工具提升销售效率，Zoho CRM的销售自动化功能可以帮助实现这一目标。</p><h2>三、与其他CRM软件的对比</h2><p>为了更好地了解Zoho CRM的优势，我们将其与其他几款主流CRM软件进行对比。</p><h2>1. Zoho CRM vs Salesforce</h2><p>价格：Salesforce功能强大，但价格较高，适合大型企业。而Zoho CRM价格更亲民，更适合中小型外贸企业。<br/>易用性：Salesforce的功能复杂，学习曲线较陡。而Zoho CRM界面简洁，易于上手。<br/>定制性：两者都支持高度定制，但Zoho CRM的定制过程更简单。</p><h2>2. Zoho CRM vs HubSpot CRM</h2><p>功能深度：HubSpot CRM的免费版功能有限，而Zoho CRM即使是基础版也提供了丰富的功能。<br/>价格：HubSpot CRM的高级功能需要额外付费，总体成本较高，而Zoho CRM的性价比更高。<br/>适用场景：HubSpot CRM更适合以内容营销为主的企业，而Zoho CRM更适合需要全面客户管理的外贸企业。</p><h2>3. Zoho CRM vs Pipedrive</h2><p>销售自动化：Pipedrive专注于销售流程管理，但在客户管理和数据分析方面不如Zoho CRM全面。<br/>价格：两者价格相近，但Zoho CRM提供更多功能，性价比更高。<br/>四、如何选择适合自己的CRM软件？<br/>在选择CRM软件时，企业需要综合考虑以下几个因素：</p><p>预算：如果预算有限，可以优先考虑Zoho CRM等高性价比的软件。<br/>功能需求：根据企业的具体需求选择功能匹配的软件。例如，如果需要强大的销售自动化功能，Zoho CRM是一个不错的选择。<br/>易用性：确保软件易于上手，避免因学习成本过高而影响使用效果。<br/>扩展性：选择支持定制和集成的CRM软件，以便未来业务扩展时能够轻松升级。<br/>如果您正在寻找一款适合外贸业务的CRM软件，不妨试试Zoho CRM。通过其免费试用版，您可以亲自体验其功能，找到最适合自己企业的解决方案。</p>]]></description></item><item>    <title><![CDATA[征程 6X 常见 kernel pani]]></title>    <link>https://segmentfault.com/a/1190000047400887</link>    <guid>https://segmentfault.com/a/1190000047400887</guid>    <pubDate>2025-11-14 23:05:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>1. 概述</h2><p>kernel panic 包含了多种内核异常类型，包括但不限于：空指针/异常指针、HungTask、RCU Stall、softlockup、hardlockup、OOM、BUG\_ON。</p><p>下图是各种类型 panic 的路径：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400889" alt="" title=""/></p><h2>2. 通用方法</h2><ol><li>kpanic 类异常均为 kernel 软件可感知到的异常， kernel 完成 panic 流程后会由 bl31 完成一次 WarmReset，所以所有 panic 现场我们都是能够拿到 pstore log 的。</li><li>由于是软件异常，所以 pstore 中都能看到异常调用栈、寄存器等信息，通过这些信息就可以初步分析 70% 的问题。</li><li>BUG\_ON 类是软件主动触发的 panic，所以直接检查代码逻辑即可。</li><li>对于一些依赖于时序最终产生的 panic 问题，还需要进一步加 log 或 ftrace 进行复现，以跟踪时序（竞争类）引发的异常。</li><li>对于复杂的 panic 问题，还需要开启 ramdump 功能，抓取 dump 进行分析。</li></ol><h2>3. 典型问题</h2><h4>3.1. 异常指针访问</h4><p>此类问题代表内核中访问了一个空指针、未映射、没有权限的地址空间，导致触发 mem abort。</p><ul><li>例：</li></ul><pre><code class="markdown">&lt;4&gt;[ 1486.084782] CPU: 0 PID: 0 Comm: swapper/0 Tainted: P O 6.1.134-rt51-04836-g0b3e5cbe5431 #13
&lt;4&gt;[ 1486.090809] Hardware name: Horizon AI Technologies, Inc. HOBOT Sigi-P Matrix (DT)
&lt;4&gt;[ 1486.091730] pstate: 00400009 (nzcv daif +PAN -UAO -TCO BTYPE=--)
&lt;4&gt;[ 1486.092492] pc : __memcpy+0x48/0x180
&lt;4&gt;[ 1486.092953] lr : kfifo_copy_in+0x68/0x94
&lt;4&gt;[ 1486.093456] sp : ffff8000124cbd40
&lt;4&gt;[ 1486.093876] pmr_save: 000000e0
&lt;4&gt;[ 1486.094265] x29: ffff8000124cbd40 x28: ffff0001950ae200
&lt;4&gt;[ 1486.094942] x27: ffff0001765b8800 x26: 0000000000000000
&lt;4&gt;[ 1486.095619] x25: 0000000000000340 x24: 0000000000000018
&lt;4&gt;[ 1486.096295] x23: 00000000f97f0681 x22: ffff8000124cbe18
&lt;4&gt;[ 1486.096970] x21: ffff0001950ae280 x20: 00000000ffff0001
&lt;4&gt;[ 1486.097646] x19: 00000000f97f0681 x18: 0000000000000000
&lt;4&gt;[ 1486.098321] x17: 0000000000000000 x16: 0000000000000000
&lt;4&gt;[ 1486.098997] x15: 000000000000000a x14: 0000000035693bc0
&lt;4&gt;[ 1486.099672] x13: ffff800011feecd1 x12: ffffffffffffffff
&lt;4&gt;[ 1486.100348] x11: ffffffffffffffff x10: 0000000000000020
&lt;4&gt;[ 1486.101024] x9 : ffff800011feecbc x8 : 0000000005f5e100
&lt;4&gt;[ 1486.101699] x7 : ffff00027ee2f8b8 x6 : 00000001239ae000
&lt;4&gt;[ 1486.102376] x5 : ffff0001950ae280 x4 : 0000000000000008
&lt;4&gt;[ 1486.103052] x3 : 0000000100000025 x2 : 00000000f97f0679
&lt;4&gt;[ 1486.103728] x1 : ffff8000124cbe20 x0 : 00000001239ae000
&lt;4&gt;[ 1486.104405] Call trace:
&lt;4&gt;[ 1486.104717] __memcpy+0x48/0x180
&lt;4&gt;[ 1486.105133] __kfifo_in+0x3c/0x5c
&lt;4&gt;[ 1486.105558] bpu_core_tasklet+0x1b0/0x300 [bpu_cores]
&lt;4&gt;[ 1486.106214] tasklet_action_common.isra.0+0x90/0xd4
&lt;4&gt;[ 1486.106837] tasklet_action+0x28/0x34
&lt;4&gt;[ 1486.107306] _stext+0x1e0/0x220
&lt;4&gt;[ 1486.107709] __irq_exit_rcu+0x80/0xd0
&lt;6&gt;[ 1486.107789] [S1][V0]subdev_balance_lost_next_frame lost_this = 0x1, lost_next = 0x1,
&lt;6&gt;[ 1486.107803] [S2][V0]subdev_balance_lost_next_frame lost_this = 0x1, lost_next = 0x1,
&lt;6&gt;[ 1486.107813] [S3][V0]subdev_balance_lost_next_frame lost_this = 0x1, lost_next = 0x1,
&lt;6&gt;[ 1486.107827] [S0][V0]subdev_balance_lost_next_frame lost_this = 0x0, lost_next = 0x1,
&lt;6&gt;[ 1486.107921] [S4][V0]cim_balance_lost_next_frame lost_this = 0x0, lost_next = 0x1,
&lt;4&gt;[ 1486.108179] irq_exit+0x10/0x20
&lt;4&gt;[ 1486.113403] __handle_domain_irq+0x70/0xa0
&lt;4&gt;[ 1486.113928] gic_handle_irq+0x2d0/0x30c
&lt;4&gt;[ 1486.114419] el1_irq+0xcc/0x180
&lt;4&gt;[ 1486.114822] arch_cpu_idle+0x30/0x38
&lt;4&gt;[ 1486.115278] default_idle_call+0x30/0x3c
&lt;4&gt;[ 1486.115779] do_idle+0x130/0x258
&lt;4&gt;[ 1486.116194] cpu_startup_entry+0x24/0x54
&lt;4&gt;[ 1486.116695] rest_init+0xd4/0xe4
&lt;4&gt;[ 1486.117108] arch_call_rest_init+0x10/0x1c
&lt;4&gt;[ 1486.117631] start_kernel+0x6f0/0x734</code></pre><ol><li>这类问题，首先我们可以看到 mem abort 的 CPU 调用栈，所以马上就能够定位是哪个函数访问的异常地址，如果这个函数比较简单，也就能够很快定位到是哪个变量的空指针访问。</li><li>如果函数比较复杂，我们可以使用 gdb，addr2line 等工具配合符号表进行汇编分析定位代码位置，通过偏移确认变量。</li><li>确认异常指针的变量和来源后，有可能是下面的原因导致的错误：</li></ol><blockquote><ol><li>检查调用栈代码，从业务/调用逻辑上看是否存在引入错误指针情况。</li><li>检查对应变量相关代码逻辑，考虑是否可能存在竞争风险。</li><li>如果异常地址没有发现竞争或引入错误的可能，考虑是否是被踩踏，参考 memory correcption 节。</li><li>检查设备是否存在随机 crash 的情况，设备是否有单体问题，如果多设备存在随机 crash，也有可能是 DDR 软/硬件配置问题。</li></ol></blockquote><h4>3.2. HungTask</h4><p>khungtaskd 是内核对 D 状态的进程进行扫描的内核线程，当内核某进程/线程长期处于 D 状态，hungtask 就会被触发，在征程 6 的系统中，hungtask 超时时间设置为 120s，且 CONFIG\_BOOTPARAM\_HUNG\_TASK\_PANIC\_VALUE=1，故当 hungtask 检测到有进程处于 D 状态超过 120s 后就会直接触发 panic。</p><ul><li>例：</li></ul><pre><code class="markdown">[ 605.147501] INFO: task ipi7_thread:3826 blocked for more than 120 seconds.
[ 605.147532] Tainted: P O 6.1.134-rt51-04836-g0b3e5cbe5431 #13[ 605.147538] "echo 0 &gt; /proc/sys/kernel/hung_task_timeout_secs" disables this message.
[ 605.147543] task:ipi7_thread state:D stack: 0 pid: 3826 ppid: 2 flags:0x00000028
[ 605.147559] Call trace:
[ 605.147562] __switch_to+0xf8/0x160
[ 605.147583] __schedule+0x268/0x800
[ 605.147594] schedule+0x84/0xf8
[ 605.147602] cimdma_swap_buffer+0x244/0x338 [hobot_cim_dma][ 605.147631] kthread+0x160/0x188
[ 605.147640] ret_from_fork+0x10/0x18
[ 605.147649] INFO: task ipi4_thread:3830 blocked for more than 120 seconds.
[ 605.147654] Tainted: P O 6.1.134-rt51-04836-g0b3e5cbe5431 #13[ 605.147658] "echo 0 &gt; /proc/sys/kernel/hung_task_timeout_secs" disables this message.
[ 605.147661] task:ipi4_thread state:D stack: 0 pid: 3830 ppid: 2 flags:0x00000028
[ 605.147669] Call trace:
[ 605.147671] __switch_to+0xf8/0x160
[ 605.147678] __schedule+0x268/0x800
[ 605.147685] schedule+0x84/0xf8
[ 605.147692] cimdma_swap_buffer+0x244/0x338 [hobot_cim_dma][ 605.147710] kthread+0x160/0x188
[ 605.147716] ret_from_fork+0x10/0x18
[ 605.147723] INFO: task ipi6_thread:3831 blocked for more than 120 seconds.
[ 605.147728] Tainted: P O 6.1.134-rt51-04836-g0b3e5cbe5431 #13[ 605.147732] "echo 0 &gt; /proc/sys/kernel/hung_task_timeout_secs" disables this message.
[ 605.147735] task:ipi6_thread state:D stack: 0 pid: 3831 ppid: 2 flags:0x00000028
[ 605.147743] Call trace:
[ 605.147745] __switch_to+0xf8/0x160
[ 605.147751] __schedule+0x268/0x800
[ 605.147758] schedule+0x84/0xf8
[ 605.147765] cimdma_swap_buffer+0x244/0x338 [hobot_cim_dma][ 605.147783] kthread+0x160/0x188
[ 605.147789] ret_from_fork+0x10/0x18
[ 605.147796] INFO: task ipi5_thread:3832 blocked for more than 120 seconds.
[ 605.147801] Tainted: P O 6.1.134-rt51-04836-g0b3e5cbe5431 #13[ 605.147805] "echo 0 &gt; /proc/sys/kernel/hung_task_timeout_secs" disables this message.
[ 605.147808] task:ipi5_thread state:D stack: 0 pid: 3832 ppid: 2 flags:0x00000028
[ 605.147816] Call trace:
[ 605.147818] __switch_to+0xf8/0x160
[ 605.147824] __schedule+0x268/0x800
[ 605.147831] schedule+0x84/0xf8
[ 605.147838] cimdma_swap_buffer+0x244/0x338 [hobot_cim_dma][ 605.147856] kthread+0x160/0x188
[ 605.147862] ret_from_fork+0x10/0x18</code></pre><ol><li>这类问题，khungtaskd 进程会在触发 crash 前，将长时间 D 状态的进程栈都输出出来，所以在 pstore 中能够快速定位到对应的调用信息。</li><li>对于驱动中长时间处于 D 状态，一般是由于在等待的资源无法获取，需要分析业务流程，对于时间不可预期的资源，可以使用*\_interruable 族、或*\_timout 族函数进行优化。</li><li>另一类由于死锁导致的 hungtask，需要代码分析死锁的根源，可以根据 log 中输出的所有 D 状态进程栈和 running 进程栈进行综合分析，对于大量 D 状态进程的复杂死锁问题，只能抓取 ramdump 去分析了。</li></ol><h4>3.3. RCU Stall</h4><p>RCU（Read-Copy-Update），顾名思义就是读-拷贝修改，它是基于其原理命名的。对于被 RCU 保护的共享数据结构，读者不需要获得任何锁就可以访问它，但写者在访问它时首先拷贝一个副本，然后对副本进行修改，最后使用一个回调（callback）机制在适当的时机把指向原来数据的指针替换为新的被修改的数据。</p><p>释放原来资源的工作由 RCU 软中断和 rcu 线程负责，RCU Stall 在 tick 中断中检查，当负责释放线程一直未执行起来（RCU Stall timeout 时间为 30s），就会出现 RCU Stall panic。</p><ul><li>例：</li></ul><pre><code class="markdown">&lt;3&gt;[122235.050769] rcu: INFO: rcu_preempt detected stalls on CPUs/tasks:
&lt;3&gt;[122235.050778] rcu: Tasks blocked on level-0 rcu_node (CPUs 0-5):
&lt;4&gt;[122235.050789] (detected by 4, t=7502 jiffies, g=34171837, q=56419)
&lt;3&gt;[122235.050796] rcu: All QSes seen, last rcu_preempt kthread activity 1 (4325451296-4325451295), jiffies_till_next_fqs=1, root -&gt;qsmask 0x0
&lt;0&gt;[122235.050805] Kernel panic - not syncing:
&lt;4&gt;[122235.050809] RCU Stall
&lt;4&gt;[122235.050813] CPU: 4 PID: 0 Comm: swapper/4 Tainted: P O 6.1.134-rt51-04836-g0b3e5cbe5431 #13
&lt;4&gt;[122235.050822] Hardware name: Horizon AI Technologies, Inc. HOBOT Sigi-P Matrix (DT)
&lt;4&gt;[122235.050828] Call trace:
&lt;4&gt;[122235.050830] dump_backtrace+0x0/0x1cc
&lt;4&gt;[122235.050846] show_stack+0x18/0x24
&lt;4&gt;[122235.050853] dump_stack+0xcc/0x12c
&lt;4&gt;[122235.050863] panic+0xcc/0x344
&lt;4&gt;[122235.050870] panic_on_rcu_stall+0x24/0x28
&lt;4&gt;[122235.050881] rcu_sched_clock_irq+0x830/0x900
&lt;4&gt;[122235.050889] update_process_times+0x60/0x88
&lt;4&gt;[122235.050898] tick_sched_handle.isra.0+0x50/0x68
&lt;4&gt;[122235.050907] tick_sched_timer+0x4c/0x90
&lt;4&gt;[122235.050914] __hrtimer_run_queues+0x108/0x19c
&lt;4&gt;[122235.050922] hrtimer_interrupt+0xb0/0x1b8
&lt;4&gt;[122235.050930] arch_timer_handler_phys+0x2c/0x44
&lt;4&gt;[122235.050940] handle_percpu_devid_irq+0x5c/0x104
&lt;4&gt;[122235.050951] generic_handle_irq+0x24/0x3c
&lt;4&gt;[122235.050958] __handle_domain_irq+0x9c/0xa0
&lt;4&gt;[122235.050965] gic_handle_irq+0x2d0/0x30c
&lt;4&gt;[122235.050975] el1_irq+0xcc/0x180
&lt;4&gt;[122235.050982] arch_cpu_idle+0x30/0x38
&lt;4&gt;[122235.050991] default_idle_call+0x30/0x3c
&lt;4&gt;[122235.050999] do_idle+0x144/0x270
&lt;4&gt;[122235.051008] cpu_startup_entry+0x24/0x54
&lt;4&gt;[122235.051015] secondary_start_kernel+0x1a4/0x1bc
&lt;6&gt;[122236.028018] [S0][V0]pym_subdev_stop
&lt;6&gt;[122236.028038] pym_check_stop_state cnt 10 pym-&gt;irq_status = 4
&lt;6&gt;[122236.046863] pym_check_exit_state cnt 9 pym-&gt;irq_status = 4
&lt;2&gt;[122236.061751] SMP: stopping secondary CPUs
&lt;0&gt;[122236.062276] Kernel Offset: disabled
&lt;0&gt;[122236.062730] CPU features: 0x0040426,2a00aa38
&lt;0&gt;[122236.063284] Memory Limit: none</code></pre><p>所以，当出现 RCU Stall 问题一般是出现了调度问题：</p><ol><li>长时间关闭硬/软中断、中断风暴，RCU 软中断无法执行。</li><li>长时间关闭强占。</li><li>高优先级 RT 进程占用 CPU 导致 rcu 线程无法执行。</li><li>由于 RT 版本中软中断由 cfs:19 优先级的 ksoftirqd 负责，rcu 软中断的工作可能被各种高优先级强占导致超时。</li><li>从 RCU Stall 的 log 中能看到发生 Rcu Stall 的核，检查对应 core 上进程，及调度情况定位问题，这种问题最好打开 ftrace，或者至少打开 CONFIG\_SCHED\_LOGGER 抓取到各核的调度信息才能更快的分析。</li></ol><p>解决 RCU Stall 问题的方案：</p><ol><li>检查是否存在高负载的 RT 进程一直被调用。如果存在，请评估是否降低为非 RT 进程，或者降低优先级。</li><li>调整 RCU Stall Timeout。修改/sys/module/rcupdate/parameters/rcu\_cpu\_stall\_timeout。</li><li>检查/proc/interrupts 中所有中断的次数，排除是否是中断风暴导致。</li></ol><p>如下面的 evt\_thread 进程每次调度都会占用 1s 时间：</p><pre><code class="markdown">[122233.054801] [6] : swapper/6(0) -&gt; evt_thread0(26886)
[122234.026784] [6] : evt_thread0(26886) -&gt; swapper/6(0)
[122234.028451] [6] : swapper/6(0) -&gt; grep(14873)
[122234.028515] [6] : grep(14873) -&gt; swapper/6(0)
[122234.051471] [6] : swapper/6(0) -&gt; grep(14873)
[122234.051541] [6] : grep(14873) -&gt; swapper/6(0)
[122234.054793] [6] : swapper/6(0) -&gt; evt_thread0(26886)
[122235.030776] [6] : evt_thread0(26886) -&gt; swapper/6(0)</code></pre>]]></description></item><item>    <title><![CDATA[真正免费CRM推荐：Zoho CRM 遭]]></title>    <link>https://segmentfault.com/a/1190000047400891</link>    <guid>https://segmentfault.com/a/1190000047400891</guid>    <pubDate>2025-11-14 23:04:30</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>对于初创公司以及预算有限的团队来说，Zoho CRM的免费版本是一款不可多得的高性价比客户管理软件。它不仅功能全面，而且真正免费，能够帮助企业高效管理客户信息、优化销售流程并提升客户满意度。</p><p>市场上大多数CRM软件功能强大，但价格昂贵，尤其是对于预算有限的中小企业来说，动辄数百美元的订阅费用可能会成为一大负担。幸运的是，Zoho CRM为企业提供了一种真正免费的解决方案。Zoho CRM不仅功能全面，而且其免费版本足以满足许多企业的基本需求，是一款性价比极高的客户管理软件。<br/><img width="723" height="487" referrerpolicy="no-referrer" src="/img/bVdm3iA" alt="" title=""/></p><h2>一、什么是Zoho CRM？</h2><p>Zoho CRM是由Zoho公司开发的一款客户关系管理软件，旨在帮助企业更高效地管理客户信息、优化销售流程并提升客户体验。作为一款全球知名的CRM软件，Zoho CRM在功能、灵活性和易用性方面表现出色，深受各行业企业的青睐。</p><p>与许多CRM软件不同的是，Zoho CRM提供了一个完全免费的版本，适合中小企业和初创公司使用。即使是免费版本，Zoho CRM也包含了许多强大的功能，能够满足企业的基本客户管理需求。</p><h2>二、Zoho CRM免费版的核心功能</h2><h2>Zoho CRM的免费版本功能丰富，涵盖了客户管理、销售自动化、数据分析等多个方面。以下是免费版的核心功能：</h2><h2>1. 客户信息管理</h2><p>Zoho CRM免费版允许企业集中管理客户信息，包括客户的联系方式、公司信息、沟通记录等。通过Zoho CRM，企业可以轻松分类和筛选客户，快速找到目标客户。</p><h2>2. 线索管理</h2><p>Zoho CRM支持线索管理功能，帮助企业跟踪潜在客户的来源、状态和转化情况。销售团队可以通过Zoho CRM了解每个线索的进展，并制定相应的跟进策略。</p><h2>3. 销售流程自动化</h2><p>免费版的Zoho CRM支持基本的销售自动化功能，例如自动分配线索、设置提醒、跟踪销售进度等。这些功能可以帮助企业节省时间，提高销售效率。</p><h2>4. 多渠道沟通</h2><p>Zoho CRM支持通过电子邮件、电话和社交媒体与客户沟通，并将所有沟通记录集中存储，方便随时查看。</p><h2>5. 任务和活动管理</h2><p>Zoho CRM允许用户创建任务、设置提醒并跟踪活动进度，确保销售团队不会错过任何重要的客户跟进。</p><h2>6. 数据分析与报表</h2><p>虽然免费版的分析功能有限，但Zoho CRM仍然提供了一些基础的报表功能，帮助企业了解销售业绩和客户行为。</p><h2>7. 移动端支持</h2><p>Zoho CRM提供功能齐全的移动应用，销售人员可以随时随地访问客户信息并更新销售进度。</p><h2>三、Zoho CRM免费版的优势</h2><p>相比其他CRM软件，Zoho CRM的免费版本具有以下几个显著优势：</p><h2>1. 真正免费</h2><p>许多CRM软件虽然声称免费，但实际上功能非常有限，甚至需要额外付费才能解锁基本功能。而Zoho CRM的免费版本不仅功能全面，而且没有隐藏费用，是真正意义上的免费。</p><h2>2. 功能强大</h2><p>尽管是免费版本，Zoho CRM仍然提供了许多强大的功能，例如客户管理、销售自动化和多渠道沟通等，足以满足中小企业的基本需求。</p><h2>3. 用户友好</h2><p>Zoho CRM的界面简洁直观，即使是没有技术背景的用户也能快速上手。此外，Zoho还提供丰富的在线教程和技术支持，帮助用户更好地使用软件。</p><h2>4. 灵活性高</h2><p>Zoho CRM支持用户根据自身需求定制界面、字段和工作流程，确保软件完全符合企业的业务需求。</p><h2>5. 全球化支持</h2><p>Zoho CRM支持多语言和多币种，适合需要与全球客户打交道的企业。</p><h2>6. 可扩展性</h2><p>如果企业未来需要更多高级功能，可以随时升级到Zoho CRM的付费版本，而无需更换软件。</p><h2>四、Zoho CRM免费版的适用场景</h2><h2>Zoho CRM的免费版本适合以下几种场景：</h2><h2>1. 中小型企业</h2><p>对于预算有限的中小型企业来说，Zoho CRM的免费版本已经能够满足大部分客户管理需求，无需额外付费。</p><h2>2. 初创公司</h2><p>初创公司通常需要一款简单易用的CRM软件来管理客户信息，而Zoho CRM的免费版本正是一个理想选择。</p><h2>3. 个人或小团队</h2><p>如果您是自由职业者或小团队，Zoho CRM的免费版本可以帮助您高效管理客户信息并提升工作效率。</p><h2>4. 试用CRM软件</h2><p>如果您对CRM软件不熟悉，可以先使用Zoho CRM的免费版本进行试用，了解其功能和优势，再决定是否需要升级到付费版本。</p><h2>五、如何开始使用Zoho CRM免费版？</h2><p>使用Zoho CRM免费版非常简单，只需按照以下步骤操作：</p><p>注册账户：访问Zoho CRM官网，点击“免费试用”按钮，填写基本信息即可完成注册。<br/>设置账户：登录后，根据企业需求设置账户信息，例如添加团队成员、创建自定义字段等。<br/>导入客户数据：将现有的客户数据导入Zoho CRM，开始集中管理客户信息。<br/>探索功能：通过Zoho CRM的在线教程和帮助文档，了解并使用其核心功能。<br/>如果您正在寻找一款免费的CRM软件，不妨试试Zoho CRM。通过其免费版本，您可以体验到强大的客户管理功能，并为企业的长期发展打下坚实的基础。</p>]]></description></item><item>    <title><![CDATA[什么是进销存系统？好处有哪些 遭老罪的程]]></title>    <link>https://segmentfault.com/a/1190000047400898</link>    <guid>https://segmentfault.com/a/1190000047400898</guid>    <pubDate>2025-11-14 23:03:39</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在当今竞争激烈的商业环境中，企业对高效管理的需求日益增长。进销存管理系统作为一种重要的管理工具，能够帮助企业更好地管理采购、销售和库存，提升运营效率和盈利能力。本文将详细介绍进销存管理系统的基本概念及其主要优点，并重点介绍Zoho Books如何助力企业实现高效的进销存管理。<br/><img width="723" height="480" referrerpolicy="no-referrer" src="/img/bVdm3iL" alt="" title=""/></p><h2>一、进销存管理系统是什么？</h2><p>进销存管理系统是一种集成化的软件解决方案，用于管理企业的采购、销售和库存活动。它通过自动化和优化这些关键业务流程，帮助企业提高效率、降低成本，并增强对业务的控制能力。进销存管理系统通常包括以下几个核心模块：</p><h2>1. 采购管理</h2><p>采购管理模块帮助企业高效地管理采购流程。它支持创建采购订单、跟踪采购进度、管理供应商信息等功能。通过与供应商的紧密合作，企业可以确保原材料和商品的及时供应，避免因缺货而影响销售。</p><h2>2. 销售管理</h2><p>销售管理模块用于处理企业的销售活动。它支持创建销售订单、管理客户信息、生成发票等功能。通过自动化销售流程，企业可以提高客户满意度，减少人工错误，提升销售效率。</p><h2>3. 库存管理</h2><p>库存管理模块是进销存管理系统的核心部分。它实时监控库存水平，支持多仓库管理、库存预警、库存盘点等功能。通过优化库存管理，企业可以减少库存成本，避免积压和缺货问题，确保库存水平始终处于最佳状态。</p><h2>二、进销存管理系统的优点</h2><h2>1. 提高运营效率</h2><p>进销存管理系统通过自动化处理日常业务流程，减少了人工操作的时间和错误。例如，自动化的采购订单生成和销售订单处理功能，可以显著提高工作效率，使员工能够专注于更有价值的工作。</p><h2>2. 优化库存管理</h2><p>实时监控库存水平和自动库存预警功能，帮助企业及时补货，避免缺货或积压。通过优化库存管理，企业可以减少库存成本，提高资金周转率。</p><h2>3. 增强决策支持</h2><p>进销存管理系统提供了丰富的数据分析和报告功能，帮助企业深入了解业务运营情况。通过生成销售趋势报表、库存周转率报表等，企业管理者可以做出更科学的决策，优化业务流程。</p><h2>4. 提升客户满意度</h2><p>通过自动化销售流程和实时库存管理，企业可以更快地响应客户需求，提高订单处理速度和准确性。这有助于提升客户满意度和忠诚度，增强企业的市场竞争力。</p><h2>5. 降低运营成本</h2><p>进销存管理系统通过优化采购和库存管理，减少了库存成本和采购成本。同时，自动化的业务流程减少了人工操作的需求，降低了人力成本。</p><h2>三、Zoho Books进销存管理系统的六大核心优势</h2><h2>1. 库存精准管控，避免资金积压</h2><p>实时库存追踪：通过序列号和批次管理，Zoho Books可精确追踪每个商品的流向，支持多仓库协同，实时同步库存数据。<br/>智能补货模型：系统根据历史销售数据和市场趋势，企业可以根据以往数据生成采购计划。Zoho Books的库存预警功能可设置补货阈值，当库存低于安全线时，自动发送提醒。</p><h2>2. 自动化流程，释放人力成本</h2><p>订单处理自动化：销售订单可一键转换为付款通知单，采购订单自动同步至供应商。Zoho Books的智能审批流功能可设置多级审核，确保交易合规性。<br/>财务数据自动对账：连接银行账户后，系统自动导入交易记录，匹配发票与付款，可以在几分钟内完成对账。</p><h2>3. 全球化适配，助力跨境业务</h2><p>多语言多币种支持：Zoho Books 提供22种语言界面和180种货币处理，支持以客户本地货币生成发票，自动换算汇率。例如，外贸企业可同时管理美元、欧元、日元等多币种交易，降低汇率波动风险。<br/>国际税务合规：内置15个国家的税务模板，自动计算增值税（VAT）、商品及服务税（GST），生成符合当地法规的财务报表。</p><h2>4. 数据驱动决策，提升运营效率</h2><p>可视化报表分析：Zoho Books 提供50+种定制化报表，包括损益表、现金流分析、库存周转率等。企业可通过数据标签化功能按部门、产品线分类，快速定位问题。<br/>AI 预测与优化：系统基于历史数据预测销售趋势，推荐最佳采购量和促销策略。</p><h2>5. 移动办公与协同协作</h2><p>全平台覆盖：Zoho Books的iOS和Android应用支持离线操作，用户可随时随地创建发票、审批订单、查看报表。通过 Apple Watch或智能手环，还能接收付款提醒和库存警报。<br/>多角色权限管理：可设置财务、采购、销售等不同角色的访问权限，供应商和客户可通过专属门户查看订单状态，减少沟通成本。</p><h2>6. 安全合规与成本优势</h2><p>数据安全保障：Zoho Books通过GDPR、PCI-DSS认证，采用银行级加密技术，确保数据传输和存储安全。系统还提供审计跟踪功能，记录所有操作日志。<br/>灵活定价策略：Zoho Books免费版支持1用户使用，付费版每月168元起，按年订阅可节省25%。</p><h2>四、Zoho Books 的差异化竞争力</h2><h2>1. 轻量级ERP功能</h2><p>Zoho Books不仅支持基础的进销存管理，还提供项目成本控制、工时跟踪、预算管理等 ERP 功能。例如，企业可按项目维度统计成本，生成利润分析报表，优化资源分配。</p><h2>2. 生态系统集成</h2><p>与 Zoho CRM、Zoho Inventory等20+款Zoho应用无缝集成，同时支持与Shopify、亚马逊、eBay等第三方平台对接。</p><h2>五、如何选择适合的进销存系统？</h2><h2>1. 明确业务需求</h2><p>跨境企业需重点关注多语言、多币种支持；电商企业需优先考虑平台集成能力。</p><h2>2. 评估功能深度</h2><p>中小型企业可选择 Zoho Books 等轻量级工具；大型企业可能需要 SAP 等复杂 ERP 系统。</p><h2>3. 试用与对比</h2><p>Zoho Books 提供14天免费试用，建议企业先测试，对比操作体验和功能适配性。</p><h2>总结</h2><p>进销存管理系统不仅是企业数字化转型的基石，更是提升效率、降低成本的核心工具。无论是库存的智能管控，还是数据的深度分析，Zoho Books均能以专业化的解决方案助力企业实现高效运营。</p>]]></description></item><item>    <title><![CDATA[不同传感器前中后融合方案简介 地平线智驾]]></title>    <link>https://segmentfault.com/a/1190000047400901</link>    <guid>https://segmentfault.com/a/1190000047400901</guid>    <pubDate>2025-11-14 23:02:46</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在自动驾驶场景下，摄像头 + 激光雷达的传感器融合方案是最常见的感知技术路线，目标是充分利用二者的互补性：</p><ul><li>摄像头优势：分辨率高、纹理丰富、颜色信息齐全，有利于识别语义信息（车道线、交通灯、行人类别等）。</li><li>激光雷达优势：天然地具有深度信息，直接测得高精度距离和稠密点云，有利于构建 3D 几何结构和检测障碍物。</li></ul><p>融合方式大致分为三类：前融合、中融合、后融合。</p><h2>1. 前融合</h2><p>前融合，是指把各个传感器的数据采集后，经过数据同步后，对这些原始数据进行融合，因此也称为数据级融合。将摄像头图像与激光雷达点云在几何空间对齐，例如把 3D LiDAR 点云投影到 2D 图像上， 然后检查点云是否属于 2D 边界框。前融合展示如下图：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400903" alt="" title=""/></p><p>前融合可以从整体上来处理信息，让数据更早做融合，整体处理信息，让数据更有关联性，把激光雷达点云和摄像头像素级数据进行融合，信息损失比较少；但前融合也会存在一些问题，例如：点云数据和像素数据坐标系不同，直接融合效果差；需要处理的数据量大，对算力要求较高；对融合策略要求也比较高，目前业内应用的比较少。</p><h2>2. 后融合</h2><p>后融合是指摄像头和激光雷达等各传感器独立完成感知任务（如检测、分割），最后在结果层面进行融合（如加权，IOU 匹配等），因此也称之为目标级融合。例如，可以将摄像头的 2D 边界框投影到 3D 边界框，然后将这些边界框与 LiDAR 检测过程中获得的边界框进行融合。</p><p>后融合的优点是传感器独立识别，解耦性好，易于扩展。缺点是会损失中间信息影响精度；rule-based 融合规则有局限性，难以充分利用跨模态互补信息。</p><p>后融合展示如下图：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400904" alt="" title="" loading="lazy"/></p><h2>3. 中融合</h2><p>中融合，是指先将各个传感器通过神经网络模型提取中间层特征（即有效特征），再融合有效主要特征，也称为特征级融合，典型的是对有效特征在 BEV 空间进行融合。相比于前融合与后融合，在 BEV 空间进行中融合有如下优点：</p><ol><li>跨摄像头融合和多模融合更容易实现，因为统一了数据空间，不需要处理规则关联不同传感器的感知结果，算法实现更加简单；</li><li>可以很容易地融合时序信息，形成 4D 空间，感知网络可以更好地实现一些感知任务，如测速等；</li><li>可“脑补”出被遮挡区域目标，在 BEV 空间，给予先验知识，对被遮挡的区域进行预测；</li><li>感知和预测在统一空间（BEV 空间）内完成，可以通过神经网络直接做端到端优化，并行出结果，既可以避免误差累积，也可以减少人工逻辑，让感知网络通过数据驱动的方式自学习，从而更好地实现功能迭代。</li></ol><p>目前使用最多的是中融合方案。</p><ol start="4"><li><h2>BEVFusion</h2></li></ol><p>BEVFusion 是典型的中融合方法，将来自相机和 LiDAR 的原始输入编码到同一个 BEV 空间。如下图所示，BEVFusion 主要由相机流、激光雷达流、动态融合模块和检测头组成，分别简单看下</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400905" alt="" title="" loading="lazy"/></p><p>相机流将多视角图像转到 BEV 空间，由图像编码器、视觉投影模块、BEV 编码器组成。</p><p>图像编码器旨在将输入图像编码为语义信息丰富的深度特征，它由用于基本特征提取的 2D backbone 和用于多尺度特征提取的 FPN 组成，并采用了一个简单的功能自适应模块 ADP 来完善上采样功能，如下图所示：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400906" alt="" title="" loading="lazy"/></p><p>视觉投影模块采用 LSS，将图像特征转换到自车坐标系的 3D 表示。该方法以图像视图为输入，通过离散分类的方式密集预测深度；随后结合相机外参与预测深度，生成伪体素表示。</p><p>BEV 编码模块采用空间到通道（S2C）操作将 4D 伪体素特征编码到 3D BEV 空间，从而保留语义信息并降低成本。然后使用四个 3 × 3 卷积层缩小通道维度，并提取高级语义信息。</p><p>动态融合模块的作用是将 concat 后的 相机、 LiDAR 的 BEV 特 进行有效融合，BEVFusion 应用一个简单的通道注意力模块来选择重要的融合特征，网络结构图如下所示：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400907" alt="" title="" loading="lazy"/></p><p>LiDAR 流将激光雷达点转换为 BEV 空间，BEVFusion 采用 3 种流行的方法，PointPillars、CenterPoint 和 TransFusion 作为激光雷达流，从而展示模型框架的优秀泛化能力。</p>]]></description></item><item>    <title><![CDATA[小众网盘推荐：Zoho WorkDriv]]></title>    <link>https://segmentfault.com/a/1190000047400916</link>    <guid>https://segmentfault.com/a/1190000047400916</guid>    <pubDate>2025-11-14 23:02:14</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>当下，我们的生活离不开云存储，无论是为了保存数字资产，还是为了实现团队协作，找到一款合适的网盘工具格外重要。面对限速等问题，小众企业网盘也许会让你的云存储体验焕然一新！除了百度网盘，还有哪些小众网盘值得推荐呢？<br/><img width="723" height="389" referrerpolicy="no-referrer" src="/img/bVdm3i3" alt="" title=""/></p><h2>一、百度网盘的产品背景</h2><h2>1. 背景故事：从“存储革命”到“流量收割机”</h2><p>百度网盘2009年上线，彼时国内云存储市场还算一片蓝海。从一开始提供免费额度，到后来推出VIP会员模式，百度网盘发展路径几乎是国内网盘市场的“教科书”。2023年数据显示，百度网盘拥有超过8亿注册用户，这个数字意味着全国每两个人，可能就有一个账号。</p><h2>2. 价格策略</h2><p>目前，百度网盘提供免费的基础空间，但这个容量在如今视频文件“堆积如山”的情况下，显然不够用。再往上走，就是会员了，分为超级会员（30元/月）和普通会员（15元/月），再加上单独加速包和专属云空间，想用得舒适，就得不停掏腰包。</p><h2>3. 产品功能：四大主打功能</h2><p>大容量：支持超大文件存储和在线预览。<br/>支持多端同步：桌面端和移动端无缝对接。<br/>资源分享：一些用户依赖百度网盘进行资源存储和分享。<br/>功能生态化：比如在线解压、AI自动识图等优质功能。<br/>百度网盘确实在功能多样性上占尽先机，但请注意，它并不“白白提供”，付费会员才是完整版。</p><h2>二、百度网盘降低用户体验的常见问题</h2><p>百度网盘虽然有其优点，但它的一些“小问题”实在令人头大。</p><h2>1. 限速问题：没有会员，就别想“高速上传和下载”</h2><p>这是百度网盘用户最常抱怨的问题。非会员下载的文件速度达不到200kb/s，甚至更慢。在岌岌可危的网速下，试下载一个4G的大文件，可能从下午拖到晚上。为了解锁正常速度，不掏会员费基本别想。</p><h2>2. 会员分阶：从普通会员到超级会员</h2><p>百度网盘不仅会员收费，而且还细分等级。从普通会员到超级会员再到限时活动包，收费模式过于复杂，不少用户被劝退。</p><h2>3. 资源分享隐患：数字版权保护问题</h2><p>百度网盘的“资源分享”功能备受欢迎，但这也让它陷入了灰色内容与违规资源的困境。经常会传出大规模资源泄露或账号连坐封禁的问题，可靠性与安全性频频遭到质疑。</p><p>百度网盘就是这么一个让人又爱又恨的存在：“爱”在功能齐全，“恨”在体验太贵且局限。话不多说，咱来看看那些不用割肾、而又功能强劲的小众网盘。</p><h2>三、有哪些小众网盘值得推荐？</h2><p>在百度网盘的光环下，小众网盘像星星点缀夜空，虽不耀眼，却各有亮点。这里强烈安利一个宝藏工具：Zoho网盘（Zoho WorkDrive）。没有套路，使用一次，体验可能会超出预期！</p><h2>适合团队协作的Zoho网盘</h2><p>Zoho网盘是Zoho旗下的一款云存储服务，最大的卖点是团队协作能力。很多人对Zoho的认知止于CRM，但其实它是一家深耕SaaS工具的全球化公司。网盘是Zoho面向企业用户推出的文档管理与协作云平台，同时也支持个人用户的高效存储。</p><h2>功能亮点：</h2><p>多层团队权限设置：支持多用户同时在线协作，权限包括管理、编辑、预览等。<br/>低成本大容量：入门版21/月起，提供1T云存储空间。<br/>每个版本最大存储限制<br/>入门版，团队的存储空间为 20 TB 起<br/>团队版，团队的存储空间为 60 TB 起<br/>商业版，团队的存储空间为 100 TB 起<br/>良好的使用体验：作为一家走向世界的企业，Zoho在世界各地拥有16座数据中心，数据稳定性非常高，符合GDPR、个保法等多项安全条例。不限速、无和谐资源、无插件和广告。</p><h2>四、FAQ</h2><p>Q1. 小众网盘安全吗？<br/>答：选择靠谱品牌是重中之重！一般网盘均具备高加密与隐私保护能力。</p><p>Q2. 小众网盘能替代百度网盘吗？<br/>答：可以，但要看你的使用场景。如果是团队文档管理、文件同步、团队协作，Zoho网盘完美适配；如果是存储超大型文件，MEGA或PCloud是更优解。</p><p>Q3. 小众网盘的收费如何？<br/>答：不同网盘定价不同，大部分网盘的价格区间非常透明且稳定。</p>]]></description></item><item>    <title><![CDATA[常用邮件营销工具排行榜2025 遭老罪的]]></title>    <link>https://segmentfault.com/a/1190000047400924</link>    <guid>https://segmentfault.com/a/1190000047400924</guid>    <pubDate>2025-11-14 23:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>本篇文章整理了一些市场上常用的邮件营销工具，分别是“Zoho Campaigns、Mailchimp、Constant Contact、GetResponse、Campaign Monitor、ActiveCampaign”。<br/><img width="723" height="486" referrerpolicy="no-referrer" src="/img/bVdm3i7" alt="" title=""/><br/>在当今快速发展的数字化时代，邮件营销依然是企业与客户沟通、推广产品和增强客户黏性的强大工具。这种营销方式成本低且定制化程度高，无论是大型企业还是中小型企业都可以通过这一途径有效触及目标用户。然而，在展开邮件营销活动之前，选对一款合适的邮件营销工具至关重要。本文将探索市场上那些备受推崇的邮件营销工具，帮助企业发现适合自身发展的解决方案。</p><h2>篇章一：Zoho Campaigns——全面而灵活的解决方案</h2><p>Zoho Campaigns是一款功能全面且灵活的邮件营销工具，适合各种规模的企业。它提供了直观的拖放式编辑器和丰富的模板库，帮助用户轻松创建专业的邮件内容。</p><p>其自动化功能强大，支持设置复杂的邮件序列和触发器，助力企业实现精准营销。详细的分析和报告功能可以实时跟踪邮件活动的效果，帮助企业优化营销策略。</p><p>此外，Zoho Campaigns还支持与Zoho CRM等其他Zoho产品的无缝集成，提供了一体化的客户关系管理解决方案，帮助企业更好地管理客户数据和营销活动。</p><h2>篇章二：Mailchimp——小企业的最佳选择</h2><p>Mailchimp被广泛认为是邮件营销领域的新手优选。这款工具界面直观、操作简单，提供免费和付费两个版本，适合预算有限的小型企业使用。</p><p>Mailchimp的强大之处在于其拖放编辑器，用户无需编程基础即可设计出精美的电子邮件。内部集成的分析工具，可帮助用户实时跟踪邮件的开信率和点击率，让企业对市场反馈一目了然。Mailchimp还提供了丰富的自动化功能，用户可以轻松设置生日问候和行动提醒邮件，帮助企业与用户建立更加亲密的关系。</p><p>Mailchimp的定价模型也较为灵活。对于拥有不足2000订阅者的企业，Mailchimp提供了免费版本，允许每月发送高达10,000封邮件，大大降低了初期投入。</p><h2>篇章三：Constant Contact——传统与现代的完美结合</h2><p>作为邮件营销领域的老牌选手，Constant Contact凭借其可靠性和优良的客户服务，长期稳居市场前列。Constant Contact的客户支持团队提供电话、邮件和社交媒体多渠道支持，是企业制定复杂邮件策略的得力助手。</p><p>Constant Contact的另一大亮点在于其活动管理功能。高度集成的活动管理工具允许用户组织和推广线下活动，如讲座、研讨会等，拓宽企业的互动渠道。此外，它的市场细分功能能够按不同用户群自动分类邮件，确保邮件发送至真正感兴趣的目标客户。</p><p>尽管Constant Contact没有免费版本，但考虑到其专业度，仍被认为是希望以邮件营销提升品牌影响力的企业值得投资的选择。</p><h2>篇章四：GetResponse——多功能一体化平台</h2><p>GetResponse无疑是那些寻求多功能整合方案企业的首选。除了邮件营销，GetResponse还提供了网页设计、自动响应和CRM客户关系管理等多种功能，堪称一站式平台。</p><p>对于高级用户，GetResponse提供了先进的自动化工具，例如漏斗构建器和网页推送功能，让营销人员能够制定复杂的市场活动计划。此外，GetResponse强大的A/B测试功能，让企业可以在邮件推送前，测试不同版本的邮件内容、主题行、发送时间等，确保营销活动的有效性。</p><p>GetResponse基于邮件数量的定价方案，同样适合不同规模的企业，不同套餐包含了不同数量的邮件和服务功能，用户可以根据自身需求自由选择。</p><h2>篇章五：Campaign Monitor——高定制化和品牌推广的优质工具</h2><p>Campaign Monitor是那些强烈关注品牌一致性的企业的最佳选择。它提供的丰富模板库，可以让用户轻松设计与品牌风格相符的邮件内容，确保每一封邮件都展示出企业的独特形象。</p><p>Campaign Monitor的动态内容功能可根据用户行为，自动调整邮件内容，提高邮件的相关性和个性化程度。例如，作为电商企业，用户浏览过的产品可能会在后续的邮件中再次出现，增加下单机会。</p><p>此外，Campaign Monitor提供的详细分析报告，能帮助企业深度挖掘客户数据，包括开信行为、订阅者增长趋势和邮件列表健康度等，为企业策略调整提供了丰富的数据支持。</p><h2>篇章六：ActiveCampaign——人工智能加持的智能营销工具</h2><p>ActiveCampaign不仅是邮件营销工具，更是集成了人工智能应用的深度营销平台。它通过AI技术预测和分析客户行为，自定义营销漏斗和自动化流程，为企业提供了前所未有的全方位营销体验。</p><p>ActiveCampaign的AI驱动技术能够根据数据分析，主动建议最佳发送时间和客户细分策略，让发送出去的每封邮件都能到达最合适的客户。其独特的客户旅程自动化功能，能够全面管理客户生命周期，提高用户转化率。</p><p>此外，ActiveCampaign支持多渠道营销，包括邮件、短信、社交媒体和网站等，帮助企业形成统一的营销声调，在全渠道环境中赢得更多客户。</p><p>总结来说，面对市场上众多邮件营销工具，各企业应充分考虑自身的规模、预算、需求和目标，选择适合的平台来推进邮件营销策略。得当的邮件营销不仅能够帮助企业增加收入，还能提升品牌价值，增强客户忠诚度。因此，深入了解邮件营销工具的功能细节，是每位营销人员必备的一项技能。</p>]]></description></item><item>    <title><![CDATA[《C++在LLM系统中的核心赋能与技术深]]></title>    <link>https://segmentfault.com/a/1190000047400784</link>    <guid>https://segmentfault.com/a/1190000047400784</guid>    <pubDate>2025-11-14 22:02:21</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>从技术演进规律来看，LLM的能力边界不仅由模型架构定义，更受限于底层系统的承载能力，而C++凭借无额外运行时依赖、内存管理自主可控、编译优化灵活高效等核心特性，恰好弥补了高层语言在性能与控制力上的短板，为LLM系统提供了从推理速度、内存占用到稳定性的全方位保障，成为连接LLM复杂算法需求与硬件底层算力的核心桥梁，更是决定LLM能否从实验室原型走向规模化商业应用的技术基石。</p><p>C++的内存管理机制是其赋能LLM系统的核心优势之一，也是区别于高层语言的关键特性，更是解决LLM大内存需求痛点的核心手段。LLM运行过程中需要同时处理三类核心数据：以GB甚至TB级存在的模型权重参数、推理过程中动态生成的中间计算结果、以及用户输入与模型输出的非结构化文本数据，这些数据的存储方式、流转路径直接决定了系统的运行效率与稳定性。高层语言的自动内存回收机制虽然降低了开发门槛，却存在无法规避的天然缺陷：回收时机的不确定性可能导致推理过程中出现突发延迟，自动分配的内存布局难以适配LLM数据的连续性需求，进而引发内存碎片过多、CPU缓存命中率下降等问题，严重时甚至会因内存溢出导致系统崩溃。而C++赋予开发者直接干预内存分配与释放的权限，通过自定义内存分配器，可根据LLM数据的生命周期与大小特征构建专属内存池—采用分层设计思路，将内存池划分为固定大小块池与动态扩容块池，固定块池适配模型权重、常用张量等尺寸稳定的数据，按2^n字节规格划分块大小（如64B、128B、4KB），通过空闲链表快速分配回收；动态块池则用于处理中间计算结果等尺寸可变的数据，采用伙伴系统算法减少内存碎片。同时，将长期复用的模型权重存储在连续的物理内存区域，按CPU缓存页面对齐（通常为4KB或2MB）优化数据读取速度，避免跨页访问带来的性能损耗；对短期存在的中间计算结果采用栈内存分配，利用栈的LIFO特性快速分配释放，避免堆内存申请与释放带来的系统调用开销；通过指针操作与引用机制实现数据在不同模块间的零拷贝流转，彻底杜绝不必要的数据冗余。在边缘设备部署7B参数LLM的实际场景中，这种精细化的内存管理方式可使系统内存利用率提升40%以上，将原本需要16GB的内存占用压缩至10GB以内，不仅有效解决了大模型运行中的内存瓶颈，更让边缘设备等资源受限场景下的LLM部署成为可能，这也是C++在LLM底层开发中无法被替代的核心价值所在。</p><p>C++的编译优化能力为LLM系统的性能提升提供了巨大空间，其对代码的深度优化与硬件指令的精准适配，让LLM的密集型计算效率达到极致水平。LLM的核心计算集中在张量运算、矩阵乘法、自注意力机制计算等密集型任务，这些任务的计算量往往随模型参数规模呈指数级增长，对CPU的运算能力、指令执行效率提出了极高要求。与高层语言依赖虚拟机或解释器执行不同，C++编译器支持从O1到O3的多级优化配置，且不同编译器（GCC、Clang、MSVC）的优化侧重点存在差异—GCC的O3优化更注重循环优化与指令重排，Clang则在向量优化与内存访问优化上表现更优，开发者可根据LLM的计算特性与部署硬件选择适配的编译器。开启O3优化级别时，编译器会自动完成循环展开（将多层循环合并为单层，减少循环控制开销）、指令重排（调整指令执行顺序，避免CPU流水线阻塞）、常量传播（将常量直接代入计算，消除冗余变量）、死代码消除（移除未被调用的函数与无效逻辑）等一系列优化操作，大幅减少冗余指令的执行；对LLM中频繁调用的基础计算函数（如自注意力机制中的点积计算、Softmax激活函数）采用内联函数优化，通过inline关键字或编译器强制内联选项（如GCC的__attribute__((always_inline))），消除函数调用带来的栈帧切换开销，尤其适用于重复执行次数达数百万次的核心计算逻辑。更重要的是，C++支持内嵌汇编与硬件指令集直接调用，开发者可通过CPU检测工具（如cpuid指令、lscpu命令）识别部署硬件的指令集支持情况，针对性适配SIMD、AVX2、AVX-512等高级向量指令集—以AVX-512为例，其可将向量寄存器宽度扩展至512位，单次指令能同时处理16个32位浮点数或8个64位浮点数，将原本需要16次指令完成的矩阵乘法运算压缩至1次，大幅提升张量运算与矩阵乘法的效率。在云端部署175B参数LLM的实践中，仅针对自注意力机制核心计算模块进行编译器选型（选择Clang 16）、O3优化配置与AVX-512指令集适配，就能使该模块的计算速度提升两倍以上，单条推理请求的延迟从800ms降至280ms，这种底层的性能突破是高层语言难以企及的，也充分体现了C++在LLM密集型计算场景下的绝对优势。</p><p>C++的多线程编程模型与同步机制，为LLM系统的并行计算提供了灵活且高效的实现方案，是挖掘多核CPU算力、提升系统吞吐量的核心支撑。LLM的推理过程中蕴含大量可并行的计算任务：多头注意力机制中不同注意力头的计算可独立进行，批量处理用户请求时多个推理任务可同时执行，甚至单条请求的推理过程中，张量拆分后的子任务也能并行运算，如何充分利用多核CPU的计算资源，实现这些任务的高效协同，是提升LLM服务吞吐量、降低单请求延迟的关键。C++的标准多线程库（std::thread）与第三方高性能线程库（如TBB、Boost.Thread）提供了丰富的线程管理与同步工具，支持开发者根据LLM的计算逻辑进行精细化的线程设计：采用线程池模式预先创建与CPU核心数匹配的线程（通常为核心数的1.5倍，避免线程过多导致的上下文切换开销），通过任务队列存储待执行的推理任务，线程池中的空闲线程主动从队列中获取任务执行，避免频繁创建与销毁线程带来的系统开销；同时引入任务优先级机制，将用户请求分为实时查询（如智能客服对话）、批量处理（如文档生成）、后台预处理（如模型预热）三类，为实时查询分配最高优先级，确保高优先级任务抢占计算资源，快速响应。在同步机制上，利用std::mutex解决多线程访问共享资源（如全局配置、缓存数据、模型权重）的竞争问题，通过std::unique_lock实现锁的自动释放，避免死锁风险；对高频访问的共享数据（如批量请求的统计信息）采用std::atomic实现无锁编程，利用CPU的原子操作指令保证数据一致性，彻底消除线程切换带来的性能损耗；通过std::condition_variable实现线程间的精准同步，当任务队列为空时，工作线程进入阻塞状态，避免忙等导致的CPU资源浪费，当新任务加入队列时，主线程通过notify_one或notify_all唤醒空闲线程。此外，C++的异步编程模型（std::future、std::promise）支持将IO密集型任务（如数据读取、网络传输）与计算密集型任务（如模型推理）并行执行—例如在读取用户输入文本的同时，启动模型的前序初始化计算，待数据读取完成后直接接入后续推理流程，进一步提升系统的整体运行效率。这种基于C++的并行计算设计，在云端LLM API服务场景中，能够充分挖掘32核CPU的多核潜力，让系统在处理批量请求时吞吐量提升3倍以上，同时将单请求平均延迟控制在300ms以内，为高并发场景下的LLM服务（如智能客服、内容生成API）提供了坚实的技术支撑。</p><p>C++的跨平台特性与硬件亲和性，让LLM系统能够灵活适配不同的部署场景，从云端高性能服务器到边缘嵌入式设备，实现全场景的高效落地。随着LLM技术的广泛应用，其部署场景日益多元化：云端服务需要支撑海量用户的并发请求，对计算性能、内存容量有极高要求；边缘设备（如智能终端、工业网关）受限于功耗与体积，要求系统具备低内存占用、低功耗运行的特性；嵌入式系统（如智能车载设备、物联网终端）则注重实时响应能力与稳定性。而C++的核心优势在于无需依赖额外的运行时环境，编译后的二进制文件可直接在不同硬件平台上运行，无论是x86架构的高性能服务器、ARM架构的边缘设备，还是RISC-V架构的嵌入式芯片，都能保持一致的稳定表现。针对边缘设备（如搭载ARM Cortex-A53处理器的工业网关）的资源限制，开发者可通过C++的编译优化选项对代码进行裁剪与压缩：使用GCC的-Os优化级别（以体积优化为目标），移除不必要的功能模块、调试信息与冗余代码，将LLM推理引擎的可执行文件体积压缩30%以上；通过链接时优化（LTO）将多个目标文件合并编译，消除跨文件的冗余符号与函数，进一步减小文件体积；同时采用内存压缩技术，将模型权重以16位浮点数（FP16）存储，配合C++的位运算与结构体封装，降低内存占用与数据传输开销。利用C++对硬件的直接操作能力，可通过内嵌汇编调用ARM处理器的NEON指令集，充分发挥边缘设备专用计算单元的算力，避免通用CPU计算带来的资源浪费。在云端部署场景中，C++可与各类操作系统（Linux、Windows Server）、数据库、中间件无缝兼容，通过epoll、kqueue等异步I/O机制提升网络通信效率，配合负载均衡策略（如Nginx+Keepalived）应对海量用户请求的并发处理；针对x86架构的高性能服务器，可适配AVX-512指令集与多通道内存架构，最大化发挥CPU的计算潜能。在智能车载场景中，C++的实时性优势尤为突出—通过编写无锁数据结构与优先级调度逻辑，确保LLM推理任务在100ms内完成响应，满足车载场景的实时交互需求；同时利用C++对硬件的底层控制能力，直接与车载传感器、显示屏等设备进行数据交互，减少中间层开销。这种强大的跨平台适配能力，让C++成为LLM全场景部署的首选语言，也为LLM技术从互联网行业向工业、车载、物联网等领域渗透奠定了基础。</p><p>C++的模块化设计与接口抽象能力，为LLM系统的可扩展性与可维护性提供了有力保障，支撑系统在快速的技术迭代中持续演进。LLM技术处于高速发展阶段，模型架构不断更新（如从Transformer到GPT系列、LLaMA系列、Qwen系列的演进），功能需求日益复杂（如支持多模态输入、长上下文理解、插件扩展），底层系统需要具备足够的灵活性，以适应快速的技术变化与业务迭代。C++支持面向对象、泛型编程等多种编程范式，为模块化设计提供了灵活的实现路径：开发者可通过类与对象的封装，将LLM系统的核心功能拆分为独立的模块，如内存管理模块、计算加速模块、网络通信模块、任务调度模块、模型适配模块等，每个模块内部高度内聚，仅通过清晰的接口（如纯虚函数定义的抽象接口类）与其他模块进行交互，降低模块间的耦合度。当LLM模型升级（如从7B参数模型替换为13B参数模型）或新增功能时，只需对相应模块进行修改或新增——例如引入新的量化推理算法时，可实现统一的计算接口（如IQuantizationEngine），通过接口继承与多态特性，将新算法无缝接入现有系统；适配新的硬件平台时，只需替换硬件适配模块（如将x86指令集适配模块替换为ARM指令集适配模块），无需改动核心业务逻辑。同时，C++的抽象基类与虚函数机制可实现接口与实现的分离，便于不同算法或硬件适配层的灵活替换，例如在计算加速模块中，可定义IComputeAccelerator抽象接口，分别实现CPUAccelerator、GPUAccelerator、NPUAccelerator三个子类，根据部署环境动态选择对应的加速方案。</p>]]></description></item><item>    <title><![CDATA[《LLM零开销抽象与插件化扩展指南》 程]]></title>    <link>https://segmentfault.com/a/1190000047400787</link>    <guid>https://segmentfault.com/a/1190000047400787</guid>    <pubDate>2025-11-14 22:01:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>许多高层语言构建的LLM方案，虽能通过灵活封装适配复杂架构，却因抽象层的运行时开销、硬件调用的中间损耗，导致实际推理效率大打折扣，尤其在高并发、资源受限场景下，这种损耗会被无限放大。而C++的核心价值，正体现在其“零开销抽象”与“硬件级可控”的双重特性上：它既能够以接近汇编的底层效率直接操作CPU、内存、缓存等硬件资源，又能通过泛型编程、强类型系统构建灵活的抽象层，无需额外 runtime 支撑，彻底避免冗余开销。这一特性恰好击中了LLM系统的痛点，无论是多精度张量运算的灵活适配、硬件缓存的极致利用，还是动态场景下的资源安全管理、跨算法架构的快速兼容，C++都能提供坚实的底层支撑。从低功耗边缘设备的小模型部署，到云端千亿参数模型的高并发推理，C++的价值远超单纯的“性能提升”，更是构建高效、可靠、可扩展LLM系统的底层逻辑，成为突破技术瓶颈的核心驱动力。</p><p>C++的强类型系统与泛型编程，为LLM系统的多精度计算、多格式张量处理提供了兼具灵活性与性能的解决方案，彻底摆脱了高层语言“封装即损耗”的困境。LLM的计算过程中，张量类型与精度需求呈现出高度多样性：训练阶段需依赖FP32、FP64等高精度浮点数保证收敛性，推理阶段为节省资源常采用INT8、FP16、FP8甚至INT4的低精度量化格式，而针对稀疏激活的场景，还需适配COO、CSR等不同稀疏张量存储格式。高层语言往往需要通过额外的类型转换、格式适配层来兼容这种多样性，不仅增加了代码冗余，更会带来可观的运行时开销—例如某Python实现的LLM量化推理方案，仅类型转换环节就占用了15%的总推理时间。而C++的模板元编程与编译期类型推导机制，能够在编译阶段完成类型适配与逻辑生成，完全规避运行时额外开销。通过设计泛型张量类，可将数据类型、维度、存储格式、量化精度作为模板参数，编译器会为每种组合自动生成针对性的优化代码，既保证了接口的统一性（开发者无需关注底层类型差异），又避免了类型转换、格式兼容的性能浪费。同时，C++的强类型特性能够在编译期捕获类型不匹配、张量维度错误、精度溢出等问题，大幅减少LLM运行时的异常风险，降低调试成本。在13B参数LLM的INT8量化推理场景中，这种泛型设计可灵活适配不同量化方案（对称量化、非对称量化），通过模板特化为每种方案实现最优运算逻辑，相较于高层语言的统一封装，计算效率提升28%以上，同时保持代码的简洁与可维护性，完美平衡了LLM系统的灵活性与性能需求。</p><p>C++的零开销抽象特性，从根本上解决了LLM系统“复杂架构设计”与“低性能损耗”的矛盾，让高层抽象与底层效率得以兼顾。随着LLM系统功能日益复杂，需兼顾模型推理、任务调度、数据流转、硬件交互、异常处理等多个模块，而抽象层的设计是降低模块耦合、提升可扩展性的关键。但高层语言的抽象往往伴随着难以避免的运行时开销：虚函数调用的间接跳转（每次调用增加2-3个时钟周期，千亿次调用累积损耗显著）、接口封装的额外层级（数据需经过多层转发才能到达硬件）、动态类型转换的资源消耗，这些看似微小的开销在LLM密集型计算场景下会被无限放大，导致整体性能下降。C++的零开销抽象理念，通过编译期优化彻底消除了抽象带来的冗余：采用静态多态（CRTP设计模式）替代传统动态多态，将虚函数调用转化为编译期确定的直接调用，避免运行时跳转开销；利用inline关键字与编译器强制内联优化（如GCC的__attribute__((always_inline))），将高频调用的抽象接口直接嵌入核心代码，消除函数调用的栈帧切换开销；通过模板特化与SFINAE机制（Substitution Failure Is Not An Error），在编译期根据不同场景（如CPU/GPU部署、不同精度计算）选择最优实现，无需运行时判断分支。在LLM的Transformer层设计中，通过零开销抽象构建的通用接口，可灵活组合自注意力机制、前馈网络、层归一化等模块，同时支持不同模型架构（GPT、LLaMA、Qwen）的快速适配—例如新增某类改进型自注意力机制时，仅需实现通用接口的特化版本，无需修改其他核心代码。这种设计既保证了模块的灵活组合与扩展，又确保了各模块的运算效率与直接编写底层代码相当，让LLM系统在具备复杂架构设计的同时，不牺牲核心计算性能。</p><p>C++对内存布局的精准控制能力，成为优化LLM系统缓存利用率、降低内存访问延迟的核心抓手，这一优势在密集型张量运算中尤为关键。LLM的核心计算（如矩阵乘法、自注意力机制）高度依赖CPU缓存的性能—CPU的L1缓存访问延迟仅1-3个时钟周期，L2缓存为10-20个时钟周期，而内存访问延迟高达100-200个时钟周期，缓存命中率每提升10%，整体计算效率可提升8%-12%。高层语言的内存布局由编译器或运行时自动管理，往往难以适配LLM数据的访问模式：例如张量数据跨缓存行存储、相关性低的数据紧凑排列，导致缓存行浪费、频繁缓存失效，严重影响计算速度。而C++允许开发者通过精细化控制内存布局，使其与CPU缓存的工作机制高度匹配：将LLM中频繁访问的张量数据、模型权重按缓存行大小（通常为64字节）对齐排列，通过__attribute__((aligned(64)))等编译器指令强制对齐，避免单个数据跨缓存行存储，减少缓存加载次数；通过数据重排优化空间局部性，将自注意力机制中Q、K、V矩阵的相关元素紧凑存储，确保CPU访问一个缓存行时，能加载到后续运算所需的更多数据；利用内存预取指令（如GCC的__builtin_prefetch），在运算前主动将即将访问的数据加载到缓存中，减少缓存等待时间；针对稀疏张量，按访问热度排序非零元素，将高频访问的非零值与索引存储在连续内存区域，提升缓存命中率。在千亿参数LLM的自注意力机制计算中，通过这些内存布局优化，可将缓存命中率从60%提升至85%以上，减少大量不必要的内存访问，进而使该模块的计算效率提升27%左右，整体推理延迟降低22%。这种对内存布局的底层控制能力，是高层语言无法实现的，也成为C++在LLM密集型计算场景下的核心竞争力之一。</p><p>C++的异常安全与RAII（资源获取即初始化）机制，为LLM系统的长期稳定运行提供了坚实保障，尤其适配高负载、长时间不间断的工业化部署场景。LLM系统在规模化应用中，往往需要面对连续数日甚至数月的高并发运行，期间可能遭遇网络波动、硬件异常、数据格式错误、请求突增等各类突发情况，若资源管理不当，极易出现内存泄漏、显存泄漏、硬件句柄未释放、资源竞争死锁等问题，导致系统性能逐步衰减，甚至直接崩溃。高层语言的自动资源管理机制（如垃圾回收）虽然降低了开发门槛，但存在明显缺陷：回收时机的不确定性可能导致资源释放不及时，在高并发场景下引发资源耗尽；无法高效处理非内存资源（如GPU显存、网络连接、硬件设备句柄），容易出现非内存资源泄漏；垃圾回收过程中的“Stop-The-World”机制会导致LLM推理延迟突发增高。而C++的RAII机制，将资源的生命周期与对象的生命周期严格绑定，通过栈对象、智能指针（std::unique_ptr、std::shared_ptr）等实现资源的自动、安全释放—无论程序正常执行还是遭遇异常退出，只要对象超出作用域，资源就会被立即回收，从根本上避免泄漏。同时，C++的异常处理机制（try-catch）可精准捕获并处理LLM运行中的各类异常，通过noexcept关键字明确函数是否抛出异常，帮助编译器优化代码，减少异常处理的性能开销。在云端LLM API服务场景中，基于RAII机制设计的资源管理模块，可确保每个推理请求占用的内存、CPU核心、网络连接、GPU显存等资源在请求结束后立即释放，即使遭遇突发异常（如请求数据格式错误、GPU算力波动）也不会出现资源残留。某日均处理120万次请求的云端LLM服务，采用该机制后，内存泄漏率始终保持为0，连续运行90天无故障，推理延迟波动控制在5%以内，充分体现了C++在保障LLM系统稳定性方面的核心价值。</p><p>C++的动态链接与插件化扩展能力，完美适配了LLM技术快速迭代的行业现状，为系统的灵活升级、多场景适配提供了高效解决方案。当前LLM技术迭代速度极快，新的模型结构（如MoE混合专家模型、狭长注意力模型）、优化算法（如动态量化、增量推理）、量化方案（如FP8、INT4混合精度）层出不穷，而传统的静态编译系统往往需要全量重构、编译、部署，不仅耗时费力（大型LLM系统全量编译需数小时甚至一两天），还可能影响现有服务的稳定性，导致业务中断。C++的动态链接库（DLL/SO）机制，支持将LLM系统的核心模块（如模型推理引擎、量化算法、硬件适配层、任务调度器）封装为独立的动态链接库，主程序可通过动态加载接口（如dlopen、LoadLibrary）在运行时加载、卸载这些模块，无需重启系统即可完成升级或替换。</p>]]></description></item><item>    <title><![CDATA[ICAIS 2025国际AI科学家大会日]]></title>    <link>https://segmentfault.com/a/1190000047400737</link>    <guid>https://segmentfault.com/a/1190000047400737</guid>    <pubDate>2025-11-14 21:02:01</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400739" alt="" title=""/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400740" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400741" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400742" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400743" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400744" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400745" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400746" alt="" title="" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[告别“随心所欲”编程：Spec Kit ]]></title>    <link>https://segmentfault.com/a/1190000047400735</link>    <guid>https://segmentfault.com/a/1190000047400735</guid>    <pubDate>2025-11-14 21:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>告别“随心所欲”编程：Spec Kit 灵魂文件 Constitution 深度解析</h2><h3>I. 引言</h3><p>在软件开发中，我们依靠 AI 提升效率，但也面临一个挑战：AI 缺乏上下文，容易导致代码不一致甚至“随心所欲编程”（Vibe Coding）。</p><p>在<strong>上一篇文章</strong>中，我们介绍了 <strong>Spec Kit</strong> 这一规范驱动开发（SDD）框架及其五大核心元素：<strong>Constitution, Specification, Plan, Tasks, 和 Implement</strong>。</p><p>今天，我们将聚焦于 Spec Kit 的灵魂文件——<strong>Constitution (宪法/章程)</strong>。它是整个 SDD 流程的<strong>基石</strong>，为项目设立了<strong>不变的、必须遵守的规则</strong>。</p><p>Constitution 是一份<strong>非协商性（Non-negotiable）</strong>的最高法典。它的核心作用是：<strong>彻底终结“随心所欲编程”</strong>，确保无论是 AI 还是人类，都遵循相同的技术和质量标准，为项目设立一个永恒的“北极星”，保证代码的长期<strong>可维护性和合规性</strong>。简单来说，Constitution 定义了：<strong>无论如何，项目必须在什么界限内构建。</strong></p><hr/><h3>II. Constitution 的结构与作用</h3><p>Constitution 必须在项目开始之初就确定，并在整个生命周期中保持固定。</p><h4>作用机制</h4><p>Constitution 不会描述你要构建什么具体功能（那是 Specification 的工作），但它会深度影响 AI 代理在后续步骤中的所有决策：</p><ul><li><strong>约束输入：</strong> 当你要求 AI 制定计划（<code>/plan</code>）时，AI 必须基于 Constitution 中规定的技术栈（例如必须使用 React）来设计方案。</li><li><strong>验证输出：</strong> 在实施（<code>/implement</code>）阶段，AI 必须确保生成的代码满足 Constitution 中规定的质量标准（例如 90% 的测试覆盖率）。</li></ul><h4>三大核心组成部分</h4><p>一个结构严谨的 Constitution 通常包含以下三个关键部分，它们共同构筑了项目的开发哲学和技术底线：</p><ol><li><strong>核心原则 (Core Principles)：</strong> 定义项目的“开发哲学”和“质量底线”。（如用户体验 (UX) 必须遵循 GDS 标准、代码必须达到 A 级可读性、性能最低要求等。）</li><li><strong>技术约束 (Technical Constraints)：</strong> 锁定项目使用的技术和架构选择。（如必须使用 Go 语言、状态管理必须使用 Redux Toolkit 等。）</li><li><strong>质量与治理 (Quality &amp; Governance)：</strong> 设定不可妥协的测试、安全和合规标准。（如最低单元测试覆盖率必须达到 85%、提交信息必须遵循 Conventional Commits 规范等。）</li></ol><hr/><h3>III. 实践案例：Flutter 计时器应用的 Constitution 剖析</h3><p>为了更好地理解 Constitution 的实践意义，我们以一个具体的项目为例：<strong>构建一个跨平台的 Flutter 计时器应用。</strong></p><h4>Constitution 内容拆解与深度解析</h4><table><thead><tr><th align="left">Constitution 部分</th><th align="left">规则示例</th><th align="left">为什么必须写入？</th></tr></thead><tbody><tr><td align="left"><strong>核心原则</strong></td><td align="left">“应用必须在所有目标平台上保持流畅的 <strong>60 FPS</strong>。”</td><td align="left"><strong>【性能约束】</strong>计时器应用对实时性和性能要求极高。写入此条迫使 AI 在代码设计中优先考虑性能优化和减少重绘。</td></tr><tr><td align="left"><strong>技术约束</strong></td><td align="left">“状态管理必须使用 <strong>Riverpod</strong> 库。”</td><td align="left"><strong>【技术锁定】</strong>Flutter 有多种状态管理方案。锁定 <strong>Riverpod</strong> 可以确保团队和代码库的技术栈统一，避免 AI 随机选择，保证长期可维护性。</td></tr><tr><td align="left"><strong>技术约束</strong></td><td align="left">“在 Android 上使用 Material Design 风格，iOS 上可选择 Cupertino，但须保持整体设计的一致性。”</td><td align="left"><strong>【UX 规范】</strong>确保跨平台应用遵循平台原生风格，但同时又通过“保持一致性”的约束来防止设计上的分裂。</td></tr><tr><td align="left"><strong>质量与治理</strong></td><td align="left">“核心业务逻辑必须包含单元测试，<strong>覆盖率目标为 90%</strong>。”</td><td align="left"><strong>【质量硬指标】</strong>这是衡量 AI 产出质量的硬性指标。它强制 AI 不仅要写功能代码，还要为核心的计时逻辑编写高质量的测试代码。</td></tr><tr><td align="left"><strong>质量与治理</strong></td><td align="left">“提交信息必须遵循 Conventional Commits 规范。”</td><td align="left"><strong>【治理规范】</strong>保证 Git 历史清晰，方便自动化工具（如 CI/CD 流程）自动生成 Change Log 和版本号。</td></tr></tbody></table><h4>总结：Constitution 如何防止“跑偏”</h4><p>如果没有 Constitution，当你要求 AI 构建“一个计时器”时，它可能会随机选择一个过时或不流行的库、忽略单元测试、或者在代码中混用多种语言风格。</p><p><strong>Constitution 就像一个强大的“过滤器”</strong>，它在代码生成前就设定了边界和标准，确保 AI 的每一个输出都符合这些预设的、严格的、面向未来的项目标准。<br/>Constitution 是 Spec Kit 中最重要的文件，它决定了项目的方向和最终质量。我们不应将其视为额外的负担，而应将其视为<strong>成功的蓝图和对项目未来的投资</strong>。花时间精心起草这份文件，将为后续的开发工作节省大量返工和调试的时间。</p><p>本文由<a href="https://link.segmentfault.com/?enc=M34mIA5E7voZLHHINhTM%2FQ%3D%3D.ca%2B6RtU7kUHddVUHJr6rk0SfVK2fzLB10zLdSmGVxII%3D" rel="nofollow" target="_blank">mdnice</a>多平台发布</p>]]></description></item><item>    <title><![CDATA[外贸公司外网怎么开？有哪些连接外网的方法]]></title>    <link>https://segmentfault.com/a/1190000047400556</link>    <guid>https://segmentfault.com/a/1190000047400556</guid>    <pubDate>2025-11-14 19:07:04</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>对于外贸企业来说，一条稳定、高速且安全的国际网络就是拓展业务必要工具，但是很多企业不知道如何选择哪种网络连接方式以及服务商，所以本篇内容为大家介绍外贸公司外网怎么开？有哪些连接外网的方法？一起往下看看吧。</p><p>一、外贸公司连接外网的两种主流方式</p><p>外贸公司稳定访问外网主要依赖于两类合规专线：传统国际专线和更现代的SD-WAN专线。它们之间的核心区别如下表所示：<br/><img width="723" height="296" referrerpolicy="no-referrer" src="/img/bVdm3dc" alt="" title=""/><br/>小结与建议：</p><p>传统专线适合对网络稳定性和安全性有极致要求、且预算非常充足的大型金融或跨国企业。</p><p>SD-WAN专线则凭借其智能、灵活和高性价比的特性，成为当前绝大多数外贸中小企业的首选，它能很好地满足跨境电商、视频会议、海外社媒运营等需求。</p><p>二、主流外贸网络专线服务商</p><p>主要可分为两大类型：<br/><img width="723" height="296" referrerpolicy="no-referrer" src="/img/bVdm3dd" alt="" title="" loading="lazy"/></p><p>小结与建议：</p><p>传统专线适合对网络稳定性和安全性有极致要求、且预算非常充足的大型金融或跨国企业。</p><p>SD-WAN专线则凭借其智能、灵活和高性价比的特性，成为当前绝大多数外贸中小企业的首选，它能很好地满足跨境电商、视频会议、海外社媒运营等需求。</p><p>三、如何选择合适的网络专线?</p><p>1、明确自身业务需求</p><p>业务类型：是日常办公、视频会议、跨境电商，还是TK直播?直播通常需要5M以上的稳定带宽。</p><p>覆盖地域：主要需要访问哪些国家和地区?</p><p>用户规模：公司内部有多少员工需要同时使用?</p><p>2、评估服务商</p><p>节点覆盖：确保服务商在您业务重点区域有充足的POP接入点。</p><p>SLA服务等级协议：仔细查看服务商对网络可用性(如99.9%)、延迟、故障响应时间的承诺。</p><p>安全与合规：务必确认服务商持有合法资质，提供的是合规线路，这是企业稳定运营的生命线。</p><p>3、平衡成本与预算</p><p>对比不同服务商的报价时，要了解清楚是独享带宽还是共享带宽，以及费用中是否包含安装、设备和IP地址等增值服务费。</p><p>4、考量部署与运维</p><p>确认服务商的部署速度和售后技术支持能力，是否提供7×24小时的技术支持。</p><p>四、外贸网络专线推荐</p><p>OSDWAN：尤其适合广大中小外贸企业。它提供合规、高性价比的解决方案，支持硬件和软件多种部署方式，全球节点丰富。</p><p>OSDWAN的核心优势</p><ol><li>合规安全的跨境连接</li></ol><p>OSDWAN使用三大运营商的合规国际网络专线，支持CPE硬件和专属软件，提供更灵活、智能和可管理的跨境专线网络。</p><p>在多个国家租用本地运营商家庭或商业宽带，向客户提供合法、稳定、长期使用的家庭IP地址。这对于需要访问国际服务或进行跨境数据传输的湖南企业来说，既保障了合规性，又确保了连接质量。</p><ol start="2"><li>性价比优势</li></ol><p>相比传统SD-WAN服务商与运营商的昂贵价格，OSDWAN走的是跟三大运营商（中国电信 、中国移动、中国联通）一样的线路，比如外贸办公价格690元/年起，并且企业专线比传统营业厅价格低至一半，性价比高。</p><ol start="3"><li>灵活简单的部署方式</li></ol><p>OSDWAN支持多种型号的CPE设备，还支持Windows、Mac、iPhone、安卓、iPad等多种终端，让企业员工随时随地一键连接全球互联网。</p><p>五、OSDWAN开通使用指南</p><p>以OSDWAN为例，开通使用非常简单：</p><ul><li>开通账号：联系服务商购买并开通账号，企业需要提供营业执照和实名信息。</li><li>下载客户端：在官网下载对应操作系统(Windows、macOS、手机端)的客户端软件。</li><li>登录连接：安装后打开软件，登录账号，根据业务场景(如企业SaaS、海外直播、开发科研等)选择合适的加速模式，点击连接即可。<br/>当日开通，一分钟即可连接使用。</li></ul><p><img width="723" height="474" referrerpolicy="no-referrer" src="/img/bVdm3df" alt="image.png" title="image.png" loading="lazy"/></p><p>六、常见问题解答(FAQ)</p><p>问：VPN可以用于公司业务吗?</p><p>答：绝对不建议。 企业私自搭建或使用未经授权的VPN进行跨境联网是明令禁止的，存在严重的法律风险。企业务必选择像OSDWAN这样的合规网络专线服务。</p><p>问：开通专线需要哪些企业资质?</p><p>答： 通常需要提供公司的营业执照等基本资质文件，用于服务商进行合规审核。</p><p>问：带宽选择多大合适?</p><p>答： 这取决于具体业务。普通办公1-5M可能足够，但高清视频会议或跨境直播则需要5M甚至更高的稳定带宽。建议与服务商沟通进行精准评估。</p>]]></description></item><item>    <title><![CDATA[从“事后抢险”到“事前防控”：江西水投用]]></title>    <link>https://segmentfault.com/a/1190000047400564</link>    <guid>https://segmentfault.com/a/1190000047400564</guid>    <pubDate>2025-11-14 19:06:27</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><strong>小T导读</strong>：在洪涝频发的江西，江西水投打造了一套覆盖全域的智慧水利体系：实时采集水位、流量、水质等关键数据，借助 AI 与数字孪生进行动态推演，实现精准预警与智能调度。实践证明，这套系统让防汛从“事后抢险”变为“事前防控”，大幅提升了治理效率与安全保障。TDengine TSDB 正是这套体系的“定海神针”，承担起海量水情数据的实时采集、存储、处理与共享。本文由江西水投分享他们应用 TDengine TSDB 的相关经验，给到大家参考。</p><h2>应用背景</h2><p>江西作为长江流域五大暴雨区之首，受亚热带季风气候与鄱阳湖盆地地形影响，洪涝灾害频发且影响深远。几乎每年都有局部洪涝发生，较大规模灾害平均 3 至 5 年便会出现一次。仅 2024 年，全省就遭遇 33 次强降雨、14 次编号洪水，46 条河湖 117 个监测站点超警，鄱阳湖更创下 21 世纪以来第二高水位，超警时间长达 38 天。</p><p>在这样水情复杂的核心区域，江西水投正以物联网和 AI 技术重塑传统治水模式。江西省水利物联网平台整合物联网网关、数据中台与“五慧”AI 决策引擎，构建起覆盖 217 座水厂、服务近 2000 万人口的智慧治理网络。从蜂巢式智能测站织就的“神经末梢”，到数字孪生峡江水利枢纽实现的防洪调度可视化，再到 DMA 分区计量将管网漏损精准锁定，这套系统以 80 万+ 设备的泛连接筑牢供水防线，更借助“慧算”模型延长洪水预见期，让科技成为守护鄱阳湖生态与长江经济带水安全的核心支撑。</p><p>江西省水利物联网平台不仅覆盖全省水厂和管网，更在关键环节部署了精细化的感知单元。</p><h3>智能测站数据采集：实时感知现场状态</h3><p>依托蜂巢式智能综合测站，平台能够实时采集水务现场的多维度数据，既包含环境参数（温度、湿度），也覆盖设施运行状态（风扇启停、箱门开关、机箱进水、立杆倾斜度），同时还可监测 MCU 模块、主控模块、电源模块等核心硬件的工况。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400566" alt="" title=""/></p><p><strong>业务收益：</strong> 消除了传统水务监测的“数据盲区”，为后续分析与告警提供实时、全面的数据源。从源头确保设施运行状态精准可感知，夯实了监测的及时性与准确性基础。</p><h3>告警模型管理：精准识别异常风险</h3><p>在告警模型管理模块中，系统可灵活配置多类型业务规则，包括超阈值告警、极值突破告警、水位/雨量异常告警、超警戒告警、对比校验告警等，并支持对模型的启用/停用及规则详情进行精细化管控。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400567" alt="" title="" loading="lazy"/></p><p><strong>业务收益：</strong> 通过差异化的告警规则，全面覆盖水位超限、雨量异常、设备参数越界等典型水务风险场景，使监测从“被动应对故障”升级为“主动识别风险”，显著提升了异常发现的精准度与前瞻性，最大限度降低因异常未及时察觉而带来的安全隐患。</p><h3>告警发布与全流程管理：高效推动应急处置</h3><p>告警发布管理模块能够全要素记录并实时推送告警信息，涵盖告警编号、规则名称、级别、涉及设备/测站、时间、状态及通知情况，并支持“查看详情”“发送通知”等操作，串联起“告警触发—信息发布—人员响应”的闭环流程。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400568" alt="" title="" loading="lazy"/></p><p><strong>业务收益：</strong> 运维人员和管理部门可第一时间掌握告警详情（严重程度、发生位置、关联设施等），大幅缩短应急响应时长；同时，全流程的告警记录为后续复盘与管理优化提供依据，使水务应急处置从“经验驱动”升级为“数据驱动”，管理效率与规范性显著提升。</p><p><strong>总结：</strong> 通过“采集—分析—处置”的智能化流程，系统既实现了对水务运行状态的全方位感知与精准预警，又全面提升了应急处置的效率与规范性，为水务系统的安全与稳定运行提供了坚实支撑。</p><h2>TDengine TSDB 应用经验</h2><p><strong>TDengine TSDB 正是这套系统的“定海神针”，承担起实时数据采集、存储、处理与共享的核心任务。</strong>在此，我们结合业务在 TDengine TSDB 平台上的落地实践，分享过去几年的应用经验。</p><h3>时序数据库选型</h3><p>在早期的业务系统中，我们曾使用 Oracle 作为物联网实时数据的存储底座。但随着时序数据规模的快速增长，Oracle 的瓶颈逐渐显现，已无法高效支撑我们的业务：</p><ul><li>单表数据量达到千万级后，查询性能急剧下降，甚至出现无法响应的情况；</li><li>存量数据随时间累积持续膨胀，空间占用越来越大，存储成本直线提升。</li></ul><p>为此，我们系统性调研了多款时序数据库，最终选择 TDengine TSDB，原因在于其具备以下核心优势：</p><ul><li><strong>高吞吐性能：</strong> 单核即可支撑每秒 50 万条数据的写入与查询，并支持水平扩展，业务高峰期依然稳定运行；</li><li><strong>高压缩比：</strong> 数据压缩率可达 1:50，显著降低存储占用和成本；</li><li><strong>国产化适配：</strong> 完全支持国产 CPU 与操作系统，提升系统的自主可控能力；</li><li><strong>低成本拥有：</strong> 兼容标准 SQL，大幅降低迁移和学习成本。</li></ul><h3>标准化设备模型</h3><p>此前使用 Oracle/MySQL 时，我们习惯将所有设备数据集中存储在一张表中，导致模型冗杂、治理困难。引入 TDengine TSDB 后，超级表的架构优势为数据存储与治理之间搭建起天然桥梁，使业务应用的高效性与数据管理的便捷性得以兼得。</p><ul><li><strong>标准化设备管理：</strong> 通过超级表模板，将同类设备统一建模，实现治理从源头落地；</li><li><strong>标签化业务数据：</strong> 借助标签机制，将业务信息与数据信息有机融合，统一管理与应用；</li><li><strong>并行化数据处理：</strong> 通过超级表查询充分发挥分布式数据库的优势，实现毫秒级响应。</li></ul><p>以流量计为例，创建超级表 FlowMeter，即可对所有同类设备的数据进行标准化建模，简化了管理流程并提升了查询性能。</p><h3>高效的数据查询</h3><p>在 TDengine TSDB 中，各类设备的数据检索可直接通过标准 SQL 高效实现，不需要再像 Oracle 那样依赖复杂的表参数调优。例如在告警场景下，面对数十万设备的告警信息，系统依然能够在毫秒级完成查询，全面支撑业务应用的实时性需求。</p><p>其中，<strong>缓存 + last\_row</strong> 以及 <strong>超级表 + partition by</strong> 是最常用且实用的组合。以渗压计的实时监控为例：</p><ul><li>针对单个设备，开启缓存后使用 <code>last_row</code> 查询最新数据，仅需 <strong>4.8 毫秒</strong>：</li></ul><pre><code class="sql">taos&gt; select last_row(*) from nwater.shenyj where deviceid = 54000000034915 &gt;&gt; /dev/null;
Query OK, 1 row(s) in set (0.004813s)</code></pre><ul><li>针对所有设备，使用超级表查询近 4 万个设备的最新数据，仅需 <strong>167 毫秒</strong>：</li></ul><pre><code>taos&gt; select last_row(*) from nwater.shenyj partition by tbname &gt;&gt; /dev/null ;
Query OK, 37911 row(s) in set (0.167385s)</code></pre><h2>TDengine TSDB 版本升级</h2><p>在跨大版本升级时，我们的核心诉求是<strong>不停服升级</strong>，以尽量减少业务影响。经过 TDengine 专业服务团队评估，最终采用了三阶段在线升级方案，彻底消除了我们的升级顾虑：</p><ul><li><strong>阶段一：历史数据批量迁移</strong>——将原低版本数据从旧有集群，批量同步至新集群。</li><li><strong>阶段二：近线实时数据迁移</strong>——将历史数据同步期间产生的近线实时数据，从旧有集群，实时同步至新集群。</li><li><strong>阶段三：应用切换数据库</strong>——将应用原指向数据库切换为新数据库。</li></ul><p>实践中，在完成阶段一后，我们只用了 <strong>1 个工作日</strong>就完成了新旧系统的切换。整个过程中，应用只需修改数据库地址和部分查询语句，对业务基本无感知，数据始终保持一致，大大节省了运维和开发的人力与时间。</p><p>这一高效迁移的秘诀在于 <strong>TDengine 企业版工具 taosX</strong>。它支持以压缩方式实时同步集群间数据，无需手写迁移脚本，也无需考虑版本差异，迁移效率最高可达 <strong>千万行/秒</strong>，显著提升了升级的平滑性与可靠性。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400569" alt="" title="" loading="lazy"/></p><h2>4 年稳定运行下的经验汇总</h2><p><strong>在近 4 年的应用过程中，我们从 TDengine TSDB 2.2 升级至 3.3.6.x</strong>，一路见证了产品的不断增强与完善。期间双方紧密协作，积累了一些值得分享的经验，供大家参考：</p><ul><li><strong>及时沟通与需求反馈：</strong> TDengine TSDB 企业版提供专业服务支持，遇到技术问题应第一时间联系技术团队，以获取最佳实践指导，避免走弯路。同时，用户可将业务中遇到的功能需求及时反馈，企业用户往往能获得快速的响应与支持。</li><li><strong>持续关注产品升级：</strong> 随着 TDengine TSDB 的迭代，3.0 之后的版本功能更丰富、稳定性更高，升级过程也极为简便。常规升级可在不停服、不改应用的情况下，于小时级完成。</li><li><strong>定期开展巡检服务：</strong> 不要忽视 TDengine 提供的周期性自动化巡检服务，这能帮助我们提前发现潜在问题并及时处理，保障系统的稳定运行。</li></ul><h2>期待更多的可能性</h2><p>经过多年的探索与实践，江西水投已在“水务 + IoT”架构中走在业界前列。随着业务不断深入，我们将从更多维度开展水文监测与预测，尤其是结合气象数据开展中短期水文状况的趋势分析与相关性研究。这不仅会对 TDengine 提出新的挑战，也为双方合作开辟更广阔的空间。我们期待未来 TDengine TDgpt、IDMP 等新一代产品为水务治理注入更强的智能能力，助力构建更加安全、智慧的水务体系。</p><h2>关于江西水投</h2><p>江西省水投江河信息技术有限公司（以下简称“江河信息”）成立于 2018 年 6 月，是江西水投旗下全资二级企业，是一家集咨询规划、软硬件研发、综合运营为一体的高新技术国有企业。公司承担江西省智慧水利建设项目法人及江西水投集团信息化建设项目法人职责，致力于成为江西数字经济产业的标杆服务商、全国智慧水利领域的一流运营服务商。</p><p><strong>作者 | 江西省水投江河信息技术有限公司 刘博武</strong></p>]]></description></item><item>    <title><![CDATA[Cantata 25.07 全新上线：完]]></title>    <link>https://segmentfault.com/a/1190000047400574</link>    <guid>https://segmentfault.com/a/1190000047400574</guid>    <pubDate>2025-11-14 19:05:27</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>Cantata 25.07版本全新发布！此版本为以代码编辑器为中心的用户添加了更多功能，包括完整的CLI测试脚本创建和执行以及新的测试用例编辑，更新了最新铁路软件标准EN 50716:2023的工具认证，增强了代码覆盖率报告，并进一步扩展了支持的平台。此外，在此版本中修复了核心组件和辅助工具中的许多错误。</p><p>Cantata 25.07还包含许多其他生产力和灵活性增强以及修复。全套更改记录在发行说明中，该说明跟踪了Cantata自4.0版本以来的所有更改。此版本中最重要的更改将在以下部分中突出显示。</p><h3>完整的CLI测试脚本生成</h3><p>对于许多以代码编辑器为中心的Cantata用户（例如在VSCode等编辑器中开发测试的用户）来说，Cantata  25.07中的新命令行测试脚本生成器实用程序将是一个受欢迎的生产力提升。这个新的headless  Eclipse实用程序使用一些可配置的选项和其他默认设置，完全从命令行生成Cantata测试脚本。</p><p>只要有一个现有的Eclipse工作区，该实用程序就会提供生成工作测试脚本所需的所有选项，包括：</p><ul><li>测试的位置，绝对和相对路径</li><li>测试脚本名字</li><li>CSI文件位置</li><li>桩和封装函数的生成</li><li>使用Cantata makefile构建测试或将其放置在正在测试的源代码旁边</li><li>测试用例生成（无用例、每函数1用例、AutoTest以及使用或不使用测试步骤）</li><li>代码覆盖率规则集</li></ul><h3>新的设置测试输入的宏</h3><p>在25.07版本中，为以代码编辑器为中心的用户添加了新的Cantata Library宏 SET_TEST_INPUT。这增加了编辑测试脚本时的功能，可以直接设置输入值并将该输入值记录到生成的Cantata测试结果文件（.CTR）中，而不用复制代码。这个新宏只接受一个参数var，它应该是一个有效的变量赋值。以下示例显示了一个测试用例和生成的测试结果报告部分。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400576" alt="图片" title="图片"/><br/>​<br/>图 1 测试用例</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400577" alt="图片" title="图片" loading="lazy"/><br/>​<br/>图 2 测试结果文件片段</p><h3>CPPGETCOV扩展上下文覆盖率</h3><p>Cantata的经过认证的工具CPPGETCOV是一个可执行文件，在一个或多个Cantata代码覆盖率（.COV）文件上运行，以生成适合认证的Cantata测试结果文件（.CTR）。传统的代码覆盖率衡量源代码构造的执行情况，但不考虑代码对象执行的上下文。根据上下文的不同，相同的源代码可能表现不同（例如，在多个线程中运行、在多个继承中运行多态基类代码或在不同状态下运行状态机代码）。Cantata提供了将结构代码覆盖率与其执行上下文叠加（测量和过滤）的能力。这允许用户根据上下文区分代码覆盖率。Cantata上下文覆盖的应用包括：</p><ul><li>继承</li><li>状态机</li><li>线程</li></ul><p>Cantata会自动收集继承上下文的代码覆盖率。可以使用添加到测试脚本中的user_context_function来设置状态上下文或线程上下文的代码覆盖率，该函数定义了执行被测源代码的可能不同上下文。</p><p>在Cantata 25.07中，CPPGETCOV得到了增强，可以对不同的代码上下文进行覆盖率报告。--context:&lt;string&gt;参数指定覆盖率报告的上下文字符串，而--function:&lt;name&gt;参数指定要报告的函数或方法。这两个参数默认都是“*”。</p><h3>故障修复</h3><p><strong>核心组件</strong></p><p>经过认证的核心组件中有30多个缺陷得到了解决。亮点包括：</p><ul><li>修复了调用返回覆盖率与模板函数、lambds和构造函数不一致的问题。</li><li>改进了与Boost和C++20构造的兼容性。</li><li>增强CTR2HTML转换逻辑。</li><li><p>许可证日志、测试工具缓冲区管理和表达式评估的稳定性改进。</p></li></ul><h3>补充工具</h3><p>补充工具的改进。亮点包括：</p><ul><li>AutoTest增强了对复杂数据类型和联合访问的处理</li><li>Eclipse UI元素、测试用例生成和部署工具可靠性的修复</li><li>为国际用户更正缺失或错误报告的教程内容</li></ul><h3>更新了平台支持版本</h3><p>Cantata的每个版本都有支持平台的变化。</p><p>Cantata紧密地与Eclipse®的IDE环境集成，提供Eclipse-Ready®插件。Cantata 25.07建立在Eclipse 2024-12版本（Eclipse 4.34）上，也可以作为从Neon（4.6）版本直到Eclipse 2023-12（4.30）版本的Eclipse-Ready插件来安装：</p><ul><li>Eclipse 4.6 (Neon)</li><li>Eclipse 4.7 (Oxygen)</li><li>Eclipse 4.9 (2018-09)</li><li>Eclipse 4.14 (2019-12)</li><li>Eclipse 4.15 (2020-03）</li><li>Eclipse 4.16 (2020-06)</li><li>Eclipse 4.19 (2021-03)</li><li>Eclipse 4.23 (2022-03)</li><li>Eclipse 4.24 (2022-06)</li><li>Eclipse 4.30 (2023-12)</li></ul><p>Cantata 25.07增加了对Microsoft Visual Studio 2022和GNU GCC for C/C++ 14和15版本。完整的支持平台列表如下：</p><p>在Windows（32和64位）版本7、8/8.1、10、11上：</p><ul><li>Microsoft Visual C++ (32-bit): 2010, 2013, 2015, 2017, 2019, 2022</li><li><p>GNU GCC for C/C++: 4.6.2 to 13.2.x</p></li></ul><p>在Linux（32和64位）内核发行版无关版本3.x、4.x、5.x、6.x上：</p><ul><li><p>GNU GCC for C/C++: 3.4.6 to 15.1.x</p></li></ul><p>了解更多有关Cantata的技术信息及商务服务，请访问<a href="https://link.segmentfault.com/?enc=JOei6ZUWltYaPoGikV3xQQ%3D%3D.60%2FbD0iNKqC%2FuLYKxR%2Fyzfp2yZzu8vyfdFtkmQcu7JM%3D" rel="nofollow" target="_blank">http://www.softtest.cn/</a>留言，或按以下方式联系旋极智能：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400578" alt="图片" title="图片" loading="lazy"/><br/>​</p><p>获取更多资讯▼关注我们<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047400579" alt="图片" title="图片" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[越南纯净住宅IP怎么收费的？一个月多少钱]]></title>    <link>https://segmentfault.com/a/1190000047400586</link>    <guid>https://segmentfault.com/a/1190000047400586</guid>    <pubDate>2025-11-14 19:04:35</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>最近，很多用户都想做越南地区的Tik Tok，那么选择一个纯净住宅IP是非常重要的，可以有效避免Tik Tok的风控机制，但是很多新手用户不知道越南纯净住宅IP的价格，所以本篇内容为大家详细介绍。具体如下：</p><p>一、越南纯净住宅IP是什么？为什么需要？</p><p>越南纯净住宅IP指的是来源于越南本地网络服务提供商(ISP)、分配给真实家庭宽带用户的IP地址。与数据中心IP相比，它们最大的特点是直接关联到一个真实住宅地址，因此具有更高的信任度。</p><p>这类IP的核心价值在于其真实性和隐蔽性，能有效规避许多网站针对数据中心IP和代理服务器的访问限制。这对于需要模拟越南本地真实用户行为的业务至关重要。</p><p>其主要作用体现在以下几个方面：</p><p>1、社交媒体平台：Facebook、Zalo、Instagram、Tik Tok和本地平台Gapo在越南广泛使用。这些平台对IP变动异常敏感，频繁切换IP或使用数据中心IP可能导致账号被标记为异常，要求稳定的本地住宅IP环境。</p><p>2、电商平台：Shopee、Lazada、Tiki等主流电商平台会基于IP地址展示差异化内容和定价。使用越南本地IP可以获得真实的本地用户体验，准确监控竞争对手动态和价格策略。</p><p>3、通讯工具与流媒体：Zalo是越南主流的通讯工具，Netflix、YouTube等流媒体平台也拥有大量用户。这些服务一般对于IP类型要求比较高，建议使用纯净的住宅IP。</p><p>4、支付与金融系统：Momo、VNPay等本地电子钱包和银行应用为保障安全，常会阻止来自外国IP的登录尝试，需要靠谱的越南IP才能顺畅操作。</p><p>越南网络环境的一个显著特点是，即使IP地址显示在越南，某些网站仍可能因DNS缓存或浏览器语言设置拒绝提供服务。清理DNS缓存(命令提示符中输入ipconfig/flushdns)并将浏览器语言改为越南语是必要的辅助措施。</p><p>二、越南IP有哪些类型？不同IP有哪些差异？</p><p>选择合适的越南IP前，需明确各类IP的关键区别：</p><p><img width="723" height="265" referrerpolicy="no-referrer" src="/img/bVdm3dn" alt="" title=""/></p><p>选择的关键因素：</p><p>业务持续性要求：长期业务如电商店铺管理、社交媒体运营应选择静态住宅IP或者原生住宅IP，它提供不变的IP地址，建立可靠的数字身份。临时任务如市场调研则适合成本更低的动态住宅IP。</p><p>账号安全等级：高价值账号务必使用独享IP，共享IP池中其他用户的行为可能导致“连坐封号”。</p><p>我们OSDWAN提供合规专线网络及不同类型的IP（机房、普通住宅、原生住宅等等，满足不同场景的业务需求）。</p><p>三、越南纯净住宅IP怎么收费的？有哪些注意事项？</p><p>越南纯净住宅IP的收费方式灵活多样，以下是收费模式参考：</p><p>主要的收费模式包括：</p><p>按IP数量计费：许多代理服务商会根据你需要的独享IP数量来定价。例如，OSDWAN提供包括越南以及100+国际的住宅静态IP，其中越南独享静态IP费用参考价为50-200元/月/个。</p><p>按流量计费：部分服务商会按照实际使用的数据流量（例如每GB） 来收费，这种模式适合流量需求波动较大的用户。</p><p>按时间套餐计费：提供日、周、月、年等不同时长的套餐，购买时间越长，通常单价越划算。</p><p>混合计费模式：有些服务商会将以上几种模式结合，例如，在月费基础上包含一定量的流量，超出部分另行计费。</p><p>选购时需要关注的要素：</p><p>IP纯净度与独享性：务必确认IP是真实住宅IP且为独享。共享IP容易被滥用，导致连带风险。而OSDWAN提供真实并且可靠的住宅静态IP，可以通过检测工具去检查。</p><p>以下是OSDWAN的越南原生住宅IP真实检测图：</p><p><img width="640" height="824" referrerpolicy="no-referrer" src="/img/bVdm3dH" alt="image.png" title="image.png" loading="lazy"/></p><p>服务商的技术实力：考察其网络稳定性(如SLA服务等级协议)、可用率以及并发连接数是否满足需求。</p><p>合规性与售后服务：选择能提供7*24小时技术支持的服务商非常重要。同时，要明确服务条款，确保你的使用方式符合当地法律和服务商的规定。</p><p>四、如何选择靠谱的服务商购买？哪些好？</p><p>购买越南纯净住宅IP，通常遵循以下步骤：</p><p>1、明确需求：首先想清楚你需要静态还是动态IP、需要多少个、带宽和流量要求大致是多少。</p><p>2、寻找服务商：建议选择拥有合法资质的服务商购买，比如OSDWAN是通过工信部备案的。</p><p>3、测试验证：务必利用服务商提供的免费试用或测试流量。重点测试IP的纯净度(是否被主要网站识别为代理)、速度以及稳定性。</p><p>4、选择套餐并购买：根据测试结果和业务需求，选择合适的套餐并付款。</p><p>哪家好？推荐OSDWAN，具体如下：</p><p>OSDWAN采用运营商合规国际网络专线，100+地区高纯净度原生住宅静态IP，在多个国家租用本地运营商家庭或商业宽带，向客户提供合法、稳定、长期使用的家庭IP地址来源，纯净独享，可用于TK直播 。</p><p>五、 常见问题解答</p><p>问：越南纯净住宅IP和机房IP有什么区别？</p><p>答：主要区别在于来源和信任度。住宅IP来自ISP，关联真实家庭地址，信任度高；机房IP来自数据中心，可能一个IP被多个用户共用，容易被网站的风控系统识别和拦截。</p><p>问：购买时如何验证IP确实是纯净住宅IP？</p><p>答：你可以使用一些在线的IP信息查询网站。在连接代理后访问这些网站，检查IP的归属机构是否为知名的越南ISP(如VNPT、FPT、Viettel)，以及IP类型是否被识别为”residential”或”ISP”。</p><p>问：可以指定越南某个城市的IP吗？</p><p>答：可以。一些高级的代理服务支持城市级甚至运营商级的IP定位。例如，OSDWAN就支持在全球100多个国家和地区进行城市级别的定位。在购买前，你可以和服务商的确认哪个地区。</p>]]></description></item><item>    <title><![CDATA[【HarmonyOS 6】SpeechK]]></title>    <link>https://segmentfault.com/a/1190000047400590</link>    <guid>https://segmentfault.com/a/1190000047400590</guid>    <pubDate>2025-11-14 19:03:57</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>【HarmonyOS 6】SpeechKit中的朗读控件，初始化前不进行窗口舞台的设置，也不会报错，与文档描述不符。</h2><h2>一、前言</h2><p>该文为官方文档bug信息同步帖，结尾有bug官方回复。便于大家信息同步。</p><p>前段时间应用升级到HarmonyOS 6，系统提供了很多酷炫的API和功能Kit。对于AI赋能朗读控件，我们在集成后发现了一些问题，由此产生了下面的问题背景。</p><h2>二、问题背景</h2><p>如下图所示，官方文档中强调，朗读控件需要在init前，在EntryAbility中进行如下操作：</p><pre><code class="typescript">    WindowManager.setWindowStage(windowStage);</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400592" alt="在这里插入图片描述" title="在这里插入图片描述"/><br/>但实际上，不进行该操作，直接调用init初始化朗读控件，不会报错，可将以下DEMO源码，可直接新建工程后，贴到index.ets类中，启自动签名后，启动查看效果。</p><pre><code class="typescript">// 导入语音朗读相关的组件和类型
import { TextReader, TextReaderIcon, ReadStateCode } from '@kit.SpeechKit';

@Entry
@Component
struct Index {

  /**
   * 待加载的文章列表
   */
  @State readInfoList: TextReader.ReadInfo[] = [];

  /**
   * 当前选中的文章
   */
  @State selectedReadInfo: TextReader.ReadInfo = this.readInfoList[0];

  /**
   * 朗读状态
   */
  @State readState: ReadStateCode = ReadStateCode.WAITING;

  /**
   * 初始化状态标记
   */
  @State isInit: boolean = false;

  // 组件即将显示时触发
  async aboutToAppear(){
    /**
     * 模拟加载文章数据
     */
    let readInfoList: TextReader.ReadInfo[] = [{
      id: '001',
      title: {
        text:'水调歌头.明月几时有',
        isClickable:true
      },
      author:{
        text:'宋.苏轼',
        isClickable:true
      },
      date: {
        text:'2024/01/01',
        isClickable:false
      },
      bodyInfo: '明月几时有？把酒问青天。不知天上宫阙，今夕是何年？'
    }];

    // 更新状态变量
    this.readInfoList = readInfoList;
    this.selectedReadInfo = this.readInfoList[0];

    // 初始化朗读组件
    this.init();
  }

  /**
   * 初始化朗读组件
   */
  async init() {
    // 朗读参数配置
    const readerParam: TextReader.ReaderParam = {
      isVoiceBrandVisible: true, // 显示品牌信息
      businessBrandInfo: {
        panelName: '小艺朗读', // 面板名称
        panelIcon: $r('app.media.startIcon') // 面板图标
      }
    }

    try {
      // 获取上下文
      let context: Context | undefined = this.getUIContext().getHostContext()
      if (context) {
        // 初始化朗读组件
        await TextReader.init(context, readerParam);
        this.isInit = true; // 标记初始化完成
        this.setActionListener(); // 设置事件监听
      }
    } catch (err) {
      // 初始化失败时打印错误信息
      console.error(`TextReader failed to init. Code: ${err.code}, message: ${err.message}`);
    }
  }

  // 设置朗读事件监听
  setActionListener() {
    // 监听朗读状态变化
    TextReader.on('stateChange', (state: TextReader.ReadState) =&gt; {
      this.onStateChanged(state);
    });

    // 监听加载更多请求
    TextReader.on('requestMore', () =&gt; {
      TextReader.loadMore([], true);
    })
  }

  // 处理朗读状态变化
  onStateChanged = (state: TextReader.ReadState) =&gt; {
    // 只处理当前选中文章的状态变化
    if (this.selectedReadInfo?.id === state.id) {
      this.readState = state.state;
    } else {
      this.readState = ReadStateCode.WAITING;
    }
  }

  // 构建UI界面
  build() {
    Column() {
      // 朗读状态图标
      TextReaderIcon({ readState: this.readState })
        .margin({ right: 20 })
        .width(32)
        .height(32)
        .onClick(async () =&gt; {
          // 点击图标时开始朗读
          try {
            await TextReader.start(this.readInfoList, this.selectedReadInfo?.id);
          } catch (err) {
            // 朗读失败时打印错误信息
            console.error(`TextReader failed to start. Code: ${err.code}, message: ${err.message}`);
          }
        })
    }
    .height('100%')
  }
}</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400593" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h2>三、问题反馈：</h2><p>目前官方文档已更新，setWindowStage，新增设备行为差异说明，在手机设备上，不需要调用该接口，直接初始化朗读朗读控件就可以了。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047400594" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[[大厂实践] 超越极限：利用路由服务器实]]></title>    <link>https://segmentfault.com/a/1190000047400603</link>    <guid>https://segmentfault.com/a/1190000047400603</guid>    <pubDate>2025-11-14 19:03:14</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <blockquote><em>本文介绍了 Zalando 如何通过引入路由服务器（RouteSRV）帮助 Skipper Ingress 应对高速增长的流量，以更有效管理控制平面并确保集群稳定运行的实践。原文：<a href="https://link.segmentfault.com/?enc=NdY0F7tfrhqLDqQbqedbSg%3D%3D.B5xf1FOWHBsurDBNt6NBlsnCAZykPX2ClOGZm2%2BEniJ4CfHqXyAhnsX42rG2AwqdDZnx1wfR7Yz5ishnRLtvs2U4hnHsc%2FD2ORjc1B3t3ouSg7DzUJkVbahFHpfYG%2BE2mXNDPzdqQNtvKdtuuT8iDA2XqCX9J0vCocTRdCxmITc%3D" rel="nofollow" title="Scaling Beyond Limits: Harnessing Route Server for a Stable Cluster" target="_blank">Scaling Beyond Limits: Harnessing Route Server for a Stable Cluster</a></em></blockquote><h2>简介</h2><p>在 Zalando，我们正面临严峻挑战：入口控制器有可能使 Kubernetes 集群不堪重负。我们需要能够应对不断增长的流量并实现高效扩展的解决方案，本文将介绍我们如何实现路由服务器以更有效管理控制平面流量并确保集群稳定运行的实践。</p><h2>Skipper：Ingress 控制器</h2><p>我们用 <a href="https://link.segmentfault.com/?enc=m%2FYotSIcJLCdV08oCP2Lyg%3D%3D.RwqX8SUcGuNnv%2FWcQoY4KRkT4nq%2BEPzevR6hqsWBkWshuEVg7uOECnvivPqMDkQb" rel="nofollow" title="Skipper" target="_blank">Skipper</a>（HTTP 反向代理）来实现 <a href="https://link.segmentfault.com/?enc=qYbGgVzzd0MjaoseNdWsQQ%3D%3D.ru%2FyTbD6S4lDKR35tGSg7Z2lIPONomuHjGnpxCkKOkJ6ePFXRTsYHNW1rRmO1%2BP%2BkW0gCf%2BqZ0RaiTzZpl1MNA%3D%3D" rel="nofollow" title="ubernetes Ingress" target="_blank">ubernetes Ingress</a> 和 <a href="https://link.segmentfault.com/?enc=%2FtzPWScNyxxJgoatCXtrBw%3D%3D.wsx35L1zmhSfHxaZBYne7I8A0nomGmv1TODb3FPPLT2ZstvovcCPjRM8jZy6k0SYrkgyhWbWP4QVMc65wf5FlCptxcjzzhvlXbSXa1VJ4yI%3D" rel="nofollow" title="RouteGroups" target="_blank">RouteGroups</a> 的控制平面和数据平面。创建 <code>Ingress</code> 或 <code>RouteGroup</code> 将会产生<a href="https://link.segmentfault.com/?enc=n8JYKKCMH9byyj3zkmBH9g%3D%3D.T2dy7y2Pg1%2Fad%2FSnPsCIAyAaDEi2d2yCD%2BUuFrULm5uQMRGxGouII11CcuCKREppeS0Mdl4CnRJR5NU5mbS%2BlhfoCbEAhZ0GVrvjPkUHxkF2sBEKB0nP5ocSm6lGEJzG5hxC1V7qnTnteezdM%2BdE%2FKEjg9xmpcecNV4CKlKr1eY%3D" rel="nofollow" title="带有 TLS 终止功能的 AWS LB" target="_blank">带有 TLS 终止功能的 AWS LB</a>，该 LB 会通过 <a href="https://link.segmentfault.com/?enc=fk%2FIOD5mpS65CZMe5E0kKA%3D%3D.yKQl%2BL5oTTIy7mF3alXqlm0avRKROCi%2B7H6EotqMsIo5iM%2FO9IxXATTB34hmSjiQeTTaCdQOdDV18RawAcMcLPtBKZ8KILi78Q1NsLpbea4%3D" rel="nofollow" title="kube-ingress-aws-controller" target="_blank">kube-ingress-aws-controller</a> 与 Skipper 进行通信，同时在 Skipper 上设置 HTTP 路由，并通过 <a href="https://link.segmentfault.com/?enc=ytI3g%2F5sCNIPqDVfENs45A%3D%3D.D5MObgXFUIIXNx9y9B%2Foo4Tqeuve9sV7nWytr86tRgc2R6eCC7YnOVKyCX3AaSOx" rel="nofollow" title="external-dns" target="_blank">external-dns</a> 将 DNS 域名指向该 LB。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400605" alt="" title=""/></p><p>为了理解部署环境，以下是我们的实际运行规模：</p><ul><li>15,000 个 Ingress 和 5,000 个 RouteGroup。</li><li>每秒处理高达 2,000,000 次请求的流量。</li><li>80% - 90% 的流量是经过认证的服务间调用，服务集群每天调用次数在 500,000 到 1,000,000 次。</li><li>共有 200 个 Kubernetes 集群。</li></ul><h2>挑战</h2><h5>扩容的痛点</h5><p>Skipper 实例从 Kubernetes API 获取 Ingress 和 RouteGroups 信息，起初这种方式运行良好。但 Skipper 实例数量迅速增加，达到每个集群约 180 个，开始超出 etcd 基础设施的承载能力。</p><p>这种负载过重导致了严重的 Kubernetes API CPU 限流问题，引发了关键的控制平面稳定性风险。主要表现为两种情况：集群失去了有效调度新 Pod 的能力，而现有 Pod 的管理操作也开始出现故障。这些问题威胁到了 Kubernetes 基础设施的整体稳定性和可靠性。</p><h5>实施路由服务器</h5><p>在引入路由服务器之前，Skipper 的职责包括：</p><ol><li>从 Kubernetes API 获取 Ingress 和 RouteGroups 信息。</li><li>解析并处理这些资源以转换为 <a href="https://link.segmentfault.com/?enc=VV45bAXA3ZETI2X0wZo91g%3D%3D.ihSZ3mriwpH9q1d9wFGkMb3ah9HClE1jPmXb0jop1TQ0Gpqiz9eVy38DaCrI4stKcsRYp9P3I7pL6qWN%2FCrsdN8Yg%2FP9%2F8spjNvJRGSgHrOOZ5lDISmRvUsiqL5kwn0esQ7fmVa7DS3W35sP3FyiWXw30C06b8SN7mScjmSPFKE%3D" rel="nofollow" title="Eskip" target="_blank">Eskip</a> 格式。</li><li>验证生成的 Eskip 格式。</li><li>更新路由表。</li></ol><p>我们引入<a href="https://link.segmentfault.com/?enc=qmCvJi1HUaoNv1EDZCu%2Fkw%3D%3D.Uh046qWLaBMsGeo%2FM1Qm6pGMtWYiIdpd4cvLpeCbXOlS3zSDGV75rmMGBZ6Oztwxt1VTi%2BasARVyTex%2BhgrdYQ%3D%3D" rel="nofollow" title="路由服务器" target="_blank">路由服务器</a>作为自定义代理层，以更高效处理控制平面流量，并在 Skipper 与 Kubernetes API 服务器之间充当带有 <a href="https://link.segmentfault.com/?enc=EMwzq5E8Cm3909m8B%2BL2LA%3D%3D.2%2F7mHDLejhryvnuLw6THSKBBn5PTmaQO8Gw2Q9IMbBsKn9j%2FWOHzSLxXCEFGEtkwv4QQ9j9MFdG8%2FVUcwQDPkg%3D%3D" rel="nofollow" title="HTTP ETag 缓存层" target="_blank">HTTP ETag 缓存层</a>的代理。</p><p>现在，路由服务器负责执行轮询和解析操作，减少了 Skipper 的计算负担，同时实现了清晰的职责划分。</p><h5>缓存层</h5><p>路由服务器每隔 3 秒向 Kubernetes API 发送一次请求，以获取最新的 <code>Ingress</code> 和 <code>RouteGroup</code>。然后生成路由表以及相应的 ETag 值。当 Skipper 向路由服务器请求更新时，会包含自己当前的 ETag。如果这个 ETag 与路由服务器当前的 ETag 相匹配，表示没有变化，路由服务器会以 <a href="https://link.segmentfault.com/?enc=zLhhE2A5wwFZfsCgTw87Xg%3D%3D.YkQ2wR0o6a5B4d%2FY2PfV2TMQvTgT6WgGFAm9v5tYjQ5QnhM4tyU6IIyOq9wqFQK39X%2BC3nKjzh7%2BVKN3QYelCg%3D%3D" rel="nofollow" title="HTTP 304 (Not Modified" target="_blank">HTTP 304 (Not Modified) 状态码</a> 状态码")进行响应。然而，如果 ETag 不同，路由服务器会将更新后的路由表发送给 Skipper，然后 Skipper 会更新其本地配置以及 ETag。</p><h5>路由服务器不可用</h5><p>尽管路由服务器极大提高了系统效率，但也必须考虑到可能出现的故障情况。当路由服务器不可用时，有以下两种可能的情况：</p><ol><li>Skipper 没有初始路由表。</li><li>Skipper 有初始路由表，但路由服务器无法更新。</li></ol><p>在第一种情况下，如果启用了 <a href="https://link.segmentfault.com/?enc=bVYxEh4M9U46pWBzRP0Uuw%3D%3D.NjT%2BmF7yUVGrT4ywH6krmdhwqUCG%2FtikRT%2FaMaL9y%2Bk1JyH41qrC3YKFR%2BegOhDH8FsGCMS%2BEU5PMLcMbtGj1cTS4N%2FJ%2BwTvsdPssCHiaDmpIT%2F5zQP6sHX%2BmJwRA6U1idri8higNQdp%2BLK%2BAOn5CuLHFY2i6hLZfoLsaYP0mJkOIK4BvGMq1wRMNSYyiaJYOsjZkPgDZK%2BaBgud17nyCw%3D%3D" rel="nofollow" title="&lt;code target=" _blank="">-wait-first-route-load 标志"&gt;<code>-wait-first-route-load</code> 标志</a>，那么 Skipper 容器将无法启动。在第二种情况下，Skipper 将继续使用最后已知的路由表。这是在可用性和一致性之间做出的权衡。</p><p>在这两种情况下，我们都会收到告警，并且需要决定是修复路由服务器，还是将其禁用，然后让 Skipper 在没有路由服务器的情况下继续运行。目前，我们还没有自动切回旧方法的机制。</p><p>集成路由服务器后的最终流程如下：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400606" alt="" title="" loading="lazy"/></p><h2>部署策略</h2><p>部署路由服务器并非易事，哪怕出现一个错误，也可能导致 Kubernetes API 与 Skipper 的连接中断，从而可能影响销售业绩和商品交易总额（GMV）。我们必须极其谨慎，并遵循完善的部署策略。</p><p>我们计划以可控的方式逐步部署路由服务器，先从测试集群开始，生产集群则被分为不同的层级，路由服务器逐层部署，每部署完一层都会进行监控，然后再进行下一层部署。</p><p>为了实现这一目标，我们为部署路由服务器制定了不同的设置模式：</p><ul><li><strong>模式：False</strong> - 禁用模式</li><li><strong>模式：Pre</strong> - 预处理模式</li><li><strong>模式：Exec</strong> - 执行模式</li></ul><p>这些模式通过<a href="https://link.segmentfault.com/?enc=paCjpxgRGogkwuC0jI4E1w%3D%3D.v%2ForDPpT1Aq%2FBZtNmtSdCTCC86eJQLGb1ygEipBkPFnOC5DDkIa%2BONJOPluBEC96T1Ei8Ds2VdwfDhN6DQ%2FzMYOW5ouDXOqyEAgW7VtQrHOikk80EVkNQ1ko%2FgtRYGaZqFlUveZ%2Bx6cuGct4tYcg2l8AQbeLiB9Lo4pIJXCyF%2BRWbRUbcFFxI7FBnzXL7kKk" rel="nofollow" title="配置项" target="_blank">配置项</a>进行控制。</p><p>默认模式为 <code>false</code>，意味着路由服务器已被禁用，此时就用常规的控制平面流量。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400607" alt="" title="" loading="lazy"/></p><h5>预处理模式</h5><p>在该模式下，路由服务器与 Skipper 协同工作，从 Kubernetes API 获取 <code>Ingress</code> 和 <code>RouteGroup</code>，并对其进行预处理。此模式适用于测试和调试，也是我们推出策略的关键因素。</p><p>通过成功获取 Skipper 和路由服务器的路由表，并将其与原表进行对比，以确保路由服务器运行正常。要知道，如果路由表因为某种原因出现故障，就会导致服务中断。这就是为什么必须格外谨慎，检查所有集群中路由表的任何细微差异。</p><pre><code># 用非常大的 limit 获取所有 Skipper 路由
➜ curl -i http://127.0.0.1:9911/routes\?limit\=10000000000000\&amp;nopretty &gt; skipper_routes.eskip
# 获取路由服务器的所有路由，我们决定不使用分页来减少请求数量，Skipper 是目前唯一的消费者
➜ curl -i http://127.0.0.1:9090/routes &gt; routesrv_routes.eskip
➜ git diff --no-index -- skipper_routes.eskip routesrv_routes.eskip</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400608" alt="" title="" loading="lazy"/></p><h5>执行模式</h5><p>在该模式下，路由服务器充当 Skipper 与 Kubernetes API 之间的代理。Skipper 向路由服务器发送请求，然后路由服务器再将这些请求转发至 Kubernetes API。路由服务器会缓存响应并将其返回给 Skipper。此模式是用于生产环境的最终设置。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400609" alt="" title="" loading="lazy"/></p><h2>产品上线</h2><p>经过全面的负载测试后，我们以可控的方式将路由服务器投入生产使用：</p><ol><li>已分发至所有测试集群，并进行了为期两周的监测。</li><li>逐层部署到生产集群，每部署一层都会对其进行监测，然后继续进行下一层部署。</li></ol><h2>替代方案</h2><p>我们曾考虑使用 <a href="https://link.segmentfault.com/?enc=8gqm%2BueKbKMsexwK9RgKWA%3D%3D.o92ZjiC%2FK1wxZPzR9Z9HU0VVyJcxDDfN5AGxCTFdMXP7RYNrZTRbCyCG4MG9PPGg" rel="nofollow" title="Kubernetes Informer" target="_blank">Kubernetes Informer</a> 来监视 Kubernetes API 的变化。然而，这种方法仍需要 Kubernetes API 向所有 Skipper 实例发送信息，可能会导致遇到的同样的问题。因为问题的本质是流量突然增加，而 HPA 无法跟上并扩展 Kubernetes API 和 etcd。</p><h2>未来改进措施</h2><ul><li><strong>自动回退机制</strong>：建立回退机制，以确保在路由服务器不可用的情况下，Skipper 仍能继续运行。</li></ul><h2>总结</h2><ul><li>在上线过程中实现了零停机时间且未出现商品交易总额（GMV）损失的情况。</li><li>将 Skipper HPA 扩展至 300 个 Pod。</li><li>单个路由服务器能够处理高达 100 个每秒请求数（RPS），相当于约 300 个 Skipper Pod，且没有任何问题。</li><li>路由服务器现已成为平台核心组件。</li></ul><hr/><blockquote>你好，我是俞凡，在Motorola做过研发，现在在Mavenir做技术工作，对通信、网络、后端架构、云原生、DevOps、CICD、区块链、AI等技术始终保持着浓厚的兴趣，平时喜欢阅读、思考，相信持续学习、终身成长，欢迎一起交流学习。为了方便大家以后能第一时间看到文章，请朋友们关注公众号"DeepNoMind"，并设个星标吧，如果能一键三连(转发、点赞、在看)，则能给我带来更多的支持和动力，激励我持续写下去，和大家共同成长进步！</blockquote><p>本文由<a href="https://link.segmentfault.com/?enc=jeii%2Fg3WkW2HWvDbUocAkA%3D%3D.7GbvfVKKFf9UgPllj%2Bhd3tkQOkImDtzYx2sl0fST8Ms%3D" rel="nofollow" target="_blank">mdnice</a>多平台发布</p>]]></description></item><item>    <title><![CDATA[antd 上传文件组件在表单回显时不显示]]></title>    <link>https://segmentfault.com/a/1190000047400629</link>    <guid>https://segmentfault.com/a/1190000047400629</guid>    <pubDate>2025-11-14 19:02:13</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>之前需求方提出说想要给表单上传的文件增加预览功能，原来点击展示列表中的文件时，docx文件会启动下载，而pdf会启动新的tab页进入预览，所以最好是统一处理。</p><p>因为我对Upload组件用的不多，对它不够了解，所以一开始我想着从fileList下手，不用Upload默认的展示列表，经过多番尝试发现有点麻烦，于是打开官网文档研究，才发现原来文档里已经提供了相关的功能，原来点击文件的展示列表默认的动作是文档里的<code>onPreview</code>回调，要区分预览和下载的入口，可以增加<code>showDownloadIcon</code>的配置，并增加<code>onDownload</code>的回调用于处理文件的下载，那么预览和下载的处理就可以区分开来。</p><p><img width="723" height="63" referrerpolicy="no-referrer" src="/img/bVdm3dU" alt="" title=""/></p><p>但是问题到这里并没有完全解决，当我重新进入表单页面进入编辑时，也就是表单内容回显时，发现没有出现下载按钮，查了很久的文档都没有找到怎么解决，也在网上搜索了一下，不知道是不是我搜索的关键词不对，就是没找到答案，就只能自己翻项目里的依赖包，各种尝试，才发现原来文件列表中的文件需要同时设置<code>status</code>为<code>'done'</code>，下载的按钮才会显示。</p><p>所以表单内容回显的时候，需要单独给上传的文件列表进行处理，因为我这边接口没有存status的值，又因为文件上传成功后，才会被表单整体提交保存，文件的状态可以默认为done，所以在加载表单内容时，直接给文件列表处理成如下结构就可以。</p><pre><code class="json">[
    { url, name, status: 'done' }
]</code></pre>]]></description></item><item>    <title><![CDATA[uniapp微信小程序分包以及分包优化 ]]></title>    <link>https://segmentfault.com/a/1190000047400647</link>    <guid>https://segmentfault.com/a/1190000047400647</guid>    <pubDate>2025-11-14 19:01:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>分包限制说明</h2><p>微信小程序上传项目时会有分包大小限制，官方文档介绍：<br/>目前小程序分包大小有以下限制：</p><ul><li>整个小程序所有分包大小不超过 30M（服务商代开发的小程序不超过 20M）</li><li>单个分包/主包大小不能超过 2M</li></ul><p>主包就是<code>Tabbar</code>页面，所有的<code>Tabbar</code>页面加起来的文件大小不能超过<code>2M</code><br/>在小程序启动时，默认会下载主包并启动主包内页面，当用户进入分包内某个页面时，客户端会把对应分包下载下来，下载完成后再进行展示。<br/><img width="534" height="516" referrerpolicy="no-referrer" src="/img/bVdm3ez" alt="" title=""/><br/>你可以在这里查看当前项目的分包大小和依赖分析<br/><img width="723" height="401" referrerpolicy="no-referrer" src="/img/bVdm3eA" alt="" title="" loading="lazy"/></p><h2>uniapp分包</h2><p><code>pages.json</code>文件中</p><ul><li>pages 主包</li><li>subPackages 子包</li></ul><p>在<code>uniapp</code>的<code>pages.json</code>文件中，<code>pages</code>存储的是主包，一般我们的<code>Tabbar</code>页面都会写在<code>pages</code>里<br/>另外，根目录除了你配置的子包，都算在主包内，比如：</p><ul><li>components</li><li>static</li><li>uni_modules</li><li>utils</li><li>...</li></ul><p>所以我们在引入第三方组件、公共方法、静态资源时需要注意主包占用空间<br/>下面是一个分包的示例：<br/><img width="590" height="214" referrerpolicy="no-referrer" src="/img/bVdm3eB" alt="" title="" loading="lazy"/></p><pre><code>{
    "pages": [ //pages数组中第一项表示应用启动页，参考：https://uniapp.dcloud.io/collocation/pages
        {
            "path": "pages/home/index",
            "style": {
                "navigationBarTitleText": "首页",
                "navigationStyle": "custom", // 隐藏系统导航栏
                "navigationBarTextStyle": "white" // 状态栏字体为白色，只能为 white-白色，black-黑色 二选一
            }
        }
    ],
    "subPackages": [
        {
            "root": "subPackages/login", // 子包的根目录
            "pages": [
                {
                    "path": "pages/login/index",
                    "style": {
                        "navigationBarTitleText": "",
                        "navigationStyle": "custom",
                        "navigationBarBackgroundColor": "#ffffff"
                    }
                }
            ]
        },
        {
            "root": "subPackages/setting", // 子包的根目录
            "pages": [
                {
                    "path": "pages/system/index",
                    "style": {
                        "navigationBarTitleText": "设置",
                        "navigationBarTextStyle": "black",
                        "navigationBarBackgroundColor": "#F3F3F3"
                    }
                },
                {
                    "path": "pages/user/index",
                    "style": {
                        "navigationBarTitleText": "用户设置",
                        "navigationBarTextStyle": "black",
                        "navigationBarBackgroundColor": "#F3F3F3"
                    }
                }
            ]
        }
    ]
}</code></pre><p>结构如下：</p><pre><code>Project
├─ subPackages
│  ├─ setting
│  │  └─ pages
│  │     ├─ user
│  │     │  └─ index.vue
│  │     └─ system
│  │        └─ index.vue
│  └─ login
│     └─ pages
│        └─ login
│           └─ index.vue
└─ pages
   └─ home
      └─ index.vue</code></pre><p><code>Project</code>为你的项目文件夹，其中<code>pages</code>为主包，而<code>subPackages</code>为子包<br/><code>subPackages</code>内有两个子包，分别是<code>setting</code>、<code>login</code><br/>按照官方的说法，子包其实可以跟<code>pages</code>同级，你只需要在<code>subPackages</code>配置的<code>root</code>里配置好路径即可，我在这里将所有子包都写在<code>subPackages</code>文件夹内，方便统一管理<br/>之后你正常写页面即可，主包和子包已经分好了，<code>Tabbar</code>的页面就写在<code>pages</code>里，非<code>Tabbar</code>页面就写在<code>subPackages</code>内。</p><p><strong>页面跳转</strong><br/>跳子包</p><pre><code>uni.navigateTo({
  url: '/subPackages/setting/pages/user/index'
});</code></pre><p>跳主包</p><pre><code>uni.navigateTo({
  url: '/pages/home/index'
});</code></pre><p>页面跳转没有什么区别，正常跳就好了</p><h2>分包优化</h2><h3>uniapp配置manifest.json启用分包优化</h3><p><img width="723" height="161" referrerpolicy="no-referrer" src="/img/bVdm3eC" alt="" title="" loading="lazy"/><br/><code>manifest.json</code>内配置</p><pre><code>"mp-weixin": {
 
   "optimization":{"subPackages":true}
 
}</code></pre><h3>分包预加载配置</h3><p>目的：当我们进到某个页面时，有些子包访问概率很大，可以预先加载子包资源，提升进入后续分包页面时的启动速度<br/><code>preloadRule</code>中，<code>key</code>是页面路径，<code>value</code>是进入此页面的预下载配置，每个配置有以下几项：<br/><img width="723" height="112" referrerpolicy="no-referrer" src="/img/bVdm3eD" alt="" title="" loading="lazy"/><br/>假如，你进入登录页后，需要预先加载<code>subPackages/setting</code>子包，配置如下：<br/><strong>pages.json</strong></p><pre><code>    "preloadRule": {
        "subPackages/login/pages/login/index": { // 指定页面
            "network": "all", //指定网络 all 不限网络   wifi：仅wifi
            "packages": ["subPackages/setting"] // 进入指定页面后需要加载的分包 root 或 name
        }
    },</code></pre><p><img width="302" height="71" referrerpolicy="no-referrer" src="/img/bVdm3eE" alt="" title="" loading="lazy"/><br/>当你进入指定页面后，比如登录页，控制台打印<code>preloadSubpackages: success</code>则说明分包预加载成功了。</p><h3>节省uni_modules的体积占用</h3><p>有时候我们在插件市场下载的组件只在某个子包内使用，此时可以直接将<code>uni_modules</code>移到子包内，这样可以减少主包的体积<br/><img width="287" height="141" referrerpolicy="no-referrer" src="/img/bVdm3eG" alt="" title="" loading="lazy"/><br/>像这样，直接移到子包的根目录，你在对应页面使用的时候需要按照路径引入</p><pre><code>&lt;template&gt;
  &lt;view&gt;
    &lt;KevyEmpty/&gt;
  &lt;/view&gt;
&lt;/template&gt;

&lt;script setup&gt;
import KevyEmpty from '@/subPackages/setting/uni_modules/kevy-empty/components/kevy-empty/kevy-empty.vue';
&lt;/script&gt;</code></pre><hr/><p>参考文档：<br/><a href="https://link.segmentfault.com/?enc=3vaha0KcdOvAK%2F5cKPn6TQ%3D%3D.FJYSSFl86VI%2FzrXQUm5UdBsO3avPfQRQCK%2Bjc%2BGJzMDyMN7XYfTx2KO27B3nt08CGNyp3ZDPOZjjTlK%2F5vVpYJ%2BAaK7ErGlC7aY8VZyS%2FKw%3D" rel="nofollow" target="_blank">分包加载</a><br/><a href="https://link.segmentfault.com/?enc=2EqYGFIAHQcgB3AQR155Mg%3D%3D.r2%2BkhYDRnimsrx2jX%2Bb99%2B4doh6xNiK438qWywsYTQdfvdwJ94H92rTqpF59h%2B4lNHTxMHQ1Yad2dytriXzFv5LM5pE9O9SlmH95i8cTILvFZeKgI4dgMMRB0qhjdr8nhATP%2FFCYUNSIWFHUN0bJ98UPe1T0otJHthO7Z84X7gZBdLYPVo5ONEoq2sKfNl7b" rel="nofollow" target="_blank">关于分包优化的说明</a><br/><a href="https://link.segmentfault.com/?enc=eFOLwUfBlWsGZbLNiXxanQ%3D%3D.IvWa08cmFwfvzWsjHveSJSVcwCDNVdKcfCXmZ1%2FfMnfe0qm62rBHRagivF5Xz4SvG3Dofr%2Fv%2F%2B80JVAV9g%2BHkg%3D%3D" rel="nofollow" target="_blank">preloadRule分包预加载</a></p>]]></description></item><item>    <title><![CDATA[每个产品经理都要知道的 6 个软技能 俞]]></title>    <link>https://segmentfault.com/a/1190000047400439</link>    <guid>https://segmentfault.com/a/1190000047400439</guid>    <pubDate>2025-11-14 18:06:19</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <blockquote><em>本文总结了产品经理在工作中需要具备的六项最重要的软技能：沟通、非权威型领导力、说服、优先级排序、授权、问题解决能力，并提到了若干其他重要的软技能。原文：<a href="https://link.segmentfault.com/?enc=8w56shYAZY9bJKczOmw0oA%3D%3D.JLbVlmk3knG2nS3EsTS7%2BauAdpX%2FGTPhbqAWi9BmvtauCVZp4kf6R2p5BEsGQAaEJeIvwTH2oNviDICQrVUEe59w90%2BUM6S9Yq1nGGGsmqxCpUJd93qaHQ1iZfvctR32" rel="nofollow" title="6 Soft Skills Every Product Manager Needs" target="_blank">6 Soft Skills Every Product Manager Needs</a></em></blockquote><p>产品经理的最终职责是推出对目标市场真正有用的产品。要实现这一目标，需要多样化的技能组合，将产品经理的软技能和硬技能结合起来。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400441" alt="" title=""/></p><p>你可能存在这样的误解，即认为硬技能比其他任何技能都更为重要。没错，商业知识、数据分析以及其他可学习的技能都是有用的。但是，产品经理所具备的软技能才能帮你发展职业生涯、领导团队，并在组织中获得一定的影响力，从而被视为产品或市场方面的专家。</p><p>如果 PM 想要获得他人的认可和尊重，那么首先就应该在已有的工程和技术技能基础上，提升自身的软技能。</p><h2>为什么软技能在产品管理中如此重要？</h2><p>当你刚开始担任产品经理时，会更多专注于执行与产品相关的任务（基层执行和产品上线），包括完成质量检查、与市场营销部门合作、进行 A/B 测试、收集客户数据、进行市场调研等等。</p><p>当你晋升为高级产品经理或产品负责人时，工作重点将从执行转向影响力方面，会与同事建立更紧密的工作关系。尽管执行仍是职责的一部分，但你正朝着领导角色、团队成员的职业发展以及说服不同团队支持你所做出的决策方面迈出更多步伐。</p><p>当你获得更高职位，并晋升为集团项目经理、产品负责人或首席产品官等领导岗位时，与人建立关系以及与他人合作就变得愈发重要。在领导层中担任 PM 一职的人员，需要能够领导团队、赋予他人权力、做出重要的产品决策，并在整个组织内清晰的进行沟通，这些任务都需要提升软技能。</p><h2>最重要的产品经理软技能</h2><p>我们总结了每位产品经理都应掌握的六项最重要的软技能，这些关键的产品经理软技能将帮助你成为受团队尊重的顶尖领导者：</p><h5>1. 沟通</h5><p>有效沟通是所有优秀产品经理的基石，因为没有沟通就无法完成任何工作。</p><p>一款产品要想从一个想法转变为完整的实现，需要有效沟通作为支撑。作为产品经理，沟通将成为每一天每一刻的工作内容。从与高层管理人员沟通，到与用户沟通，PM 要负责向合适的群体传达正确的信息。</p><p>在向直接或间接参与产品开发过程的其他人交流或传达想法时，沟通也至关重要。例如，PM 需要将工程师提出的复杂想法以用户能够理解并产生共鸣的方式呈现出来，还需要知道如何与利益相关者进行沟通，并清晰的将他们的想法传达给产品团队。</p><p>任何沟通链条的中断都会导致产生出完全不符合预期的产品。而有了有效沟通，PM 就能倾听与他们互动的人员的意见，并以清晰的方式将这些想法传达给其他人。总的来说，PM 是所有人之间的纽带，同时也是信息的传递者。</p><p><strong>如何提升沟通能力</strong></p><p>关于沟通，首先要强调的一点是，必须先倾听。因为人们希望知道自己的话语被听到了，尤其是在产品管理方面。当你有目的、有意识的倾听时，人们就会知道他们的想法正在被考虑，即便你并不能百分百表示赞同。</p><h5>2. 非权威型领导</h5><p>要组建一支高效的团队，产品经理需要在产品线的每个部门赢得尊重和信任。信任和尊重能够帮助 PM 在做出和论证产品决策时发挥其影响力。</p><p>与外界可能的看法相反，PM 的权力其实很小，他们需要充分利用现有资源来开展工作。在产品团队中，没有成员直接向 PM 汇报工作，工程师直接向工程经理汇报，设计师也是如此，直接向设计经理汇报。</p><p>PM 所做的就是不凭借权威来领导，而是凭借影响力来引领。PM 会说服所有人确定最佳决策是什么，并同时提供证据来支持这一决策。如果 PM 无法为某一举措提供证据，就会导致人们对其领导能力和决策的合法性产生怀疑。</p><p>这种领导方式也可以被称为非权威型领导方式，这意味着交流并非是下达命令，而是一种建议。当 PM 们与团队成员进行这种交流，而不是明确指示他们以某种方式行事，通常会带来员工工作效率的大幅提升以及更高的认同感。</p><p>这种生产力的提升源于领导者也是团队的一员。领导意味着合作，意味着要与团队并肩作战，参与到产品开发的每一个环节中。这是你能够了解每个角色的实际情况，并掌握与每个人合作的最佳方式的唯一途径。</p><p><strong>如何在工作中提升影响力？</strong></p><p>首先，必须与组织目标保持一致。一旦 PM 理解了目标的意义所在，那么支持和倡导这个目标就会变得容易得多。高层管理人员也会因此而对你表示赞赏。</p><p>对于你的团队，必须支持他们所做的工作，尤其是在促进他们职业发展方面。当他们就公司内部的运作方式提出意见时，要作为他们的代言人向高层管理人员汇报。</p><h5>3. 说服</h5><p>说服他人就是要寻求双方的共同点，做出妥协，并帮助对方从而让对方也能帮助你。换句话说，就是“我帮你一下，你也得帮我一下”。</p><p>将一款产品推向用户的过程可能会十分漫长，其间会遇到无数阻碍。PM 的软技能中需要包含说服力，以便能够克服或绕过这些障碍。</p><p>说服工作不仅仅意味着与零售商达成一项重大商业交易，让他们销售你的产品。还意味着要敢于面对可能对基层员工要求过高的高层管理人员。这意味着当基层员工不理解时，要为高层管理人员发声，寻找中间立场，成为理性的代表，这应该是任何 PM 的首要任务。</p><p>然而，需要记住的是，掌握这项技能需要一定时间，还需要拥有丰富的经验才能培养出这种能力。不过，任何擅长说服的 PM 都能成功推出出色的产品。</p><p><strong>增强说服力</strong></p><p>关于说服力，最重要的一点在于说话者的可信度。就我个人而言，一旦在团队和组织内部建立起可信度，那么说服他们去做某事就将毫无困难。</p><p>还必须记住的另一个重要方面是“互惠原则”。当队友或组织中的任何成员提供了帮助时，你也必须以某种方式回报这份恩情。如果不是以提供帮助的形式，那么也必须分享你所知晓的机会。</p><h5>4. 优先级</h5><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400442" alt="" title="" loading="lazy"/></p><p>如果 PM 不懂得如何合理安排与项目计划和待办列表相关的事务，那么很快就会发现工作进度停滞不前 —— 而在时间紧迫的情况下，这种情况是绝对不能发生的。</p><p>要使成功推出一款产品，需要完成的任务数量可能极其庞大。在此情况下，产品管理意味着时间管理，即要对任务进行优先级排序，以确保都能按时完成。这不仅需要你按时完成所有任务，还需要工程师和设计师也遵循同样的时间安排来工作。</p><p>你还会发现，各种想法会从各个方向涌来。其中一些想法可能看起来像是某个问题的完美解决方案，或者是某个产品的重要改进之处。但确定优先次序意味着要明白什么样的东西是完美产品所不可或缺的，而不是那些无关紧要的设计元素。</p><p>关于优先级排序，应该了解的最重要一点是，往往意味着需要学会拒绝。可能是拒绝那些与愿景不符的想法，也可能是拒绝自己某些不想做出牺牲的事项。学会说“不”最终会赋予你力量并带来成效。</p><p>采用诸如看板或价值与复杂性四象限（Value vs Complexity Quadrants）等特定的优先级排序框架，有助于 PM 真正优化其时间安排。这些框架设计简单，旨在为每个工作场所带来成功。</p><h5>5. 授权</h5><p>作为 PM，往往会觉得自己需要完成每一项任务。虽然完成工作是你的职责所在，但并非所有任务都得由你独自完成。放弃这种控制权会很困难，尤其是当你肩负着带领团队并交付出色产品的巨大压力时。不过，将任务授权给他人会让团队变得高效且富有成效。</p><p>授权意味着需要了解团队中每个人的优势所在。这样一来，就能确定哪些任务适合哪个团队成员。这会营造出高效的工作环境，让每个人都能发挥自己的最佳水平。没有 PM 能做到面面俱到，但最优秀的 PM 会清楚知道谁最适合完成特定的任务。</p><p>事实上，授权能让领导人的工作变得极其简单。一旦确定了应该把哪些任务分配给哪些人的原则，那么这些任务就会从你的工作清单中移除。这样一来，就减轻了自己的负担，并且知道这项工作正由有能力完成最佳成果的人来负责。而你只需要学会放手。</p><h5>6. 问题解决与创造力</h5><p>问题往往是 PM 日常工作中最为关键的部分。因此，我们将问题解决能力和创造力视为 PM 必备的软技能之一。</p><p>当出现问题时，高层管理人员会期望 PM 去解决这些问题，而那些在 PM 手下工作的人员则会向 PM 寻求答案。并非每一个问题的解决方案都一目了然，要解决出现的所有问题，需要有大量创造力。</p><p>解决问题意味着要从多个不同角度去审视问题。通过综合考虑多种观点，PM 能够从不同角度看到解决某个问题的不同方法。这种共情和换位思考的方式已经解决了许多重大全球性问题，而且肯定也能解决生产中的小问题。</p><h2>其他产品经理应具备的软技能</h2><h5>保持团队热情的能力</h5><p>没错，保持团队积极性也是 PM 的另一项默默的职责。当团队成员积极性高涨时，工作效率也很可能会提高。但是，PM 如何让团队成员保持积极性呢？并不需要是一次性的大型举措，而是在日常的小时刻、一天天的积累中进行。例如，在产品团队内部，可以尝试：</p><ul><li>进行坦诚交流</li><li>为队友设定目标</li><li>认可每位成员的贡献</li><li>成为团队代言人</li><li>促进团队合作</li></ul><h5>同理心</h5><p>同理心指的是理解并分享他人感受的能力。在产品管理领域，这种技能会非常有用，因为同理心能让 PM 更轻松的与他人合作。</p><p>具备同理心能够帮你理解客户、产品团队以及利益相关者。当你理解了产品开发过程中所有参与者的观点时，就能在决策中找到平衡点，并解释为何选择这种平衡方案。</p><p><strong>培养同理心的技巧</strong></p><ul><li>培养好奇心（尤其是对与你共事的人保持好奇心）</li><li>走出舒适区</li><li>以建设性的方式接受反馈</li><li>尝试设身处地为他人着想</li><li>参加公司组织的社区活动</li></ul><h5>主动作为</h5><p>主动作为指的是独立评估并采取行动的能力。PM 一天大部分时间都会被会议占据，可以说，当 PM 主动发起并引导会议（即使是偶然的或未计划的）时，他/她就是在主动作为。</p><p>PM 还需要审查诸如健康指标或竞争对手评估之类的各种报告，一位优秀的 PM 会主动去做这些事情，而且还会做得比这更多，不会因为有人要求才去做。</p><p><strong>作为 PM，为什么要主动作为呢？</strong></p><p>简单来说，主动作为就是让公司看到你的价值所在。当你主动作为时，不仅会完成本职工作，还会承担一些并非作为 PM 所必须承担的任务。这可能看起来像是额外的工作量，但你必须转变思维模式，因为当你主动作为时，就是在为自己创造成长机会。</p><h5>灵活/适应性强</h5><p>许多经验丰富的 PM 都会告诉你，这类工作非常具有动态性。这意味着情况可能会非常多变、出乎意料且节奏很快。即便现在，如果你不能明确认识到 PM 每天其实并没有严格固定的日程安排，而且任何事情都有可能发生，那么可能会发现自己总是处于极度紧张的状态，以至于无法正常完成工作。</p><p>杰出的 PM 懂得如何应对各种情况。他们早已预料到会有意想不到的情况出现，知道如何处理每一个情况，尽管有些情况可能颇具挑战性，但最出色的 PM 总会挺身而出，承担起责任。</p><p><strong>如何提高适应能力和灵活性</strong></p><ol><li>改变思维模式</li></ol><p>当处境发生变化时，必须接受自己也应该随之改变。摒弃那种一味按原计划行事的心态，要学会灵活应对，欣然接受变化。</p><ol start="2"><li>边学边做</li></ol><p>培养自己具备适应能力的一种方法就是不断学习。要乐于学习新技术、从糟糕的状况中汲取教训、关注市场最新趋势等等。</p><ol start="3"><li>鼓励他人保持开放的心态</li></ol><p>作为 PM，还必须帮助他人培养开放的心态和适应能力。在开发产品的过程中，每个人都会需要这种技能，所以不妨鼓励并教导他人如何适应不断变化的环境，尽可能给予支持。</p><h2>总结</h2><p>作为产品经理，依靠硬技能可能是最容易做到的事情。你可以是一位精通产品管理技术细节的产品经理，但实际上，最成功的产品经理会将硬技能与软技能相结合，以构建高效且富有成效的体系。</p><p>当硬技能无法解决某个问题时，软技能就会发挥作用。而且在你从事工作中的不同方面时，这两种技能会协同工作，相辅相成。</p><p>最终，正是技能的综合运用，造就了品质更高的产品，并且拥有更广泛的用户群体。沟通、非权威型领导、谈判、优先级排序、问题解决等等，都将成为 PM 工具包中的完美补充。</p><p>要满怀自信的坚信自己已经具备了所需能力。成为最核心且表现卓越的产品经理这一目标就在眼前，你也清楚自己需要做些什么。走出去，在日常工作中运用这些 PM 所需的软技能，然后会看到一切都会变得越来越好。</p><h2>FAQ</h2><h5>产品经理需要具备哪四项关键技能？</h5><p>产品经理最核心的四项技能是同理心、沟通能力、倾听能力和组织能力。当然，要做好这份工作还需要其他技能，但上述这四项必不可少，是 PM 应具备的最低要求。</p><h5>成为一名产品经理需要具备哪些技能？</h5><p>作为 PM，主要会与人打交道。从这个角度来看，单一技能是不够的。而所具有的人际交往能力的综合表现，才会在与其他团队、客户和利益相关者打交道时发挥作用。</p><h5>作为产品经理，最出色的三项特质是什么？</h5><p>要胜任产品经理这一职位，必须具备战略思维能力，对产品充满热情，并致力于为用户提供卓越的体验。然而，对于每位 PM 而言，所具备的特质可能会有所不同，但这里列出的三项特质是 PM 能够以此为基础发展成为优秀产品管理者的基石。</p><h5>产品经理是否需要具备编程技能？</h5><p>不，编程技能并非 PM 的必备技能，但这种技能肯定会派上用场，尤其是当 PM 负责技术产品，并且需要与工程团队进行有效沟通和协作时。不过，这并非是必须具备的先决条件。</p><h5>产品管理是一种软技能吗？</h5><p>产品管理更像是硬技能和软技能的结合体。比如，具备编写技术规格说明或使用产品管理工具的硬技能，在工作中可能会有用，但这只是其中一方面。PM 还需要处理产品管理中的人性方面的问题。这就是软技能发挥作用的地方，因为参加会议、与不同部门团队沟通以及向客户了解他们的需求都是常态。</p><hr/><blockquote>你好，我是俞凡，在Motorola做过研发，现在在Mavenir做技术工作，对通信、网络、后端架构、云原生、DevOps、CICD、区块链、AI等技术始终保持着浓厚的兴趣，平时喜欢阅读、思考，相信持续学习、终身成长，欢迎一起交流学习。为了方便大家以后能第一时间看到文章，请朋友们关注公众号"DeepNoMind"，并设个星标吧，如果能一键三连(转发、点赞、在看)，则能给我带来更多的支持和动力，激励我持续写下去，和大家共同成长进步！</blockquote><p>本文由<a href="https://link.segmentfault.com/?enc=hTmBjWVTHh%2FH7%2FWN2D38vQ%3D%3D.fUCxMKgLzi45%2FJB2mMZBo9s%2Bw0WhJwxSmjsCAWuKWBU%3D" rel="nofollow" target="_blank">mdnice</a>多平台发布</p>]]></description></item><item>    <title><![CDATA[使用 C# 导出 Excel 数据并保存]]></title>    <link>https://segmentfault.com/a/1190000047400472</link>    <guid>https://segmentfault.com/a/1190000047400472</guid>    <pubDate>2025-11-14 18:05:47</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在现代企业信息化管理中，Excel 已经成为最常用的数据存储和分析工具。从员工信息表、销售数据报表到财务分析表，几乎所有部门都离不开 Excel。然而，在实际业务中，我们往往需要将系统中的数据动态生成 Excel 文件，而不是手动录入。手动操作不仅效率低，而且容易出错，对于需要批量生成报表、进行定期统计或对外发布数据的场景尤其不适用。</p><p>为了解决这一问题，C# 开发者可以借助 <strong><a href="https://link.segmentfault.com/?enc=gZPlS5ikQ%2BFrHUdPRfHE1w%3D%3D.udeoSKuoZOTBTSSvCoMaeh1Lbjq%2Bpp9vX8Wj7W2UClSKfxRWxmZoxuiJc6EpcUKdmN3sJHg1kUgtS1jNaEB%2BTA%3D%3D" rel="nofollow" target="_blank">Free Spire.XLS for .NET</a></strong>，通过代码快速创建 Excel 文件、填充数据、应用样式，并将文件导出为多种格式，包括 XLSX、CSV、PDF，甚至直接保存到内存流以便网络传输。本文将通过一个完整示例，详细演示如何在 C# 中实现 Excel 数据导出，让你的报表生成工作既高效又专业。</p><h2>1. 安装 Spire.XLS</h2><p>在开始编码前，需要通过 NuGet 安装 Spire.XLS：</p><pre><code class="bash">Install-Package FreeSpire.XLS</code></pre><p>安装完成后，即可在 C# 项目中引用命名空间：</p><pre><code class="csharp">using Spire.Xls;
using System.Data;
using System.IO;</code></pre><hr/><h2>2. 创建工作簿和填充数据</h2><p>下面示例演示如何创建一个 Excel 文件，并将员工信息填充到工作表中：</p><pre><code class="csharp">// 创建工作簿
Workbook workbook = new Workbook();
Worksheet sheet = workbook.Worksheets[0];
sheet.Name = "EmployeeData";

// 创建 DataTable 并添加列
DataTable table = new DataTable();
table.Columns.Add("EmployeeID");
table.Columns.Add("FullName");
table.Columns.Add("Department");
table.Columns.Add("HireDate");
table.Columns.Add("Salary");

// 添加示例数据
table.Rows.Add("E101", "John Miller", "Finance", "2020-02-15", "7500");
table.Rows.Add("E102", "Sarah Brown", "HR", "2019-07-10", "6800");
table.Rows.Add("E103", "Michael Davis", "IT", "2021-01-22", "8200");
table.Rows.Add("E104", "Laura Wilson", "Marketing", "2018-11-18", "7100");
table.Rows.Add("E105", "Daniel Lee", "Sales", "2022-06-12", "6900");

// 将 DataTable 插入工作表，从第一行第一列开始，并保留列名
sheet.InsertDataTable(table, true, 1, 1);

// 应用内置样式
sheet.AllocatedRange.Rows[0].BuiltInStyle = BuiltInStyles.Heading2; // 标题行
for (int i = 1; i &lt; sheet.AllocatedRange.Rows.Count(); i++)
{
    sheet.AllocatedRange.Rows[i].BuiltInStyle = BuiltInStyles.Accent2; // 数据行
}

// 自动调整列宽和行高
sheet.AllocatedRange.AutoFitColumns();
sheet.AllocatedRange.AutoFitRows();</code></pre><p><strong>说明</strong>：</p><ul><li><code>InsertDataTable</code> 可以直接将 <code>DataTable</code> 内容写入工作表，同时支持保留列名。</li><li>内置样式（<code>BuiltInStyles</code>）可以快速美化表格，例如标题行加粗、数据行配色。</li><li><code>AutoFitColumns</code> 和 <code>AutoFitRows</code> 可自动调整列宽和行高，使表格美观。</li></ul><hr/><h2>3. 保存为不同格式</h2><p>Spire.XLS 支持多种保存格式，常见的包括：</p><ul><li><strong>XLS/XLSX</strong>：传统 Excel 文件</li><li><strong>CSV</strong>：逗号分隔文本文件</li><li><strong>PDF</strong>：用于打印或发布</li><li><strong>HTML</strong> / <strong>SVG</strong>：网页或矢量图格式</li><li><strong>XLSB/XLSM</strong>：二进制或带宏 Excel 文件</li><li><strong>MemoryStream</strong>：将文件写入内存流，用于网络传输或其他二次处理</li></ul><p>示例代码：</p><pre><code class="csharp">// 保存为 Excel 2016 格式
workbook.SaveToFile("EmployeeData.xlsx", FileFormat.Version2016);

// 保存为 CSV
workbook.SaveToFile("EmployeeData.csv", FileFormat.CSV);

// 保存为 PDF
workbook.SaveToFile("EmployeeData.pdf", FileFormat.PDF);

// 保存到 MemoryStream
using (MemoryStream ms = new MemoryStream())
{
    workbook.SaveToStream(ms, FileFormat.Version2016);
    // 这里可以将 ms 写入数据库、发送 HTTP 响应等
}</code></pre><p><strong>说明</strong>：</p><ul><li><code>FileFormat</code> 枚举支持多达 25 种格式，例如 <code>Xlsb2007</code>、<code>ODS</code>、<code>HTML</code>、<code>Markdown</code> 等。</li><li>MemoryStream 保存方式适合 Web 应用场景，可以直接将文件返回给客户端而不写入磁盘。</li></ul><hr/><h2>4. 效果展示</h2><p>生成的 Excel 文件：</p><p><img width="693" height="275" referrerpolicy="no-referrer" src="/img/bVdm3bT" alt="C#保存Excel" title="C#保存Excel"/></p><p>表头加粗，数据行有配色，并且列宽自适应。</p><hr/><h2>5. 扩展说明</h2><ol><li><strong>为什么要使用代码导出？</strong><br/>对于批量生成报表或动态数据，手动操作效率低且易出错，使用代码生成可以自动化、可复用。</li><li><p><strong>MemoryStream 场景</strong></p><ul><li>Web API 返回文件下载</li><li>将 Excel 存入数据库或云存储</li><li>在内存中生成并进一步处理，例如加密或压缩</li></ul></li><li><strong>多格式支持</strong><br/>Spire.XLS 的 <code>FileFormat</code> 枚举几乎覆盖了主流的 Excel、PDF、网页、模板等格式，可以满足多种业务需求。</li></ol><hr/><h2>6. 总结</h2><p>本文演示了如何使用 <strong>Spire.XLS for .NET</strong>：</p><ul><li>在 C# 中创建 Excel 文件并填充数据</li><li>应用内置样式和自动调整行列</li><li>将文件保存为多种格式（XLSX、CSV、PDF、HTML 等）</li><li>使用 MemoryStream 保存用于网络传输或二次处理</li></ul><p>通过掌握 <code>Workbook</code>、<code>Worksheet</code>、<code>InsertDataTable</code> 和 <code>SaveToFile/SaveToStream</code>，你可以轻松实现 Excel 数据导出和格式转换，提升企业应用开发效率。</p>]]></description></item><item>    <title><![CDATA[Rust性能调优：从劝退到真香 烦恼的沙]]></title>    <link>https://segmentfault.com/a/1190000047400483</link>    <guid>https://segmentfault.com/a/1190000047400483</guid>    <pubDate>2025-11-14 18:05:04</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>地球人都说Rust快，安全，并发牛。但有时候我们写出来的代码，跑起来却像踩了脚刹车。这是为啥？其实，Rust给你的法拉利，你可能只当成了买菜车在开。性能这玩意儿，不是玄学，而是科学（和一点点小技巧）。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400485" alt="" title=""/></p><p>BUT，在开始之前，谁也不想在配置环境这种破事上浪费生命，对吧？装Rust、装PostgreSQL、装Redis……一套下来，半天没了。这里就要用 ServBay，这是开发者的福音，一键就能把<a href="https://link.segmentfault.com/?enc=fibNiS76DfbCiDMY1AUx%2BA%3D%3D.OYRbqk91llhZM5tXpBJwQgmnA9nV7gF4sbJGWaO64K1QzOOAw0if8wtwQvOQjqeF" rel="nofollow" target="_blank">Rust开发环境</a>给搞定了，连带各种数据库都安排得明明白白。哥哥你放心飞，ServBay永相随。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400486" alt="" title="" loading="lazy"/></p><p>好了，环境搞定，系好安全带，我们发车！</p><h4><strong>技巧一：函数参数别老用</strong><code>String</code>，<code>&amp;str</code><strong>才是万金油</strong></h4><p>这可能是新手最容易犯的错误。看到字符串，下意识就用<code>String</code>。</p><p><strong>别这么干：</strong></p><pre><code class="rust">// 每次调用这个函数，都可能发生一次内存拷贝，把所有权交出去
fn welcome_user(name: String) {
    println!("Hello, {}! 欢迎来到Rust的世界！", name);
}

fn main() {
    let user_name = "CodeWizard".to_string();
    // 为了不失去 user_name 的所有权，你不得不克隆它
    welcome_user(user_name.clone()); 
    println!("你的用户名是: {}", user_name); // 如果不clone，这里就编译不过了
}</code></pre><p><strong>试试这个：</strong></p><pre><code class="rust">// 使用 &amp;str，我们只是借用了数据，不涉及所有权转移
fn welcome_user(name: &amp;str) {
    println!("Hello, {}! 欢迎来到Rust的世界！", name);
}

fn main() {
    let user_name = "CodeWizard".to_string();
    welcome_user(&amp;user_name); // 轻松借用
    welcome_user("Newbie"); // 字符串字面量也完全没问题
    println!("你的用户名是: {}", user_name); // user_name 还在，啥事没有
}</code></pre><p><strong>为啥呢？</strong> <code>String</code>是动态的、拥有所有权的字符串，把它作为参数传递，要么所有权被移走（原来的变量不能再用），要么你就得<code>clone()</code>一份，这可是实打实的内存分配和拷贝，开销不小。而<code>&amp;str</code>（字符串切片）只是一个“引用”，一个指向数据某部分的“指针+长度”组合，传递它就跟递张名片一样轻巧，不产生任何数据拷贝。</p><h4><strong>技巧二：数据共享？别傻傻地</strong><code>clone()</code>，请用<strong><code>Arc</code></strong></h4><p>当多个线程或多个数据结构需要访问同一份大数据时，比如一个共享的配置信息，无脑<code>clone()</code>会付出沉重的代价。</p><p><strong>别这么干：</strong></p><pre><code class="rust">use std::thread;

#[derive(Clone)] // 为了能在线程间传递，不得不加上Clone
struct AppConfig {
    api_key: String,
    timeout: u32,
}

fn main() {
    let config = AppConfig {
        api_key: "a_very_long_and_secret_api_key".to_string(),
        timeout: 5000,
    };

    let mut handles = vec![];
    for i in 0..5 {
        let thread_config = config.clone(); // 每次都深度拷贝整个结构体
        handles.push(thread::spawn(move || {
            println!("线程 {} 使用的 API Key 是: {}", i, thread_config.api_key);
        }));
    }

    for handle in handles {
        handle.join().unwrap();
    }
}</code></pre><p><strong>试试这个：</strong></p><pre><code class="rust">use std::sync::Arc;
use std::thread;

struct AppConfig {
    api_key: String,
    timeout: u32,
}

fn main() {
    // Arc是“原子引用计数”智能指针，可以安全地在线程间共享数据
    let config = Arc::new(AppConfig {
        api_key: "a_very_long_and_secret_api_key".to_string(),
        timeout: 5000,
    });

    let mut handles = vec![];
    for i in 0..5 {
        let thread_config = Arc::clone(&amp;config); // 这不是数据拷贝！只是增加引用计数，非常快
        handles.push(thread::spawn(move || {
            println!("线程 {} 使用的 API Key 是: {}", i, thread_config.api_key);
        }));
    }

    for handle in handles {
        handle.join().unwrap();
    }
}</code></pre><p><strong>为啥呢？</strong> <code>Arc::clone()</code>做的不是复制数据本体，它只是把一个记录“有多少人正在引用这份数据”的计数器加一。这个操作非常轻量，几乎没有成本。只有当最后一个引用消失时，数据才会被真正清理。面对多线程共享只读数据的场景，<code>Arc</code>就是不二之选。</p><h4><strong>技巧三：</strong> <strong>迭代器</strong> <strong>大法好，告别C风格的索引循环</strong></h4><p>还在用<code>for i in 0..vec.len()</code>？那可就错过了Rust编译器给准备的免费午餐。</p><p><strong>别这么干：</strong></p><pre><code class="rust">fn main() {
    let numbers = vec![1, 2, 3, 4, 5, 6];
    let mut sum_of_squares = 0;
    for i in 0..numbers.len() {
        // 每次访问 numbers[i]，编译器都会插入一个边界检查，以防你越界
        if numbers[i] % 2 == 0 {
            sum_of_squares += numbers[i] * numbers[i];
        }
    }
    println!("偶数的平方和是: {}", sum_of_squares);
}</code></pre><p><strong>试试这个：</strong></p><pre><code class="rust">fn main() {
    let numbers = vec![1, 2, 3, 4, 5, 6];
    // 迭代器是惰性的，并且链式调用会被编译器优化成一个高效的循环
    let sum_of_squares: i32 = numbers
        .iter()                // 创建一个迭代器
        .filter(|&amp;&amp;n| n % 2 == 0) // 筛选出偶数
        .map(|&amp;n| n * n)       // 计算平方
        .sum();                // 求和

    println!("偶数的平方和是: {}", sum_of_squares);
}</code></pre><p><strong>为啥呢？</strong> Rust的迭代器是零成本抽象。写的链式调用，在编译后会被融合成一个手写的、极其高效的循环，而且编译器在编译时就能确定访问不会越界，从而去掉了运行时的边界检查。既安全，又高效，代码还更清晰，何乐而不为？</p><h4><strong>技巧四：</strong> <strong>泛型</strong> <strong>优于动态分发（</strong> <code>Box&lt;dyn Trait&gt;</code> <strong>）</strong></h4><p>当代码需要处理多种不同类型，但它们都实现了同一个<code>Trait</code>时，这时候会有两种选择：静态分发（泛型）和动态分发（Trait对象）。在性能敏感的路径上，请选择前者。</p><p><strong>别这么干（动态分发）：</strong></p><pre><code class="rust">trait Sound {
    fn make_sound(&amp;self) -&gt; String;
}

struct Dog;
impl Sound for Dog {
    fn make_sound(&amp;self) -&gt; String { "汪汪!".to_string() }
}

struct Cat;
impl Sound for Cat {
    fn make_sound(&amp;self) -&gt; String { "喵~".to_string() }
}

// 使用Box&lt;dyn Trait&gt;，运行时需要通过虚函数表(vtable)查找具体调用哪个方法
fn trigger_sound(animal: Box&lt;dyn Sound&gt;) {
    println!("{}", animal.make_sound());
}

fn main() {
    trigger_sound(Box::new(Dog));
    trigger_sound(Box::new(Cat));
}</code></pre><p><strong>试试这个（静态分发）：</strong></p><pre><code class="rust">trait Sound {
    fn make_sound(&amp;self) -&gt; String;
}

struct Dog;
impl Sound for Dog {
    fn make_sound(&amp;self) -&gt; String { "汪汪!".to_string() }
}

struct Cat;
impl Sound for Cat {
    fn make_sound(&amp;self) -&gt; String { "喵~".to_string() }
}

// 使用泛型，编译器会为每种类型生成一个专门的版本，没有运行时开销
fn trigger_sound&lt;T: Sound&gt;(animal: T) {
    println!("{}", animal.make_sound());
}

fn main() {
    trigger_sound(Dog);
    trigger_sound(Cat);
}</code></pre><p><strong>为啥呢？</strong> 动态分发<code>Box&lt;dyn Trait&gt;</code>需要在运行时查找一个叫做“虚表”的东西来确定到底该调用哪个具体实现的方法，这会带来额外的指针间接引用和查找开销。而泛型，编译器在编译时就知道要用<code>Dog</code>还是<code>Cat</code>，它会直接生成两个不同版本的<code>trigger_sound</code>函数，一个给<code>Dog</code>，一个给<code>Cat</code>，调用时直接就是函数地址，没有任何运行时开销。这种技术也叫单态化。</p><h4><strong>技巧五：给小函数戴上</strong><code>#[inline]</code><strong>的帽子</strong></h4><p>对于那些又小又被频繁调用的函数，函数调用本身的开销（比如建立栈帧）可能比函数体执行的开销还大。</p><pre><code class="rust">// 这是一个非常小的辅助函数
#[inline]
fn is_positive(n: i32) -&gt; bool {
    n &gt; 0
}

fn count_positives(numbers: &amp;[i32]) -&gt; usize {
    numbers.iter().filter(|&amp;&amp;n| is_positive(n)).count()
}

fn main() {
    let data = vec![-1, 1, -2, 2, 3];
    println!("正数的个数: {}", count_positives(&amp;data));
}</code></pre><p><strong>为啥呢？</strong> <code>#[inline]</code>像是一个给编译器的建议，告诉它：“哥们，把这个函数的代码直接复制粘贴到调用它的地方吧，别走函数调用流程了。” 这样就消除了函数调用的开销。当然，别滥用，给一个巨大的函数加上<code>#[inline]</code>只会让最终程序体积膨胀，得不偿失。</p><h4><strong>技巧六：栈上分配永远比堆上快</strong></h4><p>能放在栈上的数据，就别往堆上扔。栈分配就是移动一下栈指针，快如闪电；堆分配则需要去仓库（堆）里找一块合适的空地，要慢得多。</p><p><strong>别这么干：</strong></p><pre><code class="rust">struct Point {
    x: f64,
    y: f64,
}

fn main() {
    // Box::new会把数据分配在堆上
    let p1 = Box::new(Point { x: 1.0, y: 2.0 });
    println!("堆上的点: ({}, {})", p1.x, p1.y);
}</code></pre><p><strong>试试这个：</strong></p><pre><code class="rust">struct Point {
    x: f64,
    y: f64,
}

fn main() {
    // 默认情况下，变量是分配在栈上的
    let p1 = Point { x: 1.0, y: 2.0 };
    println!("栈上的点: ({}, {})", p1.x, p1.y);
}</code></pre><p>这个技巧看起来非常简单，但其核心是当不需要在函数返回后数据仍然存活，或者数据大小在编译期就确定时，优先使用栈。<code>Box</code>、<code>String</code>、<code>Vec</code>这类都是在堆上分配的，使用时要心里有数。</p><h4><strong>技巧七：</strong> <code>MaybeUninit</code> <strong>：大</strong> <strong>内存</strong> <strong>初始化时开挂了</strong></h4><p>如果需要一块非常大的内存，并且确定马上会用自己的数据把它填满时，让Rust先用0初始化一遍的话，纯属浪费CPU。</p><p>这是一个高级技巧，需要使用<code>unsafe</code>，新手慎用！</p><pre><code class="rust">use std::mem::MaybeUninit;

const BUFFER_SIZE: usize = 1024 * 1024; // 1MB

fn main() {
    // 创建一个Vec，但告诉Rust：“先别初始化这块内存，我待会儿自己弄”
    let mut buffer: Vec&lt;MaybeUninit&lt;u8&gt;&gt; = Vec::with_capacity(BUFFER_SIZE);

    // 假设我们从某个地方读取数据填满了这块缓冲区
    // 这里我们用一个简单的循环模拟
    // 注意：在真实场景中，你会用类似 read_exact 的方法填充
    unsafe {
        // 伪装成已经初始化了，因为我们确信下面的代码会完成初始化
        buffer.set_len(BUFFER_SIZE); 
        for i in 0..BUFFER_SIZE {
            // get_mut_unchecked是`unsafe`的，但我们知道索引是合法的
            *buffer.get_mut_unchecked(i) = MaybeUninit::new((i % 256) as u8);
        }
    }

    // 现在，我们确信内存已经完全初始化，可以安全地把它转换成 Vec&lt;u8&gt;
    let buffer: Vec&lt;u8&gt; = unsafe {
        // 这步转换是零成本的，因为内存布局完全一样
        std::mem::transmute(buffer)
    };

    println!("缓冲区创建并填充完毕，第一个元素是: {}", buffer[0]);
    println!("最后一个元素是: {}", buffer[BUFFER_SIZE - 1]);
}</code></pre><p><strong>为啥呢？</strong> <code>Vec::with_capacity</code>只分配内存，不初始化。但如果你接着用<code>resize</code>或者其他安全的方法，它还是会帮你初始化。<code>MaybeUninit</code>允许你跳过这个默认的初始化步骤，直接操作未初始化的内存，对于高性能网络编程、数据解析等场景，能省下可观的时间。但记住，<code>unsafe</code>意味着你得自己对内存安全负责！</p><h3><strong>总结一下</strong></h3><p>Rust性能调优的核心思想无非几点：</p><ul><li><strong>减少</strong> <strong>内存</strong> <strong>分配和拷贝</strong>：多用借用（<code>&amp;</code>），善用智能指针（<code>Arc</code>）。</li><li><strong>让编译器帮你干活</strong>：多用迭代器，多用泛型。</li><li><strong>理解</strong> <strong>内存</strong> <strong>布局</strong>：区分栈和堆，知道什么时候该用谁。</li></ul><p>当然，优化要讲究章法，不要上来就对着贴脸代码开大。先用性能分析工具（比如<code>cargo-flamegraph</code>）找到问题在哪，再对症下药。</p><p>最后，别忘了，一个顺手的开发环境是高效工作的开始。ServBay 搞定繁琐的配置，开发者就能把全部精力投入到编写优雅且高性能的Rust代码中。现在，去把你的买菜车调教成一辆真正的法拉利吧！</p>]]></description></item><item>    <title><![CDATA[Databend SQL 存储过程使用指]]></title>    <link>https://segmentfault.com/a/1190000047400488</link>    <guid>https://segmentfault.com/a/1190000047400488</guid>    <pubDate>2025-11-14 18:04:04</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>一、什么是存储过程？</h2><p>存储过程（Stored Procedure）是一组预编译的 SQL 语句集合，它们被保存在数据库中，可以像函数一样被重复调用。想象一下，如果你经常需要执行一系列复杂的数据处理操作，与其每次都手动输入这些 SQL 语句，不如将它们封装成一个存储过程，需要时直接调用即可。</p><h3>存储过程的优势</h3><ol><li><strong>代码复用</strong>：一次编写，多次调用，避免重复代码</li><li><strong>性能优化</strong>：预编译的 SQL 语句执行效率更高</li><li><strong>业务逻辑封装</strong>：将复杂的业务逻辑封装在数据库层</li><li><strong>维护便利</strong>：统一管理和修改业务逻辑</li><li><strong>安全性</strong>：通过权限控制，限制用户对底层数据的直接访问</li></ol><h2>二、第一个存储过程：Hello World</h2><p>让我们从最简单的例子开始。假设我们需要一个简单的加法存储过程：</p><pre><code>CREATE PROCEDURE my_add(a Int32, b Int32)
RETURNS Int32
LANGUAGE SQL
AS $$
BEGIN
    RETURN a + b;
END;
$$;</code></pre><h3>语法解析</h3><p>让我们逐行理解这个存储过程：</p><ul><li><code>CREATE PROCEDURE my_add</code>：创建一个名为 <code>my_add</code> 的存储过程</li><li><code>(a Int32, b Int32)</code>：定义输入参数 <code>a</code> 和 <code>b</code>，类型为 Int32</li><li><code>RETURNS Int32</code>：指定返回值类型为 Int32</li><li><code>LANGUAGE SQL</code>：指定使用 SQL 语言编写（目前 Databend 仅支持 SQL）</li><li><code>AS $$ ... $$</code>：使用美元符号包裹存储过程的主体代码</li><li><code>BEGIN ... END</code>：存储过程主体的开始和结束标记</li><li><code>RETURN a + b</code>：执行计算并返回结果</li></ul><h3>调用存储过程</h3><p>创建后，我们可以这样调用它, 注意参数类型需要显式指定：</p><pre><code>call PROCEDURE my_add(3::Int,4::Int);
----
7</code></pre><h3>SqlScript</h3><p>存储过程中的语法我们称之为 SqlScript， 我们也可以直接使用 <code>execute immediate</code> 来执行 SqlScript 语句。</p><ul><li>执行单个 SQL</li></ul><pre><code>execute immediate 'CREATE TABLE test (id Int32)';</code></pre><ul><li>执行多个 SQL, 用 begin 和 end 包裹</li></ul><pre><code>execute immediate $$
BEGIN
    select 33;
    let s RESULTSET := select number from numbers(100);
    RETURN TABLE(s);
END;
$$;</code></pre><h2>三、进阶：使用变量和流程控制</h2><p>现在让我们学习如何在 SqlScript 中使用变量、条件判断和循环。</p><h3>3.1 变量声明和使用</h3><h4>Scalar 变量</h4><p>在 Databend 中，使用 <code>LET</code> 关键字声明变量：</p><p>语法有：</p><ol><li><code>LET &lt;variable_name&gt; := &lt;value&gt;</code> -- 声明并初始化变量 x</li><li><code>LET &lt;variable_name&gt; [&lt;type&gt;] := &lt;value&gt;</code> -- 声明并初始化变量 x</li><li><code>LET &lt;variable_name&gt; [&lt;type&gt;] DEFAULT &lt;value&gt;</code> -- 声明并初始化变量 x</li><li><code>LET &lt;variable_name&gt; [&lt;type&gt;]</code> -- 声明变量 x, 后续初始化</li></ol><pre><code>execute immediate $$
BEGIN
    LET sum := 0;  -- 声明并初始化变量 sum

    FOR i IN 1 TO 10 DO
        IF i % 2 = 0 THEN
            sum := sum + i;  -- 累加偶数
        END IF;
    END FOR;

    RETURN sum;
END;
$$;</code></pre><p>在这个例子中：</p><ul><li><code>LET sum := 0</code>：声明一个名为 <code>sum</code> 的变量并初始化为 0</li><li><code>:=</code>：赋值操作符</li><li><code>RETURNS UInt8 NOT NULL</code>：指定返回值不能为 NULL</li></ul><h4>ResultSet 变量</h4><p>ResultSet 变量用于存储查询结果集，语法有：</p><p>示例语法：</p><pre><code>execute immediate $$
BEGIN
    LET x RESULTSET := select number from numbers(10);
    RETURN TABLE(x);
END;
$$;</code></pre><p>上面是返回结果集，所以使用 <code>RETURN TABLE(x)</code> 语句</p><h4>Cursor 变量</h4><p>Cursor 变量用于遍历结果集，语法有：</p><ol><li><code>LET &lt;cursor_variable&gt; CURSOR for &lt;query&gt;</code></li><li><code>LET &lt;cursor_variable&gt; CURSOR for &lt;result_set_variable&gt;</code></li><li><code>OPEN &lt;cursor_variable&gt;</code></li><li><code>FETCH &lt;cursor_variable&gt; INTO &lt;variable&gt;</code></li><li><code>CLOSE &lt;cursor_variable&gt;</code></li><li><code>for &lt;variable&gt; in &lt;cursor_variable&gt; do ... end for</code></li></ol><p>示例语法：</p><pre><code>execute immediate $$
BEGIN
    LET v Int;
    LET c CURSOR for select max(number) from numbers(10);
    OPEN c;
    FETCH c INTO v;
    CLOSE c;

    let d RESULTSET := select number from numbers(10);
    let e CURSOR for d;
    for v2 in e do
        v := v + v2.number;
    end for;

    return v;
END;
$$;</code></pre><h3>3.2 条件判断：IF-THEN-ELSEIF-ELSE</h3><p>IF 语句允许我们根据条件执行不同的代码分支：</p><pre><code>execute immediate $$
BEGIN
    LET score := 57 + 10 + 10 + 10;
    LET grade := '';

    IF score &gt;= 90 THEN
        grade := '优秀';
    ELSEIF score &gt;= 80 THEN
        grade := '良好';
    ELSEIF score &gt;= 70 THEN
        grade := '中等';
    ELSEIF score &gt;= 60 THEN
        grade := '及格';
    ELSE
        grade := '不及格';
    END IF;
    RETURN grade;
END;
$$;</code></pre><h3>3.3 循环：FOR 循环</h3><p>FOR 循环有两种常见形式：</p><h4>形式一：范围循环</h4><pre><code>FOR i IN start_value TO end_value DO
    -- 循环体
END FOR;</code></pre><p>示例：</p><pre><code>execute immediate $$
BEGIN
    LET sum := 0;
    FOR i IN 1 TO 10 DO
        sum := sum + i;
    END FOR;
    RETURN sum;
END;
$$;</code></pre><h4>形式二：结果集循环</h4><p>示例：</p><pre><code>execute immediate $$
BEGIN
    -- 声明一个结果集变量
    LET x RESULTSET := SELECT number n FROM numbers(10);
    LET sum := 0;

    -- 遍历结果集
    FOR r IN x DO
        -- 使用 r.n 访问列值
        sum := sum + r.n;
    END FOR;
    RETURN sum;
END;
$$;</code></pre><h2>四、高级应用：嵌套循环与复杂逻辑</h2><p>让我们看一个更复杂的例子，展示嵌套循环和多层逻辑：</p><pre><code>execute immediate $$
BEGIN
    -- 声明结果集变量：从 0 到 9 的数字
    LET x RESULTSET := SELECT number n FROM numbers(10);
    LET sum := 0;

    -- 外层循环：遍历结果集
    FOR x IN x DO
        -- 内层循环：从 0 到当前数字
        FOR batch IN 0 TO x.n DO
            IF batch % 2 = 0 THEN
                sum := sum + batch;  -- 偶数加
            ELSE
                sum := sum - batch;  -- 奇数减
            END IF;
        END FOR;
    END FOR;

    RETURN sum;
END;
$$;</code></pre><h3>逻辑分析</h3><p>让我们分析一下这个过程的执行流程：</p><ol><li><strong>外层循环</strong>：遍历 0-9 这 10 个数字</li><li><strong>内层循环</strong>：对于每个数字 n，从 0 循环到 n</li><li><strong>条件判断</strong>：如果是偶数则加，奇数则减</li></ol><p>例如当 x.n = 3 时：</p><ul><li>batch = 0（偶）：sum += 0</li><li>batch = 1（奇）：sum -= 1</li><li>batch = 2（偶）：sum += 2</li><li>batch = 3（奇）：sum -= 3</li></ul><h3>动态拼接语句，嵌套执行</h3><pre><code>execute immediate $$
BEGIN
   LET tbl_name := 'abcd1' ;
   LET drop_sql := 'DROP TABLE default."' || tbl_name || '"' ;
   EXECUTE IMMEDIATE :drop_sql ;
END ;
$$ ; </code></pre><h2><em>五、返回表格数据</em></h2><p>除了返回单个值，存储过程还可以返回整张表：</p><pre><code>execute immediate $$
BEGIN
    RETURN TABLE(
        SELECT
            number % 3 d,
            SUM(number) AS total_amount
        FROM numbers(10)
        GROUP BY d
    ) ;
END ;
$$ ; </code></pre><h2><em>六、存储过程管理</em></h2><table><thead><tr><th>操作</th><th>SQL</th><th>说明</th></tr></thead><tbody><tr><td>查看所有存储过程</td><td><code>SHOW PROCEDURES;</code></td><td> </td></tr><tr><td>查看存储过程详情</td><td><code>DESC PROCEDURE sum_even_numbers(UInt8, UInt8);</code><br/>或<br/><code>DESCRIBE PROCEDURE sum_even_numbers(UInt8, UInt8);</code></td><td><strong>注意：</strong><br/>• 无参数的存储过程使用空括号：<code>DESC PROCEDURE proc_name()</code><br/>• 有参数的必须指定确切的参数类型</td></tr><tr><td>删除存储过程</td><td><code>DROP PROCEDURE my_add(int, int);</code></td><td> </td></tr><tr><td>替换存储过程</td><td><code>CREATE OR REPLACE PROCEDURE my_add(a Int32, b Int32)</code><br/><code>RETURNS Int32</code><br/><code>LANGUAGE SQL</code><br/><code>AS $$`&lt;br&gt;`BEGIN`&lt;br&gt;`    RETURN a + b + 3;`&lt;br&gt;`END;`&lt;br&gt;`$$;</code></td></tr></tbody></table><h2><em>七、</em> <em>最佳实践</em></h2><h3><em>7.1 命名规范</em></h3><ul><li>使用有意义的名称，清晰表达功能</li><li>使用下划线分隔单词（snake_case）</li><li>添加前缀区分不同类型的过程（如 <code>calc_</code>, <code>get_</code>, <code>update_</code>）</li></ul><pre><code>-- 好的命名
CREATE PROCEDURE calc_monthly_revenue(...)
CREATE PROCEDURE get_active_users(...)
CREATE PROCEDURE update_user_status(...)

-- 不好的命名
CREATE PROCEDURE proc1(...)
CREATE PROCEDURE x(...)</code></pre><h3><em>7.2 注释说明</em></h3><p>始终为存储过程添加清晰的注释：</p><pre><code>CREATE PROCEDURE process_orders(order_date DATE)
RETURNS INT
LANGUAGE SQL
COMMENT = '处理指定日期的订单，返回处理数量'
AS $$ ... $$ ; </code></pre><h3><em>7.3 性能考虑</em></h3><ol><li><strong>避免过度循环</strong>：对于大数据集，尽量使用集合操作而非逐行循环</li><li><strong>合理使用索引</strong>：在存储过程中查询的表应有适当的索引</li><li><strong>批量操作</strong>：尽可能使用批量插入/更新而非逐条处理</li><li><strong>结果集大小</strong>：返回表格时，使用 LIMIT 限制结果集大小</li></ol><h2><em>八、实战案例：数据清洗流程</em></h2><p>让我们用二个实际案例来综合运用所学知识：</p><h3><em>9.1 清理和归档不活跃用户数据</em></h3><pre><code>CREATE OR REPLACE PROCEDURE cleanup_user_data(days_threshold INT)
RETURNS TABLE(
    action VARCHAR,
    user_count INT,
    processed_at TIMESTAMP
)
LANGUAGE SQL
COMMENT = '清理和归档不活跃用户数据'
AS $$
BEGIN
    LET cutoff_date := DATE_SUB(DAY, days_threshold,today()) ;
    LET inactive_users := 0 ;
    LET deleted_users := 0 ;

    -- 统计不活跃用户
    LET inactive_resultset RESULTSET :=
        SELECT COUNT(*) AS cnt
        FROM users
        WHERE last_login_date &lt; cutoff_date
        AND status = 'active' ;

    FOR r IN inactive_resultset DO
        inactive_users := r.cnt ;
    END FOR ;

    -- 标记不活跃用户
    UPDATE users
    SET status = 'inactive'
    WHERE last_login_date &lt; cutoff_date
    AND status = 'active' ;

    -- 删除长期不活跃用户
    DELETE FROM users
    WHERE last_login_date &lt; DATE_SUB(cutoff_date, INTERVAL days_threshold DAY)
    AND status = 'inactive' ;

    -- 返回处理结果
    RETURN TABLE(
        SELECT
            'Marked Inactive' AS action,
            inactive_users AS user_count,
            CURRENT_TIMESTAMP() AS processed_at
        UNION ALL
        SELECT
            'Deleted' AS action,
            deleted_users AS user_count,
            CURRENT_TIMESTAMP() AS processed_at
    ) ;
END ;
$$ ; </code></pre><p>调用方式：</p><pre><code>-- 清理 90 天未登录的用户
CALL PROCEDURE cleanup_user_data(90::Int) ; </code></pre><h3><em>9.2 扫描表并合并数据到target表</em></h3><pre><code>CREATE OR REPLACE PROCEDURE PROC_MERGE_GPS()
RETURNS STRING
LANGUAGE SQL
AS
$$
BEGIN
    create or replace table default.gps as select number from numbers(100) ;
    create or replace table default.abcd1 as select number from numbers(100) ;
    create or replace table default.abcd2 as select number from numbers(100) ;
    create or replace table default.abcd3 as select number from numbers(100) ;

    -- Step 1: 查询符合条件的表名（使用 INFORMATION_SCHEMA）
    LET records RESULTSET := (
        select name  from system.tables where database = 'default' and name like '%abcd%'
    ) ;
    LET table_count := 0 ;
    LET record_count := 0 ;
    LET table_names := [] ;
    LET union_parts := [] ;
    for table_record in records DO
        LET name := table_record.name ;
        table_count := table_count + 1 ;
        table_names := ARRAY_APPEND(table_names, name) ;
        union_parts := ARRAY_APPEND(union_parts, 'SELECT * FROM default.' || name) ;
    END FOR ;

    -- 如果没有匹配的表，直接返回
    IF (table_count = 0) THEN
        RETURN 'No data to process' ;
    END IF ;

    -- Step 3: 创建临时视图
    LET view_sql := 'CREATE OR REPLACE VIEW default.TEMPORARY_GPS_TABLES AS ' || ARRAY_TO_STRING(union_parts, ' UNION ALL ') ;
    EXECUTE IMMEDIATE :view_sql ;

    -- Step 2: 查询表中的记录数
    LET record_count_sql := 'SELECT COUNT(*) c FROM default.TEMPORARY_GPS_TABLES' ;
    LET r RESULTSET := EXECUTE IMMEDIATE :record_count_sql ;
    for record in r DO
        record_count := record.c ;
    END FOR ;

    -- Step 4: 设置会话参数, example
    EXECUTE IMMEDIATE 'set max_block_size = 65536' ;

    -- Step 5: 执行 示例SQL
    LET merge_sql := 'insert into default.gps select * from default.TEMPORARY_GPS_TABLES;' ;
    EXECUTE IMMEDIATE :merge_sql ;

    -- Step 6: 清理：删除视图
    EXECUTE IMMEDIATE 'DROP VIEW IF EXISTS default.TEMPORARY_GPS_TABLES' ;

    -- Step 7: 删除所有 %abcd% 表
    FOR i IN 1 TO ARRAY_SIZE(table_names) DO
        LET tbl_name := table_names[i]::STRING ;
        LET drop_sql := 'DROP TABLE default."' || tbl_name || '"' ;
        EXECUTE IMMEDIATE :drop_sql ;
    END FOR ;
    RETURN 'Merge completed successfully. Processed ' || table_count || ' tables. Total records: ' || record_count ;
END ;
$$ ; </code></pre><p>调用结果：</p><pre><code>call PROCEDURE PROC_MERGE_GPS() ;
---
Merge completed successfully. Processed 3 tables. Total records: 300</code></pre><h2><em>九、总结</em></h2><p>Databend 的 SQL 存储过程为数据处理提供了强大而灵活的工具。通过本文，我们学习了：</p><ol><li><strong>基础语法</strong>：如何创建和调用存储过程</li><li><strong>变量和赋值</strong>：使用 LET 声明和管理变量</li><li><strong>流程控制</strong>：IF 条件判断和 FOR 循环</li><li><strong>高级特性</strong>：嵌套循环、结果集遍历、返回表格</li><li><strong>管理操作</strong>：查看、描述、删除存储过程</li><li><strong>最佳实践</strong>：命名规范、注释、错误处理、性能优化</li></ol><h3><em>关键要点回顾</em></h3><ul><li>✅ 使用 <code>CREATE PROCEDURE</code> 创建存储过程</li><li>✅ 使用 <code>CALL PROCEDURE</code> 调用存储过程</li><li>✅ 使用 <code>EXECUTE IMMEDIATE</code> 执行动态 SQL</li><li>✅ 使用 <code>LET</code> 声明变量，<code>:=</code> 赋值</li><li>✅ 支持 <code>IF-THEN-ELSE</code> 条件判断</li><li>✅ 支持 <code>FOR...IN...DO</code> 循环</li><li>✅ 可以返回单个值或整张表</li><li>✅ 使用 <code>CREATE OR REPLACE</code> 更新存储过程</li><li>✅ 使用 <code>RESULTSET</code> 类型处理查询结果</li></ul><h3><em>下一步</em></h3><p>现在你已经掌握了 Databend 存储过程的核心知识，可以开始：</p><ol start="7"><li>在自己的项目中创建简单的存储过程</li><li>逐步引入更复杂的逻辑和流程控制</li><li>将常用的数据处理任务封装为存储过程</li><li>探索更多高级特性和优化技巧</li></ol><p>Happy coding with Databend! 🚀</p><h2>关于 Databend</h2><p>Databend 是一款开源、弹性、低成本，基于对象存储也可以做实时分析的新式湖仓。期待您的关注，一起探索云原生数仓解决方案，打造新一代开源 Data Cloud。</p><p>👨‍💻‍ Databend Cloud：<a href="https://link.segmentfault.com/?enc=P3aVDBMB4HdPc9YUZapaVQ%3D%3D.AUOUhDeqroEbJS0UaNFRDfA5Ep1%2FDbTlLqmlt1t5Asg0pgXyWXVXIKR6o0o0jX496k35jOsLSOkTnvD3SYwEcw%3D%3D" rel="nofollow" title="https://link.juejin.cn/?target=https%3A%2F%2Fdatabend.cn%2F" target="_blank">databend.cn</a></p><p>📖 Databend 文档：<a href="https://link.segmentfault.com/?enc=H%2F8PlpltaS34N1DwPC3tbw%3D%3D.8Lkk6SMMF6WICouN6oUR6YGaauLewcQhKE3C4lwdUrZ38YfIB%2B8gW4zjEuCg8%2B%2FdoPDt1sUS7U%2FvA5QKOZsFnJQB0ClU3D9uM7tFGf5lYXE%3D" rel="nofollow" title="https://link.juejin.cn/?target=https%3A%2F%2Fdocs.databend.cn%2F" target="_blank">docs.databend.cn</a></p><p>💻 Wechat：Databend</p><p>✨ GitHub：<a href="https://link.segmentfault.com/?enc=Cprp84F2tBEipBiWEQOG9Q%3D%3D.MYRIUJ7Xotc1UqbUieYqVR0E9eH5VyoRYtES4XFHSe5MVXiO6%2FZz6fD%2B0ABOhGf2C6B9so4LWIp%2F4mpRjaNeCC9x3maTvFGdVSeh3xquH39BE%2FJ1HnXh7kuvstjMGrgl" rel="nofollow" title="https://link.juejin.cn/?target=https%3A%2F%2Fgithub.com%2Fdatabendlabs%2Fdatabend" target="_blank">github.com/databendlab…</a></p>]]></description></item><item>    <title><![CDATA[如何使用 C# 创建 Word 文档填充]]></title>    <link>https://segmentfault.com/a/1190000047400494</link>    <guid>https://segmentfault.com/a/1190000047400494</guid>    <pubDate>2025-11-14 18:03:05</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在企业应用中，Word 文档（DOC/DOCX）仍然是信息交换和报告制作的核心工具。无论是合同、通知、汇报材料还是自动生成报表，都需要程序化生成 Word 文件。在传统做法中，开发者可能依赖手动操作或 Office 自动化（Interop），但这类方法存在依赖 Office 安装、性能低下及易出错的问题。</p><p>本文将详细介绍如何使用 <strong><a href="https://link.segmentfault.com/?enc=POKUCajmFjOyO0%2Bl8NSMWA%3D%3D.1e6jImGNhIRiwCs4JQSpN1eGnGdPUdh%2BXVjMKE9XNB6S9mQdyJ6GBkmYMxtvRGf2WzTZ9keyAYgjIW90OtVm7A%3D%3D" rel="nofollow" target="_blank">Free Spire.Doc for .NET</a></strong> 在 C# 中创建 Word 文档、插入文本、表格、图片及页眉页脚，并扩展到保存不同格式和 MemoryStream 的场景。示例数据仍使用英文文本，以便快速理解。</p><hr/><h2>1. 安装 Spire.Doc</h2><p>在使用前，需要通过 NuGet 安装 Spire.Doc：</p><pre><code class="bash">Install-Package FreeSpire.Doc</code></pre><p>安装完成后，在 C# 项目中引用必要命名空间：</p><pre><code class="csharp">using Spire.Doc;
using Spire.Doc.Documents;
using Spire.Doc.Fields;
using System.IO;
using System.Drawing;</code></pre><hr/><h2>2. 创建 Word 文档并添加段落</h2><pre><code class="csharp">// 创建新的文档
Document document = new Document();
Section section = document.AddSection();

// 添加标题段落
Paragraph title = section.AddParagraph();
title.AppendText("Employee Report");
title.Format.HorizontalAlignment = HorizontalAlignment.Center;
title.ApplyStyle(BuiltinStyle.Heading1);

// 添加正文段落
Paragraph intro = section.AddParagraph();
intro.AppendText("This report contains the details of employees in the company. All information is for internal use only.");
intro.Format.HorizontalAlignment = HorizontalAlignment.Left;
intro.Format.LineSpacing = 15f;</code></pre><p><strong>说明</strong>：</p><ul><li><code>AddSection</code> 创建独立章节，方便分页和样式管理。</li><li>内置样式（<code>BuiltinStyle</code>）提供 Word 标准格式。</li><li><code>Paragraph.Format</code> 可自定义对齐、行距、缩进等。</li></ul><hr/><h2>3. 插入表格并填充数据</h2><pre><code class="csharp">// 创建表格，5 行 5 列（含标题行）
Table table = section.AddTable(true);
table.ResetCells(5, 5);

// 设置标题行
table[0, 0].AddParagraph().AppendText("EmployeeID");
table[0, 1].AddParagraph().AppendText("FullName");
table[0, 2].AddParagraph().AppendText("Department");
table[0, 3].AddParagraph().AppendText("HireDate");
table[0, 4].AddParagraph().AppendText("Salary");

// 填充示例数据
table[1, 0].AddParagraph().AppendText("E101");
table[1, 1].AddParagraph().AppendText("John Miller");
table[1, 2].AddParagraph().AppendText("Finance");
table[1, 3].AddParagraph().AppendText("2020-02-15");
table[1, 4].AddParagraph().AppendText("7500");

table[2, 0].AddParagraph().AppendText("E102");
table[2, 1].AddParagraph().AppendText("Sarah Brown");
table[2, 2].AddParagraph().AppendText("HR");
table[2, 3].AddParagraph().AppendText("2019-07-10");
table[2, 4].AddParagraph().AppendText("6800");

table[3, 0].AddParagraph().AppendText("E103");
table[3, 1].AddParagraph().AppendText("Mike Smith");
table[3, 2].AddParagraph().AppendText("IT");
table[3, 3].AddParagraph().AppendText("2020-01-20");
table[3, 4].AddParagraph().AppendText("9000");

table[4, 0].AddParagraph().AppendText("E104");
table[4, 1].AddParagraph().AppendText("Lisa Jones");
table[4, 2].AddParagraph().AppendText("Marketing");
table[4, 3].AddParagraph().AppendText("2018-09-05");
table[4, 4].AddParagraph().AppendText("5500");</code></pre><p><strong>说明</strong>：</p><ul><li><code>AddTable(true)</code> 创建具有默认样式的表格。</li><li><code>ResetCells</code> 定义行列数。</li><li><code>table[i, j].AddParagraph()</code> 可插入文本，支持格式和超链接。</li></ul><hr/><h2>4. 自定义表格样式和段落格式</h2><pre><code class="csharp">// 设置标题行背景色
for (int i = 0; i &lt; 5; i++)
{
    table[0, i].CellFormat.BackColor = Color.LightGray;
    table[0, i].Paragraphs[0].GetStyle().CharacterFormat.Bold = true;
}

// 设置表格边框
table.TableFormat.Borders.BorderType = BorderStyle.Single;

// 设置行高
for (int i = 0; i &lt; table.Rows.Count; i++)
{
    table.Rows[i].Height = 20f;
}</code></pre><hr/><h2>5. 插入图片</h2><pre><code class="csharp">// 添加图片
Paragraph imgPara = section.AddParagraph();
DocPicture picture = imgPara.AppendPicture(Image.FromFile("company_logo.png"));
picture.Width = 100;
picture.Height = 50;
imgPara.Format.HorizontalAlignment = HorizontalAlignment.Right;</code></pre><p><strong>说明</strong>：</p><ul><li>使用 <code>AppendPicture</code> 插入图片，可调整宽高。</li><li>图片可放置于段落中，可对齐左、中、右。</li></ul><hr/><h2>6. 添加页眉页脚</h2><pre><code class="csharp">// 页眉
HeaderFooter header = section.HeadersFooters.Header;
Paragraph headerPara = header.AddParagraph();
headerPara.AppendText("Company Confidential");
headerPara.Format.HorizontalAlignment = HorizontalAlignment.Center;

// 页脚
HeaderFooter footer = section.HeadersFooters.Footer;
Paragraph footerPara = footer.AddParagraph();
footerPara.AppendText("Page ");
footerPara.AppendField("PAGE", FieldType.FieldPage);
footerPara.AppendText(" of ");
footerPara.AppendField("NUMPAGES", FieldType.FieldNumPages);
footerPara.Format.HorizontalAlignment = HorizontalAlignment.Center;</code></pre><p><strong>说明</strong>：</p><ul><li>页眉页脚可包含文字、页码、图片等内容。</li><li><code>FieldType.FieldPage</code> 与 <code>FieldType.FieldNumPages</code> 可实现自动页码功能。</li></ul><hr/><h2>7. 保存 Word 文档及其他格式</h2><pre><code class="csharp">// 保存为 DOCX
document.SaveToFile("EmployeeReport.docx", FileFormat.Docx);

// 保存为 PDF
document.SaveToFile("EmployeeReport.pdf", FileFormat.PDF);

// 保存为 HTML
document.SaveToFile("EmployeeReport.html", FileFormat.Html);

// 保存到 MemoryStream
using (MemoryStream ms = new MemoryStream())
{
    document.SaveToStream(ms, FileFormat.Docx);
    // 可直接发送到客户端或存储到数据库
}</code></pre><hr/><h2>8. 生成效果展示</h2><p>以下是上述代码生成的 Word 文档效果：</p><p><img width="723" height="500" referrerpolicy="no-referrer" src="/img/bVdm3cf" alt="C#创建并保存Word文档" title="C#创建并保存Word文档"/></p><hr/><h2>9. 扩展应用场景</h2><ol><li><strong>自动化报表生成</strong><br/>系统可以定期生成员工报告、销售报表，减少手工操作。</li><li><strong>动态内容生成</strong><br/>根据数据库动态填充段落、表格、图片，生成模板化文档。</li><li><strong>多格式导出</strong><br/>Spire.Doc 支持 DOCX、PDF、HTML 等多种格式，满足打印、网页展示或二次处理。</li><li><strong>Web 集成</strong><br/>MemoryStream 方式可直接返回客户端，无需写入磁盘，提高安全性和性能。</li></ol><hr/><h2>10. 总结</h2><p>本文演示了如何使用 <strong>Spire.Doc for .NET</strong>：</p><ul><li>创建 Word 文档并添加标题、正文、表格</li><li>美化表格和段落样式</li><li>插入图片和页眉页脚</li><li>将文档保存为 DOCX、PDF、HTML 等多种格式</li><li>使用 MemoryStream 实现网络传输或二次处理</li></ul><p>通过掌握 <code>Document</code>、<code>Section</code>、<code>Paragraph</code>、<code>Table</code>、<code>DocPicture</code> 等核心类和方法，你可以轻松实现 Word 文档自动化生成，提高办公系统开发效率和文档管理水平。</p>]]></description></item><item>    <title><![CDATA[【HarmonyOS 6】静态和动态添加]]></title>    <link>https://segmentfault.com/a/1190000047400506</link>    <guid>https://segmentfault.com/a/1190000047400506</guid>    <pubDate>2025-11-14 18:02:08</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>【HarmonyOS 6】静态和动态添加应用快捷方式详解</h2><h3>一、前言</h3><p>在功能日益复杂的应用中，用户往往需要多步操作才能找到常用功能。而应用快捷方式能让用户一键直达核心功能，既提升操作效率，也能增强用户对应用的粘性。</p><p>本文结合实际开发场景，详细分享 HarmonyOS 中两种快捷方式的实现方法，包括静态快捷方式配置和应用内动态添加，全程基于单 HAP 包场景（多 HAP 包配置逻辑一致）。</p><h3>二、静态快捷方式：基础配置与快速跳转</h3><p>静态快捷方式是通过配置文件预先定义的快捷方式，用户长按应用图标即可看到。例如“回家导航”“新建便签”这类高频固定功能。效果如下：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047400508" alt="在这里插入图片描述" title="在这里插入图片描述"/></p><h5>1、 创建目标页面并配置路由</h5><p>首先创建快捷方式对应的功能页面（如“回家”“去公司”页面），页面需用 <code>@Entry</code> 装饰。然后在 <code>resources/base/profile/main_pages.json</code> 中添加页面路由，确保应用能识别页面路径：</p><pre><code class="json">{
  "src": [
    "pages/Index",  // 应用主页面
    "pages/GoHouse", // 回家导航页面
    "pages/GoCompany" // 去公司导航页面
  ]
}</code></pre><h5>2、 编写快捷方式配置文件</h5><p>在 <code>resources/base/profile/</code> 目录下新建 <code>shortcuts_config.json</code> 文件，定义快捷方式的 ID、显示文本、图标和跳转目标。每个快捷方式需包含以下核心参数：</p><ul><li><code>shortcutId</code>：唯一标识，不超过 63 字节</li><li><code>label</code>：显示文本（支持字符串或资源索引）</li><li><code>icon</code>：图标资源索引</li><li><code>wants</code>：跳转配置（包名、模块名、组件名、自定义参数）</li></ul><p>示例配置：</p><pre><code class="json">{
  "shortcuts": [
    {
      "shortcutId": "id_company",
      "label": "$string:Go_to_the_Company",
      "icon": "$media:company",
      "wants": [
        {
          "bundleName": "com.example.desktopshortcuts",
          "moduleName": "entry",
          "abilityName": "EntryAbility",
          "parameters": {
            "shortCutKey": "CompanyPage"
          }
        }
      ]
    },
    {
      "shortcutId": "id_house",
      "label": "$string:Go_to_House",
      "icon": "$media:house",
      "wants": [
        {
          "bundleName": "com.example.desktopshortcuts",
          "moduleName": "entry",
          "abilityName": "EntryAbility",
          "parameters": {
            "shortCutKey": "HousePage"
          }
        }
      ]
    }
  ]
}</code></pre><h5>3、在 module.json5 中关联配置</h5><p>在 <code>module.json5</code> 的 <code>abilities</code> 标签下添加 <code>metadata</code> 配置，指定快捷方式配置文件路径，让系统识别快捷方式：</p><pre><code class="json">{
  "module": {
    "abilities": [
      {
        "name": "EntryAbility",
        "srcEntry": "./ets/entryability/EntryAbility.ets",
        "skills": [
          {
            "entities": ["entity.system.home"],
            "actions": ["ohos.want.action.home"]
          }
        ],
        "metadata": [
          {
            "name": "ohos.ability.shortcuts",
            "resource": "$profile:shortcuts_config"
          }
        ]
      }
    ]
  }
}</code></pre><h5>4、实现页面跳转逻辑</h5><p>在主页面（Index.ets）中定义跳转方法，通过读取 <code>wants</code> 中的自定义参数 <code>shortCutKey</code>，判断用户点击的快捷方式，进而跳转到对应页面：</p><pre><code class="typescript">goToSpecifyPage(want?: Want) {
  let shortCutKey = want?.parameters?.shortCutKey;

  if (shortCutKey === 'CompanyPage') {
    this.getUIContext().getRouter().pushUrl({ url: 'pages/GoCompany' })
      .catch((err: BusinessError) =&gt; {
        hilog.error(0x0000, 'testTag', `跳转失败：${err.code}, ${err.message}`);
      });
  }
  if (shortCutKey === 'HousePage') {
    this.getUIContext().getRouter().pushUrl({ url: 'pages/GoHouse' })
      .catch((err: BusinessError) =&gt; {
        hilog.error(0x0000, 'testTag', `跳转失败：${err.code}, ${err.message}`);
      });
  }
}</code></pre><h5>5、 保存并传递 Want 参数</h5><p>快捷方式跳转分为冷启动和热启动，需在 <code>EntryAbility.ets</code> 中通过 <code>AppStorage</code> 保存 <code>want</code> 参数，确保页面能获取到跳转信息：</p><pre><code class="typescript">// 冷启动时保存参数
onCreate(want: Want, launchParam: AbilityConstant.LaunchParam): void {
  this.context.getApplicationContext().setColorMode(ConfigurationConstant.ColorMode.COLOR_MODE_NOT_SET);
  if (want?.parameters?.shortCutKey) {
    AppStorage.setOrCreate('want', want);
  }
}

// 热启动时更新参数
onNewWant(want: Want, launchParam: AbilityConstant.LaunchParam): void {
  if (want?.parameters?.shortCutKey) {
    AppStorage.setOrCreate('want', want);
  }
}</code></pre><h5>6、 页面显示时执行跳转</h5><p>在主页面的 <code>onPageShow</code> 方法中，读取 <code>AppStorage</code> 中保存的 <code>want</code> 参数，调用跳转方法完成快捷方式响应：</p><pre><code class="typescript">onPageShow(): void {
  if (AppStorage.has('want')) {
    let want: Want | undefined = AppStorage.get('want');
    if (want) {
      this.goToSpecifyPage(want);
      AppStorage.delete('want'); // 跳转后清除参数，避免重复触发
    }
  }
}</code></pre><p>具体跳转的处理，通过want中的参数，开发者可以根据自己业务习惯进行跳转处理，以上处理为参考。</p><h4>注意事项</h4><p>（1）静态快捷方式最多支持配置 4 个，仅能跳转至 UIAbility 入口页面，无法直接跳转到非入口页面。<br/>（2）多 HAP 包场景无需额外配置，所有操作均在 entry 文件夹下完成。</p><h3>二、应用内动态添加快捷方式</h3><p>除了预先配置的静态快捷方式，还可以在应用内通过代码动态添加快捷方式（如用户点击“添加到桌面”按钮时创建），灵活性更高。</p><h4>核心实现代码</h4><p>创建 <code>ShortcutsUtils</code> 工具类，封装动态添加快捷方式的逻辑，包含权限校验、重复判断和创建请求：</p><pre><code class="typescript">import { hilog } from "@kit.PerformanceAnalysisKit";
import { BusinessError } from "@kit.BasicServicesKit";
import { productViewManager } from "@kit.StoreKit";
import { common, Want } from "@kit.AbilityKit";
import promptAction from '@ohos.promptAction';

export class ShortcutsUtils {
  /**
   * 点击按钮添加快捷方式
   */
  static addShortcuts() {
    const uiContext = getContext() as common.UIAbilityContext;
    const shortcutId = "id_test1"; // 需与 shortcuts_config.json 中定义的一致
    const labelResName = "shortcut"; // 对应 label 的资源索引名称
    const iconResName = "aa_icon"; // 对应 icon 的资源索引名称
    const want: Want = {
      bundleName: "com.example.appgallery.kit.demo",
      moduleName: "entry",
      abilityName: "EntryAbility",
      parameters: {
        testKey: "testValue" // 自定义参数
      }
    };

    try {
      // 校验快捷方式是否可添加（是否已存在、是否有权限）
      productViewManager.checkPinShortcutPermitted(uiContext, shortcutId, want, labelResName, iconResName)
        .then((result) =&gt; {
          hilog.info(0x0001, 'addShortcuts', `校验成功：${JSON.stringify(result)}`);
          const tid = result.tid;
          // 发起添加快捷方式请求
          productViewManager.requestNewPinShortcut(uiContext, tid)
            .then(() =&gt; {
              hilog.info(0x0001, 'addShortcuts', "快捷方式添加成功！");
            })
            .catch((error: BusinessError) =&gt; {
              hilog.error(0x0001, 'addShortcuts', `快捷方式添加失败：${error.code}, ${error.message}`);
            });
        })
        .catch((error: BusinessError) =&gt; {
          hilog.error(0x0001, 'addShortcuts', `err：${error.code}, ${error.message}`);
          // 错误码 1006620003 表示快捷方式已存在
          if (error.code === 1006620003) {
            promptAction.showToast({ message: '桌面已存在此快捷方式！' });
          }
        });
    } catch (err) {
      hilog.error(0x0001, 'TAG', `catch err：${err.code}, ${err.message}`);
    }
  }
}</code></pre><h4>使用方式</h4><p>在应用页面的按钮点击事件中调用工具类方法，即可触发快捷方式添加流程：</p><pre><code class="typescript">// 示例：按钮点击事件
Button('添加测试快捷方式')
  .onClick(() =&gt; {
    ShortcutsUtils.addShortcuts();
  })</code></pre><p>productViewManager允许应用添加快捷方式的数量为两个。这是鸿蒙官方的设计如此。</p><h3>三、两种快捷方式的区别与适用场景</h3><table><thead><tr><th>类型</th><th>配置方式</th><th>灵活性</th><th>适用场景</th></tr></thead><tbody><tr><td>静态快捷方式</td><td>配置文件定义</td><td>较低（固定功能）</td><td>高频固定功能，如导航、新建、快速拍照</td></tr><tr><td>动态快捷方式</td><td>代码动态添加</td><td>较高（用户触发）</td><td>个性化功能，如用户自定义收藏、临时高频功能</td></tr></tbody></table>]]></description></item><item>    <title><![CDATA[【赵渝强老师】OceanBase的连接与]]></title>    <link>https://segmentfault.com/a/1190000047400537</link>    <guid>https://segmentfault.com/a/1190000047400537</guid>    <pubDate>2025-11-14 18:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>OceanBase数据库连接路由管理组件ODP（OceanBase Database Proxy）是OceanBase数据库专用的连接路由管理集群。OceanBase数据库用户的数据会以多副本的形式存放在各个OBServer节点上，ODP接收用户发出的SQL请求，并将SQL请求转发至最佳目标OBServer节点，最后将执行结果返回给用户。</p><h2>一、 ODP简介</h2><p>OceanBase数据库与传统单机数据库不同，OceanBase数据库是分布式数据库，每个表甚至每个表的不同分区都可能存放在不同的机器上。想要对表进行读写，必须先要定位到数据所属的表或是分区的主副本位置，然后才能执行相应的SQL语句，这在应用层面而言是几乎不可能做到的。ODP作为OceanBase数据库专用的反向代理软件，其核心功能是路由，将客户端发起的数据访问请求转发到正确的OBServer节点上，并将OBServer节点的响应结果转发给客户端。视频讲解如下：<br/><a href="https://www.bilibili.com/video/BV1kcCbB4Ei2/?aid=115542555893412&amp;cid=33978453859" target="_blank">https://www.bilibili.com/video/BV1kcCbB4Ei2/?aid=115542555893...</a></p><p>作为OceanBase数据库的关键组件，ODP具有以下特性：</p><ul><li><strong>连接管理</strong>：针对一个客户端的物理连接，ODP维持自身到后端多个OBServer节点的连接，并维持了每个OBServer节点连接的会话状态，保证了客户端高效访问各个OBServer节点。</li><li><strong>最佳路</strong>由：ODP充分考虑用户请求涉及的副本位置、用户配置的读写分离路由策略、OceanBase多地部署的最优链路，以及OceanBase各机器的状态及负载情况，将用户的请求路由到最佳的OBServer节点，最大程度地保证了OceanBase整体的高性能运转。</li><li><strong>高性能转发</strong>：ODP完整兼容MySQL协议，并支持OceanBase自研协议，采用多线程异步框架和透明流式转发的设计，保证了数据的高性能转发，同时确保了自身对机器资源的最小消耗。</li><li><strong>易运维</strong>：ODP本身无状态，支持无限水平扩展，支持同时访问多个OceanBase集群。可通过丰富的内部命令对ODP状态进行实时监控，这使得运维简单便利。</li><li><strong>高可用</strong>：ODP高可用分为两部分：一方面保证自身高可用，持续提供代理服务；另一方面ODP是OceanBase高可用体系的主要组成部分，可以对用户屏蔽宕机、升级等情况，保证OceanBase数据库服务的稳定和快速恢复。</li><li><strong>专有协议</strong>：ODP与OBServer节点默认采用了OceanBase专有协议，如增加报文的CRC校验保证与OBServer节点链路的正确性，增强传输协议以支持Oracle兼容性的数据类型和交互模型。</li></ul><p>客户端通过ODP访问OceanBase数据库的数据链路如下图所示。<br/><img width="723" height="460" referrerpolicy="no-referrer" src="/img/bVdmYFf" alt="image.png" title="image.png"/></p><h2>二、 使用ODP连接数据库集群</h2><p>部署好ODP集群后，便可以通过OBProxy连接OceanBase数据库集群了，下面是具体的操作步骤。<br/>（1）在中控机上执行命令查看集群的节点信息。</p><pre><code class="powershell">obd cluster display myob-cluster

# 输出的信息如下：
......
Connect to obproxy ok
+-------------------------------------------------------------------+
|                             obproxy-ce                            |
+---------------+------+-----------------+-----------------+--------+
| ip            | port | prometheus_port | rpc_listen_port | status |
+---------------+------+-----------------+-----------------+--------+
| 192.168.79.11 | 2883 | 2884            | 2885            | active |
| 192.168.79.13 | 2883 | 2884            | 2885            | active |
+---------------+------+-----------------+-----------------+--------+
obclient -h192.168.79.11 -P2883 -uroot@proxysys -p'Welcome_1' -Doceanbase -A 
......

# 提示：从输出的信息可以看出，ODP集群中包含两台OBProxy，
# 它们分别运行在：192.168.79.11和192.168.79.13主机上。</code></pre><p>（2）登录192.168.79.11主机，查看OBProxy的目录结构。</p><pre><code class="powershell">tree /root/obproxy/ -L 1

# 输出的信息如下：
/root/obproxy/
├── bin                    保存ODP的可执行二进制文件
├── control-config
├── etc                    保存配置信息的目录
├── lib
├── log                    保存日志文件的目录
├── obproxyd.sh            OBProxy的守护进程
├── run                    保存OBProxy启动的进程号信息
└── sharding-config        保存Sharding（分片）相关的配置文件

# 提示：如果OBProxy进程不存在，或者异常宕机。
# obproxyd.sh脚本负责重新启动OBProxy进程。</code></pre><p>（3）通过操作的的ps命令可以查看到OBProxy的进程信息。</p><pre><code class="powershell">ps -ef | grep obproxy

# 输出的信息如下：
root  4895 ... bash /root/obproxy/obproxyd.sh /root/obproxy 192.168.79.11 2883 daemon
root  4904 ... /root/obproxy/bin/obproxy --listen_port 2883
root 10892 ... grep obproxy

# 提示：这里的进程号4895与4904与run目录下的进程号文件保持一致，如下所示：
[root@node11 obproxy]# ls run/
obproxy-192.168.79.11-2883.pid  obproxyd-192.168.79.11-2883.pid
[root@node11 obproxy]# cat run/*
4904
4895</code></pre><p>（4）通过OBProxy连接OceanBase数据库集群</p><pre><code class="powershell">obclient -h192.168.79.11 -P2883 -uroot@sys#myob-cluster -pWelcome_1 -Doceanbase -A

# 提示：该命令也可以简写成下面的形式：
obclient -h192.168.79.11 -P2883 -uroot -pWelcome_1 -Doceanbase -A

# 此时如果出现下面的错误：
ERROR 2013 (HY000): 
Lost connection to MySQL server at 'reading authorization packet', 
system error: 11

# 这是由于集群配置信息中的proxyro_password不一致造成。</code></pre><p>（5）在中控机上执行下面的命令编辑集群的配置信息。</p><pre><code class="powershell">obd cluster edit-config myob-cluster</code></pre><p>（6）将global下的proxyro_password修改为正确的密码，保存并退出。</p><pre><code class="powershell">  global:
    ......
    root_password: Welcome_1
    appname: myob-cluster
    ocp_agent_monitor_password: ztkrtULS7u
    proxyro_password: YqNSd87E3K
    ......
    
  修改为：
  
  global:
    ......
    root_password: Welcome_1
    appname: myob-cluster
    ocp_agent_monitor_password: ztkrtULS7u
    proxyro_password: Welcome_1
    ......</code></pre><p>（7）重新加载配置信息。</p><pre><code class="powershell">obd cluster reload myob-cluster</code></pre><p>（8）通过OBProxy连接OceanBase数据库集群</p><pre><code class="powershell">obclient -h192.168.79.11 -P2883 -uroot@sys#myob-cluster -pWelcome_1 -Doceanbase -A

ob&gt; show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| LBACSYS            |
| mysql              |
| oceanbase          |
| ocs                |
| ORAAUDITOR         |
| scott              |
| SYS                |
| sys_external_tbs   |
| test               |
+--------------------+
10 rows in set (0.011 sec)</code></pre><h2>三、 查看ODP配置属性</h2><p>通过使用root@sys用户通过ODP代理登录OceanBase数据库，或使用root@proxysys用户登录ODP均可以查看ODP的配置参数。下面是具体的操作步骤：<br/>（1）执行命令登录OceanBase数据库或者ODP</p><pre><code class="powershell"># 登录OceanBase数据库
obclient -h192.168.79.11 -P2883 -uroot@sys#myob-cluster -pWelcome_1 -Doceanbase -A

# 登录ODP
obclient -h192.168.79.11 -P2883 -uroot@proxysys -p'Welcome_1' -Doceanbase -A</code></pre><p>（2）查看ODP的参数配置。</p><pre><code class="powershell">ob&gt; show proxyconfig \G;

# 输出的信息如下：
......
*************************** 326. row ***************************
         name: json_config_cluster_count
        value: 1
         info: ob cluster count, meta db cluster not included
  need_reboot: false
visible_level: virtual
        range: NULL
 config_level: NULL
*************************** 327. row ***************************
         name: json_config_modified_time
        value: 2025-04-15 14:12:20.271644
         info: json config modified time
  need_reboot: false
visible_level: virtual
        range: NULL
 config_level: NULL
327 rows in set (0.012 sec)</code></pre><p>（3）使用like关键字查看ODP的参数配置。</p><pre><code class="powershell">ob&gt; show proxyconfig like '%full%'\G;

# 输出的信息如下：
*************************** 1. row ***************************
         name: enable_full_username
        value: False
        info: used for non-cloud user, if set true, username must have tenant and cluster
  need_reboot: false
visible_level: SYS
        range: 
 config_level: LEVEL_GLOBAL
*************************** 2. row ***************************
         name: enable_cloud_full_username
        value: False
         info: used for cloud user, if set false, treat all login user as username
  need_reboot: false
visible_level: SYS
        range: 
 config_level: LEVEL_VIP
*************************** 3. row ***************************
         name: enable_full_link_trace
        value: False
         info: if enable proxy will use full link trace to trace query execution
  need_reboot: false
visible_level: USER
        range: 
 config_level: LEVEL_GLOBAL
3 rows in set (0.009 sec)</code></pre><p>（4）执行select * from proxy_config命令查看配置参数。</p><pre><code class="powershell">ob&gt; select * from proxy_config;

# 输出信息如下：
+---------------------------------+-----------------+--------------+
......                                              
| server_state_refresh_interval   | 20s             | LEVEL_GLOBAL |
| cache_cleaner_clean_interval    | 20s             | LEVEL_GLOBAL |
| proxy_hot_upgrade_check_interval| 5s              | LEVEL_GLOBAL |
| proxy_info_check_interval       | 60s             | LEVEL_GLOBAL |
| refresh_config                  | False           | LEVEL_GLOBAL |
| refresh_idc_list                | False           | LEVEL_GLOBAL |
| refresh_rslist                  | False           | LEVEL_GLOBAL |
| refresh_json_config             | False           | LEVEL_GLOBAL |
| enable_xa_route                 | True            | LEVEL_GLOBAL |
| observer_sys_password           | d809d427528be882| LEVEL_GLOBAL |
+---------------------------------+-----------------+--------------+
319 rows in set (0.056 sec)

# 提示：该命令仅在使用root@proxysys用户登录ODP时可执行，其他用户下执行会报错。</code></pre><h2>四、 修改ODP配置属性</h2><p>修改ODP配置属性的值可以通过以下两种方式实现：</p><ul><li>在ODP运行时，使用root@proxysys用户登录ODP后，执行alter proxyconfig命令修改ODP配置项。</li><li>在ODP启动时，启动命令中添加-o选项修改配置项。</li></ul><p>这里以配置属性enable_cluster_checkout为例来进行演示。该属性用于控制是否进行集群名称校验，默认值是False。如果启用集群校验，在登录时ODP会发送集群名称，服务器会对其进行检查。下面是具体的操作步骤。</p><h3>方式一：通过alter proxyconfig命令</h3><p>（1）登录ODP</p><pre><code class="powershell">obclient -h192.168.79.11 -P2883 -uroot@proxysys -pWelcome_1</code></pre><p>（2）查看配置属性enable_cluster_checkout的值。</p><pre><code class="powershell">ob&gt; show proxyconfig like 'enable_cluster_checkout' \G;

# 输出信息如下：
*************************** 1. row ***************************
         name: enable_cluster_checkout
        value: False
         info: if enable cluster checkout, proxy will send cluster 
               name when login and server will check it
  need_reboot: false
visible_level: USER
        range: 
 config_level: LEVEL_GLOBAL
1 row in set (0.002 sec)</code></pre><p>（3）通过alter proxyconfig命令修改属性。</p><pre><code class="powershell">ob&gt; alter proxyconfig set enable_cluster_checkout=True;</code></pre><p>（4）重新查看配置属性enable_cluster_checkout的值。</p><pre><code class="powershell">ob&gt; show proxyconfig like 'enable_cluster_checkout' \G;

# 输出信息如下：
*************************** 1. row ***************************
         name: enable_cluster_checkout
        value: True
         info: if enable cluster checkout, proxy will send cluster 
               name when login and server will check it
  need_reboot: false
visible_level: USER
        range: 
 config_level: LEVEL_GLOBAL
1 row in set (0.002 sec)</code></pre><h3>方式二：通过启动命令的-o选项</h3><p>（1）在中控机上执行命令查看集群的节点信息。</p><pre><code class="powershell">obd cluster display myob-cluster

# 输出的信息如下：
......
Connect to obproxy ok
+-------------------------------------------------------------------+
|                             obproxy-ce                            |
+---------------+------+-----------------+-----------------+--------+
| ip            | port | prometheus_port | rpc_listen_port | status |
+---------------+------+-----------------+-----------------+--------+
| 192.168.79.11 | 2883 | 2884            | 2885            | active |
| 192.168.79.13 | 2883 | 2884            | 2885            | active |
+---------------+------+-----------------+-----------------+--------+
obclient -h192.168.79.11 -P2883 -uroot@proxysys -p'Welcome_1' -Doceanbase -A 
......</code></pre><p>（2）以192.168.79.11主机上的OBProxy为例，查看OBProxy进程信息并停止OBProxy</p><pre><code class="powershell">ps -ef|grep obproxy

# 输出信息如下：
Root 7574 1 ... bash /root/obproxy/obproxyd.sh /root/obproxy 192.168.79.11 2883 daemon
root 7583   1  ... /root/obproxy/bin/obproxy --listen_port 2883
root 11441 5714  ... grep obproxy

# 停止obproxy 进程和obproxyd进程
kill -9 7574
kill -9 7583

# 提示：obproxyd进程也需要停止。
# 否则当obproxy进程停止后，obproxyd会自动重启obproxy进程。</code></pre><p>（3）重启OBProxy，并通过-o选项修改配置参数的值。</p><pre><code class="powershell">cd /root/obproxy/
bin/obproxy -p 2883 -r'192.168.79.11:2881;192.168.79.12:2881;192.168.79.13:2881' \
  -o enable_cluster_checkout=True -c myob-cluster</code></pre><p>（4）连接OBProxy确认配置参数已修改。</p><pre><code class="powershell">obclient -h192.168.79.11 -P2883 -uroot@proxysys -pWelcome_1

ob&gt; show proxyconfig like 'enable_cluster_checkout' \G;

# 输出的信息如下：
*************************** 1. row ***************************
         name: enable_cluster_checkout
        value: True
         info: if enable cluster checkout, proxy will send 
               cluster name when login and server will check it
  need_reboot: false
visible_level: USER
        range: 
 config_level: LEVEL_GLOBAL
1 row in set (0.009 sec)</code></pre>]]></description></item><item>    <title><![CDATA[经销商管理系统小程序：高效赋能企业渠道管]]></title>    <link>https://segmentfault.com/a/1190000047400152</link>    <guid>https://segmentfault.com/a/1190000047400152</guid>    <pubDate>2025-11-14 17:12:57</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><strong>一、概述总结</strong><br/>这款经销商管理系统小程序是专为生产销售企业、微商团队打造的渠道管理工具。它以微擎系统为交付基础，提供在线交付服务，具备官方正品保障，且所有功能支持自由配置，能适配不同类型企业的个性化需求。系统核心聚焦经销商管理与授权认证，同时整合多元实用功能，助力企业简化管理流程、规范经销商体系，提升渠道运营效率。</p><p><strong>二、功能介绍</strong><br/>经销商管理：构建完善的经销商管理体系，涵盖经销商档案创建与维护，实现对经销商信息的集中化、规范化管理。</p><p>授权相关功能：支持授权查询、授权证生成，同时对接微商系统，满足企业对经销商授权认证的全流程需求。</p><p>上下级推荐：内置经销商上下级推荐机制，助力企业拓展经销商网络，优化渠道布局。</p><p>关注海报功能：附带关注海报生成能力，为企业及经销商提供便捷的品牌传播与推广工具。</p><p><strong>三、适用场景与行业价值</strong><br/>适用场景<br/>生产销售企业：适用于各类有渠道经销商的生产厂家、销售公司，用于管理全国或区域经销商团队。</p><p>微商团队：适配不同规模的微商品牌与团队，满足其多层级经销商管理、授权认证的核心需求。</p><p>行业价值<br/>简化管理流程：通过功能模块化与配置自由化，减少人工操作成本，让经销商管理更高效。</p><p>规范授权体系：清晰的授权查询与证书生成功能，避免授权混乱，保障企业与经销商的合法权益。</p><p>助力渠道拓展：上下级推荐功能为企业拓宽经销商来源，搭配关注海报功能，提升品牌传播与渠道扩张效率。</p><p>适配多元需求：支持功能自由配置，无论是小型初创企业还是大型成熟品牌，都能找到贴合自身的使用方案。</p><p><strong>四、问答环节</strong><br/>问：这款经销商管理系统小程序支持哪些交付方式？</p><p>答：支持在线交付，基于微擎系统完成交付流程。</p><p>问：系统是否适合小型微商团队使用？</p><p>答：适合，系统所有功能可自由配置，能适配不同规模的微商团队及各类企业的需求。</p><p>问：系统能否生成经销商授权证书？</p><p>答：可以，系统具备授权证生成功能，同时支持授权查询，满足授权管理需求。</p><p>问：除了经销商管理，系统还有哪些辅助功能？</p><p>答：包含上下级推荐、关注海报、微商系统对接等功能，兼顾渠道拓展与品牌传播需求。</p>]]></description></item><item>    <title><![CDATA[芒果疯狂霸屏小程序：抖音 + 微信双平台]]></title>    <link>https://segmentfault.com/a/1190000047400157</link>    <guid>https://segmentfault.com/a/1190000047400157</guid>    <pubDate>2025-11-14 17:12:10</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><strong>一、概述总结</strong><br/>芒果疯狂霸屏是一款基于微擎系统开发，融合抖音开放平台接口的新型商户引流拓客工具。它支持微信公众号部署，通过 AI 自动化视频合成技术，让终端客户扫码即可一键转发商家预设视频至抖音，帮助商家低成本实现精准获客。产品提供源码交付服务，搭配多档运营套餐与完善的素材支持，操作简单易上手，商户接受度高，同时保障服务周期内的免费更新，满足不同规模商户的引流需求。</p><p><strong>二、功能介绍</strong><br/>核心视频合成功能<br/>后台可上传视频、图片、音频等多元素材，AI 自动完成分割、加特效、合成及音频插入操作。</p><p>独家合成机制有效减少服务器压力，无需高配置即可稳定运行，同时解决视频去重问题。</p><p>合成视频可随机发布，搭配抖音平台传播优势，提升曝光效率。</p><p>引流拓客与运营功能<br/>终端客户一键扫码即可转发商家预设抖音视频，操作便捷降低参与门槛。</p><p>支持卡券模式与纯推广模式，卡券模式可引导用户领取卡券后跳转其他功能，纯推广模式直接跳转商家抖音主页。</p><p>后台具备完善的用户管理、商家管理、活动管理功能，可统计用户数量、商家数量、活动数据，支持新增活动、绑定商家、设置核销员等操作。</p><p>配套支持功能<br/>提供丰富运营素材，包括招商 PPT、展架、引导图片、宣传网站源文件、宣传视频等十余类资料。</p><p>支持增值服务，涵盖服务器环境部署、模块安装、二次开发、抖音蓝 V 认证等。</p><p>兼容 PHP5.5、PHP5.6、PHP7.1 版本，采用在线交付方式，源码加密保障官方正品权益。</p><p><strong>三、适用场景与行业价值</strong><br/>适用场景<br/>线下实体门店：包括餐饮、装饰、零售等需要本地精准引流的店铺，通过客户自发转发视频扩大门店影响力。</p><p>创业者与服务商：可通过包月、包年、代理授权等模式开展业务，为商户提供引流服务赚取收益。</p><p>各类营销活动：适用于门店开业、新品推广、节日促销等场景，通过视频传播 + 卡券激励提升活动参与度。</p><p>行业价值<br/>降低引流成本：无需大额广告投入，借助用户社交传播实现 “裂变式” 获客，提升获客性价比。</p><p>提升操作效率：商户无需专业视频制作能力，AI 自动化合成减少人力成本，终端用户操作简单促进参与率。</p><p>拓展盈利模式：为创业者提供多档运营方案，从基础服务到代理授权、团队收购，满足不同阶段发展需求。</p><p>精准对接流量：依托抖音平台流量优势与微信生态传播渠道，实现线上流量向线下门店的精准转化。</p><p><strong>四、常见问答环节</strong><br/>问：该系统适用于什么平台？</p><p>答：适用于微信公众号，需基于微擎系统部署，同时对接抖音开放平台实现视频传播功能。</p><p>问：使用系统前需要准备什么？</p><p>答：需申请抖音开放平台账号，商家可自行申请，平台会提供相关申请方案。</p><p>问：若抖音开放平台参数修改，系统无法使用该怎么办？</p><p>答：因抖音开放平台参数调整导致系统不可用，芒果团队不承担责任，不同意此条款请勿购买。</p><p>问：转发视频会对终端用户产生影响吗？</p><p>答：系统活动需提前告知商户及终端用户，视频会转发至用户抖音作品，未告知引发的后果由程序购买者承担。</p>]]></description></item><item>    <title><![CDATA[开源之谜：是理想乌托邦，还是商业新战略？]]></title>    <link>https://segmentfault.com/a/1190000047400161</link>    <guid>https://segmentfault.com/a/1190000047400161</guid>    <pubDate>2025-11-14 17:11:26</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在软件吞噬世界的今天，开源软件已成为不可或缺的基础设施。然而，围绕它的误解与困惑从未停止。它究竟是程序员理想主义的乌托邦，还是商业世界精心设计的战略？我们将通过一系列问题，揭开开源软件的层层面纱。</p><p><strong>第一问：开源软件是“用爱发电”的公益项目吗？</strong></p><p><strong>答：不，可持续的开源根本上是“商业驱动的现实主义”。</strong></p><p>许多人被开源的“开放、共享”精神所感动，认为这源于无私的奉献。然而，绝大多数能够长期存在并流行的开源项目，其根本动力是<strong>广义的盈利</strong>。这里的“盈利”并非单指软件授权的直接收入，而是指确保项目主导者（个人或企业）能够获得维持生存与发展的资源。</p><p>这包括：</p><ul><li><strong>个人作者</strong>：通过开源建立声誉，从而获得高薪工作、咨询合同、捐赠或赞助。</li><li><strong>创业公司</strong>：通过开源项目获取大量用户，再通过提供付费的企业版功能、云托管服务（SaaS）、技术支持或培训来赚钱。这就是经典的 <strong>“Open Core”（开源核心）</strong> 模式。</li><li><strong>科技巨头</strong>：通过开源来建立行业标准，降低整个生态的开发成本，从而更好地销售自己的云服务或硬件产品。</li></ul><p>没有可持续的收入来源，任何个体或组织都难以在漫长的岁月中持续投入巨大的研发和运维成本。<strong>“为爱发电”可以启动一个项目，但商业回报才能让它茁壮成长。</strong></p><p><strong>第二问：既然最终要收费，开源对客户有何实际意义？</strong></p><p><strong>答：开源为客户提供了“确定性与灵活性”，这是一种深层的商业价值。</strong></p><p>客户的核心诉求是“付钱解决问题”，这没错。但开源如何帮助客户更好地实现这一目标呢？</p><ol><li><strong>避免供应商锁定</strong>：如果软件是闭源的，客户就被牢牢绑定在单一供应商身上。对方可以随意提价、降低服务质量，客户却毫无还手之力。开源软件确保了客户<strong>永远拥有选择的自由</strong>。如果服务商A不满意，客户可以轻松切换到服务商B，甚至可以自己组织团队进行维护。</li><li><strong>供应链的确定性</strong>：开源代码是“不可撤回”的公共资产。这意味着，一旦客户基于某个开源版本构建了系统，就不会因为原公司倒闭、改变策略或停止更新而瞬间导致业务崩溃。这为企业的技术选型提供了<strong>最底层的安全感和确定性</strong>。</li><li><strong>透明与安全</strong>：代码可见意味着客户（或其委托的专家）可以自行审查安全性，确保没有隐藏的后门或致命漏洞。</li></ol><p>对于客户而言，开源并非一个虚无的口号，而是一个<strong>强大的议价工具和风险对冲工具</strong>。</p><p><strong>第三问：开源项目真的“人人平等”吗？为何总是少数人主导？</strong></p><p><strong>答：事实上的开源项目，尤其是成功的大型项目，几乎都是“精英治理”和“方法论专政”。</strong></p><p>观察GitHub上流行项目的提交图，我们会发现一个普遍现象：绝大部分代码贡献来自于极少数核心维护者。这并非偶然，而是由两个核心因素决定的：</p><ol><li><strong>能力的极端稀缺</strong>：主导一个流行的开源软件，需要主导者具备超凡的<strong>问题分析、架构抽象、模块拆解、社区治理和商业洞察</strong>等综合能力。这种“复合型天才”本身就是凤毛麟角。</li><li><strong>方法论的统一性</strong>：一个成功的开源软件，本质上是一套解决特定领域问题的、高度自洽的<strong>方法论的代码实践</strong>。项目的方向和架构，必须由这套方法论的创立者或核心理解者来把握，否则项目就会陷入混乱和分歧。</li></ol><p>因此，开源社区并非纯粹的民主制，而更像是“仁慈的独裁者”或“核心委员会”制度。这种集中式的决策机制，是保证项目在复杂性和规模增长中保持<strong>方向一致性和代码质量</strong>的关键。</p><p><strong>第四问：既然代码公开，开源作者不怕被竞争对手抄袭吗？</strong></p><p><strong>答：不怕。因为真正的护城河不是代码，而是“生态与方法论”。</strong></p><p>抄袭一个开源项目，看似简单，实则愚蠢。原因如下：</p><ul><li><strong>方法论之争</strong>：顶尖的竞争对手之间，往往存在着根本性的<strong>方法论分歧</strong>。让一个信奉A方法的团队，去全盘抄袭基于B方法构建的项目，无异于让其自我否定，这在技术和文化上都极其困难。</li><li><strong>生态系统的力量</strong>：一个成熟的开源项目，其价值远不止代码。它拥有庞大的用户社区、丰富的文档、海量的问答、成熟的工具链和认证的服务商。抄袭者能复制代码，但无法复制这整个<strong>活的生态系统</strong>。用户选择某个开源软件，正是因为信任这个生态带来的整体价值。</li><li><strong>分叉的代价</strong>：历史上，因社区内讧而“分叉”的项目很多，但能取代原项目成为新事实标准的，寥寥无几。分叉意味着社区分裂、资源分散，是一场伤筋动骨的“内战”。除非原主导层犯下致命错误且拒绝改正，否则分叉很难成功。</li></ul><p><strong>结论：开源——一场精心设计的“阳谋”</strong></p><p>经过以上层层剖析，我们可以清晰地看到，现代开源运动并非一场纯粹的理想主义盛宴，而是一套极其精妙的商业和社会协作模型。</p><p>它是一场“阳谋”：主导者光明正大地公开核心代码，通过吸引用户、构建生态、确立标准，最终在服务、支持和增值领域建立起难以撼动的护城河。在这个过程中，<strong>主导者实现了商业上的可持续回报，客户获得了自由和确定性，整个行业则因为知识的共享和协作而加速创新。</strong></p><p>这正是一种多赢的格局——开源，用开放的姿态，成就了最稳固的商业壁垒，并最终推动了整个数字世界的进步。它既是理想主义的火花，也是现实主义的选择，二者的结合，正是其强大生命力的源泉。</p>]]></description></item><item>    <title><![CDATA[步数运动宝 QQ 版本：步数变现 + 裂]]></title>    <link>https://segmentfault.com/a/1190000047400163</link>    <guid>https://segmentfault.com/a/1190000047400163</guid>    <pubDate>2025-11-14 17:10:49</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>步数运动宝 QQ 版本是一款适配微信、QQ、抖音等多平台的小程序系统，以 “运动步数” 为核心纽带，融合步数兑换、任务赚币、夺宝互动、商城购物等功能，既满足用户运动变现需求，又为商家提供爆炸式吸粉与营销转化解决方案，是兼具趣味性与商业价值的轻量化工具。</p><p><strong>一、概述总结</strong><br/>步数运动宝 QQ 版本通过将用户日常运动步数转化为可流通的 “活力币 / 步币”，构建起 “运动 - 赚币 - 兑换 - 分享” 的完整闭环。用户可通过签到、走步、看视频、邀请好友等方式积累虚拟货币，兑换现金红包、实物商品或参与夺宝活动；商家则借助步数砍价、邀请裂变、广告植入等功能实现快速吸粉、用户留存与收益增长。系统支持高度自定义配置，适配线上线下多场景营销，且提供微擎系统加密交付与持续更新服务，兼顾安全性与实用性。</p><p><strong>二、核心功能介绍</strong><br/>步数变现与兑换体系<br/>步数直接兑换活力币，支持微信现金红包、实物商品（如榨汁机、电影票）、虚拟道具（迷你币）等多类型兑换。</p><p>创新 “砍步数” 机制，用户可邀请好友助力减少兑换所需步数，强制裂变引流。</p><p>设置兑换门槛，可要求邀请指定数量新用户或完成特定任务，提升转化质量。</p><p>互动营销与夺宝玩法<br/>幸运转盘、运动币夺宝、免币夺宝三大互动模块，用户消耗步数或观看激励视频即可参与，奖品涵盖手机、现金红包等，增强用户粘性。</p><p>每日签到、答题闯关、试玩任务等领币渠道，丰富用户赚币路径，延长使用时长。</p><p>支持激励视频、插屏广告植入，为商家开辟额外创收途径。</p><p>裂变吸粉与用户运营<br/>邀请好友奖励机制，成功邀请可获得 3-10 活力币，部分商品兑换需邀请数十名新用户，实现粉丝几何级增长。</p><p>好友排行、全国榜单等社交互动功能，激发用户竞争与分享意愿。</p><p>支持关注公众号解锁提现、领取口令等功能，完成私域流量沉淀。</p><p>商城与线下核销功能<br/>内置步数换购商城，涵盖食品、美妆、电器等多品类商品，支持 “活力币兑换”“活力币 + 现金” 混合支付。</p><p>线上下单、到店自提模式，生成专属核销码，实现线上引流与线下实体交易的无缝衔接。</p><p>库存管理功能，支持每日限购与总计库存设置，灵活控制营销成本。</p><p>高度自定义配置<br/>导航栏、UI 界面、签到规则、红包金额、提现门槛等核心参数均可自定义，适配不同商家需求。</p><p>防撸羊毛机制内置，保障营销活动公平性，避免资源浪费。</p><p>支持第三方发货、关联店铺、商品分类管理等商家实用功能，简化运营流程。</p><p><strong>三、适用场景与行业价值</strong><br/>适用场景<br/>本地生活服务：餐饮、零售、影院、景区等线下门店，用于到店引流与到店核销。</p><p>电商平台：拼多多等电商渠道优惠券发放、商品促销，提升下单转化率。</p><p>品牌营销：需要快速积累用户的新品牌、新 APP，通过低成本裂变实现冷启动。</p><p>健身运动类产品：与运动场景深度绑定，提升用户活跃度与留存率。</p><p>公众号 / 自媒体：作为涨粉工具，快速积累私域流量，提升账号商业价值。</p><p>行业价值<br/>低成本吸粉：以步数为零成本载体，通过趣味玩法与实际奖励，实现单日数百甚至数万新用户增长，案例中商家单月吸粉超 50 万。</p><p>高用户粘性：将运动习惯与奖励激励结合，用户每日签到、走步、互动，形成稳定使用惯性。</p><p>多维度收益：融合商品销售、广告植入、线下引流转化等收益渠道，实现 “吸粉 - 留存 - 变现” 闭环。</p><p>线上线下融合：打通线上流量与线下实体交易，为实体店解决获客难问题，提升到店率。</p><p><strong>四、常见问题问答</strong><br/>问：用户如何获取活力币 / 步币？答：主要通过每日签到、运动步数兑换、邀请好友、观看激励视频、参与答题闯关或试玩任务等方式获取。</p><p>问：商家可以自定义哪些核心规则？答：可自定义兑换门槛、邀请好友数量要求、签到奖励金额、红包设置、提现规则、UI 界面、商品库存与限购数量等。</p><p>问：系统是否支持线下门店使用？</p><p>答：支持，用户线上下单后可选择到店自提，生成核销码后到店出示即可完成核销，实现线上引流线下消费。</p><p>问：购买后商家能获得哪些服务保障？</p><p>答：提供微擎系统在线交付，源码加密保障安全，服务周期内可免费更新，支持 PHP5.6、PHP7.1 运行环境，工作日 9:00-18:00 卖家服务支持。</p><p>问：“砍步数” 功能如何帮助商家吸粉？答：用户兑换部分商品时需邀请好友助力砍步数，好友需为新用户，且需贡献一定比例步数，强制触发社交分享，快速裂变新用户。</p>]]></description></item><item>    <title><![CDATA[智慧城市 O2O 分销系统：连接城市服务]]></title>    <link>https://segmentfault.com/a/1190000047400174</link>    <guid>https://segmentfault.com/a/1190000047400174</guid>    <pubDate>2025-11-14 17:09:50</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><strong>一、概述总结</strong><br/>智慧城市 O2O 分销系统是基于微擎系统开发的数字化工具，专注于智慧城市场景下的 O2O 业务分销需求。系统以在线交付为核心交付方式，提供未加密源码保障，确保官方正品品质，支持用户新购使用。它打破传统城市服务分销的地域与渠道限制，通过数字化手段搭建起高效的分销桥梁，助力相关主体快速布局智慧城市 O2O 业务，实现资源整合与高效流转。</p><p><strong>二、功能介绍</strong><br/>分销核心功能：适配智慧城市 O2O 场景，支持多渠道分销链路搭建，满足不同层级分销需求。</p><p>便捷交付体验：采用在线交付模式，购买后可快速获取系统，无需复杂线下流程，提升使用效率。</p><p>源码灵活优势：提供未加密源码，用户可根据自身业务需求进行二次开发与定制，适配个性化场景。</p><p>品质保障机制：依托官方正品保障，确保系统稳定性与安全性，减少使用过程中的技术风险。</p><p><strong>三、适用场景与行业价值</strong><br/>适用场景<br/>城市生活服务运营商：用于整合本地餐饮、家政、出行等生活服务资源，通过分销模式扩大服务覆盖范围。</p><p>智慧城市项目服务商：为智慧社区、智慧交通、智慧医疗等细分领域的项目，搭建分销渠道与推广网络。</p><p>区域商业运营主体：助力商圈、产业园区等实现线下资源线上化分销，打通服务触达用户的 “最后一公里”。</p><p>行业价值<br/>降低运营成本：数字化分销模式减少中间环节，降低渠道拓展与维护的人力、时间成本。</p><p>提升业务覆盖：打破地域限制，快速整合分散的城市服务资源，扩大业务辐射范围与市场份额。</p><p>增强灵活适配：未加密源码支持定制化开发，可根据不同智慧城市细分场景的需求调整功能，提升适配性。</p><p>保障合作信任：官方正品保障为合作双方提供安全背书，降低合作风险，提升业务推进效率。</p><p><strong>四、问答环节</strong><br/>问：该智慧城市 O2O 分销系统的交付方式是什么？</p><p>答：系统采用微擎在线交付方式，购买后可快速获取使用，无需线下交接流程。</p><p>问：系统源码是否支持二次开发？</p><p>答：支持。系统源码未加密，用户可根据自身业务需求进行二次开发与定制调整。</p><p>问：使用该系统能获得哪些品质保障？</p><p>答：系统提供官方正品保障，确保系统的稳定性、安全性与合规性，减少使用过程中的技术与合规风险。</p><p>问：该系统主要适配哪些业务场景？</p><p>答：主要适配智慧城市相关的 O2O 业务场景，包括城市生活服务分销、智慧社区项目推广、区域商业资源整合等。</p>]]></description></item><item>    <title><![CDATA[如何评估CRM软件是否适配长销售周期的业]]></title>    <link>https://segmentfault.com/a/1190000047400178</link>    <guid>https://segmentfault.com/a/1190000047400178</guid>    <pubDate>2025-11-14 17:09:19</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>随着企业业务的不断扩展，销售周期的长短已成为影响企业运营效率的重要因素。长销售周期通常指从客户初次接触到最终成交的整个过程较长，常见于专业服务、高端产品销售或高附加值行业。典型行业包括：咨询公司、汽车制造、房地产、医疗设备、教育服务等。这类业务往往需要更精细的客户管理、更复杂的销售流程和更高的客户关系维护效率。</p><p>本文将围绕<strong>CRM软件在长销售周期业务中的适配性</strong>，分析适合的CRM产品，并通过表格形式罗列5-6个产品，帮助用户在选择CRM时做出更明智的决策。</p><ul><li><ul><li>*</li></ul></li></ul><h2>一、长销售周期的业务特点</h2><p>在长销售周期的业务中，以下特点尤为突出：</p><ul><li><strong>客户关系复杂</strong>：客户可能经历多个阶段，涉及多个部门协作。</li><li><strong>销售流程长</strong>：从接洽到成交需要多轮沟通和审批。</li><li><strong>客户维护周期长</strong>：客户关系持续时间较长，需要持续的跟进和维护。</li><li><strong>数据管理复杂</strong>：涉及多环节数据，需整合和分析。</li></ul><p>因此，适合的CRM软件应具备以下功能：</p><ul><li>多角色协同管理</li><li>长周期销售流程支持</li><li>数据分析与预测功能</li><li>客户生命周期管理</li><li>高度可定制化</li></ul><h2>二、适合长销售周期的CRM产品分析</h2><p>以下为五款在长销售周期业务中表现突出的CRM产品：</p><table><thead><tr><th>序号</th><th>CRM产品名称</th><th>定位</th><th>特点</th><th>优势</th></tr></thead><tbody><tr><td>1</td><td><strong>八骏CRM</strong></td><td>国产企业级CRM</td><td>支持多角色协同、复杂销售流程、客户生命周期管理</td><td>个性化定制、强大的数据分析、多渠道整合</td></tr><tr><td>2</td><td><strong>Salesforce</strong></td><td>全球领先的CRM</td><td>云端部署、集成性强、数据可视化</td><td>灵活的销售流程配置、丰富的API、全球支持</td></tr><tr><td>3</td><td><strong>Salesforce Suite</strong></td><td>企业级CRM</td><td>包含Salesforce、Service Cloud、Marketing Cloud等模块</td><td>完整的客户旅程管理、多平台无缝集成</td></tr><tr><td>4</td><td><strong>HubSpot CRM</strong></td><td>企业级CRM</td><td>以营销为中心，支持客户旅程管理、数据分析</td><td>低门槛部署、易用性强、强大的营销功能</td></tr><tr><td>5</td><td><strong>Microsoft Dynamics 365</strong></td><td>企业级CRM</td><td>与Microsoft生态系统无缝集成，支持多角色协作</td><td>混合云部署、数据分析强大、流程自动化</td></tr><tr><td>6</td><td><strong>Pipedrive</strong></td><td>中端企业级CRM</td><td>以销售流程管理为主，适合长周期销售</td><td>简洁直观、流程可视化、自定义能力强</td></tr></tbody></table><h2>三、如何评估CRM软件是否适配长销售周期？</h2><p>在选择CRM软件时，需考虑以下几点：</p><ol><li><strong>业务流程的复杂性</strong>：CRM是否支持多角色协同和复杂销售流程？</li><li><strong>数据管理能力</strong>：是否能有效管理客户生命周期数据？</li><li><strong>数据分析与预测功能</strong>：是否提供数据分析和预测能力？</li><li><strong>可定制化与扩展性</strong>：是否能根据业务需求进行定制？</li><li><strong>技术支持与售后服务</strong>：是否有良好的技术支持和售后服务？</li></ol><h2>四、总结</h2><p>在长销售周期的业务中，CRM软件的选择至关重要。它不仅决定了销售效率，也影响客户关系的维护和企业整体运营。选择合适的CRM产品，应注重其<strong>流程管理、数据整合、数据分析、定制化能力</strong>等核心功能。</p><p>建议用户根据自身业务特点，结合实际需求和预算，综合评估CRM软件的适配性，以实现更高效的销售管理和客户关系维护。</p>]]></description></item><item>    <title><![CDATA[微商圈双 11 特惠模块：助力商户数字化]]></title>    <link>https://segmentfault.com/a/1190000047400181</link>    <guid>https://segmentfault.com/a/1190000047400181</guid>    <pubDate>2025-11-14 17:08:21</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><strong>一、概述总结</strong><br/>微商圈双 11 狂欢节专属模块，活动时间覆盖 11 月 1 日至 11 月 18 日，带来官方直降 50% 的半价福利，叠加领券折上折优惠。该模块基于微擎系统在线交付，提供源码加密保护与官方正品保障，聚焦微商户数字化经营需求，整合多元实用功能，为商户打造低成本、高效能的线上经营解决方案。</p><p><strong>二、功能介绍</strong><br/>核心经营功能：涵盖微餐饮、微外卖、微点餐、微餐厅等核心场景功能，满足商户线上接单、点餐服务需求。</p><p>高效运营工具：配备排号功能，优化门店就餐秩序；支持码上点餐，提升顾客点餐效率，降低商户人力成本。</p><p>安全保障服务：源码已加密，保障商户经营数据安全；官方正品保障，确保模块稳定运行无后顾之忧。</p><p><strong>三、适用场景与行业价值</strong><br/>适用场景<br/>线下餐饮门店：包括快餐、正餐等各类餐饮商户，需拓展线上点餐、外卖渠道或优化店内排号、点餐流程。</p><p>本地生活商户：希望借助微商圈流量，通过数字化工具提升经营效率、扩大服务覆盖范围的中小商户。</p><p>行业价值<br/>降低经营成本：双 11 半价优惠，大幅降低商户数字化转型门槛，无需高额投入即可获取专业工具。</p><p>提升运营效率：码上点餐、在线排号等功能减少顾客等待时间，优化服务体验，同时减轻店员工作压力。</p><p>拓展经营渠道：整合微外卖、微点餐等线上功能，帮助商户打破线下经营局限，触达更多潜在客户。</p><p><strong>四、问答环节</strong><br/>问：该模块的活动时间是什么时候？</p><p>答：活动时间为 11 月 1 日至 11 月 18 日，期间可享受双 11 半价及领券折上折优惠。</p><p>问：模块的交付方式是什么？是否需要线下安装？</p><p>答：采用微擎系统在线交付，无需线下安装，购买后可直接在线使用。</p><p>问：新购用户需要支付费用吗？</p><p>答：当前新购价格为 0 元，叠加双 11 半价优惠，无需额外支付费用即可获取。</p><p>问：该模块适用于哪些类型的商户？</p><p>答：主要适用于微餐饮、快餐等餐饮类商户，也可满足需要线上点餐、排号、外卖功能的本地生活商户。</p>]]></description></item><item>    <title><![CDATA[AI 时代的产品管理 俞凡 ]]></title>    <link>https://segmentfault.com/a/1190000047400198</link>    <guid>https://segmentfault.com/a/1190000047400198</guid>    <pubDate>2025-11-14 17:07:44</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <blockquote><em>本文介绍了在 GenAI 时代，产品管理仍然占据主导地位的原因，以及产品经理如何增强其能力以适合 AI 时代的到来。原文：<a href="https://link.segmentfault.com/?enc=Hg3w%2Bys5Bc%2FS6B%2F66wG58Q%3D%3D.t2B%2FCRzrBo0ogti3u91yYXSKR%2Bffpup2avMlHaI7e80m3gZIuVlC%2BiTmL9Kndc33W%2BMg%2Bk1mtvCAHZ0Wf9fq%2BCiOK%2FLW5nWVmVNQ25BbT0lKkgl%2Bcgsvg1Y1XCyjEGT6dicI73gehyWdAonoc6JlMQ%3D%3D" rel="nofollow" title="Fundamental Product Management: Why it’s more important in the AI Age" target="_blank">Fundamental Product Management: Why it’s more important in the AI Age</a></em></blockquote><p>生成式人工智能（GenAI）不断扩大其在众多行业的视野，使所有领域的产品经理（PM）都有机会成为专注于 AI 并且精通技术的人。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400200" alt="" title=""/></p><p>过去几年里，GenAI 变得极为流行。具备 AI 功能的产品在各个行业纷纷涌现，就像蒲公英一样四处播散，其发展速度几乎不受控制，而且似乎还有源源不断的风投资金为其提供持续的“阳光和水分”。</p><p>从产品管理角度来看，AI 在诸多方面能够提升 PM 的工作效率和专业领域知识水平。</p><p>话虽如此，本文旨在探讨为何基本的产品管理实践仍然占据主导地位，以及这些基本原理如何能让产品管理在 AI 领域脱颖而出。产品管理作为一种实践方式，是一项适用于所有产品开发领域的核心技能，无论其是否涉及 AI。</p><p>那么，无论是在哪个行业（即便不涉及 AI），基本 PM 技能为何如此重要呢？</p><p>以下是基础产品管理仍然重要的三个主要原因，以及一些切实可行的方法，这些方法能让 PM 在充满未知、不断发展的 AI 世界中真正取得成功。</p><h2>1. 产品开发过程太过复杂</h2><p>每次经验不足的 PM 仅仅通过理论来了解产品团队的运作方式时，都会认为产品开发其实并不那么复杂 —— 这是一种新手常犯的错误。</p><p>实际情况是，通常情况下，任何时候都会有数百个不同环节在运作。这些环节可能包括基于团队的依赖关系、销售和营销支持、由海外团队负责的内部工具、需要更新的数据传输，或者那些对上述所有方面都有影响的小任务和职责。</p><p>PM 这一职位之所以特殊，是因为需要能够识别并管理那些隐藏的、不断变化的要素。他们是那种无论需要付出何种努力，都要竭尽全力助力产品发展与交付的超级英雄。在工作中，这种能力比成为团队中最顶尖的 AI 专家更为重要（尽管成为顶尖的 AI 专家也是好事！）</p><p>最近，我受邀前往位于温哥华的 Maximizer CRM 公司总部，就 AI 助手领域发表演讲。在演讲中，我阐述了全球 GenAI 市场规模从 2023 年的 500 亿美元增长至 2024 年的 1840 亿美元这一情况。演讲结束后，我被众多关于如何真正采用 AI 以改进产品开发流程的问题所包围。他们的担忧与我一致：鉴于产品开发的复杂性，采用像 Github Copilot 这样的工具真的能加快工作速度吗？我的回答始终围绕着基本要点：PM 需要保持强大的产品文化，以确保无论 AI 的采用多么复杂，都能顺利进行。</p><p>在产品开发领域，还有一点需要留意的是技术变化的速度，这一速度已经大幅加快。如果团队试图在产品中运用 GenAI，那么技术变化的速度可能会更快。AI 的能力发展迅速，有时甚至每周都会有所变化，因此 PM 必须坚守永恒的原则：理解用户需求、明确问题并提供实际价值。如果没有这些基本原则，团队可能会追逐 AI 的能力而未能解决客户的问题，这可能会导致项目失败。</p><p>GenAI 现在能够自动执行特定任务和流程，但其在成本、针对性和细微差别方面存在局限。具备深厚基础知识的真正人类 PM 会知道如何在拥有 AI 工具支持的产品团队中迅速发挥作用，并懂得如何协调所有推动项目向前发展的关键要素。这些要素可能包括：</p><ul><li><em>了解一天中最重要的 5 到 10 项事务（从 100 项中筛选得出）</em></li><li><em>明白哪些事项需要优先处理，哪些可以放低优先级</em></li><li><em>学会何时拒绝</em></li><li><em>利用电子邮件 AI 工具来过滤掉干扰信息</em></li><li><em>挑选出可以实现自动化或削减的领域或流程</em></li></ul><h2>2. 产品基础涉及人际交往能力，而 AI 无法取代。</h2><p>尽管这听起来可能有些讽刺，但随着 AI 产品开发的复杂性不断增加（这是必然趋势！），PM 在团队中展现出出色的人际交往能力就变得愈发重要了。</p><p>我坚信，强大的利益相关者管理是一项任何 PM 都绝不能放弃的关键要素，无论其技术有多么先进。大多数 PM 都会与各种各样的团队合作（比如：前端和后端开发人员、数据科学家、设计师、市场营销人员、销售人员、管理人员以及外部利益相关者）。你会依靠 GenAI 来切换情境并根据特定受众调整演示内容，还是会依靠自己强大的人际交往能力来推进这一工作呢？</p><p>用户访谈、客户关系管理、利益相关者管理，以及与产品团队就诸如功能优先级等问题进行的讨论，都应当依靠人际交往能力来推动，比如：</p><ul><li>了解社会动态，并且要友善、体贴，最重要的是要易于与工程师们合作</li><li>在无需权威的情况下发挥领导和影响力，通过倾听同事的意见并表明自己理解他们的观点（即便自己可能不同意）来实现这一点</li><li>在用户和客户访谈中表现出同理心，以便真正了解他们在使用产品时的感受和经历</li></ul><p>若想了解 PM 在长期职业生涯中应培养的重要人际交往和软技能，可以参考 PM 练习网站上的这篇文章：<a href="https://link.segmentfault.com/?enc=LBcEQ4mDUmhG1SaHjhKUxg%3D%3D.uR8AmoCXds3%2BLXT3FkM4R%2F2nJW%2FimGDIA3ALuG73kpANK%2FsS0qWZuy8IILH33d4ALYbtOIZi2LddZMWhyVe%2F87K4naH6%2B9U%2BShnqkiWTfh1CHaz%2FQt5beOpylRNr%2BlcL" rel="nofollow" title="https://www.productmanagementexercises.com/blog/6-soft-skills-every-product-manager-needs" target="_blank">https://www.productmanagementexercises.com/blog/6-soft-skills-every-product-manager-needs</a></p><h2>3. 产品基础概念有助于 PM 理解垂直应用场景</h2><p>垂直应用场景与传统应用场景在侧重点上有所不同。传统应用场景范围更广，可以涵盖任何类型的任务、JTBD（待完成任务，job to be done）或客户/用户试图达成的目标。而垂直应用场景只是更广泛的应用场景定义的一个子集，专注于更狭窄和特定的任务。</p><p>在 GenAI 的世界里，我们有所谓 <em>AI 代理</em>。AI 代理是独立的由语言模型驱动的 AI 组件，负责完成一项或一组特定任务。例如，在微软 Copilot 中，某个特定的 AI 代理可以是微软 Word 的摘要生成代理，其中语言模型被配置为仅分析 Word 文档中的内容，然后为用户生成摘要。与关注所有事情不同，该代理仅专注于以更专注的方式完成其特定应用场景。</p><p>这就引出了“垂直型 AI 代理”这一话题 —— 这其实只是对一种特定类型 AI 代理的形象化描述，即这种代理能够比更通用的 AI 代理或助手更好的完成某个特定任务或应用场景。</p><p>自 2022 年 GenAI 兴起以来，垂直 AI 市场迅速扩张，并有望达到创纪录的市场估值。据 <a href="https://link.segmentfault.com/?enc=ZsMc52bDiUCxeAlDGSxwVg%3D%3D.mUmJ0gOf1digFP09SK4sMmkTsTCEM5RLRKinLAvtGj5gleVtfpVm%2FeHPHnxx2sWURLcDnjUhc7dMROUGTTYoxh7t6gF3ykMO17HWlaZvDUY%3D" rel="nofollow" title="AIM 研究公司" target="_blank">AIM 研究公司</a>称，2024 年垂直 AI 市场规模为 51 亿美元，预计到 2030 年将增长至 471 亿美元，这一增长幅度令人惊叹。</p><p>PM 们理应引领这一增长趋势，他们需要找出每个垂直领域的应用场景，并确定每个垂直领域的智能代理都能成为该领域的专家。但要如何才能发现这些有价值的垂直应用场景呢？</p><p>我想分享一个专业方面的趣闻，那就是我们在 Planview 公司的工作经历以及所做的持续探索工作，以验证客户的垂直应用场景。在推出 <a href="https://link.segmentfault.com/?enc=r0bDFTdLONjSh5%2FPwxxdhg%3D%3D.byn8XutDFLyFL3hsLSWQZ%2BPaPKQ%2BN5LD%2Fjap1uAddRY%3D" rel="nofollow" title="Planview 公司的 AI 助手 Planview Copilot" target="_blank">Planview 公司的 AI 助手 Planview Copilot</a> 之后，团队很快发现，我们的客户群体根本不清楚能带来什么好处，而且潜在的应用场景范围广泛且各不相同。</p><p>作为 Planview Copilot 的产品经理，我选择了几个具体用例来启动产品 MVP，并以此作为假设，然后通过反馈电话和数据监测与客户进行互动，以验证这些用例是否对他们有用。在这一年里，我持续采用快速失败方法，直到某些东西引起客户共鸣：一系列基于 AI 的用例，真正为他们的日常工作流程带来了价值。对我们来说，基本实践是取得这一成功的关键，这就是为什么垂直 AI 代理市场将充满成长的烦恼和令人兴奋的活力，因为越来越多的公司开始像 Planview Copilot 那样发现这些垂直用例。</p><p>基本产品管理实践 —— 涵盖产品管理存在的根本原因的技能 —— 将是解决方案。例如，产品发现、用例优先级排序、客户关系以及反馈整合。PM 被雇用是为了在 GenAI 的世界中发现那些垂直用例，然后制定策略并兑现承诺。</p><p>我建议 PM 们继续做到以下几点：</p><ul><li>探索最常见但又极具创新性的产品及使用案例发现方法</li><li>通过不同方式激发思维，对需要解决的问题进行优先排序</li><li>深入研究 GenAI 市场，以预测变化、理解客户问题并识别其产品可能解决的核心差距</li></ul><h2>结论</h2><p>希望我已经阐明了产品管理基本原则的永恒重要性，即便在数字化 AI 时代也是如此。我相信，随着 PM 们继续分享最佳实践，并改进他们的工作流程和框架，GenAI 市场将继续提升其为客户带来的价值。其真正的影响将体现在工作效率、时间节省、娱乐以及生活质量等方面。</p><hr/><blockquote>你好，我是俞凡，在Motorola做过研发，现在在Mavenir做技术工作，对通信、网络、后端架构、云原生、DevOps、CICD、区块链、AI等技术始终保持着浓厚的兴趣，平时喜欢阅读、思考，相信持续学习、终身成长，欢迎一起交流学习。为了方便大家以后能第一时间看到文章，请朋友们关注公众号"DeepNoMind"，并设个星标吧，如果能一键三连(转发、点赞、在看)，则能给我带来更多的支持和动力，激励我持续写下去，和大家共同成长进步！</blockquote><p>本文由<a href="https://link.segmentfault.com/?enc=3vOLfhZDpw9Ik%2F7IPZDnuA%3D%3D.b5leFCwZ2RRFUP084P2FPyszHG2vrfXGoOyRf06HdMA%3D" rel="nofollow" target="_blank">mdnice</a>多平台发布</p>]]></description></item>  </channel></rss>