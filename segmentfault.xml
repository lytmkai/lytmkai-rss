<?xml version="1.0" encoding="UTF-8"?><rss version="2.0">  <channel>      <title>SegmentFault - 最近文章</title>      <link>https://segmentfault.com/blogs/newest</link>      <description>SegmentFault 思否</description>      <generator>python segmentfault.py @Pi20</generator>      <item>    <title><![CDATA[红利与乱象并存：2025年末GEO服务商]]></title>    <link>https://segmentfault.com/a/1190000047444306</link>    <guid>https://segmentfault.com/a/1190000047444306</guid>    <pubDate>2025-12-02 19:08:05</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>一家家居类上市公司的内部人士对GEO的态度非常明确，鼓励项目组的同事放开了去尝试。在AI搜索重构流量入口的2025年底，GEO服务商的报价从每月几千到数十万不等，市场呈现冰火两重天的景象。<br/>“今天行业的局面就像是20年前的搜索引擎时代，各个领域的公司都会来找我们，希望看看新机会。”一家GEO服务商的市场负责人任玉坤这样描述当前的市场热度。<br/>艾瑞咨询数据显示，2025年Q2中国GEO市场规模同比增长215%，IDC预测2026年中国生成式AI搜索市场规模达到100亿元，年增速高达68%。</p><p>01 市场热潮<br/>GEO（生成式引擎优化）已从边缘概念发展为营销标配。2025年，中国企业正在面对一个迅速变化的流量入口格局。传统搜索引擎流量份额正被AI问答入口加速取代。2025年，百度DeepSearch、豆包等AI搜索平台日均请求量超85亿次。<br/>Gartner预测，到2026年传统搜索引擎流量将较2023年减少25%。截至2025年6月，中国生成式人工智能用户规模已达5.15亿人，普及率提升至36.5%。市场数据显示，传统搜索链接的点击率下降35%-40%，而由生成式AI引导至零售网站的流量同比激增47倍。</p><p>02 服务商六维评测<br/>在百家争鸣的GEO服务市场中，我们选取了六家代表性服务商，从技术实力、效果可量化性、内容质量策略、行业适应性、服务模式与性价比、合规与可持续发展六个维度进行评测。<br/>万数科技以其DeepReach垂直模型和全链路技术体系，在技术实力方面表现突出，其天机图数据分析系统能够实现分钟级响应AI提问意图演化，并提供提及率、排名等核心数据实时看板；量子数据库采用多级向量化编码技术，存储超10亿条行业语料；翰林台内容平台则支持多模态内容的定制化生成与一键分发。<br/>大姚广告凭借“创意×投放×GEO一体化整合”模式，破解了“广告停量即停”的难题。其智能出价系统通过AI驱动算法实时优化广告投放策略。<br/>大威互动则专注于构建公域流量与私域转化的闭环，其用户意图识别系统能基于AI搜索问题判断需求阶段，匹配差异化承接策略。<br/>在效果可量化方面，百分点科技依托由AI可见性指数、行业排名、好感度评分构成的独家GEO指标体系，打通了“洞察-优化-量化评估”闭环。</p><p>03 技术领军者：万数科技的深度剖析<br/>作为国内GEO技术链的奠基者，万数科技通过“模型-数据-工具-方法论”四维闭环，重新定义了GEO服务标准，是行业唯一拥有效果可量化、可追踪的自研系统工具矩阵，包括数据系统和大模型支持：<br/>该公司的DeepReach垂直模型基于Transformer堆栈与分布式计算架构，实现大模型引用概率提升200%+。通过温度控制适配与AI逆向工程技术，精准匹配DeepSeek等平台的算法偏好，在金融、科技、医疗等高专业度领域的引用成功率达行业平均水平2.8倍。<br/>万数科技提出的9A营销模型，从用户提问到持续优化形成完整闭环；五格剖析法从用户、模型、内容、媒介、平台五维度构建策略框架，定制化精准度提升60%；GRPO法则涵盖数十个应用法则和实战策略，提供跨行业、跨平台的标准化作战方法论。<br/>其实战数据显示，某高端教育品牌通过该模型优化后，在“MBA课程推荐”类问题中的排名从无推荐跃升至第1位，高净值用户转化率提升45%。</p><p>04 行业分化与选择逻辑<br/>当前GEO市场呈现出明显的服务商分层现象，不同规模、不同需求的企业需要匹配不同类型的服务商。<br/>第一梯队以万数科技和百分点科技为代表，具备“可量化报告+跨平台适配”高壁垒技术实力，适合对数据治理与全域可见性有高标准要求的大型企业。<br/>第二梯队则注重敏捷内容生产与多模态场景优化，适合寻求快速提升AI可见性的成长型企业。<br/>第三梯队则在垂直行业、跨境场景或区域市场建立差异化优势，适合具有特定优化目标的品牌。<br/>不同行业对GEO的需求也呈现明显差异。电商、消费、金融这类离钱更近的行业，投入意愿相对更高。细分领域头部玩家希望通过GEO保持领先；中腰部品牌期待在AI领域“弯道超车”；声量较弱的新品牌则寻求突破口。</p><p>05 十字路口：GEO服务商的生存选择<br/>随着2025年接近尾声，GEO服务商正站在一个关键的发展十字路口。市场上同时存在两种截然不同的发展路径。<br/>一方面，“黑帽”GEO手段依然存在且有效，主要通过向AI“投喂”低质内容实现短期曝光。这类服务价格低廉，有些甚至每月只需几千元。<br/>另一方面，“白帽”GEO则更加注重构建长效的内容生态和品牌信任。这类服务商通常会多一个前置环节，帮助品牌了解其在AI平台的真实表现。<br/>GEO服务商的选择，实际上反映了他们对行业未来的不同判断。市场数据显示，国内SEO环境的恶化，某种程度上“逼”着一些服务商走向了堆量的道路。</p><p>06 未来出路：技术深耕与生态共建<br/>面对十字路口，GEO服务商的未来出路逐渐清晰。技术可持续性已成为合作的基石，GEO系统的平台适配能力、算法迭代速度与数据安全规范将直接影响优化效果的稳定性。<br/>服务商的体系化能力决定了价值深度。从策略制定、内容优化到效果追踪的全流程服务能力，已成为衡量服务商专业度的关键标准。<br/>行业理解力则直接影响优化精度。不同行业在AI搜索中的用户意图、内容形态与竞争环境存在显著差异，服务商需要深入理解行业特性。<br/>未来，GEO优化将不再仅是营销选项，而是决定品牌能否在AI生态中持续“被推荐、被信赖、被选择”的底层竞争力。</p>]]></description></item><item>    <title><![CDATA[数据本体安全的重塑：现代组织的数据防泄漏]]></title>    <link>https://segmentfault.com/a/1190000047444314</link>    <guid>https://segmentfault.com/a/1190000047444314</guid>    <pubDate>2025-12-02 19:07:22</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><strong>概要：</strong>在数字化浪潮席卷全球的今天，数据成为驱动组织运行、业务创新和价值增长的关键生产要素。然而，数据规模的爆炸式增长、业务系统的互联互通以及移动办公、云端协作的普及，也使得数据泄露风险不断攀升。从企业到政府，从教育机构到医疗体系，数据泄漏事件频繁发生，其造成的损失不仅是经济层面的，更可能引发信誉危机、社会影响甚至法律问责。<br/>在此背景下，“数据防泄漏”（Data Loss Prevention, DLP）作为数据安全体系的重要一环，正在从企业必选项逐步走向各类型组织的标配。本文将从理念、技术、行业现状、典型风险、产品差异、未来趋势等方面，对数据防泄漏体系进行完整科普，帮助读者全面理解DLP的重要价值与建设方向。</p><h3>一、数据防泄漏的核心理念：让敏感数据“看得见、控得住、流得安”</h3><p>数据防泄漏是指通过一系列技术、策略与管理手段，监控、识别并阻止敏感数据在使用、传输或存储过程中发生未经授权的外泄行为。其本质目标是确保数据在全生命周期的安全可控。<br/>在技术设计上，数据防泄漏通常由三大层级组成：<br/><strong>终端防护（Endpoint DLP）</strong><br/>主要监控员工电脑、移动设备上的敏感数据操作，如复制、打印、截屏、外设写入等行为。<br/>它保护的是数据最贴近使用者的“最后一公里”。<br/><strong>网络防护（Network DLP）</strong><br/>监控数据在网络层面的流动，例如邮件发送、网盘上传、HTTP/FTP 访问等，防止敏感信息在不受控的通道中泄露。<br/><strong>存储防护（Storage DLP）</strong><br/>关注数据库、文件服务器等核心数据存储区域，通过加密、访问控制、权限管理、文件指纹比对等方式实现“数据静态状态”的安全。<br/>数据防泄漏引擎的核心，是对数据内容的精准识别，包括关键字匹配、正则检测、结构化数据指纹、文件指纹识别等。结合策略引擎后，系统可对风险行为进行告警、阻断、脱敏或加密，从而构建敏感数据可知、可控、可审计的完整防护体系。</p><h3>二、为什么数据防泄漏成为刚需：网络安全体系的“最后一公里”补齐</h3><p>过去多年，我国的网络安全建设主要围绕网络边界、主机安全、应用安全进行，例如：<br/>• 网络层：防火墙、入侵检测、边界隔离等<br/>• 应用层：身份认证、接入控制等<br/>• 主机层：终端防护、主机审计、防病毒等<br/>这些措施在防范外部攻击方面成效明显，但它们未能直接保护数据本身。换句话说，当攻击者突破了外围防线进入内部系统时，没有任何措施可以阻止其继续访问或窃取数据库中的敏感信息。<br/>因此，数据层安全（如数据库加密、访问控制、文档保护）成为补齐网络安全体系的最后一道关键防线。只有当数据本身具备防护能力时，组织才能真正实现“边界内外皆安全”。<br/>在真实事件中，这类风险更加触目惊心：<br/>• 全球知名招聘网站 Monster 曾被攻击，数百万求职者个人信息被窃取并被用于勒索。<br/>• 著名程序员程稚瀚多次入侵北京移动数据库，恶意盗取充值卡密码并牟利数百万。<br/>• 广东联通内部员工利用权限漏洞进行违规充值，造成超过 260 万元损失。<br/>• 美国银行丢失包含 1200 万信用卡数据的备份介质，引发严重后果。<br/>更值得注意的是，根据 CSI/FBI 报告显示，约 70% 的数据泄露来自内部人员或内部系统漏洞。这意味着，数据泄露已不再局限于黑客攻击，更多发生在组织内部、合法账号、正常权限下的业务行为中。这些事实共同指向一个核心趋势：数据防泄漏已成为保护组织命脉数据的必备措施。</p><h3>三、传统数据库安全增强方案面临的挑战</h3><p>在核心数据防护领域，长期以来的数据库安全增强主要依赖前置代理、应用层加密以及数据库厂商自带的加密选件。但这些传统技术路线在实际应用中都面临明显局限，可概括为三个方面：<br/><strong>（1）高耦合改造导致落地成本高昂</strong><br/>无论是前置代理还是应用层加密，都需要以不同方式对现有应用进行大规模改造。这不仅增加开发与维护成本，同时严重影响系统稳定性与业务连续性。许多数据库原生功能（如存储过程、函数、触发器等）往往因方案兼容性不足而无法正常使用，直接导致方案在实际场景中难以真正落地。<br/><strong>（2）加密方式对性能和可用性影响显著</strong><br/>传统方案普遍依赖对数据进行深度处理，如字段级加密、密文读写等，这些方式会带来明显的性能损耗。此外，由于加密后的数据无法做检索、排序或范围查询，系统在业务处理上受到限制，易出现响应延迟或功能受限等问题，影响用户体验与业务效率。<br/><strong>（3）不符合国家密码政策及本土业务需求</strong><br/>国外加密方案虽然成熟，但大多无法使用国密算法，无法满足国内政企行业的合规要求。即便是 Oracle 官方加密选件，也存在价格昂贵、不可灵活适配、多项能力不满足国内要求等问题。国内部分产品虽符合政策，但仍受制于技术架构本身的局限，难以兼顾透明性、兼容性和高性能。<br/>总体来看，传统数据库增强技术均存在适用性有限、改造成本高、兼容性不足、性能受损等共同不足，这也推动市场对更透明、更低侵入、更高性能、政策符合度更强的新型数据库安全技术需求不断增长。</p><h3>四、国内外数据库安全产品的局限性</h3><p>国外数据库加密产品进入中国市场后，也面临政策、安全性和兼容性问题，例如：<br/>不支持国密算法，无法用于政企、金融等关键行业/无法进行密文检索，导致性能下降与国情政策规范不兼容/难以满足本土业务的复杂场景需求等。国内产品虽然更符合政策，但部分方案仍基于代理或应用层加密，导致开发改造成本高、兼容性差、体验不佳。因此，市场对更透明、更高性能、政策合规、能真正实现“无感部署”的数据安全产品需求强烈。</p><h3>五、DLP的优势与价值：从技术到管理的全方位提升</h3><p>数据防泄漏并不是只靠一个产品就能解决的，它是一套体系、多层技术与组织机制的组合。其价值主要体现在以下五个方面：<br/>1、让数据资产“可见”——从资产盲区到全量感知<br/>许多组织甚至不知道自己拥有多少敏感数据。DLP 能自动识别敏感信息的分布、存储状态和流动轨迹，让管理者第一次真正看清自己的数据全貌。<br/>2、让敏感操作“可控”——策略治理与访问最小化<br/>结合敏感数据分级分类，实现基于身份、终端、场景、通道、内容等多维度的访问控制，确保“谁能看、能看什么、什么时候看、从哪里看、通过什么方式看”都可精确治理。<br/>3、让外泄行为“可阻断”——实时防护与违规防止<br/>无论是通过U盘、打印、网盘、邮件还是聊天工具，只要可能导致敏感数据外泄，DLP 系统均可实时识别并阻断。<br/>4、让合规落地“可审计”——为监管提供证据链<br/>各行业的监管要求越来越明确，如数据分级分类、访问最小化、日志留存等。DLP 能提供全量审计链条，助力企业满足政策要求。<br/>5、提升企业竞争力——数据安全能力成为品牌资产<br/>数据泄露事件一旦发生，往往伴随巨额赔偿、法律责任甚至企业倒闭。建设成熟的数据安全体系是企业品牌可靠性的核心基础。</p><h3>六、与其他数据安全产品的边界与差异</h3><p>数据防泄漏（尤其是数据库保险箱类技术）常与漏洞扫描、数据库审计、以及综合安全增强产品混淆，但这些产品与 DLP 的定位与能力存在本质差异，可从三个维度进行概括：<br/>（1）与漏洞扫描的差异：防护目标不同，作用侧重点不同<br/>漏洞扫描侧重发现数据库系统的配置弱点与软件漏洞，通过检测密码策略、补丁情况、端口风险等，帮助组织进行安全加固。但它“只能发现问题”，无法对数据层面的真实泄露风险进行阻断。而 DLP 则保护“数据本身”，解决的是组织在权限合法、操作正常情况下依然可能发生的敏感数据外泄风险。<br/>（2）与数据库审计的差异：一个事后追溯，一个事前预防<br/>数据库审计擅长记录和追踪数据访问行为，为事后分析提供证据。但审计无法阻拦访问本身，无法阻止管理员、内部人员或恶意程序直接获取敏感数据。<br/>数据库保险箱/DLP 则建立在更高的安全能力之上，既能记录，也能“阻断”；不仅能审计数据访问，还能对高危访问、异常行为、文件级窃取、离线拷贝等行为进行防范和控制，实现对敏感数据主动、实时的保护。<br/>（3）与综合数据库增强产品的差异：透明性与兼容性是关键分水岭<br/>综合安全增强类产品通常集合认证、授权、审计等能力，但普遍需要对应用进行深度改造，并要求 DBA、开发人员使用专门的接口工具来替代原生数据库功能，侵入性较强。<br/>相比之下，先进的 DLP/数据库保险箱方案以透明、无侵入、原生支持国密算法、兼容数据库特性、无需改造应用为核心优势，能够大幅降低部署与运维成本，同时最大限度保持业务连续性。<br/>因此，DLP 的定位并非替代上述产品，而是在它们的基础上补齐“数据本体防护”这一关键短板，实现从系统安全到数据安全的完整闭环。</p><h3>七、数据防泄漏建设的最佳实践：从理念到落地的路线图</h3><p>数据防泄漏并不是简单部署某款产品，而是一项牵涉数据治理、业务流程、安全策略和组织机制的系统工程。在实际建设中，应从全局视角出发，逐步形成贯穿数据全生命周期的安全体系。<br/>组织需要建立对自身数据资产的充分认知，包括敏感数据分布、系统架构、业务链路与潜在暴露面。只有对“数据在哪里、谁在用、如何流动”形成清晰视图，后续的策略与防护措施才能做到精准有效。<br/>基于这一认知，组织应进一步梳理数据使用的行为模式与业务场景，识别数据在流转链条中可能出现的风险环节。这个过程不仅是对技术层面的梳理，更是一个跨部门协同的治理过程，需要业务、开发、运维、安全等共同参与。<br/>在此基础上，防护策略的制定应遵循分级负责、循序渐进的思路。对于一般性风险，可通过行为审计、适度控制等方式进行治理；而对于核心与高度敏感数据，则需采用加密、动态脱敏、最小权限访问等强措施，使其从访问到流通都处于可控状态。同时，策略的配置不可一刀切，而应结合业务敏感度、人员角色和实际工作习惯，使安全不会阻碍业务。<br/>此外，一个成熟的数据防泄漏体系必须伴随完备的审计与响应机制。任何关于敏感数据的访问、流转、共享、导出等行为都应留存可追溯的记录。在出现风险信号时，系统应能自动预警，并根据规则触发拦截、审批或升级处理，从而让组织从“事后发现”走向“实时防护”。</p><h3>八、未来趋势：从 DLP 到数据安全治理体系化</h3><p>数据防泄漏技术正在从传统的规则驱动模式迈向更加智能化、体系化的方向。未来的发展趋势不仅关乎某一个功能点的提升，而是关乎整个数据安全治理体系的演变。<br/>一个显著趋势是智能识别技术的普及。过去依赖固定规则与人工维护的内容识别模式，已经难以应对复杂业务环境和多样化数据类型。随着 AI 与大模型技术的引入，系统将能够更智能地判断数据敏感度、识别异常行为模式，甚至从上下文中推断潜在风险，从而让数据防护更加主动而非被动。<br/>数据防泄漏将逐步从局部环节的增强，迈向覆盖数据全生命周期的治理能力。无论数据处于采集、加工、分析、共享还是归档状态，都将有对应的安全机制与控制措施。这种转变意味着数据安全将不再依附于单点产品，而是成为贯穿整个业务链条的底层能力。<br/>此外，未来的数据防泄漏将更加注重平台化与统一治理。随着企业上云、多云与混合环境的普及，安全能力分散在各系统中难以统一管理。平台化的数据安全体系能够整合分级分类、权限治理、访问控制、加密脱敏、日志审计等能力，为组织提供统一的策略管理与风险视图，实现“全局治理、统一策略、一体化响应”的能力。</p><h3>九、数据防泄漏，是组织数字化时代的必选项</h3><p>在数字化高速发展的今天，数据防泄漏不再是选配，而是组织赖以稳健运行的基础安全能力。随着监管强化、行业数字化加速、数据价值提升，构建全面的数据防泄漏体系对于每一个组织而言，都具有深远意义。</p>]]></description></item><item>    <title><![CDATA[11 月热搜精选 KaiwuDB ]]></title>    <link>https://segmentfault.com/a/1190000047444319</link>    <guid>https://segmentfault.com/a/1190000047444319</guid>    <pubDate>2025-12-02 19:06:50</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2><strong>1、KaiwuDB V3.0 &amp; KWDB V3.0 产品正式发布</strong></h2><p>11月12日，我们迎来了"数据洞见未来，共赴物联网全域智能------浪潮KaiwuDB 新品发布会"的精彩时刻。会上，浪潮正式推出了自研分布式多模数据库全新版本------KaiwuDB V3.0！</p><p>本次KaiwuDB V3.0以"多模"为核心，在单机写入、分布式写入、跨模查询等数据处理能力实现全面大幅度升级。新版本针对物联网复杂部署环境，优化了可用性、易用性与安全性，并新增多项功能。同时发布的还有智能运维工具 KAT（基于MCP协议），致力于为企业提供高性能、高可靠、低成本、易运维的一站式数据解决方案。</p><p>同时，社区开源版本 KWDB V3.0 也同步发版，欢迎开发者访问社区（<a href="https://link.segmentfault.com/?enc=BdeSbwnkw4t1MV83jQfcIA%3D%3D.MtQo4QTZ7Kh7HwynfqERhdL797zB7PGtg784N81o1pU%3D" rel="nofollow" target="_blank">https://gitee.com/kwdb/kwdb</a>） 下载最新版本进行体验！</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444321" alt="" title=""/></p><p>👉点击了解 KaiwuDB V3.0 新增特性解读 &gt;&gt; 🔗<a href="https://link.segmentfault.com/?enc=Kzp%2BQ6yupweNGn8bZwIzIg%3D%3D.VJNlE%2Fj4d28MS2JRYD4DqUhtW1gM71%2Frr6ebMEGJceoH%2B%2BoYrdKJnYLGnz4foczOg61Y3kbGAAR0THdTA5aWsNbB%2B7gRwIO%2B9MOblU2VPdCAqAU8zbgvhqPViufnN5KubyKx5UvPtVJL8jKzgfibcAY2%2BIeZmyuEpEpQuWsbWBHJHRh2VgC5RKt85xARLTey" rel="nofollow" target="_blank">KaiwuDB 焕新升级 ------ V3.0 重磅发布！</a>  </p><p>👉点击了解 KWDB V3.0 版本更新&gt;&gt; 🔗<a href="https://link.segmentfault.com/?enc=H5cOTn%2B3V6T5lgANerv%2BEQ%3D%3D.lmhb2VVzaDOBHG0U4z6XojMQ6cyqAwVUB%2FfMOggzCvIMCb%2FG1xwAowCz2LgmAWyarHQzIV4nXSVSbn24nyvEy5EP%2BwTw45BSB0ozCZx6X4a%2Bgbp6JNWCaaDBERDucCMrfgXV7%2Fh7MzWYGH9qpXsE980V2XNyVYmeTcrzQI0%2FXkm7pvRBEsjLKr%2BSmok8VQYZ" rel="nofollow" target="_blank">KWDB 3.0.0 正式发布！年度重磅升级，重塑 AIoT 产业智能数据基座</a></p><h2><strong>2、KaiwuDB 与映云科技(EMQ)达成战略合作</strong></h2><p>11 月 12 日，KaiwuDB 与杭州映云科技（EMQ）达成战略合作，双方将整合技术优势，共同推动物联网在云边端业务中实现全链路数据闭环，为能源电力、工业制造、ICT 等重点行业的数字化转型提供支持。KaiwuDB 总经理黄越与 EMQ 生态技术总监丰志飞出席了签约仪式。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444322" alt="" title="" loading="lazy"/></p><p>KaiwuDB 总经理黄越（左）、EMQ 生态技术总监丰志飞（右）出席签约仪式</p><p>双方合作推出"云边端一体化数据底座联合解决方案"。在边缘端，NeuronEX 集成 KaiwuDB-Lite，支持上百种工业协议，提供采、算、存、转发与分析一体化能力。在云端，EMQX 集成 KaiwuDB V3.0，融合其海量连接与高效转发能力与 KaiwuDB V3.0 的高并发写入、高压缩存储及实时分析能力，形成从实时多协议接入、边缘计算、云边存储到云端智能决策分析的完整数据链路。</p><p>这一方案不仅有效降低了在边缘端部署多套系统所带来的复杂度，更助力边缘设备实现实时智能响应，精准匹配工业场景对数据实时处理的严苛需求。</p><p>👉点击了解详情 &gt;&gt; 🔗<a href="https://link.segmentfault.com/?enc=b6JK9rPNJmlcwOfuZx8jbQ%3D%3D.uMpNvTTN5TgILAzDE1x2qwm1tEyLvEJKHcPnA3RdYLW4A5KWoYym47GVvrR6lVz%2FfNjjQbq9%2Fs6Tll5P4kcwKwFfYR3pJmNuuUwqbSf6o8tYkNpCa7XQWvZdZRnE8hFVoKhxS1DWdVwoAgo%2BOvKCmd7FKqJC2mxzpGfjbcM1ArDmRJtioRjfHq3NcYrzCvwJ" rel="nofollow" target="_blank">KaiwuDB 与映云科技( EMQ )达成战略合作，共拓物联网云边端数据市场</a></p><h2><strong>3、 浪潮开务 K-Mind 行业数智大脑正式发布</strong></h2><p>浪潮开务物联网行业数智大脑（K-Mind）是由时序、语言、视觉、图学习、科学计算与决策优化六大核心基础模型协同工作，专为物联网场景打造的行业大模型有机体。</p><p>以 K-Mind 为核心的基建平台：</p><p>• 底层依托 KaiwuDB 分布式多模数据库与数据湖仓，为多模态数据提供高效、可靠的存储与计算支持；</p><p>• 中间通过多模态数据治理与语义层构建，将原始数据转化为 AI-ready 数据，为模型训练提供高质量数据基础；</p><p>• 上层基于丰富的行业知识库、算法与模型库，构建起行业智能体，并通过 API/SDK 为应用层提供"感知-认知-决策-优化"的全链路 AI 能力。</p><p>浪潮开务物联网数智大脑 K-Mind 的正式发布，将助力客户在物联网场景，如能源、水利、矿山等关键领域快速、低成本地实现 AI 工程化落地，并为业务的重构与智能化提供高效赋能。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444323" alt="" title="" loading="lazy"/></p><p>以 K-Mind 为核心的基建平台链路</p><p>👉点击了解详情 &gt;&gt; 🔗<a href="https://link.segmentfault.com/?enc=TAggpja34Tq53hgViYp2aw%3D%3D.9dBXfJGi1rEO1krsF8LOhv2k0%2FFZQzFIQzXj48Pt9NY3FaDqRb0ggpFvN6I1fLT1hWh2%2FaOZjO0H0trzA2zPRnOSnUFUyf8NJDGkaEIpJ0WO00o1pUxvxlNaRGArSuFv6dCH7vso5yAVzKHX8cpdlhYHIM%2BfIcbZYeDxsvv02EckeHq3n4TYsIk7w9oPivbX" rel="nofollow" target="_blank">K-Mind 行业数智大脑：破解企业 AI 工程化落地难题</a></p><h2><strong>4、KWDB 社区有奖征文大赛第二季正式开始！</strong></h2><p>11 月精彩不断，又一重磅社区活动来啦！🎉</p><p>11 月 12 日，「码」上数据库------KWDB 2025 创作者计划暨社区征文（第二季）正式启动！</p><p>本次征稿持续时间：<strong>2025 年 11 月 12 日------2026 年 1 月 12 日</strong> 。我们依然设置了"<strong>实践</strong> "与"<strong>技术</strong>"两大赛道，等你来挑战！</p><p>奖励当然不会少！本届大赛共设 <strong>45</strong> 个获奖名额，总奖池价值高达 <strong>32,000 元</strong>🎁。所有奖励都将通过 KWDB 社区积分商店进行兑换，实用又贴心。</p><p>才华需要舞台，经验值得被看见。无论你是深耕技术的开发者，还是一线实践的布道者，这里都有你的位置。快来执笔为"码"，参与 KWDB 社区征文大赛吧！<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047444324" alt="" title="" loading="lazy"/></p><p>👉点击了解大赛详情 &gt;&gt;🔗<a href="https://link.segmentfault.com/?enc=hzsVk9EyJvUnCuR3V38ytg%3D%3D.z%2FMm84EpoJBFqaWw38925eOc6OruB6tHVxMWYCoVdAUCRGTzdMlSRDtMxejmMVHstuj97RkuzoucOcRA4l1XkQaHkbFIp82TZI1P7w%2BafsdtVztx3ib8V%2BGYm0FPtzcRY5p8Dcoz2ueZzH3YdX2mrDaZsKjWvaMjicgNRMzoTHc5BM6%2F7cdpOZYTrostMUki" rel="nofollow" target="_blank">征文大赛 |「码」上数据库 ------ KWDB 社区征文第二季启幕！</a></p><h2><strong>5、 KaiwuDB 数据库高级工程师认证上线！</strong></h2><p>本月，KaiwuDB 数据库高级工程师认证（KWCP）正式上线了！这一认证专为已获得 KaiwuDB 数据库工程师认证（KWCA）的从业者设计，旨在帮助大家进一步掌握安装部署、日常运维、性能优化及故障处理等深度实战技能，助力您在专业道路上持续精进。</p><p>参与方式非常简单：只需<strong>注册 KaiwuDB 官网并完成实名认证</strong> ，即可报名参加认证考试（<a href="https://link.segmentfault.com/?enc=5vYVgQb5Orr7nEiq2Wr%2BUQ%3D%3D.X5ZdfoxiP2rm9F3VW7lAg3nJlmvhpBypBfcSaeMNdRNArBWOq%2Brwbsrp1ynOUHEZ" rel="nofollow" target="_blank">https://www.kaiwudb.com/learning/</a> )。认证考试<strong>全程免费</strong>，我们还为您准备了相关的视频课程与学习资料，助您一臂之力。</p><p>欢迎各位数据库开发者与技术从业者踊跃参与，一起解锁更高阶的技能认证！</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444325" alt="" title="" loading="lazy"/></p><p>👉点击了解详情 &gt;&gt;🔗<a href="https://link.segmentfault.com/?enc=vArPTdvFJU6frVMMDH2uMw%3D%3D.8rFBKOwZavftRA2r0aAAfn1mbc7DIHSXSgOZ2xpXP5dU37l9sG4WsvnAA9ozEae6NLATMk2TJnoWObFTTUK%2FtLRz7X0AdhUR9EUGiiOW16oOvJ90fHtHGBGoQHNEj%2Fl8am5m7AYUlFMNCf2BxIQQzhm5lQdxb24LnXHd7VS0%2Br85QZj9XOT%2Fh9LxDuL2TLJr" rel="nofollow" target="_blank">领证啦！KaiwuDB 数据库高级工程师认证上线！</a></p><h2><strong>6、KWDB MVP 首批入选名单重磅公布!</strong></h2><p>11 月 14 日，KWDB 社区正式揭晓了 <strong>2025 年度的 MVP 名单</strong> ，本次共有 <strong>8</strong> 位社区专家获此殊荣！🎉</p><p>KWDB Community MVP 是 KWDB 数据库社区荣誉认证，为表彰和激励在 KWDB 生态建设与技术推进中做出突出贡献的技术专家，每位 MVP 都将获得定制认证标识、品牌曝光机会、专属权益以及积分兑换通道等多重支持。</p><p>KWDB 社区 MVP 计划将持续开放招募，欢迎前往社区了解更多 KWDB MVP 计划内容：<a href="https://link.segmentfault.com/?enc=7GQqEFG8zGc%2FT9K3aBxWQg%3D%3D.z8aSdBfJerqRLTMoO%2BBKDeobR6LL1Tnys8BxN9g7W2sa52zNcugAHvhHGMJLnVwn" rel="nofollow" target="_blank">https://kwdb.atomgit.net/dev/mvp/</a> ，我们期待更多热爱技术、乐于分享、积极参与社区建设的同行者加入，一起推动社区的成长与进步！</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444326" alt="" title="" loading="lazy"/></p><p>👉点击了解详情 &gt;&gt;🔗<a href="https://link.segmentfault.com/?enc=d2VCHaDHosC8R4sytJWxKw%3D%3D.L73ISIFLxXoKCF3Bbeh3qhm4uHvoXPf679MgpBW2siyAKkpFFuzgJN9nhal%2BNTW67jfgzysWXIerHJrF3NuLL4SS1kzLu9vguwcoocmzGhC9GUL98U9NfIMBRSUfCSbKuR6tBXuKkN%2F0T4ZPkSUHNr5cdzGn0PYtiD4bUJT02VPj7lZgVJjBz3d3L8OXnkLb" rel="nofollow" target="_blank">荣耀揭晓 | KWDB MVP 首批入选名单重磅公布!</a></p><h2><strong>7、KWDB 核心贡献挑战赛获奖名单重磅揭晓！</strong></h2><p>11 月 20 日，"第三届开放原子大赛------KWDB核心贡献挑战赛"在北京收官。来自全国的 10 支优秀团队围绕三大赛题方向进行了路演答辩，展示了创新实用的技术方案，并决出一、二、三等奖。</p><p>本次赛事聚焦多模与时序数据库核心能力构建，通过与开源开发者协同攻关，推动数据库技术演进。比赛中涌现的优秀成果，使KWDB在写入性能、数据导出效率、系统稳定性和可扩展性等方面得到进一步优化，提升了开发者体验。</p><p>祝贺所有获奖团队，也感谢每一支积极参与的队伍！期待未来与更多开发者携手，在开源共创新的道路上不断突破，共同推动数据库技术的进步与落地。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444327" alt="" title="" loading="lazy"/></p><p>👉点击了解详情 &gt;&gt;🔗<a href="https://link.segmentfault.com/?enc=oIpIzR6Hf4nPUXvtDPUfaQ%3D%3D.JHvlz6onJrJzB174jiFmKlTUryBMYUHJkoSGNfFvKuXTfc0oMLtJCh1yldPtK7%2Ba0rHpVx794R4KRDXngql4dYJoSnaNwXORI0tdyld8ohAs66YTmSvCtqOcKIy6x8erIlWEx%2BWmNOwQKeOhAxi06FjDEnt0xdHHDOo8IbgulIS28C2%2FDnoAfn1X2BuEQSBQ" rel="nofollow" target="_blank">KWDB 核心贡献挑战赛决赛获奖名单重磅揭晓！</a></p><h2><strong>8、KWDB 获 2025 开放原子基金会年度多项荣誉</strong></h2><p>11 月 21 日，在 2025 开放原子开发者大会的开幕式上，KWDB 接连收获三项荣誉，为这个今年的社区成绩再添亮点：</p><p>• KWDB 荣获数据库领域"<strong>开源先锋项目</strong>"。</p><p>• KaiwuDB 资深技术专家、KWDB 社区 TOC 成员窦志彤获评"<strong>开源贡献之星</strong>"。</p><p>• KWDB 社区被授予"<strong>校源行优秀合作伙伴</strong>"。</p><p>感谢每一位社区成员的陪伴与贡献。期待未来继续与大家同行，在开源的道路上共同成长，共创更多可能！</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444328" alt="" title="" loading="lazy"/></p><p>KWDB 获颁数据库领域开源先锋项目及开源贡献之星</p><h2><strong>9、KWDB 精彩亮相 2025 开放原子开发者大会</strong></h2><p>11 月的尾声，我们也在开放原子开发者大会上留下了难忘的足迹。</p><p>11 月 21-22 日，2025 开放原子开发者大会在北京隆重举行。开幕式上，"KWDB 核心贡献挑战赛"的一等奖团队代表登台，接受了第三届开放原子大赛首批赛项的荣誉颁奖，展现了社区开发者的卓越实力。</p><p>在同期举办的"AI 时代数据库创新实践分论坛"中，KaiwuDB 资深技术专家、KWDB 社区 TOC 委员窦志彤，以《AI 时代的数据基石》为题，带来了关于开源分布式多模数据库 KWDB V3.0 的技术演进与未来规划的深度分享。</p><p>从赛场到讲台，从社区贡献到技术展望，这个十一月，因每一位参与者的投入而更加完整。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444329" alt="" title="" loading="lazy"/></p><p>KWDB "开源贡献之星"窦志彤受邀做主题分享</p>]]></description></item><item>    <title><![CDATA[如何通过制造工艺创新提升智能制造效率？ ]]></title>    <link>https://segmentfault.com/a/1190000047444342</link>    <guid>https://segmentfault.com/a/1190000047444342</guid>    <pubDate>2025-12-02 19:06:20</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在全球制造业的激流中，一场以智能制造为核心的技术革命正在悄然改变着传统的生产方式。在这场变革中，制造工艺创新作为转型的关键支点，正成为推动整个行业变革的决定性力量。广域铭岛，作为这一领域的先行者，通过其领先的技术平台，开创了多个创新应用方向，引发了一场颠覆性的转型浪潮。<br/>制造工艺创新不仅仅体现在技术层面，更是一种思维方式的转变。传统制造业中，工艺往往是通过经验积累和试错得到优化，这种方式效率低下且缺乏系统性；而现代制造工艺创新则借助数据驱动和智能算法，实现了从被动响应到主动预判的智能化转变。这种创新模式不仅提升了生产效率，更重要的是建立起一种可持续的技术沉淀机制。在新能源电池制造这一新兴领域中，工艺创新的价值尤为显著。<br/>汽车制造工艺的智能化转型为我们提供了极具说服力的案例。在冲压、焊装、涂装到总装的整个工艺链中，新技术的应用使传统制造业焕发新生机。例如，在电池电芯装配这一关键环节，制造工艺的突破不仅提升了装配精度，更实现了生产全流程的数字化监控。这种创新模式正是广域铭岛的核心优势所在，通过其Geega工业互联网平台，将AI能力嵌入到电池制造的各个工序中，实现了从单个工艺到整个生产系统的智能化跨越。<br/>更为深入的是，制造工艺创新正在推动整个产业链的重构。广域铭岛通过横向融合5G、物联网、数字孪生等技术，以及纵向贯通设备、产线、工厂级应用的多层架构，构建了独特的技术生态。这种生态化创新思维，不仅加快了工艺知识的标准化输出，更显著提升了问题定位效率。如相关数据显示，在某些项目中，问题诊断时间从2小时缩短至20分钟，处置效率提升6倍。这些成果充分证明了制造工艺创新在实际应用中的卓越价值。<br/>值得注意的是，制造工艺创新具有极强的渗透力。这种创新不仅仅停留在单一技术突破层面，更通过系统性整合实现全方位提升。在电解铝行业中，广域铭岛的平台应用使电流效率从92%提升至96%以上，年节电量达1.2亿千瓦时，碳排放减少约10万吨。这种全方位的创新成果，展示了制造工艺在提升效率、降低成本和实现绿色可持续发展方面的巨大潜能。<br/>最终，制造工艺创新的真正价值在于其为未来的智能制造奠定了坚实基础。在这个过程中，广域铭岛通过建立开放生态系统，不仅促进了技术成果的推广，更重要的是推动了整个行业的技术升级。实践证明，制造工艺的创新能够在三个层面同时发力：提升生产效率、提高产品质量和降低运营成本。而这一过程，正是广域铭岛平台的核心优势所在。</p>]]></description></item><item>    <title><![CDATA[Android 弹出进度条对话框 避免用]]></title>    <link>https://segmentfault.com/a/1190000047444344</link>    <guid>https://segmentfault.com/a/1190000047444344</guid>    <pubDate>2025-12-02 19:05:36</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>下面给出最常用、最简洁的 Java 实现方式：<br/><strong>ProgressDialog</strong>（已废弃但仍可用）和 <strong>ProgressBar + 透明不可取消 Dialog</strong>（推荐，兼容性好，可定制）。<br/>两种写法都 <strong>强制屏蔽用户点击</strong>（setCancelable(false) + setCanceledOnTouchOutside(false)），避免界面交互。</p><hr/><p>一、ProgressDialog（一行代码即可，已废弃但简单）</p><pre><code class="java">private ProgressDialog progressDialog;

private void showLoading_PD() {
    if (progressDialog == null) {
        progressDialog = new ProgressDialog(this);   // this = Activity
        progressDialog.setMessage("加载中…");
        progressDialog.setIndeterminate(true);
        progressDialog.setCancelable(false);          // 屏蔽返回键
        progressDialog.setCanceledOnTouchOutside(false); // 屏蔽外部点击
    }
    progressDialog.show();
}

private void dismissLoading_PD() {
    if (progressDialog != null &amp;&amp; progressDialog.isShowing()) {
        progressDialog.dismiss();
    }
}</code></pre><hr/><p>二、官方推荐：自定义 Dialog（通用，不废弃）</p><ol><li>先写个极简布局 <code>dialog_loading.xml</code>（放根目录 <code>res/layout/</code>）：</li></ol><pre><code class="xml">&lt;?xml version="1.0" encoding="utf-8""&gt;
&lt;LinearLayout xmlns:android="http://schemas.android.com/apk/res/android"
    android:layout_width="wrap_content"
    android:layout_height="wrap_content"
    android:orientation="horizontal"
    android:padding="24dp"
    android:gravity="center_vertical"&gt;

    &lt;ProgressBar
        android:layout_width="32dp"
        android:layout_height="32dp"
        android:indeterminate="true"/&gt;

    &lt;TextView
        android:id="@+id/tv_msg"
        android:layout_marginStart="16dp"
        android:layout_width="wrap_content"
        android:layout_height="wrap_content"
        android:text="加载中…"
        android:textSize="16sp"/&gt;
&lt;/LinearLayout&gt;</code></pre><ol start="2"><li>Java 代码：</li></ol><pre><code class="java">public class LoadingDialog {

    private final Dialog dialog;

    public LoadingDialog(@NonNull Activity activity) {
        dialog = new Dialog(activity);
        dialog.setContentView(R.layout.dialog_loading);
        // 去掉标题
        if (dialog.getWindow() != null) {
            dialog.getWindow().setBackgroundDrawable(new ColorDrawable(Color.TRANSPARENT));
        }
        // 关键：禁止一切返回/触摸取消
        dialog.setCancelable(false);
        dialog.setCanceledOnTouchOutside(false);
    }

    public void show() {
        if (!dialog.isShowing()) dialog.show();
    }

    public void dismiss() {
        if (dialog.isShowing()) dialog.dismiss();
    }
}</code></pre><ol start="3"><li>在 Activity / Fragment 中使用：</li></ol><pre><code class="java">LoadingDialog loading = new LoadingDialog(this);   // this = Activity
loading.show();
// ...耗时操作...
loading.dismiss();</code></pre><hr/><p>三、几点注意</p><ol><li>两种写法都 <strong>必须在主线程</strong>（UI 线程）中 <code>show()/dismiss()</code>。</li><li>如果放在 <code>AsyncTask/Thread</code> 里，用 <code>runOnUiThread()</code> 或 <code>Handler(Looper.getMainLooper())</code>。</li><li>若使用 <code>DialogFragment</code> 同理，只要 <code>setCancelable(false)</code> 即可。</li><li>Android O 以后官方推荐用 <code>ProgressBar</code> + <code>Dialog/DialogFragment</code>，<code>ProgressDialog</code> 虽仍能用，但随时可能被彻底移除，建议新项目用第二种方案。</li></ol><p>复制即可运行，屏蔽一切用户点击事件。</p>]]></description></item><item>    <title><![CDATA[如何通过数字化协同战略优化研发管理效率？]]></title>    <link>https://segmentfault.com/a/1190000047444350</link>    <guid>https://segmentfault.com/a/1190000047444350</guid>    <pubDate>2025-12-02 19:04:47</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在制造业数字化转型的时代洪流中，研发管理作为企业技术创新的生命线，其体系化建设已超越传统工具范畴。广域铭岛凭借其深厚的行业洞察，创新性地推出了Geega捷做设计研发协同平台，以三维数据管理为核心突破口，重构研发价值链条。<br/>制造业企业常陷入效率与质量的双重困境：需求端与技术端的断层导致企业资源配置失衡，而研发部门内部又普遍存在工作流程割裂的问题。这类企业在设计环节最显著的表现是版本混乱与协同不足。面临这些挑战，企业亟需建立专业的研发管理体系，实现从创意萌发到产品落地的全链路协同。<br/>捷做平台的核心价值体现在其创新理念与实践路径相融合的优势。PDM模块为企业提供可追溯的设计数据中心，支持产品全生命周期管理；Fview实现了零件与工艺的云端化，支持3D工艺引擎驱动的高效协同场景；FMEA则建立了预防为主的质量防护体系，让质量管理工作从单点式演变为系统性。<br/>以某白电企业为例，通过部署捷做平台平台后，引入了标准化管理和项目流程管控。设计变更的有效控制避免了BOM数据错误问题，而基于工时预测的质量体系让企业能够在第一次"FMEA"现场检测中发现并消除设计缺陷。这种转变彻底改变了传统研发需经历反复测试才能被确认的局面。其中，Fview通过智能算法优化工艺路线，让产线操作接口更加统一化，项目的多维度管控思想贯穿始终。从设计角度看，多视图BOM使得工艺路线规划和三维作业指导生成更加科学合理；从生产维度看，系统输出的立体化工艺文件降低了操作培训成本。这一系列变化的真实数据印证了平台效能，例如在某科技企业案例中，零部件复用率提升35%，用户满意度呈现正态增长特征。<br/>更值得关注的是捷做平台实现的降本增效战略，特别是在产品上市周期管控上的突破。通过创新的三维模型共享机制，各部门不需要物理"I/O"即可获取所需设计信息，真正做到设计与生产双向赋能，不仅显著缩短了开发周期，更在高质量研发与运维安全之间建立了数字化的思维桥梁。平台构建的知识资产体系，帮助企业打通了从前端需求到后端交付的闭环链条，FMEA智能推送的防错功能自动过滤变形分析中的误判风险。这些创新举措无疑都是企业数字化管理的典范，广域铭岛正引导企业实现研发管理的专业化革新，将系统性思维深化到质量管控、资源调度等更细化的领域。<br/>在转型中，企业需要的不仅是简单的研发工具，而是有能协同推进管理理念与技术水平升级的战略伙伴。广域铭岛提供的不只是解决方案，而是以数据中枢为核心的专业研发指导框架，包括全栈式问题管理与质量追溯机制，全面覆盖了企业创新系统各层级需求。正如此哲所说，高质量的3D工艺文件是企业最宝贵的数字化资产；正如广域铭岛始终强调的那样，成功的研发管理应当聚焦人机协同的优化，让数据流动成为创新最有力的推手。</p>]]></description></item><item>    <title><![CDATA[NeurIPS 2025 | 浙大、浙工]]></title>    <link>https://segmentfault.com/a/1190000047444363</link>    <guid>https://segmentfault.com/a/1190000047444363</guid>    <pubDate>2025-12-02 19:04:07</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444365" alt=" " title=" "/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444366" alt=" " title=" " loading="lazy"/></p><p>论文标题：<em>Controlling Thinking Speed in Reasoning Models</em></p><p>作者团队：浙江大学、阿里巴巴云、浙江工业大学</p><p>发布时间：2025年10月30日</p><p><a href="https://link.segmentfault.com/?enc=HztnsLTuxaMTosiNlYisTQ%3D%3D.sHLqQ7QQE0TfW67DGqYVT8CmRrcKcoh%2BuTDNGNcHZr42vhVIXMo%2Fpeqn4DG7gJi%2F" rel="nofollow" target="_blank">👉一键直达论文</a></p><p><a href="https://link.segmentfault.com/?enc=rVVPE38wrdGNB%2F8GU1VEbg%3D%3D.uZO5nFzWQ1AFFrhwnNpEY0T7KkGHID62QCrOAIbQUwS6rmVUBwwLgWit9HanRBQ5YQDyVcLjhVKIAXNKE791etCp4hr5mJlcaK3pUwziErzTRa%2BCpSgCdoFM0BBwjMYAn2RIEdDqyKWPKBgBTqiVzhvowKviOCKvS%2FaoRXFsuYo%3D" rel="nofollow" target="_blank">👉Lab4AI大模型实验室论文阅读</a></p><p>✅Lab4AI平台提供AI导读和AI翻译等工具，辅助论文阅读。您还可以投稿复现这篇论文~</p><h2>核心亮点</h2><p>本研究的核心亮点集中在三大突破性贡献：</p><ul><li>其一，首次揭示LRMs存在快慢思维模式的内在切换机制，发现“To”“Okay”等特定开头词可分别触发快速、慢速思维，为思维控制提供了天然切入点；</li><li>其二，基于表示工程技术首创思维速度控制方法，通过读取快慢思维样本的PCA导向向量，并向模型隐藏状态注入该向量，实现推理时的缩放效应；</li><li>其三，设计自适应动态推理策略，借助Jensen-Shannon散度量化推理难度、滑动窗口检测高难度片段，再通过动态阈值机制自动在简单段加速、复杂段减速，且方法无需训练即可嵌入现有部署系统，兼顾创新性与实用性。</li></ul><h2>核心结果</h2><p>研究在多模型、多基准上验证了方法有效性。</p><ol><li>实验以DeepSeek-R1-Distill-Qwen-7B/32B、QwQ-32B等为测试模型，在AIME24、MATH-500等基准上对比预算强制法等基线；</li><li>思维速度控制方面，所有LRMs加速（α&gt;0）时准确率较基线平均提升8.2-11.4%，减速（α&lt;0）时平均提升0.51-1.46%；自适应控制表现更优，相比原始LRMs，在将准确率提升1.26%的同时，减少8.56%的token使用量；</li><li>此外，模型呈现明显测试时缩放效应，随响应长度增加（思维变慢），性能持续提升，验证了思维速度调控的有效性与稳定性。</li></ol>]]></description></item><item>    <title><![CDATA[项目级效能提升一站式交付最佳实践 百度G]]></title>    <link>https://segmentfault.com/a/1190000047444370</link>    <guid>https://segmentfault.com/a/1190000047444370</guid>    <pubDate>2025-12-02 19:03:19</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>导读</h2><p>面对研发交付中Feature级项目复杂度攀升、信息分散及跨端协作低效等痛点，传统的Story级管理模式已显乏力。本文详细阐述了一套“项目级效能提升一站式交付最佳实践”，通过构建三大核心体系重塑研发流程：一是通过AI侧边栏与风险管控打造“AI项目管理”，实现信息聚合与决策提效；二是推动“一站式Feature交付”，利用AI自动生成测试方案与搭建环境，实现端到端闭环；三是建立涵盖“重点战役-Feature-Story”的三级数字化度量体系。这套新范式旨在以智能替代人工低效环节，助力团队从“被流程束缚”向“借智能破局”转变，实现研发效能的质的飞跃。</p><h2>01 背景</h2><p>在研发交付场景中，Story级别效率持续向好，但端到端 Feature 级项目持续增多，复杂度呈上升趋势。在传统工作模式下，研发团队正遭遇一系列制约效能的痛点：</p><ul><li><strong>信息分散、Feature视角管控缺失</strong>：研发过程中，需求卡片、Bug列表、测试用例等信息分散于不同空间；以及历史交付流程侧重 story 侧，缺少完整需求视角交付的风险洞察，导致项目无预警延期，管理成本趋增。</li><li><strong>多方协作效率低下</strong>：联调测试依赖手动触发脚本，环境配置依赖人工协调；多模块联动存在用例交叉冗余、测试评审缓慢；跨产品线借调沟通成本高，各端测试人力重复投入且耦合重，拖慢研发节奏，项目进度风险激增 。</li><li><strong><em><em>Feature 级数字化能力缺失</em></em></strong>：既缺乏能够精准衡量 Feature 价值与进展的指标度量体系，也缺乏用于支撑分析、优化的标准化数据积累流程，导致 Feature 相关的评估无据可依，数据资产难以沉淀，进一步制约效能提升与问题根因定位。</li></ul><p>为有效破解以上痛点，提升产研团队整体效能，我们构建项目级交付新范式：通过 “ <strong><em><em>AI 项目管理</em></em></strong>” 打造一站式项目信息与工具服务获取新入口，实现过程风险AI精准管控；通过 “<strong><em><em>一站式 Feature 交付</em></em></strong>” 推动单端联调模式向端到端交付模式转变，同时借助 AI 测试提效驱动交付效能跃升；通过 “<strong><em><em>项目级效能数字化度量</em></em></strong>” 构建完善的效能评估体系。</p><ul><li><strong>AI项目管理</strong>：借助群聊侧边栏打造一站式项目信息看板，提升风险感知与决策效率；支持产研团队一键获取所需工具、服务，提升工具使用与协同效率；依托AIQA构建全流程管控能力并提效。</li><li><strong>一站式Feature交付</strong>：通过建设端到端交付能力，释放冗余人力，并将测试方案生成、基础环境搭建等场景与AIQA深度融合，为 Feature 全生命周期提供高效、智能的一站式支撑。</li><li><strong>项目级效能数字化度量</strong>：构建涵盖重点战役、Feature、Story 三个层级的更全面、立体的洞察体系，借助数据驱动的力量，全方位、深层次评估分析产品开发过程的效能表现与最终成果，为业务决策提供坚实有力数据支撑。</li></ul><p>以智能替代人工低效环节，推动团队从 “被流程束缚” 向 “借智能破局” 转变，为效能提升注入新动能，引领团队协作进入智能化新范式，让每一次交付都更高效、更可控！</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444372" alt="图片" title="图片"/></p><h2>02 AI项目管理</h2><h3><strong>2.1 项目管理痛点</strong></h3><p>在研发交付体系中，<strong><em><em>Feature级项目</em></em></strong>持续<strong><em><em>增多</em></em></strong>，复杂度呈上升趋势，团队项目管理普遍面临四大核心痛点：</p><ul><li>信息碎片化带来高昂的把控成本</li><li>跨角色协作过程产生的高额隐性成本</li><li>分散工具链造成执行效率损耗</li><li>项目交付进展、风险纯依赖人工通知确认，交付周期长尾</li></ul><p>为破解上述痛点，我们构建融合 “侧边栏 + AIQA过程管控” 的 AI 项目管理体系，实现信息整合、协作提效、工具聚合与交付管控闭环。</p><h3><strong>2.2 侧边栏应用</strong></h3><p><strong><em><em>侧边栏统一解决方案，</em></em></strong>通过配置<strong><em><em>侧边栏</em></em></strong>框架，<strong><em><em>灵活定制卡片</em></em></strong>，以满足业务线各类场景应用，通常涵盖<strong><em><em>项目概览</em></em></strong>、<strong><em><em>项目详情</em></em></strong>、<strong><em><em>工具集合</em></em></strong>三大核心模块。</p><ul><li><strong><em><em>项目概览模块</em></em></strong>：以 PMO 视角为核心，深度整合项目进度、资源占用、风险预警等维度数据，支撑 PMO 实现精准的项目群管控与决策穿透 。</li><li><strong><em><em>项目详情模块</em></em></strong>：聚焦产研团队执行视角，整合项目关联卡片、各类文档、bug 记录、上线记录、实验记录及测试环境等信息，保障研发高效协同与质量可控。</li><li><strong><em><em>工具集合模块</em></em></strong>：提供了项目管理、联调提效等工具，可根据角色、产品线、项目，提供不同的工具入口，推动研发端到端衔接与操作链路简化。</li></ul><p>通过具象化的配置实践，可在实际业务场景中落地，助力各角色高效协作，破解产研团队项目管理痛点 。以下实践案例，包括：<strong><em><em>项目概览</em></em></strong>、<strong><em><em>项目详情</em></em></strong>、<strong><em><em>工具集三大类内容</em></em></strong>，且支持PC和手机端样式，以及群吊顶和侧边栏位置。</p><p>| 项目概览 | 项目详情 | 工具集 |<br/>| <img referrerpolicy="no-referrer" src="/img/remote/1460000047444373" alt="" title="" loading="lazy"/> | <img referrerpolicy="no-referrer" src="/img/remote/1460000047444374" alt="" title="" loading="lazy"/> | <img referrerpolicy="no-referrer" src="/img/remote/1460000047444375" alt="" title="" loading="lazy"/> |</p><h3><strong>2.3 过程管控</strong></h3><p>在项目各环节，AIQA以PMO数字助手的角色，建设基于AIQA的项目进度/风险提醒能力，通过输入框形式进行交互，全流程管控并提效。具体能力包括：AB实验长时间停留、AB实验放量实时、技术方案&amp;打点方案等未评审风险等</p><ul><li>项目评审风险提醒：支持技术方案、UI、实验方案、打点方案等提醒</li><li>AB实验：待启动实验、实验中、评估中等9个阶段的停留时长；单台、放量、灰度等7个阶段的放量提醒</li><li>项目进度风险提醒</li></ul><h2>03 一站式Feature交付</h2><h3><strong>3.1 端到端交付</strong></h3><p>产研需求常常是包括客户端、前端、服务端，两端以上联动的需求占比较高（&gt;40%），各端分别投入人力测试，测试耦合严重，人力重复投入严重，通过<strong><em><em>建设交付能力</em></em></strong>，支撑实现需求测试从「单端测试+多端联调」交付模式，转为「<strong><em><em>端到端」交付模式，释放冗余人力</em></em></strong>。</p><p>例如客户端&amp;服务端联动的需求，通过从功能角度评估客户端case对服务端case覆盖，覆盖的部分由客户端QA端到端测试，未覆盖部分通过夯实自动化能力补充测试或调起服务端QA补充测试，并通过准入/准出能力评估影响面和测试完备度，保证项目质量，释放冗余人力，提升整体测试吞吐。</p><p>各阶段支撑能力建设有：</p><ul><li><strong><em><em>测试前</em></em></strong>：通过<strong><em><em>端到端模式识别</em></em></strong>判断需求是否可以进行端到端的交付，动态<strong><em><em>自动分配测试人力，</em></em></strong>基于需求生成<strong><em><em>端到端测试用例，</em></em></strong>前端&amp;服务端的<strong><em><em>环境自动搭建/更新</em></em></strong>，创建相应的mock环境等</li><li><strong><em><em>测试中</em></em></strong>：<strong><em><em>基于代码提交进行风险洞察，</em></em></strong>以及提供<strong><em><em>问题定位、mock 能力</em></em></strong>供前端/客户端的同学更顺畅的完成测试过程，并且在过程中对测试流量进行录制，实时采集覆盖率，供后续测试评估；并在测试过程中阶段性评估测试进度风险，及时发现&amp;通报过程中风险；</li><li><strong><em><em>测试准出</em></em></strong>：测试完成后，自动触发服务端的<strong><em><em>异常测试</em></em></strong>、<strong><em><em>自动生成后续用于回归的自动化case</em></em></strong>，以保障服务端的迭代质量，整体完成后根据手工case完成率、bug闭环率、手工测试覆盖率、异常测试结果等多个维度综合进行测试<strong><em><em>准出评估</em></em></strong></li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444376" alt="图片" title="图片" loading="lazy"/></p><h3><strong>3.2 AI测试提效</strong></h3><h4>3.2.1 测试方案自动生成</h4><p>我们探索测试方案自动生成，目前可以通过分析MRD/PRD/CR，结合历史业务&amp;工具知识经验，自动生成完整的测试方案，包括：</p><ul><li>对需求的基本洞察理解（背景概述、分系统/模块升级点）</li><li>联调测试范围（涉及系统/模块等）作为环境推荐能力的输入</li><li>联调测试用例及可驱动AI测试执行的相关场景参数</li><li>测试经验&amp;风险、历史相似项目参考</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444377" alt="图片" title="图片" loading="lazy"/></p><h4>3.2.2 测试环境LUI搭建</h4><p>建设LUI交互端到端环境部署能力，支持产研团队各业务线及图搜联调场景调用，端到端环境部署时长保持在小时级</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444378" alt="图片" title="图片" loading="lazy"/></p><p>功能点：</p><ul><li>聚合用户的部署意图，支持多种prompt，完成LUI环境部署诉求：支持Feature卡片、QA单模块产物、单story卡片、联调CR、Fcnap域名等多种部署意图，聚合部署变更的信息</li><li>提供丰富的prompt向量库维护，实现精准的意图识别：prompt维护</li><li>基于qs-bot openmanus和mcp框架，实现丰富的工具集，通过动态规划调度工具交付各场景下的端到端测试环境：需求变更信息处理，数据聚合；触发多路复用环境部署；kirin异步轮询部署状态；qsbot回调重新触发动态规划；环境前后端链接与配置管理</li><li>聚合部署任务中的工具使用历史，异步回调完成环境部署完成后的智卡推送：聚合单次LUI中动态规划的工具返回信息；完成智卡数据构造并发卡推送给用户</li></ul><h2>04 项目级效能数字化度量</h2><p>针对 Story 维度的度量工作，主要聚焦于对研发测试阶段展开持续且深入的洞察，旨在为从事研发测试工作的人员提供切实可行的优化方向与手段。但story维度的度量也存在如下问题：</p><ul><li>Story 粒度本身存在一定局限性，呈现研发-测试阶段的效率洞察，向左延伸的需求设计阶段，向右延伸的上线实验转全阶段，都不涵括在内，无法代表整体情况；</li><li>随着产品复杂程度日益提高，传统以 Story 维度为主的度量方式，无法站在产品需求视角观测交付效率，已难以满足需求；</li><li>站在每个组织的重点战役角度，story度量的方式，无法看到战役视角的资源投入和效率瓶颈，无法提供深层次的分析和决策。</li></ul><p>为此我们开始建设贯穿重点战役-》feature-》Story的统一三级视角的数字化方案：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444379" alt="图片" title="图片" loading="lazy"/></p><h3><strong>4.1 Feature级数字化</strong></h3><p>围绕从最初的发布规划、设计构思、开发实施、测试验证、正式上线，直至后续的小流量到逐步推全的整个生命周期，实施全方位、系统性的评估与监测，确保 Feature 的每个阶段都能得到有效把控与持续优化。最终实现更加高效地管理和优化产品开发流程，以及进一步提升团队协作效率。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444380" alt="图片" title="图片" loading="lazy"/></p><h3><strong>4.2 战役级数字化</strong></h3><p>重点战役是企业为实现特定战略目标而发起的关键行动，往往需要通过一系列具体的Feature来实现其目标。</p><p>协同机制：重点战役的范围在季度初由PMO圈定，在业务拆解功能时在Feature上打上标记，数字化定期采集和处理分析，支持业务进行重点战役的进度监控和项目复盘。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444381" alt="图片" title="图片" loading="lazy"/></p><h2>05 总结与展望</h2><p>立足项目级一站式交付实践，AI 原生思维在研发领域的价值将向更深、更广维度延伸：</p><ul><li>从能力深化看，AI 将实现从 “被动响应需求” 到 “主动预测需求” 的升级，通过持续学习团队协作数据、项目交付规律，可提前预判研发各阶段的核心需求，预警潜在风险，让智能服务更具前瞻性</li><li>从场景拓展看，AI 与高频协作场景的融合将突破群聊边界，向需求评审、代码联调、线上问题排查等全研发链路渗透，构建 “全场景覆盖、全流程智能” 的研发协同体系，让智能能力随研发动作自然触发</li><li>从生态构建看，基于侧边栏的 AI 驱动协作模式，可进一步打通跨团队、跨业务线的数据与工具壁垒，形成可复用、可迭代的研发效能提升方案，推动 AI 原生思维从单一团队实践，升级为业务级研发协同标准</li></ul><p>最终，AI 将不再仅是 “提效工具”，更将成为研发团队创新的 “核心引擎”，通过持续解放人工低效环节，让团队聚焦于技术攻坚、产品创新等核心工作，推动研发领域从 “效能提升” 向 “价值创造” 跨越，开启智能化研发的全新阶段。</p>]]></description></item><item>    <title><![CDATA[从销售到供应链：6 大 CRM+ERP ]]></title>    <link>https://segmentfault.com/a/1190000047444404</link>    <guid>https://segmentfault.com/a/1190000047444404</guid>    <pubDate>2025-12-02 19:02:41</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>从销售到供应链：6 大 CRM+ERP 平台核心模块评测（超兔 / 金蝶 / Salesforce 等）</p><h2>引言</h2><p>在数字化转型进入“全链路整合”的新阶段，企业对管理系统的需求已从“单一CRM销售管理”升级为“<strong>客户-商机-销售-库存-采购</strong>全流程闭环”。传统CRM（如Salesforce）与ERP（如金蝶）的割裂式部署，往往导致数据断层、流程冗余；而原生一体化系统（如超兔一体云）则通过底层数据连通，实现了“销售触发库存、库存驱动采购、采购联动财务”的全链路自动化。</p><p>本文选取<strong>超兔一体云、Salesforce、SugarCRM、Freshsales、金蝶、管家婆</strong>6大主流平台，围绕<strong>客户管理、商机管理、销售跟进、库存管理、采购管理</strong>五大核心模块展开横向对比，结合流程图、脑图、雷达图等工具，揭示各平台的差异化优势与适配场景。</p><h2>一、核心概念与评估框架</h2><p>在正式对比前，先明确本文的<strong>评估维度</strong>：</p><ol><li><strong>全业务一体化</strong>：CRM与库存/采购的原生连通性（非集成）；</li><li><strong>AI智能能力</strong>：线索评分、预测分析、自动化的智能化水平；</li><li><strong>定制化灵活度</strong>：适配企业个性化流程的成本与难度；</li><li><strong>生态</strong> <strong>兼容性</strong>：与现有ERP/工具的集成能力；</li><li><strong>中小微适配性</strong>：操作复杂度、成本、轻量化程度。</li></ol><h2>二、五大核心模块横向对比</h2><h3>（一）客户管理：从“线索收集”到“全生命周期运营”</h3><p>客户管理的核心是<strong>整合多渠道数据、构建360度视图、实现分层运营</strong>。各平台的差异集中在“数据补全能力”“多渠道整合深度”“定制化灵活性”三方面。</p><h4>1. 横向对比表</h4><table><thead><tr><th>品牌</th><th>核心能力</th><th>差异化优势</th><th>局限性</th></tr></thead><tbody><tr><td><strong>超兔一体云</strong></td><td>多渠道集客（百度/抖音/官网/微信）、客户查重（公司名/手机号/简称模糊）、工商信息自动补全（天眼查/微信头像）、客户分层（需求培养/有需求/成功）</td><td>原生多渠道整合+背景补全，低成本实现客户画像</td><td>AI预测精度弱于Salesforce</td></tr><tr><td><strong>Salesforce</strong></td><td>360度客户视图（整合互动/交易/服务记录）、Einstein AI线索评分、多渠道互动历史</td><td>企业级客户视图+AI智能，适合高价值客户运营</td><td>多渠道集客需额外配置，库存/采购需集成</td></tr><tr><td><strong>SugarCRM</strong></td><td>高度可定制客户档案、数据权限分级（字段/模块级权限）、私有化部署、GDPR合规</td><td>敏感行业（金融/医药）的 data security 首选</td><td>原生多渠道整合弱，需二次开发</td></tr><tr><td><strong>Freshsales</strong></td><td>AI自动补全工商信息、多渠道线索整合（网站/社交媒体/地推）、移动端360视图</td><td>轻量级AI驱动，适合初创团队快速搭建客户体系</td><td>复杂客户分层（如项目型）支持不足</td></tr><tr><td><strong>金蝶</strong></td><td>业财联动客户视图（整合销售/库存/财务数据）、移动端多终端跟进（文字/图片/语音）、客户全生命周期与ERP同步</td><td>从销售到财务的全链路数据连通</td><td>客户背景分析（如工商）弱于超兔</td></tr><tr><td><strong>管家婆</strong></td><td>多渠道客户统一管理（线下/线上/微信）、移动端跟进记录、中小微适配的客户分层（新客/老客/流失）</td><td>中小微企业的“拿来即用”，操作简单</td><td>复杂客户画像（如经纬度）无法实现</td></tr></tbody></table><h4>2. 关键差异解析</h4><ul><li><strong>超兔的“原生多渠道+背景补全”</strong> ：通过官网落地页自定义表单、抖音/百度线索自动抓取，结合工商信息/微信头像补全，快速构建客户画像，解决了“线索碎片化”痛点；</li><li><strong>Salesforce的“企业级360视图”</strong> ：整合邮件/电话/交易等多渠道互动历史，适合大型企业管理高价值客户，但多渠道集客需依赖Marketing Cloud等生态产品；</li><li><strong>SugarCRM的“数据安全”</strong> ：支持字段级权限控制（如金融行业的客户资产信息仅客户经理可见），私有化部署满足《数据安全法》要求，是敏感行业的首选。</li></ul><h3>（二）商机管理：从“线索筛选”到“高价值转化”</h3><p>商机管理的核心是<strong>识别高潜力线索、优化销售漏斗、提升转化效率</strong>。各平台的差异集中在“AI预测能力”“漏斗定制化”“复杂项目适配”三方面。</p><h4>1. 横向对比表</h4><table><thead><tr><th>品牌</th><th>核心能力</th><th>差异化优势</th><th>局限性</th></tr></thead><tbody><tr><td><strong>超兔一体云</strong></td><td>三一客小单模型（三定+关键节点）、多方项目跟单（项目组/合同/采购全周期）、阶段/预期日期管理</td><td>适配小单快单与复杂项目，全链路商机追踪</td><td>AI预测精度弱于Salesforce</td></tr><tr><td><strong>Salesforce</strong></td><td>Einstein AI线索评分（预测成交概率）、自定义销售漏斗、预测性商机分析（未来30天成交概率）</td><td>企业级AI预测，适合高价值商机管理</td><td>项目型商机需集成Field Service等产品</td></tr><tr><td><strong>SugarCRM</strong></td><td>自定义商机阶段（如“需求确认→报价→签单”）、成交概率计算、可视化转化报表</td><td>灵活配置，适配个性化销售流程</td><td>缺乏智能预测，依赖手动分析</td></tr><tr><td><strong>Freshsales</strong></td><td>AI智能线索评分（基于互动频率/内容）、高优先级商机推送（如“7天未跟进”自动提醒）、看板视图监控</td><td>轻量级AI驱动，适合快速转化的中小商机</td><td>复杂项目商机（如多方决策）管理弱</td></tr><tr><td><strong>金蝶</strong></td><td>商机全流程追踪（市场活动→线索→合同）、客户流失预警（30天未互动自动提醒）、项目拓展跟踪（高层沟通/投标）</td><td>与ERP联动，覆盖从线索到合同的全流程</td><td>商机智能分析弱于纯CRM品牌</td></tr><tr><td><strong>管家婆</strong></td><td>老客户需求挖掘（基于历史购买记录）、简单商机阶段管理（如“跟进中→待签单”）、销售计划推进</td><td>适合中小微企业的老客户复购商机</td><td>复杂商机（如长单/项目）管理能力不足</td></tr></tbody></table><h4>2. 关键差异解析</h4><ul><li><strong>超兔的“双模型覆盖”</strong> ：针对小单快单（三一客：定性/定级/定量）、复杂项目（多方项目模型：项目组/合同/采购全周期），解决了“小单效率低、大单流程乱”的痛点；</li><li><strong>Salesforce的“Einstein AI”</strong> ：通过机器学习分析线索的互动频率、内容、历史成交数据，预测成交概率（如“线索A未来30天成交概率85%”），适合高价值商机的优先级排序；</li><li><strong>金蝶的“</strong> <strong>ERP</strong> <strong>联动”</strong> ：商机转化为合同后，自动同步至ERP生成收入凭证，实现“商机→合同→财务”的闭环，适合需业财一体化的企业。</li></ul><h3>（三）销售跟进：从“碎片化记录”到“全流程可控”</h3><p>销售跟进的核心是<strong>提升团队协作效率、减少流程遗漏、实现业绩可追踪</strong>。各平台的差异集中在“跟单视图完整性”“自动化程度”“项目管理能力”三方面。</p><h4>1. 横向对比表</h4><table><thead><tr><th>品牌</th><th>核心能力</th><th>差异化优势</th><th>局限性</th></tr></thead><tbody><tr><td><strong>超兔一体云</strong></td><td>360度跟单视图（整合客户/商机/库存/采购数据）、跟单时间线（超兔独有）、AI电话录音分析、自动生成日报</td><td>全维度跟单记录，适配复杂项目与团队协作</td><td>自动化工作流灵活性弱于Salesforce</td></tr><tr><td><strong>Salesforce</strong></td><td>自动化工作流（如“线索分配给区域销售”）、邮件/电话集成、移动端实时追踪、团队协作（共享任务/笔记）</td><td>企业级自动化，适合大型销售团队</td><td>项目型跟进需集成Field Service等产品</td></tr><tr><td><strong>SugarCRM</strong></td><td>任务自动化分配（如“商机阶段推进后自动创建任务”）、跟进时间线、私有化部署</td><td>数据安全与流程可控，适配敏感行业</td><td>缺乏原生AI录音分析等智能工具</td></tr><tr><td><strong>Freshsales</strong></td><td>一键拨号、通话录音、Slack集成（任务提醒同步）、移动端任务提醒</td><td>轻量级工具，适合外勤与快速跟进</td><td>复杂项目跟进（如多方决策）能力弱</td></tr><tr><td><strong>金蝶</strong></td><td>业财联动跟进（销售订单自动生成收入凭证）、全售中环节管理（发货/安装/收款）、移动库存查询（实时库存/价格）</td><td>从销售到售后的全流程闭环，财务数据实时同步</td><td>销售工具的智能化弱于纯CRM品牌</td></tr><tr><td><strong>管家婆</strong></td><td>扫码开单（快速生成销售单）、营销工具集成（拼团/分销）、实时库存查看、简单任务管理</td><td>中小微企业的快速操作，适合线下销售</td><td>复杂跟进场景（如项目）支持不足</td></tr></tbody></table><h4>2. 关键差异解析</h4><ul><li><strong>超兔的“360度跟单视图”</strong> ：整合客户背景、商机阶段、销售记录、库存状态、采购进度，销售无需切换系统即可查看全链路信息；<strong>跟单时间线</strong>（超兔独有）按时间顺序展示客户互动、任务、订单记录，解决了“跟进记录碎片化”问题；</li><li><strong>Freshsales的“轻量级工具”</strong> ：一键拨号、通话录音、Slack集成，适合外勤销售快速跟进，无需复杂培训；</li><li><strong>金蝶的“业财联动”</strong> ：销售订单生成后，自动扣减库存、生成收入凭证，财务实时查看销售业绩，解决了“销售与财务数据不同步”的痛点。</li></ul><h3>（四）库存管理：从“被动盘点”到“智能预警”</h3><p>库存管理的核心是<strong>实时监控</strong> <strong>库存状态、优化库存周转、减少呆滞料</strong>。各平台的差异集中在“原生一体化”“复杂库存操作”“智能预警”三方面。</p><h4>1. 横向对比表</h4><table><thead><tr><th>品牌</th><th>核心能力</th><th>差异化优势</th><th>局限性</th></tr></thead><tbody><tr><td><strong>超兔一体云</strong></td><td>原生库存管理、多仓库支持（最多500个）、SKU/批次/序列号管理、智能补货（基于历史数据+安全库存）</td><td>与CRM原生连通，无需集成</td><td>复杂BOM管理（如制造业）弱于金蝶</td></tr><tr><td><strong>Salesforce</strong></td><td>需集成第三方ERP（如SAP/Oracle）、库存数据同步（销售订单→库存扣减）</td><td>生态兼容，适合已用ERP的企业</td><td>原生无库存功能，依赖集成</td></tr><tr><td><strong>SugarCRM</strong></td><td>需二次开发对接ERP、库存预警定制（如“库存低于10个自动提醒”）</td><td>可定制，适配企业现有ERP</td><td>开发成本高，不适合快速部署</td></tr><tr><td><strong>Freshsales</strong></td><td>需API对接第三方库存工具、实时库存查询（销售时查看库存）</td><td>轻量级适配，适合无需复杂库存的销售团队</td><td>不支持复杂库存操作（如批次/序列号）</td></tr><tr><td><strong>金蝶</strong></td><td>ERP原生库存、多维度监控（仓库/批次/效期）、智能预警（呆滞料提前90天提醒）、呆滞料管理智能体</td><td>与ERP深度联动，适合制造业/零售等行业</td><td>库存功能与CRM的联动需配置</td></tr><tr><td><strong>管家婆</strong></td><td>实时库存监控、扫码出入库、多仓库同步、简单预警（如“库存不足”提醒）</td><td>中小微企业的快速库存管理，操作简单</td><td>复杂库存场景（如BOM/批次）支持不足</td></tr></tbody></table><h4>2. 关键差异解析</h4><ul><li><strong>超兔的“原生库存管理”</strong> ：销售订单生成时，库存自动扣减，触发智能补货（如“某商品库存低于安全库存，自动生成采购建议”），无需集成ERP，解决了“CRM与库存数据割裂”的痛点；</li><li><strong>金蝶的“</strong> <strong>ERP</strong> <strong>原生库存”</strong> ：支持复杂BOM管理（如制造业的“原材料→半成品→成品”）、批次/效期追踪（如食品行业的保质期管理），适合需精细库存管理的企业；</li><li><strong>Salesforce的“生态集成”</strong> ：适合已用SAP/Oracle ERP的企业，通过集成实现库存数据同步，但需额外成本与维护。</li></ul><h3>（五）采购管理：从“手动下单”到“智能协同”</h3><p>采购管理的核心是<strong>优化采购流程、</strong> <strong>降低成本</strong> <strong>、实现供需平衡</strong>。各平台的差异集中在“原生一体化”“智能采购”“复杂场景适配”三方面。</p><h4>1. 横向对比表</h4><table><thead><tr><th>品牌</th><th>核心能力</th><th>差异化优势</th><th>局限性</th></tr></thead><tbody><tr><td><strong>超兔一体云</strong></td><td>原生采购管理、智能补货（基于库存缺口+历史需求）、供应商比价（OpenCRM模块）、采购单拆分（根据供应商自动拆分）</td><td>与CRM/库存原生连通，低成本实现智能采购</td><td>复杂供应商管理（如分级）弱于金蝶</td></tr><tr><td><strong>Salesforce</strong></td><td>需集成第三方ERP、采购流程联动（采购单→入库→付款）</td><td>生态兼容，适合已用ERP的企业</td><td>原生无采购功能，依赖集成</td></tr><tr><td><strong>SugarCRM</strong></td><td>需二次开发对接ERP、采购流程定制（如“询比价→下单→入库”）</td><td>可定制，适配企业现有采购流程</td><td>开发成本高，不适合快速部署</td></tr><tr><td><strong>Freshsales</strong></td><td>需API对接第三方采购工具、简单采购记录（如“采购单创建”）</td><td>轻量级适配，适合无需复杂采购的销售团队</td><td>不支持复杂采购流程（如询比价/拆分）</td></tr><tr><td><strong>金蝶</strong></td><td>ERP原生采购、多行业定制（如制造业的BOM采购）、流程自动化（订单→入库→付款）、供应商分级</td><td>与ERP深度联动，适合制造业等复杂采购场景</td><td>采购功能与CRM的联动需配置</td></tr><tr><td><strong>管家婆</strong></td><td>简单采购流程（计划→订单→入库）、价格本管理、费用分摊（采购费用分摊至商品）</td><td>中小微企业的快速采购管理，操作简单</td><td>复杂采购场景（如询比价/供应商分级）支持不足</td></tr></tbody></table><h4>2. 关键差异解析</h4><ul><li><strong>超兔的“原生智能采购”</strong> ：通过库存缺口自动生成采购计划，匹配历史供应商（如“某商品上次采购的供应商A，价格最低”），自动拆分采购单（如“采购100件商品，拆分给3家供应商”），实现“库存→采购→供应商”的智能协同；</li><li><strong>金蝶的“</strong> <strong>ERP</strong> <strong>原生采购”</strong> ：支持复杂BOM采购（如“生产某成品需10种原材料，自动生成10张采购单”）、供应商分级（如“战略供应商/普通供应商”），适合需精细采购管理的企业；</li><li><strong>管家婆的“简单采购”</strong> ：适合中小微企业的“手动下单→入库”流程，操作简单，但无法应对复杂采购场景（如询比价/供应商分级）。</li></ul><h2>三、可视化工具辅助分析</h2><h3>1. 超兔全业务一体化流程图</h3><p>超兔的核心优势是<strong>原生全业务一体化</strong>，通过底层数据连通，实现“客户→商机→销售→库存→采购”的全流程自动化：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444406" alt="" title=""/></p><pre><code>flowchart LR
    A[多渠道集客\n（百度/抖音/官网/微信）] --&gt; B[客户查重\n（公司名/手机号/简称模糊）]
    B --&gt; C[客户背景补全\n（工商/微信/经纬度）]
    C --&gt; D[客户分层\n（需求培养/有需求/成功）]
    D --&gt; E[商机识别\n（线索筛选/阶段划分）]
    E --&gt; F[销售跟进\n（360视图/跟单时间线/AI录音分析）]
    F --&gt; G[库存联动\n（实时库存查询/出入库触发）]
    G --&gt; H[采购触发\n（智能补货/供应商比价）]
    H --&gt; I[业财闭环\n（订单→收入凭证→回款）]</code></pre><h3>2. 各品牌核心能力脑图</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444407" alt="" title="" loading="lazy"/></p><pre><code>mindmap
    root((CRM+ERP核心能力横评))
        超兔一体云
            全业务一体化
            多渠道集客
            三一客/多方项目跟单
            原生库存/采购管理
            低成本客制化
        Salesforce
            Einstein AI智能
            360度客户视图
            强大生态集成
            企业级销售管理
        SugarCRM
            高度可定制
            数据权限分级
            私有化部署
            敏感行业适配
        Freshsales
            AI驱动线索管理
            轻量级销售工具
            多渠道整合
            移动端高效
        金蝶
            业财一体化
            ERP深度联动
            智能库存预警
            多行业定制
        管家婆
            中小微轻量化
            销售营销工具
            实时库存监控
            简单流程适配</code></pre><h3>3. 雷达图评分（1 - 5分）</h3><table><thead><tr><th>指标</th><th>超兔</th><th>Salesforce</th><th>SugarCRM</th><th>Freshsales</th><th>金蝶</th><th>管家婆</th></tr></thead><tbody><tr><td>全业务一体化</td><td>5</td><td>2</td><td>1</td><td>1</td><td>3</td><td>2</td></tr><tr><td>AI智能能力</td><td>3</td><td>5</td><td>2</td><td>4</td><td>3</td><td>2</td></tr><tr><td>定制化灵活度</td><td>5</td><td>3</td><td>5</td><td>3</td><td>4</td><td>3</td></tr><tr><td>生态兼容性</td><td>3</td><td>5</td><td>3</td><td>3</td><td>4</td><td>2</td></tr><tr><td>中小微适配性</td><td>4</td><td>1</td><td>2</td><td>4</td><td>3</td><td>5</td></tr></tbody></table><h2>四、总结与建议</h2><p>通过对超兔一体云、Salesforce、SugarCRM、Freshsales、金蝶、管家婆6大主流平台在客户管理、商机管理、销售跟进、库存管理、采购管理五大核心模块的横向对比，可以看出每个平台都有其独特的优势和适配场景。</p><p>超兔一体云凭借原生全业务一体化的优势，实现了全流程自动化，在全业务一体化和定制化灵活度方面表现出色，适合追求高效运营和低成本客制化的企业，尤其是需要打通各业务环节数据的企业。</p><p>Salesforce以其强大的AI智能能力和生态集成能力，为企业级客户提供了全面的销售管理解决方案，适合大型企业管理高价值客户和商机。</p><p>SugarCRM的高度可定制性和数据安全特性，使其成为敏感行业的首选，如金融、医药等行业对数据合规和安全有较高要求的企业。</p><p>Freshsales的轻量级AI驱动和移动端高效的特点，适合初创团队和中小销售团队快速搭建客户体系和跟进销售业务。</p><p>金蝶的业财一体化和ERP深度联动能力，为制造业等复杂业务场景提供了精细的管理方案，适合需要实现业财融合和多行业定制的企业。</p><p>管家婆则以其简单易操作的特点，为中小微企业提供了快速的业务管理解决方案，适合对操作复杂度和成本较为敏感的中小微企业。</p><p>企业在选择管理平台时，应根据自身的业务需求、发展阶段、预算等因素综合考虑，选择最适合自己的平台，以实现数字化转型和业务增长。</p>]]></description></item><item>    <title><![CDATA[AgentScope 拥抱函数计算 FC]]></title>    <link>https://segmentfault.com/a/1190000047444422</link>    <guid>https://segmentfault.com/a/1190000047444422</guid>    <pubDate>2025-12-02 19:02:06</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>作者：靖苏</p><p>在 AI Agent 应用加速落地的今天，开发者和企业普遍面临三大核心痛点：<strong>部署成本高、运维复杂度高、资源利用率低</strong>。为应对这些挑战，AI Agent 与云原生、Serverless 架构的深度融合正成为行业新趋势。我们很高兴地宣布，AgentScope 正式集成基于<a href="https://link.segmentfault.com/?enc=VMwGUb0RfRiZLxubKAh%2FVQ%3D%3D.48UaiswN%2BB9bWtm0azYy0Z%2FZBaQh9OpcMFgVgiS5c1d4QC8%2F4Xh2uor23N3XyCwgvcaldmMvbQeNWXcIXw%2FDpUAZsesrU9U3owOq5gG%2BFP%2BkgTR95LXci0OItgZ9eTBc0ZAcsnYdZZ4vViKg8EakXQ%3D%3D" rel="nofollow" target="_blank">阿里云函数计算</a>（Function Compute, FC）的全新 Serverless 运行时，为多智能体应用提供“按需启动、毫秒弹性、零运维”的新一代运行底座。</p><h2>AgentScope 是什么？</h2><p>AgentScope <strong>[</strong> <strong>1]</strong> 是一个开源的多智能体应用开发框架，面向构建可观察、可控制、可扩展的 AI 智能体系统。其核心设计原则是<strong>对开发者完全透明</strong>：所有提示工程、模型调用、智能体行为及工作流编排均显式暴露，避免隐式逻辑或深度封装。</p><p>该框架拥有以下特性：</p><ul><li><strong>透明性优先：</strong> 所有内部状态、消息传递路径、工具调用链路和模型交互过程均可追踪与审计，确保行为可解释、可调试。</li><li><strong>实时介入：</strong> 实现 ReAct 智能体，原生支持任务执行过程中的实时中断与自定义中断处理逻辑，允许用户随时中断智能体的回复，介入智能体的执行，适用于需要人工干预或动态策略调整的场景。</li><li><strong>增强智能能力：</strong> 提供统一的工具管理接口、长期记忆控制机制以及智能化 RAG（检索增强生成）支持，提升智能体的上下文感知与知识利用能力。</li><li><strong>模型无关架构：</strong> 抽象统一的模型接入层允许同一套智能体逻辑无缝切换不同大语言模型（如 GPT、Claude、通义千问、Llama 系列等），降低模型迁移成本。</li><li><strong>模块化“乐高式”设计：</strong> 智能体、工具、提示模板、记忆模块、工作流节点等组件高度解耦，支持独立开发、组合复用与灵活替换。</li><li><strong>原生多智能体支持：</strong> 采用显式消息传递机制与声明式工作流编排，明确表达智能体间的协作关系，避免隐式调度带来的不可控性。</li><li><strong>高度可定制：</strong> 支持对工具链、提示策略、通信协议、第三方库集成及可视化界面进行深度定制，适配从原型验证到生产部署的全周期需求。</li></ul><p>AgentScope 旨在为开发者提供一个既具备工程严谨性，又保持足够灵活性的智能体开发基础设施，推动多智能体系统从实验走向规模化落地。自开源以来，AgentScope 已获得社区广泛认可，GitHub Star 数突破 <strong>14,000+</strong>。</p><h2>当前 Agent 运行时的挑战</h2><p>AgentScope Runtime <strong>[</strong> <strong>2]</strong> 是一个面向生产环境的智能体运行时框架，聚焦于两大核心问题：<strong>高效、可扩展的智能体部署与安全、隔离的 Sandbox 工具执行</strong>。该运行时提供上下文管理（包括长短期记忆与外部知识库集成）和多层级沙箱基础设施，构成一套框架无关的底层支撑系统，可与主流开源智能体框架或自定义实现无缝协同。其设计目标是为服务级智能体应用提供具备完整可观测性、强安全性与便捷部署能力的基础运行环境。</p><p>AgentScope Runtime实现了双核心架构：</p><ul><li><strong>智能体部署运行时（Engine）：</strong> 提供智能体生命周期管理、会话状态维护、上下文存储（短期对话历史与长期记忆）以及外部知识库接入能力，并集成沙箱环境调度服务，支撑高并发、多会话的智能体服务部署。</li><li><strong>工具执行运行时（Sandbox）：</strong> 基于隔离容器构建的安全执行环境，支持智能体调用各类工具操作，包括文件系统访问、浏览器自动化、GUI 交互及 MCP（Model Context Protocol）工具集成，确保所有副作用行为被严格限制在沙箱边界内，杜绝对宿主系统的潜在风险。</li></ul><p>目前，AgentScope 的主流部署模式依赖 <strong>Docker + Kubernetes</strong> 组合。该方案在功能完备性和集群管理能力上表现优异，但在实际落地 AI Agent 应用时，暴露出若干结构性瓶颈：</p><ul><li><strong>持续运行带来固定成本：</strong> 容器实例需长期驻留内存以维持智能体状态和会话上下文，即使在无请求的空闲时段仍持续计费，导致显著的资源浪费，尤其对间歇性、事件驱动型任务极不友好。</li><li><strong>静态资源分配缺乏弹性：</strong> 资源配额（CPU、内存）通常按预估峰值设定，难以动态适配真实负载。在流量突发时可能因资源不足导致响应延迟或失败；而在低峰期则大量计算资源闲置，利用率低下。</li><li><strong>高运维复杂度形成使用门槛：</strong> 部署和维护一套生产级 K8s 集群涉及网络策略配置、服务发现、日志收集、监控告警、自动扩缩容（HPA）等多项云原生技能，对中小团队、独立开发者或非基础设施背景的研究人员构成显著障碍。</li></ul><p>这些限制使得许多具备潜力的 Agent 应用停留在实验阶段，难以实现低成本、高可用、快速迭代的规模化部署。</p><p>为系统性解决上述问题，AgentScope 正式推出基于<strong>阿里云函数计算（Function Compute, FC）</strong> 构建的 <strong>Serverless 运行时</strong>。该运行时针对 AI Agent 的典型工作负载（如会话保持、工具调用、状态依赖）进行深度优化，在保留功能完整性的同时，彻底重构资源使用与运维模型。</p><h3>Serverless 运行时的核心优势：</h3><p><strong>✅ 按量付费，成本可精细化控制</strong></p><p>计费粒度精确至毫秒级函数执行时间与内存消耗，空闲期间零费用。对于低频调用或突发型 Agent 任务，可有效降低成本。</p><p><strong>✅ 毫秒级弹性伸缩，自动应对负载波动</strong></p><p>无需预设实例数量或手动扩缩容，平台根据并发请求数自动调度计算资源，瞬时支撑从 1 到数千 QPS 的流量突增，保障服务 SLA。</p><p><strong>✅ 零运维，聚焦核心逻辑开发</strong></p><p>开发者无需关心底层服务器、容器镜像、K8s 配置或网络拓扑，仅需关注智能体逻辑、工具集成与业务流程编排，大幅缩短上线周期。</p><p>此外，Serverless 运行时通过<strong>会话亲和（Session Affinity）机制</strong>在无状态函数架构下有效支持有状态的 Agent 交互场景，兼顾弹性与一致性。</p><p>这一演进标志着 Agent 运行时正从“重资产、高运维”的传统模式，迈向“轻量化、自动化、经济高效”的云原生新范式，为 AI Agent 的大规模商业化落地扫清基础设施障碍。</p><h2>Serverless 运行时集成能力详解</h2><h3>Engine 能力拓展</h3><p>Serverless 运行时深度集成 AgentScope 的核心执行引擎（AgentScope Runtime Engine），在保留原有编程模型的基础上，为开发者提供面向云原生环境的无缝部署体验。关键能力包括：</p><ul><li><strong>本地代码一键构建与依赖打包：</strong> 开发者仅需在本地项目目录中执行<code>deploy() </code>方法，运行时即可自动分析 Python 依赖，构建包含用户代码、自定义工具及第三方库的可执行包，并上传至<a href="https://link.segmentfault.com/?enc=r2RHIhpMx0TdcSTE9OjmNQ%3D%3D.WRzQPRPREI9imO5cnxNA4l5tyEQ84tOs4ohHoQDQ70n%2BL7vMfE8i7qXThc2ZCxANiwP16QanifI2znn%2BHnR8i8zIKN9Bap41X6RYtg0XU0BkJZOohjQEHvmFGhJXotFpQIKZbaOhWk%2B8rjXWmCJ6zw%3D%3D" rel="nofollow" target="_blank">阿里云函数计算（FC）</a>——该服务已深度集成于百炼 ModelStudio 平台，实现从开发到托管的一站式闭环。</li><li><strong>一键部署生成 HTTPS Endpoint：</strong>  部署完成后，系统自动分配全局唯一的 HTTPS 端点（Endpoint），支持标准 RESTful 调用。外部系统（如 Web 前端、移动端或第三方服务）可通过该接口直接触发智能体执行，无需额外配置网关或反向代理。</li><li><strong>Header-Based Session 亲和性保障：</strong> 为支持有状态交互（如多轮对话、工具链连续调用），Serverless 运行时引入基于 HTTP 请求头的会话绑定机制。客户端通过在请求中携带 Session ID 请求头，平台将确保同一 Session ID 的所有后续请求路由至同一函数实例（或关联的沙箱上下文），从而维持内存状态、临时文件或浏览器会话的一致性。</li><li><strong>继承 Serverless 核心优势：</strong> 所有通过 Engine 部署的智能体天然享有 Serverless 架构的三大特性：按实际执行时间计费、毫秒级自动扩缩容、零基础设施运维，显著降低运营复杂度与总体拥有成本（TCO）。</li></ul><h3>Sandbox 运行时全面支持</h3><p>AgentScope 定义的四大沙箱类型现已完整适配 Serverless 运行时，可在函数计算环境中安全、高效地执行各类操作：</p><ul><li>✅ <strong>BaseSandbox</strong>：提供隔离的 Python 代码执行环境，适用于通用脚本运行与逻辑计算</li><li>✅ <strong>FileSystemSandbox</strong>：挂载临时或持久化文件系统，支持文件读写、日志记录与中间产物存储</li><li>✅ <strong>BrowserSandbox</strong>：内置无头 Chromium 浏览器，实现网页自动化、数据抓取与前端交互模拟</li><li>✅ <strong>GUISandbox</strong>：支持图形界面应用的模拟执行（如桌面软件自动化），适用于特定领域工具集成</li></ul><p>基于<a href="https://link.segmentfault.com/?enc=r8A6gZBuucrtFltsFdF4ug%3D%3D.9WWt7xFMMMCMZ8Oz6YcucEkwwKYpdY6LOuroGm0m%2FHHBlmJWUrlViuArV9hk4zx8mgVotTw8Vvzsph%2F07bT9b%2F0mbE1wMfi7qONlJvPODp1wzvzvRqaQMl0anhS5Raxb0aBfP0YhILXfWEEMWrDzdg%3D%3D" rel="nofollow" target="_blank">阿里云函数计算（FC）</a>的 Serverless 运行时，深度集成 AgentScope 的 Sandbox 运行引擎，其核心特性如下：</p><ul><li><strong>预热实例池，消除冷启动延迟：</strong>  平台可预先创建并维护一组常用类型的 Sandbox，在新会话到来时直接复用，提高常驻服务的响应速度。</li><li><strong>自动注入 Session ID，保障上下文连续性：</strong>  在首次创建 Sandbox 时，系统自动生成唯一 Session ID 并返回给客户端；后续所有针对该会话的 HTTP 请求均自动携带此 ID，确保操作始终作用于同一沙箱实例，保证状态一致性。</li><li><strong>全生命周期 Serverless 体验：</strong>  每个 Sandbox 实例在会话结束后自动回收资源，计费随执行结束而终止，同样遵循<strong>按量付费、毫秒级弹性、零运维</strong>的 Serverless 原则，在安全性、性能与成本之间取得最佳平衡。</li></ul><p>通过 Engine 与 Sandbox 的双重增强，AgentScope 的 Serverless 运行时不仅解决了传统部署的成本与运维难题，更在保持强隔离与状态支持的前提下，实现了 AI Agent 应用的高效、安全、经济化交付。</p><h2>快速体验</h2><p>现在，您就可以将 Agent 应用快速部署到 Serverless 运行时！</p><h3>部署 Agent 到 Serverless 运行时</h3><p>只需三步：</p><ol><li>配置相关环境变量</li></ol><pre><code># 确保设置环境变量
export DASHSCOPE_API_KEY="your-dashscope-api-key"
export ALIBABA_CLOUD_ACCESS_KEY_ID="your-access-key-id"
export ALIBABA_CLOUD_ACCESS_KEY_SECRET="your-access-key-secret"
export MODELSTUDIO_WORKSPACE_ID="your-workspace-id"
# 可选的OSS专用凭证
export OSS_ACCESS_KEY_ID="your-oss-access-key-id"
export OSS_ACCESS_KEY_SECRET="your-oss-access-key-secret"</code></pre><ol start="2"><li>定义好您的 AgentApp</li></ol><pre><code># -*- coding: utf-8 -*-
# pylint:disable=wrong-import-position, wrong-import-order
import asyncio
import os
from agentscope.agent import ReActAgent
from agentscope.model import DashScopeChatModel
from agentscope_runtime.engine.agents.agentscope_agent import AgentScopeAgent
from agentscope_runtime.engine.runner import Runner
from agentscope_runtime.engine.schemas.agent_schemas import (
    MessageType,
    RunStatus,
    AgentRequest,
)
from agentscope_runtime.engine.services.context_manager import (
    ContextManager,
)
from agentscope_runtime.sandbox.tools.function_tool import function_tool
from others.other_project import version
@function_tool()
def weather_search(query: str) -&gt; str:
    if "sf" in query.lower() or "san francisco" in query.lower():
        result = "It's 60 degrees and foggy."
    else:
        result = "It's 90 degrees and sunny."
    return result
agent = AgentScopeAgent(
    name="Friday",
    model=DashScopeChatModel(
        "qwen-turbo",
        api_key=os.getenv("DASHSCOPE_API_KEY"),
    ),
    agent_config={
        "sys_prompt": "You're a helpful assistant named Friday.",
    },
    agent_builder=ReActAgent,
    tools=[
        weather_search,
    ],
)
print(f"AgentScope Runtime with dependencies version: {version}")
async def run():
    # Create a request
    request = AgentRequest(
        input=[
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": "杭州天气如何？",
                    },
                ],
            },
        ],
    )
    runner = Runner(
        agent=agent,
        context_manager=ContextManager(),
        # context_manager=None       # Optional
    )
    async for message in runner.stream_query(request=request):
        # Check if this is a completed message
        if (
            message.object == "message"
            and MessageType.MESSAGE == message.type
            and RunStatus.Completed == message.status
        ):
            all_result = message.content[0].text
        print(message)
    print(f"📝 Agent response: {all_result}")
if __name__ == "__main__":
    asyncio.run(run())</code></pre><ol start="3"><li>配置部署相关代码，将您的代码部署到 Serverless 运行时上</li></ol><pre><code>import asyncio
import os
from agentscope_runtime.engine.deployers.modelstudio_deployer import (
    ModelstudioDeployManager,
    OSSConfig,
    ModelstudioConfig,
)
from agent_app import app  # 导入已配置的 app
async def deploy_to_modelstudio():
    """将 AgentApp 部署到阿里云 ModelStudio"""
    # 配置 OSS 和 ModelStudio
    deployer = ModelstudioDeployManager(
        oss_config=OSSConfig(
            access_key_id=os.environ.get("ALIBABA_CLOUD_ACCESS_KEY_ID"),
            access_key_secret=os.environ.get("ALIBABA_CLOUD_ACCESS_KEY_SECRET"),
        ),
        modelstudio_config=ModelstudioConfig(
            workspace_id=os.environ.get("MODELSTUDIO_WORKSPACE_ID"),
            access_key_id=os.environ.get("ALIBABA_CLOUD_ACCESS_KEY_ID"),
            access_key_secret=os.environ.get("ALIBABA_CLOUD_ACCESS_KEY_SECRET"),
            dashscope_api_key=os.environ.get("DASHSCOPE_API_KEY"),
        ),
    )
    # 执行部署
    result = await app.deploy(
        deployer,
        deploy_name="agent-app-example",
        telemetry_enabled=True,
        requirements=["agentscope", "fastapi", "uvicorn"],
        environment={
            "PYTHONPATH": "/app",
            "DASHSCOPE_API_KEY": os.environ.get("DASHSCOPE_API_KEY"),
        },
    )
    print(f"✅ 部署到 ModelStudio：{result['url']}")
    print(f"📦 制品：{result['artifact_url']}")
    return result
if __name__ == "__main__":
    asyncio.run(deploy_to_modelstudio())</code></pre><p>📚 详细文档请参考：部署指南 <strong>[</strong> <strong>3]</strong> 。</p><h3>快速启动 Sandbox</h3><ol><li>安装 agentscope-runtime</li></ol><pre><code>pip install agentscope-runtime</code></pre><p>由于 agentscope-runtime 仍在初期快速迭代中，建议采用源码安装方式。</p><pre><code>git clone https://github.com/agentscope-ai/agentscope-runtime.git
cd agentscope-runtime
pip install .</code></pre><ol start="2"><li>配置环境变量</li></ol><pre><code># Service settings
HOST="0.0.0.0"
PORT=8000
WORKERS=1
DEBUG=False
# Runtime Manager settings
DEFAULT_SANDBOX_TYPE=base
POOL_SIZE=0
AUTO_CLEANUP=True
CONTAINER_PREFIX_KEY=agent-runtime-container-
CONTAINER_DEPLOYMENT=agentrun
DEFAULT_MOUNT_DIR=
STORAGE_FOLDER=runtime_sandbox_storage
PORT_RANGE=[49152,59152]
# FC 相关账户信息
FC_ACCOUNT_ID=&lt;your-account-id&gt;
FC_ACCESS_KEY_ID=&lt;your-access-key-id&gt;
FC_ACCESS_KEY_SECRET=&lt;your-access-key-secret&gt;
FC_REGION_ID=cn-hangzhou
# 规格配置
FC_CPU=2.0
FC_MEMORY=2048
# 网络配置
FC_VPC_ID=&lt;your-vpc-id&gt;
FC_VSWITCH_IDS=[&lt;your-vswitch-id&gt;]
FC_SECURITY_GROUP_ID=&lt;your-security-group-id&gt;
# 前缀
FC_PREFIX=agentscope-sandbox
# 日志配置
FC_LOG_PROJECT=&lt;your-sls-log-project&gt;
FC_LOG_STORE=&lt;your-sls-log-store&gt;</code></pre><ol start="3"><li>运行命令，启动沙箱服务器</li></ol><pre><code>runtime-sandbox-server --config fc.env</code></pre><ol start="4"><li>使用您的沙箱</li></ol><pre><code>from agentscope_runtime.sandbox import BaseSandbox
# 连接到远程服务器（替换为您的实际服务器地址和端口）
with BaseSandbox(
    base_url="http://127.0.0.1:8000",
) as sandbox:
    # 正常使用沙箱
    print(box.list_tools())
    print(box.run_ipython_cell(code="print('hi')"))
    print(box.run_shell_command(command="echo hello"))
    input("Press Enter to continue...")</code></pre><p>📚 详细文档请参考：沙箱部署指南 <strong>[</strong> <strong>4]</strong> 。</p><h2>迈向“省钱又好用”的 AI 运行时</h2><p>AI Agent 的运行时基础设施正经历一场深刻的演进：从早期追求“能跑起来”的基础可用性，到关注开发体验与功能完备性的“好用”阶段，如今正加速迈向兼顾性能、安全与经济性的“省钱用”新范式。</p><p>AgentScope 与 Serverless 架构的深度集成，正是这一演进的关键实践。通过将智能体部署与工具执行全面迁移至基于<a href="https://link.segmentfault.com/?enc=K6avb4ztcu9oB%2BL7cVUpsA%3D%3D.Dc4Xia3zoCsMrsC2jQwtXpbrTaBUQ6IVV73TSzOGTr9YL2PvJc15317KdKdGwGq%2FVvrijaajqgF9ofbIpx9O5vO4ZgTxTiw3ij69p%2F1KiHEPL5UoWJ0f90XSdROeVLtT9l2UdvIgR%2B%2Ft4sbKNSIF%2FA%3D%3D" rel="nofollow" target="_blank">阿里云函数计算（FC）</a>的 Serverless 平台，不仅大幅降低了对容器编排、集群运维等云原生技能的依赖，更从根本上重构了资源使用模型——<strong>从“为闲置付费”转向“为实际执行付费”</strong> ，使中小团队乃至个人开发者也能以极低成本运行生产级 Agent 应用。</p><p>Serverless 所提供的毫秒级弹性、自动扩缩容、强隔离沙箱与零运维特性，恰好契合 AI Agent 应用典型的负载特征：间歇性调用、状态依赖性强、工具执行风险高、成本敏感度高。我们坚信，<strong>Serverless 将成为 AI Agent 应用的最佳运行时。</strong></p><p>未来，AgentScope 将持续深化与主流云服务的协同，进一步优化会话管理、冷启动延迟、多模态工具支持等关键路径，并推动更多开源智能体项目采纳 Serverless 范式，构建一个开放、高效、经济的 Agent 运行生态，让复杂智能体系统的开发与部署如同调用普通 API 一样简单可靠。</p><p><strong>让每一个智能体，都能轻盈运行在云端。</strong></p><p><strong>相关链接：</strong></p><p>[1] AgentScope</p><p><a href="https://link.segmentfault.com/?enc=6uBTsQmXNeZ5sf1gIkOU0A%3D%3D.VZqKICG8S1xvTitbZBWNS8gBTQUnL5%2FlxFgDHUdf5rE%2FYb2eGTjEuU2mJWm29Sip" rel="nofollow" target="_blank">https://github.com/agentscope-ai/agentscope/</a></p><p>[2] AgentScope Runtime</p><p><a href="https://link.segmentfault.com/?enc=Ywoc07ywUqg4%2B7lO%2BWGfUQ%3D%3D.KqcEmKLKMCD0PP0ao7fsM9Ns5j5vvAe5s7CllMSG5GhtrrygZrWSR9xRvc6ZDF7kMc7p%2FJVQZ%2BDoiDRc6vVL8g%3D%3D" rel="nofollow" target="_blank">https://github.com/agentscope-ai/agentscope-runtime</a></p><p>[3] 部署指南</p><p><a href="https://link.segmentfault.com/?enc=tGsZM%2F%2B6YRBQVwKXMcSqEw%3D%3D.5KKggOCrciqsdPvd0dHJ7kB2e09fhrTW5xE2WHv%2Bf5dYz7RqiHXV5Zk82B9X1C5pN7MnZO91qZPCVYm4vOpooABfTBf9K8LPWbOYojYXV0BnH9eiB7mWr8Sp9K6ybsYI" rel="nofollow" target="_blank">https://runtime.agentscope.io/zh/advanced_deployment.html#met...</a></p><p>[4] 沙箱部署指南</p><p><a href="https://link.segmentfault.com/?enc=1O1driFF%2BG9pZZHXYYQ0gA%3D%3D.WMlgwlZjylnrJcIBNTaYkfiNPiyCrTMFmitCcdz1TBLG5h30%2FiEhJJiK4gYA4G4rt%2BqitFCE4HzbCVLUz%2BWjHT39GlhCmRrdEn8u4GAF53c3nFJLAI34jBxe%2BqZ7x0ro" rel="nofollow" target="_blank">https://runtime.agentscope.io/en/sandbox/advanced.html#option...</a></p>]]></description></item><item>    <title><![CDATA[10 个 Nano Banana Pro]]></title>    <link>https://segmentfault.com/a/1190000047444443</link>    <guid>https://segmentfault.com/a/1190000047444443</guid>    <pubDate>2025-12-02 19:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>前言</h2><p>如果你已经学会：</p><ol><li>免费使用 Nano Banana Pro： <a href="https://link.segmentfault.com/?enc=nQaw1kr%2B%2BHL9Lb3jXh8zsQ%3D%3D.IF4UPPEM8yQYLNSPnCtPU8WQ6CT5jpd9Y2GTy%2FjV61tHipOtVlhyxjSSzsCROM95sgtz803qXC3eAtnswm6o4w%3D%3D" rel="nofollow" target="_blank">6 个白嫖 Nano Banana Pro 的网站</a></li><li>使用提示词库复刻惊艳图片：<a href="https://link.segmentfault.com/?enc=vdDuwBIUAooLtJjVD9X%2B1w%3D%3D.KL%2Fv4GENh4VtWHhGEFpTq7vGKUwVdvjfJ%2BMUaKs51lhay4IqzWbuOmQ4GEZnUCu41YBDRoeMku%2F1edfq7D%2BZIg%3D%3D" rel="nofollow" target="_blank">一次找齐！1000 个 Nano Banana Pro 提示词</a></li><li>学会如何自己写提示词：<a href="https://link.segmentfault.com/?enc=0p8HF5CXsK2YT%2FLxIvY9UA%3D%3D.5bfbV3RSR2p25kOnNJPCGKETKEaxtEl7tZV8M1PWwGIbbDx5dXrlTx7B9kluRaqcIqv6qLFh%2BWu9PjUIltGSEQ%3D%3D" rel="nofollow" target="_blank">Nano Banana Pro 很强，但你要学会写提示词才能随心所欲</a></li></ol><p>本篇我们再分享 10 个技巧，帮助你将生成的图片直接达到生产级别。</p><p>本篇主要内容整理自 Nano Banana Pro 官方转载的这篇文章：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444445" alt="" title=""/></p><p>那就让我们开始吧！</p><p>10 年技术博主，最新资讯、前端知识、AI 干货，欢迎关注公众号：“冴羽” 或者搜索“yayujs”</p><h2>1. 提示词的黄金法则</h2><p><strong>Nano Banana Pro 是一个“思考”模型，它不只是进行关键词匹配，还能理解意图、物理原理和构图。</strong></p><p>这就意味着，如果要获得最佳的效果，不要使用传统的“标签堆砌”方式，而是要像一个创意总监一样思考和行动。</p><h3>1.1. 编辑，而不是重新生成</h3><p>Nano Banana Pro 模型非常擅长对话式编辑，如果一个图像已经正确了 80%，那就不要再从头开始生成了，你只需要提出具体的变更就可以了。</p><p>✅：太棒了，但是把照明改成日落，并且把文字变成霓虹蓝。</p><h3>1.2. 使用自然语言和完整句子</h3><p>与模型交流时，要像指导一位艺术家创作一样。使用正确的语法和描述性的形容词。</p><p>❌ 错误示范：“酷炫汽车，霓虹灯，城市，夜晚，8K”</p><p>✅ 正确示范：“一个电影风格的广角镜头，展现一辆未来主义跑车在雨夜的东京街道上飞驰。霓虹灯标志在湿漉漉的路面和跑车的金属车身上反射出光彩”</p><h3>1.3. 要具体和清晰的描述</h3><p>模糊的提示词只会产生普通的结果，要定义主题、环境、光线和氛围。</p><p>❌ 描述主题：“一个女人”</p><p>✅ 描述主题：“一位穿着香奈儿复古套装的高雅老妇人”</p><p>✅ 描述质感： 描述纹理，比如“哑光表面”、“磨砂钢”、“柔软天鹅绒”、“皱巴巴的纸张”</p><h3>1.4. 提供上下文（为什么 / 为了谁）</h3><p>Nano Banana Pro 是一个“思考”模型，给它上下文有助于它做出合理的艺术决策。</p><p>✅：“为一本巴西高端美食食谱创作一张三明治的图片”（模型将推断出专业的摆盘、浅景深和完美的照明）</p><h2>2. 文本渲染、信息图和视觉合成</h2><p>Nano Banana Pro 能够渲染清晰易读、风格化的文本，并将复杂的信息合成为视觉格式。</p><p>最佳实践：</p><ul><li><strong>压缩</strong>：要求模型将密集的文本或 PDF “压缩”成视觉辅助材料</li><li><strong>风格</strong>：指定想要的风格，是“精致的社论风格”、“技术图表风格”还是“手绘白板风格”</li><li><strong>引用</strong>：用括号明确指定你想要引用的文案</li></ul><p>举个例子：</p><blockquote>财报信息图（数据导入）：[输入谷歌最新财报的 PDF 文件] “生成一个简洁现代的信息图，概括这份财报的关键财务亮点。包含‘营收增长’和‘净利润’图表，并在风格化的引言框中突出显示 CEO 的关键语录。”</blockquote><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444446" alt="" title="" loading="lazy"/></p><blockquote>复古信息图：制作一张 20 世纪 50 年代风格的复古信息图，介绍美国餐馆的历史。信息图应包含“食物”、“点唱机”和“装饰”等独立部分。确保所有文字清晰易读，并符合当时的风格。</blockquote><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444447" alt="" title="" loading="lazy"/></p><blockquote>技术图纸：绘制一份正投影蓝图，以平面图、立面图和剖面图的形式描述该建筑物。使用专业建筑字体清晰标注“北立面”和“正门”。格式为 16:9。</blockquote><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444448" alt="" title="" loading="lazy"/></p><blockquote>白板总结（教学用途）：请用手绘白板图的形式总结“Transformer 神经网络架构”的概念，使其适用于大学讲座。编码器和解码器模块请使用不同颜色的马克笔，并清晰标注“自注意力”和“前馈”。</blockquote><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444449" alt="" title="" loading="lazy"/></p><h2>3. 角色一致性与封面图</h2><p>Nano Banana Pro 最多支持 14 张参考图像（其中 6 张为高保真图像）。这使得“身份锁定”成为可能——可以将特定人物或角色置于新的场景中，而不会造成面部变形。</p><p>最佳实践：</p><ul><li>身份锁定：明确说明：“保持人物面部特征与图像 1 完全相同。”</li><li>表情/动作：描述情绪或姿势的变化，保持身份不变，</li><li>生成封面图：将主题与醒目的图形和文字一次性结合起来</li></ul><p>举个例子：</p><blockquote><p>“封面图”（标识 + 文字 + 图形）：</p><p>使用图 1 中的人物设计一个封面图。</p><p>面部一致性：保持人物面部特征与图 1 完全相同，但改变其表情，使其看起来兴奋和惊讶。</p><p>动作：将人物置于画面左侧，手指指向画面右侧。</p><p>主题：在右侧放置一张美味的牛油果吐司的高清图片。</p><p>图形：添加一个醒目的黄色箭头，连接人物的手指和吐司。</p><p>文字：在中间叠加醒目的流行风格文字：“3 分钟搞定！”。使用粗白线和阴影。</p><p>背景：模糊明亮的厨房背景。高饱和度和高对比度。</p></blockquote><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444450" alt="" title="" loading="lazy"/></p><blockquote><p>“毛茸茸的小伙伴”场景（群体一致性）：</p><p>[输入 3 张不同毛绒玩具的图片]</p><p>“创作一个有趣的十页故事，讲述这三个毛茸茸的小伙伴去热带度假。故事跌宕起伏，充满情感高潮和低谷，最终以温馨的结局收尾。三个角色的服装和形象要保持一致，但他们的表情和角度在十张图片中要有所变化。确保每张图片中每个角色只出现一个。”</p></blockquote><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444451" alt="" title="" loading="lazy"/></p><blockquote><p>品牌素材创作：</p><p>[输入 1 张产品图片]</p><p>“创作 9 张精美时尚大片，风格如同获奖时尚大片。以此为品牌风格参考，但需在产品系列中加入细微差别和多样性，以展现专业设计感。请依次创作 9 张图片。”</p></blockquote><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444452" alt="" title="" loading="lazy"/></p><h2>4. 使用谷歌搜索作为基础</h2><p>Nano Banana Pro 使用 Google 搜索根据实时数据、时事或事实验证生成图像，从而减少对时事话题的幻觉。</p><p>最佳实践：</p><ul><li>要求提供动态数据（天气、股票、新闻）的可视化图表。</li><li>模型会对搜索结果“思考”（推理）后生成图像。</li></ul><p>举个例子：</p><blockquote><p>活动可视化：</p><p>“根据当前的旅游趋势，生成一张信息图，展示 2025 年游览美国国家公园的最佳时间。”</p></blockquote><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444453" alt="" title="" loading="lazy"/></p><h2>5. 高级编辑、修复和上色</h2><p>模型擅长通过对话式提示进行复杂的编辑，包括“图像修复”（移除/添加对象）、“修复”（修复旧照片）、“上色”（漫画/黑白照片）和“风格互换”。</p><p>最佳实践：</p><ul><li>语义指令：无需手动添加遮罩，只需自然地告诉模型要更改什么即可</li><li>物理理解：你可以进行复杂的更改，例如“将这个杯子装满液体”，以测试物理生成</li></ul><p>举个例子：</p><blockquote><p>物体移除与补全：</p><p>“从这张照片的背景中移除游客，并用与周围环境相匹配的合理纹理（鹅卵石和店面）填充空间。”</p></blockquote><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444454" alt="" title="" loading="lazy"/></p><blockquote><p>漫画/漫画上色：</p><p>[输入黑白漫画分镜]</p><p>“为这幅漫画分镜上色。使用鲜艳的动漫风格配色方案。确保能量光束的照明效果呈现霓虹蓝色，并且角色的服装颜色与其官方配色一致。”</p></blockquote><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444455" alt="" title="" loading="lazy"/></p><blockquote><p>本地化（文本翻译+文化适应）：</p><p>[输入一张伦敦公交车站广告的图片]</p><p>“将此概念本地化到东京场景，包括将标语翻译成日语。将背景更改为夜晚熙熙攘攘的涩谷街道。”</p></blockquote><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444456" alt="" title="" loading="lazy"/></p><blockquote><p>照明/季节控制：</p><p>[输入一张夏季房屋的图片]</p><p>“将此场景转换为冬季场景。保持房屋建筑结构完全相同，但在屋顶和院子里添加积雪，并将照明更改为寒冷阴沉的午后。</p></blockquote><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444457" alt="" title="" loading="lazy"/></p><h2>6. 维度转换（2D ↔ 3D）</h2><p>Nano Banana Pro 一项强大的新功能是将二维示意图转换为三维可视化图像，反之亦然。</p><p>这对于室内设计师、建筑师和表情包创作者来说非常友好。</p><p>举个例子：</p><blockquote><p>2D 平面图转 3D 室内设计效果图：</p><p>根据上传的 2D 平面图，生成一张专业的室内设计效果图。</p><p>布局：采用拼贴画形式，顶部为一张主图（客厅广角视图），下方为三张小图（主卧、家庭办公室和 3D 俯视图）。</p><p>风格：所有图片均采用现代简约风格，搭配温暖的橡木地板和米白色墙面。</p><p>质量：照片级渲染，柔和的自然光。</p></blockquote><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444458" alt="" title="" loading="lazy"/></p><blockquote><p>2D 转 3D 表情包转换：</p><p>“将‘一切都好’狗狗表情包转换成逼真的 3D 渲染图。保持构图不变，但让狗狗看起来像毛绒玩具，火焰看起来像真实的火焰。”</p></blockquote><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444459" alt="" title="" loading="lazy"/></p><h2>7. 高分辨率和纹理</h2><p>Nano Banana Pro 支持原生 1K 至 4K 图像生成。这对于处理精细纹理或大尺寸打印作品尤为有用。</p><p>最佳实践：</p><ul><li>如果 API / 接口允许，明确请求高分辨率（2K 或 4K）。</li><li>描述高保真细节（瑕疵、表面纹理）。</li></ul><p>举个例子：</p><blockquote><p>4K 纹理生成：</p><p>“利用原生高保真输出，打造令人叹为观止、充满氛围的苔藓森林地面环境。掌控复杂的光照效果和细腻的纹理，确保每一根苔藓和每一束光线都以像素级分辨率渲染，完美适用于 4K 壁纸。”</p></blockquote><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444460" alt="" title="" loading="lazy"/></p><blockquote><p>复杂逻辑（思考模式）：</p><p>“创作一幅超逼真的美食芝士汉堡信息图，将其拆解，展现烤过的奶油蛋卷面包的质地、肉饼煎至焦香的外皮以及闪闪发光的融化芝士。为每一层标注其风味特征。”</p></blockquote><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444461" alt="" title="" loading="lazy"/></p><h2>8. 思考与推理</h2><p>Nano Banana Pro 默认采用“思考”模式，它会生成一些中间的思考图像（不计费），以便在渲染最终输出之前优化构图。这有助于进行数据分析和解决视觉问题。</p><p>举个例子：</p><blockquote><p>解方程：</p><p>“在白板上用 C 语言求解方程 log\_{x^2+1}(x^4-1)=2。请清晰地写出解题步骤。”</p></blockquote><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444462" alt="" title="" loading="lazy"/></p><blockquote><p>视觉推理：</p><p>“分析这张房间图片，生成一张‘之前’的图片，展示房间在施工期间可能的样子，包括框架和未完成的石膏板。”</p></blockquote><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444463" alt="" title="" loading="lazy"/></p><h2>9. 一次性故事板和概念艺术</h2><p>无需网格即可生成连续的艺术图或故事板，从而确保在一次操作中实现连贯的叙事流程。</p><p>举个例子：</p><blockquote>请创作一个引人入胜的九部分故事，包含九张图片，故事中需出现一位女性和一位男性，他们正在拍摄一部屡获殊荣的豪华行李箱广告。故事应有跌宕起伏的情感，最后以一位女性手持品牌标识的优雅照片结尾。男女主角的身份和着装必须保持一致，但可以从不同的角度和距离拍摄。请逐一生成图片。请确保每张图片均为 16:9 横向格式。</blockquote><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444464" alt="" title="" loading="lazy"/></p><h2>10. 结构控制与布局指导</h2><p>添加的输入图像不仅仅用于角色参考或待编辑对象，你也可以使用它控制输出图像的构图和布局。</p><p>这对于需要将草图、线框图或特定网格布局转化为精美素材的设计师来说，非常有用。</p><p>最佳实践：</p><ul><li>草稿和草图：上传手绘草图，准确定义文本和对象的位置。</li><li>线框图：使用现有布局或线框图的屏幕截图来生成高保真 UI 模型。</li><li>网格：使用网格图像强制模型为基于图块的游戏或 LED 显示屏生成资源。</li></ul><p>举个例子：</p><blockquote><p>从草图到最终广告：</p><p>“根据此草图为[产品]创作一个广告。”</p></blockquote><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444465" alt="" title="" loading="lazy"/></p><blockquote><p>根据线框图创建 UI 模型：</p><p>“请按照以下准则为[产品]创建模型。”</p></blockquote><ul><li><img referrerpolicy="no-referrer" src="/img/remote/1460000047444466" alt="" title="" loading="lazy"/></li></ul><blockquote><p>像素艺术与 LED 显示屏：</p><p>“生成一个独角兽的像素艺术精灵，使其完美契合此 64×64 网格图像。使用高对比度颜色。”</p></blockquote><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444467" alt="" title="" loading="lazy"/></p><blockquote><p>精灵图：</p><p>“一位女性在无人机上做后空翻的精灵图，3×3 网格，序列式，逐帧动画，正方形宽高比。请严格按照附图的结构进行绘制。”（提示：你可以提取每个单元格并制作成 GIF 动画）</p></blockquote><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444468" alt="" title="" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[从一个开发工程师的角度，聊聊“什么是 K]]></title>    <link>https://segmentfault.com/a/1190000047444103</link>    <guid>https://segmentfault.com/a/1190000047444103</guid>    <pubDate>2025-12-02 17:09:12</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>先把话挑明：<strong>K 线不是“画出来”的，而是“算出来”的</strong>。它是对一段时间内价格与成交的压缩表示：Open、High、Low、Close、Volume（常加 Turnover、交易笔数），按某种“窗口”聚合而成。听起来像个普通的聚合任务，但真要把它在交易系统里做稳、做快、做准，会踩很多坑。</p><h2>K 线到底指什么</h2><ul><li><strong>时间维度</strong>：常见有 1s、1m、5m、15m、1h、日/周/月 K。不是自然时间，而是“交易所时间”。比如 A 股有午休，美股有夏令时，国内期货有夜盘。</li><li><strong>事件来源</strong>：一般从成交（Trade）事件聚合，也有用最新成交价驱动的 Quote K（更接近行情视角）。有的市场会有撤销/更正（Cancel/Correct）事件。</li><li><strong>数值字段</strong>：价格精度、最小变动价位、合约乘数、成交量单位（股/手/张）、货币与汇率，这些元数据必须进来一起算。</li><li><strong>类型变体</strong>：时间 K（最常见）、成交量 K（每 X 手出一根）、价格区间 K（Range Bar）、平均 K（Heikin Ashi/VWAP 相关）。业务要说清楚要哪种。</li></ul><h2>如果要在生产系统里做，这些是会“咬你”的点</h2><h3>1) 时间边界和交易日历</h3><ul><li>不同市场的开闭市/午休/夜盘/节假日/临时停牌，导致“窗口”不是整齐的自然时间。</li><li>夏令时切换会出现 61 分钟或 59 分钟的“钟”，不要按本地时区算，要用交易所时区。</li><li>周/月 K 的边界不是自然周/月，遇到长假要正确收口。</li></ul><p><strong>解决思路</strong>：</p><ul><li>维护“交易日历服务”，给出某标的在某天的有效交易片段，预先切好每个周期的窗口。</li><li>一律用 <code>java.time</code> 下的 <code>ZonedDateTime</code> 并固定为交易所时区，禁止用系统默认时区。</li><li>对跨日/夜盘的窗口，用 <code>sessionId</code>（如 <code>20250809-Night</code>）做键的一部分。</li></ul><h3>2) 数据顺序、重复与迟到</h3><ul><li>实时流里常见乱序、重复、延迟到达。极端情况下还会收到撤销/更正（对某笔成交）。</li><li>分区策略不当会把同一标的打到不同分区，顺序直接没了。</li></ul><p><strong>解决思路</strong>：</p><ul><li>流分区按 <code>symbol</code>（甚至 <code>symbol+venue</code>）哈希，保证单分区内顺序；同一 <code>symbol</code> 聚合必须单线程。</li><li>设置可接受的最大乱序窗口（比如 3 秒），窗口内迟到更新允许回补，窗口外生成“更正事件”异步修正历史。</li><li>去重用“交易所侧唯一键”（<code>tradeId</code>/<code>matchNumber</code>），每个活跃窗口挂一个 LRU Set 或 BloomFilter，窗口关了再销毁。</li><li>对 Cancel/Correct，保留事件日志或增量计数，支持对受影响窗口重算。</li></ul><h3>3) 无成交时如何“出 K”</h3><ul><li>这一分钟没人成交，要不要出一根 K？出的话 open/high/low/close 是啥？</li><li>国内股票常见规则是用上一成交价填充 O=H=L=C，Volume=0；有的业务要求“不出空 K”。</li></ul><p><strong>解决思路</strong>：</p><ul><li>把规则提前固化到配置里，按交易所/品种/周期做矩阵开关。</li><li>即使不出空 K，窗口边界也要推动 close 更新（否则下游指标会串）。</li></ul><h3>4) 价格精度与溢出</h3><ul><li><code>BigDecimal</code> 慢，<code>double</code> 有误差，<code>long</code> 容易溢出，<code>turnover</code>（成交额）乘合约乘数后尤甚。</li><li>汇率转换会引入更多精度与溢出风险。</li></ul><p><strong>解决思路</strong>：</p><ul><li>价格、数量都用“整数化”的 <code>long</code> 存（如价格按最小价位或 1e4 缩放），只在边界 I/O 处做格式化。</li><li>成交额用 128 位（Java 里 <code>BigDecimal</code>，但复用对象与避免频繁创建），或分币种分桶存 <code>long</code> 后离线汇总。</li><li>提前加载 instrument 元数据：<code>tickSize</code>、<code>priceScale</code>、<code>lot</code>、<code>multiplier</code>、<code>currency</code>。</li></ul><h3>5) 聚合策略与层级</h3><ul><li>从 tick 直接聚到所有周期 vs 先聚 1 分钟再二次聚合到 5 分钟/15 分钟？</li><li>直接从 tick 聚到所有周期，CPU 压力大；二次聚合可能引入边界误差（跨窗口的高低点）。</li></ul><p><strong>解决思路</strong>：</p><ul><li>统一以“最小基础周期”（一般 1S 或 1M）做底座，其他周期用基础周期二次聚合，且二次聚合以“<code>max(high)</code>、<code>min(low)</code>、开=首根 open、收=末根 close、量/额累加”的严格规则，避免误差。</li><li>仅对需要的周期开启实时聚合，其他由查询侧即时拼装。</li></ul><h3>6) 修正与复权</h3><ul><li>日线以上要处理分红、配股、拆合股，对历史 K 进行前/后复权。</li><li>期货连续合约、主力切换，怎么拼接不会断层。</li></ul><p><strong>解决思路</strong>：</p><ul><li>复权系数维护为“日期-&gt;factor”的时间序列，原始 K 只存不复权，查询时按前/后复权在线转换：<code>adjPrice = raw * factor(t) / factor(now)</code>。</li><li>连续合约策略分主力/指数/近月滚动，边界日给出映射表，生成“连续映射事件”，驱动重算或查询期融合。</li></ul><h3>7) 性能与 GC</h3><ul><li>高频市场每秒几十万条 tick，分钟边界瞬时抖动明显。</li><li>大量对象创建会引发 GC 抖动，延迟尾部很难看。</li></ul><p><strong>解决思路</strong>：</p><ul><li>单 symbol 单线程聚合，事件循环用 Disruptor 或 Chronicle Queue/RingBuffer，减少锁。</li><li>对象池化，Candle、事件包装重用；primitive 集合（fastutil/HPPC），尽量零装箱。</li><li>延迟敏感路径避免 <code>BigDecimal</code> 运算，批量落盘，内存对齐。</li><li>分时“削峰”：分钟收口延后几百毫秒出 K（业务可接受范围内），换吞吐量。</li></ul><h3>8) 存储与接口</h3><ul><li>历史查询高 QPS，实时订阅低延迟，冷热数据分层。</li><li>一致性：用户拉历史与订阅实时，不能看到“撕裂”的最后一根。</li></ul><p><strong>解决思路</strong>：</p><ul><li>实时内存状态 + 周期性落盘历史库（如 ClickHouse/QuestDB/TimescaleDB/Parquet）。</li><li>历史 REST 拉取采用“快照点”概念，快照后的增量通过 WebSocket 推送，给最后一根带版本号或校验码。</li><li>分区按交易日/标的，压缩列式存储，支持前缀查询。</li></ul><h2>一个精简版的聚合器结构（删繁就简）</h2><p><strong>数据模型</strong>（<code>long</code> 代表已整数化的价格与量）：</p><ul><li><code>CandleKey</code>: <code>symbol</code>, <code>interval</code>, <code>sessionId</code>, <code>windowStart</code></li><li><code>CandleState</code>: <code>open</code>, <code>high</code>, <code>low</code>, <code>close</code>, <code>volume</code>, <code>turnover</code>, <code>tradeCount</code>, <code>version</code></li></ul><p><strong>核心流程</strong>：</p><ul><li>事件进入（按 <code>symbol</code> 分区、单线程消费）</li><li>根据交易日历找到它属于哪个窗口</li><li>如窗口不存在则创建并初始化 open/high/low/close</li><li>应用成交事件更新高低收、量额</li><li>检查窗口是否到期，到期则封口输出并落盘；同时滚动到下一窗口</li><li>迟到事件：若还在“可回补期”，直接更新状态并广播修正；否则记录更正任务</li></ul><p><strong>非常小的一段 Java 伪代码（仅示意，真实实现要更多边界判断）</strong></p><pre><code>class Candle {

long open = Long.MIN\_VALUE;

long high = Long.MIN\_VALUE;

long low = Long.MAX\_VALUE;

long close = Long.MIN\_VALUE;

long volume;

long turnover;

int trades;

void applyTrade(long px, long qty) {
if (open == Long.MIN_VALUE) open = px;
if (px &gt; high) high = px;
if (px &lt; low) low = px;
close = px;
volume += qty;
turnover += px * qty; // 注意溢出与缩放
trades++;
}

boolean isEmpty() {
return open == Long.MIN_VALUE;
}

}

class Aggregator {

final Map map = new HashMap&lt;&gt;();

void onTrade(Trade t) {
CandleKey key = calendar.locateWindow(t.symbol, t.exchangeTime, t.session);
Candle c = map.computeIfAbsent(key, k -&gt; new Candle());
if (t.isCancelOrCorrect()) {
// 查找原事件并回滚/重算（需要事件日志）
return;
}
c.applyTrade(t.price, t.qty);
}

void onTickBoundary(Instant now) {
// 找到到期的窗口，封口输出，落盘并清理
}
}</code></pre><h2>实现时别忘了这些“坑口提示”</h2><ul><li><strong>集合竞价</strong>：开盘/收盘集合竞价形成的价量要算进对应窗口，尤其是收盘价定义要跟业务确认（最后成交价 vs 收盘价）。</li><li><strong>交易所回补</strong>：链路断开后的回补数据顺序可能与实时不同，回放时要沿用同一聚合逻辑，且要可幂等。</li><li><strong>标的元数据变更</strong>：停复牌、最小变动价位与合约乘数变化（再遇见就是真实世界），要有生效时间点。</li><li><strong>跨市场合并</strong>：港股/美股币种不同，turnover 汇总别悄悄相加。</li><li><strong>压力测试</strong>：用历史 tick 回放到 Kafka，按真实峰值放大 2 倍，观察分钟边界延迟尾部和丢包率。</li><li><strong>监控</strong>：窗口实时数量、乱序比率、迟到修正次数、分钟边界 99.9 延迟、落盘滞后、GC 暂停、每标的事件速率。</li></ul><h2>我会怎么落地</h2><ul><li><strong>入口</strong>：Kafka/NATS/ChronicleQueue，按 <code>symbol</code> 分区，消费端单线程聚合。</li><li><strong>时间</strong>：交易日历服务（内置规则 + 可热更新），所有时间用交易所时区。</li><li><strong>聚合</strong>：1 秒或 1 分钟作为基础周期，其他周期二次聚合。迟到容忍窗口 3 秒，超时转“修正任务队列”。</li><li><strong>去重</strong>：每窗口维护 LRU <code>tradeId</code> 集合；全局 Bloom 限制内存。</li><li><strong>存储</strong>：实时 Redis/内存快照，分钟/日线落 ClickHouse；写前批量，按 <code>symbol+date</code> 分区；历史修正以 upsert。</li><li><strong>对外</strong>：REST 历史 + WebSocket 订阅；订阅流包含“完整 K”“修正 K”两类事件；最后一根携带 version。</li><li><strong>性能</strong>：Disruptor 事件环，预分配对象；fastutil <code>LongOpenHashSet</code> 做去重；少用 <code>BigDecimal</code>，必要处汇总线程集中转换。</li><li><strong>测试</strong>：重放历史包，属性测试校验 O/H/L/C 不变量，边界日（节假日、夏令时、夜盘）专项用例。</li></ul><h2>写在最后</h2><p>K 线是“低级需求，高级实现”。从产品视角它只是几根柱子，从工程视角它是时间、数据质量、并发与业务规则的交叉地带。真正难的不是把 open/high/low/close 算出来，而是：</p><ul><li>任意时刻说得清“为什么是这个值”</li><li>在异常和修正下仍然可追溯、可重放、可幂等</li><li>在高峰时段稳稳地按时吐出每一根</li></ul><p>如果你正准备做这件事，先把时区、交易日历、事件顺序、去重与修正理顺，再谈性能优化；这样第二天早上看监控的时候，心里会更踏实。</p>]]></description></item><item>    <title><![CDATA[日本股票数据接口集成文档 股票数据源AP]]></title>    <link>https://segmentfault.com/a/1190000047444137</link>    <guid>https://segmentfault.com/a/1190000047444137</guid>    <pubDate>2025-12-02 17:08:34</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>本接口提供日本东京证券交易所（TSE）及相关市场的实时行情、历史 K 线及指数数据。所有接口均基于 HTTP/HTTPS 协议，返回 JSON 格式数据。</p><ul><li><strong>API Base URL</strong>: <code>https://api.stocktv.top</code></li><li><strong>WebSocket URL</strong>: <code>wss://ws-api.stocktv.top/connect</code></li><li><strong>认证方式</strong>: URL 参数 <code>key</code></li><li><strong>日本市场 ID (Country ID)</strong>: <code>35</code></li></ul><hr/><h2>2. 核心接口说明</h2><h3>2.1 获取日本股票列表 (Market List)</h3><p>用于获取日本市场的股票列表，包括股票名称、代码 (Symbol) 和系统内部 ID (PID)。<strong>PID 是后续查询 K 线和具体行情的关键参数。</strong></p><ul><li><strong>接口地址</strong>: <code>/stock/stocks</code></li><li><strong>请求方式</strong>: <code>GET</code></li><li><strong>关键参数</strong>:</li></ul><table><thead><tr><th align="left">参数名</th><th align="left">类型</th><th align="left">必填</th><th align="left">示例值</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left"><code>key</code></td><td align="left">String</td><td align="left">是</td><td align="left"><code>您的API密钥</code></td><td align="left">鉴权 Key</td></tr><tr><td align="left"><code>countryId</code></td><td align="left">Int</td><td align="left">是</td><td align="left"><strong>35</strong></td><td align="left"><strong>日本的国家 ID</strong></td></tr><tr><td align="left"><code>pageSize</code></td><td align="left">Int</td><td align="left">否</td><td align="left"><code>20</code></td><td align="left">每页数量</td></tr><tr><td align="left"><code>page</code></td><td align="left">Int</td><td align="left">否</td><td align="left"><code>1</code></td><td align="left">页码</td></tr></tbody></table><ul><li><strong>请求示例</strong>:</li></ul><p>&lt;!-- end list --&gt;</p><pre><code class="http">GET https://api.stocktv.top/stock/stocks?countryId=35&amp;pageSize=20&amp;page=1&amp;key=YOUR_KEY</code></pre><ul><li><strong>响应示例</strong>:</li></ul><p>&lt;!-- end list --&gt;</p><pre><code class="json">{
  "code": 200,
  "data": {
    "records": [
      {
        "id": 953373,          // [重要] PID，用于K线接口
        "name": "Toyota Motor",// 公司名称
        "symbol": "7203",      // 股票代码
        "last": 3150.0,        // 最新价
        "chgPct": 1.5,         // 涨跌幅%
        "volume": 500000       // 成交量
      }
    ]
  }
}</code></pre><hr/><h3>2.2 获取日本市场指数 (Indices)</h3><p>获取日经 225 (Nikkei 225)、TOPIX 等主要指数的实时行情。</p><ul><li><strong>接口地址</strong>: <code>/stock/indices</code></li><li><strong>请求方式</strong>: <code>GET</code></li><li><strong>关键参数</strong>:</li></ul><table><thead><tr><th align="left">参数名</th><th align="left">类型</th><th align="left">必填</th><th align="left">示例值</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left"><code>key</code></td><td align="left">String</td><td align="left">是</td><td align="left"><code>您的API密钥</code></td><td align="left">-</td></tr><tr><td align="left"><code>countryId</code></td><td align="left">Int</td><td align="left">是</td><td align="left"><strong>35</strong></td><td align="left">日本</td></tr></tbody></table><ul><li><strong>请求示例</strong>:</li></ul><p>&lt;!-- end list --&gt;</p><pre><code class="http">GET https://api.stocktv.top/stock/indices?countryId=35&amp;key=YOUR_KEY</code></pre><hr/><h3>2.3 获取 K 线数据 (Candlestick/Kline)</h3><p>获取指定股票的历史价格数据，用于绘制 K 线图。</p><ul><li><strong>接口地址</strong>: <code>/stock/kline</code></li><li><strong>请求方式</strong>: <code>GET</code></li><li><strong>关键参数</strong>:</li></ul><table><thead><tr><th align="left">参数名</th><th align="left">类型</th><th align="left">必填</th><th align="left">示例值</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left"><code>key</code></td><td align="left">String</td><td align="left">是</td><td align="left"><code>您的API密钥</code></td><td align="left">-</td></tr><tr><td align="left"><code>pid</code></td><td align="left">Int</td><td align="left">是</td><td align="left"><code>953373</code></td><td align="left">通过 2.1 接口获取的股票 ID</td></tr><tr><td align="left"><code>interval</code></td><td align="left">String</td><td align="left">是</td><td align="left"><code>P1D</code></td><td align="left">K线周期 (ISO 8601格式)</td></tr></tbody></table><ul><li><p><strong>周期 (Interval) 枚举值</strong>:</p><ul><li><code>PT1M</code> (1分钟)</li><li><code>PT5M</code> (5分钟)</li><li><code>PT1H</code> (1小时)</li><li><code>P1D</code> (日K)</li><li><code>P1W</code> (周K)</li><li><code>P1M</code> (月K)</li></ul></li><li><strong>响应示例</strong>:</li></ul><p>&lt;!-- end list --&gt;</p><pre><code class="json">{
  "code": 200,
  "data": [
    {
      "time": 1719818400000, // 时间戳 (毫秒)
      "open": 3100.0,        // 开盘
      "high": 3160.0,        // 最高
      "low": 3090.0,         // 最低
      "close": 3150.0,       // 收盘
      "volume": 45000        // 成交量
    }
  ]
}</code></pre><hr/><h3>2.4 WebSocket 实时推送</h3><p>建立长连接，实时接收日本股票的价格跳动。</p><ul><li><strong>连接地址</strong>: <code>wss://ws-api.stocktv.top/connect?key=YOUR_KEY</code></li><li><strong>推送数据格式</strong>:</li></ul><p>&lt;!-- end list --&gt;</p><pre><code class="json">{
    "pid": "953373",      // 产品ID
    "last_numeric": 3155, // 最新成交价
    "bid": 3154,          // 买一价
    "ask": 3156,          // 卖一价
    "timestamp": "1717728251", // 时间戳
    "pcp": "1.25"         // 涨跌幅
}</code></pre><hr/><h2>3. 常见问题 (FAQ)</h2><p><strong>Q1: 如何查找特定代码（如 7203 Toyota）的数据？</strong></p><blockquote><strong>A</strong>: 目前接口不支持直接通过 Symbol（如 7203）请求 K 线。流程是：先调用 <code>/stock/stocks?countryId=35</code>，在返回列表中遍历匹配 <code>symbol="7203"</code>，获取其对应的 <code>id</code> (PID)，再使用该 PID 调用 K 线接口。</blockquote><p><strong>Q2: 为什么 K 线数据的时间戳是乱序的？</strong></p><blockquote><strong>A</strong>: 接口偶尔可能返回非严格排序的数据。建议前端在接收数据后，根据 <code>time</code> 字段进行一次升序排序 (<code>sort((a,b) =&gt; a.time - b.time)</code>) 再渲染图表。</blockquote><p><strong>Q3: K 线接口支持分页吗？</strong></p><blockquote><strong>A</strong>: <code>/stock/kline</code> 接口目前是一次性返回指定周期内的近期数据，不支持分页参数。</blockquote><hr/><h2>4. 接入代码示例 (JavaScript/Fetch)</h2><pre><code class="javascript">const API_KEY = 'YOUR_API_KEY';
const JAPAN_ID = 35;

async function getJapanStockData(symbolCode) {
    // 1. 获取股票列表并查找 PID
    const listRes = await fetch(`https://api.stocktv.top/stock/stocks?countryId=${JAPAN_ID}&amp;pageSize=100&amp;key=${API_KEY}`);
    const listData = await listRes.json();
    
    // 查找指定代码 (例如 '7203')
    const targetStock = listData.data.records.find(stock =&gt; stock.symbol === symbolCode);
    
    if (!targetStock) {
        console.error('未找到该股票');
        return;
    }

    console.log(`找到股票: ${targetStock.name}, PID: ${targetStock.id}`);

    // 2. 获取 K 线数据 (日线)
    const klineRes = await fetch(`https://api.stocktv.top/stock/kline?pid=${targetStock.id}&amp;interval=P1D&amp;key=${API_KEY}`);
    const klineData = await klineRes.json();

    console.log('K线数据:', klineData.data);
}

// 调用示例：获取 7203 (丰田) 数据
getJapanStockData('7203');</code></pre>]]></description></item><item>    <title><![CDATA[一句话让一个AI为我花了（划掉）生成一个]]></title>    <link>https://segmentfault.com/a/1190000047444151</link>    <guid>https://segmentfault.com/a/1190000047444151</guid>    <pubDate>2025-12-02 17:07:45</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>最近都在讨论Google Antigravity，谷歌的亲儿子，江湖人称Cursor杀手。<br/><img width="723" height="297" referrerpolicy="no-referrer" src="/img/bVdneyd" alt="image.png" title="image.png"/></p><p>与传统的AI编程工具不同，Antigravity 不仅仅是协助写代码，它更像是一个指挥中心。在这里，开发者可以管理多个能够自主规划、编写代码甚至浏览网页的 AI Agent。</p><p>今天就手把手教你安装流程、解析核心操作逻辑，并演示如何从零生成一个应用。</p><h2>不想当将军的士兵不是一个好AI</h2><p>Antigravity 旨在改变开发者的工作方式。传统的 AI 编程助手通常是被动的，需要停下来等待代码生成。而在 Antigravity 中，AI 被预设为一个具有自主性的行动者。开发者的角色从单纯的程序员，转变一个架构师，主要负责编排任务，指挥AI员工去执行。</p><h3>安装与初始化</h3><p>目前 Antigravity 处于预览阶段，支持使用个人 Gmail 账号登录。</p><ul><li><strong>下载与安装</strong>：到官网下载并安装</li></ul><p><img width="723" height="433" referrerpolicy="no-referrer" src="/img/bVdneye" alt="image.png" title="image.png" loading="lazy"/></p><ul><li><strong>初始配置</strong>：首次启动时，可选择从 VS Code 或 Cursor 导入配置，也可选择全新开始。</li></ul><p><img width="723" height="433" referrerpolicy="no-referrer" src="/img/bVdneye" alt="image.png" title="image.png" loading="lazy"/></p><p>然后选择自己想要的主题，比如是黑夜模式还是白天模式。</p><h3>关键步骤：设定 Agent 行为策略</h3><p>安装向导中包含关于 Agent 权限的配置页面。这是 Antigravity 与传统 IDE 最大的不同之处，请重点是右边的两个核心属性。</p><p><img width="723" height="508" referrerpolicy="no-referrer" src="/img/bVdneyf" alt="image.png" title="image.png" loading="lazy"/></p><h4>Terminal execution policy (终端执行策略)</h4><p>该策略控制 Agent 是否有权直接在终端运行命令（如安装依赖包、运行测试脚本等）。</p><ul><li><strong>Off</strong>：禁止自动执行。Agent 想要运行任何命令，都必须等待人工确认。</li><li><strong>Auto</strong>：智能判断（推荐）。Agent 会自行评估命令的风险，安全的命令会自动执行，不确定或高风险的命令会请求许可。</li><li><strong>Turbo</strong>：全自动模式。除非命令在黑名单中，否则 Agent 会自动执行所有操作，适合追求极速开发的场景。</li></ul><p><img width="723" height="508" referrerpolicy="no-referrer" src="/img/bVdneyg" alt="image.png" title="image.png" loading="lazy"/></p><h4>Review policy (审查策略)</h4><p>该策略决定了 Agent 生成的任务规划（Plan）、代码变更（Diff）等产物由谁来把关。</p><ul><li><strong>Always Proceed</strong>：始终继续。Agent 不会停下来等待审批，直接推进任务。</li><li><strong>Agent Decides</strong>：Agent 自行判断。仅在它认为关键的节点或不确定的情况下，才会请求人工审查。</li><li><strong>Request Review</strong>：始终请求审查。Agent 每生成一个阶段性产物，都必须经人工批准才能继续下一步。</li></ul><p><strong>推荐配置</strong>：直接选择 Agent-assisted development（Agent 辅助开发）。这是一个平衡的选项，允许 Agent 做决策，但在关键时刻会寻求人工批准。</p><h3>界面概览：双视图逻辑</h3><p>Antigravity 基于开源的 VS Code 构建，但界面逻辑被重新设计为两个主要窗口：Agent Manager（管理器） 和 Editor（编辑器）。</p><h3>Agent Manager：任务指挥塔</h3><p>启动软件后，首先映入眼帘的不是文件列表，而是 Agent Manager。</p><ul><li><strong>多任务并发</strong>：支持同时发布多个指令（例如：“重构认证模块”、“更新依赖树”）。</li><li><strong>异步工作</strong>：每个请求都会生成一个独立的 Agent 实例。界面会可视化地展示这些并行工作流的状态，无需像传统聊天框那样等待 AI 写完代码才能进行下一个提问。</li></ul><p><img width="723" height="508" referrerpolicy="no-referrer" src="/img/bVdneyh" alt="image.png" title="image.png" loading="lazy"/></p><h3>Editor：具备感知能力的编辑器</h3><p>当需要深入代码细节时，可以切换到 Editor 视图（快捷键 <code>Cmd + E</code>）。</p><ul><li><strong>保持习惯</strong>：保留了 VS Code 的文件资源管理器、语法高亮和插件生态。</li><li><strong>Agent Awareness</strong>：编辑器右侧设有 Agent 面板。编写代码时，可随时选中一段代码，在面板中指挥 Agent 进行优化或解释。</li></ul><h3>核心差异化功能</h3><h4>内置浏览器环境</h4><p>当任务涉及到网页交互（例如“去官网查阅文档”或“测试 Web 应用”）时，主 Agent 会调用一个专门的浏览器子 Agent。该子 Agent 拥有点击、滚动、输入和读取控制台日志的能力。</p><p>而且这个浏览器是完全隔离。它不共享用户本地的 Cookie、历史记录或登录状态。Agent 的每一次操作是干净又卫生的，既保证了测试结果的客观性，也确保了用户主浏览器的隐私与安全。</p><p><img width="723" height="432" referrerpolicy="no-referrer" src="/img/bVdneyi" alt="image.png" title="image.png" loading="lazy"/></p><h4>Artifacts（产物）：建立信任</h4><p>当 Agent 反馈“任务已完成”时，该如何验证？Antigravity 通过生成 <strong>Artifacts</strong> 来解决信任问题：</p><ul><li><strong>任务计划</strong>：执行前的行动大纲。</li><li><strong>代码变更</strong>：标准的 Diff 视图。</li><li><strong>屏幕录制</strong>：如果任务涉及 UI 交互，Agent 会录制操作视频。无需亲自运行代码，查看视频即可确认是否完成了“点击登录并验证跳转”等功能性需求。</li></ul><h2>实战演练：一句话生成一个 Web 应用</h2><p>为了直观感受 Antigravity 的能力，这里通过一个简单的案例演示：从自然语言指令到可运行的软件。</p><h3><strong>下达</strong> <strong>指令</strong></h3><ol><li>回到 Agent Manager 的 Playground 界面，输入一段朴素的需求：</li></ol><blockquote>帮我做一个待办事项APP，需要手绘风格的</blockquote><h4><strong>观察思考过程</strong></h4><ol><li>提交后，Agent 开始工作。它会生成一个 Task Plan，包含分析需求、设计 UI 布局、编写倒计时逻辑等步骤。随后进入执行阶段，相关文件会被逐一创建。</li></ol><p><img width="723" height="487" referrerpolicy="no-referrer" src="/img/bVdneyj" alt="image.png" title="image.png" loading="lazy"/></p><h3><strong>自动验证</strong></h3><ol><li>Agent 编写完代码后，会自动唤醒浏览器子 Agent。它会在后台打开窗口，亲自点击“开始”按钮，检查倒计时是否正常工作。</li></ol><p><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdneyk" alt="image.png" title="image.png" loading="lazy"/></p><h4><strong>成果交付</strong></h4><ol><li>几分钟后，Agent 提示任务完成。点击生成的链接，一个功能完备、设计极简的待办事项程序就完成了。自己试着用一下，暂时没有发现问题。</li></ol><p><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdneyk" alt="image.png" title="image.png" loading="lazy"/></p><p><strong>小结</strong>：这只是一个简单的 Demo，但足以展示其闭环能力。对于更复杂的逻辑，比如“构建带数据持久化的看板”或“编写现有项目的单元测试”，Antigravity 同样适用。</p><h2>开发者小贴士：打造全能 AI 开发环境</h2><p>Antigravity 带来了 IDE 集成 Agent 的便利，但在实际的 AI 开发工作流中，往往还需要在本地进行更多维度的探索。</p><p>比如，开发者可能需要在<a href="https://link.segmentfault.com/?enc=twNXYdRbBletpKNXDK4G0Q%3D%3D.BakgUfBf1Ro%2F5sUvTmD5h6ZxnU6htoTtr%2BUwqEqkPKCkz3nxJtBPtAU3bqjyjChJ" rel="nofollow" target="_blank">本地跑通 Gemini CLI 工具</a>，这通常硬性要求 Node.js 20 及以上的环境；或者为了隐私和成本，需要在本地机器上直接运行 <strong>Gemma、Qwen3 或 Llama 3</strong> 等开源大模型进行调试。</p><p>此时，繁琐的环境配置和依赖冲突往往是最大的阻碍。若不想在环境搭建上浪费时间，推荐尝试使用 ServBay。这是一个专为开发者设计的本地化环境管理工具：</p><ul><li><strong>一键部署大模型</strong>：支持快速在本地安装并运行 Llama 3、Gemma、Qwen3 等主流模型，省去了复杂的配置过程。</li></ul><p><img width="723" height="458" referrerpolicy="no-referrer" src="/img/bVdneyl" alt="image.png" title="image.png" loading="lazy"/></p><ul><li><strong>环境隔离与管理</strong>：对于 Gemini CLI 这类对环境有严格要求的工具，ServBay 能<a href="https://link.segmentfault.com/?enc=StEWrGY70e5uB5%2B5eEDucg%3D%3D.D1SzOjgd7PnIrLZxQN6sPN20oGi%2BVUFoyMqTAGEK01zO8bDqIzdbj4Le123LCFUb" rel="nofollow" target="_blank">一键安装 Node.js</a> 20+ 等特定运行时，且互不干扰。</li></ul><p><img width="723" height="458" referrerpolicy="no-referrer" src="/img/bVdneym" alt="image.png" title="image.png" loading="lazy"/></p><p>这种超全的配置，无论是云端还是本地，AI助手都能全方位覆盖。</p><hr/><p>通过掌握 Agent Manager 的调度能力、Artifacts 的验证机制以及 Editor 的协作模式，开发者便已准备好使用 Antigravity 进行工作。</p><p>你有没有试过Antigravity，哪款AI编程工具比较好用，一起交流一下吧。</p>]]></description></item><item>    <title><![CDATA[不止加密 JoySSL深度解读SSL证书]]></title>    <link>https://segmentfault.com/a/1190000047444162</link>    <guid>https://segmentfault.com/a/1190000047444162</guid>    <pubDate>2025-12-02 17:06:44</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>全球的组织机构在数字化浪潮的推动下，正在加速数字化转型，推动社会更快更好的发展数字经济。正因如此，企业线上业务的发展也随之不断扩大，而隐藏的安全风险也逐渐提升。互联网的双刃剑属性，让广大用户无法完全信任线上业务。而看似毫不起眼的绿色安全锁以及https前缀，正是企业发展线上业务不可或缺的信任印章，是消除用户疑虑，提升信任感的重要保证。这一切，正是因为SSL证书在默默发挥着关键作用。由于国内互联网起步较晚，企业对数字证书的认知，依旧停留在“显示绿色安全锁”的初级层面。JoySSL技术专家表示：对企业来说，SSL证书不只是简单的技术配置，不止于加密，而是融合数据加密、身份验证和信任于一体的战略资产。</p><p><img width="723" height="549" referrerpolicy="no-referrer" src="/img/bVdneyr" alt="" title=""/></p><p><strong>加密传输隧道 构筑安全屏障</strong></p><p>建立高强度加密通道，是SSL证书最为基础的特点之一。在访问部署过数字证书的网站时，会触发安全通告，并在服务器与浏览器之间建立加密过的会话密钥。诸如登录注册、支付信息、个人数据等隐私信息，都会在传输通道中，以加密形式传递。即使信息被第三方以非法手段攫取，也无法被识别。JoySSL技术处负责人表示，当下数字证书采用的是符合行业标准的RSA算法，加密强度足以抵御主流的网络攻击手段，以技术手段为企业构筑安全屏障。</p><p><strong>验明网站真身 建立品牌信任</strong></p><p>SSL证书的身份验证功能，让安全标准更进一步，具备法律意义，也是免费证书与付费证书的根本区别。数字证书的验证层级包含三层：从域名验证到组织验证，最后是扩展验证，验证程度不断加深。从证明域名的基础控制权，到验证真实合法的法律实体身份，再到验证企业实际存在、运营状态等。</p><p><img width="723" height="549" referrerpolicy="no-referrer" src="/img/bVdneys" alt="" title="" loading="lazy"/></p><p>品牌信任在验证标准的提升下，一步步提高，不断消除用户疑虑。在网络环境日益严峻的当下，带有身份验证信息的网站，就是企业建立品牌信任、树立形象的最佳工具。</p><p><strong>提升防护水准 灵活高效快捷</strong></p><p>现代化企业的IT架构日趋复杂，唯有突破单点防护，全面提升防护水准的SSL证书，才能以更强的适应性为企业提供解决方案。JoySSL以通配符证书应对拥有多子站的客户企业，仅一次部署就可实现全面防护，极大的提高了企业的管理效率。而多域名证书则适用于集团运营，为企业的品牌矩阵提供全面防护。同时，数字证书的跨平台兼容性可以无缝衔接桌面端与移动端，兼容市面主流浏览器。数字证书以灵活的配置面对多样化市场需求，处理快捷，管理高效。</p><p><img width="723" height="549" referrerpolicy="no-referrer" src="/img/bVdneyt" alt="" title="" loading="lazy"/></p><p><strong>构建信任体系 实现品牌价值</strong></p><p>数字证书于用户体验层面构建信任体系，除了绿色锁形标识，部署EV证书还可以直接展现经过验证的企业名称，这与“不安全”标识相比，用户体验天差地别。绿色安全锁与地址栏，本就是谷歌、微软等全球科技巨头联手构建的用户信任体系中的重要组成部分。企业凭借数字证书，在用户访问网站的第一步，就实现了“广告宣传”，并向广大用户传递出专业、安全、可信的形象，不仅保护了网站数据，也同时提升了企业的影响力与口碑，真正实现品牌价值。</p>]]></description></item><item>    <title><![CDATA[GMI Cloud Inference ]]></title>    <link>https://segmentfault.com/a/1190000047444167</link>    <guid>https://segmentfault.com/a/1190000047444167</guid>    <pubDate>2025-12-02 17:06:10</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>一、为什么会关注 GMI Cloud？</h2><p>最近这一年，做 AI 应用开发最大的痛点不是「模型不够多」，而是「模型太多但用起来太碎」。每接一个新项目，就要重新注册平台、充值、拿 Key、改 SDK、适配一堆不同的 API 格式——尤其是要同时用 DeepSeek、Kimi、Qwen、Gemini、各家视频 / 图片模型的时候，工程成本非常高。</p><p>GMI Cloud 推出的 Inference Engine 2.0 主打的就是：多模态、统一 API、一站式控制台，把文本、图像、音频、视频模型收在同一个工作台里，并在官方博客中强调了更快的响应、更高吞吐、自动伸缩等一系列优化点。</p><p>下面就按照「线上体验」+「API 调用」两个视角，把这次体验过程梳理一下。</p><hr/><h2>二、线上体验：从 sourl 短链到多模态 Playground</h2><h3>2.1 注册与控制台首印象</h3><p>通过官方提供的注册链接 <a href="https://link.segmentfault.com/?enc=vX7svbsHi1ORv7LHGrigHg%3D%3D.9FrNyFsCdbD9618lHnc9%2FSDttkL3lEq7lQgHtaoGRLk%3D" rel="nofollow" target="_blank">https://sourl.co/QLc9ci</a> 打开网站，会跳转到 GMI Cloud 的官网 / 控制台。这个短链是官方推荐的注册入口，注册流程比较顺滑，支持邮箱注册，也支持 Google、GitHub、Hugging Face 等三方账号一键登录。</p><p>完成注册后，默认会进入主控制台，在顶部导航可以看到 GPU Cloud、Cluster Engine、Inference Engine、Model Library 等模块；本次评测主要围绕 Inference Engine 和 Model Library 展开。</p><p>比较友好的一点是：新用户可以通过控制台里的「Billing / Redeem」入口兑换一定额度的体验金（例如 2 USD 额度），足够跑一轮小规模实验。活动细节以后台实际页面为准。</p><h3>2.2 LLM 模型体验：主流大模型一站集成</h3><p><img width="723" height="388" referrerpolicy="no-referrer" src="/img/bVdneyw" alt="image.png" title="image.png"/><br/>在 Inference Engine 中切换到 LLM 模型，可以看到 GMI Cloud 已经接入了大量热门模型，比如 DeepSeek R1 / V3、Llama 3.3 / 4 系列、Qwen3 系列，以及 Kimi-K2、MiniMax 等，统一在 Model Library 中集中展示，很多模型可以一键进入 Playground。</p><p>我这次主要玩了几类场景：</p><ul><li>代码 &amp; 推理：DeepSeek R1、Qwen3 Coder 这类「代码 + 推理混合」模型，在控制台直接切换 model 就能对比效果，无需改代码。</li><li>通用对话 &amp; 文案：Llama 3.3 70B、Qwen3 32B 这类模型用来写文案 / 总结报告，速度和质量都比较均衡。</li><li>本地语境：Kimi-K2 系列在中文场景下表现不错，尤其是长文档阅读和检索问答。</li></ul><p>使用流程大致是：</p><ol><li>在 Model Library 或 Inference Engine 控制台里选择一个 LLM 模型（例如 <code>deepseek-ai/DeepSeek-R1</code>）。</li><li>点击「Playground」，进入在线调试界面。</li><li>在输入框里写提示词，右侧可以调整采样温度、最大输出长度等参数（不同模型支持的参数略有区别）。</li><li>直接发送，对话会以 Chat 形式展示出来。</li></ol><p>对开发者而言，更有价值的是它的 OpenAI 兼容接口。官方 LLM API 文档写得很清楚：通过 <code>https://api.gmi-serving.com/v1</code> 这个统一入口，就可以用标准的 <code>chat.completions</code> 协议和各种 LLM 交互，参数名和语义基本与熟悉的 OpenAI 风格一致，比如 <code>model</code>、<code>messages</code>、<code>temperature</code>、<code>max_tokens</code>、<code>stream</code> 等。</p><p>典型的 Python 代码示例如下（以 DeepSeek R1 为例）：</p><pre><code class="python">import os
from openai import OpenAI
client = OpenAI(
    api_key=os.environ["GMI_API_KEY"],
    base_url="https://api.gmi-serving.com/v1",
)
resp = client.chat.completions.create(
    model="deepseek-ai/DeepSeek-R1",
    messages=[
        {"role": "user", "content": "帮我总结一下 GMI Cloud Inference Engine 的特点，用 5 条列出来。"}
    ],
    max_tokens=512,
    temperature=0.7,
)
print(resp.choices[0].message.content)</code></pre><p><strong>主观感受</strong>：</p><ul><li>多模型切换非常轻量，Playground 支持一键换模型，对比效果很方便。</li><li>API 层用统一的 host 和协议；切换模型基本只改 <code>model</code> 字段即可，适合集成到现有的 OpenAI SDK 项目里。</li><li>文档里给了参数解释和示例响应，几乎可以「照抄即用」。</li><li>如果你习惯直接用各家官方 SDK，这里需要稍微适配一下 base_url 和模型 ID 命名。</li></ul><h3>2.3 Video 模型体验：从文本到高清视频</h3><p><img width="723" height="603" referrerpolicy="no-referrer" src="/img/bVdneyx" alt="image.png" title="image.png" loading="lazy"/><br/>Video 这一块是 Inference Engine 的亮点之一。GMI Cloud 在 Model Library 和官方文档中介绍，已经支持 Veo3、Luma Ray2、Kling V2.x、Wan2.x 等一系列前沿视频模型，统一通过队列式 API 管理生成任务。</p><p>在控制台里选择 Video 模型时，可以看到每个模型都有独立的说明页（Description），里面会写清楚支持的输入类型（仅文本 / 文本 + 图像）、分辨率、时长限制以及计费方式。大致体验流程是：</p><ol><li>在 Video 模型列表里选择一个模型，比如 <code>Veo3</code> 或 <code>Minimax-Hailuo-2.3</code>。</li><li>直接在界面上填写 Prompt，有些模型支持上传一张参考图。</li><li>根据需要设置时长（<code>durationSeconds</code>）、比例（<code>aspectRatio</code>）等参数。</li><li>点击生成，后台会通过队列异步生成视频，生成完成后在页面上可以直接预览和下载。</li></ol><p>如果你更偏向代码调用，可以参考官方的 Video API 文档。整体思路是：</p><ul><li>用 <code>GET /api/v1/ie/requestqueue/apikey/models</code> 列出可用视频模型；</li><li>用 <code>GET /api/v1/ie/requestqueue/apikey/models/{model_id}</code> 查看模型 schema 和可调参数；</li><li>用 <code>POST /api/v1/ie/requestqueue/apikey/requests</code> 提交生成任务；</li><li>用 <code>GET /api/v1/ie/requestqueue/apikey/requests/{request_id}</code> 轮询任务状态；</li><li>任务成功后，在返回的 <code>outcome</code> 字段里拿到最终的视频 URL。</li></ul><p>一个简化版的 cURL 流程可以写成这样（以 Veo3 为例）：</p><pre><code class="bash"># 1. 发送生成请求
response=$(curl -s -X POST   https://console.gmicloud.ai/api/v1/ie/requestqueue/apikey/requests   -H "Authorization: Bearer $GMI_API_KEY"   -H "Content-Type: application/json"   -d '{
    "model": "Veo3",
    "payload": {
      "prompt": "A cyberpunk city at night, tracking shot, cinematic lighting",
      "durationSeconds": "8",
      "aspectRatio": "16:9"
    }
  }')
REQUEST_ID=$(echo "$response" | jq -r .request_id)
# 2. 轮询任务状态并最终获取视频 URL
curl -s   https://console.gmicloud.ai/api/v1/ie/requestqueue/apikey/requests/$REQUEST_ID   -H "Authorization: Bearer $GMI_API_KEY" | jq .outcome</code></pre><p><strong>主观感受</strong>：</p><ul><li>队列式 API 设计比较「云原生」，很适合在后端服务里做异步任务 + 回调。</li><li>控制台一侧能看到视频生成进度，开发与运营可以共用同一个视图。</li><li>视频模型本身价格差异较大，建议提前看清每个模型的单价再「狂点生成」。</li></ul><h3>2.4 Image 模型体验：插画、产品图与创意设计</h3><p><img width="723" height="528" referrerpolicy="no-referrer" src="/img/bVdneyC" alt="image.png" title="image.png" loading="lazy"/><br/>图像部分，GMI Cloud 已经接入了 Seedream 3.0 / 4.0、SeedEdit 3.0、Flux-kontext-pro 等一系列高质量文生图 / 图生图模型，并在 Inference Engine 2.0 的介绍里强调了「端到端图像工作流」。</p><p>从实际操作体验来看，流程与视频类似：</p><ol><li>选择一个图像模型，比如 <code>seedream-4-0</code> 或 <code>flux-kontext-pro</code>（以控制台实际展示为准）。</li><li>填写文本提示词，或上传一张参考图片作为基础。</li><li>调整尺寸、风格、迭代步数这些参数（不同模型的参数名略有区别）。</li><li>发起生成后即可在控制台看到预览图和下载链接。</li></ol><p>如果你已经比较熟悉 Stable Diffusion 系列模型，迁移到这些新模型的成本非常低，Prompt 写法基本通用，只需要熟悉每个模型在人物、场景、产品图上的特长即可。官方博客和社交媒体上也会定期展示一些 Seedream / Flux-kontext-pro 的示例效果，方便选型。</p><hr/><h2>三、API 调用流程：从统一 API Key 到多模态调用</h2><h3>3.1 统一 API Key 管理</h3><p><img width="723" height="610" referrerpolicy="no-referrer" src="/img/bVdneyy" alt="image.png" title="image.png" loading="lazy"/><br/>GMI Cloud 的 API 认证方式比较统一：</p><ul><li>所有 Inference Engine 的 API 都通过 API Key 做认证；</li><li>Key 在控制台右上角的「User / Organization Settings → API Keys」里统一管理；</li><li>HTTP 请求头里用 <code>Authorization: Bearer &lt;your-api-key&gt;</code> 即可。</li></ul><p>需要特别注意的是：API Key 只在创建时完整展示一次，之后无法再次查看明文，申请完一定要妥善保存。</p><h3>3.2 LLM API：一个接口打通多家大模型</h3><p>LLM API 的核心是一个 OpenAI 风格的 <code>chat.completions</code> 接口：</p><ul><li><code>GET /v1/models</code>：列出当前可用模型；</li><li><code>POST /v1/chat/completions</code>：进行对话 &amp; 文本生成；</li><li>支持 <code>stream</code> 流式输出、<code>response_format</code> JSON Mode 等高级特性。</li></ul><p>这意味着，你可以把原来写给 OpenAI / DeepSeek / Qwen 的那套业务逻辑，几乎无缝迁移过来：</p><ul><li>业务代码只保留一个 OpenAI SDK；</li><li>把 <code>base_url</code> 换成 <code>https://api.gmi-serving.com/v1</code>；</li><li>把 <code>model</code> 换成 GMI Cloud 提供的模型 ID（例如 <code>deepseek-ai/DeepSeek-R1</code>、<code>qwen/qwen3-32b</code> 等）。</li></ul><p>对于需要做多模型 A/B 测试的团队，这种统一接口的价值非常大：你可以在配置文件里维护一组模型 ID，然后通过配置 / 灰度策略动态切换，无需频繁改代码。</p><h3>3.3 Video / Image API：队列式异步任务 + Artifact 管理</h3><p>Video / Image 部分则走的是另一条路线：基于请求队列和 Artifact 的工作流。从官方 Video API 文档可以看到，这一套接口可以概括为：</p><ul><li><code>GET /api/v1/ie/requestqueue/apikey/models</code>：查询哪些视频模型可用；</li><li><code>GET /api/v1/ie/requestqueue/apikey/models/{model_id}</code>：查看某个模型支持的参数、限制、示例；</li><li><code>POST /api/v1/ie/requestqueue/apikey/requests</code>：提交生成任务（视频 / 图像）；</li><li><code>GET /api/v1/ie/requestqueue/apikey/requests/{request_id}</code>：轮询任务状态、获取生成结果；</li><li>最终通过返回的 <code>thumbnail_image_url</code>、<code>video_url</code> 等字段拿到文件地址。</li></ul><p>这种设计对后端同学非常友好：</p><ul><li>可以自然地封装成一个「提交任务 + 轮询 + 回调」的异步服务；</li><li>前端 / 运营可以直接用控制台查看任务队列状态；</li><li>结合 GMI Cloud 自己的 Resources / Artifacts 模块，还可以把自定义模型、工作流统一托管在平台上。</li></ul><hr/><h2>四、性能、价格与稳定性：来自官方与公开数据的侧写</h2><p>由于本次只是功能性体验，没有做大规模压测，这里更多参考官方公开的数据来补充一些判断：</p><ul><li>Inference Engine 2.0 博客里提到，在真实负载下，新的推理架构能带来可观的延迟和吞吐提升，并通过 KV Cache、自动批处理等手段降低推理成本。</li><li>针对大规模图像生成的官方长文中还给出了一组案例：某视频生成业务在迁移到 GMI Cloud 后，推理延迟下降 65%，计算成本降低 45%，并通过自动伸缩应对高峰流量。</li><li>在 GPU 底层上，GMI Cloud 本身是 NVIDIA Reference Cloud Platform Provider，主力卡型包括 H100 / H200 等，价格按 GPU 小时计费，支持按需付费和预留容量，H200 容器实例按小时价格在 3 美元左右起步。</li></ul><p>从开发者的视角来看，这些优化的直接收益就是：</p><ul><li>做 PoC / 小规模实验时，不需要自己折腾 GPU 集群，直接用 Serverless 式推理就可以；</li><li>上线之后，可以一步步升级到 Dedicated Endpoint 或自定义模型，把成本和性能收敛到更适合自己业务的水平。</li></ul><hr/><h2>五、适用人群与典型场景</h2><p>综合这次体验，我觉得 GMI Cloud Inference Engine 比较适合这些场景：</p><h3>1. 多模型对比 &amp; 评测团队</h3><p>需要频繁对比不同厂商 / 不同版本大模型效果的团队，可以用它统一接入 DeepSeek、Kimi、Qwen、Llama、Gemini 等模型，显著降低多平台接入成本。</p><h3>2. 内容生产与创意工作室</h3><p>视频 + 图片 + 文本三件套都在同一个控制台里，对做广告创意、短视频、动态海报的团队非常友好，可以快速搭原型、做 Demo、验证创意。</p><h3>3. 想「先用托管推理，再慢慢自建」的企业</h3><p>不想一上来就自己搭 GPU 集群的团队，可以先用 Inference Engine 把业务跑起来，等业务稳定再考虑迁移到自建 Cluster Engine 或混合架构。</p><hr/><h2>六、优缺点总结与个人评价</h2><h3>优点：</h3><ul><li>多模态一站式：LLM + Image + Video + Audio 统一在一个控制台和 API 之下，多模型协作时非常顺手。</li><li>OpenAI 兼容 API：对已有项目的迁移成本很低，基本是改 base_url + model 即可。</li><li>队列式视频 / 图像 API：异步任务模型设计合理，天然适配后端服务和大规模生成场景。</li><li>基础设施扎实：NVIDIA Reference Cloud Platform、H100/H200 等高端 GPU、全球数据中心布局，对需要稳定推理服务的业务比较有吸引力。</li></ul><h3>可以改进的地方（主观）：</h3><ul><li>控制台支持的功能很多，新用户第一次进来会稍微有点「信息量过大」，适合配套一篇「新手上手指南」。</li><li>视频 / 图像模型参数较多，对完全非技术用户来说需要一点学习成本（好在 Description 页写得比较详细）。</li><li>官方案例目前更多是英文内容，国内团队如果能有更多中文最佳实践和模板，会更容易推广。</li></ul><h3>总体评价：</h3><p>如果你正在寻找一个「一个账号玩转多家模型」的平台，尤其是同时需要 LLM、视频、图像这三类能力，那么 GMI Cloud Inference Engine 值得认真试一试。通过 <a href="https://link.segmentfault.com/?enc=IMkPIX%2FfxdkZeA6mvB%2FMaA%3D%3D.CVFUwWhltTdIv0UPPLnBmNxRCQ4fDECUufveDhuUFd0%3D" rel="nofollow" target="_blank">https://sourl.co/QLc9ci</a> 注册账号，再配合官方的 Inference Engine 文档，你可以用很小的接入成本，快速搭起一个覆盖文本、图像、视频的多模态 AI 能力层，用来支撑自己的产品、工具或工作流。</p>]]></description></item><item>    <title><![CDATA[高性能cpu 咕噜云服务器晚晚 ]]></title>    <link>https://segmentfault.com/a/1190000047444197</link>    <guid>https://segmentfault.com/a/1190000047444197</guid>    <pubDate>2025-12-02 17:05:14</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>2025年高性能CPU市场主要由Intel、AMD和Apple Silicon三大阵营主导。Intel凭借Core Ultra系列在移动平台和AI性能上持续发力；AMD的Ryzen 8000系列桌面处理器及移动端处理器，在多核性能和能效比上保持强劲竞争力；Apple的M3系列芯片则在特定创意工作流中展现出极高效率。<br/>性能天梯图从上至下大致分为：旗舰级（如AMD Ryzen 9 9950X、Intel Core i9-14900KS、Apple M3 Max，适合顶级游戏、8K视频剪辑等重度负载）；高端级（如AMD Ryzen 7 9700X、Intel Core Ultra 9 185H、Apple M3 Pro，满足2K/4K高画质游戏等需求）；中端主流级（如AMD Ryzen 5 8600G、Intel Core Ultra 7 155H，应对1080P游戏等）；入门级（如AMD Ryzen 3 8300G、Intel Core Ultra 5 125H，专注基础任务）。<br/>核心选购要素需场景化分析：游戏玩家侧重单核性能，如Intel Core i7-14700K或AMD Ryzen 7 7800X3D；内容创作者依赖多核性能，如AMD Ryzen 9 9950X（16核32线程）或Apple M3 Max；办公用户优先考虑能效与续航，如AMD Ryzen 5 8600G或Intel Core Ultra 5 125H。<br/>平台考量方面，主板平台上AMD的AM5平台预计支持到2027年以上新CPU，Intel的LGA 1700/1851平台升级性相对受限；内存支持DDR5内存已成为主流，频率普遍达6000MT/s以上；散热上高性能CPU需配备高质量水冷或风冷；AI引擎方面，内置NPU的CPU（如Intel Core Ultra系列、AMD Ryzen 8040/8050系列）能高效处理AI任务。<br/>主流型号中，AMD Ryzen 9 9950X为16核32线程，在多线程任务中优势明显，大幅缩短视频导出和渲染时间；Intel Core Ultra 9 285K拥有24核24线程设计，睿频高达5.7GHz，集成36MB高速缓存与13 TOPS算力的NPU单元，支持本地运行大模型；Apple M3 Max在Final Cut Pro等苹果生态软件中表现无与伦比，适合创意工作流。</p>]]></description></item><item>    <title><![CDATA[观测云荣膺亚马逊云科技 2025 年合作]]></title>    <link>https://segmentfault.com/a/1190000047444215</link>    <guid>https://segmentfault.com/a/1190000047444215</guid>    <pubDate>2025-12-02 17:04:42</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><em>观测云荣获亚马逊云科技 Marketplace 年度合作伙伴奖项，成为亚马逊云科技全球众多推动客户创新的优秀合作伙伴之一</em></p><p>中国北京——2025年12月2日——观测云欣然宣布荣获 2025 年亚马逊云科技区域和全球合作伙伴奖项，旨在表彰全球各地帮助客户基于亚马逊云科技构建解决方案并推动创新的佼佼者。观测云荣膺亚马逊云科技 Marketplace 年度合作伙伴奖项，该奖项表彰在亚马逊云科技 Marketplace 交易业绩突出的优秀亚马逊云科技合作伙伴。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444217" alt="图片" title="图片"/></p><p>亚马逊云科技区域和全球合作伙伴奖项在 re:Invent 2025 的合作伙伴颁奖晚会上颁布，奖项表彰了在过去一年中，业务模式极具专业、创新和合作精神的亚马逊云科技合作伙伴。合作伙伴奖项的获得者在与客户的合作过程中，不断精进自身业务模式，并在亚马逊云科技上蓬勃发展。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444218" alt="图片" title="图片" loading="lazy"/></p><p>针对企业在云原生转型中面临的“监控工具链碎片化”与“海量数据存储”挑战，观测云在实际生产环境中打破了传统 APM、Log、Infrastructure 等监控的界限。以通力电梯（KONE）为例，观测云帮助其构建了从底层云资源到上层数字化维保业务的端到端观测体系，致力于打通开发、运维与业务团队的数据闭环。这一实践不仅有助于优化故障修复流程（MTTR），更为客户企业的全球化业务扩展提供了符合当地合规要求、低延迟的统一监控视角。此外，通过亚马逊 Marketplace 一键订阅，该方案有效帮助出海企业解决了跨国采购合规与账单统一管理的痛点。</p><p>观测云 CEO 蒋烁淼表示：“荣获‘亚马逊云科技 Marketplace 年度合作伙伴奖’让我们倍感荣幸。这一荣誉既<strong>是对我们全球化商业拓展的肯定，也是对观测云在云原生技术创新的认可</strong>。 通过与亚马逊云科技的深度生态合作，观测云在过去一年服务了更多的海外客户，尤其在零售和 AI 领域积累了宝贵的实践经验。<strong>面对日益复杂的云原生环境，我们将保持对技术的敬畏之心，持续打磨核心数据底座的坚韧性与适配性</strong>。 亚马逊云科技 Marketplace 为我们提供了一条通往全球市场的车道，我们将继续努力，凭籍不断进化的技术能力，为全球客户创造核心价值。”</p><p>通力股份有限公司（KONE），于 1910 年创立，总部设于芬兰，是世界上最大的电梯和电扶梯制造商之一。作为双方共同服务的标杆客户，通力电梯（KONE）数字化运维工程师徐路宝表示：“<strong>接入观测云后，我们建立了一套覆盖数字化维保业务的监控体系，能够更及时地感知设备运行状态。通过打通业务、开发与运维数据，为我们的数字化转型提供了重要的数据支撑</strong>。”</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444219" alt="图片" title="图片" loading="lazy"/></p><p>亚马逊云科技区域和全球合作伙伴奖项包括以自我提名的形式在区域和全球层面授予的多个类别奖项。所有亚马逊云科技合作伙伴均受邀参与并提交申请。奖项申请材料由第三方机构 Canalys 负责审计，评奖时尤其重视客户成功案例。</p><p>合作伙伴奖项亦包含多个基于业务数据的奖项，该类奖项采用一套完善的衡量指标，评价亚马逊云科技合作伙伴在过去一年中的表现。Canalys 对使用的数据集进行了严格审计，以确保所有测量和计算的客观性和准确性。入围者代表了每个类别中排名前三的亚马逊云科技合作伙伴。</p><p>亚马逊云科技合作伙伴网络（APN）是一个全球性计划，致力于赋能合作伙伴创新、加速向云端迁移，并充分利用亚马逊云科技广泛的资源和深厚的技术实力。</p><p>观测云是一款 AI 时代的全域数据观测平台，全面覆盖 App、Web、后端、中间件、基础设施与云平台的全链路监控，集成 500+ 主流技术栈与云服务。连接开发、运维与业务团队，打破数据孤岛，以海量数据与统一为核心，让企业实现数据的统一存储、统一查询与统一展示，最终让一切数据都能被理解与利用，让云上数据成为企业可执行的洞察。已服务1000+家企业，覆盖 AI、金融、零售、制造等行业。观测云已上架亚马逊云科技 Marketplace，并与亚马逊云科技联合构建可观测性解决方案，助力全球企业在云原生与 AI 时代实现从性能到安全的全面跃升。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444220" alt="图片" title="图片" loading="lazy"/></p><p>无论是希望深入了解本次获奖背后的技术故事，还是探讨如何利用观测云观测您的系统，我们都期待与您交流。</p>]]></description></item><item>    <title><![CDATA[关于 Ingress NGINX 停止维]]></title>    <link>https://segmentfault.com/a/1190000047444238</link>    <guid>https://segmentfault.com/a/1190000047444238</guid>    <pubDate>2025-12-02 17:03:42</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>关于 Ingress NGINX 停止维护的说明</h2><p>感谢大家一直以来对 KubeSphere 的关注，也感谢社区伙伴第一时间向我们反馈 Ingress NGINX 停止维护的相关信息。为了帮助大家提前做好规划，我们在这里做一个清晰的说明。</p><h4>需要先明确的一点</h4><p><strong>Ingress NGINX 项目终止维护并不代表 Kubernetes Ingress API 被弃用。</strong></p><ul><li>Ingress NGINX 是 Ingress Controller 的一种社区实现，由社区维护。</li><li>根据公告，该项目将从<strong>2026 年 3 月</strong>起停止维护，不再提供补丁和版本更新。</li><li><strong>Kubernetes 官方的 Ingress API（<code>networking.k8s.io/v1</code>）仍然处于稳定状态，可以继续正常使用。</strong></li></ul><p>也就是说，Ingress NGINX 的停止维护影响的是某个实现，而不是整个 Ingress 标准。</p><h3>KubeSphere 的后续支持计划</h3><p>为了保证用户的使用体验和生态的长期稳定性，我们将提供以下支持路径。</p><h4><strong>1. 从 2026 年 3 月起，提供 Gateway API 支持</strong></h4><p>Gateway API 是 Kubernetes 社区推出的新一代流量管理标准，具备更强的扩展性和更清晰的角色模型。</p><p>KubeSphere 将在 2026 年 3 月起提供：</p><ul><li><strong>Gateway API 的可视化管理能力</strong></li><li><strong>一个可开箱即用的内置 Gateway API 实现</strong></li></ul><p>我们希望用户能够在原有体验基础上，平滑过渡到更现代的流量管理方式。</p><h4><strong>2. 默认替换 Ingress NGINX，选用社区活跃的替代方案</strong></h4><p>在 Ingress NGINX 停止维护后，KubeSphere 将：</p><ul><li><strong>选择一个社区活跃度高、维护稳定、具备长期支持能力的 Ingress Controller 作为默认方案</strong></li><li>新版本与新集群将默认启用该替代实现</li></ul><p>候选方案会在活跃度、稳定性、生态支持方面进行综合评估。</p><h4><strong>3. 过渡期间，您可以自由选择适合的方案</strong></h4><p>在新的默认方案正式发布前，为了不影响现有业务，您依然可以自由扩展自己的流量管理方式：</p><ul><li><strong>手动部署任意 Ingress Controller</strong>（<a href="https://link.segmentfault.com/?enc=vNdmKILkyNVjeL%2B5uRZLFw%3D%3D.T8sWup8qBwNK2gPDIla1VCz8q3jsuXchYZncVn%2F4Q6bcO6d7n%2FgP0IXv4LRal0JAvyf0P%2FTLWO3ekUkHtlFyfkzWE6hFa0sKKK9ukGdbDJs%3D" rel="nofollow" target="_blank">https://kubernetes.io/docs/concepts/services-networking/ingre...</a>）</li><li><strong>手动部署任意 Gateway API 实现</strong>（<a href="https://link.segmentfault.com/?enc=k%2BKB740FhyGS4UPrJSbf3A%3D%3D.B%2B8Uzu95pMzZI2HDHBFBpQjZcDr31uOU6T1%2FaLbI0V3AIk9gKmbEEudLX69%2B7z7OuZr9jTzDZ15YrAJJeqmrTA%3D%3D" rel="nofollow" target="_blank">https://gateway-api.sigs.k8s.io/implementations/</a>）</li><li><strong>继续通过 Web Terminal 或其他 CLI 工具进行管理</strong></li></ul><p>这些方式不会影响现有应用运行，也为您提前测试或逐步迁移提供了空间。</p><h3>总结</h3><ul><li><strong>Ingress NGINX 停止维护不等于 Ingress API 弃用</strong></li><li><strong>KubeSphere 将在 2026 年 3 月起提供 Gateway API 的可视化能力与内置实现</strong></li><li><strong>我们将选择更稳定、社区更活跃的 Ingress Controller 作为默认替代</strong></li><li><strong>在此期间，您可以根据需求自由部署和测试其他实现，确保业务稳定</strong></li></ul><p>如果您在迁移方案、兼容性或最佳实践方面有任何疑问，我们很愿意继续提供帮助。感谢大家对 KubeSphere 的信任与支持。</p><p>—— KubeSphere 团队</p>]]></description></item><item>    <title><![CDATA[小白也能看懂的保姆级攻略 咕噜云服务器晚]]></title>    <link>https://segmentfault.com/a/1190000047444243</link>    <guid>https://segmentfault.com/a/1190000047444243</guid>    <pubDate>2025-12-02 17:03:09</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>云服务器使用超简单教程，小白也能看懂的保姆级攻略<br/>最近好多朋友问我云服务器怎么用，说听起来特高大上，怕自己玩不转。其实真没那么复杂，今天就用大白话给你唠唠，保证看完就能上手！<br/>一、先搞明白云服务器是个啥<br/>说白了，云服务器就是别人家电脑的硬盘和主机，只不过这台电脑放在专业机房里，24小时不关机。你租了之后，就相当于拥有了一个随时在线的“远程电脑”，可以存文件、跑程序、搭网站，比自己买服务器省事儿多了——不用买硬件，不用管维修，按月交钱想用就用，不想用就停，跟租房子似的灵活。<br/>二、选服务器就像挑外卖，这几点得看准<br/>1.配置别瞎买，够用就行<br/>新手就从“入门款”开始，比如1核2G内存、40G硬盘，像阿里云的“学生机”、腾讯云的“轻量应用服务器”都挺合适，一年才一百多块，比手机话费还便宜。等以后你网站访问量大了，再像手机升级套餐一样加配置就行。<br/>2.地域选得好，访问速度嗷嗷快<br/>选离你用户近的地方！比如你主要给北京人用，就选华北节点；给广东人用，就选华南节点。别图便宜选国外的，不然访问起来跟蜗牛似的，用户早跑光了。<br/>3.系统选对少踩坑<br/>小白直接选Windows Server，跟你家电脑操作一模一样，看见桌面图标就亲切；要是你想搭网站、玩Linux，选CentOS或Ubuntu，虽然是黑框框命令行，但教程一搜一大把，照着敲就行。<br/>三、购买到上手，三步搞定<br/>第一步：下单付款，就像网购一样简单<br/>打开阿里云、腾讯云这些官网（认准带“官网”标识的，别进错钓鱼网站），注册账号实名验证（现在都要身份证，正规平台放心填），然后找到“云服务器ECS”或“轻量应用服务器”，选好配置、地域、系统，付款！记住选“按年付”比“按月付”便宜，新用户还有折扣，别错过。<br/>第二步：拿到“钥匙”，远程登录<br/>买完后在“控制台”找到你的服务器，会显示一个“公网IP”（就像服务器的门牌号），还有“用户名”（Windows默认是Administrator，Linux是root）。第一次登录需要重置密码，设个复杂点的（字母+数字+符号），不然容易被黑客破解。<br/>Windows登录：打开你电脑的“远程桌面连接”（按Win+R，输入mstsc回车），输入公网IP，点连接，然后输入用户名密码，啪！直接看到服务器桌面，跟操作自己电脑一样，可以复制粘贴文件、装软件。<br/>Linux登录：用“PuTTY”或“Xshell”这些工具（官网免费下），输入IP、端口（默认22），点连接，输入用户名密码，黑框框里出现“#”就成功了，想传文件用“WinSCP”，图形化界面拖文件就行。<br/>第三步：装软件、存文件，想干嘛干嘛<br/>登录进去后，Windows用户直接打开浏览器下软件，跟平时用电脑没区别；Linux用户想搭网站？先装个宝塔面板（命令行输入一行代码就行，官网有教程），瞬间变成可视化界面，点鼠标就能装Nginx、MySQL、PHP，比搭积木还简单。存文件？直接把电脑上的照片、文档拖到服务器里，相当于拥有了一个永不关机的移动硬盘，随时随地用IP访问。<br/>四、服务器常用操作，小白必备技能<br/>1.文件传输：把电脑文件传到服务器<br/>Windows直接用“远程桌面”里的“复制粘贴”，或者共享文件夹；Linux用WinSCP，左边是你电脑文件，右边是服务器文件，拖过去就完事。<br/>2.装软件：跟手机下APP一样<br/>Windows打开浏览器下.exe安装包，双击下一步；Linux用命令行，比如Ubuntu装软件就输“sudo apt install 软件名”，不会就搜“Linux 装XXX教程”，复制粘贴命令就行。<br/>3.搭网站：三步让别人访问你的网页<br/>o买个域名（阿里云万网、腾讯云域名注册，几十块一年，比如xxx.com），然后“域名备案”（国内服务器必须备案，免费但要等一周左右，按提示填资料拍照片）。<br/>o在服务器上装“宝塔面板”，一键部署“WordPress”（全球最火的建站程序，模板多到挑花眼），跟着向导填数据库信息，5分钟搞定网站框架。<br/>o把域名解析到服务器IP（在域名控制台操作，跟着教程来，一般10分钟生效），然后在浏览器输入域名，就能看到你的网站啦！<br/>五、这些坑千万别踩！<br/>1.别把密码设成123456<br/>简单密码等于给黑客留门，人家用软件一跑就破解了，到时候服务器被用来挖矿、发垃圾邮件，你哭都来不及。密码至少8位，字母大小写+数字+符号，记不住就写在小本本上。<br/>2.服务器不是无限空间<br/>买的时候看清硬盘多大，别使劲存电影，满了就打不开了。定期清理没用的文件，像Windows的回收站、日志文件，占空间还拖慢速度。<br/>3.别乱点不明链接<br/>服务器上的浏览器别乱逛，尤其是那些弹窗广告，一不小心就中病毒，服务器被黑了可不是小事。装个杀毒软件（Windows自带Windows Defender，Linux基本不用），定期扫描。<br/>4.记得备份！记得备份！记得备份！<br/>重要的事情说三遍！在控制台找到“快照”功能，每周手动备份一次，或者设置自动备份。万一服务器崩了、文件丢了，用快照一秒恢复，不然你辛辛苦苦做的网站、存的文件全没了，哭都没地方哭。<br/>六、遇到问题怎么办？找客服啊！<br/>别以为技术问题就得自己扛，阿里云、腾讯云这些大平台都有24小时客服，在控制台点“帮助中心”或“在线客服”，输入你的问题，比如“服务器登录不上”“IP怎么查”，客服会一步步教你。还有社区论坛，全是跟你一样的新手，发帖提问总有大神回复，比自己瞎琢磨强多了。<br/>总结一下<br/>云服务器真不是啥高科技玩意儿，就把它当成你租的一台远程电脑，买下来、登录进去、想干嘛干嘛。新手别怕，谁都是从不会到会的，多点点多试试，不出一周你就能熟练操作了。现在云服务器越来越便宜，个人玩玩、搭个博客、存点文件都划算，赶紧动手试试吧！记住，实践出真知，光看不动手永远学不会，冲！</p>]]></description></item><item>    <title><![CDATA[AI To C：一场重构流量入口的生死博]]></title>    <link>https://segmentfault.com/a/1190000047444246</link>    <guid>https://segmentfault.com/a/1190000047444246</guid>    <pubDate>2025-12-02 17:02:10</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>当阿里巴巴集团CEO吴泳铭在财报分析师电话会上将“AI To C”与“AI To B”并列为集团核心战略时，这场关乎互联网未来十年格局的战争已悄然升级。这不是一场简单的技术竞赛，而是大厂们在移动互联网红利消退后，为争夺下一代流量入口、用户心智乃至商业命脉的生死博弈。</p><h3>一、入口之变：从“点击”到“对话”的底层逻辑重构</h3><p>互联网发展史本质上是一部入口变迁史。PC时代，浏览器与搜索引擎是第一入口，用户通过“点击-链接”逻辑在信息海洋中逡巡；移动时代，应用商店与超级App成为新霸主，用户被切割在封闭的生态孤岛中。而今，大模型技术的突破正让“对话即界面”从理想照进现实——人类最自然的交互方式，终于不再是迁就机器的妥协。</p><p>以阿里千问App为例，其公测首日因用户涌入过载导致服务中断，次日便冲入苹果App Store免费应用总榜第四位。这款集成了通义系模型能力的产品，不仅支持深度思考、AI修图、翻译等基础功能，更通过“一句指令生成研究报告并制作PPT”的场景化能力，展现出“对话即服务”的颠覆性潜力。当用户无需跳出对话界面即可完成从“查天气”到“订餐厅”的全链路动作时，传统的“搜索-跳转-操作”模式正被彻底解构。</p><p>这种变革绝非技术决定论的狂欢，而是人机交互演进的必然。正如浏览器取代文件目录、触摸屏取代键盘鼠标，对话式入口的崛起将重新定义流量分配规则。掌握这一入口者，将掌握未来至少五年的用户时长与商业转化权——这解释了为何字节跳动、腾讯、百度等大厂纷纷亮剑，推出集成多模态能力的智能体平台。</p><h3>二、大厂困局：移动互联网时代的“囚徒困境”</h3><p>然而，这场战争的残酷性在于：To C是一场零和博弈，一旦某个APP占据用户心智，其他对手将极难逆转。阿里、腾讯、百度等传统大厂，此刻正陷入移动互联网时代遗留的“囚徒困境”。</p><p>阿里电商业务虽为其C端根基，但流量已呈消耗状态。抖音电商GMV逼近阿里核心板块，拼多多在下沉市场持续放大小价优势，用户时长与消费决策被强力分流。更严峻的是，阿里C端场景过于垂直封闭，难以形成自增长闭环。其试图通过钉钉打造超级App的尝试已告失败，如今押注AI To C，实为背水一战——若不能重构流量入口，未来或沦为AI时代的“基础设施供应商”。</p><p>腾讯虽坐拥微信这一超级入口，但风险同样隐现。当用户习惯通过对话满足交流欲望、直接调用服务时，真实社交关系链向新型“Chatbot”迁移的可能性正在增加。AI原生的对话入口，若体验足够极致，完全可能反向吞噬微信的传统地位。</p><p>百度则深陷“搜索依赖症”。尽管“文心一言”试图重构入口壁垒，但其用户场景单一、生态闭环薄弱的短板暴露无遗。在搜索框输入超过38个汉字后仍以传统链接列表呈现的割裂体验，折射出传统搜索与AI生成内容融合的艰难。缺乏高频消费场景支撑的百度，若不能将AI能力嵌入更多生活场景，终难构建真正的“使用惯性”。</p><h3>三、破局之道：场景、数据与生态的“铁三角”</h3><p>在这场入口争夺战中，大厂们并非没有破局之道。场景、数据与生态的“铁三角”模型，正在成为制胜关键。</p><p>以阿里为例，其生态内丰富的应用场景为AI To C提供了独特优势。电商、支付、本地生活等高频消费场景，可形成“场景-数据-模型”的闭环迭代。千问App计划整合地图、外卖、订票等服务，正是试图打破应用壁垒，构建覆盖用户全生活动线的场景化网络。若能实现“规划周末亲子游，订门票、酒店，用余额宝支付”的一站式服务，阿里或将重获流量分配权。</p><p>字节跳动的策略则更具“场景驱动”特色。其通过将AI深度嵌入内容推荐、广告投放、直播互动等核心环节，构建了“场景驱动数据、数据反哺模型、模型优化体验”的闭环。豆包App依托字节庞大的内容生态与多元业务场景，既可利用流量优势导流做大用户池，又可通过守势迫使竞争对手购买流量——攻守之间，尽显主动权。</p><p>而拼多多的“轻量化”策略，则提供了另一种思路。其聚焦电商主业，将AI应用于推荐系统、动态定价、物流调度等场景，通过“场景-数据-反馈”闭环以极低成本快速迭代。在下沉市场消费复苏的背景下，这种务实策略展现出强大的现实杀伤力。</p><h3>四、伦理之殇：技术狂欢下的阴影</h3><p>然而，AI To C的狂飙突进并非没有代价。当Glow等应用靠NSFW（性相关）内容迅速增长，当character.ai因NSFW过滤器招致用户投诉，当AI角色陷入“伦理擦边”的争议时，技术狂欢的阴影已悄然浮现。</p><p>更严峻的是，当AI开始重构人际关系与社会结构时，其伦理风险正从虚拟世界向现实渗透。AI心理治疗师能否替代真实的人际关怀？AI生成的虚假信息如何甄别？用户隐私在多模态交互中如何保护？这些问题，正成为AI To C发展道路上无法回避的“达摩克利斯之剑”。</p><h3>五、未来之战：从“辅助人”到“超越人”</h3><p>阿里管理层将通往超级人工智能（ASI）的路径分为三阶段：智能涌现、自主行动、自我迭代。当前，大模型能力已进入“辅助人”的Agentic AI时代，C端应用涌现并接入现实场景的时机已到。但真正的决战，或许将在ASI时代到来时展开——当AI掌握工具使用和编程能力，具备在真实世界中行动的能力时，流量入口的争夺将升级为“人机共生”生态的构建。</p><p>在这场未来之战中，大厂们需要的不仅是技术突破，更是对人性、伦理与社会的深刻洞察。正如《南方周末》所倡导的“激浊扬清、坚守良知”，AI To C的发展，终需回归“以人为本”的初心——让技术服务于人，而非让人迁就技术；让AI成为提升人类福祉的工具，而非操控人类的枷锁。</p><p>当AI To C的战火愈燃愈烈，我们或许正站在一个新时代的门槛上。这场战争的胜负，不仅将决定大厂们的命运，更将深刻影响人类社会的未来走向。</p>]]></description></item><item>    <title><![CDATA[通往可信数据智能的路线图，就在这本《No]]></title>    <link>https://segmentfault.com/a/1190000047443898</link>    <guid>https://segmentfault.com/a/1190000047443898</guid>    <pubDate>2025-12-02 17:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>数据不好找、不敢用、用不对。<br/>数据取不出、跑不动、要排期。<br/>AI 生成的内容“好看”，但不一定“真实”。</p><p>在大模型席卷各行各业的今天，企业数据智能体（Data Agent）正成为新的“数字员工”。但如果没有一套可信的数据基础，再智能的 Agent 也难逃“数据迷宫”与“口径陷阱”。</p><p>在昨天的推文中，Aloudata CEO 周卫林清晰阐释了 Aloudata 在新时代的品牌定位：NoETL to Trusted AI——以语义编织（Semantic Fabric）为钥，打开“大数据通往大模型”之门，让数据资产成为可信的 AI 资产。</p><p>这份最新的《NoETL to Trusted AI》白皮书将进一步深入厘清以下几个核心问题，并为您揭示通往可信数据智能体的可行路径：</p><p>1.数据智能体“可信”的标准是什么？</p><p>我们提出了数据智能体必须满足的 “三真三好” 可信要求：</p><p>三真：口径真、数据真、血缘真，确保分析根基的牢固。</p><p>三好：听力好、眼力好、脑力好，确保智能体具备卓越的业务理解与洞察能力。</p><p>2.如何实现从“数据资产”到 “AI 资产”的关键跨越？</p><p>白皮书指出，为实现从“数据资产”到“AI 资产”的关键跨越，必须建立统一、可信的数据语义层（Semantic Layer）。</p><p>数据语义层是企业数据架构的中枢神经系统，其核心价值在于为所有分析场景与 AI 应用提供一致、可解释的业务语义。</p><p>白皮书中将深入剖析数据语义层的核心价值，并纵览全球领先厂商（如 Palantir、Google Looker、Databricks 等）在此方向的前沿布局，印证这一技术趋势的必然性。</p><p>3.如何构建可信数据智能体的数据语义层？</p><p>传统上，厘清企业海量数据资产的口径和血缘关系是一项耗时数月、令人望而却步的“脏活累活”。白皮书中分享了 Aloudata 基于“NoETL”理念在这一领域的实践经验。通过语义编织（Semantic Fabric） 能力和自动化算子级血缘解析，企业能够将数据语义层的构建周期从数月大幅缩短至数周，实现对历史数据资产的自动化、智能化盘点与迁移，真正步入“NoETL to Trusted AI”。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047443900" alt="图片" title="图片"/></p>]]></description></item><item>    <title><![CDATA[技术分享 | Oracle 19c RA]]></title>    <link>https://segmentfault.com/a/1190000047443722</link>    <guid>https://segmentfault.com/a/1190000047443722</guid>    <pubDate>2025-12-02 16:13:42</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>本文为<a href="https://link.segmentfault.com/?enc=breej8ZTN%2FHt8H9wqCOeEA%3D%3D.PYzJMSCLCntVYJCbPrCfZXgi5Ycz9JapHydV4f4k5aZVrN0uLN8cI1WCXjMe7wRo" rel="nofollow" target="_blank">墨天轮数据库管理服务团队</a>第146期技术分享，内容原创，作者为技术顾问<strong>达世德</strong>，如需转载请联系小墨（VX：modb666）并注明来源。如需查看更多文章可关注【墨天轮】公众号。</p><h2><strong>一、问题描述</strong></h2><p>巡检发现：客户系统数据库备库ADG数据同步异常，具体信息如下：</p><p>查看复制错误信息：  <br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047443724" alt="image.png" title="image.png"/></p><p>查看复制相关的进程状态：  <br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047443725" alt="image.png" title="image.png" loading="lazy"/></p><h2><strong>二、分析过程</strong></h2><h3><strong>2.1、查看主节点alert日志：</strong></h3><p>发现用户认证错误：  </p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047443726" alt="image.png" title="image.png" loading="lazy"/></p><h3><strong>2.2、验证SYS用户密码，远程访问：</strong></h3><p>主库-备库：  </p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047443727" alt="image.png" title="image.png" loading="lazy"/></p><p>备库-主库：  </p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047443728" alt="image.png" title="image.png" loading="lazy"/></p><h3><strong>2.3 在备库上查询数据最后的同步时间：</strong></h3><pre><code class="sql">select max(CHECKPOINT_TIME) from v$datafile_header;</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047443729" alt="image.png" title="image.png" loading="lazy"/></p><p>在同一时间发生了网络故障，因此初步判断ADG的数据同步应该是网络故障引发。</p><h3><strong>2.4、备库rac节点1无法获取磁盘组信息</strong></h3><p>发现当前节点无法获取到磁盘组的信息：  </p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047443730" alt="image.png" title="image.png" loading="lazy"/></p><h3><strong>2.5、查看磁盘组状态信息：</strong></h3><p>通过命令验证asm服务状态。发现磁盘组无法连接，但是asm服务是正常运行的  </p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047443731" alt="image.png" title="image.png" loading="lazy"/></p><h3><strong>2.6、分析asm alert日志信息</strong></h3><p>日志显示 ORA-04031错误码，提示shared memory太小，无法分配shared\_pool\_size 。  </p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047443732" alt="image.png" title="image.png" loading="lazy"/></p><h3><strong>2.7、查询node1实例启动时间：</strong></h3><p>实例在2024-07-21进行了重启操作，当前无法通过sqlplus / as sysasm连接到asm。  </p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047443733" alt="image.png" title="image.png" loading="lazy"/></p><p>在node2（asm正常）上查看sga信息：  </p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047443734" alt="image.png" title="image.png" loading="lazy"/></p><h3><strong>2.8、查看密码文件</strong></h3><p>确认密码文件位置：  </p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047443735" alt="image.png" title="image.png" loading="lazy"/></p><p>可以看到密码文件存储在磁盘组中，但是node1节点的磁盘组当前法识别，因此导致密码认证错误，ADG出现同步异常。</p><p>因此：ADG数据同步异常根本是备节点的ASM磁盘组异常，而ADG同步的密码文件存储在ASM中，所以数据同步发生认证错误，导致的异常，因此解决办法即恢复备节点的ASM状态即可。</p><h2><strong>三、问题处理</strong></h2><h3><strong>3.1 先解决node1节点的asm异常问题</strong></h3><h4><strong>3.1.1尝试重启node1的asm服务</strong></h4><pre><code class="sql"># 
root用户执行：
srvctl status asm 
srvctl stop asm 
srvctl start asm</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047443736" alt="image.png" title="image.png" loading="lazy"/></p><p>可以看到，asm服务正常运行，且无法停止。</p><h4><strong>3.1.2 重启node1 的集群服务</strong></h4><p>停止node1集群：（请选择在业务低峰期（23:00）执行如下操作），操作日志如下：</p><pre><code class="sql"># 
确认服务信息：
[root@testdb1 ~]# su - grid
testdb1:/home/grid(+ASM1)$asmcmd lsdg
Connected to an idle instance.
ASMCMD-8102: no connection to Oracle ASM; command requires Oracle ASM to run
testdb1:/home/grid(+ASM1)$srvctl status asm
ASM is running on testdb1,testdb2
# 
开始停止节点集群（使用root用户执行）：
testdb1:/home/grid(+ASM1)$exit
logout
[root@testdb1 ~]# cd /oracle/app/19.0.0/grid/bin/
[root@testdb1 bin]# ./crsctl stop crs -f
CRS-2791: Starting shutdown of Oracle High Availability Services-managed resources on 'testdb1'
CRS-2673: Attempting to stop 'ora.crsd' on 'testdb1'
CRS-2790: Starting shutdown of Cluster Ready Services-managed resources on server 'testdb1'
CRS-2673: Attempting to stop 'ora.dsg.dsg.acfs' on 'testdb1'
CRS-2673: Attempting to stop 'ora.chad' on 'testdb1'
CRS-2673: Attempting to stop 'ora.testdbstd.db' on 'testdb1'
Error unmounting '/dsg'. Possible busy file system. Verify the logs.
Retrying unmount
CRS-2677: Stop of 'ora.testdbstd.db' on 'testdb1' succeeded
CRS-33673: Attempting to stop resource group 'ora.asmgroup' on server 'testdb1'
CRS-2679: Attempting to clean 'ora.OCR_VOTE.dg' on 'testdb1'
CRS-2679: Attempting to clean 'ora.ARCHIVEDG.dg' on 'testdb1'
CRS-2679: Attempting to clean 'ora.DATADG1.dg' on 'testdb1'
CRS-2679: Attempting to clean 'ora.DATADG2.dg' on 'testdb1'
CRS-2679: Attempting to clean 'ora.DSG.dg' on 'testdb1'
CRS-2679: Attempting to clean 'ora.MGMT.dg' on 'testdb1'
CRS-2673: Attempting to stop 'ora.LISTENER.lsnr' on 'testdb1'
CRS-2673: Attempting to stop 'ora.LISTENER2.lsnr' on 'testdb1'
CRS-2673: Attempting to stop 'ora.LISTENER3.lsnr' on 'testdb1'
CRS-2673: Attempting to stop 'ora.LISTENER_DG.lsnr' on 'testdb1'
CRS-2677: Stop of 'ora.LISTENER.lsnr' on 'testdb1' succeeded
CRS-2677: Stop of 'ora.LISTENER2.lsnr' on 'testdb1' succeeded
CRS-2677: Stop of 'ora.LISTENER3.lsnr' on 'testdb1' succeeded
CRS-2677: Stop of 'ora.LISTENER_DG.lsnr' on 'testdb1' succeeded
CRS-2673: Attempting to stop 'ora.testdb1.vip' on 'testdb1'
CRS-5017: The resource action "ora.ARCHIVEDG.dg clean" encountered the following error: 
ORA-04031: unable to allocate 816 bytes of shared memory ("shared pool","unknown object","sga heap(1,0)","KGLHD")
. For details refer to "(:CLSN00106:)" in "/oracle/app/grid/diag/crs/testdb1/crs/trace/crsd_oraagent_grid.trc".
CRS-2677: Stop of 'ora.testdb1.vip' on 'testdb1' succeeded
CRS-5017: The resource action "ora.ARCHIVEDG.dg check" encountered the following error: 
ORA-04031: unable to allocate 816 bytes of shared memory ("shared pool","unknown object","sga heap(1,0)","KGLHD")
. For details refer to "(:CLSN00109:)" in "/oracle/app/grid/diag/crs/testdb1/crs/trace/crsd_oraagent_grid.trc".
CRS-2680: Clean of 'ora.ARCHIVEDG.dg' on 'testdb1' failed
CRS-5017: The resource action "ora.OCR_VOTE.dg clean" encountered the following error: 
ORA-04031: unable to allocate 5184 bytes of shared memory ("shared pool","unknown object","SO private sga","kss private so")
. For details refer to "(:CLSN00106:)" in "/oracle/app/grid/diag/crs/testdb1/crs/trace/crsd_oraagent_grid.trc".
CRS-5017: The resource action "ora.DSG.dg clean" encountered the following error: 
ORA-04031: unable to allocate 5184 bytes of shared memory ("shared pool","unknown object","SO private sga","kss private so")
. For details refer to "(:CLSN00106:)" in "/oracle/app/grid/diag/crs/testdb1/crs/trace/crsd_oraagent_grid.trc".
CRS-5017: The resource action "ora.DATADG2.dg clean" encountered the following error: 
ORA-04031: unable to allocate 5184 bytes of shared memory ("shared pool","unknown object","SO private sga","kss private so")
. For details refer to "(:CLSN00106:)" in "/oracle/app/grid/diag/crs/testdb1/crs/trace/crsd_oraagent_grid.trc".
CRS-5017: The resource action "ora.DATADG1.dg clean" encountered the following error: 
ORA-04031: unable to allocate 5184 bytes of shared memory ("shared pool","unknown object","SO private sga","kss private so")
. For details refer to "(:CLSN00106:)" in "/oracle/app/grid/diag/crs/testdb1/crs/trace/crsd_oraagent_grid.trc".
CRS-5017: The resource action "ora.MGMT.dg clean" encountered the following error: 
ORA-04031: unable to allocate 5184 bytes of shared memory ("shared pool","unknown object","SO private sga","kss private so")
. For details refer to "(:CLSN00106:)" in "/oracle/app/grid/diag/crs/testdb1/crs/trace/crsd_oraagent_grid.trc".
CRS-5017: The resource action "ora.MGMT.dg check" encountered the following error: 
ORA-04031: unable to allocate 816 bytes of shared memory ("shared pool","unknown object","sga heap(1,0)","KGLHD")
. For details refer to "(:CLSN00109:)" in "/oracle/app/grid/diag/crs/testdb1/crs/trace/crsd_oraagent_grid.trc".
CRS-2680: Clean of 'ora.MGMT.dg' on 'testdb1' failed
CRS-5017: The resource action "ora.DATADG2.dg check" encountered the following error: 
ORA-04031: unable to allocate 568 bytes of shared memory ("shared pool","unknown object","sga heap(1,0)","KKSSP")
. For details refer to "(:CLSN00109:)" in "/oracle/app/grid/diag/crs/testdb1/crs/trace/crsd_oraagent_grid.trc".
CRS-2680: Clean of 'ora.DATADG2.dg' on 'testdb1' failed
CRS-5017: The resource action "ora.DSG.dg check" encountered the following error: 
ORA-04031: unable to allocate 12312 bytes of shared memory ("shared pool","unknown object","KKSSP^28","kglseshtTable")
. For details refer to "(:CLSN00109:)" in "/oracle/app/grid/diag/crs/testdb1/crs/trace/crsd_oraagent_grid.trc".
CRS-2680: Clean of 'ora.DSG.dg' on 'testdb1' failed
CRS-5017: The resource action "ora.DATADG1.dg check" encountered the following error: 
ORA-04031: unable to allocate 12312 bytes of shared memory ("shared pool","unknown object","KKSSP^2346","kglseshtTable")
. For details refer to "(:CLSN00109:)" in "/oracle/app/grid/diag/crs/testdb1/crs/trace/crsd_oraagent_grid.trc".
CRS-2680: Clean of 'ora.DATADG1.dg' on 'testdb1' failed
CRS-5017: The resource action "ora.OCR_VOTE.dg check" encountered the following error: 
ORA-04031: unable to allocate 12312 bytes of shared memory ("shared pool","unknown object","KKSSP^803","kglseshtTable")
. For details refer to "(:CLSN00109:)" in "/oracle/app/grid/diag/crs/testdb1/crs/trace/crsd_oraagent_grid.trc".
CRS-2680: Clean of 'ora.OCR_VOTE.dg' on 'testdb1' failed
CRS-2675: Stop of 'ora.dsg.dsg.acfs' on 'testdb1' failed
CRS-2679: Attempting to clean 'ora.dsg.dsg.acfs' on 'testdb1'
CRS-2675: Stop of 'ora.chad' on 'testdb1' failed
CRS-2679: Attempting to clean 'ora.chad' on 'testdb1'
CRS-2681: Clean of 'ora.chad' on 'testdb1' succeeded
Error unmounting '/dsg'. Possible busy file system. Verify the logs.
CRS-2681: Clean of 'ora.dsg.dsg.acfs' on 'testdb1' succeeded
CRS-2673: Attempting to stop 'ora.DSG.DSG.advm' on 'testdb1'
CRS-2677: Stop of 'ora.DSG.DSG.advm' on 'testdb1' succeeded
CRS-2673: Attempting to stop 'ora.proxy_advm' on 'testdb1'
CRS-2677: Stop of 'ora.proxy_advm' on 'testdb1' succeeded
CRS-2672: Attempting to start 'ora.testdb1.vip' on 'testdb2'
CRS-2676: Start of 'ora.testdb1.vip' on 'testdb2' succeeded
CRS-2799: Failed to shut down resource 'ora.ASMNET1LSNR_ASM.lsnr' on 'testdb1'
CRS-2794: Shutdown of Cluster Ready Services-managed resources on 'testdb1' has failed
CRS-2675: Stop of 'ora.crsd' on 'testdb1' failed
CRS-2799: Failed to shut down resource 'ora.crsd' on 'testdb1'
CRS-2795: Shutdown of Oracle High Availability Services-managed resources on 'testdb1' has failed
CRS-4687: Shutdown command has completed with errors.
CRS-4000: Command Stop failed, or completed with errors.
[root@testdb1 bin]# 
// 由于 ASM实例下 shared_pool_size 不足，导致集群停止报错误：
# 
登录grid用户验证集群状态
[root@testdb1 bin]# su - grid 
Last login: Tue Sep  9 23:11:19 CST 2025
testdb1:/home/grid(+ASM1)$srvctl status asm
ASM is running on testdb2
testdb1:/home/grid(+ASM1)$   
#
　再次停止集群服务，这次已经能够正常停止（原因是第一次停止时部分服务停止成功，释放了共享内存）
[root@testdb1 bin]# ./crsctl stop crs -f
CRS-2791: Starting shutdown of Oracle High Availability Services-managed resources on 'testdb1'
CRS-2673: Attempting to stop 'ora.crsd' on 'testdb1'
CRS-2790: Starting shutdown of Cluster Ready Services-managed resources on server 'testdb1'
CRS-2792: Shutdown of Cluster Ready Services-managed resources on 'testdb1' has completed
CRS-2677: Stop of 'ora.crsd' on 'testdb1' succeeded
CRS-2673: Attempting to stop 'ora.asm' on 'testdb1'
CRS-2673: Attempting to stop 'ora.crf' on 'testdb1'
CRS-2673: Attempting to stop 'ora.drivers.acfs' on 'testdb1'
CRS-2673: Attempting to stop 'ora.mdnsd' on 'testdb1'
CRS-2677: Stop of 'ora.asm' on 'testdb1' succeeded
CRS-2677: Stop of 'ora.drivers.acfs' on 'testdb1' succeeded
CRS-2677: Stop of 'ora.crf' on 'testdb1' succeeded
CRS-2673: Attempting to stop 'ora.cluster_interconnect.haip' on 'testdb1'
CRS-2677: Stop of 'ora.mdnsd' on 'testdb1' succeeded
CRS-2677: Stop of 'ora.cluster_interconnect.haip' on 'testdb1' succeeded
CRS-2673: Attempting to stop 'ora.ctssd' on 'testdb1'
CRS-2673: Attempting to stop 'ora.evmd' on 'testdb1'
CRS-2677: Stop of 'ora.ctssd' on 'testdb1' succeeded
CRS-2677: Stop of 'ora.evmd' on 'testdb1' succeeded
CRS-2673: Attempting to stop 'ora.cssd' on 'testdb1'
CRS-2677: Stop of 'ora.cssd' on 'testdb1' succeeded
CRS-2673: Attempting to stop 'ora.gipcd' on 'testdb1'
CRS-2673: Attempting to stop 'ora.gpnpd' on 'testdb1'
CRS-2677: Stop of 'ora.gipcd' on 'testdb1' succeeded
CRS-2677: Stop of 'ora.gpnpd' on 'testdb1' succeeded
CRS-2793: Shutdown of Oracle High Availability Services-managed resources on 'testdb1' has completed
CRS-4133: Oracle High Availability Services has been stopped.
[root@testdb1 bin]# </code></pre><p>验证asm服务状态：  </p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047443737" alt="image.png" title="image.png" loading="lazy"/></p><p>检查集群状态：  </p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047443738" alt="image.png" title="image.png" loading="lazy"/></p><p>启动集群：  </p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047443739" alt="image.png" title="image.png" loading="lazy"/></p><p>再次检查集群状态，确保每个服务处于online状态：  </p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047443740" alt="image.png" title="image.png" loading="lazy"/></p><p>检查监听，确保ASM和数据库实例均正常注册到监听：  </p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047443741" alt="image.png" title="image.png" loading="lazy"/></p><p>验证asm状态：  </p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047443742" alt="image.png" title="image.png" loading="lazy"/></p><p>登录数据库，检查磁盘组信息：  </p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047443743" alt="image.png" title="image.png" loading="lazy"/></p><p>检查ADG数据同步状态：</p><p>此时可以看到，数据开始同步，且目前数据传输延迟1小时53分钟，数据重放延迟15小时25分钟。  </p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047443744" alt="image.png" title="image.png" loading="lazy"/>  </p><p>0.png)此时数据同步完成，数据仍在重放中：  </p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047443745" alt="image.png" title="image.png" loading="lazy"/></p><p>此时数据已经同步、重放均已经完成  </p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047443746" alt="image.png" title="image.png" loading="lazy"/></p><p>创建临时表，测试数据复制：</p><p>主节点创建表，并写入数据后提交：  </p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047443747" alt="image.png" title="image.png" loading="lazy"/></p><p>备库进行查询：  </p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047443748" alt="image.png" title="image.png" loading="lazy"/></p><h2><strong>四、总结</strong></h2><p><strong>此次故障为备机node1节点ASM实例中 shared\_pool\_size 共享池内存不足导致磁盘组异常，无法调用，ADG数据同步异常则是，ADG认证的密码文件存储在磁盘组中，备节点磁盘组丢失，导致认证错误，错误日志如下：</strong>  </p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047443749" alt="image.png" title="image.png" loading="lazy"/></p><p>需要解决asm实例下共享内存不足的问题，否则后期还可能出现同样的错误。</p><p>查看当前的share内存配置：  </p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047443750" alt="image.png" title="image.png" loading="lazy"/></p><p>建议增加 shared\_pool\_size 的值到2G，无需重启实例。</p><pre><code class="sql">SQL&gt; alter system set shared_pool_size = 2048M scope=both;</code></pre><hr/><p><img referrerpolicy="no-referrer" src="/img/remote/1460000046208374" alt="" title="" loading="lazy"/>  </p><p>墨天轮从乐知乐享的数据库技术社区蓄势出发，全面升级，提供多类型数据库管理服务。墨天轮数据库管理服务旨在为用户构建信赖可托付的数据库环境，并为数据库厂商提供中立的生态支持。<br/>墨天轮数据库服务官网：<a href="https://link.segmentfault.com/?enc=QwrsqikZgzwXD7ba2VUh5Q%3D%3D.zuk8go395EEuO5VnqDKqUra%2Be0X3fQiOs3WzEvdpMeG2tfHbIxR1hHE1IJrVFxjT" rel="nofollow" target="_blank">https://www.modb.pro/service</a></p>]]></description></item><item>    <title><![CDATA[harmonyos 大屏设备怎么弹出 u]]></title>    <link>https://segmentfault.com/a/1190000047443786</link>    <guid>https://segmentfault.com/a/1190000047443786</guid>    <pubDate>2025-12-02 16:12:43</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在 <strong>HarmonyOS 大屏设备</strong>（智慧屏、鸿蒙电视等）上，系统并没有像 Windows 那样的“安全弹出”按钮，<strong>官方推荐的“弹出”方式</strong>是：</p><hr/><h3>✅ 正常用户操作（无 Root、无调试）</h3><ol><li><strong>退出所有正在使用 U 盘的应用</strong><br/>（如媒体中心、文件管理器、视频播放器等）。</li><li>返回桌面或主界面，<strong>等待 2~3 秒</strong>，系统会自动卸载 U 盘。</li><li>当看到提示 <strong>“USB 存储设备已移除”</strong> 或指示灯不再闪烁时，<strong>直接拔出 U 盘</strong> 即可 。</li></ol><hr/><h3>✅ 图形界面安全移除（部分 HarmonyOS 3.1+ 大屏）</h3><ol><li>进入 <strong>“全部应用” → 媒体中心 → U 盘</strong>。</li><li>按遥控器 <strong>菜单键（⋮）</strong>，选择 <strong>“安全移除”</strong>。</li><li>屏幕提示 <strong>“USB 存储设备已被移除”</strong> 后，即可拔出 U 盘 。</li></ol><hr/><h3>✅ 手机/平板端（如接的是鸿蒙平板）</h3><ol><li>打开 <strong>文件管理 App</strong> → <strong>浏览页</strong> → <strong>位置</strong> 中找到 U 盘。</li><li><strong>长按 U 盘图标</strong> → 弹出菜单中选择 <strong>“移除”</strong> 。</li></ol><hr/><h3>⚠️ 注意事项</h3><ul><li><strong>不要正在播放视频或传输文件时拔盘</strong>，否则可能提示“设备正在使用”或损坏 U 盘 。</li><li>若系统没有“移除”按钮，<strong>退出应用后直接拔盘是官方认可的安全方式</strong> 。</li></ul><hr/><p>一句话总结<br/><strong>鸿蒙大屏没有“弹出”图标，退出媒体应用后等提示“USB已移除”即可拔盘；有菜单键的设备可在媒体中心里点“安全移除”</strong> 。</p>]]></description></item><item>    <title><![CDATA[DORA2025：基于七类团队画像的 A]]></title>    <link>https://segmentfault.com/a/1190000047443818</link>    <guid>https://segmentfault.com/a/1190000047443818</guid>    <pubDate>2025-12-02 16:11:47</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <blockquote>在前一篇文章中，我们从 DORA 2025 报告的整体视角，梳理了 AI 研发效能的现状与挑战。这一篇，我们将深入分析报告中提出的“七类团队画像”，通过团队画像诊断帮助中高层管理者与 PMO 精准识别团队在 AI 引入过程中的优劣势，为进一步制定符合团队实际情况的 AI 研发效能提升路径提供理论支持和实践指南。<br/>本文聚焦关键词：DORA 2025 报告、AI 辅助开发、AI 研发效能、软件研发效能、团队画像分析、数字化转型。</blockquote><h2>七类团队画像的背景与意义</h2><p>作为 2025 年 DORA 报告中的一大亮点，七类团队画像为我们提供了一个清晰的组织分层框架，帮助管理者识别团队在 AI 研发效能方面的现状，并为后续的战略制定和执行提供数据支持。报告根据以下几个关键维度，对研发团队进行了细致的划分：</p><ul><li>交付吞吐量：团队完成任务的速度与频率；</li><li>软件交付稳定性：变更的失败率、恢复时间等；</li><li>团队效能：团队成员的工作效率和协作能力；</li><li>产品效能：最终交付的产品质量与市场表现；</li><li>工作摩擦与职业倦怠：团队内外的协作阻力与员工的工作疲劳感。</li></ul><p>通过这五个维度，DORA 将团队划分为七个类别，每个类别的团队都面临不同的挑战与机遇。</p><h4>为什么要关注“团队画像”？</h4><p>DORA 2025 报告告诉我们，AI 并不是对所有团队都能产生相同的效果。不同团队的成熟度、基础设施、文化氛围以及交付模式，决定了它们对 AI 的需求、采纳速度与效果。例如：</p><ul><li>对于已经有高效交付模式的团队，AI 可以充当“放大器”，加速其研发效能；</li><li>对于基础设施不健全或流程混乱的团队，AI 的引入可能会放大已有的低效，甚至增加额外的不稳定性。</li></ul><p>因此，了解自己团队的画像，才能在 AI 研发效能的提升过程中，做出最合适的决策和行动。</p><h2>七类团队画像分析：AI 研发效能提升的不同路径</h2><p>DORA 2025 根据研发效能的不同维度，把团队划分为七类，分别是：</p><h4>1. 基础性挑战型团队（Cluster 1）</h4><p><strong>特征：</strong></p><ul><li>吞吐量低，交付不稳定；</li><li>团队效能差，工作摩擦大，职业倦怠感高。</li></ul><p>这些团队的共同点是存在严重的流程与组织瓶颈，AI 的引入并不会立刻带来显著的效能提升。相反，可能会暴露更多流程和基础设施上的问题。因此，对于此类团队，AI 的引入更多是一个“补短板”的过程，首先需要解决好基础设施、自动化测试、版本控制等问题。</p><p><strong>管理建议：</strong></p><ul><li>先优化基础设施：在尝试引入 AI 工具之前，确保团队有高效的自动化流水线、清晰的任务分配与追踪机制。</li><li>小步试水，逐步引入 AI：从简单的任务自动化和辅助工具开始，不要立刻全面推开 AI，而是通过逐步优化实现从“痛点解决”到“效能提升”的转变。</li></ul><h4>2. 遗留瓶颈型团队（Cluster 2）</h4><p><strong>特征：</strong></p><ul><li>吞吐量稍低，交付稳定性稍差；</li><li>团队效能有一定问题，工作摩擦较多。</li></ul><p>这些团队通常已经在某些方面具备了较为成熟的开发模式，但在某些环节（如测试、发布、跨团队协作）仍存在瓶颈。AI 可以帮助其进一步优化流程，但同样要谨慎引入，避免过度依赖工具而忽视系统基础的改善。</p><p><strong>管理建议：</strong></p><ul><li>识别并优化瓶颈：首先识别哪些环节是制约团队效能的瓶颈，特别是跨团队的协作和沟通问题。</li><li>AI 辅助决策与协作：可以考虑引入 AI 助手来帮助团队更高效地管理任务、规划进度，尤其是在跨部门协作和知识共享方面。</li></ul><h4>3. 流程受限型团队（Cluster 3）</h4><p><strong>特征：</strong></p><ul><li>吞吐量和稳定性有些问题；</li><li>团队效能一般，工作摩擦和协作难度较大。</li></ul><p>这些团队的挑战通常来自于流程不顺畅、缺乏透明度，并且在决策时可能存在较多等待时间或反复讨论。AI 的引入对这类团队非常有帮助，特别是在自动化任务、预测进度和减少重复劳动等方面。</p><p><strong>管理建议：</strong></p><p>通过 AI 提高流程透明度：利用 AI 工具优化团队内部的任务跟踪、进度预测、风险评估等，提升流程的透明度和决策的效率。<br/>缩短决策周期：借助 AI 实现快速的数据分析和预测，帮助团队做出及时决策，减少因反复讨论带来的浪费。</p><h4>4. 稳健有序型团队（Cluster 4）</h4><p><strong>特征：</strong></p><ul><li>吞吐量较高，交付稳定；</li><li>团队效能较高，但仍存在改进空间。</li></ul><p>这类团队的核心问题是虽然效能已经较高，但仍未能做到最佳实践，尤其是在协作和跨部门沟通方面可能存在一定的改进空间。AI 可以帮助其进一步提升效率和交付质量。</p><p><strong>管理建议：</strong></p><ul><li>继续优化协作流程：借助 AI 工具进一步加强团队内外的协作与沟通，尤其是跨部门合作。</li><li>利用 AI 进行持续优化：这类团队已经有较为成熟的流程，AI 的引入更多是对现有流程的微调和优化，帮助团队达到“持续改进”的目标。</li></ul><h4>5. 务实执行者型团队（Cluster 5）</h4><p><strong>特征：</strong></p><ul><li>吞吐量较高，交付较为稳定；</li><li>团队效能较好，但尚未达到高效的水平。</li></ul><p>这些团队通常具备稳定的开发节奏和高效的任务管理，但可能由于资源或其他因素未能进一步突破。AI 在帮助提升执行效率、减少重复工作方面具有很大的潜力。</p><p><strong>管理建议：</strong></p><p>利用 AI 提升团队自主性：通过 AI 辅助工具提升团队成员的自主性，减少中间管理层的干预，使团队能够更加灵活地应对变化。<br/>优化任务分配与工作流：借助 AI 技术进一步优化任务分配、进度追踪和反馈机制，帮助团队更高效地完成任务。</p><h4>6. 和谐高成就者型团队（Cluster 6）</h4><p><strong>特征：</strong></p><ul><li>吞吐量高，交付非常稳定；</li><li>团队效能和产品效能都达到非常高的水平。</li></ul><p>这些团队是典型的“高效能型”团队，已经具备了成熟的开发流程和高效的协作机制。AI 的引入可以进一步加速创新和提升团队效率，使其在行业中保持领先地位。</p><p><strong>管理建议：</strong></p><p>利用 AI 进行创新驱动：这类团队可以尝试引入更为复杂的 AI 工具，例如在产品设计和需求分析环节使用 AI 生成和优化方案。<br/>进一步提高自动化水平：加速自动化测试、发布和运维，提高系统的稳定性与可维护性。</p><h4>7. 和谐高成就者型团队（Cluster 7）</h4><p><strong>特征：</strong></p><ul><li>吞吐量和稳定性都表现极好；</li><li>团队效能非常高，产品效能达到卓越水平。</li></ul><p>这是典型的“顶尖团队”，其开发和交付已经达到了行业顶尖水平。AI 的引入将进一步增强其研发效能，并可能带来更大的产品创新和市场竞争力。</p><p><strong>管理建议：</strong></p><ul><li>加速 AI 驱动的创新：继续扩展 AI 在研发中的应用，尤其是 AI 驱动的产品创新和数据分析。</li><li>维持高度的技术成熟度与灵活性：保持团队的敏捷性和创新性，同时借助 AI 持续优化开发和交付流程。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047443820" alt="七类团队原型的效能水平" title="七类团队原型的效能水平"/></p><p>七类团队原型的效能水平（图源：QECon）</p><h2>如何基于团队画像制定 AI 研发效能提升路径</h2><h4>1. 评估团队画像：你属于哪一类？</h4><p>根据 DORA 2025 报告的团队画像划分方法，首先需要评估自己团队的现状。通过分析以下维度，你可以初步判断团队所属的画像类型：</p><ul><li>交付吞吐量：你团队的任务完成速度如何？</li><li>软件交付稳定性：你的团队在处理变更时，是否经常出现失败或需要长时间恢复？</li><li>团队效能：团队成员之间的协作效率如何？</li><li>产品效能：交付的产品质量和市场表现如何？</li><li>工作摩擦与倦怠：团队的沟通效率和工作负担如何？</li></ul><h4>2. 制定 AI 实施路径</h4><p>根据你团队所属的画像，可以采用以下方法来制定 AI 实施路径：</p><ul><li>基础性挑战型团队：首先要解决流程瓶颈和团队协作问题，逐步引入 AI，优先解决文档、代码生成等低风险环节。</li><li>稳健有序型团队：继续优化协作与任务分配，利用 AI 提高研发和交付效率。</li><li>和谐高成就者型团队：重点关注 AI 驱动的创新和复杂问题的解决，提升产品效能和市场竞争力。</li></ul><p><strong>本节小结： 通过对 DORA 2025 七类团队画像的了解和诊断，管理者可以根据团队现状，定制化 AI 实施策略，避免一刀切，确保 AI 研发效能的提升切实落地。</strong></p><h2>结语：从 AI 研发效能到全局转型</h2><p>通过对 DORA 2025 团队画像的深度剖析，我们不难发现，AI 的引入不仅仅是工具层面的优化，更是组织结构、团队文化、研发流程等多个维度的系统性提升。无论你的团队目前处于哪个阶段，最关键的是：根据团队画像选择适合的 AI 战略，并根据团队特征逐步推动 AI 研发效能的提升。</p><p>在下一篇文章中，我将进一步探讨如何基于 AI 研发效能模型与团队画像，结合本土企业的实践经验，设计出一个更具针对性的AI 研发效能诊断框架，帮助企业在数字化转型中更有效地利用 AI。</p><p>敬请期待：《DORA 2025：基于 AI 研发效能模型的团队画像诊断与实践》</p>]]></description></item><item>    <title><![CDATA[智慧园区运营新范式：如何用数字孪生技术破]]></title>    <link>https://segmentfault.com/a/1190000047443823</link>    <guid>https://segmentfault.com/a/1190000047443823</guid>    <pubDate>2025-12-02 16:11:12</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在智慧园区建设的浪潮中，运营管理者们正面临一个普遍困境：数据分散在烟囱式的子系统里，设备状态难以实时掌控，应急响应依赖人工经验，而宏观的运营态势更是“雾里看花”。如何打破这些壁垒，构建一个能“看得见、管得住、想得明”的智慧运营大脑，已成为行业升级的关键。<br/>今天，我们探讨的并非某个单一产品，而是一套能够为大型系统集成商伙伴赋能的数字孪生智能运营中心（IOC）解决方案理念—孪易IOC。它旨在帮助集成商为客户交付一个真正融合数据、场景与业务的“三维可视化指挥中枢”，从而在智慧园区项目中创造显著差异价值。</p><h2>一、 告别数据孤岛：让园区数据“活”起来</h2><p>园区的运营数据来源繁杂：安防摄像头的视频流、楼宇自控系统的传感器读数、能耗监测平台的用电数据、停车管理系统的车位信息、甚至访客系统的预约记录……这些数据往往格式不一、协议各异，沉睡在各个独立的后台。<br/><strong>核心价值点</strong>：对集成商而言，一套优秀的解决方案应具备强大的多源异构数据融合能力。它能够通过标准物联网协议（如MQTT）、数据库接口、API等多种方式，将上述分散的数据近乎实时地汇聚到一个统一的平台上。这意味着，您为客户构建的不再是一个个信息孤岛，而是一个数据联动的有机整体。例如，当消防传感器告警时，系统可自动调取周边摄像头画面、关闭相关区域的电动门、并在地图上高亮显示疏散路径，实现跨系统的联动响应。</p><h2>二、 掌控全局细节：从宏观园区到微观设备的一体化操控</h2><p>传统管理平台要么只能看二维地图，要么只能看视频监控，缺乏空间纵深感。管理人员无法快速在广阔的园区中定位一个具体设备，也无法直观了解建筑内部的实时状况。<br/><strong>核心价值点</strong>：基于数字孪生技术，解决方案应提供精细化三维场景管理。集成商可以协助客户在平台上1:1复刻整个园区，支持从园区总览无缝下钻到单体建筑，甚至剖开楼宇查看内部管线与设备布局。更重要的是，场景中的每一个设备、设施、车辆都作为可查询、可定位、可交互的“孪生体”存在。运维人员只需搜索设备编号，即可在三维场景中快速定位，并查看其全量实时数据与历史状态，极大提升了巡检与故障排查效率。<br/><img width="640" height="360" referrerpolicy="no-referrer" src="/img/bVdmP6B" alt="" title=""/></p><h2>三、 从被动响应到主动预警：构建智能化分析决策能力</h2><p>运营管理的最高境界是预见性。但传统方式下，告警依赖各子系统阈值，规则简单且孤立，难以发现复杂关联风险。对于能耗优化、空间利用率等业务分析，更需要手动从多个报表中提取数据，费时费力。<br/><strong>核心价值点</strong>：解决方案应内置可配置的智能分析告警引擎。集成商可以根据客户的业务逻辑，帮助其自定义复杂的告警规则。例如，并非简单的“温度过高”，而是“会议室温度高于28℃且室内有人停留超过30分钟”才触发空调优化告警。同时，平台应支持围绕“能效管理”、“安防态势”、“设施健康”等主题，自由组合相关数据、图表与孪生体，形成专属的业务分析主题看板。这让管理者不仅能看见“发生了什么”，更能分析“为什么发生”以及“趋势如何”，为资源调配、节能降耗、预防性维护提供直接的数据洞察。<br/><img width="640" height="360" referrerpolicy="no-referrer" src="/img/bVdmRb8" alt="" title="" loading="lazy"/></p><h2>四、 加速交付与深度定制：赋能集成商的“双引擎”</h2><p>对于集成商，项目交付速度和满足客户个性化需求的能力同样重要。从零开始搭建这样的平台耗时漫长，且每次面对不同行业客户都需要重复开发。<br/><strong>核心价值点</strong>：理想的解决方案应提供丰富的行业模板与灵活的配置后台。针对智慧园区，它可能预置了常见的资产模型（如空调机组、电梯、充电桩）、业务分析模板（如物业运维、绿色节能）以及对应的三维模型库。集成商项目团队可以基于这些素材快速组装出符合客户初步需求的演示原型，大幅缩短POC周期。同时，通过强大的“所见即所得”后台管理工具，大部分场景搭建、对象绑定、规则配置工作无需编码即可完成，使得项目交付和后续的客户自主调整都变得高效便捷。</p><h2>五、 面向未来的架构：保障投资的长效价值</h2><p>客户的需求在不断变化，技术也在持续演进。一个封闭、僵化的系统很快会被淘汰。<br/><strong>核心价值点</strong>：因此，解决方案的架构灵活性与可扩展性至关重要。它应支持从公有云SaaS到本地化私有部署的多种模式，满足不同客户对数据安全与合规性的要求。更为关键的是，它需要为集成商提供完整的扩展开发工具链。当客户提出高度定制化的需求时，您的开发团队能够基于平台的SDK和API进行深度二次开发，或将其与客户已有的ERP、BIM等系统深度融合。这保障了您交付的项目能够伴随客户业务共同成长，从而建立长期、稳固的合作关系。</p><h2>结语</h2><p>智慧园区的运营升级，本质上是数据价值、空间管理与业务智慧的深度融合。对于致力于在此领域深耕的系统集成商而言，选择一套具备强大数据整合、精细场景操控、智能分析预警、快速行业适配及开放可扩展架构的数字孪生IOC解决方案作为技术基座，意味着您能为客户交付的不仅是软硬件，更是一套可持续进化的“运营智慧”。<br/>这不仅能显著提升您在项目竞标中的技术说服力与方案溢价能力，更能通过打造标杆案例，树立您在智慧城市细分领域的专业品牌形象。<br/><img width="640" height="360" referrerpolicy="no-referrer" src="/img/bVdmP6A" alt="" title="" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[告别“建模地狱”，我用“图观”引擎为数据]]></title>    <link>https://segmentfault.com/a/1190000047443869</link>    <guid>https://segmentfault.com/a/1190000047443869</guid>    <pubDate>2025-12-02 16:10:11</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>作为一名数字孪生应用开发者，我常常在“效果”与“效率”之间挣扎。客户想要电影级的可视化，却只给游戏级的预算和时间。尤其是在数据中心运维这种专业领域，复杂的管线、密布的机柜、海量的实时数据，传统开发路径就像一场噩梦。但最近一个项目的成功，让我找到了一条新路——“图观”数字孪生开发平台，它让我真正体会到了什么叫“专业工具带来的降维打击”。</p><h2>当紧急需求遇上现实瓶颈</h2><p>客户的需求很明确：一个能直观展示数据中心整体布局、实时监控设备状态、并能模拟故障影响与应急预案的<strong>三维智能运维平台</strong>。时间窗口只有六周。<br/>摆在面前的现实是：<br/><strong>场景是硬骨头</strong>：机房内部结构专业且复杂，从外部建筑到内部精密空调、冷热通道，靠手工建模周期太长，外包成本又难以承受。<br/><strong>数据是毛线团</strong>：动环数据、资产信息、能耗指标、网络拓扑……这些数据来自不同系统，格式各异，如何让它们在三维场景里“对号入座”并联动起来？<br/><strong>体验要分场景</strong>：领导要在指挥中心大屏上看高清总览，运维工程师需要在工位电脑上快速定位细节，一套方案如何兼顾？<br/><strong>未来要能生长</strong>：客户希望平台能随着机房扩容、设备更新而灵活迭代，而不是每变一次就重写一次代码。<br/>压力山大。但“图观”平台提供的组合拳，让我们看到了破局的希望。</p><h2>破局实战：图观平台的三板斧</h2><p><strong>第一板斧：用“搭积木”的方式，快速构建专业级场景</strong><br/>过去，构建一个逼真的数据中心三维场景，意味着建模师要在3ds Max或Blender里奋战数周。而“图观”的<strong>端渲染场景编辑器</strong>改变了游戏规则。<br/>我们直接利用平台内置的丰富<strong>模型库</strong>，快速拖拽出标准机柜、服务器、空调机组、UPS等设备。对于客户特有的精密空调和布线样式，我们通过简单的PBR材质编辑，调整金属度、粗糙度，就实现了高度拟真的外观。<br/>最惊艳的是<strong>数据驱动</strong>能力。我们不再需要为每一台服务器的“开机、故障、离线”状态制作三个独立的动画模型。相反，我们在编辑器里为服务器模型定义了几个关键“关节”（如状态指示灯、风扇）。之后，只需将动环系统提供的实时状态数据（如“0-正常，1-警告，2-故障”）与这些关节绑定。数据一变，模型上对应的指示灯颜色、风扇转速就自动变化。这让我们在几天内就完成了整个数据中心成百上千台设备的动态效果配置，效率提升惊人。<br/><img width="587" height="330" referrerpolicy="no-referrer" src="/img/bVdmqxd" alt="" title=""/><br/><strong>第二板斧：零代码拼出“可操作”的运维应用</strong><br/>场景建好了，如何把它变成一个运维人员能用的工具？传统方式需要前端工程师写大量代码来集成三维场景和二维图表。但在图观，我们的产品经理几乎独立完成了应用界面的搭建。<br/>通过零代码应用编辑器，他像制作PPT一样，拖拽各种图表组件（如实时能耗曲线、机柜温度分布热力图）、列表控件和按钮，并轻松嵌入了我们刚刚发布的数据中心三维场景服务。<br/>更强大的是<strong>交互配置</strong>。他通过简单的配置，就实现了：<br/><strong>1.点击图表，高亮场景</strong>：点击“北区机房能耗TOP5”柱状图的某一项，三维场景中对应的机房区域自动高亮。<br/><strong>2.筛选场景，联动图表</strong>：在三维场景中框选一批机柜，右侧的“选中设备资产列表”和“实时负载曲线”立即刷新，只显示这批设备的信息。<br/><strong>3.一键预案模拟</strong>：配置一个“模拟空调故障”的按钮，点击后，三维场景中对应空调模型变红报警，关联的冷通道温度图层开始升温变色，系统自动弹出应急预案步骤。<br/>这一切，没有写一行业务逻辑代码。这让业务人员深度参与到了应用开发中，确保最终产品真正贴合运维实际。<br/><img width="587" height="286" referrerpolicy="no-referrer" src="/img/bVdmtcO" alt="" title="" loading="lazy"/><br/><strong>第三板斧：一套代码，无缝适配大屏与桌面</strong><br/>这是“图观”给我们带来的最大惊喜，也是其核心技术壁垒。客户需要大屏的超高清画质和桌面端的流畅交互，按照传统方式，我们可能需要为流渲染（云渲染）和端渲染分别开发两套前端。<br/>但图观提供了统一的JavaScript API。我们只用一套代码进行业务开发，然后通过一个简单的配置切换，就实现了：<br/>指挥中心大屏：启用流渲染模式。所有复杂的图形计算在服务器GPU集群完成，将电影级画质的画面流式推送到大屏，确保超高清、无卡顿的震撼视觉效果。<br/>运维工程师桌面：启用端渲染模式。利用工程师电脑本地的显卡进行计算渲染，响应速度快，交互零延迟，并且大量并发访问也不会给中心服务器带来压力。<br/>这种“一套代码，双核驱动”的能力，让我们完美平衡了效果与成本，客户对未来服务器扩容的成本担忧也烟消云散。</p><h2>成果与价值：不止于“看得见”</h2><p>六周后，平台成功上线。它带来的价值远超一个“三维看板”：<br/><strong>1.运维效率提升</strong>：故障定位时间从平均半小时缩短到一分钟内。新员工通过三维场景能快速熟悉复杂的基础设施布局。<br/><strong>2.管理决策有据</strong>：能效热力图让高耗电“热点”一目了然，为绿色节能改造提供了精准依据。<br/><strong>3.安全演练无损</strong>：在数字世界模拟各种故障和应急流程，无需中断实际业务，大大提升了应急响应能力。<br/><strong>4.总拥有成本降低</strong>：快速构建与灵活开发节省了大量初期投入，“双模渲染”架构则优化了长期运营的IT资源成本。<br/><img width="640" height="360" referrerpolicy="no-referrer" src="/img/bVdm7Rl" alt="" title="" loading="lazy"/></p><h2>结语</h2><p>经历过这个项目，我深刻感受到，数字孪生开发的未来，一定属于那些能极大降低技术门槛，却不牺牲专业深度的平台。图观正是如此。它把我们从重复、繁重的底层图形编码中解放出来，让我们能更专注于业务逻辑的创新与数据价值的挖掘。<br/>如果你也正在面对数字化转型项目中，效果、效率与成本难以平衡的困局，特别是在智慧园区、工业制造、能源电力等复杂场景，我强烈建议你亲自体验一下“图观”引擎。</p>]]></description></item><item>    <title><![CDATA[《独立开发者精选工具》第 023 期 沉]]></title>    <link>https://segmentfault.com/a/1190000047443873</link>    <guid>https://segmentfault.com/a/1190000047443873</guid>    <pubDate>2025-12-02 16:09:18</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><a href="https://link.segmentfault.com/?enc=Mmxia0AQ0gCtyCm5kMnhsQ%3D%3D.QJxeX39dpXF9VzcXTebIaGK86Ij9mMa5PmyNn1X72ss%3D" rel="nofollow" target="_blank"><img referrerpolicy="no-referrer" src="/img/remote/1460000046409339" alt="" title=""/></a></p><p>Indie Tools 是一个收录独立开发、AI 出海领域最新、最实用的免费工具与资源工具站。让你快速找到所需，专注于创造产品。</p><p>独立开发者必备网站：<a href="https://link.segmentfault.com/?enc=%2FYLUa0zdc5KrbIE7PjHBrg%3D%3D.1j0964P3EE%2B1IZXjRxVqCr%2Ba3ZHgS7CfelBhta0%2BHJ4%3D" rel="nofollow" target="_blank"><code>https://www.indietools.work</code></a></p><p>Github: <a href="https://link.segmentfault.com/?enc=07nI8o6%2BpdA%2BoeDOn%2Fek0Q%3D%3D.TxqXV%2Fay%2BgpkGg2z%2F80bKYAO95ykKeeL4TMdbv9r%2Fbs51ldKgWVe7mEBbiGW2Z5ZYE2DQdUCy8rHvNlA%2B5Syjg%3D%3D" rel="nofollow" target="_blank"><code>https://github.com/yaolifeng0629/Awesome-independent-tools</code></a></p><p>如果本文能给你提供启发和帮助，感谢各位小伙伴动动小手指，一键三连 (点赞、评论、转发)，给我一些支持和鼓励，谢谢。</p><h2>favicon-generator</h2><h3>总结</h3><p>免费在线 Favicon 生成工具，快速生成多设备图标。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047443875" alt="favicon-generator" title="favicon-generator" loading="lazy"/></p><p>链接: <code>https://www.indietools.work/product/favicon-generator</code></p><h3>特性</h3><ol><li>从图像自动生成多尺寸图标。</li><li>在线编辑器支持简单编辑和预览。</li><li>一键打包下载所有格式图标。</li><li>提供可直接嵌入的 HTML 代码。</li></ol><h3>使用场景</h3><ol><li>网站开发者快速创建 Favicon。</li><li>为移动应用或 PWA 生成应用图标。</li></ol><h3>缺点</h3><ol><li>高级编辑功能有限。</li><li>网站界面较陈旧。</li></ol><h2>WeClone</h2><h3>总结</h3><p>用聊天记录微调大模型，打造个性化数字分身。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047443876" alt="WeClone" title="WeClone" loading="lazy"/></p><p>链接: <code>https://www.indietools.work/product/weclone</code></p><h3>特性</h3><ol><li>用个人聊天记录微调模型，模仿用户语言风格。</li><li>将模型绑定到聊天机器人，实现实时互动。</li><li>提供数据处理到部署的完整工作流。</li></ol><h3>使用场景</h3><ol><li>创建个人数字分身与朋友互动。</li><li>为创作者构建虚拟形象与粉丝交流。</li><li>部署具有特定语言风格的社群助手。</li></ol><h3>缺点</h3><ol><li>数据隐私保护可能不足。</li><li>生成效果受限于基础模型能力。</li></ol><h2>Midjourney Sref</h2><h3>总结</h3><p>收录 4000+个 Midjourney 风格参考代码，快速复制艺术风格。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047443877" alt="Midjourney Sref" title="Midjourney Sref" loading="lazy"/></p><p>链接: <code>https://www.indietools.work/product/midjourney-sref</code></p><h3>特性</h3><ol><li>提供超 4000 个精选--sref 代码。</li><li>每个代码配有效果图预览。</li><li>界面简洁，易于搜索浏览。</li></ol><h3>使用场景</h3><ol><li>快速为作品寻找特定艺术风格。</li><li>参考不同风格激发创作灵感。</li></ol><h3>缺点</h3><ol><li>风格库庞大，新手选择困难。</li><li>功能单一，缺乏高级筛选。</li></ol><h2>awesome-chatgpt-prompts-zh</h2><h3>总结</h3><p>丰富的中文提示词库，提升 ChatGPT 对话质量。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047443878" alt="awesome-chatgpt-prompts-zh" title="awesome-chatgpt-prompts-zh" loading="lazy"/></p><p>链接: <code>https://www.indietools.work/product/awesome-chatgpt-prompts-zh</code></p><h3>特性</h3><ol><li>收录不同场景和角色的中文提示词模板。</li><li>内容持续更新，紧跟功能迭代。</li><li>提示词经测试，可直接复制使用。</li></ol><h3>使用场景</h3><ol><li>让 ChatGPT 扮演特定角色对话。</li><li>为创作者、学生提供提问灵感。</li></ol><h3>缺点</h3><ol><li>提示词质量参差不齐。</li><li>主要面向中文用户。</li></ol><h2>awesome-chatgpt-prompts</h2><h3>总结</h3><p>社区驱动的 ChatGPT 提示词库，提升与大模型的互动效率。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047443879" alt="awesome-chatgpt-prompts" title="awesome-chatgpt-prompts" loading="lazy"/></p><p>链接: <code>https://www.indietools.work/product/awesome-chatgpt-prompts</code></p><h3>特性</h3><ol><li>提供多样化角色扮演提示。</li><li>覆盖编程、写作、营销等领域。</li><li>社区持续更新，保持实用性。</li></ol><h3>使用场景</h3><ol><li>为创作者提供灵感和文案框架。</li><li>帮助开发者获取代码解决方案。</li><li>辅助学生进行学术写作。</li></ol><h3>缺点</h3><ol><li>提示词质量水平不一。</li><li>部分提示词需调整适配新模型。</li></ol><h2>minimaxi</h2><h3>总结</h3><p>高性价比国内文本转语音 API 平台，付费使用。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047443880" alt="minimaxi" title="minimaxi" loading="lazy"/></p><p>链接: <code>https://www.indietools.work/product/minimaxi</code></p><h3>特性</h3><ol><li>多种高自然度音色可选。</li><li>性价比高，适合预算有限用户。</li><li>API 稳定，方便集成。</li></ol><h3>使用场景</h3><ol><li>为视频、有声读物生成配音。</li><li>为智能助手提供语音交互。</li></ol><h3>缺点</h3><ol><li>需付费，不适合轻度用户。</li><li>国际化和多语言支持有限。</li></ol><h2>SnippAI</h2><h3>总结</h3><p>AI 截图工具，智能识别并处理屏幕内容。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047443881" alt="SnippAI" title="SnippAI" loading="lazy"/></p><p>链接: <code>https://www.indietools.work/product/snippai</code></p><h3>特性</h3><ol><li>智能识别截图中的文本、代码或图像。</li><li>AI 驱动的总结、解释和翻译功能。</li><li>一键截图获取 AI 分析结果。</li><li>支持代码片段解释和格式优化。</li></ol><h3>使用场景</h3><ol><li>快速提取和总结网页文章核心内容。</li><li>理解和解释代码片段功能。</li><li>辅助学生快速消化文献资料。</li><li>翻译截图中的外语文字。</li></ol><h3>缺点</h3><ol><li>处理复杂专业内容时可能不精确。</li><li>离线状态下功能受限。</li></ol><h3>往期回顾</h3><ul><li><a href="https://link.segmentfault.com/?enc=P0tc%2BlyUTIQcslWlLUB%2FTQ%3D%3D.lZ9Dar3jW%2BrU6%2B2Q%2Bc11LDQc7ts6EKCkUaB4EbDloWps2ya93m3LcZblODR1EJlNEAogZeoYzs4yqf9s1oo52g%3D%3D" rel="nofollow" target="_blank">《独立开发者精选工具》第 023 期（最新）</a> 🔥</li><li><a href="https://link.segmentfault.com/?enc=7kOuHNxoESr6vEIG3qWPZg%3D%3D.oiUczP9%2FMU6v05eIOpxHBQDpOFExFQ7fB%2BSDym2bsrUhxvO3sMnlB31ZfoS1xndytLOZRVGLCrqbA0mYYMhMLA%3D%3D" rel="nofollow" target="_blank">《独立开发者精选工具》第 022 期</a></li><li><a href="https://link.segmentfault.com/?enc=8yizW0gJkk%2B7QXuPXRTVPg%3D%3D.ADbcwTBNOaQIIhfFEbuZSpYQNhQu2cvlMVtGXWOTnLcvKS%2FiYzmjF2ZPdiCRbnRgtda7txu6gl9fkC2uRhBaiQ%3D%3D" rel="nofollow" target="_blank">《独立开发者精选工具》第 021 期</a></li><li><a href="https://link.segmentfault.com/?enc=RwEeDG1Ot9sLf%2Fcyr7%2BWCw%3D%3D.X6e9IeprGM44qqeKxUhZ4NXKhJbSLiz89EePxJSPkrfvajWkzw21LI2g9BEk6b8TwFrEnhR2yAdO75y3pdj%2B7A%3D%3D" rel="nofollow" target="_blank">《独立开发者精选工具》第 020 期</a></li><li><a href="https://link.segmentfault.com/?enc=Yx8TGYdzwvVUiIzrCXf8Lg%3D%3D.uPM72c2lAD5jlMqSeU4jDnE5PchdkuSxTzno%2BdNPvl4Hw%2Fgi0JYWmomnMmN7xQ0io3UXcktsuAOQCY8iCGhCMQ%3D%3D" rel="nofollow" target="_blank">《独立开发者精选工具》第 019 期</a></li><li><a href="https://link.segmentfault.com/?enc=10fOeizru3D4h5SoSYgQOg%3D%3D.gpJ3SEpQizc1FTMGcbpukH31l82MEwuw1DNLg28g8pNxRn8hG%2BiVKVYnu0OFmJC%2BzE8XvvsIZSOJiOacRs4SVw%3D%3D" rel="nofollow" target="_blank">《独立开发者精选工具》第 018 期</a></li><li><a href="https://link.segmentfault.com/?enc=3frnfjeW7g9m%2Fbz252eTdw%3D%3D.E7N6p6x9EGRnglcQHUXTH%2B8ISUqTH1iuI7ChorNpsSVh%2FmXwXq8Mk63Lpb9%2FUwNXt7CtOLSLpu%2F49Zx%2Bu9s2rw%3D%3D" rel="nofollow" target="_blank">《独立开发者精选工具》第 017 期</a></li><li><a href="https://link.segmentfault.com/?enc=L1JCwrj2pVosW88RLDLHYg%3D%3D.5LTPAIYUrhk1Bau0DieyebwZDyksT1XsKljNluucDVETN69aPBGFTCFQqrjX9fdbE9OKuyYrWdgLHALJrWaSJA%3D%3D" rel="nofollow" target="_blank">《独立开发者精选工具》第 016 期</a></li><li><a href="https://link.segmentfault.com/?enc=%2Fvj1DIMy5gLTtgdRyRLHzQ%3D%3D.NtDtiR4u3S9FfdmBYKYAEXlQt0mB3%2BYmFofMbptGNS1QFKTtz9Anxs4S%2FWKEpxPgneo%2BSQ%2BBw1Y82syFmuIpxA%3D%3D" rel="nofollow" target="_blank">《独立开发者精选工具》第 015 期</a></li><li><a href="https://link.segmentfault.com/?enc=2Eoc3%2F%2BD6ZyWwyppAbRNvg%3D%3D.JBMfXYx%2FTCbrmwcFAnZH9S3DXzREf96RTPB0zqtOEL0UzueQSkQqDGLAAT7xJRTg0ZTohwGdyxhRAaBRjV1pxQ%3D%3D" rel="nofollow" target="_blank">《独立开发者精选工具》第 014 期</a></li><li><a href="https://link.segmentfault.com/?enc=JxpI2kMlDQuphCfEEeA%2FcA%3D%3D.VcS7LpntKDKrqfA3NZ%2BlmabpNxem%2Fcxlimu2YqxENO7yKanzsRKAPiMD%2BBIUf%2Bvg2bteAidJUtil9a%2FKhKqp8g%3D%3D" rel="nofollow" target="_blank">《独立开发者精选工具》第 013 期</a></li><li><a href="https://link.segmentfault.com/?enc=qMbnjen%2FRP1DrBBCFCPWcg%3D%3D.CD2SumTzxXP9%2BAQPrtH3o0YBVdJvi4fZuND4ds%2FOiSPrdu7KGOtrbEFRdQawlnv7z%2FVzk2Lv6zKBTtPVOx643g%3D%3D" rel="nofollow" target="_blank">《独立开发者精选工具》第 012 期</a></li><li><a href="https://link.segmentfault.com/?enc=YF95fgwOSEuq9%2B6Md5FhkA%3D%3D.kiG7%2F6igk%2BKoZbtq1yE2kEDquv0XBh3R9UmqdPRHwOo9m0F%2Fs0B5WZY%2BpkJqh0RUiAuYwJ2k3Se06JjBKAz9CQ%3D%3D" rel="nofollow" target="_blank">《独立开发者精选工具》第 011 期</a></li><li><a href="https://link.segmentfault.com/?enc=w1sPPI9qqQtbTacu488BTw%3D%3D.rWPl14YIsbcVAxwqwIJRucsTkOewTSXT2uKIl3YA%2BxCOF2D185jDS2OAOETfodeA4XJ4iLIFJlMPftlaKna6RA%3D%3D" rel="nofollow" target="_blank">《独立开发者精选工具》第 010 期</a></li><li><a href="https://link.segmentfault.com/?enc=ObpQpM%2FmjuUln8ufYydQWQ%3D%3D.bXtCjW9U%2FjGFq5UorPZBqiWgNurnz4%2F5BzX%2BEuMbjqBN1FEKQNUytP8VtBPQk4MUnmdUg%2FfTFKcWHpHz1177pA%3D%3D" rel="nofollow" target="_blank">《独立开发者精选工具》第 009 期</a></li><li><a href="https://link.segmentfault.com/?enc=kpn2kOT%2BiH566aCMUq6GKw%3D%3D.POtkMzpVkU2T%2Fxtp9cxZ%2FsikJABK%2FmXiu%2BNdnsghpQ3eC2FVMy%2FhVd61gdo7ZFGugDWjV6oQPAvrVjHd8b96iQ%3D%3D" rel="nofollow" target="_blank">《独立开发者精选工具》第 008 期</a></li><li><a href="https://link.segmentfault.com/?enc=YO5iiFKahZjTKyk8KQSIoQ%3D%3D.JbEkWDH38RlCF94qPeAJL1K1IoPJJvATSnUFZ8g%2FrJse%2BbZ2xpQtffWGG6EJZ3BH5Vp49BDXrOTZyUhh%2BeSBWA%3D%3D" rel="nofollow" target="_blank">《独立开发者精选工具》第 007 期</a></li><li><a href="https://link.segmentfault.com/?enc=rSVSRtFQzreghDfS40T3Ww%3D%3D.P7shgAcTz8YJoC0ldI6M5CtIv4ZXs%2BHsb9%2Bvsn7WkJxMzpyq1rW1Su1uPaDZfDWGUqm%2BxoQEjBqHTSv8%2F1%2FMjg%3D%3D" rel="nofollow" target="_blank">《独立开发者精选工具》第 006 期</a></li><li><a href="https://link.segmentfault.com/?enc=nU24067PROCx%2F7iJrjzEqw%3D%3D.5rwlm7cArRrem1eS7N5HsVjr84LsQz8A8LLs%2F6p1EyVzz0o1nNFvsiMMr4I5kZZWGKPVC30U2Quljig3DojA3w%3D%3D" rel="nofollow" target="_blank">《独立开发者精选工具》第 005 期</a></li><li><a href="https://link.segmentfault.com/?enc=DOpWDI81%2F4ZWdpW77aU35g%3D%3D.OiV4J6GP5H8t6G0pCg6af0Bfx%2BqAyklDXozDycBc8Mq0BDhIvV7E4B2l6Otme9OveNsy4E7x8DmLhx4cIfAaxQ%3D%3D" rel="nofollow" target="_blank">《独立开发者精选工具》第 004 期</a></li><li><a href="https://link.segmentfault.com/?enc=%2F3gkMPfRegqGySCk3g0sKA%3D%3D.nuhrhFUazWRBfK53znylQ87VJQ3SvIUDXy9nSCKwKcP%2FBAQKqpnArANnszP3HDthtptfXJj9zflavkYH%2Ble1cg%3D%3D" rel="nofollow" target="_blank">《独立开发者精选工具》第 003 期</a></li><li><a href="https://link.segmentfault.com/?enc=tfbhQ%2Bc%2BFTglpywQE8Xhcw%3D%3D.mojVZ8TUkVZ8orQCcYnthgXvR2LITxf59P36xcSK4mSptTUgwKaVKyLgXIkbF2qjuq2B9k1DPpkwxXVmTi4UBg%3D%3D" rel="nofollow" target="_blank">《独立开发者精选工具》第 002 期</a></li><li><a href="https://link.segmentfault.com/?enc=g0PXbuJ4UdfYOf70Bg1bmQ%3D%3D.dZFjxQBwC%2FZKtXsmYxCh%2Fd4Bz%2FJsLjaC05v3rg1SptZbsJThc8ak0TbSEPCTLkKiofc2bFXS9BZ7u39WRRFymQ%3D%3D" rel="nofollow" target="_blank">《独立开发者精选工具》第 001 期</a></li></ul>]]></description></item><item>    <title><![CDATA[数字孪生：为国防航天打造“全域透明、智能]]></title>    <link>https://segmentfault.com/a/1190000047443905</link>    <guid>https://segmentfault.com/a/1190000047443905</guid>    <pubDate>2025-12-02 16:08:33</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在国防与航天领域，每一次任务的成功，都依赖于对复杂系统状态的精准掌握、对瞬息万变态势的即时洞察，以及对突发事件的协同高效处置。传统的指挥控制中心，往往面临信息分散、态势割裂、预案执行依赖人工经验等挑战。如今，一种融合了全场景映射、数据智能与业务闭环的“数字孪生智能运营中心—孪易IOC”技术，正在为这一高精尖领域带来深刻的变革。<br/>它并非简单的三维可视化，而是一个将物理装备、设施环境、人员组织与业务流程在数字世界中全要素、全生命周期复现与联动的“智慧大脑”。下面，让我们通过一个典型的应用构想，来揭示它如何重塑国防航天领域的运营与指挥模式。</p><h2>一、 从“平面图纸”到“透视全域”：构建可层层剖析的立体战场</h2><p>想象一下，您面对的不仅是一个基地或一艘航天器的外部模型，而是一个可以像进行“CT扫描”一样，逐层透视其内部每一处结构、每一条管线、每一台关键设备的全维度数字镜像。<br/><strong>1.场景剖分，洞察秋毫</strong>：无论是地下掩体、舰船舱室还是卫星内部构造，操作员均可通过层级穿透，瞬间定位到特定设备或区域。在装备维护或应急检修时，这种能力能快速厘清复杂空间关系，让隐蔽的问题无处遁形。<br/><strong>2.环境仿真与历史回放</strong>：系统可以模拟任何时间点的光照、天气，甚至将历史任务中的传感器数据、人员动线、设备运行参数在三维场景中“时光倒流”般重现。这对于任务复盘、事故分析、以及演练不同环境条件下的战术预案，提供了无可比拟的沉浸式分析工具。<br/><strong>3.专业的空间分析</strong>：基于高精度三维模型，可进行可视域分析（优化观测哨所或雷达部署）、通视分析（规划通信链路）、毁伤评估模拟等。决策从基于地图和经验的推断，升级为基于三维地理信息的量化、可视化科学研判。</p><h2>二、 从“信息孤岛”到“融合智能”：实现数据驱动的主动运维</h2><p>国防航天系统传感器众多、数据源异构、信息量巨大。数字孪生IOC的核心价值在于成为全域数据的融合枢纽与智能分析引擎。<br/><strong>1.海量数据无缝接入</strong>：系统能够轻松整合来自物联网传感器（温度、压力、振动）、业务数据库（装备档案、物资库存）、实时视频流以及各类API接口的数据，确保数字世界与物理实体状态同步。<br/><strong>2.对象化管理，一键掌控</strong>：将接入的每一组数据，与三维场景中的每一个“孪生体”（如战机、发射车、在岗人员）精确绑定。指挥员可以在地图上快速检索、定位任一实体，并实时查看其全维度状态信息。<br/><strong>3.智能告警与预测性维护</strong>：用户可以基于深厚的业务知识，自定义复杂的告警规则。系统能对全网数据进行7x24小时自动监测，一旦发现异常模式（如某型发动机参数偏离基线、特定区域出现未授权活动），立即进行分级告警、空间定位与趋势推演，变“事后处置”为“事前预警”和“事中干预”，极大提升装备完好率和任务可靠性。<br/><img width="640" height="360" referrerpolicy="no-referrer" src="/img/bVdmmM0" alt="" title=""/></p><h2>三、 从“纸面预案”到“动态推演”：赋能跨部门可视化协同指挥</h2><p>当突发事件来临，分秒必争。孪易IOC将静态的应急预案，升级为在统一时空基准下可执行、可监控、可调整的动态指挥沙盘。<br/><strong>1.应急处突可视化</strong>：一旦触发预案，事件位置、影响范围、波及的关键设施将在三维场景中直观呈现。系统自动关联并显示周边应急资源（抢修分队、备件仓库、医疗站）的实时位置与状态。<br/><strong>2.任务驱动的协同调度</strong>：指挥员可在三维地图上直接下达指令，规划行动路线，任务自动派发至相关单元。通过集成的通讯能力与任务监控看板，可实时跟踪各单元反馈、处置进度与资源消耗，实现跨军种、跨部门的扁平化、可视化协同。<br/><strong>3.预案数字化与模拟推演</strong>：将各类作战想定、保障预案数字化，并可在数字孪生环境中进行多次、低成本的模拟推演，优化决策流程和资源配比，提升实战条件下的处置效能与科学性。</p><h2>四、 从“定制开发”到“自主演进”：提供灵活可持续的技术底座</h2><p>国防航天业务独特且持续演进，系统必须具备高度的灵活性与扩展性。一个成熟的数字孪生IOC平台，应提供强大的配置化工具与开放架构。<br/><strong>1.强大的后台管理</strong>：管理员无需编程，即可通过配置工具管理三维场景、定义新的装备孪生体类别、设置数据绑定规则与告警逻辑，快速响应业务变化。<br/><strong>2.开放的扩展开发</strong>：平台提供丰富的API和开发工具链，支持通过“低代码”甚至“零代码”的方式，快速搭建专属的业务分析页面或集成特定功能。这确保了用户能够随着业务深化，自主或联合生态伙伴进行功能扩展与场景创新，有效保护长期投资。<br/><img width="640" height="314" referrerpolicy="no-referrer" src="/img/bVdmQxT" alt="" title="" loading="lazy"/></p><h2>结语：迈向决策优势的新台阶</h2><p>对于国防航天领域的决策者与运营者而言，数字孪生智能运营中心带来的，远不止于炫酷的可视化效果。它构建的是一个 “全域透明、数据融合、智能预判、协同高效” 的下一代指挥决策支持平台。它致力于将指挥员从繁杂的信息筛选和协调工作中解放出来，使其能够更专注于战略判断与决策本身，最终实现态势感知、指挥效率与任务成功率的全面跃升。</p>]]></description></item><item>    <title><![CDATA[【花朵识别系统】Python+Tenso]]></title>    <link>https://segmentfault.com/a/1190000047443912</link>    <guid>https://segmentfault.com/a/1190000047443912</guid>    <pubDate>2025-12-02 16:07:32</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>一、介绍</h2><p>花朵识别系统，基于TensorFlow搭建Resnet50卷积神经网络算法，通过对5种常见的花朵图片数据集（'雏菊', '蒲公英', '玫瑰', '向日葵', '郁金香'）进行训练，最后得到一个识别精度较高的模型，然后搭建Web可视化操作平台。</p><p><strong>技术栈</strong>：</p><ul><li>项目前端使用Html、CSS、BootStrap搭建界面。</li><li>后端基于Django处理逻辑请求</li><li>基于Ajax实现前后端数据通信</li></ul><p><strong>选题背景与意义</strong>：<br/>在人工智能技术蓬勃发展的当下，图像识别领域成果丰硕，花朵识别作为其中细分方向，具有广泛的应用场景，如植物研究、花卉市场管理等。然而，传统花朵识别方法依赖人工经验，效率与准确性欠佳。为此，我们开展花朵识别系统项目，基于TensorFlow搭建Resnet50卷积神经网络算法，利用5种常见花朵图片数据集训练，以获取高精度识别模型。同时，为方便用户操作，采用Html、CSS等搭建前端界面，Django处理后端逻辑，Ajax实现数据通信，搭建Web可视化平台。</p><h2>二、系统效果图片展示</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047443914" alt="图片" title="图片"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047443915" alt="图片" title="图片" loading="lazy"/></p><h2>三、演示视频 and 完整代码 and 安装</h2><p>地址：<a href="https://link.segmentfault.com/?enc=675mxnjEYuy4vLwZ0UF%2F0Q%3D%3D.KvvT78ByhzRGVJwM0Kb0DvtEY2geSPxJb32h90zkaH4%3D" rel="nofollow" target="_blank">https://ziwupy.cn/p/6D4JhD</a></p><h2>四、卷积神经网络算法介绍</h2><p>ResNet50 是深度残差网络（Residual Network）的一种，由微软研究院提出。它通过引入残差块（Residual Block）解决了深度神经网络训练中的梯度消失和梯度爆炸问题，使得网络可以训练得更深。残差块通过跳跃连接（skip connection）将输入直接传递到输出层，让网络学习残差映射而非完整映射，降低了训练难度。ResNet50 包含 50 层深度网络，具有强大的特征提取能力，在图像分类、目标检测等任务中表现优异。</p><pre><code class="python">import tensorflow as tf
from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input
from tensorflow.keras.preprocessing import image
import numpy as np

# 加载预训练的 ResNet50 模型（不包含顶层分类层）
model = ResNet50(weights='imagenet', include_top=False, pooling='avg')

# 加载并预处理图像
img_path = 'your_image.jpg'
img = image.load_img(img_path, target_size=(224, 224))
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)

# 提取特征
features = model.predict(x)
print("提取的特征向量维度:", features.shape)
</code></pre><p>上述代码先加载预训练的 ResNet50 模型（基于 ImageNet 数据集训练），然后加载并预处理图像，最后使用模型提取图像特征。实际应用中，可在此基础上添加自定义分类层进行图像识别任务。</p>]]></description></item><item>    <title><![CDATA[2025 年数据库风险监测产品排名：行业]]></title>    <link>https://segmentfault.com/a/1190000047443924</link>    <guid>https://segmentfault.com/a/1190000047443924</guid>    <pubDate>2025-12-02 16:06:47</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>随着《数据安全法》《个人信息保护法》《网络数据安全管理条例》持续落地，企业对数据库安全的要求已从“合规记录”走向“实时风险治理”，传统的审计日志工具已无法满足对敏感数据滥用、内部违规、跨境流动和复杂攻击链路的监测需求。新一代数据库风险监测产品必须同时具备 行业领先的技术能力、高性能的处理引擎、多方式的部署模式，才能真正支撑企业的数据安全体系建设。<br/>本文基于最新技术趋势与权威评测，对国内数据库风险监测产品进行系统排名与深度解析，帮助企业完成科学选型。<br/>一、厂商排名<br/>第一名：全知科技·知形数据库风险监测系统 —— 新一代全链路风险治理标杆产品<br/>作为本次排名中唯一一家实现“数据中心化监测”的厂商，全知科技的 知形-数据库风险监测系统 在技术架构、智能识别能力、解析性能与合规适配等方面均处于行业顶尖水平。其最大特色是区别于传统仅记录 SQL 操作的审计方式，而是基于返回流量进行深度分析，从而实现更准确的风险识别与更短的响应延迟。<br/>● 行业领先的全链路行为画像能力<br/>知形可自动梳理数据库资产、敏感表结构与访问链路，构建“用户—应用—数据”三维行为模型，能够精准识别批量导出、越权访问、跨系统异常调用等核心高危行为。<br/>● 高性能多引擎解析能力<br/>通过旁路镜像方式采集流量，无需对业务系统进行改造；对 Oracle、MySQL、达梦、人大金仓、Hadoop 等主流与国产平台均能实现高吞吐、低延迟的实时解析，可在高并发环境下稳定处理 10 万 QPS 以上 SQL 行为。<br/>● 多方式部署，灵活适配大型组织架构<br/>支持旁路监测、串接阻断、云原生部署等多模式，可满足金融核心系统、能源控制系统、教育平台等不同场景的安全建设需求。<br/>● 实时风险识别能力行业领先<br/>依托自研 AI 模型，可识别 SQL 注入、批量窃取、自动化爬取、恶意脚本调用等复杂风险，误报率远低于传统规则产品；敏感数据泄漏时可实现 30 分钟内定向溯源并恢复事件链路。<br/>● 合规适配完善，可同时满足等保、审计、金融监管要求<br/>内置等保 2.0 模板、审计证据链、日志防篡改机制，可自动生成可直接用于监管报送的合规报告。<br/>综合能力判断，无论从技术深度、检测精度、产品架构还是未来演进能力，全知科技知形系统均明显领先于市场同类产品，因此位居本次排名首位。<br/>第二名：奇安信数据库安全审计与防护系统<br/>奇安信的数据库审计与防护系统以其威胁情报能力著称，内置大规模攻击特征库，可做到 SQL 注入、横向移动、恶意命令执行等攻击的高准确度识别。<br/>● 智能化威胁识别模型，SQL 注入检测准确率达 99.2%<br/>结合行为画像技术，可识别未知型攻击模式，在对抗自动化工具攻击方面表现稳定。<br/>● 能力覆盖从审计到阻断，防御链条完整<br/>可与 SOC/SIEM 深度联动，实现从预警到工单处置的闭环管理，是大型单位常见的配套部署产品。<br/>● 高性能处理能力<br/>支持高流量 SQL 行为解析，适用于党政军企、银行等高风险环境。<br/>奇安信整体能力较强，尤其适合对攻击防御要求较高的大型组织。<br/>第三名：安恒信息数据库审计与风险控制平台<br/>安恒信息专注于数据库访问控制能力，通过字段级策略实现更精细的数据治理。<br/>● 风险量化评估模型领先同类产品<br/>结合 CVSS 漏洞库与业务场景权重，能以评分方式展示数据暴露风险，推动安全治理可视化。<br/>● 字段级敏感访问控制能力强<br/>可动态阻断越权查询、异常导出等行为，对银行、能源等严控权限的行业适用性极强。<br/>总体而言，安恒产品在访问控制与风险量化方面有优势，但在 AI 能力与全链路分析方面略弱于排名第一的知形系统。<br/>第四名：启明星辰数据库审计与合规平台<br/>启明星辰主要在合规方面表现优异。<br/>● 合规模板最为完善<br/>预置等保 2.0、GDPR、金融审计等模板，一键生成审计报告，适合政府与央企。<br/>● 分布式架构支撑大规模部署<br/>单节点可处理百万级审计日志，适配大型集团与跨地区部署。<br/>综合评估，其优势在合规报送和大规模管理上，但在实时风险识别与智能分析方面相对传统。<br/>第五名：天融信数据库审计与行为监测系统<br/>天融信最大的产品特色是将 UEBA（用户实体行为分析）引入数据库场景，可识别员工恶意窃取、敏感数据批量查询等内部风险。<br/>● 内部风控能力较强<br/>适合运营商、金融机构等内控要求高的行业。<br/>● 高兼容性，满足国产化信创要求<br/>对达梦、人大金仓等具有良好适配能力。<br/>但在复杂攻击链识别与 AI 智能分析方面相对中等，与前几名产品存在差距。<br/>第六名：阿里云 DSC 风险感知<br/>DSC（数据安全中心）是云环境中常用的安全产品，其轻量化、自动化特点明显。<br/>● 自动发现实例、自动分类分级<br/>可直接识别 RDS、PolarDB 等云数据库资产，适合互联网企业、SaaS 平台等快速增长型组织。<br/>● 可视化数据地图完善<br/>显示数据流动路径与访问行为，但在实时流量解析层面的能力弱于本次排名前几名产品。<br/>整体更适合云上治理场景，而并非高风险核心数据库的深度监测场景。<br/>二、数据库风险监测产品选型策略<br/>为构建有效的数据库安全体系，企业需采用一种兼顾当前需求与未来演进的策略，将精准的产品选型与智能化的治理趋势紧密结合。<br/>核心选型：需求、技术与部署的三位一体<br/>产品选型应立足于核心需求，并接受严格的技术验证，以匹配最佳的部署模式。<br/>需求精准匹配：<br/>●合规导向型机构应选择具备成熟合规模板的产品<br/>●攻击防御型机构需优先考虑拥有高强度实时威胁识别与阻断能力的产品<br/>●实时治理型机构则应聚焦于能实现主动发现、实时预警和快速溯源的一体化平台（如全知科技知形系统）。<br/>技术能力验证：必须通过关键指标测试，包括误报率（≤0.5%）、高并发解析延迟（≤1秒）、对国产数据库与云环境的兼容性，以及敏感数据识别准确率。<br/>部署模式适配：根据业务场景灵活选择旁路监测（金融/政务核心）、串接阻断（高风险交易）或云原生架构（互联网/SaaS），确保安全与业务平衡。<br/>理想的数据库安全方案，是一个既能精准解决当前核心风险，又具备向智能化治理平台平滑演进能力的有机体。在这一演进路径上，以全知科技为代表的厂商，其产品理念与实时治理、全链路风险控制及智能化运营的未来需求高度契合，展现出显著的技术前瞻性。在智能化、自动化与深度风险治理方面构建了全链路能力的平台，将赢得长期竞争优势。</p>]]></description></item><item>    <title><![CDATA[【鸟类识别系统】Python+Tenso]]></title>    <link>https://segmentfault.com/a/1190000047443935</link>    <guid>https://segmentfault.com/a/1190000047443935</guid>    <pubDate>2025-12-02 16:06:04</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>一、介绍</h2><p>鸟类识别系统，通过TensorFlow搭建卷积神经网络算法，数据集使用经典的加利福尼亚大学CUB-200-2011鸟类数据集，对其进行多轮迭代训练，最后得到了一个精度较高的模型，并搭建Web可视化操作平台。</p><p><strong>技术栈</strong>：</p><ul><li>项目前端使用Html、CSS、BootStrap搭建界面。</li><li>后端基于Django处理逻辑请求</li><li>基于Ajax实现前后端数据通信</li></ul><p><strong>选题背景与意义</strong>：<br/>在生态保护与生物多样性研究日益重要的当下，精准识别鸟类品种对科研及爱好者而言意义重大。传统鸟类识别依赖人工比对图鉴，不仅效率低且对专业知识要求高。随着人工智能技术发展，利用深度学习算法实现自动化鸟类识别成为可行方向。本项目聚焦于此，采用TensorFlow搭建卷积神经网络算法，选用权威的加利福尼亚大学CUB-200-2011鸟类数据集，经多轮迭代训练出高精度模型。同时，为方便用户操作，还运用Html、CSS等搭建Web可视化平台，实现便捷交互。</p><h2>二、系统效果图片展示</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047443937" alt="图片" title="图片"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047443938" alt="图片" title="图片" loading="lazy"/></p><h2>三、演示视频 and 完整代码 and 安装</h2><p>地址：<a href="https://link.segmentfault.com/?enc=AkwBK4NGHiKZI1aG5MeAyA%3D%3D.P5pB%2BPfZ2w5ARrsDg1XxAEc4ZPECatyEVyVVoFJGOl8%3D" rel="nofollow" target="_blank">https://ziwupy.cn/p/CNZ6zx</a></p><h2>四、卷积神经网络算法介绍</h2><p>ResNet50是一种深度卷积神经网络（CNN），由微软研究院于2015年提出，属于ResNet系列模型。其核心创新是引入残差块（Residual Block），通过残差连接（Shortcut Connection）解决深层网络训练中的梯度消失问题，使网络能够训练更深层次的结构（共50层，含49个卷积层和1个全连接层）。残差块允许输入直接跳过部分卷积层，与输出相加，从而保留更多原始信息，提升特征提取能力。ResNet50在ImageNet数据集上达到76%的Top-1准确率，广泛应用于图像分类、目标检测等任务。</p><pre><code class="python">import tensorflow as tf
from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input
from tensorflow.keras.preprocessing import image
from tensorflow.keras.models import Model
import numpy as np

# 加载预训练模型（不包括顶层分类层）
base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# 添加自定义分类层
x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)
x = tf.keras.layers.Dense(1024, activation='relu')(x)
predictions = tf.keras.layers.Dense(10, activation='softmax')(x)  # 假设10个类别
model = Model(inputs=base_model.input, outputs=predictions)

# 冻结预训练层（可选）
for layer in base_model.layers:
    layer.trainable = False

# 示例：预处理单张图片并预测
img_path = 'example.jpg'
img = image.load_img(img_path, target_size=(224, 224))
img_array = image.img_to_array(img)
img_array = np.expand_dims(img_array, axis=0)
img_array = preprocess_input(img_array)

predictions = model.predict(img_array)
print("预测结果:", np.argmax(predictions))
</code></pre><p>代码加载预训练的ResNet50模型（基于ImageNet权重），替换顶层为自定义分类层（10类输出）。通过冻结预训练层，可利用其特征提取能力快速适配新任务（迁移学习）。输入图片需预处理为224×224尺寸，并使用preprocess_input标准化像素值。此方法适用于小数据集场景，可显著减少训练时间和计算资源需求。</p>]]></description></item><item>    <title><![CDATA[2025数据安全管理平台Top榜：自定义]]></title>    <link>https://segmentfault.com/a/1190000047443946</link>    <guid>https://segmentfault.com/a/1190000047443946</guid>    <pubDate>2025-12-02 16:05:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>随着《数据安全法》《个人信息保护法》《网络数据安全管理条例》等法规体系持续完善，数据安全平台正在从工具型产品迈向企业数字安全体系的战略基础设施。2025年的市场竞争不再只关注单点审计或局部监测，而是全面转向“平台化整合、AI智能治理、全链路防护”三大核心方向。本文结合行业标准、技术趋势与文档内容，对国内主流数据安全管理平台进行排名式分析，并围绕“自定义、合规治理、AI优化”三个关键能力进行综合评价，帮助企业形成可落地的选型参考。<br/>一、厂商排名<br/>TOP 1：奇安信数据安全治理平台<br/>奇安信在政府、金融、能源等关键行业长期积累，使其平台在合规治理、数据流动监测与零信任集成方面维持领先地位。其平台特色主要集中在三大方向：<br/>合规治理能力突出：提供嵌入式等保2.0、关基保护、GDPR等合规模板，审计证据链完整，适用于接受国家级审计的机构。<br/>动态数据流动可视化：基于行为链与数据路径渲染技术，实现跨系统、跨网络的数据流向追踪，帮助企业掌握敏感数据生命周期全貌。<br/>AI驱动风险分析：采用UEBA与量子加密技术结合，实现越权访问识别、敏感操作回溯、动态脱敏优化等能力。<br/>其在国有大型银行的数据监控项目中，实现了 99.3% 的敏感操作拦截率，为其保持排名第一提供强有力支撑。<br/>TOP 2：全知科技数据安全平台<br/>随着数据要素融入核心业务流程，全知科技凭借领先的AI优化技术、深度自定义治理能力与全链路风险感知体系，成为2025年最具成长力与技术突破性的厂商。</p><ol><li>全链路数据风险治理能力突破传统审计框架<br/>· 通过“知形-数据库风险监测系统”实现数据库资产自动识别、结构扫描与表级可视化。<br/>· 支持从数据资产地图到动态弱点捕捉（协议指纹识别）的一体化链路。<br/>· 覆盖内部违规访问、越权操作、敏感字段批量导出等全场景监测。</li><li>AI优化能力行业领先<br/>· 自研多模态识别模型，实现敏感数据自动分类分级，准确率可达 95%。<br/>· 无监督学习使平台异常识别能力持续优化，减少人为规则维护成本超过 90%。<br/>· API监测系统能基于AI识别黑灰产攻击模式，支持秒级泄露溯源。</li><li>自定义治理能力极强<br/>· 策略、模型、规则、告警链路均可自由组合，实现“企业级可控、场景级定制”。<br/>· 可根据行业（医疗/金融）将治理策略粒度细化到字段、表、业务路径。<br/>· 支持动态策略调整，由AI辅助生成最优风险拦截方案，降低误报率和对业务的影响。</li><li>合规治理深度与业务治理深度同步增强<br/>· 内置《数据安全法》《个人信息保护法》《等保2.0》审计框架，实现审计自动化。<br/>· 可结合数据资产图实现“敏感数据全生命周期合规链路”，满足金融与医疗双高敏行业要求。</li><li>标杆案例验证实战能力<br/>· 中国人寿财险：实现核心业务API链路风险实时监测，拦截率达到 99.3%。<br/>· 某三甲医院：部署后历史API泄露风险下降 98%，敏感操作实现全流程可核查。<br/>凭借 理念领先 + 技术突破 + 场景深耕 的组合优势，全知科技成为 2025 年最值得关注的新一代数据安全平台厂商。<br/>TOP 3：启明星辰数据安全平台<br/>启明星辰在政务、运营商领域具有天然优势，平台的“九天·泰合”智能模型让其在风险闭环管理上具有突出表现。<br/>主要优势包括：<br/>跨数据库与跨API审计能力强：可同时监控数据库、API、BI工具，形成多维行为链路分析。<br/>细粒度访问控制能力成熟：支持基于角色、标签、敏感度的动态授权管理。<br/>合规治理体系完备：国家级政务项目（如杭州亚运会）验证其高稳定性。<br/>启明星辰适用于大型机构构建统一审计与合规治理中心。<br/>TOP 4：天融信数据安全治理平台<br/>亮点包括：<br/>跨网络隔离环境的数据流追踪<br/>与防火墙、终端安全联动的联合防护体系<br/>对工业设备访问行为进行数据级精细分析<br/>特别适配制造业与能源行业产业链数据保护需求。<br/>TOP 5：阿里云数据安全中心（DSC）<br/>关键能力：<br/>深度集成 RDS / PolarDB，支持持续发现与自动分级敏感数据<br/>通过AI监测异常行为（如非工作时段批量下载）<br/>具备跨境数据合规治理能力<br/>适合互联网企业、跨境业务与多云环境用户。<br/>TOP 6：深信服数据安全中心<br/>主要特点：<br/>集成零信任认证与API动态防护<br/>部署简单、成本适中、上云速度快<br/>重点布局 AI 漏洞挖掘技术（研发投入达 22%）<br/>适合教育、医疗、中小企业的标准化安全治理需求。<br/>二、选型建议：</li><li>按照业务特点明确优先级<br/>若以合规治理为核心诉求，可优先考虑具备成熟模板与审计能力的平台，如启明星辰、阿里云。<br/>若强调AI优化能力、需要识别复杂行为风险，则全知科技、奇安信更具优势。<br/>若系统较多且架构复杂，需自定义策略，建议选择具备高度策略灵活性的厂商，如全知科技。</li><li>关注技术能力验证的关键指标<br/>主要包括三类：<br/>智能化能力测试：敏感数据识别准确率、异常行为误报率（应≤0.5%）<br/>性能测试：高并发环境下能否保持低延迟、大规模流量解析能力<br/>自定义能力测试：是否支持规则、阈值、流程、策略的灵活编排<br/>随着市场从“工具使用”走向“治理运营”，数据安全平台的竞争不再是单点功能，而是 全链路风险治理 + AI智能运营 + 合规持续适配 的综合能力。对于任何行业而言，选择一个“能看得见问题、能管得住资产、能控得住风险、能适应未来演化”的平台，已成为数据安全建设的必然趋势。</li></ol>]]></description></item><item>    <title><![CDATA[数据交换机案例详解|基于smardate]]></title>    <link>https://segmentfault.com/a/1190000047443957</link>    <guid>https://segmentfault.com/a/1190000047443957</guid>    <pubDate>2025-12-02 16:04:51</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><strong>需求背景</strong><br/>在智慧园区治理中，管理人员常常面临多重数据挑战。各个业务系统的数据壁垒导致企业信息、合同数据、纳税记录等分散存储，形成数据孤岛。更为棘手的是，数据处理过程严重依赖IT人员和技术团队，业务人员即使有分析思路，也难以快速实现。从数据接入到最终可视化展示，往往需要经历漫长开发周期，无法支持实时决策。当需要计算一些专业指标时，业务人员不得不等待技术团队开发相应计算逻辑，响应速度慢，成本高昂。<br/><strong>解决方案</strong><br/>smardaten平台中提供了数据交换机功能，针对上述痛点提供了完整的解决方案。数据交换机是平台中的核心数据处理模块，它通过可视化的方式，让用户能够通过简单拖拽配置复杂的数据处理流程。与传统编码方式相比，数据交换机具有以下突出优势：<br/>• 可视化操作：提供丰富的算子节点（输入、输出、基本转换等），通过拖拽即可完成数据处理流程设计，降低技术门槛；<br/>• 多源数据支持：能够同时接入数据库、外部接口、Excel等多种数据源，实现数据统一融合处理；<br/>• 便捷的数据处理能力：内置数据清洗、转换、关联、计算等全方位功能，支持复杂业务逻辑实现。<br/><strong>处理场景：入驻企业纳税与风险分析</strong><br/>某智慧园区需要对企业进行精准评估，识别高潜力企业和高风险企业。核心分析目标包括：<br/>• 计算每家入驻企业2022-2024年的纳税复合增长率，并生成排名；<br/>• 结合纳税增长率并计算租金收缴率，进行风险分级预警，形成预警清单；<br/>• 将数据处理结果通过列表、图表等可视化形式进行直观展示，支持管理决策。<br/><strong>配置过程</strong><br/><strong>1. 纳税复合增长率计算</strong><br/>在第一个交换机中，我们需要计算每家企业2022到2024年的纳税复合增长率。整个流程将涵盖数据接入、清洗与转换、关联、计算、输出和可视化展示六个核心环节。<br/><strong>1.1 数据接入</strong><br/>首先，完成多源数据的接入工作。通过“输入数据源”节点和“Excel抽取”节点，轻松导入企业信息表（来自MySQL数据库）、合同信息表（来自外部接口）和税务年度记录表（来自Excel）。<br/><img width="723" height="360" referrerpolicy="no-referrer" src="/img/bVdnetQ" alt="" title=""/><br/><strong> 1.2 数据清洗与转换</strong><br/>原始数据往往杂乱，必须清洗和转换后才能用于分析，这是确保分析结果准确性的关键步骤，能剔除无效数据、规范数据格式。<br/>在“合同信息表”中，“租用地址”字段将园区地址、楼栋号、楼层号通过横线连接存储，需要通过该字段获取到园区名称。<br/><img width="723" height="347" referrerpolicy="no-referrer" src="/img/bVdnetU" alt="" title="" loading="lazy"/><br/>通过「分列」节点，解析合同信息表中的“租用地址”字段，分别定义“园区地址”、“楼栋号”、“楼层号”三个目标字段，以横线为分隔符进行切分，形成三列数据。右侧，处理结果将会自动按列序号递增分配切分结果。<br/><img width="723" height="360" referrerpolicy="no-referrer" src="/img/bVdnet4" alt="" title="" loading="lazy"/><br/>针对“税务年度记录表”，需要过滤出最近三年的数据以计算有意义的复合增长率。使用「过滤」节点，设置年份条件为2022、2023和2024年，精准筛选出所需数据。<br/><img width="723" height="360" referrerpolicy="no-referrer" src="/img/bVdnet5" alt="" title="" loading="lazy"/><br/> 发现税收或营收字段有空值？使用「空值填充」节点，将这些空数据统一填充为 0，保障数据完整性。<br/><img width="723" height="360" referrerpolicy="no-referrer" src="/img/bVdneuj" alt="" title="" loading="lazy"/><br/>原始税务记录是一年一行，为方便后续纳税复合增长率的计算，使用「行转列」节点，将每个企业三年的纳税金额转为一行三列，结构清晰，方便后续计算。<br/><img width="723" height="218" referrerpolicy="no-referrer" src="/img/bVdneun" alt="" title="" loading="lazy"/><br/><img width="723" height="360" referrerpolicy="no-referrer" src="/img/bVdneup" alt="" title="" loading="lazy"/><br/><strong>1.3 数据关联</strong><br/>数据清洗与转换完成后，需要将分散在三张表中的数据关联起来，获取所需的字段，形成完整的数据表。使用「维表关联」的节点，将三张表根据企业ID关联起来，输出所需的字段。<br/><img width="723" height="360" referrerpolicy="no-referrer" src="/img/bVdneuq" alt="" title="" loading="lazy"/><br/><strong>1.4 数据计算</strong><br/>数据整合到位后，进入核心的指标计算环节。通过「函数」节点实现复杂运算，平台内置多种 sparkSQL 函数，无需专业编程能力，只需输入计算表达式，即可快速完成纳税复合增长率计算，非常简单！<br/><img width="723" height="360" referrerpolicy="no-referrer" src="/img/bVdneut" alt="" title="" loading="lazy"/><br/>计算完成后，还需两步优化结果呈现。首先，增长率计算完成后，是小数的展示形式。如果我们更希望展示为百分比的形式，只需使用「度量转换」节点，新增百分比字段，转换比例为1比100。<br/><img width="723" height="360" referrerpolicy="no-referrer" src="/img/bVdneuu" alt="" title="" loading="lazy"/><br/>其次，还可以使用「排名」节点，按纳税复合增长率百分比进行降序排名，让高增长企业一目了然。<br/><img width="723" height="360" referrerpolicy="no-referrer" src="/img/bVdneuv" alt="" title="" loading="lazy"/><br/><strong>1.5 数据输出</strong><br/>最后通过「合并输出数据」节点将结果输出到资产表。<br/><img width="723" height="360" referrerpolicy="no-referrer" src="/img/bVdneuw" alt="" title="" loading="lazy"/><br/>选择 “插入并更新” 模式，以企业 ID 为主键，无相同数据则插入，有相同数据则自动更新，避免数据冗余。<br/><img width="723" height="360" referrerpolicy="no-referrer" src="/img/bVdneuC" alt="" title="" loading="lazy"/><br/>现在我们已经完成了所有节点的配置，执行交换机后，很快就能得到包含企业 ID、园区名称、企业名称、纳税复合增长率以及排名的完整资产表。<br/><img width="723" height="360" referrerpolicy="no-referrer" src="/img/bVdneuD" alt="" title="" loading="lazy"/><br/>同时下方，支持查看每个处理节点的中间输出数据，便于校验与调试。<br/><img width="723" height="360" referrerpolicy="no-referrer" src="/img/bVdneuE" alt="" title="" loading="lazy"/><br/>更便捷的是，还支持设定「定时调度」，比如每个季度执行一次，设定起止时间，实现数据自动处理，无需人工重复操作。<br/><img width="723" height="360" referrerpolicy="no-referrer" src="/img/bVdneuF" alt="" title="" loading="lazy"/><br/><strong>1.6 可视化展示</strong><br/>完成数据输出后，来到智慧园区应用中，进行可视化展示。在工作台页面的画布列表中，绑定刚刚生成的资产表。预览后，可以看到排行榜中直观展示了不同园区每家企业的纳税增长排名和对应的增长率。<br/><img width="723" height="360" referrerpolicy="no-referrer" src="/img/bVdneuG" alt="" title="" loading="lazy"/><br/>我们通过可视化流程，完成了多源数据接入、清洗、关联，计算等一系列流程，将复杂的数据处理与分析工作从以“天”为单位的传统开发模式，转变为业务人员可自主配置、响应速度达分钟级的新模式，实现对企业发展潜力的实时、量化洞察。<br/><strong>2. 企业风险等级分析</strong><br/>有了核心的纳税增长数据，我们进一步延伸分析维度，将 “纳税增长能力” 与 “租金履约能力” 结合，精准识别潜在风险企业，让管理从 “被动应对” 转向 “主动预警”。<br/><strong>2.1 数据接入</strong><br/>创建一个新的交换机，拖入「输入数据源」节点，导入下方的数据表：<br/>• 纳税复合增长率资产：上一个交换机输出的资产，包含企业ID、名称、增长率等数据；<br/>• 收租计划表：包含应缴日期和应收金额等数据；<br/>• 实际收款表：包含实缴日期和实收金额等数据。<br/><img width="723" height="360" referrerpolicy="no-referrer" src="/img/bVdneuO" alt="" title="" loading="lazy"/><br/><strong>2.2 复杂分析</strong><br/>现在我们要进行一个复杂分析，除了之前我们综合使用各个节点进行处理，可灵活使用「高级SQL」节点，直接编写SQL语句进行处理，兼顾灵活性和效率。在这段查询SQL中，将针对纳税增长率的排名和收缴率两个指标对企业进行打标。例如，如果增长率排名小于等于10，同时收缴率又小于90%，标记为“高增长-高逾期风险”的企业，招商或客户部门应主动介入，了解其是否存在经营困难，防范坏账风险。最后我们会得到一份预警清单。<br/><img width="723" height="360" referrerpolicy="no-referrer" src="/img/bVdneuP" alt="" title="" loading="lazy"/><br/>同时 SQL 语句中的表名称需替换为对应的S1、S2节点，完成后点击校验SQL，确认SQL语句可用。<br/><img width="723" height="360" referrerpolicy="no-referrer" src="/img/bVdneuQ" alt="" title="" loading="lazy"/><br/><strong>2.3 数据输出</strong><br/>最后，拖入「输出数据源」节点，输出处理后的数据。<br/><img width="723" height="360" referrerpolicy="no-referrer" src="/img/bVdneu1" alt="" title="" loading="lazy"/><br/>现在我们来执行交换机，查看最终节点的输出。<br/><img width="723" height="360" referrerpolicy="no-referrer" src="/img/bVdneu5" alt="" title="" loading="lazy"/><br/>现在已经完成了企业风险等级的分析。我们发现该交换机数据的执行是依赖于前一个交换机输出的纳税增长率资产表，所以在应用配置页，选中一个交换机开启触发依赖，即一旦纳税增长率的交换机执行完成后，会立即自动触发第二个交换机的执行任务，将两个分析阶段无缝衔接，形成一个连贯的自动化管道。<br/><img width="723" height="360" referrerpolicy="no-referrer" src="/img/bVdneu8" alt="" title="" loading="lazy"/><br/><img width="723" height="360" referrerpolicy="no-referrer" src="/img/bVdneu9" alt="" title="" loading="lazy"/><br/><strong>2.4 可视化展示</strong><br/>最后，在工作台页面的配置页，将图表和列表绑定资产。左侧环形图，直观展示了各风险等级的企业数量分布，帮助管理者快速把握整体风险轮廓，右侧画布列表则可以直接查看收缴率低于95%的具体企业名单。<br/><img width="723" height="360" referrerpolicy="no-referrer" src="/img/bVdnevb" alt="" title="" loading="lazy"/><br/>我们通过多种节点与SQL语句结合，成功实现了这一复杂的数据处理与分析，得到了各个企业的收缴率和风险指标，有利于后续对不同风险等级企业的差异化、精准化监管与服务。<br/><strong>体验总结</strong><br/>通过智慧园区治理平台的数据处理与分析，smardaten数据交换机展现出以下几方面突出价值：<br/>• 支持敏捷迭代：当业务规则变化时，只需调整相应节点配置即可快速响应，无需重新开发整个流程；• 实现自动化运营：通过配置触发依赖和定时调度，整个数据处理流程可实现全自动化运行，极大减少人工干预需求。前一个交换机执行完成后可自动触发后续流程，形成连贯的自动化管道；<br/>• 数用一体：数据处理结果可直接应用于业务场景，简单直观，避免了传统模式下数据平台与应用场景脱节的问题。 </p>]]></description></item><item>    <title><![CDATA[资深前端工程师| 升职加薪这件事，我困顿]]></title>    <link>https://segmentfault.com/a/1190000047443972</link>    <guid>https://segmentfault.com/a/1190000047443972</guid>    <pubDate>2025-12-02 16:04:00</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>我大概是在工作的第五年，晋升到了高级前端工程师。那时候我挺自豪的，觉得自己技术不错，能独立负责复杂的业务，也能搞定线上疑难杂症，再往上走，应该也只是时间问题。</p><p>但没想到，高级这个title，我一挂就是三年多。</p><p>其中有整整两年，我感觉自己撞到了一堵看不见的墙。我明明是团队里解决技术难题最多的人，写的代码质量也公认是最好的，但每次晋升季，我和老板聊，得到的反馈总是有点虚：</p><p>“要多思考业务价值。”</p><p>“要展现出更大的影响力。”</p><p>“要多看看owner的角度。”</p><p>说实话，我当时听得一头雾水，甚至有点不服气。我想的是：“我一个工程师，不就是把技术搞好，把代码写漂亮吗？影响力？那不是Leader该考虑的事吗？”</p><p>这篇，就是想复盘一下我卡住的那两年，我是如何迷茫，又是如何最终想明白，从高级到资深（或者叫专家、Staff），真正需要跨越的到底是什么。<br/><img width="499" height="334" referrerpolicy="no-referrer" src="/img/bVdnept" alt="" title=""/></p><p>高级工程师的陷阱：以为自己技术无敌</p><p>在被“卡住”的那两年里，我的状态可以用四个字来形容：战术勤奋。</p><p>我做了很多事，而且自认为做得很好：</p><pre><code>产品经理提的需求，无论多复杂，到我手里，我都能拆解得明明白白，然后用最优雅的代码实现出来，交付质量又高又快。
团队里有别人搞不定的Bug，最后基本都是我来收尾。我是大家公认的技术上的“定海神针”。
社区出了什么新技术，我总是第一个去研究，然后尝试在项目里引入，比如把打包工具从Webpack换到Vite。

</code></pre><p>我做了这么多，为什么还不够？我当时觉得很不公平。我把成为一个技术更强的人，当成了唯一的晋升路径，并且认为自己已经在这条路上走得够远了。</p><p>这就是我掉进去的第一个陷阱：把高级当成了个人能力的顶点，而没有去理解“资深”这个角色，到底需要什么不一样的能力。</p><p><strong>坑位</strong></p><p>技术大厂，前端-后端-测试，新一线和一二线城市等地均有<a href="https://link.segmentfault.com/?enc=wUnIDITqxPRfSRdGL%2Fm52Q%3D%3D.04MUUtO%2BDbjhj9KMSpZjvqN72Ce2q9IzLHB4CAqYpFw%3D" rel="nofollow" target="_blank">坑位</a>，待遇和稳定性都不错，感兴趣可以试试</p><p>从我到我们</p><p>真正的转变，来自一次和公司一位架构师的午餐。</p><p>我向他抱怨了我的困惑，他听完后，问了我一个问题：</p><p>“你觉得，是你自己一个人，一个月写1万行高质量的代码，对公司的价值大；还是你花一半的时间，让团队里其他5个人，每个人都能写出和你一样80%水平的代码，对公司的价值大？”</p><p>这个问题，像一道闪电一样击中了我。</p><p>我慢慢发现， 高级工程师的价值，体现在他能独立搞定复杂问题。而资深工程师的价值，体现在他能带领和影响一群人，去持续地搞定一系列复杂问题。</p><p>前者的产出，上限就是他自己一个人的时间和精力。而后者的产出，是可以被放大的。</p><p>我终于理解了老板口中的影响力是什么意思。我的价值，不再是我自己写了多少行牛逼的代码，而是因为我的存在，我们整个团队的代码质量、开发效率、技术氛围有没有得到系统性的提升。</p><p>我的工作重心，需要从关注事，转变为关注人；从关注个人产出，转变为关注团队产出。</p><p>为了破局，我开始做的几件事</p><p>想明白了这个道理后，我不再纠结于我明明干得最多，而是开始有意识地改变我的工作方式。</p><pre><code>从接需求到反问需求

</code></pre><p>我不再满足于产品经理给我一个PRD然后我闷头做。在需求评审时，我会拉着他一起讨论：</p><pre><code>
这个需求的真实业务目标是什么？是为了提升用户留存，还是为了增加收入？


为了达到这个目标，目前的设计是最简单的方案吗？有没有更轻量的技术方案能达到80%的效果？

我开始把一部分精力，从如何实现，转移到了为何实现和如何更聪明地实现上。




从解决问题到预防问题

</code></pre><p>遇到一个线上Bug，我不再只是把它修复就完事。我会花更多时间去思考：</p><pre><code>为什么会产生这个Bug？ 是不是我们的代码规范有问题？是不是缺少了某个Eslint规则？是不是某个公共组件的设计有缺陷？
然后，我会推动建立一个机制，去系统性地预防同类问题再次发生。比如，为核心逻辑补充单元测试、推动建立Code Review的Checklist、重构那个有缺陷的公共组件。



从个人输出到团队为重

</code></pre><p>我开始刻意减少自己写一线业务代码的时间，把更多的时间花在赋能上：</p><pre><code>更用心地做Code Review：我提的建议，不再只是这里有个bug，而是“我们可以把这个逻辑抽成一个Hook，以后大家都能用”、“这个设计模式不错，我给你找篇文章可以深入了解下”。
主动做技术分享：我把最近研究的新技术、踩过的坑，整理出来在团队内部分享，帮助大家一起成长。
写文档：我开始为我们组的核心模块、复杂的业务流程写文档，极大地降低了新人的上手成本。

</code></pre><p>我开始主动去跟后端、跟测试、跟运维的同事聊天，了解他们的痛点，思考如何在前端层面，帮助他们解决问题。比如，和后端一起约定更合理的数据结构，或者开发一个Mock工具方便他们自测。我开始承担起一个技术方案指定角色。</p><p>当我开始做这些转变之后，大概又过了一年，我的晋升，就成了水到渠成的事。</p><p>现在回过头看，从高级到资深，要攀登的根本就不是同一架梯子。</p><p>那两年，我并没有白等。那段卡住的时期，虽然痛苦，但它逼着我去思考代码之外的东西。</p><p>如果你也正卡在这个阶段，希望我的这点思考，能给你一些启发。</p><p>最后，你们也有过这种焦虑吗？🙂</p><p>——转载自：ErpanOmer</p>]]></description></item><item>    <title><![CDATA[Apipost 自动化测试实战：用 IF]]></title>    <link>https://segmentfault.com/a/1190000047444011</link>    <guid>https://segmentfault.com/a/1190000047444011</guid>    <pubDate>2025-12-02 16:03:18</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在日常的API测试中，我们经常遇到后一个请求依赖于前一个请求结果的情况。比如，删除一条数据前，必须先成功创建它；或者，当查询结果为空时，我们可能希望跳过后续的更新操作。在这种场景下，简单的线性测试脚本就无法满足需求了。<br/>Apipost的自动化测试功能提供了很便捷的条件判断功能，允许我们根据前一个请求的响应结果，动态地决定后续测试的执行流程。本文将通过一个完整的“公寓管理”（增删改查）案例，手把手带你掌握如何在Apipost中使用条件判断，构建一个自动化测试集。</p><h2>一、 测试场景与接口说明</h2><p>假设我们正在测试一个简单的公寓管理模块，包含四个核心接口：</p><pre><code>1. 新增公寓 (Create) - `POST /api/apartment-api/apartment`

2. 查询公寓 (Read) - `GET /api/apartment-api/apartment/{Id}`

3. 编辑公寓 (Update) - `PUT /api/apartment-api/apartment/{Id}`

4. 删除公寓 (Delete) - `DELETE /api/apartment-api/apartment/{Id}`</code></pre><p><strong>自动化测试目标</strong>：创建一个测试集，按“增-&gt;查-&gt;改-&gt;删”的顺序执行。关键在于，每一步都依赖于上一步的成功执行。<br/>例如，只有成功创建公寓后，才能用返回的Id去查询、更新和删除</p><h2>二、 在Apipost中配置条件判断步骤</h2><p>1：创建自动化测试集并添加接口在Apipost-自动化测试中创建一个名为“公寓管理自动化测试”的测试集。将上述四个接口及登录接口导入到测试集中。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047444013" alt="图片" title="图片"/><br/>步骤2：提取新增公寓接口的响应数据id，并为后续接口设置环境变量<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047444014" alt="图片" title="图片" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444015" alt="图片" title="图片" loading="lazy"/><br/>步骤3：添加条件判断控制器1、在新增公寓接口后面添加条件判断控制器<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047444016" alt="图片" title="图片" loading="lazy"/></p><p>2、设置判断条件{id} 是一个变量，它来自于前面新增公寓后返回的id 。<br/>这个条件判断会检查 {id} 的值。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047444017" alt="图片" title="图片" loading="lazy"/><br/>3、在控制器添加子步骤：将查询、编辑、删除公寓接口添加到控制器里面解释：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047444018" alt="图片" title="图片" loading="lazy"/><br/>4、{id} 不为空的执行情况展示<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047444019" alt="图片" title="图片" loading="lazy"/><br/>5、{id} 为空的执行情况展示<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047444020" alt="图片" title="图片" loading="lazy"/></p><h2>总结</h2><p>以上就是IF控制器在自动化测试中的完整使用案例；将条件判断与环境变量、数据提取等功能结合，你就能在Apipost中设计出非常强大和智能的自动化测试套件，能够极大地提升API测试的质量和效率。</p>]]></description></item><item>    <title><![CDATA[Apache Doris 在小米统一 O]]></title>    <link>https://segmentfault.com/a/1190000047444040</link>    <guid>https://segmentfault.com/a/1190000047444040</guid>    <pubDate>2025-12-02 16:02:46</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <blockquote>小米早在 2019 年便引入 <a href="https://link.segmentfault.com/?enc=KnpZQg%2B1eL5QWHeBCF%2BtRQ%3D%3D.nWNh9eOkk9w%2FNa16Cuk23sPHEpzp0oKucNfz%2FAn6%2BHc%3D" rel="nofollow" target="_blank">Apache Doris</a> 作为 OLAP 分析型数据库之一，经过五年的技术沉淀，已形成<strong>以 Doris 为核心的分析体系</strong>，并基于 2.1 版本异步物化视图、3.0 版本湖仓一体与存算分离等核心能力优化数据架构。本文将详细介绍小米数据中台基于 Apache Doris 3.0 的查询链路优化、性能提升、资源管理、自动化运维、可观测等一系列应用实践。</blockquote><p>小米集团成立于 2010 年，是一家以智能手机、智能硬件和 IoT 平台为核心的全球领先科技企业，业务遍及全球 100 多个国家和地区。小米构建了全球最大的消费类 IoT 物联网平台，同时持续推进“手机×AIoT”战略。旗下产品涵盖智能手机、电视、笔记本、可穿戴设备及生态链智能产品，并投资孵化众多智能科技企业。</p><p>Apache Doris 在小米内部应用广泛，业务涵盖汽车、手机领域（包括手机系统应用与硬件制造）、互联网、线上线下销售与服务、底层平台以及新业务等多个领域，支撑着多样化的数据分析需求。<strong>目前，Doris 集群数量超过 40 个，管理数据规模数 PB，日均查询量达到 5000 万次，资源规模在近一年内增长约 80%，展现出快速发展的态势。</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444042" alt="Doris 对小米业务线的支持.PNG" title="Doris 对小米业务线的支持.PNG"/></p><h2>小米数据中台 OLAP 发展与挑战</h2><h3>01 架构演变历程</h3><p>早期小米技术栈复杂多样，数据湖体系与 OLAP 引擎众多。自 2019 年在小米内部投入应用以来，Apache Doris 逐渐从中脱颖而出，发展成为小米数据架构的核心引擎。</p><p><strong>一方面，Apache Doris 整合了内部复杂的 OLAP 分析体系，统一承载起原本由多系统分散提供的查询能力；另一方面，Doris 凭借出色的查询性能与良好的生态兼容，配合 Trino、Spark、Iceberg、Paimon 等完成了从外仓到湖仓一体架构的关键升级。</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444043" alt="架构演变历程.png" title="架构演变历程.png" loading="lazy"/></p><p>2022 年起，Doris 在小米内部已形成了较为成熟的应用体系：依托内部发布平台，在物理机上实现集群的自动化部署与运维；同时接入内部监控体系，全面保障 Doris 集群的可观测性与稳定性。</p><p>2025 年，我们正式引入了湖仓一体与存算分离能力成熟的 Doris 3.0 稳定版本，与 2.1 版本并行运行，并针对 Doris 3.0 在管理层面进行了重大调整：引入集群编排系统，并基于 <a href="https://link.segmentfault.com/?enc=qcvPt726vGl54bkzroPz9w%3D%3D.FM0jdknNL%2B7AmIY%2BC19zph0OPsI7Gb3oJenfrNH15bfm9%2BVktDI%2Fz4IHInMxrdjZ708fCjr3s9Vbd2L6MPE3ELbrLUtXXDjqfDc8WUPOkQE%3D" rel="nofollow" target="_blank">Doris Manager </a>自主开发了集群管理系统，提供更全面、标准化的运维与可观测性方案。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444044" alt="架构演变历程-1.PNG" title="架构演变历程-1.PNG" loading="lazy"/></p><h3>02 外仓面临的挑战</h3><p>小米早期 OLAP 体系中，离线数仓视为“内仓”，而  OLAP 服务则归为“外仓”，内外仓的数据流动依赖 Flink 或 Spark 等数据集成工具。团队主要负责 Doris 集群的部署与日常运维，在此过程中，我们遇到了诸多来自用户和自身的痛点问题，下面将结合业务场景介绍。</p><h4>跨系统数据集成</h4><p>数据通过 Flink 或 Spark 从离线的内仓抽取至 Doris，形成跨系统数据流动。这种模式带来一系列挑战：</p><ul><li>数据冗余：同一份数据在多个系统中存储，增加成本；</li><li>口径不一致：不同系统处理逻辑差异导致结果偏差；</li><li>排查困难：当 BI 看板数据出现差异时，需跨多个系统定位问题；</li><li>开发负担重：业务方需自行维护 ETL 链路和多套查询接口。</li></ul><p>以广告业务为例，其数据链路涉及多个存储系统（如 Iceberg、Druid）和同步任务，分析师需根据查询粒度选择不同系统，心智负担显著。对开发侧而言，需针对不同数据链路进行定制化开发，同时在多个系统上重复建设数据看板，导致开发工作重复、周期长，整体投入成本较高。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444045" alt="跨系统数据集成.PNG" title="跨系统数据集成.PNG" loading="lazy"/></p><h4>存算一体架构局限</h4><p><strong>1、高可用容灾</strong></p><p>2023 年海外机房火灾事件暴露了存算一体架构的脆弱性，虽然数据最终恢复，但也促使团队重新审视数据高可用策略。针对 Doris 2.x 的高可用方案，团队曾评估两种路径：</p><ul><li>主从复制（CCR）：依赖较新版本支持，缺乏生产验证，主备切换复杂，客户端需双连，恢复时间长；</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444046" alt="高可用容灾.PNG" title="高可用容灾.PNG" loading="lazy"/></p><ul><li>跨可用区副本分布：通过 Resource Group 将副本分散至不同机房，虽可避免单点故障，但跨机房读写带来性能损耗。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444047" alt="高可用容灾-1.png" title="高可用容灾-1.png" loading="lazy"/></p><p>最终采用后者作为临时方案，但仍未根本解决成本与可用性之间的矛盾。</p><p><strong>2、资源利用率低</strong></p><p>物理机部署模式下，构建一个高可用 Doris 集群需要 3 FE + 3 BE，对于中小规模业务而言，此配置远超实际需求，导致资源浪费严重。若为每个小业务独立建集群，将导致集群数量激增，运维压力剧增；若采用共享集群，则面临资源争抢、隔离困难、计费模糊等问题。</p><p>直到 Apache Doris 3.0 发布后引入存算分离版本，高可用容灾与资源弹性问题得到解决，下个章节将详细展开介绍。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444048" alt="资源利用率低.png" title="资源利用率低.png" loading="lazy"/></p><h4>集群运维效率低</h4><p>原有基于物理机的手动部署流程，从申请资源到集群上线通常耗时一周以上。面对快速增长的业务需求，该模式已无法满足敏捷交付要求。</p><h2>Apache Doris 3.0 应用实践与突破</h2><p>基于上述挑战，Doris 2.0 及早期版本在湖仓一体、存算分离、集群自动化运维等方面仍有不足，而 3.0 存算分离版本带来了诸多升级，经过一段时间的验证，团队规划出 3.0 版本与早期版本并行的升级架构，并在 3.0 版本的基础上对架构设计与使用模式进行了显著优化。</p><h3>01 Doris 3.0 核心优势</h3><p>首先是 3.0 存算分离的部署模式，其主要依赖计算组进行资源隔离通过将计算层与存储层解耦，BE 节点实现无状态化，依托底层 Kubernetes 支持，可以实现快速弹性伸缩以满足不同体量用户的需求。</p><p>同时，Doris 原生支持湖仓查询能力，在存算分离模式下，能够直接访问外部数据湖，有效打通数据孤岛。这一特性不仅显著简化了传统数据链路，也减少了因多层复制带来的数据冗余，真正推动湖仓一体架构的落地实践。</p><p>基于此，数据开发平台的整体架构发生变化：Doris 不再局限于传统“外仓”的角色，而是向上演进为统一的查询引擎层，与底层 Iceberg、Paimon 等湖仓格式解耦，直接进行联邦查询，同时利用自身的数据缓存、物化视图等能力对热点数据进行加速，兼顾灵活性与高性能。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444049" alt="Doris 3.0 核心优势.png" title="Doris 3.0 核心优势.png" loading="lazy"/></p><h4>Doris vs Trino 湖仓分析能力对比：全面领先</h4><p>在 TPC-DS 1TB 标准测试中，Doris 对比 Trino 在整体查询性能上展现出全面领先的优势。无论是复杂多表关联、聚合分析，还是高并发场景下的响应效率，Doris 均表现出更优的执行速度和资源利用率，平均查询耗时明显更低，尤其适用于对查询性能要求较高的实时分析场景。</p><ul><li>TPC-DS 1T 测试：Doris 对比 Trino 全面领先</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444050" alt="Doris vs Trino 湖仓分析能力对比.png" title="Doris vs Trino 湖仓分析能力对比.png" loading="lazy"/></p><p>在小米内部的数据查询场景，涵盖多表关联、聚合计算、过滤下推等常见操作的实际业务查询中，<strong>Doris 对比 Trino 的数据湖查询效率高 3～5 倍</strong>。</p><ul><li>内部数据查询场景：Doris 对比 Trino 数据湖查询效率高 3～5 倍</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444051" alt="Doris vs Trino 湖仓分析能力对比-1.png" title="Doris vs Trino 湖仓分析能力对比-1.png" loading="lazy"/></p><h3>02 统一查询网关</h3><ul><li><strong>统一认证鉴权</strong>：在连接层，将不同引擎的权限和认证体系统一提升到网关层，用户通过网关统一查询，无需担心引擎权限问题。</li><li><strong><a href="https://link.segmentfault.com/?enc=JB39c9%2FxKxaAXYKnogiWgA%3D%3D.7eFM0jMAdtahEF2s4tQAIkI3R8JGzai2gcFr7zyucB2h%2BDVD1xiWmH29jEMp8iO8" rel="nofollow" target="_blank">SQL 改写</a></strong>：利用 Doris 的 SQL 改写能力，将其提升到网关层，帮助用户在不同引擎间平滑切换，避免因 SQL 语句不兼容导致出错。</li><li><strong>连接协议优化</strong>：采用 <a href="https://link.segmentfault.com/?enc=IrXmLmh9aHdtNsSoNf1jNg%3D%3D.rNTUA0%2Fm%2BBn77MvjU%2BS3jOZ%2Fnky1MaZ%2FEPRUs7e2Y7X6Cv2u6HLyOpXwpBIeBoOr" rel="nofollow" target="_blank">Arrow Flight SQL </a>传输协议和 ADBC 连接方式，传输效率较 JDBC 高 10 倍以上，真实业务场景查询耗时减少 36%，Kyuubi 实例内存用量减少 50%，代理层服务的管理效率显著提升。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444052" alt="统一查询网关.png" title="统一查询网关.png" loading="lazy"/></p><h3>03 数据链路：物化视图上卷代替导入任务</h3><p>以广告业务场景为例，面对分钟级明细数据聚合查询较慢的问题，常见方案是将原始明细数据聚合成小时级数据，定期导入 Doris 以提升查询性能。这一过程需开发和维护复杂的调度任务，运维成本较高。</p><p>自 Doris 2.1 版本引入<a href="https://link.segmentfault.com/?enc=U0RIicRe41ZSumItMMReRA%3D%3D.7P7DcgFq6EW3EV%2FPfILRWb9v4g9VV7oTEzgaZYj9RrUkpzVYbu2IkJyfFPqA4Q2c" rel="nofollow" target="_blank">异步物化视图</a>能力后，只需在 Doris 中声明物化视图定义，系统即可自动完成从外部数据湖（如 Iceberg）增量同步、数据聚合、更新调度等全过程，无需额外开发 ETL 链路，也无需关注底层执行细节，显著降低了开发与运维负担。同时，Doris 支持物化视图改写能力，用户仍可使用原有 SQL 查询原始表，系统会自动识别并将其透明改写为对应的物化视图，实现查询加速。目前该功能基于增量方式实现，主要支持仅追加场景，更新场景仍处于研发状态。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444053" alt="数据链路：物化视图上卷代替导入任务.png" title="数据链路：物化视图上卷代替导入任务.png" loading="lazy"/></p><p>异步物化视图能力的建表语句示例如下：</p><pre><code class="SQL">CREATE MATERIALIZED VIEW mv
BUILD DEFERRED
REFRESH INCREMENTAL
ON COMMIT
PARTITION BY (date)
DISTRIBUTED BY RANDOM BUCKETS 4
PROPERTIES ('replication_num' = '3') 
AS
SELECT 
  date, 
  k1+1 AS k2, 
  SUM(a1) AS a2
FROM
  paimon.data.table
WHERE date &gt;= 20250222
GROUP BY 1, 2;</code></pre><h3>04 自助化、精细化的资源管理</h3><p>为了优化资源管理与运维流程，我们自研了精细的 Doris Manager 集群管理服务，将用户的运维需求转化为自助操作，依托社区开源的 Doris Operator 在 Kubernetes 平台自动完成资源申请与释放，实现快速的集群变更。用户直接通过平台提交资源申请，无需等待平台申请机器、初始化、发布和上线等步骤，以集群扩容为例，交付周期从原先的约一周大幅缩短至分钟级，显著提升了运维响应速度与效率。</p><p>同时，通过 Doris Manager 集群自动化注册与发现能力，新集群创建的同时向元数据中心注册 Catalog，可自动被查询网关识别并接入统一访问入口，用户无需额外配置即可通过网关发起 Doris 查询，进一步优化了使用体验。</p><p>接入 Kubernetes 后，资源调度更加精细化，最小调度粒度从物理机级别转变为机器核心、内存大小、磁盘容量等维度，能够根据不同业务需求灵活调配资源，提高资源利用率，满足多样化的业务场景。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444054" alt="自助化、精细化的资源管理.png" title="自助化、精细化的资源管理.png" loading="lazy"/></p><h3>05 更完善的数据采集与可观测性</h3><p>在集群可观测性方面，基于 Kubernetes 的标准化组件，参照 OpenTelemetry 的规范对 Doris 的监控体系进行全面升级。通过 Prometheus 的 ServiceMonitor 机制采集 Doris 各组件的性能指标，为用户提供全面、细粒度性能监控数据。</p><p>在日志采集方面，采用自研的 Hera（log tail 组件）实现高效采集，同时，借鉴社区的日志检索场景实践，将 Doris 作为 OpenTelemetry 的存储后端：Doris 自身运行产生的日志经采集后，最终回流并存储至 Doris 内部表中，形成“日志产生-采集-存储-查询”的闭环。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444055" alt="更完善的数据采集与可观测性.png" title="更完善的数据采集与可观测性.png" loading="lazy"/></p><p>与之前仅支持基础指标采集的 Falcon 体系相比，Hera 架构覆盖了审计日志、监控指标、运行日志、Profiling 结果以及正在完善的分布式 tracing 信息，提供更加全面的综合诊断能力。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047444056" alt="更完善的数据采集与可观测性-1.png" title="更完善的数据采集与可观测性-1.png" loading="lazy"/></p><h2>后续规划</h2><p>感谢 Doris 社区始终保持高效的版本迭代节奏与稳定性打磨，后续我们将基于以下几方面展开工作：</p><ul><li><strong>完成 Doris 版本收敛工作</strong>：将核心功能并线至 2.1 和 3.0 版本，并统一工具链版本依赖以减少环境差异，最终实现开发迭代效率的显著提升，为后续功能迭代奠定高效基础。</li><li><strong>围绕湖仓一体能力进行深度优化</strong>：重点提升湖仓支持的完整性与稳定性，推动 Doris 存算分离架构的大规模落地，同时完善增量计算能力的覆盖范围，以满足复杂场景下的实时数据处理需求。</li><li><strong>拓展新场景与 AI 融合方向</strong>：孵化日志、Tracing 等数据存储能力，通过 AI for Doris 提升运维管理效率，并探索 Doris for AI 的反向赋能能力，构建数据平台与智能技术的双向协同生态。</li></ul>]]></description></item><item>    <title><![CDATA[Agent如何重塑跨角色协作的AI提效新]]></title>    <link>https://segmentfault.com/a/1190000047444074</link>    <guid>https://segmentfault.com/a/1190000047444074</guid>    <pubDate>2025-12-02 16:01:54</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>什么是Agent？</h2><p><strong>我们开始看到一种新的“AI劳动力市场”雏形：</strong> 需求Agent、设计Agent、前端 Agent、运营Agent、数据 Agent…它们就像数字版的“岗位角色”，但永不疲惫、随时可调度。你可以把它想象成：“团队里突然多了一些懂规则、懂产品、懂代码、懂设计的AI新同事。”总结起来，<strong>Agent是“有大脑和工具调用能力”的执行者，它能做到规划、执行、调用工具、持续推进任务，完成一整套动作，是能完成任务的角色化智能体。</strong></p><p>举个例子，产品经理收到反馈：“百度文心快码官网风格不统一、细节处理不够好，想把统一所有页面风格。”通常，这个需求需要经历这些步骤：PM写文档 → 工程师读文档 → 工程师提问 → PM 补充 → 工程师开发 → PM验收。整个过程会面临很多问题和重复沟通：信息不对称、上下文传递不完整、需求细节被误解、工程师要不断追问、PM要不断确认逻辑、文档永远不够完备...这其实不是人的问题，而是角色之间天然存在断层。PM要表达业务逻辑，工程师要进行工程落地，两条线靠文档、会议、人力“粘”在一起。<strong>而多Agent协同，可以打通PM↔FE（前端工程师）全链路，协作从人-人，升级成了人Agent-人。</strong></p><h2>案例1：Agent重构网站</h2><p>重构网站传统的工作流程非常繁琐，有很多步骤。有了Agent，能给传统工作流程带来啥变化呢？先来演示下：如何用Agent实现Comate官网重构。</p><p>Comate官网首页是偏黑色稍带星空主题，而案例页面、资讯页面等以白色为主，确实主题色不统一，来试试借助Agent，能否把统一主题的需求搞定。先让Agent梳理代码库中的主要页面：“我们要对主要页面进行风格统一，帮我罗列一下项目中主要的页面有哪些”。把需求告诉Agent，先拿一个案例页来试试：”请帮我把网站的主要页面统一成深色科技风格（黑色为主）。要求包括：主题是科技感和宇宙星空元素；统一个背景色（黑色+宇宙星空元素，宇宙星空元素要有很明显的效果）；统一布局宽度（max-width 1200px）；统一字符（font-ping-fang）；圆角统一8px；阴影（深色阴影+轻微蓝色发光）；字体颜色适配黑色背景，例如font-white；请基于上面的黑色科技风格，先帮我设计和改造“案例页”。</p><p>感觉星空科技感的效果不是很明显，跟Agent强调一下试试：“增加更多一些的科技感和宇宙星空的元素，丰富一下整体页面视觉效果”。这下看确实好多了，看来Agent也是喜欢聊天的，接下来适配一下其他页面：“基于刚才对案例页面的改动，同样的风格改造，对资讯页面也进行一下样式美化”。看看最终效果，简直是“买家秀”和“卖家秀”完全一致！</p><p>Agent重构Comate官网视频效果👉<a href="https://link.segmentfault.com/?enc=AcOhCQGg8PMGWuhQzYa4hw%3D%3D.Erl8Ot8K5lTHkBe6zYX1jzlWGHZQEI%2FGQTTS7AMK6ExBthetCmaWSHJ8k1x7KewT3ePnEiU3fia0mMiN6w2j4Q%3D%3D" rel="nofollow" target="_blank">https://mp.weixin.qq.com/s/crYJB7QB2WijFxvAJaeD2g</a></p><p><strong>Agent如何理解“风格”</strong> ？它不是靠关键词，而是扫描你的CSS/组件结构，建立“隐式风格模型”：阴影、字体、圆角、留白，还会根据已有页面推断“主题意图”。<strong>Agent最大的价值点是：</strong> 一次理解，多处改造；只说“换成黑色科技风”，就能给你统一方案；人类是逐页对比，而Agent可以全局扫描。</p><p>以前，公司每年至少有一次“大改UI”，会改主题改到崩溃。面对这种大改版，PM需要面临以下问题：</p><ul><li>UI/产品定一个规范，每个页面都要跟；</li><li>不同年代写的页面风格乱，很多页面的开发者可能来自不同的时间线，圆角大小不一、配色不同、字体不一致。</li><li>如果靠手动找、手动改，通常要2–7 天。</li></ul><p>作为PM，以前遇到这种“全站换肤”的需求，最头疼的就是“漏网之鱼”和“理解偏差”。比如PM说要有“科技感”，设计师认为是“赛博朋克”，前端认为是“蓝底白字”，最后做出来是“五彩斑斓的黑”。 而且往往改了首页、忘了详情页，或者改了按钮、忘了输入框。<strong>现在Agent能通过全局扫描代码，建立一个隐式的“风格模型”</strong> 。</p><p><strong>为什么“视觉类改造”是Agent的强项？</strong> 因为它能看到页面结构，不用一句句解释意图，有些Agent还能预估效果。有了Agent帮忙把信息加工好，减少了很多沟通成本，效果一目了然，需求“对齐成本”由Agent承担了～以前为了“一个圆角是4px还是8px”争论半天，现在Agent直接统刷一遍，大家都省心。有了Agent，<strong>让“执行型工作”被自动化，所有角色都往“判断、审阅、策略、决策”迁移</strong>，对传统的开发流程也产生了很大影响。</p><h2>案例2：Agent改造活动页</h2><p>上文演示了Agent如何高效完成复杂的需求对齐。接下来挑战一个更考验效率的场景：<strong>高频、短周期的运营活动页</strong>。马上就是圣诞节了，文心快码又要搞事情了！传统流程大家都很熟悉：运营、PM提想法 → 设计师出图 → 研发开发活动组件 → 漫长的沟通和反复调整。流程链路长，为了赶上线窗口大家往往都很疲惫。现在只用三步：<strong>运营、PM提想法 → Agent结合Rules快速产出页面骨架 → 研发同学做最终集成和收尾</strong>。</p><p>来演示下PM如何通过文心快码Agent创建一个圣诞活动页面吧～输入指令：“把1024活动页改造成一个文心快码圣诞节活动页，要求包含活动规则模块和醒目的Banner，风格必须符合公司Design System规范。”</p><p>Agent已经开始工作了，这时你可能会有疑问：Agent写的代码会不会不符合公司的规范？颜色、间距会不会乱套？这就涉及Agent协作中的一个秘密武器：<strong>Rules (工程规范)</strong> 。研发会预设好design-system.md文件，这里强制规定了品牌设计师预设的“圣诞红”色值、按钮的大小、间距规范等。 这就像是给Agent戴上了一套“紧箍咒”，保证生成的页面不管怎么变，都一定符合文心快码的品牌调性。有了这套内置了工程规范的Rules，就不用花费时间去做样式Review，也不用担心PM在提需求时，Agent会生成一个和品牌格格不入的页面。<strong>Agent真正成了团队代码质量的守门人。</strong></p><p>节日主题页永远赶时间，因为运营想要快：明天上线、今晚改，设计可能只有一张活动的头图，前端要把主题“套”到现有页面，很花时间。Agent做主题换肤时，能根据“头图+色板+关键词”推断风格，自动添加“雪花、红绿配色、圣诞元素”，能避免你手动处理一堆margin/transition。</p><p>Agent改造运营活动页为圣诞节风格视频👉<a href="https://link.segmentfault.com/?enc=MaH23mqB%2BbPsU9rr7Nmdwg%3D%3D.gp3A64Bdv%2BR24cmVA4JSC9mErGDfxssGB094OiFSkJlj5R81RjTMb%2B%2FJ9fpL1F%2BzP7rEhGC%2F0XnTBUyw%2FQ2fSw%3D%3D" rel="nofollow" target="_blank">https://mp.weixin.qq.com/s/crYJB7QB2WijFxvAJaeD2g</a></p><p>代码已经生成完成了，不仅组件和样式是规范的，连活动文案都自动填充好了：“圣诞狂欢，码力全开！” ，这可比让人头疼的各种ooxx虚拟占位符强太多了！</p><p>通过Agent，我们把原本需要三天的“PM/设计/FE协作流程”压缩到了<strong>几分钟，</strong> 这就是Agent重塑跨角色协作带来的提效新范式！</p><p><strong>人类擅长审美判断，Agent擅长重复性批量改造。</strong> 最快的方式是人类给审美方向，Agent批量铺开。我们甚至把团队里最资深运营同学的经验，做成了一个 <strong>“活动页面设计专家”</strong> 。它知道什么样的活动标题点击率高，什么样的布局转化率高。它生成的页面，是带着“运营智慧”的。</p><h2>案例3：Agent构建数据统计看板</h2><p>上文在Agent的帮助下，高效上线了一个活动运营页面。为了方便观测活动效果，提前准备好了数据统计表，来试试让Agent构建数据看板：“在src/app/[lng]/dataAnalyse路径里面，以 src/constants/dataAnalyse.ts里面的 ACTIVITY_DATA为数据基础，制作一个适配 ACTIVITY_DATA数据格式的数据统计页面，要求有：根据 trackUuid去重，统计uv和pv数据的Echart柱状图，以天为横轴；使用antd的table展示，适配ACTIVITY_DATA数据格式的表格数据”。</p><p>数据页涉及表格、分页、筛选，还要对接接口、处理 loading/error，有时候还要自定义图表样式。<strong>这个场景特别适合展示Agent的“组合能力”</strong> ，帮你选图表类型，根据字段自动生成表格+Axios+TS类型，帮你生成“骨架代码 + hook + layout”。<strong>人类给目标，Agent可以自动补全细节</strong>，你可以说：“我要展示日活突增原因”，Agent可以自动提示你需要：折线图、分析维度、时间范围选择等。数据类页面很适合自动化，因为未来可能直接“上传数据库结构 → 自动生成后台系统”。</p><p>这里有个难点：如果让人来写，得先去读懂 ACTIVITY_DATA的数据结构是数组还是对象？字段名是 date 还是 timestamp？然后得写去重逻辑，还得去查Echarts的配置文档——配置项多到让人头皮发麻。但来看Agent的操作：它第一步就读取了数据文件的类型定义（TypeScript Interface），准确得理解了“根据trackUuid去重”这个逻辑，并自动生成了lodash的去重代码。最关键的是，Echarts的配置代码，一次性就写对了，不用研发去翻文档复制粘贴。完成后打开页面看看：柱状图出来了，表格也出来了。</p><p>构建数据统计Agent，并共享给全项目成员使用视频效果👉<a href="https://link.segmentfault.com/?enc=J3w2gSsqKnEl80N6Eqq%2ByA%3D%3D.WRmfuO1p3MSvV208tMnL%2Bu0Ie%2Fa90sTCx2NhDE3eMK9ESoF8iK7ZMYxRkwrvA7%2Be3TV5JFXQDWcv8JukR5%2FUCg%3D%3D" rel="nofollow" target="_blank">https://mp.weixin.qq.com/s/crYJB7QB2WijFxvAJaeD2g</a></p><p>以后谁想看数据，把这个Agent分享给他就行，想要什么维度的数据，直接跟Agent说，它就能调整图表，这就叫 <strong>“数据民主化”</strong> 呀～</p><h2>Q&amp;A</h2><p><strong>Q1：Agent听起来很强，会不会造成依赖？会不会变得不会自己动脑？</strong></p><p><strong>A：</strong> 这和IDE自动补全刚出来时大家的担心一样，但其实，我们反而更能把时间放在系统性思考上。在协作层面，本质上Agent替代的是“重复性劳动”和“对齐成本”，而不是工程师和PM的判断力。可以说：<strong>Agent把我们从“低价值沟通”中解放出来，让我们能把脑力集中在更值得思考的地方。</strong></p><p><strong>Q2：既然Plan Agent能拆需求、Design Agent能产图，PM在团队里的价值是不是变弱了？</strong></p><p><strong>A：</strong> 以前PM很多时间花在“做文档、补图、翻译给研发”。现在这些都可以交给Agent，PM能把精力放到：业务策略、用户洞察、A/B方案决策、多Agent工作流的调度，<strong>PM的角色从“信息搬运工”升级成“智能团队的策划者”。</strong></p><p><strong>Q3：文心快码提供了非常多的Agent，有什么使用小窍门吗？</strong></p><p><strong>A：</strong> 想要高效使用文心快码的多Agent ，需要抓住三个关键词：<strong>专业化、高质量和强协同</strong>。</p><p>首先是专业化：按任务选对Agent。如果你要转设计稿，用Figma2code；遇到Bug，就交给Debug Agent。它们内置了专业的领域知识，效率是最高的。其次是高质量：要善用规范和审查。 像上文演示的，通过Rules确保 Agent不犯低级错误，让CodeReview Agent在代码提交前自动把关规范和逻辑，这样代码就能得到双重保障。第三点，也是最关键的：利用Architect实现强协同。 Agent之间不是孤立的，一些复杂的研发任务可以通过Architect定义一个工作流，将DeepRead Agent、Actor Agent和WebSearch Agent串联起来，让它们像流水线一样自动化分析和拆解复杂任务并执行。</p><p><strong>Q4：怎么让Code Agent不乱改自己的项目？</strong></p><p><strong>A：</strong> Agent有时会越界，改动一些不需要它做的事情。Agent的能力强在“广度 + 主动性”，但也正因为主动性强，它极易越界，所以必须用规则（Rules）把它的活动范围、权限、约定全部框住。Rules不是限制能力，而是保障结果可控、可预期。</p><p><strong>Q5：演示过程中，对话首页有一个Spec Mode，这是什么新功能？</strong></p><p><strong>A：</strong> Spec模式是一种新的协作方式：让Agent先把它的理解与计划写成文档，把要做的事情拆成任务，经过用户确认再进行相应的代码编写，从而让Agent的代码生成质量和效果大幅提升。<strong>通过Spec，任务一次成功率显著提升、返工大幅减少、代码质量更稳。</strong> 目前Spec还处于Beta阶段，欢迎大家尝鲜试用，并提出意见，共同成长～</p>]]></description></item><item>    <title><![CDATA[活动预告｜IvorySQL 与您相约 C]]></title>    <link>https://segmentfault.com/a/1190000047444081</link>    <guid>https://segmentfault.com/a/1190000047444081</guid>    <pubDate>2025-12-02 16:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>COSCon'25 第十届中国开源年会，将于 2025 年 12 月 6-7 日，在北京市海淀区·丽亭华苑酒店举办。本次大会的主题是：「众智开源 Open Source， Open Intelligence」！</p><ul><li>📅 活动时间：2025 年 12 月 6-7 日</li><li>📌 活动地点：北京市海淀区 · 丽亭华苑酒店</li></ul><p>中国开源年会（COSCon） 由开源社于 2015 年发起，九年来已成长为国内最具影响力的开源盛会之一。COSCon 始终坚持中立社区定位，吸引了国内外众多企业、高校和组织的支持，推动开源从技术圈的“小众实践”发展为驱动产业创新的“核心力量”。</p><p>站在新的十年起点，本届大会以“众智开源”为主题，旨在汇聚全球智慧，探索“人类 + 机器”协同创智的全新可能。在 AI 深度融合的时代，开源已超越代码共享，成为汇聚全球集体智慧的创新引擎，而社区是构建生态的核心命脉。</p><p>IvorySQL 将参与本次大会，在本次大会中进行演讲和集市互动。</p><h2>演讲预告</h2><p>瀚高研发工程师、IvorySQL 贡献者梁翔宇将在本次大会周日（12 月 7 日）下午的云原生开源论坛中进行主题演讲：云原生数据库的变革及 IvorySQL 云原生的实践。</p><p>分享内容简介：</p><ol><li>云原生数据库演进之路</li></ol><ul><li>简述数据库从物理部署到虚拟机部署，最终过度到云原生部署的过程。</li><li>云原生部署数据库的变化。</li></ul><ol start="2"><li>IvorySQL 云原生的实践</li></ol><ul><li>IvorySQL 在云原生项目上做过的实践及对应项目。</li></ul><h2>集市互动</h2><p>经过组委会的精心遴选，33 家各具特色的开源社区、开发者组织与媒体伙伴将在 COSCon'25 第十届中国开源年会与大家相遇。IvorySQL 也位列其中。</p><p>我们准备了多种社区周边礼品，与各位到场的参会小伙伴互动交流。欢迎各位小伙伴到集市区打卡赢取礼品！</p>]]></description></item><item>    <title><![CDATA[嵌入软件单元测试的全面研究与实践 Tom]]></title>    <link>https://segmentfault.com/a/1190000047443464</link>    <guid>https://segmentfault.com/a/1190000047443464</guid>    <pubDate>2025-12-02 15:06:05</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>引言<br/>嵌入软件单元测试是确保嵌入式系统质量和可靠性的关键环节。嵌入式系统广泛应用于汽车电子、工业控制、医疗设备等关键领域，其软件直接操控硬件，任何微小的错误都可能导致严重后果。单元测试作为软件开发过程中最早进行的测试活动，能够有效隔离代码片段，验证其功能是否符合设计预期，从而在早期阶段发现潜在缺陷，提升代码质量。本文将系统探讨嵌入软件单元测试的标准流程、方法论、工具选择、工程师能力要求、实际案例以及最新技术发展趋势。<br/>嵌入软件单元测试的标准流程与方法论<br/>嵌入式软件单元测试流程<br/>嵌入式软件单元测试通常遵循"静态测试在先、动态测试在后"的准则，确保验证过程可靠且闭环。完整的测试流程包括以下几个关键步骤：</p><ol><li>‌需求输入阶段‌：需要《软件单元设计规范》、《软件接口规范》、《软件开发环境文档》等文档作为验证过程的需求输入。功能安全侧重于对活动过程的检查和确认，因此对重要步骤的审查是非常有必要的。</li><li>‌静态测试阶段‌：通过代码分析工具检查代码规范、潜在空指针等问题，适用于编码规范严格的嵌入式项目。静态测试不执行代码，而是通过分析源代码结构来发现问题。</li><li>‌动态测试阶段‌：执行代码并验证输出，常用框架包括CppUTest、Unity等，支持断言机制与覆盖率统计。动态测试又分为：<br/>o    ‌主机测试(On-Host/Native Testing)‌：将嵌入式代码在PC上编译和运行，通过"隔离硬件依赖"实现。优点是速度快、易自动化、调试方便。<br/>o    ‌目标机测试(On-Target Testing)‌：将测试代码编译并刷写到实际硬件运行，通过串口、LED、调试器输出结果。优点是环境真实，缺点是测试缓慢、难以自动化、调试困难。</li><li>‌覆盖率分析‌：评估测试用例对代码的覆盖程度，包括语句覆盖、分支覆盖、条件覆盖等指标。汽车电子ISO 26262、航空DO-178C等标准明确要求C1(分支覆盖)≥100%，MC/DC(修正条件判定覆盖)≥100%。<br/>嵌入式单元测试方法论<br/>嵌入式系统单元测试面临诸多独特挑战，需要采用专门的方法论：</li><li>‌硬件解耦测试‌：通过模拟硬件接口(如使用Mock对象)，开发者可在主机环境(如PC)进行测试，减少对物理设备的依赖。例如，使用CppUTest框架测试RTOS任务切换逻辑时，需模拟调度器、信号量等20+桩模块。</li><li>‌实时性验证‌：针对时间敏感型任务，单元测试可验证代码执行时间是否满足截止期限。例如，汽车ABS控制模块的测试可验证刹车压力计算算法在不同轮速差下的响应逻辑。</li><li>‌资源优化保障‌：测试用例可监测内存泄漏、栈溢出等问题，确保代码在有限资源下稳定运行。</li><li>‌测试驱动开发(TDD)‌：先编写测试用例再实现功能，确保代码高度可测性，特别适合算法模块开发。TDD的核心原理是想要实现什么功能，先编写这些功能的测试代码，而后使其测试报错，而后再在框架上做函数实现，一点一点的使测试通过。</li><li>‌硬件在环(HIL)测试‌：结合硬件仿真器，在接近真实环境中验证代码与硬件的交互。这种方法设备成本高达50万美元/套，但能提供最真实的测试环境。<br/>嵌入式单元测试工具比较与WinAMS详解<br/>主流单元测试工具对比<br/>嵌入式软件单元测试工具种类繁多，各有特点：<br/>工具类型    代表工具    主要特点    适用场景<br/>通用单元测试框架    JUnit, NUnit, PyTest    支持多种语言，功能全面    非嵌入式系统开发<br/>嵌入式专用框架    CppUTest, Unity    轻量级，资源占用少    资源受限的嵌入式环境<br/>静态分析工具    CasePlayer2    检查代码规范，预防潜在问题    编码规范检查<br/>动态符号执行工具    Parasoft C/C++test    自动探索代码路径生成测试用例    复杂逻辑验证<br/>目标代码级测试工具    WinAMS    直接对机器码测试，避免插桩失真    高安全性要求的嵌入式系统<br/>WinAMS单元测试工具详解<br/>WinAMS是一款针对嵌入式软件的单元测试工具，由日本gaio公司开发，专注于嵌入式软件测试领域。该工具具有以下核心特点和技术优势：</li><li>‌目标代码级测试技术‌：直接对交叉编译后的机器码进行测试，规避插桩导致的覆盖率失真。这是WinAMS的核心技术突破，特别适合对安全性要求极高的嵌入式系统。</li><li>‌无需源代码改动‌：WinAMS无需对原代码进行修改即可搭建测试框架，大大降低了测试准备工作的复杂度。</li><li>‌行业合规认证‌：WinAMS取得了汽车功能安全(ISO26262)的工具认证，已服务于日本所有主要汽车制造商及汽车供应商。</li><li>‌覆盖率分析能力‌：WinAMS提供全面的代码覆盖率分析，包括语句覆盖、分支覆盖、条件覆盖等关键指标，帮助开发者识别测试盲区。</li><li>‌自动化测试支持‌：通过自动化测试流程，WinAMS能够显著提高测试效率，减少人工干预，确保测试结果的一致性和可靠性。<br/>WinAMS特别适用于汽车电子、航空航天等对安全性要求极高的领域。在这些行业中，软件缺陷可能导致严重后果，因此需要严格的测试流程和工具支持。WinAMS通过其独特的目标代码级测试方法，为这些行业提供了可靠的解决方案。<br/>嵌入式测试工程师能力要求与培养<br/>测试工程师核心能力体系<br/>合格的嵌入式测试工程师需要具备全面的能力体系，主要包括以下几个方面：</li><li>‌测试基础能力‌：<br/>o    ‌测试用例设计能力‌：熟练掌握等价类划分、边界值分析、判定表、状态迁移等黑盒测试方法，同时理解白盒测试中的语句覆盖、分支覆盖等逻辑覆盖准则。<br/>o    ‌缺陷管理能力‌：从缺陷的识别、记录、跟踪到闭环，建立规范的流程意识。优秀的缺陷报告应包含清晰的重现步骤、环境信息、预期与实际结果对比，以及必要的日志和截图。<br/>o    ‌文档撰写能力‌：能够编写结构清晰、表述准确、重点突出的测试计划、测试方案和测试报告等文档。</li><li>‌自动化测试技术栈‌：<br/>o    掌握主流自动化测试工具的使用，如Jenkins、Selenium等。<br/>o    理解持续集成和持续测试(CI/CD)流程，能够将单元测试集成到自动化流水线中。<br/>o    熟悉脚本语言(如Python、Shell)，能够编写自动化测试脚本。</li><li>‌嵌入式系统专业知识‌：<br/>o    理解嵌入式系统架构和实时操作系统(RTOS)原理。<br/>o    熟悉常见嵌入式通信协议(如CAN、LIN、I2C、SPI等)。<br/>o    了解硬件接口编程和驱动程序开发基础。<br/>嵌入式测试工程师培养方法<br/>培养合格的嵌入式测试工程师需要系统化的方法和路径：</li><li>‌基础知识学习‌：<br/>o    软件测试理论基础：学习软件生命周期、测试类型、测试方法等基础知识。<br/>o    嵌入式系统知识：掌握微控制器架构、实时操作系统原理、嵌入式通信协议等。</li><li>‌实践技能培养‌：<br/>o    从简单的嵌入式项目开始实践单元测试，逐步增加复杂度。<br/>o    学习使用主流单元测试框架，如Unity、CppUTest等。<br/>o    参与实际项目，积累测试用例设计、缺陷分析和报告编写经验。</li><li>‌工具链掌握‌：<br/>o    熟悉版本控制工具(如Git)和持续集成工具(如Jenkins)。<br/>o    掌握静态分析工具和覆盖率分析工具的使用。<br/>o    学习专业测试工具如WinAMS的操作和应用。</li><li>‌行业标准学习‌：<br/>o    研究汽车电子ISO 26262、航空DO-178C等行业标准对测试的要求。<br/>o    了解功能安全概念和相关的测试方法论。<br/>单元测试实践案例与经验教训<br/>成功案例</li><li>‌汽车ABS控制模块测试‌：<br/>通过单元测试验证刹车压力计算算法在不同轮速差下的响应逻辑，无需在真实车辆中触发极端条件，显著提高测试安全性及效率。测试过程中使用了硬件接口模拟技术，实现了软硬件并行开发。</li><li>‌平均值计算函数测试‌：<br/>一个简单的嵌入式C函数示例展示了单元测试的实际应用。开发者首先编写测试用例，然后实现函数功能，确保每个边界条件都被测试到。这种方法有效发现了整数除法精度问题。</li><li>‌轻量级单元测试框架应用‌：<br/>Unity框架被成功应用于多个嵌入式C项目。其核心只有unity.c + unity.h + unity_internals.h，一个C文件、一对头文件，全部通过宏和编译选项配置，0运行时动态分配，非常适合资源受限的嵌入式环境。<br/>失败教训分析</li><li>‌单元测试"无用论"误区‌：<br/>o    ‌时机不当‌：项目开始之初未引入单元测试，后期代码耦合度高，拆分工作困难。<br/>o    ‌方法不当‌：未结合代码覆盖率分析，无法保证测试效果。<br/>o    ‌管理层期望不匹配‌：单元测试是耗时工作，但管理者往往希望在短期内看到效果。</li><li>‌嵌入式常见缺陷类型‌：<br/>o    ‌事件顺序问题‌：事件可以以不同的顺序到达，未考虑事件缺失或重复的情况。<br/>o    ‌过早问题‌：信令消息在配置和启动程序完成之前就被过早接收，导致奇怪行为。<br/>o    ‌悄无声息的故障‌：代码静静失败并扩展而非抛出错误，使调试变得困难。</li><li>‌嵌入式开发经验总结‌：<br/>o    ‌if语句问题‌：复杂的if条件容易出错，特别是当有多个条件要跟踪时。<br/>o    ‌else分支缺失‌：未考虑条件为false时的情况，导致未定义行为。<br/>o    ‌假设改变‌：初始假设(如每天只有一个客户事件)后来被改变，导致原有代码出现问题。<br/>嵌入式单元测试最新研究与发展趋势<br/>AI在单元测试中的应用<br/>随着AI技术在软件开发中的深度集成，单元测试范式正在发生转变：</li><li>‌AI驱动的测试平台‌：<br/>o    通过学习海量代码数据，自动识别常见错误模式，如未初始化指针或资源泄漏。<br/>o    结合控制流分析提出修复建议，自动生成RAII封装等安全代码结构。</li><li>‌当前局限性‌：<br/>o    在应对复杂硬件交互时仍存在明显短板。某新能源汽车企业的实践显示，AI工具为电池管理模块生成的1800个基础测试用例中，23%无法通过硬件在环验证。<br/>o    特别是在模拟ECU不同时钟频率下的响应延迟时表现不佳，表明在嵌入式领域，传统单元测试方法与AI技术的结合仍需进一步探索。<br/>单元测试技术发展趋势<br/>2024-2025年，嵌入式软件测试领域呈现以下主要技术趋势：</li><li>‌虚拟化与模拟技术‌：<br/>o    测试人员能够在不同硬件架构和操作系统环境下对嵌入式软件进行测试，无需依赖实际物理设备。<br/>o    汽车电子模拟器可模拟各种传感器输入和执行器输出，大大降低测试成本。</li><li>‌基于模型的测试(MBT)‌：<br/>o    通过建立软件系统的行为模型(如状态机模型、数据流模型)自动生成测试用例并执行测试。<br/>o    提高测试完整性和准确性，特别适合复杂嵌入式系统的验证。</li><li>‌持续集成和持续测试‌：<br/>o    随着软件开发速度加快，持续集成和持续测试已成为趋势。<br/>o    通过自动化测试手段快速发现缺陷并进行修复，提高软件质量和交付速度。</li><li>‌云测试和边缘计算结合‌：<br/>o    通过将云端资源和边缘设备相结合，实现更高效、更灵活的自动化测试。<br/>o    同时降低测试成本，提高测试资源的利用率。<br/>结论<br/>嵌入软件单元测试是确保嵌入式系统质量和可靠性的关键环节。随着嵌入式系统在汽车电子、工业控制、医疗设备等关键领域的广泛应用，单元测试的重要性日益凸显。本文系统探讨了嵌入软件单元测试的标准流程、方法论、工具选择、工程师能力要求、实际案例以及最新技术发展趋势。<br/>实践表明，采用专业的单元测试工具如WinAMS，结合适当的测试方法论(如TDD)，能够显著提高嵌入式软件的质量和可靠性。同时，测试工程师需要具备全面的能力体系，包括测试基础能力、自动化测试技术栈和嵌入式系统专业知识。<br/>未来，随着AI、虚拟化与模拟技术、基于模型的测试等前沿技术的发展，嵌入式单元测试将变得更加智能化和高效。然而，这些新技术的应用也带来了新的挑战，需要业界持续研究和创新。<br/>总之，嵌入软件单元测试是一项复杂而重要的工作，需要开发团队、测试工具和行业标准的共同努力。只有通过严格的单元测试，才能确保嵌入式软件的安全性、健壮性和可靠性，满足日益严苛的行业要求。</li></ol>]]></description></item><item>    <title><![CDATA[NeurIPS 2025！采样成本降 5]]></title>    <link>https://segmentfault.com/a/1190000047443502</link>    <guid>https://segmentfault.com/a/1190000047443502</guid>    <pubDate>2025-12-02 15:05:30</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>NeurIPS 2025！采样成本降 50%+ 准确率提升！南大等团队的RPC方法刷新 LLM 推理上限</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047443504" alt=" " title=" "/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047443505" alt=" " title=" " loading="lazy"/></p><p>论文标题：<em>A Theoretical Study on Bridging Internal Probability and Self-Consistency for LLM Reasoning</em></p><p>作者团队：南京大学、瑞士苏黎世联邦理工学院</p><p>发布时间：2025年10月17日</p><p><a href="https://link.segmentfault.com/?enc=QuFqhUYUibmsMipAXLSIRA%3D%3D.%2BN53%2FOCxfDhfuMgAsh609GOwe4PVce7eE75Veyqklp4JiqpYkxMOEOrj0uVPPT60" rel="nofollow" target="_blank">👉一键直达论文</a></p><p><a href="https://link.segmentfault.com/?enc=PK5zpSzUWhdwxuQI9cQmWQ%3D%3D.ePuBr%2BWVanL3LfnyWpD%2FEKA9VIZ%2F7j8KwzJP4U40etsdAQN8tUNA5wXf%2FG3u078dptJxoTP4BZ6sk3MB5SO4dZdYcXl1ThrqMk%2Fw5xqAUUP6cE1DFoP8xiQHbdkor3aD1zRMgTqp8Wx9L071r7cdknwCes%2FscmSRumcAlnydbjA%3D" rel="nofollow" target="_blank">👉Lab4AI大模型实验室论文阅读</a></p><p>✅Lab4AI平台提供AI导读和AI翻译等工具，辅助论文阅读。您还可以投稿复现这篇论文~</p><h3>⭐核心贡献</h3><ul><li>理论框架：首次提出用于分析LLM推理中采样式测试时缩放方法的理论框架，将推理误差分解为估计误差和模型误差。</li><li>方法创新：提出RPC方法，融合自洽性和内部概率的优势，通过Perplexity Consistency和Reasoning Pruning组件解决现有方法的局限性。</li><li>实证验证：在多个基准数据集上验证RPC的有效性，显著降低采样成本并提升推理性能。</li></ul><h3>⭐研究方法</h3><ul><li>误差分解理论：将推理误差分解为估计误差（与采样规模和置信度估计策略相关）和模型误差（由LLM固有推理能力决定）。</li><li>现有方法分析：自洽性估计误差收敛慢（线性），困惑度模型误差大且估计误差优势在低概率路径下退化。</li><li><p>RPC方法设计：</p><ul><li>Perplexity Consistency：将LLM内部概率融入自洽性框架，以指数级速率降低估计误差。</li><li>Reasoning Pruning：通过混合威布尔分布建模概率分布，自动过滤低概率路径，防止估计误差退化。</li></ul></li></ul><p>⭐研究结果</p><ul><li>效率提升：RPC在达到与自洽性相同性能时，所需采样数量减少50%以上。</li><li>性能优化：在7个基准数据集上，RPC平均准确率优于基线方法（如数学推理任务提升1.29%）。</li><li>可靠性增强：RPC的置信度估计更接近真实置信度（预期校准误差更低）。</li><li>泛化性验证：在代码生成（如HumanEval）和逻辑推理（如LogiQA）任务中均表现优异。</li></ul>]]></description></item><item>    <title><![CDATA[Access可视化进阶：散点图的底层逻辑]]></title>    <link>https://segmentfault.com/a/1190000047443514</link>    <guid>https://segmentfault.com/a/1190000047443514</guid>    <pubDate>2025-12-02 15:04:51</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>hi，大家好！<br/>今天我接着来聊access的新图表。在数据分析的语境下，当我们想要探究两个数值型变量之间是否存在某种关联（例如：广告投入与销售额的关系、设备运行温度与故障率的关系）时，散点图（Scatter Plot） 是无可替代的工具。<br/>虽然 Access 的强项在于数据管理，但作为全栈开发者，我们经常需要在窗体或报表中直接呈现这种分析结果，而不是每次都将数据导出到 Excel。<br/>在开始开发前，必须理清一个在 Access 开发中常被混淆的概念：散点图不是折线图。<br/>👀折线图 (Line Chart)：X 轴通常是分类变量（如月份、部门、人员）。即使 X 轴显示的是数字，Access 往往也会将其视为等间距的“类别”标签。<br/>👀散点图 (XY Scatter)：X 轴和 Y 轴必须都是数值型变量（Continuous Data）。数据点在坐标系中的位置完全由 (x, y) 两个数值决定，X 轴的刻度是连续且成比例的。</p><h2>01创建数据</h2><p>第一步还是一样，我们先创建一张表。<br/><img width="513" height="589" referrerpolicy="no-referrer" src="/img/bVdnenI" alt="" title=""/></p><h2>02创建图表</h2><p>还是老步骤，数据有了，我们就可以直接创建图表了。<br/><img width="188" height="208" referrerpolicy="no-referrer" src="/img/bVdnenJ" alt="" title="" loading="lazy"/></p><p><img width="486" height="462" referrerpolicy="no-referrer" src="/img/bVdnenL" alt="" title="" loading="lazy"/></p><h2>03图表设置</h2><p>接着就可以添加一下数据源了，数据源就选择我们创建的表，其他的按我的截图调整一下设置。<br/><img width="329" height="690" referrerpolicy="no-referrer" src="/img/bVdnenN" alt="" title="" loading="lazy"/></p><h2>04运行</h2><p>最后，我们就可以运行看一下效果了。<br/><img width="723" height="474" referrerpolicy="no-referrer" src="/img/bVdnenQ" alt="" title="" loading="lazy"/></p><p>散点图对数据的质量要求都非常高。在 Access 中处理数据源时，务必注意以下几点：</p><ul><li>空值处理 (Null Handling)：<br/>X 或 Y 轴任意一个值为 Null，该点都无法绘制。</li><li>异常值剔除 (Outlier Removal)：<br/>一个极端的异常值（例如录入错误的 999999）会压缩整个坐标轴，导致其他点挤成一团。建议使用 SQL 剔除标准差之外的数据，或在查询中限制范围。</li><li>数据类型转换：<br/>确保参与绘图的字段在表设计中是 Number (Double/Integer) 或 Currency 类型。如果是文本类型的数字，必须在查询中使用 CDbl() 进行转换，否则坐标轴排序会出错。</li></ul><p><strong>😊总结</strong></p><p>在 Access 中开发散点图，本质上是数据分析能力在业务系统中的延伸。对于快速查看趋势、简单的内部报表，推荐使用 Access 现代图表控件，开发效率最高。对于对外展示、需要复杂交互或大数据量的场景掌握散点图的开发，意味着你的 Access 系统不再仅仅是一个数据录入工具，而是一个具备初步商业智能（BI）属性的分析平台。喜欢这篇文章吗？欢迎点赞、转发，让更多 Access 爱好者看到！</p>]]></description></item><item>    <title><![CDATA[重塑研发管理：Geega捷做的协同价值 ]]></title>    <link>https://segmentfault.com/a/1190000047443524</link>    <guid>https://segmentfault.com/a/1190000047443524</guid>    <pubDate>2025-12-02 15:04:04</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>当前，制造业正处在一个前所未有的变革十字路口。市场节奏日益加快，技术迭代日新月异，消费者对产品的需求也变得更加个性化和复杂化。在这一切变化之下，研发管理领域却常常暴露出血淋淋的痛点，成为企业转型升级的瓶颈。设计数据分散各处，版本混乱难以追溯；流程审批依赖人工，效率低下且容易出错；零部件复用率低，重复设计频发，资源浪费严重……这些看似独立的问题，实则相互交织，导致项目频繁延期、协作成本高昂、返工现象普遍，严重拖累了企业的创新速度和市场响应能力。对于许多离散制造企业而言，如何打破这些桎梏，实现研发管理的质效飞跃，是一个亟待解决的命题。<br/>广域铭岛推出的Geega捷做设计研发协同平台，正是试图回答这一命题的实践者。它不仅仅是一个工具，更是一种面向离散型制造业的研发管理新思路，旨在打通从用户需求到产品交付的全链条，让研发真正“活”起来。想象一下，一个项目不再需要穿梭于不同的系统和文档之间，不再有孤立的审批环节和信息壁垒。Geega捷做致力于构建这样一个统一的研发数据中枢，通过整合PDM（产品数据管理）、Fview（三维数据轻量化协同）和FMEA（功能失效模式与影响分析）等核心组件，为企业提供一套覆盖研发全流程的数字化解决方案。<br/>在数据管理方面，Geega捷做的强项在于“精准”与“有序”。它能自动触发审批流程，让审批人员在移动端就能轻松处理，审批与设计活动无缝衔接，告别了以往“来回跑批”的低效模式。更重要的是，它能打通信息壁垒，让不同部门的人员都能从项目维度出发，在同一个平台上查看所需的产品数据——版本、BOM结构、模型等，确保信息的一致性和透明度。这一点在实际应用中效果显著，某制造企业在引入后，不仅实现了研发数据的规范管理，版本准确率达到了惊人的100%，审批效率更是提升了40%，项目交付周期被大幅缩短，零部件复用率提高了35%，BOM数据的准确率也高达80%。这不仅仅是效率的胜利，更是对研发质量的有力保障。<br/>然而，研发管理的挑战不仅仅在于数据本身。三维模型，作为设计的核心载体，其协作效率常常令人扼腕。设计完成后，模型数据静静躺在PDM/PLM里，难以被快速访问和查看。格式不一、软件部署复杂、数据交换困难，这些都是非设计部门在访问模型时头疼的问题，严重影响了跨部门协作的流畅性。Geega捷做-Fview应运而生，它扮演着三维数据轻量化协同的“破冰者”角色。兼容60多种CAD格式，支持跨格式模型转换与查看，这是其基础能力。但更关键的是，它能根据BOM结构的变化实时加载更新模型数据，让销售、生产、质量等人员都能便捷地在线互动，例如，销售通过网页展示，生产人员扫码查看工序模型，质量在线评审，设计人员浏览器渲染。某科技企业应用后，模型查看效率提升了60%，跨部门协作周期缩短了50%，数据准备时间更是锐减了75%。这种转变，将三维模型的静态价值转化为动态协同的生产力。<br/>如果说PDM和Fview是解决数据流通和可视化的“前台”，那么Geega捷做-FMEA便是研发质量管理的“后台”守护神。FMEA，功能失效模式与影响分析，本应是研发过程中不可或缺的预防性工具，但在很多企业中，它却沦为了一种形式化负担。原因何在？成本高效率低、标准理解不足导致数据缺失、经验难以传承、版本管理混乱……Geega捷做-FMEA通过智能分析引擎和完善的质量知识体系，重新诠释了FMEA的价值。它能自动匹配分析对象，推送相关知识和历史数据，大幅减少人工搜集的繁琐。基于庞大的历史问题库，它不仅能分析失效原因，还能推荐整改措施，让FMEA从一项被动应对的任务，转变为一种主动出击的预防策略。尤其在项目前期，它能一键生成DFMEA（设计FMEA）的全流程分析，预判潜在失效模式，智能关联质量问题，清晰展示风险矩阵。某制造企业应用后，FMEA的编制效率提升了20%，表单自动化率达到了100%，质量管理实现了从“事后补救”到“源头预防”的根本性转变。<br/>Geega捷做设计研发协同平台的价值并不仅限于单个模块的优秀表现，而在于其各组件之间的协同效应。它已经成功应用于整车、零部件、高端装备、电子制造等多个行业，帮助企业在研发流程标准化、数据一致性、效率提升和线上协同等方面取得了显著成效。无论是构建有序规范的数据基础，优化设计过程，还是实现资源共享，Geega捷做都在助力企业打造数字化时代的核心研发竞争力。<br/>在制造业数字化转型的浪潮中，Geega捷做设计研发协同平台如同一股清流，它不仅仅是在完成研发任务，更是在重新定义研发管理的逻辑。广域铭岛通过这一平台，向市场展示了其在解决实际问题、提升企业效能方面的实力。对于寻求突破的研发管理者而言，Geega捷做提供了一个值得探索的路径，它帮助企业在数据驱动的背景下，实现研发管理方式的深刻变革，从而在未来的市场竞争中占据更有利的位置。这是一次关于效率、协同与创新的重塑之旅。</p>]]></description></item><item>    <title><![CDATA[非凸科技与九方智投达成战略合作，携手赋能]]></title>    <link>https://segmentfault.com/a/1190000047443594</link>    <guid>https://segmentfault.com/a/1190000047443594</guid>    <pubDate>2025-12-02 15:03:30</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>11月18日，以“量化共赢 智领新程”为主题的九方智投“星级服务”新品发布暨非凸战略合作签约仪式在上海隆重举行。非凸科技与九方智投控股旗下九方智投正式签署战略合作协议，标志着双方在量化投资与科技赋能领域的合作进入新阶段，共同探索量化服务投资者的创新路径。<br/><img width="550" height="367" referrerpolicy="no-referrer" src="/img/bVdnepj" alt="image.png" title="image.png"/><br/>发布会上，九方智投控股创始人、董事长主席兼CEO陈文彬在《个人投资者量化新纪元》主题演讲中指出，“现阶段，正是实现量化从服务机构向服务个人转变、从间接投资走向直接投资的关键窗口，也是不断推进‘投资平权’的最佳时机。”他将AI技术的发展视为“天时”，将持续向好的市场环境比作“地利”，并将九方智投与非凸科技等企业所展现的自我突破与行业使命感，概括为实现这一愿景的“人和”。<br/><img width="552" height="368" referrerpolicy="no-referrer" src="/img/bVdnepk" alt="image.png" title="image.png" loading="lazy"/><br/>非凸科技联合创始人、CEO王浚澎在《科技赋能投资 AI普惠万家》主题分享中表示，公司正通过融合普惠AI算法与机器学习等技术，打造覆盖全生态的数智交易解决方案。他强调，顶尖的交易技术不应仅为机构投资者所独享，而应真正惠及更广大的中小投资者群体。</p><p>非凸科技致力于将专业的量化金融服务“触手可及”地提供给个人投资者。未来，双方将通过优化操作流程、提升策略响应速度等，让专业级服务真正落地到个人投资者的每一次投资行为中。<br/><img width="548" height="365" referrerpolicy="no-referrer" src="/img/bVdnepp" alt="image.png" title="image.png" loading="lazy"/><br/>我们坚信，随着战略合作的深化推进，非凸科技与九方智投将在策略研发、技术融合与生态共建方面协同共进，不仅为双方发展注入强劲动能，更将携手推动行业向更智能、更普惠的方向演进。未来，非凸科技将持续以技术为驱动，助力每一位投资者在波澜壮阔的市场中驭浪前行，智见未来。</p>]]></description></item><item>    <title><![CDATA[如何实现汽车产业链智能化以提升生产效率？]]></title>    <link>https://segmentfault.com/a/1190000047443641</link>    <guid>https://segmentfault.com/a/1190000047443641</guid>    <pubDate>2025-12-02 15:02:39</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在工业4.0和数字化浪潮席卷全球制造业的今天，汽车产业链正经历一场深刻的结构性变革。从整车制造到零部件研发，从传统机械加工到智能化系统集成，技术创新与智能化应用为整个行业重塑了竞争格局，推动其向更高层次迈进。中国作为一个全球制造业的重要枢纽，正在积极融入这场技术驱动的产业革命，并通过政策支持、企业实践以及跨界合作多维度构建智能化生态系统。其中，广域铭岛作为工业技术领域的先锋，通过其独特的工业互联网平台和智能制造解决方案，为汽车产业链的智能化演进注入了强劲动力。<br/>在中国“双碳”战略与技术革新的双重驱动下，传统汽车制造模式显然已无法满足现代市场对效率、质量与可持续发展的要求。智能工厂的建设成为这一趋势的核心载体。根据相关统计，中国目前已建成超过3.5万家基础级、7500余家先进级、500余家卓越级智能工厂，并显著提升了产业链关键指标，如平均降低20%的碳排放、缩短30%的产品研发周期、提高生产效率等。广域铭岛通过其Geega工业互联网平台，将设计、生产、管理和服务一以贯之，逐步实现从“经验试错”向“预测制造”的技术演进，塑造了一个整体协调、数据驱动的未来汽车制造蓝图。<br/>例如，在冲压工艺领域，广域铭岛的模具智能管理APP通过监测冲次数据和设备状态，将故障预警能力提升至48小时超前预判，大幅减少停机时间；而在焊接制造环节，其研发的控制系统应用了5G与深度学习算法，实现了焊接质量从经验依赖到数据驱动的创造性升级。关键数据表明，这些智能化举措使电极寿命延长30%，缺陷比例控制在小于0.02%，为企业实现了综合实力的质提升。<br/>与此同时，汽车零部件的智能化变革也加速推进，成为产业链重构的重要支点。零部件行业正从单个技术环节的优化向全周期协同控制转变，尤其在新能源车型与轻量化材料需求上升的过程中，智能制造更具战略意义。轻量化技术成为其中的焦点之一。研究表明，汽车重量每降低10%，油耗可减少6%-8%，而轻量化铝制零件的市场潜力正被装备制造企业在夹具与装配系统中释放出来。像广域铭岛这样深耕数字技术的企业，在预测性维护、能耗优化及产品质量管理上均提供了创新范例。<br/>人工智能、5G和大数据正在加速破壁，从初始辅助工具逐步转化为生产线的智能大脑。数字孪生工厂建设成为工业AI落地的有力证明，不仅汇聚了全息数据，还实时映射了产线运行效果，使制造商能够精准决策、高效反馈调整需求。从产品设计延伸至生产排程的“闭环控制”理念也在车企中广泛采纳，并结合FastWorx等协同平台，优化了模具开发、参数配置和装配逻辑。<br/>对于更广泛的价值链而言，这种智能化不仅提升了单个企业的制造能力，更重构了其生态合作关系。越来越多企业采用开放式架构与工业APP集合，如广域铭岛构建的生态平台已覆盖200余家设备与技术供应商，形成了协同发展的良性循环。在这一机制下，企业能够以远低于传统部署周期的时间完成设备集成与参数调试，为产业链的加速运转提供了基础条件。<br/>空间布局方面，伴随政策红利和产业链整合，汽车智能化重心正向智能底盘、预测性质量维护、全链协同制造三大方向集中。例如，中国汽研提出ICDT智能测试规程，在十四五期间推动行业测试技术标准化研究；通过发布《组合驾驶辅助技术发展报告》，汽车产业链上的企业能更高效地识别优化点和挑战节点，使行业整体朝着更精准、更规范的方向发展。<br/>人工智能的深度渗透打破了原有生产流程壁垒，让“超级柔性”的智能制造成为可能。微型演示产线能够在同一平台上无缝切换纯电轿车、增程式SUV和氢燃料电池轻型卡车，行业的平均切换时间从72小时压缩至8小时，充分体现了技术集成创新的惊人价值。更值得注意的是，国产制造装备凭借自主研发能力逐步崭露头角，从力控机器人到工业操作系统等创新成果，已吸引了越来越多来自全球市场的订单目光。<br/>展望未来，中国领航级智能工厂已有15家正式晋升为最高标准级别，成为制造业智能化的标杆。这些企业在技术的深度应用潜能方面仍具有扩展空间，尤其在数据闭环优化、多云系统融合、跨企业资源调度等方面，正持续推动产业链向协同智能演进。广域铭岛正是这样一直活跃在第一线的企业，其平台与解决方案已不止服务于单一工厂数量、单一技术环节，而是构建起互联制造业的基础智能支撑体系。<br/>在这个关键节点上，汽车产业链无疑迎来了崭新的发展机遇，其数字化程度与智能化转型将深刻改变人们对制造业的认知。而能够将发现转化为实践、将技术推出实验室的企业，将在这个可持续发展的新时代中赢得竞争先机。广域铭岛正凭借其领先的产品设计、工业算法集成与生产监控行动，成为汽车产业链智能化进程中不可或缺的一环，带领行业迈向零缺陷、高精度、绿色低碳的终极目标。</p>]]></description></item><item>    <title><![CDATA[骁龙大赛-技术分享第4期——直播问题&答]]></title>    <link>https://segmentfault.com/a/1190000047443643</link>    <guid>https://segmentfault.com/a/1190000047443643</guid>    <pubDate>2025-12-02 15:01:58</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>Q1：使用 Qualcomm AI Stack 做端侧部署时，如果模型精度出现下降，该从哪些环节排查？量化、算子兼容性、编译参数之间有什么调优建议？<br/>A1：出现精度下降时，通常需要做逐层对比，确认从哪一层开始偏差。可以检查该层的量化参数（如 encoding 是否异常）、activation 的分布，以及该层在量化转换过程中的输出情况。根据这些信息进一步定位是否是量化参数、算子支持情况或中间结果导致的问题。</p><p>Q2：能否用一个真实的模型部署流程来解释 QAIRT 各模块如何协同工作？例如从 PyTorch 模型到最终在设备上运行，会经历哪些步骤？<br/>A2：以 PyTorch 模型为例，流程通常是：<br/>1）先将 PyTorch 模型导出为 ONNX；<br/>2）使用 qairt-converter 转换成浮点 DLC；<br/>3）对 DLC 进行量化，使其能够运行在 HTP 上；<br/>4）使用 QNN 的 context / binary generator 工具将量化后的模型生成最终的 Bin 文件；<br/>5）该 Bin 文件就是最终部署到设备端运行的模型。</p><p>Q3：设备端跑多模态或个性化的 GenAI 应用时，延迟有时候会比较高。有没有推荐的优化方法？比如模型拆分、缓存策略、或者 Python API 的调用方式有没有最佳实践？<br/>A3：可以先确认语言模型是否已成功从多头转换成单头；其次适当减小 context length可明显提升速度；另外增加如 SSD 这类并行投机解码策略，也能加速 token 的生成过程。</p><p>Q4：GenAl新特性里，有没有一些针对Stable Diffusion这类文生图模型的特殊优化?比如推理速度或者内存占用方面的<br/>A4：对于 Stable Diffusion，我们会先检查模型是否也从多头成功转为单头，同时也有一些蒸馏(distillation)策略，可减少生成步骤，从而提升推理速度。</p><p>Q5：老师，当模型部署到手机上之后，效果和在PC上不一样，咱们的调试工具有没有什么“一键诊断”之类的便捷功能，帮我们快速定位问题？<br/>A5：目前没有“一键诊断”工具。如果遇到精度问题，主要还是需要逐层检查，通过层级输出对比来定位是哪一层的计算出现偏差。</p><p>Q6：老师，GenAl在端侧的个性化微调 (Fine-tuning) 具体是怎么实现的?需要的数据量和训练时间大概是什么量级?在手机上能完成吗?<br/>A6：目前还是不支持端侧训练的。</p><p>Q7：QAIRT 2025 相比之前的版本，对开发者来说最直观、最明显的提升是什么?<br/>A7：最明显的提升是整合了 QNN 和 SNPE，同时新增了大量 Python API，使转换、调试都更方便。现在既能支持传统模型，也能支持大模型的转换，调试工具也比之前版本更完善。</p><p>Q8：QAIRT 的生态建设如何？是否有类似 Hugging Face 的社区，能找到已优化并可直接在骁龙平台运行的模型?<br/>A8:  可以选用高通Hugging Face (<a href="https://link.segmentfault.com/?enc=tRYMYvFWxfwxxgvuiYPzkg%3D%3D.xKzo%2B7bQ5dt%2FdFxQDzH5uortpRpYNGVlzmEWEFcShFA%3D" rel="nofollow" target="_blank">https://huggingface.co/qualcomm</a>) 或 模型广场 (<a href="https://link.segmentfault.com/?enc=ZnjzwkSQYzabaaDP6RediA%3D%3D.hHrg45Aoi8fWsqDfk8EOeHd4sIBSxprnEiObmAsBTkpkx3%2F%2FpZaTct%2FR4eIZuNxa" rel="nofollow" target="_blank">https://www.aidevhome.com/data/models/</a>) 的预量化模型。</p><p>Q9：QAIRT 支持所有主流 AI 框架，是不是表示 TensorFlow、PyTorch 这类模型可以开箱即用？还需要额外转换吗？<br/>A9：需要经过 converter、量化流程和 context/binary generator 等步骤，转换完成后才能在 HTP 上实际运行。</p><p>Q10：新模型比如GLM4.6，YOLO13，也可以直接转换和量化么？<br/>A10:：的，这些模型都有过部署。</p><p>Q11：端侧 GenAI 的隐私保护是如何实现的？模型和数据是完全离线的吗?<br/>A11：是完全本地化的。模型与用户数据都在设备上运行，不依赖网络，也不会与云端交互，因此隐私能得到很好保障。</p><p>Q12：HTP 是否有计划支持 grouped quantization？<br/>A12：支持per channel和blocked quantization，不知道跟你所表达的grouped是不是一个概念。</p><p>Q13：做性能分析时，可视化工具能否看到每一层在 NPU 上的耗时和内存占用？<br/>A13：可以。工具能够显示每一层的执行耗时，以及具体的内存读写情况，并以 summary 文件的形式呈现，方便开发者优化。</p><p>Q14：除了常规算子融合、量化外，QAIRT 2025 在编译器上是否有独特优化策略？<br/>A14：是的，可以配置不同的优化编译选项。</p><p>Q15：目前端侧运行大语言模型 (LLM) 是否靠谱？例如 7B 模型在最新骁龙平台上的 token 速度、功耗大概是什么水平？<br/>A15：目前在第五代骁龙8至尊版上主要以3B和4B模型为主；在PC端，7B模型大致是 20 Token/s。</p><p>以上内容来自2025骁龙人工智能创新应用大赛</p>]]></description></item><item>    <title><![CDATA[工业互联网智能工艺：一场颠覆传统制造的数]]></title>    <link>https://segmentfault.com/a/1190000047443668</link>    <guid>https://segmentfault.com/a/1190000047443668</guid>    <pubDate>2025-12-02 15:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>你有没有被这样的场景困扰过：市场部催着新品尽快上市，而研发团队却在繁杂的流程和浩如烟海的工艺文件中疲于奔命？图纸版本混乱，沟通成本居高不下，一个微小的设计变更就可能让整个生产环节陷入混乱。更令人惋惜的是，经验丰富的工程师们本应专注于思考和创新，却不得不将大量时间耗费在手动校核图纸、反复测算工时和绘制作业指导书等重复性劳动中。这不仅是人力资源的浪费，更是企业创新效率的瓶颈。<br/>如果你正面临这样的问题，那么，工业互联网智能工艺或许能为你打开一扇新的大门。它不仅仅是技术的叠加，而是整个研发与生产流程的深度重构，旨在通过数字化手段解放工程师的创造力，打通部门间的协作壁垒，让创意从萌芽到落地都能高效运转。<br/>一、工业互联网智能工艺的核心理念：从“经验驱动”到“数据驱动”<br/>传统的工艺研发高度依赖工程师的经验和手工操作，不仅效率低下，而且容易出现人为错误。比如，图纸校核往往需要多人反复核对，耗时费力且难以完全避免疏漏；工艺路线的设计则依赖工程师的直觉判断，缺乏系统性和可扩展性。而工业互联网智能工艺通过引入AI技术、数字化工具和数据驱动的方法，彻底改变了这种局面。<br/>以广域铭岛的Geega工艺专家数智引擎系统为例，该系统融合了人工智能算法与行业Know-How，实现了从设计到作业的全流程智能化。工程师只需输入设计参数，系统就能自动完成定位、测量与标准校核，将图纸校核时间缩短50%以上，审查效率提升80%。更重要的是，它能提前拦截设计中的潜在问题，避免返工和延误。<br/>二、工业互联网智能工艺的实践：五大模块重塑工艺规划</p><p>1.AI可制造性校核<br/>在传统制造中，图纸校核往往是一个繁琐的过程，需要人工反复检查。而有了Geega工艺专家系统，这一切都变得简单高效。系统通过AI自动识别和测量零件，对照内置的标准规则快速完成校核，将问题扼杀在萌芽状态。</p><p>2.AI工艺路线生成<br/>工艺路线的制定通常由工程师手动编排，效率低下且容易出错。现在，系统通过智能算法自动生成零件装配顺序与工艺参数，大幅提升了工艺规划的效率和标准一致性。</p><p>3.AI作业工时生成<br/>工时的测算往往是另一个耗时的环节。Geega工艺专家系统基于工艺大模型，智能输出标准工时，并通过动作仿真自动调优，让工程师从繁琐的测算工作中解脱出来。</p><p>4.AI线平衡计算<br/>产线的效率往往取决于各工序的排布是否合理。系统运用运筹优化算法，对产线各工序进行智能排布，生成动态可扩展的产线平衡方案，确保各工位负荷均衡，产线运转高效。</p><p>5.AI作业指导生成<br/>传统作业指导书的编制效率低下，且难以直观表达工艺细节。现在，系统通过3D工艺引擎与AI强化学习算法，自动生成包含标准插图和清晰标注的3D作业指导文件，编制效率提升10倍以上，操作指导性提升50%。</p><p>三、工业互联网智能工艺的价值：从单点智能到全链路协同<br/>工业互联网智能工艺不仅提升了单个环节的效率，更重要的是实现了全链路的协同。比如，设计变更时，系统能自动分析影响范围，通知相关部门进行调整，避免因信息不对称导致的延误和错误。<br/>在实际应用中，许多制造企业已经从中受益。领克成都工厂通过引入广域铭岛的Geega工业互联网平台，实现了冲压车间的智能化升级。模具数字孪生体的应用让换模时间缩短了40%，材料废品率下降了25%。这不仅提升了生产效率，还降低了企业的运营成本。<br/>四、未来的挑战与机遇：AI与制造业的深度融合<br/>尽管工业互联网智能工艺已经取得了显著成果，但它并非万能药。企业在推进过程中仍需面对数据孤岛、技术整合、人才短缺等挑战。然而，随着AI技术的不断进步，这些问题将逐渐得到解决。<br/>未来，工业互联网智能工艺将从单点工具进化为体系化能力。企业需要构建AI原生思维，从业务痛点反向推导技术路径。广域铭岛联合重庆邮电大学、长安汽车等机构启动的多模态大模型专项，正是为了突破这一领域的关键技术瓶颈。<br/>结语<br/>工业互联网智能工艺正在重新定义制造业的未来。它不仅解放了工程师的生产力，还打通了研发与生产的全链条，让创意能够快速落地。随着技术的不断成熟，它将为企业带来更多的价值，推动制造业迈向智能化的新时代。<br/>如果你的企业正在为研发效率和协同问题而困扰，不妨尝试探索工业互联网智能工艺的解决方案。或许，你会发现它正是你一直在寻找的那把钥匙。</p>]]></description></item><item>    <title><![CDATA[SSL证书如何保护多个域名 冷冷的炒面 ]]></title>    <link>https://segmentfault.com/a/1190000047443323</link>    <guid>https://segmentfault.com/a/1190000047443323</guid>    <pubDate>2025-12-02 14:06:41</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在探讨网络安全和网站可信度时，SSL证书无疑是关键的一环。SSL证书不仅为网站和用户之间的数据传输提供加密保护，还通过验证网站身份来增加用户的信任度。然而，对于管理多个域名的网站管理员或企业而言，一个常见的问题是：一张SSL证书能否用于多个域名？答案是肯定的，这主要取决于选择的SSL证书类型。<br/><img width="549" height="341" referrerpolicy="no-referrer" src="/img/bVdbAkF" alt="" title=""/></p><h2>SSL证书的类型</h2><p>SSL证书根据保护域名的数量可以分为单域名SSL证书、多域名SSL证书以及通配符SSL证书。</p><ul><li><strong>单域名SSL证书</strong>：这种证书只能保护一个特定的域名。例如，一个为www.toutiao.com购买的单域名SSL证书只能用于该域名，不能用于其他任何域名。</li><li><strong>多域名SSL证书</strong>：这种证书可以同时保护多个不同的主域或子域。多域名SSL证书（也称为SAN SSL证书或UCC SSL证书）允许一张证书覆盖最多250个不同的域名，且这些域名之间可以毫无关联。这种证书类型在简化证书管理、减少配置和维护工作量方面具有显著优势，同时提供了更高的成本效益。</li><li><strong>通配符SSL证书</strong>：这种证书可以保护一个主域及其下的所有二级子域名，且不限制子域名的数量。例如，一张为*.toutiao.com购买的通配符SSL证书可以用于www.toutiao.com、mp.toutiao.com、login.toutiao.com等所有子域名。通配符证书具有高扩展性、方便管理、省钱省时等特性，特别适合那些只有一个主域但拥有多个二级子域名的网站。</li></ul><h2>多域名SSL证书的优势</h2><ol><li><strong>简化的证书管理</strong>：使用多域名SSL证书可以大大简化证书的管理流程，减少配置和维护的工作量。</li><li><strong>成本效益</strong>：购买多域名证书要比为每个域名单独购买证书更经济实惠。这尤其适用于那些拥有多个域名的企业或个人。</li><li><strong>增强的安全性</strong>：多域名SSL证书通过加密通信，可以有效防止数据泄露和中间人攻击，提升网站的整体安全性。</li><li><strong>提升用户信任</strong>：SSL证书能够在浏览器地址栏显示安全标志（如锁形图标），增强用户对网站的信任度。</li></ol><h2>实际应用场景</h2><p>多域名SSL证书适用于多种场景，包括但不限于：</p><ul><li><strong>企业网站</strong>：企业通常拥有多个域名和子域名，多域名SSL证书可以统一保护这些域名。</li><li><strong>电商平台</strong>：电商平台通常拥有多个域名用于不同的业务或市场，多域名SSL证书可以确保所有域名的数据安全。</li><li><strong>教育机构</strong>：教育机构通常拥有多个域名用于不同的课程或项目，多域名SSL证书可以保护这些域名的数据安全。</li><li><strong>个人网站或博客</strong>：对于拥有多个个人网站或博客的用户而言，多域名SSL证书提供了一种经济实惠且易于管理的安全解决方案。</li></ul><p>综上所述，一张SSL证书确实可以用于多个域名，这主要取决于选择的证书类型。对于需要保护多个域名的网站管理员或企业而言，多域名SSL证书和通配符SSL证书都是理想的选择。它们不仅提供了高效、安全的解决方案，还通过简化的管理和更高的成本效益，帮助企业或个人更好地应对日益复杂的网络安全挑战。在选择和使用这些证书时，建议充分了解其特点、优势以及申请流程，以确保证书的有效性和安全性。</p>]]></description></item><item>    <title><![CDATA[客户说“你的网站不安全”？SSL证书才是]]></title>    <link>https://segmentfault.com/a/1190000047443325</link>    <guid>https://segmentfault.com/a/1190000047443325</guid>    <pubDate>2025-12-02 14:05:43</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>“你的网站不安全”——当客户抛出这句话时，不少企业运营者都会陷入焦虑。在数字化时代，网站不仅是企业的线上门面，更是用户交互、信息传递的核心载体，安全感直接决定用户的留存与转化。而SSL证书，正是破解“安全质疑”、给客户吃下定心丸的关键所在。</p><h2>一、先搞懂：客户担心的“网站不安全”，到底怕什么？</h2><p>用户对网站安全的顾虑，并非空穴来风。未配置安全防护的网站，存在两大核心风险：一是数据传输风险，用户在网站填写的手机号、身份证号、支付信息等，会以“明文”形式在网络中传输，就像快递没密封，极易被黑客拦截、窃取；二是身份伪造风险，钓鱼网站模仿正规网站界面，诱导用户输入信息，而用户很难快速辨别真假。这两类风险，正是客户觉得“网站不安全”的根源，也是企业线上运营的隐形雷区。</p><h2>二、SSL证书的核心作用：加密+认证，双重筑牢安全防线</h2><p>SSL证书之所以能成为“安全定心丸”，核心在于它实现了“数据加密传输”和“网站身份认证”两大功能，从技术层面化解用户顾虑。</p><p>从数据加密来看，SSL证书采用非对称加密技术，相当于给数据传输装了“双重锁”。它包含公钥和私钥两把专属钥匙：用户访问网站时，服务器会向用户设备发送公钥，用户设备用公钥对要传输的信息加密；加密后的信息传输到服务器后，只有服务器持有的私钥才能解密。整个过程中，即便信息被黑客拦截，没有私钥也无法破解，从根源上保障数据安全。</p><p>从身份认证来看，SSL证书由权威第三方机构（CA机构）颁发，颁发前会严格审核网站的真实主体信息，确认网站所属企业的合法性。安装SSL证书后，浏览器地址栏会显示“小锁”图标，部分高端证书还会显示企业名称，直观告诉用户“这是正规可信的网站，不是钓鱼网站”，快速建立用户信任。</p><p><img width="530" height="343" referrerpolicy="no-referrer" src="/img/bVdbwbw" alt="" title=""/></p><h2>三、这些场景，SSL证书缺一不可</h2><p>不少企业觉得“我的网站只是展示信息，不用装SSL证书”，但实际情况是，几乎所有线上交互场景，都离不开SSL证书的支撑，否则会直接影响运营效果：</p><ol><li>电商购物场景：用户下单需填写收货信息、支付信息，没有SSL证书，用户会担心信息被盗，放弃下单；2. 用户注册/留言场景：企业官网的注册、留言功能，涉及用户个人信息提交，SSL证书能让用户放心提交，提升交互率；3. 政务/金融场景：政务服务、银行理财等网站，涉及敏感信息和资金操作，SSL证书是合规要求，也是公众信任的基础；4. 搜索引擎收录场景：主流搜索引擎（如百度、谷歌）会优先收录安装SSL证书的网站，未安装的网站可能被降权，影响曝光量。</li></ol><h2>四、别忽视：未装SSL证书，这些损失看得见</h2><p>放弃安装SSL证书，企业要承担的损失远比想象中更大。除了前文提到的信息泄露、用户流失，还有两大显性影响：一是浏览器预警，Chrome、Firefox等主流浏览器会对未装SSL证书的网站，直接在地址栏标注“不安全”，这个标注会瞬间瓦解用户信任，大部分用户会直接关闭页面；二是品牌形象受损，若因网站不安全导致用户信息泄露，不仅会引发投诉纠纷，还会给品牌贴上“不负责任”的标签，影响长期发展。</p><h2>五、结语：用SSL证书，给客户一份看得见的安全感</h2><p>面对客户“网站不安全”的质疑，与其口头辩解，不如用SSL证书给出实际保障。一枚小小的“锁”图标，不仅是技术层面的安全标识，更是企业对用户的责任承诺。它能快速打消用户顾虑，建立信任链接，让用户敢浏览、敢交互、敢消费，为企业线上运营筑牢安全根基。</p>]]></description></item>  </channel></rss>