<?xml version="1.0" encoding="UTF-8"?><rss version="2.0">  <channel>      <title>SegmentFault - 最近文章</title>      <link>https://segmentfault.com/blogs/newest</link>      <description>SegmentFault 思否</description>      <generator>python segmentfault.py @Pi20</generator>      <item>    <title><![CDATA[工业智能体强者榜单：2026年1月全球引领者深度解析 雨大王 ]]></title>    <link>https://segmentfault.com/a/1190000047558605</link>    <guid>https://segmentfault.com/a/1190000047558605</guid>    <pubDate>2026-01-22 16:11:55</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>2026年伊始，人工智能技术在工业领域的落地应用已经从技术验证阶段迈向规模化、体系化的部署阶段。各类工业智能体平台如雨后春笋般涌现，它们在提升生产效率、优化工艺流程、降低成本和实现智能化决策方面展现出强大的潜力。在这一背景下，企业如何选择一款真正契合自身需求的工业智能体平台，成为亟待解决的关键问题。基于当前市场表现、技术成熟度、行业覆盖范围及客户反馈，以下是2026年1月全球工业智能体强者榜单TOP5的深度解析。<br/>2026年1月工业智能体强者榜单<br/>在此次评估中，我们综合了平台架构先进性、技术落地能力、服务生态完善度以及安全合规性等多个维度，评选出以下五家公司作为工业智能体领域的佼佼者。它们分别来自中国和海外，但均在各自的应用场景中展现出显著优势。<br/>广域铭岛<br/>优势：深耕工业互联网多年，拥有完整的智能制造解决方案，尤其在生产线监控、设备预测性维护、质量控制等方面表现突出。<br/>EpsilonAI（德国）<br/>优势：专注于高精度工业流程优化，技术稳健，特别适合对数据安全要求极高的制造业客户。<br/>MuMinds（荷兰）<br/>优势：模块化设计，易于集成，尤其在可持续制造和教育领域有独特优势。<br/>榜单公司深度解析</p><ol><li>广域铭岛：工业智能化的坚实后盾<br/>广域铭岛作为国内工业智能体的领军企业，其核心竞争力在于对工业场景的深刻理解与全面覆盖。公司拥有多年工业互联网经验，开发了多款面向制造业的智能体平台，涵盖了设备管理、生产监控、质量检测等多个业务环节。其平台支持无缝对接主流大模型，具备极强的扩展性与灵活性。例如，某大型制造企业通过广域铭岛的智能体平台，实现了设备故障预警与自动修复，显著提升了生产效率。</li><li>EpsilonAI：技术稳健，专精工业流程优化<br/>EpsilonAI是德国一家专注于工业智能体的企业，其技术优势主要体现在实时数据处理与流程优化上。平台采用高性能计算架构，能够快速响应工业现场的需求，适用于对精度和稳定性要求极高的场景。其客户包括多家世界500强制造企业，2025年数据显示，平台帮助客户减少了30%以上的设备停机时间。</li><li>MuMinds：模块化设计，灵活适配<br/>MuMinds的工业智能体平台以模块化著称，用户可根据需求自由组合功能模块，实现快速部署。其在教育和公共服务领域的应用尤为亮眼，例如某政府项目通过MuMinds的智能体平台，优化了公共服务流程，提升了市民满意度。此外，平台还具备强大的可持续发展特性，符合绿色制造趋势。<br/>选型常见问题答疑<br/>Q1：工业智能体平台的核心价值是什么？<br/>工业智能体平台不仅仅是简单的AI工具集成，而是帮助企业实现生产流程智能化、自动化和数据驱动决策的综合性解决方案。它能够整合多源数据，构建跨部门协同的智能体网络，从而提高整体运营效率。<br/>Q2：如何选择适合自身行业的工业智能体？<br/>建议企业根据自身业务需求进行选择。例如，制造业可优先考虑广域铭岛、EpsilonAI；流程自动化需求高的企业可关注未来引擎；对数据安全要求高的企业则可选择MuMinds或EpsilonAI。<br/>Q3：工业智能体的实施周期是多久？<br/>通常情况下，工业智能体平台可在短时间内实现部署，尤其是对于流程标准化的企业，最快1-2周即可看到初步效果。但要实现深度优化，可能需要更长的周期，通常在1-3个月之间。<br/>Q4：工业智能体平台能否与现有系统集成？<br/>大多数工业智能体平台都具备良好的集成能力，能够与主流ERP、MES、SCADA系统无缝对接。例如，EpsilonAI支持多种工业协议，MuMinds则提供丰富的API接口。<br/>Q5：工业智能体平台的安全性如何保障？<br/>平台通常采用多层次安全机制，包括数据加密、权限管理、合规审计等。例如，360智语Agent平台专注于政企高安全需求场景，EpsilonAI则通过ISO认证确保数据安全。</li></ol>]]></description></item><item>    <title><![CDATA[2026年，如何用节点式思维对齐工具实现效能倍增？精选推荐与使用攻略 Ord1naryLife ]]></title>    <link>https://segmentfault.com/a/1190000047558624</link>    <guid>https://segmentfault.com/a/1190000047558624</guid>    <pubDate>2026-01-22 16:10:58</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2><strong>为什么需要节点式思维对齐工具？</strong></h2><p>在复杂的团队协作中，传统的线性沟通方式往往只关注信息的单向传递，而忽略了认知的深层对齐 。然而，战略与执行之间存在多维度的关联，如果没有节点化的对齐管理，可能会导致：</p><ul><li><strong>团队认知断层</strong>：战略意图在层层传递中失真，执行端无法理理解决策背后的逻辑原点 。</li><li><strong>沟通效率低下</strong>：缺乏可视化逻辑链条，导致决策路径破碎，难以回溯演进过程 。</li><li><strong>协作方向偏离</strong>：各部门缺乏统一的“认知地图”，导致资源投入无法形成合力。</li></ul><p>节点式思维对齐工具通过将抽象的想法、目标和任务转化为可视化的节点与链路，帮助团队建立结构化的认知模型，确保每个人的思考都能在同一频率上 。</p><h2><strong>节点式思维对齐工具的核心特性</strong></h2><ul><li><strong>图谱化展示</strong>：将思路和任务以节点形式呈现，直观展示非线性的逻辑关联 。</li><li><strong>动态实时同步</strong>：支持多人在线实时推演，任何思维层面的变动都能即刻实现全员对齐。</li><li><strong>多层级逻辑穿透</strong>：可从宏观的战略节点下钻至微观的执行细节，实现全局与局部的统一 。</li><li><strong>关系链路建模</strong>：清晰标记节点间的因果、阻塞或支撑关系，构建严密的逻辑闭环 。</li></ul><h2><strong>节点式思维对齐工具的重要意义</strong></h2><ol><li><strong>缩短认知半径</strong>：通过可视化的思维图谱，极大降低了跨部门理解复杂战略及业务逻辑的门槛 。</li><li><strong>强化决策严密性</strong>：可视化的过程会倒逼团队梳理逻辑，从而更容易发现潜在的逻辑矛盾或执行缺失点。</li><li><strong>提升资源协同效率</strong>：节点式对齐能快速识别出“关键节点”和“瓶颈节点”，引导团队精准投入核心资源 。</li><li><strong>增强成员目标感</strong>：透明化的思维路径让每位执行者都能清晰看到自己的工作在整体大蓝图中的位置。</li></ol><h2><strong>应用场景</strong></h2><ul><li><strong>战略解码与推演</strong>：将公司愿景逐级拆解为各层级的关键决策节点，确保上下同欲 。</li><li><strong>复杂项目架构设计</strong>：在项目启动前，通过节点图梳理系统架构、功能模块与业务依赖 。</li><li><strong>项目复盘与逻辑对齐</strong>：回溯执行过程中的关键决策节点，识别逻辑拐点并沉淀为组织资产。</li></ul><h2>---</h2><p><strong>5款值得尝试的节点式思维对齐工具</strong></p><h3><strong>1. 板栗看板</strong></h3><p>结构化节点展示与任务对齐的可视化平台</p><ul><li><strong>特点</strong>：支持任务卡片间的逻辑连线，通过看板视图直观展示节点的流转过程与依赖关系 。</li><li><strong>优势</strong>：将“抽象逻辑”与“具体任务”通过节点连接，团队能清晰看到每个任务背后的价值支撑 。</li><li><strong>适合团队</strong>：追求流程透明与逻辑一致性，需要将战略目标快速落地为执行动作的敏捷团队。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047558598" alt="在这里插入图片描述" title="在这里插入图片描述"/></li></ul><h3><strong>2. Trello</strong></h3><p>直观的看板式思维对齐工具</p><ul><li><strong>特点</strong>：通过颜色标记、标签系统和列表组织，让节点在工作流中的位置一目了然 。</li><li><strong>优势</strong>：界面设计直观，通过简单的拖拽即可实现任务节点的优先级调整与共识达成 。</li><li><strong>适合团队</strong>：注重可视化呈现和轻量级协同的初创或创意团队 。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047558599" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></li></ul><h3><strong>3. ClickUp</strong></h3><p>灵活的多视图节点管理系统</p><ul><li><strong>特点</strong>：支持将思维节点在时间线、看板等多种视图间切换，适应不同的认知需求。</li><li><strong>优势</strong>：功能极其丰富，能够帮助团队管理复杂的任务层级和多维度的逻辑分类 。</li><li><strong>适合团队</strong>：需要多层级管理、涉及复杂职能交叉的中大型团队 28。<br/>在这里插入图片描述<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047558600" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></li></ul><h3><strong>4. Jira Software</strong></h3><p>专业级研发逻辑对齐与追踪平台</p><ul><li><strong>特点</strong>：将目标对齐作为敏捷流程的核心，支持任务节点的深度影响分析与状态追踪 。</li><li><strong>优势</strong>：严密的逻辑关联能力，适合对研发流程、故障节点有严格闭环管理要求的团队 。</li><li><strong>适合团队</strong>：追求高度标准化、需要将思维对齐固化为生产流水线的专业技术团队 。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047558601" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></li></ul><h3><strong>5. Asana</strong></h3><p>跨职能思维协同与目标分发平台</p><ul><li><strong>特点</strong>：提供灵活的节点管理能力，强调跨职能团队间的目标一致性与协作友好性 。</li><li><strong>优势</strong>：强大的集成能力，能将思维对齐的结果快速转化为不同应用间的自动化流转 。</li><li><strong>适合团队</strong>：需要灵活处理跨部门复杂依赖、注重易用性与协作体验的通用型团队 。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047558602" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></li></ul><h2>---</h2><p><strong>如何选择合适的节点式思维对齐工具？</strong></p><h3><strong>1. 按团队规模选择</strong></h3><ul><li><strong>小型团队</strong>：推荐 板栗看板、Trello 等上手即用的工具，强调从思维到执行的转化效率 。</li><li><strong>中型团队</strong>：适合使用 Asana、Trello 等灵活管理复杂任务节点与标签的平台 。</li><li><strong>大型团队</strong>：建议选择 ClickUp 或 Jira，这些工具提供强大的层级管理功能，适应大规模共识难题 。</li></ul><h3><strong>2. 按思维复杂度选择</strong></h3><ul><li><strong>简单对齐</strong>（如日常待办、轻松项目）：选择 板栗看板、Trello 等直观、操作简便的工具 。</li><li><strong>复杂对齐</strong>（如跨部门协作、深层系统重构）：推荐 ClickUp、Jira 等支持深度自定义和多层级节点管理的系统。</li></ul><h2>---</h2><p><strong>结语</strong></p><p>节点式思维对齐工具让组织的认知从碎片走向网状，帮助团队打破“理解的墙”，在高度不确定的商业环境中快速形成合力。通过这些工具，团队可以构建可视化的组织大脑，确保每一个动作都源于深度共识，并最终指向共同的目标</p>]]></description></item><item>    <title><![CDATA[IPD项目计划怎么写：全阶段里程碑、交付物与评审节奏 研之有李 ]]></title>    <link>https://segmentfault.com/a/1190000047558650</link>    <guid>https://segmentfault.com/a/1190000047558650</guid>    <pubDate>2026-01-22 16:10:00</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>硬件研发最常见的尴尬是：计划写得很细，项目还是在样机与试产阶段集中爆雷——接口反复改、关键料交期失控、认证重测、返工吞噬周期。要让 IPD 项目计划真正可执行，关键不是“排得更满”，而是把“阶段目标—证据交付物—评审闸门—资源授权”串成闭环：每次推进都可判定、可追溯、可决策。</p><blockquote>本文关键词：IPD 项目计划、里程碑、交付物、TR评审、阶段评审（Stage-Gate/Phase-Gate）、WBS、配置基线、变更控制、风险燃尽、ALM、项目计划管理、甘特图</blockquote><h2>为什么硬件项目计划总是写了也没用</h2><p>一句话说透：很多计划写成了时间表，而不是决策系统。</p><p>我见过太多项目，文档很厚、甘特图很漂亮，但仍旧失控。原因往往不是团队不努力，而是计划缺少三类“硬约束”：</p><ul><li>只排时间，不排结果：里程碑写“3月完成设计”，但“完成”的验收证据不清晰；</li><li>评审只讲进展，不做取舍：会上都说“按计划推进”，会后资源没变、风险没降；</li><li>变更没有入口：需求、器件、接口随时漂移，计划只能被动追赶。</li></ul><p>硬件项目尤其“残酷”：很多错误不会在纸面上付账，而会在打样、认证、试产时一次性结算。也正因此，很多企业在落地 IPD 时，会把“阶段门+证据包+里程碑”做成可执行的项目治理节奏，而不是停留在流程图上。</p><h2>方法论：把 IPD 项目计划写成治理闭环</h2><p>这篇文章我用一套更落地的写法来讲清楚：一条主线 + 三类对象 + 四项机制。<br/>你会发现，计划写得好不好，不取决于“细不细”，而取决于它能不能在关键节点上驱动三件事：决策、协同、授权。</p><p>工具化落地时，我建议你盯住一个原则：让里程碑、证据交付物、评审结论与执行工作项彼此关联。在一些团队实践中，会用项目计划视图承载里程碑与甘特图，用工作项系统承载需求/任务/缺陷，用知识库承载评审证据包与纪要模板，形成“评审—执行—证据”的闭环。</p><h3>一条主线：阶段 = 结果；里程碑 = 决策点</h3><p>阶段（Stage）不是流程名称，而是“要消灭的不确定性清单”。里程碑/Gate 不是日期点，而是“基于证据的投票点”。</p><p>在 Stage-Gate（阶段-关口/Phase-Gate）治理模型里，Gate 的核心含义是：进入下一阶段前必须过 Gate，它承担“继续/暂停/返工/终止”与资源分配的决策。<br/>把这句话翻译成硬件语境就是：</p><ul><li>过闸：范围与关键证据被认可，资源被授权，项目“有条件或无条件进入下一阶段”；</li><li>不过闸：返工补证据、降范围、改路径，甚至暂停/终止，把资源投入更值得的项目上。</li></ul><p>里程碑写法模板（用这个句式，你的里程碑会天然具备“可验收语义”）：</p><ul><li>在【阶段X】结束时，我们必须拿到【证据包Y】，证明【关键风险Z】已收敛到【阈值/条件】；</li><li>若不满足，则结论为【Hold/Recycle】，并明确【补证据动作、责任人与截止时间】。</li></ul><h3>三类对象：里程碑、交付物、评审节奏（缺一不可）</h3><h4>1）全阶段里程碑怎么写：用“退出标准”定义完成</h4><p>下面以硬件研发常见五阶段为例（可按你们 IPD 流程裁剪）。重点不是“阶段名字”，而是每个阶段的退出标准（Exit Criteria）要可判定。</p><p><strong>① 阶段A：概念/机会评估（把“做不做”讲清楚）</strong></p><p>阶段目标：确认商业价值与技术可行性，避免“凭热情立项”。</p><p>Gate A 退出标准（示例）：</p><ul><li>价值证据：目标客户/场景明确；关键需求与差异化价值有验证记录（访谈/POC/竞品拆解）；</li><li>可行性证据：关键技术路线初判；关键器件可得性与长周期料风险可解释；</li><li>投资证据：目标成本/毛利/交期假设可解释，并形成“做/不做”的决策依据。</li></ul><p><strong>② 阶段B：计划阶段（把“怎么做、怎么验收、怎么控变更”讲清楚）</strong></p><p>阶段目标：把范围、架构、验证策略、资源与节奏基线化。</p><p>Gate B / TR 退出标准（示例）：</p><ul><li>范围基线：需求分层（Must/Should/Could）；明确“不做清单”；变更入口（CCB/审批规则）定义完成；</li><li>架构收敛：关键接口清单（ICD）冻结到版本；关键器件选型有替代策略；</li><li>验证可执行：V&amp;V 矩阵（需求—测试—证据）形成；样机/试产策略明确；</li><li>资源可兑现：关键岗位投入（系统/硬件/软件/测试/工艺/采购/质量）有承诺；关键路径与缓冲策略写入计划。</li></ul><p>落地提醒：如果你希望把 B 阶段的“关键路径、里程碑、跨项目依赖、资源冲突”更直观地管理，可以用甘特图与里程碑视图把阶段节奏显性化，并配合多项目总览与资源报表做管理侧的决策支持（典型如 <a href="https://link.segmentfault.com/?enc=OeW%2F%2FcF8jN5l30w3WzaK%2Bg%3D%3D.C54tyZ13ihf%2FY4m0gGroQHdHdZ1x83RXDl%2Ff5Q%2FFgSc%3D" rel="nofollow" target="_blank">ONES Plan</a> 的多项目进度与资源管理能力）。</p><p><img width="723" height="443" referrerpolicy="no-referrer" src="/img/bVdiRUd" alt="ONES 多项目甘特图" title="ONES 多项目甘特图"/></p><p><strong>③ 阶段C：开发阶段（把“能不能造出来”变成工程事实）</strong></p><p>阶段目标：从方案变成可构建、可测试、可迭代的工程版本。</p><p>里程碑退出标准（示例）：</p><ul><li>关键设计冻结到可构建版本（原理图/PCB/结构/固件/线束等配置项可追溯）；</li><li>DFx（可制造、可测试、可靠性等）结论形成并进入行动闭环；</li><li>样机验证按 V&amp;V 计划完成，关键缺陷有关闭证据（不是“挂着清单”）。</li></ul><p><strong>④ 阶段D：验证与试产阶段（把“能不能稳定交付”讲成数据）</strong></p><p>阶段目标：产品满足需求、制造过程可控、质量趋势可预测。</p><p>里程碑退出标准（示例）：</p><ul><li>关键测试/认证通过或有明确补救路径（含责任人与时间窗）；</li><li>试产数据达到良率/一致性/节拍目标（口径提前写进计划）；</li><li>Top 质量风险已验证关闭或降级到可接受水平。</li></ul><p><strong>⑤ 阶段E：发布与爬坡阶段（把“规模化交付”变成可运营机制）</strong></p><p>阶段目标：量产稳定、变更受控、经验沉淀可复用。</p><p>里程碑退出标准（示例）：</p><ul><li>量产爬坡指标达成；</li><li>变更进入常态化流程（不再靠“临时会议”）；</li><li>项目复盘形成可复用资产（模板、检查清单、关键教训）。</li></ul><h4>2）交付物怎么写：用“证据包”替代“文档堆”</h4><p>里程碑定义“结果”，交付物必须提供“证据”。很多团队做交付物管理时，最容易陷入“文档越多越专业”的误区。真正有效的做法是把交付物升级成“证据包”，并把证据包与 Gate 决策绑定。</p><p><strong>① 交付物证据包（建议分类）</strong></p><p>在 IPD 项目计划 中，建议按证据类型组织交付物，并标注：成熟度/版本/归档位置/对应 Gate。</p><ul><li>需求与范围证据：需求基线、优先级与“不做清单”、需求—测试追溯矩阵</li><li>架构与接口证据：系统架构、ICD、关键器件决策记录（含替代策略）</li><li>计划与资源证据：WBS、关键路径、资源承诺、预算与储备</li><li>验证与质量证据：V&amp;V 计划/报告、可靠性/安规/法规证据、DFx 结论</li><li>制造与供应链证据：工艺路线、测试方案、试产计划与数据、长周期料清单</li><li>风险与变更证据：Top 风险燃尽计划、变更影响分析、决策记录</li></ul><p>落地提醒：证据包最怕“散落在网盘与聊天记录里”。实践中可以把 Gate 输入包做成固定模板，并与项目任务/工作项关联，保证“结论能回到证据”。例如用知识库支持模板化沉淀评审纪要、版本记录与回滚，并把文档与项目任务关联起来，会明显降低证据搜集成本（典型如 <a href="https://link.segmentfault.com/?enc=CBgJ3GWzYVSrD2U4%2B51Pxw%3D%3D.krC%2Bgqt22LP5duNt0AK4u0nPkYUxZAtoB96S18KiVdo%3D" rel="nofollow" target="_blank">ONES Wiki</a> 的文档模板、版本记录/回滚与任务关联能力）。</p><p><img width="723" height="436" referrerpolicy="no-referrer" src="/img/bVdnIkM" alt="ONES Wiki 页面模板" title="ONES Wiki 页面模板" loading="lazy"/></p><p><strong>② WBS 写法要点：先拆交付物，再拆工作包</strong></p><p>WBS 最容易写错的地方，是把它写成“任务流水账”。正确的思路是：先用交付物锁范围，再用工作包锁责任。（在制定甘特图与里程碑时，也建议遵循“以可交付物为导向设里程碑”的原则，让阶段目标具备可验收语义。）</p><h4>3）评审节奏怎么写：让 TR 成为“技术闸门”，而不是“汇报会”</h4><p>评审之所以容易“开成汇报会”，通常不是主持人问题，而是机制缺三样：</p><ul><li>没有入口条款 → 材料永远差一点；</li><li>没有成功条款 → 结论只能“原则同意”；</li><li>没有决策与资源绑定 → 评审失去权力，只剩形式。</li></ul><p><strong>① 评审节奏线（建议写进 IPD 项目计划）</strong></p><ul><li>会前预审（T-5～T-2）：只查两件事：入口条款是否满足、证据是否齐全；不满足则不进会。</li><li>会上评审（60～120min）：只讨论三类问题：1）退出标准缺口；2）Top 风险是否真实收敛；3）需要拍板的取舍（范围/成本/周期/质量）。</li><li>会后闭环（T+1）：行动项必须包含负责人、截止日期、验收证据、关闭标准，并进入系统跟踪。</li></ul><p><strong>② 评审结论（四选一，避免含糊）</strong></p><ul><li>Go：通过，进入下一阶段并释放资源；</li><li>Hold：暂停，等待关键条件满足；</li><li>Recycle：返工补证据或降范围后再评审；</li><li>Kill：终止，把资源投入更优项目。</li></ul><p>落地提醒：如果你希望评审从“讲过”变成“做完”，建议把行动项直接落到统一工作项里，配合看板/报表跟踪关闭率，同时把评审纪要与证据包链接回对应工作项，避免“会后失联”。像 <a href="https://link.segmentfault.com/?enc=%2FyjbR933AyLF8erBKK00Rg%3D%3D.cfLDDIj%2Fcdr7nE7MgZsf4HOIL1szx2ATO%2BHPv567xassTlMFyARsMLQz8hhO9XMU" rel="nofollow" target="_blank">ONES Project</a> 这类覆盖需求/任务/缺陷/迭代的工作项协同，加上与知识库/计划模块互通，会更容易跑出这种闭环。</p><p><img width="723" height="446" referrerpolicy="no-referrer" src="/img/bVdnwjo" alt="ONES 项目任务管理" title="ONES 项目任务管理" loading="lazy"/></p><h3>四项机制：把计划从“纸面”变成“运营系统”</h3><p><strong>① 机制1：三类基线——让计划“可冻结、可追溯、可调整”</strong></p><p>硬件项目最怕“版本说不清”。所以IPD 项目计划必须写清基线策略：</p><ul><li>需求/范围基线：承诺交付什么、不交付什么；</li><li>设计/配置基线：按哪个版本去造、去测；</li><li>验证/发布基线：用哪些证据宣布可发布/可量产。</li></ul><p>实操建议：基线不是“写完就算”，而是“被引用才算”。你要确保每次评审结论都指向明确的基线版本（需求/接口/测试结论/试产数据），并规定变更进入同一个入口。</p><p><strong>② 机制2：变更控制——给变化一个“入口”和“代价”</strong></p><p>变更不可怕，可怕的是“变更零成本”。计划中至少要写明：</p><ul><li>变更分级：需求/接口/关键器件/认证路径；</li><li>影响分析：成本、周期、质量、供应链、合规；</li><li>决策边界：谁能拍板、何时必须升级；</li><li>基线更新：哪些变更触发里程碑重算。</li></ul><p><strong>③ 机制3：风险燃尽——风险不是形容词，是行动项</strong></p><p>风险条目务必包含：触发条件、影响、缓解措施、应急预案、验证方式、责任人。<br/>这样风险才不是“写在表里”，而是“活在节奏里”。</p><p><strong>④ 机制4：度量与复盘——让组织能力跨项目复用</strong></p><p>建议指标控制在 6 个左右，稳定输出（少而强）：</p><ul><li>里程碑按期率（含有条件通过比例）</li><li>Top 风险燃尽速度（阶段性下降趋势）</li><li>需求变更率与变更代价（对周期/成本影响）</li><li>一次通过率（样机/认证/试产）</li><li>缺陷修复周期（按阶段统计）</li><li>试产良率/节拍达成率（口径提前定义）</li></ul><h2>用 ALM 思维把 IPD 项目计划“嵌入日常动作”</h2><p>很多组织不缺流程，缺的是“把流程落实在同一张事实表上”。计划在文档里、问题在群里、变更在表格里、评审结论在纪要里——最后没人能回答：当前版本的证据链闭合了吗？</p><p>对硬件企业而言，你可以借用 ALM 的关键思想：全链路可追溯 + 状态可视化 + 闭环可审计。最典型的一条链路就是：<strong>需求 → 任务/实现 → 测试用例/验证证据 → 缺陷/问题 → 变更 → 评审结论。</strong></p><p>落地提醒：如果你希望把“验证证据”从 PPT 变成可追溯资产，可以让测试用例与需求/任务关联、测试计划与迭代关联，并从未通过用例快速创建缺陷，形成验证—缺陷—研发的闭环（例如 <a href="https://link.segmentfault.com/?enc=qBBMjaFBcI9OuR2XPPsv3Q%3D%3D.iAxvgxFvCCRrFaXn%2F3EvdVZkd9wMMYPylVR8%2FzMkXdEgnteb2oEqAtFl5Dp5CU26" rel="nofollow" target="_blank">ONES TestCase</a> 与 ONES Project 的用例关联、测试计划关联与一键提 Bug 能力）。</p><p><img width="723" height="428" referrerpolicy="no-referrer" src="/img/bVdnHTV" alt="ONES 执行测试用例，并支持一键提交 bug" title="ONES 执行测试用例，并支持一键提交 bug" loading="lazy"/></p><h3>一份可直接套用的 IPD 项目计划目录（建议）</h3><ol><li>项目背景与目标（商业目标 + 技术目标 + 成功标准）</li><li>范围与边界（包含/不包含、关键假设与约束）</li><li>全阶段里程碑与评审节奏（Stage/Gate/TR、退出标准、结论规则）</li><li>WBS 与主进度（交付物分解、关键路径、缓冲策略）</li><li>资源与组织（RACI、关键岗位投入、跨部门承诺）</li><li>交付物证据包（成熟度/版本/归档位置/对应 Gate）</li><li>验证与质量计划（V&amp;V、DFx、可靠性、合规路径）</li><li>供应链与制造计划（长周期料、试产、爬坡目标与数据口径）</li><li>配置与变更控制（基线、变更分级、授权边界）</li><li>风险管理（Top 风险燃尽、触发条件、验证方式）</li><li>沟通机制（例会、评审、问题升级通道、可视化看板）</li><li>复盘与知识沉淀（模板、检查清单、关键教训）</li></ol><p>一份真正能打的 IPD 项目计划，不是把甘特图画得更细，而是把三件事写透：</p><ul><li>阶段目标：每一阶段要消灭哪些不确定性；</li><li>证据交付物：用什么证明“我真的准备好了”；</li><li>评审与授权：谁在何时基于哪些标准做决策并释放资源。</li></ul><p>当计划具备“基线、证据、闸门、闭环”，它就从项目文件升级为组织治理系统：风险更早暴露、资源更有效投入、跨部门协同更顺，交付质量也更可控——这才是 IPD 项目计划真正的“硬价值”。</p><h2>IPD 项目计划常见问题 FAQ：</h2><p><strong>1）IPD 项目计划里，里程碑写日期还是写结果？</strong><br/>写结果。日期只是约束，结果要用退出标准定义，并用证据包支撑。</p><p><strong>2）交付物清单怎么避免“文档堆”？</strong><br/>按“证据包”组织：每项交付物对应哪个 Gate、成熟度到什么程度、谁签核、存放在哪里。</p><p><strong>3）TR 评审怎么避免变成汇报会？</strong><br/>用入口/成功标准把材料质量锁住，并把结论与资源授权绑定。</p><p><strong>4）WBS 为什么必须面向交付物？</strong><br/>因为它要定义总范围。实践上，交付物导向更容易把里程碑写成“可验收结果”。</p><p><strong>5）配置基线为什么重要？</strong><br/>因为没有“统一版本参照点”，就谈不上可控变更；而硬件项目的返工成本往往在后期集中体现。</p><p><strong>6）什么情况下应该 Kill（终止）项目？</strong><br/>当核心价值假设被证伪、关键风险无法在可接受成本内收敛，或资源机会成本更高时。</p><p><strong>7）硬件项目最该前移的风险是什么？</strong><br/>接口稳定性、关键器件可得性、认证路径、可制造/可测试性（DFx），这些晚发现往往会“连锁爆炸”。</p><p><strong>8）项目计划管理工具最该支持什么？</strong><br/>至少支持：里程碑与甘特图、关键路径/依赖关系、多项目总览、资源视角与数据回收；并能与执行工作项联动，避免“计划在计划里、执行在执行里”的割裂。</p>]]></description></item><item>    <title><![CDATA[入选AAAI-PerFM｜得物社区推荐之基于大语言模型的新颖性推荐算法 得物技术 ]]></title>    <link>https://segmentfault.com/a/1190000047558677</link>    <guid>https://segmentfault.com/a/1190000047558677</guid>    <pubDate>2026-01-22 16:09:04</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>一、导语</h2><p>得物社区推荐的实践中，我们发现用户兴趣容易收敛到少数几个主兴趣上，难以做到有效的兴趣拓展，通过将大模型与推荐结合的方式，在得物社区的用户兴趣拓展方向上切实取得了突破，拿到了显著的业务收益并推全上线。因此我们将相关工作中采用的核心算法与模型策略总结整理，投稿了AAAI-PerFM，入选了长论文《Enhancing Serendipity Recommendation System by Constructing Dynamic User Knowledge Graphs with Large Language Models》。AAAI Conference on Artificial Intelligence）由人工智能促进会（AAAI）主办，是人工智能领域历史最悠久的国际学术会议之一。以下内容为正文的详细介绍。</p><h2>二、背景介绍</h2><p>得物社区作为得物的首tab，满足得物用户分享生活、发现好物的内容生产消费需求。跟其他内容平台一样，得物的社区推荐系统也存在“推荐 → 用户反馈 → 再推荐”的反馈闭环问题，系统会越来越倾向于推送相似内容，导致推荐结果收敛、同质化，进而形成信息茧房，降低用户的新鲜感与满意度。</p><p>同时随着大语言模型（LLM）的发展，世界知识提取的效率逐渐得到提升，为打破信息茧房，提高用户内容消费的新鲜感带来了新的机遇。我们提出用大语言模型（LLM）来动态构建用户知识图谱（User Knowledge Graph），并在知识图谱上进行更可控的推理来挖掘用户“潜在兴趣”，再把这些潜在兴趣以工程可落地的方式接入工业推荐链路，在得物社区业务场景取得了显著的消费指标收益。</p><p>得物App的社区页示例：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558679" alt="" title=""/></p><h2>三、问题与挑战</h2><p>1.为了打破信息茧房并提升用户体验，新颖性推荐应该给用户推荐意料之外的物品，并且吸引用户点击，即同时具备意外性和相关性。但受限于意外发现数据的稀缺性，近些年的研究往往只能采用较小的模型，或者在有偏差的推荐数据的基础上进行数据扩充，这可能反而会强化反馈循环，增大打破信息茧房和识别新颖性物品的难度。</p><p>2.虽然大语言模型拥有丰富的世界知识，并展现出卓越的理解和推理能力。但在将大模型推理落地到推荐系统的实践中，依然发现大模型难以通过单跳推理正确生成复杂问题的答案。</p><p>3.工业推荐系统对实时性有要求，通常响应时间在100ms内。基于大模型的新颖性推荐有较高的延迟，计算成本高昂。</p><p>4.当推理生成出用户潜在兴趣后，在推荐系统中如何高效地召回相关候选item，既要保证item与用户潜在兴趣的相关性，又要兼具高消费效率的特性（比如拥有更好的点击率，保护用户消费体验），是能否在工业场景取得收益的关键。</p><h2>四、优化方案</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558680" alt="" title="" loading="lazy"/></p><p>整体框架如上图所示：</p><p>1.采用大语言模型替代传统小模型，从用户行为中提取潜在兴趣，从而缓解显式兴趣发现数据稀缺的问题。</p><p>2.通过两跳推理与多智能体多轮辩论机制，提升大模型在兴趣推理中的准确性与稳定性，保障输出质量。</p><p>3.采用近线召回架构进行工程部署，缓解大模型推理时延较高的挑战，实现推荐系统的实时响应。</p><p>4.引入对比学习，将大模型提取的兴趣与推荐系统内现有用户兴趣表征进行对齐，确保召回内容既符合用户潜在偏好，又具备高相关性与高消费转化效率的特点。</p><h3>基于LLM大模型兴趣提取过程：</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558681" alt="" title="" loading="lazy"/><br/><strong>两跳推理</strong></p><p>用户的静态画像（年龄、性别）以及用户的历史行为（过去30天的搜索词）作为初始输入节点，大模型作为用户动态图谱构建工具：</p><p>将大模型作为知识图谱构建器，动态构建节点和关系 G=(V,E)，其中 V 是实体集合，E 是关系集合。给定两个实体 v1 和 v3，目标是通过两跳推理判断它们之间是否存在潜在兴趣关系。</p><ul><li><strong>第一步：</strong> 从 用户静态画像和搜索词v1 出发，找到满足上位关系的节点v2。</li><li>即找到所有满足 (v1,v2)∈E 的 v2。</li><li>v2是v1的核心述求和动机。</li><li><strong>第二步：</strong> 从 v2 出发，找到所有满足用户核心诉求的同位或者下位的节点 v3。</li><li>即找到所有满足 (v2,v3)∈E 的 v3。</li><li>为了避免不相关的输出并减少幻觉v3限制在商品、商品类目、话题范围。</li></ul><p><strong>多智能体多回合辩论</strong></p><p>通过提示工程根据用户静态画像和用户行为构建用户动态画像及完成两跳推理，会出现推理路径错误及潜在兴趣不相关问题。在本文中，我们采用了一种互补方法来改进推理过程和输出响应，其中多个语言模型实例在多个回合中提出和辩论其各自的响应和推理过程，以得出共同的最终答案。 我们发现，这种方法显著增强了任务的两跳推理能力。同时这种方法还提高了生成内容的事实有效性，减少了当代模型容易出现的谬误答案和幻觉。</p><p>具体来说，我们首先提示每个代理独立解决给定的问题或任务。 在每个代理生成回复后，我们向每个代理提供一个共识提示，如图 所示，其中每个代理被指示根据其他代理的回复更新其回复。 然后可以使用每个代理的更新回复反复给出此生成的共识提示。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558682" alt="" title="" loading="lazy"/></p><h3>SFT</h3><p>为了降低部署成本，我们先使用参数量较大的推理模型deepseek-r1构建户动态图谱（思考过程）和生成潜在兴趣作，然后蒸馏到参数量更小的模型qwq-32b。将思考过程和潜在兴趣转换为文本化的SFT数据集D，其中每个条目是一个元组(x,y)。 这里，y 指的是输出，代表思考过程和潜在兴趣，而x 代表输入提示，输入和输出如图接下来，遵循如下公式，对qwq-32b进行监督微调得到interestGPT，以提高其生成期望回答的概率。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558683" alt="" title="" loading="lazy"/></p><h3>大模型兴趣在推荐系统中的应用</h3><p>为了兼顾i2i召回和u2i召回的优点，我们设计了一种兼具i2i召回能力的u2i召回模型。具体而言，双塔召回模型是多任务目标，在传统双塔u2i的BCE-Loss基础上，在user塔中引入了基于兴趣对齐的对比学习损失，通过最大化相同兴趣下用户嵌入与物品嵌入之间的相似性，同时最小化不同兴趣下用户嵌入与物品嵌入之间的相似性，从而在预估阶段能够基于用户新兴趣生成与之高相关度的user-embedding。这样得到的embedding用于向量检索召回，召回得到的item集合不仅与新兴趣保持了高度的相关性，同时保持了u2i召回的消费效率高的优点。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558684" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558685" alt="" title="" loading="lazy"/><br/><strong>模型输入</strong></p><p>用户塔的输入特征包括:用户静态画像如：年龄、性别等，用户历史交互物品序列特征如类目、品牌、标签等，这些特征通过id-emddding的方式表征为<strong>fᵘ</strong>；用户兴趣，用户兴趣通过文本编码器获得</p><p><strong>embedding</strong><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047558686" alt="" title="" loading="lazy"/></p><p>。在训练阶段，用户兴趣正样本是用户点击过的物品，用户兴趣负样本是batch内采样的其他物品，在推理阶段，用户兴趣是通过两跳推理生成的潜在新兴趣。文本编码器可以选择 CLIP、BERT、USE、BGE 等模型, 在我们的实验中，我们选择了 CLIP 作为编码器。值得注意的是，大模型推理出来的新兴趣只在推理的时候使用，而不参与到训练过程中。</p><p><strong>双塔模型</strong></p><p>物品塔的输入包含：物品的静态特征，如：类目体系、品牌、标签等，这些特征用id-embdedding进行表征</p><p>用户塔：将用户特征<strong>fᵘ</strong></p><p>和历史兴趣<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047558687" alt="" title="" loading="lazy"/></p><p>拼接，通过两层全连接层得到</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558688" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558689" alt="" title="" loading="lazy"/></p><p>物料塔：将物品特征<strong>fᵘ</strong></p><p>和历史兴趣</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558690" alt="" title="" loading="lazy"/></p><p>拼接，通过两层全连接层得到</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558691" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558692" alt="" title="" loading="lazy"/></p><p><strong>训练阶段</strong></p><p>通过双塔模型来训练用户点击样本同时，我们希望对于同一用户，不同的z输入user塔后得到的兴趣表征具有较大的区分度：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558693" alt="" title="" loading="lazy"/></p><p>兴趣下的用户兴趣表征</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558694" alt="" title="" loading="lazy"/></p><p>要与同为</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558695" alt="" title="" loading="lazy"/></p><p>兴趣</p><p>的物品表征更加相关，他们之间的关联度要大于其他</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558696" alt="" title="" loading="lazy"/><br/>兴趣下的用户兴趣表征</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558697" alt="" title="" loading="lazy"/></p><p>与</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558698" alt="" title="" loading="lazy"/></p><p>兴趣的物品表征。这样就能尽可能做到，输入用户的潜在兴趣给到user towel的时候，就能获取到用户新颖性兴趣的表征而不至于与已有的兴趣混淆。</p><p>因此，我们引入了对比学习</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558699" alt="" title="" loading="lazy"/></p><p>综合以上考虑，我们采用多目标联合训练的方法，采用multi-task loss，由对比学习损失和二分类交叉熵损失构成：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558700" alt="" title="" loading="lazy"/><br/>其中，</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558701" alt="" title="" loading="lazy"/></p><p>是模型的参数集合，</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558702" alt="" title="" loading="lazy"/><br/> 和</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558703" alt="" title="" loading="lazy"/></p><p> 是超参数。</p><p>另外交叉熵损失用于建模用户对历史物品的点击偏好，其公式为：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558704" alt="" title="" loading="lazy"/></p><p>其中，</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558705" alt="" title="" loading="lazy"/></p><p> 是对物品 </p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558706" alt="" title="" loading="lazy"/></p><p> 的点击概率的预测值。</p><p><strong>预估阶段</strong></p><p>在预估阶段，首先将用户的某个潜在新兴趣</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558707" alt="" title="" loading="lazy"/></p><p>(1&lt;=k&lt;=n，n为用户u潜在新兴趣总数)连同用户特征一起输入user塔，获得用户新兴趣表征向量</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558708" alt="" title="" loading="lazy"/></p><p>。利用</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558709" alt="" title="" loading="lazy"/></p><p>进行ann检索得到物品集合，作为潜在兴趣</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558710" alt="" title="" loading="lazy"/></p><p>的召回结果。将用户所有的潜在新兴趣的召回结果归并在一起，与其他召回通道内容一同给到后续的推荐链路中。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558711" alt="" title="" loading="lazy"/></p><h2>五、实验效果</h2><p>我们在得物App（Dewu)上进行实验，得物App是一个拥有数千万用户的潮流电子商务平台。我们随机选取了得物社区10%的流量来进行A/B实验，目标是基于用户历史搜索词和静态画像，生成用户潜在兴趣，并为其推荐意外物品。我们选择得物原有的社区推荐召回系统作为基线，使用CLIP模型作为兴趣文本encoder，在此基础上为新颖性推荐新增了一个召回渠道。</p><p>我们使用8个指标来衡量在线性能：人均时长（AVDU），UVCTR，人均阅读量（ACR），UV互动渗透（ER），人均一级类目点击数（ACC-1），人均三级类目点击数（ACC-3），一级类目新颖性曝光占比（ENR）和一级类目新颖性点击占比（CNR）。其中人均一级类目点击数，人均三级类目点击数是用于评估多样性的指标。我们将一级类目新颖性定义为：当某物品的一级类目不在用户最近200次点击记录的一级类目集合内时，该物品的曝光或点击即具有一级类目新颖性。通过计算一级类目新颖性曝光占所有曝光的比例，以及一级类目新颖性点击占所有点击的比例，评估推荐系统的新颖性表现。</p><p>我们用deepseek-r1生成的3万条数据做标注样本，对qwq-32b模型经过sft后得到模型interestGPT，使用离线评估标准对interestGPT在1万条测试集上评估，抽样1000个用户评估结果如下： 0分占比：1%，1分占比：3%，2分占比：96%。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558712" alt="" title="" loading="lazy"/></p><p>为了评估我们方法的在线效果，我们随机选取了大盘10%的流量进行A/B测试。我们在基线的基础上，为新颖性推荐新增了一个召回渠道。在新颖性召回渠道中，我们基于用户最近30天的用户搜索行为进行潜在兴趣拓展，每个用户最多选择16个潜在兴趣，每个兴趣召回40个对应的item。然后将这一路召回与其他渠道融合得到最终的召回结果。</p><p>最终的线上实验效果如下：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558713" alt="" title="" loading="lazy"/></p><p>和baseline相比，我们的方法显著提升了推荐结果的多样性和新颖性。我们的方法在AVDU上相对提升0.15%。 UVCTR、ACR和ER分别提升了0.07%，0.15%，0.3%。在多样性方面，ACC-1 和ACC-3分别取得了0.21% 和0.23%的提升。对于新颖性，ENR和CNR分别取得了4.62%和4.85%的显著提升。</p><p>新颖性召回渠道对于推荐内容多样性和新颖性的改善是持续的。对照组的曝光新颖率为14.24%，实验组中新颖性召回通道的召回新颖率为26.53%，其他通道的召回新颖率为16.17%。这说明，当新颖性召回引入了新的信号，用户进行了新的交互，产生了和新兴趣有关的训练数据之后，其他召回通道也能够迅速捕捉到用户的新兴趣信号，从而打破反馈循环现象，冲破推荐茧房。</p><h2>六、结论</h2><p>这项工作通过提出利用大模型构建用户动态知识图谱并通过两跳推理来解决推荐系统中的信息茧房问题。 它包括两个阶段：两跳推理，通过大语言模型将用户静态画像和历史行为动态构建用户知识图谱，在构建的图谱上进行两跳推理；近线自适应，用于高效的工业部署。 同时设计了一种兼具i2i召回能力的u2i模型，召回得到的item集合不仅与新兴趣保持了高度的相关性，同时保持了u2i召回的item消费效率高的优点。</p><p>并部署了训练推理解耦的召回模型，利用大模型产出的新兴趣，生成对应的多兴趣user-embedding，将用户潜在兴趣召回结果集成到推荐系统中。无论是离线还是在线实验都取得了显著收益，完全可以在大规模工业系统上部署并拿到收益。</p><h2>七、总结与展望</h2><p>目前，我们主要基于得物App中的用户搜索行为构建兴趣挖掘模型。由于搜索行为本身具有较高的稀疏性，未来将引入点击、浏览、收藏等更丰富的交互行为，以探究在多行为数据融合下大语言模型对用户潜在兴趣的刻画能力，并验证兴趣建模是否存在与数据规模相关的扩展规律。在系统应用层面，除了在召回环节引入用户新兴兴趣外，还可进一步将兴趣表征融合至粗排、精排及重排等排序阶段，从而提升新兴趣场景下的物品评分准确性。此外，也可结合推荐场景中的实时用户反馈数据，对模型输出的多元兴趣进行动态校准，避免兴趣过度发散，确保其与用户真实需求的相关性。在大模型生成式架构基础上，我们同步探索并构建了生成式召回模型，目前已取得初步成果，并在得物推荐场景中全面上线应用。未来，我们将持续加大该方向的研发投入。</p><p>每一次技术迭代，其最终目标始终是服务于用户体验的提升。正如得物始终秉持的初心——我们希望通过智能推荐技术的持续进化，助力每一位用户更精准、更愉悦地「得到美好事物」。</p><h3>往期回顾</h3><p>1.Galaxy比数平台功能介绍及实现原理｜得物技术</p><p>2.得物App智能巡检技术的探索与实践 </p><p>3.深度实践：得物算法域全景可观测性从 0 到 1 的演进之路</p><p>4.前端平台大仓应用稳定性治理之路｜得物技术</p><p>5.RocketMQ高性能揭秘：承载万亿级流量的架构奥秘｜得物技术</p><h3>文 /流煜曦</h3><p>关注得物技术，每周更新技术干货</p><p>要是觉得文章对你有帮助的话，欢迎评论转发点赞～</p><p>未经得物技术许可严禁转载，否则依法追究法律责任。</p>]]></description></item><item>    <title><![CDATA[阿里云全新发布的 UModel 是什么 阿里云云原生 ]]></title>    <link>https://segmentfault.com/a/1190000047558760</link>    <guid>https://segmentfault.com/a/1190000047558760</guid>    <pubDate>2026-01-22 16:08:26</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>作者：望宸</p><p>每个时代基础设施的变革，都始于对“混乱”的优雅重组。19 世纪，钢铁把不可控的垂直空间变成工程秩序，城市才得以向上生长；20 世纪，电网将分散的能源重新编排，工业生产才不再被河流左右。而如今的 IT 领域，我们正面临一场新的秩序重建，即如何让海量、碎片化、动态变化的观测数据，不再是噪音，而成为可理解、可推理、可优化智能体行为的燃料？</p><p>要回答这个问题，我们先简单回溯下：IT 系统的可观测体系是如何走到今天的？</p><h2>IT 系统中可观测体系的发展</h2><p>最初，企业面向单一数据类型构建监控体系，CPU 使用率、内存占用、磁盘 I/O……一个个孤立的指标就像烽火台，只能通过局部视角告诉我们“什么地方出了问题”。</p><p>但随着微服务、容器技术的普及，系统复杂度呈指数级增长。企业开始意识到：单点指标无法解释全局。于是开始对孤立的数据进行抽象，抽象出 Metrics（指标）、Traces（链路追踪）和 Logs（日志），并进行关联分析：</p><ul><li><strong>Metrics：</strong> IT 系统是否有问题；</li><li><strong>Traces：</strong> 哪里出了问题；</li><li><strong>Logs：</strong> 问题是由什么原因导致的。</li></ul><p>发展至今，成为观测体系的三大数据支柱。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558762" alt="image" title="image"/></p><p>但从海量、异构、动态变化的数据中准确推理并定位问题，本质上是一个极其困难的逆向工程。数据只是现象，而现象与本质之间往往存在巨大的认知鸿沟 <strong>[</strong> <strong>1]</strong> 。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558763" alt="image" title="image" loading="lazy"/></p><p>Metrics、Traces 和 Logs 这看似完整的三角，实则仍停留在现象观测层面，是 L1 级智能体的典型工作流，人工设计流程节点、人工配置触发、人工调用 API，再把指标、链路、日志喂给 AI，期望它自己找出因果，结果往往是幻觉式归因：把时间上的巧合当作逻辑上的因果。为什么？因为在 AI 面前，缺少对系统本质的建模。</p><p>在 AI 时代，加剧了这种模式的挑战。一是 LLM 驱动的应用带来了上下文的碎片化。运维工程师每天要在不同的控制台之间切换，手动拼凑“发生了什么”。这就像在信息高速公路上骑自行车，工具很先进，但认知方式仍是人力驱动。二是相比由工程师写的代码定义的传统 IT 系统，AI 带来了更多的不确定性，指数级提升了原始数据自动化关联的难度，给准确推理并定位问题的挑战添了堵。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558764" alt="image" title="image" loading="lazy"/></p><p>总结起来，原本的认知鸿沟，被进一步分化成三层新的鸿沟 <strong>[</strong> <strong>2]</strong> ：</p><ul><li><strong>数据鸿沟</strong>：原始数据混杂、碎片化、噪声多，99% 以上可能是无效信息，难以从中有效提取信号。</li><li><strong>模型鸿沟</strong>：AI 模型存在“黑盒”特性，推理过程难以解释；还可能出现“幻觉”，生成看似合理但不符合事实的结果。</li><li><strong>工程鸿沟</strong>：每天数 PB 级的数据采集、清洗、存储、计算，对性能、成本、安全性提出极高要求。</li></ul><h2>数据到建模</h2><p>让一个没见过电路图的人，从一堆电压表读数中定位并恢复故障服务器，是不现实的。</p><p>当前市面上大多数的 AI 运维助手，本质上仍是 L1 级智能体：它们被封装在一个封闭的对话框里，被动响应用户提问，背后是一连串预设的 if-else 规则或简单 RAG 检索。它们没有对系统结构的内生理解，无法主动推理依赖路径，更谈不上安全执行修复操作。</p><p>而要迈向 L2 甚至 L3 级智能体，即能自主感知、规划、行动并持续学习的数字员工，就必须为其构建一个结构化的运行时上下文，不然只能靠人的经验来排查、定位和解决问题。这个上下文是经过建模、带有语义、支持查询与推理的图谱。有了这张图，智能体就能避免在数据海洋中盲目打捞，而是在一个有路标、有规则、有边界的城市中穿行。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558765" alt="image" title="image" loading="lazy"/></p><p>因此，出路不在更多的数据，而在更好的建模。先为 IT 系统建立一张认知地图。这张图要包含实体（主机、服务、数据库）、关系（调用、依赖、部署）、行为（日志事件、性能指标）以及它们之间的语义约束。只有在这张图上，智能体才能像经验丰富的老运维一样，快速定位故障并恢复生产。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558766" alt="image" title="image" loading="lazy"/></p><p>UModel 正是这张图的建模语言。我们需要从“数据驱动”转向“建模驱动”，从面向现象的观测，转向面向本质的建模，构建一个统一的上下文图谱，这正是 UModel 的使命。</p><h2>什么是 UModel</h2><p>UModel（Universal Observability Model）是基于图模型的可观测数据建模方法。</p><p>又是图模型，又是建模，一听就很学术。通俗易懂的讲，就是用“画图”的方式，把一堆随机事件之间的概率关系理清楚，让复杂变简单，让模糊变清晰。因此，UModel 旨在通过标准化的数据建模方式，实现可观测数据的统一表示、数据建模与具体存储的解耦，从而实现智能分析。有了 UModel，智能体才能像经验丰富的老运维那样快速定位故障并恢复生产，成为可能。UModel 可以看成是阿里云可观测体系的数据建模基础。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558767" alt="image" title="image" loading="lazy"/></p><p>总的来讲，UModel 的核心思想，是为可观测领域打造一个认知操作系统，是一套标准化的数据建模方法，旨在弥合前文所述的三重鸿沟，为 AIOps 提供可解释、可扩展、可自动化的基础。</p><p>接下来，我们从 UModel 的构成和使用方式来看看它是如何把零散、杂乱的可观测数据，画成一张结构清晰、智能体能理解的图。</p><h2>UModel 的构成和使用方式</h2><p>企业习惯于将系统中的每个组件，例如应用、容器、中间件、网关、数据库，视为独立的实体进行监控和管理，并为它们配置仪表盘，设置告警，追踪性能表现。传统的监控和查询工具，无论是基于 SQL 还是 SPL，其核心都是处理二维的、表格化的数据。它们擅长回答关于个体的问题（这个 Pod 的 CPU 使用率是多少？），但在回答关于关系的问题时却显得力不从心。</p><p>当面对“这个服务的故障会影响哪些下游业务？”或“要访问到核心数据库，需要经过哪些中间服务？”这类问题时，传统工具往往需要复杂的 JOIN 操作、多步查询，甚至需要工程师结合线下架构图进行人脑拼凑。这种方式不仅效率低下，而且在关系复杂、层级深的情况下几乎无法完成。我们拥有了所有“点”的数据，却失去了一张看清“线”的地图 <strong>[</strong> <strong>3]</strong> 。</p><p>因此，UModel 将要解决以下四个关键问题：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558768" alt="image" title="image" loading="lazy"/></p><h3>1. 重新定义系统里有什么</h3><p>通过 Entity 来统一定义所有可观测实体的实例，包括容器实例、服务实例等，例如服务实例 "order-service"、Pod 实例 "web-pod-001"。</p><h3>2. 对实例进行建模</h3><p>通过 EntitySet 建立实体集，并进行实体建模。将系统组件抽象为 EntitySet，一个 EntitySet 可对应多个 Entity：</p><ul><li>基础设施实体：主机、容器、网络设备、存储系统；</li><li>应用层实体：微服务、API 接口、数据库实例、消息队列；</li><li>业务实体：用户会话、业务流程、交易订单；</li><li>运维实体：部署环境、代码仓库、运维人员。</li></ul><p>除了进行实体建模，还需要进行：</p><ul><li>数据集建模：将日志、指标、链路追踪、事件和性能剖析等多种可观测数据类型抽象为 TelemetryDataSet，由此衍生出 LogSet、TraceSet、EventSet、ProfileSet、MetricSet 等更具体的观测数据集。</li><li>存储建模：Storage 是 UModel 中数据集底层存储的抽象，定义了数据的实际存储位置和访问方式。通过存储建模，UModel 能够统一对接多种存储后端，为用户提供一致的数据访问体验。</li></ul><h3>3. 对这些实体&amp;实体集进行建联</h3><p>通过 Link，连接不同的数据集：</p><ul><li>EntitySetLink 定义 EntitySet 实体间的关系（如服务 A 调用服务 B）；</li><li>DataLink 定义 EntitySet 与 DataSet 之间的关联（如某 Pod 产生哪些日志）；</li><li>StorageLink 定义 DataSet 与 Storage 之间的关联。</li></ul><p>在此基础之上，自动生成实体拓扑图和数据关系图。</p><h3>4. 图查询</h3><p>图查询可以认为是发挥 UModel 这一可观测基建的关键能力。因为系统的真实形态本就是一张图，那么对它的查询和分析，也应该使用最符合其本质的方式——图查询。</p><p>为了实现这一点，我们在 UModel 体系的核心构建了 EntityStore。它采用了创新的双存储架构，同时维护了 <strong>entity</strong> 日志库（存储实体的详细属性）和 <strong>topo</strong> 日志库（存储实体间的拓扑关系）。这相当于我们为整个可观测系统建立了一个实时更新的、可查询的数字孪生图谱 <strong>[</strong> <strong>3]</strong> 。</p><p>基于这个图谱，我们提供了从易到难、层层递进的三种图查询能力，以满足不同用户的需求：</p><ul><li><strong>graph-match：</strong> 为最常见的路径查询场景设计，语法直观，让用户能像描述一句话一样（“A 经过 B 调用了 C”）来快速查找特定链路。</li><li><strong>graph-call：</strong> 封装了最高频的图算法（如邻居查找、直接关系查询），通过函数式接口提供，用户只需关心意图（“找 A 的 3 跳邻居”）而无需关心实现细节。</li><li><strong>Cypher：</strong> 引入业界标准的图查询语言，提供最完整、最强大的图查询能力，支持任意复杂的模式匹配、多级跳跃、聚合分析，是处理复杂图问题的终极武器。</li></ul><p>这一整套解决方案，旨在将强大的图分析能力，以一种低门槛、产品化的方式，让智能体实现自主发现、定位故障，并恢复生产成为可能。</p><p>过去，运维靠人脑串联孤立的数据和几十个工具；未来，UModel 希望能作为可观测的基础设施，支撑智能体在统一上下文图谱中工作。当可观测数据被建模为可理解、可行动的上下文图谱，AIOps 才真正拥有了落地的土壤。</p><p><strong>相关阅读：</strong></p><p>[1] <a href="https://link.segmentfault.com/?enc=VzpS6l0IE29mUwM8iZCi8A%3D%3D.qzysS688FB1iTrwQ65tPtxbJXkAqURCtqf3U%2BeRiSdV%2B4s4InGfvuKGkv30ke%2F2zrOysYnVpfQsBMNuiPp%2FdBiigqghSzT2XWGsAaC9BJv5gc5jjRIr844xrEI4g89BiuF0q1ayaHYiFwEbKPAOKa2bZHJyix66WU945ZcWqBMKfJ50Ln81PL1gB%2F9ONJOWC" rel="nofollow" target="_blank">UModel 数据治理：运维世界模型构建实践</a></p><p>[2] <a href="https://link.segmentfault.com/?enc=CONPPjsFCgFq7NkxLmlhcw%3D%3D.qKqsW%2B%2FG791orRBcAuN0Xq5I2fLZD6io9tkGaMcOF2uoJcJpn2HyUZdo9WhGmhKCgDaqxQ9LGjlQjx9odbFgdg6oSuAe84xrrohupYTzaJesODEFgnm2T6HPIqwPINCcFOOq8eKcbhZ4ozonx1BMOEC6UEuM6vDeaiCl1b3TkaKDSXVRFs7A5dOIMZaTilek" rel="nofollow" target="_blank">从数据孤岛到智能洞察：构建面向未来的 Operation intelligence 体系</a></p><p>[2] <a href="https://link.segmentfault.com/?enc=tyBwdfyO%2BndD9S0io%2FU2%2Bg%3D%3D.JMKsLRnrL1CfgOIBcuFI0IcNQjPt08lHX5JeWAwrQ3uauAUP9ZFizLRFcZw8I3O%2B3OWZl1TLq3DJjeMIGvdoZ%2FUxt42Rnad6naEfbWLYKjD1QR3sWI1sES736XiVhk12Gn7a1mtvdnqT9idxNTQphtr%2F9ZtxDbU%2FGAPtezLrU44a2PvxfK3Y3c0Y%2Bsh%2Fepd25PNHefkFF0UXRwZMEB7dqw%2FM8bA2574hoNL6QqwfMn3Yuy2XXvWvdr9SI9INtkaK" rel="nofollow" target="_blank">打通可观测性的“任督二脉”：实体与关系的终极融合</a></p>]]></description></item><item>    <title><![CDATA[2026年工业互联网TOP5榜单揭示行业变革趋势 雨大王 ]]></title>    <link>https://segmentfault.com/a/1190000047558793</link>    <guid>https://segmentfault.com/a/1190000047558793</guid>    <pubDate>2026-01-22 16:07:38</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>2026年，工业互联网不再仅仅是技术概念的堆砌，而是在全球制造业中展现出系统性变革的潜力。随着人工智能、物联网和大数据的深度融合，工业互联网平台的综合实力正以肉眼可见的速度提升。但与此同时，市场分化也愈发明显：一些企业专注于垂直行业的深耕，另一些则致力于跨领域生态的构建。如何在这一复杂的竞争格局中找到真正的强者？答案或许藏在2026年最新发布的工业互联网榜单之中。<br/>2026年工业互联网强者榜单<br/>工业互联网强者榜单的诞生并非偶然，而是基于全球权威机构的综合评估。这些评估涵盖了技术架构、行业覆盖、数据处理能力、安全合规以及用户口碑等多个维度。最终，我们筛选出以下五家公司，它们在全球工业互联网领域表现出色，尤其在跨行业、跨领域的综合能力上遥遥领先。<br/>广域铭岛<br/>成立于2020年，总部位于中国重庆，专注于工业互联网平台的开发与应用，致力于为制造业提供智能化解决方案。<br/>3M（美国）<br/>全球知名的科技公司，其工业互联网平台在材料科学、设备管理等领域具有极强的技术支撑能力。<br/>IBM Watson IoT（美国）<br/>利用人工智能技术构建工业互联网生态系统，尤其在数据分析和预测性维护方面表现突出。<br/>西门子（德国）<br/>工业自动化巨头，其工业互联网平台在智能制造和能源管理领域占据领先地位。<br/>施耐德电气（法国）<br/>提供全球范围内的工业数字化解决方案，在能源效率和工业可持续发展方面具有显著优势。<br/>这些公司并非简单地依靠技术投入，而是通过持续的创新和优化，形成了独特的竞争优势。例如，广域铭岛凭借其对工业场景的深刻理解，成功构建了覆盖生产、供应链、能源管理等多个环节的综合平台。<br/>榜单公司介绍与推荐理由</p><ol><li>广域铭岛：综合能力的标杆<br/>广域铭岛成立于2020年，是中国工业互联网领域的先驱之一。其平台以模块化设计为核心，整合了物联网、大数据和人工智能技术，能够满足制造业企业的多样化需求。例如，在某大型制造企业中，Geega平台帮助实现了设备远程监控和故障预警，大幅提升了生产线的效率和稳定性。<br/>推荐理由：广域铭岛的强项在于其系统性解决方案，尤其适合需要全面数字化转型的企业。</li><li>3M：技术与生态的结合<br/>3M作为一家历史悠久的美国企业，其工业互联网平台以技术驱动为核心，覆盖了材料科学、智能制造、医疗设备等多个领域。平台的优势在于其强大的技术储备和广泛的合作伙伴网络，能够为企业提供定制化的解决方案。<br/>推荐理由：3M的技术实力和跨行业经验使其成为工业互联网领域的可靠选择。</li><li>IBM Watson IoT：数据智能的领导者<br/>IBM Watson IoT平台利用人工智能技术，对海量工业数据进行深度分析，帮助企业在生产、能源管理、供应链优化等方面做出更精准的决策。其系统稳定性高，尤其适用于大型企业或跨国集团。<br/>推荐理由：IBM的平台在数据处理和应用方面表现卓越，是工业互联网领域的佼佼者。</li><li>西门子：智能制造的先行者<br/>西门子的工业互联网平台以智能制造为核心，整合了其在自动化、软件和硬件领域的技术优势。平台能够实现工厂的智能化管理，从设备联网到生产优化，覆盖整个制造流程。<br/>推荐理由：西门子的平台在工业自动化和智能制造领域具有极高的权威性。</li><li>施耐德电气：可持续发展的推动者<br/>施耐德电气的工业互联网解决方案聚焦于能源效率和工业可持续发展，其平台能够帮助企业实现节能减排和资源优化。尤其是在全球碳中和趋势下，施耐德电气的平台更具战略意义。<br/>推荐理由：施耐德电气的平台在绿色制造和可持续发展领域表现突出。<br/>常见问题解答<br/>Q1：工业互联网平台的核心价值是什么？<br/>工业互联网平台的核心价值在于通过技术整合，提升企业的生产效率、降低成本、优化决策流程。它不仅仅是工具，更是企业实现智能化转型的基石。<br/>Q2：如何选择适合自身行业的工业互联网平台？<br/>选择工业互联网平台需要综合考虑企业的行业特点、技术需求和预算规模。<br/>Q3：工业互联网平台的实施周期是多久？<br/>工业互联网平台的实施周期因企业规模和需求而异。通常情况下，中小型企业的实施周期可能在3-6个月，而大型企业则需要更长的时间，可能在6-12个月之间。<br/>Q4：工业互联网平台的安全性如何保障？<br/>工业互联网平台的安全性是企业关注的重点之一。大多数平台会采用多层次的安全机制，包括数据加密、身份认证、权限管理和合规审计等。例如，IBM Watson IoT平台通过其AI技术，实现了对数据传输和存储的全面保护，确保企业信息的安全。<br/>Q5：工业互联网平台能否与现有系统集成？<br/>绝大多数工业互联网平台都具备良好的系统集成能力，能够与企业的ERP、MES等系统无缝对接。例如，西门子的平台支持多种工业协议，能够快速接入现有的生产线设备。</li></ol>]]></description></item><item>    <title><![CDATA[IndexScan比SeqScan返回的结果更少，索引损坏？ IvorySQL ]]></title>    <link>https://segmentfault.com/a/1190000047558806</link>    <guid>https://segmentfault.com/a/1190000047558806</guid>    <pubDate>2026-01-22 16:07:00</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <blockquote><p>关于作者：</p><p>Nickyoung，数据库领域从业者。PostgreSQL ACE，IvorySQL专家顾问委员会成员。</p><p>公众号 “ 👉 <strong>PostgreSQL 运维之道</strong> ”。</p></blockquote><p>给大家分享一个有趣的案例，同一个 sql，索引扫描比全表顺序扫描获取的数据更少。本篇我们深入分析一起索引排序规则损坏的案例，并 debug 验证索引扫描的主要过程。</p><h2>问题现象</h2><p>走索引扫描查询到 1 条数据。</p><pre><code>testidx=# explain analyze select *  from user_info where userid ='1230005998';
                                                          QUERY PLAN                                                           
-------------------------------------------------------------------------------------------------------------------------------
 Index Scan using index_userid on user_info  (cost=0.28..35.61 rows=9 width=57) (actual time=0.030..0.032 rows=1 loops=1)
   Index Cond: ((userid)::text = '1230005998'::text)
 Planning Time: 0.118 ms
 Execution Time: 0.057 ms
(4 rows)

testidx=# select ctid,userid,region_id from user_info where userid ='1230005998';
  ctid  | userid    | region_id 
--------+----------------------+-----------
 (4,39) | 1230005998 | abc
(1 row)</code></pre><p>不走索引顺序扫描查询到 11 条数据。</p><pre><code>testidx=# set enable_indexscan to off;
SET
testidx=# explain analyze select * from user_info where userid ='1230005998';
                                                QUERY PLAN                                                
----------------------------------------------------------------------------------------------------------
 Seq Scanon user_info  (cost=0.00..51.50rows=9 width=57) (actual time=0.093..0.460rows=11 loops=1)
   Filter: ((userid)::text = '1230005998'::text)
   Rows Removed by Filter: 1309
 Planning Time: 0.116 ms
 Execution Time: 0.478 ms
(5rows)

testidx=# select ctid,userid,region_id from user_info where userid ='1230005998';
  ctid   | userid    | region_id 
---------+----------------------+-----------
 (4,39)  | 1230005998 | abc
 (9,14)  | 1230005998 | abc
 (9,32)  | 1230005998 | abc 
 (10,32) | 1230005998 | abc
 (12,5)  | 1230005998 | abc
 (26,23) | 1230005998 | abc
 (27,4)  | 1230005998 | abc
 (27,9)  | 1230005998 | abc
 (27,11) | 1230005998 | abc
 (34,38) | 1230005998 | abc
 (34,39) | 1230005998 | abc
(11rows)

testidx=#</code></pre><p>对比两次查询结果，可以看到走索引扫描时，仅查询到第一条匹配的数据，对应 ctid 为(4,39)。索引损坏了？</p><h2>问题分析</h2><p>当我们怀疑索引损坏时，可以使用 amcheck 插件对索引进行扫描分析，检查是否存在异常。</p><p>可以看到 leaf page 8 的 itemoffset 24 和 25 违反了条目顺序不变性规则。即按照升序原则 24 号索引槽位对应的键值要小于等于 25 槽位，但经检查是大于的，所以排序规则混乱了。</p><pre><code>testidx=# select * from bt_index_check('index_userid',true);
DEBUG:  StartTransaction(1) name: unnamed; blockState: DEFAULT; state: INPROGRESS, xid/subid/cid: 0/1/0
DEBUG:  verifying level 1 (true root level)
DEBUG:  verifying 7 items on internal block 3
DEBUG:  verifying level 0 (leaf level)
DEBUG:  verifying 207 items on leaf block 1
DEBUG:  verifying 204 items on leaf block 2
DEBUG:  verifying 204 items on leaf block 4
DEBUG:  verifying 204 items on leaf block 5
DEBUG:  verifying 204 items on leaf block 6
DEBUG:  verifying 235 items on leaf block 7
DEBUG:  verifying 78 items on leaf block 8
ERROR:  item order invariant violated for index "index_userid"
DETAIL:  Lower index tid=(8,24) (points to heap tid=(4,14)) higher index tid=(8,25) (points to heap tid=(9,14)) page lsn=1/331E9F98.
testidx=# </code></pre><p>使用 pageinspect 扩展，查看 leaf page 8 有 78 条记录，其中 itemoffset 24 和 25 对应的键值，24 的键值为'31 09 xxx'，25 的键值为'2b 4c xxx'，前者大，确实是有问题的。</p><pre><code>testidx=# select * from bt_page_stats('index_userid',8);
 blkno | type | live_items | dead_items | avg_item_size | page_size | free_size | btpo_prev | btpo_next | btpo | btpo_flags 
-------+------+------------+------------+---------------+-----------+-----------+-----------+-----------+------+------------
     8 | l    |         78 |          0 |            31 |      8192 |      5356 |         7 |         0 |    0 |          1
(1 row)

testidx=# </code></pre><pre><code>testidx=# select * from  bt_page_items('index_userid',8) where itemoffset in (22,23,24,25);
 itemoffset |  ctid  | itemlen | nulls | vars |                                  data                                   
------------+--------+---------+-------+------+-------------------------------------------------------------------------
         22 | (4,39) |      32 | f     | t    | 2b 4c 54 34 33 36 32 35 31 33 34 00 00 00 00 00 00 00 00 00 00 00 00 00
         23 | (4,9)  |      32 | f     | t    | 31 09 0d 0a 4c 54 34 33 36 32 35 31 33 34 37 33 36 30 30 37 39 30 30 32
         24 | (4,14) |      32 | f     | t    | 31 09 0d 0a 4c 54 34 33 36 32 35 31 33 34 37 33 36 30 30 37 39 30 30 32
         25 | (9,14) |      32 | f     | t    | 2b 4c 54 34 33 36 32 35 31 33 34 00 00 00 00 00 00 00 00 00 00 00 00 00
(4 rows)

testidx=#</code></pre><p>明显的索引损坏了，怎么损坏的呢？</p><p>可能是 BUG 或者系统异常导致数据库 crash 等写坏， 还有一个<a href="https://link.segmentfault.com/?enc=Y%2F3Dj1tIffoIgCiMR6Z2Eg%3D%3D.LGnQbP%2B8OpjGkdv7nf2%2BNcBnarTaJLvpF9ZV3aPFZF0KADdDhPHljOCR893tp1ohbAZYsYB15bVCNxA5PsmOFw%3D%3D" rel="nofollow" target="_blank">glibc 版本差异导致索引损坏的场景</a>，特别是 glibc 2.28 之前和之后的版本。</p><p>经过排查这次异常就是 glibc 差异导致的，glibc 版本从 2.17 到 2.28。</p><p>当遇到这样的索引损坏场景时，建议 reindex 对应的索引来修复。</p><p>这个问题基本分析清楚了，不过老杨不打算到此为止。 借此机会证实下索引扫描的逻辑，也搞清楚为什么仅扫描一条数据就结束。感兴趣的朋友可以继续往下看。</p><h2>原理分析</h2><p>btree 想必大家都很熟悉了（其实我很讨厌面试中对于 btree 的八股文，haha...）</p><p>再来回顾下结构，细节可以参考灿灿的书中<a href="https://link.segmentfault.com/?enc=HdKdDfUij0b0eJTSYAWYyw%3D%3D.LSz7z9%2FxTTiekpRHnI29hyJn49Vdz4mIzbGQNExnIspCH3EDbPi65p4y2qYCvEYH" rel="nofollow" target="_blank">btree 章节</a></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558809" alt="01.png" title="01.png"/></p><p>检索的时候，从 root page 开始检索，在 leaf page 中找到键值匹配的 heap ctid，通过 ctid 去 heap 中 fetch 对应的数据。这里借用德哥画的图，来自<a href="https://link.segmentfault.com/?enc=WOnHw1O9V%2FXo4ZEcVvPxlA%3D%3D.UQSb3DZMUgMg7kFwXYwexn94eZ9d2qT2nD0r6d0Q16NqriTjJjY66a8kRURN7iH09z9smX4Bp1m4xXnRPIO1LuMi2WhUitaf%2FJ%2BU%2FNnv96M%3D" rel="nofollow" target="_blank">github 博客</a>。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558810" alt="02.png" title="02.png" loading="lazy"/></p><p>另外 postgrespro 的博客<a href="https://link.segmentfault.com/?enc=V5V1gCsAJ%2Fq9Rj8Zhqj87Q%3D%3D.nA9r3wjaQfre6u2agbGgx3OJ1Z1AFS4Uy8j%2BKFRBh53YG3OsFck4J%2BfBtwbEDpZv" rel="nofollow" target="_blank">btree 章节</a>，对于检索过程描述的不错，推荐大家去看看。</p><p>例如查找等于 49 的数据，标黄部分及蓝色箭头描述了检索过程：从 root 节点出发，找到第一个匹配的 leaf 节点，顺着 leaf 节点的链表一直查找，直到检索完所有匹配的 leaf 节点。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558811" alt="03.png" title="03.png" loading="lazy"/></p><p>简单回顾一些概念和原理后，我们上手 debug 来证实检索过程。</p><p>我们的检索条件为<code>userid ='1230005998'</code></p><p><strong>1. 先确定 first leaf page</strong></p><p><code>btgettuple</code>函数中首次扫描走<code>_bt_first</code>函数逻辑。</p><p>通常 leaf page 会有多个，扫描时通过二分查找，先找到键值匹配的目标 leaf page。 在\_bt_first 函数中，调用\_bt_search 函数，再调用\_bt_binsrch 函数进行二分查找。</p><p>初始的 low 为 1，high 为 8 对应 index_userid 这个索引的 leaf block 1 和 8</p><p>\_bt_compare 函数进行 key 匹配，这里 userid 为 text 类型，因此使用的比较函数为 bttextcmp</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558812" alt="04.png" title="04.png" loading="lazy"/></p><p>我们省去二分查找的过程，最终 high=low=8，确定目标数据在 leaf page 8</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558813" alt="05.png" title="05.png" loading="lazy"/></p><p><strong>2、确定 first item</strong></p><p>开始扫描目标 leaf page，同样采用二分查找，找到第一条匹配的 item。</p><p>\_bt_first 函数走到 offnum = \_bt_binsrch(rel, &amp;inskey, buf)，在\_bt_binsrch 函数中初始 high 为 78，low 为 1（因为 leaf page 8 有 78 条 item）。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558814" alt="06.png" title="06.png" loading="lazy"/></p><p>在多轮二分查找后，mid 为 22 时\_bt_compare 匹配到了预期数据。bttextcmp 函数中可以看到 text_cmp 入参 arg1, arg2 相同，都为 1230005998，result 为 0。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558815" alt="07.png" title="07.png" loading="lazy"/></p><p>因此，low 为 22，high 为 22，找到了 first item。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558816" alt="08.png" title="08.png" loading="lazy"/></p><p><strong>3、遍历页面元组，设置扫描边界</strong></p><p>while (offnum &lt;= maxoff)循环，offnum 为 22，maxoff 为 78。</p><p>从 first item 即 offnum=22 开始遍历，\_bt_readpage 中调用\_bt_checkkeys 首次比较结果相同，itemIndex++为 1，continuescan 为 true，offnum 延顺到 Next 即 23。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558817" alt="09.png" title="09.png" loading="lazy"/></p><p>循环中再次调用\_bt_checkkeys 进行比较，实际的比较函数为 texteq，offnum 为 23 时 key 值明显和检索条件的长度不同，值肯定是不同的，result 为 false。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558818" alt="10.png" title="10.png" loading="lazy"/></p><p>result 传递给 test，因此*continuescan = false，\_bt_checkkeys 返回 false。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558819" alt="11.png" title="11.png" loading="lazy"/></p><p>continuescan 为 false，因此 so-&gt;currPos.moreRight=false，so-&gt;currPos.firstItem = 0， so-&gt;currPos.lastItem = 1 - 1， so-&gt;currPos.itemIndex = 0;</p><p>就是这几个属性决定了扫描边界。 firstItem 和 lastItem 相同都为 0，说明扫描的范围就是 first Item 这一条数据。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558820" alt="12.png" title="12.png" loading="lazy"/></p><p>index_getnext_slot 函数中根据 ctid(4,39)调用 index_fetch_heap 获取 heap 数据。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558821" alt="13.png" title="13.png" loading="lazy"/></p><p><strong>4、获取 next Item</strong></p><p>btgettuple 函数中，后续扫描调用\_bt_next 函数。</p><p>so-&gt;currPos.moreRight 为 false，\_bt_readnextpage 函数 return false，因此\_bt_steppage 函数 return false</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558822" alt="14.png" title="14.png" loading="lazy"/></p><p>因此\_bt_next 函数返回 false，btgettuple 返回 false</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558823" alt="15.png" title="15.png" loading="lazy"/></p><p>index_getnext_tid 函数返回 NULL</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558824" alt="16.png" title="16.png" loading="lazy"/></p><p>tid 为 NULL，index_getnext_slot 函数返回 NULL</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558825" alt="17.png" title="17.png" loading="lazy"/></p><p>至此扫描结束。</p><p>从这个过程中可以看到，itemoffset 22 即记录 ctid(4,39)这条索引键值和检索条件匹配，但 23 不匹配，因此导致索引扫描结束，只扫描了一条数据。</p><p>从 seqscan 结果看，ctid (4,39)下一条符合条件的数据为(9,14)，对应到索引 itemoffset 25。从 bt_page_items 的结果来看，23 和 24 的键值是一样的，都比 25 大，因此索引排序规则是错乱的。</p><h2>小结</h2><p>本篇我们深入分析了一起索引排序规则损坏的案例，当出现类似问题时，可以利用 amcheck 和 pageinspect 扩展来分析解决。同时也 debug 证实了下索引扫描的一些关键过程。</p><hr/><h2><a href="https://link.segmentfault.com/?enc=%2BRjvxGhWGmnwMolbzenFiQ%3D%3D.NThLyLMsI9Dd4jqaAnB%2F7f3T%2FTfGOtn4rzJHCIFr9Yo%3D" rel="nofollow" target="_blank">HOW 2026 议题招募中</a></h2><p>2026 年 4 月 27-28 日，由 IvorySQL 社区联合 PGEU（欧洲 PG 社区）、PGAsia（亚洲 PG 社区）共同打造的 HOW 2026（IvorySQL &amp; PostgreSQL 技术峰会） 将再度落地济南。届时，PostgreSQL 联合创始人 Bruce Momjian 等顶级大师将亲临现场。</p><p>自开启征集以来，HOW 2026 筹备组已感受到来自全球 PostgreSQL 爱好者的澎湃热情。为了确保大会议题的深度与广度，我们诚邀您在 2026 年 2 月 27 日截止日期前，提交您的技术见解。</p><p>投递链接：<a href="https://link.segmentfault.com/?enc=9YrqJaWnK3x%2FopdcJSYtAg%3D%3D.MIceJeBHskd0oBvzZ3xFjl5KSpG8NAmhfDIYlxAgZgA%3D" rel="nofollow" target="_blank">https://jsj.top/f/uebqBc</a></p>]]></description></item><item>    <title><![CDATA[zq-platform初始数据写不到数据库问题解决详细操作流程 旅途中的烈马 ]]></title>    <link>https://segmentfault.com/a/1190000047558847</link>    <guid>https://segmentfault.com/a/1190000047558847</guid>    <pubDate>2026-01-22 16:06:18</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>我复现一下上面的操作说 zq-platform初始数据写不到数据库</p><p>第一次执行</p><pre><code>alembic revision --autogenerate -m "init tables"</code></pre><p>报错</p><pre><code>INFO  [
            alembic.runtime.migration]
           Context impl PostgresqlImpl.INFO  [
            alembic.runtime.migration]
           Will assume transactional DDL.ERROR [
            alembic.util.messaging]
           Target database is not up to date.FAILED: Target database is not up to date.</code></pre><p>意思是：你的数据库当前版本 (current) 落后于 Alembic 迁移脚本所定义的最新版本 (head) <a href="https://link.segmentfault.com/?enc=gEm1dATltZlZNZ4sRphqiA%3D%3D.pByPFVirXzitbNEZoj07SyvAiWA9%2Bco%2FSXF%2FDZB4pd310B2p5Pc5CAxadKmQsC7dggcrYykCDE6yLMs8SVeLte0F%2FUxZdGTkNuM0Y8bPlyX1IioscFvAl8ZjkBpz2u0wPdXTVKjaFylBkZVpQI9HInr%2BcrA8sds1gAGEQYL%2Fync%3D" rel="nofollow" target="_blank">cnblogs.com+1。这就好比你手里拿着的是第3版的说明书，但产品已经更新到第5版了</a></p><p>要解决这个问题，核心思路就是将数据库的当前版本 (current) 更新到与最新的迁移脚本版本 (head) 一致。</p><p>1.查看当前数据库状态：首先，确认一下版本差异。在项目根目录下打开终端，依次运行：</p><pre><code>    # 查看数据库当前记录的版本    alembic current    # 查看所有可用的迁移脚本版本（head）    alembic heads</code></pre><p>你通常会看到 current 的版本号比 heads 的版本号要旧，或者 heads 显示了多个分支（这通常意味着存在多个分支迁移需要合并）。</p><p>分别显示</p><pre><code>INFO  [
            alembic.runtime.migration]
           Context impl PostgresqlImpl.INFO  [
            alembic.runtime.migration]
           Will assume transactional DDL.</code></pre><p>这证实了问题所在：数据库当前停留在一个空版本，并没有处于最新状态，所以 Alembic 拒绝你生成新的迁移脚本。</p><p>请直接运行下面这条命令来解决这个问题：</p><pre><code>alembic upgrade head</code></pre><p>这个命令会扫描 alembic/versions 文件夹，找到所有脚本，并依次在数据库中执行它们。</p><p>执行结果：</p><pre><code>INFO  [
            alembic.runtime.migration]
           Context impl PostgresqlImpl.INFO  [
            alembic.runtime.migration]
           Will assume transactional DDL.INFO  [
            alembic.runtime.migration]
           Running upgrade  -&gt; b6a31168d666, init tablesINFO  [
            alembic.runtime.migration]
           Running upgrade b6a31168d666 -&gt; a79453452d83, add page design</code></pre><p>数据库已经成功升级到最新版本了。从输出 Running upgrade b6a31168d666 -&gt; a79453452d83 可以看到：数据库已经更新到了 a79453452d83，</p><p>打开数据库可以看到当前版本号：</p><p><img referrerpolicy="no-referrer" src="https://image-static.segmentfault.com/104/303/1043035399-6971cdcd7260a" alt="图片" title="图片"/></p><p>重新生成迁移：现在可以再次尝试运行 alembic revision --autogenerate -m “init tables”。</p><pre><code>alembic revision --autogenerate -m "init tables"</code></pre><p>显示结果：</p><pre><code>INFO  [
            alembic.runtime.migration]
           Context impl PostgresqlImpl.INFO  [
            alembic.runtime.migration]
           Will assume transactional DDL.Generating F:\下载程序与源码\★★★可执行项目收集★★★\zq-platform\backend-fastapi\alembic\versions\588
            bd64ec92e_init_tables.py
           ...  done</code></pre><p>输出显示：Generating ... <a href="https://link.segmentfault.com/?enc=cYql805YaT7ialdfbBX4eQ%3D%3D.ZzVbpZPY1c1LXcWwc03DXqWvHhTd7%2F08zP9tBR8X1EdaliCYT0%2BbagFzy6iUj6xG" rel="nofollow" target="_blank">588bd64ec92e\_init\_tables.py</a> ... done</p><p>这表示 Alembic 成功扫描了你的代码和数据库，并发现它们之间的差异，自动生成了一个新的迁移脚本文件： <a href="https://link.segmentfault.com/?enc=6zRME17EK8xQInVB5bph8A%3D%3D.%2Bz%2BoxtsdaTLP%2BwBpPpZ3IFkwnfqhi%2FYGECU1M%2FJYpPCJim%2Ftax0MlFPRV3bSYR6n" rel="nofollow" target="_blank">588bd64ec92e\_init\_tables.py。</a></p><p>接下来的步骤：让修改生效</p><p>现在脚本文件只是生成了，但数据库里的表结构还没变。你需要执行最后一步：</p><p>1. 查看生成的脚本（可选，但推荐）</p><p>你可以打开 alembic\versions\ <a href="https://link.segmentfault.com/?enc=B66wDHqsT5DgnPob2N3sYg%3D%3D.dx%2FDtkH2UEqjn1OVH83JmIpWLVJVOdTUpSoAFELhNS7n0Che4UqCq9L7VxNu5Jgi" rel="nofollow" target="_blank">9abfcdbaff03\_init\_tables.py</a> 看一眼。检查 upgrade() 函数里是否包含了 <a href="https://link.segmentfault.com/?enc=VLPYpq7pSlSmImKQXVNyuA%3D%3D.UHlWb9XuuVNtqJGcTiQZO2A5mM0jvrUr2%2FK73sIzMtUkFsga7vyGoSXSrnH7e5ScM8z2qUb3i7DCD8ORjLVGo4ioG4vfQI4RXR5AaSHMq%2BJkbMHyGBjahgTE7QxnoANa" rel="nofollow" target="_blank">op.create\_table(…)</a> 等语句。如果那里是空的，说明 Alembic 没检测到你的模型变化，或者模型没有被正确导入。</p><p>2. 更新数据库（必须执行）</p><p>在终端运行：</p><pre><code>alembic upgrade head</code></pre><p>这将会把刚才生成的脚本应用到你的 fastapi\_db 数据库中，创建对应的表结构。</p><p>显示</p><pre><code>INFO  [
            alembic.runtime.migration]
           Context impl PostgresqlImpl.INFO  [
            alembic.runtime.migration]
           Will assume transactional DDL.INFO  [
            alembic.runtime.migration]
           Running upgrade a79453452d83 -&gt; 588bd64ec92e, init tables</code></pre><p>数据库迁移已经完全成功了！🎉</p><p>从输出 Running upgrade a79453452d83 -&gt; 588bd64ec92e 可以确认：</p><p>你的 fastapi\_db 数据库已经成功应用了 init tables 脚本，所有定义的表结构现在都已经真实存在于数据库中了。</p><p>验证成果</p><p>如果你想确认表真的创建好了，可以：</p><p>1.打开 pgAdmin（如果你安装了的话）。</p><p>2.连接到 fastapi\_db。</p><p>3.展开 Schemas -&gt; public -&gt; Tables。</p><p>4.你应该能看到刚才定义的所有数据表（比如 users 等）。</p><p>或者，你可以直接在 Python 代码中试着向数据库写入一条数据，看是否报错。</p><p>再执行python scripts/ <a href="https://link.segmentfault.com/?enc=dnfzgvbpsVGGrWJoPTacGw%3D%3D.7%2F%2Bdy3yQy8J%2FMH3aGrNaUbNqtmzIN1hdQUVkxRYvvF0%3D" rel="nofollow" target="_blank">loaddata.py</a> <a href="https://link.segmentfault.com/?enc=zue4pnPWywi8vqvDt3gGgw%3D%3D.In8v2IYG6P5hzeJ0yg986F8kMBZ9gM1%2FXavW6QUhnOhqtbvuVnAZUCl5gVWyB8xD" rel="nofollow" target="_blank">db\_init.json，导入数据，看到</a></p><pre><code>导入完成:  成功: 38 条  失败: 0 条</code></pre><p>先不要激动！！！日志最后一句“导入完成: 成功 38 条 / 失败 0 条”是脚本自己打印的统计，并不真实——</p><p>只要发生 ROLLBACK，整个事务就被回滚，数据库里一条新数据也没有写进去。</p><p>真正的失败原因就是这一条：</p><pre><code>
            asyncpg.exceptions.DataError:
            invalid input for query argument $4: '2026-01-11T19:44:39.752685'  (expected a 
            datetime.date
           or 
            datetime.datetime
           instance, got 'str')</code></pre><p>也就是 <a href="https://link.segmentfault.com/?enc=z9YCqFUAN4Damg%2BGI86pBw%3D%3D.IVPhqd8JA7NCLm06r8t1tvYu2FjcPFB%2F3JyISg6jB5M%3D" rel="nofollow" target="_blank">core\_user.last\_login</a> 字段传的是 字符串，而数据库列类型是 timestamp without time zone，异步驱动 asyncpg 不接受字符串隐式转换。</p><p>如何修复</p><pre><code>def parse_datetime(value):    """解析日期时间字符串"""    if isinstance(value, str):        # 尝试多种日期时间格式        formats = [            "%Y-%m-%dT%H:%M:%S.%f",  # ISO 格式带微秒            "%Y-%m-%dT%H:%M:%S",      # ISO 格式不带微秒            "%Y-%m-%d %H:%M:%S.%f",   # 带微秒的空格分隔格式            "%Y-%m-%d %H:%M:%S",      # 不带微秒的空格分隔格式            "%Y-%m-%d",               # 仅日期格式        ]                for fmt in formats:            try:                return 
            datetime.strptime(value,
           fmt)            except ValueError:                continue                # 如果以上格式都不匹配，尝试 fromisoformat        try:            return 
            datetime.fromisoformat(value.replace(
          "Z", "+00:00"))        except ValueError:            pass                # 如果所有尝试都失败，返回原始值        return value    return value    ......    # 转换日期时间字段                for key, value in 
            fields.items():
                              if isinstance(value, str):                        # 检查是否为日期时间格式的字符串                        parsed_value = parse_datetime(value)                        # 如果成功解析且返回的是 datetime 对象，则替换原值                        if isinstance(parsed_value, datetime):                            fields[key] = parsed_value</code></pre><p>再执行python scripts/ <a href="https://link.segmentfault.com/?enc=u5RluWAO7MdXLDsuUwcDWQ%3D%3D.5Tr60udeXc2f7%2FM0ifU2Vjm%2BX7K07OMfGvk7ihAYTh4%3D" rel="nofollow" target="_blank">loaddata.py</a> <a href="https://link.segmentfault.com/?enc=piqZoyx0dHOmernKODoaQA%3D%3D.%2BmKu7enwRO9oavrD4kYzdtX%2FBZ6NL3zA6dNnH9al9PpgJaMvxMOXuAnLDf9Mw38GzFBdQtRojA6ZVkBuCBIMDA%3D%3D" rel="nofollow" target="_blank">db\_init.json，直至这些数据都导入完成。</a></p><p>当看到</p><pre><code>从文件导入数据: 
            db_init.json
          读取到 38 条记录2026-01-20 17:07:52,224 INFO 
            sqlalchemy.engine.Engine
           select 
            pg_catalog.version()
          2026-01-20 17:07:52,225 INFO 
            sqlalchemy.engine.Engine
           [raw sql] ()......2026-01-20 17:07:52,276 INFO 
            sqlalchemy.engine.Engine
           COMMIT导入完成:  成功: 38 条  失败: 0 条</code></pre><p>·脚本成功读取了 <a href="https://link.segmentfault.com/?enc=mktUTfCzVkGwCF%2Fh%2FDMzPg%3D%3D.UxAky1%2F%2FjN1FRauxBe25kSFD3Z9LVJa%2Bcdx%2B4qXBStU%3D" rel="nofollow" target="_blank">db\_init.json</a> 文件，识别出包含 38 条待导入的记录</p><p>·SQLAlchemy 引擎成功连接到 PostgreSQL 数据库（日志中出现 <a href="https://link.segmentfault.com/?enc=WCCs0NlJl0%2FniPJx84zqaw%3D%3D.7R7FtEcK68LqLA5q%2F2uI52%2Fu%2BMJiJ8iKolsMOxiek5LCblglcejxlhW%2F4XwP3AoZB2uojdcOJH1tfOoiETK2uDLbxnA2qVurpXreYp6nWN5qgzcQPaDrzjkP0PFTtfG7" rel="nofollow" target="_blank">pg\_catalog.version()</a> 是 PostgreSQL 特有的查询）</p><p>数据库验证</p><p>出现账号数据即为数据导入成功。</p><p><img referrerpolicy="no-referrer" src="https://image-static.segmentfault.com/271/922/2719225018-6971cdcde6c5e" alt="图片" title="图片" loading="lazy"/></p><p>启动服务</p><pre><code>python main.py或使用 uvicornuvicorn main:app --reload --host 0.0.0.0 --port 8000</code></pre><p>这样初始数据写不到数据库问题就可以得到根本解决。</p>]]></description></item><item>    <title><![CDATA[AI智能体对文案设计短视频自媒体出版行业的冲击 智能体小狐 ]]></title>    <link>https://segmentfault.com/a/1190000047558854</link>    <guid>https://segmentfault.com/a/1190000047558854</guid>    <pubDate>2026-01-22 16:05:33</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h3><strong>一、引言：行业背景与问题提出</strong></h3><p>随着 AI 技术的​<strong>迭代升级</strong>​，<strong>AI 智能体</strong>已从单一工具进化为具备<strong>自主规划、任务拆解、多工具协同</strong>能力的全流程执行系统。这彻底改变了内容创作行业“人使用工具”的传统模式，迈入“​<strong>人主导目标、智能体落地执行</strong>​”的新阶段。</p><p>文案、设计、短视频、自媒体、出版等作为核心细分领域，长期面临效率瓶颈、产能限制与同质化竞争。​<strong>AI 智能体的规模化应用</strong>​，正对这些领域的生产流程、岗位结构与价值逻辑产生​<strong>系统性冲击</strong>​——既带来效率红利，也引发生存危机与行业重构的挑战。</p><p>本文旨在​<strong>拆解智能体对各细分领域的具体影响</strong>​，明确其能力边界，为从业者提供可落地的生存与发展指南，并预判行业未来趋势。</p><h3><strong>二、智能体对内容创作行业的整体影响</strong></h3><p><strong>AI 智能体</strong>的冲击是<strong>全维度、系统性</strong>的重构，核心体现在三个层面：</p><ol><li>​<strong>生产流程革新</strong>​：传统“选题-创作-优化-分发”的线性流程被打破。智能体可实现多环节​<strong>协同作业与全流程自动化</strong>​，推动行业从“手工创作”转向“​<strong>系统化生产</strong>​”。</li><li>​<strong>行业成本重构</strong>​：智能体可​<strong>24 小时不间断工作</strong>​，批量生成内容，大幅降低人力成本。这导致低门槛、标准化内容供给过剩，中低价值内容价格持续下滑。</li><li>​<strong>岗位结构分化</strong>​：行业将形成“​<strong>系统设计者、智能体管理者、高价值创作者、普通执行者</strong>​”的分层格局。依赖基础执行能力的岗位面临被替代风险，而具备<strong>策略、创意、统筹能力</strong>的从业者价值凸显。</li></ol><p>整体而言，智能体正在重塑内容创作的​<strong>生产关系</strong>​，推动行业向高效化、专业化、差异化转型。</p><h3><strong>三、各细分行业的具体变化</strong></h3><h4><strong>（一）文案行业：从“文字撰写”到“策略统筹”</strong></h4><p>文案是智能体渗透最深领域之一。<strong>AI 文案工具</strong>可自主完成选题策划、大纲生成、初稿撰写、多版本测试及调性优化，效率是人工的​<strong>8 倍以上</strong>​。这导致基础文案岗位需求锐减。</p><blockquote>​<strong>行业新焦点</strong>​：竞争从“写得好”转向“​<strong>策划得准</strong>​”。文案从业者需转型为“​<strong>内容策略师</strong>​”，聚焦需求拆解、价值传递与调性把控，依托智能体提升内容的精准度与传播力。</blockquote><h4><strong>（二）设计行业：从“像素创作”到“系统配置”</strong></h4><p><strong>AI 设计工具</strong>正替代基础执行工作，可根据需求快速生成海报、UI 界面等多种方案，并自主优化。从事基础排版、素材拼接的设计师面临替代风险。</p><blockquote>​<strong>设计师新价值</strong>​：转向​<strong>视觉系统搭建、品牌一致性把控与创意落地统筹</strong>​。未来设计师将聚焦创意构思，通过​<strong>配置智能体参数</strong>​，实现创意的快速、批量化落地。</blockquote><h4><strong>（三）短视频行业：从“流程执行”到“判断决策”</strong></h4><p><strong>AI 视频生成工具</strong>能自动化完成脚本生成、素材匹配、剪辑、配音及发布优化，实现“​<strong>一键生成短视频</strong>​”。这降低了个人创作者的竞争门槛，但也加剧了内容同质化。</p><blockquote>​<strong>从业者新核心</strong>​：竞争焦点从“剪辑能力”转向“​<strong>内容判断力</strong>​”。借助智能体完成流程，从业者需聚焦于​<strong>选题判断、差异化与情感共鸣</strong>​，以提升爆款率。</blockquote><h4><strong>（四）自媒体行业：从“个体产出”到“规模运营”</strong></h4><p><strong>AI 内容运营工具</strong>打破了个体创作者的产能限制，可实现多账号、多平台的​<strong>协同管理、内容生成、分发调度与数据监控</strong>​，让“一人多号”成为基础能力。</p><blockquote>​<strong>竞争维度升级</strong>​：从“产能竞争”转向“​<strong>价值竞争</strong>​”。自媒体人的核心价值在于“​<strong>内容观点</strong>​”与“​<strong>个人品牌</strong>​”。唯有建立独特洞察与用户信任，才能在海量内容中脱颖而出，并利用智能体实现影响力规模化。</blockquote><h4><strong>（五）出版行业：从“编辑加工”到“内容策展”</strong></h4><p><strong>AI 编辑校对工具</strong>能高效完成稿件初审、文字修正、结构优化等工作，大幅提升效率，降低出版成本。传统文字编辑岗位需求因此缩减。</p><blockquote>​<strong>编辑新角色</strong>​：从“文字加工者”转型为“​<strong>内容策展人</strong>​”与“​<strong>质量把关者</strong>​”。编辑需聚焦于选题策划、作者挖掘、内容质量与版权管理，借助智能体提升出版物的专业性与市场适配度。</blockquote><h3><strong>四、智能体能做什么</strong></h3><p>结合行业实践，<strong>AI 智能体</strong>在内容创作领域的核心能力集中于标准化、规模化的工作：</p><ol><li>​<strong>基础内容生成</strong>​：快速产出文案、设计方案、视频脚本等标准化内容。</li><li>​<strong>全流程协同执行</strong>​：自主拆解任务，调用工具，完成从选题、创作到分发、监控的​<strong>全流程自动化</strong>​。</li><li>​<strong>多版本优化迭代</strong>​：基于数据反馈生成多个内容变体，进行 A/B 测试，优化传播效果。</li><li>​<strong>数据采集与分析</strong>​：实时爬取热点与竞品数据，预测内容潜力，为创作提供数据支撑。</li></ol><p>​<strong>核心价值</strong>​：解放人力，提升效率，承担所有<strong>可标准化、可流程化</strong>的基础工作。</p><h3><strong>五、智能体不能做什么</strong></h3><p>尽管能力强大，<strong>AI 智能体</strong>仍有明确的能力边界，无法替代人类的核心价值：</p><ol><li>​<strong>无法产生原创观点与深度洞察</strong>​：内容生成基于训练数据的整合，无法形成超越现有认知的​<strong>原创思想</strong>​。</li><li>​<strong>无法做出精准的价值与审美判断</strong>​：难以把握复杂场景下的价值导向，也无法理解人类细腻的​<strong>审美偏好与情感共鸣</strong>​。</li><li>​<strong>无法实现人格化表达与信任建立</strong>​：内容缺乏温度与个性，难以建立长期的​<strong>用户信任与情感连接</strong>​。</li><li>​<strong>无法灵活应对突发与个性化需求</strong>​：擅长处理标准化任务，对个性化、突发的创作需求，仍需人类进行​<strong>统筹与决策</strong>​。</li></ol><h3><strong>六、创作者未来的机会与角色变化</strong></h3><p>冲击的本质是淘汰低价值执行劳动，放大高价值的创意与策略能力。未来创作者的机会集中在三类​<strong>角色转型</strong>​：</p><ol><li>​<strong>内容系统设计者</strong>​：掌握智能体逻辑，能设计工作流程、优化参数，搭建专属的​<strong>内容生产系统</strong>​，实现规模化、精准化产出。</li><li>​<strong>高价值创作者</strong>​：聚焦于​<strong>原创观点、深度洞察、人格化表达</strong>​，产出 AI 无法复制的深度分析或情感共鸣内容，建立独特个人品牌。</li><li>​<strong>智能体管理者</strong>​：擅长统筹需求、拆解任务，合理调配智能体完成执行，聚焦于​<strong>质量把控与效果优化</strong>​，成为连接人类与 AI 的​<strong>核心纽带</strong>​。</li></ol><p>未来的机会，不再是“会不会创作”，而是“​<strong>会不会借助智能体，做智能体做不到的事</strong>​”。</p><h3><strong>七、普通创作者的可执行建议</strong></h3><p>面对冲击，无需恐慌，核心是​<strong>找准定位、提升核心能力</strong>​：</p><ol><li>​<strong>主动拥抱工具</strong>​：学习使用各类​<strong>AI 智能体工具</strong>​，将其作为基础执行工具，解放人力，聚焦创意，实现“​<strong>人机协同</strong>​”。</li><li>​<strong>打造不可替代的能力</strong>​：重点提升<strong>原创观点、深度洞察、审美判断、情感表达</strong>等 AI 无法替代的能力，形成个人核心竞争力。</li><li>​<strong>找准细分定位</strong>​：避开标准化内容的红海竞争，聚焦于<strong>小众化、垂直化</strong>领域，结合自身优势产出差异化内容。</li><li>​<strong>持续迭代学习</strong>​：关注 AI 技术迭代与行业变化，不断更新知识体系，主动转型，避免被淘汰。</li></ol><h3><strong>八、结论：趋势总结与判断</strong></h3><p><strong>AI 智能体</strong>对内容创作行业的冲击，是​<strong>生产技术迭代带来的行业重构</strong>​，而非创作本身的消亡。未来将呈现三大趋势：</p><ol><li>​<strong>“人机协同”成为主流</strong>​：智能体承担执行，人类聚焦创意与策略，二者协同提升效率与质量。</li><li>​<strong>行业分层持续加剧</strong>​：基础岗位需求缩减，高价值的<strong>创意与策略类岗位</strong>价值凸显，竞争向精细化、差异化发展。</li><li>​<strong>内容价值回归本质</strong>​：标准化内容过剩，用户对<strong>原创、深度、有温度</strong>的内容需求提升，这将成为行业核心竞争力。</li></ol><p>对于从业者而言，​<strong>AI 智能体不是竞争对手，而是高效工具</strong>​。唯有主动拥抱变化、提升核心能力、找准自身定位，才能在行业重构中抓住机会，实现长期发展。</p>]]></description></item><item>    <title><![CDATA[在 Vite + React 项目中集成 Sentry 完整指南 李小白 ]]></title>    <link>https://segmentfault.com/a/1190000047558858</link>    <guid>https://segmentfault.com/a/1190000047558858</guid>    <pubDate>2026-01-22 16:04:41</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>在 Vite + React 项目中集成 Sentry 完整指南</h2><blockquote>📚 本教程将带你从零开始，一步步完成 Sentry 在 Vite + React 项目中的接入与配置，实现错误监控与源码映射功能。</blockquote><hr/><h3>📋 目录</h3><ul><li><a href="#一准备工作" target="_blank">准备工作</a></li><li><a href="#二创建-sentry-项目" target="_blank">创建 Sentry 项目</a></li><li><a href="#三初始化本地项目" target="_blank">初始化本地项目</a></li><li><a href="#四安装-sentry-依赖" target="_blank">安装 Sentry 依赖</a></li><li><a href="#五配置-sentry" target="_blank">配置 Sentry</a></li><li><a href="#六配置-vite-插件" target="_blank">配置 Vite 插件</a></li><li><a href="#七测试错误上报" target="_blank">测试错误上报</a></li><li><a href="#八设置-auth-token" target="_blank">设置 Auth Token</a></li><li><a href="#九构建与验证" target="_blank">构建与验证</a></li><li><h3><a href="#十查看错误日志" target="_blank">查看错误日志</a></h3><h3>一、准备工作</h3><p>在开始之前，请确保你已经：</p></li><li>✅ 安装了 <a href="https://link.segmentfault.com/?enc=8hIC07ElH%2F1%2FjoAvhE0GpA%3D%3D.%2F3Fn2CLvxZ6ssy8rwP1lc1bNuYGWRIl4EMpMQwxUM3A%3D" rel="nofollow" target="_blank">Node.js</a>（建议 v18+）</li><li>✅ 安装了 <a href="https://link.segmentfault.com/?enc=%2FdhQ9FXIsERtieokTs7B9g%3D%3D.sh029LfKXv1kQcmYWddxYEzG20sEC3SnTi1EM4mlHFA%3D" rel="nofollow" target="_blank">npm</a> 或 <a href="https://link.segmentfault.com/?enc=n8HsAYKvzrvYqDyLK7L9%2Bg%3D%3D.KeTfwXjKCgL3D6%2FtGypNGsbnZV8vkJnDy%2FqybYMJUnk%3D" rel="nofollow" target="_blank">yarn</a></li><li><h3>✅ 有基本的 React 和 Vite 开发经验</h3><h3>二、创建 Sentry 项目</h3><h4>1. 登录 Sentry 官网</h4><p>👉 <a href="https://link.segmentfault.com/?enc=eLjbkRqu8uaWlGxXEF0nxQ%3D%3D.X9QNqjX7CLb%2F0TJ9C6McFeaxMdzc3MQp305AlxIa7cY%3D" rel="nofollow" target="_blank">https://sentry.io/</a></p><h4>2. 创建 Organization</h4><p>在 Sentry 控制台中创建一个新的组织：</p><table><thead><tr><th>配置项</th><th>说明</th></tr></thead><tbody><tr><td><strong>Name</strong></td><td>组织名称，自定义（如：<code>my-company</code>）</td></tr><tr><td><strong>Plan</strong></td><td>选择 <code>Free</code> 版本即可，完全够用</td></tr></tbody></table></li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558861" alt="" title=""/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558862" alt="" title="" loading="lazy"/></p><h4>3. 创建 Project</h4><p>在组织中创建一个新项目：</p><table><thead><tr><th>配置项</th><th>说明</th></tr></thead><tbody><tr><td><strong>Platform</strong></td><td>选择 <code>React</code></td></tr><tr><td><strong>Project name</strong></td><td>填写项目名称（如：<code>vite-react-app</code>）</td></tr></tbody></table><blockquote>⚠️ <strong>重要提示</strong>：创建完成后，请复制并保存好以下 <strong>DSN</strong> 地址，后续配置会用到：</blockquote><pre><code>https://4352b88f3321d7e98766b0b743fa7115@o4514356086109909.ingest.us.sentry.io/4510743223411211</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558863" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558864" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558865" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558866" alt="" title="" loading="lazy"/></p><hr/><h3>三、初始化本地项目</h3><p>使用 Vite 创建一个新的 React 项目：</p><pre><code class="bash">npm create vite@latest my-react-app -- --template react</code></pre><hr/><h3>四、安装 Sentry 依赖</h3><p>在项目根目录执行以下命令安装 Sentry 相关包：</p><pre><code class="bash">npm install @sentry/react @sentry/vite-plugin</code></pre><table><thead><tr><th>包名</th><th>说明</th></tr></thead><tbody><tr><td><code>@sentry/react</code></td><td>浏览器错误捕获 + React Error Boundary</td></tr><tr><td><code>@sentry/vite-plugin</code></td><td>Source Map 上传插件（关键组件）</td></tr></tbody></table><hr/><h3>五、配置 Sentry</h3><h4>1. 创建 Sentry 初始化文件</h4><p>在 <code>src</code> 目录下新建 <code>sentry.ts</code> 文件：</p><pre><code>
import * as Sentry from "@sentry/react";
export function initSentry() {
  // 本地开发环境不自动上报，避免污染
  if (import.meta.env.DEV) {
    return;
  }
  Sentry.init({
    dsn: import.meta.env.VITE_SENTRY_DSN,
    integrations: [
      Sentry.browserTracingIntegration(),
    ],
    // 性能追踪采样率，生产环境建议 0.1 ～ 0.3
    tracesSampleRate: 1.0,
    
    // 设置环境标识
    environment: import.meta.env.MODE,
    // 在发送前可对事件进行脱敏处理
    beforeSend(event) {
      return event;
    },
  });
}</code></pre><h4>2. 在入口文件中初始化 Sentry</h4><p>修改 <code>main.tsx</code>，<strong>注意：必须在 React 渲染之前初始化 Sentry</strong></p><pre><code>
import React from "react";
import ReactDOM from "react-dom/client";
import App from "./App";
import { initSentry } from "./sentry";
// 初始化 Sentry（必须在渲染前调用）
initSentry();
ReactDOM.createRoot(document.getElementById("root")!).render(
  &lt;React.StrictMode&gt;
    &lt;App /&gt;
  &lt;/React.StrictMode&gt;,
);</code></pre><h4>3. 配置环境变量</h4><p>在项目根目录新建 <code>.env.production</code> 文件：</p><pre><code class="env" rel=".env.production">
SENTRY_ORG=my-company-j3
SENTRY_PROJECT=vite-react-web
VITE_SENTRY_DSN=https://4352b88f3321d7e98766b0b743fa7115@o4514356086109909.ingest.us.sentry.io/4510743223411211
SENTRY_AUTH_TOKEN=&lt;从Sentry控制台获取&gt;
SENTRY_RELEASE=my-react-app@0.0.0</code></pre><h5>环境变量说明</h5><table><thead><tr><th>变量名</th><th>说明</th><th>获取方式</th><th>截图</th></tr></thead><tbody><tr><td><code>SENTRY_ORG</code></td><td>组织标识</td><td><code>Settings</code> → <code>Organization</code> → <code>General Settings</code></td><td><img referrerpolicy="no-referrer" src="/img/remote/1460000047558867" alt="" title="" loading="lazy"/></td></tr><tr><td><code>SENTRY_PROJECT</code></td><td>项目标识</td><td><code>Settings</code> → <code>Organization</code> → <code>Projects</code> → <code>&lt;项目名称&gt;</code> → <code>Project</code> → <code>Slug</code></td><td><img referrerpolicy="no-referrer" src="/img/remote/1460000047558868" alt="" title="" loading="lazy"/></td></tr><tr><td><code>VITE_SENTRY_DSN</code></td><td>数据源名称</td><td>创建项目时显示的 DSN</td><td><img referrerpolicy="no-referrer" src="/img/remote/1460000047558869" alt="" title="" loading="lazy"/></td></tr><tr><td><code>SENTRY_AUTH_TOKEN</code></td><td>认证令牌</td><td>见下文「<a href="#设置-auth-token" target="_blank">设置 Auth Token</a>」</td><td> </td></tr><tr><td><code>SENTRY_RELEASE</code></td><td>发布版本号</td><td>根据实际项目填写（如：<code>my-react-app@1.0.0</code>）</td></tr></tbody></table><hr/><h3>六、配置 Vite 插件</h3><p>修改 <code>vite.config.ts</code>，配置 Sentry 插件以实现 Source Map 上传：</p><pre><code class="typescript" rel="vite.config.ts">
import { defineConfig, loadEnv } from 'vite'
import react from '@vitejs/plugin-react'
import { sentryVitePlugin } from '@sentry/vite-plugin'
export default defineConfig(({ mode }) =&gt; {
  const env = loadEnv(mode, process.cwd(), '')
  return {
    build: {
      sourcemap: true,
    },
    define: {
      'import.meta.env.VITE_SENTRY_RELEASE': JSON.stringify(env.SENTRY_RELEASE),
    },
    plugins: [
      react(),
      sentryVitePlugin({
        org: env.SENTRY_ORG,
        project: env.SENTRY_PROJECT,
        authToken: env.SENTRY_AUTH_TOKEN,
        sourcemaps: {
          disable: 'disable-upload',
        },
        release: {
          name: env.SENTRY_RELEASE,
          uploadLegacySourcemaps: [
            {
              paths: ['dist/assets'],
              urlPrefix: '~/assets',
            },
          ],
          setCommits: false,
        },
      }),
    ],
  }
})</code></pre><blockquote>💡 <strong>提示</strong>：该配置解决了「在 Sentry 中看不到源码」的问题，通过上传 Source Map 可以精确定位到出错的具体代码行。</blockquote><hr/><h3>七、测试错误上报</h3><p>修改 <code>App.tsx</code>，添加手动触发错误的按钮，方便测试：</p><pre><code>
import { useState } from 'react'
import reactLogo from './assets/react.svg'
import viteLogo from '/vite.svg'
import './App.css'
import * as Sentry from '@sentry/react'
function App() {
  const [count, setCount] = useState(0)
  const onClickFn = () =&gt; {
    console.log('手动触发错误')
    try {
      throw new Error('手动触发错误')
    } catch (err) {
      Sentry.captureException(err)
    }
  }
  return (
    &lt;&gt;
      &lt;div&gt;
        &lt;a href="https://vite.dev" target="_blank"&gt;
          &lt;img src={viteLogo} className="logo" alt="Vite logo" /&gt;
        &lt;/a&gt;
        &lt;a href="https://react.dev" target="_blank"&gt;
          &lt;img src={reactLogo} className="logo react" alt="React logo" /&gt;
        &lt;/a&gt;
      &lt;/div&gt;
      &lt;h1&gt;Vite + React&lt;/h1&gt;
      &lt;div className="card"&gt;
        &lt;button onClick={() =&gt; setCount((count) =&gt; count + 1)}&gt;
          count is {count}
        &lt;/button&gt;
        &lt;button onClick={() =&gt; Sentry.captureMessage('消息1')}&gt;
          消息1
        &lt;/button&gt;
        &lt;button onClick={onClickFn}&gt;
          手动触发错误
        &lt;/button&gt;
        &lt;p&gt;
          Edit &lt;code&gt;src/App.jsx&lt;/code&gt; and save to test HMR
        &lt;/p&gt;
      &lt;/div&gt;
      &lt;p className="read-the-docs"&gt;
        Click on the Vite and React logos to learn more
      &lt;/p&gt;
    &lt;/&gt;
  )
}
export default App</code></pre><hr/><h3>八、设置 Auth Token</h3><p>该步骤只需操作一次，用于获取 Source Map 上传权限。</p><h4>1. 进入 Token 创建页面</h4><p>路径：<code>Settings</code> → <code>Developer Settings</code> → <code>Personal Tokens</code></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558870" alt="" title="" loading="lazy"/></p><h4>2. 创建新 Token</h4><p>点击「Create New Token」，按以下配置权限：</p><table><thead><tr><th>权限类别</th><th>选项</th></tr></thead><tbody><tr><td><strong>Project</strong></td><td><code>Read</code></td></tr><tr><td><strong>Release</strong></td><td><code>Admin</code></td></tr><tr><td><strong>Origanization</strong></td><td><code>Read</code></td></tr><tr><td><strong>其他选项</strong></td><td>保持默认 <code>No Access</code></td></tr></tbody></table><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558871" alt="" title="" loading="lazy"/></p><h4>3. 复制 Token</h4><p>创建成功后，<strong>立即复制</strong>生成的 Token（仅显示一次），将其填入 <code>.env.production</code> 文件中的 <code>SENTRY_AUTH_TOKEN</code>。</p><hr/><h3>九、构建与验证</h3><h4>1. 构建项目并上传 Source Maps</h4><pre><code class="bash">npm run build
# 或
yarn build</code></pre><p>构建完成后，Sentry 插件会自动将 Source Maps 上传到 Sentry 服务器。</p><h4>2. 预览项目</h4><pre><code class="bash">npm run preview
# 或
yarn preview</code></pre><h4>3. 触发错误</h4><p>在浏览器中打开应用，点击「<strong>手动触发错误</strong>」按钮。如果一切配置正确，你应该能在 Sentry 中看到一条新的错误记录。</p><hr/><h3>十、查看错误日志</h3><h4>在 Sentry 中查看上报的错误</h4><p>登录 Sentry 官网，进入对应项目，即可看到捕获的错误日志，并且能够直接定位到源码，极大地方便了问题排查。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558872" alt="" title="" loading="lazy"/></p><h4>查看 Source Maps 上传情况</h4><ol><li>找到你的项目：<code>Settings</code> → <code>Organization</code> → <code>Projects</code> → <code>&lt;项目名称&gt;</code></li></ol><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558873" alt="" title="" loading="lazy"/></p><ol start="2"><li>进入 Source Maps 页面：<code>Processing</code> → <code>Source Maps</code><br/>在这里你可以确认 Source Maps 是否成功上传。</li></ol><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558874" alt="" title="" loading="lazy"/></p><hr/><h3>🎉 总结</h3><p>恭喜！你已经成功完成了 Sentry 在 Vite + React 项目中的完整配置。现在你的应用具备了：</p><table><thead><tr><th>功能</th><th>说明</th></tr></thead><tbody><tr><td>🔍 <strong>错误捕获</strong></td><td>自动捕获并上报运行时错误</td></tr><tr><td>📍 <strong>源码定位</strong></td><td>通过 Source Map 精确定位错误行号</td></tr><tr><td>📊 <strong>性能追踪</strong></td><td>可选的性能数据采样收集</td></tr><tr><td>🛡️ <strong>环境隔离</strong></td><td>本地开发环境不污染生产数据</td></tr></tbody></table><h4>常见问题</h4><p>&lt;details&gt;<br/>&lt;summary&gt;<b>❓ 为什么在 Sentry 中看不到源码？</b>&lt;/summary&gt;<br/>请检查以下几点：</p><ol><li><code>vite.config.ts</code> 中是否正确配置了 <code>sentryVitePlugin</code></li><li><code>.env.production</code> 中的 <code>SENTRY_AUTH_TOKEN</code> 是否正确</li><li><p>构建时是否成功执行（查看控制台是否有上传日志）<br/>&lt;/details&gt;<br/>&lt;details&gt;<br/>&lt;summary&gt;<b>❓ 本地开发环境会上报错误吗？</b>&lt;/summary&gt;<br/>不会。在 <code>sentry.ts</code> 中我们添加了环境判断，只有非开发环境才会初始化 Sentry。</p><pre><code class="typescript">if (import.meta.env.DEV) {
  return;
}</code></pre><h3>&lt;/details&gt;</h3><p>希望这篇教程对你有所帮助！如有问题，欢迎交流讨论。</p></li></ol><p>本文由<a href="https://link.segmentfault.com/?enc=IPNrn1Nlq5H9NK7xqiDXKA%3D%3D.SZ3ZY062ZqJTdS35LJWL%2B8xsaYTwXvOSYHnxILRl2Sw%3D" rel="nofollow" target="_blank">mdnice</a>多平台发布</p>]]></description></item><item>    <title><![CDATA[“新”意十足 · HarmonyOS模板&组件（功能增强：商城、美食、工具等模板；短视频、剪辑等组件]]></title>    <link>https://segmentfault.com/a/1190000047558897</link>    <guid>https://segmentfault.com/a/1190000047558897</guid>    <pubDate>2026-01-22 16:03:47</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><img width="568" height="328" referrerpolicy="no-referrer" src="/img/bVdnIkZ" alt="image.png" title="image.png"/></p><blockquote>💡 鸿蒙生态为开发者提供海量的HarmonyOS模板/组件，助力开发效率原地起飞 💡<br/>★ 更多内容，一键直达<a href="https://link.segmentfault.com/?enc=yKNyqFpNre5WXxnrLUe0Fw%3D%3D.172q9d4HJoqj13%2Fz8aeL13BoDvVVNJ8FXyW26XzusvTRUQlDEz7l5lGvBI33C%2BBEIwNEg0t2F200Ffm88QMaBpd%2Fsu9UJhRxrdp437TQ4LHewCvW2JC8f4Hw0GF9Rd%2Bbs3gAIgNZLKiDhcA8HkpEksBhbQOCt1FaafkiviGP4kw%3D" rel="nofollow" target="_blank">生态市场组件&amp;模板市场</a> , 快速应用<a href="https://link.segmentfault.com/?enc=%2BcHuKs7evDUxWxANNopHkA%3D%3D.iPCDX3days%2FOuOtUH3TfaEYhVJufwqd6pMx%2FCWLjfPBuul8hHJKJ6o9jhTUhuSLrarp8vBsEJueEkoQRmW%2Bs32TvoNTu7rqCPTnuyP12XUMEHtHkc%2Bf842rAz5nIrZXAi16h%2FjQUbHr6SxewWK1MzZyaNj8JLsgbDx667WsUzNIIN3lR6kjza32UxquSKevE" rel="nofollow" target="_blank">DevEco Studio插件市场集成组件&amp;模板</a> ★<br/>★ 一键直达 <a href="https://link.segmentfault.com/?enc=fZJnfcdhv3zUsIOxzALkFQ%3D%3D.eoetC2R%2BJTvH4u0H7%2BpHH9WMo%2FmYBUKUaCXiraQjlpUGoRdDh%2BfMGF4Eq1LvX888qt41RzUeZIMtSWvN0ACS%2Fy%2BBAsS586Ro3nOhGnWk7wVBUt45TXoPpyzzGzZuExhKcpcdFnadu3W8YxAfZpk4GQ%3D%3D" rel="nofollow" target="_blank">HarmonyOS 行业解决方案</a> ★</blockquote><p><img width="723" height="75" referrerpolicy="no-referrer" src="/img/bVdnIk2" alt="image.png" title="image.png" loading="lazy"/></p><h4>模版</h4><table><thead><tr><th>模板名称</th><th>更新内容</th></tr></thead><tbody><tr><td><a href="https://link.segmentfault.com/?enc=dAm98W5zvcITXeRJwXrHlA%3D%3D.MPDyL%2Fx5%2B8CA5jzNUNocrPiOaJzUceH2LYheP%2BUX2lia86d3jqqJW1R1dtRHWD0cXKmIJEpbFlRDHhhmdYDtqdfkjJ%2BQhvCZiRQLnj52TyaE4Xc8KXd7cpO07yVwo6o6SyK6%2F7Dk38PAklDr9lyY1LJzx2UdpOdRhqmsdeA1alKnr6AR3%2FMB6o%2B9hbcBvHCq5AyExyJ13ZhkkKFAZthbC%2B%2F8ERhXKfq9kKeqeNaA1Ew%3D" rel="nofollow" target="_blank">综合商城应用模板</a></td><td>能力接入：预加载、开屏广告、华为推送、数字收银台</td></tr><tr><td><a href="https://link.segmentfault.com/?enc=TtQhXVhK1AL10DmpqI7WdA%3D%3D.28sdq7JmjBmYDJT5U8mcD%2BPJH91jyaILLNrYjpb7VFIY%2B%2F3pcalDSXeV7pl1MYIGT6MCvQjqCTvuZ47oWs8PC4gD73UCbtFOwvVOM1WmyC5cjTEjZJbtVeprFSi8Lg9HTV788epi%2FSWOOtw52IVTk%2BeW2LqP6tvCjkwQEDdyM7VR0qM8Q0PONm9KxeFLthfF8dBLZj1x3UjN5pMqiD%2BLjwdoPV%2BXpxBU9NDWR8QO0fw%3D" rel="nofollow" target="_blank">综合商城应用模板</a></td><td>新增组件：地址管理、应用设置、登录、支付、分享、个人信息、意见反馈、会员组件</td></tr><tr><td><a href="https://link.segmentfault.com/?enc=b1ZPndpNMF5hB5U4wA3XjQ%3D%3D.gYW1rd%2B%2FMiOHFzdqirqSXZm8e%2FPQpz21l1oEIN75D1GeBRAwB80NgQat6MQlJqM5od68augm2z0aspJ095%2F8BCa46P6Vn4BHj%2BLE6Vnbwzg%2F%2BsKoW44RPPkOFOPECGFmoxroqnjoWOc0w9l7I%2Fxyw3pTWn%2Fn3M0oHcnmfDbs1%2Fcd50pnDsseq6sOBgQt1WBT8AwMHRrUralfKgcWhL%2Bd6vhZmUBhcSMOwFjS32vjr1E%3D" rel="nofollow" target="_blank">美食菜谱应用模板</a></td><td>能力接入：数字收银台、华为广告</td></tr><tr><td><a href="https://link.segmentfault.com/?enc=QHwtO2kNv9KgGZiTuChN5w%3D%3D.dSr2i1ftjUU2YIrroA6xxHTbMf89lcBZO5a26lm5WxcFCnHZrJRw%2Bhp94XvtHlPU5RUFB3BJPKwN43YOPo3D%2BmhTQnMQV62l7dqkhHoDZUtudsNTLBlCiFUk1pAUZH0GQCJQxXAt2YCoLRl9v0jCGH4sC16wSRJ3T8jpulRKmH9p7tO8CjvaSxZiscbWQG4uJTrCFDY4EHihwXZuX30zmuJgyf1Bom45eIH1B2e606c%3D" rel="nofollow" target="_blank">美食菜谱应用模板</a></td><td>功能增强：新增下拉刷新和饮食计划、折叠屏适配</td></tr><tr><td><a href="https://link.segmentfault.com/?enc=AfFiIkP%2FLwDqDxtKzTw06Q%3D%3D.SgZTjJiKPZRrc0%2B2S7uv7kTKvGMg%2FgJMtO8KFFPbVFuNMugYhP4s5qTXEOUK4zcg3yvgmVR%2FbPoHaSwY1hsxIcdmx%2BZDyxv2jGIAm8jrSrcIpyYEp5SMsJEnA6B8XM8dib5YxZRWzT1yEmdNUtDIiooUPNn%2FT2lz4a4ABeerpd9Rdp2n8ry7T%2Fq56E%2FnsJu1si5NGvDw2Zqbwp5L%2FTwkavQu5gJj5JUdU7iulhct6RA%3D" rel="nofollow" target="_blank">美食菜谱应用模板</a></td><td>新增组件：登录、设置、个人信息、会员组件</td></tr><tr><td><a href="https://link.segmentfault.com/?enc=CKBBoC08RyquB4mVBkU37Q%3D%3D.4imkD1xOpPGpqlBU%2FyCWGh2Qo1WHLl6Z0U1uyXUzKTsRSklQiKh0%2B1%2ByDZx4lDUZu1ZGG%2B6qGOimESJ5YH%2B3OokhZKH4s3duv19vOUUhp2QN2%2BIJGbuVFjRIKZSMxrIaO%2F6pit1O2rQoHAiXcNnoNz1x6r3sGLOqv%2FtQKyG6phTureuRmThV3pV83VTGgBrzoxXTw5VH%2B8EY0S17pgqf39UsHzWnhibWW1Xqp4qIOwg%3D" rel="nofollow" target="_blank">美业元服务模板</a></td><td>能力接入：智能填充、一多适配、华为地图</td></tr><tr><td><a href="https://link.segmentfault.com/?enc=aaOoC3SuVAyvRr4ssarmww%3D%3D.dRrZq58At1ESXFQoWee503IVr52dc4RUDGvk62jvk0ms5giYWANYs27IVlCn9iEPwWARq1B%2FqBFzv0PUqcDBJOOnqd2T2TtvcqfBlZ8xvJzncxDti3usL11eaAWloQ7gPCZUrybzzDWgZTWECCDF6CSk9PHPsyk2xrnCqx8PS5l26GVcjwGqq4vwjjF%2FQEfegIXh1S8HcV9IlRcpmxUmcgzUWNWt6hrkTkHHGCXiBZc%3D" rel="nofollow" target="_blank">美业元服务模板</a></td><td>功能增强：UI改版</td></tr><tr><td><a href="https://link.segmentfault.com/?enc=vcNd19KQPoH9uvmPruSeFw%3D%3D.XoNBKFGEb2TDfPoz74jcXO0QvCTZXg4DZ2iLjUagIi4AGKvxuaewttBKqpTss1XG2QPRWm5RdiMtxDoK%2FNIC3Eq0tZH9PpYUdebDZ3tLEBfzkCFkZVbQfQSNHYbg%2Byba%2B34i2ULrFxNxlzToI0PGYUqIVZz9pIH7gEq5pjvJEEeY5Hc35mwOwx9twJ0y2TcqX54Ri7aCFj%2BV2EEoFWfpTu%2BXsFfyzUQ20GZZsw1qbic%3D" rel="nofollow" target="_blank">美业元服务模板</a></td><td>新增组件：基础组件、个人信息组件</td></tr><tr><td><a href="https://link.segmentfault.com/?enc=zKk8MNzk3vIq29aO09s10A%3D%3D.mT0cj7w1TnKexVWkOpRkdybIKwgomVaBUAb%2BCUWx04DeJUauIdqwsqhj2FAVMDCbzBcdUDtr%2BduN5EVtJBZ9Iouu8M6%2FQxt7SHp2YP%2Fd2BuB1961r4gXdVjipxKjxrNuvvIw8jR6Cnoa5k%2BfOZSD7eGQNEzCEPKjwCdsz1wn9tjcp%2BGn3S%2BBv04buTcSw0ifPMXOcveHs0koKpz6f17r1hCy5XoF5LwXqr38dZ%2F0fPg%3D" rel="nofollow" target="_blank">点餐元服务模板</a></td><td>能力接入：一多适配、服务卡片</td></tr><tr><td><a href="https://link.segmentfault.com/?enc=SXpoWqfmj76alxWWRQJJ4Q%3D%3D.coVX7MV3DC6yXWagD33hi%2Fi4gWAzF49Fnu15qJ3AP3HXwXdhUMhVnTLaPjmLviE%2Bleq6aqMAfz50uf506PCGKwguOIz7t9CCCbQezKWcub6NHLZnoj9bgiCO3a5cdwItSTiUnBSLkWxMdtGx9Sbli3q8VNHuPilt8XIc0r3NM7G%2Fv%2B4Hyc5scCymSinhg3PN14Insgh0GK7XHUtkQ5YNG1fJtEnzqYWPKbDgZb%2BvAt0%3D" rel="nofollow" target="_blank">点餐元服务模板</a></td><td>功能增强：首页新增城市选择、扫一扫<em>、预约订座和排队取号；新增2</em>4卡片、适配一多折叠屏、优化堂食和外带场景、优化钱包和积分功能、组件元服务胶囊、兼容平板设备弹窗、兼容模拟器充值功能</td></tr><tr><td><a href="https://link.segmentfault.com/?enc=sKaK%2FOqeD95y9M16qDQ2Fw%3D%3D.2uxZRuKnQe0z9AgvsxD%2Feb2nUTFJeevv5wYtfvYlHh0fNmSwABms8N6OkcoP%2FnDdeiAT3%2FulUo5FetwyD3nrrQYbumLm31W8AMCXOoK1%2Fb1piVrGXxQLpSPFqi7AqfT5n2ZiDnrWMzrV4SkE6A6aKvWurdx5IsRfeJdp4ZmqKvpPX40dnYpwygZqozbXB7%2FQ2s1GtHu53czjpnIhJN0mqtEXcSFn%2BtyN4r5onbrG1m4%3D" rel="nofollow" target="_blank">点餐元服务模板</a></td><td>新增组件：选择店铺、搜索组件</td><td>*</td></tr><tr><td><a href="https://link.segmentfault.com/?enc=k8wJUu3WTBDTY69hJCXTAA%3D%3D.TTJXC%2F2lmnR%2BSYQ1kJbFEfcwmiZdLYB9Dgw5t26hyuOwtY5XAOD0XjP6nbWor2qXZa8Fv%2FrFqpu9uLrxdl4dkb1JaplGXG6BKX59qSbylRRRk0gj4cD0sn0HsloxIq%2BmS%2Fm9l0sRCRxSxq8KZgSqlmAdTcqzhTrk0kbzskcb7%2BkhNBkG0BPBIzJrx1a8CELLeC%2FVIeqxdEhSv6QY3PCOkGisZO2lBTunn86yyGLV%2B6I%3D" rel="nofollow" target="_blank">汽车驾考应用模板</a></td><td>能力接入：开屏广告、华为分享、数字收银台、华为推送等功能</td></tr><tr><td><a href="https://link.segmentfault.com/?enc=q3Dmnl7CoU6swipYD4AyVg%3D%3D.r%2BI5sbntfnkLF8FaR0w5teRExoFJw1fOuO7C4%2Bynq1HDjYBGpBD1KVIXJk16aIV6QseUCgsOX5U5zXMYm%2F9cL2PTJ97dsfhNsNLLQbvaYra%2FFoQGAygnVNc3Gsh9ACC3ILp0cMzKN6Jbo8lFMM5vlm4kkczGLOKGkqRQWZYh%2BblIa4vSfaBrb7oYhJjm4vB30Wqgvx%2FEijB7KCS%2FNhZ1Jt1jRw%2BzPyktH0U4mYRXezA%3D" rel="nofollow" target="_blank">汽车驾考应用模板</a></td><td>新增组件： 应用设置、会员、分享、个人信息、反馈组件</td></tr><tr><td><a href="https://link.segmentfault.com/?enc=Puu%2FaYqfvylXsGIo7wR0zg%3D%3D.ppJXgIc1VHfccdBBY4Kdsqlk1hu3vU5jVSX6haedKwaYOikBIL%2F7K3VUiI31mfCP%2F8GHOjxvw%2Fzk54VbFIARtd4Nf76GrO118IgzqNES3TP1Wv8F3KELTaO8lW3tS%2FUi8%2BFj47DHWxvWhU2%2BIJOJc8w1b0fOjbeBEJBmZHfgvOcwso%2FW%2FovGCbxTBbEcJwciFf35iIsGJE1TPO7AaAKPiB0%2BfO%2FmfUsPMZIBuBctnlU%3D" rel="nofollow" target="_blank">综合新闻应用模板</a></td><td>功能增强：新增视频直播支持退后台小窗播放、数字报纸功能、广播功能、地方电视功能</td></tr><tr><td><a href="https://link.segmentfault.com/?enc=v2uPycB9p%2FUSeE2sEFW31w%3D%3D.QN4p4oeulN0%2BxZ4RqsRaMu3rkpgpF%2B1GX%2F48gspuwg3YWoCo2uDOzCjho5mOoW0bmu9fd0lmsL%2BEjVNER3Q30yvD%2F5FDmD30CH4fEVi71vv%2B6SzT%2FzSZptT7NN71Y6K3IkhWUN2755WzXA6LG3Z%2BCLQKkflwVz7XU6FCYuqpyVCnqF14wv5wmBiNLTdeSXKPuogdBQwX1O%2BxSFa%2B9OE8jkpHPNlkupaTyHyrpwxxkhw%3D" rel="nofollow" target="_blank">综合新闻应用模板</a></td><td>新增组件：登录、分享、意见反馈、隐私弹窗、应用设置、朗读、个人信息、网络请求模拟库axios-mock-adapter、日志库util-log组件</td></tr><tr><td><a href="https://link.segmentfault.com/?enc=ysdBGBZBa9XP8sX7o0doAw%3D%3D.z4L%2FAmkcXemktToGiQiRgWWEf%2FnK92a%2BAr2H6ukYfdnaYvuvw2HI1waLNTBWMlOGWMY8Od7pJ%2FQc1Q7hGrIcuNil3uxFwIdQd49Ifn%2BHy05dzio7tPdNV3PjK1uJrj5AoSHuRNxcoSTTzTxwmT10XW%2BBopq3Q%2FHGQG0a7SFi47x5xc83ADgJYyiVkb01RUu5YL1ai%2FVBRot9pf4sPQJ6o7CTCbVagLbNN8MydY9mB74%3D" rel="nofollow" target="_blank">综合工具应用模板</a></td><td>能力接入：华为推送、华为账号一键登录、开屏广告</td></tr><tr><td><a href="https://link.segmentfault.com/?enc=Om6CZ%2FDiJAkLewolHVa48A%3D%3D.t5bZ34Y5lf%2BjpwHnyjq5vdMwn01Os7fCGKAtXWMu4Cuqaz27Md3krdfztNzXMJ0Pvbx6QUZ8JF85dZ7HQqhV85A97QFfd4HhITNMmVY36ZdD53xSkor9S%2BNjyoNWtCehbmdchjOv4flBpD%2BPyhRuDSMbK8oPNdIgrXxM1j3MYeMhD5HPN43qfi%2B1anP5zuD6Tx5yGYRY4nTjnEI4PV2rMUMzrz71dpLCq9ENDfAAFek%3D" rel="nofollow" target="_blank">综合工具应用模板</a></td><td>新增组件：会员、登录、意见反馈、个人信息组件</td></tr><tr><td><a href="https://link.segmentfault.com/?enc=8CyYTQHdBjqCzfNn8nDTng%3D%3D.rfzRQestbl%2Bmy0oishIBpnIc3AlFLlpPnj35NfI7CwdvSFcLo3kOdgB97mITfgZbD9V0lwmSne123aUGqqYAHlk%2B%2F1G7iND5U0qWmSTkleFMRJIyhcxNOT5SHnqbkX0gEENynaL%2FQ2O4eV8Wij2dpA0W1E%2Bh%2BBXcrUpifU2K%2Bk4%2BKIRaGe%2Bn0lmWQ3y8mUB0OsreqTNfD9woMoNHv%2BpD7BNFzDNpXGtKQauM%2BvdcBMM%3D" rel="nofollow" target="_blank">电子书阅读应用模板</a></td><td>功能增强：折叠屏和平板适配</td></tr></tbody></table><h4>组件</h4><table><thead><tr><th>组件归属</th><th>组件名称</th><th>更新内容</th></tr></thead><tbody><tr><td><a href="https://link.segmentfault.com/?enc=c4mEwKiOSAybCSjye7BObA%3D%3D.DUQANI80BkVNZDmqC7b%2F%2F7nvtGHYEVC%2F2iARZqJesXFQ553wq7uB8AXRLah50wARhn9NEYDijU1yCmIYl2A8Q2%2FVFzDveOHzaCPhWYb0CYYZzpRJwWVVOOzghMOM0f4SIyPKtnMF9FxuulYTQPTHFa%2FXoTtRftRD095lOUbwW%2FdDtgaBrLflcmnRhj0SaUqPcpP3jgGXcakGYGqZHIirObTfjjkNVt%2F%2FZSFFS0m%2BnJU%3D" rel="nofollow" target="_blank">美食菜谱应用模板</a></td><td><a href="https://link.segmentfault.com/?enc=7IO0plW%2FJcwRjj%2BjIo2Ctg%3D%3D.xzQeUSbQX2mJNfuSJtQOZ1AHBFjBRymSfuVdhhuJxcMz5t96%2Bo2pZ%2B1Zi7yvrC4GZ9aA6CYPok%2FESeYazwaJd4FDWs1G3qM1LNeKzpEp9X9N85a41dq5g6khLR%2BtpzvtJpsjtkNieitdfm6s%2F7qFu6P3IBs53S7KAF7eVy3kaDzls74vwu1Tgs0lLUxyjj9C7e5%2FeCi0p%2B58zrxWYR28Kk5nroGfn0BbXhl3FyrjYXY%3D" rel="nofollow" target="_blank">菜谱瀑布流组件</a></td><td>瀑布流增加下拉加载和上拉刷新；新增折叠屏适配</td></tr><tr><td><a href="https://link.segmentfault.com/?enc=71db%2Be6GGe65Ef8PH4GnrA%3D%3D.CjB6dZNb2vieHMmxnBjIlQd76kLvoER0%2B8kzJNSub6Jrinayzu%2BuRPZVIoSMqp1K5pRiLjHz68rRTN00XhqtNRjx1Pyh3KpeugWUdKcRkv5Q4zAHi7pdyatwqb4TyMkPk0K70ls4ypkg3Zx7NM6Wfpxq1VCL8QoFQ%2BEi8%2BHGN%2FeLRoTo94kjdD2QWzqa2AKAKVaOKossOqoW4%2FX5uriHXSAJVN9qMtahXx9yFoEd36g%3D" rel="nofollow" target="_blank">综合新闻应用模板</a></td><td><a href="https://link.segmentfault.com/?enc=UunlOH8XK1zOHIEl%2BJKrYQ%3D%3D.V0VdZk6peVFYPVlZwFTrUFoJJ9EyymdKu6h9cdDIElHGvWV9D7lrQtyOAduxjkhsVTuxoUdDoYDL2PUBoCtMI2wR4CuB%2BtkjANDZ4K0FVfMB8iKIHlph5qKPPF2glPG3gKgU%2BTyMJ0v1WexC8MAOuEZCn0hC04dvKYULl6EOmuRSnYA94%2Fs0SlipPTQeltLiYkSZTRPjGJfAmX%2BYZ2mIPE1I%2BTiWAEKK67ubumbb2a4%3D" rel="nofollow" target="_blank">短视频滑动组件</a></td><td>修改视频横竖屏切换问题；修改互动内的视频在页面退出后，会在持续播放的问题；修改滑动进度条时不展示总时间的问题</td></tr><tr><td><a href="https://link.segmentfault.com/?enc=kRdOPx3HIBpoozPr76ciSQ%3D%3D.5Z4atoQGwo2vGgwWS5c8b%2F7xnlE0%2BCwJoik2RMjf%2FiBt2WuSS61k%2FlxVxvJ%2BjoY3gL2tpt63ROrKdMzqvjnOuR%2F8eWI5zf%2FMKzoBHdyFoxvBPo0ud23gdHahIIGsMNLqm3lxN29DCCk2AzGeYt1S1PtyzOSbgorGjAVlL4zsdCdvjAbm0D3A3EINOKvrXClcMKhab4SRF38weCW33pIO%2BrinKi87x9P4296W1OIjIiQ%3D" rel="nofollow" target="_blank">综合新闻应用模板</a></td><td><a href="https://link.segmentfault.com/?enc=6mxYfMjWx6emOmm6nVQCXQ%3D%3D.PD9%2FX6ftcf3jS7CfNmSs5mOt7fdDH7Njqi3bcACWCUcNs3AY7E0loHkNKa2n1xwjRR4B7cYIIJ9nhthpFuM6lzwHpXtAIPb%2FlZUQNhd0lYLOYJNEuYLYhL8CdYc5ZTShBsIAZc8iv1QAS3w%2FJu2A%2BSZWRcW9MmpMj2oCoTXg9Y05T59M36U4T4JLmOpRX6LUxQYkKkrSINic8g2z8CG4pquisblRjUsb9yAo1MbH2ek%3D" rel="nofollow" target="_blank">数字报纸组件</a></td><td>首次发布</td></tr><tr><td><a href="https://link.segmentfault.com/?enc=AbUi4aySZNOXfzdcTIRYDA%3D%3D.dzCGHMyp1tZFdJi%2F%2BZPgBJnx2h%2FSHlvG7gwPMOTKfhA17MGIsJWBZeo6uuMvDNb5Rm60pO%2B5Qec9v24jZkLZfWgQliUMarw9WeDK33sM29NqUltujd4CRPDrn1Aj2q9p0Mp67EVZ8OMINNRLcISNf7TfooeoCqOaVO4%2FcWfPyn6bG9bQb6V%2BDp0PjSYTRrLCiJFIs7HT5tptTZWPHkF99xOpNvfEP0XMijSKkRDFNA0%3D" rel="nofollow" target="_blank">综合工具应用模板</a></td><td><a href="https://link.segmentfault.com/?enc=L7bWbSWQ3D06lZkwytSKFA%3D%3D.HbukOgSRnOr0MvYyGGv2R0hJrmasKgBl4kgipG9h1Xnb0hnrIGR2JlcfEnthg1QGLdRc1P1TP6SBTloskBs9OjeUoqHUaNSPhJJtEKg%2FJfCsgBA%2BLiieZg416b0VmuE0cg2quURwUCc45FVsDX1Y8aB6vTnJgBHmXmgIvTqCUDeTb7iXTHm00EFyR9BhUHLvSI%2FleIqGyUFKqxN8XzlGpBC5kzUhA%2B3g44TdsFpdaIM%3D" rel="nofollow" target="_blank">吉他调音器组件</a></td><td>新增会员功能</td></tr><tr><td><a href="https://link.segmentfault.com/?enc=mbVWsHZvBt83zlvuflxscw%3D%3D.IwuEMPQRZg9ExQEElzAa8%2BORAvAYzXHfKdaMaLGtdhCvNGWpNv2gZ9VnbQE6ntvSaMTrpV6VkHVAEq%2BNxL%2FQ%2B0i4SamItPTI8jEI3iNfzcuSgESjPVax3xWVJnFcjiyBhJlZPxdbWYb8TB5vrINuHG9FhkVPOpUqh89WsyECJXuJmyk2aI4RK%2Bxod9A5PX0yZlCAEAwDGzyHREZ4iP7jP8E4AZaS2jl2I%2FVebNtW84c%3D" rel="nofollow" target="_blank">综合工具应用模板</a></td><td><a href="https://link.segmentfault.com/?enc=mxCdJ1XHFEIUQhFbkUDUEw%3D%3D.jrPKkcePHDvNWJs%2FUTw7gCsSI8MGESocroV9fHnY%2BD2OqFeS2C6UMfJLvmi%2FtpavVqztGDwDucQB%2Blv7swD5qG9oPoOPaaVYWNSUibloeRWg8XYuOZxlKnpY%2FnclNw5nxWzSW3Ds7%2B57pFO257yx%2BkX8yug%2BaAZvEuRciRGmEESQ5f%2FTS2LjhRFvPuQgSlq%2FAGjD8nfNAdv6PZSNgk0kzqcCEVaJXBXh1lYM4knoYKA%3D" rel="nofollow" target="_blank">修图神器组件</a></td><td>新增会员功能</td></tr><tr><td><a href="https://link.segmentfault.com/?enc=vf3npfLwBN0VR2sPPoOKWA%3D%3D.u8pEFpE5cgnRz%2F4GctKav6130XaH6%2BqtGOR%2FWJYhSgngqxflRWYX5OnuZkhEh%2B2YUrRNW7qPlySEX3h7fPLkYDxw8koXrdGGPEjV7IpiFlwniRfk%2FV3UcIewOysMDiSuXAAj%2FIgdGETsG%2BDNY6MtphKfz4qqFqwE6zzOpZGfamyEvL1%2FJ4OlxFs3vQzb6OMsqWS%2FHOmBF%2FxpKsj0PrPIVHB7jvvuz14816JOb52AUfQ%3D" rel="nofollow" target="_blank">综合工具应用模板</a></td><td><a href="https://link.segmentfault.com/?enc=z0IqsOjPgWYY%2FxVdszHD6Q%3D%3D.rIIlL5ywhCjyJ5Xnr7Kt%2FIJK%2F7QHPvEZsAL0SUPXOwAiEwK%2FezZwU9Ev6wJojGhC%2FwKrsbtrLs8oSIRoc%2Bb%2BoetvN%2BMLBAlyN4FzxaKTQxzI6nP3GTOtcOoyn7q2v5aqw0N%2Be%2BUbYFo1L0a%2F9YsvSZ3M10OdFaZFLl2%2FcTDKGZ7llzqFdklbWunkqVDStrwzCogcAZkFAliIBpON7aRxse%2F0OfY%2BvesxgDW5cRQlAWY%3D" rel="nofollow" target="_blank">视频剪辑组件</a></td><td>新增会员功能</td></tr><tr><td><a href="https://link.segmentfault.com/?enc=%2B4eb7Zq9B6VLRPGSWrIRFw%3D%3D.kquHOOG3UfJzFfqA8H%2FwEpJhsjjr12e6qmxvnEbya2BVOq%2BTyGX4p3YzCNA1XIfSAKVQGpRZiZmRJPPaYDYRPrr%2BEm%2FNrzxP6DT00YRnpKzmIaAxV%2BaBHLB5PQNmz39bqiPFdc5idRc%2F4qdYmbymfK9YGuvNC98uJ%2B8NRpp4XrZnHVtcjtughvrHIUoPd4S7oopQagkA%2FJKH10N5hLlAUx4AysjJYe3mTdasfbcBhGE%3D" rel="nofollow" target="_blank">综合工具应用模板</a></td><td><a href="https://link.segmentfault.com/?enc=CY4DEFwUcg68WwCq60x9gw%3D%3D.7h45718gKb5R4Ge6qTFWcYPH58edxF3WE4mxFPD3jDJqBzwMq5DwjEeGQC335tv0RcbyLay2K379C9%2F81zyJCxyLN%2FUDTxFS%2FAL1XxTDdmWx4HuSXxj8icRB9qxvqrUvzI3Nig1VGN6Sh5GNcmfBDWWQRARf9NiGtPs9g%2BCTKqnmeIyqkmJRDu9VMjeJwEYRmMqcsl%2FTKLbitVoRu6qq7d8y9zkD%2B6%2BwdK8DH457Fz4%3D" rel="nofollow" target="_blank">解压缩组件</a></td><td>新增会员功能；修复大文件压缩问题</td></tr><tr><td><a href="https://link.segmentfault.com/?enc=4uFl2IbaCGeZ6PvvqL9Q0w%3D%3D.BcBjTJgXriW8Xa7Q8Wd5Z5O4x58yuSmvbEtuROTsCCLcTxl%2BwpNB90X5bal3RgqojzhVYYYVpNwNrIQGg4jTNVk7t3rcqlUxJIUokDgnF5CtfxdYXgjVdnSJPTyN3G6R5rTzO8bdA%2B0UrTqHQClZ71a2Pzd59zNr5yA1G02W4VKtVWlY5Q1GfZxpTvuvIa7eqZObsOC754ggBaBaDxKbGyd%2B9Lshu%2FKP1E%2BlSnWOtyQ%3D" rel="nofollow" target="_blank">美业元服务模板</a></td><td><a href="https://link.segmentfault.com/?enc=ddHBBZcI%2BWVchLz1HftKOw%3D%3D.elV%2BRzI42mqx4E0StLbqC%2B9l6dzZh9P%2BE0%2FYyMkRDxdAeDGJoCol2qeOIUXMEhHPEbBobg%2Fl6gsp9lT9l%2BH5%2BThCuYYogJZUYnrE2a10D%2F0oNhzUYSOosLXtBDHBo1kcmOUResBOeDoGvIuwwsBwIwGI0a6rrJmyxFV5x1hzLt2aSfjc2COwg6Bhk8RBihi%2By7FThSb2%2Bsf7cyyDyAXdPRHX9LAHVtfGnutngaj5jAk%3D" rel="nofollow" target="_blank">个人信息编辑组件</a></td><td>接入智能填充服务；一多适配</td></tr></tbody></table><p>更多模板&amp;组件上新，敬请关注！<br/>欢迎下载使用模板&amp;组件“<a href="https://link.segmentfault.com/?enc=CG4MiNMGsSyc0e3eOH6ARQ%3D%3D.XJ2ZTK7ipqtmsUlIkTIY9521K12Com6rZRo%2BEIeuNmbabtY3yPD6M3eJHUY8jm%2Bz5jSBFTptFG%2B8HtvQnrAJvR3r71yzsRm9d7%2B5kMywVxr%2FoiClVZlfnlAJ64mMipJv2J0iv0MvN%2Bv2MT1OzzN33Vl%2B9q9mlwouQNfRA75qfuw%3D" rel="nofollow" target="_blank">点击下载</a>”，若您有体验和开发问题，或者相关心愿单<br/>欢迎在评论区留言，小编会快马加鞭为您解答~<br/>同时诚邀您添加下方二维码加入“组件模板开发者社群”，精彩上新&amp;活动不错过！<br/><img width="723" height="415" referrerpolicy="no-referrer" src="/img/bVdnInc" alt="image.png" title="image.png" loading="lazy"/></p><p>【相关推荐】<br/>👉HarmonyOS官方模板优秀案例系列持续更新，<a href="https://link.segmentfault.com/?enc=bNRmbr2EyVfQ5g2DMCdymA%3D%3D.sFLIR1M%2BxyzjeTwhLefFntfhQHqBfNyRParxTnqdQanp2AaFuSzTXPziRuKUGVKQbdnCnY8gwyjHo%2F9M4bsBQiBB0ubVbtyZLPFdbKwQtOMUISprMvDOXYrI6MbyqFNSzrMP%2FvgLKYNpClPFW%2Bv%2Bg%2F%2BNnd22Z3po32NUNjEmaC6JcgNDRF1msip8zGioovuY" rel="nofollow" target="_blank">点击查看</a> 往期案例汇总贴，欢迎收藏，方便查找！<br/>👉【组件征集】HarmonyOS组件开发征集活动，<a href="https://link.segmentfault.com/?enc=p%2BzPvb8TD0XGFFyw20e41g%3D%3D.w2yevjjzHPyTx6CltEvPxAboR9TRvbOfuUkPlCRssi%2FHdQNWBDawNm6CZc0aY9I7VtDZPegn0kUVFJ6en6l%2Fn36CGStVQq6sUAVF%2B9Vnq19Ldo2wrHfH7DTE2pFAFPii6fsPJyiFXRs3i61IE8FN2w%3D%3D" rel="nofollow" target="_blank">点击参加</a><br/>👉【HarmonyOS行业解决方案】为各行业鸿蒙应用提供全流程技术方案。<a href="https://link.segmentfault.com/?enc=pcoXQVfbT6Kd4O%2BtZy8qSA%3D%3D.TzOIt6sUbVRwbGNsx1G1fvBTnpGJ1KQi08LM4QFSJ5C5UP3ptvHrB6o8EWjvAx4z1BVKj%2BLfak42EDZKUU2eGjTvetar7DO7nTzU9R5TXDH4fxG5yG%2Brzd0jiFCfQxL%2F78qBFxtv3PB%2B3BFC0qxHZQ%3D%3D" rel="nofollow" target="_blank">点击查看</a></p>]]></description></item><item>    <title><![CDATA[vivo互联网全链路多版本环境落地实践 vivo互联网技术 ]]></title>    <link>https://segmentfault.com/a/1190000047558901</link>    <guid>https://segmentfault.com/a/1190000047558901</guid>    <pubDate>2026-01-22 16:02:47</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <blockquote>作者：互联网效能平台团队-Wu Qinghua  <br/>在软件研发过程中，“环境问题”是制约研发效能的关键瓶颈之一。环境不稳定、测试环境混乱、环境抢占严重等问题，显著影响开发与测试效率。本文系统介绍vivo通过“全链路多版本环境管理”模式，实现开发测试环境的快速构建与高效管理，使多版本环境能够像“平行宇宙”一般，实现安全、隔离、高效的并行测试与发布。</blockquote><p>本文为2025年 vivo 开发者大会互联网技术专场分享内容之一，在公众号“vivo互联网技术”对话框回复【2025VDC】获取 2025VDC 互联网技术会场议题相关资料。</p><p>1分钟看图掌握核心观点👇</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558903" alt="" title=""/><img referrerpolicy="no-referrer" src="/img/remote/1460000047558904" alt="" title="" loading="lazy"/></p><p><em>图1 VS 图2，您更倾向于哪张图来辅助理解全文呢？欢迎在评论区留言</em></p><h2>一、背景&amp;问题</h2><h2>1.1 我们遇到的问题</h2><p>在软件研发过程中，环境问题常常成为关键路径上的阻塞点。2020年vivo某核心业务数据显示，因测试环境问题导致的转测延期占比高达67%，策划验收阶段因环境问题导致的延期超过10次。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558905" alt="" title="" loading="lazy"/></p><p>这些数据背后，反映的是研发过程中常见的典型场景：</p><ul><li>场景一：急需联调时，依赖服务异常，导致研发阻塞；</li><li>场景二：准备测试时，环境被其他版本占用，需求排期被迫延后；</li><li>场景三：环境配置差异导致线上Bug漏测，引发更多问题。</li></ul><p>深入分析该业务场景后，我们发现环境问题主要集中在以下几个方面：<strong>环境不稳定、测试环境混乱、环境抢占严重、资源利用率低下</strong>。这些问题并非单一项目特有，在微服务架构和快速迭代模式下，已成为多个团队共同面临的挑战。</p><h2>1.2 问题的挑战</h2><p>随着vivo互联网业务的快速发展，为满足更快发布需求，我们全面转向微服务架构。这一转变在提升灵活性与敏捷性的同时，也带来了新的管理挑战。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558906" alt="" title="" loading="lazy"/></p><p>挑战主要来自两个维度：</p><ul><li><strong>架构层面：</strong>服务拆分导致服务数量激增，各服务需独立部署维护，系统调用链路显著延长，任一环节故障都可能导致整体功能不可用。</li><li><strong>流程层面：</strong>业务快速迭代需求推动多版本并行推进，如版本A测试、版本B功能开发、版本C线上热修复等同步进行。</li></ul><p>这些变化叠加，使得研发环境管理复杂度大幅提升，环境稳定性下降、资源浪费严重，最终导致整体研发效率受损。</p><p>传统环境管理方式已难以满足当前需求，亟需一种创新方法，实现多版本像“平行宇宙”一样安全、隔离、高效地并行测试与发布。</p><h2>二、解决方案思路</h2><h2>2.1 什么叫全链路多版本环境管理</h2><p>为解决环境管理难题，我们提出了“全链路多版本环境管理”理念，其核心基于三大关键能力：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558907" alt="" title="" loading="lazy"/></p><p><strong>1.全链路能力</strong></p><p>单一服务版本环境不足以保证整体功能验证。必须确保版本依赖的所有组件——从前端、网关到微服务，再到数据库、缓存和消息队列——整条链路能够一键拉起、快速就绪。以支付业务调试为例，无需手动启动账户、风控、结算等服务，通过一键操作即可分钟级生成完整环境，数据流、配置流与生产环境保持一致。</p><p><strong>2.多版本并行</strong></p><p>支持同时创建多个“完整环境”，使各版本在独立“沙箱”中运行，彻底解决资源抢占问题。热修复版本可分钟级拉起独立环境，新功能开发同步进行，实现“分钟级响应，零等待协作”。</p><p><strong>3.环境自动化管理</strong></p><p>通过全生命周期自动化——从环境搭建、弹性伸缩到闲置回收，减少人工干预，降低错误率，提升资源利用效率，实现降本增效。</p><p>基于这三项核心能力，线上问题或紧急需求出现时，我们可在几分钟内创建独立环境进行验证，且不影响其他版本进程。</p><h2>2.2 业务目标示意图</h2><p>理解全链路多版本环境管理理念后，我们的核心解决思路也从传统的“环境隔离”转向“流量隔离”模式。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558908" alt="" title="" loading="lazy"/></p><p>传统方式为每个版本构建完整独立的测试环境，如同各自独立的烟囱。此方式隔离性好，但资源浪费严重，环境数量有限，扩展性差。</p><p>全链路多版本环境管理方案则采用不同策略：首先维护稳定可靠的公用基线环境。当某版本需开发新功能时，无需从头搭建整套环境，仅需为实际发生变更的服务创建独立的“特性环境”。</p><p>关键问题在于如何实现流量的精准路由。答案在于流量统一网关平台，该系统在流量入口识别每个请求的环境标签，根据标签将请求路由至对应版本的服务实例。</p><p>未改动服务继续共享稳定基线环境，发生变更的服务则拥有独立环境——通过流量精准调度，既保证隔离性，又显著节约资源与成本。</p><p>这一模式类似于单栋大楼内通过不同颜色手环区分访问区域，整栋楼共享基础设施，但各区域活动互不干扰。流量统一网关平台充当“智能前台”，负责识别“手环”、调度流量，使多版本并行开发井然有序。</p><p><strong>“逻辑隔离”相较于“物理隔离”展现出显著优势：更弹性、更经济、更高效。</strong></p><h2>2.3 全链路多版本业务架构图</h2><p>基于上述思路，我们构建了完整的技术架构，清晰展示系统核心组件及协同工作机制。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558909" alt="" title="" loading="lazy"/></p><p>全链路多版本环境的核心能力可归纳为四个关键部分：环境编排、流量隔离、容器部署与分布式链路系统。</p><p><strong>环境编排：</strong>负责组织软件从开发到部署各环节，确保每次代码变更快速部署至指定环境。在多版本环境中，编排系统自动识别不同版本，触发对应构建部署流程，保证各版本独立高效就绪。</p><p><strong>流量隔离：</strong>实现多版本并行的关键。通过灵活路由策略，精确控制各版本流量走向。无论是HTTP请求、Dubbo调用还是MQ消息，均能在各自服务实例间有序流转、互不干扰，如同智能交通系统确保不同“车流”各行其道。</p><p><strong>容器部署：</strong>为环境提供轻量、标准化封装方式，各服务及其依赖打包为独立镜像。借助容器技术，实现应用秒级启动与弹性伸缩。多版本场景下，各版本可快速拉起自身实例组，极大提升资源利用率与发布效率。</p><p><strong>分布式链路系统：</strong>架构的“可观测性”基础，实时追踪记录请求在微服务间的完整流动路径并传递环境标签。当请求进入系统，经多服务处理时，该系统完整记录其“足迹”——包括经过服务、携带标签、是否异常，为问题排查与性能优化提供关键支撑。</p><p>接下来，我们将深入解析全链路多版本环境背后的三大关键技术实现。</p><h2>三、关键技术实现</h2><p>从实现视角聚焦，核心技术主要包括：</p><ul><li>环境编排 - 负责指挥与创造</li><li>资源弹性 - 负责支撑与供给</li><li>流量隔离 - 负责识别与路由</li></ul><p>三大技术形成有机整体，紧密协作，缺一不可。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558910" alt="" title="" loading="lazy"/></p><h2>3.1 环境编排</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558911" alt="" title="" loading="lazy"/></p><p>实现多版本并行的第一步是高效、标准化地“创建环境”。</p><p>这主要由CI/CD平台支撑，它不仅是自动化工具，更是强大的可视化环境编排器。开发人员在界面定义待部署服务，系统自动识别服务间依赖关系，判断哪些可并行部署、哪些需串行执行，最终实现“一键完成”环境编排。</p><p>优势显而易见：无论是全新版本环境搭建，还是单一服务更新，均可通过单次点击，在分钟级别快速完成，使“秒级拉起独立完整环境”成为研发流程常态。</p><p>具体而言，CI/CD平台在全链路多版本中提供两方面关键支撑：</p><ul><li><strong>全链路能力支持：</strong>实现代码提交到自动化验证的端到端集成，确保各环境配置一致，大幅减少环境差异问题。同时精细管理微服务间依赖，支持串并行混合执行，使复杂部署流程井然有序。</li><li><strong>多版本并行支持：</strong>平台根据代码分支自动触发独立构建部署流程，为各版本创建隔离环境、添加环境标签，实现环境高效复用与隔离。底层对接强大容器化平台，为环境快速启动提供技术保障。</li></ul><p>CI/CD平台作为多版本环境体系的“指挥中心”，高效调度四大核心组件——为容器部署提供调度依据，为流量隔离准备环境标签，使分布式链路系统充分发挥跟踪与观测能力。</p><h2>3.2 弹性资源</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558912" alt="" title="" loading="lazy"/></p><p>指令发出后，需要强健的“执行体”高效落实。vivo容器化平台正是这一强大、可靠的实体。</p><p>弹性资源能力由容器化平台核心支撑。全链路多版本环境中，我们能够轻松、快速创建大量隔离环境，背后依赖的正是容器技术。</p><p><strong>容器化工作原理简述：</strong>开发者将应用及其所有依赖打包为标准容器镜像。该镜像可在任何支持容器的环境中运行，确保开发、测试、预发和生产环境高度一致，真正实现“一次构建，随处运行”，从根源解决环境差异问题。</p><p>资源利用率方面，容器技术优势明显。传统虚拟机部署中，单节点通常仅运行单一应用，资源利用率低。容器化部署允许多个容器共享节点操作系统内核，轻量高效。对多版本环境管理而言，这意味着可低成本、高效率创建大量隔离环境。以往需10台服务器支撑的多版本测试，现仅需3-4台，成本显著降低。</p><p>此外，容器平台具备自动扩缩容能力，这在多版本场景中尤为重要：特性环境压力测试时，系统自动扩容保障稳定性；测试结束环境闲置时，资源自动缩容回收，真正实现按需使用、高效节能。</p><p>容器化带来三大核心价值：环境标准化、资源高效化与伸缩自动化。这些能力组合使我们能够轻松维护多版本并行研发，加速产品迭代，提高系统稳定性，同时显著降低成本。</p><p>对业务团队而言，这意味着更快功能交付、更稳定系统运行与更高资源利用率。这是全链路多版本环境支撑大量环境并行而无需担忧资源成本激增的根本原因。</p><h2>3.3 流量隔离&amp;流量染色</h2><p>环境与资源就绪后，确保流量“对号入座”是实现隔离性的关键。这引出两个核心概念：“流量隔离”与“流量染色”。</p><h3>3.3.1 流量隔离和流量染色的定义</h3><p><strong>流量隔离</strong>指由统一流量网关平台维护智能路由表，记录“环境标签”与“服务实例地址”间映射关系。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558913" alt="" title="" loading="lazy"/></p><p>如图示：Feature1环境流量仅路由至IP1、IP2实例；Feature2流量指向IP3、IP4实例，实现真正互不干扰。</p><p><strong>流量染色</strong>如同为每批流量分配“颜色标识”。请求进入网关前，为其添加明确环境标识，声明“属于Feature1”或“属于Feature2”。网关据此正确识别与路由。</p><p>理解流量隔离与染色后，需将其应用于真实网络环境。微服务架构下，流量基本分为两类：南北流量与东西流量。</p><p>图示说明：</p><ul><li><strong>南北流量：</strong>外部客户端与服务器间流量，即“进出数据中心流量”；</li><li><strong>东西流量：</strong>数据中心内部服务器间流量，即微服务间调用。</li></ul><p>在vivo实践中：</p><ul><li>HTTP流量由vivo统一访问平台处理；</li><li>Dubbo流量由Dubbo服务治理平台负责；</li><li>MQ消息通过MQ消息网关平台路由。</li></ul><h3>3.3.2 流量隔离实现</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558914" alt="" title="" loading="lazy"/></p><p><strong>1.HTTP流量隔离</strong></p><p>过程如图绿色路径所示。始于环境编排阶段：通过流水线部署服务时，为各实例注入唯一环境标签。同时，vivo统一访问平台建立“环境标签”与后端服务实例组（Upstream）的绑定关系，触发创建相应CRD并实施监听。</p><p>此后，无论是部署、实例扩容、缩容还是重启，只要实例IP和端口变化，变更都会被实时监听并动态更新至网关路由规则，形成高效自动化闭环，确保每个带环境标签的HTTP请求被网关精准路由至正确特性环境实例。</p><p><strong>2.DUBBO协议隔离</strong></p><p>借助Dubbo官方原生标签路由能力实现。原理直观：将服务实例动态划分至不同逻辑分组，约束带特定标签流量仅能访问指定分组。vivo实践中，打标动作发生于部署环节。容器启动时，Init Container自动调用Dubbo服务治理平台，通过动态规则配置，无感地为当前服务实例添加环境标签。整个过程无需重启服务，配置实时生效，完美支持全链路多版本对灵活性与实时性要求。</p><p><strong>3.消息队列（MQ）隔离</strong></p><p>与前两者不同，MQ组件本身缺乏完善隔离机制。我们基于MQ消息网关平台mq-proxy组件实现。</p><p>实现方式巧妙：生产者与消费者启动并与mq-proxy建立连接时，在连接属性中携带自身环境标签。消息生产时，mq-proxy拦截消息，将环境标签写入消息user-property中。消费时，mq-proxy根据消息中标签与消费者自身环境标签进行匹配过滤，确保消息不会被跨环境消费。整个过程对业务代码完全透明，实现无侵入隔离。</p><h3>3.3.3 流量染色实现</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558915" alt="" title="" loading="lazy"/></p><p><strong>南北流量染色：</strong>客户端至服务器端流量染色实现方式如下。</p><ul><li><strong>HTTP请求：</strong>在请求头中添加环境信息，推荐使用ModHeader等浏览器插件，便捷地在请求头中添加env_tag=feature1等信息。</li><li><strong>Dubbo调用：</strong>将环境标签置于Attachment中，提供简洁API，开发者只需在发起调用前，通过RpcContext.setAttachment("dubbo.tag","feature1")代码即可设置环境标签，对业务代码侵入性极低。</li><li><strong>MQ流量染色：</strong>对业务方完全透明，由前述mq-proxy组件自动完成，业务代码无感知。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558916" alt="" title="" loading="lazy"/></p><p><strong>具体实现：</strong>生产者与消费者启动时，与mq-proxy建立连接，使用连接属性v-env-tag存放环境标签，即图示中间启动部分。消息生产消费环节中，生产者生产消息时，mq-proxy拦截消息，将环境标签写入消息user-property中。</p><p>消息消费端，mq-proxy拉取消息时，获取消息中环境标签信息并进行过滤，推送至对应环境服务实例，确保仅消费属于当前环境的消息。通过此机制，保证消息在整个生命周期携带环境标识，实现MQ流量染色。</p><h3>3.3.4 标签的传递</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558917" alt="" title="" loading="lazy"/></p><p>最复杂部分在于环境标签在整条调用链中<strong>自动传递</strong>。通过vivo分布式链路系统实现，核心技术为javaagent，通过调用链Agent透明完成此项“接力”工作。</p><p>示例如下：来自客户端的HTTP请求携带env\_tag=feature1，网关将其路由至feature1环境的用户中心。用户中心需调用积分中心时，调用链Agent拦截此次Dubbo调用，从HTTP请求头中获取env\_tag，并注入Dubbo调用的Attachment中，积分中心因此收到该标签。积分中心处理完毕，需发送MQ消息通知活动中心。此时Agent再次拦截，从Dubbo Attachment中获取标签，写入MQ消息属性。最终，仅标注feature1的活动中心实例消费此消息。整条链路中，如有环节未匹配环境标签，流量则回退至基线环境。</p><p>如此，环境标签在HTTP→Dubbo→MQ完整链路中自动传递，确保全链路环境隔离，真正实现“一次染色，全程生效”。</p><p>回顾关键技术部分：<strong>环境编排是指挥中心，负责调度与创造；弹性资源是执行实体，负责支撑与运行；流量隔离与染色是传导系统，负责精准识别与路由。</strong>三者有机结合，构成全链路多版本环境管理的稳固架构，缺一不可。</p><h2>四、业务实践与效果</h2><p>全链路多版本环境落地实践后，成效显著：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558918" alt="" title="" loading="lazy"/></p><ul><li><strong>环境搭建效率提升：</strong>从过去多团队沟通、手动配置、平均耗时2人天，转变为开发者一键触发、分钟级自动完成。</li><li><strong>版本并发能力增强：</strong>以往受资源限制，仅支持2-3个版本串行测试；现可轻松支持9个以上特性环境并行开发测试。</li></ul><p>这不仅带来效率提升，更实现研发节奏全面加速与业务响应能力质的飞跃。</p><h2>五、未来规划</h2><p>展望未来，我们对全链路多版本环境管理有清晰规划。这不仅是技术升级，更是研发管理理念的演进。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558919" alt="" title="" loading="lazy"/></p><p>未来规划采用双轨并行策略，从研发效能环境标准化与资源成本高效化两个维度同步推进。两方向相互促进、协同支撑。</p><h2>5.1 研发效能环境标准化</h2><p>在已实现的环境编排、资源弹性与流量隔离基础上，重点推进三项关键措施：</p><p><strong>1. 构建环境即服务平台</strong></p><p>平台提供标准化环境模板，包括不同规模测试环境及各类专用环境（如性能测试、安全测试等）。通过模板化方式，确保环境一致性与标准化，同时大幅提升环境创建效率。</p><p>平台集成环境全生命周期管理功能，从环境申请、审批、创建、使用、监控到回收，形成完整闭环管理。这不仅提升管理效率，更建立完善的环境治理体系。</p><p><strong>2. 建立全链路环境监控与可观测体系</strong></p><p>监控体系涵盖多层：基础设施层监控CPU、内存、存储等资源使用；中间件层监控数据库、消息队列、缓存等组件性能；应用层监控服务响应时间、错误率、吞吐量等关键指标。</p><p>通过分层监控，快速识别环境中异常情况，及时发觉性能瓶颈，为环境优化提供数据支撑。监控数据同时为资源调度与成本优化提供重要决策依据。</p><p><strong>3. 建立环境治理与合规自动化机制</strong></p><p>治理机制包括环境命名规范、资源配置标准、安全配置要求、数据保护规则等多方面。通过自动化合规检查工具，实时监控环境合规状态，自动发现与修复不合规配置。</p><p>机制还包括环境定期审计功能，自动生成合规报告，为管理决策提供支撑。通过此方式，既确保环境安全合规，又减少人工审计工作量。</p><h2>5.2 资源成本高效化</h2><p>资源成本高效化方面，推进以下两项关键措施：</p><p><strong>1. 非活跃环境自动回收</strong></p><p>针对非活跃环境，建立智能自动回收机制。系统自动识别长期未使用环境，在确保数据安全前提下，自动进行资源回收。</p><p>机制包含多层管理：</p><ul><li>测试环境非工作时间自动休眠；</li><li>开发环境连续7天未使用发出提醒；</li><li>连续14天未使用自动回收。</li></ul><p>通过分层管理，既保证开发效率，又有效控制成本。</p><p><strong>2. 成本可视化与归因分析</strong></p><p>成本分析从多维度展开：</p><ul><li>按<strong>项目</strong>维度分析各项目资源使用成本；</li><li>按<strong>团队</strong>维度分析各团队成本构成；</li><li>按<strong>环境类型</strong>维度分析不同环境成本效益；</li><li>按<strong>时间</strong>维度分析成本变化趋势等。</li></ul><p>通过精确成本统计与分析，为成本优化提供数据支撑。</p><p>通过双轨并行策略，我们实现研发效能提升与资源利用最大化的良性循环。</p><p>全链路多版本环境管理的未来规划不仅是技术升级，更是研发管理理念的转变。通过双轨并行策略，我们将建立更高效、经济、可靠的研发环境体系，同时打造更先进的研发环境管理体系。</p>]]></description></item><item>    <title><![CDATA[Apache DolphinScheduler 3.4.0 重磅发布！ 海豚调度 ]]></title>    <link>https://segmentfault.com/a/1190000047558946</link>    <guid>https://segmentfault.com/a/1190000047558946</guid>    <pubDate>2026-01-22 16:02:13</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558948" alt="" title=""/></p><p>最新消息，Apache DolphinScheduler 3.4.0 已正式发布！</p><p>本次版本带来了多租户调度隔离、工作流并行性能优化、任务重试与告警机制增强，以及资源管理和日志处理改进。无论是复杂企业业务场景，还是高并发任务调度，3.4.0 都让系统更高效、更可靠、更易用。立即升级，体验全新调度能力！</p><h2>升级与下载</h2><p><strong>下载页面</strong>（可选择镜像下载）：<br/><a href="https://link.segmentfault.com/?enc=XksKSzR%2FDujDJEGStqOwRQ%3D%3D.%2FmfKHuTq1wJiNInTDYmUlXNngGpwFM7YBSH1%2BLucXV%2BkwgZZUmm%2FY1xIg%2BLcbaNvhutpMH56DDkFo8sDannUpA%3D%3D" rel="nofollow" target="_blank">https://dolphinscheduler.apache.org/zh-cn/download/3.4.0</a></p><p><strong>GitHub Release 页面</strong>：<br/><a href="https://link.segmentfault.com/?enc=8TQyX7TQ2VDbnAD2QgR%2Bgw%3D%3D.HeSeQLoDGNBXSYxa5jRsMrobonbUY6YlbTzY11lqV%2B68qfPKqovD6KV5lg24h5gjgdElmOTgs3f1pu9jXMdxjA%3D%3D" rel="nofollow" target="_blank">https://github.com/apache/dolphinscheduler/releases/tag/3.4.0</a><br/>升级时建议参考官方文档中的集群升级指南，确保兼容性和配置一致性。</p><h2>核心功能增强与重要更新</h2><h3>通用 OIDC 认证支持</h3><p>3.4.0 引入了对 OpenID Connect（OIDC）的通用支持，旨在简化与企业身份认证系统的集成。通过 OIDC，用户可以使用统一的身份提供商（如 Keycloak、Okta 等）进行 SSO 登录，无需额外实现复杂自定义逻辑。这提升了安全性和用户体验，尤其是在多系统联邦登录与统一认证场景中，能够使 DolphinScheduler 更自然地融入企业级认证体系，减少重复配置和验证成本，从而提高登录配置的扩展性和一致性。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558949" alt="" title="" loading="lazy"/><br/>（参考图）</p><h3>gRPC 任务插件支持</h3><p>本版本新增了 gRPC 任务插件能力，使调度器能够通过原生 gRPC 协议直接与远程服务交互。用户可以将后端微服务暴露的 gRPC 接口作为任务执行目标，无需中间脚本封装。这种方式特别适合微服务生态或跨语言执行场景，通过明确参数契约和高性能通信协议提升任务整合效率，从而减少资源调度延迟、提高任务可靠性。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558950" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558951" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558952" alt="" title="" loading="lazy"/></p><h3>支持工作流串行策略</h3><p>实现了 <strong>工作流串行执行策略（Workflow Serial Strategy）</strong> 的核心逻辑重构，通过引入一个全新的串行命令队列机制（<code>t_ds_serial_command</code> 表及相关 DAO/Mapper），配合一套串行执行协调器（<code>WorkflowSerialCoordinator</code>）及策略处理器，使 DolphinScheduler 能更智能地管理串行类型的工作流（如 <code>SERIAL_WAIT</code>、<code>SERIAL_PRIORITY</code>、<code>SERIAL_DISCARD</code>）。</p><p>该设计改进了工作流触发流程的执行类型判断、状态管理、命令队列处理等关键路径，使串行调度逻辑更清晰、更可靠，有助于提升串行工作流场景下的调度稳定性与可控性。同时，3.4.0 重构了触发器与状态机相关代码，增强该能力的可维护性和扩展性。</p><h3>移除 PyTorch 任务类型</h3><p>3.4.0 对任务类型体系进行了精简，正式移除了内置的 PyTorch 任务类型。该调整主要基于实际使用情况和长期维护成本的考量，因为原有 PyTorch 任务实现使用率较低，且与调度器核心任务模型耦合度较高，增加了版本演进和兼容性维护的复杂度。通过移除该任务类型，DolphinScheduler 能保持核心架构的简洁与稳定。</p><p>我们鼓励用户通过更通用的 Shell、Python 或插件化方式运行 PyTorch 作业，从而提升系统整体的可维护性和扩展性。</p><h2>稳定性与重要修复</h2><h3>Kubernetes Worker 部署增强</h3><p>在 Kubernetes 原生部署场景下，3.4.0 使 Worker StatefulSet 的 Helm Chart 支持注入 Secrets 和 InitContainers。通过 Secrets 注入，可以安全传递证书或凭据；InitContainers 允许在主容器启动前完成必要的初始化逻辑，如准备文件系统或校验环境依赖。</p><p>这些增强有助于在容器化环境下实现更安全、更一致的部署策略和生命周期管理。</p><h3>SQL 任务取消能力</h3><p>针对 SQL 任务类型，本次版本提供了对任务执行取消的原生支持。当执行的 SQL 语句由于逻辑错误或长期运行导致资源占用时，用户可以通过调度器下发取消操作，使任务尽快中止，而不是简单失败或等待超时。这一能力改善了任务控制能力，避免长时间运行对集群资源的无效占用，有助于提升整体资源利用率和执行调度体验。</p><h3>条件任务节点在前置失败情况下执行逻辑修复</h3><p>在某些复杂工作流中，当条件任务节点的前置任务失败时，条件节点未按预期执行。3.4.0 修复了这一调度核心逻辑，确保条件节点能够正确响应前置失败状态。这样，工作流分支逻辑能够按照既定 DAG 定义可靠运行，从而避免因逻辑错误导致的流程中断或不一致执行。</p><h3>ZooKeeper 节点清理问题修复</h3><p>在使用 ZooKeeper 作为协调组件的高可用部署中，部分用户反馈 Master Server 在启动失败后未正确清理已注册的 failover 节点路径，可能导致后续状态异常。该版本修复了这个问题，使 Master 在异常启动路径中能够正确清理关联注册节点，保持注册中心状态一致，确保高可用场景下集群状态的健康和可靠性。</p><h3>Worker Group 分配逻辑错误修复</h3><p>此前版本中，项目与 Worker Group 关联/移除操作可能在 API 层出现逻辑不一致，导致调度器未能正确识别项目与 Worker Group 的关系。本次版本修正了相关逻辑，使 API 行为与用户预期一致，从而改善 Worker 管控、资源隔离和调度分配体验。</p><p>此外，3.4.0 版本还进行了很多功能优化和问题修复，包括<strong>文档与配置规范完善</strong>（时区、安全、负载均衡）、<strong>核心调度与注册中心稳定性增强</strong>（TraceId、Failover 清理、可重入锁）、<strong>性能与资源管理优化</strong>（任务组索引）、<strong>前端与插件体验改进</strong>（日志查询、DataX 校验、文件展示）、<strong>依赖与安全更新</strong>（PostgreSQL JDBC、Spring Boot CVE 修复）等，篇幅所限不再一一展开，详情可查询完整更新列表：<a href="https://link.segmentfault.com/?enc=oseH429BqJM4VmwreH3hmQ%3D%3D.3d50YoUXH9A8cMcG3IDQz%2Bnvuie2Aq0O8k6uWTUFEjnsuqx%2F4um64%2FEV1pNoTQchOPT%2FgOqr2W1i30Pa2gsUgQ%3D%3D" rel="nofollow" target="_blank">https://github.com/apache/dolphinscheduler/releases/tag/3.4.0</a></p><h2>Bug 修复亮点</h2><h3>标记任务为 Inactive 状态逻辑修复</h3><p>某些生命周期事件中，当任务状态需要被标记为 Inactive 时，状态变更可能未正确触发，导致 UI 和执行引擎状态不一致。此版本修复了这一逻辑，使状态标记与生命周期事件更加一致。</p><h3>Workflow Lineage 删除逻辑优化</h3><p>在工作流血缘关系删除操作中，系统可能未能彻底清理相关引用，导致历史血缘链路残留。3.4.0 改进了删除逻辑，使 DolphinScheduler 在删除血缘链时能够更精确地清理对应关系，避免分析后续依赖时出现错误链路。</p><p>其他 Bug 修复包括前置任务失败导致条件节点不执行问题修复、项目级 Worker Group 绑定与移除逻辑修正、子工作流触发参数丢失问题修复等，详情请查询完整 Release Note：<a href="https://link.segmentfault.com/?enc=mldq8RljaXjx3UWNwZiTXw%3D%3D.5qm9M6MOkGCiwYzheFxK5zK7VY9dOGXmJNVxvGtj3c%2BQt7L%2FxIaQuvn2yT8O4j0AraqTLQMZHAI4Bt16QbfJ1g%3D%3D" rel="nofollow" target="_blank">https://github.com/apache/dolphinscheduler/releases/tag/3.4.0</a></p><h3>文档更新</h3><ol><li>发布并完善 Apache DolphinScheduler 3.3.2 版本发布说明文档。</li><li>修复文档 CI 构建错误，提升文档发布流程的稳定性。</li><li>补充 Prometheus 指标接口的认证机制及其在 Kubernetes 环境下的使用说明。</li><li>同步更新 JdbcRegistry 引入事务机制后的相关文档描述，保证文档与实际行为一致。</li></ol><h2>致谢</h2><p>本次版本发布离不开社区各位贡献者的热情参与与支持。特别感谢 @ <strong>Gallardot</strong> 作为 3.4.0 的 <strong>Release Manager</strong>，从版控、构建、候选版验证到最终投票组织，确保发布流程高质量推进。</p><p>同时，感谢以下本次版本的所有贡献者（GitHub ID，排名不分先后）：</p><p>Gallardot、njnu‑seafish、det101、Mrhs121、EinsteinInIct、sanfeng‑lhh、ruanwenjun、tusaryan、qiong‑zhou、SbloodyS、kvermeulen、npofsi、CauliflowerEater、ChaoquanTao、dill21yu、sdhzwc、zhan7236、KwongHing、jmmc‑tools、liunaijie</p><p>感谢所有通过提交 PR、Issue、文档贡献、社区讨论、测试验证等方式参与 Apache DolphinScheduler 项目的人。正是你们的努力推进了 DolphinScheduler 的持续演进与社区繁荣，欢迎更多人加入我们的队伍！</p>]]></description></item><item>    <title><![CDATA[“新”意十足 · HarmonyOS模板&组件 （本次上新：求职、回收、旅游攻略模板；发票、估价等组]]></title>    <link>https://segmentfault.com/a/1190000047558957</link>    <guid>https://segmentfault.com/a/1190000047558957</guid>    <pubDate>2026-01-22 16:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><img width="568" height="328" referrerpolicy="no-referrer" src="/img/bVdnIk4" alt="image.png" title="image.png"/></p><blockquote>💡 鸿蒙生态为开发者提供海量的HarmonyOS模板/组件，助力开发效率原地起飞 💡<br/>★ 更多内容，一键直达<a href="https://link.segmentfault.com/?enc=BI4AKEAyCzhoVjTCnwXIAw%3D%3D.BKXEOxjDa7srnNYdb4QkFuNPrq9P6UZYqkMPQvvYbzIHUcrvGs%2BIBJgInLK8sq9grmkiRjI3uhuxlnHyKu82SIrmt2gThKdNnEat%2BcHKWdJBujp44zasN42cCs8D3XJQ%2BdH02d92MSyW6lO3P7y4MI3LESgGZ1nZwfPK2Q943zw%3D" rel="nofollow" target="_blank">生态市场组件&amp;模板市场</a> , <a href="https://link.segmentfault.com/?enc=dR4vknJpUZxvRNP4biBz1Q%3D%3D.dXjWD1hlrLruGnrqBUx7%2Bl5qN4BUKkJPn1l7VRucA9SQOeJyQDETV%2FFnSqpSXmc9X4Rbp9befQPWA1F%2F65RG0bgKphv4sscwBJEanI2KsH%2BpU4RbDK%2BmepXZLfUaKpC6exgM6RnzovbK6KL9vGThXSOO%2BEw9NJNvaNjugqHn6qDQ2mKrf%2BV5AUM6S5FlWKsg" rel="nofollow" target="_blank">快速应用DevEco Studio插件市场集成组件&amp;模板</a> ★<br/>★ <a href="https://link.segmentfault.com/?enc=f%2F5ZJf8rfMCRRnBj1cjwgA%3D%3D.l73C4hbKSBeWhM99tNPbTHTy%2F1nQgOWIIpslqu4iOT3Wj2T%2BZv7YRgiyrB4NHQfQ%2BiE2B6vkU%2BPAQwOFZpbsZLTp%2BAjRk%2FrDLhsC2Joc%2FE4GwSwG79fDs7xRkYZlubOH31XTQnVUP33q7g0wGcCr2w%3D%3D" rel="nofollow" target="_blank">一键直达 HarmonyOS 行业解决方案</a> ★</blockquote><p><img width="723" height="75" referrerpolicy="no-referrer" src="/img/bVdnIld" alt="image.png" title="image.png" loading="lazy"/></p><h2>模板 | 求职招聘应用模板（<a href="https://link.segmentfault.com/?enc=yztw66L09yfpTA%2FwnryLtw%3D%3D.o09qAoTn9ZDx8U1Vw3PckRgMfLdN%2BekACOIrENHhd4Fixwxr5o9HaQ3LRNYsGZuMnWVQDWmu3eeVPuJjL9Wzmgz84BbgwoZgk%2BoF%2BRtyzNz7DPWikdPWUjh6gqEgBglorCqUSbXp7uW1%2FAxuo42yWLKQm7%2Fc4nIlTKh8px844s8K65zSeJM3koaux%2B4tVpBxbfu1EJDWZlHt0SRRsmCXFEarJabHXLZnc7OEGsS8p1k%3D" rel="nofollow" target="_blank">点击下载</a>）</h2><p>本模板为招聘类应用提供了常用功能的开发样例，模板主要分职位、消息、个人中心三大模块。本模板已集成华为账号、即时通讯、推送、分享等服务，支持深色模式、适老化、无障碍等特性，提供完整的招聘应用解决方案，只需做少量配置和定制即可快速实现招聘应用的核心功能。<br/><img width="723" height="377" referrerpolicy="no-referrer" src="/img/bVdnIlq" alt="image.png" title="image.png" loading="lazy"/></p><h2>模板 | 购物（回收）应用模板（<a href="https://link.segmentfault.com/?enc=TfMP6AMrntW8h6EQrfMKrQ%3D%3D.Yjkfgy9nVYrY0nnfw4XQrJBblGHqHNSIAzvIbYtEcVKb2tz%2B%2BkfUIScDWkg1PgSc7U41g9fp8ImB8Fxpqbp9nOfhNvd%2FleyOTv70ARbPNmK0Y5wPvINf6b9dek8w%2FN%2FpoMKM%2B9xsGs3MzkLXUv1Tf3BBGVehb6%2FroOAYykzc1C6ODGcl9LreE%2FBfRxucA2tsO5tIKjIbb31pLfoM2Y2sYYeGYPPl25H%2Ftt1ZkVW%2FV3g%3D" rel="nofollow" target="_blank">点击下载</a>）</h2><p>本模板为回收类应用提供了常用功能的开发样例，模板主要分首页和我的两大模块。本模板已集成回收服务、华为账号、订单流程、地址管理、银行卡等服务，支持创建订单、编辑地址、我的设置等特性，提供完整的回收服务应用解决方案，只需做少量配置和定制即可快速实现回收服务应用的核心功能。<br/><img width="723" height="379" referrerpolicy="no-referrer" src="/img/bVdnIlu" alt="image.png" title="image.png" loading="lazy"/></p><h2>模板 | 旅游攻略应用模板（<a href="https://link.segmentfault.com/?enc=GqeCIZOmV9vBB3Prb4aGug%3D%3D.%2BrQ%2Bj2xKkf%2B7mmRrrulp84lHd8sGOE3mIpEpnb1Ed3YGx5gNfiDvv%2FgPH5LtCXJmLC%2Fq0dAeNjdagtI4irA2WMKWjyFNe4iwM%2BDezNj8bov2o0O88JKMQiqWvm3cYX4QVtIeKxR5%2F%2BekyE0Bgcif5zIBJyV0ol%2Blm0EZlMheiQDv9r7ph19UJ%2BdaNbHY6N3rrSElVmi2Q22Tj%2BlpBFEo3703UGXJmNvI1u6iO63aXwE%3D" rel="nofollow" target="_blank">点击下载</a>）</h2><p>本模板为旅游类应用提供了常用功能的开发样例，模板主要分首页、行程、消息和个人中心四大模块。本模板已集成华为账号、微信登录、消息管理、应用更新检查、意见反馈、实名认证等服务，采用模块化架构设计，支持多设备适配，只需做少量配置和定制即可快速实现旅游攻略应用的核心功能。<br/><img width="723" height="379" referrerpolicy="no-referrer" src="/img/bVdnImx" alt="image.png" title="image.png" loading="lazy"/></p><h2>组件 | 可分可合组件</h2><table><thead><tr><th>归属模块</th><th>名称</th><th>简介</th></tr></thead><tbody><tr><td><a href="https://link.segmentfault.com/?enc=HDrgwS8KbQAM%2BiK60aUwaQ%3D%3D.7dGMTlYu6It5QZZDxwn7XMbmQwIbgdIgymVQfiPYdQkwZ5feg6FtcECpxYeUgD7RfNZOBbybGH%2BfaKbOVyMFCG%2FBX3JHfLxyYiHevn%2FwID92%2ByONXajgVY9tvg6GGyHk8LE42MKqNp038Xgs6lgK4mXnDv38w%2BfHCJikCnNZxRjMSCX%2B86cpVLUprZf1c1eGLE61p5yIoWB8TcpCgry4dYmf0sCV4hBN%2F0HF48XYeQM%3D" rel="nofollow" target="_blank">公交地铁应用模板</a></td><td><a href="https://link.segmentfault.com/?enc=kKQWveGeYLxRtWdnyCvFIA%3D%3D.pazD8kpmal1zUOKY7gL9A%2BH3wbHXMngYg0CsvaZl83rxsJTtoNjRE84Yr9VyxQ4uLoCEgleb4QtkzJ25KrJXt9A041%2BsAVJ%2BftfDnFVQlAE%2B54XyBCMxUo0Lt8kYxIKyqGEvB0hOdylcEhc5J1LXcci%2FY1Z3jOtfY7lMlFwnZcx8uKexNLmR4mE8MAIxk%2B5OyhvQM5wHLcnCnOE%2Bd2Xbmk8uB%2FX75G4X2PpitWfYUdo%3D" rel="nofollow" target="_blank">公交地铁站点地图组件</a></td><td>提供了展示当前位置信息、附近站点、路线规划、导航功能。</td></tr><tr><td><a href="https://link.segmentfault.com/?enc=ToeSpfiyPg84Tph0rPPkQA%3D%3D.qm1ajV302peIHUieDe4EsdFD5CDay1jv1DTtBLnyKtnHVc451zGBUhc7VITqtniSoCZB9357PmKTp0h%2BrApfXK%2B4uz%2BkXBT6Wi3Uts%2B1kGKv%2FakxkuJrSVdLKhJ5mdxQOFsCrw0yqLo0ZMXf3BarTEXE4Z%2BOd3lCUn2aZcrcygtTha%2Fx1fl9ZbvWRxLMquqx8b6sqpYidcfGthSwQoRJ8mpgShCpWQk53yf8oH%2FSi8Q%3D" rel="nofollow" target="_blank">公交地铁应用模板</a></td><td><a href="https://link.segmentfault.com/?enc=xIjSVDrTFwSx1p1qYihTLw%3D%3D.Zu38vanv8qyTnyUzvoW7%2FxClI2CfiHX%2B6TItrctgyyN1pjlsTIjSalwWTC7u2YPH1awTDki8Eu01RErShz0Lcc3OhDU96zJ5l9amvJBCxSZL4W2dmyfDbNXpB03zMWSU6tjjNtyNLC3R42BscRE3LpQqcA1qqVcKdZTL2%2B3AyOdvkB761NoeQqDxXKgbog7q8QsSDR9d9Y39VZ4HDH2Rv4qmxpmalHGzvJpSQtPuUCI%3D" rel="nofollow" target="_blank">站点线路组件</a></td><td>提供公交地铁站点和线路的综合信息展示功能，支持导航、收藏、到站提醒及地图轨迹展示，还可查看同站线路。</td></tr><tr><td><a href="https://link.segmentfault.com/?enc=uWfqhTnlWM7KtMTUHHwABw%3D%3D.YdpYKaLmYjcNq8aV%2BIdhElnXDBECgQRhaR3n%2Fp1CbDOWt2QLnh%2Fm7xCLBk0hO27qxnDqfk5lppW3X7a7gq0tv387063ZPaDjT1i0sobalzFJ6r5d0a%2FiQdyS50jGG7RtJgMBOvF4knSKKdo2SEUumn5CYO0tT1jo5zuRr7FmE5CPMc6AoFeD4MczNcWf0J5zc7xmLp8PgKH9zy8JopD0PwFlRAEEPo%2BGy0P2a0cBleA%3D" rel="nofollow" target="_blank">求职招聘应用模板</a></td><td><a href="https://link.segmentfault.com/?enc=2FVZn4XUKs1OajTQ33LrGg%3D%3D.k%2Bv5XAKNSeKKe6dkUDR13QytIobFX0SeCZqB7fJHXIPyXImsw80PIB8qp1BkyqPVo1WGstKMn9GOcZSv8hffXQTdFw3jxRwBgKoVlvVzpj5QfYx8ESZBBiGt9fSgpk%2BUHfi3ltqoQST0jmDlFumTIkw7QPIjoQ8pQNu4ypR0dEgWq1WH64aqqlkPh6EWYzTrFzTIAVol%2FkFy8%2FgvPuFXL0y0su1vs6HIUZL%2FH30N6Rw%3D" rel="nofollow" target="_blank">求职意向组件</a></td><td>提供了求职意向管理功能，支持添加、编辑、删除求职意向信息，包括工作性质、意向职位、工作城市、行业类型、期望薪资和求职状态等信息的填写和管理。</td></tr><tr><td><a href="https://link.segmentfault.com/?enc=K7cUWtJvbuJJR0i%2FNM6m7A%3D%3D.Q2AoGezlb5W1XKKYXufMYhHQnsf5oQqBXFoDATbpxeAOYPKhKTI6JO%2BEmxkOkQCrUwij9a429xOLm7sEdQQ8QnKEn2LwryGKoavFZrAN7vnZJHHFt8xjOmQEcZrTXYeT9Slhcv4QH%2BUo%2B9W1a9wp9XvtVc14WC3TjM9oMxM%2BsDcs1maZ2e1M4mIkyLWXV7dB4L4Iuu0YjqK2O%2B39CnfOMWQ1sv0A9fcEDng24h1YfRg%3D" rel="nofollow" target="_blank">回收应用模板</a></td><td><a href="https://link.segmentfault.com/?enc=VCPkc3p9MqkpxpbwQ%2BhSvQ%3D%3D.4mFTHt5u3hAhdCRUTwjrAFu4c0vAO2lqebG3TrFr6gVzMxnp0PVanNYIUICV5wIMQ6GV9XjZNXtmtX8MoGiYrRgISw6yDSOd8xeVDjDg4EPk7WiiPKJ9oI1WnG250sXsFscTFfW3%2FDZmgwslFrbZe3lZd8BdTXBox1e9%2FXDAhhq65PyuR1hlNUJ5URwJxtfMKD%2FWi0GjI9WZ%2FQgvecHVBevNJo%2FxSxVKaWRPpNJH5ro%3D" rel="nofollow" target="_blank">回收估价表单组件</a></td><td>提供手机/电脑回收估价表单能力。估价表单：通过 BuildValuationInfoPageBuilder 构建页面，支持型号、设备类型、选项选择与价格计算，并通过回调返回估价结果。</td></tr><tr><td><a href="https://link.segmentfault.com/?enc=FJgb6ezVMYNCwnta8Wlmsg%3D%3D.23maIpfMZvtwKJx1aVuioW1xbHrzgQ2owIT8GCwCpSjC5O3G5KdXsQ%2BGszWnfW2ZSGqfjFzKhi7OmjKMKK9G2EJuAxNJUKYHaNo1JqyBa0SoB5RI1YCKl94XIJp%2BC9Bgm8gFUboIwXyiHTZ7%2FnG8tNBMtiQBtRPb9BEM%2BMK6Rrm4%2BiG6jNGnVWdG2LBE9MZyLXq%2FFAf3HgYfjdMlOou%2FAaRKKPB4X%2Fbya2d5oP6Wi9o%3D" rel="nofollow" target="_blank">旅游攻略应用模板</a></td><td><a href="https://link.segmentfault.com/?enc=mMZpPcoLFVPYJlpXiHw2LA%3D%3D.G7nQzRWtahOppWrigrhHXjo1RcK4KlQQK0PnYlF9ibdUdh9ufEAQDXiq9va82yMzBLga33ChqoNQrm%2FI6n9bP287WLzf4CJ6rmGwqzbLvIHcP5xbNOLhSmUT8Ss2Uw%2BqiD0Xf1djO5Q2rpMaAmHNU1RVlw%2BxkRWxljlHoCLfQTaFzsGQYDwkg7nu7dMs72uBWaWedF2I0DzN1ptGvSwDEl8nigRTmh%2FoPgycXFA2dso%3D" rel="nofollow" target="_blank">旅行足迹组件</a></td><td>提供了旅行足迹管理的相关功能，支持足迹地图展示、总里程统计、足迹列表浏览、添加新足迹等能力。</td></tr><tr><td><a href="https://link.segmentfault.com/?enc=DaCGdWFNBMT9hF5J%2BA%2FFVQ%3D%3D.mEkLRvS9I0gEYz5jgCHajdwfmQvPbn0fE3ChFkq%2BxYrdVfrRWiBx15bqPlUI7QvtAVF8GIOM7jNKKZnhYd0YQ5k8gCWUifg%2BUayYNyoqW%2F0sqBsU%2FalGCFtIh11fB6x9Bc6Y5NiG20MFwA22Mf7vF4D7tcJN%2BC7nWarbonTS3f5TyxCnV%2F25x91MLOh%2Buq3c0UXph9p3fUxRnf%2BbIBwfycZQE4tl0ich0zdt4l5Iyhw%3D" rel="nofollow" target="_blank">旅游攻略应用模板</a></td><td><a href="https://link.segmentfault.com/?enc=eaFyfES2%2FX06ud0yB%2BLEOw%3D%3D.%2BSA1a3fCpkUkpZGCUjIE86sAC%2Bpug%2F%2FZfo0BQIqu5HqGkaI%2B5wiYQqjrCWPvCJ0u1Jhb965gZuF7u2MWYeJ1AxvuniQK%2FGxpcGcjFwnj%2FEaMlHL70yfgsL96BZBELPm5%2FFi%2BddbLOw0s8mHyP2Itcf3sCeLx3YDS7txIokm9BnPeVPiTfgYW9vLSx%2FKniuv9pzJnkvD8VcMXhH0fUuuSgwSUagxtc9IGlmujxSf9pzA%3D" rel="nofollow" target="_blank">发票编辑组件</a></td><td>提供了发票管理的相关功能，支持发票列表展示、添加新发票、编辑现有发票、删除发票等能力。</td></tr><tr><td><a href="https://link.segmentfault.com/?enc=lDKlKOb48j2e3jWxkKsqwg%3D%3D.5mRhgkaptNJcmImqmEJBK%2BzkVeDyerF7ADqHp%2Byxum%2BHC6zWIw%2BM0SvJF6mk2Y9JDYR9RJMCR4tmoDVxSfaDommREcAo64w7pJKfN9QTr4eZR3yqJcH8I1JoK0Brp%2FbXChRTsF5aTmIgCz8spn%2BpkHiOC%2BkvYbdIJUVHdgB5%2FxLDoohfmyWCRIItIMtdcK1UtAPNLR3aF9AxyJUywJydg%2FW1iRCUjay%2BA%2F5O76LZYqc%3D" rel="nofollow" target="_blank">旅游攻略应用模板</a></td><td><a href="https://link.segmentfault.com/?enc=OFwPL3BZvtRDwnZV2j0%2Fxg%3D%3D.auH7qqQa6PJREHi3cUAYOeiWGzc9MGUoxcA1qlMT404J0W%2F6p83HF0SkS0ouc8zoqapGMQUrjO8tSqN5Y6N11UVvzYmuLAK4DtPhGAqmT5R9jgjXetXIvpXKbPndi0DvhSdxfnpwt4BuQR0UFMlceOubdpd4WZPZcNRgQyjtfKWJdST9QQqBb5gblF6hkqvRsxEulIZMOtmGnHVE9RryGwWLBJGBfmjI3BUBo1O1gB0%3D" rel="nofollow" target="_blank">路线规划组件</a></td><td>提供了旅游路线规划功能，支持用户选择出发地、目的地和游玩天数，并根据选择智能推荐旅游路线。</td></tr><tr><td><a href="https://link.segmentfault.com/?enc=W3mMM%2BcYETFhzHR7uh3KZA%3D%3D.c9FmmDUGekGdZCC2lJ7OY6Dnj55G5bO4Ko9Tvv7QPQ1r1bYnVIAvtdf%2FUwumdMtYyW3vfTJWNdN8ZJtxwDT4NEMSHsmeCkbzhAJSpMNykE0ETGKJ1KYqTHSMBi%2FavcEhBTkpMe5q2ZTsAe0SzfYzf0pYaT0B6PnwtUP3ghEp%2BuAUF3e7MMhn3hWypwbGGvBhVBQWgk482N5Y9oNJCUZVjzTvBIvZGvMhkQrhlnpe59s%3D" rel="nofollow" target="_blank">壁纸应用模板</a></td><td><a href="https://link.segmentfault.com/?enc=iIP5trYxCwfuSTY01O8rpQ%3D%3D.m4So0XtfDqqfICPjOD%2B1ODbWsU5nczvixCaidLJr7MrNpUAqSDmc0nku3LF3Httg1UiAkN0UGEK0V7VTzHjUyadN6TbdzsW4UGqU7mnF6JkWBatIV%2FrADOS1pTruO7nw6lhzYD0tgYMxP6aRtIMdqoMIhKzeFsZ0%2BulXUeHS%2FA2wqLXAuG%2BakzyORm9MvYtNBLDzZpIy7Porlj%2FtSnBuTzLiGGu92RDXr5qZeadGdNI%3D" rel="nofollow" target="_blank">壁纸详情组件</a></td><td>提供了壁纸详情展示功能，其中包含：作者名称、作者头像、壁纸分类、壁纸关键词、以及收藏、取消收藏、预览、下载、设为壁纸、左右切换壁纸等功能。</td></tr></tbody></table><p>更多模板&amp;组件上新，敬请关注！<br/>欢迎下载使用模板&amp;组件“<strong><a href="https://link.segmentfault.com/?enc=MI2Gw1%2FRPgADlRhha2%2FdNg%3D%3D.wMPHLQ%2BqJrGr8B0djoz%2F0Kgj9XnKLP2b7WX%2Flu0U5IrgjZwECKRel9BE6%2FzNKir3KBCW3HT1ePGOSNn0J2W304PBfoa2WfBsdZajZC8lQ3VZ4Uu%2BeKfsTZ9lAjc2pK4mHUBbGkpps5rVzA3HhiFpRYj6dbEdxCNYhwWfizXteaQ%3D" rel="nofollow" target="_blank">点击下载</a></strong>”，若您有体验和开发问题，或者相关心愿单<br/>欢迎在<strong><code>评论区留言</code></strong>，小编会快马加鞭为您解答~<br/>同时诚邀您添加下方二维码加入“组件模板开发者社群”，精彩上新&amp;活动不错过！</p><p><img width="723" height="415" referrerpolicy="no-referrer" src="/img/bVdnImV" alt="image.png" title="image.png" loading="lazy"/></p><h2>【相关推荐】</h2><p>👉 HarmonyOS官方模板优秀案例系列持续更新， <a href="https://link.segmentfault.com/?enc=t5ApUUsaxE7R0IrKbjI2PA%3D%3D.ZEm%2FkJkWToPz14%2FskUlIL04H%2BWz1%2Fd7NozcbCV8TsIcIF7mcUa%2FEgGTwHKrJN4yfoftCAQZr064FzL6RrKzVujw8A9VyyGdBF8hOR48lkzgF%2BKla7msvoMFPAFGhMjVbyw9RqclaOl8RXSkVVYeOCiNvVS7g9ZtN76J9G%2BybhhRyCqIGZFSr%2BAaj7kuWRYpI" rel="nofollow" target="_blank">点击查看</a> 往期案例汇总贴，欢迎收藏，方便查找！<br/>👉【组件征集】HarmonyOS组件开发征集活动，<a href="https://link.segmentfault.com/?enc=Zc7mAL%2Bm5IoZ6%2FwzQlKENQ%3D%3D.udfDPuqhT7DQ61haCfbFv7X%2FzxJQWDYzxLXXBLePqFd%2Bk3HD47eRdSnRtvBTLCTfD%2FZzVad0X4%2B5rD9Y19TOEGGVNSY6O2csavo6TZCDBtYyFy%2BLluHFWp1UNFXQ%2BI2Y0sgTI7QsQWjBW%2F4oF04D2A%3D%3D" rel="nofollow" target="_blank">点击参加</a><br/>👉【HarmonyOS行业解决方案】为各行业鸿蒙应用提供全流程技术方案。<a href="https://link.segmentfault.com/?enc=sZZPpGFn7rMwKriXcCM%2FoA%3D%3D.pwLyiPWTTF1kUZh%2BiZBye34tz790zhqoOmqf0ouQzgwYDJoBZjVwDsWSOdS19bfTlbtaTChffzlMF2R%2BxjO38QMp5xev9TDP8cQ9eekrDSJP4bNsIB4kPFbCFb4TCjjl79S6heYWNdccRyXDsS0oDQ%3D%3D" rel="nofollow" target="_blank">点击查看</a></p>]]></description></item><item>    <title><![CDATA[怎么让 vscode/trae 的 git graph 显示的 date 用 iso8601 的格式]]></title>    <link>https://segmentfault.com/a/1190000047558307</link>    <guid>https://segmentfault.com/a/1190000047558307</guid>    <pubDate>2026-01-22 15:12:03</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>现在 datetime 都是英文的，英文不看的都看不到是几月份的，所以我需要改成纯数字的 iso8601 格式的</p><p>操作方法看下面的图片</p><p><img width="723" height="395" referrerpolicy="no-referrer" src="/img/bVdnIfB" alt="图片.png" title="图片.png"/></p>]]></description></item><item>    <title><![CDATA[2026移动办公全指南：高效移动端管理工具选型建议 曾经爱过的汉堡包 ]]></title>    <link>https://segmentfault.com/a/1190000047558316</link>    <guid>https://segmentfault.com/a/1190000047558316</guid>    <pubDate>2026-01-22 15:11:07</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <blockquote>站在咖啡馆的柜台前，项目经理李薇用手机轻点几下，就重新分配了因航班延误而受影响的三个任务。这种随时随地的管理能力，如今正通过移动端好用的管理工具成为现实。</blockquote><p>在移动办公成为常态的今天，工作场所已从固定的办公桌延伸至通勤路上、客户会议室甚至家庭客厅。据统计，超过68%的职场人需要在下班后处理工作事务，而其中<strong>近60%的核心协作</strong>通过手机完成。</p><p>但屏幕尺寸、网络环境和交互方式的根本性改变，也给团队管理带来了前所未有的挑战。</p><h2>01 移动办公的挑战：为何传统管理工具力不从心？</h2><p>移动办公的核心特征是<strong>碎片化与场景化</strong>。工作被切割成更短的时间块，穿插在差旅途中等候、会议间隙甚至家庭生活中。这种模式下，传统为桌面端设计的管理工具暴露出了明显短板。</p><p>信息同步延迟是最常见的痛点。团队成员更新了项目状态，但其他人手机上的通知可能迟迟未到，或淹没在混杂的社交信息中。在需要快速决策时，这种延迟可能导致机会错失。</p><p>其次，<strong>功能阉割与操作繁琐</strong>严重阻碍效率。许多工具的移动版只是桌面版的简化移植，关键功能缺失，操作路径深且不符合触屏逻辑。在小屏幕上创建复杂任务、查看甘特图或进行多文件比对，常常令人沮丧。</p><p>更深层的是协作壁垒。移动环境下，沟通与管理往往脱节——重要的讨论散落在微信、钉钉等即时通讯工具中，却无法与任务状态自动同步，导致信息孤岛，<strong>执行过程不透明</strong>，管理者难以掌握真实进度。</p><h2>02 核心价值：移动端专用管理工具如何破局？</h2><p>移动端管理工具的核心价值，在于它<strong>不是对桌面工具的补充，而是为移动场景原生设计的新工作界面</strong>。它重新定义了信息如何被获取、任务如何被处理以及协作如何发生。</p><p>其首要优势是<strong>极致的实时性与可达性</strong>。优秀的移动工具通过优化的推送机制和后台同步，确保信息秒级触达。即使网络短暂中断，也能在本地记录操作，待网络恢复后自动同步，保证工作流不间断。</p><p>其次是<strong>情境智能与操作简化</strong>。工具能根据用户所处场景（如时间、地点、正在处理的任务）智能推荐下一步行动。例如，在接近客户公司时自动弹出相关项目资料；通过语音快速创建任务、用拍照一键上传并关联至工作项，极大降低了移动输入成本。</p><p>最终，它实现了<strong>沟通与执行的融合</strong>。在任务卡片中直接讨论，评论自动转为待办事项，关键对话一键转为任务指派。这让协作上下文完整保存，决策过程可追溯，真正做到了“讨论即执行，执行即记录”。</p><h2>03 实战解析：主流移动端管理工具深度评测</h2><p>理解价值后，我们来剖析几款真正为移动场景深度优化、在手机和平板上拥有卓越体验的管理工具。</p><p><strong>微软 To Do</strong> 是跨平台轻量级任务管理的典范。其移动端与Office 365生态深度绑定，支持邮件星标自动同步，适合个人事务与轻量协作。</p><p><strong>滴答清单</strong> 集日历、习惯打卡、番茄钟于一体，移动端自然语义识别强大，输入“明天三点开会”即可智能创建任务。</p><p><strong>板栗看板</strong> 与微信、钉钉深度融合，支持将群聊对话转为卡片，其移动端看板视图经专门优化，交互流畅。</p><p><strong>Things 3</strong> 是苹果生态中设计美学与生产力的标杆，移动端交互为触控全新设计，能与系统深度联动构建自动化工作流。</p><h2>04 未来展望：AI与移动管理工具的融合趋势</h2><p>移动设备天生的便携性与丰富的传感器，使其成为人工智能技术落地的绝佳平台。未来，移动端管理工具将变得更加主动、情境感知和预见性。</p><p><strong>情境感知的自动辅助</strong>将成为标配。工具将综合GPS定位、日历日程、手机使用状态，智能判断用户当前是否可处理深度任务。例如，在检测到用户正在通勤时，自动推送适合短时处理的审批或阅读任务。</p><p><strong>语音与自然语言成为主要交互界面</strong>。未来的移动管理将更多地通过“语音创建任务”、“对话式询问项目进度”来完成。AI不仅能理解指令，还能追问模糊细节，一次性生成结构完整的任务项，彻底解放双手。</p><p><strong>预测性风险干预</strong>是更高阶的应用。AI通过分析任务推进速度、协作互动频率、历史延期数据等，在移动端提前预警项目风险。例如，向项目经理推送提示：“A任务关联的3个子任务进度均落后，整体延期风险高达70%，建议今天下午召集核心成员进行5分钟快速同步。”</p><h2>05 选择指南：四步找到你的移动管理利器</h2><p>面对众多选择，你可以遵循以下路径，找到最适合团队的那一款：</p><ol><li><strong>核心场景匹配测试</strong>：不要被功能列表迷惑。邀请团队成员，用最常发生的2-3个移动办公场景（如“客户突然来电要求修改方案并同步给团队”）来实测候选工具。观察完成整个流程需要多少步操作，是否顺畅。</li><li><strong>评估离线与弱网能力</strong>：主动关闭Wi-Fi和蜂窝数据，测试能否查看最近的任务列表、能否编辑任务内容。恢复网络后，观察编辑内容是否自动同步、有无冲突提示。这是移动工具可靠性的试金石。</li><li><strong>审视通知系统</strong>：仔细研究工具的通知定制粒度。能否按项目、任务类型、紧急程度设置不同的提醒方式和频率？能否在移动端设置“免打扰时段”？一个既及时又不构成骚扰的通知系统至关重要。</li><li><strong>考量生态集成成本</strong>：检查工具是否与你团队已离不开的日常应用（如邮箱、网盘、通讯软件、签批系统）良好集成。在移动端，每一次强制性的应用切换，都意味着注意力的打断和效率的损耗。</li></ol><h2>06 技术实践：移动任务管理器的简易代码实现</h2><p>以下是一个模拟移动端智能任务管理核心逻辑的简化代码示例，展示了如何根据场景生成任务并进行智能同步：</p><pre><code class="python">from datetime import datetime, timedelta

class MobileTaskManager:
    """移动端智能任务管理器核心逻辑演示"""
    
    def create_task_from_context(self, context: str, location: str = None) -&gt; dict:
        """根据场景和位置创建智能任务"""
        # 智能优先级判断
        priority = "中"
        if "紧急" in context or "尽快" in context:
            priority = "高"
        elif "整理" in context or "备份" in context:
            priority = "低"
        
        # 智能截止时间建议
        due_hours = {"高": 4, "中": 24, "低": 72}.get(priority, 24)
        due_date = (datetime.now() + timedelta(hours=due_hours)).strftime("%m-%d %H:%M")
        
        task = {
            "id": f"task_{datetime.now().strftime('%H%M%S')}",
            "title": f"[移动端]{context[:15]}..." if len(context) &gt; 15 else context,
            "priority": priority,
            "due": due_date,
            "location": location,
            "created": datetime.now().strftime("%H:%M"),
            "status": "待处理"
        }
        
        print(f"✓ 创建任务: {task['title']}")
        print(f"  优先级:{priority} | 截止:{due_date}" + (f" | 位置:{location}" if location else ""))
        return task
    
    def sync_offline_tasks(self, task_list: list) -&gt; dict:
        """模拟离线任务同步"""
        print(f"\n📡 同步中... 发现{len(task_list)}个待同步任务")
        print("─" * 30)
        
        for i, task in enumerate(task_list, 1):
            print(f"{i}. {task['title']:20} | 状态: {task['status']}")
        
        return {
            "success": True,
            "synced": len(task_list),
            "time": datetime.now().strftime("%H:%M:%S")
        }

# 演示移动端任务管理场景
print("🚀 移动端任务管理器演示\n")

manager = MobileTaskManager()

# 场景1：紧急任务创建
print("场景1：客户现场紧急任务")
manager.create_task_from_context("紧急修复客户演示系统BUG", "客户办公室")

# 场景2：常规任务创建
print("\n场景2：常规跟进任务")
manager.create_task_from_context("整理项目会议纪要并发送")

# 场景3：同步演示
print("\n场景3：网络恢复后同步")
tasks = [
    {"title": "修复演示BUG", "status": "进行中"},
    {"title": "整理会议纪要", "status": "待处理"},
    {"title": "提交周报", "status": "已完成"}
]

sync_result = manager.sync_offline_tasks(tasks)
print(f"\n✅ 同步完成 ({sync_result['time']})")
print(f"   成功同步 {sync_result['synced']} 个任务状态")</code></pre><hr/><p>移动端管理工具的进化，其本质是将管理的主动权交还给身处不同时空的人。在上海的地铁里审阅设计稿，在西安的出差途中批准预算，在广州的茶餐厅里同步项目节点——<strong>工作的节奏不再由地点决定，而是由想法和决策驱动</strong>。</p><p>当工具真正理解了移动的本质是“人的流动”，而不仅是“桌面的缩小”，高效协作便不再受限于任何物理边界。选择正确的移动端管理工具，不仅是选择一个软件，更是为你的团队选择一种更自由、更敏锐、更连贯的工作方式。</p>]]></description></item><item>    <title><![CDATA[智能体从0到1：AI Agent构建方法与大模型应用指南 智能体小狐 ]]></title>    <link>https://segmentfault.com/a/1190000047558318</link>    <guid>https://segmentfault.com/a/1190000047558318</guid>    <pubDate>2026-01-22 15:10:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><strong>关键词：智能体、AI Agent、大模型智能体、从 0 到 1、Agent 架构、AI 工作流、LLM 应用</strong></p><hr/><h2>一、背景：为什么现在是智能体爆发的起点</h2><p>2024 年之后，大模型（LLM）进入“能力稳定、成本下降、工具成熟”的阶段，单纯的聊天式 LLM 已无法满足复杂任务需求。真正的拐点在于：​<strong>大模型开始被组织成系统，而不是工具</strong>​，这正是智能体（AI Agent）出现的背景。</p><p>智能体的爆发并不是因为模型突然更聪明，而是因为三件事同时成熟：第一，大模型具备可靠的推理和工具调用能力；第二，API、插件、数据库、搜索等外部工具全面可连接；第三，真实业务场景对自动化、持续运行、闭环执行的需求迅速上升。于是，智能体成为连接大模型能力与真实世界的关键形态。</p><p>从这个意义上说，​<strong>智能体是大模型应用从 0 到 1 的起点，而不是终点</strong>​。</p><hr/><h2>二、什么是智能体：通俗解释与技术解释</h2><p>​<strong>通俗地说，智能体就是“能自己做事的 AI 系统”</strong>​。<br/>它不只是回答问题，而是能理解目标、拆解任务、调用工具、执行动作、接收反馈，并持续调整策略。</p><p>​<strong>技术上，智能体（AI Agent）是以大模型为核心决策引擎的闭环系统</strong>​，它至少包含五个组件：</p><ul><li>感知（输入信息）</li><li>规划（拆解目标）</li><li>执行（调用工具）</li><li>记忆（保存状态）</li><li>反馈（修正行为）</li></ul><p>这使智能体具备“持续运行能力”，而不仅是一次性回答能力。</p><hr/><h2>三、Agent 与普通 LLM 的区别</h2><p>很多人混淆“大模型应用”和“智能体”，但二者差别非常关键。</p><ul><li>​<strong>普通 LLM</strong>​：一次输入，一次输出，任务到此结束</li><li>​<strong>智能体（Agent）</strong>​：目标驱动，循环执行，直到任务完成</li></ul><p>换句话说，LLM 是“大脑”，Agent 是“有手有脚的大脑”。<br/>这也是为什么真正的复杂自动化，一定要使用智能体架构，而不是单次 Prompt。</p><hr/><h2>四、Workflow 与 Agent 的区别</h2><p>在实践中，很多人会问：我用工作流（Workflow）就够了，为什么还要智能体？</p><p><strong>Workflow 是确定性的流程自动化，而 Agent 是不确定性的目标自动化。</strong></p><ul><li>Workflow：步骤固定，适合稳定流程（如数据清洗、报表生成）</li><li>Agent：路径可变，适合开放问题（如研究、决策、协作）</li></ul><p>从 0 到 1 阶段，推荐的做法是：<br/>​<strong>用 Workflow 承载稳定部分，用 Agent 处理不确定部分</strong>​。</p><hr/><h2>五、从 0 到 1 构建智能体的关键步骤</h2><p>构建智能体并不复杂，但必须遵循结构化步骤，否则系统不可控。</p><h3>1. 明确目标（Goal）</h3><p>智能体必须是目标驱动的，而不是指令驱动的。目标越清晰，智能体越稳定。</p><h3>2. 设计规划能力（Planning）</h3><p>规划模块负责把目标拆解成可执行子任务，是 Agent 与 LLM 的关键接口。</p><h3>3. 工具调用（Tool Calling）</h3><p>智能体必须能调用真实工具，例如：</p><ul><li>搜索</li><li>数据库</li><li>API</li><li>文件系统</li><li>代码执行</li></ul><p>没有工具的 Agent 只是“会想不会做”。</p><h3>4. 记忆系统（Memory）</h3><p>记忆让智能体具备“连续性”，包括：</p><ul><li>短期记忆（当前任务）</li><li>长期记忆（历史经验）</li><li>外部记忆（数据库 / 向量库）</li></ul><h3>5. 执行与反馈（Action &amp; Feedback）</h3><p>智能体必须能根据执行结果调整策略，这一步决定系统是否可持续运行。</p><hr/><h2>六、智能体的典型应用场景</h2><p>智能体适合的不是“单点功能”，而是“完整任务”。</p><p>常见场景包括：</p><ul><li>自动研究与资料整理</li><li>企业知识库与问答系统（RAG + Agent）</li><li>数据分析与报告生成</li><li>自动化客服与运营</li><li>软件开发辅助（Coding Agent）</li><li>流程协作与任务管理</li></ul><p>可以这样判断：​<strong>如果一个任务需要反复思考 + 多步执行，就应该用智能体</strong>​。</p><hr/><h2>七、普通人和企业如何入场</h2><p><strong>普通人从 0 到 1 的路径：</strong></p><ol><li>使用现成平台（如智能体构建工具）</li><li>从单一任务开始（例如自动写周报）</li><li>理解 Agent 的结构，而不是模型参数</li><li>优先解决“真实痛点”</li></ol><p><strong>企业从 0 到 1 的路径：</strong></p><ol><li>不要先做平台，先做场景</li><li>用智能体增强流程，而不是替代员工</li><li>从“辅助型 Agent”开始，而不是“全自动”</li><li>把 Agent 当作系统工程，而不是 AI 功能</li></ol><hr/><h2>八、未来趋势与判断</h2><p>可以明确判断：<br/><strong>大模型应用将从“功能型”全面进入“智能体型”阶段。</strong></p><p>未来的核心变化包括：</p><ul><li>Agent 将成为默认应用形态</li><li>RAG + Agent 成为企业标准架构</li><li>单一模型不再重要，系统能力才重要</li><li>智能体将成为新型“数字员工”</li></ul><hr/><h2>九、总结：从 0 到 1，应该立刻做什么？</h2><p>如果你想真正进入智能体时代，建议你马上做三件事：</p><ol><li><strong>停止只学 Prompt，开始学 Agent 架构</strong></li><li><strong>从真实任务构建第一个智能体</strong></li><li><strong>把智能体当系统，而不是工具</strong></li></ol><p>智能体不是未来，而是现在。<br/>从 0 到 1 的窗口期，正在快速关闭。</p>]]></description></item><item>    <title><![CDATA[整合蛋白序列/三维结构/功能特征等数据，德国团队基于度量学习构建构建人类E3泛素连接酶「全景图」 超]]></title>    <link>https://segmentfault.com/a/1190000047558400</link>    <guid>https://segmentfault.com/a/1190000047558400</guid>    <pubDate>2026-01-22 15:09:34</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>生物体中，细胞蛋白的及时降解与更新是维持蛋白稳态的关键。泛素-蛋白酶体系统（UPS）是调控信号传导和蛋白质降解的核心机制。在这一系统中，E3 泛素连接酶作为关键催化单元，负责识别特定底物并催化泛素标记，从而调控蛋白降解、定位和功能状态。此外，E3 连接酶还调控免疫和炎症通路。由于其组织特异性表达及与发育和代谢综合征（包括癌症进展）的关联，E3 连接酶已成为很有前景的药物靶点，尤其适用于以往难以药物化的靶标。</p><p>与 E1（约 10 种）和 E2（约 50 种）酶相比，人类已鉴定出大量 E3 连接酶（约 600 种）。尽管如此，许多人类 E3 连接酶仍仅被部分表征，仍有大量酶处于假设或未知状态。迄今为止，已研究的 E3 连接酶表现出高度异质性，使其成为最具多样性的酶类之一，为模式识别和大规模研究带来瓶颈。因此，对人类 E3 连接酶组——即人类基因组编码的全部 E3 连接酶进行详细表征和分析，对于全面理解其生物学功能至关重要。</p><p>在此背景下，来自德国歌德大学的研究团队对「人类 E3 连接酶组（human E3 ligome）」进行了分类，整合了多层次数据，包括蛋白序列、结构域组成、三维结构、功能以及表达模式。该团队的分类方法基于度量学习（metric-learning）范式，采用弱监督的层级框架，以捕捉 E3 家族及亚家族间的真实关系。这一方法扩展了 E3 酶的传统分类（RING、HECT 和 RBR 类），区分了多亚基复合物与单体酶，并将 E3 酶映射到底物及潜在药物作用靶点。</p><p>相关研究成果以「Multi-scale classification decodes the complexity of the human E3 ligome」为题，已刊登 nature communications。</p><p>研究亮点：</p><ul><li>将现有 E3 连接酶的结构域架构、三维结构、功能、底物网络及小分子相互作用映射到分类框架中，以获得一般性及家族特异性洞察</li></ul><p>* 所开发的多尺度分类框架涵盖了典型及非典型 E3 机制，为理解 E3 连接酶的广阔生物学图景提供了完整路线图</p><p>* 为开发 E3-底物网络的药物干预策略打开了新思路</p><p><img width="723" height="464" referrerpolicy="no-referrer" src="/img/bVdnIgT" alt="" title=""/><br/><em>论文地址：</em><br/><em><a href="https://link.segmentfault.com/?enc=zxG0v9wdlNjUFAMvT8OPHg%3D%3D.J4EY78kpvgs7n3BP2QMSZcnC41ue2I6ibBBNu9%2BHhYp56fgnB5wJlTQx8unp%2FJ5XVfakJhjLYl9z3gADcpLknQ%3D%3D" rel="nofollow" target="_blank">https://www.nature.com/articles/s41467-025-67450-9</a></em><br/>关注公众号，后台回复「E3 酶」获取完整 PDF</p><p>更多 AI 前沿论文：<br/><a href="https://link.segmentfault.com/?enc=VtCb6NXS21dnt%2FR5%2BIaeYA%3D%3D.mEkLr23pga9WeILiYPcbQ%2FZ4f062wOxMY4Wj2ZTWXOo%3D" rel="nofollow" target="_blank">https://hyper.ai/papers</a></p><h2>数据集：构建人类 E3 泛素连接酶数据</h2><p>研究团队首先整合了来自 8 个独立数据源的人类 E3 泛素连接酶数据，包括既往文献报道和公共数据库（E3Net、UbiHub、UbiNet 2.0、UniProt、BioGRID 等），形成初步数据集共计 1,448 个蛋白条目。通过对各来源数据的交叉比对与一致性评分，去除了重复和潜在假阳性条目。随后，利用 InterPro 提供的 RING、HECT 和 RBR 催化结构域特征，筛选出 462 个高置信度的催化 E3 泛素连接酶，形成最终的人类 E3 连接酶组。</p><p>在多亚基 E3 复合物（如 Cullin-RING ligases）中，三个功能不同的子单元（支架蛋白、适配蛋白和受体蛋白）协同工作，将 E2\~Ub 分子定位到特定底物上。大型、刚性且位于中心的支架蛋白（如 Cullin 家族，Cul1–Cul5）通过同时结合催化 RING 指结构域亚基和适配蛋白/受体的对接位点，组织起整个连接酶复合体；适配蛋白桥接各模块，将支架蛋白 N 端对接面与独立的底物受体相连；受体蛋白决定底物特异性，直接识别并结合底物上的降解信号（degron），确定哪些底物会被泛素化（如 Skp2、Keap1、VHL）。研究团队独立注释并分类了三类亚基：151 个适配蛋白、106 个受体蛋白和 8 个支架蛋白，并利用它们的蛋白–蛋白相互作用（PPIs）绘制多亚基 E3 的底物映射。</p><p>随后，在催化结构域筛选阶段，研究人员以催化能力为核心判据，对候选蛋白进行严格过滤。通过 InterPro 等结构域数据库，系统识别与 E3 活性直接相关的关键催化结构域，包括 RING、HECT 和 RBR。仅保留明确包含这些结构域、且在序列和结构层面支持其泛素连接功能的蛋白，构建最终的「催化型 E3 连接酶」。这一过程有效剔除了仅参与调控、但不具备直接催化能力的辅助蛋白，从而保证了核心 E3 集合的功能一致性。</p><h2>基于度量学习的多尺度分类框架</h2><p>为了捕捉人类 E3 连接酶组中的复杂关系，研究人员采用机器学习方法来学习一个 Emergent 距离度量，整体框架如下图：</p><p><img width="723" height="145" referrerpolicy="no-referrer" src="/img/bVdnIgU" alt="" title="" loading="lazy"/></p><p>度量学习流程示意图</p><p>①多尺度距离度量</p><p>研究人员通过计算 12 种不同的距离来编码 E3 连接酶两两之间的关系，这些距离覆盖多个粒度层次：一级序列、结构域架构、三级结构、功能、亚细胞定位以及细胞系/组织表达。所有距离度量均被缩放至 [0,1] 区间，以便比较和组合，见下图：</p><p><img width="723" height="149" referrerpolicy="no-referrer" src="/img/bVdnIgV" alt="" title="" loading="lazy"/></p><p>覆盖分子和系统层级组织的多种成对距离度量的分布情况</p><ul><li>序列层面：使用了无比对的局部匹配得分（LMS）距离和基于比对的 γ 距离</li><li>结构域架构层面：计算了三种距离——Jaccard 距离、Goodman–Kruskal γ 距离和结构域重复距离</li><li>三维结构层面：使用 AlphaFold2 模型 TM-score</li></ul><p>* 功能层面：蛋白对 P 和 Q 的功能距离使用 GO 注释的语义相似性衡量，涵盖* 分子功能（MF）、生物过程（BP）和细胞组分（CC）三类本体</p><p>* 亚细胞定位距离</p><p>* 组织和细胞系共表达距离</p><p>②度量优化、聚类、自助法与分类</p><p>四个主要距离（γ、Jaccard、结构、分子功能）通过加权和整合，权重通过弱监督学习和元素中心相似指数（SEC）优化，如下图 ，得到最优组合指标。</p><p><img width="723" height="302" referrerpolicy="no-referrer" src="/img/bVdnIgW" alt="" title="" loading="lazy"/></p><p>通过最 SEC 评估 emergent 分层聚类（右图）与真实标签（左图）的重叠程度</p><p>层次聚类采用 Ward 最小方差法，结合自举方法计算支持度，生成最终 E3 树状图，并在树切割阈值 h = 0.25 下获得最优 emergent clusters，即将 462 个 E3 系统性地划分为 13 个家族，10 个 RING 家族、2 个 HECT 家族、1 个 RBR 家族，如下图：</p><p><img width="723" height="853" referrerpolicy="no-referrer" src="/img/bVdnIgX" alt="" title="" loading="lazy"/><br/>人类 E3 连接酶的分类</p><p>每个家族进一步人工分析序列和结构域特征，识别亚家族和异常蛋白。</p><p>③小分子聚类与结合概率</p><p>整合的 2D UMAP 投影用于小分子聚类，结合局部密度峰值识别 20 个代表性小分子簇。通过 log-transformed propensities（LPij）量化每个簇与 E3 蛋白的结合可能性，为后续 PROTAC 开发和靶向小分子设计提供指导。</p><h2>对人类 E3 连接酶组的完整性提供了详细评估</h2><p>①精细整理人类 E3 连接酶组</p><p>为了解决已有研究在整理 E3 系统时策略多样且定义标准常有差异的挑战，该研究团队明确界定了 E3 系统的催化成分，即包含一个或多个催化结构域的多肽序列。利用这一客观标准，能够对 E3 进行恰当注释并进行针对性分析。最终，研究人员发现所有数据集中共有 462 条多肽序列至少包含一个催化结构域，这些多肽构成了精细整理的人类 E3 连接酶组，见下图：</p><p><img width="590" height="440" referrerpolicy="no-referrer" src="/img/bVdnIgY" alt="" title="" loading="lazy"/></p><p>饼图显示了蛋白注释与筛选的程度，用以区分人类 E3 连接酶的催化和非催化组分</p><p>为了验证整理过程的可靠性，研究人员为每个蛋白定义了基于其在不同来源数据集中出现频次的共识评分。结果显示，HECT 类和 RBR 类 E3 连接酶在数据集中高度一致（共识评分 ≥ 0.6，橙色和紫色柱），而 RING 类（绿色柱）共识评分分布较广，显示出注释上的挑战，如下图：</p><p><img width="596" height="450" referrerpolicy="no-referrer" src="/img/bVdnIgZ" alt="" title="" loading="lazy"/><br/>所有注释蛋白类别的共识评分分布反映了跨数据集对 E3 催化组分的一致性</p><p>通过这一方法，研究人员最大限度地减少了假阳性和真阴性，纳入了高可信度的催化活性 E3，同时考虑了伪 E3 及未经过催化活性验证的其他 E3，从而对人类 E3 连接酶组的完整性提供了详细评估。</p><p>②人类 E3 连接酶的功能分化</p><p>为了评估人类 E3 连接酶的功能，研究人员进行了 UPS 基因的 CRISPR-Cas9 缺失筛选，以细胞活力作为主要表型。结果显示，共识别出 53 个催化型和 32 个非催化型 E3 组分对于细胞活力至关重要，如下图：</p><p><img width="723" height="320" referrerpolicy="no-referrer" src="/img/bVdnIg1" alt="" title="" loading="lazy"/></p><p>火山图显示 CRISPR 筛选中 E3 连接酶的关键基因分析结果</p><p>对 53 个关键 E3 的 GO 分析显示，其在核成分以及 DNA 损伤、复制和修复过程中显著富集，如下图，表明它们在维持基因组完整性和细胞核调控方面的核心作用，这些结果揭示了对细胞生存至关重要的 E3 组分。</p><p><img width="572" height="518" referrerpolicy="no-referrer" src="/img/bVdnIg2" alt="" title="" loading="lazy"/></p><p>对必需催化型 E3 的 GO 富集分析结果</p><p>*<br/>*</p><p>利用 Metascape 对 13 个 E3 家族进行 GO 富集分析，并通过 Cytoscape 可视化网络。结果显示，不同家族在底物选择、细胞定位和催化功能上具有明显分工，如下图。例如，RBR 家族成员 RNF14、RNF144A 和 PRKN 对 K6-linked 泛素具有特异性。K6-linked 链可标记停滞的 RNA-蛋白交联复合物（RNF14）、用于激活干扰素信号的 DNA 感应适配器 STING（RNF144A）以及受损线粒体以便清除（PRKN）。类似地，TRIM E3s（RING5）显著富集于抗病毒先天免疫反应中，它们调控细胞中模式识别受体活性，如 RIG-1 和 MDA5 介导的反应。</p><p><img width="723" height="949" referrerpolicy="no-referrer" src="/img/bVdnIg4" alt="" title="" loading="lazy"/></p><p>热图显示所有功能簇及对应家族特异性富集的 E3</p><p>④人类 E3 连接酶的可成药性图谱</p><p>为了探索基于近距离作用的潜在治疗途径，研究人员将已知的蛋白降解靶向嵌合体（PROTAC）和 E3 结合子衍生的现有 E3 操作位映射到各个 E3 及其家族。目前，仅有 16 个蛋白（9 个催化型 E3 和 7 个适配器）可被现有 E3 操作位直接靶向。已设计的 E3 操作位大多针对适配器蛋白（如 VHL、CRBN），而直接靶向催化型 E3 的仅极少数（如 XIAP、MDM2/4/7、BIRC2/3/7）。</p><p>利用该研究的人类 E3 连接酶进行最近邻分析，发现 5 个高度相关蛋白（BIRC8、RN166/181/141 和 UBR2），如下图：</p><p><img width="728" height="294" referrerpolicy="no-referrer" src="/img/bVdnIg5" alt="" title="" loading="lazy"/></p><p>由于它们具有高度结构相似性（通常为同源蛋白），现有 E3 操作位可被重新利用来靶向这些蛋白。映射小分子 E3 结合子使研究人员获得潜在的化合物集合，可靶向另外 25 个 E3 和 15 个非催化成分，从而发现未开发的靶点，为 E3 操作位的理性设计提供先导化合物开发途径，如下图：</p><p><img width="723" height="434" referrerpolicy="no-referrer" src="/img/bVdnIg6" alt="" title="" loading="lazy"/></p><h2>多尺度框架为复杂生物系统的解析提供利器</h2><p>在机器学习领域，多尺度框架（multi-scale framework）指的是一种能够在不同抽象层次或不同特征尺度上处理数据的建模方法或分析策略。它并不是固定的算法，而是一种设计思想，用于整合局部与全局信息、粗粒度与细粒度特征，从而提高模型的表达能力和泛化能力。</p><p>多尺度分类框架的价值，并不局限于对 E3 连接酶家族本身的系统梳理，其更重要的意义在于提供了一种可迁移、可扩展的组学整合方法论范式。这种跨尺度的整合思路，使其天然具备向其他多模态组学数据扩展的能力，为复杂生物系统的系统性解析提供了通用工具。</p><p>例如，细胞是生命的基本单位，其功能和命运由复杂的分子网络共同决定。传统的深度学习方法虽在单细胞转录组数据的细胞类型识别中表现良好，但缺乏生物学可解释性。2025 年 10 月 20 日，来自中国国家蛋白质科学中心（北京）、清华大学团队的研究人员提出了一种融合生物先验知识的多尺度可解释深度学习框架 Cell Decoder，实现了从基因、通路到生物过程的分层表征与推理，为单细胞水平上解码细胞类型提供了新的思路。Cell Decoder 通过将蛋白质互作网络、基因-通路映射及通路层级关系嵌入图神经网络架构，构建出跨尺度的生物知识图谱。在七个公开单细胞数据集的人体和小鼠样本上，研究团队对 Cell Decoder 与 9 种主流方法进行了系统评测。结果显示，Cell Decoder 在预测准确率 (0.87) 与 Macro F1 (0.81) 上均居首位，且在存在噪声扰动、细胞类型不平衡及跨批次分布偏移等复杂情形下仍保持稳定性能。\<br/>论文标题：Cell Decoder: decoding cell identity with multi-scale explainable deep learning\<br/>论文地址：</p><p><a href="https://link.segmentfault.com/?enc=hcIsrLdyUihw3QY3SUs0Ig%3D%3D.Y8Zi02Oxud0CZtpsJ%2BALdiUZixv%2FFLo33Ge%2BCpiVfGaJC%2FYffEC%2FayVT03vyMPPNgk%2FTo4t8ubAPSOs4E0mTmg%3D%3D" rel="nofollow" target="_blank">https://link.springer.com/article/10.1186/s13059-025-03832-y</a></p><p>从更长远的视角来看，多尺度框架可以进一步与空间蛋白组学数据、小分子药物库及化学空间信息等相结合，从而打通基础生物学研究、疾病机制解析与转化应用之间的数据壁垒。随着多组学数据持续积累，这一框架有望在生命科学研究与生物医药创新中发挥越来越重要的支撑作用。</p><p>参考文献：<br/>\<br/>1.<a href="https://link.segmentfault.com/?enc=RbuLagC4Ae6UOlT6KntYeA%3D%3D.zY55iSycGHZ%2BUCYb4FPw6sl3lhL73DzSHs%2BYtoBHjAz5Gw%2BQ8USyvv0NHyBPdOdpHrEU5rSsE1Cp9q%2BfEU%2BZTA%3D%3D" rel="nofollow" target="_blank">https://www.nature.com/articles/s41467-025-67450-9</a><br/>\<br/>2.<a href="https://link.segmentfault.com/?enc=6UVoUlRb2y1x3c9kHGoFMw%3D%3D.GqhpyzzNKPmAfmsWHug8Up3Oo5kRiWKlyduvpD4RmTd1Nzr4thUXUDyP7afasdj2vhX13VtFrrlnjcjbJ2sZUg%3D%3D" rel="nofollow" target="_blank">https://blog.csdn.net/qazplm12_3/article/details/153948711</a><br/>\<br/>3.<a href="https://link.segmentfault.com/?enc=b2RqhaDy1oTsGQmQ9qPJdA%3D%3D.cJQeLIGmX7jLj%2BQcQ6fiFGE8DOiKqec404w%2Bv2hNIVFJLUq37bcdwg7FCjvFjvUkf1OqR5teNy%2Blv%2BjQKz265g%3D%3D" rel="nofollow" target="_blank">https://link.springer.com/article/10.1186/s13059-025-03832-y</a><br/></p>]]></description></item><item>    <title><![CDATA[通义 DeepResearch：开源 AI 智能体的新纪元 DashVector ]]></title>    <link>https://segmentfault.com/a/1190000047558405</link>    <guid>https://segmentfault.com/a/1190000047558405</guid>    <pubDate>2026-01-22 15:08:40</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>相关点击访问：</h2><p><a href="https://link.segmentfault.com/?enc=1T7dhaV3ee3t4Y3wBaeyFw%3D%3D.DArqDLmvG%2B62DBULdclJZJq5iliBoV%2BKYl%2FeTIBaAo7oGwXdoDHaehGn8Y4mAbOX" rel="nofollow" target="_blank"><strong>github</strong></a></p><p><a href="https://link.segmentfault.com/?enc=u%2BRdIhnVCc1HCuQfKHb3DA%3D%3D.o0%2FSzkzGMjwm10Niom%2FmRji5tPcfRBg%2Bc93IUV5vTn6DwR%2Bk0j66kfFndPqVwOaM%2BIjQQXU1QKxkfSqryHGeiA%3D%3D" rel="nofollow" target="_blank"><strong>HUGGINGFACE</strong></a></p><p><a href="https://link.segmentfault.com/?enc=2fFPQ1LmbKVKpx%2BRk%2FCNxQ%3D%3D.jtg0Fj%2FO1kJvR1NZkwJybCVWDr7h5JfwSbu2UYhYDzHRM%2FpUtqfapX4K%2B1Iwmwmi5yBqCjB%2Bb8A1YOgoK9tZxg%3D%3D" rel="nofollow" target="_blank"><strong>MODELSCOPE</strong></a></p><p><a href="https://link.segmentfault.com/?enc=3s5Ixe7lAs2fn3K4hNUfnQ%3D%3D.KMpZDSE7o7XvLDhDTiXxoDdH8FIQ3jIuOuYEgx7RQVv2bZIUJt2QF4ZmOW2yxaLK" rel="nofollow" target="_blank"><strong>SHOWCASE</strong></a><a href="https://link.segmentfault.com/?enc=WLtM6pfRAPA4UsnO0Xwo4g%3D%3D.XIubzeNjpoNMtrn%2FBZnEgBmq7VXj4XLFshge9f0KiCAR35v4Nlb6U%2FUVx86v4f0W" rel="nofollow" target="_blank"><strong>github</strong></a></p><h2>从 Chatbot 到 Autonomous Agent</h2><p><a href="https://link.segmentfault.com/?enc=dSM1jdA0x6qQCsBz%2BFlEYQ%3D%3D.IiIAvzr3KyNAEauGr3hHqtyFqTsAK5fkg3rPhbjdXzya9lUlCCgtCLYNA445u5f9eWxP3S1MTp33a93qaiEKbvpRxqVERSSQ22eZc4o71cTgI%2BxWMCjA1bgGaoUNgDiV8Rdv6IbUOZg%2FJjGMca0IejDpHbYGiQiwWReAQGiyoqu%2B4%2B%2BNJTzNQ%2FbnJa0Nu2nJ" rel="nofollow" target="_blank"><strong>通义DeepResearch</strong></a> —— 首个在性能上可与 OpenAI DeepResearch 相媲美、并在多项权威基准测试中取得领先表现的全开源 Web Agent。</p><p>在多个极高难度的信息检索和推理任务中，通义DeepResearch 取得了最先进的（SOTA）成绩：</p><ul><li>Humanity’s Last Exam (HLE)：32.9</li><li>BrowseComp‑EN：43.4</li><li>BrowseComp‑ZH：46.7</li><li>xBench‑DeepSearch：75.0</li></ul><p>全面超越了目前所有的闭源及开源 Deep Research 智能体（Agent）。</p><p>不仅如此，我们还完整分享了一套可落地的高水平Agent构建方法论，详细介绍了从数据合成、Agentic 增量预训练（CPT）、有监督微调（SFT）冷启动，到强化学习（RL）的全套流程。在 RL 环节，我们提供了算法创新、自动化数据构建与高稳定性基础设施的全栈解决方案。</p><p>在推理阶段，基础的 ReAct 模式无需任何提示工程即可充分展现模型固有能力，而深度模式（test‑time‑scaling） 则展示了其在复杂推理与规划能力上的上限。</p><h2>基于合成数据的增量预训练和后训练</h2><h4>增量预训练数据</h4><p>我们提出在Agent模型训练中加入智能体增量预训练（Agentic Continual Pre‑training, Agentic CPT）阶段，从而为后训练提供一个强大的Agent基座模型。为此，我们提供了一套支持大规模持续扩展的智能体预训练数据合成方案AgentFounder，并与后训练过程中源源不断生产的数据形成数据飞轮。</p><p><strong>数据重组和问题构建</strong> </p><p>基于广泛收集和持续更新的知识文档、公开可用的爬虫数据、知识图谱以及后训练数据生产和训练中产生的轨迹数据和工具调用返回结果（例如，搜索结果和网页访问记录）等，我们构建了一个以实体为锚定的开放世界知识记忆。进一步，我们基于采样的实体和相关知识构造多风格的（问题，答案）对，以尽可能涵盖智能体所面临的真实场景。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558408" alt="image" title="image"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558409" alt="image" title="image" loading="lazy"/></p><p><strong>动作合成</strong> </p><p>基于多风格问题和历史轨迹数据，我们分别构建了三种类型的动作数据，包含单步的规划、推理动作和多步的决策动作合成。我们的方法能够在离线环境下大规模、全面地探索潜在的推理‑动作空间，从而消除了对额外商业工具 API 调用的需求。例如，对于决策动作合成，我们将原始轨迹中的步骤进行扩展，并最终建模成多步骤决策过程数据，以激发模型的探索能力和决策能力。</p><h4>后训练数据</h4><p><strong>High‑quality QA</strong></p><p>我们开发了一套端到端的合成数据生成解决方案。这一全自动流程无需人工干预即可构建超越人类质量的数据集，旨在突破智能体的性能极限。经过长期的探索和迭代——从早期的网页点击流逆向工程Benchmark（WebWalker）到基于图谱的合成方法（WebSailor 和 WebSailor‑V2），再到形式化的任务建模（WebShaper），我们的方法确保了卓越的数据质量和强大的可扩展性，突破了模型能力的上限。</p><p>为了解决复杂且高度不确定的问题，我们通过一种新颖的流程合成基于 Web 的问答数据。该流程首先通过在高度互联的知识图谱随机游走和基于表格数据融合同构表构建，将来自真实网站数据整合，并确保信息结构的真实性；然后，我们对子图和子表进行采样，生成初始问题和答案，关键步骤是通过策略性地混淆或模糊问题中的信息来增加问题难度。该方法基于一个组合泛化的理论框架，我们将问答难度正式建模为一系列可控的“原子操作”（例如，合并具有相似属性的实体），这些操作基于实体关系，使我们能够系统地增加复杂性。</p><p>为了进一步减少问答系统的信息结构与推理结构之间的不一致性，提高推理难度和结构扩展能力，我们提出了一种基于集合论的信息搜索问题形式化建模，基于这种建模，我们开发了能够以可控方式扩展问题的智能体，并最大限度地减少了推理捷径和结构冗余，从而进一步提升了问题质量，此外，这种形式还能高效地验证问答的正确性，有效解决了信息搜索合成数据难以验证的挑战。</p><p>我们还开发了一个<strong>自动化学术数据构建流程</strong>，以扩大博士级研究问题的规模。该引擎基于多学科知识库，生成需要多源推理的“种子”问答对；然后，每个种子都会进入一个自我引导的“迭代复杂性升级”循环，其中，一个问题构建代理配备了一套强大的工具，包括网络搜索、学术检索和 Python 执行环境。在每次迭代中，代理都会扩展知识边界，深化概念抽象，甚至构建计算任务，从而形成一个演化循环，上一轮的输出成为下一轮更复杂的输入，确保任务难度的可控且系统地升级。</p><p><strong>融合多样推理模式，激发智能体潜能</strong></p><p>为激发模型的初始能力，我们基于 ReAct 和 IterResearch 框架，通过拒绝采样的方式构建了一组轨迹。一方面，ReAct 作为一个经典且基础的多轮推理范式，为模型注入了丰富的推理行为，并加强了其遵循结构化格式的能力。</p><p>另一方面，我们引入了一种创新的智能体范式——IterResearch（下文将详细介绍）。它通过在每一轮动态地重构一个精简的工作空间，来释放模型的全部推理潜力，从而确保每一个决策都经过深思熟虑，不受上下文噪声干扰。</p><h2>Rollout模式</h2><p>我们对深度研究型智能体的部署范式进行了广泛的探索。因此，我们的最终模型支持多种部署格式，包括原生的 ReAct 模式和上下文管理的深度模式。</p><h4>ReAct 模式</h4><p>我们的模型使用ReAct推理范式展现出卓越的性能。它严格遵循“思考‑行动‑观察”的循环，通过多次迭代来解决问题。模型上下文长度为 128K，可以处理大量的交互轮次，从而完全实现与环境交互的可扩展性。ReAct 的简单性和通用性为模型的内在能力和我们训练流程的有效性提供了最清晰的基准。</p><p>我们选择ReAct很大程度上受到了“The Bitter Lesson”的影响，利用可扩展计算的通用方法最终将优于依赖复杂的人工知识和复杂设计的方法。</p><h4>深度模式</h4><p>除了 ReAct 模式外，我们还开发了“<strong>深度模式</strong>”，用于处理极端复杂的多步研究任务。此模式基于我们全新的 IterResearch 范式，旨在将Agent的能力发挥到极致。</p><p>IterResearch 范式的创建是为了解决Agent将所有信息堆积在一个不断扩展的单一上下文窗口中时出现的认知瓶颈和噪音污染。针对多步研究任务，IterResearch 将其解构为一系列研究回合。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558410" alt="image" title="image" loading="lazy"/></p><p>在每一轮中，Agent仅使用上一轮中最重要的输出来重建一个精简的工作空间，在这个专注的工作空间中，Agent会分析问题，将关键发现整合成一个不断演变的核心报告，然后决定下一步行动——是收集更多信息还是提供最终答案。这种“综合与重构”的迭代过程使Agent能够在执行长期任务时保持清晰的认知焦点和高质量的推理能力。</p><p>在此基础上，我们提出了<strong>Research‑Synthesis框架，</strong>并行使用多个IterResearch Agent探索同一个问题。并最终整合它们完善的报告和结论，从而得出更准确的最终答案，这种并行结构使模型能够在有限的上下文窗口内考虑更广泛的研究路径，从而将其性能推向极限。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558411" alt="image" title="image" loading="lazy"/></p><h2>端到端Agent训练流程</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558412" alt="image" title="image" loading="lazy"/></p><p>训练这样的Agent模型需要<strong>重新思考整个模型训练流程</strong>，从预训练到微调再到强化学习，我们建立了一套完整的智能体模型训练范式，将Agentic CPT → Agentic SFT → Agentic RL 连接起来，为 AI Agent创建了一个无缝的端到端训练循环。</p><p>以下是我们利用强化学习解决最后阶段的方法，对于使代理的行为与高阶目标保持一致至关重要：</p><h4>基于On-Policy策略的智能体强化学习 (RL)</h4><p>通过强化学习构建高质量的Agent是一项复杂的系统工程挑战；如果将整个开发过程视为一个“强化学习”循环，其组件中的任何不稳定或鲁棒性不足都可能导致错误的“奖励”信号。接下来，我们将分享我们在强化学习方面的实践，涵盖算法和基础设施两个方面。</p><p>在强化学习（RL）算法方面，我们基于GRPO进行了定制优化，我们严格遵循 on‑policy 的训练范式，确保学习信号始终与模型当前的能力精准匹配，同时，我们采取了一个 token 级别的策略梯度损失函数来优化训练目标。</p><p>其次，为了进一步降低优势估计（advantage estimation）的方差，我们采用了留一法 (leave‑one‑out) 策略，此外，我们发现未经筛选的负样本会严重影响训练的稳定性，这种不稳定性在长时间训练后可能表现为“格式崩溃”（format collapse）现象。为缓解此问题，我们会选择性地将某些负样本排除在损失计算之外，例如那些因过长而未能生成最终答案的样本，出于效率考虑，我们没有采用动态采样，而是通过增大批次（batch size）和组规模（group size）的方式，来维持较小的方差并提供充足的监督信号。</p><p>训练过程的动态指标显示，模型学习效果显著，奖励（reward）呈持续上升趋势。同时，策略熵（policy entropy）始终维持在较高水平，这表明模型在持续进行探索，有效防止了过早收敛。我们将此归因于Web环境天然的非平稳性，该特性促进了稳健自适应策略的形成，也因此无需再进行显式的熵正则化。</p><p>我们认为，<strong>算法固然重要，但并非 Agentic RL 成功的唯一决定因素。</strong> 在尝试了多种算法和优化技巧后我们发现，<strong>数据质量和训练环境的稳定性，可能是决定强化学习项目成败的更关键一环</strong>。一个有趣的现象是，我们曾尝试直接在 BrowseComp 测试集上训练，但<strong>其表现远不如</strong>使用我们合成数据的结果。我们推测，这种差异源于合成数据提供了一致性更高的分布，使模型能进行更有效的学习和拟合。</p><p>相比之下，像 BrowseComp 这样的人工标注数据，本身就含有更多噪声，加之其规模有限，导致模型很难从中提炼出一个可供学习的潜在分布，从而影响了其学习和泛化（generalize）能力。这一发现对其他智能体的训练同样具有启发意义，为构建更多样、更复杂的智能体训练方案提供了思路。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558413" alt="image" title="image" loading="lazy"/></p><p>在基础设施方面，使用工具训练智能体需要一个高度稳定高效的环境：</p><p>● 仿真训练环境：依赖实时 Web API 进行开发成本高昂、速度慢且不一致。我们利用离线维基百科数据库和自定义工具套件创建了一个模拟训练环境来解决这一问题。并且通过SailorFog‑QA‑V2的流程，为该环境生成专属的高质量数据，创建了一个经济高效、快速可控的平台，显著加快了我们的研究和迭代速度。</p><p>● 稳定高效的工具沙盒：为了确保在智能体训练和评估期间对工具的稳定调用，我们开发了一个统一的沙盒。该沙盒通过缓存结果、重试失败的调用以及饱和式响应等改进来高效地处理并发和故障。这为智能体提供了快速且鲁棒的交互环境，可以有效防止工具的错误响应破坏其学习轨迹。</p><p>● 自动数据管理：数据是提升模型能力的核心驱动力，其重要性甚至超过了算法。数据质量直接决定了模型是否能通过自我探索提升分布外泛化能力。因此，我们在训练动态的指导下实时优化数据，通过全自动数据合成和数据漏斗动态调整训练集。通过数据生成和模型训练之间的正向循环，这种方法不仅确保了训练的稳定性，还带来了显著的性能提升。</p><p>● On‑Policy策略的异步框架：我们在 rLLM 之上实现了异步强化学习训练推理框架，多个智能体实例并行与（模拟或真实）环境交互，独立生成轨迹。</p><p>通过这些措施，我们实现了智能体强化训练的“闭环”。从基座模型开始，我们进行了Agentic持续预训练以初始化工具使用技能，然后使用类似专家的数据进行监督微调以实现冷启动，最后进在on‑policy的强化学习，使模型进行自我进化。这种全栈方法为训练能够在动态环境中稳健地解决复杂任务的 AI 代理提供了一种全新的范例。</p><p>（我们的强化学习算法受到 <a href="https://link.segmentfault.com/?enc=chMv6udW7qF1Yvd03AnBAQ%3D%3D.csnYfBBdf63MQvJ6UDm61I9LDLkngWGKUNgwHyMNMEsCD%2Fl1P7zxxGQn1K2LxOrg" rel="nofollow" target="_blank">Agentica</a> 过去研究的启发。我们基于<a href="https://link.segmentfault.com/?enc=sjZnuGwX%2BwFZUnO2ByFdBw%3D%3D.QpEQcRmxNyAgMaLLf6mBXKM0N5xkfkh%2FUi4oYEyw2yyKB2nQY59w4ERG0%2FsPhOGu" rel="nofollow" target="_blank">rLLM</a>框架进行开发和扩展，实现高效训练）</p><h2>应用及影响</h2><p>通义Deep Research不仅仅是一个研究成果的展示，它<strong>已经在阿里巴巴内外赋能实际应用</strong>，并在实际场景中展现其价值：</p><p><strong>高德地图（地图导航智能体）</strong> 高德 App 作为通义在集团内长期共建的重点客户，其“地图导航+本地生活”的业务场景，以及高德内部丰富的专用工具，具备构建Deep Research 类 Agent 的土壤，高德也将这种能力作为 25 年暑期大版本 V16 的一个亮点功能。通义团队近期在地图+本地生活场景，基于纯agentic + ReAct执行复杂推理的垂类Deep Research技术建设，为高德提供更好效果的模型。因此，双方团队共建合作，“通义团队提供Deep Research模型 + 高德团队提供工具和 Agent 链路”，打造了高德 App 中助手「小高老师」的复杂查询体验，在地图行业内打出影响力。</p><p><strong>通义法睿（法律Deep Research）</strong> 作为大模型原生的“法律智能体”，致力于为大众及法律从业者提供专业、便捷的法律智能服务。集法律问答、案例法条检索、合同审查、文书阅读、文书起草等功能于一体，全面满足法律用户需求。依托创新的Agentic架构与迭代式规划（Iterative Planning）技术，通义法睿全新升级司法DeepResearch能力，可高效执行多步查询与复杂推理，实现权威类案精准检索、法条智能匹配与专业观点深度融合。我们以真实判例、官方法规和权威解读为基础，打造可追溯、高可信的法律分析服务，在法律问答的深度研究三大核心维度——答案要点质量、案例引用质量、法条引用质量上领先行业。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558414" alt="image" title="image" loading="lazy"/></p><h2>未来工作</h2><p>我们未来的工作将致力于解决以下三个关键局限性：首先，当前 128k 的上下文长度在处理极端复杂的长程推理任务时仍显不足。为此，我们将探索扩展上下文窗口的有效方法，并研究更精细的上下文管理策略。其次，我们训练流程的可扩展性在远超 30B 参数规模的模型上尚未得到充分验证，我们计划在更大规模的模型上测试并验证我们流程的有效性。最后，我们旨在通过引入 partial rollouts 等技术进一步提升强化学习框架的效率，这需要我们攻克离线训练所面临的挑战，尤其是分布偏移问题。</p><p>敬请期待我们下一代Agent模型：</p><pre><code class="plaintext">@misc{tongyidr,
  author={Tongyi DeepResearch Team},
  title={Tongyi DeepResearch: A New Era of Open-Source AI Researchers},
  year={2025},
  howpublished={\url{https://github.com/Alibaba-NLP/DeepResearch}}
}</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558415" alt="image" title="image" loading="lazy"/></p><hr/><p><strong>点击下方访问产品链接：</strong></p><p><a href="https://link.segmentfault.com/?enc=zTojal2kc65mlfEUH5hFQw%3D%3D.cBkzywWGuE8%2BXRi8EEXXXFZjXrtUE1hTd3TGWb6npAuHQMZYV9r4wk3WzEEa%2F0YZt4ny%2B%2Fqz92%2B9GKZn8qAfSWIqX4d0BFarL80fEIkKNLoJN7lifrE75PQFewYGM1kLi1rvJ3a%2FJhs4gi%2Fu%2BloR%2BIb5UCWYZnQSp8IpIHKsCf9ILNpL%2F3f%2FRwwrxG1NFaTIayPTS1bFFosMcH%2FB6KiNi2gQghZ2lDRSCt%2FswgvTCb5QfXnjrKT5Diaz5OnQH9y2" rel="nofollow" target="_blank">面向深度的查询问答和调研分析需求场景,多步骤推理规划研究路径,生成有洞察、可溯源、图文并茂的长文报告-大模型服务平台百炼(Model Studio)-阿里云帮助中心</a></p>]]></description></item><item>    <title><![CDATA[2026-01-22 GitHub 热点项目精选 程序员锋仔 ]]></title>    <link>https://segmentfault.com/a/1190000047558426</link>    <guid>https://segmentfault.com/a/1190000047558426</guid>    <pubDate>2026-01-22 15:07:56</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>🌟 2026-01-22 GitHub Python 热点项目精选(12个)</h2><blockquote>每日同步 GitHub Trending 趋势，筛选优质 Python 项目，助力开发者快速把握技术风向标～</blockquote><hr/><h3>📋 项目列表（按 Star 数排序）</h3><h4>1. <a href="https://link.segmentfault.com/?enc=dk453IY0z0VEaX093J6IRA%3D%3D.KDoi3%2BprwNf59nwA5hfx3jhUQhKEVaTlJR6KVXjhq0GEPo8XOSTFp8v%2BUej6upBg" rel="nofollow" target="_blank">xai-org/grok-1</a></h4><blockquote>这是一个由 xai-org 开发的项目，可能与人工智能的可解释性（XAI）相关。从项目名称来看，它可能是某种模型或工具，用于帮助理解复杂模型的行为或数据的底层结构。</blockquote><table><thead><tr><th>指标</th><th>详情</th></tr></thead><tbody><tr><td>Star 数</td><td>🌟 51045（今日+141）</td></tr><tr><td>Fork 数</td><td>🔄 8433</td></tr><tr><td>开发语言</td><td>🐍 Python</td></tr><tr><td>项目地址</td><td><a href="https://link.segmentfault.com/?enc=ygXp5%2Byf7KrTSV6hA3ohgA%3D%3D.XvMM7%2BhRtBy1%2BbmUlPxA7G9nzVY1UvNtdoryYeO%2BkaOz8m9XTu9ExzT6i6mRW%2FYJ" rel="nofollow" target="_blank">https://github.com/xai-org/grok-1</a></td></tr></tbody></table><hr/><h4>2. <a href="https://link.segmentfault.com/?enc=UEY%2F4Kq%2FH%2F9wgcXXOrBCGg%3D%3D.Dv8CY%2FE1SXn0nv1sLI0hvFB2P%2F16aNaqzI1N72Ji4iYGfjdAP5TMHExqWcMkddcW" rel="nofollow" target="_blank">microsoft/agent-lightning</a></h4><blockquote>微软开发的项目，从名称上看，可能与轻量级代理或快速响应的代理系统有关。它可能用于优化网络通信、提高代理服务的效率或构建低延迟的代理架构。</blockquote><table><thead><tr><th>指标</th><th>详情</th></tr></thead><tbody><tr><td>Star 数</td><td>🌟 11286（今日+527）</td></tr><tr><td>Fork 数</td><td>🔄 924</td></tr><tr><td>开发语言</td><td>🐍 Python</td></tr><tr><td>项目地址</td><td><a href="https://link.segmentfault.com/?enc=Cp6kGl1UfRWndDm9JvidAA%3D%3D.0s%2BRVCjuOgJidcU1Yf5XOP80xAWDE%2FyeYf3QxH8AS2oSmHkXJTexa12aRnsPYXs6" rel="nofollow" target="_blank">https://github.com/microsoft/agent-lightning</a></td></tr></tbody></table><hr/><h4>3. <a href="https://link.segmentfault.com/?enc=xehlwBuTFWjlwNv28qORrQ%3D%3D.3hiIEplAQeFAGgQeIA61ChpKIN1tLDBCg8bT7NpgL9Y4SZQUi6%2FNEAzRltfXYqaG" rel="nofollow" target="_blank">VectifyAI/PageIndex</a></h4><blockquote>VectifyAI 开发的项目，可能与数据索引或搜索技术有关。它可能用于构建高效的索引系统，以便快速检索和处理大量数据，适用于人工智能和机器学习场景。</blockquote><table><thead><tr><th>指标</th><th>详情</th></tr></thead><tbody><tr><td>Star 数</td><td>🌟 6220（今日+100）</td></tr><tr><td>Fork 数</td><td>🔄 493</td></tr><tr><td>开发语言</td><td>🐍 Python</td></tr><tr><td>项目地址</td><td><a href="https://link.segmentfault.com/?enc=huMkmyVLGtmCUwhneoDgLA%3D%3D.NCmCaKy1DbKoag%2Bc4z2HOClougW8xFrBba7CqBsCAMCZRFwM7l2ne5AVHTF7R06X" rel="nofollow" target="_blank">https://github.com/VectifyAI/PageIndex</a></td></tr></tbody></table><hr/><h4>4. <a href="https://link.segmentfault.com/?enc=Ety41EcrspBZFg%2FlwLB5jQ%3D%3D.pa37N%2FjbHX4Ye1p%2Bqm2J%2BZZTnloN3aZBVo0qo%2B0yy8JVfWkKylJYEV1%2BhClLmX0k" rel="nofollow" target="_blank">ahujasid/blender-mcp</a></h4><blockquote>这个项目可能是与 Blender（一个流行的开源 3D 建模和动画软件）相关的一个插件或工具。它可能用于增强 Blender 的功能，例如自动化建模流程或提供新的材质处理方式。</blockquote><table><thead><tr><th>指标</th><th>详情</th></tr></thead><tbody><tr><td>Star 数</td><td>🌟 16246（今日+97）</td></tr><tr><td>Fork 数</td><td>🔄 1542</td></tr><tr><td>开发语言</td><td>🐍 Python</td></tr><tr><td>项目地址</td><td><a href="https://link.segmentfault.com/?enc=d0El6wo%2BbEyod%2F4AJQraVA%3D%3D.jTMo%2FghvWn05ehYwvNQPujlRIAZKOMCpsxf25wlDOUuPUYzRqLFhnZHviOd7%2FLaG" rel="nofollow" target="_blank">https://github.com/ahujasid/blender-mcp</a></td></tr></tbody></table><hr/><h4>5. <a href="https://link.segmentfault.com/?enc=Xg9xwUBNGsTltGtvSmS%2FjA%3D%3D.BuiOg0Xa3GfFLruuYqR5Q%2B0ntT5xbRPsDeKJgdoT%2Fi50Lkc4ETXe%2BQY5DhROxmBJ" rel="nofollow" target="_blank">PaddlePaddle/PaddleOCR</a></h4><blockquote>PaddleOCR 是由百度开源的 PaddlePaddle 框架下的光学字符识别（OCR）工具。它支持多种语言的文本检测和识别，具有高精度和高效率的特点，广泛应用于文档处理、图像识别等领域。</blockquote><table><thead><tr><th>指标</th><th>详情</th></tr></thead><tbody><tr><td>Star 数</td><td>🌟 68576（今日+142）</td></tr><tr><td>Fork 数</td><td>🔄 9682</td></tr><tr><td>开发语言</td><td>🐍 Python</td></tr><tr><td>项目地址</td><td><a href="https://link.segmentfault.com/?enc=gzfEwg9zSt%2FCGif8ndsZ2g%3D%3D.Sh%2BadED9QrvVwBCrGiIgCWosPWHGCUTcRmcv53cmB4fCpCcWmtZNXJXBNSZ1I6mZ" rel="nofollow" target="_blank">https://github.com/PaddlePaddle/PaddleOCR</a></td></tr></tbody></table><hr/><h4>6. <a href="https://link.segmentfault.com/?enc=0aTnv1le4TE%2FF2QmNYOasA%3D%3D.m9LRXSgi5H2jB0aQeeT9f7pAlO0QSco3fGJ1Hn2eZCCCoQJ6AxaRIihXTmDHNCNd" rel="nofollow" target="_blank">datawhalechina/all-in-rag</a></h4><blockquote>DatawhaleChina 开发的项目，可能与检索增强生成（RAG）技术有关。它可能用于构建更智能的问答系统或文本生成工具，通过结合检索和生成模型来提高输出质量和相关性。</blockquote><table><thead><tr><th>指标</th><th>详情</th></tr></thead><tbody><tr><td>Star 数</td><td>🌟 3275（今日+36）</td></tr><tr><td>Fork 数</td><td>🔄 1533</td></tr><tr><td>开发语言</td><td>🐍 Python</td></tr><tr><td>项目地址</td><td><a href="https://link.segmentfault.com/?enc=zYdl5r9B%2B5ysXdnTSWnzRw%3D%3D.csuGfSseSArbO43JAOUBkwR8Fc50ACFb17i52QrwPT%2BzeUy3BRUw0jBoy5BNcJBO" rel="nofollow" target="_blank">https://github.com/datawhalechina/all-in-rag</a></td></tr></tbody></table><hr/><h4>7. <a href="https://link.segmentfault.com/?enc=aOQlc5m9OqXiHoRRjdw%2FwQ%3D%3D.6eFRfgwL%2BOOMGWJ%2F3y3Vsh9NidBW4pzK5ejCrQaZBJ3nEBl0KR5PuoFlZUoH08s6" rel="nofollow" target="_blank">pytorch/executorch</a></h4><blockquote>PyTorch 开发的项目，可能与模型部署和执行优化有关。它可能用于将 PyTorch 模型高效地部署到各种设备上，提高模型的运行速度和资源利用率。</blockquote><table><thead><tr><th>指标</th><th>详情</th></tr></thead><tbody><tr><td>Star 数</td><td>🌟 4172（今日+7）</td></tr><tr><td>Fork 数</td><td>🔄 806</td></tr><tr><td>开发语言</td><td>🐍 Python</td></tr><tr><td>项目地址</td><td><a href="https://link.segmentfault.com/?enc=eVM3az8qJZ29fPcgtfQNZw%3D%3D.EjGL7B4dxdaH1bhbbJJ3UvsaYgmhZ5uv786TZU4BjcnlkDmugrwtXCR29R6IKFdA" rel="nofollow" target="_blank">https://github.com/pytorch/executorch</a></td></tr></tbody></table><hr/><h4>8. <a href="https://link.segmentfault.com/?enc=oCSMx8yiBMoqi7fbVtd%2F9A%3D%3D.MoLYFsUHxng8%2FsysgYnHkPY3ETMiQkmQ1UXiVJor7n%2Bm1hyfC4yMfZf0T0oXq0IY" rel="nofollow" target="_blank">lzhoang2801/OpCore-Simplify</a></h4><blockquote>这个项目可能是某种操作核心（OpCore）的简化版本或优化工具。它可能用于简化复杂的操作流程或优化代码性能，适用于特定的计算任务或框架。</blockquote><table><thead><tr><th>指标</th><th>详情</th></tr></thead><tbody><tr><td>Star 数</td><td>🌟 4702（今日+32）</td></tr><tr><td>Fork 数</td><td>🔄 461</td></tr><tr><td>开发语言</td><td>🐍 Python</td></tr><tr><td>项目地址</td><td><a href="https://link.segmentfault.com/?enc=rqvRm5zFAjQpvaEa%2BDhW7A%3D%3D.LX1ILGtq6dF8wS04OEI%2B7%2BfgJOKAbdYze7d7taQ7lEqXloJsg1btEUVl7r7GHyc1" rel="nofollow" target="_blank">https://github.com/lzhoang2801/OpCore-Simplify</a></td></tr></tbody></table><hr/><h4>9. <a href="https://link.segmentfault.com/?enc=xetubbOfNKgofdfLfKMCfA%3D%3D.O%2BBGZITGQ8e40BZn3FnfN3ZOiFxSvWxh%2Fi8yPZzlNjtMemwlNw%2Fa%2BG%2BF3mybuA76" rel="nofollow" target="_blank">karpathy/nanochat</a></h4><blockquote>由 Andrej Karpathy 开发的项目，可能是一个轻量级的聊天机器人或对话系统。它可能用于研究自然语言处理中的对话生成技术，具有简单的架构和易于扩展的特点。</blockquote><table><thead><tr><th>指标</th><th>详情</th></tr></thead><tbody><tr><td>Star 数</td><td>🌟 40618（今日+42）</td></tr><tr><td>Fork 数</td><td>🔄 5257</td></tr><tr><td>开发语言</td><td>🐍 Python</td></tr><tr><td>项目地址</td><td><a href="https://link.segmentfault.com/?enc=%2F9fTolwJ8y8ND71OVcxw8w%3D%3D.6klsyKOaHa7r5PnHTI8%2FXH2wU0%2BVIGx22zjCh1j69up32vSlJAUC7dvWcnzMhqt0" rel="nofollow" target="_blank">https://github.com/karpathy/nanochat</a></td></tr></tbody></table><hr/><h4>10. <a href="https://link.segmentfault.com/?enc=1773Hr40u2d49B0v%2FsMKLg%3D%3D.B8NodLBtfxQi%2FBakKj2IxquLY%2B3TDw2iSsNoxjpv1jHYiMMzJ1fmequf5F9s0Hes" rel="nofollow" target="_blank">vllm-project/vllm</a></h4><blockquote>VLLM 项目，可能与大规模语言模型的优化和部署有关。它可能提供了一种高效的方式来管理和运行大型语言模型，适用于需要高性能计算的自然语言处理任务。</blockquote><table><thead><tr><th>指标</th><th>详情</th></tr></thead><tbody><tr><td>Star 数</td><td>🌟 68081（今日+101）</td></tr><tr><td>Fork 数</td><td>🔄 12770</td></tr><tr><td>开发语言</td><td>🐍 Python</td></tr><tr><td>项目地址</td><td><a href="https://link.segmentfault.com/?enc=79YAeupGRhPzbFQSVjtI7Q%3D%3D.Ao7%2F1gjjUE%2FhgrFOiWW6LAgp6vFyga0wf%2BrOik7fs65isaiq9KO2sWJxutC%2FOC9b" rel="nofollow" target="_blank">https://github.com/vllm-project/vllm</a></td></tr></tbody></table><hr/><h4>11. <a href="https://link.segmentfault.com/?enc=%2BxUJPGHLUGxB0ZAR6w5eBw%3D%3D.5RuH3%2F4leT8Y0XnRiO39iNKWSHNlQ7cQvajrefydPkkwkjAKX1v9vz2JW3MqJlKJ" rel="nofollow" target="_blank">yichuan-w/LEANN</a></h4><blockquote>这个项目可能是某种学习算法或框架的实现。它可能用于研究新的机器学习方法或优化现有算法，适用于数据科学和人工智能领域的研究。</blockquote><table><thead><tr><th>指标</th><th>详情</th></tr></thead><tbody><tr><td>Star 数</td><td>🌟 9545（今日+45）</td></tr><tr><td>Fork 数</td><td>🔄 822</td></tr><tr><td>开发语言</td><td>🐍 Python</td></tr><tr><td>项目地址</td><td><a href="https://link.segmentfault.com/?enc=Oh5P2QpEsUYQ0wqXTWduRQ%3D%3D.sYtOIR90IQXFmfYcfkLKKiwneC%2FfPXNt4mZ%2BYcaeqDHkmclrd6SoCYx9fL%2Bz6kF5" rel="nofollow" target="_blank">https://github.com/yichuan-w/LEANN</a></td></tr></tbody></table><hr/><h4>12. <a href="https://link.segmentfault.com/?enc=grAQ98BFNtGOLwK8E6WSqA%3D%3D.aXEikkc7GT8yLCAuW3B2JJmrPfDnTdIf6te%2FHwGihdXOUsw6QZyBUcu8eGdI8wVo" rel="nofollow" target="_blank">KellerJordan/modded-nanogpt</a></h4><blockquote>这是一个对 Nanogpt 进行修改或扩展的项目。它可能在原始的 Nanogpt 基础上增加了新的功能或优化了性能，适用于自然语言处理和生成任务。</blockquote><table><thead><tr><th>指标</th><th>详情</th></tr></thead><tbody><tr><td>Star 数</td><td>🌟 4223（今日+16）</td></tr><tr><td>Fork 数</td><td>🔄 564</td></tr><tr><td>开发语言</td><td>🐍 Python</td></tr><tr><td>项目地址</td><td><a href="https://link.segmentfault.com/?enc=25nCOz9Rxmn91ttVdv5LWA%3D%3D.z0RZLsCByqdujjOqP0iN2oTOOCDQujFXGzALyrZhjiYK4200a5me%2FDRWMzEDn5vc" rel="nofollow" target="_blank">https://github.com/KellerJordan/modded-nanogpt</a></td></tr></tbody></table><hr/><h3>📝 说明</h3><ul><li>数据来源：GitHub Trending（2026-01-22 每日榜单）</li><li>筛选条件：Python 语言 + 当日热门项目</li><li>自动更新：每日同步最新趋势，建议收藏本文持续关注～</li></ul><h3>⭐ 推荐理由</h3><ol><li>热门项目代表当前技术趋势，学习价值高</li><li>优质项目代码规范，可作为学习参考</li><li>部分项目可直接用于实际开发，提高效率</li></ol>]]></description></item><item>    <title><![CDATA[金融资管实战：WhaleStudio 助力某亚洲投资基金构建跨云 Lakehouse 统一数据中枢 ]]></title>    <link>https://segmentfault.com/a/1190000047558429</link>    <guid>https://segmentfault.com/a/1190000047558429</guid>    <pubDate>2026-01-22 15:07:15</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558431" alt="" title=""/></p><h2>案例背景</h2><p>作为亚洲领先的投资基金，某东南亚投资基金公司（以下简称 A 基金）正处于从传统数仓向企业级数据中台转型的关键期。目前，其核心业务系统深植于 AWS 环境，涵盖了 SQL Server、MySQL 及 S3 等多种存储形态，并已初步建成基于 MSK（Kafka）与 Flink 的实时处理链路。为了应对日益增长的业务需求，A 基金规划引入 <strong>Databricks Lakehouse</strong> 作为统一的数据底座。</p><p>然而，随着任务规模预估跨越式增长，多云环境导致的“碎片化”问题愈发凸显。跨云任务协同困难、多套调度体系割裂、缺乏 CI/CD 机制以及 Databricks 作业无法深度纳管等挑战，使得平台运维成本激增，资源弹性难以支撑业务峰值。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558432" alt="e6984589-71da-4116-8f19-e47ad63b2d2b" title="e6984589-71da-4116-8f19-e47ad63b2d2b" loading="lazy"/></p><h2>核心挑战</h2><p>具体来说，A 基金在推动企业级数仓与数据中台建设的过程中 遇到的核心挑战来源于多方面：</p><ul><li><strong>多云环境共存导致协同困难</strong>： 存量系统在 AWS，新系统与 Lakehouse 规划落在 Databricks（跨云可部署），跨云数据传输与资源调度缺乏统一协同机制。</li><li><strong>数据工具多样、调度体系割裂</strong>： 内部存在多套同步与调度方案，缺少统一编排、统一运维监控与统一告警体系。</li><li><strong>缺乏 CI/CD 机制</strong>： 任务上线、变更依赖人工导入导出，版本控制、审计与回滚能力不完善。</li><li><strong>资源弹性不足</strong>： 高峰期任务堆积、低峰期资源闲置，扩缩容响应不及时，影响整体 SLA。</li><li><strong>Databricks 作业体系纳管不足</strong>： Databricks Jobs/Notebook/Workflow 与现有调度体系割裂，容易形成“第二套平台”，进一步加剧治理碎片化。</li><li><strong>Lakehouse 建设需求增强</strong>： 需要支持批/实时数据统一落地到 Lakehouse，支持 Schema 演进、版本治理与表格式演进策略，避免口径漂移与数据孤岛。</li><li><strong>运维噪声与体验问题</strong>： 任务状态多、告警多、定位慢；Dashboard 缺少时间记忆与常用筛选保持，影响日常运营效率。</li></ul><h2>WhaleStudio + Databricks 统一湖仓方案</h2><p>针对上述挑战，A 基金采用 <strong>WhaleStudio 商业版</strong> 作为统一的数据集成与调度中枢，深度纳管 AWS 与 Databricks 作业体系。通过“批处理+CDC”双引擎及实时链路（MSK+Flink）统一编排，打破多云割裂，消除治理孤岛。结合 CI/CD 自动化交付与动态扩缩容架构，在支撑万级任务扩展的同时，实现 Lakehouse 的标准化治理与智能运维，确保金融级数据的高可靠与强一致性。</p><p>具体来说，WhaleStudio 商业版作为核心的数据集成与调度中枢，通过以下四大核心模块，实现了从数据接入到运维治理的全流程自动化，将 Databricks Lakehouse 深度整合进企业的统一治理闭环：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558433" alt="cb49a6e2-44ac-4ac0-bc6d-4a99cdca86f9" title="cb49a6e2-44ac-4ac0-bc6d-4a99cdca86f9" loading="lazy"/></p><h3>1. 统一编排中枢：跨云协同与 Databricks 深度纳管</h3><p>该方案通过构建统一的任务中心与元数据仓库，整合了原本分散的集成与调度工具，实现跨系统的集中管理与审计。它不仅能够统一编排 AWS 生态下的原生任务，更实现了对 <strong>Databricks Jobs / Notebook / Workflow</strong> 的深度对接。通过建立跨云任务的统一依赖、统一调度与统一监控体系，有效避免了 Databricks 沦为孤立的“第二套平台”，确保了多云环境下业务协同的连贯性。</p><h3>2. 批流一体架构：双引擎接入与实时链路治理</h3><p>为了满足金融资管对数据时效性的多样化需求，平台提供 <strong>“批处理 + CDC”</strong> 双引擎接入能力，全面覆盖 SQL Server、MySQL 及 S3 等多源数据的采集与同步。同时，方案将 Kafka (MSK) 与 Flink 实时流任务深度纳入统一工作流编排，形成了离线分层落地与实时链路供给并行的治理模式。这种“批流一致”的体系，确保了实时与离线任务在调度逻辑、监控视图及告警机制上的高度统一。</p><h3>3. 规范化湖仓落地：Lakehouse 演进与自动化交付</h3><p>在数据落地阶段，方案优先支撑产出统一汇聚至 <strong>Databricks Lakehouse</strong>，构建起从 ODS、DWD 到 DWA 的标准化分层体系。平台兼容 Delta 与 Iceberg 等主流表格式策略，并提供 Schema 演进与版本治理能力，防止口径漂移。此外，通过引入 <strong>CaC（配置即代码）与 CI/CD 标准化流水线</strong>，实现了配置版本化、变更审计与灰度发布，将传统的人工操作转化为自动化的持续交付，极大降低了上线风险。</p><h3>4. 智能化运维体系：告警降噪与交互体验优化</h3><p>针对大规模任务环境下的运维压力，方案提供了智能化的监控解决方案。通过多级告警聚合与降噪技术，配合失败/告警过滤视图，运维人员能从海量信息中快速锁定核心问题。同时，系统对 Dashboard 进行了人性化改良，支持时间记忆与筛选状态保持，大幅提升了异常定位的速度与日常运营的整体效率。</p><h2>方案对比：从多工具拼装到一体化中枢</h2><p>在 A 基金最初的架构设计中，多工具拼装的“烟囱式”结构虽然在短期内解决了业务上线快的问题，但随着任务规模向万级跨越，这种模式带来的协同成本和运维压力已成为技术债。</p><p>WhaleStudio 方案的核心价值在于“打破割裂”，它不是在原有的工具堆栈上多打一个补丁，而是通过<strong>统一的编排大脑和标准化的交付流水线，将 Databricks 从一个孤立的计算引擎，彻底转变为企业全局数据治理闭环中的一部分</strong>。这种转变不仅是为了解决当前的运维噪声，更是为了在跨云环境下，为后续 Lakehouse 的长期演进提供一个稳固的工程化底座。</p><p>通过下图和表格，我们可以直观地看到架构重塑前后的差异：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558434" alt="129d92dc-237e-48b1-95e1-4cb9f0881471" title="129d92dc-237e-48b1-95e1-4cb9f0881471" loading="lazy"/></p><table><thead><tr><th>维度</th><th>原方案：多工具拼装</th><th>推荐方案：WhaleStudio + Databricks Lakehouse</th></tr></thead><tbody><tr><td><strong>典型形态</strong></td><td>SQL Server/MySQL/S3/Blob →（多套同步工具+多套调度系统）→ Kafka/MSK（实时）+ Flink（流计算）→ Databricks/数仓落地（各自管理）→ 数据质量/告警/审计分散</td><td>数据源（AWS SQL Server/MySQL/S3/Blob/Kafka）→ WhaleStudio（统一集成+统一编排+统一治理）→ 实时链路（MSK/Flink）与湖仓链路（Databricks Lakehouse）闭环</td></tr><tr><td><strong>优点</strong></td><td>选型灵活，局部上线快；单点需求可用最熟悉工具解决；短期推进速度较快。</td><td>更少组件、更强一体化；Databricks 统一纳管；跨云统一视图与资源调度；CI/CD 标准化交付；分布式弹性扩缩容；Lakehouse 可演进。</td></tr><tr><td><strong>缺点</strong></td><td>链路割裂，跨系统定位成本高；跨云难统一，协同效率低；缺少 CI/CD 导致上线风险高；资源不弹性，SLA 不稳定；Databricks 纳管不足。</td><td><strong>（实施建议）：</strong> 建议分阶段落地：先统一集成与编排中枢，再逐步深化 CI/CD、Lakehouse 治理与智能运维能力，以确保风险可控。</td></tr></tbody></table><h2>业务价值与收益：从效率跃迁到治理升级</h2><p>总结起来，通过引入 WhaleStudio 平台，A 基金成功实现了从“多工具拼装”向“一体化治理”的架构跨越，其核心收益主要体现在以下三个维度：</p><p><strong>首先，在管理架构上实现了全链路闭环与深度纳管。</strong><br/>平台将集成、编排、监控、告警与审计高度整合，彻底终结了系统割裂带来的重复维护。最显著的变化在于，Databricks 的作业体系与数据落地被完整纳入统一调度，使其不再是游离于主体系之外的“第二套平台”，实现了真正的跨云而不割裂。</p><p><strong>其次，在交付能力与资源利用率上达成了双重突破。</strong><br/>在工程化方面，标准化的流水线交付取代了低效的人工导入导出，配合审计与一键回滚机制，让业务变更既快又稳。在性能方面，分布式架构配合动态扩缩容，有效缓解了金融业务在峰值期的任务堆积，在确保 SLA 稳定的同时，大幅减少了低峰期的资源浪费。</p><p><strong>最后，在运维体验与长期演进中建立了坚实底座。</strong><br/>针对金融级治理需求，Schema 演进与版本控制能力显著降低了口径漂移风险，保障了 Lakehouse 的长期健康演进。而在日常运营中，告警降噪、过滤视图与时间记忆等智能化功能，将运维人员从干扰信号中解放出来，实现了异常问题的精准定位与快速响应。</p><p>归结起来，在多云与多工具并存的背景下，A 基金选择以 WhaleStudio 商业版作为统一的数据集成与调度中枢，将 AWS 上的批处理/CDC 与实时链路（MSK + Flink）以及 Databricks Lakehouse 的作业与数据落地纳入同一套编排、交付与运维治理体系。通过分布式架构与跨云统一编排，其能在任务规模从数百向数千增长的过程中保持 SLA 稳定，并以 CI/CD、告警降噪与 Lakehouse 治理能力，为基金业务提供更安全、更可追溯、更易演进的数据底座。</p>]]></description></item><item>    <title><![CDATA[CRM软件推荐：全球6款企业必备工具 晨曦钥匙扣 ]]></title>    <link>https://segmentfault.com/a/1190000047558472</link>    <guid>https://segmentfault.com/a/1190000047558472</guid>    <pubDate>2026-01-22 15:06:35</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>全流程一体化能力横评：6大CRM/ERP工具的「线索-回款」闭环之战</h2><p>在数字化转型中，<strong>「客户线索-销售报价-库存查询-订单履约-回款对账」的全流程一体化</strong>已成为企业降本增效的核心需求——零散的工具集成不仅会导致数据割裂，更会增加运营成本（据Gartner统计，企业因工具集成不畅导致的效率损失可达20%）。</p><p>本文将围绕<strong>5大核心维度</strong>，对<strong>超兔一体云、Salesforce、SugarCRM、Freshsales、金蝶云星辰、管家婆</strong>的一体化能力展开深度对比，结合<strong>功能细节、行业适配性、原生 vs 集成成本</strong>三大视角，为企业选择提供参考。</p><h3>一、核心维度与评估指标定义</h3><p>先明确每个维度的<strong>关键评估指标</strong>（均为企业实际场景中的痛点）：</p><table><thead><tr><th>维度</th><th>关键评估指标</th></tr></thead><tbody><tr><td>客户线索跟踪</td><td>渠道整合能力、AI驱动的线索培育、定制化灵活性、合规性</td></tr><tr><td>销售报价生成</td><td>模板化效率、自动化规则（如定价/库存校验）、审批流程、状态跟踪</td></tr><tr><td>库存实时查询</td><td>原生功能覆盖、多仓支持、智能预警、与销售/采购的联动</td></tr><tr><td>订单履约</td><td>业财联动深度、流程自动化（如采购/生产对接）、跨境/多场景适配</td></tr><tr><td>回款对账一体化</td><td>应收触发自动化、回款跟踪与提醒、对账自动化、业财数据一致性</td></tr></tbody></table><h3>二、6大工具核心能力横评</h3><h4>（一）客户线索跟踪：从「获客」到「转化」的效率之战</h4><p>客户线索是业务的起点，<strong>渠道整合深度</strong>与<strong>AI驱动的精准培育</strong>是核心竞争力。</p><table><thead><tr><th>工具</th><th>渠道整合</th><th>AI能力</th><th>定制化/合规性</th><th>核心优势场景</th></tr></thead><tbody><tr><td><strong>超兔一体云</strong></td><td>原生支持百度/抖音/微信/工商搜客等10+渠道，自动抓取表单数据</td><td>线索自动分配（手机号/IP归属地）、生命周期管理（客池分类：需求培养→成功）</td><td>支持线索字段自定义，无合规风险</td><td>需全渠道线索统一管理的商贸/制造企业</td></tr><tr><td><strong>Salesforce</strong></td><td>全渠道整合（邮件/社交/线下），需配置Einstein Connector</td><td>Einstein AI分析客户行为（如浏览轨迹），推送个性化内容，线索评分预测转化</td><td>生态丰富，但定制需懂Apex语言</td><td>大型跨国企业，需AI驱动精准营销</td></tr><tr><td><strong>SugarCRM</strong></td><td>支持API对接多渠道，需二次开发</td><td>无原生AI，依赖第三方插件</td><td>代码级定制（适合金融/医药合规）</td><td>对数据隐私/流程合规要求高的行业</td></tr><tr><td><strong>Freshsales</strong></td><td>整合电话/邮件/社交，自动补全客户信息</td><td>AI线索评分（基于互动频率）、预测分析</td><td>模板化配置，灵活度一般</td><td>侧重线索快速跟进的SaaS/互联网企业</td></tr><tr><td><strong>金蝶云星辰</strong></td><td>支持客户分层，结合AI模型驱动精准营销（如美妆复购率提升27%）</td><td>AI客户画像分析，推荐营销活动</td><td>适合零售/电商的客户分层管理</td><td>成长型企业，需从线索到复购的闭环</td></tr><tr><td><strong>管家婆</strong></td><td>内置客户档案，记录需求/服务历史</td><td>无原生AI，依赖人工跟进</td><td>适合中小微企业（如家政/维修）</td><td>服务行业，需记录客户历史偏好</td></tr></tbody></table><h5>关键结论：</h5><ul><li>超兔的<strong>原生多渠道整合</strong>无需额外配置，是中小微企业的「省心之选」；</li><li>Salesforce的<strong>Einstein AI</strong>是大型企业的「精准营销利器」；</li><li>SugarCRM的<strong>代码级定制</strong>适合金融/医药等强合规行业。</li></ul><h4>（二）销售报价生成：从「精准」到「高效」的平衡</h4><p>销售报价的核心是「准确」（库存/定价）<strong>与</strong>「快速」（模板+审批）。</p><table><thead><tr><th>工具</th><th>模板化能力</th><th>自动化规则</th><th>审批与状态跟踪</th><th>核心优势场景</th></tr></thead><tbody><tr><td><strong>超兔一体云</strong></td><td>支持个性化模板（按产品/客户类型），可自定义字段/计算方式</td><td>针对询价客户，发起报价，可自动生成报价单</td><td>支持多级审批，记录审批历史</td><td>需精准报价的生产/商贸企业</td></tr><tr><td><strong>Salesforce</strong></td><td>内置CPQ（配置-定价-报价）工具，自动化生成报价单</td><td>基于产品规则（如捆绑销售）、客户合同定价</td><td>与Sales Cloud联动，状态实时更新</td><td>需复杂定价规则的大型企业（如软件）</td></tr><tr><td><strong>Freshsales</strong></td><td>模板化报价，支持一键发送邮件</td><td>无库存校验，需集成ERP</td><td>跟踪报价打开/点击状态</td><td>侧重报价快速触达的中小企业</td></tr><tr><td><strong>金蝶云星辰</strong></td><td>多端移动办公，切换客户时价格自动更新（客户等级差异化定价）</td><td>支持批量报价，自动关联客户档案</td><td>报价与财务联动，精准度高</td><td>零售/电商，需客户分层定价</td></tr><tr><td><strong>管家婆</strong></td><td>15种行业模板（便利店/微商），快速配置</td><td>自定义报价规则（如折扣）</td><td>无审批流程，适合简单场景</td><td>小微企业，需快速生成报价</td></tr></tbody></table><h5>关键结论：</h5><ul><li>超兔的订单价格校验、出库校验，确保业务顺利执行；</li><li>Salesforce的<strong>CPQ功能</strong>适合复杂产品组合（如软件license+服务）；</li><li>金蝶的<strong>客户等级定价</strong>是零售/电商的「差异化竞争工具」。</li></ul><h4>（三）库存实时查询：从「报价」到「发货」的准确性保障</h4><p>库存是销售的「底气」，<strong>原生功能覆盖</strong>与<strong>实时联动</strong>是避免「超卖/缺货」的关键。</p><table><thead><tr><th>工具</th><th>原生功能</th><th>多仓支持</th><th>智能预警与联动</th><th>核心优势场景</th></tr></thead><tbody><tr><td><strong>超兔一体云</strong></td><td>原生进销存模块，支持多价格策略/成本算法</td><td>多仓管理，实时同步库存数量/位置</td><td>库存上下限预警，自动生成采购计划</td><td>需多仓联动的生产/商贸企业</td></tr><tr><td><strong>Salesforce</strong></td><td>无原生库存，需集成ERP（如SAP）</td><td>依赖ERP的多仓能力</td><td>无原生预警，需ERP配置</td><td>大型企业，已有成熟ERP系统</td></tr><tr><td><strong>Freshsales</strong></td><td>无原生库存，需集成Google Workspace/ERP</td><td>无</td><td>无</td><td>无需库存管理的轻量级销售团队</td></tr><tr><td><strong>金蝶云星辰</strong></td><td>原生进销存模块，采购/销售/库存全链路同步</td><td>多仓管理，支持跨仓调拨</td><td>智能库存预警（避免缺货/积压）</td><td>成长型零售/电商，需进销存联动</td></tr><tr><td><strong>管家婆</strong></td><td>原生多仓管理，支持离线操作（数据实时同步）</td><td>多仓/多计量单位管理</td><td>保质期预警，库存数量预警</td><td>小微企业（如便利店），需简单库存</td></tr></tbody></table><h5>关键结论：</h5><ul><li>超兔的<strong>原生库存+智能采购</strong>是「库存-销售」联动的「最优解」；</li><li>金蝶的<strong>进销存全链路同步</strong>适合成长型企业；</li><li>Salesforce/Freshsales需额外集成ERP，成本高。</li></ul><h4>（四）订单履约：从「下单」到「交付」的流程自动化</h4><p>订单履约的核心是「业财联动」<strong>与</strong>「流程标准化」，避免「订单漏处理」或「财务对账难」。</p><table><thead><tr><th>工具</th><th>业财联动</th><th>流程自动化</th><th>跨境/特殊场景</th><th>核心优势场景</th></tr></thead><tbody><tr><td><strong>超兔一体云</strong></td><td>原生业财架构，订单生成后自动触发应收/财务凭证</td><td>订单工作流（锁库→采购→生产→物流）、生产对接MES系统</td><td>通过客户信用管控来实现跨境订单风控（减少坏账）</td><td>生产制造企业，需从订单到生产的闭环</td></tr><tr><td><strong>Salesforce</strong></td><td>需集成FinancialForce等财务工具</td><td>订单流程自动化（如审批→发货），需配置Flow</td><td>支持跨国订单，但需集成物流工具</td><td>大型企业，已有财务系统集成</td></tr><tr><td><strong>金蝶云星辰</strong></td><td>业财一体化，订单处理效率提升3倍（自动生成凭证）</td><td>自动匹配采购需求，跨境订单风控</td><td>支持跨境电商，减少坏账损失</td><td>零售/跨境电商，需业财快速联动</td></tr><tr><td><strong>管家婆</strong></td><td>进销存数据自动生成财务报表</td><td>流程标准化（如采购→入库→销售）</td><td>适合中小微企业，快速部署</td><td>便利店/微商，需简单订单流程</td></tr></tbody></table><h5>关键结论：</h5><ul><li>超兔的<strong>原生业财联动+生产对接</strong>是制造企业的「刚需」；</li><li>金蝶的<strong>业财自动凭证</strong>是零售/电商的「效率利器」；</li><li>Salesforce需集成财务系统，适合已有IT架构的企业。</li></ul><h4>（五）回款对账一体化：从「应收」到「结算」的风险控制</h4><p>回款是企业的「现金流生命线」，<strong>应收自动化</strong>与<strong>对账一致性</strong>是核心。</p><table><thead><tr><th>工具</th><th>应收触发</th><th>回款跟踪</th><th>对账自动化</th><th>核心优势场景</th></tr></thead><tbody><tr><td><strong>超兔一体云</strong></td><td>签约/开票/发货自动触发应收，支持一票对多单/一笔对多单</td><td>账期管理、客户信用度控制（规避发货风险）、逾期提醒</td><td>自动匹配应收/回款，生成对账报告</td><td>需严格控制账期的制造/商贸企业</td></tr><tr><td><strong>Salesforce</strong></td><td>需集成财务工具（如QuickBooks）</td><td>回款跟踪（需手动录入），无自动提醒</td><td>需手动匹配应收/回款</td><td>大型企业，已有财务系统</td></tr><tr><td><strong>金蝶云星辰</strong></td><td>业务数据自动生成财务凭证，票/税/档一体</td><td>回款状态实时追踪，缩短对账周期</td><td>自动生成对账报告，支持批量结算</td><td>零售/电商，需票税一体化</td></tr><tr><td><strong>管家婆</strong></td><td>进销存数据自动生成应收，支持简单账期管理</td><td>手动录入回款，生成回款报表</td><td>自动匹配应收/回款，简单对账</td><td>小微企业，需快速对账</td></tr></tbody></table><h5>关键结论：</h5><ul><li>超兔的<strong>应收自动触发+信用控制</strong>是「风险规避」的核心；</li><li>金蝶的<strong>票税档一体</strong>适合需合规报税的企业；</li><li>管家婆的<strong>简单对账</strong>适合中小微企业。</li></ul><h3>三、一体化能力总结：从「零散工具」到「原生闭环」的选择逻辑</h3><h4>（一）一体化流程对比：超兔的「原生闭环」vs 其他工具的「集成依赖」</h4><p>超兔一体云的<strong>原生一体化流程</strong>：</p><p><img referrerpolicy="no-referrer" src="https://p0-xtjj-private.juejin.cn/tos-cn-i-73owjymdk6/73f8632e418647eab6ae807ccd735d04~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5pmo5pumNjA5NQ==:q75.awebp?policy=eyJ2bSI6MywidWlkIjoiMjc5MDM0MzA3NjM3ODUifQ%3D%3D&amp;rk3s=e9ecf3d6&amp;x-orig-authkey=f32326d3454f2ac7e96d3d06cdbb035152127018&amp;x-orig-expires=1769150570&amp;x-orig-sign=pfeqjknEhKsfxwc%2FkomkNaasK7U%3D" alt="" title=""/></p><p>其他工具（如Salesforce）的<strong>集成依赖流程</strong>：</p><p><img referrerpolicy="no-referrer" src="https://p0-xtjj-private.juejin.cn/tos-cn-i-73owjymdk6/3700e61944564cc3a5772a862965cf62~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5pmo5pumNjA5NQ==:q75.awebp?policy=eyJ2bSI6MywidWlkIjoiMjc5MDM0MzA3NjM3ODUifQ%3D%3D&amp;rk3s=e9ecf3d6&amp;x-orig-authkey=f32326d3454f2ac7e96d3d06cdbb035152127018&amp;x-orig-expires=1769150570&amp;x-orig-sign=kzO680sMtUx7MvYjvJ4%2FrIhLIpM%3D" alt="" title="" loading="lazy"/></p><h3>四、适用场景推荐</h3><table><thead><tr><th>企业类型/需求</th><th>推荐工具</th><th>核心原因</th></tr></thead><tbody><tr><td>中小微企业，需全流程闭环</td><td><strong>超兔一体云</strong></td><td>原生一体化，无需集成，成本低</td></tr><tr><td>大型跨国企业，需AI与生态</td><td><strong>Salesforce</strong></td><td>Einstein AI+丰富生态，适合全球化</td></tr><tr><td>成长型零售/电商，需业财融合</td><td><strong>金蝶云星辰</strong></td><td>业财自动凭证+票税一体，效率高</td></tr><tr><td>小微企业（如便利店/微商）</td><td><strong>管家婆</strong></td><td>功能实用，快速部署，成本低</td></tr><tr><td>金融/医药，需合规定制</td><td><strong>SugarCRM</strong></td><td>代码级定制，符合数据隐私要求</td></tr><tr><td>SaaS/互联网，需线索快速跟进</td><td><strong>Freshsales</strong></td><td>AI线索评分+多渠道互动，效率高</td></tr></tbody></table><h3>五、结论：一体化的本质是「数据打通」与「流程自动化」</h3><p>从6大工具的对比来看，<strong>原生一体化</strong>（如超兔、金蝶）是中小微企业的「最优解」——无需投入集成成本，就能实现从线索到回款的全流程数据打通；而大型企业（如Salesforce）则需根据已有IT架构选择「生态整合」方案。</p><p>最终，企业选择工具的核心逻辑是：<strong>以业务流程为中心，优先选择「原生覆盖核心环节」的工具</strong>，避免「为了集成而集成」的无效投入。</p><p>超兔一体云作为「原生一体化」的代表，其核心优势在于<strong>将「线索-报价-库存-订单-回款」的每一步都设计为「数据自动流动」</strong>，真正实现了「业务驱动数据，数据反哺业务」的闭环。这也是其能帮助企业<strong>降低30%运营成本、提升25%回款效率</strong>的关键。</p>]]></description></item><item>    <title><![CDATA[筑业云资料 “流水段视图” 功能：资料管理的高效秘籍 聪明的拐杖 ]]></title>    <link>https://segmentfault.com/a/1190000047558477</link>    <guid>https://segmentfault.com/a/1190000047558477</guid>    <pubDate>2026-01-22 15:05:48</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在工程资料管理工作中，众多用户渴望有一个功能，能集中查看所有已创建部位，并清晰知晓各部位所创建的表格，以便于统一查看与汇总管理。筑业云资料的 “流水段视图” 功能恰好满足了这一需求，成为资料管理的得力助手。<br/>以流水段为维度的便捷整合<br/>“流水段视图” 功能以施工流水段为维度，将同一部位的所有表格巧妙列在一起。这种整合方式极大地方便了资料的查看、复制、编辑及管理。例如在大型建筑项目中，不同楼层的相同部位可能存在相似的资料表格，通过该功能，可快速定位并查看这些部位及其相关表格，无需在海量资料中逐一查找，节省大量时间与精力。<br/>清晰多样的操作流程<br/>功能入口与展示：在软件工具栏找到并点击 “流水段视图” 功能入口，进入后，所有单位工程下的所有表格会以目录树的形式清晰展示。这种直观的展示方式，让用户对整个工程资料架构一目了然。<br/>新建操作：右键点击可进行多种新建操作，如新建单位工程、新建表格、新建文件夹等。新建文件夹功能尤为实用，例如创建 “楼层”“构件” 等文件夹，输入楼层名称如 “一层”，含一层的部位就会自动归到该文件夹中，无需手动移动，使资料分类更加有序。<br/>复制操作：当制作标准层资料时，复制功能尽显便捷。右键复制并输入如 “第二层”，即可快速建立标准层的表格。对于文件夹，同样可右键选择 “复制文件夹”，输入新名称如 “二层”，点击 “确定” 后，该部位下面的所有表格都会复制过来，且部位名称按新输入内容自动填充，大大减少重复建表工作。<br/>重命名与删除操作：右键 “重命名” 时，勾选相应选项可选择是否同步修改文件夹下所有表格的名称，确保资料一致性。而右键 “删除” 仅删除文件夹，文件夹里的表格会被移出，不会被删除，保障资料安全。<br/>显著提升资料管理效率<br/>“流水段视图” 功能通过 “创建一次，多次复制” 的智能化方式，将资料员从大量重复性建表工作中解放出来。它不仅规范了资料管理，使资料分类清晰、易于查找，还显著提升了做表效率。在工程项目周期紧张的情况下，高效的资料管理能为项目推进节省时间，确保各环节顺利进行。<br/>筑业云资料的 “流水段视图” 功能，以其独特的整合方式与丰富实用的操作，成为工程资料管理不可或缺的功能，助力资料员轻松应对复杂的资料管理任务，提升整体工作质量与效率。</p>]]></description></item><item>    <title><![CDATA[用自然语言玩转 AI 原生数据库 —— seekdb MCP Server 老纪的技术唠嗑局 ]]></title>    <link>https://segmentfault.com/a/1190000047558484</link>    <guid>https://segmentfault.com/a/1190000047558484</guid>    <pubDate>2026-01-22 15:04:49</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2><strong>引言</strong></h2><p>想象一下：你只需要用自然语言描述你的需求，AI 就能自动帮你完成数据库操作 —— 创建文档集合、插入数据、执行复杂查询，甚至构建一个完整的知识库应用。这不是未来，而是现在就能实现的能力。</p><p><strong>seekdb MCP Server</strong> 就是实现这一愿景的桥梁。它基于 Anthropic 提出的 <strong>MCP（Model Context Protocol）协议</strong>，让 AI 助手能够直接与 seekdb 数据库交互，将 "自然语言" 转化为 "数据库操作"。</p><p>本文将带你上手 seekdb MCP Server，并通过一个实战案例 —— <strong>通过自然语言构建 AI 应用</strong>，让你亲身体验 AI 原生数据库的魅力。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558486" alt="" title=""/></p><p>欢迎大家关注，在这里，我们会持续为大家更新与 #数据库、#AI 相关的技术内容！</p><h2><strong>什么是 seekdb MCP Server？</strong></h2><p><strong>seekdb</strong> 是一款 AI 原生搜索数据库，在统一架构下融合了关系数据、向量数据、全文索引、JSON 和 GIS 能力，支持混合检索和库内 AI 工作流。</p><p><strong>MCP Server</strong> 则是连接 AI 工具与数据库的"适配器"。通过 MCP 协议，Cursor、Claude Code、Cline 等 AI 工具可以直接访问和操作 seekdb 数据库。</p><h3><strong>核心能力一览</strong></h3><table><thead><tr><th align="left"><strong>能力分类</strong></th><th align="left"><strong>工具列表</strong></th><th align="left"><strong>功能说明</strong></th></tr></thead><tbody><tr><td align="left"><strong>向量集合管理</strong></td><td align="left"><code>create_collection</code>、<code>query_collection</code>、<code>add_data_to_collection</code> 等</td><td align="left">创建向量集合、语义搜索、文档管理</td></tr><tr><td align="left"><strong>高级搜索</strong></td><td align="left"><code>full_text_search</code>、<code>hybrid_search</code></td><td align="left">全文搜索、混合搜索（BM25 + 向量）</td></tr><tr><td align="left"><strong>AI 函数</strong></td><td align="left"><code>ai_complete</code>、<code>ai_rerank</code>、<code>create_ai_model</code> 等</td><td align="left">调用 LLM 生成文本、重排序搜索结果</td></tr><tr><td align="left"><strong>AI 记忆系统</strong></td><td align="left"><code>seekdb_memory_query</code>、<code>seekdb_memory_insert</code> 等</td><td align="left">跨会话持久化记忆，让 AI "记住"你</td></tr><tr><td align="left"><strong>数据导入导出</strong></td><td align="left"><code>import_csv_file_to_seekdb</code>、<code>export_csv_file_from_seekdb</code></td><td align="left">CSV 文件与数据库表/向量集合互转</td></tr></tbody></table><h2><strong>安装 seekdb 数据库</strong></h2><p>在使用 seekdb MCP Server 之前，你需要先准备好 seekdb 数据库。seekdb 提供两种部署模式：</p><h3><strong>模式一：嵌入式模式（零配置，仅限 Linux）</strong></h3><p><strong>嵌入式模式无需单独安装 seekdb 数据库</strong>！seekdb MCP Server 启动时会自动初始化一个本地嵌入式数据库，开箱即用。</p><p>适用场景：个人学习、快速原型开发、边缘设备运行。</p><p>⚠️ <strong>提示</strong>：<br/><strong>macOS 和 Windows 用户</strong>需要使用「客户端 / 服务器模式」，需要先部署 seekdb 数据库（推荐 Docker 方式），然后配置连接参数。</p><h3><strong>模式二：客户端/服务器模式（生产推荐）</strong></h3><p>如果你需要在测试或生产环境部署 seekdb，可以选择以下方式：</p><h5><strong>方式 1：使用 yum 安装（RPM 系统）</strong></h5><pre><code class="plain"># 1. 添加 seekdb 镜像源
sudo yum-config-manager --add-repo https://mirrors.aliyun.com/oceanbase/OceanBase.repo

# 2. 安装 seekdb 和客户端
sudo yum install seekdb obclient

# 3. 启动 seekdb
sudo systemctl start seekdb

# 4. 检查启动状态（状态为 "Service is ready" 表示启动成功）
sudo systemctl status seekdb

# 5. 连接测试
mysql -h127.0.0.1 -uroot -P2881 -A oceanbase</code></pre><h5><strong>方式 2：使用 Docker（最快捷）</strong></h5><pre><code class="plain"># 一行命令启动 seekdb
sudo docker run -d -p 2881:2881 oceanbase/seekdb

# 如果拉取失败，可使用备用镜像源：
# sudo docker run -d -p 2881:2881 quay.io/oceanbase/seekdb
# sudo docker run -d -p 2881:2881 ghcr.io/oceanbase/seekdb</code></pre><p><strong>系统要求</strong>：</p><ul><li>CPU：最低 1 核</li><li>内存：最低 2 GB 可用内存</li><li>支持的操作系统：CentOS 7/8、Ubuntu 20+、Debian 9+、Anolis OS 8、麒麟 V10 等</li></ul><p>更多部署方式请参考 <strong>seekdb 部署文档</strong><sup><strong>[1]</strong></sup>。</p><hr/><h2><strong>安装 seekdb MCP Server</strong></h2><h3><strong>安装 uv 包管理器</strong></h3><pre><code class="plain"># 安装 uv 包管理器
curl -LsSf https://astral.sh/uv/install.sh | sh</code></pre><h2><strong>配置 AI 工具连接</strong></h2><h3><strong>Stdio 模式</strong></h3><p>以 Cursor 为例在 Cursor 中，打开设置 → Tools &amp; MCP → New MCP Server，根据你的操作系统选择配置方式：</p><h4><strong>Linux 用户（嵌入式模式）</strong></h4><pre><code class="plain">{
  "mcpServers": {
    "seekdb": {
      "command": "uvx",
      "args": ["seekdb-mcp-server"]
    }
  }
}</code></pre><p>就这么简单！<strong>嵌入式模式无需任何配置</strong>，服务器启动时会自动初始化一个本地 seekdb 数据库。</p><h4><strong>macOS / Windows 用户（服务器模式）</strong></h4><p>macOS 和 Windows 不支持嵌入式模式，需要先部署 seekdb 数据库（推荐使用 Docker），然后配置连接参数：</p><pre><code class="plain">{
  "mcpServers": {
    "seekdb": {
      "command": "uvx",
      "args": ["seekdb-mcp-server"],
      "env": {
        "SEEKDB_HOST": "127.0.0.1",
        "SEEKDB_PORT": "2881",
        "SEEKDB_USER": "",
        "SEEKDB_PASSWORD": "",
        "SEEKDB_DATABASE": "test"
      }
    }
  }
}</code></pre><p><strong>参数说明</strong>：</p><table><thead><tr><th align="left"><strong>参数</strong></th><th align="left"><strong>说明</strong></th><th align="left"><strong>默认值</strong></th></tr></thead><tbody><tr><td align="left"><code>SEEKDB_HOST</code></td><td align="left">seekdb 服务器地址</td><td align="left"><code>127.0.0.1</code></td></tr><tr><td align="left"><code>SEEKDB_PORT</code></td><td align="left">seekdb 服务端口</td><td align="left"><code>2881</code></td></tr><tr><td align="left"><code>SEEKDB_USER</code></td><td align="left">数据库用户名</td><td align="left">无</td></tr><tr><td align="left"><code>SEEKDB_PASSWORD</code></td><td align="left">数据库密码</td><td align="left">无</td></tr><tr><td align="left"><code>SEEKDB_DATABASE</code></td><td align="left">数据库名称</td><td align="left">无</td></tr></tbody></table><h3><strong>SSE 模式</strong></h3><h4><strong>Linux 用户（嵌入式模式）</strong></h4><p>直接启动 SSE 服务器：</p><pre><code class="plain">uvx seekdb-mcp-server --transport sse --port 6000</code></pre><h4><strong>macOS / Windows 用户（服务器模式）</strong></h4><p>先配置环境变量，再启动服务器：</p><pre><code class="plain"># 配置 seekdb 连接信息
export SEEKDB_HOST=127.0.0.1
export SEEKDB_PORT=2881
export SEEKDB_USER=
export SEEKDB_PASSWORD=
export SEEKDB_DATABASE=test

# 启动 SSE 服务器
uvx seekdb-mcp-server --transport sse --port 6000</code></pre><p>然后在客户端配置：</p><pre><code class="plain">{
  "sse-seekdb": {
    "type": "sse",
    "url": "http://127.0.0.1:6000/sse"
  }
}</code></pre><h2><strong>实战案例：用 AI 对话构建个人笔记知识库</strong></h2><p>现在让我们通过一个完整的实战案例，体验 seekdb MCP Server 的强大能力。我们将构建一个<strong>个人笔记知识库</strong>，实现：</p><ul><li>✅ 用自然语言存储笔记</li><li>✅ 语义搜索相关内容</li><li>✅ 混合搜索精准定位</li><li>✅ AI 智能问答</li></ul><h3><strong>场景设定</strong></h3><p>假设你是一名技术工作者，平时会记录各种学习笔记、工作心得。现在你希望用 AI 帮你管理这些笔记，并能通过自然语言快速找到需要的内容。</p><h3><strong>第一步：创建笔记集合</strong></h3><p>在 AI 工具（如 Cursor）的对话框中输入：</p><pre><code class="plain">创建一个名为 "my_notes" 的知识库集合</code></pre><p><strong>AI 响应示例：</strong></p><p>我已成功创建名为 <strong>"my_notes"</strong> 的集合：</p><ul><li><strong>维度</strong>: 384（向量大小）</li><li><strong>距离度量</strong>: L2（欧几里得距离）</li></ul><p>就这样，一个支持语义搜索的向量集合就创建好了！</p><h3><strong>第二步：添加笔记内容</strong></h3><p>继续输入：</p><pre><code class="plain">向 my_notes 中添加以下笔记：

1. "seekdb 支持向量搜索和全文搜索的混合检索，可以同时利用关键词匹配和语义理解"
2. "MCP 协议是 Anthropic 在 2024 年 11 月提出的开源协议，让大模型可以与外部工具交互"
3. "Python 的 asyncio 模块提供了异步编程能力，适合 I/O 密集型任务"
4. "Docker 容器化技术可以实现应用的快速部署和环境隔离"
5. "RAG（检索增强生成）是目前最流行的 AI 应用架构，结合检索和生成能力"</code></pre><p><strong>AI 响应示例：</strong></p><p>完成！已成功向 <strong>"my_notes"</strong> 集合添加 5 条笔记：</p><table><thead><tr><th align="left"><strong>ID</strong></th><th align="left"><strong>内容</strong></th></tr></thead><tbody><tr><td align="left">doc1</td><td align="left">seekdb 支持向量搜索和全文搜索的混合检索...</td></tr><tr><td align="left">doc2</td><td align="left">MCP 协议是 Anthropic 在 2024 年 11 月提出的...</td></tr><tr><td align="left">doc3</td><td align="left">Python 的 asyncio 模块提供了异步编程能力...</td></tr><tr><td align="left">doc4</td><td align="left">Docker 容器化技术可以实现应用的快速部署...</td></tr><tr><td align="left">doc5</td><td align="left">RAG（检索增强生成）是目前最流行的 AI 应用架构...</td></tr></tbody></table><h3><strong>第三步：语义搜索</strong></h3><p>现在，让我们用自然语言搜索笔记：</p><pre><code class="plain">在 my_notes 中搜索与 "AI 应用开发" 相关的笔记</code></pre><p><strong>AI 响应示例：</strong></p><p>以下是与 <strong>"AI 应用开发"</strong> 相关的笔记，按相关性排序：</p><table><thead><tr><th align="left"><strong>排名</strong></th><th align="left"><strong>内容</strong></th><th align="left"><strong>相关度</strong></th></tr></thead><tbody><tr><td align="left">1</td><td align="left">RAG（检索增强生成）是目前最流行的 AI 应用架构...</td><td align="left">最高</td></tr><tr><td align="left">2</td><td align="left">MCP 协议是 Anthropic 在 2024 年 11 月提出的...</td><td align="left">高</td></tr><tr><td align="left">3</td><td align="left">seekdb 支持向量搜索和全文搜索的混合检索...</td><td align="left">中</td></tr></tbody></table><p>注意：我们搜索的是 "AI 应用开发"，但笔记中并没有这个确切的词。seekdb 的向量搜索能够理解<strong>语义相似性</strong>，自动找到相关内容！</p><h3><strong>第四步：混合搜索</strong></h3><p>混合搜索结合了<strong>关键词匹配</strong>和<strong>语义理解</strong>，效果更精准：</p><pre><code class="plain">对 my_notes 执行混合搜索：
- 全文关键词："Python"
- 语义查询："异步编程和并发处理"</code></pre><p><strong>AI 响应示例：</strong></p><table><thead><tr><th align="left"><strong>排名</strong></th><th align="left"><strong>内容</strong></th></tr></thead><tbody><tr><td align="left">1</td><td align="left">Python 的 asyncio 模块提供了异步编程能力，适合 I/O 密集型任务</td></tr><tr><td align="left">2</td><td align="left">Docker 容器化技术可以实现应用的快速部署和环境隔离</td></tr></tbody></table><p>混合搜索使用 <strong>RRF（倒数排名融合）</strong> 算法，综合关键词匹配（BM25）和向量相似度得分，排名结果更准确。</p><h3><strong>第五步：让 AI 记住你的偏好</strong></h3><p>seekdb MCP Server 还提供了 <strong>AI 记忆系统</strong>，让 AI 能够跨会话记住你的信息：</p><pre><code class="plain">记住我是一名 Python 开发者，主要使用 seekdb 做向量搜索应用</code></pre><p><strong>AI 响应示例：</strong></p><p>已记录！我会记住：</p><ul><li>你是一名 Python 开发者</li><li>主要使用 seekdb 做向量搜索应用</li></ul><p>下次对话时，你可以直接问：</p><pre><code class="plain">根据我的技术背景，推荐一些学习资源</code></pre><p>AI 会自动检索你的偏好，给出个性化推荐！</p><h2><strong>功能一览</strong></h2><h3><strong>向量集合管理</strong></h3><table><thead><tr><th align="left"><strong>工具</strong></th><th align="left"><strong>功能</strong></th></tr></thead><tbody><tr><td align="left"><code>create_collection</code></td><td align="left">创建向量集合</td></tr><tr><td align="left"><code>list_collections</code></td><td align="left">列出所有集合</td></tr><tr><td align="left"><code>has_collection</code></td><td align="left">检查集合是否存在</td></tr><tr><td align="left"><code>peek_collection</code></td><td align="left">预览集合中的文档</td></tr><tr><td align="left"><code>add_data_to_collection</code></td><td align="left">添加文档（自动生成向量）</td></tr><tr><td align="left"><code>update_collection</code></td><td align="left">更新文档</td></tr><tr><td align="left"><code>delete_documents</code></td><td align="left">删除文档</td></tr><tr><td align="left"><code>query_collection</code></td><td align="left">向量相似性搜索</td></tr><tr><td align="left"><code>delete_collection</code></td><td align="left">删除集合</td></tr></tbody></table><h3><strong>高级搜索</strong></h3><table><thead><tr><th align="left"><strong>工具</strong></th><th align="left"><strong>功能</strong></th></tr></thead><tbody><tr><td align="left"><code>full_text_search</code></td><td align="left">全文搜索（基于关键词）</td></tr><tr><td align="left"><code>hybrid_search</code></td><td align="left">混合搜索（结合全文和向量搜索）</td></tr></tbody></table><h3><strong>AI 模型工具</strong></h3><table><thead><tr><th align="left"><strong>工具</strong></th><th align="left"><strong>功能</strong></th></tr></thead><tbody><tr><td align="left"><code>create_ai_model</code></td><td align="left">注册 AI 模型（嵌入、文本生成或重排序）</td></tr><tr><td align="left"><code>create_ai_model_endpoint</code></td><td align="left">创建将模型连接到 API 服务的端点</td></tr><tr><td align="left"><code>drop_ai_model</code></td><td align="left">移除已注册的 AI 模型</td></tr><tr><td align="left"><code>drop_ai_model_endpoint</code></td><td align="left">移除 AI 模型端点</td></tr><tr><td align="left"><code>ai_complete</code></td><td align="left">调用 LLM 进行文本生成</td></tr><tr><td align="left"><code>ai_rerank</code></td><td align="left">使用 AI 模型按相关性重排文档</td></tr><tr><td align="left"><code>get_registered_ai_models</code></td><td align="left">列出所有已注册的 AI 模型</td></tr><tr><td align="left"><code>get_ai_model_endpoints</code></td><td align="left">列出所有 AI 模型端点</td></tr></tbody></table><h3><strong>AI 记忆系统</strong></h3><p>seekdb MCP Server 提供了强大的 AI 记忆功能，让 AI 助手能够跨会话记住信息：</p><table><thead><tr><th align="left"><strong>工具</strong></th><th align="left"><strong>功能</strong></th></tr></thead><tbody><tr><td align="left"><code>seekdb_memory_query</code></td><td align="left">语义搜索记忆</td></tr><tr><td align="left"><code>seekdb_memory_insert</code></td><td align="left">存储新记忆</td></tr><tr><td align="left"><code>seekdb_memory_update</code></td><td align="left">更新记忆</td></tr><tr><td align="left"><code>seekdb_memory_delete</code></td><td align="left">删除记忆</td></tr></tbody></table><p><strong>使用场景</strong>：</p><ul><li>AI 记住你的技术栈偏好（如 "我习惯使用 Python"）</li><li>AI 记住项目信息（如 "这个项目使用 FastAPI"）</li><li>AI 记住个人偏好（如 "我喜欢简洁的代码风格"）</li></ul><h3><strong>数据导入导出</strong></h3><table><thead><tr><th align="left"><strong>工具</strong></th><th align="left"><strong>功能</strong></th></tr></thead><tbody><tr><td align="left"><code>import_csv_file_to_seekdb</code></td><td align="left">导入 CSV 文件</td></tr><tr><td align="left"><code>export_csv_file_from_seekdb</code></td><td align="left">导出数据到 CSV</td></tr></tbody></table><h3><strong>SQL 操作</strong></h3><table><thead><tr><th align="left"><strong>工具</strong></th><th align="left"><strong>功能</strong></th></tr></thead><tbody><tr><td align="left"><code>execute_sql</code></td><td align="left">执行 SQL 查询</td></tr><tr><td align="left"><code>get_current_time</code></td><td align="left">获取数据库当前时间</td></tr></tbody></table><h2><strong>更多工具探索</strong></h2><p>除了本文介绍的功能，seekdb MCP Server 还支持：</p><ul><li><p>AI 函数调用</p><ul><li>使用 AI 模型分析这段文本的情感倾向："今天天气真好，心情愉悦！"</li></ul></li><li><p>CSV 数据导入</p><ul><li>将 /path/to/products.csv 导入为向量集合，使用第 2 列（产品描述）作为文档</li></ul></li></ul><h2><strong>常见问题</strong></h2><h4><strong>Q: 需要安装 seekdb 吗？</strong></h4><p><strong>A:</strong> 不需要！seekdb MCP Server 使用嵌入式模式，seekdb 已经包含在内，无需单独安装。</p><h4><strong>Q: 数据存储在哪里？</strong></h4><p><strong>A:</strong> 数据存储在本地文件系统中，默认在当前用户家目录下。你的数据完全在本地，不会上传到任何云端。</p><h4><strong>Q: 支持哪些操作系统？</strong></h4><p><strong>A:</strong> 目前支持 Linux（glibc &gt;= 2.28），支持 x86_64 和 aarch64 架构。</p><h4><strong>Q: 如何升级？</strong></h4><p><strong>A:</strong> 使用 <code>uvx</code> 时会自动使用最新版本。</p><h2><strong>总结</strong></h2><p><strong>seekdb MCP Server</strong> 让数据库操作变得前所未有的简单：</p><table><thead><tr><th align="left"><strong>传统方式</strong></th><th align="left"><strong>MCP 方式</strong></th></tr></thead><tbody><tr><td align="left">学习 SQL 语法</td><td align="left">用自然语言描述需求</td></tr><tr><td align="left">编写代码调用 API</td><td align="left">AI 自动执行操作</td></tr><tr><td align="left">手动管理向量嵌入</td><td align="left">自动生成和索引</td></tr><tr><td align="left">分别处理搜索逻辑</td><td align="left">一句话混合搜索</td></tr></tbody></table><p>无论你是想快速构建 RAG 应用，还是想让 AI 助手拥有"长期记忆"，seekdb MCP Server 都是你的最佳选择。</p><p><strong>开始你的 AI 原生数据库之旅吧！</strong> 🚀</p><hr/><p><strong>参考资料</strong></p><p>[1] seekdb 部署文档: <em><a href="https://link.segmentfault.com/?enc=CPVDFyVE2PCoemWFic0UkA%3D%3D.2xIJZGuFps2tkS1ywY%2B0HEO9Rr6p8Sm5calKrNV1PGFRUXfhnwNk93AN28eQzy%2B0" rel="nofollow" target="_blank">https://www.oceanbase.ai/docs/deploy-overview/</a></em></p>]]></description></item><item>    <title><![CDATA[2026AI 元年：智能体技术落地与产业应用变革白皮书 智能猫 ]]></title>    <link>https://segmentfault.com/a/1190000047558491</link>    <guid>https://segmentfault.com/a/1190000047558491</guid>    <pubDate>2026-01-22 15:03:58</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h3>摘要</h3><p>2026 年被定义为​<strong>AI 智能体技术规模化落地元年</strong>​，依托大模型技术的持续迭代、工具生态的完善以及行业场景的深度适配，智能体从技术概念走向商业落地，完成从 “文本生成工具” 到 “自主任务执行系统” 的核心转变。本文系统阐述 2026AI 元年的技术基础、产业特征、核心应用领域，分析智能体技术对生产生活、产业结构的重构价值，梳理技术落地的核心挑战与解决路径，为产业从业者、研究人员及普通用户提供全面的技术与应用参考框架。​<strong>关键词</strong>​：2026AI 元年；智能体；大模型；技术落地；产业变革；人机协同</p><h3>一、2026 成为 AI 智能体元年的核心技术与产业基础</h3><h4>1.1 大模型技术的成熟：智能体的核心能力底座</h4><p>2023-2025 年大模型完成从 “通用理解” 到 “逻辑推理 + 多模态交互” 的能力突破，为智能体落地奠定核心基础：</p><ol><li>​<strong>推理能力升级</strong>​：主流大模型（GPT-4o、文心一言 4.0、通义千问 3.0 等）的因果推理、步骤拆解能力较 2024 年提升 70% 以上，可完成复杂任务的层级化拆解，满足智能体 “规划” 环节的核心需求；</li><li>​<strong>多模态融合</strong>​：实现文本、图像、语音、视频、结构化数据的无缝交互，支持智能体在多场景下的 “感知” 能力，可对接不同类型的外部数据与工具；</li><li>​<strong>参数效率优化</strong>​：大模型实现 “大参数能力 + 小参数部署”，轻量化模型可在端侧运行，降低智能体的开发与使用成本，适配个人与中小企业场景。</li></ol><h4>1.2 智能体技术体系的完善：标准化闭环与工具生态</h4><p>智能体的 **“感知 - 规划 - 行动 - 反思”** 底层闭环实现标准化、模块化，成为技术落地的关键支撑：</p><ol><li>​<strong>核心模块标准化</strong>​：感知模块支持多渠道信息接入（用户指令、API 数据、本地文件），规划模块适配不同任务的拆解逻辑，行动模块对接通用工具接口，反思模块实现错误识别与自动修正，各模块可灵活组合适配场景；</li><li>​<strong>零代码 / 低代码工具普及</strong>​：Coze（扣子）、LangGraph、AutoGen 等工具完成产品化升级，提供可视化配置、现成插件与模板，降低智能体开发门槛，实现 “无编程基础也能搭建专属智能体”；</li><li>​<strong>工具生态互联互通</strong>​：智能体可对接 90% 以上的主流办公、生产、运营工具（Excel、ERP、设计软件、社交平台等），实现从 “数字世界执行” 到 “现实业务落地” 的衔接，打破技术应用的场景壁垒。</li></ol><h4>1.3 产业需求的爆发：从 “技术尝鲜” 到 “效率刚需”</h4><p>2025 年以来，各行业从 “AI 技术尝鲜” 转向 “降本增效刚需”，为智能体规模化落地提供产业土壤：</p><ol><li>​<strong>企业端</strong>​：中小企业对自动化、轻量化智能工具的需求激增，希望通过智能体替代基础重复性工作，降低人力成本；大型企业开始搭建专属智能体体系，实现产、供、销、服全流程的人机协同；</li><li>​<strong>个人端</strong>​：职场人、创作者、自由职业者等群体对个性化智能助手的需求提升，覆盖办公、学习、创作、生活等多场景，推动智能体向 “全民化” 发展；</li><li>​<strong>政策端</strong>​：多国出台 AI 产业扶持政策，明确智能体技术的发展方向与应用规范，保障技术落地的同时，规避数据安全、伦理风险等问题，为产业发展营造良好环境。</li></ol><h3>二、2026AI 智能体元年的核心产业特征</h3><h4>2.1 技术特征：从 “专用智能体” 到 “通用智能体 + 垂直适配”</h4><p>2026 年智能体技术呈现 “​<strong>通用能力打底，垂直场景深耕</strong>​” 的核心特征：</p><ol><li>​<strong>通用智能体</strong>​：具备跨场景的基础任务执行能力，可完成文档处理、数据整理、简单沟通、工具调用等通用工作，成为个人与企业的 “基础数字助手”；</li><li>​<strong>垂直智能体</strong>​：基于通用智能体进行行业微调与场景定制，适配特定行业的业务逻辑与需求，如工业生产智能体、电商运营智能体、医疗辅助智能体、教育答疑智能体等，具备行业专属的知识储备与任务执行能力；</li><li>​<strong>多智能体协同</strong>​：单智能体向 “智能体集群” 发展，通过角色分工、任务协作完成复杂产业任务，如电商行业的 “选品智能体 + 文案智能体 + 运营智能体 + 数据分析智能体” 协同，实现从产品上架到数据优化的全流程自动化。</li></ol><h4>2.2 应用特征：从 “线上内容生成” 到 “全场景业务执行”</h4><p>智能体突破此前 “仅能完成线上内容生成” 的局限，实现 **“线上 + 线下”“数字 + 实体”** 的全场景业务执行：</p><ol><li>​<strong>线上场景深度渗透</strong>​：覆盖办公自动化、内容创作、客户服务、数字营销等领域，完成从 “辅助生成” 到 “自主执行” 的转变，如智能体可自主完成市场调研、数据整理、报告生成、渠道发布的全流程；</li><li>​<strong>线下场景逐步落地</strong>​：依托物联网、工业互联网等技术，智能体可对接线下设备与生产流程，如工业制造中的智能体可实现设备监控、故障预警、生产调度，物流行业的智能体可完成路径规划、仓储管理、配送调度等。</li></ol><h4>2.3 产业特征：从 “技术驱动” 到 “需求驱动”，生态化发展</h4><p>2026 年 AI 产业从 “技术厂商主导的技术迭代” 转向 “产业端主导的需求落地”，形成 **“大模型厂商 + 智能体开发平台 + 场景应用方 + 工具生态方”** 的完整产业生态：</p><ol><li>​<strong>大模型厂商</strong>​：提供核心的基础模型能力，为智能体开发提供底层技术支撑，如 OpenAI、百度、阿里等；</li><li>​<strong>智能体开发平台</strong>​：提供零代码 / 低代码开发工具、标准化模块与插件生态，连接大模型技术与产业需求，如 Coze、LangGraph 等；</li><li>​<strong>场景应用方</strong>​：企业、机构及个人根据自身需求，在开发平台上搭建或定制智能体，实现技术落地；</li><li>​<strong>工具生态方</strong>​：各类办公、生产、运营工具厂商开放接口，与智能体开发平台对接，完善智能体的行动能力，形成产业协同。</li></ol><h3>三、2026 智能体技术的核心应用领域与落地案例</h3><h4>3.1 企业服务领域：办公自动化与人机协同办公体系构建</h4><p>智能体成为企业数字化转型的核心工具，实现办公全流程的自动化与高效化，核心应用包括：</p><ol><li>​<strong>行政办公智能体</strong>​：自主完成考勤统计、周报 / 月报生成、会议纪要整理、文件归档、邮件回复等基础行政工作，降低行政人员的重复性劳动；</li><li>​<strong>销售运营智能体</strong>​：对接企业 CRM 系统，完成客户线索筛选、客户咨询自动回复、销售数据统计分析、销售报表生成，辅助销售团队提升获客与转化效率；</li><li>​<strong>人力资源智能体</strong>​：完成简历筛选、初试邀约、员工考勤、薪酬核算、员工培训答疑等工作，优化 HR 工作流程，聚焦核心的人才招聘、员工发展等工作。  <br/>​<strong>落地案例</strong>​：某中小企业通过 Coze 搭建专属销售智能体，对接企业微信与 Excel，实现客户咨询 7×24 小时自动回复，销售数据每日自动统计并生成分析报告，销售团队的基础工作效率提升 65%，人力成本降低 30%。</li></ol><h4>3.2 产业制造领域：工业智能体赋能智能制造与生产优化</h4><p>智能体与工业互联网、物联网、大数据技术结合，赋能制造业从 “自动化生产” 到 “智能化生产” 的升级，核心应用包括：</p><ol><li>​<strong>生产调度智能体</strong>​：根据订单需求、设备状态、原材料库存，自主制定生产计划，实时调整生产调度，提升生产效率；</li><li>​<strong>设备运维智能体</strong>​：实时监控设备运行数据，识别设备故障前兆，自动发出预警并提供维修方案，降低设备停机率；</li><li>​<strong>质量检测智能体</strong>​：结合机器视觉技术，完成产品生产过程中的实时质量检测，识别不合格产品，分析质量问题原因并提出优化建议。  <br/>​<strong>落地案例</strong>​：某中小型机械制造企业引入工业智能体，对接生产车间的物联网设备，实现生产计划的自动制定与动态调整，设备故障预警准确率提升 80%，产品不良率降低 25%，生产效率提升 40%。</li></ol><h4>3.3 民生服务领域：智能体提升公共服务效率与个性化体验</h4><p>智能体在教育、医疗、政务、物流等民生服务领域落地，实现公共服务的高效化、个性化与普惠化，核心应用包括：</p><ol><li>​<strong>教育辅助智能体</strong>​：为学生提供个性化学习答疑、笔记整理、考点梳理、作业批改，为教师提供备课素材整理、教学进度规划、学生成绩分析，优化教与学的流程；</li><li>​<strong>医疗辅助智能体</strong>​：为基层医疗机构提供常见病诊断答疑、病历整理、药品咨询，为患者提供就医指引、预约挂号、术后康复指导，缓解优质医疗资源紧张问题；</li><li>​<strong>政务服务智能体</strong>​：实现政务咨询自动回复、政务办理流程指引、线上材料初审，推动 “政务服务一网通办”，提升政务服务效率，降低群众办事成本。  <br/>​<strong>落地案例</strong>​：某地方政务服务中心上线政务智能体，对接政务服务平台，实现社保、医保、户籍等高频政务问题的 7×24 小时自动回复，线上材料初审通过率提升 75%，窗口办理业务的平均时长缩短 60%，群众办事满意度提升 90%。</li></ol><h4>3.4 个人端应用：全民化智能体成为个人数字分身</h4><p>2026 年个人智能体实现全民化普及，成为覆盖<strong>办公、学习、创作、生活</strong>的个人数字分身，核心应用包括：</p><ol><li>​<strong>个人办公助手</strong>​：为职场人完成文档整理、会议纪要、任务提醒、邮件撰写等工作，提升个人办公效率；</li><li>​<strong>学习创作智能体</strong>​：为学生、创作者提供文献整理、内容创作初稿、素材收集、排版发布等服务，解放创作与学习的基础劳动；</li><li>​<strong>生活服务智能体</strong>​：完成日程规划、购物比价、出行规划、家庭账单整理等生活服务，提升个人生活的便捷性。</li></ol><h3>四、2026 智能体技术落地的核心挑战与解决路径</h3><h4>4.1 核心挑战</h4><ol><li>​<strong>技术层面</strong>​：部分复杂场景下的智能体仍存在​<strong>任务执行误差</strong>​，如复杂逻辑的拆解、多工具协同的衔接、错误识别与修正的精准度不足；端侧智能体的能力与云端存在差距，轻量化与高性能的平衡仍需突破；</li><li>​<strong>数据层面</strong>​：智能体的落地依赖高质量、场景化的数据，部分行业存在<strong>数据孤岛</strong>问题，企业内部数据与外部数据无法有效打通；数据安全与隐私保护成为核心痛点，智能体在数据读取、使用过程中存在数据泄露风险；</li><li>​<strong>产业层面</strong>​：部分传统行业对智能体技术的​<strong>认知与接受度不足</strong>​，缺乏专业的技术落地与运营人才，导致技术与产业需求无法有效匹配；智能体的行业定制化成本仍较高，中小企业的落地门槛有待进一步降低；</li><li>​<strong>伦理层面</strong>​：智能体的自主决策可能引发<strong>责任界定模糊</strong>问题，如智能体执行任务出现错误时，责任归属于开发平台、应用方还是用户；部分场景下的智能体应用可能引发就业结构调整，带来社会就业问题。</li></ol><h4>4.2 解决路径</h4><ol><li>​<strong>技术迭代</strong>​：持续优化大模型的推理与决策能力，完善智能体的 “反思” 模块，提升任务执行的精准度；加大端侧大模型与智能体的研发投入，实现轻量化与高性能的平衡；推动多智能体协同算法的优化，提升复杂任务的执行能力；</li><li>​<strong>数据治理</strong>​：建立行业数据共享机制，打破数据孤岛，为智能体落地提供高质量数据支撑；完善数据安全与隐私保护的技术与法规体系，采用数据加密、联邦学习等技术，保障数据在采集、使用、传输过程中的安全；明确智能体数据使用的边界与规范，禁止未经授权的数椐读取与使用；</li><li>​<strong>产业赋能</strong>​：加强智能体技术的行业普及与培训，培养兼具<strong>产业知识与 AI 工具能力</strong>的复合型人才；推动智能体开发平台的产品化与标准化，降低行业定制化成本，推出针对中小企业的轻量化智能体解决方案；鼓励大模型厂商、开发平台与行业龙头企业合作，打造行业标杆案例，推动技术的规模化落地；</li><li>​<strong>伦理与政策规范</strong>​：建立智能体技术的伦理准则与责任界定体系，明确开发平台、应用方、用户在智能体执行过程中的权利与责任；出台相关的就业扶持政策，针对智能体技术带来的就业结构调整，开展职业技能培训，推动劳动力向高价值、不可替代的岗位转型；建立智能体技术的监管体系，加强对技术应用的规范与引导，规避伦理风险。</li></ol><h3>五、2026AI 元年之后的智能体技术发展趋势</h3><h4>5.1 短期趋势（2026-2027 年）：垂直场景深度落地，全民化普及加速</h4><ol><li>智能体在电商、制造、政务、教育等行业实现深度落地，形成一批标准化、可复制的行业解决方案；</li><li>个人智能体的功能与场景进一步丰富，成为手机、电脑之外的 “标配数字工具”，全民化普及速度加快；</li><li>零代码 / 低代码智能体开发平台进一步完善，插件生态更加丰富，开发门槛进一步降低，实现 “人人皆可搭建智能体”。</li></ol><h4>5.2 中期趋势（2028-2030 年）：通用智能体成熟，人机协同成为生产生活标配</h4><ol><li>通用智能体技术实现成熟，具备跨行业、跨场景的自主决策与执行能力，可完成复杂的综合性任务；</li><li>人机协同成为生产、生活、办公的标配模式，人类专注于创意、决策、情感连接等高价值工作，智能体完成基础的执行与操作工作；</li><li>智能体与机器人、物联网、元宇宙等技术深度融合，实现从 “数字世界” 到 “物理世界” 的全面渗透，打造智能化的生产生活体系。</li></ol><h4>5.3 长期趋势（2030 年以后）：智能体向 “通用人工智能” 迈进，人机共生体系形成</h4><ol><li>智能体在技术层面逐步具备自主学习、自主进化的能力，向<strong>通用人工智能（AGI）</strong> 迈进，具备与人类相当的综合智能；</li><li>形成 “人机共生、相互赋能” 的全新体系，智能体不仅是人类的 “工具”，更是人类的 “协作伙伴”，共同推动社会生产力的提升；</li><li>智能体技术将重构产业结构、社会分工与生产生活方式，推动人类社会进入智能化发展的新阶段。</li></ol><h3>六、结论</h3><p>2026 年作为 AI 智能体元年，标志着 AI 技术从 “内容生成” 阶段进入 “自主任务执行” 阶段，完成了从技术概念到产业落地的核心跨越。依托大模型技术的成熟、智能体体系的完善与产业需求的爆发，智能体在企业服务、产业制造、民生服务、个人端等领域实现规模化落地，成为推动产业升级、提升生产效率、优化生活体验的核心力量。</p><p>同时，2026 年智能体技术的落地仍面临技术、数据、产业、伦理等多方面的挑战，需要技术厂商、产业从业者、政策制定者共同努力，通过技术迭代、数据治理、产业赋能、政策规范，推动智能体技术的健康、可持续发展。</p><p>未来，随着技术的持续迭代与产业的深度融合，智能体将逐步实现从 “垂直智能体” 到 “通用智能体” 的升级，人机协同将成为生产生活的标配，最终形成 “人机共生” 的全新发展体系。2026AI 元年不仅是智能体技术的落地起点，更是人类社会智能化发展的全新开端，技术的发展将始终围绕 “赋能人类、提升社会生产力” 的核心目标，推动人类社会向更高质量、更高效、更智能的方向发展。</p><h3>参考文献</h3><p>[1] 斯坦福大学. AI 指数报告 2026 [R]. 斯坦福大学人类与人工智能研究院，2026.[2] 麦肯锡咨询。智能体技术与产业变革白皮书 2026 [R]. 麦肯锡全球研究院，2026.[3] 中国人工智能产业发展联盟。中国智能体技术落地与应用规范指南 (2026 版)[S]. 2026.[4] OpenAI. GPT-4o 技术白皮书 [R]. OpenAI 官方技术团队，2026.[5] 腾讯云。智能体技术在企业服务领域的落地实践与趋势分析 [R]. 腾讯云 AI 研究院，2026.[6] Coze（扣子）. 零代码智能体开发与应用白皮书 2026 [R]. 字节跳动 AI 实验室，2026.</p>]]></description></item><item>    <title><![CDATA[实时云渲染平台如何接入摄像头与本地媒体数据 点量小耿 ]]></title>    <link>https://segmentfault.com/a/1190000047558493</link>    <guid>https://segmentfault.com/a/1190000047558493</guid>    <pubDate>2026-01-22 15:03:28</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>———以点量云流商用实时云渲染平台为例</p><ol><li>技术背景：从“渲染流畅”到“业务适配”的能力升级<br/>随着实时云渲染技术的日趋成熟，其应用场景已从单纯的三维模型轻量化展示，深度渗透到数字孪生、工业仿真、远程三维协作、在线教学培训等多元化业务领域。当前，行业对云渲染平台的核心需求已发生本质转变：不再局限于“依赖云端算力实时渲染复杂三维模型，实现终端轻量化交互操作”，更聚焦于“能否承载真实业务场景中的全流程沟通，实现虚拟场景与现实信息的无缝联动”。<br/>点量云流在对接大量政企、工业、教育类商用项目落地过程中发现，仅依靠三维模型的实时渲染与基础交互，远不足以支撑复杂的远程协作场景。例如，工业远程运维中，工程师需要同步查看设备三维仿真模型与现场摄像头拍摄的设备实际运行状态；三维项目协作会议中，参会者需结合本地文档、操作演示视频，对虚拟场景进行精准讨论；在线技能培训中，讲师需通过摄像头实时讲解，同步展示课件、实操视频与三维仿真操作流程。<br/>基于此，点量云流在现有实时云渲染架构的基础上，针对性引入摄像头与本地媒体数据接入能力，通过技术优化实现现实世界数据流与虚拟三维场景的无缝融合，有效补齐了传统云渲染平台在“全维度信息表达”“业务场景适配”层面的短板，进一步拓宽了实时云渲染技术的商用落地边界。<br/><img width="723" height="593" referrerpolicy="no-referrer" src="/img/bVdnIiy" alt="" title=""/></li><li>技术架构：四层协同，实现数据高效接入与融合呈现<br/>从技术实现逻辑来看，点量云流的摄像头与本地媒体数据接入能力，可拆解为“本地采集层—流媒体传输层—云端渲染融合层—Web三维呈现层”四个核心层级，各层级协同联动，既保证数据传输的低延迟、高稳定，又实现媒体内容与三维场景的自然融合，适配商用场景的严苛需求。<br/>2.1 本地数据采集与编码：多源适配，筑牢数据基础<br/>作为数据接入的源头，本地采集层的核心目标是实现多类型本地媒体数据的全面、高效采集，并通过标准化编码处理，为后续流媒体传输奠定基础。点量云流突破传统平台的采集局限，支持多种本地数据源的全覆盖采集，具体包括：<br/> 摄像头数据：支持电脑内置摄像头、高清工业摄像头等各类设备，可根据场景需求灵活调整采集分辨率、帧率，适配从日常沟通到工业监测的不同清晰度要求；<br/> 本地屏幕数据：支持全屏采集、指定区域采集、单个应用窗口采集，可精准捕捉桌面操作、软件演示等内容，适配项目演示、技能培训等场景；<br/> 各类课件与文件内容：兼容Flash课件、exe可执行课件、PPT、Word、PDF等多种格式文档，支持直接采集展示，无需额外格式转换，提升使用便捷性；<br/> 本地媒体文件：支持MP4等主流格式的本地视频文件，可实现文件的实时采集与流式播放，适配预录视频演示、案例讲解等场景。<br/> 针对采集到的多类型数据，平台会进行实时标准化编码处理，采用H.264/H.265高效编码算法，在保证画面清晰度的前提下，最大限度压缩数据体积，降低后续网络传输压力，同时支持编码参数动态调整，适配不同网络环境下的采集传输需求。<br/>2.2 流媒体化与协议支持：低延迟传输，适配多场景分发<br/>流媒体传输层是连接本地采集与云端融合的核心枢纽，其核心作用是将本地编码后的媒体数据，统一转化为标准流媒体格式，并通过适配商用场景的传输协议，实现数据的低延迟、高稳定推送，同时支持多用户并发访问与各类外部视频源对接。<br/>点量云流采用“统一流媒体化”处理逻辑，将采集编码后的摄像头画面、屏幕内容、课件、视频文件等各类数据，均转化为标准化流媒体流，确保后续云端融合与终端播放的兼容性。在传输协议方面，平台聚焦商用场景的核心需求，重点支持两大主流协议，实现多场景适配：<br/> RTSP协议：主打低延迟、强控制特性，传输延迟可控制在毫秒级，适合对实时性要求极高的场景，如工业设备实时监测、远程手术指导、实时互动演示等，可实现媒体数据的实时推送与精准控制；<br/> RTMP协议：生态成熟、兼容性强，支持多用户并发分发，可适配大规模用户同时访问的场景，如在线公开课、大型项目协作会议、多终端同步演示等，确保不同用户的访问体验一致。<br/>值得注意的是，点量云流的媒体接入能力并非局限于本地摄像头，还可实现与监控系统、网络摄像头等各类标准视频源的无缝对接，通过协议兼容，将外部视频数据同步接入三维场景，进一步拓展了业务适配范围，适配工业数字孪生、智慧监控等高端场景需求。<br/>2.3 云端渲染融合层：无缝联动，实现虚实融合<br/>云端渲染融合层是整个技术架构的核心，承担着“三维场景渲染”与“本地媒体数据融合”的双重职责，也是点量云流区别于传统云渲染平台的关键所在。平台通过自研的融合渲染算法，将流媒体传输层推送的本地媒体数据（摄像头画面、屏幕内容等），与云端渲染的三维场景进行实时无缝融合，实现以下核心效果：<br/> 媒体内容可灵活嵌入三维场景：支持将摄像头画面、本地视频、文档等内容，以悬浮窗口、内嵌模块等形式，嵌入三维场景的任意位置，不遮挡核心三维模型，实现自然呈现；<br/> 虚实数据实时联动：当三维场景进行旋转、缩放、漫游等操作时，嵌入的本地媒体内容可同步适配，保持画面同步性，确保用户在查看三维场景的同时，能实时获取本地媒体信息；<br/> 多源媒体内容协同展示：支持同时接入多路本地媒体数据（如摄像头+本地文档+屏幕演示）。<br/>2.4 Web端播放与访问：无插件适配，降低使用门槛<br/>Web三维呈现层作为面向用户的最终展示载体，核心目标是实现“便捷访问、跨端兼容”，降低用户使用门槛，适配企业多样化的访问场景。点量云流摒弃了传统平台需要安装专用客户端、插件才能播放媒体内容的模式，通过技术优化，实现媒体流与三维场景的Web端无插件直接播放。<br/>该层的核心优势的体现在三个方面：<br/> 一是无需安装任何插件、客户端，用户通过Chrome、Edge等主流浏览器，即可直接访问平台，查看融合了本地媒体数据的三维场景，大幅降低企业用户的部署与使用成本；<br/> 二是全面支持跨平台访问，兼容Windows、Mac等各类桌面操作系统，同时适配平板、手机等移动终端，用户可随时随地通过终端设备接入，满足远程协作、移动办公的需求；<br/> 三是灵活适配网络环境，无论是企业内网的封闭场景，还是公网的开放场景，均能实现稳定播放，通过网络自适应算法，动态调整播放参数，避免因网络波动导致的卡顿、黑屏，保障商用场景的流畅体验。</li><li>多人同步与分组控制：适配协作场景，提升业务效率<br/>在商用场景中，实时云渲染平台的核心应用之一是多人远程协作，而摄像头与本地媒体数据的接入，本质上是为了提升协作的高效性与精准性。为此，点量云流针对性打造了完善的多人同步与分组控制机制，将媒体数据接入能力与协作场景深度绑定，解决了多用户协作中“内容不同步、权限不清晰、场景切换繁琐”等痛点。其核心功能包括：<br/> 多用户实时同步订阅：同一路本地媒体数据（如主讲人的摄像头画面、演示文档），可支持多个用户同时订阅查看，所有用户看到的内容与主讲人实时同步，无延迟、无偏差，确保协作沟通的一致性，适配多人项目会议、在线培训等场景；<br/> 基于用户分组的内容隔离：支持根据业务需求，将用户划分为不同分组（如项目A组、项目B组、教学分组等），不同分组可接入不同的本地媒体数据，实现内容隔离，避免不同业务场景的内容干扰，同时保障数据安全，适配多项目并行、多班级教学等复杂场景；<br/> 动态切换：支持本地媒体内容的动态切换（如从摄像头画面切换为本地文档、从屏幕演示切换为视频文件），实现协作流程的顺畅衔接，提升沟通效率。<br/>这套同步与控制机制，为各类复杂协作场景提供了坚实的技术支撑，无论是企业的多项目分组协作、教育机构的分班在线教学，还是工业领域的多团队远程运维沟通，都能通过该机制实现高效协作，进一步发挥实时云渲染与本地媒体接入融合的价值。</li><li>技术价值总结：从“渲染引擎”到“综合型三维协作基础设施”的跨越<br/>实时云渲染平台接入摄像头与本地媒体数据，并非简单的功能叠加，而是对云渲染技术商用价值的深度挖掘与能力升级，从技术层面来看，这一能力的落地，具有三大核心价值，推动云渲染平台实现从“单一渲染工具”到“综合型三维协作基础设施”的跨越式发展。<br/>第一，搭建现实世界与三维空间的实时数据通道。传统云渲染平台仅能呈现虚拟三维场景，与现实世界存在明显的信息割裂；而摄像头与本地媒体数据的接入，打通了虚拟场景与现实世界的数据流壁垒，实现了现实信息与虚拟模型的实时联动，让三维场景不再是“孤立的虚拟载体”，而是能够承载现实业务信息的“综合展示窗口”，提升了平台的业务适配能力。<br/>第二，强化系统的整合与扩展能力。点量云流的媒体接入能力，支持多类型本地数据源、多标准传输协议、多终端访问场景的兼容适配，不仅可接入普通摄像头与本地文件，还能对接工业相机、监控系统等专业设备，实现与企业现有业务系统的无缝整合，无需对现有设备、系统进行大规模改造，降低企业数字化升级成本；同时，开放的接口设计，也为后续接入更多类型的媒体数据源、拓展更多协作功能提供了可能，具备极强的扩展性。<br/>第三，奠定高阶商用场景落地的技术基础。数字孪生、远程运维、三维协同设计、在线技能培训等高阶应用场景，均需要虚拟场景与现实信息的深度融合，而摄像头与本地媒体数据接入能力，正是支撑这些场景落地的核心技术支撑。例如，工业数字孪生中，通过接入现场摄像头与设备监控视频，可实现虚拟孪生模型与设备实际运行状态的实时对照，助力远程运维与故障排查；三维协同设计中，通过接入本地设计文档、操作演示视频，可实现多设计师的精准沟通，提升设计效率。<br/>综上，点量云流通过在实时云渲染平台中融入摄像头与本地媒体数据接入能力，不仅补齐了传统平台的能力短板，更推动云渲染技术从“专注渲染”向“赋能业务”转型，使其成为能够支撑多元化商用场景、承载全流程协作沟通的综合型三维协作基础设施，为各行业的数字化转型提供更加强劲的技术支撑。<br/><img width="723" height="593" referrerpolicy="no-referrer" src="/img/bVdnIiz" alt="" title="" loading="lazy"/></li></ol>]]></description></item><item>    <title><![CDATA[Microsoft AI Genius | 解锁 Agent-to-Agent 大规模协作新范式！ ]]></title>    <link>https://segmentfault.com/a/1190000047558516</link>    <guid>https://segmentfault.com/a/1190000047558516</guid>    <pubDate>2026-01-22 15:02:48</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>还在为复杂的智能体系统集成发愁？想让您的 AI 助手不仅聪明，还能像人类团队一样高效“组队打怪”？</p><p>当 AI 从“单体智能”走向“群体协作”，Agent-to-Agent（A2A）正在成为企业级 AI 系统的新底座。在微软 AI Genius 第二期课程中，我们将深入拆解：如何构建、编排并扩展可协作的多智能体系统，让智能体像团队一样分工协作、自动完成复杂任务。</p><p><img width="723" height="1301" referrerpolicy="no-referrer" src="/img/bVdnIiT" alt="dec304a8651bac1ac84ca08d76286981.png" title="dec304a8651bac1ac84ca08d76286981.png"/></p><p><strong>您将学到</strong></p><ul><li>使用 Microsoft Agent Framework 统一智能体，降低集成复杂度。</li><li>借助 SWE Agents 加速编码，实现快速原型开发。</li><li>利用 MCP 在编排过程中保护敏感数据，确保企业合规。</li></ul><p><strong>直播互动福利</strong></p><p>本期课程不仅有硬核技术拆解，更准备了有奖互动福利！观看直播课程，根据小助手指引参与直播互动，并加入技术交流群参与抽奖，即有机会获得 Microsoft AI Genius 定制好礼！</p><p>如果您正在关注企业级 Agent 架构、多智能体协作与自动化工作流、AI Coding Agent 与工程化落地。这一期课程，千万不要错过。</p><p>1 月 28 日 14:00 - 15:30，锁定 Microsoft AI Genius 第三季第二期直播，一起走进多智能体协作的下一站。</p>]]></description></item><item>    <title><![CDATA[DolphinScheduler 3.1.9 + Minio 开发环境【IDEA】搭建访问及相关问题]]></title>    <link>https://segmentfault.com/a/1190000047558525</link>    <guid>https://segmentfault.com/a/1190000047558525</guid>    <pubDate>2026-01-22 15:02:15</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558527" alt="Apache DolphinScheduler3.1.9+Minio 海报" title="Apache DolphinScheduler3.1.9+Minio 海报"/></p><h4>目录</h4><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558528" alt="" title="" loading="lazy"/></p><ul><li><p><a href="https://link.segmentfault.com/?enc=Tx8YT3lMS1LKYWU5PE2QmA%3D%3D.p6KaLCmxbw4VqXQKOIGr7yYXis6ix0bg6yRxLW%2B5oCZicwOlIFgCU6FAdRyl9%2F961rmDumCM9WbLbab4D98Ztw%3D%3D" rel="nofollow" target="_blank">DolphinScheduler 3.1.9 开发环境【IDEA】搭建访问</a></p><ul><li><p><a href="https://link.segmentfault.com/?enc=L0osZNcRH3xHZyWbS%2BRJUA%3D%3D.TWeenOXal40jI4DRTuce50N4yP%2FANw9ozpjddke%2FGgU%3D" rel="nofollow" target="_blank">前提</a></p><ul><li><a href="https://link.segmentfault.com/?enc=oswQYHEDiQFHhKYGB1XveA%3D%3D.HDKlAMWPurVHty9O8i8tbKAMcYr5o9aDQnrUxYFFOhY%3D" rel="nofollow" target="_blank">1、软件要求</a></li><li><a href="https://link.segmentfault.com/?enc=YtPtMpo9l%2FNLK%2BqBdlR%2BEQ%3D%3D.JLJTShR%2FZQ5nrHmZ8jLEGawq0J9cSoqP41sE9hcRm4U%3D" rel="nofollow" target="_blank">2、克隆代码库</a></li><li><a href="https://link.segmentfault.com/?enc=g3h8SXmWJouR7AhOi7c7Rg%3D%3D.zsd9nMRmZ3MvxITPLcWTbaAQgbZ%2BZG20CpCg0x2wwXc%3D" rel="nofollow" target="_blank">3、编译源码</a></li></ul></li><li><p><a href="https://link.segmentfault.com/?enc=0bGQil2Pplqmp7lcovuuIg%3D%3D.8Vg1Xd%2BAWTlLnmSAXr%2FfZwRpwCJy7%2FsFk%2F0mMZHGw0ctLMjuyihwq49TDlPZaDaj" rel="nofollow" target="_blank">DolphinScheduler 普通开发模式</a></p><ul><li><a href="https://link.segmentfault.com/?enc=szwE0vteV8%2BSvzIML9mWgw%3D%3D.EYQb4C5HR5qsmp7hqJCyp7Hz7SBTGsYsTOG%2BEcggb5M%3D" rel="nofollow" target="_blank">1、编译问题：</a></li><li><p><a href="https://link.segmentfault.com/?enc=aA8sef57ArFyqT75sF0X8g%3D%3D.MrNEleTR%2FSSx3lRCg2BxXhrpA9lEZjO%2F8w84BCCC0wtwq7LFp8VpGteKIQh0Zz1E" rel="nofollow" target="_blank">2、启动zookeeper</a></p><ul><li><a href="https://link.segmentfault.com/?enc=tWRXXupfn8T5x21uEzSz3Q%3D%3D.7vqMnwikfny9B96d100c5MO5tRdoY1aURyGpYRFizOo%3D" rel="nofollow" target="_blank">官方内容</a></li><li><a href="https://link.segmentfault.com/?enc=QS7i7CM3QoNstNvdSxlQVg%3D%3D.N5dqXodySFrTeFw%2FrjSh0L%2F7JW28KbgQsnXO3XDURw0%3D" rel="nofollow" target="_blank">存储配置</a></li><li><a href="https://link.segmentfault.com/?enc=Gu9DzzQto6qzAJvlwA1bUA%3D%3D.l5sjJcGaVtiatSdq7loXi6XLCKYclNU4rlmdkfcpq20%3D" rel="nofollow" target="_blank">启动脚本</a></li></ul></li><li><a href="https://link.segmentfault.com/?enc=GPyyOfXQOvDZ3QP4LLDl9Q%3D%3D.GKPj9E3hlgosAmdaJ2pRb4oR%2FkMJGa0cwotB%2BXudnK%2F%2Brx%2Bb4HlRaylVR%2Br42xxx" rel="nofollow" target="_blank">3、workspace.xml 修改</a></li><li><p><a href="https://link.segmentfault.com/?enc=K04pamIOTSUdB79KduT%2BkA%3D%3D.8wAqOsIPRdR8ltltuuusdh1b07rDJjPS7jpMPN1GkA0%3D" rel="nofollow" target="_blank">4、数据库</a></p><ul><li><a href="https://link.segmentfault.com/?enc=%2BOBroVnCsLc6Gtjev39Djw%3D%3D.xHK6aVyiHOMUSzVM8EJpVbD3Ep9adCYPphM1Guf0PBw%3D" rel="nofollow" target="_blank">4-1：数据初始化</a></li><li><a href="https://link.segmentfault.com/?enc=ydg%2BffaDq5wYRaA6AQKqsA%3D%3D.xE2TNMPZHcIoaC0NClbedQ9m%2FE5FKmLTFu7CcB4WZmQ%3D" rel="nofollow" target="_blank">4-2：依赖相关修改</a></li></ul></li><li><p><a href="https://link.segmentfault.com/?enc=N8CRImhXHyDFT1Xv65dBUg%3D%3D.4geiwwJs2ZZ74CyqHAht64D8I%2BTNVEDAszyqXpJc%2BjtgTg145ZDZyKVCp8yOSvsb" rel="nofollow" target="_blank">5、application.yaml 修改数据库配置</a></p><ul><li><a href="https://link.segmentfault.com/?enc=TkIkt4Iwa6KP87FfSiFOzQ%3D%3D.T8x0FSMTljsGp3OFuLKlKc5YLqOdDgfV9UVoBvbweoewLr74gZt0ET69eWQx%2FnsPmO3gcfVd6v06tXdBApb8IQ%3D%3D" rel="nofollow" target="_blank">5-1：dolphinscheduler-master</a></li><li><a href="https://link.segmentfault.com/?enc=2%2FRvjMBLZkvBB8Nl2JThIg%3D%3D.sqVcNMdEeJyUo%2FRYqhIHx4MmhhE0vEIXqkhhmCaTMf6wbZ59rtyn3zk18X91hkKfCYYJIyVGuyl1WJIhm0rkWA%3D%3D" rel="nofollow" target="_blank">5-2：dolphinscheduler-worker</a></li><li><a href="https://link.segmentfault.com/?enc=fWT3Vb0fk7PIw8sJxAZTmA%3D%3D.B28Ee%2Fsqq4%2Fcd0mCxLzc69j6Wa4upGsc0x8iNm3szkXNIKEd6B3Ed3J4b7OWIif9" rel="nofollow" target="_blank">5-3：dolphinscheduler-api</a></li></ul></li><li><p><a href="https://link.segmentfault.com/?enc=SXrSq6RMt41%2BHvldqrAHqg%3D%3D.UVjvBs%2FjsOgbHIqzecxJ3v8qfbTSXaqPvgqEG6VKLhTDE4CukWniM3o9XplPEnQB" rel="nofollow" target="_blank">6、logback-spring.xml 修改日志级别</a></p><ul><li><a href="https://link.segmentfault.com/?enc=EXOt3Zgei0GJj0W%2B4ROlrA%3D%3D.AwkuEbJbF2ng4bWNEKYUpkxVyY53WcrN83g7jIG1JcQPVvS0ZqYatBnzPnpBT0gWHei9e0mkpmDYRVF3tTYNRg%3D%3D" rel="nofollow" target="_blank">6-1：dolphinscheduler-master</a></li><li><a href="https://link.segmentfault.com/?enc=rR1qSQx2QKIkMNHeHR5s8Q%3D%3D.f7DlJInV6KpC6i7uWFKGCYmos9JGL9Eo7G5%2B9ov2cVwbQc9yzhFSY7J0BJ03yQL9e7%2FR2lVV2G21NLdxLhDg9A%3D%3D" rel="nofollow" target="_blank">6-2：dolphinscheduler-worker</a></li><li><a href="https://link.segmentfault.com/?enc=1HVfYSvvNlnR%2FHhQbCGtMA%3D%3D.lmHtjaYKdqktIqHhOAEBMYzQZYVd7JzZaiviGpr2nQRP4lQmv81A%2FpCTk2eCwtkQ" rel="nofollow" target="_blank">6-3：dolphinscheduler-api</a></li></ul></li><li><p><a href="https://link.segmentfault.com/?enc=juKgLTqSDar2LdOmPcn1pw%3D%3D.0bneUG1pxHFYwy1qt9T49cV5UwcS1qzN0ks6p30mYqo%3D" rel="nofollow" target="_blank">7、启动后端三个服务</a></p><ul><li><p><a href="https://link.segmentfault.com/?enc=u%2Bh20VKz1GNazQfKOM%2B54A%3D%3D.bDXL%2FH%2Fvqk8Fee6TI3%2Bgpn1ANoQiQkhTmErbRWsNntwSLeqfnMA%2FtZQ2%2BgsGv5gA" rel="nofollow" target="_blank">7-1：MasterServer</a></p><ul><li><a href="https://link.segmentfault.com/?enc=c9m9fXP8yaejHMXPlo1jUg%3D%3D.Arwtr1KQH8Nwm2Yzeo8zcaSLFkNItJxD%2FXVA0lrxKh%2BNKWfEZy6y%2FZUuS9Gsmr2M" rel="nofollow" target="_blank">配置 VM Options</a></li></ul></li><li><p><a href="https://link.segmentfault.com/?enc=iA8d72%2FrQePbn6STD9emRw%3D%3D.Dgls7LnLRgJMGYBLAIdE2VLWPui4R8xkxjWLwZ7z0okw6s%2B1Ot%2BuRPjRKurkMSw4" rel="nofollow" target="_blank">7-2：WorkerServer</a></p><ul><li><a href="https://link.segmentfault.com/?enc=8uRtVVmVLeQt5%2FGh3Nj4TQ%3D%3D.hcNss5qsdeZ%2FFWJ%2B1KWX3mZR8CBDzM2BorP1hEUFu8OZYwd4TbH0k0o%2FECLvY4pt" rel="nofollow" target="_blank">配置 VM Options</a></li></ul></li><li><p><a href="https://link.segmentfault.com/?enc=Tq6x8eoFUBXfB8%2BY1t09MA%3D%3D.RD9t%2BcPrv7U5fVN3cOuUCujkRzBk8zIZM1LDqiS93Q1rj2%2FmXyJc%2BuExEQ1PNDp7" rel="nofollow" target="_blank">7-3：ApiApplicationServer</a></p><ul><li><a href="https://link.segmentfault.com/?enc=Sw3h1LbXapbPD4jWEjjO%2Fg%3D%3D.pnoMx03UwO6bFy9AX3YJpDPVmdX89KPu7lbREUwyvkN4h5uuhEYv1bCTatLNk8ni" rel="nofollow" target="_blank">配置 VM Options</a></li></ul></li></ul></li><li><p><a href="https://link.segmentfault.com/?enc=ewoWsLI9Ti5Fq%2F54hYpXbw%3D%3D.emep7r1lV4OqHZIlardQVwgAJjIHLKKs8dyWOTSBVz4%3D" rel="nofollow" target="_blank">8、启动前端服务</a></p><ul><li><a href="https://link.segmentfault.com/?enc=hzN5v1%2Fh7McWE1%2BqffHw9w%3D%3D.hznRwk2u3qHmlj2cpXnyB0zMTHhmLmD0NOr8he3bPZE%3D" rel="nofollow" target="_blank">命令：</a></li></ul></li><li><p><a href="https://link.segmentfault.com/?enc=8h8JI%2BVYfgNZrZHgWNpaqA%3D%3D.aX79GSoD1TTAcvyPPZ%2BGAS%2BG3AKH6IokvFO4xW31Fko%3D" rel="nofollow" target="_blank">9、浏览器访问</a></p><ul><li><a href="https://link.segmentfault.com/?enc=RCqXOQjPtwQV3LRe9Ye57w%3D%3D.SuGA%2FULg6G7GjNBxGwHd1UoUfHIM2AUAdT%2FuUCXeP7k%3D" rel="nofollow" target="_blank">账号密码：</a></li><li><a href="https://link.segmentfault.com/?enc=4fv91exxgfkdB%2Fjkzm%2FWtA%3D%3D.IqbelfuKuN%2BbRO9tg0sViRqko47LkqiLdQMn9MF6TKI%3D" rel="nofollow" target="_blank">成功访问：</a></li></ul></li></ul></li><li><p><a href="https://link.segmentfault.com/?enc=yFPnMnjZqq25P5dRyf%2FZjg%3D%3D.TsvqjahSjn2tEAqy6omnUFs8DC7gsv8LV%2FmT%2F4UVI0I%3D" rel="nofollow" target="_blank">相关问题</a></p><ul><li><p><a href="https://link.segmentfault.com/?enc=ziGEQB7xDgRK1LOIuz%2BxAQ%3D%3D.%2Fljv%2ByyI2AkZ9%2FBvXumEQESV99eeli%2FkbondIh6fCI4%3D" rel="nofollow" target="_blank">1、存储未启用、租户\\用户 指定</a></p><ul><li><p><a href="https://link.segmentfault.com/?enc=D30MWsOXQKgF%2FWcY16s4aw%3D%3D.0nMkWFprOG%2FzCm5RXefDQUPATH3fitJoI3e1rzhVEUU%3D" rel="nofollow" target="_blank">解决方法：</a></p><ul><li><a href="https://link.segmentfault.com/?enc=tOteTQj0BHijqlYr6v0Vfw%3D%3D.mo6AHukV8sKc%2FDLM1%2B3hh%2FDZhLa8orUIqsJT6aEvKMgbMl%2BWoCn8wsQhAm2vwMgq7E%2B6GgwzO6Bo0H0dBU6Mgg%3D%3D" rel="nofollow" target="_blank">1、minio 创建 dolphinscheduler 桶</a></li><li><a href="https://link.segmentfault.com/?enc=cEsDiB8MK%2BZC0UPQ6whxjQ%3D%3D.jvWnw9B%2Fj5%2Bjeww2MALrRIlH39gd0X%2Bz9qqMtzABV3yZA0RBqPAakeDe52DPm8aX" rel="nofollow" target="_blank">2、commom.properties 修改</a></li><li><p><a href="https://link.segmentfault.com/?enc=BqhzF9kpDW1LmmwsBeweKg%3D%3D.goXo%2Btp3SYbgmIhZgREh5Q5c4p6mohlHjpop59KwY8Vexs4KjIqyoTBUMOjsiHQW" rel="nofollow" target="_blank">3、dolphinscheduler 可视化页面添加租户</a></p><ul><li><a href="https://link.segmentfault.com/?enc=gp5Cvs0hbgZU9KINwOVeVg%3D%3D.cO7AtsVuOQcEdvO9oMnx%2B4WIvpaKeJzryCucYeu4Qb0%3D" rel="nofollow" target="_blank">用户添加租户</a></li></ul></li></ul></li></ul></li></ul></li><li><p><a href="https://link.segmentfault.com/?enc=qOCr8J8ldfoSctq27ncP7A%3D%3D.WatAdGGH%2FOGORzKVkRAziZTKvfoKN8%2FyEGoCqRVDDZA%3D" rel="nofollow" target="_blank">演示</a></p><ul><li><a href="https://link.segmentfault.com/?enc=p71BIhY5JdTz7g67NqVVTw%3D%3D.H1y6%2FFNdLV4bK0pdKe9gP3pM9Gbmj9Wu2sONH9NEfv8%3D" rel="nofollow" target="_blank">创建文件夹、上传文件成功</a></li></ul></li></ul></li></ul><p>这里按照官方提供的文档进行操作：</p><h3>前提</h3><p>官方提供的开发手册位置</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558529" alt="" title="" loading="lazy"/></p><h4>1、软件要求</h4><p>在搭建 DolphinScheduler 开发环境之前请确保你已经安装以下软件:</p><ul><li><a href="https://link.segmentfault.com/?enc=S%2Bep%2FUONFESj0yANA%2Bzevw%3D%3D.vZB5E5UA%2FnX45J8n0cv91nQoMXoevyFKnkV4CVc4g60%3D" rel="nofollow" target="_blank">Git</a></li><li><a href="https://link.segmentfault.com/?enc=NCHX11A5pmFdJNKy2PyqKw%3D%3D.amAPZpRGlcdCjSKra5uMAULcXHT0RKalqLTqt3lNlspibJphIhMpefZYq5Ewpt51crAutXD%2Bf3jV1HWNIkHMTljjYAU4qYvhh25qWc%2FQflU%3D" rel="nofollow" target="_blank">JDK</a>: v1.8.x (当前暂不支持 jdk 11)</li><li><a href="https://link.segmentfault.com/?enc=AI8WzObH%2BqwjqNK0k6jHWQ%3D%3D.96awtZnFMlnSHK%2Fmy25yN6oLumKHOYuouh2iDwMWk4gfPWI%2B91I2obn%2BfCJPnrQO" rel="nofollow" target="_blank">Maven</a>: v3.5+</li><li><a href="https://link.segmentfault.com/?enc=%2FPSgb2iY0jBLIp6hJrokUA%3D%3D.9t8TPVF%2BV5xbwPny8H6ticNDMUAJ0IMBPro8qXBuNQs%3D" rel="nofollow" target="_blank">Node</a>: v16.13+ (dolphinScheduler 版本低于 3.0, 请安装 node v12.20+)</li><li><a href="https://link.segmentfault.com/?enc=AYucG%2B1hL2oGE4vAqemTUg%3D%3D.x6hxcf9eDq4QI%2BUNXwXGMp%2Bouv%2FmLJJXsUUJrRncSjM%3D" rel="nofollow" target="_blank">Pnpm</a>: v6.x</li></ul><h4>2、克隆代码库</h4><p>通过你 git 管理工具下载 git 代码，下面以 git-core 为例</p><pre><code>mkdir dolphinscheduler
cd dolphinscheduler
git clone git@github.com:apache/dolphinscheduler.git</code></pre><h4>3、编译源码</h4><pre><code>支持的系统:
* MacOS
* Linux
【这个我没有运行试试】
运行 `mvn clean install -Prelease -Dmaven.test.skip=true`</code></pre><h3>DolphinScheduler 普通开发模式</h3><p>上面是官方提供的，我觉得有用就复制下来，</p><p>这里开始我就按照自己的操作顺序记录</p><h4>1、编译问题：</h4><pre><code>1、git相关
1-1：开启 Windows Git 长路径支持，
管理员 PowerShell 执行，解决 DolphinScheduler 路径太深导致 git add 失败
git config --system core.longpaths true

1-2：先初始化git仓库，只在本地，不涉及账号、不推远程，Spotless 需要 HEAD
git init
git add .
git commit -m "initial commit"

2、Maven 编译 / 格式化（IDEA 里的 Terminal）
2-1：依赖 Git HEAD，自动修复格式问题
mvn spotless:apply
2-2：编译整个项目（跳过测试），确保所有模块已 install
mvn clean install -DskipTests

3、前端相关：

查看 Node.js 是否已安装
node -v

查看 npm 版本
npm -v

安装 pnpm
npm install -g pnpm
pnpm -v</code></pre><p>编译都没有问题</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558530" alt="" title="" loading="lazy"/></p><h4>2、启动zookeeper</h4><h5>官方内容</h5><p>下载 <a href="https://link.segmentfault.com/?enc=arSlBatMPlk8k%2FU3u568mA%3D%3D.bIODjsbF9iYgXvFngDK42x8HcZZ02vX8rHPzZCjyXwU%2FquIxNZZYqnjr%2Fvw16oH40gDT961f4HNVsEWtgql%2FAw%3D%3D" rel="nofollow" target="_blank">ZooKeeper</a>，解压</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558531" alt="" title="" loading="lazy"/></p><h5>存储配置</h5><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558532" alt="" title="" loading="lazy"/></p><h5>启动脚本</h5><p>搞个txt编辑完后，后缀该bat即可</p><pre><code>@echo off
echo 正在启动 ZooKeeper...
cd /d E:\\install\\ZooKeeper\\zookeeper-3.8.3\\bin
zkServer.cmd
pause</code></pre><h4>3、workspace.xml 修改</h4><p>【可以不用，我也是看其他文章有添加的，不过我没添加也能正常运行，这里只做记录】</p><pre><code>在其他文章看到说在这里添加这行，说是让 IDEA 在运行时动态使用模块的 classpath，而不是用启动时生成的静态 classpath。

注意点：
这个作用只会影响本地 IDEA 启动，线上环境如果有问题这个是解决不了的。

"dynamic.classpath": "true",</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558533" alt="" title="" loading="lazy"/></p><h4>4、数据库</h4><p>我这里用的是mysql，所以需要修改</p><h5>4-1：数据初始化</h5><pre><code>创建名为【dolphinscheduler】的新数据库后，
把这个位置的sql直接拷贝复制执行即可。</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558534" alt="" title="" loading="lazy"/></p><p>如图：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047558535" alt="" title="" loading="lazy"/></p><h5>4-2：依赖相关修改</h5><pre><code>如果使用 MySQL 作为元数据库，需要先修改 `dolphinscheduler/pom.xml`，
将 `mysql-connector-java` 依赖的 `scope` 改为 `compile`，
使用 PostgreSQL 则不需要

test 改成 compile</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558536" alt="" title="" loading="lazy"/></p><h4>5、application.yaml 修改数据库配置</h4><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558537" alt="" title="" loading="lazy"/></p><h5>5-1：dolphinscheduler-master</h5><pre><code>如图，配置文件中修改这些数据：三个内容都是一样的

spring:
  config:
    activate:
      on-profile: mysql
  datasource:
    driver-class-name: com.mysql.cj.jdbc.Driver
    url: jdbc:mysql://127.0.0.1:3306/dolphinscheduler?useUnicode=true&amp;characterEncoding=utf8&amp;zeroDateTimeBehavior=convertToNull&amp;useSSL=true&amp;serverTimezone=GMT%2B8
    username: 账户名
    password: 数据库密码</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558538" alt="" title="" loading="lazy"/></p><h5>5-2：dolphinscheduler-worker</h5><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558539" alt="" title="" loading="lazy"/></p><h5>5-3：dolphinscheduler-api</h5><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558540" alt="" title="" loading="lazy"/></p><h4>6、logback-spring.xml 修改日志级别</h4><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558541" alt="" title="" loading="lazy"/></p><h5>6-1：dolphinscheduler-master</h5><pre><code>&lt;appender-ref ref="STDOUT"/&gt;</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558542" alt="" title="" loading="lazy"/></p><h5>6-2：dolphinscheduler-worker</h5><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558543" alt="" title="" loading="lazy"/></p><h5>6-3：dolphinscheduler-api</h5><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558544" alt="" title="" loading="lazy"/></p><h4>7、启动后端三个服务</h4><pre><code>我们需要启动三个服务，包括 MasterServer，WorkerServer，ApiApplicationServer

* MasterServer：在 Intellij IDEA 中执行 `org.apache.dolphinscheduler.server.master.MasterServer` 中的 `main` 方法，并配置 *VM Options* `-Dlogging.config=classpath:logback-spring.xml -Ddruid.mysql.usePingMethod=false -Dspring.profiles.active=mysql`

* WorkerServer：在 Intellij IDEA 中执行 `org.apache.dolphinscheduler.server.worker.WorkerServer` 中的 `main` 方法，并配置 *VM Options* `-Dlogging.config=classpath:logback-spring.xml -Ddruid.mysql.usePingMethod=false -Dspring.profiles.active=mysql`

* ApiApplicationServer：在 Intellij IDEA 中执行 `org.apache.dolphinscheduler.api.ApiApplicationServer` 中的 `main` 方法，并配置 *VM Options* `-Dlogging.config=classpath:logback-spring.xml -Dspring.profiles.active=api,mysql`。启动完成可以浏览 Open API 文档，地址为 http://localhost:12345/dolphinscheduler/swagger-ui/index.html

&gt; VM Options `-Dspring.profiles.active=mysql` 中 `mysql` 表示指定的配置文件</code></pre><h5>7-1：MasterServer</h5><h6>配置 VM Options</h6><pre><code>按照操作配置这个：打开后填入即可

-Dlogging.config=classpath:logback-spring.xml -Ddruid.mysql.usePingMethod=false -Dspring.profiles.active=mysql</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558545" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558546" alt="" title="" loading="lazy"/></p><h5>7-2：WorkerServer</h5><h6>配置 VM Options</h6><p>跟上面一样操作：</p><pre><code>-Dlogging.config=classpath:logback-spring.xml -Ddruid.mysql.usePingMethod=false -Dspring.profiles.active=mysql</code></pre><h5>7-3：ApiApplicationServer</h5><h6>配置 VM Options</h6><pre><code>-Dlogging.config=classpath:logback-spring.xml -Dspring.profiles.active=api,mysql</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558547" alt="" title="" loading="lazy"/></p><p>总的就这三个：</p><h4>8、启动前端服务</h4><h5>命令：</h5><pre><code>安装前端依赖并运行前端组件

cd dolphinscheduler-ui
pnpm install
pnpm run dev</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558548" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558549" alt="" title="" loading="lazy"/></p><h4>9、浏览器访问</h4><h5>账号密码：</h5><pre><code>浏览器访问：
http://localhost:5173/home

默认账号密码：

账号：admin
密码：dolphinscheduler123
</code></pre><h5>成功访问：</h5><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558550" alt="" title="" loading="lazy"/></p><h3>相关问题</h3><h4>1、存储未启用、租户\用户 指定</h4><p>问题：测试能否创建文件夹、上传文件等，提示【存储未启用】<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047558551" alt="" title="" loading="lazy"/></p><p>问题：当前登录用户的租户信息未被指定<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047558552" alt="" title="" loading="lazy"/></p><h5>解决方法：</h5><p><a href="https://link.segmentfault.com/?enc=CWVrVLhobFTncDHHMhBwjQ%3D%3D.fWUKkCNK8BlTtdAD4VXLoWrLUC%2Bt%2FE5GU8mKeZmMZCPsCWTVcN6QsT4TNmWRfkPmHPfogrM%2FyBKDE%2F7au6Bzdk7IZy%2F5QhHlrLy3fIylKcJczWCZQQCISeox1%2B3NIwmP" rel="nofollow" target="_blank">Minio 安装、启动</a></p><p>我这里直接用minio来尝试：</p><h6>1、minio 创建 dolphinscheduler 桶</h6><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558553" alt="" title="" loading="lazy"/></p><h6>2、commom.properties 修改</h6><p>配置文件改了这些地方<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047558554" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558555" alt="" title="" loading="lazy"/></p><pre><code># Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

# user data local directory path, please make sure the directory exists and have read write permissions
data.basedir.path=/tmp/dolphinscheduler

# resource view suffixs
#resource.view.suffixs=txt,log,sh,bat,conf,cfg,py,java,sql,xml,hql,properties,json,yml,yaml,ini,js

# resource storage type: HDFS, S3, OSS, NONE
# ljh --&gt;   S3 is Minio--------------------------------------
resource.storage.type=S3
# resource store on HDFS/S3 path, resource file will store to this base path, self configuration, please make sure the directory exists on hdfs and have read write permissions. "/dolphinscheduler" is recommended
resource.storage.upload.base.path=/dolphinscheduler

# ljh --&gt; The account and password of MinIO-------------------------------
# The AWS access key. if resource.storage.type=S3 or use EMR-Task, This configuration is required
resource.aws.access.key.id=minioadmin
# The AWS secret access key. if resource.storage.type=S3 or use EMR-Task, This configuration is required
resource.aws.secret.access.key=minioadmin
# The AWS Region to use. if resource.storage.type=S3 or use EMR-Task, This configuration is required
resource.aws.region=cn-north-1
# ljh --&gt; add bucket ------------------------------
# The name of the bucket. You need to create them by yourself. Otherwise, the system cannot start. All buckets in Amazon S3 share a single namespace; ensure the bucket is given a unique name.
resource.aws.s3.bucket.name=dolphinscheduler
# You need to set this parameter when private cloud s3. If S3 uses public cloud, you only need to set resource.aws.region or set to the endpoint of a public cloud such as S3.cn-north-1.amazonaws.com.cn
# ljh --&gt; localhost convert  127.0.0.1
resource.aws.s3.endpoint=http://127.0.0.1:9000

# alibaba cloud access key id, required if you set resource.storage.type=OSS
resource.alibaba.cloud.access.key.id=&lt;your-access-key-id&gt;
# alibaba cloud access key secret, required if you set resource.storage.type=OSS
resource.alibaba.cloud.access.key.secret=&lt;your-access-key-secret&gt;
# alibaba cloud region, required if you set resource.storage.type=OSS
resource.alibaba.cloud.region=cn-hangzhou
# oss bucket name, required if you set resource.storage.type=OSS
resource.alibaba.cloud.oss.bucket.name=dolphinscheduler
# oss bucket endpoint, required if you set resource.storage.type=OSS
resource.alibaba.cloud.oss.endpoint=https://oss-cn-hangzhou.aliyuncs.com

# if resource.storage.type=HDFS, the user must have the permission to create directories under the HDFS root path
resource.hdfs.root.user=hdfs
# if resource.storage.type=S3, the value like: s3a://dolphinscheduler; if resource.storage.type=HDFS and namenode HA is enabled, you need to copy core-site.xml and hdfs-site.xml to conf dir
resource.hdfs.fs.defaultFS=hdfs://mycluster:8020

# whether to startup kerberos
hadoop.security.authentication.startup.state=false

# java.security.krb5.conf path
java.security.krb5.conf.path=/opt/krb5.conf

# login user from keytab username
login.user.keytab.username=hdfs-mycluster@ESZ.COM

# login user from keytab path
login.user.keytab.path=/opt/hdfs.headless.keytab

# kerberos expire time, the unit is hour
kerberos.expire.time=2

# resourcemanager port, the default value is 8088 if not specified
resource.manager.httpaddress.port=8088
# if resourcemanager HA is enabled, please set the HA IPs; if resourcemanager is single, keep this value empty
yarn.resourcemanager.ha.rm.ids=192.168.xx.xx,192.168.xx.xx
# if resourcemanager HA is enabled or not use resourcemanager, please keep the default value; If resourcemanager is single, you only need to replace ds1 to actual resourcemanager hostname
yarn.application.status.address=http://ds1:%s/ws/v1/cluster/apps/%s
# job history status url when application number threshold is reached(default 10000, maybe it was set to 1000)
yarn.job.history.status.address=http://ds1:19888/ws/v1/history/mapreduce/jobs/%s

# datasource encryption enable
datasource.encryption.enable=false

# datasource encryption salt
datasource.encryption.salt=!@#$%^&amp;*

# data quality option
data-quality.jar.name=dolphinscheduler-data-quality-dev-SNAPSHOT.jar

#data-quality.error.output.path=/tmp/data-quality-error-data

# Network IP gets priority, default inner outer

# Whether hive SQL is executed in the same session
support.hive.oneSession=false

# use sudo or not, if set true, executing user is tenant user and deploy user needs sudo permissions; if set false, executing user is the deploy user and doesn't need sudo permissions
sudo.enable=true
setTaskDirToTenant.enable=false

# network interface preferred like eth0, default: empty
#dolphin.scheduler.network.interface.preferred=

# network IP gets priority, default: inner outer
#dolphin.scheduler.network.priority.strategy=default

# system env path
#dolphinscheduler.env.path=dolphinscheduler_env.sh

# development state
development.state=false

# rpc port
alert.rpc.port=50052

# set path of conda.sh
conda.path=/opt/anaconda3/etc/profile.d/conda.sh

# Task resource limit state
task.resource.limit.state=false

# mlflow task plugin preset repository
ml.mlflow.preset_repository=https://github.com/apache/dolphinscheduler-mlflow
# mlflow task plugin preset repository version
ml.mlflow.preset_repository_version="main"

# ljh --&gt; minio must open path style
resource.aws.s3.path.style.access=true
</code></pre><h6>3、dolphinscheduler 可视化页面添加租户</h6><p>安全中心 - 租户管理 - 创建租户<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047558556" alt="" title="" loading="lazy"/></p><h6>用户添加租户</h6><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558557" alt="" title="" loading="lazy"/></p><h3>演示</h3><h4>创建文件夹、上传文件成功</h4><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558558" alt="" title="" loading="lazy"/></p><p>如图，数据已经存放在我指定的minio文件夹里面了<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047558559" alt="" title="" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[2026开年即用：节点式思维对齐工具快速上手指南与核心功能攻略 NAVI_s1mple ]]></title>    <link>https://segmentfault.com/a/1190000047558596</link>    <guid>https://segmentfault.com/a/1190000047558596</guid>    <pubDate>2026-01-22 15:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2><strong>为什么需要节点式思维对齐工具？</strong></h2><p>在复杂的团队协作中，传统的线性沟通方式往往只关注信息的单向传递，而忽略了认知的深层对齐 。然而，战略与执行之间存在多维度的关联，如果没有节点化的对齐管理，可能会导致：</p><ul><li><strong>团队认知断层</strong>：战略意图在层层传递中失真，执行端无法理理解决策背后的逻辑原点 。</li><li><strong>沟通效率低下</strong>：缺乏可视化逻辑链条，导致决策路径破碎，难以回溯演进过程 。</li><li><strong>协作方向偏离</strong>：各部门缺乏统一的“认知地图”，导致资源投入无法形成合力。</li></ul><p>节点式思维对齐工具通过将抽象的想法、目标和任务转化为可视化的节点与链路，帮助团队建立结构化的认知模型，确保每个人的思考都能在同一频率上 。</p><h2><strong>节点式思维对齐工具的核心特性</strong></h2><ul><li><strong>图谱化展示</strong>：将思路和任务以节点形式呈现，直观展示非线性的逻辑关联 。</li><li><strong>动态实时同步</strong>：支持多人在线实时推演，任何思维层面的变动都能即刻实现全员对齐。</li><li><strong>多层级逻辑穿透</strong>：可从宏观的战略节点下钻至微观的执行细节，实现全局与局部的统一 。</li><li><strong>关系链路建模</strong>：清晰标记节点间的因果、阻塞或支撑关系，构建严密的逻辑闭环 。</li></ul><h2><strong>节点式思维对齐工具的重要意义</strong></h2><ol><li><strong>缩短认知半径</strong>：通过可视化的思维图谱，极大降低了跨部门理解复杂战略及业务逻辑的门槛 。</li><li><strong>强化决策严密性</strong>：可视化的过程会倒逼团队梳理逻辑，从而更容易发现潜在的逻辑矛盾或执行缺失点。</li><li><strong>提升资源协同效率</strong>：节点式对齐能快速识别出“关键节点”和“瓶颈节点”，引导团队精准投入核心资源 。</li><li><strong>增强成员目标感</strong>：透明化的思维路径让每位执行者都能清晰看到自己的工作在整体大蓝图中的位置。</li></ol><h2><strong>应用场景</strong></h2><ul><li><strong>战略解码与推演</strong>：将公司愿景逐级拆解为各层级的关键决策节点，确保上下同欲 。</li><li><strong>复杂项目架构设计</strong>：在项目启动前，通过节点图梳理系统架构、功能模块与业务依赖 。</li><li><strong>项目复盘与逻辑对齐</strong>：回溯执行过程中的关键决策节点，识别逻辑拐点并沉淀为组织资产。</li></ul><h2>---</h2><p><strong>5款值得尝试的节点式思维对齐工具</strong></p><h3><strong>1. 板栗看板</strong></h3><p>结构化节点展示与任务对齐的可视化平台</p><ul><li><strong>特点</strong>：支持任务卡片间的逻辑连线，通过看板视图直观展示节点的流转过程与依赖关系 。</li><li><strong>优势</strong>：将“抽象逻辑”与“具体任务”通过节点连接，团队能清晰看到每个任务背后的价值支撑 。</li><li><strong>适合团队</strong>：追求流程透明与逻辑一致性，需要将战略目标快速落地为执行动作的敏捷团队。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047558598" alt="在这里插入图片描述" title="在这里插入图片描述"/></li></ul><h3><strong>2. Trello</strong></h3><p>直观的看板式思维对齐工具</p><ul><li><strong>特点</strong>：通过颜色标记、标签系统和列表组织，让节点在工作流中的位置一目了然 。</li><li><strong>优势</strong>：界面设计直观，通过简单的拖拽即可实现任务节点的优先级调整与共识达成 。</li><li><strong>适合团队</strong>：注重可视化呈现和轻量级协同的初创或创意团队 。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047558599" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></li></ul><h3><strong>3. ClickUp</strong></h3><p>灵活的多视图节点管理系统</p><ul><li><strong>特点</strong>：支持将思维节点在时间线、看板等多种视图间切换，适应不同的认知需求。</li><li><strong>优势</strong>：功能极其丰富，能够帮助团队管理复杂的任务层级和多维度的逻辑分类 。</li><li><strong>适合团队</strong>：需要多层级管理、涉及复杂职能交叉的中大型团队 28。<br/>在这里插入图片描述<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047558600" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></li></ul><h3><strong>4. Jira Software</strong></h3><p>专业级研发逻辑对齐与追踪平台</p><ul><li><strong>特点</strong>：将目标对齐作为敏捷流程的核心，支持任务节点的深度影响分析与状态追踪 。</li><li><strong>优势</strong>：严密的逻辑关联能力，适合对研发流程、故障节点有严格闭环管理要求的团队 。</li><li><strong>适合团队</strong>：追求高度标准化、需要将思维对齐固化为生产流水线的专业技术团队 。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047558601" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></li></ul><h3><strong>5. Asana</strong></h3><p>跨职能思维协同与目标分发平台</p><ul><li><strong>特点</strong>：提供灵活的节点管理能力，强调跨职能团队间的目标一致性与协作友好性 。</li><li><strong>优势</strong>：强大的集成能力，能将思维对齐的结果快速转化为不同应用间的自动化流转 。</li><li><strong>适合团队</strong>：需要灵活处理跨部门复杂依赖、注重易用性与协作体验的通用型团队 。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047558602" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></li></ul><h2>---</h2><p><strong>如何选择合适的节点式思维对齐工具？</strong></p><h3><strong>1. 按团队规模选择</strong></h3><ul><li><strong>小型团队</strong>：推荐 <strong>板栗看板</strong>、Trello 等上手即用的工具，强调从思维到执行的转化效率 。</li><li><strong>中型团队</strong>：适合使用 <strong>Asana</strong>、Trello 等灵活管理复杂任务节点与标签的平台 。</li><li><strong>大型团队</strong>：建议选择 <strong>ClickUp</strong> 或 <strong>Jira</strong>，这些工具提供强大的层级管理功能，适应大规模共识难题 。</li></ul><h3><strong>2. 按思维复杂度选择</strong></h3><ul><li><strong>简单对齐</strong>（如日常待办、轻松项目）：选择 <strong>板栗看板</strong>、Trello 等直观、操作简便的工具 。</li><li><strong>复杂对齐</strong>（如跨部门协作、深层系统重构）：推荐 <strong>ClickUp</strong>、Jira 等支持深度自定义和多层级节点管理的系统。</li></ul><h2>---</h2><p><strong>结语</strong></p><p>节点式思维对齐工具让组织的认知从碎片走向网状，帮助团队打破“理解的墙”，在高度不确定的商业环境中快速形成合力。通过这些工具，团队可以构建可视化的组织大脑，确保每一个动作都源于深度共识，并最终指向共同的目标</p>]]></description></item><item>    <title><![CDATA[启动｜2026 中国边缘计算20强榜单评选：寻找 AI 时代的边缘力量 边缘计算社区 ]]></title>    <link>https://segmentfault.com/a/1190000047558186</link>    <guid>https://segmentfault.com/a/1190000047558186</guid>    <pubDate>2026-01-22 14:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在这个被大模型和智能体（Agent）疯狂重塑的年份，我们不得不承认一个残酷的事实：传统的边缘计算叙事，正在失效。</p><p>当算力从中心有序下沉，当 AI Agent 开始接管终端决策，边缘计算不再只是网络的延伸，而正在成为智能的前沿阵地。谁还停留在旧叙事中，谁又真正拿到了通往下一个十年的船票，答案正在迅速分化。</p><p>基于这样的行业背景，边缘计算社区正式启动「2026 中国边缘计算企业 20 强」榜单评选。这不仅是一份年度名单，更是一场在技术代际更迭下的行业校准。</p><p><img width="723" height="311" referrerpolicy="no-referrer" src="/img/bVdnIdE" alt="image.png" title="image.png"/></p><h2>榜单背景</h2><p>自 2019 年起，边缘计算社区已连续六年发布「中国边缘计算企业 20 强」榜单，累计吸引 800 余家产业链企业参与评选，覆盖边缘云、边缘一体机、边缘 AI、5G MEC 等核心领域。</p><p>过去六年中，该榜单全网累计传播曝光量突破 3500 万次（清博大数据舆情统计），不仅持续为行业树立技术与商业标杆，也逐步成为企业扩大市场影响力、获取生态与产业资源的重要入口。</p><p>当边缘计算进入 “边缘 × AI × 智能体” 的新阶段，我们认为：这份榜单，也必须随技术代际一起升级。</p><h2>从“连接”到“智算”</h2><p>回望过去两年，边缘计算的演进速度远超预期。</p><p>如果说 2024 年行业仍在聚焦边缘盒子、网关与连接能力，那么到了 2025 年底，只谈连接、不谈推理的产品，已经很难再获得市场认可。</p><p>大模型正在以前所未有的速度“瘦身”并下沉至边缘侧：从手机、PC，到工业控制器与现场设备，越来越多的终端被要求具备本地推理与自主决策能力。</p><p>边缘计算正在从“管道”，演进为 AI 的“触角”。当然，这并不意味着所有传统边缘计算企业都会被淘汰。但可以确定的是：</p><blockquote>以“连接能力”为核心竞争力的边缘产品，正在快速失去议价权。</blockquote><h2>智能体爆发，边缘侧的“寒武纪时刻”</h2><p>2026 年，或将成为边缘智能体（Edge Agents）走向规模化应用的起点。所谓边缘智能体，并非简单的模型端侧部署，而是指在受限算力、弱网络甚至离线条件下，仍具备自主感知、规划与执行能力的边缘决策单元。</p><p>未来的边缘计算竞争，将不再取决于硬件参数，而在于：</p><ul><li>谁能让大模型在边缘侧稳定运行</li><li>谁能在毫秒级延迟内完成复杂决策</li><li>谁能在算力、算法与网络之间实现系统级优化</li></ul><p>这不仅是技术升级，更是一轮生态重构。</p><h2>寻找 2026 年的“边缘脊梁”</h2><p>正是在这样的行业变局之下，我们启动「2026 中国边缘计算企业 20 强」评选。</p><p>我们要寻找的，不是停留在历史成绩上的老牌玩家，也不是只会包装概念的“PPT 公司”，而是那些真正进入 “边缘 × AI”深水区 的企业：</p><ul><li>成功将 7B、14B 等模型量化并部署到边缘端的技术实践者</li><li>用边缘智能体解决真实、碎片化场景问题的实干团队</li><li>在算力、算法与网络协同中实现突破的破局者</li></ul><p>他们，才是真正决定边缘计算下一个十年走向的力量。</p><hr/><h2>评选标准与参选要求</h2><h3>参选条件</h3><ul><li>在边缘计算领域具备成熟的技术解决方案与商业化落地案例；</li><li>拥有核心技术壁垒（如边缘芯片、算法优化、异构计算等）或独特生态资源；</li><li><p><strong>2026 年新增重点：</strong>展示边缘计算与 AI 大模型的融合实践（如优化 AI 推理效率、隐私计算、联邦学习等），以及算力。  <br/><img width="723" height="970" referrerpolicy="no-referrer" src="/img/bVdnIdF" alt="image.png" title="image.png" loading="lazy"/></p><h3>评分机制</h3></li><li><strong>线上投票（30%）：</strong>公众通过官方渠道为心仪企业投票；</li><li><p><strong>专家评审（70%）：</strong>从以下四大维度综合打分：</p><ul><li>技术领先性（35%）</li><li>商业落地（30%）</li><li>边缘×AI创新（25%）</li><li>生态贡献（10%）</li></ul></li></ul><h3>上榜权益</h3><ul><li><strong>品牌升维：</strong>通过头部合作伙伴渠道全域曝光，覆盖 10 万+ 开发者社区；</li><li><strong>商机裂变：</strong>优先对接甲方订单资源，2024 年某上榜企业通过生态合作斩获 800 万项目订单；</li><li><strong>权威认证：</strong>榜单企业客户咨询量平均提升 120%（历史数据）；</li><li><strong>生态赋能：</strong>优先加入“边缘计算产业图谱”。</li></ul><h2>特别提醒</h2><p>独行者快，众行者远：在 AI 巨头定义规则的战场上，边缘计算企业唯有被看见，才有机会被选择。技术不应被埋没，真正的能力值得被记录。边缘计算的下一个十年，不属于参数最多的人，而属于最懂场景、最懂约束、也最懂 AI 如何落地的人。</p><p><strong>边缘计算社区</strong>  <br/>2026年1月21日</p>]]></description></item><item>    <title><![CDATA[TDengine IDMP 让制糖生成真正做到“看得清、管得住、跑得稳” TDengine涛思数据 ]]></title>    <link>https://segmentfault.com/a/1190000047558063</link>    <guid>https://segmentfault.com/a/1190000047558063</guid>    <pubDate>2026-01-22 13:03:25</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>2025 年 12 月，涛思数据与北京海莱德自动化工程有限公司（简称“海莱德”）正式建立合作伙伴关系。此次合作，海莱德将基于自身行业自动化系统集成能力，结合涛思数据提供的 TDengine TSDB + IDMP 产品组合，共同为制糖等行业客户打造从数据采集、治理到智能分析应用的完整解决方案，助力制糖工业企业实现生产运营的数字化与智能化转型。</p><h2>行业背景｜制糖生产正在面对的新挑战</h2><p>制糖行业的生产实践表明，甘蔗制糖是一项高度连续、强耦合、对运行稳定性要求极高的工业过程。原料受品种、成熟度、含糖量和纤维含量等因素影响，天然波动较大；加之榨季集中、生产节奏紧凑，一旦发生非计划停车或关键参数失控，带来的不仅是产量损失，更可能造成难以弥补的经济影响和社会影响（涉及甘蔗和甜菜的农业生产）。</p><p>在此背景下，行业内绝大多数糖厂长期依赖以人工经验为主的工艺调整方式，以及以工段为单位、相互割裂的数据管理模式，这些传统做法逐渐显现出其局限性。经验固然重要，但难以在不同班组、不同人员之间稳定传承与高效复制；生产数据虽然持续产生，却因分散在不同系统与记录中而难以整合分析，从而无法有效支撑对稳产、提质、降本目标的持续精细化管控。这已成为行业的一个普遍共识：仅依靠传统方式，已难以应对当前生产运行对稳定性与过程可控性日益提升的要求。</p><h2>面临挑战｜从“看不清”到“管不住”</h2><p>在实际运行中，以下这些挑战并非个案，而是制糖行业中普遍存在的共性问题。</p><p>首先，生产过程链条长、环节多，从预处理、压榨、澄清、蒸发、煮糖到分蜜、干燥包装，各工段数据往往分散在不同的系统与记录中，缺乏统一视角，导致难以形成真正贯穿全流程的生产监控与分析能力。</p><p>其次，在工艺质量管控方面，参数调整长期依赖人工经验判断。许多异常往往在最终质量指标已发生偏差后才得以察觉，缺乏对工艺质量的过程性分析与持续监控手段，难以实现事前预警与主动干预。</p><p>最后，在物料与糖分损耗管理上，行业长期缺乏有效的工具进行清晰、有效的分析和管理。糖分损耗分散于滤泥、废蜜、洗水、跑糖等多个环节，大多依靠经验估算，无法形成系统、可对比的“糖损画像”，这在很大程度上制约了对产糖效率与整体经营指标的持续优化。</p><p>正是这些普遍存在的“看不清、管不住”的痛点，促使制糖行业开始重新思考生产管理方式，并推动如 TDengine IDMP 这样的生产数据与工艺管理平台，逐渐成为企业进行数字化转型、实现精细化运营的重要选择。</p><h2>解决方案｜从“数据分散”到“AI Ready”，让制糖跑在数据之上</h2><p>在榨季现场，行业内常有一种共识：“数据其实都有，就是用不起来。”原料特性每日波动，工艺流程长且复杂，相关数据往往分散在局部的 DCS、各类设备的独立系统及手工台账中。操作人员依赖经验盯守，生产系统中前后无高效的数据流通，一旦生产节奏加快，潜在的风险与异常便容易被淹没在庞杂的信息流中。</p><p>因此，选择引入 TDengine IDMP 平台，其初衷并非简单“再上一套系统”，而是旨在将沉睡的数据转化为直接支撑生产决策与运营优化的能力。围绕制糖行业原料波动大、流程链路长、设备可靠性要求高等特点，该平台以 <strong>TDengine TSBS + TDengine IDMP</strong> 为核心，从数据采集与接入起步，逐步打通数据治理、业务情景化建模与 AI 分析应用，致力于构建一套真正面向生产、服务于工艺优化与稳定运行的工业数据管理体系。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558065" alt="图1 以 TDengine IDMP 为基础面向生产的工业数据管理体系" title="图1 以 TDengine IDMP 为基础面向生产的工业数据管理体系"/></p><h3>数据采集｜先把“碎数据”连成一条线</h3><p>在项目启动之初，制糖企业现场所面临的情况在行业中并不陌生：数据体量并不少，但分布零散。工厂局部的 DCS、各类设备的独立系统仅仅服务于局部的监控层面。而在数据分析、集中管理与智能应用层面，则长期缺乏统一、高效的数据出口。</p><p>针对这一现状，项目规划在不影响现有控制系统稳定运行的前提下，于集控层之上构建独立的数据采集与汇聚通道。计划在每个工厂部署一套 TDengine TSDB，利用其自带的零代码采集工具 taosX，通过 OPC 标准接口从 DCS Server 读取实时工艺数据，以实现关键生产数据的稳定采集与接入。同时，在企业级数据中心部署统一的 TDengine TSDB，对各工厂的时序数据进行集中汇聚与统一管理，为后续的数据整合分析与跨厂协同打下基础。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558066" alt="图2 某甘蔗制糖项目的数据采集架构图" title="图2 某甘蔗制糖项目的数据采集架构图" loading="lazy"/></p><p>这种架构既充分保留了 DCS 与 SCADA 的成熟运行体系，又在其之上形成统一、可扩展的数据采集与汇聚层，为后续的数据治理、业务情景化和 AI 应用奠定了可靠基础。</p><h3>数据分析｜从“看历史”到“提前知道”</h3><p>在数据分析层，平台基于 <strong>TDengine TSDB</strong> 的高性能时序数据管理能力，实现实时与历史数据的统一处理，并能够结合<strong>时序基础模型的时序数据预测与异常检测能力</strong>，对生产过程和设备运行状态进行持续分析。</p><p>通过对关键工艺参数和运行指标的时序建模，时序基础模型能够识别正常运行模式，预测指标变化趋势，并对偏离正常区间的异常波动进行及时检测与预警，帮助企业提前发现潜在风险。请参考：<a href="https://link.segmentfault.com/?enc=sN2jyz915433SqiwfRuT%2BQ%3D%3D.pmuJOlFbX4NXAt3exFSZR%2BySFEDHkXAggJWr1R9%2FAT38Oa7cr%2FHdAVDgl6dUK5Zy" rel="nofollow" target="_blank">时序数据分析智能体 TDgpt</a></p><p>该能力使生产管控从依赖经验的事后分析，转向基于数据的趋势预判与异常识别，为工艺稳定运行、设备可靠性提升及运营决策提供更加及时、可靠的数据支撑。</p><h3>数据目录｜让每个岗位都用得上数据</h3><p>如果说采集和分析解决了“数据有没有、算不算得动”的问题，那么数据目录解决的，是“业务用不用得上”。</p><p>TDengine IDMP 并没有强制所有人用同一种视角看数据，而是允许不同部门按自己的业务逻辑组织数据。生产车间可以围绕工艺流程，把数据按工序、工段和关键参数来组织；设备管理部门则按设备类型和运行状态建立目录，专注设备可靠性和维护。同一份底层数据，可以在不同业务视角下被反复引用。</p><p>对业务人员来说，找数据不再是“翻系统”，而是“进目录”；对系统来说，数据有了清晰的结构和入口，才能被稳定调用、持续分析。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558067" alt="图3 甘蔗制糖厂数据目录（按设备、按工艺）" title="图3 甘蔗制糖厂数据目录（按设备、按工艺）" loading="lazy"/><br/><a href="https://segmentfault.com/write###" target="_blank">https://segmentfault.com/write###</a></p><h3>数据标准化 | 让“一吨糖”只有一种算法</h3><p>在工业系统中，数据标准化不是“规范问题”，而是直接影响结果是否可信的基础工程。航天领域曾因单位不统一而导致重大事故，这一案例反复被提及，并不是偶然，而是揭示了一个普遍规律：<strong>当数据口径不统一时，系统即使运行正常，结论也可能完全错误。</strong></p><p>在制糖生产中，这类风险同样真实存在。以澄清汁流量为例，DCS 系统通常以体积流量 m³/h 采集数据，而部分历史系统或人工台账则沿用质量流量 t/h。两种口径在各自系统内都能够正常使用，但一旦进入跨系统分析场景——例如物料衡算、产能评估或能耗核算——问题便会显现：同一个“澄清汁流量”，在不同系统中参与计算，得到的却是两套完全不同的结果。</p><p>在 TDengine IDMP 中，这类问题不再依赖人工经验去“记住差异”，而是通过模型层面的标准化设计，从源头上消除歧义，确保“一吨糖”在系统中只有一种确定、可复用的计算方式。</p><h4>将“老师傅的共识”固化为系统规则</h4><p>在实际生产中，许多关键口径早已形成行业共识，只是长期存在于经验和习惯中。TDengine IDMP 通过元素模板机制，将这些共识转化为可执行、可约束的系统规则。</p><p>以“澄清汁”这一对象为例，IDMP 在模型层对其进行统一、规范的定义，明确其所包含的各类属性，并对每个属性的名称、业务含义、数据类型、计量单位及使用口径进行统一约束。针对澄清汁流量，模型中会明确其业务含义、统一采用的标准计量单位、适用的工艺计算口径，以及是否参与物料衡算与产能分析等核心规则。</p><p>通过这种方式，<strong>同一类工艺对象、同一类指标在系统中只保留唯一、确定的解释</strong>，从根本上避免“同名不同义”或“同数不同算”的问题，为后续跨系统分析和长期稳定运行提供一致、可靠的数据基础。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558068" alt="图4 通过元素模板将知识固化" title="图4 通过元素模板将知识固化" loading="lazy"/></p><h4>单位不同？系统自动算清楚</h4><p>在统一标准的同时，TDengine IDMP 也充分考虑了现有系统的复杂性。针对属性模板，平台在公式层引入计量单位的自动识别与推导能力。</p><p>当数据来自 DCS 系统时，平台能够识别其计量单位为体积流量（m³/h）；当数据来自历史系统或台账时，则识别为质量流量（t/h）。在参与计算或分析时，TDengine IDMP 会根据目标属性所要求的计量单位，自动推导并完成必要的单位换算，确保计算结果口径一致。</p><p>整个过程无需人工干预，也不依赖个人经验假设，使不同来源、不同口径的数据能够在统一模型下安全、可靠地参与分析，为物料衡算和经营决策提供稳定支撑。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558069" alt="图5 澄清汁的质量流量到体积流量的自动推导" title="图5 澄清汁的质量流量到体积流量的自动推导" loading="lazy"/></p><h3>数据情景化｜让工业数据真正看得懂、用得上</h3><p>在实际生产中，制糖行业越来越深刻地体会到：<strong>没有情景的数据，只是一串数字；只有将其置于具体的工艺场景中，数据才真正具有意义。</strong></p><p>榨季期间，生产现场变化极为迅速。今天可能是澄清工段的 pH 值出现波动，明天发现废蜜纯度偏高，过几天又察觉实际产糖率与理论值存在偏差。这类问题本身并不复杂，但过去的分析方式却异常耗时费力——通常由业务人员凭借经验提出初步判断，再由技术人员到各个独立系统中查找相关点位、收集数据；数据找齐后，还需反复确认其时间范围、计算口径是否一致。往往经过这样一轮繁琐流程，数天时间已经过去。</p><p>究其根源，问题通常不在于人员专业能力，而在于数据本身缺乏情景化组织。业务人员往往不清楚所需数据具体分布在哪些系统中、是否可直接使用；技术人员也难以理解这些数据在工艺上应如何关联、如何分析，以及它们之间的业务逻辑是什么。这种数据与业务之间的“断层”，使得高效的分析与决策难以实现。</p><h4>连接业务与技术的关键一环</h4><p>引入 TDengine IDMP 平台后，制糖企业将能够使数据真正成为业务与技术之间的“通用语言”。</p><p>该平台通过为数据补充统一、清晰的业务语义，将其与具体的生产过程直接关联。每一条数据都将被明确归属到特定的工艺环节（如澄清、蒸发或煮糖），同时标识其反映的工艺机理类型（如反应强度、抽提效率或回收损失），并清楚定义其适用的业务场景（如质量监控、物料衡算、异常分析或工艺优化）。</p><p>在此基础上，平台还将构建标准化的技术元数据层，对数据来源、计量单位和合理取值范围进行统一管理。由此，数据从何处来、如何计算将变得清晰可溯，在进行数据分析、计算或设置告警时，系统能够自动确保口径一致，从而避免因理解偏差导致的结果不一。</p><p>这一步的关键价值在于，许多原本存在于“老师傅经验”中的隐性知识与共识，将被有效地沉淀并固化为清晰、可复用的系统规则，为知识的传承与规模化应用奠定基础。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558070" alt="图6 数据情景化（业务描述和限值）" title="图6 数据情景化（业务描述和限值）" loading="lazy"/></p><h4>业务分析真正实现自助</h4><p>在数据完成情景化之后，制糖企业的业务分析方式将发生根本性转变，从过去高度依赖 IT 部门支持，转向以业务人员自助分析为主。系统前端将不再展示零散的点位编号与底层数据结构，而是围绕“澄清稳定性”“物料衡算”“产糖效率”等业务人员熟悉的工艺情景来组织数据与功能。</p><p>以澄清工段为例，工艺人员在“澄清稳定性”情景下，将能够直接选取 pH 值、混浊度、色值等关键指标，并自行拖拽搭建趋势对比与关联分析面板，用于实时判断反应状态是否偏离正常区间。整个过程无需向 IT 部门提出建模或取数需求，分析逻辑也将更加贴近现场实际。业务人员从而能真正基于数据流进行自主判断与决策。</p><p>这种以业务情景为核心的分析模式，将显著降低数据使用门槛与技术障碍，使得工艺人员更愿意、也更能够主动、自信地使用数据工具，推动数据分析融入日常作业闭环。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558071" alt="图7 澄清工艺是否稳定？业务人员自助分析" title="图7 澄清工艺是否稳定？业务人员自助分析" loading="lazy"/></p><h4>响应能力的显著提升</h4><p>当业务分析实现自助化，为制糖企业带来最直接的变化就是——<strong>业务响应速度得到显著提升</strong>。过去，从发现异常到形成分析结论，往往需要经过多环节传递与处理，周期以天计算，等结论出来时，问题可能已经扩大，甚至错过了最佳工艺调整窗口。</p><p>未来，在数据情景化的支撑下，业务人员将能够在当班内直接完成数据取用、对比分析和假设验证。例如，当澄清工段 pH 值刚出现连续偏移时，系统可在对应的业务情景中自动聚合相关指标，工艺人员即可当场判断是否需要调整加药或工艺参数；当产糖率与预期出现偏差时，也可快速定位问题根源，判别是前段抽提、澄清损失，还是后段回收效率所致。</p><p>这意味着，问题有望在“扩大之前”就被识别和处理，从而使生产运行从被动应对逐步转向主动预防与控制。</p><p>总体而言，数据情景化将帮助制糖企业真正把数据用活于业务。生产管理将不再高度依赖个人经验与事后分析，而是逐步形成一套以数据为驱动、以业务场景为依托的快速决策机制，生产运行也因此有望变得更加稳定、高效与可控。</p><h3>无问智推｜AI 驱动的生产洞察升级</h3><p>在实际生产中，制糖行业逐渐形成一种共识：AI 技术在其中的真正价值，并非在于“替代人工思考”，而在于能够<strong>在问题尚未被明确提出之前，就已将所需的相关信息与洞察准备就绪</strong>。</p><p>过去，行业中的中控系统更多地扮演着“被动工具”的角色。监控哪些指标、如何进行关联分析，完全依赖当班人员的个人经验：工艺人员需自行回忆关键指标、查找数据点位、调整分析的时间窗口。新接班的团队往往难以快速入手；而当经验丰富的老师傅不在场时，许多隐性的工艺逻辑与判断也难以得到有效复用。</p><p>在引入 TDengine IDMP 平台并完成数据情景化构建之后，AI 所扮演的角色将发生显著转变。它将不再被动等待指令，而是基于对工艺语义与业务上下文的理解，主动识别当前生产状态，并动态<strong>推荐最贴合该业务场景的监控视图与分析内容</strong>。这使得系统能够引导注意力，辅助不同经验层次的人员更快地聚焦于关键问题，从而<strong>将专家经验转化为可持续、可复用的系统能力</strong>。</p><h4>澄清段的一个真实场景</h4><p>以澄清工段的澄清汁监控为例。过去，制糖行业在监控澄清段时，往往仅限于观察几条关键参数的实时曲线，难以系统性地判断“当前工况是否真正处于正常状态”或“其趋势是否正在恶化”。</p><p>现在，AI 会自动为用户推荐一整套<strong>符合澄清工艺逻辑的监控面板</strong>，只需简单的点击“生成”，TDengine IDMP 就能够自动生成监控看板。在澄清汁场景下，系统会优先推荐：</p><ul><li> 过去一小时澄清汁 pH 的最新值，用于快速判断当前反应状态；</li><li> 过去一天每小时澄清汁锤度的平均值，帮助用户观察短周期稳定性；</li><li> 过去一周澄清汁还原糖的平均值，以及按天汇总的变化趋势，用于评估澄清效果对糖损的影响。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558072" alt="AI 推荐的澄清汁的监控面板" title="AI 推荐的澄清汁的监控面板" loading="lazy"/></p><p>这些内容并不是“通用模板”，而是因为系统已经理解：<strong>这些指标正是澄清段最关键、最有业务意义的数据组合</strong>。</p><h4>从“人盯数据”到“系统叫人”</h4><p>在引入 TDengine IDMP 之前，制糖行业对澄清段的监控更多依赖人工经验。中控画面上曲线一直在动，工艺人员需要长时间盯着趋势，凭感觉判断是不是“有点不对劲”。采用 TDengine IDMP 之后，这种状态发生了明显改变。基于已经完成的数据情景化，AI 不再等待人工提问，而是<strong>主动推荐与澄清汁相关的实时事件监控和分析</strong>，通过实时分析预警，能够在关键时刻把人“叫过来”。</p><p>在澄清汁场景中，系统能够自动推荐分析：</p><ul><li>当澄清汁加热器出口温度超过 105℃，并持续 5 分钟以上时，立即触发主要告警，同时给出该时段的平均出口温度，清楚提示存在过热风险；</li><li>对澄清汁锤度，系统每 5 分钟基于 3 倍标准差的 K-sigma 方法进行异常检测，一旦波动异常，直接给出最大锤度值，帮助用户快速判断异常程度；</li><li>系统还推荐每 10 分钟滚动计算过去 30 分钟内的平均流量，用于辅助判断当前负荷是否发生变化。</li></ul><p>在过去，这些判断逻辑往往只掌握在少数经验丰富的工艺人员手中，依赖于人员持续盯守数据、反复比对分析才能得以运用。如今，通过引入 TDengine IDMP 平台，这些经验与逻辑得以被 AI 沉淀并固化为持续、自动运行的系统能力。生产管理模式由此从依赖“人盯数据”逐步转向为“系统预警、人员确认”的协同机制，使异常得以更早被识别，工艺调整也能更及时地执行。这正是 TDengine IDMP 为制糖行业生产管理带来的最直观价值——<strong>将隐性知识显性化，将个人经验转化为可持续、可复用的系统智能。</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558073" alt="AI 自动推荐的实时分析场景" title="AI 自动推荐的实时分析场景" loading="lazy"/></p><h4>给制糖行业带来的真正变化</h4><p>对制糖行业来说，最大的变化在于：<strong>正常时不被数据打扰，异常时绝不会被遗漏。</strong><br/>生产管理也由此从“人盯数据”转向“系统叫人”，让异常更早被发现，让调整更及时发生。这正是 TDengine IDMP 在实际生产中带给制糖行业的最直观价值。</p><h2>应用成效｜从“系统上线”到“价值落地”</h2><p>随着该工业数据平台在生产现场的深入部署与应用，制糖企业有望在生产管理与工艺管控方面逐步收获系统性成效。整体解决方案围绕生产、工艺和设备三大核心对象展开，将推动数据不再仅仅停留在系统层面，而是持续融入日常运行与管理决策之中。</p><h3>全流程生产监控：让制糖过程“看得见”</h3><p>通过对制糖工艺流程进行统一的数据资产建模，平台实现了从预处理到干燥包装的全过程数据采集与集中监控。各工段之间原本割裂的数据被打通，形成连续、完整的生产视图。关键工艺参数和运行状态能够集中呈现，为现场管理、生产调度以及异常发现提供了直观、统一的支撑。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558074" alt="" title="" loading="lazy"/></p><h3>生成物料损耗分析：让损耗“算得清”</h3><p>围绕工艺过程和物料流转，平台引入了系统化的数据分析与物料衡算方法，对糖分在关键环节中的变化进行结构化分析，使以往主要依赖经验判断的物料损耗问题，转变为可量化、可对比的结果。生产、工艺和设备状态对管理层更加透明，为工艺优化和质量管控提供了更有依据的决策支持。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558075" alt="各个工艺段制糖损耗分析" title="各个工艺段制糖损耗分析" loading="lazy"/></p><h3>工艺质量实时监控：让生产“跑得稳”</h3><p>围绕关键工艺参数和质量指标，平台构建了持续运行的工艺质量监控体系，对生产各环节的运行状态进行实时跟踪和对比分析，使工艺波动由事后发现逐步转变为过程可控。通过对工艺偏差和异常趋势的及时识别，有效降低了过程波动对产品质量的影响，推动生产运行保持稳定。</p><p>工艺质量状态在生产层和管理层之间更加透明，为工艺调整和质量管控提供了持续、可靠的数据依据，有效支撑制糖生产的稳定运行和产品质量的均质化。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558076" alt="澄清汁 PH 值实时监控" title="澄清汁 PH 值实时监控" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558077" alt="工艺质量异常告警（澄清汁 PH 值）" title="工艺质量异常告警（澄清汁 PH 值）" loading="lazy"/></p><h2>商业价值｜制糖企业可持续演进的数字化底座</h2><p>从行业应用与发展的角度来看，此类项目的价值并不仅体现在一次性的系统建设或阶段性验收上，更在于为企业构建了一套可长期演进、持续赋能的数字化底座。通过统一的数据标准与平台架构，制糖行业首次获得了对全生产过程进行持续感知、系统分析与长效优化的能力，这为后续的管理深化与智能应用奠定了坚实基础。</p><p>短期而言，项目的实施将有效提升生产透明度与运行稳定性；从中长期看，该平台有望逐步成长为支撑企业实现稳产、提质、降本与风险精准管控的核心基础设施。</p><h2>行业意义｜一条稳健、可落地的制糖数字化路径</h2><h4>适用企业</h4><ul><li>希望持续提升管理水平和长期竞争力的甘蔗制糖企业</li><li>正处于数字化转型关键阶段的中小规模糖厂</li></ul><h4>成功前提</h4><ul><li>管理层对数字化目标和数据价值形成清晰、统一的认知</li><li>具备相对稳定、连续的生产和设备数据基础</li></ul><h4>核心路径</h4><ul><li>以“工艺 + 物料 + 设备”为主线，系统推进数字化建设</li><li>按“看得见 → 算得清 → 跑得稳”的节奏逐步实施，避免激进投入</li><li>在夯实数据基础之上，稳步迈向智能优化和 AI 应用</li></ul><h2>未来展望｜通过组态强化生产过程与工艺质量管控</h2><p>从预期效果来看，TDengine IDMP 将在生产数据采集、集中监控与分析方面为制糖企业打下坚实基础，从而有效支撑生产过程监控与工艺质量分析的日常需求。</p><p>在此基础上，企业可期待未来进一步引入并强化平台的组态能力，以更加直观、图形化的方式呈现工艺流程、设备运行状态与关键工艺参数。这将推动生产监控从以数据列表和图表展示为主，逐步升级为面向过程与运行状态的综合可视化管控。通过组态化配置关键质量指标和工艺约束条件，有助于将成熟的工艺经验固化为可自动执行的监控规则，提升对工艺偏差和质量风险的提前识别与主动干预能力，从而更好地服务于制糖生产长期、稳定、高效的运行目标。</p><h2>关于海莱德</h2><p>北京海莱德自动化工程有限公司成立于 2010 年，是国内工业自动化技术与解决方案提供商，在制糖行业自动化领域具有专业积累。公司业务覆盖系统设计、工程实施、调试及售后服务等全流程，并在食品饮料、汽车、电力、冶金、烟草和机械制造等行业积累了丰富工程经验。近年来，海莱德参与了多个“一带一路”糖厂的集中控制 DCS 系统及数字化系统的设计、供货与调试，持续推进从自动化向数字化、信息化和智能化方向升级，并结合涛思数据的时序数据库和 TDengine IDMP 平台建立起了对制糖企业真正高效、实用且易于掌握的，具备 AI 智能的数字化系统。</p>]]></description></item><item>    <title><![CDATA[再添钻石伙伴！TDengine 签约上海罗盘，共拓数据治理 + 时序存储新生态 TDengine涛思]]></title>    <link>https://segmentfault.com/a/1190000047558092</link>    <guid>https://segmentfault.com/a/1190000047558092</guid>    <pubDate>2026-01-22 13:02:52</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>近日，涛思数据与上海罗盘信息科技有限公司（以下简称 “上海罗盘”）举行钻石分销商签约仪式，标志着双方正式达成深度战略合作，将依托各自在数据领域的核心优势，携手为金融、制造、政企等多行业客户提供 “数据治理 + 时序存储” 全链路解决方案，推动时序数据技术在更多场景中的落地应用。</p><p>涛思数据创始人兼 CEO 陶建辉、战略渠道与生态合作总监郭浩，上海罗盘董事长马力等双方核心团队成员出席签约仪式，共同见证这一重要合作时刻。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558094" alt="" title=""/></p><h2>优势互补，构建数据全生命周期服务闭环</h2><p>作为深耕数据领域 23 年的资深玩家，上海罗盘自 2002 年成立以来，始终聚焦数据治理与数据中台核心赛道，在全国布局分支机构、研发基地与交付中心，服务覆盖银行、证券、保险、制造等多个关键行业，已为 200 多家大型客户落地创新项目，与多家 500 强企业建立长期信任合作关系。凭借完善的解决方案、成熟的交付模式与多项自主知识产权，上海罗盘在数据资产梳理、质量管控、中台搭建等领域积累了深厚的行业经验与客户资源，成为国内数据管理领域的标杆企业。</p><p>而涛思数据自主研发的 TDengine 时序数据库（Timeseries Database），凭借 “读写性能超传统方案 10 倍以上、存储成本仅为 1/10” 的核心优势，以及信创认证、高并发支撑、轻量化部署等特性，已成为工业时序数据存储与分析的首选方案；同时，AI 原生的工业数据管理平台 TDengine IDMP 以首创的“无问智推”能力重塑工业数据的建模、治理与消费方式，推动企业加速迈向数字化与智能化。</p><p>此次合作，上海罗盘在数据治理与中台建设的前端优势，将与 TDengine 在时序数据存储、分析的核心技术形成完美互补，构建 “数据治理 - 中台整合 - 时序存储 - 智能分析” 的全生命周期服务闭环，为客户解决数据管理中的碎片化痛点，提供更高效、更完整的数字化转型支撑。</p><p>签约仪式上，涛思数据创始人&amp; CEO 陶建辉表示：“数据治理是数字化转型的基础，时序数据是工业互联网、物联网场景的核心资产，两者的深度融合是行业发展的必然趋势。上海罗盘在数据治理领域的 23 年沉淀与广泛客户资源，与 TDengine 的技术优势高度契合。此次钻石级合作，将进一步完善涛思数据的生态布局，让优质的时序数据技术通过成熟的服务体系触达更多行业客户，共同赋能千行百业的数字化升级。”</p><p>上海罗盘董事长马力对合作充满期待：“TDengine 作为国产时序数据库的领军品牌，其技术实力与市场口碑有口皆碑。上海罗盘深耕数据管理领域多年，深刻理解不同行业客户在数据全链路管理中的核心诉求。此次与涛思数据达成深度合作，将借助 TDengine 的核心技术补全时序数据存储与分析的关键环节，为客户提供更全面的数字化解决方案。期待双方在技术协同、市场推广、行业落地等方面实现共赢，共创数据价值新高度。</p><h2>生态聚力，共绘数字化转型新蓝图</h2><p>当前，数字化转型进入深水区，数据已成为企业核心生产要素，而时序数据作为物联网、工业互联网、金融风控等场景的关键数据类型，市场需求持续爆发。涛思数据始终坚持 “技术驱动 + 生态共建” 的战略，通过汇聚行业优质伙伴力量，构建优势互补、协同共赢的生态体系，让 TDengine 技术更快落地行业场景，为客户提供本地化、高效化的服务支持。</p><p>此次上海罗盘的加入，不仅为涛思数据生态注入了数据治理领域的强劲动能，更标志着 TDengine 钻石分销商矩阵正式成型！自分销商招募计划启动以来，涛思数据凭借全球领先的产品体系、开放共赢的合作理念，吸引了众多行业标杆企业加入，生态影响力持续扩大。</p><p>未来，涛思数据将继续深化与包括上海罗盘在内的所有生态伙伴的合作，在技术协同、方案共创、行业落地等方面持续发力，以更完整的产品服务链路、更深厚的行业落地能力，为千行百业的数字化转型提供核心支撑。</p>]]></description></item><item>    <title><![CDATA[AI赋能！TDengine IDMP工业数据管理平台助力化工研发创新 TDengine涛思数据 ]]></title>    <link>https://segmentfault.com/a/1190000047558097</link>    <guid>https://segmentfault.com/a/1190000047558097</guid>    <pubDate>2026-01-22 13:02:05</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>2025 年 12 月，涛思数据与沈阳化工研究院（简称“沈阳院”）正式达成合作。涛思数据将为其提供 TDengine TSDB + IDMP 产品组合，通过部署工业数据管理平台，以 AI 原生的数据智能技术，支撑沈阳院构建覆盖从实验室研究到中试放大全流程的统一数据基座，助力其研发数字化转型迈向新阶段。</p><p>沈阳院是我国重要的综合性化工科研院所，其研发过程中涉及海量、多源的时序数据与非时序数据，同时其中试基地拥有多条专业化生产线。面对实验室、中试装置产生的庞杂数据，如何打破数据孤岛，实现数据的统一管理、关联分析与智能洞察，从而加速研发进程、优化生产工艺，是沈阳院数字化转型的重要任务。</p><p>随着数字化进程的推进，沈阳院需要一个能够打通从实验到中试全流程的数据管理平台，能够将时序数据与非时序数据（如物料信息、实验记录）进行关联分析，同时满足信创环境要求和数据安全规范。涛思数据全新发布的 <strong>TDengine IDMP</strong>（工业数据管理平台）产品，具备“<strong>无问智推</strong>”的 AI 原生能力，这种让数据主动说话的能力，正是解决业务人员依赖 IT 团队获取数据洞察的关键。</p><p>本次项目需要采集和分析来自实验室、中试生产线的数据，总计需要监控的<strong>测点约 2 万</strong>。这些数据来源于高压釜、干燥箱、色谱仪等实验设备，以及生产线的温度、压力、流量等工艺参数，还包括水电气等能耗数据。TDengine TSDB 支持多种数据接入方式，包括 MQTT、OPC-UA/DA 等。这对于研究院现有的数据采集系统（MQTT 和 OPC）非常重要。在数据建模方面，TDengine IDMP 采用树状层次结构，这与研究院的设备组织方式天然契合。比如，可以按照“研究院-中试基地-生产线-设备”的层级结构建立数据目录，每个节点都可以配置属性、分析规则和可视化面板。这种结构特别适合中试基地的批次分析需求，可以清晰地展示每个批次的工艺参数和质量指标。</p><p>本项目采用“整体规划、分步实施”的策略，项目计划分两阶段进行：</p><ul><li>第一阶段，选择 3 个实验室和 1 条中试生产线进行试点实施；</li><li>第二阶段，基于试点成果向全院范围推广。</li></ul><p>基于数据安全性和网络环境考虑，选择本地化部署方案。部署架构如下图所示：<br/><img width="723" height="397" referrerpolicy="no-referrer" src="/img/bVdnIce" alt="" title=""/></p><p>本次项目规划的设计思路紧密围绕化工研发的业务特点展开，力图在以下几大关键业务场景提升数据应用效率与深度：</p><ol><li><strong>数据全景可视化与智能告警</strong>：通过 TDengine IDMP 的智能可视化功能，实现实验数据和中试生产数据的全景可视化管理。研究人员无需 IT 支持即可通过自然语言交互获取所需数据视图；通过实时分析和事件管理功能，自动触发告警，并帮助研究人员快速定位问题根源；借助“无问智推”能力，自动推送质量波动的批次与标准参数的对比分析，帮助管理人员快速决策。</li><li><strong>工艺优化与批次对比分析</strong>：批次分析是中试生产的核心需求之一。借助 TDengine IDMP，可以实现多批次数据的自动对比分析。系统能够根据批次质量指标帮助科研人员找到"黄金批次"，并分析其工艺参数特征，为工艺优化提供数据支持。通过时序数据高级分析功能，研究人员可以轻松对比不同批次的差异，找出影响产品质量的关键工艺参数。</li><li><strong>预测性维护与能耗管理</strong>：基于 TDengine TDgpt 的能力，平台能够轻松集成时序数据的预测、异常检测、分类、补全、相关性分析等算法和模型，帮助客户实现对关键设备的实时监控与预测性维护。在中试基地的能耗管理方面，通过对水、电、气的实时监测与统计分析，帮助找出能效瓶颈、识别出能耗异常点，用以指导设备改造和工艺调整。</li><li><strong>数据驱动的工艺包开发</strong>：TDengine 产品组合将帮助研究院实现数据驱动的研发模式，提高工艺包开发的效率和质量。新工艺包的设计可以基于历史中试数据，确保工艺参数的可靠性。而工艺包转化为实际生产后，又可以通过对比设计数据与实际生产数据，持续优化工艺模型。同时，TDengine IDMP 内置了备份/恢复机制，未来还将支持 Git 式数据版本管理，有望进一步提高数据归档、变迁、回溯的能力。</li></ol><p>本次涛思数据与沈阳化工研究院的强强联合，为化工科研数据管理和数据分析描绘出更多可能性。相信此次合作不仅能提升沈阳院的研发效率，更有望探索出一条以数据智能驱动化工行业创新的可行路径。</p><h3>关于沈阳化工研究院</h3><p>沈阳化工研究院有限公司始建于 1949 年 1 月 8 日，是综合性化工科研院所，现为中国中化控股有限责任公司直管单位。目前沈阳院主要开展化工新材料、生态农业、生物化工、化学品测试与评价、化工反应风险评估、危险废物鉴别、化工智能优化等方向的研究及产业化。沈阳院聚焦提升关键共性技术的研究与开发能力、较强的新产品孵化能力和适度产业规模和盈利能力；致力于成为精细化工行业国内领先，国际有一定影响力的科技型企业。</p>]]></description></item><item>    <title><![CDATA[阶跃星辰开源多模态模型 Step3‑VL‑10B，小模型实现大模型能力；华为或将发布首款 AI 眼镜]]></title>    <link>https://segmentfault.com/a/1190000047558108</link>    <guid>https://segmentfault.com/a/1190000047558108</guid>    <pubDate>2026-01-22 13:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558110" alt="" title=""/></p><p><strong>开发者朋友们大家好：</strong></p><p>这里是 <strong>「RTE 开发者日报」</strong> ，每天和大家一起看新闻、聊八卦。我们的社区编辑团队会整理分享 RTE（Real-Time Engagement） 领域内「有话题的<strong>技术</strong>」、「有亮点的<strong>产品</strong>」、「有思考的<strong>文章</strong>」、「有态度的<strong>观点</strong>」、「有看点的<strong>活动</strong>」，但内容仅代表编辑的个人观点，欢迎大家留言、跟帖、讨论。</p><p><em>本期编辑：@瓒an、@鲍勃</em></p><h2>01有话题的技术</h2><p><strong>1、阶跃星辰开源 Step3‑VL‑10B：10B 模型对标 200B 能力</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558111" alt="" title="" loading="lazy"/></p><p>昨天，阶跃星辰宣布正式开源旗下 10B 参数量多模态模型 Step3‑VL‑10B。该模型在多项核心基准测试中达到同规模 SOTA 水平，部分能力甚至超越 10–20 倍体量的大模型。</p><p>Step3‑VL‑10B 主打「小模型实现大模型能力」，在视觉感知、逻辑推理、数学竞赛题、多模态对话等任务中表现突出。</p><p>阶跃星辰称，Step3‑VL‑10B 的性能已接近甚至超越部分百亿级开源模型（如 GLM‑4.6V 106B‑A12B、Qwen3‑VL‑Thinking 235B‑A22B），并在部分场景中达到顶级闭源旗舰模型（如 Gemini 2.5 Pro、Seed‑1.5‑VL）水平。</p><p>官方强调，该模型的关键突破来自三项核心设计：</p><ul><li><strong>全参数端到端多模态联合预训练</strong>：在 1.2T 高质量多模态数据上训练，实现视觉与语言的深度对齐；</li><li><strong>大规模多模态强化学习</strong>：经历超过 1,400 次迭代，使模型在识别、推理与对话能力上持续提升；</li><li><strong>并行协调推理机制</strong>：通过并行探索与证据聚合提升复杂任务的准确度，尤其在数学推理、OCR、计数与空间拓扑任务中效果显著。</li></ul><p>Step3‑VL‑10B 同时提供 SeRe（顺序推理）与 PaCoRe（并行推理）两种范式，覆盖 STEM 推理、OCR、GUI Grounding、空间理解与代码等多项能力维度。</p><p>当前，Step3‑VL‑10B 已开放 Base 与 Thinking 两个版本，社区可在 HuggingFace 与 ModelScope 获取模型并进行微调。</p><p>项目主页：<br/><a href="https://link.segmentfault.com/?enc=gQK0nod50ZMU7xahz9SMVw%3D%3D.eb%2FTnjHG7XLQncxIrjK2MBT26i5Fss5dsy%2BYIb32s4gj4X7AK2rCIbx2CUOwcBZj" rel="nofollow" target="_blank">https://stepfun-ai.github.io/Step3-VL-10B/</a></p><p>Hugging Face: <br/><a href="https://link.segmentfault.com/?enc=5op%2BnrliMKf%2BfXIob8jG%2BQ%3D%3D.kmEK3dSxBvmwmGsf1bWKSLFavWWC443252vKXjpwDAS4hr%2BddzJsr6OCWebpT%2FUkYtN7lf9pgqWgd9HFfEpN2g%3D%3D" rel="nofollow" target="_blank">https://huggingface.co/collections/stepfun-ai/step3-vl-10b</a></p><p>ModelScope: <br/><a href="https://link.segmentfault.com/?enc=Zo22gGo1za%2FM42QlIUx2Ig%3D%3D.gVgplhmUVFdeTyzRQIQ0E0tInouekMN%2BOFRpKQ6Y1RKKp33k7R3%2BVpJTEm7UInuDvbobYa7RRWcJrO3r0duyzw%3D%3D" rel="nofollow" target="_blank">https://modelscope.cn/collections/stepfun-ai/Step3-VL-10B</a></p><p>论文链接：<br/><a href="https://link.segmentfault.com/?enc=hShAiScLaMbKWRRgvAtE7A%3D%3D.J3ZMiCrh6HYXHef0wNE%2FXamv5Z4VJXUguaCAtWw%2F%2BZhd06Co7qIFgLVMcwxuYUUg" rel="nofollow" target="_blank">https://arxiv.org/pdf/2601.09668</a></p><p>（@阶跃星辰、@APPSO）</p><p><strong>2、showlab 开源 whisperVideo：集成 SAM3 与 TalkNet 实现长视频「音视对齐」的说话人转录</strong></p><p>showlab 近期开源了名为 whisperVideo 的项目，专门致力于解决长视频场景下「谁在说话」的身份归属难题。该工具打破了传统方案仅依赖音频的局限，通过融合视听双重特征，实现了语音内容与画面特定人脸的精准对齐。</p><p>为了突破纯音频方案在多人混响或近距离交谈时常见的识别漂移问题，whisperVideo 构建了一套紧密的多模态级联架构。它集成了 WhisperX 负责语音转录、Pyannote.audio 处理声纹分离，并引入 SAM3 进行人脸分割以及 TalkNet 判定主动说话人。这种组合拳方式，确保了机器能像人类一样同时「听」和「看」，从而做出更准确的判断。</p><p>针对小时级素材中常见的跨场景挑战，工具特别引入了「长时身份一致性」机制。利用视觉嵌入与轨迹聚类技术，系统能在漫长的视频时间轴上记住每一张脸，确保同一说话人的 ID 在不同场景切换中始终保持稳定。</p><p>在工作流设计上，whisperVideo 追求全自动化体验。内置的 SceneDetect 能够自动进行场景切割与分段处理，无需人工干预即可完成时间戳、文本与视觉 ID 的三方对齐。最终生成的成果不仅包括带说话人 ID 的字幕，还支持可视化的面板模式，并将底层数据以 。pckl 格式开放给开发者。</p><p>目前，项目已在 GitHub 开源，需使用 CUDA GPU 环境，依赖 HuggingFace Token 调用 Diarization 模型，支持 Python 命令行一键推理。</p><p>GitHub: <br/><a href="https://link.segmentfault.com/?enc=2gryj89afY7wssArAKTKTg%3D%3D.Hsrj5fFNCx4%2BA7YP7rvyGvgg6CcC1KjImMHzKfYRB%2BnzP3tOYXPi09dGJ3ewJ0lO" rel="nofollow" target="_blank">https://github.com/showlab/whisperVideo</a></p><p>( @aigclink\@X)</p><p><strong>3、Bolna 获 630 万美元种子轮融资：自研 SLM 语音智能体，支持「印式英语」混说</strong></p><p>总部位于班加罗尔的初创公司「Bolna」近日完成了由 General Catalyst 领投的 630 万美元种子轮融资。这家公司致力于通过自研的专用小模型（SLM）技术，打破多语言环境下的自动化通信瓶颈。</p><p>为了适应印度极其复杂的语言生态，Bolna 构建的语音智能体不仅将端到端响应延迟控制在 500 毫秒以内，更实现了深度的本地化适配。它能够流畅处理包括印地语、泰米尔语在内的 10 余种本土语言及 50 多种地区口音，甚至针对印度特有的语言混合现象，专门优化了对「印式英语（Hinglish）」的语义理解与生成能力。</p><p>在技术架构上，Bolna 摒弃了昂贵的通用大模型方案，转而采用针对事务性查询优化的 SLM 与智能路由架构。这种策略有效平衡了计算成本与响应速度，使其更适合大规模商业落地。配合其提供的无代码控制台，企业可自主设计并监控智能体。目前，该平台的日呼叫处理量已从 1,500 通激增至 20 万通以上，广泛应用于购物车挽回、货到付款确认及招聘筛选等场景。</p><p>平台现已正式上线，主要面向印度企业提供订阅制的自助服务。</p><p>( @AI Tech Suite)</p><h2>02有亮点的产品</h2><p><strong>1、消息称华为首款 AI 眼镜将在上半年发布：搭载鸿蒙 OS，支持同传翻译与拍照</strong></p><p>1 月 20 日多家媒体消息，华为的第一款「AI 眼镜」暂定在今年上半年推出，支持拍照和音频，鸿蒙系统 + 跨端无缝协同，同传翻译等功能。 AI 眼镜被誉为「下一代 AI 终端超级入口」，已然是大厂必争之地，百度、小米、阿里、理想等早已进场，并推出了 AI 拍照眼镜，字节也即将推出 AI 眼镜，作为国内消费类智能终端龙头的华为自然不会落后于人。</p><p>据 @数码闲聊站 爆料，华为 AI 眼镜将采用鸿蒙 OS 系统与轻量化设计，内置 3 块锂电池，支持跨端无缝协同，进一步拓展使用场景。并提供流光银、钛银灰、摩登黑三款配色，支持拍照、拍视频、音频播放以及同声传译等功能。</p><p>虽然目前具体细节尚未公布，但结合华为在 AI 技术领域的探索，预计将内置华为 AI 助手小艺，产品可能涉及 AI 识物、智能场景推荐等功能。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558112" alt="" title="" loading="lazy"/></p><p>经查询发现，华为曾推出带有音频功能的智能眼镜，主打听音乐、打电话、健康播报等。如今随着 AI 的兴起，智能眼镜行业也纷纷上马 AI，以及自带摄像头、显示屏的 AI 眼镜也不断推新。</p><p>据 IDC 预测，智能眼镜产品成为 2025 年消费电子赛道的黑马，相应产品在中国市场出货量预计达到 290.7 万台，同比增长 121.1%。业内人士普遍认为，这缘于技术突破、市场需求释放以及产业链成熟等多重因素。</p><p>汇丰控股认为，智能眼镜市场仍处于加速扩张阶段。分析师预计，智能眼镜的用户规模将在未来十多年内迎来爆发式增长，到 2030 年代末将达到 2.89 亿人，较 2025 年的 1500 万用户增长超过 18 倍。</p><p>（@即智 Ultra、@IT 之家）</p><p><strong>2、MiniMax 推出「Agent 实习生」，AI-native Workspace 全面升级</strong></p><p>昨天，MiniMax 官宣，AI-native Workspace 迎来两项核心升级，进一步推动 AI 深度嵌入真实工作场景，并面向用户开放限时免费体验。</p><ul><li><strong>桌面端应用正式上线：</strong> 用户可在本地环境中指定 Workspace 作为工作空间与上下文，使 AI 能够直接理解本地文档、代码仓库、邮件与日程，从而构建一个专属于个人的智能工作环境。</li><li><strong>推出「专家 Agents」能力：</strong> 用户可构建在特定领域达到「95 分甚至 100 分」水平的专业智能体。这类 Agent 能够在复杂任务链路中稳定执行、主动判断并长期协作。</li></ul><p>公司内部数据显示，「Agent 实习生」在过去数周已被接近 100% 的员工使用，并在运维场景中承担了约 80% 的查 Bug 工作量。</p><p>MiniMax 表示，AI-native Workspace 标志着 Agent 从「被动执行指令」向「主动感知环境」的形态演进。</p><p>公司认为，未来的 Agent 将具备长期记忆、完整职业上下文与跨系统感知能力，成为用户的长期工作伙伴，而非一次性工具。</p><p>目前，MiniMax 已开启专家 Agents 的限时免费体验。用户可通过 Web 端直接试用，也可通过官方体验链接获取桌面端安装包。</p><p>体验地址：<br/><a href="https://link.segmentfault.com/?enc=I6nPxwLpIqCMjyhJBWIICw%3D%3D.HHQkLPkFfmobUemJQvVgx5TiZxGbLRxzhj8xxyLQLzw%3D" rel="nofollow" target="_blank">https://agent.minimaxi.com/</a></p><p>( @APPSO)</p><p><strong>3、Crow 发布 AI 智能体框架：支持 OpenAPI 与 MCP 协议，实现「对话即 UI」交互</strong></p><p>Crow 近期推出了一套专为 SaaS 产品打造的 AI 智能体基础设施，旨在通过「对话即 UI」的理念重构软件交互模式。该工具的核心逻辑在于将传统的点击操作转化为自然语言指令流，通过接入 OpenAPI 规范或 MCP 协议，使智能体不仅能回答问题，更能直接触发后端 API 调用及前端 UI 导航，从而实现对软件功能的深度控制。</p><p>为了解决生成式 AI 不可控的难题，Crow 引入了名为「Journeys」的结构化工作流。开发者可以针对取消订阅、创建报表等特定业务场景，定义确定性的引导路径，确保智能体在执行敏感操作时严格遵循预设的逻辑分支。配合支持文件与文档集成的 RAG 管道，智能体还能充分理解产品特定的业务逻辑与私有数据。</p><p>在开发与运维层面，Crow 提供了生产级的观测指标，能够详细追踪每一条指令对应的工具调用路径。其低代码部署方案仅需嵌入单行 Script 标签，官方宣称这能将传统长达半年以上的自研周期缩短至一周以内，并支持与 Claude Code 或 Cursor 等工具集成。目前该产品已正式上线，开发者项目可免费试用，同时针对中大型企业提供了定制化方案。</p><p>( @Y Combinator Launch)</p><p><strong>4、Thread 发布 Voice AI：实现 MSP 电话自动化分拣与实时工单同步，单人效能提升 30%</strong></p><p>Thread 宣布其专为托管服务提供商设计的 Voice AI 正式商用。该产品旨在终结传统 IVR（交互式语音应答）系统的僵化体验，通过语音智能体接管电话接入、分拣与派发的全流程，将高成本的电话渠道整合进结构化的自动化运维体系中。</p><p><strong>AI Attendant 与 Overflow Agent 双引擎驱动：</strong></p><ul><li><strong>AI Attendant</strong>：取代传统 IVR，能够即时接听电话并识别来电者身份。它不仅能进行自然的语音交互，还能在后台实时创建工单、匹配技术人员，并完成「热切换」，确保客户在转接给真人时无需重复复述问题。</li><li><strong>Overflow Agent</strong>：专为下班后或线路繁忙场景设计。它能拦截进入语音信箱的电话，自动收集关键信息并进行分类；遇到 P1 级紧急事件时，可直接升级并呼叫待命团队，消除了「下班后盲区」。</li></ul><p>Voice AI 的核心价值在于将非结构化的语音高效转化为结构化数据。系统不仅能根据通话内容自动填充工单的标题、类别、优先级和解决摘要，还引入了「自动时间条目」功能，可依据通话时长直接生成计费记录。据官方数据统计，这一特性为每张工单平均节省了 19 分钟的处理时间，从而推动单一技术人员的日均通话处理量从 8-12 通显著提升至 14-20 通。</p><p>在生态兼容性方面，该方案作为 Thread AI Service Desk 平台的重要组成部分，已与 ConnectWise、Autotask 和 HaloPSA 等主流 PSA 系统实现了原生集成。这意味着所有通话数据都会实时转化为结构化文档，并无缝同步至企业现有的工作流中，从而确保了整个服务链条的完整性与可追溯性。</p><p>据 Thread 统计，通过消除手动记录和人工轮班需求，该系统可使响应速度提升 5 倍，平均解决时间缩短 78%。目前该服务已正式上线。</p><p>相关链接：<br/><a href="https://link.segmentfault.com/?enc=nOwKqElwmEHnC4Pt5Cwb5w%3D%3D.pTtohgfX4CTHHC8ljusOHEFS6T3YcrRESxLScfzXNOsMTcJdMpgYTpo%2Bxv2LZgsk" rel="nofollow" target="_blank">https://www.getthread.com/voice-ai</a></p><p>( @Mansfield News Journal)</p><h2>03有态度的观点</h2><p><strong>1、谷歌前 CEO 施密特：欧洲要么投资开源 AI，要么依赖中国模型</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558113" alt="" title="" loading="lazy"/></p><p>1 月 20 日，据外媒报道，谷歌前 CEO、科技投资人埃里克 · 施密特 （Eric Schmidt） 周二表示，<strong>欧洲必须投资建设自己的开源 AI 实验室，并解决能源价格飙升的问题，否则很快就会发现自己对中国的模型产生依赖。</strong> 施密特周二在达沃斯世界经济论坛表示：「在美国，企业基本上正在转向闭源，这意味着这些技术将被购买、授权等等。而与此同时，中国在做法上基本是开放权重、开源的。除非欧洲愿意为欧洲自己的模型投入大量资金，否则欧洲最终将会使用中国的模型。」</p><p>目前，许多热门 AI 模型都是闭源的，比如谷歌的 Gemini 和 OpenAI 的 ChatGPT，这意味着这些公司不会向外界提供底层代码供下载或审查。虽然这种方式能为用户带来更顺畅、更统一的使用体验，但通常成本更高、灵活性也更低。中国在所谓「开放权重」模型的开发方面处于领先地位，这类模型具有更高的透明度。</p><p>为了在开发更强大 AI 模型和智能体的全球竞赛中具备竞争力，欧洲还需要解决高企的能源价格问题，并建设更多可用于训练这些技术的数据中心。施密特曾联合创办一家数据中心公司，致力于应对这类基础设施巨大的能源需求。他也对美国 AI 发展对电力供应的影响表示担忧。</p><p>（@IT 之家）</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558114" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558115" alt="" title="" loading="lazy"/></p><p><a href="https://link.segmentfault.com/?enc=fixs3xAKfdvLACDGOdaE9A%3D%3D.SEjbj4AwR2Zz8yYTwCZ%2BBsbBwuoIy1ZcQMgoxGkXX4Y%3D" rel="nofollow" target="_blank">阅读更多 Voice Agent 学习笔记：了解最懂 AI 语音的头脑都在思考什么</a></p><p><strong>写在最后：</strong></p><p>我们欢迎更多的小伙伴参与 <strong>「RTE 开发者日报」</strong> 内容的共创，感兴趣的朋友请通过开发者社区或公众号留言联系，记得报暗号「共创」。</p><p>对于任何反馈（包括但不限于内容上、形式上）我们不胜感激、并有小惊喜回馈，例如你希望从日报中看到哪些内容；自己推荐的信源、项目、话题、活动等；或者列举几个你喜欢看、平时常看的内容渠道；内容排版或呈现形式上有哪些可以改进的地方等。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558116" alt="" title="" loading="lazy"/></p><p>作者提示: 个人观点，仅供参考</p>]]></description></item><item>    <title><![CDATA[如何通过Java SDK新建Client DashVector ]]></title>    <link>https://segmentfault.com/a/1190000047557765</link>    <guid>https://segmentfault.com/a/1190000047557765</guid>    <pubDate>2026-01-22 12:06:58</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>本文介绍如何通过Java SDK新建一个DashVector Client。</p><p><strong>说明</strong></p><p>通过DashVector Client可连接DashVector服务端，进行Collection相关操作。</p><h2>前提条件</h2><ul><li>已创建Cluster</li><li>已获得API-KEY</li><li>已安装最新版SDK</li></ul><h2>接口定义</h2><p>Java示例：</p><pre><code class="java">package com.aliyun.dashvector;

// 通过apiKey和endpoint构造
DashVectorClient(String apiKey, String endpoint);

// 通过DashVectorClientConfig构造
DashVectorClient(DashVectorClientConfig config);</code></pre><h2><strong>使用示例</strong></h2><p><strong>说明</strong></p><p>需要使用您的api-key替换示例中的YOUR_API_KEY、您的Cluster Endpoint替换示例中的YOUR_CLUSTER_ENDPOINT，代码才能正常运行。</p><p>Java示例：</p><pre><code class="java">import com.aliyun.dashvector.DashVectorClient;
import com.aliyun.dashvector.DashVectorClientConfig;
import com.aliyun.dashvector.common.DashVectorException;

public class Main {
    public static void main(String[] args) throws DashVectorException {
        // 通过apiKey和endpoint构造
        DashVectorClient client = new DashVectorClient("YOUR_API_KEY", "YOUR_CLUSTER_ENDPOINT");
      
        // 通过Builder构造DashVectorClientConfig
        DashVectorClientConfig config = DashVectorClientConfig.builder()
            .apiKey("YOUR_API_KEY")
            .endpoint("YOUR_CLUSTER_ENDPOINT")
            .timeout(10f)
            .build();
        client = new DashVectorClient(config);
    }
}</code></pre><p><strong>说明</strong></p><p>DashVectorClient初始化期间可能抛出<code>DashVectorException</code>异常，可通过具体异常信息分析初始化失败原因。</p>]]></description></item><item>    <title><![CDATA[供应商管理系统有哪些？谈谈我们测评的这8款 SaaS圈老马 ]]></title>    <link>https://segmentfault.com/a/1190000047557793</link>    <guid>https://segmentfault.com/a/1190000047557793</guid>    <pubDate>2026-01-22 12:06:19</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>供应商来对账，数据对不上，耽误好几天；采购价格不透明，成本居高不下；供应商绩效全凭印象，合作质量参差不齐...如果你也正被这些问题困扰，是时候了解一下供应商管理系统了。</p><p>今天我们就来一次深度测评，聊聊市面上主流的几款供应商管理解决方案，帮你找到最适合自家业务的那一款。</p><p><strong>一、选型要点：好的系统，到底该看什么？</strong></p><p>在直接推荐产品前，先明确几个核心选型标准，这是避开坑的关键。</p><p><strong>第一，要看它能不能解决你真实的痛点</strong>。很多企业痛点很具体：比如采购流程不规范、线上线下数据对不上、供应商质量不稳定、对账周期漫长等。系统功能是否直击这些要害，是首要考量。</p><p><strong>第二，灵活性和扩展性至关重要</strong>。特别是成长型企业，业务变化快，今天用的功能明天可能就要调整。如果系统僵硬，改个流程都要找原厂花大价钱二开，那用起来会很痛苦。所以，是否支持一定程度的自定义或低代码调整，是个加分项。</p><p><strong>第三，性价比和长期投入成本</strong>。这不单指软件本身的购买费用，还包括实施费用、每年的维护费、未来需求变化的二次开发成本，甚至数据迁移的成本。一个“买得起但用不起”的系统，不如一开始就放弃。</p><p><strong>第四，厂商的服务与可持续性</strong>。软件即服务，后续的响应速度、问题解决能力、版本迭代计划，都直接影响你的使用体验。选择有成熟服务团队、产品持续迭代的厂商，更稳妥。</p><p>基于以上几点，结合市场主流选择，我筛选出 <strong>8款值得深入考察的供应商管理系统</strong>，并对其核心特点、适用场景进行分析。</p><p><strong>二、测评盘点：8款主流供应商管理系统</strong></p><p><strong>1. 支道</strong></p><p><a href="https://link.segmentfault.com/?enc=cqxrxxRY6Nd9FS%2By%2FFYk1g%3D%3D.J8SfPTlsZ8fW%2Fj1ATN1YfIPpjy3Z2XE7wLWGeYzKzZo%3D" rel="nofollow" target="_blank">https://www.zdsztech.com</a></p><p><strong>核心特点</strong>：基于无代码平台构建，高度可定制</p><p>如果要用一个词形容支道的供应商管理方案，那就是 <strong>“灵活”</strong>。它并非一个功能固化的标准产品，而是基于其强大的无代码开发平台，能够快速搭建出贴合企业实际采购业务流程的系统。</p><p>从测评角度看，它的优势很明显：<strong>可视化搭建，改起来方便</strong>。</p><p>企业的采购审批流程、供应商准入标准、询比价模板，都可以通过拖拉拽的方式配置和修改，业务人员经过培训也能参与调整。这解决了很多企业“需求说不清、软件改不动”的痛点。</p><p>具体到SRM功能上，它覆盖了供应商全生命周期管理：供应商电子档案、在线准入申请、询价/招标/比价流程、采购订单协同、送货与验收协同、对账付款、以及供应商绩效评估。</p><p>亮点在于流程的在线化和自动化，比如报价自动汇总比价、订单状态自动同步给供应商、绩效数据自动采集计算等。</p><p><strong>适合谁用</strong>：业务独特、流程经常优化、或者未来可能将SRM与内部CRM、项目管理系统打通的成长型企业。它的无代码特性让长期迭代成本更低。</p><p><strong>需要注意</strong>：高度灵活也意味着初期需要更多的业务梳理和配置投入，更适合愿意在管理梳理上花时间、追求长期适配性的企业。<br/><img width="723" height="292" referrerpolicy="no-referrer" src="/img/bVdnH6W" alt="" title=""/></p><p><strong>2. 用友</strong></p><p><strong>核心特点</strong>：与ERP、财务系统天然集成，业财一体化能力强</p><p>用友作为国内企业管理软件的老牌厂商，其YonSuite中的SRM模块最大优势在于 “集成”。如果你的企业已经在使用或用友的ERP、财务系统，那么选择它的SRM模块，在数据打通上会非常顺畅。</p><p>采购订单直接生成应付、入库信息实时同步、成本数据自动归集，真正实现业务流、信息流、资金流合一。</p><p>功能层面，它提供标准的供应商管理、寻源管理、采购协同、库存协同等功能。在供应商绩效方面，支持多维度指标（如质量、交期、价格、服务）的量化评估。</p><p><strong>适合谁用</strong>：尤其是那些已经使用用友体系产品的中大型企业，或者对财务业务一体化要求极高、希望杜绝数据孤岛的企业。</p><p><strong>需要注意</strong>：作为标准化程度较高的产品，在面对一些非常规的、行业特有的采购流程时，可能需要通过二次开发来实现，成本和周期需提前评估。<br/><img width="723" height="285" referrerpolicy="no-referrer" src="/img/bVdnH6X" alt="" title="" loading="lazy"/></p><p><strong>3. 金蝶</strong></p><p><strong>核心特点</strong>：强调供应链协同，尤其在生产制造领域有深度方案</p><p>金蝶的云星空SRM，在制造业企业中口碑不错。它的设计思路强调 <strong>“供应链协同”</strong> ，不止管理供应商，更注重与供应商之间的高效协作。比如，支持供应商门户，让供应商自助查看订单、确认交期、填报送货单；支持与生产计划的联动，实现采购需求的精准触发。</p><p>其功能亮点在于对 VMI库存管理、JIT准时化采购、寄售业务 等复杂场景的支持，这些都是制造企业的核心痛点。在供应商风险方面，也提供了诸如资质预警、交期预警等管理功能。</p><p><strong>适合谁用</strong>：生产制造型企业，特别是对原材料采购协同、精益生产有要求的企业。也适合金蝶ERP的老用户，保障系统连贯性。</p><p><strong>需要注意</strong>：方案相对偏向中大型制造企业，对于贸易类、项目服务类企业的贴合度可能需要详细验证。<br/><img width="723" height="300" referrerpolicy="no-referrer" src="/img/bVdnH68" alt="" title="" loading="lazy"/></p><p><strong>4. SAP</strong></p><p><strong>核心特点</strong>：全球化、战略寻源、网络化协同</p><p>SAP Ariba 是全球领先的采购云平台，它的定位更高，更像一个 <strong>“采购网络”</strong>。其核心优势在于 <strong>全球寻源和战略采购</strong>。如果你的企业采购范围遍布全球，需要管理跨国供应商、进行复杂的招标和合同管理，Ariba 提供了强大的支持。它拥有庞大的供应商网络，方便发现新供应商。</p><p>功能极其全面，从支出分析、寻源招标、合同管理、到供应商协同、发票与付款，覆盖整个直接和间接采购流程。其数据分析能力强大，能帮助企业深度洞察采购支出，优化采购策略。</p><p><strong>适合谁用</strong>：大型集团企业、跨国公司，或者采购品类复杂、将采购视为战略职能的企业。预算充足是前提。</p><p><strong>需要注意</strong>：实施和运维成本非常高，系统复杂，对内部管理规范性和团队能力要求极高。对于中小型企业来说，可能“杀鸡用牛刀”。<br/><img width="723" height="269" referrerpolicy="no-referrer" src="/img/bVdnH7e" alt="" title="" loading="lazy"/></p><p><strong>5. 甄云</strong></p><p><strong>核心特点</strong>：产品化程度高，开箱即用，聚焦采购全流程数字化</p><p>甄云是国内较早专注于采购数字化SRM的厂商之一。其产品特点是 “全流程、产品化” ，功能模块成熟，设计理念清晰。它围绕企业采购业务，提供从供应商管理、寻源管理、采购协同、到财务协同的完整闭环。用户体验和界面设计比较现代化，易于上手。</p><p>在供应商风险管控方面，它整合了外部大数据，可以提供供应商的工商、司法、舆情等多维度风险监控和预警，这是个很实用的亮点。</p><p><strong>适合谁用</strong>：希望快速部署一套成熟、完整SRM系统的中大型企业，特别是对供应商风险有主动管理需求的企业。它降低了从零自研的风险和成本。</p><p><strong>需要注意</strong>：作为标准化SaaS产品，在应对极端个性化的业务流程时，灵活性可能不如低代码/无代码平台。<br/><img width="723" height="364" referrerpolicy="no-referrer" src="/img/bVdnH7f" alt="" title="" loading="lazy"/></p><p><strong>6. 携客云</strong></p><p><strong>核心特点</strong>：SaaS模式，轻量化，以“协同”为核心，实施快</p><p>携客云主打 “轻量化、易实施” 的SaaS SRM。它的核心价值在于快速解决制造企业与供应商之间的 “协同效率” 问题，比如订单确认、交货、对账等高频场景。</p><p>它的供应商门户做得很轻便，供应商上手门槛低。通过它，企业可以快速实现采购订单发布、送货预约、质量反馈、对账确认等业务的在线化，显著减少打电话、发邮件的低效沟通。</p><p><strong>适合谁用</strong>：广大中小制造企业，作为ERP的延伸，首要解决与供应商的日常业务协同问题。需求明确、预算有限、希望快速上线看到效果的企业可以重点关注。</p><p><strong>需要注意</strong>：在战略寻源、深度供应商绩效分析、复杂业务流程管控等更深层的管理需求上，功能可能不如前面几款全面。<br/><img width="723" height="368" referrerpolicy="no-referrer" src="/img/bVdnH7i" alt="" title="" loading="lazy"/></p><p><strong>7. 企企通</strong></p><p><strong>核心特点</strong>：平台化思路，强调连接与生态</p><p>企企通的SRM平台同样强调协同，但其特色在于 “平台化” 和 “连接能力” 。它致力于成为连接采购方和供应商的协作平台。除了常规的SRM功能外，它在 非生产性物料采购、电商化采购 方面有特色方案，支持企业搭建内部采购商城。它也具备较强的集成能力，可以与企业内部ERP、OA等系统对接，实现流程和数据贯通。</p><p><strong>适合谁用</strong>：注重与供应商建立在线化协作生态，特别是间接物料采购（MRO）需求旺盛的大中型企业。也适合希望整合分散采购渠道的企业。</p><p><strong>需要注意</strong>：平台的综合性强，企业需要明确自身核心需求是“管理”还是“连接协同”，以便判断是否匹配。<br/><img width="723" height="349" referrerpolicy="no-referrer" src="/img/bVdnH7j" alt="" title="" loading="lazy"/><br/><strong>8. 浪潮云</strong></p><p><strong>核心特点</strong>：贴合大型集团管控需求，尤其在高安全要求行业有积累</p><p>浪潮的云ERP中包含SRM解决方案，其优势在于服务 <strong>大型集团企业、国有企业</strong> 的经验。在供应商集中管控、分级管理、采购合规性、审计追溯等方面有较深的设计。对于有严格内控和合规性要求的行业，如国资、军工等，是重点考察对象。</p><p>功能上，支持集中采购、分散采购等多种模式，与浪潮的财务、预算系统也能深度集成。</p><p><strong>适合谁用</strong>：大型集团、国有企业、对采购合规性和集中管控有刚性要求的组织。</p><p><strong>需要注意</strong>：产品和实施风格相对“稳重”，在用户体验和敏捷性上可能不是其首要追求。<br/><img width="723" height="353" referrerpolicy="no-referrer" src="/img/bVdnH7k" alt="" title="" loading="lazy"/></p><p><strong>三、总结与建议：如何选择？</strong></p><p>看了一圈，你可能更纠结了。别急，最后给你一些落地的建议：</p><p>如果业务<strong>灵活多变</strong>，<strong>支道</strong>这类无代码平台的长远适配性更好。预算不仅要看首次投入，更要评估3-5年的总拥有成本。并且一定要<strong>看演示、做试点，</strong>功能列表都是美好的，真实体验才能暴露问题。要求厂商用你的真实数据（脱敏后）或模拟场景进行演示。条件允许的话，选择一个非核心采购品类或一个分子公司进行试点，这是最有效的试金石。</p><p><strong>供应商管理系统</strong>的选型，没有“最好”，只有“最适合”。它不仅是采购工具，更是企业供应链竞争力的数字化体现。</p><p>花时间厘清自身需求，结合以上测评信息，相信你能找到最适合自己提升管理效率、降低运营成本的优秀系统。</p>]]></description></item><item>    <title><![CDATA[Unity实现Nanite 本文系转载，阅读原文
https://zhuanlan.zhihu.co]]></title>    <link>https://segmentfault.com/a/1190000047557816</link>    <guid>https://segmentfault.com/a/1190000047557816</guid>    <pubDate>2026-01-22 12:05:26</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>【USparkle专栏】如果你深怀绝技，爱“搞点研究”，乐于分享也博采众长，我们期待你的加入，让智慧的火花碰撞交织，让知识的传递生生不息！</p><hr/><blockquote><h3><strong>一、前序</strong></h3></blockquote><p><strong>1. 介绍</strong><br/>Nanite是UE5中虚拟几何体（Virtualized Geometry System）的系统，主要用途是高效率渲染的高面数模型。Nanite会为模型自动生成LOD结构，与传统LOD不同，Nanite的LOD不再是每个模型的，而是精细到模型中的局部区域，艺术家不需再为制作或处理LOD烦恼。并且还能享有GPU Driven的高效剔除，单个绘制调用的好处。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047557818" alt="" title=""/></p><p><strong>2. 技术要点</strong><br/>Nanite技术结合了多种技术做到了高效渲染：</p><ol><li>Cluster Rendering：由Cluster组织三角形，可以享有更高效的剔除。</li><li>Auto LOD：通过Graph Partitioning技术划分和简化模型构建LOD，并且把数据组织成BVH结构在Runtime时候可以高效地并行选择LOD，通过这种方式构建的LOD过渡非常丝滑。</li><li>GPU Driven Pipeline：由GPU驱动的绘制，减少了CPU的性能开销。</li><li>Occlusion Culling：更细颗粒的遮挡剔除，用于剔除不可见的三角形。</li><li>Hardware/Software Rasterization：由于小三角形对于硬件光栅化非常不友好，所以针对这些三角形用Compute Shader执行软光栅提高效率。</li><li>Visibility Buffer：利用Visibility Buffer减少Overdraw，进一步提高GPU效率。</li><li>Streaming：加载只看到的相关数据，减少几何体对内存的压力。</li></ol><p><strong>3. 本文效果</strong><br/>由于Nanite系统非常庞大和有非常多的工程细节要处理，所以本文会简化和略过一些东西，仅实现核心部分，而且会与有UE5的版本有点出入。</p><p>下图是本文实现的效果，每个色块是一个三角形，可以看出LOD切换和相机剔除都非常丝滑。</p><p>色块表示三角面<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047557819" alt="" title="" loading="lazy"/></p><p>色块表示Cluster<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047557820" alt="" title="" loading="lazy"/></p><blockquote><h3><strong>二、实现</strong></h3></blockquote><p><strong>1. Clusterize</strong><br/>第一步，在离线阶段处理，将复杂的超高精度网格模型高效且合理地分割成更小、更易于管理的簇（Cluster），每个Cluster最多128个三角形。这种划分不是简单的切割，而是旨在最小化簇与簇之间连接的边数（即切割大小），同时保持每个簇的大小大致均衡。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047557821" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047557822" alt="" title="" loading="lazy"/></p><p>UE使用的Partition是Metis库：<br/><a href="https://link.segmentfault.com/?enc=jFIama9AHxGwqfiSLc9oKw%3D%3D.qnhGN7PR8sH5OMg2R7RLc80vUsRaVgJh3DPzoXFzrrbQsJe%2FWE0fg7lXlwO18Hj%2F" rel="nofollow" target="_blank"/><a href="https://link.segmentfault.com/?enc=dbZWfgBHI4KBuhG3F1vizw%3D%3D.1O5dl3Q1mIM2Fld8oq69ba9LJKFdjhH9jXavE58Zie6LgrTUT990v0BueGQJexat" rel="nofollow" target="_blank">https://github.com/KarypisLab/METIS</a></p><p>实现代码可以参考UE5的源码部分：<br/>UnrealEngine-release\Engine\Source\Developer\NaniteBuilder\Private\NaniteBuilder.cpp</p><p>本文使用meshoptimizer实现Mesh的切分Cluster和Partition功能，这个库功能还有优化Over Draw，Shadow Depth Index等功能：<br/><a href="https://link.segmentfault.com/?enc=I%2Fm5xna8XvlVITdYshbUvQ%3D%3D.%2F5KpcQ9rYEByP5%2BS%2B1MBhPM6%2Fp83jKpR%2BAEN95v5FR4M0Ltq8oLlXYmbY1ykmeTV" rel="nofollow" target="_blank"/><a href="https://link.segmentfault.com/?enc=RWVNXT89UHeL%2FOJsmIAVHg%3D%3D.Ya4jEXTaMlTlWXJHgktb1RyWwMNEDXzmsreIc%2BE9LU74rgT9rh1TVHzagco0oiuC" rel="nofollow" target="_blank">https://github.com/zeux/meshoptimizer</a></p><p>我们新建一个C++导出DLL的工程，封装几个主要函数让Unity可以使用。其实代码量不多，翻译成C#直接用也可以。</p><p>分别是：</p><ul><li>meshopt_buildMeshlets（构建Cluster）</li><li>meshopt_partitionClusters（Cluster划分Partition）</li><li>meshopt_buildMeshletsBound（计算Cluster数量）</li><li>meshopt_computeSphereBounds（合并BoundsSphere）</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047557823" alt="" title="" loading="lazy"/></p><p>在C#中引用这些函数：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047557824" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047557825" alt="" title="" loading="lazy"/></p><pre><code>unsafe static List&lt;Cluster&gt; clusterize(Vector3[] vertices, int[] indices)
    {
        constint max_vertices = 192; // TODO: depends on kClusterSize, also may want to dial down for mesh shaders
        constint max_triangles = kClusterSize; //128
        constint min_triangles = (kClusterSize / 3) &amp; ~3;
        constfloat split_factor = 2.0f;
        constfloat fill_weight = 0.75f;
        int max_meshlets = BuildMeshletsBound(indices.Length, max_vertices, max_triangles);//meshopt_buildMeshletsBound 
        var meshlets = new Meshlet[max_meshlets * 2];
        var meshlet_vertices = newint[max_meshlets * max_vertices];
        var meshlet_triangles = newbyte[max_meshlets * max_triangles * 3];
        var meshlet_count = BuildMeshletFlex(meshlets, meshlet_vertices, meshlet_triangles, indices, indices.Length, vertices, vertices.Length, sizeof(float) * 3, max_vertices, min_triangles, max_triangles, 0.0f,
            split_factor);//meshopt_buildMeshlets 
        List&lt;Cluster&gt; clusters = new List&lt;Cluster&gt;(meshlet_count);
        for (int i = 0; i &lt; meshlet_count; i++)
        {
            ref Meshlet meshlet = ref meshlets[i];
            fixed (int* ptr = &amp;meshlet_vertices[meshlet.vertex_offset])
            {
                fixed (byte* ptr2 = &amp;meshlet_triangles[meshlet.triangle_offset])
                {
                    OptimizeMeshlet(ptr, ptr2, (int)meshlet.triangle_count, (int)meshlet.vertex_count);
                }
            }

            Cluster cluster = new Cluster();
            cluster.indices = newint[meshlet.triangle_count * 3];
            for (int j = 0; j &lt; meshlet.triangle_count * 3; ++j)
                cluster.indices[j] =
                    meshlet_vertices[meshlet.vertex_offset + meshlet_triangles[meshlet.triangle_offset + j]];

            cluster.parent.error = float.MaxValue;
            clusters.Add(cluster);
        }

        return clusters;
    }</code></pre><p>然后可以直接通过meshopt_buildMeshlets函数，获得每个cluster的indexs。</p><p><strong>2. Build DAG</strong><br/>有了这些Cluster，就可以构建“LOD”了，只需要循环这个操作：打组-&gt;合并-&gt;减面-&gt;clusterize。如下图：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047557826" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047557827" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047557828" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047557829" alt="" title="" loading="lazy"/></p><p>这个过程感觉就像Mipmap一样，一层一层往上合并和简化，并记录一个Err误差值和Bounds用于运行时LOD选择用。而这些合并的的节点就叫做Cluster Group。最后得出一个DAG（有向无环图，Directed Acyclic Graph）的结构。</p><pre><code>public struct ClusterGroup
    {
        public List&lt;int&gt; Children;
        public Vector3 Bounds;
        publicfloat radius;
        public Vector3 LODBounds;
        publicfloat MinLODError;
        publicfloat MaxParentLODError;
        publicint MipLevel;
    } 

publicclassNaniteSubMesh
    {
        public List&lt;ClusterGroup&gt; clusterGroupList;
        public List&lt;Cluster&gt; clusterList;
        publicint maxMipLevel;
    }

static NaniteSubMesh Nanite(Vector3[] vertices,Vector3[] normals, int[] indices)
    {
        NaniteSubMesh res = new NaniteSubMesh();
        List&lt;ClusterGroup&gt; clusterGroupList = new List&lt;ClusterGroup&gt;();
        var clusters = clusterize(vertices, indices);
        res.clusterList = clusters;
        res.clusterGroupList = clusterGroupList;
        res.maxMipLevel = 0;
        for (int i = 0; i &lt; clusters.Count; ++i)
        {
            var c = clusters[i];
            c.self = Bounds(vertices, clusters[i].indices, 0f);
            c.mip = 0;
            clusters[i] = c;
        }

        List&lt;int&gt; pending = new List&lt;int&gt;(clusters.Count);
        int[] remap = newint[vertices.Length];
        for (int i = 0; i &lt; remap.Length; ++i)
            remap[i] = i;
        for (int i = 0; i &lt; clusters.Count; ++i)
            pending.Add(i);

        int curMip = 1;
        byte[] locks = newbyte[vertices.Length];
        while (pending.Count &gt; 1)
        {
            List&lt;List&lt;int&gt;&gt; groups = partition(clusters, pending, remap, vertices);
            if (kUseLocks)
                lockBoundary(locks, groups, clusters, remap);
            pending.Clear();
            List&lt;int&gt; retry = new List&lt;int&gt;();
            int triangles = 0;
            int stuck_triangles = 0;
            for (int i = 0; i &lt; groups.Count; ++i)
            {
                var curGroupClusters = groups[i];
                if (curGroupClusters.Count == 0)
                {
                    continue; // metis shortcut
                }

                List&lt;int&gt; merged = new List&lt;int&gt;(vertices.Length);
                for (int j = 0; j &lt; curGroupClusters.Count; ++j)
                {
                    merged.AddRange(clusters[curGroupClusters[j]].indices);
                }
                LODBounds groupb = boundsMerge(clusters, curGroupClusters);
                ClusterGroup clusterGroup = new ClusterGroup();
                clusterGroup.Bounds = groupb.center;
                clusterGroup.MaxParentLODError = groupb.error;
                clusterGroup.radius = groupb.radius;
                clusterGroup.Children = new List&lt;int&gt;(merged.Count);
                clusterGroup.MipLevel = curMip - 1;
                for (int j = 0; j &lt; curGroupClusters.Count; ++j)
                {
                    clusterGroup.Children.Add(curGroupClusters[j]);
                }
                clusterGroupList.Add(clusterGroup);

                // aim to reduce group size in half
                int target_size = (merged.Count / 3) / 2 * 3;
                float error = 0f;
                var simplified = simplify(vertices, normals, merged.ToArray(), kUseLocks ? locks : null, target_size,
                    ref error);
                if (simplified.Count &gt; merged.Count * kSimplifyThreshold)
                {
                    stuck_triangles += merged.Count / 3;
                    for (int j = 0; j &lt; curGroupClusters.Count; ++j)
                    {
                        retry.Add(curGroupClusters[j]);
                    }

                    continue; // simplification is stuck; abandon the merge
                }

                // enforce bounds and error monotonicity
                // note: it is incorrect to use the precise bounds of the merged or simplified mesh, because this may violate monotonicity

                var split = clusterize(vertices, simplified.ToArray());
                groupb.error += error; // this may overestimate the error, but we are starting from the simplified mesh so this is a little more correct
                // update parent bounds and error for all clusters in the group
                // note that all clusters in the group need to switch simultaneously so they have the same bounds
                for (int j = 0; j &lt; curGroupClusters.Count; ++j)
                {
                    int clusterIndex = curGroupClusters[j];
                    var t = clusters[clusterIndex];
                    t.parent = groupb;
                    clusters[clusterIndex] = t;
                }

                for (int j = 0; j &lt; split.Count; ++j)
                {
                    var sj = split[j];
                    sj.self = groupb;
                    sj.mip = curMip;
                    split[j] = sj;
                    clusters.Add(sj); // std::move
                    pending.Add(clusters.Count - 1);
                    triangles += sj.indices.Length / 3;
                }
            }

            curMip++;
        }

        if (pending.Count == 1)
        {
            var c = clusters[pending[0]];
            ClusterGroup clusterGroup = new ClusterGroup();
            clusterGroup.Bounds = c.self.center;
            clusterGroup.MaxParentLODError = c.self.error;
            clusterGroup.radius = c.self.radius;
            clusterGroup.Children = new List&lt;int&gt;(1);
            clusterGroup.MipLevel = curMip - 1;
            clusterGroup.Children.Add(pending[0]);
            clusterGroupList.Add(clusterGroup);
        }

        res.maxMipLevel = curMip - 1;
        return res;
    }

static void lockBoundary(byte[] locks, List&lt;List&lt;int&gt;&gt; groups, List&lt;Cluster&gt; clusters, int[] remap)
    {
        // for each remapped vertex, keep track of index of the group it's in (or -2 if it's in multiple groups)
        int[] groupmap = newint[locks.Length];
        for (int i = 0; i &lt; groupmap.Length; ++i)
            groupmap[i] = -1;

        for (int i = 0; i &lt; groups.Count; ++i)
        {
            var c = groups[i];
            for (int j = 0; j &lt; c.Count; ++j)
            {
                var indices = clusters[c[j]].indices;
                for (int k = 0; k &lt; indices.Length; ++k)
                {
                    var v = indices[k];
                    var r = remap[v];

                    if (groupmap[r] == -1 || groupmap[r] == i)
                        groupmap[r] = i;
                    else
                        groupmap[r] = -2;
                }
            }
        }

        // note: we need to consistently lock all vertices with the same position to avoid holes
        for (int i = 0; i &lt; locks.Length; ++i)
        {
            var r = remap[i];
            locks[i] = (byte)((groupmap[r] == -2) ? 1 : 0);
        }
    }</code></pre><p>这样我们得到各级Mip的一系列Clusters。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047557830" alt="" title="" loading="lazy"/></p><p><strong>3. 加速结构</strong><br/>即使把三角形划分成Clusters数量也太多，使用Compute Shader来做并行结算效率也不高，于是Nanite就使用了BVH来作为ClusterGroup的加速结构，然后配合Persistent Threads做查找过滤。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047557831" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047557832" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047557833" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047557834" alt="" title="" loading="lazy"/></p><p>Persistent Threads遍历BVH部分，有兴趣可以参考UE5源码：<br/>Shaders\Private\Nanite\NaniteClusterCulling.usf</p><p>UE5中也有不使用Persistent Threads的流程，应该说一般默认就是不使用的。</p><p>UE5源码部分<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047557835" alt="" title="" loading="lazy"/></p><p>个人认为Persistent Threads方案在GPU遍历这种BVH结构有点暴力和重度，所以简化了一下，把多个Cluster合并成一个剔除单元（Part），先并行对Part做剔除，再对Part里的Cluster去做并行剔除，两层结构来加速作为Persistent Threads的一个简单替代方案。</p><p>然后把多个Part组织成Page用于分块加载。材质处理细节也不同，UE5的材质是每个Cluster会记录MaterialRange，简单起见这里实现是每个SubMesh会去构建独立的Clusters。</p><p>代码如下：</p><pre><code> [Serializable]
    publicstruct NaniteCluster
    {
        publicint indiceIndex;
        publicint indiceCount;
        publicfloat selfErrer;
        publicfloat parentErrer;
        public Vector4 selfSphere;
        public Vector4 parentSphere;
        publicint subMeshID;
        publicint vertexOffset;
    };
    
    [Serializable]
    publicstruct NaniteClusterGroup
    {
        publicint ClusterStart;
        publicint ClusterCount;
        public Vector3 Bounds;
        publicfloat radius;
        public Vector3 LODBounds;
        publicfloat MinLODError;
        publicfloat MaxParentLODError;
        publicint MipLevel;
    }

    [Serializable]
    publicstruct NaniteMeshPart
    {
        publicint ClusterStart;
        publicint ClusterCount;
        public Vector4 selfSphere;
        publicfloat MaxParentLODError;
    }</code></pre><pre><code>public classNaniteSubMesh
    {
        public List&lt;ClusterGroup&gt; clusterGroupList;
        public List&lt;Cluster&gt; clusterList;
        publicint maxMipLevel;
    }
publicclassBuildPart
    {
        public List&lt;int&gt; clusterList;
        publicint mip;
        publicint subMesh;

    }
public static void BuildNaniteMesh(Mesh mesh)
    {
          var vertices = mesh.vertices;
        var normals = mesh.normals;
        var uvs = mesh.uv;

        int subMeshCount = mesh.subMeshCount;
        int totalClusterCount = 0;
        int totalIndexCount = 0;
        List&lt;NaniteSubMesh&gt; subMeshList = new List&lt;NaniteSubMesh&gt;();
        for (int i = 0; i &lt; subMeshCount; i++)
        {
            var triangles = mesh.GetTriangles(i);
            var subMesh = Nanite(vertices,normals,triangles);
            subMeshList.Add(subMesh);
            totalClusterCount += subMesh.clusterList.Count;
        }

        List&lt;BuildPart&gt; buildPartsList = new List&lt;BuildPart&gt;(totalClusterCount);
        int MAX_PART_PERPAGE = 128;
        int MAX_CLUSTER_PERPART = 8;

        for (int subMeshIndex = 0; subMeshIndex &lt; subMeshList.Count; subMeshIndex++)
        {
            var subMesh = subMeshList[subMeshIndex];
            List&lt;Cluster&gt; clusters = subMesh.clusterList;
            var groupsList = subMesh.clusterGroupList;
            BuildPart buildPart = null;
            for (int i = 0; i &lt; groupsList.Count; i++)
            {
                var gIndex = i; // sortGroups[i].OldIndex;
                var g = groupsList[gIndex];
                var childs = g.Children;
                for (int c = 0; c &lt; childs.Count; c++)
                {
                    int cIndex = childs[c];
                    int cMip = clusters[cIndex].mip;
                    totalIndexCount += clusters[cIndex].indices.Length;
                    //new Part
                    if (buildPart == null || buildPart.clusterList.Count &gt;= MAX_CLUSTER_PERPART ||
                        buildPart.mip != cMip)
                    {
                        buildPart = new BuildPart();
                        buildPart.clusterList = new List&lt;int&gt;(MAX_CLUSTER_PERPART);
                        buildPart.mip = cMip;
                        buildPart.subMesh = subMeshIndex;
                        buildPartsList.Add(buildPart);
                    }

                    buildPart.clusterList.Add(cIndex);
                }
            }
        }

        int buildPartCount = buildPartsList.Count;
        NaniteMeshPage[] pageArray = new NaniteMeshPage[(buildPartCount+(MAX_PART_PERPAGE-1))/MAX_PART_PERPAGE];//ceil
        List&lt;int&gt; tempIndiceList = new List&lt;int&gt;(totalIndexCount);
        List&lt;int&gt; mipLists = new List&lt;int&gt;(totalClusterCount);
        int partIndex = 0;
        for (int i = 0; i &lt; pageArray.Length; i++)
        {
            //create new page
            var p = ScriptableObject.CreateInstance&lt;NaniteMeshPage&gt;();
            pageArray[i] = p;
            tempIndiceList.Clear();
            int partCount =  (i == (pageArray.Length -1)) ? (buildPartCount % MAX_PART_PERPAGE) : MAX_PART_PERPAGE;
            p.parts = new NaniteScene.NaniteMeshPart[partCount];
            List&lt;NaniteScene.NaniteCluster&gt; pageClusters = new List&lt;NaniteScene.NaniteCluster&gt;(partCount * MAX_CLUSTER_PERPART);
            for (int j = 0; j &lt; partCount; j++)
            {
                var buildPart = buildPartsList[partIndex];
                var buildPartCluster = buildPart.clusterList;
                //create part
                var part = new NaniteScene.NaniteMeshPart();
                part.ClusterStart = pageClusters.Count; //local index
                part.ClusterCount = buildPartCluster.Count;
                int subMeshID = buildPart.subMesh;
                float maxParentErr = 0f;
                var clusters = subMeshList[subMeshID].clusterList;
                for (int c = 0; c &lt; buildPartCluster.Count; c++)
                {
                    var cluster = clusters[buildPartCluster[c]];
                    mipLists.Add(cluster.mip); 
                    //create Cluster
                    NaniteScene.NaniteCluster naniteCluster = new NaniteScene.NaniteCluster();
                    naniteCluster.indiceIndex = tempIndiceList.Count;
                    naniteCluster.indiceCount = cluster.indices.Length;
                    naniteCluster.parentErrer = cluster.parent.error;
                    naniteCluster.parentSphere = new Vector4(cluster.parent.center.x,cluster.parent.center.y,cluster.parent.center.z, cluster.parent.radius);
                    naniteCluster.selfErrer = cluster.self.error;
                    naniteCluster.selfSphere = new Vector4(cluster.self.center.x,cluster.self.center.y,cluster.self.center.z, cluster.self.radius);
                    naniteCluster.subMeshID = subMeshID;
                    tempIndiceList.AddRange(cluster.indices);
                    maxParentErr = Mathf.Max(naniteCluster.parentErrer, maxParentErr);
                    pageClusters.Add(naniteCluster);
                }

                LODBounds partBounds =  boundsMerge(clusters, buildPartCluster,true);
                part.selfSphere = new Vector4(partBounds.center.x,partBounds.center.y,partBounds.center.z,partBounds.radius);
                part.MaxParentLODError = maxParentErr;
                p.parts[j] = part;
                partIndex++;
            }
            p.clusterArray = pageClusters.ToArray();
            p.indiceArray = tempIndiceList.ToArray();
            p.clusterMip = mipLists.ToArray();
        }

        string fileName = AssetDatabase.GetAssetPath(mesh);
        string extension = Path.GetExtension(fileName);
        fileName = fileName.Replace(extension, "");
        //Build page
        int totalVerts = 0;
        for (int i = 0; i &lt; pageArray.Length; i++)
        {
            var page = pageArray[i];
            var clusterArray = page.clusterArray;
            var indiceArray = page.indiceArray;
            Dictionary&lt;int,int&gt; indicesMap = new Dictionary&lt;int,int&gt;();
            List&lt;Vector3&gt; tempVerts = new List&lt;Vector3&gt;(vertices.Length);
            List&lt;Vector3&gt; tempNormals = new List&lt;Vector3&gt;(vertices.Length);
            List&lt;Vector2&gt; tempUVs = new List&lt;Vector2&gt;(vertices.Length);
            List&lt;int&gt; newIndices = new List&lt;int&gt;(totalIndexCount);
            for (int c = 0; c &lt; clusterArray.Length; c++)
            {
                refvar cluster = ref clusterArray[c];
                var indexStart = cluster.indiceIndex;
                var indexEnd = indexStart+cluster.indiceCount;
                for (int index = indexStart; index &lt; indexEnd; index++)
                {
                    int vertIndex = indiceArray[index];
                    int newIndex;
                    if (!indicesMap.TryGetValue(vertIndex,out newIndex))
                    {
                        newIndex = newIndices.Count;
                        indicesMap.Add(vertIndex, newIndex);
                        tempVerts.Add(vertices[vertIndex]);
                        tempNormals.Add(normals[vertIndex]);
                        if (uvs.Length == 0)
                        {
                            tempUVs.Add(Vector2.zero);
                        }
                        else
                        {
                            tempUVs.Add(uvs[vertIndex]);
                        }

                        newIndices.Add(newIndex);
                    }

                    indiceArray[index] = newIndex;
                }
            }

            page.vertexStride = 5;//pos3 + uv2
            page.vertexData = newfloat[tempVerts.Count * page.vertexStride];
            page.vertexCount = tempVerts.Count;
            for (int v = 0; v &lt; tempVerts.Count; v++)
            {
                int vertexIndex = v * page.vertexStride;
                page.vertexData[vertexIndex + 0] = tempVerts[v].x;
                page.vertexData[vertexIndex + 1] = tempVerts[v].y;
                page.vertexData[vertexIndex + 2] = tempVerts[v].z;
                page.vertexData[vertexIndex + 3] = tempUVs[v].x;
                page.vertexData[vertexIndex + 4] = tempUVs[v].y;
            }
            totalVerts +=tempVerts.Count;
            string newPath = fileName + "_p"+i +".asset";
            AssetDatabase.CreateAsset(page, newPath);
        }
        AssetDatabase.Refresh();

        Debug.Log("mesh Vertx:"+vertices.Length +" mesh Nanite:"+ totalVerts + " cluster:"+totalClusterCount + "part:"+ buildPartCount +" page:"+pageArray.Length);
        NaniteMesh naniteMesh = ScriptableObject.CreateInstance&lt;NaniteMesh&gt;();
        {
            naniteMesh.subMeshCount = subMeshCount;
            naniteMesh.pageArray = new NaniteMeshPage[pageArray.Length];
            for (int i = 0; i &lt; pageArray.Length; i++)
            {
                string newPath = fileName + "_p" + i + ".asset";
                naniteMesh.pageArray[i] = AssetDatabase.LoadAssetAtPath&lt;NaniteMeshPage&gt;(newPath);
            }
        }

        var meshBound = mesh.bounds;
        naniteMesh.boundingSphere = meshBound.center;
        naniteMesh.boundingSphere.w = meshBound.extents.magnitude;
        string meshExt = "_mesh.asset";
        AssetDatabase.CreateAsset(naniteMesh, fileName + meshExt);
        AssetDatabase.Refresh();
    }</code></pre><p>到这里离线部分基本结束，可以得到一个Nanite的资源。当然UE5原文还做了很多操作，如BVH、Encode、编码、压缩、Page的划分、顶点属性优化等，个人认为这些都属于工程细节。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047557836" alt="" title="" loading="lazy"/></p><p><strong>4. 运行时资源</strong><br/>来到Runtime部分，我们需要把这个Nanite Mesh加载上来，方便起见，这里直接引用一下资源在脚本上，偷懒省略加载部分。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047557837" alt="" title="" loading="lazy"/></p><p>把资源、Object、材质信息整合起来，传到GPU的Buffer中。这里做法很不正式还是偷懒来处理。当然也可以用Compute Shader来更新Page数据到GPUBuffer中。</p><pre><code>    public static List&lt;NaniteRenderer&gt; renderers = new List&lt;NaniteRenderer&gt;();
    privatestatic SceneObject[] gpuObjects = new SceneObject[2048];
    //cluster -&gt; part -&gt; page
    publicstruct SceneObject
    {
        publicint naniteMeshID;
        public Matrix4x4 localToWorldMatrix;
        publicint materialIDOffset;
    }
    publicstruct NaniteRes
    {
        public Vector4 boundingSphere;
        publicint partIndex;
        publicint partCount;
    }

unsafe static void UpdateRenderList()
    {
         if(renderers.Count == 0)
            return;
        //object update
        if (renderers.Count &gt; gpuObjects.Length)
        {
            gpuObjects = new SceneObject[Mathf.NextPowerOfTwo(renderers.Count)];
        }

        objectCount = 0;
        maxPartCount = 0;
        naniteMeshes.Clear();
        materialList.Clear();
        List&lt;int&gt; materialIndices = new List&lt;int&gt;();
        for (int i = 0; i &lt; renderers.Count; i++)
        {
           var renderer = renderers[i];
           var nMesh = renderer.naniteMesh;
            foreach (var p in nMesh.pageArray)
           {
               maxPartCount += p.parts.Length;
               maxClusterCount += p.clusterArray.Length;
           }

           SceneObject obj = new SceneObject();
           obj.localToWorldMatrix = renderer.transform.localToWorldMatrix;
            //mesh index
           int index = naniteMeshes.IndexOf(nMesh);
           if (index &lt; 0)
           {
               index = naniteMeshes.Count;
               naniteMeshes.Add(nMesh);
           }
           obj.naniteMeshID = index;
           //mat indexs
           obj.materialIDOffset = materialIndices.Count;
           for (int m = 0; m &lt; renderer.materials.Length; m++)
           {
               var mat = renderer.materials[m];
               int matIndex = materialList.IndexOf(mat);
               if (matIndex &lt; 0)
               {
                   matIndex = materialList.Count;
                   materialList.Add(mat);
               }
               materialIndices.Add(matIndex);
           }
           gpuObjects[i] = obj;
           renderer.transformChanged = false;
           objectCount++;
        }

        if(candidateClusterBuffer!=null)
            candidateClusterBuffer.Dispose();
        candidateClusterBuffer = new GraphicsBuffer(GraphicsBuffer.Target.Structured, maxClusterCount *2, sizeof(int));

        if(visibleClusterBuffer != null)
            visibleClusterBuffer.Dispose();
        visibleClusterBuffer = new GraphicsBuffer(GraphicsBuffer.Target.Structured,maxClusterCount *2, sizeof(int));

        if (objectsBuffer != null)
            objectsBuffer.Dispose();
        objectsBuffer = new GraphicsBuffer(GraphicsBuffer.Target.Structured, objectCount, sizeof(SceneObject));
        objectsBuffer.SetData(gpuObjects,0,0,objectCount);

        if(visObjectsBuffer !=null)
            visObjectsBuffer.Dispose();
        visObjectsBuffer = new GraphicsBuffer(GraphicsBuffer.Target.Structured,objectCount, sizeof(int));

        int vertCount = 0;
        List&lt;NaniteCluster&gt; tempClusters = new List&lt;NaniteCluster&gt;(2048);
        List&lt;NaniteMeshPart&gt; tempParts = new List&lt;NaniteMeshPart&gt;(2048);
        List&lt;NaniteRes&gt; naniteRes = new List&lt;NaniteRes&gt;(2048);
        List&lt;int&gt; tempIndices = new List&lt;int&gt;(2048 * 100);
        List&lt;float&gt; vertexDataList = new List&lt;float&gt;();
        //load page
        for (int nID = 0; nID &lt; naniteMeshes.Count; nID++)
        {
            NaniteRes res = new NaniteRes();
            var nMesh = naniteMeshes[nID];
            //填充到GPU
            var pages = nMesh.pageArray;
            res.partIndex = tempParts.Count;
            res.partCount = 0;
            res.boundingSphere = nMesh.boundingSphere;
            for (int p = 0; p &lt; pages.Length; p++)
            {
                var page = pages[p];
                var parts = page.parts;
                int vertOffset = vertCount;
                int indicesOffset = tempIndices.Count;
                int clusterOffset = tempClusters.Count;

                //add all cluster
                var clusters = page.clusterArray;
                for (int c = 0; c &lt; clusters.Length; c++)
                {
                    var cluster = clusters[c];
                    cluster.indiceIndex += indicesOffset;
                    cluster.vertexOffset = vertOffset;
                    tempClusters.Add(cluster);
                }

                //add all part
                for (int partIndex = 0; partIndex &lt; parts.Length; partIndex++)
                {
                    var part = parts[partIndex];
                    part.ClusterStart += clusterOffset;
                    tempParts.Add(part);
                    res.partCount++;
                }

                //add page data
                tempIndices.AddRange( page.indiceArray);
                vertexDataList.AddRange(page.vertexData);
                vertCount += page.vertexCount;
            }
            naniteRes.Add(res);
        }

        //TODO GPU Update Buffer
        if (naniteResBuffer != null)
            naniteResBuffer.Dispose();
        naniteResBuffer = new GraphicsBuffer(GraphicsBuffer.Target.Structured, naniteRes.Count, sizeof(NaniteRes));
        naniteResBuffer.SetData(naniteRes);

        if (partsBuffer != null)
            partsBuffer.Dispose();
        partsBuffer = new GraphicsBuffer(GraphicsBuffer.Target.Structured,tempParts.Count, sizeof(NaniteMeshPart));
        partsBuffer.SetData(tempParts);

        if (clusterBuffer != null)
            clusterBuffer.Dispose();
        clusterBuffer = new GraphicsBuffer(GraphicsBuffer.Target.Structured, tempClusters.Count, sizeof(NaniteCluster));
        clusterBuffer.SetData(tempClusters);


        if (indiceseBuffer != null)
            indiceseBuffer.Dispose();
        indiceseBuffer = new GraphicsBuffer(GraphicsBuffer.Target.Raw, tempIndices.Count, sizeof(int));
        indiceseBuffer.SetData(tempIndices);

        if(materialIndexBuffer!=null)
            materialIndexBuffer.Dispose();
        materialIndexBuffer = new GraphicsBuffer(GraphicsBuffer.Target.Structured,materialIndices.Count, sizeof(int));
        materialIndexBuffer.SetData(materialIndices);

        if(vertexDataBuffer!=null)
            vertexDataBuffer.Dispose();
        vertexDataBuffer = new GraphicsBuffer(GraphicsBuffer.Target.Raw, vertexDataList.Count,sizeof(float));
        vertexDataBuffer.SetData(vertexDataList);
    }

    //input object ID =&gt; 
    public unsafe static void UpdateNaniteScene()
    {
        if (renderListDirty)
        {
            UpdateRenderList();
           // UpdateRenderListGPU();
            renderListDirty = false;
        }

       for (int i = 0; i &lt; renderers.Count; i++)
       {
           var renderer = renderers[i];
           if (renderer.transformChanged)
           {
               gpuObjects[i].localToWorldMatrix = renderer.transform.localToWorldMatrix;
               renderer.transformChanged = false;
               transformDirty = true;
           }
       }

       if (objectsBuffer != null &amp;&amp; transformDirty)
           objectsBuffer.SetData(gpuObjects, 0, 0, objectCount);
    }</code></pre><p><strong>5. 剔除</strong><br/>这时离线时候已经把Clusters扁平化到数组中了，这些Clusters是可以并行进行剔除的，巧妙之处是他记录了父级的误差和自己的误差，当我们传入误差系数时候就可以独立地判断自己是否被剔除，而和上下级无关。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047557838" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047557839" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047557840" alt="" title="" loading="lazy"/></p><p>先从CPU发起剔除Compute Shader的Dispatch。这里因为组织数据时候就知道了所有Object最大的Parts/Cluster数量，所以直接用这个数去Dispatch了。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047557841" alt="" title="" loading="lazy"/></p><p>Objects剔除：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047557842" alt="" title="" loading="lazy"/></p><p>根据Object找到NaniteMesh的Parts进行Culling：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047557843" alt="" title="" loading="lazy"/></p><p>ClustersCulling：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047557844" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047557845" alt="" title="" loading="lazy"/></p><p><strong>6. 软光栅</strong><br/>略。</p><p><strong>7. VisibilityBuffer</strong><br/>VBuffer主要用来减少Overdraw，着色器直接输出InstanceID、ClusterID、材质ID。然后用这个VBuffer来计算顶点数据来着色。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047557846" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047557847" alt="" title="" loading="lazy"/></p><p>这个得益于GPUDriven的好处，一个DrawProceduralIndirect就可以绘制所有物体了：<br/>一次DrawProceduralIndirect绘制多个物体<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047557848" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047557849" alt="" title="" loading="lazy"/></p><p>VBuffer存哪些属性，多少位，都是工程细节这里就不考究了。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047557850" alt="" title="" loading="lazy"/></p><p><strong>8. 着色</strong><br/>有了VBuffer就需要逐材质进行绘制，原文是材质ID分Tile组合IndirectDraw画Quad的思想。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047557851" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047557852" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047557853" alt="" title="" loading="lazy"/></p><p>需要注意一下这里VBuffer通过三角重心插值求出的UV是不能直接采样贴图的，因为DDXY不对，所以需求重新计算，计算的代码放下面。并且利用SampleGrad（samplerName, coord2, dpdx, dpdy）来采样。</p><pre><code>uint MurmurMix(uint Hash)
{
    Hash ^= Hash &gt;&gt; 16;
    Hash *= 0x85ebca6b;
    Hash ^= Hash &gt;&gt; 13;
    Hash *= 0xc2b2ae35;
    Hash ^= Hash &gt;&gt; 16;
    return Hash;
}
float3 IntToColor(uint Index)
{
    uint Hash = MurmurMix(Index);

    float3 Color = float3
    (
        (Hash &gt;&gt; 0) &amp; 255,
        (Hash &gt;&gt; 8) &amp; 255,
        (Hash &gt;&gt; 16) &amp; 255
    );

    return Color * (1.0f / 255.0f);
}

struct FBarycentrics
{
    float3 Value;
    float3 Value_dx;
    float3 Value_dy;
};

float2 Lerp(float2 Value0, float2 Value1, float2 Value2, FBarycentrics Barycentrics, out float2 dxy)
{
    float2 Value = Value0 * Barycentrics.Value.x + Value1 * Barycentrics.Value.y + Value2 * Barycentrics.Value.z;
    dxy.x = Value0 * Barycentrics.Value_dx.x + Value1 * Barycentrics.Value_dx.y + Value2 * Barycentrics.Value_dx.z;
    dxy.y = Value0 * Barycentrics.Value_dy.x + Value1 * Barycentrics.Value_dy.y + Value2 * Barycentrics.Value_dy.z;

    return Value;
}

/** Calculates perspective correct barycentric coordinates and partial derivatives using screen derivatives. */
FBarycentrics CalculateTriangleBarycentrics(float2 PixelClip, float4 PointClip0, float4 PointClip1,
                                            float4 PointClip2, float2 ViewInvSize)
{
    FBarycentrics Barycentrics;
    PixelClip.y = 1 - PixelClip.y;
    PixelClip.xy = PixelClip.xy * 2 - 1;
    const float3 RcpW = rcp(float3(PointClip0.w, PointClip1.w, PointClip2.w));
    const float3 Pos0 = PointClip0.xyz * RcpW.x;
    const float3 Pos1 = PointClip1.xyz * RcpW.y;
    const float3 Pos2 = PointClip2.xyz * RcpW.z;

    const float3 Pos120X = float3(Pos1.x, Pos2.x, Pos0.x);
    const float3 Pos120Y = float3(Pos1.y, Pos2.y, Pos0.y);
    const float3 Pos201X = float3(Pos2.x, Pos0.x, Pos1.x);
    const float3 Pos201Y = float3(Pos2.y, Pos0.y, Pos1.y);

    const float3 C_dx = Pos201Y - Pos120Y;
    const float3 C_dy = Pos120X - Pos201X;

    const float3 C = C_dx * (PixelClip.x - Pos120X) + C_dy * (PixelClip.y - Pos120Y);
    // Evaluate the 3 edge functions
    const float3 G = C * RcpW;

    constfloat H = dot(C, RcpW);
    constfloat RcpH = rcp(H);

    // UVW = C * RcpW / dot(C, RcpW)
    Barycentrics.Value = G * RcpH;

    // Texture coordinate derivatives:
    // UVW = G / H where G = C * RcpW and H = dot(C, RcpW)
    // UVW' = (G' * H - G * H') / H^2
    // float2 TexCoordDX = UVW_dx.y * TexCoord10 + UVW_dx.z * TexCoord20;
    // float2 TexCoordDY = UVW_dy.y * TexCoord10 + UVW_dy.z * TexCoord20;
    const float3 G_dx = C_dx * RcpW;
    const float3 G_dy = C_dy * RcpW;

    constfloat H_dx = dot(C_dx, RcpW);
    constfloat H_dy = dot(C_dy, RcpW);

    Barycentrics.Value_dx = (G_dx * H - G * H_dx) * (RcpH * RcpH) * (2.0f * ViewInvSize.x);
    Barycentrics.Value_dy = (G_dy * H - G * H_dy) * (RcpH * RcpH) * (-2.0f * ViewInvSize.y);

    return Barycentrics;
}</code></pre><p>到这里其实基本完成了，利用IntToColor函数，可以对ClustersID或者IndexID对三角形或Cluster进行可视化。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047557854" alt="" title="" loading="lazy"/></p><blockquote><h3><strong>三、总结</strong></h3></blockquote><p>不得不说Nanite技术真是太强大了，但是也有很多工程细节需要处理，本文只是实现了其中一小部分。整体像是处理图片的Mipmap过程。</p><p><strong>参考</strong></p><p><a href="https://www.bilibili.com/video/BV17G4y1x7VX/?spm_id_from=333.337.search-card.all.click&amp;vd_source=07d4f665c85998941c935676c2e50d81" target="_blank">22.GPU驱动的几何管线-nanite (Part 2) | GAMES104-现代游戏引擎：从入门到实践</a></p><p><a href="https://www.bilibili.com/video/BV1MP4y1a7Hh/?spm_id_from=333.1387.search.video_card.click&amp;vd_source=07d4f665c85998941c935676c2e50d81" target="_blank">[UnrealCircle]Nanite技术简介 | Epic Games China 王祢</a></p><p><a href="https://link.segmentfault.com/?enc=OiCon8HoejdpYcHdz0%2F47g%3D%3D.MgJ2RkInLFJQ9U%2FMSDyTWmYoi1lSusaqkg3q2ydeLaMPDjCPx0DdCgRi%2FdtFNoLtlCBQKj5N0hl4hhGa0HusEr8SzVDYFanO0uRkXDXey5g5IqQ%2FfF7k0noaH%2FXMtMRy" rel="nofollow" target="_blank">Karis_Nanite_SIGGRAPH_Advances_2021_final.pdf</a></p><p><a href="https://link.segmentfault.com/?enc=6IMKalDSFCX2oRp0RdzeQg%3D%3D.4%2BEQEgpYdQXsuf3N2aGJRkU332rytDQd1bst4NYZ3mQmlhrRDdVwSajdaULXn1gFAWvx9upWpXHI%2F%2F7R%2BOS8mg%3D%3D" rel="nofollow" target="_blank">Nanite-GPU-Driven</a></p><p>UE5 Nanite源码入口：<br/>Engine\Source\Runtime\Renderer\Private\Nanite\NaniteCullRaster.cpp  <strong>（渲染流程入口）</strong><br/>Engine\Shaders\Private\Nanite\ <strong>（GPU的Shader入口）</strong><br/>Engine\Source\Developer\NaniteBuilder\Private\ <strong>（离线生成Nanite资源入口）</strong></p><hr/><p>这是侑虎科技第1939篇文章，感谢作者傻头傻脑亚古兽供稿。欢迎转发分享，未经作者授权请勿转载。如果您有任何独到的见解或者发现也欢迎联系我们，一起探讨。（QQ群：793972859）</p><p>作者主页：<a href="https://link.segmentfault.com/?enc=1isfSoQj5tZS6PcAUj2ewg%3D%3D.zIAiK6Leeh2UdiKdAG8BEsg25FqvnlySwnM24Hztwvr1%2BoaSDLjxRv1OFFhyhoVUdFE47UiPuDk1p98DoxVsoA%3D%3D" rel="nofollow" target="_blank"/><a href="https://link.segmentfault.com/?enc=Kpbq3Xj6qrF1D6IR2NcDsA%3D%3D.C3GG0nh8pNdzmzIcDO5HrqKrUdFYIwv%2FMZKlUV%2BAzNgVxV1sVSCDfRh11%2BCh3j3nkXHe97eUMkKn6tAMm18Txw%3D%3D" rel="nofollow" target="_blank">https://www.zhihu.com/people/tian-cai-ya-gu-shou</a></p><p>再次感谢傻头傻脑亚古兽的分享，如果您有任何独到的见解或者发现也欢迎联系我们，一起探讨。（QQ群：793972859）</p>]]></description></item><item>    <title><![CDATA[从 0 到 1 的智能体搭建之路 智能猫 ]]></title>    <link>https://segmentfault.com/a/1190000047557937</link>    <guid>https://segmentfault.com/a/1190000047557937</guid>    <pubDate>2026-01-22 12:04:49</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h3>🚀 快速回答 (Golden Answer)</h3><p>从 0 到 1 搭建智能体的核心逻辑是 “明确需求 → 选对工具 → 配置闭环 → 测试优化”：无需复杂编程，优先用零代码 / 低代码工具（如 Coze、LangGraph），先定义 “智能体要解决的具体任务”（如自动化办公、设计辅助），再通过 “设定角色 → 拆解任务 → 配置工具 → 添加反思逻辑” 完成搭建，最终通过测试迭代优化效果。核心是 “让智能体精准匹配需求”，而非追求技术复杂度。</p><h2>一、前置认知：先搞懂 “搭建智能体” 的核心前提</h2><h3>1.1 搭建智能体的核心目标：解决 “具体问题”</h3><p>智能体的核心价值是 “自主完成复杂任务”，搭建前必须明确 “它要帮你做什么”，避免盲目搭建。常见落地场景：</p><ul><li>个人场景：自动化周报生成、文献整理助手、学习笔记总结、购物比价监控；</li><li>职场场景：客户咨询智能客服、销售数据自动分析、市场调研报告生成、设计批量出图；</li><li>垂直场景：电商运营助手（商品上架 + 文案生成）、科研辅助（数据检索 + 分析）、教育答疑（学科知识点梳理）。</li></ul><h3>1.2 搭建智能体的核心逻辑：“感知 - 规划 - 行动 - 反思” 闭环</h3><p>无论用哪种工具，智能体的底层逻辑都是这四个环节的循环，搭建的本质就是 “配置这四个环节的规则”：</p><ul><li>感知：让智能体 “接收信息”（如用户需求、外部数据、工具反馈）；</li><li>规划：让智能体 “拆解任务”（如 “生成销售报告” 拆解为 “收集数据 → 清洗数据 → 分析 → 排版”）；</li><li>行动：让智能体 “执行步骤”（如调用 Excel、API 接口、设计工具完成具体操作）；</li><li>反思：让智能体 “修正错误”（如数据缺失时重新收集，格式错误时自动调整）。</li></ul><h3>1.3 零基础搭建的核心原则：“工具优先，不造轮子”</h3><p>无需从零开发大模型或底层架构，当前主流工具已提供 “可视化配置 + 现成组件”，零基础只需聚焦 “需求匹配” 和 “流程配置”，核心原则：</p><ol><li>优先选零代码工具（如 Coze、Notion AI Agent），快速验证需求；</li><li>复杂场景再用低代码工具（如 LangGraph、AutoGen），灵活适配个性化需求；</li><li>先搭建 “最小可用版本”（仅满足核心任务），再逐步添加功能。</li></ol><h2>二、工具选择：零基础必看的 “工具选型矩阵”</h2><p>不同工具的门槛、功能、适配场景差异较大，结合 “零基础友好度” 和 “落地实用性”，整理核心工具对比：</p><table><thead><tr><th>工具名称</th><th>技术门槛</th><th>核心优势</th><th>适配场景</th><th>学习成本</th></tr></thead><tbody><tr><td>Coze（扣子）</td><td>零代码</td><td>可视化配置，插件生态丰富（支持 Excel、数据库、设计工具等），可直接发布为小程序 / APP</td><td>个人助手、职场自动化、客服机器人</td><td>低（1-2 小时掌握基础配置）</td></tr><tr><td>Notion AI Agent</td><td>零代码</td><td>与文档深度融合，支持笔记整理、报告生成、任务管理，操作简单直观</td><td>学习助手、文献整理、文档自动化</td><td>极低（熟悉 Notion 即可上手）</td></tr><tr><td>LangGraph</td><td>低代码（Python 基础）</td><td>状态控制极强，支持复杂循环逻辑，适配高定制化任务</td><td>科研辅助、复杂数据分析、自动化办公流</td><td>中（需掌握基础 Python 和 Prompt 技巧）</td></tr><tr><td>AutoGen</td><td>低代码（Python 基础）</td><td>支持多智能体协作，角色分工明确，降低复杂任务的配置难度</td><td>软件工程、内容生产流水线、多步骤商业分析</td><td>中（需理解多智能体协同逻辑）</td></tr><tr><td>Make（原 Integromat）</td><td>零代码</td><td>专注工具集成，支持 1000 + 款软件对接，擅长自动化工作流串联</td><td>跨平台自动化（如微信 + Excel + 邮件协同）</td><td>低（重点学习工具对接逻辑）</td></tr></tbody></table><p>💡 零基础优先推荐：Coze（功能全、生态完善）或 Notion AI Agent（简单直观）；若需处理复杂任务，再学习 LangGraph（低代码门槛）。</p><h2>三、分步实操：用 Coze 从零搭建 “自动化周报生成智能体”（零代码案例）</h2><p>以 “自动收集 Excel 数据 → 生成周报 → 排版导出” 为核心任务，用 Coze 完成搭建，全程可视化操作，10 分钟即可完成基础版本：</p><h3>3.1 第一步：明确需求与角色设定</h3><ol><li>核心需求：用户上传 Excel 销售数据后，智能体自动计算核心指标（销售额、增长率、Top3 产品），生成结构化周报，支持 Word 导出；</li><li>角色设定：在 Coze 后台 “角色定义” 中填写 ——“你是职场销售周报生成助手，擅长从 Excel 数据中提取核心信息，生成逻辑清晰、格式规范的周报，语言正式专业”；</li><li>补充提示：添加 “周报格式要求”（如包含 “本周概况、核心数据、趋势分析、下周计划” 模块），让智能体输出更精准。</li></ol><h3>3.2 第二步：配置 “工具”（让智能体具备执行能力）</h3><p>智能体需要对接 Excel 和 Word 工具，才能完成数据读取和导出，操作步骤：</p><ol><li>在 Coze “插件市场” 中搜索 “Excel 解析” 和 “Word 导出” 插件，点击 “启用”；</li><li>配置插件权限：授权 Coze 读取用户上传的 Excel 文件（仅读取权限，保障数据安全）；</li><li>测试工具连通性：上传一份测试 Excel 数据，点击 “测试插件”，确认智能体能正常提取数据。</li></ol><h3>3.3 第三步：设计 “任务流程”（拆解执行步骤）</h3><p>在 Coze “流程设计” 模块，用可视化拖拽配置任务步骤，核心流程：</p><ol><li>触发条件：用户上传 Excel 文件并发送 “生成周报” 指令；</li><li>步骤 1：调用 “Excel 解析” 插件，提取数据（销售额、产品名称、日期等）；</li><li>步骤 2：智能体计算核心指标（本周总销售额、环比增长率、Top3 热销产品）；</li><li>步骤 3：按照预设格式生成周报文本；</li><li>步骤 4：调用 “Word 导出” 插件，生成周报文件并反馈给用户。</li></ol><h3>3.4 第四步：添加 “反思逻辑”（让智能体能修正错误）</h3><p>为避免数据缺失或格式错误，添加简单反思规则：</p><ol><li>在 “流程设计” 中添加 “判断节点”：若 Excel 数据缺失关键字段（如 “销售额”），则自动向用户发送 “请补充包含销售额字段的 Excel 文件”；</li><li>添加 “格式校验”：生成周报到导出前，自动检查是否包含预设的 4 个模块，缺失则补充完善。</li></ol><h3>3.5 第五步：测试与发布</h3><ol><li>测试验证：上传测试 Excel 数据，发送 “生成周报” 指令，查看智能体是否能正确完成全流程，重点检查数据计算准确性和格式规范性；</li><li>优化迭代：若存在格式混乱，补充 “周报格式细则”（如字体、行距、标题层级）；若数据计算错误，调整指标计算规则；</li><li>发布使用：测试通过后，点击 “发布”，可生成小程序 / 网页链接，直接在工作中使用。</li></ol><h2>四、进阶优化：让智能体更 “好用” 的 3 个关键技巧</h2><h3>4.1 精准 Prompt 优化：提升输出质量</h3><p>在角色定义中补充 “具体约束”，而非模糊描述，示例：</p><ul><li>差 Prompt：“生成专业的周报”；</li><li>好 Prompt：“生成销售周报，包含本周概况（30 字内）、核心数据（表格呈现）、趋势分析（200 字内）、下周计划（3 条核心动作），语言正式，避免口语化，数据保留 2 位小数”。</li></ul><h3>4.2 个性化适配：对接个人 / 企业知识库</h3><p>若智能体需要适配特定业务（如公司产品知识、个人工作习惯），可在 Coze 中上传 “知识库”（如公司产品手册、个人工作模板），让智能体学习后输出更贴合需求的结果。</p><h3>4.3 多智能体协作：解决复杂任务</h3><p>对于 “市场调研 → 数据分析 → 报告生成” 这类复杂任务，可搭建 “多智能体团队”：</p><ul><li>调研智能体：负责收集市场数据；</li><li>分析智能体：负责数据计算与趋势分析；</li><li>撰写智能体：负责生成最终报告； 在 Coze 中配置 “智能体间通信规则”，让它们协同完成任务，提升效率。</li></ul><h2>五、避坑指南：零基础搭建常见问题与解决方案</h2><table><thead><tr><th>常见问题</th><th>核心原因</th><th>解决方案</th></tr></thead><tbody><tr><td>智能体输出不符合预期（如格式混乱）</td><td>角色定义模糊，缺乏明确约束</td><td>补充具体的输出格式、语言风格、内容模块要求，用示例引导（如 “参考以下示例格式生成：【本周概况】XXX”）</td></tr><tr><td>智能体无法完成复杂任务（如数据计算错误）</td><td>任务拆解不细致，工具配置不当</td><td>将复杂任务拆分为更细的原子步骤，检查工具参数配置（如数据字段匹配），添加人工校验节点</td></tr><tr><td>智能体出现 “幻觉”（如编造数据）</td><td>缺乏真实数据支撑，规则约束不足</td><td>强制智能体仅基于用户上传的数据输出，添加 “禁止编造数据” 的规则，关键数据要求标注来源</td></tr><tr><td>工具调用失败（如无法读取 Excel）</td><td>插件权限不足，文件格式不兼容</td><td>重新授权插件权限，统一文件格式（如 Excel 保存为.xlsx 格式），测试工具连通性</td></tr></tbody></table><h2>六、FAQ：零基础搭建智能体最关心的核心问题</h2><h3>Q1：搭建智能体需要懂编程吗？</h3><p><strong>答：不需要。</strong> 零代码工具（如 Coze、Notion AI Agent）通过可视化拖拽和文字描述即可完成搭建；若需高定制化，仅需掌握基础 Python（低代码工具），但零基础可先从简单工具入手，无需一开始学习编程。</p><h3>Q2：搭建智能体需要花钱吗？</h3><p><strong>答：个人非商业使用基本免费。</strong> Coze、Notion AI Agent 等工具对个人用户提供免费额度（足够日常使用）；商业场景或高频率使用可能需要付费升级，但零基础入门无需付费。</p><h3>Q3：智能体的数据安全有保障吗？</h3><p><strong>答：选择正规工具即可保障。</strong> 主流工具（如 Coze、Notion）均有数据加密机制，且可设置 “仅自己可见”；避免上传敏感数据（如身份证、银行卡信息），若需处理企业数据，可选择企业版工具（提供私有部署选项）。</p><h3>Q4：搭建完成后，能修改功能吗？</h3><p><strong>答：可以。</strong> 所有主流工具均支持 “二次编辑”，可随时修改角色定义、任务流程、工具配置；建议根据使用反馈定期优化，让智能体更贴合需求。</p><h2>七、核心总结</h2><p>从 0 到 1 搭建智能体的核心不是 “技术攻关”，而是 “需求聚焦” 与 “流程拆解”：零基础用户无需畏惧，优先选择零代码工具，先明确 “智能体要解决的具体问题”，再通过 “角色定义 → 工具配置 → 流程设计 → 测试优化” 的步骤逐步落地，先搭建 “最小可用版本” 验证需求，再逐步进阶优化。</p><p>智能体的价值在于 “解放重复劳动”，搭建的关键是让它成为 “贴合自己需求的助手”，而非追求 “功能全而杂”。随着工具生态的完善，“人人都能搭建智能体” 已成为趋势，掌握这种 “人机协同” 的搭建能力，将大幅提升个人与工作效率。</p><h2>参考文献与工具资源</h2><ol><li>Coze（扣子）官方文档：《零代码智能体搭建指南》</li><li>LangGraph 官方教程：《低代码智能体开发实战》</li><li>腾讯云《智能体落地实践白皮书》（2025）</li><li>推荐学习平台：Coze 学院、Notion AI 帮助中心、GitHub AutoGen 示例仓库</li></ol><h3>核心关键词</h3><p>智能体搭建、从 0 到 1、零代码智能体、Coze、LangGraph、自动化办公、智能体工具、人机协同</p>]]></description></item><item>    <title><![CDATA[【剪映API】提取链接 失落的木瓜_esfWwz ]]></title>    <link>https://segmentfault.com/a/1190000047557940</link>    <guid>https://segmentfault.com/a/1190000047557940</guid>    <pubDate>2026-01-22 12:04:04</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>GET_URL API 接口文档</h2><h3>接口信息</h3><pre><code>POST /openapi/capcut-mate/v1/get_url</code></pre><h3>功能描述</h3><p>提取链接。该接口用于提取输入内容中的链接信息，用于多值返回变成单值返回。</p><h3>更多文档</h3><p>📖 更多详细文档和教程请访问：<a href="https://link.segmentfault.com/?enc=LhsUzGp46JpRFJzpY0uq5w%3D%3D.AWQi7n0Reo6FGV0ks9d811lAwlKYwHMyvTyxtk2JycE%3D" rel="nofollow" target="_blank">https://docs.jcaigc.cn</a></p><h3>请求参数</h3><pre><code class="json">{
  "output": "[魂牵梦萦https://sf.com；中国人https://jcaigc.cn],\"[]\""
}</code></pre><h4>参数说明</h4><table><thead><tr><th>参数名</th><th>类型</th><th>必填</th><th>默认值</th><th>说明</th></tr></thead><tbody><tr><td>output</td><td>string</td><td>✅</td><td>-</td><td>提取内容</td></tr></tbody></table><h4>参数详解</h4><h5>output</h5><ul><li><strong>类型</strong>: string</li><li><strong>说明</strong>: 需要提取链接的内容</li><li><strong>示例</strong>: <code>"[魂牵梦萦https://sf.com；中国人https://jcaigc.cn],\"[]\""</code></li></ul><h3>响应格式</h3><h4>成功响应 (200)</h4><pre><code class="json">{
  "output": "[魂牵梦萦https://sf.com；中国人https://jcaigc.cn],\"[]\""
}</code></pre><h4>响应字段说明</h4><table><thead><tr><th>字段名</th><th>类型</th><th>说明</th></tr></thead><tbody><tr><td>output</td><td>string</td><td>提取结果</td></tr></tbody></table><h4>错误响应 (4xx/5xx)</h4><pre><code class="json">{
  "detail": "错误信息描述"
}</code></pre><h3>使用示例</h3><h4>cURL 示例</h4><h5>1. 基本使用</h5><pre><code class="bash">curl -X POST https://capcut-mate.jcaigc.cn/openapi/capcut-mate/v1/get_url \
  -H "Content-Type: application/json" \
  -d '{
    "output": "[魂牵梦萦https://sf.com；中国人https://jcaigc.cn],\"[]\""
  }'</code></pre><h3>错误码说明</h3><table><thead><tr><th>错误码</th><th>错误信息</th><th>说明</th><th>解决方案</th></tr></thead><tbody><tr><td>400</td><td>output是必填项</td><td>缺少output参数</td><td>提供有效的output参数</td></tr><tr><td>500</td><td>提取链接失败</td><td>内部处理错误</td><td>联系技术支持</td></tr></tbody></table><h3>注意事项</h3><ol><li><strong>参数要求</strong>: output参数为必填项</li><li><strong>返回值</strong>: 当前版本直接返回输入的内容，不做额外处理</li></ol><h3>工作流程</h3><ol><li>验证必填参数（output）</li><li>调用服务层处理业务逻辑</li><li>返回处理结果</li></ol><h3>相关接口</h3><ul><li><a href="./create_draft.md" target="_blank">创建草稿</a></li></ul><hr/><p>📚 <strong>项目资源</strong>  <br/><strong>GitHub项目名称</strong>: capcut-mate</p>]]></description></item><item>    <title><![CDATA[智慧能源升维，实时云渲染重构管理新视角 点量实时云渲染 ]]></title>    <link>https://segmentfault.com/a/1190000047557984</link>    <guid>https://segmentfault.com/a/1190000047557984</guid>    <pubDate>2026-01-22 12:03:28</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><img width="723" height="406" referrerpolicy="no-referrer" src="/img/bVdnH94" alt="" title=""/></p><p>2026年初，工业和信息化部等五部门联合印发的《工业绿色微电网建设与应用指南（2026—2030年）》，为能源的数字化转型铺设了清晰的政策轨道。目前，全国已投入运行的工业绿色微电网项目超过300个，它们正从试点走向规模化。智慧能源的管理，正从传统的报表与经验，向一个全域可视、实时交互、智能决策的数字世界加速演进。</p><h2>01 政策引领，智慧能源按下“加速键”</h2><p>国家层面正在以前所未有的力度，推进能源系统的数字化转型。《工业绿色微电网建设与应用指南》明确将智慧能源管控系统，列为绿色微电网建设的核心内容之一。其目标是构建一个集成光伏、风电、储能、氢能等多能互补，并实现与大电网友好互动的综合能源系统。未来的能源管理，必须是数字化、可视化、智能化的。</p><h2>02 现实挑战：智慧能源的进阶痛点</h2><p>然而，理想蓝图在落地时，却面临着一系列棘手的现实挑战。当前的核心痛点可以概括为：“看不见、摸不清、调不动”。</p><ul><li>状态“看不见”：一个现代化的能源场站或微电网，包含成千上万的设备与传感器。传统分散的图表和报表，让管理者难以在短时间内掌握全局状态，如同“开盲盒”。</li><li>逻辑“摸不清”：SCADA、PLC、IoT等系统数据格式各异，形成信息壁垒。当发生故障时，运维人员需要跨多个系统排查，难以快速穿透网络层、服务器层、应用层，精准定位根源。</li><li>协同“调不动”：为了实现对复杂系统的精细化管理，数字孪生技术正成为标配。但这些高精度三维模型对终端电脑的图形性能要求极高，导致许多一线运维人员无法流畅使用，远程协同和移动办公更是困难重重。</li></ul><p><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdnIai" alt="" title="" loading="lazy"/></p><h2>03 破局关键：实时云渲染让智慧能源“轻装上阵”</h2><p>点量云流实时云渲染其核心原理是将海量三维模型的计算与渲染任务放在云端强大的服务器集群上完成，前端终端（无论是高性能工作站、普通笔记本，还是平板电脑）只需通过网页或轻量客户端，接收经过云端处理的视频流即可进行操作。</p><p>相较于传统网页3D效果受模型大小限制，点量云流实时云渲染能够在不消耗终端硬件性能的情况下，实现无需等待加载、即时打开与实时交互的体验。</p><p>这一转变带来了三个根本性改变：</p><ul><li>终端解放：运维人员不再受本地硬件性能束缚，用一台普通办公电脑或移动设备，就能流畅操控大型能源场（如风、电、煤等）的实景数字孪生模型。</li><li>数据安全：所有核心模型与数据始终保存在云端服务器，前端只传输视频流，从根本上杜绝了三维数字资产通过终端泄露的风险。</li><li>高效协同：不同地域的专家可以同时接入同一个三维场景，基于统一的、可视化的模型进行会诊、标注和决策，极大提升了跨团队协作效率。</li></ul><h2>04 实战图景：可视化如何重塑能源管理</h2><p>技术的价值，最终需要体现在真实的场景中。当实时云渲染技术卸下了硬件的重担，一系列曾经难以落地的应用，正悄然成为智慧能源管理的日常。<br/>1、运维：从“被动响应”到“主动预警”<br/>基于高精度数字孪生模型，系统能深度融合实时数据与AI算法，提前洞察设备亚健康状态，精准预测潜在故障。运维策略由此从紧急抢修的“被动处置”，转向计划性干预的“主动预防”。而这一切得以实现的关键，在于实时云渲染技术让这套复杂的三维预警系统，得以在各级管理中心的普通电脑上便捷访问与联动，使预防性维护真正触手可及。</p><p>2、管理：从“分散孤岛”到“全域一张图”<br/>传统管理中，物理设备、网络流量、业务数据往往分散于不同系统，形成信息壁垒。如今，通过实时云渲染技术，这些要素被整合进一个统一的动态三维界面，生成能源系统的“全景作战图”。结合云推流能力，无论是集控中心的大屏，还是巡检人员的移动终端，都能获得一致、流畅且可交互的全局视角，真正实现了“全域可视、全局可控”的集中化管控。</p><p><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdnIap" alt="" title="" loading="lazy"/></p><p>3、效率：从“人工跑腿”到“远程会诊”<br/>对于地处偏远的风电场或水电站，专家亲赴现场耗时费力。通过点量云渲染平台，专家在千里之外即可指挥实景复刻的虚拟现场，通过三维模型远程指导一线人员排查故障，将响应时间从数小时大幅压缩至分钟级。这不仅是距离的缩短，更意味着高精度模型得以在PC、平板等多终端安全、流畅地访问，显著提升了跨地域协同、应急指挥与人员培训的效能。</p><p>随着实时云渲染技术与能源体系的深度融合，智慧能源的管理模式将迎来根本性变革。高精度的能源系统数字孪生将不再受限于本地硬件，而是通过云推流技术，成为在任何终端均可流畅访问与协同操作的“活地图”。从宏观调度到微观运维，决策都将基于一张全域同步、实时可视、深度交互的动态图谱。</p><p>这不仅是技术的叠加，更是从“经验驱动”到“全景数据驱动”的智慧跃迁。一个更高效、更透明、更坚韧的能源时代，正借由这条“云端高速路”，清晰地向我们驶来。</p>]]></description></item><item>    <title><![CDATA[我的“Python海龟”诞生了一枚金蛋，孵出的却是“精灵” 李兴球 ]]></title>    <link>https://segmentfault.com/a/1190000047557994</link>    <guid>https://segmentfault.com/a/1190000047557994</guid>    <pubDate>2026-01-22 12:02:37</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>时光要追溯到2010年。在那之前，我一直用Visual Basic语言编写3D小游戏，乐在其中。那时我觉得Basic已经是非常简单的计算机语言了，但心中始终有一个疑问：有没有比Basic更友好、更适合少儿的编程语言呢？</p><p>于是我开始在网络上持续寻找。果然，不久后我遇到了Scratch 1.4版——那只来自美国麻省理工学院的小猫，一下子抓住了我的心。从此，我踏上了少儿编程教育的道路：2013年开办了编程培训班，2015年将Python正式纳入教学体系，到2018年时，我已积撰写了相当丰富的Python教学材料。</p><p>在教学过程中，我逐渐感到Python内置的turtle（海龟作图）模块功能有些局限。于是，我打开它的源代码文件turtle.py，仔细研究其结构，并从2019年开始，基于Python turtle模块持续开发一个更强大的扩展——Python精灵模块（sprites）。这个模块的核心是一个叫做Sprite的类，它大幅增强了海龟的功能，例如实现了像素级的碰撞检测等。如今，任何人都可以通过pip install sprites来安装并使用它。</p><p>最近几年，我将更多精力投入信息学奥赛的教学中，整日“苦思冥想”各种算法难题。2025年8月，暑假班结束后，我又开始思考另一个问题：如果C++的入门教学能像Python turtle一样直观、有趣，那不就能为中国更多青少年打开编程的大门吗？</p><p>为此，我在GitHub上搜索已有的类似成果，也尝试了一些用C或C++编写的“类turtle”库，例如小熊猫C++内置的C语言海龟作图、GoC等，甚至购买了相关教材准备投入教学。但最终，我并没有采用它们。原因何在？</p><p>小熊猫C++中的海龟作图功能，作者显然缺乏Python少儿编程的教学背景。我曾联系他，希望将命令设计得接近Python turtle的风格，但毕竟不能一直麻烦别人，后来也就作罢。GoC则为了降低输入难度，将命令简化为单个或两个字符（如pen.o），其命令集较小，功能也相对有限。它主要依赖在线环境，作者并未提供独立的编辑器（早期离线版需搭配Notepad++使用）。GoC更像为信息学奥赛选拔苗子而设计的前置课程——网上甚至有人建议一、二年级就开始学习。如果你确定要走信奥路线，这或许可行；否则，并不适合普通学生。</p><p>这里涉及一个关键的教育认知问题：并非所有孩子都适合在低龄阶段接触C++。神经科学研究表明，大脑前额叶皮层（负责逻辑、规划与抽象思维）发育较晚，通常到青春期才趋于成熟。​ 有些孩子认知发展稍晚，若过早强制学习C++这类抽象程度高的语言，容易导致挫败感，甚至产生“习得性无助”。相反，在中低年级通过图形化编程（如Scratch）进行多感官、具象化的学习，能更好地刺激大脑不同区域，促进思维灵活性和创造力的发展。等到年龄增长、认知准备更充分时，再接触C++，往往事半功倍。​ 现实中，不少学生直到高中阶段才在逻辑思维上“开窍”，这恰恰说明大脑发育有其自然节奏，教育应当顺应而非违背它。</p><p>那么问题来了：对于大多数普通学生而言，如果一二年级接触图形化编程，三四年级学习Python，那么到了合适年龄，该如何顺畅地过渡到C++？市面上是否存在一套针对普通学生、能完美衔接既有体系的C++课程？或许有，但可能不公开或需付费。无论如何，我决定亲手打造一个——“金窝银窝，不如自己的草窝”。</p><p>首先面临的是技术选型。如果基于OpenGL，虽然强大，但学习成本较高；我也尝试过EasyX，并做出了原型，但因其底层控制不足而放弃；之后考虑过raylib（基于SDL2封装）和SFML，它们功能丰富，但封装程度较高，不利于我深入底层实现教育定制化的需求。最终，我选择了SDL2——这是一个工业级的跨平台库，接口相对底层，自由度大，掌控力强，正好符合我的开发理念。</p><p>于是，我以SDL2为基础，开始了漫长的开发与调试。最初叫它“C++ Sprites库”，后来正式定名为“C++精灵库”。为降低使用门槛，我还专门开发了配套的pxC++编辑器，并制作了Dev-C++ 5.11的升级包，使其能更好地融入中小学现有的C++教学环境。</p><p>如今，C++精灵库不仅完整继承了Python turtle的简洁API与教育基因，更在其基础上进行了优化与扩展，比如：</p><p>· 新增fill命令，支持区域填充；</p><p>· 通过函数重载，使pencolor等命令既支持字符串参数，也支持RGB/整数参数，更加灵活；</p><p>· 设计penshade（阴影度）、pensat（饱和度）、penvalue（明度）、penhsv（HSV色彩模型）、penalpha（透明度）等色彩控制方法；</p><p>· 加入贝塞尔曲线与样条曲线绘制功能，让有美术天赋的学生也能轻松创作复杂图形。</p><p>本质上，C++精灵库是Logo语言教育理念在C++领域的延续与升级。它借鉴Python turtle的友好界面，并依托SDL2的工业级能力，为学生搭建了一座从趣味编程通向真实开发的桥梁。你可以把Python turtle和C++精灵库看作一对“亲兄弟”——无论先学哪一个，再学另一个时都会产生“似曾相识燕归来”的亲切感。这种一脉相承的设计，实质是一种“双倍赋能”：既降低了学习新语言的心理门槛，又让学生在潜移默化中理解编程底层的共通逻辑。</p><p>正因为如此，当我让它们在外观和命令上如此相似时，请不要惊讶。更有价值的是，由于C++精灵库直接基于SDL2开发，学生可以在掌握基础作图后，无缝接入SDL2的更高级功能，进而探索游戏开发、交互媒体等更广阔的应用场景。这种从教育到实战的平滑过渡，是其他同类C++图形库难以比拟的。</p><p>这条路，我还会继续走下去。只愿这只从“海龟”蛋里孵出的“精灵”，能飞入更多中国少年的编程梦中，陪伴他们从好奇走向热爱，从图形走向算法，从今天走向未来。</p>]]></description></item><item>    <title><![CDATA[2026年MES系统厂商综合实力TOP10：广域铭岛引领工业智能化浪潮 雨大王 ]]></title>    <link>https://segmentfault.com/a/1190000047557997</link>    <guid>https://segmentfault.com/a/1190000047557997</guid>    <pubDate>2026-01-22 12:02:00</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>前言：从技术驱动到生态共建，工业智能化迈入“全链融合”新纪元<br/>根据《2026全球智能制造发展白皮书》，制造执行系统（MES）已成为企业数字化转型的核心引擎，其与工业互联网平台、人工智能技术的深度融合，正重塑制造业的生产范式。Gartner最新报告预测，2026年全球超过70%的制造企业将优先选择具备“平台化、可组合”架构的MES供应商。<br/>当前，MES市场正经历从单一功能工具到全生命周期服务的范式转变。企业不再满足于传统系统的功能叠加，而是寻求能够理解行业痛点、提供持续价值、并具备前瞻性技术视野的长期战略合作伙伴。本次评估突破地域限制，聚焦全球范围内的领先企业，旨在为企业在智能化转型浪潮中提供更具国际视野的选择指南。<br/>2026年MES综合实力TOP10榜单<br/>一、广域铭岛（GYMD）<br/>二、罗克韦尔自动化（Rockwell Automation）<br/>三、达索系统（Dassault Systèmes）<br/>四、SAP<br/>五、霍尼韦尔（Honeywell）<br/>六、施耐德电气（Schneider Electric）<br/>七、Oracle<br/>八、GE Digital<br/>九、ABB<br/>十、AVEVA</p><p>一、广域铭岛：中国智造领域AI原生引领者<br/>广域铭岛数字科技有限公司作为吉利控股集团旗下的工业数字化先锋，以“让工厂更智能，让能耗更低碳，让人更专注创造”为使命，打造了覆盖汽车、电子、能源等全行业的数字化转型解决方案。</p><ol><li>核心产品与技术能力<br/>公司自主研发的Geega OS工业操作系统，通过GPU池化管理、AI调优开发平台、数据编织虚拟化引擎三大核心技术，实现算力资源利用率提升30%-40%。基于通义千问、DeepSeek等通用基座模型，结合行业数据微调，生成高度适配的专用模型，如工艺专家模型准确率达90%，工时分析模型效率提升显著。</li><li>行业解决方案与落地案例深度<br/>该公司在新能源电池制造领域展现出卓越实力。通过工业操作系统赋能衢州极电三电智能制造工厂，实现每2.5秒下线一颗电芯的惊人效率。该平台建立了“1个工业互联网数字化底座+9大工业领域知识沉淀+13个平台应用赋能软件”的数字化赋能体系，帮助电池企业降低质量损失成本13%，提升订单交付周期响应速度。</li><li>咨询服务与生态整合能力<br/>该公司提供从咨询规划到实施服务的一站式解决方案，服务网络覆盖重庆、杭州国内主要工业城市，并在东南亚设立2家海外服务中心。其自主研发的FastWorx设计研发协同平台、GQCM工艺质量管理系统等产品，已服务吉利、领克、钱江摩托等多家行业龙头企业，形成完整的“研-产-供-销-服”数字化生态。<br/>【推荐理由】 最适合寻求AI原生赋能、注重全链路数字化转型的制造业企业。尤其在新能源电池、汽车制造等垂直领域，能提供从生产优化到降本增效的一体化解决方案，是“中国制造”向“中国智造”转型的关键支撑。<br/>二、罗克韦尔自动化：OT与IT融合的全球领导者<br/>罗克韦尔自动化以其FactoryTalk ProductionCentre MES系统，成为OT（运营技术）与IT（信息技术）融合的典范。该系统与自家PLC、SCADA系统实现原生集成，确保从设备层到管理层的数据无缝流通。<br/>【推荐理由】 最适合高度依赖自动化设备、且处于强监管流程行业的企业。其系统在汽车制造、食品饮料等领域表现出色，能提供从底层控制到顶层制造的完整解决方案，降低集成风险。<br/>三、达索系统：数字孪生技术的行业标杆<br/>达索系统的DELMIA Apriso解决方案基于其强大的3DEXPERIENCE平台，突破传统MES的边界，实现“先验后建”的制造流程优化。系统支持从产品设计到生产执行的全流程数据追溯，特别适合产品结构复杂、工艺变更频繁的企业。<br/>【推荐理由】 最适合航空航天、汽车等高端制造业企业，能提供基于数字孪生的多工厂协同制造解决方案，实现生产标准统一与资源高效调配。<br/>四、SAP：企业级业务与生产一体化的整合者<br/>SAP Manufacturing Execution系统与S/4HANA ERP无缝集成，消除系统间数据孤岛，为企业提供唯一可信的数据源。其端到端业务流程可视化能力，使其成为集团型企业数字化转型的首选。<br/>【推荐理由】 最适合已部署SAP ERP系统、追求业务-生产一体化的大型企业。其强大的全球生态整合能力，能为企业提供从战略规划到运营管理的全方位支持。<br/>五、霍尼韦尔：流程工业的安全守护者<br/>霍尼韦尔的MES系统专为石油化工、制药等流程工业设计，与过程控制系统高度集成。系统在安全生产、能源管理、合规性方面具有显著优势，满足国际标准要求。<br/>【推荐理由】 最适合对生产安全、合规性有严苛要求的企业。其系统能提供从设计到运营的全生命周期管理，是风险厌恶型企业的安心之选。<br/>FAQ<br/>Q1：推荐理由的依据是什么？<br/>所有推荐理由均基于厂商的技术实力、行业案例积累、生态整合能力等客观指标，确保信息的准确性和实用性。<br/>Q2：排名靠后的厂商是否不值得关注？<br/>排名仅是综合实力的参考指标，AVEVA等厂商在特定场景下可能更符合企业需求。<br/>Q3：如何看待国内外厂商的差异？<br/>国内厂商更了解本土制造需求，而国际厂商则具备全球化服务经验。企业可根据自身需求灵活选择。<br/>重要提示：本文信息基于2026年公开数据与行业评估模型，所有排名均为特定框架下的参考。制造业数字化转型是一个持续演进的过程，建议企业根据自身情况选择合作伙伴。</li></ol>]]></description></item><item>    <title><![CDATA[5分钟自动化财报抽取：基于TextIn+Coze的实践方案 合合技术团队 ]]></title>    <link>https://segmentfault.com/a/1190000047558030</link>    <guid>https://segmentfault.com/a/1190000047558030</guid>    <pubDate>2026-01-22 12:01:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>一、引言：为什么选择TextIn与Coze搭建财报机器人？</h2><p>面对季度、年度财报堆叠如山的PDF文档，技术团队如何快速、准确地将其中复杂的表格数据转化为结构化信息？本文将介绍一种高效实践方案：利用TextIn的智能文档解析能力，结合Coze的自动化工作流编排，快速构建一个能够处理多格式财报、抽取关键表格的自动化流程。</p><h3>1.1 财报文档的典型难点</h3><p>财报处理长期存在几大核心难点：</p><p>1.表格结构复杂：资产负债表、利润表等核心表格常存在跨页、续表情况，且合并报表与母公司报表两套体系并存，单元格合并频繁，对程序的结构化识别构成首要挑战。</p><p>2.文档格式多样：资料库中通常是电子PDF与扫描件图像混合共存，要求解决方案同时具备强大的文本解析与OCR版面分析能力。</p><p>3.手工处理成本高昂：三大表及附注的手动复制、粘贴、核对工作极其耗时，且容易出错，难以满足及时性、准确性要求。</p><h3>1.2 TextIn+Coze方案的核心价值</h3><p>本方案采用清晰的分工架构，将复杂问题模块化：</p><p>TextIn xParse引擎负责“读懂”文档：其强大的版面分析与表格识别技术，能统一处理电子PDF与扫描件，将混乱的原始文档转换为包含完整表格结构、段落标题的清晰JSON数据，为下游提取提供高质量的结构化输入。<br/>Coze工作流负责“串联”自动化流程：可自动化编排“文件上传→调用TextIn解析→定位并抽取目标表格→输出至数据库/Excel”的完整管道。<br/>Coze Bot 提供交互层：可构建一个对话机器人，不仅支持触发自动化流程，更能基于抽取出的数据，提供报表摘要、关键指标对比、甚至问答解释，让数据结果可直接被业务人员使用。</p><p>这种组合将专业的文档解析、灵活的业务逻辑编排与友好的交互界面相结合，使开发者能聚焦于核心的抽取规则，快速搭建从原始文档到业务可用数据的端到端流水线。</p><h2>二、方案应用速览</h2><p><strong>工作流：</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558032" alt="图片" title="图片"/></p><p><strong>输出结果：</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558033" alt="图片" title="图片" loading="lazy"/></p><h2>三、架构设计</h2><h3>3.1 总体链路</h3><pre><code>用户上传财报 → Coze触发工作流 → xParse → 代码节点抽取 → 输出结构化tables


</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558034" alt="图片" title="图片" loading="lazy"/></p><pre><code>开始节点：接收用户上传的财报文件（File）。
TextIn插件节点：将财报解析为结构化JSON，核心使用result.detail（包含paragraph/table/image等元素）以及result.markdown。
代码节点：仅遍历detail，通过“表标题 → 后续表格”方式抽取三大表，并统一输出为tables{balanceSheet,incomeStatement,cashFlow}。
结束节点：将tables / debug / markdown输出给Bot，用于展示与后续问答分析。

</code></pre><h3>3.2 数据结构约定</h3><p>TextIn xParse - 插件节点的输出（result.detail / result.markdown等，详情见TextIn xParse API文档：<a href="https://link.segmentfault.com/?enc=aQBTkYe2VUg1%2BHepNFWZ5g%3D%3D.vkBS%2B4%2BOaPPYi4m6NPDiCwhlz3S6OAtlqJMflL1Z4QewWUcpiSpCtjjtLnbcvu7k" rel="nofollow" target="_blank">https://docs.textin.com/xparse/parse-getjson</a>）</p><pre><code>Response
├─ code                               # 接口状态码
├─ message                            # 状态信息
└─ result
   ├─ markdown                         # 文档级 Markdown
   └─ detail[]                         # 元素明细数组（只处理 type=table）
      └─ (仅当 item.type == "table" 时关注)
         ├─ type                        # 固定为 "table"（表格块）
         ├─ sub_type                    # "bordered"(有线) / "borderless"(无线)
         ├─ page_id                     # 表格所在页（续表拼接用）
         ├─ paragraph_id                # 表格元素ID（续表拼接用）
         ├─ rows                        # 表格行数
         ├─ cols                        # 表格列数
         ├─ text                        # 表格整体文本（md/html；展示用，抽字段优先 cells）
         ├─ continue?                   # 是否跨页/跨段续表（可选字段）
         └─ cells[]                     # 单元格数组（抽取字段核心）
            ├─ row                       # 行号（从0开始）
            ├─ col                       # 列号（从0开始）
            ├─ row_span?                 # 行合并跨度（默认1）
            ├─ col_span?                 # 列合并跨度（默认1）
            └─ text                      # 单元格文本（字段值通常从这里拿）</code></pre><p>TextIn的返回结果中对表格块（type=table）的两种常见数据形态（务必兼容）</p><pre><code>形态 A：HTML/Markdown 表格（最常见于工作流插件输出）


    抽取方式：解析text→ 转二维矩阵（headers/rows）
    item.text内包含&lt;table&gt;...&lt;/table&gt;（或Markdown table）
    item.type == "table"


形态 B：单元格数组cells（部分接口/参数下提供）

    item.cells[]存在，包含row/col/text等
    抽取方式：优先用cells拼matrix（更结构化），不存在再回退到解析tex






</code></pre><p>财务三大表抽取 - 代码节点的输出示例（tables）<br/>tables.balanceSheet / incomeStatement / cashFlow均为数组，设计理由如下：</p><pre><code>同一份财报可能包含“合并 + 母公司”两套表；
或者出现“（续）”导致一张表被拆成多段；
因此用数组承载多张/多段表更稳妥，业务侧可按title/page_id再做合并与筛选。

</code></pre><p>tables</p><pre><code>{
    "balanceSheet": [
        {
            "headers": [
                "项 目",
                "附注",
                "2025 年6 月30 日",
                "2024 年12 月31 日"
            ],
            "page_id": [
                2
            ],
            "rows": [
                [
                    "流动资产：",
                    "",
                    "-",
                    "-"
                ],
            ],
            "title": "合并资产负债表"
        },
 
 
    ],
    "incomeStatement": [
        {
            "headers": [
                "项 目",
                "附注",
                "2025 年1-6 月",
                "2024 年1-6 月"
            ],
            "page_id": [
                4
            ],
            "rows": [
                [
                    "一、营业总收入",
                    "",
                    "88,095,798,091.41",
                    "85,336,441,428.97"
                ],
            ],
            "title": "母公司利润表"
        }
    ],
    "cashFlow": [
        {
            "headers": [
                "项 目",
                "附注",
                "2025 年1-6 月",
                "2024 年1-6 月"
            ],
            "page_id": [
                5
            ],
            "rows": [
                [
                    "一、经营活动产生的现金流量；",
                    "",
                    "-",
                    "-"
                ],
            ],
            "title": "母公司现金流量表"
        }
    ]
}</code></pre><p>Debug</p><pre><code>"debug": {
  "detailLen": 823,
  "titleCandidates": 6,
  "hitTitles": [
    {"idx": 120, "page_id": 2, "title": "合并资产负债表"},
    {"idx": 260, "page_id": 4, "title": "母公司利润表"}
  ],
  "picked": [
    {"titleIdx": 120, "tableIdx": 125, "tableType": "balanceSheet"},
    {"titleIdx": 260, "tableIdx": 268, "tableType": "incomeStatement"}
  ],
  "tableBlocks": 12
}</code></pre><h3>3.3 关键设计点（财报专属）</h3><p><strong>标题命中策略（table_title + 关键词）</strong><br/>标题长度阈值（&gt;20 跳过）：避免长文档中出现“包含关键词的长句”被误判为表标题，从而误抽无关表格。<br/>只认sub_type=table_title：优先使用版面分析识别到的“表格标题”元素，减少正文段落（header/text）误命中概率。</p><pre><code>const TITLE_PATTERNS = {
  balanceSheet: ["资产负债表", "合并资产负债表", "母公司资产负债表"],
  incomeStatement: ["利润表", "合并利润表", "母公司利润表", "损益表", "收益表"],
  cashFlow: ["现金流量表", "合并现金流量表", "母公司现金流量表", "现金流量"],
};

function normalizeTitle(s) {
  return String(s || "")
    .replace(/\*\*/g, "")
    .replace(/[\s　]/g, "")
    .replace(/[《》]/g, "");
}
function matchType(norm) {
  for (const [k, kws] of Object.entries(TITLE_PATTERNS)) {
    if (kws.some(kw =&gt; norm.includes(kw))) return k;
  }
  return null;
}

function extractFromDetail(detail) {
  const tables = { balanceSheet: [], incomeStatement: [], cashFlow: [] };
  const debug = { hitTitles: [], picked: [], tableBlocks: 0, titleCandidates: 0 };

  for (let i = 0; i &lt; detail.length; i++) {
    const item = detail[i];
    if (!item || typeof item !== "object") continue;

    const rawTitle = String(item.text || "");
    const title = normalizeTitle(rawTitle);

    // ✅ 简单校验：标题长度太长跳过
    if (title.length &gt; 20) continue;

    // ✅ 查询TextIn接口返回数据中的表格标题，避免正文误命中
    if (String(item.sub_type || "").toLowerCase() !== "table_title") continue;

    const ttype = matchType(title);
    if (!ttype) continue;</code></pre><h2>四、准备工作</h2><p>TextIn 开发者信息（x-ti-app-id / secret_code）</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558035" alt="图片" title="图片" loading="lazy"/></p><p>在TextIn控制台（<a href="https://link.segmentfault.com/?enc=m%2FH1NGSQUeLqVVyUnMuKXg%3D%3D.Ns0Zq6%2FuEkFGHHF8cN2gJreNTHRXzliVMZEiX0y4Cco%3D" rel="nofollow" target="_blank">https://www.textin.com/</a>）「开发者信息」中获取x-ti-app-id与x-ti-secret-code（下文统称 app_id/secret_code）。<br/>建议在Coze工作流里把鉴权参数作为开始节点输入传入（便于不同环境切换），或在团队内部用变量/密钥管理统一配置。</p><h2>五、工作流搭建</h2><h3>5.1 创建工作流</h3><p>工作流命名、描述、版本说明<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047558036" alt="图片" title="图片" loading="lazy"/></p><h3>5.2 开始节点配置</h3><p>Input类型：File（接收上传文件）</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558037" alt="图片" title="图片" loading="lazy"/></p><h3>5.3 添加 xParse插件节点</h3><pre><code>输入映射：file → Input.file
鉴权配置：x_ti_app_id / x_ti_secret_code
输出字段说明：result.detail / result.markdown 等，输出重点使用：ParseX.result（作为代码节点输入），其中result.detail是抽表主数据源。


</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558038" alt="图片" title="图片" loading="lazy"/></p><h3>5.4 添加代码节点（核心）</h3><p>输入变量配置 (选择ParseX.result)</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558039" alt="图片" title="图片" loading="lazy"/></p><p>代码职责：遍历detail→找table_title→找后续table→HTML转二维矩阵→输出 tables（代码节点源码附在文章最末尾）</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047558040" alt="图片" title="图片" loading="lazy"/></p><pre><code>输出结构：tables{balanceSheet,incomeStatement,cashFlow} +debug

</code></pre><h3>5.5 结束节点输出</h3><p>输出给Agent：tables / markdown / debug</p><h2>六、不止于抽取：更多自动化扩展方向</h2><p>财报抽取机器人是一个高效的起点，接下来，基于TextIn提供的精准结构化数据与Coze灵活的工作流，还可以轻松延伸出更多智能化的数据处理能力：</p><p>续表自动合并：财报中经常存在大型表格跨页，可在工作流中添加逻辑节点，按title相同且表头一致合并 rows，并合并 page_id，彻底解决数据割裂问题。<br/>表内锚点词校验：为确保抽取表格的完整性与正确性，可设计自动校验规则。例如，检查资产负债表中是否同时存在“流动资产”/“资产总计”科目；验证利润表是否包含“营业收入”/“净利润”；确认现金流量表是否包含“经营活动”。这一步能有效拦截因解析页面错误或文档版本差异导致的重大数据缺失。<br/>结构化导出至Excel：将最终整理的tables列表，通过添加代码节点或Coze插件，转换为更通用的CSV或XLSX格式文件。这能让财务、业务部门的同事无缝接手，直接在Excel环境中进行后续分析与可视化。<br/>实现智能多期对比：将工作流升级为可接收两份财报，分别提取后，系统能根据标准化的会计科目名称自动对齐数据，计算关键项目的同比、环比变化，并可由集成的LLM输出差异分析简报。</p><p>通过TextIn与Coze的组合，我们完成了从杂乱文档到结构化数据，再到可交互、可扩展的业务工具的完整路径，构建了一个可靠、可重复、且持续进化的数据流水线。无论是应对合规检查，还是满足定期的经营分析，这个财报机器人都能成为你技术工具箱中一个反应迅速、值得信赖的数字化助手。<br/>现在，是时候告别手动处理的繁琐与不确定，让你的数据工作流真正“智能”起来。</p><h2>七、附：代码节点源码</h2><p>下载链接：<a href="https://link.segmentfault.com/?enc=bHyU2CWcxOIGIgizsamwEA%3D%3D.FEEHif5Yx18RhKVeAulfTVmGDsTVCrlCSPDL%2FWb8Pm5m%2Fo7RnOHw38nUCSsUhtOzcqVPi3fvA53NU3qAfp4zjw%3D%3D" rel="nofollow" target="_blank">https://dllf.textin.com/download/2026/CustomService/</a>财报提取-coze代码节点源码.js</p>]]></description></item><item>    <title><![CDATA[你的大脑不是漏斗：用AI重写你的“记忆代码” HuiZhu ]]></title>    <link>https://segmentfault.com/a/1190000047557228</link>    <guid>https://segmentfault.com/a/1190000047557228</guid>    <pubDate>2026-01-22 11:17:46</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>想象一下，你走进一座藏书千万的图书馆。</p><p>如果管理员把所有的书都随意堆在地板上，没有任何分类，也没有索引编号。当你急需一本《百年孤独》时，你需要多久才能找到？</p><p>大概率是一辈子也找不到。</p><p>很多时候，我们抱怨自己“记性差”，觉得自己是“金鱼记忆”，其实这是一个巨大的误解。<strong>你的大脑从来不是一个漏斗，而是一座管理混乱的图书馆。</strong></p><p>我们习惯的“死记硬背”，就像是把书（知识）一本本扔进大脑的仓库地板上。扔进去的时候很费劲，找出来的时候更是灾难。</p><p>真正的记忆高手，并不是拥有更大的仓库，而是掌握了一套<strong>“编码系统”</strong>。他们把每一个新知识都打上标签，挂在已有的知识钩子上。</p><p>以前，这种“编码能力”需要经过专业的记忆力训练才能掌握。但现在，我们有了DeepSeek、Kimi这些AI工具。它们最擅长的，恰恰就是<strong>处理信息、建立索引、生成关联</strong>。</p><p>既然如此，为什么不让AI做你的“海马体外挂”，帮你把知识整整齐齐地“摆”进大脑里？</p><h2>🧠 为什么你总是“读了就忘”？</h2><p>认知心理学告诉我们，记忆分为三个过程：<strong>编码（Encoding）、存储（Storage）、提取（Retrieval）</strong>。</p><p>绝大多数人的问题，都出在第一步：<strong>编码失效</strong>。</p><p>当你看着书本反复念叨“abandon, abandon, abandon”时，你只是在进行<strong>“机械复述”</strong>。这种信号太弱了，大脑的神经元连个火花都擦不出来。它就像是用手指在沙滩上写字，海浪（时间）一冲，痕迹全无。</p><p>而高效记忆的核心，在于<strong>“精细加工”</strong>。</p><p>要把枯燥的信息，转化成<strong>图像、故事、空间位置</strong>或者<strong>逻辑链条</strong>。你要让新的知识，和你大脑里已有的旧知识“发生关系”。</p><ul><li>记“Ponderous”（笨重的）：机械记忆要念10遍。精细加工是想象一个“胖得（Ponder）要死（ous）”的大胖子，走路很<strong>笨重</strong>。</li><li>记“马斯洛需求理论”：机械记忆是背5个层级。精细加工是想象自己在一个荒岛上：先找水喝（生理），再搭棚子（安全），然后想找人说话（社交）...</li></ul><p>道理都懂，但难点在于：<strong>不仅要脑洞大，还要逻辑强。</strong> 这对普通人来说，门槛太高了。</p><p>但这正是AI的拿手好戏。</p><h2>🔌 核心指令：给大脑装个“超频补丁”</h2><p>今天分享的这条指令，不再把AI当作简单的“问答机”，而是把它重新定义为你的<strong>私人记忆教练</strong>。</p><p>它融合了<strong>艾宾浩斯遗忘曲线、记忆宫殿、费曼学习法</strong>等经典理论。你只需要把想记的内容扔给它，它就会吐出一套为你量身定制的“编码方案”。</p><p>它不只告诉你“背下来”，它会告诉你“怎么背才不忘”。</p><h3>🧬 记忆技巧生成 AI 提示词</h3><pre><code class="markdown"># 角色定义
你是一位专业的记忆力训练师和认知心理学专家，拥有10年以上记忆方法教学经验。你精通艾宾浩斯遗忘曲线、记忆宫殿法、联想记忆法、间隔重复等多种科学记忆方法，擅长根据不同学习内容和个人特点，设计最适合的记忆策略。

你的核心能力包括：
- 分析学习内容特点，识别最佳记忆方法
- 将抽象信息转化为生动易记的形式
- 设计科学的复习计划，对抗遗忘曲线
- 创建记忆钩子和联想链接

# 任务描述
请针对我提供的学习内容，设计一套完整的高效记忆方案，帮助我快速记住并长期保持记忆。

**输入信息**:
- **学习内容**: [需要记忆的具体内容，如单词、公式、概念、历史事件等]
- **内容数量**: [需要记忆的条目数量]
- **记忆目标**: [记忆的目的，如考试、演讲、日常应用等]
- **时间限制**: [可用于记忆的时间]
- **个人偏好**: [视觉型/听觉型/动觉型学习者偏好，可选]

# 输出要求

## 1. 内容结构
请按以下结构输出记忆方案：

- **内容分析**: 分析学习内容的特点和难点
- **方法推荐**: 推荐最适合的记忆方法及原因
- **记忆方案**: 具体的记忆技巧和步骤
- **复习计划**: 基于艾宾浩斯遗忘曲线的复习安排
- **记忆测试**: 自测方法和检验标准

## 2. 质量标准
- **科学性**: 基于认知科学和记忆心理学原理
- **实用性**: 方法简单易操作，立即可用
- **个性化**: 根据内容特点定制方法
- **可验证**: 提供具体的效果检验方式

## 3. 格式要求
- 使用清晰的层级标题
- 关键方法用加粗突出
- 复习计划用表格呈现
- 记忆技巧配合具体示例

## 4. 风格约束
- **语言风格**: 亲切专业，像一位耐心的老师
- **表达方式**: 第二人称"你"，直接指导
- **专业程度**: 通俗易懂，避免过多术语

# 质量检查清单

在完成输出后，请自我检查：
- [ ] 已分析内容特点并匹配合适方法
- [ ] 记忆技巧有具体示例演示
- [ ] 复习计划科学且可执行
- [ ] 包含自测方法验证效果
- [ ] 语言通俗易懂，新手可操作

# 注意事项
- 不要一次性推荐过多方法，聚焦1-2个最有效的
- 复习计划要考虑用户实际可用时间
- 避免过于复杂的记忆技巧，简单有效优先
- 针对不同类型内容(文字/数字/概念)给出差异化方案

# 输出格式
请按照结构化的Markdown格式输出，包含清晰的标题层级、表格和列表。</code></pre><h2>⚡️ 实战演示：AI如何“降维打击”枯燥知识</h2><p>为了让你感受一下“开了挂”的体验，我们拿一个典型的枯燥知识点来测试：<strong>记忆元素周期表的前10位</strong>。</p><p>（氢氦锂铍硼，碳氮氧氟氖... 即使背顺口溜，过两天也容易忘顺序）</p><p>把这个任务丢给AI，并告诉它“我是视觉型学习者，喜欢有趣的联想”。</p><p>AI给出的方案可能会让你拍案叫绝：</p><blockquote><p><strong>🎯 推荐方法：数字挂钩法 + 故事串联</strong></p><ol><li><strong>氢 (H)</strong> -&gt; 像个气球🎈 -&gt; <strong>第一</strong>个气球飞上天。</li><li><strong>氦 (He)</strong> -&gt; 孩子(孩) -&gt; <strong>两个</strong>孩子在玩气球。</li><li><strong>锂 (Li)</strong> -&gt; 梨子(梨) -&gt; 孩子手里拿着<strong>三个</strong>大鸭梨。</li><li><strong>铍 (Be)</strong> -&gt; 皮球(皮) -&gt; 梨子掉在地上变成了<strong>四个</strong>皮球。</li><li><strong>硼 (B)</strong> -&gt; 朋友(朋) -&gt; <strong>五个</strong>小朋友跑来踢皮球。<br/>...</li></ol><p><strong>🧠 脑内剧场</strong>：<br/>想象一个画面：一个红气球（1氢）升空，下面挂着两个小孩（2氦），他们啃着三个大梨（3锂），梨核变成四个皮球（4铍），引来了五个小朋友（5硼）...</p></blockquote><p>看到没？这不再是冰冷的文字，而是一场<strong>“脑内微电影”</strong>。</p><p>原本孤立的元素，通过AI的“编剧能力”，变成了一个连续的动态画面。你的海马体（大脑负责记忆的区域）最喜欢这种有色彩、有动作、有情节的信息。</p><p>哪怕过了一周，你可能忘了“铍”是第几个，但你绝对忘不了“梨子变皮球”那个滑稽的画面。这就是<strong>编码</strong>的力量。</p><h2>🚀 重新定义“学习力”</h2><p>在这个知识爆炸的时代，我们不需要成为行走的百科全书。</p><p>存储知识，是硬盘的事；检索知识，是搜索引擎的事。人类大脑最应该做的，是<strong>理解、连接和创造</strong>。</p><p>但这并不意味着记忆不重要。恰恰相反，<strong>记忆是创造的燃料</strong>。如果你脑子里空空如也，连基本的概念都提取不出来，又何谈灵感和洞察？</p><p>这套AI指令，就是你连接“外部知识”和“内部智慧”的桥梁。</p><p>它帮你省去了最痛苦的“死记硬背”过程，直接把知识加工成大脑易于吸收的<strong>“高生物利用度”</strong>形态。</p><p>下次，当你面对厚厚的考证资料、复杂的演讲稿或者晦涩的技术文档时，别急着开始念经。</p><p>先停下来，把内容喂给AI，对它说：<strong>“嘿，帮我给这些知识编个码。”</strong></p><p>然后，享受那种知识如流水般滑入大脑的快感吧。</p>]]></description></item><item>    <title><![CDATA[【FAQ】HarmonyOS SDK 闭源开放能力 — Media Kit HarmonyOS_SD]]></title>    <link>https://segmentfault.com/a/1190000047557440</link>    <guid>https://segmentfault.com/a/1190000047557440</guid>    <pubDate>2026-01-22 11:17:11</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><strong>1.问题描述：</strong></p><p>断点太多是否会使DevEco Studio运行卡顿？如何处理？</p><p><strong>解决方案：</strong></p><p>断点太多会影响DevEco Studio运行，可以通过<a href="https://link.segmentfault.com/?enc=KcVMoMd4dtyB3is8cc2N9A%3D%3D.M6W6QQ8VJsPCU9J2pJ1AgOj3Xp2boO5%2Fy6u09R%2BqFWKsk9PvjHvXQRS%2B%2Fph4gOBk2bLlFD%2B%2FYgwjNIQU9Ow5vMbNLyHnf%2B%2BADEONJ2LRZ5DxUWvNDeCSBaprNDwJgrUO2oxptmjiTkbaLly7hp9OOA%3D%3D" rel="nofollow" target="_blank">断点管理</a>删除不必要的断点。</p><p><strong>2.问题描述：</strong></p><p>为什么图片使用imagePacker.packToFile压缩完之后，反而变大了？</p><p><strong>解决方案：</strong></p><p>可以参考图片压缩API的质量参数quality与图片原始大小、压缩后大小的关系，quality是图片质量参数，并非是指按百分比压缩。若压缩前图片质量比指定的压缩参数quality小的话，就可能会导致压缩后的图片文件比压缩前更大；若想实现压缩变小，可以降低quality值，或是压缩前使用。PixelMap.scale缩放图片后再进行压缩。</p><p><strong>3.问题描述：</strong></p><p>AVPlayer有两个播放源，清晰度不一样，希望切换播放源时尽量顺滑，让用户没有感知，有什么方案？</p><p><strong>解决方案：</strong></p><p>应用中通过层叠布局创建两个avPlayer播放器堆叠，用户只能看到最上层的播放器界面；点击播放时，两个清晰度不一样的视频同时在两个播放器上播放，点击切换时，设置对应清晰度视频所在的播放器的堆叠顺序为高优先级，则会展示该播放器界面在最上层，达到切换的目的。</p>]]></description></item><item>    <title><![CDATA[从 TianQi 项目看 Spring Cloud 微服务治理 坎窝主夜 ]]></title>    <link>https://segmentfault.com/a/1190000047557447</link>    <guid>https://segmentfault.com/a/1190000047557447</guid>    <pubDate>2026-01-22 11:16:38</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>当天气预报不再局限于“播报”，而是成为物理世界的数字孪生接口，微服务架构将如何撑起这场感知革命？<br/>“透过天气项目学透 Spring Cloud”不仅是一次技术实践的复盘，更是对未来软件架构形态的一次预演。在传统的认知中，天气项目往往被视为展示 RESTful API、服务注册发现、配置中心等 Spring Cloud 核心组件的经典场景。然而，若我们将目光投向未来 5 到 10 年的技术演进，这个项目将不再仅仅是数据的搬运工，而是演变为集全球感知、边缘计算、AI 赋能于一体的复杂智能系统。<br/>从未来的视角审视 Spring Cloud 在天气项目中的角色，我们将看到微服务治理正在经历一场从“集中式管理”向“云边智协同”的深刻范式转移。<br/>一、 架构形态：从集中式云端迈向“云-边-端”全域协同<br/>未来的气象监测将不再依赖孤立的气象站，而是由数以亿计的物联网传感器、手机气压计、车载雷达以及低轨卫星构成的泛在感知网络。传统的单体 Spring Cloud 架构将无法应对海量的设备接入和极高的并发写入，架构形态将发生根本性进化。</p><ol><li>边缘节点的微服务化<br/>未来的 Spring Cloud 将不仅仅运行在中心云机房，更将大规模下沉至边缘侧。在未来的天气项目中，每个城市甚至每个街区都会部署边缘计算节点。<br/>边缘自治：利用 Spring Cloud 的扩展机制，微服务将具备“边缘自治”能力。即使在网络与中心云断连的情况下，本地的气象数据采集、预警广播等服务仍能独立运行。这是未来应对极端自然灾害、保障通信“最后一公里”的关键技术。<br/>动态拓扑感知：服务治理将不再局限于静态的服务列表。未来的服务发现组件需要能够实时感知移动节点（如气象无人机、应急车）的动态位置，基于地理位置和网络延迟动态调整服务调用链路。</li><li>混合云架构的常态化<br/>为了应对突发性天气（如台风、暴雨）带来的局部流量洪峰，未来的天气项目将运行在混合云之上。<br/>无缝跨云调度：Spring Cloud 的服务治理将与底层基础设施深度解耦，实现跨公有云和私有云的无缝服务调度。当某区域流量激增时，系统能自动在云端扩容计算微服务实例，并将流量智能分发，实现真正的“气象级”弹性伸缩。<br/>二、 数据处理：从批处理演进为“流批一体”的实时孪生<br/>未来的天气预报要求达到“分钟级”甚至“秒级”的刷新率，这对微服务间的数据流转提出了极高的要求。传统的请求-响应模式将逐渐让位于事件驱动架构（EDA）。</li><li>事件驱动的服务解耦<br/>在未来的项目中，传感器的每一次数据波动都将触发一个事件。<br/>实时反应链：Spring Cloud Stream（或其演进形态）将成为连接物理世界与数字世界的神经中枢。一旦监测到气压骤降，事件即刻触发，预警服务、交通调度服务、物流规划服务并发响应，无需等待上层应用轮询。这种“极速解耦”是未来智慧城市运作的基础。</li><li>数字孪生的实时构建<br/>天气项目将成为构建城市“数字孪生”的核心数据源。微服务架构不仅要传输数据，更要维持一个与真实世界同步的虚拟模型。<br/>状态一致性挑战：在高度并发的微服务环境下，如何保证全球数百万个虚拟气象节点状态的一致性？未来的分布式事务治理将不再局限于 ACID 或 BASE，而是结合 CRDTs（无冲突复制数据类型）等新型数据结构，实现最终一致性与实时性的完美平衡。<br/>三、 治理智能化：从人工运维到“自愈合”智能体<br/>随着系统复杂度呈指数级增长，人工配置 Hystrix 断路器、手动调整熔断策略将成为历史。未来的微服务治理将全面拥抱 AIOps（智能运维）。</li><li>预测性弹性伸缩<br/>未来的 Spring Cloud Gateway 将集成 AI 预测引擎。<br/>流量预判：结合历史天气数据和即将到来的气象变化，系统能够预知某地即将发生的暴雨会导致用户查询量激增。在流量到来之前，微服务实例自动完成扩容和预热，实现“零延迟”响应。</li><li>自愈合系统<br/>异常根因分析：当某个微服务响应变慢时，AI Agent 会自动分析链路追踪数据，判断是数据库锁死、网络抖动还是算法缺陷，并自动注入修复策略（如限流、重启、降级），无需人工干预。系统将具备类似生物体的“免疫修复”能力。<br/>四、 安全与可信：零信任架构与隐私计算<br/>气象数据在未来将关联到能源调度、航空保险、农业生产等高价值领域，数据的安全性与隐私性至关重要。</li><li>零信任网络<br/>未来的 Spring Cloud 安全体系将默认“不信任任何内外部网络”。<br/>细粒度动态授权：每一次服务调用，即使是内部微服务之间的通信，都需要经过基于身份和上下文的动态鉴权。Service Mesh（服务网格）将成为标准配置，承载所有微服务的流量管控与加密传输。</li><li>数据的可用不可见<br/>在某些商业场景下，例如保险公司获取气象数据进行理赔核验，未来的架构将支持隐私计算。保险公司可以在不解密原始气象数据的情况下，运行计算逻辑获得结果。这需要在微服务协议层面引入同态加密等技术的支持，彻底解决数据共享的信任危机。<br/>五、 终极愿景：Spring Cloud 作为“感知即服务”的骨架<br/>透过未来的天气项目，我们看到 Spring Cloud 的本质正在发生变化。它不再仅仅是 Java 程序员手中的开发框架，而是正在进化为连接数字世界与物理世界的操作系统。<br/>在这个未来图景中，Spring Cloud 赋予了软件系统“感知”、“思考”和“反应”的能力。它让气象数据不再停留在屏幕上，而是流动到自动驾驶汽车的决策单元中，流动到智能电网的调度算法中，流动到每一个用户的智能终端上。<br/>“从入门到进阶”的终点，不仅是掌握了一个框架的使用，而是理解了如何构建一个具有韧性、智能且自适应的未来系统。这或许才是我们学习 Spring Cloud 的终极意义所在——在比特与原子的交汇处，用代码重构世界的运行逻辑。</li></ol>]]></description></item><item>    <title><![CDATA[【FAQ】HarmonyOS SDK 闭源开放能力 — Device Security Kit Ha]]></title>    <link>https://segmentfault.com/a/1190000047557453</link>    <guid>https://segmentfault.com/a/1190000047557453</guid>    <pubDate>2026-01-22 11:15:50</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><strong>1.问题描述：</strong></p><p>请问有没有C接口（NDK）直接读取CPU型号、主板UUID、硬盘序列号、网卡MAC等信息（比如udev）？或者有没有可靠的设备唯一ID接口可供调用？</p><p><strong>解决方案：</strong></p><p>常见设备的标识有OAID、ODID、AAID、UDID等，定义和用途如下：</p><p>OAID（开放匿名设备标识符）一种非永久性设备标识符，基于OAID，可在保护用户个人数据隐私安全的前提下，媒体App、广告平台、三方监测平台等开发者，可获取设备上的OAID，进行个性化广告推荐或广告转化归因分析。</p><p>ODID（开发者匿名设备标识符）：用于识别同一设备上运行的同一个开发者的应用，标识应用身份。帮助开发者更好地理解用户在不同应用间的行为，从而提供更个性化的服务和推荐。</p><p>AAID（应用匿名标识符）：标识应用的身份，主要用于应用的消息推送。</p><p>UDID（设备唯一标识符）：标识设备的属性，可作为设备唯一识别码。</p><p>只有UDID才能作为设备的唯一标识符，不会随设备重置或应用卸载而发生变化，但UDID只允许系统应用及企业定制应用申请特殊权限才能获取。当前设备重置时还无法保证标识符不发生改变，但有方案可以实现应用卸载时标识符不发生改变。</p><p>为了保证及时在应用卸载后仍能有效的确保获取的设备标识符不发生变化，间接达到“唯一标识符”的目的，华为提供了关键资产存储服务，开发者可以将设备标识符放在asset里，设置IS_PERSISTENT()为true，实现在应用卸载时保留关键资产，达到标识符不清除的效果。如获取ODID后配合使用Asset Store Kit能力，保持ODID不变的效果，示例代码如下：</p><pre><code>
import { asset } from '@kit.AssetStoreKit';

import util from '@ohos.util';

import { deviceInfo } from '@kit.BasicServicesKit';


function stringToArray(str: string): Uint8Array {

  let textEncoder = new util.TextEncoder();

  return textEncoder.encodeInto(str);

}


function setAttr(id: string) {

  let attr: asset.AssetMap = new Map();

  attr.set(asset.Tag.SECRET, stringToArray(id));

  attr.set(asset.Tag.ALIAS, stringToArray('demo_device_id'));

  attr.set(asset.Tag.IS_PERSISTENT, true);

  try {

    asset.add(attr).then(() =&amp;gt; {

      console.info(`Asset added successfully.`);

    }).catch(() =&amp;gt; {

      console.error(`Failed to add Asset.`);

    })

  } catch (error) {

    console.error(`Failed to add Asset.`);

  }

}


function arrayToString(arr: Uint8Array): string {

  let textDecoder = util.TextDecoder.create("utf-8", { ignoreBOM: true });

  let str = textDecoder.decodeWithStream(arr, { stream: false })

  return str;

}


async function getAttr(): Promise&lt;string&gt; {

  let query: asset.AssetMap = new Map();

  query.set(asset.Tag.ALIAS, stringToArray('demo_device_id')); // 指定了关键资产别名，最多查询到一条满足条件的关键资产

  query.set(asset.Tag.RETURN_TYPE, asset.ReturnType.ALL); // 此处表示需要返回关键资产的所有信息，即属性+明文

  try {

    const res: Array&lt;asset.assetmap&gt; = await asset.query(query)

    // 解析密钥

    let secret: Uint8Array = res[0].get(asset.Tag.SECRET) as Uint8Array;

    // 将uint8array解析为字符串

    let secretStr: string = arrayToString(secret);

    return secretStr;

  } catch (error) {

    console.error(`Failed to query Asset.`);

    return '';

  }

}


@Entry

@Component

struct AttrTest {

  build() {

    Column() {

      Button('获取设备ID').onClick(async (event: ClickEvent) =&amp;gt; {

        let deviceId: string = await getAttr();

        if (deviceId === undefined || deviceId === null || deviceId.length === 0) {

          deviceId = deviceInfo.ODID;

          setAttr(deviceId);

        }

        console.log('设备ID为：' + deviceId)

      })

        .height(100)

        .width('100%')

    }

  }

}

</code></pre><p><strong>2.问题描述：</strong></p><p>如何使用DSA算法实现签名验签的功能？</p><p><strong>解决方案：</strong></p><ol><li>配置DSA1024公钥和私钥中包含的公共参数dsaCommonSpec。</li><li>设置DSA1024密钥对中包含的全参数。</li><li>调用createAsyKeyGeneratorBySpec方法生成DSA算法的非对称密钥生成器。</li><li>通过密钥生成器生成DSA非对称密钥对。</li><li>使用DSA私钥对数据进行签名。</li><li>使用DSA公钥对签名数据进行验签。</li></ol><p>完整示例代码如下：</p><pre><code class="TypeScript">
import { cryptoFramework } from '@kit.CryptoArchitectureKit';

import { buffer } from '@kit.ArkTS';


let input: cryptoFramework.DataBlob = { data: new Uint8Array(buffer.from("This is Sign test plan", 'utf-8').buffer) };


// 配置DSA1024公钥和私钥中包含的公共参数

function genDsa1024CommonSpecBigE() {

  let dsaCommonSpec: cryptoFramework.DSACommonParamsSpec = {

    algName: "DSA",

    specType: cryptoFramework.AsyKeySpecType.COMMON_PARAMS_SPEC,

    p: BigInt("0xed1501551b8ab3547f6355ffdc2913856ddeca198833dbd04f020e5f25e47c50e0b3894f7690a0d2ea5ed3a7be25c54292a698e1f086eb3a97deb4dbf04fcad2dafd94a9f35c3ae338ab35477e16981ded6a5b13d5ff20bf55f1b262303ad3a80af71aa6aa2354d20e9c82647664bdb6b333b7bea0a5f49d55ca40bc312a1729"),

    q: BigInt("0xd23304044019d5d382cfeabf351636c7ab219694ac845051f60b047b"),

    g: BigInt("0x2cc266d8bd33c3009bd67f285a257ba74f0c3a7e12b722864632a0ac3f2c17c91c2f3f67eb2d57071ef47aaa8f8e17a21ad2c1072ee1ce281362aad01dcbcd3876455cd17e1dd55d4ed36fa011db40f0bbb8cba01d066f392b5eaa9404bfcb775f2196a6bc20eeec3db32d54e94d87ecdb7a0310a5a017c5cdb8ac78597778bd"),

  }

  return dsaCommonSpec;

}


// 设置DSA1024密钥对中包含的全参数

function genDsa1024KeyPairSpecBigE() {

  let dsaCommonSpec = genDsa1024CommonSpecBigE();

  let dsaKeyPairSpec: cryptoFramework.DSAKeyPairSpec = {

    algName: "DSA",

    specType: cryptoFramework.AsyKeySpecType.KEY_PAIR_SPEC,

    params: dsaCommonSpec,

    sk: BigInt("0xa2dd2adb2d11392c2541930f61f1165c370aabd2d78d00342e0a2fd9"),

    pk: BigInt("0xae6b5d5042e758f3fc9a02d009d896df115811a75b5f7b382d8526270dbb3c029403fafb8573ba4ef0314ea86f09d01e82a14d1ebb67b0c331f41049bd6b1842658b0592e706a5e4d20c14b67977e17df7bdd464cce14b5f13bae6607760fcdf394e0b73ac70aaf141fa4dafd736bd0364b1d6e6c0d7683a5de6b9221e7f2d6b"),

  }

  return dsaKeyPairSpec;

}


async function signMessagePromise(priKey: cryptoFramework.PriKey) {

  let signAlg = "DSA1024|SHA256";

  let signer = cryptoFramework.createSign(signAlg);

  await signer.init(priKey);

  let signData = await signer.sign(input);

  return signData;

}


async function verifyMessagePromise(signMessageBlob: cryptoFramework.DataBlob, pubKey: cryptoFramework.PubKey) {

  let verifyAlg = "DSA1024|SHA256";

  let verifier = cryptoFramework.createVerify(verifyAlg);

  await verifier.init(pubKey);

  let res = await verifier.verify(input, signMessageBlob);

  console.info('DSA verify result is ' + res);

  return res;

}


function main() {

  let asyKeyPairSpec = genDsa1024KeyPairSpecBigE();

  let asyKeyGeneratorBySpec = cryptoFramework.createAsyKeyGeneratorBySpec(asyKeyPairSpec);

  // 异步获取非对称密钥生成器生成的密钥

  asyKeyGeneratorBySpec.generateKeyPair(async (err, keyPair) =&amp;gt; {

    if (err) {

      console.error('generateKeyPair: error.');

      return;

    }

    console.info('generateKeyPair: success.');

    // 签名

    let signData = await signMessagePromise(keyPair.priKey)

    // 验签

    let verifyResult = await verifyMessagePromise(signData, keyPair.pubKey);

    if (verifyResult === true) {

      console.info('verify success');

    } else {

      console.error('verify failed');

    }

  })

}
</code></pre><p><strong>3.问题描述：</strong></p><p>从应用设置页跳转至系统设置显示没有权限。</p><p><strong>解决方案：</strong></p><p>应用在权限管理界面的操作，未先进行相关权限申请，则根据系统设计，无法在系统隐私设置权限页面设置，可以参考以下步骤：</p><ol><li>通过<a href="https://link.segmentfault.com/?enc=sApY7GWgz%2BeuI1DtoOAAKA%3D%3D.oANU0%2FovH9a43brGjtbdygFbVRyNzu1AsN4xgtdQGVdUTPsFmlkmKnRKCRmn2GmsWogORMXb8A%2Fal7VtvGF7Vi%2F3Nfiluutfl680on4JVif8G6%2BnY53msn%2F03UkMi3xhehQrYnemo49IcmJq%2F8%2F0z8oL%2Fxvs6DkqbGlxqJNXR4k%3D" rel="nofollow" target="_blank">getSelfPermissionStatus</a>接口查询应用权限状态，参考代码：</li></ol><pre><code class="TypeScript">
getPermissionStatus(permission: string) {

  try {

    let data: abilityAccessCtrl.PermissionStatus = this.atManager.getSelfPermissionStatus(permission);

    console.info(`data-&amp;gt;${data}`);

  } catch (err) {

    console.error(`catch err-&amp;gt;${err}`);

  }

}
</code></pre><ol start="2"><li>当结果为NOT_DETERMINED时，表示未操作。应用声明用户授权权限，暂未调用requestPermissionsFromUser接口请求用户授权，此时可以调用请求用户授权接口进行授权，参考代码：</li></ol><pre><code class="TypeScript">
reqPermissionFromUser(permissionList: Array&lt;permissions&gt;) {

  let atManager: abilityAccessCtrl.AtManager = abilityAccessCtrl.createAtManager();

  let context: Context = this.getUIContext().getHostContext() as common.UIAbilityContext;

  atManager.requestPermissionsFromUser(context, permissionList,

    (err: BusinessError, data: PermissionRequestResult) =&amp;gt; {

      if (err) {

        console.error(`requestPermissionsFromUser fail, err-&amp;gt;${err}`);

      } else {

        console.info('data permissions:' + data.permissions);

        console.info('data authResults:' + data.authResults);

      }

    });

}
</code></pre><ol start="3"><li>当前结果为已授权或未授权时，可以跳转到系统权限设置页面调整，或者使用<a href="https://link.segmentfault.com/?enc=1JDPlRoMfFlrSflfoV8M0A%3D%3D.rn%2BjlEPa2046QWZdblnY3CSNvLLwku3TVNERvV%2B4q1f2bllSGky2ao%2FOW3k%2BWY0a5bmovOb4IpdhwSOMYmtfPa4RP2qCDKRiiJQjaS7CcpKX5g7TmeBKhTitYa%2BVYvxUvOQOIJHuMzkc94neviJSP2RuFoCuMrAMvePlpRFFTR0%3D" rel="nofollow" target="_blank">requestPermissionOnSetting</a>拉起权限设置弹框。参考代码：</li></ol><pre><code class="TypeScript">
applyPermissions(permissionList: Array&lt;permissions&gt;) {

  if (!this.atManager || !this.context) {

    return

  }


  this.atManager.requestPermissionOnSetting(this.context, permissionList)

    .then((data: Array&lt;abilityaccessctrl.grantstatus&gt;) =&amp;gt; {

      console.info(`data: ${data}`);

    })

    .catch((err: BusinessError) =&amp;gt; {

      console.error(`data: ${err}`);

    });

}
</code></pre><p>&lt;/abilityaccessctrl.grantstatus&gt;&lt;/permissions&gt;&lt;/permissions&gt;&lt;/asset.assetmap&gt;&lt;/string&gt;</p>]]></description></item><item>    <title><![CDATA[【FAQ】HarmonyOS SDK 闭源开放能力 — Audio Kit HarmonyOS_SD]]></title>    <link>https://segmentfault.com/a/1190000047557456</link>    <guid>https://segmentfault.com/a/1190000047557456</guid>    <pubDate>2026-01-22 11:15:06</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><strong>1.问题描述：</strong></p><p>如何实现自定义音量调节？</p><p><strong>解决方案：</strong></p><p>设置系统音量</p><p>应用无法直接调节系统音量，系统提供了ArkTS组件<a href="https://link.segmentfault.com/?enc=4Ltum8%2Fs1e8bul5QZmQ7kw%3D%3D.0t%2FHuaMuuZrv3in1UWgEFhIRb9UKEswn5ZMbWD80pol96iCyMbxJOJ3x8vE6MoF3DOQB5RBnv676v3cF8eEIIjdSwM2miucW10OQCRL07l6K7gilxQupwlunCROrPkf0" rel="nofollow" target="_blank">AVVolumePanel音量面板</a>，应用可以创建该组件，让用户通过界面操作来调节音量。</p><p>设置应用音量</p><ol><li><p>管理应用音量的接口由AudioVolumeManager提供，在使用之前，需要使用getVolumeManager()获取AudioVolumeManager实例，示例代码如下：</p><pre><code class="TS">
import { audio } from '@kit.AudioKit';



let audioManager = audio.getAudioManager();

let audioVolumeManager = audioManager.getVolumeManager();
</code></pre></li><li><p>设置应用音量。</p><p>当<a href="https://link.segmentfault.com/?enc=iDBJfxb48XMm2xFzNVo6fQ%3D%3D.%2B%2BiKf6BRmyp28PdMGNoj%2BEOgmKoJGL2%2Bp%2BICHJjvgmd0X5Mh1p6UkGm8uuxQZqoCOVNkiOYzXgppETCevCKaU5KksgTfz63Jpbe0XrLsdm8fZW4wPdA8ljyJ8ftVMtf%2BBpgmFEsKyuMnxZ0EdtnG5A%3D%3D" rel="nofollow" target="_blank">音量模式</a>设置为APP_INDIVIDUAL时，可通过下面示例接口设置应用音量。</p><pre><code class="ts">
// 设置应用的音量（范围为0到100）。

audioVolumeManager.setAppVolumePercentage(20).then(() =&amp;gt; {

  console.info(`set app volume success.`);

});
</code></pre></li></ol><p>设置音频流音量</p><p>在ArkTS API端和Native API端分别有对应的API用来设置音频流音量。</p><p>使用ArkTS API时，开发者可以使用AVPlayer或AudioRenderer的setVolume()方法。</p><ul><li><p>使用<a href="https://link.segmentfault.com/?enc=UAdz%2FcvtlUeq5eUn%2BaVbWg%3D%3D.AUnBW6mybbt6EVv0VYtkSEgL64PMZmD4H5XQn5GNV0lPAgwNS047evihTfx0yC3qzj742OcQsnNKU%2BUewnKowm%2FNJ8kDQajYjW0p1spzmUQBU%2Fp8DxtcmIme1Al1867H4MMO%2Bf%2FlOtyGGUJGIWDn6A%3D%3D" rel="nofollow" target="_blank">AVPlayer</a>设置音频流音量的示例代码如下：</p><pre><code class="ts">
let volume = 1.0;  // 指定的音量大小，取值范围为[0.00-1.00]，1表示最大音量

avPlayer.setVolume(volume);
</code></pre></li><li><p>使用<a href="https://link.segmentfault.com/?enc=BfsDkrs%2FoFBpq4V%2FBnEEHw%3D%3D.1UssOZCS0g4UWwvAqyJtaCTMNSqPqF%2FxIKY6Xmmo7gAmogl6YXtdaq5Wh4DIfG0GnxtGh%2Buw8i9zL8SMV9We5efX%2F0SYnyGq6pwtFHLdv5BjE7ez1pAkut9pPRUhPDKDp81SqTHxdX%2FyR1MzWuVMEg%3D%3D" rel="nofollow" target="_blank">AudioRenderer</a>设置音频流音量的示例代码如下：</p><pre><code class="ts">
import { BusinessError } from '@kit.BasicServicesKit';



audioRenderer.setVolume(0.5).then(() =&amp;gt; {  // 音量范围为[0.0-1.0]

  console.info('Invoke setVolume succeeded.');

}).catch((err: BusinessError) =&amp;gt; {  

  console.error(`Invoke setVolume failed, code is ${err.code}, message is ${err.message}`);

});
</code></pre></li><li><p>使用Native API时开发者可使用<a href="https://link.segmentfault.com/?enc=NjmO0IPHfymqf7Eobyx4LA%3D%3D.%2FA4D%2B7c%2BTpAV8jbv%2FqueucYWboATbv3YDdIPfu36YlBal1eCZSNnIwBb7Gs4OUv1Vu03z85wc%2FAG4Ki2qdkHBSke8RjZLZwUwZz0vJonYdtotMLGNtrfnzXC3UTsAHACfySLmJMFk5qFvwluTlzW5%2FBnrelyCITJyY0JrFhsUMA%3D" rel="nofollow" target="_blank">OH_AudioRenderer_SetVolume</a>接口设置当前音频流音量值，示例代码如下：</p><pre><code class="C++">
// 要设置的音量值，音量值的范围是[0.0, 1.0]。

float volume = 0.5f;



// 设置当前音频流音量值。

OH_AudioStream_Result OH_AudioRenderer_SetVolume(audioRenderer, volume);
</code></pre></li></ul><p>请注意：</p><ul><li><strong>setVolume接口</strong>调整的是音频流本身的音量，不是系统音量，音量条本身不会发生变化，而且音频流本身的音量默认值是1，即以系统音量来播放，应用只可以在系统音量的基础上调到0~1倍，不会超过系统音量，也不会影响系统音量的值（即音量条）。</li><li>为确保用户能感知音量变化，应用后台不能调节音量，否则系统会做出对应的控制措施，因此音量面板设置volumeLevel初始值是不生效的，只有改变volumeLevel值触发音量面板，才会改变当前系统音量；并且音量面板调节具体音量由系统控制，当前播放什么音频就调节什么音量，没有播放时就会调节媒体音量。</li></ul><p><strong>2.问题描述：</strong></p><p>如何实现支持滑动的视频音量调节功能？</p><p><strong>解决方案：</strong></p><p><a href="https://link.segmentfault.com/?enc=GbRi4GWI2xCEmOtbpXn3sg%3D%3D.df4%2BoISAx5k%2BxmwLItD1%2BKN8Vbsd6DnBbMuOjFbAavugJsHMH1wOzpPjcZDaHFMsbn6CntsZtwFN6P4o9DKMjyjyc60wfbFxN0aKZ4ghK4UOD0ujh3Tikz4jPGW7lLjZ" rel="nofollow" target="_blank">Slider</a>组件结合音频流音量管理<a href="https://link.segmentfault.com/?enc=Uu7JyeQTxcTgPjJeomUk3A%3D%3D.x0XZu58uYNdQwmBxpoVkGZq%2BTT%2F5lfNmzOiHkMFqvGKo6HJ3cNq9PFybj%2BZd2bicyVxGVBI7jKnAy9%2BevGT9uYUd8lvCcwSaaeEZv%2B48IMQI101W0h8llD8dT%2F0fK%2Fpb3rNf4JaevE70JFJg6RJ8%2Fg%3D%3D" rel="nofollow" target="_blank">AVPlayer</a>或<a href="https://link.segmentfault.com/?enc=IJ%2BjK6AW4F5R2muVkGy1Hw%3D%3D.DiNJ7Gim4YRbZJawYy8npCelKhE%2BnTvzkk2j%2FhDJwu1MDs8304xfOhsJON1d1mMvL%2Fe7g0sRofHXXzy0Ze%2F8FX9b0ebUYJv0CozqYFO%2F485VUaBZTwKQSbDznal%2Bgp%2FDYmq49Zmw0FU5nsE2EBpOlA%3D%3D" rel="nofollow" target="_blank">AudioRenderer</a>实现。Slider组件用于支持用户滑动获取音量值，将获取到的值通过setVolume接口传递给音频音量管理实现音量滑动控制调节。</p><p><strong>3.问题描述：</strong></p><p>集成腾讯云点播实现视频播放，自定义声音按钮实现音量滑动调节有什么比较好的策略？</p><p><strong>解决方案：</strong></p><p>使用<a href="https://link.segmentfault.com/?enc=oJ7et3FlHtr0dMLrN6KHbA%3D%3D.FLIidWZmhveKlktRy97ZPq0wIOu6bZtgw5%2FBpQ1%2Bfwp1mcZhGMzoya9e%2BEr%2BHXD%2BH8ECIUb48Q6rR7Q9BL3qLbJJxL4d7ZPewEP9K%2FkhNT%2BCwyJz3KUSmnDMtmZBO%2FZs" rel="nofollow" target="_blank">Slider</a>组件实现音量控制滑动条，结合腾讯云点播SDK的setAudioPlayoutVolume方法进行实现。实现时，建议默认音量100，即默认系统当前音量播放。</p><p><strong>4.问题描述：</strong></p><p>音乐播放器的音频输出如何增加PCM输出模式，支持数字耳放小尾巴usb独占？</p><p><strong>解决方案：</strong></p><p>方案一：使用AudioRenderer直接播放PCM格式的音频数据。</p><p>AudioRenderer可以直接播放PCM数据，还可以通过数据预处理来实现更灵活的播放，关键代码如下：</p><ol><li>配置文件路径：</li></ol><pre><code class="TS">
let bufferSize: number = 0;

let path = getContext().cacheDir;

let filePath = path + '/StarWars10s-2C-48000-4SW.wav';

let file: fs.File = fs.openSync(filePath, fs.OpenMode.READ_ONLY);
</code></pre><ol start="2"><li>读取文件数据：</li></ol><pre><code class="TS">
try {

  fs.readSync(file.fd, buffer, options);

  bufferSize += buffer.byteLength;

  // 系统会判定buffer有效，正常播放。

  return audio.AudioDataCallbackResult.VALID;

} catch (error) {

  console.error('Error reading file:', error);

  // 系统会判定buffer无效，不播放。

  return audio.AudioDataCallbackResult.INVALID;

}
</code></pre><ol start="3"><li>调用start()方法进行音频渲染</li></ol><pre><code class="TS">
audioRenderer.start((err: BusinessError) =&amp;gt; {

  if (err) {

    console.error(`Renderer start failed, code is ${err.code}, message is ${err.message}`);

  } else {

    console.info('Renderer start success.');

  }

});
</code></pre><p>具体开发步骤以及完整代码可以参考<a href="https://link.segmentfault.com/?enc=6P83Zf8CGVJDxM%2FBvtV57w%3D%3D.MQ6ciVr42Q7pINrYcF1AQ15mi5dvNgJ0HodDASmbsX5x3GT3bk4lhZdwEFqE1pnfQ8fPwtyVdR5FtaQGDZ4lmZ3J7h%2FJQkGWvR292E4%2FharvJclxCU3Pn5CtLiN7ipBJIXRo2GW3BhLoQnkJTTp%2BWfaNoeYstqhlcnVSafX6bfU%3D" rel="nofollow" target="_blank">AudioRenderer的开发步骤</a>。</p><p>方案二：对PCM数据进行音频转码后使用AVPlayer播放。</p><p>AVPlayer无法直接播放PCM格式的音频数据，需要将音频数据转码封装成AVPlayer支持的格式。PCM格式数据是裸流，播放占用内存大，使用AVPlayer播放封装后的音频数据会占用更小的内存。</p><p>这里以WAV格式为例，WAV格式是一种无损的格式，可以最好地保存音频质量，如果对音频大小或者格式有其他要求，可以参考<a href="https://link.segmentfault.com/?enc=6%2BWl%2BV%2F9ekZAY3WvC2NjIA%3D%3D.2J5f5g966h9%2F2A1LE7nmXnThtnNNZetlEV3U3bepA9At%2FCevMwwdPPlDHUNtMb3v2PVRt1CcpAevbwoC0tjXe3qWiVG0ZLs3GEIuDC8EQ%2FE%3D" rel="nofollow" target="_blank">音频编码</a>和<a href="https://link.segmentfault.com/?enc=2nftjBi7FGxnrWOkSALoIw%3D%3D.OIZOryB5NysGfJURXUEm1ZZzrWJvRqMB17T9b3PDOp6jscscQNgr7ghWZaDqXxsud59g2dm0xJcD5LLivw3b7AQbCXvJviujBK%2FvCfI78AM%3D" rel="nofollow" target="_blank">媒体数据封装</a>进行其他的音频编码格式转化。</p><p>现在将PCM数据转码封装成完整的WAV文件再用AVPlayer播放，参考代码如下：</p><ol><li>定义PCM转WAV的方法，获取源文件路径和目标文件路径，分别写入WAV文件头和PCM数据，参考代码如下：</li></ol><pre><code class="TS">
public pcmToWav(src:string, dest:string){

  const inFile: fs.File = fs.openSync(src, fs.OpenMode.READ_ONLY);

  const outFile: fs.File = fs.openSync(dest, fs.OpenMode.READ_WRITE | fs.OpenMode.CREATE);

  let byteRate = 16 * sampleRate * channel / 8;

  const inFileStat = fs.statSync(inFile.fd)

  // 获取源文件信息，包括文件大小等

  let audioDataSize = inFileStat.size;

  let totalDataLen = audioDataSize + 36;

  console.log('audioDataSize= ', audioDataSize)

  // 1.wav文件头编写

  this.writeWavFileHeader(outFile, audioDataSize, totalDataLen, byteRate);

  // 2.写入pcm数据

  this.writePcmData(inFile, outFile, audioDataSize)

}
</code></pre><ol start="2"><li>定义写入WAV头部信息的方法，创建一个大小为44字节的缓冲区，用于存储WAV文件的头部信息，再将其写入输出文件，参考代码如下：</li></ol><pre><code class="TS">
private writeString(dv:DataView, offset:number, str:string){

  for (let i = 0; i &amp;lt; str.length; i++) {

    dv.setUint8(offset + i, str.charCodeAt(i));

  }

}

// 定义写入WAV头文件信息的方法

private writeWavFileHeader(out:fs.File, audioDataSize:number, totalDataLen:number, byteRate:number){

  const header = new ArrayBuffer(44);

  const dv = new DataView(header);

  const bitsPerSample = 16; // 当前位深是16

  // 写入RIFF块

  this.writeString(dv, 0, 'RIFF');

  dv.setUint32(4, totalDataLen, true);

  this.writeString(dv, 8, 'WAVE');

  // 写入fmt块

  this.writeString(dv, 12, 'fmt ');

  dv.setUint32(16, 16, true); // fmt块大小

  dv.setUint16(20, 1, true); // 格式类别(PCM)

  dv.setUint16(22, channel, true); // 通道数

  dv.setUint32(24, sampleRate, true); // 采样率

  dv.setUint32(28, byteRate, true); // 比特率

  dv.setUint16(32, channel * bitsPerSample / 8, true); // 每个采样点的字节数

  dv.setUint16(34, bitsPerSample, true); // 位深

  // 写入data块

  this.writeString(dv, 36, 'data');

  dv.setUint32(40, audioDataSize, true); // 数据块大小

  console.log('audioDataSize= ', audioDataSize)

  // 将头文件信息写入输出文件

  fs.writeSync(out.fd, new Uint8Array(header).buffer, {

    length: 44

  })

}

 
</code></pre><ol start="3"><li>定义读取pcm数据的方法，将PCM数据从输入文件写入输出文件，使用fs.readSync读取输入文件的数据，并写入输出文件，直到读取完毕，参考代码如下：</li></ol><pre><code class="TS">
private writePcmData(inFile:fs.File, outFile:fs.File, audioDataSize:number){

  // 写入PCM数据

  let readSize = 0

  let data = new ArrayBuffer(audioDataSize);

  let readOptions: ReadOptions = {

    offset: readSize,

    length: audioDataSize

  };

  let readLen = fs.readSync(inFile.fd, data, readOptions);

  while (readLen &amp;gt; 0) {

    readSize += readLen;

    fs.writeSync(outFile.fd, data, { length: readLen });

    readOptions.offset = readSize;

    readLen = fs.readSync(inFile.fd, data, readOptions);

  }

  fs.closeSync(inFile.fd)

  fs.closeSync(outFile.fd)

}

 
</code></pre><ol start="4"><li>完成转码后让AVPlayer使用fs文件系统打开沙箱地址获取媒体文件地址并通过dataSrc属性进行播放，AVPlayer的具体开发流程可以参考<a href="https://link.segmentfault.com/?enc=rFO%2B%2F3k2WyzIEwYUHsgBtA%3D%3D.oVzH12nohl1ONaXsVpUUjnqxCqFb7MNvayAjAcU65427oAvwDCqR3Fpetj%2BJt0nsVy0JNaw3kIeYY2SxNxoS8RoGVvELR4owaZs0WKMElgmZhMdcGOBeHNMLgTdBg7XVVG3afpCpjnlbMPDqZQxc8A%3D%3D" rel="nofollow" target="_blank">AVPlayer播放音频完整示例</a>。</li></ol>]]></description></item><item>    <title><![CDATA[三步构建你的敏捷中枢：节点式思维对齐工具落地全攻略 Ord1naryLife ]]></title>    <link>https://segmentfault.com/a/1190000047557458</link>    <guid>https://segmentfault.com/a/1190000047557458</guid>    <pubDate>2026-01-22 11:14:13</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在多项目并发与复杂任务流管理的数字化协作中，传统的线性计划已难以应对灵活多变的业务需求 。如果计划编排缺乏原子化的卡片管理，可能会导致：</p><ul><li><strong>执行断层</strong>：计划背景被淹没在厚重文档中，导致执行者无法直观获取关键信息 。</li><li><strong>排期僵化</strong>：无法快速响应需求变更，导致项目排期与实际进度严重脱节。</li><li><strong>透明度缺失</strong>：团队成员难以实时了解全局节奏及各阶段的准入准出标准。</li><li><strong>资源错配</strong>：缺乏对任务依赖关系的清晰视图，容易造成资源闲置或关键路径阻塞。</li></ul><p>卡片式计划编排工具通过将模糊的项目计划转化为可灵活组合、可实时追踪、可多维对齐的卡片执行引擎，确保团队在复杂的竞争环境中实现精准交付 。</p><h2><strong>卡片式计划编排工具的核心特性</strong></h2><ul><li><strong>原子化任务卡片</strong>：将复杂计划拆解为独立卡片，封装背景、标准、工时等核心元数据 。</li><li><strong>多维可视化视图</strong>：支持看板、时间线、甘特图等多种表现形式，实现计划的直观编排 。</li><li><strong>依赖关系建模</strong>：清晰标记卡片间的逻辑关联（如包含、阻塞、并行），自动计算关键路径 。</li><li><strong>自动化流转规则</strong>：基于触发器实现卡片状态自动更新，确保计划与执行同步 。</li><li><strong>递归进度核算</strong>：底层原子卡片的执行质量自动驱动顶层计划的达成率评估。</li></ul><h2><strong>卡片式计划编排工具的重要意义</strong></h2><ol><li><strong>消除信息颗粒度偏差</strong>：通过卡片的高度封装，确保执行层与管理层在任务定义上达成高度共识 。</li><li><strong>提升排期灵活性</strong>：支持通过拖拽、连线等操作快速调整计划，大幅降低重排排期的成本。</li><li><strong>强化过程确定性</strong>：实时审计实际流转速率与排期模型的差异，实现风险的主动预警与修正 。</li><li><strong>沉淀组织标准化路径</strong>：将验证有效的编排模式固化为卡片模板，实现项目经验的快速复用。</li></ol><h2><strong>应用场景</strong></h2><ul><li><strong>敏捷迭代管理</strong>：将产品愿景拆解为 Sprint 任务卡片，驱动研发交付流高效流转。</li><li><strong>复杂项目规划</strong>：在启动阶段梳理各模块间的依赖链路，利用卡片编排规避交付冲突 。</li><li><strong>资源负载均衡</strong>：通过可视化看板监控各环节卡片堆积情况，实现动态的人力资源调度。</li><li><strong>跨团队协同</strong>：通过共享的计划卡片池，对齐跨职能部门的协作节奏与产出标准 。</li></ul><h2>---</h2><p><strong>5款值得尝试的卡片式计划编排工具</strong></p><h3><strong>1. 板栗看板</strong></h3><p>直观的任务流转与多层级穿透</p><ul><li><strong>特点</strong>：支持任务卡片的无限层级嵌套，通过看板视图展示计划的深度编排逻辑。</li><li><strong>优势</strong>：看板视图极度直观，支持卡片逻辑连线，适合追求过程透明的敏捷团队。</li><li><strong>适合团队</strong>：需要快速响应并对计划进行纵向穿透的小型和中型研发团队 。</li></ul><h3><strong>2. ClickUp</strong></h3><p>全功能任务编排与数据看板平台</p><ul><li><strong>特点</strong>：提供强大的“目标”模块，支持将微观卡片进度自动聚合为宏观指标。</li><li><strong>优势</strong>：支持极高维度的自定义，能根据卡片元数据生成复杂的排期审计报告。</li><li><strong>适合团队</strong>：需要对大规模计划进行参数化管理和深度数据分析的团队 。</li></ul><h3><strong>3. Trello</strong></h3><p>简单轻量的卡片流转工具</p><ul><li><strong>特点</strong>：强调“清单化”的计划编排，支持丰富的卡片封面与标签分类 。</li><li><strong>优势</strong>：操作极简，学习曲线极低，适合快速搭建基础的交付工作流 。</li><li><strong>适合团队</strong>：注重任务分类和灵活调整、倾向于视觉驱动型协作的团队 。</li></ul><h3><strong>4. Jira Software</strong></h3><p>工业级标准与自动化编排引擎</p><ul><li><strong>特点</strong>：拥有严密的权限与流程控制逻辑，支持复杂的卡片依赖与版本排期。</li><li><strong>优势</strong>：可与代码仓库深度集成，实现从“计划编排”到“自动执行”的闭环审计。</li><li><strong>适合团队</strong>：追求高度标准化执行、有严格合规与闭环审计需求的大型组织。</li></ul><h3><strong>5. Monday.com</strong></h3><p>高度自由的卡片式协同看板</p><ul><li><strong>特点</strong>：支持看板与时间轴、工作负荷视图的实时联动，动态展示卡片状态。</li><li><strong>优势</strong>：视觉色彩丰富，支持强大的自动化集成，能显著提升团队编排兴趣。</li><li><strong>适合团队</strong>：强调团队协同氛围、需要灵活配置复杂编排场景的项目组。</li></ul><h2>---</h2><p><strong>如何选择合适的卡片式计划编排工具？</strong></p><h3><strong>1. 按团队规模选择</strong></h3><ul><li><strong>小型团队（1-10人）</strong>：推荐 <strong>板栗看板</strong>、Trello 等工具，侧重于快速启动与核心任务的直观流转。</li><li><strong>中型团队（10-50人）</strong>：适合使用 <strong>Monday.com</strong>、ClickUp，支持更复杂的多维对齐与资源核算 。</li><li><strong>大型团队（50+人）</strong>：建议选择 <strong>Jira</strong> 或 <strong>ClickUp</strong>，这些工具提供强大的层级管理与权限隔离功能。</li></ul><h3><strong>2. 按计划复杂度选择</strong></h3><ul><li><strong>线性任务</strong>（如内容生产、日常运营）：选择 <strong>板栗看板</strong>、Trello 等简洁易用的视图工具 。</li><li><strong>交叉任务</strong>（如软件研发、系统重构）：推荐 <strong>Jira</strong>、<strong>板栗看板</strong>等支持深度连线与递归逻辑核算的专业平台。</li></ul><h2>---</h2><p><strong>提升计划编排效率的小建议</strong></p><ol><li><strong>坚持卡片原子化</strong>：确保每张卡片描述的是最小可执行单元，避免职责模糊。</li><li><strong>设置基准流转速率</strong>：定期审计实际完成时长，为后续计划编排提供真实的数据支撑。</li><li><strong>建立风险预警连线</strong>：为关键路径上的卡片设置依赖预警，确保下游环节能提前预知变动 。</li><li><strong>定期进行计划“减脂”</strong>：及时清理、归档过时卡片，保持编排体系的干练与精准执行力。</li></ol><h2>---</h2><p><strong>总结</strong></p><p>卡片式计划编排工具是管理组织执行复杂性的关键手段。通过 板栗看板、ClickUp、Jira 等工具，团队能够将宏观的战略意图精准解构为微观的原子卡片，实现“计划-执行-状态”的实时对齐。</p><p>精准的编排，是高效交付的基石。</p>]]></description></item>  </channel></rss>