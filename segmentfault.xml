<?xml version="1.0" encoding="UTF-8"?><rss version="2.0">  <channel>      <title>SegmentFault - 最近文章</title>      <link>https://segmentfault.com/blogs/newest</link>      <description>SegmentFault 思否</description>      <generator>python segmentfault.py @Pi20</generator>      <item>    <title><![CDATA[将研发了近10年的跨境ERP开源了，现实却很无奈！ Wimoor ]]></title>    <link>https://segmentfault.com/a/1190000047459907</link>    <guid>https://segmentfault.com/a/1190000047459907</guid>    <pubDate>2025-12-09 11:11:07</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>说起开源，大家都知道大名顶顶的Odoo，Odoo真那么完美吗？依我看未必如此。Odoo虽然开源，却还是分社区版和企业版的，社区版几乎只剩进销存功能，如果是生产制造企业，要么要自己进行定制开发，要么是租用企业版的模块，再要么买企业版授权，不然还是用不起来。而且国外软件的设计对国内企业也不够友好，操作复杂，不符合国内操作习惯，业务流程也跟国内有着天壤之别……</p><p>总结：Odoo虽好，但是不适合中国宝宝体质，还是选择国内开源ERP更为稳妥。例如国内首款百分百开源、支持商用的<strong>Wimoor ERP</strong>！<br/><img width="723" height="382" referrerpolicy="no-referrer" src="/img/bVdniFN" alt="image.png" title="image.png"/></p><h3>为什么开源？</h3><p>2022年我们决定将团队自2016年起，完全自主研发、从0起步的跨境ERP系统进行开源。 彼时正值疫情爆发，做跨境行业的朋友应该都理解下这个决定内心会有多么挣扎，但经过深思熟虑还是觉得必须得走这一步了，主要有以下三个原因：</p><p><strong>第一，AI大大降低了技术门槛，产品功能方面将不再能够形成很深的护城河</strong>。随着各种开发模板、低代码平台以及cursor等工具的不断普及，未来任何团队只需要花很小的成本，就能够快速生成一个具备核心功能的竞品。 过去那种靠时间积累出的所谓【功能和技术壁垒】，价值将越来越低。索性不如通过开源成熟的项目，让更多潜在的同行加入进来，形成合作而非竞争关系。</p><p><strong>第二，这个时代，引流营销及运营远比产品本身更重要</strong>。如今，几乎每个行业都面临产品过剩、供大于求的局面。一个项目能否成功，产品已非决定性因素（100分和80分的产品对用户来说区别不大），而是更多地取决于团队的营销、运营、转化等能力。 目前，我们这个赛道已经有不少拿到钱的同行，已经开始靠疯狂砸钱补贴用户来拓展市场份额。而这方面我们毫无优势，选择开源项目可能是一个低成本提高影响力的方式。</p><p><strong>第三，定制化或成为公司新的营收方式</strong>。过去公司主要依赖少数几个忠实客户的租赁费作为主要收入来源，但这些收入其实极为有限。反正也是不赚钱，还不如卖个人情，吸引更多开发者和企业用户使用，这样总会有定制的需求找到我们，虽然这个钱赚的很辛苦，但是对于不擅长营销的我们别无他法。</p><h3>系统展示</h3><p><img width="723" height="384" referrerpolicy="no-referrer" src="/img/bVdniEk" alt="" title="" loading="lazy"/><br/><img width="723" height="363" referrerpolicy="no-referrer" src="/img/bVdniEm" alt="" title="" loading="lazy"/><br/><img width="723" height="364" referrerpolicy="no-referrer" src="/img/bVdniEn" alt="" title="" loading="lazy"/></p><p>选择将团队研发了近10年的ERP开源是一个艰难的决定，希望这么做能得到好的反馈吧。</p>]]></description></item><item>    <title><![CDATA[企业知识管理新选择：五款AI Wiki软件深度测评与实战指南 百川云开发者 ]]></title>    <link>https://segmentfault.com/a/1190000047459937</link>    <guid>https://segmentfault.com/a/1190000047459937</guid>    <pubDate>2025-12-09 11:10:25</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在信息爆炸的2025年，企业知识管理正经历着一场由AI驱动的革命。传统的文档管理系统已无法满足现代企业对知识高效流转、智能应用的需求，而新一代AI Wiki软件正在重塑企业知识管理的格局。本文将为您深度剖析五款在2025年表现突出的AI Wiki工具，帮助您找到最适合企业需求的知识管理解决方案。</p><h2>一、AI Wiki软件：企业知识管理的新范式</h2><p>随着大模型技术的成熟，Wiki软件已从简单的文档存储工具进化为智能知识中枢。现代AI Wiki不仅能存储海量知识，更能理解内容语义、自动关联知识点、智能回答用户问题，甚至主动推荐相关知识。这种转变使得企业知识从"被动查询"变为"主动服务"，大幅提升了知识利用率和员工工作效率。</p><p>在2025年的技术环境下，优秀的AI Wiki软件通常具备以下核心能力：多模态知识管理（支持文本、表格、代码、图片等多种内容格式）、智能语义搜索、自然语言问答、知识自动关联、团队协作编辑、细粒度权限控制等。这些功能共同构成了企业知识管理的智能基础设施。</p><h2>二、2025年五款顶尖AI Wiki软件横向评测</h2><h3>1. PandaWiki：企业级开源知识中枢</h3><p><img width="723" height="319" referrerpolicy="no-referrer" src="/img/bVdnbcA" alt="" title=""/></p><p>PandaWiki作为一款AI大模型驱动的开源知识库系统，在2025年获得了众多技术型企业的青睐。其最大特色是提供从文档创作、团队协作到AI问答的全流程解决方案，真正实现了知识管理的闭环。</p><p><strong>核心优势：</strong></p><ul><li><strong>开箱即用的AI能力</strong>：内置AI创作、AI问答、AI搜索三大核心功能，非技术团队也能轻松使用</li><li><strong>企业级知识管理</strong>：完善的权限体系、版本控制、多终端集成，适合构建企业制度中心、技术文档库等严肃场景</li><li><strong>卓越的召回效果</strong>：知识库问答能精准过滤无关信息，回答简洁明了，避免了大模型常见的"废话连篇"问题</li><li><strong>灵活的部署方式</strong>：基于Docker的一键部署，同时也支持SaaS模式，满足不同企业的IT策略<br/><img width="723" height="366" referrerpolicy="no-referrer" src="/img/bVdniEZ" alt="" title="" loading="lazy"/><br/><strong>适用场景：</strong><br/>PandaWiki特别适合中大型企业构建系统化知识管理体系，尤其是需要跨部门协作、客户服务集成或严格权限控制的场景。从我们的实测来看，它在替代Confluence搭建企业文档中心、构建销售/客服知识支撑系统等方面表现尤为出色。</li></ul><p>了解更多：<a href="https://link.segmentfault.com/?enc=XtfTIQ4a9fDvjUq2fXhstw%3D%3D.h5XNXG5IMNEC6tdcWtiPBsD8%2Bjc9DI4TDvgl8XeXAL5anWUcELubkBRgujEoCJb5x61u859Bf%2B%2FuBXWRj192As7%2F2xHKjJzcHN6kw26KFNw%3D" rel="nofollow" target="_blank">PandaWiki官方文档</a></p><h3>2. DeepWiki：开发者专属的智能文档平台</h3><p>由Cognition AI推出的DeepWiki是2025年技术文档领域的一匹黑马。它专为解决开发者文档难题而设计，能将GitHub代码库自动转化为交互式、易懂的技术文档。</p><p><strong>创新功能：</strong></p><ul><li><strong>代码智能解析</strong>：自动分析代码结构、功能模块、依赖关系，生成结构化技术文档</li><li><strong>可视化工具</strong>：通过交互式图表展示复杂代码关系，降低理解门槛</li><li><strong>上下文感知问答</strong>：AI助手能结合代码上下文给出精准解答，而非泛泛而谈</li><li><strong>实时同步</strong>：与代码仓库保持同步更新，确保文档时效性</li></ul><p><strong>适用场景：</strong><br/>DeepWiki特别适合开源项目团队、技术型企业和教育机构。它不仅能大幅降低文档编写负担，还能通过可视化手段让复杂技术更易理解，是技术传播的理想工具。</p><h3>3. MaxKB：轻量级知识问答引擎</h3><p>MaxKB在2025年专注于打造极致轻量的知识问答体验。与PandaWiki的全功能定位不同，MaxKB更注重问答场景下的性能和准确率。</p><p><strong>产品亮点：</strong></p><ul><li><strong>毫秒级响应</strong>：优化后的检索算法能在海量知识中快速定位答案</li><li><strong>精准问答</strong>：通过强化学习不断优化答案质量，减少无关信息</li><li><strong>多平台集成</strong>：提供API和插件，可轻松嵌入各类业务系统</li><li><strong>学习曲线平缓</strong>：界面简洁，上手难度低，适合快速部署</li></ul><p><strong>适用场景：</strong><br/>MaxKB适合需要快速搭建智能问答系统的中小企业，特别是客服自动化、内部知识查询等场景。如果您的需求主要集中在问答而非全功能知识管理，MaxKB会是不错的选择。</p><h3>4. ChatWiki：对话式知识协作平台</h3><p>ChatWiki将即时通讯的便捷性与Wiki的结构化知识管理相结合，创造出独特的"对话式知识协作"体验。</p><p><strong>创新体验：</strong></p><ul><li><strong>聊天界面操作</strong>：通过自然语言指令完成文档创建、编辑、查询等操作</li><li><strong>智能知识推荐</strong>：根据对话上下文主动推送相关知识卡片</li><li><strong>实时协作</strong>：支持多人同时编辑，变更实时可见</li><li><strong>情绪分析</strong>：能识别用户查询中的情绪倾向，调整回答方式</li></ul><p><strong>适用场景：</strong><br/>ChatWiki特别适合年轻化、重协作的团队，尤其是创意型、市场类部门。它将知识管理融入日常沟通，降低了使用门槛，提高了知识贡献率。</p><h3>5. Dify：低代码AI知识平台</h3><p>Dify主打"让每个企业都能轻松构建AI知识库"的理念，通过低代码方式降低AI应用门槛。</p><p><strong>核心价值：</strong></p><ul><li><strong>可视化编排</strong>：拖拽式界面设计知识流程，无需编码</li><li><strong>多模型支持</strong>：可灵活切换不同大模型作为知识引擎</li><li><strong>业务集成</strong>：提供丰富模板，快速对接CRM、ERP等业务系统</li><li><strong>成本可控</strong>：按需付费模式，适合预算有限的中小企业</li></ul><p><strong>适用场景：</strong><br/>Dify是技术资源有限但希望快速部署AI知识系统的企业的理想选择。其低代码特性让业务部门能自主搭建知识应用，减少对IT部门的依赖。</p><h2>三、选型建议：如何选择最适合的AI Wiki</h2><p>面对五款各具特色的产品，企业该如何做出明智选择？我们建议从以下几个维度考量：</p><ol><li><strong>团队规模与技术能力</strong>：大型技术团队可能偏好PandaWiki的开源灵活性，而中小非技术团队可能更适合Dify的低代码方案</li><li><strong>核心需求场景</strong>：如果重点是技术文档，DeepWiki是专业选择；如果追求全功能知识管理，PandaWiki更全面</li><li><strong>预算与IT策略</strong>：开源方案初期成本低但需要运维投入，SaaS方案则相反</li><li><strong>未来扩展性</strong>：考虑3-5年内业务发展可能带来的知识管理需求变化</li></ol><p>根据我们的实测评估，<strong>PandaWiki</strong>在综合能力上表现最为均衡，特别适合将知识管理作为长期战略的企业。其"知识库+AI"的全闭环能力不仅能满足当下需求，更能随着企业发展不断扩展应用场景。</p><h2>四、AI Wiki的未来趋势</h2><p>展望2026年，AI Wiki软件将呈现以下发展趋势：</p><ul><li><strong>多模态深度融合</strong>：支持视频、3D模型等更丰富的内容形式</li><li><strong>主动知识服务</strong>：从被动应答进化为主动推送相关知识</li><li><strong>业务流程深度整合</strong>：知识系统与业务系统无缝衔接，实现"知识随行"</li><li><strong>个性化体验</strong>：根据用户角色、习惯提供定制化知识视图</li></ul><p>在这个知识即竞争力的时代，选择一款合适的AI Wiki软件，就是为企业装上智能知识引擎。无论您最终选择哪款产品，重要的是开始行动——将企业知识资产数字化、智能化，为未来发展奠定坚实基础。</p><p>想深入了解PandaWiki如何助力您的企业知识管理？欢迎访问<a href="https://link.segmentfault.com/?enc=PIq4GZzS4u6%2BUdDB1%2FD8UQ%3D%3D.dIxUiEv%2Fapa6l%2BOBc3z%2BvCUYIc%2BtesQaj2wwouEVrSb5LJzSqx%2BSp93jWi99g6%2FyNQQ7RSkZn7ZocHX75g473M1Tj9AZHsFHgxMuf81spRY%3D" rel="nofollow" target="_blank">官方文档</a>获取更多信息，或申请产品演示体验其强大功能。</p>]]></description></item><item>    <title><![CDATA[巡查做了，隐患还在！为什么企业的隐患闭环这么难 温文尔雅敲代码 ]]></title>    <link>https://segmentfault.com/a/1190000047459947</link>    <guid>https://segmentfault.com/a/1190000047459947</guid>    <pubDate>2025-12-09 11:09:29</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在制造企业里，“巡查闭环”是管理会议上经常被提到的词。几乎所有工厂都有巡查制度，表格、检查点、班组责任、月度通报……一套机制看起来都很完整。但真正落地时，常见的困境却是这样的：</p><ul><li>巡查做了，问题上报了，但没人跟进；</li><li>整改做了，但复查没有落地；</li><li>数据分散在各种群里、纸张里，管理层无法看到全貌；</li><li>同样的问题隔三差五反复出现。</li></ul><p>为什么闭环如此难？为什么巡查看似做了很多，却很难转化为管理改善？本文尝试从工厂的真实情况出发，回答这个问题。</p><h2>一、巡查本身不是目的，“闭环”才是</h2><p>很多制造企业的巡查制度依旧停留在：检查次数够不够、有没有按规定填表、制度有没有上墙，这些工作能确保“巡查被做”，但并不能保证“问题被解决”。</p><p>一个真正有效的巡查体系，应该反问的是：“巡查发现的问题，有没有派给对的人？有没有在规定时间内处理？”</p><p>如果巡查只是停留在记录，而不是推动整改，那么巡查体系很快会被一线视为额外负担，最终管理层也无法从中看到价值。</p><p>所以，从管理逻辑看，巡查的核心不是“发现”，而是“闭环”。</p><h2>二、隐患闭环为什么难做</h2><p>巡查闭环的难点并不是人不用心，而是机制断档。以下四个原因，在不同工厂中普遍存在。</p><h3>难点一：问题的流转路径不清晰</h3><p>很多工厂的问题处理路径都是这样的：</p><blockquote>巡查人拍照发群 → 群里回复“收到” → 最后没人明确“谁来处理”</blockquote><p>尤其是跨部门区域，如公共通道、仓库边界线，责任界限往往模糊。</p><p>本质问题是：没有一个清晰、固定的责任分派机制。</p><h3>难点二：信息分散在纸、群里、手机里</h3><p>一个常见案例：巡查记录在纸上，隐患照片在个人手机，整改情况在微信群，复查记录在另一个 Excel，统计数据靠人工拼凑。当管理层问一句：“这个问题最后处理了吗？”调查的成本往往比处理问题还高。</p><p>信息分散带来两个直接后果：</p><ul><li><strong>透明度低</strong>：管理者无法看到问题从发现到整改的完整流程；</li><li><strong>无法复盘</strong>：缺少结构化数据，自然无法知道重复问题、隐患成因。</li></ul><h3>难点三：重复问题无法被统计，导致“治标不治本”</h3><p>同样的问题今天出现一次，下周再一次，下个月又三次，但每次都被当成“新问题”处理。原因很简单：没有沉淀数据。</p><p>区域巡查如果只是把问题“处理掉”，但没有把数据“留下来”，企业就永远只能停留在“灭火模式”，而无法进入“系统治理”。</p><h3>难点四：责任压力落不到具体人身上</h3><p>管理里最避讳的两个字就是：<strong>大家</strong>。“大家注意一下”、“大家尽快整改”。在管理学里，“大家”等于“没人”。</p><p>闭环要想真正执行，必须做到责任明确：谁接单？谁整改？谁复查？超时谁负责？</p><p>闭环不是靠喊出来的，而是靠机制来压实责任。</p><h2>三、闭环的本质不是流程，而是协同</h2><p>巡查闭环涉及三条“线”：</p><ul><li><strong>时间线</strong>：什么时候发现、什么时候分派、什么时候处理；</li><li><strong>责任线</strong>：谁发现、谁承担、谁复查；</li><li><strong>信息线</strong>：信息能否稳定地流向正确的人。</li></ul><p>任意一条线断掉，都容易导致闭环失败。</p><p>目前市面上有很多数字化工具，主要价值就是让这三件事变得更稳定、透明、可控，而不是为了看起来企业更先进。</p><h2>四、数字化工具能否解决问题</h2><p>近几年，不少工厂逐步将数字化从生产管理拓展到隐患治理方面，想借助工具让巡查闭环真正跑起来。市面上方案大致可分为三类：</p><ul><li><strong>大型系统类</strong>（如 SAP EAM、IBM Maximo）：功能强大但实施周期长（3–6 个月），成本高（几十万到百万级），适合有 IT 团队的大型集团企业；</li><li><strong>电子表单工具</strong>：部署快、成本低，但缺乏点位、设备台账功能，数据分散，难以支撑长期闭环管理；</li><li><strong>二维码巡检工具</strong>（如草料二维码）：免费就能搭建、部署快、无需培训，扫码即可巡查、上报、跟踪整改，是近两年工厂用得最多的轻量化方式之一。</li></ul><p>这些工具能不能解决问题，关键不在“数字化本身”，而在于工具是否贴合制造现场的节奏。</p><p>不少企业之所以最终选择二维码方式，是因为它更符合现场人员的使用习惯，也更容易让记录、派发、整改、验收走在同一个通道里。下面以草料二维码为例，说明数字化工具如何让隐患更好闭环：</p><h3>1. 巡查到点，记录留痕</h3><p>每个设备或区域贴上独立二维码，巡查人员只需要微信扫一扫，系统自动记录：巡查人、点位、时间和检查项，并支持照片上传。可以有效解决巡检人员未到点假检的问题。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459949" alt="file" title="file"/></p><h3>2. 问题自动提醒到责任人</h3><p>发现问题后，系统根据预设规则提醒到相应责任人，实现责任分派自动化，避免了微信群内 @ 来 @ 去。以自动方式替代人工，明确责任，避免一线的推诿。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459950" alt="file" title="file" loading="lazy"/></p><h3>3. 整改过程在线记录</h3><p>维修人员直接在手机上记录整改过程，上传整改照片，并 @ 验收人员进行验收。验收合格后，将处理进度变更为“已整改”，完成隐患销号，实现管理闭环。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459951" alt="file" title="file" loading="lazy"/></p><h3>4. 所有问题自动沉淀为结构化数据</h3><p>所有隐患上报和整改数据保存在后台，管理员可随时登录后台查看和导出数据。通过数据分析可以了解有多少隐患未整改、哪类问题最频繁、整改周期是否在缩短等。</p><p>这类数据让管理层看到隐患的规律，而不是靠经验判断。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459952" alt="file" title="file" loading="lazy"/></p><h2>五、闭环做好了，才能推动管理改善</h2><p>巡查执行得再认真，如果问题不能闭环，体系依旧是无效的；闭环做得再快，如果结果不能沉淀成数据，体系仍然无法改进。</p><p>闭环最终带来的价值在于：让一线敢上报、让责任明确、让管理层看得见、让问题有复盘、让风险逐步下降。</p><p>像草料二维码这类轻量化工具，虽然不是闭环管理的唯一方案，但能帮助企业用更低成本、更简单的方式，把整改流程跑顺，把闭环做扎实，让原本难落地的机制变得可执行。</p><p>当闭环跑得通，巡查才真正有意义；当闭环跑不通，巡查只能停留在表面。</p><p>而让闭环变得可执行、可持续、可复盘，正是当前制造企业数字化转型中最务实的一步。</p>]]></description></item><item>    <title><![CDATA[推荐一款比较好用的国产CRM系统 闷骚的绿茶 ]]></title>    <link>https://segmentfault.com/a/1190000047460026</link>    <guid>https://segmentfault.com/a/1190000047460026</guid>    <pubDate>2025-12-09 11:08:41</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>CRM（客户关系管理）自上个世纪 90 年代末引入中国以来，经历了多个重要阶段。在萌芽阶段，国内市场对 CRM 的认知有限，市场区域主要集中在北京、上海等经济发达地区。拥有 CRM 产品的国内厂商主要聚集在上海，而此时的 CRM 应用行业以电信、金融等经济实力较强、信息化程度较高的行业为主。<br/>进入引入阶段，2000 年前后，传统 CRM 市场在中国出现，国内市场上的 CRM 产品主要由国外厂商如 Siebel、Microsoft Dynamics 等提供。当时国内企业开始认识到客户关系管理的重要性，但实际还尚处知识普及阶段，市场的发展以 CRM 供应商的推动为主。<br/>随着中国互联网浪潮兴起，国产 CRM 迎来崛起阶段。2004 年后，头部企业软件服务商和创业企业进入 CRM 行业，开始探索 SaaS 部署模式。虽然 SaaS 服务使企业能够节省大量成本，按需租赁的模式吸引了一批创业者进入，但由于企业对 SaaS 软件的接受度不够、基础设施资源昂贵以及传统软件公司的市场控制等因素，SaaS CRM 市场在这个阶段遭遇了严重困难。然而，随着移动互联网的发展和技术的不断进步，国产 CRM 厂商逐渐崛起，如销售易成立于 2011 年，成为国内最早一批 CRM 创业公司的一员。此后，泛场景 CRM、垂直型 CRM 和社交型 CRM 等多样形式软件纷纷出现，百花齐放。</p><p>二、国产 CRM 推荐之一<br/>（一）销售易 CRM<br/>销售易 CRM 作为国内市场的佼佼者，拥有众多强大功能。在功能方面，它是模型驱动的 PaaS+SaaS，支撑企业复杂多变的业务需求，通过将复杂业务抽象成可视化组件，实现灵活组合和扩展，满足不同行业、不同企业的个性化场景。其数据平台和 BI+AI 功能，帮助企业更好地沉淀数据资产，释放数据价值。例如，通过湖仓一体的数据架构，结合强大的数据计算引擎，为企业提供全员 BI、敏捷 BI 和嵌入式 BI 能力，让业务人员在权限范围内进行分析，制作数据看板，并实现数据联动和层层下钻。<br/>在性能方面，销售易 CRM 不断优化前端交互体验、性能以及灵活定制能力。早在 2013 年就推出移动 App，今年又重磅推出 Neo UI，全面优化系统布局，降低系统操作成本，信息展示更清晰，业务推进更快速。NeoUI 适用于 Web 端、移动端、小程序及 H5，为企业客户、伙伴提供良好的应用体验。<br/>在服务方面，销售易以客户为先，为企业提供从需求调研到实施交付的全流程服务。例如，在项目开发期间，销售易项目组驻扎在企业，结合内部分析团队规划迫切改造的功能，加班加点确保完美交付，赢得了客户的高度认可。在服务的灵活性上，销售易按照内部员工的工作安排协调培训时间，体现出国产品牌的优质服务体验。<br/>销售易 CRM 的客户案例众多，涵盖制造、软互、医疗、化工等多个行业。如施耐德、海能达、蒙牛、华大基因等大型企业，选择销售易成功替换国际 CRM 品牌，并给予高度评价。在各行业的解决方案中，销售易联合企业微信发布三大行业解决方案，助力企业连接客户。在汽车行业，销售易 CRM 连接企业微信后，实现了流量的双向汇入和集中管理，加强了员工管理和精准营销服务，提升了客户关系管理的数字化升级。此外，销售易还提供智能分析云服务，凭借 Gartner SFA 全球魔力象限可视化分析能力第一的优势，与 CRM 原生一体，打通全流程数据，为不同行业提供数据分析模板，实现多端随心配置、数据订阅、智能预警等功能，助力企业更聪明地洞察客户与业务，及时做出科学决策。<br/>三、国产 CRM 优势</p><p>（一）本地化服务<br/>国产 CRM 系统通常提供更适合中国市场的本地化服务。首先，具备中文界面，方便国内用户操作和理解，无需花费大量时间去适应外语界面。同时，中文客服能够及时响应国内企业的问题和需求，沟通更加顺畅高效。在数据处理方面，符合中国法规，确保企业数据的安全性和合规性。例如，纷享销客等国产 CRM 厂商，深入了解国内企业的商业习惯和需求，为企业提供更加贴合实际的解决方案，满足不同行业的特殊需求。<br/>（二）成本效益<br/>相较于国际品牌，国产 CRM 系统在价格上更为亲民。国产 CRM 提供了灵活的定价策略，企业可以根据自身需求和预算选择合适的产品版本。例如，一些中小企业可以选择基础版的国产 CRM 系统，降低使用成本，同时满足基本的客户关系管理需求。随着企业的发展，还可以根据实际情况升级功能，实现成本的有效控制。<br/>（三）快速响应迭代<br/>国产 CRM 供应商能够更快地响应市场变化和用户需求，进行产品迭代和功能升级。由于更贴近国内市场，能够及时了解国内企业的动态需求，快速调整产品策略。以悟空 CRM 为例，作为国内为数不多的开源 CRM，能够根据用户反馈迅速进行功能优化，满足不同企业在不同发展阶段的需求。<br/>（四）高度可定制性<br/>国产 CRM 系统通常具备高度的可定制性，支持企业根据自身业务需求进行快速定制和调整。例如，纷享销客支持低代码功能扩展，企业可根据自身需求快速定制系统，实现从线索管理到客户服务的全流程个性化管理。金蝶 CRM、用友 CRM 等也都具备强大的定制功能，满足不同企业在供应链管理、财务和人力资源等领域的集成管理需求。<br/>（五）强大集成能力<br/>多数国产 CRM 系统具备强大的集成能力，能够与企业现有的 ERP、SCM 等系统无缝集成。例如，八百客 CRM 提供基于 PaaS 的管理自动化平台，支持企业快速开发和部署定制应用，实现与其他系统的高度集成。浪潮 CRM 集成能力强，与 ERP、SCM 等系统无缝集成，提升管理效率，为制造行业提供有针对性的解决方案。<br/>（六）政策支持<br/>在数字经济和信创政策的推动下，国产 CRM 系统得到了更多的政策支持和市场机会。国家对信息技术自主可控的重视，使得国产 CRM 在政府采购和大型企业招标中获得更多机会。同时，国家对本土软件产业的扶持，包括研发资金支持、税收优惠等措施，为国产 CRM 的技术发展和创新提供了良好的环境。<br/>四、总结</p><p>中国 CRM 市场近年来呈现出快速增长的态势，随着数字化转型需求的不断增加、技术进步以及政策支持，市场规模持续扩大。目前，国内 CRM 品牌在市场中占据较大比重，国产 CRM 软件正逐步实现对海外产品的替代。<br/>在国产 CRM 中，涌现出了众多优秀的厂商和产品。从排行榜 TOP10 可以看出，销售易、白码 CRM、悟空 CRM、用友 CRM、神州云动 CRM、八百客 CRM、金蝶 CRM、销帮帮 CRM、珍客 CRM 等各有特色。销售易以其全功能覆盖、高度可定制性和良好的用户体验，在大中型企业市场占有率和品牌影响力方面表现突出；销售易凭借强大的功能和优质的服务赢得了众多企业的青睐；白码 CRM 作为低代码开发平台，为企业提供了灵活的 CRM 功能；悟空 CRM 以开源的特点在中小企业中知名度较高；用友 CRM 和金蝶 CRM 依托在企业管理软件领域的深厚积累，为用户提供集成化、模块化的 CRM 解决方案；神州云动 CRM 专为中大型企业设计，提供全面的客户生命周期管理；八百客 CRM 提供基于 PaaS 的管理自动化平台，具有高度集成能力；浪潮 CRM 集成能力强，为制造行业提供有针对性的解决方案。<br/>国产 CRM 具有诸多优势，如本地化服务更贴合国内企业需求，包括中文界面、中文客服以及符合中国法规的数据处理；成本效益更高，价格更为亲民，提供灵活的定价策略；快速响应和迭代，能及时满足市场变化和用户需求；高度可定制性，支持企业根据自身业务需求进行快速定制和调整；强大的集成能力，可与企业现有 ERP、SCM 等系统无缝集成；政策支持力度大，在数字经济和信创政策推动下获得更多发展机会。</p>]]></description></item><item>    <title><![CDATA[【开源代码】基于STM32的智能杯垫—喝水提醒系统设计与实现 逐梦AI ]]></title>    <link>https://segmentfault.com/a/1190000047460039</link>    <guid>https://segmentfault.com/a/1190000047460039</guid>    <pubDate>2025-12-09 11:07:55</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>【开源代码】基于STM32的智能杯垫—喝水提醒系统设计与实现</h2><blockquote><strong>Smart-Coaster-Water-Clock</strong><br/>基于STM32的智能杯垫项目，提供定时喝水提醒功能，通过语音播报与OLED显示实现多模态交互，为用户科学饮水提供便利。</blockquote><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047460041" alt="展示图" title="展示图"/></p><hr/><h3>源码分享</h3><p>直接放到之前写的文章里了，免费开源，下载学习即可。</p><blockquote><a href="https://link.segmentfault.com/?enc=xlJLJJ2vhYY%2Bi4QgVyDAkA%3D%3D.E6cJX2kb9b7MUzegQfJAyGbJVwRnQscfLuaEZ4icUQDhnn4vBoWeKH%2BBsOSijK41eUsnSj4K5G0AIaHsdFfzrw%3D%3D" rel="nofollow" target="_blank">https://blog.csdn.net/weixin_52908342/article/details/155617852</a></blockquote><h3>项目背景</h3><p>随着现代人生活节奏的加快，许多人因为忙碌常常忘记按时饮水，长期如此可能导致身体脱水、注意力下降、皮肤干燥等问题。传统的喝水提醒方式多依赖手机闹钟或手动记录，缺乏智能化和交互体验。</p><p>为了解决这一问题，本项目设计了一款<strong>智能杯垫</strong>，通过STM32单片机控制，能够自动检测杯子状态，并在设定时间到达时提供语音和视觉提醒，实现科学、便捷的饮水管理。该项目不仅注重功能实现，还关注用户交互体验，通过上位机界面和语音播报，使操作直观、自然。</p><hr/><h3>硬件选型与功能模块</h3><p>智能杯垫的硬件设计以STM32F103C8T6为核心，通过外设和传感器模块实现感知与交互。主要硬件如下：</p><ol><li><p><strong>STM32F103C8T6</strong></p><ul><li>核心控制单元，负责处理定时、传感器输入、语音输出以及显示逻辑。</li><li>提供丰富的定时器、GPIO和中断功能，满足系统多任务管理需求。</li></ul></li><li><p><strong>TCRT5000红外反射传感器</strong></p><ul><li>用于检测水杯是否放置在杯垫上。</li><li>通过检测DO引脚电平变化，实现杯子在位与否的判断，为提醒逻辑提供准确依据。</li></ul></li><li><p><strong>JQ8900-16P语音播报模块</strong></p><ul><li>实现语音提醒功能，支持定制语音文件，提升交互体验。</li><li>配合小喇叭扬声器，提供清晰的语音提示。</li></ul></li><li><p><strong>0.96寸OLED屏幕</strong></p><ul><li>实时显示倒计时、当前时间以及操作反馈信息。</li><li>配合语音播报，实现多模态提醒效果。</li></ul></li><li><p><strong>电源与面包板模块</strong></p><ul><li>AMS1117 3.3V电源模块通过9V电源为传感器及模块提供稳定电压。</li><li>400孔面包板用于实验性电路搭建，方便快速迭代开发。</li></ul></li><li><p><strong>辅助器件</strong></p><ul><li>轻触开关用于用户设置提醒时间。</li><li>杜邦线及小零件辅助连接，实现模块化设计。</li></ul></li></ol><hr/><h3>系统设计原理</h3><p>智能杯垫的核心功能是“定时喝水提醒”，系统逻辑可分为以下几部分：</p><h4>1. 定时器功能实现</h4><p>系统采用STM32的 <strong>TIM定时器中断</strong> 来实现倒计时和时钟功能，每秒触发一次中断，用于更新倒计时数据。用户通过轻触开关设定提醒间隔时间，系统将设定时间存储在内部变量中，通过定时器每秒递减，直至到达提醒条件。</p><h4>2. 水杯检测机制</h4><p>为了确保提醒的准确性，系统通过 <strong>TCRT5000红外反射传感器</strong> 检测水杯状态：</p><ul><li>当水杯放置在杯垫上时，传感器DO引脚为低电平，表示“杯子在位”。</li><li>当水杯离开时，DO引脚变为高电平，提醒逻辑暂停，避免无意义提醒。</li></ul><p>通过结合定时器中断和外部中断（EXTI），系统能够在水杯状态变化时立即响应，实现实时检测。</p><h4>3. 多模态提醒实现</h4><p>当倒计时到达并且杯子在位时，系统触发提醒：</p><ul><li><strong>语音提醒</strong>：JQ8900语音模块播放预设的喝水提示音，告知用户需要饮水。</li><li><strong>屏幕提示</strong>：OLED屏幕显示提醒信息，如“请喝水！”及倒计时图标，确保用户在噪声环境下也能察觉。</li></ul><p>如果用户未取走杯子，系统将循环播放语音和屏幕提示，直到杯子被拿起为止。</p><h4>4. 上位机交互界面</h4><p>操作界面通过OLED实现，用户可通过按键调整提醒时间。每一步操作均配合语音复述，提供良好的用户体验：</p><ul><li>“设置提醒时间为30分钟”</li><li>“倒计时开始”</li><li>“水杯已放置，提醒启动”</li></ul><p>这种交互方式既直观又减少了操作失误。</p><hr/><h3>软件实现细节</h3><h4>1. 定时器与中断配置</h4><pre><code class="c">// TIM2 每秒触发一次中断
void TIM2_IRQHandler(void) {
    if(TIM_GetITStatus(TIM2, TIM_IT_Update) != RESET) {
        // 更新倒计时
        countdown--;
        TIM_ClearITPendingBit(TIM2, TIM_IT_Update);
    }
}</code></pre><h4>2. 外部中断实现杯子检测</h4><pre><code class="c">void EXTI0_IRQHandler(void) {
    if(EXTI_GetITStatus(EXTI_Line0) != RESET) {
        cup_present = GPIO_ReadInputDataBit(GPIOB, GPIO_Pin_0);
        EXTI_ClearITPendingBit(EXTI_Line0);
    }
}</code></pre><h4>3. 提醒逻辑</h4><pre><code class="c">if(countdown == 0 &amp;&amp; cup_present) {
    play_voice("请喝水.wav");
    display_oled("请喝水!");
}</code></pre><p>通过定时器与传感器的协作，实现实时、多模态提醒。</p><hr/><h3>系统特点与优势</h3><ol><li><strong>智能化</strong>：结合传感器与定时器，实现自动检测与提醒，无需用户手动干预。</li><li><strong>多模态交互</strong>：语音+屏幕提示，提升提醒有效性。</li><li><strong>用户可定制化</strong>：轻触按键设定时间，界面直观。</li><li><strong>可扩展性强</strong>：未来可接入Wi-Fi或蓝牙，实现手机远程控制与数据统计。</li></ol><hr/><h3>项目心得与优化思路</h3><p>在开发过程中，我们遇到了一些问题：</p><ul><li><strong>传感器灵敏度调整</strong>：初期红外传感器容易误判杯子状态，通过调节电位器和程序滤波解决。</li><li><strong>语音播报时延</strong>：由于模块启动需要时间，增加了初始化延迟，优化了语音播放队列，使提醒更及时。</li><li><strong>界面与交互优化</strong>：通过OLED显示倒计时与语音复述结合，提高操作体验。</li></ul><p>未来可以进一步改进：</p><ul><li>引入<strong>蓝牙或Wi-Fi模块</strong>，实现手机APP远程设置与喝水记录统计。</li><li>增加<strong>定制化语音提醒</strong>功能，让提醒更个性化。</li><li>优化功耗，实现<strong>便携式低功耗智能杯垫</strong>。</li></ul><hr/><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047460042" alt="基本原理及功能" title="基本原理及功能" loading="lazy"/></p><h3>总结</h3><p>本项目通过STM32实现了一款智能杯垫，具备定时提醒、语音播报、OLED显示及上位机交互功能。系统不仅解决了用户日常饮水提醒问题，还体现了嵌入式开发在智能健康设备中的应用价值。通过硬件模块化设计和软件中断逻辑，实现了高效、稳定的多任务运行。</p><p>智能杯垫为日常健康管理提供了便捷解决方案，同时也展示了嵌入式系统在智能家居和物联网场景中的广阔应用前景。未来结合远程控制和数据统计功能，能够形成完整的健康饮水生态系统，为用户带来更智能、更人性化的使用体验。</p>]]></description></item><item>    <title><![CDATA[元服务调测无需上架，App Linking助力高效分发元服务链接 鸿蒙百晓生 ]]></title>    <link>https://segmentfault.com/a/1190000047460108</link>    <guid>https://segmentfault.com/a/1190000047460108</guid>    <pubDate>2025-12-09 11:06:57</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>元服务已经开发完却无法进行效果测试，上架后又担心影响现网用户体验。为解决开发者在元服务调测场景中的核心痛点，App Linking 全新升级实用功能 —— <strong>支持未上架元服务进行全阶段调测</strong>，无需等待上架且不影响现网，让链接运营更高效、用户体验更流畅！</p><p><strong>核心功能：</strong></p><ol><li>开发者配置App Linking元服务链接后，在开发、邀请测试等阶段均可使用元服务链接进行功能调测；</li><li>针对二维码测试链接，若元服务链接关联了二维码，可以单独创建测试链接进行端到端真机调测，确认无误后再正式发布到现网，避免对存量的二维码产生影响，可以有效提升元服务质量！</li></ol><p><strong>具体操作步骤如下：</strong><br/>1、创建元服务链接时可正常在AGC控制台进行配置，若不关联二维码，可直接使用元服务链接进行测试。</p><p>2、若选择关联二维码，可创建测试链接进行调试，链接需符合匹配规则，多个测试链接使用英文分号分隔，如：</p><p>3、点击“保存”后，元服务链接为“草稿态”，您可以查看、编辑或者删除链接信息。开发者可扫描由测试链接生成的二维码进行端到端调测。</p><p>4、调测确认无误后可点击“发布”，AGC会判断当前时间是否在链接有效期内，并实时更新元服务链接状态：“待生效”、“已生效”或“已失效”。</p><p><img width="723" height="421" referrerpolicy="no-referrer" src="/img/bVdniGA" alt="image.png" title="image.png"/><br/><img width="723" height="136" referrerpolicy="no-referrer" src="/img/bVdniGB" alt="image.png" title="image.png" loading="lazy"/></p><p><a href="https://link.segmentfault.com/?enc=s%2FdxrKoGTyITBKbU%2BplOjQ%3D%3D.NYtCwrNQtbDHRYWPDUK%2FW6cF5MXZWO03UpVj9jcLJhzquPOI4B06G%2BrS3%2F2EpdMHg783PaZp2fx%2FEcwGZ6LBNezEU3KGW%2FRvIyWNZqNLW6Xn78ZAOfTJ6x7rfpZiRGjHlMfQBnrah68xseopcPr5Mq330k09Dw%2FAJrDrkscvrGmiKjdOID%2Ff5LcgzYmGhZq4uAGdqKFwliEYxmkDAVkAqA%3D%3D" rel="nofollow" target="_blank">App Linking</a>元服务链接和融合码是华为<a href="https://link.segmentfault.com/?enc=SAgcl1afEvI%2Bp1ow6fFgSA%3D%3D.e7z1l61DNvvSms5GchoWChmtkCYnPpH2%2FokcZLFaidVnDubJrGjEBCrRMcHSAoNukKEq%2Fy%2FhG6jLpp9MO2sQDcxngoC%2BkbvQPqPaPAqtOmMcpVcp%2Fl3iqwXBYq24JS8wykUpJ6rhBRPcQ3poyvfdFQ%3D%3D" rel="nofollow" target="_blank">AppGallery Connect</a>（简称AGC）向鸿蒙开发者提供的链接跳转元服务能力，可用于通过点击链接或扫描存量二维码实现跳转元服务指定页面的功能，实现元服务的点击触达、即点即用，为鸿蒙用户带来便捷的体验。</p><p>对于开发者而言，App Linking 不只是简单的链接工具，更是提升用户使用体验的核心利器。它打通 “用户触达” 与 “服务落地”，让应用与用户连接更高效。点击下方链接，即刻开启鸿蒙生态场景化运营新篇章 —— <a href="https://link.segmentfault.com/?enc=lIrwBWaQvFgheT4QdMU97A%3D%3D.ymRGJmLZCPU0uby9xXhmAa9PDlqR1JqA3XeFgZY28e8D9FE4CFdGY8tkraPgNr%2BRozAAAaL7Y%2FDhuUnyApg9Ga1qElGL8ivwf5CvcQyAIx3BrCk96PjvIrl5WyqQ6DnYPLLY3qXVsOzfpuH9MxOoB3q0I%2F3qP6GomSIR6li0ERKU3n%2B31Yr2HV4kZRCDrMWbwp0UNOd9ir%2BB%2BTL4v4P1OQ%3D%3D" rel="nofollow" target="_blank">App Linking</a>。</p><p><a href="https://link.segmentfault.com/?enc=XiRmyJgdMJxwe2zO%2FAnCyw%3D%3D.1%2B48eW4QrLHgVA9gtANXgVVSVNvijQA6D4VIFwfHypZxvC3AC2edfQ1o4lAdkOQU%2FaIft0Da8nYyA%2FG9B6XqH%2Ba7dodeF5Ecs%2FUL7x%2BLMlpthPg2QLHAjwOVWdvn6Ld6AZU%2BbLMIoShog0nYdgFoiA%3D%3D" rel="nofollow" target="_blank">AppGallery Connect</a>致力于为应用的创意、开发、分发、运营、经营各环节提供一 站式服务，构建全场景智慧化的应用生态体验。为给您带来更好服务，<strong>请扫描下方二维码或者<a href="https://link.segmentfault.com/?enc=8nXeEkpMeL7UfV4YY91Rmg%3D%3D.vUCziYf3Ho%2BWFmAoEOoK6yLYAaGMm0B5sxRtYHuS9PBMIABUZQhbr6xWoL%2FEqZuxzKisllnRcCcp8BH8N%2B0sSA%3D%3D" rel="nofollow" target="_blank">点击此处</a>免费咨询</strong>。</p><p><img width="723" height="231" referrerpolicy="no-referrer" src="/img/bVdniHs" alt="" title="" loading="lazy"/></p><p>如您有任何疑问，请发送邮件至<a href="mailto:agconnect@huawei.com" target="_blank">agconnect@huawei.com</a>咨询，感谢您对HUAWEI AppGallery Connect的支持！</p>]]></description></item><item>    <title><![CDATA[一文讲透机械组装行业MES的7大适用场景与实施路径 万界星空科技 ]]></title>    <link>https://segmentfault.com/a/1190000047460117</link>    <guid>https://segmentfault.com/a/1190000047460117</guid>    <pubDate>2025-12-09 11:06:02</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>机械组装 MES 系统主要适用于以离散制造为主、产品由多个零部件通过装配工序集成而成的行业。这类企业通常具有 多品种、小批量（或单件定制）、工艺复杂、质量追溯要求高的特点。<br/><img width="723" height="345" referrerpolicy="no-referrer" src="/img/bVdmZmH" alt="" title=""/><br/><strong>机械组装 MES 系统的典型适用行业及应用场景：</strong><br/>✅ 1. 通用机械设备制造<br/>代表产品：泵、阀、压缩机、风机、减速机、空压机<br/>核心需求：<br/>单台设备全流程追溯（如密封件批次、轴承安装扭矩）<br/>关键装配参数闭环（压装力、气密性测试）<br/>应对频繁的非标订单变更<br/>MES 价值：避免“装错密封圈导致泄漏”“返修时找不到原始记录”。<br/>✅ 2. 工程机械与重型装备<br/>代表产品：挖掘机、起重机、混凝土泵车、农业机械<br/>核心需求：<br/>大型部件 RFID 自动识别（如驾驶室、液压系统）<br/>总装线工位协同与进度可视化<br/>满足主机厂（如三一、徐工）对供应商的追溯与质量数据上传要求<br/>MES 价值：实现“一机一档”，支持客户远程审计。<br/>✅ 3. 工业自动化与非标设备<br/>代表产品：自动化产线、机器人工作站、检测设备、包装机械<br/>核心需求：<br/>项目制管理（每个订单即一个独立项目）<br/>BOM 与工艺路线高度灵活可配<br/>电子作业指导书（eSOP）引导复杂装配流程<br/>MES 价值：缩短新项目交付周期，降低对“老师傅”的依赖。<br/>✅ 4. 新能源装备<br/>代表产品：光伏组件设备、锂电池生产设备、氢能压缩机<br/>核心需求：<br/>高洁净度/防爆环境下的无纸化作业<br/>关键部件（如伺服电机、传感器）批次绑定<br/>符合 IATF 16949 或行业安全认证<br/>MES 价值：确保设备一致性，支撑高端客户验厂。<br/>✅ 5. 汽车零部件总成<br/>代表产品：变速箱、转向器、制动系统、电驱总成<br/>核心需求：<br/>扭矩/角度拧紧数据自动采集与存档<br/>全生命周期追溯（VIN 级或序列号级）<br/>与主机厂 MES/EDI 系统对接<br/>MES 价值：满足汽车行业“零缺陷”和快速召回要求。<br/>✅ 6. 电力电气设备<br/>代表产品：高低压开关柜、变压器、配电箱、充电桩整机<br/>核心需求：<br/>铜排加工与元器件装配防错<br/>出厂耐压、绝缘、功能测试数据自动记录<br/>支持 CCC、CE 等认证审计<br/>MES 价值：杜绝“元器件型号装错”“测试漏做”等风险。<br/>✅ 7. 医疗器械（中大型设备类）<br/>代表产品：影像设备（CT/MRI 外壳）、手术床、消毒设备<br/>核心需求：<br/>严格符合 FDA 21 CFR Part 11 或 ISO 13485<br/>电子批记录（EBR）全程留痕<br/>物料与操作员双重绑定<br/>MES 价值：通过合规审计，加速产品上市。</p><p><strong>如何判断您的企业是否适合部署机械组装 MES？</strong><br/>如果您的工厂符合以下 任意 3 条以上，就具备实施 MES 的基础条件：<br/>□ 产品由 10 个以上零部件组装而成<br/>□ 每月处理 20+ 个不同订单或型号<br/>□ 存在“错装、漏装、返工”质量问题<br/>□ 客户要求提供产品追溯信息<br/>□ 依赖纸质图纸、Excel 或手工报工<br/>□ 交期经常延误，原因说不清<br/>□ 想提升 OEE 或人均产出</p><p>💡<strong> 温馨提示：系统演示+项目合作可以私信交流</strong><br/>中小型企业可选择轻量化 MES（PDA + 扫码 + 看板），7~15 天上线核心模块；<br/>集团型企业可分阶段实施：先试点关键产线，再横向推广；<br/>非纯组装企业（如有机加环节）可扩展至“机加+装配”一体化 MES。</p>]]></description></item><item>    <title><![CDATA[运营周报上线！数据周周可查，运营效率稳步提升 鸿蒙百晓生 ]]></title>    <link>https://segmentfault.com/a/1190000047460188</link>    <guid>https://segmentfault.com/a/1190000047460188</guid>    <pubDate>2025-12-09 11:05:04</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>运营周报功能正式上线，可为在架应用/元服务提供每周运营数据报告，无需多平台切换、手动导出整理，一键即可查看下载安装、用户分析、安装失败等核心指标及趋势，支持邮件+互动中心双渠道接收，帮你快速聚焦关键信息、高效支撑运营决策！</p><p><strong>核心功能亮点：</strong></p><ul><li>多维度数据摘要展示：运营周报聚焦核心业务指标，涵盖下载安装、用户分析、安装失败等关键数据。帮助开发者快速了解应用核心指标变化趋势，便于及时调整运营策略和产品优化方向，提升运营效率。</li><li>最新能力推荐与直达：运营周报嵌入平台核心能力介绍及解决方案，并配置直达链接，帮助开发者快速匹配业务需求与平台能力，让产品升级更高效。</li></ul><p><strong>查看指南：</strong></p><ul><li>双渠道同步推送：默认推送你最后一次操作的应用/元服务当周数据，可通过邮件或互动中心站内信直接查看。</li><li>多应用快速切换：若需查看其他应用/元服务周报，在互动中心点击左上角即可便捷切换。</li></ul><p><img width="723" height="370" referrerpolicy="no-referrer" src="/img/bVdniIA" alt="image.png" title="image.png"/></p><p>数据是运营优化的核心驱动力，运营周报致力于为开发者提供准确及时的数据支撑。我们诚邀鸿蒙开发者们体验，让数据更好地赋能产品成长。使用过程中若有疑问或建议，请扫描下方二维码或者<a href="https://link.segmentfault.com/?enc=fbJ4fTlDgflgpQEv7FW8xA%3D%3D.V7v9rnCIC7fp0eR1klVs%2BkGQd5mcsDQ4loSs5oCV6jirA%2Br6S1lqSpwbYMw9%2FASV89l62hiv1gZnvdhsMLMajSaEwSTvsr6Fz6GCpEzBKLH9ep0byLhBDfVhOkor8EdZHLtRU6hNMCF8Hr7HN5DN8A%3D%3D" rel="nofollow" target="_blank">点击此处</a>与我们取得联系。期待与你一同推动产品迭代、助力生态繁荣。</p><p><img width="723" height="231" referrerpolicy="no-referrer" src="/img/bVdniIX" alt="" title="" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[烟草专卖执法案卷评查系统荣获“2025年度数字化创新最佳实践奖” 中烟创新 ]]></title>    <link>https://segmentfault.com/a/1190000047460224</link>    <guid>https://segmentfault.com/a/1190000047460224</guid>    <pubDate>2025-12-09 11:04:30</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>近日，在深圳举办的“闪耀光明 智见未来——中国AI赛道与ESG可持续发展大会”上，北京中烟创新科技有限公司（简称：中烟创新）研发的“烟草专卖执法案卷评查系统”荣获“2025年度数字化创新最佳实践奖”。本次大会汇聚了人工智能与可持续发展领域的专家学者与企业代表，共同探讨技术赋能行业转型的前沿路径。中烟创新在执法监督数字化领域技术实力被再度认可，更折射出人工智能技术在提升治理效能、推动规范执法方面的深化应用与重要价值。</p><p>烟草专卖执法案卷评查系统此前已凭借其创新性与实效性，获得了一系列来自国际、国家及行业层面的权威认可：不仅入选2025全球数字经济大会“北京市人工智能赋能行业发展典型案例”，获评2025世界人工智能大会“AI Solutions for SME”全球推荐案例，还被中国信息通信研究院认定为“2025年商业产品及企业典型案例”。此外，在专业领域评选中，获评“技术创新探索先锋案例”，并在第十届中国国际人工智能大会上荣膺“中国人工智能行业十大创新力产品”。</p><p>这一系列高规格、多纬度的荣誉，充分印证了烟草专卖执法案卷评查系统在推动人工智能技术与执法监督实践深度融合方面的先进性与标杆意义。坚实的技术基础与完备的合规资质是该系统得以成功部署与应用的根本保障，作为国家高新技术企业，中烟创新已构建起完善且自主可控的知识产权体系与质量保障体系。公司核心积累包括二十余项发明专利与八十余项软件著作权，为公司的持续创新提供了法律保护与技术支撑。烟草专卖执法案卷评查系统积极响应国家信息技术应用创新（信创）战略，在产品兼容性与安全性上达到了行业高标准。</p><p>目前，已成功完成与主流国产技术生态的全面对接，实现了对国产服务器、芯片、操作系统、数据库及中间件的深度兼容、适配与优化。其累计获得的信创领域互认认证超过一百余项，这一成果不仅充分验证了烟草专卖执法案卷评查系统在复杂国产化环境下的高度可靠性、安全性与卓越性能，更从底层架构上确保了行政执法核心数据与业务全过程能在安全、自主、可控的信息技术底座上稳定流畅运行。</p><p>在过去近一年中，我们的产品与研发团队跨越二十余省六十多市，先后走访了山东、河北、江苏、湖北、河南、吉林、黑龙江、山西、贵州、陕西、四川等省局（公司），并深入济南、临沂、德州、烟台、莱芜、雄安、镇江、连云港、南通、黄冈、十堰、洛阳、商丘、通化、牡丹江、太原、贵安新区、咸阳、绵阳等市局（公司），开展了一场又一场的需求座谈与现场调研。</p><p>在产品开发过程中，团队始终秉持“前沿而不冒进，稳定而不守旧”的技术理念，明确制定了“三最”原则——采用最新的技术框架、设计最友好的交互方法、实现最高的安全运维标准，以保障平台在技术先进性、用户体验与系统可靠性方面的领先优势。为确保技术方案精准匹配一线实际，我们实地考察，实地走访，将脚步深深扎进业务的土壤里。不仅全程记录了各环节的具体操作、文书流转与判断决策，更关键的是，以流程解构的视角，识别出其中依赖个人经验、重复性高、标准不易统一的关键节点，为后续将实务逻辑转化为精准、可执行的算法规则奠定了不可替代的实证基础。烟草专卖执法案卷评查系统在于针对传统人工案卷评查中的痛点，通过智能化技术将系统性的评查工作转化为高效、精准、一致的数字化流程。</p><p>实现全流程自动化，重构评查效能传统人工评查依赖逐页翻阅、手动核对，处理复杂案卷耗时长达数小时。该系统集成OCR、NLP、知识图谱、RAG、大模型技术，可自动解析卷宗文本，并依据内置规则引擎进行批量处理。实践表明，烟草专卖执法案卷评查系统能将单份案卷的全面评查时间从数小时缩短至分钟级，使评查人员能从重复性劳动中解放出来，专注于需要专业判断的复杂环节。建立数字化标尺，统一执法度量人工评查易受个人经验与理解差异影响，烟草专卖执法案卷评查系统内嵌了覆盖法律法规、程序规范及文书制作要点的结构化知识库，包含超过1000项具体规则。</p><p>通过对案卷内容进行毫秒级的自动比对与核验，烟草专卖执法案卷评查系统确保了不同单位、不同评查人员遵循同一套标准，有效减少了主观偏差，提升了评查结果的客观性与公信力。前置评查节点，内嵌合规控制传统评查多为事后进行，问题发现时已难以纠正。烟草专卖执法案卷评查系统将评查规则前置，在案卷制作、审批等流程中即可进行实时合规性检查。能自动识别并提示证据缺失、条款引用错误、程序超期等常见问题，推动评查职能从“事后纠错”向“事中防控”延伸，降低了整体纠错成本。基于当前基础，团队将紧密配合已试点单位，提供全面的部署支持与培训，确保系统与日常评查流程无缝融合。</p><p>同时，持续收集一线反馈，进行有针对性的功能优化与体验改进，致力于打造一个真正满足行业需求、人人可用的卓越平台。一个有价值的产品，其长期生命力不仅在于处理了眼前的业务，更在于它是否能沉淀下来自实践的智慧。</p><p>我们相信，每一次规范的执法行为，每一条严谨的文书记录，都不仅仅是流程的终点，更是洞察与改进的起点。通过持续的技术迭代与价值深化，为执法队伍的规范化建设与培训资源的精准配置提供实证参考，最终为烟草专卖执法监督迈向规范化、精细化、智能化提供稳定可靠的技术支撑。</p>]]></description></item><item>    <title><![CDATA[无需复杂培训，即装即用！轻量型OA工具如何让办公快速提效？ Zoey的笔记本 ]]></title>    <link>https://segmentfault.com/a/1190000047460267</link>    <guid>https://segmentfault.com/a/1190000047460267</guid>    <pubDate>2025-12-09 11:03:35</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>一、什么是OA工具？</h2><p>OA（Office Automation，办公自动化）工具是一套利用软件和信息技术，将企业日常办公流程数字化、标准化、自动化的协同工作平台。它的核心是连接“人、事、数据和流程”，将传统的、需要人工跑腿、纸质流转的审批、汇报、协作、知识管理等工作，转移到线上进行。简单来说，OA工具就是一个“数字化的公司办公中枢”，通常包含以下核心模块：</p><p>· 流程审批：请假、报销、采购、合同等申请与审批。</p><p>· 协同办公：任务分派、项目协作、日程共享、会议管理。</p><p>· 知识管理：公司制度、项目文档、经验案例的集中存储与共享。</p><p>· 沟通工具：集成即时通讯、公告通知、工作汇报（如日报/周报）。</p><p>· 行政管理：考勤打卡、用印申请、资产领用等。</p><h2>二、为什么要使用OA工具？（解决什么问题？）</h2><p>使用OA工具的主要目的是提升效率、规范管理、加强协同，解决传统办公模式中的核心痛点：</p><ol><li>解决效率低下与等待浪费</li></ol><p>· 痛点：员工拿着纸质单据满楼找领导签字；领导出差，流程停滞数天；查询一份过往合同需要翻遍文件柜。</p><p>· OA的解决：审批7x24小时在线流转，手机随时处理；历史文件全文检索，秒级查找。</p><ol start="2"><li>解决管理不规范与权责不清</li></ol><p>· 痛点：审批靠口头、靠微信，规则不透明，事后无据可查；任务进度不明，出了问题互相推诿。</p><p>· OA的解决：流程固化，权责清晰，每一步操作留痕，实现过程可追溯、结果可分析。</p><ol start="3"><li>解决信息孤岛与协同困难</li></ol><p>· 痛点：信息分散在个人电脑、微信群、邮件里，团队信息不对称；项目协作靠频繁开会，版本混乱。</p><p>· OA的解决：提供统一的信息发布、文档协作和任务看板平台，确保团队在同一个上下文里工作。</p><ol start="4"><li>赋能远程与移动办公</li></ol><p>· 痛点：离开办公室就无法处理工作，团队分布多地时协作困难。</p><p>· OA的解决：通过手机App即可完成绝大部分办公操作，支持分布式团队高效运作。</p><p>核心价值：将管理者从繁琐的日常事务中解放出来，将员工从低效的沟通等待中解放出来，让整个组织的运行更流畅、更透明、更可控。</p><h2>三、轻量型OA工具的优点是什么？</h2><p>“轻量型”是相对于传统“重量级”的、需要复杂部署和长时间实施的ERP或综合OA系统而言的，其核心优点在于：</p><ol><li>成本低廉，启动门槛低：</li></ol><p>· 通常采用SaaS模式，按年订阅付费，无需一次性投入大量硬件和软件许可费用。很多产品提供免费或低费用的基础版，适合初创和小微企业。</p><ol start="2"><li>部署快速，上手容易：</li></ol><p>· “开箱即用”：注册账号即可开始使用，无需漫长部署周期。</p><p>· “配置而非开发”：通过可视化拖拽、选择模板等方式，非技术人员也能快速搭建审批流程和应用，满足大部分日常需求。</p><ol start="3"><li>聚焦核心，体验流畅：</li></ol><p>· 功能聚焦在流程、协同、沟通、文档等高频核心场景，不追求大而全。界面设计通常更现代化，操作简洁，学习成本低，员工接受度高。</p><ol start="4"><li>灵活迭代，随需而变：</li></ol><p>· 业务变化时，可以快速调整或新建流程。SaaS模式能保证用户持续获得功能更新，保持工具的活力。</p><ol start="5"><li>集成生态，连接能力强：</li></ol><p>· 优秀的轻量型OA工具通常具备开放的API，可以很方便地与钉钉、企业微信、飞书等办公平台，以及财务软件、CRM等业务系统连接，避免数据孤岛。</p><p>适用对象：中小企业、初创公司、大企业中的部门/项目团队，以及对成本敏感、追求敏捷、IT能力有限的组织。</p><h2>四、有哪些主要推荐？</h2><p>市场上的轻量型OA工具各具特色，可根据团队核心需求进行选择：</p><p>对于预算极其有限或初创的小团队，首选各大平台提供的免费基础套件，如钉钉、飞书。它们集成了审批、打卡、文档、会议等核心功能，完全免费，且分别背靠阿里、字节的成熟生态，是性价比最高的入门选择。</p><p>对于项目驱动、追求敏捷协作的互联网、产品研发或创意团队，推荐以项目和目标管理为核心的工具，如板栗看板、Teambition。它们以看板、甘特图、OKR为核心，深度嵌入任务、文档和沟通，天然适合快速迭代和协同共创的工作模式。</p><p>其中板栗看板无需下载，网页直用，尤为轻量便捷。</p><p>若团队业务流程独特，个性化需求较强，则应关注以表单和流程驱动为核心的低代码/零代码平台，例如简道云。这类工具允许用户通过拖拽方式，像搭积木一样自定义搭建各种管理应用（如采购、客服工单），无需编程即可满足复杂的业务流程管理。</p><p>选型的关键建议是：切忌追求一步到位的大而全。 应从团队最核心的一个痛点（如报销慢或任务乱）入手，选择气质契合的工具进行小范围试用。让团队“愿意用、用起来”是成功的第一步，轻量型OA的价值正是以最小成本和门槛启动数字化协同，伴随业务共同成长。</p>]]></description></item><item>    <title><![CDATA[“码”上跑腿：拆解一套可商用的校园外卖跑腿小程序源码如何快速部署 伊伊DK ]]></title>    <link>https://segmentfault.com/a/1190000047460275</link>    <guid>https://segmentfault.com/a/1190000047460275</guid>    <pubDate>2025-12-09 11:02:59</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>商用级校园外卖跑腿小程序的快速部署，核心是 “标准化流程 + 校园场景适配 + 合规落地”，本文基于可商用的完整源码包（UniApp 前端 + SpringBoot 后端），从环境准备、源码部署、配置调试到上线商用，拆解全流程，让你最快 1 天完成部署，适配校园商业化运营需求。<br/>一、部署前核心准备</p><ol><li>核心资源清单（商用必备）<br/><img width="569" height="395" referrerpolicy="no-referrer" src="/img/bVdniKj" alt="image.png" title="image.png"/><br/>二、5 分钟适配前端小程序（UniApp）</li><li>源码配置修改（HBuilderX）<br/>打开 HBuilderX，导入前端源码包（/campus-runner/frontend）；<br/>修改全局接口地址：打开utils/request.js，将baseUrl改为<a href="https://link.segmentfault.com/?enc=0%2BVgFRRjHg7ADCA8tGn3vg%3D%3D.GmsnDfe7OVc31LGMJNU6S4PA5GmYFVGqT8rnAsjcp3o%3D" rel="nofollow" target="_blank">https://your-domain.com/api</a>；<br/>适配校园场景：<br/>修改pages/index/index.vue中的订单类型（如新增 “打印店代取”“图书馆占座” 等校园特色服务）；<br/>调整config/payment.js中的配送费（校园内建议 1-3 元 / 单，商用可按距离梯度设置）；<br/>配置小程序 AppID：点击「运行」→「运行到小程序模拟器」→「微信小程序」，输入自己的小程序 AppID。</li><li>打包发布代码<br/>点击 HBuilderX「发行」→「微信小程序」，选择 “发行到微信小程序开发者工具”；<br/>生成代码包后，打开微信开发者工具，导入生成的代码目录；<br/>调试核心功能：<br/>测试用户下单→支付→跑腿员接单→配送完成全流程；<br/>验证 WebSocket 实时推送（新订单是否推送给跑腿员）；<br/>检查管理后台（<a href="https://link.segmentfault.com/?enc=TR8byI3SteoyM58Ou8VAIw%3D%3D.4wsvuFD1NZTZiIK4blYBtYOZwnyoSaGjDVrBuF77a18%3D" rel="nofollow" target="_blank">https://your-domain.com/admin</a>）的订单管理、用户审核功能。<br/><img width="291" height="490" referrerpolicy="no-referrer" src="/img/bVdm6Ao" alt="" title="" loading="lazy"/><img width="387" height="860" referrerpolicy="no-referrer" src="/img/bVdniKq" alt="" title="" loading="lazy"/><br/><strong>总结</strong><br/>可商用的校园外卖跑腿小程序部署核心是 “标准化流程 + 商用配置适配”，基于完整源码包，只需完成服务器环境初始化、域名 / 微信配置、校园场景适配三大核心步骤，最快 1 天即可完成部署上线。商用阶段重点关注校园认证、佣金体系、合规配置三大模块，既能满足微信审核要求，又能适配校园轻量化运营需求，快速实现从 “部署” 到 “商用” 的落地。<br/><img width="723" height="697" referrerpolicy="no-referrer" src="/img/bVdjVHX" alt="" title="" loading="lazy"/><img width="723" height="697" referrerpolicy="no-referrer" src="/img/bVdh3qY" alt="" title="" loading="lazy"/><img width="723" height="247" referrerpolicy="no-referrer" src="/img/bVdmcMZ" alt="" title="" loading="lazy"/></li></ol>]]></description></item><item>    <title><![CDATA[集成产品开发（IPD）全指南：核心优势、自动化IPD工作流工具推荐 Zoey的笔记本 ]]></title>    <link>https://segmentfault.com/a/1190000047460277</link>    <guid>https://segmentfault.com/a/1190000047460277</guid>    <pubDate>2025-12-09 11:02:01</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>一、IPD：重新定义产品开发模式</h2><p>集成产品开发（Integrated Product Development，简称IPD）是一套系统性的产品开发管理理念与方法论。它起源于20世纪80年代的美国，由IBM、波音等大型科技和制造企业率先实践，随后华为在1999年引入并成功本土化，使其在中国企业界广为人知。 IPD的核心思想是通过跨部门协作、结构化流程和基于市场需求的决策，将产品开发从传统的“技术驱动”转变为“市场驱动”，从而提升产品成功率、缩短上市时间并优化资源利用。</p><h2>二、IPD的六大核心优势</h2><ol><li>市场成功率显著提升<br/>IPD强调在产品开发前进行充分的市场调研和需求分析，确保产品从概念阶段就与市场需求对齐。据统计，采用IPD方法的企业，其新产品市场成功率平均可提高20-30%。</li><li>开发周期大幅缩短<br/>通过并行工程、阶段评审和跨部门协作，IPD能够减少返工和等待时间。实践数据显示，IPD可将开发周期缩短30-50%，使企业更快响应市场变化。</li><li>开发成本有效控制<br/>IPD通过早期发现和解决问题，避免后期修改的高昂成本。其结构化流程也有助于资源合理分配，通常可降低开发成本20-40%。</li><li>产品质量全面提升<br/>质量管理贯穿IPD全过程，从需求定义到产品发布，每个阶段都有明确的质量标准和控制点，确保最终产品符合预期质量。</li><li>跨部门协同高效运作<br/>IPD打破部门壁垒，形成跨职能团队（如市场、研发、制造、服务等部门代表），实现信息共享和协同决策，减少内部摩擦。</li><li>投资回报率优化<br/>通过组合管理和阶段门控评审，IPD确保资源投向最有前景的项目，提高整体投资回报率。</li></ol><h2>三、哪些企业适合引入IPD？</h2><p>高度适用企业类型<br/>· 高科技与通信企业：如华为、中兴等，产品复杂度高、更新换代快</p><p>· 制造业与装备企业：特别是产品结构复杂、涉及多学科集成的领域</p><p>· 医疗器械与制药公司：严格监管环境下需要结构化开发流程</p><p>· 汽车及零部件企业：复杂系统集成和供应链协同要求高</p><p>· 软件开发与互联网企业：特别是2B和企业级软件提供商</p><p>适用条件评估<br/>企业考虑引入IPD前，可评估以下条件：</p><ol><li>产品开发复杂度较高，涉及多个专业领域</li><li>市场竞争激烈，对上市时间和成功率敏感</li><li>已有一定规模，部门墙明显，协同效率低</li><li>有资源投入流程变革，能够接受短期阵痛换取长期收益</li><li>领导层有坚定决心推动组织变革</li></ol><p>值得注意的是，小型创业公司可能不需要完整的IPD体系，但可以借鉴其核心理念，如市场导向、跨职能协作等。</p><h2>四、自动化IPD工作流工具推荐</h2><p>现代IPD实施越来越依赖数字化工具的支持，以下分类推荐主流工具：</p><p>国产优秀工具</p><ol><li>板栗看板：可视化项目协作工具，支持飞书、钉钉、企业微信等多平台，基于看板理论实现灵活任务管理</li></ol><p>o 优势：项目信息可视化呈现流程阶段、任务同步实时提醒督办、数据统计图表化穿透企业层级，支持看板/甘特/表格/日历等多视图切换及自动化工作流</p><p>o 适用场景：适用于电商、互联网服务、制造业等中小型团队，提升项目管理透明度和跨部门协作效率</p><ol start="2"><li>PingCode：国产一体化研发管理平台</li></ol><p>o 优势：符合国内团队工作习惯，支持敏捷和混合开发模式</p><p>o 适用场景：国内软件和互联网企业</p><p>综合型<br/>PTC Windchill：全面的产品生命周期管理(PLM)解决方案</p><p>o 优势：与CAD工具深度集成，支持复杂产品数据管理</p><p>o 适用场景：离散制造业、复杂产品开发</p><p>敏捷型<br/>Jira Align：企业级敏捷规划平台，支持规模化敏捷框架(SAFe)</p><p>o 优势：连接战略与执行，可视化价值流动</p><p>o 适用场景：大型软件开发组织，敏捷与IPD结合</p><h2>五、IPD实施建议与成功要素</h2><p>分阶段实施策略</p><ol><li>评估诊断阶段：分析企业现状，确定IPD适配度和实施范围</li><li>试点项目阶段：选择1-2个典型项目试点，积累经验</li><li>逐步推广阶段：在试点成功基础上，逐步扩大实施范围</li><li>全面实施阶段：全公司范围推广，持续优化流程</li><li>文化固化阶段：将IPD融入企业文化，形成持续改进机制</li></ol><p>成功关键要素<br/>· 高层承诺与支持：IPD是管理变革，需要高层持续推动</p><p>· 跨职能团队建设：培养真正的多功能团队，而非形式组合</p><p>· 流程与工具平衡：避免过度依赖工具而忽视流程本质</p><p>· 渐进式改进：根据企业实际情况调整IPD，不盲目照搬</p><p>· 度量与反馈：建立合适的度量体系，持续评估和改进</p><h2>结语</h2><p>IPD不是一成不变的僵化体系，而是一套可适应不同企业环境的柔性框架。在数字化和智能化时代，IPD与敏捷开发、DevOps等现代方法不断融合，演化出更加适应快速变化市场的新形态。企业引入IPD时，应把握其“以市场为导向、跨部门协同、结构化决策”的核心本质，结合自身情况灵活应用，才能真正发挥其提升产品创新能力和市场竞争力的价值。 无论选择何种工具或方法，最终目标始终是：在正确的时间，以正确的方式，交付满足客户需求的高质量产品——这正是IPD历经数十年仍被全球领先企业推崇的根本原因。</p>]]></description></item><item>    <title><![CDATA[工厂大脑如何实现"零停机"生产的终极目标？ 雨大王 ]]></title>    <link>https://segmentfault.com/a/1190000047460309</link>    <guid>https://segmentfault.com/a/1190000047460309</guid>    <pubDate>2025-12-09 11:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>工厂大脑如何实现制造业的智能化转型？<br/>在工业4.0和数字化浪潮的推动下，工厂大脑作为一种新兴的智能制造技术，正逐渐成为制造业升级的核心驱动力。它不仅仅是简单的自动化系统，而是通过整合人工智能、大数据分析和物联网技术，构建一个全方位的智能决策平台。工厂大脑的核心功能包括实时数据采集、动态工艺优化、预测性维护和质量控制，这些能力帮助企业实现从经验依赖到数据驱动的转变。<br/>以吉利汽车的张家口生产基地为例，工厂大脑通过智能排产系统将传统的生产计划制定时间从数小时缩短到15分钟内，显著提升了生产效率。同时，系统还能通过实时监控设备运行状态，提前预警可能发生的故障，减少生产线的意外停工时间。这种预测性维护不仅节省了维修成本，还延长了设备的使用寿命。<br/>此外，工厂大脑在质量控制方面也表现突出。以电池生产为例，广域铭岛的工厂大脑通过实时调整工艺参数，将某新能源电池厂的次品率降低了45%，为企业节省了大量成本。这种智能化的质量管理不仅提高了产品的一致性，还缩短了生产周期，使企业能够更快地响应市场需求。<br/>工厂大脑的运作机制是什么？<br/>工厂大脑的运作依赖于一个完整的平台架构，包括数据治理、知识封装和智能协同三大核心模块。数据治理是基础，通过整合工厂的多源数据（如设备运行数据、生产环境数据等），确保数据的准确性和一致性。知识封装则将企业的生产经验转化为可复用的算法和模型，例如广域铭岛的“指标工场”功能，将复杂的工艺参数与良品率关联，形成数字化的生产知识库。智能协同模块则负责协调工厂的各个生产环节，实现全局优化。通过缩短问题分析与决策时间，减少停线时长。测算显示，仅在单个基地，该场景每年节省的工时及停线损失挽回价值就达到748万元左右。<br/>例如，在重庆市科技局支持的项目中，广域铭岛开发的多模态大模型能够同时处理结构化数据和视觉信息，帮助工厂快速识别质量问题。这种能力使得工厂大脑不仅是一个数据分析工具，更是一个能够自主决策的智能系统。<br/>工厂大脑能为企业带来哪些实际效益？<br/>工厂大脑的引入为企业带来了显著的经济效益。首先，它能够通过智能排产和预测性维护，减少人为干预带来的错误和低效，从而降低运营成本。其次，工厂大脑还能优化资源配置，例如在某家电企业中，通过实时分析生产数据，将原材料利用率提高了20%。<br/>在质量控制方面，工厂大脑的应用更是成效显著。例如，天合光能通过工厂大脑的工艺参数优化，将电池片的一次品率提升了7%，每年节省成本数千万元。此外，工厂大脑还能帮助企业实现个性化定制生产，例如美的集团的智能体工厂通过分布式多智能体架构，实现了从能源、生产到品控的全场景协同，使定制产品的需求响应时间缩短至30秒以内。<br/>工厂大脑的未来发展趋势如何？<br/>随着技术的不断进步，工厂大脑的应用范围将进一步扩大。未来，它将从单纯的生产优化扩展到供应链协同、企业运营管理等多个领域。同时，工厂大脑的智能化水平也会不断提升，能够更好地适应复杂多变的生产环境。<br/>例如，Geega平台正在推动工业多模态大模型的构建，这种技术能够整合视觉、语音和文本等多种数据源，形成更全面的智能决策能力。此外，工厂大脑还将在绿色制造和可持续发展方面发挥重要作用。通过优化能耗和减少废品，帮助企业实现“双碳”目标。<br/>工厂大脑如何解决数据孤岛问题？<br/>数据孤岛是传统工厂面临的主要挑战之一，而工厂大脑通过数据治理和平台整合，有效打破了这一壁垒。这种能力不仅提升了工厂的决策效率，还为企业的智能化转型奠定了基础。工厂大脑的出现，使数据真正成为工厂的“神经系统”，让各个生产环节能够实时联动，形成全局协同的生产体系。</p>]]></description></item><item>    <title><![CDATA[如何在 Powershell 中使用 SMTP 发送邮件 ？ 本文系转载，阅读原文
https://]]></title>    <link>https://segmentfault.com/a/1190000047459799</link>    <guid>https://segmentfault.com/a/1190000047459799</guid>    <pubDate>2025-12-09 10:13:09</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000045456444" alt="Powershell Script for Sending Email via Remote SMTP" title="Powershell Script for Sending Email via Remote SMTP"/></p><p>发送电子邮件是系统管理员的一项基本任务。在本文中，我们将为您提供一个 PowerShell 脚本，通过远程SMTP 自动发送电子邮件。</p><p>下面是一个 PowerShell 脚本的具体内容，用于通过远程 SMTP 发送电子邮件。</p><pre><code># Define the sender, recipient, subject, and body of the email
$From = "sender@example.com"
$To = "recipient@example.com"
$Subject = "Test Email"
$Body = "This is a test email sent via remote SMTP using PowerShell."
 
# Define the SMTP server details
$SMTPServer = "smtp.example.com"
$SMTPPort = 587
$SMTPUsername = "username"
$SMTPPassword = "password"
 
# Create a new email object
$Email = New-Object System.Net.Mail.MailMessage
$Email.From = $From
$Email.To.Add($To)
$Email.Subject = $Subject
$Email.Body = $Body
# Uncomment below to send HTML formatted email
#$Email.IsBodyHTML = $true
 
# Create an SMTP client object and send the email
$SMTPClient = New-Object System.Net.Mail.SmtpClient($SMTPServer, $SMTPPort)
$SMTPClient.EnableSsl = $true
 
$SMTPClient.Credentials = New-Object System.Net.NetworkCredential($SMTPUsername, $SMTPPassword)
$SMTPClient.Send($Email)
 
# Output a message indicating that the email was sent successfully
Write-Host "Email sent successfully to $($Email.To.ToString())"</code></pre><h3>我的开源项目</h3><p><a href="https://link.segmentfault.com/?enc=AD%2Bj2EA9%2B46jBZUPKPM5bw%3D%3D.iTjbsBYdkq1BdwbmsPxIROTDeNnpzq8fTSPMXx9IIX4%3D" rel="nofollow" target="_blank"><img referrerpolicy="no-referrer" src="/img/remote/1460000043426502" alt="酷瓜云课堂-开源知识付费解决方案" title="酷瓜云课堂-开源知识付费解决方案" loading="lazy"/></a></p><ul><li><a href="https://link.segmentfault.com/?enc=z9tM5%2BJWfHJYfyeRCZQo%2Fg%3D%3D.gSc%2F%2FsVXPP4%2BYI4g0ZyxloiicqsJThqaXbTVemtmHZ5dH3tXSzQjMu8QZXlbIrMw" rel="nofollow" target="_blank">course-tencent-cloud（酷瓜云课堂 - gitee仓库）</a></li><li><a href="https://link.segmentfault.com/?enc=Bi0wGJskiNTsHgaAY1s22g%3D%3D.qI5cKWxoU1eUe7l2YVJ2mqkq23kgr%2B%2Bd8UxpDALmHNIHY56uPoKnyoCBxvxZxHLtVpoK2kcqCZRAOiGmyv3qQQ%3D%3D" rel="nofollow" target="_blank">course-tencent-cloud（酷瓜云课堂 - github仓库）</a></li></ul>]]></description></item><item>    <title><![CDATA[阁下 AI 多模型协同能力解析，有哪些方面？ 阁下AI ]]></title>    <link>https://segmentfault.com/a/1190000047459803</link>    <guid>https://segmentfault.com/a/1190000047459803</guid>    <pubDate>2025-12-09 10:12:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>阁下 AI 作为全球首个 AI 工具智能体平台，其多模型协同能力体现在五大核心维度，构建了超越单体模型的 "超级智能体" 系统：</p><p>一、异构模型智能整合  <br/>核心能力：无缝集成全球顶级大模型，构建 "模型联邦"  <br/>多元模型池：内置 NanoBanana Pro、Gemini3、DeepSeek 等 10 + 顶级大模型，覆盖语言理解、图像生成、代码编写等全领域能力  <br/>智能模型选择：通过自研 "意图解析引擎"，在 1 秒内分析用户需求，自动匹配合适模型组合  <br/>动态路由机制：根据任务复杂度、响应延迟和模型负载，智能分配请求，实现 "最强大脑" 与 "最适工具" 的精准匹配  <br/>技术实现：独创 "模型适配器" 技术，将不同模型接口统一标准化，实现 "一次调用、多模型响应"，避免用户手动切换的繁琐</p><p>二、任务智能拆解与流水线执行  <br/>核心能力：将复杂任务分解为原子操作，构建自动化执行链路  <br/>需求深度理解：将用户输入的自然语言需求（如 "制作产品发布会视频"）解析为完整的任务图谱，识别所需的文本创作、视觉设计、视频合成等子任务  <br/>工作流自动编排：像资深架构师一样，智能连接所需模型（如文案生成→视觉设计→视频合成），创建高效执行管道  <br/>执行节点无缝衔接：前一模型输出自动成为下一模型输入，全程无需人工干预，实现 "一键式" 全流程自动化  <br/>应用案例：用户创建 "照片修复上色" 工具时，系统自动串联图像识别、破损修复、色彩重建等模型，完成从模糊老照片到高清彩色图像的完美转换</p><p>三、多模态协同与融合推理  <br/>核心能力：打破模态壁垒，实现文本、图像、音频、视频的协同理解与创作  <br/>跨模态感知：支持多类型数据联合分析，例如：  <br/>上传菜品照片→AI 识别食材→生成食谱（图像 + 文本协同）  <br/>输入文字描述→生成对应场景图像→添加语音旁白（文本 + 图像 + 音频协同）  <br/>多模型交叉验证：对复杂问题，同时调用多个模型并行处理，通过结果比对生成可信度 &gt; 92% 的最终答案，降低单一模型误判风险  <br/>协同创作：实现 "你构思、AI 实现" 的全链路创作，如输入 "制作科幻风格产品海报"，系统自动协调文案模型、图像生成模型、排版模型共同完成作品</p><p>四、智能体协作系统  <br/>核心能力：构建 "AI 团队"，实现专业化分工与协作  <br/>角色化智能体：  <br/>总指挥智能体（Manager）：分析需求、规划任务、分配职责  <br/>专业技能智能体（Worker）：如文案专家、设计大师、数据分析员，各擅所长  <br/>记忆智能体（Memory）：保存对话历史和知识，确保上下文一致性  <br/>任务动态分发：根据实时负载和模型专长，将子任务精准分配给最合适的智能体，形成 "流水线式" 高效协作  <br/>执行监控与异常处理：协调智能体（Controller）实时监督执行进度，遇故障自动切换备用路径，确保任务完成率  <br/>应用实例：创建 "智能数据分析仪表盘" 时，系统自动安排：  <br/>数据智能体清洗整合多源数据  <br/>分析智能体生成可视化图表  <br/>报告智能体撰写分析结论  <br/>设计智能体美化界面，最终输出完整可交互的仪表盘</p><p>五、工具创造与自主扩展  <br/>核心能力：将 "模型能力" 转化为 "用户可用工具"，实现能力的指数级增长  <br/>自然语言驱动的工具生成：输入 "创建一个 AI 简历优化工具"，系统自动完成：  <br/>需求分析→界面设计→模型集成→代码生成→完整工具部署，全程无需编程  <br/>模型能力自由组合：像搭积木一样，将不同模型的能力（如文本生成 + 图像识别 + 数据可视化）组合成全新工具，满足用户独特需求  <br/>持续进化：系统通过用户反馈自动优化模型协作策略，使工具越用越智能，形成良性循环  <br/>价值提升：这种 "多模型协同 + 工具创造" 的模式，让用户不仅是 AI 功能的使用者，更成为 AI 能力的 "创造者"，将 AI 从单一服务升级为 "能力生产平台"</p><p>总结：阁下 AI 的多模型协同能力不是简单的 "模型叠加"，而是构建了一个有机智能体生态，让不同模型像交响乐团般协同演奏，将 AI 从 "单一工具" 升级为 "全能助手"。这种能力使阁下 AI 能够解决任何复杂度的任务，为用户提供 "所想即所得" 的终极 AI 体验，真正实现 "一个平台，解决所有智能需求" 的愿景。</p>]]></description></item><item>    <title><![CDATA[怎么申请免费SSL证书 冷姐Joy ]]></title>    <link>https://segmentfault.com/a/1190000047459835</link>    <guid>https://segmentfault.com/a/1190000047459835</guid>    <pubDate>2025-12-09 10:11:43</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h4><strong>一、什么是SSL证书？为什么你需要它？</strong></h4><p>简单来说，SSL证书是一个数字文件，它有两个核心作用：</p><ol><li><strong>数据加密</strong>：将你在网站上输入的密码、银行卡号等信息变成乱码，只有指定的服务器才能解密，确保传输过程中不被黑客窃取。</li><li><strong>身份验证</strong>：向访客证明你的网站是真实可信的，而不是一个仿冒的钓鱼网站。</li></ol><p><strong>拥有SSL证书的好处：</strong></p><ul><li><strong>提升安全性</strong>：保护用户和网站的数据。</li><li><strong>获取信任</strong>：浏览器地址栏会显示“锁”的标识，告诉用户此网站安全。</li><li><strong>利于SEO</strong>：谷歌等搜索引擎会给启用HTTPS的网站更高的搜索排名。</li><li><strong>满足合规要求</strong>：许多在线支付系统都要求网站必须使用HTTPS。</li></ul><h3>直接访问JoySSL，注册一个账号记得填写注册码230973获取免费证书。</h3><p><img width="614" height="404" referrerpolicy="no-referrer" src="/img/bVdisvl" alt="" title=""/></p><h4><strong>二、申请SSL证书的详细步骤</strong></h4><p>整个过程可以概括为：提交申请 -&gt; 验证身份 -&gt; 安装证书。</p><h5><strong>1. 选择类型并提交申请</strong></h5><p>根据你的需求，选择合适的SSL证书类型：</p><ul><li><strong>域名型DV</strong>：<strong>只验证域名所有权</strong>，申请最快，通常几分钟到几小时。适合个人网站、博客。</li><li><strong>企业型OV</strong>：<strong>需要验证企业真实性</strong>，地址栏会显示公司名称，信任度更高。适合企业官网。</li><li><strong>增强型EV</strong>：<strong>最严格的验证</strong>，地址栏会<strong>绿色显示公司名称</strong>，安全级别最高。适合银行、金融、电商平台。</li></ul><p><strong>选择证书颁发机构</strong>： 你可以从<strong>付费CA</strong>（如DigiCert）或<strong>免费CA</strong>（如JoySSL，Let‘s Encrypt）处获取证书。</p><ul><li><strong>免费推荐</strong>：提供免费的DV证书，非常适合个人和小型网站。许多主机商现已内置支持，一键即可申请。</li><li><strong>付费选择</strong>：如果需要OV或EV证书，或更长的有效期和专业的技术支持，则需购买付费证书。</li></ul><p>选定后，在证书服务商的网站上提交申请，并将上一步生成的<strong>CSR代码粘贴</strong>到指定位置。</p><h5><strong>2. 完成域名/所有权验证</strong></h5><p>提交申请后，CA需要确认你确实拥有这个域名。验证方式通常有三种：</p><ul><li><strong>DNS验证</strong>：按照CA的要求，在你的域名DNS解析中添加一条特定的TXT记录。<strong>这是最常见的方式。</strong></li><li><strong>文件验证</strong>：在网站的根目录下放置一个特定的验证文件。</li><li><strong>邮箱验证</strong>：向域名WHOIS信息中的管理员邮箱发送验证邮件。</li></ul><p><strong>完成验证后，CA就会审核并签发证书。</strong>  你会收到一个包含证书文件（通常是.crt或.pem格式）的邮件。</p><h5><strong>3. 安装到你的服务器</strong></h5><p>现在，你需要将收到的证书文件“安装”到你的网站服务器上。</p><ul><li><strong>对于虚拟主机用户</strong>：这通常非常简单。登录主机控制面板，找到“安装SSL证书”的选项，上传你收到的证书文件，很多主机商提供“一键安装”功能。</li><li><strong>对于VPS/独立服务器用户</strong>：你需要将证书文件和第一步生成的私钥文件上传到服务器指定目录，并在Web服务器（如Nginx, Apache）的配置文件中进行配置，然后重启服务。</li></ul><p><strong>安装成功后，访问你的网站，地址栏应该会出现一把“小锁”，URL也变成了 <code>https://</code> 开头。</strong></p><h4><strong>三、总结与后续</strong></h4><p>申请SSL证书的核心流程就是：<strong>生成CSR -&gt; 提交验证 -&gt; 安装生效</strong>。</p><p><strong>重要提醒：</strong></p><ul><li><strong>私钥安全</strong>：第一步生成的私钥是最高机密，一旦丢失或泄露，证书就失效了。</li><li><strong>注意有效期</strong>：SSL证书不是永久的（免费证书通常3个月，付费证书1年），<strong>务必在到期前续费或重新申请</strong>，否则网站会显示为“不安全”。</li></ul>]]></description></item><item>    <title><![CDATA[Gartner Magic Quadrant for Hybrid Mesh Firewall 20]]></title>    <link>https://segmentfault.com/a/1190000047459843</link>    <guid>https://segmentfault.com/a/1190000047459843</guid>    <pubDate>2025-12-09 10:10:45</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>Gartner Magic Quadrant for Hybrid Mesh Firewall 2025</p><p>Gartner 魔力象限：混合网格防火墙 2025</p><p>请访问原文链接：<a href="https://link.segmentfault.com/?enc=QiVN%2FqH3PwByY3rByt%2FMGA%3D%3D.9hrFRZjFGJ2vIACJOnEVYP29PswhsrhxJJEYKfSi2s1CWNeQ%2FyzH4jvU%2BXK%2FLOIGtT3DKwI0CeEfT%2B6R4IcI4Q%3D%3D" rel="nofollow" target="_blank">https://sysin.org/blog/gartner-magic-quadrant-firewalls-2025/</a> 查看最新版。原创作品，转载请保留出处。</p><p>作者主页：<a href="https://link.segmentfault.com/?enc=jheNQ7J7IOHSnJEJt7Ueww%3D%3D.8kMqLZICUV1sAd3yhUg1gsq0MhRgDbbEuFtS7iDd6Ik%3D" rel="nofollow" target="_blank">sysin.org</a></p><hr/><p>Gartner Magic Quadrant for Hybrid Mesh Firewall 2025</p><p>Published 25 August 2025</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459845" alt="Magic Quadrant" title="Magic Quadrant"/></p><h2>魔力象限</h2><p>Hybrid Mesh Firewall 魔力象限</p><p>25 August 2025</p><p>本魔力象限分析了 Hybrid Mesh Firewall（HMF），这些产品在硬件、虚拟与云部署中提供统一的云端管理。厂商可以利用本研究了解能够支持混合环境、具备高级 CI/CD 集成、原生云能力以及强大威胁防御的 HMF。</p><p><strong>市场定义/描述</strong>：</p><p>Hybrid Mesh  Firewall（HMF）是一种多部署模式的防火墙，包括硬件、虚拟设备和基于云的选项，并具有统一的云端管理平面。HMF  旨在通过提供成熟的持续集成/持续交付（CI/CD）管道集成、原生云集成，以及可扩展至 Internet of Things（IoT）设备和  DNS 攻击的高级威胁防御功能 (sysin)，以支持混合环境和不断演进的使用场景。</p><p>随着混合环境的普及，客户倾向于使用同一家防火墙厂商，通过集中管理和跨环境的策略可视性来简化管理并降低运维复杂性。因此，来自同一本地防火墙厂商的 Cloud Firewall 的需求和采用量正在增长。Hybrid Mesh Firewall  通过硬件、虚拟和专用云防火墙部署形式，以及基于云的集中可视化与管理能力，来支持这一场景。</p><p>Hybrid Mesh Firewall 支持多云和混合环境中的防火墙使用场景  (sysin)，包括数据中心、企业边界与分支办公室。它们提供高级威胁防御，例如 DNS security 和 IoT  security。CI/CD 集成以及与云原生控制集成的能力支持 Cloud Firewall  部署场景。基于云的集中管理器可对这些以不同形式（硬件/虚拟/云）部署在混合环境中的防火墙提供可视性与控制能力。</p><p><strong>必备功能</strong>（Mandatory Features）</p><ul><li>可由单一管理接口管理的硬件/虚拟与专用 cloud firewall 部署形式。</li><li>具备自动调优与策略推荐能力的云端集中管理器。</li><li>防火墙能力（状态检测、Secure Sockets Layer [SSL] 解密、URL filtering、app control、threat prevention）。</li><li>针对 IoT 和 DNS 攻击的高级威胁防御 (sysin)。</li><li>安全远程访问（例如 SSL VPN、IPsec VPN、zero-trust network access（ZTNA））。</li><li>CI/CD 集成。</li><li>与云原生基础架构的集成。</li></ul><p><strong>常见功能</strong>（Common Features）</p><ul><li>对云原生网络安全控制的集中可视性</li><li>Zero-touch 家庭办公防火墙设备</li><li>对云原生微分段控制的集中可视性</li><li>集中可视性以及微分段与第三方的集成</li><li>从集中管理平台中可选地编排 firewall as a service（FWaaS）</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459846" alt="Hybrid Mesh Firewall 魔力象限" title="Hybrid Mesh Firewall 魔力象限" loading="lazy"/></p><p><strong>领导者（Leaders）</strong>：（无变化）</p><ul><li>Palo Alto Networks</li><li>Fortinet</li><li>Check Point</li></ul><p><strong>挑战者（Challengers）</strong>：</p><ul><li>Juniper（HPE）</li></ul><p><strong>有远见者（Visionaries）</strong>：</p><ul><li>Cisco</li></ul><p><strong>特定领域者（Niche Players）</strong>：见图</p><p>查看完整报告（限期公开）：<a href="https://link.segmentfault.com/?enc=K0Mo4ypFy5y2Gse4sZKy8g%3D%3D.vU5NilhMsNM%2B%2B7GL26cquR3ClDpF9cax0hVqyqPvsCLjQzLeHM3S05D7apFotrDLD80WBsnpTfwvikN%2FKFkIdA%3D%3D" rel="nofollow" target="_blank">https://sysin.org/blog/gartner-magic-quadrant-firewalls-2025/</a></p><h2>如何选择</h2><p>主要技术市场上有哪些竞争参与者？他们如何为您提供长期帮助？Gartner  魔力象限是对特定市场的巅峰研究，可帮您广泛了解市场竞争对手的相对位置 (sysin)。利用图示法和一系列统一的评估标准，魔力象限可帮助您快速确定技术提供商执行其既定愿景的情况，并参照 Gartner  的市场观点了解其表现。</p><p><strong>如何使用 Gartner 魔力象限？</strong></p><p>面对特定投资机会考虑技术提供商时，请借助 Gartner 魔力象限迈出第一步。</p><p>请记住，专注于领导者象限不一定是最好的行动方案。有充分的理由考虑市场挑战者。特定领域者可能比市场领导者更能满足您的需求。这完全取决于提供商如何与您的业务目标保持一致。</p><p><strong>Gartner 魔力象限如何发挥作用？</strong></p><p>面对快速增长和提供商差异化明显的众多市场，Gartner 魔力象限用图形化方法划分出四类提供商：</p><ul><li>领导者很好地执行了当前愿景 (sysin)，并为未来做好了充分准备</li><li>有远见者了解市场发展方向，或者有改变市场规则的设想，但执行效果不尽如人意。</li><li>特定领域者成功专注于一个小的细分市场，或者目标不明确，创新和表现未能超越竞争对手。</li><li>挑战者当前表现很好，或者可能在大部分细分市场占据主导地位，但未表现出对市场方向的了解。</li></ul><h2>相关产品下载</h2><p>下载试用<strong>领导者</strong>产品：<a href="https://link.segmentfault.com/?enc=0bzsrItCi%2BrW8YogNKg4jA%3D%3D.loEegxZ4SoGvkS8LTWDElnX88zDzWztraV3xdtu2ObLWnRGGJbP%2ByBQmU%2BrKvPJE" rel="nofollow" target="_blank">Firewall 产品链接汇总</a></p>]]></description></item><item>    <title><![CDATA[告别“不安全”警告：一文读懂SSL证书部署全攻略 魁梧的松鼠 ]]></title>    <link>https://segmentfault.com/a/1190000047459850</link>    <guid>https://segmentfault.com/a/1190000047459850</guid>    <pubDate>2025-12-09 10:09:47</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>当您在浏览器中输入网址，期待看到熟悉的网站界面时，突然出现的红色“不安全”警告无疑令人不安。这个刺眼的提示不仅影响用户体验，更可能让潜在客户对网站的可信度产生怀疑。今天，让我们深入探究这一现象背后的原因，并系统性地解决SSL证书相关问题。</p><h3>为什么会出现“不安全”警告？</h3><p><img width="723" height="323" referrerpolicy="no-referrer" src="/img/bVdmVAD" alt="" title=""/></p><p>现代浏览器（如Chrome、Edge、Firefox）对网站安全性有着严格标准。当您访问一个使用HTTP而非HTTPS协议的网站，或HTTPS网站存在证书问题时，浏览器就会发出警告。这并非系统错误，而是浏览器在尽职提醒：您与该网站之间的连接可能被第三方窥探或篡改。</p><p>其核心原因主要围绕SSL/TLS证书：</p><ul><li>网站未安装SSL证书（仍使用HTTP协议）</li><li>SSL证书已过期（通常证书有效期为1年）</li><li>证书与域名不匹配（如证书为<a href="https://link.segmentfault.com/?enc=P%2FzoQYPWwCZ581QTR7tJdg%3D%3D.EeStXg%2BVXIsxlitFlR5oXipYfH%2FVRNdljeNfJeAj%2Bw4%3D" rel="nofollow" target="_blank">www.domain.com</a>，但访问的是<a href="https://link.segmentfault.com/?enc=0zHFN3waXYyOZlDz9yMMaQ%3D%3D.Z5xXYOum%2FUVYnybV9rkjknCFLUOCsGO1byPIqJZdUvE%3D" rel="nofollow" target="_blank">domain.com</a>）</li><li>证书由不受浏览器信任的机构签发</li><li>网站包含混合内容（HTTPS页面中引用了HTTP资源）</li></ul><h3>SSL证书：网络世界的“数字身份证”</h3><p>SSL证书好比网站的数字身份证，它通过加密技术在用户浏览器和网站服务器之间建立安全通道，确保传输数据（如登录凭证、支付信息）不被窃取或篡改。当浏览器检测到有效证书时，地址栏会显示锁形图标和“安全”字样，使用户安心访问。</p><h3>四步解决SSL证书问题</h3><h4>第一步：获取合适的SSL证书  <a href="https://link.segmentfault.com/?enc=BcHZMD0dOH7VE%2ByV2oLcDg%3D%3D.YZWjB7Zk5MM3fg8mZ%2FZurxizcJkoVQU8VW%2FphPE6li%2BvwNeiLLxpOC5yzTImFTNkQggzE%2BYd8uo9UlYZkBcYWJN%2F5YFu1OE2%2FfS6vU55hKM%3D" rel="nofollow" target="_blank"> 申请入口</a></h4><h4>获取SSL证书渠道：<strong><em>打开JoySSL证书官网，填写注册码230970获取技术支持</em></strong></h4><p>根据网站需求选择证书类型：</p><ul><li><strong>域名验证（DV）证书</strong>：基础加密，验证域名所有权，适合个人网站、博客</li><li><strong>组织验证（OV）证书</strong>：验证企业真实性，适合企业官网</li><li><strong>扩展验证（EV）证书</strong>：最高级别验证，地址栏显示公司名称，适合电商、金融机构</li><li><strong>通配符证书</strong>：保护主域名及其所有子域名</li><li><strong>多域名证书</strong>：单一证书保护多个不同域名</li></ul><h4>第二步：正确安装与配置证书</h4><ol><li><strong>生成CSR（证书签名请求）</strong> ：在服务器上生成包含网站信息和公钥的CSR文件</li><li><strong>提交CSR并验证</strong>：向CA提交CSR，按要求完成域名或组织验证</li><li><strong>安装证书</strong>：收到CA颁发的证书后，安装到服务器</li><li><strong>强制HTTPS重定向</strong>：修改网站配置，将所有HTTP请求重定向到HTTPS</li></ol><h4>第三步：排查混合内容问题</h4><p>即使启用了HTTPS，如果网页中引用了HTTP资源（如图片、脚本、样式表），浏览器仍可能显示“不安全”。使用浏览器开发者工具（F12）的“控制台”或“安全”选项卡，可识别混合内容。解决方案是更新所有资源引用为HTTPS或使用相对协议（如“//<a href="https://link.segmentfault.com/?enc=T2vGsSLkKkiZjfWYdkHRoQ%3D%3D.wcgMffwP6D2C%2FuX1Jbj%2FCMLa9Cxy2KdXtl03sEZoEOmWBjBDHvpFO2TfmXlXdaCT" rel="nofollow" target="_blank">example.com/resource.jpg”</a>）。</p><h4>第四步：验证与测试</h4><p>部署完成后，使用以下工具验证：</p><ul><li><strong>SSL Labs SSL Test</strong>（<a href="https://link.segmentfault.com/?enc=Mh0gaTKdrj6Y75%2Bdu6uSkQ%3D%3D.gCu20gdku6aVSZBVP6jV%2FS6Wr9IwCwB0lSykXP5Q3fs%3D" rel="nofollow" target="_blank">ssllabs.com/ssltest</a>）：全面检测证书配置和安全性</li><li><strong>浏览器开发者工具</strong>：检查安全状态和证书详情</li><li><strong>Why No Padlock</strong>（<a href="https://link.segmentfault.com/?enc=QzpRnOG4JWvN0pAZ4sd9EQ%3D%3D.gQDcLzEuX5le2wpaOAcbHY82t3K4toe7%2BcPIVQee464%3D" rel="nofollow" target="_blank">whynopadlock.com</a>）：专门检测混合内容问题</li></ul><h3>结语：安全是信任的基石</h3><p>解决HTTPS“不安全”警告不仅是技术调整，更是对访客安全的郑重承诺。在数据泄露频发的数字时代，一个简单的锁形图标代表着网站运营者对用户隐私的尊重和保护。投资SSL证书就是投资用户信任——这份信任，正是任何在线业务最宝贵的资产。</p><p>无论您是个人站长还是企业IT管理员，花少量时间部署和维护SSL证书，都将为您的网站访客构筑一道坚固的安全防线。在这个细节决定体验的时代，让每一处“安全”提示，成为您专业性与责任感的无声宣言。</p>]]></description></item><item>    <title><![CDATA[一文详细讲解CRM系统（附架构图、流程、功能、主流厂商） 程序员老叶 ]]></title>    <link>https://segmentfault.com/a/1190000047459852</link>    <guid>https://segmentfault.com/a/1190000047459852</guid>    <pubDate>2025-12-09 10:08:52</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>过去十年，企业花了巨额预算做广告投放、活动营销，却越来越常说一句话：<strong>“获客成本越来越高，成交率却上不去。”</strong>  <br/>问题往往不在流量，而在「管理」。于是，CRM（客户关系管理系统）从“小工具”升级成了很多企业的“增长中枢”。</p><p>这篇文章，我们用一篇长文，把 <a href="https://link.segmentfault.com/?enc=SXouU1uUZocImZg1UZq9yg%3D%3D.xnkDW37AkrjyB%2Brm9PYdtG6hK%2Fey8NgYOGeV3vrUOHZYCYhcUtCwfaIJRHTh7mbQ" rel="nofollow" target="_blank">CRM系统</a> 讲清楚：</p><ul><li>CRM系统 是什么、到底解决哪些问题？</li><li>一套 CRM 系统的<strong>典型架构图长什么样？</strong></li><li>从线索到回款，<strong>完整业务流程如何在 CRM 落地？</strong></li><li>一个成熟 CRM 应该包含哪些<strong>核心功能模块？</strong></li><li>市面上有哪些<strong>主流 CRM 厂商</strong>，适合什么阶段的企业？</li></ul><p>下面按逻辑顺序展开。</p><h2><img width="723" height="610" referrerpolicy="no-referrer" src="/img/bVdniC0" alt="image.png" title="image.png"/></h2><h2>一、什么是 CRM？为什么几乎所有公司都在用？🧭</h2><h3>1. CRM 的基本定义</h3><p>CRM（Customer Relationship Management），中文是<strong>客户关系管理系统</strong>。  <br/>一句人话概括：</p><blockquote><strong>CRM 就是把“人”的信息和整个成交过程系统化管理，帮企业用更低成本、更高效率地获得和留住客户。</strong></blockquote><p>从表面看，它是一个软件系统；  <br/>从本质看，它是企业对客户全生命周期管理的一套方法论与数据平台。</p><h3>2. CRM 解决的典型痛点</h3><p>在没有 CRM 的公司里，常见现象有：</p><ul><li>客户信息散落在：销售个人微信、Excel、钉钉群、邮箱里</li><li>老销售一离职，<strong>客户资源直接“人走客走”</strong></li><li>同一个客户，被不同销售<strong>重复电话打扰、体验极差</strong></li><li>线索来源不清楚，<strong>钱到底花在哪个平台最有效完全看感觉</strong></li><li>销售数据全靠人填日报、周报，领导看报表<strong>滞后又不准确</strong></li></ul><p>CRM 的核心就是解决这些问题，让客户和销售过程<strong>在线化、可追踪、可复盘、可优化</strong>。</p><h3>3. CRM 带来的核心价值</h3><p>用一句公式概括 CRM 的价值：</p><blockquote><strong>更多合格线索 × 更高转化率 × 更高客单价 × 更长客户生命周期</strong></blockquote><p>落到实际，可以拆成几类价值：</p><ul><li><strong>获客效率提升</strong>：打通官网、广告、表单、线下活动等，线索自动进入系统并分配</li><li><strong>销售转换率提升</strong>：统一销售流程、自动提醒跟进，减少“忘记跟进”和“乱跟进”</li><li><strong>管理可视化</strong>：领导随时看销售漏斗、预测业绩，调整策略有依据</li><li><strong>客户体验提升</strong>：客户资料和沟通记录完整沉淀，不再“你是谁、我们之前聊过吗？”</li><li><strong>组织抗风险能力提升</strong>：客户和业绩不再高度依赖某几位销售个人</li></ul><hr/><h2>二、CRM 系统架构图：从“流量入口”到“业务中台”🏗️</h2><p>为了更直观，先看一张抽象后的<strong>CRM 典型架构图</strong>思路说明（本文用文字+结构化方式来描述）：</p><hr/><h3>1. 经典 CRM 高层架构（逻辑示意）</h3><p>可以将 CRM 系统拆成四层：</p><ol><li><p><strong>渠道与触点层（最上层）</strong></p><ul><li>官网、落地页、表单</li><li>在线聊天工具（如网站 IM、WhatsApp 等）</li><li>电话、邮件、短信</li><li>广告平台（百度、Google、Facebook、抖音等）</li><li>线下展会、门店、活动</li></ul></li><li><p><strong>业务应用层（中间）</strong>  <br/>核心就是 CRM 的各业务模块：</p><ul><li>线索管理</li><li>商机 / 交易管理</li><li>客户（公司与联系人）管理</li><li>活动 / 任务管理</li><li>报价、订单、合同、回款管理</li><li>服务工单 / 客服管理（如果与服务模块整合）</li></ul></li><li><p><strong>数据与规则层</strong></p><ul><li>客户数据模型（客户、联系人、账户关系等）</li><li>业务规则（线索分配规则、审批流、计分规则）</li><li>自动化流程（工作流、邮件/短信自动触发）</li><li>报表与分析（销售漏斗、业绩预测、多维分析）</li></ul></li><li><p><strong>集成与平台层（底层）</strong></p><ul><li>与 <strong>邮件系统</strong>（如 Gmail、Outlook）集成</li><li>与 <strong>电话系统/呼叫中心</strong> 集成</li><li>与 <strong>财务/ERP</strong> 系统对接（同步订单、发票、回款）</li><li>与 <strong>营销自动化工具</strong>、表单工具、BI 工具等对接</li><li>API / Webhook 对外开放，支持定制开发</li></ul></li></ol><hr/><h3>2. CRM系统架构图</h3><p><img width="723" height="610" referrerpolicy="no-referrer" src="/img/bVdniC2" alt="image.png" title="image.png" loading="lazy"/></p><hr/><h2>三、CRM 里的完整业务流程：从线索到回款🔁</h2><p>理解 CRM，最重要的是看清一条主线：<strong>客户从“陌生”到“成交”再到“复购”的全过程</strong>。<br/><img width="723" height="616" referrerpolicy="no-referrer" src="/img/bVdniC4" alt="image.png" title="image.png" loading="lazy"/><br/>下面以典型 B2B 企业为例，把流程拆开讲。</p><h3>1. 线索获取与导入</h3><p><strong>入口很多，目标只有一个：让线索不再“散落各处”。</strong></p><p>常见来源：</p><ul><li>官网/落地页表单（自动写入 CRM 线索模块）</li><li>广告平台（通过 API 或表格导入）</li><li>线下活动/展会（扫描名片或 Excel 导入）</li><li>公众号/小程序留资（通过中间件或接口打通）</li><li>手工录入（如客户电话进来，前台/销售登记）</li></ul><p>在 Zoho CRM 这样的系统中，可以设置规则：</p><ul><li>自动识别来源渠道</li><li>自动打标签（比如“展会 XX”、“百度搜索”、“老客户转介绍”）</li><li>自动分配给对应团队或销售人员</li></ul><hr/><h3>2. 线索分配与跟进</h3><p>线索进来之后，下一步是：<strong>尽快分配给对的人，并开始跟进</strong>。</p><p>常见分配方式：</p><ul><li><strong>按区域</strong>：华东给 A 团队，华南给 B 团队</li><li><strong>按行业</strong>：教育、制造、互联网金融，各自有团队</li><li><strong>按来源</strong>：大客户渠道给资深销售，小 B 客户给电销团队</li><li><strong>轮询分配</strong>：按照顺序自动轮流分配，防止“抢资源”</li></ul><p>分配之后，销售在 CRM 中进行：</p><ul><li>拨打电话、发短信、发邮件（部分 CRM 支持系统内一键呼叫/发信）</li><li>记录沟通要点、客户需求、预算、时间计划</li><li>预约下次跟进时间，系统自动提醒</li></ul><p>这一步的目标：<strong>确认意向，进行初步资格评估</strong>。</p><hr/><h3>3. 线索转化为客户 + 商机</h3><p>当确认某个线索是“值得继续深度跟进的”，就会在 CRM 中做一次关键动作：<strong>转化（Convert）</strong>。</p><p>通常会自动生成：</p><ul><li>一个“客户（公司）”记录</li><li>对应的“联系人”记录（决策人/使用人等）</li><li>可选：一个“商机 / 交易”记录（包含预计成交金额、预计成交日期等）</li></ul><p>从这一刻起，这个对象已经不再是“海量线索池里的一条记录”，而是进入了<strong>正式销售流程</strong>。</p><hr/><h3>4. 商机阶段推进（销售漏斗）</h3><p>商机是 CRM 的“心脏”。  <br/>每一个商机，就像一条在漏斗里往下流的机会。</p><p>典型阶段包括（可按企业自定义）：</p><ol><li>初步接触</li><li>需求沟通</li><li>方案／报价</li><li>商务谈判</li><li>合同审批</li><li>成交 / 失单</li></ol><p>在 CRM 中，销售可以：</p><ul><li>更新商机阶段、金额、预计签单日期</li><li>记录每一次会议、拜访、Demo 结果等</li><li>附件上传：方案文档、报价单等</li><li>关联相关联系人（决策人、技术评审、财务等）</li></ul><p>系统则会：</p><ul><li>自动计算销售漏斗（不同阶段金额）</li><li>自动生成业绩预测（比如本月有多少可能成交）</li><li>自动识别卡在某阶段时间过长的商机，提醒处理</li></ul><hr/><h3>5. 报价、合同、订单与回款</h3><p>到了后期阶段，就会涉及到钱：<strong>报价、合同、订单、发货、回款</strong>。</p><p>在很多 CRM（包括 Zoho CRM）中，这一部分可以这样落地：</p><ul><li>在商机下直接生成<strong>报价单</strong>（可用产品目录、折扣规则）</li><li>报价需要审批时，走<strong>价格/折扣审批流程</strong></li><li>确认后生成<strong>销售订单 / 合同</strong></li><li>订单对接 ERP / 财务系统，完成<strong>发货、开票、回款记录</strong></li><li>回款数据回写到 CRM，形成完整闭环</li></ul><p>这样做有几个好处：</p><ul><li>销售不开“空头支票”，折扣有边界可控</li><li>订单和回款与商机一一对应，<strong>后续复盘“哪种客户更容易回款”</strong>有数据支持</li><li>财务、销售、运营看的是同一套事实数据</li></ul><hr/><h3>6. 售后与二次营销（客户成功）</h3><p>成交只是开始，长期价值在后面。  <br/>优秀的 CRM 还会延伸到：</p><ul><li><strong>服务/工单模块</strong>：记录客户问题、处理进度、满意度</li><li><strong>续费/增购提醒</strong>：按产品到期时间自动提醒销售或客服</li><li><strong>交叉销售 / 向上销售机会挖掘</strong>：通过数据分析识别潜在增购客户</li></ul><p>CRM 与客服系统、邮件营销工具、在线工单打通后，企业可以真正做到：</p><blockquote>从获客 → 成交 → 售后 → 续费 → 口碑转介绍的完整闭环管理。</blockquote><hr/><h2>四、CRM 核心功能模块全梳理📦</h2><p>下面系统地列一列，一套成熟 CRM 的典型功能构成。</p><h3>1. 客户与线索管理</h3><ul><li>线索管理：导入、分配、打分、去重、转化</li><li><p>客户管理：</p><ul><li>公司/账户（Account）</li><li>联系人（Contact）：职位、角色、决策权重</li><li>客户标签：行业、规模、阶段、等级（A/B/C）等</li></ul></li><li>历史记录：所有电话记录、邮件往来、会议、备注等</li></ul><h3>2. 销售过程管理（商机 &amp; 活动）</h3><ul><li><p>商机 / 交易管理：</p><ul><li>阶段设置与推进</li><li>预计签单金额、概率、日期</li><li>与产品/报价关联</li></ul></li><li><p>活动 &amp; 任务：</p><ul><li>电话、会议、拜访、跟进任务</li><li>待办提醒、日程安排、同步到日历</li></ul></li><li><p>销售节奏模板：</p><ul><li>标准化的跟进节奏（例如 T+1 电话、T+3 邮件等）</li></ul></li></ul><h3>3. 报价、订单、合同、回款</h3><ul><li>产品目录管理（SKU、价格、成本、税率）</li><li>报价单生成与审批</li><li>订单管理（可与库存、发货对接）</li><li>合同管理（合同版本、审批流、电子签集成）</li><li>发票与回款记录（可对接财务系统）</li></ul><h3>4. 自动化与工作流</h3><ul><li>线索自动分配规则（按来源、地区、行业、渠道等）</li><li>自动化跟进（例如：新线索 10 分钟未跟进自动提醒销售）</li><li>阶段变更触发动作（发邮件、创建任务、通知经理）</li><li>审批流（折扣审批、合同审批、费用申请）</li></ul><h3>5. 报表、仪表盘与预测</h3><ul><li>销售漏斗分析（不同阶段数量与金额）</li><li>业绩报表（按个人、团队、区域、产品维度）</li><li>渠道 ROI 分析（不同渠道线索转化与订单金额）</li><li>回款与逾期情况分析</li><li>业绩预测（预测本月/季度收入）</li></ul><h3>6. 协同与权限管理</h3><ul><li>团队协作：共享客户、@同事评论、分工跟进</li><li><p>权限控制：</p><ul><li>按角色控制可见字段和数据范围</li><li>敏感数据脱敏（如仅部分人员可看客户电话）</li></ul></li><li>审计日志：谁看了哪些数据、做了哪些修改</li></ul><h3>7. 集成与扩展</h3><ul><li>邮件集成（收发邮件自动关联到对应客户）</li><li>电话系统集成（弹屏、通话录音、通话记录）</li><li>表单工具、营销自动化、工单系统集成</li><li>ERP/财务/进销存对接</li><li>API、Webhook、自定义函数（支持二次开发）</li></ul><hr/><h2>五、主流 CRM 厂商盘点与对比（含 Zoho CRM）📊</h2><p>下面用一个简单表格，把主流 CRM 厂商做一个高层对比（侧重国内常见认知，并适度提及国际）。</p><blockquote>注意：具体功能适配、价格、实施模式等会随着时间调整，这里只做思路级概览。</blockquote><h3>1. 典型 CRM 厂商对比表</h3><table><thead><tr><th><strong>厂商</strong></th><th><strong>定位与特点</strong></th><th><strong>适合企业阶段</strong></th></tr></thead><tbody><tr><td><a href="https://link.segmentfault.com/?enc=oYya5Kz1YWOosWGBSikoLA%3D%3D.%2B4h3%2F9PvVlNHRTViQBkXE%2B%2BtIYROsvInbc14KVbIrQE%3D" rel="nofollow" target="_blank">Zoho CRM</a></td><td>全球化 SaaS CRM，功能全面、性价比高；支持销售+营销+客服一体化，生态产品丰富</td><td>中小企业、成长型企业、出海企业、注重性价比的团队</td></tr><tr><td>Salesforce</td><td>全球 CRM 龙头，平台能力极强，高度可定制，生态庞大，但价格与实施成本较高</td><td>中大型企业、跨国集团、有复杂流程和 IT 团队</td></tr><tr><td>Microsoft Dynamics 365</td><td>与 Office、Teams、Azure 深度集成，适合已大量使用微软生态的企业</td><td>中大型企业，尤其是已有微软体系的客户</td></tr><tr><td>HubSpot CRM</td><td>以入站营销著称，营销+销售+服务一体化，使用体验友好，对内容营销型公司很友好</td><td>中小企业、营销驱动的 SaaS 或服务企业</td></tr><tr><td>国内本土厂商（泛指）</td><td>针对本地业务场景优化，如本地化流程、对接本地 IM/企微/钉钉、电商等</td><td>各阶段企业，看重本地服务与本土生态</td></tr></tbody></table><p>（具体国内厂商如纷享销客、销售易、XTools、神州云动等，这里不逐一展开，可按行业选择落地经验多的厂商。）</p><h2><img width="723" height="548" referrerpolicy="no-referrer" src="/img/bVdniDB" alt="image.png" title="image.png" loading="lazy"/></h2><h3>2. 为什么很多成长型企业会选择 Zoho CRM？</h3><p>站在 Zoho CRM 市场视角，可以客观列一下自身在众多 CRM 里的位置：</p><ul><li><strong>全球化经验</strong>：在 150+ 国家有用户，对出海企业、跨国团队的多语言、多币种、多时区支持比较成熟</li><li><strong>模块覆盖全面</strong>：从线索、客户、商机，到报价、订单、回款，再到客服、项目，多模块打通</li><li><strong>高度可配置</strong>：字段、布局、流程、审批、自动化都可以配置，无需大量代码</li><li><strong>价格相对友好</strong>：相比部分国际巨头，成本压力更小，对中小和成长型企业更友好</li><li><strong>生态丰富</strong>：可与 Zoho 旗下其他产品（如营销自动化、工单、表单、BI 等）打通，形成一体化业务系统</li></ul><p>简而言之：<strong>不是“功能最贵最大”的那一类，而是“够用、好用、可扩展、性价比高”的那一类。</strong></p><hr/><h2>六、企业在选型 CRM 时应关注什么？🧩</h2><p>讲完系统和厂商，落到执行层面，很多企业真正的难点在于：<strong>“我家到底该选哪一个？”</strong><br/><img width="723" height="567" referrerpolicy="no-referrer" src="/img/bVdniC5" alt="image.png" title="image.png" loading="lazy"/><br/>这里给一个简洁的选型 checklist：</p><h3>1. 业务匹配度</h3><ul><li>是否支持你当前的销售模式？（To B / To C / 线下门店 / 渠道分销…）</li><li>是否能支持你“未来两三年”的业务形态？（比如从单一产品到多产品线、从国内到海外）</li></ul><h3>2. 易用性与落地难度</h3><ul><li>前线销售是否愿意用、用得顺手？  <br/>（界面复杂度、移动端体验、操作步骤等）</li><li>是否需要大量定制开发，还是配置就能满足大部分需求？</li></ul><h3>3. 集成能力</h3><ul><li>能否平滑对接现有系统？（财务、ERP、官网、表单、IM 等）</li><li>是否提供标准 API、是否有成熟的对接案例（尤其是你所在行业）</li></ul><h3>4. 成本与 ROI</h3><ul><li><p>不只是“许可证价格”，还包括：</p><ul><li>实施服务费</li><li>培训成本</li><li>内部运营人力投入</li></ul></li><li>是否支持先小规模试点，再逐步扩展？</li></ul><h3>5. 安全与合规</h3><ul><li>数据安全与隐私保护（加密、权限、日志）</li><li>是否符合所在地监管要求（如跨境数据、多地区存储等）</li></ul><hr/><h2>七、写在最后：CRM 不只是一个系统，更是一种运营思维✨</h2><p>很多企业上线 CRM 后有两种截然不同的结局：</p><ul><li>一种是：系统上了，没人用，最后变成“高价买来的高级 Excel”</li><li>另一种是：持续迭代管理流程，CRM 真正成为“企业增长中枢”</li></ul><p>区别往往不在软件本身，而在企业有没有把 CRM 当作一个<strong>持续运营工程</strong>：</p><ul><li>领导层是否重视，用 CRM 来对齐目标和过程？</li><li>销售、营销、客服团队有没有统一共识和规范？</li><li>是否有人负责长期优化字段、流程、自动化规则和报表？</li></ul><p>当你把 CRM 视作企业的“客户关系操作系统”，而不只是一个记录工具，它就会反过来推动组织的进步：</p><ul><li>从以“拍脑袋”决策 → 走向以数据决策</li><li>从“个人英雄主义” → 走向可复制的团队能力</li><li>从“单次成交” → 走向可持续的客户生命周期价值</li></ul><hr/><p>如果你正在考虑为团队搭建或升级 CRM，希望这篇「一文讲清」式的拆解，能帮助你更系统地理解：  <br/><strong>一套好的 CRM，应该长什么样、怎么跑起来、由谁来用好。</strong></p>]]></description></item><item>    <title><![CDATA[JoySSL一年期免费证书申请教程：手把手教你快速部署 追风的苦咖啡 ]]></title>    <link>https://segmentfault.com/a/1190000047459864</link>    <guid>https://segmentfault.com/a/1190000047459864</guid>    <pubDate>2025-12-09 10:08:22</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>JoySSL一年期免费证书申请与部署全攻略</h2><p>在2025年的今天，网络安全的重要性日益凸显。尽管许多云服务商已停止提供一年期的免费SSL证书，但国产自主品牌JoySSL依然为广大用户提供了安全可靠的选择。</p><h3>一、准备工作：注册账号与关键步骤</h3><p><img width="650" height="407" referrerpolicy="no-referrer" src="/img/bVdmdBK" alt="" title=""/></p><p>首先，打开浏览器访问 JoySSL官方网站。点击右上角的“注册”按钮创建新账户。<strong>请注意，这是整个流程中最为关键的一步</strong>：在注册页面的“邀请码”或“注册码”字段中，务必准确填写官方提供的特定代码（如 <code>230959</code>），这是解锁一年期免费证书申请权限的必要条件。完成信息填写后提交注册，并登录到您的新账户。</p><h3>二、选择并申请免费的SSL证书</h3><p>登录成功后，进入SSL证书选购页面。在众多证书类型中，找到标注为“免费一年期”或“政务版/教育版”的证书产品。根据搜索结果显示，JoySSL目前主要向个人站长、教育机构及非营利组织等用户提供此类免费资源。选择适合您网站性质的证书类型后，点击“立即申请”或“0元下单”。虽然系统会引导您走支付流程，但实际上不会产生任何费用，此举仅为形成正式订单。</p><h3>三、填写详细的申请信息</h3><p>接下来进入域名信息填报阶段。您需要精确输入希望保护的主域名（例如 <code>www.yourdomain.com</code>）。随后完善单位或个人资料，包括但不限于联系人姓名、联系电话以及有效的电子邮箱地址。所有带星号(*)的项目均为必填项，且直接影响后续验证环节能否顺利进行，因此请务必保证内容的完整性和准确性。</p><h3>四、验证域名所有权</h3><p>提交申请之后，系统会自动跳转至域名控制权验证界面。JoySSL提供了两种主流的验证方法供用户选用：</p><ul><li><strong>DNS记录解析验证</strong>: 根据后台提示添加一条特定的TXT记录或者CNAME记录到你域名的DNS设置里。完成后返回控制台点击我已操作按钮等待系统检测通过即可签发证书。该方法适用于绝大多数情况并且无需接触服务器文件更加便捷安全。</li><li><strong>服务器文件上传验证</strong>: 下载由系统生成的一个独一无二的文本文件并将其上传至你所管理网站的根目录下然后再通过访问特定路径来证明对该站点的操作权限以此完成校验过程。此方式对于那些熟悉FTP操作的用户来说也是一个可靠的备选方案。</li></ul><p>任选其一完成上述操作后静待片刻通常几分钟内就能收到邮件通知告知你的证书已经成功签发下来了！</p><h3>五、下载与安装SSL证书</h3><p>一旦证书签发成功便可前往JoySSL的用户后台查找对应的订单详情页从中下载包含完整密钥对及证书链压缩包的文件解压后根据自身使用的Web服务器环境挑选合适的配置文件进行安装即可常见的NginxApacheIIS等均有详尽的配置指引可供参考遵循标准化流程导入相应证书重启服务使改动生效最终实现整站HTTPS加密访问的目标达成！</p>]]></description></item><item>    <title><![CDATA[面向学科领域的网络信息资源深度聚合与服务研究_目录（qbit学习记录） qbit ]]></title>    <link>https://segmentfault.com/a/1190000047459873</link>    <guid>https://segmentfault.com/a/1190000047459873</guid>    <pubDate>2025-12-09 10:07:40</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>图书信息</h2><ul><li>《面向学科领域的网络信息资源深度聚合与服务研究》<br/><img width="345" height="441" referrerpolicy="no-referrer" src="/img/bVdniDt" alt="" title=""/></li><li>作者: <code>孙建军 等</code></li><li>出版社: <code>南京大学出版社</code></li><li>ISBN: <code>9787305252778</code></li><li><p>项目背景</p><pre><code>本书是国家社科基金重大项目“面向学科领域的网络信息资源深度聚合与服务研究”的结项成果，
孙建军教授是该项目的首席专家。</code></pre></li><li><p>内容简介</p><pre><code>书稿主要探讨学科发展尤其是人文社会科学研究在大数据时代的发展问题，
认为大数据的运用将进一步推动学术技术分析服务、数据服务的发展，
传统承担文献资料服务和普通信息服务的图书馆、情报服务机构等将向数据委托服务、计算分析服务转型。
随着人文社会科学数据的快速增长以及大数据分析技术的日益完善，
人文社会科学的大数据研究必然会成为人文社会科学的主流领域，
但不会替代现有的人文社会科学研究，而是相互补充，相得益彰。</code></pre></li><li><p>作者简介</p><pre><code>孙建军，博士，南京大学信息管理学院教授，院长。
主要研究领域为：信息经济、信息学教育、信息资源管理与网络计量。
全国核心期刊上发表专业文章120余篇，独著、参著、编、译书20余本。</code></pre></li></ul><h2><a href="https://segmentfault.com/a/1190000047459876" target="_blank">第一部分 概述</a></h2><h3>1 学科资源聚合与网络导航</h3><h2>第二部分 学术网络资源特征及利用</h2><h3>2 学术网络资源特征、分步及模式</h3><h3>3 学术网络资源利用特征——以我国人文社会科学领域为例</h3><h2>第三部分 学科网络资源采集与获取</h2><h3>4 学科网络资源采集与预处理</h3><h3>5 学科网络信息的集成</h3><h2>第四部分 学科网络资源深度标注</h2><h3>6 本体学习和资源深度标准理论基础</h3><h3>7 概念学习</h3><h3>8 关系学习</h3><h3>9 学科资源语义标注</h3><h2>第五部分 学科网络资源聚合</h2><h3>10 学科网络资源的主题聚合</h3><h3>11 学科网络资源的语义聚合</h3><h2>第六部分 学科网络资源导航机制及可视化</h2><h3>12 网络导航建设现状</h3><h3>13 学科网络导航认知行为特征及影响因素</h3><h3>14 学科网络资源导航改进与可视化</h3><blockquote>本文出自 <a href="https://segmentfault.com/blog/qbit" target="_blank">qbit snap</a></blockquote>]]></description></item><item>    <title><![CDATA[面向学科领域的网络信息资源深度聚合与服务研究——Part1（qbit学习记录） qbit ]]></title>    <link>https://segmentfault.com/a/1190000047459876</link>    <guid>https://segmentfault.com/a/1190000047459876</guid>    <pubDate>2025-12-09 10:07:03</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <blockquote>本文出自 <a href="https://segmentfault.com/blog/qbit" target="_blank">qbit snap</a></blockquote>]]></description></item><item>    <title><![CDATA[2026年CRM系统市场全景：5大趋势与7款主流产品深度解析 Python最棒 ]]></title>    <link>https://segmentfault.com/a/1190000047459888</link>    <guid>https://segmentfault.com/a/1190000047459888</guid>    <pubDate>2025-12-09 10:06:30</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>根据当前市场数据和行业预测，2026年CRM系统将呈现 <strong>AI深度整合、行业垂直化和SaaS主导</strong> 三大核心趋势。本文将从市场格局、技术趋势、厂商路线和选型建议四个维度进行解析，帮助企业构建中长期CRM规划。<br/><img width="723" height="579" referrerpolicy="no-referrer" src="/img/bVdniEa" alt="image.png" title="image.png"/></p><h2>一、2026年CRM系统市场格局</h2><p>全球CRM市场预计在2026年将突破 <strong>960亿美元</strong>，年复合增长率（CAGR）约 <strong>10.2%</strong>。  <br/>中国市场则在全球竞争格局下呈现本地化与国际化并行的特点。</p><h3>1. 全球与中国市场体量</h3><ul><li>全球市场规模：<strong>&gt;960亿美元（2026E）</strong></li><li>年复合增长率：<strong>10.2%</strong></li><li>SaaS模式成为主流交付形态，中国市场中本土厂商加速崛起</li></ul><h3>2. 主要厂商市场份额与优势（节选）</h3><p>下面是调整完「全球市场份额」和「中国市场份额」列顺序后的版本（仍然按中国市场份额由高到低排序），你可以直接整体替换原文对应表格👇</p><hr/><h3>2. 主要厂商市场份额与优势（节选）</h3><p>下表为部分典型CRM厂商在全球及中国市场的表现（按中国市场份额排序）：</p><table><thead><tr><th><strong>排名（中国）</strong></th><th><strong>CRM系统</strong></th><th><strong>中国市场份额</strong></th><th><strong>全球市场份额</strong></th><th><strong>核心优势</strong></th></tr></thead><tbody><tr><td>1</td><td><strong>Zoho CRM</strong></td><td><strong>25.18%</strong></td><td>5.3%</td><td>「全球化 + 本地化」策略，针对大中小企业提供差异化版本，覆盖营销、销售、服务全流程</td></tr><tr><td>2</td><td>Microsoft Dynamics 365</td><td>12.5%</td><td>18.2%</td><td>与微软生态（Office、Azure、Teams）深度集成，适合跨国集团及大型组织</td></tr><tr><td>3</td><td>Salesforce</td><td>8.3%</td><td>21.7%</td><td>AI驱动（Einstein AI）、全模块一体化解决方案，生态成熟</td></tr><tr><td>4</td><td>纷享销客</td><td>5.7%</td><td>-</td><td>连接型CRM，强化内外部协同，适配以渠道与终端管理为主的中型企业场景</td></tr></tbody></table><p><img width="723" height="584" referrerpolicy="no-referrer" src="/img/bVdniD4" alt="image.png" title="image.png" loading="lazy"/></p><h2>二、2026年CRM系统五大核心趋势</h2><p>2026年的CRM不再只是“客户信息管理系统”，而是逐步演变为 <strong>“智能增长中枢”</strong>。以下五大趋势将深刻影响产品形态与企业选型。<br/><img width="723" height="562" referrerpolicy="no-referrer" src="/img/bVdniD5" alt="image.png" title="image.png" loading="lazy"/></p><h3>1. AI深度整合 🤖</h3><ul><li><strong>智能决策普及</strong>：  <br/>预计 <strong>70% 以上的CRM系统</strong> 将内置智能决策引擎，用于线索评分、成交预测、客户流失预警等。</li><li><p><strong>典型厂商数据</strong>：</p><ul><li>Salesforce <strong>Einstein AI</strong>：销售预测准确率可达 <strong>82%</strong></li><li>Microsoft Dynamics 365 <strong>AI Agent</strong>：正在向“从线索到回款”的 <strong>全流程自动化</strong> 演进</li></ul></li></ul><h3>2. 行业垂直化加速</h3><ul><li>制造业、金融业、汽车等 <strong>高复杂度行业</strong> 的定制化需求明显上升。</li><li><p>行业案例：</p><ul><li><strong>SAP</strong> 在汽车行业市占率超过 <strong>30%</strong></li><li><strong>Zoho CRM</strong> 在制造行业服务宝马、华为、万达等大型客户，聚焦“营销+销售+服务”一体化场景</li></ul></li></ul><h3>3. SaaS主导市场</h3><ul><li>全球CRM <strong>SaaS渗透率已达 75%</strong></li><li><p>市场规模：</p><ul><li>2025年前后整体市场规模预计突破 <strong>960亿美元</strong></li><li>维持约 <strong>10.2%</strong> 的年复合增长率</li></ul></li><li>企业更倾向于订阅模式与按需扩容，以降低前期IT投入与运维成本。</li></ul><h3>4. 多模态交互成为标配 🎙️</h3><ul><li><p>支持 <strong>语音、视频、IM</strong> 等多通道融合交互：</p><ul><li>语音机器人与智能外呼系统，有效缓解传统电销“封号”“低接通率”等痛点</li><li>可视化、3D化数据分析界面逐步普及，管理层可通过“看图决策”</li></ul></li><li>客户沟通不再局限于电话与邮件，而是全渠道统一管理。</li></ul><h3>5. 数据安全与合规升级</h3><ul><li><strong>区块链</strong>：用于客户数据存证与追踪，保障数据不可篡改</li><li><strong>隐私计算</strong>：实现数据“<strong>可用不可见</strong>”，在不暴露原始数据的前提下进行联合分析</li><li><strong>信创市场</strong>：  <br/>中国信创CRM市场份额预计增长至 <strong>38%</strong>，国产替代与合规要求推动本土厂商快速发展。</li></ul><hr/><h2>三、7款主流CRM系统的2026发展路线</h2><p>以下为全球与中国市场具有代表性的7款CRM系统的产品发展重点梳理。</p><h3>1. Zoho CRM</h3><ul><li><p>持续打磨内置AI助手 <strong>Zia</strong>：</p><ul><li>提供智能推荐、自动记录、邮件建议等功能</li></ul></li><li><p>本地生态集成：</p><ul><li>深化与 <strong>微信、飞书</strong> 等中国本地生态的连接</li></ul></li><li><p>市场策略：</p><ul><li>主攻 <strong>大中企业市场</strong>，强调性价比与轻量部署</li></ul></li></ul><h3>2. Salesforce</h3><ul><li><p>持续强化 <strong>AI能力</strong>，重点聚焦：</p><ul><li>客服云（Service Cloud）</li><li>平台云（Platform Cloud）</li></ul></li><li><p>2025财年AI相关业务增长：</p><ul><li>客服云：<strong>+9%</strong></li><li>平台云：<strong>+19.5%</strong></li></ul></li><li><p>核心方向：</p><ul><li>预测分析（销售预测、流失预测）</li><li>自动化工作流（From Lead to Cash完整链路自动化）</li></ul></li></ul><h3>3. Microsoft Dynamics 365</h3><ul><li><p><strong>AI Agent</strong> 能力升级：</p><ul><li>从销售线索管理、订单创建到报告生成的 <strong>端到端自动化</strong></li></ul></li><li><p>与 <strong>Power Platform</strong> 深度整合：</p><ul><li>Power BI、Power Apps、Power Automate 联动，支持业务自助搭建与可视化分析</li></ul></li><li><p>新兴方向：</p><ul><li>扩展可持续发展模块，如 <strong>碳排放追踪</strong>、ESG数据管理</li></ul></li></ul><h3>4. Oracle CRM</h3><ul><li>战略重心：<strong>AI数据库 + 企业私有数据价值挖掘</strong></li><li><p>推出支持数据向量化的AI数据库：</p><ul><li>有利于在私有数据上构建专属智能助手和推荐引擎</li></ul></li><li><p>定位：</p><ul><li>“<strong>全球最大高价值私有企业数据托管方</strong>”，强化在大型集团与跨国企业的优势</li></ul></li></ul><h3>5. 销氪CRM</h3><ul><li>产品理念：<strong>AI驱动、主动获客</strong></li><li><p>核心能力：</p><ul><li>集成 <strong>3亿+企业线索数据库</strong></li><li>搭配智能外呼系统，解决电销“封号难”“效率低”问题</li></ul></li><li><p>适用场景：</p><ul><li>大规模电话获客、地推团队与电销团队为主的业务模型</li></ul></li></ul><h3>6. 超兔CRM</h3><ul><li><p>功能亮点：</p><ul><li><strong>AI跟单智能体</strong>，销售跟进效率提升可达 <strong>30%</strong></li></ul></li><li><p>技术架构：</p><ul><li>“<strong>一体云架构</strong>”打通CRM与进销存、生产系统，减少信息孤岛</li></ul></li><li><p>行业聚焦：</p><ul><li>专注 <strong>制造业解决方案</strong>，适用于订单复杂、生产周期长的企业</li></ul></li></ul><h3>7. 纷享销客</h3><ul><li><p>架构特点：</p><ul><li><strong>连接型架构</strong>，强化销售、服务、供应链之间的协同</li></ul></li><li><p>数据能力：</p><ul><li>提供 <strong>600+ API接口</strong>，打造企业级数据闭环</li></ul></li><li><p>客户群体：</p><ul><li>主要服务 中小型企业，适合强调“渠道+终端+总部协同”的组织。</li></ul></li></ul><hr/><h2>四、企业选型的4大关键建议</h2><p>在2026年的技术与监管环境下，CRM选型需要同时考虑 <strong>业务复杂度、组织规模、行业属性以及数据安全要求</strong>。<img width="723" height="628" referrerpolicy="no-referrer" src="/img/bVdniD6" alt="image.png" title="image.png" loading="lazy"/></p><h3>1. 按企业类型的选型建议</h3><ul><li><p><strong>跨国企业</strong></p><ul><li>优先考虑：<strong>Zoho CRM、Salesforce、Microsoft Dynamics 365</strong></li><li>理由：全球部署能力强，多语言多地区支持完善，与现有IT生态（Office、ERP等）集成成熟。</li></ul></li><li><p><strong>中国大中型企业</strong></p><ul><li>推荐：<strong>销氪CRM、Zoho CRM</strong></li><li>理由：兼顾本地化服务、国产化与信创要求，支持复杂流程与高度定制。</li></ul></li><li><p><strong>制造业企业</strong></p><ul><li>推荐：<strong>Zoho CRM、超兔CRM</strong></li><li>理由：更适配“订单—生产—交付—售后”的闭环场景，支持BOM、多工厂、多仓库等复杂业务模型。</li></ul></li><li><p><strong>中小企业</strong></p><ul><li>推荐：<strong>Zoho Bigin、HubSpot CRM</strong></li><li>理由：上手快、成本可控，适合以销售线索管理、简单流程自动化为主的团队。</li></ul></li></ul><h3>2. 实施与验证建议</h3><ul><li><p>在正式铺开前，建议进行 <strong>3–6个月的 POC（概念验证）</strong>：</p><ul><li>小范围试点：选取1–2个典型业务部门</li><li><p>验证内容：</p><ul><li>与现有系统（ERP、财务、人力）集成情况</li><li>关键流程（线索→商机→合同→回款）跑通程度</li><li>报表与管理看板是否满足日常运营与管理决策</li></ul></li></ul></li><li><p>特别关注：</p><ul><li><strong>数据安全与合规</strong>（尤其是涉及跨境数据、隐私数据时）</li><li><strong>二次开发与灵活性</strong>（未来业务变更的可适配性）</li><li><strong>使用体验与培训成本</strong>（销售与客服团队能否快速接受）</li></ul></li></ul><hr/><h2>五、结语：从“买CRM”到“设计增长系统”</h2><p>2026年的CRM将更加 <strong>智能化、行业化、平台化</strong>。  <br/>企业不应只从“买一个系统”的视角出发，而要将CRM视作 <strong>增长引擎与数据底座</strong>，围绕自身行业特性、组织结构与合规要求，规划中长期的系统与数据架构。</p><p>在明确业务目标和关键指标（如线索转化率、复购率、客单价、客户生命周期价值）的前提下，再依据本文的市场格局、趋势和产品路线进行选型，将明显降低试错成本，并提升数字化投入的ROI。</p>]]></description></item><item>    <title><![CDATA[面向学科领域的网络信息资源深度聚合与服务研究——Part2（qbit学习记录） qbit ]]></title>    <link>https://segmentfault.com/a/1190000047459903</link>    <guid>https://segmentfault.com/a/1190000047459903</guid>    <pubDate>2025-12-09 10:05:47</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>图书信息</h2><ul><li>《面向学科领域的网络信息资源深度聚合与服务研究》</li><li><p>项目背景</p><pre><code>本书是国家社科基金重大项目“面向学科领域的网络信息资源深度聚合与服务研究”的结项成果，
孙建军教授是该项目的首席专家。</code></pre></li><li>回<a href="https://segmentfault.com/a/1190000047459873" target="_blank">目录</a></li></ul><h2>第一部分 概述</h2><h3>1 学科资源聚合与网络导航</h3><h2>第二部分 学术网络资源特征及利用</h2><h3>2 学术网络资源特征、分步及模式</h3><h3>3 学术网络资源利用特征——以我国人文社会科学领域为例</h3><h2>第三部分 学科网络资源采集与获取</h2><h3>4 学科网络资源采集与预处理</h3><h3>5 学科网络信息的集成</h3><h2>第四部分 学科网络资源深度标注</h2><h3>6 本体学习和资源深度标准理论基础</h3><h3>7 概念学习</h3><h3>8 关系学习</h3><h3>9 学科资源语义标注</h3><h2>第五部分 学科网络资源聚合</h2><h3>10 学科网络资源的主题聚合</h3><h3>11 学科网络资源的语义聚合</h3><h2>第六部分 学科网络资源导航机制及可视化</h2><h3>12 网络导航建设现状</h3><h3>13 学科网络导航认知行为特征及影响因素</h3><h3>14 学科网络资源导航改进与可视化</h3><blockquote>本文出自 <a href="https://segmentfault.com/blog/qbit" target="_blank">qbit snap</a></blockquote>]]></description></item><item>    <title><![CDATA[面向学科领域的网络信息资源深度聚合与服务研究——Part3（qbit学习记录） qbit ]]></title>    <link>https://segmentfault.com/a/1190000047459910</link>    <guid>https://segmentfault.com/a/1190000047459910</guid>    <pubDate>2025-12-09 10:04:54</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>图书信息</h2><ul><li>《面向学科领域的网络信息资源深度聚合与服务研究》</li><li><p>项目背景</p><pre><code>本书是国家社科基金重大项目“面向学科领域的网络信息资源深度聚合与服务研究”的结项成果，
孙建军教授是该项目的首席专家。</code></pre></li><li>回<a href="https://segmentfault.com/a/1190000047459873" target="_blank">目录</a></li></ul><h2>第一部分 概述</h2><h3>1 学科资源聚合与网络导航</h3><h2>第二部分 学术网络资源特征及利用</h2><h3>2 学术网络资源特征、分步及模式</h3><h3>3 学术网络资源利用特征——以我国人文社会科学领域为例</h3><h2>第三部分 学科网络资源采集与获取</h2><h3>4 学科网络资源采集与预处理</h3><h3>5 学科网络信息的集成</h3><h2>第四部分 学科网络资源深度标注</h2><h3>6 本体学习和资源深度标准理论基础</h3><h3>7 概念学习</h3><h3>8 关系学习</h3><h3>9 学科资源语义标注</h3><h2>第五部分 学科网络资源聚合</h2><h3>10 学科网络资源的主题聚合</h3><h3>11 学科网络资源的语义聚合</h3><h2>第六部分 学科网络资源导航机制及可视化</h2><h3>12 网络导航建设现状</h3><h3>13 学科网络导航认知行为特征及影响因素</h3><h3>14 学科网络资源导航改进与可视化</h3><blockquote>本文出自 <a href="https://segmentfault.com/blog/qbit" target="_blank">qbit snap</a></blockquote>]]></description></item><item>    <title><![CDATA[面向学科领域的网络信息资源深度聚合与服务研究——Part4（qbit学习记录） qbit ]]></title>    <link>https://segmentfault.com/a/1190000047459915</link>    <guid>https://segmentfault.com/a/1190000047459915</guid>    <pubDate>2025-12-09 10:04:04</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>图书信息</h2><ul><li>《面向学科领域的网络信息资源深度聚合与服务研究》</li><li><p>项目背景</p><pre><code>本书是国家社科基金重大项目“面向学科领域的网络信息资源深度聚合与服务研究”的结项成果，
孙建军教授是该项目的首席专家。</code></pre></li><li>回<a href="https://segmentfault.com/a/1190000047459873" target="_blank">目录</a></li></ul><h2>第一部分 概述</h2><h3>1 学科资源聚合与网络导航</h3><h2>第二部分 学术网络资源特征及利用</h2><h3>2 学术网络资源特征、分步及模式</h3><h3>3 学术网络资源利用特征——以我国人文社会科学领域为例</h3><h2>第三部分 学科网络资源采集与获取</h2><h3>4 学科网络资源采集与预处理</h3><h3>5 学科网络信息的集成</h3><h2>第四部分 学科网络资源深度标注</h2><h3>6 本体学习和资源深度标准理论基础</h3><h3>7 概念学习</h3><h3>8 关系学习</h3><h3>9 学科资源语义标注</h3><h2>第五部分 学科网络资源聚合</h2><h3>10 学科网络资源的主题聚合</h3><h3>11 学科网络资源的语义聚合</h3><h2>第六部分 学科网络资源导航机制及可视化</h2><h3>12 网络导航建设现状</h3><h3>13 学科网络导航认知行为特征及影响因素</h3><h3>14 学科网络资源导航改进与可视化</h3><blockquote>本文出自 <a href="https://segmentfault.com/blog/qbit" target="_blank">qbit snap</a></blockquote>]]></description></item><item>    <title><![CDATA[面向学科领域的网络信息资源深度聚合与服务研究——Part5（qbit学习记录） qbit ]]></title>    <link>https://segmentfault.com/a/1190000047459924</link>    <guid>https://segmentfault.com/a/1190000047459924</guid>    <pubDate>2025-12-09 10:03:22</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>图书信息</h2><ul><li>《面向学科领域的网络信息资源深度聚合与服务研究》</li><li><p>项目背景</p><pre><code>本书是国家社科基金重大项目“面向学科领域的网络信息资源深度聚合与服务研究”的结项成果，
孙建军教授是该项目的首席专家。</code></pre></li><li>回<a href="https://segmentfault.com/a/1190000047459873" target="_blank">目录</a></li></ul><h2>第一部分 概述</h2><h3>1 学科资源聚合与网络导航</h3><h2>第二部分 学术网络资源特征及利用</h2><h3>2 学术网络资源特征、分步及模式</h3><h3>3 学术网络资源利用特征——以我国人文社会科学领域为例</h3><h2>第三部分 学科网络资源采集与获取</h2><h3>4 学科网络资源采集与预处理</h3><h3>5 学科网络信息的集成</h3><h2>第四部分 学科网络资源深度标注</h2><h3>6 本体学习和资源深度标准理论基础</h3><h3>7 概念学习</h3><h3>8 关系学习</h3><h3>9 学科资源语义标注</h3><h2>第五部分 学科网络资源聚合</h2><h3>10 学科网络资源的主题聚合</h3><h3>11 学科网络资源的语义聚合</h3><h2>第六部分 学科网络资源导航机制及可视化</h2><h3>12 网络导航建设现状</h3><h3>13 学科网络导航认知行为特征及影响因素</h3><h3>14 学科网络资源导航改进与可视化</h3><blockquote>本文出自 <a href="https://segmentfault.com/blog/qbit" target="_blank">qbit snap</a></blockquote>]]></description></item><item>    <title><![CDATA[KaiwuDB 跨模查询百倍性能提升背后的技术密码 KaiwuDB ]]></title>    <link>https://segmentfault.com/a/1190000047459928</link>    <guid>https://segmentfault.com/a/1190000047459928</guid>    <pubDate>2025-12-09 10:02:49</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在 AIoT、工业互联网场景中，类似"设备元数据（关系数据）+ 传感器数据（时序数据）"这样的联合查询是业务的重要需求之一。然而，在传统多库架构下，这类跨模查询往往意味着 "数据迁移 + 小时级等待"。KaiwuDB 创新自研的跨模优化技术，可将原本可能需要 5 小时的查询任务压缩至 64 秒，场景性能甚至能实现百倍的飞跃。今天就带大家一同探秘，深度拆解 KaiwuDB 跨模查询性能飞跃的核心技术。</p><h2><strong>先看结果------跨模查询的性能起飞</strong></h2><p>我们以能源管道网络物联网场景为测试基准，针对 3 个典型应用跨模优化的查询场景开展对比测试，具体结果如下：</p><p><img width="723" height="325" referrerpolicy="no-referrer" src="/img/bVdniEJ" alt="" title=""/></p><h3><strong>测试场景基础信息</strong></h3><p>本次测试涉及的数据源包括关系型数据库和时序数据库，具体表结构与数据量如下：</p><p><img width="723" height="810" referrerpolicy="no-referrer" src="/img/bVdniEL" alt="" title="" loading="lazy"/></p><h3><strong>测试查询场景 SQL 语句</strong></h3><pre><code class="SQL">Q2：
SELECT si.workarea_name,
       si.site_name,
       t.measure_type,
       time_bucket(t.k_collect_time, '10s') as timebucket,
       AVG(t.monitor_value) AS avg_value,
       MAX(t.monitor_value) AS max_value,
       MIN(t.monitor_value) AS min_value,
       COUNT(t.monitor_value) AS number_of_values
FROM monitor_r.site_info si,                              
     monitor_r.region_info wi,                                
     monitor_r.pipeline_info li,                                    
     monitor_r.point_base_info pi,                                      
     db_monitor.t_monitor_point t                                             
WHERE li.pipeline_id = pi.pipeline_id               
  AND pi.site_id = si.site_id                      
  AND si.region_id = wi.region_id          
  AND t.point_id = pi.point_id                            
  AND li.pipeline_name = 'pipeline_1'                  
  AND wi.region_name in ('work_area_1', 'work_area_2', 'work_area_3')  
  AND t.k_collect_time &gt;= '2023-08-01 01:00:00'     
GROUP BY si.workarea_name,
         si.site_name,
         t.measure_type,
         timebucket;
         
Q3：
SELECT si.site_name,
       COUNT(DISTINCT point_id) AS abnormal_point_count
FROM
     db_monitor.t_monitor_point t,
     monitor_r.pipeline_info li,                               
     monitor_r.site_info si                     
WHERE li.pipeline_id = t.pipeline_id                 
    AND t.site_id = si.site_id                      
    AND li.pipeline_name = 'pipeline_1'                
    AND t.monitor_type = 4                                   
    AND t.k_collect_time &gt;= '2023-08-01 00:00:00'
    AND t.k_collect_time &lt;= '2024-08-01 01:00:00'   
    AND t.monitor_value &lt; 0.5 * (
        SELECT AVG(t1.monitor_value) 
        FROM db_monitor.t_monitor_point t1                            
        WHERE t1.pipeline_id = li.pipeline_id        
          AND t1.monitor_type = 4)                           
GROUP BY
    si.site_name
ORDER BY
    abnormal_point_count DESC;
    
Q8：
SELECT ci1.sub_company_name,
       wi1.region_name,
       si1.site_name,
       t1.measure_type,
       time_bucket(t1.k_collect_time, '10s') as timebucket,
       AVG(t1.monitor_value) AS avg_value,
       MAX(t1.monitor_value) AS max_value,
       MIN(t1.monitor_value) AS min_value,
       COUNT(t1.monitor_value) AS number_of_values
FROM monitor_r.site_info si1,          
     monitor_r.site_info si2,                 
     monitor_r.region_info wi1,            
     monitor_r.region_info wi2,           
     monitor_r.company_info ci1,              
     monitor_r.company_info ci2,              
     monitor_r.pipeline_info li1,                
     monitor_r.pipeline_info li2,                
     monitor_r.point_base_info pi1,                   
     monitor_r.point_base_info pi2,                     
     db_monitor.t_monitor_point t1,                        
     db_monitor.t_monitor_point t2                         
WHERE li1.pipeline_id = pi1.pipeline_id                     
  AND pi1.site_id = si1.site_id                         
  AND si1.branch_id = ci1.branch_id  
  AND si1.region_id = wi1.region_id             
  AND t1.point_id = pi1.point_id                                  
  AND li1.pipeline_name = 'pipeline_1'                         
  AND wi1.region_name in ('work_area_1', 'work_area_2', 'work_area_3')  
  AND ci1.sub_company_name = 'sub_com_1'          
  AND li2.pipeline_id = pi2.pipeline_id                       
  AND pi2.site_id = si2.site_id                         
  AND si2.branch_id = ci2.branch_id  
  AND si2.region_id = wi2.region_id             
  AND t2.point_id = pi2.point_id                                
  AND li1.pipe_start_point = li2.pipe_start_point                           
  AND pi1.signal_type = pi2.signal_type                      
  AND pi1.signal_id = pi2.signal_id                    
  AND li2.pipeline_name = 'pipeline_4'                        
  AND wi2.region_name in ('work_area_7', 'work_area_8', 'work_area_9')  
  AND ci2.sub_company_name = 'sub_com_2'          
  AND t1.k_collect_time &gt;= '2023-08-01 01:00:00'      
  AND t1.k_collect_time = t2.k_collect_time                    
  AND t1.monitor_type = t2.monitor_type                 
  AND t1.monitor_value &gt; t2.monitor_value            
GROUP BY ci1.sub_company_name,
         wi1.region_name,
         si1.site_name,
         t1.measure_type,
         timebucket;</code></pre><h2><strong>"原生多模" 的独有优势</strong></h2><p>百倍级别的性能提升，绝非 "简单调优" 能实现 。其背后的密码是------KaiwuDB 通过<strong>跨模统计信息融合、跨模聚合下推、高速跨模连接算子</strong>这三项优化技术，把 "关系数据 + 时序数据" 的联合查询时间极致缩短。</p><p>目前一些支持 "多模" 的数据库选择的方案，是在关系库上套一个时序插件。这类方案的跨模查询，本质还是 "在关系库中模拟时序计算"，因此性能依然受限。而 KaiwuDB 凭借"原生双引擎 + 算子下推"的跨模性能优势，<strong>从架构层面实现了 "多模数据的存储协同 + 计算协同"</strong>：</p><p><strong>• 存储协同</strong>：时序/关系数据同节点、同实例存储；</p><p><strong>• 计算协同</strong>：算子下推到对应引擎，避免跨库/跨节点的数据移动。</p><h2><strong>KaiwuDB 多模的基础框架</strong></h2><p><img width="723" height="810" referrerpolicy="no-referrer" src="/img/bVdniEL" alt="" title="" loading="lazy"/></p><p>KaiwuDB 的<strong>多模框架是面向 AIoT 场景设计的 "统一 SQL 执行层 + 异构引擎融合 + 分布式协同" 架构</strong>，核心是在一个数据库实例内同时支持时序、关系等多类型数据的统一存储、计算与管理，避免"专库专用" 的复杂度。</p><h4>📌 统一的 SQL 执行层</h4><p>通过 KaiwuDB 客户端接收请求，对外提供标准 SQL 接口（兼容 PostgreSQL 语法），屏蔽多模数据的差异。</p><p>多模 SQL 处理：</p><p><strong>• 解析器</strong>：将 SQL 解析为抽象语法树，识别数据类型（时序 / 关系）；</p><p><strong>• 优化器</strong>：根据数据类型选择引擎（时序引擎 / 关系引擎），并将算子拆分为 "时序算子 + 关系算子"；</p><p><strong>• 执行计划生成与分片</strong>：按节点 / 数据类型生成分布式执行计划，通过 RPC 将子计划分发到对应节点。</p><h4>📌 分布式协同层（RPC stream）</h4><p>• 采用 RPC 作为统一通信协议，实现节点间（如 Node1 与 Node2/Node3）的执行计划分发、数据传输；</p><p>• 每个节点同时具备 RPCClient 和 RPCServer 能力，支持无中心对等通信，保证分布式场景下的多模计算协同。</p><h4>📌 多模存储引擎层（Storage Engine）</h4><p>在每个节点的 Storage Engine 中，集成两种核心引擎，实现多模数据的本地处理。</p><p><strong>• TS Executor + TS Store（时序数据存储引擎）</strong>：负责时序数据的存储与计算；对应架构图中的 "ts local run"，处理本地时序数据的写入/查询。</p><p><strong>• KV Store（关系数据存储引擎）</strong>：基于 MVCC 实现关系型数据的事务处理，采用 B + 树索引保证低延迟点查；处理关系型数据的增删改查，与时序引擎共享存储资源。</p><h2><strong>两大关键多模能力</strong></h2><h4><strong>✅ 多模数据统一管理</strong></h4><p><strong>• 统一存储</strong>：时序数据（如传感器数据）和关系数据（如设备元数据）存储在同一实例中，通过元数据服务区分数据类型；</p><p><strong>• 跨模计算</strong>：支持时序数据与关系数据的联合查询。如：按设备 ID（关系数据）查询某时段的传感器数据（时序数据），无需数据迁移。</p><h4><strong>✅ 自适应引擎协同</strong></h4><p><strong>• 引擎自动选择</strong>：SQL 优化器根据数据类型自动路由到对应引擎（时序数据→TS Store，关系数据→KV Store）；</p><p><strong>• 算子下推</strong>：将计算推近数据（即就地计算），如时序聚合算子直接下推到 TS Store 执行，避免全量数据传输；</p><p><strong>• 跨节点协同</strong>：通过 RPC 将多模算子分发到不同节点的引擎中执行，再汇总结果返回客户端。</p><h2><strong>跨模查询优化技术</strong></h2><p>为了提升跨模查询的性能，KaiwuDB 提出并应用了三种跨模查询优化技术：</p><p><img width="723" height="629" referrerpolicy="no-referrer" src="/img/bVdniER" alt="" title="" loading="lazy"/></p><h3><strong>1、 跨模统计信息和代价估算融合：让优化器"读懂"时序数据</strong></h3><p>传统优化器对时序数据的认知存在盲区，既不了解其"按时间有序存储"的特性，也无法精准掌握数据分布情况，导致生成低效执行计划。KaiwuDB 通过给优化器补充时序专属统计信息，实现了代价估算的精准化。</p><h4><strong>🛠️ 技术原理</strong></h4><p><strong>• 时序统计信息 "模式化"</strong>：给时序数据定义专属统计项（比如 "标签条数"、"某设备的聚合统计信息"、"某设备的时序数据条数"），并和关系数据的统计信息存在同一个元数据系统里；</p><p><strong>• 定制化统计规则</strong>：针对时序数据 "写密集、按时间有序" 的特点，创新统计项（比如 "聚合值预计算结果"）；</p><p><strong>• 自适应采集策略</strong>：即可手动收集时序数据统计信息，也可定时收集时序数据统计信息，tag 表会全量统计，metric 表粗量统计(精确统计表行数、预估列不同值与 null 值)，既保证精度又不占资源；</p><p><strong>• 代价估算融合</strong>：优化器同时参考关系数据和时序数据的统计信息，根据代价估算选择最优的连接顺序以及自动选择 "算子下推/高速连接" 等最优策略。</p><h4><strong>🎯 实战效果（Q1 场景）</strong></h4><blockquote>统计"pipeline_1"管道下，2023-2024 年间测量值低于同管道均值 50% 的异常监测点数量（按站点分组排序）</blockquote><p><strong>无优化流程</strong></p><p>因为不知道某型号设备的时序数据占比，与时序表的连接顺序不是最佳的，会先全量扫描时序表，再和关系表的型号做连接，产生大量的中间数据，导致计算慢，耗时 &gt; 5 小时；</p><p><strong>使用优化流程</strong></p><p>通过时序统计信息知道该型号设备的时序数据远多于关系表，会先让关系表进行连接后再与时序表进行连接，这样的话就减少了大量的中间结果，最终耗时 64 秒，<strong>性能提升 279.1 倍</strong>。</p><h3><strong>2、 跨模聚合下推技术：让计算"贴着"数据跑</strong></h3><p>跨模查询的核心痛点之一是数据在引擎间的无效传输，KaiwuDB 的解决方案是"将计算逻辑推至数据所在引擎，就地计算后再汇总"，从源头减少数据移动。</p><h4><strong>🛠️ 技术原理</strong></h4><p>KaiwuDB 的 SQL 引擎会做 "自底向上的下推判断" 机制：</p><p><strong>• 下推白名单</strong>：提前定义时序引擎支持的算子以及操作（比如 TS Store 支持时序聚合等）。</p><p><strong>• 场景化下推优化</strong>：</p><p>① 时间条件下推到时序表的时间索引，避免全表扫描；</p><p>② 聚合计算下推到时序表扫描阶段，减少中间数据；</p><p>③ 排序/窗口/limit 等算子，结合时序数据的有序性，直接下推到引擎层消除冗余计算。</p><h4><strong>🎯 实战效果（Q2 场景）</strong></h4><blockquote>"统计 2023-08-01 01:00 后，pipeline_1 管道下 work_area_1/work_area_2/work_area_3 作业区所有站点的时序数据：按作业区、站点、测量类型分组，以 10 秒为时间桶，计算每个时间桶内测量值的平均值、最大值、最小值及数据条数"</blockquote><p><strong>无优化流程</strong></p><p>① <strong>时序库全量扫描</strong>：从时序表 db_monitor.t_monitor_point 中读取 2023-08-01 01:00 后的所有数据（无前置过滤，仅按时间范围拉取）；</p><p>② <strong>全量数据传输</strong>：将海量原始时序数据从时序引擎传输到关系引擎（monitor_r 库），涉及大量网络 IO 和数据序列化/反序列化；</p><p>③ <strong>关系引擎多表关联</strong>：在关系引擎中依次关联关系表 ，筛选出 pipeline_1 管道 + 指定作业区的数据；</p><p>④<strong>关系引擎计算聚合</strong>：按作业区、站点、测量类型、10 秒时间桶分组，逐一计算平均值、最大值、最小值、数据条数，无预聚合优化。</p><p>无优化流程最终耗时 356,834 ms。</p><p><strong>使用优化流程</strong></p><p>时序引擎前置过滤 + 预聚合：</p><p>① <strong>将核心条件下推</strong>：把过滤条件"li.pipeline_name = 'pipeline_1' AND wi.region_name in ('work_area_1', 'work_area_2', 'work_area_3') AND t.k_collect_time &gt;= '2023-08-01 01:00:00'" 下推到时序引擎，先筛选出仅符合条件的测点数据；</p><p>② <strong>时序引擎就地聚合</strong>：利用时序表按 k_collect_time 有序存储的特性（时间索引），直接在时序引擎内按 10 秒时间桶、测点 sn 分组，提前计算每个时间桶的平均值、最大值、最小值、数据条数（避免原始数据传输）。</p><p>使用优化流程最终耗时 2,351 ms，<strong>性能提升 151 倍</strong>。</p><h3><strong>3、 高速跨模连接算子技术：用"数据裁剪"换"传输效率"</strong></h3><p>跨模连接的核心成本是 "数据在关系时序引擎间的传输量"------KaiwuDB 的高速连接算子，通过先计算数据量较少的关系数据，再将关系数据传输到数据量巨大的时序引擎中进行计算达到过滤数据量的目的，最终可以把需要传输的数据大量裁剪掉，以此提升效率。</p><h4><strong>🛠️ 技术原理</strong></h4><p><strong>• 自适应连接模式</strong>：通过优化器根据融合的统计信息和代价估算，自动选择是否使用高速连接算子以及连接顺序；</p><p><strong>• 先关系后时序</strong>：通常时序的数据是巨大的，先将关系数据在关系引擎进行计算，然后将结果数据传输到时序引擎中与时序数据进行连接再聚合；</p><p><strong>• 设备级并发</strong>：按设备维度拆分计算任务，多设备的连接/聚合并行执行。</p><h4><strong>🎯 实战效果（Q3 场景）</strong></h4><blockquote>在指定工作区、同一时间戳下的监测数据差异，按 10 秒窗口聚合统计</blockquote><p><strong>无优化流程</strong></p><p>① 两台设备的全量时序数据（如 4500 万条）传到关系库；</p><p>② 与 10 张关系数据做 join 连接；</p><p>③ 最后再做聚合。</p><p>无优化流程最终耗时耗时 1,606,706 ms。</p><p><strong>使用优化流程</strong></p><p>① 先通过跨模统计信息和代价估算，选择最优的连接顺序，将两张时序表放到最后再与关系表，同时选择高速连接算子；</p><p>② 在关系引擎先将 10 张关系表的数据进行计算；</p><p>③ 少量的结果数据传输到时序引擎进行连接再聚合（并发计算），大大减少了时序引擎向关系引擎传输的数据量。</p><p>使用优化流程最终耗时 7,398 ms，<strong>性能提升 216.2 倍</strong>。</p><h2><strong>性能提升的本质 ------让数据"少奔波"</strong></h2><p>从统计信息融合让优化器"选对路"，到聚合下推让计算"贴着数据跑"，再到高速连接算子"削减传输量"， KaiwuDB 三项跨模优化技术的核心逻辑始终一致------<strong>让计算尽可能靠近数据，将"跨库跨引擎的数据传输"转化为"引擎内的就地计算"</strong>。当数据不再需要跨引擎、跨节点"奔波"，自然能够实现从"查得出"到"查得快"的飞跃。</p>]]></description></item><item>    <title><![CDATA[专利战敲响警钟！数字孪生成规避研发风险的“创新试验场” 张老师讲数字孪生 ]]></title>    <link>https://segmentfault.com/a/1190000047458615</link>    <guid>https://segmentfault.com/a/1190000047458615</guid>    <pubDate>2025-12-09 10:02:13</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>2025年10月底，国内激光雷达行业爆发了一场引人瞩目的专利纠纷。头部企业禾赛科技正式起诉同行图达通，指控其新发布的“灵雀E1X”产品涉嫌侵犯多项专利。此案的一个焦点在于，图达通长期以来坚持1550纳米波长技术路线，但其新品却转向了禾赛占据优势的905纳米路线，且产品在接口设计、内部光路结构上存在高度相似性。</p><p>这场发生在图达通冲刺港股上市关键节点的诉讼，不仅关乎企业竞争，更尖锐地揭示了一个行业通病：在面临技术路线转型或市场竞争压力时，企业容易陷入模仿与创新的灰色地带，甚至遭遇核心技术的“卡脖子”风险。这场纠纷为所有高技术赛道敲响了警钟——自主创新与知识产权布局，已从发展问题演变为生存问题。<br/><img width="710" height="822" referrerpolicy="no-referrer" src="/img/bVdnijs" alt="" title=""/></p><p>那么，是否存在一种方法，能够在产品开发的早期阶段，就在虚拟世界中充分验证和迭代创新设计，从而规避后期的专利风险与试错成本？数字孪生技术正为此提供一种前瞻性的解决方案。它通过创建物理实体的高保真虚拟映射，构建了一个安全、高效的“创新试验场”。</p><p>数字孪生规避技术风险、加速正向研发，主要依托于三大技术原理实现：</p><ol><li>多源传感融合与高精度实时建模<br/> 构建与物理世界一致的数字孪生体，首要任务是高精度、高效率地获取三维空间信息。激光雷达（LiDAR）因其能直接获取海量的三维点云数据，成为核心传感器之一。</li></ol><p>一项基于激光雷达与图像融合的数字孪生实时建模方法，系统性地解决了此问题。其技术流程始于同步采集激光雷达点云、相机图像及惯性测量单元（IMU）数据。对点云数据进行降噪与分割，对图像进行去畸变与特征提取后，通过算法将两者融合配准。</p><p>这一过程可简化为一个数据关联优化问题：寻找最优的空间变换矩阵 T（包含旋转R和平移t），使得来自不同传感器的数据特征在统一坐标系下的误差最小。<br/>常用的配准算法如迭代最近点（ICP），其目标函数为：<br/><img width="308" height="84" referrerpolicy="no-referrer" src="/img/bVdnijz" alt="" title="" loading="lazy"/></p><p>其中，( p_i ) 和 ( q_i ) 分别是源点云和目标点云中的对应点。通过求解使 ( E ) 最小的 ( R ) 和 ( t )，实现精准对齐。融合后的数据通过即时定位与地图构建（SLAM）技术，能实时构建并动态更新三维环境模型，为后续仿真奠定几何与物理基础。<br/><img width="723" height="303" referrerpolicy="no-referrer" src="/img/bVdnijA" alt="" title="" loading="lazy"/></p><ol start="2"><li>云端智能处理与自适应数据净化<br/>激光雷达产生的点云数据量巨大，且包含大量背景噪声（如空气中的尘埃、雨雾反射），直接处理对算力要求极高。为了在保证精度的同时实现实时性，云边端协同的智能处理架构至关重要。在这一架构中，边缘计算节点负责第一轮数据预处理，执行如基于距离和密度自适应滤波（DDAF）的算法。</li></ol><p>该算法能根据点云中每个点与周围点的距离和分布密度，动态调整滤波阈值，有效剥离无关的背景噪声点，其核心思想可表述为对每个点 ( P_i ) 计算其局部密度 ( \rho_i ) 和最小距离 ( \delta_i )，并设定自适应阈值进行筛选。净化后的轻量化数据被上传至云端，利用更强大的深度学习模型进行进一步的特征提取、对象识别与场景语义分割，从而实现从原始数据到结构化知识的智能增强。<br/><img width="723" height="481" referrerpolicy="no-referrer" src="/img/bVdnijC" alt="" title="" loading="lazy"/></p><ol start="3"><li>高保真传感器仿真与虚拟验证<br/> 这是数字孪生赋能研发、规避专利风险最直接的环节。在构建好的高精度三维场景中，可以植入完全参数化的虚拟传感器模型进行仿真测试。例如，一个真实的激光雷达模型不仅会仿真其扫描方式（如旋转式或闪光式）、波长（905纳米或1550纳米），还能精确模拟激光在虚拟材料表面的反射特性、在不同天气条件（雨、雾）下的衰减模型，甚至多径传播效应。开发者可以在数字孪生环境中，自由地调整虚拟激光雷达的光路设计、扫描模式和信号处理算法，并对不同设计方案进行海量的、零物理成本的测试与对比。<br/><img width="723" height="410" referrerpolicy="no-referrer" src="/img/bVdm9co" alt="" title="" loading="lazy"/></li></ol><p>所有创新的技术细节，在投入昂贵的物理原型制造和专利申请之前，其性能与独特性已在虚拟世界中得到充分验证和优化。通过上述技术路径，数字孪生将产品研发的核心创新环节，前置并迁移到了虚拟空间。这实质上是将传统的“物理试错-迭代”模式，转变为“虚拟仿真-优化-验证”的新范式。企业可以在数字世界中穷尽各种设计思路，确保最终落地的物理方案不仅是创新的，而且是经过充分验证、知识产权清晰的最优解。<br/><img width="723" height="410" referrerpolicy="no-referrer" src="/img/bVdm9co" alt="" title="" loading="lazy"/></p><p>在这一领域，国内凡拓数创已展开实践。其自主研发的FTE数字孪生引擎，致力于为智慧城市、智能制造等领域提供高精度、可交互的数字孪生底座。该引擎通过了国产化信创适配认证，能够融合多源数据构建三维场景。例如，在智慧水务等项目中，通过构建覆盖全过程的数字孪生感知体系，实现对复杂系统的仿真、分析与优化。这种能力为工业装备、自动驾驶等领域的研发提供了一个可控、可溯的虚拟验证环境，辅助企业在数字空间先行探索技术边界，从源头上筑牢自主创新的防火墙。<br/><img width="723" height="332" referrerpolicy="no-referrer" src="/img/bVdnijF" alt="" title="" loading="lazy"/></p><p>归根结底，禾赛与图达通的诉讼是行业成熟化进程中一次不可避免的阵痛。它警示我们，真正的技术安全与产业主导权，不仅来自于对既有专利的尊重，更源于开辟新路径的能力。数字孪生，作为连接虚拟与现实的桥梁，正将这种“从零到一”的创造性过程，变得前所未有的高效与清晰。它或许不能直接平息专利战场上的硝烟，但却能为下一轮真正意义上的技术跃迁，准备好最先进的“创新工场”。</p>]]></description></item><item>    <title><![CDATA[面向学科领域的网络信息资源深度聚合与服务研究——Part6（qbit学习记录） qbit ]]></title>    <link>https://segmentfault.com/a/1190000047459932</link>    <guid>https://segmentfault.com/a/1190000047459932</guid>    <pubDate>2025-12-09 10:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>图书信息</h2><ul><li>《面向学科领域的网络信息资源深度聚合与服务研究》</li><li><p>项目背景</p><pre><code>本书是国家社科基金重大项目“面向学科领域的网络信息资源深度聚合与服务研究”的结项成果，
孙建军教授是该项目的首席专家。</code></pre></li><li>回<a href="https://segmentfault.com/a/1190000047459873" target="_blank">目录</a></li></ul><h2>第一部分 概述</h2><h3>1 学科资源聚合与网络导航</h3><h2>第二部分 学术网络资源特征及利用</h2><h3>2 学术网络资源特征、分步及模式</h3><h3>3 学术网络资源利用特征——以我国人文社会科学领域为例</h3><h2>第三部分 学科网络资源采集与获取</h2><h3>4 学科网络资源采集与预处理</h3><h3>5 学科网络信息的集成</h3><h2>第四部分 学科网络资源深度标注</h2><h3>6 本体学习和资源深度标准理论基础</h3><h3>7 概念学习</h3><h3>8 关系学习</h3><h3>9 学科资源语义标注</h3><h2>第五部分 学科网络资源聚合</h2><h3>10 学科网络资源的主题聚合</h3><h3>11 学科网络资源的语义聚合</h3><h2>第六部分 学科网络资源导航机制及可视化</h2><h3>12 网络导航建设现状</h3><h3>13 学科网络导航认知行为特征及影响因素</h3><h3>14 学科网络资源导航改进与可视化</h3><blockquote>本文出自 <a href="https://segmentfault.com/blog/qbit" target="_blank">qbit snap</a></blockquote>]]></description></item><item>    <title><![CDATA[剑指offer-47、求1+2+3...+n SevenCoding ]]></title>    <link>https://segmentfault.com/a/1190000047455319</link>    <guid>https://segmentfault.com/a/1190000047455319</guid>    <pubDate>2025-12-09 09:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>题⽬描述</h2><p>求 1+2+3+...+n ，要求不能使⽤乘除法、 for 、 while 、 if 、 else 、 switch 、 case 等关键字及条件判断语句（ A?B:C ）。</p><p>示例<br/>输⼊：5<br/>输出：15</p><h2>思路及解答</h2><h3>用for循环</h3><p>这个问题，如果直接使⽤ for 循环，超级简单，重拳出击，时间复杂度为 O(n) 。代码如下：</p><pre><code class="java">public class Solution {
    public int Sum_Solution(int n) {
        int sum = 0;
        for (int i = 1; i &lt;= n; i++) {
            sum += i;
        }
        return sum;
    }
}</code></pre><p>可是上⾯的明显违反了使⽤for 循环的原则</p><h3>乘除法</h3><p>试试公式法， 1+2+3+...+(n-1)+n = n * (n+1)/2 ,</p><pre><code class="java">public class Solution {
    public int Sum_Solution(int n) {
        if (n &gt;= 0) {
            return n * (n + 1) / 2;
        }
        return 0;
    }
}</code></pre><p>但是上⾯的做法，同样是使⽤乘法，也违反了原则，那么要不使⽤循环，也不适⽤乘法，怎么做呢？</p><h3>递归</h3><p>递归可以模拟出循环，⼏乎所有的for 循环操作，都可以以递归的⽅式实现。每⼀次递归，我们让n 减少1 ，直到减少为0 。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047455321" alt="" title=""/></p><pre><code class="java">public class Solution {
    public int Sum_Solution(int n) {
        if (n &gt;= 0) {
            return n + Sum_Solution(n - 1);
        }
        return 0;
    }
}</code></pre><ul><li>时间复杂度为O(n)</li><li>空间复杂度也是O(n)</li></ul><h3>位运算乘法</h3><p>位运算乘法法：通过位运算实现乘法操作</p><p>思路：将n(n+1)用位运算实现，然后右移1位代替除以2</p><pre><code class="java">public class Solution {
    public int sum(int n) {
        // 计算n*(n+1) using bit manipulation
        int result = multiply(n, n + 1);
        // 右移1位相当于除以2
        return result &gt;&gt; 1;
    }
    
    /**
     * 位运算实现乘法：利用俄罗斯农民算法
     * 原理：a * b = (a &lt;&lt; i)的和，其中i对应b中为1的位
     */
    private int multiply(int a, int b) {
        int result = 0;
        
        // 当a不为0时继续循环
        while (a != 0) {
            // 如果a的最低位是1，则加上对应的b值
            if ((a &amp; 1) != 0) {
                result += b;
            }
            // a右移1位，b左移1位
            a &gt;&gt;= 1;
            b &lt;&lt;= 1;
        }
        
        return result;
    }
    
    // 无循环的位运算乘法版本（符合要求）
    public int sumNoLoop(int n) {
        int res = multi(n, n + 1);
        return res &gt;&gt; 1;
    }
    
    private int multi(int a, int b) {
        int res = 0;
        // 通过多个位判断代替循环
        res += ((a &amp; 1) == 1) ? b : 0;
        a &gt;&gt;= 1;
        b &lt;&lt;= 1;
        
        res += ((a &amp; 1) == 1) ? b : 0;
        a &gt;&gt;= 1; 
        b &lt;&lt;= 1;
        
        // 继续处理更多位...（根据n的范围确定需要处理的位数）
        return res;
    }
}</code></pre><ul><li>时间复杂度：O(log n) - 取决于数字的位数</li><li>空间复杂度：O(1)</li></ul><p>案例解析：</p><pre><code class="text">计算 13 × 9:
13 = 1101(二进制)
9 = 1001(二进制)

13 × 9 = 13 × (1 + 0 + 0 + 1) 按位展开
       = (13&lt;&lt;0) + (13&lt;&lt;3) 对应9中为1的位
       = 13 + 104 = 117</code></pre>]]></description></item><item>    <title><![CDATA[AI巨头连夜亮剑，普通人如何抓住这波技术红利？ 曾经爱过的烤面包 ]]></title>    <link>https://segmentfault.com/a/1190000047459564</link>    <guid>https://segmentfault.com/a/1190000047459564</guid>    <pubDate>2025-12-08 23:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>阿里和华为同日放出技术大招，当行业格局被重新定义，掌握前沿技术不再只是工程师的特权。</p><p>阿里Ovis团队12月3日发布了文本渲染图像生成模型Ovis-Image，专门为高质量文本渲染优化，同时保持低计算成本。这一模型基于Ovis-U1构建，通过增加MMDiT参数和优化结构设计，采用以文本为核心的训练流程，结合大规模预训练与精心设计的后训练优化。</p><p>模型整体由三大核心组件精密咬合而成：作为大脑的Ovis 2.5多模态大模型负责构思；作为手的多模态扩散Transformer负责执行；来自FLUX.1-schnell的变分自编码器则负责视觉信息的压缩与解压，确保视觉特征的稳定性。</p><p>01 <br/>技术突破</p><p>在同一天，华为发布了 openPangu-R-7B-Diffusion，这一模型基于openPangu-Embedded-7B进行少量数据续训练，成功将扩散语言模型的上下文长度扩展至32K。</p><p>它在注意力机制上创新性地融合了自回归的前文因果注意力掩码，从架构层面解决了适配难题。训练策略上延续了BlockDiffusion的思路，但进行了关键优化，拼接带掩码的Block与无掩码的Context，展现出更强的适应性和效率。</p><p>阿里和华为在同一天发布多模态大模型重要进展，标志着AI技术竞赛进入新阶段。高质量文本渲染与长上下文处理能力的突破，正在重塑内容创作、设计、教育等多个行业的边界。</p><p>当技术门槛不断降低，应用场景却呈指数级增长，一个明显的趋势是：掌握这些技术不再局限于研究实验室里的少数专家。</p><p>02 <br/>变革</p><p>模型技术的进步正在产生连锁反应。Ovis-Image的低计算成本特性意味着中小企业和个人开发者也能使用高质量的文本渲染图像生成技术。</p><p>而华为的32K上下文长度突破，则为处理长篇文档、复杂对话和连续创作任务提供了可能。这两项进展共同指向一个方向：多模态AI正从炫技阶段走向实用化、普及化阶段。</p><p>行业变革的节奏超出了大多数人的预期。那些原本需要专业设计师数小时完成的工作，现在可能只需要几句文字描述；复杂的文档分析与生成任务，也能通过长上下文模型高效完成。</p><p>变革的核心逻辑在于，技术突破降低了专业门槛，但提高了应用广度。这意味着非技术背景的人士也有机会借助这些工具创造价值，前提是他们理解这些技术能做什么、不能做什么，以及如何将其融入工作流程。</p><p>03 <br/>技能</p><p>技术快速迭代的背景下，传统技能框架正在失效。过去，掌握单一技能可能足够应对职业挑战；现在，理解技术边界、能够跨领域整合的能力变得尤为重要。</p><p>市场对既懂技术原理又懂应用场景的人才需求急剧增加。企业需要的不再是纯粹的技术专家，而是能够将AI能力转化为实际解决方案的“桥梁型”人才。</p><p>AI技术普及带来了新的职业机会，但也对现有职业构成挑战。内容创作者需要学习如何与文本生成模型协作，设计师需要掌握图像生成工具的新特性。</p><p>产品经理则需要理解多模态技术的可能性与局限性，以设计出真正符合用户需求的产品。这些变化要求从业者保持持续学习的状态，不断更新自己的技能树。</p><p>04 <br/>学习</p><p>面对技术浪潮，系统化学习成为应对不确定性的最佳策略。专业课程的价值不仅在于传授知识，更在于提供经过验证的学习路径和实践机会。</p><p>随着阿里华为等技术巨头持续推进AI边界，行业对掌握多模态大模型应用能力的人才需求将持续增长。那些能够将最新技术转化为实际应用的专业人士，将在这个技术驱动的时代中获得独特优势。</p><p>系统化学习和实战训练为普通人提供了掌握前沿技术的可行路径。当技术门槛降低，理解并应用这些技术的能力将成为新的职业分水岭。行业变革的浪潮中，持续学习是抓住机会的最佳策略。</p><p>选择合适的学习路径，培养跨领域整合能力，普通人也能在这场技术革命中找到自己的位置。</p>]]></description></item><item>    <title><![CDATA[PyTorch推理扩展实战：用Ray Data轻松实现多机多卡并行 本文系转载，阅读原文
https]]></title>    <link>https://segmentfault.com/a/1190000047459515</link>    <guid>https://segmentfault.com/a/1190000047459515</guid>    <pubDate>2025-12-08 22:02:58</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>单机 PyTorch 模型跑推理没什么问题，但数据量一旦上到万级、百万级，瓶颈就暴露出来了：内存不够、GPU 利用率低、I/O 拖后腿，更别说还要考虑容错和多机扩展。</p><p>传统做法是自己写多线程 DataLoader、管理批次队列、手动调度 GPU 资源，这哥工程量可不小，调试起来也麻烦。Ray Data 提供了一个更轻量的方案：在几乎不改动原有 PyTorch 代码的前提下，把单机推理扩展成分布式 pipeline。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047459517" alt="" title=""/></p><h2>原始的 PyTorch 代码</h2><p>典型的推理场景：模型加载、预处理、批量预测，一套下来大概长这样：</p><pre><code> import torch  
import torchvision  
from PIL import Image  
from typing import List

class TorchPredictor:  
    def __init__(self, model: torchvision.models, weights: torchvision.models):  
        self.weights = weights  
        self.model = model(weights=weights)  
        self.model.eval()  
        self.transform = weights.transforms()  
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'  
        self.model.to(self.device)  
    def predict_batch(self, batch: List[Image.Image]) -&gt; torch.Tensor:  
        with torch.inference_mode():  
            batch = torch.stack([  
                self.transform(img.convert("RGB")) for img in batch  
            ]).to(self.device)  
            logits = self.model(batch)  
            probs = torch.nn.functional.softmax(logits, dim=1)  
             return probs</code></pre><p>处理几张图片完全没问题：</p><pre><code> predictor = TorchPredictor(  
    torchvision.models.resnet152,   
    torchvision.models.ResNet152_Weights.DEFAULT  
)

images = [  
    Image.open('/content/corn.png').convert("RGB"),  
    Image.open('/content/corn.png').convert("RGB")  
]  
 predictions = predictor.predict_batch(images)</code></pre><h2>大数据量</h2><p>图片数量从几张变成几万张、几百万张，情况完全不一样了。</p><p>内存撑不住，不可能把所有图一股脑塞进去；GPU 利用率上不去，多卡场景下吞吐量优化是个棘手的问题；万一跑到一半挂了怎么办？分布式部署能不能用上集群资源？还有个容易被忽视的点：数据加载的 I/O 往往才是真正的瓶颈。</p><p>自己从头写一套健壮的 pipeline 处理这些问题，少说得折腾好几天。</p><h2>Ray Data 的思路</h2><p>Ray Data 是个分布式数据处理框架，跟 PyTorch 配合得很好。关键是改造成本极低，原有代码基本不用大动。</p><p><strong>第一步：改造 Predictor 类</strong></p><p>把</p><pre><code>predict_batch</code></pre><p>方法换成</p><pre><code>__call__</code></pre><p>，输入从 PIL Image 列表改成包含 numpy 数组的字典：</p><pre><code> import numpy as np  
from typing import Dict

class TorchPredictor:  
    def __init__(self, model: torchvision.models, weights: torchvision.models):  
        self.weights = weights  
        self.model = model(weights=weights)  
        self.model.eval()  
        self.transform = weights.transforms()  
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'  
        self.model.to(self.device)  
    def __call__(self, batch: Dict[str, np.ndarray]):  
        """Ray Data passes a dict batch with numpy arrays."""  
        # Convert numpy arrays back to PIL Images  
        images = [Image.fromarray(img_array) for img_array in batch["image"]]  
        with torch.inference_mode():  
            tensor_batch = torch.stack([  
                self.transform(img.convert("RGB")) for img in images  
            ]).to(self.device)  
            logits = self.model(tensor_batch)  
            probs = torch.nn.functional.softmax(logits, dim=1)  
              
            # Get top prediction  
            top_probs, top_indices = torch.max(probs, dim=1)  
        return {  
            "predicted_class_idx": top_indices.cpu().numpy(),  
            "confidence": top_probs.cpu().numpy()  
         }</code></pre><p>改动点说明：</p><pre><code>__call__</code></pre><p>替代</p><pre><code>predict_batch</code></pre><p>；输入类型从</p><pre><code>List[Image.Image]</code></pre><p>变成</p><pre><code>Dict[str, np.ndarray]</code></pre><p>；方法内部把 numpy 数组转回 PIL Image；输出改成 dict 格式；结果要搬回 CPU（数据在进程间的移动由 Ray 负责）。</p><p>还有个细节要注意，Ray Data 用 numpy 数组而非 PIL Image，因为 numpy 数组跨进程序列化效率更高。</p><p><strong>第二步：构建 Ray Dataset</strong></p><p>根据场景选择合适的创建方式，小数据集直接从内存构建：</p><pre><code> import ray  
import numpy as np  

ray.init()  

# Convert PIL Images to numpy arrays  
images = [  
    Image.open("/path/to/image1.png").convert("RGB"),  
    Image.open("/path/to/image2.png").convert("RGB")  
]  

# Create Ray Dataset from numpy arrays  
 ds = ray.data.from_items([{"image": np.array(img)} for img in images])</code></pre><p>中等规模数据集推荐从文件路径延迟加载：</p><pre><code> # Create dataset from paths  
image_paths = ["/path/to/img1.png", "/path/to/img2.png"]  
ds_paths = ray.data.from_items([{"path": path} for path in image_paths])  

# Load images lazily  
def load_image(batch):  
    images = [np.array(Image.open(path).convert("RGB")) for path in batch["path"]]  
    return {"image": images}  

 ds = ds_paths.map_batches(load_image, batch_size=10)</code></pre><p>生产环境首选</p><pre><code>read_images()</code></pre><p>，Ray 全权接管：</p><pre><code> # Most efficient - Ray handles everything  
 ds = ray.data.read_images("/path/to/image/directory/")  
 # or with specific files  
 ds = ray.data.read_images(["/path/img1.png", "/path/img2.png"])</code></pre><p><strong>第三步：跑分布式推理</strong></p><p>核心代码如下：</p><pre><code> weights = torchvision.models.ResNet152_Weights.DEFAULT  

# Distributed batch inference  
results_ds = ds.map_batches(  
    TorchPredictor,  
    fn_constructor_args=(torchvision.models.resnet152, weights),  
    batch_size=32,  
    num_gpus=1,  
    compute=ray.data.ActorPoolStrategy(size=4)  # 4 parallel actors  
)  
# Collect results  
results = results_ds.take_all()  
# Process results  
for result in results:  
    class_idx = result['predicted_class_idx']  
    confidence = result['confidence']  
     print(f"Predicted: {weights.meta['categories'][class_idx]} ({confidence:.2%})")</code></pre><p>搞定了。新版 Ray 里</p><pre><code>concurrency</code></pre><p>参数已经废弃，要换成</p><pre><code>compute=ActorPoolStrategy(size=N)</code></pre><p>这种写法。</p><p>改动总结：</p><p>自动分批，Ray 自己决定最优 batch size；</p><p>分布式执行，多 worker 并行跑；</p><p>GPU 调度，自动把卡分配给 worker；</p><p>流式处理，数据在 pipeline 里流动，不用一次性全加载进内存；</p><p>容错机制，worker 挂了会自动重试。</p><h2>生产环境</h2><p>RAY还可以直接读云存储的数据，S3、GCS、Azure Blob 都支持：</p><pre><code> # Read directly from S3, GCS, or Azure Blob  
ds = ray.data.read_images("s3://my-bucket/images/")  

results = ds.map_batches(  
    predictor,  
    batch_size=64,  
    num_gpus=1,  
    concurrency=8  # 8 parallel GPU workers  
 )</code></pre><p>多节点集群也可以用同一套代码，10 台机器还是 100 台机器，根本不用改：</p><pre><code># Connect to your Ray cluster  
ray.init("ray://my-cluster-head:10001")  

# Same code as before  
ds = ray.data.read_images("s3://my-bucket/million-images/")  
results = ds.map_batches(predictor, batch_size=64, num_gpus=1)</code></pre><h2>进阶用法</h2><p>每个 batch 都重新加载模型太浪费了，用 ActorPoolStrategy 让模型实例常驻内存：</p><pre><code>from ray.data import ActorPoolStrategy  

results = ds.map_batches(  
    TorchPredictor,  
    fn_constructor_args=(torchvision.models.resnet152, weights),  
    batch_size=32,  
    num_gpus=1,  
    compute=ActorPoolStrategy(size=4)  # Keep 4 actors alive  
)</code></pre><p>这样吞吐量提升很明显。</p><p>CPU、GPU 资源可以细调</p><pre><code>results = ds.map_batches(  
    TorchPredictor,  
    fn_constructor_args=(torchvision.models.resnet152, weights),  
    batch_size=32,  
    num_gpus=1,  # 1 GPU per actor  
    num_cpus=4,  # 4 CPUs per GPU worker  
    compute=ActorPoolStrategy(size=8)  
)</code></pre><p>推理完直接写到云存储：</p><pre><code>results.write_parquet("s3://my-bucket/predictions/")</code></pre><h2>几个容易踩的坑</h2><p>Ray Data 没法直接序列化 PIL Image 对象，得先转成 numpy 数组：</p><pre><code># ❌ This will fail  
ds = ray.data.from_items([{"image": pil_image}])  

# ✅ This works  
ds = ray.data.from_items([{"image": np.array(pil_image)}])  

# ✅ Or use read_images() (best)  
ds = ray.data.read_images("/path/to/images/")</code></pre><p>Ray 2.51 之后</p><pre><code>concurrency</code></pre><p>不能用了：</p><pre><code># ❌ Deprecated  
ds.map_batches(predictor, concurrency=4)  

# ✅ New way  
ds.map_batches(predictor, compute=ActorPoolStrategy(size=4))</code></pre><p>batch size 太大容易 OOM，保守起见可以从小的开始试：</p><pre><code># Monitor GPU memory and adjust batch_size accordingly  
results = ds.map_batches(  
    predictor,  
    batch_size=16,  # Start conservative  
    num_gpus=1  
)</code></pre><h2>实践建议</h2><p>batch size 可以从小往大试，观察 GPU 显存占用：</p><pre><code># Too small: underutilized GPU  
batch_size=4  

# Too large: OOM errors  
batch_size=256  

# Just right: depends on your model and GPU  
# For ResNet152 on a single GPU, 32-64 works well  
batch_size=32</code></pre><p>ActorPoolStrategy 处理 20 张图大概要 9.7 秒，而原生 PyTorch 跑 2 张图几乎瞬间完成。所以图片量少的时候 Ray Data 的启动开销反而不划算，所以这个方案是几百上千张图的场景才能体现优势。</p><p>Ray 自带 dashboard，默认在 8265 端口：</p><pre><code># Check Ray dashboard at http://localhost:8265  
ray.init(dashboard_host="0.0.0.0")</code></pre><p>代码中可以包一层 try-except 防止单个样本出错拖垮整个任务：</p><pre><code>def safe_predictor(batch: dict):  
    try:  
        return predictor(batch)  
    except Exception as e:  
        return {"error": str(e), "probs": None}</code></pre><p>跑之前加个计时，可以进行性能 profiling：</p><pre><code>import time  

start = time.time()  
results = ds.map_batches(predictor, batch_size=32)  
results.take_all()  
print(f"Processed in {time.time() - start:.2f} seconds")</code></pre><h2>总结</h2><p>适合的场景：数据集太大内存放不下；需要多卡或多机并行；长时间任务需要容错；不想自己写分布式代码。</p><p>不太必要的场景：图片量在百张以内；数据集轻松塞进内存；只有一张卡而且短期内不打算扩展。</p><p>Ray Data 的好处在于迁移成本低。PyTorch 代码改动很小，换个方法签名、把数据包成 Ray Dataset，就能换来从单卡到多机的无痛扩展、自动 batching 和并行优化、内置容错、云存储无缝对接等功能。</p><p>如果你下次写多线程 data loader 或者手动管理 GPU pool 之前，可以先考虑一下这哥方法，把分布式系统的脏活累活交给 Ray，精力留给构建模型本身。</p><p><a href="https://link.segmentfault.com/?enc=6tu94Y5qIzEgz0bmdfip9A%3D%3D.ElinHbZyxfnmA0S2bINuFVYCzHXam4TMb9oA9MRhApxK67fZtC8Q7mI3BJAoanaCcTcy%2BQbtaqFdsK5BkPjNiA%3D%3D" rel="nofollow" target="_blank">https://avoid.overfit.cn/post/6320b9b6e1a14e0ba4c3384c83d06986</a></p><p>作者：Moutasem Akkad</p>]]></description></item><item>    <title><![CDATA[《Nginx在嵌入式场景的高效配置与运维逻辑》 程序员阿伟 ]]></title>    <link>https://segmentfault.com/a/1190000047459530</link>    <guid>https://segmentfault.com/a/1190000047459530</guid>    <pubDate>2025-12-08 22:02:09</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>轻量型Nginx的核心魅力，正在于打破“功能全量加载”的固有思维，通过对核心功能的聚焦与非必要模块的精准剥离，在有限的资源边界内实现高效稳定的服务输出。这种轻量并非妥协式的功能删减，而是基于场景需求的理性取舍，它要求部署者既要深刻理解Nginx的底层架构，清楚每个模块的功能定位与资源消耗，又要精准把握业务的核心诉求，明确哪些功能是不可或缺的，哪些是可替代或暂时不需要的。在长期的技术实践中，这种轻量部署思路不仅解决了边缘场景的实际痛点，技术工具的本质—工具的价值不在于功能的堆砌，而在于与场景的高度适配，这也是轻量架构在边缘计算、嵌入式系统等领域愈发普及的核心原因，更是技术人在复杂环境中寻求高效解决方案的必然选择。</p><p>轻量型Nginx的环境搭建，核心逻辑是“按需构建、资源适配”，这一过程最能体现技术人的取舍智慧与底层认知。不同于传统部署中“一键安装全量依赖”的便捷操作，轻量部署需要从源头把控每一个资源占用环节。首先要明确服务的核心定位，是仅提供静态资源分发，还是需要简单的请求转发、访问控制，不同的定位直接决定了依赖模块的选择。例如，若仅用于嵌入式设备的本地静态配置文件分发，便无需加载SSL、反向代理等模块，仅保留最基础的HTTP核心模块即可，这样能最大程度减少内存占用。在操作系统选择上，轻量部署更倾向于采用Alpine Linux、BusyBox这类精简版系统，它们剔除了普通Linux发行版中大量不必要的预装组件与服务，自身占用资源极低，能为Nginx预留更多运行空间。在依赖安装环节，需要逐一甄别每个依赖包的作用，比如编译依赖中的gcc、make等工具，在编译安装完成后便失去了存在的意义，可及时通过系统自带的包管理工具清理，进一步压缩环境体积；而pcre、zlib等核心依赖，也需选择轻量版本或仅编译必要功能，避免因全量安装带来的资源浪费。这种搭建方式看似繁琐，实则是对资源利用效率的极致追求，每一步操作都围绕“最小资源占用、最大功能输出”的目标，在实践中不断调试、优化，最终形成一套适配资源受限场景的高效部署流程。</p><p>配置环节是轻量型Nginx发挥效能的关键，其核心思路是“功能聚焦、性能适配”，拒绝无意义的配置项堆砌。轻量配置的本质是让每一项设置都有明确的场景指向，每一个参数都能对应具体的性能优化目标，避免因盲目照搬通用配置导致的资源浪费。在实践中，首先要基于业务场景确定配置重心：如果是静态资源服务，配置重点应放在资源缓存策略与传输效率上，比如根据资源类型设置差异化的缓存时长，静态图片、CSS等可设置较长缓存周期，而动态生成的静态文件则缩短缓存时间，同时优化传输模式，启用压缩功能减少数据传输量，降低带宽占用；如果是简单的请求转发场景，则需聚焦于连接管理与响应速度，合理设置连接超时时间，避免无效连接长时间占用资源，同时根据CPU核心数调整工作进程数，让每个进程都能充分利用硬件资源，避免进程过多导致的调度开销。此外，轻量配置还需充分考虑运行环境的资源上限，比如根据可用内存大小设置并发连接数，若内存仅有512MB，便不宜将并发连接数设置过高，否则会导致内存溢出；根据CPU性能调整请求处理模型，在单核CPU环境下采用单进程多线程模型，在多核环境下则可采用多进程模型，实现资源与性能的最佳平衡。这种配置思路要求部署者不仅要熟悉Nginx的配置选项，更要具备对系统资源的敏感度与把控力，在实践中通过反复测试、调试，找到最适合当前场景的配置方案，让轻量Nginx在有限资源下发挥出最优性能。</p><p>轻量型Nginx的动态适配能力，是其在复杂边缘场景中保持竞争力的核心优势，这种适配并非依赖复杂的插件或工具，而是源于对Nginx核心机制的灵活运用与对场景变化的快速响应。在实际部署中，业务需求往往会随时间推移发生变化，比如最初仅需提供静态资源服务，后续可能需要新增简单的API转发功能；或者原本低流量的服务，因业务推广出现阶段性流量峰值。此时，轻量环境的配置调整需要遵循“最小改动、精准扩容”的原则，在保留原有核心配置的基础上，按需添加必要模块与设置，避免因全面重构导致的资源浪费与稳定性风险。例如，当需要新增API转发功能时，无需重新编译安装Nginx，可通过加载轻量的反向代理模块，仅配置必要的转发规则与健康检查参数，即可实现功能扩展，同时避免加载其他无关模块；当流量出现阶段性增长时，可通过调整工作进程数、连接池大小等参数，在不增加额外硬件资源的前提下提升处理能力，若流量峰值持续时间较短，还可设置临时配置文件，峰值过后自动恢复原配置，避免资源长期占用。在实践中，我曾遇到过边缘网关因业务扩展需要新增访问控制功能的场景，最初考虑加载复杂的权限管理模块，但测试后发现会增加近30%的内存占用，后来通过利用Nginx核心配置中的基础规则，结合IP白名单与简单的请求头校验，同样实现了精准的访问控制，且资源占用几乎无明显增加。这种动态适配的思路，核心是“以最小的资源代价满足变化的需求”，它要求部署者深刻理解Nginx的配置逻辑与模块特性，能够快速定位功能扩展的核心关键点，在实践中不断积累调整经验，形成一套灵活高效的适配方法论。</p><p>长期运维中的“轻量坚守”，是保障Nginx环境持续高效运行的关键，这种坚守并非墨守成规，而是在日常维护中始终保持对资源占用与功能冗余的警惕。轻量环境的运维核心是“持续优化、动态清理”，因为即使初始配置再精简，随着业务迭代与环境变化，也可能出现冗余配置、无效模块占用资源的情况。在日常运维中，我会定期对Nginx环境进行“资源体检”，重点关注内存占用、CPU使用率、连接数等核心指标，通过系统自带的监控工具（文字描述功能，无代码）观察资源变化趋势，若发现内存占用持续上升，会逐一排查是否存在未清理的临时配置、冗余模块或无效连接。例如，曾在一次运维中发现，某边缘设备的Nginx内存占用在一周内增长了20%，排查后发现是之前测试时添加的日志模块未及时禁用，该模块会实时记录详细日志，导致内存持续累积，禁用后内存占用迅速恢复正常。日志管理也是轻量运维的重点，默认的日志配置会记录大量冗余信息，不仅占用存储空间，还会增加IO开销，因此我会根据实际需求设置日志级别，仅保留错误日志与核心访问日志，同时配置日志轮转策略，定期压缩归档旧日志，避免日志文件过大占用资源。此外，对于不再使用的模块，我会及时通过编译工具卸载，避免其在后台占用系统资源，同时定期更新Nginx版本，但仅选择轻量版更新，避免新版本中新增的冗余功能增加资源负担。这种运维思路，将“精简高效”的理念贯穿于环境生命周期的每一个环节，通过持续的监控、清理与优化，让轻量Nginx始终保持最佳运行状态，这也是从长期实践中总结出的运维智慧。</p><p>轻量型Nginx的部署与配置，本质上是一场对技术本质的回归，它剥离了冗余的功能外壳与复杂的配置套路，让工具回归到“解决核心问题”的原始定位。在这个过程中，我所积累的不仅是具体的操作方法，更是一种“精准适配”的技术思维—无论是环境搭建时的依赖取舍，还是配置优化中的参数调整，亦或是运维过程中的资源管控，核心都是围绕“场景需求”与“资源上限”进行动态平衡。这种思维不仅适用于Nginx的轻量部署，更可以迁移到其他技术工具的使用中，比如在边缘场景部署数据库时，同样可以采用“核心功能保留、冗余模块剥离”的思路，选择轻量型数据库版本；在开发嵌入式应用时，遵循“最小资源占用”的原则设计架构。技术的发展往往是从“复杂”到“简单”的循环，当我们习惯了各种功能强大的工具与框架后，反而容易陷入“功能依赖”的误区，而轻量部署的实践让我明白，真正高效的技术方案，往往是最贴合场景的方案，它不需要华丽的功能堆砌，只需要精准解决核心问题。</p>]]></description></item><item>    <title><![CDATA[《TXT与专用HSTS记录的浏览器安全通信轻量配置指南》 程序员阿伟 ]]></title>    <link>https://segmentfault.com/a/1190000047459534</link>    <guid>https://segmentfault.com/a/1190000047459534</guid>    <pubDate>2025-12-08 22:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在网络安全架构向轻量化、多场景适配演进的实践中，我们面对的并非复杂的企业级服务集群，而是静态博客、边缘计算节点、无服务器架构应用等资源受限或权限受限的场景，传统的服务器响应头配置方式往往受限于环境约束—比如静态站点无法自定义后端响应头，多域名管理场景下逐一配置服务器过于繁琐，边缘节点缺乏复杂配置的硬件支撑。而通过TXT记录或专用HSTS记录告知浏览器的方式，恰恰以“轻量无侵入”的特性，打破了这些场景限制，它无需深度改造服务架构，无需占用过多系统资源，仅通过简洁的记录配置，就能实现对浏览器访问行为的精准安全引导。这种配置思路的核心价值，在于将安全策略从服务器环境中剥离，转化为可跨场景复用的“信任凭证”，无论是静态资源分发、临时站点部署，还是多域名统一安全管理，都能快速落地。在长期的安全实践中，这种轻量配置方式不仅解决了多类场景的安全痛点，更让我深刻意识到，安全配置的本质是“信任的高效传递”—浏览器与服务器的安全通信，无需依赖复杂的技术堆砌，只需通过标准化的记录约定，就能建立起可靠的信任关系，这也是轻量安全架构在当下多场景部署需求中愈发重要的核心原因。</p><p>要真正掌握这种配置方式，必须先穿透技术表象，理解HSTS的底层信任机制，它的核心并非简单的HTTP强制跳转，而是通过浏览器的本地缓存形成“安全访问记忆”，从根源上阻断非加密访问的可能。当浏览器首次获取到HSTS记录后，会将对应的域名标记为“强制HTTPS访问”对象，并在本地缓存该策略一段时间，在此期间，所有针对该域名的HTTP请求都会被浏览器自动拦截并转换为HTTPS请求，无需等待服务器响应，既提升了访问安全性，又减少了跳转带来的性能损耗。而TXT记录与专用HSTS记录的核心差异，在于信任凭证的存储与传递载体：专用HSTS记录依赖服务器的HTTP响应头，当浏览器发起首次HTTP请求时，服务器通过响应头将安全策略传递给浏览器，适用于具备后端配置权限的场景，生效速度快且兼容性覆盖主流浏览器；TXT记录则将安全策略存储于域名解析系统中，浏览器在解析域名时会同步获取该记录，无需依赖后端服务的响应，这种特性使其成为静态站点、无服务器架构、嵌入式设备等无法自定义响应头场景的最优解。在实践中，这种差异直接决定了配置方案的选择逻辑—有后端配置权限时，优先选择专用HSTS记录以保障兼容性；无配置权限或场景受限，TXT记录则成为安全加固的关键路径，这种“因场景制宜”的选择思维，正是安全技术实践中最核心的底层逻辑。</p><p>通过TXT记录配置HSTS的实践过程，需围绕“规范定义、精准配置、验证闭环”三个核心环节层层推进，每个环节都需兼顾行业标准与场景适配性，避免因细节疏漏导致配置失效。首先是记录内容的规范定义，虽然不能涉及代码，但需明确核心要素的逻辑：记录类型需选择域名解析系统支持的专用安全类型，确保浏览器能够识别；内容需包含四项关键策略—HTTPS强制生效的有效期、是否将子域名纳入策略范围、是否允许浏览器预加载该策略、是否禁用HTTP降级访问，这些要素的设置直接影响安全效果与业务可用性。例如，有效期的设置需要平衡安全性与灵活性，过长可能导致配置错误后难以快速修正，过短则会频繁触发策略重新验证，建议根据业务稳定性调整，静态站点可设置较长有效期，频繁迭代的站点则适当缩短；子域名策略需根据实际需求选择，若多子域名统一管理，可开启子域名包含功能，若仅需保护主域名，则关闭该选项。其次是解析配置环节，需登录域名管理平台，找到DNS解析模块，新增一条TXT记录，准确填入定义好的策略内容，同时注意记录的“主机记录”字段设置，确保覆盖目标域名及所需保护的子域名范围，配置完成后需等待DNS解析全球同步，不同服务商的同步周期从几分钟到几小时不等，期间需避免频繁修改配置。最后是验证闭环环节，解析生效后，可通过两种方式确认配置效果：一是直接访问目标域名的HTTP地址，观察浏览器是否自动跳转至HTTPS，且地址栏显示安全锁标识；二是使用行业认可的在线检测工具，输入域名后查看HSTS策略的识别状态，确认策略中的各项参数是否被正确解析。在实践中，验证环节往往需要多次调试，比如排查记录内容是否存在格式偏差、解析是否完全同步、浏览器缓存是否影响首次验证结果等，这些细节的把控直接决定了配置的成功率，也是技术实践中积累经验的关键过程。</p><p>专用HSTS记录的配置逻辑，更侧重于“后端响应头的精准管控”，适用于具备服务器配置权限的场景，其核心优势在于生效即时性与浏览器兼容性，是企业级服务、动态站点等场景的首选安全方案。与TXT记录不同，专用HSTS记录无需依赖DNS解析，而是通过服务器在处理HTTP请求时，主动在响应头中携带安全策略信息，浏览器首次接收后便缓存该策略，后续访问直接生效。配置的核心环节在于服务器响应头的自定义设置，需根据服务器类型调整配置思路：静态服务器可通过修改配置文件，全局启用HSTS响应头；应用服务器可在应用代码中统一配置响应头，或通过中间件实现策略分发。无论哪种方式，都需确保响应头的名称与内容格式符合行业标准，策略参数与TXT记录保持一致，包括有效期、子域名包含、预加载权限等关键信息。在实践中，配置时需注意“灰度过渡”原则，避免直接启用严格策略导致业务异常：首次配置可设置较短的有效期（如几小时），同时关闭预加载功能，测试主流浏览器的兼容性与业务访问稳定性，确认无异常后，再逐步延长有效期并开启预加载；若业务存在特殊需求，需临时允许HTTP访问，可通过缩短有效期快速调整策略，待需求结束后恢复严格配置。此外，专用HSTS记录支持将域名提交至浏览器厂商维护的HSTS预加载列表，提交通过后，浏览器在首次访问前就已内置该域名的安全策略，无需等待首次HTTP请求，进一步提升安全防护的即时性，尤其适用于用户基数大、安全需求高的场景。</p><p>无论是TXT记录还是专用HSTS记录，配置后的持续优化与动态监控，都是保障安全策略长期有效、适配业务变化的关键，核心在于建立“策略迭代-效果监控-问题修复”的闭环机制。安全策略并非一成不变，需根据业务发展与安全需求动态调整：当域名新增子域名时，需及时更新HSTS记录，将新子域名纳入策略范围，避免出现安全防护盲区；当业务架构调整，如从动态站点转为静态站点，需同步切换配置方案，从专用HSTS记录改为TXT记录；当安全漏洞出现时，可通过缩短有效期快速更新策略，关闭存在风险的配置项。监控环节需聚焦两个核心维度：一是浏览器兼容性监控，定期测试主流浏览器及不同版本的访问情况，确认策略在各类环境中都能正常生效，避免因浏览器版本差异导致策略失效；二是策略执行效果监控，通过分析服务器访问日志，统计HTTP请求的转换率，判断是否存在未被拦截的HTTP请求，同时关注是否有因策略配置导致的访问异常，如HTTPS证书失效时，策略会导致用户无法访问，需及时预警并处理。在实践中，可结合安全监控工具，定期扫描域名的HSTS配置状态，自动检测策略参数是否合规、是否存在配置漏洞，同时建立配置变更记录台账，每次调整后及时记录原因与效果，便于后续追溯与优化。这种“动态优化+持续监控”的思路，体现了安全防护的“主动防御”理念，只有让策略始终适配业务与安全的变化，才能实现长期稳定的安全保障。</p><p>通过TXT记录或专用HSTS记录告知浏览器的配置方式，本质上是轻量安全架构的典型实践，它剥离了传统安全配置的复杂流程与资源消耗，以“最小化干预”实现“最大化安全”，完美适配了当下多场景、轻量化的部署需求。在这个过程中，积累的不仅是具体的操作方法，更是一种“场景化安全”的技术思维—安全配置不应是标准化的模板套用，而应是基于场景特性的精准适配，不同的业务架构、不同的权限边界、不同的用户群体，都需要匹配对应的安全方案。这种思维不仅适用于HSTS配置，更可以迁移到其他安全技术的实践中，比如静态站点的跨域安全配置、边缘节点的访问控制策略等，核心都是“以最小成本实现核心安全需求”。</p>]]></description></item><item>    <title><![CDATA[Pixelmator Pro for Mac v3.5.4.dmg 安装方法｜简单易懂 小童童 ]]></title>    <link>https://segmentfault.com/a/1190000047459382</link>    <guid>https://segmentfault.com/a/1190000047459382</guid>    <pubDate>2025-12-08 21:02:10</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>​</p><p>Pixelmator Pro 是 Mac 上一款很受欢迎的图片编辑软件，界面清爽、操作简单，功能却挺全，像修图、调色、抠图、加特效都能搞定。它支持图层、蒙版、矢量图形这些专业玩法，但对新手也很友好，不用学太多复杂操作就能出效果</p><ol><li>先下好安装包</li></ol><p><strong>安装包下载：</strong><a href="https://link.segmentfault.com/?enc=05q%2FtQohWeq99RjWDSxWKA%3D%3D.wC0xUb3ZYcKXW6RkoQVcRoAu%2Fxdlgkds81eb01oDDqqU8%2BKEpOFVrt43rbLi8v%2Fl" rel="nofollow" title="https://pan.quark.cn/s/537dce9946a1" target="_blank">https://pan.quark.cn/s/537dce9946a1</a>，把 <code>Pixelmator Pro for Mac v3.5.4.dmg</code>下载到电脑里，记住放哪了，别等会儿找不着（一般默认在“下载”文件夹）。</p><h3>2. 打开 DMG 文件</h3><p>找到刚下载的 <code>.dmg</code>文件，双击它！这时候会弹出一个新窗口，里面能看到 Pixelmator Pro 的图标和一个箭头（或者叫“应用程序”文件夹的快捷方式）。</p><h3>3. 拖图标到“应用程序”</h3><p>重点来了：直接按住 Pixelmator Pro 的图标，往右边那个“应用程序”文件夹的快捷方式上拖——拖过去松开鼠标，等它自己复制完（进度条跑完就OK）。</p><h3>4. 等复制完，关掉窗口</h3><p>复制好了之后，把刚才弹出的 DMG 窗口关掉就行，不用留着。</p><h3>5. 打开软件试试</h3><p>现在去“启动台”（屏幕底部火箭图标）找 Pixelmator Pro，点一下打开。第一次开可能会提示“是否信任”，选“打开”就行（Mac 有时候对新软件会多问一句，正常操作）。</p><p>​</p>]]></description></item><item>    <title><![CDATA[腾讯新闻APP的消息推送Push架构技术重构实践 JackJiang ]]></title>    <link>https://segmentfault.com/a/1190000047459419</link>    <guid>https://segmentfault.com/a/1190000047459419</guid>    <pubDate>2025-12-08 21:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>本文由腾讯技术团队颜勇分享，原题“腾讯新闻PUSH架构升级之路”，有修订和重新排版。</p><h2>1、引言</h2><p>68 万行代码精简到8.6 万；Golang 重写大部分 C++模块；解决过度微服务化问题…… 这是新闻 PUSH 架构团队取得的技术收益。PUSH 是腾讯新闻精品资讯的重要分发途径，也是新闻 App 重要的促活手段。作为 PUSH 架构团队，我们一方面在积极支持好新闻护盘，同时也在对 PUSH 架构进行不断的升级与进化，以持续提升 PUSH 系统的稳定性与质量、研发效率，同时持续减少运营成本。<br/>本文主要分享的是腾讯技术团队近年来对腾讯新闻消息推送PUSH系统做的架构优化和技术实践。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459421" alt="图片" title="图片"/></p><h2>2、Push平台介绍</h2><p>2.1 概述PUSH 是腾讯新闻内容重要的分发渠道，新闻 PUSH 平台承担着将新闻资讯触达到新闻用户、满足用户及时获取精品资讯的需求。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459422" alt="图片" title="图片" loading="lazy"/></p><p>总体上，新闻 PUSH 链路分为下面两部分。</p><p>2.2 PUSH触发</p><p>按触发方式的不同，新闻 PUSH 分为三类：<br/>1）人工 PUSH：运营在 push cms 系统指定要发送的文章、要触达的人群包，人工触发push发送；这类 PUSH 目前主要用于推送热点事件/热点资讯等；<br/>2）自动化 PUSH：周期性地给用户计算他可能感兴趣的内容，这类推送由后台自动触发；<br/>3）功能性 PUSH：由业务系统触发，主要是为了实现一些业务功能通知，比如评论通知、关注通知等。</p><p>2.3 PUSH下发</p><p>对于所有 PUSH 触发 的PUSH 进行调度（包括避让、打散和频控等）和触达（通过自有通道或厂商通道推送给用户）。新闻业务对新闻 PUSH 平台最重要的要求是：</p><p>1）要保证精品咨讯触达的及时性：新闻 PUSH 最重要的是要体现“新”，因为腾讯新闻用户有及时获取热点/突发资讯的诉求，用户经常有这样的体感，有热点突发事件时，所有 App 都会尝试第一时间向用户发起推送，用户大概率会点击收到的第一个推送。在了解了相关热点事件后，对于后续其它 App 的推送，对用户而言就没信息量了，大概率会被忽略，甚至可能会被用户视为一种打扰，影响用户体验。从我们实验数据来看，当P USH 下发延迟降低 50%，PUSH 点击量会提升 10%。所以新闻 PUSH 一直以来的目标是：热点资讯需要第一时间触达给用户，要做到“全网首推”。</p><p>2）要保证推送的用户体验和较好的拉起效率：PUSH 是新闻重要的促活手段，需要有较好的促活效率，这要求保证用户较好的推送体验，因为用户如果感觉推送体验不好，用脚投票，把 App 的 PUSH 系统开关给关了，这对 PUSH 而言就基本上就永远丧失了给这个用户推送的机会了。</p><p>这就要求要尽量保证在合适的时间点给推送用户感兴趣的内容，推送要有合理的频次，相邻 PUSH 之间要有合理的时间间隔，推送内容要做合适的打散。</p><p>其实这两个要求其实在一定层面上是有冲突的：<br/>a.如果要保证推送的及时性，就要求尽量减少计算，拿到消息消息后无脑推到消息通道，这个肯定最快；<br/>b.如果要保证良好的推送用户体验，就需要做很多的判断、考量和计算，这些考虑越多就需要做更多的计算和 io 操作，会影响推送的及时性；最近几年，业务成本的考虑也是 PUSH 关注的重点，需要削减使用的机器和资源，就要求用更少的机器如何发得更快更好。<br/>总结而言，之前新闻 PUSH 业务的突出问题主要有两个方面，请继续往下阅读。</p><h2>3、Push平台问题1：推送速度慢</h2><p>我们团队从 2022 年年中开始接手新闻 PUSH 平台。交接工作刚启动，就遇到了一次 S 级热点事件——一个国际级突发新闻。那天晚上，全网用户都在密切关注它的最新进展。这个事件有两个特点：热度极高、且并非完全突发——早在一个月前就已经有明确预告，因此运营部门提前布置了应急预案。我们刚接手系统时，对整个下发链路还不够熟悉，只能凭直觉扩容机器，希望能抗住峰值。结果现实很快给了我们一记当头棒喝。当晚，很多内部同事都装着多个新闻 App，一眼能看到谁家的推送更快。那晚我们的延迟问题非常明显，甚至有用户在热点过去一个多小时后才收到通知。事后有专门的评测团队做了分析，指出“PUSH 下发耗时过长，高活用户 P90 均值达 20 分钟”，报告还发到了高层群里——对我们来说，那无疑是一次刻骨铭心的教训。</p><h2>4、Push平台问题2：开发效率和问题排查效率低</h2><p>之前 PUSH 链路特别长，新闻 PUSH 内部有 30+ 个模块，同时还依赖其它两个跨业务团队。经常一个需求开发要改多个模块，要团队几个人一起开发，约定交互协议，开发后再联调测试，在多个模块起联合实验；然后还得给中台提需求，然后匹配中台的排期后，才能完成需求上线；这一系列操作就拉长了 push 需求的leadtime。线上有 case 时，问题排查也需要串联多个模块，关联多个模块数据，甚至需要跨部门拉上其它这边来一起来排查，排查效率非常低。push case 非常多，比如用户为什么收到了/没收到某条 push 之类的典型 case，之前需要关联链路20来个模块的日志，还要联合中台一起排查，每次 case 排查时间都在天级；之前在case 排查上，每天都耗费我们大量的人力。既要持续提升 PUSH 触达的及时性、又要持续提升推送的用户体验和拉活效率，还要持续降低运营成本，客观而言，在技术上是一个较大的挑战。本文主要详述，我们如何通过技术架构升级来支撑这个既要&amp;又要&amp;还要的目标。</p><h2>5、老Push架构的问题梳理</h2><p>5.1 模块链路过长，内耗过多</p><p>一条快速PUSH，从推送内容过审后，到最终发出去，最长要经过18个模块，另外还需要经过中台多个模块。一条待推送的数据最多要经历 17 次内部 rpc 转发，多个模块之间腾挪流转，各种网络 rpc，各种内耗，肯定发得慢。一个最典型的例子：原架构有个模块叫scheduler，它主要负责决定一个push该不该发，直观上感觉它里面应该囊括了各种过滤策略，但是原架构做成了多个微服务。scheduler 模块里本身有一些过滤逻辑，另外有一个叫做 filter 的模块，专门负责品牌、开关等硬规则过滤；另外有一个叫做 policy 的模块，专门负责配额等软规则过滤；所有过滤规则都通过后，进入一个叫做 channer 模块，就决定下这次推送走哪个通道；然后又走到一个叫 worker 的模块里，而它只做对接下游中台的协议适配。总体上看，原链路就是过度微服务化了：1）模块多会导致数据流转的低效，模块间网络 rpc 会浪费处理耗时；2）其次会影响迭代效率，模块数不是越多越好，因为经常一个需求需要改多个模块，做多次上线；3）同时模块过多也对联调&amp;测试效率，影响线上 case 排查效率。这就违反了“模块内高内聚，模块间低耦合”的架构设计原则，进而会影响业务迭代效率。</p><p>5.2 依赖服务有瓶颈</p><p>上文提到的 S 级热点事件时，我们将下发服务机器扩了一倍，但是下发速度并没有提升，说明瓶颈不在下发服务本身下，而是在依赖服务上；通过链路debug，我们定位到了链路瓶颈：号码包拉取。在发送人工 push，运营会指定受众人群包（几百万到几亿不等），这时候需要分页拉取该号码包数据进行处理。之前老架构使用了底层平台的人群包服务，新闻所有 push 人群包都上传到了该人群包服务，当发送指定人群包，需要请求平台侧接口分页拉取人群包数据，当时因为平台侧人群包功能实现比较复杂，能支持一些比较高级的能力，因此这个分页接口耗时比较长。但其实我们只用到了最简单的数据分页的功能，完全可以采用更简单的实现方案，以减少接口耗时。</p><p>5.3 链路稳定性不好</p><p>5.3.1）容错能力差：之前链路基本无容错能力，发生了过一次因上游未按约定协议跟我们请求交互，导致我们服务挂了半天，是一次典型的 P0 级事故。</p><p>5.3.2）缺少节点自动故障转移：scheduler 负责 push 调度，原架构为了提升处理效率，scheduler 里做了本地缓存；为了避免缓存失效，起了一个服务 dispatch 消费触发侧生产的待推送的消息，然后按照用户设备号一致性哈希来 sharding，通过 rpc 请求对应的 scheduler，scheduler接受到请求后，塞入到它本地的内存队列里，如果队列满了就直接丢弃。它原来存在有这些问题：dispatch无脑往下游转发，sharding规则非常僵硬，一个用户的push一定要打到某个节点，未做故障转移；当某节点异常满载时，dispatch还是会往这个节点打，导致丢消息或者是 push发送得慢。而且当节点满载时，有限的cpu还需要耗费在rpc解包、无法插入内存队列而丢弃之类的无用消耗上。</p><p>5.4 链路处理无优先级区分</p><p>运营人工发的 PUSH 和自动化 PUSH 都使用同一个下发链路，热点突发事件资讯多由运营人工发送，而自动化 PUSH 多发一些用户可能感兴趣的内容，其实它对于推送速度并没那么敏感；当有人工推送的热点突发内容时，自动化 PUSH 会和它一起争抢有限的链路资源。另外，在链路总吞吐量一定的情况下，其实处理顺序可以调整，让链路资源有限保证人工推送的热点突发内容的发送；</p><p>5.5 技术栈不统一</p><p>之前 push 下发链路有 C++/Go 两种技术栈，技术栈不统一不利于代码复用，影响需求迭代效率。push下发链路本质上是一个高 io 型的流程，其实可以完全可以统一到 Golang 技术栈。</p><p>5.6 链路测试效率低</p><p>push 链路业务逻辑比较多，在日常密集业务需求迭代中，新功能我们可以在线上通过构造对应的功能 case 来进行冒烟测试，但是比较难评估是否影响了线上已有的业务逻辑。之前缺乏有效的回归测试手段，由于担心影响线上业务指标，为了验证是否影响线上已有业务逻辑，我们大的修改都会开比较长的小流量实验验证，比如我们在做调度架构升级时，开了一个近两个月的小流量实验，测试效率比较低也会导致需求迭代效率比较低。</p><h2>6、新Push架构优化1：消息通道自建</h2><p>之前新闻 PUSH 依赖于平台侧的消息通道，业务侧主要负责 PUSH 调度，即业务侧决定触发和过滤，平台侧负责 PUSH 触达给用户终端。由于 PUSH 是新闻增长护盘的重点方向，有较频繁的业务迭代，对底层消息通道我们有较多的业务需求，在业务迭代过程中我们发现平台侧需求 leadtime 比较长，无法满足业务侧迭代效率的要求；在经平台侧这边商量且同意后，我们完成新闻push消息通道的自研，直接对接厂商推送并搭建了长链接通道，实现了 push 全链路在业务侧的全闭环。我们在自建 push 消息通道时，对原来的架构做了重写：1）精简链路，模块整合，减少系统复杂度：去掉我们不关心的无用功能，将原链路15个模块，代码 68 万行整合为了6个模块，代码共8.6万行；通过代码精简能减少系统复杂度，有助于提升业务迭代效率；同时能避免模块之间的rpc通信开销，提升链路处理效率。2）客户端/服务端交互接口整合，提升数据通信成功率：以前 PUSH 注册依赖于注册&amp;绑定&amp;上报三个接口请求，任何一次请求出错，push 注册就会失败；我们在新流程里将注册&amp;绑定&amp;上报需要的所有数据，都一起传给新接口，由服务端在一个接口里实现注册、绑定和上报；将注册成功率从90%提升到了99.9%。3）与新闻技术技术架构保持统一：将原架构发现/rpc技术栈的基础组件升级为腾讯新闻自用的基础组件，尽量使用我们熟练使用的技术栈，以提升业务开发&amp;运维效率。4）优化了原来链路一些不合理的地方：对原来链路的限流机制、通道选择策略做了优化，增加了必要的功能，比如小流量实验环境的支持。</p><h2>7、新Push架构优化2：统一技术栈</h2><p>之前 push 链路有 C++/Golang 两种技术栈，除了 push 推荐服务外， 其它 C++链路模块全部使用 Golang 模块进行了重写，以提升业务迭代效率和链路稳定性。</p><h2>8、新Push架构优化3：链路整合升级，提升效率</h2><p>一个架构如果如果过度微服务化了，会带来各种问题：1）模块间耦合严重，影响研发效率：本来是一个模块应该完成的工作，硬拆成了2个模块，有改动需要都需要改两个模块，需要模块间联调测试，影响需求迭代效率。2）架构效率低：拆成微服务后，函数本地调用变成了RPC网络调用，需要增加大量的拆包、解包的操作，资源白白浪费在这些无用的内耗上了。对于频繁迭代的地方，单独抽成单独的微服务是有助于提升迭代效率的；但是我们review历史push需求，都比较分散，没有集中到一个特定的地方，我们按照“一个需求尽量只用改一个模块”的原则，对原来的push链路的所有模块进行了整合升级。具体的升级内容是：a. 触发侧合并为了1个模块：将原来触发侧的5个模块合并为1个模块；b. 调度侧合并为了1个模块：将原来调度侧的5个模块合并为了1个模块；c. 将消息通道侧模块做了整合：如上所述，我们将push消息通道原来15个模块合并为了5个。经过链路整合后：以前一个 PUSH 消息最多要经过 18 个模块，17次内部链路rpc转发；升级后，只用经过 3 个模块，只用经过 2 次 rpc 转发；这样就显著提升了链路效率；而且模块减少后，业务需要迭代无需开发多个模块，避免模块之间联调和测试，提升了业务迭代效率；同时，线上 case 排查时，无需做多模块的日志 join，提升了 case 排查效率。</p><h2>9、新Push架构优化4：自建号码包服务，提升号码包获取速度</h2><p>如上文所述：之前号码包的拉取慢是系统的主要瓶颈所在，而在我们这个场景比较简单，因此我们考虑自建号码包服务，针对于我们自己的需求来定制开发，以提升服务性能。我们的需求只有一个，就是对离线包进行分页，并提供服务接口返回指定页的数据。1）画像中台圈选兴趣包，并按页切成若干个小文件，每个兴趣包一个文件夹，并上传到cos，兴趣包里带着数据版本号；2）构建包管理服务，提供获取指定兴趣包指定页数据的能力；包管理服务定期从cos上check是否有更新的数据（比较本地数据版本和cos最新的数据版本），如果有，则拉取最新的数据更新本地数据；当接收到拉取指定包指定页数据的请求后，则定位到对应文件夹读取对应页文件数据并返回；3）集群有个数据一致性哨兵，定期检查集群节点的数据版本，当发现集群数据版本不一致时，给集群所有节点发信号，强制让每个节点同步cos上的最新数据，让集群所有节点数据跟最新数据保持一致。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459423" alt="图片" title="图片" loading="lazy"/></p><h2>10、新Push架构优化5：在线过滤改成离线预处理，避免在线处理耗时</h2><p>运营在发PUSH时会选择受众人群包，同时会指定系统、品牌等筛选项，之前的处理流程是先把人群包一股脑发到链路里，然后在下发链路里根据用户画像数据，对数据进行实时过滤。在线过滤增加了链路下发的耗时。其实系统&amp;品牌过滤完全可以前置到离线侧，我们将号码包按品牌和系统维度进行了拆分，比如“社会”包按 android/ios、huawei/oppo/vivo/honor/xiaomi，拆成了13个包，当运营选择指定的筛选项时，直接拉取对应的号码包，这样就避免了在线过滤的耗时，减少了下发的延时。</p><h2>11、新Push架构优化6：将单IO操作自动聚合成批量操作</h2><p>push下发链路有大量io操作，比如获取用户维度的多路数据（比如用户系统、品牌、下发&amp;曝光&amp;点击历史等），获取文章维度的多路数据（文章正排数据等）。链路其实主要耗时还是在io部分，如果能提升io吞吐量，就能提升PUSH链路的吞吐量，减少下发延时；io操作批处理肯定能提升吞吐量。但是在具体业务流程中，不同push类型、不用品牌用户，处理逻辑会有不同，因为每个push的处理流程可能都不一样，无法直接批处理。所以之前调度主链路流程是从队列里按单个消费进行处理的。为了提升链路吞吐量，我们对每一类io操作做了一个类，对外暴露一个单个io请求接口，外部调用该接口后，将请求压入一个异步队列，同时开始等待结果的返回；这样该类io请求都会在该异步队列里进行了汇聚。下层会开若干个处理协程，批量从异步队列消费出若干请求任务，拼成批量的io请求，然后拿到批量io结果，按序向上层返回io结果；这样对上层而言，看到的还是单个的同步io接口，上层业务逻辑开发流程无需做改造，底层其实已经自动做了io的批量聚合，显著提升了链路吞吐量。</p><h2>12、新Push架构优化7：优先推送热点突发内容，优先保证高价值用户及时性体验</h2><p>在链路吞吐量一定的情况下，一个推送任务小到几百万，大到一两亿的发送量，都需要处理时间。这时候先处理比后处理的时延要少。</p><p>其实可以考虑对链路发送进行调度：<br/>1）链路优先保障热点突发PUSH的发送，我们建立了任务优先级队列，当有热点突发PUSH在发送时，其它PUSH延迟发送；<br/>2）同一个PUSH任务，对用户推送顺序也做了排序：活跃度高、历史push点击率高、预估商业化价值高、对push时延敏感的用户优先发送。通过优先级调度，最大程度保障了热点突发内容和高价值用户的推送及时性的体感。</p><h2>13、新Push架构优化8：增加自动故障恢复能力</h2><p>为了提升链路吞吐量，调度节点进程通过 LRU cache 缓存了大量数据，所以在推送消息处理的 sharding 方式上采用了按设备号一致性哈希。很多时候某个节点异常时，会出现慢而不死的情况：处理能力陡降，但是节点存活正常。北极星未能把它摘掉，相当一部分设备会打到该节点，即使该节点已经满载了，之前架构为了避免缓存失效而导致处理耗时增加，还是会一致性哈希将流量打往该节点，导致这部分用户处理耗时异常增加，甚至发送失败。新架构对于推送任务sharding做了优化：在一致性哈希的基础上，每个节点计算出4个固定的backup；当某节点的失败率或处理耗时超过一定阈值时，将该节点的流量均匀低分给他的backup。通过这种方式就支持单节点异常时的自动故障恢复。</p><h2>14、新Push架构优化9：构建push链路自动化测试能力</h2><p>构建了接口自动化回归测试流程：1）case覆盖push链路的核心逻辑；2）合并master时自动触发回归测试流程的执行。构建了自动化diff测试流程：diff流程大体思路都类似，通过录制线上流量的真实请求和返回结果，在测试环境进行回放，观察同一请求下，返回结果是否会有差别；如果无差别，说明测试环境跟线上一样，上线不会引起线上数据异常；如果有差别，就需要分析这些差别是否是符合预期的。diff测试基本能回归到线上所有业务逻辑分支，能弥补回归测试覆盖度有限的问题。主要挑战：push依赖的数据变化比较快，导致在同一时间，同一请求的返回结果会不同；比如push为了避免重复下发同一篇文章，会依赖于下发历史数据，线上录制了刚下发的某篇文章，在测试环境去回放肯定就不能下发了，因为线上刚把这篇文章写入到下发历史里，导致回放请求时返回结果是不能下发了，这样自然就产生了diff。解决方案：在流量录制时，除了录制请求之外，同时录制各个依赖数据，在回放时，依赖数据以依赖数据为准，通过这种方案就避免了依赖数据易变而引入diff的问题。</p><h2>15、架构升级后的系统表现</h2><p>1）push运营成本显著降低：通过持续的 push 架构优化，新闻 push 总运营成本下降70%；2）PUSH链路性能（吞吐量）显著提升：通过持续的 push 架构优化，显著提升了 push 链路的性能，push推送量（出口）峰值吞吐量提升了3.5倍；3）热点突发（全国/快速）PUSH全链路耗时下降明显：a. 热点突发（全国/快速）PUSH内部链路耗时P90下降了90%；b. 内部链路耗时指的是从push审核通过到推送给厂商的时间，即我们内部链路总的耗时时长；c. 热点突发（全国/快速）PUSH全链路耗时（包括内部链路耗时和厂商链路耗时）下降了90%d. 全链路耗时指的是从push审核通过到用户收到PUSH时间，即包括内部链路和厂商链路总的耗时时长.我们完成一些架构升级后，还是评测团队对了评测，腾讯新闻的PUSH已经领先于竞品1～4分钟了。4）提升了PUSH点击效果：push推送速度提升后，push点击数据也能看到明显受益，热点突发PUSH点击pv提升了10%，push大盘点击UV也能看到显著的正向收益；线上收不到PUSH的用户客诉也减少到25年H1 0 例，提升了用户产品体验。5）稳定性良好：push链路主要重构完成后，PUSH链路稳定性&amp;质量明显提升，2025.02以后 0 故障。</p><h2>16、参考资料</h2><p>[1] 极光推送系统大规模高并发架构的技术实践分享<br/>[2] 魅族2500万长连接的实时消息推送架构的技术实践分享<br/>[3] 专访魅族架构师：海量长连接的实时消息推送系统的心得体会<br/>[4] 一个基于长连接的安全可扩展的订阅/推送服务实现思路<br/>[5] 实践分享：如何构建一套高可用的移动端消息推送系统？<br/>[6] Go语言构建千万级在线的高并发消息推送系统实践(来自360公司)<br/>[7] 腾讯信鸽技术分享：百亿级实时消息推送的实战经验<br/>[8] 百万在线的美拍直播弹幕系统的实时推送技术实践之路<br/>[9] 京东京麦商家开放平台的消息推送架构演进之路<br/>[10] 技术干货：从零开始，教你设计一个百万级的消息推送系统<br/>[11] 长连接网关技术专题(四)：爱奇艺WebSocket实时推送网关技术实践<br/>[12] 喜马拉雅亿级用户量的离线消息推送系统架构设计实践<br/>[13] 直播系统聊天技术(四)：百度直播的海量用户实时消息系统架构演进实践<br/>[14] 消息推送技术干货：美团实时消息推送服务的技术演进之路<br/>[15] 揭秘vivo百亿级厂商消息推送平台的高可用技术实践<br/>[16] 得物从零构建亿级消息推送系统的送达稳定性监控体系技术实践<br/>[17] B站千万级长连接实时消息系统的架构设计与实践<br/>[18] 转转千万级用户量消息推送系统的架构演进之路<br/>[19] 企业级实时消息推送系统的架构设计，一文即懂！</p><p>即时通讯技术学习：</p><ul><li>移动端IM开发入门文章：《新手入门一篇就够：从零开发移动端IM》</li><li>开源IM框架源码：<a href="https://link.segmentfault.com/?enc=nSoY4erMvS%2FLirrDJKmvoQ%3D%3D.RgJWh1UTnDHCxgVsArJzyPGaZu7shQ1hoYR6eFFVx%2F0dQBozE6ODiH75fZyvJUCa" rel="nofollow" target="_blank">https://github.com/JackJiang2011/MobileIMSDK</a>（备用地址点此）<br/>（本文已同步发布于：<a href="https://link.segmentfault.com/?enc=xpDsbUclHyZOt7Uyt%2Fv1VA%3D%3D.5yhkXMsMVwhJsWE3J%2F%2BsTfSybYiaN6%2B27gT722pYkZYGBCGRb2%2Bwqxr9uxMAZ3Gj" rel="nofollow" target="_blank">http://www.52im.net/thread-4883-1-1.html</a>）</li></ul>]]></description></item><item>    <title><![CDATA[一文了解 openFuyao“低底噪容器底座” openFuyao ]]></title>    <link>https://segmentfault.com/a/1190000047459299</link>    <guid>https://segmentfault.com/a/1190000047459299</guid>    <pubDate>2025-12-08 20:04:36</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>业务痛点</h2><p>在资源受限的运行环境（如单节点、嵌入式）中，Kubernetes（以下简称“K8s”）自身的资源占用与调度瓶颈，制约了业务 Pod 的可靠拉起与预期规模的实现。</p><h2>根因分析</h2><ul><li>K8s 生态集成多种功能，组件较多，架构略重，自身运行需要系统资源较多。</li><li>K8s 组件独立进程运行，APIServer 与 etcd 需通过网络协议通信，流量较高场景中组件间交互成为瓶颈。</li><li>containerd 创建 Pod 同时产生 shim 进程，随 Pod 数量线性占用内存资源，阻碍高密部署场景。</li></ul><h2>低底噪容器底座方案</h2><p>openFuyao 采用从编排系统、容器运行时、操作系统多层次入手，消减容器环境底噪和提升容器环境性能，打造业界首个单节点部署 1000+Pod 容器环境。<br/><img width="723" height="470" referrerpolicy="no-referrer" src="/img/bVdniuG" alt="" title=""/><br/><img width="723" height="457" referrerpolicy="no-referrer" src="/img/bVdniuH" alt="" title="" loading="lazy"/></p><h3>Kubernetes 子系统：</h3><ul><li>将 K8s 及其周边组件整合为单进程，并将 APIServer 和 etcd 的网络通信优化为进程内内存交互，从而显著降低系统底噪，提升容器编排性能。100Pod 场景可降低 500+MB 内存。</li><li>使用文件探测等低成本方式代替传统消息交互方式，降低高密场景下探针消息对 CPU 和网络的影响。</li><li>最小化 K8s 基础功能，裁剪内存占用较多且不使用的特性（如 OpenAPI v3 ）。</li></ul><h3>运行时子系统：</h3><ul><li>消减 shim 进程，支持 containerd 通过 shimless 方式运行，降低底噪，使单节点可部署 1000+Pod，领先业界 4~10 倍。该典型场景可降低 20GB 内存占用。</li><li>通过启用 cgroup v2，为容器提供了更精细、高效的资源管理能力，使得高密部署时容器管理性能不下降。</li></ul>]]></description></item><item>    <title><![CDATA[React项目里，Record<string, any>和{ [key: string]: any ]]></title>    <link>https://segmentfault.com/a/1190000047459303</link>    <guid>https://segmentfault.com/a/1190000047459303</guid>    <pubDate>2025-12-08 20:03:47</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在 React 项目中，<code>Record&lt;string, any&gt;</code> 和 <code>{ [key: string]: any }</code> <strong>在功能层面几乎等价</strong>（都表示「键为字符串、值为任意类型的对象」），但在<strong>类型语义、语法灵活性、TS 内置特性</strong>上存在关键区别，以下是详细拆解（结合 React 实战场景说明）：</p><h3>一、核心结论先明确</h3><table><thead><tr><th>维度</th><th><code>Record&lt;string, any&gt;</code></th><th><code>{ [key: string]: any }</code></th></tr></thead><tbody><tr><td>核心功能</td><td>表示「键类型固定、值类型固定」的对象</td><td>表示「索引签名为字符串、值任意」的对象</td></tr><tr><td>语义侧重</td><td>强调「键值对映射关系」（内置工具类型）</td><td>强调「自定义索引规则」（基础语法）</td></tr><tr><td>语法灵活性</td><td>仅支持「单一键类型 + 单一值类型」</td><td>可扩展（混合固定属性 + 索引签名）</td></tr><tr><td>React 常用场景</td><td>状态/Props 快速声明、对象映射</td><td>自定义组件 Props（混合固定/动态属性）</td></tr><tr><td>类型推导</td><td>无额外扩展能力</td><td>可结合接口/类型别名扩展</td></tr></tbody></table><h3>二、具体区别与 React 实战示例</h3><h4>1. 语义与设计初衷</h4><ul><li><code>Record&lt;K, V&gt;</code> 是 TypeScript <strong>内置工具类型</strong>，设计初衷是「明确表示一个<strong>键类型为 K、值类型为 V 的键值对映射对象</strong>」，语义更聚焦“映射”；</li><li><code>{ [key: string]: V }</code> 是 TypeScript <strong>基础索引签名语法</strong>，设计初衷是「定义对象的索引规则」，语义更聚焦“对象的索引方式”。</li></ul><p>在 React 中，比如声明一个“动态配置对象”：</p><pre><code class="tsx">// Record：语义更清晰（“字符串键 → 任意值”的映射）
const formConfig: Record&lt;string, any&gt; = {
  username: { label: '用户名', required: true },
  password: { label: '密码', type: 'password' },
};

// 索引签名：语义偏“对象的索引规则”，功能等价
const formConfig: { [key: string]: any } = {
  username: { label: '用户名', required: true },
  password: { label: '密码', type: 'password' },
};</code></pre><h4>2. 语法灵活性（React 中最关键的区别）</h4><p><code>{ [key: string]: any }</code> 支持<strong>混合「固定属性 + 动态索引」</strong>，而 <code>Record&lt;string, any&gt;</code> 只能表示「纯动态键值对」—— 这在 React 组件 Props 定义中尤为常用：</p><pre><code class="tsx">// ✅ 合法：索引签名 + 固定属性（React Props 常用）
interface InputProps {
  // 固定属性
  defaultValue: string;
  onChange: (value: string) =&gt; void;
  // 动态属性（兼容其他未显式声明的 props）
  [key: string]: any;
}

// ❌ 非法：Record 无法混合固定属性
interface InputProps extends Record&lt;string, any&gt; {
  defaultValue: string; // 语法上允许，但语义矛盾（Record 是纯动态映射）
  onChange: (value: string) =&gt; void;
}</code></pre><p>比如 React 中封装通用组件时，常需要「固定核心 Props + 兼容任意扩展属性」，此时只能用索引签名，而 Record 做不到这种混合：</p><pre><code class="tsx">// 正确：用索引签名封装通用按钮 Props
interface ButtonProps {
  type: 'primary' | 'default';
  size: 'small' | 'large';
  [key: string]: any; // 兼容 className、style 等原生属性
}

const Button = (props: ButtonProps) =&gt; {
  const { type, size, ...rest } = props;
  return &lt;button className={`btn-${type}-${size}`} {...rest} /&gt;;
};

// 错误：Record 无法区分“固定属性”和“动态属性”
type ButtonProps = Record&lt;string, any&gt;; // 丢失 type/size 的类型校验</code></pre><h4>3. 类型参数扩展（非 React 专属，但影响写法）</h4><p><code>Record&lt;K, V&gt;</code> 的 <code>K</code> 支持<strong>联合类型</strong>（比如 <code>string | number</code>），而索引签名的 <code>key</code> 只能是 <code>string</code>/<code>number</code>/<code>symbol</code> 单一类型（但实际中 <code>number</code> 键会被转为 <code>string</code>，效果等价）：</p><pre><code class="ts">// ✅ Record 支持联合键类型
type MixedKeyObj = Record&lt;string | number, any&gt;;
const obj: MixedKeyObj = {
  name: '张三',
  123: '数字键', // 合法
};

// ✅ 索引签名也支持 number，但实际键会转字符串
type MixedKeyObj2 = { [key: number]: any };
const obj2: MixedKeyObj2 = {
  123: '数字键', // 合法（键实际是 "123"）
  // 'name': '张三' // ❌ 索引签名是 number，不允许字符串键
};</code></pre><h4>4. 代码简洁性</h4><ul><li>当只需声明「字符串键 + 任意值」时，<code>Record&lt;string, any&gt;</code> 比 <code>{ [key: string]: any }</code> 更简洁；</li><li><p>当需要自定义值类型（比如 <code>string | number</code>），两者简洁度相当：</p><pre><code class="ts">// 等价写法
type StrNumObj1 = Record&lt;string, string | number&gt;;
type StrNumObj2 = { [key: string]: string | number };</code></pre></li></ul><h3>三、React 项目中的选择建议</h3><table><thead><tr><th>场景</th><th>推荐写法</th><th>原因</th></tr></thead><tbody><tr><td>临时声明纯动态对象（如 state、临时变量）</td><td><code>Record&lt;string, any&gt;</code></td><td>语义清晰、代码更短</td></tr><tr><td>组件 Props（混合固定属性 + 动态扩展）</td><td><code>{ [key: string]: any }</code></td><td>支持固定属性 + 索引签名，适配 React 原生属性（如 className）</td></tr><tr><td>明确“键值映射”语义（如配置对象、字典）</td><td><code>Record&lt;string, T&gt;</code></td><td>语义更贴合“映射”场景，可读性更高</td></tr><tr><td>需扩展/复用类型（如接口继承）</td><td><code>{ [key: string]: T }</code></td><td>可与接口/类型别名无缝混合，灵活性更高</td></tr></tbody></table><h3>四、避坑提醒（React 中常见误区）</h3><ol><li>不要滥用 <code>any</code>：无论是 <code>Record&lt;string, any&gt;</code> 还是 <code>{ [key: string]: any }</code>，<code>any</code> 会丢失 TypeScript 类型校验，React 中建议尽量指定具体值类型（比如 <code>Record&lt;string, FormItemConfig&gt;</code>）；</li><li><p>函数组件 Props 扩展：如果想兼容 React 原生 HTML 属性，推荐用 <code>React.HTMLAttributes&lt;HTMLElement&gt;</code> 而非纯索引签名，比如：</p><pre><code class="tsx">interface CustomInputProps extends React.HTMLAttributes&lt;HTMLInputElement&gt; {
  value: string;
  onChange: (value: string) =&gt; void;
}</code></pre></li></ol><h3>最终总结</h3><p>在 React 项目中，<code>Record&lt;string, any&gt;</code> 和 <code>{ [key: string]: any }</code> <strong>功能上等价</strong>（都表示字符串键的任意对象），核心差异在：</p><ul><li><code>Record</code> 更简洁、语义聚焦“映射”，适合纯动态对象；</li><li>索引签名更灵活，支持混合固定属性，适合组件 Props 等场景。</li></ul><p>日常开发中可根据“是否需要混合固定属性”选择，无需过度纠结，重点是避免滥用 <code>any</code>，尽量指定具体类型。</p>]]></description></item><item>    <title><![CDATA[VibeCoding 翻新个人站 (Nextjs+Django) alpha94511 ]]></title>    <link>https://segmentfault.com/a/1190000047459306</link>    <guid>https://segmentfault.com/a/1190000047459306</guid>    <pubDate>2025-12-08 20:03:09</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>最近从个人站引来了德国客户，成功开出海外服务第一单✌️，也让我意识到该把自己的古早个人站做个大升级。折腾了几个小时终于把上线，欢迎大家+友链  <a href="https://link.segmentfault.com/?enc=lvvgY6Yh0fQSZuUVs%2FjF3g%3D%3D.8O4I7zjMRGsl1u9iYpI8%2BRsL3G3lp%2FQbqmEiIxoZwOg%3D" rel="nofollow" target="_blank">https://www.hephaestus.fr/</a></p><p>前端 Nextjs部署在 Vercel上<br/>后端 Django+S3+PostgreSQL 部署在了 DigitalOcean上，资源使用了CDN加速</p><p>后续工作主要是SEO优化，持续引流</p>]]></description></item><item>    <title><![CDATA[漏算的 Token：AI 网关限额机制的攻防博弈 spacewander ]]></title>    <link>https://segmentfault.com/a/1190000047459312</link>    <guid>https://segmentfault.com/a/1190000047459312</guid>    <pubDate>2025-12-08 20:02:21</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>攻</h2><p>AI 网关通常有这样的功能：基于 token 消耗量来做限额操作。有些地方叫做 ai-rate-limiting，有些地方叫做 ai-quota。无论名字为何，原理同出一辙，都是基于推理请求结束时返回的 token usage 信息。</p><p>那么绕过限制的方式就显而易见了，只需找找有没有能让网关看不到推理请求结束时的 usage 信息即可。有些时候，用户在无意中就能绕过这些限制。比如在 OpenAI chat 接口里，默认 streaming 的时候就不会返回 usage，除非用户请求时指定了 include_usage：<a href="https://link.segmentfault.com/?enc=G5trmV9jTtPAgCMyhA2EuQ%3D%3D.ZroCVxC7NoOhrMJXG%2FRhRrjq07ZiUzdvDfXpMQqxB%2BqrxZ11FbltNSctbJJMsrwelwB1GUlSJ%2B%2B1huib5lJ00QcQFyObPhcnfGOnd2nwOPoTTBeHpUMiuNtmmNv%2BDG0kn98A89KqtHlgeSe5m5KTwA%3D%3D" rel="nofollow" target="_blank">https://platform.openai.com/docs/api-reference/chat/create#ch...</a>。</p><p>假设模型供应商总是会提供 token usage，抑或网关在处理用户请求时做了点 hack 额外加上 include_usage，保证了 token usage 总是在推理请求结束时存在，那该怎么办了？方法还是有的，让推理请求提前中断即可。我们可以插入一段 prompt，指定在返回结果结束时输出一个 stop word，然后再执行一个耗时的任务。当客户端收到这个 stop word 后，就可以安心地把连接中断掉。只要请求是提前中断的，网关就不会继续保持和上游的请求，自然收不到上游最后发过来的 usage 了。当然有些配置项可以修改这种行为，比如 Nginx 的 proxy_ignore_client_abort。但如果这么做的话，万一是正常的客户端想要提前终止推理，结果因为网关还是继续和上游通信而导致被多算钱就麻烦了。这种小伎俩可以骗过中间件，不过推理引擎侧还是能知道 prefill 时收到多少 input token，decode 时发出了多少 output token。所以最后给到来的账单还是正常的。</p><h2>守</h2><p>上述各种攻击手段，本质上揭示了当前 AI 网关在流式传输场景下的架构痛点：计费的异步性。在传统的 Request-Response 模型中，网关可以轻松拦截并统计流量；但在 LLM 的流式交互中，Token 的消耗是一个随着时间推移动态累加的过程，而精准的 token usage 报告往往滞后于请求的结束。只要网关依赖于“事后”的上报数据，客户端就有机会利用断连等手段制造“计费黑洞”。</p><p>那么有什么可靠的方式，能够不依赖推理请求中的 token usage 信息，自己在通信过程中算出实际的 token 用量？</p><p>最简单粗暴的方法，就是将字节数乘上一个 magic number 系数，作为找不到 token usage 时的 fallback。如果能在准确性上睁一只眼闭一只眼，这倒是开销最小的方案。</p><p>官方的做法，是调用模型提供商自己的 count token 接口。对于开源的推理引擎像是 vllm 或 TensorRT-LLM，也有对应的 tokenize 接口。只是要让网关在每次请求时额外发起多次 HTTP 调用，代价有点高，尤其在流式处理响应的时候。</p><p>一些编码库提供了本地 tokenize 的能力，如：</p><ul><li>huggingface/tokenizers</li><li>openai/tiktoken 和它的 Go 移植：pkoukk/tiktoken-go</li></ul><p>但是这些 tokenizer 在工作时需要知道模型的 tokenizer 配置，而模型提供商大概率不会公布这些数据。不过市面上也有这些私有模型的开源版本，比如 Gemma 之于 Gemini。不知道这些开源版本的 tokenizer 配置和私有的差别有多少，基于它们的 tokenizer 配置和官方的 count token 接口返回结果是否近似。</p><p>如果是自己部署的模型，那么理论上有了 tokenizer 配置就能自己本地做 tokenize，无需依赖一个远程的 tokenizer 服务。</p><p>假设 token usage 不是由本地提供，而是依赖远程的返回结果，出于谨慎起见，最好在基于 token 限额的同时加上基于请求数（或字节数，有的话更好）的限额，这样一旦远端无法返回 token usage，不至于出现完全不设防的情况。</p>]]></description></item><item>    <title><![CDATA[未来应用生态变革趋势探讨 小虫_top ]]></title>    <link>https://segmentfault.com/a/1190000047459352</link>    <guid>https://segmentfault.com/a/1190000047459352</guid>    <pubDate>2025-12-08 20:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>豆包手机助手遭到各方质疑，围绕微信、银行App等与人工智能的对抗成为热议焦点。但我们眼光放长远一些，或许能看到一个更本质的趋势：<strong>未来的应用生态，很可能会从“一个个孤立的产品”逐渐转向“一组组开放的接口”</strong>。</p><p>甚至连App这个概念本身都会慢慢淡化，成为数字发展史上的一个阶段性产物。越来越多的后端服务，应该在经过安全评审之后直接对外开放。面向终端用户的产品形态，也会像今天的阿里云、百度智能云那样——除了依赖固定的界面，也可以通过API的形式提供数据挖掘、图像识别、AI能力等核心功能。<br/><strong>用户无需被既定操作流程束缚</strong>，只需遵循接口规范，就能自主调用、组合这些服务，实现真正个性化的需求。这正是“智能化”走向深水区的体现：<strong>技术不再仅仅是给人用的工具，更成为可被自由调用的“数字积木”</strong>。</p><p>所有人都能感受到近两年大模型的迅猛发展，技术演进的速度远超我们的想象。与其争论“AI是否会取代程序员”，不如看清一个宏观事实：开发一款产品的门槛正在快速降低，周期不断缩短，智能程度持续提高。这意味着，<strong>未来的产品竞争维度必将发生改变</strong>。</p><p>一款优秀的产品，除了需要“直观、简洁、易懂”的人性化交互界面，也必然要提供“开放、安全、高效”的“机性化”可调用接口，这不再是一种选择，而会逐渐成为标配。</p><p>当然，<strong>任何变革都无法一蹴而就</strong>。如果现强行推动这样一场“接口化革命”，对许多依赖现有商业模式的公司来说，无疑会造成巨大冲击，比如现有的广告营收体系，或将面临重构。<strong>但方向已经清晰，新的竞赛其实早已悄然开始</strong>。</p><p>如果今天的独角兽们仍固守封闭的生态思维，执着于现有旧叙事，那么很可能，它们就会成为下一个诺基亚、下一个柯达——<strong>不是败给技术，而是输给了趋势</strong>。</p><p>时代从不停留，而唯一能确定的是：<strong>开放、连接与智能融合，正在重新定义我们与数字世界交互的方式</strong>。</p>]]></description></item><item>    <title><![CDATA[在 Pycharm 中 debug Scrapy 项目 codists ]]></title>    <link>https://segmentfault.com/a/1190000047459002</link>    <guid>https://segmentfault.com/a/1190000047459002</guid>    <pubDate>2025-12-08 19:05:35</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>缘起</h2><p>为什么写这篇文章呢？因为自己想在 Scrapy 项目里 debug, 看看 Response 有哪些属性。但是 Scrapy 的官方文档的 debug 说明只有 VSCode 的，没有 Pycharm 的(详见：<a href="https://link.segmentfault.com/?enc=eBtdfMM8hwzj6h%2BGwrf%2BTw%3D%3D.6sNNIP1co39SaiiTqJF%2B0dt6M5woeG%2FyofyFN%2BAAV3FO26y2ZcBPfMbV62lH%2Fb0OtuaTPAyLtLxUyNzQTQg7LQ%3D%3D" rel="nofollow" target="_blank">https://docs.scrapy.org/en/latest/topics/debug.html</a>)：</p><pre><code>{
    "version": "0.1.0",
    "configurations": [
        {
            "name": "Python: Launch Scrapy Spider",
            "type": "python",
            "request": "launch",
            "module": "scrapy",
            "args": [
                "runspider",
                "${file}"
            ],
            "console": "integratedTerminal"
        }
    ]
}</code></pre><p>当然，如果熟悉 VSCode 的人看到这个配置就明白其实执行方式是：python -m scrapy runspider xxx_spider.py (注：这里的 xxx_spider.py 指 spider 文件，如官方文档里面的 quotes_spider.py)。如果这个人同时还熟悉 Pycharm, 那么他就知道在 Pycharm 里面配置进行 debug：</p><p><img width="723" height="396" referrerpolicy="no-referrer" src="/img/bVdnipG" alt="" title=""/></p><p>很遗憾，我不是这样的人，所以就有了这篇文章。</p><h2>说明</h2><p>时间：2025/12/06</p><p>Pycharm 版本：2025.2.4</p><p>Python 版本：3.12.0</p><p>Scrapy 版本：2.13.4</p><p>Windows 版本：Win 11</p><h2>main.py</h2><p>在与 scrapy.cfg 文件同层级的目录中新建一个名为 main.py 的文件，用于 debug。示例：</p><pre><code># main.py
from scrapy.cmdline import execute


if __name__ == '__main__':
    print(1)
    print(2)
    execute(['scrapy', 'crawl', 'manning'])</code></pre><p>项目结构：</p><p><img width="723" height="234" referrerpolicy="no-referrer" src="/img/bVdnipK" alt="" title="" loading="lazy"/></p><h2>TypeError: 'Task' object is not callable</h2><p>当 Debug'main'时， 出现错误：</p><pre><code>2025-12-06 10:51:15 [asyncio] ERROR: Exception in callback &lt;Task pending name='Task-1' coro=&lt;ExecutionEngine.open_spider() running at D:\Projects\PythonProjects\python-talk\backend\venv\Lib\site-packages\scrapy\core\engine.py:430&gt; cb=[Deferred.fromFuture.&lt;locals&gt;.adapt() at D:\Projects\PythonProjects\python-talk\backend\venv\Lib\site-packages\twisted\internet\defer.py:1255]&gt;()
handle: &lt;Handle &lt;Task pending name='Task-1' coro=&lt;ExecutionEngine.open_spider() running at D:\Projects\PythonProjects\python-talk\backend\venv\Lib\site-packages\scrapy\core\engine.py:430&gt; cb=[Deferred.fromFuture.&lt;locals&gt;.adapt() at D:\Projects\PythonProjects\python-talk\backend\venv\Lib\site-packages\twisted\internet\defer.py:1255]&gt;()&gt;
Traceback (most recent call last):
  File "D:\Apps\Python3.12\Lib\asyncio\events.py", line 84, in _run
    self._context.run(self._callback, *self._args)
TypeError: 'Task' object is not callable</code></pre><p><img width="723" height="145" referrerpolicy="no-referrer" src="/img/bVdnipO" alt="" title="" loading="lazy"/><br/>之所以产生这个问题，不是代码的问题，是 Pycharm debuger 的问题，我还没梳理完，故暂不展开，只讲怎么解决。</p><h2>Debug 方式</h2><h3>方法 1：TWISTED_REACTOR</h3><ol><li>Settings &gt; Python &gt; Debugger，取消 Gevent compitable 的勾选。<br/><img width="723" height="187" referrerpolicy="no-referrer" src="/img/bVdnipP" alt="" title="" loading="lazy"/></li></ol><p>2.在项目的 settings.py 文件里设置 TWISTED_REACTOR = 'twisted.internet.selectreactor.SelectReactor'</p><p><img width="723" height="273" referrerpolicy="no-referrer" src="/img/bVdnipQ" alt="" title="" loading="lazy"/></p><h3>方法 2：python.debug.asyncio.repl</h3><p>1.Settings &gt; Python &gt; Debugger，取消 Gevent compitable 的勾选(这步和方法 1 是一样的)。<br/><img width="723" height="187" referrerpolicy="no-referrer" src="/img/bVdnipP" alt="" title="" loading="lazy"/></p><p>2.双击 Shift 键打开搜索窗口。</p><p>双击 Shift 的意思是“search everywhere，详见 <a href="https://link.segmentfault.com/?enc=q8IEv8FcpgZfiKocEztE2A%3D%3D.D2DsrKtXTM8%2F1uRCX%2FdWDe5DqJvefCJ%2FERPvaKQLD3UiBcFiqFtgagIDwaoMxhUduGkjxsEkyl7hdEZQYc4tNHxRu8sj9mg5osMDHSkuPQo%3D" rel="nofollow" target="_blank">https://www.jetbrains.com/help/pycharm/searching-everywhere.html</a>”。</p><p><img width="723" height="197" referrerpolicy="no-referrer" src="/img/bVdnipR" alt="" title="" loading="lazy"/><br/>3.点击 ALL 选项，输入 registry，最后点击 Regisry 选项。</p><p><img width="723" height="319" referrerpolicy="no-referrer" src="/img/bVdnipS" alt="" title="" loading="lazy"/></p><p>4.找到 python.debug.asyncio.repl，取消勾选 Value 列的方框。 <br/><img width="723" height="431" referrerpolicy="no-referrer" src="/img/bVdnipT" alt="" title="" loading="lazy"/></p><h2>验证</h2><p><img width="723" height="422" referrerpolicy="no-referrer" src="/img/bVdnipU" alt="" title="" loading="lazy"/></p><p>如上图所示，设置后可以 debug。</p><h2>参考资料</h2><p>1.Scrapy 文档, Debugging Spiders: <a href="https://link.segmentfault.com/?enc=iEQOrkid%2B1eoNdACgabyAw%3D%3D.cSxZkF5J7Xp%2BVIiWuz7gf220%2FSq394SZog3jJnu8k4yKwOx7%2BRps5wyiDzj4kO0WhXHqsDkE4e5mtNFg%2FpZ2WA%3D%3D" rel="nofollow" target="_blank">https://docs.scrapy.org/en/latest/topics/debug.html</a></p><p>2.Pycharm 文档，Search for a target by name：<a href="https://link.segmentfault.com/?enc=YyI1Rjbq92AkKo4jaYwFKw%3D%3D.mI97mAjvRoznZLOriWa399OPHYdbtnmZPpZv67xlZ7A5zSo5CranddGipgrYIJfri2CuhXSP2FANyHcFTgzhMOnJWYDJDCPwJxzZbltrnWA%3D" rel="nofollow" target="_blank">https://www.jetbrains.com/help/pycharm/searching-everywhere.html</a><br/><img width="723" height="263" referrerpolicy="no-referrer" src="/img/bVdfTXK" alt="" title="" loading="lazy"/><br/>欢迎搜索及关注：编程人(a_codists)，如有问题请留言。</p>]]></description></item><item>    <title><![CDATA[警惕“上下文污染”：为什么建议你频繁重置 AI 对话？ 飞奔的毛巾 ]]></title>    <link>https://segmentfault.com/a/1190000047459123</link>    <guid>https://segmentfault.com/a/1190000047459123</guid>    <pubDate>2025-12-08 19:05:04</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在使用 LLM 时，我们常遇到“风格漂移”和“逻辑幻觉”。 比如你让 AI 扮演 Python 专家“只写代码不解释”，但因为你中间追问了一次“为什么”，它在后续的回答里就开始喋喋不休地解释。</p><p>这是因为大语言模型的注意力是有限的。 当异质性内容（不同类型的话题）在历史记录中堆积，初始指令的权重就会被不可避免地削弱。</p><p>解决办法：</p><ol><li>一事一议 绝不混用窗口。写代码的窗口别用来写诗，翻译的窗口别用来做数学题。</li><li>物理隔离 任务一旦结束，或者话题一旦转换，立刻关闭当前对话。</li><li>学会“手动垃圾回收” 当你发现 AI 开始不听话，试图通过打字去纠正它（比如“请回到刚才的设定”）通常效果很差，因为这增加更多的噪音。 最高效的方法是：直接开新窗口，重新输入提示词。</li></ol><p>让每一个对话窗口都只为一个明确的目标服务。你会发现，那个“听话、聪明、精准”的AI，又回来了。</p>]]></description></item><item>    <title><![CDATA[SQL Server到Oracle：不同事务机制下的数据一致性挑战 RestCloud ]]></title>    <link>https://segmentfault.com/a/1190000047459136</link>    <guid>https://segmentfault.com/a/1190000047459136</guid>    <pubDate>2025-12-08 19:04:32</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在当今企业数据架构日益复杂的背景下，跨数据库平台的数据同步已成为许多组织的常态化需求。当数据需要从SQL Server迁移至Oracle时，我们不仅面临语法差异的挑战，更需深入理解两大数据库在事务处理机制上的本质区别。本文将深入探讨在异构数据库同步过程中，通过使用ETLCLoud的离线数据集成及实时数据集成功能，确保数据在跨平台传输时的一致性与完整性，为构建可靠的数据流通体系提供实践指导。</p><h3>一、创建数据源连接</h3><p>在平台首页左侧模块菜单栏找到数据源管理模块，下拉选择数据源列表选项。</p><p>右侧面板点击新建数据源按钮创建一个新的数据源连接。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459139" alt="图片 1" title="图片 1"/></p><p>根据自己的数据库类型选择，这里要连接SqlServer。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459140" alt="图片 2" title="图片 2" loading="lazy"/></p><p>根据面板信息填写相关信息，影响能否连接的主要配置有账号、密码、数据库IP端口，注意不能有空格。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459141" alt="图片 1" title="图片 1" loading="lazy"/></p><p>配置完信息后点击保存并测试连接按钮，上方弹出测试成功证明数据库连通。如果连接失败可以到监控中心查看控制台日志。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459142" alt="图片 2" title="图片 2" loading="lazy"/></p><p>再创建一个目标端Oralce的数据源。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459143" alt="图片 1" title="图片 1" loading="lazy"/></p><h3>二、创建离线同步流程</h3><p>在左侧离线数据集成模块找到流程管理，点击新建流程创建一个新的流程。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459144" alt="图片 1" title="图片 1" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459145" alt="图片 2" title="图片 2" loading="lazy"/></p><p>点击流程设计进入流程设计页面。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459146" alt="图片 3" title="图片 3" loading="lazy"/></p><p>从左侧组件栏拖取组件到右侧画布，并用路由线从开始连接到最后。</p><p>这里使用一个库表输入组件从SqlServer表拉取数据，用库表输出组件将数据推送到目标表。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459147" alt="图片 4" title="图片 4" loading="lazy"/></p><p>库表输入配置：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459148" alt="图片 5" title="图片 5" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459149" alt="图片 6" title="图片 6" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459150" alt="图片 7" title="图片 7" loading="lazy"/></p><p>库表输出组件配置：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459151" alt="图片 8" title="图片 8" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459152" alt="图片 9" title="图片 9" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459153" alt="图片 10" title="图片 10" loading="lazy"/></p><p>配置完流程，点击运行按钮运行数据同步任务。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459154" alt="图片 11" title="图片 11" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459155" alt="图片 12" title="图片 12" loading="lazy"/></p><p>等待流程运行，流程运行结束即完成同步任务。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459156" alt="图片 13" title="图片 13" loading="lazy"/></p><p>检查目标表数据</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459157" alt="图片 14" title="图片 14" loading="lazy"/></p><h3>三、实时数据同步</h3><p>离线同步数据后，后续源表如果有增量数据（数据增删改）想要同步到目标表，ETLCloud可以通过采集数据库日志的方式去读取表的增量数据，这样就不必每次同步都读取整张表造成资源的浪费，并且实时数据集成能让源表目标表达到毫秒级的数据一致。</p><p>但是实时数据集成需要对数据库做一下配置，因为主要是采集数据库归档日志，每种数据库开启CDC的步骤不一样，可以到官网帮助文档查看开启方法。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459158" alt="图片 15" title="图片 15" loading="lazy"/></p><p>开启数据库的CDC后，来到实时数据集成模块创建数据库监听器。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459159" alt="图片 16" title="图片 16" loading="lazy"/></p><p>这里源表和目标表表机构一致就采用直接传到到目标的同步方式，如果需要对增量数据做特殊处理可以使用传输到ETL的方式。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459160" alt="图片 17" title="图片 17" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459161" alt="图片 18" title="图片 18" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459162" alt="图片 19" title="图片 19" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459163" alt="图片 20" title="图片 20" loading="lazy"/></p><p>配置好监听器后点击增量启动监听器。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459164" alt="图片 21" title="图片 21" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459165" alt="图片 22" title="图片 22" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459166" alt="图片 23" title="图片 23" loading="lazy"/></p><p>对源表进行数据更改</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459167" alt="图片 24" title="图片 24" loading="lazy"/></p><p>数据库监听器捕获到了源表的变更数据，并且直接将源端的增删改都同步到目标表。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459168" alt="图片 25" title="图片 25" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459169" alt="图片 26" title="图片 26" loading="lazy"/></p><p>检查目标表数据与源表一致。</p><h3>四、最后</h3><p>通过从SQL Server到Oracle的完整同步实践，我们看到在异构数据库环境中维护数据一致性需要系统性的解决方案。无论是离线全量同步还是实时增量同步，关键在于深入理解不同数据库的事务特性，并选择与之匹配的同步策略。ETLCloud通过CDC机制实现了近乎实时的数据同步，有效解决了异构环境下的数据一致性问题。随着企业数据生态的不断发展，掌握跨数据库平台的同步技术将成为数据工程师的核心能力，为构建更加弹性、可靠的数据架构奠定坚实基础。</p>]]></description></item><item>    <title><![CDATA[AI 正在“杀死”敏捷开发？它反而让我们重新读懂敏捷的真谛 悲伤的斑马 ]]></title>    <link>https://segmentfault.com/a/1190000047459203</link>    <guid>https://segmentfault.com/a/1190000047459203</guid>    <pubDate>2025-12-08 19:03:38</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>最近在技术论坛刷到个热门话题：“AI 时代，敏捷开发是不是要凉了？”有人贴出代码生成工具的截图，配文“现在AI 10分钟能写完的代码，还要什么迭代开发？”；也有人悲观预言：“敏捷的核心是‘人’，AI来了，人的价值被稀释了。”</p><p>作为从业8年的产品经理，我亲历过从瀑布模型到敏捷转型的阵痛，也玩过ChatGPT写需求文档、GitHub Copilot生成代码。但越用越觉得：AI不是在替代敏捷，而是在用最直接的方式，把敏捷开发中那些“形式化”的泡沫戳破，逼我们回归最本真的敏捷。</p><p>一、被误解的敏捷：我们早就偏离了初心<br/>先问个问题：你所在的团队，真的在做“敏捷”吗？</p><p>我见过太多“伪敏捷”现场：</p><p>每天站会变成“汇报表演”，15分钟扯皮1小时；<br/>用户故事拆得比分子还细，但没人关心真实需求；<br/>迭代评审会成了“背锅大会”，开发吐槽产品改需求，产品吐槽测试漏bug；<br/>最讽刺的是，有些团队连“敏捷教练”都配齐了，但交付的产品依然离用户十万八千里。<br/>敏捷开发的本质是什么？《敏捷宣言》的四大价值观早就写明白了：<br/>个体与互动 &gt; 流程与工具<br/>可工作的软件 &gt; 全面的文档<br/>客户合作 &gt; 合同谈判<br/>响应变化 &gt; 遵循计划</p><p>但现实中，我们往往把敏捷做成了“流程崇拜”——用Jira看板划分任务状态，用燃尽图证明“我们在敏捷”，用固定两周的迭代周期掩盖对需求的逃避。当敏捷变成一套标准化的SOP，它就已经死了。</p><p>二、AI 来了，先“杀死”的是伪敏捷<br/>现在AI登场了，它最先冲击的，恰恰是这些“形式化敏捷”的痛点。</p><ol><li>代码生成工具：打破“为迭代而迭代”的怪圈<br/>以前我们拆用户故事，总爱把一个功能切成“前端页面”“接口开发”“联调测试”三期，美其名曰“小步快跑”。但AI可以直接生成完整可运行的代码模块，甚至自动补全测试用例。这时候再强行拆解迭代，反而成了效率拖累——敏捷的“快速交付”不是目的，快速验证价值才是。</li><li>需求分析工具：倒逼我们直面真实用户<br/>用AI做用户调研是什么体验？输入“25-30岁一线城市女性，健身爱好者，想通过APP记录饮食”，它能瞬间生成10条用户故事，甚至模拟出使用场景对话。但这些“完美需求”背后，藏着更残酷的真相：如果AI都能替代我们理解用户，那产品经理的核心价值是什么？<br/>答案是：比AI更懂“人”。敏捷强调“客户合作”，但很多团队把“客户”简化成了产品经理自己。AI的出现，逼我们走出办公室，去和真实用户聊天——因为只有人的洞察，才能让需求从“正确”变成“惊艳”。</li><li>自动化测试：让“响应变化”不再昂贵<br/>传统敏捷中，测试是瓶颈：改一行代码可能触发连锁反应，回归测试要花半天。但AI驱动的自动化测试能实时监控代码变更，自动生成测试报告。这意味着什么？我们可以更勇敢地调整需求了——因为试错成本被AI拉低了，敏捷的“响应变化”才能真正落地。</li></ol><p>三、AI 时代，我们需要怎样的敏捷？<br/>说到底，AI不是敏捷的敌人，而是“敏捷升级”的催化剂。它让我们看清：敏捷的核心从来不是“快”，而是“灵活”——灵活地理解需求、灵活地调整方向、灵活地创造价值。</p><p>未来真正稀缺的敏捷团队，会具备这三种能力：</p><ol><li>人类独有的“价值判断力”<br/>AI能生成代码，但判断“这个功能该不该做”“用户会不会买单”的，只能是人。敏捷中的“用户故事”，未来会从“作为XX，我需要XX”变成“作为XX，我愿意为XX付费”——因为AI让试错成本降低，我们可以更聚焦商业价值。</li><li>跨领域的“系统思维”<br/>当AI接管了代码、测试、甚至部分设计工作，团队成员需要跳出单一角色，理解整个产品链路。比如产品经理要懂技术架构，开发要懂用户心理——因为敏捷的“个体与互动”，在AI时代会升级为“多学科碰撞”。</li><li>持续学习的“反脆弱”心态<br/>AI在进化，敏捷团队也必须进化。那些抱着“我懂敏捷流程”吃老本的人，终将被淘汰；但那些把AI当工具、不断拓展能力边界的人，会成为新时代的“敏捷超级个体”。</li></ol><p>最后：敏捷从未过时，过时的是我们对敏捷的想象<br/>20年前，敏捷宣言是对“重型流程”的反叛；20年后，AI是对“形式化敏捷”的反叛。变化的从来不是敏捷本身，而是我们理解敏捷的方式。</p><p>所以下次再有人问你“AI来了，敏捷还重要吗？”，你可以这样回答：<br/>“AI不是在替代敏捷，而是在帮我们撕掉敏捷的‘标签’，回到那个最本质的问题：我们究竟在为什么而敏捷？”</p>]]></description></item><item>    <title><![CDATA[2025年团队知识库与知识管理工具选型指南：评估维度与思维框架 许国栋 ]]></title>    <link>https://segmentfault.com/a/1190000047459231</link>    <guid>https://segmentfault.com/a/1190000047459231</guid>    <pubDate>2025-12-08 19:02:54</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <blockquote>在企业数据驱动转型的过程中，仅靠项目管理、CI/CD、代码仓库工具，往往难以形成系统化的“组织知识资产”。团队知识库成为连接“人—项目—知识—复用”的关键桥梁。本文聚焦主流团队知识库工具，从战略与执行双层视角分析其适用性、优势与局限，并提出“工具之外”的思维框架，帮助中高层研发负责人、PMO、效能管理专家在选型时作出理性决策。</blockquote><h2>为什么知识库建设对现代研发组织至关重要</h2><p>在大型、复杂的 B2B 研发组织中，技术规范、架构设计、需求文档、测试方案、运维流程、项目复盘、新人 onboarding、跨团队协作……这些知识与经验，往往分散在代码仓库、即时通讯、文件共享、项目管理系统、邮件、甚至 “某个老员工脑袋里”。</p><ul><li>这样的分布方式，会导致知识难以检索、沉淀和复用。每当类似问题重复出现，团队无时借鉴，容易“重新造轮子”；</li><li>新员工 onboarding、跨团队合作、知识传承成本高，效率低下；</li><li>当关键人员离职、业务扩展、合规审计、交接与培训出现时，知识流失与风险暴露更为严重。</li></ul><p>研究表明，将组织隐性知识转为显性知识，是企业知识管理的核心任务。</p><p>一个好的知识库，远不应只是“文档存储”的集合——它应该承担组织的“记忆”和“学习”功能。通过结构化、分类、权限、版本控制、搜索、标签／元数据管理、关联项目与任务、与工具链集成、审计与治理机制，一个知识库能真正成为企业的长期知识资产。</p><p>企业实践也表明，系统化知识管理可以显著提升决策效率、减少重复劳动、加速协作、缩短新人成熟周期，并为创新、合规与风险管理提供基础。</p><p>因此，知识库建设，是组织从“项目驱动型”向“能力／资产驱动型”跃迁的重要一步。</p><h2>主流团队知识库工具测评（2025 年终总结）</h2><p>以下是几款当前国内外广泛使用、适合不同发展阶段和组织规模的知识库工具，包括 ONES Wiki、Confluence、GitBook、Tettra、Notion、Nuclino。它们各有定位，没有“万能最优”，关键在于与你组织的阶段、规模、治理水平、战略规划匹配。</p><h4>ONES Wiki——一体化的文档协同和知识库管理工具</h4><p>核心功能：成熟的企业级知识管理平台，能把“文档／知识／经验／流程”组织起来，支持多人协同编辑、版本控制、权限管理、模板机制、与项目/任务管理系统集成、文档关联项目/任务、支持多种内容嵌入（思维导图、代码片段、流程图等）以及内容结构化。支持组织细粒度权限、安全、审计等。</p><p>适用场景：中大型企业、复杂项目 / 多团队协作、有合规／审计／安全要求、需要知识与任务／项目全流程关联、追求长期知识资产积累与治理的组织；尤其适合技术、产品、运维、管理等多角色协作与知识共享。</p><p>优势亮点：<br/>一体化：将知识库与项目任务管理、DevOps／交付流程关联，减少信息孤岛。<br/>权限与治理：支持分类、读写权限、版本控制、模板机制、结构化管理，便于制度化管理与审计。<br/>灵活性与扩展性：支持多种内容类型，可嵌入代码、流程图、表格等，适合复杂业务与混合团队需求。</p><p>【ONES 官网：<a href="https://link.segmentfault.com/?enc=7nrAkJTBvthL7GNMlCAurw%3D%3D.PxOLi5TykxP9YDLaDu%2Fm7gxPs7PVXuQGuMP09wUole8%3D" rel="nofollow" target="_blank">https://ones.cn/</a> 】</p><p><img width="723" height="436" referrerpolicy="no-referrer" src="/img/bVdnirQ" alt="ONES Wiki 文档协同和知识库管理工具" title="ONES Wiki 文档协同和知识库管理工具"/></p><h4>Confluence——稳定的企业级 Wiki</h4><p>核心功能：包括空间（Space）和页面划分、多级页面结构、版本控制、权限管理、模板与蓝本、历史版本、全文搜索、富文本／表格／宏／流程图嵌入等。与项目管理／需求管理工具（如 Jira）在生态中常有集成。</p><p>适用场景：中到大型组织、已有 Atlassian 生态基础、对文档规范、流程文档、制度文档、架构设计、长期技术／管理文档管理有需求；适合文档规范化、流程制度化、需要稳定可靠文档平台的组织。</p><p>优势亮点：<br/>成熟、稳定、功能全面；适合建立系统化文档体系、规范反馈机制、文档审批、审计与版本控制；<br/>与项目管理工具集成，有助于将文档、任务、需求、缺陷等信息统一管理，实现 traceability；<br/>对于技术 / 管理 /制度文档、规范、安全政策文件等，需要严谨格式、统一管理的内容特别适合。</p><p>局限与挑战：<br/>灵活性、现代体验、结构化／数据库式内容支持较弱；不太适合“结构化条目 + 元数据 + 枚举 + 数据 + 文档混合”的复杂知识形式；<br/>对非文档型、快速变化型、需要轻量、快速响应的团队而言，上手和维护成本较高；<br/>如果仅作为“文档仓库”，与项目／交付流程及工具链分离，知识与执行脱节，也降低沉淀和复用价值。<br/>【官网：<a href="https://link.segmentfault.com/?enc=ceKceiEVDqPrL7c7NSWC5A%3D%3D.KNMSujJ39j7dNE650V5Z%2F9PLr5DMk6SjOzqag5Vuj%2Fd%2Br47QHRQiEtBShEBlwawxrzMlJCcOe3%2BVb36g3qxfPQ%3D%3D" rel="nofollow" target="_blank">https://www.atlassian.com/zh/software/confluence</a> 】<br/><img width="723" height="428" referrerpolicy="no-referrer" src="/img/bVdnirR" alt="" title="" loading="lazy"/></p><h4>GitBook—— 开发文档与技术知识库专家</h4><p>核心功能：以 Markdown 为基础的在线文档与知识库平台，支持文档编辑、版本控制、多用户协作、目录／导航结构、全文搜索、导出、历史版本、评论／审核等。适用于技术文档、API 手册、操作手册、对内／对外文档库等维护。</p><p>适用场景：技术团队、产品团队、需要维护 API 文档、技术规范、用户手册、内部／对外技术文档、轻量／中量级文档库的组织。也适合快速搭建文档库、对文档结构有一定规范要求，但对流程／项目管理要求不高的情况。</p><p>优势亮点：<br/>对开发者友好（Markdown + 版本管理 + 与 Git 思维兼容）；<br/>前端简洁、专注文档本身，适合轻量、中量级文档管理；<br/>适合技术文档/规范/说明书等对格式、结构、可读性有要求的内容；易于对外分享。</p><p>局限与挑战：<br/>不具备复杂权限管理、内容治理、版本审批、任务／项目／交付／流程关联、结构化数据管理等能力；<br/>不适合将知识库作为“公司级知识资产管理 + 知识治理 + 持续维护 + 流程闭环”的平台；<br/>【官网：<a href="https://link.segmentfault.com/?enc=5T44I8q5KHLmGX3uIz9TRQ%3D%3D.pkxplMHOQZQnG7EsrPzvrdG4Rnyj5LVUe2CMjviQS7U%3D" rel="nofollow" target="_blank">https://www.gitbook.com/</a> 】<br/><img width="723" height="389" referrerpolicy="no-referrer" src="/img/bVdnirV" alt="" title="" loading="lazy"/></p><h4>Tettra——轻量团队内部知识共享平台</h4><p>核心功能：轻量级团队 Wiki / 知识库平台，强调易用性、快速部署、与协作／沟通工具（例如 Slack）集成、知识 Q&amp;A / FAQ /流程说明、标签／分类、全文搜索、共享与协作。适合快速建立团队内部知识共享机制。</p><p>适用场景：小型／中型团队、初创公司、远程／分布式团队、跨职能协作频繁、需要轻量共享内部经验、流程说明、FAQ、SOP 的场景。适合希望快速搭建知识库并降低维护成本的组织。</p><p>优势亮点：<br/>上手门槛低，部署速度快，适合敏捷、灵活、小规模团队；<br/>与协作 / 沟通工具集成，降低使用门槛，提高知识访问频率；<br/>适合动态知识、经验总结、流程说明、FAQ 等轻量／非结构化内容管理。</p><p>局限与挑战：<br/>权限控制、版本管理、文档生命周期管理、审计、内容结构化、分类／标签治理等能力较弱；<br/>随着团队规模扩大、内容体量增长，容易出现混乱、重复、冗余、难以维护的问题；<br/>难以支撑复杂项目、多团队、多角色、长期知识资产化、治理与合规需求。<br/>【官网：<a href="https://link.segmentfault.com/?enc=9ipp5yXjQEd4FRHOBfJhmQ%3D%3D.rSJKCd4lGSquLt66EoliZOScQc8m8t34nNOcCS8LNYA%3D" rel="nofollow" target="_blank">https://tettra.com/</a> 】<br/><img width="723" height="377" referrerpolicy="no-referrer" src="/img/bVdnirW" alt="" title="" loading="lazy"/></p><h4>Notion——灵活的混合内容与协作空间</h4><p>核心功能：模块化工作空间，包括文档、页面、数据库/表格/看板、页面嵌套、模板、数据库视图、任务管理与内容混合管理。适合文档、数据、任务、协作混合管理。</p><p>适用场景：小型／中型团队、跨职能团队、对灵活性、快速响应、混合内容管理（例如文档 + 数据表 + 流程 +任务）的需求较高的组织；适合研发、产品、设计、运营混合团队；适合快速搭建、迭代、试错。</p><p>优势亮点：<br/>灵活、模块化、高度自定义，能够适应快速变化、需求不确定的业务环境；<br/>支持混合内容（文档 + 数据 +任务 +看板 +流程）；适合多角色、多职能协作团队；<br/>用户友好，界面现代，适合非技术背景的团队成员。</p><p>局限与挑战：<br/>权限治理、结构化治理、审计与合规能力弱，不适合对文档安全性、审批流程、长期维护有严格要求的组织；<br/>随着内容与团队规模扩大，容易出现分类混乱、权限混乱、内容重复与冗余、缺乏结构化治理。<br/>【官网：<a href="https://link.segmentfault.com/?enc=2HpJ2BE0LPa%2Fyr05rScJjg%3D%3D.Vw9w7EdZ9OgLKvhBSljT2or6kvjbCrvsYTaP5%2BgnEE0%3D" rel="nofollow" target="_blank">https://www.notion.com/</a> 】<br/><img width="723" height="474" referrerpolicy="no-referrer" src="/img/bVdnirY" alt="" title="" loading="lazy"/></p><h4>Nuclino——简洁轻量的团队知识库</h4><p>核心功能：轻量团队协作／知识库工具，支持实时协作、多用户编辑、标签／分类、知识图谱／知识关系地图、全文搜索、版本历史、简单结构化与导航。适合构建内部知识库、团队 Wiki、经验共享库。</p><p>适用场景：初创／中小型团队、分布式团队、跨职能协作、希望快速建立知识共享和协作机制、内容体量适中、结构不复杂的组织。</p><p>优势亮点：<br/>界面简洁、上手成本低；适合快速启动知识管理；<br/>支持标签、分类、知识关系图谱／地图，便于知识结构化和关联；<br/>实时协作、多人编辑、快速编辑 / 更新，适合动态、频繁变化的知识内容。</p><p>局限与挑战：<br/>权限控制、内容治理、版本审批、审计、安全合规、长期维护机制缺乏；<br/>对复杂组织结构、多团队、多角色、合规审计、多项目交付的组织支持不足；<br/>【官网：<a href="https://link.segmentfault.com/?enc=D4nS%2BtauHWaaQZ8eW3IRnQ%3D%3D.jfSb63qmV%2FEyqfUZOmyeoltbtVn6V3axvwkEGeGvHz4%3D" rel="nofollow" target="_blank">https://www.nuclino.com/</a> 】<br/><img width="723" height="438" referrerpolicy="no-referrer" src="/img/bVdnir1" alt="" title="" loading="lazy"/></p><h2>从战略视角看：关键维度对比与决策要素</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459233" alt="图片" title="图片" loading="lazy"/></p><h2>工具之外：构建组织知识管理能力的战略框架</h2><p>作为管理者，我建议将知识库建设作为组织战略能力建设的一部分，而不仅仅是工具部署。以下是必须同步建设的能力与机制。</p><h4>知识文化 &amp; 贡献机制 —— 知识不是“写一次就完事”</h4><p>责任与所有权：明确谁负责文档撰写、谁负责审核、谁负责更新／归档。知识不是某个人的副产品，而是组织的资产。</p><p>激励与制度化：通过绩效、考核、奖励机制，鼓励团队贡献与维护文档；将文档／知识产出／更新纳入项目交付／迭代流程 — 即“项目完成 + 文档归档”成为标准步骤。</p><p>标准、模板与规范体系：制定统一文档模板、分类／标签体系、版本管理规则、内容生命周期定义、审查与归档流程。保证文档风格一致、可管理、可检索、易维护。</p><h4>与项目／DevOps／工具链深度融合</h4><p>构建知识 ↔ 流程 ↔ 执行 ↔ 复盘闭环。</p><p>将知识库与代码仓库、CI/CD、测试／发布／运维工具、项目管理系统集成，使经验／方案／决策／复盘／文档与交付流程关联 — 打通“需求 → 设计 → 实施 → 复盘 → 文档／知识沉淀 → 下一轮复用”的闭环。</p><p>确保每个项目、每次交付、每次复盘都有文档与知识沉淀产出，形成可持续的知识积累机制，使知识库真正成为组织基础设施的一部分。</p><h4>数据驱动与知识资产分析 —— 可衡量、可优化</h4><p>对知识库的使用情况（访问频率、文档活跃度、内容覆盖率、过期文档、贡献者分布、更新频率等）进行监控与统计。</p><p>将这些数据与业务 / 项目绩效（交付周期、缺陷率、新人上手速度、重复问题数量等）关联分析，以量化知识库对效率、质量、协作、风险降低等方面的贡献 — 即衡量知识库 ROI。</p><p>基于分析结果，识别知识薄弱领域、制定补充／优化策略、调整文档结构与内容、优化流程与治理机制，推动持续改进。</p><h4>可扩展性 / 未来适应性 —— 为组织长期发展留足弹性</h4><p>随着组织规模增长、团队分布广、业务复杂度提升、合规需求上升、国际化发展，需要支持灵活扩展、模块化治理、多租户／多团队管理、多语言、多地域协作、权限分级、审计合规、知识图谱、多内容类型、移动／云端访问。</p><p>同时，应规划适应未来趋势 — 支持 AI / NLP / 知识图谱 / 智能搜索 / 智能推荐 / 自动分类 / 内容质量检查 / 跨系统同步等能力，使知识库持续进化为“智能知识资产管理平台”。</p><h2>知识库建设，是组织能力建设，而不仅仅是工具部署</h2><p>当下，知识库工具众多，从轻量、灵活、快速部署，到企业级、功能全面、治理规范。关键不在于“哪个工具最流行”，而在于是否与组织的阶段、规模、治理需求、未来规划契合。</p><p>真正能够带来组织效能提升与竞争力增强的，不是某一个好用的工具，而是：</p><ol><li>一个 制度化 + 文化化 的知识贡献与管理机制；</li><li>一个 与项目 / DevOps / 工具链深度融合 的知识闭环体系；</li><li>一个 将知识视为组织资产 的理念体系，具备 数据驱动、可衡量、可治理、可复用、可持续 的知识管理能力；</li><li>一个 具备扩展性与未来适应性 的平台化／架构化布局，为组织长期发展留足空间。</li></ol><p>因此，对于中大型、B2B、业务线复杂、团队多元、强调数据驱动与协同效率的研发组织，应把知识库建设视为战略基础设施 — 把“知识库”当作“知识资产管理 + 组织能力建设”的长期项目来规划。</p><p>与其纠结“今天选择哪个工具”，不如先问自己三个问题：</p><ul><li>我们希望未来的研发组织是什么样子？</li><li>我们希望知识库在未来承载怎样的能力与价值？</li><li>我们是否准备好为知识管理设立制度、流程、责任与文化？</li></ul><p>当你对这些问题有明确答案时，再去选工具、建机制、落实推进 — 将比仅仅选一个“好工具”更具战略价值。</p>]]></description></item><item>    <title><![CDATA[『京墨文库』鸿蒙版上线！ hefengbao ]]></title>    <link>https://segmentfault.com/a/1190000047459251</link>    <guid>https://segmentfault.com/a/1190000047459251</guid>    <pubDate>2025-12-08 19:02:12</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>用了二十多天，边学习边做项目，使用官方提供的 ArkTS、ArkUI、ArkData、ArkWeb、NetworkKit 等技术栈开发的原生 APP，完成了第一个版本的基础功能，相对于 Android 版而言，功能有些单薄，以后一点一点迭代添加了。先发布一个版本，看看使用情况。</p><p>之前使用 Android Jetpack Compose 、 Room 、Datastore(Preference) 等技术实现了 Android 版，对照之下对于 ArkUI、ArkData 等技术理解起来也轻松一点，虽然有些磕磕绊绊，但还是完成了基础的功能。</p><p>申请上架 3 次被驳回，第 4 次终于成功上架华为应用市场，如果使用华为系手机和纯血鸿蒙系统（HarmonyOS  NEXT），感兴趣的话可以下载试一下。</p><p><img width="723" height="222" referrerpolicy="no-referrer" src="/img/bVdnitV" alt="" title=""/></p><p>最低支持的 HarmonyOS 版本选择了 5.1.1(19)，研究了版本变迁列表，这是 HarmonyOS 5 最新的版本，既然都用了 HarmonyOS 5 系统，那升级到最新版也是不错的选择吧😄。</p><p><img width="723" height="414" referrerpolicy="no-referrer" src="/img/bVdnitW" alt="" title="" loading="lazy"/></p><p>项目仍然是开源的：</p><p><a href="https://link.segmentfault.com/?enc=iA0TeZISNnqvM9ri5nuYWA%3D%3D.eaMu4oBFvsYmKeIdUJ4UTelxcHR8jmwDn8%2FcvqsDqolAiJULeX14m70cZWQorIi2zbL%2BN3PWVNxsosjSzi2YAg%3D%3D" rel="nofollow" target="_blank">https://github.com/hefengbao/jingmo-for-HarmonyOS</a></p><p><a href="https://link.segmentfault.com/?enc=qv0ToI6AS54EDKB8hHzlRQ%3D%3D.kFbn3UI8n3DxgluWv87nAmbqUF1yylxvVqwCaKVS96pWGV9AGuc4tY6FZj%2FVMfptBtUnfnpdkl9GO8j1lAUOGA%3D%3D" rel="nofollow" target="_blank">https://gitee.com/hefengbao/jingmo-for-HarmonyOS</a></p><p>另外也附上 Android 版的仓库：</p><p><a href="https://link.segmentfault.com/?enc=57W%2F93L9X0Hj%2Fry7adcUpw%3D%3D.nk1ao%2FQ14kLFyRnqb6J8BSZlsjRbfOL9tAqqxpr7DMgZZoz14m8NLnJcrBeHC3m5" rel="nofollow" target="_blank">https://gihub.com/hefengbao/jingmo</a></p><p><a href="https://link.segmentfault.com/?enc=mGd%2BE%2BB8vI3loAhusZeZeQ%3D%3D.a%2FhBHBqUompydzC%2B8A2TDqx2XzICU4XwpoHo3nYcp%2FBxSPw2TJcNYmR9tziYIGDl" rel="nofollow" target="_blank">https://gitee.com/hefengbao/jingmo</a></p><p>IDE 使用官方提供的 DevEco Studio，模拟器用起来都挺方便。但也遇到过一些问题：</p><p><strong>经检测发现，您的应用使用了HarmonyOS beta版本的API。</strong></p><p>修改建议：为提升消费者使用体验，请使用HarmonyOS release版本的API开发应用，申请上架。请参考版本说明集成release版本API：<a href="https://link.segmentfault.com/?enc=lEty9bw6VUjcTkwAu0LNDw%3D%3D.2D2w1SiZBDOl309DcU%2Fm7EJdS1dqGgkubdvLVCMcwFg4uA17vYNWyxjrBzcOMPmdJ5FHvQkuEEB3n4yjB%2F1Jnun4nzldwpSr3Jpg%2F7%2BFfyGWFrLMiJj8zAZo8d7t0DD%2F" rel="nofollow" target="_blank">https://developer.huawei.com/consumer/cn/doc/harmonyos-releas...</a></p><p>解决：下载使用 release 版本的 IDE</p><p><strong>Navigation 添加了路由后不生效</strong></p><p>点击 “构建” - “清理构建” 后，重新运行项目。</p>]]></description></item><item>    <title><![CDATA[AI 招聘智能体核心功能清单 爱跑步的香蕉_cKtiNz ]]></title>    <link>https://segmentfault.com/a/1190000047459285</link>    <guid>https://segmentfault.com/a/1190000047459285</guid>    <pubDate>2025-12-08 19:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>AI 招聘智能体核心功能清单<br/>AI招聘智能体：重塑招聘决策的智能化变革<br/>传统招聘正逐渐成为企业发展的“隐性天花板”，人才短缺、筛选耗时、复试标准不一、候选人体验不佳等问题频发。与此同时，AI智能体在人力资源管理领域的应用加速渗透，为企业带来降本增效、业务协同、提升员工体验、数据化决策四大核心战略价值，推动招聘行业迎来根本性变革。</p><p>招聘智能化的核心：精准与体验双突破<br/>AI招聘智能体的核心竞争力集中在“精准”与“体验”两大维度，针对性解决传统招聘低效、主观、成本高的核心痛点，成为企业决胜招聘的关键支撑。<br/>精准评估：告别“凭感觉”的科学决策<br/>AI招聘智能体的打分体系经过多重实证验证，不仅能与企业面试官进行一对一“背靠背”比对，还通过效标效度与重测信度双重验证，评估结果可直接作为招聘决策依据，而非单纯的辅助参考。<br/>这种精准性贯穿招聘全环节：<br/>•一问多能，一道题目即可同步评估多项能力，无需HR初筛与技术复试反复衔接，评估效率提升50%以上。<br/>•具备自由追问能力，根据候选人回答生成针对性问题，如同资深面试官般精准捕捉核心能力点。<br/>•自动深度挖掘简历信息，抓取关键亮点与模糊疑点，通过递进式提问杜绝造假行为，同时避免遗漏优质候选人。<br/>•覆盖通用能力与专业领域考察，从沟通协作到编程算法、工程财务等专业技能，均可精准出题评估，大幅减轻HR与专业面试官的工作负担。<br/>体验升级：让面试成为雇主品牌加分项<br/>传统AI面试因机械、生硬的交互模式备受诟病，新一代AI招聘智能体通过“拟人化交互”彻底优化候选人体验：<br/>•能识别候选人的语速、情绪及暗含信息，通过有效引导帮助候选人稳定发挥，展现真实能力。<br/>•自动识别答题状态，无需手动点击操作，全程无打断，营造自然流畅的交流氛围。<br/>•实现语音与口型精准同步，打造沉浸式视觉体验，摆脱“纸片人AI”的刻板印象。<br/>•支持多轮对话答疑，实时回应候选人关于岗位职责、福利待遇、招聘流程等疑问，有效提升入职意愿。<br/>优质的面试体验已不再是附加项，而是企业展示雇主品牌、吸引优质人才的重要竞争力。<br/>从自动化到“自动识人”：招聘全流程智能闭环<br/>AI人才寻访智能体的出现，将招聘流程从单纯的自动化推向“自动识人”的新阶段，构建起完整的智能招聘流水线：<br/>•配置便捷，30-60秒即可启动使用，开启后无需人工值守。<br/>•按年龄、学历、薪资等预设条件自动筛选简历，精准识别符合要求的候选人。<br/>•模拟人类语气与候选人动态沟通，具备提问、交流、筛选淘汰的完整交互能力。<br/>•全覆盖处理未读消息，逐条进行个性化回复，确保沟通无遗漏。<br/>•拟人化交互细节拉满，缺简历时主动请求投递，模仿真实打字节奏交流，增强沟通自然感。<br/>•自动下载简历并上传至企业ATS系统，生成完整候选人档案，同时保障数据流转安全。<br/>这一闭环体系将招聘中的“经验型判断”彻底升级为“数据型决策”，推动招聘流程更科学、更高效。<br/>拥抱AI招聘：把握行业变革机遇<br/>AI技术正在重构招聘行业的底层逻辑，传统依赖人工的招聘模式已难以适应企业快速发展的需求。AI招聘智能体通过精准评估提升招聘质量，通过流程优化降低时间与人力成本，通过体验升级强化雇主品牌，全方位破解传统招聘痛点。<br/>对于企业而言，拥抱招聘智能化已不是可选项，而是在人才竞争中占据优势的必然选择，更是顺应行业发展趋势、突破增长瓶颈的关键举措。</p>]]></description></item>  </channel></rss>