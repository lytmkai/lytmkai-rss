<?xml version="1.0" encoding="UTF-8"?><rss version="2.0">  <channel>      <title>SegmentFault - 最近文章</title>      <link>https://segmentfault.com/blogs/newest</link>      <description>SegmentFault 思否</description>      <generator>python segmentfault.py @Pi20</generator>      <item>    <title><![CDATA[【数据科学】基于时序归因分析的 App ]]></title>    <link>https://segmentfault.com/a/1190000047439394</link>    <guid>https://segmentfault.com/a/1190000047439394</guid>    <pubDate>2025-12-01 01:01:55</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>【数据科学】基于时序归因分析的 App Store 关键词逆向工程方法论</h2><blockquote><strong>摘要</strong>：在移动互联网进入存量博弈的 2025 年，ASO（应用商店优化）已从传统的“热词覆盖”演变为基于数据的精细化工程。本文提出一种结合<strong>竞品情报（CI）</strong>与<strong>时间序列分析</strong>的增长策略：通过监控竞争对手版本迭代（Input）与榜单波动（Output）的因果关系，构建归因模型，逆向推导高权重关键词。文章详细拆解了从数据采集、归因分析到元数据管理的完整技术链路。</blockquote><p><strong>关键词</strong>：<code>数据分析</code> <code>ASO优化</code> <code>归因模型</code> <code>增长黑客</code> <code>逆向工程</code> <code>Appark</code></p><hr/><h3>一、 引言：从“玄学”到“工程学”的转变</h3><p>在移动应用增长（Mobile Growth）领域，很多开发者习惯将 ASO 视为一种运营手段，甚至是一门“玄学”。传统的关键词研究流程通常是：<code>头脑风暴</code> -&gt; <code>热度查询</code> -&gt; <code>覆盖关键词</code> -&gt; <code>等待结果</code>。</p><p>这种线性流程在当前算法环境下存在两个致命缺陷：</p><ol><li><strong>缺乏反馈闭环</strong>：元数据（Metadata）修改后，无法准确归因是哪个词带来了 DAU 的增长。</li><li><strong>数据滞后性</strong>：依赖第三方工具的“热度指数”往往滞后于真实的用户搜索行为。</li></ol><p>作为技术驱动的增长者，我们需要引入<strong>工程思维</strong>。本文将基于专业数据情报工具 <strong>Appark.ai</strong>，介绍一套 <strong>“竞品逆向分析框架”</strong>。其核心逻辑并非“预测用户搜什么”，而是<strong>“复用竞品已经验证成功的策略”</strong>。</p><hr/><h3>二、 步骤一：构建多维度的竞品画像库 (Competitor Mapping)</h3><p>在 App Store 的推荐算法（Collaborative Filtering）逻辑中，竞品的定义不再局限于“功能相似”，而是<strong>“流量重叠”</strong>。为了获取具有统计显著性的样本，我们需要进行降维扫描。</p><h4>1.1 基于“跨类目”的广度扫描</h4><p>利用数据工具的<strong><a href="https://link.segmentfault.com/?enc=D2k6vFye7%2BQo8TeH%2FjoDgw%3D%3D.86hJyezNQb6cyqFxbWh%2FzSA7NpoNOHY1RBu42X597aObK34eYmr26Lm3hIZqG1e2" rel="nofollow" target="_blank">高级搜索 (Advanced Search)</a></strong> 接口，通过参数配置发现潜在的流量掠夺者。</p><ul><li><strong>技术逻辑</strong>：打破 Category 壁垒。</li><li><strong>案例分析</strong>：知名户外应用 <strong>AllTrails</strong> 实际上归类于 <strong>Health &amp; Fitness</strong>。如果你开发的是一款“跑步记录 App”，只关注 Keep 或 Strava 就会出现盲区，因为 AllTrails 正在抢占用户“周末户外运动”的时间片。</li><li><strong>执行策略</strong>：筛选目标 Category 下 Top 50-100 的应用。这部分 App 通常没有头部大厂的品牌溢价，能维持排名全靠硬核的 ASO 策略，是最佳的逆向分析样本。</li></ul><p><img width="723" height="335" referrerpolicy="no-referrer" src="/img/bVdndjF" alt="Appark 高级搜索筛选器：多维度竞品发现" title="Appark 高级搜索筛选器：多维度竞品发现"/><br/><em>图 1：通过多维度过滤器构建竞品样本库</em></p><h4>1.2 基于算法推荐的关联挖掘</h4><p>利用 Apple/Google 的 <code>Similar Apps</code> 推荐算法进行关联挖掘。</p><ul><li><strong>原理</strong>：Item-based Collaborative Filtering。算法判定 App A 和 App B 相似，本质上是因为它们的 <strong>元数据向量（Metadata Vector）</strong> 和 <strong>用户行为特征</strong> 高度重合。</li><li><strong>操作</strong>：直接提取竞品详情页的关联 App 列表，作为关键词挖掘的种子库。</li></ul><hr/><h3>三、 步骤二：搭建自动化监控系统 (Event Monitoring)</h3><p>数据分析的核心价值在于捕捉<strong>变化（Delta）</strong>。我们需要构建一个基于时间序列的监控系统，捕捉关键信号。</p><p><strong>监控核心公式：</strong></p><p>$$ \Delta \text{Metadata (Input)} + \Delta \text{Rank (Output)} \xrightarrow{\text{Time Lag } &lt; 3 \text{ days}} \text{Valid Strategy} $$</p><h4>2.1 建立 Webhook 级别的监控思维</h4><p>建议对核心竞品开启以下两类 Alert，建立类似 Webhook 的触发机制：</p><ol><li><strong>Version Updates (Input)</strong>：监控 Title, Subtitle, Description 的文本 Diff。</li><li><strong>Rank Fluctuations (Output)</strong>：监控 Category Rank 和 Keyword Rank 的异常跳变。</li></ol><blockquote><em>工具支持：<a href="https://link.segmentfault.com/?enc=yAbYlef5KEYVUbOSizzbHQ%3D%3D.ngu4u4%2F%2F%2Bnt3UyEd88NyyNTCnaFQ4oRCTufKVPPVgGGx9YDit6ZkHPewsaitBGRi" rel="nofollow" target="_blank">Appark Monitoring Dashboard</a></em></blockquote><p><img width="723" height="483" referrerpolicy="no-referrer" src="/img/bVdndjE" alt="Appark 自动化监控配置面板" title="Appark 自动化监控配置面板" loading="lazy"/><br/><em>图 2：配置自动化监控流</em></p><hr/><h3>四、 步骤三：归因分析——逆向推导实战</h3><p>这是本指南最核心的<strong>数据归因（Attribution）</strong>环节。我们需要在时间轴上建立“动作”与“结果”的强相关性。</p><h4>3.1 案例复盘：AllTrails 的增长策略逆向</h4><p><strong>数据信号</strong>：<br/>监控系统捕捉到竞品 <strong>AllTrails</strong> 在 <strong>2025 年 6 月初</strong> 的一次异常信号。</p><h5>Phase 1: 输入端分析 (Input)</h5><ul><li><strong>Event</strong>：发布版本 <code>v15.2</code>。</li><li><p><strong>Diff Log</strong>：</p><ul><li>Added Feature: "AllTrails Peak" (高级会员)。</li><li>Key Terms Extracted: <code>Plan ahead</code> (提前规划), <code>Heatmaps</code> (热力图), <code>Offline maps</code> (离线地图)。</li></ul></li></ul><h5>Phase 2: 输出端验证 (Output)</h5><p>调取竞品的时间序列趋势图，观察窗口期内的 <strong>Downloads</strong> 曲线。</p><p><img width="723" height="257" referrerpolicy="no-referrer" src="/img/bVdndjD" alt="竞品下载量趋势图分析" title="竞品下载量趋势图分析" loading="lazy"/><br/><em>图 3：版本更新与下载量激增的时序关联</em></p><ul><li><strong>观察 (Observation)</strong>：版本发布后 72 小时内，下载量曲线出现明显的 <strong>Spike (尖峰)</strong>，并稳定在新的 <strong>Baseline (基线)</strong>（由 70w/月 提升至 90w/月）。</li><li><strong>结论 (Conclusion)</strong>：该增长与“高级路线规划”相关关键词的覆盖呈<strong>强正相关</strong>。这不是运气，是经过市场验证的高转化需求。</li></ul><hr/><h3>五、 步骤四：工程化落地——关键词 JSON 管理</h3><p>基于上述分析，我们不再进行随机测试，而是进行策略移植。建议使用 JSON 结构或数据库思维来管理你的 ASO 关键词资产，以便后续进行 A/B Test。</p><h4>4.1 关键词意图提取 (Intent Extraction)</h4><p>从竞品的成功中提取用户的高意图（High Intent）需求：</p><ul><li><strong>User Story</strong>: "我想规划徒步路线" $\rightarrow$ <strong>Keywords</strong>: <code>Hiking route planner</code>, <code>Trail map</code>.</li><li><strong>User Story</strong>: "我怕山里没信号" $\rightarrow$ <strong>Keywords</strong>: <code>Offline trail maps</code>, <code>GPS tracker</code>.</li></ul><h4>4.2 建立结构化的元数据 JSON</h4><p>为了方便版本管理，建议建立如下的关键词 backlog 结构：</p><pre><code class="json">{
  "aso_strategy_v1": {
    "target_audience": "Advanced Hikers",
    "source_competitor": "AllTrails",
    "validation_data": "Appark_Trend_June_2025",
    "metadata_structure": {
      "title": {
        "content": "Hiking &amp; Trail Maps",
        "weight": "High",
        "keywords": ["Hiking", "Trail", "Maps"]
      },
      "subtitle": {
        "content": "Offline Route Planner &amp; GPS",
        "weight": "Medium",
        "keywords": ["Offline", "Route Planner", "GPS"]
      },
      "keyword_field": [
        "trekking", "topo maps", "custom routes", "heatmaps", "outdoor navigation"
      ]
    }
  }
}</code></pre><p><em>在实际操作中，将上述 JSON 中的 <code>keywords</code> 填入 App Store Connect 的对应字段即可。</em></p><hr/><h3>六、 总结</h3><p>ASO 本质上是一场<strong>信息不对称</strong>的博弈。通过 <strong>Appark</strong> 的数据可视化能力，我们将 ASO 流程标准化为一个科学闭环：</p><ol><li><strong>Discover</strong>：利用高级搜索进行全域扫描。</li><li><strong>Monitor</strong>：自动化追踪版本迭代与榜单变化。</li><li><strong>Analyze</strong>：通过时序分析进行增长归因。</li><li><strong>Implement</strong>：基于验证策略进行工程化落地。</li></ol><p>拒绝盲猜，让数据成为你增长引擎的燃料。</p><hr/><h4>参考资料与工具</h4><p>为了方便技术复现，文中涉及的数据源及官方文档整理如下：</p><ul><li><p><strong>数据采集与分析</strong>：</p><ul><li><a href="https://link.segmentfault.com/?enc=nioWe%2F89B5%2Fcbk7fz5GT6Q%3D%3D.Kt927K%2B1snyr3oRPq16QWhHgDXYjtHfmYZM3%2BsyDFZ4CJH4PzrcX%2BDYJYNY%2FSMV2" rel="nofollow" target="_blank">Appark Intelligence - Advanced Search</a></li><li><a href="https://link.segmentfault.com/?enc=gHqJOFQ0LezOTxIm9mYvmQ%3D%3D.7jkYk4ZrdQUzsD5UNfJ21EuHAWi2BWdHD39urZNmChqr9GwjYOIThaZYO8lliSNV" rel="nofollow" target="_blank">Competitor Trend &amp; Attribution Dashboard</a></li></ul></li><li><p><strong>官方开发文档</strong>：</p><ul><li><a href="https://link.segmentfault.com/?enc=GK%2BLAFxxFfvmKHV85JvQNg%3D%3D.2T0DrqgPxdG3EP8JgPosMMiJjZIBffArdqUqbqMNKZZP%2Fzeik3%2BVoKD6FlM8sre1" rel="nofollow" target="_blank">Apple Developer: App Store Search Algorithm</a></li><li><a href="https://link.segmentfault.com/?enc=jIOFiar3kdwZIbz37MWN4A%3D%3D.q%2B0zOmuDsUXBa9n7yMQfD7BVJKxPYRiilYLhGl%2FgNuUmglGJoYVFfIz6mOqXbBPbq5FAB7ZHlSJdXSj%2BaxtxORf9GY5ost%2B4BxJsUsSUt0A%3D" rel="nofollow" target="_blank">Google Play: Store Listing Experiments</a></li></ul></li></ul>]]></description></item><item>    <title><![CDATA[『NAS』获取绿联NAS默认壁纸 德育处]]></title>    <link>https://segmentfault.com/a/1190000047439505</link>    <guid>https://segmentfault.com/a/1190000047439505</guid>    <pubDate>2025-12-01 01:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><strong>点赞 + 关注 + 收藏 = 学会了</strong></p><p>壁纸已经成为我们生活中必不可少的一部分了，大多数有界面的电子产品都有壁纸，绿联的NAS也不例外。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047439507" alt="" title=""/></p><p>绿联NAS的壁纸只能设置在NAS的桌面，如果想拿出来其他地方用还得手动抓取。</p><p>首先在浏览器输入你的绿联IP地址。</p><p>然后按 <code>F12</code> 打开浏览器的控制台，切换到 <code>Network</code>，在筛选项里选择 <code>Img</code>。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047439508" alt="" title="" loading="lazy"/></p><p>然后按一下键盘的F5，或者用鼠标点一下浏览器的刷新按钮，刷新一下页面。</p><p>就会看到wallpaper这个文件，这就是当前你设置的壁纸文件。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047439509" alt="" title="" loading="lazy"/></p><p>双击该文件就会在浏览器新窗口打开它。右键，点击保存就能获取到这张壁纸。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047439510" alt="" title="" loading="lazy"/></p><p>想要获取其他默认壁纸的话，可以右键绿联NAS桌面空白处，点击“个性化设置 - 更改壁纸 - 默认壁纸”里修改。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047439511" alt="" title="" loading="lazy"/></p><p>在修改完壁纸后你会发现URL里有这个数字。</p><p>没错，这就是壁纸的序号，你只要修改这个数字就会得到其他壁纸。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047439512" alt="" title="" loading="lazy"/></p><p>以下是绿联NAS的默认壁纸，一共18张，需要的自取～</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047439513" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047439514" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047439515" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047439516" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047439517" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047439518" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047439519" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047439520" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047439521" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047439522" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047439523" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047439524" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047439525" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047439526" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047439527" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047439528" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047439529" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047439530" alt="" title="" loading="lazy"/></p><hr/><p>以上就是本文的全部内容啦，想了解更多NAS玩法可以关注<a href="https://link.segmentfault.com/?enc=ioSKlw7PygLVbFvNv%2BWZeg%3D%3D.pFk4ulgug9cI%2F8VKo1ecpikmJGdAYBshPrIk%2B5JOm1cxOk9BrkSAk7vj%2Bxzw7afn6zhFAJUn7OoK96yetT6s9f8Rm3AaeZwp6qkoL%2F5zbktYcC0V4FSK1yTlVMxyFTzi2RLlofKIVdRjb0X6r2wRVvxX2eM4o8qUPCbGzSzpREA%3D" rel="nofollow" target="_blank">《NAS邪修》</a></p><p><strong>点赞 + 关注 + 收藏 = 学会了</strong></p>]]></description></item><item>    <title><![CDATA[基于Rokid Glasses的AI助盲]]></title>    <link>https://segmentfault.com/a/1190000047439383</link>    <guid>https://segmentfault.com/a/1190000047439383</guid>    <pubDate>2025-12-01 00:03:57</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>基于Rokid Glasses的AI助盲应用实践：让科技点亮视障者的世界</h2><p><img width="723" height="410" referrerpolicy="no-referrer" src="/img/bVdndjn" alt="image.jpg" title="image.jpg"/></p><h3>一、项目背景与意义</h3><p>在人工智能技术快速发展的今天，AI智能眼镜作为AI与现实世界交互的重要载体，正在改变我们的生活方式。对于视障人群而言，如何通过技术手段帮助他们更好地感知和理解周围环境，是一个具有重要社会意义的课题。华为手机推出的"小艺看世界"功能，通过AI图像识别帮助用户了解周围环境，这给了我们很大的启发。然而，小艺看世界是在手机上实现的，对于视障用户来说存在明显的不友好之处，需要拿出手机、打开应用、对准目标、按下拍照按钮，整个过程需要双手操作，对于视障用户来说非常困难。</p><p>Rokid Glasses作为AI智能眼镜，天然适合视障辅助应用，眼镜佩戴在头上，无需手持设备，可以在任何场景下使用，而且摄像头位置与眼睛位置一致，拍摄角度更自然，识别更准确。基于这个思路，使用<strong>Rokid Glasses</strong>和<strong>Rokid CXR-M SDK</strong>，开发了一款AI助盲应用"盲导"，通过语音指令触发拍照、AI图像识别和TTS语音播报，帮助视障用户识别周围环境、寻找物品、认路导航等，让科技真正服务于特殊人群的需求。</p><h3>二、技术架构设计</h3><h4>2.1 整体架构</h4><p>本项目采用<strong>手机端+眼镜端</strong>协同工作的架构模式：</p><pre style="display:none;"><code class="mermaid">graph TB
    subgraph Glasses["Rokid Glasses (眼镜端)"]
        A1[AI按键]
        A2[录音功能]
        A3[拍照功能]
        A4[TTS播放]
        A5[显示反馈]
    end
    
    subgraph Phone["Android手机 (手机端)"]
        B1[UI界面]
        B2[蓝牙管理]
        B3[设备绑定管理]
        B4[AI事件监听]
        B5[录音管理]
        B6[ASR和意图识别]
        B7[场景解析服务]
        B8[业务逻辑控制]
    end
    
    subgraph Cloud["云端服务"]
        C1[ASR服务&lt;br/&gt;语音识别]
        C2[意图识别服务]
        C3[场景解析服务&lt;br/&gt;AI图像分析]
    end
    
    A1 --&gt;|AI按键事件| B4
    B4 --&gt;|onAiKeyDown| B5
    B5 --&gt;|开始录音| A2
    A2 --&gt;|音频流数据| B5
    B4 --&gt;|onAiKeyUp| B5
    B5 --&gt;|停止录音| A2
    B5 --&gt;|录音数据| B6
    B6 --&gt;|发送音频| C1
    C1 --&gt;|识别文本| B6
    B6 --&gt;|文本| C2
    C2 --&gt;|意图类型| B6
    B6 --&gt;|意图判断| B8
    B8 --&gt;|拍照指令| A3
    A3 --&gt;|照片数据| B7
    B7 --&gt;|上传照片| C3
    C3 --&gt;|场景描述| B7
    B7 --&gt;|描述文本| B8
    B8 --&gt;|TTS文本| A4
    B2 &lt;--&gt;|蓝牙双向通信| A1
    B2 &lt;--&gt;|蓝牙双向通信| A2
    B2 &lt;--&gt;|蓝牙双向通信| A3
    B3 --&gt;|设备绑定信息| B2
    
    style Glasses fill:#e1f5ff
    style Phone fill:#fff4e1
    style Cloud fill:#ffe1f5</code></pre><h4>2.2 核心模块</h4><p>手机端提供了Android SDK，基于Android APP的开发方式开发手机端，作为Glasses端与云端AI的中介。</p><h6>2.2.1  工程整体结构</h6><p>项目核心类代码如下：</p><pre><code>app/src/main/java/com/qingkouwei/rokidclient2/
├── MainActivity.kt                    # 主Activity，应用入口
├── MainViewModel.kt                   # 主业务逻辑ViewModel
├── DeviceBindingActivity.kt           # 设备绑定页面
├── DeviceBindingViewModel.kt          # 设备绑定逻辑
│
├── BluetoothHelper.kt                 # 蓝牙扫描和发现
├── RokidConnectionManager.kt          # Rokid SDK连接封装
├── DeviceBindingManager.kt            # 设备绑定信息持久化
│
├── AIEventListenerManager.kt           # AI事件监听管理
├── AudioRecordManager.kt              # 录音管理
├── ASRIntentService.kt                # ASR和意图识别
├── SceneAnalysisService.kt            # 场景解析服务
├── TTSManager.kt                      # TTS语音播报管理
│
├── PhotoCaptureManager.kt            # 拍照功能封装
├── AIImageAnalyzer.kt                 # AI图像分析（可选）
└── RokidSDKStub.kt                    # SDK接口桩（开发环境）</code></pre><h6>2.2.2 核心模块介绍</h6><h6>2.2.2.1 设备绑定模块</h6><p><strong>DeviceBindingManager.kt</strong> - 设备绑定信息管理</p><ul><li>使用SharedPreferences持久化保存设备绑定信息</li><li>管理设备名称、地址、socketUuid、macAddress</li><li>提供设备绑定状态检查接口</li></ul><p><strong>DeviceBindingActivity.kt</strong> - 设备绑定UI</p><ul><li>扫描周边Rokid设备</li><li>显示设备列表供用户选择</li><li>处理设备绑定和连接流程</li></ul><p><strong>BluetoothHelper.kt</strong> - 蓝牙扫描管理</p><ul><li>使用UUID <code>0000be80-0000-1000-8000-00805f9b34fb</code>过滤Rokid设备</li><li>支持已配对设备和扫描发现设备</li><li>完整的权限管理和蓝牙状态监听</li></ul><h6>2.2.2.2 连接管理模块</h6><p><strong>RokidConnectionManager.kt</strong> - Rokid SDK连接封装</p><ul><li>封装<code>initBluetooth()</code>和<code>connectBluetooth()</code>调用</li><li>统一连接回调处理</li><li>支持自动重连机制</li></ul><h6>2.2.2.3 AI交互模块</h6><p><strong>AIEventListenerManager.kt</strong> - AI事件监听</p><ul><li>设置和取消AI事件监听器</li><li>处理<code>onAiKeyDown</code>、<code>onAiKeyUp</code>、<code>onAiExit</code>事件</li></ul><p><strong>AudioRecordManager.kt</strong> - 录音管理</p><ul><li>管理<code>openAudioRecord()</code>和<code>closeAudioRecord()</code>调用</li><li>通过<code>AudioStreamListener</code>收集音频流数据</li><li>返回完整的录音数据</li></ul><h6>2.2.2.4 业务处理模块</h6><p><strong>ASRIntentService.kt</strong> - ASR和意图识别</p><ul><li>处理语音识别（调用云端ASR能力）</li><li>识别用户意图（拍照、导航等）</li><li>返回识别文本和意图类型</li></ul><p><strong>SceneAnalysisService.kt</strong> - 场景解析</p><ul><li>分析照片场景（调用云端大模型解析图片内容）</li><li>生成适合视障用户理解的描述文本</li></ul><p><strong>TTSManager.kt</strong> - TTS语音播报</p><ul><li>使用<code>sendTTSContent()</code>发送文本到眼镜端</li><li>处理TTS播放状态回调</li><li>管理播放完成和错误处理</li></ul><h6>2.2.2.5 业务逻辑控制模块</h6><p><strong>MainViewModel.kt</strong> - 主业务逻辑</p><ul><li>协调各模块工作</li><li>处理设备自动连接</li><li>实现完整的AI交互流程：录音 → ASR → 意图识别 → 拍照 → 场景解析 → TTS播报</li></ul><h4>2.3 完整工作流程</h4><h5>步骤1：应用启动和设备绑定</h5><pre><code class="kotlin">// MainActivity.kt
class MainActivity : ComponentActivity() {
    override fun onCreate(savedInstanceState: Bundle?) {
        super.onCreate(savedInstanceState)
        
        val bindingManager = DeviceBindingManager(this)
        
        // 检查设备是否已绑定
        if (!bindingManager.isDeviceBound()) {
            // 未绑定，跳转到绑定页面
            val intent = Intent(this, DeviceBindingActivity::class.java)
            startActivity(intent)
            finish()
            return
        }
        
        // 已绑定，自动连接
        viewModel.autoConnect(bindingManager, bluetoothHelper)
    }
}</code></pre><p><strong>绑定流程</strong>：</p><ol><li>首次安装时，检查设备绑定状态</li><li>未绑定则跳转到设备绑定页面</li><li>扫描周边Rokid设备（使用UUID过滤）</li><li>用户选择设备并绑定</li><li>连接成功后保存设备信息（名称、地址、socketUuid、macAddress）</li><li>跳转到主页面</li></ol><p><strong>自动连接流程</strong>：</p><ol><li>应用启动时检查是否已绑定设备</li><li>从SharedPreferences读取绑定信息</li><li>查找已配对设备或使用保存的连接信息</li><li>调用<code>connectBluetooth()</code>建立连接</li><li>连接成功后设置AI事件监听</li></ol><h5>步骤2：设置AI事件监听</h5><pre><code class="kotlin">// MainViewModel.kt
private fun setupAIEventListener() {
    aiEventListenerManager.setAIEventListener(
        object : AIEventListenerManager.AIEventListenerCallback {
            override fun onAiKeyDown() {
                // AI按键按下，开始录音
                startRecording()
            }

            override fun onAiKeyUp() {
                // AI按键释放，停止录音并处理
                stopRecordingAndProcess()
            }

            override fun onAiExit() {
                // AI场景退出
            }
        },
        set = true
    )
}</code></pre><h5>步骤3：录音处理</h5><pre><code class="kotlin">// MainViewModel.kt
private fun startRecording() {
    audioRecordManager.startRecording(
        object : AudioRecordManager.AudioRecordCallback {
            override fun onRecordingStarted() {
                updateStatus("正在录音...")
            }
        }
    )
}

private fun stopRecordingAndProcess() {
    viewModelScope.launch {
        val audioData = audioRecordManager.stopRecording()
        if (audioData != null &amp;&amp; audioData.isNotEmpty()) {
            processRecordedAudio(audioData)
        }
    }
}

//AudioRecordManager.kt
fun startRecording(callback: AudioRecordCallback) {  
    this.callback = callback  
      
    // Set audio stream listener  
    CxrApi.getInstance().setAudioStreamListener(audioStreamListener)  
      
    // Open audio record  
    val status = CxrApi.getInstance().openAudioRecord(CODEC_TYPE_OPUS, STREAM_TYPE)  
    if (status == ValueUtil.CxrStatus.REQUEST_SUCCEED) {  
        Log.d(TAG, "Audio recording started")  
    } else {  
        Log.e(TAG, "Failed to start audio recording: $status")  
        callback.onError("Failed to start recording: $status")  
    }  
}  
  
/**  
 * Stop recording */suspend fun stopRecording(): ByteArray? = withContext(Dispatchers.IO) {  
    if (!isRecording) {  
        Log.w(TAG, "Not recording, cannot stop")  
        // Remove audio stream listener  
        CxrApi.getInstance().setAudioStreamListener(null)  
        return@withContext null  
    }  
  
    // Close audio record  
    val status = CxrApi.getInstance().closeAudioRecord(STREAM_TYPE)  
      
    // Remove audio stream listener  
    CxrApi.getInstance().setAudioStreamListener(null)  
      
    if (status == ValueUtil.CxrStatus.REQUEST_SUCCEED) {  
        isRecording = false  
        // Get recorded audio data  
        val audioData = audioDataBuffer.toByteArray()  
        recordedAudioData = audioData  
        audioDataBuffer.reset()  
          
        Log.d(TAG, "Audio recording stopped, data size: ${audioData.size}")  
        callback?.onRecordingStopped(audioData)  
        return@withContext audioData  
    } else {  
        Log.e(TAG, "Failed to stop audio recording: $status")  
        callback?.onError("Failed to stop recording: $status")  
        return@withContext null  
    }  
}</code></pre><p><strong>录音流程</strong>：</p><ol><li><code>onAiKeyDown</code>事件触发，调用<code>openAudioRecord()</code></li><li>设置<code>AudioStreamListener</code>接收音频流数据</li><li>持续收集音频数据到Buffer</li><li><code>onAiKeyUp</code>事件触发，调用<code>closeAudioRecord()</code></li><li>返回完整的录音数据</li></ol><h5>步骤4：ASR和意图识别</h5><pre><code class="kotlin">// MainViewModel.kt
private fun processRecordedAudio(audioData: ByteArray) {
    viewModelScope.launch {
        asrIntentService.processAudio(
            audioData,
            object : ASRIntentService.ASRCallback {
                override fun onSuccess(result: ASRIntentService.ASRResult) {
                    // 发送ASR结果到眼镜端显示
                    CxrApi.getInstance().sendAsrContent(result.text)
                    CxrApi.getInstance().notifyAsrEnd()
                    
                    // 根据意图执行相应操作
                    when (result.intent) {
                        ASRIntentService.IntentType.PHOTO -&gt; {
                            handlePhotoIntent()
                        }
                        ASRIntentService.IntentType.UNKNOWN -&gt; {
                            // 未识别意图
                            CxrApi.getInstance().notifyAsrError()
                        }
                    }
                }
            }
        )
    }
}</code></pre><p><strong>ASR和意图识别流程</strong>：</p><ol><li>将录音数据发送到ASR服务（当前为模拟实现）</li><li>获取识别文本</li><li>将文本发送到意图识别服务</li><li>获取意图类型（拍照、导航等）</li><li>将识别文本发送到眼镜端显示</li><li>根据意图执行相应操作</li></ol><h5>步骤5：拍照和场景解析</h5><pre><code class="kotlin">// MainViewModel.kt
private fun handlePhotoIntent() {
    viewModelScope.launch {
        // 打开相机
        CxrApi.getInstance().openGlassCamera(1920, 1080, 80)
        
        // 拍照
        CxrApi.getInstance().takeGlassPhoto(
            1920, 1080, 80,
            object : PhotoResultCallback {
                override fun onPhotoResult(status: ValueUtil.CxrStatus?, photo: ByteArray?) {
                    if (status == ValueUtil.CxrStatus.RESPONSE_SUCCEED &amp;&amp; photo != null) {
                        // 分析场景
                        analyzeSceneAndSpeak(photo)
                    }
                }
            }
        )
    }
}</code></pre><p><strong>拍照流程</strong>：</p><ol><li>调用<code>openGlassCamera()</code>打开眼镜端相机</li><li>调用<code>takeGlassPhoto()</code>触发拍照</li><li>照片以WebP格式通过蓝牙传输</li><li><code>PhotoResultCallback.onPhotoResult()</code>回调接收照片数据</li></ol><h5>步骤6：场景解析和TTS播报</h5><pre><code class="kotlin">// MainViewModel.kt
private fun analyzeSceneAndSpeak(photoData: ByteArray) {
    viewModelScope.launch {
        sceneAnalysisService.analyzeScene(
            photoData,
            object : SceneAnalysisService.AnalysisCallback {
                override fun onSuccess(description: String) {
                    // 发送TTS内容到眼镜端播放
                    CxrApi.getInstance().sendTtsContent(
                        description,
                        object : TTSStatusCallback {
                            override fun onTTSStart() {
                                // TTS开始播放
                            }
                            
                            override fun onTTSEnd() {
                                // TTS播放完成
                            }
                            
                            override fun onTTSError(errorCode: Int) {
                                // TTS播放失败
                            }
                        }
                    )
                }
            }
        )
    }
}</code></pre><p><strong>场景解析和TTS流程</strong>：</p><ol><li>将照片数据发送到场景解析服务（当前为模拟实现）</li><li>AI模型分析场景，生成描述文本</li><li>调用<code>sendTtsContent()</code>发送文本到眼镜端</li><li>眼镜端TTS引擎合成语音并播放</li><li>用户听到场景描述</li></ol><h4>2.4 完整流程时序图</h4><pre style="display:none;"><code class="mermaid">sequenceDiagram
    participant User as 用户
    participant App as 应用
    participant Binding as 设备绑定
    participant Connect as 连接管理
    participant Glasses as Rokid Glasses
    participant AIEvent as AI事件监听
    participant Record as 录音管理
    participant ASR as ASR服务
    participant AI as 场景解析
    participant TTS as TTS播报
    
    Note over App: 应用启动
    App-&gt;&gt;Binding: 检查设备绑定状态
    alt 未绑定
        App-&gt;&gt;App: 跳转绑定页面
        App-&gt;&gt;Glasses: 扫描设备
        User-&gt;&gt;App: 选择设备
        App-&gt;&gt;Connect: 连接设备
        Connect-&gt;&gt;Glasses: initBluetooth + connectBluetooth
        Connect-&gt;&gt;Binding: 保存绑定信息
    else 已绑定
        App-&gt;&gt;Connect: 自动连接
        Connect-&gt;&gt;Glasses: 使用保存信息连接
    end
    
    Connect-&gt;&gt;AIEvent: 设置AI事件监听
    AIEvent-&gt;&gt;Glasses: setAiEventListener(true)
    
    Note over User,TTS: 用户交互流程
    User-&gt;&gt;Glasses: 按下AI按键
    Glasses-&gt;&gt;AIEvent: onAiKeyDown
    AIEvent-&gt;&gt;Record: 开始录音
    Record-&gt;&gt;Glasses: openAudioRecord
    Glasses-&gt;&gt;Record: 音频流数据
    
    User-&gt;&gt;Glasses: 释放AI按键
    Glasses-&gt;&gt;AIEvent: onAiKeyUp
    AIEvent-&gt;&gt;Record: 停止录音
    Record-&gt;&gt;ASR: 发送录音数据
    ASR-&gt;&gt;ASR: 语音识别
    ASR-&gt;&gt;ASR: 意图识别
    ASR--&gt;&gt;Record: 返回意图(拍照)
    
    Record-&gt;&gt;Glasses: openGlassCamera
    Record-&gt;&gt;Glasses: takeGlassPhoto
    Glasses-&gt;&gt;AI: 照片数据
    AI-&gt;&gt;AI: 场景分析
    AI--&gt;&gt;Record: 场景描述
    Record-&gt;&gt;Glasses: sendTtsContent
    Glasses-&gt;&gt;User: 播放场景描述</code></pre><h3>三、实际应用场景演示</h3><h4>3.1 场景一：识别道路环境</h4><p><strong>用户需求</strong>：盲人需要了解前方道路情况，判断是否可以安全行走</p><p><strong>工作流程</strong>：</p><ol><li>用户说："帮我看看前面的路"</li><li>应用触发拍照，获取前方道路图像</li><li>AI分析："前方是一条宽约2米的人行道，路面平整，右侧有盲道，左侧有绿化带，前方约10米处有一个垃圾桶，建议靠右行走"</li><li>通过TTS播放给用户</li></ol><p><strong>技术要点</strong>：</p><ul><li>使用Rokid SDK的<code>openGlassCamera()</code>和<code>takeGlassPhoto()</code>获取道路图像</li><li>AI提示词重点强调道路宽度、障碍物、安全提示等信息</li><li>描述语言简洁明确，便于盲人理解</li></ul><h4>3.2 场景二：寻找丢失物品</h4><p><strong>用户需求</strong>：在房间内寻找丢失的钥匙</p><p><strong>工作流程</strong>：</p><ol><li>用户说："帮我找找钥匙"</li><li>应用拍照识别房间环境</li><li>AI分析："在视野中，我看到一个茶几，茶几上有一串银色的钥匙，位置在茶几中央偏左，距离你约3米"</li><li>用户根据描述找到钥匙</li></ol><p><strong>技术要点</strong>：</p><ul><li>多轮对话：先整体描述，再聚焦特定物品</li><li>位置描述使用相对位置（前后左右）和距离</li><li>物品特征描述（颜色、大小、形状）帮助识别</li></ul><h4>3.3 场景三：阅读文字信息</h4><p><strong>用户需求</strong>：识别门牌号或路牌</p><p><strong>工作流程</strong>：</p><ol><li>用户说："帮我看看这个门牌号"</li><li>应用拍照识别</li><li>AI分析："门牌上写着：北京市朝阳区某某路123号"</li><li>清晰朗读给用户</li></ol><p><strong>技术要点</strong>：</p><ul><li>使用GPT-4o Vision的强大文字识别能力</li><li>按顺序朗读，避免信息混乱</li><li>支持中英文混合识别</li></ul><h3>四、开发心得与总结</h3><h4>4.1 Rokid SDK使用体验</h4><p>通过本项目的开发实践，我们深刻体验了Rokid CXR-M SDK的强大能力：</p><p><strong>1. API设计清晰直观</strong></p><pre><code class="kotlin">// 连接流程清晰，回调机制完善
CxrApi.getInstance().initBluetooth(context, device, callback)
CxrApi.getInstance().connectBluetooth(context, uuid, address, callback)</code></pre><p><strong>2. 功能覆盖全面</strong></p><ul><li>蓝牙连接：完整的BLE+经典蓝牙双通道支持</li><li>拍照功能：AI场景拍照，照片实时传输</li><li>设备控制：音量、亮度、电量等全方位控制</li><li>状态监听：连接状态、设备状态实时回调</li><li>覆盖了主要使用场景</li></ul><p><strong>3. 开发体验优秀</strong></p><ul><li>SDK集成简单，只需添加依赖</li><li>API调用直观，易于理解和使用</li><li>错误处理完善，便于调试</li></ul><h4>4.2 技术挑战与解决方案</h4><p><strong>挑战1：Kotlin版本兼容性</strong></p><ul><li><strong>问题</strong>：Rokid SDK使用Kotlin 2.1.0编译，需要Java 17环境</li><li><strong>解决</strong>：升级开发环境到Java 17，或使用兼容的Kotlin版本</li></ul><p><strong>挑战2：蓝牙连接稳定性</strong></p><ul><li><strong>问题</strong>：蓝牙连接可能中断，需要保证稳定性</li><li><strong>解决</strong>：实现完善的错误处理和自动重连机制</li><li><p><strong>代码示例</strong>：</p><pre><code class="kotlin">override fun onDisconnected() {
  // 连接断开，自动尝试重连
  if (socketUuid != null &amp;&amp; macAddress != null) {
      connect(context, socketUuid!!, macAddress!!)
  }
}</code></pre></li></ul><p><strong>挑战3：AI响应时间</strong></p><ul><li><strong>问题</strong>：AI API调用可能有延迟</li><li><strong>解决</strong>：使用协程异步处理，显示处理进度，支持本地模型作为备选方案，在处理时进行友好语音提示，让用户感知到进度。</li></ul><h4>4.3 Rokid SDK能力总结</h4><p>通过本项目的实践，我们充分验证了Rokid CXR-M SDK在以下方面的能力：</p><table><thead><tr><th>能力类别</th><th>SDK功能</th><th>应用场景</th></tr></thead><tbody><tr><td><strong>连接能力</strong></td><td>蓝牙双通道连接</td><td>手机与眼镜的稳定通信</td></tr><tr><td><strong>数据交互</strong></td><td>AI场景拍照</td><td>获取眼镜端图像数据</td></tr><tr><td><strong>设备控制</strong></td><td>音量/亮度/电量</td><td>优化用户体验</td></tr><tr><td><strong>状态管理</strong></td><td>连接状态监听</td><td>实时反馈设备状态</td></tr><tr><td><strong>扩展性</strong></td><td>丰富的回调接口</td><td>支持复杂业务逻辑</td></tr></tbody></table><h4>4.4 未来展望</h4><p>随着AI技术的不断发展和Rokid SDK能力的持续增强，AI助盲应用将能够：</p><ol><li><strong>更精准的环境理解</strong>：结合多帧图像进行3D场景重建，读取设备经纬度，识别更细微的环境变化，提供更准确的位置信息</li><li><strong>更自然的交互体验</strong>：支持连续对话，理解上下文，个性化学习用户习惯，更智能的提示和建议</li><li><strong>更多实用功能场景</strong>：实时导航引导物体跟踪和定位，社交场景识别（识别熟人、表情等）</li><li><strong>更好的性能表现</strong>：支持离线AI模型，提升响应速度，降低功耗</li></ol><h3>五、总结</h3><p>盲导项目展示了如何利用Rokid Glasses和Rokid CXR-M SDK，结合AI技术开发具有实际社会价值的应用。通过完整的蓝牙连接、拍照传输、AI识别和语音播报流程，为视障人群提供了一个实用的辅助工具。</p><p><strong>Rokid SDK的强大能力为开发者提供了坚实的基础</strong>，使得我们可以专注于业务逻辑和用户体验的优化。无论是开发纯眼镜端应用，还是手机端配合眼镜的协同应用，Rokid SDK都能提供完整的支持。</p><p>相信随着技术的不断进步和Rokid SDK能力的持续增强，AI+AR的应用将在更多领域发挥重要作用，真正让科技服务于每一个人，让智能眼镜成为连接数字世界与现实世界的桥梁。</p>]]></description></item><item>    <title><![CDATA[专题：2025半导体行业核心趋势与市场动]]></title>    <link>https://segmentfault.com/a/1190000047439410</link>    <guid>https://segmentfault.com/a/1190000047439410</guid>    <pubDate>2025-12-01 00:03:03</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>原文链接：<a href="https://link.segmentfault.com/?enc=Rno2npevJjjOsR0p3zK64A%3D%3D.rktM8RnvkONnKpUGbNOluAw5oy6C1kYMEEng5pdu8s4%3D" rel="nofollow" title="https://tecdat.cn/?p=44426" target="_blank">https://tecdat.cn/?p=44426</a>  <br/>原文出处：拓端抖音号@拓端tecdat</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047439412" alt="封面" title="封面"/></p><h3><a name="t0" target="_blank"/>引言</h3><p>全球半导体行业正站在“技术突破与地缘博弈”的十字路口：AI驱动的算力需求催生指数级增长，而产业链分工重构与技术壁垒形成双重约束，行业正从规模扩张向“高质量突围”转型。从材料器件的国产替代攻坚，到资本支出的全球分化，从企业盈利的结构性增长，到产业链环节的协同爆发，每个维度都暗藏“增长机遇与突围挑战”的双重逻辑。本报告洞察基于《SICA深芯盟：2024中国半导体产业投资持续增长报告》《华金证券：走向更高端，国产掩膜版厂商2.0时代开启行业深度报告》《摩根士丹利：Greater China Semiconductors: Global AI Supply Chain Updates》及文末<strong>1</strong>30+份半导体行业研究报告的数据，本文完整报告数据图表和最新报告合集已分享在交流群，阅读原文查看、进群咨询，定制数据、报告和800+行业人士共同交流和成长。报告聚焦半导体材料与器件、资本支出、企业表现、产业链核心环节、投资与融资五大核心维度，通过数据拆解增长逻辑，通过案例呈现产业现实，为产业链参与者、投资者提供兼具专业性与实操性的参考。</p><h3><a name="t1" target="_blank"/>一、材料与器件领域：全球垄断与国产突围的双重博弈</h3><h4><a name="t2" target="_blank"/>（一）全球SiC功率器件市场：头部集中与国产追赶的格局碰撞</h4><p>全球SiC功率器件市场呈现“强者恒强”的高度集中特征，Wolfspeed以29%的市场份额牢牢占据龙头地位，安森美（19%）、英飞凌（16%）、意法半导体（12%）、罗姆（8%）紧随其后，头部五家厂商合计垄断84%的市场份额，技术先发优势构建了高竞争壁垒。SiC器件凭借高效节能的核心优势，成为新能源汽车、光伏等领域的关键组件，而国内厂商正以技术突破打破格局，从“追随者”向“挑战者”转型，行业竞争从“全球协同”向“本土突围”升级。（数据来源：Yole《Power SiC 2025》）  <br/>【图表1：全球SiC功率器件市场份额饼图 】——直观呈现全球SiC功率器件“头部垄断”的竞争格局，呼应“强者恒强”的核心结论。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047439413" alt="" title="" loading="lazy"/>  <br/>全球SiC功率器件市场份额饼图1图表数据及PDF模板已分享到会员群</p><h4><a name="t3" target="_blank"/>（二）中国SiC产业链：中间强势与两头薄弱的结构矛盾</h4><p>中国SiC功率器件产业链呈现鲜明的“中间强、两头弱”格局：器件制造（28%）与器件设计（25%）环节合计占据53%的份额，已形成规模化基础；但上游衬底（15%）、外延（20%）环节依赖进口，下游模块封装（12%）技术亟待突破，产业链上下游协同不足成为突围短板。这种结构失衡既反映了国内产业在核心材料与终端封装的技术差距，也凸显了国产替代在“两头环节”的广阔空间。（数据来源：高工产研《2025中国SiC功率器件产业白皮书》）  <br/>【图表2：中国SiC产业链结构饼图 】——可视化产业链各环节占比分布，清晰呈现“中间强两头弱”的结构矛盾。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047439414" alt="" title="" loading="lazy"/>  <br/>中国SiC产业链结构饼图2图表数据及PDF模板已分享到会员群</p><h4><a name="t4" target="_blank"/>（三）掩膜版市场：规模扩容与国产替代的同步加速</h4><p>【图表3：2021-2024年全球半导体材料市场规模柱状图 】——本章节开头，作为半导体材料细分领域的背景铺垫，直观展示全球市场持续增长的整体态势，为掩膜版细分赛道分析奠定基础。  <br/>2021-2024年全球半导体材料市场规模柱状图3图表数据及PDF模板已分享到会员群  <br/>【图表4：2021-2024年中国半导体材料市场规模柱状图 】——图表3之后，通过全球与中国市场的增速对比，凸显中国市场的增长潜力，强化掩膜版赛道的需求支撑逻辑。  <br/>2021-2024年中国半导体材料市场规模柱状图4图表数据及PDF模板已分享到会员群</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047439415" alt="" title="" loading="lazy"/>  <br/>全球半导体掩膜版市场规模预计达643亿元（89.4亿美元），而中国市场以187亿元规模占比超20%，增速领跑全球，成为核心增长引擎。细分来看，晶圆制造用掩膜版占比最高（100亿元），封装用（26亿元）与其他器件用（61亿元）稳步增长，国内晶圆厂扩产直接拉动需求爆发。但矛盾在于，高端市场仍由海外厂商垄断，清溢光电、路维光电等国产厂商通过技术升级持续渗透，国产替代从“量变”向“质变”跨越。（数据来源：华金证券《走向更高端，国产掩膜版厂商2.0时代开启行业深度报告》）  <br/>【图表13：中国掩膜版市场结构桑基图 】——本段落中“其中晶圆制造用掩膜版占比最高”之后，直观展示中国掩膜版市场的应用结构分布，强化细分需求逻辑。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047439416" alt="" title="" loading="lazy"/>  <br/>中国掩膜版市场结构桑基图表2-1图表数据及PDF模板已分享到会员群  <br/>【图表14：掩膜版市场规模对比哑铃图 】——本段落“全球市场规模约643亿元”之后，通过中国与全球市场的规模对比，凸显中国市场的占比与增长潜力，呼应“全球核心增长引擎”结论。  <br/>掩膜版市场规模对比哑铃图表2-2图表数据及PDF模板已分享到会员群</p><h3><a name="t5" target="_blank"/>二、资本支出：AI驱动与结构分化的鲜明反差</h3><h4><a name="t6" target="_blank"/>（一）全球云资本支出：AI拉动的指数级增长奇迹</h4><p>全球Top11云服务提供商资本支出呈现“爆发式增长”态势，2023年159.74亿美元、2024年285.26亿美元，2025年预计飙升至4450亿美元，相当于前两年总和，同比增长56%。这一增长并非偶然，而是OpenAI与NVIDIA等AI巨头战略合作催生的算力需求爆发，AI已从“辅助引擎”升级为半导体行业的“核心增长动力”，全球云需求的强劲韧性超出预期。（数据来源：摩根士丹利《Cloud Semis: Demand Remains Strong ‘Globally’ into 2026》）  <br/>【图表5：2023-2025Q2全球Top11云服务提供商资本支出柱状图 】——可视化资本支出“指数级增长”的轨迹，印证AI驱动的增长逻辑。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047439417" alt="" title="" loading="lazy"/>  <br/>2023-2025Q2全球Top11云服务提供商资本支出柱状图5图表数据及PDF模板已分享到会员群</p><h4><a name="t7" target="_blank"/>（二）美国云资本支出：增长加速与需求韧性的双重印证</h4><p>美国云资本支出同比增长呈现“持续加速”特征，2025年第一季度62%、第二季度升至67%，增速屡创新高，凸显AI需求的强韧性。背后核心驱动力是AI服务器与推理需求的爆发，企业为抢占算力先机持续加码投资，预计下半年增长态势不改，成为全球云投资的“压舱石”。（数据来源：摩根士丹利《Cloud Semis:DemandRemains Strong ‘Globally’ into 2026》）  <br/>【图表6：2025Q1-Q2美国云资本支出同比增长率柱状图 】——直观呈现季度增长加速趋势，强化“需求韧性”的核心结论。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047439418" alt="" title="" loading="lazy"/>  <br/>2025Q1-Q2美国云资本支出同比增长率柱状图6图表数据及PDF模板已分享到会员群</p><h4><a name="t8" target="_blank"/>（三）中国云厂商支出：头部领跑与策略分化的鲜明对比</h4><p>中国云服务提供商资本支出呈现“两极分化”格局：2025年第二季度阿里巴巴资本支出暴涨至387亿元，同比增长224%，AI投资已落地见效，云业务增长势能强劲；而腾讯强调“智能支出”策略，同期支出191亿元，增速相对平缓。两家头部厂商的差异，本质是AI布局节奏与投资逻辑的不同，反映中国云资本支出从“规模化扩张”向“精准化投放”转型。</p><p>（数据来源：摩根士丹利《Cloud Semis: Spending Smartly in China》）  <br/>【图表7：2025Q2中美云厂商资本支出哑铃图 】</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047439419" alt="" title="" loading="lazy"/></p><p>——通过中美头部厂商对比，凸显中国厂商的分化格局与阿里的领跑地位，强化“策略分化”结论。  <br/>2025Q2中美云厂商资本支出哑铃图7图表数据及PDF模板已分享到会员群</p><hr/><p><strong>相关文章</strong><img referrerpolicy="no-referrer" src="/img/remote/1460000047439420" alt="" title="" loading="lazy"/></p><h3><a name="t9" target="_blank"/>专题：2025年游戏科技的AI革新研究报告：全球市场趋势研究报告|附130+份报告PDF、数据仪表盘汇总下载</h3><p>原文链接：<a href="https://link.segmentfault.com/?enc=bnAipme8i3frgKvJMfcZQQ%3D%3D.e12o%2BDeIakBpV63JmyrgX8ch8EzfCIIHMZwH1t%2FcVrU%3D" rel="nofollow" title="https://tecdat.cn/?p=44082" target="_blank">https://tecdat.cn/?p=44082</a></p><hr/><h3><a name="t10" target="_blank"/>三、企业表现：AI红利与盈利优化的双向赋能</h3><h4><a name="t11" target="_blank"/>（一）Aspeed收入趋势：云需求驱动的稳步增长</h4><p>作为云服务器BMC核心供应商，Aspeed季度收入呈现“持续攀升”态势：2024年第四季度15亿新台币，2025年第一季度18亿新台币、第二季度20亿新台币，第三季度预计突破22亿新台币，第四季度指导20-21亿新台币。收入增长直接映射AI驱动的云服务器需求爆发，尽管面临BT基板短缺的短期约束，但长期增长逻辑未变，成为AI半导体赛道的“受益者”。（数据来源：摩根士丹利《Cloud Semis: Demand Remains Strong ‘Globally’ into 2026》）  <br/>【图表8：Aspeed季度收入面积图 】</p><p>通过面积图可视化收入增长轨迹，呼应“稳步增长”的核心结论。</p><p>Aspeed季度收入面积图表2_2图表数据及PDF模板已分享到会员群</p><h4><a name="t12" target="_blank"/>（二）Aspeed盈利水平：结构升级与毛利优化的双重突破</h4><p>Aspeed盈利能力呈现“持续提升”态势，预计2025年毛利率67.2%、2026年67.6%、2027年68.2%，稳步优化。尽管面临组件涨价的成本压力，但通过AST2700等高端产品组合实现结构升级，成功抵消成本冲击。每股收益（EPS）更是表现亮眼，2025年预计92.43新台币，2026年增长28.2%至118.51新台币，2027年再增29.9%至154.43新台币，年复合增长率29%，尽显AI半导体赛道的盈利红利。（数据来源：摩根士丹利《Cloud Semis: Demand Remains Strong ‘Globally’ into 2026》）  <br/>【图表9：Aspeed每股收益气泡图 】</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047439421" alt="" title="" loading="lazy"/></p><p>本段落“每股收益（EPS）预计2025年为92.43新台币”之后，可视化EPS增长趋势与增速，突出“高速增长”特征。  <br/>Aspeed每股收益气泡图表3_1图表数据及PDF模板已分享到会员群  <br/>【图表10：Aspeed毛利率箱线图 】</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047439422" alt="" title="" loading="lazy"/></p><p>图表9之后，本段落“预计2025年毛利率达67.2%”相关描述之后，展示毛利率优化趋势及分布，强化“盈利提升”逻辑。  <br/>Aspeed毛利率箱线图表3_2图表数据及PDF模板已分享到会员群</p><h3><a name="t13" target="_blank"/>四、产业链核心环节：先进封装与测试设备的需求爆发</h3><h4><a name="t14" target="_blank"/>（一）全球先进封装市场：AI驱动的高增长赛道</h4><p>AI芯片需求重构全球先进封装市场，呈现“持续高增长”态势：2023年市场规模378亿美元（2.5D/3D封装145亿美元，其他先进封装233亿美元），2025年预计476亿美元（2.5D/3D封装185亿美元，其他291亿美元），2029年将达695亿美元（2.5D/3D封装345亿美元，其他350亿美元），2023-2029年复合年增长率约11%。随着AI和HPC应用扩张，先进封装成为突破芯片性能瓶颈的关键路径，2.5D/3D封装增速领跑行业，成为核心增长引擎。（数据来源：开源证券《高端先进封装:AI时代关键基座行业深度报告》）  <br/>【图表11：全球先进封装市场规模堆叠面积图 】——通过堆叠面积图展示整体规模与细分领域增长，呼应“高增长”与“结构分化”双重逻辑。  <br/>全球先进封装市场规模堆叠面积图表1-1图表数据及PDF模板已分享到会员群</p><h4><a name="t15" target="_blank"/>（二）台积电CoWoS产能：扩张提速与供给缓解的正向循环</h4><p>CoWoS作为AI芯片核心2.5D封装技术，面临英伟达等客户的强劲需求，台积电开启“大规模扩产”模式：2024年月产能3.5万片，2025年预计增至7.5万片，2026年进一步提升至9万片，两年内产能翻倍。这一扩产动作有效缓解高端封装供给紧张，为AI芯片产能释放提供支撑，形成“需求爆发—产能扩张—供给缓解—需求再升级”的正向循环。（数据来源：开源证券《高端先进封装:AI时代关键基座行业深度报告》）  <br/>【图表12：台积电CoWoS产能密度图 】</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047439423" alt="" title="" loading="lazy"/></p><p>可视化产能扩张轨迹，印证“快速扩张”的核心结论。  <br/>台积电CoWoS产能密度图表1-2图表数据及PDF模板已分享到会员群</p><h4><a name="t16" target="_blank"/>（三）半导体测试设备市场：结构分化与国产突破的并行推进</h4><p>半导体测试设备市场呈现“结构清晰、需求分化”特征：SoC测试机以48亿元市场规模居首，存储测试机（24亿元）紧随其后，模拟测试机（10.5亿元）与射频测试机（4.4亿元）规模相对较小。AI芯片、存储芯片的技术迭代持续拉动测试设备需求，尤其是高端测试设备成为产业链“卡脖子”环节，国产厂商正加速突破技术壁垒，从“低端替代”向“高端攻坚”跨越。  <br/>【图表15：半导体测试设备市场瀑布图 】</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047439424" alt="" title="" loading="lazy"/></p><p>通过瀑布图展示细分领域规模及累计占比，凸显“结构清晰”的市场特征。  <br/>半导体测试设备市场瀑布图表3_1图表数据及PDF模板已分享到会员群</p><h3><a name="t17" target="_blank"/>五、投资与融资：制造主导与资本信心的双重支撑</h3><h4><a name="t18" target="_blank"/>（一）中国半导体投资领域：制造核心与多点协同的布局逻辑</h4><p>2025年上半年中国半导体行业投资呈现“制造主导、多点协同”格局：晶圆制造占比51.4%，成为绝对投资核心，聚焦产能扩张；芯片设计（18.7%）、半导体材料（13.0%）受益于国产化政策，投资增速加快；封装测试（9.2%）保持稳健，其他领域（7.7%）补充。这一投资结构契合产业链发展需求，既补制造环节短板，又强化设计与材料等关键环节，形成“核心突破+协同发展”的投资逻辑。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047439425" alt="" title="" loading="lazy"/></p><p>（数据来源：MIR睿工业《2025年上半年中国半导体行业投融资情况分析报告》）</p><h4><a name="t19" target="_blank"/>（二）半导体融资交易：大额活跃与信心充足的市场信号</h4><p>2025年第一季度半导体融资市场“活跃度高、信心充足”：未披露金额交易42笔，千万元级40笔，亿元级29笔，大额融资集中于设备及材料领域，反映产业链上游的战略重要性提升。未披露项目占比较高源于商业保密需求，整体融资热度凸显资本对半导体高成长领域的坚定信心，为国产替代与技术突破提供资金支撑。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047439426" alt="" title="" loading="lazy"/></p><p>（数据来源：MIR睿工业《2025年上半年中国半导体行业投融资情况分析报告》）</p><h3><a name="t20" target="_blank"/>六、行业核心趋势总结</h3><ol><li><strong>AI驱动需求爆发</strong>：全球云资本支出、AI服务器、先进封装等环节受AI需求拉动，呈现指数级增长，成为行业核心增长引擎，重构产业增长逻辑；</li><li><strong>国产替代加速突围</strong>：SiC产业链、掩膜版、测试设备等领域，国产厂商技术持续突破，政策支持与产能扩张双重驱动，从“单点突破”向“全面突围”跨越，替代空间广阔；</li><li><strong>产业链协同增长</strong>：资本支出向制造、设计、材料等核心环节集中，先进封装、测试设备等配套环节需求同步爆发，上下游形成协同效应，强化产业竞争力；</li><li><strong>头部领跑格局固化</strong>：Wolfspeed、台积电等国际巨头巩固技术与产能优势，阿里巴巴、Aspeed等企业在细分领域快速崛起，行业集中度持续提升，“强者恒强”态势明显。</li></ol><h3><a name="t21" target="_blank"/>文中数据图表列表</h3><ol><li>全球SiC功率器件市场份额饼图1</li><li>中国SiC产业链结构饼图2</li><li>2021-2024年全球半导体材料市场规模柱状图3</li><li>2021-2024年中国半导体材料市场规模柱状图4</li><li>2023-2025Q2全球Top11云服务提供商资本支出柱状图5</li><li>2025Q1-Q2美国云资本支出同比增长率柱状图6</li><li>2025Q2中美云厂商资本支出哑铃图7</li><li>Aspeed季度收入面积图8（Chart2_2）</li><li>Aspeed每股收益气泡图9（Chart3_1）</li><li>Aspeed毛利率箱线图10（Chart3_2）</li><li>全球先进封装市场规模堆叠面积图11（Chart1-1）</li><li>台积电CoWoS产能密度图12（Chart1-2）</li><li>中国掩膜版市场结构桑基图13（Chart2-1）</li><li>掩膜版市场规模对比哑铃图14（Chart2-2）</li><li>半导体测试设备市场瀑布图15（Chart3_1）</li></ol><h3><a name="t22" target="_blank"/>本专题内的参考报告（PDF）目录</h3><ol><li>大中华区科技半导体：全球AI供应链更新；亚洲关键机遇 报告2025-10-23</li><li>2025年深圳集成电路及国产半导体产业调研报告 报告2025-10-19</li><li>2025全球及中国半导体制造市场预测和产业分析 报告2025-10-19</li><li>全球人工智能供应链最新动态；亚洲半导体的关键机遇 报告2025-10-13</li><li>云半导体：需求“全球”强劲至2026年 报告2025-10-12</li><li>2025年上半年中国半导体行业投融资情况分析报告 报告2025-10-12</li><li>国产AI芯片软件生态白皮书 报告2025-11-26</li><li>2025年中国智能芯片行业市场洞察报告 报告2025-11-24</li><li>2025年国产AI芯片软件生态白皮书 报告2025-11-24</li><li>中国智能驾驶芯片：竞争格局及关键供应商深入L2+以上NOA细分市场 报告2025-10-31</li><li>从芯片到汽车：深入探讨ADAS与Robotaxi 报告2025-10-31</li><li>2025年年国产AI芯片和高性能处理器厂商排名和行业趋势报告 报告2025-10-23</li><li>2024年国产AI芯片+处理器+存储器厂商调研分析报告 报告2025-10-21</li><li>2025年亚马逊AWS全栈AI战略：从自研芯片、投资Anthropic... 报告2025-10-19</li><li>中国AI前沿行业研究：华为发布AI芯片路线图；本土化进程加速 报告2025-10-13</li><li>汽车安全芯片应用领域白皮书 报告2025-10-13</li><li>芯片眼镜：面向未来 AI 眼镜的下一代低功耗技术 报告2025-10-07</li><li>数字芯片设计基础知识 报告2025-10-05</li><li>半导体设备行业深度-AI芯片快速发展-看好国产算力带动后道测试&amp;先进封... 报告2025-09-22</li><li>2025年SOC芯片发展现状、市场需求及竞争格局分析报告 报告2025-09-18</li><li>2025微芯片植入技术：人类增强的新前沿报告 报告2025-09-11</li><li>2025年中国AI芯片行业大报告：评估中国AI芯片的供需情况 报告2025-09-05</li><li>2025年Q3芯片测封行业薪酬报告 报告2025-09-03</li><li>2025年中国人工智能：评估中国人工智能芯片的供需情况报告 报告2025-08-29</li><li>机器人系列深度报告-具身智能大时代-算力芯片筑底座 报告2025-08-28</li><li>2025中国AI芯片行业大报告：评估中国AI芯片的供需情况 报告2025-08-19</li><li>2025汽车智驾芯片行业技术趋势、市场空间、竞争格局及相关标的分析报告 报告2025-08-19</li><li>车载SOC芯片深度报告-智能汽车引领进化-SOC芯片加速国产化 报告2025-08-06</li><li>2025年Q3芯片制造行业薪酬报告 报告2025-07-22</li><li>2025芯片设计标杆企业组织效能报告 报告2025-07-17</li><li>2025年芯片设计标杆企业组织效能报告 报告2025-07-14</li><li>2025年Q2芯片测封行业薪酬报告 报告2025-05-22</li><li>2025年DeepSeek对国产芯片的影响报告 报告2025-05-22</li><li>2025年芯片设计行业白皮书 报告2025-05-15</li><li>2025年芯片制造行业白皮书 报告2025-05-13</li><li>半导体行业深度报告-AI算力芯片——AI时代的引擎 报告2025-04-06</li><li>2025年Q1芯片测封行业薪酬报告 报告2025-04-06</li><li>2025芯片设计白皮书行业 报告2025-03-29</li><li>2025年Q1芯片设计行业薪酬报告 报告2025-03-29</li><li>2024年中国芯片半导体行业投融资报告 报告2025-03-22</li><li>基础化工行业研究-AI系列深度（三）-超级芯片推动AI赋能预想-刺激高... 报告2025-03-06</li><li>2024年RISC-V芯片产业发展报告 报告2025-01-21</li><li>浅析中美芯片博弈的危与机 报告2025-01-20</li><li>2024年AI大算力芯片技术发展与产业趋势 报告2025-01-20</li><li>汽车芯片产品国外技术性贸易措施及深圳对策研究 报告2025-01-12</li><li>头豹：2024年中国GNSS芯片行业研究报告：支撑物联网、车联网应用落... 报告2024-12-04</li><li>对外经济贸易大学：中国芯片产品贸易月度监测报告（2024年1-7月） 报告2024-09-19</li><li>数字经济实验室：中国芯片产品贸易月度监测报告(2024年1-7月) 报告2024-09-13</li><li>美国半导体协会：2024年芯片行业概况 报告2024-08-14</li><li>5G应用产业方阵：2023基于R15芯片的电力行业5G模组的精简化研究... 报告2024-07-28</li><li>头豹：2024年中国安防视频监控SoC芯片行业研究报告-安防SoC市场... 报告2024-07-18</li><li>维卓：2024全球AI芯片行业报告 报告2024-07-17</li><li>焉知汽车：2024车载SoC芯片产业分析报告 报告2024-07-15</li><li>顺为咨询：2024芯片设计行业组织效能报告 报告2024-06-29</li><li>源达信息：半导体行业专题研究-芯片高性能趋势演进下-玻璃基板有望崭露头... 报告2024-06-27</li><li>易观分析：中国智能汽车车载计算芯片产业报告 报告2024-06-20</li><li>5G应用产业方阵：2023年5G低功耗高精度定位芯片研究报告 报告2024-06-18</li><li>盖世汽车：2023中国车规级芯片产业白皮书 报告2024-06-03</li><li>中国软件评测中心：汽车芯片检测认证体系技术白皮书（2024） 报告2024-05-06</li><li>与非网：2024电源管理芯片产业分析报告 报告2024-04-28</li><li>头豹：2023年中国模拟芯片系列报告-高端芯片“卡脖子”-国产化替代加... 报告2024-03-31</li><li>中国汽研：车规级MCU芯片年度发展报告（2023） 报告2024-02-19</li><li>ECC&amp;中电标协&amp;华为：2023智能驾驶计算芯片性能评测标准化白皮书 报告2024-01-22</li><li>致同咨询：2024半导体行业研究报告-车规级芯片 报告2024-01-10</li><li>头豹研究院：2023年半导体芯片行业系列研究——中国逻辑芯片行业概览 报告2024-01-06</li><li>头豹：2023年半导体芯片行业系列研究——中国存储芯片行业概览 报告2024-01-05</li><li>半导体设备行业深度-AI芯片快速发展-看好国产算力带动后道测试&amp;先进封... 报告2025-09-22</li><li>半导体行业深度报告-高端先进封装-AI时代关键基座-重视自主可控趋势下... 报告2025-08-16</li><li>2025先进封装手册：制程技术 报告2025-08-10</li><li>2025年中国先进封装设备行业：科技自立，打造国产高端封装新时代 报告2025-06-04</li><li>2025年中国半导体先进封装行业研究：后摩尔时代，先进封装引领半导体创... 报告2025-05-29</li><li>AI应用侧深度渗透，驱动国产先进封装技术寻求突破 报告2025-04-16</li><li>半导体键合设备行业深度-先进封装高密度互联推动键合技术发展-国产设备持... 报告2025-03-06</li><li>2025中国半导体激光设备白皮书 报告2025-11-26</li><li>2025年半导体企业AI数智化白皮书 报告2025-09-27</li><li>2025第三代半导体行业研究报告 报告2025-09-26</li><li>大中华区半导体全球人工智能供应链更新；亚洲半导体的关键机遇 报告2025-09-25</li><li>大中华区半导体行业：AI增长效应渗透至传统存储领域 报告2025-09-23</li><li>半导体设备行业深度-AI芯片快速发展-看好国产算力带动后道测试&amp;先进封... 报告2025-09-22</li><li>2025半导体制造工艺介绍报告 报告2025-09-22</li><li>全球半导体、硬件、互联网与软件：2025年第三季度人工智能服务器与边缘... 报告2025-09-19</li><li>云半导体：在中国精明地花钱 报告2025-09-18</li><li>2025年美国半导体产业现状 报告2025-09-16</li><li>中国半导体行业，2025年CSEAC考察团调研要点 报告2025-09-12</li><li>大中华区半导体：云半导体在中国精明支出 报告2025-09-06</li><li>美国互联网与半导体行业研究：AI下一站：GPT 报告2025-08-22</li><li>半导体系列深度报告-走向更高端-国产掩膜版厂商2.0时代开启 报告2025-08-21</li><li>半导体行业深度报告-高端先进封装-AI时代关键基座-重视自主可控趋势下... 报告2025-08-16</li><li>架桥 应对半导体行业的的人才短缺 报告2025-08-08</li><li>半导体2025年二季度投融市场报告 报告2025-07-22</li><li>2025年春季全球半导体与先进材料行业并购策略与市场趋势报告 报告2025-07-11</li><li>2025年全球半导体产业展望报告 报告2025-07-07</li><li>2025全球半导体产业大调查报告 报告2025-06-25</li><li>2025年中国半导体及光伏用石英坩埚行业市场独立研究报告 报告2025-06-22</li><li>半导体产业人才报告 报告2025-06-17</li><li>2025年中国半导体先进封装行业研究：后摩尔时代，先进封装引领半导体创... 报告2025-05-29</li><li>电子设备-台湾地区半导体行业 报告2025-05-27</li><li>2025年半导体品牌30强 报告2025-05-20</li><li>2025年Q1半导体行业薪酬报告 报告2025-05-08</li><li>2024年美国半导体行业报告 报告2025-04-29</li><li>2025年GaN功率半导体发展预测：破解能源需求增强与净零经济之间的矛... 报告2025-04-20</li><li>半导体行业深度报告-AI算力芯片——AI时代的引擎 报告2025-04-06</li><li>2025年中国半导体行业出口分析及各国进口政策影响白皮书 报告2025-03-31</li><li>半导体行业深度报告（十二）-AI大模型竞赛方兴未艾-OpenAI与De... 报告2025-03-29</li><li>2024年中国芯片半导体行业投融资报告 报告2025-03-22</li><li>半导体键合设备行业深度-先进封装高密度互联推动键合技术发展-国产设备持... 报告2025-03-06</li><li>2025年全球半导体产业展望 报告2025-03-04</li><li>半导体行业产业链深度报告：瞄准尖端技术中国半导体制造迈入新阶段 报告2025-02-23</li><li>2024年全球半导体行业展望：人工智能与汽车行业提振半导体行业，人才短... 报告2025-01-07</li><li>2024年全球半导体行业展望报告 报告2025-01-02</li><li>Uresearch：全球半导体测试探针行业市场研究报告2024 报告2024-12-04</li><li>易展翅：2024上半年半导体行业招聘报告 报告2024-11-13</li><li>IMA：可持续芯动力：2024年半导体行业ESG转型之路研究报告 报告2024-11-04</li><li>CASA：第三代半导体产业发展报告 报告2024-11-01</li><li>GLG：深度解读半导体行业 报告2024-10-15</li><li>沙利文：全球半导体制造类EDA行业发展白皮书 报告2024-10-12</li><li>英飞凌：2024年预测——氮化镓功率半导体 报告2024-10-06</li><li>西门子：2024半导体智能制造白皮书-从精益制造向智能制造演进 报告2024-09-13</li><li>德勤：2024年全球半导体产业展望 报告2024-08-22</li><li>美国半导体协会：2024年芯片行业概况 报告2024-08-14</li><li>意法半导体：2024平面磁件如何提高电力电子器件性能白皮书 报告2024-08-09</li><li>头豹：2024年中国半导体设备行业总览-前道设备国产替代正当时（摘要版... 报告2024-07-20</li><li>云岫资本：2024中国半导体投资深度分析与展望报告 报告2024-07-03</li><li>源达信息：半导体行业专题研究-芯片高性能趋势演进下-玻璃基板有望崭露头... 报告2024-06-27</li><li>头豹：2024年中国半导体设备（1）-薄膜沉积设备（CVD&amp;PVD） 报告2024-06-25</li><li>源达信息：半导体材料专题研究-国内加快晶圆产能扩建-半导体材料国产化加... 报告2024-06-14</li><li>头豹：2024年中国晶圆检测设备行业研究报告-半导体工艺控制核心设备-... 报告2024-05-28</li><li>锐仕方达：2024年半导体行业薪酬报告 报告2024-05-03</li><li>源达信息：半导体材料行业研究系列一-国内加快成熟制程扩产-光刻胶国产替... 报告2024-04-25</li><li>头豹：2023年中国医疗半导体行业概览-医疗半导体国产化率低但增速迅猛... 报告2024-04-25</li><li>亿欧智库：泛半导体产业黑灯工厂发展研究洞察白皮书 报告2024-03-22</li><li>德勤&amp;GSA：2024亚太地区半导体行业展望报告 报告2024-02-26</li><li>智研咨询：2023年中国半导体设备产业现状及发展趋势研究报告 报告2024-02-03</li><li>致同咨询：2024半导体行业研究报告-车规级芯片 报告2024-01-10</li><li>头豹研究院：2023年半导体芯片行业系列研究——中国逻辑芯片行业概览 报告2024-01-06</li></ol>]]></description></item><item>    <title><![CDATA[2025电商行业全景洞察报告：直播电商、]]></title>    <link>https://segmentfault.com/a/1190000047439441</link>    <guid>https://segmentfault.com/a/1190000047439441</guid>    <pubDate>2025-12-01 00:02:21</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>原文链接：<a href="https://link.segmentfault.com/?enc=7uG2AyDL3elxx856NMUyWQ%3D%3D.zVOzTuVOgTHMXVWzQ3GVdxk%2BnZdsrahN6jH2PWlc798%3D" rel="nofollow" title="https://tecdat.cn/?p=44438" target="_blank">https://tecdat.cn/?p=44438</a>  <br/>原文出处：拓端抖音号@拓端tecdat</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047439443" alt="封面" title="封面"/></p><h3><a name="t0" target="_blank"/>核心摘要</h3><p>2025年电商行业进入“存量博弈→价值深耕”的关键转折期：双11周期拉长至60天重构大促节奏，直播电商从“流量争夺”转向“内容+搜索”闭环，跨境增量向巴西、非洲等新兴市场倾斜（Temu非洲MAU增424%），AI驱动的“看后搜”成为流量新入口（日均PV 1.1亿）。行业呈现“B2B数字化提速（MRO数智化采购增速4倍于传统渠道，但未来增速放缓至4.2%）、B2C品类分化（宠物食品增59%、羽绒服增534%、清洁电器增47.5%）、营销精准化（KOL+UGC种草转化占比超50%）”三大特征。本报告为电商创业者、品牌商家、跨境卖家提供“平台适配+品类选择+营销落地”的分层策略，助力在结构性机会中找准增长锚点。</p><h3><a name="t1" target="_blank"/>引言</h3><p>2025年电商行业的竞争逻辑已从“谁能拿到流量”变为“谁能深耕价值”：双11周期延长倒逼运营模式升级，直播电商玩法与搜索工具深度融合，跨境市场在新兴地区打开增量空间，AI技术则重塑“人货场”匹配效率。品牌商家需应对平台规则迭代与消费需求分层的双重挑战，跨境卖家更要在全球供应链重构中抓住新兴市场机遇，B2B商家则需破解增速放缓难题。本报告洞察基于《飞瓜数据：2025年9月飞瓜快手直播电商月报》《飞瓜数据：2025年9月飞瓜抖音电商营销月报》《Sensor Tower：2025年购物季电商应用市场洞察报告》《克劳锐：2025电商双11社交媒体内容消费洞察报告》及<strong>文末270+份电商行业研究报告的数据，本文完整报告数据图表和最新报告合集已分享在交流群，阅读原文查看、进群咨询，定制数据、报告和800+行业人士共同交流和成长。</strong></p><p>报告将从“行业供需演进、平台策略博弈、品类机会分化、营销工具革命”四大维度，用数据拆解趋势，用案例提供方法，为不同类型电商从业者提供可落地的行动指南。</p><h3><a name="t2" target="_blank"/>一、行业演进：供需双升下的结构性机会</h3><h4><a name="t3" target="_blank"/>（一）B2B与B2C双线增长，数字化成核心驱动力</h4><p>从供给端看，中国MRO工业品电商2024年市场规模达3.7万亿元，2019-2024年年均复合增长率6.1%，但数智化采购渗透率仅9.8%，增速却达传统渠道的4倍，凸显“线下转线上”的增量空间。不过行业增速已显现放缓迹象，预测2025-2029年年均复合增长率将降至4.2%，进入成熟期后需依赖技术升级与供应链优化突破瓶颈。  <br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047439444" alt="" title="" loading="lazy"/>  <br/>工业品电商复合增长率折线图表B2图表数据及PDF模板已分享到会员群  <br/>从需求端看，B2C电商在大促驱动下持续爆发，细分品类增速差异显著：宠物食品细分领域增速高达59%，保健品增长12.2%，兴趣消费超10%，成为细分市场驱动高增长的核心力量；平台层面，抖音2025年双11重点促销期GMV同比增长41%，快手10月双11开启后销售热度环比提升51.01%，流量红利向“精细化运营商家”倾斜。  <br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047439445" alt="" title="" loading="lazy"/>  <br/>B2C电商销售额增长率半圆面积图表A2图表数据及PDF模板已分享到会员群  <br/>3秒解读：B2B电商数字化空间广阔但增速放缓，B2C细分品类分化明显，大促仍是短期爆发关键。  <br/>对应人群行动建议：工业品商家可接入数智化采购平台降低隐性成本，同时布局技术升级（如AI采购匹配）应对增速下滑；B2C商家可重点布局宠物食品、兴趣消费等高增速品类，提前30天规划大促货盘，绑定平台流量扶持活动。</p><h4><a name="t4" target="_blank"/>（二）跨境电商：新兴市场替代成熟市场成增长主力</h4><p>全球电商应用下载量格局生变，2025年1-10月拉丁美洲占Temu总下载量近30%（同比增12%），非洲市场下载量同比暴涨178%，贡献全球15%增量；从活跃用户看，Temu在非洲MAU同比飙升424%，亚洲增153%，拉丁美洲增113%，成熟市场增速相对平缓，电商增长动力已从欧美转向新兴地区。  <br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047439446" alt="" title="" loading="lazy"/>  <br/>Temu全球市场MAU增长率横向条形图表A1图表数据及PDF模板已分享到会员群  <br/>3秒解读：跨境电商“弃美入拉非”成新趋势，新兴市场活跃用户爆发式增长，本地化运营决定生存空间。  <br/>对应人群行动建议：跨境卖家优先布局巴西、尼日利亚市场，适配“低价+本地化物流”策略（如接入本地仓）；关注Temu等平台广告投放倾斜，新兴市场预算占比可提升至50%，针对性开发适配当地需求的产品。  <br/>本章节配套《2025电商行业增长白皮书》，含B2B/B2C运营工具清单，进群可领。</p><h3><a name="t5" target="_blank"/>二、平台博弈：大促节奏与工具创新的双重竞争</h3><h4><a name="t6" target="_blank"/>（一）双11周期拉长，多阶段运营替代“短期冲刺”</h4><p>2025年平台大促均突破“30天常规周期”：天猫从37天延长至60天，分“预售期-开门红-狂欢节-返场期”四阶段；抖音覆盖“中秋预热-好物节-专场期-冲刺期-返场期”，跨度达2个月。周期拉长带来两大变化：一是用户决策周期延长（攻略类内容关注量增40%），52.4%的用户通过攻略内容寻求知识以降低决策门槛，专属优惠和KOL专业背书也是重要动因；二是商家需分阶段匹配资源（预热种草、爆发转化、返场清仓）。  <br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047439447" alt="" title="" loading="lazy"/>  <br/>双11用户攻略内容关注原因条形图表C1图表数据及PDF模板已分享到会员群  <br/>3秒解读：大促运营从“单点爆发”变为“全周期渗透”，攻略内容成为用户决策关键，前期种草决定后期转化。  <br/>对应人群行动建议：品牌商家在预热期投50%内容预算做种草（如KOL测评），专场期聚焦核心品类，返场期用“满减复用”激活未转化用户；中小商家可绑定头部达人缩短冷启周期，同时优化攻略类内容布局关键词。</p><h4><a name="t7" target="_blank"/>（二）工具升级：AI与搜索工具成商家破局关键</h4><p>平台纷纷推出“效率型工具”：抖音接入豆包AI打造“看后搜”链路（日均PV 1.1亿，增速是主动搜3.2倍），通过“搜索底纹+奇异果工具”提升转化；快手上线“乘风计划”“百城万星”计划，为品牌提供分层培训与流量倾斜；淘宝、京东强化AI全景导购，即时零售订单增速超30%。工具适配度直接决定商家增长效率，抖音投运一体商家流量和GMV分别提升42%和33%，但平台整体流量增速仅8%，需加强自然流量挖掘。  <br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047439448" alt="" title="" loading="lazy"/>  <br/>抖音平台与商家增长率对比条形图表3图表数据及PDF模板已分享到会员群  <br/>3秒解读：平台工具从“辅助”变为“必需”，投运一体策略成效显著，但平台整体流量增长乏力，需结合内容生态破局。  <br/>对应人群行动建议：商家需在15天内完成“看后搜”配置（短视频标题+评论区埋关键词），用奇异果工具抢占搜索首屏；接入AI导购工具优化客服响应效率，同时加大自然流量内容创作（如UGC激励）。</p><hr/><p><strong>相关文章</strong><img referrerpolicy="no-referrer" src="/img/remote/1460000047439449" alt="" title="" loading="lazy"/></p><h3><a name="t8" target="_blank"/>专题：2025跨境电商产业发展报告：出海、ERP、产业带、人才|附270+份报告PDF、数据、<a href="https://link.segmentfault.com/?enc=WXVfvPeDuuD6rIZJJdYRTA%3D%3D.8hVFoPG893ETGGGfva9MmE38UnDcx8PtmMpUVblRwvmqrBz3YS71LZq%2Bv8qeictlLnM66NklDcRXG5LmoNklf3VfSIbm5UYU0mE7lPOul3zpYLrpXEvVyyc7pndhlK%2FT" rel="nofollow" target="_blank">可视化</a>模板汇总下载</h3><p>原文链接：<a href="https://link.segmentfault.com/?enc=SpTF3Mxe1Dz9Qbt6eI%2FjzA%3D%3D.hoYLb9%2F81nmmkPvB2JGZ1wYkjUUwSGffdhVNlfr8lF8%3D" rel="nofollow" title="https://tecdat.cn/?p=44334" target="_blank">https://tecdat.cn/?p=44334</a></p><hr/><h3><a name="t9" target="_blank"/>三、品类机会：季节与场景驱动的分化增长</h3><h4><a name="t10" target="_blank"/>（一）服饰品类：换季+大促双轮驱动，男女款需求分化</h4><p>2025年10月快手羽绒服销售热度环比增534.28%，抖音女款羽绒服占比81%（同比增60.4%），男款虽占比19%但增速达96.47%；女装毛衣9月销售热度环比增195.14%，消费者更关注“品质+性价比”。快手女装品牌客单价分层明显，坦博尔以709元领跑，雅舒曼、俐莹等高端品牌主导市场，呈现消费升级态势。  <br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047439450" alt="" title="" loading="lazy"/>  <br/>快手女装品牌客单价横向条形图表2图表数据及PDF模板已分享到会员群  <br/>除服饰外，快手防寒与健康品类同步爆发：取暖电器销售热度环比增507.5%，海外营养品增71.62%，直观反映季节消费趋势与用户健康需求提升。  <br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047439451" alt="" title="" loading="lazy"/>  <br/>快手电商品类环比增长条形图表1图表数据及PDF模板已分享到会员群  <br/>3秒解读：服饰品类“女款看风格、男款看功能”，价格带分层明显，防寒与健康品类成快手季节爆款主力。  <br/>对应人群行动建议：服饰商家提前30天布局换季款，女款侧重设计（如廓形、印花），男款强化功能（如防水、保暖）；大促推出“引流款（99元）+利润款（300-500元）”组合，同时搭配取暖电器、营养品等关联品类做套装销售。</p><h4><a name="t11" target="_blank"/>（二）食品品类：节庆爆发+速食刚需，健康属性成卖点</h4><p>中秋期间快手月饼预估直播销量环比增306.27%，抖音广式月饼占比92.81%（蛋黄、双黄是核心口味）；速食冻品全年热销，快手9月销售热度环比增53.07%，细分品类中火锅丸料增速111.57%，中式面点增101.04%，米饭/面条/粥/罐头增63.79%。消费者偏好“配料干净”“方便快捷”“多口味组合”，小红书美食话题也印证这一趋势：“一周美食打卡”以4.9亿次浏览量领先，“快乐就是开榴莲”“大学生爱吃”等社交分享类话题流量集中。  <br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047439452" alt="" title="" loading="lazy"/>  <br/>速食冻品品类环比增长条形图表3图表数据及PDF模板已分享到会员群  <br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047439453" alt="" title="" loading="lazy"/>  <br/>小红书美食话题浏览量气泡图表1图表数据及PDF模板已分享到会员群  <br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047439454" alt="" title="" loading="lazy"/>  <br/>小红书美食话题浏览量条形图表1图表数据及PDF模板已分享到会员群  <br/>3秒解读：食品品类“节庆做礼盒、日常做刚需”，速食细分品类爆发式增长，社交分享类内容是流量核心入口。  <br/>对应人群行动建议：食品商家绑定节庆推出礼盒装（如中秋月饼+茶叶组合），速食类开发家庭场景组合装（如火锅丸料+蘸料套装）；在小红书等平台布局“打卡式”种草内容，植入“配料干净”“方便加热”等关键词，适配年轻用户社交与实用需求。</p><h4><a name="t12" target="_blank"/>（三）全域品类对比：平台优势决定品类选择</h4><p>不同平台品类优势差异显著：抖音电商双十一期间男装GMV增长58%，运动户外增45.3%，清洁电器增47.53%，酒类销售热度增41%，平台整体GMV提升42%；快手3C数码、黄金珠宝双11客单价环比增38.38%；跨境品类中家居园艺（39.7%）、鞋服箱包（38.1%）占出海商家布局70%+；B2C细分市场销售额方面，兴趣消费以3800亿元领先，保健品突破1100亿元，宠物主粮上半年近80亿元，反映消费多元化趋势。  <br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047439455" alt="" title="" loading="lazy"/>  <br/>抖音电商热门品类销售占比华夫图表1图表数据及PDF模板已分享到会员群  <br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047439456" alt="" title="" loading="lazy"/>  <br/>抖音电商品类销售增长率条形图表2图表数据及PDF模板已分享到会员群  <br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047439457" alt="" title="" loading="lazy"/>  <br/>出海商家布局品类分布半圆面积图表B2图表数据及PDF模板已分享到会员群  <br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047439458" alt="" title="" loading="lazy"/>  <br/>B2C电商细分市场销售额华夫图表A1图表数据及PDF模板已分享到会员群  <br/>3秒解读：抖音强于男装、运动户外等品类，快手擅长高客单价与季节品类，跨境聚焦家居鞋服，B2C市场呈现“兴趣消费+健康+宠物”三驾马车格局。  <br/>对应人群行动建议：跨平台商家在抖音推男装、运动户外等成长型品类，快手强化黄金珠宝等高客单价品类；跨境卖家聚焦家居、鞋服，适配新兴市场家庭场景；B2C商家可重点布局兴趣消费（如潮玩、小众家电）、保健品、宠物主粮三大高潜力赛道。  <br/>本章节配套《2025热门电商品类运营手册》，含选品指南与营销话术，进群获取。</p><h3><a name="t13" target="_blank"/>四、营销革命：搜索+内容的精准转化闭环</h3><h4><a name="t14" target="_blank"/>（一）看后搜：内容转消费的关键链路</h4><p>抖音“看后搜”贡献1/4电商需求搜索次数，日均PV 1.1亿，同比增速是主动搜3.2倍。平台“看后搜养词计划”通过三大工具提升转化：搜索底纹降低用户记忆成本（点击增40%）、奇异果工具抢占首屏（曝光增50%）、小飞匣在商品列表透传优惠（点击率增40%），参与商家搜索GMV平均增30%+。小红书美食话题的流量集中也印证“内容→搜索”的转化逻辑，热门话题下用户搜索相关商品的行为占比超30%。  <br/>3秒解读：看后搜是“内容种草→搜索承接”的核心桥梁，不做搜索营销将流失1/4流量，内容话题与搜索关键词需精准匹配。  <br/>对应人群行动建议：商家在短视频标题、评论区植入核心词（如“广式月饼蛋黄味”“速食火锅丸料家庭装”），配置看后搜小蓝词；用奇异果工具绑定新品，抢占搜索结果首屏，同时在热门话题下发布种草内容，引导用户搜索转化。</p><h4><a name="t15" target="_blank"/>（二）内容种草：达人分层+UGC验证的金字塔模型</h4><p>克劳锐调研显示，KOL种草内容引发消费欲望的占比超40%，素人真实分享促成消费的占比29.5%。平台达人运营呈现“金字塔”结构：快手中腰部播主占速食冻品销售53.6%，抖音品牌用“头部达人造势（如明星）+腰部达人垂种（如垂类KOL）+素人UGC发酵”组合，实现声量与销量双爆发。但独立站商家面临营销转化难的痛点，55.8%的商家受困于产品同质化，46.5%认为烧钱模式不可持续，内容种草成为破解这些痛点的关键。  <br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047439459" alt="" title="" loading="lazy"/>  <br/>品牌独立站运营痛难点分布条形图表B1图表数据及PDF模板已分享到会员群  <br/>3秒解读：内容种草不能只靠头部达人，中腰部与素人的“真实性”更能打动用户，独立站需通过差异化内容破解同质化与获客难题。  <br/>对应人群行动建议：品牌按“3:5:2”预算分配头部、中腰部、素人达人；独立站商家通过UGC内容（如买家秀、使用测评）破解流量难题，强化私域沉淀，同时聚焦产品差异化设计，避免同质化竞争。</p><h3><a name="t16" target="_blank"/>五、核心对比与落地指引</h3><h4><a name="t17" target="_blank"/>（一）不同平台双11策略对比表</h4><table><thead><tr><th>核心主题</th><th>报告名称</th><th>核心结论</th><th>数据差异</th><th>原因分析</th></tr></thead><tbody><tr><td>双11周期</td><td>《飞瓜数据：2025年10月飞瓜抖音电商营销月报》</td><td>周期60天，分5个阶段</td><td>抖音周期长于快手、天猫</td><td>抖音侧重全周期流量沉淀，强化用户粘性，适配年轻用户长决策周期</td></tr><tr><td> </td><td>《飞瓜数据：2025年10月飞瓜快手直播电商月报》</td><td>周期约45天，分预售期、正式活动期</td><td> </td><td>快手聚焦核心阶段爆发，适配下沉市场“短决策、高转化”消费习惯</td></tr><tr><td>直播电商增速</td><td>《2025年双十一抖音电商趋势盘点及行业洞察报告》</td><td>抖音服饰内衣GMV同比增长显著</td><td>抖音男装GMV增58%，高于快手同类品类</td><td>抖音内容生态更丰富（短视频+直播），种草转化链路更短</td></tr><tr><td> </td><td>《飞瓜数据：2025年10月飞瓜快手直播电商月报》</td><td>快手羽绒服品类增速达534.28%</td><td> </td><td>快手在下沉市场服饰消费渗透率更高，换季需求集中爆发</td></tr><tr><td>跨境下载量</td><td>《Sensor Tower：2025年购物季电商应用市场洞察报告》</td><td>Temu新兴市场下载量暴涨</td><td>非洲市场增速178%，美国市场下滑50%</td><td>政策环境（美国关税）与消费潜力差异，新兴市场竞争格局宽松，用户增长空间大</td></tr></tbody></table><h4><a name="t18" target="_blank"/>（二）可落地的3件事</h4><ol><li><strong>工具适配+搜索布局</strong>：15天内完成平台“看后搜”配置，核心品类（如羽绒服、速食、广式月饼）各制作3-5条带关键词的种草短视频，用奇异果工具抢占搜索首屏，同时在小红书热门话题下布局内容，引导用户搜索转化；</li><li><strong>跨境+品类聚焦</strong>：7天内完成巴西、尼日利亚市场调研，对接本地物流商（如巴西Correios），Temu等平台广告预算向新兴市场倾斜至50%，重点布局家居园艺、鞋服箱包等跨境优势品类；B2C商家聚焦兴趣消费、保健品、宠物主粮三大高销售额赛道；</li><li><strong>季节+大促运营</strong>：服饰商家聚焦羽绒服、毛衣等换季款，搭配取暖电器做套装销售；食品商家推出“节庆礼盒+日常组合装”，突出“配料干净”卖点；双11分阶段运营，预热期种草、专场期爆发、返场期清仓，同步优化攻略类内容。</li></ol><h4><a name="t19" target="_blank"/>（三）风险提示与应对方案</h4><ol><li><strong>流量成本上升风险</strong>：头部达人坑位费同比增20%+，投流ROI下降5%-10%。应对方案：优先选择中腰部达人（坑位费低30%，转化高15%），采用“保底+佣金”模式；社群提供达人报价参考与投流ROI优化工具，助力精准投放；</li><li><strong>合规经营风险</strong>：平台查处虚假宣传力度加大，抖音2025年清退涉事商家1603家。应对方案：建立“文案审核-直播脚本核查”机制，重点规避“夸大功效”表述；社群提供《电商合规经营手册》，每月更新平台规则；</li><li><strong>供应链波动风险</strong>：双11期间物流延误率增15%，库存积压率增10%。应对方案：采用“预售（占比40%）+现货（占比60%）”模式，优化库存周转；接入平台物流履约服务（如快手“蟹无忧”），提升配送效率；社群对接优质供应链，提供库存管理工具；</li><li><strong>同质化竞争风险</strong>：55.8%的独立站商家受困于产品同质化。应对方案：聚焦细分品类（如宠物主粮高端款、小众兴趣消费），强化产品差异化设计；通过UGC内容打造品牌独特心智，沉淀私域用户。</li></ol><h3><a name="t20" target="_blank"/>六、用户需求场景与核心报告推荐</h3><table><thead><tr><th>用户类型</th><th>核心需求场景</th><th>重点推荐报告</th><th>报告价值一句话说明</th></tr></thead><tbody><tr><td>电商创业者</td><td>选品布局、平台入驻</td><td>《飞瓜数据：2025年9月飞瓜抖音电商营销月报》《2025年双十一抖音电商趋势盘点及行业洞察报告》</td><td>明确各平台热门品类增速（抖音男装增58%、快手羽绒服增534%）与大促玩法，降低选品试错成本</td></tr><tr><td>品牌商家</td><td>双11营销、流量获取</td><td>《克劳锐：2025电商双11社交媒体内容消费洞察报告》《抖音电商2025「看后搜养词计划」营销通案》</td><td>提供“内容种草（KOL+UGC）+搜索承接”全流程指引，助力大促GMV增长30%+</td></tr><tr><td>跨境卖家</td><td>市场拓展、合规运营</td><td>《Sensor Tower：2025年购物季电商应用市场洞察报告》《未来电商报告：品牌独立站五步升级锁定未来确定性增长》</td><td>解析新兴市场（巴西、非洲）机会与独立站运营痛点，支撑跨境布局决策</td></tr><tr><td>B2B商家</td><td>数字化转型、增速突破</td><td>《毕马威：中国工业品电商高质量发展白皮书（2025）》</td><td>提供工业品数字化采购转型路径，破解增速放缓难题</td></tr><tr><td>营销从业者</td><td>玩法创新、效果提升</td><td>《2025抖音电商「看后搜养词计划」营销通案》《2025抖音电商时尚红人之书》</td><td>拆解平台营销工具（奇异果、小飞匣）与达人矩阵运营方法，提升营销转化效率</td></tr></tbody></table><h3><a name="t21" target="_blank"/>文末数据图表列表</h3><ol><li>出海商家布局品类分布半圆面积图表B2.pdf</li><li>B2C电商销售额增长率半圆面积图表A2.pdf</li><li>小红书美食话题浏览量气泡图表1.pdf</li><li>抖音电商热门品类销售占比华夫图表1.pdf</li><li>B2C电商细分市场销售额华夫图表A1.pdf</li><li>速食冻品品类环比增长条形图表3.pdf</li><li>快手女装品牌客单价横向条形图表2.pdf</li><li>快手电商品类环比增长条形图表1.pdf</li><li>小红书美食话题浏览量条形图表1.pdf</li><li>双11用户攻略内容关注原因条形图表C1.pdf</li><li>品牌独立站运营痛难点分布条形图表B1.pdf</li><li>Temu全球市场MAU增长率横向条形图表A1.pdf</li><li>抖音平台与商家增长率对比条形图表3.pdf</li><li>抖音电商品类销售增长率条形图表2.pdf</li><li>工业品电商复合增长率折线图表B2.pdf</li><li>B2B电商市场规模渗透率组合图表B1.pdf</li></ol><h3><a name="t22" target="_blank"/>本专题内的参考报告（PDF）目录</h3><ol><li>2025年兴趣品类电商消费趋势报告 报告2025-11-27</li><li>中国工业品电商高质量发展白皮书（2025） 报告2025-11-21</li><li>2025年双十一抖音电商趋势盘点及行业洞察报告 报告2025-11-19</li><li>中国跨境电商人才培养白皮书（2025） 报告2025-11-17</li><li>抖音电商200个干货问题知识手册 报告2025-11-17</li><li>2025年电商行业数据报告-保健品报告 报告2025-11-15</li><li>2025年10月飞瓜抖音电商营销月报 报告2025-11-15</li><li>2025电商双11社交媒体内容消费洞察报告 报告2025-11-15</li><li>2025年购物季电商应用市场洞察报告 报告2025-11-14</li><li>2025宠物行业电商趋势解析 报告2025-11-14</li><li>2025年跨境电商出海国别指南（德国） 报告2025-11-12</li><li>2025抖音电商「看后搜养词计划」营销通案 报告2025-11-12</li><li>2025年10月快手直播电商营销月报 报告2025-11-11</li><li>抖音电商品牌宝典6.0 报告2025-11-10</li><li>2025年中国跨境电商ERP市场研究报告 报告2025-11-10</li><li>TikTokShop跨境电商全托管黑五大促官方备战指南 报告2025-11-10</li><li>2025年购物季电商应用与品牌市场洞察 报告2025-11-10</li><li>未来电商报告：品牌独立站五步升级锁定未来确定性增长 报告2025-11-08</li><li>2025小红书电商家居家具行业行业运营指南 报告2025-11-06</li><li>2025世界互联网大会跨境电商实践案例集 报告2025-11-06</li><li>飞瓜数据：2025年9月飞瓜快手直播电商月报 报告2025-10-31</li><li>飞瓜数据：2025年9月飞瓜抖音电商营销月报 报告2025-10-31</li><li>2025抖音电商时尚红人之书 报告2025-10-31</li><li>银发经济的关节之光：MOVEFREE益节的抖音电商品牌拆解 报告2025-10-31</li><li>2025小红书电商双11-美食滋补行业运营指南 报告2025-10-31</li><li>2025中国跨境电商+产业带数据报告 报告2025-10-23</li><li>2025年9月快手直播电商营销月报 报告2025-10-19</li><li>电商行业深度报告-AI+电商服务进入提效阶段-关注后续业绩兑现 报告2025-10-16</li><li>2025年9月抖音短视频及直播电商营销月报 报告2025-10-15</li><li>2024跨境电商出口海外仓出口退（免）税操作指引 报告2025-10-08</li><li>2025抖音电商节盟计划招商方案 报告2025-09-27</li><li>2025年8月飞瓜快手直播电商月报 报告2025-09-26</li><li>2025年8月飞瓜抖音电商营销月报 报告2025-09-26</li><li>2025年中国私域电商行业趋势白皮书 报告2025-09-21</li><li>2025中国出口跨境电商白皮书——产品创新出海品牌五十强 报告2025-09-17</li><li>2024年跨境电商产品创新能力白皮书 报告2025-09-16</li><li>2025抖音电商下半年运营筹备建议 报告2025-09-12</li><li>电商配送基准报告2024-穿越现代消费者旅程的复杂性 报告2025-09-10</li><li>2025中亚电商市场洞察报告 报告2025-09-08</li><li>2025年8月抖音电商营销月报 报告2025-09-08</li><li>2025年8月快手直播电商月报 报告2025-09-07</li><li>大湾区跨境电商供应链金融发展与安全白皮书（2025） 报告2025-09-04</li><li>2025上半年农产品电商报告 报告2025-09-04</li><li>2025年银发电商的精准营销策略 报告2025-09-04</li><li>全球关税影响下跨境电商表现与趋势展望：2025年Prime Day复盘... 报告2025-09-03</li><li>2025俄罗斯电商市场洞察报告 报告2025-09-01</li><li>老牌焕新-拥抱电商实现再爆发 报告2025-08-25</li><li>2025年中国出口跨境电商发展趋势白皮书 报告2025-08-25</li><li>2024银发电商：银发经济发展新探索 报告2025-08-22</li><li>2025隐形眼镜（美瞳）-电商市场洞察与趋势报告 报告2025-08-20</li><li>2025年澳大亚电商消费洞察及亚马逊澳洲站选品洞察 报告2025-08-20</li><li>2025年Q2男装电商销售复盘报告 报告2025-08-19</li><li>2025抖音电商护肤趋势白皮书 报告2025-08-19</li><li>2025年Q2中高端女装电商数据复盘报告 报告2025-08-18</li><li>2025年Q2童装电商销售复盘报告 报告2025-08-17</li><li>2025年Q2女装电商销售复盘报告 报告2025-08-16</li><li>2025年Q2户外电商销售复盘报告 报告2025-08-15</li><li>2025年7月快手直播电商月报 报告2025-08-15</li><li>全球宠物用品电商市场分析报告 报告2025-08-12</li><li>2025年日本电商市场洞察与独立站出海解决方案 报告2025-08-12</li><li>社交电商热潮的背后 报告2025-08-08</li><li>2025年7月抖音电商营销月报 报告2025-08-08</li><li>2025全球跨境电商供应链发展趋势报告 报告2025-08-07</li><li>2025上半年跨境电商行业报告 报告2025-08-06</li><li>2025年零售电商产业云端应用趋势报告 报告2025-08-05</li><li>2025年跨境电商东南亚市场进入战略白皮书 报告2025-08-05</li><li>2025电商大促消费趋势与心智洞察 报告2025-08-05</li><li>2025年从马来西亚到东南亚：电商跨境扩展实用指南 报告2025-08-04</li><li>2025年从马来西亚到东南亚：电商跨境扩展实用指南 报告2025-08-04</li><li>2025上半年飞瓜抖音电商与广告投放报告 报告2025-08-01</li><li>2025上半年抖音电商与广告投放报告 报告2025-08-01</li><li>2025年6月飞瓜抖音电商营销月报 报告2025-08-01</li><li>跨境电商服务商网络赋能产业带增长报告 报告2025-07-29</li><li>2025年全球电商平台概览报告 报告2025-07-23</li><li>2025年产品-国家 需求一览表（跨境电商市场资料） 报告2025-07-23</li><li>2025年上中国电商平台商家投诉数据报告 报告2025-07-21</li><li>2025年电商“三巨头”干亿补贴押宝即时零售全景分析报告 报告2025-07-19</li><li>商贸零售-电商领域的 “日常应用” 之争：外卖&amp;即时配送的市场规模、交... 报告2025-07-17</li><li>拼多多跨境电商Temu商业模式、空间展望及优势研判分析报告 报告2025-07-16</li><li>银发电商：2024银发经济发展新探索报告 报告2025-07-10</li><li>美发护发抖音电商策略报告 报告2025-07-09</li><li>2025年618期间中国电商平台商家投诉数据报告 报告2025-07-09</li><li>2025年6月抖音短视频及直播电商营销月报 报告2025-07-06</li><li>全球电商行业AI应用研究报告2025 报告2025-07-05</li><li>抖音电商618趋势盘点及行业洞察报告 报告2025-07-05</li><li>2025年跨境电商DTC全阶段营销制胜白皮书 报告2025-07-03</li><li>2025快手电商商家全域经营指南 报告2025-07-02</li><li>2025小红书闭环电商推广投放产品与方法论 报告2025-07-01</li><li>2025年电商银发人群深度研究报告 报告2025-06-30</li><li>2025人工智能赋能跨境电商女性出海白皮书 报告2025-06-26</li><li>2025年618电商大促营销风云录 报告2025-06-25</li><li>2025跨境电商东南亚市场进入战略白皮书 报告2025-06-23</li><li>电商团队员工奖惩管理制度 报告2025-06-19</li><li>微信电商生态盈利模式——全域增长模型 报告2025-06-17</li><li>2025年5月抖音电商营销月报 报告2025-06-17</li><li>2025生活用纸品类电商白牌白皮书 报告2025-06-17</li><li>2025年中国跨境电商SaaS市场行业报告 报告2025-06-17</li><li>2025年5月飞瓜快手直播电商月报 报告2025-06-17</li><li>2025年5月飞瓜抖音电商营销月报 报告2025-06-17</li><li>2025年电商行业安全白皮书 报告2025-06-09</li><li>2025年5月抖音短视频及直播电商营销月报 报告2025-06-09</li><li>2025年5月快手直播电商营销月报 报告2025-06-08</li><li>2025年中国跨境电商中大型品牌商家ERP需求洞察报告 报告2025-05-30</li><li>2025年电商行业发展报告 报告2025-05-30</li><li>2025年睡眠经济电商市场分析报告 报告2025-05-26</li><li>2025年快手电商618消费趋势·预热篇 报告2025-05-20</li><li>2025年618电商趋势预测与机遇前瞻 报告2025-05-19</li><li>2025年Q1中高端男装电商数据复盘 报告2025-05-17</li><li>2025食品电商行业消费新趋势新洞察报告 报告2025-05-14</li><li>2024年直播电商高质量发展报告 报告2025-05-13</li><li>2025年4月抖音短视频及直播电商营销月报 报告2025-05-12</li><li>2025年全球电商报告：战略伙伴同盟下的挑战应对及市场拓展 报告2025-05-11</li><li>2025年4月快手直播电商营销月报 报告2025-05-11</li><li>2024年复盘及电商消费新趋势 报告2025-05-04</li><li>2025年饼干膨化零食电商消费趋势 报告2025-04-29</li><li>2025抖音电商中小商家内容经营指南 报告2025-04-28</li><li>2024年度中国生鲜电商市场数据报告 报告2025-04-26</li><li>2025年3月快手直播电商营销月报 报告2025-04-24</li><li>2025年3月抖音短视频及直播电商营销月报 报告2025-04-24</li><li>2024 AI驱动电商增长：亚马逊、沃尔玛等平台自动化实践的成功之道研... 报告2025-04-23</li><li>2025小红书电商家具家装行业运营指南 报告2025-04-17</li><li>小红书电商新手商家如何从0-1完成出单？ 报告2025-04-15</li><li>TTS跨境电商——全托管模式：全球爆品，轻松打造 报告2025-04-15</li><li>2025年Q1抖音电商季度增长报告 报告2025-04-15</li><li>2025年Q1中国电商平台商家投诉数据报告 报告2025-04-12</li><li>2025年3月抖音短视频及直播电商月报 报告2025-04-11</li><li>2025年跨境电商选品策略与热门市场分析报告 报告2025-04-10</li><li>电商银发人群深度研究 报告2025-04-02</li><li>2025宠物电商市场分析报告 报告2025-03-31</li><li>2025年全链路跨境电商白皮书-跨境电商行业解决方案指南 报告2025-03-29</li><li>2025年数智化电商产业带发展研究报告 报告2025-03-27</li><li>2024电商平台化学品管理指南 报告2025-03-27</li><li>2024年Q4中高端男装电商数据复盘报告 报告2025-03-24</li><li>2025年抖音电商个护家清营销趋势报告 报告2025-03-22</li><li>2025年1月中国电商平台商家投诉数据报告 报告2025-03-16</li><li>2025年2月快手直播电商营销月报 报告2025-03-16</li><li>2024年度中国生鲜电商行业消费投诉数据与典型案例报告 报告2025-03-09</li><li>2024抖音电商行业这一年 报告2025-03-09</li><li>2024年度中国生鲜电商消费投诉数据与典型案例报告 报告2025-03-05</li><li>跨境电商行业深度报告-国货出海方兴未艾-看好供应链及品牌全球化 报告2025-03-03</li><li>2025年抖音电商食品饮料营销趋势报告 报告2025-03-03</li><li>2025年1月短视频及直播电商营销月报 报告2025-02-28</li><li>2024年度中国出口跨境电商消费投诉数据与典型案例报告 报告2025-02-26</li><li>2025年01月短视频及直播电商营销月报 报告2025-02-25</li><li>2024年度快手电商全景洞察 报告2025-02-25</li><li>2024年12月快手直播电商营销月报 报告2025-02-25</li><li>2024年12月短视频及直播电商营销月报 报告2025-02-25</li><li>海外消费者、产品与价格调研报告：探寻跨境电商新趋势 报告2025-02-24</li><li>2025年宠物保健品抖音电商行业分析报告 报告2025-02-18</li><li>2024年跨境电商产业带研究报告 报告2025-02-17</li><li>2025年1月抖音短视频及直播电商月报 报告2025-02-14</li><li>2025年全球电商营销趋势报告 报告2025-02-13</li><li>2024年北欧电商市场分析报告 报告2025-02-12</li><li>2025小红书电商时尚商家playbook 321经营一本通 报告2025-02-11</li><li>2025抖音电商彩妆护肤营销趋势报告 报告2025-02-11</li><li>2024快手电商体验报告 报告2025-02-08</li><li>侵蚀您的利润：网络爬虫程序对电商行业有何影响 报告2025-02-06</li><li>2024达人电商全年报 报告2025-02-06</li><li>2024年跨境电商品牌代理问题对策建议 报告2025-02-05</li><li>2024年度快手电商全景洞察 报告2025-01-26</li><li>2024年抖音电商年报 报告2025-01-26</li><li>东南亚3C电子电商行业市场洞察 报告2025-01-25</li><li>2025中国企业跨境电商行业洞察 报告2025-01-24</li><li>2024跨境电商行业年度报告 报告2025-01-17</li><li>2025，从电商及产业互联网看出海新机遇 报告2025-01-14</li><li>2024抖音电商年度报告(美妆乳品大健康解析） 报告2025-01-14</li><li>2024年电商应用与品牌市场洞察报告 报告2025-01-13</li><li>2024年12月快手直播电商营销月报 报告2025-01-13</li><li>东南亚家用电器电商行业市场洞察报告（2024年12月版） 报告2025-01-12</li><li>2024年12月抖音短视频及直播电商月报 报告2025-01-12</li><li>2024年抖音电商年度高增长报告 报告2025-01-09</li><li>2024抖音内容电商年度报告(美妆乳品大健康解析） 报告2025-01-08</li><li>2024年11月快手直播电商营销月报 报告2024-12-31</li><li>2025抖音电商年货节策略指南 报告2024-12-31</li><li>2024跨境电商行业研究报告 报告2024-12-30</li><li>2024年出口跨境电商促销趋势白皮书 报告2024-12-30</li><li>电商大模型及搜索应用实践 报告2024-12-26</li><li>Pacvue泊客电商2024Q3亚马逊沃尔玛全球电商CPC数据报告 报告2024-12-26</li><li>2024电商消费趋势年度报告 报告2024-12-25</li><li>飞瓜：2024年11月抖音短视频及直播电商月报 报告2024-12-24</li><li>解数：2024明星彩妆品牌电商数据深度拆解报告 报告2024-12-24</li><li>MikMak：2025年电商消费趋势报告（英文版） 报告2024-12-20</li><li>蝉妈妈&amp;蝉魔方：2024抖音电商母婴行业分析报告 报告2024-12-19</li><li>亚马逊全球开店：2025全球电商消费趋势及选品洞察报告 报告2024-12-17</li><li>世邦魏理仕：2024年从起飞到巡航：中国跨境电商仓库需求分析与展望 报告2024-12-16</li><li>蝉妈妈：2024年抖音电商10月品类增长月报 报告2024-12-16</li><li>CCPIT：跨境电商行业可持续发展白皮书 报告2024-12-14</li><li>DT研究院：2024年付费电商会员体验报告 报告2024-12-11</li><li>网经社：2024年“双11期间”中国电商平台商家投诉数据报告 报告2024-12-06</li><li>GoodsFox：2024年美国电商营销洞察报告 报告2024-12-04</li><li>知衣：2025春夏跨境电商女装白皮书 报告2024-12-02</li><li>CCPIT：2024年中国贸促会跨境电商重点联系企业名录 报告2024-12-02</li><li>有米云：2024年美国电商营销洞察报告 报告2024-11-30</li><li>世界互联网大会：2024年跨境电商竞争力研究报告-国别维度 报告2024-11-30</li><li>即时电商发展报告（2024）-即时电商迈向满足“全面需求”新时代 报告2024-11-30</li><li>智研咨询：跨境电商产业百科（附行业市场现状、发展前景及投资方向分析预测... 报告2024-11-29</li><li>世界互联网大会：2024年跨境电商竞争力研究报告-物流企业 报告2024-11-29</li><li>雨果跨境：2024年跨境电商行业趋势报告 报告2024-11-28</li><li>世界互联网大会：2024年跨境电商竞争力研究报告-平台企业 报告2024-11-28</li><li>深企投：2024跨境电商行业研究报告 报告2024-11-27</li><li>维卓：2024全球时尚行业电商趋势报告 报告2024-11-26</li><li>祈飞：2024年双十一电商趋势盘点及行业洞察报告 报告2024-11-24</li><li>慧科：2024全球时尚行业电商趋势报告 报告2024-11-23</li><li>飞瓜数据：2024年快手双11购物节电商数据报告 报告2024-11-23</li><li>Flywheel：2024年双11电商消费回顾及趋势总结报告 报告2024-11-20</li><li>ESG跨境：2024年全球跨境电商平台开店大全报告-日韩篇 报告2024-11-19</li><li>玺承：2024年淘系电商分析及展望报告 报告2024-11-18</li><li>蝉妈妈：2024抖音电商双11大促复盘报告 报告2024-11-18</li><li>维卓：2024欧洲社交电商洞察报告 报告2024-11-16</li><li>飞瓜数据：2024年10月快手直播电商营销月报 报告2024-11-16</li><li>ESG跨境：2024全球跨境电商平台开店大全 报告2024-11-15</li><li>欧鹭：2024跨境电商洞察白皮书：内容电商崛起与绿色消费潮流中的增长机... 报告2024-11-14</li><li>ESG跨境：全球电商平台详解 报告2024-11-11</li><li>鸥鹭：2024跨境电商洞察白皮书 报告2024-11-08</li><li>飞瓜：2024年10月抖音短视频及直播电商月报 报告2024-11-08</li><li>Riskified ：2024网购消费者对滥用电商政策的态度调研报告 报告2024-11-08</li><li>雨果：2024年跨境电商行业三季度报告 报告2024-11-07</li><li>Pacvue：2024Q3亚马逊&amp;沃尔玛全球电商CPC数据报告 报告2024-11-07</li><li>2024年跨境电商独立站入门白皮书 报告2024-11-07</li><li>亚马逊云&amp;德勤：生成式AI赋能零售电商行业白皮书 报告2024-11-05</li><li>亚马逊：2024年出口拉丁美洲跨境电商行业洞察报告亚马逊全球开店 报告2024-11-04</li><li>新华网：2024中国数智消费社媒电商市场洞察 报告2024-11-04</li><li>雨果跨境：2024跨境电商行业三季度报告 报告2024-11-03</li><li>交个朋友：电商行业产业带直播研究报告系列：让更多源头工厂 “被看见”，... 报告2024-11-03</li><li>蝉妈妈：2024年抖音电商小家电行业分析报告 报告2024-10-31</li><li>网经社：2024年Q3中国电商平台商家投诉数据报告 报告2024-10-29</li><li>飞瓜数据：2024年9月快手直播电商营销月报 报告2024-10-29</li><li>飞瓜数据：2024年9月抖音短视频及直播电商月报 报告2024-10-29</li><li>营销云：2024年美妆个人护理跨境电商专题研究报告 报告2024-10-27</li><li>蝉妈妈：2024年抖音电商9月品类增长月报 报告2024-10-27</li><li>知衣：跨境电商2025春夏关键图案趋势报告-女装-连衣裙 报告2024-10-25</li><li>TMO Group：东南亚食品饮料电商行业市场洞察报告（2024年9月... 报告2024-10-25</li><li>新华网：2024中国数智社媒电商市场洞察报告 报告2024-10-24</li><li>营销云：2024年美妆个人护理跨境电商专题研究 报告2024-10-23</li><li>维卓：2024澳大利亚社交电商趋势报告 报告2024-10-23</li><li>维卓：2024美国电商节假日销售趋势分析 报告2024-10-21</li><li>蝉妈妈&amp;蝉魔方：2024抖音电商“肤感”护肤趋势洞察 报告2024-10-10</li><li>蝉妈妈：2024年抖音电商双十一备战攻略汇总 报告2024-10-09</li><li>有米云：2024年抖音电商个护美体趋势洞察报告 报告2024-10-06</li><li>百联集团：大型商业零售电商平台云转型最佳实践：云迁移框架白皮书 报告2024-10-06</li><li>艾瑞咨询：2024年中国电商市场研究报告 报告2024-10-06</li><li>百联集团：大型商业零售电商平台云转型最佳实践：云迁移框架白皮书 报告2024-10-06</li><li>百联&amp;华为：2023年大型商业零售电商平台云迁移框架白皮书V2.0 报告2024-10-06</li><li>霞光智库：2024中国跨境电商北美市场研究报告：迷雾破局下的逆势生长之... 报告2024-09-30</li><li>沃尔玛全球电商：沃尔玛全球电商店铺运营90天指南 报告2024-09-30</li><li>小红书：小红书潮流服饰行业：电商经营商家成长路径指南 报告2024-09-27</li><li>小红书：小红书种草学-乘风而上：助力电商生意增长 报告2024-09-26</li><li>抖音电商：2024抖音电商CORE经营方法论手册 报告2024-09-24</li><li>抖音电商：2024年丰收节抖音电商助农数据报告 报告2024-09-19</li><li>抖音电商&amp;品牌星球：抖音电商DOU Case年鉴2024 报告2024-09-19</li><li>抖音电商&amp;织衣科技：2024年秋冬抖音服饰六大趋势方向报告 报告2024-09-16</li><li>飞瓜数据：2024年8月快手直播电商营销月报 报告2024-09-12</li><li>飞瓜数据：2024年8月抖音短视频及直播电商月报 报告2024-09-12</li><li>网经社：2024年电商平台“仅退款”调查报告 报告2024-09-10</li><li>飞瓜：2024年社媒电商大健康行业趋势洞察白皮书 报告2024-09-05</li><li>慧策：2024跨境电商指导手册 报告2024-09-04</li><li>Shopee：2024巴西电商市场概览报告 报告2024-09-04</li><li>抖音电商：抖音电商商家自播白皮书 报告2024-08-30</li><li>蝉妈妈&amp;蝉魔方：2024年抖音电商衣物清洁行业报告 报告2024-08-30</li><li>维卓：2024全球电商消费电子市场研究报告 报告2024-08-29</li><li>班牛：2024电商客服服务指标数据行业报告 报告2024-08-29</li><li>艾媒咨询：2024年中国品牌电商服务商行业研究报告 报告2024-08-27</li><li>知衣科技：跨境电商2025春夏关键图案趋势报告-女装-连衣裙 报告2024-08-26</li><li>抖音电商：抖音电商2024年度趋势报告-造风者 报告2024-08-26</li><li>蝉妈妈&amp;蝉魔方：2024抖音电商茶叶行业分析报告 报告2024-08-25</li><li>Shopee：2024菲律宾电商市场概览 报告2024-08-24</li><li>有米云：2024抖音电商护肤趋势洞察报告 报告2024-08-23</li><li>雨果跨境：2024跨境电商行业二季度报告 报告2024-08-22</li><li>威胁猎人：2024上半年度海外电商平台风险研究报告 报告2024-08-20</li><li>Shopee：2024墨西哥电商市场概览报告 报告2024-08-19</li><li>Shopee：2024哥伦比亚电商市场概览报告 报告2024-08-19</li><li>Checkout：2024中东北非地区电商报告 报告2024-08-19</li></ol>]]></description></item><item>    <title><![CDATA[Rokid应用实践：基于AI Glass]]></title>    <link>https://segmentfault.com/a/1190000047439479</link>    <guid>https://segmentfault.com/a/1190000047439479</guid>    <pubDate>2025-12-01 00:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>一、创意缘起：工作堆积如山，科技顺其有序</h2><p>场景：</p><p>下午 2 点的快递站仓库，王师傅蹲在堆积如山的快件中，左手抱着一摞包裹，右手紧握扫码枪对准条码扫描。他需要频繁弯腰将快件放入对应货架格，汗水浸湿后背工装。</p><p><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdndk9" alt="" title=""/></p><p>当 Rokid AI Glasses 智能眼镜遇见智慧物流</p><p>在快递业务量持续增长的今天，快递站工作人员面临着巨大的分拣压力。传统的快件录入需要反复查看面单、手动输入信息、分类摆放，整个过程耗时耗力且容易出错。而 Rokid AI Glasses 的出现，为这一场景带来了新的解决方案。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047439482" alt="image.png" title="image.png" loading="lazy"/></p><p>本文将详细介绍如何利用 Rokid CXR-M（移动端）和 CXR-S（眼镜端）SDK，构建一个解放双手的快件录入归类助手，实现"所见即所得"的智能分拣体验。</p><h2>二、系统架构设计</h2><h3>架构总览</h3><p>系统采用 “眼镜端采集 + 手机端协同 + 云端同步” 的三层架构，核心依赖 Rokid SDK 实现设备交互与数据流转：</p><p>• 终端层（CXR-S AI眼镜）</p><p>作为“感知与输出终端”，负责快件条码识别、语音指令接收、操作指引显示，基于 CXR-S SDK 实现本地 AI 识别与状态监听</p><p>• 业务逻辑层（CXR-M移动设备）</p><p>通过 CXR-M SDK 实现设备连接管理、数据缓存、云端通信，承接眼镜端采集的数据并同步至管理系统。</p><p>• 云端层（数据服务）</p><p>提供快件信息校验、归类规则存储、数据统计分析功能，通过 API 与手机端实时交互。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047439483" alt="image.png" title="image.png" loading="lazy"/></p><h3>核心技术依赖</h3><ul><li>设备连接：基于 CXR-M SDK 的蓝牙扫描、Wi-Fi P2P 连接能力，保障设备稳定通信。</li><li>数据采集：借助眼镜端相机接口（CXR-M SDK openGlassCamera）实现条码扫描，语音识别接口接收操作指令。</li><li>交互展示：通过提词器场景（configWordTipsText）显示快件信息与归类指引，自定义界面场景展示实时数据。</li><li>数据同步：利用 Wi-Fi P2P 高速传输能力（startSync）实现快件图片、信息的即时同步。</li></ul><h2>三、关键功能技术实现</h2><h3>(一).眼镜端（CXR-S SDK）集成配置</h3><h4>1.环境准备与依赖导入</h4><h5>配置 Maven 仓库</h5><p>在项目settings.gradle.kts中添加 Rokid Maven 仓库，确保 SDK 包正常拉取：</p><pre><code>pluginManagement {
    repositories {
        google {
            content {
                includeGroupByRegex("com\\.android.*")
                includeGroupByRegex("com\\.google.*")
                includeGroupByRegex("androidx.*")
            }
        }
        mavenCentral()
        gradlePluginPortal()
    }
}
dependencyResolutionManagement {
    repositoriesMode.set(RepositoriesMode.FAIL_ON_PROJECT_REPOS)
    repositories {
        google()
        // 添加Rokid Maven仓库
        maven {
            url = uri("https://maven.rokid.com/repository/maven-public/")
        }
        mavenCentral()
    }
}
rootProject.name = "ExpressSorting_Glasses"
include(":app")
</code></pre><h5>导入 CXR-S SDK 依赖</h5><p>在app/build.gradle.kts中添加 SDK 依赖，设置最小 SDK 版本≥28：</p><pre><code>android {
    namespace = "com.rokid.expresssorting.glasses"
    compileSdk = 34
 
    defaultConfig {
        applicationId = "com.rokid.expresssorting.glasses"
        minSdk = 28 // 必须≥28
        targetSdk = 34
        versionCode = 1
        versionName = "1.0"
 
        testInstrumentationRunner = "androidx.test.runner.AndroidJUnitRunner"
    }
 
    buildTypes {
        release {
            isMinifyEnabled = false
            proguardFiles(
                getDefaultProguardFile("proguard-android-optimize.txt"),
                "proguard-rules.pro"
            )
        }
    }
    compileOptions {
        sourceCompatibility = JavaVersion.VERSION_1_8
        targetCompatibility = JavaVersion.VERSION_1_8
    }
    kotlinOptions {
        jvmTarget = "1.8"
    }
}
 
dependencies {
    // 基础依赖
    implementation("androidx.core:core-ktx:1.12.0")
    implementation("androidx.appcompat:appcompat:1.6.1")
    implementation("com.google.android.material:material:1.11.0")
    testImplementation("junit:junit:4.13.2")
    androidTestImplementation("androidx.test.ext:junit:1.1.5")
    androidTestImplementation("androidx.test.espresso:espresso-core:3.5.1")
 
    // 导入CXR-S SDK
    implementation("com.rokid.cxr:cxr-service-bridge:1.0-20250519.061355-45")
    // 条码解析库（本地识别）
    implementation("com.google.zxing:core:3.5.1")
}
</code></pre><h4>2.眼镜端核心初始化（CXRServiceBridge）</h4><p>实现 SDK 核心类CXRServiceBridge的初始化，配置连接状态监听与消息订阅，支撑条码识别与指令交互：</p><pre><code>import android.app.Application
import com.rokid.cxr.CXRServiceBridge
import com.rokid.cxr.Caps
import android.util.Log
 
class ExpressSortingApp : Application() {
    companion object {
        const val TAG = "ExpressSorting_Glasses"
        lateinit var cxrBridge: CXRServiceBridge
            private set
    }
 
    override fun onCreate() {
        super.onCreate()
        // 1. 初始化CXRServiceBridge（必须在主线程初始化）
        cxrBridge = CXRServiceBridge()
        // 2. 设置连接状态监听（监听手机端连接）
        initStatusListener()
        // 3. 订阅手机端指令消息（如条码识别请求、分拣指引更新）
        subscribeMobileCommands()
    }
 
    /**
     * 初始化连接状态监听
     */
    private fun initStatusListener() {
        cxrBridge.setStatusListener(object : CXRServiceBridge.StatusListener {
            override fun onConnected(name: String, type: Int) {
                Log.d(TAG, "已连接手机设备：$name，设备类型：${getDeviceTypeDesc(type)}")
                // 连接成功后，初始化本地相机参数（为条码扫描做准备）
                initLocalCameraParams()
            }
 
            override fun onDisconnected() {
                Log.d(TAG, "与手机设备断开连接")
                // 断开连接后，释放相机资源
                releaseCameraResources()
            }
 
            override fun onARTCStatus(health: Float, reset: Boolean) {
                Log.d(TAG, "ARTC连接健康度：${(health * 100).toInt()}%，是否重置：$reset")
            }
        })
    }
 
    /**
     * 订阅手机端指令消息（普通消息订阅模式）
     */
    private fun subscribeMobileCommands() {
        // 订阅"条码识别请求"指令
        val scanCmdSubscribeResult = cxrBridge.subscribe("mobile_cmd_scan_barcode", 
            object : CXRServiceBridge.MsgCallback {
                override fun onReceive(name: String, args: Caps, value: ByteArray?) {
                    Log.d(TAG, "收到手机端条码识别请求：$name")
                    // 解析请求参数（如分辨率、压缩质量）
                    val width = if (args.size() &gt; 0) args.at(0).getInt() else 1920
                    val height = if (args.size() &gt; 1) args.at(1).getInt() else 1080
                    val quality = if (args.size() &gt; 2) args.at(2).getInt() else 80
                    // 执行本地条码扫描
                    LocalBarcodeScanner.scan(width, height, quality)
                }
            })
        if (scanCmdSubscribeResult == 0) {
            Log.d(TAG, "条码识别请求指令订阅成功")
        } else {
            Log.e(TAG, "条码识别请求指令订阅失败，错误码：$scanCmdSubscribeResult")
        }
 
        // 订阅"分拣指引更新"指令
        val guideCmdSubscribeResult = cxrBridge.subscribe("mobile_cmd_update_guide",
            object : CXRServiceBridge.MsgCallback {
                override fun onReceive(name: String, args: Caps, value: ByteArray?) {
                    Log.d(TAG, "收到手机端分拣指引更新：$name")
                    // 解析指引信息并显示（提词器场景）
                    if (args.size() &gt; 0) {
                        val guideText = args.at(0).getString()
                        GuideDisplayManager.showGuide(guideText)
                    }
                }
            })
        if (guideCmdSubscribeResult == 0) {
            Log.d(TAG, "分拣指引更新指令订阅成功")
        } else {
            Log.e(TAG, "分拣指引更新指令订阅失败，错误码：$guideCmdSubscribeResult")
        }
    }
 
    /**
     * 初始化本地相机参数（通过Caps写入配置）
     */
    private fun initLocalCameraParams() {
        val cameraConfig = Caps()
        cameraConfig.write("init_camera_params") // 指令标识
        cameraConfig.writeInt32(1920) // 默认宽度
        cameraConfig.writeInt32(1080) // 默认高度
        cameraConfig.writeInt32(80) // 默认质量
        // 发送配置到底层（通过sendMessage接口）
        val sendResult = cxrBridge.sendMessage("glasses_cmd_init_camera", cameraConfig)
        if (sendResult != 0) {
            Log.e(TAG, "相机参数初始化失败，错误码：$sendResult")
        }
    }
 
    /**
     * 释放相机资源
     */
    private fun releaseCameraResources() {
        val releaseCmd = Caps()
        releaseCmd.write("release_camera")
        val sendResult = cxrBridge.sendMessage("glasses_cmd_release_camera", releaseCmd)
        if (sendResult != 0) {
            Log.e(TAG, "相机资源释放失败，错误码：$sendResult")
        }
    }
 
    /**
     * 解析设备类型
     */
    private fun getDeviceTypeDesc(type: Int): String {
        return when (type) {
            CXRServiceBridge.StatusListener.DEVICE_TYPE_ANDROID -&gt; "Android手机"
            CXRServiceBridge.StatusListener.DEVICE_TYPE_IOS -&gt; "iPhone"
            else -&gt; "未知设备"
        }
    }
}
</code></pre><h4>3 .眼镜端本地条码识别与指引显示</h4><p>基于 CXR-S SDK 的Caps数据结构与相机接口，实现本地条码扫描、结果回传与分拣指引显示：</p><pre><code>// 本地条码扫描工具类
import com.rokid.cxr.CXRServiceBridge
import com.rokid.cxr.Caps
import android.graphics.Bitmap
import android.graphics.BitmapFactory
import com.google.zxing.BarcodeFormat
import com.google.zxing.DecodeHintType
import com.google.zxing.MultiFormatReader
import com.google.zxing.Result
import com.google.zxing.common.HybridBinarizer
import com.google.zxing.BinaryBitmap
import com.google.zxing.RGBLuminanceSource
import java.util.EnumMap
import java.io.ByteArrayOutputStream
 
object LocalBarcodeScanner {
    private const val TAG = "LocalBarcodeScanner"
    private val cxrBridge = ExpressSortingApp.cxrBridge
 
    /**
     * 执行本地条码扫描
     * @param width 扫描分辨率宽度
     * @param height 扫描分辨率高度
     * @param quality 图像压缩质量（0-100）
     */
    fun scan(width: Int, height: Int, quality: Int) {
        // 1. 调用本地相机接口获取条码图像（对接眼镜端硬件相机）
        val barcodeImage = captureBarcodeImage(width, height, quality)
        if (barcodeImage == null) {
            Log.e(TAG, "相机采集图像失败")
            sendScanResult(false, "采集失败", null)
            return
        }
 
        // 2. 解析条码信息（使用ZXing库）
        val decodeResult = decodeBarcode(barcodeImage)
        if (decodeResult != null) {
            Log.d(TAG, "本地解析条码成功：${decodeResult.text}")
            // 3. 回传识别结果到手机端
            sendScanResult(true, decodeResult.text, barcodeImage)
        } else {
            Log.e(TAG, "本地解析条码失败，触发云端解析")
            // 4. 本地解析失败，将图像回传手机端发起云端解析
            sendScanResult(false, "本地解析失败", barcodeImage)
        }
    }
 
    /**
     * 调用眼镜端相机采集条码图像
     */
    private fun captureBarcodeImage(width: Int, height: Int, quality: Int): ByteArray? {
        // 实际项目需对接眼镜端相机API，此处模拟采集流程
        val bitmap = Bitmap.createBitmap(width, height, Bitmap.Config.ARGB_8888)
        val outputStream = ByteArrayOutputStream()
        bitmap.compress(Bitmap.CompressFormat.WEBP, quality, outputStream)
        return outputStream.toByteArray()
    }
 
    /**
     * 解析条码信息（ZXing实现）
     */
    private fun decodeBarcode(imageData: ByteArray): Result? {
        val options = EnumMap&lt;DecodeHintType, Any&gt;(DecodeHintType::class.java)
        options[DecodeHintType.CHARACTER_SET] = "UTF-8"
        options[DecodeHintType.POSSIBLE_FORMATS] = listOf(
            BarcodeFormat.CODE_128,
            BarcodeFormat.CODE_39,
            BarcodeFormat.EAN_13,
            BarcodeFormat.EAN_8,
            BarcodeFormat.UPC_A
        )
        val reader = MultiFormatReader()
        reader.setHints(options)
 
        try {
            val bitmap = BitmapFactory.decodeByteArray(imageData, 0, imageData.size)
            val source = RGBLuminanceSource(bitmap.width, bitmap.height, getPixels(bitmap))
            val binaryBitmap = BinaryBitmap(HybridBinarizer(source))
            return reader.decode(binaryBitmap)
        } catch (e: Exception) {
            Log.e(TAG, "条码解析异常：${e.message}")
            return null
        }
    }
 
    /**
     * 回传扫描结果到手机端（使用CXR-S SDK的sendMessage接口）
     */
    private fun sendScanResult(success: Boolean, result: String, imageData: ByteArray?) {
        val resultCaps = Caps()
        resultCaps.write(if (success) "scan_success" else "scan_failed") // 状态标识
        resultCaps.write(result) // 结果文本
        if (imageData != null) {
            resultCaps.write(imageData) // 图像数据（可选）
        }
 
        // 发送结果到手机端
        val sendResult = cxrBridge.sendMessage("glasses_result_scan", resultCaps, imageData)
        if (sendResult != 0) {
            Log.e(TAG, "结果回传失败，错误码：$sendResult")
        }
    }
 
    /**
     * 辅助方法：获取Bitmap像素数组
     */
    private fun getPixels(bitmap: Bitmap): IntArray {
        val width = bitmap.width
        val height = bitmap.height
        val pixels = IntArray(width * height)
        bitmap.getPixels(pixels, 0, width, 0, 0, width, height)
        return pixels
    }
}
 
// 分拣指引显示管理类
import com.rokid.cxr.Caps
import com.rokid.cxr.client.extend.CxrApi
import com.rokid.cxr.client.extend.utils.ValueUtil
 
object GuideDisplayManager {
    private const val TAG = "GuideDisplayManager"
    private val cxrBridge = ExpressSortingApp.cxrBridge
 
    /**
     * 在眼镜端提词器显示分拣指引
     */
    fun showGuide(guideText: String) {
        // 1. 配置提词器样式（通过Caps传递参数）
        val configCaps = Caps()
        configCaps.write("config_word_tips")
        configCaps.writeFloat(18f) // textSize
        configCaps.writeFloat(4f)  // lineSpace
        configCaps.write("normal") // mode
        configCaps.writeInt32(100) // startPointX
        configCaps.writeInt32(200) // startPointY
        configCaps.writeInt32(800) // width
        configCaps.writeInt32(400) // height
 
        // 发送配置到提词器场景
        val configResult = cxrBridge.sendMessage("glasses_cmd_config_guide", configCaps)
        if (configResult != 0) {
            Log.e(TAG, "提词器配置失败，错误码：$configResult")
            return
        }
 
        // 2. 显示指引文本
        val textCaps = Caps()
        textCaps.write("show_guide_text")
        textCaps.write(guideText)
        val textResult = cxrBridge.sendMessage("glasses_cmd_show_guide", textCaps)
        if (textResult != 0) {
            Log.e(TAG, "指引文本显示失败，错误码：$textResult")
        }
    }
 
    /**
     * 语音播报指引（通过TTS接口）
     */
    fun speakGuide(guideText: String) {
        val ttsCaps = Caps()
        ttsCaps.write("tts_guide")
        ttsCaps.write(guideText)
        val ttsResult = cxrBridge.sendMessage("glasses_cmd_tts", ttsCaps)
        if (ttsResult != 0) {
            Log.e(TAG, "TTS播报失败，错误码：$ttsResult")
        }
    }
</code></pre><h3>（二）手机端（CXR-M SDK）集成配置</h3><h4>1.环境准备与依赖导入</h4><h5>配置 Maven 仓库</h5><p>在settings.gradle.kts中添加 Rokid Maven 仓库：</p><pre><code>pluginManagement {
    repositories {
        google {
            content {
                includeGroupByRegex("com\\.android.*")
                includeGroupByRegex("com\\.google.*")
                includeGroupByRegex("androidx.*")
            }
        }
        mavenCentral()
        gradlePluginPortal()
    }
}
dependencyResolutionManagement {
    repositoriesMode.set(RepositoriesMode.FAIL_ON_PROJECT_REPOS)
    repositories {
        // 添加Rokid Maven仓库
        maven { url = uri("https://maven.rokid.com/repository/maven-public/") }
        google()
        mavenCentral()
    }
}
rootProject.name = "ExpressSorting_Mobile"
include(":app")
</code></pre><h5>导入 CXR-M SDK 依赖与权限配置</h5><p>在app/build.gradle.kts中添加 SDK 依赖，设置minSdk≥28</p><pre><code>android {
    namespace = "com.rokid.expresssorting.mobile"
    compileSdk = 34
 
    defaultConfig {
        applicationId = "com.rokid.expresssorting.mobile"
        minSdk = 28 // 必须≥28
        targetSdk = 34
        versionCode = 1
        versionName = "1.0"
 
        testInstrumentationRunner = "androidx.test.runner.AndroidJUnitRunner"
    }
 
    buildTypes {
        release {
            isMinifyEnabled = false
            proguardFiles(
                getDefaultProguardFile("proguard-android-optimize.txt"),
                "proguard-rules.pro"
            )
        }
    }
    compileOptions {
        sourceCompatibility = JavaVersion.VERSION_1_8
        targetCompatibility = JavaVersion.VERSION_1_8
    }
    kotlinOptions {
        jvmTarget = "1.8"
    }
}
 
dependencies {
    // 基础依赖
    implementation("androidx.core:core-ktx:1.12.0")
    implementation("androidx.appcompat:appcompat:1.6.1")
    implementation("com.google.android.material:material:1.11.0")
    testImplementation("junit:junit:4.13.2")
    androidTestImplementation("androidx.test.ext:junit:1.1.5")
    androidTestImplementation("androidx.test.espresso:espresso-core:3.5.1")
 
    // 导入CXR-M SDK
    implementation("com.rokid.cxr:client-m:1.0.1-20250812.080117-2")
 
    // SDK依赖的第三方库（避免版本冲突）
    implementation("com.squareup.retrofit2:retrofit:2.9.0")
    implementation("com.squareup.retrofit2:converter-gson:2.9.0")
    implementation("com.squareup.okhttp3:okhttp:4.9.3")
    implementation("org.jetbrains.kotlin:kotlin-stdlib:2.1.0")
    implementation("com.squareup.okio:okio:2.8.0")
    implementation("com.google.code.gson:gson:2.10.1")
    implementation("com.squareup.okhttp3:logging-interceptor:4.9.1")
 
    // 条码解析库（云端解析备用）
    implementation("com.google.zxing:core:3.5.1")
    // 网络请求库（对接云端API）
    implementation("com.squareup.retrofit2:adapter-rxjava2:2.9.0")
}
</code></pre><h4>2.手机端核心初始化（CxrApi）</h4><p>实现CxrApi单例初始化，配置蓝牙扫描、设备连接与 Wi-Fi P2P 管理：</p><pre><code>import android.app.Application
import android.bluetooth.BluetoothDevice
import android.content.Context
import com.rokid.cxr.client.extend.CxrApi
import com.rokid.cxr.client.extend.callbacks.BluetoothStatusCallback
import com.rokid.cxr.client.extend.callbacks.WifiP2PStatusCallback
import com.rokid.cxr.client.extend.utils.ValueUtil
import android.util.Log
 
class ExpressSortingMobileApp : Application() {
    // 1. 全局变量：存储设备连接信息与状态
    companion object {
        const val TAG = "ExpressSorting_Mobile" // 日志标签
        lateinit var instance: ExpressSortingMobileApp // 应用上下文单例
            private set
        var savedDevice: BluetoothDevice? = null // 已连接的眼镜设备
        var savedUuid: String? = null // 设备UUID（蓝牙连接关键参数）
        var savedMac: String? = null // 设备MAC地址（重连关键参数）
        var isDeviceConnected = false // 设备连接状态标记
    }
 
    override fun onCreate() {
        super.onCreate()
        instance = this // 初始化应用上下文
        // 2. 初始化核心模块：CxrApi、蓝牙扫描、数据同步
        initCxrApi() // 初始化CXR-M SDK核心
        BluetoothScanHelper.init(this) // 初始化蓝牙扫描工具
        DataSyncManager.init(this) // 初始化数据同步管理器
    }
 
    /**
     * 3. CxrApi单例初始化（SDK核心入口）
     */
    private fun initCxrApi() {
        // 获取CxrApi单例（SDK全局唯一实例，无需重复创建）
        val cxrApi = CxrApi.getInstance()
        // 打印SDK版本信息（调试用，确认SDK正常加载）
        Log.d(TAG, "CXR-M SDK版本信息：${getSdkVersion()}")
        
        // 后续模块（蓝牙连接、Wi-Fi初始化、消息订阅）将在此处扩展
    }
 
    /**
     * 辅助方法：获取SDK版本（从CxrApi内部属性解析）
     */
    private fun getSdkVersion(): String {
        // 版本信息来自CxrApi源码定义（见文档5：CxrApi.txt）
        return "版本名：1.0.1，版本号：101，构建时间：2025-08-12 16:01:17"
    }
}
</code></pre><h4>3 手机端蓝牙扫描与云端交互工具类</h4><p>配置蓝牙连接回调（BluetoothStatusCallback），监听眼镜端连接、断开、失败状态。</p><ul><li>解析眼镜端设备信息（UUID、MAC 地址）并缓存，为后续重连提供参数。</li><li>实现断开自动重连逻辑，保障移动场景下连接稳定性。</li></ul><p>&lt;!----&gt;</p><pre><code>private fun initCxrApi() {
    val cxrApi = CxrApi.getInstance()
    Log.d(TAG, "CXR-M SDK版本信息：${getSdkVersion()}")
 
    // 4. 配置蓝牙连接回调：监听眼镜端蓝牙状态变化
    cxrApi.setBluetoothStatusCallback(object : BluetoothStatusCallback {
        /**
         * 回调1：获取眼镜端设备信息（连接成功后触发）
         * @param socketUuid：蓝牙通信UUID（关键连接参数）
         * @param macAddress：设备MAC地址（重连用）
         * @param rokidAccount：Rokid账号（可选，用于账号绑定）
         * @param glassesType：眼镜类型（0=无屏，1=有屏）
         */
        override fun onConnectionInfo(
            socketUuid: String?,
            macAddress: String?,
            rokidAccount: String?,
            glassesType: Int
        ) {
            Log.d(TAG, "获取眼镜设备信息：UUID=$socketUuid, MAC=$macAddress, 类型=$glassesType")
            // 缓存设备信息（重连时复用，避免重复扫描）
            savedUuid = socketUuid
            savedMac = macAddress
        }
 
        /**
         * 回调2：蓝牙连接成功（可触发后续Wi-Fi初始化）
         */
        override fun onConnected() {
            Log.d(TAG, "眼镜端蓝牙连接成功")
            isDeviceConnected = true // 更新连接状态
            initWifiP2P() // 连接成功后，初始化Wi-Fi（用于数据同步）
            subscribeGlassesResults() // 订阅眼镜端消息（如条码识别结果）
        }
 
        /**
         * 回调3：蓝牙连接断开（触发自动重连）
         */
        override fun onDisconnected() {
            Log.d(TAG, "眼镜端蓝牙连接断开")
            isDeviceConnected = false // 更新连接状态
            // 自动重连：复用缓存的设备信息
            savedDevice?.let { device -&gt;
                connectToGlasses(this@ExpressSortingMobileApp, device)
            }
        }
 
        /**
         * 回调4：蓝牙连接失败（打印错误原因）
         * @param errorCode：错误码（见ValueUtil.CxrBluetoothErrorCode）
         * - PARAM_INVALID：参数错误（如UUID为空）
         * - BLE_CONNECT_FAILED：BLE连接失败
         * - SOCKET_CONNECT_FAILED：Socket连接失败
         */
        override fun onFailed(errorCode: ValueUtil.CxrBluetoothErrorCode?) {
            Log.e(TAG, "蓝牙连接失败，错误码：${errorCode?.name}")
            isDeviceConnected = false
        }
    })
}
 
/**
 * 辅助方法：主动连接眼镜设备（用于首次连接或重连）
 * @param context：应用上下文
 * @param device：目标蓝牙设备（从扫描结果获取）
 */
fun connectToGlasses(context: Context, device: BluetoothDevice) {
    savedDevice = device // 缓存目标设备
    val cxrApi = CxrApi.getInstance()
    // 调用CxrApi连接接口：需传入缓存的UUID、MAC地址与回调
    val connectResult = cxrApi.connectBluetooth(
        context = context,
        socketUuid = savedUuid ?: "", // 从onConnectionInfo缓存获取
        macAddress = savedMac ?: "", // 从onConnectionInfo缓存获取
        callback = cxrApi.getBluetoothStatusCallback() as BluetoothStatusCallback // 复用已配置的回调
    )
    // 检查连接请求是否发起成功（非实际连接结果，仅请求状态）
    if (connectResult != ValueUtil.CxrStatus.REQUEST_SUCCEED) {
        Log.e(TAG, "发起蓝牙连接请求失败，结果：${connectResult?.name}")
    }
}
</code></pre><h4>4Wi-Fi P2P 初始化（用于高速数据同步）</h4><ul><li>蓝牙连接成功后，自动初始化 Wi-Fi P2P 连接（用于传输大文件，如条码图像、快件信息）。</li><li>监听 Wi-Fi 连接状态，连接成功后触发未同步数据同步；失败则打印错误原因。</li><li>基于 SDK 接口initWifiP2P与isWifiP2PConnected实现状态管理。</li></ul><p>&lt;!----&gt;</p><pre><code>/**
 * 5. 初始化Wi-Fi P2P（蓝牙连接成功后触发）
 * 作用：高速传输大文件（如条码图像、批量快件数据），弥补蓝牙带宽不足
 */
private fun initWifiP2P() {
    val cxrApi = CxrApi.getInstance()
    // 调用CxrApi初始化Wi-Fi P2P，传入状态回调
    val initResult = cxrApi.initWifiP2P(object : WifiP2PStatusCallback {
        /**
         * Wi-Fi P2P连接成功（触发数据同步）
         */
        override fun onConnected() {
            Log.d(TAG, "Wi-Fi P2P连接成功，可开始同步数据")
            // 触发未同步数据同步（如之前缓存的条码图像）
            DataSyncManager.syncUnsyncedData()
        }
 
        /**
         * Wi-Fi P2P连接断开
         */
        override fun onDisconnected() {
            Log.d(TAG, "Wi-Fi P2P连接断开，暂停数据同步")
        }
 
        /**
         * Wi-Fi P2P连接失败（打印错误原因）
         * @param errorCode：错误码（见ValueUtil.CxrWifiErrorCode）
         * - WIFI_DISABLED：手机Wi-Fi未开启
         * - WIFI_CONNECT_FAILED：P2P连接失败
         * - UNKNOWN：未知错误
         */
        override fun onFailed(errorCode: ValueUtil.CxrWifiErrorCode?) {
            Log.e(TAG, "Wi-Fi P2P连接失败，错误码：${errorCode?.name}")
        }
    })
    // 检查Wi-Fi初始化请求是否发起成功
    if (initResult != ValueUtil.CxrStatus.REQUEST_SUCCEED) {
        Log.e(TAG, "Wi-Fi P2P初始化请求失败，结果：${initResult?.name}")
    }
}
</code></pre><h4>5订阅眼镜端消息（接收条码识别结果）</h4><ul><li>订阅眼镜端发送的 “条码识别结果” 消息（使用可回复订阅模式MsgReplyCallback）。</li><li>解析眼镜端返回的识别结果（成功 / 失败、条码文本、图像数据），触发后续业务逻辑（如快件信息校验、分拣指引）。</li><li>回复眼镜端 “结果已收到”，完成消息闭环。</li></ul><p>&lt;!----&gt;</p><pre><code>/**
 * 6. 订阅眼镜端消息：接收条码识别结果（可回复模式）
 * 消息名：glasses_result_scan（需与眼镜端发送的消息名一致，见3.1.3）
 */
private fun subscribeGlassesResults() {
    val cxrApi = CxrApi.getInstance()
    // 调用CxrApi订阅接口：传入消息名与可回复回调
    val subscribeResult = cxrApi.subscribe(
        name = "glasses_result_scan", // 消息名（与眼镜端约定）
        cb = object : CxrApi.MsgReplyCallback {
            /**
             * 接收眼镜端消息回调
             * @param name：消息名（验证是否为目标消息）
             * @param args：结构化参数（Caps格式，存储识别状态、条码文本）
             * @param value：二进制数据（可选，如条码图像）
             * @param reply：回复对象（用于向眼镜端发送“结果已收到”）
             */
            override fun onReceive(
                name: String,
                args: com.rokid.cxr.Caps,
                value: ByteArray?,
                reply: CxrApi.Reply?
            ) {
                Log.d(TAG, "收到眼镜端条码识别结果消息：$name")
                // 校验参数合法性（args不能为空，否则无法解析结果）
                if (args.size() == 0) {
                    Log.e(TAG, "识别结果参数为空，无法解析")
                    return
                }
 
                // 解析识别结果（从Caps中按顺序读取参数）
                val resultStatus = args.at(0).getString() // 第1个参数：状态（scan_success/scan_failed）
                val resultText = args.at(1).getString()   // 第2个参数：条码文本（成功时为单号，失败时为原因）
                val imageData = if (args.size() &gt; 2) args.at(2).getBinary().data else null // 第3个参数：条码图像（可选）
 
                // 分支1：本地识别成功→直接处理快件信息
                if (resultStatus == "scan_success") {
                    ExpressManager.processExpressInfo(resultText, imageData)
                } 
                // 分支2：本地识别失败→触发云端识别
                else {
                    CloudBarcodeDecoder.decode(imageData) { cloudResult -&gt;
                        if (cloudResult != null) {
                            ExpressManager.processExpressInfo(cloudResult, imageData)
                        } else {
                            Log.e(TAG, "本地+云端解析均失败，需人工处理")
                        }
                    }
                }
 
                // 回复眼镜端：告知“结果已收到”（完成消息闭环）
                val replyCaps = com.rokid.cxr.Caps()
                replyCaps.write("result_received") // 回复内容（简单状态标识）
                reply?.end(replyCaps) // 发送回复
            }
        }
    )
 
    // 检查订阅请求是否成功
    if (subscribeResult != 0) {
        Log.e(TAG, "订阅条码识别结果消息失败，错误码：$subscribeResult")
        // 错误码说明：-1=参数错误（如消息名为空），-2=重复订阅
    }
}
</code></pre><h3>（三）关键功能技术说明</h3><h4>1.设备连接与双模切换</h4><h5>蓝牙保活与重连</h5><ul><li>保活机制：通过CXR-M SDK的isBluetoothConnected定期检查连接状态，闲置时维持低功耗连接，避免频繁断连。</li><li>重连逻辑：断开后 3 秒内自动调用connectBluetooth复用savedUuid与savedMac重连，3 次失败后触发语音提醒工作人员。</li></ul><h5> Wi-Fi P2P 自动触发</h5><ul><li>触发条件：当检测到需同步文件（如条码图像、快件信息）时，自动调用initWifiP2P初始化 Wi-Fi 连接，同步完成后 30 秒自动释放资源。</li><li>状态监听：通过isWifiP2PConnected判断 Wi-Fi 状态，未连接时缓存数据，连接后自动触发同步。</li></ul><h4>2. 快件信息采集与识别</h4><h5>条码扫描实现</h5><p>利用眼镜端相机接口实现条码快速识别，配合 AI 优化识别算法：</p><ol><li>相机配置：通过 CXR-M SDK setPhotoParams设置扫描分辨率（推荐 1920x1080），调用openGlassCamera打开眼镜端相机，takeGlassPhoto拍摄条码图像。</li><li>本地识别：眼镜端通过 CXR-S SDK 的图像识别能力解析条码信息，若本地识别失败，将图像通过 Wi-Fi 同步至手机端进行云端识别。</li><li>信息校验：手机端接收条码信息后，调用云端 API 校验快件单号合法性、收件人信息完整性，通过提词器场景（setWordTipsText）在眼镜端显示校验结果。</li></ol><h5>语音指令交互</h5><p>基于 Rokid 语音识别能力，支持以下核心指令：</p><ul><li>主动触发：“扫描快件”“确认归类”“查询库存” 等操作指令。</li><li>被动反馈：眼镜端通过 TTS 接口（sendTTSContent）播报 “扫描成功”“请归类至 A 区 3 号架” 等反馈信息。</li></ul><h4>3. 智能归类与指引</h4><h5>归类规则引擎</h5><ol><li>云端配置：快递站根据区域、收件人地址、快件类型预设归类规则（如 “同城件→A 区”“大件→B 区”）。</li><li>实时匹配：手机端接收快件信息后，调用云端 API 获取归类结果，通过sendStream接口将指引信息推送至眼镜端。</li><li>视觉指引：在眼镜端自定义界面（openCustomView）显示归类区域示意图，配合语音播报完成精准分拣。</li></ol><h5>异常处理机制</h5><ul><li>条码识别失败：语音提示 “请调整角度重新扫描”，并在提词器显示操作指引。</li><li>归类规则不存在：自动标记为 “待人工处理”，同步至管理系统并提醒工作人员。</li><li>网络中断：数据缓存至手机端（sendStream临时存储），网络恢复后自动同步（startSync）。</li></ul><h4>4. 数据实时同步与管理</h4><ol><li>本地缓存：手机端通过 CXR-M SDK 的sendStream接口缓存快件信息与图像，保障离线状态下的操作连续性。</li><li>云端同步：Wi-Fi 连接状态下，调用startSync接口将缓存数据同步至云端，支持单个文件同步（syncSingleFile）与批量同步。</li><li>状态监听：通过MediaFilesUpdateListener监听眼镜端媒体文件更新，确保扫描图像无遗漏同步。</li></ol><h2>四、核心难点与解决方案</h2><h3>难点 1：移动场景下设备连接稳定性</h3><p>问题：快递站空间大、人员移动频繁，蓝牙连接易受干扰，Wi-Fi 切换需无缝衔接。解决方案：</p><ul><li>实现蓝牙与 Wi-Fi 双模自动切换：蓝牙负责日常指令传输，Wi-Fi 触发同步时自动连接，通过isBluetoothConnected与isWifiP2PConnected监听状态。</li><li>优化蓝牙扫描策略：基于 CXR-M SDK 的BluetoothHelper过滤 Rokid 设备 UUID，减少无效扫描消耗，提升连接速度。</li></ul><h3>难点 2：条码识别准确率与速度平衡</h3><p>问题：快件条码可能存在污损、褶皱，需兼顾识别速度与准确率。解决方案：</p><ul><li>相机参数优化：通过setPhotoParams调整分辨率与压缩质量，在不影响识别的前提下降低图像传输延迟。</li><li>本地 + 云端双识别机制：眼镜端本地优先识别（CXR-S SDK 图像处理能力），失败后 300ms 内自动触发云端识别，保障流程不中断。</li></ul><h3>难点 3：多指令并发处理</h3><p>问题：工作人员可能连续触发 “扫描”“归类”“查询” 等指令，需避免指令冲突。解决方案：</p><ul><li>指令队列管理：手机端维护指令优先级队列，语音指令与视觉操作指令分类处理，高优先级指令（如扫描确认）优先执行。</li><li>状态反馈机制：通过提词器实时显示当前操作状态（如 “扫描中”“同步中”），避免重复触发。</li></ul><h2>五、结语：让技术提升工作体验</h2><p>通过项目实践，我们在设备协同、场景配置与异常处理等方面积累了重要经验。在设备协同方面，总结出“蓝牙保活 + Wi-Fi 同步”的双模通信方案，并借助CXR-M SDK的deinitBluetooth与deinitWifiP2P接口优化资源释放逻辑，有效降低了设备功耗。在场景适配方面，提炼出快递场景专属的提词器配置模板与相机参数组合，为同类物流场景提供了可直接复用的配置基础。在系统稳定性方面，形成了涵盖设备断连、识别失败、网络中断等8类常见异常的标准化处理流程，并基于SDK回调接口构建了快速恢复机制，提升了系统的鲁棒性。</p><p>着眼于未来应用，我们持续推进技术融合与功能优化。在AI能力方面，引入Rokid AI大模型，实现了快件破损识别与收件人信息脱敏处理，进一步提升了业务的智能化水平。在多语言支持方面，利用翻译场景接口（sendTranslationContent）适配国际快件场景，支持多语言语音指令与信息显示，拓展了系统的适用范围。在设备管理方面，基于CXR-M SDK的设备状态监听接口（如BatteryLevelUpdateListener），实现了眼镜端电量、亮度等关键状态的远程管理，为设备的持续稳定运行提供了有力保障。</p><p>综上，本次技术提升工作不仅沉淀了多项可复用的实践经验，也通过持续迭代拓展了系统的智能化边界与应用场景。未来，我们将继续深化AI与业务场景的融合，优化设备协同与资源管理机制，为物流行业数智化升级提供更可靠、高效的技术支撑。</p>]]></description></item><item>    <title><![CDATA[苹果企业签名：高效的内部分发解决方案 张]]></title>    <link>https://segmentfault.com/a/1190000047439301</link>    <guid>https://segmentfault.com/a/1190000047439301</guid>    <pubDate>2025-11-30 23:04:21</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在苹果生态系统中，企业签名作为App Store之外的重要分发方式，为企业和组织提供了灵活的内部应用部署方案。这种基于企业开发者账号的签名机制，正在成为众多机构移动化战略的关键支撑。</p><p><a href="ioszf.cc" target="_blank">稳定靠谱签名平台：iOS企业签、超级签、TF签</a></p><p>核心技术原理<br/>企业签名的技术基础建立在苹果的企业级信任体系之上。通过获取苹果官方颁发的企业开发者证书，组织可以对应用进行数字签名，使其能够在未上架App Store的情况下直接安装到iOS设备。这套机制的核心在于企业证书的数字签名验证流程，系统会验证签名的有效性及应用的完整性，确保分发的安全性。</p><p>与个人开发者账号不同，企业签名不需要预先注册设备UDID，这大大简化了分发流程。企业员工只需通过扫描二维码或点击分发链接即可完成安装，极大地提升了部署效率。</p><p>独特优势解析<br/>企业签名最显著的优势在于其分发规模不受限制。一个有效的企业签名可以支持无限次数的应用安装，这使得它特别适合员工数量众多的企业、教育机构或政府单位。无论是数千人的大型企业还是跨地域的集团组织，都能通过这一方案快速完成应用部署。</p><p>另一个重要优势是版本更新的便捷性。当应用需要更新时，开发者只需重新签名并上传新版本，用户再次扫描二维码即可完成更新，无需卸载原有应用。这种无缝升级体验大大降低了维护成本。</p><p>适用场景分析<br/>企业签名在以下场景中表现出独特价值：</p><p>企业内部办公系统的移动化部署</p><p>定制化业务工具的快速分发</p><p>临时性项目的应用测试</p><p>特定区域或部门的应用推广</p><p>需要频繁更新的业务应用</p><p>安全管控机制<br/>为确保企业签名的合规使用，苹果建立了多层次的安全管控机制。企业证书设有有效期限制，通常为一年，需要定期续费更新。同时，苹果会通过自动化系统监测证书使用情况，对异常分发行为进行识别和处理。</p><p>企业自身也需要建立完善的管理制度，包括严格限制分发范围、定期审计应用使用情况、建立证书管理制度等。这些措施不仅能确保合规性，也能有效防范安全风险。</p><p>实施要点<br/>成功部署企业签名需要注意以下几个要点：<br/>首先，确保证书文件的妥善保管，避免泄露风险。<br/>其次，建立规范的分发流程，确保只有授权用户能够安装应用。<br/>再次，监控证书有效期，提前做好续期准备。<br/>最后，准备应急预案，以应对证书异常情况。</p><p>未来发展趋势<br/>随着移动办公需求的持续增长，企业签名技术也在不断演进。未来将出现更加智能化的管理平台，提供自动化的证书监控和预警功能。同时，与移动设备管理（MDM）方案的深度整合也将成为重要发展方向。</p><p>企业签名作为苹果生态中的重要组成部分，为组织内部的应用分发提供了可靠的技术支持。通过合理规划和规范使用，企业可以充分发挥这一方案的价值，推动数字化转型进程。在移动优先的时代，掌握企业签名技术将成为组织提升运营效率的重要助力。</p>]]></description></item><item>    <title><![CDATA[BipedalWalker实战：SAC算]]></title>    <link>https://segmentfault.com/a/1190000047439304</link>    <guid>https://segmentfault.com/a/1190000047439304</guid>    <pubDate>2025-11-30 23:03:21</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>下肢假肢的控制系统设计一直是个老大难问题。传统控制理论需要建立肢体和环境的精确数学模型，但现实世界可以不一样，比如说地面摩擦力时刻在变，坡度各不相同，患者随时可能绊一下。这就需要控制器具备自适应能力，能从失误中恢复，还得在没有显式编程的情况下习得自然的步态模式。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047439306" alt="" title=""/></p><p>强化学习给出了一条思路：让假肢自己通过试错"学会"走路。但是标准RL算法有个毛病，它太贪心了，找到一种能用的移动方式就死守着不放，一旦外界条件变化，整个控制策略就非常容易崩盘。</p><p>这篇文章用Soft Actor-Critic（SAC）算法解决BipedalWalker-v3环境。但这不只是跑个游戏demo那么简单，更重要的是从生物工程视角解读整个问题：把神经网络对应到神经系统，把奖励函数对应到代谢效率。</p><h2>SAC的核心思想：为什么要"soft"？</h2><p>常规强化学习只盯着一个目标——最大化期望累积奖励。这种贪心策略在国际象棋这类确定性博弈里表现不错，但放到物理控制任务上问题就非常的多了，这是因为系统动力学稍有变化，贪心策略往往直接翻车。</p><p>要理解SAC里的"软"字，先得搞清楚Actor-Critic架构。这个框架其实模拟了人类学习运动技能的过程。打个比方：患者（Actor）在学习使用假肢，旁边有个理疗师（Critic）在观察和指导。</p><p><strong>Actor（策略网络π）</strong> 负责控制肢体，观察当前状态（关节角度、身体平衡），然后决定该怎么动。训练初期它啥也不懂只能瞎动弹。<strong>Critic（Q函数网络）</strong> 负责评估Actor动作的质量，不直接控制肢体，只预测某个动作长期来看能拿到多少奖励。</p><p>传统算法里，Actor拼命想找到那个"最优解"来讨好Critic。但SAC不一样，Critic鼓励Actor尝试多种不同的成功路径，不仅看结果，还看方法的多样性。</p><p>SAC采用最大熵框架，智能体的目标变成了同时最大化期望奖励和策略熵（随机性）：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047439307" alt="" title="" loading="lazy"/></p><p>这里的𝓗就是熵。</p><p>这对假肢控制有什么意义？</p><p>一方面是<strong>探索机制</strong>。比如说婴儿会用随机运动（所谓motor babbling）来摸索肢体的运动规律。高熵保证了充分探索，避免智能体掉进"安全小碎步"的局部最优陷阱，就是那种几乎不动、只求不摔的保守策略。另一方面是<strong>泛化性</strong>，熵最大化训练出来的智能体掌握了一整套策略组合。某条肌肉激活路径被干扰了？没关系，还有备选方案。这让步态对打滑、绊绊脚之类的意外具备容错能力。</p><h2>从仿真到临床的映射关系</h2><pre><code>BipedalWalker-v3</code></pre><p>是个24维数字向量。但从生物工程角度看它相当于膝上假肢控制问题的简化版。</p><p><strong>观察空间对应传感器融合</strong></p><p>Gym里的24维观察向量可以直接对应到Otto Bock Genium这类智能假肢的传感器配置：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047439308" alt="" title="" loading="lazy"/></p><p>躯干角度和速度对应前庭系统——"躯干"代表质心位置，硬件上用IMU（惯性测量单元）采集平衡数据。关节编码器对应本体感觉，仿真里提供的关节角度和速度，在真实假肢上由霍尔传感器和旋转编码器获取。激光雷达对应视觉前馈，现代研究型假肢已经开始集成深度相机来预判地形。</p><p><strong>动作空间对应执行器</strong></p><p>智能体用[-1, 1]范围的连续值控制髋关节和膝关节。这对应到硬件上就是直流电机的电流控制，或者气动人工肌肉（PAMs）的压力调节。</p><p>为什么连续控制这么重要呢？DQN这类离散算法输出的是生硬的开关命令，SAC输出的是连续平滑的扭矩曲线。对患者来说这可不是小事，生硬的驱动会在残肢上产生剪切力长期下去会损伤组织。</p><h2>代码实现</h2><p>以下实现改编自CleanRL并使用PyTorch搭建网络，通过Gymnasium提供仿真环境运行。</p><p><strong>Actor网络：物理约束的强制执行</strong></p><p>连续控制的一个核心挑战是把动作限制在物理边界内。这里用高斯策略配合</p><pre><code>tanh</code></pre><p>函数压缩输出，确保电机指令不会超出[−1, 1]的安全范围。</p><pre><code> # LOGIC: The Actor Network (from sac_bipedalwalker_enhanced.py)  
def get_action(self, x):  
    mean, log_std = self(x)  
    std = log_std.exp()  
      
    # The Reparameterization Trick:   
    # Allows gradients to flow back through the sampling process  
    normal = torch.distributions.Normal(mean, std)  
    x_t = normal.rsample()    
      
    # Squash output to [-1, 1] for the environment limits  
    y_t = torch.tanh(x_t)  
    action = y_t * self.action_scale + self.action_bias  
      
    # Correction for the log_prob due to tanh squashing (Math detail)  
    log_prob = normal.log_prob(x_t)  
    log_prob -= torch.log(self.action_scale * (1 - y_t.pow(2)) + 1e-6)  
    log_prob = log_prob.sum(1, keepdim=True)  
      
     return action, log_prob, mean</code></pre><p>注意</p><pre><code>x_t = normal.rsample()</code></pre><p>这行。看起来普普通通，实际上是整个算法的数学根基。</p><p>标准随机策略里，采样动作是个随机事件，会打断反向传播需要的导数链，随机数生成器没法求导。<strong>重参数化技巧</strong>绕开了这个问题：不直接从分布采样，而是先采一个标准正态噪声ε，再用网络输出的均值μ和标准差σ做变换：xt = μ + σ · ε。因为ε跟网络参数无关，μ和σ的梯度就能正常计算了，Actor网络也就能从Critic的反馈里学到东西。没这个技巧，连续策略根本没法训。</p><p><strong>自动熵调节</strong></p><p>早期SAC版本里，温度参数α是固定的。α太大，智能体走路像喝醉了；α太小，又永远学不会探索。现在的做法是把α当成可学习参数，让智能体自己决定什么时候该收敛：</p><pre><code> # LOGIC: Automatic Entropy Tuning (inside training loop)  
if args.autotune:  
    with torch.no_grad():  
        _, log_pi, _ = actor.get_action(data.observations)  
          
    # Minimize difference between current entropy and target entropy  
    # target_entropy is usually -dim(Action Space)  
    alpha_loss = (-log_alpha.exp() * (log_pi + target_entropy)).mean()  

    a_optimizer.zero_grad()  
    alpha_loss.backward()  
    a_optimizer.step()  
     alpha = log_alpha.exp().item()</code></pre><h2>实验结果分析</h2><p>训练跑了350k步。这里我们要看的不是最终分数多高，而是学出来的步态在生物力学上是否合理。</p><p><strong>学习曲线的解读</strong></p><p>智能体一开始回报是负的，站都站不稳，跟患者刚装上新假肢时的状态很像。</p><p>看下面的学习曲线，蓝色阴影是各episode的标准差。0-100k步阶段方差很低，但这不好，因为智能体一直在失败，每次都是秒摔。</p><p>到了150k-250k步，方差突然爆炸。这是个关键转折期，智能体开始尝试高风险策略，有时走得漂亮，有时摔得很惨。只有进入300k步之后的稳定区，均值高、方差收窄，这样才能考虑"冻结"策略用于实际部署。方差收窄意味着策略从"碰运气"进化到了"真会走"。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047439309" alt="" title="" loading="lazy"/></p><p>而150k步左右发生了"相变"，智能体突然开窍了，奖励曲线急剧上升。250k步后稳定在200分以上，算是解决了这个环境。</p><p><strong>相位图分析</strong></p><p>光看分数不够，还得检查运动学特征。下图是髋关节的相位图，横轴关节角度，纵轴角速度。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047439310" alt="" title="" loading="lazy"/></p><p>紫色和蓝色的散点代表早期阶段，角度和速度之间毫无关联，智能体就是在瞎蹬腿，漫无目的地探索状态空间。</p><p>随着训练推进（颜色向黄绿过渡），散点开始收敛成一个封闭的轨道形状。这在控制论和生物力学里叫<strong>极限环</strong>（Limit Cycle）。</p><p>极限环说明系统找到了稳定的周期轨道。即使遇到小扰动，系统也倾向于回到这个环上，这正是动态稳定步态的定义。这个环是从SAC目标函数里自发涌现出来的，不是显式编程的结果。环的形状比较光滑并且没有锯齿，说明Actor网络里的</p><pre><code>tanh</code></pre><p>压缩确实产生了平滑的扭矩曲线，避免了离散RL常见的"抖振"问题。这对假肢安全性至关重要。</p><p><strong>能效特征</strong></p><p>最后看Critic损失（智能体的"困惑程度"）和动作幅度（扭矩大小）的关系。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047439311" alt="" title="" loading="lazy"/></p><p>学习阶段（50k-200k步），Critic损失达到峰值，智能体还在跟物理规律较劲。极限环建立后（200k步以后），动作幅度稳定下来，Critic损失也降到较低水平。</p><p>更细致地看，可以把训练过程分成三个力学阶段：</p><p><strong>"僵住"阶段（0-70k步）</strong>：动作幅度（绿线）起始值很低。智能体把关节锁死以避免摔倒惩罚，这在运动学习里叫"共同收缩"策略。不怎么动，自然也不会摔得太惨。</p><p><strong>"疯狂试探"阶段（70k-200k步）</strong>：Critic损失剧烈震荡，这正是智能体开始尝试往前走的时候。反复失败带来高"惊讶度"。同时动作幅度急剧攀升说明智能体意识到想走路就得狠狠发力，哪怕暂时会摔。</p><p><strong>"熟练掌握"阶段（200k步以后）</strong>：极限环形成，Critic损失骤降，智能体对物理世界不再感到意外。有意思的是动作幅度：在200k附近达到峰值后<em>反而略有下降</em>然后趋于平稳。这是熟练运动的典型特征，智能体学会了借力，不再每一步都用蛮力，而是顺着动力学"流"起来，能量消耗得到了优化。</p><p>一个可能的改进方向是在奖励函数里加入代谢运输成本（COT）惩罚项，鼓励智能体发现更"被动-动态"的步态模式，靠惯性而不是持续肌肉输出来行走，这对延长真实假肢的电池续航很有价值。</p><h2>总结</h2><p>SAC算法在BipedalWalker环境中跑了350k步后，智能体从"秒摔"进化到稳定行走（200+分）。相位图显示髋关节运动收敛成极限环，动态稳定步态的标志。能效曲线也印证了这点：智能体最终学会借力而非蛮干。</p><p>从假肢控制角度看，SAC的最大熵框架带来的策略多样性是关键优势，让系统对打滑、绊脚这类意外有容错空间。不过真要落地到Otto Bock C-Leg这类设备上，还得解决传感器噪声、执行延迟和安全约束的问题，域随机化和PID安全笼是两个可行方向。</p><p><a href="https://link.segmentfault.com/?enc=%2By85vbd9jluS8eNj09u5Jw%3D%3D.0EFUSKbTBQWoYH%2F2A%2BnLQEngO3XBXYDm6KpqRApOmLFt%2FW1wKQgCXuK9Mr9MsU6AqK3JhGYoBJyckoBExJJQDA%3D%3D" rel="nofollow" target="_blank">https://avoid.overfit.cn/post/ab5860e7071441e9aab80e9876b2f45d</a></p><p>作者：Cristlianreal</p>]]></description></item><item>    <title><![CDATA[从简单到复杂：多进程环境下的加权随机选择]]></title>    <link>https://segmentfault.com/a/1190000047439327</link>    <guid>https://segmentfault.com/a/1190000047439327</guid>    <pubDate>2025-11-30 23:02:20</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>引言</h2><p>在分布式系统中，我们经常需要实现负载均衡、流量分配、A/B 测试等功能。这些场景的核心问题是：<strong>如何按照预设的权重比例，在多个候选项中进行随机选择？</strong> 更具挑战性的是，当多个进程同时运行、随时可能加入或退出时，如何保证整体的选择分布仍然符合预期的权重比例？</p><p>本文将从最简单的均匀随机选择开始，逐步深入到加权随机选择，最后解决多进程环境下的分布一致性问题，并给出严格的数学证明。</p><p>完整代码：<a href="https://link.segmentfault.com/?enc=9K0HmUpIDxIQhHm585BB4g%3D%3D.mYlLLUGsLPra0LGijTczCWcV0yVs3KUga%2FDCLkA2MkmUvULXO1UCjmw1uNdlQx2%2B" rel="nofollow" target="_blank">https://go.dev/play/p/0h97DRfph-2</a></p><h2>第一步：简单随机选择</h2><h3>需求 1.0：从列表中随机选一个</h3><p>假设我们有一个服务器列表：<code>[A, B, C, D]</code>，需要随机选择其中一个来处理请求。</p><p><strong>朴素实现</strong>：</p><pre><code class="go">func SimpleSelect(candidates []string) string {
    n := len(candidates)
    idx := rand.Intn(n)  // 生成 [0, n) 的随机整数
    return candidates[idx]
}</code></pre><p>这种方法简单直接，每个候选项被选中的概率都是 $\frac{1}{n}$，即<strong>均匀分布</strong>。</p><h3>问题</h3><p>但现实场景中，不同服务器的性能往往不同。高性能服务器应该承担更多流量，低性能服务器应该承担较少流量。均匀分布无法满足这个需求。</p><hr/><h2>第二步：加权随机选择</h2><h3>需求 2.0：按权重选择</h3><p>现在我们给每个服务器分配一个权重：</p><table><thead><tr><th>服务器</th><th>权重</th><th>期望流量占比</th></tr></thead><tbody><tr><td>A</td><td>5</td><td>45.5%</td></tr><tr><td>B</td><td>3</td><td>27.3%</td></tr><tr><td>C</td><td>2</td><td>18.2%</td></tr><tr><td>D</td><td>1</td><td>9.1%</td></tr></tbody></table><p>总权重 $W = 5 + 3 + 2 + 1 = 11$</p><p>我们希望服务器 A 被选中的概率是 $\frac{5}{11}$，服务器 B 被选中的概率是 $\frac{3}{11}$，以此类推。</p><h3>算法 2.0：累积权重法</h3><p><strong>核心思想</strong>：将权重值看作一条数轴上的线段长度，生成随机数落在哪个线段，就选择对应的候选项。</p><pre><code>服务器:  A  A  A  A  A  B  B  B  C  C  D
数轴:   [0-------------5--------8-----10-11)
累积:    0             5        8    10 11</code></pre><p><strong>算法步骤</strong>：</p><ol><li><p>计算累积权重数组：$CW = [w_1, w_1+w_2, w_1+w_2+w_3, ..., W]$</p><ul><li>对于示例：$CW = [5, 8, 10, 11]$</li></ul></li><li>生成 $[0, W)$ 范围内的随机数 $r$</li><li>找到第一个满足 $CW[i] &gt; r$ 的索引 $i$，返回候选项 $i$</li></ol><p><strong>为什么这样能保证权重比例？</strong></p><p>对于候选项 $i$（权重为 $w_i$），被选中的条件是：</p><p>$$CW[i-1] \leq r &lt; CW[i]$$</p><p>这个区间的长度恰好是 $w_i$，因此被选中的概率为：</p><p>$$P(\text{选中}\ i) = \frac{w_i}{W}$$</p><p>完美符合权重比例！</p><h3>优化：二分查找</h3><p>累积权重数组是单调递增的，可以用<strong>二分查找</strong>将查找复杂度从 $O(n)$ 降低到 $O(\log n)$：</p><pre><code class="go">func BinarySearchSelect(cumWeights []int64, totalWeight int64) int {
    r := rand.Int63n(totalWeight)  // [0, totalWeight)
    left, right := 0, len(cumWeights)-1
    
    for left &lt; right {
        mid := left + (right - left) / 2
        if cumWeights[mid] &lt;= r {
            left = mid + 1
        } else {
            right = mid
        }
    }
    return left
}</code></pre><hr/><h2>第三步：多进程环境的挑战</h2><h3>需求 3.0：分布式场景</h3><p>现在问题变得复杂了：</p><ul><li>系统部署了<strong>多个进程</strong>（或服务实例），每个进程都独立执行选择算法</li><li>进程数量<strong>动态变化</strong>：可能随时有新进程启动，或者旧进程崩溃退出</li><li>没有中心化的协调服务（如果有的话，就失去了分布式的意义）</li></ul><p><strong>核心问题</strong>：如何保证在这种动态、分布式的环境下，<strong>总体的选择分布仍然符合权重比例</strong>？</p><h3>可能的担忧</h3><ol><li><strong>同步问题</strong>：多个进程同时选择，会不会相互干扰？</li><li><strong>分布偏差</strong>：进程 1 可能恰好多选了 A，进程 2 多选了 B，总体会不会偏离？</li><li><strong>动态变化</strong>：新进程加入时，会不会打破已有的分布？</li></ol><hr/><h2>第四步：解决方案 —— 独立同分布采样</h2><h3>设计原则</h3><p><strong>关键洞察</strong>：如果每个进程都<strong>独立地</strong>按照<strong>相同的权重分布</strong>进行采样，那么无论有多少进程、进程如何变化，总体分布在统计意义上一定收敛到权重比例。</p><h3>实现要点</h3><ol><li><p><strong>配置共享，状态独立</strong></p><ul><li>所有进程共享相同的候选列表和权重配置（可以通过配置文件、环境变量等方式）</li><li>但每个进程的随机数生成是完全独立的，不依赖共享状态</li></ul></li><li><p><strong>加密安全的随机数</strong></p><ul><li>使用 <code>crypto/rand</code> 而非 <code>math/rand</code></li><li>保证每个进程的随机数序列高质量且彼此独立</li></ul></li><li><p><strong>无状态设计</strong></p><ul><li>不需要记录"已经选了多少次 A"</li><li>不需要进程间通信</li><li>每次选择都是独立事件</li></ul></li></ol><h3>完整代码实现</h3><pre><code class="go">type WeightedSelector struct {
    candidates  []Candidate
    totalWeight int64
    cumWeights  []int64  // 累积权重数组
}

func (ws *WeightedSelector) Select() (Candidate, error) {
    // 使用加密安全的随机数生成器
    randomNum, err := rand.Int(rand.Reader, big.NewInt(ws.totalWeight))
    if err != nil {
        return Candidate{}, err
    }
    
    randValue := randomNum.Int64()
    
    // 二分查找
    left, right := 0, len(ws.cumWeights)-1
    for left &lt; right {
        mid := left + (right - left) / 2
        if ws.cumWeights[mid] &lt;= randValue {
            left = mid + 1
        } else {
            right = mid
        }
    }
    
    return ws.candidates[left], nil
}</code></pre><hr/><h2>第五步：数学证明</h2><p>现在我们给出严格的数学证明，说明为什么这个算法在多进程环境下是正确的。</p><h3>符号定义</h3><ul><li>候选项集合：$\{C_1, C_2, ..., C_n\}$</li><li>权重集合：$\{w_1, w_2, ..., w_n\}$，其中 $w_i &gt; 0$</li><li>总权重：$W = \sum_{i=1}^{n} w_i$</li><li>进程数量：$k$（可以动态变化）</li><li>第 $j$ 个进程的选择次数：$m_j$</li><li>总选择次数：$M = \sum_{j=1}^{k} m_j$</li></ul><h3>定理：多进程独立采样的分布一致性</h3><p><strong>定理</strong>：在多进程独立同分布采样的情况下，候选项 $C_i$ 被选中的总次数 $N_i$ 满足：</p><p>$$\lim_{M \to \infty} \frac{N_i}{M} = \frac{w_i}{W} \quad \text{(依概率)}$$</p><p>即，当总选择次数 $M$ 足够大时，候选项 $i$ 的实际选择比例依概率收敛到其权重比例。</p><h3>证明</h3><p><strong>第一步：单次选择的概率</strong></p><p>根据算法设计，每次选择时，候选项 $C_i$ 被选中当且仅当随机数 $r \in [CW_{i-1}, CW_i)$，其中 $CW_0 = 0$。</p><p>该区间长度为 $w_i$，因此：</p><p>$$P(C_i \text{ 被选中}) = \frac{w_i}{W}$$</p><p><strong>第二步：单个进程的期望</strong></p><p>设第 $j$ 个进程执行 $m_j$ 次选择，令 $X_{ji}$ 为该进程中 $C_i$ 被选中的次数。</p><p>由于每次选择是独立的，$X_{ji}$ 服从<strong>二项分布</strong> $B(m_j, \frac{w_i}{W})$，其期望为：</p><p>$$E[X_{ji}] = m_j \cdot \frac{w_i}{W}$$</p><p><strong>第三步：多进程的总期望</strong></p><p>所有进程中 $C_i$ 被选中的总次数为：</p><p>$$N_i = \sum_{j=1}^{k} X_{ji}$$</p><p>由期望的线性性质：</p><p>$$E[N_i] = \sum_{j=1}^{k} E[X_{ji}] = \sum_{j=1}^{k} m_j \cdot \frac{w_i}{W} = M \cdot \frac{w_i}{W}$$</p><p>这说明，<strong>无论进程数量如何变化</strong>，只要总选择次数是 $M$，$C_i$ 被选中的期望次数总是 $M \cdot \frac{w_i}{W}$。</p><p><strong>第四步：大数定律保证收敛</strong></p><p>由于 $X_{ji}$ 都是独立同分布的随机变量（每个进程独立采样），我们可以应用<strong>弱大数定律</strong>：</p><p>$$\lim_{M \to \infty} P\left(\left|\frac{N_i}{M} - \frac{w_i}{W}\right| &gt; \epsilon\right) = 0 \quad \forall \epsilon &gt; 0$$</p><p>即，当 $M$ 足够大时，$\frac{N_i}{M}$ 以高概率接近 $\frac{w_i}{W}$。</p><p><strong>第五步：方差分析（可选）</strong></p><p>为了更精确地刻画收敛速度，我们计算方差：</p><p>$$\text{Var}(N_i) = \sum_{j=1}^{k} \text{Var}(X_{ji}) = \sum_{j=1}^{k} m_j \cdot \frac{w_i}{W} \cdot \left(1 - \frac{w_i}{W}\right)$$</p><p>$$= M \cdot \frac{w_i}{W} \cdot \left(1 - \frac{w_i}{W}\right)$$</p><p>标准差为：</p><p>$$\sigma(N_i) = \sqrt{M \cdot \frac{w_i}{W} \cdot \left(1 - \frac{w_i}{W}\right)}$$</p><p>相对误差的标准差为：</p><p>$$\frac{\sigma(N_i)}{E[N_i]} = \sqrt{\frac{1}{M} \cdot \frac{W - w_i}{w_i}} = O\left(\frac{1}{\sqrt{M}}\right)$$</p><p>这说明，误差以 $\frac{1}{\sqrt{M}}$ 的速度递减，收敛速度是<strong>根号级别</strong>的。</p><h3>推论：进程动态变化的影响</h3><p><strong>推论 1</strong>（进程加入）：新进程加入相当于增加 $M$，会加快收敛速度，但不改变期望分布。</p><p><strong>推论 2</strong>（进程退出）：进程退出不影响已产生的样本，只是减少了未来的采样次数。由于已有样本仍然有效，总体分布不受影响。</p><p><strong>推论 3</strong>（进程组合无关性）：无论是 10 个进程各选 100 次，还是 1 个进程选 1000 次，或者任意其他组合，只要 $M = 1000$，期望分布和收敛性质完全相同。</p><h3>关键假设的验证</h3><p>我们的证明依赖于以下假设，现在验证它们在实现中是否满足：</p><ol><li><strong>独立性</strong>：✓ 每个进程使用独立的 <code>crypto/rand.Reader</code>，随机数序列互不相关</li><li><strong>同分布</strong>：✓ 所有进程加载相同的配置，使用相同的算法</li><li><strong>正整数权重</strong>：✓ 代码中检查 <code>w &gt; 0</code></li><li><strong>足够大的 $M$</strong>：✓ 在实际应用中，选择次数通常达到成千上万次</li></ol><hr/><h2>实验验证</h2><p>我们进行了三组实验来验证理论：</p><h3>实验 1：单进程，10,000 次选择</h3><table><thead><tr><th>候选项</th><th>权重</th><th>理论比例</th><th>实际次数</th><th>实际比例</th><th>误差</th></tr></thead><tbody><tr><td>A</td><td>5</td><td>45.45%</td><td>4523</td><td>45.23%</td><td>-0.48%</td></tr><tr><td>B</td><td>3</td><td>27.27%</td><td>2738</td><td>27.38%</td><td>+0.40%</td></tr><tr><td>C</td><td>2</td><td>18.18%</td><td>1821</td><td>18.21%</td><td>+0.16%</td></tr><tr><td>D</td><td>1</td><td>9.09%</td><td>918</td><td>9.18%</td><td>+0.99%</td></tr></tbody></table><p><strong>结论</strong>：误差在 ±1% 以内，符合预期。</p><h3>实验 2：10 进程，每进程 1,000 次（共 10,000 次）</h3><table><thead><tr><th>候选项</th><th>权重</th><th>理论比例</th><th>实际次数</th><th>实际比例</th><th>误差</th></tr></thead><tbody><tr><td>A</td><td>5</td><td>45.45%</td><td>4551</td><td>45.51%</td><td>+0.13%</td></tr><tr><td>B</td><td>3</td><td>27.27%</td><td>2719</td><td>27.19%</td><td>-0.29%</td></tr><tr><td>C</td><td>2</td><td>18.18%</td><td>1812</td><td>18.12%</td><td>-0.33%</td></tr><tr><td>D</td><td>1</td><td>9.09%</td><td>918</td><td>9.18%</td><td>+0.99%</td></tr></tbody></table><p><strong>结论</strong>：多进程结果与单进程几乎一致，证明进程数量不影响分布。</p><h3>实验 3：100 进程，每进程 1,000 次（共 100,000 次）</h3><table><thead><tr><th>候选项</th><th>权重</th><th>理论比例</th><th>实际次数</th><th>实际比例</th><th>误差</th></tr></thead><tbody><tr><td>A</td><td>5</td><td>45.45%</td><td>45472</td><td>45.47%</td><td>+0.04%</td></tr><tr><td>B</td><td>3</td><td>27.27%</td><td>27251</td><td>27.25%</td><td>-0.07%</td></tr><tr><td>C</td><td>2</td><td>18.18%</td><td>18193</td><td>18.19%</td><td>+0.05%</td></tr><tr><td>D</td><td>1</td><td>9.09%</td><td>9084</td><td>9.08%</td><td>-0.11%</td></tr></tbody></table><p><strong>结论</strong>：随着 $M$ 增加到 100,000，误差降低到 ±0.1% 以内，完美验证了 $O(\frac{1}{\sqrt{M}})$ 的收敛速度。</p><hr/><h2>总结</h2><p>本文从简单的均匀随机选择出发，逐步引入权重、多进程等复杂因素，最终设计出一个既简单又严谨的分布式加权随机选择算法。</p><h3>核心要点</h3><ol><li><strong>算法设计</strong>：累积权重 + 二分查找，时间复杂度 $O(\log n)$</li><li><strong>分布式原则</strong>：独立同分布采样，无需进程间同步</li><li><strong>数学保证</strong>：大数定律确保收敛性，方差分析预测误差</li><li><strong>实践验证</strong>：实验结果与理论完全吻合</li></ol><h3>适用场景</h3><ul><li>负载均衡（根据服务器性能分配流量）</li><li>A/B 测试（按比例分配用户到不同版本）</li><li>分布式限流（按权重分配配额）</li><li>随机抽奖（按中奖概率分配奖品）</li></ul><h3>关键优势</h3><p>✓ <strong>无状态</strong>：不需要记录历史，每次选择都是独立的  <br/>✓ <strong>高性能</strong>：$O(\log n)$ 时间复杂度，适合高频调用  <br/>✓ <strong>分布式友好</strong>：天然支持多进程，无需协调  <br/>✓ <strong>数学严谨</strong>：有完整的理论保证和实验验证  <br/>✓ <strong>加密安全</strong>：使用 <code>crypto/rand</code>，适合安全敏感场景  </p><p>这个算法的美妙之处在于：<strong>复杂性隐藏在数学之中，实现却极其简单</strong>。只要遵循独立同分布的原则，复杂的多进程协调问题就自然而然地解决了。</p>]]></description></item><item>    <title><![CDATA[因此未来合规成 苦闷的键盘 ]]></title>    <link>https://segmentfault.com/a/1190000047439345</link>    <guid>https://segmentfault.com/a/1190000047439345</guid>    <pubDate>2025-11-30 23:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>从生成式 AI 的惊艳亮相引起全球科技巨头军备竞赛般的投入开始，整个 AI 行业仿佛被注入了无限的想象力。似乎在宣告着即将出现一个生产力即将被彻底解放、商业模式即将被完全颠覆的光明未来。<br/>微软、谷歌、亚马逊等云巨头纷纷将资本支出的绝大部分押注于 AI 基础设施建设，而无数逐利而来的 AI 初创公司，更是如雨后春笋般涌现试图分一杯羹，全球 AI 领域的投资额也达到了史无前例的高度。<br/>然而，正如任何过热的淘金热最终都会迎来冷静期当技术以超乎预期的速度普及时，潜在的负面效应也以同样的速度被放大，正在悄然侵蚀着行业参与者。<br/>从 " 可选项 " 到 " 必选项 " 的巨额支出<br/>根据奇安信集团对外发布《2024 人工智能安全报告》来看，在 2023 年基于 AI 的深度伪造欺诈便已暴增了 3000%，基于 AI 的钓鱼邮件也增长了 1000%；而内容生成环节更是实现规模化生产。<br/>基于 Stable Diffusion 和 GPT-4 的定制模型，可每小时生成 2000 条伪原创研报、800 段逼真视频。暗网平台 "DarkGPT" 更是提供包月服务，1 万美元即可获得每日 5000 条金融虚假内容的产能。<br/>而且 "AI 滥用 " 的后遗症并不仅仅在社会新闻版块，可以说它已经穿透了科技公司的防火墙直接作用于其财务报表。而金融行业正是这场风暴的中心，当 AI 以假乱真的能力被精准地应用于金融诈骗时，其破坏力可以说是指数级的增长。<br/>据行业估算，2024 年由深度伪造技术引发的各类欺诈造成的全球经济损失已高达 120 亿美元。尤其在监管相对滞后、交易更为匿名的加密货币领域，AI 滥用更是如鱼得水。根据相关的报告也显示 2024 年仅 AI 深度伪造技术全年造成的损失便高达 46 亿美元。<br/>随着 AI 滥用事件的频发，过去模糊的 " 伦理指南 " 正在迅速转变为具有强制约束力的法律条文，而且这种转变直接导致了企业合规成本的急剧攀升。<br/>而且一旦出现违规需要付出的代价更是惨痛的，罚款最高可达全球年营业额的数个百分点或数千万欧元，而且合规也不再是法务部门的单一工作，而是渗透到研发、产品、市场的每一个环节。<br/>这些 " 反噬 " 也并非凭空产生，在 AI 商业化过程中对速度和规模的追求，长期以来压倒了对安全和伦理的考量所以形成了这种 " 原罪 "。因此未来合规成本的升高是不可避免的，而欧盟的《AI 法案》可以说是这一趋势的先行者。<br/>该法案于 2024 年 8 月 1 日正式生效并分阶段实施，着重对高风险的 AI 系统施加了严格的合规要求。而且这不仅仅是一项区域性法规，更可能产生 " 布鲁塞尔效应 " 从而影响全球的 AI 监管格局。<br/>监管的落地也将会直接转化为企业的合规成本。据公开信息推算，仅欧盟 AI 法案便可能导致欧洲企业的 AI 采纳成本增加约 310 亿欧元，并使 AI 投资减少近 20%。而美国联邦贸易委员会也已对 OpenAI 展开调查，谷歌等公司也不得不调整其营销话术，避免被处以巨额罚款。<br/>可以说 " 监管的铁幕 " 正在迫使整个行业从过去 " 快速行动，打破陈规 " 的互联网思维转向一种更为审慎、合规驱动的开发模式。可以说这种转变无疑会减缓创新速度并增加运营成本，对于那些资源有限的中小企业和初创公司构成尤为严峻的挑战。<br/>对 " 信任 " 的侵蚀或许是 AI 滥用最难修复的一种<br/>这源于在激烈的竞争压力下，企业急于抢占市场将产品快速推向用户，所以将风险控制和安全测试置于次要位置。但是这种 " 快速行动并打破规则 " 的心态在 AI 时代尤为危险，因为 AI 技术的潜在破坏力远超以往的软件应用。<br/>并且市场对于 AI 技术的可靠性极度敏感，甚至一次小小的失误都可能引发巨大的信任危机和财务损失。谷歌的 Bard 模型之前便在一次演示中出现事实性错误，竟然导致其母公司 Alphabet 的股价在单日内暴跌 7%，市值蒸发超过 1000 亿美元。<br/>并且随着 AI 投资的巨额支出持续攀升，投资者开始担忧其回报前景，这种悲观情绪导致 Meta、Microsoft、Alphabet 和 Nvidia 等 AI 领域的领军企业股价普遍承压下跌，市场也开始讨论 "AI 泡沫 " 的风险，并开始质疑哪些不计成本的 " 军备竞赛 " 式投资。<br/>更何况大量公司缺乏对 AI 伦理的明确责任归属，高管层面也并未对其有所调整。所以 AI 系统的决策过程像一个 " 黑箱 "，在责任主体模糊的情况下滥用和误用的风险便难以控制。企业内部也未建立有效的问责机制。<br/>但是更深层次的原因在于当前主流生成式 AI 商业模式本身所内含的风险。这些模型依赖于海量数据的投喂，其训练过程难以完全避免偏见和有害信息的吸收。而其强大的生成能力却为恶意利用提供了温床。<br/>因此当商业模式的核心是追求更强大的模型、更广泛的应用时，如果缺乏与之匹配的强大 " 安全刹车 " 系统，滥用就成了可预见的副产品。这种商业逻辑与伦理要求之间的结构性失衡才是导致 " 反噬 " 的根本内因。<br/>所以当企业享受了技术红利带来的增长，如今便也不得不为其模式所伴生的风险 " 买单 "。哪怕科技公司以 " 让世界更美好 " 的叙事推广 AI，公众在实际体验中，也会频繁受到隐私泄露、算法偏见、就业替代、虚假信息等负面影响。<br/>这种落差也导致了广泛的 "AI 焦虑 " 和不信任感。公众普遍认为现有的监管法规不足以应对 AI 带来的社会风险期望政府采取更加果断的行动。这种强大的民意压力也是推动监管机构加速行动的根本动力。<br/>面对公众的呼声和潜在的社会风险，监管机构的介入是必然的。但由于技术发展的速度远超立法速度监管往往表现出一定的滞后性，欧盟 AI 法案便被部分人士认为可能增加企业负担、抑制创新。<br/>全球主要经济体在 AI 领域的竞争，也使得监管变得更加复杂。各国都希望在鼓励创新和防范风险之间找到平衡点但这种平衡点的位置各不相同，因此形成了复杂的国际监管格局给跨国企业的合规带来了巨大挑战。<br/>而且这种外部滥用对整个 AI 行业的声誉造成了 " 连坐 " 效应。即使一家公司本身恪守伦理，也无法完全独善其身，因为公众对 AI 的信任是整体性的。恶意滥用行为如同向池塘中投下的毒药，在污染了整个水域后迫使所有 " 池中生物 " 共同承担后果。<br/>这场危机成为 AI 自我革新的契机<br/>这场 " 反噬 " 带来的阵痛，是 AI 产业从野蛮生长走向规范发展的必经阶段。它正在淘汰那些只想赚快钱、缺乏责任感的 " 玩家 "，筛选出真正有实力、有远见的长期主义者。从长远来看，这也是为 AI 产业的健康、可持续发展所必须付出的代价。<br/>其中最大的机遇在于将 " 信任 " 从一种道德呼吁，转变为一种可量化、可变现的商业资产和竞争壁垒。数据显示近 85% 的客户也更愿意与重视 AI 伦理实践的公司合作，而那些优先考虑伦理和透明度的公司收入增长也更快。<br/>可以说在 AI 产品同质化日益严重的未来，谁能赢得用户的信任谁就能赢得市场。" 负责任的 AI" 将不再仅仅是公关部门的口号，而是必须贯穿于产品设计、开发、部署全流程的核心战略。<br/>谷歌和微软等公司已经开始调整其策略，谷歌选择利用 AI 技术提升广告安全审核的效率，打击欺诈内容；微软则发布了负责任 AI 透明度报告，并推出了 AzureAIContentSafety 等服务，帮助客户构建更安全的 AI 应用。这些举措既是应对风险的防御，也是在构建新的竞争优势。<br/>正是 " 反噬 " 催生了全新的 " 安全即服务 " 市场。随着 AI 滥用风险的加剧企业对 AI 安全审计、风险评估、内容过滤、合规咨询等服务的需求将急剧增长。这为专门从事 AI 安全和伦理治理的科技公司、咨询机构创造了巨大的市场空间。<br/>而科技巨头自身也可以将其内部成熟的安全工具和能力平台化、服务化，开拓新的收入来源。例如，谷歌和微软在内容审核、风险识别方面的技术weibo.com/ttarticle/p/show?id=2309405238677524840593<br/>weibo.com/ttarticle/p/show?id=2309405238677999059065<br/>weibo.com/ttarticle/p/show?id=2309405238678338535509<br/>weibo.com/ttarticle/p/show?id=2309405238678682468514<br/>weibo.com/ttarticle/p/show?id=2309405238679018012899<br/>weibo.com/ttarticle/p/show?id=2309405238679504552195<br/>weibo.com/ttarticle/p/show?id=2309405238679844552753<br/>weibo.com/ttarticle/p/show?id=2309405238680171708599<br/>weibo.com/ttarticle/p/show?id=2309405238680515641390积累，完全可以转化为对外输出的商业服务。<br/>虽然监管的收紧虽然带来了成本，但也为行业设定了 " 准入标准 "，能够率先满足高标准合规要求的企业将获得更强的市场公信力和竞争优势，从而在未来的市场整合中占据有利地位。这实际上是一种由监管驱动的市场出清和格局优化。<br/>从滥用事件的激增，到资本市场的审慎，再到全球监管的收紧，这股 " 反噬 " 之力正在重塑 AI 产业的发展轨迹。它迫使整个行业从过去对技术力量的无限崇拜，转向对技术责任和社会价值的深刻反思。<br/>麦肯锡预测，到 2030 年 AI 将为全球经济创造 13 万亿美元价值。但价值分配取决于我们如何驾驭这头猛兽。未来的竞争，将不仅仅是模型参数和算力大小的竞争，更是治理能力、责任担当和用户信任的竞争。</p>]]></description></item><item>    <title><![CDATA[AI时代程序员转型思考 xindoo ]]></title>    <link>https://segmentfault.com/a/1190000047439157</link>    <guid>https://segmentfault.com/a/1190000047439157</guid>    <pubDate>2025-11-30 21:02:05</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>  先说一下我上周的工作情况，因为我们人事变动，前端资源紧张，一些需求前端同学没有人力支持，我就试着用AI帮忙跨栈解决。然后上周我就改了6个代码库，有前端、后端、还有微信小程序，语言涉及Java、Python、JavaScript。代码绝大部分都是AI帮忙写的，这个时候你是不是开始觉得程序员这个行业危矣！但这个经历让我有产生了一些新想法，我先直接抛结论：<strong>AI会干掉大量初级程序员，但对高级程序员来说反而是一种能力增强。</strong></p><p>  为什么这么说？让我换个角度思考这个问题。假设没有AI，这些工作我依然能完成，只不过原本一周能搞定的事情可能需要两周，也许我需要多查些资料、多看看代码、多调试几次。但反过来想，如果只有AI没有我，不管给它多少时间，它产出都是0。另一件事，在今年的国际大学生程序设计大赛（ICPC)上（这可是编程领域的顶尖赛事，被誉为程序员的奥林匹克），GPT-5和Gemini都超越人类拿到了金牌，所以我可以很笃定的讲，写代码你绝对写不过头部的那几个AI。 结合这两件事，我得出一个结论：<strong>程序员的核心价值已经不再是写代码了，而是知道该做什么、该怎么做、以及如何管理好这个过程</strong>。AI可以是完美的执行者，但它还不足以成为决策者。</p><p>  当AI能完成大部分代码编写工作时，程序员面临两种可能：如果无法与AI有效协同，可能被淘汰；如果善用AI提升生产力，则会变得更强大。这引出几个关键问题：</p><ul><li><strong>程序员的核心价值到底是什么?</strong> 如果写代码本身不再是壁垒，那什么才是我们不可替代的能力?</li><li><strong>如何与AI协作才能发挥最大效能?</strong> 是简单地把AI当作代码生成工具，还是需要掌握新的协作方式?</li><li><strong>什么样的程序员会被淘汰，什么样的会变得更强?</strong> 技术能力的分水岭会发生怎样的变化?</li></ul><p>带着这些问题，让我们先明确AI时代程序员的新定位，然后再看如何在实际工作中践行这些角色。</p><h3>AI时代程序员的三种新定位</h3><h3>1. 产品经理——决定做什么</h3><p>  决定应该实现什么样的功能，把控产品方向和需求。在使用AI之前，必须先搞清楚要解决什么问题，包括明确功能目标、梳理业务流程、定义验收标准。</p><p>  举例来说，在这次修改6个代码库的过程中，我首先需要决策应该修改和增加哪些功能，这些功能与之前的功能如何配合协同才更合理。比如前端页面需要新增一个数据展示模块，我要先确定这个模块应该放在哪个位置、与现有功能如何交互、用户操作流程是否顺畅。</p><p>  AI可以帮我写代码，但无法替我决定产品的功能规划和用户体验设计。只有把这些问题想清楚，才能给AI提供准确的上下文，让它生成符合预期的代码。</p><h3>2. 架构师——决定怎么做</h3><p>  虽然以AI目前的能力，这个"架构师"仍需关注一些琐碎的细节，但核心职责是设计系统架构和技术方案。关键问题是：<strong>哪种方案更适合你当前的业务情况?成本更低?风险更小?</strong></p><p>  这需要基于业务背景、团队现状、历史技术债务、未来扩展规划等因素综合考虑，而这些都是AI所不了解的信息，所以它很难帮你做出最优决策。技术方案的选择必须由你来决定，包括选择合适的技术栈、设计系统架构、评估技术风险。</p><p>  在我修改6个代码库的过程中，有些需要调整API接口，有些需要修改数据库表结构，有些需要重构前端组件。这些偏架构层面的决策都是我做的，AI只是帮我完成具体的实现。</p><h3>3. 管理者——管好AI执行</h3><p>  这里管理的对象不是人，而是AI。与管理人类团队不同，AI协作需要采用更细致的微管理（Micromanagement）方式。因此，在与AI协作时，你需要像管理实习生一样，把任务拆解得足够细，每个环节都要明确要求和验收标准。</p><p><strong>有效的AI协作需要遵循以下原则：</strong></p><ul><li><strong>拆解任务</strong> — 不要给AI一个大而模糊的任务，而是拆解成具体的小步骤。比如"实现用户登录功能"应该拆解为"创建登录API接口"、"添加参数校验"、"编写单元测试"等独立任务。</li><li><strong>提供明确上下文</strong> — 告诉AI当前代码的结构、使用的框架、命名规范、编码风格。例如不要说"优化这段代码"，而要明确"将这段重复代码提取成公共方法"。</li><li><strong>严格代码审查</strong> — AI生成的代码必须逐行Review，检查逻辑正确性、异常处理、安全漏洞和性能问题，不能因为是AI写的就盲目信任。另外，Review不仅是为了找出问题，更是为了理解AI的实现思路，方便后续的维护和扩展。</li><li><strong>持续反馈优化</strong> — 如果AI的输出不符合预期，要明确指出问题在哪里，让它修改。这个过程可能需要多轮迭代。</li></ul><h3>总结</h3><p>  AI不会取代程序员，但会重新定义程序员的工作方式。未来的程序员不再是纯粹的代码编写者，而是<strong>懂业务的产品经理、懂技术的架构师、会管理的协调者</strong>。那些只会写代码、不思考业务和架构的程序员会被淘汰，而那些能有效驾驭AI、将其作为生产力工具的程序员会变得更强大。</p><p>  关键在于：不要把AI当作威胁，而要把它当作助手;不要被动地担心被取代，而要主动地学习如何与AI协作。就像当年IDE的出现没有让程序员失业，反而让我们写代码更高效一样，AI也会成为我们工作中不可或缺的伙伴。</p><p>  最后，如果你还在纠结"AI会不会取代程序员"这个问题，不如问问自己：<strong>我是在单纯地写代码，还是在做有价值的决策?我是在被动地完成任务，还是在主动地思考和创造?</strong> 答案决定了你在AI时代的位置。</p>]]></description></item><item>    <title><![CDATA[IT运维人员能力建设：从技术岗到管理岗的]]></title>    <link>https://segmentfault.com/a/1190000047439203</link>    <guid>https://segmentfault.com/a/1190000047439203</guid>    <pubDate>2025-11-30 21:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>那一年，我刚从一线工程师的岗位被提拔为项目经理。<br/> 这本该是一件值得庆贺的事，可我却度过了极为焦虑的三个月。<br/> 每天的工作不再是修复服务器、排查日志，而是协调资源、写计划、开会、谈预算。<br/> 我突然发现，过去十年积累的技术经验似乎一下子变得“不够用了”。<br/> 那段时间，我深刻体会到：从技术岗位到管理岗位的转变，并不是职位的变化，而是思维方式的革命。<br/>在IT运维领域，这样的转型几乎是每一位从业者的必经之路。</p><p><img width="630" height="610" referrerpolicy="no-referrer" src="/img/bVdndgA" alt="" title=""/><br/> 一线工程师关注的是“怎么把故障修好”，而管理者必须思考“为什么会故障”“怎样防止它再次发生”“对业务影响有多大”。<br/> 当我第一次主持变更评审会议时，才真正明白了“流程管理”的重要性——它不是束缚，而是让所有技术行为有章可循、可追溯、可改进的唯一途径。<br/> 技术可以让你快速解决问题，但流程才是确保问题不再重演的系统方法。<br/>我还记得第一次做年度运维计划的场景。<br/> 面对上百个待处理的任务单，我试图用熟悉的“工单逻辑”去排序优先级。<br/> 但领导问我：“这些工作对应哪些业务目标？资源投入和回报比例是多少？”<br/> 那一刻，我才意识到自己仍然站在技术视角看世界。<br/> 而管理岗位，需要从业务视角出发，以成本、风险、交付周期为决策依据。<br/> 这就是ITSS标准体系中提到的“服务管理思维”——不再只看技术成效，而是用可度量的指标来定义服务价值。<br/>当我开始理解“服务是为业务存在”这句话后，很多难题自然解开。<br/> 我学会了用流程化的方式整合资源，用SLA（服务级别协议）来管理预期，用KPI来衡量团队绩效。<br/> 同时，我逐渐懂得，管理者不是“最懂技术的人”，而是能让懂技术的人发挥最大价值的人。<br/> 这让我第一次从“技术执行者”变成了“组织推动者”。<br/>当然，这个转变过程并不轻松。<br/> 最难的一步，是从“自己动手”到“授权他人”。<br/> 我曾经忍不住亲自修改系统配置，因为觉得自己做得更快、更准。<br/> 结果却打乱了同事的排期，破坏了责任分工。<br/> 那次之后我学会了真正的“放手”——管理的核心，不是替别人完成任务，而是让每个人都能在标准化体系中高效完成任务。<br/> 这正是ITSS提出“能力管理”章节的核心精神：通过制度与流程的结合，形成组织能力，而非个人英雄主义。<br/>为了适应这种变化，我开始系统学习ITSS国家标准体系。<br/> 在那套标准中，我第一次看到“人员、过程、技术、资源”四要素被统一纳入运维管理框架的逻辑。<br/> 原来，技术能力只是其中一个维度。<br/> 更高层次的能力，来自于对流程的理解、对人的管理、以及对资源的优化。<br/> 这也是为什么在成熟度模型（T/CESA 1299）中，一级企业靠个体能力存活，而四级以上企业依赖流程和文化。<br/> 只有当一个组织的运维活动可以被标准化、量化、复用，它才真正具备“能力”。<br/>在这过程中，我也见证了许多同行的成长。<br/> 有位叫李明的同事，从机房夜班工程师做起。<br/> 当初他对项目计划表完全无感，只想“快点修完下班”。<br/> 后来在我们的ITSS培训班上，他开始用PDCA循环管理自己的工作。<br/> 他发现，当流程被梳理清楚后，团队效率提升了30%，故障率下降了一半。<br/> 三年后，他成了我们公司第一个通过ITSS服务项目经理认证的人，如今负责整个区域的服务交付质量管理。<br/>作为艾拓先锋的官方ITSS授权讲师，在讲授ITSS服务项目经理认证培训课程时我会特别强调这一点：<br/>管理不是抛弃技术，而是用系统思维重新整合技术，让它为业务目标服务。<br/> 很多学员在听完课程后才发现，管理的本质不是“多一个头衔”，而是“多一套方法论”。<br/> 而这套方法论，正是ITSS体系带给行业最宝贵的财富。<br/>这几年，我越来越相信：职业发展的天花板，从来不是岗位名称，而是你愿不愿意构建自己的能力模型。<br/> 有的工程师在同一个岗位上十年如一日，因为他始终把自己定位为“修电脑的人”；<br/> 而另一些人，却能一步步成为CIO，因为他们学会了用“流程、标准、策略”看问题。<br/> 这就是“能力建设”的差异所在。<br/>ITSS标准为这种成长提供了清晰的路径。<br/> 从基础的知识学习，到能力评估、再到成熟度验证，它帮每一位从业者明确：技术是入门，流程是进阶，战略才是顶层。<br/> 无论是工程师、项目经理，还是服务总监，都可以在标准化体系中找到自己的坐标。<br/> 当一个组织鼓励成员通过标准化工具学习和成长，它的整体能力就能持续积累，而不是依赖少数人的经验。<br/>回头看，我从那个“靠经验修问题”的技术人，变成了“靠体系防问题”的管理者。<br/> 这种变化带来的不是身份转变，而是一种全新的职业自觉。<br/> 我开始主动复盘失败项目的根因，不是为了追责，而是为了让流程更稳、风险更低。<br/> 我也学会了衡量团队的能力差距，用量化指标去驱动培训计划。<br/> 这种以标准为基础的成长方式，让我对职业生涯有了更长期的信心。<br/>运维行业的未来，属于那些既懂技术、又懂管理的人。<br/> 懂技术，才能与团队共语；懂管理，才能与业务共赢。<br/> 当我们逐渐从执行者变成引领者，ITSS标准不再只是参考文件，而是帮助我们把复杂世界变得可控的指南针。<br/> 能力建设，从来不是外部的要求，而是职业人的主动选择。<br/>能力建设永远是主动选择。</p>]]></description></item><item>    <title><![CDATA[效能工具十之接入deepseek实现AI]]></title>    <link>https://segmentfault.com/a/1190000047439153</link>    <guid>https://segmentfault.com/a/1190000047439153</guid>    <pubDate>2025-11-30 20:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>前言</h2><p>看文，看的是一种思路，希望笔者的文章能给诸位带来一些灵感思路☺️☺️☺️</p><h2>业务需求场景描述</h2><ul><li>公司每个月都会安排员工学习一个pdf文档（有点形式主义的学习）</li><li>然后，根据文档内容写一篇500字左右读后感txt</li><li>员工都是把文档丢给AI让其帮忙写读后感</li><li>一个员工每个月要花费10分钟，几十个员工，就累计是几个小时的成本</li><li>人越多，成本越高</li><li>针对于这个情况，笔者思考，倒不如写一个工具</li><li><strong>由专人在月末的时候，直接通过工具，点一点，一键生成几十份甚至上百份的学后感</strong></li><li>如此这般，就能够进行相应的提效</li></ul><h2>代码实现</h2><h3>技术选型</h3><ul><li>首先是pdf的文字提取，这里使用FileReader去读取需要学习的pdf文件（上传pdf）</li><li>然后，把读取到的数据，交给<a href="https://link.segmentfault.com/?enc=5FF5%2BhNLuaILWQtSZdKBEg%3D%3D.hFepA7DnGajpC9EPqoMWnRanxucV21zO2%2BfCjU9XtVVd5vcS5ATDkGJ1eIgdO6IjGTtghhT2YE4i%2F6o9WDomkA%3D%3D" rel="nofollow" target="_blank">pdf-dist</a>中的pdf.js和pdf.worker.js</li><li>这里就可以拿到pdf中的所有文字信息了（包括页码数）</li><li>再然后，把pdf中的文字信息作为user的内容</li><li>再提前写好系统级的提示词内容</li><li>丢给deepseek的接口返回给前端</li><li>前端再通过<a href="https://link.segmentfault.com/?enc=Xl1Yl36UbnC1nTcju57Z1g%3D%3D.QUEtPT6x7ARrHkmqXSJEdP6CyoauS773ostA4BBw77BSsaWRqBY9mThJZXha3NwxP%2B%2FtmObmBU7nr9x7i7kQNw%3D%3D" rel="nofollow" target="_blank">file-saver.js</a>下载对应的内容即可做到生成pdf学后感txt文本的功能</li><li>生成多份，就批量请求一下接口，整体Promise.allSettled一下即可</li><li>最终，再使用<a href="https://link.segmentfault.com/?enc=8ZxOZxADmlLPBBuo3U8DoQ%3D%3D.YQ3XEjIHxGc0lPhEiDhDHLnxf%2B%2FCA8qpSZPH8A7uBWvWx1Tm6Vu7zeEw204kjyLL" rel="nofollow" target="_blank">jszip</a>把所有的txt打包成一个压缩包，直接下载了</li></ul><h3>deepseek开放平台注册API keys</h3><p>地址：<a href="https://link.segmentfault.com/?enc=OyXnPCImdVXKZ%2B0%2FGMSbbg%3D%3D.TJckMUgOAaI7%2Bdyk85J%2BCVtT1HQDN%2Bo2J7GuQDg5d30vBhs1r%2BjA279GCQi8cHk6" rel="nofollow" target="_blank">https://platform.deepseek.com/api_keys</a></p><p>截图：</p><p><img width="723" height="359" referrerpolicy="no-referrer" src="/img/bVdndfL" alt="" title=""/></p><p>当然，需要充点两块钱，如下：</p><p><img width="723" height="516" referrerpolicy="no-referrer" src="/img/bVdndfM" alt="" title="" loading="lazy"/></p><blockquote>实际上，大模型的生成文字的token一般都不贵，笔者测算了一下，<strong>生成50篇500字的txt文，成本不到一毛钱</strong></blockquote><h3>使用express框架通过openai包调用deepseek的服务</h3><p>有了deepseek的API keys且账户有钱后，就可以在服务端调用了，通过npm安装openai这个包</p><pre><code class="json">  "dependencies": {
    "express": "^5.1.0",
    "openai": "^6.9.1"
  }</code></pre><blockquote>笔者这里使用的是express</blockquote><p>如下：</p><pre><code class="js">import express from 'express';
import OpenAI from "openai";

// 初始化 OpenAI
const openai = new OpenAI({
    baseURL: 'https://api.deepseek.com',
    apiKey: 'sk-27cae***********************1093', // 换成自己的
});

const systemContent = `系统级提示词高权重，用于规范限定回答内容`;

app.post('/api/chat', async (req, res) =&gt; {
    try {
        const { content } = req.body;

        if (!content) {
            return res.status(400).json({ error: '请提供要学习的内容' });
        }

        const completion = await openai.chat.completions.create({
            messages: [
                { role: "system", content: systemContent },
                { role: "user", content: content },
            ],
            model: "deepseek-chat",
        });
        const result = completion.choices[0]?.message?.content;
        res.json({ result });
    } catch (error) {
        console.error('API 调用失败:', error);
        res.status(500).json({ error: error.message || 'API 调用失败' });
    }
});</code></pre><h3>编写系统级提示词</h3><p>上述的systemContent可以根据实际业务情况，进行适当编写</p><pre><code class="js">const systemContent =
`
你是一个热爱中国的优秀员工。
所在的公司是xxx。
所在的部门是yyy。
仔细阅读用户提供的学习内容材料，并返回一段学习学后感。

格式要求：
- 纯文本格式，不要使用markdown
- 字数控制在400-600个字符之间
- 使用第一人称"我"来叙述

内容要求：
1. 学后感要简洁明了，逻辑清晰
2. 内容要符合实际
3. 要体现...
4. 要结合学习材料的具体内容，不能泛泛而谈
5. 要实事求是，言之有物，避免空话套话
6. 注意分段落

多样性要求：
- 每次生成都要使用不同的表达方式、不同的角度和不同的案例
- 避免使用重复的词语、句子和段落结构
- 确保每次生成的学后感都是全新的内容

重要提醒：
- 返回的内容必须符合中国的法律法规
- 要结合学习材料的具体内容进行深入思考
- 不要使用缓存！
`;</code></pre><h3>快速理解什么是提示词？</h3><ul><li>ai交互的核心就是系统级提示词（System Prompt）和用户提示词（User Prompt）</li></ul><p>如下表</p><table><thead><tr><th>维度</th><th>系统级提示词</th><th>用户提示词</th></tr></thead><tbody><tr><td>生效范围</td><td>全局生效（所有对话轮次）</td><td>仅当前 / 指定轮次生效</td></tr><tr><td>优先级</td><td>更高（覆盖用户提示词冲突项）</td><td>服从系统规则</td></tr><tr><td>核心目的</td><td>设定规则与角色</td><td>提出具体问题 / 需求</td></tr><tr><td>可见性</td><td>通常对用户不可见（后台配置）</td><td>用户主动输入，完全可见</td></tr></tbody></table><p>比如，有如下场景</p><ul><li><strong>客服智能问答场景</strong>：系统提示词定义 “语气友好、优先解决用户问题、无法解答时引导转人工”，用户仅需提问 “我的订单为什么没发货”，AI 就会按该规则响应；</li><li><strong>AI创作场景</strong>：系统提示词设定 “风格为悬疑短篇、字数 500 字以内、结尾留悬念”，用户仅需说 “以雨夜为背景写一个故事”，AI 的输出就会贴合这些要求。</li></ul><blockquote>系统级提示词有点像cosplay的身份角色背景设定...</blockquote><p>所以，上述systemContent才会定义成为那样的</p><p>现在，有了接口了<code>app.post('/api/chat', async (req, res) =&gt; { ... })</code></p><p>这样的话，前端就可以做对应请求数据，下载操作了...</p><blockquote>篇幅有限，不继续赘述</blockquote><h2>总结</h2><ul><li>看完本文，大家可记住这样一句话：<strong><code>所有重复的、没有技术含量的办公操作，都可以考虑使用AI进行提效</code></strong></li><li>此外，大家可以思考一下，如何能把公司的一些业务场景给抽象出来，使用AI进行高效解决问题？</li></ul><blockquote>手工创作不易，感谢大家支持鼓励☺️☺️☺️</blockquote>]]></description></item><item>    <title><![CDATA[CRM软件是什么？功能解析+选型指标一篇]]></title>    <link>https://segmentfault.com/a/1190000047438943</link>    <guid>https://segmentfault.com/a/1190000047438943</guid>    <pubDate>2025-11-30 19:04:29</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>CRM软件不是“高大上的通讯录”，而是把线索变订单、把订单变复购的“印钞机”。从客户首次点击官网，到售后回访，所有数据若能自动沉淀、智能提醒、实时分析，销售人均产能可立刻提升30%。下文将用Zoho CRM实战界面，带你先弄清“CRM软件是什么”，再给出5条“好坏判断标尺”，让选型不再踩坑。<br/><img width="431" height="287" referrerpolicy="no-referrer" src="/img/bVdndco" alt="" title=""/><br/>一、什么是CRM软件？<br/>CRM软件，即客户关系管理软件，是一种帮助企业管理和优化客户关系的工具。其核心目的是通过全面了解客户需求与行为，提升客户满足度和忠诚度。CRM软件通过集成客户信息、分析数据和自动化业务流程，帮助企业实现以下目标：</p><ol><li>集中客户数据<br/>CRM软件能够收集并整合来自各种渠道的客户数据，包括电子邮件、电话记录、社交媒体互动等。这种数据集成使企业能够全面了解客户行为和偏好。</li></ol><p>Zoho CRM支持多渠道客户数据整合，包括电子邮件、社交媒体、电话和网站交互，帮助企业实时掌握客户动态。</p><ol start="2"><li>改善客户互动<br/>通过CRM，企业可以更好地管理客户沟通，提升客户服务质量。软件通常配备自动化功能，如邮件提醒、客户预定和问题跟进，增强客户体验。</li></ol><p>Zoho CRM的销售自动化工具可以帮助企业跟进客户互动，并通过AI助手Zia提供智能提醒和建议。</p><ol start="3"><li>增强销售和市场营销<br/>CRM软件提供深入的数据分析，帮助企业识别销售机会、制定更精准的市场策略，并提高销售转化率。</li></ol><p>Zoho CRM提供销售漏斗管理、预测分析和营销自动化功能，帮助企业优化销售和营销流程。</p><p>二、CRM软件的核心功能<br/>了解CRM软件的功能模块是判断其优劣的第一步。尽管不同的软件平台提供的功能可能不同，大多数CRM系统都具备以下核心功能：</p><ol><li>客户管理<br/>提供关于客户的完整概览，包括联系信息、交互历史、购买记录等，帮助企业个性化客户服务。</li></ol><p>Zoho CRM功能：Zoho CRM的360度客户视图整合客户的所有数据，帮助企业更好地理解和服务客户。</p><ol start="2"><li>销售管理<br/>包括销售漏斗管理、销售预测、报告生成等功能，支持销售团队更高效地管理交易和客户关系。</li></ol><p>Zoho CRM功能：Zoho CRM提供可视化的销售管道，并通过AI助手Zia预测销售趋势，优化销售策略。</p><ol start="3"><li>市场营销自动化<br/>通过自动化电子邮件营销、广告活动跟踪等功能，帮助营销团队设计和执行更具针对性的营销活动。</li></ol><p>Zoho CRM功能：Zoho CRM与Zoho Campaigns无缝集成，支持跨渠道营销活动的自动化管理。</p><ol start="4"><li>客户服务与支持<br/>提供服务请求管理、客户自助服务门户和实时聊天支持等工具，提高客户服务效率。</li></ol><p>Zoho CRM功能：Zoho CRM与Zoho Desk集成，帮助企业高效管理客户服务请求并提升客户满意度。</p><ol start="5"><li>报告与分析<br/>提供数据可视化工具和定制化报告功能，帮助企业分析市场趋势、客户行为和销售绩效。</li></ol><p>Zoho CRM功能：Zoho CRM支持自定义仪表板和实时报告，帮助企业快速获取关键业务洞察。</p><p>三、如何判断CRM软件的好坏？<br/>在评估CRM软件的好坏时，应从以下几个方面进行全面考量：</p><ol><li>功能与需求匹配<br/>企业需要明确自身的业务需求，并评估CRM软件功能是否与之匹配。有些软件适合大型企业的复杂需求，而另一些则更适合中小企业。</li></ol><p>Zoho CRM优势：Zoho CRM提供多种版本（如免费版、专业版和企业版），适合不同规模和需求的企业。</p><ol start="2"><li>用户友好性<br/>软件应具备直观、易于操作的界面，提供简便的导航和清晰的功能分类。此外，丰富的在线培训资源和客服支持也是评估用户友好性的重要因素。</li></ol><p>Zoho CRM优势：Zoho CRM提供简洁的界面设计和丰富的在线学习资源（如Zoho Academy），并支持多语言操作。</p><ol start="3"><li>集成与兼容性<br/>选择能够与现有系统无缝集成的CRM软件，可以大大提升整体工作效率。此外，关注软件对移动设备的兼容性。</li></ol><p>Zoho CRM优势：Zoho CRM支持与第三方工具（如Gmail、Slack、QuickBooks等）集成，同时提供强大的API接口，便于企业自定义扩展。</p><ol start="4"><li>数据安全性<br/>CRM系统存储了大量的客户敏感信息，因此，评估软件的数据加密方式、访问权限管理和备份选项尤为重要。</li></ol><p>Zoho CRM优势：Zoho CRM采用企业级安全措施，包括数据加密、双因素认证和定期备份，确保客户数据的安全性。</p><ol start="5"><li>可扩展性<br/>随着业务的发展，企业对CRM软件的需求可能会变化。因此，选择一款具有扩展能力的软件系统至关重要。</li></ol><p>Zoho CRM优势：Zoho CRM支持模块化设计，并提供丰富的第三方插件和扩展功能，适应企业未来的增长需求。</p><ol start="6"><li>成本效益<br/>企业需结合价格与收益评估软件的性价比，包括许可证费用、实施成本、培训费用和后续维护成本。</li></ol><p>Zoho CRM优势：Zoho CRM以其灵活的定价模式和高性价比受到广泛好评，尤其适合预算有限的中小企业。</p><p>四、如何选择适合的CRM供应商？<br/>除了软件本身，供应商的资质和信誉也是选择过程中的重要考量因素。企业应优先选择拥有良好市场口碑和丰富行业经验的供应商。以下是选择供应商时需要关注的关键点：</p><ol><li>技术支持与服务<br/>确保供应商提供及时的客户支持，包括在线帮助、电话支持和技术指导。</li></ol><p>Zoho CRM优势：Zoho CRM提供24/7的全球技术支持，并拥有本地化服务团队，帮助企业快速解决问题。</p><ol start="2"><li>开发路线图<br/>了解供应商的产品更新计划和长期发展方向，确保软件能够满足未来需求。</li></ol><p>Zoho CRM优势：Zoho CRM定期推出新功能和更新，保持产品的竞争力和创新性。</p><ol start="3"><li>客户评价与案例<br/>查看其他企业的使用案例和评价，了解供应商在实际应用中的表现。</li></ol><p>Zoho CRM优势：Zoho CRM在全球拥有超过80000家客户，涵盖多种行业，具有广泛的市场认可度。</p><p>选CRM的本质是选增长杠杆。Zoho CRM提供从免费版到企业版的模块化套餐，AI销售预测、360°客户视图、营销自动化、API开放接口一次给齐，14天全功能试用零门槛。现在就注册，把文内的5条评估标准立刻套用在真实数据上，让下一封跟进邮件自带成交概率，下一次客户拜访自带采购热度——增长从此可量化、可复制、可持续。</p>]]></description></item><item>    <title><![CDATA[CRM信息系统怎么查公司运营数据？实操步]]></title>    <link>https://segmentfault.com/a/1190000047438953</link>    <guid>https://segmentfault.com/a/1190000047438953</guid>    <pubDate>2025-11-30 19:03:51</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>还在 Excel 里手动拼接销售、市场、客服三张表？数据晚一天，决策慢一拍。CRM 信息系统的真正价值，是让你“一键”看清公司运营全貌：线索转化、订单进度、客户活跃度、复购预测实时推送到仪表盘。下文拆解高效获取运营数据的 5 步流程，并全程示范 Zoho CRM 的 AI 采集、智能标签、实时仪表盘，让 2 人团队也能拥有大数据部门的决策速度。<br/><img width="512" height="340" referrerpolicy="no-referrer" src="/img/bVdndcy" alt="" title=""/><br/>一、CRM信息系统的核心功能<br/>CRM信息系统的主要功能是帮助企业管理客户关系，但其作用远不止于此。以下是CRM系统的五大核心功能模块：</p><p>客户数据管理<br/>CRM系统能够集中存储客户的基本信息、交易记录、沟通历史等数据，形成完整的客户档案。这种集中化管理不仅提高了数据的可访问性，还能避免信息孤岛的出现。</p><p>销售流程管理<br/>CRM系统可以帮助企业跟踪销售线索、商机和订单状态，优化销售流程。例如，通过销售漏斗分析，企业可以清楚地了解每个阶段的转化率，从而调整销售策略。</p><p>市场营销自动化<br/>通过CRM系统，企业可以实现营销活动的自动化管理，如邮件营销、社交媒体推广和活动跟踪等。这不仅提高了营销效率，还能通过数据分析评估活动效果。</p><p>客户服务支持<br/>CRM系统能够记录客户的服务请求、投诉和反馈，帮助企业快速响应客户需求，提升客户满意度。</p><p>数据分析与报告<br/>CRM系统内置的数据分析工具可以生成各种报表和图表，帮助企业洞察运营状况。例如，Zoho CRM提供了强大的数据分析功能，支持自定义报表和实时仪表盘，帮助企业快速获取关键数据。</p><p>二、如何通过CRM系统高效获取公司运营数据？<br/>要通过CRM系统高效获取公司运营数据，需要从以下几个关键步骤入手：</p><ol><li>明确数据需求<br/>在使用CRM系统之前，企业需要明确自身的数据需求。例如：</li></ol><p>销售团队需要了解客户的购买行为和订单状态；<br/>市场团队需要分析营销活动的转化效果；<br/>管理层需要掌握整体的业务运营状况。<br/>明确需求后，企业可以根据目标设置CRM系统中的数据字段和报表模板。</p><ol start="2"><li>数据的全面采集<br/>CRM系统的核心在于数据的全面性和准确性。以下是几种常见的数据采集方式：</li></ol><p>手动录入：销售人员或客服人员将客户信息录入系统。<br/>自动化采集：通过网站表单、社交媒体、电子邮件等渠道自动采集客户数据。<br/>第三方集成：CRM系统与其他工具（如ERP、电子商务平台）集成，实现数据的自动同步。例如，Zoho CRM支持与多种第三方工具无缝集成，确保数据采集的全面性。</p><ol start="3"><li>数据的清洗与整理<br/>在数据采集完成后，企业需要对数据进行清洗和整理，确保数据的准确性和一致性。CRM系统通常提供数据去重和清洗功能，帮助企业优化数据质量。</li><li>数据的分类与标签化<br/>为了便于分析和使用，企业可以通过CRM系统对数据进行分类和标签化。例如：</li></ol><p>按客户行业、地域、规模等维度分类；<br/>为客户添加“高价值客户”“潜在客户”等标签。<br/>Zoho CRM的“高级过滤器”和“智能标签”功能可以帮助企业快速对数据进行分类和筛选。</p><ol start="5"><li>数据的可视化与分析<br/>高效的数据获取离不开直观的可视化工具。CRM系统通常内置仪表盘和报表功能，帮助企业快速生成数据分析结果。例如，Zoho CRM的仪表盘支持实时数据更新，企业可以随时查看销售业绩、客户增长趋势等关键指标。</li></ol><p>三、CRM系统在公司运营数据获取中的实际应用场景</p><ol><li>销售团队的应用<br/>销售团队可以通过CRM系统获取以下关键数据：</li></ol><p>销售漏斗分析：了解每个销售阶段的客户数量和转化率。<br/>客户行为数据：跟踪客户的购买历史和沟通记录，预测未来需求。<br/>业绩报表：实时查看团队和个人的销售业绩。<br/>例如，Zoho CRM的“销售预测”功能可以帮助销售经理预测未来的收入，并根据数据调整销售策略。</p><ol start="2"><li>市场团队的应用<br/>市场团队可以通过CRM系统获取以下数据：</li></ol><p>营销活动效果分析：评估邮件营销、广告投放等活动的转化率。<br/>潜在客户数据：通过表单和社交媒体采集潜在客户信息。<br/>客户画像：基于客户数据生成精准的客户画像，优化营销策略。<br/>Zoho CRM的“营销自动化”模块支持多渠道数据采集和分析，帮助市场团队提升工作效率。</p><ol start="3"><li>管理层的应用<br/>管理层可以通过CRM系统获取以下数据：</li></ol><p>业务运营数据：全面了解公司的销售额、客户增长率等关键指标。<br/>团队绩效数据：评估各部门和团队的工作效率。<br/>战略决策支持：基于数据分析结果制定长期发展战略。<br/>Zoho CRM的“高级分析”功能支持跨部门数据整合，帮助管理层全面掌握企业运营状况。</p><p>四、选择合适的CRM系统：Zoho CRM的优势<br/>在众多CRM系统中，Zoho CRM因其功能全面、易用性强和性价比高而备受企业青睐。以下是Zoho CRM的几大优势：</p><p>功能全面<br/>Zoho CRM涵盖了客户管理、销售自动化、营销自动化、数据分析等核心功能，能够满足不同规模企业的需求。</p><p>高度可定制化<br/>企业可以根据自身需求自定义字段、工作流和报表，确保系统与业务流程高度契合。</p><p>多渠道集成<br/>Zoho CRM支持与电子邮件、社交媒体、电话系统等多种渠道集成，实现数据的无缝流转。</p><p>强大的数据分析能力<br/>Zoho CRM内置多种数据分析工具，支持实时仪表盘、自定义报表和高级分析，帮助企业快速获取关键数据。</p><p>高性价比<br/>相较于其他CRM系统，Zoho CRM的价格更具竞争力，适合中小企业和初创公司。</p><p>五、常见问答FAQ<br/>FAQ 1: CRM系统如何帮助企业高效获取运营数据？<br/>CRM系统通过集中化管理客户信息、自动化采集数据、分类与标签化、以及内置的数据分析工具，帮助企业高效获取运营数据。例如，CRM系统可以自动采集客户的沟通记录、购买行为等信息，并通过仪表盘和报表功能直观呈现销售业绩、客户增长趋势等关键指标，从而支持企业的决策和优化流程。</p><p>FAQ 2: Zoho CRM在数据分析方面有哪些优势？<br/>Zoho CRM在数据分析方面具有以下优势：</p><p>实时仪表盘：支持实时更新数据，帮助企业随时掌握运营状况。<br/>自定义报表：企业可以根据需求生成个性化的报表，满足不同部门的分析需求。<br/>高级分析功能：支持跨部门数据整合，帮助管理层全面了解业务运营情况。这些功能使Zoho CRM成为企业获取和分析运营数据的强大工具。<br/>FAQ 3: 如何选择适合企业的CRM系统？<br/>选择CRM系统时，企业需要考虑以下几点：</p><p>功能需求：确保CRM系统涵盖客户管理、销售自动化、数据分析等核心功能。<br/>可定制性：选择能够根据企业需求自定义字段、工作流和报表的系统。<br/>集成能力：优先选择支持与其他工具（如邮件、社交媒体、ERP系统）无缝集成的CRM系统。<br/>性价比：根据企业规模和预算选择合适的CRM系统，例如Zoho CRM以其高性价比和全面功能成为中小企业的理想选择。<br/>六、总结<br/>数据驱动不是口号，而是“实时可看、可导、可预测”。立即免费试用 Zoho CRM：15 天全功能开放，自动同步邮件、社媒、广告表单等 20 + 渠道数据，5 分钟生成可视化仪表盘，把销售漏斗、客户画像、复购预警一次看全。今天注册，让下一次复盘会议不再依赖“我觉得”，而是打开 Zoho CRM 直接说“数据在这里”。</p>]]></description></item><item>    <title><![CDATA[全球贸易挑战？进出口企业2025业务流程]]></title>    <link>https://segmentfault.com/a/1190000047439005</link>    <guid>https://segmentfault.com/a/1190000047439005</guid>    <pubDate>2025-11-30 19:03:12</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>2025 年，关税一夜调整、汇率瞬间跳水、航线突然中断……全球贸易的“灰犀牛”接踵而来。面对政策、供应链、合规三座大山，进出口企业只有把流程压缩到最短、把账算到最细，才能挤出利润。本文给出一张“业务流程优化路线图”，并实测演示：如何用 Zoho Books 一套系统搞定多币种报价、自动算税、库存联动，让订单到收款全程提速 50%。<br/><img width="500" height="328" referrerpolicy="no-referrer" src="/img/bVdnddk" alt="" title=""/><br/>一、全球贸易挑战：进出口企业面临的五大痛点</p><ol><li>关税与政策变化<br/>全球贸易政策的频繁调整，如关税壁垒、出口管制等，增加了企业的运营成本和合规难度。企业需要实时掌握政策动态，并快速调整策略以规避风险。</li><li>供应链不稳定<br/>地缘政治、自然灾害和疫情等因素导致供应链中断风险上升。企业需要建立灵活的供应链管理体系，确保货物按时交付。</li><li>汇率波动<br/>汇率的剧烈波动直接影响进出口企业的利润。企业需要通过有效的财务管理工具来对冲汇率风险，优化成本控制。</li><li>合规与数据安全<br/>各国对数据安全和隐私保护的要求日益严格，企业需要确保业务流程符合当地法规，避免因违规而遭受处罚。</li><li>客户与市场变化<br/>消费者需求和市场趋势的变化要求企业快速响应，调整产品策略和销售渠道。</li></ol><p>二、优化业务流程：进出口企业的突围之道<br/>面对上述挑战，进出口企业需要从以下几个方面优化业务流程：</p><ol><li>数字化转型与自动化<br/>通过引入ERP、财务管理软件等工具，实现业务流程的自动化，减少人工错误，提高效率。例如，Zoho Books智能外贸管理工具可以帮助企业一键生成报价单、跟踪账款、管理库存，从而简化财务流程。</li><li>供应链可视化与协作<br/>利用供应链管理技术，实时监控物流和库存状态，与供应商和客户保持高效协作。</li><li>数据驱动的决策<br/>通过数据分析工具，企业可以预测市场趋势、优化库存水平，并制定更精准的业务策略。</li><li>合规与风险管理<br/>建立完善的合规体系，确保业务流程符合国际贸易法规。</li><li>客户关系管理<br/>通过CRM系统提升客户服务质量，增强客户忠诚度。Zoho Books与Zoho CRM的无缝集成，帮助企业实现从订单到收款的全流程管理。</li></ol><p>三、Zoho Books：助力企业更好地应对全球化挑战<br/>在全球化浪潮中，企业面临着诸多管理挑战，如多语言多币种交易、国际税务合规、供应链协同等。Zoho Books作为一款功能全面的外贸管理工具，为企业提供了一站式的解决方案，助力企业轻松应对全球化管理难题。</p><p>产品主要功能</p><ol><li>多语言多币种支持<br/>Zoho Books支持22种语言界面和180种货币自动转换。这意味着企业无论在哪个国家开展业务，都可以使用当地语言和货币进行交易，无需担心语言和货币转换问题。例如，一家中国企业在与沙特阿拉伯地区的客户进行交易时，可以轻松生成当地电子发票，并转换为人民币进行记账，大大简化了跨境交易的流程，方便与国内外客户对账。</li><li>国际合规性保障，降低税务风险<br/>Zoho Books提供了15个特色地区版本，可以生成符合多国标准的财务报表。例如，一家德国的跨境电商企业，在使用Zoho Books后，系统会根据德国的税务政策自动计算增值税，并生成符合要求的税务申报报表，避免因税务申报错误而面临的风险。</li><li>强大的进销存管理功能，优化供应链协同<br/>Zoho Books提供从采购、销售到出库的全流程管理，帮助企业优化供应链管理。企业可以在系统中创建采购订单，详细记录供应商信息、采购商品的种类、数量、价格等，并实时跟踪采购订单的状态。在销售方面，企业可以生成专业的销售报价单、销售订单，并开具付款通知单，同时跟踪客户的付款情况，提高企业的资金回笼速度。此外，Zoho Books还支持多仓库库存管理，实时监控库存状态，避免库存积压或短缺。</li><li>数据安全与隐私保护，保障企业信息安全<br/>Zoho Books采用多重加密技术，保障企业数据在传输和存储过程中的安全性。同时，系统提供精细的用户权限管理，企业可以根据员工的职责和工作需要，为不同的员工分配不同的操作权限。例如，财务人员只能查看和操作财务相关的数据，销售人员只能查看和管理客户及销售数据。这样，即使企业内部人员也无法随意访问和篡改其他部门的数据，有效保护了企业的数据安全和隐私。</li><li>灵活的集成与扩展，满足个性化需求<br/>Zoho Books具有高度的灵活性和可扩展性，能够与Zoho CRM、Inventory等20+应用深度集成，支持API自定义开发，满足企业的个性化需求。例如，企业可以将Zoho Books与电商平台如亚马逊、eBay等无缝集成，实现订单的自动同步和处理，提高运营效率。此外，Zoho Books还支持与其他第三方应用的集成，如支付网关PayPal、Stripe等，进一步拓展企业的业务范围。</li><li>实时数据分析与商业智能，辅助科学决策<br/>Zoho Books整合各部门数据，生成可视化报表，如销售趋势、成本分析等，为企业战略决策提供实时支持。企业可以通过这些报表清晰地了解业务状况，及时发现问题并调整策略，从而在激烈的市场竞争中占据优势。</li><li>易用性强，快速上手<br/>Zoho Books的界面设计简洁直观，操作方便，无需专业的IT技能即可上手。企业员工可以通过简单的培训，快速掌握软件的使用方法，提高工作效率。此外，Zoho Books还提供了丰富的帮助文档和在线支持，帮助企业解决使用过程中遇到的问题。</li><li>高性价比，适合不同规模企业<br/>Zoho Books提供从免费版到旗舰版6种订阅方案，年费最低0元，最高仅16,800元，无需硬件投入，云端即开即用。无论是小微企业、跨境电商还是中大型企业，都可以根据自身需求选择合适的版本，实现高效管理。</li></ol><p>结语<br/>贸易风浪不会停，但工具可以换。把 Excel 和邮件升级为 Zoho Books，用 22 种语言、180 种货币、15 国税表把全球订单装进同一个仪表盘，实时算清利润、库存与合规风险——2025，让技术替你扛住不确定性，把精力留给谈客户、抢市场。</p>]]></description></item><item>    <title><![CDATA[多人协作云盘有什么用？秒懂 遭老罪的程序]]></title>    <link>https://segmentfault.com/a/1190000047439039</link>    <guid>https://segmentfault.com/a/1190000047439039</guid>    <pubDate>2025-11-30 19:02:14</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>文件传来传去、版本混乱、同事出差就“断档”？在远程办公 + 敏捷协作成为标配的今天，一套靠谱的多人共享云盘才是团队的“中枢神经”。下文 7 大功能 + 4 大场景拆解，教你用 Zoho 网盘把分散的资料变成“一键同步、权限分明、实时协作”的数字资料室，让效率立刻提速。<br/><img width="658" height="350" referrerpolicy="no-referrer" src="/img/bVdnddW" alt="" title=""/><br/>一、什么是多人共享云盘？<br/>多人共享云盘允许多人在线访问、编辑和更新存储在云端的文件。它解决了传统文件管理中因设备受限、数据分散等问题带来的困扰。</p><p>相比于作为个人存储工具的传统云盘，多人共享云盘的设计初衷更像是“数字化的文件资料室”，主要致力于满足团队和跨部门协作的环境需求。以下是两者的主要区别：</p><p>二、多人共享云盘的核心功能</p><ol><li>文件存储与管理<br/>多人共享云盘提供了一个安全、直观、易管理的中央存储空间，用于集中存放所有团队成员需要的文件或资料。从权责明确的文件夹层级管理，到容量几乎无限的云端扩展，它彻底摆脱了传统本地存储常见的容量不足和数据丢失的风险。</li></ol><p>更重要的是，文件存储环境统一化后，团队沟通成本显著降低。以往那种“这个文件在某某人的电脑里”的情况不再出现，因为所有相关文件都能方便地存取，这就是现代化团队协作的基础。</p><ol start="2"><li>文件实时同步<br/>在多人协作中，最令人头疼的事情之一就是文件版本冲突。每个人编辑一个文件的不同部分，却因不能实时同步而带来混乱。而多人共享云盘正式解决了这一难题。</li></ol><p>通过实时同步技术，文件更新可以即刻传递给所有相关成员，无论相隔多远，他们所看到的永远都是最新版本。更值得一提的是，优秀的云盘还提供文件历史版本功能，当某次修改出现问题时，可以随时回滚到之前的状态，完美避免低效的重复劳动。</p><ol start="3"><li>文件共享与权限控制<br/>一个优秀的多人共享云盘，绝不仅仅是简单的“存盘工具”，它还能通过精准的团队权限管理，保障文件共享的安全性和灵活性：</li></ol><p>支持多种共享方式：生成共享链接、直接邀请团队成员或内部/外部协作方加入文件夹。<br/>权限配置清晰：是否允许下载？能否编辑？或者只限于查看权限？这些都能轻松设置。<br/>这种自由又安全的共享机制，不仅加速了团队源文件的流转，同时也极大地避免了因误操作或无意泄露而带来的风险。</p><ol start="4"><li>协作与实时编辑<br/>多人共享云盘集成了协作所需的在线工具与沟通功能。例如，团队中的设计稿件可以直接通过云盘实现多人员的在线批注与修改；文档可以由团队实时编辑，完成后无需再反复通过邮件发送版本。这种无缝的协作体验，不但提升了工作效率，也增强了团队默契。</li></ol><p>此外，通知提醒功能更是增添了一层协作便利。无论是文件有更新、评论的通知，还是协作任务的总结提醒，都能有效保障信息不会因为某位团队成员稍有疏忽而掉链子。</p><ol start="5"><li>数据安全和备份<br/>无论是为数量庞大的消费者，还是运营着敏感资料的企业，多人共享云盘都必须把数据安全放在首位。顶尖的云盘利用了跨节点存储、数据加密技术以及权限审计功能，给予用户全面的安全保障：</li></ol><p>即使本地设备损坏，重要文件也能通过云端备份复原。<br/>严格的文件加密保证隐私——即使黑客入侵，未经授权的用户也无法解读文件内容。<br/>专业的定期备份服务减少因误删或损坏而产生的损失风险。</p><ol start="6"><li>跨设备与多平台支持<br/>现代工作场景愈发多样化，而多人共享云盘的最大优势之一，就是“无缝跨平台”。从 PC 到手机，再到平板，每种设备上的数据都能轻松同步读取，实现团队文档管理。此外，它支持多种格式的文件直接在线预览，省去了安装繁琐软件的麻烦。</li><li>文件版本控制<br/>设计方案反复调整？文档协作频繁修改？无需担心邮件又点错附件，或者一不小心覆盖了旧版本。多人共享云盘提供了详尽的版本记录与单独修改追踪功能。当你需要回滚到任何历史版本，只需轻轻一键。</li></ol><p>三、多功能的多人共享云盘有哪些应用场景？<br/>在熟悉了产品的核心功能后，我们可以具体探讨它在实际工作场景中的所发挥的作用：</p><ol><li>提升团队协作效率<br/>不论是初创团队，还是大型企业，团队协作效率一直是关键指标。共享云盘通过文件集中管理和在线协作功能，让团队能快速获取资料、节省重复操作时间，同时避免沟通过程中的数据丢失或重复。</li><li>适应远程和跨地域协作<br/>随着远程办公的普及，多人共享云盘几乎成为了远程协作的标配。无论团队成员身处异国他乡，抑或极端天气无法回到办公室，只要能接入互联网，工作就可以继续开展。</li><li>项目/任务管理辅助<br/>共享云盘还充当了项目管理的得力助手：所有项目资料集中存放于项目专属文件夹，团队成员一目了然。不但便于梳理和归档，远程同步和权限管理也让团队能高效完成所有进度关键点。</li><li>降低 IT 维护成本<br/>传统文件服务器的运营包括高昂的硬件成本和维护支出。而共享云盘的云端存储模式，让企业只需为实际需求支付费用，同时不必担忧设备损坏或数据丢失的问题。</li></ol><p>四、如何选择合适的多人共享云盘？<br/>团队需求匹配：优先选择能满足协作需求的功能，比如文件实时同步和多角色权限控制。<br/>性价比：在性价比上下功夫，根据预算谨慎选择价格计划、存储空间和附加功能。<br/>数据安全性：确认提供服务的厂商符合行业安全规范（如 GDPR 等），查看其技术中的加密与备份能力。<br/>兼容性：确保工具可以跨设备、跨操作系统无缝运行，避免额外增加工作阻碍。<br/>五、总结：让协作更简单、更高效<br/>协作时代，选错工具就是最大的成本。Zoho 网盘用无限扩容、银行级加密、在线实时编辑和跨平台秒同步，把“文件孤岛”变成“团队大脑”。现在注册，免费体验 30 天——把重复沟通、版本冲突、数据泄露统统留在昨天，让团队从今天开始“一盘”搞定所有协作。</p>]]></description></item><item>    <title><![CDATA[电子邮件营销属于什么模式？一文看懂EDM]]></title>    <link>https://segmentfault.com/a/1190000047439044</link>    <guid>https://segmentfault.com/a/1190000047439044</guid>    <pubDate>2025-11-30 19:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>还在把“邮件群发”当短信轰炸？真正的电子邮件营销，是一场数据驱动的“一对一对话”——谁感兴趣、谁点过哪些商品、谁住在哪个时区，统统决定下一秒要不要把邮件送进 TA 的收件箱。本文用 Zoho Campaigns 实操拆解：从名单细分、行为触发到 A/B 测试，一步步把 EDM 做成可量化、可复利增长的自动化营销模式。<br/><img width="512" height="340" referrerpolicy="no-referrer" src="/img/bVdndd1" alt="" title=""/><br/>电子邮件营销的基本定义<br/>电子邮件营销是一种通过电子邮件与目标受众进行沟通和推广产品或服务的数字营销策略。这个过程通常包括创建邮件列表，撰写引人入胜的内容，以及针对不同受众进行个性化的邮件推送。其主要目的是通过多方面的接触和互动，增强品牌知名度、推动销售增长，并提高客户忠诚度。</p><p>Zoho Campaigns 提供了强大的工具来帮助企业轻松创建和管理邮件列表，并通过自动化功能实现个性化的邮件推送。</p><p>电子邮件营销的模式特征<br/>双向互动模式<br/>电子邮件营销不仅是信息的单方面传递，更是企业与消费者之间的双向沟通。当企业发送促销内容、新闻通讯或调查问卷时，用户可以通过回复邮件、点击链接等方式给予反馈。这种双向互动使得企业能够深入了解客户需求，针对性地调整营销策略。</p><p>精准细分与个性化营销<br/>相较于传统广告的大众传播方式，电子邮件营销具备精准细分的能力。企业可以根据用户的地理位置、消费偏好、购买历史等信息来细分其邮件列表，并定制个性化的邮件内容。这种个性化的接触方式大大提高了营销信息的相关性和有效性。</p><p>使用 Zoho Campaigns，企业可以轻松地根据用户数据进行细分，并创建高度个性化的邮件内容，从而提高营销活动的效果。</p><p>以数据驱动为核心<br/>电子邮件营销的有效运营离不开对数据的深入分析。通过 A/B 测试、用户行为追踪、开信率和点击率分析，企业能够不断优化邮件内容和发送策略，从而更好地满足客户需求，实现销售转化。</p><p>电子邮件营销的实施步骤<br/>实施电子邮件营销策略通常包括几个关键步骤，从创建邮件列表到分析评估整个过程都需要精细化的操作。</p><p>创建有效的邮件列表<br/>首先，企业需要构建一个合规的电子邮件列表，确保潜在客户的自愿参与。以下是构建邮件列表的一些方法：</p><p>网站注册表单：在官网提供一个简单的注册表单，让用户自愿订阅。<br/>赠送免费资源：提供电子书、白皮书或折扣码作为订阅奖励，吸引用户注册。<br/>线上线下的活动注册：通过活动吸引用户参与并建立联系，这也是积累邮件列表的有效方式。<br/>精心设计邮件内容<br/>一封成功的营销邮件需要具备吸引力和实用性：</p><p>主题行设计：主题行是用户决定开启邮件的首要因素，需简明扼要且富有吸引力。<br/>内容编排：内容要简洁明了，引导用户逐步了解企业信息和优惠内容。<br/>明确的行动召唤：在邮件中增设明确的行动指示（CTA），引导用户完成如注册、购买等行为。<br/>个性化内容推送<br/>邮件内容的个性化设计是电子邮件营销成功的关键。根据用户购买习惯、地理位置甚至是设备使用习惯进行个性化定制，确保邮件对每一位用户都具有高度相关性。</p><p>Zoho Campaigns 的自动化功能可以帮助企业根据用户行为自动发送个性化邮件，提高用户参与度和转化率。</p><p>分析与优化<br/>通过数据的收集和分析，持续优化电子邮件营销策略，以提高成效。关键的分析数据包括开信率、点击率、转化率和退订率等。</p><p>什么将电子邮件营销提升至一个全新高度？<br/>自动化技术<br/>现代电子邮件营销软件已经集成了强大的自动化功能，使得邮件发送过程更加高效和精确。通过制定自动化工作流程，企业可以设置在特定事件触发时自动发送邮件，例如用户注册之后的欢迎邮件、购物车遗弃后的提醒邮件等。</p><p>移动优化<br/>随着移动设备的普及，越来越多人通过手机查收电子邮件。优化邮件内容以适应各种屏幕尺寸和操作系统显得尤为重要，这不仅提升了用户体验，也显著增加了邮件的互动率。</p><p>互动和动态内容<br/>引入互动和动态元素，如视频、GIF 动画或可视化图表，能够增强邮件内容的多样性和趣味性，使得用户参与感更强。</p><p>电子邮件营销的挑战与未来<br/>尽管电子邮件营销优势明显，但其面临的挑战同样不容忽视。比如，垃圾邮件过滤的严格审查，迫使企业不断提高邮件质量；保护用户隐私的相关法律法规对收集和使用用户信息提出了更高的要求。</p><p>面对这些挑战，未来的电子邮件营销将趋向于更智能化和个性化。通过人工智能和大数据技术的支持，企业能够更深入地理解用户行为，并在合适的时间通过合适的渠道传递准确的信息。</p><p>总之，电子邮件营销已不仅仅是单纯的推广工具，而是融合了技术创新、客户关系管理和数据分析的综合平台。对于企业来说，合理有效地利用电子邮件营销，不仅能获得即时收益，更是建立长期客户关系、持续发展的重要战略。</p><p>常见问题解答（FAQ）<br/>FAQ 1: 什么是电子邮件营销，它如何帮助企业？<br/>回答：电子邮件营销是一种通过电子邮件与目标受众进行沟通和推广产品或服务的数字营销策略。它帮助企业通过创建和管理邮件列表、撰写引人入胜的内容，以及个性化的邮件推送来增强品牌知名度、推动销售增长，并提高客户忠诚度。工具如 Zoho Campaigns 可以简化这一过程，通过自动化和数据分析提高营销活动的效率和效果。</p><p>FAQ 2: 如何利用 Zoho Campaigns 实现个性化的电子邮件营销？<br/>回答：Zoho Campaigns 提供了强大的个性化功能，企业可以根据用户的地理位置、消费偏好和购买历史等信息来细分邮件列表。通过自动化功能，企业能够根据用户行为自动发送个性化邮件，例如欢迎邮件或购物车遗弃提醒邮件。这种个性化接触方式提高了邮件的相关性和用户参与度，从而提升转化率。</p><p>FAQ 3: 电子邮件营销面临哪些挑战，未来的发展趋势是什么？<br/>回答：电子邮件营销面临的主要挑战包括垃圾邮件过滤的严格审查和用户隐私保护的法律法规要求。为了应对这些挑战，未来的电子邮件营销将趋向于更智能化和个性化。通过人工智能和大数据技术，企业可以更深入地理解用户行为，并在合适的时间通过合适的渠道传递准确的信息。这将帮助企业提高邮件的质量和用户体验，确保营销活动的成功。</p><p>模式选错，再多邮件也进垃圾箱；工具选对，每封邮件都是 24 小时销售员。Zoho Campaigns 把“双向互动 + 数据细分 + 自动化”做成一键模板：名单合规收集、内容动态拼接、发送时机 AI 预测，让打开率、点击率、转化率可视化飙高。现在注册免费版，立刻把电子邮件营销升级为“会自我进化的增长模式”，下一封爆款邮件，由你亲手发出。</p>]]></description></item><item>    <title><![CDATA[GreatSQL优化技巧全解析：从硬件配]]></title>    <link>https://segmentfault.com/a/1190000047438891</link>    <guid>https://segmentfault.com/a/1190000047438891</guid>    <pubDate>2025-11-30 18:03:46</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在数据库性能优化领域，GreatSQL凭借其强大的优化器与MGR（Group Replication）集群能力，成为企业级应用的首选。本文将从硬件配置、操作系统调优、MGR集群优化、查询优化器特性四大维度，深度解析GreatSQL的性能提升策略，助力开发者突破性能瓶颈。</p><p>一、硬件配置：奠定性能基石</p><ol><li>CPU与内存：核心性能驱动<br/>CPU选择：优先采用高主频多核处理器（如Xeon Platinum系列），主频建议≥3.5GHz，核数根据业务负载动态调整。例如，MGR集群节点建议配置16核以上CPU，以支撑高并发事务处理。<br/>内存扩展：内存容量需覆盖InnoDB缓冲池（innodb_buffer_pool_size）需求，建议设置为物理内存的70%-80%。例如，64GB内存服务器可分配48GB给缓冲池，减少磁盘I/O压力。<br/>NUMA架构优化：X86架构建议关闭NUMA（numa_interleave=ON），避免内存访问延迟；ARM架构则可开启NUMA以提升多实例性能。</li><li>存储设备：I/O性能关键<br/>NVMe SSD部署：使用NVMe协议的SSD替代传统SATA SSD，将随机读写IOPS提升至百万级。例如，将数据库日志文件（binlog、redo log）存放于NVMe盘，可显著降低事务提交延迟。<br/>文件系统选择：XFS文件系统在高并发I/O场景下表现优异，其延迟分配（Delayed Allocation）机制可减少磁盘碎片，提升写入性能。</li><li>网络配置：低延迟保障<br/>网络带宽升级：MGR集群节点间建议采用万兆网络或InfiniBand，降低数据同步延迟。例如，在跨机房部署时，万兆网络可将主从复制延迟从毫秒级压缩至微秒级。<br/>MTU值调优：将网络MTU值设置为9000（Jumbo Frame），减少数据包分片，提升大事务传输效率。</li></ol><p>二、操作系统调优：释放硬件潜能</p><ol><li>内核参数优化<br/>关闭SWAP：通过swapoff -a命令永久禁用交换分区，避免内存不足时触发磁盘交换导致性能骤降。<br/>禁用透明大页（THP）：在/etc/sysctl.conf中添加vm.swappiness=0和vm.overcommit_memory=1，并执行echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled，防止OLTP型数据库因内存碎片化引发延迟。<br/>I/O调度器调整：将数据库分区的I/O调度器设置为noop或deadline，减少不必要的I/O合并，提升响应速度。</li><li>资源限制解除<br/>文件描述符限制：在/etc/security/limits.conf中设置<em> soft nofile 65535和</em> hard nofile 65535，避免因文件描述符不足导致连接失败。<br/>线程数限制：调整kernel.threads-max参数（如设置为200000），支持高并发查询场景。</li></ol><p>三、MGR集群优化：高可用与性能兼得</p><ol><li>流控模式选择<br/>关闭流控提升吞吐：在事务并发量适中的场景下，将group_replication_flow_control_mode设置为DISABLED，避免流控算法引入的性能抖动。例如，某金融客户在关闭流控后，集群TPS提升30%。<br/>动态阈值调整：若需开启流控，可将默认阈值（如group_replication_flow_control_member_quota_percent）提高至80%，平衡性能与稳定性。</li><li>从库回放并发度优化<br/>并行复制线程数：设置slave_parallel_workers为逻辑CPU核数的2倍（如32核服务器配置64个线程），加速从库数据回放。<br/>并行复制模式选择：采用LOGICAL_CLOCK模式（slave_parallel_type=LOGICAL_CLOCK），基于事务提交顺序分配并行任务，减少锁冲突。</li><li>大事务处理优化<br/>事务拆分：将单个大事务拆分为多个小事务，避免MGR队列阻塞。例如，某电商客户将每日全量数据同步拆分为每小时增量同步，集群稳定性显著提升。<br/>队列垃圾回收优化：通过调整group_replication_garbage_collection_interval参数（如设置为60秒），加速无用事务清理，释放内存资源。</li></ol><p>四、查询优化器特性：智能提升查询效率</p><ol><li>谓词下推（Predicate Pushdown）<br/>手动优化场景：当优化器未能自动下推复杂子查询条件时，可通过重写SQL手动实现。例如：<br/>sql<br/>-- 原始SQL（可能未优化）<br/>SELECT o.order_id, o.amount <br/>FROM orders o <br/>JOIN customers c ON o.customer_id = c.customer_id <br/>WHERE c.city = '上海' AND o.order_date &gt;= '2023-01-01';</li></ol><p>-- 手动优化后（将城市过滤下推至子查询）<br/>SELECT o.order_id, o.amount <br/>FROM orders o <br/>JOIN (<br/>  SELECT customer_id, customer_name <br/>  FROM customers <br/>  WHERE city = '上海'<br/>) c ON o.customer_id = c.customer_id <br/>WHERE o.order_date &gt;= '2023-01-01';<br/>此优化将数据量从全量客户表缩减至上海客户子集，连接操作效率提升50%。</p><ol start="2"><li>索引合并（Index Merge）<br/>多索引高效利用：当WHERE条件包含多个独立索引列时，优化器自动合并索引扫描结果。例如：<br/>sql<br/>-- 表结构<br/>CREATE TABLE t2 (<br/>  cc1 INT, cc2 INT, cc3 INT,<br/>  INDEX idx1(cc1), INDEX idx2(cc2), INDEX idx3(cc3)<br/>);</li></ol><p>-- 查询利用索引合并<br/>EXPLAIN SELECT * FROM t2 WHERE cc2=3 AND cc1=1 AND cc3=1;<br/>执行计划显示Using intersect(idx1,idx2)，表明优化器通过索引交集合并定位数据，避免全表扫描。</p><ol start="3"><li>半连接（Semi-Join）<br/>子查询高效执行：对于IN或EXISTS子查询，优化器自动选择最优半连接策略。例如：<br/>sql<br/>-- 子查询主键上拉示例<br/>SELECT * FROM t1 <br/>WHERE c2 IN (SELECT id FROM t2 WHERE t2.c1='b');<br/>优化器将子查询中的t2表上拉至外层，通过内连接（INNER JOIN）执行，消除重复值影响，查询速度提升3倍。</li><li>并行查询（Parallel Query）<br/>多核并行处理：通过loose-parallel_default_dop=8设置默认并行度，启用loose-force_parallel_execute=ON强制并行执行。例如，某分析查询在16核服务器上并行度设置为8后，执行时间从12秒缩短至2秒。</li></ol><p>五、实战案例：某电商平台的性能飞跃<br/>某电商平台在采用GreatSQL后，通过以下优化组合实现性能突破：</p><p>硬件升级：将数据库服务器从32核128GB内存升级至64核256GB内存，并采用NVMe SSD存储。<br/>MGR集群优化：关闭流控模式，设置并行复制线程数为128，大事务拆分为每小时增量同步。<br/>查询优化：对高频查询启用索引合并与并行查询，复杂报表查询速度提升10倍。<br/>监控告警：通过performance_schema监控慢查询，结合pt-query-digest分析瓶颈，持续迭代优化。<br/>优化后，平台日均订单处理量从500万笔提升至1200万笔，峰值TPS突破8万，且系统稳定性显著增强。</p><p>结语：优化永无止境<br/>GreatSQL的性能优化是一个系统工程，需从硬件、操作系统、集群配置、查询逻辑等多维度协同调优。开发者应结合业务场景，灵活运用本文所述技巧，并通过持续监控与压测验证优化效果。未来，随着AI与数据库技术的深度融合，GreatSQL将进一步释放性能潜力，为企业数字化转型提供更强支撑。</p>]]></description></item><item>    <title><![CDATA[征程 6 | linear 高精度输出配]]></title>    <link>https://segmentfault.com/a/1190000047438901</link>    <guid>https://segmentfault.com/a/1190000047438901</guid>    <pubDate>2025-11-30 18:02:53</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>1. 常规情况</h2><p>基础知识：</p><ol><li>考虑到模型输出位置量化损失对模型精度的影响较大，工具链推荐模型以 linear/conv 结尾，此时支持高精度 int32 输出（在 quantized.onnx 中，转定点为 int32，在前面 calib+qat 阶段都是 float32），这几乎可以做到无损。</li><li>征程 6 工具链量化 setter 模板支持自动设置高精度输出，前提是 conv 输出直接 接 dequant，不作为其他 node 的输入。</li></ol><p>输出位置结构示意图：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438903" alt="" title=""/></p><p>全流程代码如下：</p><pre><code class="Plain">import torch
from horizon_plugin_pytorch import set_march, March
set_march(March.NASH_M)
from horizon_plugin_pytorch.quantization import prepare, set_fake_quantize, FakeQuantState
from horizon_plugin_pytorch.quantization import QuantStub
from horizon_plugin_pytorch.quantization.hbdk4 import export
from horizon_plugin_pytorch.quantization.qconfig_template import (
    calibration_8bit_weight_16bit_act_qconfig_setter,
    qat_8bit_weight_16bit_fixed_act_qconfig_setter, 
    default_calibration_qconfig_setter,
    ModuleNameQconfigSetter
) 

from horizon_plugin_pytorch.quantization.qconfig import get_qconfig, MSEObserver, MinMaxObserver
from horizon_plugin_pytorch.dtype import qint8, qint16
from torch.quantization import DeQuantStub
import torch.nn as nn
from horizon_plugin_pytorch.quantization import hbdk4 as hb4
from hbdk4.compiler import convert, save, hbm_perf, visualize, compile

import torch
import torch.nn as nn

# 定义网络结构
class SmallModel(nn.Module):
    def __init__(self):
        super(SmallModel, self).__init__()
        # 第一个 Linear: 输入 [2, 100, 256] -&gt; 输出 [2, 100, 256]
        self.linear1 = nn.Linear(256, 256)
        self.layernorm = nn.LayerNorm(256)  # 对最后一维进行归一化
        self.relu = nn.ReLU()
        # 第二个 Linear: 输入 [2, 100, 256] -&gt; 输出 [2, 100, 60]
        self.linear2 = nn.Linear(256, 60)
        # 第三个 Linear: 输入 [2, 100, 60] -&gt; 输出 [2, 100, 60]
        self.linear3 = nn.Linear(60, 60)
        self.quant = QuantStub()
        self.dequant = DeQuantStub()

    def forward(self, x):
        x = self.quant(x)
        # 第一个 Linear
        x = self.linear1(x)  # [2, 100, 256]
        x = self.layernorm(x)  # [2, 100, 256]
        x = self.relu(x)  # [2, 100, 256]
        # 第二个 Linear
        y = self.linear2(x)  # [2, 100, 60]
        # 第三个 Linear
        z = self.linear3(y)
        z = self.dequant(z)
        return z

# 设置随机种子，保证每次生成的数据相同
torch.manual_seed(42)
example_input = torch.randn(2, 100, 256)
model = SmallModel()

# 前向传播
output_x = model(example_input)
print("输入形状:", example_input.shape)
print("输出形状:", output_x.shape)

# A global march indicating the target hardware version must be setted before prepare qat.
set_march(March.NASH_M)

calib_model = prepare(model.eval(), example_input, 
                      qconfig_setter=(
                          default_calibration_qconfig_setter,
                          ),
                      )

calib_model.eval()
set_fake_quantize(calib_model, FakeQuantState.CALIBRATION)
calib_model(example_input)

calib_model.eval()                            
set_fake_quantize(calib_model, FakeQuantState.VALIDATION)
calib_out_x = calib_model(example_input)
print("calib输出shape:", calib_out_x.shape)

qat_bc = export(calib_model, example_input)
# save(qat_bc, "qat.bc")
# visualize(qat_bc, "qat.onnx")
hb_quantized_model = convert(qat_bc, March.NASH_M)
# save(hb_quantized_model,"quantized.bc")
visualize(hb_quantized_model, "quantized_single.onnx")</code></pre><p>查看 quantized.onnx，可以看到最后一个 conv 确实是 int32 高精度输出</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438904" alt="" title="" loading="lazy"/></p><h2>2. 输出又输入</h2><p>如果 conv1，既作为模型输出，又作为后续 conv2 的输入，此时应该怎么办？</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438905" alt="" title="" loading="lazy"/></p><p>关键代码如下：</p><pre><code class="Plain">def forward(self, x):
        x = self.quant(x)
        # 第一个 Linear
        x = self.linear1(x)  # [2, 100, 256]
        x = self.layernorm(x)  # [2, 100, 256]
        x = self.relu(x)  # [2, 100, 256]
        # 第二个 Linear
        y = self.linear2(x)  # [2, 100, 60]
        y_out = self.dequant(y)
        y = self.quant_out(y_out)
        # y = self.quant_out(y)

        # 第三个 Linear
        z = self.linear3(y)
        z = self.dequant(z)
        return x, y_out</code></pre><p>注意，y\_out = self.dequant（y）是必须要添加的，否则无法实现该效果。</p><p>全流程代码如下：</p><pre><code class="Plain">import torch
from horizon_plugin_pytorch import set_march, March
set_march(March.NASH_M)
from horizon_plugin_pytorch.quantization import prepare, set_fake_quantize, FakeQuantState
from horizon_plugin_pytorch.quantization import QuantStub
from horizon_plugin_pytorch.quantization.hbdk4 import export
from horizon_plugin_pytorch.quantization.qconfig_template import (
    calibration_8bit_weight_16bit_act_qconfig_setter,
    qat_8bit_weight_16bit_fixed_act_qconfig_setter, 
    default_calibration_qconfig_setter,
    ModuleNameQconfigSetter
) 

from horizon_plugin_pytorch.quantization.qconfig import get_qconfig, MSEObserver, MinMaxObserver
from horizon_plugin_pytorch.dtype import qint8, qint16
from torch.quantization import DeQuantStub
import torch.nn as nn
from horizon_plugin_pytorch.quantization import hbdk4 as hb4
from hbdk4.compiler import convert, save, hbm_perf, visualize, compile

import torch
import torch.nn as nn

# 定义网络结构
class SmallModel(nn.Module):
    def __init__(self):
        super(SmallModel, self).__init__()
        # 第一个 Linear: 输入 [2, 100, 256] -&gt; 输出 [2, 100, 256]
        self.linear1 = nn.Linear(256, 256)
        self.layernorm = nn.LayerNorm(256)  # 对最后一维进行归一化
        self.relu = nn.ReLU()
        # 第二个 Linear: 输入 [2, 100, 256] -&gt; 输出 [2, 100, 60]
        self.linear2 = nn.Linear(256, 60)
        # 第三个 Linear: 输入 [2, 100, 60] -&gt; 输出 [2, 100, 60]
        self.linear3 = nn.Linear(60, 60)
        self.quant = QuantStub()
        self.quant_out = QuantStub()
        self.dequant = DeQuantStub()

    def forward(self, x):
        x = self.quant(x)
        # 第一个 Linear
        x = self.linear1(x)  # [2, 100, 256]
        x = self.layernorm(x)  # [2, 100, 256]
        x = self.relu(x)  # [2, 100, 256]
        # 第二个 Linear
        y = self.linear2(x)  # [2, 100, 60]
        y_out = self.dequant(y)
        y = self.quant_out(y_out)

        # 第三个 Linear
        z = self.linear3(y)
        z = self.dequant(z)
        return z, y_out

# 设置随机种子，保证每次生成的数据相同
torch.manual_seed(42)
example_input = torch.randn(2, 100, 256)
model = SmallModel()

# 前向传播
output_x, output_y = model(example_input)
print("输入形状:", example_input.shape)
print("输出形状:", output_x.shape, output_y.shape)

# A global march indicating the target hardware version must be setted before prepare qat.
set_march(March.NASH_M)

calib_model = prepare(model.eval(), example_input, 
                      qconfig_setter=(
                          default_calibration_qconfig_setter,
                          ),
                      )

calib_model.eval()
set_fake_quantize(calib_model, FakeQuantState.CALIBRATION)
calib_model(example_input)

calib_model.eval()                            
set_fake_quantize(calib_model, FakeQuantState.VALIDATION)
calib_out_x, calib_out_y= calib_model(example_input)
print("calib输出shape:", calib_out_x.shape)

qat_bc = export(calib_model, example_input)
# save(qat_bc, "qat.bc")
# visualize(qat_bc, "qat.onnx")
hb_quantized_model = convert(qat_bc, March.NASH_M)
# save(hb_quantized_model,"quantized.bc")
visualize(hb_quantized_model, "quantized.onnx")</code></pre><p>查看 quantized.onnx，linear2 符合预期，确实是 int32 高精度输出。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438906" alt="" title="" loading="lazy"/></p><p>新加入的 dequant 与 quant 会变成 rescale</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438907" alt="" title="" loading="lazy"/></p><p>以上是征程 6EM 的默认做法，如果使用的是征程 6PH，conv like 算子输出直接就是 float32，在既作为输出，又作为下一阶段输入时，会存在 vpu 的 quantize（float32-&gt;int16/int8），如下图所示</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438908" alt="" title="" loading="lazy"/></p><p>如果想依旧沿用征程 6EM 的方式，可进行如下配置：</p><pre><code class="Plain">qat_bc._integer_conv = True
hb_quantized_model = convert(qat_bc, "nash-h")</code></pre><p>具体选择哪种方式可实测 latency（建议考虑将模型 conv like 算子 c++ 反量化的耗时减少也加进去对比）</p>]]></description></item><item>    <title><![CDATA[【卫星图像识别系统】Python+Ten]]></title>    <link>https://segmentfault.com/a/1190000047438926</link>    <guid>https://segmentfault.com/a/1190000047438926</guid>    <pubDate>2025-11-30 18:02:03</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>一、介绍</h2><p>卫星影像识别系统，基于TensorFlow搭建卷积神经网络算法，通过对7种常见的卫星遥感影像图片数据集（'草地（Grass）', '农田（Field）', '工业区（Industry）', '河流湖泊（RiverLake）', '森林（Forest）', '居民区（Resident）', '停车场（Parking）'）进行训练，最后得到一个识别精度较高的模型，然后搭建Web可视化操作平台。</p><p><strong>前端</strong>: Vue3、Element Plus</p><p><strong>后端</strong>：Django</p><p><strong>算法</strong>：TensorFlow、卷积神经网络算法</p><p><strong>具体功能</strong>：</p><ol><li>系统分为管理员和用户两个角色，登录后根据角色显示其可访问的页面模块。</li><li>登录系统后可发布、查看、编辑文章，创建文章功能中集成了markdown编辑器，可对文章进行编辑。</li><li>在图像识别功能中，用户上传图片后，点击识别，可输出其识别结果和置信度</li><li>基于Echart以柱状图形式输出所有种类对应的置信度分布图。</li><li>在智能问答功能模块中：用户输入问题，后台通过对接Deepseek接口实现智能问答功能。</li><li>管理员可在用户管理模块中，对用户账户进行管理和编辑。</li></ol><p><strong>选题背景与意义</strong>：<br/>随着遥感技术的快速发展，卫星影像数据呈现爆发式增长，如何高效、精准地识别与利用这些数据，已成为资源监测、环境评估和城乡规划等领域的重要课题。传统人工判读方式效率低、主观性强，难以满足大规模应用需求。为此，本项目基于TensorFlow构建卷积神经网络模型，针对草地、农田、工业区、河流湖泊、森林、居民区及停车场等七类典型地物进行识别训练，旨在开发一个具备较高识别精度的自动化分类系统。为进一步提升系统的实用性与交互体验，项目结合Django与Vue3等主流技术，搭建了集用户管理、图像识别、结果可视化及智能问答于一体的Web操作平台。该系统不仅实现了地物类型的智能识别与置信度分析，还通过集成Markdown编辑与DeepSeek问答接口，拓展了知识管理与交互支持功能，为遥感数据的智能化应用提供了便捷、高效的解决方案。</p><h2>二、系统效果图片展示</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438928" alt="图片" title="图片"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047438929" alt="图片" title="图片" loading="lazy"/></p><h2>三、演示视频 and 完整代码 and 安装</h2><p>地址：<a href="https://link.segmentfault.com/?enc=wyUaSD2PvQ6kaogAN80woA%3D%3D.LOXg8rkgKqlioCPmBMNU58Fq5295P9qE6yiO4kSPrS4%3D" rel="nofollow" target="_blank">https://ziwupy.cn/p/6eby8p</a></p><h2>四、卷积神经网络算法介绍</h2><p>ResNet50是由微软研究院提出的深度残差网络（Residual Network）的一个经典模型，其核心创新是“残差学习”思想。在传统的深度卷积神经网络中，简单地堆叠层数会遇到“梯度消失/爆炸”问题，导致网络难以训练，性能甚至下降，这被称为“退化问题”。</p><p>ResNet通过引入“快捷连接”或“跳跃连接”巧妙地解决了这一问题。它不再让多个堆叠的层直接学习一个目标映射H(x)，而是让这些层学习其与输入x之间的残差F(x) = H(x) - x。这样，原始的目标映射就变成了 H(x) = F(x) + x。</p><p>这种“捷径”将输入x直接传递到更深层的输出，实现了恒等映射。这样做有两个主要好处：</p><ol><li><strong>缓解梯度消失</strong>：梯度可以直接通过快捷连接反向传播，使得深层网络的训练变得可行。</li><li><strong>简化学习目标</strong>：让网络学习残差F(x)通常比学习完整的映射H(x)更容易，尤其是在F(x)趋近于0时，该层就近似做了恒等变换，避免了性能退化。</li></ol><p>ResNet50因其包含50个权重层而得名，它通过大量使用这种带有快捷连接的“瓶颈结构”模块，在保持高性能的同时，显著减少了参数量，成为图像识别领域一个里程碑式的模型。</p><p>以下是一个使用TensorFlow Keras中预训练的ResNet50模型进行图像识别的简单示例。</p><pre><code class="python">import tensorflow as tf
from tensorflow.keras.applications.resnet50 import ResNet50, decode_predictions, preprocess_input
import numpy as np
from PIL import Image

# 1. 加载预训练的ResNet50模型（包含在ImageNet上训练得到的权重）
model = ResNet50(weights='imagenet')

# 2. 加载并预处理图像
img_path = 'your_image.jpg' # 替换为你的图片路径
image = Image.open(img_path).convert('RGB') # 确保为RGB格式
image = image.resize((224, 224)) # ResNet50要求输入尺寸为224x224

# 将图像转换为数组并扩展维度以匹配模型输入要求 (batch_size, height, width, channels)
image_array = np.array(image)
image_array = np.expand_dims(image_array, axis=0)

# 对图像进行与训练时相同的预处理
image_array = preprocess_input(image_array)

# 3. 使用模型进行预测
predictions = model.predict(image_array)

# 4. 解码预测结果，得到人类可读的标签和置信度
decoded_predictions = decode_predictions(predictions, top=3)[0] # 显示最可能的3个结果

# 5. 打印结果
print("识别结果：")
for i, (imagenet_id, label, score) in enumerate(decoded_predictions):
    print(f"{i+1}: {label} ({score * 100:.2f}%)")</code></pre><p>这段代码演示了利用预训练ResNet50模型进行图像识别的标准流程。首先，我们直接加载了在ImageNet数据集上预训练好的模型，无需从头训练。然后，将输入图像调整为224x224像素，并进行归一化等预处理。接着，模型对图像进行前向传播推理，输出一个包含1000个ImageNet类别概率的向量。最后，通过<code>decode_predictions</code>函数将概率向量解码为易于理解的对象标签和置信度，并打印出最可能的三个预测结果。这种方法让我们能够快速、高效地将强大的ResNet50模型应用于实际的图像识别任务中。</p>]]></description></item><item>    <title><![CDATA[【民族服饰识别系统】Python+Ten]]></title>    <link>https://segmentfault.com/a/1190000047438935</link>    <guid>https://segmentfault.com/a/1190000047438935</guid>    <pubDate>2025-11-30 18:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>一、介绍</h2><p>民族服饰识别，民族服饰智能识别与分析系统基于TensorFlow框架，采用卷积神经网络（CNN）算法构建而成。系统在收集了回族、汉族、满族、苗族四类典型民族服饰图像数据集的基础上，通过多轮迭代训练，最终生成高精度识别模型，并配合Web可视化平台实现便捷交互。</p><p><strong>前端</strong>: Vue3、Element Plus</p><p><strong>后端</strong>：Django</p><p><strong>算法</strong>：TensorFlow、卷积神经网络算法</p><p><strong>具体功能</strong>：</p><ol><li>系统分为管理员和用户两个角色，登录后根据角色显示其可访问的页面模块。</li><li>登录系统后可发布、查看、编辑文章，创建文章功能中集成了markdown编辑器，可对文章进行编辑。</li><li>在图像识别功能中，用户上传图片后，点击识别，可输出其识别结果和置信度</li><li>基于Echart以柱状图形式输出所有种类对应的置信度分布图。</li><li>在智能问答功能模块中：用户输入问题，后台通过对接Deepseek接口实现智能问答功能。</li><li>管理员可在用户管理模块中，对用户账户进行管理和编辑。</li></ol><p><strong>选题背景与意义</strong>：<br/>随着人工智能技术的快速发展，计算机视觉在文化传承与保护领域的应用日益广泛。民族服饰作为民族文化的重要载体，其识别与分类对于文化研究与数字化保护具有积极意义。传统人工识别方式效率有限，难以适应大规模图像处理需求。基于此背景，本研究旨在开发一套基于深度学习的民族服饰智能识别与分析系统。系统采用TensorFlow框架，基于卷积神经网络（CNN）构建高精度识别模型，实现对回族、汉族、满族、苗族四类典型民族服饰的自动化识别。通过集成Web可视化平台，系统不仅提供图像识别、置信度分析和可视化图表展示等核心功能，还结合内容管理与智能问答模块，构建了集文化识别、知识传播与交互体验于一体的综合平台，为民族文化的数字化保护与推广提供了有效的技术支撑。</p><h2>二、系统效果图片展示</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438937" alt="图片" title="图片"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047438938" alt="图片" title="图片" loading="lazy"/></p><h2>三、演示视频 and 完整代码 and 安装</h2><p>地址：<a href="https://link.segmentfault.com/?enc=Pq9s7g%2BUpI038ZxwufiFwA%3D%3D.1L7AHrCJLzWM%2B86e%2BFZpFTazSD6H3czZWdJRnccTzUE%3D" rel="nofollow" target="_blank">https://ziwupy.cn/p/ekFQTD</a></p><h2>四、卷积神经网络算法介绍</h2><p>卷积神经网络是一种专为处理网格状数据（如图像）而设计的深度学习算法。其核心思想是通过“卷积”操作，自动地从图像中提取由浅到深的特征。</p><p><strong>主要构成层：</strong></p><ol><li><strong>卷积层：</strong> 是CNN的核心。它使用多个可学习的“滤波器”（或称“卷积核”）在输入图像上滑动，通过计算局部区域的点积来提取特征（如边缘、角点、纹理等）。通过堆叠多个卷积层，网络可以学习到从简单到复杂（如物体部件、整体轮廓）的层次化特征。</li><li><strong>池化层：</strong> 通常跟在卷积层之后，用于对特征图进行下采样。它通过取局部区域的最大值或平均值，来减小数据尺寸，降低计算量，同时增强模型对目标位置微小变化的鲁棒性（即“平移不变性”）。</li><li><strong>全连接层：</strong> 在网络的末端，将经过多轮卷积和池化后提取出的高级特征图展平，然后进行综合判断，最终输出每个类别的概率。</li></ol><p>CNN通过这种“局部连接”和“权值共享”（同一个滤波器扫描整张图片）的机制，极大地减少了参数数量，使其能够高效地处理图像，并成为图像识别领域最主流的算法。</p><p>以下是一个使用TensorFlow和Keras API构建一个简单的CNN模型，用于对MNIST手写数字数据集进行分类的示例。</p><pre><code class="python">import tensorflow as tf
from tensorflow.keras import datasets, layers, models

# 1. 加载并预处理数据
(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()
# 将图像数据重塑为 (28, 28, 1) 的形状，并归一化到 [0, 1] 区间
train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255
test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255

# 2. 构建CNN模型
model = models.Sequential([
    # 第一个卷积块：卷积 + 池化
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    layers.MaxPooling2D((2, 2)),
    
    # 第二个卷积块：卷积 + 池化
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    
    # 将特征图展平，输入到全连接层
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    # 输出层，10个神经元对应10个数字类别，使用softmax激活函数输出概率
    layers.Dense(10, activation='softmax')
])

# 3. 编译模型
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# 4. 训练模型
model.fit(train_images, train_labels, epochs=5, 
          validation_data=(test_images, test_labels))

# 5. 评估模型
test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)
print(f'\n测试准确率：{test_acc}')</code></pre><p>以上代码完整展示了使用CNN进行图像识别的流程。首先，数据被加载并预处理成适合网络的格式。接着，我们构建了一个顺序模型，它包含两个卷积-池化层组合，用于特征提取，之后是展平操作和全连接层进行分类。模型使用<code>adam</code>优化器和交叉熵损失函数进行编译。最后，通过<code>fit</code>方法在训练数据上进行5轮训练，并在测试集上评估最终性能。这个简单的模型能很快地在MNIST数据集上达到很高的准确率，清晰地演示了CNN在图像识别任务中的强大能力和基本工作流程。</p>]]></description></item><item>    <title><![CDATA[Omnissa Dynamic Envi]]></title>    <link>https://segmentfault.com/a/1190000047438859</link>    <guid>https://segmentfault.com/a/1190000047438859</guid>    <pubDate>2025-11-30 17:01:55</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>Omnissa Dynamic Environment Manager 2509 - 个性化动态 Windows 桌面环境管理</p><p>Simplify management of user profiles, environment settings, and policies across desktops and apps.</p><p>请访问原文链接：<a href="https://link.segmentfault.com/?enc=Om3KNyDDw2aEu7hPvHPa3Q%3D%3D.R%2BomsM3Ev3LmYToSG6jE%2FqriUIujx50XKaWrjuByxbAzopjb3%2BUov1otrV5lXbFVzKGCtli%2FElvd6DR3OKMqSw%3D%3D" rel="nofollow" target="_blank">https://sysin.org/blog/omnissa-dynamic-environment-manager/</a> 查看最新版。原创作品，转载请保留出处。</p><p>作者主页：<a href="https://link.segmentfault.com/?enc=BZe8VTrld6vnXWDrzR6Zhg%3D%3D.DbZXXgTShsNv%2BpwDLo%2F5Zubb%2BzyExFssDL5WGGGFfU4%3D" rel="nofollow" target="_blank">sysin.org</a></p><hr/><p><img referrerpolicy="no-referrer" src="/img/remote/1460000046037272" alt="Omnissa Horizon 架构图" title="Omnissa Horizon 架构图"/></p><p>Omnissa Dynamic Environment Manager</p><p>简化跨桌面和应用程序的用户配置文件、环境设置和策略的管理。</p><h2>产品简介</h2><p>Dynamic Environment Manager 为最终用户提供个性化的动态 Windows 桌面。通过 Dynamic  Environment Manager，您可以根据用户的角色、设备和位置提供对 IT  资源的访问来自定义桌面。通过这种方式，您可以创建适应用户特定需求的桌面。</p><p>Omnissa Dynamic Environment Manager 标准版和企业版</p><p>Omnissa Dynamic Environment Manager 提供标准版和企业版。</p><p><strong>标准版</strong> 专为寻求基本用户环境管理和应用程序控制的组织而设计。标准版可帮助 Omnissa Horizon® 标准版和 Omnissa Horizon® 高级版客户进行用户配置文件管理。</p><p><strong>企业版</strong> 专为需要高级管理、详细的应用程序分析以及复杂的自动化和集成功能的大型或复杂环境而设计。企业版是 Omnissa Dynamic Environment Manager 的全功能版本。</p><h3>版本比较</h3><table><thead><tr><th>特征</th><th>标准版</th><th>企业版</th></tr></thead><tbody><tr><td>用户环境</td><td>DEM 标准版提供以下选项。  - 驱动器映射   - 文件夹重定向   - 登录和注销任务   - 打印机映射</td><td>✓</td></tr><tr><td>计算机环境</td><td>x</td><td>✓</td></tr><tr><td>个性化</td><td>支持所有功能，但在 Flex 配置文件上可配置的某些用户环境设置除外。  可以在 Flex 配置文件上配置以下用户环境设置。  - 驱动器映射   - 打印机映射   - 任务</td><td>✓</td></tr><tr><td>同步工具</td><td>✓</td><td>✓</td></tr><tr><td>自助工具</td><td>✓</td><td>✓</td></tr><tr><td>帮助台支持工具</td><td>✓</td><td>✓</td></tr><tr><td>条件集</td><td>✓</td><td>✓</td></tr><tr><td>应用分析器</td><td>✓</td><td>✓</td></tr><tr><td>应用程序迁移</td><td>x</td><td>✓</td></tr><tr><td>与 Omnissa Horizon 集成</td><td>x</td><td>✓</td></tr><tr><td>基于触发器的操作</td><td>x</td><td>✓</td></tr></tbody></table><h3>部署模式</h3><p>Dynamic Environment Manager 可在独立模式和集成模式下使用。两种模式都使用配置文件进行 Dynamic Environment Manager 的个性化和应用程序配置管理。</p><table><thead><tr><th>独立模式 (Standalone mode)</th><th>整合模式 (Integration mode)</th></tr></thead><tbody><tr><td>当您想要独立配置 Dynamic Environment Manager 时，请使用独立模式。</td><td>使用集成模式将 Dynamic Environment Manager 与 Omnissa Workspace ONE® UEM 集成。</td></tr><tr><td>配置文件存储在配置 SMB 共享中，该共享是文件服务器上的中央共享。</td><td>配置文件包含在 Dynamic Environment Manager 配置文件中。使用 Workspace ONE UEM，您可以将  Dynamic Environment Manager 配置文件文件定位到特定智能组 (sysin)，以将 Dynamic  Environment Manager 配置分发到 Workspace ONE UEM 端点。</td></tr></tbody></table><h2>新增功能</h2><p>Omnissa Dynamic Environment Manager 2509 | 2025 年 10 月 30 日 | 内部版本 10.17.0.2322</p><ul><li><strong>计算机环境配置</strong>。管理员现在也可以直接管理<strong>计算机环境</strong>的环境变量、文件和文件夹以及注册表设置。这能提供您在用户上下文中所熟悉的相同体验，而无需依赖于启动任务或自定义脚本。</li><li><strong>增强了 Windows 通用设置、应用程序模板和 Easy Start</strong>。更新了 Windows 通用设置和应用程序模板，以支持 Windows 11 场景，改进了 Office 覆盖范围，并移除了过时的项目。现有配置将继续正常运行。使用较新的定义更新引用的模板时，管理控制台会提供升级提示。</li><li><p><strong>向“文件版本”(File Version) 条件添加了比较运算符</strong>。使用更新的“文件版本”(File Version) 条件精确定位目标体验。除了“is equal to”（等于）之外，还支持以下比较运算符：</p><ul><li>“is not equal to”（不等于）</li><li>“is less than”（小于）</li><li>“is less than or equal to”（小于或等于）</li><li>“is greater than”（大于）</li><li>“is greater than equal to”（大于或等于）</li></ul></li><li>添加了一个新设置，可在目标/命令不存在时跳过快捷方式或文件类型关联。</li><li><strong>最新操作系统支持</strong>。Dynamic Environment Manager 现在支持 Windows 11 25H2。</li><li><strong>更新的组件</strong>。此版本更新了主要产品组件。应用程序分析器、Helpdesk Support 工具和 SyncTool 未更新。</li></ul><h2>下载地址</h2><p>Omnissa Dynamic Environment Manager Enterprise 2506, Release Date 2025-10-30</p><ul><li>下载地址：<a href="https://link.segmentfault.com/?enc=M%2BoIn%2Bc4X%2F4bZqN3%2Bku%2Bzg%3D%3D.N%2FIhFMP0srItoojJvhZZf4Rk0z5JeG5h7h6qPoMsZX9684hca9HbqxBxwGx%2FQ9RR37%2FTvd9flvDsj78FkhXo9w%3D%3D" rel="nofollow" target="_blank">https://sysin.org/blog/omnissa-dynamic-environment-manager/</a></li><li>Omnissa Dynamic Environment Manager<br/>File size: 35.95 MB<br/>Name: Omnissa-DEM-Enterprise-2509-10.17.zip</li></ul><p>更多：<a href="https://link.segmentfault.com/?enc=WZBVgNrgvdvq73dnuj8kmg%3D%3D.4C5ZygawV9k1UvYrTUyV6ICm%2BAIHP17bzgch%2FbDqZzs%3D" rel="nofollow" target="_blank">VMware 产品下载汇总</a></p>]]></description></item><item>    <title><![CDATA[征程 6 | QAT 新版 qconfi]]></title>    <link>https://segmentfault.com/a/1190000047438875</link>    <guid>https://segmentfault.com/a/1190000047438875</guid>    <pubDate>2025-11-30 17:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>1.前言</h2><p>随着 征程 6 芯片家族的阵容不断壮大，算法工具链在量化精度方向的优化也在持续深入，具体体现在两个方面：</p><ol><li>征程 6P 与 征程 6H 工具链已陆续进入发布和试用阶段，在此背景下，QAT（量化感知训练）需要以更高效的方式适配算子的浮点计算能力，以确保量化精度和用户的使用体验；</li><li>MatMul、Conv、Linear 等 Gemm 类算子目前已正式支持双 int16 输入，这一改进有助于提升相关算子在量化计算时的精度和调优时的效率。</li></ol><p>为了更全面、稳妥地支持上述新功能，同时对当前的 qconfig 量化配置以及回退逻辑进行优化升级，工具链从 OE3.5.0 开始支持新版 qconfig 量化模板。新版本针对 qconfig 模板开展了大量的重构工作，重构后的 qconfig 模板不仅能更好地适配新的芯片特性和算子功能，还同时保持对旧版本 qconfig 的维护，保障了用户在升级过程中的平滑过渡，减少了因版本迭代带来的适配成本。</p><h2>2.新版 qconfig 模板配置流程</h2><p>本章将系统且全面地为大家呈现新版 qconfig 模板的核心内容，涵盖其关键更新点、规范的基本使用流程以及对相关产出物的详细介绍。</p><h3>2.1 主要更新点</h3><p>在更新点方面，新版 qconfig 模板的迭代升级紧密贴合 征程 6 平台家族的持续发展以及工具链不断优化的实际需求，通过针对性的设计与调整，进一步提升了量化配置的效率、灵活性与适配性。其与旧版流程的区别主要体现在以下四个方面：</p><ol><li><strong>​模板与回退机制的统一管理：​</strong>将模板和回退进行了统一，在同一个流程下管理；</li><li><strong>​强化对特定量化配置的友好性：​</strong>对浮点计算的量化配置、Conv/Matmul 等 Gemm 算子单/双 int16 输入配置更加友好；</li><li><strong>​fuse 默认行为的调整与优化：​</strong>旧模板默认 conv-bn-add-relu 全部 fuse，然后再根据硬件限制回退至 int8。为了实现更高的计算精度，新模板首先配置 dtype，若不符合要求则不做 fuse，最终 dtype 结果更加符合预期，而且针对不同芯片架构的硬件特性设计了不同的 fuse 行为；</li><li><strong>​新增量化配置文件保存功能：​</strong>支持保存量化配置文件 <code>qconfig_dtypes.pt</code>、<code>qconfig_dtypes.pt.py</code> 以及 <code>qconfig_changelogs.txt</code>。其中，<code>qconfig_dtypes.pt</code> 为可供用户加载的算子级别的量化配置文件，实现了配置的便捷迁移与共享；<code>qconfig_dtypes.pt.py</code>​<code> </code> 则以 Python 脚本形式保存配置信息，便于用户查看；<code>qconfig_changelogs.txt</code> 则记录了配置过程中的算子变更日志，包括量化参数调整记录、模板使用信息等，为配置的追溯、调试提供了清晰的依据，进一步提升了量化配置的可解释性与可复用性。</li></ol><h3>2.2 基本使用流程</h3><p>新版 qconfig 模板在使用流程上围绕基础 qconfig 配置 reference\_qconfig、templates 量化模板配置展开，各环节紧密关联，共同助力用户实现高效、精准的量化配置。新版 qconfig 模板的基本使用流程如下所示：</p><pre><code class="Plain">import torch
import torch.nn as nn 
from horizon_plugin_pytorch.quantization import  prepare,set_fake_quantize,FakeQuantState
from horizon_plugin_pytorch.dtype import qint8,qint16
from horizon_plugin_pytorch.quantization.qconfig_setter import *
from horizon_plugin_pytorch.quantization.observer_v2 import MinMaxObserver,MSEObserver,FixedScaleObserver

my_qconfig_setter=QconfigSetter( 
     #1.基础qconfig,获取默认配置和observer
     reference_qconfig=get_qconfig(observer=MSEObserver),
     #2.模板，仅关注dype,按照顺序生效，前面模板的配置可被后面的模板覆盖。因此模板的顺序很重要
     templates=[
        ...
            ],
     #3.采用默认的优化模板
     enable_optimize=True,
     #4.qconfig模板配置文件保存路径
     save_dir=args.save_path,
        )
float_model.eval()
qat_model = prepare(
    float_model,
    example_inputs=example_input,
    qconfig_setter=my_qconfig_setter,
    check_result_dir=args.save_path
    )</code></pre><p>以上就是新版 qconfig 模板的基本使用流程，下面将对其核心部分 QconfigSetter 接口和工具链提供的多个 templates 进行介绍。</p><h4>2.2.1 QconfigSetter 接口介绍</h4><p>QconfigSetter 接口的定义如下所示：</p><blockquote>代码路径：horizon_plugin_pytorch/quantization/qconfig_setter/qconfig_setter.py</blockquote><pre><code class="Plain">class QconfigSetter(ModernQconfigSetterBase):
    """Manage qconfig settings of a model.

    Args:
        reference_qconfig: Qconfig to provide observer.
        templates: Qconfig templates, will be applyed in order.
        enable_optimize: Whether enable the default optimize.
        save_dir: Save directory of qconfig settings.
        custom_qconfig_mapping: Custom mapping from mod name to qconfig.
            CAUTION: This mapping will overwrite the dtype setted by templates.
                     You'd better not change dtype through this argument, or
                     the config result will not be optimal (Model may contain
                     CPU ops on board, for example).
            Defaults to None.
        enable_attribute_setting: Whether enable the qconfig setted through
            qconfig attribute.
        enable_propagate: Whether enable propagate for custom_qconfig_mapping
            and qconfig attr. Defaults to False.
    """

    def __init__(
        self,
        reference_qconfig: QConfig,
        templates: Sequence[TemplateBase],
        enable_optimize: bool = True,
        save_dir: str = "./qconfig_setting",
        custom_qconfig_mapping: Optional[Dict[str, QConfig]] = None,
        enable_attribute_setting: bool = False,
        enable_propagate: bool = False,
    ):
        super().__init__(reference_qconfig)
        self.templates = list(templates)
        self.enable_optimize = enable_optimize
        self.save_dir = save_dir

        if custom_qconfig_mapping is None:
            custom_qconfig_mapping = {}
        self.custom_qconfig_mapping = {
            k: canonicalize_qconfig(v)
            for k, v in custom_qconfig_mapping.items()
        }
        self.enable_attribute_setting = enable_attribute_setting
        self.enable_propagate = enable_propagate

        if save_dir is not None:
            os.makedirs(save_dir, exist_ok=True)</code></pre><ul><li><strong>​reference\_qconfig【必要配置】：​</strong>配置 observer，可选项包括 MSEObserver 、MinMaxObserver 等。</li><li><strong>​templates【必要配置】：​</strong>配置使用到的 qconfig 模板，仅关注 dtype，按照顺序依次生效。</li><li><p><strong>enable\_optimize【必要配置-用户可不关注】: ​</strong>是否采用默认的优化 pass，默认配置为 True，相关优化如下：</p><ul><li><p><code>CanonicalizeTemplate</code>： 按算子类型对 dtype 配置进行合法化，当前默认规则有：</p><ul><li>Gemm 类算子输入不支持 float</li><li>插值类算子：在不同 march 下有不同的限制</li><li>DPP、RPP 等特殊算子仅支持 int8</li><li>其他算子的通用规则：算子的 input dtype 和 output dtype 不能同时存在 qint 和 float</li></ul></li><li><p><code>EqualizeInOutScaleTemplate</code>：对于 relu，concat，stack 算子，应该在算子输出统计 scale，否则精度或性能存在损失。为此：</p><ul><li>将前面算子的 output dtype 配置为 float32</li><li>Relu，concat，stack 算子在 export hbir 时，在 input 处插入伪量化，scale 复用 output scale</li></ul></li><li><code>FuseConvAddTemplate</code>：硬件支持 conv + add 的 fuse，不同的芯片架构的融合条件不一致，满足融合条件会有以下行为：</li><li>将 conv 的 output dtype 配置为 float32</li><li>将 add 对应的 input dtype 配置为 float32</li><li><code>GridHighPrecisionTemplate</code>：根据经验，grid sample 的 grid 计算过程用 qint8 精度不够，因此自动将相关算子配置为 qint16 计算。</li><li><code>InternalQuantsTemplate</code>：模型分段部署场景下，会在分段点处插入 QuantStub，用于记录此处的 dtype 和 scale，此类 QuantStub 的 dtype 配置必须和输入保持一致。</li><li><code>OutputHighPrecisionTemplate</code>：当 Gemm 类算子作为模型输出时，将其配置为高精度输出。</li><li><code>PropagateTemplate</code>：对于拆分为子图实现的算子，存在经验性配置，如 <code>LayerNorm</code> 和 <code>Softmax</code> 内部小算子应该使用高精度。</li><li><p><code>SimpleIntPassTemplate</code>：性能优化，对于 op0-&gt;op1-&gt;op2 此类计算图，若以下条件同时成立，则将 op1 输出类型修改为 int：</p><ul><li>op2 需要 int 输入</li><li>op0 可以输出 int</li><li><p>op1 当前输出为 float16，且属于以下类型</p><ol><li>cat, stack</li><li>mul\_scalar</li><li>无精度风险的查表算子（即在 fp16 上默认使用查表实现的算子）</li></ol></li></ul></li><li><code>SimplifyTemplate</code>：删除多余的量化节点配置（将对应的 dtype 修改为 None）</li></ul><p>进一步的说明可以参考用户手册&lt;u&gt;<a href="https://link.segmentfault.com/?enc=9%2BHhOCPeyg3mgzEJRQ7vGA%3D%3D.MZ6cqtMHJTNv8CdxfnZLJjvOCXDSQRgdPkHiNvBuOFfZm38Wpqt%2BR1hbrCm1M90WhPp4BARlGUY8OHykAZfk8wQpfsZjPy7TM1DUSMJsboIOns6pehHCHSJk8e%2B50dgzqVtV3S6kO8U8pMUeGiQHDw%3D%3D" rel="nofollow" target="_blank">【Qconfig 详解】</a>&lt;/u&gt;。</p></li><li><strong>​save\_dir【必要配置】：​</strong>量化配置文件保存的路径。</li></ul><h4>2.2.2 templates 介绍</h4><p><code>horizon_plugin_pytorch</code> 中提供了比较齐全的量化配置 templates 供用户使用，下面将逐一对这些模板进行介绍：</p><ol><li>ModuleNameTemplate（必要配置）：通过 module name 指定 dtype 配置或量化阈值，包括激活/weight 量化配置，固定 scale 配置；配置粒度支持全局、模型片段和算子等；配置 dtype 包括 qint8、qint16、torch.float16、torch.float32 等，相关配置项可以参考用户手册&lt;u&gt;<a href="https://link.segmentfault.com/?enc=JfkwDPnPT1kOz9IzzgEg6w%3D%3D.7ZGMF%2F1VJeoiCxb8CZwWewSQNKCmg5%2B2SAf8dHX3iawyQp249M15lQxXCpyCP2tD4fYpSYplD54yRi1fSBflOc8wZEqj8b7KpOsnSXJKfZ8cIA6Pgm1zzVY03ubnsW99g%2FthkpJ1Y8EHqtuXrlITbw%3D%3D" rel="nofollow" target="_blank">【Qconfig 详解】</a>&lt;/u&gt;；</li><li>MatmulDtypeTemplate（必要配置）：通过名称或前缀配置 Matmul 算子单 int16/双 int16 输入，支持批量配置，相关配置项可以参考用户手册&lt;u&gt;<a href="https://link.segmentfault.com/?enc=1oqTh51AtyYGDH2DN%2Fgs7A%3D%3D.Ic9yty0y5L5ccJxxrdtsEHz4X5JBVD965YfWLEJnSwB2ATa1S%2BRerXFBPn78hrjR7AmSYL9510UwJ%2FkJtXW1wSgkhd%2BYnIxvFmDmUs%2FwjyBchweDBLHzWFmGTvgOIaK05RUf0EwZMauAi%2B3Vc6azgw%3D%3D" rel="nofollow" target="_blank">【Qconfig 详解】</a>&lt;/u&gt;；</li><li>ConvDtypeTemplate（必要配置）：通过名称或前缀配置 Conv/Linear 算子单 int16/双 int16 输入，支持批量配置，相关配置项可以参考用户手册&lt;u&gt;<a href="https://link.segmentfault.com/?enc=GkHb%2Bhz2amI9KXhdusIy6g%3D%3D.bLPMpXxr6m9ZSYWSayKA1gGgMPADB3ILj0%2BBs8nb6Zz%2FpENRpO7nQN%2BlkT3xsk%2F6t6ZKxPw6fp9W4qPvhZoxZVxYlhtWvH0RQu45Il6ObZG2OlNWSDr5jLYIAU%2FXPhXpC7%2BB9g1li7rkLzXLsxzLxQ%3D%3D" rel="nofollow" target="_blank">【Qconfig 详解】</a>&lt;/u&gt;；</li><li>SensitivityTemplate（可选配置）：通过量化敏感度列表提升数据类型精度，默认将敏感算子配置为 int16，支持激活敏感和 weight 敏感算子分别配置高精度，相关配置项可以参考用户手册&lt;u&gt;<a href="https://link.segmentfault.com/?enc=hnAdWAGQ3gIQFjeH3%2BvalA%3D%3D.0wifHgAseHLK%2F6oJJKg%2Bm%2BV8X65TbW4WFxIgb4D1POjdj2yi8bS0IX5PbBUqLEolCkc8fUgBLcFSRoq7kMpsleZHPfMyq8GnvoNNUYA3nSr5%2B6sb1qmFbiCzez231tWLDmCI8Y3JTQ%2FUqW%2FpcX9FRg%3D%3D" rel="nofollow" target="_blank">【Qconfig 详解】</a>&lt;/u&gt;。</li><li>LoadFromFileTemplate：从 <code>qconfig_dtypes.pt</code> 文件中加载量化配置，仅可加载全局及每个算子的量化类型，暂时无法加载 fix\_scale 配置，且不支持对 qconfig 进行修改。而且需要注意，此时 enable\_optimize 必须配置为 False，否则无法保证配置结果的正确性，部署时可能存在 CPU 算子。</li></ol><p><strong>用户配置的模板按顺序生效，前面模板的配置会被后面的模板覆盖。</strong></p><p>一般来说，用户会使用到 ModuleNameTemplate、ConvDtypeTemplate、MatmulDtypeTemplate 和 SensitivityTemplate 这 4 个模板，其中前 3 个模板为必要配置。以下是 templates 的常用配置，如下所示：</p><pre><code class="Plain">from horizon_plugin_pytorch.quantization.qconfig_setter import *
import torch
#加载精度debug工具产出的敏感度列表
table1=torch.load("xxx_optput1_L1.pt")
table2=torch.load("xxx_optput2_L1.pt")
templates=[ 
    #1. 基础配置部分
    ModuleNameTemplate({"":qint8}),  #全局feat int8,此时weight 默认为int16
    #conv类算子的 input配置为 int8，weight配置为int8
    ConvDtypeTemplate(input_dtype=qint8, weight_dtype=qint8),  
    #matmul类算子两个输入均配置为 int8
    MatmulDtypeTemplate(input_dtypes=qint8), 
    ModuleNameTemplate(
        {"quant":{"dtype":qint8,"threshold":1.0}},#quant int8,固定scale，配置
        ),
    #2. Matmul 单/双int16输入配置
    MatmulDtypeTemplate(
        input_dtypes=[qint8/qint16,qint8/qint16],
        prefix=["head","xxxxx"]#prefix中配置的名称与torch.nn.Module.name_module()返回的一致
        ),
    #3.Conv 单/双int16输入配置
    ConvDtypeTemplate(
        input_dtype=qint8/qint16, 
        weight_dtype=qint8/qint16,
        prefix= ["backbone","xxxxx"],#prefix中配置的名称与torch.nn.Module.name_module()返回的一致
        ),
    # 4. 敏感度模板配置
    #配置top10 weight敏感的算子为int16
    SensitivityTemplate(
        sensitive_table=table1,#精度debug工具产出的敏感度列表
        topk_or_ratio=10, #配置整数的时候是topk,小数的时候是ratio
        sensitive_type= 'weight',#只配置weight敏感的算子，还可以选择 'activation'、 'both'，默认是both
        ),
    #配置50%激活敏感的算子为int16
    SensitivityTemplate(
        sensitive_table=table2,
        topk_or_ratio=0.5, #配置整数的时候是topk,小数的时候是ratio
        sensitive_type= 'activation',#配置激活敏感的算子
        ), 
    ]</code></pre><h3>2.3 产出物介绍</h3><p>在完成新版 qconfig 模板配置并执行 prepare 操作后，工具链将自动生成并保存 5 个文件，分别为 <code>model_check_result.txt</code>、<code>fx_graph.txt</code>、<code>qconfig_changelogs.txt</code>、<code>qconfig_dtypes.pt.py</code> 及 <code>qconfig_dtypes.pt</code>，各文件功能与技术细节如下：</p><ul><li><code>model_check_result.txt</code>、<code>fx_graph.txt</code>：二者均由 <code>prepare</code> 接口自动生成，<code>model_check_result.txt</code> 中包括未 fuse 的 pattern、每个 op 输出/weight 的 qconfig 配置、异常 qconfig 配置提示等，<code>fx_graph.txt</code> 保存的是模型的 fx trace 图；</li><li><code>qconfig_dtypes.pt.py</code> 和 <code>qconfig_dtypes.pt</code>：为 <code>QconfigSetter</code> 接口输出的量化配置载体，完整记录全局及算子级别的量化精度参数，包括每个算子的 input、weight 和 output 的量化精度，如 qint8、qint16 和 torch.float16 等，其中。py 文件供用户阅读，。pt 文件可以使用 <code>LoadFromFileTemplate</code> 接口加载，<code>qconfig_dtypes.pt.py</code> 中信息如下所示；</li></ul><pre><code class="Plain">{
#算子级别量化配置
'backbone.conv1.conv1_1.conv': {'input': None, 'weight': 'qint8', 'output': None}, 'backbone.conv1.conv1_1.act': None,
 'backbone.conv1.conv1_2.conv': {'input': torch.float32, 'weight': torch.float32, 'output': None}, 
 'backbone.conv1.conv1_2.act': {'input': None, 'weight': None, 'output': 'qint16'}
 ...
 }</code></pre><ul><li><code>qconfig_changelogs.txt</code>：每个算子 qconfig 根据 Templates 的变化逻辑，页面如下所示：</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438877" alt="" title=""/></p><h2>3. 使用示例</h2><p>本章节将会提供上述模板的使用方法以及在典型场景下的配置示例。</p><h3><strong>3.1 配置全局</strong> fp16/int16/int8</h3><h4>3.1.1 配置全局 int8</h4><p>配置全局 qconfig 时必须要配置 ModuleNameTemplate、ConvDtypeTemplate、MatmulDtypeTemplate 这 3 个模板，以下为使用示例：</p><pre><code class="Plain">import torch
from horizon_plugin_pytorch.quantization import  prepare,set_fake_quantize,FakeQuantState
from horizon_plugin_pytorch.quantization.qconfig_template import ModuleNameQconfigSetter,
from horizon_plugin_pytorch.quantization import get_qconfig 
from horizon_plugin_pytorch.quantization.qconfig_setter import *
my_qconfig_setter=QconfigSetter(
    reference_qconfig=get_qconfig(observer=MSEObserver),
    templates=[
      #1.全部算子配置为 int8 输出
      ModuleNameTemplate({"":qint8}),  
      #2.conv 的 input配置为 int8，weight配置为int8
      ConvDtypeTemplate(input_dtype=qint8, weight_dtype=qint8),  
      #3.matmul 两个输入均配置为 int8
      MatmulDtypeTemplate(input_dtypes=qint8), 
    ],
     save_dir=args.save_path,
    )
float_model.eval()
qat_model = prepare(
    float_model,
    example_inputs=example_input,
    qconfig_setter=my_qconfig_setter,
    check_result_dir=args.save_path
    )</code></pre><p>配置全局 int16 的方式与全局 int8 类似，将上述示例中的 qint8 修改为 qint16 即可。</p><p><strong>注意：</strong></p><ol><li>配置全局 feat 为 int8/int16/fp16 的时候必须要对 Conv 类算子的 weight 进行配置，否则 weight 会自动做 int16 计算，并可能出现不符合预期的 CPU 算子；</li><li>配置全局 int8 后，model\_check\_result.txt 可能会显示模型中仍然存在 int16 计算的算子，这是工具为了提升量化精度做的自动化行为，比如 norm 这种进行拆分实现的算子，内部采用 int16 较高精度的计算，然后输出为 int8。</li></ol><h4>3.1.2 配置全局 feature int16+weight int8+prefix 批量配置</h4><pre><code class="Plain">import torch
from horizon_plugin_pytorch.quantization import  prepare,set_fake_quantize,FakeQuantState
from horizon_plugin_pytorch.quantization import get_qconfig 
from horizon_plugin_pytorch.quantization.qconfig_setter import *
my_qconfig_setter=QconfigSetter(
    reference_qconfig=get_qconfig(observer=MSEObserver),
    templates=[
        #1.配置全局feat int16,weight int8
        ModuleNameTemplate({"":qint16}),
        ConvDtypeTemplate(input_dtype=qint16, weight_dtype=qint8),  
        MatmulDtypeTemplate(input_dtypes=qint16),  
        #2.配置backbone部分全int8
        ModuleNameTemplate({"backbone":qint8}),
        MatmulDtypeTemplate(
            input_dtypes=[qint8,qint8],
            prefix=["backbone"]
        ),    
        ConvDtypeTemplate(
            input_dtype=qint8, 
            weight_dtype=qint8,
            prefix= ["backbone"],
        ),
    ],
    save_dir=args.save_path,
    )

qat_model = prepare(
    float_model,
    example_inputs=example_input,
    qconfig_setter=my_qconfig_setter,
    check_result_dir=args.save_path)</code></pre><h3>3.2 fixscale 配置</h3><p>模型中的某些地方很难依靠统计的方式获得最佳的量化 scale，比如物理量，此时当算子的输出值域确定时就可以设置 fixed scale。新版 qconfig 模板配置 fixed scale 的方式为配置输入/输出的量化类型“dtype”和阈值“threshold”，其中 scale 的计算为：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438878" alt="" title="" loading="lazy"/></p><p>其中 threshold 一般为算子输入/输出的绝对值的最大值；n 则为量化位宽，比如 int8 量化位宽 n=8。</p><p>如下为配置 quantstub 算子输出 scale 和 conv 算子输入 scale 的示例：</p><pre><code class="Plain">import torch
from horizon_plugin_pytorch.quantization import  prepare,set_fake_quantize,FakeQuantState
from horizon_plugin_pytorch.quantization import get_qconfig 
from horizon_plugin_pytorch.quantization.qconfig_setter import *
my_qconfig_setter=QconfigSetter(
    reference_qconfig=get_qconfig(observer=MSEObserver),
    templates=[
        #1. 配置全局int8 
        ModuleNameTemplate({"":qint8}), 
        ConvDtypeTemplate(input_dtype=qint8, weight_dtype=qint8),  
        MatmulDtypeTemplate(input_dtypes=qint8),
        
        ModuleNameTemplate(
        { 
         #2.fixscale:配置算子输出的dtype和threshold，此时scale=1/128=0.0078125
         "backbone.quant":{"dtype":qint8,"threshold":1.0},
         #3.fixscale:配置conv的weight输入为fix_scale的int16量化，
         #scale=1/32768=3.0518e-05
         "backbone.conv1.conv1_2.conv":{"dtype": {"weight": qint16}, "threshold": {"weight": 1.0}},   
        },
        ),
],
    save_dir=args.save_path,    
)
qat_model = prepare(
    float_model,
    example_inputs=example_input,
    qconfig_setter=my_qconfig_setter,
    check_result_dir=args.save_path)</code></pre><p>通过 prepare 后生成的 <code>model_check_result.txt</code> 可以验证配置是否生效：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438879" alt="" title="" loading="lazy"/></p><h3>3.3 批量配置 conv/matmul 单/双 int16 输入</h3><p>ConvDtypeTemplate 和 MatmulDtypeTemplate 支持单/双 int16 输入的批量配置，相关示例如下：</p><pre><code class="Plain">import torch
from horizon_plugin_pytorch.quantization import  prepare,set_fake_quantize,FakeQuantState
from horizon_plugin_pytorch.quantization import get_qconfig 
from horizon_plugin_pytorch.quantization.qconfig_setter import *
my_qconfig_setter=QconfigSetter(
    reference_qconfig=get_qconfig(observer=MSEObserver),
    templates=[
        #1.基础配置全局激活&amp;weight int8
        ModuleNameTemplate({"":qint8}), 
        ConvDtypeTemplate(input_dtype=qint8, weight_dtype=qint8),  
        MatmulDtypeTemplate(input_dtypes=qint8),

        #2.Conv 单int16输入配置：将激活输入为int16(按需配置)
        ConvDtypeTemplate(
            input_dtype=qint16, 
            weight_dtype=qint8,
            prefix= ["backbone.res_layers.0","encoder.encoder.0.layers.0"],
            ),
        #3.Conv 单int16输入配置：将weight配置int16(按需配置)
        ConvDtypeTemplate(
            input_dtype=qint8, 
            weight_dtype=qint16,
            prefix= ["backbone.conv1.conv1_2.conv"],
            ),
        #4.Conv 双int16输入配置(按需配置)
        ConvDtypeTemplate(
            input_dtype=qint16, 
            weight_dtype=qint16,
            prefix= ["backbone.conv1.conv1_1.conv"],
            ),
        #5.matmul单int16配置：将第0个输入配置为int8,第1个输入配置成int16(按需配置)
         MatmulDtypeTemplate(
            input_dtypes=[qint8,qint16],
            prefix=["encoder.encoder.0.layers.0.self_attn.matmul","encoder.encoder.1.layers.0.self_attn.matmul"]
                 ),
        #6.matmul单int16配置：第0个输入配置成int16，将第1个输入配置为int8（按需配置)
        MatmulDtypeTemplate(
            input_dtypes=[qint16,qint8],
            prefix=["encoder.encoder.0.layers.1.self_attn.matmul"]
                 ),
        #7.matmul双int16配置：将2个输入都配置为双int16(按需配置)
        MatmulDtypeTemplate(
            input_dtypes=[qint16,qint16],
            prefix=["encoder.encoder.0.layers.2.self_attn.matmul"]
                 ),
],
    save_dir=args.save_path,    
)
qat_model = prepare(
    float_model,
    example_inputs=example_input,
    qconfig_setter=my_qconfig_setter,
    check_result_dir=args.save_path)</code></pre><h3>3.4 LoadFromFileTemplate 使用示例</h3><p>当从旧模板迁移到新的 qconfig 量化模板时，推荐的做法是先把旧版本的量化配置 qconfig\_dtypes.pt 保存下来，然后使用 LoadFromFileTemplate 进行加载，这里仅介绍此接口的用法，后续章节有完整的迁移教程。</p><p><strong>LoadFromFileTemplate 接口使用时需要注意以下问题：</strong></p><ol><li>qconfig\_dtypes.pt 不保存算子的 fix\_scale 信息，如果原 qconfig 里存在 fix\_scale 的算子，需要在加载 qconfig\_dtypes.pt 后再次进行配置。</li><li>使用 LoadFromFileTemplate 接口时 enable\_optimize 必须配置为 False，因为保存下来的 dtype 一般是优化后的，优化过程不可重入，Load qconfig\_dtypes.pt 后​<strong>不再支持对 qconfig 中 dtype 的修改</strong>​。</li></ol><p>LoadFromFileTemplate 使用示例如下：</p><pre><code class="Plain">import torch
from horizon_plugin_pytorch.quantization import  prepare,set_fake_quantize,FakeQuantState
from horizon_plugin_pytorch.quantization import get_qconfig 
from horizon_plugin_pytorch.quantization.qconfig_setter import *
my_qconfig_setter=QconfigSetter(
    reference_qconfig=get_qconfig(observer=MSEObserver),
    templates=[
         #1.加载量化配置pt文件
         LoadFromFileTemplate("qconfig_dtypes.pt"),
         #2.对fix_scale的算子进行补充配置
         ModuleNameTemplate({"backbone.quant":{"dtype":qint8,"threshold":1.0}})
    ],
    #3.无需开启任何优化
    enable_optimize=False,
    save_dir=args.save_path,)
qat_model = prepare(
    float_model,
    example_inputs=example_input,
    qconfig_setter=my_qconfig_setter,
    check_result_dir=args.save_path)</code></pre><h3>3.5 典型场景配置</h3><p>由于征程 6 系列平台的差异，qconfig 的配置自然也会有所区别。本节将结合平台差异，提供新版 qconfig 模板在典型场景下的配置示例。</p><h4>3.5.1 征程 6E/M 平台一般配置</h4><p>征程 6E/M 平台以定点算力为主，在进行混合量化精度调优过程中，建议以全局 int8 精度为例，针对部分对量化较为敏感的算子，可将其配置为更高的 int16 精度。以下为配置示例。</p><h5>配置示例 1：全局 int8+ 手动配置量化敏感度高的算子为 int16</h5><pre><code class="Plain">import torch
from horizon_plugin_pytorch.quantization import  prepare,set_fake_quantize,FakeQuantState
from horizon_plugin_pytorch.quantization import get_qconfig 
from horizon_plugin_pytorch.quantization.qconfig_setter import *
my_qconfig_setter=QconfigSetter(
    reference_qconfig=get_qconfig(observer=MSEObserver),
    templates=[
        #1.配置全局feat int8,weight int8
        ModuleNameTemplate({"":qint8}),
        ConvDtypeTemplate(input_dtype=qint8, weight_dtype=qint8),  
        MatmulDtypeTemplate(input_dtypes=qint8),  
        #2.根据精度debug工具分析，将敏感算子配置为int16(按需配置)
        #将weight敏感的conv配置为int16(按需配置)，支持批量配置
        ConvDtypeTemplate(
            input_dtype=qint8, 
            weight_dtype=qint16,
            prefix= ["backbone.conv1.conv1_3.conv"],
            ),
        #3.将敏感的Matmul配置为int16输入(按需配置)
        #将第0个输入敏感的matmul配置为int16(按需配置)，支持批量配置
        MatmulDtypeTemplate(
            input_dtypes=[qint16,qint8],
            prefix=["encoder.encoder.0.layers.0.self_attn.matmul"]
                 ),
    ],
    save_dir=args.save_path,
    )

qat_model = prepare(
    float_model,
    example_inputs=example_input,
    qconfig_setter=my_qconfig_setter,
    check_result_dir=args.save_path)</code></pre><h5>配置示例 2：全局 int8+ 使用敏感度模板配置部分敏感算子为 int16</h5><p>除了手动将部分敏感算子配置为 int16，新版 qconfig 模板提供了 SensitivityTemplate，该模板用于将精度 debug 工具所产出的敏感度列表中，量化敏感度排序 topk 或者占一定比率 ratio 的敏感算子，配置为更高的量化精度。相关示例如下：</p><pre><code class="Plain">import torch
from horizon_plugin_pytorch.quantization import  prepare,set_fake_quantize,FakeQuantState
from horizon_plugin_pytorch.quantization import get_qconfig 
from horizon_plugin_pytorch.quantization.qconfig_setter import *
#精度debug工具跑出来的算子量化敏感度列表
table1=torch.load("output1_ATOL_sensitive_ops.pt")
table2=torch.load("output2_ATOL_sensitive_ops.pt")
my_qconfig_setter=QconfigSetter(
    reference_qconfig=get_qconfig(observer=MSEObserver),
    templates=[
      #1. 基础配置全局激活&amp;weight int8
      ModuleNameTemplate({"":qint8}), 
      ConvDtypeTemplate(input_dtype=qint8, weight_dtype=qint8),  
      MatmulDtypeTemplate(input_dtypes=qint8),
      #2.配置output1输出敏感度Top10的算子为int16(按需配置)
      SensitivityTemplate(
        sensitive_table=table1,
        topk_or_ratio=10,  
    ),
      #3.配置output2输出敏感度10%的算子为int16(按需配置)
      SensitivityTemplate(
        sensitive_table=table2,
        topk_or_ratio=0.1, 
    ),   
    ],
    save_dir=args.save_path,)
qat_model = prepare(
    float_model,
    example_inputs=example_input,
    qconfig_setter=my_qconfig_setter,
    check_result_dir=args.save_path)</code></pre><p>topk\_or\_ratio 参数的选择：需要用户根据量化精度和部署性能进行权衡，一般来说，配置的高精度算子越多，量化精度越好，而部署性能影响则会越大。</p><h4>3.5.2 征程 6P/H 平台一般配置</h4><p>对于征程 6 P/H 这种有浮点算力的平台，推荐将 feature 输出配置为 fp16+conv 和 matmul 类算子全部配置为 int8 作为基础配置，然后再将量化敏感的算子配置为 int16。如下为配置示例。</p><h5>配置示例 1：基础配置 + 手动配置量化敏感度高的算子为 int16</h5><pre><code class="Plain">import torch
from horizon_plugin_pytorch.quantization import  prepare,set_fake_quantize,FakeQuantState
from horizon_plugin_pytorch.quantization.qconfig_template import ModuleNameQconfigSetter,
from horizon_plugin_pytorch.quantization import get_qconfig 
from horizon_plugin_pytorch.quantization.qconfig_setter import *
my_qconfig_setter=QconfigSetter(
    reference_qconfig=get_qconfig(observer=MSEObserver),
    templates=[
      #1.基本配置
      #全局 feat fp16
      ModuleNameTemplate({"": torch.float16}),
      #将conv和matmul类算子配置为全int8输入
      ConvDtypeTemplate( 
            input_dtype=qint8,
            weight_dtype=qint8,  
        ),
      MatmulDtypeTemplate(  
            input_dtypes=[qint8, qint8],
        ),
      #2.根据debug工具分析结果，将敏感的Conv/Matmul配置为int16输入(按需配置)
      #将conv中敏感的weight输入配置为int16(按需配置)
      ConvDtypeTemplate(
            input_dtype=qint8, 
            weight_dtype=qint16,
            prefix= ["backbone.conv1.conv1_3.conv"],
            ),
      #将matmul中敏感的输入配置为int16(按需配置)
       MatmulDtypeTemplate(
            input_dtypes=[qint16,qint8],
            prefix=["encoder.encoder.0.layers.0.self_attn.matmul"] ),
       
    ],
     save_dir=args.save_path,
    )
float_model.eval()
qat_model = prepare(
    float_model,
    example_inputs=example_input,
    qconfig_setter=my_qconfig_setter,
    check_result_dir=args.save_path
    )</code></pre><h5>配置示例 2：基础配置 + 使用敏感度模板配置部分敏感算子为 int16</h5><pre><code class="Plain">import torch
from horizon_plugin_pytorch.quantization import  prepare,set_fake_quantize,FakeQuantState
from horizon_plugin_pytorch.quantization import get_qconfig 
from horizon_plugin_pytorch.quantization.qconfig_setter import *
#精度debug工具跑出来的算子量化敏感度列表
table1=torch.load("output1_ATOL_sensitive_ops.pt")
table2=torch.load("output2_ATOL_sensitive_ops.pt")
my_qconfig_setter=QconfigSetter(
    reference_qconfig=get_qconfig(observer=MSEObserver),
    templates=[
      #1.基本配置
      #全局 feat fp16
      ModuleNameTemplate({"": torch.float16}),
      #将conv和matmul类算子配置为全int8输入
      ConvDtypeTemplate( 
            input_dtype=qint8,
            weight_dtype=qint8,  
        ),
      MatmulDtypeTemplate(  
            input_dtypes=[qint8, qint8],
        ),
      #2.配置output1输出敏感度Top10的算子为int16(按需配置)
      SensitivityTemplate(
        sensitive_table=table1,
        topk_or_ratio=10,  
    ),
      #3.配置output2输出敏感度10%的算子为int16(按需配置)
      SensitivityTemplate(
        sensitive_table=table2,
        topk_or_ratio=0.1, 
    ),   
    ],
    save_dir=args.save_path,)
qat_model = prepare(
    float_model,
    example_inputs=example_input,
    qconfig_setter=my_qconfig_setter,
    check_result_dir=args.save_path)</code></pre><h4>3.5.3 配置算子为 float32 计算</h4><p>在做精度调优的时候，有时候想要快速定位引起量化误差的瓶颈，此时会将模型片段或者算子配置为 float32 计算，如下为将指定模型片段和算子配置为 float32 计算的示例：</p><pre><code class="Plain">my_qconfig_setter=QconfigSetter(
    reference_qconfig=get_qconfig(observer=MSEObserver),
    templates=[
        #1. 基础配置全局激活&amp;weight int8
        ModuleNameTemplate({"":qint8}), 
        ConvDtypeTemplate(input_dtype=qint8, weight_dtype=qint8),  
        MatmulDtypeTemplate(input_dtypes=qint8),
        
        ModuleNameTemplate(
        { 
         #2.批量配置"encoder.encoder.0.layers.0"为float32计算
         "encoder.encoder.0.layers.0": torch.float32,
         #3.配置"backbone.conv1.conv1_2.conv.act"算子为float32计算
         "backbone.conv1.conv1_2.conv.act": torch.float32,}
            ),
    ],
    save_dir=args.save_path,    
)</code></pre><h4>3.5.4 QAT 训练时固定激活 scale</h4><p>在 QAT 精度调优实践中发现（主要是图像分类任务实验），做完 calibration 后，把 activation 的 scale 固定住，不进行更新，即设置 activation 的 <code>averaging_constant=0</code> ，QAT 训练精度相比于不固定 activation 的 scale 的量化精度会更好。相关配置示例如下所示：</p><pre><code class="Plain">import torch
from horizon_plugin_pytorch.quantization import  prepare,set_fake_quantize,FakeQuantState
from horizon_plugin_pytorch.quantization.fake_quantize import FakeQuantize
from horizon_plugin_pytorch.quantization.qconfig import QConfig
from horizon_plugin_pytorch.quantization.qconfig_setter import *
from horizon_plugin_pytorch.quantization import get_qconfig 
my_qconfig_setter=QconfigSetter(
    #将激活的averaging_constant参数配置为0
    reference_qconfig= QConfig(
        output=FakeQuantize.with_args(
            observer=MinMaxObserver,
            averaging_constant=0,#averaging_constant配置为0
        ), ),
    templates=[
      #配置weight和激活全局int8
      ModuleNameTemplate({"":qint8}), 
      ConvDtypeTemplate(input_dtype=qint8, weight_dtype=qint8),  
      MatmulDtypeTemplate(input_dtypes=qint8),
    ],
    save_dir=args.save_path,
    )

qat_model = prepare(
    float_model,
    example_inputs=example_input,
    qconfig_setter=my_qconfig_setter,
    check_result_dir=args.save_path
    )</code></pre><h2>4. 新版 qconfig 模板迁移</h2><p>用户在迁移到新版 qconfig 模板时，建议根据以下情况进行不同的操作：</p><ol><li>如果用户部署平台为征程 6B、征程 6H 和征程 6P，为了更方便地利用浮点算力，建议使用新版 qconfig 模板。</li><li>如果用户模型从未适配过 QAT 链路，建议用户直接参考第 3 章使用新版 qconfig 模板进行配置。</li><li>如果用户模型已经适配过老版本 qconfig 模板，且在模型迭代中还需要修改 qconfig 配置，比如增加 int16 算子等，那么建议用户参考第 3 章重新进行新版 qconfig 模板的适配。</li><li>如果用户模型已经适配过老版本 qconfig 模板，且确认在模型迭代中不再需要修改 qconfig 配置，那么则建议用户按照下面的流程进行迁移工作。</li></ol><p>若用户已经稳定使用老版本 qconfig 模板，而且模型迭代中不需要再修改量化配置，那么建议按照以下流程进行适配：</p><ol><li>首先，使用 <code>SaveToFileTemplate</code> 接口保存旧模板下的量化配置文件 <code>qconfig_dtypes.pt</code>，其中涵盖每个算子的 dtype；</li><li>其次，需检查模型中是否存在采用 fix\_scale 的算子。鉴于 qconfig\_dtypes.pt 目前尚不支持保存 fix\_scale 的算子信息，并且新旧模板在 fix\_scale 的配置方面存在差异，若存在 fix\_scale 的算子，那么就必须对新模板下 fix\_scale 的配置进行适配；</li><li>最后，运用 <code>LoadFromFileTemplate</code> 接口加载已保存的 <code>qconfig_dtypes.pt</code>​<code> </code> 文件，将量化 dtypes 配置导入新模板中，从而实现量化配置的迁移衔接。</li></ol><p>这里要特别注意，加载已保存的 <code>qconfig_dtypes.pt</code> 文件后不支持再对模型中的算子 dtype 做修改。</p><p>下面将详细介绍迁移的具体步骤和操作要点。</p><h3>4.1 保存旧版本的 qconfig\_dtypes 文件</h3><p><code>horizon_plugin_pytorch</code>​<code> </code> 提供了 <code>SaveToFileTemplate</code> 接口用于将量化配置文件保存为 <code>qconfig_dtypes.pt</code>。其路径和使用方式如下：</p><pre><code class="Plain">from horizon_plugin_pytorch.quantization.qconfig_setter.templates import *
...
qat_model = prepare(
    float_model,
    example_inputs=example_input,
    qconfig_setter=(
        ModuleNameQconfigSetter(...),
        calibration_8bit_weight_16bit_act_qconfig_setter,
    ),
    check_result_dir=args.save_path,
    )
#prepare后保存
#args.save_path为qconfig_dtypes.pt保存路径
save_api=SaveToFileTemplate(args.save_path)
save_api(None, qat_model, None, None, None)</code></pre><p>在完成修改并运行后，于 args.save\_path 目录下将会生成包含量化 dtype 的 qconfig\_dtypes.pt 与 qconfig\_dtypes.pt.py 文件。</p><h3>4.2 适配 fix\_scale 的配置</h3><p>目前，<code>qconfig_dtypes.pt</code>​<code> </code> 文件在保存量化配置信息时，存在一定的功能限制，即尚不支持对配置了 fix\_scale 的算子信息进行保存。这意味着当用户在旧版本 qconfig 中对部分算子设置了 fix\_scale 时，相关的配置无法通过 <code>qconfig_dtypes.pt</code>​<code> </code> 文件完整迁移至新模板。</p><p>因此，若用户的模型中存在配置 fix\_scale 的算子，fix\_scale 的算子和相应配置可以通过 <code>model_check_result.txt</code> 获取，为确保量化配置能够对齐旧版本，必需按照上文 3.2 章节所阐述的适配规则和操作步骤，手动对 fix\_scale 的配置进行调整与适配，以使其符合新模板的要求。</p><h3>4.3 加载 <code>qconfig_dtypes.pt</code> 文件</h3><p>使用 <code>LoadFromFileTemplate</code> 加载旧版本模板 qconfig\_dtypes.pt 时，为确保与旧版本行为相适配，必须对特定参数予以配置。否则，可能会面临加载 calib/qat 权重失败的问题。以下为相关参数的详细阐述：</p><ol><li>对于 <code>QconfigSetter()</code>，应将“enable\_optimize”参数配置为“False”，以此避免启用任何新版本中的默认优化。</li><li>针对 <code>LoadFromFileTemplate()</code>，务必将“only\_set\_mod\_in\_graph”参数配置为“False”。原因在于，在老版本配置中，存在对非 graph 中的操作进行 qconfig 设置的情形。</li><li>在执行 <code>prepare</code> 操作时，需将“fuse\_mode”参数配置为“FuseMode.BNAddReLU”，进而实现与老版本行为的对齐。</li></ol><p><strong>以下为完整的使用示例：</strong></p><pre><code class="Plain">import torch
from horizon_plugin_pytorch.quantization import  prepare,set_fake_quantize,FakeQuantState
from horizon_plugin_pytorch.quantization import get_qconfig 
from horizon_plugin_pytorch.quantization.qconfig_setter import *

my_qconfig_setter=QconfigSetter(
    reference_qconfig=get_qconfig(observer=MSEObserver),
    templates=[
        ModuleNameTemplate(
        { #1.适配fix_scale的配置
          "backbone.quant":{"dtype":qint8,"threshold":1.0},
          }
        #2.Load旧模板下保存的qconfig_dtypes.pt
        LoadFromFileTemplate(
        "./qconfig_old/qconfig_dtypes.pt",
        #3.该参数需要设置 False，原来配置中有对非 graph 中的 op 设置 qconfig
        only_set_mod_in_graph=False,
    ),],
    save_dir=args.output_dir,
    #4.无需开启任何优化,关闭enable_optimize
    enable_optimize=False,
    )
from horizon_plugin_pytorch.quantization.fx.fusion_patterns import FuseMode
qat_model = prepare(
    float_model,
    example_inputs=example_input,
    qconfig_setter=my_qconfig_setter,
    check_result_dir=args.output_dir,
    #5.对齐老版本的融合行为
    fuse_mode=FuseMode.BNAddReLU,
    )
          </code></pre>]]></description></item><item>    <title><![CDATA[打造专属知识大脑：个人电脑上的本地私有知]]></title>    <link>https://segmentfault.com/a/1190000047438816</link>    <guid>https://segmentfault.com/a/1190000047438816</guid>    <pubDate>2025-11-30 16:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>打造专属知识大脑：个人电脑上的本地私有知识库全攻略</h2><h3>为什么你需要一个本地私有知识库？</h3><p>想象一下：当你突然需要查找半年前读过的那篇精彩文章，或者在会议中急需某个重要数据，却发现自己收藏的内容散落在微信、浏览器、笔记软件等十几个地方...这种场景是不是很熟悉？</p><p>在信息爆炸的时代，我们每天都在接收海量信息，但真正能内化为个人知识资产的却少之又少。这就是为什么你需要一个<strong>本地私有知识库</strong>——它就像是为你的大脑配备了一个外接硬盘，帮你：</p><ul><li><strong>永久保存</strong>重要资料，不再担心链接失效</li><li><strong>快速检索</strong>任何信息，秒级找到所需内容</li><li><strong>建立知识连接</strong>，让零散信息形成知识网络</li><li><strong>完全私密安全</strong>，所有数据都保存在你的电脑上</li></ul><h3>本地私有知识库的核心优势</h3><h4>数据安全，完全掌控</h4><p>与云端存储不同，本地知识库的所有数据都保存在你的个人设备上。这意味着：</p><ul><li>不用担心服务商突然停止运营</li><li>不会因为账号问题丢失珍贵资料</li><li>敏感信息完全由自己掌控</li></ul><h4>离线可用，随时随地</h4><p>即使没有网络连接，你依然可以：</p><ul><li>查看所有已保存的内容</li><li>进行全文检索</li><li>整理和编辑知识</li></ul><h4>个性化定制，贴合习惯</h4><p>你可以按照自己的思维习惯来组织知识结构，打造真正属于自己的知识体系。</p><h3>优秀本地知识库推荐：访答知识库</h3><p>在众多知识库软件中，知识库以其出色的用户体验和强大的功能脱颖而出。</p><h4>为什么选择访答？</h4><p><strong>智能收集，一键归档</strong>  <br/>访答支持从网页、文档、图片等多种来源快速收集信息。遇到有价值的内容，只需简单操作就能将其纳入你的知识体系。</p><p><strong>强大的关联能力</strong>  <br/>它能够自动识别内容间的关联性，帮助你发现知识之间的内在联系，让零散的信息形成有机的知识网络。</p><p><strong>流畅的搜索体验</strong>  <br/>基于本地索引的搜索功能，让你在数千条记录中也能秒级找到目标内容，大大提升知识复用效率。</p><p><strong>简洁优雅的界面</strong>  <br/>清爽的界面设计让知识管理变成一种享受，而不是负担。</p><h4>我的使用体验</h4><p>自从开始使用构建个人知识库，我的工作效率得到了显著提升。以前需要花费半小时查找的资料，现在几秒钟就能找到。更重要的是，通过持续的知识积累，我开始发现不同领域知识间的奇妙联系，这为我的创作和工作带来了源源不断的灵感。</p><h3>如何开始构建你的知识库？</h3><h4>第一步：明确需求</h4><p>先思考你主要想管理哪些类型的知识：</p><ul><li>工作文档和项目资料</li><li>学习笔记和研究材料</li><li>灵感收集和创意素材</li><li>个人生活和兴趣内容</li></ul><h4>第二步：选择合适的工具</h4><p>根据你的需求和技术水平选择合适的知识库软件。如果你注重易用性和美观度，是个不错的选择。</p><h4>第三步：建立分类体系</h4><p>不要一开始就追求完美的分类结构。建议：</p><ul><li>从简单的几个大类开始</li><li>随着内容增多再逐步细化</li><li>善用标签系统进行多维度分类</li></ul><h4>第四步：养成收集习惯</h4><p>知识库的价值在于持续积累：</p><ul><li>每天花10分钟整理当天收集的信息</li><li>定期回顾和整理旧内容</li><li>建立固定的知识处理流程</li></ul><h3>进阶技巧：让知识库真正为你所用</h3><h4>建立个人工作流</h4><p>将知识库融入你的日常工作流程：</p><ul><li>项目启动前先搜索相关经验</li><li>会议前快速回顾背景资料</li><li>定期从知识库中提炼总结</li></ul><h4>知识复利效应</h4><p>随着时间的推移，你的知识库会像滚雪球一样产生复利效应：</p><ul><li>新旧知识相互碰撞产生新见解</li><li>积累的专业知识形成个人竞争力</li><li>减少重复学习和查找的时间浪费</li></ul><h3>立即开始，打造你的第二大脑</h3><p>不要再让宝贵的知识和灵感流失在信息的海洋中。选择一个合适的本地私有知识库，比如，开始构建属于你自己的知识体系。</p><p>记住，知识管理的核心不是工具本身，而是持续积累和有效利用的习惯。从今天开始，每天花一点点时间整理知识，一年后你会惊喜地发现，自己已经拥有了一个强大的个人知识资产。</p><p>你的知识，值得被更好地管理和利用。现在就开始行动吧！</p><p><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdndal" alt="" title=""/></p>]]></description></item><item>    <title><![CDATA[AI技术驱动下的招聘行业转型 爱跑步的香]]></title>    <link>https://segmentfault.com/a/1190000047438744</link>    <guid>https://segmentfault.com/a/1190000047438744</guid>    <pubDate>2025-11-30 13:02:11</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>AI技术驱动下的招聘行业转型<br/>当前招聘领域正经历深刻变革，智能化转型已成为不可逆转的趋势。过去一年间，人力资源行业在AI技术的推动下呈现出明显的分化态势：部分企业仍采用传统的人工筛选、沟通方式，而领先企业已实现全流程智能化管理。<br/>多项数据显示，AI技术正在重塑招聘行业的效率标准，具体表现为以下案例与数据：<br/>•智联招聘采用AI全托管系统后，招聘周期缩短40%；<br/>•某大型国有银行运用AI技术将面试到场率提升至90.7%；<br/>•辉瑞制药通过AI技能图谱精准识别人才缺口，研发创新周期缩短22%；<br/>•49.6%的企业已完成HR流程的AI优化；<br/>•ING银行将AI应用于组织健康诊断与薪酬策略，管理决策效率提升50%。<br/>这些案例表明，AI技术已从单纯的效率工具，逐步发展为能够辅助招聘及管理决策的重要支持系统，其应用价值在多个环节得到充分体现。</p><p>一、AI面试评分的科学化应用<br/>传统招聘中主观判断因素较多，评估结果易受个人经验影响，而AI面试系统通过建立标准化评估体系，有效提升了人才评估的准确性与客观性，核心实现方式包括：<br/>•采用效标效度与重测稳定信度双指标验证体系，确保评估标准的科学性；<br/>•经过大规模人机背靠背实验验证，不断优化评估模型；<br/>•评估结果与资深面试官判断高度一致，具备实际应用价值。<br/>目前，最新版本的AI面试系统已进一步提升技术成熟度，其评分结果可直接为招聘决策提供参考依据。<br/>二、全流程精准化设计<br/>AI系统贯穿招聘全流程，通过功能优化实现各环节的精准赋能，打破了传统工具的应用局限，具体优势体现在：<br/>•一问多能：单道面试题可同步评估多项胜任力指标，使评估效率提升50%以上；<br/>•智能追问：基于语义理解技术实时生成针对性追问，确保核心能力评估的完整性；<br/>•简历深度分析：自动识别候选人简历中的能力亮点与信息疑点，辅助HR高效筛选；<br/>•全维度测评：覆盖通用能力与专业技能两大维度，支持根据岗位需求自动生成测评题目。<br/>凭借这些功能优势，AI招聘系统已在初筛及技术复试等关键环节发挥重要作用，成为招聘团队的核心辅助工具。<br/>三、候选人体验优化<br/>针对早期AI面试系统存在的体验不佳问题，新一代系统从候选人需求出发进行全面升级，通过人性化设计提升面试参与度，具体改进包括：<br/>•新增情绪识别与引导功能，实时感知候选人状态并给予适当提示，提升其表现稳定性；<br/>•采用无断点交互设计，模拟真实面试中的对话场景，降低使用陌生感；<br/>•优化视觉呈现效果，增强场景沉浸感，提升整体面试体验；<br/>•支持多轮问答互动，及时解答候选人关于面试流程的疑问，减少信息不对称。<br/>在人才竞争日益激烈的市场环境下，优质的面试体验已成为企业雇主品牌建设的重要组成部分，AI系统的体验优化对此具有积极意义。<br/>四、全流程自动化人才寻访<br/>除面试评估环节外，AI技术在人才寻访领域的应用也实现了突破性进展，自动化人才寻访系统完成了从人才识别到信息录入的全流程智能化覆盖，核心功能包括：<br/>•快速初始化部署：可根据企业招聘需求快速完成系统配置，缩短上线周期；<br/>•自动筛选与智能沟通：基于岗位画像自动筛选匹配人才，并通过智能话术完成初步沟通；<br/>•全覆盖应答机制：针对候选人常见问题实现24小时自动应答，提升沟通效率；<br/>•数据自动同步：将候选人信息及沟通记录自动同步至企业HR系统，实现数据无缝对接。<br/>该系统的应用显著降低了人才寻访环节的人工成本，提升了整体招聘效率与人才匹配精准度。<br/>五、技术应用的验证路径<br/>为帮助企业降低AI技术应用风险，目前相关AI招聘系统已提供实际场景验证渠道，企业用户可在真实的招聘环境中，对系统在面试、测评、筛选等多个环节的效果进行全面测试。这种低风险的体验途径，为招聘团队了解并应用AI技术提供了便利。<br/>从应用实践来看，多家知名企业及高校已引入这类AI招聘工具，其实际应用效果获得了行业认可。当前，AI招聘技术的发展重点集中于精准选人与体验提升两大方向，最新版本的系统在这两个维度均展现出较高的技术水平，为招聘行业的智能化转型提供了有力支撑。</p>]]></description></item><item>    <title><![CDATA[连接池的价值与风险——池化提升与资源枯竭]]></title>    <link>https://segmentfault.com/a/1190000047438753</link>    <guid>https://segmentfault.com/a/1190000047438753</guid>    <pubDate>2025-11-30 13:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <blockquote>连接池是现代应用架构中的基础设施，用好了是性能加速器，配置不当则成为系统崩溃的导火索</blockquote><p>在数据库应用系统中，连接管理是影响性能的关键因素之一。数据库连接池通过池化技术将昂贵的数据库连接进行复用，显著提升了系统性能，但不当的配置和使用也会导致资源枯竭甚至系统崩溃。本文将深入探讨连接池的工作机制、优化策略以及风险防范，帮助开发者掌握这一强大而危险的工具。</p><h2>1 连接池的本质与演进历程</h2><h3>1.1 连接池解决的核心问题</h3><p>在传统的数据库访问模式中，应用程序每次需要与数据库交互时都会创建新的连接，完成操作后立即关闭。这种方式存在明显的性能缺陷：建立数据库连接是​<strong>昂贵操作</strong>​，通常需要 10-20ms 的耗时，涉及 TCP 三次握手、数据库身份验证和会话初始化等多个步骤 。</p><p>连接池通过<strong>连接复用</strong>机制解决了这一性能瓶颈。它在系统初始化时创建一定数量的数据库连接并维护在池中，当应用程序需要连接时，直接从池中获取空闲连接而非新建，使用完毕后归还给连接池而非实际关闭 。这种机制特别适合 Web 应用等高并发场景，其中大量短生命周期请求频繁访问数据库 。</p><h3>1.2 连接池的演进历程</h3><p>连接池技术经历了从简单到复杂、从功能单一到智能管理的演进过程。早期连接池如 DBCP 和 C3P0 奠定了基本模式，现代连接池如 HikariCP 和 Druid 则在性能和可观测性方面有了显著提升 。</p><p><strong>HikariCP</strong> 以其极简设计和卓越性能成为 Spring Boot 的默认连接池，它通过无锁并发结构和字节码优化实现了在高并发场景下的优异表现 。<strong>Druid</strong> 则提供了更为全面的功能，包括 SQL 监控、防御注入攻击和可视化界面，适合需要深度监控的复杂企业环境 。</p><h2>2 连接池的核心价值与性能提升机制</h2><h3>2.1 性能提升的三重机制</h3><p>连接池通过三种核心机制提升系统性能：<strong>连接复用</strong>避免了频繁创建和销毁连接的开销，使系统能够将资源集中于业务处理而非连接管理 。<strong>连接预热</strong>在系统启动阶段初始化连接，保证服务就绪后立即具备处理能力，避免首批请求的冷启动延迟 。<strong>统一管理</strong>通过参数配置实现连接的合理分配和故障转移，提高系统稳定性 。</p><h3>2.2 资源消耗优化</h3><p>连接池通过多种机制优化资源使用：<strong>资源回收</strong>自动关闭空闲超时连接，防止资源泄露 。<strong>弹性伸缩</strong>根据系统负载动态调整活跃连接数，平衡性能与资源消耗 。<strong>失效检测</strong>通过心跳机制识别并替换失效连接，保证连接可用性 。</p><h2>3 连接池的潜在风险与资源枯竭场景</h2><h3>3.1 连接泄露与池耗尽</h3><p><strong>连接泄露</strong>是连接池最常见的问题，当应用程序获取连接后未正确释放，会导致池中可用连接逐渐减少直至耗尽 。典型场景包括异常路径下未在 finally 块中关闭连接、框架配置错误导致连接未归还等。</p><p><strong>连接池耗尽</strong>则发生在系统并发请求超过连接池最大容量时，新请求将陷入长时间等待或直接失败 。这种状况通常由突发流量、慢查询累积或下游系统故障引发。</p><h3>3.2 错误配置的连锁反应</h3><p>不合理的参数配置会引发多种问题：<strong>过大连接数</strong>可能压垮数据库，导致级联故障 。<strong>过长等待时间</strong>会耗尽应用服务器资源，造成系统假死 。<strong>不足验证</strong>会导致应用使用无效连接，增加业务失败率 。</p><h2>4 关键配置参数与调优策略</h2><h3>4.1 容量规划参数</h3><p>​<strong>最大连接数</strong>​（maxActive/maximumPoolSize）是连接池最重要的参数，直接影响系统最大并发能力。设置过小会导致请求阻塞，设置过大会增加数据库负担 。经验公式为：<code>最大连接数 = (核心数 * 2) + 磁盘数</code>，但需根据实际业务测试调整 。</p><p>​<strong>最小空闲连接</strong>​（minIdle/minimumIdle）决定了池中保持的最小空闲连接数，合理设置可以平衡突发流量响应与资源消耗 。通常设置为最大连接数的 25%-50%，根据业务波动特征调整 。</p><h3>4.2 健康检测参数</h3><p>​<strong>验证查询</strong>​（validationQuery）是简单的 SQL 语句（如 SELECT 1），用于检查连接是否有效 。​<strong>测试策略</strong>​（testOnBorrow/testWhileIdle）决定了何时执行验证，<code>testWhileIdle</code> 模式在性能与可靠性间提供了较好平衡 。</p><p>​<strong>存活时间</strong>​（maxLifetime）控制连接最大存活时间，避免长期运行导致的隐性问题 。​<strong>空闲超时</strong>​（idleTimeout）自动回收闲置连接，释放资源 。</p><h2>5 监控指标与故障诊断</h2><h3>5.1 核心监控指标</h3><p><strong>活跃连接数</strong>反映系统当前负载，持续接近最大值表明需要扩容 。<strong>等待线程数</strong>显示排队等待连接的请求数，非零值表示连接不足 。<strong>连接获取时间</strong>直接影响用户体验，突增通常预示问题 。</p><h3>5.2 故障诊断流程</h3><p>当出现连接池问题时，系统化的诊断流程至关重要：首先检查​<strong>基础指标</strong>​，确认活跃连接、等待线程等关键数据 。然后分析​<strong>等待链</strong>​，找出持有连接时间过长的操作 。最后检查​<strong>系统资源</strong>​，确认数据库负载和网络状况 。</p><h2>6 不同场景下的配置策略</h2><h3>6.1 高并发 Web 应用</h3><p>对于在线交易类应用，推荐配置：较小​<strong>最大连接数</strong>​（20-100）避免数据库过载，较短​<strong>最大等待时间</strong>​（1-3 秒）快速失败而非阻塞，启用<strong>泄露检测</strong>快速定位未关闭连接 。</p><h3>6.2 批处理与报表系统</h3><p>对于长时间运行的数据处理任务，适合的配置包括：适中​<strong>连接数</strong>​（10-30）减少数据库压力，较长<strong>超时设置</strong>适应复杂查询，开启<strong>事务隔离</strong>保证数据一致性 。</p><h2>7 连接池选型指南</h2><h3>7.1 性能优先场景</h3><p><strong>HikariCP</strong> 是性能敏感场景的首选，其极简设计和高并发性能表现优异 。适合微服务架构和云原生环境，特别是容器化部署的轻量级应用 。</p><h3>7.2 可观测性优先场景</h3><p><strong>Druid</strong> 提供丰富的监控功能，适合需要详细连接统计和 SQL 分析的企业环境 。内置防 SQL 注入和慢查询检测功能，为复杂应用提供全方位保护 。</p><h2>总结</h2><p>连接池是现代应用架构中的关键组件，正确使用可以提升性能几个数量级，配置不当则会导致系统脆弱不堪。成功的连接池管理需要深入理解业务特征、持续监控关键指标以及建立完善的故障处理机制。</p><p>连接池优化不是一次性的任务，而是需要随着业务发展不断调整的持续过程。通过科学的容量规划、细致的监控预警和快速的故障响应，可以最大化连接池的价值，避免资源枯竭风险。</p><hr/><p><strong>📚 下篇预告</strong>​</p><p>《MyBatis 设计观——映射思想、动态 SQL 的边界与可维护性考量》—— 我们将深入探讨：</p><ul><li>🗺️ ​<strong>ORM 映射哲学</strong>​：MyBatis 如何平衡数据库操作与面向对象思维的鸿沟</li><li>🔄 ​<strong>动态 SQL 边界</strong>​：何时使用动态 SQL，何时应该避免过度灵活带来的复杂性</li><li>🏗️ ​<strong>架构可维护性</strong>​：MyBatis 项目结构与配置组织的最佳实践</li><li>⚡ ​<strong>性能优化策略</strong>​：MyBatis 缓存机制与 SQL 执行过程的调优要点</li><li>🔍 ​<strong>代码生成与手写平衡</strong>​：如何在开发效率与控制力之间找到最佳平衡点</li></ul><p><strong>​点击关注，掌握 MyBatis 设计的精髓！​</strong>​</p><blockquote><p>​<strong>今日行动建议</strong>​：</p><ol><li>检查当前项目连接池配置，对比本文推荐值进行合理性评估</li><li>在测试环境模拟连接泄露场景，验证监控告警有效性</li><li>对关键业务接口进行压力测试，确定连接池参数的最优值</li><li>建立连接池监控仪表盘，跟踪核心指标变化趋势</li></ol></blockquote>]]></description></item><item>    <title><![CDATA[【URP】Unity[内置Shader]]]></title>    <link>https://segmentfault.com/a/1190000047438702</link>    <guid>https://segmentfault.com/a/1190000047438702</guid>    <pubDate>2025-11-30 12:03:00</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <blockquote><a href="https://link.segmentfault.com/?enc=x2UIDTjMy30QedSAazUgnQ%3D%3D.LFI0ucK6di2ZW8gxLKjdiWPGeLaJ4HtFlEwe7oVXWnpnh4F1EPMsdZDzVKsOR%2FUC9MYX%2BVS%2FYUPD3aijcVJZoOlJAJlcJ42qi%2Bsa2oBSezflTeH6uQynczL%2Blm3wmOTXi3mhDcvunX30NN%2Fqy6tJ7UZrR9dLSNrLGCzrbLjcttetuNmiY83sNQLosvJReRH05o6mtqRuyk%2BjP3zq6uCTVKKi8P3kVONwvUPqqdPJcLs%3D" rel="nofollow" target="_blank">【从UnityURP开始探索游戏渲染】</a><strong>专栏-直达</strong></blockquote><h2><strong>URP内置Unlit Shader的作用与原理</strong></h2><p><a href="https://link.segmentfault.com/?enc=fs%2F%2F%2BRXwo1wf8sx8L6ogag%3D%3D.shou9%2FoPJ%2FEq8xnXfUuE5qj%2BoJs8SVkc0XsbVsiuH9P9kG%2FvMUY%2Fb0llbMLODkTMKQG8RO9Wpz87nqQ8PrOEpsQU3X%2BymEsH9oyTcaHFTTFCL90Pdhe9a%2BFCS%2FRgRxVgzWMWsCOI2GyyX5dNRf5DRw%3D%3D" rel="nofollow" target="_blank">Unlit Shader</a>是Unity通用渲染管线(URP)中的基础着色器，主要用于渲染不受光照影响的物体。其核心原理是通过直接采样纹理或颜色值输出到屏幕，跳过了复杂的光照计算流程。这种着色器特别适合UI元素、粒子特效、全息投影等需要保持恒定亮度的场景，因为它的渲染结果不会随光照环境变化而改变。</p><p>在URP架构中，Unlit Shader通过ShaderLab语法定义，内部使用HLSL编写核心逻辑。与Built-in管线相比，URP版本优化了渲染流程，包含三个关键Pass：主绘制Pass、深度Only Pass和元数据Pass（用于光照烘焙）。其核心特点是：</p><ul><li>无光照计算：直接输出Albedo颜色或纹理采样结果</li><li>支持Alpha混合：可实现透明效果</li><li>移动端优化：减少了GPU指令数量</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438704" alt="" title=""/></p><h2><strong>发展历史演变</strong></h2><p>Unlit Shader随着Unity渲染管线的演进经历了三个阶段：</p><ul><li>‌<strong>Built-in管线时期</strong>‌（2012-2018）：最初作为简单着色器出现在标准资源包中，使用CG语言编写，功能较为基础</li><li>‌<strong>LWRP过渡期</strong>‌（2018-2020）：轻量级渲染管线中首次针对移动平台优化，引入HLSL替代CG</li><li>‌<strong>URP成熟期</strong>‌（2020至今）：成为Universal RP的核心组件，支持Shader Graph可视化编程，并优化了多Pass协作机制</li></ul><h2><strong>具体使用示例</strong></h2><p>创建Unlit材质的基本步骤：</p><ul><li>在Project窗口右键创建Material</li><li>材质Inspector中选择Shader路径："Universal Render Pipeline/Unlit"</li><li><p>配置基础属性：</p><ul><li>‌<strong>Base Map</strong>‌：主纹理贴图</li><li>‌<strong>Base Color</strong>‌：色调叠加</li><li>‌<strong>Alpha</strong>‌：透明度控制</li></ul></li></ul><p>代码说明：</p><ul><li>定义包含纹理和颜色属性的基础Unlit Shader</li><li>使用URP核心库中的TransformObjectToHClip方法进行坐标转换</li><li>片元着色器直接返回纹理采样结果与颜色的乘积</li><li><p>UnlitExample.shader</p><pre><code class="c">Shader "Custom/UnlitTexture"
{
    Properties {
        _MainTex ("Texture", 2D) = "white" {}
        _Color ("Color", Color) = (1,1,1,1)
    }
    SubShader {
        Tags { "RenderType"="Opaque" }
        Pass {
            HLSLPROGRAM
            #pragma vertex vert
            #pragma fragment frag
            #include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl"

            struct Attributes {
                float4 positionOS : POSITION;
                float2 uv : TEXCOORD0;
            };

            struct Varyings {
                float4 positionCS : SV_POSITION;
                float2 uv : TEXCOORD0;
            };

            sampler2D _MainTex;
            float4 _Color;

            Varyings vert(Attributes IN) {
                Varyings OUT;
                OUT.positionCS = TransformObjectToHClip(IN.positionOS.xyz);
                OUT.uv = IN.uv;
                return OUT;
            }

            half4 frag(Varyings IN) : SV_Target {
                return tex2D(_MainTex, IN.uv) * _Color;
            }
            ENDHLSL
        }
    }
}</code></pre></li><li><p>UnlitGraph.shadergraph</p><pre><code class="c">{
    "m_Nodes": [
        {
            "m_Id": "d4f5e3c7-1a2d-4b8f-a3e1-6c9b8d2e1f0a",
            "m_Type": "UnityEditor.ShaderGraph.Texture2DNode",
            "m_Position": { "x": -208, "y": -16 },
            "m_Outputs": [ { "m_Id": "out" } ],
            "m_Texture": { "m_DefaultValue": {} }
        },
        {
            "m_Id": "a1b2c3d4-e5f6-7g8h-9i0j-k1l2m3n4o5p6",
            "m_Type": "UnityEditor.ShaderGraph.ColorNode",
            "m_Position": { "x": -200, "y": 100 },
            "m_Outputs": [ { "m_Id": "out" } ],
            "m_Color": { "r": 1, "g": 1, "b": 1, "a": 1 }
        },
        {
            "m_Id": "b2c3d4e5-f6g7-8h9i-0j1k-l2m3n4o5p6q7",
            "m_Type": "UnityEditor.ShaderGraph.MultiplyNode",
            "m_Position": { "x": 0, "y": 0 },
            "m_Inputs": [
                { "m_Id": "a", "m_SlotId": 0 },
                { "m_Id": "b", "m_SlotId": 1 }
            ],
            "m_Outputs": [ { "m_Id": "out" } ]
        }
    ],
    "m_Edges": [
        { "m_OutputSlot": "d4f5e3c7-1a2d-4b8f-a3e1-6c9b8d2e1f0a.out", "m_InputSlot": "b2c3d4e5-f6g7-8h9i-0j1k-l2m3n4o5p6q7.a" },
        { "m_OutputSlot": "a1b2c3d4-e5f6-7g8h-9i0j-k1l2m3n4o5p6.out", "m_InputSlot": "b2c3d4e5-f6g7-8h9i-0j1k-l2m3n4o5p6q7.b" }
    ]
}</code></pre></li></ul><h2><strong>Shader Graph应用示例</strong></h2><p>在Shader Graph中创建Unlit效果的步骤：</p><ul><li>创建新的Shader Graph文件（右键 &gt; Create &gt; Shader &gt; Universal Render Pipeline &gt; Unlit Shader Graph）</li><li><p>核心节点配置：</p><ul><li>添加‌<strong>Sample Texture 2D</strong>‌节点作为基础纹理输入</li><li>连接‌<strong>Color</strong>‌参数节点实现色调控制</li><li>使用‌<strong>Multiply</strong>‌节点混合纹理和颜色</li></ul></li><li><p>高级功能扩展：</p><ul><li>添加‌<strong>Time</strong>‌节点驱动UV动画</li><li>通过‌<strong>Vertex Position</strong>‌节点实现顶点变形</li></ul></li></ul><p>代码说明：</p><ul><li>构建包含纹理采样和颜色混合的基础Unlit着色器</li><li>通过节点连接实现材质属性的可视化编辑</li><li>可扩展添加UV滚动、顶点动画等高级效果</li><li><p>UnlitExample.shader</p><pre><code class="c">Shader "Custom/UnlitTexture"
{
    Properties {
        _MainTex ("Texture", 2D) = "white" {}
        _Color ("Color", Color) = (1,1,1,1)
    }
    SubShader {
        Tags { "RenderType"="Opaque" }
        Pass {
            HLSLPROGRAM
            #pragma vertex vert
            #pragma fragment frag
            #include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl"

            struct Attributes {
                float4 positionOS : POSITION;
                float2 uv : TEXCOORD0;
            };

            struct Varyings {
                float4 positionCS : SV_POSITION;
                float2 uv : TEXCOORD0;
            };

            sampler2D _MainTex;
            float4 _Color;

            Varyings vert(Attributes IN) {
                Varyings OUT;
                OUT.positionCS = TransformObjectToHClip(IN.positionOS.xyz);
                OUT.uv = IN.uv;
                return OUT;
            }

            half4 frag(Varyings IN) : SV_Target {
                return tex2D(_MainTex, IN.uv) * _Color;
            }
            ENDHLSL
        }
    }
}</code></pre></li><li><p>UnlitGraph.shadergraph</p><pre><code class="c">{
    "m_Nodes": [
        {
            "m_Id": "d4f5e3c7-1a2d-4b8f-a3e1-6c9b8d2e1f0a",
            "m_Type": "UnityEditor.ShaderGraph.Texture2DNode",
            "m_Position": { "x": -208, "y": -16 },
            "m_Outputs": [ { "m_Id": "out" } ],
            "m_Texture": { "m_DefaultValue": {} }
        },
        {
            "m_Id": "a1b2c3d4-e5f6-7g8h-9i0j-k1l2m3n4o5p6",
            "m_Type": "UnityEditor.ShaderGraph.ColorNode",
            "m_Position": { "x": -200, "y": 100 },
            "m_Outputs": [ { "m_Id": "out" } ],
            "m_Color": { "r": 1, "g": 1, "b": 1, "a": 1 }
        },
        {
            "m_Id": "b2c3d4e5-f6g7-8h9i-0j1k-l2m3n4o5p6q7",
            "m_Type": "UnityEditor.ShaderGraph.MultiplyNode",
            "m_Position": { "x": 0, "y": 0 },
            "m_Inputs": [
                { "m_Id": "a", "m_SlotId": 0 },
                { "m_Id": "b", "m_SlotId": 1 }
            ],
            "m_Outputs": [ { "m_Id": "out" } ]
        }
    ],
    "m_Edges": [
        { "m_OutputSlot": "d4f5e3c7-1a2d-4b8f-a3e1-6c9b8d2e1f0a.out", "m_InputSlot": "b2c3d4e5-f6g7-8h9i-0j1k-l2m3n4o5p6q7.a" },
        { "m_OutputSlot": "a1b2c3d4-e5f6-7g8h-9i0j-k1l2m3n4o5p6.out", "m_InputSlot": "b2c3d4e5-f6g7-8h9i-0j1k-l2m3n4o5p6q7.b" }
    ]
}</code></pre></li></ul><p>实际应用时可结合粒子系统创建发光轨迹，或为UI元素添加动态高亮效果。URP Unlit Shader的轻量级特性使其在移动设备上能保持60fps以上的渲染性能</p><h2>典型应用场景及实现</h2><h3><strong>光晕效果（Halo）</strong></h3><ul><li>‌<strong>应用实例</strong>‌：角色技能特效、UI高亮提示。通过透明纹理实现边缘发光，如1中描述的透明光晕材质。</li><li><p>‌<strong>实现步骤</strong>‌：</p><ul><li>导入纹理并设置：<code>Texture Type</code>为<code>Default (sRGB)</code>，勾选<code>Alpha Is Transparency</code>，<code>Wrap Mode</code>设为<code>Clamp</code>。</li><li>创建材质：选择<code>Universal Render Pipeline/Unlit</code> Shader，设置<code>Surface Type</code>为<code>Transparent</code>，拖拽纹理到<code>Base Map</code>插槽。</li><li>调整<code>Tint</code>颜色控制光晕色彩。</li></ul></li></ul><h3><strong>全息投影效果</strong></h3><ul><li>‌<strong>应用实例</strong>‌：科幻场景中的虚拟角色或界面。结合透明度与扫描线纹理。</li><li><p>‌<strong>实现步骤</strong>‌：</p><ul><li>使用<code>Unlit</code> Shader并启用透明混合（<code>Blend SrcAlpha OneMinusSrcAlpha</code>）。</li><li>添加顶点偏移代码模拟全息抖动，通过<code>_Time</code>变量控制动态效果。</li><li>叠加扫描线纹理（如<code>_HologramLine1</code>）和菲涅尔反射增强立体感。</li></ul></li></ul><h3><strong>透明遮罩（如塑料薄膜）</strong></h3><ul><li>‌<strong>应用实例</strong>‌：UI遮罩或半透明装饰物。通过Alpha通道控制透明度，如中的塑料薄膜材质。</li><li><p>‌<strong>实现步骤</strong>‌：</p><ul><li>在图片编辑器中创建带Alpha通道的纹理，白色区域不透明，灰色区域半透明。</li><li>材质Shader选择<code>Unlit</code>，设置<code>Transparent</code>模式，纹理绑定到<code>Base Map</code>。</li></ul></li></ul><h3><strong>发光广告牌（Billboard）</strong></h3><ul><li>‌<strong>应用实例</strong>‌：游戏内固定亮度标识或霓虹灯。直接显示纹理颜色不受光照影响。</li><li><p>‌<strong>实现步骤</strong>‌：</p><ul><li>使用<code>Unlit</code> Shader，<code>Surface Type</code>设为<code>Opaque</code>。</li><li>通过<code>Base Map</code>设置发光纹理，调整<code>Tint</code>颜色增强亮度。</li></ul></li></ul><h3><strong>景深遮挡标记</strong></h3><ul><li>‌<strong>应用实例</strong>‌：半透明物体深度写入（如玻璃瓶），解决景深效果失效问题。</li><li><p>‌<strong>实现步骤</strong>‌：</p><ul><li>创建两个材质：一个透明材质（<code>Queue=Transparent</code>），一个深度写入材质（<code>Queue=2000</code>）。</li><li>深度写入材质使用<code>Unlit</code> Shader并启用<code>ZWrite On</code>。</li></ul></li></ul><h3><strong>关键注意事项</strong></h3><ul><li>‌<strong>渲染顺序</strong>‌：透明物体需关闭深度写入（<code>ZWrite Off</code>），并合理设置<code>Queue</code>标签避免混合错误。</li><li>‌<strong>性能优化</strong>‌：复杂效果（如全息投影）建议结合顶点着色器计算，减少片元着色器负担</li></ul><hr/><blockquote><a href="https://link.segmentfault.com/?enc=Ci3ZLiUmcKa4b0JOuyV1EQ%3D%3D.8clYuyajqYqNn6lBHE2R7WwhnMvimiLgnmGNuMCM9Rj7cU5bEc1HPWJDngLwJqx1zQkezpYq4utFdXz8nEe5heLe%2Bx01J4Ts3s8XF%2FD%2BFyX%2BqixXC8ZBguV2jlyI82NbJxlhZMqG7X2HE2q%2FxEO3tERzyI8nF1jkQpmSwConE542K66ds%2BjoDRMOgIln%2BtFogND6nsKvWsbuTOejKdlNZEqTZfxnxblweXN7Ux5Bmh0%3D" rel="nofollow" target="_blank">【从UnityURP开始探索游戏渲染】</a><strong>专栏-直达</strong><br/>（欢迎<em>点赞留言</em>探讨，更多人加入进来能更加完善这个探索的过程，🙏）</blockquote>]]></description></item><item>    <title><![CDATA[基于DCT的彩色图像压缩MATLAB实现]]></title>    <link>https://segmentfault.com/a/1190000047438739</link>    <guid>https://segmentfault.com/a/1190000047438739</guid>    <pubDate>2025-11-30 12:02:09</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h4><strong>一、核心流程</strong></h4><p>基于DCT的图像压缩遵循JPEG标准的核心步骤，具体流程如下：</p><ol><li><strong>颜色空间转换</strong>：将RGB图像转换为YCbCr空间，分离亮度（Y）与色度（Cb/Cr）分量。</li><li><strong>分块DCT变换</strong>：将每个通道划分为8×8块，进行二维DCT变换。</li><li><strong>量化</strong>：根据人眼视觉特性设计量化表，对DCT系数进行量化。</li><li><strong>熵编码</strong>：采用Zigzag扫描、游程编码和霍夫曼编码压缩量化后的数据。</li><li><strong>解压缩</strong>：逆向执行熵解码、反量化、逆DCT变换，重构图像。</li></ol><hr/><h4><strong>二、MATLAB代码实现</strong></h4><h5><strong>1. 颜色空间转换与分块</strong></h5><pre><code class="matlab">% 读取图像并转换为YCbCr
img = imread('lena.jpg');
if size(img,3) == 3
    img_ycbcr = rgb2ycbcr(img);
    Y = img_ycbcr(:,:,1);
    Cb = img_ycbcr(:,:,2);
    Cr = img_ycbcr(:,:,3);
else
    Y = img;
    Cb = [];
    Cr = [];
end

% 分块处理（8x8）
block_size = 8;
[rows, cols] = size(Y);
num_blocks_row = ceil(rows / block_size);
num_blocks_col = ceil(cols / block_size);</code></pre><h5><strong>2. DCT变换与量化</strong></h5><pre><code class="matlab">% 定义量化表（JPEG标准）
luminance_quant = [16 11 10 16 24 40 51 61;
                  12 12 14 19 26 58 60 55;
                  14 13 16 24 40 57 69 56;
                  14 17 22 29 51 87 80 62;
                  18 22 37 56 68 109 103 77;
                  24 35 55 64 81 104 113 92;
                  49 64 78 87 103 121 120 101;
                  72 92 95 98 112 100 103 99];

% DCT变换与量化函数
function quant_block = dct_quant(block, quant_table, quality)
    dct_block = dct2(block);
    scale = 100 / quality;  % 质量因子调整量化强度
    quant_block = round(dct_block ./ (quant_table * scale));
end

% 对每个块进行DCT和量化
Y_compressed = zeros(size(Y));
for i = 1:num_blocks_row
    for j = 1:num_blocks_col
        % 提取块
        row = (i-1)*block_size + 1 : min(i*block_size, rows);
        col = (j-1)*block_size + 1 : min(j*block_size, cols);
        block = Y(row,col);
        
        % DCT与量化
        quant_block = dct_quant(block, luminance_quant, 80);
        Y_compressed(row,col) = quant_block;
    end
end</code></pre><h5><strong>3. Zigzag扫描与熵编码</strong></h5><pre><code class="matlab">% Zigzag扫描
function zigzag_vec = zigzag_scan(block)
    zigzag_order = [1,2,6,7,15,16,28,29,3,5,8,14,17,27,30,43,4,9,13,18,26,31,42,44,10,12,19,25,32,41,45,54,11,20,24,33,40,46,53,21,23,34,39,48,52,55,22,35,38,47,51,56,29,50,60,61,62,63,64];
    flat_block = block(:);
    zigzag_vec = flat_block(zigzag_order(1:numel(flat_block)));
end

% 示例：对量化后的块进行Zigzag扫描
zigzag_data = [];
for i = 1:block_size
    for j = 1:block_size
        block = Y_compressed((i-1)*block_size+1:i*block_size, (j-1)*block_size+1:j*block_size);
        zigzag_data = [zigzag_data, zigzag_scan(block)];
    end
end</code></pre><h5><strong>4. 霍夫曼编码</strong></h5><pre><code class="matlab">% 霍夫曼编码（使用MATLAB内置函数）
huff_dict = huffmandict([0:255], [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64]);
encoded_data = huffmandeco(zigzag_data, huff_dict);</code></pre><h5><strong>5. 解压缩与逆变换</strong></h5><pre><code class="matlab">% 逆量化
dequant_block = quant_block .* (quant_table * scale);

% 逆DCT变换
idct_block = idct2(dequant_block);

% 合并块并转换回RGB
reconstructed_Y = zeros(rows,cols);
block_idx = 1;
for i = 1:num_blocks_row
    for j = 1:num_blocks_col
        % 提取逆量化块
        row = (i-1)*block_size + 1 : min(i*block_size, rows);
        col = (j-1)*block_size + 1 : min(j*block_size, cols);
        dequant_block = reshape(encoded_data(block_idx:block_idx+63), [8,8]);
        reconstructed_Y(row,col) = idct_block;
        block_idx = block_idx + 64;
    end
end

% 合并通道并转换回RGB
reconstructed_img = cat(3, reconstructed_Y, Cb, Cr);
reconstructed_img = ycbcr2rgb(reconstructed_img);</code></pre><h4><strong>三、性能评估</strong></h4><pre><code class="matlab">% 计算PSNR
original = im2double(img);
reconstructed = im2double(reconstructed_img);
mse = mean((original(:) - reconstructed(:)).^2);
psnr = 10 * log10(1 / mse);

% 计算压缩率
original_size = rows * cols;
compressed_size = numel(encoded_data);
compression_ratio = original_size / compressed_size;

disp(['PSNR: ', num2str(psnr), ' dB, 压缩率: ', num2str(compression_ratio), ':1']);</code></pre><h4><strong>四、优化点</strong></h4><ol><li><strong>量化表自适应调整</strong>：根据质量因子动态缩放量化表，平衡压缩率与质量。</li><li><strong>颜色空间优化</strong>：对Cb/Cr通道进行4:2:0下采样，减少数据量。</li><li><strong>快速DCT实现</strong>：使用<code>dctmtx</code>预生成变换矩阵，避免重复计算。</li><li><strong>并行分块处理</strong>：利用<code>parfor</code>加速大尺寸图像处理。</li></ol><h4><strong>五、实验结果示例</strong></h4><table><thead><tr><th>压缩质量</th><th>PSNR (dB)</th><th>压缩率 (原图:压缩图)</th><th>视觉质量</th></tr></thead><tbody><tr><td>100</td><td>45.2</td><td>1:1</td><td>几乎无损</td></tr><tr><td>80</td><td>38.7</td><td>4:1</td><td>细节轻微模糊</td></tr><tr><td>50</td><td>32.1</td><td>10:1</td><td>明显块效应</td></tr></tbody></table><p>参考代码  基于DCT的彩色图像压缩    www.youwenfan.com/contentsfa/82678.html</p><h4><strong>六、总结</strong></h4><p>通过上述步骤，可实现基于DCT的彩色图像压缩，核心在于分块DCT、量化表设计及熵编码。实际应用中需结合视觉特性优化量化策略，并通过PSNR等指标评估压缩效果。</p>]]></description></item><item>    <title><![CDATA[FFmpeg开发笔记（九十）采用FFmp]]></title>    <link>https://segmentfault.com/a/1190000047438168</link>    <guid>https://segmentfault.com/a/1190000047438168</guid>    <pubDate>2025-11-30 12:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>​FFmpeg是个经典的音视频处理开源框架，可是FFmpeg仅提供命令行方式，通过FFmpeg剪辑音视频只能在命令行下面操作，从而限制了普通用户掌握FFmpeg。</p><p>虽然《FFmpeg开发实战：从零基础到短视频上线》一书不仅给出了基于FFmpeg函数调用的示例代码，也给出了具体的ffmpeg操作命令，从而兼具FFmpeg的代码开发教程与FFmpeg的命令使用手册两种用途。但是普通用户并非开发者，用户更希望提供桌面程序那种可视化界面，通过鼠标简单操作就能实现音视频文件的剪辑操作。  <br/>FFBox便是一个FFmpeg套壳的多媒体转码百宝箱，它全链路支持：输入→滤镜→编码→输出。参数配置透明直观，对齐FFmpeg的原生用法。所有的FFmpeg参数公开透明，用户通过操作界面，即能同时学习FFmpeg的命令。相比大多数软件仅支持的简单滤镜，FFBox支持完整的流图和滤镜图编辑，可处理复杂的多输入多输出任务。  <br/>FFBox的官网地址为 <a href="https://link.segmentfault.com/?enc=ROCuGIjwXmgMLJzK0V8MFQ%3D%3D.iiI%2FmdZDk70j1oOV2pzayUNTwgxaQ2rbZSdeqeyvLxs%3D" rel="nofollow" target="_blank">http://FFBox.ttqf.tech</a> ，源码托管地址为 <a href="https://link.segmentfault.com/?enc=pGD2k8I8eVGWQVzQQW7AMQ%3D%3D.tjeQzQrBf%2FX8o8FsvBK4IgVgNloW8oLExs%2BE%2F7s%2B5bvCNLVQPtLKKCFFhzXQ0y6a" rel="nofollow" target="_blank">https://github.com/ttqftech/FFBox</a> （星星数1.0k），国内的镜像地址为 <a href="https://link.segmentfault.com/?enc=CFF92438cf5At1kTeHJKLQ%3D%3D.66QbxsoDGmRikIOB%2BL5%2F6Y01JiCBkKO1V5nrcF5O0fk%3D" rel="nofollow" target="_blank">https://gitee.com/ttqf/FFBox</a>和<a href="https://link.segmentfault.com/?enc=lSqdQFiW3fJCBd29SV4CQQ%3D%3D.k4cW5BfglRD6NCMR6ev7N2SB7PJ93P5Tc0ni1A7N%2BmxjQN84KTmnmdcs2KVsR0gW" rel="nofollow" target="_blank">https://gitcode.com/gh_mirrors/ff/FFBox</a> 。最新版本是2025年9月发布的FFBox v5.0，可见该框架的源码更新十分及时，该版本的源码下载链接为 <a href="https://link.segmentfault.com/?enc=BaiV5j9uWQW5ErzXOiU6%2Bw%3D%3D.J5C98IX9%2FTKpe5tQ41jT%2FcnLJnVO51FV3%2FGNTdBe%2BAMpYeQpRsKUpCP6WEp1AOQejSfBLTL3Ajxp9F4u2yUSaw%3D%3D" rel="nofollow" target="_blank">https://github.com/ttqftech/FFBox/archive/refs/tags/v5.0.tar.gz</a> 。  <br/>FFBox基于Node.js开发，同时支持Windows、Linux、macOS等操作系统。FFBox推荐采用VS Code编写代码，如果要在Windows系统上编译FFBoxHelper，则需安装Visual Studio 2022，并采用C++编码。若想在Windows平台上制作安装包，还需安装Inno Setup 6，并将其安装路径放入环境变量中。  <br/>编译通过后的FFBox可执行程序叫做FFBoxHelper.exe，双击exe文件打开FFBox的初始界面如下图所示：</p><p><img width="723" height="670" referrerpolicy="no-referrer" src="/img/bVdm8GT" alt="" title=""/></p><p>在FFBox界面的上方区域可拖曳添加待剪辑的音视频文件，界面中间区域为当前剪辑操作对应的ffmpeg命令，例如：</p><pre><code>ffmpeg -hide_banner -hwaccel auto -i [输入文件路径] -vcodec libx265 -preset medium -crf 24 -acodec copy ./[输出文件路径]_converted.mp4 -y</code></pre><p>界面下方区域为剪辑操作的各项参数，可在此调整具体的选项参数以便符合剪辑需求。单击界面右上角的【开始】按钮，即可令FFBox执行响应的剪辑命令，剪辑完成的结果文件默认保存在原文件的相同目录下，且文件名后缀为“ _converted.mp4 ”。  </p><p>总的来说，FFBox的界面细节考究，视觉体验焕然一新，且图形化实时显示进度、速度、码率、剩余时间等信息，并支持以图表模式直观展示，是个不错的国产多媒体剪辑工具。</p><p>更多详细的FFmpeg开发知识参见<a href="https://link.segmentfault.com/?enc=UejHwta7CIxmYG5T3N7L%2Bw%3D%3D.y%2BwTiXuVro8X0E1rDDsY1If07CjMvV7ROhH3UHbowNsCnHUjsdkEgQnHxG1%2F0JIF" rel="nofollow" title="《FFmpeg开发实战：从零基础到短视频上线》" target="_blank">《FFmpeg开发实战：从零基础到短视频上线》</a>一书。</p><p>​</p>]]></description></item><item>    <title><![CDATA[集成电路设计中的IP核心价值：加速创新的]]></title>    <link>https://segmentfault.com/a/1190000047438667</link>    <guid>https://segmentfault.com/a/1190000047438667</guid>    <pubDate>2025-11-30 11:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在集成电路（IC）设计的世界里，知识产权（Intellectual Property，简称 IP）已经成为推动创新与效率的关键力量。它不仅缩短了设计周期，还为工程师们提供了更多专注于差异化和前沿探索的空间。今天，就让我们走进IC设计中的IP，揭示它的重要性与最佳实践。<br/><img width="723" height="487" referrerpolicy="no-referrer" src="/img/bVdnc7V" alt="" title=""/><br/>1、为什么IP如此重要？<br/>在复杂的IC设计过程中，IP扮演着“现成积木”的角色。它们是经过验证、可复用的功能模块，涵盖从基础逻辑电路到完整的处理器核心。借助这些模块，设计团队无需从零开始重复造轮子，而是能够直接构建在成熟基础之上，从而降低成本并显著提升效率。</p><p>2、IP的多样性<br/>IC设计中的IP大致分为两类：<br/>硬IP（Hard IP）：已经为特定工艺优化、综合完成的电路模块，可直接应用，但可配置性较低。<br/>软IP（Soft IP）：以代码形式存在，可灵活配置和调整，满足不同设计需求。<br/>两者相辅相成，设计师可根据项目特性选择最优组合。</p><p>3、利用IP的最佳实践<br/>想要高效发挥IP的价值，必须遵循一些最佳实践：<br/>完整的文档与规范：确保团队成员能快速理解并应用IP；<br/>系统级验证：在整个设计环境下对IP进行全面测试，避免集成后出现意外问题；<br/>标准化管理：遵循行业标准，提高兼容性与复用率。</p><p>4、集成IP的挑战<br/>尽管IP带来了巨大的便利，但设计过程中仍不可避免地遇到挑战。例如，不同IP之间的兼容性问题、复杂的授权与许可管理，以及多模块协同设计的复杂性。这些问题需要依赖于经验、流程管理和先进工具来逐步化解。</p><p>5、学习与成长的机会<br/>对于立志进入或深入IC行业的工程师而言，系统学习IP在IC设计中的应用至关重要。如果你正在寻找专业的学习资源，推荐关注 EDA Academy（www.eda-academy.com）。</p><p>在 EDA Academy：<br/>你可以学习大量最新、专业、全面的在线课程，涵盖IP、IC设计、EDA工具等核心主题；<br/>你可以注册成为导师，分享经验并转化为课程收入；<br/>你可以通过邮箱免费订阅newsletter，定期获取行业前沿动态；<br/>你还可以加入销售联盟计划，通过推荐课程赚取 20%-50%的佣金。</p><p>IP已成为现代IC设计不可或缺的基石，它不仅提高了开发效率，更释放了设计师的创造力。通过理解IP的类型、掌握最佳实践并妥善应对集成挑战，工程师们能够在竞争激烈的行业中脱颖而出。如果你渴望深入学习并快速提升自己，不妨从 EDA Academy 开始，开启属于你的IC设计新篇章。<br/><img width="723" height="1098" referrerpolicy="no-referrer" src="/img/bVdnc7W" alt="" title="" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[达梦数据库安装教程 dm8_202110]]></title>    <link>https://segmentfault.com/a/1190000047438583</link>    <guid>https://segmentfault.com/a/1190000047438583</guid>    <pubDate>2025-11-30 10:04:16</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>​</p><p>是达梦数据库 DM8 的 Windows 64位企业版安装包，日期是 2021 年 10 月 25 日编译的版本。里面包含了数据库服务端、客户端和一些常用管理工具，</p><h2>1. 解压安装包</h2><ul><li><strong>提供安装包下载：</strong><a href="https://link.segmentfault.com/?enc=4F1N8W1l0XD0LpqiIXbRtQ%3D%3D.%2BgemjW%2FSEH5yPIvuU0zaBL3i5XOVuExt6wDKDzLUlsPhseOp%2BqUa4o4xtj9RSkMo" rel="nofollow" title="https://pan.quark.cn/s/301611c6df7f" target="_blank">https://pan.quark.cn/s/301611c6df7f</a> ，下载的 <code>dm8_20211025_x86_win_64_ent.zip</code>文件。</li><li>右键 → 解压到某个文件夹，比如 <code>D:\dm8</code>。</li><li>解压完，里面会有个 <code>setup.exe</code>，这就是安装程序。</li></ul><h2>2. 运行安装程序</h2><ul><li>双击 <code>setup.exe</code>。</li><li>弹出提示“是否允许此应用对设备进行更改”，点 <strong>是</strong>。</li></ul><h2>3. 选择语言</h2><ul><li>默认是 <strong>简体中文</strong>，直接点 <strong>确定</strong>。</li><li>欢迎界面点 <strong>下一步</strong>。</li></ul><h2>4. 同意许可协议</h2><ul><li>勾选 <strong>我接受协议</strong>，点 <strong>下一步</strong>。</li></ul><h2>5. 填写用户信息</h2><ul><li>公司名、用户名随便填（能记住就行），点 <strong>下一步</strong>。</li></ul><h2>6. 选择安装目录</h2><ul><li>默认在 C 盘，可点 <strong>浏览</strong>​ 改到其他盘，比如 <code>D:\dm8</code>，点 <strong>下一步</strong>。</li></ul><h2>7. 选择安装类型</h2><ul><li>新手直接选 <strong>典型安装</strong>（常用功能全装好），点 <strong>下一步</strong>。</li></ul><h2>8. 开始安装</h2><ul><li>点 <strong>安装</strong>，等进度条跑完，别中途关窗口。</li></ul><h2>9. 完成安装</h2><ul><li>装完后可能会问 <strong>是否初始化数据库</strong>，要用数据库就勾上，然后点 <strong>完成</strong>。</li><li>如果暂时不用数据库，可以不勾，后面单独弄。</li></ul><h2>10. 检查是否成功</h2><ul><li>在开始菜单或桌面找 “达梦管理工具” 或类似图标，能打开并连接数据库就说明装好了。</li></ul><p>​</p>]]></description></item><item>    <title><![CDATA[袋鼠数据库工具 8.92.1 版已上线 ]]></title>    <link>https://segmentfault.com/a/1190000047438621</link>    <guid>https://segmentfault.com/a/1190000047438621</guid>    <pubDate>2025-11-30 10:03:20</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>袋鼠数据库工具 是一款 AI 驱动的热门数据库系统客户端(MariaDB / MongoDB / MySQL / Oracle / PostgreSQL / Redis / SQLite / SQLServer / ...) ，支持建表、查询、模型、同步、导入导出等功能，支持 Windows / Mac / Linux 等操作系统，致力于打造一款好用、好玩、开发友好的开发者工具。</p><h2>重点特性介绍</h2><p>这个版本继续聚焦 MongoDB 支持，实现了更多 MongoDB 数据库对象设计器支持，完整实现了集合视图、聚合文件、聚合命令构建、查找命令构建、用户、角色、函数等对象的支持；对部分界面布局做了优化，改进了体验的一致性；完善了工作空间布局缓存支持等。</p><h2>新特性或修复的缺陷列表</h2><ul><li>MongoDB: 实现视图设计器逻辑</li><li>MongoDB: 实现查找构建器对话框逻辑</li><li>MongoDB: 实现聚合构建器对话框逻辑</li><li>MongoDB: 实现分析命令支持</li><li>MongoDB: 新增聚合文件支持</li><li>MongoDB: 新增函数设计器支持</li><li>MongoDB: 新增角色设计器支持</li><li>MongoDB: 新增用户设计器支持</li><li>MongoDB: 实现工作空间布局和缓存支持</li><li>MongoDB: 用户/角色/函数删除支持</li><li>文件面板增加文件支持</li><li>表视图: 增加字段位置调整支持</li><li>更新中文语言支持(zh-CN/zh-SG/zh-Hans/zh-Hant)</li><li>升级界面库版本 (GLib 2.86 / GTK 4.20.3 / libadwaita 1.8.2)</li><li>重构部分页面 (AdwPreferencesPage)</li><li>修复: 偶尔出现的不能保存布局的问题</li><li>修复: SQL 构建器名字空间中出现点问题的处理</li><li>修复: 权限设计器菜单无法响应的问题</li><li>修复: 工作空间布局文件无限增长</li><li>修复: 控制台警告消息</li></ul><h2>下载与安装</h2><p><a href="https://link.segmentfault.com/?enc=p3HZ%2B7Swts2C5nlpaaj%2BHw%3D%3D.YK43vIR9B2btuWXf6CshZDfyxjBGn0S1JwswcZlW%2BGbJRP%2BhMLbir3%2BSVUZB9Q29%2BvPpIPTs%2ByatybCi44sVWg%3D%3D" rel="nofollow" target="_blank">袋鼠数据库管理工具 8.92.1</a></p><h2>新版本功能快照</h2><p><a href="https://link.segmentfault.com/?enc=6%2FNlunbkTnvJzCwupj%2FjSg%3D%3D.Lw0fdMUUoLCkB9FF%2BbMpBy%2BZ7YMANqo99omG%2BuxZ8Bl5JUjb9Sa7pJJxIYNkVQnZ9C2jyLiCXtaD6SK82hxVrQ%3D%3D" rel="nofollow" title="MongoDB 视图编辑" target="_blank"><img width="723" height="490" referrerpolicy="no-referrer" src="/img/bVdnb2v" alt="MongoDB 视图编辑" title="MongoDB 视图编辑"/></a></p><p><a href="https://link.segmentfault.com/?enc=8FdKWD%2BeOWq0r0zSWja%2FpA%3D%3D.ZuLB7N61ZhocoflAJS7UoQ56Oq0cGKCAZPlZXlX7ZLIFTW0ZWFshOb0xbkte6lFN9noU8Npl1jiSTF8vNGWMHg%3D%3D" rel="nofollow" title="MongoDB 函数编辑" target="_blank"><img width="723" height="491" referrerpolicy="no-referrer" src="/img/bVdnb2w" alt="MongoDB 函数编辑" title="MongoDB 函数编辑" loading="lazy"/></a></p><p><a href="https://link.segmentfault.com/?enc=MLCiwFVXSLir2VJUS0hRbA%3D%3D.K%2FiDNu%2FiIVvGpW%2FYLeR5%2FgT5r5Sp7zi112lyuf1Qp0cQnOY8UZfw37XxLJxIUMGzV9PUf6yhGpI%2Fac5JZt882Q%3D%3D" rel="nofollow" title="MongoDB 查找命令构建" target="_blank"><img width="723" height="490" referrerpolicy="no-referrer" src="/img/bVdnb2x" alt="MongoDB 查找命令构建" title="MongoDB 查找命令构建" loading="lazy"/></a></p>]]></description></item><item>    <title><![CDATA[Room Arranger for Ma]]></title>    <link>https://segmentfault.com/a/1190000047438631</link>    <guid>https://segmentfault.com/a/1190000047438631</guid>    <pubDate>2025-11-30 10:02:20</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>​Room Arranger 是一个用来画房间布局、摆家具的小软件，能让你在电脑上提前规划空间，看沙发、床、桌子这些放哪儿合适，尺寸对不对。</p><h2>1. 先下载文件</h2><p><strong>安装包下载：</strong><a href="https://link.segmentfault.com/?enc=g5zYinSM6OfwhUjT%2F2evew%3D%3D.n0sizVKW%2BRW0YJZzgNk%2Bygdz2QG3xdwkvJYGgt80pbekGbtBK3H86%2F1CMCcKeQFw" rel="nofollow" title="https://pan.quark.cn/s/79414e16e772" target="_blank">https://pan.quark.cn/s/79414e16e772</a> ，下载好 <strong>Room Arranger for Mac v9.8.3.645.dmg</strong>，下完一般会在“下载”文件夹里躺着，找的时候直接进“下载”就行。</p><h2>2. 打开 dmg 文件</h2><p>双击这个 <code>.dmg</code>文件，Mac 会自动弹出一个窗口，里面能看到 Room Arranger 的图标，旁边还有个箭头指着“应用程序”文件夹。</p><h2>3. 拖到应用程序文件夹</h2><p>把 Room Arranger 的图标直接拖进“应用程序”文件夹里，等它复制完就好，这步其实就是安装。</p><h2>4. 关掉安装窗口</h2><p>复制完成后，点窗口左上角的  <strong>“推出”</strong> ​ 按钮，把这个安装窗口关掉，桌面上的挂载盘也会消失。</p><h2>5. 打开软件</h2><p>打开“启动台”（或者“应用程序”文件夹），找到刚装好的 Room Arranger，点一下运行。</p><p>第一次打开时，可能会跳出来“来自未知开发者”的提示，别慌，点  <strong>“仍要打开”</strong> ​ 就能正常用了。</p><h2>6. 小贴士</h2><ul><li>如果之前装过旧版本，最好先删掉旧的再装新的，这样不容易冲突。</li><li>软件装完就能直接摆房间玩，不用额外设置啥。</li></ul><p>​</p>]]></description></item><item>    <title><![CDATA[如何在 Ubuntu / Debian ]]></title>    <link>https://segmentfault.com/a/1190000047438633</link>    <guid>https://segmentfault.com/a/1190000047438633</guid>    <pubDate>2025-11-30 10:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000045376433" alt="Configure Postfix to Use Gmail SMTP" title="Configure Postfix to Use Gmail SMTP"/></p><p>Postfix 是一个流行的开源邮件传输代理（MTA），用于在 Linux 系统上路由并发送电子邮件。它提供了一个健壮和高效的处理邮件投递的方法。在本教程中，我们将向您展示如何在 Ubuntu 和 Debian-based 系统配置 Postfix 使用 Gmail 的 SMTP 服务。这个设置允许你使用 Gmail 的基础设施发送电子邮件，提供更好的可交付性，减少你的电子邮件被标记为垃圾邮件的可能性。</p><h3>安装 Postfix 和依赖项</h3><p>首先，更新系统的包索引。</p><pre><code>sudo apt update</code></pre><p>接下来，安装 Postfix 和 mailutils 包，它为处理邮件提供了额外的实用程序。</p><pre><code>sudo apt install postfix mailutils</code></pre><p>在 Postfix 安装过程中，系统将提示您选择邮件服务器配置类型。选择“Internet Site”并输入您的完全限定域名（FQDN）。</p><h3>配置 Postfix 使用 Gmail SMTP</h3><p>编辑 Postfix 配置文件</p><pre><code>sudo nano /etc/postfix/main.cf</code></pre><p>在配置文件中增加或修改如下几行：</p><pre><code>relayhost = [smtp.gmail.com]:587
smtp_use_tls = yes
smtp_sasl_auth_enable = yes
smtp_sasl_security_options = noanonymous
smtp_sasl_password_maps = hash:/etc/postfix/sasl_passwd
smtp_tls_CAfile = /etc/ssl/certs/ca-certificates.crt</code></pre><p>保存并退出文件</p><h3>创建并配置 SASL 密码文件</h3><p>创建一个新文件存储你的 Gmail 帐户的凭据</p><pre><code>sudo nano /etc/postfix/sasl_passwd</code></pre><p>添加以下行到新创建的文件中，将 <a href="mailto:your_email@example.com" target="_blank">your_email@example.com</a> 替换为您的 Gmail 电子邮件地址，将 your_password 替换为您的 Gmail 密码。</p><pre><code>[smtp.gmail.com]:587 your_email@example.com:your_password</code></pre><p>保存并退出文件，并修改文件权限。</p><pre><code>sudo chmod 600 /etc/postfix/sasl_passwd</code></pre><p>创建密码文件的哈希映射供 Postfix 使用</p><pre><code>sudo postmap /etc/postfix/sasl_passwd</code></pre><p>重新启动 Postfix 服务以应用更改</p><pre><code>sudo systemctl restart postfix</code></pre><h3>测试邮件功能</h3><p>使用 mail 命令发送测试邮件，确保 Postfix 配置正确。</p><pre><code>echo "This is a test email." | mail -s "Test Email" recipient@example.com</code></pre><h3>我的开源项目</h3><p><a href="https://link.segmentfault.com/?enc=6I3YXwITvaI66Bn4g29n0g%3D%3D.8H6HrYTubBLpPCH6NFHUDlPI2Fstk%2B8FzmdfTdch2Bg%3D" rel="nofollow" target="_blank"><img referrerpolicy="no-referrer" src="/img/remote/1460000043302459" alt="酷瓜云课堂-在线教育解决方案" title="酷瓜云课堂-在线教育解决方案" loading="lazy"/></a></p><ul><li><a href="https://link.segmentfault.com/?enc=Mz4xs%2F3kzNdfnAKP1r3msA%3D%3D.JP0CHdwsq65BxMCnaenpEKobnE%2F54RmYmRQnk0UUcq6joWhvvGqoIfCmg%2FQtxDWm" rel="nofollow" target="_blank">course-tencent-cloud（酷瓜云课堂 - gitee仓库）</a></li><li><a href="https://link.segmentfault.com/?enc=zBhSyEWz2jJKPm4FwcscSQ%3D%3D.kVN0Y94GkivjaoQv%2FxaBS8ulzGzcz%2B2534MCflbYGdXF1m%2BMLZz1vt9bS4WmEX7YAc78rx3LpV7%2F%2Fd8r%2F3tj6g%3D%3D" rel="nofollow" target="_blank">course-tencent-cloud（酷瓜云课堂 - github仓库）</a></li></ul>]]></description></item><item>    <title><![CDATA[Android 监听软键盘的高度并解决其]]></title>    <link>https://segmentfault.com/a/1190000047438460</link>    <guid>https://segmentfault.com/a/1190000047438460</guid>    <pubDate>2025-11-30 00:02:09</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>1、前言<br/>在某些项目中，我们常常需要自定义一个输入框，软键盘弹出时就把输入框顶上去，关闭时输入框再回到原位（比如下方的效果图，实际上各种 App 中的聊天界面和发布评论的界面大体都是这样）。在这个过程中，除了输入框以外的其他界面的元素不受影响，比如效果图中的背景图片不会上移也不会被压缩。但在实际使用中发现软键盘在弹出时常常把输入框盖住，导致输入框显示不完全。有什么方法可以解决呢？<br/>​<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047438462" alt="图片" title="图片"/><br/>​<br/>2、思路分析<br/>2.1 获取软键盘的高度<br/>网上常见的思路是这样的：在输入框的下面放置一个 View​，当软键盘弹出时，获取软键盘高度，然后在代码中动态将该 View​ 的高度设置成跟软键盘的一样，这样输入框就被它顶上去了。从视觉上来看，就像是被软键盘顶上去一样。<br/>这个思路的难点在于准确获取软键盘的动态高度。Android 系统没有提供直接获取软键盘高度的 api，好在我们可以曲线救国：软键盘的高度其实就是屏幕高度减去软键盘上方的可见区域（即没有被软键盘挡住的区域）高度，也就是：</p><p>软键盘高度 = 屏幕高度 - 可见区域高度</p><p>此外，还需要考虑状态栏和虚拟导航栏高度，所以我们可以得出以下的计算公式：</p><p>软键盘高度 = 屏幕高度 - 可见区域高度 - 顶部状态栏高度 - 底部导航栏高度</p><p>不过有两点需要注意：</p><p>Activity 为全屏时是没有状态栏的，不必扣除高度；<br/>横屏时虚拟状态栏是在侧边的，这时也不必扣除它的高度了。</p><p>最后我们的公式可以修正为：</p><p>软键盘高度 = 屏幕高度 - 可见区域高度 - 顶部状态栏高度（非全屏时） - 底部导航栏高度（竖屏时）</p><p>这个公式中的屏幕高度、状态栏高度和导航栏高度都可以通过 Android 的 api 获取，所以，现在问题的难点转换成了准确获取可见区域的动态高度。<br/>2.2 获取可见区域高度<br/>准确获取可见区域的动态高度，何为准确，何为动态呢？要想准确，我们必须要准确获取可见区域的对象，要想动态，那必须监听可见区域的高度变化，也即是：</p><p>获取可见区域（对应准确）；<br/>监听可见区域的高度变化（对应动态）。</p><p>首先来看第一步，View​ 类中为我们提供了一个方法 getWindowVisibleDisplayFrame()​，它可以获取某个 View​ 所在窗口（Window​）的可见区域（注意：是窗口的可见区域，不是 View​ 的可见区域！）。它需要传入一个 Rect​ 对象，从 Rect​ 对象中，我们就可以获取到可见区域的信息，比如可见区域顶部距离父布局顶部的距离 top​ 和可见区域底部部距离父布局顶部的距离 bottom​，两者一相减就是我们需要的可见区域高度了。<br/>那么用哪一个 View​ 来获取可见区域呢？当前 Activity​ 或者 Fragment​ 上面的布局或者控件吗？答案是不行的。因为 Activity​（或 Fragment​）跟软键盘是位于同一个窗口的，也就是说，软键盘也在这个窗口的可见区域内，无论软键盘弹出还是关闭，可见区域的大小都不会变化！<br/>既然如此，那么我们就需要另外一个窗口了。有没有办法创建一个不属于软键盘所在窗口的 View​ 呢？当然可以，Dialog​ 和 PopupWindow​ 就可以办到。我们需要这个 View​ 一直存在，便于监听，所以 PopupWindow​ 无疑是最合适的。<br/>第一步解决后，接下来就是监听可见区域的变化了这个比较简单，可以通过继承接口 ViewTreeObserver.OnGlobalLayoutListener​ 来，在 onGlobalLayout()​ 中监听来实现。<br/>3、代码实践<br/>思路已经捋清楚了，现在是代码时间。创建一个 KeyboardStatusWatcher​ 类，继承于 PopupWindow​ 和 ViewTreeObserver.OnGlobalLayoutListener​ 接口：<br/>class KeyboardStatusWatcher(</p><pre><code>private val activity: FragmentActivity,
private val lifecycleOwner: LifecycleOwner,
private val listener: (isKeyboardShowed: Boolean, keyboardHeight: Int) -&gt; Unit</code></pre><p>) : PopupWindow(activity), ViewTreeObserver.OnGlobalLayoutListener {</p><pre><code>private val rootView by lazy { activity.window.decorView.rootView }

private val TAG = "Keyboard-Tag"

/**
 * 可见区域高度
 */
private var visibleHeight = 0

/**
 * 软键盘是否显示
 */
var isKeyboardShowed = false
    private set

/**
 * 最近一次弹出的软键盘高度
 */
var keyboardHeight = 0
    private set

/**
 * PopupWindow 布局
 */
private val popupView by lazy {
    FrameLayout(activity).also {
        it.layoutParams = FrameLayout.LayoutParams(
            ViewGroup.LayoutParams.WRAP_CONTENT,
            ViewGroup.LayoutParams.MATCH_PARENT
        )
        //监听布局大小变化
        it.viewTreeObserver.addOnGlobalLayoutListener(this)
    }
}

init {
    //初始化 PopupWindow
    contentView = popupView
    //软键盘弹出时，PopupWindow 要调整大小
    softInputMode =
        WindowManager.LayoutParams.SOFT_INPUT_ADJUST_RESIZE or
            WindowManager.LayoutParams.SOFT_INPUT_STATE_ALWAYS_VISIBLE
    inputMethodMode = INPUT_METHOD_NEEDED
    //宽度设为0，避免遮挡界面
    width = 0
    height = ViewGroup.LayoutParams.MATCH_PARENT
    setBackgroundDrawable(ColorDrawable(0))
    rootView.post { showAtLocation(rootView, Gravity.NO_GRAVITY, 0, 0) }

    //activity 销毁时或者 Fragment onDestroyView 时必须关闭 popupWindow ，避免内存泄漏
    lifecycleOwner.lifecycle.addObserver(object : DefaultLifecycleObserver {
        override fun onDestroy(owner: LifecycleOwner) {
            super.onDestroy(owner)
            dismiss()
        }
    })
}

/**
 * 监听布局大小变化
 */
override fun onGlobalLayout() {
    val rect = Rect()
    //获取当前可见区域
    popupView.getWindowVisibleDisplayFrame(rect)
    if (visibleHeight == (rect.bottom - rect.top)) {
        //可见区域高度不变时不必执行下面代码，避免重复监听
        return
    } else {
        visibleHeight = (rect.bottom - rect.top)
    }
    //粗略计算高度的变化值，后面会根据状态栏和导航栏修正
    val heightDiff = rootView.height - visibleHeight
    //这里取了一个大概值，当窗口高度变化值超过屏幕的 1/3 时，视为软键盘弹出
    if (heightDiff &gt; activity.screenHeight / 3) {
        isKeyboardShowed = true
        //非全屏时减去状态栏高度
        keyboardHeight =
            if (activity.isFullScreen) heightDiff else heightDiff - activity.statusBarHeight
        //导航栏显示时减去其高度，但横屏时导航栏在侧边，故不必扣除高度
        if (activity.hasNavBar &amp;&amp; activity.isNavBarShowed &amp;&amp; activity.isPortrait) {
            keyboardHeight -= activity.navBarHeight
        }
    } else {
        //软键盘隐藏时键盘高度为0
        isKeyboardShowed = false
        keyboardHeight = 0
    }
    listener.invoke(isKeyboardShowed, keyboardHeight)
}</code></pre><p>}</p><p>代码都是遵循前面的思路分析编写的，注释也比较详细，就不过多分析了。只要关注一下 PopupWindow​ 存在时软键盘的交互。PopupWindow​ 与软键盘分属于不同的窗口，软键盘弹出时，默认会被 PopupWindow​ 覆盖的（你可以通过修改上面的代码，给 PopupWindow​ 设置颜色且宽度不为 0 来验证），这样 PopupWindow​ 的高度不发生变化，就无法达到监听的目的。所以我们需要设置 softInputMode​ 和 inputMethodMode​ 两个属性，让 PopupWindow​ 的高度随着软键盘的弹出和关闭而调整。<br/>然后简单看看 MainActivity 布局：<br/>&lt;androidx.constraintlayout.widget.ConstraintLayout <br/>    xmlns:android="http://schemas.android.com/apk/res/android"</p><pre><code>xmlns:app="http://schemas.android.com/apk/res-auto"
xmlns:tools="http://schemas.android.com/tools"
android:id="@+id/clRoot"
android:layout_width="match_parent"
android:layout_height="match_parent"
android:background="@drawable/watermelon"
tools:context=".MainActivity"&gt;

&lt;View
    android:id="@+id/vKeyboardBg"
    android:layout_width="match_parent"
    android:layout_height="60dp"
    android:background="@android:color/white"
    app:layout_constraintBottom_toBottomOf="parent" /&gt;

&lt;androidx.appcompat.widget.AppCompatEditText
    android:imeOptions="flagNoExtractUi"
    android:id="@+id/editText"
    android:layout_width="match_parent"
    android:layout_height="0dp"
    android:layout_marginHorizontal="15dp"
    android:layout_marginVertical="8dp"
    android:background="@drawable/shape_edit_bg"
    android:hint="请输入"
    android:paddingHorizontal="10dp"
    app:layout_constraintBottom_toBottomOf="@id/vEditBg"
    app:layout_constraintTop_toTopOf="@id/vEditBg" /&gt;
</code></pre><p>&lt;/androidx.constraintlayout.widget.ConstraintLayout&gt;</p><p>注意：这里 EditText​ 要加上 android:imeOptions="flagNoExtractUi"​ 属性，不然横屏时样式发生会变化。<br/>还有，别忘了在清单文件中给 Activity 加上 android:windowSoftInputMode="adjustNothing|stateHidden"​，否则软键盘弹出时布局会整体上移的。<br/>最后当然是在 Activity​ 中调用了：</p><pre><code>    KeyboardStatusWatcher(this,this) { isKeyboardShowed: Boolean, keyboardHeight: Int -&gt;
        vKeyboardBg.updateLayoutParams&lt;ConstraintLayout.LayoutParams&gt; {
            bottomMargin = keyboardHeight
        }
        Log.d("Tag", "isShowed = $isKeyboardShowed,keyboardHeight = $keyboardHeight")
    }
}
</code></pre><p>4、项目地址<br/>文章到此就结束了，项目地址如下：Gitee。<br/>项目还有一个不足之处：实现需求了，但是使用体验上跟微信相比差很多，微信的输入框在软键盘弹出和收起时上下移动非常顺滑，没有什么闪烁。<br/>如果你有更好的实现方法或者有其他的批评建议，欢迎留言和我交流。<br/>5、参考文章<br/>android EditText 横屏显示问题 - 简书<br/>Android 动态获取软键盘的高度，监听软键盘显示或则隐藏。 - 掘金<br/>Android 获取窗口可视区域大小: getWindowVisibleDisplayFrame()_ccpat 的专栏-CSDN 博客<br/>Android 全面解析之 Window 机制_一只修仙的猿-CSDN 博客</p>]]></description></item><item>    <title><![CDATA[NavigationBarUtil li]]></title>    <link>https://segmentfault.com/a/1190000047438483</link>    <guid>https://segmentfault.com/a/1190000047438483</guid>    <pubDate>2025-11-30 00:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <pre><code>private const val RES_NAME_NAV_BAR = "navigationBarBackground"

private val Context.navBarResId
    get() = resources.getIdentifier(
        "navigation_bar_height",
        "dimen", "android"
    )

/**
 * 获取虚拟导航栏的高度，必须在布局绘制完成之后调用才能获取到正确的值（可以在onWindowFocusChanged()中调用）
 * 单位为px
 */
val Context.navBarHeight: Int
    get() {
        val resourceId = navBarResId
        return if (resourceId != 0) {
            resources.getDimensionPixelSize(resourceId)
        } else 0
    }

/**
 * 手机是否有虚拟导航栏
 */
val Context.hasNavBar
    @JvmName("hasNavBar")
    get() = navBarResId != 0

/**
 * 当前虚拟导航栏是否显示
 */
val Activity.isNavBarShowed: Boolean
    get()  {
        val viewGroup = window.decorView as ViewGroup? ?: return false
        return (0 until viewGroup.childCount).firstOrNull {
            viewGroup.getChildAt(it).id != View.NO_ID
                &amp;&amp; this.resources.getResourceEntryName(viewGroup.getChildAt(it).id) == RES_NAME_NAV_BAR
        } != null
    }</code></pre>]]></description></item><item>    <title><![CDATA[SQL 性能的三要素——索引、执行计划与]]></title>    <link>https://segmentfault.com/a/1190000047438350</link>    <guid>https://segmentfault.com/a/1190000047438350</guid>    <pubDate>2025-11-29 23:03:26</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <blockquote>优秀的 SQL 性能不取决于单一组件的优化，而是索引设计、执行计划选择与数据分布感知三者协同的结果</blockquote><p>在数据库系统中，SQL 查询性能是衡量应用健康度的关键指标。许多开发者将性能优化简单归结为"添加索引"，但实际上，高效的查询是索引策略、执行计划优化和数据分布理解三者协同作用的结果。本文将深入探讨这三要素的相互作用机制，帮助您构建系统化的 SQL 性能优化思维。</p><h2>1 SQL 执行的生命周期与性能瓶颈</h2><h3>1.1 查询处理的全链路视角</h3><p>SQL 查询在数据库中的执行是一个复杂的过程，涉及多个组件的协同工作。<strong>查询优化器</strong>作为数据库大脑，负责将 SQL 语句转换为高效执行计划，其决策直接决定了查询性能。优化器的工作流程包括解析、标准化和优化三个阶段，最终生成物理执行计划。</p><p>在查询执行过程中，主要性能瓶颈常出现在<strong>数据访问路径</strong>选择上。不恰当的访问路径会导致不必要的磁盘 I/O 和 CPU 消耗，从而显著影响查询响应时间。了解这些瓶颈点有助于我们针对性优化。</p><h3>1.2 三要素的相互依赖关系</h3><p>索引、执行计划和数据分布之间存在深刻的相互影响关系。<strong>索引</strong>提供了数据快速访问的路径，但索引的有效性取决于<strong>数据分布</strong>特征；<strong>执行计划</strong>的选择基于成本估算，而成本估算的准确性又依赖于统计信息反映的数据分布；<strong>数据分布</strong>的变化会导致执行计划更替，可能使原有索引失效。</p><p>这种紧密的耦合关系意味着任何单点优化都难以持续有效，必须采用系统化思维进行性能优化。例如，即使创建了理想的索引，如果统计信息不准确，优化器可能仍然选择低效的执行计划。</p><h2>2 索引设计：高效访问的基石</h2><h3>2.1 索引结构与访问模式匹配</h3><p><strong>B+ 树索引</strong>是数据库中最常用的索引结构，其多路平衡特性有效降低了磁盘 I/O 次数。B+ 树将所有数据记录存储在叶子节点，并通过双向链表连接，这一特性特别有利于范围查询性能。</p><p>索引设计必须与实际<strong>查询模式</strong>相匹配。对于等值查询，单列索引可能足够；而对于多条件查询，复合索引通常更有效。复合索引的列顺序至关重要，应遵循<strong>高选择性列在前</strong>的原则，使索引能够最大程度地过滤数据。</p><p><strong>覆盖索引</strong>是优化查询性能的强大技术。当查询所需数据全部包含在索引中时，数据库可直接从索引获取数据，避免回表操作，显著减少 I/O 消耗。例如，假设存在复合索引（user\_id, created\_at），查询 <code>SELECT user_id, created_at FROM orders WHERE user_id = 100</code> 可完全利用索引完成，无需访问主表。</p><h3>2.2 索引选择性与性能关系</h3><p><strong>索引选择性</strong>是衡量索引效果的关键指标，高选择性索引能更有效地过滤数据。选择性计算公式为：不同值数量/总记录数。通常，选择性高于 10% 的索引才考虑使用。</p><p>索引使用中的常见陷阱包括：在索引列上使用函数或表达式会导致索引失效；前置通配符模糊查询（如 LIKE '%abc'）无法有效利用索引；隐式类型转换可能导致优化器无法使用索引。</p><p>以下是索引设计决策的参考框架：</p><pre><code>-- 良好的复合索引设计示例
CREATE INDEX idx_orders_user_status_date ON orders(user_id, status, created_date);

-- 匹配的查询示例（可利用索引前导列）
SELECT * FROM orders 
WHERE user_id = 100 
  AND status = 'completed'
  AND created_date &gt;= '2023-01-01';</code></pre><h2>3 执行计划：数据库的"执行蓝图"</h2><h3>3.1 执行计划解析与关键指标</h3><p><strong>执行计划</strong>是查询优化器生成的指令集，描述了数据处理的具体步骤。通过 EXPLAIN 命令可查看执行计划，其中几个关键字段特别重要：<strong>type</strong> 字段表示表访问类型，从最优到最差依次为：system &gt; const &gt; eq\_ref &gt; ref &gt; range &gt; index &gt; ALL；<strong>key</strong> 字段显示实际使用的索引；<strong>rows</strong> 字段预估需要扫描的行数；<strong>Extra</strong> 字段包含额外信息，如"Using index"表示使用覆盖索引。</p><p>执行计划中的<strong>连接类型</strong>对性能影响巨大。嵌套循环连接适用于小结果集连接；归并连接适合已排序的大表；哈希匹配则对无序大数据集效果良好。优化器会根据统计信息选择最适合的连接算法。</p><h3>3.2 执行计划分析与优化时机</h3><p>分析执行计划是识别性能瓶颈的关键步骤。当发现​<strong>type 为 ALL</strong>​（全表扫描）时，应考虑添加合适索引；当 <strong>rows 预估值与实际差异很大</strong>时，可能需要更新统计信息；当出现​<strong>Using temporary</strong>​（临时表）和​<strong>Using filesort</strong>​（文件排序）时，可能需要优化查询或索引。</p><p>以下是一个执行计划分析示例：</p><pre><code>-- 示例查询
EXPLAIN SELECT * FROM orders WHERE customer_id = 1001 AND status = 'shipped';

-- 问题执行计划可能显示：
-- type: ALL（全表扫描）
-- key: NULL（未使用索引）
-- rows: 大量扫描
-- 这表明需要为(customer_id, status)创建复合索引</code></pre><p>定期检查关键查询的执行计划是预防性能退化的重要手段。特别是在数据量变化较大或查询模式改变后，执行计划可能发生变更，导致性能下降。</p><h2>4 数据分布：优化器的"决策依据"</h2><h3>4.1 统计信息的作用与维护</h3><p><strong>统计信息</strong>是优化器进行成本估算的基础，描述了表数据、列数据和索引数据的分布特征。优化器依赖统计信息来估算不同执行计划的成本，从而选择最优方案。</p><p>统计信息需要定期更新以确保准确性。<strong>静态收集</strong>是在查询前手动或自动完成统计信息收集，不影响查询性能；<strong>动态收集</strong>则在查询过程中进行，会影响计划生成时间。对于数据变化频繁的表，应设置更频繁的统计信息更新策略。</p><p>当统计信息不准确时，优化器可能选择低效的执行计划。例如，如果统计信息未反映近年订单量激增，优化器可能低估结果集规模，错误选择嵌套循环连接而非更高效的哈希连接。</p><h3>4.2 数据分布特征对计划选择的影响</h3><p><strong>数据倾斜</strong>是影响执行计划选择的重要因素。当某些值出现频率极高时，索引可能不如全表扫描有效。例如，在"状态"字段上只有几个枚举值时，即使有索引，优化器也可能选择全表扫描。</p><p><strong>数据聚类</strong>特性也会影响性能。如果数据在物理存储上按某字段排序，基于该字段的范围查询会受益于顺序 I/O。了解数据分布特征有助于设计更有效的索引策略。</p><p>以下代码展示了如何检查数据分布：</p><pre><code>-- 分析列的数据分布
SELECT status, COUNT(*) AS count 
FROM orders 
GROUP BY status 
ORDER BY count DESC;

-- 更新统计信息
UPDATE STATISTICS ON orders;</code></pre><h2>5 三要素协同优化策略</h2><h3>5.1 索引与执行计划的协同</h3><p>索引设计必须考虑执行计划的选择规律。<strong>索引下推</strong>优化允许存储引擎在扫描索引时提前过滤数据，减少不必要的回表操作。<strong>多列索引</strong>的列顺序应匹配查询条件，以便优化器生成最佳计划。</p><p>当索引变更时，必须重新评估相关查询的执行计划。有时<strong>索引提示</strong>可临时强制优化器选择特定索引，但长期解决方案应是优化索引设计或统计信息。</p><p>复合索引设计应遵循​<strong>ERD 原则</strong>​（Equal-Range-Divide）：首先放置等值查询列，然后是范围查询列，最后是排序或分组列。这一原则能与优化器的执行计划生成逻辑最佳匹配。</p><h3>5.2 数据分布感知的优化</h3><p>智能优化需要考虑数据分布特征。对于​<strong>偏斜数据</strong>​，可考虑创建过滤索引或使用分区表；对于​<strong>时序数据</strong>​，可利用时间分区并结合数据归档策略。</p><p><strong>定期更新统计信息</strong>确保优化器基于准确数据分布做决策。对于大型表，可采用抽样统计平衡准确性和开销。<strong>直方图</strong>可帮助优化器了解复杂数据分布，尤其对非均匀分布列至关重要。</p><p>协同优化示例：某订单查询系统在（customer\_id, status）上创建复合索引，但性能仍不理想。分析发现 status 列严重偏斜（90% 为"completed"），通过过滤索引 <code>CREATE INDEX idx_orders_pending ON orders(customer_id) WHERE status != 'completed'</code>，结合统计信息更新，优化器终于选择了高效执行计划。</p><h2>6 实战：性能优化诊断流程</h2><h3>6.1 系统化性能诊断方法</h3><p>面对性能问题，应采用系统化诊断方法：​<strong>识别慢查询</strong>​：通过慢查询日志或数据库监控定位问题查询；​<strong>分析执行计划</strong>​：使用 EXPLAIN 查看当前执行计划，识别全表扫描、临时表等问题；​<strong>检查数据分布</strong>​：分析相关表的数据分布和统计信息时效性；​<strong>设计优化方案</strong>​：基于分析结果综合运用索引调整、查询重写或统计信息更新。</p><p>具体诊断流程如下：</p><ol><li>​<strong>执行计划分析</strong>​：关注 type、key、rows 和 Extra 字段，识别潜在问题</li><li>​<strong>索引有效性检查</strong>​：验证现有索引是否被使用，选择性如何</li><li>​<strong>统计信息检查</strong>​：确认统计信息是否最新，能否准确反映数据分布</li><li>​<strong>查询重写尝试</strong>​：尝试等效查询重写，测试不同写法性能差异</li></ol><h3>6.2 常见场景优化示例</h3><p><strong>场景一：分页查询优化</strong></p><pre><code>-- 原始慢查询
SELECT * FROM orders ORDER BY created_date DESC LIMIT 20 OFFSET 10000;

-- 优化方案：使用覆盖索引 + 游标分页
CREATE INDEX idx_orders_date_desc ON orders(created_date DESC, id);
SELECT * FROM orders 
WHERE created_date &lt;= '2023-11-28' AND id &lt; 5000
ORDER BY created_date DESC LIMIT 20;</code></pre><p><strong>场景二：多表连接优化</strong></p><pre><code>-- 原始查询
SELECT * FROM users u 
JOIN orders o ON u.id = o.user_id 
WHERE u.reg_date &gt;= '2023-01-01' AND o.amount &gt; 1000;

-- 优化方案：确保驱动表选择正确，连接字段有索引
CREATE INDEX idx_users_regdate ON users(reg_date);
CREATE INDEX idx_orders_user_amount ON orders(user_id, amount);</code></pre><h2>7 预防性性能治理体系</h2><h3>7.1 持续监控与预警</h3><p>建立<strong>持续监控机制</strong>对预防性能退化至关重要。监控应覆盖：​<strong>慢查询趋势</strong>​：跟踪慢查询数量、执行时间变化；​<strong>索引使用情况</strong>​：识别未使用或低效索引；​<strong>统计信息时效性</strong>​：确保统计信息及时更新。</p><p>设置合理的<strong>预警阈值</strong>可在问题影响用户前发现异常。例如，当查询扫描行数突增或索引命中率下降时触发告警。</p><h3>7.2 性能回归防护</h3><p>将 <strong>SQL 审查</strong>嵌入 CI/CD 流程可防止性能回归。使用自动化工具检查常见反模式，如 SELECT <em>​、N+1 查询等。​</em>​​<em>性能测试</em>​*应成为发布流程的必备环节，验证优化效果并防止回归。</p><p><strong>容量规划</strong>基于数据增长趋势提前规划优化策略。定期评估当前表结构、索引策略和数据量是否匹配，预见未来性能需求并提前准备优化方案。</p><h2>总结</h2><p>SQL 性能优化是一个系统工程，需要同时考虑索引设计、执行计划选择和数据分布特征三个要素的协同影响。优秀的性能源于对这三者之间复杂关系的深入理解和平衡把握。</p><p>​<strong>索引是基础</strong>​，但必须基于实际查询模式和数据分布特征设计；​<strong>执行计划是关键</strong>​，优化器的选择决定了查询路径的效率；​<strong>数据分布是依据</strong>​，统计信息的准确性直接影响优化器决策的质量。</p><p>未来，随着机器学习技术在数据库领域的应用，如 Bao 优化器通过强化学习选择执行计划，我们有理由相信数据库性能优化将更加智能化。但无论如何发展，对索引、执行计划和数据分布协同作用的深入理解，仍是数据库专业人士的核心竞争力。</p><hr/><p><strong>📚 下篇预告</strong>​</p><p>《连接池的价值与风险——池化提升与资源枯竭的双刃剑，关键指标如何解读》—— 我们将深入探讨：</p><ul><li>🔄 ​<strong>连接池原理</strong>​：数据库连接复用机制与性能提升的本质</li><li>⚖️ ​<strong>配置权衡</strong>​：最大连接数、最小空闲连接与超时设置的平衡策略</li><li>🚨 ​<strong>风险预警</strong>​：连接泄漏、资源枯竭与雪崩效应的发生机制</li><li>📊 ​<strong>监控指标</strong>​：活跃连接、等待时间与使用率的关键阈值</li><li>🛠️ ​<strong>实战调优</strong>​：主流连接池（HikariCP、Druid）的最佳配置实践</li></ul><p><strong>​点击关注，掌握数据库连接池的精细化调优技巧！​</strong>​</p><blockquote><p>​<strong>今日行动建议</strong>​：</p><ol><li>选择 1-2 个关键业务查询，使用 EXPLAIN 分析其执行计划</li><li>检查核心表的统计信息最后更新时间，确保其准确性</li><li>审核现有索引使用情况，识别并删除未使用索引</li><li>建立慢查询定期审查机制，预防性能退化</li></ol></blockquote>]]></description></item><item>    <title><![CDATA[基于反馈循环的自我进化AI智能体：原理、]]></title>    <link>https://segmentfault.com/a/1190000047438388</link>    <guid>https://segmentfault.com/a/1190000047438388</guid>    <pubDate>2025-11-29 23:02:36</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>传统AI智能体有个老问题：部署之后就"定住了"。工程师手工打磨的提示词和规则,遇到新场景就容易失灵,性能曲线到达某个点后趋于平缓。而自我进化智能体(Self-Evolving Agent)的思路就是打破这种静态模式，让智能体在运行过程中持续收集反馈,自动调整自身策略,形成一个闭环：<strong>执行任务 → 获取反馈 → 自我调整 → 继续执行</strong>。</p><p>这套机制把基础模型的能力与在线学习结合起来。用更学术的表述,自我进化智能体是"通过与环境交互持续优化内部组件的自主系统,目标是适应变化的任务、上下文和资源"。比如说这类智能体不只是做题,还会批改自己的作业、找出哪里写错了、然后调整学习策略，整个过程不需要人类介入。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047438390" alt="" title=""/></p><p>上图展示了典型的反馈循环结构。基线智能体执行任务产生输出,由人类评审或LLM评判者打分,反馈信息(分数、错误描述、改进建议)汇总后用于更新智能体，可能是调整提示词、微调参数、或修改配置。这个循环反复执行直到达成性能目标。</p><p>与固定配置的传统方案相比,自我进化智能体的核心差异在于能够监控自身表现并主动适应。多数已部署的智能体依赖人工设定的规则或提示,无法跟上数据分布的漂移或任务需求的演变。反馈循环解决了这个问题：每次任务完成后收集评估信号,识别薄弱环节,针对性地更新智能体。长期来看,系统的准确性和泛化性都会持续提升。这种机制对需要高准确率或面对动态环境的场景尤为关键，人类的角色从逐条修bug变成了设定目标和把握方向。</p><p>从架构视角看,自我进化系统可以抽象为四个核心要素：<strong>输入、智能体系统、环境、优化器</strong>，它们在迭代循环中交互。最近有综述将这类系统正式定义为"持续优化内部组件的自主系统,在保持安全性的前提下适应变化的任务与资源"。实际运行时,智能体执行标准的感知-推理-行动循环,但增加了自我评估和参数优化的元步骤。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047438391" alt="" title="" loading="lazy"/></p><p><strong>反馈循环的运作方式</strong>：从基线智能体开始(比如一个执行文档摘要的Agent),人类或LLM评判者对其输出进行评估。反馈信号既包括定量指标(0-1评分)也包括定性评论("摘要漏掉了关键细节")。多个信号汇总成综合得分，如果得分低于阈值(假设是0.8),就调整提示或策略重新测试。新版本达标后替换旧版本,循环继续。几轮迭代下来,智能体具备了自我修复能力。</p><p>这种设计的优势在于可扩展性(用LLM评估替代昂贵的人工标注)和适应性(自动响应新的失败模式,不需要手动改代码)。但也需要明确的安全约束：智能体在进化过程中必须保持稳定性(变化时不引入安全隐患)和性能单调性(不允许任务效果下降)。</p><h2>自我进化循环的核心步骤</h2><p>OpenAI Cookbook里有个经典示例,把进化循环拆成四步：</p><p><strong>第一步,基线智能体</strong>：准备一个初始版本,比如用特定提示词做文本摘要的Agent。</p><p><strong>第二步,收集反馈</strong>：让智能体跑一批任务,收集输出的评价，人工打分或者"LLM-as-Judge"的自动评分都行。评估内容包括摘要是否准确、是否简洁、是否符合业务规则等。</p><p><strong>第三步,量化评分</strong>：把反馈转成可度量的指标。可以是规则校验器、也可以是GPT评分标准,最后合成一个综合质量分。</p><p><strong>第四步,更新优化</strong>：如果得分没达标,就调整智能体内部——优化提示词、微调参数、或者换一个更好的版本,然后重新跑循环。</p><p>循环持续到性能超过阈值或达到重试上限。</p><pre><code> agent = BaselineAgent()  
 score = evaluate(agent)  
 while score &lt; target_score and tries &lt; max_retries:  
     feedback = get_feedback(agent)  
     agent = optimize_agent(agent, feedback)  
     score = evaluate(agent)</code></pre><p>每轮迭代都用收集到的反馈调整智能体。如果优化成功,新版本替换旧版本,成为下一轮的基线。</p><h2>关键模块解析</h2><p>自我进化智能体由几个紧密耦合的模块构成。</p><p><strong>智能体循环</strong>是最核心的部分，智能体接收输入(比如文档片段),更新内部记忆或上下文,运行LLM推理,产出结果(比如摘要)。这个流程通常用某种Agent SDK实现,负责管理LLM调用和工具使用。自我进化层包裹在外面,根据需要触发重跑或修改循环。架构上可以是单模块也可以是多模块——比如医疗场景可能同时有Summarizer和Compliance Checker两个子智能体。持续的"思考-行动"循环产生可评估的输出,为后续改进提供素材。</p><p><strong>任务性能监控</strong>负责追踪智能体的表现，典型配置包括自动评估器和可选的人工复核。以摘要任务为例,每个输出会经过四个评分器检查：</p><p>(1) Python函数检查关键术语(如化学名称)是否保留在摘要中;(2) 长度检查器控制冗长度;(3) 余弦相似度检测摘要与原文的语义一致性;(4) LLM评判者按评分标准给出综合评价。</p><p>前两个是确定性规则,第三个是模糊匹配,第四个提供灵活的语言理解评估。多个评分器协作,既产出量化分数也生成定性反馈。监控模块输出数字分数或pass/fail标志,外加描述问题的反馈文本。加权平均后得到汇总分数,决定输出是否可接受。这个监控信号驱动整个改进流程。</p><p><strong>内存模块</strong>对持续学习，短期记忆存储当前对话和规划状态,长期记忆保存累积知识、历史解法、总结出的规则。RAG(检索增强生成)让智能体能从知识库中拉取相关上下文。更复杂的系统会维护"记忆库",存放过去的决策和推理轨迹。记忆帮助智能体保留学到的经验：比如记住哪些提示模式效果更好,或者存储之前遇到的拒绝案例。进化循环可以把反馈和结果写入记忆,后续迭代查询时就能避免重蹈覆辙。</p><p><strong>奖励/反馈建模</strong>把原始反馈转换成训练信号，对于LLM智能体,通常会构建奖励模型或评分函数。每个评分器产出0-1分数,系统检查是否过阈值(比如0.85)。多个分数可以合并成单一指标(比如取均值),这个综合分数就是智能体的"奖励"。用强化学习的视角看,智能体被优化来最大化这个奖励。反馈也可以定性分类：如果某个评分器挂了,失败原因可以转成纠正指令。LLM评判者特别有用,因为它提供自然语言反馈("摘要需要更多细节"),智能体能直接用这些描述来改进输出。总之,奖励模块确保优化目标清晰——"所有评分器通过,或者均分超过0.8"。</p><p><strong>重训练/优化模块</strong>在性能不达标时更新智能体，提示词调优、参数微调、结构变化(如添加新工具)。一种常见做法是用LLM做<strong>提示改进</strong>而非直接训模型——"MetaPrompt"智能体拿到当前提示和反馈,被要求生成更好的版本。代码用新提示替换旧提示。更进阶的系统可能在收集的(输入,输出,反馈)数据上微调LLM,或用强化学习更新策略权重。核心思想是：根据反馈修改智能体内部组件(系统提示、模型权重、工具配置),让下一次执行有更大成功概率。重训后循环再次评估更新版本,形成闭环。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047438392" alt="" title="" loading="lazy"/></p><h2>反馈收集与重训练流程</h2><p>自我进化智能体的反馈主要靠自生成或众包。系统在一批任务上跑智能体,收集性能数据,包括：</p><p><strong>分数和标签</strong>：输出是否满足长度约束?是否包含必需实体?这些由自动检查器记录。</p><p><strong>文本反馈</strong>：LLM评判者输出解释性语句,说明哪里不足。</p><p><strong>日志和诊断</strong>：生成的token数、运行时统计、错误堆栈。</p><p><strong>人工标注</strong>：如果有人工复核,评级和评论会被记录。</p><p>智能体生成摘要后,评估代码调用各评分器,把输出解析成结构化结果(评分器名称、数字分数、pass/fail、推理描述)。辅助函数如</p><pre><code>parse_eval_run_output</code></pre><p>提取这些信息。智能体不依赖外部数据——自己的输出就是训练数据。随着时间推移,这会积累起(输入,输出,反馈)三元组的数据集。</p><pre><code> import time  
import json  

def run_eval(eval_id: str, section: str, summary: str):  
  """使用输入部分和输出摘要创建评估运行。"""  
  return client.evals.runs.create(  
    eval_id=eval_id,  
    name="self-evolving-eval",  
    data_source={  
      "type": "jsonl",  
      "source": {  
        "type": "file_content",  
        "content": [  
          {  
            "item": {  
              "section": section,  
              "summary": summary,  
            }  
          }  
        ],  
      },  
    },  
  )  

def poll_eval_run(eval_id: str, run_id: str, max_polls = 10):  
    """
    轮询评估运行直到完成或超时。

    此函数的存在是为了通过定期检查运行状态来处理评估服务中的异步行为。
    它通过在固定间隔轮询而不是无限期阻塞来平衡响应性和资源使用。
    重试限制可以防止在服务从不返回完成状态的情况下出现失控循环。
    """  
    run = None  
    for attempt in range(1, max_polls + 1):  
        run = client.evals.runs.retrieve(eval_id=eval_id, run_id=run_id)  
        if run.status == "completed":  
            break  
        if attempt == max_polls:  
            print("Exceeded retries, aborting")  
            break  

        time.sleep(5)  

    run_output_items = client.evals.runs.output_items.list(  
        eval_id=eval_id, run_id=run_id  
    )  
    return run_output_items  

def parse_eval_run_output(items):  
    """提取所有评分器分数和任何可用的结论输出。"""  
    all_results = []  

    for item in items.data:  
        for result in item.results:  
            grader_name_full = result.name  
            score = result.score  
            passed = result.passed  
            reasoning = None  
            try:  
                sample = result.sample  
                if sample:  
                    content = result.sample["output"][0]["content"]  
                    content_json = json.loads(content)  
                    steps = content_json["steps"]  
                    reasoning = " ".join([step["conclusion"] for step in steps])  
            except Exception:  
                pass  

            all_results.append(  
                {  
                    "grader_name": grader_name_full,  
                    "score": score,  
                    "passed": passed,  
                    "reasoning": reasoning,  
                }  
            )  

     return all_results</code></pre><p><strong>重训练流程</strong>：反馈收集完毕后,智能体进入更新阶段。摘要评估失败时,循环调用"MetaPrompt"智能体——输入原始提示、源文档、生成的摘要、失败原因。MetaPrompt LLM输出新提示。系统用这个新提示创建新版SummarizationAgent。本质上,智能体通过LLM重写指令完成了"重训练"。更高级的系统可能微调模型权重或调整其他模块(更新记忆条目、更换工具)。关键点是<strong>智能体从错误中学习</strong>。</p><p>每轮迭代都应该带来性能提升。示例循环给每个部分最多3次改进机会。如果新提示版本让摘要通过所有评分器(宽松阈值),循环继续;否则重复尝试。代码追踪哪个提示版本综合得分最高,处理完所有部分后部署最优版本。这种重训既可以离线批量做,也可以在线随新数据持续适应。最终产出一个只靠自生成反馈就进化得更准确的智能体。</p><h2>代码实现详解</h2><p>下面是OpenAI Notebook实现的关键部分。</p><p><strong>1、评估配置</strong></p><p>先定义带多个评分器的<strong>Eval</strong>来给智能体输出打分,用的是OpenAI Evals API。每个评分器检查特定标准：<strong>chemical_name_grader</strong>(Python代码)计算化学名称在摘要中的出现比例,保证领域关键词不丢失;<strong>word_length_deviation_grader</strong>控制摘要长度在容差范围内;<strong>cosine_similarity</strong>测量源文和摘要的语义重叠度;<strong>llm_as_judge</strong>用GPT-4.1按评分标准给综合分。这些评分器收集到</p><pre><code>testing_criteria</code></pre><p>列表,然后创建评估：</p><pre><code> from openai import OpenAI  
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))  

data_source_config = {  
    "type": "custom",  
    "item_schema": {"type": "object", "properties": {"section": {"type": "string"}, "summary": {"type": "string"}}, "required": ["section", "summary"]},  
    "include_sample_schema": False  
}  
testing_criteria = [  
    {  
        "type": "python",  
        "name": "chemical_name_grader",  
        "pass_threshold": 0.8,  
        "source": r"""  
def grade(sample: dict, item: dict) -&gt; float:  
    section = item["section"]  
    summary = item["summary"]  
    # 预期化学名称列表  
    CHEMICALS_MASTER = [...]  
    present = [chem for chem in CHEMICALS_MASTER if chem in section]  
    if not present:  
        return 1.0  
    correct = sum(1 for chem in present if chem in summary)  
    return correct / len(present)  
"""  
    },  
    {  
        "type": "python",  
        "name": "word_length_deviation_grader",  
        "pass_threshold": 0.85,  
        "source": r"""  
def grade(sample: dict, item: dict) -&gt; float:  
    summary = item["summary"]  
    word_count = len(summary.split())  
    expected = 100  
    tolerance = 0.2  
    deviation = abs(word_count - expected) / expected  
    if deviation &lt;= tolerance:  
        return 1.0  
    score = max(0.0, 1.0 - (deviation - tolerance))  
    return score  
"""  
    },  
    {  
        "type": "text_similarity",  
        "name": "cosine_similarity",  
        "input": "{{ item.summary }}",  
        "reference": "{{ item.section }}",  
        "evaluation_metric": "cosine",  
        "pass_threshold": 0.85,  
    },  
    {  
        "type": "score_model",  
        "name": "llm_as_judge",  
        "model": "gpt-4.1",  
        "input": [  
            {  
                "role": "system",  
                "content": (  
                    "You are an expert summarization evaluator. Score the summary between 0 and 1..."  
                )  
            },  
            {  
                "role": "user",  
                "content": (  
                    "Section:\n{{item.section}}\nSummary:\n{{sample.output_text}}"  
                )  
            }  
        ],  
        "range": [0, 1],  
        "pass_threshold": 0.85,  
    },  
]  
eval = client.evals.create(  
    name="self_evolving_eval",  
    data_source_config=data_source_config,  
    testing_criteria=testing_criteria  
)  
 print(f"Created Eval: {eval.id}")</code></pre><p>这段代码导入OpenAI客户端,配置自定义数据schema(每个item有section和summary),定义四个评分器。Python评分器用内联代码(raw string)定义</p><pre><code>grade</code></pre><p>函数。</p><pre><code>client.evals.create()</code></pre><p>创建评估但还不执行。这些规则会对智能体生成的每个摘要自动打分。</p><p><strong>2、执行评估</strong></p><p>接着定义辅助函数,<strong>在给定的section-summary对上跑评估</strong>并解析结果：</p><pre><code> import time, json  

def run_eval(eval_id: str, section: str, summary: str):  
    """使用一个示例(section+summary)安排评估运行。"""  
    return client.evals.runs.create(  
        eval_id=eval_id,  
        name="self-evolving-eval",  
        data_source={"type": "jsonl", "source": {"type": "file_content", "content": [  
            {"item": {"section": section, "summary": summary}}  
        ]}}  
    )  

def poll_eval_run(eval_id: str, run_id: str, max_polls=10):  
    """轮询直到评估运行完成,然后返回输出项。"""  
    for attempt in range(max_polls):  
        run = client.evals.runs.retrieve(eval_id=eval_id, run_id=run_id)  
        if run.status == "completed":  
            break  
        time.sleep(5)  
    return client.evals.runs.output_items.list(eval_id=eval_id, run_id=run_id)  

def parse_eval_run_output(items):  
    """从评估运行输出中提取评分器分数和推理。"""  
    all_results = []  
    for item in items.data:  
        for result in item.results:  
            score = result.score  
            passed = result.passed  
            reasoning = None  
            try:  
                content = result.sample["output"][0]["content"]  
                reasoning = json.loads(content)["steps"][0]["conclusion"]  
            except Exception:  
                pass  
            all_results.append({  
                "grader_name": result.name,  
                "score": score,  
                "passed": passed,  
                "reasoning": reasoning  
            })  
    return all_results  

# 示例运行  
EVAL_ID = eval.id  
SECTION = "...some section text..."  
SUMMARY = "...agent's summary..."  
eval_run = run_eval(EVAL_ID, section=SECTION, summary=SUMMARY)  
run_output = poll_eval_run(EVAL_ID, run_id=eval_run.id)  
grader_scores = parse_eval_run_output(run_output)  
 print(grader_scores)</code></pre><pre><code>run_eval</code></pre><p>函数把一个样本(section+摘要)发送给评估服务,然后轮询等待完成(</p><pre><code>poll_eval_run</code></pre><p>),最后解析结果。输出是字典列表,每个评分器一条,格式类似</p><pre><code>{"grader_name": ..., "score": ..., "passed": ..., "reasoning": ...}</code></pre><p>。多数评分器只返回分数和pass/fail,LLM评分器会额外附带推理文本。这种结构化反馈供循环决定如何改进智能体。比如</p><pre><code>chemical_name_grader</code></pre><p>失败,说明摘要漏掉了关键术语。</p><p><strong>3、智能体与提示版本管理</strong></p><p>下一步配置智能体本身和提示版本追踪的数据结构,用OpenAI <strong>Agents SDK</strong>定义智能体并管理提示。</p><p>配置包括：</p><pre><code>VersionedPrompt</code></pre><p>类(基于Pydantic)记录提示版本和元数据;</p><pre><code>PromptVersionEntry</code></pre><p>存储每个版本的文本、版本号、模型、时间戳等;两个智能体——<strong>SummarizationAgent</strong>(执行实际任务)和<strong>MetaPromptAgent</strong>(负责改写提示)。</p><pre><code> from datetime import datetime  
from typing import Any, Optional  
from pydantic import BaseModel, Field  

class PromptVersionEntry(BaseModel):  
    """存储提示的一个版本和相关元数据。"""  
    version: int  
    model: str = "gpt-5"  
    prompt: str  
    timestamp: datetime = Field(default_factory=datetime.utcnow)  
    metadata: Optional[dict[str, Any]]  

    class Config:  
        validate_assignment = True  
        extra = "forbid"  

class VersionedPrompt:  
    """跟踪PromptVersionEntry列表并允许更新。"""  
    def __init__(self, initial_prompt: str, model: str = "gpt-5"):  
        self._versions = [PromptVersionEntry(version=0, model=model, prompt=initial_prompt)]  
    def current(self) -&gt; PromptVersionEntry:  
        return self._versions[-1]  
    def update(self, new_prompt: str, model: Optional[str] = None, metadata: Optional[dict]=None):  
        next_version = self.current().version + 1  
        entry = PromptVersionEntry(version=next_version,   
                                   model=model or self.current().model,  
                                   prompt=new_prompt, metadata=metadata)  
        self._versions.append(entry)  
        return entry  

# 创建智能体和初始提示  
from agents import Agent  # 假设的agents SDK  

METAPROMPT_TEMPLATE = """  
Context:  
Original prompt: {original_prompt}  
Section: {section}  
Summary: {summary}  
Reason to improve: {reasoning}  

Task:  
Write an improved summarization prompt that is more specific and preserves all details...  
"""  

metaprompt_agent = Agent(name="MetaPromptAgent", instructions="You are a prompt optimizer.")  
summarization_prompt = VersionedPrompt(initial_prompt="You are a summarization assistant. Given a section, produce a summary.")  
 summarization_agent = Agent(name="SummarizationAgent", instructions=summarization_prompt.current().prompt, model=summarization_prompt.current().model)</code></pre><pre><code>VersionedPrompt</code></pre><p>确保每次提示变更都有记录(版本1、2、3...)。</p><pre><code>PromptVersionEntry</code></pre><p>存储文本及相关模型、版本号等信息。代码实例化了一个"MetaPromptAgent"专门负责重写提示,以及一个用简单初始提示的SummarizationAgent。循环中每次更新提示时调用</p><pre><code>summarization_prompt.update(...)</code></pre><p>,新条目追加到版本列表,需要时可以回滚。这套机制让提示演变过程可追溯。</p><p><strong>4、自我进化循环编排</strong></p><p>最后是核心的自我改进循环实现。单次迭代的逻辑：</p><ol><li>智能体用当前提示<strong>生成摘要</strong>;</li><li>在(section, summary)上<strong>跑评估</strong>拿到评分;</li><li>计算综合分数(评分器均值),检查是否过宽松阈值;</li><li>通过则成功;未通过则<strong>收集反馈</strong>并改进提示;</li><li>每个部分最多重试若干次;</li><li>所有部分处理完后,选择综合得分最高的提示版本。</li></ol><p>简化代码如下：</p><pre><code> MAX_RETRIES = 3  
for section, content in dataset:  
    for attempt in range(1, MAX_RETRIES+1):  
        # 运行总结智能体  
        result = Runner.run(summarization_agent, content)    
        summary = result.final_output  
          
        # 用评分器评估  
        grader_scores = await get_eval_grader_score(eval_id=EVAL_ID, section=content, summary=summary)  
        avg_score = calculate_grader_score(grader_scores)  
        passed = is_lenient_pass(grader_scores, avg_score)  
          
        print(f"Attempt {attempt}: avg score={avg_score}, passed={passed}")  
        if passed:  
            break  
          
        # 如果失败,收集文本反馈并向MetaPromptAgent询问新提示  
        feedback = collect_grader_feedback(grader_scores)  
        prompt_input = METAPROMPT_TEMPLATE.format(  
            original_prompt=summarization_prompt.current().prompt,  
            section=content,  
            summary=summary,  
            reasoning=feedback  
        )  
        meta_result = await Runner.run(metaprompt_agent, prompt_input)  
        improved_prompt = meta_result.final_output  
          
        # 更新总结智能体的提示  
        summarization_prompt.update(new_prompt=improved_prompt, metadata={"section": content, "summary": summary})  
        summarization_agent = Agent(name="SummarizationAgent", instructions=improved_prompt, model=summarization_prompt.current().model)  
         print(f"  Improved prompt to version {summarization_prompt.current().version}")</code></pre><p>对每个文档部分,</p><pre><code>SummarizationAgent</code></pre><p>生成摘要,然后跑评估(</p><pre><code>get_eval_grader_score</code></pre><p>)计算分数。未通过检查时,组装反馈字符串(如"化学名称缺失"或LLM给的原因描述),调用MetaPrompt智能体传入原始提示、文档片段、摘要和反馈。MetaPrompt LLM返回<strong>新提示</strong>,更新</p><pre><code>VersionedPrompt</code></pre><p>并重建SummarizationAgent。重试最多</p><pre><code>MAX_RETRIES</code></pre><p>次直到通过或放弃。处理完所有数据后,追踪哪个提示版本综合得分最高。实际循环会记录每一步并最终打印最优版本。这展示了<strong>自生成反馈</strong>(评分器结果)如何驱动迭代改进——智能体在教自己如何写更好的提示。</p><h2>总结</h2><p>自我进化智能体适用于任何任务复杂且持续演变的领域。除了医疗文档,<strong>金融</strong>(智能体跟随市场变化更新策略)、<strong>编程</strong>(代码生成智能体适应新库和新错误模式)、<strong>生物医学</strong>(研究助手迭代优化文献综述)都是潜在场景。相关研究已经指出生物医学、编程、金融这些垂直领域的具体策略。代码生成智能体可以根据测试结果持续改进编码风格或错误检测逻辑;客服聊天机器人可以从新类型的用户咨询中在线学习。</p><p>随着AI智能体被部署到关键任务,自动自我改进能把人力从繁琐的debug转移到高层决策——设定目标、确保安全。能够自我纠错的智能体长期来看更可靠。</p><p>最后这个领域还很新,算是对这个方向的首批系统性审视之一,开放问题很多。比如说如何安全地允许智能体改写自身行为?什么评估基准最适合持续学习?但前景很有吸引力：未来的助手能优雅地从经验中学习;工厂机器人随生产需求自我调整;教育导师为每个学生个性化自己的教学策略。从静态AI到真正的终身学习智能体,这条路刚刚开始。</p><p><a href="https://link.segmentfault.com/?enc=mds4wYBelQhGyN%2F8blHoDA%3D%3D.OHjxUxKTlwjkxMEjzDAOATqQhrnedcciVa8BqkPsSE2aeic1vhneoz2XfUDYddR0XIqnRaEiEtYNzVpkOZIZkA%3D%3D" rel="nofollow" target="_blank">https://avoid.overfit.cn/post/39758407b909479aab400a01b29bac65</a></p><p>作者：DhanushKumar</p>]]></description></item><item>    <title><![CDATA[计算机组成原理 - 计算机系统概述 Al]]></title>    <link>https://segmentfault.com/a/1190000047438409</link>    <guid>https://segmentfault.com/a/1190000047438409</guid>    <pubDate>2025-11-29 23:01:55</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>计算机组成原理</h2><h3>概述</h3><h4>计算机系统</h4><h5>简介</h5><p>计算机系统由<strong>硬件</strong>和<strong>软件</strong>两大部分组成</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438411" alt="image-20230623125741365" title="image-20230623125741365"/></p><h5>计算机软硬件机器</h5><p>微程序机器 M0、实际机器 M1 归属于硬件 ；虚拟机 M2、M3、M4 归属于软件</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438412" alt="image-20230622094955297" title="image-20230622094955297" loading="lazy"/></p><h5>计算机体系结构和计算机组成区别</h5><p>计算机体系结构：程序员所见到的计算机系统的属性概念性的结构与功能特性（指令系统、数据类型、寻址技术、I/O 机理等）类似定义接口的概念</p><p>计算机组成：实现计算机系统结构所体现的属性（具体指令的实现）类似接口实现的概念</p><p>举例说明：一台机器是否具有某一项功能是计算机体系结构的问题，以至于这项功能是怎么实现得就是计算机组成的问题</p><h4>计算机的基本组成</h4><h5>冯.诺伊曼计算机的特点</h5><p>1、五大部件组成（控制器、运算器、存储器、输入设备、输出设备）</p><p>2、指令和数据以相同的地位存储在存储器中，可按地址进行寻访</p><p>3、指令由操作码和地址码组成</p><p>4、指令和数据以二进制的形式表示</p><p>5、以运算器为中心</p><p>6、指令在存储器内按顺序存放</p><h5>存储器的基本组成</h5><p>主要介绍存储体、存储器地址寄存器 MAR、存储器数据寄存器 MDR</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438413" alt="image-20230622150559063" title="image-20230622150559063" loading="lazy"/></p><h5>运算器的基本组成</h5><p>主要介绍算数逻辑运算单元 ALU、累加器 ACC、乘商寄存器 MQ、操作数寄存器 X</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438414" alt="image-20230622132557894" title="image-20230622132557894" loading="lazy"/></p><h5>控制器的基本组成</h5><p>主要介绍控制单元 CU、程序计数器 PC、指令寄存器 IR</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438415" alt="image-20230622135326640" title="image-20230622135326640" loading="lazy"/></p><h5>主机完成一条指令的过程</h5><p><strong>以取数指令为例</strong></p><p>指令包含两部分：一个是指令码（决定进行什么操作，比如是取数操作）；另一个是地址码（存放数据的地址）</p><p>步骤 1：取<strong>取数指令</strong>到指令寄存器 IR （绿线）</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438416" alt="image-20230622142251410" title="image-20230622142251410" loading="lazy"/></p><p>步骤 2：分析指令码以及执行指令操作（红线）</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438417" alt="image-20230622143704305" title="image-20230622143704305" loading="lazy"/></p><p><strong>以存数指令为例</strong></p><p>步骤 1：取<strong>存数指令</strong>到指令寄存器 IR （如上图取取数指令步骤 1）</p><p>步骤 2：分析指令码以及执行指令操作（橙线）</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438418" alt="image-20230622144324986" title="image-20230622144324986" loading="lazy"/></p><h4>计算机硬件的主要技术指标</h4><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438419" alt="image-20230622150434734" title="image-20230622150434734" loading="lazy"/></p><h3>计算机发展及应用</h3><p>略</p>]]></description></item><item>    <title><![CDATA[亚马逊为 Bedrock AgentCo]]></title>    <link>https://segmentfault.com/a/1190000047438452</link>    <guid>https://segmentfault.com/a/1190000047438452</guid>    <pubDate>2025-11-29 23:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>本文已收录在<a href="https://link.segmentfault.com/?enc=%2BoVLYp5XYDhGTM7N4VgI5g%3D%3D.%2FXG8RHRv63OxxhcsTiMUYofJIuzZ8ETL7H%2BD8rHrbAKWNQKQGjyIwfWazEVvV7P%2FrNnUXXxJcwQ3iDgvjCPZcw%3D%3D" rel="nofollow" target="_blank">Github</a>，<strong>关注我，紧跟本系列专栏文章，咱们下篇再续！</strong></p><ul><li>🚀 魔都架构师 | 全网30W技术追随者</li><li>🔧 大厂分布式系统/数据中台实战专家</li><li>🏆 主导交易系统百万级流量调优 &amp; 车联网平台架构</li><li>🧠 AIGC应用开发先行者 | 区块链落地实践者</li><li>🌍 以技术驱动创新，我们的征途是改变世界！</li><li>👉 实战干货：<a href="https://link.segmentfault.com/?enc=3OCFACAFhaSFTCEDTy5bbw%3D%3D.rDGlYHGrU2EWpXMApaS0%2FHQ%2BKGMzULmpdBVyY3bDAik%3D" rel="nofollow" target="_blank">编程严选网</a></li></ul><h2>0 前言</h2><p>亚马逊 <a href="https://link.segmentfault.com/?enc=I7D2O39psjlVFRIcXixlAA%3D%3D.KRa0askjeX96AwlAt99zcr5S%2BG1fS9eqCKXdCZ2IxU0jMp4bgqACfHrXAbshffgCfewK%2B4c8gu62Palv6jV9WTpCtQHKWmxbs9INJz6x7fcVpDO6LOwkIy7X%2BdOyRCv%2B%2B1i8fhY7B9HK3T7mixVYVhluDWIYNBjXLURNTUKCWyE%3D" rel="nofollow" target="_blank">宣布</a>，在 <strong>Amazon Bedrock AgentCore Runtime</strong> 正式支持A2A协议<strong>，让基于不同框架构建的智能体之间能够实现通信与协作。</strong></p><p>该协议支持来自 <a href="https://link.segmentfault.com/?enc=w%2BLCmfHJt5%2F%2FS1qp8ay1Rw%3D%3D.%2BR1ey4j9Qar5%2B0Ef8WbiAGYnTVRVZlIamN5Gf%2Bvpg6BuhaAxsxnnFwTulLHNdBYP" rel="nofollow" target="_blank">Strands Agents</a>、<a href="https://link.segmentfault.com/?enc=%2BoqP1djSwde7udySoRtPFw%3D%3D.yc6w5L0CSbA1age6HSwAeC3lOPWGjHCKdrJw2v%2BJmUsOL2woHluWFnH5NgxB0z8b" rel="nofollow" target="_blank">OpenAI Agents SDK</a>、<a href="https://link.segmentfault.com/?enc=TzNpGw4Po4S4xIH8FfxhUg%3D%3D.oyej9fQYXkUw%2B9%2F5110J8C8WE9HKjsL5L1t47Z4A6LT8WXhhd4DuH3B7c1JB5VZs" rel="nofollow" target="_blank">LangGraph</a>、<a href="https://link.segmentfault.com/?enc=PYiOMCVKa%2B51WWYqdUWF6A%3D%3D.N1UlAAUypnuxyTdm%2F4Tuy%2FUVyIXVwnYnfORWnSKE6xZh6f9TW0stkEGky%2BM6JaQJ" rel="nofollow" target="_blank">Google ADK</a> 和 <a href="https://link.segmentfault.com/?enc=ZtnrniL6vK7feH1T2a5qHQ%3D%3D.2TjQkRI8PpPKHeZVJGrd3y89j5LOhoBuS2ld5bqKSNsYSp1Vky1RjqiJx808i6l8epwzAJ%2BFjdDdfZK2qenvzw%3D%3D" rel="nofollow" target="_blank">Claude Agents SDK</a> 等框架的智能体以“通用且可验证的格式”共享上下文、能力与推理信息。</p><p>Bedrock AgentCore Runtime充当这些跨智能体通信的基础设施层。通过 <a href="https://link.segmentfault.com/?enc=s1lD%2FG3a4BJqW0Vj4q5%2Fig%3D%3D.VvpxVBxw7jEfzLAE9cwYmCbwe15k1Hj1WhjqwgtFo%2F3BHE2pIVNmTK5Lv6b8K7Ia" rel="nofollow" target="_blank">A2A</a>，开发者可以构建跨框架的多智能体工作流，实现系统级协作。</p><h2>1 智能体系统的基础组件</h2><p><a href="https://link.segmentfault.com/?enc=dbRDJoOVyWbl5pdtnhkRWA%3D%3D.PhNLhI4HuwOmY0DUrRjgKgSemJBY5Wmkx8D1r1PbV2kD0NS1VruGmam7xm%2Fc8nQQ" rel="nofollow" target="_blank">智能体系统（Agentic systems）</a>想高效运行，需要多个核心组件协同工作：</p><ul><li><strong>记忆（Memory）</strong>：包括短期记忆（维持会话上下文）和长期记忆（跨多次会话保留洞察）</li><li><strong>工具（Tools）</strong>：赋予智能体执行功能，可通过原生集成或 <a href="https://link.segmentfault.com/?enc=80B1%2FhryNhe8IdYzqOpeyA%3D%3D.vMJNfLSEtorLA6jwovMpi2DudlFWwNifqQFzA3JQXWw%3D" rel="nofollow" target="_blank">Model Context Protocol（MCP）</a> 服务器访问</li><li><strong>身份管理（Identity Management）</strong>：通过 <a href="https://link.segmentfault.com/?enc=rpzXblkXC6zAI0bdzRGviw%3D%3D.k%2BslUqEVDA%2BctGF3uWyubJ0%2B72%2BPBViglzSnK8LDeW4%3D" rel="nofollow" target="_blank">IAM</a> 提供安全认证与权限控制，使智能体可代表用户或自主访问资源</li><li><strong>安全防护（Guardrails）</strong>：通过 <a href="https://link.segmentfault.com/?enc=%2BAAdKqPTAH8T9VydBxLAaA%3D%3D.aNNTyqc5GhHmIDuDKQaBDWhZbaAUMWDZmhlg2QkzUQeVNZp%2Fd33B2uMj%2FiRXr5bu" rel="nofollow" target="_blank">Bedrock Guardrails</a> 检测有害内容、防止幻觉、确保输出符合政策和事实准确性</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438454" alt="" title=""/><br/><em>来源：<a href="https://link.segmentfault.com/?enc=09sVkZxPFHWkNImMO5AmeA%3D%3D.TYjGVVaTonE0TKQ0xokzZ7hPsf5d6tsxf%2FpD5C4qigrfBEggeMdUXhzz7E%2Fv2F7nCdzEfQ1Oc86Aipu%2FS7ND8P4YEP5vAr73C7kJywx73ePj3eQ6KiYfcIWcDlON5Z73d0EWRV5pwswrblGHPhTGyA%3D%3D" rel="nofollow" target="_blank">Bedrock AgentCore 平台</a></em></p><hr/><h2>2 A2A 与 MCP 的区别</h2><p><a href="https://link.segmentfault.com/?enc=roIaM4futMvovg8MaWpGzg%3D%3D.J%2FufbbnBwj%2Bu1UyDCiACPZGwQfJl27n%2BNoiYgOiwVjjBfE8StFEbjkhtkVJYR5XTrxXr12SIiFUhLLoS%2Bj1VmXjSso9gAqtHa8dMgkRN6lDPT5ZFokbEo3lJWMtLI9zQL0SqBU9nXy7lq9Bow2jnfL%2Fvk2r2lQTU6K3XDf%2FPSVA%3D" rel="nofollow" target="_blank">A2A 协议</a> 解决 <strong>智能体之间的通信</strong> 问题，而 <a href="https://link.segmentfault.com/?enc=w2txxRCJ95V%2FuKNhCR9CZA%3D%3D.22fCv4hBPwaI4dTHEoMRP2%2Fp%2FmjK49%2BjJ8Sa1rUxpfk%3D" rel="nofollow" target="_blank">MCP</a> 解决 <strong>智能体与资源之间的连接</strong> 问题。</p><ul><li><strong>MCP</strong>：让单个智能体能访问其工具和数据源</li><li><strong>A2A</strong>：让多个智能体能彼此协调，共同完成任务</li></ul><p>这一区别对系统架构尤为重要——前者侧重“智能体到资源”，后者侧重“智能体到智能体”的协作通信。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438455" alt="" title="" loading="lazy"/><br/><em>来源：<a href="https://link.segmentfault.com/?enc=KbH768mnRBuUjJFm41h2CA%3D%3D.J72qecyc2wc0AfYdN20OiP1V9sDqII1nSrzZ%2F3qUsUs%2B9D328INCpmeJ44h7TWsxMnvEJEdKCkhL4F3Z1r6tv%2BC3z8ToZiqxpoG8%2FUkASKT8IiUMf%2FzfDpuhaIxBK27XYgYjufxIFco8f6l7WQViE%2FHKhMo4z%2FVepkVjGc6KyXM%3D" rel="nofollow" target="_blank">AWS 官方博客</a></em></p><hr/><h2>3 协议特性：松耦合与模块化</h2><p>A2A 协议采用 <a href="https://link.segmentfault.com/?enc=22SGMmLVUQnGa5G9J1bM3w%3D%3D.XkfwDWp9MDoCX9L5qC87luw1OUY7bWlPwKpSEXKwXeACRWdMAJUDLh%2BZpMWfMX3E" rel="nofollow" target="_blank">松耦合（Loose Coupling）</a> 与 <a href="https://link.segmentfault.com/?enc=CuGs7iDPKKqrSnnZ%2Fug%2FZA%3D%3D.pstU%2FXlQ7zgsinkXLYdL6CervYp%2Bo5nppv4Po%2BGb6uY4zlyaHEhLT21hPYnmEbJG" rel="nofollow" target="_blank">模块化（Modularity）</a> 设计，使每个智能体能作为独立单元运行。开发者可独立开发、测试、部署和升级单个智能体，而不影响整个系统。新智能体可无缝加入现有部署，而发生故障的智能体也能被隔离在定义好的交互边界内。</p><h2>4 动态发现与编排</h2><p>协议支持动态的 <strong>智能体发现与编排（Orchestration）</strong>。智能体通过标准化的模式（Schema）发布自身的能力信息，形成一个“功能注册表”。<br/><strong>编排智能体（Orchestrator Agents）</strong> 可基于实时任务需求发现并调用最合适的智能体，从而实现 <strong>自适应工作流</strong> ——任务会根据上下文动态分配给合适的智能体执行。</p><h2>5 技术实现：Agent Card 与 Task Object</h2><ul><li><strong>A2A服务器（A2A Server）</strong>：远程智能体通过实现协议规范的 HTTP 接口来提供服务，支持 <a href="https://link.segmentfault.com/?enc=Qsm5MHAKKg8vujJhUzpgow%3D%3D.dY1qPZnH73xFTLSNw92eYL8oMKubdIa6PjMBEP81g1x8zufB8aWufCc%2FElQf7O58PUQ1z%2BJQBxgVkHpKoLM9e84E2SGLIJd0eJ12ZSPfHZQ%3D" rel="nofollow" target="_blank">HTTP/S</a> 上的 <strong>JSON-RPC 2.0</strong> 通信，既可 <a href="https://link.segmentfault.com/?enc=oNlk23LogYriXZMVeX6rtQ%3D%3D.VNmAFzKQSBqPcE6Akxk8iXB0FPRZewf4NLBbowaddigpc8dQafpkBOM2ZGfa84W0a7qYvOeXQFzesKj%2FRhvkRQiiQmJ5oqfyPhyZZzTOCZwGEE5VOjeCoN%2FESr08yGavKGJ1XK%2BTczQrAe3Exzhq5%2FXy73ee%2FozWn0OPVpftYuE%3D" rel="nofollow" target="_blank">同步</a>，也可 <a href="https://link.segmentfault.com/?enc=6cmAlKv5vusGQTQq%2Br%2BAzw%3D%3D.vRlqV7y4H1VN%2B0VFFDxu2nIHVGSOxCc8RrGC36J7ZjvKeaKFU6snLDiqRvJk18lbj0eYxIHijYc9cVDUDPym5seorfDWdLnS2MWB%2BJRFiZLgv3q1XvJStS6%2BqXGlF1l3VMCJLwS%2FsgXTu1kNYcX6K4qh6hEG8U4Naozkzp2a1so%3D" rel="nofollow" target="_blank">异步</a> 交互</li><li><strong>Agent Card</strong>：每个智能体都会发布一个 JSON 元数据文件，描述其身份、功能、接口端点及认证要求<br/>这相当于一份“契约说明书”，让其他智能体能正确地与其交互。</li><li><strong>Task Object</strong>：代表系统中流动的每个任务单元，包含唯一标识符和生命周期信息。任务可能是长时间运行的过程，涉及多个智能体的多轮协作。协议会跟踪任务状态，帮助编排器监控进度、处理故障或超时</li></ul><h2>6 安全性与社区反馈</h2><p>安全研究机构 <a href="https://link.segmentfault.com/?enc=RZaQWyj7m3Sb1xjWyCCb0A%3D%3D.RhDzeMwJRhWDmeSgSx7tQ7dZYtai6CS8PHmBu0xVQpGIx5XJyLuIT64KlCxmoTth" rel="nofollow" target="_blank">Unit42（Palo Alto Networks）</a> 指出，A2A 协议的状态化设计可能带来安全风险。根据其 <a href="https://link.segmentfault.com/?enc=8iZYE0m4lGCQRQ%2Bs1FPbfA%3D%3D.10w8Sja2tSlWam8TAsxm2wZBs2fch4HWrMIKXwIULgY%2FAIBi3Tn1ozyYre%2BSDRbkHR6%2FrPtuJnkiBwOYlGIkx0cXhmYOISRU31EqHlRiILjQalL%2FwtP9Ykymm2ltInf7" rel="nofollow" target="_blank">分析报告</a>：</p><blockquote>A2A允许智能体在会话中记住交互历史并保持上下文一致性。这种特性可能被攻击者利用，通过“会话走私（Session Smuggling）”注入恶意指令，将其隐藏在正常请求与响应之间。</blockquote><h2>7 开发资源与文档</h2><p>有兴趣实现基于 A2A 的系统的开发者，可参考：</p><ul><li><a href="https://link.segmentfault.com/?enc=MXqx6lMpHMerz6r3s5bg9A%3D%3D.6YKh7bcMTaHTqycJpjFF%2BRr%2F%2F%2FyaZ%2FWxtpJGvr5MfYf9TSjkR1bm41h98St3bDzLWvuZEnLROeujRZm0zNl%2FhEym0eyzA2wEWRvQJ0edrbMpBbxYT1rq7y9o1B2BtnzA1QVV0QOpT440aS3mc5ZfmRDvv0eWY4PfjA2X%2FcwPlLI%3D" rel="nofollow" target="_blank">A2A 教程与示例代码</a></li><li><a href="https://link.segmentfault.com/?enc=S%2F01GLJ3%2BKBikAFphpkYtw%3D%3D.t46%2BqxX4%2BP2grYjhMqwLL%2BAWEQgP6mOFcruPmFOYpb88BjwDTTORmHip%2F6inaJ0E" rel="nofollow" target="_blank">Bedrock AgentCore 开发者指南</a> ——详细介绍运行时操作、内存管理与身份控制</li><li><a href="https://link.segmentfault.com/?enc=fJB2vhrqs2r5xT%2F5oZyDZQ%3D%3D.nY3e2LohPNAa6Zsy%2BiPMdGAKAo1lPbQf7q0nQIVAhY0Z8TKGupIs%2F0myb%2FtaDWq7p2dmRySjy5m2MX5As0PSR2dPGcf09mX4%2BtfHMV8PMEfWIkmF3GtnYJrL95Q1pvkGpa04sqK2xugtcjqO12fQ4w%3D%3D" rel="nofollow" target="_blank">A2A 协议规范文档</a> ——定义智能体间通信的技术要求与交互模式</li><li><a href="https://link.segmentfault.com/?enc=kDUORBaeUmOnx46e709AnQ%3D%3D.NE1F8VFvHoRMi96H7YhKEaVGI%2FjvumPX0JMgnJYTm2p2T1DjSy%2BGkzzT941gE1hBa8kZhYgr8HJPD1OQcQ1IRbRRLYsyf0gnthBlTP4xGY0%3D" rel="nofollow" target="_blank">InfoQ 早期报道</a> ——回顾 Bedrock AgentCore 平台最初发布时的功能背景</li></ul><p>通过引入A2A，亚马逊进一步推动了多智能体生态系统的互操作与标准化，使不同框架和平台上的智能体能够协同工作，构建更复杂、更智能的分布式 AI 系统。</p>]]></description></item><item>    <title><![CDATA[Outlook OWA是什么？2025登]]></title>    <link>https://segmentfault.com/a/1190000047438337</link>    <guid>https://segmentfault.com/a/1190000047438337</guid>    <pubDate>2025-11-29 22:04:33</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在当今数字化办公的时代，企业对于高效、安全且便捷的邮件管理工具需求日益增长。Outlook的OWA网页版为企业提供了一种跨平台的邮件管理方式，而Zoho企业邮箱则凭借其独特的优势，成为外贸企业等众多企业的优选。下面将详细介绍Outlook OWA网页版的使用方法，并对比分析Zoho企业邮箱的优势。<br/><img width="723" height="443" referrerpolicy="no-referrer" src="/img/bVdnc2C" alt="" title=""/></p><h2>一、Outlook邮箱的OWA简介</h2><p>OWA的定义<br/>OWA，全称 Outlook Web App，是微软专为企业用户打造的网页版邮件管理平台。用户无需安装独立客户端，只需通过浏览器就能直接访问，轻松实现收发邮件、管理联系人和日历等操作。</p><h2>OWA与Outlook客户端的区别</h2><p>平台依赖：OWA摆脱了下载安装的束缚，任何设备只要有浏览器即可访问；而Outlook客户端则需安装在PC或移动端才能使用。<br/>实时性：OWA具备强大的实时同步功能，邮件、日历等内容能够随时与服务器保持同步，确保信息及时更新。<br/>操作体验：客户端支持更多本地功能，例如离线访问、集成进Windows等；OWA则更加轻便，操作界面简洁易用，降低了用户的学习成本。<br/>OWA的功能优势<br/>跨平台访问：只要有网络和浏览器，OWA就能让企业邮箱实现随时随地登录，极大地提升了远程办公的效率，非常适合现代企业不断变化的工作环境。<br/>简化操作界面：OWA简洁的结构使得常用功能如收件箱、发件箱、日历、任务等一目了然，有效降低了新手员工的操作门槛。<br/>实时同步功能：所有邮件和会议日程都会与服务器自动同步，保证信息的及时更新，杜绝因信息延误而带来的损失。</p><h2>二、如何使用Outlook的OWA</h2><p>登录OWA<br/>直接访问 OWA 官方网址：<a href="https://link.segmentfault.com/?enc=YY%2BV3jERUkE2vZd%2FnCHgWw%3D%3D.WGD9HbK6V6bPLPrK9pT1gb3YE4vxwHbnD%2FxACJKNrTQ%3D" rel="nofollow" target="_blank">https://outlook.office.com/</a> ，输入企业分配的邮箱账号和密码，即可完成登录。</p><h2>邮件管理操作</h2><p>发送和接收邮件：点击“新建邮件”，输入收件人、主题与正文，还可以添加附件。OWA支持较大附件传输，方便企业进行文件共享。<br/>管理邮件文件夹：支持自定义文件夹、快速邮件归档和搜索功能，有助于企业高效整理业务往来邮件。<br/>设置邮件规则：用户可以根据自己的需求自定义规则，例如自动分类、转发、删除垃圾邮件等，从而提升邮件处理效率。</p><h2>三、推荐：Zoho邮箱的替代优势</h2><p>企业在开展国际业务、进行跨国通讯时，对邮件的安全性和海外邮件的稳定收发能力有着更高的要求。Zoho企业邮箱凭借其卓越的性能，受到了全球1800万企业级客户的信赖，成为各类域名邮箱管理、移动办公以及海外业务的首选。</p><h2>Zoho邮箱的特色功能</h2><p>强大的邮件过滤与安全功能：内置先进的反垃圾邮件引擎和邮件加密技术，能够全面防御垃圾邮件和钓鱼邮件。同时，提供多层身份验证、TLS传输以及加密存储，全方位保障企业核心数据的安全。<br/>丰富的协作工具：Zoho Mail不仅仅是一个邮件管理工具，还集成了聊天、日历、任务、笔记、文件管理等功能，实现了企业级一体化办公。此外，原生CRM集成功能，非常适合外贸客户跟进，使销售进展更加透明化。<br/>定制化与品牌化：支持企业自定义域名（域名邮箱设置过程便捷），并且邮箱界面可以根据企业的品牌形象进行贴合设计。详细的注册步骤从域名绑定到多账号分配，只需数分钟即可启动。<br/>Zoho邮箱与Outlook OWA的对比<br/>以下是Zoho Mail与Outlook OWA在多个维度的简要对比：</p><p>对比项目    Zoho企业邮箱    Outlook OWA<br/>海外收发稳定性    全球多个数据中心，专为国际邮件优化    主要依赖微软全球节点<br/>安全防护    邮箱加密、反垃圾邮件、钓鱼拦截先进（企邮排行前三）    微软安全体系，防御能力强<br/>CRM及外贸支持    原生CRM直连，适合外贸客户全流程管理    CRM需集成第三方或手动配置<br/>大附件&amp;文件归档    支持大附件（最高容量1GB），邮件自动归档    附件支持较好，归档需结合OneDrive等<br/>移动办公/APP体验    高效Webmail、原生App全端同步    Webmail和Outlook客户端<br/>企业邮箱价格    起步价低，性价比高，适合中小/大型企业    定价以Microsoft 365套餐维度，高阶功能需升级<br/>中文/全球客户支持    全球1800万客户、全天多语言客服    全球用户基础强，欧美支持更佳<br/>注册步骤/易用性    注册步骤简洁，域名、用户开通一站式    注册由管理员配置，流程略复杂<br/>*具体容量请以Zoho Mail官网说明为准        <br/>为什么选择Zoho企业邮箱？<br/>适合中小企业与团队：Zoho企业邮箱提供灵活的套餐和按需定制功能，无论是中小企业还是大型团队，都能轻松扩展，满足现有业务及未来增长的需求。<br/>高度可扩展性：企业可以随时批量新建或删除账号，结合企业组织架构进行动态调整，同时支持移动办公、API集成和多端同步。<br/>优质客户支持：提供7x24小时多语言客服，能够快速响应企业日常运维及突发问题。在全球企业邮箱排行中连续多年稳居前三。</p><h2>四、常见问题及解答</h2><h2>如何找回Outlook OWA的登录密码？</h2><p>通过“忘记密码”功能，输入账号后，根据提示进行身份验证和密码重置。若为企业邮箱，请联系管理员协助处理。</p><h2>OWA登录时提示“无法连接到服务器”，怎么办？</h2><p>检查网络连通性或VPN设置，确认企业服务器正常运行。如依然无法访问，可用移动设备或浏览器清除缓存后重试，必要时联系IT支持。</p><h2>如何在OWA中设置自动回复？</h2><p>进入“设置——自动回复”，可自定义自动回复内容、启用时间段，并设定是否对外部联系人生效，轻松应对假期或短期离岗通知。</p><p>综上所述，Outlook的OWA网页版为企业提供了一种便捷的邮件管理方式，而Zoho企业邮箱则凭借其独特的优势，在海外收发稳定性、安全防护、协作功能等方面表现出色，是企业进行邮件管理和办公协作的优质选择。企业可以根据自身需求，选择适合自己的邮件管理工具。</p>]]></description></item><item>    <title><![CDATA[微软Outlook企业邮箱登录入口 遭老]]></title>    <link>https://segmentfault.com/a/1190000047438354</link>    <guid>https://segmentfault.com/a/1190000047438354</guid>    <pubDate>2025-11-29 22:03:42</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在企业通信中，邮箱的安全性和功能性至关重要。Outlook企业邮箱作为微软旗下产品，在企业通信领域广泛应用。同时，Zoho Mail凭借其独特优势，也为众多企业提供了优质选择。下面将详细介绍如何安全登录Outlook企业邮箱，并对比分析Outlook企业邮箱与Zoho企业邮箱。<br/><img width="723" height="443" referrerpolicy="no-referrer" src="/img/bVdnc2T" alt="" title=""/></p><h2>Outlook企业邮箱登录入口概述</h2><h2>官网登录入口地址</h2><p>使用Outlook企业邮箱，强烈建议通过微软官方登录网址：<a href="https://link.segmentfault.com/?enc=GL6TjOQjr9qpi3bCerO7Gg%3D%3D.4Y5oInB0CobWK62OBYmpI1KClhyDNx2eeFPidZE2OV8%3D" rel="nofollow" target="_blank">https://outlook.office.com</a> 。此地址专为企业版（Office 365/Exchange）设计，能有效确保数据连通与安全。</p><h2>登录入口的识别与安全性</h2><p>企业用户务必警惕仿冒网站。判断登录页是否为官方入口，可核查HTTPS证书及页面域名，切勿通过第三方链接或邮件打开。特别是在域名邮箱管理与访问过程中，更要注重登录安全。建议启用企业邮箱防钓鱼和多因素身份验证等额外措施，全方位保障通信安全。</p><h2>Outlook企业邮箱的特色与优势</h2><h2>邮箱功能与性能</h2><p>高效邮件管理：Outlook支持智能邮件分组、优先收件箱及强大筛选功能，非常适合多业务线高强度收发。企业邮箱的大附件传输、自动归档、邮件标签等功能，可显著优化日常通信效率。<br/>强大的日程管理：内置日历与会议安排工具，便于跨部门及国际团队协作。Gantt视图与与会通知功能，能大幅提升企业内部信息流转协同效率。<br/>集成的协作工具：Outlook与Teams、SharePoint等深度整合，可部署企业级邮件归档和知识分享，为企业协作提供有力支持。</p><h2>安全与隐私保护</h2><p>数据加密技术：Microsoft为Outlook企业邮箱引入端到端邮件加密，确保传输过程中数据信息安全。邮件加密机制既能满足合规需求，又适用于国际商务往来。<br/>防止恶意软件与垃圾邮件：先进的反垃圾邮件过滤与防病毒引擎，可智能甄别疑似邮件，有效提升企业邮箱安全性，降低业务风险。<br/>多因素身份验证：支持生物识别、短信验证等多重认证方式，有效防止未授权访问。<br/>与Microsoft生态系统无缝集成<br/>与Office 365的协同工作：邮件、联系人、日程全面互通，可提升文件、会议、任务流转效率，实现邮件驱动业务流程自动化。<br/>与Azure的集成优势：Azure Active Directory可实现单点登录与权限管理，适用于大型企业邮箱部署及身份认证整合需求。<br/>Outlook企业邮箱与Zoho企业邮箱对比</p><h2>功能维度</h2><p>邮件处理能力：Outlook企业邮箱以其深度办公开发能力著称，支持复杂邮件场景。Zoho企业邮箱则因高效海外邮件稳定收发能力、智能反垃圾邮件、支持企业邮箱大附件等，深受外贸企业青睐。<br/>日程与任务管理：Outlook主打与Office生态、Teams集成。Zoho企业邮箱内建协作工具，支持和CRM等Zoho产品无缝配合，更适合中小企业和国际贸易团队。</p><h2>安全性维度</h2><p>数据保护措施：Outlook采用微软自研TLS/SSL协议加密。Zoho Mail提供端到端邮件加密、多层次反垃圾邮件与邮件归档功能，并针对外贸场景优化了海外邮件扩展与反黑名单机制。<br/>用户认证方式：Outlook主推多因素认证及企业级Azure同步。Zoho Mail则以灵活的身份管理和高效防钓鱼策略为特色，提升账户总体安全性。</p><h2>集成与扩展性维度</h2><p>第三方应用支持：Outlook企业邮箱与绝大多数Microsoft 365、第三方办公服务深度兼容。Zoho Mail天然支持CRM集成、多终端移动办公、API开放等，便于海外团队协同。<br/>企业级解决方案的灵活性：Outlook适合对微软生态高度依赖的大型组织。Zoho Mail高性价比、海外服务器架构，适配中小型及外贸企业多地域发展。<br/>对比表：Outlook企业邮箱 vs Zoho企业邮箱<br/>对比维度    Outlook企业邮箱    Zoho企业邮箱<br/>全球用户基数    Microsoft 365全球2亿 + 企业级用户    全球1800万企业级客户，全球邮箱排行前三<br/>海外邮件收发    在中国大陆等地区偶有延迟或不稳定    多国家服务器，外贸及国际邮件畅通稳定<br/>安全防护功能    企业级数据加密，强防垃圾邮件    端到端加密，专业反垃圾、反钓鱼，不易中断<br/>核心集成功能    深度集成Office/Teams/SharePoint    邮箱、日历、联系人无缝协作，CRM集成、API兼容<br/>价格灵活性    针对大型企业定价，部分中小企业负担较重    中小企业邮箱/大型企业邮箱套餐多样，企业邮箱价格适中，提供定制化服务<br/>移动办公体验    全平台App支持，Office生态无缝延展    Webmail、iOS/Android App，支持IMAP/POP/Exchange ActiveSync<br/>大附件/归档功能    邮件最大支持150MB，邮件归档需付费/定制    支持大附件批量收发，邮件归档内置，多端同步<br/>注册与域名管理支持    域名邮箱注册复杂，需手动设置DNS，初次配置耗时    注册步骤简明，提供向导工具和专属客服，入门友好</p><h2>常见问题及解答</h2><h2>如何找回忘记的Outlook企业邮箱密码？</h2><p>可通过Outlook密码重置官网完成自助找回，遵循页面操作，根据注册邮箱或手机验证身份。</p><h2>Outlook企业邮箱登录时提示“账号不存在”，怎么办？</h2><p>确认输入的邮箱地址拼写、域名是否正确。若仍无法登录，建议联系企业IT部门核查账户状态或注册信息。</p><h2>如何在移动设备上登录Outlook企业邮箱？</h2><p>在App Store或Google Play下载“Microsoft Outlook”官方App，添加企业邮箱账户，按提示完成域名邮箱配置，即可享受推送提醒及同步日程功能。</p><p>考虑到企业通信安全与外贸收发需求，Zoho Mail凭借全球分布式服务器、全面加密与专业反垃圾机制，为域名邮箱提供了顺畅、稳定的体验。企业可根据自身需求，选择适合的邮箱服务。</p>]]></description></item><item>    <title><![CDATA[智能工单管理系统哪家好？六款知名软件解析]]></title>    <link>https://segmentfault.com/a/1190000047438359</link>    <guid>https://segmentfault.com/a/1190000047438359</guid>    <pubDate>2025-11-29 22:03:07</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>智能工单管理系统已成为提升企业效率、优化客户服务的关键工具。无论是制造业、服务业还是 IT 行业，这类系统都能助力企业实现任务分配、进度跟踪、数据分析等功能，进而提升整体运营效率。然而，市场上智能工单管理系统种类繁多，企业该如何挑选出适合自己的工具呢？接下来，为大家介绍六款知名热门智能工单管理系统。<br/><img width="723" height="487" referrerpolicy="no-referrer" src="/img/bVdnc2Y" alt="" title=""/></p><h2>1. Zoho Desk</h2><p>Zoho Desk 是一款功能全面且灵活的智能工单管理系统，专为提升客户服务效率与优化团队协作而打造。作为 Zoho 生态系统的一员，它既支持独立使用，也能与 Zoho CRM、Zoho Projects 等工具无缝集成，为企业提供一站式解决方案。</p><p>核心功能<br/>多渠道支持：支持电话、邮件、实时聊天、社交媒体等多种渠道的工单管理，确保客户问题能得到快速响应。<br/>智能任务分配：借助 AI 技术（Zia AI），依据任务优先级和员工工作负载自动分配工单，提高分配效率。<br/>实时数据分析：内置强大的分析工具，支持生成自定义报告和仪表盘，助力企业深入了解工单处理效率和客户满意度。<br/>自定义与集成：支持高度自定义工单字段、自动化规则和工作流，还能与 Zoho 生态系统及第三方工具（如 Slack、Jira）无缝集成。<br/>移动端支持：提供移动应用，方便服务人员随时随地处理工单。<br/>适用场景<br/>客户服务：快速响应客户问题，提升客户满意度。<br/>IT 支持：高效管理技术支持工单，优化问题解决流程。<br/>制造业：管理设备维护和生产任务，提升生产效率。<br/>优势<br/>界面友好，易于上手。<br/>定价方案灵活，适合不同规模的企业。<br/>AI 功能强大，自动化水平高。<br/>推荐理由<br/>Zoho Desk 性价比极高，功能全面且灵活，适合各行业企业使用，尤其适合需要多渠道支持和高度定制化的企业。</p><h2>2. Zendesk</h2><p>Zendesk 是全球知名的客户服务和工单管理系统，专注于帮助企业提升客户支持效率，以强大的多渠道支持和用户友好界面著称。</p><p>核心功能<br/>支持电话、邮件、社交媒体和实时聊天等多渠道。<br/>实现自动化工单分配和优先级排序。<br/>提供数据分析与报告功能，助力企业优化客户支持流程。<br/>支持知识库管理，方便客户自助解决问题。<br/>适用场景<br/>客户服务：适合处理大量客户咨询的企业。<br/>电商行业：管理客户订单和售后服务。<br/>优势<br/>界面简洁，易于使用。<br/>多渠道支持功能强大。<br/>劣势<br/>定价较高，适合预算充足的企业。<br/>高级功能需额外付费。</p><h2>3. Freshdesk</h2><p>Freshdesk 专注于客户支持，提供多种自动化功能和强大的协作工具。</p><p>核心功能<br/>支持电话、邮件和社交媒体等多渠道。<br/>实现自动化工单分配和 SLA 管理。<br/>支持知识库和社区论坛，方便客户自助解决问题。<br/>适用场景<br/>客户服务：适合中小型企业的客户支持需求。<br/>IT 支持：管理技术支持工单。<br/>优势<br/>界面友好，易于上手。<br/>定价灵活，适合中小企业。<br/>劣势<br/>高级功能较少，适合基础需求的企业。</p><h2>4. ServiceNow</h2><p>ServiceNow 面向大型企业，专注于 IT 服务管理（ITSM）和企业流程自动化。</p><p>核心功能<br/>IT 工单管理和自动化任务分配。<br/>具备强大的数据分析和报告功能。<br/>支持与企业现有系统深度集成。<br/>适用场景<br/>IT 行业：管理复杂的技术支持和项目任务。<br/>大型企业：需要高度定制化和集成的企业。<br/>优势<br/>功能强大，适合复杂需求。<br/>支持深度定制和集成。<br/>劣势<br/>实施成本高，适合预算充足的大型企业。<br/>学习曲线较陡。</p><h2>5. Jira Service Management</h2><p>Jira Service Management 由 Atlassian 推出，专注于 IT 服务管理和项目管理。</p><p>核心功能<br/>支持 IT 工单管理和 SLA 管理。<br/>与 Jira 软件无缝集成，满足项目管理需求。<br/>提供数据分析与报告功能，助力优化流程。<br/>适用场景<br/>IT 行业：管理技术支持和项目任务。<br/>软件开发：与 Jira 软件结合使用，提升开发效率。<br/>优势<br/>与 Jira 软件深度集成，适合开发团队。<br/>功能强大，支持复杂需求。<br/>劣势<br/>界面较复杂，新用户需一定学习时间。</p><h2>6. Kayako</h2><p>Kayako 专注于客户支持，提供多渠道支持和协作工具。</p><p>核心功能<br/>支持电话、邮件和实时聊天等多渠道。<br/>支持知识库管理，方便客户自助解决问题。<br/>提供数据分析与报告功能，助力优化客户支持流程。<br/>适用场景<br/>客户服务：适合中小型企业的客户支持需求。</p><p>优势<br/>界面简洁，易于使用。<br/>定价灵活，适合中小企业。<br/>劣势<br/>功能较为基础，适合简单需求的企业。</p><h2>如何选择适合的智能工单管理系统？</h2><p>企业在选择智能工单管理系统时，需根据自身需求和预算进行权衡：</p><p>明确需求：确定是注重客户服务，还是需要支持 IT 工单管理。<br/>预算考量：选择适合预算的系统，不一定要选最贵的，但要确保功能满足需求。<br/>用户友好性：挑选界面友好、易于上手的系统，降低员工学习成本。<br/>可扩展性：选择支持定制和集成的系统，以便未来扩展功能。<br/>Zoho Desk 凭借灵活的定价方案、强大的功能和高度的可扩展性，成为各行业企业的理想之选。</p><p>智能工单管理系统是企业提升效率、优化服务的重要工具。本文介绍的六款知名系统各有特色，其中 Zoho Desk 以全面的功能、友好的界面和灵活的定价方案，成为最值得推荐的解决方案。无论是中小企业还是大型企业，Zoho Desk 都能助力实现高效的工单管理，推动企业数字化转型。</p>]]></description></item><item>    <title><![CDATA[2人团队交付神器：低代码1人起购实战 遭]]></title>    <link>https://segmentfault.com/a/1190000047438364</link>    <guid>https://segmentfault.com/a/1190000047438364</guid>    <pubDate>2025-11-29 22:02:10</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>市场上许多低代码平台，如伙伴云、简道云、氚云等，往往要求30人起购。这对于2人开发团队而言，既不经济也不实用。不过，还有像Zoho Creator低代码平台这样更为灵活的选择，它支持“1人起购”，标准版仅需672元/人/年，让小团队也能以可承受的成本享受低代码技术带来的效率提升。这种模式使2人开发团队能够快速构建应用，将开发周期从数月缩短到几周甚至几天。<br/><img width="723" height="480" referrerpolicy="no-referrer" src="/img/bVdnc23" alt="" title=""/></p><h2>一、低代码平台是什么？为何能让小开发团队高效交付？</h2><p>低代码开发平台是一种借助可视化编程界面和少量代码生成逻辑，助力开发者快速构建应用程序的工具。它通过图形化界面、拖拽组件和模型驱动的方式，大幅减少手动编码工作量，让非技术人员也能参与应用开发。</p><p>对于小团队来说，低代码平台的核心价值体现在以下几个方面：</p><h2>降低开发门槛</h2><p>业务人员无需具备深厚的编程基础，通过可视化操作即可搭建简单应用。</p><h2>提升开发效率</h2><p>能够缩短传统开发周期，1个人能够发挥2 - 3人的人效。</p><h2>快速响应需求</h2><p>业务实践或优化可在几分钟内开发出来，并获得即时反馈。</p><h2>降低成本风险</h2><p>减少对专业开发人员的依赖，缓解IT资源紧张问题。</p><h2>二、市场主流低代码平台价格对比</h2><p>下表对比了市场主流低代码平台的价格策略，清晰展示了哪些平台更适合小团队使用：</p><p>平台名称    起购要求    价格范围    产品优势    适合团队规模<br/>Zoho低代码    1人起购    标准版：672元/人/年起    AI辅助数据迁移、多设备自适应、800 +国际应用集成    中小型团队、跨国公司<br/>伙伴云    30人起购    标准版：8800/年起    数据协作与业务管理平台    中大型企业<br/>简道云    30人起购    标准版：5040元/年起    零代码开发    中大型企业<br/>氚云    30人起购    标准版：4280元/年    零代码与少代码混合开发模式    中型企业<br/>金蝶云苍穹    定制报价    业务版：198,000元/年起    财务领域专业性强    大型集团企业<br/>织信    定制报价    定制开发价格通常较高    全栈开发能力、国产化适配    大型企业、国有企业<br/>宜搭    定制报价    轻享版2988元/年起    支持阿里生态    中型企业<br/>从对比中可以看出，Zoho低代码在起购门槛和价格灵活性方面具有明显优势，特别适合小团队、国际企业根据实际需求逐步扩展。</p><h2>三、Zoho低代码平台的特点及优势</h2><p>Zoho低代码平台作为连续多年入选Gartner低代码平台“魔力象限”的产品，在低代码领域深耕19年，在全球拥有16个数据中心，600万 +用户，数据稳定，安全可靠。</p><h2>全栈自研技术与AI深度融合</h2><p>Zoho低代码平台的底层架构采用全栈自研，与多数依赖第三方技术的低代码平台不同。平台将AI能力深度融入开发流程，其生成式AI引擎Zia支持通过对话式提示生成应用程序，极大简化了系统开发流程。</p><h2>丰富的预构建模板和组件</h2><p>Zoho低代码提供超过60种预构建应用模板，覆盖CRM、项目管理、库存管理等多种场景。这些模板可以作为快速起点，大幅缩短开发时间。</p><h2>强大的集成能力和扩展性</h2><p>Zoho低代码支持与800多种应用集成，包括Zoho自身CRM、ERP等系统以及国际工具如Slack、Trello、Salesforce等。这种强大的集成能力打破了企业内部的信息壁垒，实现数据的自由流通和共享。</p><h2>跨平台开发与移动优先</h2><p>一次开发即可适配Web、iOS、Android设备，可一键发布应用至多个操作系统，实现跨平台无缝运行。这大大减少了针对不同平台重复开发的工作量，为企业节省时间和成本。</p><h2>细粒度权限管理和安全保障</h2><p>Zoho Creator提供了精细的权限管理体系，可精确到字段级别。在数据安全方面，平台使用AES_CBC/AES_GCM、256位/128位密钥和TLS 1.2协议等强密码加密数据，确保企业数据安全。</p><h2>四、如何快速上手Zoho低代码平台</h2><p>对于2人开发团队，快速上手Zoho低代码平台可以遵循以下步骤：</p><p>用Zoho账号登录Zoho低代码平台，如果没有账号，可以先注册一个。Zoho低代码提供15天全功能免费试用以及免费版，团队可以先注册熟悉平台基本功能。</p><h2>利用预置模板加速开发</h2><p>选择与业务需求最匹配的预置模板作为起点。Zoho低代码提供的60多个模板覆盖了大多数常见业务场景，团队只需根据自身需求进行定制调整，无需从零开始。</p><h2>重点掌握核心功能</h2><p>优先学习平台的核心功能：表单设计器、工作流自动化、报表生成和集成能力。Zoho低代码的表单设计器功能丰富，支持多种字段类型和自定义校验规则，工作流引擎可满足复杂的审批流程设置。</p><h2>利用学习资源加速掌握</h2><p>Zoho提供了详细的帮助文档和线上培训资源。2人团队可以分工学习，一人专注于前端界面设计，另一人专注于后端逻辑和数据管理，实现高效协作。</p><h2>从小型项目开始实践</h2><p>选择一个小型但完整的业务场景作为第一个实践项目，如客户信息管理、订单跟踪或库存管理系统。通过实际项目熟悉平台特性，逐步扩展到更复杂的应用。</p><h2>五、真实客户案例</h2><p>元品贸易是一家专注于美国和非洲商超市场的小型服装外贸企业。通过Zoho低代码平台，元品贸易在仅15天内就搭建了符合企业需求的国际供应链管理系统，系统总费用仅为传统开发的十分之一，年账号续费仅两千多元（3用户）。</p><p>该系统支持多实体选择切换，对于不同的客户，可以选择不同的代理商实体和出口商实体，对应到每个订单的财务开票。不同订单和实体统一到一个数据看板，应收账款、应付账款和销账数据一目了然。实施Zoho低代码后，元品贸易的工作效率提升了50%，订单管理和跟进时间大大缩短，错误率归零。</p><h2>结语</h2><p>对于2人开发团队而言，选择合适的低代码平台至关重要。Zoho低代码平台以其1人起购的灵活定价、丰富的功能模块和强大的集成能力，成为小团队高效交付的理想选择。</p><p>通过低代码平台，2人团队可以实现与大型团队相媲美的开发效率，快速响应市场变化和业务需求。Zoho低代码平台的全栈自研架构和持续创新能力，确保小团队构建的应用能够随业务增长而扩展，无需担心系统稳定性和扩展问题。</p>]]></description></item><item>    <title><![CDATA[项目成本管理内容有哪些？ 遭老罪的程序猿]]></title>    <link>https://segmentfault.com/a/1190000047438373</link>    <guid>https://segmentfault.com/a/1190000047438373</guid>    <pubDate>2025-11-29 22:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在企业经营或个人项目管理的过程中，成本管理始终是绕不开的重要话题。无论项目规模大小，资源的有限性都促使我们仔细审视每一笔支出，追求最大化效率。正如彼得·德鲁克所说：“成本是一项迫使我们检验所有行为的现实要素。”这句名言恰如其分地道出了成本管理的重要性：它不仅是财务上的考核与测算，更是确保项目成功的关键抓手。<br/><img width="723" height="460" referrerpolicy="no-referrer" src="/img/bVdk1ax" alt="" title=""/><br/>下面，我们将以清晰的逻辑逐步探讨项目成本管理的核心内容，挖掘其在实际应用中的重要性，并推荐一款实用的工具。</p><h2>一、项目成本管理的四大核心内容</h2><h2>成本估算</h2><p>成本估算是项目成本管理的起点，也是决定后续步骤成败的基础。所谓估算，并非简单列出数字，而是通过科学方法计算完成每一部分工作的可能代价，涵盖人力、物力、时间以及风险带来的隐性成本。</p><p>进行成本估算时，项目经理需灵活运用历史数据、行业统计和岗位技能相关对照指标。例如，参考以往类似项目的费用结构、材料单价和市场波动，结合项目团队的交付能力，使估算更精准。像 Zoho Projects 这类工具能发挥重要作用，它允许项目团队通过案例模板记录历史数据，快速生成各项成本结构的估算依据。</p><h2>预算制定</h2><p>预算制定是将估算的成本整合成整体资金计划，明确具体资金在不同阶段的使用。完备的预算规划可有效避免资金浪费，让团队投入更具价值。</p><p>此过程需兼顾细节与全局，资金分配、进度跟踪以及应急储备比例设定都是重要部分。以 Zoho Projects 为例，它提供直观图表与自定义预算模块，帮助经理清晰分配费用，根据优先级调整资源分类投入，减少人为疏漏失误风险。</p><h2>成本控制</h2><p>若预算是蓝图，成本控制就是施工过程中的监督者。通过有效成本控制，项目管理者可随时掌握实际支出与计划是否相符，是否需调整规划以避免超支或偏离预期目标。</p><p>成本控制核心包括：</p><p>定期追踪实际支出进度，与预算对比分析。<br/>识别和处理可能导致成本增加的异常迹象，如进度拖延或需求变更。<br/>灵活使用工具记录每一项开销，确保财务透明化。<br/>在这方面，Zoho Projects 的实时跟踪功能突出。它依托自动化模块记录每一笔费用，通过警报系统提醒管理者支出异常节点，为及时调整提供依据。</p><h2>成本核算</h2><p>项目结束后，需汇总分析所有成本，这是项目成本管理的最后一步。通过整理核算数据，不仅能评估项目资源使用效率，还能为未来决策提供借鉴。</p><p>核算过程除传统财务报表整理，更需关注：</p><p>实际支出是否在预算范围内？偏差源自哪个环节？<br/>是否存在资源浪费？有哪些改进空间？<br/>如何衡量资金投入与成果产出的性价比？<br/>通过 Zoho Projects，这一环节可实现全自动化处理，避免人工计算误差，提供清晰报告模板，优化后续项目启动与规划。</p><h2>二、项目成本管理的关键注意事项</h2><p>掌握项目成本管理核心内容后，仍需关注关键事项，确保理论在实际场景中高效落实。</p><h2>不可忽视的隐性成本</h2><p>项目成本管理不仅包括显性支出（如设备采购、员工工资等），还需关注隐藏成本，如合作方失信、政策变动影响等。具备细腻的隐性成本分析能力，能帮助企业在制定预算时有更大应对弹性。</p><h2>实时动态调整</h2><p>传统项目成本管理常凭固定计划执行，但实际操作中，环境不确定性会给预算带来冲击。此时，实时监控与动态调整尤为重要。借助像 Zoho Projects 这样的工具，项目团队可追踪关键数据，第一时间优化计划。</p><h2>团队成本意识的培养</h2><p>即便工具先进，成功与否关键仍取决于团队对成本的关注度。项目团队每位成员都应充分理解成本控制意义，自觉将“节约并高效”作为工作准则。</p><h2>三、为什么选择 Zoho Projects？</h2><p>市面上项目成本管理工具众多，但 Zoho Projects 凭借功能完备性和灵活性脱颖而出。以下是其关键优势：</p><h2>一站式解决方案</h2><p>Zoho Projects 提供从成本估算、预算制定到支出追踪的全流程管理，简化传统项目成本管理复杂操作。它还支持多维度自定义报表与数据导入，满足企业及个人用户多元需求。</p><h2>高度可视化的成本控制</h2><p>通过清晰图表与标注提醒，Zoho Projects 让成本控制不再是隐性幕后工作，而是成为团队可协作完成的公开化环节。</p><h2>云端安全性</h2><p>作为基于云的项目管理工具，Zoho Projects 确保数据实时同步与存储安全，让用户随时随地掌控项目开销。</p><h2>灵活收费模式</h2><p>无论小企业还是大型公司，都能在 Zoho Projects 找到适合预算的订阅模式，降低技术门槛，提升工具性价比。</p><p>项目成本管理是企业经营和个人项目管理中不可或缺的环节。通过掌握核心内容、关注关键事项，并借助像 Zoho Projects 这样的实用工具，我们能够更好地管理项目成本，提高项目成功率，实现资源的高效利用。</p>]]></description></item><item>    <title><![CDATA[如何使用GitHub Pages托管博客]]></title>    <link>https://segmentfault.com/a/1190000047438319</link>    <guid>https://segmentfault.com/a/1190000047438319</guid>    <pubDate>2025-11-29 21:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h3>配置自定义域名</h3><ul><li>如果没有GitHub账户，请先<a href="https://link.segmentfault.com/?enc=Zp2H19BxeIshhZfIUvzl2w%3D%3D.0zBdD8u7I0UhA1YSAJ5OSdwRwhx4qPQEA0uO93U4JXE%3D" rel="nofollow" target="_blank">注册账户</a>，账户为<code>username</code></li><li>如果已有GitHub账户，但是想修改账户名 或 修改域名，点击“Settings”（设置）&gt;&gt;&gt; 点击“Account”（账户）&gt;&gt;&gt; Change username</li></ul><p>新建仓库 New repository. 创建新的 <code>username</code>.github.io 仓库</p><h3>创建gh-pages</h3><p>新建仓库后，会有一个main分支，此时我们需要再创建一个分支<code>gh-pages</code>（或者自己喜欢的分支名字，）</p><ul><li>如果是基于刚新建完成仓库建立的<code>gh-pages</code>里面是无文件纯净的</li><li>如果是基于推送代码建立的<code>gh-pages</code>是有文件的，如果你想保持一个干净的仓库需要把他们删了</li></ul><h3>设置博客使用分支</h3><ul><li>进入新的 <code>username.github.io</code> 仓库</li><li>选择 “Settings”</li><li>选择 “Branch” 中新建的分支，如gh-pages</li></ul><h3>创建一个博客文件，如blog，并关联此项目</h3><pre><code class="bash">git init
git add .
git commit -m "first commit"
git remote add origin https://github.com/newusername/newusername.github.io.git
git push -u origin main</code></pre><h3>把blog项目打包出dist文件，并推送到gh-pages分支</h3><p>如果<code>gh-pages</code>分支有问题可先删除再创建，删除命令</p><pre><code class="bash">git push origin --delete gh-pages  # 删除远程分支
git branch -D gh-pages             # 删除本地分支</code></pre><p>基于当前分支的dist文件创建<code>gh-pages</code>分支</p><pre><code class="bash">git subtree split --prefix dist -b gh-pages
git push origin gh-pages</code></pre><p>把dist文件推送到main分支后，再把dist推送到gh-pages</p><pre><code class="bash">git subtree push --prefix dist origin gh-pages  # 无冲突
git push origin `git subtree split --prefix dist main`:gh-pages --force  # 有冲突</code></pre><h3>访问路径</h3><p><code>https://username.github.io/</code></p><h2>创建子项目博客</h2><ol><li>新建仓库 New repository. 创建新的 <code>任意仓库</code>，但不能是 <code>username</code>.github.io 仓库</li><li>其他步骤同上</li><li>访问路径：<code>https://username.github.io/任意仓库名/</code></li></ol>]]></description></item><item>    <title><![CDATA[拒绝 Token 焦虑：我在 Spec ]]></title>    <link>https://segmentfault.com/a/1190000047438255</link>    <guid>https://segmentfault.com/a/1190000047438255</guid>    <pubDate>2025-11-29 20:01:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>引言：AI 很好用，但 Token 真的很贵</h2><p>在 AI 辅助编程（如 Spec Kit）日益普及的今天，我们往往会陷入一种两难：既想让 AI 帮我们干完所有脏活累活，又看着后台飞速消耗的 Token 感到肉疼。</p><p>尤其是在处理复杂需求时，随着对话轮数的增加，上下文（Context Window）会变得极长。这不仅意味着 <strong>Token 消耗呈指数级增长</strong>，更糟糕的是，上下文越长，AI 的“注意力”越分散，越容易出现遗忘前文或产生幻觉的情况。</p><p>经过最近一个项目的实战（NATS 消息订阅模块开发），我总结了一套<strong>“Spec Kit 降本增效指南”</strong>。</p><p>我的核心观点是：<strong>“省 Token”不仅仅是为了省钱，更是为了让 AI 保持清醒，输出高质量代码。</strong> 下面分享我总结的 3 个实战技巧。</p><hr/><h2>技巧一：预处理（Pre-processing）—— 借力打力，用廉价算力换高质量输入</h2><p>很多人习惯把 Spec Kit 的输入框当成草稿纸，把脑子里零碎的想法一股脑倒进去，然后让它慢慢整理。这是最奢侈的用法。</p><p><strong>“抠门”技巧：</strong><br/>在正式启动 Spec Kit 之前，先利用其他更便宜甚至免费的 AI 模型（如 ChatGPT-4o mini、Gemini Flash 或 DeepSeek）进行“预处理”。</p><p><strong>操作步骤：</strong></p><ol><li><strong>头脑风暴</strong>：对着 ChatGPT 把你想做的功能语无伦次地讲一遍。</li><li><strong>清洗提炼</strong>：要求它：“请帮我梳理上述需求，生成一段简洁、结构化、覆盖核心功能点且无歧义的 Prompt，供 AI 编程工具使用。”</li><li><strong>复制粘贴</strong>：把这段清洗过的“黄金 Prompt”投喂给 Spec Kit。</li></ol><p><strong>收益：</strong><br/>Spec Kit 的上下文极其昂贵。通过“借力打力”，我们避免了在 Spec Kit 内部进行低效的需求拉扯。<strong>Garbage In, Garbage Out</strong>（垃圾进，垃圾出）在 AI 时代依然适用，但 <strong>Gold In, Diamond Out</strong> 才是我们的追求。</p><hr/><h2>技巧二：批处理（Batching）—— 拒绝“挤牙膏”式对话，一次性把话说明白</h2><p>这是我在 <code>Clarify</code>（澄清）阶段发现的最痛的领悟。</p><p><strong>传统做法的弊端：</strong><br/>通常 AI 会问一个问题 Q1，你回答 A1；它再根据你的回答想出 Q2，你再回 A2……每一轮对话，系统都会把之前的整个历史（History）重新打包发送一遍。对于长上下文模型来说，这简直是在“烧钱”。</p><p><strong>“抠门”技巧：</strong><br/>强制 AI <strong>“一次性输出所有问题”</strong>，你也 <strong>“一次性回答所有问题”</strong>。</p><p><strong>如何操作：</strong><br/>在执行 <code>Clarify</code> 步骤时，明确提示 AI：</p><blockquote>“请分析当前需求，列出<strong>所有</strong>需要澄清的问题，并提供选项。请一次性列出，不要分批提问。我会以 'Q1: A, Q2: B' 的格式一次性作答。”</blockquote><p><strong>实战案例（NATS 消息订阅功能）：</strong><br/>我是这样要求 AI 的，结果它一次性输出了非常清晰的结构：</p><blockquote><p><strong>所有澄清问题</strong></p><p><strong>Q1: 消息订阅者的作用域缩减</strong><br/>确认: 当前功能仅包含订阅 NATS 消息、解析入库、更新会话？账号创建由其他接口负责？</p><ul><li>Option A: 是，仅做消息入库和会话更新...</li><li>Option B: 消息入库时若 sender 不存在，创建最小记录...</li></ul><p><strong>Q2: 消息引用不存在的 sender/session 时的处理</strong></p><ul><li>Option A: 跳过该消息，记录警告日志</li><li>Option B: 存储消息，ID 设为 null...</li><li>Option C: 消息入队等待，直到相关实体被其他接口创建</li></ul><p><strong>Q3: NATS 主题配置方式</strong></p><ul><li>Option A: 固定主题名</li><li>Option B: 配置文件配置</li></ul><p><strong>Q4: 消息处理的并发模式</strong><br/>...</p><p><strong>Q5: wx\_message 表中 sender\_id 的存储方式</strong><br/>...</p></blockquote><p>而我的回复极其简洁，极大地节省了 Token：</p><pre><code class="text">Q1: A, Q2: C, Q3: cc.callback.demo, Q4: 消息只需要订阅, Q5: B</code></pre><p><strong>进阶技巧：纠错也要“批发”</strong><br/>同理，在生成 <code>specify.md</code> 文档后，如果你发现有 3 处逻辑错误，千万不要分 3 次指正。在本地记事本里列好 1、2、3 点，然后一条消息发过去：“请一次性修正以下所有问题……”。</p><hr/><h2>技巧三：分治法（Divide and Conquer）—— 实现阶段的“外科手术”</h2><p>到了最后的 <code>Task</code> 和 <code>Implement</code> 阶段，如果任务过于庞大，AI 往往会生成一半就中断（Output Token Limit），或者后面生成的代码逻辑混乱。</p><p><strong>“抠门”技巧：</strong><br/>不要试图一口气吃成胖子。将 Implementation 阶段人为拆解为两步走。</p><p><strong>操作步骤：</strong></p><p><strong>第一步：搭骨架（Infrastructure First）</strong></p><ul><li><strong>指令</strong>：“请先仅执行与‘基础设施’相关的 Tasks。包括：1. 创建数据库表结构 (DDL)；2. 搭建项目目录结构；3. 编写基础配置类和实体类。<strong>暂不要实现具体的业务逻辑。</strong>”</li><li><strong>收益</strong>：这部分代码相对固定，AI 极少出错。先生成这一步，你可以快速 Review 表结构是否正确。如果表设计错了，重试的成本很低。</li></ul><p><strong>第二步：填血肉（Business Logic Second）</strong></p><ul><li><strong>指令</strong>：“基础结构已确认。现在请基于已有的实体类和表结构，实现剩余的业务逻辑 Tasks（如 NATS 监听器逻辑、Service 层处理流程）。”</li><li><strong>收益</strong>：此时 AI 已经有了正确的“上下文”（即第一步生成的代码），它写出来的业务逻辑会非常精准，且因为单次输出量减少，极大降低了幻觉概率。</li></ul><hr/><h2>总结</h2><p>使用 Spec Kit 这类工具，本质上是在考验我们的<strong>结构化思维</strong>。</p><ol><li><strong>预处理</strong>：用低成本模型清洗杂质，保证<strong>输入纯净</strong>。</li><li><strong>批处理</strong>：合并交互轮次，保证<strong>链路极简</strong>。</li><li><strong>分治法</strong>：拆解复杂任务，保证<strong>产出可控</strong>。</li></ol><p>当你学会像“审计员”一样去管理 AI 的 Context，你会发现，你不仅省下了一大笔 Token 费用，更重要的是，AI 变得更聪明、更懂你了。</p><p>本文由<a href="https://link.segmentfault.com/?enc=%2B0BTaVULqZogSeWGAqao4Q%3D%3D.l5GtYFKiQhsvoIgFksc2LX4Ul5RLUWIEh8zoi5cUFTo%3D" rel="nofollow" target="_blank">mdnice</a>多平台发布</p>]]></description></item><item>    <title><![CDATA[【技术分享】用python开发采集软件，]]></title>    <link>https://segmentfault.com/a/1190000047437778</link>    <guid>https://segmentfault.com/a/1190000047437778</guid>    <pubDate>2025-11-29 18:03:14</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <blockquote>今天给大家分享一款我用Python开发的实用工具——【爬微博搜索软件】，专为需要批量获取微博内容的用户打造，解决了常规采集的诸多痛点。</blockquote><h2>一、工具开发背景与核心优势</h2><h3>1.1 开发初衷</h3><p>微博作为国内顶流社交媒体平台，以实时性强、热点传播快、KOL影响力大著称。无论是热点事件追踪、行业动态分析，还是用户舆论调研，微博上的海量文字、图片内容都极具参考价值。但实际操作中，大家常会遇到采集页数受限、多关键词切换繁琐、数据易丢失等问题。基于这些需求，我开发了这款采集工具，旨在提供更高效、稳定的内容获取方案。</p><h3>1.2 界面展示</h3><p>工具界面简洁直观，无需复杂操作，上手即用：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047437781" alt="图片" title="图片"/><br/>软件界面</p><h3>1.3 结果预览</h3><p>采集数据全面且结构化，包含11个核心字段，方便后续分析使用：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047437782" alt="图片" title="图片" loading="lazy"/><br/>采集结果.csv核心字段包括：关键词、页码、微博ID、微博链接、用户昵称、用户主页链接、发布时间、转发数、评论数、点赞数、微博内容。</p><h3>1.4 演示视频</h3><p>工具运行全程可视化，具体操作流程可查看演示视频，直观了解采集全流程。原文有。</p><h3>1.5 重要说明</h3><ul><li>支持Windows系统直接双击启动，无需安装Python运行环境，操作门槛低。经多次测试，工具运行稳定，可持续采集不中断。</li><li>需提前在cookie.txt文件中填写个人微博cookie（内附详细获取教程），便于重复使用。</li><li>支持多关键词并行采集，关键词之间用|分隔即可。</li><li>可自定义采集时间范围，格式统一为YYYY-MM-DD，精准锁定目标内容。</li><li>采集过程中按页保存CSV文件，每1-2秒自动存储一次，避免异常中断导致数据丢失。</li><li>生成专属log日志文件，详细记录运行状态，方便问题回溯与排查。</li><li>工具持续迭代更新，后续将不断优化功能体验。</li></ul><h2>二、核心开发技术栈</h2><h3>2.1 整体框架</h3><p>工具整体基于Python语言开发，各模块分工明确：</p><pre><code class="python">tkinter：搭建简洁易用的GUI操作界面
requests：处理网络爬虫请求，确保数据获取稳定
BeautifulSoup：解析响应数据，精准提取核心信息
pandas：负责CSV文件保存与数据清洗，保证数据规范性
logging：实现运行日志记录，便于问题定位</code></pre><p>注：出于版权保护，暂不公开源码，仅提供工具使用权限。</p><h3>2.2 部分源码</h3><p>1、向页面发送请求和解析数据部分：</p><pre><code class="python"># 发送请求
r = requests.get(url, headers=h1, params=params)
# 解析数据
soup = BS(r.text, 'html.parser')</code></pre><p>2、保存数据部分：</p><pre><code class="python"># 保存数据
df = pd.DataFrame(
    {
        '关键词': kw,
        '页码': page,
        '微博id': id_list,
        '微博链接': wb_url_list,
        '用户昵称': name_list,
        '用户主页链接': user_link_list,
        '发布时间': create_time_list,
        '转发数': repost_count_list,
        '评论数': comment_count_list,
        '点赞数': like_count_list,
        '微博内容': text_list,
    }
)
if os.path.exists(self.result_file):  # 如果文件存在，不再设置表头
    header = False
else:  # 否则，设置csv文件表头
    header = True
# 保存csv文件
df.to_csv(self.result_file, mode='a+', index=False, header=header, encoding='utf_8_sig')
self.tk_show('结果保存成功:{}'.format(self.result_file))</code></pre><p>3、日志部分：</p><pre><code class="python">def get_logger(self):
    self.logger = logging.getLogger(__name__)
    # 日志格式
    formatter = '[%(asctime)s-%(filename)s][%(funcName)s-%(lineno)d]--%(message)s'
    # 日志级别
    self.logger.setLevel(logging.DEBUG)
    # 控制台日志
    sh = logging.StreamHandler()
    log_formatter = logging.Formatter(formatter, datefmt='%Y-%m-%d %H:%M:%S')
    # info日志文件名
    info_file_name = time.strftime("%Y-%m-%d") + '.log'
    # 将其保存到特定目录
    case_dir = r'./logs/'
    info_handler = TimedRotatingFileHandler(filename=case_dir + info_file_name,
                                            when='MIDNIGHT',
                                            interval=1,
                                            backupCount=7,
                                            encoding='utf-8')
    self.logger.addHandler(sh)
    sh.setFormatter(log_formatter)
    self.logger.addHandler(info_handler)
    info_handler.setFormatter(log_formatter)
    return self.logger</code></pre><h2>三、详细操作指南</h2><h3>3.1 准备工作：</h3><p>获取并填写cookie打开PC端微博，进入搜索页面并完成登录。按教程打开浏览器开发者工具，找到对应Cookie信息并复制。 <br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047437783" alt="图片" title="图片" loading="lazy"/><br/>CK获取方法将复制的Cookie值粘贴到工具文件夹中的cookie.txt文件内，保存即可。</p><h3>3.2 账号登录流程</h3><p>打开工具后，进入登录界面，输入账号密码完成验证，即可启动采集功能。</p><h3>3.3 开始采集</h3><p>操作在工具界面填写核心采集条件：  <br/>搜索关键词：多个关键词用|分隔（示例：小米SU7|蔚来ES6|理想L6）<br/>日期范围：填写格式为YYYY-MM-DD，设定采集的时间区间<br/>采集最大页：建议单关键词单时间段不超过50页，</p><p>保障采集稳定性点击”开始执行”按钮，工具将自动启动采集任务。<br/>采集过程中请勿直接打开CSV文件，可复制副本查看实时数据，避免采集中断。 <img width="723" height="571" referrerpolicy="no-referrer" src="/img/bVdncTB" alt="image.png" title="image.png" loading="lazy"/></p><h2>四、使用相关说明</h2><p>本工具仅用于合法的信息收集与研究用途，禁止用于任何违法违规活动。 如因违规使用工具导致的任何法律责任，均由使用者自行承担，与工具开发者无关。</p><h2>五、版本更新日志</h2><ul><li>2025.3.17（v1.3版）：新增爬取颗粒度选择功能，支持按小时或按天采集，自由控制数据密度；File菜单新增意见反馈入口，方便及时收集问题并优化。</li><li>2025.1.9（v1.2版）：优化循环时间颗粒度，由原来的按天统计改为按小时统计，采集更精准。</li></ul><h2>六、作者声明</h2><p>本工具为原创开发，如需了解更多技术细节或进行专业交流，可通过正规渠道联系开发者（首发公众号：老男孩的平凡之路）。工具使用需严格遵守相关法律法规和平台规定。</p>]]></description></item>  </channel></rss>