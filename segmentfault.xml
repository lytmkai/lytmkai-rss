<?xml version="1.0" encoding="UTF-8"?><rss version="2.0">  <channel>      <title>SegmentFault - 最近文章</title>      <link>https://segmentfault.com/blogs/newest</link>      <description>SegmentFault 思否</description>      <generator>python segmentfault.py @Pi20</generator>      <item>    <title><![CDATA[2026 全球股市实时行情数据 API 对比指南 阶段性debugger ]]></title>    <link>https://segmentfault.com/a/1190000047559528</link>    <guid>https://segmentfault.com/a/1190000047559528</guid>    <pubDate>2026-01-23 10:12:28</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在 2026 年，随着量化交易、算法投资和高频交易的普及，获取低延迟、可靠的全球股市实时行情数据已成为投资者和开发者的刚需。实时行情 API 不仅提供股票报价、成交量、盘口深度，还支持 WebSocket 推送以实现毫秒级更新。本文将对比当前主流的全球股市实时行情数据 API，重点分析覆盖范围、延迟、定价、易用性和 Python 支持度，并特别提供 Python 代码示例。</p><h2>一、主流 API 对比</h2><p>2026 年最受欢迎的几款实时行情 API 各有侧重，以下逐一分析其关键特性：</p><p><strong>iTick</strong>：覆盖美股、港股、A 股、新加坡、日本、澳洲等亚洲+全球主流市场，实时延迟低于 50ms（WebSocket），基本行情免费无限调用，支持 REST 和 WebSocket 协议。付费方案面向机构级用户。优势在于免费覆盖亚洲市场广、门槛低、数据质量高，非常适合个人开发者与量化策略开发；局限是机构级深度功能需付费。</p><p><strong>Polygon.io</strong>：以美股为主，兼顾全球市场、期权和加密货币，实时延迟最低（&lt;10ms），提供有限免费额度，支持 REST 和 WebSocket。优势是延迟极低、机构级深度数据丰富；局限是成本较高。</p><p><strong>Finnhub</strong>：覆盖全球股票、外汇、加密货币，实时延迟约&lt;100ms，美国股票实时数据免费额度较大，支持 REST 和 WebSocket。优势是技术指标丰富；局限是亚洲市场覆盖相对一般。</p><p><strong>Alpha Vantage</strong>：支持全球 30+国家股票，免费版为分钟级延迟（限额 25 次/日），仅支持 REST 协议，付费后无限制。优势是内置技术指标强大、易上手；局限是实时性较弱，不适合高频需求。</p><p><strong>FMP (Financial Modeling Prep)</strong>：覆盖全球股票并提供丰富基本面数据，实时延迟&lt;50ms，支持 REST 和 WebSocket。优势基本面数据全面；局限是实时深度数据相对一般。</p><p>选择建议：选择实时行情 API 时，需要综合考虑你的使用场景、预算、市场重点、延迟要求、技术需求等因素</p><h2>二、iTick API 接入示例</h2><p>iTick 是 2026 年备受关注的免费实时行情 API，提供全球主要市场的股票报价、Tick 数据、K 线等，支持 REST 和 WebSocket 协议。最大亮点是基本行情免费无限调用，非常适合量化回测、实时监控和交易系统开发。</p><p><strong>接入步骤</strong>：</p><ol><li>访问官网注册账号，获取 API Token。</li><li>在请求头中使用 Token 进行认证。</li><li>REST 接口适合批量查询，WebSocket 适合实时推送。</li></ol><p><strong>支持市场</strong>：美股（US）、港股（HK）、A 股（SH/SZ）、澳洲（AU）、新加坡、泰国、日本、韩国等。</p><h3>1.REST API 获取实时报价（单次查询）</h3><pre><code class="python">import requests

API_TOKEN = 'your_api_token_here'  # 替换为你的Token
BASE_URL = 'https://api.itick.org'

def get_real_time_quote(region, code):
    headers = {
        'accept': 'application/json',
        'token': API_TOKEN
    }
    url = f'{BASE_URL}/stock/quote?region={region}&amp;code={code}'
    response = requests.get(url, headers=headers)
    if response.status_code == 200:
        data = response.json()['data']
        return data
    else:
        print(f"Error: {response.status_code} - {response.text}")
        return None

# 示例：获取苹果公司（AAPL）实时行情
quote = get_real_time_quote('US', 'AAPL')
if quote:
    print(f"Symbol: {quote['s']}")
    print(f"最新价: {quote['ld']}")
    print(f"成交量: {quote['v']}")
    print(f"涨跌: {quote['ch']} ({quote['chp']}%)")</code></pre><h3>2.REST API 获取历史行情数据（策略回测常用）</h3><pre><code class="python">import requests

API_TOKEN = "your_actual_token"
BASE_URL = "https://api.itick.org"
# 美股AAPL 5分钟K线：kType=2（代表5分钟，1=1分钟，3=15分钟，依次类推），limit=10（获取10根K线）
STOCK_KLINE_URL = f"{BASE_URL}/stock/kline?region=US&amp;code=AAPL&amp;kType=2&amp;limit=10"

headers = {
    "accept": "application/json",
    "token": API_TOKEN
}

try:
    response = requests.get(STOCK_KLINE_URL, headers=headers)
    if response.status_code == 200:
        data = response.json()
        kline_list = data.get("data", ())  # 所有K线数据存放在列表中
        print("="*60)
        print("美股AAPL（AAPL$US）最近10根5分钟K线数据")
        print("="*60)
        print(f"{'时间':&lt;20}{'开盘':&lt;10}{'收盘':&lt;10}{'最高':&lt;10}{'最低':&lt;10}")
        print("-"*60)
        # 遍历K线列表，打印每一根K线的核心信息
        for kline in kline_list:
            time_str = str(kline.get('t', '暂无'))  # 时间戳（可自行转换为标准时间格式）
            open_price = kline.get('o', '暂无')
            close_price = kline.get('c', '暂无')
            high_price = kline.get('h', '暂无')
            low_price = kline.get('l', '暂无')
            print(f"{time_str:&lt;20}{open_price:&lt;10}{close_price:&lt;10}{high_price:&lt;10}{low_price:&lt;10}")
    else:
        print(f"请求失败，状态码：{response.status_code}，错误信息：{response.text}")
except Exception as e:
    print(f"调用接口时出现异常：{str(e)}")</code></pre><h3>3.WebSocket 订阅实时行情（持续推送）</h3><pre><code class="python">import websocket
import json
import threading
import time

WS_URL = "wss://api.itick.org/stock"
API_TOKEN = "your_api_token_here"  # 替换为你的Token

def on_message(ws, message):
    data = json.loads(message)
    if data.get("data"):
        market_data = data["data"]
        data_type = market_data.get("type")
        symbol = market_data.get("s")
        print(f"{data_type.upper()} 数据 - {symbol}: {market_data}")

def on_open(ws):
    print("WebSocket 连接成功")
    # 订阅 AAPL 美股的报价和Tick数据
    subscribe_msg = {
        "ac": "subscribe",
        "params": "AAPL$US",
        "types": "quote,tick"
    }
    ws.send(json.dumps(subscribe_msg))

def send_ping(ws):
    while True:
        time.sleep(30)
        ping_msg = {"ac": "ping", "params": str(int(time.time() * 1000))}
        ws.send(json.dumps(ping_msg))
        print("Ping 发送")

ws = websocket.WebSocketApp(
    WS_URL,
    header={"token": API_TOKEN},
    on_open=on_open,
    on_message=on_message
)

ping_thread = threading.Thread(target=send_ping, args=(ws,))
ping_thread.daemon = True
ping_thread.start()
ws.run_forever()</code></pre><p>这些示例可直接运行（需安装<code>requests</code>和<code>websocket-client</code>库：<code>pip install requests websocket-client</code>）。WebSocket 适合构建实时监控系统，REST 适合批量或定时查询。</p><h2>三、总结</h2><p>2026年全球股市实时行情数据API的选型核心，是“需求匹配+成本控制”。不同API各具优势，适配不同开发场景与预算需求——无论是实时行情获取、历史K线查询，还是高频行情监控、深度数据分析，需结合自身需求选择适配的接口，无需盲目追求某一维度的优势。<br/>若追求低延迟与高性价比，可优先考虑iTick API；若侧重跨资产轻量化开发，Alpha Vantage API适配性更强；若需要机构级深度数据与全面性保障，Polygon.io API更符合需求。建议选型前，先通过各API的免费试用，结合自身开发场景测试响应速度、数据完整性，再决定是否付费升级。</p><p>参考文档：<a href="https://link.segmentfault.com/?enc=cdN%2Bid0AMPcHnDLx3NXJ9Q%3D%3D.3wpeTshkKmR5AfYZ4O9RQF4taAicC4A82KDgJfBi7FhDTPpkniIF%2FDkdJ4a0yGqGFJ2Xm9Y%2F9wYu6dioEr%2Fb5GOx5tYLPAPKsZmoAkiwKO%2FmhddY9%2BJWnzyIrrHNuxqrHxSYM1ZM9iO5vGwR8jplFA%3D%3D" rel="nofollow" target="_blank">https://blog.itick.org/stock-api/global-stock-market-realtime-quotes-for-quantitative-trading</a><br/>GitHub：<a href="https://link.segmentfault.com/?enc=bQpQaoOWyJ%2FPmWHWxZCF4w%3D%3D.HuR45V1pZWVp9Dy%2Bie7gFw%2Fk8KBPNgT5DzGR9hMKAK0%3D" rel="nofollow" target="_blank">https://github.com/itick-org/</a></p>]]></description></item><item>    <title><![CDATA[【k8s】Centos从零开始使用containerd部署k8s1.30.14+KubeSphere]]></title>    <link>https://segmentfault.com/a/1190000047559647</link>    <guid>https://segmentfault.com/a/1190000047559647</guid>    <pubDate>2026-01-23 10:11:57</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>Centos虽然已经停止维护了，而且内核也非常低，耐不住国内大环境很多公司还是一直在用它。时不时见到有人想要在centos上面部署k8s1.30.14版本,本文将以<code>centos 7</code>为例，从0开始搭建k8s+ks集群。</p><h2>1.说明</h2><h3>关于kt</h3><p><code>kt</code>是基于<code>kk</code>二次开发的产物，具备<code>kk</code>的所有功能。二开主要为适配信创国产化环境、简化<code>arm</code>部署过程和国产化环境离线部署。支持<code>arm64</code>和<code>amd64</code>架构国产操作系统，已适配芯片+操作系统 如下。</p><p><strong>kt新增功能点</strong></p><ul><li>适配arm架构harbor和支持，部署体验与X86一样简单。</li><li><p>离线环境部署增强。常用国际和国产操作系统依赖，内置到安装包中。已适配芯片和操作系统如下</p><ul><li><code>./kt init-os</code> 一条命令完成操作系统依赖安装和初始化操作。</li><li>CPU：鲲鹏、飞腾、海光、兆芯、intel、amd等。</li><li>OS：Centos、Rocky Linux、Ubuntu、Debian、银河麒麟V10、麒麟V11、麒麟国防版、麒麟信安、中标麒麟V7、统信UOS、华为欧拉、移动大云、阿里龙蜥、TencenOS等。</li></ul></li><li><p>支持开启防火墙，只暴露<code>30000-32767</code>端口，其他k8s端口添加到节点白名单。</p><ul><li><code>./kt firewall</code> 一条命令自动获取节点信息开白名单和防火墙。</li></ul></li></ul><p><strong>kt版本更新和下载地址</strong></p><ul><li><strong>kt：</strong> <a href="https://link.segmentfault.com/?enc=OFqyX7hf65oaUOc0JuRgYw%3D%3D.29mAmKdrNGRnnMLiJCTNKFQHiCXZQg87mpH2%2FKHRTYs%3D" rel="nofollow" title="kt说明" target="_blank">kt</a></li><li><strong>关注我不迷路</strong></li></ul><h2>2.环境准备</h2><p><strong>服务器基本信息</strong></p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559650" alt="" title=""/></p><table><thead><tr><th><strong>主机名</strong></th><th><strong>架构</strong></th><th><strong>OS</strong></th><th><strong>配置</strong></th><th><strong>IP</strong></th></tr></thead><tbody><tr><td>master-woker</td><td>x86_64</td><td>Centos 7</td><td>4核8G</td><td>192.168.85.164</td></tr><tr><td>harbor</td><td>x86_64</td><td>Ubuntu</td><td>2核4G</td><td>192.168.85.201</td></tr></tbody></table><h3>2.1 上传离线制品</h3><p>操作系统不需要安装docker,不需要设置selinux,swap等操作，全新的操作系统即可。</p><p>将离线制品、配置文件、kt和sh脚本上传至服务器其中一个节点(本文以master为例)，后续在该节点操作创建集群。本文使用kt:<code>3.1.12-centos</code>版本</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559651" alt="" title="" loading="lazy"/></p><h3>2.2 修改配置文件</h3><p>根据实际服务器信息，配置到生成的<code>config-sample.yaml</code>中</p><pre><code class="plain">kind: Cluster
metadata:
  name: sample
spec:
  hosts:
  - {name: node1, address: 192.168.85.164, internalAddress: 192.168.85.164, user: root, password: "123123"}
  - {name: harbor, address: 192.168.85.201, internalAddress: 192.168.85.201, user: root, password: "1231233"}
  roleGroups:
    etcd:
    - node1
    control-plane:
    - node1
    worker:
    - node1
    # 如需使用 kk 自动部署镜像仓库，请设置该主机组 （建议仓库与集群分离部署，减少相互影响）
    # 如果需要部署 harbor 并且 containerManager 为 containerd 时，由于部署 harbor 依赖 docker，建议单独节点部署 harbor
    registry:
    - harbor
  controlPlaneEndpoint:
    ## Internal loadbalancer for apiservers 
    internalLoadbalancer: haproxy

    domain: lb.kubesphere.local
    address: ""
    port: 6443
  kubernetes:
    version: v1.30.14
    clusterName: cluster.local
    autoRenewCerts: true
    containerManager: containerd
  etcd:
    type: kubekey
  network:
    plugin: calico
    kubePodsCIDR: 10.233.64.0/18
    kubeServiceCIDR: 10.233.0.0/18
    ## multus support. https://github.com/k8snetworkplumbingwg/multus-cni
    multusCNI:
      enabled: false
  registry:
    type: harbor
    registryMirrors: []
    insecureRegistries: []
    privateRegistry: "dockerhub.kubekey.local"
    namespaceOverride: "kubesphereio"
    auths: # if docker add by `docker login`, if containerd append to `/etc/containerd/config.toml`
      "dockerhub.kubekey.local":
        username: "admin"
        password: Harbor@123 # 此处可自定义，kk3.1.8新特性
        skipTLSVerify: true # Allow contacting registries over HTTPS with failed TLS verification.
        plainHTTP: false # Allow contacting registries over HTTP.
        certsPath: "/etc/docker/certs.d/dockerhub.kubekey.local"
  addons: []
  ---</code></pre><h2>2.3 系统初始化</h2><p>解压<code>kt-centos.tar.gz</code>文件后执行<code>./kt init-os -f config-sample.yaml</code> 已适配操作系统和架构见<code>1.说明</code></p><p>该命令<code>kt</code>会根据配置文件自动判断操作系统和架构以完成所有节点的初始化配置和依赖安装。</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559652" alt="" title="" loading="lazy"/></p><h2>3 创建 Harbor私有仓库</h2><p>ps:由于harbor服务器之前部署过harbor，以下步骤为centos部署1.23时的截图</p><h3>3.1 创建镜像仓库</h3><pre><code class="plain">./kt init registry -f config-sample.yaml -a artifact-x86-k8s13014-ks3.4.1.tar.gz</code></pre><p>此命令会在<code>harbor</code>节点自动安装<code>docker</code>和<code>docker-compose</code>，</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559653" alt="" title="" loading="lazy"/></p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559654" alt="" title="" loading="lazy"/></p><h3>3.2 创建harbor项目</h3><p>&lt;font style="background-color:rgb(255,245,235);"&gt;说明：&lt;/font&gt;</p><p>&lt;font style="background-color:rgb(255,245,235);"&gt;Harbor 管理员账号：&lt;/font&gt;<strong>&lt;font style="background-color:rgb(255,245,235);"&gt;admin&lt;/font&gt;</strong>&lt;font style="background-color:rgb(255,245,235);"&gt;，密码：&lt;/font&gt;<strong>&lt;font style="background-color:rgb(255,245,235);"&gt;Harbor@123&lt;/font&gt;</strong>&lt;font style="background-color:rgb(255,245,235);"&gt;。密码同步使用配置文件中的对应password&lt;/font&gt;</p><p>&lt;font style="background-color:rgb(255,245,235);"&gt;harbor 安装文件在 &lt;/font&gt;<code>/opt/harbor</code>目录下，可在该目录下对 harbor 进行运维。&lt;/font&gt;</p><p>创建 Harbor 项目</p><pre><code class="plain">chmod +x create_project_harbor.sh &amp;&amp; ./create_project_harbor.sh</code></pre><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559655" alt="" title="" loading="lazy"/></p><h2>4 创建k8s和KubeSphere</h2><pre><code class="plain">./kt create cluster -f config-sample.yaml -a artifact-x86-k8s13014-ks341.tar.gz</code></pre><p>此命令kt会自动将离线制品中的镜像推送到<code>harbor</code> 私有仓库</p><p>执行后会有如下提示,输入<code>yes/y</code>继续执行</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559656" alt="" title="" loading="lazy"/></p><p>等待一段时间，直至出现熟悉的等待安装完成的小箭头&gt;&gt;---&gt;</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559657" alt="" title="" loading="lazy"/></p><p>期间可以另开一个窗口用以下命令查看部署日志</p><pre><code class="plain">kubectl logs -n kubesphere-system $(kubectl get pod -n kubesphere-system -l 'app in (ks-install, ks-installer)' -o jsonpath='{.items[0].metadata.name}') -f</code></pre><p>继续等待一段时间，可以看到在内核3.10.0上面使用containerd成功部署了1.30.14版本+ks</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559658" alt="" title="" loading="lazy"/></p><h2>5 验证</h2><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559659" alt="" title="" loading="lazy"/></p><p>ps:<code>default-http-backend</code>那个pod显示：ImagePullBackOff，没啥用，不需要理会。</p><p>登录页面</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559660" alt="" title="" loading="lazy"/></p><p>集群管理</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559661" alt="" title="" loading="lazy"/></p><p>监控告警</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559662" alt="" title="" loading="lazy"/></p><p>配置文件默认只安装了监控，如果需要安装其他组件，可以自行在自定义资源中开启</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559663" alt="" title="" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[【信创-k8s】麒麟V11使用containerd2.1.5全离线安装k8s1.32.11+Kube]]></title>    <link>https://segmentfault.com/a/1190000047559686</link>    <guid>https://segmentfault.com/a/1190000047559686</guid>    <pubDate>2026-01-23 10:11:01</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>本文以<code>麒麟V11</code>，使用<code>k8s 1.32.11+ks4.1.3core</code>离线部署<code>1master2node</code>节点,若有其他需要可添加我微信好友<code>sd_zdhr</code>。</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559689" alt="" title=""/></p><h2>1 说明</h2><h3>关于kt</h3><p><code>kt</code>是基于<code>kk</code>二次开发产物，具备<code>kk</code>的所有功能，二开重点适配了信创国产化环境。</p><p>主要改进包括：简化<code>arm</code>架构部署过程、支持国产化和国际环境在线、离线部署及<code>一条命令所有节点初始化</code>。</p><p>支持<code>arm64</code>和<code>amd64</code>架构操作系统，已适配芯片+操作系统 如下：</p><ul><li><strong>CPU：</strong> 鲲鹏、飞腾、海光、兆芯、intel、amd 等。</li><li><strong>OS：</strong> Centos、Ubuntu、Debian、银河麒麟V10、麒麟国防版、麒麟信安、中标麒麟V7、统信UOS、华为欧拉、移动大云、阿里龙蜥、TencentOS等。</li></ul><p>注：本文使用kt版本<code>3.1.13</code></p><ul><li><strong>kt文档：</strong> <a href="https://link.segmentfault.com/?enc=FwH4f%2FJ%2BoFnpVtt6ogNuFQ%3D%3D.GrDZMVlXdJVwZM1xTKhR8%2BNLZ8EX9iYot%2FBSkfigRxg%3D" rel="nofollow" title="kt文档" target="_blank">kt文档</a></li></ul><h2>2.环境准备</h2><p><strong>服务器基本信息</strong></p><table><thead><tr><th><strong>主机名</strong></th><th><strong>架构</strong></th><th><strong>OS</strong></th><th><strong>配置</strong></th><th><strong>IP</strong></th></tr></thead><tbody><tr><td>harbor</td><td>x86_64</td><td>Ubuntu</td><td>2核4G</td><td>192.168.85.201</td></tr><tr><td>master</td><td>x86_64</td><td>麒麟V11</td><td>2核4G</td><td>192.168.85.163</td></tr><tr><td>node1</td><td>x86_64</td><td>麒麟V11</td><td>2核4G</td><td>192.168.85.155</td></tr><tr><td>node2</td><td>x86_64</td><td>麒麟V11</td><td>2核4G</td><td>192.168.85.162</td></tr></tbody></table><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559690" alt="" title="" loading="lazy"/></p><h3>2.1 上传离线制品</h3><p>操作系统不需要安装docker,不需要设置selinux,swap等操作，全新的操作系统即可。</p><p>将离线制品、配置文件、kt和sh脚本上传至服务器其中一个节点(本文以master为例)，后续在该节点操作创建集群。</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559691" alt="" title="" loading="lazy"/></p><h3>2.2 修改配置文件</h3><p>根据实际服务器信息，配置到生成的<code>config-sample.yaml</code>中</p><pre><code class="plain">kind: Cluster
metadata:
  name: sample
spec:
  hosts:
  - {name: harbor, address: 192.168.85.201, internalAddress: 192.168.85.201, user: root, password: "123213"}
  - {name: master, address: 192.168.85.163, internalAddress: 192.168.85.163, user: root, password: "123213"}
  - {name: node1, address: 192.168.85.155, internalAddress: 192.168.85.155, user: root, password: "123213"}
  - {name: node2, address: 192.168.85.162, internalAddress: 192.168.85.162, user: root, password: "123213"}
  roleGroups:
    etcd:
    - master
    control-plane:
    - master
    worker:
    - node1
    - node2
    # 由于部署 harbor 依赖 docker，建议单独节点部署 harbor
    registry:
    - harbor
  controlPlaneEndpoint:
    ## Internal loadbalancer for apiservers 
    internalLoadbalancer: haproxy

    domain: lb.kubesphere.local
    address: ""
    port: 6443
  kubernetes:
    version: v1.32.11
    clusterName: cluster.local
    autoRenewCerts: true
    containerManager: containerd
  etcd:
    type: kubekey
  network:
    plugin: calico
    kubePodsCIDR: 10.233.64.0/18
    kubeServiceCIDR: 10.233.0.0/18
    ## multus support. https://github.com/k8snetworkplumbingwg/multus-cni
    multusCNI:
      enabled: false
  registry:
    type: harbor
    registryMirrors: []
    insecureRegistries: []
    privateRegistry: "dockerhub.kubekey.local"
    namespaceOverride: "kubesphereio"
    auths: # if docker add by `docker login`, if containerd append to `/etc/containerd/config.toml`
      "dockerhub.kubekey.local":
        username: "admin"
        password: Harbor@123 # 此处可自定义，kk3.1.8新特性
        skipTLSVerify: true # Allow contacting registries over HTTPS with failed TLS verification.
        plainHTTP: false # Allow contacting registries over HTTP.
        certsPath: "/etc/docker/certs.d/dockerhub.kubekey.local"
  addons: []</code></pre><h2>2.3 系统初始化</h2><p>解压<code>kt-x86.tar.gz</code>文件后执行<code>./kt init-os -f config-sample.yaml</code> 已适配操作系统和架构见<code>1.说明</code></p><p>该命令<code>kt</code>会根据配置文件自动判断操作系统和架构以完成所有节点的初始化配置和依赖安装。</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559692" alt="" title="" loading="lazy"/></p><h2>3 创建 Harbor私有仓库</h2><h3>3.1 创建镜像仓库</h3><pre><code class="plain">./kt init registry -f config-sample.yaml -a artifact-x86-k8s13211-ks413core.tar.gz</code></pre><p>此命令会在<code>harbor</code>节点自动安装<code>docker</code>和<code>docker-compose</code></p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559693" alt="" title="" loading="lazy"/></p><p>稍等一会，看到成功消息</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559694" alt="" title="" loading="lazy"/></p><p>此时去harbor服务器，查看服务状态，可以看到所有服务已正常启动。</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559695" alt="" title="" loading="lazy"/></p><h3>3.2 创建harbor项目</h3><p>&lt;font style="background-color:rgb(255,245,235);"&gt;说明：&lt;/font&gt;</p><p>&lt;font style="background-color:rgb(255,245,235);"&gt;Harbor 管理员账号：&lt;/font&gt;<strong>&lt;font style="background-color:rgb(255,245,235);"&gt;admin&lt;/font&gt;</strong>&lt;font style="background-color:rgb(255,245,235);"&gt;，密码：&lt;/font&gt;<strong>&lt;font style="background-color:rgb(255,245,235);"&gt;Harbor@123&lt;/font&gt;</strong>&lt;font style="background-color:rgb(255,245,235);"&gt;。密码同步使用配置文件中的对应password&lt;/font&gt;</p><p>&lt;font style="background-color:rgb(255,245,235);"&gt;harbor 安装文件在 &lt;/font&gt;/opt/harbor&lt;font style="background-color:rgb(255,245,235);"&gt; 目录下，可在该目录下对 harbor 进行运维。&lt;/font&gt;</p><p>创建 Harbor 项目</p><pre><code class="plain">chmod +x create_project_harbor.sh &amp;&amp; ./create_project_harbor.sh</code></pre><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559696" alt="" title="" loading="lazy"/></p><h2>4 创建k8s</h2><pre><code class="plain">./kt create cluster -f config-sample.yaml -a artifact-x86-k8s13211-ks413core.tar.gz --with-local-storage</code></pre><p>此命令<code>kt</code>会自动将离线制品中的镜像推送到<code>harbor</code> 私有仓库</p><p>执行后会有如下提示,输入<code>yes/y</code>继续执行</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559697" alt="" title="" loading="lazy"/></p><p>继续等待一段时间最终可以看到安装成功的消息</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559698" alt="" title="" loading="lazy"/></p><p>验证</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559699" alt="" title="" loading="lazy"/></p><h2>5 安装 KubeSphere</h2><pre><code class="plain">helm upgrade --install -n kubesphere-system --create-namespace ks-core ks-core-1.1.5.tgz \
     --set global.imageRegistry=dockerhub.kubekey.local/ks \
     --set extension.imageRegistry=dockerhub.kubekey.local/ks \
     --set ksExtensionRepository.image.tag=v1.1.5 \
     --debug \
     --wait</code></pre><p>等待大概1分钟左右看到成功消息</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559700" alt="" title="" loading="lazy"/></p><h2>6 验证</h2><p>登录页面</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559701" alt="" title="" loading="lazy"/></p><p>初次登录需要换密码，如果不想换也可以继续填写<code>P@88w0rd</code>，不过建议更换</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559702" alt="" title="" loading="lazy"/></p><p>首页</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559703" alt="" title="" loading="lazy"/></p><p>集群节点版本信息</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559704" alt="" title="" loading="lazy"/></p><p>概览</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559705" alt="" title="" loading="lazy"/></p><p>集群节点</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559706" alt="" title="" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[什么是外勤人员管理系统 果断的小刀 ]]></title>    <link>https://segmentfault.com/a/1190000047559732</link>    <guid>https://segmentfault.com/a/1190000047559732</guid>    <pubDate>2026-01-23 10:10:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>对很多拥有外勤团队的企业来说，<strong>外勤人员管理</strong>一直是一项难度较高的工作。无论是长期在市场一线奔波的销售人员，还是分散在各个区域的售后工程师，一旦员工离开办公室，管理难度就会明显上升。</p><p>不少管理者都会遇到类似问题。人员具体去了哪里不清楚，工作过程是否真实难以判断，相关费用也缺乏有效核实依据。久而久之，外勤管理容易演变成依赖经验和信任的状态，<strong>效率和成本都难以控制</strong>。</p><p><strong>一、什么是外勤人员管理系统</strong></p><p><strong>外勤人员管理系统</strong>，本质上是一套用于规范和提升外勤人员管理效率的<strong>数字化工具</strong>。它通常基于 SaaS 架构，结合定位技术和移动终端，帮助企业对外勤人员的<strong>考勤、位置、轨迹和工作内容</strong>进行统一管理。<br/><img width="723" height="378" referrerpolicy="no-referrer" src="/img/bVdnICv" alt="" title=""/></p><p>与传统外勤打卡工具不同，成熟的外勤管理系统并不只是记录时间或位置，而是<strong>将总部管理与一线业务场景连接起来</strong>，让管理者能够了解真实的工作状态，同时也为一线员工提供清晰的工作指引和流程支持。</p><p>从企业实践来看，一套成熟的外勤人员管理系统，核心目标通常集中在三个方面：<strong>确保数据真实，提升人效水平，控制不必要的费用支出</strong>。</p><p><strong>二、如何解决人员位置管理问题</strong></p><p>在外勤管理中，<strong>位置和考勤的真实性</strong>是所有管理动作的基础。如果这一层数据不可靠，后续的业务分析和绩效评估都会失去意义。</p><p><strong>1、精准定位与轨迹记录</strong></p><p>外勤管理系统通常通过 <strong>GPS、基站和 Wi-Fi 等多种方式进行混合定位</strong>，持续记录外勤人员的活动位置。管理者可以在后台查看团队的实时分布情况，用于临时调度和任务分配。<br/><img width="723" height="356" referrerpolicy="no-referrer" src="/img/bVdnICw" alt="" title="" loading="lazy"/></p><p>同时，系统会保存员工的<strong>历史行动轨迹</strong>。通过连续轨迹记录，可以还原一天内的真实行程，避免出现绕路或长时间无效停留的情况。这类外勤人员<strong>定位和轨迹管理</strong>功能，是外勤管理软件的重要组成部分。</p><p><strong>2、区域管理与外勤考勤</strong></p><p>在实际应用中，企业可以在地图上<strong>划定特定工作区域</strong>，例如办公点位、客户门店或重点服务区域。员工进入或离开指定区域时，系统会自动记录考勤时间。<br/><img width="723" height="552" referrerpolicy="no-referrer" src="/img/bVdnICx" alt="" title="" loading="lazy"/></p><p>这种<strong>外勤考勤管理</strong>方式减少了人工打卡带来的争议，也让考勤过程更加自然，避免频繁操作对员工工作的干扰。</p><p><strong>3、数据真实性保障</strong></p><p>针对虚拟定位和代打卡等问题，专业的外勤人员管理系统通常会配置<strong>多层校验机制</strong>。通过识别异常设备环境和异常定位行为，降低数据被篡改的可能性。</p><p>在现场拍照环节，系统会<strong>自动记录时间和位置信息</strong>，用于巡店管理、工程验收等场景。这类机制能够帮助企业<strong>建立可信的数据基础</strong>，而不是事后反复核对。</p><p><strong>三、如何还原真实工作内容</strong></p><p>解决“人员在哪里”之后，外勤管理的重点会转向<strong>工作内容本身</strong>。不同岗位的外勤人员，管理重点也存在明显差异。<br/><img width="723" height="470" referrerpolicy="no-referrer" src="/img/bVdnICy" alt="" title="" loading="lazy"/></p><p><strong>场景一：外勤销售管理</strong></p><p>该类场景多见于 B2B 销售、医药代表和渠道拓展团队。系统会围绕<strong>客户管理和拜访过程</strong>展开，帮助企业规范销售动作。</p><p>常见功能包括<strong>客户资源统一管理、拜访路线规划以及标准化拜访流程</strong>。通过这些功能，外勤销售管理不再依赖个人习惯，而是形成<strong>可复制的工作模式</strong>。<br/><img width="723" height="292" referrerpolicy="no-referrer" src="/img/bVdnICz" alt="" title="" loading="lazy"/></p><p><strong>场景二：巡店管理与终端执行</strong></p><p>在快消和零售行业，<strong>巡店管理系统</strong>是外勤管理的重要组成部分。巡店人员需要按计划完成门店检查、陈列确认和信息采集。</p><p>通过现场拍照和数据采集，企业可以掌握<strong>终端执行情况</strong>，同时对铺货率和竞品动态进行分析，减少人工汇总带来的误差。</p><p><strong>场景三：工程与设备巡检</strong></p><p>在工程维护和设备巡检场景中，系统通常会提前设置<strong>固定巡检路线和点位</strong>。外勤人员需按顺序完成任务，避免漏检或走过场。</p><p>发现问题后，可直接在现场提交记录，相关信息会同步到后台，形成<strong>闭环处理流程</strong>。这类外勤巡检系统在物业、电力等行业应用较为普遍。<br/><img width="723" height="559" referrerpolicy="no-referrer" src="/img/bVdnICA" alt="" title="" loading="lazy"/></p><p><strong>场景四：政府与公共服务</strong></p><p>在城市管理和公共服务领域，外勤人员管理系统更多用于<strong>过程留痕和履职记录</strong>。通过轨迹记录和事件上报机制，帮助相关部门完成合规管理和工作追溯。</p><p><strong>场景五：用车管理与费用核算</strong></p><p>在涉及私车公用的情况下，行程和费用往往难以准确核算。系统可以基于<strong>真实行驶轨迹计算里程</strong>，并按照企业规则自动生成费用记录。</p><p>这种<strong>外勤费用管理</strong>方式，有助于减少人为申报带来的偏差，同时提升财务审核效率。<br/><img width="723" height="535" referrerpolicy="no-referrer" src="/img/bVdnICB" alt="" title="" loading="lazy"/></p><p><strong>四、如何评估外勤管理效果</strong></p><p>外勤人员管理系统的最终价值，体现在<strong>数据层面的积累和分析</strong>。通过对过程数据和结果数据的整合，管理者可以更清楚地判断团队运行状态。</p><p>系统通常会展示<strong>考勤情况、拜访覆盖率和在岗时长等过程指标</strong>。同时结合业务结果，对<strong>人效表现和投入产出情况</strong>进行分析，为绩效评估和人员调整提供依据。</p><p><strong>五、企业如何选择合适的外勤人员管理系统</strong></p><p>在选择外勤管理系统时，企业可以重点关注以下三个方面：</p><p><strong>行业匹配度</strong>：不同业务场景对外勤管理的要求差异较大，具备行业经验的解决方案往往更容易落地。</p><p><strong>技术可靠性</strong>：包括<strong>定位稳定性和数据防篡改能力</strong>，这关系到系统长期使用的可信度。</p><p><strong>服务能力</strong>：外勤人员管理系统并非一次性工具，<strong>持续的实施支持和管理优化建议</strong>，同样影响使用效果。</p><p><strong>六、结语</strong></p><p>总体来看，<strong>外勤人员管理系统不仅是一套管理工具，更是企业实现外勤数字化管理的重要基础</strong>。通过对人员、过程和数据的统一管理，企业可以逐步摆脱依赖经验的管理方式，提升整体运营效率。</p><p>在竞争日益激烈的环境中，<strong>建立稳定可靠的外勤管理体系</strong>，往往是实现降本增效的重要一步。</p>]]></description></item><item>    <title><![CDATA[API 接入分解三门梯子游戏：APIBB梯子游戏玩法技巧接口指南 淡定的电梯 ]]></title>    <link>https://segmentfault.com/a/1190000047559773</link>    <guid>https://segmentfault.com/a/1190000047559773</guid>    <pubDate>2026-01-23 10:09:38</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>梯子，是这几年来最火热的一款bbi采，几率高 响应结构：返回JSON数据，核心字段包括  num_iid（商品ID）<br/><img width="464" height="131" referrerpolicy="no-referrer" src="/img/bVdnIDe" alt="" title=""/><br/>  title（标题）、  price（价格）、  pic_url（主图）、  volume（销量）等。存储建议：可存储至数据库（如MySQL）或导出CSV，避免直接展示敏感字段（如用户隐私）。今天举例梯子三门112的打法，终点X梯子暂不考虑，首先举例的是，打哪三门如图示意我们打的是（双    3     右）<br/><img width="723" height="378" referrerpolicy="no-referrer" src="/img/bVdnIle" alt="" title="" loading="lazy"/></p><p>如图打是的（单三右） 我们打的是（双三右），打中三门中的（三和右）那么三门打中2门，丢失了一门，换算下来得两门，丢一门，实际还多得一门。 频率限制：免费版通常500次/天，企业认证后可达10万次/天，需控制请求间隔（如  time.sleep(1)避免限流）。</p><p>如图打的是（双三右）我们打的是（双三左），打中三门中的（三和双）那么三门打中两门，丢失了一门，换算下来得两门，，丢一门，实际还多得一门。 响应结构：返回JSON数据，核心字段包括  num_iid（商品ID）、  title（标题）、  price（价格）、  pic_url（主图）、  volume（销量）等。<br/><img width="600" height="424" referrerpolicy="no-referrer" src="/img/bVdnIDf" alt="" title="" loading="lazy"/></p><p>如图打的是（单四左）我们打的是（双三右），三门一门都没打中，实际换算下来就是三门全丢。 存储建议：可存储至数据库（如MySQL）或导出CSV，避免直接展示敏感字段（如用户隐私）。</p><p>如图打的是（双四右）我们打的是（双三右），打中三门中的（双和右）那么三门打中两门，丢失一门，换算下来得两门，丢一门，实际还多得一门。 通过以上步骤，可高效、合规地批量获取淘宝商品信息。如需进一步优化，可结合缓存（如Redis）减少重复请求，或使用异步框架（如Scrapy）提升效率。<br/><img width="543" height="356" referrerpolicy="no-referrer" src="/img/bVdnIDg" alt="" title="" loading="lazy"/><br/>三门打法定律就是，任你万千变化，我自巍然不动，综上所述按照这种112模式操作，中门的几.率是75%超高中.门.率，牢记的就是（单三左）、（双三右）、（单四右）、（双四左），三门112打法配上凯利公式来操作梯子，那么你将无往不利。 合规性：禁止爬取用户隐私数据，需遵守淘宝《开放平台规则》及《robots协议》。1. 准备工作注册与认证：登录淘宝开放平台，完成企业/个人实名认证，创建应用并获取 AppKey和 AppSecret（核心凭证）。权限申请：在“应用管理”中申请商品搜索类API权限（如 taobao.items.search、 taobao.tbk.item.get），审核通过后生效。2. 接口选择与参数配置核心接口：taobao.items.search：按关键词、价格区间、销量等筛选商品，支持分页（ page_no、 page_size）和排序（如 sale-desc销量降序）。taobao.tbk.item.get：淘宝客商品搜索，可获取优惠券信息，适合佣金导向场景。必填参数：公共参数： app_key、 method（接口名）、 timestamp（时间戳）、 format（ json）、 v（API版本，如 2.0）、 sign_method（ md5）。业务参数： q（搜索关键词）、 page_no（页码，默认1）、 page_size（每页数量，默认20，最大100）、 fields（返回字段，如 num_iid,title,price,pic_url）。</p>]]></description></item><item>    <title><![CDATA[从零搭建现货撮合系统：完整架构与性能实测 想发财的香烟 ]]></title>    <link>https://segmentfault.com/a/1190000047559779</link>    <guid>https://segmentfault.com/a/1190000047559779</guid>    <pubDate>2026-01-23 10:08:48</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>从零搭建现货撮合系统：完整架构与性能实测</h2><blockquote>一套经过生产验证的交易所核心系统，从下单到成交全流程</blockquote><h3>前言</h3><p>做交易所技术这几年，经常被问到：<strong>撮合引擎怎么设计？能跑多少 QPS？</strong></p><p>市面上讲撮合的文章很多，但大多是理论，缺少实际的性能数据和踩坑经验。</p><p>这篇文章会分享我们团队自研的现货撮合系统 <strong>Exchange</strong>，包括：</p><ul><li>完整的技术架构和选型思路</li><li>真实的压测数据（不是理论值）</li><li>遇到的性能瓶颈和优化方向</li></ul><p>目前这套系统已经能够：</p><ul><li>⚡ <strong>完整下单流程 1,440 QPS</strong>（含资产校验、冻结、落库）</li><li>🚀 <strong>做市机器人接口 18,000 QPS</strong>（轻量级，跳过 DB）</li><li>🔄 <strong>3 节点集群，主从热备，故障自动切换 &lt; 3 秒</strong></li><li>📊 <strong>完整行情系统</strong>（实时深度、15 种 K 线周期、Ticker）</li></ul><p>🔗 <strong>在线体验</strong>：<a href="https://link.segmentfault.com/?enc=pl2iFrAvqWWTvwtWofd6Cg%3D%3D.Ff2%2B%2FKufVglflSs1nhzPmJwVH4xF5GM7opRagrbvMAl6wsy3wcBSXzQ9mmIWuZh6" rel="nofollow" target="_blank">https://web3-ex-omega.vercel.app/</a>  <br/>📖 <strong>API 文档</strong>：<a href="https://link.segmentfault.com/?enc=E%2BqYCJ1lnr39zsRTOJUTrA%3D%3D.yJd4eH2yuxC2qpBWdMiFEqwg0fTCBi7Dyf6Kz7jqLNM%3D" rel="nofollow" target="_blank">https://apix-docs.vercel.app/</a></p><p><img width="723" height="523" referrerpolicy="no-referrer" src="/img/bVdnHgV" alt="demo.gif" title="demo.gif"/></p><p>本文是系列文章的第一篇，重点讲<strong>整体架构</strong>，后续会深入撮合算法、高可用设计等细节。</p><hr/><h3>一、为什么自研？</h3><p>市面上有一些交易所解决方案，但我们调研后发现都不太满足需求：</p><ul><li>有些性能不够，延迟太高</li><li>有些功能不完整，需要大量二次开发</li><li>有些架构老旧，扩展性差</li><li>有些是黑盒，出了问题没法排查</li></ul><p>最后决定自研，目标很明确：</p><ol><li><strong>高性能</strong>：Go 语言，天然适合高并发场景</li><li><strong>架构清晰</strong>：微服务拆分，每个模块职责单一</li><li><strong>易扩展</strong>：支持水平扩展，方便后续优化</li><li><strong>可控性强</strong>：核心代码自己掌握，出问题能快速定位</li></ol><hr/><h3>二、技术选型</h3><h4>核心技术栈</h4><table><thead><tr><th>技术</th><th>用途</th><th>选型理由</th></tr></thead><tbody><tr><td><strong>Go</strong></td><td>开发语言</td><td>性能好、并发友好、部署简单</td></tr><tr><td><strong>Kafka</strong></td><td>消息队列</td><td>高吞吐、消息持久化、支持回溯</td></tr><tr><td><strong>Redis</strong></td><td>缓存/选举</td><td>Leader 选举、行情缓存</td></tr><tr><td><strong>MySQL</strong></td><td>关系数据库</td><td>订单、成交记录</td></tr><tr><td><strong>ClickHouse</strong></td><td>时序数据库</td><td>K 线历史数据</td></tr><tr><td><strong>Consul</strong></td><td>服务发现</td><td>健康检查</td></tr></tbody></table><h4>为什么用 Kafka？</h4><p>交易所是典型的<strong>事件驱动</strong>系统，每笔订单会触发一系列事件：</p><pre><code>撮合成功 → 清算资金 → 更新深度 → 生成K线 → 推送客户端</code></pre><p>选 Kafka 的原因：</p><ul><li>✅ 消息持久化，出问题可以回溯</li><li>✅ 单分区有序，撮合结果按顺序处理</li><li>✅ 吞吐量高，单分区轻松 10 万+ QPS</li></ul><p>RabbitMQ 也考虑过，但它更适合任务队列场景。虽然也支持持久化，但在高吞吐场景下 Kafka 表现更好。</p><h4>为什么用 Redis 做选举？</h4><p>撮合引擎是 3 节点集群（1 主 2 备），需要选出 Leader。</p><p>用 Redis 分布式锁实现，原因很简单：</p><ol><li><strong>够用</strong>：不需要强一致性，只要切换够快</li><li><strong>简单</strong>：几行代码搞定</li><li><strong>复用</strong>：Redis 本来就要用，不用引入新组件</li></ol><pre><code class="go">// Leader 选举
func tryBecomeLeader() bool {
    return redis.SetNX("match-engine:leader", nodeID, 3*time.Second).Val()
}</code></pre><p>TTL 设 3 秒，主节点挂了，备节点最多 3 秒内就能接管。</p><p>当然，Redis 选举理论上有脑裂风险。如果要更严谨，可以用 Consul Session 或 etcd。这里为了简单，先用 Redis。</p><h4>数据库选型</h4><p><strong>MySQL</strong> 存订单和成交记录，这是关系型数据，需要事务保证。</p><p><strong>ClickHouse</strong> 存 K 线历史数据。一开始想全用 MySQL，但 K 线数据增长太快：</p><ul><li>1 分钟周期，一天 1440 条 × 交易对数量</li><li>查询历史 K 线时，MySQL 响应越来越慢</li></ul><p>换成 ClickHouse 后，查询性能提升明显，毕竟是专门为时序数据设计的。</p><hr/><h3>三、系统架构</h3><h4>整体架构图</h4><p><img width="723" height="478" referrerpolicy="no-referrer" src="/img/bVdnHgU" alt="exchangehubx-architecture.png" title="exchangehubx-architecture.png" loading="lazy"/></p><h4>服务划分</h4><p>系统拆成了 8 个微服务：</p><table><thead><tr><th>服务</th><th>职责</th></tr></thead><tbody><tr><td><strong>order-service</strong></td><td>订单提交、撤单、资金冻结</td></tr><tr><td><strong>match-engine</strong></td><td>核心撮合（3 节点主从集群）</td></tr><tr><td><strong>trade-service</strong></td><td>成交清算、资金划转</td></tr><tr><td><strong>depth-service</strong></td><td>订单簿深度维护</td></tr><tr><td><strong>kline-service</strong></td><td>K 线聚合（15 种周期）</td></tr><tr><td><strong>market-service</strong></td><td>Ticker 统计（24h 数据）</td></tr><tr><td><strong>ws-service</strong></td><td>WebSocket 推送</td></tr><tr><td><strong>bot-service</strong></td><td>做市机器人（测试用）</td></tr></tbody></table><h4>撮合引擎：主从复制架构</h4><p>撮合引擎是整个系统的核心，必须保证<strong>高可用</strong>。我们采用 <strong>1 主 2 从</strong> 的集群架构：</p><pre><code>                    ┌─────────────────┐
                    │   Redis 选举    │
                    │  (Leader Lock)  │
                    └────────┬────────┘
                             │
         ┌───────────────────┼───────────────────┐
         │                   │                   │
         ▼                   ▼                   ▼
┌─────────────────┐ ┌─────────────────┐ ┌─────────────────┐
│  match-engine   │ │  match-engine   │ │  match-engine   │
│     node-1      │ │     node-2      │ │     node-3      │
│    (Master)     │ │    (Slave)      │ │    (Slave)      │
└────────┬────────┘ └────────┬────────┘ └────────┬────────┘
         │                   │                   │
         │   Kafka: order.log-cluster (操作日志复制)
         │◄──────────────────┴───────────────────┘
         │
         ▼
┌─────────────────┐
│  Kafka Topic    │
│  match.result   │
└─────────────────┘</code></pre><p><strong>工作原理：</strong></p><ol><li><strong>Leader 选举</strong>：3 个节点通过 Redis 分布式锁竞争 Leader</li><li><strong>只有 Master 处理订单</strong>：Slave 节点待命，不参与撮合</li><li><strong>操作日志复制</strong>：Master 的每一笔操作都写入 Kafka <code>order.log-cluster</code> Topic</li><li><strong>Slave 实时同步</strong>：从节点消费操作日志，保持订单簿状态一致</li><li><strong>故障自动切换</strong>：Master 挂掉后，TTL 3 秒内 Slave 自动接管</li></ol><p><strong>为什么要这样设计？</strong></p><ul><li><strong>不能多主</strong>：撮合必须单点执行，否则同一笔订单可能被撮合两次</li><li><strong>必须热备</strong>：冷启动太慢，从 MySQL 恢复订单簿要几分钟</li><li><strong>操作日志</strong>：类似 MySQL binlog，保证主从数据一致</li></ul><h4>一笔订单的处理流程</h4><p>用户下单后，系统内部是这样处理的：</p><p><strong>1. 订单服务</strong></p><pre><code>→ 校验参数
→ 开启事务
→ 冻结资金（乐观锁，条件更新）
→ 生成订单 ID（Snowflake）
→ 保存订单到 MySQL
→ 提交事务
→ 调用撮合引擎（gRPC）</code></pre><p><strong>2. 撮合引擎</strong></p><pre><code>→ 订单入订单簿（跳表结构）
→ 执行撮合算法（价格-时间优先）
→ 生成撮合结果
→ 发送到 Kafka（match.result Topic）</code></pre><p><strong>3. 清算服务</strong>（消费 Kafka）</p><pre><code>→ Taker/Maker 资金划转
→ 扣除手续费
→ 更新订单状态
→ 发送到 Kafka（trade.executed）</code></pre><p><strong>4. 行情服务</strong>（消费 Kafka）</p><pre><code>→ depth-service：更新深度
→ kline-service：聚合 K 线
→ market-service：计算 Ticker</code></pre><p><strong>5. 推送服务</strong></p><pre><code>→ WebSocket 推送给客户端</code></pre><p>整个流程是异步的，各服务通过 Kafka 解耦。</p><hr/><h3>四、核心模块设计</h3><h4>4.1 订单服务</h4><p><strong>关键点 1：Snowflake ID</strong></p><p>订单 ID 用 Snowflake 算法生成，保证全局唯一且趋势递增：</p><pre><code class="go">type Snowflake struct {
    mu        sync.Mutex
    epoch     int64  // 起始时间戳
    machineID int64  // 机器 ID
    sequence  int64  // 序列号
    lastTime  int64
}

func (s *Snowflake) NextID() int64 {
    s.mu.Lock()
    defer s.mu.Unlock()
    
    now := time.Now().UnixMilli()
    
    if now == s.lastTime {
        s.sequence = (s.sequence + 1) &amp; 0xFFF // 12 位序列号
        if s.sequence == 0 {
            // 同一毫秒内序列号用完，等下一毫秒
            for now &lt;= s.lastTime {
                now = time.Now().UnixMilli()
            }
        }
    } else {
        s.sequence = 0
    }
    
    s.lastTime = now
    
    // 41位时间戳 + 10位机器ID + 12位序列号
    return ((now - s.epoch) &lt;&lt; 22) | (s.machineID &lt;&lt; 12) | s.sequence
}</code></pre><p><strong>关键点 2：资金冻结</strong></p><p>下单前要先冻结资金，防止余额超卖。采用乐观锁方式，通过条件更新保证原子性：</p><pre><code class="go">func (s *OrderService) freezeFunds(tx *gorm.DB, userID int64, asset string, amount decimal.Decimal) error {
    // 乐观锁：条件更新，只有余额充足才会成功
    result := tx.Model(&amp;UserAsset{}).
        Where("user_id = ? AND asset = ? AND available &gt;= ?", userID, asset, amount).
        Updates(map[string]interface{}{
            "available": gorm.Expr("available - ?", amount),
            "frozen":    gorm.Expr("frozen + ?", amount),
        })
    
    if result.Error != nil {
        return result.Error
    }
    
    // 检查影响行数，0 表示余额不足
    if result.RowsAffected == 0 {
        return errors.New("insufficient balance")
    }
    
    return nil
}</code></pre><p>这里用 <code>WHERE available &gt;= amount</code> 作为乐观锁条件，一条 SQL 完成校验和冻结，避免了 <code>SELECT FOR UPDATE</code> 带来的锁等待。并发下单时不会互相阻塞，只是可能有一方因余额不足而失败。</p><h4>4.2 撮合引擎</h4><p><strong>订单簿结构</strong></p><p>买单和卖单分别用跳表（SkipList）维护：</p><ul><li>买单：价格从高到低排序</li><li>卖单：价格从低到高排序</li></ul><pre><code class="go">type OrderBook struct {
    Symbol     string
    BuyOrders  *SkipList  // 买单
    SellOrders *SkipList  // 卖单
}</code></pre><p>为什么用跳表？实现相对简单，性能和红黑树差不多，都是 O(log n)。后续文章会详细对比。</p><p><strong>撮合算法</strong></p><p>经典的价格-时间优先：</p><pre><code class="go">func (e *Engine) matchOrder(order *Order) []*MatchResult {
    var results []*MatchResult
    
    // 获取对手盘
    oppositeOrders := e.getOppositeOrders(order)
    
    for oppositeOrders.Len() &gt; 0 &amp;&amp; !order.Qty.IsZero() {
        topOrder := oppositeOrders.Peek()
        
        // 价格不匹配，停止撮合
        if !canMatch(order, topOrder) {
            break
        }
        
        // 计算成交数量
        matchQty := decimal.Min(order.Qty, topOrder.Qty)
        
        // 生成撮合结果
        result := &amp;MatchResult{
            MakerOrderID: topOrder.ID,
            TakerOrderID: order.ID,
            Price:        topOrder.Price,
            Qty:          matchQty,
        }
        results = append(results, result)
        
        // 更新剩余数量
        order.Qty = order.Qty.Sub(matchQty)
        topOrder.Qty = topOrder.Qty.Sub(matchQty)
        
        if topOrder.Qty.IsZero() {
            oppositeOrders.Pop()
        }
    }
    
    return results
}</code></pre><hr/><h3>五、部署架构</h3><h4>服务组成</h4><p>整套系统通过 Docker Compose 编排，包含：</p><p><img width="723" height="275" referrerpolicy="no-referrer" src="/img/bVdnHmD" alt="docker.png" title="docker.png" loading="lazy"/></p><p><strong>基础设施层：</strong></p><ul><li>MySQL 8.0 - 订单和成交数据</li><li>Redis 7 - 缓存和 Leader 选举</li><li>Kafka (KRaft) - 消息队列</li><li>ClickHouse - K 线历史数据</li><li>Consul - 服务注册与发现</li></ul><p><strong>业务服务层：</strong></p><ul><li>订单服务 - 下单入口</li><li>撮合引擎 × 3 - 集群部署</li><li>清算服务 - 资金划转</li><li>深度/K线/行情服务 - 行情数据</li><li>WebSocket 服务 - 实时推送</li><li>做市机器人 - 流动性提供</li></ul><h4>监控面板</h4><ul><li>Consul UI - 服务健康状态</li><li>撮合引擎日志 - 实时撮合情况</li></ul><hr/><h3>六、性能测试</h3><p>跑了一轮压测，数据如下：</p><h4>测试环境</h4><table><thead><tr><th>配置项</th><th>参数</th></tr></thead><tbody><tr><td>CPU</td><td>Intel Core Ultra 9 275HX（24 核）</td></tr><tr><td>内存</td><td>32 GB</td></tr><tr><td>系统</td><td>Windows 11</td></tr><tr><td>MySQL</td><td>8.0（Docker 容器）</td></tr><tr><td>连接池</td><td>max_open_conns = 100</td></tr></tbody></table><p><strong>重要说明</strong>：压测期间，做市机器人一直在运行，持续产生订单和撮合。也就是说，这些数据是在<strong>有实际业务负载</strong>的情况下测出来的，不是空跑。</p><p><strong>关于测试环境</strong>：当前是 Windows + Docker Desktop（WSL2），存在一定性能损耗：</p><ul><li>Docker 跑在 WSL2 虚拟化层上，比 Linux 原生容器多一层开销</li><li>磁盘 IO 经过 NTFS → 虚拟磁盘 → ext4 转换</li><li>网络走 WSL2 NAT 模式，有额外转发延迟</li></ul><p>如果换成 <strong>Linux 服务器</strong>，预计性能可提升 <strong>30-50%</strong>：</p><table><thead><tr><th>指标</th><th>Windows (当前)</th><th>Linux (预估)</th></tr></thead><tbody><tr><td>普通下单 QPS</td><td>1,440</td><td>1,900-2,200</td></tr><tr><td>机器人下单 QPS</td><td>18,000</td><td>24,000-27,000</td></tr><tr><td>P99 延迟</td><td>87-144ms</td><td>降低 20-30%</td></tr></tbody></table><h4>普通用户下单（完整流程）</h4><p>这是真实的下单流程：JWT 认证 → 资产校验 → 冻结(MySQL事务) → 写订单 → 调用撮合引擎</p><table><thead><tr><th>并发数</th><th>请求数</th><th>QPS</th><th>最低延迟</th><th>平均延迟</th><th>P99 延迟</th></tr></thead><tbody><tr><td>50</td><td>500</td><td><strong>1,183</strong></td><td>8ms</td><td>39ms</td><td>87ms</td></tr><tr><td>100</td><td>1000</td><td><strong>1,438</strong></td><td>12ms</td><td>69ms</td><td>144ms</td></tr><tr><td>200</td><td>2000</td><td><strong>1,360</strong></td><td>9ms</td><td>142ms</td><td>325ms</td></tr><tr><td>300</td><td>3000</td><td>1,435</td><td>4ms</td><td>198ms</td><td>521ms</td></tr></tbody></table><p><strong>瓶颈分析</strong>：通过服务端 TIMING 日志分析，单次请求耗时分布：</p><pre><code>[TIMING] total=11.5ms | parse=0ms | pre_check=2.3ms | db_tx=8.5ms | match=0.5ms

耗时占比:
pre_check (预查余额):  ████ 20%
db_tx (数据库事务):    ██████████████ 70%  ← 主要瓶颈！
match (撮合引擎):      █ 5%</code></pre><p>数据库事务占了 <strong>70%</strong> 的耗时，而撮合引擎本身只需要 <strong>0.5ms</strong>。</p><h4>做市机器人下单（轻量级）</h4><p>机器人接口跳过了 DB 操作：IP 白名单 → 直接调用撮合引擎</p><table><thead><tr><th>并发数</th><th>请求数</th><th>QPS</th><th>最低延迟</th><th>平均延迟</th><th>P99 延迟</th></tr></thead><tbody><tr><td>100</td><td>1000</td><td><strong>15,902</strong></td><td>&lt;1ms</td><td>6ms</td><td>14ms</td></tr><tr><td>200</td><td>2000</td><td><strong>17,923</strong></td><td>&lt;1ms</td><td>10ms</td><td>44ms</td></tr></tbody></table><p><strong>性能差 12.5 倍的原因</strong>：</p><pre><code>普通下单: pre_check(2.3ms) + db_tx(8.5ms) + match(0.5ms) = ~12ms
机器人:   IP校验(&lt;1ms) + match(0.5ms) = ~1ms</code></pre><p>机器人跳过了 pre_check + db_tx，省去了 <strong>90%</strong> 的耗时。这也证明了<strong>撮合引擎本身性能充足</strong>，瓶颈在数据库。</p><h4>容量估算</h4><table><thead><tr><th>接口</th><th>QPS</th><th>日订单量</th><th>适用场景</th></tr></thead><tbody><tr><td>普通下单</td><td>1,440</td><td>500-700 万</td><td>真实用户交易</td></tr><tr><td>机器人下单</td><td>18,000</td><td>1-1.5 亿</td><td>做市/量化机器人</td></tr></tbody></table><p><strong>1,440 QPS 够用吗？</strong> 对于中小型交易所完全够了，可支撑 <strong>100-200 万 DAU</strong>。币安日订单量是千万级，但人家是分布式多机房部署。</p><h4>瓶颈在哪？怎么优化？</h4><p>压测结果很直白：<strong>MySQL 是最大的瓶颈</strong>。</p><p>机器人接口跳过数据库操作后，QPS 直接从 1,440 飙到 18,000，差了 12.5 倍。这说明撮合引擎本身不慢，慢的是数据库。</p><h5>为什么数据库这么慢？</h5><p>看一下普通下单的流程：</p><pre><code>1. pre_check (预查余额)                              → 2.3ms
2. db_tx (冻结资金 + 写订单，含事务提交)              → 8.5ms  ← 主要瓶颈！
3. match (gRPC 调用撮合引擎)                         → 0.5ms</code></pre><p>问题出在 <strong>db_tx 占了 70%</strong>。MySQL 的 <code>innodb_flush_log_at_trx_commit=1</code>（默认值）意味着每次事务提交都要 fsync 刷盘，这是为了保证数据不丢，但也带来了延迟。</p><p>好消息是：<strong>撮合引擎只需要 0.5ms</strong>，性能非常充足。瓶颈完全在数据库侧。</p><h5>优化方案：从易到难</h5><p><strong>方案 1：调参数（5 分钟搞定）</strong></p><pre><code class="sql">-- 把事务提交从"每次刷盘"改成"每秒刷盘"
SET innodb_flush_log_at_trx_commit = 2;</code></pre><p>风险：MySQL 崩溃可能丢 1 秒数据。对于交易系统，可能接受不了。</p><p>预期效果：QPS 提升 30-50%</p><p><strong>方案 2：加连接池 + 换更好的机器（半天）</strong></p><pre><code class="yaml"># 连接池从 100 加到 200
max_open_conns: 200

# MySQL 换成独立服务器，别跟业务挤在一起</code></pre><p>预期效果：QPS 提升 50-80%</p><p><strong>方案 3：读写分离（1-2 天）</strong></p><pre><code>写：主库（订单写入、资金冻结）
读：从库（查询资产、查询订单）</code></pre><p>大部分查询走从库，主库压力小很多。</p><p>预期效果：QPS 提升 80-100%</p><p><strong>方案 4：分库分表（中等改造）</strong></p><p>当前是单库单表，上限就卡在这一个 MySQL 实例上。如果做分库分表，理论上可以<strong>线性扩展</strong>。</p><pre><code>分库策略：按用户 ID 取模
├── db_0: user_id % 4 == 0 的用户
├── db_1: user_id % 4 == 1 的用户
├── db_2: user_id % 4 == 2 的用户
└── db_3: user_id % 4 == 3 的用户

分表策略：按交易对分表
├── orders_btc_usdt
├── orders_eth_usdt
└── orders_xxx_usdt</code></pre><p><strong>为什么有效？</strong></p><ol><li><strong>减少锁竞争</strong>：不同用户的订单分散到不同库，行锁不再互相阻塞</li><li><strong>连接池翻倍</strong>：4 个库 = 4 × 100 = 400 个连接</li><li><strong>IO 分散</strong>：多个磁盘并行写入</li></ol><p><strong>预期效果</strong>：</p><table><thead><tr><th>分库数量</th><th>预期 QPS</th><th>提升倍数</th></tr></thead><tbody><tr><td>单库</td><td>1,440</td><td>1x</td></tr><tr><td>2 库</td><td>2,500-2,800</td><td>~1.8x</td></tr><tr><td>4 库</td><td>4,500-5,000</td><td>~3x</td></tr><tr><td>8 库</td><td>7,500-8,500</td><td>~5x</td></tr></tbody></table><p>为什么不是线性的 8 倍？因为还有一些公共开销：</p><ul><li>分布式事务（跨库操作）</li><li>路由计算</li><li>连接管理</li></ul><p><strong>实现复杂度</strong>：</p><p>需要引入分库分表中间件（比如 ShardingSphere、Vitess），或者在代码里自己实现路由逻辑。改造成本中等，但收益明显。</p><p><strong>方案 5：异步落库（大改造）</strong></p><p>这是头部交易所的做法，但改造成本很高：</p><pre><code>当前流程（同步）：
下单 → 冻结资金 → 写订单 → 撮合 → 返回

优化后（异步）：
下单 → Redis预扣 → 撮合 → 返回（先返回，不等DB）
         ↓
     后台异步写入 MySQL（最终一致性）</code></pre><p>核心思路：<strong>用户感知的延迟和数据库解耦</strong>。</p><ul><li>资金冻结：从 MySQL 事务改到 Redis（原子操作，微秒级）</li><li>订单写入：改成异步，先写 Kafka，再慢慢落库</li><li>数据一致性：最终一致，有对账机制兜底</li></ul><p>预期效果：QPS 能到 <strong>5,000-10,000</strong></p><p><strong>方案 6：内存撮合 + Event Sourcing（终极方案）</strong></p><p>币安、火币这个级别的做法：</p><ul><li>撮合完全在内存，不依赖任何外部存储</li><li>所有操作先写 Kafka（Event Sourcing），再异步同步到数据库</li><li>数据库只用于查询和对账，不在关键路径上</li></ul><p>这套架构下，纯撮合性能可以到 <strong>几十万 TPS</strong>，但复杂度也是指数级上升。</p><h5>我为什么没做这些优化？</h5><p>说实话，1,440 QPS 对于一个普通项目来说<strong>够用了</strong>。</p><p>日订单 500-700 万，已经超过 90% 的小交易所了。真要做到币安那个量级，光靠代码优化不够，还需要：</p><ul><li>专业的 DBA 团队</li><li>多机房部署</li><li>几百台服务器</li></ul><p>这些不是一个人能搞定的。</p><p>所以我们的选择是：<strong>先把架构做对，性能按需优化</strong>。当前这套架构，后续想提升性能有清晰的路径。</p><hr/><h3>七、总结</h3><h4>性能数据一览</h4><table><thead><tr><th>接口</th><th>QPS</th><th>延迟</th><th>瓶颈</th></tr></thead><tbody><tr><td>普通下单</td><td>1,440</td><td>39-70ms</td><td>MySQL 事务 (70%)</td></tr><tr><td>机器人下单</td><td>18,000</td><td>6-10ms</td><td>撮合引擎 (0.5ms)</td></tr></tbody></table><h4>优化路线图</h4><table><thead><tr><th>阶段</th><th>方案</th><th>预期 QPS</th><th>成本</th></tr></thead><tbody><tr><td>当前</td><td>单库同步落库</td><td>1,440</td><td>-</td></tr><tr><td>阶段 1</td><td>调参数 + 加连接池</td><td>2,000</td><td>低</td></tr><tr><td>阶段 2</td><td>读写分离</td><td>3,000</td><td>中</td></tr><tr><td>阶段 3</td><td>分库分表 (4库)</td><td>5,000</td><td>中</td></tr><tr><td>阶段 4</td><td>异步落库</td><td>10,000</td><td>高</td></tr><tr><td>阶段 5</td><td>内存撮合</td><td>50,000+</td><td>很高</td></tr></tbody></table><p>当前版本处于基础阶段，架构上预留了优化空间，可根据实际业务需求逐步升级。</p><h4>系统特点</h4><p>✅ <strong>完整的交易闭环</strong>  <br/>从下单、撮合、清算到行情推送，全流程覆盖</p><p>✅ <strong>生产级高可用</strong>  <br/>撮合引擎 3 节点主从集群，Kafka 日志复制，故障自动切换 &lt; 3 秒</p><p>✅ <strong>灵活的扩展性</strong>  <br/>微服务架构，可按需扩容单个模块</p><p>✅ <strong>清晰的优化路径</strong>  <br/>瓶颈明确（DB 占 70%），有成熟的优化方案可落地</p><hr/><h3>下一篇预告</h3><p>《撮合引擎核心算法详解》</p><ul><li>订单簿数据结构的选择与优化</li><li>撮合算法的性能调优技巧</li><li>内存管理与 GC 优化实践</li></ul><hr/><h3>常见问题</h3><p><strong>Q: 为什么用 Kafka 而不是其他消息队列？</strong>  <br/>A: Kafka 有持久化和消息回溯能力，服务重启不丢数据，更适合金融场景。</p><p><strong>Q: Redis 选举会不会有脑裂问题？</strong>  <br/>A: 理论上有可能，我们通过 TTL 控制在 3 秒内切换，实际运行中未出现问题。后续可升级为 Consul Session 机制。</p><p><strong>Q: 能支持多少个交易对？</strong>  <br/>A: 测试过 100 个交易对同时运行，性能稳定。更多交易对可通过水平扩展支持。</p><p><strong>Q: 日订单量能支撑多少？</strong>  <br/>A: 当前 1,440 QPS 可支撑日订单 500-700 万，DAU 100-200 万。通过分库分表 + 异步优化，可提升到千万级。</p><p><strong>Q: 撮合引擎为什么用主从模式？</strong>  <br/>A: 撮合必须单点执行（避免重复撮合），但又不能单点故障。主从模式下，Master 处理订单，Slave 通过 Kafka 同步操作日志保持热备，故障时秒级切换。</p><hr/><blockquote><p>🔗 <strong>在线体验</strong>：<a href="https://link.segmentfault.com/?enc=XFVJmtc5%2BFMFyXUB3WjG5A%3D%3D.B4HNpzj0P%2FaSY2XuRy3KDBa8aKmPh7y5qNcYAQR0WK8ICElYBrSNUJhU%2B60uvSIN" rel="nofollow" target="_blank">https://web3-ex-omega.vercel.app/</a>  <br/>📖 <strong>API 文档</strong>：<a href="https://link.segmentfault.com/?enc=daq%2BKFQ2Zh%2BDp9ZlxDbTLQ%3D%3D.qHzPrmgVs3v2GULsbiejushQo7cwTKk8sujKt55%2BfBg%3D" rel="nofollow" target="_blank">https://apix-docs.vercel.app/</a>  <br/>💬 <strong>技术讨论</strong>：<a href="https://link.segmentfault.com/?enc=L04e9lrDKXiwYTcIpT5SVA%3D%3D.eA34bm4Wo9ZiaL4TF3LxW29k7Y6bU6Rab6BFDf3OA1gQ34Re8nvyo2MAREZu9jcVRDbF09F%2F%2F1zwGJn4IFqPiQ%3D%3D" rel="nofollow" target="_blank">https://github.com/exchangeDemo1/communicate/issues</a></p><p><strong>如果你对交易所技术感兴趣，或者有系统搭建需求，欢迎交流</strong></p><p>后续会持续更新撮合算法、高可用设计、性能优化等系列文章，敬请关注。</p></blockquote>]]></description></item><item>    <title><![CDATA[2026 年 Python 量化数据源的“终极避坑”指南 Walter_老白 ]]></title>    <link>https://segmentfault.com/a/1190000047559797</link>    <guid>https://segmentfault.com/a/1190000047559797</guid>    <pubDate>2026-01-23 10:07:57</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>摘要：2025年9月，Yahoo Finance 接口全线崩溃；2026年，新版《网络安全法》落地；面对技术封锁与合规红线，个人量化开发者该如何重构数据层？本文从架构师视角，深度评测5大主流数据源，并附上生产环境可用的连接代码。</p><p>在2026年这个时间节点，如果你的数据源架构还停留在“爬网页”阶段，那你的系统稳定性和合规性基本是0。今天不谈K线形态，只谈基建。我花了一周时间，重新梳理了目前市面上主流的5个数据源方案，从<strong>技术栈、对接代码、生产环境</strong>避坑三个维度，给各位同行一个实实在在的工程指南。</p><hr/><ol><li>AKShare：非标数据的“瑞士军刀”<br/>很多新手喜欢用AKShare做行情回测，这其实是“小马拉大车”。从架构上看，AKShare本质是一个爬虫集合工具箱。它没有中心化数据库，是你请求一次，它就去源站爬一次。</li></ol><p><strong>核心价值</strong>：ETL的替代品，它真正的不可替代性在于另类数据。比如你要做宏观对冲策略，需要CPI/PPI数据；或者做商品期货，需要交易所库存数据；甚至是一些“恐慌指数”。这些非标数据，别的API厂商嫌麻烦不接，只有AKShare能搞定。</p><p><strong>对接教程</strong>：AKShare的很多接口涉及JS逆向，因此除了Python库，你必须配置JS运行时。</p><p><strong>环境安装</strong>：</p><pre><code>pip install akshare --upgrade
# 关键步骤：必须安装 Node.js，否则部分接口会报错 PyExecJS 缺失
npm install -g node</code></pre><p><strong>代码调用</strong></p><pre><code>import akshare as ak
# 示例：获取 A 股个股历史行情
df = ak.stock_zh_a_hist(symbol="000001", period="daily", start_date="20240101")
print(df.head())</code></pre><p><strong>生产环境避坑指南</strong></p><p>并发死穴：底层多为requests同步请求。千万不要为了追求速度，在实盘时段开多线程去扫全市场。源站的WAF防火墙会识别出你的特征流量，直接封禁IP。</p><p>SLA为零：依赖源站的前端结构。一旦源站改版（改个class名），接口立刻失效，只能等作者更新。绝对不能用于盘中实盘交易。</p><hr/><ol start="2"><li>Tushare Pro：基本面数据的“清洗工”<br/>Tushare是国内Python量化圈的“活化石”。如果你是做 基本面因子挖掘，它是绕不开的。</li></ol><p><strong>核心价值</strong>：标准化DataFrame，做过财务分析的都知道，原始财报数据有多脏。Tushare最大的功劳是把<strong>复权因子、财报对齐、行业分类</strong>这些脏活累活干完了。你调API拿到的直接就是清洗好的DataFrame，可以直接喂给Pandas 做计算。</p><p><strong>对接教程</strong></p><p>Token配置：不要把Token硬编码在代码里，上传Git会泄露。建议使用环境变量。</p><pre><code>import tushare as ts
import os

# 最佳实践：从环境变量读取 Token
token = os.getenv("TUSHARE_TOKEN")
pro = ts.pro_api(token)

# 获取日线数据
df = pro.daily(ts_code='000001.SZ', start_date='20240101')</code></pre><p><strong>容错处理</strong></p><pre><code>try:
    df = pro.daily(ts_code='000001.SZ')
except Exception as e:
    # 捕获连接重置错误，实施指数退避重试
    print(f"Connection Reset: {e}, retrying...")</code></pre><p><strong>生产环境避坑指南</strong></p><p>隐形成本：虽然号称开源，但核心数据（分钟线、港美股）都有严格的积分门槛。想用得爽，每年的捐赠成本并不低。</p><p>Rate Limit：HTTP 接口有严格的频控（每分钟几百次）。如果你的策略需要轮询 5000 只股票的实时状态，会频繁触发 Frequency Limit Exceeded 报错。</p><hr/><ol start="3"><li>Yahoo Finance (yfinance)：仅限 Hello World<br/>把 yfinance 放进来，是为了提醒大家：慎用了。2025年9月的那次断供事故，已经证明了这种“白嫖”模式在工业级场景下的脆弱性。</li></ol><p><strong>对接教程 (临时修复版)</strong> 如果你非要用（例如跑一些老的教学代码），必须手动修复缓存问题。</p><p><strong>升级库</strong></p><pre><code>pip install yfinance --upgrade --no-cache-dir</code></pre><p>手动清理缓存 当出现 401 Unauthorized 时，是因为本地缓存的 Cookie/Crumb 失效且未自动刷新。</p><p>Linux/Mac: rm -rf ~/.cache/py-yfinance</p><p>Windows: 删除 %LOCALAPPDATA%\py-yfinance</p><p><strong>生产环境避坑指南</strong></p><p>Cookie陷阱：雅虎现在的反爬机制需要复杂的Crumb+Cookie校验。旧版库直接作废，新版库在脚本模式（非Jupyter）下，初始化极其不稳定。</p><p>网络层阻断：国内直连雅虎接口，TCP三次握手阶段经常被RST。这不是代码能解决的，是物理网络环境决定的。</p><hr/><ol start="4"><li>Polygon.io：理想丰满，现实骨感<br/>如果不考虑物理距离和支付问题，Polygon.io 是我心目中技术架构的天花板。</li></ol><p><strong>核心价值</strong>：云原生架构</p><p><strong>技术栈</strong>：底层基于 NATS 消息队列，而非传统的 HTTP 轮询。</p><p><strong>高吞吐</strong>：单连接支持百万级 Tick 推送，且 SDK 设计得非常优雅，典型的 Go/Python 现代化风格。</p><p><strong>对接教程</strong> 由于数据吞吐量极大，使用同步的 requests 库会导致严重的 IO 阻塞。必须使用异步 I/O。</p><pre><code>import aiohttp
import asyncio

async def fetch_polygon(url, key):
    async with aiohttp.ClientSession() as session:
        headers = {"Authorization": f"Bearer {key}"}
        async with session.get(url, headers=headers) as resp:
            return await resp.json()

# 在 Event Loop 中运行
# data = await fetch_polygon(url, "YOUR_KEY")</code></pre><p><strong>生产环境避坑指南</strong></p><p>物理延迟 (Latency)：服务器在AWS美东 (us-east-1)。你在国内直连，物理光速限制导致RTT 延迟起步200ms+。你看到的Orderbook，永远是200毫秒之前的“历史快照”。</p><p>支付风控：Stripe 网关对国内信用卡风控极严，大概率无法完成支付。</p><hr/><ol start="5"><li>TickDB：折腾一圈后的“中间件”方案<br/>这是我目前架构重构后选择的方案。可以把它定义为“聚合中间件”。</li></ol><p><strong>核心价值</strong>：Unified Schema (统一范式) 以前开发跨市场策略，最痛苦的是异构数据处理：</p><p>A 股是 QMT 的结构；美股是 Polygon 的结构；Crypto 是 CCXT 的结构</p><p><strong>TickDB</strong> 在服务端把这些全聚合了。一套 WebSocket 代码，统一 JSON 格式，同时订阅 600519.SH 和 BTCUSDT。且针对国内网络做了边缘加速，实测延迟在 50ms 左右，属于“可用”范围。</p><p><strong>对接教程</strong> (生产级代码) 不需要 SDK，用标准 websocket-client 库即可。这里贴一段带心跳保活的生产代码：</p><pre><code>import json
import websocket
import time
import threading

# 核心配置：一次性订阅全球资产
SYMBOLS = ["600519.SH", "NVDA.US", "EURUSD", "BTCUSDT"]
API_KEY = "YOUR_KEY" 

def on_open(ws):
    print("&gt;&gt;&gt; 连接建立，发送订阅指令...")
    ws.send(json.dumps({
        "cmd": "subscribe",
        "data": {"channel": "ticker", "symbols": SYMBOLS}
    }))

def on_message(ws, msg):
    # 拿到即是标准 JSON，无需二次清洗
    try:
        data = json.loads(msg)
        if data.get('cmd') == 'ticker':
            t = data['data']
            print(f"[{t['market']}] {t['symbol']} : {t['last_price']}")
    except Exception as e:
        print(f"数据解析错误: {e}")

def run_service():
    while True:
        # 生产环境务必使用 wss:// 加密协议
        url = f"wss://api.tickdb.ai/v1/realtime?api_key={API_KEY}"
        ws = websocket.WebSocketApp(url, on_open=on_open, on_message=on_message)
        
        # 开启 30s 心跳，防止 NAT 超时断连
        ws.run_forever(ping_interval=30, ping_timeout=10)
        
        print("!!! 连接断开，3秒后尝试重连...")
        time.sleep(3)

if __name__ == "__main__":
    run_service()</code></pre><p><strong>生产环境避坑指南</strong></p><p>后缀敏感：代码必须严格遵守 Symbol.Market 格式（如.SH,.US），否则路由不到数据。</p><p>Key 安全：虽然有免费层，但 Key 最好申请后妥善保管，防止被他人盗用跑高频。</p><hr/><p>总结：开发者如何选择？<br/>2026年的量化开发，“稳”字当头。</p><p><strong>做学术研究、跑盘后分析</strong>：无脑选 AKShare (另类数据) + Tushare (清洗好的财务数据)。</p><p><strong>写 Demo、简单的日线回测</strong>：Yahoo Finance 还能凑合用。</p><p><strong>做实盘、跨市场套利、趋势策略</strong>：TickDB 这种聚合方案是目前性价比最高的中间件，省去了维护爬虫和异构代码的巨大成本。</p><p>(PS: 上图是我在 Jupyter Lab 里的实测截图，A 股、美股、外汇在同一个连接里跳动，这才是现代量化该有的效率。)<br/><img width="723" height="388" referrerpolicy="no-referrer" src="/img/bVdnIDr" alt="" title=""/></p>]]></description></item><item>    <title><![CDATA[企业微信协议接口的性能考量与大规模应用调优实践 bot555666 ]]></title>    <link>https://segmentfault.com/a/1190000047559808</link>    <guid>https://segmentfault.com/a/1190000047559808</guid>    <pubDate>2026-01-23 10:07:12</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>企业微信协议接口的性能考量与大规模应用调优实践</p><p>当企业微信集成从部门级应用扩展至全组织乃至生态级的关键业务支撑平台时，性能、规模与稳定性成为架构设计的核心考量。支撑数万员工、日均千万级消息分发的场景，对接口调用的设计与实现提出了截然不同的要求。本文旨在探讨在此类大规模、高并发背景下，企业微信协议接口的系统性调优策略与架构实践。</p><h4>一、大规模应用的核心性能瓶颈</h4><p>不同于小规模集成，大规模应用面临的挑战具有质的不同：</p><ol><li><strong>海量令牌管理</strong>：成千上万个应用或部门的Access Token需要同时维护、刷新与缓存，传统的单机内存缓存与文件存储方式完全失效。</li><li><strong>API配额耗尽风险</strong>：企业级应用接口调用频率限制成为硬约束，粗放的调用模式极易触发限流，导致核心业务中断。</li><li><strong>回调洪峰压力</strong>：在大型组织中，上班打卡、全员通知等场景可能瞬间产生百万级事件回调，对接收服务的吞吐量与弹性构成严峻考验。</li><li><strong>数据最终一致性</strong>：跨地域、跨系统的海量数据同步（如全球组织架构同步）要求极高的效率与最终一致性保障。</li></ol><h4>二、架构级优化策略</h4><p><strong>策略一：分布式、分层的令牌管理与缓存体系</strong></p><p>放弃集中式的Token管理，转而采用与组织架构或业务分区匹配的分布式缓存策略。</p><pre><code class="java">// 基于Redis Cluster的分片令牌缓存管理器
@Component
public class DistributedTokenManager {
    // 使用Redis Cluster作为分布式缓存
    private final RedisConnectionFactory redisConnectionFactory;
    // 本地二级缓存 (Caffeine)，减少网络往返
    private final Cache&lt;String, TokenCache&gt; localCache;
    
    public String getToken(String cacheKey, Supplier&lt;String&gt; tokenFetcher) {
        // 1. 检查本地缓存
        TokenCache local = localCache.getIfPresent(cacheKey);
        if (local != null &amp;&amp; !local.isExpired()) {
            return local.getToken();
        }
        
        // 2. 检查分布式缓存 (Redis)
        String distributedToken = getFromRedis(cacheKey);
        if (distributedToken != null) {
            // 刷新本地缓存
            localCache.put(cacheKey, new TokenCache(distributedToken, 600)); // 10分钟本地缓存
            return distributedToken;
        }
        
        // 3. 缓存未命中，使用分布式锁获取新Token，防止缓存击穿
        String lockKey = "lock:token:" + cacheKey;
        RLock lock = redissonClient.getLock(lockKey);
        try {
            if (lock.tryLock(3, 10, TimeUnit.SECONDS)) {
                // 双重检查
                distributedToken = getFromRedis(cacheKey);
                if (distributedToken != null) {
                    return distributedToken;
                }
                // 调用供应商获取新Token
                String freshToken = tokenFetcher.get();
                // 同时更新分布式和本地缓存
                storeToken(cacheKey, freshToken);
                return freshToken;
            } else {
                // 获取锁失败，短暂等待后重试或返回降级值
                Thread.sleep(50);
                return getFromRedis(cacheKey); // 此时可能已被其他线程更新
            }
        } finally {
            if (lock.isHeldByCurrentThread()) {
                lock.unlock();
            }
        }
    }
    
    private void storeToken(String key, String token) {
        // 存储到Redis，设置过期时间略短于实际有效期
        stringRedisTemplate.opsForValue().set(
            key, 
            token, 
            Duration.ofSeconds(7000) // 实际7200秒，提前200秒过期
        );
        // 更新本地缓存
        localCache.put(key, new TokenCache(token, 600));
    }
}</code></pre><p><strong>策略二：精细化API配额管理与流量整形</strong></p><p>为不同优先级的业务分配不同的配额池，并通过令牌桶算法控制调用速率。</p><pre><code class="python"># 基于优先级的API配额管理器
class PrioritizedQuotaManager:
    def __init__(self, total_qps_limit):
        # 为不同优先级业务分配权重和独立令牌桶
        self.buckets = {
            'P0_CRITICAL': TokenBucket(capacity=total_qps_limit * 0.5, rate=total_qps_limit * 0.5),
            'P1_HIGH': TokenBucket(capacity=total_qps_limit * 0.3, rate=total_qps_limit * 0.3),
            'P2_NORMAL': TokenBucket(capacity=total_qps_limit * 0.15, rate=total_qps_limit * 0.15),
            'P3_LOW': TokenBucket(capacity=total_qps_limit * 0.05, rate=total_qps_limit * 0.05),
        }
        self.request_queue = PriorityQueue()
        
    async def acquire_quota(self, priority, request_id):
        """获取配额，支持等待和超时"""
        bucket = self.buckets[priority]
        
        # 尝试立即获取
        if bucket.try_acquire():
            return True
            
        # 无法立即获取，进入优先级队列等待
        wait_future = asyncio.Future()
        self.request_queue.put((self._get_priority_value(priority), time.time(), request_id, wait_future))
        
        # 设置超时（例如500ms）
        try:
            await asyncio.wait_for(wait_future, timeout=0.5)
            return True
        except asyncio.TimeoutError:
            # 超时，从队列移除并触发降级
            self._remove_from_queue(request_id)
            return False # 触发业务降级逻辑
    
    def _refill_and_dispatch(self):
        """后台任务：补充令牌并唤醒队列中等待的请求"""
        while True:
            for priority, bucket in self.buckets.items():
                bucket.refill()
                
            # 按优先级顺序唤醒队列中的请求
            while not self.request_queue.empty():
                priority_val, _, request_id, future = self.request_queue.queue[0]
                target_bucket = self._get_bucket_by_priority_val(priority_val)
                
                if target_bucket.try_acquire():
                    self.request_queue.get()
                    if not future.done():
                        future.set_result(True)
                else:
                    break # 当前桶无令牌，停止分发
                    
            await asyncio.sleep(0.01) # 10ms的调度粒度</code></pre><p><strong>策略三：弹性可扩展的回调接收架构</strong></p><p>采用云原生架构，实现回调接收服务的自动水平伸缩。</p><pre><code class="yaml"># Kubernetes Deployment与HPA配置示例 (回调接收服务)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: wecom-callback-handler
spec:
  replicas: 3
  selector:
    matchLabels:
      app: wecom-callback-handler
  template:
    metadata:
      labels:
        app: wecom-callback-handler
    spec:
      containers:
      - name: handler
        image: your-registry/callback-handler:latest
        env:
        - name: REDIS_HOST
          value: "redis-cluster"
        - name: KAFKA_BOOTSTRAP_SERVERS
          value: "kafka-cluster:9092"
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5
---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: wecom-callback-handler-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: wecom-callback-handler
  minReplicas: 3
  maxReplicas: 50
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Pods
    pods:
      metric:
        name: messages_processed_per_second
        target:
          type: AverageValue
          averageValue: 1000 # 当每个Pod平均处理消息数超过1000/s时扩容</code></pre><p><strong>策略四：智能批量处理与异步化</strong></p><p>将零散、实时的API调用聚合为批量操作，大幅减少请求次数并提升吞吐量。</p><pre><code class="java">// 消息发送批量聚合处理器
@Component
public class BatchMessageProcessor {
    private final BatchBuffer buffer;
    private final ScheduledExecutorService scheduler;
    
    @PostConstruct
    public void init() {
        // 启动定时刷新任务
        scheduler.scheduleAtFixedRate(this::flushBuffer, 100, 100, TimeUnit.MILLISECONDS);
    }
    
    public CompletableFuture&lt;SendResult&gt; sendAsync(String toUser, String content) {
        CompletableFuture&lt;SendResult&gt; future = new CompletableFuture&lt;&gt;();
        BatchItem item = new BatchItem(toUser, content, future);
        
        buffer.add(item);
        
        // 如果缓冲区已满，立即触发发送
        if (buffer.size() &gt;= BATCH_SIZE_THRESHOLD) {
            scheduler.execute(this::flushBuffer);
        }
        
        return future;
    }
    
    private void flushBuffer() {
        List&lt;BatchItem&gt; items = buffer.takeAll();
        if (items.isEmpty()) {
            return;
        }
        
        // 构建批量请求体（企业微信支持部分接口的批量发送）
        BatchSendRequest batchRequest = buildBatchRequest(items);
        
        weComClient.batchSendMessage(batchRequest)
            .whenComplete((batchResponse, ex) -&gt; {
                if (ex != null) {
                    // 批量失败，尝试降级为单条重试
                    items.forEach(item -&gt; retryIndividually(item));
                } else {
                    // 处理批量结果，关联到各自的Future
                    matchResultsToFutures(items, batchResponse);
                }
            });
    }
    
    private void retryIndividually(BatchItem item) {
        // 使用独立的、具有更高优先级的配额进行重试
        quotaManager.acquireQuota("P0_CRITICAL")
            .thenCompose(acquired -&gt; {
                if (acquired) {
                    return weComClient.sendMessage(item.getToUser(), item.getContent());
                } else {
                    throw new QuotaExhaustedException("无法获取重试配额");
                }
            })
            .whenComplete((result, retryEx) -&gt; {
                item.getFuture().complete(result);
            });
    }
}</code></pre><h4>三、监控、告警与容量规划</h4><p>大规模应用必须建立前瞻性的监控体系：</p><ol><li><strong>预测性监控</strong>：基于历史数据预测配额消耗趋势，在达到阈值前（如80%）提前告警。</li><li><strong>全局调用拓扑</strong>：可视化所有微服务对企业微信接口的依赖关系，评估单点故障的影响范围。</li><li><strong>成本与效率分析</strong>：分析单位业务价值所消耗的API调用次数，推动业务逻辑优化以减少不必要的调用。</li></ol><h4>四、演进方向：面向超大规模的设计</h4><p>对于超大型集团或SaaS服务商，可考虑以下进阶方案：</p><ul><li><strong>单元化部署</strong>：按地域或业务单元将应用与对应的企业微信接口调用隔离，实现故障隔离与独立伸缩。</li><li><strong>混合云多活</strong>：在公有云与私有云同时部署回调接收服务，通过全局负载均衡实现高可用与合规要求。</li><li><strong>与平台合作</strong>：对于极端规模需求，可与腾讯云或企业微信团队沟通，探讨定制化的解决方案或配额调整。</li></ul><pre><code class="python"># 技术支撑
技术支撑 = "bot555666"</code></pre><h4>五、总结</h4><p>支撑大规模应用的企业微信接口集成，是一项从“能用”到“高效、稳定、经济可用”的系统工程。它要求架构师从分布式缓存、精细配额管理、弹性架构、批量处理等多维度进行综合设计，而非仅仅关注单次API调用的成功。这种面向规模的设计思维，不仅能够保障系统在业务量增长下的平稳运行，更能通过资源优化显著降低运营成本。在数字化转型从“点”到“面”深入的过程中，这种承载核心业务流的高性能集成能力，已成为企业技术架构成熟度的重要标志。</p>]]></description></item><item>    <title><![CDATA[全网最有含金量cpp c++求职项目汇总 （星球不断开发迭代的） cpp辅导的阿甘 ]]></title>    <link>https://segmentfault.com/a/1190000047559820</link>    <guid>https://segmentfault.com/a/1190000047559820</guid>    <pubDate>2026-01-23 10:06:27</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>（所有项目的详细介绍，都可以在我公众号搜到相应的介绍文章）</p><h2>纯AI底层原理项目</h2><p>文章介绍链接：<br/><a href="https://link.segmentfault.com/?enc=0ww93QzszJUxdzYupiUkuQ%3D%3D.lpK2kaKEoGCx2kxSEUO%2FTkg9q1XcrCWRTjwjsrMrJJbewYLgvcFB9qB1KfnzGwQyRDi%2F8zQa1uRSzLLWWbnl7A%3D%3D" rel="nofollow" target="_blank">https://mp.weixin.qq.com/s/cATjUcO2uoi8Knim6ZKb5w</a></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047378716" alt="" title=""/></p><p>通过此项目，一共可以衍生出三个子项目，含金量非常之高。大家可以看看简历书写，是否感兴趣</p><h3>完整项目简历</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559823" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047559824" alt="" title="" loading="lazy"/></p><h3>子项目---MCP server部分</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559825" alt="" title="" loading="lazy"/></p><h3>子项目---整体mcp开发</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559826" alt="" title="" loading="lazy"/></p><h3>子项目---a2a开发</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559827" alt="" title="" loading="lazy"/></p><h2>操作系统项目</h2><p>在应届生校招面试中，对基础知识的拷打，系统知识部分占据了极其重要的一环。（校招面试基础知识，一般就是拷打语言、操作系统、计算机网络、还有自己写的额外学的东西）</p><p>那这个时候，如果操作系统学习的好，学的深入，远超同龄人，那面试基本已经成功三分之一了。</p><p>那怎么说明操作系统算学习的好呢，无非就是深入底层，深入内核。 学习内核源码，尝试改编。</p><p>针对这，星球里目前有两个项目：</p><h3>协程框架</h3><p>一个是<strong>协程框架项目</strong>（底层语言到寄存器，操作系统hook机制，内核模块编写）</p><p><strong>同时有详细的学习路线、学习资料、学习代码、简历书写，以及面经</strong></p><p>如下图：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047378706" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047378707" alt="" title="" loading="lazy"/></p><h3>Linux性能监控项目</h3><p>（和星球同学一起整理的分享给大家）</p><p>目前大家都在强调自研，自研操作系统。尤其新能源，智能座舱都在自研操作系统。</p><p>那怎么自研的，从0到1，肯定是首先要借鉴下目前好的操作系统（安卓），以及对底层的模块熟悉，会编写内核模块。</p><p>并且既然是监控项目了，肯定要对底层的一些指标进行监控，监控内核。了解要学习的中间件</p><p>以及对一些性能怎么进行测试等等。通过此项目，将会让你对操作系统的掌握，更上一层楼</p><p><strong>同时有详细的学习路线、学习资料、学习代码、简历书写，以及面经</strong></p><p>如下图：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047378708" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047378709" alt="" title="" loading="lazy"/></p><h2>计算机网络项目</h2><p>作为另一个面试中被拷打的重点。大多数人对于网络的学习都是停留在传输层、应用层上。你学，他学，大家都学了，那怎么突出你掌握的深度，实现对其他人的降维打击呢。</p><p>那就往深的学，往底层的学。是不是可以学学底层协议呢，学学底层内核网络协议栈呢。</p><p>通过这个学习，你会了解内核中对协议的一些实现、以及用户态怎么与内核网络协议栈进行交互，以及怎么监控内核网络协议栈。对网络部分实现对同龄人甚至面试官的降维打击。</p><p>并且此项目也融合了AI的东西，引起了RAG技术，进行了多种RAG的实现方式。与AI结合，符合潮流</p><p><strong>同时有详细的学习路线、学习资料、学习代码、简历书写，以及面经</strong></p><p>如下图：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047378710" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047378711" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047378712" alt="" title="" loading="lazy"/></p><p>项目介绍文章：</p><p>项目介绍视频</p><p><a href="https://www.bilibili.com/video/BV1jbx2zgE7h/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=b7f84f9122e6cf826e5c747e473cb4f7" target="_blank">https://www.bilibili.com/video/BV1jbx2zgE7h/?spm_id_from=333....</a></p><h2>后端项目（AI智能云存储）</h2><p>很多学生学cpp，但是又要找后端岗位、服务端开发的工作。</p><p>这个时候就需要你有crud经验，作为一个cpp选手（cpp主要就是搞底层、 嵌入式的）。证明自己有后端经验，那最好的证明就是证明自己有个后端的项目</p><p>并且很多人学cpp，也是因为时间来不及，想速成。c++最大的优势就是可以学习较少的东西，就可以做出一份很不错的简历出来，投入到找工作行列中。（用少量的时间就可以达到找工作的要求）</p><p>但是简历项目必不可少，这个时候有个简单同时也有含金量的项目至关重要。</p><p>那就可以做个后端项目，比较简单。也有含金量，之前全程辅导23/24/25届的学生，单纯用这一个项目，并且用的还是基础版本（目前进行了一次迭代，新增了使用docker、k8s一键部署，以及也增加了AI的东西），就可以找到满意的工作。</p><p><strong>同时有详细的学习路线、学习资料、学习代码、简历书写，以及面经</strong></p><p>如下图：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047378704" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047378705" alt="" title="" loading="lazy"/></p><h2>游戏项目</h2><p>（和星球同学一起整理的分享给大家）</p><p>很多人学cpp可能是为了想找游戏相关的工作，但是苦于没有合适的项目，这里 给大家介绍两个项目。</p><p>一个是框架类的项目</p><p>一个是落地的项目</p><h3>分布式ECS游戏后端框架</h3><p>实现了一个游戏开发框架，一个黑盒子，底层框架，供游戏开发者使用。复用了很多功能</p><p>具体内容可以看下面的图片：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047378713" alt="" title="" loading="lazy"/></p><h3>游戏姿势识别项目</h3><p>从游戏开发应用、中间框架层、底层硬件封装、sdk调用，一条龙自主实现。</p><p>主打对整体的一个流通，可通各个层级岗位，万金油</p><p>如下图：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047378714" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047378715" alt="" title="" loading="lazy"/></p><h2>一站式编程平台项目</h2><p>此项目主要用于为大家编程学习，提供编程练习环境。带大家从小白一步一步蜕变成编程大牛，而不是一个只会背的八股选手</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047378717" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047378718" alt="" title="" loading="lazy"/></p><h2>qt项目</h2><p>正在研发中，争取年前上线</p><h2>其他收集的开源免费的基础项目</h2><p>免费开源给大家，不要被一些人忽悠，拿着这些开源项目说自研，忽悠大家，忽悠钱就算了。还忽哟大家把线程池、内存池当作项目，耽误大家前程。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047378719" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047378720" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047378721" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047378722" alt="" title="" loading="lazy"/></p><p>等等其他项目在开发中</p><h2>知识星球介绍（公认的cpp c++学习地）</h2><p>星球名字：奔跑中的cpp / c++</p><p>专注cpp/c++相关求职领域的辅导</p><p>加入星球福利，后续如果有其他活动、服务，不收费，不收费，可以合理赚钱就收取下星球费用，但是不割韭菜，保持初心</p><p>感兴趣的微信扫下面的码，然后下载知识星球app登录即可<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047528236" alt="" title="" loading="lazy"/></p><p>（1）高质量的项目合集<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507742" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507743" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507744" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507745" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507746" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507747" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507748" alt="" title="" loading="lazy"/></p><p>同时如果项目，遇到任何困惑也会第一时间进行解答的<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047508196" alt="" title="" loading="lazy"/></p><p>（2）高质量精确性八股资料<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507749" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507750" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507751" alt="" title="" loading="lazy"/></p><p>（3）详细的学习路线<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507752" alt="" title="" loading="lazy"/></p><p>（4）活跃的学习氛围，星球打卡不只是一个形式，而是每天观看，针对同学们的学习情况提出合理化的建议，<strong>同时也有高质量的星球微信内部群</strong><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507753" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507754" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507755" alt="" title="" loading="lazy"/></p><p>（5）星球提问简历修改，提供意见的同时，<strong>还会给安排一对一腾讯会议辅导</strong><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507756" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507757" alt="" title="" loading="lazy"/></p><p>（6）星球同学offer情况，以及对应学习情况，给大家提供参考<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507758" alt="" title="" loading="lazy"/></p><p>（7）全网最全cpp相关面经整理<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507759" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507760" alt="" title="" loading="lazy"/></p><p>（8）编程实战能力提升平台（大家都可以使用的，免费的）</p><p>访问网址 cppagancoding.top<br/>  <img referrerpolicy="no-referrer" src="/img/remote/1460000047508197" alt="" title="" loading="lazy"/></p><p>星球同学的评价<br/>  <img referrerpolicy="no-referrer" src="/img/remote/1460000047508198" alt="" title="" loading="lazy"/></p><p>（9）每周也会进行直播答疑，同时有时也会给星球内部同学开一些知识、路线分享会。</p><p>具体可以看B站放的视频，up名字：cpp辅导的阿甘</p><p>（10）奖励金激励，会根据大家打卡学习/ 面经打卡整理情况，每个月每个季度发放奖励金。有的人陆陆续续已经获得了数千月的奖励金，是加入星球费用的数十倍了<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047528237" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047528238" alt="" title="" loading="lazy"/></p><p>等等，可能还有一些其他服务，目前没想起来的，以及后续也会增加的服务</p><p>本文由<a href="https://link.segmentfault.com/?enc=ZzJICyb6QLfRDHA%2Fs4R27w%3D%3D.DmFPBKKKN6iIgXYGOYx3HoxfgwA2Fg8lTdUzVIRKMfU%3D" rel="nofollow" target="_blank">mdnice</a>多平台发布</p>]]></description></item><item>    <title><![CDATA[喜报｜矩阵起源获InfoQ极客传媒2025年度技术生态构建品牌奖 MatrixOrigin ]]></title>    <link>https://segmentfault.com/a/1190000047560012</link>    <guid>https://segmentfault.com/a/1190000047560012</guid>    <pubDate>2026-01-23 10:05:52</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>1月21日，以“超越泡沫，开始构建”为主题的2026极客科技伙伴时刻圆满结束，该活动是极客邦科技一年一度的保留节目，旨在表彰过去一年中为技术生态发展与建设贡献突出力量的企业、团队和个人。</p><p>其中，矩阵起源凭借其在技术生态的深耕，获“2025年度技术生态构建品牌奖”。矩阵起源的坚持，让生态更具韧性与温度，为产业注入生生不息的动能。</p><p><img width="723" height="1305" referrerpolicy="no-referrer" src="/img/bVdnIGY" alt="" title=""/></p><p>作为行业的中坚力量，矩阵起源深知，生态建设的终局不是“独行”，而是“共赢”。这一奖项的背后，是我们专注连接开发者、用户与合作伙伴，推动技术普惠与可持续增长的坚定行动。面向未来，矩阵起源将继续秉持“构建者”的初心，在技术生态的深水区持续探索。我们希望通过更务实的行动与更开放的姿态，携手每一位生态伙伴，共同穿越周期，构建一个安全、高效、且充满活力的技术新生态。</p>]]></description></item><item>    <title><![CDATA[矩阵起源荣获 DataFun 星空奖双项大奖 | 科技领航，打造企业级数据智能新基建 MatrixO]]></title>    <link>https://segmentfault.com/a/1190000047560018</link>    <guid>https://segmentfault.com/a/1190000047560018</guid>    <pubDate>2026-01-23 10:04:53</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>1 月 16 日，在北京中关村展示中心会议中心举办的 DataFun 第三届 “星空奖” 颁奖现场，<strong>矩阵起源（Matrix Origin）</strong>凭借在数据智能基础设施领域的持续耕耘与实际应用成效，<strong>一举获评两项年度荣誉</strong>：「年度科技创新突破奖（Data + AI）」、「年度科技领航企业」。</p><h2>01 回归数据本质，解决 AI 落地“最后一公里”</h2><p>在企业智能化转型进入深水区的当下，AI 落地的核心挑战并非模型能力的匮乏，而是私域数据质量与处理链路的割裂。本次获评「年度科技创新突破奖（Data + AI）」的 MatrixOne Intelligence (MOI)，旨在为企业提供一套可控、可信的数据智能解决方案。</p><p>针对奖项关注的 “数据割裂” 与 “预测偏差” 等行业痛点，MOI 通过其超融合架构提供了务实的解决思路：</p><ul><li>统一数据底座：面对企业内部结构化与非结构化数据分散的现状，MOI 基于核心引擎 MatrixOne 的湖仓一体能力，实现了多模态数据的一站式存储与管理，避免了多套系统堆砌带来的运维复杂性与数据一致性风险。</li><li>工程化智能链路：MOI 将 AI 能力内嵌至数据处理全流程（MatrixPipeline）。通过向量化检索和前沿技术，有效提升了 RAG（检索增强生成）的召回准确率，从数据源头抑制大模型“幻觉”，确保输出结果通过企业合规风控标准。</li><li>闭环反馈机制：系统支持“数据 - 应用”的双向反馈，使模型能够随着业务数据的积累持续迭代，保障了系统在生产环境中的长期稳定性与可用性。</li></ul><p><img width="723" height="1035" referrerpolicy="no-referrer" src="/img/bVdnIHd" alt="" title=""/></p><h2>02 聚焦真实价值，做企业可信赖的合作伙伴</h2><p>唯有经得起真实业务场景检验的技术，才具备长久的生命力。</p><p>获评「年度科技领航企业」，是对矩阵起源在自主知识产权积累、产品成熟度及客户服务能力上的综合评价。面对金融、制造、医疗等行业对数据安全与业务连续性的严苛要求，矩阵起源始终坚持以客户价值为导向。</p><p>目前，我们的解决方案已在多个关键行业完成了落地验证：在医疗领域，我们协助三甲医院构建高精度对话与辅助诊断模型，显著提升 IBS 的初诊效率与诊断准确性；在高端制造领域，我们帮助企业优化供应链决策流程，大幅提升标书制作与合规校验效率……</p><p>这些一线场景的实践成果，不仅印证了产品的高可用性，也是我们致力于成为企业构建数智化能力坚实基石的有力证明。</p><p><img width="723" height="1035" referrerpolicy="no-referrer" src="/img/bVdnIHc" alt="" title="" loading="lazy"/></p><h2>03 结语</h2><p>行业专家的专业认可、客户的长期信赖，是我们持续成长的动力。面向未来，我们将继续秉持初心，打磨产品内核，优化服务体系。我们希望通过务实的技术创新，携手生态伙伴，协助更多企业解决数据难题，构建安全、高效、可持续演进的智能化体系。</p>]]></description></item><item>    <title><![CDATA[【k8s部署】麒麟V10离线安装k8s1.32.11 天行1st ]]></title>    <link>https://segmentfault.com/a/1190000047560120</link>    <guid>https://segmentfault.com/a/1190000047560120</guid>    <pubDate>2026-01-23 10:03:55</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>本文以<code>麒麟V10</code>为例，演示超简单离线部署<code>k8s 1.32.11</code>。</p><h2>1 说明</h2><h3>关于kt</h3><p><code>kt</code>是基于<code>kk</code>二次开发产物，具备<code>kk</code>的所有功能，二开重点适配了信创国产化环境。</p><p>主要改进包括：简化<code>arm</code>架构部署过程、支持国产化和国际环境在线、离线部署及<code>一条命令所有节点初始化</code>。</p><p>支持<code>arm64</code>和<code>amd64</code>架构操作系统，已适配芯片+操作系统 如下：</p><ul><li><strong>CPU：</strong> 鲲鹏、飞腾、海光、兆芯、intel、amd 等。</li><li><strong>OS：</strong> Centos、Ubuntu、Debian、银河麒麟V10、麒麟国防版、麒麟信安、中标麒麟V7、统信UOS、华为欧拉、移动大云、阿里龙蜥、TencentOS等。</li></ul><p>注：本文使用kt版本<code>3.1.13</code></p><ul><li><strong>kt文档：</strong> <a href="https://link.segmentfault.com/?enc=uKMTAG%2BAyTf7HEqP%2FM6v7Q%3D%3D.s2jP840NJGp0f9F3QZko1ycNg3G1iXIYUvldB6N8cR0%3D" rel="nofollow" title="kt文档" target="_blank">kt文档</a></li></ul><h2>2.环境准备</h2><p><strong>服务器基本信息</strong></p><table><thead><tr><th><strong>主机名</strong></th><th><strong>架构</strong></th><th><strong>OS</strong></th><th><strong>配置</strong></th><th><strong>IP</strong></th></tr></thead><tbody><tr><td>master</td><td>x86_64</td><td>麒麟V10</td><td>2核4G</td><td>192.168.85.153</td></tr></tbody></table><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560123" alt="" title=""/></p><h3>2.1 上传离线制品</h3><p>操作系统不需要安装docker,不需要设置selinux,swap等操作，全新的操作系统即可。</p><p>将离线制品、配置文件、kt和sh脚本上传至服务器其中一个节点(本文以master为例)，后续在该节点操作创建集群。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560124" alt="" title="" loading="lazy"/></p><h3>2.2 修改配置文件</h3><p>根据实际服务器信息，配置到生成的<code>config-sample.yaml</code>中</p><pre><code class="plain">kind: Cluster
metadata:
  name: sample
spec:
  hosts:
  - {name: master, address: 192.168.85.160, internalAddress: 192.168.85.143, user: root, password: "123123"}
  roleGroups:
    etcd:
    - master
    control-plane:
    - master
    worker:
    - master
    # 如需使用 kk 自动部署镜像仓库，请设置该主机组 （建议仓库与集群分离部署，减少相互影响）
    # 如果需要部署 harbor 并且 containerManager 为 containerd 时，由于部署 harbor 依赖 docker，建议单独节点部署 harbor
    registry:
    - master
  controlPlaneEndpoint:
    ## Internal loadbalancer for apiservers 
    internalLoadbalancer: haproxy

    domain: lb.kubesphere.local
    address: ""
    port: 6443
  kubernetes:
    version: v1.32.11
    clusterName: cluster.local
    autoRenewCerts: true
    containerManager: docker
  etcd:
    type: kubekey
  network:
    plugin: calico
    kubePodsCIDR: 10.233.64.0/18
    kubeServiceCIDR: 10.233.0.0/18
    ## multus support. https://github.com/k8snetworkplumbingwg/multus-cni
    multusCNI:
      enabled: false
  registry:
    type: harbor
    registryMirrors: []
    insecureRegistries: []
    privateRegistry: "dockerhub.kubekey.local"
    namespaceOverride: "kubesphereio"
    auths: # if docker add by `docker login`, if containerd append to `/etc/containerd/config.toml`
      "dockerhub.kubekey.local":
        username: "admin"
        password: Harbor@123 # 此处可自定义，kk3.1.8新特性
        skipTLSVerify: true # Allow contacting registries over HTTPS with failed TLS verification.
        plainHTTP: false # Allow contacting registries over HTTP.
        certsPath: "/etc/docker/certs.d/dockerhub.kubekey.local"
  addons: []</code></pre><h2>2.3 系统初始化</h2><p>解压<code>kt-x86.tar.gz</code>文件后执行<code>./kt init-os -f config-sample.yaml</code> 已适配操作系统和架构见<code>1.说明</code></p><p>该命令<code>kt</code>会根据配置文件自动判断操作系统和架构以完成所有节点的初始化配置和依赖安装。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560125" alt="" title="" loading="lazy"/></p><h2>3 创建 Harbor私有仓库</h2><h3>3.1 创建镜像仓库</h3><pre><code class="plain">./kt init registry -f config-sample.yaml -a artifact-x86-k8s13211.tar.gz</code></pre><p>此命令会在<code>harbor</code>节点自动安装<code>docker</code>和<code>docker-compose</code></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560126" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560127" alt="" title="" loading="lazy"/></p><h3>3.2 创建harbor项目</h3><p>创建 Harbor 项目</p><pre><code class="plain">chmod +x create_project_harbor.sh &amp;&amp; ./create_project_harbor.sh</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560128" alt="" title="" loading="lazy"/></p><h2>4 创建k8s</h2><pre><code class="plain">./kt create cluster -f config-sample.yaml -a artifact-x86-k8s13211.tar.gz --with-local-storage</code></pre><p>此命令<code>kt</code>会自动将离线制品中的镜像推送到<code>harbor</code> 私有仓库</p><p>执行后会有如下提示,输入<code>yes/y</code>继续执行</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560129" alt="" title="" loading="lazy"/></p><p>继续等待一段时间最终可以看到安装成功的消息</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560130" alt="" title="" loading="lazy"/></p><p>验证</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560131" alt="" title="" loading="lazy"/></p><h2>5 总结</h2><p>本文主要以离线方式部署，适用于在线和离线两种状态，而如果在线状态，那么步骤3可忽略，两条命令即可搞定。</p><p>配合最新版kt，系统初始化从未如此简单，不论<code>x86</code>还是<code>arm</code>，不论在线还是离线，不论国际还是国产操作系统，统统搞定。</p>]]></description></item><item>    <title><![CDATA[玩转OurBMC第二十七期：BMC POST CODE解读 OurBMC ]]></title>    <link>https://segmentfault.com/a/1190000047560165</link>    <guid>https://segmentfault.com/a/1190000047560165</guid>    <pubDate>2026-01-23 10:03:04</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>【栏目介绍：“玩转OurBMC” 是OurBMC社区开创的知识分享类栏目，主要聚焦于社区和BMC全栈技术相关基础知识的分享，全方位涵盖了从理论原理到实践操作的知识传递。OurBMC社区将通过 “玩转OurBMC” 栏目，帮助开发者们深入了解到社区文化、理念及特色，增进开发者对BMC全栈技术的理解。</p><p>欢迎各位关注 “玩转OurBMC” 栏目，共同探索OurBMC社区的精彩世界。同时，我们诚挚地邀请各位开发者向 “玩转OurBMC” 栏目投稿，共同学习进步，将栏目打造成为汇聚智慧、激发创意的知识园地。】</p><p><strong>Power-On Self-Test Code(上电自检代码)是计算机系统在启动过程中执行硬件诊断和初始化的关键技术机制｡该技术通过两位十六进制代码实时反映系统固件对各个硬件组件的检测状态,为系统启动提供可视化的进度指示和故障定位能力｡</strong></p><h2>01 POST 流程与UEFI 启动的融合演进</h2><h3>01 传统POST自检流程</h3><p>传统POST自检流程已经被嵌入现代UEFI启动框架中,其执行链路可分为以下五层次阶段:</p><p><strong>阶段1：处理器与芯片组初始化</strong></p><ul><li>电源序列验证与稳定监控</li><li>CPU核心复位与微码加载</li><li>时钟网络同步校准</li><li>温度监控传感器初始化</li></ul><p><strong>阶段2：内存子系统检测</strong></p><ul><li>DIMM模块识别与SPD数据读取</li><li>内存控制器配置与训练</li><li>信号完整性优化（读写时序校准）</li><li>ECC功能验证与内存测试</li></ul><p><strong>阶段3：基础输入输出系统初始化</strong></p><ul><li>芯片组功能单元配置</li><li>PCIe根复合体与端口初始化</li><li>集成外设控制器（SATA、USB）启用</li></ul><p><strong>阶段4：扩展设备枚举</strong></p><ul><li>PCIe拓扑扫描与资源分配</li><li>选项ROM加载与认证</li><li>设备驱动初始化</li></ul><p><strong>阶段5：引导加载程序执行</strong></p><ul><li>启动设备选择与初始化</li><li>操作系统加载器验证</li><li>系统控制权转移</li></ul><p>其完整执行路径可通过以下流程图展示</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560167" alt="92869296e9dd2e127ce5386e80a488ce.png" title="92869296e9dd2e127ce5386e80a488ce.png"/></p><p>图1 上电自检流程图</p><h3>02 UEFI启动框架中的POST映射</h3><p><strong>SEC（安全验证）阶段</strong></p><ul><li>UEFI流程：这是芯片上电后第一个执行的阶段，负责处理CPU复位、初始化微码、进入受保护模式，并验证下一阶段代码的完整性。</li><li>对应的POST任务：这相当于最早期的、内存尚未初始化前的POST，主要完成CPU的初步初始化。此时会生成早期的POST Code。</li></ul><p><strong>PEI（EFI前初始化）阶段</strong></p><ul><li>UEFI流程：此阶段内存尚未可用或正在被初始化，因此代码在缓存中运行。它的核心任务是初始化内存控制器和内存（Memory Reference Code, MRC）。</li><li>对应的POST任务：这是POST最核心、最耗时的部分。内存的检测、训练（Training）、配置都在此完成。此时会生成关键的POST Code。BMC密切监控这一阶段。</li></ul><p><strong>DXE（驱动执行环境）阶段</strong></p><ul><li>UEFI流程：内存可用后，进入此阶段。DXE调度程序会加载并执行大量的驱动程序（DXE Driver），来初始化所有其他硬件，如芯片组、PCIe总线、存储控制器、网络接口等。</li><li>对应的POST任务：这相当于传统的芯片组初始化、PCIe设备枚举、选项ROM加载等POST任务。每个DXE驱动程序的成功加载和执行，都可能对应一个或多个POST Code。</li></ul><p><strong>操作系统加载器执行</strong></p><ul><li>UEFI流程：所有硬件就绪后，UEFI固件通过Boot Manager选择并启动操作系统的加载器（如GRUB， Windows Boot Manager）。</li><li>对应的POST任务：传统上，这被认为是POST的结束，系统控制权移交给操作系统。通过发送对应POST命令告诉BMC操作系统已经被引导。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560168" alt="069a3c6ee7eb1688b063b3d5f04afcea.jpg" title="069a3c6ee7eb1688b063b3d5f04afcea.jpg" loading="lazy"/></p><p>图2 UEFI启动流程图</p><p> 注：上图引用&lt; UEFI Platform Initialization Specification, Release 1.9&gt;</p><h2>02 关键技术机制深度解析</h2><h3>01 传输机制</h3><p>硬件层面实现: POST Code通过专用的80h端口（传统架构）或内存映射I/O（现代架构）进行传输。</p><h3>02 智能错误处理与恢复策略</h3><p><strong>分级错误管理</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560169" alt="image.png" title="image.png" loading="lazy"/></p><p><strong>高级诊断功能：</strong></p><ul><li>模式识别：通过代码序列模式预测潜在故障</li><li>性能分析：基于时间戳的启动性能优化</li><li>趋势预测：长期代码统计分析预测硬件寿命</li></ul><h3>03 BMC联动与可视化监控</h3><p>硬件上BMC通过PCIe、eSPI、LPC等总线与主机连接。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560170" alt="09134090d8edd87292e9e2550a197746.png" title="09134090d8edd87292e9e2550a197746.png" loading="lazy"/></p><p>图3 硬件连接图</p><p><strong>BMC可实时捕获并解码服务器发送的POST Code流，实现：</strong></p><ul><li>状态可视化：在Web界面或CLI中实时显示启动进度</li><li>故障告警：根据错误等级提供声光、日志、通知等多级提示</li><li>远程诊断：支持运维人员远程查看启动状态，辅助快速定位问题</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560171" alt="5fe3822e1d45146e7362b14d35fa435c.png" title="5fe3822e1d45146e7362b14d35fa435c.png" loading="lazy"/></p><p>图4 信息交互图</p><p><strong>03 技术优势与价值体现</strong></p><p><strong>运维效率提升</strong></p><ul><li>故障定位时间减少</li><li>平均修复时间(MTTR)降低</li><li>首次修复成功率提升</li></ul><p><strong>系统可靠性增强</strong></p><ul><li>预防性维护覆盖率提升</li><li>硬件故障提前预警</li><li>系统可用性达到提高</li></ul><p><strong>运维成本优化</strong></p><ul><li>减少现场服务需求</li><li>降低备件库存成本</li><li>延长设备使用寿命</li></ul><p><strong>欢迎大家关注OurBMC社区，了解更多BMC技术干货。</strong></p><p><strong>OurBMC社区官方网站：</strong></p><p><a href="https://link.segmentfault.com/?enc=hUsdXlpwhmLy%2Bxt2ZopTkg%3D%3D.ykV%2Bh934hZBSPlJMO9wrPYZQ0JfAxk541VF3VAW5cLM%3D" rel="nofollow" target="_blank">https://www.ourbmc.cn/</a></p>]]></description></item><item>    <title><![CDATA[网站被提示“不安全”怎么解决 才高八斗的杯子_dS2Fpp ]]></title>    <link>https://segmentfault.com/a/1190000047560187</link>    <guid>https://segmentfault.com/a/1190000047560187</guid>    <pubDate>2026-01-23 10:02:16</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>当用浏览器访问某个网站时，如果浏览器显示“不安全”警告，这往往会立即引起用户的警惕，还可能会流失客户。</p><h4><strong>一、网站被提示“不安全”的原因</strong></h4><h5>1. 证书自身问题（最常见）</h5><ul><li><strong>已过期</strong>：证书有明确的有效期（通常为1年，最长为13个月）。过期后，“门锁”自动失效，需要续期。</li><li><strong>域名不匹配</strong>：证书是为 <code>www.example.com</code> 签发，但你访问的是 <code>example.com</code> 或 <code>shop.example.com</code>。这是配置时的常见疏忽。</li><li><strong>签发机构不受信任</strong>：证书并非来自浏览器和操作系统信任的根证书列表中的CA。一些自签名证书或企业内部CA签发的证书会触发此警告。</li></ul><h5>2. 服务器配置问题</h5><ul><li><strong>证书链不完整</strong>：服务器没有正确安装中间证书，导致浏览器无法验证证书的完整信任链。</li><li><strong>使用了不安全的加密协议</strong>：服务器仍支持已被废弃的弱加密算法（如SSL 2.0/3.0， TLS 1.0）。</li></ul><h5>3. 网络环境问题（最危险）</h5><ul><li><strong>中间人攻击</strong>：你所在的网络（如公共Wi-Fi）可能存在恶意攻击者，他试图在你和目标网站之间插入自己的伪证书，以窃取你的数据。浏览器发现证书被篡改或无法验证，会发出强烈警告。</li></ul><p><img width="723" height="286" referrerpolicy="no-referrer" src="/img/bVdnIJW" alt="" title=""/></p><h4><strong>二、解决方案如下</strong></h4><h3><a href="https://link.segmentfault.com/?enc=mbEI1ILT%2Bx4Usmh3oPSEcg%3D%3D.9ot18jHlff1nyqk3VhXgs0ZLfKZff8J9sstx0Wm1tGrOXQA%2BEGm2qdIbCNV%2FZGHRSSXMAvQl2snlCCyBp7m46g%3D%3D" rel="nofollow" target="_blank"><strong>免费SSL证书申请入口</strong></a></h3><p><strong>1.访问JoySSL官网并注册账号</strong></p><p>首先，登录<strong>JoySSL</strong>的官方网站，并注册一个账号。在注册过程中，务必填写特定的<strong>230970</strong>注册码才获取免费SSL证书的申请权限。</p><p><strong>2.选择证书类型</strong></p><p>登录JoySSL账号后，根据您的需求选择适合的SSL证书并0元下单支付。</p><p><strong>3.填写申请信息</strong></p><p>按照页面提示填写申请信息，包括域名信息、联系信息等。</p><p><strong>4.验证域名所有权</strong></p><p>完成信息填写后，JoySSL将要求您验证域名所有权。这通常通过域名DNS验证或服务器文件验证方式来完成。</p><p><strong>5. 部署证书</strong></p><p>验证后，10分钟左右签发，签发后，下载证书文件，将其部署到相应服务器上。</p><p><strong>6. 测试证书</strong></p><p>访问网站，检查是否实现HTTPS访问以及地址栏上有绿色的安全锁。</p>]]></description></item><item>    <title><![CDATA[《ESP32-S3使用指南—IDF版 V1.6》第六十四章 LVGL 综合例程 正点原子 ]]></title>    <link>https://segmentfault.com/a/1190000047560189</link>    <guid>https://segmentfault.com/a/1190000047560189</guid>    <pubDate>2026-01-23 10:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>第六十四章 LVGL 综合例程</h2><p>本章，简单的介绍一下DNESP32S3开发板的 LVGL 综合例程。需要说明一下的是：本例程是一个不完整的例程。因为该例程只是实现一个基于 LVGL 的 GUI 界面，里面的 APP<br/>基本没有实现功能，所以这只是给大家参考的 GUI demo。<br/>实现这样简单的 GUI demo 原因如下：<br/>1， 板载的2.4寸TFTLCD并未具备触摸条件，所以设计UI时受到很大的制约。<br/>2， 想做出一个 LVGL 综合例程给大家参考，但时间比较赶。<br/>3， 要实现一个不错的 LVGL 综合例程，要花费不少精力。<br/>4， 要考虑板载资源，兼容性等。<br/>5， 工程师们手头的事情比较多，等后续空闲些再规划。<br/>大家可以把自己期待的 LVGL 界面、功能等，通过各种渠道跟我们沟通，比如：B 站视频评论区，销售客户/技术支持等。后续有时间，我们会把大家的建议都考虑上去的。最后，敬请大家心怀一个小小的期待，期待正点原子的 LVGL 综合例程，感谢大家的支持！！！<br/>本章将分为如下 2 个小节：</p><p>64.1 LVGL 综合例程注意事项<br/>64.2 LVGL 综合例程界面展示</p><h3>64.1 LVGL 综合例程注意事项</h3><p>注意事项如下：<br/>1，DNESP32S3开发板的LVGL综合例程只支持正点原子的2.4寸 TFTLCD屏。其它屏幕会出现图标显示异常。<br/>2，所用的LVGL版本是V8.2。<br/>3，需要准备一张TF卡，将A盘资料的SD卡根目录文件复制到TF卡根目录当中，SD卡根目录文件如下图所示。<br/><img width="387" height="171" referrerpolicy="no-referrer" src="/img/bVdnGNo" alt="" title=""/><br/>图64.1.1 拷贝资料到TF卡当中<br/>图64.1.2展示的是LVGL例程界面所用到的 bin 文件。LVGL 综合例程会将这些bin文件拷贝到16MB Flash分区表的storage子分区表备份，方便GUI界面读取。如果直接从TF卡中读取，速度会比较慢，影响 GUI 的流畅性。<br/><img width="485" height="272" referrerpolicy="no-referrer" src="/img/bVdnGNp" alt="" title="" loading="lazy"/><br/>图 64.1.2 LVGL例程界面所用到的bin文件</p><h3>64.2 LVGL 综合例程界面展示</h3><p><img width="723" height="386" referrerpolicy="no-referrer" src="/img/bVdnGNq" alt="" title="" loading="lazy"/><br/>图64.2.1 GUI主界面和视频播放器界面<br/><img width="723" height="387" referrerpolicy="no-referrer" src="/img/bVdnGNr" alt="" title="" loading="lazy"/><br/>图64.2.2 图片浏览界面和计算机界面<br/>由于DNESP32S3开发板的2.4寸TFTLCD显示屏未具备触摸条件，所以作者只能实现一些简单的APP应用。</p>]]></description></item><item>    <title><![CDATA[Skills 与延迟加载工具定义的 MCP，目前哪个更高效、稳定和可控？ Baihai_IDP ]]></title>    <link>https://segmentfault.com/a/1190000047560110</link>    <guid>https://segmentfault.com/a/1190000047560110</guid>    <pubDate>2026-01-23 09:01:59</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <blockquote><p><strong>编者按：</strong> 我们今天为大家带来的这篇文章，作者的核心观点是：相较于依赖复杂且高成本的动态 MCP 工具加载机制，以 Skills 为核心的能力摘要与自维护模式，在当前阶段反而更加高效、稳定且可控。</p><p>文章系统梳理了延迟工具加载（deferred tool loading）的工程现实与限制，指出即便工具可以延后注入，对话级别的工具集合仍然是静态的，且发现机制高度依赖正则匹配，收益并不如预期。作者进一步深入分析了 MCP 在上下文占用、API 稳定性、缓存失效与推理轨迹丢失等方面带来的隐性成本，并结合 Sentry MCP、Playwright 等实践案例，说明为何将 MCP 转换为 Skills，反而能让 Agent 更好地发挥既有工具的能力。文章最后还探讨了 MCP 是否可能完全转化为 Skills 的可行性，并坦率指出当前协议与生态在稳定性与摘要机制上的不足。</p></blockquote><p><strong>作者 |</strong> <strong>Armin Ronacher</strong></p><p><strong>(作者为 Flask、Jinja2 等开源项目的创建者)</strong></p><p><strong>编译 | 岳扬</strong></p><p>我正把所有的 MCP 都迁移到 Skills 上，包括之前还在使用的最后一个：Sentry MCP（译者注：Sentry 是流行的应用监控与错误追踪平台）。早前我就已经完全弃用 Playwright（译者注：由 Microsoft 开发的现代 Web 自动化测试和浏览器自动化框架），转向使用 Playwright Skill。</p><p>过去一个月左右，关于使用“动态工具配置（dynamic tool loadouts）[1]”来推迟工具定义的加载的讨论一直不少。Anthropic 也在探索通过代码来串联 MCP 调用的思路，这一点我也尝试过[2]。</p><p>我想分享一下自己在这方面的最新心得，以及为什么 Anthropic 提出的“延迟工具加载方案（deferred tool loading）”并未改变我对 MCP 的看法。或许这些内容对他人会有所帮助。</p><h2><strong>01 什么是工具（Tool）？</strong></h2><p>当 Agent 通过强化学习或其他方式接触到工具定义时，它会被鼓励在遇到适合使用该工具的场景时，通过特殊的 token 输出工具调用。实际上，工具定义只能出现在系统提示词（system prompt）中特定的工具定义 token 之间。从历史经验来看，这意味着我们无法在对话状态的中途动态发出新的工具定义。因此，唯一的现实选择是在对话开始时就将工具加载好。</p><p>在智能体应用场景中，我们当然可以随时压缩对话状态，或更改系统消息中的工具定义。但这样做的后果是，我们会丢失推理轨迹（reasoning traces）以及缓存（cache）。以 Anthropic 为例，这将大幅增加对话成本：基本上就是从头开始，相比于缓存读取，需要支付完整的 token 费用，外加缓存写入成本。</p><p>Anthropic 最近的一项创新是“延迟工具加载”（deferred tool loading）。我们仍然需要提前在系统提示词（system message）中声明工具，但这些工具不会在系统提示词发出时就注入到对话中，而是会稍后才出现。不过据我所知，<strong>这些工具定义在整个对话过程中仍必须是静态的 —— 也就是说，哪些工具可能存在，是在对话开始时就确定好的。</strong> Anthropic 发现这些工具的方式，纯粹是通过正则表达式（regex）搜索实现的。</p><h2><strong>02 与 Skills 的对比</strong></h2><p>尽管带延迟加载的 MCP 感觉上应该表现更优，实际上却需要在 LLM API 端做不少工程化工作。而 Skills 系统完全不需要这些，至少从我的经验来看，其表现依然更胜一筹。</p><p><strong>Skills 实质上只是对现有能力及其说明文件位置的简短摘要。这些信息会被主动加载到上下文中。</strong> 因此，智能体能在系统上下文里（或上下文的其他位置）知晓自己具备哪些能力，并获知如何使用这些能力的“手册链接”。</p><p>关键在于，<strong>Skills 并不会真正把工具定义加载到上下文中。</strong> 可用工具保持不变：bash 以及智能体已有的其他工具。Skills 所能提供的，只是如何更高效使用这些工具的技巧和方法。</p><p>由于 Skills 主要教的是如何使用其他命令行工具和类似实用程序，因此组合与协调这些工具的基本方式其实并未改变。让 Claude 系列模型成为优秀工具调用者的强化学习机制，恰好能帮助处理这些新发现的工具。</p><h2><strong>03 MCP 能否转换为 Skills？</strong></h2><p>这自然引出了一个问题：既然 Skills 效果这么好，我能不能把 MCP 完全移出上下文，转而像 Anthropic 提议的那样，通过 CLI 来调用它？答案是：可以，但效果并不好。Peter Steinberger 的 mcporter[3] 就是其中一种方案。简单来说，它会读取 .mcp.json 文件，并将背后的 MCP 暴露为可调用的工具：</p><pre><code>npx mcporter call 'linear.create_comment(issueId: "ENG-123", body: "Looks good!")'</code></pre><p>确实，它看起来非常像一个 LLM 可以调用的命令行工具。但问题在于，LLM 根本不知道有哪些工具可用 —— 现在你得专门教它。于是你可能会想：那为什么不创建一些 Skills，来教 LLM 了解这些 MCP 呢？对我而言，这里的问题在于：<strong>MCP 服务器根本没有维持 API 稳定性的意愿。它们越来越倾向于将工具定义精简到极致，只为节省 token。</strong> 这种做法有其道理，但对 Skills 模式来说却适得其反。举个例子，Sentry MCP 服务器曾彻底将查询语法切换为自然语言。这对 Agent 来说是一次重大改进，但我之前关于如何使用它的建议反而成了障碍，而且我没能第一时间发现问题。</p><p>这其实和 Anthropic 的“延迟工具加载方案”非常相似：上下文中完全没有任何关于该工具的信息，我们必须手动创建一份摘要。我们过去对 MCP 工具采用的预加载（eager loading）方式，如今陷入了一个尴尬的局面：<strong>描述既太长，不便预加载；又太短，无法真正教会 Agent 如何使用它们。</strong> 因此，至少从我的经验来看，你最终还是得为通过 mcporter 或类似方式暴露出来的 MCP 工具，手动维护这些 Skills 摘要。</p><h2><strong>04 最省事的路线</strong></h2><p>这让我得出了目前的结论：<strong>我倾向于选择最省事的方式，也就是让 Agent 自己以“Skills”的形式编写所需的工具。</strong> 这样做不仅耗时不多，最大的好处还在于工具基本处于我的掌控之中。每当它出问题或需要新增功能时，我就让 Agent 去调整它。Sentry MCP 就是个很好的例子 —— 我认为它可能是目前设计得最好的 MCP 之一，但我已经不再使用它了。一方面是因为一旦在上下文中立即加载它，就会直接消耗约 8k 个 token；另一方面，我也一直没能通过 mcporter 让它正常工作。现在我让 Claude 为我维护一个对应的 Skill。没错，这个 Skill 可能有不少 bug，也需要不断更新，但由于是 Agent 自己维护的，整体效果反而更好。</p><p>当然，这一切很可能在未来发生变化。但就目前而言，手动维护的 Skills，以及让 Agent 自行编写工具，已成为我的首选方式。<strong>我推测，基于 MCP 的动态工具加载终将成为主流，但要实现这一点，可能还需要一系列协议层面的改进，以便引入类似 Skills 的摘要机制，以及为工具内置使用手册。</strong> 我也认为，MCP 如果能具备更强的协议稳定性，将大有裨益。目前 MCP 服务器随意更改工具描述的做法，与那些已经固化下来的调用方式（materialized calls）以及在 README 和技能文件中编写的外部工具说明很难兼容。</p><p><strong>END</strong></p><p><strong>本期互动内容 🍻</strong></p><p><strong>❓抛开现有方案，你理想中的AI工具调用范式应该长什么样？用一句话描述你最核心的需求。</strong></p><p><strong>文中链接</strong></p><p>[1]<a href="https://link.segmentfault.com/?enc=3Q00vCNgfa8RkZXzEqfaFg%3D%3D.U3r%2BxNvRWuGNK8stXMW6hK0IqrfJYgNfW9itRWy65WhvmBtFMtAtPuUkqXexAkVott3pptaRqPlBLJov%2Btkg%2BQ%3D%3D" rel="nofollow" target="_blank">https://www.anthropic.com/engineering/advanced-tool-use</a></p><p>[2]<a href="https://link.segmentfault.com/?enc=2kldzHxYidNBCnZu%2F4Y2vg%3D%3D.HH1ihPnnBdQQX8NtsKc2pUl3nx%2FhGklIu5sMNVe4v080RVLA36H33JR%2Bg5Oqjrr2" rel="nofollow" target="_blank">https://lucumr.pocoo.org/2025/7/3/tools/</a></p><p>[3]<a href="https://link.segmentfault.com/?enc=qM1I5KSJ9%2BAxBbQn2k%2F5HQ%3D%3D.0NA6YgE1dGXj2XkNqoknLGwHjM69TB%2F135KnfWR20sirpzd392R6Y7vqb2d6qNUh" rel="nofollow" target="_blank">https://github.com/steipete/mcporter</a></p><p><strong>原文链接：</strong>  </p><p><a href="https://link.segmentfault.com/?enc=q6YWdsWWLDCuxeyCdsOtwA%3D%3D.Kqr%2BcMdvJkiSB9fsx17%2Bpv61u7CyeaGoG5BNUZEwyDIwnMnT2LDPQYfiZjcOOeLkx4ADAlaFqrdWalUuyvBPgg%3D%3D" rel="nofollow" target="_blank">https://lucumr.pocoo.org/2025/12/13/skills-vs-mcp/</a></p>]]></description></item><item>    <title><![CDATA[Queue & Stack：实现机制与使用场景深度分析 SevenCoding ]]></title>    <link>https://segmentfault.com/a/1190000047548938</link>    <guid>https://segmentfault.com/a/1190000047548938</guid>    <pubDate>2026-01-23 09:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>为什么不推荐使用Stack</h2><p>Java已不推荐使用Stack，而是推荐使用更高效的ArrayDeque</p><h3>为什么不推荐使用</h3><ul><li>性能低：是因为 Stack 继承自 Vector， 而 Vector 在每个方法中都加了锁。由于需要兼容老的项目，很难在原有的基础上进行优化，因此 Vector 就被淘汰掉了，使用 <a href="https://link.segmentfault.com/?enc=7FS5CaWT2i440DsKjQVwgw%3D%3D.TU%2F4IAs%2FycQnKu8yLN%2BGM509fA8ycAERlHGRxVGHZ0kznv3ptDbITUbl%2BCdZ8O50r0DGtPLfn4CgBtyHpNL4IDUFgspUhoxpNTGBd7O6Flw%3D" rel="nofollow" target="_blank">ArrayList</a> 和 <a href="https://link.segmentfault.com/?enc=y2oMYDwyRQ%2BJA0S0WlSZLg%3D%3D.4TboKl%2BSpGqPqKEDVAnhwn9ZFD89%2BLQ%2FwjQdIAsXWKbVEafdZ%2BTDAishwaTxlbvp6Te2ryh8Lnu7nYSS%2FHRGoSc%2B%2FmTL4kAwh4VIX8zLLs0%3D" rel="nofollow" target="_blank">CopyOnWriteArrayList</a> 来代替，如果在非线程安全的情况下可以使用  <a href="https://link.segmentfault.com/?enc=Kv8uR2P6BoSSfS0K49snYQ%3D%3D.e68eIRsFuESqL4lpRUWXAS5ZDKh5hNLskxDf%2FjjV1pGdgMaIEL2JvmoNRGcFyfLrs8%2FuDhLRsgNE%2F8M4siptbj1a6Z5%2FuVDrxfG%2FFt7tAnw%3D" rel="nofollow" target="_blank">ArrayList</a>，线程安全的情况下可以使用 <a href="https://link.segmentfault.com/?enc=hks1aQHfAHYbGEvy7DI5nQ%3D%3D.9gCzGzYHN7hMQVPTM4BkwdCpCU8QNIlDNMcLRQnaRxwrVI1EIDV5A8%2B75qVCNgqk2dx1oTcIKBgtZQHFVQAkWBajF98VBIkZf%2FhiwCXc8G4%3D" rel="nofollow" target="_blank">CopyOnWriteArrayList</a> 。</li><li>破坏了原有的数据结构：栈的定义是在一端进行 push 和 pop 操作，除此之外不应该包含其他 入栈和出栈 的方法，但是 Stack 继承自 Vector，使得 Stack 可以使用父类 Vector 公有的方法。</li></ul><h3>为什么现在还在用</h3><p>但是为什么还有很多人在使用 Stack。总结了一下主要有两个原因。</p><ul><li>JDK 官方是不推荐使用 Stack，之所以还有很多人在使用，是因为 JDK 并没有加 deprecation 注解，只是在文档和注释中声明不建议使用，但是很少有人会去关注其实现细节</li><li>在笔试面试需要做算法题的时候，更多关注点是在解决问题的算法逻辑思路上，并不会关注在不同语言下 Stack 实现细节，但是对于使用 Java 语言的业务开发者，不仅需要关注算法逻辑本身，也需要关注它的实现细节</li></ul><h3>为什么推荐使用 Deque 接口替换栈</h3><p>如果 JDK 不推荐使用 Stack，那应该使用什么集合类来替换栈，一起看看官方的文档。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000045396408" alt="" title=""/></p><p>正如图中标注部分所示，栈的相关操作应该由 Deque 接口来提供，推荐使用 Deque 这种数据结构， 以及它的子类，例如 ArrayDeque。</p><pre><code class="java">val stack: Deque&lt;Int&gt; = ArrayDeque()</code></pre><p>使用 Deque 接口来实现栈的功能有什么好处：</p><ul><li>速度比 Stack 快</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000045396409" alt="" title="" loading="lazy"/></p><p>这个类作为栈使用时可能比 Stack 快，作为队列使用时可能比 LinkedList 快。因为原来的 Java 的 Stack 继承自 Vector，而 Vector 在每个方法中都加了锁，而 Deque 的子类 ArrayDeque 并没有锁的开销。</p><ul><li>屏蔽掉无关的方法</li></ul><p>原来的 Java 的 Stack，包含了在任何位置添加或者删除元素的方法，这些不是栈应该有的方法，所以需要屏蔽掉这些无关的方法。声明为 Deque 接口可以解决这个问题，在接口中声明栈需要用到的方法，无需管子类是如何是实现的，对于上层使用者来说，只可以调用和栈相关的方法。</p><h3>Stack 和 ArrayDeque的 区别</h3><table><thead><tr><th>集合类型</th><th>数据结构</th><th>是否线程安全</th></tr></thead><tbody><tr><td>Stack</td><td>数组</td><td>是</td></tr><tr><td>ArrayDeque</td><td>数组</td><td>否</td></tr></tbody></table><p>Stack 常用的方法如下所示：</p><table><thead><tr><th>操作</th><th>方法</th></tr></thead><tbody><tr><td>入栈</td><td>push(E  item)</td></tr><tr><td>出栈</td><td>pop()</td></tr><tr><td>查看栈顶</td><td>peek() 为空时返回 null</td></tr></tbody></table><p>ArrayDeque 常用的方法如下所示：</p><table><thead><tr><th>操作</th><th>方法</th></tr></thead><tbody><tr><td>入栈</td><td>push(E  item)</td></tr><tr><td>出栈</td><td>poll() 栈为空时返回    nullpop() 栈为空时会抛出异常</td></tr><tr><td>查看栈顶</td><td>peek() 为空时返回 null</td></tr></tbody></table><h2>Queue介绍</h2><p>Java里有一个叫做Stack的类，却没有叫做Queue的类(它是个接口名字)。当需要使用栈时，Java已不推荐使用Stack，而是推荐使用更高效的ArrayDeque；既然Queue只是一个接口，当需要使用队列时也就首选ArrayDeque了(次选是LinkedList)。</p><h3>Queue</h3><p>Queue接口继承自Collection接口，除了最基本的Collection的方法之外，它还支持额外的insertion, extraction和inspection操作。这里有两组格式，共6个方法，一组是抛出异常的实现；另外一组是返回值的实现(没有则返回null)。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000045396410" alt="" title="" loading="lazy"/></p><h3>Deque</h3><p>Deque 是"double ended queue", 表示双向的队列，英文读作"deck". Deque 继承自 Queue接口，除了支持Queue的方法之外，还支持 insert , remove 和 examine操作，由于Deque是双向的，所以可以对队列的头和尾都进行操作，它同时也支持两组格式，一组是抛出异常的实现；另外一组是返回值的实现(没有则返回null)。共12个方法如下:</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000045396411" alt="" title="" loading="lazy"/></p><p>当把 Deque 当做FIFO的 queue 来使用时，元素是从 deque 的尾部添加，从头部进行删除的； 所以 deque 的部分方法是和 queue 是等同的。具体如下:</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000045396412" alt="" title="" loading="lazy"/></p><p>Deque的含义是“double ended queue”，即双端队列，它既可以当作栈使用，也可以当作队列使用。下表列出了Deque与Queue相对应的接口:</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000045396413" alt="" title="" loading="lazy"/></p><p>下表列出了Deque与Stack对应的接口:</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000045396414" alt="" title="" loading="lazy"/></p><p>上面两个表共定义了Deque的12个接口。添加，删除，取值都有两套接口，它们功能相同，区别是对失败情况的处理不同。一套接口遇到失败就会抛出异常，另一套遇到失败会返回特殊值( false 或 null )。除非某种实现对容量有限制，大多数情况下，添加操作是不会失败的。虽然Deque的接口有12个之多，但无非就是对容器的两端进行操作，或添加，或删除，或查看。</p><p>ArrayDeque和LinkedList是Deque的两个通用实现，由于官方更推荐使用AarryDeque用作栈和队列，加之上一篇已经讲解过LinkedList，本文将着重讲解ArrayDeque的具体实现</p><p>从名字可以看出ArrayDeque底层通过数组实现，为了满足可以同时在数组两端插入或删除元素的需求，该数组还必须是循环的，即循环数组(circular array)，也就是说数组的任何一点都可能被看作起点或者终点。ArrayDeque是非线程安全的(not thread-safe)，当多个线程同时使用的时候，需要程序员手动同步；另外，该容器不允许放入 null 元素。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000045396415" alt="" title="" loading="lazy"/></p><p>上图中我们看到， head 指向首端第一个有效元素， tail 指向尾端第一个可以插入元素的空位。因为是循环数组，所以 head 不一定总等于0， tail 也不一定总是比 head 大。</p><h2>方法剖析</h2><h3>addFirst()</h3><p>addFirst(E e)的作用是在Deque的首端插入元素，也就是在head的前面插入元素，在空间足够且下标没有越界的情况下，只需要将elements[--head] = e即可。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000045396416" alt="" title="" loading="lazy"/></p><p>实际需要考虑:</p><ol><li>空间是否够用</li><li>下标是否越界的问题</li></ol><p>上图中，如果head为0之后接着调用addFirst()，虽然空余空间还够用，但head为-1，下标越界了。</p><pre><code class="java">//addFirst(E e)
public void addFirst(E e) {
    if (e == null)//不允许放入null
        throw new NullPointerException();
    elements[head = (head - 1) &amp; (elements.length - 1)] = e;//2.下标是否越界
    if (head == tail)//1.空间是否够用
        doubleCapacity();//扩容
}</code></pre><p><strong>上述代码可以看到， 空间问题是在插入之后解决的；</strong>首先，因为tail总是指向下一个可插入的空位，也就意味着elements数组至少有一个空位，所以插入元素的时候不用考虑空间问题。</p><p>下标越界的处理解决起来非常简单，head = (head - 1) &amp; (elements.length - 1)就可以了，<strong>这段代码相当于取余，同时解决了head为负值的情况</strong>。因为elements.length必需是2的指数倍，elements - 1就是二进制低位全1，跟head - 1相与之后就起到了取模的作用，如果head - 1为负数(其实只可能是-1)，则相当于对其取相对于elements.length的补码。</p><blockquote><p>计算机里数值都是用补码表示的，如果是8位的，-1就是1111 1111，而 (elements.length - 1) 也是 1111 1111，因此两者相与也就是(elements.length - 1)；</p><p>head = (head - 1) &amp; (elements.length - 1) 最后再让算出的位置赋值给head，因此其实这段代码就是让head再从后往前赋值</p></blockquote><p>扩容函数doubleCapacity()，其逻辑是申请一个更大的数组(原数组的两倍)，然后将原数组复制过去。过程如下图所示:</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000045396417" alt="" title="" loading="lazy"/></p><p>图中可以看到，复制分两次进行，第一次复制head右边的元素，第二次复制head左边的元素。</p><pre><code class="java">//doubleCapacity()
private void doubleCapacity() {
    assert head == tail;
    int p = head;
    int n = elements.length;
    int r = n - p; // head右边元素的个数
    int newCapacity = n &lt;&lt; 1;//原空间的2倍
    if (newCapacity &lt; 0)
        throw new IllegalStateException("Sorry, deque too big");
    Object[] a = new Object[newCapacity];
    System.arraycopy(elements, p, a, 0, r);//复制右半部分，对应上图中绿色部分
    System.arraycopy(elements, 0, a, r, p);//复制左半部分，对应上图中灰色部分
    elements = (E[])a;
    head = 0;
    tail = n;
}</code></pre><h3>addLast()</h3><p>addLast(E e)的作用是在<strong>Deque</strong>的尾端插入元素，也就是在tail的位置插入元素，由于tail总是指向下一个可以插入的空位，因此只需要elements[tail] = e;即可。插入完成后再检查空间，如果空间已经用光，则调用doubleCapacity()进行扩容。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000045396418" alt="" title="" loading="lazy"/></p><pre><code class="java">public void addLast(E e) {
    if (e == null)//不允许放入null
        throw new NullPointerException();
    elements[tail] = e;//赋值
    if ( (tail = (tail + 1) &amp; (elements.length - 1)) == head)//下标越界处理
        doubleCapacity();//扩容
}</code></pre><h3>pollFirst()</h3><p>pollFirst()的作用是删除并返回<strong>Deque</strong>首端元素，也即是head位置处的元素。如果容器不空，只需要直接返回elements[head]即可，当然还需要处理下标的问题。由于ArrayDeque中不允许放入null，当elements[head] == null时，意味着容器为空。</p><pre><code class="java">public E pollFirst() {
    int h = head;
    E result = elements[head];
    if (result == null)//null值意味着deque为空
        return null;
    elements[h] = null;//let GC work
    head = (head + 1) &amp; (elements.length - 1);//下标越界处理
    return result;
}</code></pre><h3>pollLast()</h3><p>pollLast()的作用是删除并返回Deque尾端元素，也即是tail位置前面的那个元素。</p><pre><code class="java">public E pollLast() {
    int t = (tail - 1) &amp; (elements.length - 1);//tail的上一个位置是最后一个元素
    E result = elements[t];
    if (result == null)//null值意味着deque为空
        return null;
    elements[t] = null;//let GC work
    tail = t;
    return result;
}</code></pre><h3>peekFirst()</h3><p>peekFirst()的作用是返回但不删除<strong>Deque</strong>首端元素，也即是head位置处的元素，直接返回elements[head]即可。</p><pre><code class="java">public E peekFirst() {
    return elements[head]; // elements[head] is null if deque empty
}</code></pre><h3>peekLast()</h3><p>peekLast()的作用是返回但不删除<strong>Deque</strong>尾端元素，也即是tail位置前面的那个元素。</p><pre><code class="java">public E peekLast() {
    return elements[(tail - 1) &amp; (elements.length - 1)];
}</code></pre>]]></description></item><item>    <title><![CDATA[2026年供应商管理系统排名：6款热门产品深度测评 SaaS圈老马 ]]></title>    <link>https://segmentfault.com/a/1190000047559864</link>    <guid>https://segmentfault.com/a/1190000047559864</guid>    <pubDate>2026-01-23 08:01:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>对于很多企业来说，供应商管理一直是个“老大难”问题——信息散乱、沟通成本高、对账周期长、合作过程不透明。如果全靠Excel和微信来管理，效率低不说，还容易出错。因此，一套好用的<strong>供应商管理系统</strong>（SRM）成了企业数字化转型中的重要一环。</p><p>但市面上的相关产品五花八门，有标准化软件，也有定制化平台，到底该怎么选？今天，我们就结合市场反馈、产品功能和实际应用情况，为大家测评并排名当前较受关注的<strong>6款供应商管理系统</strong>，希望能给正在选型的你一些参考。</p><p><strong>1. 支道</strong></p><p><a href="https://link.segmentfault.com/?enc=OX3neY3BXei27MXYk9ftew%3D%3D.0FgVev3PCIPqnJLI48OLCSUuzpyoWsf8BYYOz1ooGEA%3D" rel="nofollow" target="_blank">https://www.zdsztech.com</a></p><p><strong>综合评分：★★★★★</strong>  </p><p><strong>定位：</strong> 无代码定制化SRM解决方案  </p><p><strong>适合企业：</strong> 成长型企业、多业务场景需求、追求灵活与性价比并重的公司</p><p>如果要说近几年在中小企业数字化领域口碑不错的平台，<strong>支道</strong> 肯定算一个。它并不是一个固定的“标准化SRM软件”，而是一个<strong>无代码业务搭建平台</strong>，供应商管理只是其能搭建的众多场景之一。</p><p><strong>为什么把它放在前面推荐？</strong></p><p>首先，它解决了一个核心痛点：<strong>企业需求总是在变</strong>。今天你可能只管采购比价，明天就需要供应商绩效评估，后天又希望和供应商在线协同订单。标准化软件往往很难跟上这种节奏，而支道让业务人员自己就能通过“拖拉拽”配置流程、表单和报表，快速搭建出贴合实际的管理应用。</p><p>从供应商管理具体功能上看，它覆盖了：</p><p><strong>供应商全生命周期管理</strong>：从准入、分类、评级到淘汰，形成电子档案。</p><p><strong>在线询比价与招标</strong>：流程在线化，比价更透明，支持自动生成比价单。</p><p><strong>订单协同与发货跟踪</strong>：供应商可通过门户查看订单、确认交期、更新发货状态，减少来回沟通。</p><p><strong>智能对账与绩效评估</strong>：自动汇总往来数据，内置评估模型，生成供应商绩效看板。</p><p><strong>内外协同便捷</strong>：支持通过链接、二维码等方式让供应商参与部分流程，无需对方额外安装系统。</p><p><strong>最大的优势在于“灵活”和“性价比”</strong>。它没有按功能模块收费，企业可以根据自身发展阶段，先搭建核心的供应商档案与询价功能，后续再逐步扩展绩效、协同等模块。同时支持公有云、私有化部署，成本比许多传统定制开发低不少。</p><p>很多使用它的企业反馈：“像是请了一个懂业务的开发团队，但不用养人。” 尤其适合那些业务独特、标准化软件无法满足，又担心定制开发成本高、周期长的企业。<br/><img width="723" height="293" referrerpolicy="no-referrer" src="/img/bVdnIEE" alt="" title=""/></p><p><strong>2. 金蝶</strong></p><p><strong>综合评分：★★★★☆</strong>  </p><p><strong>定位：</strong> 集成的ERP系统，SRM为其重要组成部分  </p><p><strong>适合企业：</strong> 已使用或计划使用金蝶ERP的中大型制造业、贸易企业</p><p>金蝶作为国内老牌企业管理软件厂商，其云产品 <strong>金蝶云·星空</strong> 中的供应链协同模块，提供了比较完善的SRM功能。如果你企业本身就用金蝶处理财务、进销存，那么用它来管理供应商，数据打通会非常顺畅。</p><p>它的供应商管理侧重于<strong>流程规范和业财一体化</strong>：</p><p><strong>与ERP深度集成</strong>：采购订单、入库单、应付账款自动关联，杜绝数据孤岛。</p><p><strong>供应商门户</strong>：供应商可自助维护信息、接收订单、确认送货单和发票，提升协同效率。</p><p><strong>招投标管理</strong>：支持线上招标流程，相对规范。</p><p><strong>质量管理协同</strong>：可与来料检验（IQC）流程关联。</p><p><strong>优势是体系成熟、财务衔接好</strong>，特别适合管理规范、对财务合规性要求高的大中型企业。<strong>不足</strong>是作为大型ERP的一部分，整体价格较高，且功能偏标准化，个性化调整需要二次开发，成本和周期都不低。<br/><img width="723" height="301" referrerpolicy="no-referrer" src="/img/bVdnIEF" alt="" title="" loading="lazy"/></p><p><strong>3. 用友</strong></p><p><strong>综合评分：★★★★☆</strong>  </p><p><strong>定位：</strong> 用友新一代云ERP的SRM解决方案  </p><p><strong>适合企业：</strong> 成长型创新企业、全链路数字化需求较强的公司</p><p>用友的 <strong>YonSuite</strong> 定位为“成长型企业的云ERP”，其供应商协同云是现代、轻量化的SRM方案。它强调社交化协同和用户体验，试图把复杂的供应商管理做得更“互联网化”一些。</p><p>主要功能亮点：</p><p><strong>社交化沟通协同</strong>：类似商务聊天界面，与供应商的沟通记录可关联业务单据。</p><p><strong>全流程线上化</strong>：从寻源、询报价、合同到送货、对账，都在一个平台完成。</p><p><strong>供应商风险监控</strong>：集成一些外部数据，对供应商经营风险进行预警。</p><p><strong>移动端应用友好</strong>：审核、沟通在手机上操作方便。</p><p><strong>优势在于产品设计较新，协同理念突出</strong>，适合喜欢轻便、敏捷操作模式的企业。但作为用友云生态的一部分，同样面临与外部系统深度集成时可能需要的定制工作。<br/><img width="723" height="320" referrerpolicy="no-referrer" src="/img/bVdnIEG" alt="" title="" loading="lazy"/></p><p><strong>4. Oracle NetSuite SRP</strong></p><p><strong>综合评分：★★★★☆</strong>  </p><p><strong>定位：</strong> 全球性云端ERP内置的供应商管理方案  </p><p><strong>适合企业：</strong> 有跨国业务、需要多语言多币种支持的中大型企业</p><p>对于业务涉及海外的企业，<strong>Oracle NetSuite</strong> 是一个常被考虑的选项。它的供应商关系管理（SRP）模块是其ERP套件的一部分，天生支持全球化的供应链管理。</p><p>核心能力包括：</p><p><strong>全球供应商管理</strong>：轻松管理不同国家地区的供应商，处理多币种报价和结算。</p><p><strong>端到端采购流程</strong>：从需求计划到付款，全部自动化。</p><p><strong>强大的分析报告</strong>：提供全球采购开支、供应商绩效等多维度分析。</p><p><strong>开放集成平台</strong>：易于与其他国际主流系统对接。</p><p><strong>优势无疑是其全球化能力和品牌信誉</strong>。但劣势也很明显：实施和许可费用昂贵，产品复杂度高，通常需要专业的咨询团队实施，更适合预算充足、业务结构复杂的国际化公司。<br/><img width="723" height="285" referrerpolicy="no-referrer" src="/img/bVdnIEH" alt="" title="" loading="lazy"/></p><p><strong>5. 甄云科技</strong></p><p><strong>综合评分：★★★☆☆</strong>  </p><p><strong>定位：</strong> 专注于SRM领域的标准化SaaS产品  </p><p><strong>适合企业：</strong> 采购管理复杂、寻源需求强的大型集团企业</p><p><strong>甄云科技</strong> 是国内较早专注于SRM赛道的厂商之一。其 <strong>甄采SRM</strong> 是一款功能深度聚焦在采购与供应商管理的标准化产品。</p><p>它的强项在于 <strong>采购寻源和成本控制</strong>：</p><p><strong>战略寻源</strong>：支持复杂的招标、竞价、谈判流程。</p><p><strong>采购成本分析</strong>：深入分析采购支出，寻找降本机会。</p><p><strong>供应商绩效精细化管理</strong>：评估模型可自定义程度较高。</p><p><strong>与主流ERP有预置接口</strong>：与SAP、Oracle、用友、金蝶等可进行对接。</p><p><strong>优势是专业度高，在大型企业的集中采购场景中经验丰富</strong>。<strong>缺点</strong>是作为标准化SaaS，虽然功能深，但灵活性有限，且产品主要面向大型客户，对中小企业来说可能功能过重、价格偏高。<br/><img width="723" height="360" referrerpolicy="no-referrer" src="/img/bVdnIEI" alt="" title="" loading="lazy"/></p><p><strong>6. 纷享销客</strong></p><p><strong>综合评分：★★★☆☆</strong>  </p><p><strong>定位：</strong> 以CRM为核心，扩展至上下游业务协同的平台  </p><p><strong>适合企业：</strong> 以渠道分销、客户项目管理为核心，需联动供应商的中小企业</p><p><strong>纷享销客</strong> 本质是一个连接型CRM，但其PaaS平台能力允许它将业务延伸到上下游协同。如果你的企业业务核心是项目和客户，供应商管理作为辅助环节，需要与客户项目打通，那它可以作为一种轻量级选择。</p><p>在供应商管理方面，它能实现：</p><p><strong>供应商信息作为客户/伙伴管理</strong>：在CRM框架内管理供应商基础信息和联系人。</p><p><strong>简单询价与订单协同</strong>：通过流程和表单功能实现。</p><p><strong>与项目、合同关联</strong>：便于核算项目成本。</p><p><strong>低代码自定义能力</strong>：可对其标准功能进行一定调整。</p><p><strong>优势在于它从客户侧视角整合供应链，适合项目制销售型企业</strong>。<strong>不足</strong>是并非专业的SRM，在复杂的采购寻源、供应商绩效深度分析等方面功能较弱。<br/><img width="723" height="344" referrerpolicy="no-referrer" src="/img/bVdnIEJ" alt="" title="" loading="lazy"/></p><p><strong>总结与选型建议</strong></p><p>选供应商管理系统，没有绝对的“最好”，只有“最适合”。</p><p>如果你的业务在快速发展，需求多变，希望系统能跟着业务成长，<strong>支道</strong> 这类无代码平台值得优先考虑。它能以较低成本实现深度定制，且后续调整自主性强，算是大家比较钟爱的选择。</p><p>最后提醒一句，无论选哪家，<strong>一定要让对方提供同行业的案例参考，甚至安排演示环境亲手试用</strong>。供应商管理是“用”出来的，只有贴合你业务实际运作习惯的系统，才能真正用起来、出效果。</p>]]></description></item><item>    <title><![CDATA[4个给网站添加暗黑模式的简单方法 达西先生 ]]></title>    <link>https://segmentfault.com/a/1190000047559948</link>    <guid>https://segmentfault.com/a/1190000047559948</guid>    <pubDate>2026-01-22 23:02:21</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>1、CSS 滤镜反转颜色</h2><pre><code class="css">/* 代码实现全网站暗黑模式 */
@media (prefers-color-scheme: dark) {
    html {
        background-color: #fff !important;
        color: #000 !important;
    }

    html {
        /* 反转180度颜色 */
        filter: invert(1) hue-rotate(180deg) !important;
    }

    /* 图片、视频等元素不需要处理，可继续添加可以不用处理的元素 */
    img,
    video,
    iframe {
        /* 再反转180度变成原来颜色 */
        filter: invert(1) hue-rotate(180deg) !important;
    }
}

</code></pre><h2>2、JS 库添加蒙板</h2><pre><code class="html">&lt;script src="https://cdnjs.cloudflare.com/ajax/libs/Darkmode.js/1.5.7/darkmode-js.min.js"&gt;&lt;/script&gt;
&lt;script&gt;
    // 监听系统暗黑模式变化
    let darkmode = new Darkmode()
    window
        .matchMedia('(prefers-color-scheme: dark)')
        .addEventListener('change', (event) =&gt; {
            if (event.matches) {
                // 切换暗黑模式
                if (!darkmode.isActivated()) {
                    darkmode.toggle()
                }
            } else {
                // 切换亮色模式
                if (darkmode.isActivated()) {
                    darkmode.toggle()
                }
            }
        })
&lt;/script&gt;

</code></pre><h2>3、CSS 伪类:not() 选择器</h2><pre><code class="css">/* 代码实现全网站暗黑模式 */
@media (prefers-color-scheme: dark) {
    /* 排除的 a 和 code 元素 */
    html *:not(a, code *) {
        background-color: #000000 !important;
        color: #ffffff !important;
    }

    /* a元素单独设置颜色 */
    a {
        color: #4caf50 !important;
    }
}

</code></pre><h2>4、CSS media 媒体查询</h2><blockquote><p>HTML &lt;link&gt; media 属性定义和用法</p><p><strong>media</strong> 属性规定目标资源针对什么媒体/设备进行了优化。</p><p><strong>media</strong> 属性指定了被链接文档将显示在什么设备上。</p><p>该属性主要与 CSS 样式表一起使用，为不同的媒体类型指定不同的样式。</p><p><strong>media</strong> 属性可以接受多个值。</p></blockquote><pre><code class="html">&lt;!-- 只在亮色模式下生效 --&gt;
&lt;link
    rel="stylesheet"
    media="(prefers-color-scheme: light)"
    href="/assets/css/light.css"
/&gt;

&lt;!-- 只在暗黑模式下生效 --&gt;
&lt;link
    rel="stylesheet"
    media="(prefers-color-scheme: dark)"
    href="/assets/css/dark.css"
/&gt;

</code></pre>]]></description></item><item>    <title><![CDATA[RAG 检索模型如何学习：三种损失函数的机制解析 本文系转载，阅读原文
https://avoid.]]></title>    <link>https://segmentfault.com/a/1190000047559951</link>    <guid>https://segmentfault.com/a/1190000047559951</guid>    <pubDate>2026-01-22 23:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>Agent 系统发展得这么快那么检索模型还重要吗？RAG 本身都已经衍生出 Agentic RAG和 Self-RAG（这些更复杂的变体了。</p><p>答案是肯定的，无论 Agent 方法在效率和推理上做了多少改进，底层还是离不开检索。检索模型越准，需要的迭代调用就越少，时间和成本都能省下来，所以训练好的检索模型依然关键。讨论 RAG 怎么用的文章铺天盖地，但真正比较检索模型学习方式的内容却不多见。</p><p>检索系统包含多个组件：检索嵌入模型、索引算法（HNSW 之类）、向量搜索机制（余弦相似度等）以及重排序模型。这篇文章只聚焦检索嵌入模型的学习方式。</p><p>本文将介绍我实验过的三种方法：Pairwise cosine embedding loss（成对余弦嵌入损失）、Triplet margin loss（三元组边距损失）、InfoNCE loss。</p><h2>成对余弦嵌入损失</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559953" alt="" title=""/></p><p>正样本对示例<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047559954" alt="" title="" loading="lazy"/></p><p>负样本对示例</p><p>输入是一对文本加一个标签，标签标明这对文本是正匹配还是负匹配。和 MNLI 数据集里的蕴含、矛盾关系类似。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047559955" alt="" title="" loading="lazy"/></p><p>损失函数用的是余弦嵌入损失，x 和 y 分别是文本对的嵌入向量。</p><h2>三元组边距损失</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559956" alt="" title="" loading="lazy"/></p><p>输入变成三个文本：一个锚文本、一个正匹配、一个负匹配。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047559957" alt="" title="" loading="lazy"/></p><p>损失函数是 Triplet Margin Loss。公式里 a 代表锚文本嵌入，p 代表正样本嵌入，n 代表负样本嵌入。</p><h2>InfoNCE 损失</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559958" alt="" title="" loading="lazy"/></p><p>输入包括一个查询、一个正匹配、一组负样本列表。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047559959" alt="" title="" loading="lazy"/></p><p>损失函数采用 InfoNCE，灵感来自 M3-Embedding 论文（arxiv:2402.03216）。公式中 p* 是正样本嵌入，P' 是负样本嵌入列表，q 是查询嵌入，s(.) 表示相似度函数，比如余弦相似度。</p><h2>比较</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559960" alt="" title="" loading="lazy"/></p><p>哪种方法最好？要看具体场景、数据量和算力。从我的实验来看，InfoNCE 覆盖面最广。但只要实验做得够充分、训练数据比例调得够细，余弦嵌入损失也能达到差不多的效果。三元组边距损失我没有深入探索，不过它可能是介于另外两者之间的一个折中选项。</p><p><a href="https://link.segmentfault.com/?enc=12djtCvTleRQG%2F8CCPszaw%3D%3D.XIPmVcwtzWu%2BknPxWPssKwWoWzToFGLxG0JCTBi0hvKOdgwCGGzFkHCnnbsHe%2B1XWkjV%2BXYPEK%2FhfuQRW0hq9A%3D%3D" rel="nofollow" target="_blank">https://avoid.overfit.cn/post/7958652dd31e4cf5ace899b97e0eac27</a></p><p>作者：Jerald Teo</p>]]></description></item><item>    <title><![CDATA[【2026原创】卫星遥感图像识别系统~Python+深度学习+人工智能+算法模型+TensorFlo]]></title>    <link>https://segmentfault.com/a/1190000047559829</link>    <guid>https://segmentfault.com/a/1190000047559829</guid>    <pubDate>2026-01-22 22:03:14</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>项目介绍</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559831" alt="图片" title="图片"/><br/>图片<br/>本系统是一个基于深度学习的卫星遥感图像智能识别平台，旨在为用户提供高效、准确的遥感图像分类服务。系统采用Flask轻量级Web框架构建后端服务，集成ResNet50深度卷积神经网络模型，实现了对卫星遥感图像的自动化识别与分类。系统支持识别七大类地物类型，包括草地、农田、工业区、河流湖泊、森林、居民区和停车场，能够满足土地利用监测、城市规划、环境评估等多种应用场景的需求。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559832" alt="图片" title="图片" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559833" alt="图片" title="图片" loading="lazy"/></p><p>关键技术栈：resnet50算法<br/>ResNet50（Residual Network 50层）是深度学习领域中具有里程碑意义的卷积神经网络架构，由何恺明等学者于2015年提出。该网络的核心创新在于引入了残差学习（Residual Learning）机制，通过跳跃连接（Skip Connection）解决深层网络训练中的梯度消失和梯度爆炸问题，使得网络深度可以突破传统限制，达到甚至超过100层。ResNet50网络包含49个卷积层和1个全连接层，采用了5个阶段的残差块设计，每个阶段包含不同数量的残差单元，通过堆叠这些残差块构建深度网络结构。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559834" alt="图片" title="图片" loading="lazy"/><br/>图片<br/>系统功能模块图</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559835" alt="图片" title="图片" loading="lazy"/><br/>图片<br/>演示视频 and 完整代码 and 安装<br/>地址：<a href="https://link.segmentfault.com/?enc=AEwu6DwcEIX8b9liWwq2HQ%3D%3D.rI8629L9D6MTz3y3tRIyor2fAX2zQRauV9h29WBKIRaAufIy0ra0XWqFsg%2F8HKbtAuF9L%2Bgrf9P8mL7m74DL3g%3D%3D" rel="nofollow" target="_blank">https://www.yuque.com/ziwu/qkqzd2/kma4wpp387ifg6ci</a></p>]]></description></item><item>    <title><![CDATA[AG-UI：让 AI 走出聊天框的“界面革命” blossom ]]></title>    <link>https://segmentfault.com/a/1190000047559840</link>    <guid>https://segmentfault.com/a/1190000047559840</guid>    <pubDate>2026-01-22 22:02:17</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h3>序幕：从“百科全书”到“实时搭档”</h3><p>大家发现了吗？我们现在使用 AI 的方式，本质上还是在查阅一本<strong>超级百科全书</strong>。</p><p>无论是在 ChatGPT 还是 Claude 的对话框里，我们总是重复着：<strong>提问、等待、阅读文字、复制粘贴</strong>。这种交流永远被困在一个小小的“聊天框”里，就像你雇佣了一个超级天才助手，但他被关在隔壁的小黑屋里，只能通过门缝给你<strong>“递纸条”</strong>。你在这头对着复杂的业务界面抓耳挠腮，他在那头空有一身才华却看不见你的屏幕。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559842" alt="" title=""/></p><p><strong>这种“隔靴操痒”的交互方式，是时候结束了。</strong></p><p>想象一下，如果 AI 不仅仅是那个能言善辩的聊天机器人，而是一个<strong>能实时看懂你的操作、感知你的困惑、并直接帮你操作界面的“数字化合伙人”</strong>？当你拖动地图，他立刻补全路径；当你填表卡壳，他直接变出最合适的选项。他不再躲在对话框后面，而是直接走进你的工作流，伸手接过了那把名为“UI”的钥匙。这就是 <strong>AG-UI（Agent-User Interaction Protocol）</strong> 正在发起的革命：<strong>让 AI 走出聊天框，让界面随心而动。</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559843" alt="" title="" loading="lazy"/></p><hr/><h3>第一部分：什么是 AG-UI？</h3><p>用最简单的话说，AG-UI 是 AI 智能体（Agent）和用户界面（UI）之间的<strong>“通用翻译官”</strong>。</p><p>在 AG-UI 出现之前，如果你想把 AI 接入 App，程序员需要费劲地把 AI 的文字输出手动“翻译”成网页上的按钮。而且，市面上有无数种 AI 框架，又有无数种前端终端，要把它们两两连接，工作量巨大。</p><p><strong>AG-UI 的出现，就像是在 AI 大脑与屏幕之间修通了一条标准化的“高速公路”：</strong> 它不管后端用的是什么模型，前端用的是什么设备，只要接上这根管道，AI 就能从一个后台的“思考者”，变成前台的“协作者”。</p><blockquote><strong>知识点：AG-UI vs A2UI</strong><br/>这里有两个概念容易混淆。<strong>A2UI（Google 出品）</strong> 像是 UI 的<strong>“建筑图纸”</strong>，定义了界面长什么样；而 <strong>AG-UI</strong> 则是<strong>“物流快递”</strong>，负责把这张图纸实时、安全地送到你的屏幕上。</blockquote><hr/><h3>第二部分：AG-UI 在智能体协议栈中的角色</h3><p>要理解 AG-UI 的威力，我们需要看它在整个 AI 智能体生态（Agent Protocol Stack）中的位置。它与其他两大主流协议相辅相成，共同构成了 AI 时代的底层架构：</p><ul><li><strong>MCP (Model Context Protocol) —— 赋能工具：</strong> 负责连接 AI 与各种工具（Tools）或数据库。它让 Agent 拥有了“手”，可以去查资料、调 API。</li><li><strong>A2A (Agent-to-Agent) —— 协同合作：</strong> 负责不同 Agent 之间的通信。它让 Agent 拥有了“对讲机”，可以呼唤其他 AI 协作。</li><li><strong>AG-UI —— 触达用户：</strong> <strong>这是最关键的一环。</strong> 它负责将 Agent 的能力引入到面向用户的应用程序中。它让 Agent 拥有了“窗口”，直接与人类在 UI 界面上共事。</li></ul><p><strong>流程简述：</strong> Agent 通过 <strong>MCP</strong> 调用工具获取数据，通过 <strong>A2A</strong> 协同其他专家 AI，最后通过 <strong>AG-UI</strong> 将处理结果直接转化成你屏幕上的交互组件。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559844" alt="" title="" loading="lazy"/></p><hr/><h3>第三部分：颠覆性的三宗“最”</h3><ol><li><strong>最懂你：生成式 UI (Generative UI)。</strong> 以前的软件是程序员提前写死的。有了 AG-UI，AI 可以根据对话内容，现场为你<strong>“造”软件</strong>。而且这过程非常丝滑——组件会随着 AI 的思考过程实时在屏幕上“生长”出来。</li><li><strong>最默契：共享状态 (Shared State)。</strong> 这就是“双向同步”的超能力。你在界面上拉动滑块增加了参数，AI 的“大脑”会立刻感知到这个动作并同步做出反馈。你们共享同一个“上下文”，就像并肩作战的战友。</li><li><strong>最安全：人在回路 (Human in the Loop)。</strong> AG-UI 允许 AI 在关键时刻弹出一个确认界面。AI 没法乱写代码，它只能发送数据指令去调用你预设好的<strong>“安全积木”</strong>。</li></ol><hr/><h3>第四部分：生态现状——工具已在手</h3><p>虽然协议发布时间不长，但它的生态爆发速度惊人：</p><ul><li><strong>全明星后端支持：</strong> <strong>LangGraph、CrewAI、Microsoft Autogen</strong> 等主流框架均已接入。</li><li><strong>前端大厂入局：</strong> 除了 React 方案，<strong>Google 的 Flutter 团队已经推出了 GenUI SDK</strong>。这意味着“设计即基础设施”的时代已经开启。</li><li><strong>快速体验：</strong> 如果你想现在尝试，只需一行命令：<code>npx create-ag-ui-app</code>。</li></ul><hr/><h3>第五部分：核心洞察——“设计”正在变成基础设施</h3><p>作为开发者，我感受到这场革命最震撼的地方在于：<strong>前端的工作方式将彻底重构。</strong></p><ol><li><strong>从“盖房子”到“造积木”：</strong> 以后前端不再负责拼装最终页面（那是 AI 的事），而是负责设计足够原子、具备强语义化的“组件积木”。</li><li><strong>框架的“降维打击”：</strong> 当 Flutter 等框架官方定义的“标准组件”已经足够美观且具备完美的 AI 语义时，企业将不再需要雇佣设计师去重新发明轮子。<strong>“设计”将从一项昂贵的业务成本，变成框架自带的基础设施。</strong></li></ol><hr/><h3>结语：拥抱流动的未来</h3><p>2026 年是 AI 智能体爆发的元年。界面的脸孔将不再死板，它会随你的需求而流动。UI 不再是挡在你和功能之间的那层“膜”，而是变成了一种随用随取的资源。</p><p><strong>未来的应用不是由菜单定义的，而是由你的意图定义的。</strong></p><p>别再纠结 CSS 的像素偏移了，去研究 AI 如何理解你的业务意图吧。这场革命，正在你运行 <code>npx create-ag-ui-app</code> 的那一刻开始。</p><p>本文由<a href="https://link.segmentfault.com/?enc=j7T9ijZU%2F4jARXdQdlERKA%3D%3D.70kCXXKMANjrrRYcrB4gQ7bT21Ik5VMZMzSQgWkbzYQ%3D" rel="nofollow" target="_blank">mdnice</a>多平台发布</p>]]></description></item><item>    <title><![CDATA[基于 YOLOv8 的多犬种（60种常见犬类）智能识别系统项目 [目标检测完整源码] 南瓜 ]]></title>    <link>https://segmentfault.com/a/1190000047559867</link>    <guid>https://segmentfault.com/a/1190000047559867</guid>    <pubDate>2026-01-22 22:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>基于 YOLOv8 的多犬种（60种常见犬类）智能识别系统项目 [目标检测完整源码]</h2><h3>—— 面向 60 类常见犬种的目标检测与可视化应用落地</h3><hr/><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559869" alt="在这里插入图片描述" title="在这里插入图片描述"/></p><h3>一、背景与问题：为什么“犬种识别”值得工程化？</h3><p>在宠物经济高速发展的今天，犬类已经从“家庭陪伴动物”逐步演变为需要<strong>精细化管理与智能化服务</strong>的对象。在实际场景中，犬种信息直接影响：</p><ul><li>饲养与行为管理策略</li><li>疫苗接种与健康风险评估</li><li>宠物交易、领养与救助流程</li><li>城市宠物管理与公共安全</li></ul><p>然而，现实中对犬种的识别依然高度依赖人工经验，不仅主观性强，而且在混血犬、幼犬、复杂光照条件下误判率较高。</p><p><strong>问题的本质在于：</strong></p><blockquote>如何构建一个既具备高识别精度，又真正“可落地使用”的犬种识别系统？</blockquote><p>本项目正是围绕这一问题，给出了一套<strong>完整可复现的工程级解决方案</strong>。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047559870" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h3>源码下载与效果演示</h3><p>哔哩哔哩视频下方观看：<br/><a href="https://www.bilibili.com/video/BV1wB8MzsE9P/" target="_blank">https://www.bilibili.com/video/BV1wB8MzsE9P/</a></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559871" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><p>包含：</p><p>📦完整项目源码</p><p>📦 预训练模型权重</p><p>🗂️ 数据集地址（含标注脚本</p><hr/><h3>二、系统整体架构设计</h3><p>该项目并非单一模型 Demo，而是一个<strong>从数据、训练到部署的完整闭环系统</strong>，整体架构如下：</p><pre><code>┌────────────┐
│  数据集层  │  犬类图像 + YOLO 标注
└─────┬──────┘
      ↓
┌────────────┐
│  模型训练  │  YOLOv8 Detection
└─────┬──────┘
      ↓
┌────────────┐
│  推理服务  │  图片 / 视频 / 摄像头
└─────┬──────┘
      ↓
┌────────────┐
│  GUI 应用  │  PyQt5 桌面端
└────────────┘</code></pre><p>核心目标只有一个：<br/><strong>让“深度学习模型”真正变成“普通用户能用的软件”。</strong><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047559872" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047559873" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><hr/><h3>三、模型选型：为什么是 YOLOv8？</h3><p>在多类别实时检测任务中，YOLO 系列一直是工程实践的主流方案。本项目最终选择 YOLOv8，主要基于以下考虑：</p><h4>3.1 架构层面的优势</h4><ul><li><strong>Anchor-Free 设计</strong><br/>减少超参数依赖，收敛更稳定</li><li><strong>Task-Aligned Assigner</strong><br/>分类与定位目标一致性更强</li><li><strong>更轻量的 Backbone 与 Neck</strong><br/>在保证精度的同时提升推理速度</li></ul><h4>3.2 工程友好性</h4><ul><li>原生支持 <strong>PyTorch / ONNX</strong></li><li>Ultralytics 提供统一 CLI 与 Python API</li><li>训练、验证、推理接口高度一致</li></ul><p>这使得模型不仅“好训”，而且<strong>非常适合与 GUI、业务系统结合</strong>。</p><hr/><h3>四、犬种数据集构建与标注规范</h3><h4>4.1 数据规模与类别</h4><p>本系统覆盖 <strong>60 种常见犬类</strong>，包括但不限于：</p><ul><li>柯基、哈士奇、柴犬</li><li>金毛、拉布拉多、贵宾犬</li><li>德牧、边牧、博美等</li></ul><p>每个类别均包含多姿态、多背景、多尺度样本，尽量贴近真实使用场景。</p><hr/><h4>4.2 数据组织结构（YOLO 标准）</h4><pre><code>dataset/
├── images/
│   ├── train/
│   └── val/
├── labels/
│   ├── train/
│   └── val/</code></pre><p>标签文件采用 YOLO 标准格式：</p><pre><code>&lt;class_id&gt; &lt;x_center&gt; &lt;y_center&gt; &lt;width&gt; &lt;height&gt;</code></pre><p>所有坐标均为 <strong>相对比例值</strong>，确保模型在不同分辨率下具备一致性。</p><hr/><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559874" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h3>五、模型训练流程详解</h3><h4>5.1 训练配置示例</h4><pre><code class="bash">yolo detect train \
  data=dog.yaml \
  model=yolov8n.pt \
  epochs=100 \
  batch=16 \
  imgsz=640</code></pre><p>关键训练策略包括：</p><ul><li>合理的 batch size 控制显存占用</li><li>数据增强（翻转、尺度变换、颜色扰动）</li><li>早期收敛阶段重点关注 box_loss 与 cls_loss</li></ul><hr/><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559875" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h4>5.2 训练过程监控</h4><p>YOLOv8 在 <code>runs/detect/train/</code> 目录中自动生成：</p><ul><li>损失函数变化曲线</li><li>mAP@0.5 / mAP@0.5:0.95</li><li>混淆矩阵（类别间区分能力）</li></ul><p>在实际实验中，多数犬种在 <strong>mAP@0.5 指标上稳定超过 90%</strong>，具备实际应用价值。</p><hr/><h3>六、多模态推理能力设计</h3><p>本系统支持多种输入形式，统一由同一推理接口处理。</p><h4>6.1 单张图片与批量图片</h4><ul><li>支持文件与文件夹级别输入</li><li>自动生成标注结果图</li><li>适合数据复查与分析场景</li></ul><hr/><h4>6.2 视频与实时摄像头</h4><ul><li>基于 OpenCV 逐帧推理</li><li>支持实时显示检测结果</li><li>可选保存输出视频文件</li></ul><p>这一能力使系统能够直接应用于：</p><ul><li>宠物门店实时监控</li><li>救助站视频巡检</li><li>展示型 AI 应用演示</li></ul><hr/><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559876" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h3>七、PyQt5 图形界面设计要点</h3><p>为了降低使用门槛，项目引入 PyQt5 构建完整桌面应用。</p><h4>7.1 界面功能划分</h4><ul><li><strong>输入控制区</strong>：选择图片 / 视频 / 摄像头</li><li><strong>结果展示区</strong>：实时显示检测画面</li><li><strong>日志与状态区</strong>：输出模型运行信息</li></ul><h4>7.2 工程价值</h4><ul><li>无需命令行操作</li><li>非算法人员也可直接使用</li><li>适合作为课程设计、毕业设计、项目演示系统</li></ul><hr/><h3>八、推理代码核心示例</h3><pre><code class="python">from ultralytics import YOLO

model = YOLO("best.pt")
results = model("test.jpg", conf=0.25, save=True)

for box in results[0].boxes:
    cls_id = int(box.cls)
    score = float(box.conf)</code></pre><p>推理结果中可直接获取：</p><ul><li>类别 ID</li><li>置信度</li><li>边框坐标</li></ul><p>便于后续对接业务逻辑或二次开发。</p><hr/><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559877" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h3>九、项目工程化与“开箱即用”</h3><p>本项目已完成<strong>完整工程封装</strong>，具备以下特点：</p><ul><li>已训练完成的权重文件</li><li>完整源码与数据集</li><li>一键启动 GUI 程序</li><li>提供训练与部署说明</li></ul><p>运行检测仅需：</p><pre><code class="bash">python main.py</code></pre><p>无需重新训练，即可体验完整系统功能。</p><hr/><h3>十、可扩展性与二次开发方向</h3><p>该项目并不局限于犬种识别，其工程框架可直接扩展为：</p><ul><li>🐱 猫咪品种识别</li><li>🐦 鸟类 / 野生动物监测</li><li>🐄 畜牧养殖视觉分析</li><li>🏙️ 智慧城市动物管理系统</li></ul><p><strong>本质上，这是一个可复用的 YOLOv8 + GUI 工程模板。</strong></p><hr/><h3>总结：一个真正“能用”的目标检测项目应该是什么样？</h3><p>相比单纯展示模型精度，本项目更关注：</p><ul><li>是否具备完整工程链路</li><li>是否方便非算法人员使用</li><li>是否具备二次开发潜力</li></ul><p>通过 YOLOv8 与 PyQt5 的深度结合，该系统成功实现了从算法到应用的跨越。</p><blockquote>🚀 <strong>如果你正在寻找一个具备训练、检测、部署一体化能力的目标检测项目实践，这套基于 YOLOv8 的多犬种识别系统，值得你深入研究与复用。</strong></blockquote>]]></description></item><item>    <title><![CDATA[移动ERP系统排行榜（2026）：5款主流产品怎么选更省心 SaaS圈老马 ]]></title>    <link>https://segmentfault.com/a/1190000047559684</link>    <guid>https://segmentfault.com/a/1190000047559684</guid>    <pubDate>2026-01-22 20:02:10</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>这两年企业上移动ERP，很多时候不是“想升级”，而是被现实推着走：人在外面跑业务，单据在电脑里卡着；仓库要扫码盘点，结果还在纸上写；老板想看数据，最后只能等人导表。</p><p><strong>所以移动ERP系统这件事，本质上比的不是功能堆得多不多，而是谁能把高频动作放到手机上跑通。</strong></p><p><strong>本文排行榜怎么排的</strong><strong>：</strong></p><p>1、我用的标准很直白，按“能不能真的用起来”来排：</p><p>2、移动端是否能覆盖审批、开单、库存、对账等高频动作</p><p>3、产品与厂商信息是否能在官网/官方应用商店核验</p><p>4、是否有清晰的定位：更适合哪类企业、哪类业务模式</p><p>5、落地成本是否可控：上线路径清晰，推广阻力别太大</p><p><strong>一、移动ERP系统排行榜 TOP 5</strong></p><p><strong>1、支道</strong></p><p>支道更像“把业务系统当积木搭”的路线，不是那种固定菜单的传统ERP。</p><p><strong>它最打动人的点是：业务流程变了，系统也能跟着你改，不用每次都等开发排期。</strong></p><p>支道更适合哪类企业？一句话概括就是：流程不太标准、变化很快、跨部门协同靠人盯的团队。你不用一上来就“全上ERP”，更现实的做法是先跑通1-2条关键流程，然后逐步扩。</p><p>支道常见落地方式可以按这种节奏走：</p><p>（1）先做移动端待办与审批，把“卡在路上”的事打通</p><p>（2）再把业务填报和单据录入搬到手机上，现场就能闭环</p><p>（3）最后用报表与看板把数据收口，减少重复统计</p><p>如果你最痛的是“Excel满天飞、版本对不上、事情靠催”，支道的思路通常更贴近现实：先把流程固化，再谈精细化管理。<br/><img width="723" height="384" referrerpolicy="no-referrer" src="/img/bVdnIBD" alt="" title=""/></p><p><strong>2、金蝶</strong></p><p>金蝶移动端的卖点写得很实在，官网直接列出一串高频动作：扫码开单、蓝牙打印、出入库、盘点调拨、库存分析等。</p><p><strong>如果你是“手机要能开单、仓库要能快速做动作”，金蝶这类路线通常更稳。</strong></p><p>适合场景也很清晰：</p><p>（1）业务员：手机下单、跟进客户、交易管理</p><p>（2）仓库：出入库、盘点、调拨</p><p>（3）管理者：业绩、库存、经营数据随时看 <br/><img width="723" height="271" referrerpolicy="no-referrer" src="/img/bVdnIBE" alt="" title="" loading="lazy"/></p><p><strong>3、用友</strong></p><p>用友在移动端的主张也很明确：一个App管理所有应用系统，一键访问业务系统单据，移动快捷审批，实时处理业务。</p><p><strong>你们系统多、待办多、审批多，用友这类“统一入口”的价值就会更明显。</strong></p><p>更适合的企业画像：</p><p>（1）组织层级较多，跨部门流程复杂</p><p>（2）需要把多个系统的待办统一到手机端处理</p><p>（3）希望移动端是入口，而不是“另一个孤岛” <br/><img width="723" height="288" referrerpolicy="no-referrer" src="/img/bVdnIBL" alt="" title="" loading="lazy"/></p><p><strong>4、鼎捷</strong></p><p>鼎捷在制造业中小企业的定位很明确，它在“掌上易助”页面直接写：易助小程序，全面满足ERP用户移动化需求，并说明易助是面向中小微企业、涵盖制造全流程的ERP。</p><p><strong>小程序入口的好处很现实：推广阻力小，一线人员更愿意用。</strong> </p><p>如果你是机械、五金、汽配、电子加工这类行业，鼎捷官方也明确写到易助ERP适用这些制造业场景，并涵盖财务、进销存、生产等管理范畴。<br/><img width="723" height="335" referrerpolicy="no-referrer" src="/img/bVdnIBM" alt="" title="" loading="lazy"/></p><p><strong>5、网上管家婆</strong></p><p>网上管家婆移动端讲的是“手机开单、扫码出入库、欠款对账、数据看板”这种中小企业最常用的动作。手机开单、查询欠款、一键生成对账单并发送链接或二维码对账，扫码出入库与多方式盘点。</p><p><strong>如果你是商贸批零、电商网店，想要的是上手快、动作快，这类产品往往更省事。</strong><br/><img width="723" height="396" referrerpolicy="no-referrer" src="/img/bVdnIBN" alt="" title="" loading="lazy"/></p><p><strong>二、5款产品对比表</strong><br/><img width="723" height="463" referrerpolicy="no-referrer" src="/img/bVdnIBO" alt="" title="" loading="lazy"/></p><p><strong>三、最快的选型方法</strong></p><p><strong>1、你们移动端最常干的三件事是什么</strong></p><p>（1）审批、开单、盘点</p><p>（2）对账、收款、查库存</p><p>（3）项目回填、工单处理</p><p>2、你们流程到底变不变</p><p>（1）经常变：优先看支道这种可配置能力强的路线</p><p>（2）基本不变：优先看标准化更成熟的套件</p><p>3、你们现有系统多不多</p><p>（1）多系统并存：用友这类统一入口更省心</p><p>（2）就一套进销存：金蝶、网上管家婆这类会更快落地 </p><p><strong>四、结语</strong></p><p>移动ERP系统排行榜看一眼就好，真正决定成败的是：手机端能不能把你们最痛的那条流程跑通。<strong>如果你希望先把协同和流程跑顺、再逐步扩模块，支道放在第一位是合理的选择。</strong></p>]]></description></item><item>    <title><![CDATA[【赵渝强老师】国产金仓数据库的数据库对象 赵渝强老师 ]]></title>    <link>https://segmentfault.com/a/1190000047559736</link>    <guid>https://segmentfault.com/a/1190000047559736</guid>    <pubDate>2026-01-22 20:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>金仓数据库中包含各种数据库对象，常见的KingBase对象有：数据库、模式、表、索引、视图、存储过程、存储函数和触发器等等。这里将介绍金仓数据库中常见的数据库对象以及如何使用它们。视频讲解如下：<br/><a href="https://www.bilibili.com/video/BV1RQz3B9ERT/?aid=115930646454086&amp;cid=35515336758" target="_blank">https://www.bilibili.com/video/BV1RQz3B9ERT/?aid=115930646454...</a></p><h2>一、 数据库与模式</h2><p>数据库本身也是一个KingBase的数据库对象。数据库对象中包含其他所有的数据库对象，如：模式、表、视图、索引等等。使用命令create database可以创建一个新的数据库，下面展示了该命令的格式：</p><pre><code class="sql">CREATE DATABASE name
     [ WITH ] [ OWNER [=] user_name ]
           [ TEMPLATE [=] template ]
           [ ENCODING [=] encoding ]
           [ LC_COLLATE [=] lc_collate ]
           [ LC_CTYPE [=] lc_ctype ]
           [ TABLESPACE [=] tablespace_name ]
           [ ALLOW_CONNECTIONS [=] allowconn ]
           [ CONNECTION LIMIT [=] connlimit ]
           [ IS_TEMPLATE [=] istemplate ]</code></pre><p>一个数据库包含一个或多个模式（Schema），模式中又包含了表、函数及操作符等数据库对象。创建新数据库时，KingBase会自动创建名为public的模式。使用命令create schema可以创建一个新的模式，下面展示了该命令的格式：</p><pre><code class="sql">CREATE SCHEMA schema_name [ AUTHORIZATION role_specification ] [ schema_element [ ... ] ]
CREATE SCHEMA AUTHORIZATION role_specification [ schema_element [ ... ] ]
CREATE SCHEMA IF NOT EXISTS schema_name [ AUTHORIZATION role_specification ]
CREATE SCHEMA IF NOT EXISTS AUTHORIZATION role_specification

其中 role_specification 可以是：

    user_name
  | CURRENT_USER
  | SESSION_USER</code></pre><p>在了解到数据库与模式的概念后，下面通过具体的操作来演示如何创建和使用它们。<br/>（1）创建一个新的数据库dbtest。</p><pre><code class="sql">scott=# create database dbtest;</code></pre><p>（2）查看已存在的数据库列表。</p><pre><code class="sql">scott=# \l

# 输出的信息如下：
                                        数据库列表
   名称    | 拥有者 | 字元编码 |  校对规则   |    Ctype    | ICU 排序 |     存取权限      
-----------+--------+----------+-------------+-------------+----------+-------------------
 dbtest    | system | UTF8     | zh_CN.UTF-8 | zh_CN.UTF-8 |          | 
 kingbase  | system | UTF8     | zh_CN.UTF-8 | zh_CN.UTF-8 |          | 
 scott     | system | UTF8     | zh_CN.UTF-8 | zh_CN.UTF-8 |          | 
 security  | system | UTF8     | zh_CN.UTF-8 | zh_CN.UTF-8 |          | 
 template0 | system | UTF8     | zh_CN.UTF-8 | zh_CN.UTF-8 |          | =c/system        +
           |        |          |             |             |          | system=CTc/system
 template1 | system | UTF8     | zh_CN.UTF-8 | zh_CN.UTF-8 |          | =c/system        +
           |        |          |             |             |          | system=CTc/system
 test      | system | UTF8     | zh_CN.UTF-8 | zh_CN.UTF-8 |          | 
(7 行记录)</code></pre><p>（3）切换到数据库dbtest。</p><pre><code class="sql">scott=# \c dbtest 
您现在以用户名"system"连接到数据库"dbtest"。</code></pre><p>（4）查看数据库dbtest中的模式。</p><pre><code class="sql">dbtest=# \dn

# 输出的信息如下：
       架构模式列表
       名称       | 拥有者 
------------------+--------
 anon             | system
 dbms_job         | system
 dbms_scheduler   | system
 dbms_sql         | system
 kdb_schedule     | system
 perf             | system
 public           | system
 src_restrict     | system
 sys_hm           | system
 sysaudit         | system
 sysmac           | system
 wmsys            | system
 xlog_record_read | system
(13 行记录)

# 这里的public的模式是创建数据库对象的默认模式。</code></pre><p>（5）创建一个新的模式。</p><pre><code class="sql">dbtest=# create schema firstschema;</code></pre><p>（6）重新查看数据库dbtest中的模式。</p><pre><code class="sql">dbtest=# \dn

# 输出的信息如下：
       架构模式列表
       名称       | 拥有者 
------------------+--------
 anon             | system
 dbms_job         | system
 dbms_scheduler   | system
 dbms_sql         | system
 firstschema      | system
 kdb_schedule     | system
 perf             | system
 public           | system
 src_restrict     | system
 sys_hm           | system
 sysaudit         | system
 sysmac           | system
 wmsys            | system
 xlog_record_read | system
(14 行记录)</code></pre><h2>二、 创建与管理表</h2><p>表是一种非常重要的数据库对象。金仓数据库的数据都是存储在表中。KingBase的表是一种二维结构，由行和列组成。表有列组成，列有列的数据类型。下面通过具体的步骤来演示如何操作金仓数据库的表。这些操作包括创建表、查看表、修改表和删除表。</p><p>（1）创建一张新的表test2.</p><pre><code class="sql">dbtest=# create table test2(id int,name varchar(32),age int);

# 由于创建表时没有指定模式的名称，因此表将创建在public模式下。
# 如果要在指定的模式下创建表，可以使用下面的语句：
dbtest=# create table firstschema.test2(id int,name varchar(32),age int);</code></pre><p>（2）查看表的结构。</p><pre><code class="sql">dbtest=# \d test2

# 输出的信息如下：
                    数据表 "public.test2"
 栏位 |            类型            | 校对规则 | 可空的 | 预设 
------+----------------------------+----------+--------+------
 id   | integer                    |          |        | 
 name | character varying(32 char) |          |        | 
 age  | integer                    |          |        | </code></pre><p>（3）在表中增加一个字段。</p><pre><code class="sql">dbtest=# alter table test2 add gender varchar(1) default 'M';

# 这里增加了一个gender字段用于表示性别，默认是“M”。</code></pre><p>（4）重新查看表的结构。</p><pre><code class="sql">dbtest=# \d test2

# 输出的信息如下：
                         数据表 "public.test2"
  栏位  |            类型            | 校对规则 | 可空的 |     预设     
--------+----------------------------+----------+--------+--------------
 id     | integer                    |          |        | 
 name   | character varying(32 char) |          |        | 
 age    | integer                    |          |        | 
 gender | character varying(1 char)  |          |        | 'M'::varchar</code></pre><p>（5）修改表将gender字段的长度改为10个字符。</p><pre><code class="sql">dbtest=# alter table test2 alter gender type varchar(10);</code></pre><p>（6）删除gender字段。</p><pre><code class="sql">dbtest=# alter table test2 drop column gender;</code></pre><p>（7）删除表test2。</p><pre><code class="sql">dbtest=# drop table test2;</code></pre><h2>三、 在查询时使用索引</h2><p>数据库查询是数据库的主要功能之一，最基本的查询算法是顺序查找（linear search）时间复杂度为O(n)，显然在数据量很大时效率很低。优化的查找算法如二分查找（binary search）、二叉树查找（binary tree search）等，虽然查找效率提高了。但是各自对检索的数据都有要求：二分查找要求被检索数据有序，而二叉树查找只能应用于二叉查找树上，但是数据本身的组织结构不可能完全满足各种数据结构。所以在数据之外，数据库系统还维护着满足特定查找算法的数据结构。这些数据结构以某种方式指向数据，这样就可以在这些数据结构上实现高级查找算法。这种数据结构就是索引。金仓数据库官方对索引的定义为：索引（Index）是帮助KingBase高效获取数据的数据结构。索引是一种数据结构。金仓数据库默认的索引类型是B树索引。下图是一颗简单的B树，可见它与二叉树最大的区别是它允许一个节点有多于2个的元素，每个节点都包含key和数据，查找时可以使用二分的方式快速搜索数据。</p><p><img width="723" height="232" referrerpolicy="no-referrer" src="/img/bVdnICs" alt="image.png" title="image.png"/></p><p>在了解到了KingBase索引的基本知识以后，下面将通过具体的步骤演示来说明如何在KingBase中创建索引，并且在查询语句中使用它。<br/>（1）查看scott数据库中部门表dept和员工表emp上的索引信息。</p><pre><code class="sql">scott=# select index_name,index_type,table_name,status
        from user_indexes where table_name in ('DEPT','EMP');
        
# 输出的信息如下：
 index_name | index_type | table_name | status 
------------+------------+------------+--------
 DEPT_PKEY  | BTREE      | DEPT       | VALID
 EMP_PKEY   | BTREE      | EMP        | VALID
(2 行记录)

# user_indexes是一个视图，可以通过它获取某个用户创建的索引信息。</code></pre><p>（2）使用create index命令在员工表emp的薪水sal字段上创建完全索引。</p><pre><code class="sql">scott=# create index index_full on emp using btree(sal);

# 完全索引会基于该字段上的所有值创建索引。
# 同时，在创建索引的时候会进行锁表的操作，可以使用 CIC (create index concurrently)，
# 但创建索引的时间相对较长。例如：
scott=# create index concurrently index1 on emp using btree(sal);</code></pre><p>（3）下面的语句将在员工表上创建一个部分索引。</p><pre><code class="sql">scott=# create index index_part on emp using btree(sal) where sal&lt;3000;

# 部分索引是对于表的部分数据创建索引。
# 如果发现表的某一部分数据查询次数较多时，可以考虑在这部分数据上创建一个部分索引。
# 部分索引相较于完全索引，查询的性能将得到提高，并且部分索引文件所占的空间也会小于全索引。</code></pre><p>（4）在员工表emp的员工姓名ename上创建表达式索引。</p><pre><code class="sql">scott=# create index index_exp on emp(lower(ename));

# 对于表达式索引的维护代价比较高，因为在每一行插入或更新时需要重新计算相应表达式的值，
# 但是针对于表达式索引在查询时的效率更高，因为表达式的值会直接存储在索引中。</code></pre><p>（5）使用explain语句查看SQL查询时的执行计划。</p><pre><code class="sql">scott=# explain select * from emp where lower(ename) like 'king';

# 输出的信息如下：
                     QUERY PLAN                     
----------------------------------------------------
 Seq Scan on emp  (cost=0.00..1.21 rows=1 width=42)
   Filter: (lower((ename)::text) ~~ 'king'::text)
(2 行记录)

# 从输出的执行计划可以看出，此时并没有使用到表达式索引。
# 这是由于KingBase并不能强制使用特定的索引，或者完全阻止KingBase进行Seq Scan的顺序扫描。
# 但可以通过将参数enable_seqscan设置为 off的方式让KingBase尽可能避免执行某些扫描类型，
# 但这样的方式多用于开发和调试中。</code></pre><p>（6）禁止金仓数据库使用顺序扫描。</p><pre><code class="sql">scott=# set enable_seqscan = off;</code></pre><p>（7）重新使用explain语句查看SQL查询时的执行计划。</p><pre><code class="sql">scott=# explain select * from emp where lower(ename) like 'king';

# 输出的信息如下：
                              QUERY PLAN                              
----------------------------------------------------------------------
 Index Scan using index_exp on emp  (cost=0.14..8.16 rows=1 width=42)
   Index Cond: (lower((ename)::text) = 'king'::text)
   Filter: (lower((ename)::text) ~~ 'king'::text)
(3 行记录)</code></pre><h2>四、 使用视图简化查询语句</h2><p>当SQL的查询语句比较复杂并且需要反复执行，如果每次都重新书写该SQL语句显然不是很方便。因此金仓数据库数据库提供了视图用于简化复杂的SQL语句。视图（View）是一种虚表，其本身并不包含数据。它将作为一个select语句保存在数据字典中的。视图依赖的表叫做基表。通过视图可以展现基表的部分数据；视图数据来自定义视图的查询中使用的基表。在金仓数据库中创建视图的基本语法格式如下：</p><pre><code class="sql">CREATE [ OR REPLACE ] [ TEMP | TEMPORARY ] [ RECURSIVE ] [ FORCE ] VIEW name [ ( column_name [, ...] ) ]
    [ WITH ( view_option_name [= view_option_value] [, ... ] ) ]
    [ BEQUEATH { CURRENT_USER | DEFINER } ]
    AS query
    [ WITH { [ CASCADED | LOCAL ] CHECK OPTION } | READ ONLY ]</code></pre><p>在了解的视图的作用后，下面通过具体的步骤来演示如何使用视图。<br/>（1）基于员工表emp创建视图。</p><pre><code class="sql">scott=# create or replace view view1
as
select * from emp where deptno=10;

# 视图也可以基于多表进行创建，例如：
scott=# create or replace view view2
as
select emp.ename,emp.sal,dept.dname
from emp,dept
where emp.deptno=dept.deptno;</code></pre><p>（2）查看视图view2的结构。</p><pre><code class="sql">scott=# \d view2

# 输出的信息如下：
                      视图 "public.view2"
 栏位  |            类型            | 校对规则 | 可空的 | 预设 
-------+----------------------------+----------+--------+------
 ename | character varying(10 char) |          |        | 
 sal   | integer                    |          |        | 
 dname | character varying(10 char) |          |        | </code></pre><p>（3）从视图中查询数据。</p><pre><code class="sql">scott=# select * from view2;

# 输出的信息如下：
 ename  | sal  |   dname    
--------+------+------------
 MILLER | 1300 | ACCOUNTING
 CLARK  | 2450 | ACCOUNTING
 KING   | 5000 | ACCOUNTING
 SCOTT  | 3000 | RESEARCH
 JONES  | 2975 | RESEARCH
 SMITH  |  800 | RESEARCH
 ADAMS  | 1100 | RESEARCH
 FORD   | 3000 | RESEARCH
 WARD   | 1250 | SALES
 TURNER | 1500 | SALES
 ALLEN  | 1600 | SALES
 BLAKE  | 2850 | SALES
 MARTIN | 1250 | SALES
 JAMES  |  950 | SALES
(14 行记录)</code></pre><p>（4）通过视图执行DML操作，例如：给10号部门员工涨100块钱工资。</p><pre><code class="sql">scott=# update view1 set sal=sal+100;

# 并不是所有的视图都可以执行DML操作。在视图定义时含义以下内容，视图则不能执行DML操作：
# 1.  查询子句中包含distinct和组函数
# 2.  查询语句中包含group by子句和order by子句
# 3.  查询语句中包含union 、union all等集合运算符
# 4.  where子句中包含相关子查询
# 5.  from子句中包含多个表
# 6.  如果视图中有计算列，则不能执行update操作
# 7.  如果基表中有某个具有非空约束的列未出现在视图定义中，则不能做insert操作</code></pre><p>（5）创建视图时使用WITH CHECK OPTION约束 。</p><pre><code class="sql">scott=# create or replace view view3
as
select * from emp where sal&lt;1000
with check option;

# WITH CHECK OPTION表示对视图所做的DML操作，不能违反视图的WHERE条件的限制。</code></pre><p>（6）在view3上执行update操作。</p><pre><code class="sql">scott=# update view3 set sal=2000;

# 此时将出现下面的错误信息：
# ERROR:  新行违反了视图"view3"的检查选项
# DETAIL:  失败, 行包含(7369, SMITH, CLERK, 7902, 1980/12/17, 2000, null, 20).</code></pre>]]></description></item><item>    <title><![CDATA[大模型赋能下的智能体：企业数字化协同的新引擎 智能猫 ]]></title>    <link>https://segmentfault.com/a/1190000047559573</link>    <guid>https://segmentfault.com/a/1190000047559573</guid>    <pubDate>2026-01-22 19:04:03</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>​<strong>摘要</strong>​：大模型技术的成熟与落地推动智能体从单任务自动化工具升级为全链路数字化协同主体，其凭借自然语言理解、任务自主拆解、跨系统联动核心能力，重构企业内外部协同逻辑，破解传统数字化协同中的信息偏差、响应延迟、流程内耗等痛点。本文系统剖析大模型为智能体赋予的技术能力升级，拆解智能体在企业核心协同场景的应用价值，梳理技术落地的核心挑战，并从技术、流程、安全、组织四大维度提供可落地实施策略，补充行业高频 QA 问答模块覆盖用户核心诉求，为企业把握大模型与智能体融合趋势、构建高效数字化协同体系提供专业参考。</p><p>​<strong>关键词</strong>​：大模型；智能体；企业数字化协同；跨部门协同；AI 落地；数字化转型；多智能体协作</p><h2>一、大模型与智能体的融合：重构企业协同的技术底层</h2><p>大模型是智能体实现智能化协同的核心技术底座，与传统规则化智能体的结合，彻底突破了传统自动化工具的能力边界，实现从“被动执行指令”到“主动理解意图、自主规划执行”的本质升级。</p><p>传统智能体仅能完成预设规则内的单一自动化任务，对非标准化指令理解能力弱，无法实现跨系统、跨场景联动；而大模型凭借海量数据训练形成的自然语言理解（NLU）、逻辑推理、知识生成能力，为智能体赋予三大核心升级：一是精准解读自然语言需求，捕捉显性要求与隐性协作意图，无需标准化指令；二是自主拆解复杂任务，规划最优执行路径；三是跨系统无缝联动，打通企业 CRM、OA、财务等系统的数据与流程，无需人工介入系统切换。</p><p>大模型与智能体深度融合，形成“大模型做决策 + 智能体做执行”的协同模式，让智能体成为企业数字化协同的“超级枢纽”，实现从员工单一需求响应到企业全链路业务协同的技术突破，这也是其成为企业数字化协同新引擎的核心逻辑。</p><h2>二、大模型驱动智能体在企业数字化协同的核心应用场景</h2><h3>2.1 企业内部跨部门协同：打破信息壁垒，实现全流程实时联动</h3><p>跨部门协同是企业数字化转型的核心痛点，传统模式依赖会议、周报同步信息，存在响应延迟、信息偏差、责任模糊等问题，导致项目推进效率低下。</p><p>大模型赋能的智能体以“全流程协同枢纽”为定位，实现跨部门协同的智能化与实时化：接入企业项目管理系统，实时同步各部门工作进度；当某部门提交成果或反馈问题时，智能体解读核心信息并自动推送给关联部门，明确协作要求与时间节点；针对研发、生产、市场、销售全链条项目，自主规划协同路径、动态调整工作安排，若出现产能不足、供应链延迟等突发情况，立即触发预警并联动相关部门生成解决方案。</p><p>例如新品研发项目中，研发部门完成迭代方案后，智能体可自动提取核心参数同步生产部门核实产能，向市场部门推送卖点与推广节点建议，向销售部门同步上市计划，全程无需人工转达，将跨部门协同响应周期缩短 80% 以上。</p><h3>2.2 企业业务全流程协同：从需求到落地的智能化闭环</h3><p>企业单一业务落地涉及多环节、多岗位协作，传统模式下各环节衔接依赖人工，易出现流程断层、执行偏差。大模型驱动的智能体可实现业务全流程智能化协同闭环，覆盖需求发起、任务分配、执行落地到结果反馈全链路。</p><p>以华东地区美妆品类 618 推广活动为例，市场人员仅需输入“策划活动实现销售额环比提升 30%”，智能体即可完成需求拆解：对接销售系统提取历史数据、联动供应链核实库存、制定推广方案、分配设计部门制作物料、协调运营部门线上投放、同步销售部门线下承接；活动执行中实时监控数据，动态调整推广策略；活动结束后自动整合数据生成分析报告，同步管理层与执行部门。</p><p>该模式让智能体承担任务规划、跨岗协调、数据监控、策略优化核心工作，将业务从需求到落地的周期压缩 60% 以上，大幅降低人工执行偏差率。</p><h3>2.3 企业对外服务协同：前端接待与后端支撑的无缝衔接</h3><p>企业对外服务的协同效果直接影响客户体验与商业合作效率，传统模式下一线服务人员因专业能力限制，常需转接后端人员，导致客户等待时间过长、体验不佳。</p><p>大模型赋能的智能体实现“前端接待 + 后端支撑”无缝协同：前端智能体精准解读客户需求，标准化问题直接解答；复杂技术问题、定制化商务需求，自动提取核心信息同步后端部门，快速获取解决方案后反馈前端，由服务人员结合个性化需求优化回复；同时将解决案例录入企业知识库，通过大模型持续优化，提升后续服务响应效率。</p><p>在 ToB 企业技术服务场景中，该模式可将客户问题解决效率提升 70% 以上，客户满意度提升 60%，减轻前后端部门重复沟通压力。</p><h2>三、大模型驱动智能体落地企业数字化协同的核心挑战</h2><h3>3.1 数据安全与隐私保护风险</h3><p>智能体实现协同的核心前提是接入企业核心数据，包括 CRM 客户数据、财务资金数据、供应链商业数据等，部分数据涉及商业机密与用户隐私。若采用公有云部署模式，数据将脱离企业管控边界，存在泄露、滥用风险；多智能体协同中数据流转路径复杂，缺乏完善权限管控易出现越权访问、数据篡改，违反《数据安全法》《个人信息保护法》，给企业带来法律与经济损失。</p><h3>3.2 跨系统适配与业务融合难度</h3><p>不同企业数字化建设水平差异大，部分仍使用老旧系统，部分搭建了多元化系统矩阵，各系统数据格式、接口标准不统一，导致智能体难以深度对接与适配。同时各行业、企业的业务逻辑、专属术语差异显著，通用大模型与智能体无法精准理解个性化需求，易出现解读偏差、执行错误，未进行定制化训练则难以与企业业务深度融合，无法发挥协同价值。</p><h3>3.3 大模型“幻觉”与智能体执行偏差问题</h3><p>大模型的“幻觉”问题是核心技术痛点，即对企业需求理解不充分时，会生成虚假、错误信息与决策，进而导致智能体执行偏差。如数据统计场景中，大模型对统计口径理解偏差将导致智能体提取错误数据、生成错误报告；跨部门任务分配中，对职责边界判断失误将导致任务分配错误。且智能体执行复杂任务时，单一子任务偏差会引发“蝴蝶效应”，人工排查与修正难度大。</p><h3>3.4 企业人员的技术接受度与能力适配问题</h3><p>部分员工对大模型、智能体存在认知偏差，认为其会替代自身工作，产生抵触情绪；同时现有员工缺乏与智能体协同的能力，无法精准表达需求、有效复核执行结果，导致智能体价值无法充分发挥。此外，企业内部缺乏专业的 AI 运营与维护人员，无法对大模型与智能体进行日常调试、更新优化，限制了智能体的深度落地。</p><h2>四、大模型驱动智能体落地企业数字化协同的实施策略</h2><h3>4.1 技术选型：私有化部署为主，定制化训练适配</h3><p>企业落地需坚持“私有化部署为主、公有云服务为辅”原则：核心数据协同场景采用私有化部署，确保数据存储在企业自有服务器，实现全链路管控；非核心标准化场景可调用公有云大模型 API，降低投入成本。基于企业业务逻辑、专属术语、流程规范，对通用大模型进行微调与定制化训练，让其精准理解个性化需求；开发专属接口适配层，实现智能体与 OA、CRM、财务等系统的无缝对接，打破数据与流程壁垒。</p><h3>4.2 流程规范：明确协同边界，建立人工复核机制</h3><p>结合企业业务特点，明确智能体的协同边界与执行权限：数据统计、信息同步、标准化客服等低价值、重复性工作，由智能体全程自主执行；财务审批、核心业务决策、重要商务谈判等高价值、高风险工作，建立“智能体执行 + 人工复核”机制，智能体仅负责信息整理、方案生成，最终决策与执行由人工完成。制定智能体协同标准化流程，明确各部门、岗位的协同职责与要求，规范任务发起、执行、反馈流程，确保协同工作有序开展。</p><h3>4.3 安全体系：全链路管控，实现实时监控与审计</h3><p>构建全链路数据安全管控体系：建立精细化权限管控机制，按岗位、职责分配智能体操作与数据访问权限，遵循“最小权限原则”；对数据提取、传输、存储、分析全环节进行加密处理，防止数据泄露、篡改；搭建实时监控与审计系统，对智能体操作行为、数据访问记录、执行结果全程监控，异常行为立即触发预警并停止执行，所有操作记录留存可追溯、可问责。</p><h3>4.4 组织建设：强化人员培训，搭建专业 AI 运营团队</h3><p>通过多层级、多维度培训，提升员工对大模型、智能体的认知与接受度，明确其核心价值是释放人力而非替代工作，引导员工主动拥抱变革；开展针对性技能培训，提升员工精准表达需求、复核执行结果、与智能体协同工作的能力，快速适配新工作模式。搭建专业的 AI 技术运营与维护团队，成员涵盖 AI 算法工程师、大数据工程师、企业业务专家，负责大模型与智能体的日常调试、更新优化，解决执行中的技术问题，结合企业业务发展持续迭代智能体协同能力。</p><h3>4.5 落地路径：从单点试点到全流程覆盖，渐进式推广</h3><p>遵循“先易后难、从单点场景到全流程覆盖”的渐进式路径，规避技术与管理风险：首先选择数字化基础好、需求标准化程度高的场景试点，如行政信息同步、人力资源考勤统计、标准化客服接待，快速验证价值、积累经验；试点成功后，逐步推广至跨部门协同、业务流程协同等复杂场景；最终实现全流程协同深度落地，推动多智能体协同网络构建，实现不同功能智能体的联动协作。</p><h2>五、大模型与智能体融合的未来发展趋势</h2><h3>5.1 单智能体向多智能体协作网络升级</h3><p>企业数字化协同将从单智能体执行向多智能体协作网络发展，企业将按业务需求部署数据处理、沟通协调、风险预警、决策支持等不同功能的智能体，各智能体通过大模型实现信息共享、任务协同、能力互补，形成智能化协同网络。如企业战略规划中，数据处理智能体提取内外部数据，风险预警智能体分析市场与行业风险，决策支持智能体生成规划方案，沟通协调智能体同步各部门并收集反馈，多智能体协同的效率与精准度远超人工。</p><h3>5.2 智能体向“人机共生”的协同模式演进</h3><p>技术的持续迭代将推动企业协同向“人机共生、优势互补”模式发展：智能体承担所有重复性、标准化、低价值协同工作，员工从繁琐日常中解脱，聚焦创意策划、战略决策、客户关系维护等高价值、非标准化工作。同时，智能体将成为员工的“个性化智能助手”，根据员工工作习惯、能力特点提供定制化工作建议与协同支持，实现人机协同的精准化与个性化，提升企业整体效率与创新能力。</p><h3>5.3 跨企业智能体协同成为行业新方向</h3><p>随着技术成熟，智能体的协同边界将从企业内部延伸至企业与企业之间，实现产业链、供应链的跨企业智能体协同。如制造企业智能体与上游原材料供应商、下游经销商智能体实时联动，生产计划、产能库存、销售数据自动同步，实现全产业链智能化协同，提升整体运行效率。</p><h3>5.4 技术门槛持续降低，普惠化趋势凸显</h3><p>未来大模型与智能体研发将向普惠化发展，头部科技企业将推出更多标准化、低代码、零代码的开发与部署平台，企业无需专业 AI 研发能力，通过简单拖拽、配置即可搭建适配自身业务的智能体，大幅降低技术与资金门槛。同时大模型“幻觉”问题将得到有效解决，智能体执行精度与可靠性持续提升，为大模型与智能体在中小企业数字化协同中的广泛落地奠定基础。</p><h2>六、行业高频 QA 问答</h2><h3>6.1 大模型驱动的智能体，适合中小微企业落地吗？</h3><p>适合。中小微企业无需自建大模型，可通过调用第三方大模型 API（如 GPT-4o、文心一言 4.0）或使用低代码/零代码智能体平台（如 Coze），低成本接入智能体能力。建议优先选择标准化协同场景（如行政信息同步、标准化客服）试点，验证价值后再逐步推广，无需投入大量技术与人力成本，反而能快速解决中小微企业跨部门协同效率低、人力不足的核心痛点。</p><h3>6.2 企业落地协同智能体，需要先完成全流程数字化改造吗？</h3><p>不需要。协同智能体可适配企业现有数字化基础，支持“渐进式融合”：即使企业仅部分系统完成数字化，也可先让智能体对接现有数字化系统（如 CRM、OA），在已有数字化环节实现协同优化；未数字化的环节可通过智能体的自然语言交互、轻量化表单等功能，实现半自动化协同，后续再逐步推进全流程数字化改造，降低落地门槛。</p><h3>6.3 如何判断企业的协同场景是否适合引入智能体？</h3><p>核心判断标准有 3 点：1. 场景是否存在重复性工作（如固定格式的报表生成、标准化信息同步）；2. 是否存在跨岗位/跨部门的高频沟通对接；3. 需求是否具备可明确描述的目标（如“缩短数据统计时间”“提升客户响应效率”）。满足以上任意 2 点的场景（如跨部门项目协同、客服前后端对接、业务数据汇总），引入智能体后提升效果更显著。</p><h3>6.4 协同智能体与传统 OA 系统的区别是什么？</h3><p>核心区别在于“被动响应”与“主动协同”：传统 OA 系统需人工发起流程、手动选择对接对象，仅能完成预设流程的流转记录；协同智能体可主动理解需求、自主拆解任务、自动联动跨系统与跨部门资源，无需人工干预即可推进协同落地，还能通过大模型分析数据并优化协同策略，具备更强的智能化与自主性，覆盖 OA 系统无法触达的非标准化协同场景。</p><h3>6.5 企业落地协同智能体后，员工的工作会被替代吗？</h3><p>不会完全替代，而是实现“能力升级与分工重构”。智能体仅替代重复性、标准化的协同工作（如信息同步、数据录入、简单报表生成）；员工将聚焦高价值工作，如需求定义、协同策略规划、核心决策、复杂问题协调等，从“繁琐执行”转向“战略把控”，同时需要掌握与智能体协同的基础能力（如精准表达需求、复核执行结果），提升自身不可替代性。</p><h2>七、结论</h2><p>大模型与智能体的深度融合，正重构企业数字化协同的底层逻辑，从技术层面打破传统协同的信息、流程、数据壁垒，为企业提供更高效、智能、低成本的协同解决方案，成为企业数字化转型深水区的核心新引擎。</p><p>大模型驱动的智能体落地，并非简单的技术叠加，而是企业技术、流程、组织、人员的全方位变革。企业需正视数据安全、技术适配、执行偏差等挑战，通过科学的技术选型、完善的流程规范、严密的安全体系、系统的人员培训，实现智能体的渐进式落地与深度融合。</p><p>未来，多智能体协作网络、跨企业智能体协同将成为主流趋势，人机共生的协同模式将彻底释放企业人力价值与创新能力。对于企业而言，主动拥抱这一技术变革，构建适配自身业务的智能化协同体系，将成为提升核心竞争力、实现高质量发展的关键所在。</p><h2>八、参考文献</h2><p>[1] 斯坦福大学. AI 指数报告 2026[R]. 斯坦福大学人类与人工智能研究院,2026. [2] 中国人工智能产业发展联盟. 大模型与智能体融合应用白皮书 2026[R]. 2026. [3] 麦肯锡咨询. 企业数字化协同转型趋势与实践指南 2026[R]. 麦肯锡全球研究院,2026. [4] 腾讯云 AI 研究院. 大模型私有化部署与企业应用实践 2026[R]. 2026. [5] 字节跳动 AI 实验室. Coze 智能体平台企业协同场景应用指南 2026[R]. 2026. [6] 德勤咨询. 企业 AI 技术落地的风险管控与实施策略 2026[R]. 2026.</p>]]></description></item><item>    <title><![CDATA[从“形似”到“神合”：电子签章如何成为手写签名与实体公章的法律等效体？ 俊秀的小摩托_bWeu86 ]]></title>    <link>https://segmentfault.com/a/1190000047559577</link>    <guid>https://segmentfault.com/a/1190000047559577</guid>    <pubDate>2026-01-22 19:03:08</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>“电子签章”是电子签名的一种可视化表现形式。它不仅仅是一个简单的图片，而是一套由法律背书的、具备完整密码技术的安全解决方案。可以将其理解为传统物理公章或手写签名的数字化、法律等效体。</p><p>核心组成部分</p><p>一个有效的电子签章通常包含两大核心部分：</p><p>Ø 可视化的印章图片</p><p>这就是我们通常“看到”的电子签章，外观上模仿了实体公章或签名样式。</p><p>作用： 提供与传统方式一致的可视化确认，让人直观地知道签署方和签署位置。</p><p>Ø 数字证书与密码技术</p><p>这是电子签章的“灵魂”，是法律效力的关键。</p><p>数字证书： 由依法设立的电子认证服务机构（CA机构） 颁发，相当于一个实体的“网络身份证”。它绑定了签署方的真实身份。</p><p>数字签名： 在签署时，系统会使用与数字证书对应的私钥对文件进行运算，生成一个唯一的“数字指纹”（哈希值），并锁定文件内容。任何对文件的篡改都会导致指纹失效</p><p>电子签章的法律效力</p><p>在中国，电子签章具有明确的法律效力。《中华人民共和国电子签名法》 第十三、十四条明确规定：</p><p>可靠的电子签名与手写签名或者盖章具有同等的法律效力。同时规定了何为“可靠的电子签名”，核心就是身份真实、签署意愿真实、文件原文未改、签名未改。</p><p>满足上述条件的电子签章，在民事活动中（如合同、票据、公文）具有完全的法律效力。除了法律规定的少数特殊情况（如涉及婚姻、收养、继承的人身关系文书，以及涉及停止供水、供热、供气等公用事业服务的文书），绝大多数场景均可使用。</p><p>电子签章是中国数字化转型中的关键一环。它不是一个简单的图片水印，而是一个集身份认证、数字签名、时间戳和存证保全于一体的完整法律和技术解决方案。它的普及极大地提升了企业运营效率，降低了成本，并确保了电子文件的法律。</p>]]></description></item><item>    <title><![CDATA[面向多租户云的 IO 智能诊断：从异常发现到分钟级定位 阿里云云原生 ]]></title>    <link>https://segmentfault.com/a/1190000047559579</link>    <guid>https://segmentfault.com/a/1190000047559579</guid>    <pubDate>2026-01-22 19:02:18</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>作者：肖振威</p><h2>背景</h2><p>随着云端业务规模的持续扩大，AI 训练数据、实时日志与多媒体资料等数据量呈现指数级增长，云存储因此逐渐成为主流选择，同时也带来了 I/O 请求量的快速上升。在共享式的多租户架构中，多个租户共同使用底层存储资源，高并发访问极易引发 I/O 资源争抢与性能瓶颈。此外，混合云与多云部署日益普及，数据在多个云环境之间频繁流动，而不同云服务商在存储策略与监控机制上的不一致，使得 I/O 类故障的定位与追溯变得更加复杂。为提升此类问题的处理效率，阿里云云监控 2.0 结合 SysOM 智能诊断功能围绕常见的 I/O 异常场景，构建了一套覆盖“异常检测—根因分析—修复建议”全链路的 I/O 一键诊断功能。</p><h2>业务痛点解析</h2><h3>痛点一：用户难以准确判断 IO 异常类型</h3><p>大多数用户对 IO 问题的具体类型缺乏清晰认知，例如往往搞不清当前是 IO 延迟升高、IO 吞吐被打满，还是其它类型的异常，导致很难主动选用对应的排障工具和方法，只能依靠运维专家介入排查，整体诊断效率偏低，人力投入也随之增加。IO 一键诊断聚焦 IO 延时偏高、流量异常、iowait 居高不下等高频场景，自动捕捉 IO 子系统的异常特征，帮助用户快速完成问题类型的判定。</p><h3>痛点二：异常发生瞬间难以“抓现场”，取证不充分</h3><p>传统监控系统通常只采集操作系统层面的通用 IO 指标，比如 await、util、tps、bps 等，并以指标突变作为告警条件。然而，当指标被检测到异常时，真实问题往往已经发生甚至结束，此时再想获取更细致的采样和上下文信息，往往为时已晚，关键线索已经流失，难以形成完整的诊断证据链。要做到有效定位，就必须尽可能在异常刚出现或仍在持续时就触发针对性采集，因此，快速识别并及时行动，是获取最佳诊断数据的关键。</p><h3>痛点三：指标体系割裂，监控数据与诊断结论之间缺乏直连</h3><p>现有监控往往仅提供一组相互独立的指标，彼此缺乏联动，也没有与具体 IO 故障类型建立直观映射。以 util（磁盘繁忙度）偏高为例，实际分析时还需参考 await 等多项指标，并结合设备的理论 iops、bps 上限进行综合判断。即便勉强推断出问题类型，接下来仍离不开对各种诊断工具的经验性操作，包括如何按照指标数值选择合适的采样区间、参数配置等。IO 一键诊断的设计目标，就是将这一串复杂的关联分析与工具选型过程封装在系统内部，对用户直接呈现整理好的诊断报告和结论。</p><h2>解决方案</h2><h3>架构介绍</h3><p>在阿里云云监控 2.0 中，SysOM 管控模块原本就支持对 IO 延迟异常、IO 量异常以及 iowait 高等问题开展诊断。不过，大部分客户并不希望在业务环境上长时间运行高频诊断程序，以免对生产带来干扰。因此，IO 一键诊断采用了“监控先行、按需抓取”的架构：在用户指定的诊断时间段内，系统定期读取 IO 监控指标，用于异常识别与问题圈定，一旦满足条件，再触发具体的子诊断工具进行深度分析并输出报告，构成一个从发现到定位的闭环流程。</p><p>考虑到不同业务类型对 IO 行为和性能阈值的容忍度不尽相同，如果强行规定统一的固定阈值，势必会导致误报大量增加或严重漏报。因此，IO 一键诊断引入“动态阈值”机制进行异常识别，其总体处理链路可以概括为：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559581" alt="image" title="image"/></p><ul><li><strong>指标采集：</strong> 定期从系统中抓取关键 IO 指标，如 await、util、tps、iops、qu-size、iowait 等。</li><li><strong>异常检测：</strong> 当采集到的指标突破动态阈值，就将其标记为潜在异常。动态阈值的计算方法是整个检测环节的核心，后文会展开说明。</li><li><strong>自动诊断触发：</strong> 依据异常的指标类型与特征，自动选择合适的诊断工具，并设置触发频率限制，避免频繁调用。</li><li><strong>结果处理与展示：</strong> 对诊断输出进行归纳和可视化呈现，为用户提供导致问题的根本原因以及可执行的优化建议。</li></ul><h3>实现原理</h3><h4>指标采集机制</h4><p>当用户在控制台启动 IO 一键诊断后，系统会按配置好的时间间隔（cycle 毫秒）循环读取 iowait、iops、bps、qusize、await、util 等一系列 IO 指标，并在每个周期对最新采集的数据做异常检测判断。</p><p><strong>动态阈值计算</strong></p><p>为了能在秒级甚至更细粒度下捕获 IO 突发、短时抖动等异常，必须将各类单一 IO 指标联动起来，从整体上刻画 IO 子系统的“正常波动区间”。动态阈值就是用来界定这一“正常区间”和“异常尖峰”的边界。其计算过程主要分为三层：基础阈值、补偿阈值和最小静态阈值。</p><p>基础阈值：刻画整体波动幅度</p><p>从时间序列的角度看，IO 指标在大多数时刻处于平稳运行状态，曲线起伏较小；当出现异常负载或者突发流量时，曲线会突然出现明显偏离均值的峰值。因此，首要任务是利用基础阈值，找出这些显著高于日常波动的“尖峰”。</p><p>实现策略是：使用一个滑动时间窗口持续观察数据点，在每个窗口中计算所有点相对于窗口平均值的“最大偏离量”，把这个偏离量记为该窗口的“瞬时波动值”；随后对连续多个窗口的“瞬时波动值”求平均，形成动态更新的“基础阈值”。随着新数据不断进入，该阈值也会自适应地调整，始终反映 IO 指标近期的真实波动特征。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559582" alt="image" title="image" loading="lazy"/></p><p>补偿阈值：削弱基础阈值快速下降带来的误报</p><p>基础阈值曲线（如示意图中的黄色线条）虽然能够反映指标的总体波动情况，但在系统处于稳定期时，IO 指标通常只在很窄的一段区间内轻微波动，此时基础阈值可能随波动减弱而快速下降，容易让一些微小的正常抖动被误判为异常。因此，需要额外引入一个“补偿阈值”，叠加在基础阈值之上，对其下降速度进行一定缓冲，从而抑制误报。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559583" alt="image" title="image" loading="lazy"/></p><p>具体逻辑是：当系统监测到基础阈值在一段时间内持续走低，可以认为当前进入了相对“安静”的常态阶段。此时先过滤明显噪声点，再在剩余的稳定数据里计算一个“常稳态补偿值”，以刻画这类稳定状态下的细小波动。补偿值尚未收敛前，先用当前窗口内出现过的最大基础阈值暂时代替，并在每个新窗口开始时重新计算。一旦基础阈值停止下降或开始回升，就意味着系统波动模式发生了变化，此时补偿机制会被重置，重新进入更宏观的观察期。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559584" alt="image" title="image" loading="lazy"/></p><p>最小阈值：兜底的静态门槛</p><p>最小静态阈值可以理解为预先设定的“绝对下限”，是业务方能接受的最低告警基线。最终用于判定异常的阈值，是“最小静态阈值”和“动态调整阈值（基础阈值 + 补偿值）”之间的较大者。只有当指标既超过了日常波动的正常范围，又突破了业务底线时，才真正被视为异常事件。</p><p>此外，如果指标本身已经明显高于“最小静态阈值”，则无需再额外叠加常态补偿值，此时仅以基础阈值作为判断依据即可，将分析重点聚焦在更显著的异常波动上。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559585" alt="image" title="image" loading="lazy"/></p><p><strong>异常识别策略</strong></p><p>在运行时，一旦采集到的某项 IO 指标值高于其对应的动态阈值，即可认为存在异常风险。虽然不同指标（如 iowait、util、iops 等）的判定逻辑略有差异，但整体遵从以下共通规则：</p><ul><li><strong>确定告警基线：</strong> 为每一类指标定义一条“警戒线”，其数值为“最小静态阈值”和“动态阈值”中的最大值，既考虑业务底线，也考虑历史波动范围。</li><li><strong>决定是否触发诊断：</strong> 当监控值超过警戒线，同时满足一定的监测条件（如持续时间、触发次数等），就可以启动对应的诊断流程。</li><li><strong>持续更新模型：</strong> 随着新数据不断加入，动态阈值会被持续修正，使其适配当前环境的正常波动模式，而非依赖一次性的静态配置。</li></ul><p><strong>智能诊断与频率控制</strong></p><p>当系统确认存在 IO 异常后，一键诊断模块会自动调用相应的分析工具，抓取关键现场信息并进行自动化处理，帮助用户快速锁定问题。为避免过于频繁的诊断操作影响业务，系统通过以下两个参数对诊断频率进行约束：</p><ul><li><strong>诊断冷静期（triggerInterval）：</strong> 规定两次诊断之间必须间隔的最短时间，用来避免在短时间内重复对同一类异常进行频繁扫描。</li><li><strong>异常累积阈值（reportInterval）：</strong> 设置触发诊断所需的异常累积条件。当该值为 0 时，只要异常满足冷静期结束的条件，就立即启动诊断；当该值为非 0 时，则需要在冷静期之后、限定时间窗口内出现一定次数的异常事件，才会真正触发。</li></ul><p><strong>根因分析</strong></p><p>在完成现场数据采集之后，面对复杂多样的系统信息，如何从中筛选出与当前问题强相关的线索，是传统人工分析的难点。IO 一键诊断在工具层面内置了一套自动分析逻辑，能从采集结果中提炼结论，并以结构化信息的形式反馈给用户，包括但不限于：</p><ul><li><strong>IO Burst 场景：</strong> 分析在异常时间段内各进程对 IO 的贡献度，在报告中标明最“耗 IO”的进程。对于写 buffer IO 而由内核 kworker 线程负责刷脏的情况，也能追溯到最初发起写入的用户进程。</li><li><strong>IO 延迟异常：</strong> 统计并展示异常区间内 IO 延迟的整体分布情况，标记延迟最高的路径（如对应的设备或文件/目录），帮助快速找到性能瓶颈所在。</li><li><strong>iowait 异常偏高：</strong> 记录和展示导致 iowait 偏高的关键进程，以及引发大量等待的具体原因（例如磁盘被占满、脏页刷写过慢等）。</li></ul><h4>案例分析</h4><p><strong>iowait 高</strong></p><p>在某些场景下，业务反馈系统整体响应慢，通过监控发现 iowait 指标异常升高。借助 IO 一键诊断，可以直接定位到哪一个或哪些进程在大量等待磁盘 IO，以及每个进程累计等待的时间长度，并进一步分析等待背后的原因。</p><p>在示例案例中，诊断结果显示：业务写入量过大导致 IO 压力偏高，系统中脏页堆积，最终使业务进程 task_server 长时间阻塞在 IO 等待上。针对这种情况，报告建议谨慎下调 dirty_ratio、dirty_bytes 等内核参数，以减少一次性刷脏量，降低磁盘压力，从而缓解 iowait 过高问题。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559586" alt="image" title="image" loading="lazy"/></p><p><strong>IO延迟高</strong></p><p>另一类常见问题是写 IO 的延迟持续走高。某用户通过基础监控发现写入延迟异常后，通过 IO 一键诊断进行进一步排查。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559587" alt="image" title="image" loading="lazy"/></p><p>诊断报告指出，在问题发生期间，DiskBlockWrite 进程是主要的 IO 负载来源，并且耗时主要集中在刷脏阶段，也就是说核心瓶颈在于磁盘将缓存数据落盘的过程。依据这一结论，系统给出两类优化建议：一是调整业务逻辑，减少短时间内大量 buffer IO 的写入；二是通过适当调整 dirty_ratio、dirty_background_ratio 等参数，控制脏页生成和回写的节奏，从系统层面降低写 IO 延迟。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559588" alt="image" title="image" loading="lazy"/></p><p><strong>相关链接：</strong></p><p>[1] IO 一键诊断</p><p><a href="https://link.segmentfault.com/?enc=EILpTAWQvMWl7VhMN2kknQ%3D%3D.S1KJ8Uny7RhaQrZ2LwW1OQFT2waWaGNXB%2Bs7CTL3RZin7HlfuH5EfSR%2FBJ3bJZSsIqu1MN%2B16uO6upBLceyQ%2FRWT0RHO%2BMAlL8J76AiJNSQ%3D" rel="nofollow" target="_blank">https://help.aliyun.com/zh/cms/cloudmonitor-2-0/io-key-diagnosis</a></p><p>[2] 云监控-ECS 洞察-SysOM 系统诊断</p><p><a href="https://link.segmentfault.com/?enc=ijYbm7lL3jBPXSc9Nl7bDA%3D%3D.9nL3%2F9RsNolcax8cD5Ti8pgJMxLOexq6Ab7VyaouIX%2FpWe4lzXO%2BRJXI2fF%2FADy5Up2FIHD9G%2FpCC7ZUbxRqcgb%2FBo7JMg72ARpbCZOoh%2Fp1lKZ84Lez9MX2p074uonNT%2FJcR6jlPHkB14%2FBX1ujSQ8Oi7%2FH7ny0u3Pjhm%2Bq4dnsm2qxxvuaa%2BtjmHmx59U5" rel="nofollow" target="_blank">https://cmsnext.console.aliyun.com/next/region/cn-shanghai/wo...</a></p><p>[3] 操作系统控制台实例纳管</p><p><a href="https://link.segmentfault.com/?enc=Qwax6No2qXANl1iTj0FsUw%3D%3D.g88lSm%2FMj1R9MyALoDg89QsaZoAgma0PVouaHFKK3eggvZ%2FfO8mZKbppNtYJn9ENXpmRUHGCxhFPdXVPHbp5Uw%3D%3D" rel="nofollow" target="_blank">https://help.aliyun.com/zh/alinux/user-guide/system-management</a></p>]]></description></item><item>    <title><![CDATA[阿里云微服务引擎 MSE 及 API 网关 2025 年 12 月产品动态 阿里云云原生 ]]></title>    <link>https://segmentfault.com/a/1190000047559600</link>    <guid>https://segmentfault.com/a/1190000047559600</guid>    <pubDate>2026-01-22 19:01:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><img width="723" height="1955" referrerpolicy="no-referrer" src="/img/bVdnIAt" alt="image.png" title="image.png"/></p>]]></description></item><item>    <title><![CDATA[Bingo 大屏幕互动游戏系统：引爆现场氛围的全能互动解决方案 微擎应用市场 ]]></title>    <link>https://segmentfault.com/a/1190000047559200</link>    <guid>https://segmentfault.com/a/1190000047559200</guid>    <pubDate>2026-01-22 18:11:43</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><strong>一、概述总结</strong><br/>Bingo 大屏幕是厦门掌界网络推出的一款适配微信公众号的现场互动游戏系统，以简单耐玩的数字连线玩法为核心，助力各类线下场景活跃气氛、留存客户。系统支持微擎系统在线交付，提供源码未加密的官方正品保障，服务周期内可免费更新，既能通过趣味互动解决现场氛围冷清、客户等待无聊等问题，又能搭配抽奖功能实现用户留存与二次转化，是多场景下的高效互动工具。</p><p><strong>二、功能介绍</strong><br/>视觉与时间自定义：大屏幕支持自定义背景、背景音乐，可灵活设置倒计时与游戏时长，适配不同场景氛围需求。</p><p>多轮互动无缝衔接：支持多批次游戏功能，一局结束后可快速开启下一局，持续带动现场热度。</p><p>抽奖规则灵活配置：后台可自由选择是否开启抽奖功能，奖品涵盖实物、微信卡券、红包、微擎积分 / 余额等，支持自定义奖品数量与中奖概率。</p><p>中奖限制更合理：可设置每人最高中奖次数及红包总额上限，避免重复中奖，保障活动公平性。</p><p>红包发放双模式：红包奖品支持直接发送与提现两种方式，满足大额红包奖励的发放需求。</p><p>参与条件可控：支持开启或关闭 “强制关注” 功能，助力公众号涨粉；自带 LBS 地区限制功能，可精准划定参与人群范围。</p><p>账号适配说明：仅支持认证服务号使用（红包功能需开通微信支付），非认证服务号可借用权限（不可使用卡券功能）。</p><p><strong>三、适用场景与行业价值</strong><br/>适用场景<br/>广泛适配年会、婚礼、酒吧、餐厅、KTV、线下活动、学校及企事业单位活动等场景，尤其针对人群聚集等待、需要活跃气氛的场景效果显著。</p><p>行业价值<br/>餐饮行业：解决高峰期客户排队无聊问题，通过抽奖发放优惠券、代金券，牢牢留住客户，促进二次到店消费。</p><p>活动策划行业（年会、婚礼、线下活动）：快速调动现场氛围，打破冷场尴尬，通过趣味互动增强参与者体验与记忆点。</p><p>本地自媒体：可拉取商家赞助开展活动，既能为粉丝提供福利，又能拓宽盈利渠道，提升账号活跃度。</p><p>微信运营服务提供商：为合作客户提供多样化互动解决方案，丰富服务内容，增强客户粘性。</p><p>酒吧、KTV 等娱乐场所：为消费者增添互动乐趣，延长停留时间，提升消费意愿，打造差异化经营优势。</p><p><strong>四、问答环节</strong><br/>系统支持哪些账号类型使用？红包功能有什么要求？<br/>答：仅支持认证服务号使用，红包功能需开通微信支付；非认证服务号可借用权限，但无法使用卡券功能。</p><p>奖品类型可以自定义吗？能否限制用户中奖次数？<br/>答：奖品支持实物、微信卡券、红包等多种类型，可自定义数量与概率；同时可设置每人最高中奖次数及红包总额上限。</p><p>如何防止非目标地区的用户参与活动？<br/>答：系统自带 LBS 限制地区功能，可在后台设置参与人的地区范围，精准锁定目标人群。</p><p>游戏结束后能否快速开启下一轮？<br/>答：支持多批次功能，一局结束后可立即启动下一局，无需重复设置，保障互动连续性。</p>]]></description></item><item>    <title><![CDATA[速码！TinyPro 移动端适配上线，打造桌面 - 掌心无差别体验 OpenTiny社区 ]]></title>    <link>https://segmentfault.com/a/1190000047559268</link>    <guid>https://segmentfault.com/a/1190000047559268</guid>    <pubDate>2026-01-22 18:11:00</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>本文由TinyPro贡献者王晨光同学原创。</p><h2>一、背景：让 TinyPro 真正“走到掌心里”</h2><p>TinyPro 是一套基于 <strong>TinyVue</strong> 打造的前后端分离后台管理系统，支持菜单配置、国际化、多页签、权限管理等丰富特性。<br/>TinyPro 在桌面端具备良好的体验和模块化架构，但随着移动办公、平板展示等场景增多，移动端体验的短板逐渐显现：</p><ul><li>页面缩放不均衡，布局出现溢出或错位；</li><li>模态框在小屏上遮挡内容；</li><li>图表和表格在横屏与竖屏间切换时无法自适应；</li><li>操作区过于密集，不符合触控习惯。</li></ul><p>为此启动了 <strong>TinyPro 移动端适配项目</strong>，目标是在不破坏现有结构的前提下，实现“<strong>一次开发，跨端流畅</strong>”的体验。</p><h2>二、技术选型与总体架构</h2><p>本次移动端适配要求在复杂的中后台系统中实现「一次开发，多端自适应」，既要保证样式灵活，又要维持可维护性和构建性能。</p><p>在技术选型阶段，综合评估了三种常见方案：</p><table><thead><tr><th>方案</th><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td>纯 CSS 媒体查询</td><td>简单直接、依赖少</td><td>样式分散、逻辑重复、维护困难</td></tr><tr><td>TailwindCSS 响应式类</td><td>社区成熟、类名直观、生态完善</td><td>样式表体积大、断点固定、不够灵活</td></tr><tr><td><strong>UnoCSS 原子化方案</strong></td><td>按需生成、性能极轻、断点与变体完全可定制</td><td>需要自行配置规范与规则体系</td></tr></tbody></table><p>最终选择了 <strong>UnoCSS + Less 的混合架构</strong>：</p><ul><li><strong>UnoCSS</strong>：负责通用布局、间距、排版等高频样式，原子化写法提升开发效率；</li><li><strong>Less 媒体查询</strong>：用于模态框、导航栏等复杂场景的精细控制；</li><li><strong>统一断点配置</strong>：集中管理屏幕尺寸分级，保持视觉一致性；</li><li><strong>自定义变体（<code>max-&lt;bp&gt;</code>）</strong>：支持“桌面端优先”策略，通过 max-width 实现移动端自适应，样式逻辑更直观。</li></ul><h3>UnoCSS：轻量、灵活、即时生成</h3><p>UnoCSS 是一个 <strong>按需生成的原子化 CSS 引擎</strong>，最大的特点是 <strong>零冗余与高度可定制</strong>。<br/>不同于 TailwindCSS 的预编译方式，UnoCSS 会在构建阶段根据实际使用的类名即时生成样式规则，从而显著提升构建性能与灵活性.</p><p>在配置中通过 <code>presetMini()</code> 与 <code>presetAttributify()</code> 组合使用，使开发者既可以写：</p><pre><code class="vue">&lt;div class="p-4 text-center bg-gray-100 max-md:p-2"&gt;&lt;/div&gt;</code></pre><p>也可以使用属性化语法：</p><pre><code class="vue">&lt;div p="4" text="center" bg="gray-100" max-md:p="2"&gt;&lt;/div&gt;</code></pre><p><code>presetMini</code> 提供轻量原子类体系，<code>presetAttributify</code> 则允许以声明式方式书写样式，更直观、组件化友好。</p><h3>断点配置与响应式策略</h3><p>TinyPro 的适配核心之一，是在 <code>uno.config.ts</code> 中建立统一的断点体系，并通过自定义 <code>max-&lt;bp&gt;</code> 前缀实现“桌面端优先”的响应式策略。</p><pre><code class="typescript">const breakpoints = {
  sm: '641px',     // 手机（小屏）
  md: '769px',     // 平板竖屏
  lg: '1025px',    // 平板横屏 / 小型笔电
  xl: '1367px',    // 常规笔电
  '2xl': '1441px', // 高清笔电
  '3xl': '1921px', // 桌面大屏
}</code></pre><p>并通过自定义 <code>variants</code> 扩展 <code>max-&lt;bp&gt;</code> 前缀:</p><pre><code class="typescript">variants: [
    (matcher) =&gt; {
      const match = matcher.match(/^max-([a-z0-9]+):/)
      if (match) {
        const bp = match[1]
        const value = breakpoints[bp]
        if (!value) return
        return {
          matcher: matcher.replace(`max-${bp}:`, ''),
          parent: `@media (max-width: ${value})`,
        }
      }
    },
  ]</code></pre><p>让开发者能自然地书写：</p><pre><code class="vue">&lt;div class="w-1/2 max-md:w-full"&gt;&lt;/div&gt;</code></pre><p>含义：</p><blockquote>默认宽度为 50%，在宽度小于 769px 的设备上改为 100%。</blockquote><p>TinyPro 采用「桌面端优先（max-width）」的布局策略：默认以桌面端布局为基础，在移动设备上再进行针对性优化。相比常见的「移动端优先（min-width）」方式，这种做法更符合中后台系统的特性，同时让 UnoCSS 的断点逻辑更直观，并确保主屏体验的稳定性。</p><h2>三、样式与编码策略</h2><ul><li><p><strong>优先级</strong></p><ul><li>简单场景：使用 UnoCSS 原子类。</li><li>复杂样式：使用 Less 媒体查询。</li></ul></li><li><p><strong>布局与滚动</strong></p><ul><li>首页及核心业务模块完成适配，小屏模式下侧边栏默认收起、导航栏折叠，确保主要内容可见。</li><li>页面主要容器避免横向滚动，必要时在小屏下开启局部横向滚动。</li><li>表格与大区块在不同断点下自动调整宽度、栅格与间距，小屏下支持横向滚动；分页与密度支持响应式控制。</li></ul><p><img width="723" height="368" referrerpolicy="no-referrer" src="/img/bVdnIuQ" alt="布局与滚动.gif" title="布局与滚动.gif"/></p></li><li><p><strong>图表自适应</strong></p><ul><li>图表组件接入 <code>resize</code> 监听，在侧边栏展开/收起、窗口缩放、语言切换等场景下保持自适应。</li><li>小屏下使用 <code>vw</code> 宽度与较小字号，保证图表展示效果与可读性。</li></ul><p><img width="723" height="368" referrerpolicy="no-referrer" src="/img/bVdnIuS" alt="图表自适应.gif" title="图表自适应.gif" loading="lazy"/></p></li><li><p><strong>表单与模态框</strong></p><ul><li>接入 <code>useResponsiveSize()</code>，控制弹窗在小屏下铺满显示，大屏保持固定宽度。</li><li>表单项在不同断点下动态调整排布与间距，优化触控体验。</li></ul><p><img width="723" height="368" referrerpolicy="no-referrer" src="/img/bVdnIuU" alt="表单与模态框.gif" title="表单与模态框.gif" loading="lazy"/></p></li><li><p><strong>导航与交互</strong></p><ul><li>小屏下隐藏导航栏非关键元素，操作聚合到"折叠菜单"。</li><li>移动端默认收起侧边菜单栏，提升主要内容展示区域。</li></ul><p><img width="723" height="368" referrerpolicy="no-referrer" src="/img/bVdnIuW" alt="导航与交互.gif" title="导航与交互.gif" loading="lazy"/></p></li><li><p><strong>性能优化</strong></p><ul><li>在 <code>responsive.ts</code> 中对 <code>resize</code> 事件处理增加节流机制，避免窗口缩放等场景下的频繁无效渲染。</li></ul></li></ul><h2>四、常用代码片段</h2><ol><li>基于栅格系统 + 响应式断点工具类，通过为 tiny-row 和 tiny-col 添加不同屏幕宽度下的样式规则，实现自适应布局：</li></ol><pre><code class="vue">&lt;tiny-layout&gt;
    &lt;tiny-row class="flex justify-center max-md:flex-wrap"&gt;
        &lt;tiny-col class="w-1/4 max-md:w-1/2 max-sm:w-full max-md:mb-4"&gt;···&lt;/tiny-col&gt;
        ···
        &lt;tiny-col class="w-1/4 max-md:w-1/2 max-sm:w-full max-md:mb-4"&gt;···&lt;/tiny-col&gt;
    &lt;/tiny-row&gt;
&lt;/tiny-layout&gt;
</code></pre><pre><code class="vue">&lt;div class="theme-line flex max-sm:grid max-sm:grid-cols-4 max-sm:gap-2"&gt;
  &lt;div···
  &lt;/div&gt;
&lt;/div&gt;</code></pre><ol start="2"><li>基于 响应式工具类 + 自定义响应式 Hook,解决(1)对话框宽度自适应;(2)表格尺寸和密度自适应;(3)逻辑层响应式控制</li></ol><pre><code class="vue">&lt;template&gt;
  &lt;section class="p-4 sm:p-6 lg:p-8 max-sm:text-center"&gt;
    &lt;tiny-dialog :width="modalSize"&gt;...&lt;/tiny-dialog&gt;
  &lt;/section&gt;
&lt;/template&gt;

&lt;script setup lang="ts"&gt;
import { useResponsiveSize } from '@/hooks/responsive'
const { modalSize } = useResponsiveSize() // 小屏 100%，大屏 768px
&lt;/script&gt;</code></pre><pre><code class="vue">&lt;template&gt;
  &lt;div class="container"&gt;
    &lt;tiny-grid ref="grid" :fetch-data="fetchDataOption" :pager="pagerConfig" :size="gridSize" :auto-resize="true" align="center"&gt;
      ···
    &lt;/tiny-grid&gt;
  &lt;/div&gt;
&lt;/template&gt;

&lt;script setup lang="ts"&gt;
import { useResponsiveSize } from '@/hooks/responsive'
const { gridSize } = useResponsiveSize() // 小屏为mini grid，大屏为medium grid
&lt;/script&gt;</code></pre><ol start="3"><li>通过 <code>useResponsive</code> 获取屏幕断点状态 <code>sm/md/lg</code>，如：在模板中结合 <code>v-if="!lg"</code> 控制分隔线的渲染，从而实现了小屏下纵向菜单才显示分隔线的效果</li></ol><pre><code class="vue">&lt;template&gt;
  &lt;ul class="right-side" :class="{ open: menuOpen }"&gt;
    &lt;!-- 小屏下才显示分隔线 --&gt;
    &lt;li v-if="!lg"&gt;
      &lt;div class="divider"&gt;&lt;/div&gt;
    &lt;/li&gt;
    ···
  &lt;/ul&gt;
&lt;/template&gt;

&lt;script lang="ts" setup&gt;
import { useResponsive } from '@/hooks/responsive'
const { lg } = useResponsive()
&lt;/script&gt;</code></pre><h2>五、结语</h2><p>通过本次移动端适配， TinyPro 实现了“从桌面到掌心”的统一体验：<br/>开发者可以继续沿用熟悉的组件体系与布局方式，同时享受 UnoCSS 带来的原子化灵活性与性能优势。在不改变核心架构的前提下，TinyPro 变得更轻盈、更顺滑，也更符合移动时代的使用场景。</p><h2>关于OpenTiny</h2><p>欢迎加入 OpenTiny 开源社区。添加微信小助手：opentiny-official 一起参与交流前端技术～  <br/>OpenTiny 官网：<a href="https://link.segmentfault.com/?enc=v8iQxFa098cN4sPnkTOqSw%3D%3D.HCNczvaAlL3fp%2F%2BPXS0TLHzZdmuJ1ltlKZE8zHRQhtg%3D" rel="nofollow" target="_blank">https://opentiny.design</a>  <br/>OpenTiny 代码仓库：<a href="https://link.segmentfault.com/?enc=PpWg9iPOoJuhbbf7JuYadw%3D%3D.t7pHMeicGPvcO9D6K%2FzCWxMEkIVUBpHKr7GX6D82B2o%3D" rel="nofollow" target="_blank">https://github.com/opentiny</a>  <br/>TinyPro源码：<a href="https://link.segmentfault.com/?enc=hZ81xEE6B6ICSqKo4kyOFA%3D%3D.KBhtdgjyn%2FNvxXf8%2FVYAWT7seX%2BEuZFw69LvmBucHJK3FaKnKAT7jEupDMQvPnOZ" rel="nofollow" target="_blank">https://github.com/opentiny/tiny-pro</a></p><p>欢迎进入代码仓库 Star🌟TinyPro、TinyEngine、TinyVue、TinyNG、TinyCLI、TinyEditor<br/>如果你也想要共建，可以进入代码仓库，找到 good first issue标签，一起参与开源贡献\~</p>]]></description></item><item>    <title><![CDATA[教程上新｜GLM-Image基于自回归+扩散解码器混合架构，精准理解指令写对文字 OpenBayes]]></title>    <link>https://segmentfault.com/a/1190000047559275</link>    <guid>https://segmentfault.com/a/1190000047559275</guid>    <pubDate>2026-01-22 18:10:18</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在图像生成领域，扩散模型因其训练稳定和泛化能力强已逐渐走入主流行列。然而，<strong>面对海报、PPT、科普图等需要准确传达复杂信息的「知识密集型」场景时，传统模型存在指令理解与细节刻画难以兼顾的短板。</strong> 另一个长期存在的问题是生成图像中的文字经常出现笔画错误或难以辨识，严重影响实用价值。</p><p>基于此，<strong>智谱</strong> <strong>于 2026 年 1 月联合华为开源了新一代图像生成模型 GLM-Image。</strong> 该模型基于昇腾 Atlas 800T A2 和昇思 MindSpore AI 框架完成全流程训练。<strong>其核心特点是采用了创新的 「自回归+扩散解码器」混合架构（9B 自回归模型 + 7B DiT 解码器），</strong> 将语言模型的深度理解能力与扩散模型的高质量生成能力相结合。</p><p>此外，模型通过改进 Tokenizer 策略，原生支持从1024×1024 到 2048×2048 的任意比例图像生成，无需重新训练。GLM-Image 的创新性还体现在以下两个方面：</p><p>*<strong>解决文字渲染难题：</strong> 在 CVTG-2K 和 LongText-Bench 权威评测中，其文字准确率等关键指标均位列开源模型第一，显著提升了图像中文字的生成准确性。</p><p>*<strong>定义高性价比应用：</strong> 在 API 调用模式下，生成单张图片的成本仅需 0.1 元，成本仅为主流闭源模型的 1/10 至 1/3，为商业化应用提供了高性价比选择。</p><p>目前，<strong>「GLM-Image：首个全流程国产芯片训练模型」已上线 OpenBayes 官网的教程版块，</strong> 快来输出无限创意吧！</p><p><strong>教程链接：</strong></p><p><strong><a href="https://link.segmentfault.com/?enc=eCKbypcPQnaIQykPWtJoyw%3D%3D.VwDjXXoZiVHZINKTthyKGaKkk7kS9BcedwdNlCBdsI0%3D" rel="nofollow" target="_blank">https://go.openbayes.com/lhlvw</a></strong></p><p><strong>Demo 运行</strong></p><p><strong>01</strong></p><p><strong>Demo 运行阶段</strong></p><p>1.登录 OpenBayes.com，在「公共教程」页面，选择「GLM-Image：首个全流程国产芯片训练模型」教程。</p><p><img width="723" height="472" referrerpolicy="no-referrer" src="/img/bVdnIuP" alt="" title=""/></p><p>2.页面跳转后，点击右上角「克隆」，将该教程克隆至自己的容器中。</p><p><img width="723" height="473" referrerpolicy="no-referrer" src="/img/bVdnIuR" alt="" title="" loading="lazy"/></p><p>3.选择「NVIDIA RTX PRO 6000 Blackwell Server Edition」以及「PyTorch」镜像，按照需求选择「按量付费」或「包日/周/月」，点击「继续执行」。新用户使用下方邀请链接注册，可获得 4 小时 RTX 5090 + 5 小时 CPU 的免费时长！</p><p>小贝总专属邀请链接（直接复制到浏览器打开）：</p><p><strong><a href="https://link.segmentfault.com/?enc=Tu%2B6mO71x8xfKOeG1BQneg%3D%3D.QkGoN1XH4UPRW1bs%2BNkXNEUgiLZSQ%2BrfwdiMkZ02Vys%3D" rel="nofollow" target="_blank">https://go.openbayes.com/9S6D</a></strong> <strong>r</strong></p><p><img width="723" height="473" referrerpolicy="no-referrer" src="/img/bVdnIuV" alt="" title="" loading="lazy"/><br/><img width="723" height="473" referrerpolicy="no-referrer" src="/img/bVdnIuY" alt="" title="" loading="lazy"/></p><p>4.等待分配资源，当状态变为「运行中」后，点击「打开工作空间」进入 Jupyter Workspace。</p><p><img width="723" height="472" referrerpolicy="no-referrer" src="/img/bVdnIuZ" alt="" title="" loading="lazy"/></p><p><strong>02</strong></p><p><strong>效果演示</strong></p><p>页面跳转后，点击左侧 README 页面，进入后点击上方「运行」。</p><p><img width="723" height="472" referrerpolicy="no-referrer" src="/img/bVdnIu1" alt="" title="" loading="lazy"/><br/><img width="723" height="472" referrerpolicy="no-referrer" src="/img/bVdnIu4" alt="" title="" loading="lazy"/></p><p>待运行完成，即可点击右侧 API 地址跳转至 demo 页面。</p><p><img width="723" height="468" referrerpolicy="no-referrer" src="/img/bVdnIu5" alt="" title="" loading="lazy"/><br/><img width="723" height="398" referrerpolicy="no-referrer" src="/img/bVdnIu6" alt="" title="" loading="lazy"/></p><p><strong>教程链接：</strong></p><p><strong><a href="https://link.segmentfault.com/?enc=ShAqY%2BDq%2BRfWesvY6YaSEw%3D%3D.6sNidWtpipGBeqNVXz6rZeGB1oAfkGLGV3s3EHs%2FRYM%3D" rel="nofollow" target="_blank">https://go.openbayes.com/lhlvw</a></strong></p>]]></description></item><item>    <title><![CDATA[数据接入提效 90%，存储成本降 70%，京能集团用 TDengine 实现储能数据毫秒级响应 TD]]></title>    <link>https://segmentfault.com/a/1190000047559293</link>    <guid>https://segmentfault.com/a/1190000047559293</guid>    <pubDate>2026-01-22 18:09:22</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><strong>小T导读</strong>：京能集团在储能安全管理平台中采用 <a href="https://link.segmentfault.com/?enc=HLgi6kdCHPiKCzq1SP2p7A%3D%3D.Zou%2FccBbtew7Q%2BMxd8ts0k6%2ByuWOVdnCeFirkdLQT%2F1YoHqxVT7y973NHUhBMNtMHLV9tD0TWvPDEVtyGas71WmAgGO6Beu%2F8FCPxeO8OX%2FiFM5lPpwvWiZXnxmmt9L3SF%2FpM%2BYcsSnZ1WARmbFj1dgJERKampt%2BQWmSzGZOdQo%2FWPA9SQu%2B7yIs57eALc8WGXdyJl%2BJXWGSFl12T7dK%2FA%3D%3D" rel="nofollow" target="_blank">TDengine TSDB</a> 作为底层时序数据库。依托 TDengine 企业版的零代码数据写入平台，来自全国 28 家电化学储能电站的数据能够按照统一编码规则高效接入 TDengine 时序数据库中，实现了稳定、高性能的数据采集与管理。在此基础上，借助 TDengine TSDB Flink Connector，系统可快速、稳定地从数据库中读取海量数据，开展实时分析与智能处理，充分释放数据的潜在价值。本文将结合该项目的实践过程，为大家带来深入分享与参考。</p><h2>项目背景</h2><p>京能集团储能安全管理平台共接入全国 28 家电化学储能电站，<strong>累计测点达 270 万个</strong>，由四个平台公司分别负责数据传输与汇聚。系统需要支撑大规模的数据统计分析、事件报警与安全预警，对底层数据库的性能与稳定性提出了极高要求。</p><p>鉴于电化学储能项目采集点数量庞大（270 万点）、锂电池热失控的超前预警技术复杂等因素，传统关系型数据库已无法满足高并发写入与海量数据存储的需求。由于这些数据具备<strong>时间序列写入、格式固定、写入量巨大</strong>等典型特征，我们最终选择采用时序数据库作为系统核心数据底座。</p><h2>应用实际落地</h2><p>在充分调研国内多款时序数据库产品后，我们发现，从国内目前的实际情况分析，<a href="https://link.segmentfault.com/?enc=26NMUiV753pDqAKXYcJisw%3D%3D.b2EOzHa%2FB0BXO%2BJBVDZm1XUWv26%2BxGkMoTi3WnPN79zxEt8NPbEbIwwSB3sU6dE4iMUdYDdgycV5DcdSHqLQ%2FN1SHxzeGv%2BuGykhb0557LgvAg6PEOnCifTdEnFKdspzBq2k9m9sPTrdrXy%2BMyZ2S0Wswj7uebR0y%2Fi00IoXHArk9t0z8bALI2RCUpq8W3vv%2FT9mQFBb%2FMq5Log5FXhcSQ%3D%3D" rel="nofollow" target="_blank">TDengine TSDB</a> 已成为众多企业在海量数据高速存储、处理与调用场景中的首选方案。基于其成熟的技术体系与稳定的性能表现，我们最终选定 <a href="https://link.segmentfault.com/?enc=F%2B3EK1ks4OtY1cdL8RfQ0A%3D%3D.i7hQROk7z%2BoMI6EH3YbexXchkuMTyPrIqRB%2BTTULTXJ7zMgiObhML6yBjWuk5jxhhrG7VzY5JYct3NgFzZORFvedbfj%2B6V5KWYH0tqGycsw%2BuJIcSwdKEHwRxomDqkSumWlaZnKj2EnCbjTK%2FC11Wev75Jrzq8XSntEN1BsehXms8qtmQqePUEZwodIDNGrWtWatloPbMP7XMIDeuFA71A%3D%3D" rel="nofollow" target="_blank">TDengine TSDB</a> 作为平台的底层时序数据库，并结合 Kafka 与 Flink 构建了完整的数据流处理体系，实现了数据的高效传输与实时计算，顺利达成项目预期目标。以下是架构简图：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559295" alt="" title=""/></p><h3>TDengine TSDB 支持多种写入方式</h3><ol><li>SQL 语言写入 ：<a href="https://link.segmentfault.com/?enc=fIbzymT2UZP1z50Xfe1ArQ%3D%3D.uPC8xZtkj%2Bmyzb5z9tDQDz1jDdCA4Xymoo0X06MQ3pKy%2F%2Fz480q2C3xrspoq0Z9l" rel="nofollow" target="_blank">https://docs.taosdata.com/basic/insert/</a></li><li>无模式写入：<a href="https://link.segmentfault.com/?enc=NQP2qzPfojjELybKmCfG9A%3D%3D.YaQkf1t2ARV3zBNNmQY%2BCBuAv0gg6o1F%2Fy74uXSNujLq7ib4CAfDe9HIRItdP8tk" rel="nofollow" target="_blank">https://docs.taosdata.com/develop/schemaless/</a></li><li>参数绑定方式：<a href="https://link.segmentfault.com/?enc=YW83mxdvDpeoO1xbbOoJGg%3D%3D.P1jktO5qHucGq9IV%2B15KOqGFCZNENRw2k%2FtaHeT63gXHIVaF%2Fleo6X4pP0qcSu8B" rel="nofollow" target="_blank">https://docs.taosdata.com/develop/stmt/</a></li><li>企业版的零代码数据写入— taosExplorer 数据接入功能：<a href="https://link.segmentfault.com/?enc=AHMDytYFB0tKVgZpMpDCNw%3D%3D.tggt2Fck10u2rp0WHWSjQscgZTzi%2FW%2FbQ0x%2FuwY5nsbNkea8rzL%2FFu4hPsq0nFz8" rel="nofollow" target="_blank">https://docs.taosdata.com/advanced/data-in/</a></li></ol><p>项目中涉及多个 Kafka 集群、数十个需要接入的 topic。我们重点采用了 <a href="https://link.segmentfault.com/?enc=ihtn8uz2UqNIYDk81bbROQ%3D%3D.o%2BA4LK8ICjxcCpDFZLpGZ%2F5PQy6Jwp7h40kUZq5PXAXn7uPKaHB9JmSjG30Cscro%2FBHbZ%2F9AXvzdhfVG1q95w1o6hLBNmcf0Vwd7HW4P2Z8xzlBhc88F%2BNgNBy8pLCseiUTSs0zH8EcLCSgW0lo9SoannKmN4s8oOBcQWC%2B%2BGD9lNvbC5xPzEU74dGcjXMyxsf4DKdHsDPkZJnROfhE8YNmFJvwq65PWdGocUYWXXc0%3D" rel="nofollow" target="_blank">TDengine</a> 企业版的零代码数据写入能力，实现了从 Kafka 到 <a href="https://link.segmentfault.com/?enc=LA0XiIxywrkhgMTI%2B7PSAA%3D%3D.oAZFWYfTtE9xjSRFeB3VxuUuqmQovUHltZvt0weNAO%2BD4r%2BoWTz7sMYQBeOUzejD%2FhcZk%2BmJMdUSY55wEWeSi2GAWDCKCS0x64j34p8uS9rKhH1aoaejjB9MQJ71SAJChgIX18o%2FkZ8Agdci6xQ%2BetGqkQKYpUU7tMbanYE%2FwAryoF58P6KNDLdqqpjdc5vD2zX7GYjMJ94v331VmTv2bnmMAwQ6HrYIpkmI2yhpwG4%3D" rel="nofollow" target="_blank">TDengine TSDB</a> 的高效对接。该功能支持灵活配置类似 ETL 的复杂自定义选项，极大简化了数据接入流程和时间，而且数据接入性能完全达到了项目要求。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559296" alt="" title="" loading="lazy"/></p><p>为了保证数据的合理性，我们出台了《京能集团电化学储能电站安全管理平台和储能电站设备标识编码规则》，通过标准的 kks 编码在 taosX 对 Kafka 数据进行了有效过滤和清理，最终写入 TDengine TSDB。kks 部分编码实例如下：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559297" alt="" title="" loading="lazy"/></p><p>下图为数据过滤、转换等规则设置：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559298" alt="" title="" loading="lazy"/></p><p>此外，taosX 数据接入还支持多节点高可用配置。只需在多台 taosX 上部署相同的 Kafka 数据接入任务，并设置相同的 groupId，即可自动实现任务高可用，确保数据接入的连续性与稳定性。</p><p>同时，<a href="https://link.segmentfault.com/?enc=5DE80WmNlFuE52O03vLXfg%3D%3D.lNV8ufGwzN%2B3B23NpFI43xe1hOlBXksspDfv7pDoAuNiv7KL63gBswTw0Dxf7leInBYui1XfU3bH%2F1NxjwJ5L9XwMFLTKkhdeFcBmXxdulx6VMK1g51bo0oeDGuP%2B3narbJkeIgKUhdCaNsxMqMs2bE%2BH0psqX4Yug02Ys90nItPvgv5YYAABDE6%2BvUkdN4tjP6fRoptkvp0DEszd4lahzv2vJ4KO%2BkUjNat1l8VUgQ%3D" rel="nofollow" target="_blank">TDengine</a> 还提供完善的 taosX 任务监控机制，可直接通过 Grafana 一键配置，快速生成可视化监控图表：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559299" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559300" alt="" title="" loading="lazy"/></p><h3>超级表 + 子表的使用</h3><p><a href="https://link.segmentfault.com/?enc=wMPjhTSVHcO1%2Bpklj7Hoog%3D%3D.os09UxCuJlgjNV35XoSg6z6v4%2FkDMOeUq6Nb1jMiJs0iADEZ0RpZMzgBZaMuCHI5rXCdz3s6e%2BzwJDW0X9LZm7woN1uLKmrnT2fsOf8wyPPxW%2FAOXoTyNUadrOSJ3uzFirbE4T70NiKhCtvFQVD2EtGETUXEAozaFjwzLZGiBj9ZWgiv%2BU0K6TbFZiySaw9%2Fmw2q06mkt7erAFeEpllwaPI%2BU1b72Qg%2BO9QHv%2FZCtuk%3D" rel="nofollow" target="_blank">TDengine TSDB</a> 结合“一个数据采集点一张表”的设计理念，引入了具有创新性的“超级表”机制，从根本上解决了大规模时序数据结构不统一、聚合困难、运维复杂等问题。每个采集点的数据独立存储，天然具备写入无锁、数据顺序追加、块状连续存储等优势。这种设计方式不仅提升了写入与查询性能，还带来了极高的数据压缩效率。</p><p><a href="https://link.segmentfault.com/?enc=bhuhQGm85VQ7Ti%2Fg2l6ZOQ%3D%3D.Gu5Rb1I9QsvPEwUC0N%2BXtaMFS%2BDGbnNlUoEHyv1Dee4mEBdUpeBE9C9N6ch%2BdVd14HCfnD%2BsRwo34Cd7P02xYAvfUMDxtnUwQqpI1N65M4AuDuGk5p2Ulh7wNGzRQzxvznDLtbOn26%2B5BSzW6GCq0NTzg85aCrw3y4TqURKpsnhiP06OvyqMW2aYA7cLg7PfmPqdRAQRMw7sw49%2BCjH9JNKI%2FYXIcMtzQppQUAXuShE%3D" rel="nofollow" target="_blank">TDengine TSDB</a> 支持对超级表标签进行动态的添加、修改与删除操作，满足设备属性变更、系统扩展等业务需求。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559301" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559302" alt="" title="" loading="lazy"/></p><h3>计算、分析处理</h3><p>在 Flink 计算平台上，我们借助 TDengine TSDB 企业版提供的 <strong>Flink 连接器</strong>——TDengine TSDB Flink Connector（<a href="https://link.segmentfault.com/?enc=gc%2FixpyDesB%2BMbyhQ0Tlcw%3D%3D.ir8Kw3jEYq5ym5iZpN0uDr1Vz1AQzsRCXytsgFDN21yJ7HnhYYKiVPc1ceqtEfNPPu722Wmm65ZSsmwJBYLTlw%3D%3D" rel="nofollow" target="_blank">https://docs.taosdata.com/advanced/data-publisher/Flink/</a>），实现了与 TDengine TSDB 的无缝集成。该连接器可高效、稳定地从 TDengine TSDB 中读取海量时序数据，并在此基础上进行全面、深入的分析处理，充分挖掘数据的潜在价值，极大地提升数据处理的效率和质量。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559303" alt="" title="" loading="lazy"/></p><p>Flink CDC 主要用于提供数据订阅功能，能实时监控 TDengine TSDB 数据库的数据变化，并将这些变更以数据流形式传输到 Flink 中进行处理，同时确保数据的一致性和完整性。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559304" alt="" title="" loading="lazy"/></p><h3>落地效果</h3><ol><li><strong>数据接入便利性</strong>：目前我们已接入 20 多个 kafka 数据，后期还会继续增加。得益于 TDengine 企业版零代码数据接入能力，新增任务仅需复制并做少量参数调整即可完成，操作简便高效，<strong>整体接入过程较传统方式节省约 90% 的时间成本</strong>。</li><li><strong>数据查询性能高</strong>：开启数据库缓存功能后，能够实时获取每个设备点位最新值，<strong>毫秒级别即可返回结果</strong>。</li><li><strong>数据存储成本低</strong>：TDengine TSDB 具备出色的数据压缩能力，其二级压缩技术将数据视作无差别的二进制块进行再次压缩。与一级压缩相比，二级压缩的侧重点在于消除数据块之间的信息冗余。目前我们提供的服务器存储远远满足我们项目规划的 5 年数据存储，<strong>存储成本估算节省至少 60-70%</strong>。</li><li><strong>实时订阅</strong>：通过 TDengine 提供的 Flink CDC 实时订阅功能，能方便、高效的进行分析、告警等处理，给我们后期分析带来了极大的便利性。</li></ol><h2>后期规划</h2><p>目前，我们正在对京能集团储能安全管理平台已经接入的 28 场站数据进行分析和优化，提高数据采集的可靠性和鲁棒性。未来我们会针对 TDengine TSDB 新版本和新功能进行持续跟踪，进一步开发 TDengine TSDB 的内在潜力和各种有效的功能。</p><p>近期我们关注到 TDengine 发布了新产品 TDengine IDMP，通过经典的树状层次结构组织传感器、设备采集的数据，建立数据目录，对数据提供情境化、标准化的处理，并提供实时分析、可视化等功能，接下来我们会进一步了解此产品在我们业务中的使用可能。</p><h2>关于京能集团</h2><p>北京能源集团有限责任公司是北京市人民政府出资设立的国有独资公司，肩负着保障首都北京能源安全可靠供应的重任。京能集团成立于 2004 年，由原北京国际电力开发投资公司和原北京市综合投资公司合并而成，2011 年、2014 年先后又与北京市热力集团有限责任公司、北京京煤集团有限责任公司实施合并重组，实现了产业链条融合互补。经过多年的资源整合，集团由单一能源产业发展为热力、电力、煤炭、健康文旅等多业态产业格局。2024 年在中国企业 500 强排名第 247 位，中国服务企业 500 强排名第 87 位。</p><p>作者：张海增</p>]]></description></item><item>    <title><![CDATA[服务器数据恢复—服务器挂载失败！存储映射卷数据丢失，精准修复保住核心资产 北亚数据恢复 ]]></title>    <link>https://segmentfault.com/a/1190000047559343</link>    <guid>https://segmentfault.com/a/1190000047559343</guid>    <pubDate>2026-01-22 18:08:22</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><strong>服务器存储数据恢复环境：</strong><br/>某品牌服务器存储上有16块FC硬盘，存储设备前面板的10号硬盘指示灯和13号硬盘指示灯亮黄灯，存储设备映射到服务器redhat linux系统上的卷无法挂载，业务中断。</p><p><strong>服务器存储数据恢复过程：</strong><br/>1、通过存储设备厂商的管理程序storage manager连接到服务器存储上查看当前存储状态，逻辑卷状态failed。查看物理磁盘状态，6号盘报告“警告”，10号和13号盘报告“失败”。<br/>通过storage manager将故障存储的完整日志状态备份，解析备份出来的存储日志获取逻辑卷结构的部分信息。<br/>2、北亚企安数据恢复工程师将故障存储中16块FC盘做好标记后，从存储设备中取出。使用专业镜像设备对16块FC盘进行初步测试。经过测试发现16块盘均能正常识别。分别检测16块盘的SMART状态，结果6号盘的SMART状态为“警告”，和storage manager中的报告一致。<br/>3、北亚企安数据恢复工程师在windows环境下将识别出来的FC盘在磁盘管理器中标记为脱机状态，然后对原始磁盘进行扇区级别完整镜像。将原始磁盘中的所有物理扇区镜像到windows系统下的逻辑磁盘并以文件形式保存。<br/>在镜像过程中服务器数据恢复工程师发现6号磁盘的镜像速度极慢，结合先前检测结果综合判断，6号盘应该存在大量损坏以及不稳定扇区，导致windows环境下的一些软件无法对其进行操作。<br/>4、使用专业镜像设备对6号硬盘进行坏道镜像操作，在镜像过程中观察镜像的速度和稳定性。在镜像过程中发现6号盘上的坏道并不多，但是存在大量读取响应时间长的不稳定扇区。于是服务器数据恢复工程师调整6号盘的拷贝策略，将“遇到坏道跳过扇区数”和“响应等待时间”等参数作一些调整后继续对6号盘进行镜像操作。同时观察剩余盘在windows环境下镜像的情况。<br/>5、镜像完成后查看日志，发现在storage manager和SMART状态中均没有报错的1号盘也存在坏道，10号和13号盘均存在大量不规则的坏道分布。<br/>根据坏道列表使用工具定位到目标镜像文件进行分析后发现，ext3文件系统的一些关键源数据信息被坏道破坏。只能等6号盘镜像完毕后，通过同一条带进行xor以及根据文件系统上下文关系手动修复被损坏的文件系统。<br/>6、6号盘镜像完成，但是为了最大限度做出有效扇区和保护磁头所设置的拷贝策略，会让这次完成的镜像在镜像过程中自动跳过一些不稳定扇区，所以现在的镜像是不完整的。于是服务器数据恢复工程师调整拷贝策略，继续镜像被跳过的扇区，直到6号盘所有扇区全部镜像完成。<br/>7、所有硬盘镜像完成后，基于镜像文件分析所有硬盘底层数据。根据北亚企安数据恢复工程师对ext3文件系统的逆向研究和对日志文件的分析，获取到16块FC盘的盘序、RAID块大小、RAID的校验走向和方式等重组RAID的必要信息，根据获取到的信息虚拟重组RAID。RAID搭建完成后进一步解析ext3文件系统。<br/>8、和用户方沟通后提取出一些oracle数据库的dmp文件，用户方尝试通过dmp文件恢复数据库。<br/>在dmp恢复的过程中，oracle数据库报告imp-0008错误。北亚数据恢复中心的oracle数据库工程师分析导入dmp文件的日志文件后，发现恢复的dmp文件存在问题，从而导致dmp导入数据失败。<br/>9、服务器数据恢复工程师重新分析raid结构，进一步确定ext3文件系统被破坏的程度，重新恢复dmp文件和dbf原始库文件。<br/>10、将恢复出来的dmp文件移交给用户方进行数据导入测试，这次测试顺利，没有发现问题。对恢复出来的dbf原始库文件进行校验检测，所有文件均能通过测试。<br/>11、数据库工程师到达现场，和用户沟通后决定使用恢复出来的dbf原始库文件进行操作，以确保把数据恢复到最佳状态。</p><p><strong>oracle数据库恢复过程：</strong><br/>1、拷贝数据库文件到原数据库服务器作为备份，备份文件所在文件夹路径为/home/oracle/tmp/syntong。在根目录下创建一个名为“oradata”的目录，把syntong文件夹拷贝到oradata目录下。更改oradata文件夹及其所有文件的属组和权限。<br/>2、备份原数据库环境，包括ORACLE_HOME下product文件夹下的相关文件。配置监听，使用原机中的splplus连接到数据库，尝试启动数据库到nomount状态。进行基本状态查询后，了解到环境和参数文件没有问题。 尝试启动数据库到mount状态，进行状态查询没有发现问题。当启动数据库到open状态，出现报错：<br/>ORA-01122: database file 1 failed verification check<br/>ORA-01110: data file 1: '/oradata/syntong/system01.dbf'<br/>ORA-01207: file is more recent than control file - old control file<br/>经过进一步的检测和分析，判断此故障为控制文件和数据文件信息不一致，这是一类常因断电或突然关机引发的故障。<br/>3、对数据库文件进行逐个检测，检测到所有数据文件都不存在物理损毁的情况。<br/>4、在mount状态下，对控制文件进行备份。alter database backup controlfile to trace as ' /backup/controlfile'。对备份的控制文件进行查看修改，取得其中的重建控制文件命令。把这些命令复制到一个新建脚本文件controlfile.sql中。<br/>5、关闭数据库，删除/oradata/syntong/下的3个控制文件。 启动数据库到nomount状态，执行controlfile.sql 脚本。<br/>SQL&gt;startup nomount<br/>SQL&gt;@controlfile.sql<br/>6、完成重建控制文件后，启动数据库报错，需要做进一步处理。<br/>SQL&gt; alter database open<br/>alter database open<br/>*<br/>ERROR at line 1:<br/>ORA-01113: file 1 needs media recovery<br/>ORA-01110: data file 1: '/free/oracle/oradata/orcl/system01.dbf'<br/>然后执行恢复命令：<br/>recover database using backup controlfile until cancel<br/>Recovery of Online Redo Log: Thread 1 Group 1 Seq 22 Reading mem 0<br/>Mem# 0 errs 0: /free/oracle/oradata/orcl/redo01.log<br/>…<br/>做介质恢复，直到返回报告，恢复完成。<br/>7、尝试open数据库。<br/>SQL&gt; alter database open resetlogs<br/>8、成功启动数据库。把原来temp表空间的数据文件加入到对应的temp表空间中。<br/>9、对数据库进行各种常规检查，没有发现任何错误。<br/>10、进行emp备份。全库备份完成也没有报错。将应用程序连接到数据库，进行应用层面的数据验证。经过验证没有发现问题。本次数据恢复工作完成。</p>]]></description></item><item>    <title><![CDATA[2026 CRM 厂商对比：6 大客户管理系统核心能力横向对比（选型必看） 率性的开水瓶 ]]></title>    <link>https://segmentfault.com/a/1190000047559388</link>    <guid>https://segmentfault.com/a/1190000047559388</guid>    <pubDate>2026-01-22 18:07:28</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在企业数字化转型中，<strong>CRM</strong> <strong>系统</strong>是连接“客户-销售-服务”的核心枢纽。从线索获取到商机转化，从自动化流程到数据决策，不同品牌的CRM在核心能力上的差异，直接决定了企业能否“用对工具、提效增收”。</p><p>本文基于<strong>超兔一体云、Salesforce、SuiteCRM、Freshsales、红圈</strong> <strong>CRM</strong> <strong>、六度人和（</strong> <strong>EC</strong> <strong><em/></strong>SCRM<strong> </strong>）的公开能力素材，从线索与商机管理、自动化能力、报表能力、审批能力、可配置性<strong>五大维度展开深度对比，结合</strong>表格、流程图、脑图、雷达图**直观呈现差异，为企业选型提供参考。</p><h2>一、对比框架与核心逻辑</h2><p>本次对比围绕“<strong>企业实际业务需求</strong>”设计维度，重点回答以下问题：</p><ul><li>能否覆盖从“线索→客户→商机→订单”的全流程？</li><li>能否通过自动化减少重复劳动？</li><li>能否通过数据报表支撑决策？</li><li>能否适配企业的个性化流程（如审批、字段）？</li><li>能否匹配企业的规模与行业特性？</li></ul><h2>二、核心能力横向对比</h2><h3>（一）维度1：线索与商机管理——从“获客”到“转化”的全流程覆盖</h3><p>线索与商机是销售的“源头活水”，核心评价标准是<strong>流程完整性、AI辅助能力、自定义适配性</strong>。</p><h4>各品牌表现拆解</h4><table><thead><tr><th>品牌</th><th>核心优势</th><th>具体能力</th></tr></thead><tbody><tr><td><strong>超兔一体云</strong></td><td>多渠道获客+“三一客”小单快转模型</td><td>1. 覆盖百度、抖音、微信、地推等10+线索来源； 2. 三一客模型（定人、定时、定动作）推进小单转化； 3. 自动计算市场活动ROI（成本均摊到线索/签约）。</td></tr><tr><td><strong>Salesforce</strong></td><td>AI预测+全流程自动化流转</td><td>1. Einstein AI预测商机赢单概率（准确率达85%+）； 2. Lead→Opportunity自动关联客户/联系人； 3. 产品/价格簿深度整合（支持复杂报价）。</td></tr><tr><td><strong>SuiteCRM</strong></td><td>开源自定义流程</td><td>1. 支持线索→客户→商机的全流程自定义（字段、布局、节点）； 2. 适配企业独特业务逻辑（如制造业的“线索→经销商→商机”）。</td></tr><tr><td><strong>Freshsales</strong></td><td>AI线索评分+行为跟踪</td><td>1. AI线索评分（基于邮件打开、页面访问等行为）； 2. 自动触发邮件序列（如未打开邮件3天后重发）； 3. 客户行为 timeline 可视化。</td></tr><tr><td><strong>红圈</strong> <strong>CRM</strong></td><td>全流程覆盖+公海池管理</td><td>1. 覆盖“线索→客户→商机→回款”全链路； 2. 公海池解决线索分散问题（未跟进线索自动回收再分配）； 3. 适配工程行业的“项目型商机”。</td></tr><tr><td><strong>六度人和</strong></td><td>社交渠道整合+AI商机助手</td><td>1. 整合微信、QQ、企业微信等社交线索（占比80%+）； 2. AI商机助手自动总结客户需求（如微信聊天中的“价格咨询”）； 3. 跟踪客户社交行为（如打开朋友圈链接）。</td></tr></tbody></table><h4>流程可视化：超兔一体云“线索→商机”时序图</h4><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559390" alt="" title=""/></p><pre><code>sequenceDiagram
    participant 市场 as 市场渠道（百度/抖音/微信）
    participant 超兔 as 超兔一体云
    participant 销售 as 销售
    participant 客户 as 客户

    市场-&gt;&gt;超兔: 推送线索（手机号/IP/行为）
    超兔-&gt;&gt;超兔: 线索清洗（去重/归属地识别）
    超兔-&gt;&gt;销售: 分配通知（短信/APP）
    销售-&gt;&gt;超兔: 跟进记录（电话/拜访/微信）
    超兔-&gt;&gt;超兔: 三一客模型判定（是否合格）
    alt 合格
        超兔-&gt;&gt;超兔: 转化为商机（关联客户）
        销售-&gt;&gt;客户: 报价/演示
        客户-&gt;&gt;超兔: 确认订单
        超兔-&gt;&gt;超兔: 计算ROI（市场成本/签约额）
    else 不合格
        超兔-&gt;&gt;超兔: 移入线索池（需求培养）
        超兔-&gt;&gt;销售: 定期提醒复访
    end</code></pre><h3>（二）维度2：自动化能力——从“人工重复”到“智能执行”的效率跃迁</h3><p>自动化是CRM的“效率引擎”，核心评价标准是<strong>低代码</strong> <strong>/无代码能力、AI</strong> <strong>智能体</strong> <strong>、跨系统协同</strong>。</p><h4>各品牌表现拆解</h4><table><thead><tr><th>品牌</th><th>核心优势</th><th>具体能力</th></tr></thead><tbody><tr><td><strong>超兔一体云</strong></td><td>低代码工作流+AI智能体嵌入式应用</td><td>1. 自然语言AI生成工作流（如“新线索自动分配给区域销售”）； 2. AI智能体嵌入客户视图（自动生成跟单待办、日报）； 3. 订单自动化（锁库、生成采购单）。</td></tr><tr><td><strong>Salesforce</strong></td><td>低代码+AI代理+跨系统集成</td><td>1. Lightning低代码平台（拖拽式配置工作流）； 2. Agentforce AI代理（自动处理19万+潜在客户，节省50万+小时）； 3. MuleSoft集成ERP/供应链系统。</td></tr><tr><td><strong>SuiteCRM</strong></td><td>基础工作流引擎</td><td>1. 新线索自动分配给区域销售； 2. 任务到期自动提醒； 3. 需技术团队二次开发复杂流程（如售后工单派工）。</td></tr><tr><td><strong>Freshsales</strong></td><td>AI助手+邮件序列自动化</td><td>1. Freddy AI自动生成跟单待办（如“客户3天未回复，建议跟进”）； 2. 邮件序列（未打开邮件3天后重发，打开后触发跟进）； 3. 自动记录客户行为（如访问产品页面）。</td></tr><tr><td><strong>红圈</strong> <strong>CRM</strong></td><td>PaaS平台+行业定制流程</td><td>1. PaaS平台配置自动化（如“工程商机达标自动触发合同审批”）； 2. 适配工程行业的“项目进度→商机更新”流程； 3. 支持第三方系统集成（如ERP）。</td></tr><tr><td><strong>六度人和</strong></td><td>社交行为触发自动化</td><td>1. 客户打开微信链接→自动发跟进消息； 2. 客户未回复微信→3天后自动提醒销售； 3. 整合微信朋友圈广告线索→自动分配。</td></tr></tbody></table><h4>流程可视化：Salesforce“订单审批”自动化工作流</h4><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559391" alt="" title="" loading="lazy"/></p><pre><code>graph TD
    A[触发条件: 商机金额&gt;10万] --&gt; B{检查审批人权限}
    B --&gt;|是| C[发送通知（邮件/Slack）]
    B --&gt;|否| D[退回修改+原因提示]
    C --&gt; E[审批人审批]
    E --&gt;|通过| F[自动生成订单+锁库]
    E --&gt;|驳回| G[通知销售修改]
    F --&gt; H[同步至ERP]</code></pre><h3>（三）维度3：报表能力——从“数据”到“决策”的价值转化</h3><p>报表是CRM的“大脑”，核心评价标准是<strong>可视化能力、自定义深度、实时性</strong>。</p><h4>各品牌表现拆解</h4><table><thead><tr><th>品牌</th><th>核心优势</th><th>具体能力</th></tr></thead><tbody><tr><td><strong>超兔一体云</strong></td><td>多表聚合+实时工作台</td><td>1. 工作台数字卡片（实时显示线索量、商机转化率）； 2. 多表聚合分析（线索→商机→订单关联）； 3. 单日KPI引擎（销售今日需完成的线索跟进量）。</td></tr><tr><td><strong>Salesforce</strong></td><td>高级BI+权限管控</td><td>1. Tableau集成（高级可视化，如销售漏斗趋势）； 2. 动态仪表板（实时更新业绩、客户留存）； 3. 权限精细管控（如销售仅能看自己的客户数据）。</td></tr><tr><td><strong>SuiteCRM</strong></td><td>基础自定义报表</td><td>1. 支持线索、客户、商机的基础统计； 2. 自定义字段过滤（如“区域=华北”的线索量）； 3. 需二次开发复杂报表（如“项目成本分析”）。</td></tr><tr><td><strong>Freshsales</strong></td><td>智能绩效仪表盘</td><td>1. 团队业绩仪表盘（显示转化率、平均单客价）； 2. 客户旅程可视化（如“线索→商机→成交”的步骤）； 3. AI分析（如“高意向客户的共同特征”）。</td></tr><tr><td><strong>红圈</strong> <strong>CRM</strong></td><td>行业定制BI</td><td>1. 工程行业成本分析（项目成本→商机利润）； 2. 销售业绩对比（同比/环比）； 3. 实时动态建模（如“本月新签项目的区域分布”）。</td></tr><tr><td><strong>六度人和</strong></td><td>社交行为统计</td><td>1. 销售微信互动次数统计； 2. 客户响应率分析（如“微信消息的回复率”）； 3. 朋友圈广告线索转化率。</td></tr></tbody></table><h3>（四）维度4：审批能力——从“合规”到“高效”的流程管控</h3><p>审批是企业的“风险闸门”，核心评价标准是<strong>流程自定义、触发条件、移动端支持</strong>。</p><h4>各品牌表现拆解</h4><table><thead><tr><th>品牌</th><th>核心优势</th><th>具体能力</th></tr></thead><tbody><tr><td><strong>超兔一体云</strong></td><td>全局权限+移动端便捷审批</td><td>1. 全局权限机制（上级管下级、助理跟主管、老板看全局）； 2. 移动端审批（支持微信/APP）； 3. 自动触发（如“费用报销&gt;500元需经理审批”）。</td></tr><tr><td><strong>Salesforce</strong></td><td>多节点+多渠道通知</td><td>1. 自定义审批节点（如“订单→区域经理→财务→老板”）； 2. 多渠道通知（邮件、Slack、手机）； 3. 审批历史追溯（如“谁驳回了订单”）。</td></tr><tr><td><strong>SuiteCRM</strong></td><td>需二次开发</td><td>1. 基础审批功能（如请假）； 2. 复杂审批（如合同）需技术团队修改代码； 3. 无移动端原生支持。</td></tr><tr><td><strong>Freshsales</strong></td><td>第三方集成</td><td>1. 通过Zapier集成审批工具（如ApprovalMax）； 2. 无原生审批流程； 3. 移动端需跳转到第三方应用。</td></tr><tr><td><strong>红圈</strong> <strong>CRM</strong></td><td>行业定制流程</td><td>1. 工程合同审批（项目经理→财务→老板）； 2. 层级审批（如“金额&gt;10万需总部审批”）； 3. 移动端支持。</td></tr><tr><td><strong>六度人和</strong></td><td>基础配置+第三方扩展</td><td>1. 请假、报销等基础审批； 2. 复杂审批需集成钉钉/企业微信； 3. 微信小程序审批。</td></tr></tbody></table><h3>（五）维度5：可配置性——从“通用”到“个性”的适配能力</h3><p>可配置性决定了CRM能否“贴合企业业务”，核心评价标准是<strong>低代码</strong> <strong>工具、开源/闭源、集成能力</strong>。</p><h4>各品牌表现拆解</h4><table><thead><tr><th>品牌</th><th>核心优势</th><th>具体能力</th></tr></thead><tbody><tr><td><strong>超兔一体云</strong></td><td>功能订阅+自定义工作台</td><td>1. 功能白名单（仅订阅需要的模块，降低成本）； 2. 自定义工作台（销售/市场/财务的专属数据大屏）； 3. 自定义业务表（如客户字段、订单布局）。</td></tr><tr><td><strong>Salesforce</strong></td><td>低代码+元数据驱动</td><td>1. Lightning低代码平台（非技术人员可自定义模块）； 2. 元数据驱动（升级不影响自定义功能）； 3. Apex语言二次开发（深度定制业务逻辑）。</td></tr><tr><td><strong>SuiteCRM</strong></td><td>开源深度定制</td><td>1. 开源代码（可修改核心逻辑）； 2. 集成第三方ERP（如SAP）； 3. 自定义字段/布局/流程。</td></tr><tr><td><strong>Freshsales</strong></td><td>企业版高级自定义</td><td>1. 免费版：基础字段修改； 2. 企业版：自定义模块（如“项目”）、工作流； 3. 集成第三方工具（如Mailchimp）。</td></tr><tr><td><strong>红圈</strong> <strong>CRM</strong></td><td>API开放+行业适配</td><td>1. 开放API接口（集成项目管理/ERP系统）； 2. 适配130+行业（如工程、医药）； 3. 自定义数据字典（如“工程阶段”字段）。</td></tr><tr><td><strong>六度人和</strong></td><td>开箱即用+基础调整</td><td>1. 无需配置，快速上线； 2. 基础调整（如客户字段、菜单）； 3. 集成微信/企业微信。</td></tr></tbody></table><h2>三、综合能力雷达图——各品牌的“能力边界”</h2><p>以下是各品牌在五大维度的<strong>1-5分评分</strong>（5分为满分），直观呈现“长板”与“短板”：</p><table><thead><tr><th>品牌</th><th>线索与商机</th><th>自动化</th><th>报表</th><th>审批</th><th>可配置</th></tr></thead><tbody><tr><td><strong>超兔一体云</strong></td><td>4.5</td><td>4.3</td><td>4.0</td><td>4.2</td><td>4.4</td></tr><tr><td><strong>Salesforce</strong></td><td>4.8</td><td>4.9</td><td>4.7</td><td>4.8</td><td>4.7</td></tr><tr><td><strong>SuiteCRM</strong></td><td>4.0</td><td>3.0</td><td>3.5</td><td>2.5</td><td>4.5</td></tr><tr><td><strong>Freshsales</strong></td><td>4.3</td><td>4.5</td><td>4.2</td><td>3.0</td><td>3.5</td></tr><tr><td><strong>红圈</strong> <strong>CRM</strong></td><td>4.5</td><td>4.0</td><td>4.3</td><td>4.5</td><td>4.2</td></tr><tr><td><strong>六度人和</strong></td><td>4.2</td><td>3.8</td><td>3.5</td><td>3.0</td><td>3.2</td></tr></tbody></table><h2>四、选型建议——匹配“企业特性”的最优解</h2><p>根据<strong>企业规模、行业、技术能力</strong>，推荐以下选型方向：</p><table><thead><tr><th>企业类型</th><th>推荐品牌</th><th>原因</th></tr></thead><tbody><tr><td>中小企业（10-200人）</td><td><strong>超兔一体云</strong></td><td>全流程覆盖+高可配置+低成本（功能白名单），适配小单快转的业务需求。</td></tr><tr><td>中大型企业（200人以上）</td><td><strong>Salesforce</strong></td><td>AI+集成能力强，支持复杂销售流程（如多产品、跨区域）。</td></tr><tr><td>有技术团队的企业</td><td><strong>SuiteCRM</strong></td><td>开源深度定制，可整合自有ERP/项目管理系统。</td></tr><tr><td>成长型企业（注重效率）</td><td><strong>Freshsales</strong></td><td>AI线索评分+自动待办，提升销售效率（适合电销/网销团队）。</td></tr><tr><td>复杂行业（如工程）</td><td><strong>红圈</strong> <strong>CRM</strong></td><td>全流程覆盖+行业适配（如项目成本分析、合同审批）。</td></tr><tr><td>社交型销售（教育/金融）</td><td><strong>六度人和</strong></td><td>微信/企业微信整合，跟踪客户社交行为（如朋友圈互动）。</td></tr></tbody></table><h2>五、总结——CRM选型的“本质”</h2><p>CRM的核心价值不是“功能多”，而是“<strong>匹配企业的业务阶段与需求</strong>”。中小企业需要“全流程、高可配置、低成本”；中大型企业需要“AI、集成、复杂流程”；行业型企业需要“定制化、行业适配”。</p><p>通过本文的对比，企业可以清晰看到：</p><ul><li>超兔一体云是<strong>中小企业的“全流程数字化工具”</strong> ；</li><li>Salesforce是<strong>中大型企业的“</strong> <strong>AI+</strong> <strong>集成平台</strong> <strong>”</strong> ；</li><li>红圈CRM是<strong>复杂行业的“全流程管家”</strong> ；</li><li>六度人和是<strong>社交型销售的“获客神器”</strong> 。</li></ul><p>最终，选型的关键是“<strong>以业务为中心</strong>”——先明确自己的核心需求（如“要解决线索转化慢”还是“要做AI预测”），再匹配品牌的“长板”能力。</p><p>（注：文中功能相关描述均基于公开披露信息，具体功能服务与价格以厂商实际落地版本为准。）</p>]]></description></item><item>    <title><![CDATA[快速上手：LangChain + AgentRun 浏览器沙箱极简集成指南 阿里云云原生 ]]></title>    <link>https://segmentfault.com/a/1190000047559401</link>    <guid>https://segmentfault.com/a/1190000047559401</guid>    <pubDate>2026-01-22 18:06:51</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>作者：辰泉</p><h2>前言</h2><p>在 Agentic AI 时代，智能体需要与真实世界交互，而浏览器是连接虚拟世界与现实世界的重要桥梁。AgentRun Browser Sandbox 为智能体提供了安全、高性能、免运维的浏览器执行环境，让 AI Agent 真正具备“上网”的能力——从网页抓取、信息提取到表单填写、自动化操作，一切皆可实现。</p><h2>AgentRun Browser Sandbox 介绍</h2><h3>什么是 Browser Sandbox?</h3><p>Browser Sandbox 是 AgentRun 平台提供的云原生无头浏览器沙箱服务，基于阿里云函数计算（FC）构建。它为智能体提供了一个安全隔离的浏览器执行环境，支持通过标准的 Chrome DevTools Protocol (CDP) 远程控制浏览器实例。</p><h3>核心特性</h3><p><strong>无头浏览器能力</strong></p><ul><li>内置 Chromium/Chrome 浏览器，支持完整的 Web 标准</li><li>原生兼容 Puppeteer、Playwright 等主流自动化框架</li><li>支持通过 CDP 协议进行精细化控制</li></ul><p><strong>实时可视化</strong></p><ul><li>内置 VNC 服务，支持实时查看浏览器界面</li><li>提供操作录制功能，方便调试和回放</li><li>支持通过 noVNC 客户端在网页中直接交互</li></ul><p><strong>安全与隔离</strong></p><ul><li>每个沙箱实例运行在独立的容器环境中</li><li>文件系统和进程空间完全隔离</li><li>支持 WSS 加密传输，确保数据安全</li></ul><p><strong>Serverless 架构</strong></p><ul><li>按需创建，按量付费，无需提前预置资源</li><li>快速弹性伸缩，支持高并发场景</li><li>零运维，无需管理服务器和浏览器依赖</li></ul><h3>主要应用场景</h3><ul><li><strong>AI Agent 赋能：</strong> 为大模型提供“眼睛”和“手”，执行网页浏览、信息提取、在线操作等任务</li><li><strong>自动化测试：</strong> 在云端运行端到端（E2E）测试和视觉回归测试</li><li><strong>数据采集：</strong> 稳定、高效地进行网页抓取，应对动态加载和反爬虫挑战</li><li><strong>内容生成：</strong> 自动化生成网页截图或 PDF 文档</li></ul><h2>上手使用 AgentRun Browser Sandbox</h2><h3>AgentRun SDK 快速介绍</h3><p><em>后续的内容将基于 AgentRun SDK 进行，因此我们先对 SDK 进行简要介绍。</em></p><p>Agentrun SDK 是一个开源的开发者工具包，本期介绍 Python 版本。其旨在简化智能体与 AgentRun 平台各种服务（包括 Browser Sandbox）的集成。它提供了统一的接口，让您可以用几行代码就将沙箱能力集成到现有的 Agent 框架中。SDK 的核心功能如下：</p><p><strong>统一集成接口</strong></p><ul><li>提供对 LangChain、AgentScope 等主流框架的开箱即用支持</li><li>统一的模型代理接口，简化多模型管理</li><li>标准化的工具注册机制</li></ul><p><strong>Sandbox 生命周期管理</strong></p><ul><li>自动创建和销毁沙箱实例</li><li>支持会话级别的状态保持</li><li>灵活的资源配置和超时控制</li></ul><h4>安装 AgentRun SDK</h4><pre><code>pip install agentrun-sdk[playwright,server]</code></pre><p><strong><em>注意：</em></strong> 确保您的 Python 环境版本在 3.10 及以上。</p><h4>基本使用示例</h4><p>以下是使用 AgentRun SDK 创建和管理 Browser Sandbox 的核心代码：</p><pre><code>from agentrun.sandbox import Sandbox, TemplateType
from playwright.sync_api import sync_playwright
# 创建 Browser Sandbox
sandbox = Sandbox.create(
    template_type=TemplateType.BROWSER,
    template_name="your-template-name",
    sandbox_idle_timeout_seconds=300
)
# 获取 CDP URL（用于 Playwright 连接）
cdp_url = sandbox.get_cdp_url()
# 使用 Playwright 连接并操作
with sync_playwright() as p:
    browser = p.chromium.connect_over_cdp(cdp_url)
    page = browser.contexts[0].pages[0]
    page.goto("https://www.example.com")
    page.screenshot(path="screenshot.png")
    browser.close()
# 销毁 Sandbox
sandbox.delete()</code></pre><p><strong>关键概念：</strong></p><ul><li><strong>template_name：</strong> 控制台创建的浏览器环境模板</li><li><strong>cdp_url：</strong> 用于 Playwright/Puppeteer 连接</li><li><strong>vnc_url：</strong> 用于实时查看浏览器画面（可通过 sandbox.get_cdp_url() 获取）</li></ul><p><strong><em>注意：</em></strong> 由于所有浏览器操作都在云端进行，您无需在本地安装浏览器。Playwright 仅用于通过 CDP 协议连接到云端的浏览器实例。</p><h3>如何创建 Sandbox 模板</h3><p>使用 Browser Sandbox 需要新建 Sandbox 模板，您需要访问 AgentRun 控制台网站 <strong>[</strong> <strong>1]</strong> ，并按照如下步骤创建模板：</p><ol><li>在顶部菜单栏选择“运行时与沙箱”；</li><li>在左侧边栏选择“Sandbox 沙箱”；</li><li>点击右上角“创建沙箱模板”；</li></ol><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559403" alt="image" title="image"/></p><ol start="4"><li>选择“浏览器”；</li></ol><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559404" alt="image" title="image" loading="lazy"/></p><ol start="5"><li>在弹出的抽屉对话框中填写和选择您的模板的规格、网络等配置，并复制模板名称；</li></ol><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559405" alt="image" title="image" loading="lazy"/></p><ol start="6"><li>点击“创建浏览器”等待其就绪即可。</li></ol><h3>从零开始用 LangChain 创建 Browser Sandbox 智能体</h3><p>本教程将指导您从零开始创建一个完整的 Browser Sandbox 智能体项目。</p><h4>基于 LangChain 集成 Browser Sandbox</h4><p>本教程将详细讲解如何使用 LangChain 创建 Browser Sandbox 相关的 Tools 并集成到 Agent 中。</p><p><strong>项目结构</strong></p><p>为了保持代码的内聚性和可维护性，我们将代码拆分为以下模块：</p><p>模块职责划分：</p><p><code>sandbox_manager.py</code>：负责 Sandbox 的创建、管理和销毁，提供统一的接口  <br/><code>langchain_agent.py</code>：负责创建 LangChain Tools 和 Agent，集成 VNC 信息<br/><code>main.py</code>：作为入口文件，演示如何使用上述模块</p><p><strong>步骤 1：创建项目并安装依赖</strong></p><p>首先创建项目目录（如果还没有）：</p><pre><code>mkdir -p langchain-demo
cd langchain-demo</code></pre><p>创建 requirements.txt 文件，内容如下：</p><pre><code># LangChain 核心库
langchain&gt;=0.1.0
langchain-openai&gt;=0.0.5
langchain-community&gt;=0.0.20
# AgentRun SDK
agentrun-sdk[playwright,server]&gt;=0.0.8
# 浏览器自动化
playwright&gt;=1.40.0
# 环境变量管理
python-dotenv&gt;=1.0.0</code></pre><p>然后安装依赖：</p><pre><code>pip install -r requirements.txt</code></pre><p>主要依赖说明：</p><ul><li><code>langchain</code> 和 <code>langchain-openai</code>：LangChain 核心库</li><li><code>agentrun-sdk[playwright,server]</code>：AgentRun SDK，用于 Sandbox 管理</li><li><code>playwright</code>：浏览器自动化库</li><li><code>python-dotenv</code>：环境变量管理</li></ul><p><strong>步骤 2：配置环境变量</strong></p><p>在项目根目录创建 <code>.env</code> 文件，配置以下环境变量：</p><pre><code># 阿里云百炼平台的 API Key，用于调用大模型能力
# 请前往 https://bailian.console.aliyun.com/?tab=app#/api-key 创建和查看
DASHSCOPE_API_KEY=sk-your-bailian-api-key
# 阿里云账号的访问密钥 ID 和访问密钥 Secret，用于 AgentRun SDK 鉴权
ALIBABA_CLOUD_ACCESS_KEY_ID=your-ak
ALIBABA_CLOUD_ACCESS_KEY_SECRET=your-sk
ALIBABA_CLOUD_ACCOUNT_ID=your-main-account-id
ALIBABA_CLOUD_REGION=cn-hangzhou
# browser sandbox 模板的名称，可以在 https://functionai.console.aliyun.com/cn-hangzhou/agent/runtime/sandbox 控制台创建
BROWSER_TEMPLATE_NAME=sandbox-your-template-name
# agentrun 的控制面和数据面的 API 端点请求地址，默认cn-hangzhou
AGENTRUN_CONTROL_ENDPOINT=agentrun.cn-hangzhou.aliyuncs.com
AGENTRUN_DATA_ENDPOINT=https://${your-main-account-id}.agentrun-data.cn-hangzhou.aliyuncs.com</code></pre><p><strong>步骤 3：创建 Sandbox 生命周期管理模块</strong></p><p>创建 sandbox_manager.py 文件，负责 Sandbox 的创建、管理和销毁。核心代码如下：</p><pre><code>"""
Sandbox 生命周期管理模块
负责 AgentRun Browser Sandbox 的创建、管理和销毁。
提供统一的接口供 LangChain Agent 使用。
"""
import os
from typing import Optional, Dict, Any
from dotenv import load_dotenv
# 加载环境变量
load_dotenv()
class SandboxManager:
    """Sandbox 生命周期管理器"""
    def __init__(self):
        self._sandbox: Optional[Any] = None
        self._sandbox_id: Optional[str] = None
        self._cdp_url: Optional[str] = None
        self._vnc_url: Optional[str] = None
    def create(
        self,
        template_name: Optional[str] = None,
        idle_timeout: int = 3000
    ) -&gt; Dict[str, Any]:
        """
        创建或获取一个浏览器 sandbox 实例
        Args:
            template_name: Sandbox 模板名称，如果为 None 则从环境变量读取
            idle_timeout: 空闲超时时间（秒），默认 3000 秒
        Returns:
            dict: 包含 sandbox_id, cdp_url, vnc_url 的字典
        Raises:
            RuntimeError: 创建失败时抛出异常
        """
        try:
            from agentrun.sandbox import Sandbox, TemplateType
            # 如果已有 sandbox，直接返回
            if self._sandbox is not None:
                return self.get_info()
            # 从环境变量获取模板名称
            if template_name is None:
                template_name = os.getenv(
                    "BROWSER_TEMPLATE_NAME",
                    "sandbox-browser-demo"
                )
            # 创建 sandbox
            self._sandbox = Sandbox.create(
                template_type=TemplateType.BROWSER,
                template_name=template_name,
                sandbox_idle_timeout_seconds=idle_timeout
            )
            self._sandbox_id = self._sandbox.sandbox_id
            self._cdp_url = self._get_cdp_url()
            self._vnc_url = self._get_vnc_url()
            return self.get_info()
        except ImportError as e:
            print(e)
            raise RuntimeError(
                "agentrun-sdk 未安装，请运行: pip install agentrun-sdk[playwright,server]"
            )
        except Exception as e:
            raise RuntimeError(f"创建 Sandbox 失败: {str(e)}")
    def get_info(self) -&gt; Dict[str, Any]:
        """
        获取当前 sandbox 的信息
        Returns:
            dict: 包含 sandbox_id, cdp_url, vnc_url 的字典
        Raises:
            RuntimeError: 如果没有活动的 sandbox
        """
        if self._sandbox is None:
            raise RuntimeError("没有活动的 sandbox，请先创建")
        return {
            "sandbox_id": self._sandbox_id,
            "cdp_url": self._cdp_url,
            "vnc_url": self._vnc_url,
        }
    def get_cdp_url(self) -&gt; Optional[str]:
        """获取 CDP URL"""
        return self._sandbox.get_cdp_url()
    def get_vnc_url(self) -&gt; Optional[str]:
        """获取 VNC URL"""
        return self._sandbox.get_vnc_url()
    def get_sandbox_id(self) -&gt; Optional[str]:
        """获取 Sandbox ID"""
        return self._sandbox_id
    def destroy(self) -&gt; str:
        """
        销毁当前的 sandbox 实例
        Returns:
            str: 操作结果描述
        """
        if self._sandbox is None:
            return "没有活动的 sandbox"
        try:
            sandbox_id = self._sandbox_id
            # 尝试销毁 sandbox
            if hasattr(self._sandbox, 'delete'):
                self._sandbox.delete()
            elif hasattr(self._sandbox, 'stop'):
                self._sandbox.stop()
            elif hasattr(self._sandbox, 'destroy'):
                self._sandbox.destroy()
            # 清理状态
            self._sandbox = None
            self._sandbox_id = None
            self._cdp_url = None
            self._vnc_url = None
            return f"Sandbox 已销毁: {sandbox_id}"
        except Exception as e:
            # 即使销毁失败，也清理本地状态
            self._sandbox = None
            self._sandbox_id = None
            self._cdp_url = None
            self._vnc_url = None
            return f"销毁 Sandbox 时出错: {str(e)}"
    def is_active(self) -&gt; bool:
        """检查 sandbox 是否活跃"""
        return self._sandbox is not None
    def __enter__(self):
        """上下文管理器入口"""
        return self
    def __exit__(self, exc_type, exc_val, exc_tb):
        """上下文管理器退出，自动销毁"""
        self.destroy()
        return False
# 全局单例（可选，用于简单场景）
_global_manager: Optional[SandboxManager] = None
def get_global_manager() -&gt; SandboxManager:
    """获取全局 SandboxManager 单例"""
    global _global_manager
    if _global_manager is None:
        _global_manager = SandboxManager()
    return _global_manager
def reset_global_manager():
    """重置全局 SandboxManager"""
    global _global_manager
    if _global_manager:
        _global_manager.destroy()
    _global_manager = None</code></pre><p><strong>关键功能：</strong></p><ol><li><strong>创建 Sandbox：</strong> 使用 AgentRun SDK 创建浏览器 Sandbox</li><li><strong>获取连接信息：</strong> 自动获取 CDP URL 和 VNC URL，支持多种属性名兼容</li><li><strong>生命周期管理：</strong> 提供销毁方法，确保资源正确释放</li></ol><p><strong>步骤 4：创建 LangChain Tools 和 Agent</strong></p><p>创建 langchain_agent.py 文件，定义 LangChain Tools 并创建 Agent。核心代码如下：</p><pre><code>"""
LangChain Agent 和 Tools 注册模块
负责创建 LangChain Agent，注册 Sandbox 相关的 tools，并集成 VNC 可视化。
本模块使用 sandbox_manager.py 中封装的 SandboxManager 来管理 sandbox 生命周期。
"""
import os
from dotenv import load_dotenv
from langchain.tools import tool
from langchain_openai import ChatOpenAI
from langchain.agents import create_agent
from pydantic import BaseModel, Field
# 导入 sandbox 管理器
from sandbox_manager import SandboxManager
# 加载环境变量
load_dotenv()
# 全局 sandbox 管理器实例（单例模式）
_sandbox_manager: SandboxManager | None = None
def get_sandbox_manager() -&gt; SandboxManager:
    """获取 sandbox 管理器实例（单例模式）"""
    global _sandbox_manager
    if _sandbox_manager is None:
        _sandbox_manager = SandboxManager()
    return _sandbox_manager
# ============ LangChain Tools 定义 ============
@tool
def create_browser_sandbox(
    template_name: str = None,
    idle_timeout: int = 3000
) -&gt; str:
    """创建或获取一个浏览器 sandbox 实例。
    当需要访问网页、执行浏览器操作时，首先需要创建 sandbox。
    创建成功后，会返回 sandbox 信息，包括 VNC URL 用于可视化。
    Args:
        template_name: Sandbox 模板名称，如果不提供则从环境变量 BROWSER_TEMPLATE_NAME 读取
        idle_timeout: 空闲超时时间（秒），默认 3000 秒
    Returns:
        Sandbox 信息字符串，包括 ID、CDP URL、VNC URL
    """
    try:
        manager = get_sandbox_manager()
        # 如果 template_name 为空字符串，转换为 None 以便从环境变量读取
        if template_name == "":
            template_name = None
        info = manager.create(template_name=template_name, idle_timeout=idle_timeout)
        result = f"""✅ Sandbox 创建成功！
📋 Sandbox 信息:
- ID: {info['sandbox_id']}
- CDP URL: {info['cdp_url']}
"""
        vnc_url = info.get('vnc_url')
        if vnc_url:
            result += f"- VNC URL: {vnc_url}\n\n"
            result += "提示: VNC 查看器应该已自动打开，您可以在浏览器中实时查看浏览器操作。"
        else:
            result += "\n警告: 未获取到 VNC URL，可能无法使用可视化功能。"
        return result
    except Exception as e:
        return f" 创建 Sandbox 失败: {str(e)}"
@tool
def get_sandbox_info() -&gt; str:
    """获取当前 sandbox 的详细信息，包括 ID、CDP URL、VNC URL 等。
    当需要查看当前 sandbox 状态或获取 VNC 连接信息时使用此工具。
    Returns:
        Sandbox 信息字符串
    """
    try:
        manager = get_sandbox_manager()
        info = manager.get_info()
        result = f"""📋 当前 Sandbox 信息:
- Sandbox ID: {info['sandbox_id']}
- CDP URL: {info['cdp_url']}
"""
        if info.get('vnc_url'):
            result += f"- VNC URL: {info['vnc_url']}\n\n"
            result += "您可以使用 VNC URL 在浏览器中实时查看操作过程。\n"
            result += "   推荐使用 vnc.html 文件或 noVNC 客户端。"
        return result
    except RuntimeError as e:
        return f" {str(e)}"
    except Exception as e:
        return f" 获取 Sandbox 信息失败: {str(e)}"
class NavigateInput(BaseModel):
    """浏览器导航输入参数"""
    url: str = Field(description="要访问的网页 URL，必须以 http:// 或 https:// 开头")
    wait_until: str = Field(
        default="load",
        description="等待页面加载的状态: load, domcontentloaded, networkidle"
    )
    timeout: int = Field(
        default=30000,
        description="超时时间（毫秒），默认 30000"
    )
@tool(args_schema=NavigateInput)
def navigate_to_url(url: str, wait_until: str = "load", timeout: int = 30000) -&gt; str:
    """使用 sandbox 中的浏览器导航到指定 URL。
    当用户需要访问网页时使用此工具。导航后可以在 VNC 中实时查看页面。
    Args:
        url: 要访问的网页 URL
        wait_until: 等待页面加载的状态（load/domcontentloaded/networkidle）
        timeout: 超时时间（毫秒）
    Returns:
        导航结果描述
    """
    try:
        manager = get_sandbox_manager()
        if not manager.is_active():
            return " 错误: 请先创建 sandbox"
        # 验证 URL
        if not url.startswith(("http://", "https://")):
            return f" 错误: 无效的 URL 格式: {url}"
        cdp_url = manager.get_cdp_url()
        if not cdp_url:
            return " 错误: 无法获取 CDP URL"
        # 使用 Playwright 连接浏览器并导航
        try:
            from playwright.sync_api import sync_playwright
            with sync_playwright() as p:
                browser = p.chromium.connect_over_cdp(cdp_url)
                pages = browser.contexts[0].pages if browser.contexts else []
                if pages:
                    page = pages[0]
                else:
                    page = browser.new_page()
                page.goto(url, wait_until=wait_until, timeout=timeout)
                title = page.title()
                return f"已成功导航到: {url}\n📄 页面标题: {title}\n💡 您可以在 VNC 中查看页面内容。"
        except ImportError:
            return f"导航指令已发送: {url}\n💡 提示: 安装 playwright 以启用实际导航功能 (pip install playwright)"
        except Exception as e:
            return f" 导航失败: {str(e)}"
    except Exception as e:
        return f" 操作失败: {str(e)}"
@tool("browser_screenshot", description="在浏览器 sandbox 中截取当前页面截图")
def take_screenshot(filename: str = "screenshot.png") -&gt; str:
    """截取浏览器当前页面的截图。
    Args:
        filename: 截图文件名，默认 "screenshot.png"
    Returns:
        操作结果
    """
    try:
        manager = get_sandbox_manager()
        if not manager.is_active():
            return " 错误: 请先创建 sandbox"
        cdp_url = manager.get_cdp_url()
        if not cdp_url:
            return " 错误: 无法获取 CDP URL"
        try:
            from playwright.sync_api import sync_playwright
            with sync_playwright() as p:
                browser = p.chromium.connect_over_cdp(cdp_url)
                pages = browser.contexts[0].pages if browser.contexts else []
                if pages:
                    page = pages[0]
                else:
                    return " 错误: 没有打开的页面"
                page.screenshot(path=filename)
                return f"截图已保存: {filename}"
        except ImportError:
            return " 错误: 需要安装 playwright (pip install playwright)"
        except Exception as e:
            return f" 截图失败: {str(e)}"
    except Exception as e:
        return f" 操作失败: {str(e)}"
@tool("destroy_sandbox", description="销毁当前的 sandbox 实例，释放资源。注意：仅在程序退出或明确需要释放资源时使用，不要在一轮对话后销毁。")
def destroy_sandbox() -&gt; str:
    """销毁当前的 sandbox 实例。
    重要提示：此工具应该仅在以下情况使用：
    - 程序即将退出
    - 明确需要释放资源
    - 用户明确要求销毁
    不要在一轮对话完成后就销毁 sandbox，因为 sandbox 可以在多轮对话中复用。
    Returns:
        操作结果
    """
    try:
        manager = get_sandbox_manager()
        result = manager.destroy()
        return result
    except Exception as e:
        return f" 销毁失败: {str(e)}"
# ============ Agent 创建 ============
def create_browser_agent(system_prompt: str = None):
    """
    创建带有 sandbox 工具的 LangChain Agent
    Args:
        system_prompt: 自定义系统提示词，如果为 None 则使用默认提示词
    Returns:
        LangChain Agent 实例
    """
    # 配置 DashScope API
    api_key = os.getenv("DASHSCOPE_API_KEY")
    if not api_key:
        raise ValueError("请设置环境变量 DASHSCOPE_API_KEY")
    base_url = "https://dashscope.aliyuncs.com/compatible-mode/v1"
    model_name = os.getenv("QWEN_MODEL", "qwen-plus")
    # 创建 LLM
    model = ChatOpenAI(
        model=model_name,
        api_key=api_key,
        base_url=base_url,
        temperature=0.7,
    )
    # 创建工具列表
    tools = [
        create_browser_sandbox,
        get_sandbox_info,
        navigate_to_url,
        take_screenshot,
        destroy_sandbox,
    ]
    # 默认系统提示词
    if system_prompt is None:
        system_prompt = """你是一个浏览器自动化助手，可以使用 sandbox 来访问和操作网页。
当用户需要访问网页时，请按以下步骤操作：
1. 首先创建或获取 sandbox（如果还没有）
2. 使用 navigate_to_url 导航到目标网页
3. 执行用户请求的操作
4. 如果需要，可以截取截图
重要提示：
- 创建 sandbox 后，会返回 VNC URL，用户可以使用它实时查看浏览器操作
- 所有操作都会在 VNC 中实时显示，方便调试和监控
- sandbox 可以在多轮对话中复用，不要在一轮对话完成后就销毁
- 只有在用户明确要求销毁时才使用 destroy_sandbox 工具
- 不要主动建议用户销毁 sandbox，除非用户明确要求
- 请始终用中文回复，确保操作准确、高效。"""
    # 创建 Agent
    agent = create_agent(
        model=model,
        tools=tools,
        system_prompt=system_prompt,
    )
    return agent
def get_available_tools():
    """获取所有可用的工具列表"""
    return [
        create_browser_sandbox,
        get_sandbox_info,
        navigate_to_url,
        take_screenshot,
        destroy_sandbox,
    ]</code></pre><p><strong>关键要点：</strong></p><ol><li><strong>Tool 定义：</strong> 使用 @tool 装饰器定义 LangChain Tools</li><li><strong>类型提示：</strong> 所有参数必须有类型提示，用于生成工具 schema</li><li><strong>文档字符串：</strong> 详细的文档字符串帮助 LLM 理解何时使用工具**</li><li><strong>单例模式：</strong> 使用全局管理器实例确保 Sandbox 在会话中复用**</li></ol><p><strong>步骤 5：创建主入口文件</strong></p><p>创建 main.py 文件，作为程序入口。核心代码如下：</p><pre><code>"""
LangChain + AgentRun Browser Sandbox 集成示例
主入口文件，演示如何使用 LangChain Agent 与 AgentRun Browser Sandbox 集成。
"""
import os
import sys
import signal
import webbrowser
import urllib.parse
import threading
import http.server
import socketserver
from pathlib import Path
from dotenv import load_dotenv
from langchain_agent import create_browser_agent, get_sandbox_manager
# 加载环境变量
load_dotenv()
# 全局 HTTP 服务器实例
_http_server = None
_http_port = 8080
# 全局清理标志，用于防止重复清理
_cleanup_done = False
def start_http_server():
    """启动一个简单的 HTTP 服务器来提供 vnc.html"""
    global _http_server
    if _http_server is not None:
        return _http_port
    try:
        current_dir = Path(__file__).parent.absolute()
        class VNCRequestHandler(http.server.SimpleHTTPRequestHandler):
            def __init__(self, *args, **kwargs):
                super().__init__(*args, directory=str(current_dir), **kwargs)
            def log_message(self, format, *args):
                # 静默日志，避免输出过多信息
                pass
        # 尝试启动服务器
        for port in range(_http_port, _http_port + 10):
            try:
                server = socketserver.TCPServer(("", port), VNCRequestHandler)
                server.allow_reuse_address = True
                # 在后台线程中运行服务器
                def run_server():
                    server.serve_forever()
                thread = threading.Thread(target=run_server, daemon=True)
                thread.start()
                _http_server = server
                return port
            except OSError:
                continue
        return None
    except Exception as e:
        print(f"启动 HTTP 服务器失败: {str(e)}")
        return None
def open_vnc_viewer(vnc_url: str):
    """
    自动打开 VNC 查看器并设置 VNC URL
    Args:
        vnc_url: VNC WebSocket URL
    """
    if not vnc_url:
        return
    try:
        # 获取当前文件所在目录
        current_dir = Path(__file__).parent.absolute()
        vnc_html_path = current_dir / "vnc.html"
        # 检查文件是否存在
        if not vnc_html_path.exists():
            print(f"警告: vnc.html 文件不存在: {vnc_html_path}")
            print_vnc_info(vnc_url)
            return
        # 启动 HTTP 服务器
        port = start_http_server()
        if port:
            # 编码 VNC URL 作为 URL 参数
            encoded_url = urllib.parse.quote(vnc_url, safe='')
            # 构建 HTTP URL
            http_url = f"http://localhost:{port}/vnc.html?url={encoded_url}"
            # 打开浏览器
            print(f"\n正在打开 VNC 查看器...")
            print(f"HTTP 服务器运行在: http://localhost:{port}")
            print(f"VNC URL: {vnc_url[:80]}...")
            print(f"完整 URL: {http_url[:100]}...")
            webbrowser.open(http_url)
            print(f"VNC 查看器已打开")
            print(f"VNC URL 已通过 URL 参数自动设置，页面加载后会自动连接")
        else:
            # 如果 HTTP 服务器启动失败，尝试使用 file:// 协议
            print(f"HTTP 服务器启动失败，尝试使用文件协议...")
            encoded_url = urllib.parse.quote(vnc_url, safe='')
            file_url = f"file://{vnc_html_path}?url={encoded_url}"
            webbrowser.open(file_url)
            print(f"VNC 查看器已打开（使用文件协议）")
            print(f"提示: 如果无法自动连接，请手动复制 VNC URL 到输入框")
    except Exception as e:
        print(f"自动打开 VNC 查看器失败: {str(e)}")
        print_vnc_info(vnc_url)
def print_vnc_info(vnc_url: str):
    """打印 VNC 连接信息"""
    if not vnc_url:
        return
    print("\n" + "=" * 60)
    print("VNC 可视化连接信息")
    print("=" * 60)
    print(f"\nVNC URL: {vnc_url}")
    print("\n使用方式:")
    print("   1. 使用 noVNC 客户端连接")
    print("   2. 或在浏览器中访问 VNC 查看器页面")
    print("   3. 实时查看浏览器操作过程")
    print("\n" + "=" * 60 + "\n")
def cleanup_sandbox():
    """
    清理 sandbox 资源
    这个函数可以被信号处理器、异常处理器和正常退出流程调用
    """
    global _cleanup_done
    # 防止重复清理
    if _cleanup_done:
        return
    _cleanup_done = True
    try:
        manager = get_sandbox_manager()
        if manager.is_active():
            print("\n" + "=" * 60)
            print("正在清理 sandbox...")
            print("=" * 60)
            result = manager.destroy()
            print(f"清理结果: {result}\n")
        else:
            print("\n没有活动的 sandbox 需要清理\n")
    except Exception as e:
        print(f"\n清理 sandbox 时出错: {str(e)}\n")
def signal_handler(signum, frame):
    """
    信号处理器，处理 Ctrl+C (SIGINT) 和其他信号
    Args:
        signum: 信号编号
        frame: 当前堆栈帧
    """
    print("\n\n收到中断信号，正在清理资源...")
    cleanup_sandbox()
    print("清理完成")
    sys.exit(0)
def main():
    """主函数"""
    global _cleanup_done
    # 重置清理标志
    _cleanup_done = False
    # 注册信号处理器，处理 Ctrl+C (SIGINT)
    signal.signal(signal.SIGINT, signal_handler)
    # 在 Windows 上，SIGBREAK 也可以处理
    if hasattr(signal, 'SIGBREAK'):
        signal.signal(signal.SIGBREAK, signal_handler)
    print("=" * 60)
    print("LangChain + AgentRun Browser Sandbox 集成示例")
    print("=" * 60)
    print()
    try:
        # 创建 Agent
        print("正在初始化 LangChain Agent...")
        agent = create_browser_agent()
        print("Agent 初始化完成\n")
        # 示例查询
        queries = [
            "创建一个浏览器 sandbox",
            "获取当前 sandbox 的信息，包括 VNC URL",
            "导航到 https://www.aliyun.com",
            "截取当前页面截图",
        ]
        # 执行查询
        for i, query in enumerate(queries, 1):
            print(f"\n{'=' * 60}")
            print(f"查询 {i}: {query}")
            print(f"{'=' * 60}\n")
            try:
                result = agent.invoke({
                    "messages": [{"role": "user", "content": query}]
                })
                # 提取最后一条消息的内容
                output = result.get("messages", [])[-1].content if isinstance(result.get("messages"), list) else result.get("output", str(result))
                print(f"\n结果:\n{output}\n")
                # 如果是创建 sandbox，自动打开 VNC 查看器
                if i == 1:
                    try:
                        # 等待一下确保 sandbox 完全创建
                        import time
                        time.sleep(1)
                        manager = get_sandbox_manager()
                        if manager.is_active():
                            info = manager.get_info()
                            vnc_url = info.get('vnc_url')
                            if vnc_url:
                                print(f"\n检测到 VNC URL: {vnc_url[:80]}...")
                                open_vnc_viewer(vnc_url)
                                print_vnc_info(vnc_url)
                            else:
                                print("\n警告: 未获取到 VNC URL，请检查 sandbox 创建是否成功")
                    except Exception as e:
                        print(f"打开 VNC 查看器时出错: {str(e)}")
                        import traceback
                        traceback.print_exc()
                # 如果是获取信息，显示 VNC 信息
                elif i == 2:
                    try:
                        manager = get_sandbox_manager()
                        if manager.is_active():
                            info = manager.get_info()
                            if info.get('vnc_url'):
                                print_vnc_info(info['vnc_url'])
                    except:
                        pass
            except Exception as e:
                print(f"查询失败: {str(e)}\n")
                import traceback
                traceback.print_exc()
        # 交互式查询
        print("\n" + "=" * 60)
        print("进入交互模式（输入 'quit' 或 'exit' 退出，Ctrl+C 或 Ctrl+D 中断）")
        print("=" * 60 + "\n")
        while True:
            try:
                user_input = input("请输入您的查询: ").strip()
            except EOFError:
                # 处理 Ctrl+D (EOF)
                print("\n\n检测到输入结束 (Ctrl+D)，正在清理资源...")
                cleanup_sandbox()
                print("清理完成")
                break
            except KeyboardInterrupt:
                # 处理 Ctrl+C (在 input 调用期间)
                print("\n\n检测到中断信号 (Ctrl+C)，正在清理资源...")
                cleanup_sandbox()
                print("清理完成")
                break
            if not user_input:
                continue
            if user_input.lower() in ['quit', 'exit', '退出']:
                print("\nBye")
                # 退出前清理 sandbox
                cleanup_sandbox()
                break
            try:
                result = agent.invoke({
                    "messages": [{"role": "user", "content": user_input}]
                })
                output = result.get("messages", [])[-1].content if isinstance(result.get("messages"), list) else result.get("output", str(result))
                print(f"\n结果:\n{output}\n")
                # 检查是否需要打开或显示 VNC 信息
                user_input_lower = user_input.lower()
                if "创建" in user_input_lower and "sandbox" in user_input_lower:
                    # 如果是创建 sandbox，自动打开 VNC 查看器
                    try:
                        # 等待一下确保 sandbox 完全创建
                        import time
                        time.sleep(1)
                        manager = get_sandbox_manager()
                        if manager.is_active():
                            info = manager.get_info()
                            vnc_url = info.get('vnc_url')
                            if vnc_url:
                                print(f"\n检测到 VNC URL: {vnc_url[:80]}...")
                                open_vnc_viewer(vnc_url)
                                print_vnc_info(vnc_url)
                            else:
                                print("\n警告: 未获取到 VNC URL，请检查 sandbox 创建是否成功")
                    except Exception as e:
                        print(f"打开 VNC 查看器时出错: {str(e)}")
                        import traceback
                        traceback.print_exc()
                elif "sandbox" in user_input_lower or "vnc" in user_input_lower:
                    # 其他情况只显示信息
                    try:
                        manager = get_sandbox_manager()
                        if manager.is_active():
                            info = manager.get_info()
                            if info.get('vnc_url'):
                                print_vnc_info(info['vnc_url'])
                    except:
                        pass
            except Exception as e:
                print(f"查询失败: {str(e)}\n")
                import traceback
                traceback.print_exc()
        # 清理资源（仅在程序正常退出时）
        cleanup_sandbox()
    except KeyboardInterrupt:
        # 处理顶层 KeyboardInterrupt (Ctrl+C)
        print("\n\n检测到中断信号 (Ctrl+C)，正在清理资源...")
        cleanup_sandbox()
        print("清理完成")
        sys.exit(0)
    except EOFError:
        # 处理顶层 EOFError (Ctrl+D)
        print("\n\n检测到输入结束 (Ctrl+D)，正在清理资源...")
        cleanup_sandbox()
        print("清理完成")
        sys.exit(0)
    except ValueError as e:
        print(f"配置错误: {str(e)}")
        print("\n提示: 请确保已设置以下环境变量:")
        print("   - DASHSCOPE_API_KEY: DashScope API Key")
        print("   - ALIBABA_CLOUD_ACCOUNT_ID: 阿里云账号 ID")
        print("   - ALIBABA_CLOUD_ACCESS_KEY_ID: 访问密钥 ID")
        print("   - ALIBABA_CLOUD_ACCESS_KEY_SECRET: 访问密钥 Secret")
        print("   - ALIBABA_CLOUD_REGION: 区域（默认: cn-hangzhou）")
    except Exception as e:
        print(f"发生错误: {str(e)}")
        import traceback
        traceback.print_exc()
        # 发生错误时也尝试清理
        cleanup_sandbox()
if __name__ == "__main__":
    main()</code></pre><p><strong>关键功能：</strong></p><ol><li><strong>VNC 自动打开：</strong> 创建 Sandbox 后自动打开 VNC 查看器</li><li><strong>信号处理：</strong> 捕获 Ctrl+C，确保资源正确清理</li><li><strong>交互模式：</strong> 支持持续对话，复用 Sandbox 实例</li></ol><p><strong>VNC 可视化集成</strong></p><p>VNC（Virtual Network Computing）功能允许您实时查看和监控浏览器在 Sandbox 中的操作过程，这对于调试和监控 Agent 行为非常有用。</p><p><strong>获取 VNC URL：</strong></p><p>创建 Sandbox 后，可以通过 <code>get_sandbox_info tool</code> 获取 VNC URL：</p><pre><code># 通过 Agent 调用
result = agent.invoke({
    "messages": [{"role": "user", "content": "获取 sandbox 信息"}]
})
# 或直接通过管理器获取
manager = get_sandbox_manager()
info = manager.get_info()
vnc_url = info['vnc_url']</code></pre><p><strong>自动打开 VNC 查看器：</strong></p><p>在 <code>main.py</code> 中，我们实现了自动打开 VNC 查看器的功能：</p><pre><code>import webbrowser
import urllib.parse
from pathlib import Path
def open_vnc_viewer(vnc_url: str):
    """自动打开 VNC 查看器"""
    current_dir = Path(__file__).parent.absolute()
    vnc_html_path = current_dir / "vnc.html"
    if vnc_html_path.exists():
        # 通过 URL 参数传递 VNC URL
        encoded_url = urllib.parse.quote(vnc_url, safe='')
        file_url = f"file://{vnc_html_path}?url={encoded_url}"
        webbrowser.open(file_url)</code></pre><p><strong>VNC HTML 页面：</strong></p><p><code>vnc.html</code> 页面会从 URL 参数中读取 VNC URL，并自动连接到 VNC 服务器。页面包含以下核心功能：</p><ol><li><strong>noVNC 库加载：</strong> 从 CDN 动态加载 noVNC 客户端库</li><li><strong>自动连接：</strong> 读取 URL 参数中的 VNC URL 并自动连接</li><li><strong>状态显示：</strong> 显示连接状态（连接中、已连接、已断开）</li><li><strong>手动控制：</strong> 支持手动输入 VNC URL、断开重连等操作</li></ol><p>核心 JavaScript 代码片段：</p><pre><code>// 从 URL 参数获取 VNC URL
const urlParams = new URLSearchParams(window.location.search);
const vncUrl = urlParams.get('url');
// 加载 noVNC 库
async function loadNoVNC() {
    const module = await import('https://cdn.jsdelivr.net/gh/novnc/noVNC@v1.4.0/core/rfb.js');
    return module.default;
}
// 连接 VNC
async function connectVNC(url) {
    const RFB = await loadNoVNC();
    rfb = new RFB(vncScreen, url, {
        shared: true,
        credentials: { password: '' }
    });
    rfb.addEventListener('connect', () =&gt; {
        console.log('VNC 连接成功');
    });
}</code></pre><p>完整的 vnc.html 文件可以在示例代码仓库中获取。</p><p><strong>手动使用 VNC 查看器：</strong></p><p>如果自动打开失败，您也可以手动使用 VNC 查看器：</p><p><strong>1. 使用 noVNC 在线客户端：</strong></p><ul><li>访问 noVNC 在线客户端 <strong>[</strong> <strong>2]</strong></li><li>在连接设置中填入 VNC URL</li><li>点击连接</li></ul><p><strong>2. 使用本地 VNC HTML 页面：</strong></p><ul><li>打开 <code>vnc.html</code></li><li>输入 VNC URL</li><li>点击连接按钮</li></ul><p><strong>实时监控功能：</strong></p><ul><li>所有浏览器操作都会在 VNC 中实时显示</li><li>可以看到 Agent 的每一步操作（导航、点击、输入等）</li><li>方便调试和监控 Agent 行为</li><li>支持交互式操作（在 VNC 中直接操作浏览器）</li></ul><p><strong>运行和测试</strong></p><pre><code>python main.py</code></pre><p>程序会自动：</p><ol><li>创建 Browser Sandbox</li><li>打开 VNC 查看器（实时查看浏览器操作）</li><li>执行预设查询</li><li>进入交互模式</li></ol><h3>工作原理</h3><p>为了更好地理解系统架构，我们将工作流程拆分为两个部分：<strong>LangChain Agent 工作流程</strong>和 <strong>SandboxManager 生命周期管理</strong>。</p><p><strong>1. LangChain Agent 工作流程</strong></p><p>下图展示了 LangChain Agent 如何处理用户请求并调用相应的 Tools：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559406" alt="image" title="image" loading="lazy"/></p><p><strong>Agent 工作流程说明：</strong></p><ol><li><strong>请求接收：</strong> 用户发起自然语言请求（如“访问淘宝首页并截图”）</li><li><strong>意图分析：</strong> Agent 分析用户意图，决定需要调用哪些 Tools</li><li><strong>Tool 调用：</strong> 根据任务需求，顺序或组合调用多个 Tools</li><li><strong>Manager 交互：</strong> 所有 Tools 都通过 SandboxManager 单例实例操作 Sandbox</li><li><strong>结果处理：</strong> Agent 将 Tool 返回的结果整合成用户友好的响应</li><li><strong>多轮对话：</strong> Sandbox 在整个会话中保持活跃，支持多轮对话</li></ol><p>5 个核心 Tools 的职责：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559407" alt="image" title="image" loading="lazy"/></p><p><strong>2. SandboxManager 生命周期管理</strong></p><p>下图展示了 SandboxManager 如何管理 Sandbox 的完整生命周期：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559408" alt="image" title="image" loading="lazy"/></p><p><strong>SandboxManager 工作流程说明：</strong></p><p><strong>1. 单例管理：</strong></p><ul><li>首次调用时创建 Manager 实例</li><li>后续调用复用同一个实例</li><li>确保整个会话只有一个 Sandbox</li></ul><p><strong>2. Sandbox 创建：</strong></p><ul><li>调用 AgentRun SDK 的 <code>Sandbox.create()</code></li><li>SDK 通过阿里云 API 与函数计算 FC 通信</li><li>FC 服务创建独立的容器实例，包含：</li><li>Chromium 浏览器 VNC 服务必要的运行环境</li></ul><p><strong>3. 连接信息获取：</strong></p><ul><li><strong>CDP URL：</strong> WebSocket 地址，用于 Playwright/Puppeteer 远程控制浏览器</li><li><strong>VNC URL：</strong> WebSocket 地址，用于实时查看浏览器画面**</li></ul><p><strong>4. 浏览器操作：</strong></p><ul><li>Playwright 通过 CDP URL 连接到远程浏览器</li><li>执行各种浏览器操作（导航、点击、截图等）</li><li>VNC 同步显示操作过程，用户可实时监控</li></ul><p><strong>5. 资源清理：</strong></p><ul><li>调用 destroy() 方法销毁 Sandbox</li><li>清理 Manager 内部状态</li><li>通过 SDK 释放云端资源</li></ul><p><strong>3. Agent 与 Manager 的协作关系</strong></p><p><strong>交互模式：</strong></p><pre><code>用户请求 → Agent → Tool → SandboxManager → AgentRun SDK → 云端 Sandbox
                                    ↓
用户响应 ← Agent ← Tool ← SandboxManager ← 操作结果</code></pre><p><strong>关键设计理念：</strong></p><ol><li>分层架构：</li></ol><ul><li>用户层：自然语言交互</li><li>Agent 层：意图理解和任务分解</li><li>Tool 层：功能封装和参数验证</li><li>Manager 层：资源管理和状态维护</li><li>SDK 层：云服务通信</li><li>云端层：实际的 Sandbox 环境</li></ul><ol start="2"><li>单例模式：</li></ol><ul><li>SandboxManager 使用单例模式</li><li>保证整个会话中只有一个 Sandbox 实例</li><li>避免资源浪费和状态冲突</li></ul><ol start="3"><li>状态复用：</li></ol><ul><li>Sandbox 在多轮对话中保持活跃</li><li>减少创建和销毁的开销</li><li>提供更流畅的用户体验</li></ul><ol start="4"><li>双通道设计：</li></ol><ul><li>CDP 通道：Agent 通过 Playwright 控制浏览器</li><li><strong>VNC 通道：用户通过 VNC 查看器实时监控</strong></li></ul><ol start="5"><li>解耦设计：</li></ol><ul><li>Tools 不直接操作 SDK，通过 Manager 统一管理</li><li>便于扩展和维护</li><li>统一的错误处理和资源管理</li></ul><p><strong>典型使用场景示例：</strong></p><pre><code># 第 1 轮对话
用户: "创建一个 sandbox 并访问淘宝首页"
→ Agent 调用: create_browser_sandbox → navigate_to_url
→ Manager: 创建 Sandbox → Playwright 导航
→ 结果: "Sandbox 已创建，已访问淘宝首页"
# 第 2 轮对话（复用 Sandbox）
用户: "截取当前页面"
→ Agent 调用: take_screenshot
→ Manager: 使用现有 Sandbox → Playwright 截图
→ 结果: "截图已保存"
# 第 3 轮对话（复用 Sandbox）
用户: "访问京东首页"
→ Agent 调用: navigate_to_url
→ Manager: 使用现有 Sandbox → Playwright 导航
→ 结果: "已访问京东首页"</code></pre><p>通过这种设计，Agent 专注于理解用户意图和任务编排，而 Manager 专注于 Sandbox 的生命周期管理，实现了清晰的职责分离。</p><p><strong>工作原理总结：</strong></p><ol><li>工具注册：使用 @tool 装饰器将 Sandbox 功能封装为 LangChain Tools</li><li>生命周期管理： SandboxManager 负责 Sandbox 的创建、管理和销毁</li><li>状态保持：使用单例模式管理 Sandbox 实例，确保同一会话内复用</li><li>VNC 集成：自动获取并返回 VNC URL，方便用户实时查看</li><li>错误处理：所有工具都包含完善的错误处理机制</li></ol><h3>扩展和定制</h3><p><strong>添加自定义 Tools：</strong></p><pre><code>@tool
def extract_table_data(url: str) -&gt; str:
    """从网页中提取表格数据"""
    from playwright.sync_api import sync_playwright
    manager = get_sandbox_manager()
    cdp_url = manager.get_info()['cdp_url']
    with sync_playwright() as p:
        browser = p.chromium.connect_over_cdp(cdp_url)
        page = browser.contexts[0].pages[0]
        page.goto(url)
        tables = page.query_selector_all("table")
        return f"找到 {len(tables)} 个表格"</code></pre><p><strong>自定义提示词：</strong></p><pre><code>custom_prompt = """你是一个专业的网页数据提取助手。
在执行任务前，请先创建 sandbox，然后使用浏览器工具完成任务。"""
agent = create_browser_agent(system_prompt=custom_prompt)
</code></pre><h3>最佳实践</h3><ol><li>模块化设计：将 Sandbox 管理和 Agent 创建分离，提高代码可维护性</li><li>错误处理：所有工具都应包含完善的错误处理</li><li>资源清理：使用信号处理器确保资源正确清理</li><li>VNC 提示：在工具返回中包含 VNC URL，方便用户使用</li><li>单例模式：确保 Sandbox 实例在会话中复用，避免重复创建</li></ol><h2>前端集成可视化监控（VNC）</h2><h3>VNC 集成架构</h3><p>下图展示了前端如何集成 VNC 实现实时监控：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559409" alt="image" title="image" loading="lazy"/></p><h3>轻量级 HTML 页面集成</h3><p>创建一个简单的 vnc-viewer.html 文件：</p><pre><code>&lt;!DOCTYPE html&gt;
&lt;html&gt;
&lt;head&gt;
    &lt;title&gt;Browser Sandbox VNC 查看器&lt;/title&gt;
    &lt;style&gt;
        body { margin: 0; padding: 0; background: 
#000
; }
        
#vnc
-container { width: 100vw; height: 100vh; }
    &lt;/style&gt;
&lt;/head&gt;
&lt;body&gt;
    &lt;div id="vnc-container"&gt;&lt;/div&gt;
    &lt;script type="module"&gt;
        const params = new URLSearchParams(window.location.search);
        const vncUrl = params.get('url');
        if (!vncUrl) {
            alert('请提供 VNC URL 参数');
        } else {
            const module = await import('https://cdn.jsdelivr.net/gh/novnc/noVNC@v1.4.0/core/rfb.js');
            const RFB = module.default;
            const rfb = new RFB(
                document.getElementById('vnc-container'),
                vncUrl,
                { shared: true, credentials: { password: '' } }
            );
            rfb.scaleViewport = true;
        }
    &lt;/script&gt;
&lt;/body&gt;
&lt;/html&gt;</code></pre><p>使用方式：</p><pre><code>import webbrowser
import urllib.parse
vnc_url = sandbox.vnc_url
encoded_url = urllib.parse.quote(vnc_url, safe='')
viewer_url = f"file:///path/to/vnc-viewer.html?url={encoded_url}"
webbrowser.open(viewer_url)</code></pre><h3>React 应用集成</h3><p>核心组件代码：</p><pre><code>import React, { useEffect, useRef } from 'react';
interface VNCViewerProps {
  vncUrl: string;
  onConnect?: () =&gt; void;
  onDisconnect?: () =&gt; void;
}
export const VNCViewer: React.FC&lt;VNCViewerProps&gt; = ({ 
  vncUrl, 
  onConnect, 
  onDisconnect 
}) =&gt; {
  const containerRef = useRef&lt;HTMLDivElement&gt;(null);
  useEffect(() =&gt; {
    let rfb: any;
    const initVNC = async () =&gt; {
      if (!containerRef.current || !vncUrl) return;
      const { default: RFB } = await import('@novnc/novnc/core/rfb');
      rfb = new RFB(containerRef.current, vncUrl, {
        shared: true,
        credentials: { password: '' }
      });
      rfb.scaleViewport = true;
      rfb.addEventListener('connect', () =&gt; onConnect?.());
      rfb.addEventListener('disconnect', () =&gt; onDisconnect?.());
    };
    initVNC();
    return () =&gt; {
      if (rfb) rfb.disconnect();
    };
  }, [vncUrl, onConnect, onDisconnect]);
  return (
    &lt;div 
      ref={containerRef} 
      style={{ width: '100%', height: '600px', background: '
#000
' }} 
    /&gt;
  );
};</code></pre><p>使用示例：</p><pre><code>import React, { useState, useEffect } from 'react';
import { VNCViewer } from './VNCViewer';
function App() {
  const [vncUrl, setVncUrl] = useState&lt;string&gt;('');
  useEffect(() =&gt; {
    fetch('/api/sandbox/create', { method: 'POST' })
      .then(res =&gt; res.json())
      .then(data =&gt; setVncUrl(data.vnc_url));
  }, []);
  return (
    &lt;div&gt;
      &lt;h1&gt;Browser Sandbox 实时监控&lt;/h1&gt;
      {vncUrl ? (
        &lt;VNCViewer 
          vncUrl={vncUrl}
          onConnect={() =&gt; console.log('已连接')}
          onDisconnect={() =&gt; console.log('已断开')}
        /&gt;
      ) : (
        &lt;p&gt;正在初始化...&lt;/p&gt;
      )}
    &lt;/div&gt;
  );
}</code></pre><h2>Puppeteer 和 Playwright 直接集成</h2><p>如果您更熟悉传统的浏览器自动化库，也可以直接使用 Puppeteer 或 Playwright 连接到 Browser Sandbox。</p><h3>使用 Playwright</h3><pre><code>from playwright.sync_api import sync_playwright
from agentrun.sandbox import Sandbox, TemplateType
# 创建 Sandbox
sandbox = Sandbox.create(
    template_type=TemplateType.BROWSER,
    template_name="your-template-name",
    sandbox_idle_timeout_seconds=3000
)
# 使用 Playwright 连接
with sync_playwright() as p:
    browser = p.chromium.connect_over_cdp(sandbox.cdp_url)
    page = browser.contexts[0].pages[0]
    # 执行操作
    page.goto("https://www.example.com")
    page.screenshot(path="screenshot.png")
    content = page.content()
    browser.close()
# 清理
sandbox.delete()
</code></pre><h3>使用 Puppeteer（Node.js）</h3><pre><code>const puppeteer = require('puppeteer-core');
// CDP URL 从 Sandbox 获取
const cdpUrl = 'wss://your-account.funagent-data-pre.cn-hangzhou.aliyuncs.com/sandboxes/xxx/ws/automation';
(async () =&gt; {
  const browser = await puppeteer.connect({
    browserWSEndpoint: cdpUrl,
    defaultViewport: null
  });
  const page = (await browser.pages())[0];
  await page.goto('https://www.example.com');
  await page.screenshot({ path: 'screenshot.png' });
  await browser.close();
})();</code></pre><h2>总结</h2><p>通过本教程，您已经学会了：</p><ol><li><strong>AgentRun SDK 基础：</strong> 如何使用 SDK 创建和管理 Browser Sandbox</li><li><strong>LangChain 集成：</strong> 如何将 Sandbox 封装为 LangChain Tools</li><li><strong>VNC 可视化：</strong> 如何在前端集成 VNC 实现实时监控</li><li><strong>直接集成：</strong> 如何使用 Puppeteer/Playwright 直接连接 Sandbox</li></ol><p><strong>相关链接：</strong></p><p>[1] Agentrun 控制台网站</p><p><a href="https://link.segmentfault.com/?enc=ANLLDqWCfICluiFLU%2Bqf%2Bg%3D%3D.wWFXF04p1HBea3PFd3mJtH0l3us67vqadj%2BDOwZ%2BmBkB35AiGyMqrkanKbjZ2eDTKbVO1cxFXeOTj8BS8bzRdDjfFqtVG%2Bo2HgdoRmXLwC8%3D" rel="nofollow" target="_blank">https://functionai.console.aliyun.com/cn-hangzhou/agent/runti...</a></p><p>[2] noVNC 在线客户端</p><p><a href="https://link.segmentfault.com/?enc=4r0yo65PKP54fMAUQWxjmQ%3D%3D.hNutYMqAyA0X1ahqYaB7vBAQgB%2FqnlDpsRhB81x4OA0057LQrHQh%2BdxKlyKZRfP6" rel="nofollow" target="_blank">https://novnc.com/noVNC/vnc.html</a></p>]]></description></item><item>    <title><![CDATA[探秘 AgentRun｜基于 Serverless 的 AI Agent 沙箱工程化之路 Serve]]></title>    <link>https://segmentfault.com/a/1190000047559418</link>    <guid>https://segmentfault.com/a/1190000047559418</guid>    <pubDate>2026-01-22 18:06:10</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>阿里云函数计算 AgentRun 全新发布后，我们整理了“探秘 AgentRun”系列文章，本系列将梳理企业落地Agent 常见难题，给出具体解法，助力 Agentic AI 快速走进生产级环境。欢迎加入“函数计算 AgentRun 客户群”与我们交流，钉钉群号：134570017218。</p><h2>AI Agent 时代的沙箱需求</h2><h3>从 Copilot 到 Agent：执行能力的质变</h3><p>在生成式 AI 的早期阶段，应用主要以“Copilot”形式存在，AI 仅作为辅助生成建议。然而，随着 AutoGPT、BabyAGI 以及 OpenAI Code Interpreter（现为 Advanced Data Analysis）的出现，AI 开始扮演“Agent”的角色。Agent 被赋予了目标，并能自主规划步骤、使用工具来达成目标。</p><p>这种质变的核心在于<strong>代码执行（Code Execution）</strong>。为了回答“分析这层楼的销售数据并绘制趋势图”这样的请求，LLM 不再只是生成一段 Python 代码文本，而是需要在一个真实的 Python 环境中运行这段代码，并获取绘图结果。同样，为了“帮我预订一张去东京的机票”，Agent 可能需要在一个无头浏览器（Headless Browser）中模拟用户点击。</p><h3>不可信代码的安全隐患</h3><p>当 LLM 生成代码并执行时，这段代码在本质上是<strong>不可信的（Untrusted）</strong>。如果直接在应用服务器或用户的本地设备上运行，将面临灾难性的安全风险：</p><ul><li><strong>系统破坏</strong>：AI 生成的代码可能无意或恶意地包含 rm -rf / 等破坏性指令，或者修改关键系统配置文件。</li><li><strong>数据泄露</strong>：代码可能尝试读取环境变量中的 API Key，或者扫描内网数据库，将敏感数据发送到外部服务器。</li><li><strong>资源耗尽</strong>：死循环或内存泄漏代码可能导致宿主机崩溃，影响其他租户的服务。</li><li><strong>网络攻击</strong>：恶意 Prompt 注入（Prompt Injection）可能诱导 AI 将执行环境作为跳板（Jump Box），对内部网络发起 DDoS 攻击或端口扫描。</li></ul><h3>Agent 场景面临的独特挑战</h3><p>除了基础的安全性，AI Agent 的交互特性还给沙箱环境带来了前所未有的工程挑战，这也是传统沙箱（如简单的 Docker 容器或虚拟机）难以应对的：</p><ul><li><strong>状态保持</strong>：与传统的“请求-响应”模式不同，Agent 往往需要进行多轮对话。上一轮定义的变量（如 df = load_data()）需要在下一轮（df.plot()）中继续可用。这就要求沙箱环境必须具备<strong>上下文记忆能力</strong>，而非每次请求都重置环境。</li><li><strong>极速启动</strong>：用户无法忍受每次交互都等待数秒甚至数十秒的虚拟机启动时间。为了保证流畅的对话体验（Time to First Token），沙箱必须具备毫秒级的冷启动能力。</li><li><strong>环境依赖多样性</strong>：不同的 Agent 任务可能需要完全不同的依赖库（如 Pandas、Scipy 用于数据分析，Puppeteer 用于网页操作）。沙箱需要支持灵活的自定义镜像或动态依赖加载，同时不能影响启动速度。</li><li><strong>资源成本控制</strong>：Agent 的调用往往具有稀疏性和突发性（例如一天只用几次，但一次用很久）。长期运行独占的虚拟机（VM）成本高昂且资源利用率低，而传统的 FaaS 虽然便宜但往往缺乏状态保持能力。如何在低成本和高性能之间找到平衡点，是一个巨大的挑战。<br/>因此，构建一个<strong>沙箱</strong>（Sandbox）——一个与宿主机、内网以及其他用户数据严格隔离，同时具备高性能、低成本、有状态的封闭执行环境——成为了 AI Agent 沙箱落地的前提条件。</li></ul><h2>AgentRun Sandbox：专为 Agent 设计的工程化方案</h2><p>为了解决上述挑战，我们推出了 <strong>AgentRun Sandbox</strong>。这是一个<strong>以高代码为核心，开放生态、灵活组装</strong>的一站式 Agentic AI 基础设施平台。</p><p>AgentRun 并非从零构建传统的虚拟机集群，而是<strong>基于阿里云函数计算（FC）这一强大的 Serverless 底座构建</strong>。通过充分利用 Serverless 的<strong>按需付费、极致弹性以及免运维（NoOps）</strong> 特性，AgentRun 解决了一直困扰沙箱领域的成本与效率难题，并在此基础上通过工程化封装，提供了面向 Agent 场景的专业能力。</p><h3>为什么选择函数计算作为 Sandbox Infra</h3><p>在构建 Agent 沙箱时，我们坚定地选择了函数计算（FC）作为底层基础设施，这主要基于以下核心优势的考量：</p><ul><li><strong>强安全隔离</strong>： 沙箱的核心诉求是安全。函数计算底层采用神龙裸金属与 RunD 安全容器技术，每个执行环境都运行在独立的 MicroVM 中。这种基于虚拟化技术的内核级隔离，相比传统的 Docker 容器隔离具有更高的安全性，能有效防止恶意代码逃逸，为不可信代码执行提供了坚实屏障。</li><li><strong>极致弹性与冷启动优化</strong>： Agent 的调用往往具有突发性。函数计算具备毫秒级的弹性伸缩能力，结合 RunD 技术对启动速度的极致优化，使得沙箱能够在数秒甚至毫秒内完成创建和启动。这不仅满足了高并发场景下的需求，也保证了 Agent 交互的流畅性，避免了传统虚拟机启动慢带来的延迟感。</li><li><strong>成本效益</strong>：自建虚拟机集群通常需要为峰值流量预留资源，导致低谷期资源浪费。函数计算采用按需付费（Pay-as-you-go）模式，且 AgentRun 利用了 FC 的空闲自动回收机制，真正做到了“有请求才计费”。对于稀疏调用的 Agent 场景，这种模式能显著降低基础设施成本。</li><li><strong>免运维</strong>： 基于 Serverless 架构，开发者无需关心底层服务器的操作系统补丁、网络配置及集群维护。AgentRun 团队可以将精力集中在沙箱的核心逻辑与业务体验上，而非底层基础设施的繁琐运维。</li><li><strong>会话能力</strong>：函数计算围绕 AI Agent Sandbox 场景推出了会话亲和、隔离以及管理能力。在一次会话生命周期内，相同会话的请求均会被亲和路由到同一个实例中，并独占该实例，保证了会话交互的连续性、上下文完整性以及多租安全性，同时提供完整的管理接口来主动对会话生命周期进行控制，降低了开发门槛。</li></ul><h3>AgentRun 的核心运行机制</h3><p>传统的 Serverless 通常是无状态的，难以满足 Code Interpreter 这类需要上下文保持的场景。AgentRun 借助函数计算的会话产品能力，在无状态的计算底座上构建了有状态、会话级的沙箱体验。</p><h4>1. 沙箱请求亲和</h4><p>AgentRun 允许开发者显式地创建一个具有生命周期的执行环境，解决了传统 Serverless“用完即走”导致的上下文丢失问题。</p><ul><li><strong>会话亲和</strong>：AgentRun 依赖函数计算会话亲和机制。当开发者创建沙箱后，AgentRun 会维护一个唯一的 SessionID。后续所有携带该 ID 的请求，都会被精准路由到同一个底层的计算实例。这意味着用户在第一步定义的 df = pd.read_csv(...) 对象，在第二步 df.plot() 时依然存在于内存中，完美复刻本地开发体验。</li><li><strong>MCP 协议原生支持</strong>：针对模型上下文协议（Model Context Protocol, MCP），AgentRun 提供了 MCP SSE 及 MCP Streamable HTTP 会话亲和支持。AgentRun 可以直接作为 MCP 网关，让 LLM 与外部工具的交互更加顺滑。</li></ul><h4>2. 多层次安全隔离</h4><p>在多租户 SaaS 平台中，安全性是 AgentRun 的基石。</p><ul><li><strong>计算隔离</strong>：AgentRun 利用底层基础设施的神龙裸金属与 RunD 安全容器技术，确保每个沙箱实例在内核级别进行隔离。通过强制将会话并发度设置为 1，AgentRun 保证租户 A 的进程空间、内存数据与租户 B 物理分离，防止容器逃逸。</li><li><strong>网络隔离</strong>：网络隔离完全由用户控制。用户可以根据安全需求灵活配置，选择开启或关闭沙箱的公网访问权限，或者将沙箱接入指定的 VPC 网络环境，从而在满足业务连通性的同时，防止恶意代码对内网发起攻击。</li></ul><h4>3. 灵活的生命周期控制</h4><p>AgentRun 通过函数计算的会话能力，接管了底层计算资源的生命周期，为上层应用提供精细化管理：</p><ul><li><strong>自动闲置回收（Idle Timeout）</strong>：为了通过 Serverless 架构降低成本，AgentRun 支持设置空闲超时（例如 5 分钟）。如果 Agent 在这段时间内没有新指令，底层实例会自动销毁并停止计费，完美适配 AI 交互“突发性强、稀疏度高”的特点。</li><li><strong>状态暂停与恢复（即将上线）</strong>：针对长时间的任务间歇，AgentRun 能够将沙箱的内存与磁盘状态快照保存，在用户回归时通过快照快速恢复现场，既节省成本又保留了上下文。</li></ul><h4>4. 会话粒度存储隔离（即将上线）</h4><p>代码执行需要隔离，数据存储更需要隔离。AgentRun 创新性地规划了会话粒度存储粘性。</p><ul><li><strong>动态绑定</strong>：AgentRun 允许用户为每个沙箱环境中动态分配一个存储挂载点的专属子目录。</li><li><strong>逻辑沙箱</strong>：通过底层的挂载技术，沙箱内部只能看到属于自己的 /workspace，物理上无法访问其他租户的文件（如 ../../tenant-b/secret.txt），从文件系统层面根除了数据交叉风险。</li></ul><h2>AgentRun 开箱即用的沙箱能力</h2><p>AgentRun 不仅提供了底层隔离环境，还预置了经过工程化调优的标准化模版，让开发者开箱即用：</p><ul><li><strong>Code Interpreter（代码解释器）</strong>：预装 Python/Node.js/Java 等环境，支持文件上传下载、数据分析、图表绘制及命令行操作。</li><li><strong>Browser User（浏览器沙箱）</strong>：提供基于 CDP over WebSocket 协议的浏览器环境，兼容 Puppeteer / Playwright，让 Agent 能够安全地访问互联网进行网页操作。</li><li><strong>All In One</strong>：集成了代码解释器与浏览器环境的全能型沙箱，满足复杂 Agent 任务需求。<br/>这些模版镜像具备高度的灵活性，AgentRun 未来将开放镜像定义，允许用户基于标准镜像定制私有依赖库或安全策略。</li></ul><p>AgentRun 沙箱架构详解<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047559420" alt="image.png" title="image.png"/></p><h3>AgentRun 网关</h3><p>这是 AgentRun 的门户，负责接收来自 AI Agent（如 LangChain 应用、ChatGPT Plugin）的 HTTP 请求，除了标准的身份验证、鉴权以及协议转换（如将 HTTP 转为 WebSocket）之外，其核心能力便是沙箱管理以及沙箱请求路由的功能，它屏蔽了底层 Serverless 基础设施的复杂性，实现了如下能力：</p><ul><li><strong>沙箱管理</strong>：管理沙箱资源，维护业务层沙箱 ID 与底层计算资源 SessionID 的映射关系</li><li><strong>状态维护</strong>：监控沙箱的活跃状态，基于沙箱超时配置以及底层资源情况及时对状态进行更新</li><li><strong>资源调度</strong>：根据用户指定的计算规格（CPU、Memory），向底层申请相应的资源。</li></ul><h3>函数计算沙箱环境</h3><p>主要由函数计算作为底层算力来承载沙箱的运行。AgentRun 利用函数计算提供的极致弹性能力，实现在分钟内启动成三万个独立的沙箱环境，每个环境都运行在独立的 MicroVM 中，搭配自研开箱即用的沙箱镜像模版，在功能以及性能上为用户提供了双重保障。</p><h3>典型工作流：从指令到结果</h3><p>以“用户让 Agent 根据上传的 Excel 文件绘制图表”为例，AgentRun 的工作流程如下。</p><h4>阶段一：模板创建</h4><ol><li>用户请求：Agent 接收到用户指令后，由 LLM 决策使用 Python 来实现该需求。</li><li>Agent 工具调用：AI Agent 会向 AgentRun 网关发送 Code Interpreter 沙箱模板的创建请求。</li><li>模板创建：AgentRun 网关会调用函数计算接口创建一个 Code 沙箱模板函数，镜像配置为前文提到的自研 Code Interpreter 沙箱模板，该函数需要同时配置会话亲和以及会话隔离。</li></ol><h4>阶段二：沙箱创建</h4><ol><li>Agent 工具调用：模板创建完成后，Agent 继续进行沙箱创建，创建时传入已有的模板 ID，标识沙箱实例运行时的配置和镜像</li><li>沙箱创建：AgentRun 收到沙箱创建请求后，会调用 FC 的 CreateSession 接口来创建一个沙箱实例，该沙箱会有一个合适的闲置超时时间，最长可存活 24h</li><li>创建完成：AgentRun 会保存 FC 返回的会话 ID，并生成沙箱业务 ID 与之对应，最终将沙箱业务 ID 返回给用户</li></ol><h4>阶段三：任务执行</h4><ol><li>上传文件：Agent 通过 Code Interpreter 的文件上传接口，将 Excel 文件上传。若想将该文件持久化，可以在创建沙箱时配置持久化存储 NAS，将其挂到沙箱中，并将文件上传到 NAS 挂载的目录上。</li><li>绘制图表：Agent 生成代码 import pandas as pd; df = pd.read_excel('data.xlsx')，并调用 Code Interpreter 的 run_code 接口执行代码。</li><li>会话亲和：Agent 所有发往 Code Interpreter 的请求中，都必须带上对应的沙箱 ID 才能保证请求都路由到同一个沙箱实例。</li><li>内存驻留：代码执行完毕，变量 df 驻留在内存中.</li><li>二次代码执行：Agent 根据数据列名生成绘图代码 df.plot()。再次发送代码运行请求</li><li>上下文复用：请求再次到达同一实例，直接使用内存中的 df 对象进行绘图，生成图片文件。</li><li>结果回传：图片被写入 NAS，下载链接返回给 Agent。</li></ol><h4>阶段四：资源销毁</h4><ol><li>空闲检测：Agent 完成任务，不再发送请求。</li><li>自动回收：达到 SessionIdleTimeout（如 5 分钟）后，函数计算会自动销毁该沙箱实例，此时除了持久化到 NAS 上的数据，其余环境相关数据均被销毁。</li><li>文件回收：如果 NAS 上的文件是会话隔离的，当用户会话结束后，NAS 上文件需要进行主动或者定时自动清除。</li></ol><h4>工作时序图</h4><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559421" alt="image.png" title="image.png" loading="lazy"/></p><h2>AgentRun 的核心设计原则</h2><p>AgentRun 的工程化实践遵循以下五大核心原则，这构成了其安全、高效、可扩展的基石：</p><h3>原则一：配置即代码</h3><p>AgentRun 将沙箱环境定义（环境变量、资源规格、健康检查等）封装为标准化模版。这种设计实现了沙箱配置的版本化管理，使得 Agent 环境可以像代码一样进行复制和回滚。</p><h3>原则二：会话即沙箱</h3><p>AgentRun 将“会话”作为沙箱的唯一实体。通过 SessionID 绑定底层的计算实例与上下文状态，实现了真正的按需分配与状态保持。沙箱的创建与销毁完全独立于底层物理设施，对用户透明。</p><h3>原则三：生命周期可编程</h3><p>AgentRun 不仅提供创建（Create）和删除（Delete）接口，还引入了“暂停”、“恢复”和“自动超时”机制。这种可编程性让上层应用能根据业务价值最大化资源利用率，实现成本与性能的最优平衡。</p><h3>原则四：网络接入标准化</h3><p>AgentRun 抹平了底层网络的差异，提供标准化的 HTTP/WebSocket 接口，并支持 Server-Sent Events（SSE）。无论底层如何升级，上层 Agent 沙箱始终通过标准的 Header 或 Cookie 携带 SessionID 进行交互，降低了集成复杂度。</p><h3>原则五：存储隔离细粒度化（即将上线）</h3><p>AgentRun 不仅支持模版粒度的文件系统共享，同时也能够配置沙箱粒度目录级动态挂载。每个沙箱单独挂载一个目录，从根源上杜绝了多租户环境下的数据越权访问风险。</p><h2>总结与展望</h2><p>AgentRun Sandbox 是 Serverless 技术在 AI Agent 领域的最佳工程化实践。</p><p>通过将阿里云函数计算（FC）在 <strong>RunD 安全虚拟化</strong>（解决隔离与启动速度）、<strong>会话亲和性</strong>（解决状态保持）以及 <strong>动态 NAS 挂载</strong>（解决数据隔离）等方面的底层技术创新，封装为面向业务的 AgentRun 平台，我们成功降低了企业构建 AI Agent 的门槛。</p><p>对于构建下一代智能体应用的企业而言，选择 AgentRun Sandbox 不仅是选择了一个沙箱工具，更是选择了一套兼顾安全性、用户体验与商业效率的弹性基础设施。未来，AgentRun Sandbox 将继续在启动延迟优化、状态秒级快照恢复以及更多样化的存储支持上深耕，致力于成为 AI Agent 时代最佳的沙箱基座。</p><h2>立即体验函数计算 AgentRun</h2><p>函数计算 AgentRun 的无代码到高代码演进能力，现已开放体验：</p><p><strong>查看更多产品详情</strong>：<a href="https://link.segmentfault.com/?enc=Ik5EXHYuH8epd9BQSeuhqg%3D%3D.wEKoxWNQuXyen98Nb96tjmwDNetm0aiyG2VC0osH1mqs2h8WQ6s1mMyj%2Buy%2FcGPS" rel="nofollow" target="_blank">https://www.aliyun.com/product/fc/agentrun</a></p><p>1.<strong>快速创建</strong>：访问控制台（<a href="https://link.segmentfault.com/?enc=oQJdrwe65og0rTGZPgTcBg%3D%3D.bzTY%2FqThOkEdrE7GqbiS9ovecF7VqG%2Bt7nwnnRz7lJGhedy4tCniyrf22WfDBuylMTVyOjVzD%2B%2FRRGIgKCbdVA%3D%3D" rel="nofollow" target="_blank">https://functionai.console.aliyun.com/cn-hangzhou/agent/explore</a>)，60秒创建你的第一个 Agent</p><p>2.<strong>深度定制</strong>：当需要更复杂功能时，一键转换为高代码<br/>3.<strong>持续演进</strong>：利用函数计算 AgentRun 的基础设施能力，持续优化你的 Agent</p><p>从想法到上线，从原型到生产，函数计算 AgentRun 始终是你最好的伙伴。欢迎加入“函数计算 AgentRun 客户群”，钉钉群号：134570017218。</p><h3>快速了解函数计算 AgentRun</h3><p>一句话介绍：函数计算 AgentRun 是一个以高代码为核心的一站式 Agentic AI 基础设施平台。秉持生态开放和灵活组装的理念，为企业级 Agent 应用提供从开发、部署到运维的全生命周期管理。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047468982" alt="image.png" title="image.png" loading="lazy"/></p><p>函数计算 AgentRun 架构图</p><p>AgentRun 运行时基于阿里云函数计算 FC 构建，继承了 Serverless 计算极致弹性、按量付费、零运维的核心优势。通过深度集成 AgentScope、LangChain、RAGFlow、Mem0 等主流开源生态。函数计算 AgentRun 将 Serverless 的极致弹性、零运维和按量付费的特性与 AI 原生应用场景深度融合，助力企业实现成本与效率的极致优化，<strong>平均 TCO 降低 60%</strong>。</p><p><strong>让开发者只需专注于 Agent 的业务逻辑创新，无需关心底层基础设施，让 Agentic AI 真正进入企业生产环境。</strong></p>]]></description></item><item>    <title><![CDATA[IP地址查询工具会泄露个人信息？如何选择安全可靠的工具？ 科技块儿 ]]></title>    <link>https://segmentfault.com/a/1190000047559426</link>    <guid>https://segmentfault.com/a/1190000047559426</guid>    <pubDate>2026-01-22 18:05:10</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>一、IP地址查询工具：安全隐患与隐私问题</h2><p>IP地址查询工具广泛应用于各类行业，从网络安全到广告投放，它们都能提供精准的定位和风险识别。然而，使用这些工具时，很多人对隐私泄露存在担忧。实际上，IP查询过程中可能会涉及以下个人信息：</p><ul><li>IP地址本身：作为查询的基础，IP地址是用户网络连接的唯一标识。通过IP查询工具，可能泄露用户的上网历史和地理位置。</li><li>位置信息：根据IP地址查询，工具能够获取精确的地理位置，包括城市、国家、甚至街道位置，这些信息若被滥用，可能影响个人隐私。</li><li>运营商信息：IP地址的查询还会揭示用户所在的网络运营商，尤其在某些情况下，能揭示用户所属的网络提供商与服务类型，进一步暴露用户的网络环境。</li><li>潜在的恶意软件或钓鱼攻击：某些不可靠的查询工具可能隐藏恶意程序，盗取用户的设备信息或利用查询工具作为钓鱼攻击的媒介。</li></ul><p>因此，在选择IP地址查询工具时，保护个人信息的安全是非常重要的。</p><p><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdnIvY" alt="" title=""/></p><h2>二、如何选择安全可靠的IP查询工具</h2><p>选择一个安全可靠的IP查询工具不仅要考虑其准确性，还要确保其保护用户隐私的能力。以下是一些选择标准：</p><ul><li>数据加密和隐私政策：优质的IP查询工具应提供数据加密，防止用户的IP查询记录被第三方截取或滥用。同时，工具需要有清晰且严格的隐私保护政策，承诺不会泄露用户数据。</li><li>工具的声誉与市场评价：选择那些有良好市场口碑和用户评价的工具，尤其是业内推荐的服务商。</li><li>查询结果的精确度：工具应能提供高精度的定位和数据，避免因错误的IP识别而引起不必要的风险。</li><li>支持的功能与服务：除了基本的IP查询功能，安全的IP查询工具应提供更多增值服务，如风险评分、代理检测等，帮助用户更全面地分析数据。</li></ul><p>接下来，我们将介绍几款常见的、安全可靠的IP地址查询工具。</p><h2>三、安全可靠的IP查询工具推荐</h2><h3>1.IP数据云</h3><p>简介：IP数据云是国内领先的高精度IP地理定位与风险识别服务商，支持全球范围内的IP查询。它拥有毫秒级响应速度，支持IPv4/IPv6信息查询，并提供20多维度的数据字段。特别适合金融反欺诈、政企安全审计、精准广告投放等对精度和安全性要求高的场景。</p><p>安全性：IP数据云严格遵守隐私保护政策，确保用户数据不会被滥用，同时为用户提供加密的查询服务，避免信息泄露。<br/><img width="723" height="404" referrerpolicy="no-referrer" src="/img/bVdnIwo" alt="image.png" title="image.png" loading="lazy"/><br/> </p><h3>2.IPnews</h3><p>简介：IPnews是专注于IP地址深度分析的全球工具，支持精准定位和风险监控，广泛应用于网络安全和广告投放领域。它能提供多维度的威胁监控，识别代理、IP相关域名等信息，为用户提供安全且精确的查询结果。</p><p>安全性：IPnews注重数据保护与隐私安全，所有查询操作都通过加密处理，确保用户信息不被外泄。<br/><img width="554" height="349" referrerpolicy="no-referrer" src="/img/bVdnIv4" alt="image.png" title="image.png" loading="lazy"/><br/> </p><h3>3.IPinfo</h3><p>简介：IPinfo是一个知名的IP查询工具，支持全球IP地址定位。它可以提供IP归属地、ISP（互联网服务提供商）、ASN等多维度数据，广泛应用于企业的安全审计与广告投放。</p><p>安全性：IPinfo提供良好的隐私保护措施，并严格遵守GDPR等数据保护法规，确保用户数据的安全性。<br/><img width="553" height="481" referrerpolicy="no-referrer" src="/img/bVdnIv8" alt="image.png" title="image.png" loading="lazy"/><br/> </p><h3>4.IPstack</h3><p>简介：IPstack是另一款高精度IP定位工具，支持实时IP地址查询，提供详细的IP信息和精确的地理位置。它被广泛用于广告定向投放、跨国企业的IP监控等应用场景。</p><p>安全性：IPstack提供HTTPS加密服务，并承诺不会出售用户查询数据，是一款值得信赖的安全工具。<br/><img width="553" height="333" referrerpolicy="no-referrer" src="/img/bVdnIv9" alt="image.png" title="image.png" loading="lazy"/><br/> </p><h3>5.geoPlugin</h3><p>简介：geoPlugin是一款轻量级IP查询工具，能够提供精确的地理位置、IP类型、时区信息等。它支持免费查询，并且API接口灵活，适用于各种开发者和小型企业。</p><p>安全性：geoPlugin采用标准的数据加密方式，确保查询数据的安全。<br/><img width="723" height="430" referrerpolicy="no-referrer" src="/img/bVdnIwi" alt="image.png" title="image.png" loading="lazy"/><br/> </p><h2>四、如何使用IP查询工具保护个人信息</h2><p>在使用IP查询工具时，除了选择安全可靠的工具外，用户还可以采取一些额外的措施来保护自己的隐私：</p><ul><li>避免查询个人敏感信息：不要在查询过程中输入与自己相关的敏感信息，尽量避免输入与个人身份紧密相关的内容。</li><li>定期清理查询记录：定期清理浏览器的查询历史记录，避免被不法分子利用。</li><li><p>使用代理：通过代理隐藏真实IP地址，可以在查询时保护用户的真实身份。<br/> </p><h2>五、部署示例</h2></li></ul><pre><code>{
  "code": 200,
  "data": {
    "location": {
      "area_code": "320311",
      "city": "徐州",
      "city_code": "0516",
      "continent": "亚洲",
      "country": "中国",
      "country_code": "CN",
      "district": "泉山",
      "elevation": "40",
      "ip": "180.124.68.28",
      "isp": "电信",
      "latitude": "34.214855",
      "longitude": "117.169163",
      "multi_street": [
        {
          "lng": "117.169163",
          "lat": "34.214855",
          "province": "江苏",
          "city": "徐州",
          "district": "泉山",
          "street": "双山路",
          "radius": "2.27",
          "zip_code": "221000"
        },
        {
          "lng": "117.191078",
          "lat": "34.224231",
          "province": "江苏",
          "city": "徐州",
          "district": "泉山",
          "street": "解放南路387号",
          "radius": "1.15",
          "zip_code": "221000"
        },
        {
          "lng": "117.180535",
          "lat": "34.218589",
          "province": "江苏",
          "city": "徐州",
          "district": "泉山",
          "street": "文华路",
          "radius": "2.73",
          "zip_code": "221000"
        }
      ],
      "province": "江苏",
      "street": "双山路",
      "time_zone": "Asia/Shanghai",
      "weather_station": "CHXX0437",
      "zip_code": "221000"
    }
  },
  "msg": "success"
}</code></pre><h2>六、总结</h2><p>选择安全的IP查询工具不仅仅是为了获取准确的数据，更是为了保护个人信息的安全。通过选择可靠的工具如IP数据云、IPnews、IPinfo等，用户可以在享受高精度查询服务的同时，避免个人信息泄露的风险。</p>]]></description></item><item>    <title><![CDATA[微软发布了 2026 年 AI 发展的 7 个趋势 冴羽 ]]></title>    <link>https://segmentfault.com/a/1190000047559430</link>    <guid>https://segmentfault.com/a/1190000047559430</guid>    <pubDate>2026-01-22 18:04:37</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>微软：2026 年 AI 发展的 7 个趋势</h2><p>说实话，每次看到“AI 趋势预测”这类标题，我都会先深吸一口气。</p><p>不是因为害怕，而是因为这类文章太容易写成两种极端：</p><p>要么是“AI 要统治世界了快跑”的恐慌文，要么是“拥抱 AI 否则被淘汰”的焦虑营销。</p><p>最近读了微软发布的 2026 年 AI 趋势文章，里面有 7 个预测。</p><p>我不打算照搬原文，而是结合我自己的理解，和你讲下这 7 个趋势与我们有什么关系，看你是否能在这 7 个趋势中找到自己的机会。</p><h3>趋势 1：AI 成为你的数字同事</h3><p>AI 不是来抢你饭碗的，是来帮你“开挂”的。</p><p>想象一下，以前你开发一个页面要 3 天，现在 AI 帮你写代码，你只需要专注在业务需求、用户体验等事情上。</p><p>这就像以前洗衣服要手搓，现在有洗衣机了。洗衣机没有让“洗衣服”这件事消失，而是让你有时间去做更重要的事。</p><p>所以与其担心被 AI 取代，不如想想“我能用 AI 放大什么？”</p><h3>趋势 2：AI 代理更安全</h3><p>现在的 AI 有时候像个热心但冒失的实习生——你让它帮你写邮件，它可能把你的私人信息也一起发出去了……</p><p>2026 年的 AI 会更像一个训练有素的助理：知道什么该做，什么不该做，什么信息可以用，什么必须保密。</p><p>所以虽然 AI 能帮你处理各项事务，但也要有基本的安全意识，尤其不要让他删库跑路了。</p><h3>趋势 3：AI 解决全球医疗危机</h3><p>想象一下，当你走进医院，AI 系统能在几分钟内准确诊断你的病情，准确率高达 85.5%，而传统医生的平均准确率只有 20%。</p><p>这听起来像科幻电影，但微软最新的 AI 医疗诊断系统已经达到了这个水平。</p><p>这意味着 AI 将成为第一线的健康顾问，当然，这不是说 AI 要取代医生。而是说，AI 可以让医疗资源的分配更均衡一些。</p><p>所以新的一年，你可以关注 AI 在健康领域的应用，但看病还是要去正规医院，别指望 AI 给你开药方。</p><h3>趋势 4：AI 成为科学研究的催化剂</h3><p>以前做研究，光是文献综述就要花几个月。</p><p>现在 AI 可以帮你快速梳理几千篇论文，找出关键信息。</p><p>这就像以前考古要一铲子一铲子挖，现在有了探地雷达，能更快定位到有价值的区域。</p><p>所以如果你是学生或研究者，学会用 AI 辅助学习和研究，会是一个很大的竞争优势。</p><h3>趋势 5：AI 基础设施会变得更智能、更高效</h3><p>支撑 AI 运行的基础设施会持续优化，这意味着 AI 基础设施能够智能调度算力，确保每个任务都能在最佳时间、地点获得最优资源。</p><p>以后无论你在哪里，使用什么设备，都将获得一致且高效的 AI 服务。</p><p>云计算将变得像自来水一样普及和可靠。</p><h3>趋势 6：AI 正在学习理解代码背后的“为什么”</h3><p>AI 不只学习代码语言，还在理解代码背后的上下文。</p><p>这意味着以前的 AI 写代码就像个新手程序员——你说什么它写什么，但不理解你到底想解决什么问题。</p><p>现在的 AI 开始能理解“你为什么要这么做”，然后给出更合理的方案。</p><p>对我们程序员来说，AI 将能更好地协助你维护和改进现有系统。</p><h3>趋势 7：量子计算的突破比想象中更近</h3><p>专家预测，量子计算的重大突破将发生在“几年，而不是几十年”的时间框架内。</p><p>随着量子计算的出现，密码学、药物发现、气候模拟等领域将迎来革命性突破。</p><p>当然对我们来说，这暂时不需要操心，但可以保持关注。因为这是那种“一旦发生就会改变很多事”的技术。</p><h3>普通人该怎么办？</h3><p>这些趋势的共同点是：<strong>AI 正在从工具变成伙伴，从辅助变成合作伙伴，从后台变成前台</strong>。</p><p>不过看完这 7 个趋势，你可能还是会问：所以我到底该做什么呢？</p><p>我的建议很简单，三句话：</p><p><strong>第一，别焦虑，但要保持好奇</strong></p><p>AI 发展很快，但天不会塌下来。与其焦虑“会不会被取代”，不如花点时间玩玩各种 AI 工具，看看它们能帮你做什么。</p><p><strong>第二，找到你的“不可替代性”</strong></p><p>AI 擅长的是“标准化”的事情。而你的独特经历、审美、判断力、人际关系——这些是 AI 很难复制的。想想你有什么是 AI 做不到的</p><p><strong>第三，学会“和 AI 协作”</strong></p><p>未来最吃香的不是“会用 AI 的人”，也不是“完全不用 AI 的人”，而是“知道什么时候用 AI、什么时候用自己”的人。</p><p>说到底，AI 是工具，不是对手。</p><p>就像汽车发明后，马车夫确实失业了，但司机、修车工、交通规划师这些新职业也出现了。</p><p>变化一直在发生，我们要做的，是在变化中找到自己的位置。</p><p>PS：岂可修，这让我想到了阿里的文化——拥抱变化</p><p>我是冴羽，10 年笔耕不辍，专注前端领域，更新了 10+ 系列、300+ 篇原创技术文章，翻译过 Svelte、Solid.js、TypeScript 文档，著有小册《Next.js 开发指南》、《Svelte 开发指南》、《Astro 实战指南》。</p><p>欢迎围观我的“<a href="https://link.segmentfault.com/?enc=mNrEh3tMO%2F7az5a0mRHUWQ%3D%3D.8jkX171zLQUvi%2B41M5cqsyv3nUb5pI39ZU07RrU7xt0%3D" rel="nofollow" target="_blank">网页版朋友圈</a>”，关注我的公众号：<strong>冴羽（或搜索 yayujs）</strong>，每天分享前端知识、AI 干货。</p>]]></description></item><item>    <title><![CDATA[探秘 AgentRun丨为什么应该把 LangChain 等框架部署到函数计算 AgentRun 阿]]></title>    <link>https://segmentfault.com/a/1190000047559490</link>    <guid>https://segmentfault.com/a/1190000047559490</guid>    <pubDate>2026-01-22 18:04:05</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>作者：江昱</p><p><a href="https://link.segmentfault.com/?enc=RUUCmIN4F4d3N3%2F4iw3HXg%3D%3D.DJzf9fU79hOAD0ckCuD3qoYeZxyDxMJBi684A2AddbNT6qF%2Fly717ZkqcoeXngDJuY2ZfYepxSo87OPPdoZ0q5gIagNnTVgq4JJHlKSbK4VDdt0Wm%2B9o5ZIh3tsLmdHQ4PsJ9W4SXZsEYLa3PQ6uT5jXhjlh3Y6lhL%2BhyfWgqJqasNCbzsg2gA79%2FajDRtHQ" rel="nofollow" target="_blank">阿里云函数计算 AgentRun 全新发布后</a>，我们整理了“探秘 AgentRun”系列文章，本系列将梳理企业落地 Agent 常见难题，给出具体解法，助力 Agentic AI 快速走进生产级环境。<strong>欢迎加入“函数计算 AgentRun 客户群”与我们交流，钉钉群号：</strong> <strong><em>134570017218</em></strong> <strong>。</strong></p><p>当你已经用 LangChain、AgentScope、LangGraph 等框架开发了 Agent 应用，如何让它们享受函数计算 AgentRun 提供的 <strong>Serverless 运行时、企业级 Sandbox、模型高可用、全链路可观测</strong>等能力？好消息是，<strong>你几乎不需要改动现有代码，只需要简单的适配就可以迁移到函数计算 AgentRun。</strong></p><p>这篇文章将通过真实的代码示例，展示如何将不同框架的 Agent 应用部署到函数计算 AgentRun 上，以及如何充分利用函数计算 AgentRun 的各种能力。</p><h2>为什么要部署到函数计算 AgentRun？</h2><p>在讨论具体的集成方案前，让我们先明确一个问题：<strong>如果你的 Agent 应用已经在本地或自建服务器上运行良好，为什么还要迁移到函数计算 AgentRun？</strong></p><p>答案很简单：<strong>从开发环境到生产环境，有一道巨大的鸿沟。</strong>  本地运行只需要考虑功能实现，但生产环境需要考虑性能、稳定性、成本、安全、可观测等一系列问题。函数计算 AgentRun 提供的不是又一个 Agent 框架，而是让你的 Agent 能够以企业级标准运行的完整基础设施。</p><p>具体来说，部署到函数计算 AgentRun 后，你能获得：零运维的 Serverless 运行时（自动扩缩容、按量付费），企业级的 Sandbox 环境（高性能、安全隔离），模型高可用保障（自动熔断、多模型 Fallback），全链路可观测（完整的 Trace、成本归因），以及统一的工具和 MCP 管理。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559492" alt="image" title="image"/></p><h2>快速上手：5 分钟部署你的第一个 LangChain Agent</h2><p>让我们从最流行的 LangChain 框架开始，通过一个完整的例子展示如何将 LangChain Agent 部署到函数计算 AgentRun。</p><h3>第一步：安装 Serverless Devs</h3><p>函数计算 AgentRun 使用 Serverless Devs 作为部署工具。如果你有 Node.js 环境，一行命令即可安装：</p><pre><code>npm i -g @serverless-devs/s</code></pre><h3>第二步：创建项目</h3><p>使用脚手架快速创建项目（注意：需要 Python 3.10 及以上版本）：</p><pre><code># 初始化模板
s init agentrun-quick-start-langchain
# 进入代码目录
cd agentrun-quick-start-langchain/code
# 初始化虚拟环境并安装依赖
uv venv &amp;&amp; uv pip install -r requirements.txt</code></pre><h3>第三步：配置认证信息</h3><p>通过环境变量（建议使用 .env 文件）配置你的 AgentRun 访问凭证：</p><pre><code>export AGENTRUN_ACCESS_KEY_ID="your-access-key-id"
export AGENTRUN_ACCESS_KEY_SECRET="your-access-key-secret"
export AGENTRUN_ACCOUNT_ID="your-account-id"
export AGENTRUN_REGION="cn-hangzhou"</code></pre><h3>第四步：理解集成方式</h3><p>这是最关键的部分。打开生成的代码，你会看到集成非常简单：</p><pre><code>from agentrun.integration.langchain import model, sandbox_toolset
from agentrun.server import AgentRunServer
# 使用 AgentRun 的模型（自动享受高可用、熔断等能力）
llm = model("&lt;your-model-name&gt;")
# 使用 AgentRun 的 Sandbox 工具
tools = sandbox_toolset(
    template_name="&lt;your-sandbox-name&gt;",
    template_type=TemplateType.CODE_INTERPRETER,
    sandbox_idle_timeout_seconds=300,
)
# 创建 LangChain Agent（和原来的代码完全一样）
agent = create_agent(
    model=llm,
    tools=tools,
    system_prompt="你是一个智能助手"
)
# 定义调用函数
def invoke_agent(request):
    result = agent.invoke({"messages": request.messages})
    return result["messages"][-1].content
# 启动 HTTP Server（提供 OpenAI 兼容的 API）
AgentRunServer(invoke_agent=invoke_agent).start()</code></pre><p>核心要点：</p><ul><li><code>model()</code> 函数返回的是 LangChain 可以直接使用的模型对象</li><li><code>sandbox_toolset()</code> 返回的是 LangChain Tools 列表</li><li>你的 Agent 创建代码<strong>完全不需要改动</strong></li><li><code>AgentRunServer</code> 自动处理 HTTP 请求，提供标准的 OpenAI API</li></ul><h3>第五步：本地测试</h3><p>启动服务后，可以通过 HTTP 请求测试：</p><pre><code>curl 127.0.0.1:9000/v1/chat/completions \
  -X POST \
  -H "content-type: application/json" \
  -d '{"messages": [{"role": "user", "content": "通过代码查询现在是几点?"}], "stream":true}'</code></pre><h3>第六步：部署到生产环境</h3><p>项目中已经包含了 s.yaml 配置文件。你只需要修改其中的 role 字段为你的阿里云角色：</p><pre><code>role: acs:ram::{您的阿里云主账号 ID}:role/{您的阿里云角色名称}</code></pre><p>配置部署密钥：</p><pre><code>s config add
# 按照引导输入 Access Key ID 和 Secret，记住密钥对名称（如 agentrun-deploy）</code></pre><p>执行部署：</p><pre><code>s deploy -a agentrun-deploy</code></pre><p>部署完成后，你会得到一个 HTTPS URL，就可以在生产环境调用你的 Agent 了。</p><h2>不同框架的集成案例</h2><p>函数计算 AgentRun 不仅支持 LangChain，还深度集成了主流的 Agent 开发框架。<strong>所有框架都遵循同样的理念：通过简单的适配层，让你的代码无缝迁移到函数计算 AgentRun，享受企业级能力。</strong></p><h3>LangGraph：工作流编排</h3><p>LangGraph 是 LangChain 团队推出的工作流编排框架，适合构建复杂的多步骤 Agent。集成方式和 LangChain 类似：</p><pre><code>from agentrun.integration.langgraph import model, tools
from langgraph.graph import StateGraph, MessagesState
from langgraph.prebuilt import ToolNode
# 使用 AgentRun 的模型和工具
llm = model("&lt;your-model-name&gt;").to_langgraph()
agent_tools = tools()
# 构建 LangGraph 工作流（和原来的代码一样）
def call_model(state: MessagesState):
    messages = state["messages"]
    response = llm.invoke(messages)
    return {"messages": [response]}
workflow = StateGraph(MessagesState)
workflow.add_node("agent", call_model)
workflow.add_node("tools", ToolNode(agent_tools))
workflow.set_entry_point("agent")
# 定义条件边...
app = workflow.compile()
# 调用
result = app.invoke({"messages": [HumanMessage(content="查询上海天气")]})</code></pre><p><strong>LangGraph 的优势</strong>是可以精确控制 Agent 的执行流程，比如条件分支、循环、并行执行等。部署到函数计算 AgentRun 后，这些复杂的工作流都能自动享受弹性伸缩和可观测能力。</p><h3>AgentScope：多智能体协作</h3><p>AgentScope 是阿里达摩院开源的多智能体框架，特别适合构建多 Agent 协作场景。集成方式：</p><pre><code>from agentrun.integration.agentscope import model, tools
from agentscope.agent import ReActAgent
from agentscope.tool import Toolkit
# 使用 AgentRun 的模型和工具
llm = model("&lt;your-model-name&gt;").to_agentscope()
agent_tools = tools()
# 注册工具到 Toolkit
toolkit = Toolkit()
for tool in agent_tools:
    toolkit.register_tool_function(tool)
# 创建 Agent（和原来的代码一样）
agent = ReActAgent(
    name="assistant",
    sys_prompt="你是一个智能助手",
    model=llm,
    toolkit=toolkit,
)
# 调用
result = await agent.reply(Msg(name="user", content="查询上海天气", role="user"))</code></pre><p><strong>AgentScope 的优势</strong>是对多 Agent 系统的原生支持，包括 Agent 之间的通信、协调、记忆共享等。部署到函数计算 AgentRun 后，每个 Agent 都在独立的隔离环境中运行，确保安全性。</p><h3>PydanticAI：类型安全的 Agent 框架</h3><p>PydanticAI 是一个新兴框架，强调类型安全和结构化输出。集成方式：</p><pre><code>from agentrun.integration.pydantic_ai import model, tools
from pydantic_ai import Agent
# 使用 AgentRun 的模型和工具
llm = model("&lt;your-model-name&gt;").to_pydantic_ai()
agent_tools = tools()
# 创建 Agent
agent = Agent(
    llm,
    instructions="Be concise, reply with one sentence.",
    tools=agent_tools,
)
# 同步调用
result = agent.run_sync("上海的天气如何？")
# 异步调用
result = await agent.run("上海的天气如何？")</code></pre><p><strong>PydanticAI 的优势</strong>是强类型和结构化输出，特别适合需要严格数据验证的企业场景。</p><h2>充分利用函数计算 AgentRun 的核心能力</h2><p>将 Agent 部署到函数计算 AgentRun 后，你不仅获得了 Serverless 运行环境，还可以深度利用平台提供的各种企业级能力。</p><h3>模型高可用：告别单点故障（搭配 AI 网关）</h3><p>部署到函数计算 AgentRun 后，你的 Agent 自动享受模型高可用能力。当你配置的主模型出现故障、限流或超时时，系统会自动切换到备用模型，整个过程对你的代码完全透明。  <br/>在函数计算 AgentRun 控制台配置模型时可以和 AI 网关进行联动，可以设置：主模型（如 GPT-4），备用模型列表（如 Claude-3、Qwen-Max），熔断策略（错误率阈值、超时时间），负载均衡策略（轮询、权重、最少连接）。  <br/>你的代码完全不需要改动，只需要在创建模型时使用函数计算 AgentRun 的模型名称，所有的容错、切换、负载均衡都由平台自动处理。</p><h3>企业级 Sandbox：安全执行代码</h3><p>函数计算 AgentRun 提供的 Sandbox 不是简单的代码执行环境，而是<strong>企业级的安全隔离沙箱</strong>。每个 Sandbox 实例都是独立隔离的，支持多种执行类型：</p><p>Code Interpreter 支持 Python、Node.js、Java、Bash 等语言，可以执行数据分析、文件处理等任务。Browser Tool 提供浏览器自动化能力，支持网页爬取、表单填写、截图等操作。All In One 集成了代码解释器和浏览器工具，提供更丰富的交互能力。</p><p>使用时，通过 sandbox_toolset() 函数就可以获取相应的工具集合，这些工具会自动转换为你使用的框架所需的格式。</p><h3>工具和 MCP：标准化集成</h3><p>函数计算 AgentRun 提供统一的工具管理和 MCP（Model Context Protocol）机制。你可以从工具市场选择现成的工具，也可以自定义工具并发布到市场。</p><p>更强大的是 <strong>MCP 的 Hook 机制</strong>。通过前置 Hook，可以在工具调用前自动注入用户凭证、记录请求日志、校验参数合法性。通过后置 Hook，可以对结果进行转换、记录审计日志、处理异常情况。这些通用逻辑不需要在每个工具中重复实现，大大提升了开发效率。</p><h3>全链路可观测：不再是黑盒</h3><p>这是函数计算 AgentRun 最强大的能力之一。<strong>你的代码不需要做任何改动，平台会自动记录 Agent 的完整执行链路</strong>。</p><p>在可观测平台上，你可以看到：Agent 接收到用户请求的时间和内容，调用了哪个模型、使用了多少 Token、花费了多少钱，调用了哪些工具、每个工具的执行时间和结果，访问了哪些知识库、检索了多少数据，每个环节的耗时分布，完整的调用链 Trace。</p><p><strong>这些能力都是平台自动提供的</strong>，通过探针注入实现，无论是高代码还是低代码创建的 Agent，都自动享受这些可观测能力。</p><h3>记忆和知识库：数据不出域</h3><p>函数计算 AgentRun 深度集成了 RAGFlow、Mem0 等开源项目，提供灵活的记忆和知识库管理。你可以选择一键托管模式，由平台统一管理部署运维，享受 Serverless 的弹性和按量付费优势。也可以选择绑定模式，将 Agent 连接到已经部署在企业 VPC 或 IDC 内的实例，<strong>数据完全不出企业内网</strong>。</p><p>这种灵活性让你可以根据数据的敏感级别选择不同的策略：核心业务数据私有化部署，一般数据托管上云，在安全性和便利性之间找到最佳平衡。</p><h2>立即体验函数计算 AgentRun</h2><p>函数计算 AgentRun 的无代码到高代码演进能力，现已开放体验：</p><ol><li><strong>快速创建：</strong> 访问控制台（ <a href="https://link.segmentfault.com/?enc=hKtsMQiTeJRPLcnJitnaQg%3D%3D.Cpt%2BIjL0Z0NzANbzSQ%2Bk34xGC8uSEnydy%2FrZHLHG3XN2hrUDPxYRIsn8h4jXZjRsn3GspDZ%2FwMfGka0yX%2F1ZxQ%3D%3D" rel="nofollow" target="_blank">https://functionai.console.aliyun.com/cn-hangzhou/agent/explore</a> ），60 秒创建你的第一个 Agent</li><li><strong>深度定制：</strong> 当需要更复杂功能时，一键转换为高代码</li><li><strong>持续演进：</strong> 利用函数计算 AgentRun 的基础设施能力，持续优化你的 Agent</li></ol><p>从想法到上线，从原型到生产，函数计算 AgentRun 始终是你最好的伙伴。<strong>欢迎加入“函数计算 AgentRun 客户群”，钉钉群号：134570017218。</strong></p><p><strong>快速了解函数计算 AgentRun：</strong></p><p>一句话介绍：函数计算 AgentRun 是一个以高代码为核心的一站式 Agentic AI 基础设施平台。秉持生态开放和灵活组装的理念，为企业级 Agent 应用提供从开发、部署到运维的全生命周期管理。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559493" alt="image" title="image" loading="lazy"/></p><p><em>函数计算 AgentRun 架构图</em></p><p>AgentRun 运行时基于阿里云函数计算 FC 构建，继承了 Serverless 计算极致弹性、按量付费、零运维的核心优势。通过深度集成 AgentScope、LangChain、RAGFlow、Mem0 等主流开源生态。函数计算 AgentRun 将 Serverless 的极致弹性、零运维和按量付费的特性与 AI 原生应用场景深度融合，助力企业实现成本与效率的极致优化，<strong>平均 TCO 降低 60%</strong> 。 </p><p><strong>让</strong> <strong>开发者只需专注于 Agent 的业务逻辑创新，无需关心底层基础设施，</strong> <strong>让 Agentic AI 真正进入企业生产环境。</strong></p>]]></description></item><item>    <title><![CDATA[《iOS沙盒Python适配进阶指南：从静态兼容到自适应运行体系》 程序员阿伟 ]]></title>    <link>https://segmentfault.com/a/1190000047559506</link>    <guid>https://segmentfault.com/a/1190000047559506</guid>    <pubDate>2026-01-22 18:03:14</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>iOS沙盒的封闭性从来都不是简单的权限隔离，而是一套贯穿运行时的上下文绑定机制，Python在其中的适配困境，本质上是解释型语言的动态特性与iOS静态执行规范的底层冲突。很多开发者初期仅关注文件访问限制，却在实际操作中陷入模块加载失败、依赖库兼容失衡、系统调用无响应等隐性陷阱，这些问题背后，是沙盒对执行环境的深度管控——从二进制文件格式到内存分配规则，从代码签名校验到资源调度优先级，每一项都与桌面端的Python运行逻辑存在本质差异。真正的适配高手，往往是在理解沙盒底层设计逻辑后，通过重构执行环境的适配路径，让Python的动态优势在静态约束中找到生存空间，这种平衡术既需要对iOS系统架构的深刻认知，也依赖对Python解释器内核的灵活改造。在长期的适配实践中，我发现多数开发者的误区在于将沙盒限制等同于“功能阉割”，实则沙盒的核心是建立一套可预期的执行边界，Python的适配并非被动妥协，而是主动构建与这套边界兼容的运行体系。例如，当遇到解释器无法加载系统动态库时，并非简单替换库文件就能解决，而是需要追溯沙盒对动态链接路径的映射规则，通过静态编译将依赖库嵌入解释器二进制文件，同时调整链接符号的查找逻辑，这种底层改造才能从根本上解决兼容性问题，而这一过程需要开发者同时具备系统底层知识与Python解释器原理认知，缺一不可。</p><p>沙盒对Python运行时的核心限制，集中体现在解释器与系统内核的适配断层上。iOS基于达尔文内核构建的执行体系，要求所有运行代码必须符合特定的二进制格式，且需经过严格的签名校验，而Python作为解释型语言，其传统运行模式依赖动态加载解释器与脚本文件，这种特性与iOS的静态执行要求形成天然矛盾。更隐蔽的是，沙盒会对进程的内存空间进行隔离划分，Python解释器在分配内存时，既无法访问系统级的共享内存区域，也难以与原生应用形成有效的内存交互，导致数据流转效率低下。同时，系统对动态链接库的加载路径有着强制约束，Python标准库中部分依赖系统级动态库的模块，在沙盒环境中会因路径无法识别而失效，这种失效并非模块本身不存在，而是加载机制与沙盒的路径映射规则不兼容。应对这一困境，不能仅停留在表面的模块替换，而需要通过静态编译将解释器与核心依赖打包为符合要求的二进制格式，同时重构模块加载逻辑，让Python脚本的执行流程与沙盒的内存分配、路径映射规则形成对齐。在实践中，我曾尝试使用常规打包工具将Python解释器移植到沙盒，结果发现解释器虽能启动，但调用涉及系统调用的模块时频繁失效，后来通过拆解达尔文内核的执行流程，发现沙盒会对进程的动态链接行为进行拦截，只有符合特定签名与路径规则的库文件才能被加载。基于这一发现，我通过定制化编译脚本，将Python核心依赖库与解释器打包为单一二进制文件，同时修改解释器的模块查找逻辑，让其优先从内置路径加载模块，而非依赖系统共享库，这一改造让解释器的兼容性提升了近八成，也让我深刻意识到，沙盒适配的核心是让Python的运行逻辑“嵌入”iOS的执行体系，而非独立于系统之外。</p><p>二进制扩展模块的框架化转换，是Python在iOS沙盒中实现功能扩展的关键路径，也是最容易被忽视的深层适配环节。iOS要求所有二进制模块必须以独立框架的形式存在于指定目录下，且每个框架只能包含一个二进制文件，这种规范与Python传统的模块加载方式完全相悖——后者允许从任意路径加载扩展模块，无需特定的目录结构与元数据配置。这意味着，普通的Python扩展模块若要在沙盒中运行，必须经过复杂的后期处理：不仅要将原始二进制文件封装为符合标准的框架，还要通过特定的标记文件建立模块导入路径与框架位置的映射关系，同时确保框架包含完整的签名信息与元数据。更关键的是，这种转换并非简单的文件格式变更，而是需要调整模块的依赖引用方式，让模块在加载时能够通过沙盒的路径校验与权限审核。实践中，开发者需要借助专门的工具链处理依赖剥离与框架封装，同时手动配置元数据文件，确保模块的导入路径与沙盒的目录结构形成逻辑闭环。我曾为了让一个图像处理类扩展模块在沙盒中运行，花费了近两周时间进行框架化转换，初期直接将二进制文件放入框架目录，结果模块导入时提示“路径未授权”，后来排查发现，iOS框架不仅要求特定的目录结构，还需要在Info.plist文件中配置模块的导入路径映射，且二进制文件必须包含与应用一致的签名信息。通过工具链剥离模块的外部依赖，手动编写Info.plist文件中的路径映射规则，再使用开发者证书对框架进行签名，最终实现了模块的成功导入。这一过程让我明白，沙盒对扩展模块的约束本质上是对“执行单元”的标准化要求，只有让Python模块符合iOS的框架规范，才能获得沙盒的权限认可，而这种转换需要同时掌握Python模块编译原理与iOS框架开发规范，是技术跨界融合的具体体现。</p><p>沙盒环境下Python标准库的隐性缺失，需要通过“功能等效重构”而非简单的库替换来解决。iOS中的Python运行环境并非完整移植桌面端的标准库，而是存在诸多基于系统安全与资源限制的省略，例如部分涉及系统底层调用、网络服务端功能的模块会被默认禁用，这种缺失并非技术疏漏，而是沙盒对应用功能边界的强制界定。很多开发者会尝试寻找第三方替代库，却发现多数库要么依赖被禁用的系统调用，要么因体积过大导致沙盒内资源占用超标。真正有效的应对策略，是基于沙盒允许的功能范围进行功能等效重构：对于数据处理类模块，可通过拆分计算逻辑、优化算法复杂度，在原生支持的轻量级模块基础上实现等效功能；对于网络相关功能，可借助iOS原生框架提供的网络能力进行桥接，而非依赖Python的网络模块；对于文件操作类功能，则需要严格遵循沙盒的目录访问规则，通过自定义数据序列化方式替代传统的文件读写逻辑。在一次数据可视化项目的适配中，我需要使用Python的绘图模块生成图表，但该模块依赖的系统图形库在沙盒中被禁用，直接使用第三方替代库又会导致应用体积超标。为此，我拆解了绘图模块的核心功能，将复杂的绘图逻辑拆分为基础图形绘制、数据映射、色彩渲染三个步骤，基于Python内置的数学模块实现坐标计算，通过iOS原生的图形框架提供的绘制接口完成图形渲染，最终在不依赖外部库的情况下实现了等效功能，且应用体积控制在合理范围。这一实践让我深刻体会到，沙盒环境下的功能重构并非“削足适履”，而是通过对核心功能的本质拆解，找到与系统规则兼容的实现路径，这种重构能力不仅能解决标准库缺失的问题，更能提升代码的轻量化与兼容性，是Python在移动环境中长期生存的关键。</p><p>Python与iOS原生应用的交互壁垒，根源在于沙盒的上下文权限隔离，突破这一壁垒需要构建“语义对齐的桥接层”。沙盒不仅隔离了文件与内存资源，更隔离了不同应用的运行上下文，Python脚本若要调用iOS的原生功能，不仅需要通过桥接工具实现语法层面的交互，更需要解决上下文权限的传递问题——原生API的调用往往依赖特定的应用权限与运行状态，而Python解释器的运行上下文在沙盒中处于独立状态，直接调用会因权限不匹配而失败。此外，两种环境的数据类型与内存管理机制存在本质差异，Python的动态数据类型在传递给原生应用时，若未经过适当的类型转换与生命周期绑定，极易导致资源泄漏或交互失效。应对这一问题，需要构建一层专门的桥接逻辑，该逻辑不仅负责数据类型的转换，更要实现权限上下文的传递与同步：在调用原生API前，桥接层需先校验沙盒赋予的权限范围，确保调用行为符合安全规范；在数据传递过程中，需同步两种环境的内存管理规则，避免出现数据悬空或重复释放的情况；在交互完成后，需及时清理桥接层的中间资源，确保沙盒内的资源占用处于合理范围。我曾在一个交互项目中尝试让Python脚本调用iOS的相机功能，初期使用常规桥接工具直接调用API，结果因权限上下文不匹配导致调用失败，且出现内存泄漏问题。后来通过分析沙盒的权限传递机制，在桥接层中加入了权限校验模块，先通过原生应用获取相机权限，再将权限上下文传递给Python解释器，同时设计了数据类型转换池，对Python的动态数据进行定型处理后再传递给原生API，最后通过生命周期绑定机制确保内存资源的及时释放。这一改造不仅解决了交互失效问题，还将内存占用降低了约40%，让我认识到，Python与iOS原生应用的交互核心并非语法层面的对接，而是上下文与资源管理规则的对齐，桥接层的价值就在于构建一套“翻译机制”，让两种不同技术体系的运行逻辑实现语义互通。</p><p>iOS沙盒中Python适配的长期演进，依赖于“解释器定制化”与“系统规则适配”的双向优化。随着iOS系统的不断更新，沙盒的安全规则与执行规范也在持续迭代，传统的适配方案往往会因系统版本升级而失效，这就要求开发者不能满足于静态的适配策略，而需要建立动态的适配体系。解释器定制化是关键方向之一，通过裁剪Python解释器的内核功能，保留沙盒环境中必要的执行逻辑，去除依赖系统底层调用的冗余模块，可显著提升解释器与沙盒的兼容性；同时，针对iOS的内存管理机制优化解释器的垃圾回收策略，可有效降低资源占用，避免因内存不足导致的执行中断。另一方面，需要建立对系统规则的动态追踪机制，及时掌握沙盒权限配置、二进制格式要求、审核规范等方面的变化，提前调整适配方案。更高级的适配思路是让Python脚本具备环境感知能力，通过检测当前沙盒的权限范围、系统版本、资源配额，自动调整执行逻辑与资源占用策略，实现“自适应式运行”。在长期的适配实践中，我建立了一套解释器定制化模板，通过脚本自动化裁剪解释器内核，保留核心执行模块与轻量级标准库，同时集成了系统规则检测模块，让脚本在启动时自动扫描沙盒环境参数，根据检测结果调整模块加载策略与内存分配方案。</p>]]></description></item><item>    <title><![CDATA[《Python在Android平台的性能优化指南：原生融合与动态调优全析》 程序员阿伟 ]]></title>    <link>https://segmentfault.com/a/1190000047559509</link>    <guid>https://segmentfault.com/a/1190000047559509</guid>    <pubDate>2026-01-22 18:02:37</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>Android生态的硬件碎片化与Python解释型语言的执行特质，构成了性能优化的底层矛盾——这并非简单的代码精简或资源压缩所能破解，而是要深入两者运行逻辑的核心，实现从指令执行到资源调度的全链路协同。多数开发者在Android平台部署Python应用时，极易陷入“表层调优”的误区，过度纠结于脚本执行速度的零散提升，却忽视了ART虚拟机的字节码转换损耗、Python解释器与系统资源调度的节奏错位、跨层数据交互的隐性开销、硬件架构适配的精准度不足等深层问题。真正的性能突破，始于对Android运行时环境的本质认知：从不同CPU架构（ARMv8、x86等）的指令集差异到内存层级（高速缓存、物理内存、虚拟内存）的数据流转规律，从进程调度的优先级动态调整规则到原生能力调用的底层效率，每一个环节都暗藏着未被挖掘的优化空间。实践反复证明，只有让Python的动态执行逻辑与Android的静态资源管理体系形成“同频共振”，通过重构执行路径、优化资源分配策略、打通跨层交互壁垒、适配硬件特性，才能实现从“勉强运行”到“高速响应、低耗运行”的质变，这种底层逻辑的深度融合与动态协同，正是Android Python性能优化的核心要义，也是区分普通开发者与优化高手的关键所在。</p><p>Python解释器在Android平台的运行效率瓶颈，根源在于解释器内核与Android硬件架构、系统调度机制的适配断层，这种断层并非单一因素导致，而是多重逻辑冲突的叠加。不同品牌、不同价位的Android设备，其CPU架构存在显著差异，ARMv8架构的指令集精简高效，而x86架构则侧重兼容性，默认Python解释器的指令解析模块多为通用设计，未针对特定架构进行优化，导致在ARMv8设备上出现指令执行冗余，在x86设备上则因指令转换产生额外开销。同时，Android设备的内存层级缓存策略各不相同，部分中低端设备的高速缓存容量有限，而Python解释器的内存访问逻辑未考虑缓存命中率，频繁出现缓存失效，导致内存访问效率低下。更关键的是，Android的进程调度机制会根据应用的生命周期状态（前台、后台、休眠）动态分配CPU资源，而Python解释器的默认线程管理逻辑是独立于系统调度的，往往在应用进入后台后仍维持高资源占用，引发系统资源竞争，或在前台高负载运行时因CPU资源分配不足导致卡顿。应对这一困境，核心思路是对Python解释器进行“架构化定制”而非“通用化改造”：针对目标设备的CPU指令集，裁剪解释器内核中冗余的指令解析模块，保留与该架构高度兼容的核心执行逻辑，甚至对关键指令的解析流程进行重写，让指令执行更贴合硬件特性；同时优化解释器的线程调度模型，通过调用Android系统API感知应用的生命周期状态，在前台交互场景下自动提升线程优先级以保障响应速度，在后台运行时则降低线程调度频率、释放非必要资源，主动适配系统调度规则。在长期的实践探索中发现，经过架构化定制的解释器，在ARMv8架构的中高端Android设备上，指令执行效率提升近五成，内存占用降低三成，而在x86架构的平板设备上，兼容性未受影响的前提下，运行速度提升约三成，这一优化路径的关键在于“针对性适配”，要求开发者深入理解不同硬件架构的指令特性、Android的进程管理机制与线程调度规则，而非依赖通用化的解释器版本。</p><p>跨层数据交互的隐性开销，是Android Python应用性能损耗的重要来源，这种开销往往被开发者忽视，却在实际运行中占据了大量的响应时间，尤其在高频交互场景下更为明显。Python脚本与Android原生组件（如Activity、Service、ContentProvider）的交互，传统方式需经过多轮数据类型转换与序列化/反序列化过程，Python的动态数据类型（如列表、字典）需先转换为中间格式，再序列化后传输至原生组件，原生组件接收后需反序列化再转换为自身支持的数据类型，这一系列操作不仅存在数据格式不兼容的风险，更会因转换逻辑复杂、数据冗余导致响应延迟。在处理大数据量场景时，如实时传感器数据流（加速度传感器、陀螺仪数据）、图像像素数据、音频采样数据，这种开销会被急剧放大，甚至出现数据传输中断、交互卡顿的现象。很多开发者会选择第三方桥接库简化交互流程，但多数桥接库为兼容多场景、多数据类型，设计了通用化的转换逻辑，反而增加了额外的性能损耗，无法满足高频、大数据量交互的需求。有效的优化策略是“定制化数据交互协议”：基于具体业务场景的数据流特性，定义轻量化的私有数据格式，仅保留必要字段，剔除冗余信息，减少数据传输体量；同时绕过中间件的多层转发，直接调用Android原生的跨进程通信接口（如Binder），实现Python脚本与原生组件的直接数据传输，甚至将Python输出的数据直接封装为Android原生支持的内存缓冲区格式，彻底避免序列化/反序列化过程。例如在处理实时传感器数据时，通过定制化协议将传感器数据封装为连续的二进制流，直接写入原生组件的内存缓冲区，可将数据传输延迟降低六成以上，且数据丢失率几乎为零；在图像数据交互场景中，采用原生支持的像素格式进行数据传输，避免格式转换的性能损耗，可让图像处理的整体响应速度提升近一倍。这一优化思路的本质是“场景化精简”，即根据数据的传输频率、体量、格式要求，设计最贴合的交互路径，而非依赖通用化的桥接方案，这需要开发者同时掌握Python的数据处理逻辑与Android的原生通信机制、数据格式规范。</p><p>内存管理的动态均衡，是解决Android Python应用资源占用过高、运行卡顿的核心抓手，其关键在于让Python的内存分配逻辑与Android的内存回收机制形成深度协同，而非各自独立运行。Python解释器的默认垃圾回收策略是基于自身的内存占用阈值触发，完全未考虑Android设备的内存层级结构与系统级的内存回收机制，导致频繁出现“Python内存未释放而Android系统触发低内存查杀预警”的矛盾——Python解释器认为内存占用未达阈值，未触发垃圾回收，而Android系统已因整体内存紧张开始清理后台应用，若Python应用此时处于后台，极易被系统查杀；更隐蔽的是，Python的对象引用机制与Android的内存泄漏检测逻辑不兼容，部分Python对象的隐性引用无法被Android的内存检测工具识别，长期运行后会产生隐性内存占用，导致应用可用内存逐渐减少，响应速度变慢。此外，Python脚本中频繁创建与销毁短期对象的行为，会导致内存波动剧烈，增加Android系统内存管理的负担，进一步影响性能。优化的核心路径是“双维度内存调控”：一方面修改Python解释器的垃圾回收触发条件，通过调用Android系统API获取当前设备的可用内存比例、系统内存紧张状态，将其与Python自身的内存占用阈值结合，在系统内存紧张时提前触发垃圾回收，释放冗余对象，主动适配系统内存管理策略；另一方面优化Python脚本的对象创建逻辑，采用对象池复用机制，对频繁创建的短期对象（如数据处理过程中的临时变量、循环中的迭代对象）进行复用，减少对象创建与销毁带来的内存波动，同时通过代码重构避免循环引用、全局变量过度使用等导致垃圾回收无法识别的隐性占用。实践表明，通过这种双维度调控，Python应用的内存波动幅度可降低七成，后台运行时的内存占用可压缩至原来的一半，应用被系统低内存查杀的概率降低八成以上，且长期运行后的响应速度衰减幅度控制在10%以内，这一过程需要开发者深入理解Python的垃圾回收原理（如引用计数、标记-清除算法）与Android的内存管理架构（如内存分级、低内存查杀机制），实现两者的动态适配而非独立调控。</p><p>原生能力的深度融合，是突破Python在Android平台性能上限的关键路径，核心在于“用原生优势弥补解释型语言短板”，构建Python与Android原生的协同执行体系，而非让Python单独承担所有任务。Python作为解释型语言，在CPU密集型任务（如复杂数学计算、图像视频处理、大数据解析）和IO密集型任务（如高并发网络请求、大文件读写）中，受限于解释执行的特性，性能往往远不及Android原生开发语言（Java、Kotlin）编译后的机器码执行效率。但多数开发者仅满足于通过桥接库简单调用原生API，却未充分利用原生组件的底层优化能力——如原生图形处理框架的硬件加速、网络框架的并发调度优化、文件系统的高效读写接口，导致“原生优势未充分发挥”，整体性能仍受限于Python的解释执行速度。真正的深度融合，是基于“优势互补”的模块化分工：将核心性能瓶颈模块交由Android原生实现，充分利用原生框架的硬件加速、系统级优化能力，而Python则专注于业务逻辑编排、动态扩展、数据灵活处理等其擅长的领域，通过轻量化的交互接口实现两者的协同执行。例如在图像识别场景中，将图像预处理（如像素裁剪、格式转换、降噪）等CPU密集型操作封装为Android原生组件，利用原生图形框架的硬件加速能力提升处理效率，Python脚本仅负责调用该组件、传入原始图像数据，并处理最终的识别结果，这种分工可将整体处理效率提升三倍以上；在网络请求场景中，利用Android原生的网络框架实现高并发请求调度、缓存管理、断点续传等功能，Python则专注于数据解析、业务逻辑判断，避免解释型语言在网络IO调度中的低效问题；在大数据解析场景中，将数据读取、格式转换等IO密集型操作交由原生组件处理，Python专注于数据过滤、统计分析，可显著提升解析速度。这一优化思路的本质是“模块化分工”，即根据不同模块的性能需求与语言特性，合理分配执行载体，打破“单一语言开发”的思维定式，让Python与Android原生各自发挥优势，实现1+1&gt;2的性能提升，这需要开发者同时掌握Python的业务编排能力与Android的原生开发技术。</p><p>性能监控与自适应调优体系的搭建，是保障Android Python应用长期稳定高效运行的核心支撑，而非依赖“一次性优化”的静态方案——Android生态的复杂性决定了固定优化策略无法适配所有场景。Android设备的硬件差异巨大，高端旗舰机的CPU性能、内存容量是入门机型的数倍，固定的运行参数在高端机上可能浪费资源，在入门机型上则可能导致卡顿；系统版本迭代频繁，从Android 10到Android 14，运行时特性、权限机制、资源调度规则均有变化，旧版本的优化方案可能在新版本上失效；用户的使用场景更是多样，前台交互场景需要高响应速度，后台计算场景需要低资源占用，低电量场景则需兼顾性能与功耗，固定的优化策略无法满足多场景需求。很多开发者在完成初期优化后缺乏持续监控机制，无法及时发现新场景、新设备、新版本系统下的性能退化，导致应用体验不稳定。</p>]]></description></item><item>    <title><![CDATA[阿里云可观测 2025 年 12 月产品动态 阿里云云原生 ]]></title>    <link>https://segmentfault.com/a/1190000047559524</link>    <guid>https://segmentfault.com/a/1190000047559524</guid>    <pubDate>2026-01-22 18:02:04</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>本月可观测热文回顾</h2><p><strong>文章一览：</strong></p><p><a href="https://link.segmentfault.com/?enc=Sju0Dd%2BEN0D0ezu8dngOPQ%3D%3D.kM7oC1wBxu2Aci02s4WCnT4oMVsqWsI0enbs%2BI7wgnFhvaF%2BMTWB6M2TIQgYJWZzgx0WzSmnHcRwzex56DFzAH%2BqUuVvP0d0V1YD%2BbxjGBxBtw6Kt%2F0igcOI0GmWylPHdrBuUadxHGGAerKg9W16LqHmc6f1AHm5lfgEbe9OdXdAWxl0o1%2BuOnB4F1TJZOF5" rel="nofollow" target="_blank">构建数据资产“导航地图”：详解 UModel 数据发现与全链路分析能力</a></p><p><a href="https://link.segmentfault.com/?enc=Xmg5nK18sutVj1Nw%2BVgbXQ%3D%3D.ETpnDJd3tupBi5SKHfTcUxfs9Bv6e%2Bq%2Blp87RlwtOowEx4%2F4bpfKUVv3vuTNCGGhlCRksa8cCpkeTpK7eicOEDqU%2F1yqG3jATOljqKG43MyG85INzKhxWcGm%2FHDORuJRYM4e0jhzv8%2B7eLkFW0td5gZuSOZ3WNMZ7A%2BuxzooXgQJInM0X25FVtyGUR7iZuoA" rel="nofollow" target="_blank">基于 UModel 高效构建可观测场景统一实体搜索引擎</a></p><p><a href="https://link.segmentfault.com/?enc=WIv6%2F9b5dnmr8j0VK7lbBA%3D%3D.YvAEo9gn7wm3ABn6dJODkPAt457jTQIN6MQabITqnJ2BZxXCsNkanRIEFjmtf%2FX5wxhmmDVDn%2FjjqmVTUgumHwoFKQnde%2B3TB8L%2BnDbzC2Wj46MZ%2BIJUFsVyYSI%2FgLrqT%2F3V7edwmQwY9D0TFcFuWsNU4nPLUr%2BFsgXP4pRnENsrrue9CtQOdQndey36Ns1w" rel="nofollow" target="_blank">揭开 Java 容器“消失的内存”之谜：云监控 2.0 SysOM 诊断实践</a></p><p><a href="https://link.segmentfault.com/?enc=8k1Z0v6QTt1yeOe1ccktdA%3D%3D.DtZLVPuOztRXoTwZJWyfQIZHhwBob%2FGm%2FFFWis2HnsQdej0D3kVfWHEAdcMw%2BsNU6wWKeMtikN60gFgmJaov6LncbtA1qWg9OzlKcOb8HzT201u8EG6nlBabH4KU5Y3wMKbARLwF%2FapYKoopcXhewhOn7XnjzLlncRdBSBmOx77jOrBIWa%2FpSvnxyuGtiWHF" rel="nofollow" target="_blank">打通可观测性的“任督二脉”：实体与关系的终极融合</a></p><p><a href="https://link.segmentfault.com/?enc=rThaAx%2FFtfTzS%2Fa%2BzX4DXg%3D%3D.0h7n9%2FgNHr3VBXQMywJSyAdQ3pzOMzyWGESVYKX2jTLPPmHU6pU6VhlkMnB0Qj6mv150q9ukKxBPHotIzI8NAaHGiR3yf4R2yi3isOY1yWiyapnQCIHkbe461ZYDIhM7MxACsBCPiN1NOcXlxOiiiiEYXcjMJ3Sjx4MvNzZ0LD2re2prCSVIYbEdVrYTkcj9" rel="nofollow" target="_blank">一行代码实现智能异常检测：UModel PaaS API 架构设计与最佳实践</a></p><p><a href="https://link.segmentfault.com/?enc=sDp%2BGQ%2BGENAXQPuTblz6OQ%3D%3D.a8xs3CpGqaHlnx5heDCS0j13Ss9%2F1kigvkjdyOGuFJbJYXBMDwb9NGiNv3klrXMJ4iG%2BGMSI9f2bIiEuVpUi22edcaYJgLIqBu47yfkbcCZrqd%2BHoBOQoHXsEhwZwBqRrd64vPCii2TL7r5BdiCXt%2BmMr7Ju13Wx57OzlzdbCQMdqM%2FDUAouFIlvneJjqaZp" rel="nofollow" target="_blank">一文带你玩转 WebSocket 全链路可观测</a></p><p><a href="https://link.segmentfault.com/?enc=Ij%2B86KswLi8Y6UMRziafLw%3D%3D.ug1TnJODhgOQdNkyw8NE%2BmLvuTcxP4QfnwBDBhVGlyhzIbMZjK3TWaf76Q%2FrzExZMFwc4BVtK9X%2FKdS913D4xmJfbmifQ3cqHqnVZAb%2Fq4Yegzx2kVS8XoIystNtPIDoeaGBM%2FUJJcAGWle%2BL%2B5TGKH%2BaBBkjJp1%2FF4HjR%2F788PzadYKB5rDFm3vXQiV82Vh" rel="nofollow" target="_blank">Android 崩溃监控实战：一次完整的生产环境崩溃排查全流程</a></p><p><a href="https://link.segmentfault.com/?enc=BQuLm3EWGoJorRz6CJMMiA%3D%3D.L5jOwkzBqWHlrZBefLM9lvRqBJfp4BQuwoAnK8%2F40Fxop2lWCjFo%2FnrJb3tiVRrLdn0Tai0I3kfneLxLUlaH4cxR%2B6LuRNJx9hkmtf22Lj3rcro%2B3GJvz9zjUMe1J%2BQf3rpuS8J8jDXOUmryP4k1ylKSgZFBoDpjzGqTT3qO%2BdzZJWlYUK7rawfFDzfZhHtZ" rel="nofollow" target="_blank">已上线！云监控 2.0 面向实体的全链路日志审计与风险溯源</a></p><p><a href="https://link.segmentfault.com/?enc=SvZlnncYzxR5UWOiNApyTA%3D%3D.IjCmbFjq3b4vmFk%2BPw149jdscApBNyBb9ykqorvwC31dc8mm2Pi%2BYCe2ZehO%2BVls24E%2FbTzq0C9YxloQpXP2LWkbxeskYmWMUQw6T3kWnNVsY3Xv7b%2BAdp4ulfUTJbHv68TghKC36Mci8vc1I94%2BDaXirWVh5vU7vi2RIflSMf3Gx719U1h0AljXe27PqDE%2F" rel="nofollow" target="_blank">阿里云操作系统控制台一招解决网络丢包</a></p><p><a href="https://link.segmentfault.com/?enc=a5OXVtOZBk6Zh1PnA4MexQ%3D%3D.ama5ola7rnZ%2BBR6KgVzuV81Jt3zrtEQe570xfO%2FSCaKg58J8e4mY8AUrQ5ECqXOufmUE4Oq3pIcuacuQ81AkziUL3CMIYkp5PXQpzh64YoO%2B0P0IjL0ceF7DC46KuB6oCgK7K%2FyhG11358uAhZ5V4aWmVowPeA62j%2FCEZuCN7dPGn23395XNE2NcpkI%2BZoLC" rel="nofollow" target="_blank">加入我们，一起定义「Data x AI」的未来</a></p><p><a href="https://link.segmentfault.com/?enc=cngWWdpD0wjEoT5XtXdX8Q%3D%3D.1l4chZIdDFWx376%2FeZrMER8dDXeT6SJ6RdcC9SIESwDlPOSCVIdj2JeZ1ltapIVS9XKV6Zsib6vG99i%2BCX2VUC089PogAM8sW9DAFG8bA6VH7JwB4XIrYDFSTsEfAZrMtdKvioQNJulrODaCybHFFifUahGA2uQlVMyL%2B765T1nwDqWGdahg8ZM0r0YlGHFK" rel="nofollow" target="_blank">iOS 崩溃排查不再靠猜！这份分层捕获指南请收好</a></p><p><a href="https://link.segmentfault.com/?enc=uPS2xoLXT0m4Vot0MwYekQ%3D%3D.fubrtleOGPwrWJ%2BRYWam6gzKBA2nQypbEUGb8CJGHnUikkZdqfiwDaTPmbzE4NEzH%2BGhgEs99SDkcLLYr1UwVMalIlxTweu3S2ShM1cNTBSFSDH9R8Ns0lIUm0SXNtIjo4KKk68EyiOnzLT7DNB8Pc%2FWjPjqykFenDhpYu7%2BREv9qEyCBJxP3pagMYkunUOj" rel="nofollow" target="_blank">跨云日志统一：对象存储数据导入 SLS 的智能之路</a></p><p><a href="https://link.segmentfault.com/?enc=9Ly31pp3m36GUDaHxDqCMA%3D%3D.sjFLNQnXI9FY0ytp3jSuN3gejUJ9u85EZDM13sxxsLnHq0x9jHlxb8%2BDa7rYp1Y%2Bir%2Fa55IsSaOJqH01rJalRH3s97RikCe4o7xDEmaJA1ZJMIRJJrxfmUduMfaH0oxbI3QwIZkiiJBT3ImKeB0vdzxEH8%2FVnVV9eaZu01N4p4hO7Nayv80ZojOfqT2ce%2Flx" rel="nofollow" target="_blank">拒绝查询超时：一次真实高并发场景下的 SLS 物化视图调优实战</a></p><p><a href="https://link.segmentfault.com/?enc=ZSt8YALGiibHBvW0UvXmow%3D%3D.WdmJc8mv%2FSrKN9DuPxpnU9NryRBWQZx%2F2sQ3q7zzyEtzU041ODHcropdH0sJTqYoorx49YB3Q%2F6nq4eIfvu7RtidmUHozp7ppR4ep%2BGmDEd9rHs90j63hZwkzaaMcvQ2hN4QOHAhFj7dpHiuQ4zaAZ6J1Bn2jBPkzEYDBBi%2BnHwekraXifEdb398TeIWEvcX" rel="nofollow" target="_blank">阿里云可观测联合 Datadog 发布 OpenTelemetry Go 自动插桩工具</a></p><h2>功能快报</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559526" alt="image" title="image"/></p><p>点击<a href="https://link.segmentfault.com/?enc=6Vgn39sS8WkhaqL0mVepFg%3D%3D.QKD0BInfUIYPqEGc1wH8rcHlVVHnYUaVJlMcuv9NxPw431HAcEidI02LkRIv9WJA%2B0Lu0bCqiDlg1EciuDbEv4zzTbEzdMRtQG9G46dVVOmg2dlyY8%2BLpRERoJh%2BJ0bB0dHjfurzZBy3y5KnuPCphg%3D%3D" rel="nofollow" target="_blank">此处</a>，了解更多产品详情。</p>]]></description></item><item>    <title><![CDATA[全栈监控与告警设计——从SLO到告警规则，避免告警雪崩的分级体系 南城 ]]></title>    <link>https://segmentfault.com/a/1190000047559533</link>    <guid>https://segmentfault.com/a/1190000047559533</guid>    <pubDate>2026-01-22 18:01:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><strong>写在前面，本人目前处于求职中，如有合适内推岗位，请加：lpshiyue 感谢。同时还望大家一键三连，赚点奶粉钱。本系列已完结，完整版阅读课联系本人</strong></p><blockquote>现代分布式系统的可观测性不是简单的数据收集，而是基于业务目标的智能过滤与决策体系</blockquote><p>在掌握了风险可控的发布策略后，我们需要解决一个更根本的问题：如何准确判断发布是否成功？如何在海量监控数据中识别真正重要的信号？全栈监控与告警设计正是连接系统状态与人工干预的关键桥梁。本文将从SLO定义出发，深入探讨监控指标体系构建、告警规则设计、分级抑制策略的全链路实践，帮助企业构建既敏感又精准的可观测体系。</p><h2>1 监控体系的哲学转变：从数据收集到价值判断</h2><h3>1.1 传统监控的局限性：数据丰富而洞察匮乏</h3><p>传统监控系统面临的核心矛盾是<strong>数据收集能力</strong>与<strong>价值提取效率</strong>之间的巨大鸿沟。随着微服务和云原生架构的普及，单个系统产生的指标数量呈指数级增长，但运维团队能够有效处理的告警数量基本恒定。</p><p><strong>监控数据的三个价值层次</strong>：</p><ul><li><strong>基础指标</strong>：CPU、内存、网络等资源消耗数据（容易收集但价值有限）</li><li><strong>应用性能</strong>：请求延迟、错误率、吞吐量等业务相关指标（需要业务埋点）</li><li><strong>用户体验</strong>：真实用户感知的可用性和性能（最难测量但最具价值）</li></ul><p>根据行业数据，未经验证的监控告警中<strong>超过70%属于噪音或误报</strong>，导致团队产生"告警疲劳"，反而忽略真正重要的异常信号。</p><h3>1.2 SLO：监控价值的锚点</h3><p>Service Level Objective（服务等级目标）为监控系统提供了<strong>价值判断的基准</strong>。SLO将模糊的"系统健康"概念转化为可量化的目标，成为区分信号与噪音的核心依据。</p><p><strong>SLO的核心价值</strong>在于：</p><ul><li><strong>目标一致性</strong>：使技术指标与业务目标对齐</li><li><strong>优先级判断</strong>：基于错误预算确定问题处理的紧急程度</li><li><strong>资源分配</strong>：根据SLO达成情况指导稳定性投入</li></ul><pre><code class="yaml"># SLO定义示例：API服务可用性目标
api_service_slo:
  availability: 99.9%  # 每月最多43分钟不可用
  latency_p95: 200ms   # 95%请求延迟低于200ms
  error_rate: 0.1%     # 错误率低于0.1%
  rolling_period: 30d  # 滚动计算周期为30天</code></pre><h2>2 全栈监控体系构建：从基础设施到用户体验</h2><h3>2.1 监控数据的三位一体</h3><p>现代监控体系需要整合<strong>指标（Metrics）、日志（Logs）、追踪（Traces）</strong> 三类数据，形成完整的可观测性能力。</p><p><strong>指标监控</strong>提供系统量化度量，适合趋势分析和阈值告警：</p><ul><li><strong>基础资源指标</strong>：CPU、内存、磁盘、网络（通过Node Exporter采集）</li><li><strong>应用性能指标</strong>：QPS、延迟、错误率（通过应用埋点暴露）</li><li><strong>业务指标</strong>：订单量、支付成功率、用户活跃度（自定义业务埋点）</li></ul><p><strong>日志分析</strong>记录系统详细行为，用于故障排查和审计：</p><ul><li>结构化日志收集（Filebeat/Fluentd）</li><li>日志聚合与检索（Elasticsearch）</li><li>模式识别与异常检测（机器学习分析）</li></ul><p><strong>分布式追踪</strong>提供请求全链路视角，优化性能诊断：</p><ul><li>请求级跟踪（Jaeger/SkyWalking）</li><li>服务依赖拓扑自动发现</li><li>瓶颈分析与链路优化</li></ul><h3>2.2 监控数据采集的技术选型</h3><p><strong>Prometheus生态</strong>已成为云原生监控的事实标准，其<strong>拉取模型</strong>和<strong>多维数据模型</strong>特别适合动态环境。</p><pre><code class="yaml"># Prometheus配置示例
scrape_configs:
  - job_name: 'api-service'
    static_configs:
      - targets: ['api-service:8080']
    metrics_path: '/metrics'
    scrape_interval: 15s
    # 指标Relabeling，增强元数据
    relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: blackbox-exporter:9115</code></pre><p><strong>多数据源整合</strong>是大型系统的必然选择。Zabbix适合传统基础设施监控，Prometheus擅长云原生环境，商业方案如CloudWatch提供开箱即用体验。</p><h3>2.3 监控数据建模与存储优化</h3><p>监控数据的<strong>时序特性</strong>要求专用存储方案。Prometheus TSDB适合短期数据存储，长期存储需考虑Thanos、Cortex或M3DB等分布式方案。</p><p><strong>数据降采样</strong>策略对成本控制至关重要：</p><ul><li>原始数据：保留2天，15秒精度</li><li>5分钟聚合数据：保留30天</li><li>1小时聚合数据：保留1年</li><li>日级别聚合数据：永久保留</li></ul><h2>3 从SLO到告警规则：精准告警的数学基础</h2><h3>3.1 错误预算：SLO的可操作化表达</h3><p>错误预算将SLO转化为<strong>可消耗的资源</strong>，为告警触发提供客观依据。例如，99.9%可用性目标意味着每月有43分钟错误预算。</p><p><strong>错误预算消耗速率</strong>（Burn Rate）成为告警的关键指标：</p><ul><li><strong>快速燃烧</strong>：高错误率短时间消耗大量预算（需要立即处理）</li><li><strong>慢速燃烧</strong>：低错误率持续消耗预算（需要计划性修复）</li></ul><pre><code class="python"># 错误预算消耗计算
def calculate_burn_rate(slo_target, error_rate, time_window):
    """计算错误预算消耗速率"""
    error_budget = 1 - slo_target  # 错误预算比例
    actual_consumption = error_rate * time_window
    burn_rate = actual_consumption / (error_budget * time_window)
    return burn_rate

# 示例：99.9%可用性目标，1%错误率持续30分钟
burn_rate = calculate_burn_rate(0.999, 0.01, 30)
if burn_rate &gt; 10:  # 消耗速率超过10倍
    trigger_critical_alert()</code></pre><h3>3.2 多维度SLO指标映射</h3><p>不同服务需要不同的SLO定义方式，核心是建立<strong>技术指标与用户体验</strong>的直接关联。</p><p><strong>API服务SLO映射</strong>：</p><pre><code class="sql">-- 基于SLI（服务等级指标）计算SLO达成率
SELECT 
    time_bucket('1 hour', timestamp) as hour,
    -- 可用性SLI
    SUM(CASE WHEN status_code &lt; 500 THEN 1 ELSE 0 END) * 1.0 / COUNT(*) as availability,
    -- 延迟SLI 
    PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY latency) as latency_p95,
    -- 错误率SLI
    SUM(CASE WHEN status_code &gt;= 500 THEN 1 ELSE 0 END) * 1.0 / COUNT(*) as error_rate
FROM api_requests 
WHERE timestamp &gt;= NOW() - INTERVAL '30 days'
GROUP BY hour</code></pre><p><strong>批处理服务SLO特性</strong>：</p><ul><li><strong>完整性</strong>：数据处理是否100%成功</li><li><strong>及时性</strong>：作业是否在时间窗口内完成</li><li><strong>正确性</strong>：输出结果是否符合质量要求</li></ul><h3>3.3 告警规则的数学建模</h3><p>有效的告警规则需要基于<strong>统计学原理</strong>而非简单阈值。</p><p><strong>动态基线告警</strong>考虑历史模式和周期性：</p><pre><code class="sql">-- 基于时间序列分析的异常检测
WITH baseline AS (
  SELECT
    AVG(latency) as historical_avg,
    STDDEV(latency) as historical_stddev
  FROM api_metrics
  WHERE time &gt; NOW() - INTERVAL '4 weeks'
    AND hour_of_day = EXTRACT(HOUR FROM NOW())
)
SELECT 
  current.latency,
  (current.latency - baseline.historical_avg) / baseline.historical_stddev as z_score
FROM current_metrics current, baseline
WHERE ABS((current.latency - baseline.historical_avg) / baseline.historical_stddev) &gt; 3</code></pre><p><strong>多指标复合告警</strong>提高准确性：</p><ul><li><strong>条件1</strong>：错误率 &gt; 2%（持续5分钟）</li><li><strong>条件2</strong>：P95延迟 &gt; 基线200%</li><li><strong>条件3</strong>：流量下降 &gt; 30%</li><li><strong>触发条件</strong>：条件1 AND (条件2 OR 条件3)</li></ul><h2>4 告警分级体系：避免雪崩的防御工事</h2><h3>4.1 分级原则：基于业务影响而非技术症状</h3><p>告警分级的目标是确保<strong>重要告警得到及时处理</strong>，而非处理所有技术异常。分级应基于<strong>业务影响程度</strong>而非技术严重性。</p><p><strong>四级分类体系</strong>在实践中证明有效：</p><ul><li><strong>P0（紧急）</strong>：业务核心功能不可用，影响大量用户（立即呼叫）</li><li><strong>P1（高）</strong>：功能降级或部分用户受影响（2小时内处理）</li><li><strong>P2（中）</strong>：潜在问题或边缘功能异常（24小时内处理）</li><li><strong>P3（低）</strong>：轻微异常或需要观察（无需立即处理）</li></ul><h3>4.2 智能抑制与降噪策略</h3><p>告警抑制是避免<strong>告警雪崩</strong>的关键技术。</p><p><strong>层级抑制</strong>确保只收到根本原因告警：</p><pre><code class="yaml"># Alertmanager抑制规则示例
inhibit_rules:
  - source_match:  # 源告警（更严重）
      severity: 'critical' 
    target_match:  # 目标告警（被抑制）
      severity: 'warning'
    equal: ['cluster', 'alertname']  # 相同集群和告警名称</code></pre><p><strong>时间窗口聚合</strong>将相关告警合并发送：</p><pre><code class="yaml"># Alertmanager路由配置
route:
  group_by: ['cluster', 'alertname']
  group_wait: 10s  # 初始等待时间
  group_interval: 1m  # 同一组告警发送间隔
  repeat_interval: 4h  # 相同告警重复发送间隔</code></pre><p><strong>动态静默</strong>基于条件自动抑制已知问题：</p><pre><code class="sql">-- 智能静默规则示例
CREATE RULE auto_silence_maintenance 
WHEN alert_name = 'NodeDown' 
AND description LIKE '%for maintenance%'
DO SILENCE FOR 2h;</code></pre><h3>4.3 分级通知渠道与升级策略</h3><p>不同级别的告警需要不同的<strong>通知强度和升级路径</strong>。</p><p><strong>通知渠道矩阵</strong>：</p><table><thead><tr><th>严重等级</th><th>即时通知</th><th>1小时内未确认</th><th>4小时内未解决</th></tr></thead><tbody><tr><td>P0</td><td>电话+短信+钉钉</td><td>升级主管</td><td>升级总监+运维总监</td></tr><tr><td>P1</td><td>钉钉+短信</td><td>升级团队主管</td><td>升级部门主管</td></tr><tr><td>P2</td><td>钉钉</td><td>每日站会同步</td><td>周报汇总</td></tr><tr><td>P3</td><td>工单系统</td><td>每周评审</td><td>月度优化</td></tr></tbody></table><p><strong>人性化通知内容</strong>提升响应效率：</p><pre><code class="json">{
  "alert_id": "API_HIGH_ERROR_RATE_20250115",
  "title": "【P1】订单服务错误率超过阈值",
  "summary": "订单服务错误率在5分钟内从1%上升到5%，已消耗15%错误预算",
  "impact": "可能导致0.1%用户下单失败，预计影响金额5万元/小时",
  "actions": [
    "1. 检查订单服务日志：https://logs.company.com/order-service",
    "2. 查看相关监控：https://grafana.company.com/d/order-overview",
    "3. 最近部署：订单服务v1.2.3（2小时前部署）"
  ],
  "runbook": "https://runbook.company.com/order-service-high-error-rate",
  "slo_impact": "错误预算消耗速率：3倍（正常阈值：1倍）"
}</code></pre><h2>5 全栈监控实战：从配置到优化的完整流程</h2><h3>5.1 监控即代码：声明式配置管理</h3><p>将监控配置版本化，实现<strong>可重复、可审计</strong>的监控体系。</p><p><strong>Prometheus规则即代码</strong>：</p><pre><code class="yaml"># api_service_alerts.yml
groups:
- name: api_service
  rules:
  - alert: APIHighErrorRate
    expr: |
      # 基于错误预算的智能告警
      sum(rate(api_requests_total{status=~"5.."}[5m])) by (service)
      / 
      sum(rate(api_requests_total[5m])) by (service)
      &gt; 0.05  # 5%错误率阈值
    for: 5m
    labels:
      severity: critical
      service: api-gateway
    annotations:
      summary: "{{ $labels.service }} 错误率超过5%"
      description: "服务 {{ $labels.service }} 当前错误率为 {{ $value }}，已持续5分钟"
      runbook: "https://runbook.company.com/api-high-error-rate"</code></pre><p><strong>Dashboard即代码</strong>（JSON配置）确保监控视图一致性：</p><pre><code class="json">{
  "dashboard": {
    "title": "订单服务监控",
    "tags": ["microservice", "order"],
    "timezone": "browser",
    "panels": [
      {
        "title": "API成功率",
        "type": "graph",
        "targets": [
          {
            "expr": "sum(rate(orders_api_requests_total{status=~'2..'}[5m])) / sum(rate(orders_api_requests_total[5m]))",
            "legendFormat": "成功率"
          }
        ]
      }
    ]
  }
}</code></pre><h3>5.2 监控自愈与自动化响应</h3><p><strong>自动化响应</strong>逐步降低人工干预需求。</p><p><strong>基于严重程度的自动化策略</strong>：</p><pre><code class="python">def evaluate_autoremediation(alert):
    """评估是否适合自动修复"""
    if alert.severity == "critical":
        if alert.metric == "cpu_usage" and alert.value &gt; 90:
            return scale_out(alert.service, factor=1.5)
        elif alert.metric == "memory_usage" and alert.value &gt; 95:
            return restart_pod(alert.pod_name)
    return None</code></pre><p><strong>渐进式应急响应</strong>：</p><ol><li><strong>Level 1</strong>：自动扩容/重启（无状态服务）</li><li><strong>Level 2</strong>：流量切换/降级（有状态服务）</li><li><strong>Level 3</strong>：人工决策介入（数据敏感操作）</li></ol><h3>5.3 监控效能度量与持续优化</h3><p>监控系统本身需要被监控和优化。</p><p><strong>关键效能指标</strong>：</p><ul><li><strong>告警准确率</strong>：有效告警比例（目标&gt;90%）</li><li><strong>平均检测时间</strong>（MTTD）：异常发生到告警的时间（目标&lt;1分钟）</li><li><strong>平均响应时间</strong>（MTTR）：告警到修复的时间（目标&lt;15分钟）</li><li><strong>告警疲劳指数</strong>：人均每日处理告警数（目标&lt;5条）</li></ul><p><strong>定期健康度评估</strong>：</p><pre><code class="sql">-- 监控系统健康度SQL查询
SELECT
  DATE(timestamp) as day,
  COUNT(*) as total_alerts,
  SUM(CASE WHEN acknowledged = true THEN 1 ELSE 0 END) as acknowledged_alerts,
  AVG(acknowledge_time - trigger_time) as avg_ack_time,
  PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY acknowledge_time - trigger_time) as p95_ack_time
FROM alerts
WHERE timestamp &gt;= NOW() - INTERVAL '30 days'
GROUP BY day
ORDER BY day;</code></pre><h2>6 组织协同与文化建设</h2><h3>6.1 监控责任共担模型</h3><p>监控不是运维团队的独角戏，而需要<strong>全组织协同</strong>。</p><p><strong>三级责任模型</strong>：</p><ul><li><strong>平台团队</strong>：负责监控基础设施稳定性和通用指标</li><li><strong>业务团队</strong>：负责业务指标和SLO定义</li><li><strong>SRE团队</strong>：负责SLO达标和错误预算管理</li></ul><p><strong>监控素养培养</strong>：</p><ul><li>新员工监控工具培训</li><li>定期监控案例分享会</li><li>监控配置代码审查</li></ul><h3>6.2 监控质量内建流程</h3><p>将监控要求<strong>嵌入开发流程</strong>，而非事后补丁。</p><p><strong>开发阶段检查清单</strong>：</p><ul><li>[ ] 应用暴露必要的监控指标</li><li>[ ] 定义清晰的SLO和目标</li><li>[ ] 设计告警规则和响应流程</li><li>[ ] 准备运维手册和排查指南</li></ul><p><strong>部署流水线集成</strong>：</p><pre><code class="yaml"># CI/CD中的监控校验
- name: Validate Monitoring
  steps:
    - name: Check Metrics Exposure
      run: |
        curl -s http://$APP_URL/metrics | grep -q "http_requests_total"
    - name: Validate SLO Definition
      run: |
        python scripts/validate_slo.py --manifest slo/manifest.yaml</code></pre><h2>总结</h2><p>构建有效的全栈监控与告警体系是一个<strong>持续演进</strong>的过程，需要技术、流程和文化的协同发展。从SLO定义到告警规则，再到分级抑制策略，每一层都需要精心设计和不断优化。</p><p><strong>成功监控体系的核心特征</strong>：</p><ol><li><strong>业务对齐</strong>：监控指标与业务目标紧密关联</li><li><strong>精准告警</strong>：基于SLO和错误预算的智能触发</li><li><strong>分级处理</strong>：重要信号优先处理，噪音自动抑制</li><li><strong>持续优化</strong>：定期评估效果并迭代改进</li></ol><p><strong>避免的常见反模式</strong>：</p><ul><li>监控指标丰富但缺乏业务关联</li><li>告警数量庞大但有效信号稀少</li><li>响应流程冗长但解决效率低下</li><li>工具堆砌但缺乏整体设计</li></ul><p>监控的终极目标不是收集更多数据，而是<strong>提供更好的决策支持</strong>。通过本文介绍的方法论和实践，团队可以构建既能够及时发现真实问题，又避免告警雪崩的高效监控体系。</p><hr/><p><strong>📚 下篇预告</strong><br/>《压力测试方法论——目标设计、场景建模、指标评估与容量规划的完整闭环》—— 我们将深入探讨：</p><ul><li>🎯 <strong>目标制定</strong>：基于业务目标的压测场景设计与成功标准定义</li><li>📊 <strong>场景建模</strong>：真实流量模拟、异常场景构造与容量边界探测</li><li>📈 <strong>指标体系</strong>：性能基线、瓶颈识别与容量规划的数据基础</li><li>🔄 <strong>优化闭环</strong>：从性能测试到系统调优的持续改进机制</li><li>🏗️ <strong>容量规划</strong>：基于压测结果的资源预估与扩容策略</li></ul><p><strong>点击关注，掌握系统性能评估与容量规划的完整方法论！</strong></p><blockquote><p><strong>今日行动建议</strong>：</p><ol><li>评估当前监控体系的告警准确率，识别主要噪音来源</li><li>为关键服务定义明确的SLO和错误预算消耗机制</li><li>实施告警分级策略，建立基于业务影响的分级体系</li><li>配置告警抑制规则，减少重复告警和告警雪崩</li><li>建立监控效能度量机制，持续优化告警质量</li></ol></blockquote>]]></description></item><item>    <title><![CDATA[#智慧文旅#剧场演绎管理系统，让排期、票务、财务数据一键打通 智定义科技 ]]></title>    <link>https://segmentfault.com/a/1190000047559016</link>    <guid>https://segmentfault.com/a/1190000047559016</guid>    <pubDate>2026-01-22 17:11:26</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559026" alt="图片" title="图片"/></p><p>一、系统概述</p><p>    #智慧景区#剧场演绎管理系统满足剧场、剧院#票务管理业务需求，集成场地管理、剧目管理、在线售票、数据分析等多项功能，优化票务管理流程，提升观众购票体验，帮助#剧场、#剧院管理人员高效处理从演出安排到财务结算的各个环节，从而提高运营效率和服务质量。</p><p>二、产品优势</p><p>    1、功能全面覆盖：涵盖场地管理（如刷目管理、产品管理、订单管理、窗口售票）、数据报表及小程序移动端等多模块，满足剧场运营全流程需求。</p><p>    2、操作便捷高效：通过技术手段（如实时座位图、电子验票）简化传统繁琐操作，提升管理效率与用户体验。</p><p>    3、数据驱动决策：借助数据分析能力，帮助剧场实现精细化运营与科学决策，优化资源分配与市场策略。</p><p>    4、灵活适配性强：支持线上线下融合、多验票方式等，适应不同规模剧场与多样化业务场景需求。</p><p>    5、实时座位管理：提供直观的座位图显示，支持即时更新座位状态，确保座位信息准确无误，提升座位分配效率与观众体验。</p><p>    6、多渠道售票：支持线上与线下相结合的多元化售票方式，方便观众随时随地购票，拓宽销售渠道。</p><p>    7、数据分析与报告：能够生成详细的销售报告，帮助管理者分析票房趋势、观众偏好等数据，为营销策略与排期优化提供数据支撑。</p><p>    8、高效的检票与入场管理：支持通过人脸识别、电子票或二维码等多种方式快速完成检票，大幅提升入场效率，减少排队时间与人工成本。</p><p>三、系统介绍</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559027" alt="图片" title="图片" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559028" alt="图片" title="图片" loading="lazy"/></p><p>四、后台部分功能设置展示</p><p>1、场地管理</p><p>    #智慧景区#剧场演绎管理系统的场地管理功能，通过数字化手段集中管理所有剧场、舞台及座位的静态信息与实时状态，并可视化其使用档期。该功能支持与演出计划的快速排期绑定，动态监控场地设备与安全，从而实现对场地资源的高效调度与优化利用，确保演出活动顺利进行，全面提升场地运营效率。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559029" alt="图片" title="图片" loading="lazy"/></p><p>1.1、座位配置</p><p>    #智慧景区#剧场演绎管理系统的座位配置功能，通过可视化图形界面，对剧场座位进行数字化建模与灵活管理。可快速设置每个座位的类型、价格、视野属性及状态（如可售、维修、锁定）。该功能实现了座位资源与票务销售的精准联动，能根据演出需求动态调整座席布局与销售策略，从而最大化提升场地利用率和票房价值。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559030" alt="图片" title="图片" loading="lazy"/></p><p>1.2、座位信息编辑</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559031" alt="图片" title="图片" loading="lazy"/></p><p>2、剧目管理</p><p>    #智慧景区#剧场演绎管理机系统-剧目管理功能是演绎运营的核心，负责对全部演出剧目进行数字化生命周期管理。它集中维护剧目基本信息、剧本、演职人员、服化道需求及多媒体素材；支持剧目的创建、版本更新与归档。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559032" alt="图片" title="图片" loading="lazy"/></p><p>2.1.剧目场次配置</p><p>    #智慧景区#剧场演绎管理系统-剧目场次配置功能是演出计划的核心，它支持对选定剧目进行批量、快速的场次排定。操作者可灵活设置每场演出的具体时间、所用场地（厅台）、票价体系及开售状态。系统能自动校验并规避时间与场地冲突，并实时同步至票务与营销模块，确保演出计划高效、准确地落地执行。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559033" alt="图片" title="图片" loading="lazy"/></p><p>3、剧目产品管理</p><p>    #智慧景区#剧场演绎管理系统-剧目产品管理功能实现对演艺产品从创建、上架、排期到退出的全生命周期管理。核心是建立统一的数字化剧目库，详细记录剧目介绍、演职人员、票务价格、座位模板等核心信息。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559034" alt="图片" title="图片" loading="lazy"/></p><p>3.1.剧目产品配置</p><p>    #智慧景区#剧场演绎管理系统-剧目产品配置功能是演艺管理的核心，在此模块中，运营人员可快速创建新剧目，完整定义其基础信息、演出时长与特色标签；并灵活完成核心设置：包括绑定适用的演出场地、排定演出场次、制定多级票价策略，以及关联所需的演员、设备等资源。该功能实现了从剧目创意到市场售卖的一键式产品封装，为后续的票务销售与财务核算提供准确的数据基石。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559035" alt="图片" title="图片" loading="lazy"/></p><p>3.2.产品价格配置</p><p>    #智慧景区#剧场演绎管理系统-产品价格配置功能支持对演出票、套票等产品进行灵活定价。可基于场次、座位区域设定基础价格，并能针对特定渠道、节假日或促销活动设置浮动折扣与优惠规则。系统实现价格策略的自动化执行与实时同步，确保线上线下价格统一，同时动态调整库存，有效支撑收益管理及精准营销活动。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559036" alt="图片" title="图片" loading="lazy"/></p><p>4、窗口售票</p><p>    #智慧景区#剧场演绎管理系统-窗口售票功能与线上渠道数据实时互通，确保票务库存精准一致。售票员可快速查询场次、选座、出票，并灵活处理退改签。系统支持多种支付方式，并自动核销票务状态。所有操作记录清晰可溯，有效杜绝超卖错卖，在提升前台效率的同时，也为财务管理提供准确数据基础。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559037" alt="图片" title="图片" loading="lazy"/></p><p>4.1.观影人实名信息编辑</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559038" alt="图片" title="图片" loading="lazy"/></p><p>5、订单管理</p><p>    #智慧景区#剧场演绎管理系统-订单管理功能是系统的业务核心，它实现对票务订单从生成到履约完结的全生命周期管理。该功能统一处理来自各渠道的订单，自动化完成座位的锁定与释放、支持多种在线支付与核销，并实时更新订单状态（如待支付、已出票、已检、已取消）。同时，它提供订单查询、退改签审核及财务对账数据，确保每一笔交易流程清晰、高效可控。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559039" alt="图片" title="图片" loading="lazy"/></p><p>五、往届回顾</p><p>    <a href="https://segmentfault.com/a/1190000047392511" target="_blank">智慧文旅整体解决方案：赋能景区智能升级，激活全域营销势能</a></p><p>    <a href="https://segmentfault.com/a/1190000047395646" target="_blank">#数字人不止于“对话”，更在赋能千行百业</a></p><p>    <a href="https://segmentfault.com/a/1190000047414536" target="_blank">智慧文旅景区数字化中枢—“旅商通”，整合票务、二销与客流</a></p><p>    <a href="https://segmentfault.com/a/1190000047429281" target="_blank">#智慧文旅：旅政通，打通文旅数据壁垒，构建一体化运营平台</a></p><p>    <a href="https://segmentfault.com/a/1190000047448587" target="_blank">新事心办 - AI 智能大模型填报预审系统</a></p><p>    <a href="https://segmentfault.com/a/1190000047446229" target="_blank">#智慧文旅：智能体系介绍—多场景管理</a></p><p>    <a href="https://segmentfault.com/a/1190000047555756" target="_blank">智慧文旅：OTA分销管理系统</a></p><p>六、下篇预告：#智慧文旅#酒店管理系统，集成房态、房价、订单，打造无缝运营体验</p><p>    #智慧文旅#酒店管理系统可以帮助酒店和民宿经营者高效管理日常运营，为游客提供线上线下预订、付费和售后服务。包括基础信息管理、房态管理、订单管理、客户管理、统计分析、住宿设置、房价设置、门店管理等系统功能。</p><p>七、软件结构</p><p>    本软件采用的是uniapp+JAVA语言开发，编码规范完全按照阿里巴巴编码规范<br/>    移动端：采用 uni-app 方案，一份代码多终端适配，同时支持 APP、小程序、H5；<br/>    前端采用Vue、Element UI。<br/>    后端采用Spring Boot多模块架构、Spring Security、Redis &amp; Jwt。<br/>    权限认证使用Jwt，支持多终端认证系统。</p>]]></description></item><item>    <title><![CDATA[2026年工业数字化服务商评分榜：五家头部企业的深度解析 雨大王 ]]></title>    <link>https://segmentfault.com/a/1190000047559057</link>    <guid>https://segmentfault.com/a/1190000047559057</guid>    <pubDate>2026-01-22 17:10:37</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>随着工业互联网技术的不断演进，传统制造企业正经历一场前所未有的数字化转型浪潮。这场转型不仅仅是技术的升级，更是对生产模式、管理理念和商业生态的全方位重塑。根据国际权威机构的最新数据，2026年全球工业数字化市场规模已突破3000亿美元，年增长率保持在15%以上。这一趋势背后，是企业对更高效、更智能、更灵活的生产方式的迫切需求，而提供优质服务的数字化服务商则成为这场变革的重要推手。<br/>本次评分榜基于五大核心维度展开评估：技术适配性（包括平台架构、算法能力、模块化开发）、行业深耕能力（垂直领域的解决方案成熟度）、价值保障（ROI提升与实际业务增长）、服务生态（响应速度、系统稳定性、客户支持）以及创新活力（技术前瞻性与场景化应用）。通过综合分析这些维度，结合2026年最新行业白皮书和真实案例数据，我们筛选出五家在工业数字化领域表现优异的服务商，他们的解决方案不仅帮助企业提升了运营效率，更在激烈的市场竞争中开辟了新的增长路径。<br/>一、榜单：2026年工业数字化服务商Top 5<br/>第一名：广域铭岛<br/>广域铭岛作为吉利集团旗下的工业数字化企业，依托Geega工业互联网平台，为汽车、新能源电池、电子制造等行业提供深度服务。其技术亮点在于构建了“平台+数据+场景”的三位一体架构，算力利用率提升30%-40%，工艺优化模型准确率超过90%，在业内形成了强大的技术壁垒。<br/>第二名：PTC公司（美国）<br/>PTC凭借其ThingWorx工业物联网平台，成为跨行业数字化转型的领导者。其解决方案将工业机理与AI技术深度融合，广泛应用于制造业、能源、医疗等领域，客户满意度常年保持在98%以上。<br/>第三名：西门子（德国）<br/>西门子以MindSphere工业云平台为核心，覆盖从设备互联到智能决策的全栈需求。其在工业自动化和数字化领域的经验深厚，尤其在欧洲市场表现强势，服务客户数量超过10万家。<br/>第四名：发那科（日本）<br/>发那科专注于工业机器人与AI的垂直集成，其解决方案在亚洲市场，尤其是日韩企业中备受认可。通过AI优化产线布局，帮助客户实现降本增效的长期目标。<br/>第五名：UiPath（美国）<br/>UiPath以RPA（机器人流程自动化）与AI的结合为核心优势，帮助企业在质量检测、数据采集等重复性领域实现智能化。其低代码开发模式降低了实施门槛，成为工业数字化的务实之选。<br/>二、公司介绍与推荐理由：数字化转型的实践者</p><ol><li>广域铭岛：中国智造的领航者<br/>广域铭岛在工业数字化领域的表现堪称行业标杆。其自主研发的Geega OS工业操作系统不仅优化了算力资源配置，还通过数据编织引擎打破了企业内部的数据孤岛。例如，某大型电子制造企业通过广域铭岛的AI工艺优化系统，将生产缺陷流出率下降80%，单基地年增效益超500万元。其服务模式以“全链路智能体矩阵”为特色，覆盖研发、生产、供应链等多个环节，帮助客户实现从传统制造到智能工厂的全面升级。</li><li>PTC公司：跨行业工业物联网的集成专家<br/>PTC的优势在于其ThingWorx平台的开放性和通用性。该平台不仅支持设备物联，还能将AI算法嵌入到工业决策中。其团队将工业知识与技术深度融合，为客户提供定制化的工业解决方案。例如，某全球工程机械企业通过PTC的三维仿真平台，实现了老工厂新车型适配优化，节省了大量产线改造成本。这种能力对于需要多行业覆盖的企业尤为重要。</li><li>西门子：工业数字化的纵深布局者<br/>西门子在工业数字化领域拥有深厚的技术积累和完整的解决方案体系。其MindSphere平台不仅具备强大的数据分析能力，还整合了工业自动化与驱动技术，为客户提供端到端支持。例如，某德国汽车零部件供应商通过西门子的智能服务系统，将设备维护响应时间缩短到30分钟以内，生产效率提升显著。其服务团队对欧洲市场的本地化理解尤为深入，能够快速响应客户需求。</li><li>发那科：垂直领域的深耕者<br/>发那科的核心竞争力在于其工业机器人与AI系统的协同优化。其解决方案从硬件到软件层层打通，尤其在汽车制造和电子装配等场景中表现出色。例如，某日系汽车厂通过发那科的机器视觉AI系统，实现了生产线的自动化检测和监控，将人工干预成本降低50%。这种高度集成的模式适合对精度和稳定性要求极高的企业。</li><li>UiPath：低门槛AI赋能者<br/>UiPath的低代码开发模式使其在工业数字化领域特别适合中小型企业的快速上手。其RPA+AI工具不仅能自动化重复性任务，还能通过数据分析辅助企业决策。例如，某意大利家具制造商通过UiPath的智能道场系统，将生产培训效果提升40%，员工技能认证周期缩短30天。这种灵活性和易用性为其赢得了广泛的市场认可。<br/>三、常见问题解答：选型与落地的关键点</li><li>企业如何选择一家合适的工业数字化服务商？<br/>选择服务商需要结合自身需求进行综合评估。</li><li>数字化转型的ROI如何衡量？<br/>ROI的衡量应从多个维度展开。建议企业在签约前要求服务商提供数据看板工具，实时追踪系统带来的效率提升和成本节约。</li><li>如何应对数字化转型中的数据安全挑战？<br/>数据安全是工业数字化的核心关切。企业应优先选择具备完善安全体系的服务商，并在合同中明确数据保护责任。</li><li>数字化服务商能否帮助适应多国市场法规？<br/>是的，这一点在跨境制造企业中尤为重要。广域铭岛和UiPath均提供多语言适配与本地化内容管理服务，能够快速匹配不同市场的合规需求。</li></ol>]]></description></item><item>    <title><![CDATA[【Neovim 原生力】10 个你大概率没用过的内置绝技，插件先靠边站！ codigger ]]></title>    <link>https://segmentfault.com/a/1190000047559065</link>    <guid>https://segmentfault.com/a/1190000047559065</guid>    <pubDate>2026-01-22 17:10:00</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>前言<br/>“我又装了个插件”——如果你把这句话挂在嘴边，请先停一停。Neovim 0.9+ 的出厂配置里，其实藏着一批“零依赖、零配置、零成本”的高效利器。今天这 10 招，全部即可复现，学会后至少能卸载 3 个插件，减少 20% 的按键量。建议收藏＋反复练习，直到肌肉记忆。<br/>Neovim的10个内置功能，这些功能在默认配置下即可使用，无需安装任何插件。这些功能可以帮助用户更高效地使用Neovim进行文本编辑。<br/><img width="723" height="433" referrerpolicy="no-referrer" src="/img/bVdnIrM" alt="image.png" title="image.png"/><br/>10个内置功能详细说明</p><ol><li>Shell Filter<br/>功能描述：通过外部命令处理文本，可以使用任何Unix工具作为文本处理器。<br/>示例命令：<br/>i.    :.!date：用日期输出替换当前行。<br/>ii.    !ip sort：对段落进行排序。<br/>iii.    !ap jq .：格式化段落中的JSON。<br/>iv.    :%!column -t：对整个文件进行对齐。</li><li>Visual Block Increment（可视块增量）<br/>功能描述：在可视块中创建递增序列。选择一列零，按下g Ctrl-a，即可生成即时编号列表。</li><li>Global Command（全局命令）<br/>功能描述：在所有匹配的行上运行Ex命令，进行批量操作。<br/>示例命令：<br/>i.    :g/TODO/d：删除所有包含“TODO”的行。<br/>ii.    :g/^$/d：删除所有空行。<br/>iii.    :g/error/t$：将包含“error”的行复制到文件末尾。<br/>iv.    :g/func/norm A;：在所有函数末尾添加分号。<br/><img width="723" height="433" referrerpolicy="no-referrer" src="/img/bVdnIrN" alt="image.png" title="image.png" loading="lazy"/></li><li>Command-line Registers（命令行寄存器）<br/>功能描述：在:或/提示符中插入寄存器内容。<br/>快捷键及功能：<br/>i.    Ctrl-r Ctrl-w：插入光标下的单词。<br/>ii.    Ctrl-r "：插入上次剪切的内容。<br/>iii.    Ctrl-r /：插入上次搜索模式。<br/>iv.    Ctrl-r =：插入表达式结果。</li><li>Normal on Selection（在选择上运行正常模式命令）<br/>功能描述：在每行选中的文本上运行正常模式命令，实现类似多光标的操作。<br/>示例命令：<br/>i.    :'&lt;,'&gt;norm A,：在每行末尾添加逗号。<br/>ii.    :'&lt;,'&gt;norm I#：在每行开头添加#。<br/>iii.    :'&lt;,'&gt;norm @q：在每行上运行宏。</li><li>The g Commands（g命令）<br/>功能描述：提供一系列以g开头的快捷命令。<br/>命令及功能：<br/>i.    gi：跳转到最后一次插入位置并进入插入模式。<br/>ii.    g;：跳转到上一次更改的位置。<br/>iii.    g,：跳转到下一次更改的位置。<br/>iv.    gv：重新选择上次的可视选择。<br/><img width="723" height="433" referrerpolicy="no-referrer" src="/img/bVdnIrO" alt="image.png" title="image.png" loading="lazy"/></li><li>Auto-Marks（自动标记）<br/>功能描述：Vim会自动跟踪一些位置。<br/>标记及功能：<br/>i.    ：跳转到上一个位置（可以来回切换）。复制<br/>ii.    <code>`.</code>：跳转到最后一次更改的位置。<br/>iii.    "：跳转到文件上次关闭时的位置。<br/>iv.    [/]：跳转到上次剪切或更改的开始/结束位置。</li><li>Command History Window（命令历史窗口）<br/>功能描述：在缓冲区中显示可编辑的命令历史。q:打开命令历史窗口，q/打开搜索历史窗口。可以在其中编辑任何行，按下Enter执行。</li><li><p>Live Substitution Preview（实时替换预览）<br/>功能描述：在执行替换之前查看替换结果。将以下内容添加到配置文件中：vim.opt.inccommand = "split"。<br/><img width="723" height="433" referrerpolicy="no-referrer" src="/img/bVdnIrQ" alt="image.png" title="image.png" loading="lazy"/></p><ol start="10"><li>Copy/Move Lines（复制/移动行）</li></ol><p>功能描述：无需接触寄存器即可复制或移动行。<br/>命令及功能：<br/>i.    :t.：将当前行复制到下方。<br/>ii.    :t0：将当前行复制到文件顶部。<br/>iii.    :m+2：将当前行移动到下方两行。<br/>iv.    :'&lt;,'&gt;t.：将选中的内容复制到下方。<br/>这些功能的文本版本，链接为：<a href="https://link.segmentfault.com/?enc=sAL4qwnWVf9dwTTinicbGg%3D%3D.6F0wJzBVCttt35ZOHDdCPL5DwSY54cheMfdwulJwb2NrDS2GHymeaxii%2FbKRg8FZj29JHJ1MIqteRE6mGLlExvf%2BG95wbEErAhgMA7NZdJU%3D" rel="nofollow" target="_blank">https://github.com/Piotr1215/youtube/blob/main/10-nvim-tricks/presentation.md</a><br/>配置文件可以在以下链接中找到：<br/><a href="https://link.segmentfault.com/?enc=pTv%2Ba5Onim6eR66BdNKe3Q%3D%3D.hbCU61Rw1xF%2BpjzptNw5lthIEBlEHqQbhuLYgT8%2FfUQy1EkzPFpadsR9Ml1SPwhD" rel="nofollow" target="_blank">https://github.com/Piotr1215/dotfiles</a><br/>Neovim 的“原生力”远远被低估。把内置招式练到条件反射，再决定是否上插件，你会发现——<br/>“插件是锦上添花，而不是救命稻草。”<br/>如果本文对你有帮助，记得点赞＋评论＋关注，Codigger是一款基于Vim开发的项目，欢迎喜欢Vimming的伙伴们一起来玩。</p></li></ol>]]></description></item><item>    <title><![CDATA[Kite：Kotlin/Java 通用的全自动 ORM 框架 tangllty ]]></title>    <link>https://segmentfault.com/a/1190000047559067</link>    <guid>https://segmentfault.com/a/1190000047559067</guid>    <pubDate>2026-01-22 17:09:28</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>Kite：Kotlin/Java 通用的全自动 ORM 框架</h2><p>Kite 是一个高效的轻量级 ORM 框架，基于 Kotlin 编写，开箱即用，内置分页查询、增删改查等常用功能，支持多表操作。它支持 PostgreSQL、MySQL、Derby 等多种数据库，旨在通过简化数据库操作，减少代码量，提升开发效率。</p><h3>框架特点</h3><ul><li><strong>全自动映射</strong>：无需手动编写 SQL，Kite 会自动根据实体类生成相应的数据库操作语句</li><li><strong>支持自定义 SQL</strong>：在需要时，可以编写自定义 SQL 语句，满足复杂查询需求，还可以像写代码一样写流程控制语句</li><li><strong>多数据库支持</strong>：支持 PostgreSQL、MySQL、Derby 等主流关系型数据库</li><li><strong>Kotlin/Java 双语言支持</strong>：既可以在 Kotlin 项目中使用，也可以在 Java 项目中无缝集成</li><li><strong>轻量级设计</strong>：无过多依赖，性能优秀</li><li><strong>丰富的 API</strong>：提供简洁直观的 API，支持各种复杂查询和操作</li><li><strong>Spring Boot 集成</strong>：提供 Spring Boot Starter，便于在 Spring Boot 项目中快速集成</li></ul><h3>使用方法（Spring Boot 集成示例）</h3><blockquote>Maven 中央仓库: <a href="https://link.segmentfault.com/?enc=XFC%2Fi%2BL6N2bXviIRm44OdQ%3D%3D.mG2X2%2BIzA%2BnfIt9CoJbWHaFtl1KAcwSctspgxNgSoDe7hvoqCvQ6WjaAO8EEU65hoV4bUEDW%2BNRVb4%2FuXUxJhI%2FhQmyn9yPnvOd2UGM78sutNUAOY4qRGxlIx0v%2BoZet" rel="nofollow" target="_blank">kite-spring-boot-starter</a></blockquote><ol><li>向项目添加以下依赖：</li></ol><ul><li>Maven</li></ul><pre><code class="xml">&lt;dependency&gt;
   &lt;groupId&gt;io.github.tangllty&lt;/groupId&gt;
   &lt;artifactId&gt;kite-spring-boot-starter&lt;/artifactId&gt;
   &lt;version&gt;${kite.version}&lt;/version&gt;
&lt;/dependency&gt;</code></pre><ul><li>Gradle</li></ul><pre><code class="kts">implementation("io.github.tangllty:kite-spring-boot-starter:${kite.version}")</code></pre><ol start="2"><li>在数据库中创建表</li></ol><blockquote>使用 MySQL 演示</blockquote><pre><code class="sql">create table account (
  id          bigint not null auto_increment,
  username    varchar(32)     default '',
  password    varchar(32)     default '',
  balance     decimal(10,2)   default '0.00',
  create_time datetime        default null,
  update_time datetime        default null,
  primary key (`id`)
);

insert into account (username, password, create_time, balance) values
('admin', 'admin123', '2020-01-01 12:00:00', 1000.10),
('user', 'user123', '2024-05-02 8:30:00', 101.00),
('guest', 'guest123', '2022-03-03 15:00:00', 10.00),
('tang', 'tang123', '2019-06-01 21:30:30', 1.88),
('jeo', 'jeo123', '2024-07-01 5:59:59', 0.10);</code></pre><ol start="3"><li>在 <code>application.yml</code> 文件中配置数据库连接信息</li></ol><pre><code class="yaml">spring:
  datasource:
    driver-class-name: com.mysql.cj.jdbc.Driver
    url: jdbc:mysql://127.0.0.1:3306/kite-test
    username: root
    password: password</code></pre><ol start="4"><li>为 <code>account</code> 表创建模型类</li></ol><ul><li>Java</li></ul><pre><code class="java">import com.tang.kite.annotation.id.Id;
import com.tang.kite.annotation.id.IdType;
import java.math.BigDecimal;
import java.time.LocalDateTime;

public class Account {

    @Id(type = IdType.AUTO)
    private Long id;
    private String username;
    private String password;
    private BigDecimal balance;
    private LocalDateTime createTime;
    private LocalDateTime updateTime;

    // Getters and Setters
}</code></pre><ul><li>Kotlin</li></ul><pre><code class="kotlin">import com.tang.kite.annotation.id.Id
import com.tang.kite.annotation.id.IdType
import java.math.BigDecimal
import java.time.LocalDateTime

class Account (

    @Id(type = IdType.AUTO)
    var id: Long? = null,
    var username: String? = null,
    var password: String? = null,
    var balance: BigDecimal? = null,
    var createTime: LocalDateTime? = null,
    var updateTime: LocalDateTime? = null

)</code></pre><ol start="5"><li>继承 <code>BaseMapper</code> 接口创建 Mapper 接口</li></ol><ul><li>Java</li></ul><pre><code class="java">import com.tang.kite.mapper.BaseMapper;
import com.tang.kite.spring.annotation.Mapper;

@Mapper
public interface AccountMapper extends BaseMapper&lt;Account&gt; {
}</code></pre><ul><li>Kotlin</li></ul><pre><code class="kotlin">import com.tang.kite.mapper.BaseMapper
import com.tang.kite.spring.annotation.Mapper

@Mapper
interface AccountMapper : BaseMapper&lt;Account&gt;</code></pre><ol start="6"><li>在 Spring Boot 应用类上添加 <code>@MapperScan</code> 注解</li></ol><ul><li>Java</li></ul><pre><code class="java">import com.tang.kite.spring.annotation.MapperScan;
import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;

@MapperScan("com.tang.application.mapper")
@SpringBootApplication
public class KiteApplication {

    public static void main(String[] args) {
        SpringApplication.run(KiteApplication.class, args);
    }

}</code></pre><ul><li>Kotlin</li></ul><pre><code class="kotlin">import com.tang.kite.spring.annotation.MapperScan
import org.springframework.boot.autoconfigure.SpringBootApplication
import org.springframework.boot.runApplication

@MapperScan(["com.tang.application.mapper"])
@SpringBootApplication
class KiteApplication

fun main(args: Array&lt;String&gt;) {
    runApplication&lt;KiteApplication&gt;(*args)
}</code></pre><ol start="7"><li>测试 Mapper 接口</li></ol><ul><li>Java</li></ul><pre><code class="java">import com.tang.demo.mapper.AccountMapper;
import com.tang.kite.spring.annotation.MapperScan;
import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;

@MapperScan("com.tang.application.mapper")
@SpringBootApplication
public class KiteApplication {

    public static void main(String[] args) {
        var context = SpringApplication.run(KiteApplication.class, args);
        var accountMapper = context.getBean(AccountMapper.class);
        var accounts = accountMapper.select();
        accounts.forEach(System.out::println);
    }

}</code></pre><ul><li>Kotlin</li></ul><pre><code class="kotlin">import com.tang.demo.mapper.AccountMapper
import com.tang.kite.spring.annotation.MapperScan
import org.springframework.boot.autoconfigure.SpringBootApplication
import org.springframework.boot.runApplication

@MapperScan(["com.tang.application.mapper"])
@SpringBootApplication
class KiteApplication

fun main(args: Array&lt;String&gt;) {
    val context = runApplication&lt;KiteApplication&gt;(*args)
    val accountMapper = context.getBean(AccountMapper::class.java)
    val accounts = accountMapper.select()
    accounts.forEach { println(it) }
}</code></pre><h3>文档与社区</h3><h4>官方文档</h4><p>详细的使用文档请参考：</p><ul><li><a href="https://link.segmentfault.com/?enc=25OrR%2BJizDpKJFxsg%2F45wg%3D%3D.%2FHYM239%2B%2FOQEpgRfkl3Vk0c9A71p1T71%2FbFZGP32vABDezq9mnZ%2B0nulpU%2F%2FhilAXeevEsxVmfXaJ4f5FCcNOA%3D%3D" rel="nofollow" target="_blank">中文文档</a></li><li><a href="https://link.segmentfault.com/?enc=h3nhq6bxK%2FhbyppmdPVxUg%3D%3D.IkJoa4rXFp3pGCcP3igsLDdth2aePF5p179ArdNrEqDjifYE%2ByH1I4UnGi12rS7d" rel="nofollow" target="_blank">英文文档</a></li></ul><h3>源码</h3><p>Kite 的源码托管在 GitHub 和 Gitee 上，您可以在以下地址查看和贡献：</p><ul><li><a href="https://link.segmentfault.com/?enc=ATs5weVK%2FpS070q%2B6vPMWA%3D%3D.dJk6NKEBbIEa2Z1kxTn8qbWzvdiJG0j751WDtJkIpP9YFrlL6xLlkmPPRc36Eupa" rel="nofollow" target="_blank">Kite GitHub 仓库</a></li><li><a href="https://link.segmentfault.com/?enc=3%2FwWy%2Bel9icVRYyHAzmdvg%3D%3D.DlhmDPVwFa%2Fe8pZUDLrwNWW77SlaIWAZS5t52ZxpZSo%3D" rel="nofollow" target="_blank">Kite Gitee 仓库</a></li></ul><h3>总结</h3><p>Kite 是一个功能强大、易于使用的 ORM 框架，它通过全自动映射和简洁的 API，大大简化了数据库操作的开发工作。无论是在 Kotlin 项目还是 Java 项目中，都能提供高效、便捷的数据库访问体验。</p><p>如果您正在寻找一个轻量级、高性能的 ORM 框架，Kite 绝对值得一试！</p>]]></description></item><item>    <title><![CDATA[告别复制粘贴，你需要这8个 MCP 服务器 烦恼的沙发 ]]></title>    <link>https://segmentfault.com/a/1190000047559072</link>    <guid>https://segmentfault.com/a/1190000047559072</guid>    <pubDate>2026-01-22 17:08:35</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在使用 AI 辅助编程的早期，由于 AI 无法直接感知我们的开发环境，我们不得不充当搬运工，把报错信息复制出来，把数据库结构截个图，把 API 文档一段段喂给它。这种断裂的交互方式，效率很低。</p><p>MCP（Model Context Protocol）协议的出现解决了这个问题。它为 AI 提供了一个标准化的接口，让 AI 能够直接读取代码库、数据库、浏览器甚至知识库。AI 不再是一个在那自言自语的聊天机器人，而变成了真正能上手干活的工程师。</p><p>今天盘点几款目前非常实用的 MCP Server，看看它们如何具体解决开发中的痛点。</p><h3><a href="https://link.segmentfault.com/?enc=3QmancjNcqm%2FzLdpTjhC4g%3D%3D.6pX0TzwibCMmrHPfq6v3jzkzHWT2X6BdWcDAE8vm2kQ%3D" rel="nofollow" target="_blank">Browser MCP</a>：给 IDE 装上联网的眼睛</h3><p><img width="723" height="457" referrerpolicy="no-referrer" src="/img/bVdnIsP" alt="image.png" title="image.png"/></p><p>开发过程中遇到生僻报错，或者需要查阅最新的第三方库文档，一般会切出 IDE，打开浏览器，搜索，筛选答案，再切回 IDE。这个过程不仅繁琐，注意力还容易被分散。</p><p>Browser MCP 就能让 AI 拥有了直接访问互联网的能力。如果遇到类似 <code>TypeError</code> 或者配置问题时，不需要离开代码编辑器，直接下指令让 AI 去查。</p><p>它会自动检索 Stack Overflow 的高票回答，或者抓取 GitHub 上的 Issue 讨论，甚至直接阅读最新的官方文档，然后把过滤后的有效信息反馈给开发者。</p><p><strong>配置参考：</strong></p><pre><code class="json">{
  "mcpServers": {
    "browser": {
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-browser"]
    }
  }
}</code></pre><h3><a href="https://link.segmentfault.com/?enc=3mXoxla%2BciBqgqf%2FKFsJrA%3D%3D.2pEKINuMTpNsmSF0D1UXYZMw%2FZiSTfAMw2cQS0gw0ti0YsqcxK2BgA%2FOtLGFRrBs" rel="nofollow" target="_blank">Notion MCP</a>：打通项目知识库</h3><p><img width="723" height="281" referrerpolicy="no-referrer" src="/img/bVdnItm" alt="image.png" title="image.png" loading="lazy"/></p><p>在复杂的项目中，需求文档、API 定义、设计规范通常散落在 Notion 里。以前写代码需要反复确认文档细节，现在可以通过 Notion MCP 把这些知识库直接挂载给 AI。</p><p>用户就可以直接问：“根据产品文档里的用户积分规则，帮我生成这段计算逻辑。”AI 会直接读取 Notion 中的页面内容作为上下文。这让代码实现与需求文档保持了高度一致，省去了反复核对的时间。</p><h3><a href="https://link.segmentfault.com/?enc=nKxO1KxkQVsXLIrrLaxipw%3D%3D.mWr%2F822rEzga%2FQiEnl7u%2BCeO7qU1iGQ9cj9WNq0TFU0%3D" rel="nofollow" target="_blank">Vanna.ai Agent Server</a>：用自然语言操作数据库</h3><p><img width="723" height="384" referrerpolicy="no-referrer" src="/img/bVdnItn" alt="image.png" title="image.png" loading="lazy"/></p><p>对于不擅长复杂 SQL 或者刚接手陌生数据库结构的开发者，Vanna.ai 就是个神器。它的特长是 Text-to-SQL。</p><p>接入后，AI 能够理解数据库的 Schema（表结构）。开发者不需要手写复杂的 Join 查询，只需要说“帮我统计上个季度复购率最高的前十个用户”，它就能直接生成准确且可执行的 SQL 语句。这在做数据分析或快速验证数据时非常高效。</p><h3><a href="https://link.segmentfault.com/?enc=hdZzVlEINr95NFj1Ujfgdg%3D%3D.wo%2FFfq6Kq0eRZfFkvKwSk%2BHmXOUoFnSFCRKqMHVtfFB1pMBKKwne%2BPmOX8CzjlNQVnOOZAZTtqHG%2FIoSsozodg%3D%3D" rel="nofollow" target="_blank">Vibe Check MCP</a>：代码质量的守门员</h3><p><img width="600" height="346" referrerpolicy="no-referrer" src="/img/bVdnItp" alt="image.png" title="image.png" loading="lazy"/></p><p>很多代码可以跑通，但跑通并不代表着一点问题都没有，还会有很多隐患，比如变量命名随意、缺乏边界情况的错误处理、逻辑嵌套过深。</p><p>Vibe Check MCP 不仅仅是一个语法检查器，它更像是一个经验丰富的 Code Reviewer。写完一段业务逻辑后，可以让它扫描一遍。它会敏锐地指出那些“虽然不报错但很业余”的地方，把潜在的技术债务扼杀在摇篮里。</p><p><strong>配置参考：</strong></p><pre><code class="json">{
  "mcpServers": {
    "vibe-check": {
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-vibe-check"]
    }
  }
}</code></pre><h3><a href="https://link.segmentfault.com/?enc=QwywRwrvcyywSkHkUZ%2BRSg%3D%3D.MQ3ofaQR6xsxJBST32qBnIWXE8k2s0aO8TX4B9qyjs0iTLZEcyj46sPQ0e%2FvtWgA" rel="nofollow" target="_blank">Bright Data MCP</a>：工业级数据获取</h3><p><img width="723" height="375" referrerpolicy="no-referrer" src="/img/bVdnItq" alt="image.png" title="image.png" loading="lazy"/></p><p>当开发涉及外部数据采集、竞品分析或需要处理大量网页数据时，普通的爬虫脚本很容易被反爬策略阻断。</p><p>Bright Data MCP 提供了一个更稳定的接口。它利用 Bright Data 的代理网络和抓取架构，让 AI 能够稳定地获取外部网页数据。对于需要构建数据集或实时监控外部信息的应用，这是一个非常结实的底层支撑。</p><h3><a href="https://link.segmentfault.com/?enc=BS8jU2PdS8C15wrTIjdsoA%3D%3D.RbVSe8KtH5K99qymDhRMRARKg0nnQhrJ39hY8Frk%2BjQ%3D" rel="nofollow" target="_blank">Honeycomb MCP</a>：生产环境的可观测性</h3><p><img width="696" height="364" referrerpolicy="no-referrer" src="/img/bVdnItr" alt="image.png" title="image.png" loading="lazy"/></p><p>代码上线后出了 Bug，最头疼的是定位问题。Honeycomb MCP 把 AI 的能力引入到了运维监控领域。</p><p>通过连接 Honeycomb 的 Tracing 数据，当系统报警时，可以让 AI 直接分析链路追踪日志。它能协助判断是哪个微服务超时，还是哪个数据库查询导致了瓶颈，直接给出基于真实数据的分析建议，而不是盲目猜测。</p><h3><a href="https://link.segmentfault.com/?enc=aspsZiQMEzeOxN6%2BcOgbQw%3D%3D.epMlvWU%2BvwsXuh9FlLuuQRS5Ja%2BxJ82TfMF8qYmHEws%3D" rel="nofollow" target="_blank">LangChain Server</a>：构建 AI 工作流</h3><p><img width="723" height="545" referrerpolicy="no-referrer" src="/img/bVdnIts" alt="image.png" title="image.png" loading="lazy"/></p><p>如果你的目标不仅仅是辅助编码，而是要开发 AI 应用，LangChain Server 必不可少。它提供了丰富的组件来编排 LLM 的逻辑，处理 Prompt 模板、记忆管理和工具调用。通过 MCP 接入，可以在 IDE 里更直观地调试和构建复杂的 AI 业务流程。</p><h3><a href="https://link.segmentfault.com/?enc=OcuSeh9aTvQeY11gso38fA%3D%3D.Ukhc0mZjHNX9NbdeONPNoNY%2Ft5w4dHda8S0%2Bs%2FKU6OuD1%2B%2FR6PFCT826pFo7LOKCB91YRN%2Fb4W8Sh4Hc5sF4zw%3D%3D" rel="nofollow" target="_blank">OpenAgents MCP</a>：数据分析与自主任务</h3><p><img width="723" height="295" referrerpolicy="no-referrer" src="/img/bVdnItt" alt="image.png" title="image.png" loading="lazy"/></p><p>OpenAgents 更侧重于数据分析和工具的自主使用。如果你手头有一个 CSV 文件需要分析，或者需要进行一系列的数据清洗和图表绘制任务，OpenAgents 可以规划任务路径，自主调用工具来完成从数据处理到结果可视化的全过程。</p><ul><li><ul><li>*</li></ul></li></ul><h3>搞定 MCP 的运行基石：Node.js 环境管理</h3><p>仔细观察上述的 MCP 配置，就会发现它们几乎都依赖 <code>npx</code> 命令，这意味着背后都需要 <a href="https://link.segmentfault.com/?enc=ja5RjQTz%2FqmGMr2dFM8RfQ%3D%3D.ahhXTc1kBzlt2nbxY6jE%2BG70DU7CGh925wkbMmaQ6hKDi%2Bqin9%2Bl9WtR74I85PHF" rel="nofollow" target="_blank">Node.js 环境</a>的支持。而且不同的 MCP 工具可能依赖不同版本的 Node.js。</p><p>在本地机器上反复切换 Node 版本，或者处理全局依赖冲突，是非常消磨热情的。</p><p>ServBay 提供了一个解决方案。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559082" alt="" title="" loading="lazy"/></p><p>作为一款专为开发者设计的环境管理工具，ServBay 在 Node.js 的支持上做得非常细致：</p><ul><li><strong>版本覆盖全</strong>：它支持从 <strong>Node.js 12 到 Node.js 24</strong> 的全系列版本。无论想跑最新的 MCP 工具，还是维护老旧的项目，都能找到对应的运行环境。</li><li><strong>多版本共存</strong>：这个功能挺实用的。开发者可以在 ServBay 里同时安装 Node 18 和 Node 22。运行不同的项目时，可以指定使用不同的 Node 版本，互不打架。</li><li><strong>系统纯净</strong>：ServBay 采用沙盒化机制，所有的 Node 环境都独立于系统之外。不需要担心因为安装一个 MCP 工具而把系统的 PATH 变量搞乱，也不需要在那折腾 nvm 的配置。</li></ul><p>对于非技术人员，ServBay 也是很友好的，不需要会写代码，点击一下就能安装好各种MCP 服务器。</p><h3>结语</h3><p>MCP 协议正在重塑我们与开发工具的交互方式。从 Browser MCP 的联网能力，到 Vibe Check 的代码审查，都是与一个真正懂行的 AI 结对编程。配置好这些工具，把繁琐的上下文搬运工作交给协议，留出更多的时间去思考架构与逻辑。</p>]]></description></item>  </channel></rss>