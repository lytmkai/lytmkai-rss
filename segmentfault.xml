<?xml version="1.0" encoding="UTF-8"?><rss version="2.0">  <channel>      <title>SegmentFault - 最近文章</title>      <link>https://segmentfault.com/blogs/newest</link>      <description>SegmentFault 思否</description>      <generator>python segmentfault.py @Pi20</generator>      <item>    <title><![CDATA[《联机游戏多端通联进阶指南：逻辑协同与体]]></title>    <link>https://segmentfault.com/a/1190000047420797</link>    <guid>https://segmentfault.com/a/1190000047420797</guid>    <pubDate>2025-11-22 23:02:00</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在联机游戏的开发语境中，协同逻辑的隐性错位往往藏在跨端交互的细微链路里，它不是显性的功能失效，而是在玩家操作与数据反馈之间形成的无形滞涩，这种滞涩会随着联机人数的增加、场景复杂度的提升逐渐放大，最终影响整体体验的流畅度。这种现象如同精密仪器中未完全咬合的齿轮，每个部件单独运行时看似无虞，一旦进入协同状态，就会因微小的偏差产生连锁反应—比如玩家释放技能的指令已发出，却在其他玩家的视角中延迟出现；或者多端加载的场景道具在空间位置上出现毫米级偏差，长期积累后导致后续交互逻辑错乱。想要精准校准这种隐性错位，不能依赖零散的局部调整，而需要建立一套贯穿数据传输、状态同步、场景适配的完整逻辑体系，从根源上梳理清楚每个环节的交互原理，找到那些容易被忽略的逻辑断点。在长期的开发实践中，这种校准工作更像是一种对“协同语言”的统一，开发者需要深入理解不同模块的运行机制，让不同设备、不同网络环境下的游戏进程，能够基于同一套底层逻辑完成高效沟通。这要求开发者跳出单一功能的视角，以全局协同的思维审视每一处细节，既要考虑单个逻辑单元的稳定性，也要兼顾多个单元交互时的兼容性，甚至需要预判玩家可能出现的极端操作场景，提前做好逻辑适配，让协同机制能够在各种复杂情况下保持精准运行。</p><p>网络环境的动态波动是联机游戏协同逻辑面临的核心挑战之一，不同玩家的网络带宽、延迟、稳定性存在天然差异，如何在这种差异中保持逻辑的一致性，是校准工作的关键命题。在实践中，我们首先需要建立动态感知机制，实时捕捉网络状态的变化趋势，而不是简单监测即时数值—这种趋势性感知能够提前预判可能出现的通联波动，比如通过滑动窗口算法分析近30秒内的延迟数据，若发现延迟呈现持续上升趋势，系统会自动启动时序补偿策略，而非等到延迟超过阈值才采取行动。具体来说，时序补偿会通过调整数据发送的优先级，将玩家的移动、攻击等核心操作指令标记为最高优先级，减少非关键信息（如场景背景音效、次要道具的光影效果）的传输占用，确保核心指令能够优先抵达服务器并得到反馈。同时，针对弱网环境下的数据丢失问题，我们采用分层校验的方式，将核心交互数据与辅助渲染数据进行明确区分：核心数据采用多通道备份传输，即使某一通道数据丢失，也能通过其他通道快速补全；辅助数据则通过算法实时补全，比如根据场景规律推测缺失的光影参数，既保证了关键逻辑的稳定性，又避免了过度冗余传输导致的带宽压力。这种基于网络状态动态适配的思路，核心在于“灵活变通”，不追求绝对统一的传输标准，而是根据实际环境调整逻辑适配策略—比如在5G网络环境下，可提升同步频率以保证体验流畅；在4G或WiFi环境下，则适当降低同步频率，通过算法优化弥补延迟带来的感知差异，让协同机制能够在复杂的网络条件下保持弹性。</p><p>多端设备的硬件差异与系统特性，容易造成协同逻辑的适配偏差，这种偏差看似是表现层的差异，实则源于底层逻辑对设备特性的兼容不足。在处理这类问题时，我们需要建立“特性映射库”，将不同设备的硬件性能（如处理器运算速度、内存容量、显卡渲染能力）、系统响应机制（如进程调度优先级、内存管理方式）、交互方式（如触屏操作与键鼠操作的响应延迟差异）等核心特性进行分类梳理，然后针对每类特性制定对应的逻辑适配规则。例如，高性能PC设备能够支持每秒60次以上的状态同步，而中低端移动端设备则需要将同步频率调整至30次/秒，同时通过简化状态计算模型、优化渲染管线等方式，减少状态同步对设备资源的消耗，确保两端在不同的同步节奏下依然能够保持逻辑一致。对于系统层面的差异，比如iOS与Android的进程调度机制不同—iOS对后台进程的限制更为严格，而Android的内存管理更依赖手动回收，我们采用“核心逻辑剥离”的策略，将与系统强相关的交互逻辑（如权限申请、后台运行处理）独立封装，通过接口适配层实现与核心协同逻辑的解耦。这样一来，当针对不同系统进行适配时，只需修改接口适配层的代码，无需改动核心逻辑，既保证了核心逻辑的稳定性，又降低了适配成本。在实践过程中，这种适配工作需要反复测试验证，不仅要覆盖主流设备与系统，还要关注边缘场景下的适配效果—比如老旧安卓设备的运行状态，其内存容量较小，容易出现内存溢出导致的逻辑卡顿，此时需要针对性地优化内存占用，减少不必要的缓存数据；小众系统的兼容表现也不能忽视，通过建立适配测试矩阵，覆盖不同品牌、不同配置的设备，确保协同逻辑能够跨越设备与系统的壁垒，实现无缝衔接。</p><p>动态负载场景下的资源调度失衡，是导致协同逻辑出现波动的重要诱因，当联机场景中玩家数量骤增、场景元素密度加大时，传统的固定资源分配模式会导致部分链路出现拥堵，进而引发逻辑响应延迟。针对这一问题，我们构建了“智能资源池”机制，根据场景复杂度、玩家分布、交互频率等多维度数据，动态调整资源分配比例，让核心协同链路能够获得优先资源保障。具体来说，资源池会实时收集场景中的关键数据：比如玩家集中区域的交互频率（如战斗场景中每秒的技能释放次数、攻击指令数量）、场景元素的加载数量（如道具、NPC、特效的总数）、服务器的CPU与内存占用情况等，然后通过权重计算模型，将更多的计算资源、带宽资源分配给核心协同逻辑。例如，在玩家集中的战斗场景中，系统会自动增加状态同步、指令传输的资源配额，减少非战斗区域的资源占用；而当场景中玩家分散行动时，则会动态均衡资源分配，避免局部资源浪费。同时，我们引入“预加载预判”逻辑，根据玩家的行动轨迹、场景切换指令，提前预判可能需要加载的资源与触发的协同逻辑—比如通过分析玩家的移动方向，预判其即将进入的新场景，提前在后台加载该场景的核心资源，并初始化协同逻辑所需的基础数据，减少场景切换或突发交互时的响应延迟。这种动态资源调度的核心在于“按需分配”，打破固定资源分配的僵化模式，让资源能够随着场景与玩家行为的变化灵活流动。此外，我们还设计了资源池的扩容与收缩机制，当场景负载达到预设阈值时，自动启动资源扩容，临时调用备用服务器资源；当负载降低后，及时收缩资源，避免资源闲置，为协同逻辑的稳定运行提供坚实的资源支撑。</p><p>跨场景切换过程中的状态延续性保障，是联机游戏协同逻辑的一大难点，场景切换时的加载延迟、数据传输中断，容易导致玩家状态丢失、协同关系断裂，破坏游戏体验的连贯性。为解决这一问题，我们设计了“状态快照+增量同步”的组合方案，在玩家触发场景切换指令时，系统会快速生成当前玩家的完整状态快照，包括位置信息、属性数据（如生命值、能量值、装备状态）、交互关系（如组队信息、好友列表、任务进度）等核心内容，同时将快照数据同步至目标场景的预处理模块。在场景加载过程中，预处理模块会基于快照数据提前构建玩家的初始状态，比如在新场景中还原玩家的位置、属性数值，初始化组队协同所需的逻辑链路，待场景加载完成后，再通过增量同步的方式，补充场景切换期间产生的状态变化数据—比如其他玩家发送的组队邀请、系统触发的任务更新等，确保玩家在新场景中的状态能够与之前无缝衔接。此外，针对多玩家同时切换场景的情况，我们采用“时序协调”机制，根据玩家的切换指令发送时间、网络状态，合理安排场景加载与数据同步的顺序，避免因多玩家同时请求导致的服务器压力激增。例如，对于网络延迟较低的玩家，优先处理其场景切换请求；对于网络延迟较高的玩家，则适当延后处理，同时通过加载进度条的动态调整，让玩家感知不到等待差异。同时，我们还在场景切换过程中加入了交互反馈机制，比如通过加载动画、临时互动小游戏等方式，分散玩家的注意力，减少加载延迟带来的负面体验。这种状态延续性保障方案，既兼顾了数据传输的效率，又保证了状态的准确性，让跨场景协同能够自然衔接，无明显感知断点。</p><p>长期运行下的逻辑衰减问题，容易被开发者忽视，但它会随着游戏运行时间的延长逐渐显现，比如数据缓存冗余、逻辑判断累积误差、资源占用持续上升等，这些问题会缓慢影响协同逻辑的运行效率，最终导致体验下滑。为应对逻辑衰减，我们建立了“动态清理+定期校准”的长效机制，在游戏运行过程中，系统会实时监测数据缓存的有效性，自动清理过期、无效的缓存数据—比如玩家已完成的任务数据、临时的交互缓存、过期的网络连接信息等，减少内存占用，避免缓存冗余导致的逻辑处理速度下降。同时，针对逻辑判断中的累积误差，设置定期校准节点，在不影响玩家体验的时段（如场景加载间隙、玩家离线时、服务器低峰期），对核心协同数据进行全面校验与修正。例如，定期比对服务器与客户端的玩家状态数据，修正因网络延迟、设备差异导致的数值偏差；校验组队协同逻辑中的权限设置，确保组队成员的操作权限与角色身份一致；检查场景元素的协同关系，修正因长期运行导致的逻辑关联错误。此外，我们引入“逻辑健康度监测”指标，通过量化协同逻辑的运行效率、数据一致性、资源消耗等关键参数，实时评估逻辑运行状态。具体来说，监测指标包括：状态同步成功率、指令响应延迟均值、数据一致性偏差率、内存占用增长率、CPU使用率波动范围等，当某一指标低于预设阈值时，自动触发优化机制—比如当响应延迟均值超过50ms时，自动调整同步频率；当内存占用增长率超过10%时，启动深度清理机制；当数据一致性偏差率超过3%时，触发紧急校准流程。</p>]]></description></item><item>    <title><![CDATA[《跨端互联进阶实践指南：从链路适配到长期]]></title>    <link>https://segmentfault.com/a/1190000047420800</link>    <guid>https://segmentfault.com/a/1190000047420800</guid>    <pubDate>2025-11-22 23:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>移动端玩家在户外蜂窝网络下触发的技能指令，在PC端玩家的视角中出现帧级滞后，或是主机端加载的动态光影特效，在低配移动端呈现时出现隐性缺失，甚至同一玩家切换设备登录后，角色状态的细微偏差会影响后续交互逻辑。想要破解这一难题，不能依赖表层的功能对接，而需搭建一套贯穿数据传输协议、设备能力适配、场景协同逻辑的完整体系，从根源上实现“指令同源、状态同步、体验同频”。长期实践表明，跨端互联的本质是“异构环境下的逻辑共识”构建，开发者需要跳出单一设备的思维定式，深入拆解不同终端的硬件特性、系统架构、交互习惯，让PC、移动、主机等多元设备基于统一的底层逻辑实现高效协同。这不仅要求保留各终端的操作优势，更要通过精细化的适配策略填补能力差异，确保核心体验的一致性，让玩家在通勤时用移动端推进剧情，回家后切换PC端享受高清画质，或是与主机端好友组队联机时，都能感受到无缝衔接的游戏沉浸感，这种跨越设备边界的体验连贯性，才是跨端互联的核心价值所在。</p><p>网络环境的异构性是跨端互联面临的首要挑战，不同终端的网络接入方式（WiFi、蜂窝网络、有线网络）、带宽承载能力、延迟波动范围存在天然差异，如何在这种差异中维系数据传输的稳定性与时效性，是体验同源的核心前提。多次调试后深刻意识到，单纯依赖固定的传输协议无法应对复杂的网络场景，因此需要构建“链路弹性适配体系”，通过实时监测网络的链路质量、延迟波动、数据包丢失率，动态调整传输策略。具体而言，我们会建立多维度的网络状态评估模型，通过分析近45秒内的链路抖动率、数据包有序率、带宽利用率、重传次数等核心指标，将网络状态精准划分为优质、稳定、波动、弱网四个等级，每个等级对应一套差异化的传输方案。在优质网络环境下（延迟&lt;30ms，丢包率&lt;1%，抖动率&lt;5%），采用高频率同步策略，确保场景细节、特效表现、角色表情等非核心数据的完整传输，让跨端体验达到一致的高品质；在稳定网络环境下，维持核心数据（角色移动、操作指令、状态变更）的高优先级传输，适当压缩非关键数据的体量，比如降低远景植被的纹理精度、减少非战斗区域的粒子特效数量，以平衡传输效率与体验完整性；在波动网络环境下，启动数据包分片传输与冗余备份机制，将核心指令拆分为1KB以下的小体积数据包，通过主链路+备用链路的多路径传输避免丢失，同时采用自适应重传策略，根据网络延迟动态调整重传超时时间，避免无效重传占用带宽；在弱网环境下（延迟&gt;100ms，丢包率&gt;10%），则触发“核心体验保活”策略，只传输玩家操作、角色状态、组队协作等关键数据，通过算法补全场景细节与非核心交互—比如根据场景规则推演远景物体的位置、用简化模型替代复杂特效，确保游戏能正常运行，而非直接降低体验或出现感知断层。这种弹性适配的核心是“因网制宜”，不追求绝对的传输质量，而是根据网络实际状态动态平衡“完整性”与“流畅性”，让不同网络环境下的跨端互联都能保持可接受的体验下限，即便是在信号不稳定的地铁或偏远地区，玩家也能正常参与联机互动。</p><p>设备能力的差异化是跨端互联的另一大核心痛点，PC的高性能运算、移动端的便携性、主机的沉浸式体验，决定了不同终端的硬件算力、屏幕尺寸、交互方式存在本质差异，如何让同一套游戏逻辑在不同设备上实现“效能适配”，是体验同源的关键。长期实践总结出，解决这一问题的核心是“分层设计+能力适配”，即构建“核心逻辑层+设备适配层”的架构，核心逻辑层封装游戏的核心玩法、数据规则、协同机制，确保跨端数据的一致性，这一层是跨端互联的基石，不随设备变化而改动；设备适配层则针对不同终端的硬件能力，定制化优化渲染、交互、资源加载逻辑，让每类设备都能在自身能力范围内发挥最优效能。在渲染适配方面，我们会为不同设备设定“视觉效果基线”，明确核心视觉元素（角色模型、关键道具、场景主体）的最低呈现标准，再根据设备性能分级优化—高性能PC端支持最高精度的纹理贴图、实时全局光照、海量粒子特效，甚至支持光线追踪技术；主机端则优化光影渲染的实时性与帧率稳定性，在保证视觉品质的前提下，将帧率稳定在60帧以上；中低端PC与高端移动端支持中等精度的纹理与光影，简化部分复杂特效的计算；入门级移动端则采用简化的纹理贴图、分级的粒子效果、静态光影烘焙，在保证视觉一致性的前提下最大程度降低算力消耗。在交互适配方面，针对触屏、键鼠、手柄的操作差异，设计“操作映射矩阵”，将核心游戏操作（移动、攻击、交互、技能释放）与不同终端的输入方式进行精准映射，同时保留各终端的操作优势—移动端优化触屏按钮的布局与响应区域，根据屏幕尺寸自适应调整按钮大小，支持滑动操作与快捷手势；PC端支持键鼠的精准操作与快捷键自定义，优化鼠标的灵敏度与视角转动速度，适配不同玩家的操作习惯；主机端强化手柄的震动反馈与摇杆灵敏度调节，将技能释放、交互等操作与手柄按键精准匹配，让震动强度与游戏场景联动（如攻击命中时的轻微震动、受到伤害时的强烈震动）。在资源加载方面，根据设备的内存容量与存储速度，制定差异化的加载策略，高性能设备（PC、高端主机）支持预加载完整场景资源，进入游戏后无需等待加载；中端设备采用“核心资源预加载+非核心资源后台加载”的方式，确保进入场景后能快速开展互动；移动端则采用“分块加载+按需加载”结合的方式，将场景划分为多个100MB以内的区块，优先加载当前场景的核心资源（角色、怪物、互动道具），后台异步加载后续区块与远景资源，同时根据设备内存实时清理已离开区域的非核心资源，避免内存溢出。这种分层适配的思路，核心是“扬长避短”，既不牺牲高性能设备的体验上限，也不勉强低性能设备的运行下限，让每类设备都能在自身能力范围内呈现最优的跨端互联体验，避免出现“高性能设备体验受限”或“低性能设备运行卡顿”的情况。</p><p>动态场景下的协同逻辑适配，是跨端互联中容易被忽视但至关重要的环节。游戏场景的复杂性（开放世界、密闭空间、大规模团战）、元素密度（NPC、道具、特效）、交互频率（玩家对战、组队协作、场景互动），会直接影响跨端互联的效能，固定的协同逻辑无法应对动态变化的场景，一旦场景复杂度超出预期，就容易出现同步延迟、状态错乱等问题。因此需要构建“场景感知型协同体系”，通过实时监测场景的复杂度、玩家分布、交互强度，动态调整协同策略，让协同逻辑能随场景变化灵活适配。在开放世界场景中，玩家分布分散、交互频率较低，采用“区域同步”机制，将场景划分为多个独立的同步区域（每个区域大小根据场景密度调整，通常为50×50米），玩家只与所在区域的其他玩家进行数据同步，离开区域后自动停止该区域的非核心数据传输，减少无效带宽占用；同时设置“区域衔接缓冲区”，当玩家即将进入相邻区域时，提前同步该区域的核心数据，避免跨区域时出现加载卡顿。在大规模团战场景（如20人以上组队对战）中，玩家密度高、交互频繁（每秒可能产生数十次技能释放、攻击指令），启动“核心交互优先”机制，将玩家的攻击、技能、移动、血量变化等核心操作列为最高优先级，压缩场景环境、非战斗NPC、远景特效等数据的传输频率（从每秒30次同步降至每秒10次），同时采用“状态聚合”策略，将多个玩家的同类状态变化合并为一个数据包传输，减少数据包数量，确保团战的流畅性。在解谜类场景中，强调数据的精准同步，采用“指令确认机制”，玩家的每一次交互操作（如触发机关、移动道具、破解密码）都需得到服务器的确认后，再在所有联机玩家的终端上呈现，避免因同步偏差导致解谜流程受阻—比如玩家A触发的机关，在玩家B的终端上未同步呈现，导致后续操作无法推进。针对场景切换时的协同衔接，设计“场景预同步”机制，当玩家即将进入新场景（如通过传送门、完成当前场景任务）时，服务器提前将新场景的核心数据（场景规则、初始状态、已存在的玩家数据）同步至各终端，待玩家触发切换指令时，快速完成场景加载与状态衔接，同时通过加载动画或过渡场景掩盖加载过程，避免出现加载卡顿或状态丢失。这种场景感知型协同的核心是“因地制宜”，让协同逻辑能够根据场景的动态变化灵活调整，确保不同场景下的跨端互联都能保持高效稳定，无论是单人探索开放世界，还是多人参与激烈团战，都能获得连贯的体验。</p><p>跨端数据的同源性校验，是保障体验一致性的底层支撑。不同终端的计算精度、数据存储方式、系统时间同步存在细微差异，长期运行后容易出现数据偏差—比如玩家的角色属性（生命值、攻击力）、任务进度、道具数量在不同设备上出现不一致，或是组队时玩家的位置信息偏差导致“隔空互动”，这种偏差会严重破坏跨端体验的连贯性，甚至引发玩家对游戏公平性的质疑。为解决这一问题，我们构建了“三层数据校验体系”，从传输层、逻辑层、存储层三个维度全面确保数据同源，将偏差控制在玩家无感知的范围内。传输层采用“数据指纹校验”机制，每一组核心数据（角色属性、交互指令、场景状态）在传输前都会通过特定规则生成唯一的指纹标识（如基于数据内容的特征码），接收端收到数据后，先验证指纹标识是否与发送端一致，若不一致则说明数据在传输过程中被篡改或丢失，立即请求重传，确保传输过程的数据完整性。逻辑层建立“数据一致性算法”，定期（如每30秒）同步各终端的核心数据，通过算法比对差异—对于数值型数据（如生命值、金币数量），设定允许的偏差阈值（通常为0.1%），若偏差在阈值内，则自动校准为服务器端数据；若偏差超出阈值，则触发“溯源校准”机制，调取该数据的操作日志，追溯偏差产生的原因（如网络延迟导致的指令未同步、设备计算误差），并以服务器存储的数据为基准，同步至所有终端，确保逻辑一致性。存储层采用“分布式数据同步”架构，将玩家的核心数据（角色信息、任务进度、道具列表）存储在云端服务器集群，各终端仅缓存临时数据（如当前场景的渲染资源、操作缓存），每次登录或切换设备时，从云端同步最新数据，避免本地存储导致的数据偏差；同时采用“多节点备份”策略，将核心数据备份至多个服务器节点，确保数据不会因单个节点故障丢失，同时提升数据读取速度。针对敏感数据（如稀有道具获取记录、竞技对战积分），额外增加“多重校验机制”，结合设备标识、用户账号、操作时间戳进行交叉验证，确保数据的安全性与准确性，防止恶意篡改。这种三层校验体系的核心是“防微杜渐”，通过全链路的监测与校准，将数据偏差扼杀在萌芽状态，让玩家在不同设备间切换时，不会感受到任何数据不一致，比如用移动端获得的道具，切换到PC端后能立即使用，组队时玩家的位置、状态完全同步，避免因数据偏差影响游戏体验。</p><p>长周期运行下的互联效能维护，是跨端互联长期稳定的关键。随着游戏运行时间的延长、版本迭代的累积，跨端互联的链路可能会出现效能衰减—比如数据同步延迟逐渐增加、新发布设备的适配缺失、场景协同逻辑出现隐性偏差，这些问题不会立刻导致功能失效，但会缓慢影响体验，长期积累后可能引发玩家流失。为应对这一挑战，我们建立了“互联效能监测与优化体系”，通过实时监测关键指标、定期进行全面检测、动态迭代适配策略，确保跨端互联的长期稳定。首先，构建“效能监测指标库”，涵盖数据同步成功率、跨端响应延迟均值、设备适配兼容率、场景协同流畅度、玩家投诉率等核心指标，为每个指标设定预警阈值—比如跨端响应延迟均值超过50ms、设备适配兼容率低于95%、玩家投诉率超过1%时，自动触发预警机制，通知技术团队及时排查。监测系统会实时采集各终端、各网络环境、各游戏场景的运行数据，生成可视化的效能报表，帮助开发者快速定位问题所在，比如某款新发布的移动端设备适配兼容率低，可针对性排查该设备的硬件特性与适配层逻辑的冲突。其次，建立“定期全量检测机制”，每两周对主流终端（覆盖PC、主流品牌中高端手机、主流主机型号）、不同网络环境（WiFi、4G、5G、弱网模拟）、核心游戏场景（开放世界、团战、解谜、场景切换）进行一次全量测试，模拟玩家的真实操作流程（如连续1小时联机对战、频繁切换设备登录、长时间探索开放世界），排查潜在的适配问题与效能瓶颈。测试过程中会记录各终端的帧率、内存占用、网络带宽消耗等数据，对比不同设备、不同场景下的体验差异，形成测试报告并制定优化方案。</p>]]></description></item><item>    <title><![CDATA[对外输出 苦闷的键盘 ]]></title>    <link>https://segmentfault.com/a/1190000047420742</link>    <guid>https://segmentfault.com/a/1190000047420742</guid>    <pubDate>2025-11-22 21:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>从生成式 AI 的惊艳亮相引起全球科技巨头军备竞赛般的投入开始，整个 AI 行业仿佛被注入了无限的想象力。似乎在宣告着即将出现一个生产力即将被彻底解放、商业模式即将被完全颠覆的光明未来。<br/>微软、谷歌、亚马逊等云巨头纷纷将资本支出的绝大部分押注于 AI 基础设施建设，而无数逐利而来的 AI 初创公司，更是如雨后春笋般涌现试图分一杯羹，全球 AI 领域的投资额也达到了史无前例的高度。<br/>然而，正如任何过热的淘金热最终都会迎来冷静期当技术以超乎预期的速度普及时，潜在的负面效应也以同样的速度被放大，正在悄然侵蚀着行业参与者。<br/>从 " 可选项 " 到 " 必选项 " 的巨额支出<br/>根据奇安信集团对外发布《2024 人工智能安全报告》来看，在 2023 年基于 AI 的深度伪造欺诈便已暴增了 3000%，基于 AI 的钓鱼邮件也增长了 1000%；而内容生成环节更是实现规模化生产。<br/>基于 Stable Diffusion 和 GPT-4 的定制模型，可每小时生成 2000 条伪原创研报、800 段逼真视频。暗网平台 "DarkGPT" 更是提供包月服务，1 万美元即可获得每日 5000 条金融虚假内容的产能。<br/>而且 "AI 滥用 " 的后遗症并不仅仅在社会新闻版块，可以说它已经穿透了科技公司的防火墙直接作用于其财务报表。而金融行业正是这场风暴的中心，当 AI 以假乱真的能力被精准地应用于金融诈骗时，其破坏力可以说是指数级的增长。<br/>据行业估算，2024 年由深度伪造技术引发的各类欺诈造成的全球经济损失已高达 120 亿美元。尤其在监管相对滞后、交易更为匿名的加密货币领域，AI 滥用更是如鱼得水。根据相关的报告也显示 2024 年仅 AI 深度伪造技术全年造成的损失便高达 46 亿美元。<br/>随着 AI 滥用事件的频发，过去模糊的 " 伦理指南 " 正在迅速转变为具有强制约束力的法律条文，而且这种转变直接导致了企业合规成本的急剧攀升。<br/>而且一旦出现违规需要付出的代价更是惨痛的，罚款最高可达全球年营业额的数个百分点或数千万欧元，而且合规也不再是法务部门的单一工作，而是渗透到研发、产品、市场的每一个环节。<br/>这些 " 反噬 " 也并非凭空产生，在 AI 商业化过程中对速度和规模的追求，长期以来压倒了对安全和伦理的考量所以形成了这种 " 原罪 "。因此未来合规成本的升高是不可避免的，而欧盟的《AI 法案》可以说是这一趋势的先行者。<br/>该法案于 2024 年 8 月 1 日正式生效并分阶段实施，着重对高风险的 AI 系统施加了严格的合规要求。而且这不仅仅是一项区域性法规，更可能产生 " 布鲁塞尔效应 " 从而影响全球的 AI 监管格局。<br/>监管的落地也将会直接转化为企业的合规成本。据公开信息推算，仅欧盟 AI 法案便可能导致欧洲企业的 AI 采纳成本增加约 310 亿欧元，并使 AI 投资减少近 20%。而美国联邦贸易委员会也已对 OpenAI 展开调查，谷歌等公司也不得不调整其营销话术，避免被处以巨额罚款。<br/>可以说 " 监管的铁幕 " 正在迫使整个行业从过去 " 快速行动，打破陈规 " 的互联网思维转向一种更为审慎、合规驱动的开发模式。可以说这种转变无疑会减缓创新速度并增加运营成本，对于那些资源有限的中小企业和初创公司构成尤为严峻的挑战。<br/>对 " 信任 " 的侵蚀或许是 AI 滥用最难修复的一种<br/>这源于在激烈的竞争压力下，企业急于抢占市场将产品快速推向用户，所以将风险控制和安全测试置于次要位置。但是这种 " 快速行动并打破规则 " 的心态在 AI 时代尤为危险，因为 AI 技术的潜在破坏力远超以往的软件应用。<br/>并且市场对于 AI 技术的可靠性极度敏感，甚至一次小小的失误都可能引发巨大的信任危机和财务损失。谷歌的 Bard 模型之前便在一次演示中出现事实性错误，竟然导致其母公司 Alphabet 的股价在单日内暴跌 7%，市值蒸发超过 1000 亿美元。<br/>并且随着 AI 投资的巨额支出持续攀升，投资者开始担忧其回报前景，这种悲观情绪导致 Meta、Microsoft、Alphabet 和 Nvidia 等 AI 领域的领军企业股价普遍承压下跌，市场也开始讨论 "AI 泡沫 " 的风险，并开始质疑哪些不计成本的 " 军备竞赛 " 式投资。<br/>更何况大量公司缺乏对 AI 伦理的明确责任归属，高管层面也并未对其有所调整。所以 AI 系统的决策过程像一个 " 黑箱 "，在责任主体模糊的情况下滥用和误用的风险便难以控制。企业内部也未建立有效的问责机制。<br/>但是更深层次的原因在于当前主流生成式 AI 商业模式本身所内含的风险。这些模型依赖于海量数据的投喂，其训练过程难以完全避免偏见和有害信息的吸收。而其强大的生成能力却为恶意利用提供了温床。<br/>因此当商业模式的核心是追求更强大的模型、更广泛的应用时，如果缺乏与之匹配的强大 " 安全刹车 " 系统，滥用就成了可预见的副产品。这种商业逻辑与伦理要求之间的结构性失衡才是导致 " 反噬 " 的根本内因。<br/>所以当企业享受了技术红利带来的增长，如今便也不得不为其模式所伴生的风险 " 买单 "。哪怕科技公司以 " 让世界更美好 " 的叙事推广 AI，公众在实际体验中，也会频繁受到隐私泄露、算法偏见、就业替代、虚假信息等负面影响。<br/>这种落差也导致了广泛的 "AI 焦虑 " 和不信任感。公众普遍认为现有的监管法规不足以应对 AI 带来的社会风险期望政府采取更加果断的行动。这种强大的民意压力也是推动监管机构加速行动的根本动力。<br/>面对公众的呼声和潜在的社会风险，监管机构的介入是必然的。但由于技术发展的速度远超立法速度监管往往表现出一定的滞后性，欧盟 AI 法案便被部分人士认为可能增加企业负担、抑制创新。<br/>全球主要经济体在 AI 领域的竞争，也使得监管变得更加复杂。各国都希望在鼓励创新和防范风险之间找到平衡点但这种平衡点的位置各不相同，因此形成了复杂的国际监管格局给跨国企业的合规带来了巨大挑战。<br/>而且这种外部滥用对整个 AI 行业的声誉造成了 " 连坐 " 效应。即使一家公司本身恪守伦理，也无法完全独善其身，因为公众对 AI 的信任是整体性的。恶意滥用行为如同向池塘中投下的毒药，在污染了整个水域后迫使所有 " 池中生物 " 共同承担后果。<br/>这场危机成为 AI 自我革新的契机<br/>这场 " 反噬 " 带来的阵痛，是 AI 产业从野蛮生长走向规范发展的必经阶段。它正在淘汰那些只想赚快钱、缺乏责任感的 " 玩家 "，筛选出真正有实力、有远见的长期主义者。从长远来看，这也是为 AI 产业的健康、可持续发展所必须付出的代价。<br/>其中最大的机遇在于将 " 信任 " 从一种道德呼吁，转变为一种可量化、可变现的商业资产和竞争壁垒。数据显示近 85% 的客户也更愿意与重视 AI 伦理实践的公司合作，而那些优先考虑伦理和透明度的公司收入增长也更快。<br/>可以说在 AI 产品同质化日益严重的未来，谁能赢得用户的信任谁就能赢得市场。" 负责任的 AI" 将不再仅仅是公关部门的口号，而是必须贯穿于产品设计、开发、部署全流程的核心战略。<br/>谷歌和微软等公司已经开始调整其策略，谷歌选择利用 AI 技术提升广告安全审核的效率，打击欺诈内容；微软则发布了负责任 AI 透明度报告，并推出了 AzureAIContentSafety 等服务，帮助客户构建更安全的 AI 应用。这些举措既是应对风险的防御，也是在构建新的竞争优势。<br/>正是 " 反噬 " 催生了全新的 " 安全即服务 " 市场。随着 AI 滥用风险的加剧企业对 AI 安全审计、风险评估、内容过滤、合规咨询等服务的需求将急剧增长。这为专门从事 AI 安全和伦理治理的科技公司、咨询机构创造了巨大的市场空间。<br/>而科技巨头自身也可以将其内部成熟的安全工具和能力平台化、服务化，开拓新的收入来源。例如，谷歌和微软在内容审核、风险识别方面的技术积累，完全可以转化为对外输出的商业服务。<br/>虽然监管的收紧虽然带来了成本，但也为行业设定了 " 准入标准 "，能够率先满足高标准合规要求的企业将获得更强的市场公信力和竞争优势，从而在未来的市场整合中占据有利地位。这实际上是一种由监管驱动的市场出清和格局优化。weibo.com/ttarticle/p/show?id=2309405235726924513343<br/>weibo.com/ttarticle/p/show?id=2309405235727062925544<br/>weibo.com/ttarticle/p/show?id=2309405235727201075559<br/>weibo.com/ttarticle/p/show?id=2309405235727343681541<br/>weibo.com/ttarticle/p/show?id=2309405235728195125267<br/>weibo.com/ttarticle/p/show?id=2309405235728333799487<br/>weibo.com/ttarticle/p/show?id=2309405235728471949337<br/>weibo.com/ttarticle/p/show?id=2309405235728614817948<br/>weibo.com/ttarticle/p/show?id=2309405235731500499023<br/>从滥用事件的激增，到资本市场的审慎，再到全球监管的收紧，这股 " 反噬 " 之力正在重塑 AI 产业的发展轨迹。它迫使整个行业从过去对技术力量的无限崇拜，转向对技术责任和社会价值的深刻反思。<br/>麦肯锡预测，到 2030 年 AI 将为全球经济创造 13 万亿美元价值。但价值分配取决于我们如何驾驭这头猛兽。未来的竞争，将不仅仅是模型参数和算力大小的竞争，更是治理能力、责任担当和用户信任的竞争。</p>]]></description></item><item>    <title><![CDATA[认识苹果签名：保障应用安全的关键机制 张]]></title>    <link>https://segmentfault.com/a/1190000047420453</link>    <guid>https://segmentfault.com/a/1190000047420453</guid>    <pubDate>2025-11-22 19:04:33</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在苹果生态系统中，每一款应用的顺畅运行都离不开一项核心技术——苹果签名。这项机制如同应用的“数字身份证”，默默守护着用户的安全与体验。</p><p>更多关于签名的信息：<a href="ioszf.cc" target="_blank">iOS苹果签名-超级签企业签TF签</a></p><p>苹果签名的本质</p><p>苹果签名是一种数字认证系统。开发者在应用发布前，需通过苹果开发者平台获取专属签名证书。这个证书相当于官方许可，确保应用来源可信且未被篡改。每当用户安装应用时，系统会自动验证签名有效性，确认无误后才允许运行。</p><p>签名机制的双重价值</p><p>对用户而言，签名机制构建了可靠的安全防线。它有效阻止恶意软件入侵，保证下载的应用都经过严格审核。同时，签名系统维护着生态秩序，避免未经授权的应用随意流通。</p><p>对开发者来说，签名不仅是发布应用的必要步骤，更是建立用户信任的基石。经过签名的应用更容易获得用户认可，这在竞争激烈的应用市场显得尤为重要。</p><p>签名技术的持续进化</p><p>随着技术发展，苹果签名机制也在不断完善。从最初的基础认证到如今的多重验证，签名系统变得越来越智能高效。近年来新增的安全特性进一步强化了隐私保护，使整个生态系统更加健壮。</p><p>展望未来</p><p>在移动互联网快速发展的背景下，苹果签名将继续发挥关键作用。这项技术既维护了平台秩序，又推动了应用创新的良性循环。作为用户，每次安全下载的背后，都有这套精密的签名系统在默默工作。</p><p>苹果签名看似是技术细节，实则是连接开发者与用户的重要桥梁。理解其运作原理，不仅能帮助我们更好地使用设备，也能更深入地认识现代移动生态的安全基础。</p>]]></description></item><item>    <title><![CDATA[CRM线索管理全解析：定义+搜集方式 遭]]></title>    <link>https://segmentfault.com/a/1190000047420456</link>    <guid>https://segmentfault.com/a/1190000047420456</guid>    <pubDate>2025-11-22 19:03:42</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>线索管理不再只是简单的数据收集和分类。它需要系统化的方法、先进的技术工具以及对客户需求的深刻洞察。优秀的线索管理策略能够帮助企业抓住市场机会，优化客户体验，提升销售业绩。有效的线索管理不仅可以提高销售效率，还能优化客户体验，从而推动企业的整体业绩。那么，什么是线索管理？又有哪些线索搜集方式呢？<br/><img width="723" height="487" referrerpolicy="no-referrer" src="/img/bVdm8od" alt="" title=""/></p><h2>一、线索管理的定义</h2><p>线索管理，顾名思义，是对潜在客户线索进行追踪和管理的过程。它是CRM系统的核心功能之一，通过系统化的方法，企业能够有效地捕捉、筛选和转化潜在客户为实际客户。线索可以来自多个渠道，如网络表单、社交媒体、电话咨询、展会等。线索管理的目标在于最大化引导、增加转化率，并最终实现销售目标。</p><p>在企业竞争日益激烈的市场中，掌握详尽的线索管理流程变得至关重要。首先，企业需要定义何为“高质量线索”。这些线索通常意味着不仅对产品或服务感兴趣，还表现出购买能力以及较高的交流意愿。接下来，通过管理流程将线索从初始阶段逐步推进到销售团队的正式跟进阶段。</p><p>Zoho CRM 提供强大的线索管理功能，能够帮助企业在整个过程中实现自动化和高效管理。例如，通过Zoho CRM的线索评分功能，企业可以快速识别高质量线索，并将其分配给合适的销售人员进行后续跟进。</p><h2>二、线索搜集的方式</h2><h2>1. 在线表单</h2><p>企业网站上的联系表单是获取客户线索的基础方式之一。有效的在线表单应该设计简洁，且包含关键信息字段，例如姓名、联系方式和感兴趣的产品或服务类别。值得注意的是，过多的问题可能会导致客户流失，因此平衡信息量和用户体验相当重要。 Zoho CRM 提供与在线表单无缝集成的功能，能够将表单数据直接导入CRM系统，避免手动录入的繁琐流程。</p><h2>2. 社交媒体</h2><p>随着社交媒体平台的普及，这些平台已成为获取潜在客户线索的强大工具。通过社交媒体发布吸引眼球的内容，企业可以引导用户互动，从而产生自然的客户线索。此外，通过社交媒体广告投放，精准定位目标客户群体也是线索搜集的高效方式。 Zoho Social（Zoho CRM的社交媒体管理工具）能够帮助企业在多个社交平台上发布内容、跟踪互动，并将潜在客户信息自动同步到CRM系统中。</p><h2>3. 搜索引擎优化（SEO）</h2><p>优化网站内容和结构，以提高搜索引擎的自然排名，是获取线索的重要策略之一。高质量的SEO策略能确保企业在潜在客户寻找相关服务时出现在搜索结果的显著位置，从而提高流量和线索转化。</p><h2>4. 电子邮件营销</h2><p>电子邮件仍然是最有效的沟通和推广工具之一。通过精心设计的邮件，企业能够精准传达信息给目标受众，并引导他们关注企业的产品或服务。电子邮件营销的成功很大程度上依赖于个人化的内容和适宜的发送频率。 Zoho Campaigns 提供强大的电子邮件营销功能，能够与Zoho CRM无缝对接，实现线索培育的自动化。</p><h2>5. 内容营销</h2><p>通过创造有价值的内容（如白皮书、案例研究、博客文章等），企业能够吸引并教育潜在客户。这种非直接营销方法不仅能提高品牌知名度，还能将对某一话题感兴趣的用户转化为潜在客户线索。</p><h2>6. 网络研讨会和线下活动</h2><p>组织网络研讨会和参与行业线下活动是直接获取线索的有效方式之一。在活动中，企业有机会直接与潜在客户互动，深入了解其需求和购买意图。活动结束后，可以通过跟进电子邮件或电话保持对话的延续性。 Zoho Meeting 提供了便捷的网络研讨会功能，能够帮助企业轻松组织线上活动，并将参与者信息直接导入到CRM中。</p><h2>三、线索管理过程的关键步骤</h2><h2>1. 线索捕获</h2><p>通过上文提到的各种渠道收集初步信息，将潜在客户数据保存在线索数据库中并进行初步分类。Zoho CRM 的线索捕获工具能够自动整合来自不同渠道的线索信息，避免数据分散。</p><h2>2. 线索评分与分级</h2><p>线索评分系统可以帮助企业分辨出哪条线索最具商业价值。评分通常基于客户的行为数据和信息完整性来进行打分，分数越高说明线索越有质量，可以优先跟进。Zoho CRM 的线索评分功能支持自定义规则，满足不同企业的需求。</p><h2>3. 线索培育</h2><p>并不是所有线索都准备好立即购买，因此对于暂未决定的线索，企业需要通过持续的内容发送和互动，培养其购买意愿。Zoho CRM 的自动化工作流能够帮助销售团队定期发送个性化内容，保持与潜在客户的联系。</p><h2>4. 线索分配</h2><p>经过评分和培育，优质的线索需要及时分配给合适的销售人员，以确保跟进过程的高效和顺畅。Zoho CRM 提供自动分配规则，能够根据地理位置、评分或其他条件将线索分配给最合适的团队成员。</p><h2>5. 线索转化</h2><p>销售人员与线索保持有效沟通，提供针对性的解决方案，最终促成交易的达成。Zoho CRM 的转化功能能够将线索直接转化为客户，并自动关联相关记录，确保数据的完整性。</p><h2>四、Zoho CRM在线索管理中的作用</h2><p>一个完善的CRM系统是线索管理得以顺利进行的技术支撑。Zoho CRM 不仅帮助企业有效地组织和管理线索数据，还提供了自动化工具和分析功能，从而提高线索管理的效率。以下是Zoho CRM在线索管理中的核心功能：</p><p>自动化流程：自动捕获线索、发送跟进邮件、安排日程提醒，大大减少人为工作量。<br/>多渠道整合：支持整合社交媒体、电子邮件、在线表单等多种渠道，确保线索来源广泛且数据统一。<br/>实时分析：通过数据分析功能，企业能够追踪线索的来源和转化率，以便持续优化线索管理流程。<br/>协作工具：Zoho CRM支持团队协作，销售人员可以共享线索信息，并在同一平台上高效配合。<br/>通过全面理解并应用上述各种线索搜集方式和管理步骤，结合Zoho CRM 的强大功能，企业将能在激烈的市场竞争中占得先机，实现可持续增长。</p>]]></description></item><item>    <title><![CDATA[怎么管理大客户？CRM策略+实战技巧 遭]]></title>    <link>https://segmentfault.com/a/1190000047420463</link>    <guid>https://segmentfault.com/a/1190000047420463</guid>    <pubDate>2025-11-22 19:02:52</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>大客户管理是一项复杂而富有挑战性的工作，但通过深入了解客户需求、专业团队协作、个性化服务策略、有效沟通以及长期关系的建立，企业可以在竞争激烈的市场中稳步提升自己的业绩表现。结合 Zoho CRM 的强大功能，企业能够高效管理大客户关系，实现业绩的持续增长。<br/><img width="723" height="487" referrerpolicy="no-referrer" src="/img/bVdm8od" alt="" title=""/></p><h2>一、深入了解客户需求</h2><p>有效的大客户管理始于对客户的全面了解。了解客户的不仅仅是其业务范围和基本需求，还应深入探究其当前的市场环境、发展战略、面临的挑战等信息。这种深入的了解可以通过定期与客户开展会议、调研、行业报告分析等方式实现。</p><p>Zoho CRM 提供了强大的客户信息管理功能，能够帮助企业记录客户的详细信息，包括行业背景、业务需求、历史沟通记录等。通过 Zoho CRM 的数据分析工具，企业还可以深入挖掘客户的潜在需求，为制定个性化服务策略提供数据支持。</p><h2>二、建立专业可信赖的团队</h2><p>大客户管理需要依靠一个经验丰富、专业性强的团队。这个团队应该由销售、客户服务、技术支持以及其他相关部门的专家组成。团队中的每位成员都应具备深厚的行业知识、出色的沟通能力、强烈的客户服务意识和问题解决能力。</p><p>Zoho CRM 的协作功能能够帮助团队成员共享客户信息，实时更新客户动态，确保团队内部的高效协作。此外，Zoho CRM 的任务分配功能可以将具体的客户管理任务分配给合适的团队成员，确保每位成员都能专注于自己的职责。</p><h2>三、制定个性化的客户管理策略</h2><p>每一个大客户都是独特的，因此需要量身定制个性化的客户管理策略。企业应结合客户的实际需求和未来愿景，制定具体的合作计划。这包括定期安排高层管理会议，讨论合作成效以及未来的合作方向。此外，还应为客户提供个性化解决方案，满足其特定业务需求。</p><p>Zoho CRM 支持自定义客户管理流程，企业可以根据客户的特点和需求，设计专属的客户管理策略。通过 Zoho CRM 的自动化工作流功能，企业能够自动化执行个性化的客户跟进任务，例如发送定制化邮件、安排定期会议提醒等。</p><h2>四、与客户保持有效沟通</h2><p>高效沟通是大客户管理的核心。企业应建立多个沟通渠道，如面对面会议、电话、电子邮件等，确保随时与客户保持联系。同时，了解客户的偏好并据此调整沟通方式和频率。沟通不仅限于听取客户反馈，还应积极主动地为客户提供洞见和建议，帮助客户发掘潜在机遇，解决困难并实现目标。</p><p>Zoho CRM 提供多渠道沟通工具，例如 Zoho Mail、Zoho Meeting 和 Zoho Social，帮助企业通过电子邮件、视频会议和社交媒体与客户保持紧密联系。此外，Zoho CRM 的沟通记录功能可以保存所有客户互动历史，确保沟通的连续性和高效性。</p><h2>五、为客户创造附加价值</h2><p>想要在大客户管理中脱颖而出，企业必须超越产品和服务本身，努力为客户创造更多的附加价值。这可以通过提供专业培训、市场情报、资源对接等多种方式来实现。当企业成为客户的战略合作伙伴时，它不仅能够稳固现有的客户关系，还能使收入渠道多样化并提高整体市场竞争力。</p><p>通过 Zoho CRM 的客户洞察功能，企业可以分析客户的业务需求和市场趋势，为客户提供有针对性的建议和增值服务。此外，Zoho CRM 的整合工具（如 Zoho Analytics）能够帮助企业为客户提供定制化的市场报告和数据分析，进一步提升客户满意度。</p><h2>六、建立长期合作关系</h2><p>信任和合作是大客户管理成功的关键。建立长期合作关系需要长期的投入和坚持。企业应始终如一地关注客户的长远利益，并持续优化服务和产品。通过定期的业绩评估和反馈会议，企业可以不断调整合作方式，确保满足客户变化中的需求。</p><p>Zoho CRM 的客户生命周期管理功能能够帮助企业跟踪客户关系的每个阶段，从初始接触到长期合作，确保客户关系的持续优化。通过 Zoho CRM 的定期提醒功能，企业可以及时安排客户回访和反馈会议，进一步巩固合作关系。</p><h2>七、有效运用客户关系管理（CRM）系统</h2><p>利用先进的客户关系管理系统可以极大提升大客户管理的效率和效果。CRM系统可以帮助企业记录和分析客户信息，跟踪客户的购买记录和沟通历史，从而精准定位客户需求，制定相应的管理策略。此外，CRM系统还可提醒业务人员需执行的任务，如合同续签、重要会议等，避免错失重要的客户接触机会。</p><p>Zoho CRM 是一款功能全面的客户关系管理系统，专为大客户管理设计。它不仅能够帮助企业高效管理客户信息，还提供自动化工作流、数据分析、任务提醒等功能，全面提升大客户管理的效率和效果。</p><h2>八、不断评估与优化管理策略</h2><p>市场瞬息万变，大客户管理策略必须动态调整。企业应定期审视当前策略的有效性，识别并消除潜在的管理盲点。可通过设定明确的绩效指标，分析客户满意度、客户留存率和收入增长情况等，来评估管理策略的有效性。</p><p>Zoho CRM 的数据分析功能能够实时追踪客户管理的关键指标，帮助企业评估当前策略的效果。通过 Zoho CRM 的报表和仪表盘功能，企业可以轻松识别需要改进的领域，并快速调整策略。</p><h2>九、鼓励客户积极参与产品开发</h2><p>大客户对市场变化的敏锐感知可以为企业的产品和服务开发提供有益的借鉴。企业应鼓励大客户对现有产品和新产品开发提出建议，通过客户的直接反馈更好地满足市场需求。这不仅能提升产品的市场适应性，还能增强客户的参与感和忠诚度。</p><p>Zoho CRM 的客户反馈功能能够帮助企业收集客户的意见和建议，并将其整合到产品开发流程中。通过 Zoho CRM 的协作工具，企业还可以与客户共同探讨产品改进方案，进一步增强客户的参与感。</p><h2>十、巩固企业品牌形象</h2><p>良好的企业形象对于大客户管理具有无可替代的重要性。企业应通过各种途径塑造和传递积极的品牌形象，如高质量的产品、可靠的售后服务、积极的社会责任担当等。品牌形象不但可以提升客户对企业的信任，还能在竞争中树立企业的差异化优势。</p><p>通过 Zoho CRM 的客户满意度调查功能，企业可以定期收集客户对品牌的评价，并根据反馈不断优化产品和服务，进一步提升品牌形象。</p>]]></description></item><item>    <title><![CDATA[浅谈最近星某克被指"追杀式"营销的技术实]]></title>    <link>https://segmentfault.com/a/1190000047420466</link>    <guid>https://segmentfault.com/a/1190000047420466</guid>    <pubDate>2025-11-22 19:02:04</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <blockquote>关注我，获取更多企业级架构和人工智能应用实践和落地的深度指南。</blockquote><h2>引言</h2><p>大家好，我是Kenyon。近日，星某克App因被用户指责存在"追杀式"的营销行为而被引发广泛的关注和讨论。据某博主反馈，他安装了星某克的App，他在室外移动的时候，该App不断地向他推荐「您正路过星巴克臻选特供“一豆两喝“」活动。随着他移动的路线一路“追杀”着向他进行推销，他走到哪就推销哪家店。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047420468" alt="Starbucks.jpg" title="Starbucks.jpg"/></p><p>这样的情况一般都是企业在用户隐私边界和商业利益两者之间的利益权衡做法不一样导致的，作为一名资深的架构师，这次我想从技术架构的角度来对这个问题来进行深入的探讨。跟大家剖析一下这类营销技术常见的实现方式是怎样的，探讨其中涉及的技术架构、数据处理的流程，以及在用户体验、数据隐私和商业价值之间的利弊应该如何找到合理的平衡点。</p><h2>一、实时营销技术常见的实现方式</h2><h3>1.1 位置感知技术基础架构</h3><p>一般的App基本都能够希望通过获取用户精准的位置来进行活动营销的内容推送，为了尽可能获取更精准的位置，App很可能采用了多层次的位置感知和营销手段来实现，比如：</p><ul><li><strong>多源的位置数据采集方式</strong>：App可以通过集成北斗、GPS、WiFi指纹、蓝牙Beacon、基站信号等多种定位的技术来进行位置数据的采集。</li><li><strong>实时位置计算引擎</strong>：App内对采集到的原始位置数据进行融合、过滤和精度优化等处理，然后根据系统后台配置的时间间隔或者距离相差的范围，将处理后的位置数据发送给服务器端。</li><li><strong>地理围栏（Geofencing）服务</strong>：后台系统提前预设好门店周边的电子围栏（虚拟边界），支持动态围栏调整</li><li><strong>实时推送调度系统</strong>：后台服务基于用户位置、门店的活动营销事件等内容自动触发的消息推送和分发的机制</li><li><strong>用户行为分析平台</strong>：结合位置数据与用户历史行为的个性化推荐引擎，为用户提供定制化的营销内容。</li></ul><p>这样的架构设计可以让App在后台持续监测用户位置变化，即使App在没有活跃的状态下也能保持一定程度的位置感知能力。这样系统就可以实现基于用户位置的变化进行近实时的活动营销信息的推送了，通过这种方式来让用户知道附近门店正在进行的促销信息，从而提高门店的销售额。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047420469" alt="location.jpg" title="location.jpg" loading="lazy"/></p><h3>1.2 手机系统的限制因素</h3><p>现在很多手机为了更好地保护用户的隐私，会限制应用在后台运行时的位置服务权限。通知的权限也可以被限制甚至关闭，但是通常很多App会想办法突破这些限制，常见的有以下几种方式：</p><ul><li><strong>位置服务权限与通知权限的分离利用</strong><br/>在iOS和Android系统中，位置服务权限与通知权限是两个独立的权限项。用户可能只关闭了通知权限，但是没有关闭位置服务权限。这样的话App仍然可以在后台获取用户实时的位置信息，然后通过其他渠道或者方式（如App角标、应用内消息中心）来展示营销内容。</li><li><strong>系统级后台任务调度</strong><br/>开发者可以利用Android的WorkManager或者iOS的Background Fetch等处理机制，App可以在系统允许的时间窗口内被唤醒，来进行位置检查和消息处理，而不受前台的运行状态限制。</li><li><strong>混合推送策略</strong><br/>结合系统级推送服务（APNs/FCM）与应用内的消息机制，来确保即使部分推送渠道被关闭或者限制，仍然可以通过其他渠道来进行消息的推送。</li></ul><h3>1.3 精准推送技术的实现原理</h3><p>推送决策引擎的组成模块：</p><ul><li><strong>位置检查模块</strong>：实时地监测用户位置与门店位置的变化，满足条件的话就触发推送事件。</li><li><strong>用户偏好分析模块</strong>：基于用户的历史购买记录、浏览记录等数据，实时分析用户对不同类型的促销活动的偏好。</li><li><strong>时间窗口管理模块</strong>：根据系统配置的时间窗口，合理的分配推送时间，避免对用户正常使用造成干扰。</li></ul><p>在构建推送规则引擎和机器学习模型的时候，我们一般都会考虑以下的因素来提高模型的可用度：</p><ul><li><strong>用户位置精确性评估</strong>：通过位置融合技术取最有可能准确的位置来计算用户和门店的实际距离并预计到达时间，如果有电子围栏的话就直接用围栏的范围来判断是否在范围内。</li><li><strong>用户偏好匹配度</strong>：基于用户的历史购买记录和行为数据匹配合适的促销内容，提高用户点击消息的点击率。</li><li><strong>时间敏感度分析</strong>：一定要考虑当前时段、季节、节假日等时间因素，合理调整推送时间，避免用户在不适当的时间收到推送。</li><li><strong>推送频率控制</strong>：避免过度的推送导致用户反感，控制推送频率在合理范围内。</li><li><strong>上下文感知</strong>：结合用户当前活动状态（步行、驾车、静止等）优化推送时机，提供跟用户现状更相关的营销内容。</li></ul><h2>二、数据流程与隐私边界的问题</h2><p>从技术架构的角度来看，位置数据在从App采集到最后应用的过程中的涉及到多个流转的环节，每个环节都存在潜在的隐私风险：</p><ol><li><strong>数据采集层</strong></li></ol><ul><li>App在采集原始位置数据的时候的采集频率和精度控制，采集太频繁和精度太高的话会对用户的隐私造成风险，采集频率和精度要根据实际情况来进行调整。</li><li>采集过程中的数据是否进行匿名化的处理，采集到的原始位置数据是否需要进行脱敏处理，或者是否需要进行加密存储，这都需要根据具体的业务场景和法律法规来进行判断。</li><li>不同定位技术组合使用的策略，不同的定位技术有不同的优缺点，比如GPS定位精度高但是耗电多，而基站定位精度低但是对环境的要求低，所以在实际应用中需要根据具体的场景来选择合适的定位技术。</li></ul><ol start="2"><li><strong>数据传输层</strong></li></ol><ul><li>端到端的加密处理机制，部分App的请求是明文传输且没有使用SSL进行加密的，这就存在着严重的安全风险</li><li>差分隐私技术在批量数据传输中的应用，通过在数据传输过程中添加随机噪声，来保护用户的隐私，避免直接暴露用户的位置信息</li><li>传输过程中的数据压缩和最小化原则，在传输位置数据的时候，为了减少数据流量和传输延迟，通常会对数据进行压缩处理，同时只传输必要的位置信息</li></ul><ol start="3"><li><strong>数据存储层</strong></li></ol><ul><li>敏感位置数据的加密存储策略，能脱敏的就尽量脱敏存储，不能脱敏的就加密存储</li><li>用户历史轨迹的保留期限和自动删除机制，根据用户的隐私设置和使用习惯，来确定是否保留用户的历史轨迹数据，以及保留的时间期限</li><li>数据访问权限的严格控制，只有获得用户明确授权的情况下，才会对用户的位置数据进行访问和使用</li></ul><ol start="4"><li><strong>数据使用层</strong></li></ol><ul><li>位置数据与个人身份的关联和控制</li><li>第三方数据共享的边界和审计的机制</li><li>跟用户明确数据使用授权的实现方式，处理不当就有可能会面临法律的风险</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047420470" alt="如何在用户体验和商业价值之间权衡" title="如何在用户体验和商业价值之间权衡" loading="lazy"/></p><h2>三、用户体验与商业价值的利弊权衡</h2><p>在位置感知的营销中，如何通过技术手段来更好地平衡用户体验和商业价值，这是一个复杂的工程问题，这里涉及到：</p><h3>3.1 用户体验的考量</h3><p><strong>1. 智能推送频率控制算法</strong></p><p>尽可能实现可以基于用户反馈的自适应推送频率控制：</p><ul><li>记录用户对推送的响应行为（点击、忽略、关闭）数据</li><li>建立用户疲劳度的模型，根据用户的反馈情况动态调整推送的时间间隔</li><li>实现基于时间窗口的推送限流机制，避免用户在短时间内收到过多的推送消息</li></ul><p><strong>2. 上下文感知推送算法</strong></p><p>通过传感器数据融合技术，判断用户当前情境：</p><ul><li>结合加速度计、陀螺仪数据判断用户活动状态</li><li>分析时间、天气等外部因素优化推送内容</li><li>实现基于用户历史行为的情境预测模型，来更好地了解用户的需求和行为模式</li></ul><p><strong>3. 个性化内容推荐算法</strong></p><p>基于实时状态和位置的个性化推荐：</p><ul><li>实时特征工程：位置、时间、天气、用户状态等多维特征</li><li>在线学习模型：不断优化推送内容和时机</li><li>A/B测试框架：科学评估不同推送策略的效果</li></ul><p>基于以上的内容来进行更加合适的内容推送，提高用户的点击率和转化率，切记要避免推送一些不合时宜的消息内容，引起用户的反感。</p><h3>3.2 商业价值的最大化</h3><p><strong>1. 位置数据的商业价值挖掘</strong></p><ul><li>热点分析：识别高价值的客流区域，为门店布局和人员配置提供参考</li><li>转化漏斗：分析从位置触发到实际购买的转化率，优化营销策略</li><li>门店优化：优化门店布局和人员配置，提高用户到店率和销售额</li></ul><p><strong>2. 闭环的营销效果评估系统</strong></p><ul><li>归因模型：推送时做好数据标签，方便计算位置营销带来的增量销售</li><li>多渠道整合：将位置触发与其他营销渠道协同，实现更全面的用户群体覆盖和营销效果</li><li>ROI实时计算：动态地调整营销投入的策略，根据实时数据调整推送频率和内容，以达到商业价值的最大化</li></ul><p><strong>3. 用户生命周期价值的提升技术</strong></p><ul><li>优化基于位置的用户分群策略</li><li>设立流失预警的模型与干预的机制</li><li>优化会员忠诚度的动态优化算法</li></ul><p>通过以上的2点可以通过推送营销来提高用户的到店率，增加销售额，从而实现商业价值的最大化。但是文章开始的地方说到的"追杀式"的营销，其实是企业期望能将用户的商业价值实现最大化，但是在实现的过程中，有些操作做得太过头了，这样做的话反而会引起用户反感，从而造成用户流失。</p><h2>四、结论与展望</h2><h3>4.1 技术伦理与责任</h3><p>作为软件架构师，我们在设计用户位置感知系统时，应当始终将用户隐私和体验放在首位。"追杀式"营销的技术实现虽然在短期内可能带来商业价值，但从长远来看，会严重地损害用户信任，甚至面临法律风险。</p><p>技术本身是中性的，但是使用的方式和方法好不好这个就另当别论了。精准的位置营销技术可以在保护用户隐私的前提下，给用户提供真正有价值的服务，如：</p><ul><li>智能路线规划和到达时间预测</li><li>基于位置的个性化服务推荐</li><li>紧急情况下的安全辅助功能</li></ul><h3>4.2 未来技术发展趋势</h3><p>随着用户对个人隐私数据的重视和政策的不断完善，用户位置数据应用的技术将会朝着更加智能、更加注重隐私的方向发展，比如：</p><ul><li><strong>边缘计算与本地处理</strong>：现在设备的算力越来越强大，很多原本需要在云端进行的位置数据处理逻辑，现在可以迁移到用户的设备本地进行，减少原始数据传输。</li><li><strong>隐私增强技术（PETs）的广泛应用</strong>：差分隐私、同态加密、安全多方计算等技术也会慢慢地在位置服务中得到更广泛的应用。</li><li><strong>AI驱动的智能隐私保护</strong>：通过机器学习算法自动识别和保护敏感的用户信息和位置数据，平衡隐私保护和服务体验。</li><li><strong>去中心化位置验证</strong>：基于区块链等技术实现无需中心化服务器的位置验证机制。</li></ul><h3>4.3 给企业和开发者的建议</h3><ul><li><strong>建立隐私优先的技术架构</strong>：在系统设计初期就将隐私数据的保护纳入重点考量的范畴，而非事后补救</li><li><strong>实现细粒度的用户控制</strong>：给用户提供灵活、透明的隐私设置选项，给用户自己选择是否分享自己的隐私数据的权利。</li><li><strong>确保价值对等</strong>：每获取一项用户的设备或者数据的权限，都应提供明确、对等的服务和价值</li><li><strong>持续监控与优化</strong>：建立用户反馈机制，持续优化数据隐私服务策略</li><li><strong>合规与前瞻</strong>：不仅满足当前的隐私法规要求，还应前瞻性地应对未来可能的监管变化</li></ul><hr/><h2>结语</h2><p>星某克App这次的"追杀式"营销引起的争议，实际上反映了当前移动应用在位置服务技术应用中面临的普遍挑战。作为技术从业者，我们有责任去推动位置服务技术朝着更加尊重用户隐私、更加注重用户体验的方向去发展。</p><p>在技术创新与商业价值之间，我们需要找到合理的平衡点，始终牢记："技术是为业务服务的"，而业务的终极目标就是为了给用户创造价值。我们不能为了追求商业指标而牺牲用户的体验和隐私。只有在尊重用户、保护隐私的基础上，技术创新才能真正实现可持续发展。</p><h2>关于作者</h2><p>Kenyon，资深软件架构师，15年的软件开发和技术管理经验，从程序员做到企业技术高管。多年企业数字化转型和软件架构设计经验，善于帮助企业构建高质量、可维护的软件系统，目前专注架构设计、AI技术应用和落地；全网统一名称“六边形架构“，欢迎关注交流。</p><p><em>原创不易，转载请联系授权，如果觉得有帮助，请点赞、收藏、转发三连支持！</em></p>]]></description></item><item>    <title><![CDATA[制造业出海难题：零部件、多币种、税务合规]]></title>    <link>https://segmentfault.com/a/1190000047420482</link>    <guid>https://segmentfault.com/a/1190000047420482</guid>    <pubDate>2025-11-22 19:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>制造业出海浪潮下，汽车、电子、机械等领域的零部件企业正加速全球化布局。然而，从多币种报价、跨境采购、复合品目（BOM）管理，到多国仓库协同、税务合规及多币种结算，产业链各环节复杂度陡增。传统ERP系统难以满足动态业务需求，而Zoho Books智能ERP系统凭借全流程自动化、深度行业适配、全球化合规支持，成为零部件企业出海的“数字化中枢”。<br/><img width="500" height="328" referrerpolicy="no-referrer" src="/img/bVdm8oD" alt="" title=""/></p><h2>一、零部件制造出海的核心痛点与ERP需求</h2><h2>报价效率低</h2><p>客户需求多样，产品组合复杂，人工核算成本易出错，响应速度慢。</p><h2>复合品目（BOM）管理难</h2><p>多级物料清单、替代料管理、生产损耗计算繁琐，易导致库存偏差。</p><h2>跨境采购与供应链协同弱</h2><p>海外供应商时差沟通、多币种结算、物流延迟影响生产计划。</p><h2>多国税务合规风险高</h2><p>出口退税、VAT/GST申报、关税计算规则复杂，人工处理成本高。</p><h2>仓库与销售协同滞后</h2><p>多地仓库库存分散，难以实时调拨，导致订单履约率下降。</p><h2>二、Zoho Books智能ERP：零部件出海全链路解决方案</h2><h2>1、从询价到订单，全流程自动化管理</h2><p>Zoho Books支持创建报价单、付款通知单、销售订单、发货单、电子发票等单证，系统以“销售”为核心，可自动化追踪整个销售流程。企业可以快速生成符合国际要求的专业报价单和电子发票，并提供多种付款选项，若国外客户没有按时支付，后台可以设置付款提醒，提高企业回款效率。</p><h2>2、复合品目（BOM）与采购管理</h2><p>Zoho Books支持主料、辅料、替代料分层管理，自动关联库存与采购需求。缺料时可以自动触发采购申请，根据系统选择的首选供应商发送采购订单，减少人工工作量，提高工作效率。</p><h2>3、跨境采购与供应商协同</h2><p>多币种支持：系统支持180多种货币，能够满足出海企业在全球范围内的业务需求。企业可以进行不同客户的多币种管理，轻松创建基于不同货币的付款通知单，便于和全世界的客户进行交易。而且系统支持实时更新汇率，减少手动计算汇率而产生的失误。<br/>供应商门户管理：Zoho Books提供供应商门户管理功能，海外供应商可自助登录查看订单状态、交付要求，减少沟通成本。</p><h2>4、多仓库与销售协同管理</h2><p>多仓库管理：Zoho Books企业版支持多仓库管理，能自动跟踪库存水平，提供实时库存估值。对于制造业出海的零部件管理，可有效控制零部件库存，避免过度库存或缺货情况。同时，支持库存预警设置，当零部件库存低于设定阈值时，及时通知补货需求，确保生产的连续性。<br/>电商平台集成：支持与亚马逊、eBay、独立站等国际主流电商平台集成，实现订单同步，可以一键生成拣货单、装箱单及跨境物流标签。</p><h2>5、税务合规与多币种财务</h2><p>税务合规：Zoho Books支持处理不同国家和地区的税收制度，内置了多国版本，能够生成符合各地税法要求的报税表格和报告。覆盖15国税法规则（含欧盟/北美/东南亚），自动生成多语言合规发票，帮助企业确保在国际业务中的税务合规性，有效避免因税务问题而产生的法律风险和经济损失。<br/>财务管理：提供了丰富的财务管理功能，方便与国外客户对账。</p><h2>三、为什么选择Zoho Books？</h2><h2>行业深度适配</h2><p>专为制造企业出海设计，支持库存管理、订单管理等复杂场景。</p><h2>全球化+本地化</h2><p>覆盖多个国家财税合规，减少企业经营风险。</p><h2>高性价比</h2><p>按需订阅，提供从免费版到旗舰版的多种选择，满足不同规模企业的需求。而且支持14天免费试用，可以降低中小企业使用门槛。</p><h2>结语</h2><p>制造业出海企业应选择具备全球化功能、行业适配性强且成本效益高的ERP系统。Zoho Books以全链路数字化、智能自动化、全球合规化为核心，帮助企业打通报价、BOM、跨境供应链与财税管理壁垒，实现全球化敏捷运营。</p>]]></description></item><item>    <title><![CDATA[[数据集]作弊行为检测数据集（1100张]]></title>    <link>https://segmentfault.com/a/1190000047420412</link>    <guid>https://segmentfault.com/a/1190000047420412</guid>    <pubDate>2025-11-22 18:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>[数据集]作弊行为检测数据集（1100张图片已划分）[目标检测]</h2><p>为了在考试、教育监考等场景中实现自动化监督与作弊行为识别，我们整理并构建了一个轻量易用的<strong>作弊行为检测数据集</strong>。该数据集包含真实考试视觉特征，可高效支持 YOLO、Faster R-CNN 等主流目标检测模型训练。</p><hr/><h3>数据集下载</h3><blockquote>链接:<a href="https://link.segmentfault.com/?enc=cyO4oEaLX6Rm0Bp9d9ppig%3D%3D.E0oKSs1UX4wfXwdy%2FW%2BhwNrOSqwFxqsUaAqkGNPCYPLzyeIBE%2Fa4OU3BSh5%2BQO6Lf9JunGk08vXMTyuSi3tFYQ%3D%3D" rel="nofollow" target="_blank">https://pan.baidu.com/s/1VBxTkGOjM5PWD7jwPPTVYA?pwd=85cv</a><br/>提取码:85cv 复制这段内容后打开百度网盘手机App，操作更方便哦</blockquote><p>数据集说明</p><p>基本信息<br/>数据规模：包含 1100 张作弊检测相关图片，覆盖作弊场景核心视觉特征。<br/>存储路径：根路径为main/datasets，训练集存放于./images/train，验证集存放于./images/val，划分清晰便于模型训练与验证。<br/>标注信息<br/>类别数量（nc）：共 2 个目标类别，兼顾基础作弊行为与特定严重作弊场景。<br/>类别定义：<br/>作弊行为：涵盖各类基础作弊动作及场景，为核心检测类别。<br/>使用手机 (严重作弊)：聚焦 “使用手机” 这一特定严重作弊行为，单独标注以强化关键违规场景的检测精度。</p><p>path: main/datasets<br/>train: ./images/train<br/>val: ./images/val</p><h2>nc: 2</h2><h2>names: ['cheating', 'using mobile']</h2><p>nc: 2<br/>names: ['作弊行为', '使用手机(严重作弊) ']<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047420414" alt="在这里插入图片描述" title="在这里插入图片描述"/></p><h3>背景</h3><p>随着人工智能技术在教育管理领域的深入应用，传统人工监考方式逐渐暴露出以下问题：</p><ul><li>监考压力大、精力有限，漏判与误判风险高</li><li>大规模监考难以确保全覆盖与实时性</li><li>部分违规行为隐蔽性强，仅凭肉眼难以识别</li></ul><p>作弊行为特别是<strong>使用手机等严重违规方式</strong>，对考试公平性造成显著威胁。基于视觉 AI 的作弊检测系统已成为研究热点，而高质量标注数据是模型性能提升的核心驱动力。</p><p>为此，本数据集聚焦真实考试环境，通过图像级标注确保能够覆盖主体作弊动作特征，助力识别系统快速落地。</p><hr/><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047420415" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/><br/>考试作为社会评价体系中最重要的公正手段之一，其公平性直接影响人才选拔与教育信任度。然而，随着移动设备普及和作弊方式不断演化，传统的人工监考模式正面临严峻挑战：</p><p>作弊手法隐蔽化<br/>小型电子设备、耳机、智能穿戴的发展，使违规行为更加难以察觉。</p><p>监考压力持续上升<br/>在大规模考试中，监考教师需同时关注数十甚至上百考生，容易漏判与疲劳。</p><p>监督成本高、效率低<br/>人力成本持续增长，却难以保证全覆盖与实时性。</p><p>因此，构建智能监考系统已经成为教育行业发展的必然趋势。近年，人工智能技术特别是目标检测模型（Object Detection），在安防、行为识别领域展现出卓越效果，也为监考自动化带来了突破机会。</p><p>目标检测不仅能够识别画面中的人，还能定位其关键行为区域，例如：</p><p>手部与试卷的交互动作</p><p>是否注视屏幕之外</p><p>是否持有电子设备</p><p>与邻座异常互动行为</p><p>这使得利用 AI 来辅助监考成为现实。</p><p>然而，智能监考系统的性能高度依赖其背后的训练数据质量。目前公开的作弊场景数据较少，且缺乏针对高危行为（如使用手机）的独立标注支持。数据缺失成为制约研究落地的重要瓶颈。</p><p>为解决上述问题，本项目推出的作弊行为检测数据集具有以下目的：</p><p>提供可直接用于目标检测训练的高质量图像数据</p><p>强化对严重违规行为的精准识别能力</p><p>为学术研究与工程部署提供统一标准的数据基础</p><p>推动教育行业的智能化转型</p><p>借助该数据集，研究人员与开发团队可快速构建作弊检测模型，降低研发成本，同时提升系统实时识别能力，为考试公平提供更坚实的技术保障。</p><h3>数据集概述</h3><table><thead><tr><th>项目</th><th>内容</th></tr></thead><tbody><tr><td>数据规模</td><td>1100 张作弊检测相关图像</td></tr><tr><td>任务类型</td><td>目标检测任务（Object Detection）</td></tr><tr><td>标注格式</td><td>YOLO 标注格式</td></tr><tr><td>分类数量</td><td>2 类</td></tr><tr><td>数据划分</td><td>Train / Val 已按合理比例划分</td></tr></tbody></table><p>数据集路径结构：</p><pre><code>path: main/datasets
train: ./images/train
val: ./images/val
nc: 2
names: ['作弊行为', '使用手机(严重作弊)']</code></pre><p>分类标签聚焦作弊检测两大核心：</p><ol><li><strong>作弊行为（cheating）</strong>：包括抄袭、传纸条、遮挡视线等多态场景</li><li><strong>使用手机(严重作弊)</strong>：强化识别违规电子设备操作<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047420416" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047420417" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></li></ol><hr/><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047420418" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h3>数据集详情</h3><table><thead><tr><th>类别</th><th>含义说明</th><th>应用重点</th></tr></thead><tbody><tr><td>作弊行为</td><td>轻中度违规行为，范围广、变化多</td><td>广泛场景泛化能力</td></tr><tr><td>使用手机(严重作弊)</td><td>严重危害公平性，高优先级检测目标</td><td>提升警报触发精度</td></tr></tbody></table><p>图像覆盖多样化环境与角度：</p><ul><li>室内考试教室、机考场景</li><li>多摄像头视角：俯拍、侧拍、远距离监控</li><li>多人/单人场景</li><li>不同光照与遮挡情况</li></ul><p>确保模型在真实部署中具备稳定表现。</p><hr/><h3>适用场景</h3><p>该数据集适用于多种智能监考系统研发方向：</p><ul><li>线上/线下考试的实时作弊检测</li><li>职业资格与高校监考辅助系统</li><li>行为风险识别与违规记录管理</li><li>视频流监控分析（可拓展至动作跟踪）</li></ul><p>可与 CCTV、校园摄像头等生产环境无缝结合。</p><hr/><h3>目标检测</h3><p>为便于快速使用，本数据集默认支持 YOLO 系列模型。可直接加载并训练：</p><pre><code class="bash">yolo train model=yolov8s.pt data=main/datasets/data.yaml epochs=100 imgsz=640</code></pre><p>如需扩展，可用于：</p><ul><li>Faster R-CNN / Mask R-CNN</li><li>SSD、DETR 结构</li><li>行为识别（结合时间序列）</li><li>轻量化部署（MobileNet + TFLite / Ascend）</li></ul><p>模型训练后可实现<strong>自动告警 + 框选违规区域</strong>，显著提升监考效率与准确性。</p><hr/><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047420419" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h3>结语</h3><p>作弊行为检测是教育公平体系建设的重要方向。本数据集虽轻量，但具备良好的实用性和扩展能力，可作为 AI 监考系统研发的高效起点。</p><p>我们将持续优化数据规模与标注质量，为教育行业提供更可靠的智能化监测能力。如果你有更多真实监考场景数据来源或合作需求，也欢迎交流一起推进学术与产业落地。<br/>基于视觉 AI 的作弊行为检测正逐渐走向成熟，从简单的屏幕监控、人工复查逐步迈向自动化、实时化与精准识别。本数据集的构建，旨在为研究者与开发者提供一套轻量但高价值的训练数据，使智能监考系统能更好地识别作弊动作，尤其是使用手机等严重违规行为。</p><p>在未来，随着数据规模不断扩大、多模态信号融合（如姿态识别、手部跟踪、声音探测）、模型轻量化部署等技术演进，AI 监考系统将更加贴近真实实施场景：</p><p>更强的场景泛化能力</p><p>更低的误报/漏报率</p><p>更实用的实时告警反馈</p><p>更强的隐蔽作弊识别能力</p><p>我们也期待与教育行业、科研团队建立更多合作机会，共同推动智能监考技术发展，实现考试公平与教育治理的数字化革新。</p><p>若你对本数据集有使用建议、想训练完整系统或需要更多场景数据，欢迎随时交流。🚀</p>]]></description></item><item>    <title><![CDATA[AI Compass前沿速览：Nano ]]></title>    <link>https://segmentfault.com/a/1190000047420299</link>    <guid>https://segmentfault.com/a/1190000047420299</guid>    <pubDate>2025-11-22 17:01:56</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>AI Compass前沿速览：Nano Banana Pro、Gemini 3 、 HunyuanVideo 1.5 、Meta SAM 3D生成</h2><p><strong>AI-Compass</strong> 致力于构建最全面、最实用、最前沿的AI技术学习和实践生态，通过六大核心模块的系统化组织，为不同层次的学习者和开发者提供从完整学习路径。</p><ul><li>github地址：<a href="https://link.segmentfault.com/?enc=FlZt07wDrRQzm11quxrQ0g%3D%3D.XrolBpKh4FDjJiLnYAQGjL960%2F5DTtuglf2qw2YcZP%2Fu3VAYE8S%2BhMnSJtzkJB5H" rel="nofollow" target="_blank">AI-Compass👈：https://github.com/tingaicompass/AI-Compass</a></li><li>gitee地址：<a href="https://link.segmentfault.com/?enc=99WmyP1IZcPSZC5ovBO%2B3w%3D%3D.X0MDSDTcYe508TjEC4hQ6%2BPkFzVILQaj%2BtqrM0YnA1dBlTFHFxWia72bx4zOC3pe" rel="nofollow" target="_blank">AI-Compass👈：https://gitee.com/tingaicompass/ai-compass</a></li></ul><p>🌟 如果本项目对您有所帮助，请为我们点亮一颗星！🌟</p><h2>1.每周大新闻</h2><h3>Nano Banana Pro</h3><p>Nano Banana Pro是一款由谷歌推出的新一代图像生成与编辑模型，它结合了谷歌的Gemini 3 Pro Image技术，旨在提供高质量、高分辨率的AI图像生成和编辑服务。该平台也包含早期的Nano Banana版本，其基于Gemini 2.5 Flash Image API，共同构成了先进的AI图像处理生态系统。</p><h5>核心功能</h5><ul><li><strong>高分辨率图像生成：</strong> 支持生成2K、4K甚至更高分辨率的图像，保证输出质量。</li><li><strong>角色一致性：</strong> 能够处理多达5个角色的图像，并保持其在不同生成或编辑场景中的一致性。</li><li><strong>锐利文本渲染：</strong> 提供清晰、专业的文本在图像中的呈现能力。</li><li><strong>专业编辑工具：</strong> 内置批处理编辑器、背景移除等高级编辑功能，满足多样化的图像处理需求。</li><li><strong>文本提示编辑：</strong> 通过自然语言提示词（Prompt）对图像进行编辑和转换。</li><li><strong>API接口：</strong> 提供API，便于第三方平台或服务集成。</li></ul><h5>技术原理</h5><p>Nano Banana Pro的核心技术基于<strong>Google Gemini 3 Pro Image</strong>，这是一款先进的AI图像生成技术，能够实现对图像的精细化控制、高保真输出及复杂场景下的角色保持。早期的Nano Banana则采用<strong>Google Gemini 2.5 Flash Image API</strong>，该API以其高效和快速的图像处理能力为平台奠定基础。这些模型利用深度学习和生成对抗网络（GANs）或扩散模型等技术，通过对海量图像数据的学习，理解图像内容并根据用户指令进行创作和修改，实现从文本到图像（Text-to-Image）及图像编辑（Image Editing）的功能。</p><h5>应用场景</h5><ul><li><strong>创意设计与内容创作：</strong> 艺术家、设计师、营销人员快速生成高质量视觉内容。</li><li><strong>商业宣传与广告：</strong> 制作高分辨率的广告图片、产品展示图。</li><li><strong>个人图像编辑：</strong> 用户可利用自然语言对个人照片进行专业级编辑，如背景替换、风格转换等。</li><li><strong>Botpool服务集成：</strong> 作为图像处理能力，集成到聊天机器人、自动化工具等Botpool平台，提供图像生成和编辑服务。</li><li><strong>游戏与影视制作：</strong> 生成高质量场景、角色或特效图像，辅助内容创作。</li><li><strong>教育与研究：</strong> 作为AI图像生成与编辑技术的演示和研究平台。</li></ul><ul><li>制作一张关于这种植物的资讯图表，重点放在有趣的资讯上。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047420301" alt="banana-1.png" title="banana-1.png"/></p><ul><li>生成Switch版本对比</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047420302" alt="Switch.jpeg" title="Switch.jpeg" loading="lazy"/></p><h3>Gemini 3 – 谷歌</h3><p>Gemini 3是Google DeepMind推出的一系列新一代多模态理解与推理AI模型。它具备卓越的推理能力和多模态处理能力，可以理解并生成文本、图像、音频和代码等多种类型的内容。用户和开发者可以通过Google AI Studio、Vertex AI、Gemini CLI等平台进行访问和构建应用。</p><h5>核心功能</h5><ul><li><strong>卓越推理能力</strong>：Gemini 3 Pro在多项基准测试中展现出博士级的推理能力，如LMArena Leaderboard登顶，并在“人类终极测试”和GPQA Diamond测试中表现优异。</li><li><strong>多模态理解与生成</strong>：能够处理和生成图像、音频、代码及文本等多种模态信息，支持复杂的跨模态交互。</li><li><strong>工具使用与Agentic能力</strong>：通过“深度思考模式”（Deep Think）有效地使用工具进行复杂视觉推理任务，并支持构建具备自主规划和执行能力的AI代理。</li><li><strong>上下文保持与实时数据集成</strong>：利用“思考签名”技术在API调用间维护推理上下文，并能结合Google Search实现实时数据检索和信息“接地”。</li></ul><h5>技术原理</h5><p>Gemini 3 基于先进的<strong>多模态大型语言模型（MLLM）</strong>架构，能够深度融合并处理不同模态的数据。其<strong>高级推理架构</strong>可能包含Transformer变体、混合专家模型（MoE）等技术，以支持高层次的逻辑分析和问题解决。<strong>思考签名（Thought Signatures）</strong>机制是实现跨会话或API调用上下文连贯性的关键，可能涉及内部状态管理或记忆网络。模型还集成了<strong>实时数据获取（Real-time Data Retrieval）</strong>与<strong>检索增强生成（RAG）</strong>技术，通过外部工具（如Google Search）获取最新信息，并进行信息“接地”以提高生成内容的准确性和时效性。</p><h5>应用场景</h5><ul><li><strong>AI应用开发</strong>：开发者可在Google AI Studio、Vertex AI、Google Antigravity等平台构建和部署各类AI应用。</li><li><strong>复杂问题解决</strong>：应用于科学研究、数学问题求解、算法设计（如AlphaEvolve）等需要高水平推理的领域。</li><li><strong>多模态内容创作</strong>：生成图像、代码、文案等创意内容，辅助设计、编程和自动化写作。</li><li><strong>智能助理与对话系统</strong>：驱动更智能的对话式AI和个人助理，提供高级理解与交互能力。</li><li><strong>企业级解决方案</strong>：通过Vertex AI为企业提供定制化的AI能力，支持业务流程优化和数据分析。</li><li><strong>教育与研究</strong>：在AI教育、数学定理证明（AlphaProof）和几何问题解决（AlphaGeometry）等领域提供强大的辅助。</li><li><a href="https://link.segmentfault.com/?enc=3XZHLuPEISoWsbMP75RZaQ%3D%3D.tJaBcGoVzhNrwLVgU0MGGy6UmKLMmuOfEebpRLOCiAJsJ436q2QI3C8MPNYNqSEg" rel="nofollow" target="_blank">https://deepmind.google/models/gemini/</a></li></ul><h3>GPT-5.1-Codex-Max</h3><p>GPT-5.1-Codex-Max 是由 OpenAI 推出的高级智能编程模型，旨在处理复杂且长周期的开发任务。它是 GPT-5.1 系列的演进版本，特别为智能代理编码工作流程进行了优化，并已集成到 OpenAI 的 Codex 平台中。该模型以更快的速度、更高的智能和效率，显著提升了开发者在软件工程任务中的表现，并能有效降低开发成本。</p><h5>核心功能</h5><ul><li><strong>复杂任务处理：</strong> 能够处理数百万 token 的大规模任务，例如项目级的代码重构和深度调试。</li><li><strong>上下文压缩：</strong> 引入内置的上下文压缩技术，使其能够跨越多个上下文窗口，有效解决AI编码助手在处理长任务时上下文丢失的问题。</li><li><strong>Windows原生支持：</strong> 首次原生支持 Windows 环境运行，并提供 Windows Agent 模式，允许AI以最小的人工干预读取、写入和执行代码。</li><li><strong>高效编程：</strong> 在代码审查、前端开发等真实软件工程任务中表现出色，显著提升 token 效率。</li><li><strong>集成与扩展：</strong> 已集成到 Codex 平台，支持命令行界面 (CLI)、集成开发环境 (IDE) 扩展、云端部署以及代码审查功能。</li></ul><h5>技术原理</h5><p>GPT-5.1-Codex-Max 基于更新的<strong>基础推理架构</strong>构建，该架构经过专门训练，以处理软件工程、数学和研究等领域的<strong>智能代理任务 (Agentic Tasks)</strong>。其核心技术亮点在于创新的<strong>“压缩”技术 (Context Compaction)</strong>，使得模型能够有效地管理和利用跨越多个上下文窗口的信息，从而克服了传统模型在处理大规模、长周期任务时上下文限制的挑战。此外，其对 Windows 环境的<strong>原生支持</strong>和<strong>Windows Agent 模式</strong>，表明模型具备了在特定操作系统环境下进行<strong>自主代码操作和执行</strong>的能力。</p><h5>应用场景</h5><ul><li><strong>软件开发：</strong> 进行大规模代码重构、复杂项目调试、代码审查、前端开发等。</li><li><strong>教育与研究：</strong> 辅助编程教学、进行复杂的数学问题求解以及科学研究中的代码生成与分析。</li><li><strong>自动化编程：</strong> 在企业级开发环境中，作为智能代理自动执行编码、测试和部署任务。</li><li><strong>跨平台开发：</strong> 特别适用于需要在 Windows 操作系统环境下进行开发和部署的场景。</li><li><a href="https://link.segmentfault.com/?enc=2U3uFtv%2FEIanMmI2vCDqJA%3D%3D.BFv0MbymTStPHJcHZg8dIL06QfpkD47QEX17xjsGDYG4CdJPf730Vtxn9iM%2F9wSP" rel="nofollow" target="_blank">https://openai.com/index/gpt-5-1-codex-max/</a></li></ul><h2>2.每周项目推荐</h2><h3>HunyuanVideo 1.5</h3><p>HunyuanVideo 1.5是腾讯混元团队推出的轻量级、功能强大的开源视频生成模型。它以仅8.3B的参数量，在视频生成领域实现了领先的视觉质量和运动连贯性，有效降低了视频创作的门槛。该模型旨在提供媲美甚至超越顶尖闭源模型的视频生成能力，并支持在消费级GPU上运行。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047420303" alt="hunyuan1.5.png" title="hunyuan1.5.png" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047420304" alt="hunyuan1.5-dit.png" title="hunyuan1.5-dit.png" loading="lazy"/></p><h5>核心功能</h5><ul><li><strong>文本到视频生成 (Text-to-Video, T2V)</strong>：通过文本描述直接生成高质量视频内容。</li><li><strong>图像到视频生成 (Image-to-Video, I2V)</strong>：以参考图像为基础，生成动态视频序列。</li><li><strong>多风格视频生成</strong>：支持在真实感与虚拟艺术风格之间自由切换，实现电影级的视频质量和艺术表现力。</li><li><strong>导演级镜头能力</strong>：具备生成自然衔接的场景过渡和连续动作的能力，支持复杂的运镜效果。</li><li><strong>高保真音频驱动人像动画 (HunyuanVideo-Avatar)</strong>：通过音频输入，生成具有动态、情感可控和多角色对话能力的人像视频动画。</li><li><strong>细致的动作与表情驱动</strong>：能够精确解析人物的姿态、动作和细微情感表达，并将其转化为视频内容。</li></ul><h5>技术原理</h5><p>HunyuanVideo 1.5基于先进的<strong>扩散模型 (Diffusion Model)</strong> 架构，结合了<strong>多模态扩散Transformer (MM-DiT)</strong> 技术，以实现对视频内容的高效生成与控制。其关键技术创新包括：</p><ul><li><strong>轻量级参数设计</strong>：通过优化模型架构，将参数量控制在8.3B，同时保持卓越性能。</li><li><strong>角色图像注入模块 (Character Image Injection Module)</strong>：确保生成视频中角色形象的一致性。</li><li><strong>音频情感模块 (Audio Emotion Module, AEM)</strong>：实现音频与生成角色情感表达的精确对齐与控制。</li><li><strong>面部感知音频适配器 (Face-Aware Audio Adapter, FAA)</strong>：通过潜在层面具遮罩隔离音频驱动的角色，支持多角色场景中的独立音频注入和跨注意力机制。</li><li><strong>TeaCache优化</strong>：在HunyuanVideo-Avatar等模型中，通过引入TeaCache技术，显著降低了GPU显存需求，使其能在单张低显存GPU上运行。</li></ul><h5>应用场景</h5><ul><li><strong>内容创作</strong>：为电影、动画、短视频等行业提供高效的视频生成工具，加速创意实现。</li><li><strong>广告与营销</strong>：快速制作具有吸引力的视频广告和宣传内容，提升营销效率。</li><li><strong>教育与培训</strong>：生成教学视频、模拟场景，丰富教育资源。</li><li><strong>个性化娱乐</strong>：开发个性化故事、虚拟偶像互动、游戏角色动画等，提升用户体验。</li><li><strong>数字人与虚拟直播</strong>：通过高保真音频驱动动画，应用于数字主播、虚拟会议等场景。</li><li><strong>艺术创作</strong>：为艺术家提供新的创作介质，探索视觉艺术的边界。</li></ul><ul><li><a href="https://link.segmentfault.com/?enc=3Hb1vfj80ZZqlXsQq8xZtA%3D%3D.kvKPc3yfpOMsHYXqX4xQxV%2FQLqaxE2LWcf3p4QU%2B6JfSKFbLF%2FTANNDLK1fAay7t6BDINfiisL2bbsyGfZRfR%2F5Q44JsxNJog2li7rEEKSk%3D" rel="nofollow" target="_blank">https://github.com/Tencent-Hunyuan/HunyuanVideo-1.5/blob/main/README_CN.md</a></li><li>项目官网：<a href="https://link.segmentfault.com/?enc=IU3giPwLhv0pWqqt%2BJie4g%3D%3D.DuVcVgDlc43jz9SyIe1t7aCSS%2F4yhld8oEtDjLwX62d8YJClDvaT6HTiySz%2FSKLa" rel="nofollow" target="_blank">https://hunyuan.tencent.com/video/</a></li><li>GitHub仓库：<a href="https://link.segmentfault.com/?enc=P%2FO8BDARPa2Zit7bO7eMkg%3D%3D.0eCTckz62KZFGJlqntlZ89r5U6qPW0an10Am0TTcXFq70YWGYxwsQ9gxSymEv%2FrDFEr7F%2BFFJ8NZ1EjExG5RaA%3D%3D" rel="nofollow" target="_blank">https://github.com/Tencent-Hunyuan/HunyuanVideo-1.5</a></li></ul><h3>SAM 3D – Meta开源的3D生成模型</h3><p>SAM 3D 是Meta AI推出的先进3D重建模型套件，旨在将2D图像转化为精确的3D重建。它包含两个主要子模型：SAM 3D Objects，用于物体和场景的3D重建；以及SAM 3D Body，专注于人体姿态和形状的估算。SAM 3D模型扩展了“可提示（promptable）”视觉的概念，能够从单一图像中捕捉并还原丰富的3D信息，包括几何形状、纹理和布局，以及人体网格模型。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047420305" alt="sam3d.png" title="sam3d.png" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047420306" alt="sam3d-intro.png" title="sam3d-intro.png" loading="lazy"/></p><h5>核心功能</h5><ul><li><strong>单图像3D重建</strong>：能够从一张2D图像中重建出物体的3D模型，包括其几何结构、纹理和空间布局。</li><li><strong>人体网格恢复</strong>：精确估计图像中人物的全身3D网格模型，包括身体、手部和脚部的姿态与形状。</li><li><strong>可提示式推理</strong>：支持辅助提示（如2D关键点和掩码），允许用户引导模型进行更精确的3D重建。</li><li><strong>场景和对象理解</strong>：为静态2D图像带来对3D世界更深层次的理解，实现物体和场景的语义分割与3D表征。</li></ul><h5>技术原理</h5><p>SAM 3D采用生成模型（Generative Model）架构，实现视觉接地的3D重建。</p><ul><li><strong>SAM 3D Objects</strong>：其核心机制是通过深度学习模型分析单张图像，预测并生成物体的三维几何形状、表面纹理以及在三维空间中的位置和方向。这通常涉及到一个编码器-解码器结构，编码器提取2D图像特征，解码器则将其映射到3D表示（如体素、点云或网格）。</li><li><strong>SAM 3D Body</strong>：基于<strong>Momentum Human Rig (MHR)</strong> 这一参数化网格表示。MHR通过解耦骨骼结构和表面形状，提高了人体姿态和形状估计的准确性和可解释性。模型同样采用编码器-解码器架构，并利用2D关键点和掩码作为辅助提示，引导模型从图像中恢复完整的人体3D网格。这种“可提示”的特性使其能够像SAM系列模型一样，支持用户引导的推理过程。</li></ul><h5>应用场景</h5><ul><li><strong>虚拟现实（VR）与增强现实（AR）</strong>：快速生成高保真的3D资产，用于构建沉浸式虚拟环境或将真实世界物体融入数字空间。</li><li><strong>内容创作</strong>：为游戏开发、电影制作、广告设计等领域提供高效的3D模型创建工具，显著缩短建模周期。</li><li><strong>数字人与虚拟试穿</strong>：精确重建人体3D模型，应用于虚拟服装试穿、数字替身制作以及虚拟形象定制。</li><li><strong>机器人与计算机视觉</strong>：帮助机器人理解三维物理世界，进行更精确的物体识别、抓取和环境交互。</li><li><strong>文化遗产数字化</strong>：从历史照片或图像中重建文物、建筑的3D模型，用于保护、研究和展示。</li><li>项目官网：<a href="https://link.segmentfault.com/?enc=mugNTa%2FoFFLly%2F60cFQp1w%3D%3D.F%2BMomOkGksY98NZUor9ysYOdIYXIbp%2B2HRn2BpSSB8I%3D" rel="nofollow" target="_blank">https://ai.meta.com/sam3d/</a></li><li><p>GitHub仓库：</p><ul><li>SAM 3D Body：<a href="https://link.segmentfault.com/?enc=pMbt%2F3CDKOeWXdMFtDM1tg%3D%3D.UmWY4Pa9EVRMS5oCOx9jy1RA7KCBWQ4cQSREVClSPpv%2BEaVaTSmnJ%2BFcHpjwDhfh" rel="nofollow" target="_blank">https://github.com/facebookresearch/sam-3d-body</a></li><li>SAM 3D Objects：<a href="https://link.segmentfault.com/?enc=woT3q4D1ApbN%2FKNx04UU4A%3D%3D.iDXKF2cE7RUVierIh%2Ffq8Yu3R%2FHe4RS%2FWcZkhAJo7sBfuu3yxsb4pHAM8TOIKmGqIW7lBro6ocltM4ucpM3dCA%3D%3D" rel="nofollow" target="_blank">https://github.com/facebookresearch/sam-3d-objects</a></li></ul></li></ul><h3>SAM 3 – Meta开源的视觉分割模型</h3><p>Meta Segment Anything Model 3 (SAM 3) 是Meta AI最新推出的先进统一计算机视觉模型，旨在通过文本、示例图像和视觉提示，实现对图像和视频中对象的精准检测、分割和跟踪。它在前代SAM模型的基础上，增强了对概念性提示（如名词短语）和视觉提示（如掩码、边界框、点）的理解和处理能力。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047420307" alt="sam3.png" title="sam3.png" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047420308" alt="sa3_co_dataset.jpg" title="sa3_co_dataset.jpg" loading="lazy"/></p><h5>核心功能</h5><ul><li><strong>对象检测与分割：</strong> 能够识别图像和视频中的任意对象并精确描绘其边界。</li><li><strong>对象跟踪：</strong> 在视频序列中持续追踪特定对象的运动和状态。</li><li><strong>多模态提示支持：</strong> 接受文本描述（概念提示）、示例图像以及视觉提示（如掩码、边界框、点）作为输入，指导分割任务。</li><li><strong>交互式实例分割：</strong> 支持用户通过简单交互快速完成复杂对象的分割。</li><li><strong>模型微调：</strong> 提供代码和工具，允许开发者对模型进行推理和微调，以适应特定任务和数据集。</li></ul><h5>技术原理</h5><p>SAM 3 作为一个统一模型，其核心技术在于融合了多种输入模态的编码能力。它利用了来源于 Meta Perception Encoder 的文本和图像编码器，将概念性提示（如自然语言描述或图像示例）与视觉提示（如像素级的掩码或坐标信息）相结合，转化为模型可理解的表示。这种多模态融合使得模型能够从更抽象的层面理解用户的意图，并实现“感知一切”的通用分割能力。模型设计上可能采用Transformer架构，以处理序列化的视觉和文本信息，并生成高质量的分割掩码。</p><h5>应用场景</h5><ul><li><strong>图像与视频编辑：</strong> 实现快速精准的对象抠图、背景移除和风格迁移等。</li><li><strong>增强现实（AR）/虚拟现实（VR）：</strong> 精准识别和跟踪现实世界对象，用于虚拟内容的叠加和交互。</li><li><strong>内容理解与分析：</strong> 帮助机器更好地理解图像和视频内容，应用于场景解析、行为识别等。</li><li><strong>机器人与自动化：</strong> 赋予机器人环境感知能力，支持对象抓取、导航和交互。</li><li><strong>医学影像分析：</strong> 辅助医生进行病灶区域的自动分割和测量。</li><li><strong>多模态大语言模型（MLLM）工具：</strong> 作为MLLM的视觉组件，提升其对图像中具体对象的理解和操作能力。</li><li><strong>SAM 3D（Meta的先进3D重建模型）</strong> 能够从单张图像重建物体和场景的3D模型，提供空间理解和应用新机会。</li><li>项目官网：<a href="https://link.segmentfault.com/?enc=d5jrx%2BcOjn%2BU5%2BCrCFWFXw%3D%3D.56u7opzkhYKCRHiqJCe01brlST2P9MhP8GN4LWXtPlE%3D" rel="nofollow" target="_blank">https://ai.meta.com/sam3/</a></li><li>GitHub仓库：<a href="https://link.segmentfault.com/?enc=1sW40W4HYCYq9GrOMqDouw%3D%3D.Mvi8Pnfnbv2CTH1EhV6x36%2Bi5fbLVDOZFfXza%2F5qI8cbjiRBlEqodeuzMYPBMV7o" rel="nofollow" target="_blank">https://github.com/facebookresearch/sam3/</a></li></ul><h2>3. AI-Compass</h2><p><strong>AI-Compass</strong> 致力于构建最全面、最实用、最前沿的AI技术学习和实践生态，通过六大核心模块的系统化组织，为不同层次的学习者和开发者提供从完整学习路径。</p><ul><li>github地址：<a href="https://link.segmentfault.com/?enc=veo5U6ABNwd4du2l4d0Ytg%3D%3D.bLRIKdEqTweYiyXZxbRsTve0w3emrW39%2BH16Bocq8mbq22nT22Yu1mOSK0UfEVHL" rel="nofollow" target="_blank">AI-Compass👈：https://github.com/tingaicompass/AI-Compass</a></li><li>gitee地址：<a href="https://link.segmentfault.com/?enc=zIoJYORIwUDpeN78kYUVhg%3D%3D.mRxup9w59m2U6yebA05fwxa5sKzUfmPud21p4l6tm1CDX5I%2BVT3Zuvk9vZ4nfk1W" rel="nofollow" target="_blank">AI-Compass👈：https://gitee.com/tingaicompass/ai-compass</a></li></ul><p>🌟 如果本项目对您有所帮助，请为我们点亮一颗星！🌟</p><h4>📋 核心模块架构：</h4><ul><li><strong>🧠 基础知识模块</strong>：涵盖AI导航工具、Prompt工程、LLM测评、语言模型、多模态模型等核心理论基础</li><li><strong>⚙️ 技术框架模块</strong>：包含Embedding模型、训练框架、推理部署、评估框架、RLHF等技术栈</li><li><strong>🚀 应用实践模块</strong>：聚焦RAG+workflow、Agent、GraphRAG、MCP+A2A等前沿应用架构</li><li><strong>🛠️ 产品与工具模块</strong>：整合AI应用、AI产品、竞赛资源等实战内容</li><li><strong>🏢 企业开源模块</strong>：汇集华为、腾讯、阿里、百度飞桨、Datawhale等企业级开源资源</li><li><strong>🌐 社区与平台模块</strong>：提供学习平台、技术文章、社区论坛等生态资源</li></ul><h4>📚 适用人群：</h4><ul><li><strong>AI初学者</strong>：提供系统化的学习路径和基础知识体系，快速建立AI技术认知框架</li><li><strong>技术开发者</strong>：深度技术资源和工程实践指南，提升AI项目开发和部署能力</li><li><strong>产品经理</strong>：AI产品设计方法论和市场案例分析，掌握AI产品化策略</li><li><strong>研究人员</strong>：前沿技术趋势和学术资源，拓展AI应用研究边界</li><li><strong>企业团队</strong>：完整的AI技术选型和落地方案，加速企业AI转型进程</li><li><strong>求职者</strong>：全面的面试准备资源和项目实战经验，提升AI领域竞争力</li></ul>]]></description></item><item>    <title><![CDATA[征程 6E/M 计算平台部署指南 地平线]]></title>    <link>https://segmentfault.com/a/1190000047420356</link>    <guid>https://segmentfault.com/a/1190000047420356</guid>    <pubDate>2025-11-22 17:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>1. 前言</h2><p>本文旨在提供 征程 6E/M 计算平台的部署指南，将会从硬件、软件两部分进行介绍，本文整理了我们推荐的使用流程，和大家可能会用到的一些工具特性，以便于您更好地理解工具链。某个工具具体详细的使用说明，还请参考用户手册。</p><h2>2. 征程 6EM 硬件配置</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047420358" alt="" title=""/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047420359" alt="image.png" title="image.png" loading="lazy"/></p><p>BPU 内部器件：</p><ul><li><strong>TAE</strong>：BPU 内部的张量加速引擎，主要用于 Conv、MatMul、Linear 等 Gemm 类算子加速，支持 int8/int16 输入，int8/int16/int32 输出（仅模型输出层支持 int32 输出）</li><li><strong>AAE</strong>：Pooling、Resizer、Warping 等偏专用单元的集合，其中 Warping 可用于加速 Gridsample 等算子</li><li><strong>DTE</strong>：BPU 内部的数据排布变换引擎，支持各种维度的高效变换</li><li><strong>VAE</strong>：BPU 内部的 SIMD 向量加速引擎，可用于加速 Add、Mul、查表等 Vector 计算</li><li><strong>VPU</strong>：BPU 内部的 SIMT 向量加速单元，征程 6EM 可用于实现 Quantize、Dequantize 等算子</li><li><strong>SPU</strong>：BPU 内部的 RISC-V 标量加速单元，征程 6EM 可用于实现 TopK 等算子</li><li><strong>APM</strong>：BPU 内部另一块 RISC-V 标量加速单元，主要用于 BPU 任务调度等功能</li></ul><h2>3. 征程 6EM 工具链简介</h2><h3>3.1 模块架构图</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047420360" alt="" title="" loading="lazy"/></p><ul><li><strong>PTQ</strong>：征程 6 工具链基于 <code>horizon_tc_ui</code> 包封装的 <code>hb_compile</code> 命令行工具，提供 ONNX 模型 PTQ 全流程转换能力，其内部会先调用 <code>hmct</code> 包实现模型解析、图优化、校准功能，再调用 <code>hbdk4_compiler</code> 包实现模型的定点化和编译功能；</li><li><strong>QAT</strong>：征程 6 工具链基于 <code>horizon_plugin_pytorch</code> 包提供量化感知训练能力；</li><li><strong>HBDK</strong>：征程 6 工具链编译器，基于 <code>hbdk4_compiler</code> 包提供模型定点化、图修改、模型编译、静态 perf 等功能；</li><li><strong>高效模型算法包</strong>：征程 6 工具链基于 <code>horizon-torch-samples</code> 包，以源码开放形式提供了多场景参考算法，这些模型基于开源数据集训练，模型结构贴合地平线芯片进行了高效且用户友好的设计，并基于 QAT 链路实现了模型的量化转换；</li><li><strong>UCP</strong>：征程 6 工具链统一计算平台，通过一套统一的异构编程接口实现了对 征程 6 计算平台相关计算资源的调用，提供视觉处理、模型推理、高性能计算库、自定义算子插件开发等功能；</li><li><strong>AI-Benchmark</strong>：征程 6 工具链基于预编译好模型提供的嵌入式工程示例，可实现模型的性能评测和精度评测。</li></ul><h3>3.2 两套模型转换链路</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047420361" alt="" title="" loading="lazy"/></p><p>征程 6EM 工具链支持 PTQ（训练后量化）、QAT（量化感知训练）两套模型转换链路，其特性和优缺点如下：</p><ul><li><strong>PTQ</strong>：基于 <code>hb_compile</code> 命令行工具转换模型，配置好 yaml、校准数据集后，可一步实现模型的图优化、校准、量化、编译全流程。​<strong>该量化方式快捷易用，但仅基于数学统计的方式量化不利于模型迭代，且可能会触发难以解决的 corner case</strong>​，因此在量产项目中通常用于早期评测和简单模型的量化。</li><li><strong>QAT</strong>：在 PyTorch 开源框架上，基于 <code>plugin</code> 插件的形式提供模型量化能力，并调用 <code>hbdk</code> 编译器的 API 实现模型的定点化和编译。该链路支持模型校准后进一步的 finetune 训练，虽然上手难度和训练成本都较高，​<strong>但精度上限也更高，更利于模型迭代优化</strong>​，是量产项目中的更优选择。</li></ul><h3>3.3 工具链推荐使用流程</h3><p>鉴于两条量化链路的特性，我们建议的工具链使用流程如下：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047420362" alt="" title="" loading="lazy"/></p><ol><li><strong>Step1</strong>：先导出浮点 ONNX 模型（opset10～19），并基于 PTQ 链路进行快速的模型结构验证，全 int8 性能上限验证；若该性能符合预期，则可以精调 PTQ，若最终精度/精度都可同时满足预期，则可进行板端部署。</li><li><strong>Step2</strong>：如果遇到 PTQ 无法解决的精度 corner case，则需要转到 QAT 链路进行量化。依然建议先进行模型结构验证和全 int8 性能上限验证；若该性能符合预期，则优先在全 int16 配置下将精度训练至符合预期，然后再降低 int16 比例，实现 int8/int16 混合精度下的性能/精度调优，最终进行板端部署。</li></ol><p>在以上推荐链路中：</p><ol><li>PTQ 链路的模型结构验证和标准量化，可在 X86 端参考本文 4.2 节使用 <code>hb_compile</code> 命令行工具；</li><li>模型性能分析和验证，可在 X86 端参考本文 6.4 节《静态 perf》使用 <code>hbm_perf</code> 接口生成 html 分析文件，可在板端参考本文 8.2.1 节使用 <code>hrt_model_exec</code> 工具；</li><li>模型推理，可在 X86 端参考用户手册《&lt;u&gt;<a href="https://link.segmentfault.com/?enc=yKjZlCJwPe9WIeJ7ExdHYw%3D%3D.5S9uf05rbH7hIsssxECWXRqMrVHOS3RK2mhPtaOzv2cTaEokS1Ej23STwDw01mk4j0094qRV3uYXm5c4SaijCw%3D%3D" rel="nofollow" target="_blank">训练后量化-PTQ 转换工具-HBRuntime 推理库</a>&lt;/u&gt;》，可在板端参考本文第 8 章《模型板端部署》使用 UCP 推理接口；</li><li>模型性能/精度调优，请见后续文章的详细介绍。</li></ol><h2>4. PTQ 链路</h2><h3>4.1 模型转换流程</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047420363" alt="" title="" loading="lazy"/></p><h3>4.2 hb\_compile 工具</h3><p><code>hb_compile</code> 为 PTQ 模型转换的命令行工具，支持以下 3 种使用方式：</p><table><thead><tr><th>hb_compile<strong>--march</strong>nash-m<strong>-m</strong>xxx.onnx</th><th>模型检查，用于早期确认是否有 征程 6E/M 不支持的结构或算子</th></tr></thead><tbody><tr><td>hb_compile<strong>--march</strong>nash-m<strong>-m</strong>xxx.onnx<strong>--fast-perf</strong></td></tr><tr><td>快速性能评测，用于验证性能上限，工具会生成在板端运行性能最高的模型，工具内部主要会执行：</td></tr></tbody></table><p>将 BPU 可执行算子算尽可能地运行在 BPU 上（int8）<br/>删除模型首尾部可删除算子，如 Quantize/Dequantize、Cast、Transpose、、Reshape 等<br/>该功能执行后会在 。fast\_perf 隐藏文件夹下生成一个 yaml 文件，您可以在其基础上做二次修改复用。 |<br/>| hb_compile<strong>-c config.yaml</strong>                                          | 标准模型转换流程，精调模型性能/精度                                                                                                                                                                                                                                                                                   |</p><h3>4.3 PTQ 模型产出物</h3><table><thead><tr><th><strong>original\_float.onnx</strong></th><th>浮点</th><th>对 Caffe1.0 模型进行解析，转成 ONNX</th></tr></thead><tbody><tr><td><strong>optimized\_float.onnx</strong></td><td>浮点</td><td>图优化，例如 BN 融合到 Conv</td></tr><tr><td><strong>calibrated.onnx</strong></td><td>伪量化</td><td>插入校准节点，并基于校准数据计算统计到每个节点的量化参数</td></tr><tr><td><strong>ptq.onnx</strong></td><td>查表算子定点 + 其他算子伪量化</td><td>将查表算子定点化</td></tr><tr><td><strong>quantized.bc</strong></td><td>定点</td><td>整个模型定点化，并转换为地平线 hbir 中间表达</td></tr><tr><td><strong>hbm</strong></td><td>指令集</td><td>经过编译后的最终部署模型</td></tr></tbody></table><h3>4.4 PTQ 精度配置方法</h3><p>在 config.yaml 中，支持通过 json 的方式配置 ​<strong>全局</strong>​、​<strong>某类算子</strong>​、​<strong>某个子图</strong>​、<strong>某个节点 ​</strong>的计算精度，可根据 BPU 算子支持约束进行配置。</p><pre><code class="Plain"># 校准参数组
calibration_parameters:
  quant_config: './quant_config.json'</code></pre><h3>4.5 PTQ 精度调优流程</h3><p>请参考用户手册《&lt;u&gt;<a href="https://link.segmentfault.com/?enc=H1ovMWJ1ZMDcRYn3OP9mAA%3D%3D.JM7rwYKay%2FxjyN6bb6%2FM07EktQSlS72C8b%2BFu5wwEoMsNtGmghHlvVIoivZHUnQAxXLVC1hC7d7%2BDUPNgFqOuR0SLfFUL5FSDMAAX1gjqNk%3D" rel="nofollow" target="_blank">训练后量化-PTQ 转换步骤-模型精度调优</a>&lt;/u&gt;》和《训练后量化-PTQ 转换步骤-精度调优实战》章节。</p><h2>5. QAT 链路</h2><h3>5.1 模型转换流程</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047420364" alt="" title="" loading="lazy"/></p><ul><li><strong>浮点模型改造​</strong>：在模型前插入 QuantStub、在模型后插入 DequantStub，用于识别模型首尾部，剥离前后处理</li><li><p><strong>模型校准</strong>：通过在模型中插入 Observer 的方式，在 forward 过程中统计各处的数据分布，以计算出量化参数</p><ul><li>部分模型仅通过 Calibration 便可满足精度要求，则无需进行 QAT，可直接编译模型用于部署</li><li>即使 Calibration 无法满足精度要求，也可降低后续 QAT 难度，缩短训练时间，提升最终训练精度</li></ul></li><li><p><strong>量化感知训练</strong>：进一步通过训练的方式微调模型参数，如果 Calibration 精度较好，则推荐固定激活 scale</p><ul><li><p>JIT-STRIP：使用 hook 和 subclass tensor 的方式感知图结构，在原有 forward 上做算子替换/算子融合等操作，并且会根据模型中 QuantStub 和 DequantStub 的位置识别并跳过前后处理</p><ul><li>优点：全自动，代码修改少，屏蔽了很多细节问题，便于 debug</li><li>缺点：动态代码块仍需要特殊处理</li></ul></li></ul></li></ul><h3>5.2 QAT 精度配置方法</h3><p>请见后续文章。</p><h3>5.3 QAT 精度调优流程</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047420365" alt="" title="" loading="lazy"/></p><h2>6. 模型导出/定点化/编译</h2><h3>6.1 PTQ 链路</h3><p>该流程封装在 <code>hb_compile</code> 中，相关参数通过 yaml 进行配置。若自行调用编译器接口执行，参考代码如下：</p><pre><code class="Plain">import onnx
from hbdk4.compiler.onnx import export
from hbdk4.compiler import convert, save, compile

# 经过PTQ校准得到的伪量化onnx模型，非线性的查表算子已定点
ptq_model = onnx.load("xxx_ptq_model.onnx")    

# 导出查表算子定点+其他算子伪量化的hbir模型
qat_bc = export(ptq_model)
save(qat_bc, "qat.bc")

# 导出全定点hbir模型
quantized_bc = convert(qat_bc, "nash-b")
save(quantized_bc, "quantized.bc")

# 编译生成hbm模型
compile(
    m=quantized_bc, 
    path="model.hbm", 
    opt=2, 
    march="nash-m", 
    progress_bar=True,
    input_no_padding=True,
    output_no_padding=True
)</code></pre><h4>6.1.1 输入/输出去 padding</h4><p>模型在 BPU 上推理时，其输入和输出节点的内存大小和数据存放规则需满足硬件对齐要求。</p><p><strong>内存对齐</strong>：申请的内存大小需满足某个字节数的整数倍，</p><p><strong>跨距对齐</strong>：跨距（Stride）是指数据存储在内存中时，每一行所占空间的实际大小，当对齐到某个字节数的整数倍后，硬件即可高效处理。该对齐的操作又叫 Padding，实际的对齐规则取决于具体的软硬件系统。假设一份 NHWC 为 1x20x30x1 的 int8 数据，若硬件要求跨距 W32 对齐，那么每一行 W 都将 Padding 2 个字节。</p><p>征程 6 工具链支持在 <code>compile</code> 接口中传入 <code>input_no_padding</code>、<code>output_no_padding</code> 参数来控制是否使用 BPU 自动完成 padding 对齐操作。开启后用户即可不关心 BPU 跨距对齐要求，无需手动 Padding，数据可连续存储在内存中。该特性可优化模型输入/输出的 IO 负载，但也有微小概率会引入性能的小幅下降，所以是否开启该功能请在您的模型上实际验证，并请在模型编译和板端部署环节统一跨距对齐的处理策略。</p><h3>6.2 QAT 链路</h3><p>QAT 链路的模型定点化和编译直接调用如上的编译器接口，模型导出额外封装了一层，参考代码如下：</p><pre><code class="Plain">from horizon_plugin_pytorch.quantization.hbdk4 import export

def export(
    model: nn.Module,
    example_inputs: Any,
    name: str = "forward",
    input_names: Optional[Any] = None,    # 建议在模型导出时就配置好输入输出节点名称
    output_names: Optional[Any] = None,
    input_descs: Optional[Any] = None,
    output_descs: Optional[Any] = None,
    native_pytree: bool = True,
) -&gt; Module</code></pre><h3>6.3 模型修改</h3><p>编译器支持在 hbir 上进行多 batch 拆分、插入数据前处理、算子删除、调整输入输出 layout 等修改操作，其主要应用场景如下：</p><p><strong>多 batch 拆分</strong>：典型场景是 BEV 模型在部署时，多 V 输入来源于不同的摄像头，其数据在内存中独立存储，因此模型可将其多 V 输入沿 batch 维度做拆分；</p><p><strong>数据前处理</strong>：征程 6 工具链支持在模型前端插入一个前处理节点，以实现颜色空间转换（如 NV12—&gt; BGR）、数据归一化（<code>(data-mean)/std</code>），和 Resizer 功能（从大图上抠图 + Resize），并可由 BPU 进行加速；</p><p><strong>算子删除</strong>：征程 6 工具链支持将模型首尾部的 Quantize、Dequantize、Cast、Reshape、Transpose 等算子删除，以适配更加灵活的部署方案；</p><p><strong>调整输入输出 layout</strong>：模型首尾部除了支持删除 Reshape、Transpose 节点外，还支持插入 Transpose 节点，用户可灵活调整其 layout 排布。</p><p>以下参考代码对一个多输入模型实现了多 batch 输入拆分、图像输入的色彩空间转换、数据归一化、Resizer 功能：</p><pre><code class="Plain">from hbdk4.compiler import load, convert

qat_bc = load("qat.bc")  
func = qat_bc[0]
batch_input = ["input_name1"]   # 需要使用独立地址方式部署的输入节点名称列表
resizer_input = ["resize"]      # 部署时数据来源于resizer的输入节点名称列表
pyramid_input = ["pym"]         # 部署时数据来源于pyramid的输入节点名称列表

def channge_source(input, source):
    node = input.insert_transpose(permutes=[0, 3, 1, 2])
    node = node.insert_image_preprocess(mode="yuvbt601full2bgr", divisor=1, mean=[128, 128, 128], std=[128, 128, 128])
    if source == "pyramid":
        node.insert_image_convert("nv12")          
    elif source == "resizer":
        node.insert_roi_resize("nv12")

for input in func.inputs[::-1]:
    if input.name in batch_input:
        origin_name = input.name
        split_inputs = input.insert_split(dim=0)
        for split_input in reversed(split_inputs):
            if origin_name in pyramid_input:
                channge_source(split_input, "pyramid")
            elif origin_name in resizer_input:
                channge_source(split_input, "resizer")</code></pre><h3>6.4 静态 perf</h3><p>对于编译好的 hbm，编译器支持在 X86 端对其 BPU 部分进行静态性能预估，执行以下命令即可生成一个 html 文件，包含模型预估性能、带宽、内存占用、BPU 内部单帧执行时序图等信息。</p><pre><code class="Plain">from hbdk4.compiler import hbm_perf
hbm_perf(model="xxx.hbm", output_dir="./")</code></pre><h2>7. 浮点能力使用</h2><h3>7.1 硬件支持能力</h3><p>征程 6EM BPU 中的 VPU 单元可提供一定的向量浮点计算能力，SPU 单元可提供一定的标量浮点计算能力。因此量化、反量化、TopK 等算子都可直接由 BPU 支持浮点计算，征程 6EM 详细的 BPU 浮点算子支持列表可参考用户手册《&lt;u&gt;<a href="https://link.segmentfault.com/?enc=4aVNlxx%2BabXmL2EXiuMadQ%3D%3D.ObSAJeCDhgSsoIFrIqFEtEeXhMsk8S43Ts6X4keDMjC13WrqVfDF7JhRsS%2B8snDvGLLsM6r3FAXd6A7slfoUTrep9HYD5SDnAqaeNv7MjIxzPfAolHKhRKSZz7PP7VWeWkLpq68sqq%2FOBtvmNliw7WXregdFvB1HReJhGyBhwAM%3D" rel="nofollow" target="_blank">附录-工具链算子支持约束列表-算子 BPU 约束列表</a>&lt;/u&gt;》。</p><p>在 OE-3.5.0 正式版本中，工具链已默认开启 BPU 已支持浮点算子的加速能力，用户仅需在 PTQ/QAT 链路中，将对应算子的量化精度配置为浮点即可使用。</p><h3>7.2 量化/反量化处理</h3><p>在 征程 6EM 平台，因为 VPU 浮点能力的加持，建议模型首尾部的量化/反量化算子可优先尝试将其保留在模型中。</p><p>编译器也同时支持使用以下接口将 quantized.bc 模型首尾部的量化/反量化节点移除，但移除后建议参考该篇文章（&lt;u&gt;<a href="https://link.segmentfault.com/?enc=XOAqKqytrQR%2FLWGxj2ZDZQ%3D%3D.Nu2wCPrblCGlwTi0K%2BQn7sjiKlUrxkPX4F6Qev4xhd8dx7TTHrmZH%2FnsadBsbeP8" rel="nofollow" target="_blank">反量化节点的融合实现</a>&lt;/u&gt;）将其融合进前后处理代码中，以减少一次数据遍历的冗余开销。</p><pre><code class="Plain">from hbdk4.compiler import load

quantized_bc = load("quantized.bc")
quantized_bc[0].remove_io_op(op_types=["Quantize", "Dequantize"])</code></pre><h2>8. 模型板端部署</h2><h3>8.1 UCP 简介</h3><p>UCP（Unify Compute Platform，统一计算平台）定义了一套统一的异构编程接口， 将 SOC 上的功能硬件抽象出来并进行封装，对外提供基于功能的 API 进行调用。UCP 提供的具体功能包括：​<strong>视觉处理</strong>​（Vision Process）、​<strong>神经网络模型推理</strong>​（Neural Network）、​<strong>高性能计算库</strong>​（High Performance Library）、​<strong>自定义算子插件开发</strong>​。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047420366" alt="" title="" loading="lazy"/></p><p>UCP 支持的 Backend 如下：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047420367" alt="" title="" loading="lazy"/></p><h3>8.2 快速上手</h3><p>使用 UCP 推理模型的基本代码参考如下，详细信息可参考用户手册《&lt;u&gt;<a href="https://link.segmentfault.com/?enc=GrDQnPIacktm6FF0g1rjRg%3D%3D.fbfRl7qtRzHqAs7wC9hQG%2FW24LiVz1Ug6HglGpwEYk2pMFoZf7bwSRAlVcbp0MdDN0GmdYDwFcNeGy8ezU6Hjw%3D%3D" rel="nofollow" target="_blank">统一计算平台-模型推理开发</a>&lt;/u&gt;》、《&lt;u&gt;<a href="https://link.segmentfault.com/?enc=%2BIWfv6ccUk%2FRA2jNcjG0Vg%3D%3D.KYsXqwLb2cCKJnC4pR2c%2BROR2CZPzUvaGbHoLcavP4iro02q7wzFgScuqbBvfMRMLAYrkiiA27CXEuMtKcVi3bCXS5XmbxvkeBUMNksOEqB5%2BZ1q5dYx5wW2HrJ%2Bva%2BiIta%2FEz4N6%2Foz6TDWadNqojqNeShdxApjvtPYM0QNkdwx%2FaBBHPfAThgGlR0MMnMv" rel="nofollow" target="_blank">模型部署实践指导-模型部署实践指导实例</a>&lt;/u&gt;》、《&lt;u&gt;<a href="https://link.segmentfault.com/?enc=54CGyJeGcoDzDjUwXjmNBA%3D%3D.2FXJj9JlzFYubF1EguO2HL2v45CXxJlA88E5TABjA3xU3Aob1kufAFN0ejDm1ksSm%2BfGIrZro%2FY1ERy5IePDZeLduZxJHLgDoHodL8eIz7M%3D" rel="nofollow" target="_blank">UCP 通用 API 介绍</a>&lt;/u&gt;》等相关章节。</p><pre><code class="Plain">// 1. 加载模型并获取模型名称列表以及Handle
{
    hbDNNInitializeFromFiles(&amp;packed_dnn_handle, &amp;modelFileName, 1);
    hbDNNGetModelNameList(&amp;model_name_list, &amp;model_count, packed_dnn_handle);
    hbDNNGetModelHandle(&amp;dnn_handle, packed_dnn_handle, model_name_list[0]);
}

// 2. 根据模型的输入输出信息准备张量
std::vector&lt;hbDNNTensor&gt; input_tensors;
std::vector&lt;hbDNNTensor&gt; output_tensors;
int input_count = 0;
int output_count = 0;
{
    hbDNNGetInputCount(&amp;input_count, dnn_handle);
    hbDNNGetOutputCount(&amp;output_count, dnn_handle);
    input_tensors.resize(input_count);
    output_tensors.resize(output_count);
    prepare_tensor(input_tensors.data(), output_tensors.data(), dnn_handle);
}

// 3. 准备输入数据并填入对应的张量中
{
    read_data_2_tensor(input_data, input_tensors);
    // 确保更新输入后进行Flush操作以确保BPU使用正确的数据
    for (int i = 0; i &lt; input_count; i++) {
      hbUCPMemFlush(&amp;input_tensors[i].sysMem, HB_SYS_MEM_CACHE_CLEAN);
    }
}

// 4. 创建任务并进行推理
{
    // 创建任务
    hbDNNInferV2(&amp;task_handle, output_tensors.data(), input_tensors.data(), dnn_handle)
    
    // 提交任务
    hbUCPSchedParam sched_param;
    HB_UCP_INITIALIZE_SCHED_PARAM(&amp;sched_param);
    sched_param.backend = HB_UCP_BPU_CORE_ANY;
    hbUCPSubmitTask(task_handle, &amp;sched_param);
    
    // 等待任务完成
    hbUCPWaitTaskDone(task_handle, 0);
}

// 5. 处理输出数据
{
    // 确保处理输出前进行Flush操作以确保读取的不是缓存中的脏数据
    for (int i = 0; i &lt; output_count; i++) {
      hbUCPMemFlush(&amp;output_tensors[i].sysMem, HB_SYS_MEM_CACHE_INVALIDATE);
    }
    // 对输出进行后处理操作
}

// 6. 释放资源
{
    // 释放任务
    hbUCPReleaseTask(task_handle);
    // 释放输入内存
    for (int i = 0; i &lt; input_count; i++) {
      hbUCPFree(&amp;(input_tensors[i].sysMem));
    }
    // 释放输出内存
    for (int i = 0; i &lt; output_count; i++) {
      hbUCPFree(&amp;(output_tensors[i].sysMem));
    }
    // 释放模型
    hbDNNRelease(packed_dnn_handle);
}</code></pre><h4>8.2.1 hrt\_model\_exec 工具</h4><p>为了方便用户快速查看 hbm 和 quantized.bc 的模型信息、进行模型单帧推理和性能评测，征程 6 工具链 UCP 提供了 <code>hrt_model_exec</code> 工具，并支持编译 X86、aarch64（aarch64 仅支持 hbm 推理）两个架构下的可执行程序。</p><p>hrt\_model\_exec 的三种使用方法如下：</p><pre><code class="Plain"># 设置环境变量
# arch代表架构类型，aarch64或x86
arch=aarch64
bin=../$arch/bin/hrt_model_exec
lib=../$arch/lib/
export LD_LIBRARY_PATH=${lib}:${LD_LIBRARY_PATH}

# 获取模型信息
${bin} model_info --model_file=xxx.hbm

# 模型单帧推理
${bin} infer --model_file=xxx.hbm --input_file=xxx.bin

# 模型性能评测-Latency(单线程)
${bin} perf --model_file=xxx.hbm --thread_num 1 --frame_count=1000

# 模型性能评测-FPS(多线程)
${bin} perf --model_file=xxx.hbm --thread_num 8 --frame_count=1000</code></pre><h3>8.3 图像输入动态 shape/stride</h3><p>在 征程 6 芯片的视频通路上，有一块叫 Pyramid 的金字塔硬件处理模块，可提供 Camera 输入图像的缩放及 ROI 抠图能力，其输出为 nv12 类型的图像数据，并可基于共享内存机制直接给到 BPU 进行模型推理。因此在 征程 6 工具链中：</p><ul><li>Pyramid 模型指的是具有 nv12 图像输入的模型；</li><li>Resizer 模型指的是具有 nv12 图像输入和 ROI 输入的模型，编译器支持通过 JIT 动态指令的方式，从 nv12 图像上完成 ROI 抠图 + Resize 的功能。</li></ul><p>在 征程 6 工具链中，Pyramid 的输入 stride 为动态，Resizer 模型的 stride 和 shape 都是动态。如下为 mobilenetv1 编译后的模型信息：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047420368" alt="" title="" loading="lazy"/></p><p>其中，-1 为占位符，表示为动态，Pyramid 输入的 stride 为动态；Resizer 输入的 H、W、stride 均为动态。</p><ul><li>Resizer 输入的 ​<strong>HW 动态</strong>​，是因为原始输入的大小可以是任意的；</li><li>Pyramid/Resizer 输入的​<strong>​ stride 动态</strong>​，可以理解为是支持 ​<strong>Crop 功能</strong>​，详细内容可参考用户手册《&lt;u&gt;<a href="https://link.segmentfault.com/?enc=zzGNianeWP0AmSR92ew8Yg%3D%3D.HFsqcC86h2tfbhm4plvV6HltwGt%2B8bqxR8k5YdOQPhYZKbhL7fAbiOK2O11iyDet18V7qIoIKB%2FndActOkv7b%2BeCRbCMRDiL30o860VHSP8%3D" rel="nofollow" target="_blank">统一计算平台-模型推理开发-基础示例包使用说明-advanced\_samples-crop</a>&lt;/u&gt;》</li></ul><h3>8.4 非图像 tensor 内存对齐</h3><p>对于非图像 tensor，征程 6EM 要求内存 64 对齐，征程 6B 要求 128 对齐，征程 6PH 要求 256 对齐。如上图所示，模型输出节点虽然 stride[0] 为 4000，但需要申请的 BPU 内存大小（aligned byte size）为 4032，即为 64 对齐的结果。</p><p>在模型实际部署中，非图像输入/输出节点所需申请的内存大小（ aligned byte size）均可从模型节点属性的结构体中读取到（<code>hbDNNTensorProperties</code>），因此无需特别关注。</p><h3>8.5 图像 tensor 跨距对齐</h3><p>征程 6EMB 对于 Pyramid/Resizer 模型的图像输入，要求 W32 对齐，征程 6PH 要求 W64 对齐。若您有 征程 6 不同架构平台迁移的场景，请注意跨距对齐要求的差异。</p><p>部署代码建议您避免 hard code，推荐基于模型节点属性中的 validShape（张量有效内容尺寸）和 stride（张量各维度步长）进行解析和使用。</p><h4>8.5.1 Pyramid 输入</h4><p>Pyramid 输入 tensor 准备的参考代码如下：</p><pre><code class="Plain">hbDNNTensor *input = input_tensor;
for (int i = 0; i &lt; input_count; i++) {
HB_CHECK_SUCCESS(
    hbDNNGetInputTensorProperties(&amp;input[i].properties, dnn_handle, i),
    "hbDNNGetInputTensorProperties failed");
    
    auto dim_len = input[i].properties.validShape.numDimensions;    // 获取维度信息
    for (int32_t dim_i = dim_len - 1; dim_i &gt;= 0; --dim_i) {
      if (input[i].properties.stride[dim_i] == -1) {                // stride=-1即为动态
        auto cur_stride =                                           // 计算当前维度stride
            input[i].properties.stride[dim_i + 1] *
            input[i].properties.validShape.dimensionSize[dim_i + 1];
        input[i].properties.stride[dim_i] = ALIGN_32(cur_stride);   // 32对齐
      }
    }

    int input_memSize = input[i].properties.stride[0] *             // 计算内存大小
                        input[i].properties.validShape.dimensionSize[0];
    HB_CHECK_SUCCESS(hbUCPMallocCached(&amp;input[i].sysMem[0], input_memSize, 0),
                     "hbUCPMallocCached failed");
    
    const char *input_name;
    HB_CHECK_SUCCESS(hbDNNGetInputName(&amp;input_name, dnn_handle, i),    // 获取节点名称
                     "hbDNNGetInputName failed");
}</code></pre><p>示例：</p><pre><code class="Plain">ucp_tutorial/dnn/basic_samples/code/00_quick_start/resnet_nv12/src/main.cc</code></pre><p>​<strong>注意</strong>​：</p><p>视频通路上的金字塔硬件，其输出层支持配置 y、uv 的 stride，但仅要求 W16 对齐，若数据需要喂给 BPU 推理模型，建议直接按 BPU 的跨距对齐要求来配置。金字塔硬件的更多信息请参考系统软件用户手册。</p><h4>8.5.2 Resizer 输入</h4><p>Resizer 输入的 H、W 也是动态的，因此需要设置为原图尺寸，并计算好 W32 对齐的 Stride；ROI 作为模型输入节点，也需要对其进行赋值。以下为参考代码：</p><pre><code class="Plain">#define ALIGN(value, alignment) (((value) + ((alignment)-1)) &amp; ~((alignment)-1))
#define ALIGN_32(value) ALIGN(value, 32)

int prepare_image_tensor(const std::vector&lt;hbUCPSysMem&gt; &amp;image_mem, int input_h,
                         int input_w, hbDNNHandle_t dnn_handle,
                         std::vector&lt;hbDNNTensor&gt; &amp;input_tensor) {
  // 准备Y、UV输入tensor
  for (int i = 0; i &lt; 2; i++) {
    HB_CHECK_SUCCESS(hbDNNGetInputTensorProperties(&amp;input_tensor[i].properties,
                                                   dnn_handle, i),
                     "hbDNNGetInputTensorProperties failed");
    // auto w_stride = ALIGN_32(input_w);
    // int32_t y_mem_size = input_h * w_stride;
    input_tensor[i].sysMem[0] = image_mem[i];

    // 配置原图大小，NHWC
    input_tensor[i].properties.validShape.dimensionSize[1] = input_h;
    input_tensor[i].properties.validShape.dimensionSize[2] = input_w;
    if (i == 1) {
      // UV输入大小为Y的1/2
      input_tensor[i].properties.validShape.dimensionSize[1] /= 2;
      input_tensor[i].properties.validShape.dimensionSize[2] /= 2;
    }

    // stride满足32对齐
    input_tensor[i].properties.stride[1] =
        ALIGN_32(input_tensor[i].properties.stride[2] *
                 input_tensor[i].properties.validShape.dimensionSize[2]);
    input_tensor[i].properties.stride[0] =
        input_tensor[i].properties.stride[1] *
        input_tensor[i].properties.validShape.dimensionSize[1];
  }
  return 0;
}

// 准备roi输入tensor
int prepare_roi_tensor(const hbUCPSysMem *roi_mem, hbDNNHandle_t dnn_handle,
                       int32_t roi_tensor_id, hbDNNTensor *roi_tensor) {
  HB_CHECK_SUCCESS(hbDNNGetInputTensorProperties(&amp;roi_tensor-&gt;properties,
                                                 dnn_handle, roi_tensor_id),
                   "hbDNNGetInputTensorProperties failed");
  roi_tensor-&gt;sysMem[0] = *roi_mem;
  return 0;
}

int prepare_roi_mem(const std::vector&lt;hbDNNRoi&gt; &amp;rois,
                    std::vector&lt;hbUCPSysMem&gt; &amp;roi_mem) {
  auto roi_size = rois.size();
  roi_mem.resize(roi_size);
  for (auto i = 0; i &lt; roi_size; ++i) {
    int32_t mem_size = 4 * sizeof(int32_t);
    HB_CHECK_SUCCESS(hbUCPMallocCached(&amp;roi_mem[i], mem_size, 0),
                     "hbUCPMallocCached failed");
    int32_t *roi_data = reinterpret_cast&lt;int32_t *&gt;(roi_mem[i].virAddr);
    roi_data[0] = rois[i].left;
    roi_data[1] = rois[i].top;
    roi_data[2] = rois[i].right;
    roi_data[3] = rois[i].bottom;
    hbUCPMemFlush(&amp;roi_mem[i], HB_SYS_MEM_CACHE_CLEAN);
  }
  return 0;
}</code></pre><p>示例：</p><pre><code class="Plain">ucp_tutorial/dnn/basic_samples/code/02_advanced_samples/roi_infer/src/roi_infer.cc</code></pre><h3>8.6 小模型批量处理功能</h3><p>由于 BPU 是资源独占式硬件，所以对于 Latency 很小的模型而言，其框架调度开销占比会相对较大。在 征程 6 平台，UCP 支持通过复用 task\_handle 的方式，将多个小模型任务一次性下发，全部执行完成后再一次性返回，从而可将 N 次框架调度开销合并为 1 次，以下为参考代码：</p><pre><code class="Plain">// 获取模型指针并存储
std::vector&lt;hbDNNHandle_t&gt; model_handles;

// 准备各个模型的输入输出，准备过程省略
std::vector&lt;std::vector&lt;hbDNNTensor&gt;&gt; inputs;
std::vector&lt;std::vector&lt;hbDNNTensor&gt;&gt; outputs;

// 创建任务并进行推理
{
    // 创建并添加任务，复用task_handle
    hbUCPTaskHandle_t task_handle{nullptr};
    for(size_t task_id{0U}; task_id &lt; inputs.size(); task_id++){
        hbDNNInferV2(&amp;task_handle, outputs[task_id].data(), inputs[task_id].data(), model_handles[i]);
    }
    
    // 提交任务
    hbUCPSchedParam sche_param;
    HB_UCP_INITIALIZE_SCHED_PARAM(&amp;sche_param);
    sche_param.backend = HB_UCP_BPU_CORE_ANY;
    hbUCPSubmitTask(task_handle, &amp;sche_param);
    
    // 等待任务完成
    hbUCPWaitTaskDone(task_handle, 0);
}</code></pre><h3>8.7 优先级调度/抢占</h3><p>UCP 支持任务优先级调度和抢占，可通过 <code>hbUCPSchedParam</code> 结构体进行配置，其中：</p><ul><li><code>priority</code> &gt; <code>customId</code> &gt; submit\_time（任务提交时间）</li><li><p><code>priority</code> 支持 [0， 255]，对于模型任务而言：</p><ul><li>[0， 253] 为普通优先级，不可抢占其他任务，但在未执行时支持按优先级进行排队</li><li>254 为 high 抢占任务，可支持抢占普通任务</li><li>255 为 urgent 抢占任务，可抢占普通任务和 high 抢占任务</li><li>可被中断抢占的低优任务，需要在模型编译阶段配置 <code>max_time_per_fc</code> 参数拆分模型指令</li></ul></li><li>其他 backend 任务，priority 支持 [0， 255]，但不支持抢占，可以认为都是普通优先级</li></ul><h3>8.8 直连/中继模式</h3><p>UCP 框架还支持两种主要工作模式：直连模式、中继模式。系统默认运行在直连模式下，在中继模式下，UCP 将支持多进程任务的统一调度，即支持 priority 为 [0， 253] 的普通优先级任务的跨进程统一调度。</p><p>使用中继模式前，首先启动 <code>ucp_service</code>，service 文件位于 <code>deps_aarch64/ucp/bin/service/</code> 路径下， 并通过环境变量 <code>HB_UCP_ENABLE_RELAY_MODE=true</code> 启用 Relay 模式，使得用户进程可以通过中继服务进行通信。 无论是直连模式还是中继模式，UCP 接口的调用方式保持一致，不会对编程逻辑产生影响。您可以根据实际需求灵活选择这两种模式，以满足系统在性能和灵活性方面的要求。</p><p><strong>注意：</strong></p><p>中继模式虽然可支持用户统一调度多进程间任务，但是也存在一些缺陷，包括：</p><ol><li>需要做进程间通信和内存共享，整体的 CPU 负载更高；</li><li>模型任务底层资源的竞争都发送于 Service 进程内，相较于直连模式多个独立进程的竞争强度更高，任务的耗时可能受到影响。</li></ol><h3>8.9 X86 仿真</h3><p>征程 6 工具链在 X86 端支持 hbm 指令仿真，但效率非常低，所以更推荐使用 quantized.bc 模型进行推理，其定点部分和 hbm 数值二进制一致，浮点部分可能存在架构本身差异，但通常对精度影响可忽略不计。</p><h4>1. 推理 quantized.bc</h4><p><strong>Python 推理：</strong></p><p>quantized.bc 在 X86 端的推理，可以使用 <code>horizon_tc_ui</code> 包封装的 <code>HBRuntime</code> 接口，具体可见用户手册《&lt;u&gt;<a href="https://link.segmentfault.com/?enc=F1xGP9%2Bj7f7RYmZdVjh8bQ%3D%3D.q%2FCpFI6dD6Oa850rKi5rCAyTeDSqFVc5TYkY6UNGPHrflWfScB68J96vujAZfQfMbJCPvHIYfrbpYlRSATMLeA%3D%3D" rel="nofollow" target="_blank">训练后量化-PTQ 转换工具-HBRuntime 推理库</a>&lt;/u&gt;》，参考代码如下：</p><pre><code class="Plain">import numpy as np
from horizon_tc_ui.hb_runtime import HBRuntime

sess = HBRuntime("quantized.bc")
input_names = sess.input_names
output_names = sess.output_names

data1 = np.load("input1.npy")
data2 = np.load("input2.npy")
input_feed = {input_names[0]: data1, input_names[1]: data2}

output = sess.run(output_names, input_feed)</code></pre><p>quantized.bc 也可以直接调用其 func 的 feed 接口进行推理，其输入格式也为 dict，value 支持 torch.tensor 和 np.array 两种类型，输出格式与输入格式保持一致。参考代码如下：</p><pre><code class="Plain">import numpy as np
from hbdk4.compiler import load

hbir = load("quantized.bc")
func = hbir[0]

data1 = np.load("input1.npy")
data2 = np.load("input2.npy") 
input_feed = {inputs[0].name: data1, inputs[1].name: data2}
hbir_outputs = func.feed(input_feed)</code></pre><p><strong>C++ 推理：</strong></p><p>quantized.bc 的 C++ 推理接口复用 hbm UCP 推理接口，仅 so 动态库需要替换成 X86 版本即可。 您也可以在 X86 端使用 <code>hrt_model_exec</code> 工具对 quantized.bc 进行模型信息查看和单帧推理。</p><h4>2. 推理 hbm</h4><p>由于 X86 端 hbm 推理为指令仿真，运行速度非常慢，因此工具链提供了 <code>hbm_infer</code> 工具以便用户在服务器端给直连的开发板下发推理任务。本文只介绍最简单的单进程使用方式，多进程、多阶段模型输入输出的传输优化，以及统计模型推理、网络传输耗时等功能请参考用户手册《&lt;u&gt;<a href="https://link.segmentfault.com/?enc=6xg8LdMu2Ax5Jd6guaviIA%3D%3D.WaHCuvX4pEGjgcU3vU88Ycoy2Ivy1VKeOeVz4gEESp3nrmYkuwdzySVQ%2BCoCSiPxCk5zSVORDD8jZMYOTGQVPAbIVHwiyHCy1DDOywEDNrY%3D" rel="nofollow" target="_blank">hbm\_infer 工具介绍</a>&lt;/u&gt;》。</p><pre><code class="Plain"># hbm也可传入一个list，推理时通过指定model_name来选择推理哪个模型，推理所用的.so即可只传输一次
hbm_model = HbmRpcSession(
    host="xx.xx.xx.xx",
    local_hbm_path="xx.hbm", 
)

# 打印模型输入输出信息
hbm_model.show_input_output_info()

# 准备输入数据
input_data = {
    'img': torch.ones((1, 3, 224, 224), dtype=torch.int8)
}

# 执行推理并返回结果
# 若传入的是list，需要正确指定model_name
# output_data = hbm_model(input_data, model_name=model_name)
output_data = hbm_model(input_data) 

print([output_data[k].shape for k in output_data])

# 关闭server
hbm_model.close_server()</code></pre><h2>9. UCP 视觉处理/高性能算子</h2><p>除模型推理外，UCP 还提供了视觉处理和高性能算子两大方向的多种算子接口，可支持诸如 Remap、Jpeg、H264/265、FFT/IFF 等功能，这些算子底层是基于地平线 SOC 上不同硬件 IP 进行的封装，并提供统一的调用接口。</p><p>更多信息可参考用户手册《&lt;u&gt;<a href="https://link.segmentfault.com/?enc=dLqzeU3eAVmDphO%2BLvhtqg%3D%3D.sTUM9x%2BpbwNYy6G8GQJ2Vei4HOGpW9pGMQNfy%2BICgbL36C7%2FCxeXCHM4Du1eP%2BtZiWmXcVGrAiszFvvQbtJG8g%3D%3D" rel="nofollow" target="_blank">统一计算平台</a>&lt;/u&gt;》的相关章节。</p><p><strong>注意：</strong></p><p>板端实际部署时，ISP 到 Pyramid 的视频通路不建议使用 UCP，无法实现数据 Online，建议直接调用底软接口进行功能实现。</p><h2>10. UCP 自定义算子（DSP）</h2><p>为了简化用户开发，UCP 封装了一套基于 RPC 的开发框架，来实现 CPU 对 DSP 的功能调用，但具体 DSP 算子实现仍是调用 Cadence 接口去做开发。总体来说可分为三个步骤：</p><ol><li>使用 Cadence 提供的工具及资料完成算子开发；</li></ol><pre><code class="Plain">int test_custom_op(void *input, void *output, void *tm) {
  // custom impl
  return 0;
}</code></pre><ol start="2"><li>DSP 侧通过 UCP 提供的 API 注册算子，编译带自定义算子的镜像；</li></ol><pre><code class="Plain">// dsp镜像中注册自定义算子
hb_dsp_register_fn(cmd, test_custom_op, latency)</code></pre><ol start="3"><li>ARM 侧通过 UCP 提供的算子调用接口，完成开发板上的部署使用。</li></ol><pre><code class="Plain">// 将输入输出的hbUCPSysMem映射为DSP可访问的内存地址
hbUCPSysMem in;
hbUCPMalloc(&amp;in, in_size, 0)
hbDSPAddrMap(&amp;in, &amp;in)

hbUCPSysMem out;
hbUCPMalloc(&amp;out, out_size, 0)
hbDSPAddrMap(&amp;out, &amp;out)

// 创建并提交DSP任务
hbUCPTaskHandle_t taskHandle{nullptr};
hbDSPRpcV2(&amp;taskHandle, &amp;in, &amp;out, cmd)

hbUCPSchedParam ctrl_param;
HB_UCP_INITIALIZE_SCHED_PARAM(&amp;ctrl_param);
ctrl_param.backend = HB_UCP_DSP_CORE_ANY;
hbUCPSubmitTask(task_handle, &amp;ctrl_param);

// 等待任务完成
hbUCPWaitTaskDone(task_handle, 0);</code></pre><p>更多信息可见用户手册《&lt;u&gt;<a href="https://link.segmentfault.com/?enc=dVe2mSjyWo%2BkL8%2FI4IgUsw%3D%3D.vbdNOgUUhAEwWJRLOMzL7E28O7mv%2BXzq19hhjSuYviR6OWQYEvMB2aITBdcDSMRerQzSvL%2F1NmUpCA1g9tXfkBkCgK54fPdsFonpC4Qu8Js%3D" rel="nofollow" target="_blank">统一计算平台-自定义算子-DSP 算子开发</a>&lt;/u&gt;》。</p><h2>11. 性能监测工具</h2><p>征程 6 平台 BPU、DSP 都是独占的硬件资源，任务一旦提交就会独占推理，UCP 侧仅能通过 <code>hrt_ucp_monitor</code> 工具去监测其硬件占用率（采样频率支持配置 [10， 1000]，默认 500），并且能查看到 DDR 内存占用情况。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047420369" alt="" title="" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[【实测有效】Gemini 3 / Goo]]></title>    <link>https://segmentfault.com/a/1190000047420242</link>    <guid>https://segmentfault.com/a/1190000047420242</guid>    <pubDate>2025-11-22 16:02:21</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>最近 Google Antigravity（配合 Gemini 3）的热度非常高，作为一个尝鲜党，我自然也是第一时间下载体验。不得不说，连上之后体验确实非常丝滑，“挺爽的，大家爽起来”不是一句空话。</p><p><strong>但是！</strong> 在爽之前，有一个巨大的拦路虎挡在了很多人面前——<strong>登录问题</strong>。</p><p>我看很多兄弟都在反馈：软件装好了，魔法也挂了，点击“登录”跳转网页授权成功，但切回软件就是<strong>没有任何反应</strong>，甚至连转圈圈都没有，直接卡死在初始界面。</p><p>为了帮大家节省折腾的时间，我把目前社区里验证过、我自己也实测有效的几种解决思路做个汇总。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047420244" alt="" title=""/>---</p><h2>核心问题复现</h2><ul><li><strong>环境</strong>：Windows / macOS</li><li><strong>现象</strong>：点击 Google 账号登录，浏览器弹出授权页面，点击确认后，浏览器显示成功，但 Antigravity 软件端无法接收到 Token，处于“假死”或无响应状态。</li><li><strong>原因推测</strong>：Antigravity 的本地验证流量没有正确走代理，或者部分关键进程被直连规则绕过了。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047420245" alt="" title="" loading="lazy"/></p><ul><li><strong>跳转后没有获取权限</strong> 能跳转了下一步就不符合条件</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047420246" alt="" title="" loading="lazy"/></p><h2>处于“假死”一直转圈圈解决方案汇总</h2><h3>方案一：开启 TUN 模式（最推荐，最简单）</h3><p>这是目前成功率最高的方法。</p><p>很多人的代理软件默认只代理浏览器流量（System Proxy），而 Antigravity 作为一个独立应用，它的验证请求可能没有被系统代理捕获。</p><ul><li><strong>操作方法</strong>：<br/>  在你的代理软件（如 Clash Verge, Mihomo, V2RayN 等）中，找到 <strong>“TUN 模式”</strong> 或 <strong>“虚拟网卡模式”</strong> 并开启。</li><li><strong>我的经历</strong>：<br/>  我之前因为用不上 TUN 模式一直没开，结果卡在登录界面半天。一打开 TUN，重启软件，秒进。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047420247" alt="" title="" loading="lazy"/></p><h3>方案二：使用 Proxifier 强制代理（不愿开 TUN 的选择）</h3><p>如果你因某些原因不想开启全局 TUN 模式，或者 TUN 模式依然无效，可以使用 <strong>Proxifier</strong> 这类工具，强制指定 Antigravity 走代理。</p><ul><li><strong>适用人群</strong>：Windows/macOS 高级用户</li><li><p><strong>操作步骤</strong>：</p><ol><li>安装 Proxifier。</li><li><strong>配置代理服务器 (Proxy Server)</strong>：填入你魔法的本地端口（通常是 127.0.0.1:7890，具体看你的软件设置）。</li><li><p><strong>配置代理规则 (Proxification Rules)</strong>：</p><ul><li>新建一条规则。</li><li>Target Hosts（目标主机）可以设为通配符。</li><li>Applications（应用程序）选择 <code>Antigravity.exe</code> (Windows) 或 <code>Antigravity.app</code> (macOS)。</li><li>Action 选择你刚才设置的 Proxy。</li></ul></li></ol><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047420248" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047420249" alt="" title="" loading="lazy"/></p></li></ul><h3>方案三：macOS 用户的特殊“关照”</h3><p>Mac 用户如果开启了 TUN 还是不行，大概率是因为 Antigravity 有几个后台辅助进程没有被代理规则覆盖。</p><p>根据社区大佬 Heier 的抓包发现，你需要确保以下进程都能走代理：</p><ol><li><code>Antigravity.app</code> (主程序)</li><li><code>Antigravity Helper</code> (辅助进程)</li><li><code>language_server_macos_x64</code> (语言服务)</li></ol><p><strong>具体配置 ID 参考：</strong><br/>如果你使用 Surge 或其他支持进程名分流的软件，请确保以下 Bundle ID 或进程名被加入代理规则：</p><ul><li><code>com.google.antigravity</code></li><li><code>com.google.antigravity.helper</code></li></ul><h2>账号条件不符合解决方案</h2><p>搞定了网络环境（TUN/代理），如果你在登录时没有卡死，但弹出了红色的错误提示，那就要看这部分了。这里主要涉及 Google 的风控策略。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047420250" alt="" title="" loading="lazy"/></p><h3>1. 扎心的 "Not Eligible"（资格不符）</h3><p><strong>现象描述：</strong><br/>当你满怀期待点击登录，结果弹窗提示：</p><blockquote><em>"Your current account is not eligible for Antigravity. Try signing in with another personal Google account."</em></blockquote><p><strong>原因分析：</strong><br/>这通常不是你的网络问题，而是 Google 对<strong>账户“资历”</strong>有要求。根据社区大量实测反馈，Antigravity 目前处于限量测试（或者说灰度测试）阶段，Google 似乎有意屏蔽了<strong>新注册的账户</strong>（可能是为了防止滥用）。</p><p><strong>解决方案：</strong></p><ul><li><strong>最快解决问题</strong>：账号升级 Gemini Pro会员这是快速最有效的办法。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047420251" alt="" title="" loading="lazy"/></p><ul><li><strong>换个“老号”试试</strong>：这是最有效的办法。建议使用注册时间在 <strong>2020 年之前</strong> 的个人 Google 账户。</li><li><strong>避免使用新号</strong>：如果你是为了体验这个软件特意新注册的 Gmail，大概率是进不去的。翻翻压箱底的老账号，成功率会高很多。</li></ul><h3>2. 地区限制（Region Restricted）</h3><p><strong>现象描述：</strong><br/>提示你所在的国家/地区不在服务范围内。</p><p><strong>解决方案：</strong><br/>如果你的魔法节点是对的（比如US或SG），但依然提示地区错误，那可能是你的 Google 账户本身的<strong>“归属地（Country Association）”</strong>被判定在了不支持的区域。</p><p>你需要手动申请更改 Google 账户的归属地：</p><ol><li><strong>访问申诉链接</strong>：<br/>打开 Google 官方的地区关联表单：<code>https://policies.google.com/country-association-form</code></li><li><strong>提交修改</strong>：<br/>在页面中，将你的地区选择为支持 Antigravity 的地区（如 US 或 SG）。</li><li><p><strong>耐心等待（重点！）</strong>：<br/>这<strong>不是即时生效</strong>的！提交后，需要等待 Google 的审核系统处理。</p><ul><li>审核通过后，你会收到一封官方邮件通知。</li><li>收到邮件后，建议清除浏览器缓存或 Antigravity 的缓存再尝试登录。</li><li><img referrerpolicy="no-referrer" src="/img/remote/1460000047420252" alt="fda11763744117.png" title="fda11763744117.png" loading="lazy"/></li></ul></li></ol><p><strong>⚠️ 避坑提示：</strong></p><ul><li>不要频繁来回切换地区，容易触发风控。</li><li>建议选择与你常用魔法节点一致的地区，保持“人号合一”，避免后续出现更奇怪的验证码或封号问题。</li></ul><hr/><h2>抄作业：一套稳稳的推荐配置</h2><p>经过多轮测试，目前最稳的“黄金配置”如下，建议直接抄作业：</p><ul><li><strong>系统</strong>：macOS / Windows 均可</li><li><strong>核心</strong>：<strong>Mihomo (内核)</strong> + <strong>开启 TUN 模式</strong></li><li><strong>系统设置</strong>：System Proxy (系统代理) 开启</li><li><strong>节点选择</strong>：<strong>新加坡节点</strong> (实测响应最快，且 Google 服务支持较好，不需要开全局，规则判断即可)</li><li><strong>账号未获取权限</strong>： 快速方案账号升级 gemini Pro会员，使用老号和换地区。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047420253" alt="" title="" loading="lazy"/></p><hr/><h2>界智通(jeiagi)总结</h2><p>工具是好工具，就是网络门槛稍微有点烦人。希望这个汇总能帮大家迈过这道坎，真正体验到 Gemini 3 带来的生产力提升。</p><p>如果你有其他巧技，或者在 Windows 下有特殊的设置经验，欢迎在评论区补充，我会持续更新到文章里，造福后来的兄弟们！</p><p><em>(本文部分解决方案参考自社区大佬 Heier 和 yooling，特此感谢)</em></p><blockquote>版权信息： 本文由界智通(jieagi)团队编写，图片、文本保留所有权利。未经授权，不得转载或用于商业用途。</blockquote>]]></description></item><item>    <title><![CDATA[面向快速迭代的低代码开发：技术实现与资源]]></title>    <link>https://segmentfault.com/a/1190000047420284</link>    <guid>https://segmentfault.com/a/1190000047420284</guid>    <pubDate>2025-11-22 16:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>企业在数字化转型过程中，系统开发投入往往高昂，涉及人力、时间和资源成本。</p><p>成熟的低代码平台并非单纯依赖“可视化拖拽”操作的表面功能，而是通过模型驱动开发、自动化代码生成与可视化组件组合等技术手段，将传统开发流程中的重复性劳动大幅压缩。</p><p><img width="723" height="976" referrerpolicy="no-referrer" src="/img/bVdm8ln" alt="" title=""/></p><p>基于这些机制，原本需要多人数月完成的系统构建任务，可以在大幅降低资源消耗的前提下实现同等质量的交付。</p><blockquote><strong>然而，这种效率提升的前提是选择具备完整交付能力、支持可扩展架构和生产级部署的低代码平台，而非仅具展示效果的工具。</strong></blockquote><h2>可视化工作流</h2><h4>流程功能</h4><p><img width="723" height="1226" referrerpolicy="no-referrer" src="/img/bVdmtwr" alt="" title="" loading="lazy"/></p><h4>流程功能清单</h4><p><img width="665" height="1170" referrerpolicy="no-referrer" src="/img/bVdlGcO" alt="" title="" loading="lazy"/></p><h4>流程使用示例</h4><blockquote><strong>系统界面</strong><br/><img width="723" height="324" referrerpolicy="no-referrer" src="/img/bVdkXMH" alt="" title="" loading="lazy"/></blockquote><blockquote><strong>流程参数设置</strong><br/><img width="723" height="323" referrerpolicy="no-referrer" src="/img/bVdkXMI" alt="" title="" loading="lazy"/></blockquote><blockquote><strong>流程示例</strong><br/><img width="723" height="342" referrerpolicy="no-referrer" src="/img/bVdkXMJ" alt="" title="" loading="lazy"/></blockquote><blockquote><strong>流程设计（请假申请）</strong><br/><img width="723" height="347" referrerpolicy="no-referrer" src="/img/bVdkXMK" alt="" title="" loading="lazy"/></blockquote><blockquote><strong>流程设计（主管审批）</strong><br/><img width="723" height="347" referrerpolicy="no-referrer" src="/img/bVdkXML" alt="" title="" loading="lazy"/></blockquote><blockquote><strong>流程设计（完整请假流程）</strong><br/><img width="723" height="347" referrerpolicy="no-referrer" src="/img/bVdkXMN" alt="" title="" loading="lazy"/></blockquote><h2>可视化开发：应用构建技术分析</h2><h4>1.组件化设计：模块化与复用</h4><p>组件化设计是可视化开发的核心基础，通过将界面元素与业务逻辑拆解为独立可组合单元，实现开发效率、可维护性和系统复用性的提升。在实际应用中，组件化不仅涉及前端展示，还需考虑数据接口、状态管理和跨模块依赖。</p><p><img width="723" height="347" referrerpolicy="no-referrer" src="/img/bVdeX9O" alt="" title="" loading="lazy"/></p><ul><li>组件库构建与分类：基础组件包括表单、列表、图表等通用模块，行业组件如权限管理、审批流程可按业务需求扩展。组件通过参数化和属性绑定进行配置，可组合形成更复杂功能模块。组件库的设计需平衡通用性和扩展性，否则跨项目复用效果受限。</li><li>复用与扩展机制：组件可在不同项目间复用，但复用效率依赖接口标准化、版本管理及依赖控制。插件化机制允许功能扩展，但需关注兼容性和耦合风险。</li><li>依赖管理与耦合分析：通过可视化工具或分析方法展示组件关系，有助于识别潜在耦合、性能瓶颈和维护成本，支持结构优化和版本迭代策略。</li></ul><h4>2.实时渲染与动态预览</h4><p>实时渲染与动态预览技术使开发者可以即时观察界面和数据变化的结果，从而缩短调试周期和提高迭代效率。然而，在大数据量和复杂业务逻辑下，性能管理和渲染优化是设计的关键点。</p><p><img width="723" height="367" referrerpolicy="no-referrer" src="/img/bVdeX9R" alt="" title="" loading="lazy"/></p><ul><li>数据绑定策略：双向绑定保证界面与数据模型同步，但高复杂度场景下需采用增量更新或脏检查机制，降低不必要的渲染开销。</li><li>跨终端适配：响应式布局确保在不同屏幕尺寸和输入方式下保持交互一致性，设计时需兼顾触控、鼠标及键盘操作差异。</li><li>渲染优化技术：虚拟DOM、分层缓存及批量渲染策略减少操作开销。在复杂交互场景中，可结合异步计算与事件队列控制渲染顺序，避免界面阻塞。</li><li>交互模拟与验证：支持点击、拖拽、输入等操作模拟，用于验证逻辑完整性、操作路径覆盖及性能瓶颈，但必须结合真实数据场景。</li></ul><h4>3.可视化业务逻辑编排</h4><p>业务逻辑可视化编排通过流程图或节点拖拽呈现业务规则，实现复杂逻辑的直观管理和快速迭代。该机制不仅降低了编码门槛，也增强了业务流程的可控性和团队协作能力。</p><p><img width="723" height="437" referrerpolicy="no-referrer" src="/img/bVde9NQ" alt="" title="" loading="lazy"/></p><ul><li>节点化事件管理：通过节点表示事件触发、数据流和条件依赖，开发者可以清晰理解业务流程执行顺序与逻辑关系。</li><li>条件逻辑与分支控制：可视化条件工具支持多分支逻辑配置，减少手工编码错误，但在复杂规则集下仍需关注逻辑冲突和性能开销。</li><li>自动化任务与流程模板：支持任务序列配置、定时执行和事件触发，模块化封装可复用业务流程模板，提高一致性与可维护性。</li><li>跨角色协作与审查机制：可视化流程图使非开发角色参与审查和设计，提高透明度，但需要结合权限控制与版本管理避免冲突。</li></ul><h4>4.分布式协作支持</h4><p>分布式协作技术是多地团队协作的基础，通过模块化管理、版本控制和冲突解决机制保障开发效率和安全性。在跨地域和跨部门开发场景中，这一能力直接影响项目的可控性和上线速度。</p><p><img width="723" height="348" referrerpolicy="no-referrer" src="/img/bVdeX9V" alt="" title="" loading="lazy"/></p><ul><li>版本控制与模块管理：分布式版本控制支持模块独立开发、分支管理和并行迭代，减少合并冲突。</li><li>变更追踪与冲突解决：自动记录每次修改，结合冲突检测与回滚策略，提高协作安全性。</li><li>权限与访问控制：按角色、部门或项目划分操作权限，保障任务责任清晰，满足企业审计要求。</li><li>跨地域同步机制：远程同步和实时共享可支持全球团队协同开发，但需要优化网络延迟与数据一致性策略。</li></ul><h4>5.无缝部署与事务管理</h4><p>部署与事务管理技术确保应用在多环境下稳定运行和数据一致性。高效的部署机制不仅减少上线时间，也降低潜在故障风险。</p><p><img width="723" height="347" referrerpolicy="no-referrer" src="/img/bVdfTLE" alt="" title="" loading="lazy"/></p><ul><li>容器化部署与自动化运维：基于容器的打包与部署实现环境一致性和快速上线，结合持续集成与交付工具减少人为干预。</li><li>跨模块事务一致性：分布式事务协议保证多服务操作的数据完整性，但需注意协议选择对系统性能的影响。</li><li>版本管理与灰度发布：支持多版本并行部署和渐进发布，降低上线风险并便于回滚。</li><li>实时运维与监控：通过服务监控、性能指标采集和异常告警，结合动态调度实现负载均衡和快速故障恢复。</li></ul><h2>核心引擎：支撑高效开发的技术体系</h2><h4>1.SQL引擎：智能查询与高性能计算</h4><p>SQL引擎是数据处理的核心，通过智能优化和并行计算保障在大规模数据环境下的查询效率与一致性，同时为业务系统提供可靠的数据支撑。其设计需要兼顾性能、可扩展性和事务安全性。</p><p><img width="723" height="381" referrerpolicy="no-referrer" src="/img/bVdfI4o" alt="" title="" loading="lazy"/></p><ul><li>智能查询优化：高级优化器根据表结构、索引和数据分布动态生成执行计划，结合查询重写、索引推荐及成本模型分析，实现大数据量下的高效查询。设计时需考虑复杂联接、聚合操作和查询频率差异对执行计划的影响。</li><li>多线程与分布式处理：支持数据分区、节点并行计算及缓存策略优化，充分利用多核CPU和分布式资源，实现高并发处理和计算负载均衡。</li><li>事务管理与一致性：通过多版本并发控制（MVCC）、两阶段提交等协议保证跨表、跨节点的数据一致性，并结合快照读与锁机制降低并发冲突风险。</li><li>智能缓存与数据预取：结合内存缓存和预取策略，加速热点数据访问，减少磁盘I/O，提高响应速度与系统吞吐量，尤其在分析型查询和实时决策场景中体现价值。</li></ul><h4>2.功能引擎：模块化架构与扩展能力</h4><p>功能引擎通过模块化封装和动态服务管理，支撑业务功能快速集成和定制化，实现系统灵活性和可扩展性。其关键在于模块依赖管理、服务弹性及规则自动化执行。</p><p><img width="723" height="281" referrerpolicy="no-referrer" src="/img/bVdfI4y" alt="" title="" loading="lazy"/></p><ul><li>模块化封装：核心功能如权限控制、审批流程、报表管理等被标准化封装为可组合插件，支持按需组合和快速系统构建，同时降低模块间耦合。</li><li>动态服务注册与依赖管理：依赖注入和按需加载机制保证服务实例和资源分配的动态管理，减少冗余消耗，并可在高负载下保证性能稳定性。</li><li>规则引擎集成：提供可配置规则接口，支持可视化规则设计和自动执行，满足企业对复杂业务逻辑的个性化需求，同时兼顾可维护性。</li><li>服务监控与弹性扩展：结合负载监控和调用分析，动态调整服务实例和资源分配，实现高可用、容错和弹性扩容，确保系统在突发流量下稳定运行。</li></ul><h4>3.模板引擎：解耦设计与高效渲染</h4><p>模板引擎通过前后端逻辑分离和动态渲染优化，实现界面快速生成和高效迭代，提高开发效率和可维护性。其设计需平衡渲染性能、数据同步和可复用性。</p><p><img width="723" height="222" referrerpolicy="no-referrer" src="/img/bVdfI4C" alt="" title="" loading="lazy"/></p><ul><li>动态数据绑定：通过虚拟DOM和双向绑定实现前端与后台数据实时同步，加快界面迭代和状态更新。</li><li>编译优化：模板编译器利用静态分析和增量更新策略，减少重复渲染，提升性能稳定性，并降低复杂界面渲染延迟。</li><li>模板继承与复用：多层继承和嵌套组合支持复杂界面扩展，增强模板复用性并降低重复开发成本。</li><li>条件渲染与异步加载：按需渲染和异步组件加载优化首屏响应时间，改善用户体验，并降低初始渲染压力。</li></ul><h4>4.图表引擎：高性能可视化与交互</h4><p>图表引擎通过GPU加速渲染、分层缓存及可扩展接口，实现大规模数据的实时可视化和交互分析。其核心挑战在于保持渲染性能、数据更新实时性和多维扩展能力。</p><p><img width="723" height="210" referrerpolicy="no-referrer" src="/img/bVdfI4z" alt="" title="" loading="lazy"/></p><ul><li>GPU加速渲染：利用图形处理单元（GPU）进行高并发绘制，实现复杂动态图表在大数据场景下的实时响应。</li><li>分层缓存与增量更新：通过静态与动态图层分离，减少重复绘制，提高渲染效率和界面流畅度。</li><li>多维扩展接口：提供丰富的图表类型和可插拔扩展接口，支持自定义可视化方案，满足企业分析多样化需求。</li><li>交互事件与动画：鼠标、触控事件绑定和动画效果实现数据变化的实时反馈，提升分析交互体验，同时考虑性能负载和响应延迟。</li></ul><h4>5.切面引擎：面向切面编程与维护优化</h4><p>切面引擎通过面向切面编程（AOP）和代理模式，将横切关注点与核心业务逻辑解耦，实现系统模块化、可维护性和性能优化。设计核心在于减少重复代码、统一管理系统行为及降低运维成本。</p><p><img width="723" height="208" referrerpolicy="no-referrer" src="/img/bVdfI4M" alt="" title="" loading="lazy"/></p><ul><li>AOP框架管理：集中处理日志、性能监控、安全验证等横切关注点，提高模块化和代码复用性，便于统一策略管理。</li><li>代理模式支持：运行时动态代理和编译时静态代理结合使用，优化性能和资源利用，同时支持跨模块调用的透明化管理。</li><li>自动化维护工具：集成自动化测试、监控与诊断工具，降低运维复杂度，及时发现和修复系统问题。</li><li>统一异常处理：切面引擎集中捕获异常和日志，支持实时告警与智能分析，增强系统鲁棒性与可预测性。</li></ul><h2>模型驱动开发：全流程自动化与智能化</h2><p>模型驱动开发通过将业务模型与系统实现紧密绑定，实现开发流程的标准化、自动化和智能化，是提升开发效率和代码质量的重要技术手段。其核心在于自动化生成、智能优化和跨平台适配，兼顾可复用性、性能与稳定性。</p><h4>1.自动化代码生成：多语言支持与深度定制</h4><p>自动化代码生成是模型驱动开发的关键环节，将抽象业务模型转化为可执行代码，不仅提高开发效率，也保证了系统结构规范和逻辑一致性。<br/><img width="723" height="347" referrerpolicy="no-referrer" src="/img/bVdeX9W" alt="" title="" loading="lazy"/></p><ul><li>多语言生成：根据抽象模型自动生成Java、Python、Go等语言代码，结构清晰、逻辑严谨，并支持不同运行时特性优化。</li><li>动态模板与模块定制：通过参数化配置、条件分支和组件化生成，实现模块级灵活开发，满足复杂业务场景的多样化需求。</li><li>模型验证与自动纠错：自动检测逻辑冲突、语法错误及依赖异常，提前发现潜在问题，降低调试成本，提升代码可靠性。</li><li>跨项目复用与版本管理：模板和模型可在不同项目间复用，结合版本控制机制实现快速迭代和多版本管理，为团队协作和长周期开发提供支持。</li></ul><h4>2.智能优化引擎：性能与质量双重保障</h4><p>智能优化引擎通过静态分析、动态分析和运行时调优，全面提升代码性能、逻辑精简度和系统可靠性，为高并发或大规模数据应用提供技术保障。</p><p><img width="723" height="347" referrerpolicy="no-referrer" src="/img/bVdhiKY" alt="" title="" loading="lazy"/></p><ul><li>静态与动态分析：分析代码结构、循环逻辑、未使用变量及依赖关系，同时监控运行时行为，优化内存管理和函数调用，降低性能瓶颈。</li><li>多线程与异步优化：动态调整线程池、任务调度策略和执行优先级，提高并发环境下的吞吐量和响应速度，适应复杂业务负载。</li><li>自动化性能检测：集成性能分析工具和剖析工具，对关键路径和热点函数进行评估，自动推荐优化方案，实现持续性能改进。</li><li>安全与稳定性增强：检测潜在的资源泄漏、死锁或未捕获异常，并提供智能修复策略，确保系统在高负载和复杂场景下的安全性和稳定性。</li></ul><h4>3.无缝跨平台兼容：迁移与适配的便捷体验</h4><p>跨平台兼容能力通过抽象化技术和容器化部署，实现生成代码在多环境下的高效运行与快速适配，简化部署流程，增强系统可用性和可维护性。<br/><img width="723" height="348" referrerpolicy="no-referrer" src="/img/bVdeX90" alt="" title="" loading="lazy"/></p><ul><li>容器化与云原生部署：利用容器技术实现代码及依赖一键打包，支持跨环境部署、弹性扩缩容及自动化运维，保证高可用性。</li><li>多环境适配器：自动识别运行环境，动态调整数据库、缓存和服务配置，实现资源优化和系统稳定运行。</li><li>环境抽象与统一接口：屏蔽操作系统、数据库和网络差异，提供统一接口，降低跨平台开发复杂性。</li><li>迁移与回滚机制：支持版本化部署、快速迁移及智能回滚，减少业务中断风险，确保系统平滑演进。</li><li>多终端支持与可扩展性：生成代码可在桌面端、移动端及微服务环境中运行，支持横向扩展与新模块接入，为企业级应用提供长期可持续发展能力。</li></ul><h2>数据处理能力优化：高性能与智能化支撑</h2><p>数据处理能力是企业级系统核心能力之一，直接决定系统在高并发、大数据量和复杂业务场景下的可靠性与响应速度。本模块通过跨数据库兼容、实时流处理、自动化清洗与转换、灵活建模和底层架构优化，实现高性能与智能化的数据处理支撑。</p><h4>1.跨数据库兼容性：动态负载均衡与智能执行</h4><p>跨数据库操作能力确保系统在多数据库环境下高效运行，同时保持事务一致性与数据完整性。通过智能连接、负载调度和执行路径优化，系统能够动态适应访问模式和业务负载。</p><p><img width="723" height="359" referrerpolicy="no-referrer" src="/img/bVdfI4W" alt="" title="" loading="lazy"/></p><ul><li>多数据库无缝切换：统一访问接口，兼容关系型与非关系型数据库，屏蔽底层差异，实现操作统一化。</li><li>智能数据连接器：根据实时负载及历史访问模式自动选择最优路径，结合分区、索引优化和缓存策略，提高查询与写入效率。</li><li>负载均衡与自适应调优：动态分配计算和存储请求，优化资源利用率，提高系统吞吐量，并在高并发环境下保持稳定性。</li><li>跨库事务支持：基于分布式事务机制保证多数据库操作一致性，降低事务冲突风险，保障数据完整性。</li></ul><h4>2.实时流处理：低延迟计算与弹性扩展</h4><p>实时流处理模块针对高速数据流提供连续计算能力，通过事件驱动机制与动态资源调度，实现毫秒级响应和系统弹性扩展。</p><p><img width="723" height="346" referrerpolicy="no-referrer" src="/img/bVdfI4Z" alt="" title="" loading="lazy"/></p><ul><li>分布式流处理：支持大规模数据流的实时接收、聚合和分发，保证数据连续性和处理效率。</li><li>事件驱动机制：采用异步事件传递方式，实现低延迟响应，适用于高频交易、实时监控及用户行为分析等场景。</li><li>复杂事件处理：支持滚动窗口、滑动窗口和会话窗口，实现秒级聚合与模式识别，满足复杂事件分析需求。</li><li>弹性计算与动态资源调度：根据流量波动和计算负载动态分配计算节点与资源，确保高峰期系统稳定性和处理性能。</li></ul><h4>3.自动化数据清洗与转换：规则驱动与智能辅助</h4><p>高质量的数据是智能决策和业务分析的基础。自动化清洗与智能转换通过规则引擎和AI辅助技术，提高数据准确性和处理效率。</p><p><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdfTK9" alt="" title="" loading="lazy"/></p><ul><li>全流程自动化处理：覆盖数据提取、转换与加载全过程，减少人工干预，降低出错率。</li><li>规则引擎驱动：通过规则配置实现数据标准化、异常值处理及缺失值补全，提高数据处理精度。</li><li>智能辅助优化：结合历史数据模式预测异常情况，自动调整清洗策略，实现智能化处理。</li><li>实时数据验证与反馈：持续监控数据质量，提供即时反馈，确保数据一致性和完整性，为下游分析和决策提供可靠支撑。</li></ul><h4>4.虚拟字段与灵活统计配置：动态建模与多维分析</h4><p>灵活的数据建模与统计配置能力使系统能够快速适应业务变化，同时支持多维分析和可视化决策。</p><p><img width="723" height="348" referrerpolicy="no-referrer" src="/img/bVdfhUR" alt="" title="" loading="lazy"/></p><ul><li>虚拟字段机制：无需修改底层数据库即可动态添加业务字段，满足临时需求和快速迭代。</li><li>多维统计与自定义报表：支持按维度组合、指标聚合及条件筛选生成报表，满足复杂业务分析需求。</li><li>交互式数据可视化：通过仪表盘、热力图和动态图表，实现实时可视化，提升数据洞察能力。</li><li>动态模型更新：数据模型随着业务逻辑变化自动更新，保证报表和分析结果与业务状态一致，提高决策响应速度。</li></ul><h4>5.底层组件支持：高性能架构与模块化设计</h4><p>底层组件与模块化设计是系统高性能、可维护和可扩展的核心支撑，通过异步架构、事件驱动和优化策略，实现系统稳健运行。</p><p><img width="723" height="348" referrerpolicy="no-referrer" src="/img/bVdfI4V" alt="" title="" loading="lazy"/></p><ul><li>事件驱动与异步架构：通过事件总线和发布/订阅模式实现业务逻辑与数据处理解耦，支持高效异步任务处理和模块化管理。</li><li>跨数据库优化：根据不同数据库类型生成优化执行策略，结合索引和缓存策略，实现高性能数据操作。</li><li>高可用与扩展机制：通过组件冗余、消息重试和异常恢复保障系统稳定性，同时支持插件化模块扩展，灵活应对业务变化和技术迭代。</li></ul><h2>AI深度融合：重塑开发体验</h2><p>AI深度融合为开发流程提供智能化支撑，不仅减少手工操作量，还通过自动化分析和优化提升代码质量与系统可靠性。通过智能代码生成、故障排查、场景推荐、自然语言交互、自动化测试及自适应学习，平台在高复杂度项目中实现效率和可维护性的双重提升。</p><h4>1.智能代码助手：自然语言驱动的高效开发</h4><p>智能代码助手将开发者意图转化为可执行代码，通过自动化生成和实时优化实现高效开发。该模块不仅关注代码正确性，还兼顾性能、安全和可扩展性分析。</p><p><img width="723" height="348" referrerpolicy="no-referrer" src="/img/bVdeOdB" alt="" title="" loading="lazy"/></p><ul><li>意图解析与生成：将自然语言需求映射为结构化代码片段，支持复杂逻辑、多模块协作，并自动生成注释与文档，确保代码可读性与可维护性。</li><li>自动优化与反馈：实时识别冗余逻辑、优化函数调用顺序，并提示性能瓶颈或安全风险，结合智能建议提升迭代效率。</li><li>版本兼容与可移植性分析：在生成代码时自动检测依赖库版本和运行环境差异，提供兼容性调整方案，降低上线与迁移风险。</li></ul><h4>2.智能故障排查：提前识别风险，缩短修复周期</h4><p>智能故障排查通过实时监控、异常检测和预测分析，实现快速定位问题根因，并提供可操作分析结果。</p><p><img width="723" height="367" referrerpolicy="no-referrer" src="/img/bVdjbsw" alt="" title="" loading="lazy"/></p><ul><li>实时异常检测：基于行为模型和历史数据快速识别异常，包括性能波动、逻辑冲突及潜在安全漏洞。</li><li>诊断与可视化：自动生成故障分析报告，明确异常影响模块及业务范围，并提供修复路径，支持团队协作定位问题。</li><li>预测性维护：利用机器学习预测潜在故障并生成优化方案，提前干预关键模块，降低停机概率和运维成本。</li><li>根因追踪与智能提示：事件链追踪技术定位问题源头，提供优化建议，并支持跨模块联动分析。</li></ul><h4>3.场景化推荐：上下文驱动的开发决策支持</h4><p>场景化推荐模块通过对项目数据、业务上下文及开发行为分析，提供个性化建议，提高开发效率和决策精度。</p><p><img width="723" height="348" referrerpolicy="no-referrer" src="/img/bVdjtQh" alt="" title="" loading="lazy"/></p><ul><li>组件智能推荐：根据项目结构、业务类型和历史使用数据匹配最合适的组件与功能模块，降低试错成本。</li><li>业务逻辑模板：提供表单流程、审批逻辑、统计分析等常用业务模板，可快速套用并调整以适应特定场景。</li><li>算法与配置优化：结合系统负载和资源使用情况给出性能参数调整、资源调度及架构优化建议。</li><li>动态上下文感知：根据项目演变和开发者操作习惯，实时优化推荐策略，提高开发精度与可操作性。</li></ul><h4>4.自然语言接口与智能交互：降低操作门槛，提升构建效率</h4><p>自然语言接口使开发者可以通过直观的对话完成编码、调试和优化操作，降低复杂系统构建门槛。</p><p><img width="723" height="457" referrerpolicy="no-referrer" src="/img/bVdjtQj" alt="" title="" loading="lazy"/></p><ul><li>对话式代码生成：自然语言指令可生成或修改代码片段，支持条件逻辑、循环及函数封装等复杂操作。</li><li>交互式问题解决：通过对话快速定位问题并生成修复方案，同时自动提示逻辑或性能优化路径。</li><li>灵活交互与操作简化：减少重复性操作，让开发者专注于业务实现和创新，同时支持多角色协作。</li><li>上下文智能提示：根据当前模块和任务自动提供相关操作建议及参考示例，加快开发流程。</li></ul><h4>5.AI驱动自动化测试：提高质量保障能力</h4><p>自动化测试模块通过智能生成测试用例和优化测试策略，实现全面、动态、可扩展的质量管理。</p><p><img width="723" height="584" referrerpolicy="no-referrer" src="/img/bVdfhUP" alt="" title="" loading="lazy"/></p><ul><li>自动生成测试用例：覆盖关键功能、接口及性能路径，并自动生成边界条件和异常场景测试。</li><li>动态策略优化：根据实时测试结果调整测试顺序、资源分配和执行优先级，提升效率与覆盖率。</li><li>可视化质量分析：通过交互式报表和热力图呈现缺陷分布、影响范围及修复优先级，为决策提供数据支撑。</li><li>持续回归与智能验证：每次代码更新自动触发回归测试，并结合AI分析异常趋势，降低漏测风险。</li></ul><h4>6.自适应学习与持续优化：让系统越用越懂团队</h4><p>自适应学习模块通过分析项目数据和开发行为，持续优化工具链、资源调度和开发策略，为团队提供前瞻性决策支持。</p><p><img width="723" height="347" referrerpolicy="no-referrer" src="/img/bVdfhUO" alt="" title="" loading="lazy"/></p><ul><li>行为模式分析：识别团队高效开发模式和低效操作，自动优化流程与资源分配。</li><li>动态资源调度：根据实时负载自动调整并发、缓存和计算资源，实现性能优化与资源高效利用。</li><li>需求趋势预测：基于历史数据和开发行为预测潜在功能需求或技术挑战，为决策提供前瞻性支撑。</li><li>自我优化与策略演进：系统在使用中不断学习和调整开发、测试及运维策略，使平台适应复杂、动态的业务环境。</li></ul><h2>插件生态：覆盖多行业场景</h2><p>插件化架构为系统提供高度可扩展和可定制的能力，使平台能够针对不同行业和业务场景灵活扩展功能，同时保证核心系统的稳定性与性能。通过插件机制，开发者可以快速集成特定功能模块，实现复杂业务需求的快速响应。</p><p><img width="723" height="803" referrerpolicy="no-referrer" src="/img/bVdfhUS" alt="" title="" loading="lazy"/></p><ul><li>实时数据流处理插件：基于Kafka和Flink的插件支持大规模低延迟数据流处理，实现事件驱动的数据采集、聚合和实时分析。结合分区和状态管理机制，可保障高并发环境下的数据一致性与可靠性。</li><li>AI模型训练与部署插件：集成TensorFlow、PyTorch等主流机器学习框架，支持快速开发、训练和部署AI模型，提供模型版本管理、推理优化和自动化调优机制。</li><li>智能图像处理插件：提供OCR、图像识别和视频分析功能，利用GPU加速和批量处理机制，提高图像和视频处理效率及准确性。</li><li>自然语言处理插件：支持语义分析、情感分析、多语言处理及文本向量化，实现高精度文本理解和智能化信息处理。</li><li>容器化部署插件：支持Docker与Kubernetes，实现应用及依赖打包、弹性扩缩容与跨平台部署，提升资源利用率和系统可移植性。</li><li>边缘计算插件：在边缘设备执行数据处理任务，降低延迟、减轻中心节点负载，并确保高实时性和稳定性。</li><li>低代码RPA插件：通过自动化流程执行，提升操作效率、减少重复性人工干预，实现业务流程的自动化管理。</li><li>API网关插件：提供接口聚合、负载均衡、访问控制及版本管理，优化系统性能、提高服务可靠性，并便于多服务协同。</li><li>数据安全与隐私保护插件：支持数据加密、访问控制、隐私合规检查及敏感信息脱敏，确保数据在存储、传输及处理中的安全性。</li><li>业务流程建模插件：基于BPMN标准，实现业务流程快速建模、优化和自动化执行，提高流程透明度和协作效率。</li><li>数据可视化插件：提供丰富图表、仪表板及交互分析工具，实现数据的直观展示和多维分析支持。</li><li>数据集成与ETL插件：支持多源数据采集、清洗、转换及集成，保证数据完整性与一致性，同时减少人工操作和数据处理时间。</li><li>智能推荐系统插件：结合协同过滤与深度学习算法，实现个性化推荐，提升用户体验及业务决策支撑能力。</li><li>表单生成插件：支持动态表单设计、快速配置及条件逻辑绑定，降低开发门槛并提高表单管理效率。</li><li>智能客服插件：基于NLP与对话管理技术，实现自动问答、工单生成与问题分类，提高客户响应速度与准确性。</li><li>安全审计与日志分析插件：采集、解析系统日志，提供异常检测、事件追踪及合规报告，实现智能化安全监控。</li><li>身份认证与访问管理插件：支持多因素认证、单点登录与权限分级管理，提升系统安全性和访问控制精度。</li><li>增强搜索与推荐插件：通过语义搜索、向量检索及个性化推荐机制，提高信息检索效率和相关性。</li><li>智能运维插件：结合AIOps技术，实现故障诊断、性能监控、异常预测及自动化运维，提高系统可靠性和运维效率。</li></ul><p>插件生态的核心价值在于按需扩展、灵活组合和技术可演进，使平台能够同时满足多行业差异化需求和复杂业务场景，而无需对核心系统进行大幅改造。</p><h2>开放架构：高性能与开源生态的深度融合</h2><p>开放架构强调系统的模块化、可扩展性和生态兼容性，通过微服务设计、开源框架支持、多样化组件库和高性能优化，实现高效开发与运维能力的深度结合。该架构不仅关注系统性能与稳定性，还兼顾开发效率、二次扩展能力以及跨团队协作。</p><h4>1.微服务架构：高可维护性与弹性伸缩</h4><p>微服务架构通过将系统拆分为独立服务模块，并采用异步通信机制，提升系统在高并发场景下的可维护性与扩展能力。</p><p><img width="723" height="517" referrerpolicy="no-referrer" src="/img/bVdhiLy" alt="" title="" loading="lazy"/></p><ul><li>事件驱动架构：基于事件总线的异步通信降低服务耦合，事件追踪机制确保系统可靠性，同时提供快速故障定位能力。</li><li>任务分发与负载均衡：分布式调度根据节点负载动态分配任务，实现系统弹性伸缩和高并发处理能力。</li><li>分布式事务一致性：采用2PC、TCC或Saga等事务协议保障跨服务数据一致性，降低事务冲突风险，确保数据完整性。</li><li>服务监控与智能调度：结合服务网格与分布式追踪，实现实时性能监控、请求优化及快速故障恢复，提高系统鲁棒性。</li></ul><h4>2.开源框架支持：快速创新与二次开发</h4><p>开源框架和社区生态为系统提供稳定技术基础，支持功能扩展、创新开发和定制化二次开发。</p><p><img width="723" height="367" referrerpolicy="no-referrer" src="/img/bVdg9cM" alt="" title="" loading="lazy"/></p><ul><li>完整框架与文档：全面的开源架构及详细技术文档降低学习成本，加快系统开发速度。</li><li>自动化测试与持续集成：通过集成单元测试、CI/CD工具链和自动化构建机制，保障代码质量和迭代效率。</li><li>社区与插件生态：依托开源社区资源及插件接口，支持快速功能迭代、模块扩展及定制化适配，增强开发灵活性。</li><li>技术可持续性与演进：开源生态为技术迭代、补丁更新及安全修复提供长期支持，降低企业自研成本。</li></ul><h4>3.多样化组件库：模块化与行业适配</h4><p>组件化设计通过模块化和插件化实现跨项目复用与业务快速适配，同时兼顾不同前端框架和行业场景。</p><p><img width="723" height="348" referrerpolicy="no-referrer" src="/img/bVde2nD" alt="" title="" loading="lazy"/></p><ul><li>全面业务覆盖：内置表单、数据表格、交互式图表、权限控制等组件，覆盖金融、零售、医疗等多行业需求。</li><li>跨框架兼容：组件支持多种前端开发框架，实现前后端分离与模块化架构落地。</li><li>模块化复用与定制：组件可二次开发，快速迭代业务逻辑，实现系统个性化和扩展需求。</li><li>可扩展主题与样式：支持界面主题定制，保证品牌一致性，并兼顾桌面、移动端和多终端适配。</li><li>交互优化与响应式设计：通过响应式布局和动态渲染机制，提升用户体验和系统可用性。</li></ul><h4>4.高性能支撑：低延迟与大规模处理</h4><p>高性能设计结合优化机制和智能调度，确保系统在海量数据和高并发环境下保持稳定性和响应速度。</p><p><img width="723" height="672" referrerpolicy="no-referrer" src="/img/bVdeX9T" alt="" title="" loading="lazy"/></p><ul><li>内存级缓存加速：利用高速缓存减少磁盘I/O，提高数据访问效率，满足低延迟业务需求。</li><li>容器化与弹性部署：通过Docker和Kubernetes实现自动扩缩容，保证系统弹性与负载均衡能力。</li><li>大数据查询优化：结合批量计算与流式处理策略，优化海量数据访问与分析效率。</li><li>系统监控与智能调度：实时监控节点性能、请求分布及资源使用情况，动态调整任务调度和负载分配，提高整体稳定性。</li><li>容错与高可用机制：组件冗余、消息重试与异常恢复确保系统在节点故障或高峰负载情况下持续运行。</li></ul><h2>企业功能增强：从开发工具到智能决策支持</h2><p>企业功能增强不仅关注开发效率，也强调业务逻辑的智能化、数据操作的高效性与决策支持能力。通过组件化、规则引擎、可视化逻辑配置和多租户安全机制，平台能够支撑复杂企业场景的高效运营，同时保持系统可扩展性和安全性。</p><h4>1.数据增删查改：高效灵活的数据操作</h4><p>企业数据管理是业务系统核心，通过可视化组件、动态数据绑定及批量处理机制，实现高效、直观且灵活的数据操作，减少开发与维护成本。</p><p><img width="723" height="410" referrerpolicy="no-referrer" src="/img/bVdjE6g" alt="" title="" loading="lazy"/></p><ul><li>可视化操作：拖拽界面组件即可完成数据增删改查操作，无需手写数据库语句或后端逻辑，降低技术门槛并减少人为错误。</li><li>动态数据绑定：界面组件与数据库实时同步，支持双向更新，保证数据准确性和操作即时性，同时自动触发依赖逻辑和事件更新。</li><li>高效数据处理：集成批量操作、异步任务队列、智能缓存和索引优化策略，保障高并发场景下的快速响应与查询效率，兼顾稳定性与性能优化。</li></ul><h4>2.图表创建一键直达：交互式可视化与高性能渲染</h4><p>可视化数据分析是企业决策的基础，通过抽象化图表组件和高性能渲染引擎，实现大规模数据实时分析与交互展示，提高业务洞察力。</p><p><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdfbka" alt="" title="" loading="lazy"/></p><ul><li>抽象化组件与动态联动：支持柱状图、折线图、饼图、热力图等多类型图表，利用事件驱动实现图表间联动与数据动态刷新。</li><li>高性能渲染引擎：通过分层缓存、增量渲染及GPU加速，实现海量数据下的实时交互，保障响应流畅性。</li><li>自适应可视化与多终端支持：响应式布局和跨终端适配，支持数据钻取、交互分析和多维报表，为业务决策提供精准数据支撑。</li></ul><h4>3.灵活的业务逻辑配置：响应式编程与事件驱动</h4><p>复杂业务规则的管理需要可控、透明且可迭代的机制，通过响应式编程、事件驱动和可视化条件工具，企业可快速配置和调整业务流程。</p><p><img width="723" height="347" referrerpolicy="no-referrer" src="/img/bVdfTLE" alt="" title="" loading="lazy"/></p><ul><li>响应式编程与双向绑定：数据在组件间双向流动，条件逻辑可视化配置并实时验证执行结果，提升业务逻辑可控性。</li><li>事件驱动与交互增强：基于事件触发业务逻辑，实现动态界面响应、弹窗与提示优化用户体验。</li><li>流程自动化与策略模板：内置业务流程模板和可复用任务模块，降低配置复杂度，提升执行效率，同时支持跨项目快速应用。</li></ul><h4>4.自定义公式与规则引擎：简化计算与智能执行</h4><p>企业业务逻辑往往涉及复杂计算和条件判断，通过公式库和智能规则引擎，实现高效、自动化的业务处理，降低人工干预。</p><p><img width="723" height="367" referrerpolicy="no-referrer" src="/img/bVdhxaG" alt="" title="" loading="lazy"/></p><ul><li>多样化公式与实时验证：支持数学、逻辑、文本和日期运算，公式可自定义并即时反馈结果，确保业务逻辑正确性。</li><li>智能规则引擎：自动执行条件判断、流程控制和事件触发逻辑，提升复杂业务处理效率与可靠性。</li><li>公式模板与复用机制：标准公式库可跨项目复用，加快新业务场景部署速度，支持多版本迭代和统一管理。</li></ul><h4>5.虚拟字段与多租户权限管理：灵活与安全并重</h4><p>在企业级系统中，数据模型的灵活性与安全性同等重要，通过虚拟字段机制和多租户权限控制，实现安全、可扩展的数据管理。</p><p><img width="723" height="359" referrerpolicy="no-referrer" src="/img/bVdfI56" alt="" title="" loading="lazy"/></p><ul><li>虚拟字段与动态数据模型：无需修改底层数据库即可自定义字段和计算逻辑，快速响应业务变化，同时保持系统稳定性。</li><li>多租户数据隔离：通过独立数据空间和访问策略，保障不同租户间的数据隔离和隐私保护。</li><li>精细权限控制：基于用户、角色及部门进行访问权限管理，满足企业合规性和审计要求。</li><li>动态审计与操作追踪：记录操作与数据变更，实现实时审计和问题排查支持，增强企业运营安全性和透明度。</li></ul><h2>结束语</h2><p>整体来看，现代低代码平台的技术体系已经超越了“可视化拖拽”的表面概念，形成了以模型驱动、组件化、AI智能辅助和分布式架构为核心的高性能开发框架。</p><p><img width="723" height="384" referrerpolicy="no-referrer" src="/img/bVdm3sv" alt="" title="" loading="lazy"/></p><p>无论是数据处理能力、业务逻辑编排，还是跨平台兼容与多租户安全管理，低代码平台都通过技术手段实现了开发效率、系统可靠性与业务灵活性的综合优化。同时，插件生态和开放架构提供了面向复杂企业场景的扩展能力，使得系统既能快速迭代，又能适应不断变化的业务需求。</p><p>可以预见，未来低代码技术的发展将更多依赖于智能化、自动化与系统化的技术融合，从而在保证质量和可维护性的前提下，为企业数字化转型提供坚实的技术支撑。</p>]]></description></item><item>    <title><![CDATA[AI营销应用见实效：262%增长背后，智]]></title>    <link>https://segmentfault.com/a/1190000047420183</link>    <guid>https://segmentfault.com/a/1190000047420183</guid>    <pubDate>2025-11-22 15:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>这个数字不仅是技术能力的积累，更标志着AI商业化落地进入了规模化的新阶段。AI如何为企业创造收益？关键在于将技术能力转化为能切实解决企业“降本增效”需求的标准化产品。正如百度财报中提到的：“在移动生态中，智能体和数字人等AI原生商业化产品带来快速的收入增长，显示出强大的长期潜力。”</p><p>如今，AI已经能够听电话、做直播、谈生意，正成为影响企业增长模式的一个重要变量。商家智能体、慧播星数字人等一系列AI原生商业化产品，正成为千行百业商家“增长提效”的利器。</p><p>一、揭秘商家智能体--青否ai超级员工</p><p>7*24小时服务，打造专属AI销售团队！</p><p>青否AI超级员工，是一款基于AI的全链路营销自动化解决方案，通过“AI获客+AI引流+AI销售”三位一体架构，重构营销团队，实现人力替代、效率提升、效果稳定。</p><p>1、AI获客</p><p>告别内容内耗，多平台高效运营。</p><p>sora2批量生成爆款短视频，智能匹配行业关键词，全自动发布覆盖抖音、快手、视频号、小红书。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047420185" alt="" title=""/></p><p>GEO智能体优化多平台AI内容，用户提问时主动推荐企业及产品，精准曝光。</p><p>多账号一键绑定管理，数据实时监测，无需跨平台切换，省掉半个编辑团队。</p><p>解决：内容累、制作耗时长、跨平台管理乱的痛点。</p><p>2、AI引流</p><p>全域精准引流，获客效率倍增。</p><p>按行业+用户画像全网采集高意向客户，主动私信/评论，无需人工蹲点。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047420186" alt="" title="" loading="lazy"/></p><p>抖音客服7*24小时在线自动回复，AI拟人聊天，引导客户留资。</p><p>解决：找客难、引流慢、精准度低的痛点。</p><p>3、AI销售（青否ai员工源头v：zhibo175）</p><p>标准化私域成交，降本又增效。</p><p>智能私域管家：自动通过好友、实时监控聊天记录、拟人化自动回复，精准预测客户行为分层。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047420187" alt="" title="" loading="lazy"/></p><p>高情商促单：洞察客户需求、处理异议、推动成交，7x24 小时在线不打烊。</p><p>安全保障：本地部署 + 独立后台，知识库与数据全加密，杜绝泄露。</p><p>解决：转化低、跟进慢、客户数据不安全的痛点。</p><p>二、数字人直播  ，开辟“日不落”直播间，助力企业降本增效！（青否ai员工源头v：zhibo175）</p><p>如果说商家智能体是企业的“专属销售团队”，那么青否数字人直播，便是企业的“全能主播天团”。它正以超拟真、全天候、高转化的能力，突破传统直播的时空与人力极限，为不同行业的增长难题提供全新解法。</p><p>数字人直播的核心优势在于无需开店、无需真人主播、无需拍摄素材，降低运营门槛与成本。百度提供丰富的数字人形象，打造24小时“日不落”直播间，用户体验媲美真人，满足多场景营销需求。并且覆盖全时段用户、支持多种商机收集，为企业提供了一个轻量化、高效率的转化新阵地。</p><p>在教育领域，数字人直播成效显著。摄影师导师李国繁面临课程展示单调、真人主播精力有限等痛点，直播采用创新PPT型背景组件，让数字人主播与实时脚本无缝衔接。不仅降低了直播运营成本，更能够复刻主播最佳状态并持续直播，保证每一场直播都是高质量输出。有效看播率上升55%，转化率提升50%以上，GMV增长1.5倍。</p><p>“子贤讲学习”的讲师子贤同样面临直播课堂形式单一、缺乏深度互动、没有专业场景支持等痛点。数字人直播的超拟真形象生成技术解决了这些痛点，数字人完美复刻子贤老师形象，栩栩如生，搭配沉浸式书架背景，为学子打造专属知识殿堂。效果层面，ROI提升170%，转化率提升50%，人均停留时间达5分钟。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047420188" alt="" title="" loading="lazy"/></p><p>某旅行社通过数字人直播推广云南线路，结合生动场景讲解和实时互动，成功将用户“种草”转化为咨询行动，ROI提升60%。</p><p>双11期间，83%开播主播使用过数字人，带货GMV同比提升91%，开播直播间数同比增长119%。</p><p>当智能体24小时在线、数字人直播永不落幕，这些能为企业创造直接价值的AI原生商业化产品，构建了一个“技术-产品-场景-增长”的闭环，为企业降本增效带来了新可能。此外，ai产品的创新，也让营销变得更加自然，在解答用户问题的同时，顺势引导兴趣与转化，实现信息与商业的自然融合，带来更大的商业空间。</p><p>从技术升级到规模化落地，我们正在加速AI原生商业化产品的规模化应用，希望通过AI为更多企业实现新质增长，注入持续稳定的动力。</p>]]></description></item><item>    <title><![CDATA[RAG与Agent性能调优50讲 微笑的]]></title>    <link>https://segmentfault.com/a/1190000047420095</link>    <guid>https://segmentfault.com/a/1190000047420095</guid>    <pubDate>2025-11-22 14:05:12</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在人工智能技术迅猛发展的今天👇🏻ke程：xingkeit点top/10629/，检索增强生成（RAG）与智能体（Agent）已成为企业应用大语言模型的两大核心技术范式。然而，从技术原型到生产系统之间，横亘着一道性能的鸿沟。本课程旨在通过系统化的方法，带领大家深入攻克 RAG 与 Agent 的性能挑战，实现从理论到实践的完整跨越。</p><p>一、开篇：性能优化为何需要体系化思维？<br/>性能问题从来不是孤立存在的。一个缓慢的 RAG 系统，可能是检索质量、生成效率、系统架构等多重因素共同作用的结果。零散的优化往往事倍功半，只有建立体系化的认知框架，才能实现真正的突破。</p><p>性能优化的三个认知层次：</p><p>表层现象：响应慢、答案不准、系统崩溃</p><p>中间层逻辑：检索策略、提示工程、架构设计</p><p>底层原理：嵌入模型、推理机制、系统资源</p><p>体系化攻坚的核心价值：</p><p>避免陷入“头痛医头”的局部优化陷阱</p><p>建立可复用的性能问题分析方法论</p><p>形成持续性能改进的组织能力</p><p>二、基础篇：性能指标体系与评估方法<br/>没有度量，就没有优化。建立科学的性能指标体系是优化的第一步。</p><p>RAG 性能的“铁三角”：</p><p>准确性：答案忠实度、上下文相关性、事实一致性</p><p>效率：端到端延迟、吞吐量、首字返回时间</p><p>成本：令牌消耗、计算资源、API调用费用</p><p>Agent 性能的多维评估：</p><p>任务成功率与完成步数</p><p>工具调用的准确性与效率</p><p>长对话中的上下文维护能力</p><p>基准测试的标准化方法：</p><p>测试数据集的建设与管理</p><p>负载模式的真实性与代表性</p><p>环境一致性的保证措施</p><p>三、核心篇：RAG 性能深度优化<br/>检索阶段的质量突破：<br/>文档分块的策略选择不仅影响检索效率，更决定了信息完整性。基于语义的智能分块相比固定大小的机械分块，能显著提升后续检索的相关性。</p><p>嵌入模型的选择需要权衡通用性与领域适应性。在某些专业领域，对通用模型进行轻量微调可能带来意想不到的效果提升。</p><p>混合检索策略结合了稠密向量搜索与稀疏关键词搜索的优势，而重排模型的引入则像增加了一位专业的“评审官”，对初步结果进行精细筛选。</p><p>生成阶段的效率提升：<br/>提示工程的优化是成本与效果的平衡艺术。清晰的指令、结构化的上下文组织，能够引导模型产生更精准的回答。</p><p>上下文窗口是宝贵的资源，通过摘要提取、关键信息压缩等技术，可以有效提升令牌的利用效率，同时降低处理延迟。</p><p>系统层面的架构优化：<br/>多级缓存设计需要在不同层次上考虑数据的生命周期和失效策略。从内存缓存到持久化存储，每一级都服务于不同的访问模式。</p><p>异步处理机制将可并行操作从关键路径中剥离，比如在生成回答的同时准备后续可能需要的相关资源，实现处理过程的流水线化。</p><p>四、进阶篇：Agent 性能全面提升<br/>规划决策的智能化升级：<br/>思维链技术不仅提升了推理的透明度，更重要的是为优化提供了可分析的中间过程。通过分析这些思考轨迹，可以识别出决策瓶颈。</p><p>子目标分解的质量直接影响任务执行效率。良好的分解应该满足原子性、可验证性和适度的粒度，避免过于琐碎或过于宏大的步骤划分。</p><p>工具使用的精准化控制：<br/>工具描述的清晰度决定了 Agent 的理解深度。优秀的描述应该包含功能说明、参数规范、典型用例和异常处理建议。</p><p>失败恢复机制是系统鲁棒性的关键。从简单的重试策略到复杂的备选方案切换，都需要在设计阶段充分考虑。</p><p>记忆管理的有效性保障：<br/>记忆的筛选与压缩技术帮助 Agent 在长对话中保持焦点。就像人类的记忆机制，重要的信息被强化，次要的细节逐渐淡化。</p><p>上下文窗口的优化使用是一门艺术。通过分层存储、重要性排序等技术，可以在有限的窗口内保持最相关的信息。</p><p>五、实战篇：企业级应用的性能保障<br/>可观测性体系建设：<br/>全链路追踪不应该只是开发阶段的调试工具，更应该成为生产环境的监控手段。从用户提问到最终回答，每一个环节的性能数据都应该被采集和分析。</p><p>自动化评估流水线：<br/>持续性能监控的核心是建立自动化的评估机制。通过定时执行标准化的测试用例，可以及时发现性能回退，避免问题累积。</p><p>成本控制的精细化管理：<br/>令牌消耗的优化需要从多个维度入手。模型选型、提示设计、缓存策略共同决定了最终的成本效益。</p><p>高可用架构设计：<br/>容错与降级策略是系统稳定性的最后防线。当核心组件失效时，优雅的降级方案比完美的恢复机制更有价值。</p><p>六、融合篇：RAG 与 Agent 的协同优化<br/>架构模式的深度融合：<br/>RAG 作为 Agent 的知识引擎，为其决策提供实时、准确的信息支持。这种组合创造了“深思熟虑的行动者”的新型智能体范式。</p><p>性能瓶颈的联合分析：<br/>在复杂系统中，性能问题往往产生于组件交互的边界。建立端到端的性能分析视角，才能识别出真正的瓶颈所在。</p><p>资源调度的全局优化：<br/>计算资源在检索、生成、推理等环节的合理分配，需要基于业务场景的特点进行动态调整。</p><p>七、未来篇：性能优化的持续演进<br/>技术趋势的前瞻洞察：<br/>新模型架构、优化算法、硬件加速等技术发展，正在不断重新定义性能优化的边界。</p><p>组织能力的系统构建：<br/>性能优化不应该依赖个别专家，而应该成为团队的核心能力。建立知识库、工具链、流程规范，让优秀的实践得以沉淀和传承。</p><p>文化氛围的精心培育：<br/>对性能极致的追求应该融入团队文化的基因。从代码审查到架构评审，每一个环节都应该包含性能的考量。</p><p>结语：从性能优化到卓越体验<br/>经过这 50 个专题的系统化攻坚，我们深刻认识到：性能优化不是一项孤立的技术活动，而是贯穿产品整个生命周期的持续过程。</p><p>优秀的性能表现最终将转化为卓越的用户体验。当用户能够快速获得准确、可靠的回答，当系统能够在压力下保持稳定，技术价值就真正实现了向业务价值的转化。</p><p>在这个快速发展的领域，唯一不变的是变化本身。保持学习的热情，维持实践的勇气，坚守系统的思维，我们将能够在性能优化的道路上走得更远，为人工智能技术的落地应用贡献更多价值。</p><p>体系化的性能优化之路，既是对技术的深度探索，也是对工程艺术的执着追求。让我们一起，在这条道路上坚定前行。</p>]]></description></item><item>    <title><![CDATA[Binary Ninja 5.2 发布 ]]></title>    <link>https://segmentfault.com/a/1190000047420097</link>    <guid>https://segmentfault.com/a/1190000047420097</guid>    <pubDate>2025-11-22 14:04:22</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>Binary Ninja 5.2.8614 (macOS, Linux, Windows) - 反编译器、反汇编器、调试器和二进制分析平台</p><p>interactive decompiler, disassembler, debugger, and binary analysis platform</p><p>请访问原文链接：<a href="https://link.segmentfault.com/?enc=NbeOIzX2MlE38Y%2Fphp%2BQ3Q%3D%3D.WfgTwNetYcXkGT%2Bz1C8wbPSKfwsWnlKwxhRwdJ5SGNTYj7FVwk%2Bb2RvWFC%2B49yST" rel="nofollow" target="_blank">https://sysin.org/blog/binary-ninja/</a> 查看最新版。原创作品，转载请保留出处。</p><p>作者主页：<a href="https://link.segmentfault.com/?enc=kOyQgmrBBbwx9nubo1eYwg%3D%3D.tkoBQ8Nka9dyWJBJJ3xezeegn9FL3CZJaKwbXpke%2FGQ%3D" rel="nofollow" target="_blank">sysin.org</a></p><hr/><p>Binary Ninja</p><p>A New Type of Reversing Platform</p><p>Binary Ninja  是一个交互式反编译器、反汇编器、调试器和二进制分析平台，由逆向工程师为逆向工程师打造。它在开发时特别注重提供高质量的自动化 API  以及简洁易用的图形界面。Binary Ninja 正被全球的恶意软件分析师、漏洞研究人员和软件开发者广泛使用。Binary Ninja  具备跨平台的强大优势 (sysin)，可反编译为 Windows、macOS 和 Linux 上的许多常见架构构建的软件。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047307450" alt="decompiler, disassembler" title="decompiler, disassembler"/></p><h2>功能简介</h2><ul><li><p><strong>反编译 Decompile</strong></p><p>针对任何受支持的架构（包括您自己的架构）反汇编和反编译代码为 C 或 BNIL。</p></li><li><p><strong>分析 Analyze</strong></p><p>可视化控制流并以交互方式浏览交叉引用。</p></li><li><p><strong>自动化 Automate</strong></p><p>使用 C++、Python 和 Rust API 从 UI 内部或外部自动进行分析。</p></li><li><p><strong>调试 Debug</strong></p><p>在任何受支持的架构或平台上本地或远程调试程序。</p></li><li><p><strong>协作 Collaborate</strong></p><p>使用我们的企业产品通过同步提交轻松协作。</p></li><li><p><strong>加速 Accelerate</strong></p><p>通过额外的 AI 功能加速分析并优化理解。</p></li></ul><h2>新增功能</h2><p><strong>Binary Ninja 5.2，代号 “Io”，现已发布</strong>，包括位域支持、容器、Hexagon 支持以及更多功能。</p><p>此次发布包含了一些最具影响力且备受用户期待的功能，包括位运算数据结构支持（第二大需求）、容器支持（第五大需求）、对 Hexagon 架构的完整支持（包括反汇编和反编译），以及更多其他功能。</p><p>此更新日志仅包括稳定版本的更新内容。</p><p>5.2.8614（2025 年 11 月 13 日）</p><p><strong>主要特性</strong>：</p><ul><li>免费版功能：Objective-C 工作流、WARP 插件、DWARF 导入和 TTD 支持</li><li>位域支持</li><li>容器支持</li><li>自定义字符串 / 常量</li><li>Ghidra 导入</li><li>WARP 服务器</li><li>Hexagon 支持</li><li>新的交叉引用用户界面</li><li>TTD 查询与分析</li><li>Objective-C 改进</li></ul><p>5.2 包含了大量的改进和修复，篇幅较长，详见官方更新记录。</p><h2>下载地址</h2><p>Binary Ninja 5.2.8614 for macOS, Linux, Windows</p><ul><li>请访问：<a href="https://link.segmentfault.com/?enc=ECW7IuB7CM32J1mCUhgoxQ%3D%3D.PpoLkL0Mih4dSENrKpocJVw8YF4L90B1ghQNHvmUZUBgdbSPVlp%2By9WzUp37pBuC" rel="nofollow" target="_blank">https://sysin.org/blog/binary-ninja/</a></li></ul><hr/><p>更多：<a href="https://link.segmentfault.com/?enc=jQn1%2FxiO35u9BeNUQRyFhw%3D%3D.zDDeW5%2BUOBBEIFBVDFVm4iIMqCKG1aVTXi0CzJhlG7M%3D" rel="nofollow" target="_blank">HTTP 协议与安全</a></p>]]></description></item><item>    <title><![CDATA[Cisco Secure Client ]]></title>    <link>https://segmentfault.com/a/1190000047420100</link>    <guid>https://segmentfault.com/a/1190000047420100</guid>    <pubDate>2025-11-22 14:03:33</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>Cisco Secure Client 5.1.13.177 (macOS, Linux, Windows &amp; iOS, Android) - 远程访问客户端</p><p>思科安全客户端（包括 AnyConnect）</p><p>请访问原文链接：<a href="https://link.segmentfault.com/?enc=M11Byd6OwNG%2BkJ9MfXTTJQ%3D%3D.5NUl%2Bx8LWTkV9h0WvdbszGXxUwrKJAPRuP7kmyUKVpX6H5upTfz8z8nmdpQCPQiD" rel="nofollow" target="_blank">https://sysin.org/blog/cisco-secure-client-5/</a> 查看最新版。原创作品，转载请保留出处。</p><p>作者主页：<a href="https://link.segmentfault.com/?enc=NAg7KYCmT2ccNHIY%2BDZ5YA%3D%3D.5kSg8cDqLtyUOdeLSSZqrt7ckqSQw0Qjo3ARnHSMg5k%3D" rel="nofollow" target="_blank">sysin.org</a></p><hr/><p>Cisco Secure Client (including AnyConnect)</p><p>思科安全客户端（包括 AnyConnect）</p><h2>安全访问只是开始</h2><p>您的团队需要轻松访问公司资源和私有应用程序。您需要确保您的业务安全。思科安全访问使之成为现实。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047317154" alt="Cisco Secure Client" title="Cisco Secure Client"/></p><h2>Cisco Secure Client 5 新增功能</h2><p><strong>Cisco Secure Client 5.1.13.177</strong> 新功能</p><p>14-Nov-2025</p><p>此版本包括以下新功能和支持更新，并解决了在 Cisco Secure Client 5.1.13.177 中描述的缺陷。</p><ul><li><p>此版本解决了 CSCws00283 问题：“当信任捆绑签名证书过期时，Zero Trust Access 模块无法启动”。</p><p>此缺陷仅影响运行 Cisco Secure Client 的 Zero Trust Access 模块的用户，版本为 5.1.8 到 5.1.12。在受影响的版本（5.1.8–5.1.12）中，Zero Trust Access 模块错误地验证了代码签名证书的过期日期 (sysin)。如果客户端在到达过期日期之前没有升级到 5.1.13 或更高版本，则该模块将停止工作。</p><p>受影响的 Cisco Secure Client Zero Trust Access 模块版本：</p><ul><li>5.1.8：必须在 2025 年 11 月 20 日之前升级到 5.1.13 或更高版本</li><li>5.1.9：必须在 2026 年 1 月 14 日之前升级到 5.1.13 或更高版本</li><li>5.1.10：必须在 2026 年 1 月 14 日之前升级到 5.1.13 或更高版本</li><li>5.1.11：必须在 2026 年 6 月 4 日之前升级到 5.1.13 或更高版本</li><li>5.1.12：必须在 2026 年 6 月 4 日之前升级到 5.1.13 或更高版本</li></ul></li><li><p>macOS UI 更新：</p><ul><li>在统计表中新增了复制和粘贴功能，支持 <em>全选</em> 和 <em>复制</em> 的键盘快捷键。</li><li>在统计表中添加了自定义悬停工具提示，以便完整查看详细内容。</li><li>能够在统计页面内展开和折叠项。</li></ul></li><li>XDR 取证诊断现在已在 macOS 和 Windows 中收集到 DART。</li><li>在 Zero Trust Access 中，新增了检测和管理由用户交互触发的事件的功能 (sysin)，并提供了在 Windows 和 macOS 上暂停代理配置的选项。有关更多信息，请参阅 Zero Trust Access 模块。</li><li>Linux ARM64 支持 FIPS 140-2 和 140-3（CSCCwq60310）。</li><li>配置文件编辑器中的“登录前启动”偏好已被移除，管理员无法再控制此选项。如果您有使用此偏好的现有配置文件，它们仍会被视为有效配置文件。启用了“登录前启动”偏好的用户将受到此更改影响。</li><li>如果选择通过电子邮件发送 DART 捆绑包，现在需要输入 <code>attach@cisco.com</code>，以便自动将 DART 捆绑包附加到案例中。</li><li><p>版本 5.1.13.177 包含各个模块的以下版本：</p><ul><li>Zero Trust Access — 5.1.13.3108</li><li>Secure Client UI — 5.1.13.1379</li><li>Cisco AnyConnect VPN 核心 — 5.1.13.177</li><li>DART — 5.1.13.177</li><li>Umbrella — 5.1.13.177</li><li>SBL — 5.1.13.177</li><li>Network Access Manager — 5.1.13.177</li><li>Network Visibility Module — 5.1.13.177</li><li>Secure Firewall Posture — 5.1.13.177</li><li>ThousandEyes — 2.23.0</li><li>ISE Posture — 5.1.13.177</li></ul></li></ul><h2>下载地址</h2><p><strong>Cisco Secure Client 5 for Linux</strong> x64 (deb, rpm, tgz), Release 5.1.13.177<br/><strong>Cisco Secure Client 5 for Linux</strong> arm64 (deb, rpm, tgz), Release 5.1.13.177<br/><strong>Cisco Secure Client 5 for macOS</strong> Universal, Release 5.1.13.177<br/><strong>Cisco Secure Client 5 for Windows</strong> x64, Release 5.1.13.177<br/><strong>Cisco Secure Client 5 for Windows</strong> arm64, Release 5.1.13.177 (请慎选，仅适用于少数高通处理器的电脑)<br/>Cisco Secure Client 5 for iOS, Release 5.x <a href="https://link.segmentfault.com/?enc=lDP%2BQAwWJ%2Fppu3jVu%2FNDDw%3D%3D.L31no1kqyU6jB3VKooyKbqNJUYLTtosAN8Hu7Fik2PJ4ySzschQ7GLNvAqpUPt1GglF4sSTW%2F%2BuwnMBGNndy0w%3D%3D" rel="nofollow" target="_blank">App Store</a>（点击直接访问，CN 现已恢复 [2025 年 8 月]）<br/>Cisco Secure Client 5 for Android, Release 5.x <a href="https://link.segmentfault.com/?enc=kDoc0bE8a674x8kekoG7qw%3D%3D.FZZ8DmcLBjYb%2FJOYwGwLDGmfA1QYyE680Im2uGbwtTUbqDncMExXJeREFkSPWaTWdpJdgSXvIwkGdJqeNBtfoyUPNjnDG2qRYdfZfr2h%2BdheJxobk8kC1mcnK1%2Fbku6%2F" rel="nofollow" target="_blank">Google Play</a>（点击直接访问，有离线 apk）</p><p>发布日期： 14-Nov-2025</p><p>请访问：<a href="https://link.segmentfault.com/?enc=%2BtXZYxrAuRJxWYu5%2B1SF5A%3D%3D.lTP9zS98%2BBF7tnv7WjG27xPQqx9ah7OsJLnt%2B2sfk5Q9zZvrm30WrR1AlwPcBMVL" rel="nofollow" target="_blank">https://sysin.org/blog/cisco-secure-client-5/</a></p><hr/><p>更多：<a href="https://link.segmentfault.com/?enc=DZg842DxRDkg2Ieum9hN6w%3D%3D.xvaEM%2BzKfppAw8e4Bsj09vQQ94jDo3euyeC6k6km%2B4c%3D" rel="nofollow" target="_blank">Cisco 产品下载链接汇总</a></p>]]></description></item><item>    <title><![CDATA[数据要素怎么用？80%的企业只知其一 数]]></title>    <link>https://segmentfault.com/a/1190000047420111</link>    <guid>https://segmentfault.com/a/1190000047420111</guid>    <pubDate>2025-11-22 14:02:59</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><strong>数据到底该怎么用？</strong><br/>明明公司积累了大量客户数据，却不知道如何用来提升销量；每次做决策都靠经验拍板，结果总是不尽人意；看着别人用数据驱动业务增长，自己却不知从何入手？<br/>这三个问题，恰恰暴露了大多数企业在数据运用上的短板。<br/>其实说白了，就是不知道<strong>如何把数据变成真正的生产要素。</strong><br/>今天我就来跟大家好好聊聊数据要素，帮你跨出从拥有数据到用好数据的关键一步。</p><h2>一、什么是数据要素？</h2><p>咱们来看最根本的问题：数据要素，到底是个啥？<br/>用最朴素的话来说，<strong>数据要素，就是把“数据”看成和土地、劳动力、资本、技术一样，是一种重要的生产资料，能参与生产和价值创造。</strong><br/>听着是不是有点抽象？我给你拆开讲。<br/>过去，我们盖一个工厂，需要土地（场地）、需要钱（资本）、需要工人（劳动力）、需要机器（技术）。<br/>现在，我们运营一个公司，除了上面那些，还需要什么？我们需要知道客户是谁、喜欢什么、市场趋势如何、生产线怎么优化效率最高……这些问题的答案，就藏在<strong>数据</strong>里。<br/>数据要素化，说白了，就是<strong>承认数据是一种资产，是一种新的数据资源</strong>，并且要把它正式地、规模化地投入到经济社会的大生产中去。<br/><strong>这是一种认知上的根本性转变。</strong><br/>理解了数据要素“是什么”，你可能会问它凭什么这么特殊？它到底有什么看家本领？</p><h2>二、数据要素的核心</h2><p>它的核心特质是什么？理解了这个，你才算真正懂了数据要素。<br/>我一直强调，数据要素有四个核心特性，是传统生产要素不具备的：</p><h4>1、非竞争性</h4><p>这是数据最神奇的特性之一。传统要素具有排他性：一块地，我用了你就不能用；一台机器，我开着你就不能同时开。<br/>但数据完全不同：同一组数据，我可以用来做分析，他可以同时用它来训练算法模型，你还可以用它来做宏观趋势研究，三者之间<strong>互不干扰</strong>。<br/>要知道，<strong>数据本身不会被消耗掉</strong>。这个特性意味着数据可以被无限次、低成本地重复使用，价值可以不断被挖掘。<br/>举个例子你就知道了：<br/>一份全国性的气象数据，包含了温度、湿度、风速等历史记录。航空公司的调度部门可以同时用它来分析航线上的气流模式，来优化航班计划、节省燃油；农业公司的专家也可以同时访问这份完全相同的数据，用于研究不同气候条件对农作物产量的影响，指导种植；而保险公司的精算师同样能基于这份数据，开发针对极端天气的农业险产品。你看，同一份数据，在同一时间，被多个完全不同的主体用于不同的价值创造活动，数据本身没有丝毫损耗。<br/>那么问题来了，我们该怎么重复使用这些数据？<br/>很简单，我们可以借助<strong>数据集成工具</strong>，比如<strong>FineDdatLink</strong>，在数据连接管理处选择引用，各部门都能用上主数据，还能一键跳转到所引用的数据链接。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047420113" alt="image" title="image"/></p><h4>2、可复制共享，成本极低</h4><p><strong>物理资源的转移成本很高</strong>。你把一批精密仪器从广东运到长春，需要时间、运费，还有损坏风险等。但数据不同，你复制1TB的数据（这可能是整个公司数年的交易记录）并通过网络传输到全球任何一个角落，所需的成本就是几分钟和一点点电费的事，其边际成本几乎为零。<br/>比如说，<br/>一家电商平台，将其经过脱敏处理的用户购物行为数据，比如点击、浏览、收藏、购买记录等整理成一个分析数据集。这个数据集可以几乎零成本地复制出三份完全一样的副本。一份提供给本公司的市场部，用于分析用户偏好，策划精准营销活动；另一份副本，可以提供给合作的产品研发团队，帮助他们洞察市场需求，设计新产品；第三份副本，甚至可以安全地共享给外部的物流研究机构，用以分析区域消费习惯，优化全国的仓储布局。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047420114" alt="image" title="image" loading="lazy"/><br/>在FineDdatLink这里，点击目标数据实施同步设置，就能实现各部门用的数据都是同一个，还能不断重复使用。<br/><strong>一次采集，近乎零成本地复制与共享，就能在多个场景下持续产生新的价值</strong>。这种极低的流动成本，是土地、机器等任何实体要素都无法比拟的。</p><h4>3、价值的不确定性</h4><p><strong>这里要问：一堆数据值多少钱？很难说。它的价值完全取决于你怎么用。</strong><br/>比如，一家餐厅积累了三年的客户消费流水数据。如果只是用来做简单的财务对账，它的价值就非常有限。但如果对这些数据进行深度挖掘，就可能发现如特定节假日的消费高峰与菜品关联这样的规律，基于这些洞察，餐厅可以优化菜单设计、策划精准促销，直接提升营收。<br/>你看，数据没变，但应用方式不同，其价值也不一样。<br/><strong>所以说它的价值是潜在的、动态的、需要被激活的。</strong></p><h4>4、强协同性</h4><p><strong>数据本身很难单独创造价值，但它和别的要素一结合，就能产生1+1&gt;2的倍增效应：</strong></p><ul><li>数据+劳动力，能提升人的决策效率；</li><li>数据+资本，能催生智能投顾；</li><li>数据+技术，本身就是AI的粮食。</li></ul><p>它几乎能赋能所有传统行业，是效率的倍增器。<br/>你懂我意思吗？正是因为这些独特的核心，数据才配得上“要素”这个名号，否则它永远只是附属品。</p><h2>三、数据要素的现状</h2><p>用过来人的经验告诉你，当前数据要素的发展，可以从三个层面来看：</p><ol><li><strong>从国家层面看</strong>： 方向是无比明确的。国家已经把数据要素提升到了战略高度，在推动数据基础设施建设，大方向是<strong>让数据流动起来</strong>。</li><li><strong>从行业和企业层面看</strong>：</li></ol><ul><li><strong>头部互联网公司</strong>拥有海量数据，并且已经利用数据形成了强大的商业壁垒和盈利模式。但问题是，数据孤岛现象严重，很难也不愿拿出来与别人共享。</li><li><strong>传统企业和中小型企业</strong>，大部分还处于有数据，但不会用的阶段。可能积累了不少客户数据、生产数据，但缺乏技术和人才去分析、去变现。很多企业老板的思维还停留在数据是成本的阶段，没意识到它是资产。</li><li><strong>数据流通市场</strong>，还处在非常早期的探索期。数据怎么定价？怎么交易？交易的安全和隐私如何保障？这些都是大难题。所以现在市面上真正大规模、规范的数据交易还比较少。</li></ul><ol><li><strong>从技术和安全层面看</strong>： 技术在不断进步，隐私计算、区块链等技术试图在“数据可用不可见”的前提下促进流通。但数据安全和隐私保护始终是要关注的。用户担心自己的数据被滥用，企业担心核心数据泄露，这极大地制约了数据的开放和共享。</li></ol><p>了解了数据要素现状，那我们到底要怎么用它来为企业增效呢？</p><h2>四、怎么利用数据要素来增效？</h2><p>这是最关键的一部分，要想利用数据要素增效，下面这个思路肯定能帮到你。</p><h4>第一步：做好数据治理</h4><p>你不可能用一堆脏乱差的数据做出正确的决策。所以第一步，是把你的数据管起来。这包括：</p><ul><li><strong>采集</strong>：把业务中关键环节的数据有意识地记录下来。</li><li><strong>清洗</strong>：处理掉错误、重复、不完整的数据。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047420115" alt="image" title="image" loading="lazy"/></p><ul><li><strong>整合</strong>：把分散在不同系统的数据打通，形成一个统一的视图。</li><li><strong>标准化</strong>：统一数据的格式和定义。</li></ul><h4>第二步：进行分析与挖掘</h4><p>数据治理好了，就要开始下一步了。</p><ul><li><strong>描述性分析</strong>：“发生了什么”。比如，上个季度哪个产品销量最好？哪个地区的客户投诉最多？</li><li><strong>诊断性分析</strong>：“为什么会发生”。比如要问，为什么A产品销量突然下滑？通过数据追溯，发现是因为某个差评被大量传播。</li><li><strong>预测性分析</strong>：“可能会发生什么”。根据历史销售数据和天气预报，预测下个月冰饮的销量。</li><li><strong>处方性分析</strong>：“应该怎么做”。比如说，系统自动建议你为高价值客户提供专属折扣，以提升复购率。</li></ul><h4>第三步：落实到具体业务场景</h4><p><strong>分析出的结论，必须作用于业务，才能叫增效</strong>。我给你几个最直接的场景：</p><ul><li><strong>营销增效</strong>：可以对用户画像和行为的分析，实现广告的精准投放和商品的个性化推荐来降低获客成本。这比你撒网式地打广告，效率高得多。</li><li><strong>生产与供应链增效</strong>：比如在制造业，通过分析设备传感器数据，可以预测设备何时可能故障，从而实现预测性维护，减少停机损失。</li><li><strong>管理与决策增效</strong>：管理层看的不再是感觉，而是实打实的用户留存率、流程转化率、员工人效等数据。决策的依据从“我觉得”变成了“数据表明”，这能极大减少决策失误，提升组织运行效率。</li><li><strong>创新增效</strong>：很多互联网产品的迭代，都是数据驱动的。所以分析海量的用户反馈和数据，可以发现潜在的新需求，从而催生新的产品和服务。</li></ul><h4>第四步：参与数据流通</h4><p>当你的数据能力很强，有了富余的数据，或者你需要外部数据来补充自己的视角时，你就可以考虑数据的<strong>对外利用</strong>。<br/>就比如，购买外部的地理位置数据来优化你的物流路线。这就是在<strong>更大的范围</strong>内配置数据要素，实现社会总效率的提升。</p><h2>总结</h2><p>数据要素不是一个遥远的概念，它正在我们身边发生。<br/>它的价值，不在于数据本身有多庞大，而在于我们能否把它变成<strong>有效的洞察和行动</strong>。<br/>现在，不妨重新审视你手边的数据，哪怕只是一张简单的表格。问问自己：它能告诉我什么？我能用它优化什么？在你回答了这些问题之后，你就知道下次再面对类似的问题时该怎么做了。</p>]]></description></item><item>    <title><![CDATA[数据管理的四大支柱：一文讲清数据治理、数]]></title>    <link>https://segmentfault.com/a/1190000047420127</link>    <guid>https://segmentfault.com/a/1190000047420127</guid>    <pubDate>2025-11-22 14:02:10</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>我以前在做数据时，常会遇到这种情况——</p><ul><li>市场部和销售部报上来的“活跃用户数”永远对不上；</li><li>想做个客户分析，却发现同一个客户在CRM系统里存了四条重复信息；</li><li>业务部门急着要个数据看板，技术团队却说至少要排期一个月。</li></ul><p>为什么会这样？<br/>说白了，就是<strong>没有把数据管理做好</strong>，导致<strong>数据标准不统一、核心数据混乱、数据响应速度慢。这些问题不解决，所谓的“数据驱动业务”根本无从谈起。</strong></p><p>要解决这些问题，关键就在于理清四个核心概念：数据治理、数据中台、数据仓库和主数据。接下来，我就直接带你一步步弄懂这四大支柱分别管什么、怎么用，以及它们之间如何配合。</p><p>相信大家看了这篇文章后，心里会有对数据管理一个整体的把握。</p><h2>一、 数据治理</h2><p>简单来说，数据治理不是某个具体的技术或工具，它是<strong>一套体系，一套关于数据管理的规章制度和办事流程</strong>。它回答了数据领域的核心问题：数据谁负责？数据质量怎么保证？数据安全怎么管？数据怎么被合规使用？<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047420129" alt="image" title="image"/><br/>数据治理的核心目标是<strong>确保数据是可信、安全、可用的</strong>。</p><p>具体要怎么做呢？<br/>比如在保证数据安全方面，这里我用到的是<strong>数据集成工具FineDataLink</strong>，它除了能接收各个不同源的数据，还能对数据进行权限设置，非授权人员是不能进行查阅数据的，只需要在管理系统的权限管理上进行授权即可，非常简单方便。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047420130" alt="image" title="image" loading="lazy"/><br/>数据治理的作用具体体现在：</p><ol><li><strong>明确权责</strong>： 指定谁拥有这份数据，谁负责维护它的质量。出了问题找谁，一目了然。</li><li><strong>保障质量</strong>： 建立数据质量的标准和检查机制，比如数据必须完整、准确、唯一、及时。比如，客户表中的“性别”字段，不能一会儿是“男/女”，一会儿是“1/2”。</li><li><strong>加强安全与合规</strong>： 定义哪些是敏感数据，比如身份证号、家庭详细住址等，谁可以访问，如何加密，如何脱敏，以满足像《个人信息保护法》这样的法规要求。</li><li><strong>统一认知</strong>： 建立业务词汇表，让全公司对同一个业务术语的理解是一致的，要避免出现如市场部和销售部说的“活跃用户数”定义不一致。</li></ol><p>听着是不是很熟？ 你们公司是不是经常出现数据报表对不上、同一个指标不同部门给出的数字不一样、找不到数据负责人、不敢用数据怕泄露的情况？这些都是数据治理缺位的典型表现。</p><p>所以，我一直强调，数据治理是基石。没有它，后面的所有东西都难以稳固。</p><h2>二、 数据仓库</h2><p>数据仓库是一个大型的、中心化的<strong>存储系统</strong>，专门用来存储从各个业务系统，比如ERP、CRM、网站和APP等<strong>汇总过来的、经过清洗和转换的、历史的数据</strong>。它的设计目标不是为了处理日常交易，而是为了复杂的<strong>分析和回溯</strong>。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047420131" alt="image" title="image" loading="lazy"/><br/>数据仓库会定期从业务系统把收集到的数据进行更新、整理，然后送到数据仓库统一存放，这些数据是结构化的，按主题分类，方便数据分析师来查阅、研究历史规律。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047420132" alt="image" title="image" loading="lazy"/><br/>数据仓库的核心作用是<strong>支持企业级的、历史的数据分析和决策。</strong></p><ol><li><strong>整合数据</strong>： 把分散在不同地方的数据汇集到一起，打破数据孤岛。</li><li><strong>支持复杂查询与分析</strong>： 它的结构，比如星型、雪花型，就是为高效的、多维度、大数据量的查询而设计的。你可以轻松地分析去年哪个区域的哪个产品线，在哪个季度的销售额最高？这类复杂问题。</li><li><strong>保存历史</strong>： 它会记录数据的变化，让你能够回溯到过去的某个时间点，看当时的数据状态是怎样的。</li></ol><p>你懂我意思吗？ 数据仓库关注的是过去发生了什么以及为什么会发生，<strong>它是商业智能和传统报表的主要数据来源。</strong></p><p>但是，随着业务发展越来越快，前线部门经常抱怨：我想要一个数据服务，怎么等那么久？数据仓库虽然稳定，但响应业务变化的速度不够快。那怎么办呢？这时候就要靠数据中台了。</p><h2>三、 数据中台</h2><p>数据中台是<strong>一个理念、一套组织架构和一系列技术组件的集合</strong>。它的核心思想是，将数据作为一种资产和能力，通过标准化的方式<strong>封装成易于使用的服务</strong>，快速地提供给前台业务去使用，从而支撑业务的快速创新和响应。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047420133" alt="image" title="image" loading="lazy"/><br/>举个例子：</p><p>一家电商公司有商城、生鲜、国际业务等多个前端团队。在没有数据中台时，每个团队都各自开发一套用户画像和商品推荐系统，重复建设且数据标准不一。后来，公司成立数据中台团队，将用户行为数据、商品数据等统一加工，封装成“用户偏好标签查询API”、“智能推荐算法服务”等标准化服务。现在，任何业务线想要上线一个新推荐功能，只需直接调用这些服务，几天就能完成，就不用再从零开始处理数据和开发算法了。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047420134" alt="image" title="image" loading="lazy"/><br/>数据中台的核心作用是加速数据价值从后台到前台的转化过程，实现“<strong>数据赋能业务</strong>”。</p><ol><li><strong>提升效率</strong>： 避免每个业务部门都重复建设类似的数据处理流程，实现数据能力的复用。</li><li><strong>加速创新</strong>： 业务部门可以快速组合数据服务，试验新的业务场景，比如快速上线一个数据营销活动。</li><li><strong>能力下沉</strong>： 把复杂的数据技术能力，比如如实时计算、AI算法，封装成简单的服务，让业务人员也能轻松调用。</li></ol><p>数据中台并不是要取代数据仓库，而是在数据仓库提供的“历史数据分析”能力之外，补充了更强调<strong>服务化和快速响应</strong>的能力。</p><h2>四、 主数据</h2><p>主数据指的是<strong>企业核心业务实体中，那些需要跨部门、跨系统共享的、最基础、最关键、相对稳定的数据</strong>。比如客户、产品、员工、供应商等的关键信息。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047420135" alt="image" title="image" loading="lazy"/><br/>主数据管理的核心目标是创建并维护企业核心数据的单一视图，也就是“一份真实版本”。</p><ol><li><strong>保证一致性</strong>： 确保在销售系统、客服系统、财务系统里，同一个客户的编码、名称、基本信息是完全一致的。</li><li><strong>消除重复</strong>： 通过统一的规则，识别并合并重复的记录。</li><li><strong>支撑业务流程：</strong> 准确的客户主数据能支撑精准营销，准确的产品主数据能支撑正确的订单处理。</li></ol><h2>四者的联系：一个有机的整体</h2><p>接下来我们把这四个概念放到一起，看看它们是如何协同工作的。我用一个逻辑链条来串联一下：</p><ol><li>首先，你需要<strong>建立规则</strong>。 这是数据治理，它规定了整个数据世界该怎么运行，这是所有后续工作的前提。</li><li>接着，你要<strong>管理好最重要的核心实体信息</strong>。 这就是主数据管理，它在数据治理的框架下，确保企业最核心的实体数据是干净、统一、可信的。</li><li>然后，你要<strong>建设一个专门用于分析和回溯历史的系统</strong>。 这其实是数据仓库，它按照数据治理定的规矩，把清洗好的数据整合起来，存好，主要用于支撑传统的、偏向宏观和历史的分析。</li><li>最后，你为了更高效地赋能业务，<strong>建立了一套服务化机制</strong>。也就是是数据中台，它同样在数据治理的规则下运作，它会利用数据仓库里已经整理好的数据，把数据变成各种可复用的服务，快速响应用户的个性化、实时化需求。</li></ol><p><strong>所以，它们的关系是：</strong></p><ul><li>数据治理是基石和保障，贯穿于其他三者之中。</li><li>主数据管理是数据治理的关键实践和突破口，它的成果为数据仓库和数据中台提供了高质量的核心数据源。</li><li>数据仓库是面向历史的、稳定的“数据分析基地”。</li><li>数据中台是面向未来的、敏捷的“数据服务工厂”，它构建在数据治理、主数据管理和数据仓库等基础能力之上。</li></ul><p>用过来人的经验告诉你，很多企业的问题就在于，没有打好数据治理和主数据的基础，就直接去建数据中台或者数据仓库，结果发现里面的数据一团乱麻，根本无法信任和使用不说，还会浪费大量的时间，最终导致项目难以成功。</p><h2>总结</h2><p>聊了这么多，不知道你是否对这四个概念有了更清晰的认识？</p><p>说到底，这四个概念本质上是一个<strong>环环相扣、层层递进</strong>的体系。它们共同回答了企业数据管理的四个核心问题：<strong>规矩怎么定？核心身份怎么管？历史怎么分析？能力怎么复用？</strong></p><p>其实数据管理根本不难，关键是要把这四个部分做好了，这样你就能深入理解为什么数据能指导业务驱动了。你说是不？</p>]]></description></item><item>    <title><![CDATA[动物识别系统【最新版】Python+Te]]></title>    <link>https://segmentfault.com/a/1190000047420162</link>    <guid>https://segmentfault.com/a/1190000047420162</guid>    <pubDate>2025-11-22 14:01:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>一、简介</h2><p>动物识别系统，通过TensorFlow搭建卷积神经网络算法，并收集了4种常见的动物数据集（猫、狗、鸡、马），对其进行多轮迭代训练，最后得到了一个精度较高的模型，并搭建Web可视化操作平台。<br/><strong>前端</strong>: Vue3、Element Plus<br/><strong>后端</strong>：Django<br/><strong>算法</strong>：TensorFlow、卷积神经网络算法<br/><strong>具体功能</strong>：</p><ol><li>系统分为管理员和用户两个角色，登录后根据角色显示其可访问的页面模块。</li><li>登录系统后可发布、查看、编辑文章，创建文章功能中集成了markdown编辑器，可对文章进行编辑。</li><li>在图像识别功能中，用户上传图片后，点击识别，可输出其识别结果和置信度</li><li>基于Echart以柱状图形式输出所有种类对应的置信度分布图。</li><li>在智能问答功能模块中：用户输入问题，后台通过对接Deepseek接口实现智能问答功能。</li><li>管理员可在用户管理模块中，对用户账户进行管理和编辑。</li></ol><p><strong>选题背景介绍</strong></p><p>随着人工智能技术的快速发展，图像识别作为其重要分支，在多个领域展现出广泛的应用价值。传统的动物识别方法依赖人工特征提取，效率低且主观性强。为此，本课题基于TensorFlow框架，利用卷积神经网络算法构建了一个高效准确的动物识别系统。系统选取猫、狗、鸡、马四类常见动物作为识别对象，通过多轮迭代训练得到高精度模型，并基于Vue3与Django开发了前后端分离的Web平台。该系统不仅实现了动物图像识别及置信度可视化，还结合Markdown编辑器、智能问答等功能，满足了用户多样化的需求，为动物识别技术的实际应用提供了可行的解决方案，具有一定的理论研究意义和实际应用价值。</p><h2>二、系统效果图片展示</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047420164" alt="图片" title="图片"/>{{{width="100%" height="auto"}}}<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047420165" alt="图片" title="图片" loading="lazy"/>{{{width="100%" height="auto"}}}</p><h2>三、演示视频 and 完整代码 and 安装</h2><p>地址：<a href="https://link.segmentfault.com/?enc=a59I%2Bbmw3UBQEtvwN1ZiOQ%3D%3D.nPSs0emx4JoXheNjQw7mGZRwKQ%2FXkiOJO191BUCIAjY%3D" rel="nofollow" target="_blank">https://ziwupy.cn/p/vJyapU</a></p><h2>四、TensorFlow介绍</h2><pre><code class="python">import tensorflow as tf
from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions
import numpy as np
from PIL import Image

# 加载预训练的ResNet50模型
model = ResNet50(weights='imagenet')

def predict_image(image_path):
    # 加载和预处理图像
    img = Image.open(image_path).convert('RGB')
    img = img.resize((224, 224))  # ResNet50需要的输入尺寸
    img_array = np.array(img)
    img_array = np.expand_dims(img_array, axis=0)  # 添加批次维度
    img_array = preprocess_input(img_array)  # 预处理
    
    # 进行预测
    predictions = model.predict(img_array)
    
    # 解码预测结果
    decoded_predictions = decode_predictions(predictions, top=3)[0]
    
    # 输出结果
    print("预测结果：")
    for i, (imagenet_id, label, score) in enumerate(decoded_predictions):
        print(f"{i+1}. {label}: {score:.4f}")
    
    return decoded_predictions

# 使用示例
result = predict_image('test_image.jpg')</code></pre><p><strong>文字说明：</strong></p><p>这段代码演示了如何使用TensorFlow调用ResNet50模型进行图像识别。首先加载预训练的ResNet50模型，然后对输入图像进行预处理（调整尺寸至224×224并进行归一化），接着通过模型预测得到分类结果，最后使用decode_predictions函数将预测结果解码为可读的标签和置信度分数。代码会输出前3个最可能的预测类别及其置信度。</p>]]></description></item><item>    <title><![CDATA[重磅！NanoBanana2的4种免费使]]></title>    <link>https://segmentfault.com/a/1190000047420052</link>    <guid>https://segmentfault.com/a/1190000047420052</guid>    <pubDate>2025-11-22 13:03:02</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>大家好，我是磊哥！今天给大家带来一个重磅消息——谷歌刚刚发布了 <strong>Nano Banana Pro</strong>（也可以叫Nano Banana 2），这可能是迄今为止最强大的图片生成大模型！</p><p>作为一个每天分享干货的技术博主，我第一时间体验了这个新模型，发现它真的太太太强大了！</p><p>所以，接下来就带大家深入了解这个神器的三大核心内容：</p><ol><li><strong>Nano Banana Pro 有哪些优点？</strong></li><li><strong>Nano Banana Pro 免费使用方法有哪些？</strong></li><li><strong>如何利用官方提示词更好的使用 Nano Banana Pro？</strong></li></ol><h2>🎥 视频演示</h2><p><a href="https://www.bilibili.com/video/BV1DpUjBHEbF/" target="_blank">https://www.bilibili.com/video/BV1DpUjBHEbF/</a></p><h2>🚀 Nano Banana Pro四大惊艳特点</h2><h3>1. <strong>终于支持中文绘图！</strong></h3><p>这绝对是我最喜欢的一个功能！之前用一代Nano Banana生成中文，那叫一个惨不忍睹，文字完全没法看。而现在，Pro版本可以完美支持中文字体了！</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047420054" alt="" title=""/></p><p><strong>小技巧</strong>：想验证你用的是不是Pro版本？很简单，让它生成一个中文看看就知道了！能正常显示中文的就是Pro，否则就是一代。</p><h3>2. <strong>联网思考能力</strong></h3><p>这个功能简直太实用了！举个例子：</p><ul><li>直接告诉它"生成今天的天气情况"，它就会自动联网搜索今天的温度，然后把信息整合到图片里</li><li>让它生成"今天的比赛结果"或"最新新闻"，同样会自动搜索并生成</li></ul><p>再也不用自己查资料、写提示词了，省时省力！</p><h3>3. <strong>4K超清画质</strong></h3><p>之前只能生成 1K、2K 的图片，现在直接升级到 4K！图片清晰度大幅提升，细节更加丰富。</p><h3>4. <strong>角色一致性保持</strong></h3><p>这个功能对于做漫画连载或图片转视频的朋友来说太重要了！</p><p><strong>操作流程</strong>：</p><ol><li>先生成第一张人物图片</li><li>保存这张图片</li><li>后续生成时，把第一张图片喂给模型</li><li>生成的人物五官就会保持一致</li></ol><p>一代 Nano Banana 完全做不到这一点！</p><h2>💰 四种免费使用方法</h2><h3>1. <strong>谷歌官方渠道</strong></h3><p>访问 <strong>gemini.google.com</strong>，在聊天内容里点击"工具"→"图片制作"即可使用 Nano Banana Pro。</p><p><strong>注意</strong>：每天有使用额度限制，大概 50-100 张图后会降级到一代版本。</p><h3>2. <strong>ZenMux 平台</strong></h3><p>访问 <a href="https://link.segmentfault.com/?enc=Qs1EyDOVHryWrjkPk2KIgw%3D%3D.ylEUq%2B%2Fp9VDY7gdqyU2RAboIsdhZUmkVhdTJ3AeR6DI%3D" rel="nofollow" target="_blank">https://zenmux.ai</a> 就可以看到，他里面有 Nano Banana Pro 的免费版本，经测试确实支持中文，说明是 Pro 模型。</p><h3>3. <strong>Lova.AI</strong></h3><p>登录官网 <a href="https://link.segmentfault.com/?enc=wr16Ixl0kZbVkwdvcEC8eA%3D%3D.SVgPHshJ14r5DgUT%2F7dH4qNE2ByNeApMl6WhwT02yII%3D" rel="nofollow" target="_blank">https://www.lovart.ai/zh/home</a> 就能看到 Nano Banana Pro 已经上线，目前是限时免费，大家抓紧时间体验！</p><h3>4. <strong>Fellow.AI</strong></h3><p>官网显示已上线 Nano Banana Pro 且免费使用，但经测试效果不太确定，建议大家优先选择前三种方式。</p><h2>🎯 如何更好地使用Nano Banana Pro</h2><p>想要生成更满意的图片？一定要用谷歌官方推荐的提示词模板！</p><h3>官方模板类型包括：</h3><ul><li><strong>逼真场景生成</strong> - 适合生成真实感强的图片</li><li><strong>风格插画/贴纸</strong> - 各种艺术风格的创作</li><li><strong>文字提取</strong> - 从图片中获取文字信息</li><li><strong>摄影/产品照片</strong> - 专业级的产品展示</li><li><strong>极简风格设计</strong> - 现代简约风格</li><li><strong>连续艺术/电影画面</strong> - 漫画、电影风格</li><li><strong>元素添加/移除</strong> - 图片编辑功能</li><li><strong>局部重绘</strong> - 精细调整</li><li><strong>风格迁移</strong> - 不同风格的转换</li><li><strong>高级合成</strong> - 复杂场景组合</li><li><strong>Logo替换</strong> - 品牌元素处理</li></ul><h3>使用技巧</h3><p>直接把官方模板复制粘贴，给到 DeepSeek 或其他大模型，让它帮你生成相应的中文提示词，或者把你的业务需求转换成英文提示词。</p><h2>💡 总结</h2><p>Nano Banana Pro 的发布绝对是图片生成领域的一次重大突破！中文支持、联网思考、 4K 画质、角色一致性，每一个功能都直击痛点。</p><p><strong>重点提醒</strong>：</p><ul><li>优先使用前三种免费方式</li><li>一定要善用官方提示词模板</li><li>抓紧限时免费的机会</li></ul><p>我是磊哥，每天分享一个干货内容。如果这篇文章对你有帮助，记得点赞收藏，我们下期见！</p><blockquote>本文已收录到我的技术小站 <a href="https://link.segmentfault.com/?enc=RJsKf5DIpa7iD0GzxUxHtA%3D%3D.Ja44v4eWJTCs80PkFAWbPL89%2BYhIDtqUcZS%2Famb1TtQ%3D" rel="nofollow" target="_blank">www.javacn.site</a>，其中包含的内容有：Spring AI、Spring AI Alibaba、LangChain4j、Dify、Coze、N8N、智能体（AI Agent）、MCP、Function Call、RAG、向量数据库、Prompt、多模态、向量数据库、嵌入模型、AI 常见面试问题等内容。</blockquote>]]></description></item><item>    <title><![CDATA[HR的转型时刻：AI如何重塑招聘新范式 ]]></title>    <link>https://segmentfault.com/a/1190000047420063</link>    <guid>https://segmentfault.com/a/1190000047420063</guid>    <pubDate>2025-11-22 13:02:04</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>HR的转型时刻：AI如何重塑招聘新范式</p><p>传统招聘模式正面临严峻挑战。数据显示，一场典型校招往往需要处理3000份简历、面试400人，最终仅录用5人。当用人部门以“感觉不对”否定前期所有努力时，猎头费、差旅费、误工费等成本已累积至惊人数字，单个核心岗位招聘成本可达8万元。</p><p>在预算紧缩而招聘指标持续攀升的双重压力下，HR面临着根本性的路径选择：是继续依赖人海战术和主观判断，还是转向数据驱动的智能招聘模式？</p><p>精准度革命：从经验判断到数据决策</p><p>传统面试中存在的“五五开”魔咒——五位候选人中至少看走眼两位，导致补招成本直接翻倍。现代AI招聘系统通过双重心理学指标验证，将评估误差控制在极低水平。</p><p>其技术实现路径包括：</p><ul><li>多维评估：单题同步测评3-5项胜任力，初筛与技术复试一次完成</li><li>智能追问：实时生成深度问题，有效识别简历信息真实性</li><li>专业覆盖：题库涵盖代码、财务、工程、算法等数十个专业领域</li><li><p>人机协同：AI评分与资深面试官差异小于3%，结果可直接用于录用决策</p><p>候选人体验升级：从机械交互到拟真对话</p></li></ul><p>早期AI面试存在的机械音、固定脚本、口型不同步等问题，严重影响了雇主品牌形象。新一代AI面试系统在交互体验上实现重大突破：</p><ul><li>情绪感知：识别微停顿等细节，自动调整交互节奏</li><li>流畅体验：语音与口型同步误差小于40毫秒，达到视频级流畅度</li><li><p>智能应答：实时解答职位、福利、晋升路径等多类问题</p><p>招聘流程自动化：从人工操作到智能管理</p></li></ul><p>AI人才寻访系统的出现，将HR从“筛选-沟通-跟进-录入”的重复劳动中解放出来：</p><ul><li>快速部署：30秒完成系统初始化</li><li>智能沟通：模拟人类交互模式，自动完成信息收集</li><li>流程优化：自动识别不合适候选人并礼貌退出</li><li><p>效率提升：单HR管理岗位数量提升显著，招聘周期大幅压缩</p><p>行业转型展望</p></li></ul><p>当前，招聘领域正经历从“流程驱动”到“决策驱动”的深刻变革。AI技术的应用不仅提升了招聘效率，更重新定义了HR的价值定位——从行政事务执行者转变为战略人才决策者。</p><p>未来，优秀的HR将不再是那些最擅长处理流程的人，而是那些最懂得利用技术工具进行人才识别与决策的人。这场转型不是技术的替代，而是专业能力的升级，让HR真正把时间和精力投入到“人”的价值发掘上，而非困于繁琐的“流程”之中。</p>]]></description></item><item>    <title><![CDATA[【赵渝强老师】Oracle数据库的PL/]]></title>    <link>https://segmentfault.com/a/1190000047420084</link>    <guid>https://segmentfault.com/a/1190000047420084</guid>    <pubDate>2025-11-22 13:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>Oracle数据库在SQL的基础上提供了自己的开发语言PL/SQL。通过使用PL/SQL可以开发强大的应用程序，并且能够进一步开发Oracle的存储过程、存储函数和Oracle数据库的触发器。百度百科中对PL/SQL做了如下的说明：</p><blockquote>PL/SQL也是一种程序语言，叫做过程化SQL语言（Procedural Language/SQL）。PL/SQL是Oracle数据库对SQL语句的扩展。在普通SQL语句的使用上增加了编程语言的特点，所以PL/SQL把数据操作和查询语句组织在PL/SQL代码的过程性单元中，通过逻辑判断、循环等操作实现复杂的功能或者计算。</blockquote><p>视频讲解如下：<br/><a href="https://www.bilibili.com/video/BV1RjycBiEgT/?aid=115579818153164&amp;cid=34123548186" target="_blank">https://www.bilibili.com/video/BV1RjycBiEgT/?aid=115579818153...</a></p><p>PL/SQL程序的基本结构如下所示：</p><pre><code class="sql">declare
  说明部分
begin
  程序体部分
exception
  例外处理部分
end;
/

# 其中：
# 说明部分包括：变量常量的说明、游标的申明和例外的申明。
# 程序体部分包括：DML语句序列、条件判断语句和循环语句等。
# 例外处理部分包括：如何处理程序体部分产生例外的语句序列。</code></pre><p>在了解了PL/SQL的基本内容后，下面的步骤将开发第一个Oracle数据库的PL/SQL程序。该程序将在屏幕上输出”Hello World“的字符串。<br/>（1）使用c##scott用户登录数据库。</p><pre><code class="sql">SQL&gt; conn c##scott/tiger</code></pre><p>（2）在SQL*Plus命令行中直接书写PL/SQL程序，打印Hello World。程序代码如下：</p><pre><code class="sql">SQL&gt; declare
  --说明部分
begin
   --程序体
   dbms_output.put_line('Hello World');
end;
/

# 输入回车后执行PLSQL程序。输出的信息如下：
PL/SQL procedure successfully completed.

# 在输出的信息中没有打印Hello World。这是因为在默认情况下，
# Oracle数据库服务器输出是关闭的，需要手动将其打开。</code></pre><p>（3）打开Oracle服务器的输出开关。</p><pre><code class="sql">SQL&gt; set serveroutput on</code></pre><p>（4）在SQL*Plus输入一个右斜线重新执行第（1）步中的PL/SQL程序。</p><pre><code class="sql">SQL&gt; /

# 输出的信息如下：
Hello World

PL/SQL procedure successfully completed.</code></pre><p>（5）在SQL*Plus命令行中可以开发并执行PL/SQL程序，但是使用起来并不是很方便。借助Oracle SQL Developer可以更好地开发、运行和调试PL/SQL的应用程序。下图展示了在Oracle SQL Developer中运行PL/SQL应用程序的效果。<br/><img width="676" height="448" referrerpolicy="no-referrer" src="/img/bVdm4zj" alt="image.png" title="image.png"/></p>]]></description></item><item>    <title><![CDATA[系统应用解构 星星上的柳树 ]]></title>    <link>https://segmentfault.com/a/1190000047420007</link>    <guid>https://segmentfault.com/a/1190000047420007</guid>    <pubDate>2025-11-22 12:02:35</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>1、 系统应用是技术的支柱<br/>在现代技术生态中，“系统应用”指的是硬件与软件协同工作形成的整体系统，从简单的单设备程序到分布式复杂平台，无不依赖这一核心理念。本文将带您梳理其基本原理，并展示如何设计高效、可靠、可扩展的系统。</p><p>图示展示了计算系统的架构层次：硬件、驱动、操作系统与应用程序逐层构建，从整体上帮助理解系统应用的基本构成。<br/><img width="723" height="447" referrerpolicy="no-referrer" src="/img/bVdm8gX" alt="" title=""/><br/>2、 系统应用的核心组成<br/>I. 硬件（Hardware）<br/>包括处理器、内存、存储与输入/输出设备等，是整个系统运转的基础平台。</p><p>II. 软件（Software）<br/>指控制硬件运行并为用户提供操作功能的程序与算法。</p><p>III. 操作系统（Operating System）<br/>管理硬件资源、提供运行其他软件的基础平台，协调系统整体运行。</p><p>IV. 用户界面（User Interface）<br/>包括图形界面（GUI）、命令行界面（CLI）与应用接口（APIs），是人与系统交互的桥梁。</p><p>3、 系统设计的五大原则<br/>I. 模块化（Modularity）<br/>将复杂系统拆分为可独立开发、测试与维护的模块，提升管理效率与可复用性。</p><p>II. 抽象（Abstraction）<br/>隐藏复杂细节，仅呈现核心功能，使开发者专注于业务逻辑而非底层实现。</p><p>III. 封装（Encapsulation）<br/>数据与操作方法封装于同一单元，通过接口控制访问，确保系统稳定与安全。</p><p>IV. 互操作性（Interoperability）<br/>不同组件、系统之间无缝协作，基于标准协议与接口实现资源共享与数据交换。</p><p>V. 可扩展性（Scalability）<br/>系统能在不改动结构的前提下随需求增长而扩展，以支持更大规模和更高负载。</p><p>4、 为什么选择 EDA Academy 提升系统能力？<br/>如果你想系统深入掌握系统应用设计与开发技能，EDA Academy（www.eda-academy.com） 是你最佳选择：<br/>I. 全面实战课程<br/>覆盖从系统架构原理、模块化设计、硬件/软件协作到接口与可扩展性等核心内容，让你从理论到实战全面提升。</p><p>II. 学员与导师双轨发展<br/>无论你是希望提升技术的学员，还是渴望分享经验的导师，EDA Academy 都欢迎你入驻，提供赋能成长的舞台。</p><p>III. 免费订阅 Newsletter<br/>只需填写邮箱，便可定期收到前沿技术趋势、实战课程推荐以及系统设计实践干货，无需付费即可获取持续学习资源。</p><p>IV. 推广变现机会<br/>加入其销售联盟计划，推广课程即可获得 20%–50% 的佣金，让学习成果不仅提升技能，还带来实质收益。</p><p>系统应用是现代技术世界的核心桥梁，由硬件、软件、操作系统与接口构成，并依赖模块化、抽象、封装、互操作性与可扩展性等原则构建高效系统。</p><p>想建立坚实的系统思维与实战能力？点击访问 EDA Academy（www.eda-academy.com），开启你的系统架构实战之旅。无论你是成长中的工程师、热情的分享者，还是期望实现学习变现的个人，这里都能为你提供舞台与机会。<br/><img width="723" height="1098" referrerpolicy="no-referrer" src="/img/bVdm8gY" alt="" title="" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[2025企业级ITSM产品推荐：年度IT]]></title>    <link>https://segmentfault.com/a/1190000047420009</link>    <guid>https://segmentfault.com/a/1190000047420009</guid>    <pubDate>2025-11-22 12:01:56</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>面对日益复杂的IT环境和数字化转型挑战，选择一套合适的ITSM产品成为企业实现高效运维和价值提升的关键。本文将对市场主流ITSM产品进行深度解析，并提供一套清晰的选型逻辑，同时为企业带来ITSM产品推荐，帮助企业做出明智决策。 </p><p><strong>一、主流企业级ITSM产品推荐</strong><br/>当前市场上的ITSM产品推荐依托不同的技术架构与功能特性，满足企业多样化的运维需求。我们根据其核心战略定位，梳理分析六大主流ITSM产品及其核心亮点。 <br/>燕千云ITSM产品<br/>基于云原生架构的企业服务管理平台，基于ITIL基础，通过低代码配置、高度自动化和智能化能力，为企业提供了一套灵活、高效、可扩展的数字化运营解决方案，特别适合追求敏捷、精细化服务管理和全员协作的现代化组织，是国内ITSM产品推荐的不二之选。<br/> <br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047420011" alt="图片" title="图片"/></p><p><strong>核心优势：</strong><br/>不仅仅是ITSM产品，燕千云更是基于云原生技术、融合PaaS、低代码和AI的企业服务运营（ESM）平台，致力于将IT服务管理能力延伸至全业务部门，帮助企业构建统一的服务运营中台。<br/> <br/><strong>功能亮点：</strong></p><p><strong>高灵活度的低代码/零代码配置：</strong><br/>可视化流程设计器：基于BPMN标准，支持复杂服务流程的拖拽式编排，快速适应业务变化。平台内置国际先进ITIL4实践，提供标准化的事件、问题、变更管理模板，支持新流程3小时快速上线。<br/>表单与视图引擎：可视化设计服务请求表单、工单界面和个性化门户，无需编码即可实现业务定制。<br/>规则与决策引擎：通过配置规则表，实现工单的智能路由、自动化分派、优先级判定等，将人工决策转化为系统自动化执行。</p><p><strong>深度智能化与自动化（AIOps）：</strong><br/>AI智能助理：支持自然语言提问、知识自动总结、工单要素提取与推荐，大幅降低一线服务台的工作强度。<br/>智能驱动的全流程闭环：深度融合AIGC与大语言模型技术，实现从多模态智能提单、精准派单、自动化质检到智能知识运营的全流程闭环。<br/>数据与知识双驱动：支持全链路数据采集与知识沉淀，已帮助众多客户构建了大规模的企业级私域知识库，并支撑了高并发的工单流转与处理。<br/>自动化操作平台：通过强大的集成中心与CMDB、监控、OA等系统无缝连接，实现事件的自动修复、变更的自动执行和数据的实时同步。 </p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047420012" alt="图片" title="图片" loading="lazy"/></p><p><strong>极致的用户体验与协作：</strong><br/>多渠道服务：提供移动端、PC端、企业微信/钉钉等多渠道服务接入，支持随时随地的服务请求与审批。全员服务门户：打造简洁易用的自助服务体验，提高员工满意度和自服务解决率。<br/>​云原生架构优势：具备高可用、高并发、弹性扩展的特点，能够平稳支撑大型集团客户的高并发访问和数据增长需求。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047420013" alt="图片" title="图片" loading="lazy"/></p><p>适用场景：集团化/大型企业：适用于需要高度定制化流程、追求高并发和系统韧性、并要求本土生态深度适配（企微、钉钉等）的复杂场景。数字化转型驱动：帮助企业快速将服务管理能力从IT部门扩展至人事、行政、财务等（ESM战略），通过低代码平台实现业务的敏捷创新。<br/>  <br/>Service Now ITSM<br/>定位于企业级IT服务管理全能平台，强调单一数据模型下的全业务流程覆盖。<br/>（1）生态整合<br/>覆盖ITOM（运维）、SecOps（安全响应）、CSM（客户服务）等，是构建企业级服务运营中台的传统首选。<br/>（2）AI深度融合<br/>内置Now Assist AI助手，支持自然语言生成工单、知识库建议和自动化脚本编写。 <br/>Jira Service Management<br/>定位于敏捷开发与ITSM融合的现代化平台，专为DevOps团队打造。<br/>（1）DevOps一体化<br/>打通开发、知识库、代码等工具，实现从问题提报到事件解决的无缝流转。<br/>（2）成本效益与扩展性<br/>云版本费用友好，适合中型技术团队快速启动，提供强大的扩展性。 </p><p>BMC Helix<br/>定位于混合云环境下的认知服务管理平台，重点服务复杂、大规模IT环境。<br/>（1）混合架构支持<br/>能够无缝管理本地数据中心与多云资源，支持Kubernetes容器化部署。<br/>（2）AI运维（AIOps）<br/>Helix Chatbot和Predictive Remedy等实现主动预测故障，助力企业从被动“救火”转向主动“防御”。<br/> <br/>华为云ITSM解决方案<br/>依托云原生架构，定位于高安全合规的智能平台。<br/>（1）云原生与一体化<br/>深度集成华为云基础设施与运维工具，实现资源监控到服务管理全链路贯通。<br/>（2）安全优势<br/>内置等保2.0、ISO27001等合规模板，满足金融、政务等行业对数据主权和安全合规的严苛要求。<br/> <br/>Ivanti Neurons for ITSM<br/>定位于终端管理（UEM）与ITSM结合的安全驱动型解决方案。<br/>（1）安全联动<br/>结合ITSM与终端安全（如UEBA用户行为分析），实现对高危行为的自动响应。<br/>（2）资产智能化<br/>实现全网设备自动发现、合规检查与自动化修复，提升终端运维效率和安全防护。<br/> <br/><strong>二、ITSM产品推荐：选型逻辑与建议</strong><br/>ITSM产品推荐的选型，核心评估标准应从关注短期“功能堆砌”转向考量长期的“适应性与平台化价值”。对于谋求长远发展和数字化转型的中国企业而言，选择一套具备平台化架构的ITSM产品，是实现IT治理能力升级的战略性投资。<br/>战略聚焦：平台化架构带来的长期价值<br/>企业关注ITSM产品推荐选型时，应将以下三个方面作为核心考量点，确保所选产品能够匹配企业的未来增长与业务变动：<br/>极致的灵活性与业务自主权：平台需具备PaaS底座和低代码/零代码能力。这确保了系统能够平滑适应未来所有业务流程的变动，将流程优化的主导权牢牢掌握在企业手中，从而降低对单一供应商的长期依赖。本土生态与安全合规深度适配：优先选择对本土办公生态（如企业微信、钉钉）和国内云环境有深度优化的平台。这类产品更贴合本土企业的实际工作习惯，并能有效满足金融、政务等行业对数据主权和严苛安全合规的要求。<br/>扩展至企业服务管理（ESM）的战略潜力：优秀的平台能力应允许企业将成熟的IT服务管理模式快速复制到人事、行政、财务等非IT部门。这一扩展能力能帮助企业构建统一的服务运营中台，实现全企业服务运营的战略目标。<br/>ITSM产品推荐选型建议：采用如燕千云这类平台化架构的ITSM产品，能够为中国企业提供所需的极致灵活性、本土适配性和ESM扩展能力。 </p><p><strong>三、ITSM产品推荐关键点：产品选择的注意事项</strong><br/>ITSM产品是企业对未来IT治理能力的战略投资。核心决策点在于平台能否匹配企业未来的升级目标和业务增长的灵活性。 <br/>注意点一：构建敏捷高效的服务交付体系（提升员工体验与协作）企业追求快速响应业务需求、提升内部员工满意度，并期望实现跨部门协作的全员服务。<br/>平台匹配：优先考虑具备低代码/零代码流程引擎和本土化办公软件深度集成的平台。ITSM产品推荐方向：选择如燕千云，以其全渠道无缝衔接和敏捷配置能力，快速实现服务流程的统一和优化。<br/> <br/>注意点二：实现IT运维与研发的深度协同（DevOps转型）企业致力于打破IT运维与软件开发之间的壁垒，追求从需求到部署、再到事件解决的全生命周期管理。<br/>平台匹配：关注与主流开发工具有天然集成优势或强大API接口的平台。ITSM产品推荐方向：JiraServiceManagement或通过燕千云的集成中心实现与研发系统的打通。 </p><p>注意点三：从被动响应转向主动预防（AIOps战略）企业希望通过智能化技术，减少人工干预，实现事件的预测、根因分析和自动化修复，大幅降低MTTR。<br/>平台匹配：必须具备AI驱动的故障预测、智能分单和AIGC知识提炼能力。ITSM产品推荐方向：考量燕千云的AI全流程效能增强、BMCHelix或华为云ITSM的AIOps算法能力。<br/> <br/>注意点四：满足全球统一管理或严苛安全合规要求<br/>企业是对数据主权和安全有极高要求的行业。<br/>ITSM产品推荐方向：关注具备全球部署经验的平台或具备权威安全认证和本土云原生优势的平台（如燕千云、ServiceNow）。</p>]]></description></item><item>    <title><![CDATA[大数据计算引擎正在抛弃 JVM bigd]]></title>    <link>https://segmentfault.com/a/1190000047420023</link>    <guid>https://segmentfault.com/a/1190000047420023</guid>    <pubDate>2025-11-22 12:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在写这篇文章之前，Java 25正式发布，其中 JEP-508 Vector API 迎来了第10次孵化，旨在提供一种向量计算的接口，从而获得比等效标量计算更高的性能。传统的基于Java虚拟机（JVM）的执行引擎在处理大规模数据时逐渐显露出性能瓶颈 (标量计算) ，特别是在 CPU 密集型任务和内存管理方面。近年来，众多大数据计算引擎开始转向原生（Native）执行模型，采用 C++ 等语言实现向量化执行，以提升性能和适应现代硬件特性。 Databricks 团队于 2022 年在 SIGMOD 会议上发表的论文《Photon: A Fast Query Engine for Lakehouse Systems》中表明向量化查询引擎 Photon 有数量级的性能提升(3~10倍的性能提升)，并在 100TB TPC-DS 基准测试中创下新的经审计性能记录。本文将从 JVM 在处理大规模数据场景下的局限性说起，探讨 Photon 在此基础上的设计选择，并分析目前业界的基于 Gluten + Velox 和 Native 向量化引擎的两种方式。一. JVM的局限性在该论文中，Databricks 团队指出，放弃现有基于 JVM 的引擎，是基于观察到当前引擎的工作负载正变得受限于 CPU，改进现有引擎的性能变得越来越困难。几个因素导致了这一点。首先，本地NVMe SSD 缓存和自动优化 shuffle 等低级优化显著减少了 I/O 延迟；其次，Delta Lake 支持的数据聚类等技术通过文件修剪更积极地跳过不需要的数据，进一步减少 I/O 等待时间。最后，湖仓一体引入了需要对非规范化数据、大型字符串和非结构化嵌套数据类型进行繁重处理的新工作负载，这进一步加剧了内存性能的压力。 另一个原因是 JVM 内部即时编译器的限制（例如方法大小限制）导致性能急剧下降。此外，本地代码的性能通常比 JVM 引擎更容易解释，因为内存管理和 SIMD 等特性可被明确控制。二. Photon Photon 是 Databricks 为湖仓一体环境开发的新型向量化查询引擎，以下是 Photon 转向原生 Native 执行的关键原因和实现方式：原生 C++ 实现：Photon 选择用 C++ 实现，而不是沿用基于 JVM 的Databricks Runtime（DBR）。原生代码避免了 JVM 的性能瓶颈，如JIT编译器的限制和垃圾回收问题。Photon 通过显式控制内存管理和SIMD指令，显著提升了连接、聚合和表达式评估的性能。向量化执行模型：Photon 采用解释型向量化执行，而非 Spark SQL 的代码生成模型。向量化通过批处理数据分摊函数调用开销，利用 SIMD 提高性能。内存管理优化：Photon 通过内部缓冲池管理内存分配，避免昂贵的操作系统级分配。对于持久性分配（如聚合或连接），Photon 与 Spark 的统一内存管理器集成，支持动态溢出机制。这种灵活性在处理湖仓一体中常见的超大记录时尤为重要。与 Spark 的兼容性：尽管转向原生执行，Photon 通过 JNI 与 Spark 集成，支持部分查询在 Photon 和 Spark SQL 之间切换，确保语义一致性。这种增量部署策略降低了迁移成本，同时保留了 Spark 生态系统的优势。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047420025" alt="图片" title="图片"/><br/>Photon 的成功验证了原生向量化引擎在湖仓一体环境中的优越性，其在 100TB TPC-DS 基准测试中的世界纪录进一步证明了其性能优势。三. Gluten 和 VeloxApache Gluten 是由 Intel 和 Kyligence 发起的一个中间层组件，它的主要职责在于将基于 JVM 的SQL 引擎的执行任务卸载到原生 Native 引擎上进行处理，以此显著提升数据处理速度并降低资源消耗。如下图所示，Gluten 作为中间层，上游对接 Spark 或者其他大数据计算框架，下游执行层则对接 Velox，Clickhouse 这类本地高性能计算引擎。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047420026" alt="图片" title="图片" loading="lazy"/><br/>Velox 是 Meta 开源的一款 C++ 实现的向量化执行引擎，简单说就是一个单机/单节点的 C++ 的向量化 runtime 模块的实现，里面包括了数据类型，函数，表达式，aggregate function，operator，I/O等的向量化实现，用于替换 Spark/Presto 的 runtime 部分，使得这类计算引擎从 JVM 切换到 C++ 实现得以提速。Gluten+Velox 的组合，让Spark/Presto 也可以像等Native引擎一样发挥向量化执行的性能优势。四. Spark/Flink向量化Spark向量化目前，国内外业界主流各大互联网公司对 Spark 多通过 JNI 的方式直接在大数据量的情况下以 Gluten+Velox 的形式进行 native 算子库加速。比如英特尔公司推出的Gluten，通过 Fallback 机制，即当查询计划不能执行，或者有程序崩溃时，也能保证任务执行。因为项目初期功能表现欠佳，现阶段与 Spark JVM 协作，当有算子或是功能支持失败时，就会回退到 JVM 执行，以保证查询计划的执行成功。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047420027" alt="图片" title="图片" loading="lazy"/><br/>Flink向量化引擎-Flash阿里云也推出了向量化版本 Flink 引擎-- Flash，其中性能数据显示，相较于开源的 Flink 版本，Flash 引擎性能提升了5到10倍。如下图所示，Flash 通过中间一层 Leno 胶水层，它类似于 Spark 中的 Gluten，主要负责将流式 Native Runtime 与 Flink 的分布式框架解耦。这样，在之前的 Java 算子版本上，可以独立发布 Native 算子。Leno 胶水层的任务是生成 Native 的执行计划，即根据用户的 SQL 需求，通过 Flink Planner 判断 SQL 语句中算子是否全部被覆盖。如果全部覆盖，就生成完整的 C++ 向量化执行计划；如果不行，则回退到 Java 的执行计划。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047420028" alt="图片" title="图片" loading="lazy"/><br/>五. Native 向量化引擎业界也有一些成熟的 Native 向量化引擎，如 StarRocks。StarRocks 通过实现全面向量化引擎，充分发挥了 CPU 的处理能力。全面向量化引擎按照列式的方式组织和处理数据。StarRocks 的数据存储、内存中数据的组织方式，以及 SQL 算子的计算方式，都是列式实现的。按列的数据组织也会更加充分的利用 CPU 的 Cache，按列计算会有更少的虚函数调用以及更少的分支判断从而获得更加充分的 CPU 指令流水。另一方面，StarRocks 的全面向量化引擎通过向量化算法充分的利用 CPU 提供的 SIMD（Single Instruction Multiple Data）指令。这样 StarRocks 可以用更少的指令数目，完成更多的数据操作。经过标准测试集的验证，StarRocks 的全面向量化引擎可以将执行算子的性能，整体提升 3~10 倍。StarRocks BE 端完全用 C++ 代码实现，只有在涉及到一些外表 Paimon/Hive, 会通过 JNI 的方式进行交互，这也侧面反映 Java 生态的强大。六. 未来和挑战C++ 的复杂性和 Java 强大的生态：过去十几年的绝大部份大数据框架都是基于 Java 语言，JVM 生态系统在大数据领域根深蒂固，原生引擎需要通过 JNI 与现有周边工具集成，增加了开发复杂性。大数据计算引擎可能继续向混合模型演进。例如，Spark 和 Flink 可能在保留 JVM 生态的同时，逐步将关键算子迁移到原生实现。而 Native 原生引擎可能成为高性能 OLAP 和湖仓一体场景的主流选择。此外，随着硬件加速器（如GPU和TPU）的普及，引擎可能进一步优化以利用这些新型计算资源得到提速。</p><p>更多大数据干货，欢迎关注我的微信公众号—BigData共享</p>]]></description></item><item>    <title><![CDATA[uniapp自定义uni-easyinp]]></title>    <link>https://segmentfault.com/a/1190000047419972</link>    <guid>https://segmentfault.com/a/1190000047419972</guid>    <pubDate>2025-11-22 11:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>官网示例：<br/><img width="348" height="43" referrerpolicy="no-referrer" src="/img/bVdm8gj" alt="" title=""/></p><pre><code>&lt;uni-forms-item &gt;
        &lt;uni-easyinput  trim="all" v-model="form.address" placeholder="请输入地址" /&gt;
&lt;/uni-forms-item&gt;</code></pre><h2>自定义颜色</h2><p><img width="344" height="47" referrerpolicy="no-referrer" src="/img/bVdm8gk" alt="" title="" loading="lazy"/></p><pre><code>&lt;uni-forms-item &gt;
      &lt;uni-easyinput  trim="all" primaryColor="#FCB334" v-model="form.address" placeholder="请输入地址" /&gt;
&lt;/uni-forms-item&gt;</code></pre><p>通过<code>primaryColor</code>实现自定义边框、按钮<code>icon</code>色</p><h2>自定义边距、消除边框色、背景色</h2><p><img width="362" height="73" referrerpolicy="no-referrer" src="/img/bVdm8gl" alt="" title="" loading="lazy"/><br/><code>uni-forms-item</code>在<code>uni-forms</code>表单中有自带的<code>margin-bottom</code>，消除方式如下：</p><pre><code>:deep(.uni-forms-item) {
    margin-bottom: 0px;
}</code></pre><p>清除边框色、背景色</p><pre><code>:deep(.uni-easyinput__content) {
    border: none !important;
    background-color: transparent !important;
}
:deep(.is-input-border) {
    border: none;
}</code></pre><p><img width="354" height="49" referrerpolicy="no-referrer" src="/img/bVdm8gm" alt="" title="" loading="lazy"/><br/>这样，<code>input</code>就是一个透明的输入框，你可以在<code>input</code>外套一层<code>view</code>，自定义<code>input</code>的样式，我这里做一个演示：<br/><img width="357" height="56" referrerpolicy="no-referrer" src="/img/bVdm8gn" alt="" title="" loading="lazy"/></p><pre><code>&lt;uni-forms :modelValue="form"&gt;
    &lt;view class="input-box"&gt;
        &lt;view class="input-box-left"&gt;左侧插槽&lt;/view&gt;
    
        &lt;view class="input-box-center"&gt;
            &lt;uni-forms-item&gt;
                &lt;uni-easyinput trim="all" primaryColor="#FCB334" v-model="form.address" placeholder="请输入地址" /&gt;
            &lt;/uni-forms-item&gt;
        &lt;/view&gt;
        
        &lt;view class="input-box-right"&gt;右侧插槽&lt;/view&gt;
    &lt;/view&gt;
&lt;/uni-forms&gt;</code></pre><pre><code>.input-box {
    border-radius: 10rpx;
    background: #f0f2f6;
    display: flex;
    align-items: center;
    .input-box-left {
        background: red;
        padding: 0 10rpx;
    }
    .input-box-center {
        flex: 1;
    }
    .input-box-right {
        background: red;
        padding: 0 10rpx;
    }
}</code></pre><p>完全自定义输入框，你可以基于此实现很多其它演示，例如：<br/><img width="218" height="203" referrerpolicy="no-referrer" src="/img/bVdm8gp" alt="" title="" loading="lazy"/></p><hr/><p>参考文档：<br/><a href="https://link.segmentfault.com/?enc=O%2BRrU%2FzGLmlfkgE%2B90IaMA%3D%3D.i7HM1CuXzEn2SL9ffqjnY8LP28mWN9k%2FBkgVK9YI7D9EDPuBAg1F85wT497%2FEnVr5At%2Byj1sAxpW48dB2coADg%3D%3D" rel="nofollow" target="_blank">uniapp：uni-easyinput</a><br/><a href="https://link.segmentfault.com/?enc=Cqw0UJSS%2FfMuRBcjoSIIQQ%3D%3D.26YVJgSjgaJbdLkFzLFcFo1%2ByR3wNd3CjEftnY6onmrKrouyBAwIHsqV7qO79j%2FADgdj%2B5o0ycHMFs70PuABug%3D%3D" rel="nofollow" target="_blank">uniapp：uni-forms</a></p>]]></description></item><item>    <title><![CDATA[代理 IP 技术原理：它究竟是怎么“替你]]></title>    <link>https://segmentfault.com/a/1190000047419902</link>    <guid>https://segmentfault.com/a/1190000047419902</guid>    <pubDate>2025-11-22 10:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>谈到代理 IP，很多人的第一反应是：“换个 IP，上网更安全。”<br/> 但实际上，代理远不只是“换一个身份”，它更像是一个具备网络调度、流量转发、协议适配能力的“小型中转站”。如果你是开发者、运营人员、爬虫工程师、跨境从业者，理解代理背后的技术逻辑，会让你在业务稳定性、成功率和效率上拥有明显优势。<br/>这篇文章，我们用更容易理解的方式，讲清楚代理 IP 的技术原理和真实作用。</p><h2>一、代理 IP 的核心机制：让“你的流量看起来像他的”</h2><p>你访问一个网站时，传统流程是这样：<br/>你 ➜ 目标网站<br/>使用代理之后，流程变成：<br/>你 ➜ 代理服务器 ➜ 目标网站<br/>最终，目标网站看到的是代理服务器的 IP，而不是你的真实 IP。<br/>这个过程包含四个关键动作：<br/>1.代理代替你发起连接</p><p>2.代理重新建立 TCP 握手</p><p>3.修改网络包的源地址</p><p>4.将服务器响应再转发给你</p><p>也就是说，代理实际上“重做了一遍你要做的事情”，但用的是它的身份。<br/>这就是它能绕过地域限制、避免风控、模拟本地用户的根本原因。</p><h2>二、HTTP 与 SOCKS5 为什么会影响你业务的成功率？</h2><p>不同代理协议，对你的任务影响非常大。<br/>HTTP / HTTPS 代理：更接近“网页访问”逻辑<br/>●适用于网站、API、广告验证</p><p>●支持 CONNECT 隧道模式</p><p>●HTTPS流量全程加密</p><p>●可对内容进行基础解析（但很多高质量代理不会解析）</p><p>SOCKS5 代理：更底层、更通用、更快<br/>●不解析内容，纯转发</p><p>●支持 TCP / UDP</p><p>●游戏、程序、多账号、自动化都能用</p><p>●更不容易暴露代理痕迹</p><p>如果你的业务偏向自动化、爬虫、登录环境，建议优先使用 SOCKS5。<br/>B2Proxy 在这两种协议上都非常稳定，不管是住宅代理还是 ISP 代理，都能轻松适配不同场景。</p><h2>三、为什么住宅代理看起来“更像真用户”？</h2><p>平台风控系统并不是看你有没有代理，而是看你是不是“真实用户行为”。<br/>● 住宅代理（Residential Proxy）的关键优势是：出口 IP 来源于真实家庭网络</p><p>●使用真实运营商</p><p>●和正常用户几乎没区别</p><p>●通过风控系统的概率最高</p><p>这就是为什么爬虫、广告监测、多账号登录都更偏爱住宅代理。</p><h2>四、为什么不同代理的延迟差异巨大？</h2><p>代理延迟主要来自三段路：<br/>1.你的设备 → 代理节点</p><p>2.代理节点 → 目标服务器</p><p>3.代理内部的处理耗时</p><p>如果代理节点距离你太远，或节点带宽不足、跳数太多，就会出现：<br/>●卡顿</p><p>●丢包</p><p>●延迟飙升</p><p>●抓取成功率下降</p><p>优质代理供应商会进行：<br/>●动态路由选择</p><p>●节点负载均衡</p><p>●自动剔除坏节点</p><p>●智能出口分配</p><h2>五、代理真正强大的地方：并不是“换 IP”，而是“换环境”</h2><p>对于平台来说，IP 只是其中一个特征。真实用户的网络行为包含：<br/>●ASN（运营商）</p><p>●DNS出口位置</p><p>●时区匹配</p><p>●TCP 握手细节</p><p>●ISP 指纹</p><p>●网络链路质量</p><p>●请求模式</p><p>高质量代理做的，就是让这些特征尽可能接近真实网络。<br/>这也是为什么数据中心 IP 很容易被封，而住宅代理更稳定。</p><h2>六、代理的应用场景，远不止爬虫</h2><p>虽然很多人觉得代理和爬虫捆绑在一起，但实际上，它的应用远比你想象的广：<br/>●SEO 多地区排名监控</p><p>●广告投放与验证</p><p>●AI 数据采集、模型训练数据抓取</p><p>●品牌监控、舆情分析</p><p>●跨境电商多店铺管理</p><p>●社交平台多账号运营</p><p>如果你需要全球不同地区的“真实网络环境”，代理就是最关键的基础设施。</p><h2>结语：了解原理，才能真正用好代理</h2><p>使用代理是一种技能，而不是一个开关。<br/> 你理解得越深，就越能找到最适合你业务的方案。</p>]]></description></item><item>    <title><![CDATA[2025年AI行业最大的机会，毫无疑问属]]></title>    <link>https://segmentfault.com/a/1190000047419395</link>    <guid>https://segmentfault.com/a/1190000047419395</guid>    <pubDate>2025-11-22 00:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>大模型应用开发工程师，正在成为新的技术金字塔尖<br/>过去一年只要聊到技术岗位，不论是应届生、研发工程师还是转型中的技术人，都会问同一句话：<br/>“2025年最值得投入的技术方向是什么？”<br/>如果只能说一个——那就是“AI应用层”，更具体地说：大模型应用开发工程师。<br/>为什么是它？<br/>为什么是现在？<br/>为什么所有技术人越早转型越好？<br/>行业的变化已经给出了非常明确的答案。<br/>Part1<br/>应用层爆发速度，已经远远超过训练层与算法层<br/>AI行业2024–2025最大的结构性变化是：<br/>红利不再集中在算法岗，而是全面转移到“应用端”。<br/>头部企业的投入趋势同样十分明确。金山科技、万兴科技等公司的 AI 相关投入占比均已超过 30%，更激进的是商汤，2025 年上半年将近九成营收投入至 AI 研发，研发支出达到 21.19 亿元，体现了大模型时代的高强度投入要求与竞争门槛。<br/><img width="723" height="1358" referrerpolicy="no-referrer" src="/img/bVdm76V" alt="cfba54c6b2e3c743eb7422ca57900a27.jpg" title="cfba54c6b2e3c743eb7422ca57900a27.jpg"/><br/>字节跳动已有7个团队全速布局Agent。<br/>腾讯、京东、百度开放的技术岗中，80%与大模型应用相关。<br/>行业招聘数据显示，大模型相关岗位同比增长69%，其中最紧缺、增长最快的正是——大模型应用开发工程师。<br/>更关键的是企业侧的动作：<br/>超过60%的公司正在推进AI产品落地。<br/>但能真正把AI方案落成“能部署、能交付、能上线”的，远远不足需求。<br/>这意味着什么？<br/>AI应用正在进入真正的产业化阶段，而人才储备却几乎为零。<br/>整个行业正在被大量“会调API”但无法交付项目的人填满，而企业迫切需要的是另一个族群：<br/>能理解业务、能架构系统、能落地能力、能对接场景的应用开发者。<br/>Part2<br/>为什么企业不再需要“调参侠”，而需要能交付项目的人？<br/>从去年开始，整个行业都意识到一个现实：<br/>AI应用不是写几个prompt就能落地。<br/>企业需要的能力范畴完全不同，也更加复杂。<br/>真正的项目落地包含完整链条：<br/>从业务流程拆解→数据策略→能力编排→系统集成→Agent设计→推理链路构建→权限体系→评测→上线维护。<br/>这已经完全超出“会用模型”的范围。<br/>它需要的是一种跨越业务理解、系统设计与技术落地的复合型能力。<br/>这也是为什么<br/>懂AI原理+懂工程实现+懂业务流程<br/>的人变得极度稀缺。<br/><img width="723" height="331" referrerpolicy="no-referrer" src="/img/bVdm76X" alt="ea7e1f6cb1ed36f43fef784cf02823e4.png" title="ea7e1f6cb1ed36f43fef784cf02823e4.png" loading="lazy"/><br/>招聘端的反应最真实：<br/>脉脉上已有1000+公司同步招聘大模型岗位。<br/>AI人工智能岗平均月薪7.8万，<br/>高校实习生日薪也能达到4000。<br/>顶级岗位甚至直接开出60K×16薪，百万年薪已不再新鲜。<br/>企业的态度非常直接：<br/>真正能做应用落地的人，不够用。<br/>Part3<br/>技术圈在经历裁员，但AI应用岗在经历抢人<br/>过去一年，你一定听过太多关于降薪、裁员、岗位减少的消息。<br/>前端、后端、测试、运维等传统岗位正被工具链与自动化改写。<br/>很多研发的焦虑就是来自于：<br/>技术速度在变，岗位边界在变，薪资体系也在变。<br/>但另一条线完全不同——<br/>AI应用岗位仍处在供不应求阶段，薪资梯度全面上移，流动性极高，岗位数量持续增长。<br/>为什么？<br/>因为AI应用不是“替代原岗位”，而是在“创造新岗位”。<br/>是把各行业的流程、工具、系统重新定义的一场底层变革。<br/>这也让大模型应用开发工程师的职位具备极强的抗周期性：<br/>项目越多，需求越大；<br/>技术越强，壁垒越高。<br/>这种增长结构在过去十年极少出现。<br/>Part4<br/>转型为什么难？难在体系，不在能力<br/>很多技术人都想转型AI，但真正迈过去的人其实很少。<br/>难点不是“学不会”，而是“不会系统地学”。<br/>常见的困境包括：<br/>不了解行业风向，不知道去哪条路径；<br/>技术栈跨度大，缺乏体系化能力；<br/>知识碎片化，看了很多内容却无法整合；<br/>缺乏企业级项目经验，无法获得面试竞争力。<br/>这也是为什么<br/>真正具备完整体系能力的人，稀缺度会被放大。<br/>所谓体系，是指完整掌握：<br/>AI应用开发的底层逻辑<br/>大模型调用、RAG、Agent、工具链、评测体系的技术栈<br/>能独立完成两到三个可复用的企业级落地项目<br/>当一个技术人具备这三点，他的市场竞争力会成倍上升，甚至远超自身原有岗位的天花板。</p><p>2025是AI应用高速落地的第一年<br/>也是技术人职业路径真正分叉的一年<br/>模型层被巨头垄断，算法层越来越卷，训练层门槛巨大。<br/>唯独应用层——具备最大需求、最高薪资、最强增长，也最缺人。<br/>2025–2027将是大模型应用开发的黄金窗口期。<br/>这两三年内完成转型的人，将进入一个长期上升通道；<br/>继续观望的人，将被行业速度甩开一截。<br/>技术人从未面临过如此明确的趋势——<br/>应用层正在成为新的技术金字塔尖。<br/>现在，是提前站上浪潮；<br/>再往后，就是被动跟随浪潮。<br/>现在搜索并关注 「OJAC近屿智能」公众号，即可免费领取超值资料包：<br/>想要获取AI资料包、最新的AI行业动态和优质工作机会吗？<br/>快来扫码加入我们的AI交流群吧！<br/>1️⃣ 每周一次 | 工作机会速递<br/>整合最新的AI行业工作机会，群内推送高质量的岗位讯息。<br/>2️⃣ 每月底 | 前沿技术分享<br/>邀请一流科技领袖分享最新研究进展、行业动态和技术实践，让您时刻站在AI领域的前沿。<br/>3️⃣ 不定期 | 独家行业资讯<br/>实时推送每日AI热点、行业深度解读，助你快速掌握核心趋势。<br/>👇👇👇欢迎搜索“OJAC近屿智能”，了解详情👇👇👇</p>]]></description></item><item>    <title><![CDATA[用DeepSeek提升项目效率：实操技巧]]></title>    <link>https://segmentfault.com/a/1190000047419318</link>    <guid>https://segmentfault.com/a/1190000047419318</guid>    <pubDate>2025-11-21 22:02:58</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在纷繁复杂的信息浪潮中，如何找到真正重要的方向和节点，如何用数据和工具辅助决策，是每一位项目管理者不得不思考的问题。DeepSeek作为一款以深度学习技术为核心的智能分析工具，无疑为解答这些问题提供了一种全新的思路。<br/><img width="723" height="460" referrerpolicy="no-referrer" src="/img/bVdk1ax" alt="" title=""/></p><h2>项目管理的复杂性与盲点</h2><p>项目管理是一门介于计划与行动之间的科学。从设定目标到分解任务，从资源分配到绩效追踪，管理者需要协调的变量在不断增加。而在信息驱动的时代，数据分析成为重要工具，但带来的挑战也愈加明显——数据量庞大、结构复杂、使用不协调。这使得很多技术团队即便拥有高效的项目管理工具，也常因无法提炼关键信息而感到无所适从。</p><p>例如，传统的项目管理软件如Zoho Projects等，尽管能提供任务分配、时间跟踪和资源管理功能，但对于如何进一步优化项目进程、如何发现潜在问题和瓶颈，却往往缺乏深入见解。这就是DeepSeek所能够发挥作用的地方：它不仅能够帮助识别模式和问题，还可以提供基于数据分析的预测支持，帮助技术团队实现真正的数据驱动决策。</p><h2>DeepSeek的核心能力</h2><p>DeepSeek在数据分析和优化领域所展现的特点，正在为项目管理提供更多可能性。以下是其主要功能的概述与解析：</p><h2>1. 关键信息提取</h2><p>DeepSeek采用深度学习技术，能够迅速从复杂的多维度数据中提取关键信息。针对多团队协作，大量进度数据分散在各种表格、历史记录及项目软件中。DeepSeek通过智能化处理，可以快速整理出数据中的趋势、关键里程碑和瓶颈点。例如，一个大型的技术开发项目中的bug数量变化、任务延迟分布情况，DeepSeek都能以可视化图表的形式呈现出来。通过这些智能分析，项目经理在项目管理软件中，能够迅速抓住问题的本质，而避免深陷数据的海洋。</p><h2>2. 预测分析</h2><p>DeepSeek所承载的一项核心能力在于预测分析。它通过对历史任务周期数据、员工工作时长数据以及各类资源投入数据的归纳建模，可以预判未来可能出现的进度偏差。例如，如果某些任务长时间积压，或者团队某一部分成员的工作负载不均衡，DeepSeek将利用其数据模型及时给出警报，并提示相关问题的优先级。结合项目管理软件，管理者可以更早采取调整措施，从而避免风险的积累。</p><h2>3. 优化方案推荐</h2><p>每一个项目都蕴藏着优化潜力，但发现这一潜力的过程并不容易。DeepSeek能够有效地整理工作流信息，从任务历史数据中分析出障碍点，并给出优化方案。比如，通过追踪完成时间、不同成员的协作状态，DeepSeek可以识别并推荐改进任务分配的方式，从无形中提升效率。</p><p>通过结合DeepSeek的这些功能，项目管理软件不再只是一个任务监控平台，而成为了一个智能化的辅助决策工具。</p><h2>DeepSeek与项目管理软件的协同结合</h2><p>在将DeepSeek引入技术团队的项目管理工作中，有一个重要前提是协同。DeepSeek本身并非直接代替项目管理软件，而是通过与常见项目管理工具的整合，展现其价值。</p><h2>应用场景一：数据接入与无缝整合</h2><p>（此处可详细描述数据接入与整合的具体方式、优势等，由于原文未详细展开，暂不补充具体内容）</p><h2>应用场景二：任务优先级推荐</h2><p>（此处可详细描述任务优先级推荐的具体逻辑、应用效果等，由于原文未详细展开，暂不补充具体内容）</p><h2>应用场景三：绩效分析的深层推动</h2><p>（此处可详细描述绩效分析如何被DeepSeek推动、带来哪些改变等，由于原文未详细展开，暂不补充具体内容）</p><h2>如何引导团队适应DeepSeek所带来的变革？</h2><p>虽然DeepSeek能显著优化项目管理工作，但工具的引入与使用仍然需要一段“软着陆”过程。为了确保团队高效地接受这一新工具，以下几点建议值得管理者注意：</p><h2>开展针对性的培训</h2><p>利用简短的工作坊或在线教程，向团队成员展示DeepSeek的基本功能与实际应用案例，使其认知到这一工具的优势。</p><h2>设置试点项目</h2><p>在团队的日常工作中，选择一个技术相对成熟但管理效率不高的项目作为试点。这有助于将DeepSeek的效果直接体现在具体成果上，从而增强团队的信任感。</p><h2>建立反馈循环</h2><p>技术团队的工作往往依赖灵活的调整机制。在初期使用DeepSeek时，鼓励团队成员对工具的输出结果与提示信息提出反馈，为后续精细化配置提供依据。</p><h2>强调人机协同</h2><p>提醒管理者与团队成员，DeepSeek并非用来替代人的决策能力，而是通过丰富可靠的数据支持，增强每位项目参与者的判断力。合理分配工具与人的职责，才能激发最佳成效。</p>]]></description></item><item>    <title><![CDATA[果蔬识别系统【最新版】Python+Te]]></title>    <link>https://segmentfault.com/a/1190000047419323</link>    <guid>https://segmentfault.com/a/1190000047419323</guid>    <pubDate>2025-11-21 22:02:06</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>一、项目介绍</h2><p>本系统基于TensorFlow框架，搭建了一个采用卷积神经网络（CNN）的果蔬图像识别模型。我们收集了包括‘土豆’、‘圣女果’、‘大白菜’、‘大葱’、‘梨’、‘胡萝卜’、‘芒果’、‘苹果’、‘西红柿’、‘韭菜’、‘香蕉’和‘黄瓜’在内的12类常见果蔬数据集，通过多轮迭代训练，最终得到一个识别准确率较高的深度学习模型。同时，系统配备了完整的Web可视化操作平台，便于用户交互使用。</p><p><strong>技术架构</strong>：</p><ul><li><strong>前端</strong>：Vue3 + Element Plus</li><li><strong>后端</strong>：Django</li><li><strong>算法</strong>：TensorFlow + 卷积神经网络（CNN）</li></ul><p><strong>主要功能</strong>：</p><ol><li>系统支持管理员与普通用户两种角色，登录后依据角色权限展示相应功能模块。</li><li>登录用户可发布、查看及编辑文章，文章编辑集成Markdown编辑器，支持富文本排版。</li><li>图像识别模块支持用户上传果蔬图片，系统自动识别并返回类别名称及置信度。</li><li>基于ECharts绘制柱状图，直观展示所有果蔬类别对应的置信度分布。</li><li>智能问答模块允许用户输入问题，系统通过调用Deepseek API实现智能回复。</li><li><h2>管理员可在用户管理模块中对用户账户进行统一管理与编辑操作。</h2><p><strong>背景介绍</strong><br/>随着人工智能技术的快速发展，基于深度学习的图像识别已广泛应用于农业、零售及日常生活等多个领域。针对果蔬种类繁多、人工识别效率有限的问题，本项目基于TensorFlow框架，构建了一个采用卷积神经网络（CNN）的果蔬图像识别系统。该系统能够高效识别包括“苹果”“香蕉”“胡萝卜”“西红柿”等在内的12类常见果蔬，具备较高的识别准确率。同时，系统结合Vue3与Django技术，开发了功能完善的Web可视化交互平台，不仅支持果蔬图像识别与结果可视化，还集成了文章管理与智能问答等功能，有效提升了系统的实用性与用户体验。该研究为推动图像识别技术在智慧农业及智能生活中的应用提供了有价值的实践参考。</p></li></ol><h2>二、系统效果图片展示</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047419325" alt="图片" title="图片"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047419326" alt="图片" title="图片" loading="lazy"/></p><h2>三、演示视频 and 安装 and 完整代码</h2><p>地址：<a href="https://link.segmentfault.com/?enc=RzXJc1gkkKP2zaAEvUhP2A%3D%3D.NaKKDE7dGU%2F92nwRwaz4rHqOJeJjL7ho6gt3hnPZygU%3D" rel="nofollow" target="_blank">https://ziwupy.cn/p/bwyX8Y</a></p><h2>四、TensorFlow介绍</h2><pre><code class="python">import tensorflow as tf
from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions
import numpy as np
from PIL import Image

# 加载预训练的ResNet50模型
model = ResNet50(weights='imagenet')

def classify_image(image_path):
    # 加载和预处理图像
    image = Image.open(image_path).convert('RGB')
    image = image.resize((224, 224))  # ResNet50要求输入尺寸
    image_array = np.array(image)
    image_array = np.expand_dims(image_array, axis=0)  # 添加批次维度
    image_array = preprocess_input(image_array)  # 预处理
    
    # 进行预测
    predictions = model.predict(image_array)
    
    # 解码预测结果
    decoded_predictions = decode_predictions(predictions, top=3)[0]
    
    # 输出结果
    print("预测结果:")
    for i, (imagenet_id, label, score) in enumerate(decoded_predictions):
        print(f"{i+1}. {label}: {score:.4f}")

# 使用示例
classify_image('your_image.jpg')</code></pre><p><strong>说明：</strong> 这段代码使用TensorFlow的Keras API加载预训练的ResNet50模型。首先通过PIL加载图像并调整到224×224像素，然后进行模型特定的预处理。<code>decode_predictions</code>函数将输出转换为可读的标签和置信度分数，默认显示前3个最可能的预测结果。需要将'your_image.jpg'替换为实际图像路径。</p>]]></description></item><item>    <title><![CDATA[水果识别系统【最新版】Python+Te]]></title>    <link>https://segmentfault.com/a/1190000047419330</link>    <guid>https://segmentfault.com/a/1190000047419330</guid>    <pubDate>2025-11-21 22:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>一、项目介绍</h2><p>水果识别系统，通过TensorFlow搭建卷积神经网络算法，并收集了10种常见的水果数据集（'哈密瓜', '椰子', '樱桃', '火龙果', '猕猴桃', '红苹果', '芒果', '葡萄', '西瓜', '香蕉'），对其进行多轮迭代训练，最后得到了一个精度较高的模型，并搭建Web可视化操作平台。<br/><strong>前端</strong>: Vue3、Element Plus<br/><strong>后端</strong>：Django<br/><strong>算法</strong>：TensorFlow、卷积神经网络算法<br/><strong>具体功能</strong>：</p><ol><li>系统分为管理员和用户两个角色，登录后根据角色显示其可访问的页面模块。</li><li>登录系统后可发布、查看、编辑文章，创建文章功能中集成了markdown编辑器，可对文章进行编辑。</li><li>在图像识别功能中，用户上传图片后，点击识别，可输出其识别结果和置信度</li><li>基于Echart以柱状图形式输出所有种类对应的置信度分布图。</li><li>在智能问答功能模块中：用户输入问题，后台通过对接Deepseek接口实现智能问答功能。</li><li>管理员可在用户管理模块中，对用户账户进行管理和编辑。</li></ol><p><strong>背景介绍</strong><br/>随着人工智能技术的快速发展，基于深度学习的图像识别技术已广泛应用于日常生活与产业实践中。水果识别作为其中的一个典型应用场景，不仅有助于提升农产品分拣、零售结算等环节的自动化水平，也为普通用户提供了便捷的识别工具。本项目基于TensorFlow框架，采用卷积神经网络（CNN）构建了一个高效的水果识别模型，并选用包括哈密瓜、椰子、樱桃等在内的10类常见水果数据集进行训练与优化，最终实现了高精度的识别效果。为进一步增强系统的实用性与交互性，项目还整合了Web技术，搭建了前后端分离的可视化平台，支持图像识别、数据分析、内容管理及智能问答等多样化功能，从而为用户和管理员提供了一体化、智能化的操作体验。</p><h2>二、系统效果图片展示</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047419325" alt="图片" title="图片"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047419326" alt="图片" title="图片" loading="lazy"/></p><h2>三、演示视频 and 安装 and 完整代码</h2><p>地址：<a href="https://link.segmentfault.com/?enc=79%2FZyJfbnMXL841Ss%2BhuwA%3D%3D.13seDEwC4qKwTG1iBalCWd75LzbYWNlf8bKqMp2i3pA%3D" rel="nofollow" target="_blank">https://ziwupy.cn/p/WVdkAX</a></p><h2>四、TensorFlow介绍</h2><p>代码示例：</p><pre><code class="python">import tensorflow as tf
from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions
import numpy as np
from PIL import Image

# 加载预训练的ResNet50模型
model = ResNet50(weights='imagenet')

def predict_image(image_path):
    # 加载和预处理图像
    image = Image.open(image_path)
    image = image.resize((224, 224))  # ResNet50需要的输入尺寸
    image_array = np.array(image)
    
    # 如果图像是灰度图，转换为RGB
    if len(image_array.shape) == 2:
        image_array = np.stack([image_array] * 3, axis=-1)
    
    # 预处理
    image_batch = np.expand_dims(image_array, axis=0)
    processed_image = preprocess_input(image_batch)
    
    # 预测
    predictions = model.predict(processed_image)
    
    # 解码预测结果
    decoded_predictions = decode_predictions(predictions, top=3)[0]
    
    # 打印结果
    print("预测结果：")
    for i, (imagenet_id, label, score) in enumerate(decoded_predictions):
        print(f"{i+1}. {label}: {score:.4f}")

# 使用示例
predict_image('test_image.jpg')</code></pre><p>这段代码演示了如何使用TensorFlow中的预训练ResNet50模型进行图像识别。代码首先加载在ImageNet数据集上预训练的ResNet50模型，然后对输入图像进行预处理（调整尺寸、格式转换等），最后通过模型预测并输出置信度最高的3个类别及其概率。ResNet50是一个50层深的残差网络，在图像分类任务中表现出色，无需训练即可直接用于识别1000种常见物体类别。</p>]]></description></item><item>    <title><![CDATA[拒绝“大宽表”进阶篇：如何设计十亿级 I]]></title>    <link>https://segmentfault.com/a/1190000047418992</link>    <guid>https://segmentfault.com/a/1190000047418992</guid>    <pubDate>2025-11-21 21:05:50</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>引言：数据接进来了，然后呢？</h2><p>在上一篇文章中，我们聊到了利用“三层漏斗模型”解决了微信、抖音、QQ 等多渠道数据的<strong>接入</strong>问题。</p><p>解决了“写”的问题，紧接着就是更棘手的“读”的问题。</p><p>你是否遇到过这些场景：</p><ol><li><strong>私聊与群聊逻辑分裂</strong>：查私聊要 <code>WHERE sender = A AND receiver = B</code>，查群聊要 <code>WHERE group_id = X</code>，代码里到处是 <code>if-else</code>。</li><li><strong>列表页加载慢</strong>：为了获取<strong>首页列表显示的最新消息信息</strong>，都要去几千万行的消息表中做聚合查询 (<code>GROUP BY</code>)，数据库 CPU 直接飙升。</li><li><strong>分库分表困难</strong>：当数据量达到亿级时，发现当初表设计得太随意，根本没法做数据分片。</li></ol><p>今天，我们深入数据库底层，聊聊如何通过**“会话归一化”<strong>和</strong>“写扩散”**策略，设计一个能抗住十亿级数据的 IM 架构。</p><hr/><h2>一、 核心痛点：分裂的收发逻辑</h2><p>在传统设计中，最容易踩的坑就是把“私聊”和“群聊”看作两个完全不同的物种。</p><ul><li><strong>私聊</strong>：是“人对人”。</li><li><strong>群聊</strong>：是“人对群”。</li></ul><p>如果你设计了 <code>private_message</code> 和 <code>group_message</code> 两张表，或者在同一张表里用复杂的 <code>receiver_id</code> 逻辑，查询历史记录时就会非常痛苦：</p><pre><code class="sql">-- 痛苦的查询：需要判断方向，还要处理群聊逻辑
SELECT * FROM wx_message 
WHERE (sender_id = '我' AND receiver_id = '他') 
   OR (sender_id = '他' AND receiver_id = '我')
   OR (group_id = '某群')
ORDER BY time DESC;</code></pre><p>这种 SQL 不仅写起来累，而且极难利用索引，是性能杀手。</p><hr/><h2>二、 破局策略：全局 ID 与会话归一化</h2><p>要解决这个问题，我们需要引入一个核心概念：<strong>会话 (Session)</strong>。</p><p>无论对方是一个“人”还是一个“群”，对系统来说，都只是一个**“聊天对象”**。我们需要把它们抽象统一。</p><h3>1. 全局 ID 策略 (The Global ID)</h3><p>我们放弃传统的数据库自增 ID，改用 <strong>Snowflake (雪花算法) 的变体</strong>。我们在 ID 的比特位中，预留 3-4 位来标识 <strong>“实体类型”</strong>。</p><ul><li><strong>Contact ID (联系人)</strong>：生成的 ID 必定带有 <code>Type=1</code> 的基因。</li><li><strong>Group ID (群组)</strong>：生成的 ID 必定带有 <code>Type=2</code> 的基因。</li></ul><p><strong>收益：</strong> 任何一个 ID，不需要查库，后端一看就知道它是人还是群。且保证了 <code>Contact</code> 表和 <code>Group</code> 表的 ID <strong>绝对不重复</strong>。</p><h3>2. 消息表设计：抛弃 Receiver，拥抱 Session</h3><p>基于全局 ID，我们可以将消息表简化到极致。不再区分发送者和接收者，统一使用 <code>session_id</code>。</p><pre><code class="sql">CREATE TABLE wx_message (
    id BIGINT NOT NULL COMMENT '消息全局唯一ID',
    
    -- 【关键设计】分片键 (Sharding Key)
    -- 即使 session_id 已经能定位数据，我们依然冗余 account_id
    -- 也就是为了让同一个接入账户的数据落在同一个库，方便管理和清理
    account_id BIGINT NOT NULL COMMENT '所属账户ID',
    
    -- 【核心设计】统一会话ID
    -- 无论是私聊还是群聊，只存这一个 ID
    -- 如果是私聊 session_id 为
    session_id BIGINT NOT NULL COMMENT '全局唯一会话ID (Contact/Group)',
    
    sender_id BIGINT NOT NULL COMMENT '发送者ID',
    
    -- 消息内容
    payload JSON COMMENT '消息内容',
    
    time_stamp BIGINT NOT NULL,
    
    PRIMARY KEY (id),
    -- 【黄金索引】单索引解决所有历史记录查询
    INDEX idx_history (account_id, session_id, time_stamp DESC)
);</code></pre><p><strong>现在，查询历史记录变得异常简单：</strong></p><pre><code class="sql">-- 无论是查群还是查人，SQL 只有这一句
SELECT * FROM wx_message 
WHERE account_id = 101 AND session_id = 888888 
ORDER BY time_stamp DESC;</code></pre><hr/><h2>三、 性能优化：列表页的“写扩散”</h2><p>解决了历史记录查询，最大的 BOSS 来了：<strong>首页列表显示的最新消息信息怎么查？</strong></p><p>很多初学者会这样做：<br/><code>SELECT * FROM wx_message GROUP BY session_id ORDER BY MAX(time) DESC</code></p><p>在数据量少时没问题，但当消息表有 1 亿行数据时，这个聚合查询会让数据库直接宕机。</p><h3>解决方案：引入会话快照表 (<code>wx_session</code>)</h3><p>我们采用**“空间换时间”**的策略，维护一张“只有最新状态”的表。</p><p><strong>设计哲学：写扩散 (Write Amplification)</strong>。<br/>每当 <code>wx_message</code> 写入一条新消息时，同步更新 <code>wx_session</code> 表。</p><h4>✅ 表结构设计</h4><pre><code class="sql">CREATE TABLE wx_session (
    id BIGINT NOT NULL,
    account_id BIGINT NOT NULL,
    session_id BIGINT NOT NULL,
    
    -- 【预览优化】不要存原始 JSON，只存用于列表展示的文本
    -- 例如："[图片]"、"张三: 晚上吃啥？"
    last_message_digest VARCHAR(500) DEFAULT '',
    
    -- 用于列表排序
    last_msg_time BIGINT NOT NULL,
    unread_count INT DEFAULT 0,
    
    PRIMARY KEY (id),
    UNIQUE KEY uk_acc_sess (account_id, session_id), -- 物理防重
    INDEX idx_list (account_id, last_msg_time DESC)   -- 列表查询专用索引
);</code></pre><p><strong>收益：</strong><br/>查询会话列表时，不再需要去亿级消息海里捞针，而是直接查这张只有几万行数据的快照表：</p><pre><code class="sql">-- 极速响应的列表查询（复杂度 O(1)）
SELECT * FROM wx_session 
WHERE account_id = 101 
ORDER BY last_msg_time DESC 
LIMIT 20;</code></pre><hr/><h2>总结</h2><p>构建一个高可用、可扩展的 IM 消息系统，数据库设计是基石。通过今天的实战演练，我们总结出这套架构的三大核心策略：</p><ol><li><strong>统一 ID</strong>：利用全局 ID 策略消除“类型”字段，简化逻辑，让 ID 自解释。</li><li><strong>会话归一</strong>：放弃 <code>receiver_id</code>，使用 <code>session_id</code> 统一私聊与群聊，让消息查询变成简单的单表查询。</li><li><strong>读写分离</strong>：通过 <code>wx_session</code> 快照表，利用写扩散策略，将获取<strong>首页列表显示的最新消息信息</strong>这一高频操作的复杂度从 O(N) 降为 O(1)。</li><li><strong>分片预留</strong>：始终冗余 <code>account_id</code>，为未来的分库分表留好后路。</li></ol><p>不要让业务的复杂性污染了你的架构。好的设计，应该像乐高积木一样，模块清晰，插拔自如。</p><p>本文由<a href="https://link.segmentfault.com/?enc=v2QJ7tgS0LLbcESGXNTbDA%3D%3D.gFxRO480BUEpkX8PQTTt708RiaIPJh9Iu%2Bh95yk6fhs%3D" rel="nofollow" target="_blank">mdnice</a>多平台发布</p>]]></description></item><item>    <title><![CDATA[VeloxCon China 2025 ]]></title>    <link>https://segmentfault.com/a/1190000047419004</link>    <guid>https://segmentfault.com/a/1190000047419004</guid>    <pubDate>2025-11-21 21:04:53</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在数据驱动一切的时代，从交互式商业智能、大规模 AI 训练，到高并发实时分析与持续流处理，多样化的现代工作负载正不断挑战传统数据引擎的性能极限。</p><p>Velox 作为开源统一执行引擎，凭借其向量化执行、编码感知优化与硬件协同设计，正成为驱动这些关键场景的高性能基石。它不仅为 Presto、Spark 等平台提供了核心加速支持，其应用也已深入至 AI/ML 工作流、统一流批处理及云原生时序数据库等复杂场景。</p><p>现在，深入探索 Velox 生态的契机已然到来——首届 VeloxCon China 2025 将于 12 月 13 日在北京举办。作为 Velox 社区的顶级技术盛会，本届大会将汇聚来自 Meta、蚂蚁集团、IBM、英特尔、阿里巴巴、腾讯、小米、小红书等团队的核心开发者，通过分享一系列生产环境下的实战经验与架构演进，完整呈现 Velox 驱动下一代数据基础设施的技术全景与社区生态。</p><p>大会议程现已发布，让我们先睹为快！</p><p><strong>大会完整议程</strong><br/><img width="723" height="4711" referrerpolicy="no-referrer" src="/img/bVdm70m" alt="" title=""/></p>]]></description></item><item>    <title><![CDATA[2025国内智能工单管理系统排行榜 遭老]]></title>    <link>https://segmentfault.com/a/1190000047419007</link>    <guid>https://segmentfault.com/a/1190000047419007</guid>    <pubDate>2025-11-21 21:04:00</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>智能工单管理系统逐渐成为企业提升客户服务效率、优化内部流程的重要工具。无论是售后服务、技术支持，还是内部任务分配，工单管理系统都能助力企业实现高效的任务流转和问题解决。目前，国内市场上有许多优秀的智能工单管理系统，它们在功能、易用性和智能化程度上各有特色。本文将为大家盘点几款国内好用的智能工单管理系统。<br/><img width="723" height="487" referrerpolicy="no-referrer" src="/img/bVdm70Q" alt="" title=""/></p><h2>1. Zoho Desk</h2><p>推荐理由<br/>Zoho Desk 是一款全球领先的智能工单管理系统，专注于提升企业客户服务效率。它支持多渠道工单管理、自动化流程、智能分析等功能，能满足企业在客户支持和内部任务管理中的多样化需求。Zoho Desk 提供中文界面和本地化支持，非常适合国内企业使用。</p><p>核心功能<br/>多渠道工单管理：支持通过电子邮件、电话、社交媒体、聊天工具等多种渠道接收和管理工单。<br/>自动化流程：通过规则和工作流自动分配工单、设置优先级和触发通知，减少人工干预。<br/>人工智能助手：内置 AI 助手 Zia，能够智能分类工单、预测客户情绪，并提供解决方案建议。<br/>客户服务门户：支持企业搭建自助服务门户，客户可自行提交工单、查看进度或查阅知识库。<br/>数据分析与报表：提供全面的工单数据分析，帮助企业优化服务流程和提升客户满意度。<br/>优点<br/>界面友好，操作简单，适合各类企业使用。<br/>支持多语言，包括中文，适合国内企业。<br/>提供强大的自动化和智能化功能，减少人工操作。<br/>与 Zoho 生态系统中的其他工具（如 CRM、项目管理工具）无缝集成。<br/>适用场景<br/>客户服务团队需要高效管理多渠道工单。<br/>企业希望通过自动化和智能化提升服务效率。<br/>需要与其他业务系统（如 CRM）集成的企业。</p><h2>2. 纷享销客工单系统</h2><p>推荐理由<br/>纷享销客是一款专注于国内市场的企业服务平台，其工单管理模块功能全面，适合中小企业使用。它支持客户服务和内部任务管理，能够帮助企业实现高效的工单流转。</p><p>核心功能<br/>支持多渠道工单接入，包括电话、邮件和微信。<br/>提供工单分配、优先级设置和进度跟踪功能。<br/>支持移动端操作，随时随地管理工单。<br/>提供基础的数据分析和报表功能。<br/>优点<br/>针对国内市场设计，支持中文界面。<br/>功能全面，适合中小企业使用。<br/>提供本地化服务和支持。<br/>缺点<br/>高级功能需要付费。<br/>界面设计相对复杂，新手需要一定学习时间。<br/>适用场景<br/>国内中小企业需要一款本地化的工单管理工具。<br/>希望通过移动端管理工单的企业。</p><h2>3. Freshdesk</h2><p>推荐理由<br/>Freshdesk 是一款国际化的智能工单管理系统，提供免费版本，适合中小企业使用。它支持多渠道工单管理、自动化流程和客户自助服务功能。</p><p>核心功能<br/>支持通过电子邮件、电话、聊天工具等多种渠道接收工单。<br/>提供自动化规则和工作流，简化工单处理流程。<br/>支持客户自助服务门户和知识库管理。<br/>提供基础的数据分析和报表功能。<br/>优点<br/>界面友好，易于上手。<br/>免费版功能较为全面。<br/>支持多语言，适合国际化企业。<br/>缺点<br/>对中文支持较弱。<br/>部分高级功能需要付费。<br/>适用场景<br/>需要一款国际化工单管理工具的企业。<br/>对客户自助服务有需求的团队。</p><h2>4. 简道云工单管理</h2><p>推荐理由<br/>简道云是一款国内知名的低代码开发平台，同时提供工单管理功能，适合需要自定义功能的企业。</p><p>核心功能<br/>支持自定义工单表单和流程。<br/>提供工单分配、优先级设置和进度跟踪功能。<br/>支持移动端操作，随时随地管理工单。<br/>提供数据分析和报表功能。<br/>优点<br/>界面简洁，操作简单。<br/>支持高度自定义，满足个性化需求。<br/>缺点<br/>免费版功能有限。<br/>对复杂需求的支持较弱。<br/>适用场景<br/>需要高度自定义工单管理功能的企业。<br/>对低代码开发感兴趣的团队。</p><h2>5. 八百客（800APP）工单系统</h2><p>推荐理由<br/>八百客是一款国内知名的企业管理软件，其工单管理模块功能全面，适合中小企业使用。</p><p>核心功能<br/>支持多渠道工单接入，包括电话、邮件和微信。<br/>提供工单分配、优先级设置和进度跟踪功能。<br/>支持移动端操作，随时随地管理工单。<br/>提供数据分析和报表功能。<br/>优点<br/>针对国内市场设计，支持中文界面。<br/>功能全面，适合中小企业使用。<br/>缺点<br/>部分高级功能需要付费。<br/>用户界面相对复杂。<br/>适用场景<br/>国内中小企业需要一款本地化的工单管理工具。<br/>希望通过移动端管理工单的企业。</p><h2>6. 金蝶云·星空工单管理</h2><p>推荐理由<br/>金蝶云·星空是一款国内知名的企业管理平台，其工单管理模块功能强大，适合中大型企业使用。</p><p>核心功能<br/>支持多渠道工单接入和管理。<br/>提供自动化规则和工作流，简化工单处理流程。<br/>支持客户自助服务门户和知识库管理。<br/>提供全面的数据分析和报表功能。<br/>优点<br/>针对国内市场设计，支持中文界面。<br/>功能强大，适合中大型企业使用。<br/>缺点<br/>免费版功能有限。<br/>界面设计相对复杂。<br/>适用场景<br/>国内中大型企业需要一款本地化的工单管理工具。<br/>对数据分析和报表功能有较高需求的团队。</p><h2>7. Worktile 工单管理</h2><p>推荐理由<br/>Worktile 是一款国内知名的团队协作工具，同时提供工单管理功能，适合中小企业使用。</p><p>核心功能<br/>支持工单分配、优先级设置和进度跟踪。<br/>提供团队协作工具，提升内部沟通效率。<br/>支持移动端操作，随时随地管理工单。<br/>优点<br/>界面简洁，操作简单。<br/>提供团队协作功能，适合小团队使用。<br/>缺点<br/>免费版功能有限。<br/>对复杂需求的支持较弱。<br/>适用场景<br/>小型团队需要一款简单易用的工单管理工具。<br/>对团队协作有较高需求的企业。</p><h2>总结</h2><p>以上就是国内好用的智能工单管理系统盘点。对于企业来说，选择一款合适的工单管理系统可以显著提升客户服务效率和内部协作水平。如果您需要一款功能全面、支持中文且智能化程度高的工单管理工具，Zoho Desk 是一个非常值得推荐的选择。它不仅支持多渠道工单管理，还提供强大的自动化和智能化功能，能够帮助企业优化服务流程、提升客户满意度。</p><p>在选择工单管理系统时，建议根据企业的实际需求、团队规模以及预算进行综合考虑，选择最适合自己的工具。希望本文的盘点能为您提供有价值的参考！</p>]]></description></item><item>    <title><![CDATA[MineContext：我第一次感觉 A]]></title>    <link>https://segmentfault.com/a/1190000047419020</link>    <guid>https://segmentfault.com/a/1190000047419020</guid>    <pubDate>2025-11-21 21:03:17</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>我现在一天基本离不开 AI 了。  <br/>不是那种“把提示词写得像炼丹”式的依赖，而是很平常的那种：</p><p>我写代码，它在旁边检查。  <br/>我整理逻辑，它帮我捋一遍。  <br/>我写文档，它补补关键字、给点建议。</p><p>整个过程更像是 <strong>我在人前台写，它在后台兜底</strong>。  <br/>它不是替我工作，它是把我的工作做得更圆滑、更完整。</p><p>但说实话，我过去对“AI 助理”的期待真的不高。  <br/>因为不管助理多聪明，你不给输入，它就是个哑巴。</p><p>它更像一个“贴心的编辑器”，而不是一个“主动的助理”。  <br/>尤其是写日报、周报的时候。</p><p>我不说，它啥都不知道。  <br/>输入少，它就笨；输入多，我就累。</p><p>所以一般都是：</p><p>我亲自写 → AI 润色 → 我审核 → 再调整一下。</p><p>直到我遇到了 ​<strong>MineContext</strong>。</p><hr/><h2>直到我遇到 MineContext</h2><p>有一天我随便逛 GitHub，看到一个叫 <strong>MineContext</strong> 的东西。  <br/>它确实在某种程度上展示了某种 AI 使用的新方向。</p><p><img width="723" height="276" referrerpolicy="no-referrer" src="/img/bVdm70U" alt="" title=""/></p><p>它不是等你给材料，它是：</p><ul><li>自己看</li><li>自己分析</li><li>自己整理</li><li>自己总结</li><li>最后把报告端过来</li></ul><p>我只是正常用电脑，它就在后台默默观察。</p><p>等我晚上坐下来，它就会递给我一份报告，告诉我今天都做了什么。</p><p>那份报告甚至比我自己写的更全面、更有逻辑、更有洞察。</p><p>对于我这种喜欢把生活“数字化”来管理的人来说，这东西简直是天赐。  <br/>我甚至隐隐觉得，这可能会成为新一代人的工作方式。  <br/><strong>AI 主动帮你记录、帮你整理，而不是你逼着自己记。</strong></p><hr/><h2>MineContext 到底在干什么？</h2><p>用人话讲，它平时就在干这几件事：</p><h3><strong>定时截图你的屏幕</strong></h3><p>比如每隔几秒，它截一张当前屏幕。</p><h3><strong>用视觉模型分析你在干嘛</strong></h3><p>它能识别页面、文档、代码、聊天窗口、IDE、网页内容……  <br/>然后把这些内容结构化。</p><p>比如：</p><ul><li>你在写 PHP</li><li>你在查某个 Cloudflare 500 报错</li><li>你在写博客</li><li>你在看一个项目的 README</li><li>你在 debug</li><li>你在管理数据库</li><li>在跟桐桐聊天，她说她外公喝的茶 1680 一斤，你下单三斤并约定下周一面交（咳）</li></ul><h3><strong>自动去重、过滤、归类</strong></h3><p>把无意义的截图清理掉，把重复信息合并掉，不会让你的数据变垃圾堆。</p><p><img width="723" height="422" referrerpolicy="no-referrer" src="/img/bVdm70V" alt="" title="" loading="lazy"/></p><h3><strong>每一小段时间自动做小结</strong></h3><p>像一个实时存在的“精简时间线”。</p><p><img width="723" height="422" referrerpolicy="no-referrer" src="/img/bVdm70W" alt="" title="" loading="lazy"/></p><h3><strong>生成洞察报告</strong></h3><p>每天、每周，它会把你这些碎片化行为整理成一份真正可读的报告。</p><p>内容包括：</p><ul><li>你今天主要在做什么</li><li>处理了哪些任务</li><li>花了多少时间</li><li>今天的重点主题是什么</li><li>有哪些工作模式、习惯、偏好</li><li>今天的 highlights / issues</li><li>有时候甚至会给你建议</li></ul><p>读起来真的就像把自己交给了一个观察者，它在旁边默默记录你的一天，晚上把故事整理好给你。</p><p><img width="723" height="422" referrerpolicy="no-referrer" src="/img/bVdm70X" alt="" title="" loading="lazy"/></p><hr/><h2>为什么我说它是 ADHD 神器</h2><p>我不是专业讲 ADHD 的，就是站在“注意力容易飘”的普通人角度说一下。</p><p>很多人应该都有这种感觉：</p><ul><li>做了很多事，但回头想不起来今天干了啥</li><li>一天结束的时候没成就感</li><li>事情都是碎片的，很难拼成完整的故事</li><li>想写日报时经常“空白”</li><li>想复盘一下，发现自己根本想不起来</li></ul><p>MineContext 的价值就在这里：</p><p><strong>它帮你把碎片变成结构。</strong></p><p>白天你专心干活，无脑沉浸。  <br/>你不需要特地记，也不需要刻意整理。</p><p>到了晚上，它已经把你的：</p><ul><li>工作流</li><li>切换记录</li><li>查资料轨迹</li><li>输入输出</li><li>项目参与</li><li>日间行为模式</li></ul><p>全部整理得清清楚楚。</p><p>它甚至会告诉你：</p><ul><li>你今天对某个任务持续投入了 2 小时</li><li>你某段时间反复在查某个问题</li><li>你的注意力什么时候最集中</li><li>你什么时候容易走神</li></ul><p>这对注意力问题人群来说太有用了。</p><p>基本上你只需要“活着”，它帮你记录你的生活</p><hr/><h2>这东西意味着什么？</h2><p>我觉得 MineContext 展示了一个<strong>非常新</strong>的方向：</p><p><strong>AI 正在从“你问我答”，变成“我帮你先做”。</strong></p><p>这是一种新工作方式：</p><ul><li>人类负责体验、创造、执行</li><li>AI 负责记录、整理、总结、复盘</li></ul><p>这和我们之前用 AI 的方式完全不一样。</p><p>以前是：</p><blockquote>我要你帮我做点事 → 我提供输入 → 你输出</blockquote><p>MineContext 是：</p><blockquote>我在过我的一天 → 它收集输入 → 它输出给我 → 我再决定怎么用</blockquote><p>这带来的变化非常大：</p><ul><li>你不必靠记忆工作</li><li>你不会错过工作中的关键行为</li><li>你能轻松复盘</li><li>你的大脑不再负责“记”，它只负责“想”</li></ul><p>甚至我隐约觉得：</p><blockquote>将来老板可能会用这种东西来监控员工……</blockquote><p>（真的完全不是不可能，毕竟这玩意可以很精确地记录行为模式）</p><p>不过目前我并不是很担心这一方面，毕竟它是开源的，控制权在你。</p><p>而且数据都是存储在本地，并不会上传云端，每次启动也都需要你自己手动开启才可以。</p><p>所以可能老板会更容易从社会学层面入手，比如半夜偷偷溜回公司开你电脑看你一天摸鱼跟朋友八卦的快速总结</p><hr/><h2>最后的感受</h2><p>我现在几乎每天晚上都会看它给我生成的日报。  <br/>那种体验很奇妙。</p><p>明明是一整天的琐碎行动，它却能被整理成一个“像故事一样”的东西：  <br/>有结构、有因果、有线索、有意义。</p><p>它记录的不是任务列表，而是你的节奏、注意力、思考方式、行动轨迹。  <br/>感觉真的像是和另一个自己一起观看生活的回放。</p><p>这让我突然意识到：  <br/>AI 不是在帮我工作，而是在帮我“理解我自己”。  <br/>而理解自己，恰恰是现代人最缺的能力。</p><p>这几年，AI 热潮来得太快了，快到许多人的态度开始走形。</p><p>有人把 AI 神化，觉得它能给人带来超越常识的答案；  <br/>有人带着宗教式的期待，把提示词当作咒语，把模型当成神谕；  <br/>哪怕一次输出不准，也会怪自己“仪式没做对”，再换一次说法，再祈祷一次。</p><p>那种感觉有点像对未知祈祷：  <br/>一半期待救赎，一半害怕怪异。  <br/>而在这种矛盾里，人反而越来越看不清自己。</p><p>但我越来越觉得，拒绝 AI 和迷信 AI，本质上都是 <strong>放弃了自己的主体性。</strong></p><p>MineContext 的好在于，它的介入方式非常温和。  <br/>它不是来替你做决定的，也不会告诉你应该怎么活。  <br/>它只是默默观察、整理、复盘，把信息用你的方式还给你。</p><p>它像一面镜子，但这面镜子比你自己多看到一点点：  <br/>看到你忽略的细节、看到你一天当中的节奏、看到你无意间形成的路径。  <br/>它帮你把混乱变成秩序，把碎片变成轨迹，把流水账变成有意义的叙事。</p><p>你还是你，只是更清晰了一点。</p><p>在未来这个 AI 会越来越深入环境、工作、家庭，甚至身体的时代里，  <br/>我觉得从这种工具开始，让 AI 以一种不侵入的方式参与生活，是一种很好的提前适应。</p><p>你不会迷失自己，也不会落在潮水后面。</p><p>如果你也想体验一下，GitHub 下载下来，填上自己的 API Key，就能直接用：<strong><a href="https://link.segmentfault.com/?enc=3Kw9BjCYODI%2Fbu3G%2FbIabQ%3D%3D.NWOIYLV7pv79%2B244FzskkFQqvpOAp82BlmRvuhVehR6pR0BW7EzqNYIBDz3%2BakLn" rel="nofollow" target="_blank">MineContext</a></strong></p>]]></description></item><item>    <title><![CDATA[企业管理系统开发平台TOP5：低代码成趋]]></title>    <link>https://segmentfault.com/a/1190000047419035</link>    <guid>https://segmentfault.com/a/1190000047419035</guid>    <pubDate>2025-11-21 21:02:17</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在当今竞争激烈的商业环境中，高效的企业管理系统已成为提升运营效率、优化管理流程的核心工具。然而，传统软件开发模式的高成本、长周期与难维护等痛点，让许多企业望而却步。随着低代码技术的成熟，一种能够平衡个性化需求与实施效率的新范式应运而生。本文将为您介绍5款值得了解的企业管理系统开发平台，并重点解析Zoho低代码平台如何帮助企业高效构建管理系统。<br/><img width="723" height="480" referrerpolicy="no-referrer" src="/img/bVdm71i" alt="" title=""/></p><h2>一、什么是企业管理系统？</h2><p>企业管理系统是指集成企业各项业务流程的软件系统，它涵盖了财务、销售、生产、人力资源等多个管理领域，帮助企业实现资源优化和效率提升。常见的系统类型包括：</p><p>ERP（企业资源规划）：集成企业所有资源信息，实现全面规划和管理。<br/>CRM（客户关系管理）：以客户为中心，管理客户生命周期和价值。<br/>OA（办公自动化）：优化内部流程，提高办公效率。<br/>SCM（供应链管理）：优化供应链各环节，降低成本提高响应速度。<br/>HRM（人力资源管理）：管理员工全生命周期，提升人力资源管理效率。<br/>传统上，企业要么购买标准化软件（可能不符合独特需求），要么投入大量资源进行定制开发（成本高、周期长）。而低代码平台的出现，提供了第三条路：以较低成本快速构建完全符合企业需求的管理系统。</p><h2>二、用低代码平台开发企业管理系统有什么优势？</h2><p>低代码开发平台通过可视化拖拽组件和模型驱动逻辑，大幅降低了应用开发的技术门槛和时间成本。这类平台正在重塑企业数字化基建的构建范式，让技术真正服务于业务管理。</p><h2>1. 显著降低开发成本和时间</h2><p>低代码平台可以以“非常低的成本代替开发人员的部分重复工作”，以前需要十个人的项目现在可以由三个人甚至更少的人完成，而且开发时间能大大缩短70%以上。企业无需组建庞大的开发团队，即可在较短时间内搭建出专业的管理系统。</p><h2>2. 降低技术门槛，促进业务参与</h2><p>有了低代码开发平台，很多不懂代码的业务人员可以自己构建业务流程管理系统，有效降低沟通成本，避免了“开发人员不了解业务”的尴尬。业务部门可以直接参与应用设计和优化，确保系统更贴合实际需求。</p><h2>3. 灵活适应业务变化</h2><p>在企业的发展过程中，业务需求会不断变化，需要及时调整管理系统以适应新的需求。而低代码平台可以通过可视化的编辑界面，快速修改和调整系统的功能，实现快速迭代。</p><h2>4. 提升系统集成能力</h2><p>低代码平台通常提供丰富的API接口和连接器，可以轻松集成企业现有系统，避免信息孤岛现象。例如，Zoho Creator可以集成600多种应用，实现跨部门跨应用的数据提取。</p><h2>三、5款企业管理系统开发平台对比测评</h2><p>以下是五款主流企业管理系统开发平台的综合对比，帮助您全面了解各平台特点：</p><p>平台名称    核心定位    主要优势    适用场景    价格<br/>Zoho低代码    一站式低代码应用开发平台    800+应用集成、AI辅助数据迁移、多设备自适应、强大工作流自动化    ERP、CRM、BPM、进销存、财务管理等全业务场景    免费版：基础功能；标准版：672元/用户/年，1人起购<br/>伙伴云    数据协作与业务管理平台    表格视图功能强大、流程自动化、数据关联能力强、实时协作    订单管理、客户关系管理、进销存等数据密集型场景    标准版：8800/年起，30人起购<br/>简道云    零代码开发    以表单驱动、工作流程管理、开发难度低    企业内部管理系统、简单的B2B解决方案    标准版：5040元/年，30人起购<br/>金蝶    传统ERP系统提供商    行业经验丰富、功能模块全面、财务领域专业性强    制造业ERP、财务管理、供应链管理    业务版：198000元/年起；平台版：需定制报价<br/>织信    企业级低代码平台    预置模板、全栈开发能力、国产化适配    项目管理、生产管理、CRM、ERP等    私有化部署：需咨询报价，定制开发价格通常较高<br/>从对比可以看出，Zoho低代码在功能全面性和价格合理性上表现突出，尤其是其免费版和标准版价格对中小企业非常友好。</p><h2>Zoho低代码平台简介：全能型低代码开发平台</h2><p>Zoho低代码是基于云端的低代码开发平台，始于2006年，是发展较早的低代码产品之一。它支持构建ERP、CRM、BPM、进销存、财务管理等企业所需的各种管理工具。</p><p>核心优势：<br/>强大的集成能力：支持与800多种日常应用集成，实现跨部门跨应用的数据提取。<br/>AI辅助开发：通过智能工具可以在几分钟内将杂乱的数据转换为整洁统一的数据库。<br/>多设备适配：在Web上构建的应用程序会自动适配Android和iOS设备。<br/>可视化工作流：内置强大的工作流程管理功能，用户可以轻松设计和实施自动化的业务流程。<br/>中文技术支持：如果您遇到问题，可获1对1中文技术服务，快速响应解决。<br/>长期稳定：Zoho在全球自建16个服务器，数据传输稳定可靠。<br/>数据安全：企业级数据加密、隐私保护合规等，满足国际贸易中的数据安全要求。<br/>四、如何选择合适的低代码开发平台？选型的注意事项<br/>选择合适的企业管理系统开发平台需要考虑多方面因素，以下是一些关键注意事项：</p><h2>1. 明确业务需求优先级</h2><p>首先识别企业最迫切的需求是什么？是财务管理、客户关系管理还是供应链优化？不同平台在各领域的专长不同。例如，金蝶在财务领域有深厚积累，而Zoho低代码则在全面业务管理方面表现优异。</p><h2>2. 评估团队技术能力</h2><p>如果企业没有专业开发团队，可以选择与Zoho低代码合作伙伴合作，通过支付定制开发费用+产品订阅费，他们可以将其他项目的成功经验直接应用到您的系统中。如果有技术团队，自主利用Zoho低代码进行开发是一个非常经济高效的选择。产品价格公开透明，没有隐性成本。</p><h2>3. 考虑集成和扩展需求</h2><p>确保平台能够与企业现有系统（如财务软件、电商平台等）良好集成。Zoho低代码支持800+应用集成，在这方面表现突出。尤其是集成国际物流、电商平台等，与国内其他商品比，具有独特的优势。出海企业可以用Zoho低代码开发国际供应链系统、外贸报价管理系统、外贸订单管理系统等，打造全流程数据化管理。</p><h2>4. 关注数据安全和合规性</h2><p>特别是处理敏感数据的企业，需要确保平台提供足够的安全保障。Zoho低代码提供数据加密、访问控制等多种安全措施。</p><h2>5. 评估总拥有成本（TCO）</h2><p>除了平台订阅费用，还需考虑实施、培训、维护等隐形成本。一些平台初始价格较低，但后续添加功能或用户时费用较高。</p><h2>结语</h2><p>在数字化转型的浪潮中，选择合适的企业管理系统开发平台至关重要。低代码平台的出现，让企业能够以更低的成本、更短的时间构建完全符合自身需求的管理系统。</p><p>在众多平台中，Zoho低代码凭借其全面的功能、强大的集成能力、灵活的定制性和良好的用户体验，成为企业构建管理系统的理想选择之一。</p>]]></description></item><item>    <title><![CDATA[专题：2025年全球机器人产业发展白皮书]]></title>    <link>https://segmentfault.com/a/1190000047419059</link>    <guid>https://segmentfault.com/a/1190000047419059</guid>    <pubDate>2025-11-21 21:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>原文链接：<a href="https://link.segmentfault.com/?enc=2GD%2FVOmWzgTqKgUWVC7kug%3D%3D.R%2Fj4PhGx6GjPxGbUrRt3%2Fu0ErFTyX218DyFFocj7UTo%3D" rel="nofollow" title="https://tecdat.cn/?p=44366" target="_blank">https://tecdat.cn/?p=44366</a>  <br/>原文出处：拓端抖音号@拓端tecdat</p><h3><a name="t1" target="_blank"/><img referrerpolicy="no-referrer" src="/img/remote/1460000047419061" alt="封面" title="封面"/></h3><p>当具身智能从实验室走向产业落地，中国正凭借独特的“产业底座+生态协同”逻辑，构建全球具身智能的核心竞争力。2025年，这场以AI大模型为核心的产业革命，已形成“技术突破-生态集聚-场景落地”的闭环，中国通过“制造业底座+区域生态+政策赋能”的核心路径，成为全球具身智能规模化落地的关键战场。从协作机器人的工业渗透到人形机器人的成本突围，从大小脑协同算法的技术突破到区域集聚的生态效应，产业正从“单一产品自动化”向“全链条智能化”跃迁。本报告洞察基于《广发证券：2025中国具身智能产业星图》《北京航空航天大学：面向具身智能的大小脑模型协同算法研究及实践》《MIR睿工业：2025全球协作机器人产业发展白皮书具身智能时代的技术突破与产业重构》《东吴证券：机器人大模型深度报告》《华金证券：具身智能大时代，算力芯片筑底座》及文末<strong>300+份</strong>具身智能与机器人行业研究报告的数据，本文完整报告数据图表和最新报告合集已分享在交流群，阅读原文查看、进群咨询，定制数据、报告和800+行业人士共同交流和成长。</p><h3><a name="t2" target="_blank"/>一、战略定位与核心路径：中国的“底座+生态”双轮驱动</h3><p>中国具身智能产业的核心定位，是依托全球领先的制造业底座，构建“技术-产业-区域”三位一体的生态体系，而非单一产品竞争。核心路径清晰明确：以制造业场景为“试验场”，以区域集聚为“生态载体”，以政策赋能为“加速器”，推动具身智能从技术验证走向规模化落地。  <br/>从全球格局看，中国已形成“粤港澳+京津冀+长三角”三大核心生态区，集聚全国90%的具身智能企业，形成差异化分工：广东凭借核心部件制造优势，成为硬件供给的“技术底座”；北京聚焦通用机器人本体与算法研发，打造智能决策的“大脑中枢”；长三角构建“芯片-算法-整机-场景”全链条生态，成为场景落地的“示范窗口”。这种区域协同让中国在工业、商用场景的落地速度领先全球，2024年协作机器人国内销量占全球50%，成为全球最大单一市场。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047419062" alt="" title="" loading="lazy"/></p><p>全球协作机器人地区分布圆环图图表数据及PDF模板已分享到会员群  <br/>3秒解读：亚洲主导全球市场，中国是核心引擎，区域集聚效应构筑竞争壁垒。  <br/>对应人群行动建议：供应链企业可锚定广东、长三角产业园区布局，技术创业者可对接北京科研资源，政策申报可聚焦三地专项扶持方向，借势生态红利。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047419063" alt="" title="" loading="lazy"/></p><p>中国具身智能企业区域分布刻度线图图表数据及PDF模板已分享到会员群  <br/>3秒解读：广东企业数量领跑全国，三大生态区功能互补，形成“硬件-算法-场景”的协同闭环。  <br/>对应人群行动建议：跨区域合作可优先链接“广东硬件+北京算法+长三角场景”资源，降低产业链整合成本，提升落地效率。  <br/>中国32.38万亿元的制造业GDP规模（远超美国的20.30万亿元），为具身智能提供了不可替代的“产业底座”——既提供了海量真实场景用于技术迭代，又构建了完整的供应链支撑硬件成本降低，这也是中国在工业机器人、协作机器人领域快速实现国产化替代的核心逻辑。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047419064" alt="" title="" loading="lazy"/>  <br/>全球主要经济体制造业GDP对比灰底比例条形图图表数据及PDF模板已分享到会员群  <br/>3秒解读：中国制造业规模全球第一，为具身智能提供“场景+供应链”双重支撑。  <br/>对应人群行动建议：海外企业可借力中国供应链降低硬件成本，本土企业可依托制造业场景加速技术迭代，形成“场景-数据-模型”的正向循环。</p><h3><a name="t3" target="_blank"/>二、技术架构与平台布局：大小脑协同的“三层技术体系”</h3><p>中国具身智能的技术突破，核心是构建了“大脑（认知决策）+小脑（运动控制）+感知（环境交互）”的三层技术架构，通过模块化协同破解传统机器人“泛化弱、落地难”的痛点，形成可复用、可扩展的技术平台。  <br/>“大脑”层面，以多模态大模型为核心，实现复杂任务解析与决策规划。多智能体协作系统（MP5）通过5个LLM角色分工，可完成钻石级长时序任务；组合泛化方法（RA-P）将复杂任务拆解为基础技能，让机器人自主学习未知操作，这一技术已在工业装配场景实现落地，任务成功率提升40%。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047419065" alt="" title="" loading="lazy"/></p><p>技能泛化与任务解决水平条形图图表数据及PDF模板已分享到会员群  <br/>3秒解读：多智能体与组合泛化技术突破长时序任务边界，具身智能实用性大幅提升。  <br/>对应人群行动建议：技术研发团队可重点攻关多模态数据融合，工业企业可试点复杂工序的机器人替代，降低对人工的依赖。  <br/>“小脑”层面，聚焦运动控制与实时响应，想象链（MineDreamer）让机器人能预测行动效果，实时监控系统（Code-as-Monitor）结合反应式与主动式检测，在3000步任务中实现零失误，让机器人在动态工业环境中的稳定性提升30%，满足工业级连续作业需求。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047419066" alt="" title="" loading="lazy"/></p><p>真实交互与环境适应性折线图图表数据及PDF模板已分享到会员群  <br/>3秒解读：想象链与实时监控技术显著降低任务失败率，机器人环境适应性达标工业级要求。  <br/>对应人群行动建议：物流、仓储企业可引入该技术提升机器人避障与操作精度，传感器企业可聚焦多模态感知硬件研发，抢占技术制高点。  <br/>“感知”层面，突破三维环境交互能力，RoboRefer模型通过大规模2D/3D数据训练，能精准完成空间定位、物体指代等任务，在宇树G1、Franka等机器人上的实测显示，空间操作精度达毫米级，为精密制造、3C电子等场景落地奠定基础。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047419067" alt="" title="" loading="lazy"/></p><p>空间感知与推理能力雷达图图表数据及PDF模板已分享到会员群  <br/>3秒解读：多模态空间感知技术让机器人“看懂三维世界”，精密操作能力达标场景需求。  <br/>对应人群行动建议：3C电子、汽车零部件企业可采用该类机器人完成精密装配，科研机构可探索空间感知与大模型的深度融合，推动技术升级。  <br/>机器人大模型的性能持续刷新纪录，RT-1端到端模型在可见任务上成功率达97%，未见任务上达76%，远超传统模型，这一优势让其在工业上下料、物流分拣等场景的替代成本降低40%，成为技术落地的核心支撑。</p><p>机器人大模型可见任务成功率阴影条形图图表数据及PDF模板已分享到会员群  <br/>3秒解读：RT-1模型在已知与未知任务中均表现优异，端到端架构成为产业主流选择。  <br/>对应人群行动建议：机器人本体厂商可优先采用端到端训练方案，终端企业可对比不同模型的场景适配性，选择性价比最优的技术方案。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047419068" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047419069" alt="" title="" loading="lazy"/></p><p>机器人大模型未见任务成功率条形图图表数据及PDF模板已分享到会员群  <br/>3秒解读：模型泛化能力成为场景落地关键，RT-1的迁移学习优势显著。  <br/>对应人群行动建议：中小企业可选择成熟模型二次开发，降低自研成本；大型企业可布局定制化模型研发，形成技术壁垒。</p><h3><a name="t4" target="_blank"/>三、生态合作与场景落地：从“单点试点”到“规模复制”</h3><p>中国具身智能的生态落地，遵循“场景先行、区域集聚、伙伴协同”的逻辑，从重点行业试点逐步走向全行业复制，形成“场景-技术-生态”的正向循环。  <br/>场景落地方面，协作机器人在汽车行业以40%的份额领跑，金属制品、电子行业紧随其后，这种分布与中国制造业结构高度契合。在汽车零部件场景，机器人完成变速箱螺栓拧紧、车灯螺钉锁付等任务，效率提升30%；在3C电子场景，精密涂胶、PCBA上下料检测等任务的自动化率已达60%，成为场景落地的标杆。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047419070" alt="" title="" loading="lazy"/></p><p>中国协作机器人行业应用分布横向条形图图表数据及PDF模板已分享到会员群  <br/>3秒解读：汽车行业是协作机器人最大应用场景，多元行业渗透加速产业规模化。  <br/>对应人群行动建议：机器人企业可优先深耕汽车零部件场景，再向电子、食品饮料行业拓展；行业解决方案商可开发垂直场景定制化产品，提升场景适配效率。  <br/>区域生态方面，以广东、北京、长三角为核心，集聚上下游企业形成产业集群。广东依托制造业基础，打造硬件供给生态；北京聚焦算法与本体研发，输出核心技术；长三角整合“芯片-算法-场景”资源，推动全链条落地，三大区域协同推动中国具身智能产业规模持续扩大，2024年协作机器人全球销售规模达6.8万台，预计2025年突破10万台。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047419071" alt="" title="" loading="lazy"/></p><p>全球协作机器人市场规模预测折线图图表数据及PDF模板已分享到会员群  <br/>3秒解读：十年间市场规模增长20倍，2025年将迎来规模化落地拐点。  <br/>对应人群行动建议：制造业工厂管理者可优先布局汽车、电子产线的协作机器人替代，创业者可聚焦细分场景的技术适配服务，把握产业爆发红利。  <br/>伙伴协同方面，形成“整机厂商+核心部件供应商+场景企业”的联创模式。整机厂商牵头整合技术，核心部件供应商突破硬件瓶颈，场景企业提供真实数据与落地场景，三方协同推动产品迭代，如富临精工与智元机器人合作，实现周转箱拆垛上料任务的24小时不间断作业，单班完成800余个周转箱搬运，全程零失误。</p><h3><a name="t5" target="_blank"/>四、产业影响与挑战：重构分工与突破瓶颈</h3><p>中国具身智能产业的快速发展，正重构全球机器人产业分工，同时也面临技术、成本、合规等多重挑战。  <br/>产业影响层面，中美形成差异化竞争格局：中国侧重硬件基础设施与工业场景落地，债权融资占比51.1%，核心部件国产化率达80%，协作机器人均价降低30%；美国聚焦数据与算法创新，股权融资占比81.5%，依赖本土高端部件供应商，成本高但技术溢价明显。这种差异源于中国制造业升级需求与美国技术创新导向的不同逻辑，形成互补性竞争。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047419072" alt="" title="" loading="lazy"/></p><p>中美具身智能融资对比分组条形图图表数据及PDF模板已分享到会员群  <br/>3秒解读：中美融资路径分化，中国强硬件、美国强软件，资本逻辑决定产业发展方向。  <br/>对应人群行动建议：硬件企业可对接中国债权融资，算法企业可寻求美国VC/PE支持，跨境合作可互补产业链短板，实现共赢。  <br/>成本突破方面，人形机器人的成本瓶颈正逐步破解，当前产品成本从27万美元到250万美元不等，本土企业通过国产化供应链将核心部件成本降低50%，预计2027年人形机器人成本可降至2-3万美元，满足规模化商用需求，推动产业从“高端定制”向“批量普及”转型。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047419073" alt="" title="" loading="lazy"/></p><p>人形机器人产品成本分析瀑布图图表数据及PDF模板已分享到会员群  <br/>3秒解读：人形机器人成本差异显著，国产化是降低成本的核心路径。  <br/>对应人群行动建议：整机厂商可加大核心部件国产化替代，资本可布局电机、减速器等国产替代企业，把握成本下降带来的投资机遇。  <br/>面临的挑战主要包括三方面：一是技术路线迭代风险，端到端与分层决策两条路线并存，可能导致前期投入作废，需采用模块化架构设计预留迭代接口；二是数据采集成本风险，真机数据采集效率低，可通过“仿真数据预训练+真机数据微调”模式降低成本；三是政策合规风险，机器人安全标准、数据隐私政策日趋严格，需提前对标ISO 10218-1:2025等国际标准，建立合规体系。</p><h3><a name="t6" target="_blank"/>五、差异化价值：中国的“产业底座+生态协同”优势</h3><p>中国具身智能的差异化价值，核心是“全球领先的制造业底座+高度协同的区域生态”，形成“技术可落地、成本可控制、生态可复用”的独特竞争力。  <br/>与美国相比，中国的优势在于“场景+供应链”双轮驱动：海量制造业场景为技术迭代提供了真实数据，完整的供应链支撑硬件成本持续降低，让具身智能能快速从技术验证走向规模化落地；与欧洲相比，中国的优势在于“生态协同+政策支持”，区域集聚效应降低了产业链整合成本，政策扶持加速了技术研发与场景推广。  <br/>这种差异化优势让中国在工业具身智能领域形成领先地位，未来有望通过“平台+标准”输出，推动全球具身智能产业的规范化发展，成为产业规则的制定者之一。</p><h4><a name="t7" target="_blank"/>核心数据对比表</h4><table><thead><tr><th>对比维度</th><th>中国</th><th>美国</th><th>差异原因</th></tr></thead><tbody><tr><td>融资结构</td><td>债权融资占比51.1%，侧重硬件</td><td>股权融资占比81.5%，侧重软件</td><td>中国产业成熟度高、重资产属性强；美国初创企业多、轻资产导向</td></tr><tr><td>产业链优势</td><td>硬件供应链、规模化交付、工业场景</td><td>算法创新、数据力、消费场景</td><td>中国制造业基础雄厚；美国AI技术积累深厚</td></tr><tr><td>核心部件自主化</td><td>电机、减速器等国产化率80%</td><td>依赖本土高端部件供应商</td><td>中国供应链完善；美国核心部件技术领先</td></tr><tr><td>机器人成本</td><td>协作机器人均价降低30%</td><td>成本高但技术溢价明显</td><td>中国规模化生产优势；美国技术研发投入大</td></tr></tbody></table><h4><a name="t8" target="_blank"/>可落地的3件事</h4><ol><li>制造业企业可联合机器人厂商开展“场景试点-数据积累-模型优化”的闭环合作，优先选择汽车零部件、电子装配等成熟场景切入，降低试错成本。</li><li>创业者可聚焦核心部件国产替代，重点布局一体化关节、灵巧手等短板领域，对接区域产业基金与政策支持，把握国产化红利。</li><li>技术团队可基于大小脑协同架构，开发垂直场景专用模型，通过“通用大模型+场景小模型”的组合模式，提升落地效率与场景适配性。</li></ol><h3><a name="t9" target="_blank"/>文末数据图表列表</h3><ol><li>全球协作机器人市场规模预测折线图</li><li>全球协作机器人地区分布圆环图</li><li>中国具身智能企业区域分布刻度线图</li><li>全球主要经济体制造业GDP对比灰底比例条形图</li><li>技能泛化与任务解决水平条形图</li><li>真实交互与环境适应性折线图</li><li>空间感知与推理能力雷达图</li><li>机器人大模型可见任务成功率阴影条形图</li><li>机器人大模型未见任务成功率条形图</li><li>中国协作机器人行业应用分布横向条形图</li><li>中美具身智能融资对比分组条形图</li><li>人形机器人产品成本分析瀑布图</li></ol><h2><a name="t10" target="_blank"/>本专题内的参考报告（PDF）目录</h2><ol><li>2025中国具身智能产业星图 报告2025-10-23</li><li>2025年全球协作机器人产业发展白皮书-具身智能时代的技术突破与产业重... 报告2025-10-15</li><li>基于具身智能的智慧工厂创新应用白皮书(2025) 报告2025-10-13</li><li>具身智能的基础知识 报告2025-10-05</li><li>2025年中国具身智能产业发展规划与场景应用洞察 报告2025-09-28</li><li>2025面向具身智能的大小脑模型协同算法研究及实践报告 报告2025-09-25</li><li>2025年面向具身智能的大小模型协同算法研究和实践报告 报告2025-09-22</li><li>面向具身智能的大小模型协同算法研究和实践 报告2025-09-15</li><li>机器人系列深度报告-具身智能大时代-算力芯片筑底座 报告2025-08-28</li><li>机器人大模型深度报告-我们距离真正的具身智能大模型还有多远？ 报告2025-08-10</li><li>2025具身智能产业发展趋势研究及安全威胁分析报告 报告2025-06-26</li><li>2025垂直领域具身智能机器人产业化落地现状及潜力应用场景分析报告 报告2025-06-24</li><li>2025大模型、Agent、具身智能及人形机器人学习全路径规划报告 报告2025-06-17</li><li>具身智能行业深度：技术路线、市场机遇、产业链及相关公司深度梳理 报告2025-06-03</li><li>人形机器人行业系列深度报告二-NVIDIA“大脑”能力齐备 具身智能浪... 报告2025-06-02</li><li>大模型时代的具身智能 报告2025-04-20</li><li>具身智能时代各本体公司最新进展 报告2025-04-06</li><li>2025年具身智能市场前景及投资研究报告 报告2025-04-05</li><li>创变下一浪：穿透具身智能与资本共振下的产业趋势 报告2025-03-18</li><li>大模型驱动的具身智能：发展与挑战 报告2025-02-03</li><li>2024具身智能科技前沿热点 报告2025-01-06</li><li>36氪研究院：2024年具身智能产业发展研究报告：大模型赋能，人形机器... 报告2024-10-22</li><li>维科网：2024年AI大模型推动新一代具身智能机器人产业发展蓝皮书 报告2024-09-04</li><li>维科网：2024年AI大模型推动新一代具身智能机器人产业发展蓝皮书 报告2024-08-31</li><li>中国信通院：具身智能发展报告（2024年） 报告2024-08-30</li><li>头豹：2024年中国具身智能行业研究-知行合一-拥抱AI新范式 报告2024-08-13</li><li>量子位智库：中国具身智能创投报告 报告2024-07-31</li></ol>]]></description></item><item>    <title><![CDATA[如何使用 PowerShell 脚本备份]]></title>    <link>https://segmentfault.com/a/1190000047418907</link>    <guid>https://segmentfault.com/a/1190000047418907</guid>    <pubDate>2025-11-21 20:06:02</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000045456444" alt="PowerShell Script Backup and Cleanup Windows Event Logs" title="PowerShell Script Backup and Cleanup Windows Event Logs"/></p><p>PowerShell 是一个强大的命令行工具，允许系统管理员可以自动执行许多日常任务，包括管理 Windows 事件日志。在这个脚本中，我们将创建一个 PowerShell 脚本将所有事件日志备份到指定位置，然后清除日志，以释放磁盘空间，提高系统性能。</p><h3>设置 PowerShell 环境</h3><p>在配置计划任务之前，请确保您的机器上安装了 PowerShell。</p><p>此外，您可能需要调整 PowerShell 的执行策略以允许脚本的执行。使用 administrative 权限打开 PowerShell 控制台，并执行如下命令：</p><pre><code>Set-ExecutionPolicy RemoteSigned</code></pre><p>这个命令允许执行本地创建的脚本和来自远程源的签名脚本。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047418909" alt="Powershell: Set-ExecutionPolicy RemoteSigned" title="Powershell: Set-ExecutionPolicy RemoteSigned" loading="lazy"/></p><h3>编写 PowerShell 脚本</h3><p>下面是一个 PowerShell 脚本，它将 Windows 事件日志备份到日期格式文件夹，并删除备份后的旧事件。此脚本假定您在机器上拥有管理权限。</p><pre><code># Set variables
$backupFolderPath = "C:\EventLogBackup"
$currentDate = Get-Date
$backupPath = Join-Path -Path $backupFolderPath -ChildPath $currentDate.ToString("yyyy-MM-dd")
$logNames = @("Application", "System", "Security")
$daysToKeep = 30
 
# Create backup directory if it doesn't exist
if (!(Test-Path -Path $backupPath)) {
    New-Item -Path $backupPath -ItemType Directory | Out-Null
}
 
# Backup event logs and clear them
foreach ($logName in $logNames) {
    $exportFileName = "$logName-$($currentDate.ToString("yyyy-MM-dd")).evtx"
    $exportFilePath = Join-Path -Path $backupPath -ChildPath $exportFileName
 
    # Export the log
    Write-Host "Exporting $logName to $exportFilePath"
    wevtutil epl $logName $exportFilePath
 
    # Clear the log
    Write-Host "Clearing $logName event log"
    wevtutil cl $logName
}
 
# Remove backups older than the specified days
Get-ChildItem -Path $backupFolderPath -Directory | Where-Object {
    $folderDate = [datetime]::ParseExact($_.Name, "yyyy-MM-dd", $null)
    ($currentDate - $folderDate).Days -gt $daysToKeep
} | Remove-Item -Recurse -Force
 
# Script end</code></pre><p>该脚本执行以下操作：</p><ul><li>设置要备份的事件日志的备份文件夹路径和名称。</li><li>如果备份尚不存在，则创建以日期命名的文件夹。</li><li>导出和清除指定的事件日志。</li><li>删除超过指定天数的备份文件夹。</li></ul><p>打开文本编辑器，粘贴以上内容，将脚本保存为 "BackupEventLogs.ps1"，请确保调整 "backupFolderPath"，"logNames"，"daysToKeep" 变量以适应您的需求。</p><h3>Execute PowerShell Script</h3><p>(1) 打开 PowerShell 终端</p><p>(2) 在 PowerShell 终端，切换到脚本所在目录</p><pre><code>cd C:\path\to\script\directory</code></pre><p>(3) 执行脚本</p><pre><code>.\BackupEventLogs.ps1</code></pre><h3>我的开源项目</h3><p><a href="https://link.segmentfault.com/?enc=5x4xIAJ17W6sfZFiV3Yusw%3D%3D.9R5jS0O1VKuqjNSGLxVU0%2Fb%2FLPMgRdzSmhtOHAS3krE%3D" rel="nofollow" target="_blank"><img referrerpolicy="no-referrer" src="/img/remote/1460000043302459" alt="酷瓜云课堂-在线教育解决方案" title="酷瓜云课堂-在线教育解决方案" loading="lazy"/></a></p><ul><li><a href="https://link.segmentfault.com/?enc=zbith8H8DDDFw4oELtVdNw%3D%3D.05EqVz9D%2F8ZMH7dfDapzL82LqgH6LvHYBya9%2F2RtXdhZTIbnE4pNtF0bgqUZD0uO" rel="nofollow" target="_blank">course-tencent-cloud（酷瓜云课堂 - gitee仓库）</a></li><li><a href="https://link.segmentfault.com/?enc=6gWPFMCm8xMCRlOEVqmIUQ%3D%3D.1zh9lL0eygMX2RFDHd7ZoyOPq%2FRFV%2BS3BasiHw3RrAKVx91z%2BOjJthXLYhawr1oqTyBl1ikYARmshpv42o%2FIZg%3D%3D" rel="nofollow" target="_blank">course-tencent-cloud（酷瓜云课堂 - github仓库）</a></li></ul>]]></description></item><item>    <title><![CDATA[如何安装 AxureRP-Setup.e]]></title>    <link>https://segmentfault.com/a/1190000047418920</link>    <guid>https://segmentfault.com/a/1190000047418920</guid>    <pubDate>2025-11-21 20:05:15</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>​</p><p> 很多产品经理、设计师、研发人员都用它来做<strong>线框图、原型演示、交互效果</strong>，不用写代码就能做出能点击、有逻辑跳转的页面原型。</p><h3>一、下载安装包</h3><p><strong>AxureRP-Setup.exe</strong>提供<strong>安装包下载：</strong><a href="https://link.segmentfault.com/?enc=Om16QLn3M%2Ffywt9ShPp9HQ%3D%3D.coKITUJlvVGhDHhj2s1PGVKpsF9fDd66iXUGBhHdgaPIylEAwCDUzWw3%2BeLbf%2FqX" rel="nofollow" title="https://pan.quark.cn/s/b82139190a01" target="_blank">https://pan.quark.cn/s/b82139190a01</a> ，这个就是安装程序，双击它就能开始安装。</p><h3>二、双击运行安装程序</h3><ol><li>找到电脑上的 <strong>AxureRP-Setup.exe</strong>文件（比如在下载文件夹里）。</li><li><strong>双击它</strong>，就会弹出安装向导窗口。</li></ol><h3>三、选择安装语言（一般默认就行）</h3><ul><li>通常会先跳出来一个语言选择窗口，比如有“中文（简体）”和“English”。</li><li>如果你想用中文，就选  <strong>“中文（简体）”</strong> ，然后点  <strong>“确定”</strong> 。</li><li>如果不选，默认可能是英文，也可以，不影响使用。</li></ul><h3>四、开始安装，点“下一步”</h3><ol><li>进入安装界面后，先看协议，一般直接点  <strong>“我接受”</strong> ，然后点  <strong>“下一步”</strong> 。</li><li><p>接下来会让你选择安装位置（就是这个软件要装到电脑哪个文件夹里）。</p><ul><li>默认路径一般是在 C 盘，比如：<code>C:\Program Files (x86)\Axure\Axure RP 10</code></li><li>如果你想改，可以点“浏览”选其他盘，比如 D 盘，但一般默认也行。</li></ul></li><li>选好位置后，点  <strong>“下一步”</strong> 。</li></ol><ul><li><ul><li>*</li></ul></li></ul><h3>五、选择是否创建桌面快捷方式</h3><ul><li>一般会问你是否创建桌面图标，建议勾选  <strong>“创建桌面快捷方式”</strong> ，这样以后找软件方便。</li><li>然后点  <strong>“下一步”</strong> 。</li></ul><h3>六、开始安装</h3><ul><li>确认信息无误后，点  <strong>“安装”</strong> 。</li><li>程序就会开始自动安装，等一会儿（大概几十秒到一两分钟，看电脑速度）。</li></ul><h3>七、安装完成</h3><ul><li>安装好后，会跳出提示说“安装完成”。</li><li>建议勾选  <strong>“运行 Axure RP”</strong> （如果你想安装完马上打开软件就用它）。</li><li>然后点  <strong>“完成”</strong> 就 OK 了！</li></ul><p>​</p>]]></description></item><item>    <title><![CDATA[估值 7 亿美元，Wispr 要做语音操]]></title>    <link>https://segmentfault.com/a/1190000047418928</link>    <guid>https://segmentfault.com/a/1190000047418928</guid>    <pubDate>2025-11-21 20:04:37</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047418930" alt="" title=""/></p><p><strong>开发者朋友们大家好：</strong></p><p>这里是 <strong>「RTE 开发者日报」</strong> ，每天和大家一起看新闻、聊八卦。我们的社区编辑团队会整理分享 RTE（Real-Time Engagement） 领域内「有话题的<strong>技术</strong>」、「有亮点的<strong>产品</strong>」、「有思考的<strong>文章</strong>」、「有态度的<strong>观点</strong>」、「有看点的<strong>活动</strong>」，但内容仅代表编辑的个人观点，欢迎大家留言、跟帖、讨论。</p><p><em>本期编辑：@鲍勃</em></p><h2>01 有话题的技术</h2><p><strong>1、MOSS-Speech：无需文本引导语音生成，实现了真「语音到语音」交互</strong></p><p>现有的端到端语音助手在生成阶段仍需要先生成文本作为「引导」，再生成语音，导致生成效率降低，生成的声音内容范围也受到文本瓶颈的限制。</p><p>MOSS-Speech 的发布标志着我们迈入了「真语音到语音交互」的新阶段。MOSS-Speech 不再需要预先生成文本引导语音生成，同时还保留了强大的推理能力，从而实现了真正的「语音到语音」交互。</p><p>MOSS-Speech 的部分 Demo 样例如下：</p><ul><li><strong>真正的语音到语音（Speech-to-Speech）大模型</strong></li></ul><p>MOSS-Speech 摆脱了传统级联方案（下图左）和需要生成文本指导后续语音生成的端到端方案（下图中）对于文本的依赖，实现了无需文本引导，直接理解并生成语音词符（下图右）。模型能够捕捉并生成语调、情绪、笑声等非文字要素，实现更自然、更高效的交流。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047418931" alt="" title="" loading="lazy"/></p><ul><li><strong>为高效模态对齐设计的新架构</strong></li></ul><p>MOSS-Speech 基于预训练文本 LLM，通过模态分层+两阶段预训练，让模型在继承文本 LLM 的推理能力与知识的同时，加入了原生的语音理解与生成能力，有效避免了模态冲突，实现了高效模态对齐。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047418932" alt="" title="" loading="lazy"/></p><ul><li><strong>双模态原生支持</strong></li></ul><p>不仅能「听懂」和「说出」语音，还处理文本输入输出，实现跨模态交互。支持语音提问 → 语音回答，文字提问 → 语音回答，语音提问 → 文字回答，文字提问 → 文字回答。</p><p>MOSS-Speech 在语音到语音评测指标上取得了 SOTA 成绩。</p><ul><li>预训练模型评测结果</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047418933" alt="" title="" loading="lazy"/></p><ul><li>指令微调模型评测结果</li></ul><p><img width="723" height="328" referrerpolicy="no-referrer" src="/img/bVdm7Zo" alt="image.png" title="image.png" loading="lazy"/></p><p>视频 Demo：<a href="https://link.segmentfault.com/?enc=jdxmmqwSyvi8tr4BsABnTA%3D%3D.rnjKSurZ55klXiBGG7LOnYK6tsiyDPkQgj5wLp2o8weHsW5l7A1ZXuUtfxVPi9%2FT" rel="nofollow" target="_blank">https://moss-speech.open-moss.com/</a></p><p>在线 Demo：<a href="https://link.segmentfault.com/?enc=fpBA9Y3Vfq26xV4jNN%2FarQ%3D%3D.mCn1cM0Pk%2FYQEBhVNvUsEPPOPCC13qOE5g0WcFs11yTCy4BmHHRwtDykjX7B4a2H" rel="nofollow" target="_blank">https://huggingface.co/spaces/fnlp/MOSS-Speech</a></p><p>GitHub 主页：<a href="https://link.segmentfault.com/?enc=SJPMNPoPYObeayry3DLflg%3D%3D.DFGp%2Bx7CzoPoVeYXQh194eKKRLdZbDhHP0tyxkQC4uI0F2KYwpPeRggnIC0kymdG" rel="nofollow" target="_blank">https://github.com/OpenMOSS/MOSS-Speech</a></p><p>技术报告：<a href="https://link.segmentfault.com/?enc=Gn2kEJtLBBdjan%2FdmjEwgg%3D%3D.ePscPZLcMlHO0nl%2FDGBl%2BRebTOf2U48gdaqKBBj8FF9HkNTZ%2FCIoFVbzDFnLBbWCXNIqNVBHZM4SRB%2FQe5CmtBbI8VRgwcgaZeRQhmch5IjOZdU7k0pJRqKbOZFqxXPx" rel="nofollow" target="_blank">https://github.com/OpenMOSS/MOSS-Speech/blob/main/papers/MOSS-Speech%20Technical%20Report.pdf</a></p><p>（@开放苔藓）</p><p><strong>2、Meta 宣布推出一个全新的模型家族 SAM 3D</strong></p><p>Meta 宣布推出一个全新的模型家族 SAM 3D，并发布两款 3D 模型，分别为用于物体和场景重建的<strong> SAM 3D Objects </strong>和用于人体和体型估计的<strong> SAM 3D Body</strong>。先来看看效果，SAM 3D 系列模型能在用户点击图像中的元素后，<strong>直接从 2D 图像中扣出一个 3D 模型</strong>，无论是物体还是人像，都能被准确重建。重建后的模型 360 度旋转，也基本看不出破绽。</p><p><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdm7Zk" alt="image.png" title="image.png" loading="lazy"/></p><p>SAM 的全称是 Segment Anything Model，直译过来就是「分割一切」模型。Meta 之前已经开源过 SAM 1、SAM 2 这两款 2D 图像分割模型，是该领域标杆作品。SAM 3D 系列模型发布的同日，此前在 ICLR 大会审稿期间就引发热议的 <strong>SAM 3 也迎来正式发布</strong> 。SAM 3 图像分割模型的亮点是引入了「<strong>可提示概念分割</strong>」的新功能。在过去，大部分图像分割模型只能根据有限的预设标签对图像进行分割，而 SAM 3 让用户可以输入「狗」、「大象」、「斑马」这样具体的标签，或「动物」这样的整体概念，甚至是「穿着黑色外套、戴着白色帽子的人」这样的描述，并完成图像分割，这大幅提升了图像分割模型的通用性。</p><p><img width="723" height="379" referrerpolicy="no-referrer" src="/img/bVdm7Zl" alt="image.png" title="image.png" loading="lazy"/></p><p>SAM 3 还具有超快的推理速度，在单张英伟达 H200 GPU 上，<strong>SAM 3 能在 30 毫秒左右识别一张包含超过 100 个可检测物体的图片。</strong> SAM 3 的发布，让英伟达开发者技术总结 Nader Khalil 直呼：「<strong>这可能就是计算机视觉的 ChatGPT 时刻</strong>，强大的分割功能意味着用户只要点击一下就能训练计算机视觉模型，太疯狂了。」</p><p><img width="723" height="701" referrerpolicy="no-referrer" src="/img/bVdm7Zm" alt="image.png" title="image.png" loading="lazy"/></p><p>Meta 已经直接拿 SAM 3D Objects 和 Sam 3 开始卖货了。Facebook Market 现在提供新的「房间视图」功能，让用户可在购买家具前直观地感受家居装饰品在空间中的风格和合适度。</p><p>目前，SAM 3D 系列模型和 SAM 3 都已经能在 Meta 最新打造的 Segment Anything Playground 中进行体验。SAM 3D 的训练和评估数据、评估基准、模型检查点、推理代码以及参数化人类模型都已经开源，SAM 3 开源了模型检查点、评估数据集和微调代码。</p><p><strong>SAM 3D 博客（内含论文、开源链接）：</strong></p><p><a href="https://link.segmentfault.com/?enc=YJSyZVp6MVlMaoN2wCObnQ%3D%3D.X3o9CjcMNR2oNp1qyRwPKKvLgAYXe1lqj7ralRz8Ku90Fkfe1rNPLmrjL%2FPYVPLw" rel="nofollow" target="_blank">https://ai.meta.com/blog/sam-3d/</a></p><p><strong>SAM 3 博客（内含论文、开源链接）：</strong></p><p><a href="https://link.segmentfault.com/?enc=hw%2BHeduhITjUM42E9ZrCqA%3D%3D.AIVKWVG0jQVMY2Ms%2FsF0xXwJxFYTGDeBPhRlkG2AN2WjxYC%2BmO9I8NGLuEOOkcXIt8jOeOh0sTIYv473igqMcw%3D%3D" rel="nofollow" target="_blank">https://ai.meta.com/blog/segment-anything-model-3/</a></p><p>（@智东西）</p><h2>02 有亮点的产品</h2><p><strong>1、语音笔记应用 Wispr 新融资估值达 7 亿美元，要做语音主导的操作系统</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047418934" alt="" title="" loading="lazy"/></p><p>不同留存时间段的 Wispr Flow 用户使用语音输入和键盘输入的比例</p><p>语音 AI 公司「Wispr」在其语音听写应用「Wispr Flow」取得高速增长后，再次获得由 Notable Capital 领投的 2500 万美元新融资，公司投后估值达到 7 亿美元。这笔融资距其上一轮融资仅过去数月，凸显了市场对高效语音输入工具的强劲需求，也标志着「Wispr」将加速自研模型和跨平台扩展，与「OpenAI」等巨头在人才和技术上展开竞争。</p><ul><li>强劲的资本势头与市场验证：继 6 月获得 3000 万美元融资后，「Wispr」迅速完成新一轮 2500 万美元融资，总融资额达 8100 万美元。知名投资人 Hans Tung（曾投资 Airbnb、Slack、Anthropic）将作为观察员加入董事会，证明了其商业模式和增长潜力已获顶级资本认可。</li><li>爆炸性的用户增长指标：自 6 月以来，「Wispr Flow」实现了 40% 的月度复合增长，用户基数同比增长 100 倍，并保持着 70% 的 12 个月用户留存率。在企业市场，其服务已触达 270 家财富 500 强公司，并以每周新增 125 家企业客户的速度扩张。</li><li>自研模型与技术护城河：为提升用户体验，「Wispr」正投入资源构建自有的个性化自动语音识别（ASR）模型。公司声称，其当前模型的错误率约为 10%，显著低于「OpenAI」的「Whisper」（27%）和苹果的原生转录（47%）。</li><li>从工具到平台的战略演进：「Wispr」的愿景不止于听写工具，而是成为一个『语音主导的操作系统』，旨在通过语音自动化工作流（如回复邮件）。公司正在通过封闭 API 与企业伙伴测试其技术，并计划明年向更广泛的开发者开放。</li><li>市场竞争格局：在听写和语音输入领域，「Wispr」面临包括 YC 支持的「Willow」和「Aqua」、Every 的「Monologue」、以及「Typeless」、「TalkTastic」、「Superwhisper」、「BetterDictation」在内的多家竞争对手。</li></ul><p>(@TechCrunch)</p><p><strong>2、Simbie AI：用 AI 语音智能体赋能小型医疗实践，重塑独立行医模式</strong></p><p>Simbie AI 推出一款与 EHR（电子健康记录）深度集成的 AI 语音智能体，专为中小型医疗实践设计。该解决方案旨在大幅提升运营效率，降低人力成本，让独立诊所能与大型医疗系统竞争。自 2025 年 1 月上线以来，Simbie AI 已实现 83 倍的营收增长，获客成本为零，并显著改善了诊所的医患沟通和营收状况。</p><ul><li><strong>AI 语音智能体赋能医疗运营：</strong> Simbie AI 开发了临床智能、全天候多语言的 AI 语音智能体，能够处理预约、保险咨询等行政任务，以及处方续订、结果告知、术后随访等临床沟通，极大减轻了人工负担。</li><li><strong>EHR 深度集成，构筑竞争壁垒：</strong> 该产品与广泛应用于 90% 独立实践的 EHR 系统建立了深度工作流程集成，提高了用户粘性，构筑了显著的切换成本。</li><li><strong>营收增长与成本优化：</strong> 自 2025 年 1 月上线以来，Simbie AI 实现了 83 倍的营收增长，且获客成本为零。它能帮助诊所将员工与医师的比例降低三分之一，并挽回因漏接电话（高达 20-40%）而损失的 10-20% 营收。</li><li><strong>医生主导，信任驱动的增长模式：</strong> Simbie AI 由医生和临床运营专家创立，通过建立医生领导者的信任，实现了零获客成本的病毒式传播，尤其在小型医疗实践群体中。</li><li><strong>支持独立行医运动：</strong> 在医生倦怠和医院整合趋势下，Simbie AI 提供的通信层解决方案，让独立诊所能够获得匹敌大型医院的运营效率，有力支持了医生选择独立行医的模式。</li></ul><p>(@Y Combinator)</p><p>3、<strong>豆包输入法正式版上线：内置情境感知引擎，支持中英文混合滑行输入</strong></p><p>11 月 21 日消息，豆包输入法 1.0 正式版现已上线，目前可在小米应用商店下载，内置情境感知引擎，支持滑行输入增强版，整体观感较为符合现代审美。 </p><p>据介绍，豆包输入法搭载情境感知引擎，可基于聊天场景自动切换词库，例如工作中可以自动联想专业术语，日常聊天则可以推荐表情包，还拥有「滑行输入增强版」，支持中英文混合滑行输入，号称可在 5.5 英寸的屏幕上实现每分钟 62 字的输入速度。 </p><p>经过实测后发现，该输入法目前基础功能较为完善，可选 9 键和 26 键两种布局，支持调整键盘高度，还带有语音转文字功能，但目前并没有切换方言语种按钮，实测显示该输入法可以识别出粤语，但是在转文字过程中存在错字现象。此外，该输入法还拥有智能输入、基础输入两种模式，其中前者会将部分输入信息、应用场景等传输至云端处理；而后者则不会收集任何个人信息，使用本地资源进行输入，但确实语音转文字、翻译等功能。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047418935" alt="" title="" loading="lazy"/></p><p>（@极客公园、IT 之家）</p><h2>03 有态度的观点</h2><p><strong>1、马斯克：实时视频的理解和生成是未来</strong></p><p>埃隆·马斯克在社交媒体上明确指出：「实时视频的理解与生成是未来。」</p><p>这一前瞻性观点与 xAI 此番发布的招聘信息高度契合。xAI 的「omni」团队正致力于打造超越文本界限的 AI 体验，旨在实现跨越图像、视频和音频等多模态的内容理解与生成。此次招聘的工程师将成为推动这一宏伟愿景实现的决定性力量，他们将深度参与实时视频和多模态世界模型的开发，覆盖数据处理、模型构建、训练优化、服务部署及产品化等全流程。</p><p>（@elonmusk\@X）</p><h2>04 社区黑板报</h2><p>招聘、项目分享、求助……任何你想和社区分享的信息，请联系我们投稿。（加微信 creators2022，备注「社区黑板报」）</p><p><strong>1、招聘实习生丨加入我们，共建 RTE 开发者社区</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047418936" alt="" title="" loading="lazy"/></p><p><strong>RTE 开发者社区·运营实习生（实时互动 / Voice AI 方向，本招聘长期有效）</strong></p><p><strong>地点：北京·朝阳区望京南/上海·杨浦区五角场</strong></p><p><strong>这份实习将给你带来：</strong></p><p><strong>产品与技术成长：</strong> 深入学习垂类 AI 产品从技术到落地的全生命周期，构建全面的产品视角。</p><p><strong>社区运营实战：</strong> 与高潜力的开发者和创业者深度交流，共同探索行业前沿；并亲身体验顶级 AI 大会，拓展行业视野。<em>*</em>*</p><p><strong>【你的职责】</strong></p><ol><li><strong>Voice AI / RTE 情报官：</strong> 每日关注 Voice AI /实时互动领域的最新动态，提炼整理并分享行业洞察，定期撰写学习笔记，帮助团队和社区保持信息前沿。</li><li><strong>社区连接者：</strong> 负责 RTE 领域开发者、初创企业等核心群体的社群运营，主动建立并深化联系，鼓励并协助他们融入社区，共同维护社区的活力与生态。</li><li><strong>活动协作者：</strong> 深度参与 RTE Open Day、Meetup、Dev Talk 等线上线下活动的全流程运营，包括前期策划、中期执行、后期复盘，从实践中提升组织和协调能力。</li><li><strong>行业洞察者：</strong> 协助开展 RTE 相关行业及应用场景调研、产品竞争力分析，整理相关资料，形成对业务的深入理解和独到见解。</li></ol><p><strong>【希望你】</strong></p><ol><li>本科及以上学历，商业、技术、产品、媒体专业或经验背景优先，具备良好英文能力；</li><li>对 RTE / Voice AI 有浓厚兴趣和求知欲；具备优秀的信息收集与整合能力，乐于快速学习新事物，并具备严谨的逻辑思维。</li><li>能保证每周至少 4 天的工作时间，持续 3 个月以上。</li></ol><p><strong>【薪资】</strong></p><p>180-220 元/天</p><p><strong>【投递方式】</strong></p><p>实习地点北京或上海，请将简历发送至 rtedevcommunity\@gmail.com ；邮件标题请注明：【社区运营实习-姓名-学校-毕业年份-到岗日期-城市】</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047418937" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047418938" alt="" title="" loading="lazy"/></p><p><a href="https://link.segmentfault.com/?enc=0VJyrqhI7TR1%2B0fn5Yq9Vw%3D%3D.nlVEbmeQ7BvDt2pfKy6Zu2Xq5J28B7yWe8hVXA4pZvE%3D" rel="nofollow" target="_blank">阅读更多 Voice Agent 学习笔记：了解最懂 AI 语音的头脑都在思考什么</a></p><p><strong>写在最后：</strong></p><p>我们欢迎更多的小伙伴参与 <strong>「RTE 开发者日报」</strong> 内容的共创，感兴趣的朋友请通过开发者社区或公众号留言联系，记得报暗号「共创」。</p><p>对于任何反馈（包括但不限于内容上、形式上）我们不胜感激、并有小惊喜回馈，例如你希望从日报中看到哪些内容；自己推荐的信源、项目、话题、活动等；或者列举几个你喜欢看、平时常看的内容渠道；内容排版或呈现形式上有哪些可以改进的地方等。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047418939" alt="" title="" loading="lazy"/><br/>作者提示：个人观点，仅供参考</p>]]></description></item><item>    <title><![CDATA[Mac 安装 JDK 8u281（JDK]]></title>    <link>https://segmentfault.com/a/1190000047418951</link>    <guid>https://segmentfault.com/a/1190000047418951</guid>    <pubDate>2025-11-21 20:03:45</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>​一、准备工作</p><ol><li><p><strong>下载文件</strong></p><p><strong>安装包下载：</strong><a href="https://link.segmentfault.com/?enc=ckRNl5L31Eq2bdeQz2JSCQ%3D%3D.1pjwAyk%2BvtpBQXEngnlRTS%2BMS9WoXPfBt1Iva2cMAf%2BF02lKW%2F1cj9qrp0s63vSn" rel="nofollow" title="https://pan.quark.cn/s/24c8755b74f0" target="_blank">https://pan.quark.cn/s/24c8755b74f0</a> ，下载了 <strong>JDK-8u281-1.dmg</strong>文件，它一般是个安装包。</p></li><li><p><strong>找到文件</strong></p><p>打开你的  <strong>“下载”文件夹</strong>，看看有没有这个 <strong>JDK-8u281-1.dmg</strong>文件。如果已经下载好了，就继续下一步。</p></li></ol><h3>二、开始安装</h3><ol><li><p><strong>双击打开 dmg 文件</strong></p><p>双击桌面上或者下载文件夹里的 <strong>JDK-8u281-1.dmg</strong>文件。</p><p>👉 它会自动解压并打开一个安装窗口（类似一个小盒子，里面有一些图标）。</p></li><li><p><strong>双击安装包（pkg 文件）</strong></p><p>在打开的窗口里，你会看到一个名字像  <strong>"jdk-8u281-macosx-x64.dmg" 内的 "JDK 8 Update 281.pkg"</strong> 这样的安装包（通常是蓝色的图标，名字里有 JDK 和 pkg）。</p><p>👉 双击这个 <strong>pkg 文件</strong>开始安装。</p></li><li><p><strong>按提示安装</strong></p><ul><li>系统可能会弹出提示，问你是否要打开这个应用，点  <strong>“打开”</strong> 就行。</li><li>接着会进入安装向导，点  <strong>“继续”</strong> →  <strong>“同意”</strong> （就是同意许可协议）。</li><li>选择安装位置（一般默认是系统盘，不用改），然后点  <strong>“安装”</strong> 。</li><li>可能会让你输入电脑密码（就是你开机登录用的那个密码），输入后点  <strong>“安装软件”</strong> 。</li></ul></li><li><p><strong>等待安装完成</strong></p><p>等个一两分钟，安装程序会自己搞定，最后会跳出一个  <strong>“安装成功”</strong> 的提示，点  <strong>“关闭”</strong> 就行。</p></li></ol><h3>三、检查是否安装成功（可选）</h3><p>想确认下 JDK 是不是真的装好了，可以这样看：</p><ol><li>打开  <strong>“访达” → “应用程序” → “实用工具” → “终端”</strong> （或者直接用 Spotlight 搜“终端”）。</li><li><p>在终端里输入以下命令，然后按回车：</p><pre><code>java -version</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000041378096" alt=" title=" title=" title="/></p><p>如果你看到类似这样的信息，里面有 <strong>1.8.0_281</strong>或者 <strong>Java(TM) SE Runtime Environment (build 1.8.0_281...)</strong> ，那就说明安装成功啦！</p><p>如果你看到的是别的版本，比如 Java 17 或没有信息，那可能还需要设置一下环境变量，不过一般用 IDE（比如 Eclipse、IntelliJ IDEA）时会自动找到。</p></li></ol><p>​</p>]]></description></item><item>    <title><![CDATA[CrewAI 上手攻略：多 Agent ]]></title>    <link>https://segmentfault.com/a/1190000047418956</link>    <guid>https://segmentfault.com/a/1190000047418956</guid>    <pubDate>2025-11-21 20:03:09</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>CrewAI是一个可以专门用来编排<strong>自主 AI 智能体（Autonomous AI Agents）</strong> 的Python 框架，你可以把它理解为在代码层面组建一个“虚拟团队”，给每个 Agent 分配特定的角色、目标，让它们协同处理那些单个 LLM 搞不定的复杂任务。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047418958" alt="" title=""/></p><h2>CrewAI 介绍</h2><p>CrewAI 包含以下组件：</p><p><strong>Agents</strong> 是具体的执行实体，有角色设定和能力边界；<strong>Tasks</strong> 是具体的任务指令；<strong>Crews</strong> 是把“人”和事儿撮合到一起的团队容器；<strong>Tools</strong> 则是 Agent 手里的工具（比如搜索、读文件、调 API等等）；<strong>Processes</strong> 决定了活儿怎么干，比如说是大家排队干（顺序）还是层级汇报（层级）。</p><p>CrewA最适合的是那种<strong>链条长、环节多</strong>的工作流。比如你要搞个深度研报，需要先全网搜集信息，然后整理分析，写初稿，最后润色发布，这种“研究-写作-编辑”的流水线就非常契合。同理商业竞品分析、代码开发流程（设计-编码-测试）或者分工明确的客户支持系统，都是它的强项。</p><p>但有几种情况别用：</p><p>如果你的任务简单到一次 LLM 调用就能解决，用 CrewAI 就没有必要了而且还会增加复杂度和成本。对实时性要求极高的场景（比如毫秒级响应）也不合适，因为多 Agent 交互本来就慢。还有那种每一步都得让人盯着确认的流程，这种流程自动化程度太低也没必要上 Agent 编排。</p><h2>安装与配置</h2><p>环境准备很简单，基础包装上就行，如果需要额外的工具集，就把 tools 加上。</p><pre><code> # Install CrewAI  
 pip install crewai crewai-tools
 
 # For additional tools  
 pip install 'crewai[tools]'</code></pre><h2>基础示例：搭建内容创作团队</h2><p>下面这段代码展示了如何把 Research Analyst（研究员）、Content Writer（撰稿人）和 Editor（编辑）这三个角色串起来。代码逻辑很简单：定义 Agent，定义 Task，最后塞进 Crew 里跑起来。</p><p>*注意观察</p><pre><code>context</code></pre><p>参数，它实现了任务间的数据流转。*</p><pre><code> from crewai import Agent, Task, Crew, Process  
from crewai_tools import SerperDevTool, WebsiteSearchTool

# Initialize tools  
search_tool = SerperDevTool()  
web_tool = WebsiteSearchTool()

# Create Agents  
researcher = Agent(  
    role='Research Analyst',  
    goal='Gather comprehensive information on {topic}',  
    backstory='You are an expert researcher with a keen eye for detail and accuracy.',  
    tools=[search_tool, web_tool],  
    verbose=True,  
    allow_delegation=False  
)

writer = Agent(  
    role='Content Writer',  
    goal='Create engaging, well-structured content about {topic}',  
    backstory='You are a skilled writer who transforms research into compelling narratives.',  
    verbose=True,  
    allow_delegation=False  
)

editor = Agent(  
    role='Editor',  
    goal='Refine and polish content to ensure quality and clarity',  
    backstory='You are a meticulous editor with an eye for grammar, style, and flow.',  
    verbose=True,  
    allow_delegation=False  
)

# Define Tasks  
research_task = Task(  
    description='Research {topic} and gather key facts, statistics, and insights.',  
    expected_output='A comprehensive research report with sources',  
    agent=researcher  
)

writing_task = Task(  
    description='Using the research, write a 500-word blog post about {topic}',  
    expected_output='A well-written blog post in markdown format',  
    agent=writer,  
    context=[research_task]  # Depends on research task  
)

editing_task = Task(  
    description='Edit the blog post for grammar, clarity, and engagement',  
    expected_output='A polished, publication-ready blog post',  
    agent=editor,  
    context=[writing_task]  
)

# Create Crew  
crew = Crew(  
    agents=[researcher, writer, editor],  
    tasks=[research_task, writing_task, editing_task],  
    process=Process.sequential,  # Tasks run in order  
    verbose=True  
)

# Execute  
result = crew.kickoff(inputs={'topic': 'Artificial Intelligence in Healthcare'})  
 print(result)</code></pre><h2>进阶示例：软件开发</h2><p>对于更复杂的场景，比如软件开发，可能需要引入<strong>层级流程（Hierarchical Process）</strong>。这时候会有一个隐藏的 Manager Agent（通常用更强的模型如 GPT-5）来统筹分配任务，而不是简单的线性执行。</p><pre><code> from crewai import Agent, Task, Crew  
from crewai_tools import FileReadTool, CodeInterpreterTool

# Tools  
file_tool = FileReadTool()  
code_tool = CodeInterpreterTool()

# Agents with specific expertise  
architect = Agent(  
    role='Software Architect',  
    goal='Design scalable software architecture for {project}',  
    backstory='Senior architect with 15 years of experience in system design.',  
    verbose=True  
)

developer = Agent(  
    role='Python Developer',  
    goal='Write clean, efficient Python code',  
    backstory='Expert Python developer focused on best practices.',  
    tools=[code_tool],  
    verbose=True  
)

qa_engineer = Agent(  
    role='QA Engineer',  
    goal='Ensure code quality through comprehensive testing',  
    backstory='Detail-oriented QA engineer specializing in test automation.',  
    tools=[code_tool],  
    verbose=True  
)

# Tasks  
design_task = Task(  
    description='Design architecture for a {project} including component breakdown',  
    expected_output='Detailed architecture document with diagrams',  
    agent=architect  
)

development_task = Task(  
    description='Implement the core functionality based on the architecture',  
    expected_output='Working Python code with documentation',  
    agent=developer,  
    context=[design_task]  
)

testing_task = Task(  
    description='Write and execute unit tests for the developed code',  
    expected_output='Test suite with coverage report',  
    agent=qa_engineer,  
    context=[development_task]  
)

# Hierarchical process with manager agent  
dev_crew = Crew(  
    agents=[architect, developer, qa_engineer],  
    tasks=[design_task, development_task, testing_task],  
    process=Process.hierarchical,  # Manager coordinates tasks  
    manager_llm='gpt-4',  # Manager uses GPT-4  
    verbose=True  
)

 result = dev_crew.kickoff(inputs={'project': 'RESTful API for task management'})</code></pre><h2>进阶功能：异步、人工介入与结构化输出</h2><p>如果你追求性能，<strong>异步执行（Asynchronous Execution）</strong> 是一个可选项，特别是 IO 密集型任务。</p><pre><code> # Run crew asynchronously for better performance  
 result = await crew.kickoff_async(inputs={'topic': 'AI trends'})
 
 # Run specific tasks in parallel  
 from crewai import Task  
 task1 = Task(description='Research topic A', agent=researcher, async_execution=True)  
 task2 = Task(description='Research topic B', agent=researcher, async_execution=True)</code></pre><p>有些关键节点不能完全信赖 AI，这时候开启 <strong>Human-in-the-Loop</strong>，Agent 执行到一半会停下来问你要反馈。</p><pre><code> agent = Agent(  
     role='Decision Maker',  
     goal='Make strategic decisions',  
     human_input=True  # Will prompt for human feedback  
 )</code></pre><p>工程化最头疼的是输出格式不可控，CrewAI 支持 Pydantic 模型，强制 Agent 输出结构化数据，这对后续的数据清洗非常有帮助。</p><pre><code> from crewai import Task  
from pydantic import BaseModel

class BlogPost(BaseModel):  
    title: str  
    content: str  
    tags: list[str]

task = Task(  
    description='Write a blog post',  
    expected_output='Blog post with title and tags',  
    agent=writer,  
    output_json=BlogPost,  # Structured output  
    output_file='output.json'  # Save to file  
 )</code></pre><h2>生态与集成</h2><p>官方内置了一堆工具库，覆盖了搜索（Google/Serper）、文件操作（File/Directory Read）、代码执行（CodeInterpreter）以及各种数据源（PDF, CSV, JSON, GitHub, YouTube）的读取。</p><p>模型支持方面利用了 LangChain 的生态，OpenAI, Anthropic, Google Gemini 都能切。想省钱或者数据敏感，用 Ollama 跑本地模型（Llama 3, Mistral）也没问题。</p><h2>CrewAI vs 其他</h2><p>经常有人问它和 <strong>AutoGen</strong> 的区别。简单说CrewAI 像是管理严密的正规军，强调角色（Role）和流程（Process）；AutoGen 更像是一个聊天室，Agent 之间通过对话来解决问题，更灵活但也更难控制。至于 <strong>LangGraph</strong>，那是更底层的图编排工具，控制粒度极细，但上手门槛高。你可以理解为CrewAI 是在 LangChain 之上做了很好的封装，用起来简单。</p><h2>补充规划、记忆与安全</h2><p>新版本（0.30+）加入了 <strong>Planning Mode</strong>，Agent 开干前会先生成个计划书（现在Agent基本上都会有计划了）。记忆系统也升级了：支持短期记忆（本次执行内）、长期记忆（跨执行持久化）甚至实体记忆（记住具体的人和事）。</p><p>如果你需要监控整个 Crew 的运行状态，可以开启 Telemetry，导出 JSON 格式的日志做分析。</p><h2>总结</h2><p>CrewAI 在处理<strong>角色分工明确、流程复杂的知识型工作</strong>时表现非常出色。如果你是初学者：先别整太复杂的流程，2-3 个 Agent 起步，把目标定死，用 Pydantic 锁死输出格式，把缓存开起来。等熟悉了 Agent 的操作，再上复杂的层级结构和记忆系统。</p><p><a href="https://link.segmentfault.com/?enc=34RVSTWAeZScArwnshUv%2BQ%3D%3D.vPXyvR5W5US44JxlR4nyGKdHJo0pnUtzX3Ei%2Bb7O8g83Q5FYHMiA5T6IhVxQ0bNPWV7cm0kZAU5boBbNkRXGSw%3D%3D" rel="nofollow" target="_blank">https://avoid.overfit.cn/post/03c0bdbc21254d52b80f170a0fa2c567</a></p>]]></description></item><item>    <title><![CDATA[防止企业邮箱被盗：5个实用安全技巧分享 ]]></title>    <link>https://segmentfault.com/a/1190000047418977</link>    <guid>https://segmentfault.com/a/1190000047418977</guid>    <pubDate>2025-11-21 20:02:17</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在企业日常运营中，企业邮箱的安全性至关重要。然而，弱密码、钓鱼攻击、系统漏洞等因素常常导致企业邮箱被盗，给企业带来严重损失。本文将深入剖析企业邮箱被盗的原因，介绍Zoho Mail在安全防护方面的优势，并提供实用的企业邮箱账号安全建议。<br/><img width="723" height="443" referrerpolicy="no-referrer" src="/img/bVdm70k" alt="" title=""/></p><h2>一、企业邮箱被盗的原因</h2><h2>弱密码漏洞</h2><h2>常见弱密码类型及风险</h2><p>许多企业邮箱被盗源于弱密码，像“123456”、公司名英文字母这类简单密码，极易被黑客猜测或通过字典破解。一旦密码被破解，企业敏感信息将暴露无遗，甚至可能导致业务中断。</p><h2>密码暴力破解手段</h2><p>攻击者会借助自动化工具进行海量密码尝试。若企业全员使用过于简单或相同格式的密码，邮箱账户就极易沦陷。</p><h2>网络钓鱼攻击</h2><h2>钓鱼邮件的特征与识别</h2><p>钓鱼邮件常常伪装成供应商、客户或内部通知，诱导用户点击仿真的登录页面，进而输入账号密码。员工若缺乏警觉，很容易上当受骗。</p><h2>员工安全意识不足</h2><p>内部员工若缺乏定期的信息安全培训，自主防护能力就会较弱。频繁在公共设备、弱保护网络下登录邮箱，会大大增加邮箱被盗的风险。</p><h2>系统安全漏洞</h2><h2>邮箱系统自身漏洞</h2><p>陈旧的企业邮箱系统若未及时更新，可能存在后门。攻击者会利用零日漏洞绕过防御，获取账户权限。</p><h2>第三方插件或服务风险</h2><p>部分用于邮箱管理的“外挂”插件或第三方自动化工具，安全性难以保障，容易被攻击者利用来窃取数据。</p><h2>内部人员风险</h2><h2>员工离职后账号管理漏洞</h2><p>离职员工邮箱若未及时销号或更换密码，遗留的通道就可能成为恶意操作的隐患。</p><h2>内部人员恶意操作</h2><p>极少数内部人员可能因工作矛盾等因素，利用权限泄露或篡改邮箱信息，导致企业信息泄露。</p><h2>二、Zoho邮箱的安全优势</h2><h2>强大的密码保护机制</h2><h2>多因素认证功能</h2><p>Zoho Mail为所有账户提供双重甚至多因素认证，如手机、App动态码等。即使密码泄漏，账户也难以被入侵。</p><h2>强密码策略与定期更新提醒</h2><p>系统强制要求设置高复杂性密码，并定期强制更换。同时，通过后台提醒推送，降低长期未更换密码的风险。</p><h2>先进的反钓鱼技术</h2><p>智能识别与拦截钓鱼邮件<br/>Zoho Mail采用国际领先的AI安全算法，主动识别钓鱼邮件、仿冒域名和风险链接，将其隔离或直接拦截。</p><h2>邮件安全培训与模拟钓鱼测试</h2><p>平台为企业用户提供邮件安全培训材料，支持模拟钓鱼攻防演练，有效提升员工警觉性，防范社会工程学攻击。</p><h2>全方位的系统安全防护</h2><p>定期安全更新与漏洞修复<br/>Zoho通过全球多地服务器部署，可及时推送更新并修补已知安全风险，使整体系统长年保持高安全水准。</p><h2>数据加密与备份保障</h2><p>所有邮件内容均加密传输与存储，支持端到端加密和多地实时备份。在灾难场景下，可极速恢复数据。</p><h2>完善的账号管理与监控</h2><h2>精准的权限控制</h2><p>管理员可为每一邮箱自定义访问权限，细粒度控制员工查阅或操作界限，防止内部泄密。</p><h2>异常登录行为实时告警</h2><p>Zoho Mail具备实时登录行为监控功能，发现异地、多次尝试等异常登录行为时，会自动告警并触发锁定。</p><h2>三、企业邮箱账号安全实用建议</h2><h2>强化密码管理</h2><p>设置包含数字、大小写字母、特殊字符的高强度复杂密码，并定期更换。同时，切勿多处使用同一套密码，避免一处泄漏引发连锁危机。</p><h2>提高员工安全意识</h2><p>定期组织信息安全培训，模拟钓鱼邮件测试，提高员工辨别钓鱼和僵尸网络的能力。明确邮件日常安全操作规范，禁止在公共设备留存登录信息。</p><h2>选择安全可靠的邮箱服务</h2><p>对于外贸或国际通信场景，建议直接选择Zoho企业邮箱。其全球服务器布局确保海外邮件收发始终高可用。注册Zoho Mail只需几步，注册步骤清晰，支持域名邮箱、自定义管理后台，方便快速部署。对订单、大附件、归档、CRM集成等关键功能均有完整原生支持，省心省力。</p><h2>加强账号监控与管理</h2><p>企业应定期审查各账号授权与访问权限，对离职员工及时停用、注销邮箱账号，防止“僵尸账户”带来隐患。利用Zoho Mail的异常登录监控与自动告警系统，发现异常即刻锁定，保护企业数据安全。</p><h2>四、Zoho Mail与主流企业邮箱对比</h2><p>特性    Zoho Mail企业邮箱    X腾讯企业邮<br/>全球服务器    √ 多地，稳定海外收发    × 部分地区覆盖，海外受限<br/>邮件加密、安全加固    √ 全量加密+AI识别    √，部分支持<br/>多因素认证    √ 支持OTP与App    部分支持（短信为主）<br/>反垃圾、反钓鱼    √ AI智能+全局黑名单    √，侧重本地规则<br/>价格方案灵活    √ 多样按需付费    √，大客户优先<br/>域名邮箱设置    √ 简洁/详细新手教程    √，部分自动优化<br/>注册步骤    √ 一目了然3分钟上手    通常较快<br/>CRM及第三方集成    √ 原生CRM、多平台对接    需手动添加或付费<br/>客服支持/语言    √ 24h多语种支持    中文为主<br/>Zoho邮箱现已服务于1800万企业级客户，在全球邮件服务排名前三，深受外贸、中大型及成长型企业信赖。选择Zoho Mail，为企业邮箱安全保驾护航！</p>]]></description></item><item>    <title><![CDATA[Outlook vs Gmail：202]]></title>    <link>https://segmentfault.com/a/1190000047418988</link>    <guid>https://segmentfault.com/a/1190000047418988</guid>    <pubDate>2025-11-21 20:01:22</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在外贸业务蓬勃发展的当下，企业邮箱作为企业沟通与业务拓展的重要工具，其安全性、稳定性以及是否专为外贸场景优化，都直接影响着企业的运营效率和信息安全。本文将深入探讨如何选择适合外贸业务的企业邮箱，并详细介绍 Zoho Mail 企业邮箱的优势与特点。<br/><img width="723" height="443" referrerpolicy="no-referrer" src="/img/bVdm70w" alt="" title=""/></p><h2>一、核心对比：Outlook、Gmail 与 Zoho 邮箱基础功能</h2><h2>收发邮件效率与操作体验</h2><p>Outlook 和 Gmail 都是全球主流的邮箱服务，但对于高频进行国际沟通的企业客户而言，Zoho Mail 展现出了更高的稳定性。Zoho 企业邮箱基于全球海外服务器部署，确保外贸邮箱无需担忧国际邮件丢失或延迟问题，邮件收发稳定且流畅。同时，它支持 Webmail、移动 APP 及 IMAP/POP 协议登录，能充分满足不同办公场景的需求。</p><h2>界面简洁性与多端兼容性</h2><p>Gmail 以简洁的界面设计著称，Outlook 则强调“信息中心”的整合体验。而 Zoho 邮箱的界面中英文切换自如，邮箱、日历、任务、联系人高度一体化，并且可与 PC、Mac、iOS、Android 等多终端实现无缝同步。在国际邮件和大附件发送方面，Zoho 邮箱的操作更为友好，能轻松应对商务需求。</p><h2>邮箱扩展功能对比（如日历、联系人、任务）</h2><p>三大邮箱均配备了日历、任务、联系人等常见的办公组件。不过，Zoho Mail 的优势在于深度整合了 Zoho 生态工具，如 CRM、文档协作、Zoho Meeting 等。此外，企业关注的大附件功能（支持最大 1G 单文件）、邮件归档、邮件查找、团队协作空间等，在 Zoho Mail 中均已成为标配功能。</p><h2>二、国内使用体验对比</h2><h2>国际邮件通畅性：谁能稳定收发国际邮件？</h2><p>Gmail 时常受到国内网络环境的限制，而 Outlook 部分海外节点也存在不稳定的情况。相比之下，Zoho Mail 自建全球多点服务器，专为国内企业出海和外贸沟通设计，能够确保国际邮件实时直达，海外邮件收发不受任何限制。</p><h2>访问速度与网络环境适配</h2><p>Zoho 企业邮箱配备了本地与海外双数据中心，即便在出口带宽波动的情况下，也能保障企业稳定收发邮件，其访问速度在同类产品中处于领先地位。</p><h2>本地化服务与中文支持</h2><p>Gmail 和 Outlook 在国内客户支持和本地化服务方面存在明显短板。而 Zoho Mail 拥有全面的中文后台界面、本地客服以及专属迁移团队辅导，能够保障企业有序切换并获得持续支持。</p><h2>三、安全保障与用户服务</h2><h2>数据加密与隐私政策</h2><p>Zoho Mail 对用户邮件内容和附件内容进行全程加密存储与传输，符合 GDPR 等国际隐私标准。它支持多因子身份验证（2FA），能够主动防止账户被盗和数据泄露。同时，邮件加密和反钓鱼实时监测功能，为企业的信息安全增添了一道保险。</p><h2>垃圾邮件防护和安全措施</h2><p>Zoho 企业邮箱具备智能反垃圾邮件网关、病毒过滤、反钓鱼技术，并结合机器学习不断优化识别率。在保障国内外收发无障碍的同时，最大限度地减少垃圾邮件和风险邮件对企业造成的损害。</p><h2>售后服务对比——Zoho 邮箱的本地化支持优势</h2><p>Outlook 和 Gmail 主要依赖国外服务商，遇到本地化问题时响应周期较长。而 Zoho Mail 为中国及海外市场均提供快速本地支持，从初始对接、注册步骤、数据迁移到日常维护，提供全流程无忧服务。此外，Zoho 邮箱在全球拥有 1800 万企业级客户，跻身全球邮箱市场前三。</p><h2>四、费用、容量及适用人群分析</h2><p>免费与付费功能差异<br/>Gmail 和 Outlook 均提供有限免费版，但对于专业企业需求，通常需要付费。Zoho Mail 则提供灵活的套餐选择，轻量版本支持 5 用户，低至一年 60 元一用户，且提供充足存储空间；付费后可解锁更多容量以及如邮件归档、法律合规等高级功能。</p><h2>存储容量与附件上传限制</h2><p>Zoho 企业邮箱提供 30GB/用户起步的存储空间，支持企业邮箱大附件（单附件最大 1G），而 Gmail 和 Outlook 均存在一定限制。并且，Zoho 邮箱的邮件归档功能不额外收费，便于企业数据保存与追溯。</p><h2>个人、企业、团队用户推荐——Zoho 邮箱场景更广泛</h2><p>对于个人、外贸初创和小型团队来说，Zoho Mail 的易用性与灵活性兼具。对于中大型企业，它可通过自定义安全策略、多人协作、CRM 集成等功能满足更高标准。同时，支持域名邮箱批量创建和集中管理，能够有效降低 IT 负担。</p><h2>五、多维度对比表</h2><p>对比项    Zoho Mail    Gmail    Outlook<br/>支持全球服务器/国际收发    支持，自建全球    有，部分受限    有，部分受限<br/>域名邮箱管理    全面支持    支持（需 G Workspace）    支持（需微软 365）<br/>反垃圾邮件/反钓鱼    智能防护    基础防护    基础防护<br/>移动办公    全平台 App    全平台 App    全平台 App<br/>邮件加密    支持    Gmail Confidential    Outlook 加密<br/>本地化服务/中文支持    高度本地化    基本无    基本无<br/>注册步骤（易用性）    一键快速、全流程    相对复杂    相对复杂<br/>邮件归档/团队协作    高级支持    支持    支持<br/>企业邮箱适配（中小/大型）    全场景覆盖    偏小团队    偏中大型<br/>价格策略    免费 + 多档付费    免费/Google One    免费/微软 365<br/>本地外贸业务适配    优秀    一般    一般</p><h2>六、常见问题及答疑</h2><h2>为什么选择 Zoho 邮箱更适合国内用户？</h2><p>Zoho Mail 专为中国企业出海和外贸业务进行了优化，能够保障海外邮件收发稳定。它支持中文管理后台和本地化客户支持，企业切换门槛低，且所有邮件存储在全球主流安全标准基础设施中，数据隐私有充分保障。</p><h2>如何迁移现有邮箱（Outlook/Gmail）到 Zoho 邮箱？</h2><p>Zoho 提供一站式迁移工具和中文迁移顾问，支持主流邮箱（Outlook、Gmail 等）邮件历史批量无缝导入，无需中断业务。详细注册步骤可参见 Zoho 官方网站或咨询本地技术支持。</p><h2>Zoho 邮箱能否畅通收发国际邮件？</h2><p>Zoho 企业邮箱拥有全球多点服务器和稳定国际专线，能让外贸企业的国际邮件随时畅通，海外业务无障碍。无论是跨境收发还是团队协作，都能保持高效率和安全可靠。</p><p>通过全面对比可以发现，无论是在安全加密、反垃圾邮件、国际邮件畅通性、价格弹性还是本地化服务方面，Zoho Mail 企业邮箱都已成为中大型企业和外贸团队的首选。立即体验便捷注册步骤，启用专属域名邮箱，为您的企业业务插上全球化、数字化的翅膀。</p>]]></description></item><item>    <title><![CDATA[鸿蒙美食元服务解决方案：全场景创新体验，]]></title>    <link>https://segmentfault.com/a/1190000047418585</link>    <guid>https://segmentfault.com/a/1190000047418585</guid>    <pubDate>2025-11-21 19:09:16</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>★ 一键直达 <a href="https://link.segmentfault.com/?enc=nVb%2FXbqRgClTtdpGTMpkJQ%3D%3D.kSiRVbAncYpDiY5Cmf7w4o157EgYZ9ZCGXd3GOLqc2Q0HPSpyM9AKPIlPLNaqxDageMWPlTro47dzRW%2Frou4OMG1ATeu93fDWCiwOtrkcUfZZ3g%2F8WZaFP4hNrGsXZ3%2BX8UDOqnOqNktrIqV%2Fe9vGDFQmMmmb6EMuwlGfuajiQLbTb1KyEesrxD9IOeGupy6" rel="nofollow" target="_blank">HarmonyOS 行业解决方案</a> ★<br/>★ 快速访问 <a href="https://link.segmentfault.com/?enc=gChgipVyEbZXo1LAKkK8VA%3D%3D.JRpLCcfHIHtmbYD2D5OEXybLnV3bx%2Bf6c9bStkU6l%2BMo9owa%2FGAoVt9wuI%2Fc%2BEtq7BCGqsOkcDPhhmC7e9dWEZEoAQv6H62lR%2BcPd6qEY0u73jZZLfVn5zvy7KHfMNTmVWdzgXr%2FN1lNKyRA%2B%2BMea0CFsBy1%2FoSAR0%2BWHlSA6cg52JVfra4K9RiTLjLSHxjl" rel="nofollow" target="_blank">美食行业解决方案</a> ★</p><p>还在忍受传统餐饮服务的低效与繁琐？华为鸿蒙美食行业元服务解决方案，以多项创新开放能力为核心，从用户交互到服务体验完成全链路升级，让餐饮消费更便捷、更智能！</p><p>依托鸿蒙生态核心技术，这套方案打造了覆盖全场景的智慧服务闭环。近场服务能精准感知用户位置，靠近门店即推送个性化推荐，让潜在客流快速转；AirTouch碰一碰技术打破传统点单局限，无需打开支付码，轻轻一碰就能完成点餐支付，大幅缩短消费链路；扫码直达功能跳过冗余操作，一键点餐、取号、查菜单等核心服务；</p><p>更值得关注的是，头部品牌早已抢先入局！海底捞借助鸿蒙智能体实现门店查询、订座排号、菜品搭配一体化服务；通过扫码直达，实现系统扫一扫入口，扫码直接拉起元服务进行点餐，同时结合融合码能力，做到无需更换门店原有点餐码，即可适配拉起元服务端；通过服务动态能力，实现排队进度实时同步，让用户告别焦虑。</p><p>奈雪的茶通过AirTouch碰一碰点单+近场地图推荐，搭配服务动态实时更新取餐状态，大幅提升点单效率和用户体验。</p><p><img width="723" height="407" referrerpolicy="no-referrer" src="/img/bVdm7TX" alt="image.png" title="image.png"/></p><p>想让你的应用也拥有以上的创新能力吗？点击链接获取HarmonyOS美食行业解决方案，让你的餐饮业务在数字化浪潮中抢占先机！【快速访问：<a href="https://link.segmentfault.com/?enc=SxfpHSwoMCcVB2LM%2B1kkPg%3D%3D.%2FKq54FAjF4M8L7htv6U9Z3WZOMLXbk2cplfuzItslxPKy8W7TCHM0E294M57R3S5V0TH%2FlovzIrq6Mvxyt2yYwsxYGmX26NSMd1y3bs760nL%2BjitkfyCxoXbF6J7ywAS8au2uXePrhVZkCcDCR26vKWdTdIP4tbY8CtoGiPbIKjdZHpCAynk%2FEEmS33wWcy7" rel="nofollow" target="_blank">美食行业解决方案</a>】</p>]]></description></item><item>    <title><![CDATA[鸿蒙社交交友行业解决方案：全链路赋能社交]]></title>    <link>https://segmentfault.com/a/1190000047418641</link>    <guid>https://segmentfault.com/a/1190000047418641</guid>    <pubDate>2025-11-21 19:08:42</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>★ 一键直达 <a href="https://link.segmentfault.com/?enc=7AbSefmUerws6E%2FlQFRe8g%3D%3D.%2BPNSrzFv4QaZQPnHWKkxhunxMHd9cajhrfBztVNMxcDZsNNkA2jR0bqmvzRsdFIjtQhBQu8AuXggzVJnQDmwRx7qeLrVtgALmPGA%2FM3H6GKgmWkYtOnPkj5w7ZhT8A%2F9TOmBGyvIVBgV%2BqB206VzopLQgrMEMcc4c5fAczFBqfFxsp0ionr%2FJ7Ppw6WwiWjm" rel="nofollow" target="_blank">HarmonyOS 行业解决方案</a> ★<br/>★ 快速访问 <a href="https://link.segmentfault.com/?enc=s75TRnAHu%2BvUtujx60nSMQ%3D%3D.G713dFfvsE1v3928C%2FlChAvYK1HpRgLFfrJutAGv4gmT2RFY0TT09wZomZft8z60FHKcgqvVstBczyU1GIWI19iPqmde%2BM12vub%2FAcUnRSgSKsEDOtIlFZwMcDJOPVggO2AJISmyuQS1S21ufKuBO7bSM7mwZlIYs5fouCjsYopF%2Fuos9kh%2FEvA8GmFORjpLnZkOM5osfnvmSy89X8OrBg%3D%3D" rel="nofollow" target="_blank">社交交友行业解决方案</a> ★</p><p>在社交赛道竞争日趋激烈的当下，开发者常面临开发周期长、多设备适配难、用户体验优化瓶颈等问题。HarmonyOS开发者官网推出的社交交友行业解决方案，以 “能力集成 + 工具支撑 + 生态服务” 为核心，为社交应用从搭建到优化提供全链路支持，助力开发者快速破局、实现业务增长。</p><p><img width="723" height="453" referrerpolicy="no-referrer" src="/img/bVdm7US" alt="image.png" title="image.png"/></p><p>方案深度贴合不同社交场景需求，通过鸿蒙生态创新能力落地，打造差异化用户体验。</p><p>在内容创作与分享场景，小红书借助鸿蒙 <strong>“碰一碰分享”</strong> 能力，用户手机贴近好友设备即可分享内容，搭配 <strong>“跨设备应用接续”</strong> ，可在手机无缝同步至平板操作，双指缩放操作让笔记浏览更流畅；星野则针对兴趣社交，支持用户将 AI 生成的优质动态通过 <strong>“华为分享”</strong> 一键转发至微信、微博，生成的专属链接点击即跳转应用，轻松传播。</p><p>在内容消费场景，豆瓣在 “书影音” 长评页面集成 <strong>AI 朗读控件</strong>，用户通勤、运动时无需盯着屏幕，即可 “听评论文档”，解决长文本阅读痛点。</p><p>在社交互动场景，青藤之恋借助 <strong>push 推送能力</strong>，实时提醒用户应用内信息，避免错过关键社交机会；同时接入<strong>日历服务</strong>，自动同步至系统日历，生成日程提醒，让相亲互动更高效。Soul利用华为的<strong>LTPO技术</strong>，降低了应用的功耗，提升了用户的使用体验。</p><p><img width="723" height="424" referrerpolicy="no-referrer" src="/img/bVdm7UT" alt="image.png" title="image.png" loading="lazy"/></p><p>开发效率层面，方案提供全栈工具与灵活路径。包含一系列社交场景下常见的综合实践案例，助力开发者快速完成案例部署与功能开发。</p><p><img width="723" height="375" referrerpolicy="no-referrer" src="/img/bVdm7UU" alt="image.png" title="image.png" loading="lazy"/></p><p>组件与 SDK 资源丰富，社交相亲元服务模板、消息列表组件、开屏广告组件等开箱即用，整合融云IM、极光推送、华为位置服务等关键 SDK资源，缩短开发周期。</p><p><img width="723" height="363" referrerpolicy="no-referrer" src="/img/bVdm7UV" alt="image.png" title="image.png" loading="lazy"/></p><p>此外，方案配套完善的支持体系：行业开发精品课提供从架构到功能的实操教学，模板在线体验可提前验证逻辑，FAQ 与开发者社区实时解答，保障开发高效顺畅。<br/>无论你是刚起步的中小团队，还是寻求突破的成熟产品，都能通过该方案快速搭建优质社交行业鸿蒙应用。</p><p>登录HarmonyOS开发者官网，即可查看解决方案，借生态力量推动业务持续增长。</p><p>一步达指路：<a href="https://link.segmentfault.com/?enc=anKMgpQvnQDBF3%2FtZ7zZhg%3D%3D.0ptMfKicbylOZ4XdGpSGggBcbZh6e9IKexOddbaUdVmnz3aDMOcHZHCbWL%2BmCZ9QndKvds5x1amrGBIV94GQ5ZeNqnKHPs2uUpzpbs5e8t4g6SP6xHwegSOB4iJsxxcpw3eMW3XDXLmQIag%2B4VmDNi30MtxQQaONfNWCQmkW6V0cCU%2FTCEy1%2F7PvFq52e0iH0RMvn011xNvBvA8v3laxiA%3D%3D" rel="nofollow" target="_blank">社交交友行业解决方案 (huawei.com)</a></p>]]></description></item><item>    <title><![CDATA[面向物联网边缘数据采集与传输的事件驱动低]]></title>    <link>https://segmentfault.com/a/1190000047418696</link>    <guid>https://segmentfault.com/a/1190000047418696</guid>    <pubDate>2025-11-21 19:07:48</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>EdgeBus 是门思科技为物联网低功耗设备设计的事件驱动虚拟机框架，可在资源受限的 MCU 中以极低功耗运行。框架为 LoRaWAN 等 LPWAN 设备提供了统一的数据采集、协议解析、数据封装、上行传输和远程升级机制，并解决了版本管理、冲突避让、运维调试等关键系统难题。EdgeBus 的核心是事件驱动架构，通过周期查询事件和上行事件构建完整的数据采集与传输链路，为大规模物联网部署提供高可靠性和易维护性。</p><hr/><h2><strong>1. 概述与核心概念</strong></h2><p>EdgeBus（EB，EdgeBus Virtual Machine）是门思科技 Manthink 为物联网边缘节点开发的一套轻量级、事件驱动的低功耗虚拟机系统。其目标是为 LoRaWAN、RS 485 仪表数据采集设备、超低功耗传感终端提供一套结构化的软件运行框架，使开发者无需从零构建底层通信逻辑即可完成稳定、高效的边缘数据采集与传输。</p><p>EB 的核心是 ​<strong>事件驱动机制</strong>​，包括两个核心周期性事件：</p><h3><strong>1 查询事件（Query Event）</strong></h3><ul><li>负责从子设备（Modbus、UART 仪表等）定期采集原始数据</li><li>进行 CRC 校验、字节序转换、类型转换与数据缓存</li><li>以低功耗机制唤醒设备完成一次采集任务</li></ul><h3><strong>2 上行事件（LoraUp Event）</strong></h3><ul><li>定期将处理后的数据通过 LoRaWAN 发送</li><li>支持数据打包、压缩重组、多帧发送</li><li>适配 Class A 和 Class C 设备运行模式</li></ul><p>通过该事件模型，EB 将底层数据采集与 LPWAN 传输流程自动化，大幅提升系统稳定性与设备续航。</p><hr/><h2><strong>2. 核心功能与技术特点</strong></h2><p>EdgeBus 的优势不仅来自事件架构，还来自其围绕 FUOTA、数据解析、ADR、运维等提供的完整系统能力。</p><h3><strong>2.1 功能与特点对照表</strong></h3><table><thead><tr><th>功能模块</th><th>技术特点</th><th>解决痛点 / 优势</th></tr></thead><tbody><tr><td><strong>数据采集与处理</strong></td><td>TypeScript 开发，EB Compiler SDK，支持 Modbus CRC、整数/浮点数/BCD、多寄存器映射、EBBuffer 数据流处理</td><td>统一数据解析方式，无需重复造轮子，降低协议适配成本</td></tr><tr><td><strong>FUOTA 远程升级</strong></td><td>多 bin 分片升级、压缩算法、小数据块传输、低功耗下载</td><td>解决电池设备固件升级困难，提高大规模维护效率</td></tr><tr><td><strong>系统管理与运维</strong></td><td>内置版本管理、掌机运维、掌机信道调试、参数初始化</td><td>支持现场快速调试、避免人工拆机升级，提高项目交付速度</td></tr><tr><td><strong>网络优化能力</strong></td><td>本地 ADR、入网保护、时分机制、自动重入网</td><td>提升大规模网络容量，避免批量上电冲突</td></tr><tr><td><strong>低功耗控制</strong></td><td>Class A/C 切换、电池监测、温度监测、Battery 参数化建模</td><td>电池供电设备可运行多年并提供准确状态</td></tr><tr><td><strong>业务逻辑增强</strong></td><td>定时抄读、门限判断、数据重组、时间同步</td><td>支持智能上报，减少无效通信，提升系统效率</td></tr></tbody></table><hr/><h2><strong>3. 应用场景与行业价值</strong></h2><p>EdgeBus 适用于对 <strong>低功耗、数据可靠性、远程维护、大规模部署能力</strong> 有高要求的物联网系统。</p><hr/><h2><strong>3.1 目标客户与价值</strong></h2><table><thead><tr><th>目标群体</th><th>描述</th><th>EB 提供的核心价值</th></tr></thead><tbody><tr><td><strong>物联网解决方案提供商 ISP</strong></td><td>部署大规模 LoRaWAN / LPWAN 系统</td><td>提供经验证的底层框架，避免反复解决版本管理、冲突、升级等系统问题</td></tr><tr><td><strong>嵌入式 / IoT 开发者</strong></td><td>负责仪表采集、协议解析、数据封装</td><td>SDK 统一开发环境，大幅提升代码质量与可维护性</td></tr><tr><td><strong>工业 / 公用事业集成商</strong></td><td>水电气表计抄读、工业监控项目</td><td>满足定时抄读、远程运维、大规模稳定运行的需求</td></tr></tbody></table><hr/><h2><strong>3.2 典型应用场景</strong></h2><h3><strong>1 智能公用事业（水电气热表计抄读）</strong></h3><ul><li>​<strong>需求</strong>​：冻结抄读、7×24 小时低功耗、远程升级</li><li>​<strong>EB 价值</strong>​：精准时间同步、多 bin FUOTA、Class A 模式，大幅减少现场维护</li></ul><h3><strong>2 工业设备监控（SCADA）</strong></h3><ul><li>​<strong>需求</strong>​：采集大量 RS 485 / UART 工控数据，需阈值告警</li><li>​<strong>EB 价值</strong>​：Modbus 定制数据处理、阈值触发上报、数据重组，适合作为轻量 DTU</li></ul><h3><strong>3 智慧城市与环境监测</strong></h3><ul><li>​<strong>需求</strong>​：分散部署、低成本通信、快速定位故障</li><li>​<strong>EB 价值</strong>​：中继覆盖盲点、掌机运维加速调试流程、提升大规模运行可靠性</li></ul><hr/><h2><strong>4. 总结</strong></h2><p>EdgeBus 是一套专为物联网低功耗设备设计的系统级边缘虚拟机框架。通过事件驱动架构、多 bin 升级、数据编解码、网络优化与运维工具链，EB 有效解决了低功耗设备在<strong>开发、部署、升级、维护</strong>全生命周期面临的关键技术挑战。对于追求长期稳定运行和低运维成本的大规模物联网项目，EdgeBus 提供了成熟、可靠、可持续演进的技术基础。</p>]]></description></item><item>    <title><![CDATA[Java与AI融合创新！龙蜥邀您参加 G]]></title>    <link>https://segmentfault.com/a/1190000047418700</link>    <guid>https://segmentfault.com/a/1190000047418700</guid>    <pubDate>2025-11-21 19:07:03</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047418702" alt="图片" title="图片"/><br/>报名链接：<a href="https://link.segmentfault.com/?enc=Y%2FL71qq%2FFgkW1jaT578Bmg%3D%3D.mRugedR%2B3%2BlOg%2FH1YrFY5SlzTmqUufuvLhBA8L%2B5z30g%2FNYj%2BGEkF%2FPfeeHBki0g" rel="nofollow" target="_blank">https://m.zhundao.net/event/389233</a></p>]]></description></item>  </channel></rss>