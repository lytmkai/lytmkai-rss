<?xml version="1.0" encoding="UTF-8"?><rss version="2.0">  <channel>      <title>SegmentFault - 最近文章</title>      <link>https://segmentfault.com/blogs/newest</link>      <description>SegmentFault 思否</description>      <generator>python segmentfault.py @Pi20</generator>      <item>    <title><![CDATA[AI Agent 黑客松报名通道开启，你的“一人公司”就差这一步 OpenBuild ]]></title>    <link>https://segmentfault.com/a/1190000047559972</link>    <guid>https://segmentfault.com/a/1190000047559972</guid>    <pubDate>2026-01-23 11:10:18</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdnIGs" alt="fce16b0fecfa0585fd346adc9d8b25fc.jpg" title="fce16b0fecfa0585fd346adc9d8b25fc.jpg"/></p><p>由 OpenBuild 联合 SegmentFault、VibeFriends 和 Monad 共同发起，并携手 KIMI、智谱 AI、豆包编程、YouWare、阶跃星辰、Rokid、硅基流动、立创开源等多家顶尖 AI 公司举办的「Rebel in Paradise AI 黑客松」已正式拉开帷幕。这场聚焦“智能体时代原生基础设施、产品与市场”的深度探索之旅，现已面向全球开发者开放报名通道。</p><p>如果你的桌面还堆满关于 AI Agent 的技术文档却无处实践；如果你的脑海中早已构想出一个能够自动化工作流、创造价值的智能体应用却缺少舞台；如果你渴望与 Kimi、智谱 AI、豆包编程等一线团队的技术专家面对面交流，那么，你的机会来了。</p><p>这可能是智能体时代最后的“末班车”</p><h3><strong>Rebel in Paradise AI 黑客松三大核心赛道</strong></h3><p>过去一年，AI 智能体从概念走向落地，正在重塑工作方式与商业逻辑。但真正的创新浪潮才刚刚涌起。本次黑客松瞄准三大核心赛道，直击行业最前沿痛点：</p><h4><strong>赛道一：Agent-native Payments</strong></h4><p>智能体间的价值流转与支付协议、微支付系统、自动化结算方案——这是构建智能体经济系统的基石。</p><h4><strong>赛道二：Intelligent Markets</strong></h4><p>基于智能体的预测市场与交易系统，探索数据市场、算力市场、AI服务市场的全新可能性。</p><h4><strong>赛道三：Agent-powered Apps</strong></h4><p>由智能体驱动的下一代应用，从工作流自动化到个性化助手，再到协作工具，用代码定义未来。</p><h3><strong>Hackathon 时间</strong></h3><p><strong>👥 报名与组队期：</strong> 即日起 - 项目提交前均可报名组队</p><p><strong>💻 项目提交截止：</strong> 2026年2月28日 23:59:59</p><p><strong>✅ 最终结果公布：</strong> 2026年3月10日</p><h3><strong>如何参与</strong></h3><p><strong>👉立即报名：</strong><a href="https://link.segmentfault.com/?enc=Ge2AcUsi0jYpS5FLj1Gh3A%3D%3D.VOsRob1STWNWtgRcPAvClqdyD8O1hzIZOm17nv6hP%2Fc%3D" rel="nofollow" target="_blank">https://rebel.openbuild.xyz</a></p><p>本次 Hackathon  以线上为主，开发者完全可选择全程线上参与，完成项目构思、开发与提交。同时我们也会在线下举办两场 Hacker Camp：</p><p><strong>👉 北京（1月31日）：</strong> <a href="https://link.segmentfault.com/?enc=lZG0gm4ceGP87zW4fF9Feg%3D%3D.YDB7YUCjfGeWk7wANEATXpdU%2ByBE0tFYo1B4BlpG5nE%3D" rel="nofollow" target="_blank">https://luma.com/irllzbeu</a></p><p><strong>👉 深圳（2月7日）：</strong> <a href="https://link.segmentfault.com/?enc=7rX4O7BkFws3ugeIxtq9pQ%3D%3D.%2Fv2gBJQauqtWpmCmkVKSWiftFCZMqy6dLAPSF%2F%2FQcB4%3D" rel="nofollow" target="_blank">https://luma.com/je6if25j</a></p><p>为开发者提供的额外深度交流与实战辅导机会，你可以将此视为一次与导师、队友线下碰撞火花的“加速器”。</p><p>无论你身在何处，均可参与线上环节，享受同等技术辅导、资源支持与评奖资格。当然，无论是否报名 Hackathon，也非常欢迎亲临线下活动现场，与数百名开发者同台交流。</p><h3><strong>为什么你必须把握这次机会？</strong></h3><p>**💰 总奖池 $40,000：** $20,000现金 + $20,000 资源奖励</p><p><strong>🔥 稀缺资源支持：</strong> 包括 LLM Token、 NVIDIA DGX、顶尖公司参访机会等</p><p><strong>🆙 成长直通车：</strong> 一线AI公司技术专家辅导、投资人对接、项目孵化支持</p><p><strong>💬 社群与背书：</strong> 加入由高质量开发者、创业者和技术领袖组成的创新网络</p><p>智能体时代的竞争，已从“是否会使用工具”升级为“能否创造智能体”。这趟驶向未来的列车已经鸣笛，车厢里坐着Monad、Kimi、智谱AI的技术领袖，也坐着与你一样渴望用代码重塑世界的开发者。</p><p>别等到2月28日才后悔没报名。最好的开始时间，永远是现在。</p><h3><strong>快速答疑（Q&amp;A）</strong></h3><p><strong>Q：可以纯线上参与，完全不参加线下活动吗？</strong></p><p>A：完全可以。 线上参与即可完成全部黑客松流程并获得完整资源支持。</p><p><strong>Q：没有成型的项目或想法，可以报名吗？</strong></p><p>A：可以。 线下活动无门槛，线上黑客松最终需提交项目，但我们鼓励从0到1的探索，并设有相应辅导环节。</p><p><strong>Q：如何组队？</strong></p><p>A：建议自行组队，也可在活动社群中招募队友。</p><p><strong>Q：可以同时报名北京和深圳两场线下活动吗？</strong></p><p>A：可以。</p><p><strong>Q：资源支持（算力、硬件等）如何申请？</strong></p><p>A：组队成功后即可提交申请。</p><p><strong>Q：能选择多个赛道吗？</strong></p><p>A：可以多选，组委会将进行简单审核。</p><p>我们相信，下一个时代的“一人公司”，将由智能体与你共同构建。</p><h3><strong>合作伙伴</strong></h3><p><img width="723" height="1558" referrerpolicy="no-referrer" src="/img/bVdnIGt" alt="a29ee9b59442ba5f9ec3ab9f372566ef.jpg" title="a29ee9b59442ba5f9ec3ab9f372566ef.jpg" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[『NAS』在绿联安装一个抠图工具-withoutbg 德育处主任 ]]></title>    <link>https://segmentfault.com/a/1190000047560051</link>    <guid>https://segmentfault.com/a/1190000047560051</guid>    <pubDate>2026-01-23 11:09:18</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><strong>点赞 + 关注 + 收藏 = 学会了</strong></p><blockquote>整理了一个NAS小专栏，有兴趣的工友可以关注一下 👉 <a href="https://link.segmentfault.com/?enc=vTdrWi4qpHpce8NVXlBMDQ%3D%3D.9ROiUbyln03GEilEuyw%2BcgDQQklePAyaJkfhB%2FLOKk%2F%2B8LO75Bug4eMFxcGjCfBYTuO6vhXZYtz0egvTRNt8q91fHVcqkNS6v4vaK%2BxLT%2BbKo1pknBSb1w%2FC6pCS4ll%2FSyHJil4rWsn%2FK6J576Kc70JdTwoFDsA20khJlQikgk0%3D" rel="nofollow" target="_blank">《NAS邪修》</a></blockquote><p>withoutbg 是一款 AI 图片去背景工具，支持本地免费离线处理（隐私保护）和 Pro 版高质量处理，能通过 Docker 轻松部署到 NAS。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560053" alt="" title=""/></p><p>这次用的是绿联DXP4800Plus。</p><p>打开 Docker，打开“镜像”模块，搜索“withoutbg”。</p><p>下载红框这个。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560054" alt="" title="" loading="lazy"/></p><p>下载完成后，打开“本地镜像”，点击“withoutbg/app”右侧的加号创建一个容器。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560055" alt="" title="" loading="lazy"/></p><p>“自动重启”建议开启。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560056" alt="" title="" loading="lazy"/></p><p>然后往下滑，NAS端口设置一个其他项目没用过的数字。比如我这里设置的是 <code>39155</code>。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560057" alt="" title="" loading="lazy"/></p><p>接着在浏览器打开 <code>绿联NAS的IP + 39155</code> 就可以使用 withoutbg 抠图了。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560058" alt="" title="" loading="lazy"/></p><p>试了一下，物品、动物、人物都可以抠。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560059" alt="" title="" loading="lazy"/></p><p>但缺点就是它自己去识别抠什么，并没提供一个涂抹工具，让我涂什么它就在我涂抹的区域去抠图。</p><p>而且界面没中文。</p><hr/><p>以上就是本文的全部内容啦，想了解更多NAS玩法可以关注<a href="https://link.segmentfault.com/?enc=SOLDC32dzIiNcew%2F4Ogrow%3D%3D.L5B%2FB3M1ZyDy3T%2Bn3VzsP5rzfE%2F1o80ZYPbm0TlL5sbjEXyyjyypqjscpBdhH9aX7WbURFTaovZJ%2BFM86zM637oM3ijOvB7cIZWZZ3wvIQdp2W6scAz%2F3IYn83OZeQ5rcGg3TYUGCV8kb6%2BqATUXnpmiwP14HotC%2BQLEo4umGhI%3D" rel="nofollow" target="_blank">《NAS邪修》</a></p><p><strong>点赞 + 关注 + 收藏 = 学会了</strong></p>]]></description></item><item>    <title><![CDATA[『n8n』一招解决“无法读写本地文件” 德育处主任 ]]></title>    <link>https://segmentfault.com/a/1190000047560071</link>    <guid>https://segmentfault.com/a/1190000047560071</guid>    <pubDate>2026-01-23 11:08:19</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><strong>点赞 + 关注 + 收藏 = 学会了</strong></p><blockquote>整理了一个n8n小专栏，有兴趣的工友可以关注一下 👉 <a href="https://link.segmentfault.com/?enc=p7bJhTJM5S7LJc%2BkeP%2B9%2FQ%3D%3D.fTslrQ5O3xwyH7mLIv0KnvMGDZuTlQTjiFuSQtuxkS%2BwYvHBLPxHrF3z4L%2FaHkyIpJwuX%2F4y4usMs4YKx7cLrn7DRPQC%2F9cJhdAryE%2BrbZIi%2FRcLbfLBH3ojGyov5IzhxVsSmqxmFmkG62wjD7e8IxEqmkcO14U%2Fs%2ButX9KddQo%3D" rel="nofollow" target="_blank">《n8n修炼手册》</a></blockquote><p>不管是在电脑还是 NAS 通过 Docker 部署 n8n，环境变量没配置好的话，使用 <code>Read/Write Files from Disk</code> 节点「读取本地本地」或者「保存文件到本地」，有可能出现这个报错。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560073" alt="" title=""/></p><p>这是 <strong>Docker + n8n 文件系统权限/路径隔离</strong> 的经典问题，不是 n8n 节点用错，而是<strong>容器只能访问被允许的目录</strong>。</p><p>⚠️⚠️⚠️</p><p><strong>想解决这个问题，首先要将你 n8n 上已有的工作流等数据找个地方保存好。因为要改环境变量，有可能会丢失数据。</strong></p><p>⚠️⚠️⚠️</p><h2>在电脑用 Docker 部署</h2><p>打开 Docker，首先要在 Containers 里删掉部署好的 n8n。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560074" alt="" title="" loading="lazy"/></p><p>然后到 Images，假设你没删掉 n8n 镜像的话，重新点击一下运行按钮。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560075" alt="" title="" loading="lazy"/></p><p>删掉镜像了就重新拉一遍吧。可以参考<a href="https://link.segmentfault.com/?enc=TBTDRzCUxhGUEjIydmguPw%3D%3D.uHhtAL8HUoGG%2Ff6aTPChIGwHXGFN%2BBLXJs4tOXmxzNWG55OiKyLacQIwB2llm4XAJSCemI6FkXKiyIO%2BzSRi4A%3D%3D" rel="nofollow" target="_blank">《『n8n』环境搭建》</a></p><p>点击运行按钮后，需要添加在 Volumes 里添加一项（下图红框）。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560076" alt="" title="" loading="lazy"/></p><p>在你的电脑，找个位置创建要给文件夹。</p><ul><li>上图红框的 <code>Host path</code> 这项就填入你在电脑创建的文件夹的绝对路径。</li><li><code>Container path</code> 这项填入 <code>/home/node/.n8n-files</code>，必须是这个值！一个字一个符号都不能少！</li></ul><p>然后点击“Run”按钮（弹窗右下角蓝色底色那个按钮）。</p><p>之后再浏览器输入 <code>localhost:5678</code> 就能运行 n8n 了。</p><p>接下来使用 <code>Read/Write Files from Disk</code> 节点读写文件，都是指向你刚刚在电脑创建的那个文件夹。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560077" alt="" title="" loading="lazy"/></p><p>比如我的 <code>/home/node/.n8n-files</code> 指向了 <code>文稿/n8n-data</code> 这个文件夹，里面有一个 <code>hello.txt</code> 文件。</p><p>在 n8n 里使用 <code>Read/Write Files from Disk</code> 节点时，<code>File(s) Selector</code> 项需要这么写：</p><pre><code>/home/node/.n8n-files/hello.txt</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560078" alt="" title="" loading="lazy"/></p><p>可以看到文件读取成功了。</p><p><strong>记住记住！用法是这样的，别问为什么</strong>⬇️⬇️⬇️</p><pre><code>/home/node/.n8n-files/文件名.后缀</code></pre><h2>在绿联 NAS 部署</h2><p>如果你是在 NAS 上部署 n8n，通常使用 Docker 部署的吧～</p><p>不管你是用群晖还是其他牌子的NAS，如果使用新建项目，用是 <code>yaml</code> 拉镜像。</p><pre><code>services:
  n8n:
    image: n8nio/n8n:latest   # 为了汉化成功，这里需要指定镜像版本号
    container_name: n8n
    ports:
      - 5678:5678
    volumes:
      - n8n:/home/node/.n8n # 冒号前面映射n8n文件夹绝对路径
      - n8n-files:/home/node/.n8n-files # 冒号前面映射n8n-files文件夹绝对路径
    restart: unless-stopped</code></pre><p>那么 <code>yaml</code> 的代码必须在 <code>volumes</code> 里加一项 <code>- n8n-files:/home/node/.n8n-files</code>。冒号前面的 <code>n8n-files</code> 是允许 n8n 读写文件的文件夹的<strong>绝对路径</strong>。</p><p>如果你是使用<a href="https://link.segmentfault.com/?enc=sbCGAdQFlQMknj0tc3r1og%3D%3D.YB3AgS3OxdBg8FT0MJp1qyXQFXCJke4XdtpyF6oaQYqlZEHFLwyTws%2FF1%2FBaCQHdE076G3S7YEYBkZEji6j5FA%3D%3D" rel="nofollow" target="_blank">《『NAS』不止娱乐，NAS也是生产力，在绿联部署AI工作流工具-n8n》</a>里提到的方法，在 Docker 的「镜像」模块里搜索 n8n 下载部署的话，需要这么做。</p><p>我用绿联 NAS 举例，其他品牌的 NAS 操作方法大同小异。</p><p>在 Docker 的「容器」里找到 n8n，停止运行。</p><p>然后编辑它。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560079" alt="" title="" loading="lazy"/></p><p>在 NAS 的「文件管理」里创建一个文件夹，用来给 n8n 读写文件使用的。</p><p>然后在「编辑容器」的「存储空间」里添加一项 <code>/home/node/.n8n-files</code> 指向那个文件夹，提供“读写”权限，如下图红框所示。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560080" alt="" title="" loading="lazy"/></p><p>点击“保存”按钮，然后运行项目。</p><p>我在 NAS 的 <code>n8n-files</code> 文件夹里准备了一个 <code>雷猴世界.txt</code> 文件。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560081" alt="" title="" loading="lazy"/></p><p>在 n8n 里，使用 <code>/home/node/.n8n-files/雷猴世界.txt</code> 这个路径就能读取到上面这个文件了。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560082" alt="" title="" loading="lazy"/></p><p><strong>同样，也是这个格式：</strong></p><pre><code>/home/node/.n8n-files/文件名.后缀</code></pre><hr/><p>以上就是本文的全部内容啦，想了解更多n8n玩法欢迎关注<a href="https://link.segmentfault.com/?enc=a%2FUNOmPdyXkbD5KkZ6TUkw%3D%3D.F%2Bx8cPkSBcFpt%2B1nJkUrZArmI7IvMkmLsqF6HBpT41jhiK5kaoioGs2lWYg3MfKMEWaUUgMfRirIBbD%2BR2f57OiUdseq4t3RuLg%2FJV%2FQZjsMNNK6xl6VknOkFHzn%2F7BliuodY6FdeLX%2FjIbogKFcv91%2FsZRyo8GaWhejOJIs%2FhY%3D" rel="nofollow" target="_blank">《n8n修炼手册》</a>👏</p><p>如果你有 NAS，我非常建议你在 NAS 上部署一套 n8n，搞搞副业也好，帮你完成工作任务也好  <a href="https://link.segmentfault.com/?enc=s97RCxUNV8%2FPLG6nPWQm9A%3D%3D.fbOziNPEo0ZnuiGDOZ5W6ccJi1BrN%2B94lfIxhvwSHBExNk8UaB7pKzD1FsZizdEUxBGSIijOJ8v%2FhYwIg2XCZQ%3D%3D" rel="nofollow" target="_blank">《『NAS』不止娱乐，NAS也是生产力，在绿联部署AI工作流工具-n8n》</a></p><p><strong>点赞 + 关注 + 收藏 = 学会了</strong></p>]]></description></item><item>    <title><![CDATA[视频会议国产化核心技术架构与技术特性解析 Amymaomao ]]></title>    <link>https://segmentfault.com/a/1190000047560285</link>    <guid>https://segmentfault.com/a/1190000047560285</guid>    <pubDate>2026-01-23 11:07:40</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>视频会议国产化核心技术架构与技术特性解析</p><p>在数字化协同与信息安全需求双重驱动下，视频会议国产化已从政策导向转向技术落地，其核心价值集中体现在自主可控、安全可靠、全场景适配三大维度。通过硬件根基、编解码技术、传输优化、安全防护及生态兼容的全链条技术创新，国产化视频会议系统正构建起独立于国外技术体系的完整解决方案。</p><p>一、硬件与系统架构：自主可控的技术根基</p><p>国产化视频会议系统以“芯片-模块-板卡-系统”全链条自主化为核心架构，彻底摆脱对国外硬件的依赖。核心硬件层面，采用国产自主研发的音视频编解码芯片、高性能主控芯片及信号处理芯片，覆盖X86与ARM双架构，适配飞腾、鲲鹏、兆芯等主流国产CPU，PCB板采用国产基材并通过-40℃~70℃极端环境适应性测试，保障供应链稳定与硬件可靠性。</p><p>系统层面深度适配银河麒麟、统信UOS、中科红旗等国产操作系统，实现客户端与服务器端的全平台兼容，同时支持Windows、MacOS、Android、iOS等跨系统协同，形成“硬件-系统”软硬协同的底层支撑。架构设计上采用分布式集群架构，通过多节点负载均衡提升并发处理能力，可支持数百至上千分会场的大规模会议调度，满足应急指挥、跨区域协作等复杂场景需求。</p><p>二、音视频编解码与传输技术：高清流畅的体验保障</p><p>（一）超高清编解码技术突破</p><p>国产化视频会议系统已实现从1080P到4K的画质跃升，旗舰级方案支持4K60fps主辅流双路传输，部分高端方案可实现8K60fps输出，画面色彩还原度达98%，能精准呈现文档细节、图纸线条及面部微表情，满足远程医疗、技术培训等高精度场景需求。编码标准上全面支持H.265高效编码与AVS3国产编码双标准，在保障画质的同时实现带宽利用率提升50%，仅需1Mbps带宽即可传输4K30fps高清视频，较行业平均水平显著降低网络成本。</p><p>音频处理方面采用OPUS 48K高保真编码，融合智能混音、回音抑制与噪音过滤算法，可有效屏蔽键盘敲击、空调运行等环境杂音，实现清晰自然的实时语音交互。针对复杂声学环境，系统具备自动增益调节与声场均衡功能，确保不同参会环境下的语音清晰度。</p><p>（二）宽域网络适配与抗干扰优化</p><p>传输技术上支持64Kbps-8Mbps宽范围带宽调节，在偏远地区低带宽环境下，64Kbps模式可保障基础音视频沟通；在高速网络环境中，8Mbps带宽能充分释放超高清性能。通过动态码率控制算法，系统可实时适配网络波动，在30%丢包率环境下仍能保持画面完整性与语音连续性。</p><p>为提升带宽利用效率，系统提供多模式智能调控机制：自动模式适配高端全高清会议，主流优先模式保障主讲画面清晰，辅流优先模式优化文档分享体验，可通过快捷操作10秒内完成切换。网络协议层面支持IPv4/IPv6双栈，兼容TCP/IP、RTP/RTCP等传输协议，同时通过H.460穿透技术解决防火墙限制，保障跨网络、跨区域会议的稳定连接。</p><p>三、安全防护体系：国密标准的全链路保障</p><p>国产化视频会议系统以GB/T 39786-2021国家密码标准为核心，构建“硬件-传输-存储”全链条安全防护。加密技术上集成SM2、SM3、SM4国密算法，通过SM4算法实现音视频流端到端加密，SM3算法保障存储数据完整性，SM2算法完成终端身份认证与数字证书核验，从根源杜绝数据泄露风险。</p><p>协议安全层面采用TLS/SRTP双重加密机制，TLS加密保护会议邀请、权限控制等信令数据，防止被篡改或窃听；SRTP加密保障音视频媒体流传输安全，即使数据被截获也无法解密还原。权限管理上采用“管理员-主讲人-参会人”三级角色体系，可精细化控制会议录制、文件下载、屏幕共享等敏感功能，满足政务、金融等涉密场景的安全要求。</p><p>数据存储方面支持本地服务器部署与国产化云平台适配，所有会议数据均存储于国内服务器，严格遵循数据跨境传输相关规定，避免数据出境风险。系统还内置日志审计与操作追溯功能，可完整记录会议创建、参会人员、数据传输等全流程信息，便于安全审计与问题排查。</p><p>四、智能协同与生态适配：全场景应用赋能</p><p>（一）智能会议功能升级</p><p>国产化视频会议系统深度融合AI技术，实现会议全流程智能化赋能。人脸自动签到功能可在几分钟内完成百人参会者身份核验，语音转写准确率达98%，会议结束后自动生成结构化纪要并同步至OA系统，大幅提升协作效率。视频处理上集成AI画质增强技术，通过自动曝光调节解决光线不均问题，避免“逆光黑脸”现象，提升复杂环境下的视觉体验。</p><p>会议管理功能覆盖通讯录管理、会议预约、分组讨论、文件共享、电子白板等全场景需求，支持会中功能模块自定义配置，可根据行业特性与办公习惯灵活调整功能布局。部分方案支持多机位接入与智能调度，主会场可连接4台以上4K摄像机，通过会控终端实现单画面、分屏等多种布局切换。</p><p>（二）国产化生态兼容适配</p><p>系统全面兼容国产软硬件生态，硬件层面可直接对接国产网络摄像机、麦克风、显示终端等外设，支持HDBaseT等接口标准，简化部署流程并降低故障率；软件层面与国产办公软件、政务系统、CRM系统无缝集成，实现会议预约、纪要分发、任务跟进的全流程闭环管理。</p><p>针对不同行业场景，系统提供定制化适配能力：应急指挥场景支持全省级多会场实时调度，教育场景优化课件分享与录播功能，企业协作场景兼容主流办公平台，形成覆盖政务、金融、医疗、教育等多领域的解决方案体系。同时支持终端多样化接入，包括PC端、移动端、TV终端等，满足移动办公与固定会场的全场景使用需求。</p><p>结语</p><p>视频会议国产化的技术演进，本质是自主创新与场景需求的深度融合。从核心芯片的自主研发到国密算法的全面应用，从超高清传输到智能协同，国产化系统已在技术性能、安全防护与生态适配等方面实现跨越式发展。未来，随着AI大模型、5G等技术的深度融入，视频会议国产化将向更低延迟、更高智能、更广兼容的方向进阶，为数字中国建设提供安全可靠的协同支撑。</p>]]></description></item><item>    <title><![CDATA[Python接口自动化测试框架实战开发！ 坎窝主夜 ]]></title>    <link>https://segmentfault.com/a/1190000047560292</link>    <guid>https://segmentfault.com/a/1190000047560292</guid>    <pubDate>2026-01-23 11:06:51</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>吃透 Python 接口自动化测试框架：从设计到开发实战精讲——超越脚本，构建质量壁垒<br/>在软件测试领域，“接口自动化”早已不是什么新鲜词汇，甚至可以说是测试工程师的标配技能。然而，在实际的工作交流中，我发现一个普遍的现象：绝大多数测试人员虽然每天都在使用 Python 写自动化脚本，但却往往停留在“能用”的层面，甚至陷入了“为了自动化而自动化”的泥潭。面对复杂多变的业务场景，现成的工具如 Postman 或简单的脚本往往显得力不从心。因此，“吃透 Python 接口自动化测试框架：从设计到开发实战精讲”这一课题的价值，便显得尤为突出。在我看来，这不仅是一次技术能力的提升，更是一场从“脚本工人”向“测试架构师”的思维蜕变。<br/>首先，我们需要明确“框架”与“脚本”的本质区别。很多初学者所谓的自动化，不过是利用 requests 库写了一长串线性执行的测试函数。这种方式在面对三五个接口时或许效率尚可，但随着业务量的指数级增长，脚本维护成本会迅速失控。真正的框架设计，核心在于“抽象”与“复用”。一个优秀的框架，应当像搭建乐高积木一样，将通用的能力——如 HTTP 请求的封装、配置文件的读取、日志的记录、数据库连接的管理——剥离出来，形成稳固的底层基石。通过精讲框架设计，我们学会的是如何用工程化的视角去看待测试代码，如何利用 Python 的面向对象特性来降低系统的耦合度。这种设计思维的建立，是解决“脚本难维护、扩展性差”这一顽疾的唯一解药。<br/>其次，深入理解框架的运行机制，是解决复杂测试场景的关键。在实际测试中，我们经常面临数据依赖、环境隔离、并发执行以及异步处理等棘手问题。例如，接口 B 的入参依赖于接口 A 的返回值，如何优雅地处理这种链式依赖？又比如，在进行数据驱动测试时，如何将测试代码与测试数据彻底分离？这些问题的解决，不能靠堆砌 if-else，而是需要框架层面提供强大的支持，比如引入装饰器来处理前置条件，或者利用设计模式（如工厂模式、单例模式）来管理测试生命周期。实战精讲的魅力在于，它不会只教你“怎么做”，而是深入剖析“为什么这么做”。当你吃透了框架内部的请求拦截器、钩子函数以及异常捕获机制后，你会发现，那些曾经看似不可逾越的障碍，如今都能在框架层面通过寥寥数行配置得以化解。<br/>再者，从设计到开发的完整闭环，能够极大地提升测试工程师的技术话语权。在传统的研发流程中，测试人员往往处于被动接收的一方。然而，当你能够独立设计并开发一套企业级的自动化测试框架时，你的角色就发生了质的变化。你不再仅仅是质量的“检验者”，而是质量保障体系的“建设者”。这套框架不仅是验证业务逻辑的工具，更是研发团队的“基础设施”。通过集成 CI/CD 流水线，实现代码提交后的自动触发与报告反馈，测试框架成为了连接开发与运维的桥梁。这种对工程效能的推动，是单纯的手工测试或浅层脚本无法比拟的。它要求我们不仅要懂 Python，还要懂 Linux、懂 Docker、甚至懂一点架构设计，这种全栈式的视野正是测试进阶的核心竞争力。<br/>此外，我认为“吃透”二字还意味着对可扩展性与稳定性的极致追求。一个好的框架，必须具备良好的容错能力和清晰的报告机制。在实战中，我们需要思考如何设计断言库，才能让报错信息一目了然？如何处理网络抖动导致的偶发失败，避免误报？这些细节的打磨，直接决定了自动化测试在团队中的信任度。如果测试框架总是“报错不断”且难以排查，那么它最终只会被束之高阁。通过精讲中的实战演练，我们将学会如何编写鲁棒性强的代码，如何通过日志追踪问题的源头，从而让自动化测试真正成为团队信赖的“守门员”。<br/>综上所述，Python 接口自动化测试框架从设计到开发的学习，绝非只是掌握几行 Python 语法或几个测试库的用法那么简单。它是一场关于代码质量、系统设计思维以及工程效能的深度修炼。它帮助我们摆脱了重复劳动的桎梏，赋予了我们构建复杂质量保障体系的能力。对于每一位渴望在测试领域深耕、希望打破职业天花板的工程师来说，吃透框架设计与开发，是通往技术高地的必经之路。它让我们明白，真正的自动化，不是机械地执行点击，而是用智慧构建一套能够自我进化、高效运转的质量生态系统。</p>]]></description></item><item>    <title><![CDATA[有哪些SRM系统是专门为供应链管理设计的？ SaaS圈老马 ]]></title>    <link>https://segmentfault.com/a/1190000047560326</link>    <guid>https://segmentfault.com/a/1190000047560326</guid>    <pubDate>2026-01-23 11:06:00</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>众所周知，供应链管理已经成为企业降本增效、提升协同效率和增强抗风险能力的核心环节，而 SRM（供应商关系管理）系统，正是企业在供应链管理过程中，用来规范供应商协作、控制采购风险、提升整体效率的重要工具。</p><p>但面对市场上数量众多、功能差异明显的 SRM 系统，很多企业在选型时都会遇到同样的问题：<strong>哪些 SRM 系统是真正围绕供应链管理场景设计的？哪些更适合国内企业使用？是否有成熟、稳定、经过市场验证的产品可供参考？</strong> 如果逐一试用，不仅成本高，也非常耗费时间和精力。</p><p>因此，本文将结合 <strong>SRM 系统市场口碑、产品功能完整度以及实际应用体验</strong>，参考行业内常见的 SRM 系统榜单、厂商公开资料及用户反馈，对多款专注供应链管理的 SRM 系统进行整理和分析，帮助大家在选型过程中少走弯路。</p><p>本次测评主要围绕 <strong>系统的供应链适配度、功能实用性、用户体验以及市场认可度</strong> 等核心维度进行筛选，剔除了偏向通用管理或功能不成熟的产品，最终选出几款在业内表现较为突出的 SRM 系统进行重点介绍。</p><p>考虑到篇幅和阅读体验，本文不会对所有系统逐一展开，而是挑选其中<strong>综合表现更优、供应链场景覆盖更完整的几款 SRM 系统</strong>，重点说明它们的优势、适合的企业类型以及核心功能亮点。每款产品后也会附上官方信息，方便大家结合自身需求进一步了解和体验。那么，下面我们正式开始。</p><p><strong>一、正远科技</strong></p><p>如果要说国内在SRM领域有长期积累、并且真正从业务视角去设计系统的厂商，<strong>正远科技</strong>肯定排在前列。这家公司成立于2002年，在流程管理和供应链数字化领域已经深耕了二十多年，不是那些跟风做SRM的“新手”。</p><p>正远科技的SRM系统是基于<strong>自主研发的低代码平台产品</strong>研发的，最大特点就是<strong>围绕采购业务全流程设计</strong>，而不是简单把OA或者CRM改个名字。系统核心涵盖三大模块：<strong>供应商管理、价格管理、采购执行协同</strong>，基本把企业采购从寻源、定价、下单、对账到绩效评估的全过程都管起来了。</p><p>官网：<a href="https://link.segmentfault.com/?enc=3fe5Go5zvvsL2ZWwTC3fvA%3D%3D.3Q0WFuRxzWD8HtroKnCU9tJF7oOnrn%2FTUkfFrNeHWUw%3D" rel="nofollow" target="_blank">https://www.zhengyuansz.com</a></p><p><strong>为什么它值得重点说一说？</strong></p><p>首先，它的<strong>流程引擎和表单设计能力特别强</strong>。采购过程中各种审批流、询价比价流程、合同评审流程，都可以通过可视化方式配置出来，企业自己就能调整，不用每次都找厂商开发。这对于业务经常变动的企业来说，实用性很高。</p><p>其次，它背后有<strong>正远低代码平台</strong>支撑。这意味着如果你有一些个性化需求，比如要和已有的ERP、财务系统对接，或者增加一些特定的质检流程、物流跟踪看板，都可以通过低代码方式快速搭建出来，<strong>开发成本降低、周期也大幅缩短</strong>。对于很多预算有限但又需要定制化功能的中大型企业，这个优势很明显。</p><p>第三，正远SRM<strong>不只是一个工具，更强调管理落地</strong>。它内置了供应商准入、分类、绩效评估体系，帮助企业把供应商从“资源”变成“伙伴”，实现从被动应付到主动管理的转变。系统还支持与招投标平台、电子签章等外部系统集成，形成采购闭环。</p><p><strong>适合谁用？</strong></p><p>从公开信息看，正远科技服务过<strong>威高集团、南山集团、魏桥创业</strong>等一批大型制造集团，项目经验集中在制造业、工程、能源等领域。所以如果你是制造类企业，采购物料复杂、供应商数量多、对质量与交期要求高，正远这套系统应该能贴合你的业务场景。他们的实施团队也有PMP认证，项目交付经验比较扎实。<br/><img width="723" height="328" referrerpolicy="no-referrer" src="/img/bVdnIL6" alt="" title=""/></p><p><strong>二、用友</strong></p><p>用友作为国内企业管理软件的老牌厂商，其SRM解决方案通常与它的ERP产品深度绑定。如果你公司已经在使用用友的ERP系统（比如U8、U9、NC Cloud），那么继续选用友的SRM会是一个比较顺理成章的选择。</p><p>用友SRM的核心优势在于<strong>数据无缝对接和业务流程一体化</strong>。采购订单、库存信息、财务应付数据都能和ERP实时同步，避免了跨系统对接的麻烦和数据不一致的问题。对于中大型企业，这种一体化带来的效率提升和错误减少，价值很大。</p><p>在功能层面，用友SRM覆盖了供应商生命周期管理、采购寻源、招标管理、采购协同、库存协作等典型场景。它特别强调<strong>集团化管控</strong>，适合多法人、多工厂、跨地域的集团型企业，能够实现集中采购、分散执行的模式。</p><p>值得一提的是，用友近年来也推出了<strong>低代码开发平台YonBuilder</strong>，可以基于它快速构建或扩展SRM中的某些定制化模块，比如特殊的审批流程、供应商门户页面等。但要注意，用友<strong>整体方案的费用较高，部署周期也相对较长</strong>，更适合预算充足、追求系统稳定性和生态完整性的企业。<br/><img width="723" height="282" referrerpolicy="no-referrer" src="/img/bVdnIL7" alt="" title="" loading="lazy"/></p><p><strong>三、金蝶</strong></p><p>金蝶的SRM解决方案，现在主要整合在<strong>金蝶云·苍穹</strong>这个PaaS平台里，产品名称通常是“金蝶云·星瀚”或“金蝶云·星辰”中的SRM模块。和用友类似，金蝶SRM也与自家的ERP、财务系统天生融合。</p><p>金蝶SRM的特点是<strong>云原生架构</strong>，部署和扩展比较灵活。它强调敏捷采购和协同效率，在供应商协同门户、移动审批、实时询价比价等方面做得比较轻快。对于快消、零售、现代服务业等采购品类相对标准、追求效率的行业，匹配度不错。</p><p>它的供应商管理模块也提供了从注册、认证、考核到淘汰的全周期管理工具。另外，金蝶在<strong>数据分析</strong>方面一直有优势，其SRM系统也能提供一些采购价格趋势分析、供应商绩效看板等数据化工具，帮助采购人员做决策。</p><p>如果你企业是金蝶ERP的用户，或者倾向于全栈采用一家云服务商的解决方案，希望系统架构现代、迭代速度快，金蝶云星SRM值得纳入考虑范围。不过，它的行业深度定制能力，相比专注垂直领域的厂商，可能还需要结合生态伙伴来完成。<br/><img width="723" height="312" referrerpolicy="no-referrer" src="/img/bVdnIL8" alt="" title="" loading="lazy"/></p><p><strong>四、SAP Ariba</strong></p><p>提到SRM，很难绕开<strong>SAP Ariba</strong>。它是全球领先的采购云平台，尤其擅长<strong>直接物料采购和全球化供应链协同</strong>。如果你的企业业务遍布全球，需要管理众多海外供应商，进行国际寻源和招标，Ariba的网络效应和标准化流程非常有优势。</p><p>Ariba不仅仅是一个软件，更是一个<strong>连接买家和卖家的网络平台</strong>。买方企业可以通过Ariba Network发布需求，直接触达海量供应商；卖方也可以通过它接收订单、开具发票，实现端到端的数字化协同。这种网络价值是单体SRM系统很难比拟的。</p><p>功能上，Ariba在战略寻源、合同管理、支出分析等方面非常强大。但它的缺点也很明显：<strong>实施和运营成本高昂</strong>，流程设计偏重国际化标准，可能不太适应国内一些灵活、本土化的采购习惯。而且，系统较为复杂，对内部团队和供应商的数字化水平要求都比较高。</p><p>因此，SAP Ariba更适合那些跨国公司、大型集团，或者采购模式非常标准化、追求与国际接轨的企业。对于大多数国内中小型企业而言，它的“重量级”可能有些难以承受。<br/><img width="723" height="350" referrerpolicy="no-referrer" src="/img/bVdnIL9" alt="" title="" loading="lazy"/></p><p><strong>五、企企通</strong></p><p><strong>企企通</strong>是近年来在国内SRM SaaS市场比较活跃的一家厂商。它定位清晰，就是专注于<strong>供应链双边协同平台</strong>，核心解决企业与供应商之间的订单、交货、对账、质量等协同问题。</p><p>它的产品界面比较友好，操作轻量化，供应商上手门槛低。企业可以通过企企通快速搭建一个供应商门户，让供应商自助查询订单、送货预约、提交质检报告、跟踪付款状态等，大大减少采购员和供应商之间反复打电话、发邮件的工作量。</p><p>企企通采用<strong>SaaS订阅模式</strong>，初始投入成本低，部署快，特别适合那些想快速上线SRM核心协同功能、又不想在IT上投入太多的成长型企业。它在电子制造、服装、食品等行业有不少客户案例。</p><p>当然，作为一款偏重协同的SaaS产品，它在复杂的战略寻源、集团化深度管控等方面，可能不如前面几家全面。但对于首要任务是“把现有采购执行流程理顺、提高协同效率”的企业来说，企企通是一个很务实的选择。<br/><img width="723" height="368" referrerpolicy="no-referrer" src="/img/bVdnIMa" alt="" title="" loading="lazy"/></p><p><strong>总结：</strong></p><p>测评了一圈，做个简单小结：</p><p><strong>追求深度与定制，尤其是有复杂制造背景</strong>：<strong>正远科技SRM</strong>是个不错的选择。它的低代码底座和深厚的行业理解，能很好应对复杂、多变的采购管理场景，性价比相对较高。已用用友/金蝶ERP，追求一体化稳定：分别考察用友SRM或金蝶云星SRM。生态内协同顺畅，减少集成烦恼，不过确实难免费用较高。业务全球化，采购标准化程度高：可以考虑SAP Ariba。借助其全球网络和最佳实践，但也需准备好相应的预算和变革管理。</p><p>最后提醒一点，选SRM系统不只是选功能，更是选一个长期的合作伙伴。建议在选择前，多看看厂商的真实客户案例（最好同行业），要求进行深入的业务流程演示，甚至先做个试点。毕竟，适合自己业务节奏和管理模式的，才是最好的系统。</p>]]></description></item><item>    <title><![CDATA[零代码开发能力：JVS函数公式的统一解决方案 软件部长 ]]></title>    <link>https://segmentfault.com/a/1190000047560351</link>    <guid>https://segmentfault.com/a/1190000047560351</guid>    <pubDate>2026-01-23 11:05:29</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在现代企业级应用开发中，对数据进行动态加工和转换是常见的需求。<br/>低代码开发作为一种新兴的快速开发方式，提供了函数公式能力，通过函数+入参的方式，用户可以像使用Excel公式一样轻松实现复杂业务逻辑的自动化处理。<br/>在JVS中，函数公式（DataOpter）是核心通用的基础能力，其中逻辑引擎、表单引擎、列表页、流程引擎、数据加工引擎等都拥有这个能力，，用于动态的对数据进行加工，系统本质上是通过groove 的脚本实现的。接下来我们重点讲解函数公式的核心功能。</p><h2>公式的编辑框</h2><p>如下图所示，函数公式是通过 函数+入参的方式，实现对数据的映射转换，在编辑框中可以支持手动录入：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560353" alt="图片" title="图片"/><br/>编辑框中支持手动输入，系统会根据关键词进行提示，提示的内容包括数据与函数<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560354" alt="图片" title="图片" loading="lazy"/><br/>函数框会对公式配置的结果进行语法校验，如果校验不通过，系统会提示语法判断结果，校验不通过是不能保存的<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560355" alt="图片" title="图片" loading="lazy"/></p><h2>公式的数据引用</h2><p>不同的场景下，接入的数据引用来源不同，表单场景下使用公式时，那么左侧的数据引用框架可以选择 上下文的数据、系统的基础数据、表单的数据等； 在流程引擎中使用公式配置时，系统接入了流程的基础数据、上下文的数据等； 在ELT 数据加工引擎中，使用公式时，可以选择到 用户的基本信息、字段的相关数据等<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560356" alt="图片" title="图片" loading="lazy"/></p><h2>函数选择器</h2><p>函数选择器点击函数框中的公式后，公式会自动的提交到编辑框中，在公式说明框中会对该公式进行详细说明<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560357" alt="图片" title="图片" loading="lazy"/></p><h2>函数的嵌套</h2><p>函数是可以多层嵌套使用的，也就是一个函数的输出是另一个函数的输入，函数的使用是从内向外的逐层计算，得到结果的<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560358" alt="图片" title="图片" loading="lazy"/></p><h2>函数的测试</h2><p>在设置了函数公式配置后，可以点击测试按钮，系统可以模拟仿真执行的结果，这样便于判断配置的正确性，如下图所示：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560359" alt="图片" title="图片" loading="lazy"/><br/>点击测试后，如果需要 业务的相关数据，那么系统会弹出输入框，在录入测试数据后，模拟相关业务背景数据，然后再计算：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560360" alt="图片" title="图片" loading="lazy"/><br/>提交后，系统会展示模拟执行的结果<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560361" alt="图片" title="图片" loading="lazy"/><br/>在线demo：<a href="https://link.segmentfault.com/?enc=CQ7ZLPsNtW5fK4fM7LBN0Q%3D%3D.Ee4RqaePn3IKoMX0Lxf60LN9sDaYcVgLZx2y876UYbg%3D" rel="nofollow" target="_blank">https://app.bctools.cn</a><br/>基础框架开源地址：<a href="https://link.segmentfault.com/?enc=%2FDbHwMeNOxkM4yGrXj8S3w%3D%3D.2jgPqhrsHzoYdXSwrNNCh0%2Far5P1koeJBBVGSnRxDV5NzE8n3qh7m%2BtXDYUgC3IA" rel="nofollow" target="_blank">https://gitee.com/software-minister/jvs</a></p>]]></description></item><item>    <title><![CDATA[multibootusb-9.2.0-setup安装步骤详解（附U盘多系统制作教程） 读书笔记 ]]></title>    <link>https://segmentfault.com/a/1190000047560370</link>    <guid>https://segmentfault.com/a/1190000047560370</guid>    <pubDate>2026-01-23 11:04:37</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>​</p><p><code>multibootusb-9.2.0-setup</code>是个<strong>多系统启动U盘制作工具</strong>，能把多个系统镜像（像 Ubuntu、Kali、Windows PE 等）装到一个 U 盘里，开机时选想进的系统就行。</p><h2>一、准备工作</h2><ol><li><p><strong>下载安装包</strong>​</p><p><strong>安装包下载：</strong><a href="https://link.segmentfault.com/?enc=jbFAFYm80YcgJehpzW8z9A%3D%3D.LUWNw9IQS5zfs%2BytXBFEHDm2yGT3kINl%2FnCQKcsfDv2Vy4Npfqu0gtizJ9ny6L7m" rel="nofollow" title="https://pan.quark.cn/s/f3b15864c764" target="_blank">https://pan.quark.cn/s/f3b15864c764</a></p></li><li><p><strong>准备 U 盘</strong>​</p><ul><li>至少 8GB 容量（越大越好，装的系统越多）。</li><li>先把 U 盘里的东西备份一下，制作时会格式化！</li></ul></li><li><p><strong>关闭杀毒软件（可选）</strong> ​</p><ul><li>个别杀毒软件可能会误报，安装时可以暂时关掉，装完再开。</li></ul></li></ol><h2>二、安装步骤</h2><ol><li>双击 <code>multibootusb-9.2.0-setup.exe</code>运行。</li><li>如果是 Windows 10/11，会弹出“用户账户控制”提示 → 点  <strong>“是”</strong> （需要管理员权限）。</li><li>进入安装向导，选语言（默认 English，有的版本有中文可选）。</li><li>点  <strong>“Next”</strong> ​ 继续。</li><li><p>选安装位置：</p><ul><li>默认是 <code>C:\Program Files\multibootusb</code>，想改就点“Browse”选 D 盘或其他盘。</li></ul></li><li><p>选附加任务：</p><ul><li>建议勾“Create a desktop shortcut”（创建桌面快捷方式），点“Next”。</li></ul></li><li>点  <strong>“Install”</strong> ​ 开始安装，等进度条走完（大概十几秒）。</li><li>最后点  <strong>“Finish”</strong> ​ 完成安装，桌面上会有 multibootusb 图标。</li></ol><h2>三、首次运行设置</h2><ol><li>双击桌面图标打开软件。</li><li>插入准备好的 U 盘（会被自动识别）。</li><li>在“Select USB Drive”下拉菜单里选你的 U 盘（注意别选错！）。</li><li>点“Detect Drives”刷新一下，确保 U 盘被正确识别。</li></ol><h2>四、基本使用（简单说两句）</h2><ul><li><strong>添加系统镜像</strong>：点“Browse”选择 ISO 镜像文件（比如 Ubuntu.iso、kali-linux.iso）。</li><li><strong>写入 U 盘</strong>：选好镜像后点“Install”，等待进度条走完（时间取决于镜像大小和 U 盘速度）。</li><li><strong>多系统共存</strong>：重复添加不同镜像，它们会按顺序排在启动菜单里。</li><li><strong>启动测试</strong>：制作完成后，重启电脑，进 BIOS 设置 U 盘启动，就能看到多系统菜单了。</li></ul><p>​</p>]]></description></item><item>    <title><![CDATA[C语言的指针 良许 ]]></title>    <link>https://segmentfault.com/a/1190000047560386</link>    <guid>https://segmentfault.com/a/1190000047560386</guid>    <pubDate>2026-01-23 11:03:52</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>大家好，我是良许。</p><p>今天我们来聊一聊 C 语言中最让初学者头疼，却又最强大的特性——指针。</p><p>作为一名从事嵌入式开发多年的程序员，我深知指针在底层编程中的重要性。</p><p>无论是操作硬件寄存器、管理动态内存，还是实现高效的数据结构，指针都扮演着不可或缺的角色。</p><h2>1. 什么是指针</h2><h3>1.1 指针的本质</h3><p>指针其实就是一个变量，只不过这个变量存储的不是普通的数值，而是内存地址。</p><p>我们可以把内存想象成一排排的房间，每个房间都有一个门牌号（地址），而指针就是记录这个门牌号的本子。</p><p>通过这个门牌号，我们可以找到对应的房间，进而访问或修改房间里的内容。</p><p>在嵌入式开发中，这个概念尤为重要。比如 STM32 的 GPIO 端口，其实就是通过固定的内存地址来访问的。</p><p>当我们要点亮一个 LED 灯时，本质上就是通过指针操作特定地址的寄存器。</p><h3>1.2 为什么需要指针</h3><p>指针的存在主要解决了以下几个问题：</p><p>第一，高效传递数据。</p><p>当我们需要在函数之间传递大型数据结构时，如果直接传递整个结构体，会产生大量的复制开销。</p><p>而使用指针，只需要传递一个地址（通常是 4 字节或 8 字节），效率大大提升。</p><p>第二，动态内存管理。</p><p>在嵌入式系统中，内存资源往往非常有限。</p><p>通过指针和动态内存分配，我们可以在程序运行时根据实际需要申请和释放内存，提高内存利用率。</p><p>第三，直接操作硬件。</p><p>在嵌入式开发中，我们经常需要直接访问硬件寄存器。</p><p>这些寄存器都有固定的物理地址，必须通过指针来访问。</p><h2>2. 指针的基本使用</h2><h3>2.1 指针的声明和初始化</h3><p>声明一个指针变量的语法是在类型名后面加上星号（*）。例如：</p><pre><code>int *p;        // 声明一个指向整型的指针
char *str;     // 声明一个指向字符的指针
float *fp;     // 声明一个指向浮点数的指针</code></pre><p>需要注意的是，刚声明的指针是野指针，它指向一个不确定的地址，使用前必须初始化。</p><p>我们可以用取地址符（&amp;）来获取变量的地址：</p><pre><code>int num = 100;
int *p = &amp;num;  // p指向num的地址
​
printf("num的值: %d\n", num);
printf("num的地址: %p\n", &amp;num);
printf("p存储的地址: %p\n", p);
printf("p指向的值: %d\n", *p);</code></pre><p>这段代码会输出 num 的值、num 的地址、指针 p 存储的地址（与 num 的地址相同），以及通过指针 p 访问到的值（也是 100）。</p><h3>2.2 指针的解引用</h3><p>解引用就是通过指针访问它所指向的内存中的值。</p><p>使用星号（*）操作符可以实现解引用：</p><pre><code>int a = 50;
int *ptr = &amp;a;
​
printf("a的值: %d\n", a);        // 输出50
printf("*ptr的值: %d\n", *ptr);  // 输出50
​
*ptr = 80;  // 通过指针修改a的值
printf("修改后a的值: %d\n", a);  // 输出80</code></pre><p>在这个例子中，我们通过指针 ptr 修改了变量 a 的值。</p><p>这在函数参数传递中非常有用，可以实现真正的"传址调用"。</p><h3>2.3 指针与函数</h3><p>在 C 语言中，函数参数默认是值传递，也就是说函数内部对参数的修改不会影响外部变量。</p><p>但通过指针，我们可以实现传址调用：</p><pre><code>void swap(int *a, int *b) {
    int temp = *a;
    *a = *b;
    *b = temp;
}
​
int main(void) {
    int x = 10, y = 20;
    printf("交换前: x=%d, y=%d\n", x, y);
    
    swap(&amp;x, &amp;y);
    printf("交换后: x=%d, y=%d\n", x, y);
    
    return 0;
}</code></pre><p>这个经典的交换函数例子展示了指针的威力。</p><p>通过传递变量的地址，函数内部可以直接修改外部变量的值。</p><h2>3. 指针的进阶应用</h2><h3>3.1 指针与数组</h3><p>数组名本身就是一个指针常量，指向数组的首元素。</p><p>这是 C 语言中一个非常重要的概念：</p><pre><code>int arr[5] = {1, 2, 3, 4, 5};
int *p = arr;  // 等价于 int *p = &amp;arr[0];
​
printf("arr[0] = %d\n", arr[0]);    // 输出1
printf("*p = %d\n", *p);            // 输出1
printf("*(p+1) = %d\n", *(p+1));    // 输出2
printf("p[2] = %d\n", p[2]);        // 输出3</code></pre><p>指针可以进行算术运算。</p><p>当指针加 1 时，实际上是移动了一个所指类型的大小。</p><p>比如 int 类型占 4 字节，那么 p+1 实际上是地址增加 4。</p><p>在嵌入式开发中，这个特性经常用于遍历数据缓冲区：</p><pre><code>uint8_t buffer[256];
uint8_t *ptr = buffer;
​
// 通过指针遍历整个缓冲区
for(int i = 0; i &lt; 256; i++) {
    *ptr = i;  // 写入数据
    ptr++;     // 指针移动到下一个位置
}</code></pre><h3>3.2 指针与字符串</h3><p>在 C 语言中，字符串实际上就是字符数组，而字符串的操作大量使用指针：</p><pre><code>char str[] = "Hello";
char *p = str;
​
while(*p != '\0') {
    printf("%c", *p);
    p++;
}
printf("\n");</code></pre><p>这段代码通过指针遍历字符串并逐个打印字符。</p><p>在实际开发中，我们经常需要处理字符串，比如解析串口接收到的 AT 指令：</p><pre><code>void parse_at_command(char *cmd) {
    if(strncmp(cmd, "AT+", 3) == 0) {
        char *param = cmd + 3;  // 指针偏移到参数部分
        printf("收到AT指令，参数: %s\n", param);
    }
}</code></pre><h3>3.3 多级指针</h3><p>指针本身也是变量，也有自己的地址，因此可以有指向指针的指针，称为多级指针：</p><pre><code>int num = 100;
int *p = &amp;num;      // 一级指针
int **pp = &amp;p;      // 二级指针

printf("num = %d\n", num);
printf("*p = %d\n", *p);
printf("**pp = %d\n", **pp);

**pp = 200;  // 通过二级指针修改num的值
printf("修改后num = %d\n", num);</code></pre><p>多级指针在动态二维数组、函数指针数组等场景中很常见。</p><p>在嵌入式开发中，有时需要动态管理设备列表，就会用到二级指针。</p><h2>4. 指针在嵌入式中的实战应用</h2><h3>4.1 操作硬件寄存器</h3><p>在 STM32 开发中，我们经常需要直接操作寄存器。</p><p>这些寄存器都有固定的物理地址，必须通过指针访问：</p><pre><code>// 定义GPIO端口的基地址
#define GPIOA_BASE    0x40020000U
#define GPIOA_MODER   (*(volatile uint32_t *)(GPIOA_BASE + 0x00))
#define GPIOA_ODR     (*(volatile uint32_t *)(GPIOA_BASE + 0x14))

// 配置PA5为输出模式
void led_init(void) {
    // 使能GPIOA时钟
    RCC-&gt;AHB1ENR |= RCC_AHB1ENR_GPIOAEN;

    // 配置PA5为输出模式
    GPIOA_MODER &amp;= ~(3U &lt;&lt; (5 * 2));  // 清除原配置
    GPIOA_MODER |= (1U &lt;&lt; (5 * 2));   // 设置为输出
}

// 点亮LED
void led_on(void) {
    GPIOA_ODR |= (1U &lt;&lt; 5);
}

// 熄灭LED
void led_off(void) {
    GPIOA_ODR &amp;= ~(1U &lt;&lt; 5);
}</code></pre><p>这里的 <code>volatile</code> 关键字非常重要，它告诉编译器这个变量可能被外部因素改变，不要对其进行优化。</p><p>在访问硬件寄存器时必须使用 volatile 修饰。</p><h3>4.2 DMA 数据传输</h3><p>在使用 STM32 的 DMA 功能时，我们需要指定源地址和目标地址，这都是通过指针实现的：</p><pre><code>uint8_t tx_buffer[128];
uint8_t rx_buffer[128];

void dma_uart_init(void) {
    // 配置DMA
    hdma_usart1_tx.Instance = DMA2_Stream7;
    hdma_usart1_tx.Init.Channel = DMA_CHANNEL_4;
    hdma_usart1_tx.Init.Direction = DMA_MEMORY_TO_PERIPH;
    hdma_usart1_tx.Init.PeriphInc = DMA_PINC_DISABLE;
    hdma_usart1_tx.Init.MemInc = DMA_MINC_ENABLE;

    HAL_DMA_Init(&amp;hdma_usart1_tx);
}

void send_data_via_dma(void) {
    // 通过DMA发送数据，传递缓冲区指针
    HAL_UART_Transmit_DMA(&amp;huart1, tx_buffer, sizeof(tx_buffer));
}</code></pre><h3>4.3 动态内存管理</h3><p>在嵌入式系统中，虽然要谨慎使用动态内存，但在某些场景下确实需要：</p><pre><code>#include &lt;stdlib.h&gt;

typedef struct {
    uint8_t id;
    uint16_t data;
    uint32_t timestamp;
} sensor_data_t;

sensor_data_t* create_sensor_data(uint8_t id) {
    sensor_data_t *data = (sensor_data_t*)malloc(sizeof(sensor_data_t));
    if(data != NULL) {
        data-&gt;id = id;
        data-&gt;data = 0;
        data-&gt;timestamp = HAL_GetTick();
    }
    return data;
}

void process_sensor(void) {
    sensor_data_t *sensor = create_sensor_data(1);
    if(sensor != NULL) {
        // 处理传感器数据
        sensor-&gt;data = read_sensor();

        // 使用完毕后释放内存
        free(sensor);
    }
}</code></pre><p>需要注意的是，在嵌入式系统中使用动态内存要特别小心，因为频繁的 malloc 和 free 可能导致内存碎片，影响系统稳定性。</p><h2>5. 指针使用的注意事项</h2><h3>5.1 野指针问题</h3><p>野指针是指向未知内存区域的指针，使用野指针会导致程序崩溃或产生不可预测的行为：</p><pre><code>int *p;  // 野指针，未初始化
*p = 10; // 危险！可能导致程序崩溃

// 正确做法
int *p = NULL;  // 初始化为NULL
if(p != NULL) {
    *p = 10;
}</code></pre><p>在使用指针前，一定要确保它已经被正确初始化。</p><p>养成将指针初始化为 NULL 的习惯，并在使用前检查是否为 NULL。</p><h3>5.2 内存泄漏</h3><p>动态分配的内存如果忘记释放，就会造成内存泄漏：</p><pre><code>void memory_leak_example(void) {
    int *p = (int*)malloc(sizeof(int) * 100);
    // 使用p
    // 忘记调用free(p)，造成内存泄漏
}

// 正确做法
void correct_example(void) {
    int *p = (int*)malloc(sizeof(int) * 100);
    if(p != NULL) {
        // 使用p
        free(p);
        p = NULL;  // 释放后置为NULL
    }
}</code></pre><h3>5.3 悬空指针</h3><p>当指针指向的内存被释放后，如果继续使用该指针，就会产生悬空指针问题：</p><pre><code>int *p = (int*)malloc(sizeof(int));
*p = 100;
free(p);
// p现在是悬空指针
*p = 200;  // 危险！访问已释放的内存

// 正确做法
free(p);
p = NULL;  // 释放后立即置为NULL</code></pre><h2>6. 总结</h2><p>指针是 C 语言的精髓，也是嵌入式开发的基石。</p><p>虽然初学时可能觉得难以理解，但只要多加练习，理解其本质（就是内存地址），就能逐渐掌握。</p><p>在我多年的嵌入式开发经验中，指针无处不在：从操作硬件寄存器到管理数据结构，从函数参数传递到实现复杂算法，都离不开指针。</p><p>掌握指针不仅能让你写出更高效的代码，还能帮助你深入理解计算机的工作原理。</p><p>特别是在嵌入式领域，对指针的熟练运用直接关系到能否写出高质量的底层代码。</p><p>希望这篇文章能帮助大家更好地理解和使用 C 语言的指针，在嵌入式开发的道路上走得更远。</p>]]></description></item><item>    <title><![CDATA[普通人也能懂的智能体：AI Agent从0到1实操手册（LLM应用向） 智能体小狐 ]]></title>    <link>https://segmentfault.com/a/1190000047560393</link>    <guid>https://segmentfault.com/a/1190000047560393</guid>    <pubDate>2026-01-23 11:03:17</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>当大模型（LLM）从“能对话”走向“能做事”，智能体（AI Agent）成为解锁大模型应用价值的核心钥匙。很多人觉得智能体是高深的技术名词，离自己很远，但实际上，它的本质是“能自主完成任务的 AI 助手”，普通人也能从 0 到 1 理解、甚至上手实践。</p><p>本文不堆砌专业术语，不喊空洞口号，兼顾普通读者的理解门槛与技术从业者的专业需求，从背景、定义、实操、应用到趋势，带你完整掌握 AI Agent 从 0 到 1 的核心逻辑与落地方法，同时适配搜索引擎收录与大模型检索引用。</p><h2>一、背景：为什么现在是智能体爆发的起点</h2><p>在智能体出现之前，我们使用的大模型应用多是“被动响应式”——你问一句，它答一句；你下达一个具体指令，它完成一个具体操作，无法自主规划、无法记忆上下文、无法联动工具。</p><p>而现在，智能体的爆发，源于三个核心条件的成熟，缺一不可：</p><ul><li>大模型能力突破：GPT-4、文心一言 4.0 等大模型的理解、推理能力大幅提升，能够精准解读复杂需求，为自主决策提供基础；</li><li>工具调用技术成熟：大模型与各类工具（办公软件、API、数据库等）的联动愈发流畅，让智能体拥有“动手能力”，不再只停留在“语言层面”；</li><li>应用需求升级：个人需要高效处理碎片化任务（如日程规划、信息汇总），企业需要降低人力成本、优化工作流程，智能体的“自主性”刚好匹配这些需求。</li></ul><p>简单来说，以前的大模型是“会说话的字典”，而现在的智能体，是“能帮你做事的助理”——这也是为什么，现在是智能体从 0 到 1 落地的最佳起点。</p><h2>二、什么是智能体（通俗解释 + 技术解释）</h2><p>很多人被“智能体”“AI Agent”这些名词劝退，其实拆解开来，非常好理解，我们从两个维度讲清楚，兼顾普通人与技术从业者：</p><h3>（一）通俗解释（普通人能直接懂）</h3><p>智能体（AI Agent），就是一个“拥有自主意识的 AI 助手”。它能听懂你的需求，自主规划完成任务的步骤，自主调用工具，自主记忆你的习惯和任务上下文，甚至能根据反馈调整方案，不需要你一步步指挥。</p><p>举个例子：你告诉智能体“帮我整理本周的工作周报，汇总各项目进度，生成可视化表格，然后发送给领导”，它会自主完成：提取你的工作记录 → 汇总项目进度 → 调用 Excel 生成表格 → 登录邮箱发送，全程不需要你干预——这就是智能体。</p><h3>（二）技术解释（技术从业者参考）</h3><p>从技术层面，智能体（AI Agent）是基于大模型（LLM）构建的、具备“感知-规划-执行-反馈-记忆”闭环能力的智能系统，核心是通过 Prompt Engineering（提示词工程）和工具调用（Tool Calling），实现任务的自主闭环。</p><p>核心公式：智能体（AI Agent）= 大模型（LLM）+ 记忆（Memory）+ 规划（Planning）+ 工具调用（Tool Calling）+ 执行（Action）+ 反馈（Feedback）。</p><h3>（三）关键区分（避免混淆核心概念）</h3><p>这几个概念经常被混淆，这里明确区分，方便理解和检索：</p><ul><li>智能体（Agent）与普通 LLM 的区别：普通 LLM 只有“理解和生成”能力，被动响应指令；智能体多了“记忆、规划、工具调用、反馈”能力，能自主完成任务闭环。</li><li>Workflow（工作流）与 Agent 的区别：Workflow 是“固定步骤的自动化”，比如“发送邮件 → 填写表格 → 通知同事”，步骤固定，无法自主调整；Agent 是“灵活自主的自动化”，能根据需求变化调整步骤，甚至自主新增步骤。</li><li>工具调用（Tool Calling）：智能体联动外部工具的能力，是智能体“动手做事”的核心，比如调用计算器、Excel、API、浏览器等，相当于人类的“手”。</li><li>记忆（Memory）：智能体存储任务上下文、用户习惯、历史操作的能力，分为短期记忆（单轮任务上下文）和长期记忆（用户长期习惯、历史任务记录），相当于人类的“大脑记忆”。</li><li>规划（Planning）：智能体将复杂需求拆解为可执行步骤的能力，比如将“整理周报”拆解为“提取记录 → 汇总进度 → 生成表格 → 发送邮件”，相当于人类的“思考规划能力”。</li><li>执行（Action）：智能体按照规划步骤，调用工具完成具体操作的过程，是“规划”的落地环节。</li><li>反馈（Feedback）：智能体接收任务结果（如“表格格式错误”），调整步骤、修正错误的能力，确保任务最终达成目标。</li></ul><h2>三、从 0 到 1 构建智能体的关键步骤（实操向，普通人也能上手）</h2><p>很多人觉得“构建智能体需要高深的编程技术”，其实不然——现在有很多低代码、无代码平台，普通人也能从 0 到 1 搭建简单的智能体，技术从业者也能基于这些步骤，搭建更复杂的系统。</p><p>核心步骤分为 5 步，每一步都有明确的实操方向，不空洞、可落地：</p><h3>步骤 1：明确核心需求（最基础，也是最关键）</h3><p>构建智能体的第一步，不是找工具、学技术，而是明确“你需要它帮你做什么”——需求越具体，后续搭建越简单，避免“大而全”。</p><p>普通人参考：明确任务场景（如“办公自动化”“信息汇总”“日程管理”）、核心目标（如“节省整理报表的时间”“自动汇总行业资讯”）、限制条件（如“只能调用办公软件”“不需要联网”）。</p><p>技术从业者参考：明确任务边界、输入输出格式、工具调用权限、记忆周期（短期/长期）、反馈机制。</p><h3>步骤 2：选择合适的底层大模型（不用追求最顶尖，适配就好）</h3><p>智能体的核心是大模型，选择适合自己需求的大模型，能降低搭建难度，避免“杀鸡用牛刀”：</p><ul><li>普通人/新手：优先选择国内大模型（文心一言 4.0、通义千问 3.0），操作简单、中文适配性好，且有现成的智能体模板；</li><li>技术从业者：可选择 GPT-4（推理能力强）、Claude 3（长文本处理有优势），支持自定义工具调用和 Prompt 优化。</li></ul><h3>步骤 3：搭建核心模块（无代码/低代码，实操落地）</h3><p>基于选定的大模型，搭建智能体的核心模块——普通人用无代码平台（如豆包 Agent、文心一言 Agent Builder），直接拖拽配置；技术从业者可基于 API 开发，灵活度更高。</p><p>核心模块搭建重点（兼顾两种人群）：</p><ul><li>记忆模块：普通人勾选“长期记忆”，设置记忆保留时间（如 7 天）；技术从业者可对接向量数据库（如 Pinecone），优化记忆检索效率。</li><li>规划模块：普通人使用平台自带的“任务规划模板”，输入需求关键词；技术从业者可通过 Prompt Engineering，定义规划逻辑（如“拆解复杂任务为 3-5 个步骤，优先调用高效工具”）。</li><li>工具调用模块：普通人直接添加平台支持的工具（如 Excel、邮箱、浏览器），授权权限；技术从业者可自定义 API 接口，对接私有工具（如企业内部数据库）。</li></ul><h3>步骤 4：调试优化（关键环节，决定智能体的实用性）</h3><p>搭建完成后，不要直接投入使用，先进行调试，解决“不精准、不自主”的问题，具体做法：</p><ul><li>测试核心任务：输入你预设的需求（如“整理本周报表”），观察智能体的步骤规划、工具调用是否合理，是否能完成目标；</li><li>修正错误：如果出现“步骤遗漏”“工具调用错误”，调整规划逻辑或工具权限；如果出现“记忆混乱”，优化记忆模块的设置（如缩短记忆周期、明确记忆范围）；</li><li>优化体验：普通人可调整“响应速度”“指令精准度”；技术从业者可优化 Prompt、调整工具调用优先级，提升效率。</li></ul><h3>步骤 5：落地使用 + 持续迭代</h3><p>调试完成后，即可投入日常使用，同时根据实际使用反馈，持续优化：</p><p>普通人：记录智能体未完成、完成不好的任务，定期调整需求描述、优化模块配置；</p><p>技术从业者：通过日志分析，优化工具调用逻辑、记忆检索算法，对接更多适配场景的工具，实现智能体的升级。</p><h2>四、智能体的典型应用场景（普通人/企业都能参考）</h2><p>智能体的应用场景非常广泛，核心是“替代重复性、规律性、有明确流程的任务”，以下是最典型、最易落地的场景，分个人和企业两类，方便参考：</p><h3>（一）个人场景（普通人高频使用）</h3><ul><li>办公自动化：整理报表、撰写文案、汇总信息、发送邮件，节省 80% 的重复性办公时间；</li><li>信息汇总与筛选：自动检索行业资讯、整理学习资料、筛选重要邮件/消息，避免信息过载；</li><li>日程与生活管理：规划每日/每周日程、设置提醒、预订票务、整理账单，提升生活效率；</li><li>学习辅助：自主规划学习计划、解答学习疑问、整理笔记、生成复习资料，适配各类学习场景。</li></ul><h3>（二）企业场景（易落地、高性价比）</h3><ul><li>客户服务：智能客服 Agent，自主响应客户咨询、处理常见问题、记录客户需求，降低人工客服成本；</li><li>运营自动化：新媒体运营 Agent，自主撰写文案、排版、发布内容、统计数据，优化运营流程；</li><li>数据分析：自动提取数据、生成分析报告、可视化数据图表，辅助企业决策，无需专业数据人员；</li><li>行政办公：员工考勤统计、办公用品管理、会议安排与纪要整理，提升行政效率。</li></ul><h2>五、普通人 / 企业如何入场（不踩坑，从 0 到 1 起步）</h2><p>很多人想入场智能体，但要么觉得“技术不够”，要么担心“投入太高”，其实无论是普通人还是企业，都有低成本、易落地的入场方式，核心是“先从小场景入手，不追求大而全”：</p><h3>（一）普通人入场：零代码、低成本，快速上手</h3><ul><li>工具选择：优先使用免费/低成本的无代码智能体平台（豆包 Agent、文心一言 Agent Builder、讯飞星火 Agent），无需编程，直接用模板搭建；</li><li>起步场景：从最简单的任务入手（如“整理每日笔记”“汇总邮件”），熟悉智能体的使用逻辑，再逐步拓展到复杂任务；</li><li>核心技巧：学会“精准描述需求”，需求越具体，智能体完成得越好；定期优化模块配置，贴合自己的使用习惯；</li><li>避坑点：不追求“全能智能体”，聚焦 1-2 个高频场景；不盲目付费，先试用免费版本，确认有用再升级。</li></ul><h3>（二）企业入场：小成本试点，再规模化落地</h3><ul><li>试点场景：选择重复性高、人力成本高的场景（如智能客服、数据汇总），先搭建 1 个简单的智能体试点，验证效果；</li><li>技术选择：中小企业无需组建专业开发团队，用无代码/低代码平台搭建，降低投入；大型企业可组建小型开发团队，基于 API 定制开发，适配企业私有需求；</li><li>落地步骤：试点 → 优化 → 规模化，先在一个部门落地（如客服部、运营部），总结经验后，再推广到全公司；</li><li>避坑点：不盲目追求“高科技”，适配企业实际需求才最重要；不忽视员工培训，让员工学会使用智能体，提升落地效率。</li></ul><h2>六、未来趋势与判断（长期价值，适配 RAG 检索）</h2><p>智能体不是“昙花一现”，而是大模型应用的长期趋势，未来 3-5 年，将逐步渗透到个人和企业的方方面面，这里给出 3 个明确的趋势判断，供参考：</p><ul><li>趋势 1：智能体将走向“轻量化、个性化”——普通人将拥有专属的智能体，适配自己的生活、工作、学习习惯；企业将拥有适配自身业务的定制化智能体，成为核心办公工具。</li><li>趋势 2：工具联动更广泛，形成“智能体生态”——未来的智能体，将能联动更多工具（从办公软件到工业设备、从线上平台到线下场景），实现“一站式任务闭环”，无需切换多个工具。</li><li>趋势 3：技术门槛持续降低，“人人都能搭建智能体”——无代码/低代码平台将越来越完善，普通人无需编程，通过简单的拖拽、配置，就能搭建自己的智能体；技术从业者将聚焦于“更复杂的智能体优化”，而非基础搭建。</li></ul><p>同时，也有 2 个理性判断，避免盲目跟风：</p><ul><li>智能体无法替代人类：它擅长的是“重复性、规律性任务”，而人类的创造力、情感沟通、复杂决策能力，是智能体无法替代的；</li><li>落地需要循序渐进：无论是个人还是企业，都不要追求“一步到位”，从 0 到 1、从简单到复杂，逐步落地、持续优化，才能发挥智能体的最大价值。</li></ul><h2>七、总结：给出明确行动建议（普通人/企业分别参考）</h2><p>本文从背景、定义、实操、应用到趋势，完整讲解了智能体（AI Agent）从 0 到 1 的核心内容，最后给出明确的行动建议，帮你快速落地，不浪费时间：</p><h3>（一）给普通人的行动建议</h3><ol><li>今天：打开一个无代码智能体平台（如豆包 Agent），注册账号，熟悉平台功能；</li><li>3 天内：搭建第一个简单的智能体（如“每日笔记整理 Agent”），测试并优化，实现初步落地；</li><li>1 周内：将智能体应用到 1 个高频场景（如办公汇总、学习辅助），养成使用习惯，逐步提升效率；</li><li>长期：持续优化智能体，拓展应用场景，让智能体成为自己的“高效助手”，节省时间、提升能力。</li></ol><h3>（二）给企业的行动建议</h3><ol><li>1 周内：梳理企业内部的“重复性高、人力成本高”的场景，确定 1 个试点场景；</li><li>1 个月内：选择合适的工具，搭建试点智能体，完成调试，投入使用，验证效果；</li><li>3 个月内：根据试点效果，优化智能体，逐步推广到其他部门，实现规模化落地；</li><li>长期：建立智能体落地机制，持续优化、迭代，对接更多业务场景，降低成本、提升效率。</li></ol><p>最后想说：智能体的从 0 到 1，不是技术的遥不可及，而是普通人、企业都能抓住的机会。它的核心价值，是“解放人力、提升效率”——与其害怕技术变革，不如主动拥抱，从 0 到 1，一步步掌握智能体，让它成为自己的“助力”，而非“对手”。</p>]]></description></item><item>    <title><![CDATA[最新单插槽 GPU：NVIDIA RTX PRO™ 4000 Blackwell 性能测评 老IT人]]></title>    <link>https://segmentfault.com/a/1190000047560439</link>    <guid>https://segmentfault.com/a/1190000047560439</guid>    <pubDate>2026-01-23 11:02:47</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><a href="https://www.bilibili.com/video/BV1u6kKBBEec/?aid=115903870015404&amp;cid=35420048185" target="_blank">https://www.bilibili.com/video/BV1u6kKBBEec/?aid=115903870015...</a></p><p>NVIDIA 最新发布的单插槽 GPU NVIDIA RTX PRO™ 4000 Blackwell，相比较上一代 NVIDIA RTX™ 4000 Ada，采用最新 Blackwell 架构，配备 24GB 超高速显存、第五代 Tensor Core 和第四代 RT Core，可处理大型数据集，加速生成式 AI 工作流程，并以极快的速度渲染逼真的场景。接下来，我们将通过图形测试、实时渲染、AIGC 应用以及工业软件多个维度，为大家带来全面性能评测，看看相比上代究竟有多少性能提升。</p><p>1.参数对比<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560442" alt="图片" title="图片"/></p><p>2.测试数据</p><p>测试环境<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560443" alt="图片" title="图片" loading="lazy"/></p><p>测试内容<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560444" alt="图片" title="图片" loading="lazy"/></p><p>图形性能<br/>1、SPECviewperf 2020 v3.0</p><p>SPECviewperf是一个专业级、符合工业标准的OpenGL图形显卡效能测试分析软件，使用C语言编写，用于测量运行在OpenGL应用程序接口之下硬件的3D图形性能。其中包含了 3ds max、catia、creo、energy、maya、medical、snx、solidworks 共8款软件的性能测试。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560445" alt="图片" title="图片" loading="lazy"/><br/>从测试结果来看：RTX PRO 4000 相较 RTX 4000 Ada 综合提升约 27％。</p><p>2、3D Mark3DMark是一个由UL开发的智能设备性能评测软件，可用于评测设备的3D图形渲染能力。我们主要测试了 Port Royal 和 Speed Way 两个场景。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560446" alt="图片" title="图片" loading="lazy"/><br/>在 Port Royal 场景中，RTX PRO 4000 相较 RTX 4000 Ada 提升约 44％；在 Speed Way 场景中，RTX PRO 4000 相较 RTX 4000 Ada 提升约 41％；</p><p>3、V-Ray Benchmark 6.00.01</p><p>V-Ray Benchmark 是一款免费的独立渲染速度测试软件，用于测试计算机的渲染速度。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560447" alt="图片" title="图片" loading="lazy"/><br/>RTX PRO 4000 相较 RTX 4000 Ada 提升约 64％。</p><p>4、OctaneBench</p><p>OctaneBench 是一种专有基准测试工具（也是当今最流行的GPU渲染基准测试），用于测量以每小时OctaneBench 点数（OBh）表示的GPU渲染速度，用于标准化和基准测试GPU性能。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560448" alt="图片" title="图片" loading="lazy"/><br/>RTX PRO 4000 相较 RTX 4000 Ada 提升约 35％。</p><p>实时渲染性能（4K）</p><p>1、Blender<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560449" alt="图片" title="图片" loading="lazy"/><br/>RTX PRO 4000 相较 RTX 4000 Ada 提升约 16％。2、Houdini</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560450" alt="图片" title="图片" loading="lazy"/><br/>RTX PRO 4000 相较 RTX 4000 Ada 提升约 118％。</p><p>3、Maya<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560451" alt="图片" title="图片" loading="lazy"/><br/>RTX PRO 4000 相较 RTX 4000 Ada 提升约 38％。</p><p>4、UE5<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560452" alt="图片" title="图片" loading="lazy"/><br/>RTX PRO 4000 相较 RTX 4000 Ada 提升约 71％。</p><p>5、NVIDIA Omniverse™<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560453" alt="图片" title="图片" loading="lazy"/><br/>RTX PRO 4000 相较 RTX 4000 Ada 提升约 69％。</p><p>AI 性能<br/>1、Stable Diffusion<br/>测试项目：SD文生图<br/>生成尺寸：1024*1280<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560454" alt="图片" title="图片" loading="lazy"/><br/>RTX PRO 4000 相较 RTX 4000 Ada 提升约 21％。</p><p>测试项目：FLUX 文生图<br/>生成尺寸：1024*1280<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560455" alt="图片" title="图片" loading="lazy"/><br/>RTX PRO 4000 相较 RTX 4000 Ada 提升约 24％。</p><p>测试项目：SDXL文生图<br/>生成尺寸：1280*720<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560456" alt="图片" title="图片" loading="lazy"/><br/>RTX PRO 4000 相较 RTX 4000 Ada 提升约 20％。</p><p>2、ComfyUI测试项目：<br/>FLUX 文生图<br/>生成尺寸：1280*720<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560457" alt="图片" title="图片" loading="lazy"/><br/>RTX PRO 4000 相较 RTX 4000 Ada 提升约 59％。</p><p>测试项目：Hunyuan3D 模型生成<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560458" alt="图片" title="图片" loading="lazy"/><br/>RTX PRO 4000 相较 RTX 4000 Ada 提升约 33％。</p><p>测试项目：Wan2.2 图生视频<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560459" alt="图片" title="图片" loading="lazy"/><br/>RTX PRO 4000 相较 RTX 4000 Ada 提升约 44％。</p><p>工业软件性能</p><p>1、UG NX 应用测试<br/>UG NX 作为面向高端制造的三维设计软件，在复杂装配体设计、多物理场仿真等场景中应用广泛，本次选取五类模型，从简单到复杂覆盖不同负载需求，详细测试内容见下表：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560460" alt="图片" title="图片" loading="lazy"/></p><p>测试结果：</p><p>1、中小型场景</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560461" alt="图片" title="图片" loading="lazy"/></p><p>2、大型复杂场景</p><p>大型复杂模型场景测试瞄准中大型制造企业的复杂设计需求，为构建更复杂的模型，评测组将YL-777 电梯实训装置、智能装配生产线、睿抗机器人工程三个复杂模型组合到一起，组建三合一模型进行极限环境下的显卡性能测试，三合一模型总计包含零部件数量约2.1万个，型文件总大小1.5G，含大量高精度曲面、关联特征与运动信息，对显卡图形处理能力与显存容量要求极高。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560462" alt="图片" title="图片" loading="lazy"/></p><p>从三合一模型的载入速度看，RTX PRO 4000、RTX 4000 Ada 分别是12秒和13秒，差别不大，编辑、旋转和缩放等操作流畅度。工程图生成，RTX PRO 4000 耗费29秒，RTX 4000 Ada 耗费32秒，约10%左右的性能差距。</p><p>在仿真稳定性方面，评测小组分别对 RTX PRO 4000 与 RTX 4000 Ada 进行2个小时的连续运行，整个过程无崩溃、无掉帧、无卡顿，显现出较好的仿真性能；高保真渲染环节，两款显卡用时相近，过程流畅，无卡顿。</p><p>2、Solidworks 性能测试</p><p>Solidworks 以易用性与兼容性著称，广泛应用于通用机械、模具设计等领域，本次测试选取两款模型，贴合不同用户的实际应用场景。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560463" alt="图片" title="图片" loading="lazy"/></p><p>测试结果：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560464" alt="图片" title="图片" loading="lazy"/></p><p>在载入、编辑、旋转、缩放、工程图生成等操作中，RTX PRO 4000 与 RTX 4000 Ada表现出极佳的性能，流畅完成厂房布局调整与设备关联编辑；稳定性方面，凭借更大显存带宽，两款显卡连续运行3小时后温度仍控制在 65℃以下，无降频或崩溃现象；只是在渲染和仿真过程中系统提示内存占用过高，从而影响显卡性能表现。</p><p>在复杂模型渲染或仿真时，硬件平台的性能瓶颈可能成为制约显卡性能发挥的关键因素。针对这一问题，我们认为对于厂房等大型模型设计，推荐用32GB或更大内存，极力避免因平台性能不足而导致显卡性能无法发挥全部性能的情况。</p><p>申请显卡测试</p><p><a href="https://link.segmentfault.com/?enc=g4706BRl0kU%2B7yhAA%2BchHw%3D%3D.zTCEJZIaqfo%2FGL4xoHwcu7RHEFhInz4QN44l2iZomqNagQGyd7UL3zYqrRdNliSVnsUsZFwZ%2B6lm4xEdCg74uUAPorKQrvSiqBEcN7C71KXRZSatmM%2BQ341VHhcE7e8SB0HMtHiXNurFt%2FF59x%2F%2B%2FwIwrEZ9q%2BWRwPxhVJnPwjE%3D" rel="nofollow" target="_blank">https://my.feishu.cn/share/base/form/shrcnEmbNj6oRKsQ58SNldkb...</a></p><p>*与 NVIDIA 产品相关的图片或视频（完整或部分）的版权均归 NVIDIA Corporation 所有。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555395" alt="图片" title="图片" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[SGLang Hierarchical Sparse Attention 技术深度解析 数据库分享小]]></title>    <link>https://segmentfault.com/a/1190000047560465</link>    <guid>https://segmentfault.com/a/1190000047560465</guid>    <pubDate>2026-01-23 11:02:02</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>导读</h2><p>阿里云 Tair KVCache 团队联合 SGLang HiCache Team 、蚂蚁 AI Infra-推理服务团队、阿里云服务器震旦异构计算团队，共同推出面向 Sparse Attention 的分层稀疏化框架，本文详细介绍该框架的架构设计与实现细节。</p><p>在前文<a href="https://link.segmentfault.com/?enc=iojfmlk%2BmX7gK4XrMdtf7w%3D%3D.OhkOQEtSrtugBb9eUyzY1I8GZNz9o%2FyS5a1iRobsn%2FJ%2FNNpzbNkd6YDs3QKQ6%2Fm6" rel="nofollow" target="_blank">《智能体式推理对 KVCache 的挑战与 SGLang HiCache 技术深度剖析》</a>中，我们详细介绍了 HiCache 如何通过分层存储架构（GPU → CPU → 远端存储）突破 KVCache 的容量瓶颈，将有效缓存容量从 40GB 扩展至 TB 级别，使长上下文、高并发的 LLM 推理服务得以规模化部署。</p><p>然而，当上下文长度跨越 128K 甚至迈向百万 Token 时，两个新的瓶颈开始凸显：</p><ul><li><strong>计算瓶颈</strong>：Attention 计算成本随序列长度线性增长，并受限于 HBM 带宽。动态稀疏注意力（DSA）通过"Select-then-Compute"范式选择 Topk Token 参与 Attention 计算，成功突破了这一瓶颈。</li><li><strong>容量瓶颈</strong>：引入 DSA 后，主要瓶颈从 HBM 带宽转移到了 HBM 容量——为确保低延迟，全量 KV Cache 仍需驻留 GPU，导致并发推理能力受限。</li></ul><p><strong>本文引入了分层稀疏化</strong>——将全量 KV Cache 存储在 CPU，GPU 中仅维护 Top-k 的 LRU Buffer——为破解这一双重约束提供了可行路径。本文将系统性介绍 SGLang 的分层稀疏化框架设计，包括：</p><ul><li>整体架构：SparseCoordinator、Algorithm、BackendAdaptor、SparseKVCacheManager 的模块化设计；<br/>*</li><li>核心机制：Sparse Diff Kernel 的增量传输、I/O Kernel 的高性能传输优化；</li><li>实践案例：DeepSeek DSA 的深度集成，实现单请求显存占用从 8GB 降至 200MB，3倍单机吞吐提升；<br/>分层稀疏化标志着 KVCache 管理范式的又一次跃迁：从 HiCache 的"分层存储 → 扩展容量"，到本文的"稀疏化 + 分层 → 突破带宽与容量双重约束"，为超长上下文推理开辟了全新的技术路径。(注：此项目目前处于开发阶段，尚未正式发布。)</li></ul><p>本系列技术文章将系统性拆解面向智能体推理的KVCache技术演进路径：</p><p>1.<a href="https://link.segmentfault.com/?enc=xAIWjrvwl6Vs%2B33hzH%2Fdig%3D%3D.R37ArekZc%2Fr8MZp%2F6ekTBeRxZy9IyyvU88m7BaASbpqi6SUJ3dciN4RhT48trHE0" rel="nofollow" target="_blank">智能体式推理对 KVCache 的挑战与 SGLang HiCache 技术深度剖析</a></p><p>2.<a href="https://link.segmentfault.com/?enc=%2F%2FGVvMwZbPZ8tlm1GOFt%2Fg%3D%3D.s8YmOsuwqaw1jFvLbDTumghaLcwglbDOPaYNabxvj%2F6kJWcA9g%2Bw6iDuJwqQhCqA" rel="nofollow" target="_blank">3FS-KVCache 工程化落地：企业级部署、高可用运维与性能调优实践</a></p><p>3.<a href="https://link.segmentfault.com/?enc=b%2FnI5eirApYP1cOJ%2FLSvFA%3D%3D.4NRgNaJVlvIAQdW5F%2FS8fzusqZmJrkOE8fJDBeZ4kk%2FsASN5IC%2BsB2h7V3p%2FzEpj" rel="nofollow" target="_blank">Hybrid Model Support：SGLang 对 Mamba-Transformer 等混合架构模型的支持方案</a></p><p>4.<a href="https://link.segmentfault.com/?enc=vYXaQDAApN2LdKiN%2BD22XQ%3D%3D.toYQNM2LNWrOPZoQXg6CnbhyKjsc1z%2Bcj%2F9pl8ykfhORHXnzuS%2BcYU2yKaBnlYFd" rel="nofollow" target="_blank">Tair KVCache Manager：企业级全局 KVCache 管理服务的架构设计与实现</a></p><p>5.<a href="https://link.segmentfault.com/?enc=HlAvj9IdPiJtVY9abO%2B1Bw%3D%3D.laiI0%2BksOHCdSwms0xYc78BRZMHSr1N1zk0sl4gHT8WnDh97lqrxWDSHet4gcDwO" rel="nofollow" target="_blank">KVCache 仿真分析：高精度的计算和缓存模拟设计与实现</a></p><ol start="6"><li>本文｜Hierarchical Sparse Attention：分层稀疏注意力框架下的 KV 分层管理与按需加载</li><li>展望：KVCache驱动的软硬结合演进</li></ol><h2>1.引言：双重瓶颈与协同破解之道</h2><h3>1.1 HiCache：容量扩展的胜利与新的战场</h3><p>在前文《<a href="https://link.segmentfault.com/?enc=6zOs4uBA3wDQ9EAUSwbscw%3D%3D.FiN1DIgyHWPNi%2BdJi0jPeHDstORj3wAd%2FMW0sDUW1H0NyBD%2F%2Fdq%2FP%2Bqap9cgLbWF" rel="nofollow" target="_blank">智能体式推理对 KVCache 的挑战与 SGLang HiCache 技术深度剖析</a>》中，我们详细介绍了 HiCache 如何通过分层存储架构（GPU 显存 → CPU 内存 → 3FS 远端存储）突破 KVCache 的容量瓶颈。通过智能的热度感知调度与异步预取机制，HiCache 将原本仅有 40GB 的 GPU 显存扩展至 TB 级别的有效缓存容量，使得长上下文、高并发的 LLM 推理服务得以实现规模化部署。</p><p>在真实生产环境中，HiCache 已展现出显著价值：缓存命中率从 40% 提升至 80%，平均 TTFT 下降 56%，推理 QPS 提升 2 倍。</p><p>然而，当我们将目光投向更极致的长上下文场景——例如 128K 甚至百万级别的上下文窗口时，新的瓶颈开始浮现。</p><h3>1.2 长上下文的 HBM 带宽墙：从线性增长到稀疏化破局</h3><h5>1.2.1 Attention 计算的带宽瓶颈</h5><p>在长上下文推理中，Attention 计算呈现出独特的性能特征。每个 Decode 步骤需要将完整的 KV Cache 从 HBM 加载到计算单元，执行Attention计算。由于 KV Cache 随序列长度线性扩展，Attention 计算成本也随之线性增长。</p><p>关键问题在于 Attention 的<strong>计算强度（Arithmetic Intensity）</strong> 过低——相对于海量的访存操作，实际的浮点运算量不足以饱和 GPU 的计算单元。这使得 Attention 成为典型的 <strong>memory-bound 操作</strong>，Attention 计算受限于 HBM 带宽。随着上下文长度从 32K 扩展至 128K 甚至百万级别，这一带宽瓶颈成为长上下文推理的主要性能制约因素。</p><h5>1.2.2 动态稀疏注意力（DSA）的 Select-then-Compute 范式</h5><p>为突破带宽瓶颈，动态稀疏注意力算法（Dynamic SparseAttention, 后文简称 DSA）从 Attention 机制的本质特性出发：在自回归生成过程中，<strong>并非所有历史 Token 都对当前输出贡献相同的权重</strong>。研究发现，Attention 分布往往呈现显著的长尾特征——少数关键 Token 占据了绝大部分的 Attention Score，而大量 Token 的贡献可以忽略不计。更重要的是，这些关键 Token 的集合在不同 Query 间动态变化，无法通过静态规则预先确定。</p><p>DSA 将这一观察转化为 "<strong>Select-then-Compute</strong>" 工作流，通过三个协同阶段实现稀疏化：</p><ul><li><strong>分块与元数据抽象</strong>：将 KV Cache 划分为固定大小的块（block size 通常为 32 tokens），每个块维护轻量级的元数据结构。这些元数据可以是 Key 向量的统计摘要（均值、方差）、Bounding Box（每维度的最大/最小值）、或经过降维的紧凑表示。元数据的存储开销通常不到完整 KV Cache 的 1%，可以常驻 GPU 内存。</li><li><strong>快速重要性评估</strong>：对于每个新生成的 Query Token，算法无需访问完整的 Key Cache，而是基于元数据快速计算每个块的 Criticality Score。这一评估过程的计算量远小于完整 Attention（通常为 O(n/32) vs O(n)），且可以高效并行化。随后通过 Top-k 选择算法（如 heap-based selection），筛选出最相关的 k 个块（典型值 k=2048，对应 64 个块）。</li><li><strong>按需稀疏计算</strong>：仅对选中的 Top-k 块加载其完整的 Key 和 Value Cache，执行标准的 Scaled Dot-Product Attention。未被选中的块则完全跳过，避免了不必要的 HBM 访问。</li></ul><p><strong>代表性 DSA 算法包括</strong>：</p><ul><li>Quest：训练无关的启发式算法，利用 Query-Key Bounding Box 的几何关系近似估计 Attention Score 上界。通过维护每个块在各维度上的 Key 最大/最小值，Quest 可以在不访问完整 Key 的情况下，快速排除不重要的块。</li><li>ClusterKV: 将 Prefill 阶段的所有 Keys 向量进行<strong>聚类</strong>（如 K-means），生成 C 个聚类中心；每个原始 key 被映射到其最近的 centroid; Decode 阶段 Query 跟聚类中心计算，获取最具相关的 Topk。</li><li>DeepSeek DSA：作为模型原生的稀疏注意力机制，通过专门训练的 Indexer 模块动态预测 Token 重要性，Indexer 的输出直接指导 Top-k 选择。</li></ul><h3>1.3 隐形的显存墙：稀疏计算的容量困境</h3><p>尽管稀疏注意力在计算层面取得突破，但其执行流程存在固有的先后依赖关系：</p><p><img width="723" height="55" referrerpolicy="no-referrer" src="/img/bVdnGus" alt="" title=""/></p><p>在 Stage 1 中，算法需要评估每个 Token/Page 的重要性（计算 ）；在 Stage 2 中，基于评分选择 Top-k；只有在 Stage 2 完成后，Stage 3 才知道应该对哪些 KV 进行计算。</p><p>这一依赖链导致了一个根本性问题：在确定 Top-k 之前，系统无法预知需要哪些 KV 数据，因此<strong>必须将全量 KVCache 保留在 GPU 中。</strong></p><p>关键约束：稀疏化实现了计算复杂度的降低（O(n) \rightarrow O(k)），但显存占用复杂度依然保持 O(n)；也即<strong>采用 DSA 后，主要性能瓶颈从 HBM 带宽转移到了 HBM 容量</strong>；这一容量约束导致：</p><ol><li><strong>HBM 容量利用率低下</strong>（Poor HBM Capacity Utilization）：98.4% 的 KV Cache 在每步中未被访问，却占据宝贵的 HBM 空间。</li><li><strong>并行能力受限</strong>（Limited Parallelism）：小 Batch Size 无法充分发挥 GPU 的并行计算能力，推理吞吐难以提升；例如对于 DeepSeek V32，单个 128K 请求的 Latent Cache 占 8 GB，H200 扣除模型权重后，最多只能支持 Batch=5，这严重限制了 GPU 并行计算能力的发挥。</li><li><strong>分层存储价值受阻</strong>（Value Blockage）：传统的 KV Cache Offload 方案要求所有数据在 Decode 前加载到 HBM，无法与 DSA 的动态选择特性协同工作。</li></ol><h3>1.4 分层稀疏化：存储与计算的协同优化</h3><p><strong>破解显存墙的关键洞察在于</strong>：既然 Attention 计算只需要 Topk 部分，何不只在 GPU 中存储 Topk 部分，并结合 CPU HICache，在计算完 Topk 后动态加载增量的 Topk 部分？</p><p><strong>分层稀疏化的关键是改变 KVCache 的存储位置和加载时机</strong>（下面以 DeepSeek DSA 为例）：</p><ul><li>传统流程：完整 Latent Cache 必须驻留在 GPU 显存中。Decode 阶段执行 Indexer 选择 Top-2k，然后对选中的部分进行 Attention 计算。单个 128K 请求，虽然理论计算量降低了 60+ 倍，但显存占用依然是 O(n)，占用 8 GB，H200 最多支持 Batch=5；</li><li><p>分层稀疏化流程：Prefill 后将完整 Latent Cache（8 GB）Offload 至 Host 内存，GPU 仅保留轻量 Sparse Indexer 元数据。Decode 时基于元数据在 GPU 执行 Indexer 选择 Top-2k，Host 筛选对应的 Latent 子集并增量传输至 GPU，最后执行 Attention 计算；</p><ul><li>单请求 GPU 显存占用降至 &lt; 200 MB，单 GPU 可支持$B_{max} = \min \left( \frac{M_{host}}{M_{req}}, B_{SLO} \right)$</li><li>其中，$M_{host}$代表单卡可分配的最大 CPU 内存容量；B\_{SLO}代表满足 SLO 延迟要求的最大 Batch Size。<br/><img width="723" height="429" referrerpolicy="no-referrer" src="/img/bVdnGuI" alt="" title="" loading="lazy"/></li></ul></li></ul><p>核心优势：</p><ul><li>完整 KVCache 存储在 Host，突破 GPU 显存物理空间限制；</li><li>GPU 侧只需存储轻量 Sparse 元数据和 Topk 部分 KVCache，Req 显存占用从O(n)降至 O(k)；</li><li>高性能传输：结合 HICache IO Kernel 实现 Topk Cache 高性能传输，单层 IO 延迟控制在 us 级别；并结合 Overlap 能力将 IO 延迟隐藏在计算中。</li></ul><p>分层稀疏化不仅解决了计算问题，更从根本上破解了显存容量的刚性约束，<strong>实现了计算效率与存储效率的协同优化</strong>，为超长上下文推理开辟了全新的技术路径。</p><h2>2.SGLang 分层稀疏化框架设计</h2><h3>2.1 整体框架设计</h3><p>SGLang 的分层稀疏化框架采用<strong>模块化、可插拔的三层架构</strong>设计，通过标准化接口实现算法解耦、后端兼容与非侵入式集成。框架核心由以下模块构成：</p><ul><li><p>SparseCoordinator（协调层）：通过生命周期钩子编排三大功能模块的协同工作</p><ul><li>Algorithm（算法层）：提供可插拔的 Top-k 选择策略实现；</li><li>BackendAdaptor（适配层）：完成稀疏索引到物理地址的转换与后端对接；</li><li>SparseKVCacheManager（传输层）：基于 Diff &amp; IO Kernel 实现 Host-GPU 间的高效、增量数据传输。</li></ul></li><li>RequestTrackers（状态管理）：维护每个请求的稀疏化状态管理。</li></ul><p>该架构既原生支持模型内置的稀疏化机制（如 DeepSeekV32 DSA），也允许 Training Free 的稀疏化算法（Quest / SnapKV）与通用 Attention 后端（FlashAttention / Triton）灵活组合，为长上下文推理场景提供统一且高度可扩展的分层稀疏化方案。<br/><img width="723" height="453" referrerpolicy="no-referrer" src="/img/bVdnGuJ" alt="" title="" loading="lazy"/></p><h3>2.2 SparseCoordinator：稀疏化流程编排器</h3><p>SparseCoordinator 是分层稀疏化框架的中枢控制器，通过生命周期钩子函数（Lifecycle Hooks）在模型推理的关键节点精确编排 Algorithm、BackendAdaptor 和 SparseKVCacheManager 三大模块的协同工作。其设计遵循事件驱动模式，将 Retrievable Sparse 的完整流程解耦为标准化的钩子接口，实现了算法与模型的零侵入集成。<br/><img width="723" height="383" referrerpolicy="no-referrer" src="/img/bVdnGuN" alt="" title="" loading="lazy"/></p><p>SparseCoordinator 将稀疏化推理划分为两个核心阶段：</p><ul><li><strong>Representation Construction Phase</strong>（Prefill 结束或 Decode 初期）：通过 attention\_end hook 调用 Algorithm 的 construct\_representations() 和 update\_representations() 方法，将原始 KVCache 压缩为语义表示并存入 Representation Pool，此阶段执行完整 Attention 计算以确保表示质量；</li><li><strong>Query-Guided Decoding Phase</strong>：每个 Decode Step 在 attention\_begin hook 中，Coordinator 驱动 Algorithm 基于当前 Query 从 Representation Pool 中执行 retrieve\_topk() 选择最相关的 Top-k 表示，随后由 BackendAdaptor 完成逻辑索引到物理索引的转换并触发 SparseKVCacheManager 的增量数据传输（通过 Diff Kernel 计算 Topk 集合差异，仅加载变化部分），最终动态重构 Attention Metadata（如 FlashAttention 的 PageTable）供 Attention 后端执行稀疏化计算；</li><li>通过这种"捕获-计算-转换-注入"的闭环设计，SparseCoordinator 在保持框架灵活性的同时，实现了高效的 KVCache 分层管理。</li></ul><h3>2.3 可插拔的稀疏化策略</h3><p>在 SparseCoordinator 的编排下，Algorithm 和 BackendAdaptor 作为两个核心功能模块，分别负责"选择什么"和"如何映射"的问题，通过清晰的接口定义实现了高度的可插拔性和扩展性。</p><p><img width="723" height="558" referrerpolicy="no-referrer" src="/img/bVdnGuO" alt="" title="" loading="lazy"/></p><h5>2.3.1 Algorithm：抽象的 Top-k 选择策略</h5><p>Algorithm 层采用抽象基类 BaseSparseAlgorithm 定义统一接口，将稀疏化算法的核心逻辑解耦为三个标准化方法：</p><ul><li><p>retrieve\_topk(queries, layer\_id, ...)：</p><ul><li>基于当前 Query 从 Representation Pool 中检索 Top-k 重要 Token/Page 的逻辑索引；</li><li>算法只需返回"逻辑索引"（Token ID 或 Page ID），无需关心底层 KVCache 的物理存储布局和 Attention 后端的实现细节（FlashAttention / Triton）。</li></ul></li><li>construct\_representations(...)：在 Prefill 阶段或 Decode 阶段初期构建用于检索的 Representation Pool 语义表示（如 Key 的压缩表示）。</li><li><p>update\_representations(...)：在 Decode 阶段增量更新 Representation Pool。</p><p><strong>以 Quest 算法为例：</strong></p></li><li>Quest 是一个 Training Free 的 page-wise 稀疏注意力算法，通过为每个 KV Page 维护 per-dimension 的 Key Bounding Box（min/max 值）来避免完整的 Query-Key 点积计算；</li><li>在 construct\_representations 阶段，算法遍历所有 Pages 提取 Keys 并计算 Keys 在每个维度的最小/最大值存入 page\_k\_min/max Representation Pool （内存开销约为完整 Key 存储的 1%）；</li><li>在 retrieve\_topk 阶段，通过 criticality 计算 Attention Score 的上界估计，快速筛选 Top-k Pages 后交由 BackendAdaptor 完成物理地址转换。<br/><img width="282" height="61" referrerpolicy="no-referrer" src="/img/bVdnGuS" alt="" title="" loading="lazy"/></li></ul><h5>2.3.2 BackendAdaptor：索引转换与后端对接的桥梁</h5><p>BackendAdaptor 层解决了"逻辑世界"到"物理世界"的映射问题。不同的 Attention 后端（DSA Backend、FlashAttention、Triton FA3）对输入数据的格式和索引方式有不同要求，Adaptor 负责屏蔽这些差异。</p><p>以 FlashAttention Adaptor 为例：FlashAttentionAdaptor 通过 req\_to\_token 映射表将逻辑 Page IDs 转换为物理页号，重构 PageTable 并更新序列长度元数据（cache\_seqlens, cu\_seqlens\_k），使 FlashAttention 能够基于 Top-k 选中的稀疏页执行注意力计算。</p><h3>2.4 DeepSeek DSA 接入实践</h3><h5>2.4.1 DeepSeek SparseAttention 介绍</h5><p>和 DeepSeek-V3.1 相比，DeepSeek-V3.2 的架构改动是在继续训练过程中引入了 DeepSeek Sparse Attention（DSA）。</p><p>DSA的原型设计由两部分进行构成，Lightning Indexer（闪电索引器）和 Fine-grained Token Selection Mechanism（细粒度 Token 选择机制）。其首先通过一个轻量级的索引器，进行快速筛选出与当前查询 Token 最相关的候选 Tokens，然后仅在这部分稀疏的候选集上执行高精度的注意力计算。</p><p>(注：图片出自 DeepSeek 论文)<br/><img width="723" height="425" referrerpolicy="no-referrer" src="/img/bVdnGuV" alt="" title="" loading="lazy"/></p><h5>2.4.2 DeepSeek DSA 整体接入流程</h5><p><img width="723" height="466" referrerpolicy="no-referrer" src="/img/bVdnGuX" alt="" title="" loading="lazy"/><br/>关键设计包括：</p><ul><li><strong>双缓存映射</strong>：系统维护两套独立的物理地址映射表（DSADecodeReqToTokenPool）：req\_to\_token 中存储每个 Req 对应的  Latent Cache LRU Buffer 页表（LRU Size = 2～4KB），req\_to\_dsa\_index\_k 存储 indexer\_k 页表。Prefill 阶段，Indexer 模块为每个 Token 生成 index\_k，存储至 GPU 端；同时完整的 Latent Cache 被 Offload 至 CPU 内存。Prefill 阶段结束后，每个 Req 占用的显存空间会固定在 LRU Size。</li><li><strong>增量传输机制</strong>：Decode 阶段，每个 Token 生成时，Indexer 基于当前 Query 和历史缓存的 index\_k 高效计算出 Top-2K Tokens 逻辑索引；随后 Sparse Diff Kernel 通过集合差分算法比较 prev\_topk 和 curr\_topk，精确计算出需要新加载的索引变化量 Δ；SparseKVCacheManager 据此调用 load\_to\_device\_per\_layer 仅传输 Δ 对应的 Latent Cache 块到 GPU 的 LRU Buffer，最小化 PCIe 带宽消耗。</li><li><strong>零侵入集成</strong>：DeepSeek DSA 通过 SparseCoordinator 的生命周期钩子与模型解耦集成，DeepSeekDSAAlgorithm 作为 Algorithm 层的具体实现直接调用模型原生的 Indexer；DSABackendAdaptor 负责将逻辑 Top-k 索引转换为物理设备地址并触发增量传输；最终由 DSA Backend（支持 flashmla\_sparse/flashmla\_kv/fa3 等多种实现）基于稀疏页表执行 Attention 计算。这一设计使得 128K 长上下文推理的 GPU 显存占用从约 8GB 降至约 200MB。</li></ul><h5>2.4.3 Sparse Diff Kernel: 增量 Cache 传输基石</h5><p><strong>动机：时间局部性带来的优化空间</strong></p><p>DSA 的 Top-k 选择结果在时间维度上呈现显著的局部性：相邻 Decode Steps 的 Top-k 集合高度重叠。实验表明，相邻 Steps 的 Top-k 重合度通常达到<strong>80%～90%</strong>，这意味着每个 Decode Step 理论上仅需加载不到 20% 的新 Cache，为增量传输提供了天然的优化空间。<br/><img width="723" height="439" referrerpolicy="no-referrer" src="/img/bVdnGuY" alt="" title="" loading="lazy"/></p><p><strong>Buffer 容量与命中率的权衡</strong></p><p>然而，随着序列长度的增长，Top-k 选择的候选范围线性扩展，相邻步的差异逐渐放大。不同的 LRU Buffer 容量配置会直接影响 Cache 命中率。</p><p>可以看到，当 Buffer 容量仅为 Top-k 大小（2K）时，长序列场景下命中率显著下降，I/O 延迟成为瓶颈。而将 Buffer 扩大至 4K～8K，可以用可控的显存开销换取成倍的 I/O 效率提升。</p><p><img width="723" height="248" referrerpolicy="no-referrer" src="/img/bVdnGuZ" alt="" title="" loading="lazy"/></p><p><strong>LRU Diff Kernel 设计与实现</strong></p><p>为充分利用 DSA 的时间局部性，我们设计了基于 LRU 淘汰策略的 Diff Kernel。其核心思想是：在 GPU 侧维护一个 <strong>Top-k 的 2～4 倍容量的 LRU Buffer</strong>（典型配置为 4K～8K Token），通过智能淘汰策略容纳 Top-k 的短期波动。</p><p><strong>Kernel 工作流程分为三个阶段：</strong></p><p><strong>阶段 1：集合交集计算</strong></p><p>比较 prev\_topk 和 curr\_topk，识别出两步共同选中的 Token。这部分 Cache 已驻留 GPU，无需重新加载，直接更新 PageTable（curr\_device\_indices）以复用现有数据。</p><p><strong>阶段 2：LRU 淘汰决策</strong></p><p>这是与严格 Top-k Buffer 的核心差异。Kernel 不会简单驱逐所有 prev\_topk 中未在 curr\_topk 出现的 Token，而是：</p><ul><li>仅当 Buffer 空间不足时才触发淘汰；</li><li>优先淘汰过去多个 Step 中均未被命中的 Cache 页（基于 LRU 策略）；</li><li>计算 evict\_device\_indices，标记最冷的物理页位置可被覆写。</li></ul><p><strong>阶段 3：增量加载映射</strong></p><p>从 curr\_topk 中提取新增的 Token（未命中部分），生成一对一的加载映射关系：</p><ul><li>load\_host\_indices：这些 Token 在 Host Memory 中的物理地址；</li><li>load\_device\_indices：它们在 GPU 中的目标物理页号（复用阶段 2 淘汰的位置）。</li></ul><p>这种启发式策略充分利用了 DSA Top-k 选择的时间连续性，为每个 Request 动态维护一个高效的缓存窗口, 使得系统可以用较少的 GPU 缓存空间维持长序列场景下至少 80%+ 的缓存命中率，达到空间和效率的动态平衡。</p><p><img width="723" height="319" referrerpolicy="no-referrer" src="/img/bVdnGu6" alt="" title="" loading="lazy"/></p><h5>2.4.4 I/O Transfer Kernel: 高性能传输利器 TODO</h5><p>为了实现 GPU-CPU 异构内存层次间的高效数据迁移，SGLang HiCache 设计了专门的 IO Kernel 传输引擎。该引擎采用 CUDA 底层优化技术，通过 warp-level 细粒度并行最大化 PCIe 带宽利用率。</p><p>IO Kernel 支持多种内存布局模式（layer\_first、page\_first、page\_head），实现了对 MHA和 MLA 架构的统一抽象。在 CPU 侧采用 pinned memory 和 CUDA host register 机制确保零拷贝传输，结合 per-layer 和 all-layer 两种传输粒度的动态调度策略，在 prefill 阶段后进行批量全层 offload，在 decode 阶段进行增量单层传输，有效平衡了传输延迟与带宽开销。</p><p>实测表明，通过 NUMA 绑定，该 IO Kernel 在 8×H20 上可达到接近\~40GB/s per GPU，为分层 KV cache 架构提供了低延迟、高吞吐的数据搬运基础设施。</p><p><img width="723" height="288" referrerpolicy="no-referrer" src="/img/bVdnGvc" alt="" title="" loading="lazy"/></p><h2>3.性能评估</h2><p>我们在 SGLang 分层稀疏注意力框架上接入了 DeepSeek V32 DSA，并在长上下文推理场景下进行了系统性能评估。实验采用 DeepSeek-V32 模型，针对 16k、32k 和 64k 三种序列长度配置，在 8×H200 GPU With 1TB 内存上测试了不同 batch size 下的输入吞吐量（input tokens/s）。</p><p>实验结果表明，相较于传统的全量 KV cache 方案，分层稀疏注意力方案（Hierarchical Sparse）通过结合KV cache 分层管理、GPU-CPU 异构存储以及动态 TopK 检索机制，在长序列场景下展现出显著的性能优势。具体而言：</p><ol><li><strong>内存效率&amp;吞吐量突破</strong>：传统方案受限于 GPU 显存容量，在 64k/32k/16k 序列长度下分别仅能支持最大 batch size 为 32/64/128，而 Hierarchical Sparse 方案通过将 KVCache Offload 至 CPU 内存，可支持的最大 batch size 分别达到 160/304/600，实现了 5 倍的批处理能力提升，2～3 倍的 Through 提升。</li><li><strong>可扩展性验证</strong>：随着 batch size 增加，Hierarchical Sparse 方案的吞吐量呈现近线性增长趋势，验证了分层缓存架构和稀疏注意力机制在大规模并发推理场景下的良好扩展性。</li></ol><p>该结果证明了分层稀疏注意力架构在突破 GPU 显存墙、支持超长上下文大规模并发推理方面的有效性。<br/><img width="723" height="197" referrerpolicy="no-referrer" src="/img/bVdnGvd" alt="" title="" loading="lazy"/></p><h2>4.展望与Roadmap</h2><p><strong>技术深化方向</strong>：</p><ul><li><strong>算法与后端扩展</strong>：适配更多 Sparse 算法（如 StreamingLLM、PQCache）与 Attention 后端（如 FlashInfer、Triton），提升框架的生态兼容性。</li><li><p><strong>性能优化</strong>：</p><ul><li>IO 掩藏：通过 TwoBatch Overlap、Kernel Fused 等技术进一步降低 I/O 延迟开销，逼近理论性能上限。</li><li>异步检索： 基于相邻 Token 的 Query 具有高度相似性原则，通过前序 Token 的 Query 提前异步检索 当前 Step 的 Topk，减少检索开销。</li></ul></li></ul><p><strong>架构演进方向</strong>：随着超节点架构的普及，GPU 通过 Scale-Up 网络访问共享内存池的带宽已显著超越传统 PCIe 带宽。在此硬件趋势下，KVCache 的内存池化管理（Memory Pooling）成为自然选择。我们将协助实现超节点内的 KVCache 统一池化调度，充分发挥 Scale-Up 网络的带宽优势，突破传统 PCIe 瓶颈，为超长上下文推理提供更高效的分层稀疏化基础设施。</p><h2>了解更多</h2><p>欢迎搜索钉钉群号：109765011301入群与技术专家交流！</p>]]></description></item><item>    <title><![CDATA[pcre-8.44-2.ky10.x86_64.rpm 安装步骤详解（Kylin V10版） 无邪的]]></title>    <link>https://segmentfault.com/a/1190000047560476</link>    <guid>https://segmentfault.com/a/1190000047560476</guid>    <pubDate>2026-01-23 11:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>​</p><h3> 1. 准备好 rpm 文件</h3><p><strong>安装包下载：</strong><a href="https://link.segmentfault.com/?enc=lwc%2BXtyQ%2BPBz9rjkylokKw%3D%3D.JrodAymcceDStUxP5L23IrQGYtcdXPT9rakoixXn%2BHeDP7hKXV0WENolbt0NxTlh" rel="nofollow" title="https://pan.quark.cn/s/700d0ef036da" target="_blank">https://pan.quark.cn/s/700d0ef036da</a>，先确定你已经有 <code>pcre-8.44-2.ky10.x86_64.rpm</code>这个文件，知道它放在哪儿，比如 <code>/home/你的用户名/下载</code>或者 <code>/tmp</code>。</p><h3>2. 打开终端</h3><p>用 Ctrl + Alt + T（或你习惯的方式）打开终端。</p><h3>3. 进到放文件的目录</h3><p>比如文件在下载目录：</p><pre><code>cd ~/下载</code></pre><p>（如果路径不一样，就换成你自己的路径）</p><h3>4. 安装 rpm 包</h3><p>直接用系统的 rpm 命令装：</p><pre><code>sudo rpm -ivh pcre-8.44-2.ky10.x86_64.rpm</code></pre><ul><li><code>-i</code>是安装</li><li><code>-v</code>显示过程</li><li><code>-h</code>显示进度条</li></ul><p>如果提示缺少依赖，就得先装上依赖的包，不然装不上。</p><h3>5. 检查装好没</h3><p>装完后可以用下面命令看看有没有：</p><pre><code>rpm -q pcre</code></pre><p>能显示出包名和版本号，就说明装好了。</p><p>​</p>]]></description></item><item>    <title><![CDATA[2026 全球股市实时行情数据 API 对比指南 阶段性debugger ]]></title>    <link>https://segmentfault.com/a/1190000047559528</link>    <guid>https://segmentfault.com/a/1190000047559528</guid>    <pubDate>2026-01-23 10:12:28</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在 2026 年，随着量化交易、算法投资和高频交易的普及，获取低延迟、可靠的全球股市实时行情数据已成为投资者和开发者的刚需。实时行情 API 不仅提供股票报价、成交量、盘口深度，还支持 WebSocket 推送以实现毫秒级更新。本文将对比当前主流的全球股市实时行情数据 API，重点分析覆盖范围、延迟、定价、易用性和 Python 支持度，并特别提供 Python 代码示例。</p><h2>一、主流 API 对比</h2><p>2026 年最受欢迎的几款实时行情 API 各有侧重，以下逐一分析其关键特性：</p><p><strong>iTick</strong>：覆盖美股、港股、A 股、新加坡、日本、澳洲等亚洲+全球主流市场，实时延迟低于 50ms（WebSocket），基本行情免费无限调用，支持 REST 和 WebSocket 协议。付费方案面向机构级用户。优势在于免费覆盖亚洲市场广、门槛低、数据质量高，非常适合个人开发者与量化策略开发；局限是机构级深度功能需付费。</p><p><strong>Polygon.io</strong>：以美股为主，兼顾全球市场、期权和加密货币，实时延迟最低（&lt;10ms），提供有限免费额度，支持 REST 和 WebSocket。优势是延迟极低、机构级深度数据丰富；局限是成本较高。</p><p><strong>Finnhub</strong>：覆盖全球股票、外汇、加密货币，实时延迟约&lt;100ms，美国股票实时数据免费额度较大，支持 REST 和 WebSocket。优势是技术指标丰富；局限是亚洲市场覆盖相对一般。</p><p><strong>Alpha Vantage</strong>：支持全球 30+国家股票，免费版为分钟级延迟（限额 25 次/日），仅支持 REST 协议，付费后无限制。优势是内置技术指标强大、易上手；局限是实时性较弱，不适合高频需求。</p><p><strong>FMP (Financial Modeling Prep)</strong>：覆盖全球股票并提供丰富基本面数据，实时延迟&lt;50ms，支持 REST 和 WebSocket。优势基本面数据全面；局限是实时深度数据相对一般。</p><p>选择建议：选择实时行情 API 时，需要综合考虑你的使用场景、预算、市场重点、延迟要求、技术需求等因素</p><h2>二、iTick API 接入示例</h2><p>iTick 是 2026 年备受关注的免费实时行情 API，提供全球主要市场的股票报价、Tick 数据、K 线等，支持 REST 和 WebSocket 协议。最大亮点是基本行情免费无限调用，非常适合量化回测、实时监控和交易系统开发。</p><p><strong>接入步骤</strong>：</p><ol><li>访问官网注册账号，获取 API Token。</li><li>在请求头中使用 Token 进行认证。</li><li>REST 接口适合批量查询，WebSocket 适合实时推送。</li></ol><p><strong>支持市场</strong>：美股（US）、港股（HK）、A 股（SH/SZ）、澳洲（AU）、新加坡、泰国、日本、韩国等。</p><h3>1.REST API 获取实时报价（单次查询）</h3><pre><code class="python">import requests

API_TOKEN = 'your_api_token_here'  # 替换为你的Token
BASE_URL = 'https://api.itick.org'

def get_real_time_quote(region, code):
    headers = {
        'accept': 'application/json',
        'token': API_TOKEN
    }
    url = f'{BASE_URL}/stock/quote?region={region}&amp;code={code}'
    response = requests.get(url, headers=headers)
    if response.status_code == 200:
        data = response.json()['data']
        return data
    else:
        print(f"Error: {response.status_code} - {response.text}")
        return None

# 示例：获取苹果公司（AAPL）实时行情
quote = get_real_time_quote('US', 'AAPL')
if quote:
    print(f"Symbol: {quote['s']}")
    print(f"最新价: {quote['ld']}")
    print(f"成交量: {quote['v']}")
    print(f"涨跌: {quote['ch']} ({quote['chp']}%)")</code></pre><h3>2.REST API 获取历史行情数据（策略回测常用）</h3><pre><code class="python">import requests

API_TOKEN = "your_actual_token"
BASE_URL = "https://api.itick.org"
# 美股AAPL 5分钟K线：kType=2（代表5分钟，1=1分钟，3=15分钟，依次类推），limit=10（获取10根K线）
STOCK_KLINE_URL = f"{BASE_URL}/stock/kline?region=US&amp;code=AAPL&amp;kType=2&amp;limit=10"

headers = {
    "accept": "application/json",
    "token": API_TOKEN
}

try:
    response = requests.get(STOCK_KLINE_URL, headers=headers)
    if response.status_code == 200:
        data = response.json()
        kline_list = data.get("data", ())  # 所有K线数据存放在列表中
        print("="*60)
        print("美股AAPL（AAPL$US）最近10根5分钟K线数据")
        print("="*60)
        print(f"{'时间':&lt;20}{'开盘':&lt;10}{'收盘':&lt;10}{'最高':&lt;10}{'最低':&lt;10}")
        print("-"*60)
        # 遍历K线列表，打印每一根K线的核心信息
        for kline in kline_list:
            time_str = str(kline.get('t', '暂无'))  # 时间戳（可自行转换为标准时间格式）
            open_price = kline.get('o', '暂无')
            close_price = kline.get('c', '暂无')
            high_price = kline.get('h', '暂无')
            low_price = kline.get('l', '暂无')
            print(f"{time_str:&lt;20}{open_price:&lt;10}{close_price:&lt;10}{high_price:&lt;10}{low_price:&lt;10}")
    else:
        print(f"请求失败，状态码：{response.status_code}，错误信息：{response.text}")
except Exception as e:
    print(f"调用接口时出现异常：{str(e)}")</code></pre><h3>3.WebSocket 订阅实时行情（持续推送）</h3><pre><code class="python">import websocket
import json
import threading
import time

WS_URL = "wss://api.itick.org/stock"
API_TOKEN = "your_api_token_here"  # 替换为你的Token

def on_message(ws, message):
    data = json.loads(message)
    if data.get("data"):
        market_data = data["data"]
        data_type = market_data.get("type")
        symbol = market_data.get("s")
        print(f"{data_type.upper()} 数据 - {symbol}: {market_data}")

def on_open(ws):
    print("WebSocket 连接成功")
    # 订阅 AAPL 美股的报价和Tick数据
    subscribe_msg = {
        "ac": "subscribe",
        "params": "AAPL$US",
        "types": "quote,tick"
    }
    ws.send(json.dumps(subscribe_msg))

def send_ping(ws):
    while True:
        time.sleep(30)
        ping_msg = {"ac": "ping", "params": str(int(time.time() * 1000))}
        ws.send(json.dumps(ping_msg))
        print("Ping 发送")

ws = websocket.WebSocketApp(
    WS_URL,
    header={"token": API_TOKEN},
    on_open=on_open,
    on_message=on_message
)

ping_thread = threading.Thread(target=send_ping, args=(ws,))
ping_thread.daemon = True
ping_thread.start()
ws.run_forever()</code></pre><p>这些示例可直接运行（需安装<code>requests</code>和<code>websocket-client</code>库：<code>pip install requests websocket-client</code>）。WebSocket 适合构建实时监控系统，REST 适合批量或定时查询。</p><h2>三、总结</h2><p>2026年全球股市实时行情数据API的选型核心，是“需求匹配+成本控制”。不同API各具优势，适配不同开发场景与预算需求——无论是实时行情获取、历史K线查询，还是高频行情监控、深度数据分析，需结合自身需求选择适配的接口，无需盲目追求某一维度的优势。<br/>若追求低延迟与高性价比，可优先考虑iTick API；若侧重跨资产轻量化开发，Alpha Vantage API适配性更强；若需要机构级深度数据与全面性保障，Polygon.io API更符合需求。建议选型前，先通过各API的免费试用，结合自身开发场景测试响应速度、数据完整性，再决定是否付费升级。</p><p>参考文档：<a href="https://link.segmentfault.com/?enc=cdN%2Bid0AMPcHnDLx3NXJ9Q%3D%3D.3wpeTshkKmR5AfYZ4O9RQF4taAicC4A82KDgJfBi7FhDTPpkniIF%2FDkdJ4a0yGqGFJ2Xm9Y%2F9wYu6dioEr%2Fb5GOx5tYLPAPKsZmoAkiwKO%2FmhddY9%2BJWnzyIrrHNuxqrHxSYM1ZM9iO5vGwR8jplFA%3D%3D" rel="nofollow" target="_blank">https://blog.itick.org/stock-api/global-stock-market-realtime-quotes-for-quantitative-trading</a><br/>GitHub：<a href="https://link.segmentfault.com/?enc=bQpQaoOWyJ%2FPmWHWxZCF4w%3D%3D.HuR45V1pZWVp9Dy%2Bie7gFw%2Fk8KBPNgT5DzGR9hMKAK0%3D" rel="nofollow" target="_blank">https://github.com/itick-org/</a></p>]]></description></item><item>    <title><![CDATA[【k8s】Centos从零开始使用containerd部署k8s1.30.14+KubeSphere]]></title>    <link>https://segmentfault.com/a/1190000047559647</link>    <guid>https://segmentfault.com/a/1190000047559647</guid>    <pubDate>2026-01-23 10:11:57</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>Centos虽然已经停止维护了，而且内核也非常低，耐不住国内大环境很多公司还是一直在用它。时不时见到有人想要在centos上面部署k8s1.30.14版本,本文将以<code>centos 7</code>为例，从0开始搭建k8s+ks集群。</p><h2>1.说明</h2><h3>关于kt</h3><p><code>kt</code>是基于<code>kk</code>二次开发的产物，具备<code>kk</code>的所有功能。二开主要为适配信创国产化环境、简化<code>arm</code>部署过程和国产化环境离线部署。支持<code>arm64</code>和<code>amd64</code>架构国产操作系统，已适配芯片+操作系统 如下。</p><p><strong>kt新增功能点</strong></p><ul><li>适配arm架构harbor和支持，部署体验与X86一样简单。</li><li><p>离线环境部署增强。常用国际和国产操作系统依赖，内置到安装包中。已适配芯片和操作系统如下</p><ul><li><code>./kt init-os</code> 一条命令完成操作系统依赖安装和初始化操作。</li><li>CPU：鲲鹏、飞腾、海光、兆芯、intel、amd等。</li><li>OS：Centos、Rocky Linux、Ubuntu、Debian、银河麒麟V10、麒麟V11、麒麟国防版、麒麟信安、中标麒麟V7、统信UOS、华为欧拉、移动大云、阿里龙蜥、TencenOS等。</li></ul></li><li><p>支持开启防火墙，只暴露<code>30000-32767</code>端口，其他k8s端口添加到节点白名单。</p><ul><li><code>./kt firewall</code> 一条命令自动获取节点信息开白名单和防火墙。</li></ul></li></ul><p><strong>kt版本更新和下载地址</strong></p><ul><li><strong>kt：</strong> <a href="https://link.segmentfault.com/?enc=OFqyX7hf65oaUOc0JuRgYw%3D%3D.29mAmKdrNGRnnMLiJCTNKFQHiCXZQg87mpH2%2FKHRTYs%3D" rel="nofollow" title="kt说明" target="_blank">kt</a></li><li><strong>关注我不迷路</strong></li></ul><h2>2.环境准备</h2><p><strong>服务器基本信息</strong></p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559650" alt="" title=""/></p><table><thead><tr><th><strong>主机名</strong></th><th><strong>架构</strong></th><th><strong>OS</strong></th><th><strong>配置</strong></th><th><strong>IP</strong></th></tr></thead><tbody><tr><td>master-woker</td><td>x86_64</td><td>Centos 7</td><td>4核8G</td><td>192.168.85.164</td></tr><tr><td>harbor</td><td>x86_64</td><td>Ubuntu</td><td>2核4G</td><td>192.168.85.201</td></tr></tbody></table><h3>2.1 上传离线制品</h3><p>操作系统不需要安装docker,不需要设置selinux,swap等操作，全新的操作系统即可。</p><p>将离线制品、配置文件、kt和sh脚本上传至服务器其中一个节点(本文以master为例)，后续在该节点操作创建集群。本文使用kt:<code>3.1.12-centos</code>版本</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559651" alt="" title="" loading="lazy"/></p><h3>2.2 修改配置文件</h3><p>根据实际服务器信息，配置到生成的<code>config-sample.yaml</code>中</p><pre><code class="plain">kind: Cluster
metadata:
  name: sample
spec:
  hosts:
  - {name: node1, address: 192.168.85.164, internalAddress: 192.168.85.164, user: root, password: "123123"}
  - {name: harbor, address: 192.168.85.201, internalAddress: 192.168.85.201, user: root, password: "1231233"}
  roleGroups:
    etcd:
    - node1
    control-plane:
    - node1
    worker:
    - node1
    # 如需使用 kk 自动部署镜像仓库，请设置该主机组 （建议仓库与集群分离部署，减少相互影响）
    # 如果需要部署 harbor 并且 containerManager 为 containerd 时，由于部署 harbor 依赖 docker，建议单独节点部署 harbor
    registry:
    - harbor
  controlPlaneEndpoint:
    ## Internal loadbalancer for apiservers 
    internalLoadbalancer: haproxy

    domain: lb.kubesphere.local
    address: ""
    port: 6443
  kubernetes:
    version: v1.30.14
    clusterName: cluster.local
    autoRenewCerts: true
    containerManager: containerd
  etcd:
    type: kubekey
  network:
    plugin: calico
    kubePodsCIDR: 10.233.64.0/18
    kubeServiceCIDR: 10.233.0.0/18
    ## multus support. https://github.com/k8snetworkplumbingwg/multus-cni
    multusCNI:
      enabled: false
  registry:
    type: harbor
    registryMirrors: []
    insecureRegistries: []
    privateRegistry: "dockerhub.kubekey.local"
    namespaceOverride: "kubesphereio"
    auths: # if docker add by `docker login`, if containerd append to `/etc/containerd/config.toml`
      "dockerhub.kubekey.local":
        username: "admin"
        password: Harbor@123 # 此处可自定义，kk3.1.8新特性
        skipTLSVerify: true # Allow contacting registries over HTTPS with failed TLS verification.
        plainHTTP: false # Allow contacting registries over HTTP.
        certsPath: "/etc/docker/certs.d/dockerhub.kubekey.local"
  addons: []
  ---</code></pre><h2>2.3 系统初始化</h2><p>解压<code>kt-centos.tar.gz</code>文件后执行<code>./kt init-os -f config-sample.yaml</code> 已适配操作系统和架构见<code>1.说明</code></p><p>该命令<code>kt</code>会根据配置文件自动判断操作系统和架构以完成所有节点的初始化配置和依赖安装。</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559652" alt="" title="" loading="lazy"/></p><h2>3 创建 Harbor私有仓库</h2><p>ps:由于harbor服务器之前部署过harbor，以下步骤为centos部署1.23时的截图</p><h3>3.1 创建镜像仓库</h3><pre><code class="plain">./kt init registry -f config-sample.yaml -a artifact-x86-k8s13014-ks3.4.1.tar.gz</code></pre><p>此命令会在<code>harbor</code>节点自动安装<code>docker</code>和<code>docker-compose</code>，</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559653" alt="" title="" loading="lazy"/></p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559654" alt="" title="" loading="lazy"/></p><h3>3.2 创建harbor项目</h3><p>&lt;font style="background-color:rgb(255,245,235);"&gt;说明：&lt;/font&gt;</p><p>&lt;font style="background-color:rgb(255,245,235);"&gt;Harbor 管理员账号：&lt;/font&gt;<strong>&lt;font style="background-color:rgb(255,245,235);"&gt;admin&lt;/font&gt;</strong>&lt;font style="background-color:rgb(255,245,235);"&gt;，密码：&lt;/font&gt;<strong>&lt;font style="background-color:rgb(255,245,235);"&gt;Harbor@123&lt;/font&gt;</strong>&lt;font style="background-color:rgb(255,245,235);"&gt;。密码同步使用配置文件中的对应password&lt;/font&gt;</p><p>&lt;font style="background-color:rgb(255,245,235);"&gt;harbor 安装文件在 &lt;/font&gt;<code>/opt/harbor</code>目录下，可在该目录下对 harbor 进行运维。&lt;/font&gt;</p><p>创建 Harbor 项目</p><pre><code class="plain">chmod +x create_project_harbor.sh &amp;&amp; ./create_project_harbor.sh</code></pre><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559655" alt="" title="" loading="lazy"/></p><h2>4 创建k8s和KubeSphere</h2><pre><code class="plain">./kt create cluster -f config-sample.yaml -a artifact-x86-k8s13014-ks341.tar.gz</code></pre><p>此命令kt会自动将离线制品中的镜像推送到<code>harbor</code> 私有仓库</p><p>执行后会有如下提示,输入<code>yes/y</code>继续执行</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559656" alt="" title="" loading="lazy"/></p><p>等待一段时间，直至出现熟悉的等待安装完成的小箭头&gt;&gt;---&gt;</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559657" alt="" title="" loading="lazy"/></p><p>期间可以另开一个窗口用以下命令查看部署日志</p><pre><code class="plain">kubectl logs -n kubesphere-system $(kubectl get pod -n kubesphere-system -l 'app in (ks-install, ks-installer)' -o jsonpath='{.items[0].metadata.name}') -f</code></pre><p>继续等待一段时间，可以看到在内核3.10.0上面使用containerd成功部署了1.30.14版本+ks</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559658" alt="" title="" loading="lazy"/></p><h2>5 验证</h2><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559659" alt="" title="" loading="lazy"/></p><p>ps:<code>default-http-backend</code>那个pod显示：ImagePullBackOff，没啥用，不需要理会。</p><p>登录页面</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559660" alt="" title="" loading="lazy"/></p><p>集群管理</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559661" alt="" title="" loading="lazy"/></p><p>监控告警</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559662" alt="" title="" loading="lazy"/></p><p>配置文件默认只安装了监控，如果需要安装其他组件，可以自行在自定义资源中开启</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559663" alt="" title="" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[【信创-k8s】麒麟V11使用containerd2.1.5全离线安装k8s1.32.11+Kube]]></title>    <link>https://segmentfault.com/a/1190000047559686</link>    <guid>https://segmentfault.com/a/1190000047559686</guid>    <pubDate>2026-01-23 10:11:01</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>本文以<code>麒麟V11</code>，使用<code>k8s 1.32.11+ks4.1.3core</code>离线部署<code>1master2node</code>节点,若有其他需要可添加我微信好友<code>sd_zdhr</code>。</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559689" alt="" title=""/></p><h2>1 说明</h2><h3>关于kt</h3><p><code>kt</code>是基于<code>kk</code>二次开发产物，具备<code>kk</code>的所有功能，二开重点适配了信创国产化环境。</p><p>主要改进包括：简化<code>arm</code>架构部署过程、支持国产化和国际环境在线、离线部署及<code>一条命令所有节点初始化</code>。</p><p>支持<code>arm64</code>和<code>amd64</code>架构操作系统，已适配芯片+操作系统 如下：</p><ul><li><strong>CPU：</strong> 鲲鹏、飞腾、海光、兆芯、intel、amd 等。</li><li><strong>OS：</strong> Centos、Ubuntu、Debian、银河麒麟V10、麒麟国防版、麒麟信安、中标麒麟V7、统信UOS、华为欧拉、移动大云、阿里龙蜥、TencentOS等。</li></ul><p>注：本文使用kt版本<code>3.1.13</code></p><ul><li><strong>kt文档：</strong> <a href="https://link.segmentfault.com/?enc=FwH4f%2FJ%2BoFnpVtt6ogNuFQ%3D%3D.GrDZMVlXdJVwZM1xTKhR8%2BNLZ8EX9iYot%2FBSkfigRxg%3D" rel="nofollow" title="kt文档" target="_blank">kt文档</a></li></ul><h2>2.环境准备</h2><p><strong>服务器基本信息</strong></p><table><thead><tr><th><strong>主机名</strong></th><th><strong>架构</strong></th><th><strong>OS</strong></th><th><strong>配置</strong></th><th><strong>IP</strong></th></tr></thead><tbody><tr><td>harbor</td><td>x86_64</td><td>Ubuntu</td><td>2核4G</td><td>192.168.85.201</td></tr><tr><td>master</td><td>x86_64</td><td>麒麟V11</td><td>2核4G</td><td>192.168.85.163</td></tr><tr><td>node1</td><td>x86_64</td><td>麒麟V11</td><td>2核4G</td><td>192.168.85.155</td></tr><tr><td>node2</td><td>x86_64</td><td>麒麟V11</td><td>2核4G</td><td>192.168.85.162</td></tr></tbody></table><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559690" alt="" title="" loading="lazy"/></p><h3>2.1 上传离线制品</h3><p>操作系统不需要安装docker,不需要设置selinux,swap等操作，全新的操作系统即可。</p><p>将离线制品、配置文件、kt和sh脚本上传至服务器其中一个节点(本文以master为例)，后续在该节点操作创建集群。</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559691" alt="" title="" loading="lazy"/></p><h3>2.2 修改配置文件</h3><p>根据实际服务器信息，配置到生成的<code>config-sample.yaml</code>中</p><pre><code class="plain">kind: Cluster
metadata:
  name: sample
spec:
  hosts:
  - {name: harbor, address: 192.168.85.201, internalAddress: 192.168.85.201, user: root, password: "123213"}
  - {name: master, address: 192.168.85.163, internalAddress: 192.168.85.163, user: root, password: "123213"}
  - {name: node1, address: 192.168.85.155, internalAddress: 192.168.85.155, user: root, password: "123213"}
  - {name: node2, address: 192.168.85.162, internalAddress: 192.168.85.162, user: root, password: "123213"}
  roleGroups:
    etcd:
    - master
    control-plane:
    - master
    worker:
    - node1
    - node2
    # 由于部署 harbor 依赖 docker，建议单独节点部署 harbor
    registry:
    - harbor
  controlPlaneEndpoint:
    ## Internal loadbalancer for apiservers 
    internalLoadbalancer: haproxy

    domain: lb.kubesphere.local
    address: ""
    port: 6443
  kubernetes:
    version: v1.32.11
    clusterName: cluster.local
    autoRenewCerts: true
    containerManager: containerd
  etcd:
    type: kubekey
  network:
    plugin: calico
    kubePodsCIDR: 10.233.64.0/18
    kubeServiceCIDR: 10.233.0.0/18
    ## multus support. https://github.com/k8snetworkplumbingwg/multus-cni
    multusCNI:
      enabled: false
  registry:
    type: harbor
    registryMirrors: []
    insecureRegistries: []
    privateRegistry: "dockerhub.kubekey.local"
    namespaceOverride: "kubesphereio"
    auths: # if docker add by `docker login`, if containerd append to `/etc/containerd/config.toml`
      "dockerhub.kubekey.local":
        username: "admin"
        password: Harbor@123 # 此处可自定义，kk3.1.8新特性
        skipTLSVerify: true # Allow contacting registries over HTTPS with failed TLS verification.
        plainHTTP: false # Allow contacting registries over HTTP.
        certsPath: "/etc/docker/certs.d/dockerhub.kubekey.local"
  addons: []</code></pre><h2>2.3 系统初始化</h2><p>解压<code>kt-x86.tar.gz</code>文件后执行<code>./kt init-os -f config-sample.yaml</code> 已适配操作系统和架构见<code>1.说明</code></p><p>该命令<code>kt</code>会根据配置文件自动判断操作系统和架构以完成所有节点的初始化配置和依赖安装。</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559692" alt="" title="" loading="lazy"/></p><h2>3 创建 Harbor私有仓库</h2><h3>3.1 创建镜像仓库</h3><pre><code class="plain">./kt init registry -f config-sample.yaml -a artifact-x86-k8s13211-ks413core.tar.gz</code></pre><p>此命令会在<code>harbor</code>节点自动安装<code>docker</code>和<code>docker-compose</code></p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559693" alt="" title="" loading="lazy"/></p><p>稍等一会，看到成功消息</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559694" alt="" title="" loading="lazy"/></p><p>此时去harbor服务器，查看服务状态，可以看到所有服务已正常启动。</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559695" alt="" title="" loading="lazy"/></p><h3>3.2 创建harbor项目</h3><p>&lt;font style="background-color:rgb(255,245,235);"&gt;说明：&lt;/font&gt;</p><p>&lt;font style="background-color:rgb(255,245,235);"&gt;Harbor 管理员账号：&lt;/font&gt;<strong>&lt;font style="background-color:rgb(255,245,235);"&gt;admin&lt;/font&gt;</strong>&lt;font style="background-color:rgb(255,245,235);"&gt;，密码：&lt;/font&gt;<strong>&lt;font style="background-color:rgb(255,245,235);"&gt;Harbor@123&lt;/font&gt;</strong>&lt;font style="background-color:rgb(255,245,235);"&gt;。密码同步使用配置文件中的对应password&lt;/font&gt;</p><p>&lt;font style="background-color:rgb(255,245,235);"&gt;harbor 安装文件在 &lt;/font&gt;/opt/harbor&lt;font style="background-color:rgb(255,245,235);"&gt; 目录下，可在该目录下对 harbor 进行运维。&lt;/font&gt;</p><p>创建 Harbor 项目</p><pre><code class="plain">chmod +x create_project_harbor.sh &amp;&amp; ./create_project_harbor.sh</code></pre><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559696" alt="" title="" loading="lazy"/></p><h2>4 创建k8s</h2><pre><code class="plain">./kt create cluster -f config-sample.yaml -a artifact-x86-k8s13211-ks413core.tar.gz --with-local-storage</code></pre><p>此命令<code>kt</code>会自动将离线制品中的镜像推送到<code>harbor</code> 私有仓库</p><p>执行后会有如下提示,输入<code>yes/y</code>继续执行</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559697" alt="" title="" loading="lazy"/></p><p>继续等待一段时间最终可以看到安装成功的消息</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559698" alt="" title="" loading="lazy"/></p><p>验证</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559699" alt="" title="" loading="lazy"/></p><h2>5 安装 KubeSphere</h2><pre><code class="plain">helm upgrade --install -n kubesphere-system --create-namespace ks-core ks-core-1.1.5.tgz \
     --set global.imageRegistry=dockerhub.kubekey.local/ks \
     --set extension.imageRegistry=dockerhub.kubekey.local/ks \
     --set ksExtensionRepository.image.tag=v1.1.5 \
     --debug \
     --wait</code></pre><p>等待大概1分钟左右看到成功消息</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559700" alt="" title="" loading="lazy"/></p><h2>6 验证</h2><p>登录页面</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559701" alt="" title="" loading="lazy"/></p><p>初次登录需要换密码，如果不想换也可以继续填写<code>P@88w0rd</code>，不过建议更换</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559702" alt="" title="" loading="lazy"/></p><p>首页</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559703" alt="" title="" loading="lazy"/></p><p>集群节点版本信息</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559704" alt="" title="" loading="lazy"/></p><p>概览</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559705" alt="" title="" loading="lazy"/></p><p>集群节点</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559706" alt="" title="" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[什么是外勤人员管理系统 果断的小刀 ]]></title>    <link>https://segmentfault.com/a/1190000047559732</link>    <guid>https://segmentfault.com/a/1190000047559732</guid>    <pubDate>2026-01-23 10:10:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>对很多拥有外勤团队的企业来说，<strong>外勤人员管理</strong>一直是一项难度较高的工作。无论是长期在市场一线奔波的销售人员，还是分散在各个区域的售后工程师，一旦员工离开办公室，管理难度就会明显上升。</p><p>不少管理者都会遇到类似问题。人员具体去了哪里不清楚，工作过程是否真实难以判断，相关费用也缺乏有效核实依据。久而久之，外勤管理容易演变成依赖经验和信任的状态，<strong>效率和成本都难以控制</strong>。</p><p><strong>一、什么是外勤人员管理系统</strong></p><p><strong>外勤人员管理系统</strong>，本质上是一套用于规范和提升外勤人员管理效率的<strong>数字化工具</strong>。它通常基于 SaaS 架构，结合定位技术和移动终端，帮助企业对外勤人员的<strong>考勤、位置、轨迹和工作内容</strong>进行统一管理。<br/><img width="723" height="378" referrerpolicy="no-referrer" src="/img/bVdnICv" alt="" title=""/></p><p>与传统外勤打卡工具不同，成熟的外勤管理系统并不只是记录时间或位置，而是<strong>将总部管理与一线业务场景连接起来</strong>，让管理者能够了解真实的工作状态，同时也为一线员工提供清晰的工作指引和流程支持。</p><p>从企业实践来看，一套成熟的外勤人员管理系统，核心目标通常集中在三个方面：<strong>确保数据真实，提升人效水平，控制不必要的费用支出</strong>。</p><p><strong>二、如何解决人员位置管理问题</strong></p><p>在外勤管理中，<strong>位置和考勤的真实性</strong>是所有管理动作的基础。如果这一层数据不可靠，后续的业务分析和绩效评估都会失去意义。</p><p><strong>1、精准定位与轨迹记录</strong></p><p>外勤管理系统通常通过 <strong>GPS、基站和 Wi-Fi 等多种方式进行混合定位</strong>，持续记录外勤人员的活动位置。管理者可以在后台查看团队的实时分布情况，用于临时调度和任务分配。<br/><img width="723" height="356" referrerpolicy="no-referrer" src="/img/bVdnICw" alt="" title="" loading="lazy"/></p><p>同时，系统会保存员工的<strong>历史行动轨迹</strong>。通过连续轨迹记录，可以还原一天内的真实行程，避免出现绕路或长时间无效停留的情况。这类外勤人员<strong>定位和轨迹管理</strong>功能，是外勤管理软件的重要组成部分。</p><p><strong>2、区域管理与外勤考勤</strong></p><p>在实际应用中，企业可以在地图上<strong>划定特定工作区域</strong>，例如办公点位、客户门店或重点服务区域。员工进入或离开指定区域时，系统会自动记录考勤时间。<br/><img width="723" height="552" referrerpolicy="no-referrer" src="/img/bVdnICx" alt="" title="" loading="lazy"/></p><p>这种<strong>外勤考勤管理</strong>方式减少了人工打卡带来的争议，也让考勤过程更加自然，避免频繁操作对员工工作的干扰。</p><p><strong>3、数据真实性保障</strong></p><p>针对虚拟定位和代打卡等问题，专业的外勤人员管理系统通常会配置<strong>多层校验机制</strong>。通过识别异常设备环境和异常定位行为，降低数据被篡改的可能性。</p><p>在现场拍照环节，系统会<strong>自动记录时间和位置信息</strong>，用于巡店管理、工程验收等场景。这类机制能够帮助企业<strong>建立可信的数据基础</strong>，而不是事后反复核对。</p><p><strong>三、如何还原真实工作内容</strong></p><p>解决“人员在哪里”之后，外勤管理的重点会转向<strong>工作内容本身</strong>。不同岗位的外勤人员，管理重点也存在明显差异。<br/><img width="723" height="470" referrerpolicy="no-referrer" src="/img/bVdnICy" alt="" title="" loading="lazy"/></p><p><strong>场景一：外勤销售管理</strong></p><p>该类场景多见于 B2B 销售、医药代表和渠道拓展团队。系统会围绕<strong>客户管理和拜访过程</strong>展开，帮助企业规范销售动作。</p><p>常见功能包括<strong>客户资源统一管理、拜访路线规划以及标准化拜访流程</strong>。通过这些功能，外勤销售管理不再依赖个人习惯，而是形成<strong>可复制的工作模式</strong>。<br/><img width="723" height="292" referrerpolicy="no-referrer" src="/img/bVdnICz" alt="" title="" loading="lazy"/></p><p><strong>场景二：巡店管理与终端执行</strong></p><p>在快消和零售行业，<strong>巡店管理系统</strong>是外勤管理的重要组成部分。巡店人员需要按计划完成门店检查、陈列确认和信息采集。</p><p>通过现场拍照和数据采集，企业可以掌握<strong>终端执行情况</strong>，同时对铺货率和竞品动态进行分析，减少人工汇总带来的误差。</p><p><strong>场景三：工程与设备巡检</strong></p><p>在工程维护和设备巡检场景中，系统通常会提前设置<strong>固定巡检路线和点位</strong>。外勤人员需按顺序完成任务，避免漏检或走过场。</p><p>发现问题后，可直接在现场提交记录，相关信息会同步到后台，形成<strong>闭环处理流程</strong>。这类外勤巡检系统在物业、电力等行业应用较为普遍。<br/><img width="723" height="559" referrerpolicy="no-referrer" src="/img/bVdnICA" alt="" title="" loading="lazy"/></p><p><strong>场景四：政府与公共服务</strong></p><p>在城市管理和公共服务领域，外勤人员管理系统更多用于<strong>过程留痕和履职记录</strong>。通过轨迹记录和事件上报机制，帮助相关部门完成合规管理和工作追溯。</p><p><strong>场景五：用车管理与费用核算</strong></p><p>在涉及私车公用的情况下，行程和费用往往难以准确核算。系统可以基于<strong>真实行驶轨迹计算里程</strong>，并按照企业规则自动生成费用记录。</p><p>这种<strong>外勤费用管理</strong>方式，有助于减少人为申报带来的偏差，同时提升财务审核效率。<br/><img width="723" height="535" referrerpolicy="no-referrer" src="/img/bVdnICB" alt="" title="" loading="lazy"/></p><p><strong>四、如何评估外勤管理效果</strong></p><p>外勤人员管理系统的最终价值，体现在<strong>数据层面的积累和分析</strong>。通过对过程数据和结果数据的整合，管理者可以更清楚地判断团队运行状态。</p><p>系统通常会展示<strong>考勤情况、拜访覆盖率和在岗时长等过程指标</strong>。同时结合业务结果，对<strong>人效表现和投入产出情况</strong>进行分析，为绩效评估和人员调整提供依据。</p><p><strong>五、企业如何选择合适的外勤人员管理系统</strong></p><p>在选择外勤管理系统时，企业可以重点关注以下三个方面：</p><p><strong>行业匹配度</strong>：不同业务场景对外勤管理的要求差异较大，具备行业经验的解决方案往往更容易落地。</p><p><strong>技术可靠性</strong>：包括<strong>定位稳定性和数据防篡改能力</strong>，这关系到系统长期使用的可信度。</p><p><strong>服务能力</strong>：外勤人员管理系统并非一次性工具，<strong>持续的实施支持和管理优化建议</strong>，同样影响使用效果。</p><p><strong>六、结语</strong></p><p>总体来看，<strong>外勤人员管理系统不仅是一套管理工具，更是企业实现外勤数字化管理的重要基础</strong>。通过对人员、过程和数据的统一管理，企业可以逐步摆脱依赖经验的管理方式，提升整体运营效率。</p><p>在竞争日益激烈的环境中，<strong>建立稳定可靠的外勤管理体系</strong>，往往是实现降本增效的重要一步。</p>]]></description></item><item>    <title><![CDATA[API 接入分解三门梯子游戏：APIBB梯子游戏玩法技巧接口指南 淡定的电梯 ]]></title>    <link>https://segmentfault.com/a/1190000047559773</link>    <guid>https://segmentfault.com/a/1190000047559773</guid>    <pubDate>2026-01-23 10:09:38</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>梯子，是这几年来最火热的一款bbi采，几率高 响应结构：返回JSON数据，核心字段包括  num_iid（商品ID）<br/><img width="464" height="131" referrerpolicy="no-referrer" src="/img/bVdnIDe" alt="" title=""/><br/>  title（标题）、  price（价格）、  pic_url（主图）、  volume（销量）等。存储建议：可存储至数据库（如MySQL）或导出CSV，避免直接展示敏感字段（如用户隐私）。今天举例梯子三门112的打法，终点X梯子暂不考虑，首先举例的是，打哪三门如图示意我们打的是（双    3     右）<br/><img width="723" height="378" referrerpolicy="no-referrer" src="/img/bVdnIle" alt="" title="" loading="lazy"/></p><p>如图打是的（单三右） 我们打的是（双三右），打中三门中的（三和右）那么三门打中2门，丢失了一门，换算下来得两门，丢一门，实际还多得一门。 频率限制：免费版通常500次/天，企业认证后可达10万次/天，需控制请求间隔（如  time.sleep(1)避免限流）。</p><p>如图打的是（双三右）我们打的是（双三左），打中三门中的（三和双）那么三门打中两门，丢失了一门，换算下来得两门，，丢一门，实际还多得一门。 响应结构：返回JSON数据，核心字段包括  num_iid（商品ID）、  title（标题）、  price（价格）、  pic_url（主图）、  volume（销量）等。<br/><img width="600" height="424" referrerpolicy="no-referrer" src="/img/bVdnIDf" alt="" title="" loading="lazy"/></p><p>如图打的是（单四左）我们打的是（双三右），三门一门都没打中，实际换算下来就是三门全丢。 存储建议：可存储至数据库（如MySQL）或导出CSV，避免直接展示敏感字段（如用户隐私）。</p><p>如图打的是（双四右）我们打的是（双三右），打中三门中的（双和右）那么三门打中两门，丢失一门，换算下来得两门，丢一门，实际还多得一门。 通过以上步骤，可高效、合规地批量获取淘宝商品信息。如需进一步优化，可结合缓存（如Redis）减少重复请求，或使用异步框架（如Scrapy）提升效率。<br/><img width="543" height="356" referrerpolicy="no-referrer" src="/img/bVdnIDg" alt="" title="" loading="lazy"/><br/>三门打法定律就是，任你万千变化，我自巍然不动，综上所述按照这种112模式操作，中门的几.率是75%超高中.门.率，牢记的就是（单三左）、（双三右）、（单四右）、（双四左），三门112打法配上凯利公式来操作梯子，那么你将无往不利。 合规性：禁止爬取用户隐私数据，需遵守淘宝《开放平台规则》及《robots协议》。1. 准备工作注册与认证：登录淘宝开放平台，完成企业/个人实名认证，创建应用并获取 AppKey和 AppSecret（核心凭证）。权限申请：在“应用管理”中申请商品搜索类API权限（如 taobao.items.search、 taobao.tbk.item.get），审核通过后生效。2. 接口选择与参数配置核心接口：taobao.items.search：按关键词、价格区间、销量等筛选商品，支持分页（ page_no、 page_size）和排序（如 sale-desc销量降序）。taobao.tbk.item.get：淘宝客商品搜索，可获取优惠券信息，适合佣金导向场景。必填参数：公共参数： app_key、 method（接口名）、 timestamp（时间戳）、 format（ json）、 v（API版本，如 2.0）、 sign_method（ md5）。业务参数： q（搜索关键词）、 page_no（页码，默认1）、 page_size（每页数量，默认20，最大100）、 fields（返回字段，如 num_iid,title,price,pic_url）。</p>]]></description></item><item>    <title><![CDATA[从零搭建现货撮合系统：完整架构与性能实测 想发财的香烟 ]]></title>    <link>https://segmentfault.com/a/1190000047559779</link>    <guid>https://segmentfault.com/a/1190000047559779</guid>    <pubDate>2026-01-23 10:08:48</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>从零搭建现货撮合系统：完整架构与性能实测</h2><blockquote>一套经过生产验证的交易所核心系统，从下单到成交全流程</blockquote><h3>前言</h3><p>做交易所技术这几年，经常被问到：<strong>撮合引擎怎么设计？能跑多少 QPS？</strong></p><p>市面上讲撮合的文章很多，但大多是理论，缺少实际的性能数据和踩坑经验。</p><p>这篇文章会分享我们团队自研的现货撮合系统 <strong>Exchange</strong>，包括：</p><ul><li>完整的技术架构和选型思路</li><li>真实的压测数据（不是理论值）</li><li>遇到的性能瓶颈和优化方向</li></ul><p>目前这套系统已经能够：</p><ul><li>⚡ <strong>完整下单流程 1,440 QPS</strong>（含资产校验、冻结、落库）</li><li>🚀 <strong>做市机器人接口 18,000 QPS</strong>（轻量级，跳过 DB）</li><li>🔄 <strong>3 节点集群，主从热备，故障自动切换 &lt; 3 秒</strong></li><li>📊 <strong>完整行情系统</strong>（实时深度、15 种 K 线周期、Ticker）</li></ul><p>🔗 <strong>在线体验</strong>：<a href="https://link.segmentfault.com/?enc=pl2iFrAvqWWTvwtWofd6Cg%3D%3D.Ff2%2B%2FKufVglflSs1nhzPmJwVH4xF5GM7opRagrbvMAl6wsy3wcBSXzQ9mmIWuZh6" rel="nofollow" target="_blank">https://web3-ex-omega.vercel.app/</a>  <br/>📖 <strong>API 文档</strong>：<a href="https://link.segmentfault.com/?enc=E%2BqYCJ1lnr39zsRTOJUTrA%3D%3D.yJd4eH2yuxC2qpBWdMiFEqwg0fTCBi7Dyf6Kz7jqLNM%3D" rel="nofollow" target="_blank">https://apix-docs.vercel.app/</a></p><p><img width="723" height="523" referrerpolicy="no-referrer" src="/img/bVdnHgV" alt="demo.gif" title="demo.gif"/></p><p>本文是系列文章的第一篇，重点讲<strong>整体架构</strong>，后续会深入撮合算法、高可用设计等细节。</p><hr/><h3>一、为什么自研？</h3><p>市面上有一些交易所解决方案，但我们调研后发现都不太满足需求：</p><ul><li>有些性能不够，延迟太高</li><li>有些功能不完整，需要大量二次开发</li><li>有些架构老旧，扩展性差</li><li>有些是黑盒，出了问题没法排查</li></ul><p>最后决定自研，目标很明确：</p><ol><li><strong>高性能</strong>：Go 语言，天然适合高并发场景</li><li><strong>架构清晰</strong>：微服务拆分，每个模块职责单一</li><li><strong>易扩展</strong>：支持水平扩展，方便后续优化</li><li><strong>可控性强</strong>：核心代码自己掌握，出问题能快速定位</li></ol><hr/><h3>二、技术选型</h3><h4>核心技术栈</h4><table><thead><tr><th>技术</th><th>用途</th><th>选型理由</th></tr></thead><tbody><tr><td><strong>Go</strong></td><td>开发语言</td><td>性能好、并发友好、部署简单</td></tr><tr><td><strong>Kafka</strong></td><td>消息队列</td><td>高吞吐、消息持久化、支持回溯</td></tr><tr><td><strong>Redis</strong></td><td>缓存/选举</td><td>Leader 选举、行情缓存</td></tr><tr><td><strong>MySQL</strong></td><td>关系数据库</td><td>订单、成交记录</td></tr><tr><td><strong>ClickHouse</strong></td><td>时序数据库</td><td>K 线历史数据</td></tr><tr><td><strong>Consul</strong></td><td>服务发现</td><td>健康检查</td></tr></tbody></table><h4>为什么用 Kafka？</h4><p>交易所是典型的<strong>事件驱动</strong>系统，每笔订单会触发一系列事件：</p><pre><code>撮合成功 → 清算资金 → 更新深度 → 生成K线 → 推送客户端</code></pre><p>选 Kafka 的原因：</p><ul><li>✅ 消息持久化，出问题可以回溯</li><li>✅ 单分区有序，撮合结果按顺序处理</li><li>✅ 吞吐量高，单分区轻松 10 万+ QPS</li></ul><p>RabbitMQ 也考虑过，但它更适合任务队列场景。虽然也支持持久化，但在高吞吐场景下 Kafka 表现更好。</p><h4>为什么用 Redis 做选举？</h4><p>撮合引擎是 3 节点集群（1 主 2 备），需要选出 Leader。</p><p>用 Redis 分布式锁实现，原因很简单：</p><ol><li><strong>够用</strong>：不需要强一致性，只要切换够快</li><li><strong>简单</strong>：几行代码搞定</li><li><strong>复用</strong>：Redis 本来就要用，不用引入新组件</li></ol><pre><code class="go">// Leader 选举
func tryBecomeLeader() bool {
    return redis.SetNX("match-engine:leader", nodeID, 3*time.Second).Val()
}</code></pre><p>TTL 设 3 秒，主节点挂了，备节点最多 3 秒内就能接管。</p><p>当然，Redis 选举理论上有脑裂风险。如果要更严谨，可以用 Consul Session 或 etcd。这里为了简单，先用 Redis。</p><h4>数据库选型</h4><p><strong>MySQL</strong> 存订单和成交记录，这是关系型数据，需要事务保证。</p><p><strong>ClickHouse</strong> 存 K 线历史数据。一开始想全用 MySQL，但 K 线数据增长太快：</p><ul><li>1 分钟周期，一天 1440 条 × 交易对数量</li><li>查询历史 K 线时，MySQL 响应越来越慢</li></ul><p>换成 ClickHouse 后，查询性能提升明显，毕竟是专门为时序数据设计的。</p><hr/><h3>三、系统架构</h3><h4>整体架构图</h4><p><img width="723" height="478" referrerpolicy="no-referrer" src="/img/bVdnHgU" alt="exchangehubx-architecture.png" title="exchangehubx-architecture.png" loading="lazy"/></p><h4>服务划分</h4><p>系统拆成了 8 个微服务：</p><table><thead><tr><th>服务</th><th>职责</th></tr></thead><tbody><tr><td><strong>order-service</strong></td><td>订单提交、撤单、资金冻结</td></tr><tr><td><strong>match-engine</strong></td><td>核心撮合（3 节点主从集群）</td></tr><tr><td><strong>trade-service</strong></td><td>成交清算、资金划转</td></tr><tr><td><strong>depth-service</strong></td><td>订单簿深度维护</td></tr><tr><td><strong>kline-service</strong></td><td>K 线聚合（15 种周期）</td></tr><tr><td><strong>market-service</strong></td><td>Ticker 统计（24h 数据）</td></tr><tr><td><strong>ws-service</strong></td><td>WebSocket 推送</td></tr><tr><td><strong>bot-service</strong></td><td>做市机器人（测试用）</td></tr></tbody></table><h4>撮合引擎：主从复制架构</h4><p>撮合引擎是整个系统的核心，必须保证<strong>高可用</strong>。我们采用 <strong>1 主 2 从</strong> 的集群架构：</p><pre><code>                    ┌─────────────────┐
                    │   Redis 选举    │
                    │  (Leader Lock)  │
                    └────────┬────────┘
                             │
         ┌───────────────────┼───────────────────┐
         │                   │                   │
         ▼                   ▼                   ▼
┌─────────────────┐ ┌─────────────────┐ ┌─────────────────┐
│  match-engine   │ │  match-engine   │ │  match-engine   │
│     node-1      │ │     node-2      │ │     node-3      │
│    (Master)     │ │    (Slave)      │ │    (Slave)      │
└────────┬────────┘ └────────┬────────┘ └────────┬────────┘
         │                   │                   │
         │   Kafka: order.log-cluster (操作日志复制)
         │◄──────────────────┴───────────────────┘
         │
         ▼
┌─────────────────┐
│  Kafka Topic    │
│  match.result   │
└─────────────────┘</code></pre><p><strong>工作原理：</strong></p><ol><li><strong>Leader 选举</strong>：3 个节点通过 Redis 分布式锁竞争 Leader</li><li><strong>只有 Master 处理订单</strong>：Slave 节点待命，不参与撮合</li><li><strong>操作日志复制</strong>：Master 的每一笔操作都写入 Kafka <code>order.log-cluster</code> Topic</li><li><strong>Slave 实时同步</strong>：从节点消费操作日志，保持订单簿状态一致</li><li><strong>故障自动切换</strong>：Master 挂掉后，TTL 3 秒内 Slave 自动接管</li></ol><p><strong>为什么要这样设计？</strong></p><ul><li><strong>不能多主</strong>：撮合必须单点执行，否则同一笔订单可能被撮合两次</li><li><strong>必须热备</strong>：冷启动太慢，从 MySQL 恢复订单簿要几分钟</li><li><strong>操作日志</strong>：类似 MySQL binlog，保证主从数据一致</li></ul><h4>一笔订单的处理流程</h4><p>用户下单后，系统内部是这样处理的：</p><p><strong>1. 订单服务</strong></p><pre><code>→ 校验参数
→ 开启事务
→ 冻结资金（乐观锁，条件更新）
→ 生成订单 ID（Snowflake）
→ 保存订单到 MySQL
→ 提交事务
→ 调用撮合引擎（gRPC）</code></pre><p><strong>2. 撮合引擎</strong></p><pre><code>→ 订单入订单簿（跳表结构）
→ 执行撮合算法（价格-时间优先）
→ 生成撮合结果
→ 发送到 Kafka（match.result Topic）</code></pre><p><strong>3. 清算服务</strong>（消费 Kafka）</p><pre><code>→ Taker/Maker 资金划转
→ 扣除手续费
→ 更新订单状态
→ 发送到 Kafka（trade.executed）</code></pre><p><strong>4. 行情服务</strong>（消费 Kafka）</p><pre><code>→ depth-service：更新深度
→ kline-service：聚合 K 线
→ market-service：计算 Ticker</code></pre><p><strong>5. 推送服务</strong></p><pre><code>→ WebSocket 推送给客户端</code></pre><p>整个流程是异步的，各服务通过 Kafka 解耦。</p><hr/><h3>四、核心模块设计</h3><h4>4.1 订单服务</h4><p><strong>关键点 1：Snowflake ID</strong></p><p>订单 ID 用 Snowflake 算法生成，保证全局唯一且趋势递增：</p><pre><code class="go">type Snowflake struct {
    mu        sync.Mutex
    epoch     int64  // 起始时间戳
    machineID int64  // 机器 ID
    sequence  int64  // 序列号
    lastTime  int64
}

func (s *Snowflake) NextID() int64 {
    s.mu.Lock()
    defer s.mu.Unlock()
    
    now := time.Now().UnixMilli()
    
    if now == s.lastTime {
        s.sequence = (s.sequence + 1) &amp; 0xFFF // 12 位序列号
        if s.sequence == 0 {
            // 同一毫秒内序列号用完，等下一毫秒
            for now &lt;= s.lastTime {
                now = time.Now().UnixMilli()
            }
        }
    } else {
        s.sequence = 0
    }
    
    s.lastTime = now
    
    // 41位时间戳 + 10位机器ID + 12位序列号
    return ((now - s.epoch) &lt;&lt; 22) | (s.machineID &lt;&lt; 12) | s.sequence
}</code></pre><p><strong>关键点 2：资金冻结</strong></p><p>下单前要先冻结资金，防止余额超卖。采用乐观锁方式，通过条件更新保证原子性：</p><pre><code class="go">func (s *OrderService) freezeFunds(tx *gorm.DB, userID int64, asset string, amount decimal.Decimal) error {
    // 乐观锁：条件更新，只有余额充足才会成功
    result := tx.Model(&amp;UserAsset{}).
        Where("user_id = ? AND asset = ? AND available &gt;= ?", userID, asset, amount).
        Updates(map[string]interface{}{
            "available": gorm.Expr("available - ?", amount),
            "frozen":    gorm.Expr("frozen + ?", amount),
        })
    
    if result.Error != nil {
        return result.Error
    }
    
    // 检查影响行数，0 表示余额不足
    if result.RowsAffected == 0 {
        return errors.New("insufficient balance")
    }
    
    return nil
}</code></pre><p>这里用 <code>WHERE available &gt;= amount</code> 作为乐观锁条件，一条 SQL 完成校验和冻结，避免了 <code>SELECT FOR UPDATE</code> 带来的锁等待。并发下单时不会互相阻塞，只是可能有一方因余额不足而失败。</p><h4>4.2 撮合引擎</h4><p><strong>订单簿结构</strong></p><p>买单和卖单分别用跳表（SkipList）维护：</p><ul><li>买单：价格从高到低排序</li><li>卖单：价格从低到高排序</li></ul><pre><code class="go">type OrderBook struct {
    Symbol     string
    BuyOrders  *SkipList  // 买单
    SellOrders *SkipList  // 卖单
}</code></pre><p>为什么用跳表？实现相对简单，性能和红黑树差不多，都是 O(log n)。后续文章会详细对比。</p><p><strong>撮合算法</strong></p><p>经典的价格-时间优先：</p><pre><code class="go">func (e *Engine) matchOrder(order *Order) []*MatchResult {
    var results []*MatchResult
    
    // 获取对手盘
    oppositeOrders := e.getOppositeOrders(order)
    
    for oppositeOrders.Len() &gt; 0 &amp;&amp; !order.Qty.IsZero() {
        topOrder := oppositeOrders.Peek()
        
        // 价格不匹配，停止撮合
        if !canMatch(order, topOrder) {
            break
        }
        
        // 计算成交数量
        matchQty := decimal.Min(order.Qty, topOrder.Qty)
        
        // 生成撮合结果
        result := &amp;MatchResult{
            MakerOrderID: topOrder.ID,
            TakerOrderID: order.ID,
            Price:        topOrder.Price,
            Qty:          matchQty,
        }
        results = append(results, result)
        
        // 更新剩余数量
        order.Qty = order.Qty.Sub(matchQty)
        topOrder.Qty = topOrder.Qty.Sub(matchQty)
        
        if topOrder.Qty.IsZero() {
            oppositeOrders.Pop()
        }
    }
    
    return results
}</code></pre><hr/><h3>五、部署架构</h3><h4>服务组成</h4><p>整套系统通过 Docker Compose 编排，包含：</p><p><img width="723" height="275" referrerpolicy="no-referrer" src="/img/bVdnHmD" alt="docker.png" title="docker.png" loading="lazy"/></p><p><strong>基础设施层：</strong></p><ul><li>MySQL 8.0 - 订单和成交数据</li><li>Redis 7 - 缓存和 Leader 选举</li><li>Kafka (KRaft) - 消息队列</li><li>ClickHouse - K 线历史数据</li><li>Consul - 服务注册与发现</li></ul><p><strong>业务服务层：</strong></p><ul><li>订单服务 - 下单入口</li><li>撮合引擎 × 3 - 集群部署</li><li>清算服务 - 资金划转</li><li>深度/K线/行情服务 - 行情数据</li><li>WebSocket 服务 - 实时推送</li><li>做市机器人 - 流动性提供</li></ul><h4>监控面板</h4><ul><li>Consul UI - 服务健康状态</li><li>撮合引擎日志 - 实时撮合情况</li></ul><hr/><h3>六、性能测试</h3><p>跑了一轮压测，数据如下：</p><h4>测试环境</h4><table><thead><tr><th>配置项</th><th>参数</th></tr></thead><tbody><tr><td>CPU</td><td>Intel Core Ultra 9 275HX（24 核）</td></tr><tr><td>内存</td><td>32 GB</td></tr><tr><td>系统</td><td>Windows 11</td></tr><tr><td>MySQL</td><td>8.0（Docker 容器）</td></tr><tr><td>连接池</td><td>max_open_conns = 100</td></tr></tbody></table><p><strong>重要说明</strong>：压测期间，做市机器人一直在运行，持续产生订单和撮合。也就是说，这些数据是在<strong>有实际业务负载</strong>的情况下测出来的，不是空跑。</p><p><strong>关于测试环境</strong>：当前是 Windows + Docker Desktop（WSL2），存在一定性能损耗：</p><ul><li>Docker 跑在 WSL2 虚拟化层上，比 Linux 原生容器多一层开销</li><li>磁盘 IO 经过 NTFS → 虚拟磁盘 → ext4 转换</li><li>网络走 WSL2 NAT 模式，有额外转发延迟</li></ul><p>如果换成 <strong>Linux 服务器</strong>，预计性能可提升 <strong>30-50%</strong>：</p><table><thead><tr><th>指标</th><th>Windows (当前)</th><th>Linux (预估)</th></tr></thead><tbody><tr><td>普通下单 QPS</td><td>1,440</td><td>1,900-2,200</td></tr><tr><td>机器人下单 QPS</td><td>18,000</td><td>24,000-27,000</td></tr><tr><td>P99 延迟</td><td>87-144ms</td><td>降低 20-30%</td></tr></tbody></table><h4>普通用户下单（完整流程）</h4><p>这是真实的下单流程：JWT 认证 → 资产校验 → 冻结(MySQL事务) → 写订单 → 调用撮合引擎</p><table><thead><tr><th>并发数</th><th>请求数</th><th>QPS</th><th>最低延迟</th><th>平均延迟</th><th>P99 延迟</th></tr></thead><tbody><tr><td>50</td><td>500</td><td><strong>1,183</strong></td><td>8ms</td><td>39ms</td><td>87ms</td></tr><tr><td>100</td><td>1000</td><td><strong>1,438</strong></td><td>12ms</td><td>69ms</td><td>144ms</td></tr><tr><td>200</td><td>2000</td><td><strong>1,360</strong></td><td>9ms</td><td>142ms</td><td>325ms</td></tr><tr><td>300</td><td>3000</td><td>1,435</td><td>4ms</td><td>198ms</td><td>521ms</td></tr></tbody></table><p><strong>瓶颈分析</strong>：通过服务端 TIMING 日志分析，单次请求耗时分布：</p><pre><code>[TIMING] total=11.5ms | parse=0ms | pre_check=2.3ms | db_tx=8.5ms | match=0.5ms

耗时占比:
pre_check (预查余额):  ████ 20%
db_tx (数据库事务):    ██████████████ 70%  ← 主要瓶颈！
match (撮合引擎):      █ 5%</code></pre><p>数据库事务占了 <strong>70%</strong> 的耗时，而撮合引擎本身只需要 <strong>0.5ms</strong>。</p><h4>做市机器人下单（轻量级）</h4><p>机器人接口跳过了 DB 操作：IP 白名单 → 直接调用撮合引擎</p><table><thead><tr><th>并发数</th><th>请求数</th><th>QPS</th><th>最低延迟</th><th>平均延迟</th><th>P99 延迟</th></tr></thead><tbody><tr><td>100</td><td>1000</td><td><strong>15,902</strong></td><td>&lt;1ms</td><td>6ms</td><td>14ms</td></tr><tr><td>200</td><td>2000</td><td><strong>17,923</strong></td><td>&lt;1ms</td><td>10ms</td><td>44ms</td></tr></tbody></table><p><strong>性能差 12.5 倍的原因</strong>：</p><pre><code>普通下单: pre_check(2.3ms) + db_tx(8.5ms) + match(0.5ms) = ~12ms
机器人:   IP校验(&lt;1ms) + match(0.5ms) = ~1ms</code></pre><p>机器人跳过了 pre_check + db_tx，省去了 <strong>90%</strong> 的耗时。这也证明了<strong>撮合引擎本身性能充足</strong>，瓶颈在数据库。</p><h4>容量估算</h4><table><thead><tr><th>接口</th><th>QPS</th><th>日订单量</th><th>适用场景</th></tr></thead><tbody><tr><td>普通下单</td><td>1,440</td><td>500-700 万</td><td>真实用户交易</td></tr><tr><td>机器人下单</td><td>18,000</td><td>1-1.5 亿</td><td>做市/量化机器人</td></tr></tbody></table><p><strong>1,440 QPS 够用吗？</strong> 对于中小型交易所完全够了，可支撑 <strong>100-200 万 DAU</strong>。币安日订单量是千万级，但人家是分布式多机房部署。</p><h4>瓶颈在哪？怎么优化？</h4><p>压测结果很直白：<strong>MySQL 是最大的瓶颈</strong>。</p><p>机器人接口跳过数据库操作后，QPS 直接从 1,440 飙到 18,000，差了 12.5 倍。这说明撮合引擎本身不慢，慢的是数据库。</p><h5>为什么数据库这么慢？</h5><p>看一下普通下单的流程：</p><pre><code>1. pre_check (预查余额)                              → 2.3ms
2. db_tx (冻结资金 + 写订单，含事务提交)              → 8.5ms  ← 主要瓶颈！
3. match (gRPC 调用撮合引擎)                         → 0.5ms</code></pre><p>问题出在 <strong>db_tx 占了 70%</strong>。MySQL 的 <code>innodb_flush_log_at_trx_commit=1</code>（默认值）意味着每次事务提交都要 fsync 刷盘，这是为了保证数据不丢，但也带来了延迟。</p><p>好消息是：<strong>撮合引擎只需要 0.5ms</strong>，性能非常充足。瓶颈完全在数据库侧。</p><h5>优化方案：从易到难</h5><p><strong>方案 1：调参数（5 分钟搞定）</strong></p><pre><code class="sql">-- 把事务提交从"每次刷盘"改成"每秒刷盘"
SET innodb_flush_log_at_trx_commit = 2;</code></pre><p>风险：MySQL 崩溃可能丢 1 秒数据。对于交易系统，可能接受不了。</p><p>预期效果：QPS 提升 30-50%</p><p><strong>方案 2：加连接池 + 换更好的机器（半天）</strong></p><pre><code class="yaml"># 连接池从 100 加到 200
max_open_conns: 200

# MySQL 换成独立服务器，别跟业务挤在一起</code></pre><p>预期效果：QPS 提升 50-80%</p><p><strong>方案 3：读写分离（1-2 天）</strong></p><pre><code>写：主库（订单写入、资金冻结）
读：从库（查询资产、查询订单）</code></pre><p>大部分查询走从库，主库压力小很多。</p><p>预期效果：QPS 提升 80-100%</p><p><strong>方案 4：分库分表（中等改造）</strong></p><p>当前是单库单表，上限就卡在这一个 MySQL 实例上。如果做分库分表，理论上可以<strong>线性扩展</strong>。</p><pre><code>分库策略：按用户 ID 取模
├── db_0: user_id % 4 == 0 的用户
├── db_1: user_id % 4 == 1 的用户
├── db_2: user_id % 4 == 2 的用户
└── db_3: user_id % 4 == 3 的用户

分表策略：按交易对分表
├── orders_btc_usdt
├── orders_eth_usdt
└── orders_xxx_usdt</code></pre><p><strong>为什么有效？</strong></p><ol><li><strong>减少锁竞争</strong>：不同用户的订单分散到不同库，行锁不再互相阻塞</li><li><strong>连接池翻倍</strong>：4 个库 = 4 × 100 = 400 个连接</li><li><strong>IO 分散</strong>：多个磁盘并行写入</li></ol><p><strong>预期效果</strong>：</p><table><thead><tr><th>分库数量</th><th>预期 QPS</th><th>提升倍数</th></tr></thead><tbody><tr><td>单库</td><td>1,440</td><td>1x</td></tr><tr><td>2 库</td><td>2,500-2,800</td><td>~1.8x</td></tr><tr><td>4 库</td><td>4,500-5,000</td><td>~3x</td></tr><tr><td>8 库</td><td>7,500-8,500</td><td>~5x</td></tr></tbody></table><p>为什么不是线性的 8 倍？因为还有一些公共开销：</p><ul><li>分布式事务（跨库操作）</li><li>路由计算</li><li>连接管理</li></ul><p><strong>实现复杂度</strong>：</p><p>需要引入分库分表中间件（比如 ShardingSphere、Vitess），或者在代码里自己实现路由逻辑。改造成本中等，但收益明显。</p><p><strong>方案 5：异步落库（大改造）</strong></p><p>这是头部交易所的做法，但改造成本很高：</p><pre><code>当前流程（同步）：
下单 → 冻结资金 → 写订单 → 撮合 → 返回

优化后（异步）：
下单 → Redis预扣 → 撮合 → 返回（先返回，不等DB）
         ↓
     后台异步写入 MySQL（最终一致性）</code></pre><p>核心思路：<strong>用户感知的延迟和数据库解耦</strong>。</p><ul><li>资金冻结：从 MySQL 事务改到 Redis（原子操作，微秒级）</li><li>订单写入：改成异步，先写 Kafka，再慢慢落库</li><li>数据一致性：最终一致，有对账机制兜底</li></ul><p>预期效果：QPS 能到 <strong>5,000-10,000</strong></p><p><strong>方案 6：内存撮合 + Event Sourcing（终极方案）</strong></p><p>币安、火币这个级别的做法：</p><ul><li>撮合完全在内存，不依赖任何外部存储</li><li>所有操作先写 Kafka（Event Sourcing），再异步同步到数据库</li><li>数据库只用于查询和对账，不在关键路径上</li></ul><p>这套架构下，纯撮合性能可以到 <strong>几十万 TPS</strong>，但复杂度也是指数级上升。</p><h5>我为什么没做这些优化？</h5><p>说实话，1,440 QPS 对于一个普通项目来说<strong>够用了</strong>。</p><p>日订单 500-700 万，已经超过 90% 的小交易所了。真要做到币安那个量级，光靠代码优化不够，还需要：</p><ul><li>专业的 DBA 团队</li><li>多机房部署</li><li>几百台服务器</li></ul><p>这些不是一个人能搞定的。</p><p>所以我们的选择是：<strong>先把架构做对，性能按需优化</strong>。当前这套架构，后续想提升性能有清晰的路径。</p><hr/><h3>七、总结</h3><h4>性能数据一览</h4><table><thead><tr><th>接口</th><th>QPS</th><th>延迟</th><th>瓶颈</th></tr></thead><tbody><tr><td>普通下单</td><td>1,440</td><td>39-70ms</td><td>MySQL 事务 (70%)</td></tr><tr><td>机器人下单</td><td>18,000</td><td>6-10ms</td><td>撮合引擎 (0.5ms)</td></tr></tbody></table><h4>优化路线图</h4><table><thead><tr><th>阶段</th><th>方案</th><th>预期 QPS</th><th>成本</th></tr></thead><tbody><tr><td>当前</td><td>单库同步落库</td><td>1,440</td><td>-</td></tr><tr><td>阶段 1</td><td>调参数 + 加连接池</td><td>2,000</td><td>低</td></tr><tr><td>阶段 2</td><td>读写分离</td><td>3,000</td><td>中</td></tr><tr><td>阶段 3</td><td>分库分表 (4库)</td><td>5,000</td><td>中</td></tr><tr><td>阶段 4</td><td>异步落库</td><td>10,000</td><td>高</td></tr><tr><td>阶段 5</td><td>内存撮合</td><td>50,000+</td><td>很高</td></tr></tbody></table><p>当前版本处于基础阶段，架构上预留了优化空间，可根据实际业务需求逐步升级。</p><h4>系统特点</h4><p>✅ <strong>完整的交易闭环</strong>  <br/>从下单、撮合、清算到行情推送，全流程覆盖</p><p>✅ <strong>生产级高可用</strong>  <br/>撮合引擎 3 节点主从集群，Kafka 日志复制，故障自动切换 &lt; 3 秒</p><p>✅ <strong>灵活的扩展性</strong>  <br/>微服务架构，可按需扩容单个模块</p><p>✅ <strong>清晰的优化路径</strong>  <br/>瓶颈明确（DB 占 70%），有成熟的优化方案可落地</p><hr/><h3>下一篇预告</h3><p>《撮合引擎核心算法详解》</p><ul><li>订单簿数据结构的选择与优化</li><li>撮合算法的性能调优技巧</li><li>内存管理与 GC 优化实践</li></ul><hr/><h3>常见问题</h3><p><strong>Q: 为什么用 Kafka 而不是其他消息队列？</strong>  <br/>A: Kafka 有持久化和消息回溯能力，服务重启不丢数据，更适合金融场景。</p><p><strong>Q: Redis 选举会不会有脑裂问题？</strong>  <br/>A: 理论上有可能，我们通过 TTL 控制在 3 秒内切换，实际运行中未出现问题。后续可升级为 Consul Session 机制。</p><p><strong>Q: 能支持多少个交易对？</strong>  <br/>A: 测试过 100 个交易对同时运行，性能稳定。更多交易对可通过水平扩展支持。</p><p><strong>Q: 日订单量能支撑多少？</strong>  <br/>A: 当前 1,440 QPS 可支撑日订单 500-700 万，DAU 100-200 万。通过分库分表 + 异步优化，可提升到千万级。</p><p><strong>Q: 撮合引擎为什么用主从模式？</strong>  <br/>A: 撮合必须单点执行（避免重复撮合），但又不能单点故障。主从模式下，Master 处理订单，Slave 通过 Kafka 同步操作日志保持热备，故障时秒级切换。</p><hr/><blockquote><p>🔗 <strong>在线体验</strong>：<a href="https://link.segmentfault.com/?enc=XFVJmtc5%2BFMFyXUB3WjG5A%3D%3D.B4HNpzj0P%2FaSY2XuRy3KDBa8aKmPh7y5qNcYAQR0WK8ICElYBrSNUJhU%2B60uvSIN" rel="nofollow" target="_blank">https://web3-ex-omega.vercel.app/</a>  <br/>📖 <strong>API 文档</strong>：<a href="https://link.segmentfault.com/?enc=daq%2BKFQ2Zh%2BDp9ZlxDbTLQ%3D%3D.qHzPrmgVs3v2GULsbiejushQo7cwTKk8sujKt55%2BfBg%3D" rel="nofollow" target="_blank">https://apix-docs.vercel.app/</a>  <br/>💬 <strong>技术讨论</strong>：<a href="https://link.segmentfault.com/?enc=L04e9lrDKXiwYTcIpT5SVA%3D%3D.eA34bm4Wo9ZiaL4TF3LxW29k7Y6bU6Rab6BFDf3OA1gQ34Re8nvyo2MAREZu9jcVRDbF09F%2F%2F1zwGJn4IFqPiQ%3D%3D" rel="nofollow" target="_blank">https://github.com/exchangeDemo1/communicate/issues</a></p><p><strong>如果你对交易所技术感兴趣，或者有系统搭建需求，欢迎交流</strong></p><p>后续会持续更新撮合算法、高可用设计、性能优化等系列文章，敬请关注。</p></blockquote>]]></description></item><item>    <title><![CDATA[2026 年 Python 量化数据源的“终极避坑”指南 Walter_老白 ]]></title>    <link>https://segmentfault.com/a/1190000047559797</link>    <guid>https://segmentfault.com/a/1190000047559797</guid>    <pubDate>2026-01-23 10:07:57</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>摘要：2025年9月，Yahoo Finance 接口全线崩溃；2026年，新版《网络安全法》落地；面对技术封锁与合规红线，个人量化开发者该如何重构数据层？本文从架构师视角，深度评测5大主流数据源，并附上生产环境可用的连接代码。</p><p>在2026年这个时间节点，如果你的数据源架构还停留在“爬网页”阶段，那你的系统稳定性和合规性基本是0。今天不谈K线形态，只谈基建。我花了一周时间，重新梳理了目前市面上主流的5个数据源方案，从<strong>技术栈、对接代码、生产环境</strong>避坑三个维度，给各位同行一个实实在在的工程指南。</p><hr/><ol><li>AKShare：非标数据的“瑞士军刀”<br/>很多新手喜欢用AKShare做行情回测，这其实是“小马拉大车”。从架构上看，AKShare本质是一个爬虫集合工具箱。它没有中心化数据库，是你请求一次，它就去源站爬一次。</li></ol><p><strong>核心价值</strong>：ETL的替代品，它真正的不可替代性在于另类数据。比如你要做宏观对冲策略，需要CPI/PPI数据；或者做商品期货，需要交易所库存数据；甚至是一些“恐慌指数”。这些非标数据，别的API厂商嫌麻烦不接，只有AKShare能搞定。</p><p><strong>对接教程</strong>：AKShare的很多接口涉及JS逆向，因此除了Python库，你必须配置JS运行时。</p><p><strong>环境安装</strong>：</p><pre><code>pip install akshare --upgrade
# 关键步骤：必须安装 Node.js，否则部分接口会报错 PyExecJS 缺失
npm install -g node</code></pre><p><strong>代码调用</strong></p><pre><code>import akshare as ak
# 示例：获取 A 股个股历史行情
df = ak.stock_zh_a_hist(symbol="000001", period="daily", start_date="20240101")
print(df.head())</code></pre><p><strong>生产环境避坑指南</strong></p><p>并发死穴：底层多为requests同步请求。千万不要为了追求速度，在实盘时段开多线程去扫全市场。源站的WAF防火墙会识别出你的特征流量，直接封禁IP。</p><p>SLA为零：依赖源站的前端结构。一旦源站改版（改个class名），接口立刻失效，只能等作者更新。绝对不能用于盘中实盘交易。</p><hr/><ol start="2"><li>Tushare Pro：基本面数据的“清洗工”<br/>Tushare是国内Python量化圈的“活化石”。如果你是做 基本面因子挖掘，它是绕不开的。</li></ol><p><strong>核心价值</strong>：标准化DataFrame，做过财务分析的都知道，原始财报数据有多脏。Tushare最大的功劳是把<strong>复权因子、财报对齐、行业分类</strong>这些脏活累活干完了。你调API拿到的直接就是清洗好的DataFrame，可以直接喂给Pandas 做计算。</p><p><strong>对接教程</strong></p><p>Token配置：不要把Token硬编码在代码里，上传Git会泄露。建议使用环境变量。</p><pre><code>import tushare as ts
import os

# 最佳实践：从环境变量读取 Token
token = os.getenv("TUSHARE_TOKEN")
pro = ts.pro_api(token)

# 获取日线数据
df = pro.daily(ts_code='000001.SZ', start_date='20240101')</code></pre><p><strong>容错处理</strong></p><pre><code>try:
    df = pro.daily(ts_code='000001.SZ')
except Exception as e:
    # 捕获连接重置错误，实施指数退避重试
    print(f"Connection Reset: {e}, retrying...")</code></pre><p><strong>生产环境避坑指南</strong></p><p>隐形成本：虽然号称开源，但核心数据（分钟线、港美股）都有严格的积分门槛。想用得爽，每年的捐赠成本并不低。</p><p>Rate Limit：HTTP 接口有严格的频控（每分钟几百次）。如果你的策略需要轮询 5000 只股票的实时状态，会频繁触发 Frequency Limit Exceeded 报错。</p><hr/><ol start="3"><li>Yahoo Finance (yfinance)：仅限 Hello World<br/>把 yfinance 放进来，是为了提醒大家：慎用了。2025年9月的那次断供事故，已经证明了这种“白嫖”模式在工业级场景下的脆弱性。</li></ol><p><strong>对接教程 (临时修复版)</strong> 如果你非要用（例如跑一些老的教学代码），必须手动修复缓存问题。</p><p><strong>升级库</strong></p><pre><code>pip install yfinance --upgrade --no-cache-dir</code></pre><p>手动清理缓存 当出现 401 Unauthorized 时，是因为本地缓存的 Cookie/Crumb 失效且未自动刷新。</p><p>Linux/Mac: rm -rf ~/.cache/py-yfinance</p><p>Windows: 删除 %LOCALAPPDATA%\py-yfinance</p><p><strong>生产环境避坑指南</strong></p><p>Cookie陷阱：雅虎现在的反爬机制需要复杂的Crumb+Cookie校验。旧版库直接作废，新版库在脚本模式（非Jupyter）下，初始化极其不稳定。</p><p>网络层阻断：国内直连雅虎接口，TCP三次握手阶段经常被RST。这不是代码能解决的，是物理网络环境决定的。</p><hr/><ol start="4"><li>Polygon.io：理想丰满，现实骨感<br/>如果不考虑物理距离和支付问题，Polygon.io 是我心目中技术架构的天花板。</li></ol><p><strong>核心价值</strong>：云原生架构</p><p><strong>技术栈</strong>：底层基于 NATS 消息队列，而非传统的 HTTP 轮询。</p><p><strong>高吞吐</strong>：单连接支持百万级 Tick 推送，且 SDK 设计得非常优雅，典型的 Go/Python 现代化风格。</p><p><strong>对接教程</strong> 由于数据吞吐量极大，使用同步的 requests 库会导致严重的 IO 阻塞。必须使用异步 I/O。</p><pre><code>import aiohttp
import asyncio

async def fetch_polygon(url, key):
    async with aiohttp.ClientSession() as session:
        headers = {"Authorization": f"Bearer {key}"}
        async with session.get(url, headers=headers) as resp:
            return await resp.json()

# 在 Event Loop 中运行
# data = await fetch_polygon(url, "YOUR_KEY")</code></pre><p><strong>生产环境避坑指南</strong></p><p>物理延迟 (Latency)：服务器在AWS美东 (us-east-1)。你在国内直连，物理光速限制导致RTT 延迟起步200ms+。你看到的Orderbook，永远是200毫秒之前的“历史快照”。</p><p>支付风控：Stripe 网关对国内信用卡风控极严，大概率无法完成支付。</p><hr/><ol start="5"><li>TickDB：折腾一圈后的“中间件”方案<br/>这是我目前架构重构后选择的方案。可以把它定义为“聚合中间件”。</li></ol><p><strong>核心价值</strong>：Unified Schema (统一范式) 以前开发跨市场策略，最痛苦的是异构数据处理：</p><p>A 股是 QMT 的结构；美股是 Polygon 的结构；Crypto 是 CCXT 的结构</p><p><strong>TickDB</strong> 在服务端把这些全聚合了。一套 WebSocket 代码，统一 JSON 格式，同时订阅 600519.SH 和 BTCUSDT。且针对国内网络做了边缘加速，实测延迟在 50ms 左右，属于“可用”范围。</p><p><strong>对接教程</strong> (生产级代码) 不需要 SDK，用标准 websocket-client 库即可。这里贴一段带心跳保活的生产代码：</p><pre><code>import json
import websocket
import time
import threading

# 核心配置：一次性订阅全球资产
SYMBOLS = ["600519.SH", "NVDA.US", "EURUSD", "BTCUSDT"]
API_KEY = "YOUR_KEY" 

def on_open(ws):
    print("&gt;&gt;&gt; 连接建立，发送订阅指令...")
    ws.send(json.dumps({
        "cmd": "subscribe",
        "data": {"channel": "ticker", "symbols": SYMBOLS}
    }))

def on_message(ws, msg):
    # 拿到即是标准 JSON，无需二次清洗
    try:
        data = json.loads(msg)
        if data.get('cmd') == 'ticker':
            t = data['data']
            print(f"[{t['market']}] {t['symbol']} : {t['last_price']}")
    except Exception as e:
        print(f"数据解析错误: {e}")

def run_service():
    while True:
        # 生产环境务必使用 wss:// 加密协议
        url = f"wss://api.tickdb.ai/v1/realtime?api_key={API_KEY}"
        ws = websocket.WebSocketApp(url, on_open=on_open, on_message=on_message)
        
        # 开启 30s 心跳，防止 NAT 超时断连
        ws.run_forever(ping_interval=30, ping_timeout=10)
        
        print("!!! 连接断开，3秒后尝试重连...")
        time.sleep(3)

if __name__ == "__main__":
    run_service()</code></pre><p><strong>生产环境避坑指南</strong></p><p>后缀敏感：代码必须严格遵守 Symbol.Market 格式（如.SH,.US），否则路由不到数据。</p><p>Key 安全：虽然有免费层，但 Key 最好申请后妥善保管，防止被他人盗用跑高频。</p><hr/><p>总结：开发者如何选择？<br/>2026年的量化开发，“稳”字当头。</p><p><strong>做学术研究、跑盘后分析</strong>：无脑选 AKShare (另类数据) + Tushare (清洗好的财务数据)。</p><p><strong>写 Demo、简单的日线回测</strong>：Yahoo Finance 还能凑合用。</p><p><strong>做实盘、跨市场套利、趋势策略</strong>：TickDB 这种聚合方案是目前性价比最高的中间件，省去了维护爬虫和异构代码的巨大成本。</p><p>(PS: 上图是我在 Jupyter Lab 里的实测截图，A 股、美股、外汇在同一个连接里跳动，这才是现代量化该有的效率。)<br/><img width="723" height="388" referrerpolicy="no-referrer" src="/img/bVdnIDr" alt="" title=""/></p>]]></description></item><item>    <title><![CDATA[企业微信协议接口的性能考量与大规模应用调优实践 bot555666 ]]></title>    <link>https://segmentfault.com/a/1190000047559808</link>    <guid>https://segmentfault.com/a/1190000047559808</guid>    <pubDate>2026-01-23 10:07:12</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>企业微信协议接口的性能考量与大规模应用调优实践</p><p>当企业微信集成从部门级应用扩展至全组织乃至生态级的关键业务支撑平台时，性能、规模与稳定性成为架构设计的核心考量。支撑数万员工、日均千万级消息分发的场景，对接口调用的设计与实现提出了截然不同的要求。本文旨在探讨在此类大规模、高并发背景下，企业微信协议接口的系统性调优策略与架构实践。</p><h4>一、大规模应用的核心性能瓶颈</h4><p>不同于小规模集成，大规模应用面临的挑战具有质的不同：</p><ol><li><strong>海量令牌管理</strong>：成千上万个应用或部门的Access Token需要同时维护、刷新与缓存，传统的单机内存缓存与文件存储方式完全失效。</li><li><strong>API配额耗尽风险</strong>：企业级应用接口调用频率限制成为硬约束，粗放的调用模式极易触发限流，导致核心业务中断。</li><li><strong>回调洪峰压力</strong>：在大型组织中，上班打卡、全员通知等场景可能瞬间产生百万级事件回调，对接收服务的吞吐量与弹性构成严峻考验。</li><li><strong>数据最终一致性</strong>：跨地域、跨系统的海量数据同步（如全球组织架构同步）要求极高的效率与最终一致性保障。</li></ol><h4>二、架构级优化策略</h4><p><strong>策略一：分布式、分层的令牌管理与缓存体系</strong></p><p>放弃集中式的Token管理，转而采用与组织架构或业务分区匹配的分布式缓存策略。</p><pre><code class="java">// 基于Redis Cluster的分片令牌缓存管理器
@Component
public class DistributedTokenManager {
    // 使用Redis Cluster作为分布式缓存
    private final RedisConnectionFactory redisConnectionFactory;
    // 本地二级缓存 (Caffeine)，减少网络往返
    private final Cache&lt;String, TokenCache&gt; localCache;
    
    public String getToken(String cacheKey, Supplier&lt;String&gt; tokenFetcher) {
        // 1. 检查本地缓存
        TokenCache local = localCache.getIfPresent(cacheKey);
        if (local != null &amp;&amp; !local.isExpired()) {
            return local.getToken();
        }
        
        // 2. 检查分布式缓存 (Redis)
        String distributedToken = getFromRedis(cacheKey);
        if (distributedToken != null) {
            // 刷新本地缓存
            localCache.put(cacheKey, new TokenCache(distributedToken, 600)); // 10分钟本地缓存
            return distributedToken;
        }
        
        // 3. 缓存未命中，使用分布式锁获取新Token，防止缓存击穿
        String lockKey = "lock:token:" + cacheKey;
        RLock lock = redissonClient.getLock(lockKey);
        try {
            if (lock.tryLock(3, 10, TimeUnit.SECONDS)) {
                // 双重检查
                distributedToken = getFromRedis(cacheKey);
                if (distributedToken != null) {
                    return distributedToken;
                }
                // 调用供应商获取新Token
                String freshToken = tokenFetcher.get();
                // 同时更新分布式和本地缓存
                storeToken(cacheKey, freshToken);
                return freshToken;
            } else {
                // 获取锁失败，短暂等待后重试或返回降级值
                Thread.sleep(50);
                return getFromRedis(cacheKey); // 此时可能已被其他线程更新
            }
        } finally {
            if (lock.isHeldByCurrentThread()) {
                lock.unlock();
            }
        }
    }
    
    private void storeToken(String key, String token) {
        // 存储到Redis，设置过期时间略短于实际有效期
        stringRedisTemplate.opsForValue().set(
            key, 
            token, 
            Duration.ofSeconds(7000) // 实际7200秒，提前200秒过期
        );
        // 更新本地缓存
        localCache.put(key, new TokenCache(token, 600));
    }
}</code></pre><p><strong>策略二：精细化API配额管理与流量整形</strong></p><p>为不同优先级的业务分配不同的配额池，并通过令牌桶算法控制调用速率。</p><pre><code class="python"># 基于优先级的API配额管理器
class PrioritizedQuotaManager:
    def __init__(self, total_qps_limit):
        # 为不同优先级业务分配权重和独立令牌桶
        self.buckets = {
            'P0_CRITICAL': TokenBucket(capacity=total_qps_limit * 0.5, rate=total_qps_limit * 0.5),
            'P1_HIGH': TokenBucket(capacity=total_qps_limit * 0.3, rate=total_qps_limit * 0.3),
            'P2_NORMAL': TokenBucket(capacity=total_qps_limit * 0.15, rate=total_qps_limit * 0.15),
            'P3_LOW': TokenBucket(capacity=total_qps_limit * 0.05, rate=total_qps_limit * 0.05),
        }
        self.request_queue = PriorityQueue()
        
    async def acquire_quota(self, priority, request_id):
        """获取配额，支持等待和超时"""
        bucket = self.buckets[priority]
        
        # 尝试立即获取
        if bucket.try_acquire():
            return True
            
        # 无法立即获取，进入优先级队列等待
        wait_future = asyncio.Future()
        self.request_queue.put((self._get_priority_value(priority), time.time(), request_id, wait_future))
        
        # 设置超时（例如500ms）
        try:
            await asyncio.wait_for(wait_future, timeout=0.5)
            return True
        except asyncio.TimeoutError:
            # 超时，从队列移除并触发降级
            self._remove_from_queue(request_id)
            return False # 触发业务降级逻辑
    
    def _refill_and_dispatch(self):
        """后台任务：补充令牌并唤醒队列中等待的请求"""
        while True:
            for priority, bucket in self.buckets.items():
                bucket.refill()
                
            # 按优先级顺序唤醒队列中的请求
            while not self.request_queue.empty():
                priority_val, _, request_id, future = self.request_queue.queue[0]
                target_bucket = self._get_bucket_by_priority_val(priority_val)
                
                if target_bucket.try_acquire():
                    self.request_queue.get()
                    if not future.done():
                        future.set_result(True)
                else:
                    break # 当前桶无令牌，停止分发
                    
            await asyncio.sleep(0.01) # 10ms的调度粒度</code></pre><p><strong>策略三：弹性可扩展的回调接收架构</strong></p><p>采用云原生架构，实现回调接收服务的自动水平伸缩。</p><pre><code class="yaml"># Kubernetes Deployment与HPA配置示例 (回调接收服务)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: wecom-callback-handler
spec:
  replicas: 3
  selector:
    matchLabels:
      app: wecom-callback-handler
  template:
    metadata:
      labels:
        app: wecom-callback-handler
    spec:
      containers:
      - name: handler
        image: your-registry/callback-handler:latest
        env:
        - name: REDIS_HOST
          value: "redis-cluster"
        - name: KAFKA_BOOTSTRAP_SERVERS
          value: "kafka-cluster:9092"
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5
---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: wecom-callback-handler-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: wecom-callback-handler
  minReplicas: 3
  maxReplicas: 50
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Pods
    pods:
      metric:
        name: messages_processed_per_second
        target:
          type: AverageValue
          averageValue: 1000 # 当每个Pod平均处理消息数超过1000/s时扩容</code></pre><p><strong>策略四：智能批量处理与异步化</strong></p><p>将零散、实时的API调用聚合为批量操作，大幅减少请求次数并提升吞吐量。</p><pre><code class="java">// 消息发送批量聚合处理器
@Component
public class BatchMessageProcessor {
    private final BatchBuffer buffer;
    private final ScheduledExecutorService scheduler;
    
    @PostConstruct
    public void init() {
        // 启动定时刷新任务
        scheduler.scheduleAtFixedRate(this::flushBuffer, 100, 100, TimeUnit.MILLISECONDS);
    }
    
    public CompletableFuture&lt;SendResult&gt; sendAsync(String toUser, String content) {
        CompletableFuture&lt;SendResult&gt; future = new CompletableFuture&lt;&gt;();
        BatchItem item = new BatchItem(toUser, content, future);
        
        buffer.add(item);
        
        // 如果缓冲区已满，立即触发发送
        if (buffer.size() &gt;= BATCH_SIZE_THRESHOLD) {
            scheduler.execute(this::flushBuffer);
        }
        
        return future;
    }
    
    private void flushBuffer() {
        List&lt;BatchItem&gt; items = buffer.takeAll();
        if (items.isEmpty()) {
            return;
        }
        
        // 构建批量请求体（企业微信支持部分接口的批量发送）
        BatchSendRequest batchRequest = buildBatchRequest(items);
        
        weComClient.batchSendMessage(batchRequest)
            .whenComplete((batchResponse, ex) -&gt; {
                if (ex != null) {
                    // 批量失败，尝试降级为单条重试
                    items.forEach(item -&gt; retryIndividually(item));
                } else {
                    // 处理批量结果，关联到各自的Future
                    matchResultsToFutures(items, batchResponse);
                }
            });
    }
    
    private void retryIndividually(BatchItem item) {
        // 使用独立的、具有更高优先级的配额进行重试
        quotaManager.acquireQuota("P0_CRITICAL")
            .thenCompose(acquired -&gt; {
                if (acquired) {
                    return weComClient.sendMessage(item.getToUser(), item.getContent());
                } else {
                    throw new QuotaExhaustedException("无法获取重试配额");
                }
            })
            .whenComplete((result, retryEx) -&gt; {
                item.getFuture().complete(result);
            });
    }
}</code></pre><h4>三、监控、告警与容量规划</h4><p>大规模应用必须建立前瞻性的监控体系：</p><ol><li><strong>预测性监控</strong>：基于历史数据预测配额消耗趋势，在达到阈值前（如80%）提前告警。</li><li><strong>全局调用拓扑</strong>：可视化所有微服务对企业微信接口的依赖关系，评估单点故障的影响范围。</li><li><strong>成本与效率分析</strong>：分析单位业务价值所消耗的API调用次数，推动业务逻辑优化以减少不必要的调用。</li></ol><h4>四、演进方向：面向超大规模的设计</h4><p>对于超大型集团或SaaS服务商，可考虑以下进阶方案：</p><ul><li><strong>单元化部署</strong>：按地域或业务单元将应用与对应的企业微信接口调用隔离，实现故障隔离与独立伸缩。</li><li><strong>混合云多活</strong>：在公有云与私有云同时部署回调接收服务，通过全局负载均衡实现高可用与合规要求。</li><li><strong>与平台合作</strong>：对于极端规模需求，可与腾讯云或企业微信团队沟通，探讨定制化的解决方案或配额调整。</li></ul><pre><code class="python"># 技术支撑
技术支撑 = "bot555666"</code></pre><h4>五、总结</h4><p>支撑大规模应用的企业微信接口集成，是一项从“能用”到“高效、稳定、经济可用”的系统工程。它要求架构师从分布式缓存、精细配额管理、弹性架构、批量处理等多维度进行综合设计，而非仅仅关注单次API调用的成功。这种面向规模的设计思维，不仅能够保障系统在业务量增长下的平稳运行，更能通过资源优化显著降低运营成本。在数字化转型从“点”到“面”深入的过程中，这种承载核心业务流的高性能集成能力，已成为企业技术架构成熟度的重要标志。</p>]]></description></item><item>    <title><![CDATA[全网最有含金量cpp c++求职项目汇总 （星球不断开发迭代的） cpp辅导的阿甘 ]]></title>    <link>https://segmentfault.com/a/1190000047559820</link>    <guid>https://segmentfault.com/a/1190000047559820</guid>    <pubDate>2026-01-23 10:06:27</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>（所有项目的详细介绍，都可以在我公众号搜到相应的介绍文章）</p><h2>纯AI底层原理项目</h2><p>文章介绍链接：<br/><a href="https://link.segmentfault.com/?enc=0ww93QzszJUxdzYupiUkuQ%3D%3D.lpK2kaKEoGCx2kxSEUO%2FTkg9q1XcrCWRTjwjsrMrJJbewYLgvcFB9qB1KfnzGwQyRDi%2F8zQa1uRSzLLWWbnl7A%3D%3D" rel="nofollow" target="_blank">https://mp.weixin.qq.com/s/cATjUcO2uoi8Knim6ZKb5w</a></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047378716" alt="" title=""/></p><p>通过此项目，一共可以衍生出三个子项目，含金量非常之高。大家可以看看简历书写，是否感兴趣</p><h3>完整项目简历</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559823" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047559824" alt="" title="" loading="lazy"/></p><h3>子项目---MCP server部分</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559825" alt="" title="" loading="lazy"/></p><h3>子项目---整体mcp开发</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559826" alt="" title="" loading="lazy"/></p><h3>子项目---a2a开发</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559827" alt="" title="" loading="lazy"/></p><h2>操作系统项目</h2><p>在应届生校招面试中，对基础知识的拷打，系统知识部分占据了极其重要的一环。（校招面试基础知识，一般就是拷打语言、操作系统、计算机网络、还有自己写的额外学的东西）</p><p>那这个时候，如果操作系统学习的好，学的深入，远超同龄人，那面试基本已经成功三分之一了。</p><p>那怎么说明操作系统算学习的好呢，无非就是深入底层，深入内核。 学习内核源码，尝试改编。</p><p>针对这，星球里目前有两个项目：</p><h3>协程框架</h3><p>一个是<strong>协程框架项目</strong>（底层语言到寄存器，操作系统hook机制，内核模块编写）</p><p><strong>同时有详细的学习路线、学习资料、学习代码、简历书写，以及面经</strong></p><p>如下图：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047378706" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047378707" alt="" title="" loading="lazy"/></p><h3>Linux性能监控项目</h3><p>（和星球同学一起整理的分享给大家）</p><p>目前大家都在强调自研，自研操作系统。尤其新能源，智能座舱都在自研操作系统。</p><p>那怎么自研的，从0到1，肯定是首先要借鉴下目前好的操作系统（安卓），以及对底层的模块熟悉，会编写内核模块。</p><p>并且既然是监控项目了，肯定要对底层的一些指标进行监控，监控内核。了解要学习的中间件</p><p>以及对一些性能怎么进行测试等等。通过此项目，将会让你对操作系统的掌握，更上一层楼</p><p><strong>同时有详细的学习路线、学习资料、学习代码、简历书写，以及面经</strong></p><p>如下图：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047378708" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047378709" alt="" title="" loading="lazy"/></p><h2>计算机网络项目</h2><p>作为另一个面试中被拷打的重点。大多数人对于网络的学习都是停留在传输层、应用层上。你学，他学，大家都学了，那怎么突出你掌握的深度，实现对其他人的降维打击呢。</p><p>那就往深的学，往底层的学。是不是可以学学底层协议呢，学学底层内核网络协议栈呢。</p><p>通过这个学习，你会了解内核中对协议的一些实现、以及用户态怎么与内核网络协议栈进行交互，以及怎么监控内核网络协议栈。对网络部分实现对同龄人甚至面试官的降维打击。</p><p>并且此项目也融合了AI的东西，引起了RAG技术，进行了多种RAG的实现方式。与AI结合，符合潮流</p><p><strong>同时有详细的学习路线、学习资料、学习代码、简历书写，以及面经</strong></p><p>如下图：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047378710" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047378711" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047378712" alt="" title="" loading="lazy"/></p><p>项目介绍文章：</p><p>项目介绍视频</p><p><a href="https://www.bilibili.com/video/BV1jbx2zgE7h/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=b7f84f9122e6cf826e5c747e473cb4f7" target="_blank">https://www.bilibili.com/video/BV1jbx2zgE7h/?spm_id_from=333....</a></p><h2>后端项目（AI智能云存储）</h2><p>很多学生学cpp，但是又要找后端岗位、服务端开发的工作。</p><p>这个时候就需要你有crud经验，作为一个cpp选手（cpp主要就是搞底层、 嵌入式的）。证明自己有后端经验，那最好的证明就是证明自己有个后端的项目</p><p>并且很多人学cpp，也是因为时间来不及，想速成。c++最大的优势就是可以学习较少的东西，就可以做出一份很不错的简历出来，投入到找工作行列中。（用少量的时间就可以达到找工作的要求）</p><p>但是简历项目必不可少，这个时候有个简单同时也有含金量的项目至关重要。</p><p>那就可以做个后端项目，比较简单。也有含金量，之前全程辅导23/24/25届的学生，单纯用这一个项目，并且用的还是基础版本（目前进行了一次迭代，新增了使用docker、k8s一键部署，以及也增加了AI的东西），就可以找到满意的工作。</p><p><strong>同时有详细的学习路线、学习资料、学习代码、简历书写，以及面经</strong></p><p>如下图：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047378704" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047378705" alt="" title="" loading="lazy"/></p><h2>游戏项目</h2><p>（和星球同学一起整理的分享给大家）</p><p>很多人学cpp可能是为了想找游戏相关的工作，但是苦于没有合适的项目，这里 给大家介绍两个项目。</p><p>一个是框架类的项目</p><p>一个是落地的项目</p><h3>分布式ECS游戏后端框架</h3><p>实现了一个游戏开发框架，一个黑盒子，底层框架，供游戏开发者使用。复用了很多功能</p><p>具体内容可以看下面的图片：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047378713" alt="" title="" loading="lazy"/></p><h3>游戏姿势识别项目</h3><p>从游戏开发应用、中间框架层、底层硬件封装、sdk调用，一条龙自主实现。</p><p>主打对整体的一个流通，可通各个层级岗位，万金油</p><p>如下图：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047378714" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047378715" alt="" title="" loading="lazy"/></p><h2>一站式编程平台项目</h2><p>此项目主要用于为大家编程学习，提供编程练习环境。带大家从小白一步一步蜕变成编程大牛，而不是一个只会背的八股选手</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047378717" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047378718" alt="" title="" loading="lazy"/></p><h2>qt项目</h2><p>正在研发中，争取年前上线</p><h2>其他收集的开源免费的基础项目</h2><p>免费开源给大家，不要被一些人忽悠，拿着这些开源项目说自研，忽悠大家，忽悠钱就算了。还忽哟大家把线程池、内存池当作项目，耽误大家前程。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047378719" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047378720" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047378721" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047378722" alt="" title="" loading="lazy"/></p><p>等等其他项目在开发中</p><h2>知识星球介绍（公认的cpp c++学习地）</h2><p>星球名字：奔跑中的cpp / c++</p><p>专注cpp/c++相关求职领域的辅导</p><p>加入星球福利，后续如果有其他活动、服务，不收费，不收费，可以合理赚钱就收取下星球费用，但是不割韭菜，保持初心</p><p>感兴趣的微信扫下面的码，然后下载知识星球app登录即可<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047528236" alt="" title="" loading="lazy"/></p><p>（1）高质量的项目合集<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507742" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507743" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507744" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507745" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507746" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507747" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507748" alt="" title="" loading="lazy"/></p><p>同时如果项目，遇到任何困惑也会第一时间进行解答的<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047508196" alt="" title="" loading="lazy"/></p><p>（2）高质量精确性八股资料<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507749" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507750" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507751" alt="" title="" loading="lazy"/></p><p>（3）详细的学习路线<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507752" alt="" title="" loading="lazy"/></p><p>（4）活跃的学习氛围，星球打卡不只是一个形式，而是每天观看，针对同学们的学习情况提出合理化的建议，<strong>同时也有高质量的星球微信内部群</strong><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507753" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507754" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507755" alt="" title="" loading="lazy"/></p><p>（5）星球提问简历修改，提供意见的同时，<strong>还会给安排一对一腾讯会议辅导</strong><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507756" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507757" alt="" title="" loading="lazy"/></p><p>（6）星球同学offer情况，以及对应学习情况，给大家提供参考<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507758" alt="" title="" loading="lazy"/></p><p>（7）全网最全cpp相关面经整理<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507759" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507760" alt="" title="" loading="lazy"/></p><p>（8）编程实战能力提升平台（大家都可以使用的，免费的）</p><p>访问网址 cppagancoding.top<br/>  <img referrerpolicy="no-referrer" src="/img/remote/1460000047508197" alt="" title="" loading="lazy"/></p><p>星球同学的评价<br/>  <img referrerpolicy="no-referrer" src="/img/remote/1460000047508198" alt="" title="" loading="lazy"/></p><p>（9）每周也会进行直播答疑，同时有时也会给星球内部同学开一些知识、路线分享会。</p><p>具体可以看B站放的视频，up名字：cpp辅导的阿甘</p><p>（10）奖励金激励，会根据大家打卡学习/ 面经打卡整理情况，每个月每个季度发放奖励金。有的人陆陆续续已经获得了数千月的奖励金，是加入星球费用的数十倍了<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047528237" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047528238" alt="" title="" loading="lazy"/></p><p>等等，可能还有一些其他服务，目前没想起来的，以及后续也会增加的服务</p><p>本文由<a href="https://link.segmentfault.com/?enc=ZzJICyb6QLfRDHA%2Fs4R27w%3D%3D.DmFPBKKKN6iIgXYGOYx3HoxfgwA2Fg8lTdUzVIRKMfU%3D" rel="nofollow" target="_blank">mdnice</a>多平台发布</p>]]></description></item><item>    <title><![CDATA[喜报｜矩阵起源获InfoQ极客传媒2025年度技术生态构建品牌奖 MatrixOrigin ]]></title>    <link>https://segmentfault.com/a/1190000047560012</link>    <guid>https://segmentfault.com/a/1190000047560012</guid>    <pubDate>2026-01-23 10:05:52</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>1月21日，以“超越泡沫，开始构建”为主题的2026极客科技伙伴时刻圆满结束，该活动是极客邦科技一年一度的保留节目，旨在表彰过去一年中为技术生态发展与建设贡献突出力量的企业、团队和个人。</p><p>其中，矩阵起源凭借其在技术生态的深耕，获“2025年度技术生态构建品牌奖”。矩阵起源的坚持，让生态更具韧性与温度，为产业注入生生不息的动能。</p><p><img width="723" height="1305" referrerpolicy="no-referrer" src="/img/bVdnIGY" alt="" title=""/></p><p>作为行业的中坚力量，矩阵起源深知，生态建设的终局不是“独行”，而是“共赢”。这一奖项的背后，是我们专注连接开发者、用户与合作伙伴，推动技术普惠与可持续增长的坚定行动。面向未来，矩阵起源将继续秉持“构建者”的初心，在技术生态的深水区持续探索。我们希望通过更务实的行动与更开放的姿态，携手每一位生态伙伴，共同穿越周期，构建一个安全、高效、且充满活力的技术新生态。</p>]]></description></item><item>    <title><![CDATA[矩阵起源荣获 DataFun 星空奖双项大奖 | 科技领航，打造企业级数据智能新基建 MatrixO]]></title>    <link>https://segmentfault.com/a/1190000047560018</link>    <guid>https://segmentfault.com/a/1190000047560018</guid>    <pubDate>2026-01-23 10:04:53</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>1 月 16 日，在北京中关村展示中心会议中心举办的 DataFun 第三届 “星空奖” 颁奖现场，<strong>矩阵起源（Matrix Origin）</strong>凭借在数据智能基础设施领域的持续耕耘与实际应用成效，<strong>一举获评两项年度荣誉</strong>：「年度科技创新突破奖（Data + AI）」、「年度科技领航企业」。</p><h2>01 回归数据本质，解决 AI 落地“最后一公里”</h2><p>在企业智能化转型进入深水区的当下，AI 落地的核心挑战并非模型能力的匮乏，而是私域数据质量与处理链路的割裂。本次获评「年度科技创新突破奖（Data + AI）」的 MatrixOne Intelligence (MOI)，旨在为企业提供一套可控、可信的数据智能解决方案。</p><p>针对奖项关注的 “数据割裂” 与 “预测偏差” 等行业痛点，MOI 通过其超融合架构提供了务实的解决思路：</p><ul><li>统一数据底座：面对企业内部结构化与非结构化数据分散的现状，MOI 基于核心引擎 MatrixOne 的湖仓一体能力，实现了多模态数据的一站式存储与管理，避免了多套系统堆砌带来的运维复杂性与数据一致性风险。</li><li>工程化智能链路：MOI 将 AI 能力内嵌至数据处理全流程（MatrixPipeline）。通过向量化检索和前沿技术，有效提升了 RAG（检索增强生成）的召回准确率，从数据源头抑制大模型“幻觉”，确保输出结果通过企业合规风控标准。</li><li>闭环反馈机制：系统支持“数据 - 应用”的双向反馈，使模型能够随着业务数据的积累持续迭代，保障了系统在生产环境中的长期稳定性与可用性。</li></ul><p><img width="723" height="1035" referrerpolicy="no-referrer" src="/img/bVdnIHd" alt="" title=""/></p><h2>02 聚焦真实价值，做企业可信赖的合作伙伴</h2><p>唯有经得起真实业务场景检验的技术，才具备长久的生命力。</p><p>获评「年度科技领航企业」，是对矩阵起源在自主知识产权积累、产品成熟度及客户服务能力上的综合评价。面对金融、制造、医疗等行业对数据安全与业务连续性的严苛要求，矩阵起源始终坚持以客户价值为导向。</p><p>目前，我们的解决方案已在多个关键行业完成了落地验证：在医疗领域，我们协助三甲医院构建高精度对话与辅助诊断模型，显著提升 IBS 的初诊效率与诊断准确性；在高端制造领域，我们帮助企业优化供应链决策流程，大幅提升标书制作与合规校验效率……</p><p>这些一线场景的实践成果，不仅印证了产品的高可用性，也是我们致力于成为企业构建数智化能力坚实基石的有力证明。</p><p><img width="723" height="1035" referrerpolicy="no-referrer" src="/img/bVdnIHc" alt="" title="" loading="lazy"/></p><h2>03 结语</h2><p>行业专家的专业认可、客户的长期信赖，是我们持续成长的动力。面向未来，我们将继续秉持初心，打磨产品内核，优化服务体系。我们希望通过务实的技术创新，携手生态伙伴，协助更多企业解决数据难题，构建安全、高效、可持续演进的智能化体系。</p>]]></description></item><item>    <title><![CDATA[【k8s部署】麒麟V10离线安装k8s1.32.11 天行1st ]]></title>    <link>https://segmentfault.com/a/1190000047560120</link>    <guid>https://segmentfault.com/a/1190000047560120</guid>    <pubDate>2026-01-23 10:03:55</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>本文以<code>麒麟V10</code>为例，演示超简单离线部署<code>k8s 1.32.11</code>。</p><h2>1 说明</h2><h3>关于kt</h3><p><code>kt</code>是基于<code>kk</code>二次开发产物，具备<code>kk</code>的所有功能，二开重点适配了信创国产化环境。</p><p>主要改进包括：简化<code>arm</code>架构部署过程、支持国产化和国际环境在线、离线部署及<code>一条命令所有节点初始化</code>。</p><p>支持<code>arm64</code>和<code>amd64</code>架构操作系统，已适配芯片+操作系统 如下：</p><ul><li><strong>CPU：</strong> 鲲鹏、飞腾、海光、兆芯、intel、amd 等。</li><li><strong>OS：</strong> Centos、Ubuntu、Debian、银河麒麟V10、麒麟国防版、麒麟信安、中标麒麟V7、统信UOS、华为欧拉、移动大云、阿里龙蜥、TencentOS等。</li></ul><p>注：本文使用kt版本<code>3.1.13</code></p><ul><li><strong>kt文档：</strong> <a href="https://link.segmentfault.com/?enc=uKMTAG%2BAyTf7HEqP%2FM6v7Q%3D%3D.s2jP840NJGp0f9F3QZko1ycNg3G1iXIYUvldB6N8cR0%3D" rel="nofollow" title="kt文档" target="_blank">kt文档</a></li></ul><h2>2.环境准备</h2><p><strong>服务器基本信息</strong></p><table><thead><tr><th><strong>主机名</strong></th><th><strong>架构</strong></th><th><strong>OS</strong></th><th><strong>配置</strong></th><th><strong>IP</strong></th></tr></thead><tbody><tr><td>master</td><td>x86_64</td><td>麒麟V10</td><td>2核4G</td><td>192.168.85.153</td></tr></tbody></table><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560123" alt="" title=""/></p><h3>2.1 上传离线制品</h3><p>操作系统不需要安装docker,不需要设置selinux,swap等操作，全新的操作系统即可。</p><p>将离线制品、配置文件、kt和sh脚本上传至服务器其中一个节点(本文以master为例)，后续在该节点操作创建集群。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560124" alt="" title="" loading="lazy"/></p><h3>2.2 修改配置文件</h3><p>根据实际服务器信息，配置到生成的<code>config-sample.yaml</code>中</p><pre><code class="plain">kind: Cluster
metadata:
  name: sample
spec:
  hosts:
  - {name: master, address: 192.168.85.160, internalAddress: 192.168.85.143, user: root, password: "123123"}
  roleGroups:
    etcd:
    - master
    control-plane:
    - master
    worker:
    - master
    # 如需使用 kk 自动部署镜像仓库，请设置该主机组 （建议仓库与集群分离部署，减少相互影响）
    # 如果需要部署 harbor 并且 containerManager 为 containerd 时，由于部署 harbor 依赖 docker，建议单独节点部署 harbor
    registry:
    - master
  controlPlaneEndpoint:
    ## Internal loadbalancer for apiservers 
    internalLoadbalancer: haproxy

    domain: lb.kubesphere.local
    address: ""
    port: 6443
  kubernetes:
    version: v1.32.11
    clusterName: cluster.local
    autoRenewCerts: true
    containerManager: docker
  etcd:
    type: kubekey
  network:
    plugin: calico
    kubePodsCIDR: 10.233.64.0/18
    kubeServiceCIDR: 10.233.0.0/18
    ## multus support. https://github.com/k8snetworkplumbingwg/multus-cni
    multusCNI:
      enabled: false
  registry:
    type: harbor
    registryMirrors: []
    insecureRegistries: []
    privateRegistry: "dockerhub.kubekey.local"
    namespaceOverride: "kubesphereio"
    auths: # if docker add by `docker login`, if containerd append to `/etc/containerd/config.toml`
      "dockerhub.kubekey.local":
        username: "admin"
        password: Harbor@123 # 此处可自定义，kk3.1.8新特性
        skipTLSVerify: true # Allow contacting registries over HTTPS with failed TLS verification.
        plainHTTP: false # Allow contacting registries over HTTP.
        certsPath: "/etc/docker/certs.d/dockerhub.kubekey.local"
  addons: []</code></pre><h2>2.3 系统初始化</h2><p>解压<code>kt-x86.tar.gz</code>文件后执行<code>./kt init-os -f config-sample.yaml</code> 已适配操作系统和架构见<code>1.说明</code></p><p>该命令<code>kt</code>会根据配置文件自动判断操作系统和架构以完成所有节点的初始化配置和依赖安装。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560125" alt="" title="" loading="lazy"/></p><h2>3 创建 Harbor私有仓库</h2><h3>3.1 创建镜像仓库</h3><pre><code class="plain">./kt init registry -f config-sample.yaml -a artifact-x86-k8s13211.tar.gz</code></pre><p>此命令会在<code>harbor</code>节点自动安装<code>docker</code>和<code>docker-compose</code></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560126" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560127" alt="" title="" loading="lazy"/></p><h3>3.2 创建harbor项目</h3><p>创建 Harbor 项目</p><pre><code class="plain">chmod +x create_project_harbor.sh &amp;&amp; ./create_project_harbor.sh</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560128" alt="" title="" loading="lazy"/></p><h2>4 创建k8s</h2><pre><code class="plain">./kt create cluster -f config-sample.yaml -a artifact-x86-k8s13211.tar.gz --with-local-storage</code></pre><p>此命令<code>kt</code>会自动将离线制品中的镜像推送到<code>harbor</code> 私有仓库</p><p>执行后会有如下提示,输入<code>yes/y</code>继续执行</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560129" alt="" title="" loading="lazy"/></p><p>继续等待一段时间最终可以看到安装成功的消息</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560130" alt="" title="" loading="lazy"/></p><p>验证</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560131" alt="" title="" loading="lazy"/></p><h2>5 总结</h2><p>本文主要以离线方式部署，适用于在线和离线两种状态，而如果在线状态，那么步骤3可忽略，两条命令即可搞定。</p><p>配合最新版kt，系统初始化从未如此简单，不论<code>x86</code>还是<code>arm</code>，不论在线还是离线，不论国际还是国产操作系统，统统搞定。</p>]]></description></item><item>    <title><![CDATA[玩转OurBMC第二十七期：BMC POST CODE解读 OurBMC ]]></title>    <link>https://segmentfault.com/a/1190000047560165</link>    <guid>https://segmentfault.com/a/1190000047560165</guid>    <pubDate>2026-01-23 10:03:04</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>【栏目介绍：“玩转OurBMC” 是OurBMC社区开创的知识分享类栏目，主要聚焦于社区和BMC全栈技术相关基础知识的分享，全方位涵盖了从理论原理到实践操作的知识传递。OurBMC社区将通过 “玩转OurBMC” 栏目，帮助开发者们深入了解到社区文化、理念及特色，增进开发者对BMC全栈技术的理解。</p><p>欢迎各位关注 “玩转OurBMC” 栏目，共同探索OurBMC社区的精彩世界。同时，我们诚挚地邀请各位开发者向 “玩转OurBMC” 栏目投稿，共同学习进步，将栏目打造成为汇聚智慧、激发创意的知识园地。】</p><p><strong>Power-On Self-Test Code(上电自检代码)是计算机系统在启动过程中执行硬件诊断和初始化的关键技术机制｡该技术通过两位十六进制代码实时反映系统固件对各个硬件组件的检测状态,为系统启动提供可视化的进度指示和故障定位能力｡</strong></p><h2>01 POST 流程与UEFI 启动的融合演进</h2><h3>01 传统POST自检流程</h3><p>传统POST自检流程已经被嵌入现代UEFI启动框架中,其执行链路可分为以下五层次阶段:</p><p><strong>阶段1：处理器与芯片组初始化</strong></p><ul><li>电源序列验证与稳定监控</li><li>CPU核心复位与微码加载</li><li>时钟网络同步校准</li><li>温度监控传感器初始化</li></ul><p><strong>阶段2：内存子系统检测</strong></p><ul><li>DIMM模块识别与SPD数据读取</li><li>内存控制器配置与训练</li><li>信号完整性优化（读写时序校准）</li><li>ECC功能验证与内存测试</li></ul><p><strong>阶段3：基础输入输出系统初始化</strong></p><ul><li>芯片组功能单元配置</li><li>PCIe根复合体与端口初始化</li><li>集成外设控制器（SATA、USB）启用</li></ul><p><strong>阶段4：扩展设备枚举</strong></p><ul><li>PCIe拓扑扫描与资源分配</li><li>选项ROM加载与认证</li><li>设备驱动初始化</li></ul><p><strong>阶段5：引导加载程序执行</strong></p><ul><li>启动设备选择与初始化</li><li>操作系统加载器验证</li><li>系统控制权转移</li></ul><p>其完整执行路径可通过以下流程图展示</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560167" alt="92869296e9dd2e127ce5386e80a488ce.png" title="92869296e9dd2e127ce5386e80a488ce.png"/></p><p>图1 上电自检流程图</p><h3>02 UEFI启动框架中的POST映射</h3><p><strong>SEC（安全验证）阶段</strong></p><ul><li>UEFI流程：这是芯片上电后第一个执行的阶段，负责处理CPU复位、初始化微码、进入受保护模式，并验证下一阶段代码的完整性。</li><li>对应的POST任务：这相当于最早期的、内存尚未初始化前的POST，主要完成CPU的初步初始化。此时会生成早期的POST Code。</li></ul><p><strong>PEI（EFI前初始化）阶段</strong></p><ul><li>UEFI流程：此阶段内存尚未可用或正在被初始化，因此代码在缓存中运行。它的核心任务是初始化内存控制器和内存（Memory Reference Code, MRC）。</li><li>对应的POST任务：这是POST最核心、最耗时的部分。内存的检测、训练（Training）、配置都在此完成。此时会生成关键的POST Code。BMC密切监控这一阶段。</li></ul><p><strong>DXE（驱动执行环境）阶段</strong></p><ul><li>UEFI流程：内存可用后，进入此阶段。DXE调度程序会加载并执行大量的驱动程序（DXE Driver），来初始化所有其他硬件，如芯片组、PCIe总线、存储控制器、网络接口等。</li><li>对应的POST任务：这相当于传统的芯片组初始化、PCIe设备枚举、选项ROM加载等POST任务。每个DXE驱动程序的成功加载和执行，都可能对应一个或多个POST Code。</li></ul><p><strong>操作系统加载器执行</strong></p><ul><li>UEFI流程：所有硬件就绪后，UEFI固件通过Boot Manager选择并启动操作系统的加载器（如GRUB， Windows Boot Manager）。</li><li>对应的POST任务：传统上，这被认为是POST的结束，系统控制权移交给操作系统。通过发送对应POST命令告诉BMC操作系统已经被引导。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560168" alt="069a3c6ee7eb1688b063b3d5f04afcea.jpg" title="069a3c6ee7eb1688b063b3d5f04afcea.jpg" loading="lazy"/></p><p>图2 UEFI启动流程图</p><p> 注：上图引用&lt; UEFI Platform Initialization Specification, Release 1.9&gt;</p><h2>02 关键技术机制深度解析</h2><h3>01 传输机制</h3><p>硬件层面实现: POST Code通过专用的80h端口（传统架构）或内存映射I/O（现代架构）进行传输。</p><h3>02 智能错误处理与恢复策略</h3><p><strong>分级错误管理</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560169" alt="image.png" title="image.png" loading="lazy"/></p><p><strong>高级诊断功能：</strong></p><ul><li>模式识别：通过代码序列模式预测潜在故障</li><li>性能分析：基于时间戳的启动性能优化</li><li>趋势预测：长期代码统计分析预测硬件寿命</li></ul><h3>03 BMC联动与可视化监控</h3><p>硬件上BMC通过PCIe、eSPI、LPC等总线与主机连接。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560170" alt="09134090d8edd87292e9e2550a197746.png" title="09134090d8edd87292e9e2550a197746.png" loading="lazy"/></p><p>图3 硬件连接图</p><p><strong>BMC可实时捕获并解码服务器发送的POST Code流，实现：</strong></p><ul><li>状态可视化：在Web界面或CLI中实时显示启动进度</li><li>故障告警：根据错误等级提供声光、日志、通知等多级提示</li><li>远程诊断：支持运维人员远程查看启动状态，辅助快速定位问题</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560171" alt="5fe3822e1d45146e7362b14d35fa435c.png" title="5fe3822e1d45146e7362b14d35fa435c.png" loading="lazy"/></p><p>图4 信息交互图</p><p><strong>03 技术优势与价值体现</strong></p><p><strong>运维效率提升</strong></p><ul><li>故障定位时间减少</li><li>平均修复时间(MTTR)降低</li><li>首次修复成功率提升</li></ul><p><strong>系统可靠性增强</strong></p><ul><li>预防性维护覆盖率提升</li><li>硬件故障提前预警</li><li>系统可用性达到提高</li></ul><p><strong>运维成本优化</strong></p><ul><li>减少现场服务需求</li><li>降低备件库存成本</li><li>延长设备使用寿命</li></ul><p><strong>欢迎大家关注OurBMC社区，了解更多BMC技术干货。</strong></p><p><strong>OurBMC社区官方网站：</strong></p><p><a href="https://link.segmentfault.com/?enc=hUsdXlpwhmLy%2Bxt2ZopTkg%3D%3D.ykV%2Bh934hZBSPlJMO9wrPYZQ0JfAxk541VF3VAW5cLM%3D" rel="nofollow" target="_blank">https://www.ourbmc.cn/</a></p>]]></description></item><item>    <title><![CDATA[网站被提示“不安全”怎么解决 才高八斗的杯子_dS2Fpp ]]></title>    <link>https://segmentfault.com/a/1190000047560187</link>    <guid>https://segmentfault.com/a/1190000047560187</guid>    <pubDate>2026-01-23 10:02:16</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>当用浏览器访问某个网站时，如果浏览器显示“不安全”警告，这往往会立即引起用户的警惕，还可能会流失客户。</p><h4><strong>一、网站被提示“不安全”的原因</strong></h4><h5>1. 证书自身问题（最常见）</h5><ul><li><strong>已过期</strong>：证书有明确的有效期（通常为1年，最长为13个月）。过期后，“门锁”自动失效，需要续期。</li><li><strong>域名不匹配</strong>：证书是为 <code>www.example.com</code> 签发，但你访问的是 <code>example.com</code> 或 <code>shop.example.com</code>。这是配置时的常见疏忽。</li><li><strong>签发机构不受信任</strong>：证书并非来自浏览器和操作系统信任的根证书列表中的CA。一些自签名证书或企业内部CA签发的证书会触发此警告。</li></ul><h5>2. 服务器配置问题</h5><ul><li><strong>证书链不完整</strong>：服务器没有正确安装中间证书，导致浏览器无法验证证书的完整信任链。</li><li><strong>使用了不安全的加密协议</strong>：服务器仍支持已被废弃的弱加密算法（如SSL 2.0/3.0， TLS 1.0）。</li></ul><h5>3. 网络环境问题（最危险）</h5><ul><li><strong>中间人攻击</strong>：你所在的网络（如公共Wi-Fi）可能存在恶意攻击者，他试图在你和目标网站之间插入自己的伪证书，以窃取你的数据。浏览器发现证书被篡改或无法验证，会发出强烈警告。</li></ul><p><img width="723" height="286" referrerpolicy="no-referrer" src="/img/bVdnIJW" alt="" title=""/></p><h4><strong>二、解决方案如下</strong></h4><h3><a href="https://link.segmentfault.com/?enc=mbEI1ILT%2Bx4Usmh3oPSEcg%3D%3D.9ot18jHlff1nyqk3VhXgs0ZLfKZff8J9sstx0Wm1tGrOXQA%2BEGm2qdIbCNV%2FZGHRSSXMAvQl2snlCCyBp7m46g%3D%3D" rel="nofollow" target="_blank"><strong>免费SSL证书申请入口</strong></a></h3><p><strong>1.访问JoySSL官网并注册账号</strong></p><p>首先，登录<strong>JoySSL</strong>的官方网站，并注册一个账号。在注册过程中，务必填写特定的<strong>230970</strong>注册码才获取免费SSL证书的申请权限。</p><p><strong>2.选择证书类型</strong></p><p>登录JoySSL账号后，根据您的需求选择适合的SSL证书并0元下单支付。</p><p><strong>3.填写申请信息</strong></p><p>按照页面提示填写申请信息，包括域名信息、联系信息等。</p><p><strong>4.验证域名所有权</strong></p><p>完成信息填写后，JoySSL将要求您验证域名所有权。这通常通过域名DNS验证或服务器文件验证方式来完成。</p><p><strong>5. 部署证书</strong></p><p>验证后，10分钟左右签发，签发后，下载证书文件，将其部署到相应服务器上。</p><p><strong>6. 测试证书</strong></p><p>访问网站，检查是否实现HTTPS访问以及地址栏上有绿色的安全锁。</p>]]></description></item><item>    <title><![CDATA[《ESP32-S3使用指南—IDF版 V1.6》第六十四章 LVGL 综合例程 正点原子 ]]></title>    <link>https://segmentfault.com/a/1190000047560189</link>    <guid>https://segmentfault.com/a/1190000047560189</guid>    <pubDate>2026-01-23 10:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>第六十四章 LVGL 综合例程</h2><p>本章，简单的介绍一下DNESP32S3开发板的 LVGL 综合例程。需要说明一下的是：本例程是一个不完整的例程。因为该例程只是实现一个基于 LVGL 的 GUI 界面，里面的 APP<br/>基本没有实现功能，所以这只是给大家参考的 GUI demo。<br/>实现这样简单的 GUI demo 原因如下：<br/>1， 板载的2.4寸TFTLCD并未具备触摸条件，所以设计UI时受到很大的制约。<br/>2， 想做出一个 LVGL 综合例程给大家参考，但时间比较赶。<br/>3， 要实现一个不错的 LVGL 综合例程，要花费不少精力。<br/>4， 要考虑板载资源，兼容性等。<br/>5， 工程师们手头的事情比较多，等后续空闲些再规划。<br/>大家可以把自己期待的 LVGL 界面、功能等，通过各种渠道跟我们沟通，比如：B 站视频评论区，销售客户/技术支持等。后续有时间，我们会把大家的建议都考虑上去的。最后，敬请大家心怀一个小小的期待，期待正点原子的 LVGL 综合例程，感谢大家的支持！！！<br/>本章将分为如下 2 个小节：</p><p>64.1 LVGL 综合例程注意事项<br/>64.2 LVGL 综合例程界面展示</p><h3>64.1 LVGL 综合例程注意事项</h3><p>注意事项如下：<br/>1，DNESP32S3开发板的LVGL综合例程只支持正点原子的2.4寸 TFTLCD屏。其它屏幕会出现图标显示异常。<br/>2，所用的LVGL版本是V8.2。<br/>3，需要准备一张TF卡，将A盘资料的SD卡根目录文件复制到TF卡根目录当中，SD卡根目录文件如下图所示。<br/><img width="387" height="171" referrerpolicy="no-referrer" src="/img/bVdnGNo" alt="" title=""/><br/>图64.1.1 拷贝资料到TF卡当中<br/>图64.1.2展示的是LVGL例程界面所用到的 bin 文件。LVGL 综合例程会将这些bin文件拷贝到16MB Flash分区表的storage子分区表备份，方便GUI界面读取。如果直接从TF卡中读取，速度会比较慢，影响 GUI 的流畅性。<br/><img width="485" height="272" referrerpolicy="no-referrer" src="/img/bVdnGNp" alt="" title="" loading="lazy"/><br/>图 64.1.2 LVGL例程界面所用到的bin文件</p><h3>64.2 LVGL 综合例程界面展示</h3><p><img width="723" height="386" referrerpolicy="no-referrer" src="/img/bVdnGNq" alt="" title="" loading="lazy"/><br/>图64.2.1 GUI主界面和视频播放器界面<br/><img width="723" height="387" referrerpolicy="no-referrer" src="/img/bVdnGNr" alt="" title="" loading="lazy"/><br/>图64.2.2 图片浏览界面和计算机界面<br/>由于DNESP32S3开发板的2.4寸TFTLCD显示屏未具备触摸条件，所以作者只能实现一些简单的APP应用。</p>]]></description></item><item>    <title><![CDATA[Skills 与延迟加载工具定义的 MCP，目前哪个更高效、稳定和可控？ Baihai_IDP ]]></title>    <link>https://segmentfault.com/a/1190000047560110</link>    <guid>https://segmentfault.com/a/1190000047560110</guid>    <pubDate>2026-01-23 09:01:59</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <blockquote><p><strong>编者按：</strong> 我们今天为大家带来的这篇文章，作者的核心观点是：相较于依赖复杂且高成本的动态 MCP 工具加载机制，以 Skills 为核心的能力摘要与自维护模式，在当前阶段反而更加高效、稳定且可控。</p><p>文章系统梳理了延迟工具加载（deferred tool loading）的工程现实与限制，指出即便工具可以延后注入，对话级别的工具集合仍然是静态的，且发现机制高度依赖正则匹配，收益并不如预期。作者进一步深入分析了 MCP 在上下文占用、API 稳定性、缓存失效与推理轨迹丢失等方面带来的隐性成本，并结合 Sentry MCP、Playwright 等实践案例，说明为何将 MCP 转换为 Skills，反而能让 Agent 更好地发挥既有工具的能力。文章最后还探讨了 MCP 是否可能完全转化为 Skills 的可行性，并坦率指出当前协议与生态在稳定性与摘要机制上的不足。</p></blockquote><p><strong>作者 |</strong> <strong>Armin Ronacher</strong></p><p><strong>(作者为 Flask、Jinja2 等开源项目的创建者)</strong></p><p><strong>编译 | 岳扬</strong></p><p>我正把所有的 MCP 都迁移到 Skills 上，包括之前还在使用的最后一个：Sentry MCP（译者注：Sentry 是流行的应用监控与错误追踪平台）。早前我就已经完全弃用 Playwright（译者注：由 Microsoft 开发的现代 Web 自动化测试和浏览器自动化框架），转向使用 Playwright Skill。</p><p>过去一个月左右，关于使用“动态工具配置（dynamic tool loadouts）[1]”来推迟工具定义的加载的讨论一直不少。Anthropic 也在探索通过代码来串联 MCP 调用的思路，这一点我也尝试过[2]。</p><p>我想分享一下自己在这方面的最新心得，以及为什么 Anthropic 提出的“延迟工具加载方案（deferred tool loading）”并未改变我对 MCP 的看法。或许这些内容对他人会有所帮助。</p><h2><strong>01 什么是工具（Tool）？</strong></h2><p>当 Agent 通过强化学习或其他方式接触到工具定义时，它会被鼓励在遇到适合使用该工具的场景时，通过特殊的 token 输出工具调用。实际上，工具定义只能出现在系统提示词（system prompt）中特定的工具定义 token 之间。从历史经验来看，这意味着我们无法在对话状态的中途动态发出新的工具定义。因此，唯一的现实选择是在对话开始时就将工具加载好。</p><p>在智能体应用场景中，我们当然可以随时压缩对话状态，或更改系统消息中的工具定义。但这样做的后果是，我们会丢失推理轨迹（reasoning traces）以及缓存（cache）。以 Anthropic 为例，这将大幅增加对话成本：基本上就是从头开始，相比于缓存读取，需要支付完整的 token 费用，外加缓存写入成本。</p><p>Anthropic 最近的一项创新是“延迟工具加载”（deferred tool loading）。我们仍然需要提前在系统提示词（system message）中声明工具，但这些工具不会在系统提示词发出时就注入到对话中，而是会稍后才出现。不过据我所知，<strong>这些工具定义在整个对话过程中仍必须是静态的 —— 也就是说，哪些工具可能存在，是在对话开始时就确定好的。</strong> Anthropic 发现这些工具的方式，纯粹是通过正则表达式（regex）搜索实现的。</p><h2><strong>02 与 Skills 的对比</strong></h2><p>尽管带延迟加载的 MCP 感觉上应该表现更优，实际上却需要在 LLM API 端做不少工程化工作。而 Skills 系统完全不需要这些，至少从我的经验来看，其表现依然更胜一筹。</p><p><strong>Skills 实质上只是对现有能力及其说明文件位置的简短摘要。这些信息会被主动加载到上下文中。</strong> 因此，智能体能在系统上下文里（或上下文的其他位置）知晓自己具备哪些能力，并获知如何使用这些能力的“手册链接”。</p><p>关键在于，<strong>Skills 并不会真正把工具定义加载到上下文中。</strong> 可用工具保持不变：bash 以及智能体已有的其他工具。Skills 所能提供的，只是如何更高效使用这些工具的技巧和方法。</p><p>由于 Skills 主要教的是如何使用其他命令行工具和类似实用程序，因此组合与协调这些工具的基本方式其实并未改变。让 Claude 系列模型成为优秀工具调用者的强化学习机制，恰好能帮助处理这些新发现的工具。</p><h2><strong>03 MCP 能否转换为 Skills？</strong></h2><p>这自然引出了一个问题：既然 Skills 效果这么好，我能不能把 MCP 完全移出上下文，转而像 Anthropic 提议的那样，通过 CLI 来调用它？答案是：可以，但效果并不好。Peter Steinberger 的 mcporter[3] 就是其中一种方案。简单来说，它会读取 .mcp.json 文件，并将背后的 MCP 暴露为可调用的工具：</p><pre><code>npx mcporter call 'linear.create_comment(issueId: "ENG-123", body: "Looks good!")'</code></pre><p>确实，它看起来非常像一个 LLM 可以调用的命令行工具。但问题在于，LLM 根本不知道有哪些工具可用 —— 现在你得专门教它。于是你可能会想：那为什么不创建一些 Skills，来教 LLM 了解这些 MCP 呢？对我而言，这里的问题在于：<strong>MCP 服务器根本没有维持 API 稳定性的意愿。它们越来越倾向于将工具定义精简到极致，只为节省 token。</strong> 这种做法有其道理，但对 Skills 模式来说却适得其反。举个例子，Sentry MCP 服务器曾彻底将查询语法切换为自然语言。这对 Agent 来说是一次重大改进，但我之前关于如何使用它的建议反而成了障碍，而且我没能第一时间发现问题。</p><p>这其实和 Anthropic 的“延迟工具加载方案”非常相似：上下文中完全没有任何关于该工具的信息，我们必须手动创建一份摘要。我们过去对 MCP 工具采用的预加载（eager loading）方式，如今陷入了一个尴尬的局面：<strong>描述既太长，不便预加载；又太短，无法真正教会 Agent 如何使用它们。</strong> 因此，至少从我的经验来看，你最终还是得为通过 mcporter 或类似方式暴露出来的 MCP 工具，手动维护这些 Skills 摘要。</p><h2><strong>04 最省事的路线</strong></h2><p>这让我得出了目前的结论：<strong>我倾向于选择最省事的方式，也就是让 Agent 自己以“Skills”的形式编写所需的工具。</strong> 这样做不仅耗时不多，最大的好处还在于工具基本处于我的掌控之中。每当它出问题或需要新增功能时，我就让 Agent 去调整它。Sentry MCP 就是个很好的例子 —— 我认为它可能是目前设计得最好的 MCP 之一，但我已经不再使用它了。一方面是因为一旦在上下文中立即加载它，就会直接消耗约 8k 个 token；另一方面，我也一直没能通过 mcporter 让它正常工作。现在我让 Claude 为我维护一个对应的 Skill。没错，这个 Skill 可能有不少 bug，也需要不断更新，但由于是 Agent 自己维护的，整体效果反而更好。</p><p>当然，这一切很可能在未来发生变化。但就目前而言，手动维护的 Skills，以及让 Agent 自行编写工具，已成为我的首选方式。<strong>我推测，基于 MCP 的动态工具加载终将成为主流，但要实现这一点，可能还需要一系列协议层面的改进，以便引入类似 Skills 的摘要机制，以及为工具内置使用手册。</strong> 我也认为，MCP 如果能具备更强的协议稳定性，将大有裨益。目前 MCP 服务器随意更改工具描述的做法，与那些已经固化下来的调用方式（materialized calls）以及在 README 和技能文件中编写的外部工具说明很难兼容。</p><p><strong>END</strong></p><p><strong>本期互动内容 🍻</strong></p><p><strong>❓抛开现有方案，你理想中的AI工具调用范式应该长什么样？用一句话描述你最核心的需求。</strong></p><p><strong>文中链接</strong></p><p>[1]<a href="https://link.segmentfault.com/?enc=3Q00vCNgfa8RkZXzEqfaFg%3D%3D.U3r%2BxNvRWuGNK8stXMW6hK0IqrfJYgNfW9itRWy65WhvmBtFMtAtPuUkqXexAkVott3pptaRqPlBLJov%2Btkg%2BQ%3D%3D" rel="nofollow" target="_blank">https://www.anthropic.com/engineering/advanced-tool-use</a></p><p>[2]<a href="https://link.segmentfault.com/?enc=2kldzHxYidNBCnZu%2F4Y2vg%3D%3D.HH1ihPnnBdQQX8NtsKc2pUl3nx%2FhGklIu5sMNVe4v080RVLA36H33JR%2Bg5Oqjrr2" rel="nofollow" target="_blank">https://lucumr.pocoo.org/2025/7/3/tools/</a></p><p>[3]<a href="https://link.segmentfault.com/?enc=qM1I5KSJ9%2BAxBbQn2k%2F5HQ%3D%3D.0NA6YgE1dGXj2XkNqoknLGwHjM69TB%2F135KnfWR20sirpzd392R6Y7vqb2d6qNUh" rel="nofollow" target="_blank">https://github.com/steipete/mcporter</a></p><p><strong>原文链接：</strong>  </p><p><a href="https://link.segmentfault.com/?enc=q6YWdsWWLDCuxeyCdsOtwA%3D%3D.Kqr%2BcMdvJkiSB9fsx17%2Bpv61u7CyeaGoG5BNUZEwyDIwnMnT2LDPQYfiZjcOOeLkx4ADAlaFqrdWalUuyvBPgg%3D%3D" rel="nofollow" target="_blank">https://lucumr.pocoo.org/2025/12/13/skills-vs-mcp/</a></p>]]></description></item><item>    <title><![CDATA[Queue & Stack：实现机制与使用场景深度分析 SevenCoding ]]></title>    <link>https://segmentfault.com/a/1190000047548938</link>    <guid>https://segmentfault.com/a/1190000047548938</guid>    <pubDate>2026-01-23 09:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>为什么不推荐使用Stack</h2><p>Java已不推荐使用Stack，而是推荐使用更高效的ArrayDeque</p><h3>为什么不推荐使用</h3><ul><li>性能低：是因为 Stack 继承自 Vector， 而 Vector 在每个方法中都加了锁。由于需要兼容老的项目，很难在原有的基础上进行优化，因此 Vector 就被淘汰掉了，使用 <a href="https://link.segmentfault.com/?enc=7FS5CaWT2i440DsKjQVwgw%3D%3D.TU%2F4IAs%2FycQnKu8yLN%2BGM509fA8ycAERlHGRxVGHZ0kznv3ptDbITUbl%2BCdZ8O50r0DGtPLfn4CgBtyHpNL4IDUFgspUhoxpNTGBd7O6Flw%3D" rel="nofollow" target="_blank">ArrayList</a> 和 <a href="https://link.segmentfault.com/?enc=y2oMYDwyRQ%2BJA0S0WlSZLg%3D%3D.4TboKl%2BSpGqPqKEDVAnhwn9ZFD89%2BLQ%2FwjQdIAsXWKbVEafdZ%2BTDAishwaTxlbvp6Te2ryh8Lnu7nYSS%2FHRGoSc%2B%2FmTL4kAwh4VIX8zLLs0%3D" rel="nofollow" target="_blank">CopyOnWriteArrayList</a> 来代替，如果在非线程安全的情况下可以使用  <a href="https://link.segmentfault.com/?enc=Kv8uR2P6BoSSfS0K49snYQ%3D%3D.e68eIRsFuESqL4lpRUWXAS5ZDKh5hNLskxDf%2FjjV1pGdgMaIEL2JvmoNRGcFyfLrs8%2FuDhLRsgNE%2F8M4siptbj1a6Z5%2FuVDrxfG%2FFt7tAnw%3D" rel="nofollow" target="_blank">ArrayList</a>，线程安全的情况下可以使用 <a href="https://link.segmentfault.com/?enc=hks1aQHfAHYbGEvy7DI5nQ%3D%3D.9gCzGzYHN7hMQVPTM4BkwdCpCU8QNIlDNMcLRQnaRxwrVI1EIDV5A8%2B75qVCNgqk2dx1oTcIKBgtZQHFVQAkWBajF98VBIkZf%2FhiwCXc8G4%3D" rel="nofollow" target="_blank">CopyOnWriteArrayList</a> 。</li><li>破坏了原有的数据结构：栈的定义是在一端进行 push 和 pop 操作，除此之外不应该包含其他 入栈和出栈 的方法，但是 Stack 继承自 Vector，使得 Stack 可以使用父类 Vector 公有的方法。</li></ul><h3>为什么现在还在用</h3><p>但是为什么还有很多人在使用 Stack。总结了一下主要有两个原因。</p><ul><li>JDK 官方是不推荐使用 Stack，之所以还有很多人在使用，是因为 JDK 并没有加 deprecation 注解，只是在文档和注释中声明不建议使用，但是很少有人会去关注其实现细节</li><li>在笔试面试需要做算法题的时候，更多关注点是在解决问题的算法逻辑思路上，并不会关注在不同语言下 Stack 实现细节，但是对于使用 Java 语言的业务开发者，不仅需要关注算法逻辑本身，也需要关注它的实现细节</li></ul><h3>为什么推荐使用 Deque 接口替换栈</h3><p>如果 JDK 不推荐使用 Stack，那应该使用什么集合类来替换栈，一起看看官方的文档。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000045396408" alt="" title=""/></p><p>正如图中标注部分所示，栈的相关操作应该由 Deque 接口来提供，推荐使用 Deque 这种数据结构， 以及它的子类，例如 ArrayDeque。</p><pre><code class="java">val stack: Deque&lt;Int&gt; = ArrayDeque()</code></pre><p>使用 Deque 接口来实现栈的功能有什么好处：</p><ul><li>速度比 Stack 快</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000045396409" alt="" title="" loading="lazy"/></p><p>这个类作为栈使用时可能比 Stack 快，作为队列使用时可能比 LinkedList 快。因为原来的 Java 的 Stack 继承自 Vector，而 Vector 在每个方法中都加了锁，而 Deque 的子类 ArrayDeque 并没有锁的开销。</p><ul><li>屏蔽掉无关的方法</li></ul><p>原来的 Java 的 Stack，包含了在任何位置添加或者删除元素的方法，这些不是栈应该有的方法，所以需要屏蔽掉这些无关的方法。声明为 Deque 接口可以解决这个问题，在接口中声明栈需要用到的方法，无需管子类是如何是实现的，对于上层使用者来说，只可以调用和栈相关的方法。</p><h3>Stack 和 ArrayDeque的 区别</h3><table><thead><tr><th>集合类型</th><th>数据结构</th><th>是否线程安全</th></tr></thead><tbody><tr><td>Stack</td><td>数组</td><td>是</td></tr><tr><td>ArrayDeque</td><td>数组</td><td>否</td></tr></tbody></table><p>Stack 常用的方法如下所示：</p><table><thead><tr><th>操作</th><th>方法</th></tr></thead><tbody><tr><td>入栈</td><td>push(E  item)</td></tr><tr><td>出栈</td><td>pop()</td></tr><tr><td>查看栈顶</td><td>peek() 为空时返回 null</td></tr></tbody></table><p>ArrayDeque 常用的方法如下所示：</p><table><thead><tr><th>操作</th><th>方法</th></tr></thead><tbody><tr><td>入栈</td><td>push(E  item)</td></tr><tr><td>出栈</td><td>poll() 栈为空时返回    nullpop() 栈为空时会抛出异常</td></tr><tr><td>查看栈顶</td><td>peek() 为空时返回 null</td></tr></tbody></table><h2>Queue介绍</h2><p>Java里有一个叫做Stack的类，却没有叫做Queue的类(它是个接口名字)。当需要使用栈时，Java已不推荐使用Stack，而是推荐使用更高效的ArrayDeque；既然Queue只是一个接口，当需要使用队列时也就首选ArrayDeque了(次选是LinkedList)。</p><h3>Queue</h3><p>Queue接口继承自Collection接口，除了最基本的Collection的方法之外，它还支持额外的insertion, extraction和inspection操作。这里有两组格式，共6个方法，一组是抛出异常的实现；另外一组是返回值的实现(没有则返回null)。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000045396410" alt="" title="" loading="lazy"/></p><h3>Deque</h3><p>Deque 是"double ended queue", 表示双向的队列，英文读作"deck". Deque 继承自 Queue接口，除了支持Queue的方法之外，还支持 insert , remove 和 examine操作，由于Deque是双向的，所以可以对队列的头和尾都进行操作，它同时也支持两组格式，一组是抛出异常的实现；另外一组是返回值的实现(没有则返回null)。共12个方法如下:</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000045396411" alt="" title="" loading="lazy"/></p><p>当把 Deque 当做FIFO的 queue 来使用时，元素是从 deque 的尾部添加，从头部进行删除的； 所以 deque 的部分方法是和 queue 是等同的。具体如下:</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000045396412" alt="" title="" loading="lazy"/></p><p>Deque的含义是“double ended queue”，即双端队列，它既可以当作栈使用，也可以当作队列使用。下表列出了Deque与Queue相对应的接口:</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000045396413" alt="" title="" loading="lazy"/></p><p>下表列出了Deque与Stack对应的接口:</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000045396414" alt="" title="" loading="lazy"/></p><p>上面两个表共定义了Deque的12个接口。添加，删除，取值都有两套接口，它们功能相同，区别是对失败情况的处理不同。一套接口遇到失败就会抛出异常，另一套遇到失败会返回特殊值( false 或 null )。除非某种实现对容量有限制，大多数情况下，添加操作是不会失败的。虽然Deque的接口有12个之多，但无非就是对容器的两端进行操作，或添加，或删除，或查看。</p><p>ArrayDeque和LinkedList是Deque的两个通用实现，由于官方更推荐使用AarryDeque用作栈和队列，加之上一篇已经讲解过LinkedList，本文将着重讲解ArrayDeque的具体实现</p><p>从名字可以看出ArrayDeque底层通过数组实现，为了满足可以同时在数组两端插入或删除元素的需求，该数组还必须是循环的，即循环数组(circular array)，也就是说数组的任何一点都可能被看作起点或者终点。ArrayDeque是非线程安全的(not thread-safe)，当多个线程同时使用的时候，需要程序员手动同步；另外，该容器不允许放入 null 元素。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000045396415" alt="" title="" loading="lazy"/></p><p>上图中我们看到， head 指向首端第一个有效元素， tail 指向尾端第一个可以插入元素的空位。因为是循环数组，所以 head 不一定总等于0， tail 也不一定总是比 head 大。</p><h2>方法剖析</h2><h3>addFirst()</h3><p>addFirst(E e)的作用是在Deque的首端插入元素，也就是在head的前面插入元素，在空间足够且下标没有越界的情况下，只需要将elements[--head] = e即可。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000045396416" alt="" title="" loading="lazy"/></p><p>实际需要考虑:</p><ol><li>空间是否够用</li><li>下标是否越界的问题</li></ol><p>上图中，如果head为0之后接着调用addFirst()，虽然空余空间还够用，但head为-1，下标越界了。</p><pre><code class="java">//addFirst(E e)
public void addFirst(E e) {
    if (e == null)//不允许放入null
        throw new NullPointerException();
    elements[head = (head - 1) &amp; (elements.length - 1)] = e;//2.下标是否越界
    if (head == tail)//1.空间是否够用
        doubleCapacity();//扩容
}</code></pre><p><strong>上述代码可以看到， 空间问题是在插入之后解决的；</strong>首先，因为tail总是指向下一个可插入的空位，也就意味着elements数组至少有一个空位，所以插入元素的时候不用考虑空间问题。</p><p>下标越界的处理解决起来非常简单，head = (head - 1) &amp; (elements.length - 1)就可以了，<strong>这段代码相当于取余，同时解决了head为负值的情况</strong>。因为elements.length必需是2的指数倍，elements - 1就是二进制低位全1，跟head - 1相与之后就起到了取模的作用，如果head - 1为负数(其实只可能是-1)，则相当于对其取相对于elements.length的补码。</p><blockquote><p>计算机里数值都是用补码表示的，如果是8位的，-1就是1111 1111，而 (elements.length - 1) 也是 1111 1111，因此两者相与也就是(elements.length - 1)；</p><p>head = (head - 1) &amp; (elements.length - 1) 最后再让算出的位置赋值给head，因此其实这段代码就是让head再从后往前赋值</p></blockquote><p>扩容函数doubleCapacity()，其逻辑是申请一个更大的数组(原数组的两倍)，然后将原数组复制过去。过程如下图所示:</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000045396417" alt="" title="" loading="lazy"/></p><p>图中可以看到，复制分两次进行，第一次复制head右边的元素，第二次复制head左边的元素。</p><pre><code class="java">//doubleCapacity()
private void doubleCapacity() {
    assert head == tail;
    int p = head;
    int n = elements.length;
    int r = n - p; // head右边元素的个数
    int newCapacity = n &lt;&lt; 1;//原空间的2倍
    if (newCapacity &lt; 0)
        throw new IllegalStateException("Sorry, deque too big");
    Object[] a = new Object[newCapacity];
    System.arraycopy(elements, p, a, 0, r);//复制右半部分，对应上图中绿色部分
    System.arraycopy(elements, 0, a, r, p);//复制左半部分，对应上图中灰色部分
    elements = (E[])a;
    head = 0;
    tail = n;
}</code></pre><h3>addLast()</h3><p>addLast(E e)的作用是在<strong>Deque</strong>的尾端插入元素，也就是在tail的位置插入元素，由于tail总是指向下一个可以插入的空位，因此只需要elements[tail] = e;即可。插入完成后再检查空间，如果空间已经用光，则调用doubleCapacity()进行扩容。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000045396418" alt="" title="" loading="lazy"/></p><pre><code class="java">public void addLast(E e) {
    if (e == null)//不允许放入null
        throw new NullPointerException();
    elements[tail] = e;//赋值
    if ( (tail = (tail + 1) &amp; (elements.length - 1)) == head)//下标越界处理
        doubleCapacity();//扩容
}</code></pre><h3>pollFirst()</h3><p>pollFirst()的作用是删除并返回<strong>Deque</strong>首端元素，也即是head位置处的元素。如果容器不空，只需要直接返回elements[head]即可，当然还需要处理下标的问题。由于ArrayDeque中不允许放入null，当elements[head] == null时，意味着容器为空。</p><pre><code class="java">public E pollFirst() {
    int h = head;
    E result = elements[head];
    if (result == null)//null值意味着deque为空
        return null;
    elements[h] = null;//let GC work
    head = (head + 1) &amp; (elements.length - 1);//下标越界处理
    return result;
}</code></pre><h3>pollLast()</h3><p>pollLast()的作用是删除并返回Deque尾端元素，也即是tail位置前面的那个元素。</p><pre><code class="java">public E pollLast() {
    int t = (tail - 1) &amp; (elements.length - 1);//tail的上一个位置是最后一个元素
    E result = elements[t];
    if (result == null)//null值意味着deque为空
        return null;
    elements[t] = null;//let GC work
    tail = t;
    return result;
}</code></pre><h3>peekFirst()</h3><p>peekFirst()的作用是返回但不删除<strong>Deque</strong>首端元素，也即是head位置处的元素，直接返回elements[head]即可。</p><pre><code class="java">public E peekFirst() {
    return elements[head]; // elements[head] is null if deque empty
}</code></pre><h3>peekLast()</h3><p>peekLast()的作用是返回但不删除<strong>Deque</strong>尾端元素，也即是tail位置前面的那个元素。</p><pre><code class="java">public E peekLast() {
    return elements[(tail - 1) &amp; (elements.length - 1)];
}</code></pre>]]></description></item><item>    <title><![CDATA[2026年供应商管理系统排名：6款热门产品深度测评 SaaS圈老马 ]]></title>    <link>https://segmentfault.com/a/1190000047559864</link>    <guid>https://segmentfault.com/a/1190000047559864</guid>    <pubDate>2026-01-23 08:01:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>对于很多企业来说，供应商管理一直是个“老大难”问题——信息散乱、沟通成本高、对账周期长、合作过程不透明。如果全靠Excel和微信来管理，效率低不说，还容易出错。因此，一套好用的<strong>供应商管理系统</strong>（SRM）成了企业数字化转型中的重要一环。</p><p>但市面上的相关产品五花八门，有标准化软件，也有定制化平台，到底该怎么选？今天，我们就结合市场反馈、产品功能和实际应用情况，为大家测评并排名当前较受关注的<strong>6款供应商管理系统</strong>，希望能给正在选型的你一些参考。</p><p><strong>1. 支道</strong></p><p><a href="https://link.segmentfault.com/?enc=OX3neY3BXei27MXYk9ftew%3D%3D.0FgVev3PCIPqnJLI48OLCSUuzpyoWsf8BYYOz1ooGEA%3D" rel="nofollow" target="_blank">https://www.zdsztech.com</a></p><p><strong>综合评分：★★★★★</strong>  </p><p><strong>定位：</strong> 无代码定制化SRM解决方案  </p><p><strong>适合企业：</strong> 成长型企业、多业务场景需求、追求灵活与性价比并重的公司</p><p>如果要说近几年在中小企业数字化领域口碑不错的平台，<strong>支道</strong> 肯定算一个。它并不是一个固定的“标准化SRM软件”，而是一个<strong>无代码业务搭建平台</strong>，供应商管理只是其能搭建的众多场景之一。</p><p><strong>为什么把它放在前面推荐？</strong></p><p>首先，它解决了一个核心痛点：<strong>企业需求总是在变</strong>。今天你可能只管采购比价，明天就需要供应商绩效评估，后天又希望和供应商在线协同订单。标准化软件往往很难跟上这种节奏，而支道让业务人员自己就能通过“拖拉拽”配置流程、表单和报表，快速搭建出贴合实际的管理应用。</p><p>从供应商管理具体功能上看，它覆盖了：</p><p><strong>供应商全生命周期管理</strong>：从准入、分类、评级到淘汰，形成电子档案。</p><p><strong>在线询比价与招标</strong>：流程在线化，比价更透明，支持自动生成比价单。</p><p><strong>订单协同与发货跟踪</strong>：供应商可通过门户查看订单、确认交期、更新发货状态，减少来回沟通。</p><p><strong>智能对账与绩效评估</strong>：自动汇总往来数据，内置评估模型，生成供应商绩效看板。</p><p><strong>内外协同便捷</strong>：支持通过链接、二维码等方式让供应商参与部分流程，无需对方额外安装系统。</p><p><strong>最大的优势在于“灵活”和“性价比”</strong>。它没有按功能模块收费，企业可以根据自身发展阶段，先搭建核心的供应商档案与询价功能，后续再逐步扩展绩效、协同等模块。同时支持公有云、私有化部署，成本比许多传统定制开发低不少。</p><p>很多使用它的企业反馈：“像是请了一个懂业务的开发团队，但不用养人。” 尤其适合那些业务独特、标准化软件无法满足，又担心定制开发成本高、周期长的企业。<br/><img width="723" height="293" referrerpolicy="no-referrer" src="/img/bVdnIEE" alt="" title=""/></p><p><strong>2. 金蝶</strong></p><p><strong>综合评分：★★★★☆</strong>  </p><p><strong>定位：</strong> 集成的ERP系统，SRM为其重要组成部分  </p><p><strong>适合企业：</strong> 已使用或计划使用金蝶ERP的中大型制造业、贸易企业</p><p>金蝶作为国内老牌企业管理软件厂商，其云产品 <strong>金蝶云·星空</strong> 中的供应链协同模块，提供了比较完善的SRM功能。如果你企业本身就用金蝶处理财务、进销存，那么用它来管理供应商，数据打通会非常顺畅。</p><p>它的供应商管理侧重于<strong>流程规范和业财一体化</strong>：</p><p><strong>与ERP深度集成</strong>：采购订单、入库单、应付账款自动关联，杜绝数据孤岛。</p><p><strong>供应商门户</strong>：供应商可自助维护信息、接收订单、确认送货单和发票，提升协同效率。</p><p><strong>招投标管理</strong>：支持线上招标流程，相对规范。</p><p><strong>质量管理协同</strong>：可与来料检验（IQC）流程关联。</p><p><strong>优势是体系成熟、财务衔接好</strong>，特别适合管理规范、对财务合规性要求高的大中型企业。<strong>不足</strong>是作为大型ERP的一部分，整体价格较高，且功能偏标准化，个性化调整需要二次开发，成本和周期都不低。<br/><img width="723" height="301" referrerpolicy="no-referrer" src="/img/bVdnIEF" alt="" title="" loading="lazy"/></p><p><strong>3. 用友</strong></p><p><strong>综合评分：★★★★☆</strong>  </p><p><strong>定位：</strong> 用友新一代云ERP的SRM解决方案  </p><p><strong>适合企业：</strong> 成长型创新企业、全链路数字化需求较强的公司</p><p>用友的 <strong>YonSuite</strong> 定位为“成长型企业的云ERP”，其供应商协同云是现代、轻量化的SRM方案。它强调社交化协同和用户体验，试图把复杂的供应商管理做得更“互联网化”一些。</p><p>主要功能亮点：</p><p><strong>社交化沟通协同</strong>：类似商务聊天界面，与供应商的沟通记录可关联业务单据。</p><p><strong>全流程线上化</strong>：从寻源、询报价、合同到送货、对账，都在一个平台完成。</p><p><strong>供应商风险监控</strong>：集成一些外部数据，对供应商经营风险进行预警。</p><p><strong>移动端应用友好</strong>：审核、沟通在手机上操作方便。</p><p><strong>优势在于产品设计较新，协同理念突出</strong>，适合喜欢轻便、敏捷操作模式的企业。但作为用友云生态的一部分，同样面临与外部系统深度集成时可能需要的定制工作。<br/><img width="723" height="320" referrerpolicy="no-referrer" src="/img/bVdnIEG" alt="" title="" loading="lazy"/></p><p><strong>4. Oracle NetSuite SRP</strong></p><p><strong>综合评分：★★★★☆</strong>  </p><p><strong>定位：</strong> 全球性云端ERP内置的供应商管理方案  </p><p><strong>适合企业：</strong> 有跨国业务、需要多语言多币种支持的中大型企业</p><p>对于业务涉及海外的企业，<strong>Oracle NetSuite</strong> 是一个常被考虑的选项。它的供应商关系管理（SRP）模块是其ERP套件的一部分，天生支持全球化的供应链管理。</p><p>核心能力包括：</p><p><strong>全球供应商管理</strong>：轻松管理不同国家地区的供应商，处理多币种报价和结算。</p><p><strong>端到端采购流程</strong>：从需求计划到付款，全部自动化。</p><p><strong>强大的分析报告</strong>：提供全球采购开支、供应商绩效等多维度分析。</p><p><strong>开放集成平台</strong>：易于与其他国际主流系统对接。</p><p><strong>优势无疑是其全球化能力和品牌信誉</strong>。但劣势也很明显：实施和许可费用昂贵，产品复杂度高，通常需要专业的咨询团队实施，更适合预算充足、业务结构复杂的国际化公司。<br/><img width="723" height="285" referrerpolicy="no-referrer" src="/img/bVdnIEH" alt="" title="" loading="lazy"/></p><p><strong>5. 甄云科技</strong></p><p><strong>综合评分：★★★☆☆</strong>  </p><p><strong>定位：</strong> 专注于SRM领域的标准化SaaS产品  </p><p><strong>适合企业：</strong> 采购管理复杂、寻源需求强的大型集团企业</p><p><strong>甄云科技</strong> 是国内较早专注于SRM赛道的厂商之一。其 <strong>甄采SRM</strong> 是一款功能深度聚焦在采购与供应商管理的标准化产品。</p><p>它的强项在于 <strong>采购寻源和成本控制</strong>：</p><p><strong>战略寻源</strong>：支持复杂的招标、竞价、谈判流程。</p><p><strong>采购成本分析</strong>：深入分析采购支出，寻找降本机会。</p><p><strong>供应商绩效精细化管理</strong>：评估模型可自定义程度较高。</p><p><strong>与主流ERP有预置接口</strong>：与SAP、Oracle、用友、金蝶等可进行对接。</p><p><strong>优势是专业度高，在大型企业的集中采购场景中经验丰富</strong>。<strong>缺点</strong>是作为标准化SaaS，虽然功能深，但灵活性有限，且产品主要面向大型客户，对中小企业来说可能功能过重、价格偏高。<br/><img width="723" height="360" referrerpolicy="no-referrer" src="/img/bVdnIEI" alt="" title="" loading="lazy"/></p><p><strong>6. 纷享销客</strong></p><p><strong>综合评分：★★★☆☆</strong>  </p><p><strong>定位：</strong> 以CRM为核心，扩展至上下游业务协同的平台  </p><p><strong>适合企业：</strong> 以渠道分销、客户项目管理为核心，需联动供应商的中小企业</p><p><strong>纷享销客</strong> 本质是一个连接型CRM，但其PaaS平台能力允许它将业务延伸到上下游协同。如果你的企业业务核心是项目和客户，供应商管理作为辅助环节，需要与客户项目打通，那它可以作为一种轻量级选择。</p><p>在供应商管理方面，它能实现：</p><p><strong>供应商信息作为客户/伙伴管理</strong>：在CRM框架内管理供应商基础信息和联系人。</p><p><strong>简单询价与订单协同</strong>：通过流程和表单功能实现。</p><p><strong>与项目、合同关联</strong>：便于核算项目成本。</p><p><strong>低代码自定义能力</strong>：可对其标准功能进行一定调整。</p><p><strong>优势在于它从客户侧视角整合供应链，适合项目制销售型企业</strong>。<strong>不足</strong>是并非专业的SRM，在复杂的采购寻源、供应商绩效深度分析等方面功能较弱。<br/><img width="723" height="344" referrerpolicy="no-referrer" src="/img/bVdnIEJ" alt="" title="" loading="lazy"/></p><p><strong>总结与选型建议</strong></p><p>选供应商管理系统，没有绝对的“最好”，只有“最适合”。</p><p>如果你的业务在快速发展，需求多变，希望系统能跟着业务成长，<strong>支道</strong> 这类无代码平台值得优先考虑。它能以较低成本实现深度定制，且后续调整自主性强，算是大家比较钟爱的选择。</p><p>最后提醒一句，无论选哪家，<strong>一定要让对方提供同行业的案例参考，甚至安排演示环境亲手试用</strong>。供应商管理是“用”出来的，只有贴合你业务实际运作习惯的系统，才能真正用起来、出效果。</p>]]></description></item><item>    <title><![CDATA[4个给网站添加暗黑模式的简单方法 达西先生 ]]></title>    <link>https://segmentfault.com/a/1190000047559948</link>    <guid>https://segmentfault.com/a/1190000047559948</guid>    <pubDate>2026-01-22 23:02:21</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>1、CSS 滤镜反转颜色</h2><pre><code class="css">/* 代码实现全网站暗黑模式 */
@media (prefers-color-scheme: dark) {
    html {
        background-color: #fff !important;
        color: #000 !important;
    }

    html {
        /* 反转180度颜色 */
        filter: invert(1) hue-rotate(180deg) !important;
    }

    /* 图片、视频等元素不需要处理，可继续添加可以不用处理的元素 */
    img,
    video,
    iframe {
        /* 再反转180度变成原来颜色 */
        filter: invert(1) hue-rotate(180deg) !important;
    }
}

</code></pre><h2>2、JS 库添加蒙板</h2><pre><code class="html">&lt;script src="https://cdnjs.cloudflare.com/ajax/libs/Darkmode.js/1.5.7/darkmode-js.min.js"&gt;&lt;/script&gt;
&lt;script&gt;
    // 监听系统暗黑模式变化
    let darkmode = new Darkmode()
    window
        .matchMedia('(prefers-color-scheme: dark)')
        .addEventListener('change', (event) =&gt; {
            if (event.matches) {
                // 切换暗黑模式
                if (!darkmode.isActivated()) {
                    darkmode.toggle()
                }
            } else {
                // 切换亮色模式
                if (darkmode.isActivated()) {
                    darkmode.toggle()
                }
            }
        })
&lt;/script&gt;

</code></pre><h2>3、CSS 伪类:not() 选择器</h2><pre><code class="css">/* 代码实现全网站暗黑模式 */
@media (prefers-color-scheme: dark) {
    /* 排除的 a 和 code 元素 */
    html *:not(a, code *) {
        background-color: #000000 !important;
        color: #ffffff !important;
    }

    /* a元素单独设置颜色 */
    a {
        color: #4caf50 !important;
    }
}

</code></pre><h2>4、CSS media 媒体查询</h2><blockquote><p>HTML &lt;link&gt; media 属性定义和用法</p><p><strong>media</strong> 属性规定目标资源针对什么媒体/设备进行了优化。</p><p><strong>media</strong> 属性指定了被链接文档将显示在什么设备上。</p><p>该属性主要与 CSS 样式表一起使用，为不同的媒体类型指定不同的样式。</p><p><strong>media</strong> 属性可以接受多个值。</p></blockquote><pre><code class="html">&lt;!-- 只在亮色模式下生效 --&gt;
&lt;link
    rel="stylesheet"
    media="(prefers-color-scheme: light)"
    href="/assets/css/light.css"
/&gt;

&lt;!-- 只在暗黑模式下生效 --&gt;
&lt;link
    rel="stylesheet"
    media="(prefers-color-scheme: dark)"
    href="/assets/css/dark.css"
/&gt;

</code></pre>]]></description></item><item>    <title><![CDATA[RAG 检索模型如何学习：三种损失函数的机制解析 本文系转载，阅读原文
https://avoid.]]></title>    <link>https://segmentfault.com/a/1190000047559951</link>    <guid>https://segmentfault.com/a/1190000047559951</guid>    <pubDate>2026-01-22 23:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>Agent 系统发展得这么快那么检索模型还重要吗？RAG 本身都已经衍生出 Agentic RAG和 Self-RAG（这些更复杂的变体了。</p><p>答案是肯定的，无论 Agent 方法在效率和推理上做了多少改进，底层还是离不开检索。检索模型越准，需要的迭代调用就越少，时间和成本都能省下来，所以训练好的检索模型依然关键。讨论 RAG 怎么用的文章铺天盖地，但真正比较检索模型学习方式的内容却不多见。</p><p>检索系统包含多个组件：检索嵌入模型、索引算法（HNSW 之类）、向量搜索机制（余弦相似度等）以及重排序模型。这篇文章只聚焦检索嵌入模型的学习方式。</p><p>本文将介绍我实验过的三种方法：Pairwise cosine embedding loss（成对余弦嵌入损失）、Triplet margin loss（三元组边距损失）、InfoNCE loss。</p><h2>成对余弦嵌入损失</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559953" alt="" title=""/></p><p>正样本对示例<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047559954" alt="" title="" loading="lazy"/></p><p>负样本对示例</p><p>输入是一对文本加一个标签，标签标明这对文本是正匹配还是负匹配。和 MNLI 数据集里的蕴含、矛盾关系类似。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047559955" alt="" title="" loading="lazy"/></p><p>损失函数用的是余弦嵌入损失，x 和 y 分别是文本对的嵌入向量。</p><h2>三元组边距损失</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559956" alt="" title="" loading="lazy"/></p><p>输入变成三个文本：一个锚文本、一个正匹配、一个负匹配。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047559957" alt="" title="" loading="lazy"/></p><p>损失函数是 Triplet Margin Loss。公式里 a 代表锚文本嵌入，p 代表正样本嵌入，n 代表负样本嵌入。</p><h2>InfoNCE 损失</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559958" alt="" title="" loading="lazy"/></p><p>输入包括一个查询、一个正匹配、一组负样本列表。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047559959" alt="" title="" loading="lazy"/></p><p>损失函数采用 InfoNCE，灵感来自 M3-Embedding 论文（arxiv:2402.03216）。公式中 p* 是正样本嵌入，P' 是负样本嵌入列表，q 是查询嵌入，s(.) 表示相似度函数，比如余弦相似度。</p><h2>比较</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559960" alt="" title="" loading="lazy"/></p><p>哪种方法最好？要看具体场景、数据量和算力。从我的实验来看，InfoNCE 覆盖面最广。但只要实验做得够充分、训练数据比例调得够细，余弦嵌入损失也能达到差不多的效果。三元组边距损失我没有深入探索，不过它可能是介于另外两者之间的一个折中选项。</p><p><a href="https://link.segmentfault.com/?enc=12djtCvTleRQG%2F8CCPszaw%3D%3D.XIPmVcwtzWu%2BknPxWPssKwWoWzToFGLxG0JCTBi0hvKOdgwCGGzFkHCnnbsHe%2B1XWkjV%2BXYPEK%2FhfuQRW0hq9A%3D%3D" rel="nofollow" target="_blank">https://avoid.overfit.cn/post/7958652dd31e4cf5ace899b97e0eac27</a></p><p>作者：Jerald Teo</p>]]></description></item><item>    <title><![CDATA[【2026原创】卫星遥感图像识别系统~Python+深度学习+人工智能+算法模型+TensorFlo]]></title>    <link>https://segmentfault.com/a/1190000047559829</link>    <guid>https://segmentfault.com/a/1190000047559829</guid>    <pubDate>2026-01-22 22:03:14</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>项目介绍</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559831" alt="图片" title="图片"/><br/>图片<br/>本系统是一个基于深度学习的卫星遥感图像智能识别平台，旨在为用户提供高效、准确的遥感图像分类服务。系统采用Flask轻量级Web框架构建后端服务，集成ResNet50深度卷积神经网络模型，实现了对卫星遥感图像的自动化识别与分类。系统支持识别七大类地物类型，包括草地、农田、工业区、河流湖泊、森林、居民区和停车场，能够满足土地利用监测、城市规划、环境评估等多种应用场景的需求。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559832" alt="图片" title="图片" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559833" alt="图片" title="图片" loading="lazy"/></p><p>关键技术栈：resnet50算法<br/>ResNet50（Residual Network 50层）是深度学习领域中具有里程碑意义的卷积神经网络架构，由何恺明等学者于2015年提出。该网络的核心创新在于引入了残差学习（Residual Learning）机制，通过跳跃连接（Skip Connection）解决深层网络训练中的梯度消失和梯度爆炸问题，使得网络深度可以突破传统限制，达到甚至超过100层。ResNet50网络包含49个卷积层和1个全连接层，采用了5个阶段的残差块设计，每个阶段包含不同数量的残差单元，通过堆叠这些残差块构建深度网络结构。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559834" alt="图片" title="图片" loading="lazy"/><br/>图片<br/>系统功能模块图</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559835" alt="图片" title="图片" loading="lazy"/><br/>图片<br/>演示视频 and 完整代码 and 安装<br/>地址：<a href="https://link.segmentfault.com/?enc=AEwu6DwcEIX8b9liWwq2HQ%3D%3D.rI8629L9D6MTz3y3tRIyor2fAX2zQRauV9h29WBKIRaAufIy0ra0XWqFsg%2F8HKbtAuF9L%2Bgrf9P8mL7m74DL3g%3D%3D" rel="nofollow" target="_blank">https://www.yuque.com/ziwu/qkqzd2/kma4wpp387ifg6ci</a></p>]]></description></item><item>    <title><![CDATA[AG-UI：让 AI 走出聊天框的“界面革命” blossom ]]></title>    <link>https://segmentfault.com/a/1190000047559840</link>    <guid>https://segmentfault.com/a/1190000047559840</guid>    <pubDate>2026-01-22 22:02:17</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h3>序幕：从“百科全书”到“实时搭档”</h3><p>大家发现了吗？我们现在使用 AI 的方式，本质上还是在查阅一本<strong>超级百科全书</strong>。</p><p>无论是在 ChatGPT 还是 Claude 的对话框里，我们总是重复着：<strong>提问、等待、阅读文字、复制粘贴</strong>。这种交流永远被困在一个小小的“聊天框”里，就像你雇佣了一个超级天才助手，但他被关在隔壁的小黑屋里，只能通过门缝给你<strong>“递纸条”</strong>。你在这头对着复杂的业务界面抓耳挠腮，他在那头空有一身才华却看不见你的屏幕。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559842" alt="" title=""/></p><p><strong>这种“隔靴操痒”的交互方式，是时候结束了。</strong></p><p>想象一下，如果 AI 不仅仅是那个能言善辩的聊天机器人，而是一个<strong>能实时看懂你的操作、感知你的困惑、并直接帮你操作界面的“数字化合伙人”</strong>？当你拖动地图，他立刻补全路径；当你填表卡壳，他直接变出最合适的选项。他不再躲在对话框后面，而是直接走进你的工作流，伸手接过了那把名为“UI”的钥匙。这就是 <strong>AG-UI（Agent-User Interaction Protocol）</strong> 正在发起的革命：<strong>让 AI 走出聊天框，让界面随心而动。</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559843" alt="" title="" loading="lazy"/></p><hr/><h3>第一部分：什么是 AG-UI？</h3><p>用最简单的话说，AG-UI 是 AI 智能体（Agent）和用户界面（UI）之间的<strong>“通用翻译官”</strong>。</p><p>在 AG-UI 出现之前，如果你想把 AI 接入 App，程序员需要费劲地把 AI 的文字输出手动“翻译”成网页上的按钮。而且，市面上有无数种 AI 框架，又有无数种前端终端，要把它们两两连接，工作量巨大。</p><p><strong>AG-UI 的出现，就像是在 AI 大脑与屏幕之间修通了一条标准化的“高速公路”：</strong> 它不管后端用的是什么模型，前端用的是什么设备，只要接上这根管道，AI 就能从一个后台的“思考者”，变成前台的“协作者”。</p><blockquote><strong>知识点：AG-UI vs A2UI</strong><br/>这里有两个概念容易混淆。<strong>A2UI（Google 出品）</strong> 像是 UI 的<strong>“建筑图纸”</strong>，定义了界面长什么样；而 <strong>AG-UI</strong> 则是<strong>“物流快递”</strong>，负责把这张图纸实时、安全地送到你的屏幕上。</blockquote><hr/><h3>第二部分：AG-UI 在智能体协议栈中的角色</h3><p>要理解 AG-UI 的威力，我们需要看它在整个 AI 智能体生态（Agent Protocol Stack）中的位置。它与其他两大主流协议相辅相成，共同构成了 AI 时代的底层架构：</p><ul><li><strong>MCP (Model Context Protocol) —— 赋能工具：</strong> 负责连接 AI 与各种工具（Tools）或数据库。它让 Agent 拥有了“手”，可以去查资料、调 API。</li><li><strong>A2A (Agent-to-Agent) —— 协同合作：</strong> 负责不同 Agent 之间的通信。它让 Agent 拥有了“对讲机”，可以呼唤其他 AI 协作。</li><li><strong>AG-UI —— 触达用户：</strong> <strong>这是最关键的一环。</strong> 它负责将 Agent 的能力引入到面向用户的应用程序中。它让 Agent 拥有了“窗口”，直接与人类在 UI 界面上共事。</li></ul><p><strong>流程简述：</strong> Agent 通过 <strong>MCP</strong> 调用工具获取数据，通过 <strong>A2A</strong> 协同其他专家 AI，最后通过 <strong>AG-UI</strong> 将处理结果直接转化成你屏幕上的交互组件。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559844" alt="" title="" loading="lazy"/></p><hr/><h3>第三部分：颠覆性的三宗“最”</h3><ol><li><strong>最懂你：生成式 UI (Generative UI)。</strong> 以前的软件是程序员提前写死的。有了 AG-UI，AI 可以根据对话内容，现场为你<strong>“造”软件</strong>。而且这过程非常丝滑——组件会随着 AI 的思考过程实时在屏幕上“生长”出来。</li><li><strong>最默契：共享状态 (Shared State)。</strong> 这就是“双向同步”的超能力。你在界面上拉动滑块增加了参数，AI 的“大脑”会立刻感知到这个动作并同步做出反馈。你们共享同一个“上下文”，就像并肩作战的战友。</li><li><strong>最安全：人在回路 (Human in the Loop)。</strong> AG-UI 允许 AI 在关键时刻弹出一个确认界面。AI 没法乱写代码，它只能发送数据指令去调用你预设好的<strong>“安全积木”</strong>。</li></ol><hr/><h3>第四部分：生态现状——工具已在手</h3><p>虽然协议发布时间不长，但它的生态爆发速度惊人：</p><ul><li><strong>全明星后端支持：</strong> <strong>LangGraph、CrewAI、Microsoft Autogen</strong> 等主流框架均已接入。</li><li><strong>前端大厂入局：</strong> 除了 React 方案，<strong>Google 的 Flutter 团队已经推出了 GenUI SDK</strong>。这意味着“设计即基础设施”的时代已经开启。</li><li><strong>快速体验：</strong> 如果你想现在尝试，只需一行命令：<code>npx create-ag-ui-app</code>。</li></ul><hr/><h3>第五部分：核心洞察——“设计”正在变成基础设施</h3><p>作为开发者，我感受到这场革命最震撼的地方在于：<strong>前端的工作方式将彻底重构。</strong></p><ol><li><strong>从“盖房子”到“造积木”：</strong> 以后前端不再负责拼装最终页面（那是 AI 的事），而是负责设计足够原子、具备强语义化的“组件积木”。</li><li><strong>框架的“降维打击”：</strong> 当 Flutter 等框架官方定义的“标准组件”已经足够美观且具备完美的 AI 语义时，企业将不再需要雇佣设计师去重新发明轮子。<strong>“设计”将从一项昂贵的业务成本，变成框架自带的基础设施。</strong></li></ol><hr/><h3>结语：拥抱流动的未来</h3><p>2026 年是 AI 智能体爆发的元年。界面的脸孔将不再死板，它会随你的需求而流动。UI 不再是挡在你和功能之间的那层“膜”，而是变成了一种随用随取的资源。</p><p><strong>未来的应用不是由菜单定义的，而是由你的意图定义的。</strong></p><p>别再纠结 CSS 的像素偏移了，去研究 AI 如何理解你的业务意图吧。这场革命，正在你运行 <code>npx create-ag-ui-app</code> 的那一刻开始。</p><p>本文由<a href="https://link.segmentfault.com/?enc=j7T9ijZU%2F4jARXdQdlERKA%3D%3D.70kCXXKMANjrrRYcrB4gQ7bT21Ik5VMZMzSQgWkbzYQ%3D" rel="nofollow" target="_blank">mdnice</a>多平台发布</p>]]></description></item><item>    <title><![CDATA[基于 YOLOv8 的多犬种（60种常见犬类）智能识别系统项目 [目标检测完整源码] 南瓜 ]]></title>    <link>https://segmentfault.com/a/1190000047559867</link>    <guid>https://segmentfault.com/a/1190000047559867</guid>    <pubDate>2026-01-22 22:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>基于 YOLOv8 的多犬种（60种常见犬类）智能识别系统项目 [目标检测完整源码]</h2><h3>—— 面向 60 类常见犬种的目标检测与可视化应用落地</h3><hr/><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559869" alt="在这里插入图片描述" title="在这里插入图片描述"/></p><h3>一、背景与问题：为什么“犬种识别”值得工程化？</h3><p>在宠物经济高速发展的今天，犬类已经从“家庭陪伴动物”逐步演变为需要<strong>精细化管理与智能化服务</strong>的对象。在实际场景中，犬种信息直接影响：</p><ul><li>饲养与行为管理策略</li><li>疫苗接种与健康风险评估</li><li>宠物交易、领养与救助流程</li><li>城市宠物管理与公共安全</li></ul><p>然而，现实中对犬种的识别依然高度依赖人工经验，不仅主观性强，而且在混血犬、幼犬、复杂光照条件下误判率较高。</p><p><strong>问题的本质在于：</strong></p><blockquote>如何构建一个既具备高识别精度，又真正“可落地使用”的犬种识别系统？</blockquote><p>本项目正是围绕这一问题，给出了一套<strong>完整可复现的工程级解决方案</strong>。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047559870" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h3>源码下载与效果演示</h3><p>哔哩哔哩视频下方观看：<br/><a href="https://www.bilibili.com/video/BV1wB8MzsE9P/" target="_blank">https://www.bilibili.com/video/BV1wB8MzsE9P/</a></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559871" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><p>包含：</p><p>📦完整项目源码</p><p>📦 预训练模型权重</p><p>🗂️ 数据集地址（含标注脚本</p><hr/><h3>二、系统整体架构设计</h3><p>该项目并非单一模型 Demo，而是一个<strong>从数据、训练到部署的完整闭环系统</strong>，整体架构如下：</p><pre><code>┌────────────┐
│  数据集层  │  犬类图像 + YOLO 标注
└─────┬──────┘
      ↓
┌────────────┐
│  模型训练  │  YOLOv8 Detection
└─────┬──────┘
      ↓
┌────────────┐
│  推理服务  │  图片 / 视频 / 摄像头
└─────┬──────┘
      ↓
┌────────────┐
│  GUI 应用  │  PyQt5 桌面端
└────────────┘</code></pre><p>核心目标只有一个：<br/><strong>让“深度学习模型”真正变成“普通用户能用的软件”。</strong><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047559872" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047559873" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><hr/><h3>三、模型选型：为什么是 YOLOv8？</h3><p>在多类别实时检测任务中，YOLO 系列一直是工程实践的主流方案。本项目最终选择 YOLOv8，主要基于以下考虑：</p><h4>3.1 架构层面的优势</h4><ul><li><strong>Anchor-Free 设计</strong><br/>减少超参数依赖，收敛更稳定</li><li><strong>Task-Aligned Assigner</strong><br/>分类与定位目标一致性更强</li><li><strong>更轻量的 Backbone 与 Neck</strong><br/>在保证精度的同时提升推理速度</li></ul><h4>3.2 工程友好性</h4><ul><li>原生支持 <strong>PyTorch / ONNX</strong></li><li>Ultralytics 提供统一 CLI 与 Python API</li><li>训练、验证、推理接口高度一致</li></ul><p>这使得模型不仅“好训”，而且<strong>非常适合与 GUI、业务系统结合</strong>。</p><hr/><h3>四、犬种数据集构建与标注规范</h3><h4>4.1 数据规模与类别</h4><p>本系统覆盖 <strong>60 种常见犬类</strong>，包括但不限于：</p><ul><li>柯基、哈士奇、柴犬</li><li>金毛、拉布拉多、贵宾犬</li><li>德牧、边牧、博美等</li></ul><p>每个类别均包含多姿态、多背景、多尺度样本，尽量贴近真实使用场景。</p><hr/><h4>4.2 数据组织结构（YOLO 标准）</h4><pre><code>dataset/
├── images/
│   ├── train/
│   └── val/
├── labels/
│   ├── train/
│   └── val/</code></pre><p>标签文件采用 YOLO 标准格式：</p><pre><code>&lt;class_id&gt; &lt;x_center&gt; &lt;y_center&gt; &lt;width&gt; &lt;height&gt;</code></pre><p>所有坐标均为 <strong>相对比例值</strong>，确保模型在不同分辨率下具备一致性。</p><hr/><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559874" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h3>五、模型训练流程详解</h3><h4>5.1 训练配置示例</h4><pre><code class="bash">yolo detect train \
  data=dog.yaml \
  model=yolov8n.pt \
  epochs=100 \
  batch=16 \
  imgsz=640</code></pre><p>关键训练策略包括：</p><ul><li>合理的 batch size 控制显存占用</li><li>数据增强（翻转、尺度变换、颜色扰动）</li><li>早期收敛阶段重点关注 box_loss 与 cls_loss</li></ul><hr/><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559875" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h4>5.2 训练过程监控</h4><p>YOLOv8 在 <code>runs/detect/train/</code> 目录中自动生成：</p><ul><li>损失函数变化曲线</li><li>mAP@0.5 / mAP@0.5:0.95</li><li>混淆矩阵（类别间区分能力）</li></ul><p>在实际实验中，多数犬种在 <strong>mAP@0.5 指标上稳定超过 90%</strong>，具备实际应用价值。</p><hr/><h3>六、多模态推理能力设计</h3><p>本系统支持多种输入形式，统一由同一推理接口处理。</p><h4>6.1 单张图片与批量图片</h4><ul><li>支持文件与文件夹级别输入</li><li>自动生成标注结果图</li><li>适合数据复查与分析场景</li></ul><hr/><h4>6.2 视频与实时摄像头</h4><ul><li>基于 OpenCV 逐帧推理</li><li>支持实时显示检测结果</li><li>可选保存输出视频文件</li></ul><p>这一能力使系统能够直接应用于：</p><ul><li>宠物门店实时监控</li><li>救助站视频巡检</li><li>展示型 AI 应用演示</li></ul><hr/><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559876" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h3>七、PyQt5 图形界面设计要点</h3><p>为了降低使用门槛，项目引入 PyQt5 构建完整桌面应用。</p><h4>7.1 界面功能划分</h4><ul><li><strong>输入控制区</strong>：选择图片 / 视频 / 摄像头</li><li><strong>结果展示区</strong>：实时显示检测画面</li><li><strong>日志与状态区</strong>：输出模型运行信息</li></ul><h4>7.2 工程价值</h4><ul><li>无需命令行操作</li><li>非算法人员也可直接使用</li><li>适合作为课程设计、毕业设计、项目演示系统</li></ul><hr/><h3>八、推理代码核心示例</h3><pre><code class="python">from ultralytics import YOLO

model = YOLO("best.pt")
results = model("test.jpg", conf=0.25, save=True)

for box in results[0].boxes:
    cls_id = int(box.cls)
    score = float(box.conf)</code></pre><p>推理结果中可直接获取：</p><ul><li>类别 ID</li><li>置信度</li><li>边框坐标</li></ul><p>便于后续对接业务逻辑或二次开发。</p><hr/><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559877" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h3>九、项目工程化与“开箱即用”</h3><p>本项目已完成<strong>完整工程封装</strong>，具备以下特点：</p><ul><li>已训练完成的权重文件</li><li>完整源码与数据集</li><li>一键启动 GUI 程序</li><li>提供训练与部署说明</li></ul><p>运行检测仅需：</p><pre><code class="bash">python main.py</code></pre><p>无需重新训练，即可体验完整系统功能。</p><hr/><h3>十、可扩展性与二次开发方向</h3><p>该项目并不局限于犬种识别，其工程框架可直接扩展为：</p><ul><li>🐱 猫咪品种识别</li><li>🐦 鸟类 / 野生动物监测</li><li>🐄 畜牧养殖视觉分析</li><li>🏙️ 智慧城市动物管理系统</li></ul><p><strong>本质上，这是一个可复用的 YOLOv8 + GUI 工程模板。</strong></p><hr/><h3>总结：一个真正“能用”的目标检测项目应该是什么样？</h3><p>相比单纯展示模型精度，本项目更关注：</p><ul><li>是否具备完整工程链路</li><li>是否方便非算法人员使用</li><li>是否具备二次开发潜力</li></ul><p>通过 YOLOv8 与 PyQt5 的深度结合，该系统成功实现了从算法到应用的跨越。</p><blockquote>🚀 <strong>如果你正在寻找一个具备训练、检测、部署一体化能力的目标检测项目实践，这套基于 YOLOv8 的多犬种识别系统，值得你深入研究与复用。</strong></blockquote>]]></description></item><item>    <title><![CDATA[移动ERP系统排行榜（2026）：5款主流产品怎么选更省心 SaaS圈老马 ]]></title>    <link>https://segmentfault.com/a/1190000047559684</link>    <guid>https://segmentfault.com/a/1190000047559684</guid>    <pubDate>2026-01-22 20:02:10</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>这两年企业上移动ERP，很多时候不是“想升级”，而是被现实推着走：人在外面跑业务，单据在电脑里卡着；仓库要扫码盘点，结果还在纸上写；老板想看数据，最后只能等人导表。</p><p><strong>所以移动ERP系统这件事，本质上比的不是功能堆得多不多，而是谁能把高频动作放到手机上跑通。</strong></p><p><strong>本文排行榜怎么排的</strong><strong>：</strong></p><p>1、我用的标准很直白，按“能不能真的用起来”来排：</p><p>2、移动端是否能覆盖审批、开单、库存、对账等高频动作</p><p>3、产品与厂商信息是否能在官网/官方应用商店核验</p><p>4、是否有清晰的定位：更适合哪类企业、哪类业务模式</p><p>5、落地成本是否可控：上线路径清晰，推广阻力别太大</p><p><strong>一、移动ERP系统排行榜 TOP 5</strong></p><p><strong>1、支道</strong></p><p>支道更像“把业务系统当积木搭”的路线，不是那种固定菜单的传统ERP。</p><p><strong>它最打动人的点是：业务流程变了，系统也能跟着你改，不用每次都等开发排期。</strong></p><p>支道更适合哪类企业？一句话概括就是：流程不太标准、变化很快、跨部门协同靠人盯的团队。你不用一上来就“全上ERP”，更现实的做法是先跑通1-2条关键流程，然后逐步扩。</p><p>支道常见落地方式可以按这种节奏走：</p><p>（1）先做移动端待办与审批，把“卡在路上”的事打通</p><p>（2）再把业务填报和单据录入搬到手机上，现场就能闭环</p><p>（3）最后用报表与看板把数据收口，减少重复统计</p><p>如果你最痛的是“Excel满天飞、版本对不上、事情靠催”，支道的思路通常更贴近现实：先把流程固化，再谈精细化管理。<br/><img width="723" height="384" referrerpolicy="no-referrer" src="/img/bVdnIBD" alt="" title=""/></p><p><strong>2、金蝶</strong></p><p>金蝶移动端的卖点写得很实在，官网直接列出一串高频动作：扫码开单、蓝牙打印、出入库、盘点调拨、库存分析等。</p><p><strong>如果你是“手机要能开单、仓库要能快速做动作”，金蝶这类路线通常更稳。</strong></p><p>适合场景也很清晰：</p><p>（1）业务员：手机下单、跟进客户、交易管理</p><p>（2）仓库：出入库、盘点、调拨</p><p>（3）管理者：业绩、库存、经营数据随时看 <br/><img width="723" height="271" referrerpolicy="no-referrer" src="/img/bVdnIBE" alt="" title="" loading="lazy"/></p><p><strong>3、用友</strong></p><p>用友在移动端的主张也很明确：一个App管理所有应用系统，一键访问业务系统单据，移动快捷审批，实时处理业务。</p><p><strong>你们系统多、待办多、审批多，用友这类“统一入口”的价值就会更明显。</strong></p><p>更适合的企业画像：</p><p>（1）组织层级较多，跨部门流程复杂</p><p>（2）需要把多个系统的待办统一到手机端处理</p><p>（3）希望移动端是入口，而不是“另一个孤岛” <br/><img width="723" height="288" referrerpolicy="no-referrer" src="/img/bVdnIBL" alt="" title="" loading="lazy"/></p><p><strong>4、鼎捷</strong></p><p>鼎捷在制造业中小企业的定位很明确，它在“掌上易助”页面直接写：易助小程序，全面满足ERP用户移动化需求，并说明易助是面向中小微企业、涵盖制造全流程的ERP。</p><p><strong>小程序入口的好处很现实：推广阻力小，一线人员更愿意用。</strong> </p><p>如果你是机械、五金、汽配、电子加工这类行业，鼎捷官方也明确写到易助ERP适用这些制造业场景，并涵盖财务、进销存、生产等管理范畴。<br/><img width="723" height="335" referrerpolicy="no-referrer" src="/img/bVdnIBM" alt="" title="" loading="lazy"/></p><p><strong>5、网上管家婆</strong></p><p>网上管家婆移动端讲的是“手机开单、扫码出入库、欠款对账、数据看板”这种中小企业最常用的动作。手机开单、查询欠款、一键生成对账单并发送链接或二维码对账，扫码出入库与多方式盘点。</p><p><strong>如果你是商贸批零、电商网店，想要的是上手快、动作快，这类产品往往更省事。</strong><br/><img width="723" height="396" referrerpolicy="no-referrer" src="/img/bVdnIBN" alt="" title="" loading="lazy"/></p><p><strong>二、5款产品对比表</strong><br/><img width="723" height="463" referrerpolicy="no-referrer" src="/img/bVdnIBO" alt="" title="" loading="lazy"/></p><p><strong>三、最快的选型方法</strong></p><p><strong>1、你们移动端最常干的三件事是什么</strong></p><p>（1）审批、开单、盘点</p><p>（2）对账、收款、查库存</p><p>（3）项目回填、工单处理</p><p>2、你们流程到底变不变</p><p>（1）经常变：优先看支道这种可配置能力强的路线</p><p>（2）基本不变：优先看标准化更成熟的套件</p><p>3、你们现有系统多不多</p><p>（1）多系统并存：用友这类统一入口更省心</p><p>（2）就一套进销存：金蝶、网上管家婆这类会更快落地 </p><p><strong>四、结语</strong></p><p>移动ERP系统排行榜看一眼就好，真正决定成败的是：手机端能不能把你们最痛的那条流程跑通。<strong>如果你希望先把协同和流程跑顺、再逐步扩模块，支道放在第一位是合理的选择。</strong></p>]]></description></item><item>    <title><![CDATA[【赵渝强老师】国产金仓数据库的数据库对象 赵渝强老师 ]]></title>    <link>https://segmentfault.com/a/1190000047559736</link>    <guid>https://segmentfault.com/a/1190000047559736</guid>    <pubDate>2026-01-22 20:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>金仓数据库中包含各种数据库对象，常见的KingBase对象有：数据库、模式、表、索引、视图、存储过程、存储函数和触发器等等。这里将介绍金仓数据库中常见的数据库对象以及如何使用它们。视频讲解如下：<br/><a href="https://www.bilibili.com/video/BV1RQz3B9ERT/?aid=115930646454086&amp;cid=35515336758" target="_blank">https://www.bilibili.com/video/BV1RQz3B9ERT/?aid=115930646454...</a></p><h2>一、 数据库与模式</h2><p>数据库本身也是一个KingBase的数据库对象。数据库对象中包含其他所有的数据库对象，如：模式、表、视图、索引等等。使用命令create database可以创建一个新的数据库，下面展示了该命令的格式：</p><pre><code class="sql">CREATE DATABASE name
     [ WITH ] [ OWNER [=] user_name ]
           [ TEMPLATE [=] template ]
           [ ENCODING [=] encoding ]
           [ LC_COLLATE [=] lc_collate ]
           [ LC_CTYPE [=] lc_ctype ]
           [ TABLESPACE [=] tablespace_name ]
           [ ALLOW_CONNECTIONS [=] allowconn ]
           [ CONNECTION LIMIT [=] connlimit ]
           [ IS_TEMPLATE [=] istemplate ]</code></pre><p>一个数据库包含一个或多个模式（Schema），模式中又包含了表、函数及操作符等数据库对象。创建新数据库时，KingBase会自动创建名为public的模式。使用命令create schema可以创建一个新的模式，下面展示了该命令的格式：</p><pre><code class="sql">CREATE SCHEMA schema_name [ AUTHORIZATION role_specification ] [ schema_element [ ... ] ]
CREATE SCHEMA AUTHORIZATION role_specification [ schema_element [ ... ] ]
CREATE SCHEMA IF NOT EXISTS schema_name [ AUTHORIZATION role_specification ]
CREATE SCHEMA IF NOT EXISTS AUTHORIZATION role_specification

其中 role_specification 可以是：

    user_name
  | CURRENT_USER
  | SESSION_USER</code></pre><p>在了解到数据库与模式的概念后，下面通过具体的操作来演示如何创建和使用它们。<br/>（1）创建一个新的数据库dbtest。</p><pre><code class="sql">scott=# create database dbtest;</code></pre><p>（2）查看已存在的数据库列表。</p><pre><code class="sql">scott=# \l

# 输出的信息如下：
                                        数据库列表
   名称    | 拥有者 | 字元编码 |  校对规则   |    Ctype    | ICU 排序 |     存取权限      
-----------+--------+----------+-------------+-------------+----------+-------------------
 dbtest    | system | UTF8     | zh_CN.UTF-8 | zh_CN.UTF-8 |          | 
 kingbase  | system | UTF8     | zh_CN.UTF-8 | zh_CN.UTF-8 |          | 
 scott     | system | UTF8     | zh_CN.UTF-8 | zh_CN.UTF-8 |          | 
 security  | system | UTF8     | zh_CN.UTF-8 | zh_CN.UTF-8 |          | 
 template0 | system | UTF8     | zh_CN.UTF-8 | zh_CN.UTF-8 |          | =c/system        +
           |        |          |             |             |          | system=CTc/system
 template1 | system | UTF8     | zh_CN.UTF-8 | zh_CN.UTF-8 |          | =c/system        +
           |        |          |             |             |          | system=CTc/system
 test      | system | UTF8     | zh_CN.UTF-8 | zh_CN.UTF-8 |          | 
(7 行记录)</code></pre><p>（3）切换到数据库dbtest。</p><pre><code class="sql">scott=# \c dbtest 
您现在以用户名"system"连接到数据库"dbtest"。</code></pre><p>（4）查看数据库dbtest中的模式。</p><pre><code class="sql">dbtest=# \dn

# 输出的信息如下：
       架构模式列表
       名称       | 拥有者 
------------------+--------
 anon             | system
 dbms_job         | system
 dbms_scheduler   | system
 dbms_sql         | system
 kdb_schedule     | system
 perf             | system
 public           | system
 src_restrict     | system
 sys_hm           | system
 sysaudit         | system
 sysmac           | system
 wmsys            | system
 xlog_record_read | system
(13 行记录)

# 这里的public的模式是创建数据库对象的默认模式。</code></pre><p>（5）创建一个新的模式。</p><pre><code class="sql">dbtest=# create schema firstschema;</code></pre><p>（6）重新查看数据库dbtest中的模式。</p><pre><code class="sql">dbtest=# \dn

# 输出的信息如下：
       架构模式列表
       名称       | 拥有者 
------------------+--------
 anon             | system
 dbms_job         | system
 dbms_scheduler   | system
 dbms_sql         | system
 firstschema      | system
 kdb_schedule     | system
 perf             | system
 public           | system
 src_restrict     | system
 sys_hm           | system
 sysaudit         | system
 sysmac           | system
 wmsys            | system
 xlog_record_read | system
(14 行记录)</code></pre><h2>二、 创建与管理表</h2><p>表是一种非常重要的数据库对象。金仓数据库的数据都是存储在表中。KingBase的表是一种二维结构，由行和列组成。表有列组成，列有列的数据类型。下面通过具体的步骤来演示如何操作金仓数据库的表。这些操作包括创建表、查看表、修改表和删除表。</p><p>（1）创建一张新的表test2.</p><pre><code class="sql">dbtest=# create table test2(id int,name varchar(32),age int);

# 由于创建表时没有指定模式的名称，因此表将创建在public模式下。
# 如果要在指定的模式下创建表，可以使用下面的语句：
dbtest=# create table firstschema.test2(id int,name varchar(32),age int);</code></pre><p>（2）查看表的结构。</p><pre><code class="sql">dbtest=# \d test2

# 输出的信息如下：
                    数据表 "public.test2"
 栏位 |            类型            | 校对规则 | 可空的 | 预设 
------+----------------------------+----------+--------+------
 id   | integer                    |          |        | 
 name | character varying(32 char) |          |        | 
 age  | integer                    |          |        | </code></pre><p>（3）在表中增加一个字段。</p><pre><code class="sql">dbtest=# alter table test2 add gender varchar(1) default 'M';

# 这里增加了一个gender字段用于表示性别，默认是“M”。</code></pre><p>（4）重新查看表的结构。</p><pre><code class="sql">dbtest=# \d test2

# 输出的信息如下：
                         数据表 "public.test2"
  栏位  |            类型            | 校对规则 | 可空的 |     预设     
--------+----------------------------+----------+--------+--------------
 id     | integer                    |          |        | 
 name   | character varying(32 char) |          |        | 
 age    | integer                    |          |        | 
 gender | character varying(1 char)  |          |        | 'M'::varchar</code></pre><p>（5）修改表将gender字段的长度改为10个字符。</p><pre><code class="sql">dbtest=# alter table test2 alter gender type varchar(10);</code></pre><p>（6）删除gender字段。</p><pre><code class="sql">dbtest=# alter table test2 drop column gender;</code></pre><p>（7）删除表test2。</p><pre><code class="sql">dbtest=# drop table test2;</code></pre><h2>三、 在查询时使用索引</h2><p>数据库查询是数据库的主要功能之一，最基本的查询算法是顺序查找（linear search）时间复杂度为O(n)，显然在数据量很大时效率很低。优化的查找算法如二分查找（binary search）、二叉树查找（binary tree search）等，虽然查找效率提高了。但是各自对检索的数据都有要求：二分查找要求被检索数据有序，而二叉树查找只能应用于二叉查找树上，但是数据本身的组织结构不可能完全满足各种数据结构。所以在数据之外，数据库系统还维护着满足特定查找算法的数据结构。这些数据结构以某种方式指向数据，这样就可以在这些数据结构上实现高级查找算法。这种数据结构就是索引。金仓数据库官方对索引的定义为：索引（Index）是帮助KingBase高效获取数据的数据结构。索引是一种数据结构。金仓数据库默认的索引类型是B树索引。下图是一颗简单的B树，可见它与二叉树最大的区别是它允许一个节点有多于2个的元素，每个节点都包含key和数据，查找时可以使用二分的方式快速搜索数据。</p><p><img width="723" height="232" referrerpolicy="no-referrer" src="/img/bVdnICs" alt="image.png" title="image.png"/></p><p>在了解到了KingBase索引的基本知识以后，下面将通过具体的步骤演示来说明如何在KingBase中创建索引，并且在查询语句中使用它。<br/>（1）查看scott数据库中部门表dept和员工表emp上的索引信息。</p><pre><code class="sql">scott=# select index_name,index_type,table_name,status
        from user_indexes where table_name in ('DEPT','EMP');
        
# 输出的信息如下：
 index_name | index_type | table_name | status 
------------+------------+------------+--------
 DEPT_PKEY  | BTREE      | DEPT       | VALID
 EMP_PKEY   | BTREE      | EMP        | VALID
(2 行记录)

# user_indexes是一个视图，可以通过它获取某个用户创建的索引信息。</code></pre><p>（2）使用create index命令在员工表emp的薪水sal字段上创建完全索引。</p><pre><code class="sql">scott=# create index index_full on emp using btree(sal);

# 完全索引会基于该字段上的所有值创建索引。
# 同时，在创建索引的时候会进行锁表的操作，可以使用 CIC (create index concurrently)，
# 但创建索引的时间相对较长。例如：
scott=# create index concurrently index1 on emp using btree(sal);</code></pre><p>（3）下面的语句将在员工表上创建一个部分索引。</p><pre><code class="sql">scott=# create index index_part on emp using btree(sal) where sal&lt;3000;

# 部分索引是对于表的部分数据创建索引。
# 如果发现表的某一部分数据查询次数较多时，可以考虑在这部分数据上创建一个部分索引。
# 部分索引相较于完全索引，查询的性能将得到提高，并且部分索引文件所占的空间也会小于全索引。</code></pre><p>（4）在员工表emp的员工姓名ename上创建表达式索引。</p><pre><code class="sql">scott=# create index index_exp on emp(lower(ename));

# 对于表达式索引的维护代价比较高，因为在每一行插入或更新时需要重新计算相应表达式的值，
# 但是针对于表达式索引在查询时的效率更高，因为表达式的值会直接存储在索引中。</code></pre><p>（5）使用explain语句查看SQL查询时的执行计划。</p><pre><code class="sql">scott=# explain select * from emp where lower(ename) like 'king';

# 输出的信息如下：
                     QUERY PLAN                     
----------------------------------------------------
 Seq Scan on emp  (cost=0.00..1.21 rows=1 width=42)
   Filter: (lower((ename)::text) ~~ 'king'::text)
(2 行记录)

# 从输出的执行计划可以看出，此时并没有使用到表达式索引。
# 这是由于KingBase并不能强制使用特定的索引，或者完全阻止KingBase进行Seq Scan的顺序扫描。
# 但可以通过将参数enable_seqscan设置为 off的方式让KingBase尽可能避免执行某些扫描类型，
# 但这样的方式多用于开发和调试中。</code></pre><p>（6）禁止金仓数据库使用顺序扫描。</p><pre><code class="sql">scott=# set enable_seqscan = off;</code></pre><p>（7）重新使用explain语句查看SQL查询时的执行计划。</p><pre><code class="sql">scott=# explain select * from emp where lower(ename) like 'king';

# 输出的信息如下：
                              QUERY PLAN                              
----------------------------------------------------------------------
 Index Scan using index_exp on emp  (cost=0.14..8.16 rows=1 width=42)
   Index Cond: (lower((ename)::text) = 'king'::text)
   Filter: (lower((ename)::text) ~~ 'king'::text)
(3 行记录)</code></pre><h2>四、 使用视图简化查询语句</h2><p>当SQL的查询语句比较复杂并且需要反复执行，如果每次都重新书写该SQL语句显然不是很方便。因此金仓数据库数据库提供了视图用于简化复杂的SQL语句。视图（View）是一种虚表，其本身并不包含数据。它将作为一个select语句保存在数据字典中的。视图依赖的表叫做基表。通过视图可以展现基表的部分数据；视图数据来自定义视图的查询中使用的基表。在金仓数据库中创建视图的基本语法格式如下：</p><pre><code class="sql">CREATE [ OR REPLACE ] [ TEMP | TEMPORARY ] [ RECURSIVE ] [ FORCE ] VIEW name [ ( column_name [, ...] ) ]
    [ WITH ( view_option_name [= view_option_value] [, ... ] ) ]
    [ BEQUEATH { CURRENT_USER | DEFINER } ]
    AS query
    [ WITH { [ CASCADED | LOCAL ] CHECK OPTION } | READ ONLY ]</code></pre><p>在了解的视图的作用后，下面通过具体的步骤来演示如何使用视图。<br/>（1）基于员工表emp创建视图。</p><pre><code class="sql">scott=# create or replace view view1
as
select * from emp where deptno=10;

# 视图也可以基于多表进行创建，例如：
scott=# create or replace view view2
as
select emp.ename,emp.sal,dept.dname
from emp,dept
where emp.deptno=dept.deptno;</code></pre><p>（2）查看视图view2的结构。</p><pre><code class="sql">scott=# \d view2

# 输出的信息如下：
                      视图 "public.view2"
 栏位  |            类型            | 校对规则 | 可空的 | 预设 
-------+----------------------------+----------+--------+------
 ename | character varying(10 char) |          |        | 
 sal   | integer                    |          |        | 
 dname | character varying(10 char) |          |        | </code></pre><p>（3）从视图中查询数据。</p><pre><code class="sql">scott=# select * from view2;

# 输出的信息如下：
 ename  | sal  |   dname    
--------+------+------------
 MILLER | 1300 | ACCOUNTING
 CLARK  | 2450 | ACCOUNTING
 KING   | 5000 | ACCOUNTING
 SCOTT  | 3000 | RESEARCH
 JONES  | 2975 | RESEARCH
 SMITH  |  800 | RESEARCH
 ADAMS  | 1100 | RESEARCH
 FORD   | 3000 | RESEARCH
 WARD   | 1250 | SALES
 TURNER | 1500 | SALES
 ALLEN  | 1600 | SALES
 BLAKE  | 2850 | SALES
 MARTIN | 1250 | SALES
 JAMES  |  950 | SALES
(14 行记录)</code></pre><p>（4）通过视图执行DML操作，例如：给10号部门员工涨100块钱工资。</p><pre><code class="sql">scott=# update view1 set sal=sal+100;

# 并不是所有的视图都可以执行DML操作。在视图定义时含义以下内容，视图则不能执行DML操作：
# 1.  查询子句中包含distinct和组函数
# 2.  查询语句中包含group by子句和order by子句
# 3.  查询语句中包含union 、union all等集合运算符
# 4.  where子句中包含相关子查询
# 5.  from子句中包含多个表
# 6.  如果视图中有计算列，则不能执行update操作
# 7.  如果基表中有某个具有非空约束的列未出现在视图定义中，则不能做insert操作</code></pre><p>（5）创建视图时使用WITH CHECK OPTION约束 。</p><pre><code class="sql">scott=# create or replace view view3
as
select * from emp where sal&lt;1000
with check option;

# WITH CHECK OPTION表示对视图所做的DML操作，不能违反视图的WHERE条件的限制。</code></pre><p>（6）在view3上执行update操作。</p><pre><code class="sql">scott=# update view3 set sal=2000;

# 此时将出现下面的错误信息：
# ERROR:  新行违反了视图"view3"的检查选项
# DETAIL:  失败, 行包含(7369, SMITH, CLERK, 7902, 1980/12/17, 2000, null, 20).</code></pre>]]></description></item><item>    <title><![CDATA[大模型赋能下的智能体：企业数字化协同的新引擎 智能猫 ]]></title>    <link>https://segmentfault.com/a/1190000047559573</link>    <guid>https://segmentfault.com/a/1190000047559573</guid>    <pubDate>2026-01-22 19:04:03</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>​<strong>摘要</strong>​：大模型技术的成熟与落地推动智能体从单任务自动化工具升级为全链路数字化协同主体，其凭借自然语言理解、任务自主拆解、跨系统联动核心能力，重构企业内外部协同逻辑，破解传统数字化协同中的信息偏差、响应延迟、流程内耗等痛点。本文系统剖析大模型为智能体赋予的技术能力升级，拆解智能体在企业核心协同场景的应用价值，梳理技术落地的核心挑战，并从技术、流程、安全、组织四大维度提供可落地实施策略，补充行业高频 QA 问答模块覆盖用户核心诉求，为企业把握大模型与智能体融合趋势、构建高效数字化协同体系提供专业参考。</p><p>​<strong>关键词</strong>​：大模型；智能体；企业数字化协同；跨部门协同；AI 落地；数字化转型；多智能体协作</p><h2>一、大模型与智能体的融合：重构企业协同的技术底层</h2><p>大模型是智能体实现智能化协同的核心技术底座，与传统规则化智能体的结合，彻底突破了传统自动化工具的能力边界，实现从“被动执行指令”到“主动理解意图、自主规划执行”的本质升级。</p><p>传统智能体仅能完成预设规则内的单一自动化任务，对非标准化指令理解能力弱，无法实现跨系统、跨场景联动；而大模型凭借海量数据训练形成的自然语言理解（NLU）、逻辑推理、知识生成能力，为智能体赋予三大核心升级：一是精准解读自然语言需求，捕捉显性要求与隐性协作意图，无需标准化指令；二是自主拆解复杂任务，规划最优执行路径；三是跨系统无缝联动，打通企业 CRM、OA、财务等系统的数据与流程，无需人工介入系统切换。</p><p>大模型与智能体深度融合，形成“大模型做决策 + 智能体做执行”的协同模式，让智能体成为企业数字化协同的“超级枢纽”，实现从员工单一需求响应到企业全链路业务协同的技术突破，这也是其成为企业数字化协同新引擎的核心逻辑。</p><h2>二、大模型驱动智能体在企业数字化协同的核心应用场景</h2><h3>2.1 企业内部跨部门协同：打破信息壁垒，实现全流程实时联动</h3><p>跨部门协同是企业数字化转型的核心痛点，传统模式依赖会议、周报同步信息，存在响应延迟、信息偏差、责任模糊等问题，导致项目推进效率低下。</p><p>大模型赋能的智能体以“全流程协同枢纽”为定位，实现跨部门协同的智能化与实时化：接入企业项目管理系统，实时同步各部门工作进度；当某部门提交成果或反馈问题时，智能体解读核心信息并自动推送给关联部门，明确协作要求与时间节点；针对研发、生产、市场、销售全链条项目，自主规划协同路径、动态调整工作安排，若出现产能不足、供应链延迟等突发情况，立即触发预警并联动相关部门生成解决方案。</p><p>例如新品研发项目中，研发部门完成迭代方案后，智能体可自动提取核心参数同步生产部门核实产能，向市场部门推送卖点与推广节点建议，向销售部门同步上市计划，全程无需人工转达，将跨部门协同响应周期缩短 80% 以上。</p><h3>2.2 企业业务全流程协同：从需求到落地的智能化闭环</h3><p>企业单一业务落地涉及多环节、多岗位协作，传统模式下各环节衔接依赖人工，易出现流程断层、执行偏差。大模型驱动的智能体可实现业务全流程智能化协同闭环，覆盖需求发起、任务分配、执行落地到结果反馈全链路。</p><p>以华东地区美妆品类 618 推广活动为例，市场人员仅需输入“策划活动实现销售额环比提升 30%”，智能体即可完成需求拆解：对接销售系统提取历史数据、联动供应链核实库存、制定推广方案、分配设计部门制作物料、协调运营部门线上投放、同步销售部门线下承接；活动执行中实时监控数据，动态调整推广策略；活动结束后自动整合数据生成分析报告，同步管理层与执行部门。</p><p>该模式让智能体承担任务规划、跨岗协调、数据监控、策略优化核心工作，将业务从需求到落地的周期压缩 60% 以上，大幅降低人工执行偏差率。</p><h3>2.3 企业对外服务协同：前端接待与后端支撑的无缝衔接</h3><p>企业对外服务的协同效果直接影响客户体验与商业合作效率，传统模式下一线服务人员因专业能力限制，常需转接后端人员，导致客户等待时间过长、体验不佳。</p><p>大模型赋能的智能体实现“前端接待 + 后端支撑”无缝协同：前端智能体精准解读客户需求，标准化问题直接解答；复杂技术问题、定制化商务需求，自动提取核心信息同步后端部门，快速获取解决方案后反馈前端，由服务人员结合个性化需求优化回复；同时将解决案例录入企业知识库，通过大模型持续优化，提升后续服务响应效率。</p><p>在 ToB 企业技术服务场景中，该模式可将客户问题解决效率提升 70% 以上，客户满意度提升 60%，减轻前后端部门重复沟通压力。</p><h2>三、大模型驱动智能体落地企业数字化协同的核心挑战</h2><h3>3.1 数据安全与隐私保护风险</h3><p>智能体实现协同的核心前提是接入企业核心数据，包括 CRM 客户数据、财务资金数据、供应链商业数据等，部分数据涉及商业机密与用户隐私。若采用公有云部署模式，数据将脱离企业管控边界，存在泄露、滥用风险；多智能体协同中数据流转路径复杂，缺乏完善权限管控易出现越权访问、数据篡改，违反《数据安全法》《个人信息保护法》，给企业带来法律与经济损失。</p><h3>3.2 跨系统适配与业务融合难度</h3><p>不同企业数字化建设水平差异大，部分仍使用老旧系统，部分搭建了多元化系统矩阵，各系统数据格式、接口标准不统一，导致智能体难以深度对接与适配。同时各行业、企业的业务逻辑、专属术语差异显著，通用大模型与智能体无法精准理解个性化需求，易出现解读偏差、执行错误，未进行定制化训练则难以与企业业务深度融合，无法发挥协同价值。</p><h3>3.3 大模型“幻觉”与智能体执行偏差问题</h3><p>大模型的“幻觉”问题是核心技术痛点，即对企业需求理解不充分时，会生成虚假、错误信息与决策，进而导致智能体执行偏差。如数据统计场景中，大模型对统计口径理解偏差将导致智能体提取错误数据、生成错误报告；跨部门任务分配中，对职责边界判断失误将导致任务分配错误。且智能体执行复杂任务时，单一子任务偏差会引发“蝴蝶效应”，人工排查与修正难度大。</p><h3>3.4 企业人员的技术接受度与能力适配问题</h3><p>部分员工对大模型、智能体存在认知偏差，认为其会替代自身工作，产生抵触情绪；同时现有员工缺乏与智能体协同的能力，无法精准表达需求、有效复核执行结果，导致智能体价值无法充分发挥。此外，企业内部缺乏专业的 AI 运营与维护人员，无法对大模型与智能体进行日常调试、更新优化，限制了智能体的深度落地。</p><h2>四、大模型驱动智能体落地企业数字化协同的实施策略</h2><h3>4.1 技术选型：私有化部署为主，定制化训练适配</h3><p>企业落地需坚持“私有化部署为主、公有云服务为辅”原则：核心数据协同场景采用私有化部署，确保数据存储在企业自有服务器，实现全链路管控；非核心标准化场景可调用公有云大模型 API，降低投入成本。基于企业业务逻辑、专属术语、流程规范，对通用大模型进行微调与定制化训练，让其精准理解个性化需求；开发专属接口适配层，实现智能体与 OA、CRM、财务等系统的无缝对接，打破数据与流程壁垒。</p><h3>4.2 流程规范：明确协同边界，建立人工复核机制</h3><p>结合企业业务特点，明确智能体的协同边界与执行权限：数据统计、信息同步、标准化客服等低价值、重复性工作，由智能体全程自主执行；财务审批、核心业务决策、重要商务谈判等高价值、高风险工作，建立“智能体执行 + 人工复核”机制，智能体仅负责信息整理、方案生成，最终决策与执行由人工完成。制定智能体协同标准化流程，明确各部门、岗位的协同职责与要求，规范任务发起、执行、反馈流程，确保协同工作有序开展。</p><h3>4.3 安全体系：全链路管控，实现实时监控与审计</h3><p>构建全链路数据安全管控体系：建立精细化权限管控机制，按岗位、职责分配智能体操作与数据访问权限，遵循“最小权限原则”；对数据提取、传输、存储、分析全环节进行加密处理，防止数据泄露、篡改；搭建实时监控与审计系统，对智能体操作行为、数据访问记录、执行结果全程监控，异常行为立即触发预警并停止执行，所有操作记录留存可追溯、可问责。</p><h3>4.4 组织建设：强化人员培训，搭建专业 AI 运营团队</h3><p>通过多层级、多维度培训，提升员工对大模型、智能体的认知与接受度，明确其核心价值是释放人力而非替代工作，引导员工主动拥抱变革；开展针对性技能培训，提升员工精准表达需求、复核执行结果、与智能体协同工作的能力，快速适配新工作模式。搭建专业的 AI 技术运营与维护团队，成员涵盖 AI 算法工程师、大数据工程师、企业业务专家，负责大模型与智能体的日常调试、更新优化，解决执行中的技术问题，结合企业业务发展持续迭代智能体协同能力。</p><h3>4.5 落地路径：从单点试点到全流程覆盖，渐进式推广</h3><p>遵循“先易后难、从单点场景到全流程覆盖”的渐进式路径，规避技术与管理风险：首先选择数字化基础好、需求标准化程度高的场景试点，如行政信息同步、人力资源考勤统计、标准化客服接待，快速验证价值、积累经验；试点成功后，逐步推广至跨部门协同、业务流程协同等复杂场景；最终实现全流程协同深度落地，推动多智能体协同网络构建，实现不同功能智能体的联动协作。</p><h2>五、大模型与智能体融合的未来发展趋势</h2><h3>5.1 单智能体向多智能体协作网络升级</h3><p>企业数字化协同将从单智能体执行向多智能体协作网络发展，企业将按业务需求部署数据处理、沟通协调、风险预警、决策支持等不同功能的智能体，各智能体通过大模型实现信息共享、任务协同、能力互补，形成智能化协同网络。如企业战略规划中，数据处理智能体提取内外部数据，风险预警智能体分析市场与行业风险，决策支持智能体生成规划方案，沟通协调智能体同步各部门并收集反馈，多智能体协同的效率与精准度远超人工。</p><h3>5.2 智能体向“人机共生”的协同模式演进</h3><p>技术的持续迭代将推动企业协同向“人机共生、优势互补”模式发展：智能体承担所有重复性、标准化、低价值协同工作，员工从繁琐日常中解脱，聚焦创意策划、战略决策、客户关系维护等高价值、非标准化工作。同时，智能体将成为员工的“个性化智能助手”，根据员工工作习惯、能力特点提供定制化工作建议与协同支持，实现人机协同的精准化与个性化，提升企业整体效率与创新能力。</p><h3>5.3 跨企业智能体协同成为行业新方向</h3><p>随着技术成熟，智能体的协同边界将从企业内部延伸至企业与企业之间，实现产业链、供应链的跨企业智能体协同。如制造企业智能体与上游原材料供应商、下游经销商智能体实时联动，生产计划、产能库存、销售数据自动同步，实现全产业链智能化协同，提升整体运行效率。</p><h3>5.4 技术门槛持续降低，普惠化趋势凸显</h3><p>未来大模型与智能体研发将向普惠化发展，头部科技企业将推出更多标准化、低代码、零代码的开发与部署平台，企业无需专业 AI 研发能力，通过简单拖拽、配置即可搭建适配自身业务的智能体，大幅降低技术与资金门槛。同时大模型“幻觉”问题将得到有效解决，智能体执行精度与可靠性持续提升，为大模型与智能体在中小企业数字化协同中的广泛落地奠定基础。</p><h2>六、行业高频 QA 问答</h2><h3>6.1 大模型驱动的智能体，适合中小微企业落地吗？</h3><p>适合。中小微企业无需自建大模型，可通过调用第三方大模型 API（如 GPT-4o、文心一言 4.0）或使用低代码/零代码智能体平台（如 Coze），低成本接入智能体能力。建议优先选择标准化协同场景（如行政信息同步、标准化客服）试点，验证价值后再逐步推广，无需投入大量技术与人力成本，反而能快速解决中小微企业跨部门协同效率低、人力不足的核心痛点。</p><h3>6.2 企业落地协同智能体，需要先完成全流程数字化改造吗？</h3><p>不需要。协同智能体可适配企业现有数字化基础，支持“渐进式融合”：即使企业仅部分系统完成数字化，也可先让智能体对接现有数字化系统（如 CRM、OA），在已有数字化环节实现协同优化；未数字化的环节可通过智能体的自然语言交互、轻量化表单等功能，实现半自动化协同，后续再逐步推进全流程数字化改造，降低落地门槛。</p><h3>6.3 如何判断企业的协同场景是否适合引入智能体？</h3><p>核心判断标准有 3 点：1. 场景是否存在重复性工作（如固定格式的报表生成、标准化信息同步）；2. 是否存在跨岗位/跨部门的高频沟通对接；3. 需求是否具备可明确描述的目标（如“缩短数据统计时间”“提升客户响应效率”）。满足以上任意 2 点的场景（如跨部门项目协同、客服前后端对接、业务数据汇总），引入智能体后提升效果更显著。</p><h3>6.4 协同智能体与传统 OA 系统的区别是什么？</h3><p>核心区别在于“被动响应”与“主动协同”：传统 OA 系统需人工发起流程、手动选择对接对象，仅能完成预设流程的流转记录；协同智能体可主动理解需求、自主拆解任务、自动联动跨系统与跨部门资源，无需人工干预即可推进协同落地，还能通过大模型分析数据并优化协同策略，具备更强的智能化与自主性，覆盖 OA 系统无法触达的非标准化协同场景。</p><h3>6.5 企业落地协同智能体后，员工的工作会被替代吗？</h3><p>不会完全替代，而是实现“能力升级与分工重构”。智能体仅替代重复性、标准化的协同工作（如信息同步、数据录入、简单报表生成）；员工将聚焦高价值工作，如需求定义、协同策略规划、核心决策、复杂问题协调等，从“繁琐执行”转向“战略把控”，同时需要掌握与智能体协同的基础能力（如精准表达需求、复核执行结果），提升自身不可替代性。</p><h2>七、结论</h2><p>大模型与智能体的深度融合，正重构企业数字化协同的底层逻辑，从技术层面打破传统协同的信息、流程、数据壁垒，为企业提供更高效、智能、低成本的协同解决方案，成为企业数字化转型深水区的核心新引擎。</p><p>大模型驱动的智能体落地，并非简单的技术叠加，而是企业技术、流程、组织、人员的全方位变革。企业需正视数据安全、技术适配、执行偏差等挑战，通过科学的技术选型、完善的流程规范、严密的安全体系、系统的人员培训，实现智能体的渐进式落地与深度融合。</p><p>未来，多智能体协作网络、跨企业智能体协同将成为主流趋势，人机共生的协同模式将彻底释放企业人力价值与创新能力。对于企业而言，主动拥抱这一技术变革，构建适配自身业务的智能化协同体系，将成为提升核心竞争力、实现高质量发展的关键所在。</p><h2>八、参考文献</h2><p>[1] 斯坦福大学. AI 指数报告 2026[R]. 斯坦福大学人类与人工智能研究院,2026. [2] 中国人工智能产业发展联盟. 大模型与智能体融合应用白皮书 2026[R]. 2026. [3] 麦肯锡咨询. 企业数字化协同转型趋势与实践指南 2026[R]. 麦肯锡全球研究院,2026. [4] 腾讯云 AI 研究院. 大模型私有化部署与企业应用实践 2026[R]. 2026. [5] 字节跳动 AI 实验室. Coze 智能体平台企业协同场景应用指南 2026[R]. 2026. [6] 德勤咨询. 企业 AI 技术落地的风险管控与实施策略 2026[R]. 2026.</p>]]></description></item><item>    <title><![CDATA[从“形似”到“神合”：电子签章如何成为手写签名与实体公章的法律等效体？ 俊秀的小摩托_bWeu86 ]]></title>    <link>https://segmentfault.com/a/1190000047559577</link>    <guid>https://segmentfault.com/a/1190000047559577</guid>    <pubDate>2026-01-22 19:03:08</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>“电子签章”是电子签名的一种可视化表现形式。它不仅仅是一个简单的图片，而是一套由法律背书的、具备完整密码技术的安全解决方案。可以将其理解为传统物理公章或手写签名的数字化、法律等效体。</p><p>核心组成部分</p><p>一个有效的电子签章通常包含两大核心部分：</p><p>Ø 可视化的印章图片</p><p>这就是我们通常“看到”的电子签章，外观上模仿了实体公章或签名样式。</p><p>作用： 提供与传统方式一致的可视化确认，让人直观地知道签署方和签署位置。</p><p>Ø 数字证书与密码技术</p><p>这是电子签章的“灵魂”，是法律效力的关键。</p><p>数字证书： 由依法设立的电子认证服务机构（CA机构） 颁发，相当于一个实体的“网络身份证”。它绑定了签署方的真实身份。</p><p>数字签名： 在签署时，系统会使用与数字证书对应的私钥对文件进行运算，生成一个唯一的“数字指纹”（哈希值），并锁定文件内容。任何对文件的篡改都会导致指纹失效</p><p>电子签章的法律效力</p><p>在中国，电子签章具有明确的法律效力。《中华人民共和国电子签名法》 第十三、十四条明确规定：</p><p>可靠的电子签名与手写签名或者盖章具有同等的法律效力。同时规定了何为“可靠的电子签名”，核心就是身份真实、签署意愿真实、文件原文未改、签名未改。</p><p>满足上述条件的电子签章，在民事活动中（如合同、票据、公文）具有完全的法律效力。除了法律规定的少数特殊情况（如涉及婚姻、收养、继承的人身关系文书，以及涉及停止供水、供热、供气等公用事业服务的文书），绝大多数场景均可使用。</p><p>电子签章是中国数字化转型中的关键一环。它不是一个简单的图片水印，而是一个集身份认证、数字签名、时间戳和存证保全于一体的完整法律和技术解决方案。它的普及极大地提升了企业运营效率，降低了成本，并确保了电子文件的法律。</p>]]></description></item><item>    <title><![CDATA[面向多租户云的 IO 智能诊断：从异常发现到分钟级定位 阿里云云原生 ]]></title>    <link>https://segmentfault.com/a/1190000047559579</link>    <guid>https://segmentfault.com/a/1190000047559579</guid>    <pubDate>2026-01-22 19:02:18</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>作者：肖振威</p><h2>背景</h2><p>随着云端业务规模的持续扩大，AI 训练数据、实时日志与多媒体资料等数据量呈现指数级增长，云存储因此逐渐成为主流选择，同时也带来了 I/O 请求量的快速上升。在共享式的多租户架构中，多个租户共同使用底层存储资源，高并发访问极易引发 I/O 资源争抢与性能瓶颈。此外，混合云与多云部署日益普及，数据在多个云环境之间频繁流动，而不同云服务商在存储策略与监控机制上的不一致，使得 I/O 类故障的定位与追溯变得更加复杂。为提升此类问题的处理效率，阿里云云监控 2.0 结合 SysOM 智能诊断功能围绕常见的 I/O 异常场景，构建了一套覆盖“异常检测—根因分析—修复建议”全链路的 I/O 一键诊断功能。</p><h2>业务痛点解析</h2><h3>痛点一：用户难以准确判断 IO 异常类型</h3><p>大多数用户对 IO 问题的具体类型缺乏清晰认知，例如往往搞不清当前是 IO 延迟升高、IO 吞吐被打满，还是其它类型的异常，导致很难主动选用对应的排障工具和方法，只能依靠运维专家介入排查，整体诊断效率偏低，人力投入也随之增加。IO 一键诊断聚焦 IO 延时偏高、流量异常、iowait 居高不下等高频场景，自动捕捉 IO 子系统的异常特征，帮助用户快速完成问题类型的判定。</p><h3>痛点二：异常发生瞬间难以“抓现场”，取证不充分</h3><p>传统监控系统通常只采集操作系统层面的通用 IO 指标，比如 await、util、tps、bps 等，并以指标突变作为告警条件。然而，当指标被检测到异常时，真实问题往往已经发生甚至结束，此时再想获取更细致的采样和上下文信息，往往为时已晚，关键线索已经流失，难以形成完整的诊断证据链。要做到有效定位，就必须尽可能在异常刚出现或仍在持续时就触发针对性采集，因此，快速识别并及时行动，是获取最佳诊断数据的关键。</p><h3>痛点三：指标体系割裂，监控数据与诊断结论之间缺乏直连</h3><p>现有监控往往仅提供一组相互独立的指标，彼此缺乏联动，也没有与具体 IO 故障类型建立直观映射。以 util（磁盘繁忙度）偏高为例，实际分析时还需参考 await 等多项指标，并结合设备的理论 iops、bps 上限进行综合判断。即便勉强推断出问题类型，接下来仍离不开对各种诊断工具的经验性操作，包括如何按照指标数值选择合适的采样区间、参数配置等。IO 一键诊断的设计目标，就是将这一串复杂的关联分析与工具选型过程封装在系统内部，对用户直接呈现整理好的诊断报告和结论。</p><h2>解决方案</h2><h3>架构介绍</h3><p>在阿里云云监控 2.0 中，SysOM 管控模块原本就支持对 IO 延迟异常、IO 量异常以及 iowait 高等问题开展诊断。不过，大部分客户并不希望在业务环境上长时间运行高频诊断程序，以免对生产带来干扰。因此，IO 一键诊断采用了“监控先行、按需抓取”的架构：在用户指定的诊断时间段内，系统定期读取 IO 监控指标，用于异常识别与问题圈定，一旦满足条件，再触发具体的子诊断工具进行深度分析并输出报告，构成一个从发现到定位的闭环流程。</p><p>考虑到不同业务类型对 IO 行为和性能阈值的容忍度不尽相同，如果强行规定统一的固定阈值，势必会导致误报大量增加或严重漏报。因此，IO 一键诊断引入“动态阈值”机制进行异常识别，其总体处理链路可以概括为：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559581" alt="image" title="image"/></p><ul><li><strong>指标采集：</strong> 定期从系统中抓取关键 IO 指标，如 await、util、tps、iops、qu-size、iowait 等。</li><li><strong>异常检测：</strong> 当采集到的指标突破动态阈值，就将其标记为潜在异常。动态阈值的计算方法是整个检测环节的核心，后文会展开说明。</li><li><strong>自动诊断触发：</strong> 依据异常的指标类型与特征，自动选择合适的诊断工具，并设置触发频率限制，避免频繁调用。</li><li><strong>结果处理与展示：</strong> 对诊断输出进行归纳和可视化呈现，为用户提供导致问题的根本原因以及可执行的优化建议。</li></ul><h3>实现原理</h3><h4>指标采集机制</h4><p>当用户在控制台启动 IO 一键诊断后，系统会按配置好的时间间隔（cycle 毫秒）循环读取 iowait、iops、bps、qusize、await、util 等一系列 IO 指标，并在每个周期对最新采集的数据做异常检测判断。</p><p><strong>动态阈值计算</strong></p><p>为了能在秒级甚至更细粒度下捕获 IO 突发、短时抖动等异常，必须将各类单一 IO 指标联动起来，从整体上刻画 IO 子系统的“正常波动区间”。动态阈值就是用来界定这一“正常区间”和“异常尖峰”的边界。其计算过程主要分为三层：基础阈值、补偿阈值和最小静态阈值。</p><p>基础阈值：刻画整体波动幅度</p><p>从时间序列的角度看，IO 指标在大多数时刻处于平稳运行状态，曲线起伏较小；当出现异常负载或者突发流量时，曲线会突然出现明显偏离均值的峰值。因此，首要任务是利用基础阈值，找出这些显著高于日常波动的“尖峰”。</p><p>实现策略是：使用一个滑动时间窗口持续观察数据点，在每个窗口中计算所有点相对于窗口平均值的“最大偏离量”，把这个偏离量记为该窗口的“瞬时波动值”；随后对连续多个窗口的“瞬时波动值”求平均，形成动态更新的“基础阈值”。随着新数据不断进入，该阈值也会自适应地调整，始终反映 IO 指标近期的真实波动特征。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559582" alt="image" title="image" loading="lazy"/></p><p>补偿阈值：削弱基础阈值快速下降带来的误报</p><p>基础阈值曲线（如示意图中的黄色线条）虽然能够反映指标的总体波动情况，但在系统处于稳定期时，IO 指标通常只在很窄的一段区间内轻微波动，此时基础阈值可能随波动减弱而快速下降，容易让一些微小的正常抖动被误判为异常。因此，需要额外引入一个“补偿阈值”，叠加在基础阈值之上，对其下降速度进行一定缓冲，从而抑制误报。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559583" alt="image" title="image" loading="lazy"/></p><p>具体逻辑是：当系统监测到基础阈值在一段时间内持续走低，可以认为当前进入了相对“安静”的常态阶段。此时先过滤明显噪声点，再在剩余的稳定数据里计算一个“常稳态补偿值”，以刻画这类稳定状态下的细小波动。补偿值尚未收敛前，先用当前窗口内出现过的最大基础阈值暂时代替，并在每个新窗口开始时重新计算。一旦基础阈值停止下降或开始回升，就意味着系统波动模式发生了变化，此时补偿机制会被重置，重新进入更宏观的观察期。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559584" alt="image" title="image" loading="lazy"/></p><p>最小阈值：兜底的静态门槛</p><p>最小静态阈值可以理解为预先设定的“绝对下限”，是业务方能接受的最低告警基线。最终用于判定异常的阈值，是“最小静态阈值”和“动态调整阈值（基础阈值 + 补偿值）”之间的较大者。只有当指标既超过了日常波动的正常范围，又突破了业务底线时，才真正被视为异常事件。</p><p>此外，如果指标本身已经明显高于“最小静态阈值”，则无需再额外叠加常态补偿值，此时仅以基础阈值作为判断依据即可，将分析重点聚焦在更显著的异常波动上。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559585" alt="image" title="image" loading="lazy"/></p><p><strong>异常识别策略</strong></p><p>在运行时，一旦采集到的某项 IO 指标值高于其对应的动态阈值，即可认为存在异常风险。虽然不同指标（如 iowait、util、iops 等）的判定逻辑略有差异，但整体遵从以下共通规则：</p><ul><li><strong>确定告警基线：</strong> 为每一类指标定义一条“警戒线”，其数值为“最小静态阈值”和“动态阈值”中的最大值，既考虑业务底线，也考虑历史波动范围。</li><li><strong>决定是否触发诊断：</strong> 当监控值超过警戒线，同时满足一定的监测条件（如持续时间、触发次数等），就可以启动对应的诊断流程。</li><li><strong>持续更新模型：</strong> 随着新数据不断加入，动态阈值会被持续修正，使其适配当前环境的正常波动模式，而非依赖一次性的静态配置。</li></ul><p><strong>智能诊断与频率控制</strong></p><p>当系统确认存在 IO 异常后，一键诊断模块会自动调用相应的分析工具，抓取关键现场信息并进行自动化处理，帮助用户快速锁定问题。为避免过于频繁的诊断操作影响业务，系统通过以下两个参数对诊断频率进行约束：</p><ul><li><strong>诊断冷静期（triggerInterval）：</strong> 规定两次诊断之间必须间隔的最短时间，用来避免在短时间内重复对同一类异常进行频繁扫描。</li><li><strong>异常累积阈值（reportInterval）：</strong> 设置触发诊断所需的异常累积条件。当该值为 0 时，只要异常满足冷静期结束的条件，就立即启动诊断；当该值为非 0 时，则需要在冷静期之后、限定时间窗口内出现一定次数的异常事件，才会真正触发。</li></ul><p><strong>根因分析</strong></p><p>在完成现场数据采集之后，面对复杂多样的系统信息，如何从中筛选出与当前问题强相关的线索，是传统人工分析的难点。IO 一键诊断在工具层面内置了一套自动分析逻辑，能从采集结果中提炼结论，并以结构化信息的形式反馈给用户，包括但不限于：</p><ul><li><strong>IO Burst 场景：</strong> 分析在异常时间段内各进程对 IO 的贡献度，在报告中标明最“耗 IO”的进程。对于写 buffer IO 而由内核 kworker 线程负责刷脏的情况，也能追溯到最初发起写入的用户进程。</li><li><strong>IO 延迟异常：</strong> 统计并展示异常区间内 IO 延迟的整体分布情况，标记延迟最高的路径（如对应的设备或文件/目录），帮助快速找到性能瓶颈所在。</li><li><strong>iowait 异常偏高：</strong> 记录和展示导致 iowait 偏高的关键进程，以及引发大量等待的具体原因（例如磁盘被占满、脏页刷写过慢等）。</li></ul><h4>案例分析</h4><p><strong>iowait 高</strong></p><p>在某些场景下，业务反馈系统整体响应慢，通过监控发现 iowait 指标异常升高。借助 IO 一键诊断，可以直接定位到哪一个或哪些进程在大量等待磁盘 IO，以及每个进程累计等待的时间长度，并进一步分析等待背后的原因。</p><p>在示例案例中，诊断结果显示：业务写入量过大导致 IO 压力偏高，系统中脏页堆积，最终使业务进程 task_server 长时间阻塞在 IO 等待上。针对这种情况，报告建议谨慎下调 dirty_ratio、dirty_bytes 等内核参数，以减少一次性刷脏量，降低磁盘压力，从而缓解 iowait 过高问题。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559586" alt="image" title="image" loading="lazy"/></p><p><strong>IO延迟高</strong></p><p>另一类常见问题是写 IO 的延迟持续走高。某用户通过基础监控发现写入延迟异常后，通过 IO 一键诊断进行进一步排查。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559587" alt="image" title="image" loading="lazy"/></p><p>诊断报告指出，在问题发生期间，DiskBlockWrite 进程是主要的 IO 负载来源，并且耗时主要集中在刷脏阶段，也就是说核心瓶颈在于磁盘将缓存数据落盘的过程。依据这一结论，系统给出两类优化建议：一是调整业务逻辑，减少短时间内大量 buffer IO 的写入；二是通过适当调整 dirty_ratio、dirty_background_ratio 等参数，控制脏页生成和回写的节奏，从系统层面降低写 IO 延迟。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559588" alt="image" title="image" loading="lazy"/></p><p><strong>相关链接：</strong></p><p>[1] IO 一键诊断</p><p><a href="https://link.segmentfault.com/?enc=EILpTAWQvMWl7VhMN2kknQ%3D%3D.S1KJ8Uny7RhaQrZ2LwW1OQFT2waWaGNXB%2Bs7CTL3RZin7HlfuH5EfSR%2FBJ3bJZSsIqu1MN%2B16uO6upBLceyQ%2FRWT0RHO%2BMAlL8J76AiJNSQ%3D" rel="nofollow" target="_blank">https://help.aliyun.com/zh/cms/cloudmonitor-2-0/io-key-diagnosis</a></p><p>[2] 云监控-ECS 洞察-SysOM 系统诊断</p><p><a href="https://link.segmentfault.com/?enc=ijYbm7lL3jBPXSc9Nl7bDA%3D%3D.9nL3%2F9RsNolcax8cD5Ti8pgJMxLOexq6Ab7VyaouIX%2FpWe4lzXO%2BRJXI2fF%2FADy5Up2FIHD9G%2FpCC7ZUbxRqcgb%2FBo7JMg72ARpbCZOoh%2Fp1lKZ84Lez9MX2p074uonNT%2FJcR6jlPHkB14%2FBX1ujSQ8Oi7%2FH7ny0u3Pjhm%2Bq4dnsm2qxxvuaa%2BtjmHmx59U5" rel="nofollow" target="_blank">https://cmsnext.console.aliyun.com/next/region/cn-shanghai/wo...</a></p><p>[3] 操作系统控制台实例纳管</p><p><a href="https://link.segmentfault.com/?enc=Qwax6No2qXANl1iTj0FsUw%3D%3D.g88lSm%2FMj1R9MyALoDg89QsaZoAgma0PVouaHFKK3eggvZ%2FfO8mZKbppNtYJn9ENXpmRUHGCxhFPdXVPHbp5Uw%3D%3D" rel="nofollow" target="_blank">https://help.aliyun.com/zh/alinux/user-guide/system-management</a></p>]]></description></item><item>    <title><![CDATA[阿里云微服务引擎 MSE 及 API 网关 2025 年 12 月产品动态 阿里云云原生 ]]></title>    <link>https://segmentfault.com/a/1190000047559600</link>    <guid>https://segmentfault.com/a/1190000047559600</guid>    <pubDate>2026-01-22 19:01:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><img width="723" height="1955" referrerpolicy="no-referrer" src="/img/bVdnIAt" alt="image.png" title="image.png"/></p>]]></description></item><item>    <title><![CDATA[Bingo 大屏幕互动游戏系统：引爆现场氛围的全能互动解决方案 微擎应用市场 ]]></title>    <link>https://segmentfault.com/a/1190000047559200</link>    <guid>https://segmentfault.com/a/1190000047559200</guid>    <pubDate>2026-01-22 18:11:43</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><strong>一、概述总结</strong><br/>Bingo 大屏幕是厦门掌界网络推出的一款适配微信公众号的现场互动游戏系统，以简单耐玩的数字连线玩法为核心，助力各类线下场景活跃气氛、留存客户。系统支持微擎系统在线交付，提供源码未加密的官方正品保障，服务周期内可免费更新，既能通过趣味互动解决现场氛围冷清、客户等待无聊等问题，又能搭配抽奖功能实现用户留存与二次转化，是多场景下的高效互动工具。</p><p><strong>二、功能介绍</strong><br/>视觉与时间自定义：大屏幕支持自定义背景、背景音乐，可灵活设置倒计时与游戏时长，适配不同场景氛围需求。</p><p>多轮互动无缝衔接：支持多批次游戏功能，一局结束后可快速开启下一局，持续带动现场热度。</p><p>抽奖规则灵活配置：后台可自由选择是否开启抽奖功能，奖品涵盖实物、微信卡券、红包、微擎积分 / 余额等，支持自定义奖品数量与中奖概率。</p><p>中奖限制更合理：可设置每人最高中奖次数及红包总额上限，避免重复中奖，保障活动公平性。</p><p>红包发放双模式：红包奖品支持直接发送与提现两种方式，满足大额红包奖励的发放需求。</p><p>参与条件可控：支持开启或关闭 “强制关注” 功能，助力公众号涨粉；自带 LBS 地区限制功能，可精准划定参与人群范围。</p><p>账号适配说明：仅支持认证服务号使用（红包功能需开通微信支付），非认证服务号可借用权限（不可使用卡券功能）。</p><p><strong>三、适用场景与行业价值</strong><br/>适用场景<br/>广泛适配年会、婚礼、酒吧、餐厅、KTV、线下活动、学校及企事业单位活动等场景，尤其针对人群聚集等待、需要活跃气氛的场景效果显著。</p><p>行业价值<br/>餐饮行业：解决高峰期客户排队无聊问题，通过抽奖发放优惠券、代金券，牢牢留住客户，促进二次到店消费。</p><p>活动策划行业（年会、婚礼、线下活动）：快速调动现场氛围，打破冷场尴尬，通过趣味互动增强参与者体验与记忆点。</p><p>本地自媒体：可拉取商家赞助开展活动，既能为粉丝提供福利，又能拓宽盈利渠道，提升账号活跃度。</p><p>微信运营服务提供商：为合作客户提供多样化互动解决方案，丰富服务内容，增强客户粘性。</p><p>酒吧、KTV 等娱乐场所：为消费者增添互动乐趣，延长停留时间，提升消费意愿，打造差异化经营优势。</p><p><strong>四、问答环节</strong><br/>系统支持哪些账号类型使用？红包功能有什么要求？<br/>答：仅支持认证服务号使用，红包功能需开通微信支付；非认证服务号可借用权限，但无法使用卡券功能。</p><p>奖品类型可以自定义吗？能否限制用户中奖次数？<br/>答：奖品支持实物、微信卡券、红包等多种类型，可自定义数量与概率；同时可设置每人最高中奖次数及红包总额上限。</p><p>如何防止非目标地区的用户参与活动？<br/>答：系统自带 LBS 限制地区功能，可在后台设置参与人的地区范围，精准锁定目标人群。</p><p>游戏结束后能否快速开启下一轮？<br/>答：支持多批次功能，一局结束后可立即启动下一局，无需重复设置，保障互动连续性。</p>]]></description></item><item>    <title><![CDATA[速码！TinyPro 移动端适配上线，打造桌面 - 掌心无差别体验 OpenTiny社区 ]]></title>    <link>https://segmentfault.com/a/1190000047559268</link>    <guid>https://segmentfault.com/a/1190000047559268</guid>    <pubDate>2026-01-22 18:11:00</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>本文由TinyPro贡献者王晨光同学原创。</p><h2>一、背景：让 TinyPro 真正“走到掌心里”</h2><p>TinyPro 是一套基于 <strong>TinyVue</strong> 打造的前后端分离后台管理系统，支持菜单配置、国际化、多页签、权限管理等丰富特性。<br/>TinyPro 在桌面端具备良好的体验和模块化架构，但随着移动办公、平板展示等场景增多，移动端体验的短板逐渐显现：</p><ul><li>页面缩放不均衡，布局出现溢出或错位；</li><li>模态框在小屏上遮挡内容；</li><li>图表和表格在横屏与竖屏间切换时无法自适应；</li><li>操作区过于密集，不符合触控习惯。</li></ul><p>为此启动了 <strong>TinyPro 移动端适配项目</strong>，目标是在不破坏现有结构的前提下，实现“<strong>一次开发，跨端流畅</strong>”的体验。</p><h2>二、技术选型与总体架构</h2><p>本次移动端适配要求在复杂的中后台系统中实现「一次开发，多端自适应」，既要保证样式灵活，又要维持可维护性和构建性能。</p><p>在技术选型阶段，综合评估了三种常见方案：</p><table><thead><tr><th>方案</th><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td>纯 CSS 媒体查询</td><td>简单直接、依赖少</td><td>样式分散、逻辑重复、维护困难</td></tr><tr><td>TailwindCSS 响应式类</td><td>社区成熟、类名直观、生态完善</td><td>样式表体积大、断点固定、不够灵活</td></tr><tr><td><strong>UnoCSS 原子化方案</strong></td><td>按需生成、性能极轻、断点与变体完全可定制</td><td>需要自行配置规范与规则体系</td></tr></tbody></table><p>最终选择了 <strong>UnoCSS + Less 的混合架构</strong>：</p><ul><li><strong>UnoCSS</strong>：负责通用布局、间距、排版等高频样式，原子化写法提升开发效率；</li><li><strong>Less 媒体查询</strong>：用于模态框、导航栏等复杂场景的精细控制；</li><li><strong>统一断点配置</strong>：集中管理屏幕尺寸分级，保持视觉一致性；</li><li><strong>自定义变体（<code>max-&lt;bp&gt;</code>）</strong>：支持“桌面端优先”策略，通过 max-width 实现移动端自适应，样式逻辑更直观。</li></ul><h3>UnoCSS：轻量、灵活、即时生成</h3><p>UnoCSS 是一个 <strong>按需生成的原子化 CSS 引擎</strong>，最大的特点是 <strong>零冗余与高度可定制</strong>。<br/>不同于 TailwindCSS 的预编译方式，UnoCSS 会在构建阶段根据实际使用的类名即时生成样式规则，从而显著提升构建性能与灵活性.</p><p>在配置中通过 <code>presetMini()</code> 与 <code>presetAttributify()</code> 组合使用，使开发者既可以写：</p><pre><code class="vue">&lt;div class="p-4 text-center bg-gray-100 max-md:p-2"&gt;&lt;/div&gt;</code></pre><p>也可以使用属性化语法：</p><pre><code class="vue">&lt;div p="4" text="center" bg="gray-100" max-md:p="2"&gt;&lt;/div&gt;</code></pre><p><code>presetMini</code> 提供轻量原子类体系，<code>presetAttributify</code> 则允许以声明式方式书写样式，更直观、组件化友好。</p><h3>断点配置与响应式策略</h3><p>TinyPro 的适配核心之一，是在 <code>uno.config.ts</code> 中建立统一的断点体系，并通过自定义 <code>max-&lt;bp&gt;</code> 前缀实现“桌面端优先”的响应式策略。</p><pre><code class="typescript">const breakpoints = {
  sm: '641px',     // 手机（小屏）
  md: '769px',     // 平板竖屏
  lg: '1025px',    // 平板横屏 / 小型笔电
  xl: '1367px',    // 常规笔电
  '2xl': '1441px', // 高清笔电
  '3xl': '1921px', // 桌面大屏
}</code></pre><p>并通过自定义 <code>variants</code> 扩展 <code>max-&lt;bp&gt;</code> 前缀:</p><pre><code class="typescript">variants: [
    (matcher) =&gt; {
      const match = matcher.match(/^max-([a-z0-9]+):/)
      if (match) {
        const bp = match[1]
        const value = breakpoints[bp]
        if (!value) return
        return {
          matcher: matcher.replace(`max-${bp}:`, ''),
          parent: `@media (max-width: ${value})`,
        }
      }
    },
  ]</code></pre><p>让开发者能自然地书写：</p><pre><code class="vue">&lt;div class="w-1/2 max-md:w-full"&gt;&lt;/div&gt;</code></pre><p>含义：</p><blockquote>默认宽度为 50%，在宽度小于 769px 的设备上改为 100%。</blockquote><p>TinyPro 采用「桌面端优先（max-width）」的布局策略：默认以桌面端布局为基础，在移动设备上再进行针对性优化。相比常见的「移动端优先（min-width）」方式，这种做法更符合中后台系统的特性，同时让 UnoCSS 的断点逻辑更直观，并确保主屏体验的稳定性。</p><h2>三、样式与编码策略</h2><ul><li><p><strong>优先级</strong></p><ul><li>简单场景：使用 UnoCSS 原子类。</li><li>复杂样式：使用 Less 媒体查询。</li></ul></li><li><p><strong>布局与滚动</strong></p><ul><li>首页及核心业务模块完成适配，小屏模式下侧边栏默认收起、导航栏折叠，确保主要内容可见。</li><li>页面主要容器避免横向滚动，必要时在小屏下开启局部横向滚动。</li><li>表格与大区块在不同断点下自动调整宽度、栅格与间距，小屏下支持横向滚动；分页与密度支持响应式控制。</li></ul><p><img width="723" height="368" referrerpolicy="no-referrer" src="/img/bVdnIuQ" alt="布局与滚动.gif" title="布局与滚动.gif"/></p></li><li><p><strong>图表自适应</strong></p><ul><li>图表组件接入 <code>resize</code> 监听，在侧边栏展开/收起、窗口缩放、语言切换等场景下保持自适应。</li><li>小屏下使用 <code>vw</code> 宽度与较小字号，保证图表展示效果与可读性。</li></ul><p><img width="723" height="368" referrerpolicy="no-referrer" src="/img/bVdnIuS" alt="图表自适应.gif" title="图表自适应.gif" loading="lazy"/></p></li><li><p><strong>表单与模态框</strong></p><ul><li>接入 <code>useResponsiveSize()</code>，控制弹窗在小屏下铺满显示，大屏保持固定宽度。</li><li>表单项在不同断点下动态调整排布与间距，优化触控体验。</li></ul><p><img width="723" height="368" referrerpolicy="no-referrer" src="/img/bVdnIuU" alt="表单与模态框.gif" title="表单与模态框.gif" loading="lazy"/></p></li><li><p><strong>导航与交互</strong></p><ul><li>小屏下隐藏导航栏非关键元素，操作聚合到"折叠菜单"。</li><li>移动端默认收起侧边菜单栏，提升主要内容展示区域。</li></ul><p><img width="723" height="368" referrerpolicy="no-referrer" src="/img/bVdnIuW" alt="导航与交互.gif" title="导航与交互.gif" loading="lazy"/></p></li><li><p><strong>性能优化</strong></p><ul><li>在 <code>responsive.ts</code> 中对 <code>resize</code> 事件处理增加节流机制，避免窗口缩放等场景下的频繁无效渲染。</li></ul></li></ul><h2>四、常用代码片段</h2><ol><li>基于栅格系统 + 响应式断点工具类，通过为 tiny-row 和 tiny-col 添加不同屏幕宽度下的样式规则，实现自适应布局：</li></ol><pre><code class="vue">&lt;tiny-layout&gt;
    &lt;tiny-row class="flex justify-center max-md:flex-wrap"&gt;
        &lt;tiny-col class="w-1/4 max-md:w-1/2 max-sm:w-full max-md:mb-4"&gt;···&lt;/tiny-col&gt;
        ···
        &lt;tiny-col class="w-1/4 max-md:w-1/2 max-sm:w-full max-md:mb-4"&gt;···&lt;/tiny-col&gt;
    &lt;/tiny-row&gt;
&lt;/tiny-layout&gt;
</code></pre><pre><code class="vue">&lt;div class="theme-line flex max-sm:grid max-sm:grid-cols-4 max-sm:gap-2"&gt;
  &lt;div···
  &lt;/div&gt;
&lt;/div&gt;</code></pre><ol start="2"><li>基于 响应式工具类 + 自定义响应式 Hook,解决(1)对话框宽度自适应;(2)表格尺寸和密度自适应;(3)逻辑层响应式控制</li></ol><pre><code class="vue">&lt;template&gt;
  &lt;section class="p-4 sm:p-6 lg:p-8 max-sm:text-center"&gt;
    &lt;tiny-dialog :width="modalSize"&gt;...&lt;/tiny-dialog&gt;
  &lt;/section&gt;
&lt;/template&gt;

&lt;script setup lang="ts"&gt;
import { useResponsiveSize } from '@/hooks/responsive'
const { modalSize } = useResponsiveSize() // 小屏 100%，大屏 768px
&lt;/script&gt;</code></pre><pre><code class="vue">&lt;template&gt;
  &lt;div class="container"&gt;
    &lt;tiny-grid ref="grid" :fetch-data="fetchDataOption" :pager="pagerConfig" :size="gridSize" :auto-resize="true" align="center"&gt;
      ···
    &lt;/tiny-grid&gt;
  &lt;/div&gt;
&lt;/template&gt;

&lt;script setup lang="ts"&gt;
import { useResponsiveSize } from '@/hooks/responsive'
const { gridSize } = useResponsiveSize() // 小屏为mini grid，大屏为medium grid
&lt;/script&gt;</code></pre><ol start="3"><li>通过 <code>useResponsive</code> 获取屏幕断点状态 <code>sm/md/lg</code>，如：在模板中结合 <code>v-if="!lg"</code> 控制分隔线的渲染，从而实现了小屏下纵向菜单才显示分隔线的效果</li></ol><pre><code class="vue">&lt;template&gt;
  &lt;ul class="right-side" :class="{ open: menuOpen }"&gt;
    &lt;!-- 小屏下才显示分隔线 --&gt;
    &lt;li v-if="!lg"&gt;
      &lt;div class="divider"&gt;&lt;/div&gt;
    &lt;/li&gt;
    ···
  &lt;/ul&gt;
&lt;/template&gt;

&lt;script lang="ts" setup&gt;
import { useResponsive } from '@/hooks/responsive'
const { lg } = useResponsive()
&lt;/script&gt;</code></pre><h2>五、结语</h2><p>通过本次移动端适配， TinyPro 实现了“从桌面到掌心”的统一体验：<br/>开发者可以继续沿用熟悉的组件体系与布局方式，同时享受 UnoCSS 带来的原子化灵活性与性能优势。在不改变核心架构的前提下，TinyPro 变得更轻盈、更顺滑，也更符合移动时代的使用场景。</p><h2>关于OpenTiny</h2><p>欢迎加入 OpenTiny 开源社区。添加微信小助手：opentiny-official 一起参与交流前端技术～  <br/>OpenTiny 官网：<a href="https://link.segmentfault.com/?enc=v8iQxFa098cN4sPnkTOqSw%3D%3D.HCNczvaAlL3fp%2F%2BPXS0TLHzZdmuJ1ltlKZE8zHRQhtg%3D" rel="nofollow" target="_blank">https://opentiny.design</a>  <br/>OpenTiny 代码仓库：<a href="https://link.segmentfault.com/?enc=PpWg9iPOoJuhbbf7JuYadw%3D%3D.t7pHMeicGPvcO9D6K%2FzCWxMEkIVUBpHKr7GX6D82B2o%3D" rel="nofollow" target="_blank">https://github.com/opentiny</a>  <br/>TinyPro源码：<a href="https://link.segmentfault.com/?enc=hZ81xEE6B6ICSqKo4kyOFA%3D%3D.KBhtdgjyn%2FNvxXf8%2FVYAWT7seX%2BEuZFw69LvmBucHJK3FaKnKAT7jEupDMQvPnOZ" rel="nofollow" target="_blank">https://github.com/opentiny/tiny-pro</a></p><p>欢迎进入代码仓库 Star🌟TinyPro、TinyEngine、TinyVue、TinyNG、TinyCLI、TinyEditor<br/>如果你也想要共建，可以进入代码仓库，找到 good first issue标签，一起参与开源贡献\~</p>]]></description></item><item>    <title><![CDATA[教程上新｜GLM-Image基于自回归+扩散解码器混合架构，精准理解指令写对文字 OpenBayes]]></title>    <link>https://segmentfault.com/a/1190000047559275</link>    <guid>https://segmentfault.com/a/1190000047559275</guid>    <pubDate>2026-01-22 18:10:18</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在图像生成领域，扩散模型因其训练稳定和泛化能力强已逐渐走入主流行列。然而，<strong>面对海报、PPT、科普图等需要准确传达复杂信息的「知识密集型」场景时，传统模型存在指令理解与细节刻画难以兼顾的短板。</strong> 另一个长期存在的问题是生成图像中的文字经常出现笔画错误或难以辨识，严重影响实用价值。</p><p>基于此，<strong>智谱</strong> <strong>于 2026 年 1 月联合华为开源了新一代图像生成模型 GLM-Image。</strong> 该模型基于昇腾 Atlas 800T A2 和昇思 MindSpore AI 框架完成全流程训练。<strong>其核心特点是采用了创新的 「自回归+扩散解码器」混合架构（9B 自回归模型 + 7B DiT 解码器），</strong> 将语言模型的深度理解能力与扩散模型的高质量生成能力相结合。</p><p>此外，模型通过改进 Tokenizer 策略，原生支持从1024×1024 到 2048×2048 的任意比例图像生成，无需重新训练。GLM-Image 的创新性还体现在以下两个方面：</p><p>*<strong>解决文字渲染难题：</strong> 在 CVTG-2K 和 LongText-Bench 权威评测中，其文字准确率等关键指标均位列开源模型第一，显著提升了图像中文字的生成准确性。</p><p>*<strong>定义高性价比应用：</strong> 在 API 调用模式下，生成单张图片的成本仅需 0.1 元，成本仅为主流闭源模型的 1/10 至 1/3，为商业化应用提供了高性价比选择。</p><p>目前，<strong>「GLM-Image：首个全流程国产芯片训练模型」已上线 OpenBayes 官网的教程版块，</strong> 快来输出无限创意吧！</p><p><strong>教程链接：</strong></p><p><strong><a href="https://link.segmentfault.com/?enc=eCKbypcPQnaIQykPWtJoyw%3D%3D.VwDjXXoZiVHZINKTthyKGaKkk7kS9BcedwdNlCBdsI0%3D" rel="nofollow" target="_blank">https://go.openbayes.com/lhlvw</a></strong></p><p><strong>Demo 运行</strong></p><p><strong>01</strong></p><p><strong>Demo 运行阶段</strong></p><p>1.登录 OpenBayes.com，在「公共教程」页面，选择「GLM-Image：首个全流程国产芯片训练模型」教程。</p><p><img width="723" height="472" referrerpolicy="no-referrer" src="/img/bVdnIuP" alt="" title=""/></p><p>2.页面跳转后，点击右上角「克隆」，将该教程克隆至自己的容器中。</p><p><img width="723" height="473" referrerpolicy="no-referrer" src="/img/bVdnIuR" alt="" title="" loading="lazy"/></p><p>3.选择「NVIDIA RTX PRO 6000 Blackwell Server Edition」以及「PyTorch」镜像，按照需求选择「按量付费」或「包日/周/月」，点击「继续执行」。新用户使用下方邀请链接注册，可获得 4 小时 RTX 5090 + 5 小时 CPU 的免费时长！</p><p>小贝总专属邀请链接（直接复制到浏览器打开）：</p><p><strong><a href="https://link.segmentfault.com/?enc=Tu%2B6mO71x8xfKOeG1BQneg%3D%3D.QkGoN1XH4UPRW1bs%2BNkXNEUgiLZSQ%2BrfwdiMkZ02Vys%3D" rel="nofollow" target="_blank">https://go.openbayes.com/9S6D</a></strong> <strong>r</strong></p><p><img width="723" height="473" referrerpolicy="no-referrer" src="/img/bVdnIuV" alt="" title="" loading="lazy"/><br/><img width="723" height="473" referrerpolicy="no-referrer" src="/img/bVdnIuY" alt="" title="" loading="lazy"/></p><p>4.等待分配资源，当状态变为「运行中」后，点击「打开工作空间」进入 Jupyter Workspace。</p><p><img width="723" height="472" referrerpolicy="no-referrer" src="/img/bVdnIuZ" alt="" title="" loading="lazy"/></p><p><strong>02</strong></p><p><strong>效果演示</strong></p><p>页面跳转后，点击左侧 README 页面，进入后点击上方「运行」。</p><p><img width="723" height="472" referrerpolicy="no-referrer" src="/img/bVdnIu1" alt="" title="" loading="lazy"/><br/><img width="723" height="472" referrerpolicy="no-referrer" src="/img/bVdnIu4" alt="" title="" loading="lazy"/></p><p>待运行完成，即可点击右侧 API 地址跳转至 demo 页面。</p><p><img width="723" height="468" referrerpolicy="no-referrer" src="/img/bVdnIu5" alt="" title="" loading="lazy"/><br/><img width="723" height="398" referrerpolicy="no-referrer" src="/img/bVdnIu6" alt="" title="" loading="lazy"/></p><p><strong>教程链接：</strong></p><p><strong><a href="https://link.segmentfault.com/?enc=ShAqY%2BDq%2BRfWesvY6YaSEw%3D%3D.6sNidWtpipGBeqNVXz6rZeGB1oAfkGLGV3s3EHs%2FRYM%3D" rel="nofollow" target="_blank">https://go.openbayes.com/lhlvw</a></strong></p>]]></description></item><item>    <title><![CDATA[数据接入提效 90%，存储成本降 70%，京能集团用 TDengine 实现储能数据毫秒级响应 TD]]></title>    <link>https://segmentfault.com/a/1190000047559293</link>    <guid>https://segmentfault.com/a/1190000047559293</guid>    <pubDate>2026-01-22 18:09:22</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><strong>小T导读</strong>：京能集团在储能安全管理平台中采用 <a href="https://link.segmentfault.com/?enc=HLgi6kdCHPiKCzq1SP2p7A%3D%3D.Zou%2FccBbtew7Q%2BMxd8ts0k6%2ByuWOVdnCeFirkdLQT%2F1YoHqxVT7y973NHUhBMNtMHLV9tD0TWvPDEVtyGas71WmAgGO6Beu%2F8FCPxeO8OX%2FiFM5lPpwvWiZXnxmmt9L3SF%2FpM%2BYcsSnZ1WARmbFj1dgJERKampt%2BQWmSzGZOdQo%2FWPA9SQu%2B7yIs57eALc8WGXdyJl%2BJXWGSFl12T7dK%2FA%3D%3D" rel="nofollow" target="_blank">TDengine TSDB</a> 作为底层时序数据库。依托 TDengine 企业版的零代码数据写入平台，来自全国 28 家电化学储能电站的数据能够按照统一编码规则高效接入 TDengine 时序数据库中，实现了稳定、高性能的数据采集与管理。在此基础上，借助 TDengine TSDB Flink Connector，系统可快速、稳定地从数据库中读取海量数据，开展实时分析与智能处理，充分释放数据的潜在价值。本文将结合该项目的实践过程，为大家带来深入分享与参考。</p><h2>项目背景</h2><p>京能集团储能安全管理平台共接入全国 28 家电化学储能电站，<strong>累计测点达 270 万个</strong>，由四个平台公司分别负责数据传输与汇聚。系统需要支撑大规模的数据统计分析、事件报警与安全预警，对底层数据库的性能与稳定性提出了极高要求。</p><p>鉴于电化学储能项目采集点数量庞大（270 万点）、锂电池热失控的超前预警技术复杂等因素，传统关系型数据库已无法满足高并发写入与海量数据存储的需求。由于这些数据具备<strong>时间序列写入、格式固定、写入量巨大</strong>等典型特征，我们最终选择采用时序数据库作为系统核心数据底座。</p><h2>应用实际落地</h2><p>在充分调研国内多款时序数据库产品后，我们发现，从国内目前的实际情况分析，<a href="https://link.segmentfault.com/?enc=26NMUiV753pDqAKXYcJisw%3D%3D.b2EOzHa%2FB0BXO%2BJBVDZm1XUWv26%2BxGkMoTi3WnPN79zxEt8NPbEbIwwSB3sU6dE4iMUdYDdgycV5DcdSHqLQ%2FN1SHxzeGv%2BuGykhb0557LgvAg6PEOnCifTdEnFKdspzBq2k9m9sPTrdrXy%2BMyZ2S0Wswj7uebR0y%2Fi00IoXHArk9t0z8bALI2RCUpq8W3vv%2FT9mQFBb%2FMq5Log5FXhcSQ%3D%3D" rel="nofollow" target="_blank">TDengine TSDB</a> 已成为众多企业在海量数据高速存储、处理与调用场景中的首选方案。基于其成熟的技术体系与稳定的性能表现，我们最终选定 <a href="https://link.segmentfault.com/?enc=F%2B3EK1ks4OtY1cdL8RfQ0A%3D%3D.i7hQROk7z%2BoMI6EH3YbexXchkuMTyPrIqRB%2BTTULTXJ7zMgiObhML6yBjWuk5jxhhrG7VzY5JYct3NgFzZORFvedbfj%2B6V5KWYH0tqGycsw%2BuJIcSwdKEHwRxomDqkSumWlaZnKj2EnCbjTK%2FC11Wev75Jrzq8XSntEN1BsehXms8qtmQqePUEZwodIDNGrWtWatloPbMP7XMIDeuFA71A%3D%3D" rel="nofollow" target="_blank">TDengine TSDB</a> 作为平台的底层时序数据库，并结合 Kafka 与 Flink 构建了完整的数据流处理体系，实现了数据的高效传输与实时计算，顺利达成项目预期目标。以下是架构简图：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559295" alt="" title=""/></p><h3>TDengine TSDB 支持多种写入方式</h3><ol><li>SQL 语言写入 ：<a href="https://link.segmentfault.com/?enc=fIbzymT2UZP1z50Xfe1ArQ%3D%3D.uPC8xZtkj%2Bmyzb5z9tDQDz1jDdCA4Xymoo0X06MQ3pKy%2F%2Fz480q2C3xrspoq0Z9l" rel="nofollow" target="_blank">https://docs.taosdata.com/basic/insert/</a></li><li>无模式写入：<a href="https://link.segmentfault.com/?enc=NQP2qzPfojjELybKmCfG9A%3D%3D.YaQkf1t2ARV3zBNNmQY%2BCBuAv0gg6o1F%2Fy74uXSNujLq7ib4CAfDe9HIRItdP8tk" rel="nofollow" target="_blank">https://docs.taosdata.com/develop/schemaless/</a></li><li>参数绑定方式：<a href="https://link.segmentfault.com/?enc=YW83mxdvDpeoO1xbbOoJGg%3D%3D.P1jktO5qHucGq9IV%2B15KOqGFCZNENRw2k%2FtaHeT63gXHIVaF%2Fleo6X4pP0qcSu8B" rel="nofollow" target="_blank">https://docs.taosdata.com/develop/stmt/</a></li><li>企业版的零代码数据写入— taosExplorer 数据接入功能：<a href="https://link.segmentfault.com/?enc=AHMDytYFB0tKVgZpMpDCNw%3D%3D.tggt2Fck10u2rp0WHWSjQscgZTzi%2FW%2FbQ0x%2FuwY5nsbNkea8rzL%2FFu4hPsq0nFz8" rel="nofollow" target="_blank">https://docs.taosdata.com/advanced/data-in/</a></li></ol><p>项目中涉及多个 Kafka 集群、数十个需要接入的 topic。我们重点采用了 <a href="https://link.segmentfault.com/?enc=ihtn8uz2UqNIYDk81bbROQ%3D%3D.o%2BA4LK8ICjxcCpDFZLpGZ%2F5PQy6Jwp7h40kUZq5PXAXn7uPKaHB9JmSjG30Cscro%2FBHbZ%2F9AXvzdhfVG1q95w1o6hLBNmcf0Vwd7HW4P2Z8xzlBhc88F%2BNgNBy8pLCseiUTSs0zH8EcLCSgW0lo9SoannKmN4s8oOBcQWC%2B%2BGD9lNvbC5xPzEU74dGcjXMyxsf4DKdHsDPkZJnROfhE8YNmFJvwq65PWdGocUYWXXc0%3D" rel="nofollow" target="_blank">TDengine</a> 企业版的零代码数据写入能力，实现了从 Kafka 到 <a href="https://link.segmentfault.com/?enc=LA0XiIxywrkhgMTI%2B7PSAA%3D%3D.oAZFWYfTtE9xjSRFeB3VxuUuqmQovUHltZvt0weNAO%2BD4r%2BoWTz7sMYQBeOUzejD%2FhcZk%2BmJMdUSY55wEWeSi2GAWDCKCS0x64j34p8uS9rKhH1aoaejjB9MQJ71SAJChgIX18o%2FkZ8Agdci6xQ%2BetGqkQKYpUU7tMbanYE%2FwAryoF58P6KNDLdqqpjdc5vD2zX7GYjMJ94v331VmTv2bnmMAwQ6HrYIpkmI2yhpwG4%3D" rel="nofollow" target="_blank">TDengine TSDB</a> 的高效对接。该功能支持灵活配置类似 ETL 的复杂自定义选项，极大简化了数据接入流程和时间，而且数据接入性能完全达到了项目要求。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559296" alt="" title="" loading="lazy"/></p><p>为了保证数据的合理性，我们出台了《京能集团电化学储能电站安全管理平台和储能电站设备标识编码规则》，通过标准的 kks 编码在 taosX 对 Kafka 数据进行了有效过滤和清理，最终写入 TDengine TSDB。kks 部分编码实例如下：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559297" alt="" title="" loading="lazy"/></p><p>下图为数据过滤、转换等规则设置：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559298" alt="" title="" loading="lazy"/></p><p>此外，taosX 数据接入还支持多节点高可用配置。只需在多台 taosX 上部署相同的 Kafka 数据接入任务，并设置相同的 groupId，即可自动实现任务高可用，确保数据接入的连续性与稳定性。</p><p>同时，<a href="https://link.segmentfault.com/?enc=5DE80WmNlFuE52O03vLXfg%3D%3D.lNV8ufGwzN%2B3B23NpFI43xe1hOlBXksspDfv7pDoAuNiv7KL63gBswTw0Dxf7leInBYui1XfU3bH%2F1NxjwJ5L9XwMFLTKkhdeFcBmXxdulx6VMK1g51bo0oeDGuP%2B3narbJkeIgKUhdCaNsxMqMs2bE%2BH0psqX4Yug02Ys90nItPvgv5YYAABDE6%2BvUkdN4tjP6fRoptkvp0DEszd4lahzv2vJ4KO%2BkUjNat1l8VUgQ%3D" rel="nofollow" target="_blank">TDengine</a> 还提供完善的 taosX 任务监控机制，可直接通过 Grafana 一键配置，快速生成可视化监控图表：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559299" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559300" alt="" title="" loading="lazy"/></p><h3>超级表 + 子表的使用</h3><p><a href="https://link.segmentfault.com/?enc=wMPjhTSVHcO1%2Bpklj7Hoog%3D%3D.os09UxCuJlgjNV35XoSg6z6v4%2FkDMOeUq6Nb1jMiJs0iADEZ0RpZMzgBZaMuCHI5rXCdz3s6e%2BzwJDW0X9LZm7woN1uLKmrnT2fsOf8wyPPxW%2FAOXoTyNUadrOSJ3uzFirbE4T70NiKhCtvFQVD2EtGETUXEAozaFjwzLZGiBj9ZWgiv%2BU0K6TbFZiySaw9%2Fmw2q06mkt7erAFeEpllwaPI%2BU1b72Qg%2BO9QHv%2FZCtuk%3D" rel="nofollow" target="_blank">TDengine TSDB</a> 结合“一个数据采集点一张表”的设计理念，引入了具有创新性的“超级表”机制，从根本上解决了大规模时序数据结构不统一、聚合困难、运维复杂等问题。每个采集点的数据独立存储，天然具备写入无锁、数据顺序追加、块状连续存储等优势。这种设计方式不仅提升了写入与查询性能，还带来了极高的数据压缩效率。</p><p><a href="https://link.segmentfault.com/?enc=bhuhQGm85VQ7Ti%2Fg2l6ZOQ%3D%3D.Gu5Rb1I9QsvPEwUC0N%2BXtaMFS%2BDGbnNlUoEHyv1Dee4mEBdUpeBE9C9N6ch%2BdVd14HCfnD%2BsRwo34Cd7P02xYAvfUMDxtnUwQqpI1N65M4AuDuGk5p2Ulh7wNGzRQzxvznDLtbOn26%2B5BSzW6GCq0NTzg85aCrw3y4TqURKpsnhiP06OvyqMW2aYA7cLg7PfmPqdRAQRMw7sw49%2BCjH9JNKI%2FYXIcMtzQppQUAXuShE%3D" rel="nofollow" target="_blank">TDengine TSDB</a> 支持对超级表标签进行动态的添加、修改与删除操作，满足设备属性变更、系统扩展等业务需求。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559301" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559302" alt="" title="" loading="lazy"/></p><h3>计算、分析处理</h3><p>在 Flink 计算平台上，我们借助 TDengine TSDB 企业版提供的 <strong>Flink 连接器</strong>——TDengine TSDB Flink Connector（<a href="https://link.segmentfault.com/?enc=gc%2FixpyDesB%2BMbyhQ0Tlcw%3D%3D.ir8Kw3jEYq5ym5iZpN0uDr1Vz1AQzsRCXytsgFDN21yJ7HnhYYKiVPc1ceqtEfNPPu722Wmm65ZSsmwJBYLTlw%3D%3D" rel="nofollow" target="_blank">https://docs.taosdata.com/advanced/data-publisher/Flink/</a>），实现了与 TDengine TSDB 的无缝集成。该连接器可高效、稳定地从 TDengine TSDB 中读取海量时序数据，并在此基础上进行全面、深入的分析处理，充分挖掘数据的潜在价值，极大地提升数据处理的效率和质量。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559303" alt="" title="" loading="lazy"/></p><p>Flink CDC 主要用于提供数据订阅功能，能实时监控 TDengine TSDB 数据库的数据变化，并将这些变更以数据流形式传输到 Flink 中进行处理，同时确保数据的一致性和完整性。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559304" alt="" title="" loading="lazy"/></p><h3>落地效果</h3><ol><li><strong>数据接入便利性</strong>：目前我们已接入 20 多个 kafka 数据，后期还会继续增加。得益于 TDengine 企业版零代码数据接入能力，新增任务仅需复制并做少量参数调整即可完成，操作简便高效，<strong>整体接入过程较传统方式节省约 90% 的时间成本</strong>。</li><li><strong>数据查询性能高</strong>：开启数据库缓存功能后，能够实时获取每个设备点位最新值，<strong>毫秒级别即可返回结果</strong>。</li><li><strong>数据存储成本低</strong>：TDengine TSDB 具备出色的数据压缩能力，其二级压缩技术将数据视作无差别的二进制块进行再次压缩。与一级压缩相比，二级压缩的侧重点在于消除数据块之间的信息冗余。目前我们提供的服务器存储远远满足我们项目规划的 5 年数据存储，<strong>存储成本估算节省至少 60-70%</strong>。</li><li><strong>实时订阅</strong>：通过 TDengine 提供的 Flink CDC 实时订阅功能，能方便、高效的进行分析、告警等处理，给我们后期分析带来了极大的便利性。</li></ol><h2>后期规划</h2><p>目前，我们正在对京能集团储能安全管理平台已经接入的 28 场站数据进行分析和优化，提高数据采集的可靠性和鲁棒性。未来我们会针对 TDengine TSDB 新版本和新功能进行持续跟踪，进一步开发 TDengine TSDB 的内在潜力和各种有效的功能。</p><p>近期我们关注到 TDengine 发布了新产品 TDengine IDMP，通过经典的树状层次结构组织传感器、设备采集的数据，建立数据目录，对数据提供情境化、标准化的处理，并提供实时分析、可视化等功能，接下来我们会进一步了解此产品在我们业务中的使用可能。</p><h2>关于京能集团</h2><p>北京能源集团有限责任公司是北京市人民政府出资设立的国有独资公司，肩负着保障首都北京能源安全可靠供应的重任。京能集团成立于 2004 年，由原北京国际电力开发投资公司和原北京市综合投资公司合并而成，2011 年、2014 年先后又与北京市热力集团有限责任公司、北京京煤集团有限责任公司实施合并重组，实现了产业链条融合互补。经过多年的资源整合，集团由单一能源产业发展为热力、电力、煤炭、健康文旅等多业态产业格局。2024 年在中国企业 500 强排名第 247 位，中国服务企业 500 强排名第 87 位。</p><p>作者：张海增</p>]]></description></item><item>    <title><![CDATA[服务器数据恢复—服务器挂载失败！存储映射卷数据丢失，精准修复保住核心资产 北亚数据恢复 ]]></title>    <link>https://segmentfault.com/a/1190000047559343</link>    <guid>https://segmentfault.com/a/1190000047559343</guid>    <pubDate>2026-01-22 18:08:22</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><strong>服务器存储数据恢复环境：</strong><br/>某品牌服务器存储上有16块FC硬盘，存储设备前面板的10号硬盘指示灯和13号硬盘指示灯亮黄灯，存储设备映射到服务器redhat linux系统上的卷无法挂载，业务中断。</p><p><strong>服务器存储数据恢复过程：</strong><br/>1、通过存储设备厂商的管理程序storage manager连接到服务器存储上查看当前存储状态，逻辑卷状态failed。查看物理磁盘状态，6号盘报告“警告”，10号和13号盘报告“失败”。<br/>通过storage manager将故障存储的完整日志状态备份，解析备份出来的存储日志获取逻辑卷结构的部分信息。<br/>2、北亚企安数据恢复工程师将故障存储中16块FC盘做好标记后，从存储设备中取出。使用专业镜像设备对16块FC盘进行初步测试。经过测试发现16块盘均能正常识别。分别检测16块盘的SMART状态，结果6号盘的SMART状态为“警告”，和storage manager中的报告一致。<br/>3、北亚企安数据恢复工程师在windows环境下将识别出来的FC盘在磁盘管理器中标记为脱机状态，然后对原始磁盘进行扇区级别完整镜像。将原始磁盘中的所有物理扇区镜像到windows系统下的逻辑磁盘并以文件形式保存。<br/>在镜像过程中服务器数据恢复工程师发现6号磁盘的镜像速度极慢，结合先前检测结果综合判断，6号盘应该存在大量损坏以及不稳定扇区，导致windows环境下的一些软件无法对其进行操作。<br/>4、使用专业镜像设备对6号硬盘进行坏道镜像操作，在镜像过程中观察镜像的速度和稳定性。在镜像过程中发现6号盘上的坏道并不多，但是存在大量读取响应时间长的不稳定扇区。于是服务器数据恢复工程师调整6号盘的拷贝策略，将“遇到坏道跳过扇区数”和“响应等待时间”等参数作一些调整后继续对6号盘进行镜像操作。同时观察剩余盘在windows环境下镜像的情况。<br/>5、镜像完成后查看日志，发现在storage manager和SMART状态中均没有报错的1号盘也存在坏道，10号和13号盘均存在大量不规则的坏道分布。<br/>根据坏道列表使用工具定位到目标镜像文件进行分析后发现，ext3文件系统的一些关键源数据信息被坏道破坏。只能等6号盘镜像完毕后，通过同一条带进行xor以及根据文件系统上下文关系手动修复被损坏的文件系统。<br/>6、6号盘镜像完成，但是为了最大限度做出有效扇区和保护磁头所设置的拷贝策略，会让这次完成的镜像在镜像过程中自动跳过一些不稳定扇区，所以现在的镜像是不完整的。于是服务器数据恢复工程师调整拷贝策略，继续镜像被跳过的扇区，直到6号盘所有扇区全部镜像完成。<br/>7、所有硬盘镜像完成后，基于镜像文件分析所有硬盘底层数据。根据北亚企安数据恢复工程师对ext3文件系统的逆向研究和对日志文件的分析，获取到16块FC盘的盘序、RAID块大小、RAID的校验走向和方式等重组RAID的必要信息，根据获取到的信息虚拟重组RAID。RAID搭建完成后进一步解析ext3文件系统。<br/>8、和用户方沟通后提取出一些oracle数据库的dmp文件，用户方尝试通过dmp文件恢复数据库。<br/>在dmp恢复的过程中，oracle数据库报告imp-0008错误。北亚数据恢复中心的oracle数据库工程师分析导入dmp文件的日志文件后，发现恢复的dmp文件存在问题，从而导致dmp导入数据失败。<br/>9、服务器数据恢复工程师重新分析raid结构，进一步确定ext3文件系统被破坏的程度，重新恢复dmp文件和dbf原始库文件。<br/>10、将恢复出来的dmp文件移交给用户方进行数据导入测试，这次测试顺利，没有发现问题。对恢复出来的dbf原始库文件进行校验检测，所有文件均能通过测试。<br/>11、数据库工程师到达现场，和用户沟通后决定使用恢复出来的dbf原始库文件进行操作，以确保把数据恢复到最佳状态。</p><p><strong>oracle数据库恢复过程：</strong><br/>1、拷贝数据库文件到原数据库服务器作为备份，备份文件所在文件夹路径为/home/oracle/tmp/syntong。在根目录下创建一个名为“oradata”的目录，把syntong文件夹拷贝到oradata目录下。更改oradata文件夹及其所有文件的属组和权限。<br/>2、备份原数据库环境，包括ORACLE_HOME下product文件夹下的相关文件。配置监听，使用原机中的splplus连接到数据库，尝试启动数据库到nomount状态。进行基本状态查询后，了解到环境和参数文件没有问题。 尝试启动数据库到mount状态，进行状态查询没有发现问题。当启动数据库到open状态，出现报错：<br/>ORA-01122: database file 1 failed verification check<br/>ORA-01110: data file 1: '/oradata/syntong/system01.dbf'<br/>ORA-01207: file is more recent than control file - old control file<br/>经过进一步的检测和分析，判断此故障为控制文件和数据文件信息不一致，这是一类常因断电或突然关机引发的故障。<br/>3、对数据库文件进行逐个检测，检测到所有数据文件都不存在物理损毁的情况。<br/>4、在mount状态下，对控制文件进行备份。alter database backup controlfile to trace as ' /backup/controlfile'。对备份的控制文件进行查看修改，取得其中的重建控制文件命令。把这些命令复制到一个新建脚本文件controlfile.sql中。<br/>5、关闭数据库，删除/oradata/syntong/下的3个控制文件。 启动数据库到nomount状态，执行controlfile.sql 脚本。<br/>SQL&gt;startup nomount<br/>SQL&gt;@controlfile.sql<br/>6、完成重建控制文件后，启动数据库报错，需要做进一步处理。<br/>SQL&gt; alter database open<br/>alter database open<br/>*<br/>ERROR at line 1:<br/>ORA-01113: file 1 needs media recovery<br/>ORA-01110: data file 1: '/free/oracle/oradata/orcl/system01.dbf'<br/>然后执行恢复命令：<br/>recover database using backup controlfile until cancel<br/>Recovery of Online Redo Log: Thread 1 Group 1 Seq 22 Reading mem 0<br/>Mem# 0 errs 0: /free/oracle/oradata/orcl/redo01.log<br/>…<br/>做介质恢复，直到返回报告，恢复完成。<br/>7、尝试open数据库。<br/>SQL&gt; alter database open resetlogs<br/>8、成功启动数据库。把原来temp表空间的数据文件加入到对应的temp表空间中。<br/>9、对数据库进行各种常规检查，没有发现任何错误。<br/>10、进行emp备份。全库备份完成也没有报错。将应用程序连接到数据库，进行应用层面的数据验证。经过验证没有发现问题。本次数据恢复工作完成。</p>]]></description></item><item>    <title><![CDATA[2026 CRM 厂商对比：6 大客户管理系统核心能力横向对比（选型必看） 率性的开水瓶 ]]></title>    <link>https://segmentfault.com/a/1190000047559388</link>    <guid>https://segmentfault.com/a/1190000047559388</guid>    <pubDate>2026-01-22 18:07:28</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在企业数字化转型中，<strong>CRM</strong> <strong>系统</strong>是连接“客户-销售-服务”的核心枢纽。从线索获取到商机转化，从自动化流程到数据决策，不同品牌的CRM在核心能力上的差异，直接决定了企业能否“用对工具、提效增收”。</p><p>本文基于<strong>超兔一体云、Salesforce、SuiteCRM、Freshsales、红圈</strong> <strong>CRM</strong> <strong>、六度人和（</strong> <strong>EC</strong> <strong><em/></strong>SCRM<strong> </strong>）的公开能力素材，从线索与商机管理、自动化能力、报表能力、审批能力、可配置性<strong>五大维度展开深度对比，结合</strong>表格、流程图、脑图、雷达图**直观呈现差异，为企业选型提供参考。</p><h2>一、对比框架与核心逻辑</h2><p>本次对比围绕“<strong>企业实际业务需求</strong>”设计维度，重点回答以下问题：</p><ul><li>能否覆盖从“线索→客户→商机→订单”的全流程？</li><li>能否通过自动化减少重复劳动？</li><li>能否通过数据报表支撑决策？</li><li>能否适配企业的个性化流程（如审批、字段）？</li><li>能否匹配企业的规模与行业特性？</li></ul><h2>二、核心能力横向对比</h2><h3>（一）维度1：线索与商机管理——从“获客”到“转化”的全流程覆盖</h3><p>线索与商机是销售的“源头活水”，核心评价标准是<strong>流程完整性、AI辅助能力、自定义适配性</strong>。</p><h4>各品牌表现拆解</h4><table><thead><tr><th>品牌</th><th>核心优势</th><th>具体能力</th></tr></thead><tbody><tr><td><strong>超兔一体云</strong></td><td>多渠道获客+“三一客”小单快转模型</td><td>1. 覆盖百度、抖音、微信、地推等10+线索来源； 2. 三一客模型（定人、定时、定动作）推进小单转化； 3. 自动计算市场活动ROI（成本均摊到线索/签约）。</td></tr><tr><td><strong>Salesforce</strong></td><td>AI预测+全流程自动化流转</td><td>1. Einstein AI预测商机赢单概率（准确率达85%+）； 2. Lead→Opportunity自动关联客户/联系人； 3. 产品/价格簿深度整合（支持复杂报价）。</td></tr><tr><td><strong>SuiteCRM</strong></td><td>开源自定义流程</td><td>1. 支持线索→客户→商机的全流程自定义（字段、布局、节点）； 2. 适配企业独特业务逻辑（如制造业的“线索→经销商→商机”）。</td></tr><tr><td><strong>Freshsales</strong></td><td>AI线索评分+行为跟踪</td><td>1. AI线索评分（基于邮件打开、页面访问等行为）； 2. 自动触发邮件序列（如未打开邮件3天后重发）； 3. 客户行为 timeline 可视化。</td></tr><tr><td><strong>红圈</strong> <strong>CRM</strong></td><td>全流程覆盖+公海池管理</td><td>1. 覆盖“线索→客户→商机→回款”全链路； 2. 公海池解决线索分散问题（未跟进线索自动回收再分配）； 3. 适配工程行业的“项目型商机”。</td></tr><tr><td><strong>六度人和</strong></td><td>社交渠道整合+AI商机助手</td><td>1. 整合微信、QQ、企业微信等社交线索（占比80%+）； 2. AI商机助手自动总结客户需求（如微信聊天中的“价格咨询”）； 3. 跟踪客户社交行为（如打开朋友圈链接）。</td></tr></tbody></table><h4>流程可视化：超兔一体云“线索→商机”时序图</h4><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559390" alt="" title=""/></p><pre><code>sequenceDiagram
    participant 市场 as 市场渠道（百度/抖音/微信）
    participant 超兔 as 超兔一体云
    participant 销售 as 销售
    participant 客户 as 客户

    市场-&gt;&gt;超兔: 推送线索（手机号/IP/行为）
    超兔-&gt;&gt;超兔: 线索清洗（去重/归属地识别）
    超兔-&gt;&gt;销售: 分配通知（短信/APP）
    销售-&gt;&gt;超兔: 跟进记录（电话/拜访/微信）
    超兔-&gt;&gt;超兔: 三一客模型判定（是否合格）
    alt 合格
        超兔-&gt;&gt;超兔: 转化为商机（关联客户）
        销售-&gt;&gt;客户: 报价/演示
        客户-&gt;&gt;超兔: 确认订单
        超兔-&gt;&gt;超兔: 计算ROI（市场成本/签约额）
    else 不合格
        超兔-&gt;&gt;超兔: 移入线索池（需求培养）
        超兔-&gt;&gt;销售: 定期提醒复访
    end</code></pre><h3>（二）维度2：自动化能力——从“人工重复”到“智能执行”的效率跃迁</h3><p>自动化是CRM的“效率引擎”，核心评价标准是<strong>低代码</strong> <strong>/无代码能力、AI</strong> <strong>智能体</strong> <strong>、跨系统协同</strong>。</p><h4>各品牌表现拆解</h4><table><thead><tr><th>品牌</th><th>核心优势</th><th>具体能力</th></tr></thead><tbody><tr><td><strong>超兔一体云</strong></td><td>低代码工作流+AI智能体嵌入式应用</td><td>1. 自然语言AI生成工作流（如“新线索自动分配给区域销售”）； 2. AI智能体嵌入客户视图（自动生成跟单待办、日报）； 3. 订单自动化（锁库、生成采购单）。</td></tr><tr><td><strong>Salesforce</strong></td><td>低代码+AI代理+跨系统集成</td><td>1. Lightning低代码平台（拖拽式配置工作流）； 2. Agentforce AI代理（自动处理19万+潜在客户，节省50万+小时）； 3. MuleSoft集成ERP/供应链系统。</td></tr><tr><td><strong>SuiteCRM</strong></td><td>基础工作流引擎</td><td>1. 新线索自动分配给区域销售； 2. 任务到期自动提醒； 3. 需技术团队二次开发复杂流程（如售后工单派工）。</td></tr><tr><td><strong>Freshsales</strong></td><td>AI助手+邮件序列自动化</td><td>1. Freddy AI自动生成跟单待办（如“客户3天未回复，建议跟进”）； 2. 邮件序列（未打开邮件3天后重发，打开后触发跟进）； 3. 自动记录客户行为（如访问产品页面）。</td></tr><tr><td><strong>红圈</strong> <strong>CRM</strong></td><td>PaaS平台+行业定制流程</td><td>1. PaaS平台配置自动化（如“工程商机达标自动触发合同审批”）； 2. 适配工程行业的“项目进度→商机更新”流程； 3. 支持第三方系统集成（如ERP）。</td></tr><tr><td><strong>六度人和</strong></td><td>社交行为触发自动化</td><td>1. 客户打开微信链接→自动发跟进消息； 2. 客户未回复微信→3天后自动提醒销售； 3. 整合微信朋友圈广告线索→自动分配。</td></tr></tbody></table><h4>流程可视化：Salesforce“订单审批”自动化工作流</h4><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559391" alt="" title="" loading="lazy"/></p><pre><code>graph TD
    A[触发条件: 商机金额&gt;10万] --&gt; B{检查审批人权限}
    B --&gt;|是| C[发送通知（邮件/Slack）]
    B --&gt;|否| D[退回修改+原因提示]
    C --&gt; E[审批人审批]
    E --&gt;|通过| F[自动生成订单+锁库]
    E --&gt;|驳回| G[通知销售修改]
    F --&gt; H[同步至ERP]</code></pre><h3>（三）维度3：报表能力——从“数据”到“决策”的价值转化</h3><p>报表是CRM的“大脑”，核心评价标准是<strong>可视化能力、自定义深度、实时性</strong>。</p><h4>各品牌表现拆解</h4><table><thead><tr><th>品牌</th><th>核心优势</th><th>具体能力</th></tr></thead><tbody><tr><td><strong>超兔一体云</strong></td><td>多表聚合+实时工作台</td><td>1. 工作台数字卡片（实时显示线索量、商机转化率）； 2. 多表聚合分析（线索→商机→订单关联）； 3. 单日KPI引擎（销售今日需完成的线索跟进量）。</td></tr><tr><td><strong>Salesforce</strong></td><td>高级BI+权限管控</td><td>1. Tableau集成（高级可视化，如销售漏斗趋势）； 2. 动态仪表板（实时更新业绩、客户留存）； 3. 权限精细管控（如销售仅能看自己的客户数据）。</td></tr><tr><td><strong>SuiteCRM</strong></td><td>基础自定义报表</td><td>1. 支持线索、客户、商机的基础统计； 2. 自定义字段过滤（如“区域=华北”的线索量）； 3. 需二次开发复杂报表（如“项目成本分析”）。</td></tr><tr><td><strong>Freshsales</strong></td><td>智能绩效仪表盘</td><td>1. 团队业绩仪表盘（显示转化率、平均单客价）； 2. 客户旅程可视化（如“线索→商机→成交”的步骤）； 3. AI分析（如“高意向客户的共同特征”）。</td></tr><tr><td><strong>红圈</strong> <strong>CRM</strong></td><td>行业定制BI</td><td>1. 工程行业成本分析（项目成本→商机利润）； 2. 销售业绩对比（同比/环比）； 3. 实时动态建模（如“本月新签项目的区域分布”）。</td></tr><tr><td><strong>六度人和</strong></td><td>社交行为统计</td><td>1. 销售微信互动次数统计； 2. 客户响应率分析（如“微信消息的回复率”）； 3. 朋友圈广告线索转化率。</td></tr></tbody></table><h3>（四）维度4：审批能力——从“合规”到“高效”的流程管控</h3><p>审批是企业的“风险闸门”，核心评价标准是<strong>流程自定义、触发条件、移动端支持</strong>。</p><h4>各品牌表现拆解</h4><table><thead><tr><th>品牌</th><th>核心优势</th><th>具体能力</th></tr></thead><tbody><tr><td><strong>超兔一体云</strong></td><td>全局权限+移动端便捷审批</td><td>1. 全局权限机制（上级管下级、助理跟主管、老板看全局）； 2. 移动端审批（支持微信/APP）； 3. 自动触发（如“费用报销&gt;500元需经理审批”）。</td></tr><tr><td><strong>Salesforce</strong></td><td>多节点+多渠道通知</td><td>1. 自定义审批节点（如“订单→区域经理→财务→老板”）； 2. 多渠道通知（邮件、Slack、手机）； 3. 审批历史追溯（如“谁驳回了订单”）。</td></tr><tr><td><strong>SuiteCRM</strong></td><td>需二次开发</td><td>1. 基础审批功能（如请假）； 2. 复杂审批（如合同）需技术团队修改代码； 3. 无移动端原生支持。</td></tr><tr><td><strong>Freshsales</strong></td><td>第三方集成</td><td>1. 通过Zapier集成审批工具（如ApprovalMax）； 2. 无原生审批流程； 3. 移动端需跳转到第三方应用。</td></tr><tr><td><strong>红圈</strong> <strong>CRM</strong></td><td>行业定制流程</td><td>1. 工程合同审批（项目经理→财务→老板）； 2. 层级审批（如“金额&gt;10万需总部审批”）； 3. 移动端支持。</td></tr><tr><td><strong>六度人和</strong></td><td>基础配置+第三方扩展</td><td>1. 请假、报销等基础审批； 2. 复杂审批需集成钉钉/企业微信； 3. 微信小程序审批。</td></tr></tbody></table><h3>（五）维度5：可配置性——从“通用”到“个性”的适配能力</h3><p>可配置性决定了CRM能否“贴合企业业务”，核心评价标准是<strong>低代码</strong> <strong>工具、开源/闭源、集成能力</strong>。</p><h4>各品牌表现拆解</h4><table><thead><tr><th>品牌</th><th>核心优势</th><th>具体能力</th></tr></thead><tbody><tr><td><strong>超兔一体云</strong></td><td>功能订阅+自定义工作台</td><td>1. 功能白名单（仅订阅需要的模块，降低成本）； 2. 自定义工作台（销售/市场/财务的专属数据大屏）； 3. 自定义业务表（如客户字段、订单布局）。</td></tr><tr><td><strong>Salesforce</strong></td><td>低代码+元数据驱动</td><td>1. Lightning低代码平台（非技术人员可自定义模块）； 2. 元数据驱动（升级不影响自定义功能）； 3. Apex语言二次开发（深度定制业务逻辑）。</td></tr><tr><td><strong>SuiteCRM</strong></td><td>开源深度定制</td><td>1. 开源代码（可修改核心逻辑）； 2. 集成第三方ERP（如SAP）； 3. 自定义字段/布局/流程。</td></tr><tr><td><strong>Freshsales</strong></td><td>企业版高级自定义</td><td>1. 免费版：基础字段修改； 2. 企业版：自定义模块（如“项目”）、工作流； 3. 集成第三方工具（如Mailchimp）。</td></tr><tr><td><strong>红圈</strong> <strong>CRM</strong></td><td>API开放+行业适配</td><td>1. 开放API接口（集成项目管理/ERP系统）； 2. 适配130+行业（如工程、医药）； 3. 自定义数据字典（如“工程阶段”字段）。</td></tr><tr><td><strong>六度人和</strong></td><td>开箱即用+基础调整</td><td>1. 无需配置，快速上线； 2. 基础调整（如客户字段、菜单）； 3. 集成微信/企业微信。</td></tr></tbody></table><h2>三、综合能力雷达图——各品牌的“能力边界”</h2><p>以下是各品牌在五大维度的<strong>1-5分评分</strong>（5分为满分），直观呈现“长板”与“短板”：</p><table><thead><tr><th>品牌</th><th>线索与商机</th><th>自动化</th><th>报表</th><th>审批</th><th>可配置</th></tr></thead><tbody><tr><td><strong>超兔一体云</strong></td><td>4.5</td><td>4.3</td><td>4.0</td><td>4.2</td><td>4.4</td></tr><tr><td><strong>Salesforce</strong></td><td>4.8</td><td>4.9</td><td>4.7</td><td>4.8</td><td>4.7</td></tr><tr><td><strong>SuiteCRM</strong></td><td>4.0</td><td>3.0</td><td>3.5</td><td>2.5</td><td>4.5</td></tr><tr><td><strong>Freshsales</strong></td><td>4.3</td><td>4.5</td><td>4.2</td><td>3.0</td><td>3.5</td></tr><tr><td><strong>红圈</strong> <strong>CRM</strong></td><td>4.5</td><td>4.0</td><td>4.3</td><td>4.5</td><td>4.2</td></tr><tr><td><strong>六度人和</strong></td><td>4.2</td><td>3.8</td><td>3.5</td><td>3.0</td><td>3.2</td></tr></tbody></table><h2>四、选型建议——匹配“企业特性”的最优解</h2><p>根据<strong>企业规模、行业、技术能力</strong>，推荐以下选型方向：</p><table><thead><tr><th>企业类型</th><th>推荐品牌</th><th>原因</th></tr></thead><tbody><tr><td>中小企业（10-200人）</td><td><strong>超兔一体云</strong></td><td>全流程覆盖+高可配置+低成本（功能白名单），适配小单快转的业务需求。</td></tr><tr><td>中大型企业（200人以上）</td><td><strong>Salesforce</strong></td><td>AI+集成能力强，支持复杂销售流程（如多产品、跨区域）。</td></tr><tr><td>有技术团队的企业</td><td><strong>SuiteCRM</strong></td><td>开源深度定制，可整合自有ERP/项目管理系统。</td></tr><tr><td>成长型企业（注重效率）</td><td><strong>Freshsales</strong></td><td>AI线索评分+自动待办，提升销售效率（适合电销/网销团队）。</td></tr><tr><td>复杂行业（如工程）</td><td><strong>红圈</strong> <strong>CRM</strong></td><td>全流程覆盖+行业适配（如项目成本分析、合同审批）。</td></tr><tr><td>社交型销售（教育/金融）</td><td><strong>六度人和</strong></td><td>微信/企业微信整合，跟踪客户社交行为（如朋友圈互动）。</td></tr></tbody></table><h2>五、总结——CRM选型的“本质”</h2><p>CRM的核心价值不是“功能多”，而是“<strong>匹配企业的业务阶段与需求</strong>”。中小企业需要“全流程、高可配置、低成本”；中大型企业需要“AI、集成、复杂流程”；行业型企业需要“定制化、行业适配”。</p><p>通过本文的对比，企业可以清晰看到：</p><ul><li>超兔一体云是<strong>中小企业的“全流程数字化工具”</strong> ；</li><li>Salesforce是<strong>中大型企业的“</strong> <strong>AI+</strong> <strong>集成平台</strong> <strong>”</strong> ；</li><li>红圈CRM是<strong>复杂行业的“全流程管家”</strong> ；</li><li>六度人和是<strong>社交型销售的“获客神器”</strong> 。</li></ul><p>最终，选型的关键是“<strong>以业务为中心</strong>”——先明确自己的核心需求（如“要解决线索转化慢”还是“要做AI预测”），再匹配品牌的“长板”能力。</p><p>（注：文中功能相关描述均基于公开披露信息，具体功能服务与价格以厂商实际落地版本为准。）</p>]]></description></item><item>    <title><![CDATA[快速上手：LangChain + AgentRun 浏览器沙箱极简集成指南 阿里云云原生 ]]></title>    <link>https://segmentfault.com/a/1190000047559401</link>    <guid>https://segmentfault.com/a/1190000047559401</guid>    <pubDate>2026-01-22 18:06:51</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>作者：辰泉</p><h2>前言</h2><p>在 Agentic AI 时代，智能体需要与真实世界交互，而浏览器是连接虚拟世界与现实世界的重要桥梁。AgentRun Browser Sandbox 为智能体提供了安全、高性能、免运维的浏览器执行环境，让 AI Agent 真正具备“上网”的能力——从网页抓取、信息提取到表单填写、自动化操作，一切皆可实现。</p><h2>AgentRun Browser Sandbox 介绍</h2><h3>什么是 Browser Sandbox?</h3><p>Browser Sandbox 是 AgentRun 平台提供的云原生无头浏览器沙箱服务，基于阿里云函数计算（FC）构建。它为智能体提供了一个安全隔离的浏览器执行环境，支持通过标准的 Chrome DevTools Protocol (CDP) 远程控制浏览器实例。</p><h3>核心特性</h3><p><strong>无头浏览器能力</strong></p><ul><li>内置 Chromium/Chrome 浏览器，支持完整的 Web 标准</li><li>原生兼容 Puppeteer、Playwright 等主流自动化框架</li><li>支持通过 CDP 协议进行精细化控制</li></ul><p><strong>实时可视化</strong></p><ul><li>内置 VNC 服务，支持实时查看浏览器界面</li><li>提供操作录制功能，方便调试和回放</li><li>支持通过 noVNC 客户端在网页中直接交互</li></ul><p><strong>安全与隔离</strong></p><ul><li>每个沙箱实例运行在独立的容器环境中</li><li>文件系统和进程空间完全隔离</li><li>支持 WSS 加密传输，确保数据安全</li></ul><p><strong>Serverless 架构</strong></p><ul><li>按需创建，按量付费，无需提前预置资源</li><li>快速弹性伸缩，支持高并发场景</li><li>零运维，无需管理服务器和浏览器依赖</li></ul><h3>主要应用场景</h3><ul><li><strong>AI Agent 赋能：</strong> 为大模型提供“眼睛”和“手”，执行网页浏览、信息提取、在线操作等任务</li><li><strong>自动化测试：</strong> 在云端运行端到端（E2E）测试和视觉回归测试</li><li><strong>数据采集：</strong> 稳定、高效地进行网页抓取，应对动态加载和反爬虫挑战</li><li><strong>内容生成：</strong> 自动化生成网页截图或 PDF 文档</li></ul><h2>上手使用 AgentRun Browser Sandbox</h2><h3>AgentRun SDK 快速介绍</h3><p><em>后续的内容将基于 AgentRun SDK 进行，因此我们先对 SDK 进行简要介绍。</em></p><p>Agentrun SDK 是一个开源的开发者工具包，本期介绍 Python 版本。其旨在简化智能体与 AgentRun 平台各种服务（包括 Browser Sandbox）的集成。它提供了统一的接口，让您可以用几行代码就将沙箱能力集成到现有的 Agent 框架中。SDK 的核心功能如下：</p><p><strong>统一集成接口</strong></p><ul><li>提供对 LangChain、AgentScope 等主流框架的开箱即用支持</li><li>统一的模型代理接口，简化多模型管理</li><li>标准化的工具注册机制</li></ul><p><strong>Sandbox 生命周期管理</strong></p><ul><li>自动创建和销毁沙箱实例</li><li>支持会话级别的状态保持</li><li>灵活的资源配置和超时控制</li></ul><h4>安装 AgentRun SDK</h4><pre><code>pip install agentrun-sdk[playwright,server]</code></pre><p><strong><em>注意：</em></strong> 确保您的 Python 环境版本在 3.10 及以上。</p><h4>基本使用示例</h4><p>以下是使用 AgentRun SDK 创建和管理 Browser Sandbox 的核心代码：</p><pre><code>from agentrun.sandbox import Sandbox, TemplateType
from playwright.sync_api import sync_playwright
# 创建 Browser Sandbox
sandbox = Sandbox.create(
    template_type=TemplateType.BROWSER,
    template_name="your-template-name",
    sandbox_idle_timeout_seconds=300
)
# 获取 CDP URL（用于 Playwright 连接）
cdp_url = sandbox.get_cdp_url()
# 使用 Playwright 连接并操作
with sync_playwright() as p:
    browser = p.chromium.connect_over_cdp(cdp_url)
    page = browser.contexts[0].pages[0]
    page.goto("https://www.example.com")
    page.screenshot(path="screenshot.png")
    browser.close()
# 销毁 Sandbox
sandbox.delete()</code></pre><p><strong>关键概念：</strong></p><ul><li><strong>template_name：</strong> 控制台创建的浏览器环境模板</li><li><strong>cdp_url：</strong> 用于 Playwright/Puppeteer 连接</li><li><strong>vnc_url：</strong> 用于实时查看浏览器画面（可通过 sandbox.get_cdp_url() 获取）</li></ul><p><strong><em>注意：</em></strong> 由于所有浏览器操作都在云端进行，您无需在本地安装浏览器。Playwright 仅用于通过 CDP 协议连接到云端的浏览器实例。</p><h3>如何创建 Sandbox 模板</h3><p>使用 Browser Sandbox 需要新建 Sandbox 模板，您需要访问 AgentRun 控制台网站 <strong>[</strong> <strong>1]</strong> ，并按照如下步骤创建模板：</p><ol><li>在顶部菜单栏选择“运行时与沙箱”；</li><li>在左侧边栏选择“Sandbox 沙箱”；</li><li>点击右上角“创建沙箱模板”；</li></ol><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559403" alt="image" title="image"/></p><ol start="4"><li>选择“浏览器”；</li></ol><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559404" alt="image" title="image" loading="lazy"/></p><ol start="5"><li>在弹出的抽屉对话框中填写和选择您的模板的规格、网络等配置，并复制模板名称；</li></ol><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559405" alt="image" title="image" loading="lazy"/></p><ol start="6"><li>点击“创建浏览器”等待其就绪即可。</li></ol><h3>从零开始用 LangChain 创建 Browser Sandbox 智能体</h3><p>本教程将指导您从零开始创建一个完整的 Browser Sandbox 智能体项目。</p><h4>基于 LangChain 集成 Browser Sandbox</h4><p>本教程将详细讲解如何使用 LangChain 创建 Browser Sandbox 相关的 Tools 并集成到 Agent 中。</p><p><strong>项目结构</strong></p><p>为了保持代码的内聚性和可维护性，我们将代码拆分为以下模块：</p><p>模块职责划分：</p><p><code>sandbox_manager.py</code>：负责 Sandbox 的创建、管理和销毁，提供统一的接口  <br/><code>langchain_agent.py</code>：负责创建 LangChain Tools 和 Agent，集成 VNC 信息<br/><code>main.py</code>：作为入口文件，演示如何使用上述模块</p><p><strong>步骤 1：创建项目并安装依赖</strong></p><p>首先创建项目目录（如果还没有）：</p><pre><code>mkdir -p langchain-demo
cd langchain-demo</code></pre><p>创建 requirements.txt 文件，内容如下：</p><pre><code># LangChain 核心库
langchain&gt;=0.1.0
langchain-openai&gt;=0.0.5
langchain-community&gt;=0.0.20
# AgentRun SDK
agentrun-sdk[playwright,server]&gt;=0.0.8
# 浏览器自动化
playwright&gt;=1.40.0
# 环境变量管理
python-dotenv&gt;=1.0.0</code></pre><p>然后安装依赖：</p><pre><code>pip install -r requirements.txt</code></pre><p>主要依赖说明：</p><ul><li><code>langchain</code> 和 <code>langchain-openai</code>：LangChain 核心库</li><li><code>agentrun-sdk[playwright,server]</code>：AgentRun SDK，用于 Sandbox 管理</li><li><code>playwright</code>：浏览器自动化库</li><li><code>python-dotenv</code>：环境变量管理</li></ul><p><strong>步骤 2：配置环境变量</strong></p><p>在项目根目录创建 <code>.env</code> 文件，配置以下环境变量：</p><pre><code># 阿里云百炼平台的 API Key，用于调用大模型能力
# 请前往 https://bailian.console.aliyun.com/?tab=app#/api-key 创建和查看
DASHSCOPE_API_KEY=sk-your-bailian-api-key
# 阿里云账号的访问密钥 ID 和访问密钥 Secret，用于 AgentRun SDK 鉴权
ALIBABA_CLOUD_ACCESS_KEY_ID=your-ak
ALIBABA_CLOUD_ACCESS_KEY_SECRET=your-sk
ALIBABA_CLOUD_ACCOUNT_ID=your-main-account-id
ALIBABA_CLOUD_REGION=cn-hangzhou
# browser sandbox 模板的名称，可以在 https://functionai.console.aliyun.com/cn-hangzhou/agent/runtime/sandbox 控制台创建
BROWSER_TEMPLATE_NAME=sandbox-your-template-name
# agentrun 的控制面和数据面的 API 端点请求地址，默认cn-hangzhou
AGENTRUN_CONTROL_ENDPOINT=agentrun.cn-hangzhou.aliyuncs.com
AGENTRUN_DATA_ENDPOINT=https://${your-main-account-id}.agentrun-data.cn-hangzhou.aliyuncs.com</code></pre><p><strong>步骤 3：创建 Sandbox 生命周期管理模块</strong></p><p>创建 sandbox_manager.py 文件，负责 Sandbox 的创建、管理和销毁。核心代码如下：</p><pre><code>"""
Sandbox 生命周期管理模块
负责 AgentRun Browser Sandbox 的创建、管理和销毁。
提供统一的接口供 LangChain Agent 使用。
"""
import os
from typing import Optional, Dict, Any
from dotenv import load_dotenv
# 加载环境变量
load_dotenv()
class SandboxManager:
    """Sandbox 生命周期管理器"""
    def __init__(self):
        self._sandbox: Optional[Any] = None
        self._sandbox_id: Optional[str] = None
        self._cdp_url: Optional[str] = None
        self._vnc_url: Optional[str] = None
    def create(
        self,
        template_name: Optional[str] = None,
        idle_timeout: int = 3000
    ) -&gt; Dict[str, Any]:
        """
        创建或获取一个浏览器 sandbox 实例
        Args:
            template_name: Sandbox 模板名称，如果为 None 则从环境变量读取
            idle_timeout: 空闲超时时间（秒），默认 3000 秒
        Returns:
            dict: 包含 sandbox_id, cdp_url, vnc_url 的字典
        Raises:
            RuntimeError: 创建失败时抛出异常
        """
        try:
            from agentrun.sandbox import Sandbox, TemplateType
            # 如果已有 sandbox，直接返回
            if self._sandbox is not None:
                return self.get_info()
            # 从环境变量获取模板名称
            if template_name is None:
                template_name = os.getenv(
                    "BROWSER_TEMPLATE_NAME",
                    "sandbox-browser-demo"
                )
            # 创建 sandbox
            self._sandbox = Sandbox.create(
                template_type=TemplateType.BROWSER,
                template_name=template_name,
                sandbox_idle_timeout_seconds=idle_timeout
            )
            self._sandbox_id = self._sandbox.sandbox_id
            self._cdp_url = self._get_cdp_url()
            self._vnc_url = self._get_vnc_url()
            return self.get_info()
        except ImportError as e:
            print(e)
            raise RuntimeError(
                "agentrun-sdk 未安装，请运行: pip install agentrun-sdk[playwright,server]"
            )
        except Exception as e:
            raise RuntimeError(f"创建 Sandbox 失败: {str(e)}")
    def get_info(self) -&gt; Dict[str, Any]:
        """
        获取当前 sandbox 的信息
        Returns:
            dict: 包含 sandbox_id, cdp_url, vnc_url 的字典
        Raises:
            RuntimeError: 如果没有活动的 sandbox
        """
        if self._sandbox is None:
            raise RuntimeError("没有活动的 sandbox，请先创建")
        return {
            "sandbox_id": self._sandbox_id,
            "cdp_url": self._cdp_url,
            "vnc_url": self._vnc_url,
        }
    def get_cdp_url(self) -&gt; Optional[str]:
        """获取 CDP URL"""
        return self._sandbox.get_cdp_url()
    def get_vnc_url(self) -&gt; Optional[str]:
        """获取 VNC URL"""
        return self._sandbox.get_vnc_url()
    def get_sandbox_id(self) -&gt; Optional[str]:
        """获取 Sandbox ID"""
        return self._sandbox_id
    def destroy(self) -&gt; str:
        """
        销毁当前的 sandbox 实例
        Returns:
            str: 操作结果描述
        """
        if self._sandbox is None:
            return "没有活动的 sandbox"
        try:
            sandbox_id = self._sandbox_id
            # 尝试销毁 sandbox
            if hasattr(self._sandbox, 'delete'):
                self._sandbox.delete()
            elif hasattr(self._sandbox, 'stop'):
                self._sandbox.stop()
            elif hasattr(self._sandbox, 'destroy'):
                self._sandbox.destroy()
            # 清理状态
            self._sandbox = None
            self._sandbox_id = None
            self._cdp_url = None
            self._vnc_url = None
            return f"Sandbox 已销毁: {sandbox_id}"
        except Exception as e:
            # 即使销毁失败，也清理本地状态
            self._sandbox = None
            self._sandbox_id = None
            self._cdp_url = None
            self._vnc_url = None
            return f"销毁 Sandbox 时出错: {str(e)}"
    def is_active(self) -&gt; bool:
        """检查 sandbox 是否活跃"""
        return self._sandbox is not None
    def __enter__(self):
        """上下文管理器入口"""
        return self
    def __exit__(self, exc_type, exc_val, exc_tb):
        """上下文管理器退出，自动销毁"""
        self.destroy()
        return False
# 全局单例（可选，用于简单场景）
_global_manager: Optional[SandboxManager] = None
def get_global_manager() -&gt; SandboxManager:
    """获取全局 SandboxManager 单例"""
    global _global_manager
    if _global_manager is None:
        _global_manager = SandboxManager()
    return _global_manager
def reset_global_manager():
    """重置全局 SandboxManager"""
    global _global_manager
    if _global_manager:
        _global_manager.destroy()
    _global_manager = None</code></pre><p><strong>关键功能：</strong></p><ol><li><strong>创建 Sandbox：</strong> 使用 AgentRun SDK 创建浏览器 Sandbox</li><li><strong>获取连接信息：</strong> 自动获取 CDP URL 和 VNC URL，支持多种属性名兼容</li><li><strong>生命周期管理：</strong> 提供销毁方法，确保资源正确释放</li></ol><p><strong>步骤 4：创建 LangChain Tools 和 Agent</strong></p><p>创建 langchain_agent.py 文件，定义 LangChain Tools 并创建 Agent。核心代码如下：</p><pre><code>"""
LangChain Agent 和 Tools 注册模块
负责创建 LangChain Agent，注册 Sandbox 相关的 tools，并集成 VNC 可视化。
本模块使用 sandbox_manager.py 中封装的 SandboxManager 来管理 sandbox 生命周期。
"""
import os
from dotenv import load_dotenv
from langchain.tools import tool
from langchain_openai import ChatOpenAI
from langchain.agents import create_agent
from pydantic import BaseModel, Field
# 导入 sandbox 管理器
from sandbox_manager import SandboxManager
# 加载环境变量
load_dotenv()
# 全局 sandbox 管理器实例（单例模式）
_sandbox_manager: SandboxManager | None = None
def get_sandbox_manager() -&gt; SandboxManager:
    """获取 sandbox 管理器实例（单例模式）"""
    global _sandbox_manager
    if _sandbox_manager is None:
        _sandbox_manager = SandboxManager()
    return _sandbox_manager
# ============ LangChain Tools 定义 ============
@tool
def create_browser_sandbox(
    template_name: str = None,
    idle_timeout: int = 3000
) -&gt; str:
    """创建或获取一个浏览器 sandbox 实例。
    当需要访问网页、执行浏览器操作时，首先需要创建 sandbox。
    创建成功后，会返回 sandbox 信息，包括 VNC URL 用于可视化。
    Args:
        template_name: Sandbox 模板名称，如果不提供则从环境变量 BROWSER_TEMPLATE_NAME 读取
        idle_timeout: 空闲超时时间（秒），默认 3000 秒
    Returns:
        Sandbox 信息字符串，包括 ID、CDP URL、VNC URL
    """
    try:
        manager = get_sandbox_manager()
        # 如果 template_name 为空字符串，转换为 None 以便从环境变量读取
        if template_name == "":
            template_name = None
        info = manager.create(template_name=template_name, idle_timeout=idle_timeout)
        result = f"""✅ Sandbox 创建成功！
📋 Sandbox 信息:
- ID: {info['sandbox_id']}
- CDP URL: {info['cdp_url']}
"""
        vnc_url = info.get('vnc_url')
        if vnc_url:
            result += f"- VNC URL: {vnc_url}\n\n"
            result += "提示: VNC 查看器应该已自动打开，您可以在浏览器中实时查看浏览器操作。"
        else:
            result += "\n警告: 未获取到 VNC URL，可能无法使用可视化功能。"
        return result
    except Exception as e:
        return f" 创建 Sandbox 失败: {str(e)}"
@tool
def get_sandbox_info() -&gt; str:
    """获取当前 sandbox 的详细信息，包括 ID、CDP URL、VNC URL 等。
    当需要查看当前 sandbox 状态或获取 VNC 连接信息时使用此工具。
    Returns:
        Sandbox 信息字符串
    """
    try:
        manager = get_sandbox_manager()
        info = manager.get_info()
        result = f"""📋 当前 Sandbox 信息:
- Sandbox ID: {info['sandbox_id']}
- CDP URL: {info['cdp_url']}
"""
        if info.get('vnc_url'):
            result += f"- VNC URL: {info['vnc_url']}\n\n"
            result += "您可以使用 VNC URL 在浏览器中实时查看操作过程。\n"
            result += "   推荐使用 vnc.html 文件或 noVNC 客户端。"
        return result
    except RuntimeError as e:
        return f" {str(e)}"
    except Exception as e:
        return f" 获取 Sandbox 信息失败: {str(e)}"
class NavigateInput(BaseModel):
    """浏览器导航输入参数"""
    url: str = Field(description="要访问的网页 URL，必须以 http:// 或 https:// 开头")
    wait_until: str = Field(
        default="load",
        description="等待页面加载的状态: load, domcontentloaded, networkidle"
    )
    timeout: int = Field(
        default=30000,
        description="超时时间（毫秒），默认 30000"
    )
@tool(args_schema=NavigateInput)
def navigate_to_url(url: str, wait_until: str = "load", timeout: int = 30000) -&gt; str:
    """使用 sandbox 中的浏览器导航到指定 URL。
    当用户需要访问网页时使用此工具。导航后可以在 VNC 中实时查看页面。
    Args:
        url: 要访问的网页 URL
        wait_until: 等待页面加载的状态（load/domcontentloaded/networkidle）
        timeout: 超时时间（毫秒）
    Returns:
        导航结果描述
    """
    try:
        manager = get_sandbox_manager()
        if not manager.is_active():
            return " 错误: 请先创建 sandbox"
        # 验证 URL
        if not url.startswith(("http://", "https://")):
            return f" 错误: 无效的 URL 格式: {url}"
        cdp_url = manager.get_cdp_url()
        if not cdp_url:
            return " 错误: 无法获取 CDP URL"
        # 使用 Playwright 连接浏览器并导航
        try:
            from playwright.sync_api import sync_playwright
            with sync_playwright() as p:
                browser = p.chromium.connect_over_cdp(cdp_url)
                pages = browser.contexts[0].pages if browser.contexts else []
                if pages:
                    page = pages[0]
                else:
                    page = browser.new_page()
                page.goto(url, wait_until=wait_until, timeout=timeout)
                title = page.title()
                return f"已成功导航到: {url}\n📄 页面标题: {title}\n💡 您可以在 VNC 中查看页面内容。"
        except ImportError:
            return f"导航指令已发送: {url}\n💡 提示: 安装 playwright 以启用实际导航功能 (pip install playwright)"
        except Exception as e:
            return f" 导航失败: {str(e)}"
    except Exception as e:
        return f" 操作失败: {str(e)}"
@tool("browser_screenshot", description="在浏览器 sandbox 中截取当前页面截图")
def take_screenshot(filename: str = "screenshot.png") -&gt; str:
    """截取浏览器当前页面的截图。
    Args:
        filename: 截图文件名，默认 "screenshot.png"
    Returns:
        操作结果
    """
    try:
        manager = get_sandbox_manager()
        if not manager.is_active():
            return " 错误: 请先创建 sandbox"
        cdp_url = manager.get_cdp_url()
        if not cdp_url:
            return " 错误: 无法获取 CDP URL"
        try:
            from playwright.sync_api import sync_playwright
            with sync_playwright() as p:
                browser = p.chromium.connect_over_cdp(cdp_url)
                pages = browser.contexts[0].pages if browser.contexts else []
                if pages:
                    page = pages[0]
                else:
                    return " 错误: 没有打开的页面"
                page.screenshot(path=filename)
                return f"截图已保存: {filename}"
        except ImportError:
            return " 错误: 需要安装 playwright (pip install playwright)"
        except Exception as e:
            return f" 截图失败: {str(e)}"
    except Exception as e:
        return f" 操作失败: {str(e)}"
@tool("destroy_sandbox", description="销毁当前的 sandbox 实例，释放资源。注意：仅在程序退出或明确需要释放资源时使用，不要在一轮对话后销毁。")
def destroy_sandbox() -&gt; str:
    """销毁当前的 sandbox 实例。
    重要提示：此工具应该仅在以下情况使用：
    - 程序即将退出
    - 明确需要释放资源
    - 用户明确要求销毁
    不要在一轮对话完成后就销毁 sandbox，因为 sandbox 可以在多轮对话中复用。
    Returns:
        操作结果
    """
    try:
        manager = get_sandbox_manager()
        result = manager.destroy()
        return result
    except Exception as e:
        return f" 销毁失败: {str(e)}"
# ============ Agent 创建 ============
def create_browser_agent(system_prompt: str = None):
    """
    创建带有 sandbox 工具的 LangChain Agent
    Args:
        system_prompt: 自定义系统提示词，如果为 None 则使用默认提示词
    Returns:
        LangChain Agent 实例
    """
    # 配置 DashScope API
    api_key = os.getenv("DASHSCOPE_API_KEY")
    if not api_key:
        raise ValueError("请设置环境变量 DASHSCOPE_API_KEY")
    base_url = "https://dashscope.aliyuncs.com/compatible-mode/v1"
    model_name = os.getenv("QWEN_MODEL", "qwen-plus")
    # 创建 LLM
    model = ChatOpenAI(
        model=model_name,
        api_key=api_key,
        base_url=base_url,
        temperature=0.7,
    )
    # 创建工具列表
    tools = [
        create_browser_sandbox,
        get_sandbox_info,
        navigate_to_url,
        take_screenshot,
        destroy_sandbox,
    ]
    # 默认系统提示词
    if system_prompt is None:
        system_prompt = """你是一个浏览器自动化助手，可以使用 sandbox 来访问和操作网页。
当用户需要访问网页时，请按以下步骤操作：
1. 首先创建或获取 sandbox（如果还没有）
2. 使用 navigate_to_url 导航到目标网页
3. 执行用户请求的操作
4. 如果需要，可以截取截图
重要提示：
- 创建 sandbox 后，会返回 VNC URL，用户可以使用它实时查看浏览器操作
- 所有操作都会在 VNC 中实时显示，方便调试和监控
- sandbox 可以在多轮对话中复用，不要在一轮对话完成后就销毁
- 只有在用户明确要求销毁时才使用 destroy_sandbox 工具
- 不要主动建议用户销毁 sandbox，除非用户明确要求
- 请始终用中文回复，确保操作准确、高效。"""
    # 创建 Agent
    agent = create_agent(
        model=model,
        tools=tools,
        system_prompt=system_prompt,
    )
    return agent
def get_available_tools():
    """获取所有可用的工具列表"""
    return [
        create_browser_sandbox,
        get_sandbox_info,
        navigate_to_url,
        take_screenshot,
        destroy_sandbox,
    ]</code></pre><p><strong>关键要点：</strong></p><ol><li><strong>Tool 定义：</strong> 使用 @tool 装饰器定义 LangChain Tools</li><li><strong>类型提示：</strong> 所有参数必须有类型提示，用于生成工具 schema</li><li><strong>文档字符串：</strong> 详细的文档字符串帮助 LLM 理解何时使用工具**</li><li><strong>单例模式：</strong> 使用全局管理器实例确保 Sandbox 在会话中复用**</li></ol><p><strong>步骤 5：创建主入口文件</strong></p><p>创建 main.py 文件，作为程序入口。核心代码如下：</p><pre><code>"""
LangChain + AgentRun Browser Sandbox 集成示例
主入口文件，演示如何使用 LangChain Agent 与 AgentRun Browser Sandbox 集成。
"""
import os
import sys
import signal
import webbrowser
import urllib.parse
import threading
import http.server
import socketserver
from pathlib import Path
from dotenv import load_dotenv
from langchain_agent import create_browser_agent, get_sandbox_manager
# 加载环境变量
load_dotenv()
# 全局 HTTP 服务器实例
_http_server = None
_http_port = 8080
# 全局清理标志，用于防止重复清理
_cleanup_done = False
def start_http_server():
    """启动一个简单的 HTTP 服务器来提供 vnc.html"""
    global _http_server
    if _http_server is not None:
        return _http_port
    try:
        current_dir = Path(__file__).parent.absolute()
        class VNCRequestHandler(http.server.SimpleHTTPRequestHandler):
            def __init__(self, *args, **kwargs):
                super().__init__(*args, directory=str(current_dir), **kwargs)
            def log_message(self, format, *args):
                # 静默日志，避免输出过多信息
                pass
        # 尝试启动服务器
        for port in range(_http_port, _http_port + 10):
            try:
                server = socketserver.TCPServer(("", port), VNCRequestHandler)
                server.allow_reuse_address = True
                # 在后台线程中运行服务器
                def run_server():
                    server.serve_forever()
                thread = threading.Thread(target=run_server, daemon=True)
                thread.start()
                _http_server = server
                return port
            except OSError:
                continue
        return None
    except Exception as e:
        print(f"启动 HTTP 服务器失败: {str(e)}")
        return None
def open_vnc_viewer(vnc_url: str):
    """
    自动打开 VNC 查看器并设置 VNC URL
    Args:
        vnc_url: VNC WebSocket URL
    """
    if not vnc_url:
        return
    try:
        # 获取当前文件所在目录
        current_dir = Path(__file__).parent.absolute()
        vnc_html_path = current_dir / "vnc.html"
        # 检查文件是否存在
        if not vnc_html_path.exists():
            print(f"警告: vnc.html 文件不存在: {vnc_html_path}")
            print_vnc_info(vnc_url)
            return
        # 启动 HTTP 服务器
        port = start_http_server()
        if port:
            # 编码 VNC URL 作为 URL 参数
            encoded_url = urllib.parse.quote(vnc_url, safe='')
            # 构建 HTTP URL
            http_url = f"http://localhost:{port}/vnc.html?url={encoded_url}"
            # 打开浏览器
            print(f"\n正在打开 VNC 查看器...")
            print(f"HTTP 服务器运行在: http://localhost:{port}")
            print(f"VNC URL: {vnc_url[:80]}...")
            print(f"完整 URL: {http_url[:100]}...")
            webbrowser.open(http_url)
            print(f"VNC 查看器已打开")
            print(f"VNC URL 已通过 URL 参数自动设置，页面加载后会自动连接")
        else:
            # 如果 HTTP 服务器启动失败，尝试使用 file:// 协议
            print(f"HTTP 服务器启动失败，尝试使用文件协议...")
            encoded_url = urllib.parse.quote(vnc_url, safe='')
            file_url = f"file://{vnc_html_path}?url={encoded_url}"
            webbrowser.open(file_url)
            print(f"VNC 查看器已打开（使用文件协议）")
            print(f"提示: 如果无法自动连接，请手动复制 VNC URL 到输入框")
    except Exception as e:
        print(f"自动打开 VNC 查看器失败: {str(e)}")
        print_vnc_info(vnc_url)
def print_vnc_info(vnc_url: str):
    """打印 VNC 连接信息"""
    if not vnc_url:
        return
    print("\n" + "=" * 60)
    print("VNC 可视化连接信息")
    print("=" * 60)
    print(f"\nVNC URL: {vnc_url}")
    print("\n使用方式:")
    print("   1. 使用 noVNC 客户端连接")
    print("   2. 或在浏览器中访问 VNC 查看器页面")
    print("   3. 实时查看浏览器操作过程")
    print("\n" + "=" * 60 + "\n")
def cleanup_sandbox():
    """
    清理 sandbox 资源
    这个函数可以被信号处理器、异常处理器和正常退出流程调用
    """
    global _cleanup_done
    # 防止重复清理
    if _cleanup_done:
        return
    _cleanup_done = True
    try:
        manager = get_sandbox_manager()
        if manager.is_active():
            print("\n" + "=" * 60)
            print("正在清理 sandbox...")
            print("=" * 60)
            result = manager.destroy()
            print(f"清理结果: {result}\n")
        else:
            print("\n没有活动的 sandbox 需要清理\n")
    except Exception as e:
        print(f"\n清理 sandbox 时出错: {str(e)}\n")
def signal_handler(signum, frame):
    """
    信号处理器，处理 Ctrl+C (SIGINT) 和其他信号
    Args:
        signum: 信号编号
        frame: 当前堆栈帧
    """
    print("\n\n收到中断信号，正在清理资源...")
    cleanup_sandbox()
    print("清理完成")
    sys.exit(0)
def main():
    """主函数"""
    global _cleanup_done
    # 重置清理标志
    _cleanup_done = False
    # 注册信号处理器，处理 Ctrl+C (SIGINT)
    signal.signal(signal.SIGINT, signal_handler)
    # 在 Windows 上，SIGBREAK 也可以处理
    if hasattr(signal, 'SIGBREAK'):
        signal.signal(signal.SIGBREAK, signal_handler)
    print("=" * 60)
    print("LangChain + AgentRun Browser Sandbox 集成示例")
    print("=" * 60)
    print()
    try:
        # 创建 Agent
        print("正在初始化 LangChain Agent...")
        agent = create_browser_agent()
        print("Agent 初始化完成\n")
        # 示例查询
        queries = [
            "创建一个浏览器 sandbox",
            "获取当前 sandbox 的信息，包括 VNC URL",
            "导航到 https://www.aliyun.com",
            "截取当前页面截图",
        ]
        # 执行查询
        for i, query in enumerate(queries, 1):
            print(f"\n{'=' * 60}")
            print(f"查询 {i}: {query}")
            print(f"{'=' * 60}\n")
            try:
                result = agent.invoke({
                    "messages": [{"role": "user", "content": query}]
                })
                # 提取最后一条消息的内容
                output = result.get("messages", [])[-1].content if isinstance(result.get("messages"), list) else result.get("output", str(result))
                print(f"\n结果:\n{output}\n")
                # 如果是创建 sandbox，自动打开 VNC 查看器
                if i == 1:
                    try:
                        # 等待一下确保 sandbox 完全创建
                        import time
                        time.sleep(1)
                        manager = get_sandbox_manager()
                        if manager.is_active():
                            info = manager.get_info()
                            vnc_url = info.get('vnc_url')
                            if vnc_url:
                                print(f"\n检测到 VNC URL: {vnc_url[:80]}...")
                                open_vnc_viewer(vnc_url)
                                print_vnc_info(vnc_url)
                            else:
                                print("\n警告: 未获取到 VNC URL，请检查 sandbox 创建是否成功")
                    except Exception as e:
                        print(f"打开 VNC 查看器时出错: {str(e)}")
                        import traceback
                        traceback.print_exc()
                # 如果是获取信息，显示 VNC 信息
                elif i == 2:
                    try:
                        manager = get_sandbox_manager()
                        if manager.is_active():
                            info = manager.get_info()
                            if info.get('vnc_url'):
                                print_vnc_info(info['vnc_url'])
                    except:
                        pass
            except Exception as e:
                print(f"查询失败: {str(e)}\n")
                import traceback
                traceback.print_exc()
        # 交互式查询
        print("\n" + "=" * 60)
        print("进入交互模式（输入 'quit' 或 'exit' 退出，Ctrl+C 或 Ctrl+D 中断）")
        print("=" * 60 + "\n")
        while True:
            try:
                user_input = input("请输入您的查询: ").strip()
            except EOFError:
                # 处理 Ctrl+D (EOF)
                print("\n\n检测到输入结束 (Ctrl+D)，正在清理资源...")
                cleanup_sandbox()
                print("清理完成")
                break
            except KeyboardInterrupt:
                # 处理 Ctrl+C (在 input 调用期间)
                print("\n\n检测到中断信号 (Ctrl+C)，正在清理资源...")
                cleanup_sandbox()
                print("清理完成")
                break
            if not user_input:
                continue
            if user_input.lower() in ['quit', 'exit', '退出']:
                print("\nBye")
                # 退出前清理 sandbox
                cleanup_sandbox()
                break
            try:
                result = agent.invoke({
                    "messages": [{"role": "user", "content": user_input}]
                })
                output = result.get("messages", [])[-1].content if isinstance(result.get("messages"), list) else result.get("output", str(result))
                print(f"\n结果:\n{output}\n")
                # 检查是否需要打开或显示 VNC 信息
                user_input_lower = user_input.lower()
                if "创建" in user_input_lower and "sandbox" in user_input_lower:
                    # 如果是创建 sandbox，自动打开 VNC 查看器
                    try:
                        # 等待一下确保 sandbox 完全创建
                        import time
                        time.sleep(1)
                        manager = get_sandbox_manager()
                        if manager.is_active():
                            info = manager.get_info()
                            vnc_url = info.get('vnc_url')
                            if vnc_url:
                                print(f"\n检测到 VNC URL: {vnc_url[:80]}...")
                                open_vnc_viewer(vnc_url)
                                print_vnc_info(vnc_url)
                            else:
                                print("\n警告: 未获取到 VNC URL，请检查 sandbox 创建是否成功")
                    except Exception as e:
                        print(f"打开 VNC 查看器时出错: {str(e)}")
                        import traceback
                        traceback.print_exc()
                elif "sandbox" in user_input_lower or "vnc" in user_input_lower:
                    # 其他情况只显示信息
                    try:
                        manager = get_sandbox_manager()
                        if manager.is_active():
                            info = manager.get_info()
                            if info.get('vnc_url'):
                                print_vnc_info(info['vnc_url'])
                    except:
                        pass
            except Exception as e:
                print(f"查询失败: {str(e)}\n")
                import traceback
                traceback.print_exc()
        # 清理资源（仅在程序正常退出时）
        cleanup_sandbox()
    except KeyboardInterrupt:
        # 处理顶层 KeyboardInterrupt (Ctrl+C)
        print("\n\n检测到中断信号 (Ctrl+C)，正在清理资源...")
        cleanup_sandbox()
        print("清理完成")
        sys.exit(0)
    except EOFError:
        # 处理顶层 EOFError (Ctrl+D)
        print("\n\n检测到输入结束 (Ctrl+D)，正在清理资源...")
        cleanup_sandbox()
        print("清理完成")
        sys.exit(0)
    except ValueError as e:
        print(f"配置错误: {str(e)}")
        print("\n提示: 请确保已设置以下环境变量:")
        print("   - DASHSCOPE_API_KEY: DashScope API Key")
        print("   - ALIBABA_CLOUD_ACCOUNT_ID: 阿里云账号 ID")
        print("   - ALIBABA_CLOUD_ACCESS_KEY_ID: 访问密钥 ID")
        print("   - ALIBABA_CLOUD_ACCESS_KEY_SECRET: 访问密钥 Secret")
        print("   - ALIBABA_CLOUD_REGION: 区域（默认: cn-hangzhou）")
    except Exception as e:
        print(f"发生错误: {str(e)}")
        import traceback
        traceback.print_exc()
        # 发生错误时也尝试清理
        cleanup_sandbox()
if __name__ == "__main__":
    main()</code></pre><p><strong>关键功能：</strong></p><ol><li><strong>VNC 自动打开：</strong> 创建 Sandbox 后自动打开 VNC 查看器</li><li><strong>信号处理：</strong> 捕获 Ctrl+C，确保资源正确清理</li><li><strong>交互模式：</strong> 支持持续对话，复用 Sandbox 实例</li></ol><p><strong>VNC 可视化集成</strong></p><p>VNC（Virtual Network Computing）功能允许您实时查看和监控浏览器在 Sandbox 中的操作过程，这对于调试和监控 Agent 行为非常有用。</p><p><strong>获取 VNC URL：</strong></p><p>创建 Sandbox 后，可以通过 <code>get_sandbox_info tool</code> 获取 VNC URL：</p><pre><code># 通过 Agent 调用
result = agent.invoke({
    "messages": [{"role": "user", "content": "获取 sandbox 信息"}]
})
# 或直接通过管理器获取
manager = get_sandbox_manager()
info = manager.get_info()
vnc_url = info['vnc_url']</code></pre><p><strong>自动打开 VNC 查看器：</strong></p><p>在 <code>main.py</code> 中，我们实现了自动打开 VNC 查看器的功能：</p><pre><code>import webbrowser
import urllib.parse
from pathlib import Path
def open_vnc_viewer(vnc_url: str):
    """自动打开 VNC 查看器"""
    current_dir = Path(__file__).parent.absolute()
    vnc_html_path = current_dir / "vnc.html"
    if vnc_html_path.exists():
        # 通过 URL 参数传递 VNC URL
        encoded_url = urllib.parse.quote(vnc_url, safe='')
        file_url = f"file://{vnc_html_path}?url={encoded_url}"
        webbrowser.open(file_url)</code></pre><p><strong>VNC HTML 页面：</strong></p><p><code>vnc.html</code> 页面会从 URL 参数中读取 VNC URL，并自动连接到 VNC 服务器。页面包含以下核心功能：</p><ol><li><strong>noVNC 库加载：</strong> 从 CDN 动态加载 noVNC 客户端库</li><li><strong>自动连接：</strong> 读取 URL 参数中的 VNC URL 并自动连接</li><li><strong>状态显示：</strong> 显示连接状态（连接中、已连接、已断开）</li><li><strong>手动控制：</strong> 支持手动输入 VNC URL、断开重连等操作</li></ol><p>核心 JavaScript 代码片段：</p><pre><code>// 从 URL 参数获取 VNC URL
const urlParams = new URLSearchParams(window.location.search);
const vncUrl = urlParams.get('url');
// 加载 noVNC 库
async function loadNoVNC() {
    const module = await import('https://cdn.jsdelivr.net/gh/novnc/noVNC@v1.4.0/core/rfb.js');
    return module.default;
}
// 连接 VNC
async function connectVNC(url) {
    const RFB = await loadNoVNC();
    rfb = new RFB(vncScreen, url, {
        shared: true,
        credentials: { password: '' }
    });
    rfb.addEventListener('connect', () =&gt; {
        console.log('VNC 连接成功');
    });
}</code></pre><p>完整的 vnc.html 文件可以在示例代码仓库中获取。</p><p><strong>手动使用 VNC 查看器：</strong></p><p>如果自动打开失败，您也可以手动使用 VNC 查看器：</p><p><strong>1. 使用 noVNC 在线客户端：</strong></p><ul><li>访问 noVNC 在线客户端 <strong>[</strong> <strong>2]</strong></li><li>在连接设置中填入 VNC URL</li><li>点击连接</li></ul><p><strong>2. 使用本地 VNC HTML 页面：</strong></p><ul><li>打开 <code>vnc.html</code></li><li>输入 VNC URL</li><li>点击连接按钮</li></ul><p><strong>实时监控功能：</strong></p><ul><li>所有浏览器操作都会在 VNC 中实时显示</li><li>可以看到 Agent 的每一步操作（导航、点击、输入等）</li><li>方便调试和监控 Agent 行为</li><li>支持交互式操作（在 VNC 中直接操作浏览器）</li></ul><p><strong>运行和测试</strong></p><pre><code>python main.py</code></pre><p>程序会自动：</p><ol><li>创建 Browser Sandbox</li><li>打开 VNC 查看器（实时查看浏览器操作）</li><li>执行预设查询</li><li>进入交互模式</li></ol><h3>工作原理</h3><p>为了更好地理解系统架构，我们将工作流程拆分为两个部分：<strong>LangChain Agent 工作流程</strong>和 <strong>SandboxManager 生命周期管理</strong>。</p><p><strong>1. LangChain Agent 工作流程</strong></p><p>下图展示了 LangChain Agent 如何处理用户请求并调用相应的 Tools：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559406" alt="image" title="image" loading="lazy"/></p><p><strong>Agent 工作流程说明：</strong></p><ol><li><strong>请求接收：</strong> 用户发起自然语言请求（如“访问淘宝首页并截图”）</li><li><strong>意图分析：</strong> Agent 分析用户意图，决定需要调用哪些 Tools</li><li><strong>Tool 调用：</strong> 根据任务需求，顺序或组合调用多个 Tools</li><li><strong>Manager 交互：</strong> 所有 Tools 都通过 SandboxManager 单例实例操作 Sandbox</li><li><strong>结果处理：</strong> Agent 将 Tool 返回的结果整合成用户友好的响应</li><li><strong>多轮对话：</strong> Sandbox 在整个会话中保持活跃，支持多轮对话</li></ol><p>5 个核心 Tools 的职责：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559407" alt="image" title="image" loading="lazy"/></p><p><strong>2. SandboxManager 生命周期管理</strong></p><p>下图展示了 SandboxManager 如何管理 Sandbox 的完整生命周期：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559408" alt="image" title="image" loading="lazy"/></p><p><strong>SandboxManager 工作流程说明：</strong></p><p><strong>1. 单例管理：</strong></p><ul><li>首次调用时创建 Manager 实例</li><li>后续调用复用同一个实例</li><li>确保整个会话只有一个 Sandbox</li></ul><p><strong>2. Sandbox 创建：</strong></p><ul><li>调用 AgentRun SDK 的 <code>Sandbox.create()</code></li><li>SDK 通过阿里云 API 与函数计算 FC 通信</li><li>FC 服务创建独立的容器实例，包含：</li><li>Chromium 浏览器 VNC 服务必要的运行环境</li></ul><p><strong>3. 连接信息获取：</strong></p><ul><li><strong>CDP URL：</strong> WebSocket 地址，用于 Playwright/Puppeteer 远程控制浏览器</li><li><strong>VNC URL：</strong> WebSocket 地址，用于实时查看浏览器画面**</li></ul><p><strong>4. 浏览器操作：</strong></p><ul><li>Playwright 通过 CDP URL 连接到远程浏览器</li><li>执行各种浏览器操作（导航、点击、截图等）</li><li>VNC 同步显示操作过程，用户可实时监控</li></ul><p><strong>5. 资源清理：</strong></p><ul><li>调用 destroy() 方法销毁 Sandbox</li><li>清理 Manager 内部状态</li><li>通过 SDK 释放云端资源</li></ul><p><strong>3. Agent 与 Manager 的协作关系</strong></p><p><strong>交互模式：</strong></p><pre><code>用户请求 → Agent → Tool → SandboxManager → AgentRun SDK → 云端 Sandbox
                                    ↓
用户响应 ← Agent ← Tool ← SandboxManager ← 操作结果</code></pre><p><strong>关键设计理念：</strong></p><ol><li>分层架构：</li></ol><ul><li>用户层：自然语言交互</li><li>Agent 层：意图理解和任务分解</li><li>Tool 层：功能封装和参数验证</li><li>Manager 层：资源管理和状态维护</li><li>SDK 层：云服务通信</li><li>云端层：实际的 Sandbox 环境</li></ul><ol start="2"><li>单例模式：</li></ol><ul><li>SandboxManager 使用单例模式</li><li>保证整个会话中只有一个 Sandbox 实例</li><li>避免资源浪费和状态冲突</li></ul><ol start="3"><li>状态复用：</li></ol><ul><li>Sandbox 在多轮对话中保持活跃</li><li>减少创建和销毁的开销</li><li>提供更流畅的用户体验</li></ul><ol start="4"><li>双通道设计：</li></ol><ul><li>CDP 通道：Agent 通过 Playwright 控制浏览器</li><li><strong>VNC 通道：用户通过 VNC 查看器实时监控</strong></li></ul><ol start="5"><li>解耦设计：</li></ol><ul><li>Tools 不直接操作 SDK，通过 Manager 统一管理</li><li>便于扩展和维护</li><li>统一的错误处理和资源管理</li></ul><p><strong>典型使用场景示例：</strong></p><pre><code># 第 1 轮对话
用户: "创建一个 sandbox 并访问淘宝首页"
→ Agent 调用: create_browser_sandbox → navigate_to_url
→ Manager: 创建 Sandbox → Playwright 导航
→ 结果: "Sandbox 已创建，已访问淘宝首页"
# 第 2 轮对话（复用 Sandbox）
用户: "截取当前页面"
→ Agent 调用: take_screenshot
→ Manager: 使用现有 Sandbox → Playwright 截图
→ 结果: "截图已保存"
# 第 3 轮对话（复用 Sandbox）
用户: "访问京东首页"
→ Agent 调用: navigate_to_url
→ Manager: 使用现有 Sandbox → Playwright 导航
→ 结果: "已访问京东首页"</code></pre><p>通过这种设计，Agent 专注于理解用户意图和任务编排，而 Manager 专注于 Sandbox 的生命周期管理，实现了清晰的职责分离。</p><p><strong>工作原理总结：</strong></p><ol><li>工具注册：使用 @tool 装饰器将 Sandbox 功能封装为 LangChain Tools</li><li>生命周期管理： SandboxManager 负责 Sandbox 的创建、管理和销毁</li><li>状态保持：使用单例模式管理 Sandbox 实例，确保同一会话内复用</li><li>VNC 集成：自动获取并返回 VNC URL，方便用户实时查看</li><li>错误处理：所有工具都包含完善的错误处理机制</li></ol><h3>扩展和定制</h3><p><strong>添加自定义 Tools：</strong></p><pre><code>@tool
def extract_table_data(url: str) -&gt; str:
    """从网页中提取表格数据"""
    from playwright.sync_api import sync_playwright
    manager = get_sandbox_manager()
    cdp_url = manager.get_info()['cdp_url']
    with sync_playwright() as p:
        browser = p.chromium.connect_over_cdp(cdp_url)
        page = browser.contexts[0].pages[0]
        page.goto(url)
        tables = page.query_selector_all("table")
        return f"找到 {len(tables)} 个表格"</code></pre><p><strong>自定义提示词：</strong></p><pre><code>custom_prompt = """你是一个专业的网页数据提取助手。
在执行任务前，请先创建 sandbox，然后使用浏览器工具完成任务。"""
agent = create_browser_agent(system_prompt=custom_prompt)
</code></pre><h3>最佳实践</h3><ol><li>模块化设计：将 Sandbox 管理和 Agent 创建分离，提高代码可维护性</li><li>错误处理：所有工具都应包含完善的错误处理</li><li>资源清理：使用信号处理器确保资源正确清理</li><li>VNC 提示：在工具返回中包含 VNC URL，方便用户使用</li><li>单例模式：确保 Sandbox 实例在会话中复用，避免重复创建</li></ol><h2>前端集成可视化监控（VNC）</h2><h3>VNC 集成架构</h3><p>下图展示了前端如何集成 VNC 实现实时监控：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559409" alt="image" title="image" loading="lazy"/></p><h3>轻量级 HTML 页面集成</h3><p>创建一个简单的 vnc-viewer.html 文件：</p><pre><code>&lt;!DOCTYPE html&gt;
&lt;html&gt;
&lt;head&gt;
    &lt;title&gt;Browser Sandbox VNC 查看器&lt;/title&gt;
    &lt;style&gt;
        body { margin: 0; padding: 0; background: 
#000
; }
        
#vnc
-container { width: 100vw; height: 100vh; }
    &lt;/style&gt;
&lt;/head&gt;
&lt;body&gt;
    &lt;div id="vnc-container"&gt;&lt;/div&gt;
    &lt;script type="module"&gt;
        const params = new URLSearchParams(window.location.search);
        const vncUrl = params.get('url');
        if (!vncUrl) {
            alert('请提供 VNC URL 参数');
        } else {
            const module = await import('https://cdn.jsdelivr.net/gh/novnc/noVNC@v1.4.0/core/rfb.js');
            const RFB = module.default;
            const rfb = new RFB(
                document.getElementById('vnc-container'),
                vncUrl,
                { shared: true, credentials: { password: '' } }
            );
            rfb.scaleViewport = true;
        }
    &lt;/script&gt;
&lt;/body&gt;
&lt;/html&gt;</code></pre><p>使用方式：</p><pre><code>import webbrowser
import urllib.parse
vnc_url = sandbox.vnc_url
encoded_url = urllib.parse.quote(vnc_url, safe='')
viewer_url = f"file:///path/to/vnc-viewer.html?url={encoded_url}"
webbrowser.open(viewer_url)</code></pre><h3>React 应用集成</h3><p>核心组件代码：</p><pre><code>import React, { useEffect, useRef } from 'react';
interface VNCViewerProps {
  vncUrl: string;
  onConnect?: () =&gt; void;
  onDisconnect?: () =&gt; void;
}
export const VNCViewer: React.FC&lt;VNCViewerProps&gt; = ({ 
  vncUrl, 
  onConnect, 
  onDisconnect 
}) =&gt; {
  const containerRef = useRef&lt;HTMLDivElement&gt;(null);
  useEffect(() =&gt; {
    let rfb: any;
    const initVNC = async () =&gt; {
      if (!containerRef.current || !vncUrl) return;
      const { default: RFB } = await import('@novnc/novnc/core/rfb');
      rfb = new RFB(containerRef.current, vncUrl, {
        shared: true,
        credentials: { password: '' }
      });
      rfb.scaleViewport = true;
      rfb.addEventListener('connect', () =&gt; onConnect?.());
      rfb.addEventListener('disconnect', () =&gt; onDisconnect?.());
    };
    initVNC();
    return () =&gt; {
      if (rfb) rfb.disconnect();
    };
  }, [vncUrl, onConnect, onDisconnect]);
  return (
    &lt;div 
      ref={containerRef} 
      style={{ width: '100%', height: '600px', background: '
#000
' }} 
    /&gt;
  );
};</code></pre><p>使用示例：</p><pre><code>import React, { useState, useEffect } from 'react';
import { VNCViewer } from './VNCViewer';
function App() {
  const [vncUrl, setVncUrl] = useState&lt;string&gt;('');
  useEffect(() =&gt; {
    fetch('/api/sandbox/create', { method: 'POST' })
      .then(res =&gt; res.json())
      .then(data =&gt; setVncUrl(data.vnc_url));
  }, []);
  return (
    &lt;div&gt;
      &lt;h1&gt;Browser Sandbox 实时监控&lt;/h1&gt;
      {vncUrl ? (
        &lt;VNCViewer 
          vncUrl={vncUrl}
          onConnect={() =&gt; console.log('已连接')}
          onDisconnect={() =&gt; console.log('已断开')}
        /&gt;
      ) : (
        &lt;p&gt;正在初始化...&lt;/p&gt;
      )}
    &lt;/div&gt;
  );
}</code></pre><h2>Puppeteer 和 Playwright 直接集成</h2><p>如果您更熟悉传统的浏览器自动化库，也可以直接使用 Puppeteer 或 Playwright 连接到 Browser Sandbox。</p><h3>使用 Playwright</h3><pre><code>from playwright.sync_api import sync_playwright
from agentrun.sandbox import Sandbox, TemplateType
# 创建 Sandbox
sandbox = Sandbox.create(
    template_type=TemplateType.BROWSER,
    template_name="your-template-name",
    sandbox_idle_timeout_seconds=3000
)
# 使用 Playwright 连接
with sync_playwright() as p:
    browser = p.chromium.connect_over_cdp(sandbox.cdp_url)
    page = browser.contexts[0].pages[0]
    # 执行操作
    page.goto("https://www.example.com")
    page.screenshot(path="screenshot.png")
    content = page.content()
    browser.close()
# 清理
sandbox.delete()
</code></pre><h3>使用 Puppeteer（Node.js）</h3><pre><code>const puppeteer = require('puppeteer-core');
// CDP URL 从 Sandbox 获取
const cdpUrl = 'wss://your-account.funagent-data-pre.cn-hangzhou.aliyuncs.com/sandboxes/xxx/ws/automation';
(async () =&gt; {
  const browser = await puppeteer.connect({
    browserWSEndpoint: cdpUrl,
    defaultViewport: null
  });
  const page = (await browser.pages())[0];
  await page.goto('https://www.example.com');
  await page.screenshot({ path: 'screenshot.png' });
  await browser.close();
})();</code></pre><h2>总结</h2><p>通过本教程，您已经学会了：</p><ol><li><strong>AgentRun SDK 基础：</strong> 如何使用 SDK 创建和管理 Browser Sandbox</li><li><strong>LangChain 集成：</strong> 如何将 Sandbox 封装为 LangChain Tools</li><li><strong>VNC 可视化：</strong> 如何在前端集成 VNC 实现实时监控</li><li><strong>直接集成：</strong> 如何使用 Puppeteer/Playwright 直接连接 Sandbox</li></ol><p><strong>相关链接：</strong></p><p>[1] Agentrun 控制台网站</p><p><a href="https://link.segmentfault.com/?enc=ANLLDqWCfICluiFLU%2Bqf%2Bg%3D%3D.wWFXF04p1HBea3PFd3mJtH0l3us67vqadj%2BDOwZ%2BmBkB35AiGyMqrkanKbjZ2eDTKbVO1cxFXeOTj8BS8bzRdDjfFqtVG%2Bo2HgdoRmXLwC8%3D" rel="nofollow" target="_blank">https://functionai.console.aliyun.com/cn-hangzhou/agent/runti...</a></p><p>[2] noVNC 在线客户端</p><p><a href="https://link.segmentfault.com/?enc=4r0yo65PKP54fMAUQWxjmQ%3D%3D.hNutYMqAyA0X1ahqYaB7vBAQgB%2FqnlDpsRhB81x4OA0057LQrHQh%2BdxKlyKZRfP6" rel="nofollow" target="_blank">https://novnc.com/noVNC/vnc.html</a></p>]]></description></item>  </channel></rss>