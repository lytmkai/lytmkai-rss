<?xml version="1.0" encoding="UTF-8"?><rss version="2.0">  <channel>      <title>SegmentFault - 最近文章</title>      <link>https://segmentfault.com/blogs/newest</link>      <description>SegmentFault 思否</description>      <generator>python segmentfault.py @Pi20</generator>      <item>    <title><![CDATA[RimWorld NPC AI 系统深度]]></title>    <link>https://segmentfault.com/a/1190000047403431</link>    <guid>https://segmentfault.com/a/1190000047403431</guid>    <pubDate>2025-11-16 23:03:26</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>引言：AI系统概述</h2><p>RimWorld 的 NPC AI 系统是一个多层次、模块化的智能决策框架。与传统的单一 AI 系统不同，RimWorld 将 AI 功能分解为五个相互协作的层次，每一层负责不同的职责，共同实现 NPC 的复杂行为。</p><h3>系统架构概览</h3><pre><code class="log">┌─────────────────────────────────────────────────────────┐
│  第五层：战斗决策层 (AttackTargetFinder)                   │
│  - 目标评分与选择                                         │
└─────────────────────────────────────────────────────────┘
                    ↓
┌─────────────────────────────────────────────────────────┐
│  第四层：群体协调层 (Lord System)                          │
│  - 状态机驱动的群体行为                                    │
└─────────────────────────────────────────────────────────┘
                    ↓
┌─────────────────────────────────────────────────────────┐
│  第三层：工作执行层 (Job System)                           │
│  - Job/Toil 任务执行框架                                  │
└─────────────────────────────────────────────────────────┘
                    ↓
┌─────────────────────────────────────────────────────────┐
│  第二层：路径导航层 (PathFinder)                           │
│  - A* 路径查找算法                                        │
└─────────────────────────────────────────────────────────┘
                    ↓
┌─────────────────────────────────────────────────────────┐
│  第一层：思考决策层 (ThinkTree)                            │
│  - 决策树驱动的行为选择                                    │
└─────────────────────────────────────────────────────────┘</code></pre><p>每一层都有其独特的职责，但它们并非孤立工作，而是通过精心设计的接口相互协作，形成一个完整的 AI 决策和执行系统。</p><h3>核心设计理念</h3><ol><li><strong>分层解耦</strong>：每一层专注于特定功能，降低系统复杂度</li><li><strong>优先级驱动</strong>：决策基于优先级，确保重要行为优先执行</li><li><strong>状态管理</strong>：通过状态机管理复杂的行为转换</li><li><strong>性能优化</strong>：使用启发式算法和缓存机制提升性能</li></ol><hr/><h2>第一层：思考决策层（ThinkTree 系统）</h2><p>思考决策层是 AI 系统的"大脑"，负责决定 NPC 应该做什么。它采用决策树（Decision Tree）结构，通过遍历节点来找到合适的行动。</p><h3>核心概念</h3><h4>ThinkNode（思考节点）</h4><p>ThinkNode 是决策树的基本单元，每个节点代表一个决策点或行为生成器。节点可以包含子节点，形成树状结构。</p><p><strong>节点类型</strong>：</p><ul><li><strong>ThinkNode_Priority</strong>：优先级节点，按顺序尝试子节点，返回第一个有效结果</li><li><strong>ThinkNode_JobGiver</strong>：工作生成器，负责创建具体的 Job</li><li><strong>ThinkNode_Conditional</strong>：条件节点，根据条件决定是否执行子节点</li><li><strong>ThinkNode_Subtree</strong>：子树节点，引用另一个思考树</li></ul><h4>ThinkTree（思考树）</h4><p>ThinkTree 定义了 NPC 的完整决策逻辑。每个 NPC 拥有两个思考树：</p><ul><li><strong>MainThinkTree</strong>：主要思考树，处理常规行为决策</li><li><strong>ConstantThinkTree</strong>：常量思考树，处理需要持续检查的行为（如紧急情况）</li></ul><h3>决策流程</h3><p>思考树的遍历遵循以下逻辑：</p><pre><code>function TryIssueJobPackage(pawn, jobParams):
    for each childNode in subNodes:
        result = childNode.TryIssueJobPackage(pawn, jobParams)
        if result.IsValid:
            return result
    return NoJob</code></pre><p><strong>关键特点</strong>：</p><ul><li><strong>优先级顺序</strong>：子节点按顺序评估，高优先级节点在前</li><li><strong>短路机制</strong>：一旦找到有效结果，立即返回，不再评估后续节点</li><li><strong>异常处理</strong>：单个节点异常不会影响整个决策流程</li></ul><h3>实际示例</h3><p>假设一个 NPC 需要决定下一步行动，思考树可能是这样的结构：</p><pre><code>ThinkNode_Priority (根节点)
├── ThinkNode_Conditional (检查是否有敌人)
│   └── ThinkNode_JobGiver_Attack (攻击敌人)
├── ThinkNode_Conditional (检查是否饥饿)
│   └── ThinkNode_JobGiver_Food (寻找食物)
├── ThinkNode_Conditional (检查是否需要休息)
│   └── ThinkNode_JobGiver_Rest (去休息)
└── ThinkNode_JobGiver_Wander (闲逛)</code></pre><p>NPC 会从上到下依次检查：</p><ol><li>如果有敌人 → 攻击</li><li>如果饥饿 → 找食物</li><li>如果需要休息 → 去休息</li><li>否则 → 闲逛</li></ol><h3>JobGiver 机制</h3><p>JobGiver 是连接思考层和执行层的桥梁。它负责：</p><ol><li>评估当前情况</li><li>决定是否应该生成某个 Job</li><li>创建并返回 Job 对象</li></ol><pre><code>class JobGiver_Attack:
    function TryGiveJob(pawn):
        target = FindBestTarget(pawn)
        if target == null:
            return null
        return CreateAttackJob(pawn, target)</code></pre><hr/><h2>第二层：路径导航层（PathFinder 系统）</h2><p>路径导航层负责计算 NPC 从当前位置到目标位置的移动路径。RimWorld 使用改进的 A* 算法来实现高效的路径查找。</p><h3>A* 算法基础</h3><p>A* 算法结合了 Dijkstra 算法的准确性（考虑实际成本）和贪心算法的效率（使用启发式估计）。</p><p><strong>核心公式</strong>：</p><pre><code>f(n) = g(n) + h(n)</code></pre><ul><li><code>g(n)</code>：从起点到节点 n 的实际成本</li><li><code>h(n)</code>：从节点 n 到终点的启发式估计成本</li><li><code>f(n)</code>：节点的总评估成本</li></ul><h3>RimWorld 的路径查找实现</h3><h4>成本计算</h4><p>路径查找会考虑多种因素来计算移动成本：</p><pre><code>function CalculateCellCost(cell, pawn):
    baseCost = GetTerrainCost(cell)           // 地形基础成本
    buildingCost = GetBuildingCost(cell)      // 建筑成本（门、墙等）
    avoidCost = GetAvoidGridCost(cell)        // 避让区域成本
    areaCost = GetAreaRestrictionCost(cell)   // 区域限制成本
    collisionCost = GetPawnCollisionCost(cell) // NPC碰撞成本
    
    return baseCost + buildingCost + avoidCost + areaCost + collisionCost</code></pre><p><strong>特殊处理</strong>：</p><ul><li><strong>门</strong>：根据是否可以打开、是否需要破坏来计算成本</li><li><strong>墙</strong>：如果允许破坏，成本 = 基础成本 + 墙体血量 × 系数</li><li><strong>避让网格</strong>：避免危险区域（如炮火覆盖区）</li></ul><h4>启发式函数</h4><p>RimWorld 使用八方向距离（Octile Distance）作为启发式：</p><pre><code>function OctileDistance(dx, dz, cardinalCost, diagonalCost):
    // dx, dz: x和z方向的差值
    // cardinalCost: 直线移动成本
    // diagonalCost: 斜线移动成本
    
    if dx &gt; dz:
        return diagonalCost * dz + cardinalCost * (dx - dz)
    else:
        return diagonalCost * dx + cardinalCost * (dz - dx)</code></pre><p><strong>启发式强度</strong>：</p><ul><li>动物：固定系数 1.75</li><li>人类：根据距离动态调整（距离越远，系数越大，最高 2.8）</li></ul><h4>区域路径优化</h4><p>当搜索节点数超过阈值时（殖民者 100,000，非殖民者 2,000），系统会切换到区域级路径查找：</p><pre><code>if nodesOpened &gt; threshold:
    // 切换到区域级路径查找
    regionCost = CalculateRegionPathCost(currentRegion, targetRegion)
    heuristic = regionCost * regionWeight</code></pre><p>这种优化可以显著减少大距离路径查找的计算量。</p><h3>路径执行</h3><p>找到路径后，<code>Pawn_PathFollower</code> 负责执行移动：</p><pre><code>function PatherTick():
    if WillCollideWithPawn(nextCell):
        if CanFindAlternatePath():
            RecalculatePath()
        else:
            WaitForPawn()
    
    if nextCellCostLeft &gt; 0:
        nextCellCostLeft -= CostToPayThisTick()
    else:
        MoveToNextCell()
        SetupNextCell()</code></pre><p><strong>移动速度控制</strong>：</p><ul><li><strong>Amble（漫步）</strong>：成本 × 3，最小 60 ticks</li><li><strong>Walk（步行）</strong>：成本 × 2，最小 50 ticks</li><li><strong>Jog（慢跑）</strong>：成本 × 1</li><li><strong>Sprint（冲刺）</strong>：成本 × 0.75</li></ul><hr/><h2>第三层：工作执行层（Job 系统）</h2><p>工作执行层将抽象的"做什么"转化为具体的"怎么做"。它通过 Job、JobDriver 和 Toil 三个层次来实现任务的执行。</p><h3>核心组件</h3><h4>Job（工作）</h4><p>Job 是任务的抽象描述，包含：</p><ul><li><strong>JobDef</strong>：工作类型定义（如攻击、建造、搬运）</li><li><strong>TargetA/B/C</strong>：工作目标（位置、物体、NPC等）</li><li><strong>expiryInterval</strong>：过期时间</li><li><strong>playerForced</strong>：是否玩家强制</li></ul><h4>JobDriver（工作驱动）</h4><p>JobDriver 负责执行 Job，它包含一系列 Toil（工作步骤）：</p><pre><code>class JobDriver_AttackMelee:
    function MakeNewToils():
        toils = []
        
        // Toil 1: 移动到目标附近
        toils.Add(Toils_Goto.Goto(TargetIndex.A, PathEndMode.Touch))
        
        // Toil 2: 等待直到可以攻击
        toils.Add(Toils_Combat.WaitUntilSuitableToAttack(TargetIndex.A))
        
        // Toil 3: 执行近战攻击
        toils.Add(Toils_Combat.MeleeAttack(TargetIndex.A))
        
        // Toil 4: 跳回 Toil 2（循环攻击）
        toils.Add(Toils_Jump.JumpIf(TargetIndex.A, IsValid, toils[1]))
        
        return toils</code></pre><h4>Toil（工作步骤）</h4><p>Toil 是最小的执行单元，每个 Toil 代表一个原子操作：</p><pre><code>Toil {
    initAction:      // 初始化时执行
    tickAction:      // 每 tick 执行
    endConditions:   // 结束条件检查
    defaultDuration: // 默认持续时间
    defaultCompleteMode: // 完成模式
}</code></pre><p><strong>完成模式</strong>：</p><ul><li><strong>Instant</strong>：立即完成</li><li><strong>Delay</strong>：延迟指定时间后完成</li><li><strong>PatherArrival</strong>：到达路径终点时完成</li><li><strong>FinishedBusy</strong>：忙碌状态结束时完成</li></ul><h3>工作执行流程</h3><pre><code>function JobTrackerTick():
    // 每 30 ticks 检查常量思考树
    if IsHashIntervalTick(30):
        constantJob = DetermineConstantThinkTreeJob()
        if constantJob.IsValid:
            StartJob(constantJob)
    
    // 执行当前工作
    if curDriver != null:
        curDriver.DriverTick()
        
        // 检查工作是否过期
        if curJob.IsExpired():
            EndCurrentJob(JobCondition.Succeeded)
    
    // 如果没有工作，寻找新工作
    if curJob == null:
        TryFindAndStartJob()</code></pre><h3>工作队列</h3><p>NPC 可以维护一个工作队列，支持：</p><ul><li><strong>EnqueueFirst</strong>：插入队列头部（高优先级）</li><li><strong>EnqueueLast</strong>：插入队列尾部（低优先级）</li><li><strong>Dequeue</strong>：取出下一个工作</li></ul><p>这允许玩家为 NPC 安排多个连续任务。</p><h3>工作中断与恢复</h3><p>工作可能因为以下原因中断：</p><ul><li><strong>更高优先级的工作</strong>：思考树生成新工作</li><li><strong>工作条件失效</strong>：目标消失、不可达等</li><li><strong>玩家强制</strong>：玩家手动分配新工作</li></ul><p>中断的工作可以：</p><ul><li><strong>完全取消</strong>：释放所有资源</li><li><strong>暂停并排队</strong>：如果工作可暂停，加入队列等待恢复</li></ul><hr/><h2>第四层：群体协调层（Lord 系统）</h2><p>群体协调层管理多个 NPC 的协同行为，如袭击、商队、防御等。它使用状态机（State Machine）来协调群体行为。</p><h3>核心概念</h3><h4>Lord（领主）</h4><p>Lord 代表一个群体，管理：</p><ul><li><strong>ownedPawns</strong>：属于该群体的 NPC 列表</li><li><strong>ownedBuildings</strong>：属于该群体的建筑列表</li><li><strong>curLordToil</strong>：当前状态</li><li><strong>graph</strong>：状态图</li></ul><h4>LordJob（领主工作）</h4><p>LordJob 定义群体的整体目标，如：</p><ul><li><strong>LordJob_DefendPoint</strong>：防御某个点</li><li><strong>LordJob_Travel</strong>：旅行</li><li><strong>LordJob_ExitMap</strong>：离开地图</li></ul><h4>LordToil（领主状态）</h4><p>LordToil 是状态机中的状态节点，定义群体在该状态下应该做什么：</p><pre><code>class LordToil_DefendPoint:
    function UpdateAllDuties():
        for each pawn in ownedPawns:
            duty = CreateDefendDuty(pawn, defendPoint)
            pawn.mindState.duty = duty</code></pre><h4>StateGraph（状态图）</h4><p>StateGraph 定义状态之间的转换关系：</p><pre><code>StateGraph {
    lordToils: [Toil1, Toil2, Toil3]
    transitions: [
        Transition(Toil1 -&gt; Toil2, [Trigger1, Trigger2]),
        Transition(Toil2 -&gt; Toil3, [Trigger3])
    ]
}</code></pre><h4>Trigger（触发器）</h4><p>Trigger 定义状态转换的条件：</p><pre><code>class Trigger_FractionPawnsLost:
    threshold: 0.5  // 50% 的 NPC 失去战斗力
    
    function CheckSignal(lord, signal):
        if signal.type == PawnLost:
            lostFraction = lord.numPawnsLostViolently / lord.numPawnsEverGained
            return lostFraction &gt;= threshold</code></pre><h3>状态转换流程</h3><pre><code>function LordTick():
    curJob.LordJobTick()
    curLordToil.LordToilTick()
    
    // 检查所有从当前状态出发的转换
    for each transition in graph.transitions:
        if transition.sources.Contains(curLordToil):
            if transition.CheckSignal(this, currentSignal):
                // 执行转换前的动作
                transition.preActions.Execute()
                
                // 转换到新状态
                GotoToil(transition.target)
                break</code></pre><h3>实际示例：袭击事件</h3><p>一个典型的袭击事件状态机：</p><pre><code>初始状态: LordToil_AssaultColony
├── Trigger: 50% NPC 失去战斗力
│   └── 转换到: LordToil_PanicFlee
│
├── Trigger: 所有目标建筑被摧毁
│   └── 转换到: LordToil_ExitMap
│
└── Trigger: 玩家投降
    └── 转换到: LordToil_ExitMap</code></pre><p>每个状态会为所有 NPC 设置相应的 Duty（职责），NPC 的思考树会根据 Duty 调整行为优先级。</p><hr/><h2>第五层：战斗决策层（AttackTargetFinder）</h2><p>战斗决策层负责在战斗中选择最佳攻击目标。它使用评分系统来评估每个潜在目标。</p><h3>目标选择流程</h3><pre><code>function BestAttackTarget(searcher, flags, validator):
    // 1. 获取所有潜在目标
    candidates = GetPotentialTargets(searcher)
    
    // 2. 过滤不符合条件的目标
    validTargets = FilterTargets(candidates, flags, validator)
    
    // 3. 计算每个目标的评分
    scoredTargets = []
    for each target in validTargets:
        score = CalculateTargetScore(searcher, target)
        scoredTargets.Add((target, score))
    
    // 4. 根据评分选择目标
    return SelectBestTarget(scoredTargets)</code></pre><h3>目标过滤条件</h3><p>目标必须满足以下条件才能被考虑：</p><ol><li><strong>敌对关系</strong>：必须是敌对目标</li><li><strong>距离范围</strong>：在攻击范围内</li><li><strong>视线</strong>：如果需要，必须有视线</li><li><strong>威胁状态</strong>：目标必须是活跃威胁</li><li><strong>可达性</strong>：如果要求，目标必须可达</li></ol><h3>评分系统</h3><p>评分考虑多个因素：</p><pre><code>function CalculateTargetScore(searcher, target):
    score = 0
    
    // 基础威胁值
    score += target.ThreatValue
    
    // 距离因子（越近分数越高）
    distance = Distance(searcher, target)
    score += 1.0 / (distance + 1.0) * distanceWeight
    
    // 目标类型偏好
    if target.IsPawn:
        score += pawnTargetBonus
    if target.IsBuilding:
        score += buildingTargetBonus
    
    // 友军误伤惩罚
    friendlyFireRisk = CalculateFriendlyFireRisk(searcher, target)
    score -= friendlyFireRisk * friendlyFirePenalty
    
    // 目标当前状态
    if target.IsDowned:
        score -= downedPenalty
    if target.IsBurning:
        score -= burningPenalty
    
    return score</code></pre><p><strong>友军误伤计算</strong>：</p><ul><li>人类/机械：每个 +18 分惩罚</li><li>动物：每个 +7 分惩罚</li><li>非 NPC 物体：每个 +10 分惩罚</li><li>自己：+40 分惩罚</li></ul><h3>远程 vs 近战</h3><p>系统会根据攻击类型采用不同的选择策略：</p><p><strong>远程攻击</strong>：</p><ul><li>优先选择可以立即射击的目标</li><li>考虑射击位置（CastPosition）</li><li>评估友军误伤风险</li></ul><p><strong>近战攻击</strong>：</p><ul><li>优先选择距离最近的目标</li><li>考虑移动成本</li><li>评估近战威胁等级</li></ul><hr/><h2>层次间协作机制</h2><p>五个层次并非独立工作，而是通过精心设计的接口相互协作。下面详细说明它们如何协同工作。</p><h3>思考层 → 工作层</h3><p>思考层通过 JobGiver 生成 Job，传递给工作层：</p><pre><code>ThinkTree 遍历
    ↓
JobGiver.TryGiveJob()
    ↓
创建 Job 对象
    ↓
JobTracker.StartJob()
    ↓
创建 JobDriver
    ↓
执行 Toil 序列</code></pre><p><strong>示例</strong>：NPC 决定攻击敌人</p><ol><li>ThinkTree 遍历到 <code>ThinkNode_JobGiver_Attack</code></li><li>JobGiver 调用 <code>AttackTargetFinder.BestAttackTarget()</code> 找到目标</li><li>创建 <code>Job_AttackMelee</code>，目标设置为找到的敌人</li><li>JobTracker 创建 <code>JobDriver_AttackMelee</code></li><li>JobDriver 开始执行攻击 Toil</li></ol><h3>工作层 → 路径层</h3><p>当工作需要移动时，会调用路径查找：</p><pre><code>JobDriver.Toil_Goto
    ↓
pawn.pather.StartPath(destination)
    ↓
PathFinder.FindPath()
    ↓
返回 PawnPath
    ↓
Pawn_PathFollower 执行移动</code></pre><p><strong>示例</strong>：NPC 执行"去攻击"工作</p><ol><li>JobDriver 的第一个 Toil 是 <code>Toils_Goto.Goto(target)</code></li><li>Toil 调用 <code>pawn.pather.StartPath(target.Position)</code></li><li>PathFinder 计算路径</li><li>PathFollower 每 tick 移动一步</li></ol><h3>群体层 → 思考层</h3><p>群体层通过 Duty 影响思考层的决策：</p><pre><code>Lord 设置 Duty
    ↓
pawn.mindState.duty = newDuty
    ↓
ThinkTree 中的条件节点检查 Duty
    ↓
根据 Duty 调整行为优先级</code></pre><p><strong>示例</strong>：袭击事件中的 NPC</p><ol><li>Lord 处于 <code>LordToil_AssaultColony</code> 状态</li><li>为所有 NPC 设置 <code>PawnDuty</code>，duty.focus = 玩家基地</li><li>NPC 的思考树中有 <code>ThinkNode_Conditional_HasDuty</code></li><li>该节点激活，NPC 优先执行与 Duty 相关的行为（攻击、破坏等）</li></ol><h3>战斗层 → 工作层</h3><p>战斗层为工作层提供目标选择服务：</p><pre><code>JobGiver 需要攻击目标
    ↓
调用 AttackTargetFinder.BestAttackTarget()
    ↓
返回最佳目标
    ↓
创建攻击 Job</code></pre><h3>完整协作流程示例</h3><p>假设一个 NPC 参与袭击事件，需要攻击玩家基地：</p><pre><code>1. 群体层（Lord）：
   - Lord 处于 "AssaultColony" 状态
   - 为 NPC 设置 Duty：攻击玩家基地

2. 思考层（ThinkTree）：
   - 检查 Duty，发现需要攻击
   - JobGiver_Attack 被激活

3. 战斗层（AttackTargetFinder）：
   - JobGiver 调用 BestAttackTarget()
   - 找到最佳攻击目标（玩家 NPC）

4. 工作层（Job）：
   - 创建 Job_AttackMelee
   - JobDriver 开始执行

5. 路径层（PathFinder）：
   - JobDriver 的第一个 Toil 需要移动到目标
   - 调用 PathFinder 计算路径
   - PathFollower 执行移动

6. 工作层继续：
   - 到达目标后，执行攻击 Toil
   - 循环攻击直到目标死亡或工作被中断

7. 群体层监控：
   - 如果 NPC 死亡，Lord 收到通知
   - 检查是否触发状态转换（如撤退）</code></pre><hr/><h2>实际案例：完整行为流程</h2><p>让我们通过一个完整的游戏场景来理解整个 AI 系统如何协同工作。</p><h3>场景：NPC 袭击玩家基地</h3><h4>阶段 1：袭击开始</h4><p><strong>群体层初始化</strong>：</p><pre><code>Lord 创建
├── LordJob = LordJob_AssaultColony
├── 初始状态 = LordToil_AssaultColony
└── 添加所有袭击者 NPC 到 ownedPawns</code></pre><p><strong>为每个 NPC 设置 Duty</strong>：</p><pre><code>for each pawn in ownedPawns:
    duty = new PawnDuty {
        def = DutyDefOf.AssaultColony,
        focus = playerBaseCenter,
        radius = 50
    }
    pawn.mindState.duty = duty</code></pre><h4>阶段 2：NPC 决策</h4><p><strong>思考树遍历</strong>（以袭击者 NPC 为例）：</p><pre><code>ThinkNode_Priority (根节点)
├── ThinkNode_Conditional_HasDuty
│   ├── 检查：pawn.mindState.duty != null ✓
│   └── ThinkNode_SubtreesByTag
│       └── 根据 Duty 类型加载相应子树
│           └── ThinkNode_JobGiver_Attack
│               ├── 调用 AttackTargetFinder.BestAttackTarget()
│               ├── 找到目标：玩家 NPC "Alice"
│               └── 返回 Job_AttackMelee(Alice)</code></pre><h4>阶段 3：目标选择</h4><p><strong>AttackTargetFinder 工作流程</strong>：</p><pre><code>1. 获取所有潜在目标
   candidates = [玩家NPC1, 玩家NPC2, 炮塔1, 建筑1, ...]

2. 过滤目标
   - 检查敌对关系 ✓
   - 检查距离（在武器射程内）✓
   - 检查视线 ✓
   - 检查威胁状态 ✓
   validTargets = [玩家NPC1, 玩家NPC2, 炮塔1]

3. 计算评分
   玩家NPC1: 威胁值=50, 距离=20, 误伤风险=0 → 总分=70
   玩家NPC2: 威胁值=45, 距离=25, 误伤风险=18 → 总分=52
   炮塔1: 威胁值=60, 距离=30, 误伤风险=0 → 总分=60

4. 选择最佳目标
   返回：玩家NPC1（分数最高）</code></pre><h4>阶段 4：工作执行</h4><p><strong>Job 创建与启动</strong>：</p><pre><code>Job job = new Job_AttackMelee {
    targetA = 玩家NPC1,
    maxNumMeleeAttacks = -1,  // 无限攻击
    expiryInterval = -1
}

JobTracker.StartJob(job)</code></pre><p><strong>JobDriver 执行 Toil 序列</strong>：</p><pre><code>Toil 1: Toils_Goto.Goto(targetA, PathEndMode.Touch)
├── 调用 pawn.pather.StartPath(玩家NPC1.Position)
├── PathFinder 计算路径
│   ├── 起点：袭击者位置 (100, 0, 50)
│   ├── 终点：玩家NPC1位置 (150, 0, 80)
│   ├── 路径：[(100,0,50) → (110,0,55) → ... → (150,0,80)]
│   └── 总成本：450 ticks
└── PathFollower 开始移动

Toil 2: Toils_Combat.WaitUntilSuitableToAttack(targetA)
├── 检查：是否到达目标附近？
├── 检查：目标是否仍然有效？
└── 等待直到条件满足

Toil 3: Toils_Combat.MeleeAttack(targetA)
├── 执行近战攻击动画
├── 计算伤害
│   ├── 基础伤害值（根据武器和 NPC 属性）
│   ├── 随机因子（0.8 - 1.2 倍）
│   ├── 护甲穿透值
│   └── 伤害类型（切割、钝击、刺击等）
├── 应用伤害到目标
│   ├── 检查是否命中（考虑命中率）
│   ├── 检查是否被闪避
│   ├── 如果命中：调用 target.TakeDamage(damageInfo)
│   ├── 更新战斗日志
│   └── 播放音效和视觉效果
└── 跳回 Toil 2（循环攻击）</code></pre><h4>阶段 5：状态更新与反馈</h4><p><strong>工作完成检查</strong>：</p><pre><code>每 tick 检查：
├── 目标是否死亡？ → 结束工作
├── 目标是否离开地图？ → 结束工作
├── 工作是否过期？ → 结束工作
└── 否则继续攻击循环</code></pre><p><strong>群体层状态更新</strong>：</p><pre><code>Lord 监控：
├── 统计伤亡情况
├── 检查触发条件
│   ├── 如果 50% NPC 失去战斗力 → 触发撤退
│   ├── 如果目标完成 → 触发离开地图
│   └── 否则继续当前状态
└── 更新所有 NPC 的 Duty</code></pre><h2>总结</h2><p>RimWorld 的 NPC AI 系统通过五个层次的精心设计，实现了复杂而高效的行为决策和执行机制。每个层次都有其独特的职责，同时通过清晰的接口相互协作。</p><h3>系统特点回顾</h3><ol><li><p><strong>分层架构</strong>：</p><ul><li>思考决策层：决定"做什么"</li><li>路径导航层：解决"怎么走"</li><li>工作执行层：实现"怎么做"</li><li>群体协调层：协调"一起做"</li><li>战斗决策层：选择"打哪个"</li></ul></li><li><p><strong>优先级驱动</strong>：</p><ul><li>思考树按优先级顺序评估节点</li><li>高优先级行为（如战斗）会中断低优先级行为（如工作）</li><li>确保 NPC 能够及时响应紧急情况</li></ul></li><li><p><strong>状态管理</strong>：</p><ul><li>Lord 系统使用状态机管理群体行为</li><li>通过 Trigger 实现状态转换</li><li>支持复杂的事件流程（如袭击、商队等）</li></ul></li><li><p><strong>性能优化</strong>：</p><ul><li>A* 算法使用启发式函数加速路径查找</li><li>区域级路径优化减少大距离路径的计算量</li><li>思考树使用短路机制避免不必要的评估</li></ul></li></ol><h3>关键概念速查</h3><table><thead><tr><th>概念</th><th>层级</th><th>作用</th></tr></thead><tbody><tr><td>ThinkNode</td><td>第一层</td><td>决策树节点，决定行为选择</td></tr><tr><td>ThinkTree</td><td>第一层</td><td>完整的决策逻辑树</td></tr><tr><td>JobGiver</td><td>第一层</td><td>连接思考层和工作层的桥梁</td></tr><tr><td>PathFinder</td><td>第二层</td><td>A* 路径查找算法实现</td></tr><tr><td>Job</td><td>第三层</td><td>任务的抽象描述</td></tr><tr><td>JobDriver</td><td>第三层</td><td>任务的执行驱动</td></tr><tr><td>Toil</td><td>第三层</td><td>最小的执行单元</td></tr><tr><td>Lord</td><td>第四层</td><td>群体管理器</td></tr><tr><td>LordToil</td><td>第四层</td><td>群体状态节点</td></tr><tr><td>StateGraph</td><td>第四层</td><td>状态转换图</td></tr><tr><td>AttackTargetFinder</td><td>第五层</td><td>战斗目标选择器</td></tr></tbody></table><h3>设计优势</h3><ol><li><strong>模块化</strong>：每个层次可以独立理解、测试和修改</li><li><strong>可扩展</strong>：新行为可以通过添加新的 ThinkNode 或 JobDriver 实现</li><li><strong>可维护</strong>：清晰的层次划分使代码易于维护</li><li><strong>性能</strong>：优化的算法和缓存机制确保游戏流畅运行</li></ol><h3>实际应用</h3><p>理解这个 AI 系统对于：</p><ul><li><strong>Mod 开发者</strong>：可以创建自定义行为、工作类型和群体事件</li><li><strong>游戏设计师</strong>：可以调整 AI 参数来平衡游戏难度</li><li><strong>玩家</strong>：可以更好地理解 NPC 行为，制定策略</li></ul><h3>进一步探索</h3><p>如果你想深入了解某个特定方面，可以：</p><ul><li>查看源代码中的具体实现细节</li><li>通过游戏日志观察 AI 决策过程</li><li>使用开发工具（如 Dev Mode）测试不同场景</li><li>参考 RimWorld 的 Mod 开发文档</li></ul>]]></description></item><item>    <title><![CDATA[Python 3.14 实用技巧：10个]]></title>    <link>https://segmentfault.com/a/1190000047403453</link>    <guid>https://segmentfault.com/a/1190000047403453</guid>    <pubDate>2025-11-16 23:02:35</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>Python 3.14 引入的改进大多数都很细微，但这些小变化会让代码写起来更流畅，运行也更稳定。本文整理了 10 个实用的特性改进，每个都配了代码示例。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047403455" alt="" title=""/></p><h2>1、TypedDict 的 NotRequired 类型标注</h2><p>配置字典里的可选字段以前处理起来比较麻烦，现在有了明确的标注方式。</p><pre><code> from typing import TypedDict, NotRequired  
 class Config(TypedDict):  
     name: str  
     interval: int  
     debug: NotRequired[bool]</code></pre><p>字典验证变得更清晰，少了很多"忘记加这个键"导致的运行时错误。</p><p>如果你的自动化脚本对配置文件依赖很重，脚本的可选字段一眼就能看出来，所以这个改动非常的方便。</p><h2>2、类型窄化的静态分析增强</h2><p>3.14 版本的静态分析已经做得更好了，编辑器能在代码运行前就发现一些逻辑问题。</p><pre><code> def process(x: int | str):  
     if isinstance(x, int):  
         return x + 1  # Editor now knows x is int here</code></pre><p>类型检查器能帮你减轻不少智负担，半年后回来看代码也能快速理解。</p><h2>3、延迟导入优化</h2><p>依赖项多的脚本启动慢是个常见问题。Python 3.14 在导入解析和延迟加载上做了优化。</p><pre><code> import importlib  
 pandas = importlib.import_module("pandas")</code></pre><p>这么写导入，程序的启动速度能快一些同时也避免了加载用不到的模块。</p><h2>4. 错误消息改进</h2><p>错误提示终于说人话了。</p><pre><code> items = [1, 2, 3]  
 print(items[3])</code></pre><p>3.14 的报错信息：</p><blockquote><strong><em>IndexError:</em></strong><em>list index out of range (list has length 3, index 3 is invalid)</em></blockquote><p>现在的错误提示会直接告诉你列表长度和无效索引，调试效率提升明显。</p><h2>5、contextlib.chdir() 上下文管理器</h2><p>这是一个新增的功能很实用但容易被忽略。</p><pre><code> from contextlib import chdir  
 with chdir("logs"):  
     open("deephub.txt").write("done")</code></pre><p>文件操作时切换目录变得简洁了，不用再写</p><pre><code>os.getcwd()</code></pre><p>那套东西。</p><h2>6、异步任务取消机制改进</h2><p>并发编程在自动化场景下很常见，异步任务取消以前调试起来很头疼。</p><pre><code> import asyncio  
 async def worker():   
     await asyncio.sleep(5)  
 task = asyncio.create_task(worker())  
 task.cancel()</code></pre><p>而现在清理过程处理得更稳妥，不会像以前那样抛出奇怪的异常。</p><h2>7、紧凑帧对象优化递归</h2><p>处理递归场景（JSON 解析、目录遍历、XML 处理等）时稳定性提升了。</p><pre><code> def walk(n):   
     return n if n == 0 else walk(n - 1)</code></pre><p>运行更顺畅，内存占用也更合理。</p><h2>8、subprocess 环境变量隔离</h2><p>3.14 加强了子进程的环境变量隔离。</p><pre><code> import subprocess  
 subprocess.run(["python", "--version"], check=True)</code></pre><p>避免了不该传递的环境变量泄漏到子进程，对自动化脚本的安全性非常有帮助。</p><h2>9、模式匹配错误提示优化</h2><p>模式匹配的错误信息变得更详细了。</p><pre><code> match data:  
     case {"deep hub": name, "age": age}:  
         ...</code></pre><p>无效模式会给出具体的错误提示而不是含糊的信息，团队协作时调试起来方便很多。</p><h2>10、导入耗时分析</h2><p>对做自动化开发的人来说这个功能挺有用。</p><pre><code> importimportlib.util, time  
 start=time.perf_counter()  
 importlib.util.find_spec("numpy")  
 print(time.perf_counter() -start)</code></pre><p>因为它能快速定位哪些导入拖慢了启动速度，初始化逻辑也能做针对性优化。</p><h2>总结</h2><p>这些特性单独看都不算特别亮眼，也不是那种能拿出去炫耀的东西。但是整洁的代码不是靠引入大型框架写出来的，而是日常编码习惯积累出来的。Python 3.14 提供的这些改进就属于这类，用多了之后会慢慢内化成习惯。</p><p>这 10 个特性看着不起眼，但在几十个脚本里用起来之后：调试时间少了，代码审查快了，运行也更稳定了，而且这些改善基本不需要额外的工作量。</p><p>代码库想变得更轻量、更好维护，升级到 Python 3.14 是个不错的选择。凌晨两点调试代码的时候，会感谢做出这个决定的自己。</p><p><a href="https://link.segmentfault.com/?enc=e1kr363VJg8REStv%2Bj8XBg%3D%3D.%2Ff%2BmZDaR0xOP62T5PmhVmOq79WK6prVzIgfKpkTr5dghRyynHXi6ed1PMOyyNTmefFGjtkvMFI6inwyLzUObdg%3D%3D" rel="nofollow" target="_blank">https://avoid.overfit.cn/post/8312efd2a1e94496be1c636ab538cb38</a></p><p>作者：Arfa</p>]]></description></item><item>    <title><![CDATA[在富阳银湖成立地域化的软件研发团队 欧雷]]></title>    <link>https://segmentfault.com/a/1190000047403487</link>    <guid>https://segmentfault.com/a/1190000047403487</guid>    <pubDate>2025-11-16 23:02:04</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>随着 11 月的到来，银湖创联也已步入它生命进程中的第二阶段。</p><p>与混沌初开，一切以「先跑起来再说」为主旋律的第一阶段相比，当前阶段的主旋律，或者说核心目标是——通过简单的规则和治理单元，形成自组织、自生长的系统。</p><p>作为社区的发起人兼主理人，我这几天在很适合移动办公的瑞咖啡里对之前一些较为零星散乱的想法进行梳理，有了一个初步的清单。</p><p>打算进一步讨论完善后，召开一次宣讲会，与心系社区的人之间来一场即时的答疑与反馈，他们同时也是新阶段的第一批潜在合作者。</p><p>然而在那之前，清单中的一项完全可以立马就行动起来，也就是本文的主题。</p><h2>软件开发小组成立</h2><p>在「小雇·全国自由职业者大会·杭州站」上进行的主题分享《<a href="https://segmentfault.com/a/1190000047336860" target="_blank">典型程序员跨界做在地社区是怎样一种体验？</a>》中，临结束时有这样一段：</p><p><img width="723" height="457" referrerpolicy="no-referrer" src="/img/bVdm3Yv" alt="" title=""/></p><p>三个主要价值点中的第一个，它是：</p><ul><li>最表层的——大家有直观感受的，很容易想到和理解的；</li><li>最基础的——是实现并发挥另外两个价值点的基石，它们比较有前瞻性、创新性，解释成本更高，但落地后的价值不可估量。</li></ul><p>用更通俗点的说法，第一个价值点是以在地自由职业者为引，通过相互连接重建以信任为基础的新型熟人社会，并展现了通过自由职业实现自我价值的可行性。</p><p>再依托于信任关系、个人专业性去探索区域内可自循环的消费服务体系、商业模式，并借助更加一体化、数智化的手段提升区域内信息与资源流通的效率和体验。</p><p>另外两个价值点，要么完全依赖于软件开发，要么跟软件开发也很有关系。</p><p>在过往的社区活动中，多次参加活动进行交流且以软件开发作为职业的人，算我在内目前有三人：</p><ul><li>我，数智生活领域独立开发者，前端开发出身，擅长抽象，一直想要解决数据所有权与控制权、一体化和数智化问题；</li><li>一个 XR、3D 开发者，擅长虚拟世界与现实世界通过某种形式在图形上进行融合；</li><li>一个从良渚搬过来的 AI 连续创业者，想做数智化、游戏化的人生系统。</li></ul><p>由此可见，我们仨的共同点：</p><ul><li>侧重有所不同，但都是软件开发者；</li><li>擅长不同方面，但想解决的问题都可归为「元宇宙」；</li><li>都生活在银湖。</li></ul><p>既然如此，那我们为啥不凝聚在一起，成立「银湖软件开发小组」呢？！</p><p>这样一来：</p><ul><li>对外——以小组作为统一的信息出入口，进行社区第三阶段要落地的线上系统的研发，承接来自银湖在地企业、商家、工作室/超级个体的软件研发需求；</li><li>对内——软件研发需求信息共享，适者弹性组队承包项目，按项目自行分配收益，也可以自行组队研发其他软件产品。</li></ul><p>简而言之，一方面我们组成了面向银湖在地潜在客户的软件研发专业团队，另一方面能够相互协作让想要开发的软件产品更快地落地并进行市场验证。</p><p>今天下午，我们相聚在其中一人家里，将自己的想法向他们描述，一番讨论后达成 2 个共识：</p><ol><li>可以成立「银湖软件开发小组」；</li><li>在进行「元宇宙」落地实验这件事上分头行动，即我先去做社区场景的线上系统，他们先做个人与家庭场景的设备与应用，然后再将关键数据打通而场景融合。</li></ol><p>没准儿事后回首，这就是另一个湖畔花园！</p><h2>结语</h2><p>开篇提到的「完全可以立马就行动起来」的「清单中的一项」是「在地的以特定兴趣爱好/专业能力/业务领域为核心的垂直小团体」。</p><p>而「银湖软件开发小组」就是具体例子，也是银湖创联的第一个专项小组（小团体），但这肯定不是最后一个，还会有更多的垂直小团体相继成立！</p><p>除了从银湖创联中生长出来的垂直小团体外，也欢迎那些本来就存在且与银湖有千丝万缕联系的其他兴趣组（如「富Young·团趣社」）之类加入到银湖创联这个大网络中！</p><hr/><p>本文其他阅读地址：<a href="https://link.segmentfault.com/?enc=I4NifA%2Bo9N4sfAXJy6p%2B8w%3D%3D.20w%2BnA8qD%2BzUUgKDKycpxlaQM2pyFErSZE4GIUhOVoSxrarZSFVo6LDZhtGCW0fi" rel="nofollow" target="_blank">个人网站</a>｜<a href="https://link.segmentfault.com/?enc=SjRt5FhGceac019ditPJrA%3D%3D.9drajjp8WUHj6oPtz7D5QcWv84eoke5KOUJcL6TqfGKEUmyHOekX6JmFh6Szsc228XZ2k3g3K0L7GSjjHL7mkw%3D%3D" rel="nofollow" target="_blank">微信公众号</a></p>]]></description></item><item>    <title><![CDATA[这为专门从事 AI 留胡子的饼干_dli]]></title>    <link>https://segmentfault.com/a/1190000047403498</link>    <guid>https://segmentfault.com/a/1190000047403498</guid>    <pubDate>2025-11-16 23:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>从生成式 AI 的惊艳亮相引起全球科技巨头军备竞赛般的投入开始，整个 AI 行业仿佛被注入了无限的想象力。似乎在宣告着即将出现一个生产力即将被彻底解放、商业模式即将被完全颠覆的光明未来。<br/>微软、谷歌、亚马逊等云巨头纷纷将资本支出的绝大部分押注于 AI 基础设施建设，而无数逐利而来的 AI 初创公司，更是如雨后春笋般涌现试图分一杯羹，全球 AI 领域的投资额也达到了史无前例的高度。<br/>然而，正如任何过热的淘金热最终都会迎来冷静期当技术以超乎预期的速度普及时，潜在的负面效应也以同样的速度被放大，正在悄然侵蚀着行业参与者。<br/>从 " 可选项 " 到 " 必选项 " 的巨额支出<br/>根据奇安信集团对外发布《2024 人工智能安全报告》来看，在 2023 年基于 AI 的深度伪造欺诈便已暴增了 3000%，基于 AI 的钓鱼邮件也增长了 1000%；而内容生成环节更是实现规模化生产。<br/>基于 Stable Diffusion 和 GPT-4 的定制模型，可每小时生成 2000 条伪原创研报、800 段逼真视频。暗网平台 "DarkGPT" 更是提供包月服务，1 万美元即可获得每日 5000 条金融虚假内容的产能。<br/>而且 "AI 滥用 " 的后遗症并不仅仅在社会新闻版块，可以说它已经穿透了科技公司的防火墙直接作用于其财务报表。而金融行业正是这场风暴的中心，当 AI 以假乱真的能力被精准地应用于金融诈骗时，其破坏力可以说是指数级的增长。<br/>据行业估算，2024 年由深度伪造技术引发的各类欺诈造成的全球经济损失已高达 120 亿美元。尤其在监管相对滞后、交易更为匿名的加密货币领域，AI 滥用更是如鱼得水。根据相关的报告也显示 2024 年仅 AI 深度伪造技术全年造成的损失便高达 46 亿美元。<br/>随着 AI 滥用事件的频发，过去模糊的 " 伦理指南 " 正在迅速转变为具有强制约束力的法律条文，而且这种转变直接导致了企业合规成本的急剧攀升。<br/>而且一旦出现违规需要付出的代价更是惨痛的，罚款最高可达全球年营业额的数个百分点或数千万欧元，而且合规也不再是法务部门的单一工作，而是渗透到研发、产品、市场的每一个环节。<br/>这些 " 反噬 " 也并非凭空产生，在 AI 商业化过程中对速度和规模的追求，长期以来压倒了对安全和伦理的考量所以形成了这种 " 原罪 "。因此未来合规成本的升高是不可避免的，而欧盟的《AI 法案》可以说是这一趋势的先行者。<br/>该法案于 2024 年 8 月 1 日正式生效并分阶段实施，着重对高风险的 AI 系统施加了严格的合规要求。而且这不仅仅是一项区域性法规，更可能产生 " 布鲁塞尔效应 " 从而影响全球的 AI 监管格局。<br/>监管的落地也将会直接转化为企业的合规成本。据公开信息推算，仅欧盟 AI 法案便可能导致欧洲企业的 AI 采纳成本增加约 310 亿欧元，并使 AI 投资减少近 20%。而美国联邦贸易委员会也已对 OpenAI 展开调查，谷歌等公司也不得不调整其营销话术，避免被处以巨额罚款。<br/>可以说 " 监管的铁幕 " 正在迫使整个行业从过去 " 快速行动，打破陈规 " 的互联网思维转向一种更为审慎、合规驱动的开发模式。可以说这种转变无疑会减缓创新速度并增加运营成本，对于那些资源有限的中小企业和初创公司构成尤为严峻的挑战。<br/>对 " 信任 " 的侵蚀或许是 AI 滥用最难修复的一种<br/>这源于在激烈的竞争压力下，企业急于抢占市场将产品快速推向用户，所以将风险控制和安全测试置于次要位置。但是这种 " 快速行动并打破规则 " 的心态在 AI 时代尤为危险，因为 AI 技术的潜在破坏力远超以往的软件应用。<br/>并且市场对于 AI 技术的可靠性极度敏感，甚至一次小小的失误都可能引发巨大的信任危机和财务损失。谷歌的 Bard 模型之前便在一次演示中出现事实性错误，竟然导致其母公司 Alphabet 的股价在单日内暴跌 7%，市值蒸发超过 1000 亿美元。<br/>并且随着 AI 投资的巨额支出持续攀升，投资者开始担忧其回报前景，这种悲观情绪导致 Meta、Microsoft、Alphabet 和 Nvidia 等 AI 领域的领军企业股价普遍承压下跌，市场也开始讨论 "AI 泡沫 " 的风险，并开始质疑哪些不计成本的 " 军备竞赛 " 式投资。<br/>更何况大量公司缺乏对 AI 伦理的明确责任归属，高管层面也并未对其有所调整。所以 AI 系统的决策过程像一个 " 黑箱 "，在责任主体模糊的情况下滥用和误用的风险便难以控制。企业内部也未建立有效的问责机制。<br/>但是更深层次的原因在于当前主流生成式 AI 商业模式本身所内含的风险。这些模型依赖于海量数据的投喂，其训练过程难以完全避免偏见和有害信息的吸收。而其强大的生成能力却为恶意利用提供了温床。<br/>因此当商业模式的核心是追求更强大的模型、更广泛的应用时，如果缺乏与之匹配的强大 " 安全刹车 " 系统，滥用就成了可预见的副产品。这种商业逻辑与伦理要求之间的结构性失衡才是导致 " 反噬 " 的根本内因。<br/>所以当企业享受了技术红利带来的增长，如今便也不得不为其模式所伴生的风险 " 买单 "。哪怕科技公司以 " 让世界更美好 " 的叙事推广 AI，公众在实际体验中，也会频繁受到隐私泄露、算法偏见、就业替代、虚假信息等负面影响。<br/>这种落差也导致了广泛的 "AI 焦虑 " 和不信任感。公众普遍认为现有的监管法规不足以应对 AI 带来的社会风险期望政府采取更加果断的行动。这种强大的民意压力也是推动监管机构加速行动的根本动力。<br/>面对公众的呼声和潜在的社会风险，监管机构的介入是必然的。但由于技术发展的速度远超立法速度监管往往表现出一定的滞后性，欧盟 AI 法案便被部分人士认为可能增加企业负担、抑制创新。<br/>全球主要经济体在 AI 领域的竞争，也使得监管变得更加复杂。各国都希望在鼓励创新和防范风险之间找到平衡点但这种平衡点的位置各不相同，因此形成了复杂的国际监管格局给跨国企业的合规带来了巨大挑战。<br/>而且这种外部滥用对整个 AI 行业的声誉造成了 " 连坐 " 效应。即使一家公司本身恪守伦理，也无法完全独善其身，因为公众对 AI 的信任是整体性的。恶意滥用行为如同向池塘中投下的毒药，在污染了整个水域后迫使所有 " 池中生物 " 共同承担后果。<br/>这场危机成为 AI 自我革新的契机<br/>这场 " 反噬 " 带来的阵痛，是 AI 产业从野蛮生长走向规范发展的必经阶段。它正在淘汰那些只想赚快钱、缺乏责任感的 " 玩家 "，筛选出真正有实力、有远见的长期主义者。从长远来看，这也是为 AI 产业的健康、可持续发展所必须付出的代价。<br/>其中最大的机遇在于将 " 信任 " 从一种道德呼吁，转变为一种可量化、可变现的商业资产和竞争壁垒。数据显示近 85% 的客户也更愿意与重视 AI 伦理实践的公司合作，而那些优先考虑伦理和透明度的公司收入增长也更快。<br/>可以说在 AI 产品同质化日益严重的未来，谁能赢得用户的信任谁就能赢得市场。" 负责任的 AI" 将不再仅仅是公关部门的口号，而是必须贯穿于产品设计、开发、部署全流程的核心战略。<br/>谷歌和微软等公司已经开始调整其策略，谷歌选择利用 AI 技术提升广告安全审核的效率，打击欺诈内容；微软则发布了负责任 AI 透明度报告，并推出了 AzureAIContentSafety 等服务，帮助客户构建更安全的 AI 应用。这些举措既是应对风险的防御，也是在构建新的竞争优势。<br/>正是 " 反噬 " 催生了全新的 " 安全即服务 " 市场。随着 AI 滥用风险的加剧企业对 AI 安全审计、风险评估、内容过滤、合规咨询等服务的需求将急剧增长。这为专门从事 AI 安全和伦理治理的科技公司、咨询机构创造了巨大的市场空间。<br/>而科技巨头自身也可以将其内部成熟的安全工具和能力平台化、服务化，开拓新的收入来源。例如，谷歌和微软在内容审核、风险识别方面的技术积累，完全可以转化为对外输出的商业服务。<br/>虽然监管的收紧虽然带来了成本，但也为行业设定了 " 准入标准 "，能够率先满足高标准合规要求的企业将获得更强的市场公信力和竞争优势，从而在未来的市场整合中占据有利地位。这实际上是一种由监管驱动的市场出清和格局优化。weibo.com/ttarticle/p/show?id=2309405233698940518650<br/>weibo.com/ttarticle/p/show?id=2309405233699078930694<br/>weibo.com/ttarticle/p/show?id=2309405233699812933758<br/>weibo.com/ttarticle/p/show?id=2309405233699951608477<br/>weibo.com/ttarticle/p/show?id=2309405233700090020020<br/>weibo.com/ttarticle/p/show?id=2309405233700232626572<br/>weibo.com/ttarticle/p/show?id=2309405233700899520919<br/>weibo.com/ttarticle/p/show?id=2309405233701042127096<br/>weibo.com/ttarticle/p/show?id=2309405233703034159184<br/>从滥用事件的激增，到资本市场的审慎，再到全球监管的收紧，这股 " 反噬 " 之力正在重塑 AI 产业的发展轨迹。它迫使整个行业从过去对技术力量的无限崇拜，转向对技术责任和社会价值的深刻反思。<br/>麦肯锡预测，到 2030 年 AI 将为全球经济创造 13 万亿美元价值。但价值分配取决于我们如何驾驭这头猛兽。未来的竞争，将不仅仅是模型参数和算力大小的竞争，更是治理能力、责任担当和用户信任的竞争。</p>]]></description></item><item>    <title><![CDATA[深入探索剖析 JVM 的启动过程 程序猿]]></title>    <link>https://segmentfault.com/a/1190000047403401</link>    <guid>https://segmentfault.com/a/1190000047403401</guid>    <pubDate>2025-11-16 22:02:17</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>你可曾想过：当你在终端里敲下 <code>java</code>，在 <code>main</code> 方法真正运行之前，JVM 为了“创造一个可运行你的程序的宇宙”，到底经历了哪些步骤？从参数校验、系统资源探测，到选择垃圾回收器，再到类的加载、链接与初始化，这些看不见的过程决定了应用的启动体验与后续性能。本文用一个极简的 HelloWorld 贯穿全程，结合详细日志，一步步洞察 JVM 的启动机制，帮你在调试和性能优化时更有抓手。</p><h2>1. 概览</h2><p>当我们运行一个 Java 应用时，JVM 在我们的代码真正开始执行之前，会先完成一系列复杂步骤。本文将从执行 <code>java</code> 命令的那一刻开始，一直走到应用就绪。</p><p>我们以一个简单的 HelloWorld 程序为例，拆解每一个阶段。理解这些内部机制能显著提升调试与性能调优的效果。</p><h2>2. 从 <code>java</code> 命令到 JVM 启动</h2><p>在 JVM 执行任何代码之前，它需要先启动、校验输入并配置运行环境。下面按启动顺序走一遍早期流程：从调用 <code>java</code> 命令到初始化 JVM 运行时。</p><h3>2.1. <code>java</code> 命令与初始调用</h3><p>当我们运行 <code>java</code> 命令时，JVM 启动序列会通过 JNI 方法 <code>JNI_CreateJavaVM()</code> 开始执行。该方法完成若干关键初始化任务，为执行 Java 应用准备环境。Java Native Interface（JNI）是 JVM 与原生系统库之间的桥梁，使 Java 与平台特性可以双向通信。</p><p>本文将使用详细日志观察 JVM 的内部运作，例如：</p><pre><code class="bash">java -Xlog:all=trace HelloWorldCopy</code></pre><h3>2.2. 校验用户输入</h3><p>首先，JVM 会校验我们传入的参数：</p><pre><code class="text">[0.006s][info][arguments] VM Arguments:
[arguments] jvm_args: -Xlog:all=trace:file=helloworld.log 
[arguments] java_command: HelloWorld
[arguments] java_class_path (initial): .
[arguments] Launcher Type: SUN_STANDARD</code></pre><p>JVM 会验证目标可执行、类路径以及任何 JVM 参数，确保它们在继续执行前都是有效的。这个步骤能尽早捕获很多常见配置错误，避免后续阶段出现更难定位的问题。</p><h3>2.3. 检测系统资源</h3><p>接着，JVM 会识别可用的系统资源，例如处理器数量、内存大小以及关键系统服务：</p><pre><code class="text">[0.007s][debug][os       ] Process is running in a job with 20 active processors.
[os       ] Initial active processor count set to 20
[os       ] Process is running in a job with 20 active processors.
[gc,heap  ]   Maximum heap size 4197875712
[gc,heap  ]   Initial heap size 262367232
[gc,heap  ]   Minimum heap size 6815736
[os       ] Host Windows OS automatically schedules threads across all processor groups.
[os       ] 20 logical processors found.</code></pre><p>这些信息会影响 JVM 的一些内部决策，比如默认选择哪个垃圾回收器。可用 CPU 数和总内存会直接影响 JVM 的启发式选择。不过，大多数设置都可以通过显式的 JVM 参数进行覆盖。在这个阶段，JVM 还会检查是否支持 Native Memory Tracking，并验证它可能依赖的各类操作系统工具的可用性。</p><h3>2.4. 环境准备</h3><p>随后，JVM 会生成 HotSpot 性能数据。这些数据会被 JConsole、VisualVM 等工具用于检查和分析 JVM：</p><pre><code class="text">[perf,datacreation] name = sun.rt._sync_Inflations, dtype = 11, variability = 2, units = 4, dsize = 8, vlen = 0, pad_length = 4, size = 56, on_c_heap = FALSE, address = 0x000001f3085f0020, data address = 0x000001f3085f0050</code></pre><p>这类性能数据通常存储在系统的 <code>/tmp</code> 目录下，并会在启动阶段的一段时间里持续生成，与其他初始化任务并行进行。</p><h2>3. 加载、链接与初始化</h2><p>当 JVM 环境就绪后，它会开始为我们的程序执行做准备。</p><h3>3.1. 选择垃圾回收器</h3><p>在 JVM 内部，一个关键步骤是选择垃圾回收器（GC）。截至 JDK 23，默认情况下 JVM 会选择 G1 GC，除非系统可用内存少于 1792MB 和/或仅有单处理器：</p><pre><code class="text">[gc               ] Using G1
[gc,heap,coops    ] Trying to allocate at address 0x0000000705c00000 heap of size 0xfa400000
[os               ] VirtualAlloc(0x0000000705c00000, 4198498304, 2000, 4) returned 0x0000000705c00000.
[os,map           ] Reserved [0x0000000705c00000 - 0x0000000800000000), (4198498304 bytes)
[gc,heap,coops    ] Heap address: 0x0000000705c00000, size: 4004 MB, Compressed Oops mode: Zero based, Oop shift amount: 3
[pagesize         ] Heap:  min=8M max=4004M base=0x0000000705c00000 size=4004M page_size=4K</code></pre><p>当然，我们也可以选择其它 GC：如 Parallel GC、ZGC 等，具体可用与默认策略依不同 JDK 版本与发行版而异。</p><h3>3.2. 加载 CDS（类数据共享）</h3><p>此时，JVM 会开始寻找进一步的优化机会。CDS 是一组已经经过预处理的类文件归档，可以改善 JVM 的启动性能：</p><pre><code class="text">[cds] trying to map [Java home]/lib/server/classes.jsa
[cds] Opened archive [Java home]/lib/server/classes.jsa</code></pre><p>不过，CDS 正在被 Project Leyden 中的 AOT（提前）机制逐步替代，后文会继续讨论。</p><h3>3.3. 创建方法区</h3><p>JVM 随后会创建“方法区”，这是一个用于存储类数据的特殊离堆内存区域。在 HotSpot 中，这一区域被称为 metaspace。当关联的类加载器不再可达时，存储于此的类数据也会被移除：</p><pre><code class="text">[metaspace,map    ] Trying anywhere...
[metaspace,map    ] Mapped at 0x000001f32b000000</code></pre><p>虽然方法区不在堆中，但它仍由 GC 管理。</p><h3>3.4. 类加载</h3><p>类加载包含三个步骤：定位二进制表示、根据其派生出类、并将其加载到方法区。正是这种动态加载能力，让 Spring、Mockito 等框架可以在运行期按需生成并加载类。</p><p>类加载有两种方式：引导类加载器（bootstrap class loader）或自定义类加载器。下面借助一个简单的 <code>HelloWorld</code> 类，看看 JVM 首先会做什么：</p><pre><code class="java">public class HelloWorld extends Object {
    public static void main(String[] args) {
        System.out.println("Hello World!");
    }
}</code></pre><p>JVM 会优先加载 <code>java.lang.Object</code> 及其依赖。类在初次加载时大多处于“半隐藏”的状态，以便进行必要的验证与整理工作。</p><p>再看下 <code>java.lang.Object</code> 的方法：</p><pre><code class="java">public class Object {
    public final native Class&lt;?&gt; getClass()
    public String toString()
    public boolean equals(Object obj)
}</code></pre><p>这些方法分别引用了 <code>java.lang.Class</code> 与 <code>java.lang.String</code>，因此它们也需要先行加载。JVM 采用“按需加载”的策略，仅在类被实际引用时才加载。不过，上述这些对 JVM 至关重要的类会被“抢先加载”。在一个简单的 HelloWorld 程序里，由 <code>JNI_CreateJavaVM()</code> 初始化的引导类加载器负责所有的类加载工作。</p><h3>3.5. 类链接</h3><p>类链接可以拆分为验证（Verification）、准备（Preparation）与解析（Resolution），其发生顺序并不固定：解析可能发生在验证之前，也可能在类初始化之后。验证确保类结构正确：</p><pre><code class="text">[class,init] Start class verification for: HelloWorld
[verification] Verifying class HelloWorld with new format
[verification] Verifying method HelloWorld.&lt;init&gt;()V</code></pre><p>位于 CDS 中的类已经过验证，因此会跳过该步骤，从而提升启动性能。这是 CDS 的重要收益之一。在“准备”阶段，JVM 会用默认值初始化静态字段，没有显式初始化器的静态变量会自动获得默认值。</p><p>在“解析”阶段，JVM 会解析常量池（Constant Pool）中的符号引用。常量池保存了类的所有符号引用，JVM 必须先将其解析为真实的内存引用，才能执行相关指令。</p><p>我们可以使用 <code>javap</code> 来观察：</p><pre><code class="bash">javap -verbose HelloWorldCopy</code></pre><p>这将显示常量池的内容：</p><pre><code class="text">Constant pool:
   #1 = Methodref          #2.#3          // java/lang/Object."&lt;init&gt;":()V
   #2 = Class              #4             // java/lang/Object
   #3 = NameAndType        #5:#6          // "&lt;init&gt;":()V
   #7 = Fieldref           #8.#9          // java/lang/System.out:Ljava/io/PrintStream;
  #13 = String             #14            // Hello World</code></pre><p>构造器的字节码并不直接包含地址。它引用常量池中的符号项（例如 <code>#1</code>），这些条目描述了方法或字段。解析阶段会将这些符号项转为可执行的真实内存引用：</p><pre><code class="text">public HelloWorld();
  descriptor: ()V
  flags: (0x0001) ACC_PUBLIC
  Code:
    stack=1, locals=1, args_size=1
       0: aload_0
       1: invokespecial #1                  // Method java/lang/Object."&lt;init&gt;":()V
       4: return
  LineNumberTable:
    line 2: 0
    line 4: 4</code></pre><p>第 1 行的 <code>invokespecial</code> 指令引用了常量池条目 <code>#1</code>，其中包含链接到 <code>java.lang.Object</code> 构造器所需的信息。<code>&lt;init&gt;</code> 表示这是由 <code>javac</code> 为每个构造器自动生成的特殊方法。JVM 采用“延迟解析”，只有在尝试执行类中的某条指令时才触发解析；并非所有已加载的类都会实际执行其指令。</p><h3>3.6. 类初始化</h3><p>类初始化会为静态字段赋值并执行静态初始化器，这与我们调用构造器的实例初始化不同。该过程由 <code>javac</code> 自动生成的特殊方法 <code>clinit</code> 负责。</p><h2>4. 优化 JVM 启动性能</h2><p>尽管 JVM 的启动已经很高效，但仍有提升空间。以下是一些方向。</p><h3>4.1. 类加载的影响</h3><p>我们可以使用系统的 <code>time</code> 工具来度量 JVM 启动、加载类、链接并执行这个简单程序的总耗时：</p><pre><code class="bash">time java HelloWorldCopy</code></pre><p>该工具会测量从 JVM 进程启动到退出的挂钟时间，包含类加载、链接、JIT 预热与程序执行——不仅仅是用户代码。对于 HelloWorld，JVM 在启动期间通常会加载约 400～450 个类。在现代硬件上，即便开启冗长日志，整个过程也大约在 60 毫秒左右完成。</p><h3>4.2. Project Leyden</h3><p>Project Leyden 的目标是减少启动时间、达到峰值性能的时间以及内存占用。JDK 24 引入了 JEP 483：Ahead-of-Time Class Loading and Linking（提前类加载与链接），将这些操作从启动时前移至 AOT 阶段。</p><p>该特性会在“训练运行”中记录 JVM 的行为，将其存入缓存，并在后续启动时从缓存加载。这将取代原先的 CDS 概念，并最终以 AOT 的更广泛能力来统一表达。</p><h3>4.3. JVM 参数与调优</h3><p>虽然我们可以通过静态字段与初始化器在某些场景中优化启动性能，但应谨慎对待。为了将行为挪到类加载阶段而进行重构，往往很难获得可测量的收益——特别是考虑到运行时的大部分代码来自依赖库而非我们自己的应用。</p><h2>5. 结论</h2><p>本文从校验用户输入、检测系统资源，到类的加载、链接与初始化，系统地梳理了 JVM 在启动阶段经历的复杂流程。即便是一个简单的 HelloWorld，JVM 也会在执行代码之前构建起完整的运行环境，加载数百个类。</p><p>随着 Project Leyden 等改进（例如 AOT）的到来，JVM 的启动性能还将进一步提升。</p><blockquote>更多相关技术干货分享可以关注这个<a href="https://link.segmentfault.com/?enc=tCi%2Bp2ZsNJvrldU8McVlxQ%3D%3D.Qfc6EcXfgsCPCFQ14agAGnsVFh8Qa%2Ban0ew2jVVNTXb2QXjtx%2B65WPGOieXJSy0o" rel="nofollow" target="_blank">Java专题</a></blockquote>]]></description></item><item>    <title><![CDATA[如何驯服AI编程 reddish ]]></title>    <link>https://segmentfault.com/a/1190000047403420</link>    <guid>https://segmentfault.com/a/1190000047403420</guid>    <pubDate>2025-11-16 22:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>当泡沫遇上现实</h2><p>最近圈子里聊AI泡沫的声音越来越多，大厂裁员的消息也时不时冒出来。</p><p>说实话，氛围编程那套已经凉透了，这点毫无悬念。之前写过一篇文章专门聊这事儿："氛围编程走远，规格驱动开发降临"<a href="https://link.segmentfault.com/?enc=%2BTnKCez8tkotzE4cXeLu5g%3D%3D.gEnIi8%2Fb2vAkefOqwmDpMLmjtgtypLeXbfyC3TSk%2F06uFPwc4CNpJH6LJQ1E4BPFcWY9D8dIaFUZnOzOZrb2Nw%3D%3D" rel="nofollow" target="_blank">https://srs.pub/thinking/spec-driven-coding.html</a></p><p>AI这波泡沫更有意思。做空基金直接怼nvidia，理由是按现在的市值，得60年才能回本。更绝的是nvidia自己的神操作：给OpenAI投1000亿，然后这钱必须用来买nvidia的显卡。这不就是左手倒右手嘛，本质上就是在给自己刷数据。</p><p>但真正要命的不是这些资本游戏，而是这股风已经吹到了普通人和管理层那里。你看那个被炒得火热的口号："普通人不懂技术也能开发产品了！"</p><p>这种浮躁的氛围，让不少老板产生了一个危险的错觉：<strong>程序员要失业了</strong>。连Meta都搞出了"鼓励转行，主动离职"的骚操作。Meta都这样了，后面跟风的还会少吗？</p><p>但是，如果你真打算因为AI能写代码就开始裁人，我劝你先冷静一下。<strong>商业史上最贵的学费，往往来自对新技术能力的误判</strong>。</p><h2>美丽的幻觉</h2><p>AI不光自己会产生幻觉，更要命的是它还会传染给人。于是就有了那句让人热血沸腾的口号："普通人不懂技术也能开发产品了！"听起来多美好啊，难怪一堆人跟着喊。</p><p>但历史告诉我们一个残酷的规律：<strong>每次看起来要颠覆世界的技术突破，都会先让人high到天上，然后狠狠摔回地面</strong>。</p><p>看看下面这张图，不同编程模式的真实轨迹：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403422" alt="" title=""/></p><p>传统编程就像爬山，前期累死累活，慢慢往上爬，后期还得不停维护。但氛围编程和规格驱动开发就不一样了，一上来就能给你个惊喜，进展飞快。这也难怪那么多人相信"有想法就够了，剩下的交给AI"。</p><p>然后呢？氛围编程就开始现原形了。业内有个专门的词儿叫<strong>"腐烂"</strong>，说的就是AI写的代码崩坏的速度。</p><p>氛围编程确实能给你一个看起来还不错的初版，但你要是想继续完善？很快就会发现这玩意儿烂得比你想象的还快。我们项目里就遇到过，AI开始胡说八道，改了这里坏了那里，早期的AI模型还不知道适可而止，直接把自己都给卡死了。最后还是得人工全面接手，前前后后反而浪费了更多时间。</p><p>接下来可能成为主流的是<strong>规格驱动编程</strong>。这种方式起步和氛围编程差不多快，而且因为有明确的规格约束，初版质量可能还更好一些。虽然后面也会有腐烂的趋势，但规格就像缰绳一样，能把AI拉回正轨。最终的成熟度和覆盖面确实比纯人工要好一些。但这个"好"，也就是30%到50%的提升，没有想象中那么夸张。</p><p>所以啊，我们不仅要提防AI的幻觉，更要小心AI给我们制造的幻觉。真正的智慧在于：<strong>既不被炫酷的表象迷了眼，也不因为害怕就拒绝改变</strong>。</p><p>在很长一段时间里，AI都需要人来搭配，才能真正干成事儿。绝不是随便什么人都能上手的。</p><h2>血淋淋的真相</h2><p>说了这么多理论，来个真实的案例吧。我们团队最近就踩了一遍坑，现在想想还挺有意思的。</p><p>借助AI的能力，第一天就搭出了个基础框架，加上产品信息的整理，当天就能看到大概的样子。三天左右，核心的3-5个功能都跑起来了，通过了基础测试。那会儿我们还挺兴奋的，觉得这效率简直了。</p><p>然后就是噩梦的开始：整个研发团队全员上阵，像保姆一样盯着AI的每个操作，花了整整3个星期，才把各种bug、逻辑错误、莫名其妙的问题给填得差不多。</p><p>事后复盘，AI确实能在三天内给你一个能跑的版本，但AI+人工还是需要三周的时间来收拾残局，这还是在规格驱动模式下的结果。整个周期算下来，和纯人工开发差不了多少，而且在细节把控上，远没有人工那么可控。</p><p>不过话说回来，AI在一些我们团队薄弱的地方，比如CSS动画特效，确实提供了相当不错的补充。</p><p>这个经历让我明白了一个道理：<strong>复杂系统从来不是简单能力的拼凑，而是需要有人统筹全局</strong>。AI可以提供强大的局部能力，但整个系统的协调，还得靠人的智慧。</p><p>所以结论是什么？AI编程确实有用，但绝不是那些营销号说的那么轻松。我们的资深开发全程深度参与，工作量比平时还要大。</p><p>如果你听信了"AI让普通人都能开发产品"的鬼话，先别急着裁人，让子弹再飞一会儿。</p><h2>如何驯服这头野兽</h2><p>那AI编程到底还有没有用？当然有用！关键是要学会怎么驯服它。认清了AI的脾气秉性后，它绝对是个值得投资的好帮手。</p><h3>AI编程的四大价值</h3><ol><li><strong>做原型简直是神器</strong>：AI编程能快速给你一个可视化的原型。如果你只是想做个demo、验证个想法、或者和团队讨论创意，AI简直就是为这个而生的。</li><li><strong>补齐团队短板</strong>：以前组建研发团队，各种技能都得配齐，成本高得要命。现在AI能提供中上水平的开发能力，只要有人指导得当，很多临时需求都能搞定。</li><li><strong>打破信息壁垒</strong>：传统开发中，某些特定技能只有少数高手掌握，协调起来麻烦得很。有了AI，对传统高手的依赖大大降低了。</li><li><strong>局部功能很靠谱</strong>：AI现在的问题是记忆力不行，搞不定大系统。但对于那些短小精悍、需求明确的功能，质量还是挺高的。</li></ol><h3>不同人群的生存指南</h3><p>这波变革对研发团队的冲击还是挺明显的：</p><p><strong>高手变得有点寂寞</strong>：因为不再是独一无二的存在，门前确实冷清了不少。不过真正的高手借助AI发挥的效能还是比普通人强，价值依然在。<strong>真正的专家价值，从来不在于知道多少，而在于知道怎么用</strong>。</p><p><strong>新人的路更难走了</strong>：学编程本来就不容易，现在AI一出来，新人的学习动力和信心都受到冲击。只能从产品设计、规格规范这些方向入手，但这样一来，和AI的深度交流就成了问题，以后的路会很艰难。</p><p><strong>普通程序员如虎添翼</strong>：反倒是那些已经入门、掌握了基础技能的普通开发者，搭配AI简直如虎添翼。一个人顶好几个不是梦，甚至跨语言、跨领域都成了可能。</p><h3>普通人还有机会吗？</h3><p>如果你能做到产品经理的水平，输出详细的产品设计规格，或许还有一线希望。但最起码得有技术架构师来规范系统架构，数据结构、接口规范、设计规范这些基础知识是跑不掉的。</p><p><strong>完全不懂技术就想做产品？醒醒吧</strong>。</p><p>对普通人或者新人来说，比较靠谱的路径是学习设计思维，能把想法详细描述成产品需求，制定产品设计规范，最终确定技术规格。做到这一步，才有可能借助AI把产品做好。</p><h2>写在最后</h2><p><strong>技术的本质是放大人的能力，而不是替代人的智慧</strong>。AI编程确实是未来，但这个未来需要我们理性地参与创造，而不是盲目地跟风炒作。</p><p>别再做那些不切实际的白日梦了。AI确实能提供功能和价值，但在任何时代、任何技术革命中，都不存在躺着就能赢的机会。<strong>解决真正有价值问题的能力，永远都是稀缺资源</strong>。</p><p>驯服AI编程的核心在于：用规范约束AI的随意性，用人类智慧指导AI的创造力。学会了这一点，你就掌握了未来。</p><p>::: {#author name=reddish}<br/><em>本文同步发表在 <a href="https://link.segmentfault.com/?enc=MrOHP38rcIId5MWaUsWrlw%3D%3D.qR2RckSBM3nPOWk%2FdWepSQ%3D%3D" rel="nofollow" target="_blank">软件需求探索</a>的<a href="https://link.segmentfault.com/?enc=inptjSJm5P8xj7%2B5EWBUwg%3D%3D.XyU4i3J10XKhlwz%2FXkac0bQdyzemhf6BzIPx493zLLydTLLuAl2q4JSFg2PNkwUTKFrQO2sIKdww8Cum6Vn2WQ%3D%3D" rel="nofollow" target="_blank">https://srs.pub/thinking/stop-firing-after-ai-coming.html</a></em></p><p><em>作者: <a href="mailto:reddish@srs.pub" target="_blank">reddish@srs.pub</a></em><br/>:::</p>]]></description></item><item>    <title><![CDATA[AI 招聘智能体 爱跑步的香蕉_cKti]]></title>    <link>https://segmentfault.com/a/1190000047403347</link>    <guid>https://segmentfault.com/a/1190000047403347</guid>    <pubDate>2025-11-16 21:04:21</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>AI 招聘智能体<br/>AI重塑人才选拔：效率与精准的双重革新</p><p>人才选拔赛道的竞争日趋激烈，招聘官深陷堆积如山的简历与密集的面试流程，却仍面临核心人才难寻、面试主观性强、招聘成本高企的困境。当HR团队疲于应对初筛与基础面试时，企业正为这些低效流程承担高昂代价。</p><p>艾瑞咨询数据显示，AI技术已贡献HR SaaS市场60%的价值，其中个性化评估是核心应用场景。这场技术革命正从培训领域迅速蔓延至招聘环节，重新定义人才选拔的标准与效率。</p><p>AI面试智能体：精准选拔的核心支撑</p><p>AI面试智能体聚焦传统招聘“低效、主观、成本高”三大痛点，以“精度高”为核心优势，为企业提供智能招聘解决方案。其打分结果通过效标效度与重测稳定信度的双重心理学指标验证，可直接作为招聘决策依据，在面试智能体领域达到国际领先水平。</p><p>精准性贯穿招聘全环节。一道题目可同步评估多项胜任力，无缝衔接HR初筛与技术复试，让评估效率提升50%以上。系统能根据候选人回答即时生成针对性问题，像资深面试官一样捕捉关键信息，避免遗漏核心能力。同时，它会自动抓取简历中的关键信息与模糊点，生成递进式提问，既杜绝信息造假，也避免因HR主观疏忽错失优质候选人。无论是沟通、协作等通用胜任力，还是编程、算法、工程、财务等专业领域，系统都能精准出题，同时解放HR面试官与专业面试官。</p><p>在候选人体验层面，AI面试智能体实现了极致的拟人化交互。它能精准捕捉候选人的语速、情绪与潜台词，像真人HR一样引导候选人充分展现实力，避免因紧张影响发挥。无需手动操作“开始/结束答题”，系统可自动识别回答状态并衔接下一问题，交流过程自然流畅。语音与口型匹配精度大幅提升，同步嘴型开合与语速节奏，消除“纸片人”式的疏离感。候选人可随时提问，AI能准确解答职位信息、公司福利等问题，帮助候选人深入了解企业。</p><p>AI人才寻访智能体：全流程自动化革新</p><p>AI人才寻访智能体是一款具备简历解读、精准匹配、有效沟通能力的AI招聘工具，通过大模型技术实现有判断力的招聘决策，替代人工完成大量机械流程。</p><p>这套完整的招聘自动化系统可在无需人工干预的情况下，独立完成简历筛选、初步沟通、简历回收与系统同步的全流程，将招聘效率提升10到100倍。仅需30-60秒完成初始化，系统即可自动启动服务，无需人工值守。它能通过自主页面操作，根据企业预设条件自动筛选简历，精准识别符合要求的候选人。</p><p>针对匹配人选，AI可自动发起沟通，模拟人类语气进行问答式互动，发现不合适时即时退出。系统会自动遍历所有未读消息，逐条个性化回复，确保不遗漏潜在候选人。在缺少简历信息时，AI会主动请求简历，以自然的交流方式与候选人沟通。收到简历后，系统自动下载并上传至企业ATS系统，同时生成候选人档案，保障数据流转的完整与安全。</p><p>AI招聘的广泛应用与行业认可</p><p>AI面试智能体已在多领域得到广泛应用，服务对象包括西门子中国、太平保险、中广核集团、阿里巴巴国际、招商银行、TCL等上千家世界五百强及中国知名企事业单位，同时获得浙江大学、上海交通大学等顶尖高校的认可，其技术实力与应用效果经过了实际场景的充分验证。</p><p>AI技术正以精准化、自动化、人性化的优势，持续革新人才选拔的模式与效率，为企业解决招聘痛点提供了可靠的技术支撑。</p>]]></description></item><item>    <title><![CDATA[从“想法”到“产品”，Vibe Codi]]></title>    <link>https://segmentfault.com/a/1190000047403372</link>    <guid>https://segmentfault.com/a/1190000047403372</guid>    <pubDate>2025-11-16 21:03:35</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>AIFirst 与 OpenBuild 联合发起的 Vibe Coding 实战课，用六节干货满满的课程和一节加餐课，让无数 Web3 从业者感受到了这种 “高效开发、快速落地” 的魅力。</p><p><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdm3Wc" alt="image.png" title="image.png"/></p><p>在 Web3 赛道里，“有想法” 从来不是稀缺品，“能落地” 才是。以前做一个网站、一个小应用需要设计师、程序员、产品经理参与……少则几周，多则几个月。</p><p>但现在，一个人就能搞定！这就是 Vibe Coding 带来的新机会：用更快、更聪明的方式做产品，普通人也能从 0 到 1 搭建属于自己的产品。</p><p>从 Web3 小白到独立开发能手，从混乱编码到标准化流程，五位优秀学员用亲身经历，分享了这场 “高效开发” 的蜕变之旅。</p><p><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdm3Wd" alt="image.png" title="image.png" loading="lazy"/></p><p>同时，为了表彰以上五位小伙伴在课程中的全程投入和精彩分享，将获得本次课程赞助商 0G 和 SpoonOS 送出专属优才宝箱！</p><p><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdm3We" alt="image.png" title="image.png" loading="lazy"/></p><h3><strong>0xBrick_e²：告别无效沟通，掌握标准化流程</strong></h3><p>在今年暑假国内某家云服务公司的后端实习中，我经常让 AI 帮我完成工作任务，公司也是十分鼓励用 AI 辅助编程的，这让我意识到 Vibe Coding 是席卷而来的行业趋势。但是用AI辅助编程时，它像极了一个“热心但总是办坏事的实习生”——AI 能高效生成代码但总是与我的需求南辕北辙，复杂项目很容易抓不住重点，我需要不断地强调“这里要改”、“那里千万别动”，经常因为AI改了不该改的地方而回滚代码，十分糟心。</p><p><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdm3Wk" alt="image.png" title="image.png" loading="lazy"/></p><p>而这门 Vibe Coding 实战课，恰恰精准地治愈了我的痛点。我最大的收获，不是学会了某个酷炫的技术，而是掌握了一套标准化、可复用的 Vibe Coding 流程。从如何启动一个清晰的开发工作流，到如何精准地确认和拆解功能需求，再到让AI开始构建整个项目——这套流程成功地将我从与AI的无效沟通中解放出来。这套方法让我体会到：有了 Vibe Coding，我们每个人都是自己项目的产品经理。 即使是没有深厚编程基础的小白，也具备了成为“全栈开发者”的潜力。我们可以将脑海中天马行空的创意，快速地构建、落地为一个最小可行产品，亲眼见证想法照进现实。</p><p>作为一门名副其实的“实战课”，导师在课程中讲的满满都是干货，一步步亲手演示实操，目睹了导师如何通过 Vibe Coding 进行独立的商业转化，一个人实现从0到交付的全过程。这让我真切地看到，一个人就是一支队伍，技术能力可以直接转化为商业价值。</p><p><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdm3Wj" alt="image.png" title="image.png" loading="lazy"/></p><p>回顾这段学习旅程，我跟着导师一步步用 Vibe Coding 构建了自己的个人主页，将我的 NFT 成功部署上链、有了自己的 AI chat 机器人、给播客主定制一份播客展示页。Vibe Coding 赋予我的远不止是效率的提升和代码的规范，它更是一种“我能构建任何东西”的强大自信，是一种将创意转化为现实的能力。</p><h3><strong>花千树：3 小时完成个人站，解锁 MVP 快速验证</strong></h3><p><strong>1️⃣ 为什么学习 Vibe Coding？</strong></p><p>先从 Vibe Coding 这个词来说起吧！最初知道这个概念时，直译过来叫氛围编程，只知道这是用来辅助编程的，具体怎么个氛围法就不清楚了。当看到这个课程时，我就知道深入了解它的机会到了。</p><p><strong>2️⃣ 成果收获</strong></p><p>通过第一、二节课，我用 Vibe Coding 直接完成了一个个人网站的开发，并部署上线。在开发的过程中不用手写一行代码，通过 AI 编程工具可以实现所有开发任务，包括 debug。</p><p><img width="723" height="373" referrerpolicy="no-referrer" src="/img/bVdm3Wl" alt="image.png" title="image.png" loading="lazy"/><br/>个人网站：<a href="https://link.segmentfault.com/?enc=e%2BCc1%2F%2BCCQQiGhcGtEuuoQ%3D%3D.EO6OOM64USDQ%2BHqmspht6rYSbMaAy1h7kLERuVXBqyHV%2BJnX0AGE29GYdOC0bSY3" rel="nofollow" target="_blank">https://profile-blog-ai.vercel.app/</a></p><p>这样的网站虽然很简单，但如果要靠我自己完成全部的工作任务，至少也得两天的时间。通过 Vibe Coding 只需要几个小时就可以完成全部任务了（我记得完成这个个人网站，从开发到部署应该不到3个小时）。</p><p>通过这种方式来验证 MVP 一定是最好、最快的方案。</p><p>第三节课，老师针对 Vibe Coding 的流程给出了具体的方案和一些实用工具。这个过程我认为是非常重要的，把一整个编程流程、思维框架抽象成一个工作流，可以把这个工作流当成在 AI 编码时的一个规范，通过这个规范给编码工具提供指导，以不至于在编码时出现理解偏差，走向不归路，浪费时间。</p><p>我给这个工作流取了个名字叫做都察院，哈哈，简单好记。</p><p>PS: 最近对古代官制感兴趣，刚刚还把手机中的 app 按明朝官制进行了分类。</p><p>在有工作流的指导下，用 Vibe Coding 完成了一个简单的英语学习网站，其中需要使用到一些 AI 工具的 api，在开发过程中也有详细的指导步骤，完成起来还是比较顺利的。</p><p>仓库地址：<a href="https://link.segmentfault.com/?enc=1CPfp7T1W20gYKEYK08%2FVA%3D%3D.XeTRgfYbwTbAmRYOxKaYUJjUbkUcqQ9Wliupq13oP6vBkBJWp7cei1eCbnI7yIMuqIwWV7kd0o9zGcRC87BfQw%3D%3D" rel="nofollow" target="_blank">https://github.com/huaqianshu-lm/english-learning-site</a></p><p><img width="723" height="363" referrerpolicy="no-referrer" src="/img/bVdm3Wm" alt="image.png" title="image.png" loading="lazy"/></p><p>紧接着就来到了第四课了，基础打完了就应该实战了。我们来学习这个课程的目的一半在 Vibe Coding，另一半就是 web3**了，它终于来了。</p><p>在没有 web3 基础的情况下，可以通过 Vibe Coding 居然也能做项目了，真是件令人开心的事情啊。</p><p>呐，我的 MCoin 这不就出来了吗！</p><p><img width="723" height="378" referrerpolicy="no-referrer" src="/img/bVdm3Wn" alt="image.png" title="image.png" loading="lazy"/></p><p>呃... 虽然还点问题，但是不要紧，容我慢慢解决。</p><p>在做这几个项目的过程中，对 Vibe Coding 也是越来越熟悉，有几点经验跟大家分享一下。</p><p>1.在 coding 的过程中要有耐心。</p><ul><li>有过编程经验的小伙伴都知道，在做项目的过程中，一小部分时间在写代码，其实有一大部分的时间都是在调试 bug，解决问题。在 Vibe Coding 的过程中其实也是一样的，大部分的时间都是在解决问题。那么在解决问题的时候，与 AI 对话时，一定要把问题说清楚，那怎么说清楚呢？</li><li>我有一点小经验就是充分利用你的眼睛，看到什么就跟 AI 说什么。比如你看到页面有什么错误提示，你就跟 AI 说提示是什么，你看到颜色暗，就跟 AI 说颜色暗，需要亮一点的色彩。先把你看到的最直观的东西描述给 AI，然后再不断调整。</li><li>跟 AI 说需求时也是一样，你希望看到什么，就跟 AI 说什么，就用最直接的语言描述给它。我最近就是用这个方法跟 AI 沟通，我觉得效果还不错，有兴趣的可以试试。</li></ul><p>2.先使用其他 AI 工具整理思路。</p><ul><li>有时候我们有一个想法时，就只是有一个想法。距离想法变成产品还有很工作要做，这个时候可以先用 chatGPT** 来帮我们整理思路、确定技术方案。把这些准备工作都做好了之后，再开始 Vibe Coding。</li><li>当然这些工作也都可以用 cursor、claude** 等实现，但会消耗一些 token，毕竟还挺贵的，主打一个经济实惠🤑。</li></ul><p>后面的课程，只看了一遍，还有一些问题没有解决，也没有深入思考调研，在这里就不多说了。期待其他小伙伴的分享，搭个便车。</p><h3><strong>Zack：从 “知识空白” 到 “产品落地” 的完整跃迁</strong></h3><p>在参与 AIFirst 与 OpenBuild 联合发起的 Vibe Coding 实战课后，从基础认知到项目落地，再到商业转化，短短六节课的学习不仅填补了我在 Web3 领域的知识空白，更让我对 “高效开发” 有了全新的理解，最终实现从 “有想法” 到 “做出产品” 的完整路径，以下是我的具体收获与感悟。</p><p>第一课的基础认知环节，是我走进 Vibe Coding 世界的起点。Cell 细胞、张晋涛等五位导师毫无保留地分享了各自在开发中的宝贵经验 —— 小到日常编码的避坑技巧，大到长期深耕领域的思维方式，这些 “过来人” 的心得远比单纯的理论更有冲击力。我第一次意识到，Vibe Coding 不止是一种技术方法，更是一种 “轻量化、高效率” 的开发思维，也为后续的学习打下了认知基础。</p><p><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdm3Wo" alt="image.png" title="image.png" loading="lazy"/></p><p>第二课的工具链与工作流教学，张晋涛老师详细拆解了 Vibe Coding 常用的编码工具，不仅讲解了工具的基础操作，更结合具体使用场景、技术栈等分析了各种AI工具。<br/><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdm3Wp" alt="image.png" title="image.png" loading="lazy"/></p><p>第三课 Panda 老师主讲的 Vibe Coding 全流程，彻底改变了我以往 “想到哪写到哪” 的开发习惯。从需求收集时的用户痛点挖掘，到与 AI 协作设计文档、规划任务节点，再到执行开发中的进度把控、测试环节的风险排查，每一步都有清晰的逻辑和方法。跟着这套流程练下来，我发现自己做开发时不再频繁卡顿，原本需要一天完成的小功能，现在半天就能高质量收尾，效率提升的同时也减少了返工。</p><p><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdm3Wq" alt="image.png" title="image.png" loading="lazy"/></p><p>第四课崔棉大师带领的 Web3 NFT 应用实战，是我最有成就感的一课。作为刚接触 Web3 的小白，“从 0 到 1 做产品” 曾是我不敢想的目标，但在课程中，崔老师将复杂的开发流程拆分成一个个小步骤：从环境搭建到合约编写，从前端交互到功能测试，最终看到自己开发的 NFT 应用能正常运行时，还是挺有感触的。</p><p><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdm3Wr" alt="image.png" title="image.png" loading="lazy"/></p><p>第五课 “从 AIVerse 窥见 0G” 对我来说是一次 “跳级挑战”。刚开始听 0G 相关概念时，确实有些吃力，但 Wei 老师没有停留在理论讲解，而是带领我们动手生产 AI NFT—— 从确定 NFT 风格，到用 AI 生成素材，再到部署上链，一步步引导我们理解技术逻辑。虽然过程中遇到了不少新问题，但最终完成的 AI NFT 让我对 AIVerse 与 Web3 的结合有了具象认知。</p><p><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdm3Ws" alt="image.png" title="image.png" loading="lazy"/></p><p>最后一课 Cell 细胞老师关于独立站与付费转化的分享，则为我的开发技能赋予了 “商业价值”。老师没有空谈理论，而是结合自己的实操案例，这节课让我意识到，“做出产品” 只是第一步，“让产品产生价值” 才是关键，也让我对未来将开发技能与商业需求结合有了更多灵感。</p><p><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdm3Wt" alt="image.png" title="image.png" loading="lazy"/></p><p>回顾整个课程，Vibe Coding 带给我的不仅是技术层面的提升，更是思维方式的转变 ，感谢各位导师的倾囊相授，也感谢课程中 “实战驱动、社群支持” 的模式，让我这个 Web3 小白能快速成长。未来，我会继续运用 Vibe Coding 的方法打磨产品，把这次学习的收获转化为真正的执行力，在 Web3 领域持续探索前行。</p><h3><strong>大大黄：重新认识 Vibe Coding，构建 AI 协作新思维</strong></h3><p>这次学完 Openbuild 的 Vibe Coding 全系列课程，整体感觉收获特别大，也算是对整个 AI 编程生态有了比较完整的认识。以前我对 “Vibe Coding” 的理解还停留在“AI 帮你写代码”，但其实它是一整套基于 AI 协作的开发思维和工作流。</p><p>在张老师讲的工具链与工作流那节，我第一次系统地了解了各种 AI 工具的定位，比如 Claude、GPT、Gemini**、以及一些开源模型的差异。以前只是“哪个火用哪个，用着用着为什么降智了也不明白”，现在知道了每个模型擅长的方向，各种付费方式也间接性导致了性能的强弱， Claude 在代码解释和结构化逻辑上更强，GPT 在创意和多模态方面更好，而一些开源模型在部署灵活性上有优势。能根据项目选择最合适的 AI，是我觉得最实用的一点。</p><p><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdm3Wu" alt="image.png" title="image.png" loading="lazy"/></p><p>Vibe Coding 流程让我理解到，不是把 AI 当成“自动写手”，而是要把它融入到整个开发环节中，从需求分析、架构设计到测试部署，AI 都能参与协同。实战课更是帮我打通了理论与落地，学会了用 Claude Code 辅助开发，写代码不再是“问一句、等答案”，而是像和一个懂技术的搭档一起结对编程。效率真的提升了不少。</p><p>包括后续的独立站付费转化，以及辅助合约开发都让我受益匪浅，当然，现在的 Vibe Coding 也有一些痛点，比如不同模型之间的衔接还不够顺畅，AI 对复杂逻辑的长期记忆也有限，很多时候还需要人工“喂上下文”。不过整体趋势很明显 —— AI 编程已经不只是一个工具，而是一种新的工作方式。总体来说，这门课让我重新认识了Vibe Coding 这件事。</p><h3><strong>Latrell：从 “野路子” 到 “正规军”，掌控开发主动权</strong></h3><p>10月份有幸参与了 openbuild 组织的 vibe coding 课程，我也算是从“野路子编程”转向了 vibe coding 正规军。</p><p>面对 coding agent，新人总是很容易落入“局部最优”的 debug 陷阱中：从一个并不清晰的项目构想开始，和过于主动的AI就某个功能实现的方式方法来回拉扯，最后以一份庞大的不可读的项目屎山结束。这或许就是新人使用 vibe coding 最常见的 routine，在一次次的扯皮中逐渐忘掉了自己最初的项目构想。</p><p><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdm3WB" alt="image.png" title="image.png" loading="lazy"/></p><p>如果想要更高的完成度和更好的效果，就必须要提供更为清晰的 PRD/项目框架和任务清单。以清晰的需求，具体技术方法和详细的逐步计划来把项目搭建起来。当然这些内容也都可以交给AI生成，但是这个过程是不可或缺的，这也是为什么目前大多数的 AI building 平台都会有 Plan 这个模式的原因。只要善加利用，效果便与众不同了。</p><p>下面这几个步骤，是我觉得能帮你稳住 vibe，避免被 AI 带偏的关键：</p><p><strong>1. 先跟 AI 一起把 PRD 搞明白</strong></p><p>别一上来就急着让 AI 写代码。先把它当成产品合伙人，用自然语言把你的想法讲清楚，一起磨出一份像样的产品需求文档（PRD）。重点不仅是“要做什么”，更要明确“做到什么样子算成功”，以及技术选型和那些容易忽略的非功能需求（比如性能、安全）。这就好比出发前先看好地图，而不是走到一半才发现方向错了。</p><p><strong>2. 把大目标拆成AI能听懂的具体任务</strong></p><p>PRD 之后，宏观目标需要被拆解成具体、可验证的步骤。这时可以借助像 EARS 这样的格式化方法来描述需求，最大限度减少歧义。同时，明确优先级，划定项目范围，清楚哪些是“必须实现”，哪些可以“后续再说”。这一步的核心是让“完成”的标准变得清晰无比，避免和AI在模糊地带纠缠不清。</p><p><strong>3. 设计要模块化，AI 和人都省心</strong></p><p>在技术设计阶段，重点规划好模块和关键接口，追求模块化设计。清晰的模块边界不仅对人类友好，也让 AI 更容易理解和生成高内聚、低耦合的代码。对于特别复杂的功能，可以先让 AI 弄个简单的参考实现或原型探探路，可行性验证了再深度集成，能少走很多弯路。</p><p><strong>4. 把设计图变成可执行的任务清单</strong></p><p>设计好了，就要把它转化成一步步可执行的开发任务。采用增量实施的策略，逐个模块击破，完成一个再下一个。同时，严格使用 Git 进行版本控制是生命线。这样当AI生成的代码不理想时，你可以直接 git reset --hard 回退，而不是在屎山上艰难地打补丁。</p><p><strong>5. 边做边验，让测试成为安全带</strong></p><p>编码实现阶段，AI 是你的结对编程伙伴，但你不能当甩手掌柜。核心是建立构建-测试-提交的循环流程，让自动化测试为你保驾护航。测试不仅能验证功能，更能让 AI 进行自我检查和分析错误。如果测试失败，直接把错误信息扔给 AI 让它帮你分析和修复，这个过程本身也是推动项目稳健前进的机制。</p><p><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdm3WC" alt="image.png" title="image.png" loading="lazy"/></p><p>总之，vibe coding 不是让你变得更懒，而是让你变得更像一位架构师和指挥官。你的核心价值在于清晰的规划、精准的判断和质量把控，而把重复性的编码工作交给AI这位高效的执行者。</p><p>课程中也提到了一些很有用的 MCP，在此列举一下：</p><ol><li><strong>vibedev-specs MCP：</strong> 预设的开发工作流模板，对于没有技术背景的小白很友好，逐步引导用户提出需求和给出多种方案，相当于是将 PRD，项目方案以及逐步计划的构建过程通过工作流的方式进行了整合。</li><li><strong>Zen MCP：</strong> 协调多个LLM**合作推动开发，Debug 时的“三方会诊”</li><li><strong>BrowserTools MCP：</strong> 允许 Agent 在浏览器中高效的调试，提供包括：日志监控，视觉调试，性能和质量扫描，智能模式（调试与审计等功能）</li><li><strong>Vercel MCP：</strong> 部署上线项目，查询部署日志、管理环境变量和进行版本回滚等应用运维操作</li><li><strong>Github MCP：</strong> 自动提交 commit，操作代码仓库、管理 Issues 和 PR 等的开发工作流</li></ol><p><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdm3WD" alt="image.png" title="image.png" loading="lazy"/></p><p>web3 开发者的实战课程：</p><p>OpenBuild 作为面向 Web3 开发者的开源社区，提供了优秀友好的社区氛围和学习路线，Web3 项目实战一课中让我印象最深的是，它没有空谈概念，而是通过一个完整的项目开发，让我从基础设施的层面，切身理解了 Web3 和 Web2 的根本不同。在 Web2 中，我们开发的是运行在中心化服务器上的、可以随时修改的应用逻辑；而 Web3 要求你转变思维，去设计一套部署后即不可更改、规则对所有人透明的智能合约。这更像是在创建一个“数字协约”，代码本身即是法律，这种特性倒逼你必须以极高的严谨性对待安全和审计。</p><p>课程最宝贵的环节是从零开始设计智能合约并亲手部署到测试网。当你需要连接钱包、支付 Gas 费、等待交易确认时，“去中心化”从一个抽象概念变成了可触摸的真实体验。这对于初入 Web3 的开发者来说，不仅是一次扎实的技术练习，更是一场充满成就感的启蒙之旅。</p><p><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdm3WE" alt="image.png" title="image.png" loading="lazy"/></p><p>给独立开发者的加课：</p><p>在“Vibe Coding 独立站如何付费转化”中，作业鼓励我们与播客主交流沟通，寻找客户的真实需求。我认为这是一个很有趣的设计，对于独立开发者来说，我们最缺少的或许不是技术，而是能走出技术自嗨的幻想中，去和真实的用户和市场交流，沉淀的能力。这个小任务创造一个低风险，结构化的真实反馈场景，播客主通常既是内容创作者，也是某些工具的重度用户，他们能提供关于工作流程、痛点的鲜活洞察。这一步的关键是培养一种心态：我们的产品不是一件需要被完美保护的艺术品，而是一个用于验证想法、连接用户的工具。</p><p><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdm3WF" alt="image.png" title="image.png" loading="lazy"/></p><p>每一个开发者在做的事都一样，那就是用技术去将构想变成现实。回看最初提到的“新手陷阱”，其解药或许正在于此：AI 不是魔法驱动的美梦成真术，而是由你的思考和构想驱动的生产工具。选择 vibe coding 或许并不是选择了一条轻松的道路，一次次不清晰、失败的会话记录是对开发者思维清晰度的深刻映射。这要求着我们进一步精进对产品，对框架，对技术内容的理解，超越代码本身，去学习那些代码之外的事情。继续构建，继续创造，在 AI 的 Token 之海中，用精准的指令描绘出你想要的现实。</p><h3><strong>结语</strong></h3><p>在这个 “个体即团队” 的时代，Web3 竞争的核心早已不是 “会不会写代码”，而是 “能不能快速把想法变成产品”。Vibe Coding 打破了技术壁垒，让 Web3 小白也能实现从 0 到 1 的突破，让每一份创意都能在去中心化的浪潮中快速生长。</p><p>未来，Web3 领域的创新节奏只会更快。随着 AI 编程生态的不断完善，相信会有更多开发者借助 Vibe Coding 的力量，在 Web3 等新兴领域持续探索，让 “从想法到产品” 的路径越来越顺畅，让技术创新的火花不断绽放。</p>]]></description></item><item>    <title><![CDATA[Devconnect 活动报名中！dAI]]></title>    <link>https://segmentfault.com/a/1190000047403382</link>    <guid>https://segmentfault.com/a/1190000047403382</guid>    <pubDate>2025-11-16 21:02:49</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdm3WJ" alt="image.png" title="image.png"/></p><p><strong>欢迎回到 Web3 开发者周刊第 76 期！</strong></p><p>本期周刊内所有黑客松活动、新闻和赏金任务，请大家点击查看原文以获取完整信息。如果您喜欢我们的内容，也欢迎大家订阅 <strong>OpenBuild Substack</strong>，获取最新最全开发者资讯！</p><p>本周，我们将关注以太坊基金会的 dAI 团队2026年路线图制定进展，探讨 DeFi 借贷中预言机的核心作用与故障/优化带来的不同影响，以及 EigenCloud 与 LayerZero** 合作推出的 EigenZero 的功能与价值。除了以上见解，你还可以阅读最新的黑客松资讯和赏金任务。</p><p>值得一提的是，在即将到来的 Devconnect Argentina 期间，两场 OpenBuild 的活动正火热报名中。</p><p>ChainOpera 携手 OpenBuild 打造的「AI Agent x Crypto Afternoon」即将亮相布市。  </p><p><img width="723" height="732" referrerpolicy="no-referrer" src="/img/bVdm3WK" alt="image.png" title="image.png" loading="lazy"/></p><p>报名链接：<a href="https://link.segmentfault.com/?enc=kMW63FR3XlBBs0IXvJz42A%3D%3D.yF7WM4zB9AEv0IaAVbQyba08POMPmaqDXCZjw5qm40k%3D" rel="nofollow" target="_blank">https://luma.com/iin2m6t6</a></p><p>另外，由 OpenBuild、Coset 和 Invisible Garden 共同发起的“Asia Web3 Day @Devconnect Argentina” 将于 11 月 20 日晚上举办。</p><p><img width="723" height="732" referrerpolicy="no-referrer" src="/img/bVdmYNp" alt="image.png" title="image.png" loading="lazy"/></p><p>报名链接：<a href="https://link.segmentfault.com/?enc=%2BItLWLZxgKXGUxXBHQKcrw%3D%3D.2dGgm3%2BxdqcPfTKoChl1asby3rjgDs8ry6DSLb6UTOU%3D" rel="nofollow" target="_blank">https://luma.com/asia-web3-ar25</a></p><p>期待更多开发者加入，一起在 Devconnect Argentina 的现场，共赴这场 Web3 行业盛会！</p><p><img width="723" height="164" referrerpolicy="no-referrer" src="/img/bVdmYMt" alt="image.png" title="image.png" loading="lazy"/></p><p><strong>✅ Move the Future: Aptos x SMU Web3 Innovation Hackathon 2025</strong></p><p>📅 时间：11月10日 - 11月24日</p><p>📍 线上</p><p>💸 奖金：23,000 美元 </p><p>🔗 链接：<a href="https://link.segmentfault.com/?enc=rqTzB4%2Fw2IkF90f3I9poCA%3D%3D.1gY4ZweKQKAh2oiIpcrnWfVDfbMcURWv5NPSUucPK59q4GA5vmL8m2xFrtQhY0mM" rel="nofollow" target="_blank">https://dorahacks.io/hackathon/1759/detail</a></p><p><strong>简介：</strong></p><p>Move the Future 黑客松将学生、开发者和企业家汇聚一堂，共同探索 Aptos Move 生态系统的前沿领域。在未来一周里，参与者们将设计并制作下一代去中心化应用的原型，涵盖数字资产、现实世界资产（RWA）代币化、数据经济、集成人工智能的Web3服务以及协作智能等多个方面。</p><p><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdm3WL" alt="image.png" title="image.png" loading="lazy"/></p><p><strong>✅ Pokéthon: The First Pokémon Hackathon for AI Agents</strong></p><p>📅 时间：11月10日 - 12月1日</p><p>📍 线上</p><p>💸 奖金：20,000 美元 </p><p>🔗 链接：<a href="https://link.segmentfault.com/?enc=X%2BwlL1ShM8Ax1p9dipR1gQ%3D%3D.viDvLgruanVYUduoX3AOdUQKESJDDva%2FkqWmeKIHdiMtuLkL%2FHcgDaaCFCBHUpaB" rel="nofollow" target="_blank">https://dorahacks.io/hackathon/pokethon/detail</a></p><p><strong>简介：</strong></p><p>Pokéthon 是首个以宝可梦为主题的黑客松，致力于打造受宝可梦启发的人工智能智能体。此次黑客松将汇聚人工智能开发者、投资者和收藏家，共同打造受宝可梦启发的智能体，这些智能体融合了人工智能自主性、收藏品特性以及现实世界资产整合功能——为 Web3 领域内宝可梦与人工智能智能体相结合的新领域奠定基础。</p><p><img width="723" height="366" referrerpolicy="no-referrer" src="/img/bVdm3WM" alt="image.png" title="image.png" loading="lazy"/></p><p><strong>✅ Zypherpunk - Zcash Privacy Hackathon</strong></p><p>📅 时间：11月10日 - 12月1日</p><p>📍 线上</p><p>💸 奖金：250,000 美元</p><p>🔗 链接：<a href="https://link.segmentfault.com/?enc=uOTcgEJ6MOLsLjOfjjroQA%3D%3D.qrC76EcJhZeZFzy14svDUGP8ETik1lM8HzylQIOyMnA%3D" rel="nofollow" target="_blank">https://zypherpunk.xyz/</a></p><p><strong>简介：</strong></p><p>Zcash 首届 Zypherpunk 黑客松已经启动！你准备好打造隐私的未来了吗？Zcash 生态系统邀请开发者、数据分析师和内容创作者共同提出以隐私为核心的解决方案。</p><p>参与者将把自己的想法付诸实践，涉及隐私保护人工智能、私密去中心化金融（DeFi）、跨链解决方案、钱包创新、媒体项目等多个领域。</p><p><img width="723" height="458" referrerpolicy="no-referrer" src="/img/bVdm3WN" alt="image.png" title="image.png" loading="lazy"/></p><p><img width="723" height="162" referrerpolicy="no-referrer" src="/img/bVdmYMx" alt="image.png" title="image.png" loading="lazy"/></p><p><strong>📖 以太坊基金会 dAI 团队发布 2026 年路线图 11/10</strong></p><p>👉 链接：<a href="https://link.segmentfault.com/?enc=h0sU8OqOYKbGEkcsxxHUig%3D%3D.uxBrDbd897pFKzo%2BB%2B7pf2tV%2BccxZXn1GzBa8XR705bOVLOfWA4vQ0IsshOcucg6GGB8gVldLIcBugisOBgPvw%3D%3D" rel="nofollow" target="_blank">https://x.com/DavideCrapis/status/1987882455110656488</a></p><p>以太坊基金会人工智能负责人 Davide Crapis 发文表示，正在与以太坊基金会领导层合作制定 dAI 团队 2026 年路线图，旨在建立以太坊作为人工智能的全球去中心化结算和协调基础设施。并感谢围绕 ERC-8004 和 x402 不断壮大的社区。</p><p><strong>📖 当预言机 “三思而后行”：无需许可型预言机的设计 11/13</strong></p><p>👉 链接：<a href="https://link.segmentfault.com/?enc=VDuaNhWAQ3Bv6nJuWaXAFw%3D%3D.B2uH%2F%2FIzEvcN40XqsWOs6nlIE87WSg0YeQ23QKxzdK6RtrY0NoKr%2Fg9S5wXHg%2B%2BUWokygSpzGykm9UZ44V9q1w%3D%3D" rel="nofollow" target="_blank">https://x.com/GearboxProtocol/status/1988636448938217932</a></p><p>DeFi 借贷依赖一个无形却至关重要的组件 ——预言机。一旦预言机出现故障，后果会即刻显现：资金池遭攻击、坏账堆积、资金大规模出逃。但如果预言机设计得当，不仅能为用户带来更优质的体验，还能大幅降低借款方与出借方双方的风险。</p><p><strong>📖 EigenZero：EigenCloud 基础设施如何赋能 LayerZero 下一代跨链安全 11/13</strong></p><p>👉 链接：<a href="https://link.segmentfault.com/?enc=pjETYDR2MiKV42tzeWOFtA%3D%3D.%2FwV8BTMXYsWDVrhMWD0Hh%2FI4lZ0%2F2WWVvJdVcOMFKSIKgcW%2BqbDwXH%2FaiisJ4RxcTBdh%2F5onS5EiIX8Hi2C1dQ%3D%3D" rel="nofollow" target="_blank">https://x.com/eigencloud/status/1988668309085335778?s=20</a></p><p>EigenCloud 与 LayerZero 合作推出 EigenZero，这是加密经济去中心化验证器网络（DVN）框架的首个实现。EigenZero 为 Web3 开发者提供可定制、可量化的跨链消息验证方案，兼容 LayerZero 生态且支持灵活安全配置与定制化开发。</p><p><img width="723" height="164" referrerpolicy="no-referrer" src="/img/bVdmKOQ" alt="image.png" title="image.png" loading="lazy"/></p><p><strong>💸 LayerZero 11/11</strong></p><p>最高赏金 15,000,000 美元 </p><p>LayerZero 是一种全链互操作性协议，它允许开发者无缝地与数十个区块链上的合约进行交互。</p><p><strong>💸 Connext 11/12</strong></p><p>最高赏金 50,000 美元</p><p>Connext 是一种模块化协议，用于在链之间安全地传递资金和数据。开发者可以使用 Connext 构建跨链应用（xApps）—— 即能够同时与多个领域（区块链和 / 或 rollup）进行交互的应用程序。</p><p><strong>💸 Acala 11/14</strong></p><p>最高赏金 200,000 美元 </p><p>Acala 是 Polkadot 的去中心化金融网络和流动性枢纽。它是一个 Layer-1 智能合约平台，具有可扩展性、以太坊兼容性，并为 DeFi 进行了优化，配备内置流动性和现成的金融应用程序。凭借其无需信任的交易所、DOT 流动性质押（LDOT）和 EVM<strong>+，Acala 让开发者能够利用以太坊的优势以及 Substrate</strong> 的全部功能。</p><p><img width="723" height="163" referrerpolicy="no-referrer" src="/img/bVdm3WO" alt="image.png" title="image.png" loading="lazy"/></p><p><strong>🔍 Web3 Security 公开课：入门基础课程</strong></p><p>OpenBuild 社区联合 ResPeer 团队的 KK，推出 Linera 开发者实战系列免费课程。</p><p><img width="723" height="406" referrerpolicy="no-referrer" src="/img/bVdmYKp" alt="image.png" title="image.png" loading="lazy"/></p><p>本次课程将帮助您理解 Linera 如何通过客户端驱动的共识机制**和微链架构来解决传统区块链的性能瓶颈问题。</p><p>👉 报名链接：<a href="https://link.segmentfault.com/?enc=gC0z4rc%2ByR9PCYZxSH7Wew%3D%3D.HulyoOd0ot4pSH3aQfV6CeZgjuxlwsfTQp3ZhM5QCawWy6kb6W4ZFsLcnVaa6myZ" rel="nofollow" target="_blank">https://openbuild.xyz/learn/courses/1082550997</a></p><p><strong>🔍 Web3 Security 公开课：入门基础课程</strong></p><p>为帮助初学者全面了解区块链安全的理论与实践，OpenBuild ×  Exvul 联手，特别设计了一套系统的公开课系列——Web3 安全基础与实战课程。这个系列课程将逐步带领大家从基础安全理论到实际案例分析，开启您的区块链安全之路！ </p><p><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdm3WP" alt="image.png" title="image.png" loading="lazy"/></p><p>通过这门课程，大家将不仅仅学习安全知识，更将成为 Web3 安全生态的一部分，与全球顶尖的区块链安全专家共同推动行业发展。</p><p>👉 报名链接：<a href="https://link.segmentfault.com/?enc=zVrQvUburzp0U7vZU8pbYA%3D%3D.Tx16I7%2FuppMQNxIqW4jkWazSQ%2BsYxDLY4TRva8KV1hLOU2XLn8TCFG8QYkzFahZE" rel="nofollow" target="_blank">https://openbuild.xyz/learn/courses/1083007677</a></p><p><img width="723" height="164" referrerpolicy="no-referrer" src="/img/bVdmKO4" alt="image.png" title="image.png" loading="lazy"/></p><p>OpenBuild 是一个面向 Web3 开发人员的开源社区和平台。我们的目标是将更多的 Web2 开发人员带入 Web3 领域，同时帮助现有的 Web3 开发人员更好地构建并通过我们的产品取得商业成功！</p><p>欢迎在更多平台上关注我们：</p><p><a href="https://link.segmentfault.com/?enc=CAm8%2BAURiPx7c8hgkA55%2Fw%3D%3D.RhZnmG5KahXpc7yAkG64DT8VAroqGL4B00qyvF%2FqhwY%3D" rel="nofollow" target="_blank">https://linktr.ee/openbuild</a> 🙌🙌</p>]]></description></item><item>    <title><![CDATA[Agent 创作者社区召集令 | Sen]]></title>    <link>https://segmentfault.com/a/1190000047403384</link>    <guid>https://segmentfault.com/a/1190000047403384</guid>    <pubDate>2025-11-16 21:02:19</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdmYNY" alt="image.png" title="image.png"/></p><p>Sense Space 正在找热爱 AI Agent 的创作者！无论你是研究 LLM 的开发者，还是热衷探索 Agent 的爱好者，Sense Space 黑客松都为你准备了舞台。</p><p>本次黑客松由 Sense Space 主办，OpenBuild 大力支持！作为深耕开源生态的开发者社区，我们始终致力于为 AI Agent 创作者搭建成长与变现的桥梁，与全球创新者共探 Agent 价值新可能！</p><h3><strong>为什么值得加入？</strong></h3><p>Sense Space 是基于 Verisense 网络的全球首个 Agent 共享经济平台。</p><p>在这里，你可以：</p><p>✅ 构建自己的 AI Agent，让别人使用你的成果并付费</p><p>✅ 分享你的 MCP**（Model Context Protocols），让它被复用并获得收益</p><p>✅ 让你的 Agent 套件为个人、企业提供服务</p><p>就像 Uber 让司机共享行程，YouTube 让创作者分享视频，Sense Space 让你的 AI 能力产生价值，每一个 Agent 都可能成为你的收入来源！</p><h3><strong>黑客松怎么玩？</strong></h3><p><strong>📅 时间：</strong> 10 月 22 日 – 12 月 6 日（足够时间自由构建一个高品质并可以商业化的 agent）</p><p><strong>🎯 主题：</strong> 开放！任何 Agent、任何 MCP、任何框架都可以！</p><p><strong>👉 要求：</strong> 只需要 A2A** 兼容，并注册到 Verisense Network 即可。</p><p><strong>🌐 评审：</strong> 初赛 11/23–11/27，入围名单 12/2公布</p><p><strong>💻 Demo Day</strong>：** 12/6，Top 10 团队现场路演</p><p><strong>注册：</strong> <a href="https://link.segmentfault.com/?enc=VlYYZ%2B%2FJ5bFNzXoDi%2FajWg%3D%3D.Bnn%2BsIAiBFiCQqK4%2B44iyvb4D9Wr6eb%2BofIv%2BRK8QGofDdOMoN%2B1hwklFURTOJX0Hq0XjfP150SOthZN9yIrOw%3D%3D" rel="nofollow" target="_blank">https://dorahacks.io/hackathon/calling-for-all-agents-sf/detail</a></p><h3><strong>奖励很丰厚</strong></h3><p>✅ 现金奖励</p><p>✅ 平台使用特权 &amp; 积分</p><p>✅ 免费使用 LLM API Key和MCP</p><p>✅ 周末度假体验 </p><p>✅ 招聘 &amp; 人脉拓展机会</p><p>✅ ...更多惊喜等你来拿！</p><h3><strong>黑客资源全都有</strong></h3><p>✅ Sense Space Agent &amp; Mini App 部署指南</p><p>✅ LLM Keys（Ambient、Gemini）</p><p>✅ 教程：如何构建可互操作的 Agent</p><p>✅ Discord 社区支持：<a href="https://link.segmentfault.com/?enc=jJ%2FLgKzf%2FOxc15aTE2mwbA%3D%3D.k%2BWnUPuW0jtVvuuNLXjxS%2FN3dInHyBLqRf1JmNjTyFHXSh9pL16RwA02FzXdZUg4" rel="nofollow" target="_blank">https://discord.com/invite/mt4YhFdk</a></p><p>✅ 邮箱：<a href="mailto:dev@verisense.network" target="_blank">dev@verisense.network</a></p><h3><strong>谁来评审？</strong></h3><p>来自 AI、投资和开发者生态的顶级专家，包括 Google, Visa, Alibaba** 等风投机构。你的作品，将被业内大咖现场点评。</p><p>🔥 加入我们，和全球的 Agent 创作者一起：</p><p> Build → Share → Earn！</p><p>点击注册/了解详情 → <a href="https://link.segmentfault.com/?enc=g9w0VmqYZtjTL87YKhEbzQ%3D%3D.EFvnU0cHMUM%2FJof69bxrOR2OCETIL%2BoshHpLWGuWUXorlsn%2BWx6DzQLsiAJmfyVOyOT%2BVJ5n3w0r7KiZf83%2BLg%3D%3D" rel="nofollow" target="_blank">https://dorahacks.io/hackathon/calling-for-all-agents-sf/detail</a></p>]]></description></item><item>    <title><![CDATA[PaddleOCR、RapidOCR即O]]></title>    <link>https://segmentfault.com/a/1190000047403388</link>    <guid>https://segmentfault.com/a/1190000047403388</guid>    <pubDate>2025-11-16 21:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>OCR技术，感觉都像是过时的技术了，现在的多模态（VL）模型那么香，什么场景还会用 OCR 呢？</p><p>VL模型确实好用，但在实际使用后也有很大的缺点。NLP 模型就已经很慢了， VL模型的推理速度更慢，token 费用还是 NLP模型的好几倍。很难在实际项目中大规模使用。</p><p>我曾今以为，VL模型就是 <code>OCR + NPL 模型</code>。先通过 OCR技术识别图片中的文字等元素及其坐标信息。然后在给 NPL模型去推理。实际并不是，下面是二者的介绍</p><h2>1. OCR与VL模型</h2><h3>1.1. OCR</h3><p><strong>OCR</strong> 是一种将图片、扫描文档、手写文字等非文本信息转换成可编辑、可搜索的文本的技术。  <br/>它的核心目标是<strong>让计算机“读懂”图片里的文字</strong>，从而实现文字信息的数字化。</p><blockquote><strong>OCR 的工作原理</strong></blockquote><p>OCR 的基本流程一般包括以下几个步骤：</p><ol><li><p><strong>图像预处理</strong></p><ul><li>去噪（Noise Reduction）：去掉背景噪声，提高识别准确率。</li><li>二值化（Binarization）：将彩色或灰度图转为黑白，方便后续处理。</li><li>纠正倾斜（Deskew）：调整扫描文档的倾斜角度。</li><li>对比度增强（Contrast Enhancement）：提高文字与背景的区分度。</li></ul></li><li><p><strong>文字区域检测</strong></p><ul><li>使用算法（如 CTPN、EAST、DBNet 等）定位图片中的文字区域。</li><li>分割出每一行、每一个字符或词。</li></ul></li><li><p><strong>字符识别</strong></p><ul><li>传统方法：基于模板匹配、特征提取（如投影、轮廓、笔画）+分类器（SVM、KNN）。</li><li>现代方法：基于深度学习的卷积神经网络（CNN）、循环神经网络（RNN）、Transformer 等，直接端到端识别文字。</li></ul></li><li><p><strong>后处理</strong></p><ul><li>拼接字符序列为完整文本。</li><li>使用语言模型或词典进行纠错（如拼写修正）。</li><li>格式化输出（保留段落、表格等结构）。</li></ul></li></ol><blockquote><strong>OCR 的分类</strong></blockquote><p>根据应用场景和识别对象，OCR 可以分为：</p><ul><li><strong>印刷体 OCR</strong>：识别印刷字体（报纸、书籍、票据等）。</li><li><strong>手写 OCR</strong>：识别手写文字（笔记、表单）。</li><li><strong>多语言 OCR</strong>：支持中文、英文、日文、韩文等多种语言。</li><li><strong>特殊字符 OCR</strong>：识别公式、化学结构、乐谱等。</li></ul><p>OCR 的应用场景：</p><ul><li><strong>文档数字化</strong>：将纸质书籍、档案扫描成可编辑文本。</li><li><strong>票据识别</strong>：发票、收据、车票等自动录入。</li><li><strong>身份证/护照识别</strong>：自动读取证件信息。</li><li><strong>车牌识别</strong>：交通管理、停车场收费系统。</li><li><strong>图像搜索</strong>：在图片中搜索文字内容。</li><li><strong>辅助工具</strong>：帮助视障人士“读”文字信息。</li></ul><blockquote><strong>常用 OCR 技术与工具</strong></blockquote><ul><li><p><strong>开源工具</strong>：</p><ul><li><strong>Tesseract OCR</strong>：Google 维护的开源 OCR 引擎，支持多语言。</li><li><strong>PaddleOCR</strong>：百度飞桨的 OCR 工具，支持检测+识别一体化。</li><li><strong>EasyOCR</strong>：基于 PyTorch 的轻量级 OCR。</li></ul></li><li><p><strong>商业服务</strong>：</p><ul><li><strong>Google Cloud Vision API</strong></li><li><strong>Microsoft Azure OCR</strong></li><li><strong>百度智能云 OCR</strong></li><li><strong>阿里云 OCR</strong></li><li><strong>腾讯云 OCR</strong></li></ul></li></ul><h3>1.2. VL模型</h3><p>VL 模型（Vision-Language Model）是 <strong>同时处理视觉信息（图片/视频）和语言信息（文本）的大模型</strong>。  <br/>它的目标是让机器具备类似人类的<strong>看图理解</strong>能力。</p><blockquote><strong>基本架构</strong></blockquote><p>一个典型的 VL 模型由两部分组成：</p><ol><li><p><strong>视觉编码器（Visual Encoder）</strong></p><ul><li>常见架构：ViT（Vision Transformer）、Swin Transformer、CLIP 的视觉部分。</li><li>输入图片 → 输出一系列视觉特征向量。</li><li>这些向量编码了图片的内容：物体、颜色、布局，甚至文字的形状。</li></ul></li><li><p><strong>语言模型（Language Model / Decoder）</strong></p><ul><li>Transformer 架构的大语言模型（LLM）。</li><li>输入文字 token（或者视觉特征经过投影映射的 token）。</li><li>输出文本（描述、回答、推理结果）。</li></ul></li><li><p><strong>跨模态对齐（Cross-Modal Alignment）</strong></p><ul><li>视觉特征和语言特征通过投影到同一语义空间，实现信息融合。</li><li>方式：Cross-Attention、多模态 Transformer、对比学习（Contrastive Learning）。</li></ul></li></ol><blockquote><strong>训练方式</strong></blockquote><ul><li><strong>配对数据</strong>：图片 + 文本描述（caption）、视觉问答（Q&amp;A）、OCR标注等。</li><li><strong>多任务训练</strong>：图像描述、问答、推理、文字转写、布局分析等。</li><li><strong>对比学习</strong>（如 CLIP）：让图片和文本在同一语义空间靠近。</li></ul><blockquote><strong>VL 模型中的“文字识别”</strong></blockquote><p>VL 模型可以“直接从像素识别文字”，它的文字识别过程不是传统 OCR 的分离式模块，而是<strong>融合在视觉编码器 + 语言模型的联合训练中</strong>：</p><ul><li>视觉编码器会捕捉到文字的形状特征（例如字母的笔画、汉字的结构）。</li><li>语言模型部分在训练中学会将这些视觉特征映射到对应的字符 token。</li><li>推理时，模型在回答问题或生成描述时，可以直接输出图片中的文字，而无需调用外部 OCR。</li></ul><p><strong>例子</strong>：</p><blockquote>输入：一张街景图  <br/>任务：问“这家店的名字是什么？”  <br/>模型：视觉编码器提取整张图的特征，语言模型根据特征直接生成店名。</blockquote><h3>1.3. 区别</h3><p><strong>传统 OCR 流程：</strong></p><ol><li><strong>检测文字区域</strong>（Text Detection）：用专门的检测网络（如 EAST、DBNet）找出图片中有文字的地方。</li><li><strong>裁剪这些区域</strong>，送到识别网络（如 CRNN）逐个识别字符。</li><li>输出结构化文本。</li></ol><p><strong>端到端 VL 模型</strong>（例如 GPT-4V、Kosmos-2、Qwen-VL）：</p><ul><li>没有显式的“检测”步骤，也不会裁剪。</li><li>视觉编码器直接接收整张图片的像素，并输出一组向量。</li><li>语言模型通过这些向量<strong>在推理时“自己”找出文字的位置并识别</strong>，因为它在训练时已经学会了这个能力。</li></ul><blockquote><strong>举个类比</strong></blockquote><p>你可以把它想成一个人：</p><ul><li>传统 OCR：先用眼睛扫描文字位置，放大局部，逐个认字。</li><li>端到端 VL 模型：你看整张照片的时候，就能在脑中同时看到文字和图像，并且直接理解它写的是什么，无需额外“找字”步骤。</li></ul><blockquote><strong>VL模型识字的核心：视觉编码器 + 文本解码器联合训练</strong></blockquote><p>（1）视觉编码器</p><ul><li>常见是 <strong>ViT（Vision Transformer）</strong> 或 CNN+Transformer。</li><li>把图片切成小块（patches），每个 patch 转成向量（embedding）。</li><li>这些向量包含了局部的颜色、形状、纹理等信息。</li><li>对于有文字的区域，这些向量会包含字符的形状信息。</li></ul><p>（2）跨模态对齐</p><ul><li>模型训练时，会输入图片和它对应的文本描述（caption）、文字转写（OCR标签）、或视觉问答答案。</li><li>损失函数会引导模型让视觉特征和文字输出对齐。</li><li>例如：训练数据可能是图片+“这张图片上的牌子写着 STOP”，模型必须学会从像素中找到对应的字母形状并生成“STOP”。</li></ul><p>（3）解码文字</p><ul><li>语言模型部分（Transformer解码器）接收视觉编码器输出的向量。</li><li>当模型需要输出文字时，它会从视觉特征中“取出”对应的形状信息并映射到字母/汉字的token。</li><li>因为模型的词表里有字母、汉字等符号，视觉特征被训练成可以激活对应的token概率。</li></ul><h3>1.4. 适用于不同业务场景</h3><ul><li><strong>OCR 是一种单模态视觉任务</strong>，目标是精准提取图片中的文字，通常输出纯文本+坐标。</li><li><strong>VL 模型是多模态 AI 系统</strong>，文字识别只是它的一项能力，它更关注文字与视觉、语言的融合与推理。</li><li><p><strong>工业应用中常用混合方案</strong>：</p><ul><li>用 OCR 提供高精度文字和位置信息</li><li>用 VL 模型做语义理解、推理、生成</li></ul></li></ul><blockquote><strong>OCR</strong></blockquote><ul><li><p><strong>优势</strong></p><ul><li>精度高，尤其是小字、低分辨率、复杂字体</li><li>可输出精确位置坐标</li><li>结构化输出（适合文档、表格）</li></ul></li><li><p><strong>劣势</strong></p><ul><li>不理解文字与图像的语境</li><li>需要额外 NLP 才能做推理</li><li>对非文字视觉任务（如物体识别）无能为力</li></ul></li></ul><blockquote><strong>VL 模型</strong></blockquote><ul><li><p><strong>优势</strong></p><ul><li>同时理解文字和视觉内容</li><li>能做跨模态推理（例如“图中写的折扣信息对应哪种商品？”）</li><li>可端到端完成任务（不依赖外部 OCR）</li></ul></li><li><p><strong>劣势</strong></p><ul><li>小字或特殊字体识别精度可能不如专用 OCR</li><li>输出坐标、版面结构的能力弱（除非特别训练）</li><li>训练成本和数据需求大</li></ul></li></ul><blockquote><strong>应用场景的区别</strong></blockquote><table><thead><tr><th>场景</th><th>推荐 OCR</th><th>推荐 VL 模型</th></tr></thead><tbody><tr><td>扫描文档电子化</td><td>✅ 精准提取文本</td><td>❌ 不擅长结构化输出</td></tr><tr><td>发票/票据录入</td><td>✅ 高精度文字识别</td><td>❌ 推理不必要</td></tr><tr><td>场景文字理解（招牌、广告）</td><td>OCR 提取文字 + NLP</td><td>✅ 可直接理解文字与场景关系</td></tr><tr><td>图文问答</td><td>❌</td><td>✅</td></tr><tr><td>图表数据问答</td><td>OCR 提取数值 + LLM</td><td>✅ 端到端理解图表内容</td></tr></tbody></table><h2>2. PaddleOCR 与 RapidOCR</h2><h3>2.1. PaddleOCR</h3><h4>2.1.1 介绍</h4><p>PaddleOCR 是由 <strong>百度飞桨（PaddlePaddle）团队</strong>开源的 OCR（Optical Character Recognition，光学字符识别）全流程解决方案。  <br/>它的目标是：</p><blockquote>提供从数据准备、模型训练、评估，到推理、部署的<strong>端到端 OCR 工具库</strong>，支持多语言、多场景。</blockquote><p>首个版本在 2020 年推出，至今已经迭代到 <strong>PP-OCRv5</strong>，并形成了一个庞大的开源社区。</p><blockquote><strong>技术特点</strong></blockquote><ul><li><strong>全流程支持</strong>：训练 + 推理 + 部署。</li><li><strong>多语言多场景</strong>：适合全球化应用。</li><li><strong>轻量化模型</strong>：PP-OCR 系列适合移动端。</li><li><strong>社区活跃</strong>：有丰富的教程和预训练模型。</li></ul><blockquote><strong>适用场景</strong></blockquote><ul><li>需要从零训练或微调模型。</li><li>需要版面分析、表格识别等高级功能。</li><li>部署环境能接受 PaddlePaddle 框架的体积和依赖。</li><li>研究和教学用途。</li></ul><h4>2.1.2 核心功能</h4><ol><li><p><strong>文字检测</strong></p><ul><li>定位图片中的文字区域。</li><li>支持多种检测模型：DBNet、EAST、SAST、PSE 等。</li><li>支持旋转文本检测。</li></ul></li><li><p><strong>文字识别</strong></p><ul><li>将检测到的文字区域转为可读文本。</li><li>支持多语言（80+种），包括中文、英文、日文、韩文、阿拉伯文等。</li><li>常用识别模型：CRNN、SVTR、RARE、Rosetta 等。</li></ul></li><li><p><strong>方向分类</strong></p><ul><li>检测文字方向（如 0°、90°、180°、270°），自动矫正。</li></ul></li><li><p><strong>版面分析</strong></p><ul><li>对复杂文档进行版面结构解析（Layout Analysis）。</li><li>表格识别、公式识别、印章检测等。</li></ul></li><li><p><strong>模型训练与优化</strong></p><ul><li>支持自定义数据集训练。</li><li>提供数据增强、迁移学习、蒸馏、量化等优化方法。</li></ul></li><li><p><strong>多平台部署</strong></p><ul><li>支持 Python、C++、Paddle Lite（移动端）、Paddle Serving（服务端）、Docker 等。</li></ul></li></ol><h3>2.2. RapidOCR</h3><h4>2.2.1 背景</h4><p>RapidOCR 是一个<strong>轻量级 OCR 推理库</strong>，由国内开发者开源，核心理念是：</p><blockquote><strong>只做 OCR 推理，不负责训练，简化部署和集成，让 OCR 模型可以在不同平台快速运行。</strong></blockquote><p>它本质上是一个<strong>精简版推理工具</strong>，可以直接加载 PaddleOCR 训练好的模型（或其他兼容模型），并在多种推理后端运行。</p><blockquote><strong>技术特点</strong></blockquote><ul><li><strong>轻量化</strong>：去掉训练、数据处理等复杂功能。</li><li><strong>启动快</strong>：不加载完整深度学习框架。</li><li><strong>灵活后端</strong>：可根据硬件选择最佳推理引擎。</li><li><strong>易集成</strong>：适合嵌入到 C++ 项目、移动应用等。</li></ul><blockquote><strong>适用场景</strong></blockquote><ul><li>只做推理，不需要训练。</li><li>需要在移动端、嵌入式设备部署。</li><li>对启动速度和资源占用敏感。</li><li>希望减少依赖，简化部署流程。</li></ul><h4>2.2.2 核心功能</h4><ol><li><p><strong>模型加载与推理</strong></p><ul><li>支持检测模型 + 识别模型的加载。</li><li>输入图片，输出文字识别结果。</li></ul></li><li><p><strong>多推理后端支持</strong></p><ul><li>ONNX Runtime（跨平台）</li><li>NCNN（移动端 / 嵌入式）</li><li>Paddle Inference（原生 Paddle 推理）</li><li>OpenCV DNN（轻量推理）</li></ul></li><li><p><strong>跨平台运行</strong></p><ul><li>Windows / Linux / macOS / Android / iOS / 嵌入式设备。</li></ul></li><li><p><strong>简洁 API</strong></p><ul><li>几行代码即可完成 OCR 推理。</li></ul></li></ol><h3>2.3. 二者关系</h3><p>很多人在初学 PaddleOCR 和 RapidOCR 的时候都会有同样的疑惑：  <br/><strong>“既然 RapidOCR 也是用 PaddleOCR 的模型，那直接用 PaddleOCR 推理不就好了？为什么还要用 RapidOCR？”</strong></p><h4>2.3.1. 二者对比</h4><blockquote><strong>直接运行 PaddleOCR 的特点</strong></blockquote><ul><li><p><strong>优点</strong></p><ol><li>功能非常全面：除了推理，还能训练、评估、版面分析、多语言支持等。</li><li>官方维护，文档和社区活跃。</li><li>支持 PaddlePaddle 的全套生态（Paddle Lite、Paddle Serving 等）。</li><li>直接使用预训练模型，简单命令即可完成 OCR。</li></ol></li><li><p><strong>缺点</strong></p><ol><li><strong>依赖多</strong>：需要安装 PaddlePaddle（深度学习框架），体积较大。</li><li><strong>启动慢</strong>：第一次加载模型和框架初始化时间较长。</li><li><strong>跨平台部署复杂</strong>：在 Android/iOS/嵌入式设备上部署 PaddlePaddle 推理库相对麻烦。</li><li><strong>集成成本高</strong>：如果你只是想在一个小工具里做推理，PaddleOCR 的代码和依赖会显得“笨重”。</li></ol></li></ul><blockquote><strong>RapidOCR 的特点</strong></blockquote><ul><li><p><strong>优点</strong></p><ol><li><strong>轻量化</strong>：只保留推理部分，代码和依赖精简很多。</li><li><strong>跨平台方便</strong>：支持 ONNX Runtime、NCNN、OpenCV 等多种后端，适合在 Windows/Linux/macOS/Android/iOS/嵌入式设备部署。</li><li><strong>启动快</strong>：不需要加载完整的 Paddle 框架，推理引擎初始化速度快。</li><li><strong>集成简单</strong>：API 很精简，几行代码就能跑通。</li><li><strong>多后端选择</strong>：可以根据硬件选择最佳推理引擎（例如在 GPU 用 TensorRT，在移动端用 NCNN）。</li><li><strong>依赖可控</strong>：比如你用 ONNX Runtime 推理，只需要安装 onnxruntime 库，不必安装 PaddlePaddle。</li></ol></li><li><p><strong>缺点</strong></p><ol><li>不能训练模型。</li><li>功能比 PaddleOCR 少（比如版面分析、表格识别等高级功能不内置）。</li><li>文档和社区规模比 PaddleOCR 小。</li></ol></li></ul><blockquote><strong>对比结论</strong></blockquote><table><thead><tr><th>需求/特性</th><th>PaddleOCR</th><th>RapidOCR</th></tr></thead><tbody><tr><td><strong>功能范围</strong></td><td>全流程（训练+推理+分析）</td><td>仅推理（检测+识别）</td></tr><tr><td><strong>依赖体积</strong></td><td>大（需要 PaddlePaddle）</td><td>小（可选 ONNX/NCNN 等）</td></tr><tr><td><strong>跨平台部署</strong></td><td>相对复杂</td><td>非常方便</td></tr><tr><td><strong>启动速度</strong></td><td>较慢</td><td>较快</td></tr><tr><td><strong>集成成本</strong></td><td>高（代码量大）</td><td>低（API 简单）</td></tr><tr><td><strong>适合场景</strong></td><td>研究、训练、功能全面部署</td><td>轻量化部署、移动端、嵌入式</td></tr></tbody></table><h4>2.3.2. 什么场景适用使用</h4><blockquote><strong>什么时候选 PaddleOCR，什么时候选 RapidOCR？</strong></blockquote><ul><li><p><strong>选 PaddleOCR</strong>：</p><ul><li>需要自己训练模型。</li><li>需要版面分析、表格识别等高级功能。</li><li>部署环境可以接受 PaddlePaddle 的体积和依赖。</li><li>开发阶段，需要快速测试各种模型和参数。</li></ul></li><li><p><strong>选 RapidOCR</strong>：</p><ul><li>只做推理，不需要训练。</li><li>目标平台是移动端、嵌入式设备、跨平台应用。</li><li>需要轻量化部署，减少依赖和启动时间。</li><li>想要灵活选择推理后端（ONNX Runtime、NCNN、TensorRT 等）。</li><li>对集成简洁性要求高（比如嵌入到一个 C++ 项目或小型工具里）。</li></ul></li></ul><blockquote><strong>一句话总结</strong></blockquote><ul><li><strong>PaddleOCR</strong> 是一个功能全面的“工厂”，适合生产和测试模型；</li><li><strong>RapidOCR</strong> 是一个轻量化的“收银机”，适合快速、低成本地部署现成模型。</li><li>如果你只需要跑模型，RapidOCR 会更轻、更快、更好集成。</li></ul><h3>2.4. 本地快速体验</h3><h4>2.4.1. PaddleOCR</h4><p>使用 PaddleOCR，需要先安装 Paddle 飞桨框架，虽然官方命令简单，但要处理本地电脑的各类环境版本问题。</p><p>如果只是体验，建议直接安装 Docker 版本，参考官方文档：<a href="https://link.segmentfault.com/?enc=bRvawag4BcY5J7nGw5LzwQ%3D%3D.oDdIp9i6M7FgLhvWJexuOY39Kg%2FJ2TMDMMMXutSEvPvDeD%2BgSsM02wNrRMGWAX8VDhPfnO8I1J0erl4HGzeW5A%3D%3D" rel="nofollow" target="_blank">Paddle 安装文档</a></p><p>参考其中 <code>基于 Docker 安装飞桨</code> 部分，没有 GPU 条件，就选择 CPU 即可。</p><p>也可以参考以下脚本：</p><pre><code class="shell">#!/bin/bash
# 启动 PaddleOCR 容器（后台运行且保持不退出，并自动安装 paddleocr）

CONTAINER_NAME="paddleocr"
IMAGE="ccr-2vdh3abv-pub.cnc.bj.baidubce.com/paddlepaddle/paddle:3.0.0"

# 如果容器已经存在，则先删除
if [ "$(docker ps -aq -f name=$CONTAINER_NAME)" ]; then
    echo "删除已有容器 $CONTAINER_NAME..."
    docker rm -f $CONTAINER_NAME
fi

echo "启动容器 $CONTAINER_NAME..."
docker run --name $CONTAINER_NAME \
    --platform linux/amd64 \
    -v "$PWD":/paddle \
    -p 8080:8080 \
    --shm-size=8G \
    -d \
    $IMAGE \
    tail -f /dev/null

# 等容器启动稳定
sleep 3

echo "在容器中安装 paddleocr..."
docker exec $CONTAINER_NAME python -m pip install paddleocr

echo "容器 $CONTAINER_NAME 已启动并安装完成"
echo "进入容器请执行：docker exec -it $CONTAINER_NAME /bin/bash"</code></pre><p>安装完成后，既可以通过 <code>paddle</code> 的 cli 执行命令训练、推理。</p><p>当然，最方便的方式是通过 HTTP 方式调用 OCR 推理服务。</p><p>官网也提供了启动 HTTP 服务端的文档：<a href="https://link.segmentfault.com/?enc=9tfAtD7Hd3lpyeg1yc1tGg%3D%3D.%2BxWUxI5fdW4zLhFazD1mmKd5uwIAyqN73tGWTbVdhoDdJmC1lCsPmkT80vAbovdjA3NSbS41BvEXk4HOeqNYm2O5X8%2BiIXtgNP5EsPRnDus%3D" rel="nofollow" target="_blank">服务化部署</a></p><p>脚本中映射 8080 端口，就是为了宿主机能直接方法 HTTP 服务端。</p><p>调用 HTTP API 参数文档：<a href="https://link.segmentfault.com/?enc=SSmr9CAztTIZA573mVYD1Q%3D%3D.6gQDLOKNLwsKYslE4p%2F9e7vssyFFh24VbQi4%2BmPNPAotqvzxh%2BYImq%2B%2Fg44%2BYaTHgRZ5KqgCBsWe%2B5U9a%2B%2FSh7Z40xMi8j8o%2BXC6hGRLGRo%3D" rel="nofollow" target="_blank">API 请求参数说明</a></p><blockquote><strong>上传图片方式限制</strong></blockquote><p>通过看API文档可见，上传图片/PDF时，仅支持两种方式：</p><ul><li>文件 URL</li><li>BASE64 编码</li></ul><p>默认不支持文件流传输，这两种方式都会限制上传图片速度。</p><h4>2.4.2. RapidOCR</h4><p>Rapid OCR 的官方文档参考：<a href="https://link.segmentfault.com/?enc=FT6p53vXIJ3%2FSJwkgcuoDw%3D%3D.Z36OVgYrccd6PZ7y%2F3KLFyhOL4AyqqzQrKjBRkb%2Fbsq%2FtkOXldg0g7LZzhIr8%2Frz0lN7Q5IVir8Aip8BLtKas94jJaEAETD5B4Wy8xlOktUXBC%2FlYV7WOvmgcfE7NloX" rel="nofollow" target="_blank">RapidOCR文档</a></p><p>通常安装 <code>rapidocr</code> 即可实现图片推理，有通过官方提供的配置参数，可以自定义不同场景的配置。</p><p>就包括使用的模型，可以直接配置 paddleocr 最新的 v5 模型。当然，推荐使用基于 ONNX 引擎的模型格式。</p><p>也可以通过安装 <code>rapidocr_web</code> 实现功能更丰富的 WEB 服务。rapidocr_web是基于rapidocr库封装的web版OCR程序。它可以让小伙们快速在本地启动OCR服务，支持剪贴板、拖拽和选择图像文件上传识别，同时具有一键复制识别文本功能</p><p>如果更方便的安装，并且只需要 HTTP API，可以通过 <code>rapidocr_api</code> 安装。该包是将rapidocr库做了API封装，采用FastAPI + uvicorn实现。</p><p>这里也推荐 Docker 快速安装的法子。这次官网的文档不是很准确，仓库已经更新为<code>RapidOCRAPI</code>，但文档依然是 <code>RapidOCR</code>。踩过坑，推荐自己构建镜像再运行。</p><p>在 <a href="https://link.segmentfault.com/?enc=rz94KCwwrtOT%2BRuJZZVVwg%3D%3D.a7ybjDxy1XO0ys1EeqpNgz4WKN2WyRClh2Rnkv9YeQHrhW6tK205Q0M3cUHJztcr" rel="nofollow" target="_blank">RapidOCRAPI - releases</a> 中拉取最新 releases 的代码下来，在项目根目录有 Dockerfile 文件，直接基于该 Dockerfile 构建镜像，然后安装文档指令运行即可。</p><p>容器启动时，HTTP 服务器即自动启动了。可以在容器内修改模型文件等配置。这里的 API 就支持基于文件流上传，而且感觉推理速度也比 PaddleOCR快。</p><h2>3. ONNX</h2><p>PaddleOCR 模型能在 RapidOCR 上运行，就是因为转换成 ONNX格式。包括后续还有文章介绍 Yolo 模型，也是要转换成 ONNX 格式才会有更多部署平台。</p><p>好的，我们来系统、详细地介绍一下 <strong>ONNX</strong>（Open Neural Network Exchange），包括它的背景、作用、技术细节、生态、优缺点、使用场景，以及它与 PaddleOCR/RapidOCR 的关系。</p><h3>3.1. 定义</h3><p><strong>ONNX</strong> 全称 <strong>Open Neural Network Exchange</strong>，是一个 <strong>开放的深度学习模型交换格式</strong> 和 <strong>跨框架推理生态</strong>。  <br/>它由 <strong>微软（Microsoft）</strong> 和 <strong>Facebook（Meta）</strong> 在 2017 年联合推出，后来得到了 <strong>AWS、NVIDIA、Intel、AMD</strong> 等众多厂商的支持。</p><p><strong>核心目标</strong>：</p><blockquote>提供一个统一的中间表示（Intermediate Representation, IR），让不同深度学习框架之间的模型可以互相转换和运行，从而避免“框架锁定”。</blockquote><ul><li><strong>ONNX</strong> = 深度学习模型的“通用语言”，让模型可以跨框架、跨平台运行。</li><li>它解决了训练框架和部署环境之间的“语言不通”问题。</li><li>在 OCR 场景下，ONNX 让 PaddleOCR 的模型可以用 RapidOCR 在各种设备上运行。</li></ul><h3>3.2. 解决痛点</h3><p>在深度学习应用中，常见的痛点是：</p><ul><li><strong>跨框架问题</strong>：模型在 PyTorch 中训练，但部署环境只支持 TensorFlow 或 C++。</li><li><strong>跨平台问题</strong>：需要在移动端、嵌入式设备上运行模型，但原框架不适合直接部署。</li><li><strong>硬件优化问题</strong>：希望在不同硬件（CPU / GPU / NPU / FPGA）上快速切换推理引擎。</li></ul><p>ONNX 就像一个<strong>通用适配器</strong>：</p><ul><li>训练时用你喜欢的框架（PyTorch、TensorFlow、PaddlePaddle 等）。</li><li>导出成 ONNX 格式。</li><li>部署时用任何支持 ONNX 的推理引擎（ONNX Runtime、TensorRT、OpenVINO、NCNN 等）。</li></ul><h3>3.3. ONNX 的核心组成</h3><blockquote><strong>ONNX 模型格式</strong></blockquote><ul><li>文件后缀 <code>.onnx</code>。</li><li>基于 <strong>Protocol Buffers</strong> 存储。</li><li><p>包含：</p><ul><li><strong>计算图结构</strong>（Graph）</li><li><strong>算子定义</strong>（Operators）</li><li><strong>模型权重</strong>（Weights）</li></ul></li><li>结构化且跨平台可解析。</li></ul><blockquote><strong>ONNX 算子集（Operator Set）</strong></blockquote><ul><li>定义了标准算子（如 Conv、Relu、MatMul、Softmax 等）。</li><li>每个算子有版本号（opset version），保证不同版本间的兼容性。</li><li>框架在导出时会选择合适的 opset 版本。</li></ul><blockquote><strong>ONNX Runtime</strong></blockquote><ul><li>由微软开源的高性能推理引擎。</li><li><p>支持多种硬件后端：</p><ul><li>CPU（默认）</li><li>GPU（CUDA）</li><li>TensorRT</li><li>DirectML（Windows GPU）</li><li>OpenVINO（Intel CPU/FPGA）</li></ul></li><li>提供多语言 API：Python、C、C++、C#、Java、JavaScript 等。</li></ul><h3>3.4. ONNX 的工作流程</h3><p>一个典型的 ONNX 使用流程：</p><ol><li><p><strong>训练模型</strong></p><ul><li>在 PyTorch / TensorFlow / PaddlePaddle / MXNet 等框架中训练。</li></ul></li><li><p><strong>导出 ONNX 模型</strong></p><ul><li><p>PyTorch:</p><pre><code class="python">torch.onnx.export(model, input_data, "model.onnx", opset_version=11)</code></pre></li><li><p>TensorFlow:</p><pre><code class="bash">python -m tf2onnx.convert --saved-model ./model --output model.onnx</code></pre></li><li><p>PaddlePaddle（PaddleOCR）：</p><pre><code class="bash">python tools/export_model.py --output_dir ./inference --export_onnx True</code></pre></li></ul></li><li><p><strong>加载并推理</strong></p><ul><li><p>使用 ONNX Runtime（或其他支持 ONNX 的引擎）：</p><pre><code class="python">import onnxruntime as ort
session = ort.InferenceSession("model.onnx")
outputs = session.run(None, {"input": input_array})</code></pre></li></ul></li><li><p><strong>部署到目标平台</strong></p><ul><li>Windows / Linux / macOS / Android / iOS / 嵌入式设备等。</li></ul></li></ol><blockquote><strong>ONNX 的常见使用场景</strong></blockquote><ol><li><p><strong>跨框架部署</strong></p><ul><li>在 PyTorch 训练 → 转 ONNX → 在 TensorRT 推理。</li></ul></li><li><p><strong>移动端 / 嵌入式部署</strong></p><ul><li>转 ONNX → 用 NCNN/MNN/OpenVINO 等运行。</li></ul></li><li><p><strong>云端推理服务</strong></p><ul><li>用 ONNX Runtime 部署到云端，支持多语言调用。</li></ul></li><li><p><strong>模型优化</strong></p><ul><li>ONNX Runtime 支持图优化、算子融合、量化等。</li></ul></li></ol><h3>3.5. 优缺点</h3><blockquote><strong>ONNX 的优点</strong></blockquote><ol><li><p><strong>跨框架</strong></p><ul><li>支持 PyTorch、TensorFlow、PaddlePaddle、MXNet 等互转。</li></ul></li><li><p><strong>跨平台</strong></p><ul><li>同一个 ONNX 模型可在不同操作系统和硬件上运行。</li></ul></li><li><p><strong>高性能</strong></p><ul><li>ONNX Runtime 针对不同硬件有深度优化。</li></ul></li><li><p><strong>生态丰富</strong></p><ul><li>TensorRT、OpenVINO、NCNN、MNN 等均支持 ONNX。</li></ul></li><li><p><strong>开放标准</strong></p><ul><li>由社区维护，透明可扩展。</li></ul></li></ol><blockquote><strong>ONNX 的缺点 / 限制</strong></blockquote><ol><li><p><strong>算子兼容性问题</strong></p><ul><li>不同框架���某些自定义层可能无法直接转换，需要自己实现。</li></ul></li><li><p><strong>版本问题</strong></p><ul><li>ONNX 模型的 opset 版本不匹配时可能会报错。</li></ul></li><li><p><strong>动态图支持有限</strong></p><ul><li>对部分动态图功能支持不如原框架灵活。</li></ul></li></ol><h3>3.6. 与 PaddleOCR/RapidOCR的关系</h3><ul><li><p><strong>PaddleOCR</strong></p><ul><li>可将训练好的检测模型和识别模型导出为 ONNX 格式。</li><li>方便跨平台部署，不依赖 PaddlePaddle。</li></ul></li><li><p><strong>RapidOCR</strong></p><ul><li>内置 ONNX Runtime 后端。</li><li>可以直接加载 PaddleOCR 导出的 ONNX 模型进行推理。</li><li>这样就能在没有 PaddlePaddle 框架的环境中运行 OCR（例如移动端或嵌入式）。</li></ul></li></ul><p><strong>简单来说</strong>：  <br/>ONNX 是模型的通用格式，RapidOCR 是一个能读取 ONNX 模型并运行的轻量化推理工具。</p><h3>3.7. Java项目可运行ONNX模型</h3><ul><li><strong>ONNX</strong> 本身是一种通用的模型文件格式（<code>.onnx</code>），不依赖具体的编程语言。</li><li>要在 Java（包括 Spring Boot）中运行 ONNX 模型，需要一个支持 ONNX 格式的推理引擎。</li><li><strong>ONNX Runtime</strong> 是官方提供的高性能推理引擎，它有 <strong>Java API</strong>，可以在 JVM 环境中直接加载 <code>.onnx</code> 模型并运行。</li><li><p>因此，在 Spring 项目中，你可以：</p><ol><li>把 ONNX 模型文件放在项目资源目录或本地路径。</li><li>使用 ONNX Runtime Java API 加载模型。</li><li>在业务代码中调用推理方法获得结果。</li></ol></li></ul><p>在 Maven 项目的 <code>pom.xml</code> 中添加 ONNX Runtime 依赖：</p><pre><code class="xml">&lt;dependency&gt;
    &lt;groupId&gt;com.microsoft.onnxruntime&lt;/groupId&gt;
    &lt;artifactId&gt;onnxruntime&lt;/artifactId&gt;
    &lt;version&gt;1.15.1&lt;/version&gt; &lt;!-- 版本可根据需要选择 --&gt;
&lt;/dependency&gt;</code></pre><p>如果需要 GPU（CUDA）推理，可以用：</p><pre><code class="xml">&lt;dependency&gt;
    &lt;groupId&gt;com.microsoft.onnxruntime&lt;/groupId&gt;
    &lt;artifactId&gt;onnxruntime_gpu&lt;/artifactId&gt;
    &lt;version&gt;1.15.1&lt;/version&gt;
&lt;/dependency&gt;</code></pre><p>没错，Java项目中，你可以本地直接运行 PaddleOCR 的模型文件， 前提是和 RapidOCR 一样，先转成 ONNX 格式。</p>]]></description></item><item>    <title><![CDATA[Web3 安全必学！基础 + 实战全覆盖]]></title>    <link>https://segmentfault.com/a/1190000047403316</link>    <guid>https://segmentfault.com/a/1190000047403316</guid>    <pubDate>2025-11-16 20:02:50</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>随着 Web3 生态系统的快速发展，区块链安全已成为保障去中心化未来的核心支柱。无论是智能合约开发者、DApp 架构师，还是普通区块链用户，对安全知识的掌握都至关重要。</p><p>为帮助初学者全面了解区块链安全的理论与实践，<strong>OpenBuild ×  Exvul 联手</strong>，特别设计了一套系统的公开课系列——Web3 安全基础与实战课程。这个系列课程将逐步带领大家从基础安全理论到实际案例分析，开启您的区块链安全之路！ </p><p><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdm3VI" alt="image.png" title="image.png"/></p><p>通过这门课程，大家将不仅仅学习安全知识，更将成为 Web3 安全生态的一部分，与全球顶尖的区块链安全专家共同推动行业发展。</p><h3><strong>课程要点</strong></h3><h4><strong>区块链安全的基础知识</strong></h4><ul><li>深入理解分布式账本**、共识算法和智能合约的工作原理。</li><li>探索区块链生态中的常见安全威胁，如 51% 攻击、私钥泄露、智能合约漏洞等。</li></ul><h4><strong>链上安全威胁的识别与防护</strong></h4><ul><li>学习如何识别常见的智能合约漏洞（如重入攻击、整数溢出、权限控制问题）。</li><li>掌握安全开发的最佳实践，避免常见的合约安全问题。</li></ul><h4><strong>主流区块链安全工具与技术</strong></h4><ul><li>探索主流的安全审计工具与平台，如 BlockSec** 和 Exvul 平台的专属工具。</li><li>学习如何通过这些工具检测漏洞并优化智能合约代码。</li></ul><h4><strong>实际案例分析与实战演练</strong></h4><ul><li>通过真实案例（如 DeFi 项目漏洞事件）分析攻击过程与防护策略。</li><li>实战演练：修复一个存在漏洞的智能合约，提升您的实操能力。</li></ul><h4><strong>课程大纲</strong></h4><h4><strong>第一课：入门 Web3 必修的安全基础课</strong></h4><p>Web3 入门必冲，安全地基课  带你打牢安全底层逻辑！</p><p><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdm3VJ" alt="image.png" title="image.png" loading="lazy"/></p><h4><strong>第二课：揭秘合约安全隐患，常见致命漏洞详解</strong></h4><p>智能合约作为 Web3 重要组成部分，但漏洞藏雷无数，本节课带你深度扒光常见致命漏洞，教你避雷对策。</p><p><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdm3VK" alt="image.png" title="image.png" loading="lazy"/></p><h4><strong>第三课：拆解交易攻击，深度分析与复现</strong></h4><p>MEV 狙击、钓鱼攻击、重放攻击**… Web3 交易坑太多？ 本节课带你沉浸式复现攻击链路，吃透防御心法，掌握应对之策。</p><p><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdm3VL" alt="image.png" title="image.png" loading="lazy"/></p><h3><strong>立即报名</strong></h3><p>本系列课程已经上架到 OpenBuild 官网，登录报名后即可开始学习。包含 3 节精彩视频课程，并同步共享 84 页详细知识点 PPT。</p><p>报名链接：<a href="https://link.segmentfault.com/?enc=HP0ItpeD1C%2FVmzX6YQd7AQ%3D%3D.dnJSBDCWqW5EWI%2FGFIjk1vI0SCdbtkIAQGZYBj0UQ0J7l6BK74Bfv1p8rXHCjvQp" rel="nofollow" target="_blank">https://openbuild.xyz/learn/courses/1083007677</a></p><p>欢迎你加入课程学习群，获取课程 PPT，还有讲师为您答疑解惑。让我们一起学习，共同进步！或添加小助手微信 （ID:Carly860755 )，备注“安全”</p><h3><strong>学完本课程，你将收获满满</strong></h3><p>✅ 构建 6 大模块安全知识体系</p><p>✅ 深度剖析 20 + 真实被盗案例</p><p>✅ 熟练掌握 10 + 必备安全工具使用方法</p><p>✅ 拥有防骗防盗实操清单</p><p>✅ 摇身一变成为朋友圈的 Web3 安全顾问</p><p>在 Web3 的世界里，安全知识绝非可有可无，而是人人必修。衷心希望这门基础课程，能助力大家筑牢安全意识防线，避免不必要的资产损失。</p><p>延伸阅读 - <a href="https://link.segmentfault.com/?enc=WIR3bTBQNyobldacCUjC7A%3D%3D.%2BdVWHGy54JQiwEMU1IbVO%2FnRB8XrkewyHqaJdu7Ub7zM6%2B%2FliTxkmidak3f9Q1PRSXt7kzmoNdffeT0DX1C3cEHi8Y8RmrDr2DFUD2jtko0E85nND%2BGQ1cZgbnrfN%2FWR10Cfl2kTCXTDjo3AKssBLrhTg8MyzvyfXeXSIJ5cJhI%3D" rel="nofollow" target="_blank">智能合约漏洞解密</a></p><h3><strong>关于 Exvul</strong></h3><p>ExVul 是一家 Web3 安全公司，服务范围涵盖智能合约审计、区块链协议审计、钱包审计、Web3 渗透测试、安全咨询与规划。ExVul 致力于提升 Web3 生态整体安全性，始终站在 Web3 安全研究前沿领域。 </p><p>Website: <a href="https://link.segmentfault.com/?enc=yx2GDW9Z6ZqHo9POwfnvDw%3D%3D.cCQ9wK9ULpGjNHveXMMAsUJcUjrARS76N7YhOZIEjKY%3D" rel="nofollow" target="_blank">https://exvul.com/</a> </p><p>X: @exvulsec</p>]]></description></item><item>    <title><![CDATA[AI × Crypto 的布宜诺斯艾利斯]]></title>    <link>https://segmentfault.com/a/1190000047403321</link>    <guid>https://segmentfault.com/a/1190000047403321</guid>    <pubDate>2025-11-16 20:02:19</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img width="723" height="732" referrerpolicy="no-referrer" src="/img/bVdm3VP" alt="image.png" title="image.png"/></p><p>当探戈舞曲在布宜诺斯艾利斯的街头奏响，Devconnect 的热浪裹挟着代码与创想席卷全城。</p><p>11月20日，ChainOpera 携手 OpenBuild 打造的「AI Agent x Crypto Afternoon」即将登陆阿根廷，这将是一场围绕去中心化 AI 网络、AI Agent 开发及数字孪生应用的深度思维碰撞。</p><p>欢迎所有对 AI Agent × Crypto** 充满热情的朋友加入，共启这场跨界创新之旅！</p><h3><strong>活动亮点</strong></h3><p><strong>🔥 前沿趋势：</strong> 直击 ChainOpera 去中心化 AI 网络核心，探索 agents、模型、算力如何实现社区驱动的协同联动。</p><p><strong>🎯 实操干货：</strong> 聚焦 AI Agent、数字孪生在搜索、交易、内容创作、自动化场景的落地应用，获取可落地的开发思路。</p><p><strong>🥂 精准社交：</strong> 汇聚 Web3** 与 AI 领域的核心 builder，咖啡相伴，轻松拓展行业优质资源，找到志同道合的合作伙伴。</p><p><strong>🆙 沉浸体验：</strong>  keynote + 圆桌论坛 + 自由交流，拒绝单向输出，充分激发思想碰撞，解决实际开发 / 创业困惑。</p><p><strong>立即报名</strong></p><p>📅 活动时间：11月20日</p><p>📍 活动地点：Buenos Aires, Argentina</p><p>🎫 报名链接：<a href="https://link.segmentfault.com/?enc=UbJpxt4CwnxWytDS3pLGlg%3D%3D.SMYG8L6rU%2Bl13VNBXhkNipJBx2TVjkA4vReRIZTLAXA%3D" rel="nofollow" target="_blank">https://luma.com/iin2m6t6</a></p><h3><strong>活动议程</strong></h3><p>▷ 14:00-14:30  签到入场</p><p>▷ 14:30-14:40  开幕致辞</p><p>▷ 14:40-15:00  主题演讲</p><p>▷ 15:00-15:30  圆桌论坛</p><p>▷ 15:30-17:00  茶歇 &amp; 自由交流</p><h3><strong>适合人群</strong></h3><p>✅ Web3 开发者、AI 工程师、产品经理</p><p>✅ 关注 AI Agent、数字孪生技术的创业者</p><p>✅ 对去中心化 AI 网络感兴趣的投资者</p><p>✅ 想探索 Web3+AI 跨界应用的行业研究者</p><p>✅ 渴望拓展国际行业资源的 Builder</p><h3><strong>专属礼品</strong></h3><p>每位参与者均有机会获得 ChainOpera 和 OpenBuild 定制周边（T 恤、挂绳、棒球帽），还有超多周边好礼等你来拿！</p><p><img width="723" height="410" referrerpolicy="no-referrer" src="/img/bVdm3VQ" alt="image.png" title="image.png" loading="lazy"/></p><p>一场 AI 与 Crypto 的跨界盛宴，一次 Builder 们的灵感碰撞，11 月阿根廷，ChainOpera 与 OpenBuild 等你来共创未来！</p><p>欢迎加入，我们线下见！</p><h3><strong>关于主办方</strong></h3><p><strong>🔍 ChainOpera</strong></p><p>ChainOpera 专注构建「协同智能」去中心化 AI 网络，通过社区治理模式连接 agents、模型与算力。用户可轻松创建 AI Agent 或 “数字孪生”，应用于搜索、交易、内容创作等多元场景，所有交互全程上链，实现透明可验证，让 AI 成为每个人的虚拟伙伴与协作战友。</p><p>👉 Twitter：<a href="https://link.segmentfault.com/?enc=qATx4s4sYLwfKSezo3W1FQ%3D%3D.LngwjslamkmMjMg5NSRYE7TWYqGer1Vc0FRfRVmHOUY%3D" rel="nofollow" target="_blank">https://x.com/ChainOpera_AI</a></p><p><strong>🔍 OpenBuild</strong></p><p>OpenBuild 是一个面向 Web3 开发者的开源社区。</p><p>我们致力于为开发者提供高质量的系统性内容和活动，同时连接 Web2和 Web3，帮助开发者过渡到去中心化的网络，并通过提供必要的工具和资源，帮助开发者建立声誉体系，构建信任,创造商业机会。</p><p>👉 Twitter：<a href="https://link.segmentfault.com/?enc=xtSPlRPLcFwy4LLPsDp0sw%3D%3D.oWAO2WQHzkwu2jOgryqzVC5ywRCgvZkzfqZf2O3Xm0E%3D" rel="nofollow" target="_blank">https://x.com/OpenBuildxyz</a></p>]]></description></item><item>    <title><![CDATA[2025 Virtuals Hackat]]></title>    <link>https://segmentfault.com/a/1190000047403334</link>    <guid>https://segmentfault.com/a/1190000047403334</guid>    <pubDate>2025-11-16 20:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>由 Virtuals 及 OpenBuild 联合主办的 Virtuals Hackathon 圆满落幕，本次 Hackathon 专注于 AI Agents 协作协议这一前沿领域，旨在鼓励开发者探索和构建能够高效协同工作的智能体应用。</p><p><img width="723" height="342" referrerpolicy="no-referrer" src="/img/bVdm3V3" alt="image.png" title="image.png"/></p><p>AI 代理正逐渐进化为专业工具，在以太坊等区块链网络上驱动经济价值与创新。</p><p>但其真正潜力在于协作：专业代理必须联合起来弥补短板，超越僵化的基于规则的体系。通过利用以太坊安全、可扩展的基础设施，独立代理可以整合独特模型、数据集和行动，形成动态集群，从而释放前所未有的效率与盈利能力。</p><p>Virtuals 协议最初构建于以太坊二层网络 Base，现已将其功能扩展至以太坊一层网络，实现了 AI 代理在链上的无缝部署。这一举措获得了以太坊基金会的支持，使 Virtuals 成为将人工智能引入以太坊领域的关键力量，支持链上商业、决策制定以及多代理协调等功能。</p><p>本次黑客马拉松旨在通过激励创新，将概念转化为可部署、能创造价值的 AI 业务，进一步推动这一进程。</p><p>本届 Virtuals 黑客松盛况空前，在为期数日的活动中，我们精心组织了 <strong>4 场干货满满的 Workshop</strong>，助力开发者们提升技能，拓展思路。<strong>正式注册项目也超 100 个</strong>，充分展现了开发者们高涨的参与热情和卓越的创新能力。</p><p><img width="723" height="485" referrerpolicy="no-referrer" src="/img/bVdm3V2" alt="image.png" title="image.png" loading="lazy"/></p><p>最终， <strong>16 个优秀项目</strong>脱颖而出，登上 Demo Day<strong> 的舞台，向 </strong>7 位专业评委<strong>展示他们的创新成果。经过激烈的角逐，</strong>10 个极具潜力的项目**最终摘得桂冠，为本次黑客松画上了圆满的句点。</p><h3><strong>🏆 获奖名单</strong></h3><p>以下团队及其项目在本次 Hackathon** 中展现了出色的技术能力、创新性和完成度，从众多项目中脱颖而出：</p><p><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdm3V1" alt="image.png" title="image.png" loading="lazy"/></p><p>👏🎉 祝贺以上获奖团队！</p><h3><strong>✅ 超越奖金</strong></h3><p>Virtuals Hackathon 的成功举办，也离不开各位评委的专业投入和宝贵时间。我们衷心感谢评委团成员（排名不分先后）：</p><p><strong>✦ ethermage</strong> @Virtuals Protocol</p><p><strong>✦ Stefano Bury</strong> @Virtuals Protocol</p><p><strong>✦ Davide Crapis</strong> @Ethereum Foundation</p><p><strong>✦ Bruno Skvorc</strong> @Polygon</p><p><strong>✦ nader dabit</strong> @Eigen Labs</p><p><strong>✦ Hari</strong> @Cantina</p><p><strong>✦ p0pular</strong> @Cantina</p><p><img width="723" height="496" referrerpolicy="no-referrer" src="/img/bVdm3V0" alt="image.png" title="image.png" loading="lazy"/></p><p>各位评委凭借其深厚的行业背景和专业洞察力，为本次 Hackathon 的项目评估提供了关键支持，确保了评选的公正性和专业性。</p><h3><strong>展望未来：AI 智能体协作的新起点</strong></h3><p>本次活动的圆满举办，离不开所有参与本次 Hackathon 的开发者和团队，你们的热情、创造力和技术实力是本次活动精彩纷呈的基础，每一个提交的项目都代表了对 AI 智能体协作未来的探索和思考。</p><p>最后，感谢联合主办方以及所有合作伙伴对本次活动的大力支持，同时也再次感谢各位开发者伙伴们的参与。</p><p>Virtuals Hackathon 不仅仅是一场竞赛，更是对 AI 智能体协作技术潜力的一次集中展示和实践。我们看到了开发者们如何利用 Virtuals Protocol 等工具，应对挑战，构建创新的 Agentic 解决方案，我们期待这些项目能够继续发展，并在未来产生实际影响。</p>]]></description></item><item>    <title><![CDATA[《 Unity开发秘籍：6个决定游戏成败]]></title>    <link>https://segmentfault.com/a/1190000047403206</link>    <guid>https://segmentfault.com/a/1190000047403206</guid>    <pubDate>2025-11-16 19:02:01</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>多数Unity开发者在项目推进中，往往聚焦于功能实现与玩法落地，却容易忽略那些藏在引擎底层的隐性技术细节，表面无法直观感知，却直接决定了游戏的运行效率、体验质感与迭代空间，更是区分普通开发者与资深从业者的核心标志。很多项目在测试阶段看似流畅，上线后却频繁出现帧率波动、兼容性故障、续航消耗过快等问题，甚至部分项目因底层细节缺失，后期需要投入数倍于开发的时间重构，得不偿失。更关键的是，不同平台的隐性差异往往藏在这些细节里，比如移动端的显存带宽限制、主机端的多线程调度特性、PC端的显卡驱动兼容性，稍有疏忽就会导致项目在特定平台崩盘。真正的技术高手，从来不是盲目堆砌功能，而是能深入理解引擎的运行机制，在开发全流程中精准把控每一个关键细节，通过对底层逻辑的优化，让游戏在性能、稳定性与体验感上形成质的飞跃，这些不为人知的技术细节，正是拉开项目差距、避免后期返工的核心所在。</p><p>Shader变体的精细化管理，是很多开发者容易踩坑的隐性难点，其优化深度直接影响游戏的加载速度与内存占用，更决定了跨平台兼容性的上限。Shader变体的产生源于关键字组合、多Pass设计、材质属性差异等多个维度，多数项目在开发过程中，随着功能迭代，Shader变体数量会不知不觉累积到数千甚至上万—比如一款3D动作游戏，仅角色材质就可能因光照模式、特效开关、皮肤质感等关键字组合出数百个变体，而每一个变体都需要占用显存与加载时间，移动端设备上极易出现首次加载黑屏、场景切换卡顿，甚至因显存溢出导致闪退。优化的核心在于建立变体生命周期管理机制，首先需要通过引擎自带的变体收集工具，结合真机测试筛选出真正被使用的变体，剥离冗余的关键字组合与无效Pass，比如将仅在编辑器中使用的调试关键字、未启用的特效开关关键字彻底剔除。对于不同平台，需制定差异化的变体集合：移动端仅保留核心变体，关闭抗锯齿、高级光影等非必要关键字；主机端与PC端则可根据硬件等级，动态加载高质量效果变体。同时，利用预编译技术将常用变体提前编译为字节码，避免运行时实时编译导致的卡顿，具体可采用分阶段预编译策略—启动时预编译全局核心变体，加载场景时异步预编译场景专属变体，减少启动等待时间。对于多角色、多场景共用的Shader，采用关键字分组策略，将低频使用的功能（如角色受伤发光、环境反射）作为可选关键字，仅在需要时启用，减少基础变体数量。此外，还要注意Shader变体与批处理的兼容性，避免因变体差异导致批处理失败，通过合理的Shader结构设计，让相似材质能够共享变体，在保证画质的同时最大化提升渲染效率，曾有一款开放世界游戏因忽视变体管理，上线后移动端加载黑屏率达15%，后期通过重构Shader变体体系，将变体数量缩减70%，黑屏问题彻底解决。</p><p>动画系统的底层优化，远不止于骨骼数量与蒙皮计算的精简，更在于对动画数据流转、状态机逻辑与物理系统协同的深度把控，很多开发者在设计动画系统时，过度追求动画效果的丰富性，却忽视了动画片段的内存复用与状态切换的性能损耗，导致复杂场景下CPU占用率居高不下。动画片段的优化核心在于数据压缩与复用，针对不同类型动画需采取差异化策略：循环动画（如行走、跑步）可采用关键帧压缩算法，剔除冗余关键帧，仅保留关键姿态数据，同时通过曲线插值还原流畅效果，压缩率可达50%以上；非循环动画（如攻击、跳跃）则重点优化曲线精度，避免过度压缩导致动作变形；表情动画因关键帧密集，可采用骨骼分组压缩，仅保留面部核心骨骼的动画数据。将相似动画片段合并为动画树，通过参数驱动实现效果变体，是减少资源冗余的关键，比如将不同速度的行走动画、不同角度的攻击动画整合进同一动画树，通过移动速度、攻击方向等参数动态切换，避免创建大量重复动画资源。状态机的优化则需要规避过度复杂的状态分支，采用分层状态机架构，将全局状态（如移动、静止）与局部状态（如攻击、交互、受伤）分离，减少状态切换时的逻辑判断开销，同时通过状态过渡的优先级设置，避免出现状态冲突导致的动画卡顿。根运动的合理运用也至关重要，不当的根运动设置会导致物理碰撞与动画播放不同步，甚至增加CPU计算负担，正确的做法是根据角色移动速度动态调整根运动的更新频率—高速移动时提高频率保证精度，低速状态下降低频率节省资源，同时将根运动的位移与碰撞体的位置同步锁定，避免角色穿模或悬空。动画事件的触发机制也需要优化，避免在每帧都执行复杂逻辑，将高频事件（如脚步声播放）改为定时触发，间隔帧数根据动画节奏调整，攻击动画的伤害判定事件则可设置在动画关键帧后延迟一帧执行，既保证判定准确性，又减少帧内计算压力。此外，动画调试过程中，可通过输出状态切换耗时、蒙皮计算帧率等日志，定位性能瓶颈，曾有一款动作游戏因动画状态机分支过多，角色同时触发多个状态时CPU占用率骤升30%，通过分层重构与事件优化后，性能显著提升。</p><p>输入延迟的精准控制，是影响游戏操作手感的核心技术细节，其优化需要贯穿输入采集、事件分发、渲染呈现的全流程，多数开发者对输入延迟的认知仅停留在表面，认为只是硬件响应问题，实则Unity引擎的输入处理机制、渲染管线同步方式，甚至系统层面的资源调度，都会对延迟产生显著影响。不同平台的输入特性存在本质差异，需要针对性优化：移动端的触控输入受系统触控采样率、触控防抖机制影响较大，部分安卓设备默认的触控防抖会增加50-100毫秒延迟，开发中需通过代码禁用不必要的防抖功能，同时适配不同设备的触控采样率（常见60Hz、120Hz、240Hz），确保输入信号采集与引擎更新频率同步；主机端的手柄输入需关注 polling rate（回报率），与引擎的 FixedUpdate 频率匹配，避免因回报率过高导致输入数据堆积，或过低导致响应不及时；PC端的鼠标输入则需协调鼠标的硬件回报率与引擎的输入采样频率，同时关闭系统层面的鼠标加速，减少输入偏移。输入采集阶段，根据游戏类型调整采样策略—射击、格斗等对操作响应要求极高的游戏，应将输入采样频率提升至与屏幕刷新率一致（如120Hz），确保每一次细微操作都能被精准捕获，同时关闭引擎默认的输入过滤功能，减少信号传输中的延迟；对于休闲类游戏，则可适当降低采样频率，平衡性能与体验。事件分发阶段，要优化输入事件的处理顺序，将核心操作逻辑（如攻击、跳跃、移动）优先执行，避免被UI交互、日志输出等非关键逻辑阻塞，可通过建立输入事件优先级队列，确保核心操作第一时间响应。渲染管线层面，输入信号的采集时机与渲染帧的同步至关重要，多数情况下，输入采集在渲染帧开始前执行，但若存在帧缓冲延迟，会导致操作与画面呈现存在时间差，此时可启用引擎的“输入预测”功能，根据前几帧的输入状态预判玩家后续操作，提前执行相关逻辑，缩小延迟。实际开发中，可通过高速相机拍摄操作与画面反馈的时间差，或使用引擎自带的输入延迟检测工具，精准测量延迟数值，针对性优化，曾有一款射击游戏因输入延迟过高导致玩家反馈“手感发飘”，通过同步输入采样与渲染频率、启用预测性输入，将延迟从120毫秒降至40毫秒，玩家体验显著提升。</p><p>场景流式加载的深层优化，核心在于平衡加载效率、内存占用与帧率稳定性，而非简单的异步加载与卸载，很多开放世界或大型场景项目，因流式加载策略不当，出现加载卡顿、资源加载不及时、内存溢出、场景穿模等问题，根源在于对加载优先级、资源依赖、线程调度与容错机制的把控不足。加载优先级的动态调整是关键，需要建立基于玩家行为的预测模型，综合考虑玩家的移动速度、视野范围、行进方向、交互意图等因素，提前计算即将需要的资源—比如玩家骑马高速移动时，将加载距离扩大至正常范围的1.5倍，优先级向地形、碰撞体、关键交互对象倾斜；玩家潜行或静止时，缩小加载距离，优先加载细节资源与音效。资源依赖的预加载策略同样重要，避免因加载某个核心资源时，才发现其依赖的纹理、材质、动画尚未加载，导致画面撕裂或卡顿，正确的做法是在项目初期梳理资源依赖关系，通过引擎的资源依赖分析工具生成依赖图谱，避免循环依赖，将关联资源（如角色模型与其材质、动画）打包为资源包，加载核心资源时自动预加载依赖资源，同时设置依赖加载超时机制—核心资源超时后重试两次，仍失败则启用降级资源（如低精度模型、纯色材质），非核心资源超时则直接放弃加载，确保游戏正常运行。线程调度方面，要合理分配主线程与后台线程的工作，将资源解压、数据解析、地形烘焙等耗时操作放在后台线程执行，避免阻塞主线程的游戏逻辑与渲染更新，同时控制后台线程的CPU占用率，通过设置线程优先级与时间片分配，确保后台线程不会与主线程争夺资源导致整体帧率下降。对于开放世界游戏的地形加载，可采用分块加载与LOD（细节层次）结合的策略，玩家当前所在区块使用高精度地形，远处区块使用低精度地形，随着玩家移动动态更新精度，减少显存占用。加载过程中的用户体验优化也不可忽视，避免因加载卡顿导致玩家流失，可通过动态进度条、加载动画、场景过渡效果掩盖加载过程，同时在加载间隙插入简短的剧情文本或操作提示，分散玩家注意力。曾有一款开放世界游戏因未考虑玩家快速转向导致的资源加载不及时，出现“远景空白”问题，后期通过优化预测模型，根据玩家视角变化调整加载优先级，彻底解决了这一故障。</p><p>UI渲染优化的核心，在于减少Draw Call数量与布局计算开销，很多游戏的UI卡顿问题，都源于对UI渲染底层逻辑的认知不足，尤其是在UI元素密集、动态更新频繁的场景（如排行榜、聊天窗口、战斗HUD），性能损耗会被无限放大。UI的Draw Call合并是优化的关键，多数开发者仅知道将UI纹理打包为Atlas，却忽视了Atlas的合理规划与UI层级、渲染顺序的影响。Atlas打包时，应根据UI元素的使用频率、生命周期与场景分布进行分组—将常驻UI（如状态栏、导航按钮）打包在全局Atlas中，场景专属UI（如任务面板、场景提示）打包在对应场景Atlas中，临时UI（如弹窗、加载提示）打包在独立Atlas中，避免因临时UI加载卸载导致全局Atlas频繁重建。同时控制Atlas的尺寸，移动端建议将Atlas尺寸控制在2048x2048或4096x4096，避免因Atlas过大导致显存浪费，对于透明通道占比高的UI元素（如图标、文字背景），可采用RGBA4444格式压缩，平衡画质与性能。UI层级管理同样重要，将静态UI与动态UI分层，静态UI（如背景、标题）合并为一个Draw Call，动态UI（如列表、按钮）单独分层，避免因动态UI的频繁更新导致静态UI重新绘制，同时合理设置UI的渲染顺序，减少渲染状态切换。布局计算开销的优化容易被忽视，过度复杂的锚点设置、嵌套层级过深的UI结构，会导致每帧都需要进行大量的布局计算，尤其是在UI元素频繁刷新时，这种开销会急剧增加。正确的做法是简化UI嵌套结构，嵌套层级控制在4层以内，对于固定尺寸的UI元素，使用绝对布局替代相对布局，减少布局计算量；对于动态列表（如好友列表、背包），采用滚动复用机制，仅创建当前视野内的UI元素，滚动时复用已创建的元素，避免一次性创建大量UI导致内存占用过高与布局计算卡顿。文字渲染的优化也不容忽视，动态字体的实时生成会占用大量CPU资源，应提前将常用文字（如数字、常用汉字、按钮文本）生成字体图集，对于需要显示大量文字的场景（如剧情文本、聊天窗口），采用分批渲染策略，每帧渲染固定数量的文字，避免一次性渲染过多文字导致卡顿；同时控制文字的阴影、描边等效果数量，优先使用Shader实现文字效果，替代多Pass渲染，减少Draw Call。此外，UI与渲染管线的协同优化也很关键，将UI渲染设置在渲染队列的合适位置，避免与3D场景渲染冲突，同时关闭不必要的UI抗锯齿功能，在保证视觉效果的前提下降低渲染开销，曾有一款手游因战斗HUD嵌套层级过深（达8层），导致战斗时UI渲染占用CPU 20%，通过简化层级与复用机制优化后，开销降至5%以内。</p><p>脚本执行顺序与线程调度的精细化管控，是保证游戏逻辑稳定与性能高效的底层基础，很多开发者忽视这一细节，导致逻辑冲突、线程安全问题与性能浪费，尤其在多人协作开发的大型项目中，脚本执行顺序混乱引发的BUG往往难以排查，后期修复成本极高。脚本执行顺序的混乱，容易引发逻辑依赖错误—比如资源管理脚本尚未初始化完成，游戏逻辑脚本就已开始请求资源，导致空引用错误；或者输入处理脚本执行在物理更新之后，导致操作响应延迟。解决这一问题的核心，在于建立清晰的脚本执行顺序规则，根据功能模块划分执行优先级：核心系统脚本（如资源管理、输入处理、内存监控）设置为最高优先级，确保最先执行；基础功能脚本（如角色控制、UI管理、音效播放）设置为中优先级；业务逻辑脚本（如任务系统、战斗规则、NPC行为）根据依赖关系排序，依赖其他脚本的业务脚本优先级低于被依赖脚本。同时利用Unity的脚本执行顺序设置功能，明确指定关键脚本的执行顺序，避免依赖冲突，多人协作时可制定脚本命名规范与优先级对照表，确保所有开发者遵循统一标准。线程调度的优化则需要平衡多线程的并行优势与线程安全风险，很多开发者盲目使用多线程处理耗时操作，却忽视了线程间的资源竞争问题，导致数据错乱或崩溃。正确的做法是明确主线程与后台线程的职责划分：主线程负责游戏逻辑、渲染更新、用户交互等实时性要求高的操作；后台线程负责资源加载、数据计算（如AI路径规划、排行榜排序）、网络通信、日志上传等耗时操作。</p>]]></description></item><item>    <title><![CDATA[《Unity优化指南：直击引擎本质的非典]]></title>    <link>https://segmentfault.com/a/1190000047403212</link>    <guid>https://segmentfault.com/a/1190000047403212</guid>    <pubDate>2025-11-16 19:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>Unity开发的核心进阶，不在于掌握多少表层API，而在于能否穿透引擎封装的表象，触及资源流转、渲染协同、内存调度的底层本质。多数开发者在面对性能瓶颈、兼容性故障时，习惯沿用常规优化手段，却陷入“优化效果有限”“问题反复出现”的困境，根源在于未能理解引擎各模块的隐性关联与运行规律。真正的高效开发，需要跳出“单点优化”的思维定式，从资源导入到逻辑架构，从平台适配到监控调试，建立一套贴合引擎本质的系统性技术认知。这种认知不仅能解决当下项目的核心痛点，更能让开发者在复杂场景中灵活应对各种问题，实现性能与体验的双重突破，真正拉开与普通开发者的技术差距。</p><p>资源导入管线的底层优化，是决定项目基础性能的核心环节，其影响贯穿开发全流程与最终运行效果，却常被简化为“压缩格式选择”的表层操作，多数项目因导入阶段的粗放处理，为后续性能问题埋下隐患。不同类型资源的导入规则，直接关联着加载效率、内存占用与渲染开销，需要根据资源特性与引擎解析机制精准适配。对于纹理资源，除了常规的ETC2、ASTC等格式压缩，更需关注纹理维度与GPU缓存的匹配度—非2的幂次纹理会破坏GPU的纹理缓存机制，增加采样计算量，而超过GPU显存页大小的纹理，会导致缓存命中率大幅下降，进而引发渲染帧率波动，实际开发中应尽量将纹理尺寸控制在2048x2048或4096x4096以内，同时根据纹理用途选择合适的Mipmap层级，UI纹理可适当减少Mipmap数量以节省显存。模型资源的导入优化，核心在于网格数据的预处理：合理拆分模型组件，避免单个网格包含过多子对象，否则会增加引擎实例化与渲染调用的开销；优化顶点数据布局，将位置、法线、UV等数据按GPU读取顺序排列，减少数据传输时的格式转换耗时，对于动画角色模型，还需剔除未参与动画的冗余骨骼，降低蒙皮计算压力。音频资源的导入则需平衡音质与性能，不同平台的音频解码效率差异显著，移动端应优先选择MP3、AAC等硬件支持的解码格式，避免使用WAV等未压缩格式导致的内存占用过高，同时控制音频文件的位率与采样率，高频播放的短音频（如音效）可适当降低采样率，减少CPU的解码开销。更关键的是建立资源导入的标准化流程，通过编写Editor脚本自动化配置导入参数，比如根据纹理命名规则自动分配压缩格式与Mipmap设置，根据模型用途自动设置网格压缩等级，避免因人工操作差异导致的资源冗余，从源头减少后续优化的复杂度，曾有一款3D手游因未优化模型顶点布局，导致角色加载耗时比同类项目高30%，后期通过调整顶点数据顺序与网格拆分，加载效率显著提升。</p><p>渲染管线的深层协同，是突破画面表现力与性能平衡的关键，其核心在于让顶点处理、光栅化、像素着色等各阶段形成高效联动，而非孤立优化单个环节，很多项目因各阶段性能失衡，导致整体帧率难以提升。很多开发者在优化渲染性能时，仅聚焦于减少Draw Call或降低像素着色复杂度，却忽视了各阶段的性能损耗叠加效应—比如顶点数量过多会增加CPU的批处理压力，导致CPU成为性能瓶颈，而此时单纯优化像素着色器毫无意义；反之，若像素着色器过于复杂，即使CPU批处理效率再高，GPU也会因不堪重负导致帧率下降。顶点处理阶段的优化，需结合模型的LOD策略与GPU的顶点缓存特性，合理控制各层级LOD的顶点数量，避免相邻LOD切换时的视觉跳变，同时通过顶点数据压缩（如将法线数据从32位浮点压缩为16位）减少内存带宽占用，对于大面积重复的场景元素（如树木、草丛），可采用GPU实例化技术，通过一次绘制调用批量渲染多个对象，降低CPU的批处理压力。光栅化阶段的关键在于减少过度绘制，通过合理的渲染排序（透明对象按距离排序，不透明对象按材质排序）、遮挡剔除与模板测试，避免不可见像素的无效计算，对于复杂场景，可采用预计算可见性集合（PVS），提前标记不同视角下的可见对象，减少实时遮挡剔除的开销，同时利用深度测试尽早丢弃被遮挡的像素，降低后续像素着色的压力。像素着色阶段的优化，不能单纯追求算法简化，而应利用GPU的并行计算特性，通过纹理压缩、采样优化（如使用点过滤替代线性过滤）、数学运算简化（如用乘法替代除法、用查表法替代复杂函数）等方式，提升着色器的执行效率，同时避免在像素着色器中使用分支判断与循环，减少GPU线程 divergence（分歧）导致的性能损耗。更重要的是让渲染管线与资源特性深度匹配，比如根据纹理的使用场景选择合适的过滤模式，UI纹理使用点过滤保证清晰度，场景纹理使用线性过滤提升视觉效果；根据光照复杂度调整着色器的计算精度，静态场景采用低精度光照计算，动态角色采用高精度光照，让每一处渲染配置都能发挥硬件的最大潜力。</p><p>内存与缓存的联动优化，是解决运行时帧率波动与内存溢出的核心，其本质在于理解CPU、GPU缓存机制与内存分配逻辑，通过合理的资源调度提升数据访问效率，很多项目的内存问题并非源于资源总量过大，而是数据布局不合理导致的缓存命中率低下。CPU缓存的空间局部性与时间局部性原理，决定了连续存储的数据能大幅提升读取速度，而零散分布的小资源会增加缓存缺失率，导致CPU频繁访问主存—主存的访问速度比CPU缓存慢数百倍，这种频繁切换会产生巨大的性能损耗。优化的核心在于资源数据的结构化布局：将高频访问的资源数据（如角色动画的骨骼数据、UI的布局信息、AI的路径规划数据）按连续地址存储，避免碎片化分布，可通过自定义数据结构替代Unity默认的数据存储方式，确保数据的连续性；对于批量处理的资源（如粒子系统的位置、速度参数），采用数组而非链表存储，利用CPU的SIMD（单指令多数据）指令集提升并行处理效率，大幅减少循环执行时间。GPU缓存的优化同样关键，纹理的格式选择、Mipmap设置直接影响GPU的采样效率，合理的Mipmap链能让远处纹理使用低分辨率版本，既减少显存占用，又提升缓存命中率，同时避免使用过大的纹理图集，防止缓存冲突导致的采样延迟；对于顶点缓存，通过优化顶点数据的顺序，让相邻顶点在内存中连续存储，提升GPU读取顶点数据的效率。内存分配策略的优化需规避频繁的小对象创建与销毁，这类操作会导致内存碎片累积，即使总体内存占用不高，也可能因无法分配连续内存而触发崩溃，解决方案是通过内存池技术对高频复用的对象（如网络数据包、临时计算数据、UI弹窗）进行集中管理，提前创建一定数量的对象池，使用时从池中获取，销毁时归还池中，避免频繁分配回收内存。此外，建立内存监控与预警机制，实时跟踪缓存命中率、内存碎片率、资源加载卸载频率等关键指标，能及时发现并解决隐性的内存问题，比如通过Unity的Profiler工具监控CPU缓存缺失率，若某段代码的缺失率过高，可通过调整数据布局优化；定期分析内存快照，定位未被回收的资源，排查内存泄漏源头，让内存与缓存形成高效联动，确保游戏运行过程中内存占用稳定，帧率平滑无波动。</p><p>多平台适配的底层逻辑重构，需要跳出“表面参数调整”的误区，深入不同平台的硬件特性与系统机制，建立从底层到上层的全链路适配思维，而非简单的功能删减或参数降级。不同平台的硬件架构差异巨大，CPU的核心数、GPU的渲染特性、内存带宽的限制，直接决定了游戏的运行上限，适配的核心并非“削足适履”，而是“量体裁衣”式的底层优化。移动端的适配重点在于平衡性能与功耗，需针对ARM架构的CPU优化指令执行效率，避免使用复杂的分支判断与深层循环嵌套—ARM架构对分支预测的支持较弱，过多分支会导致指令流水线中断，同时利用NEON指令集加速批量数据处理，提升计算效率；GPU方面，需根据型号差异调整渲染管线配置，低端GPU（如Adreno 500系列）需关闭复杂的后期处理（如 bloom、景深）与实时光照，优先保证帧率稳定，高端GPU（如Adreno 700系列）则可启用高级渲染特性（如光线追踪、HDR），提升画面表现力；系统层面，需适配不同安卓版本的权限管理规则，避免因权限申请不当导致应用闪退，同时优化后台运行机制，减少后台驻留时的功耗消耗。主机端的适配需充分利用多核心CPU与高性能GPU的优势，通过多线程并行处理提升逻辑执行效率，比如将AI计算、物理模拟、资源加载等耗时操作分配到不同线程，避免主线程阻塞；GPU方面，优化渲染管线以支持4K、60帧的高规格输出，关注主机平台的特有API（如PS5的DirectGPU Access）与硬件加速功能，最大化发挥硬件潜力；操作适配方面，深度优化手柄的振动反馈与按键映射，贴合主机玩家的操作习惯。PC端的适配则需应对硬件配置的多样性，建立动态画质调节系统，通过检测显卡型号、内存大小、CPU性能等参数，自动匹配最优的渲染配置，同时兼容不同版本的显卡驱动，避免因驱动差异导致的画面撕裂或闪退；窗口模式与全屏模式的切换逻辑需优化，确保切换过程中不出现卡顿或黑屏，支持多显示器适配与高刷新率（如144Hz）输出，满足PC玩家的个性化需求。通过底层逻辑的重构，让游戏在不同平台上都能发挥硬件优势，实现流畅稳定的运行体验。</p><p>逻辑架构的解耦与扩展性设计，决定了项目的长期迭代效率与维护成本，其核心在于建立一套灵活的底层框架，让各模块既能独立运行，又能高效协同，很多大型项目在后期迭代中陷入困境，根源在于初期架构设计的耦合度过高。模块间直接依赖、数据共享混乱、功能扩展需修改核心代码，这些问题会导致新增功能或修复BUG时牵一发而动全身，不仅迭代效率低下，还容易引入新的BUG。突破这一困境的关键在于采用数据驱动的架构设计，将核心逻辑与数据分离，通过配置文件（如JSON、Excel）而非硬编码定义游戏规则—比如角色的属性、技能效果、任务流程等都存储在配置文件中，功能调整无需修改代码，仅需更新配置，既提升迭代效率，又降低出错概率。事件总线与观察者模式的深度运用，能有效降低模块间的直接依赖，各模块通过事件发布与订阅实现通信，比如玩家升级时发布“等级提升”事件，UI模块、成就模块、奖励模块订阅该事件并各自处理相关逻辑，避免出现“模块A直接调用模块B方法”的强依赖关系，同时提升代码的可测试性与可维护性。插件化与模块化设计则为扩展功能提供了灵活路径，将非核心功能（如社交系统、付费系统、统计分析系统）封装为独立插件，通过接口与核心框架对接，按需加载与卸载，既减少初始安装包大小，又便于后期更新迭代，比如某项目将广告系统封装为插件，不同渠道可选择加载不同的广告插件，无需修改核心代码。架构的扩展性还需考虑热更新的底层支持，通过合理的代码分区与资源管理，将核心逻辑与可更新内容分离，核心逻辑编译为原生代码保证性能，可更新内容（如活动玩法、剧情文本）通过Lua等脚本语言实现，确保热更新过程的稳定性与兼容性。此外，建立统一的代码规范与接口设计标准，比如命名规范、注释要求、接口返回格式等，能让不同开发者的代码风格保持一致，降低协作成本，同时为架构的长期演进预留空间，比如设计接口时遵循“开闭原则”，新增功能无需修改原有接口，仅需扩展实现类，让项目在持续迭代中始终保持清晰的逻辑结构。</p><p>调试与性能监控的进阶实践，是发现并解决隐性问题的关键，其价值不仅在于定位已出现的BUG，更在于预判潜在的性能风险，实现“防患于未然”的主动优化，常规的调试手段往往难以应对复杂场景下的性能瓶颈与偶发BUG。利用Unity的Profiler工具进行深度分析，不仅能查看帧率、内存、CPU等基础指标，更能深入各模块的执行耗时，比如定位到某个脚本的Update函数执行过长、某个资源加载导致的卡顿、某个着色器的像素计算耗时过高，通过帧剖析功能还原每帧的执行流程，精准定位性能瓶颈的具体位置。自定义日志与监控系统的搭建，能弥补引擎工具的局限性，通过在核心逻辑节点（如资源加载完成、战斗开始与结束、网络请求发送与接收）插入关键日志，记录数据流转、状态变化、资源加载耗时等信息，在测试阶段可通过日志快速复现偶发BUG，上线后通过后台监控系统收集日志数据，分析用户设备上的崩溃原因与性能问题。性能监控的进阶之处在于建立自定义指标体系，除了引擎自带的指标，还需根据项目特性设计关键指标，比如开放世界游戏的场景加载成功率、动作游戏的输入响应延迟、手游的电池消耗速度等，通过实时监控这些指标，设置预警阈值，当指标超过阈值时及时触发告警，让开发者第一时间介入处理。</p>]]></description></item><item>    <title><![CDATA[外贸Invoice是什么？作用一次看懂 ]]></title>    <link>https://segmentfault.com/a/1190000047402958</link>    <guid>https://segmentfault.com/a/1190000047402958</guid>    <pubDate>2025-11-16 18:02:10</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>外贸Invoice并非增值税发票，它是卖方向买方发出的“付款通知书”，更是海关清关与买方付款的核心依据。一张小小的Invoice若出现信息错漏，就可能导致货物滞港、税款争议甚至收汇失败。本文将拆解外贸Invoice的真实含义、常见痛点，并演示如何用Zoho Books在3分钟内生成符合国际规范、支持180+币种与多语言的专业Invoice，让单据流程零失误、收款更快。<br/><img width="500" height="328" referrerpolicy="no-referrer" src="/img/bVdm3PZ" alt="" title=""/><br/>一、外贸Invoice的真实含义</p><ol><li>Invoice≠“发票”<br/>虽然中文常将Invoice直译为“发票”，但实际含义更接近商业账单或付款通知单。Invoice是卖方提供给买方的交易明细文件，列明货物/服务内容、数量、价格、付款条件等，本质是催款凭证而非付款后的收据（Receipt）。早期翻译中将Invoice与中文“发票”对应，但现代中文“发票”（如增值税发票）特指已付款的税务凭证，与Invoice的用途存在本质差异。</li><li>外贸Invoice的核心作用<br/>交易确认：作为买卖双方达成协议的书面证明。<br/>清关依据：进口国海关通过Invoice核查货物价值、征税依据。<br/>付款指令：买方根据Invoice内容完成付款流程。<br/>二、外贸Invoice管理中的常见痛点<br/>信息错漏：商品描述不清晰、金额计算错误导致清关延误。<br/>流程繁琐：多类型Invoice需手工制作，耗时且易重复。<br/>合规风险：不同国家对Invoice格式、内容要求差异大，易触犯法规。<br/>财务对账难：Invoice与物流、付款记录不同步，增加对账成本。<br/>三、如何借助Zoho Books优化外贸Invoice管理？<br/>Zoho Books作为专为外贸企业设计的订单管理工具，提供从invoice付款通知单制作到跨境收款的全流程自动化解决方案，显著降低人工错误并提升效率。</li><li>Zoho Books的核心功能<br/>智能模板库：支持180+种货币、多语言模板。<br/>实时汇率更新：动态汇率转换，避免手动计算错误。<br/>自动化催款：设置付款提醒，自动发送催款通知，加速资金回笼。<br/>全链路跟踪：实时查看发票状态（已发送、已查看、已付款），减少沟通成本。</li><li>三步生成专业Invoice<br/>创建模板：系统支持自定义企业Logo、银行账户信息，强化品牌形象。<br/>填写信息：系统可以自动关联报价单数据，一键转换为付款通知单。<br/>发送与跟踪：通过邮件或在线链接发送，并实时监控客户反馈。<br/>四、使用Zoho Books制作外贸Invoice的步骤</li><li>注册并登录Zoho Books<br/>访问Zoho Books官网，完成注册并登录账户。</li><li>创建发票模板<br/>进入【设置】-【更多设置】-【模板】，创建一个新的商业发票模板。Zoho Books提供多种预设Invoice模板，支持添加企业Logo、自定义字体颜色、银行账户信息等，确保品牌形象统一。用户还可根据客户语言偏好调整内容，例如发送英文或西班牙语版本，提升沟通效率。别忘了添加您的银行账户信息，方便收款。</li><li>填写发票信息<br/>找到【invoice】功能，依次填入必要的信息，如发票号码、日期、卖方信息、买方信息、货物信息等。确保所有信息准确无误，避免交易中的纠纷。Zoho Books支持180+种货币，系统自动更新实时汇率，避免手动计算错误。</li><li>选择发送方式<br/>直接通过电子邮件发送PDF格式Invoice，或生成在线链接供客户查看。所有发送记录自动归档至客户档案，便于后续跟进。</li></ol><p>结语<br/>别让手工Invoice拖慢出海速度。立即免费试用Zoho Books，14天全功能开放：一键把报价单转为Invoice、实时汇率自动换算、系统根据账期发催款邮件，发送记录与付款状态全程可视。用Zoho Books把外贸Invoice做成标准化、自动化、可追踪的数字化资产，让每笔国际贸易都安全、合规、高效地落袋为安。</p>]]></description></item><item>    <title><![CDATA[从需求到预算，EDM软件这么选 遭老罪的]]></title>    <link>https://segmentfault.com/a/1190000047403013</link>    <guid>https://segmentfault.com/a/1190000047403013</guid>    <pubDate>2025-11-16 18:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>邮件群发软件五花八门，选错=白烧钱。EDM干货第14期教你9步锁定真正需要的工具：先捋清客群画像，再对照功能、集成、口碑、价格4大维度过筛，最后用试用数据说话。文中示例以Zoho Campaigns演示——从模板拖拽、自动化流程到实时报表，一套系统让邮件营销“既好看又好卖”。<br/><img width="512" height="340" referrerpolicy="no-referrer" src="/img/bVdm3QS" alt="" title=""/><br/>1、了解企业自身需求<br/>首先，企业需要对自己的业务需求有一个清晰的了解。是更关注潜在客户的开发，还是更加重视现有客户的维护基础？是需要帮助销售获取高质量的潜在客户，还是需要频繁的品牌宣传？明确这些需求，将帮助企业缩小选择范围，从而提高选择效率。</p><p>2、目标市场与受众分析<br/>企业在选择EDM工具前，须明晰目标市场及受众特征。这包括年龄、性别、兴趣爱好、购买习惯等数据。比如，关注年轻时尚人群的企业，可能会需要更多创意模板和数据分析功能；而面向B2B的企业，则可能需要更加重视邮件的投递率和自动化程度。</p><p>3、内容管理方面的需求<br/>不同企业对内容管理的需求可能有天壤之别。注重品牌形象的企业可能需要先进的设计功能，确保邮件视觉与整体品牌一致；而重视性能的公司则可能更关注A/B测试功能，以便测试邮件的效果。</p><p>4、评估邮件营销软件的功能和特性<br/>当前市面上的EDM软件功能各异，但核心功能包括邮件设计、自动化、分析与报告等。企业需要从这些核心功能中评估出最符合其需求的产品。Zoho Campaigns作为一款功能全面的EDM工具，提供了以下关键特性：</p><p>邮件设计<br/>Zoho Campaigns提供了丰富的预设模板和拖放编辑功能，使用户能够轻松创建专业邮件。对于有自己设计团队的企业，Zoho Campaigns支持自定义HTML设计。此外，其响应式设计功能确保邮件在不同设备上的良好呈现，满足现代邮件设计的基本需求。</p><p>自动化功能<br/>自动化是EDM的精髓，Zoho Campaigns通过其强大的自动化功能，帮助企业显著减少重复劳作，实现精准营销。企业可以利用Zoho Campaigns设置自动化流程，如欢迎邮件序列、购物车遗弃提醒等，帮助维持与用户的长期互动关系。</p><p>分析与报告工具<br/>Zoho Campaigns提供详细的数据分析与报告功能，帮助企业评估邮件活动的效果，如开信率、点击率、取消订阅率等。其分析工具能够提供实时数据，并深入到特定用户行为，协助企业及时调整策略。</p><p>通过评估这些功能，企业可以选择最符合其需求的EDM软件，确保其营销活动的成功。</p><p>5、软件的兼容性与集成能力<br/>考虑软件与企业现有系统的集成能力也至关重要，特别是在信息化程度较高的企业中。软件的API接口支持、与CRM系统的兼容性及是否能与社会化媒体平台结合等，都可能影响最终的选择。</p><p>6、软件商的信誉与服务支持<br/>选择邮件营销软件时，企业还需关注提供商的信誉与服务支持。对于初创企业，可能会特别看重厂商的技术支持质量及响应速度。而对于较大的企业，可能会更在意软件的稳定性和提供商的持续创新能力。</p><p>7、客户口碑与成功案例<br/>研究其他企业使用同一软件的评价，尤其是成功案例能够为选择决策提供有益启示。分析这些案例可以衡量软件在类似业务环境中的实用性与有效性。</p><p>8、成本与预算<br/>最终，企业需衡量软件的成本与预算匹配。不同软件的定价模式可能差别巨大，有的按用户数量收费，有的按邮件发送数量收费。企业需要结合自身情况进行评估，确保投资回报比符合预期。</p><p>9、试用与反馈<br/>在做出最终决定之前，尽量争取试用不同软件，并通过试用阶段获取反馈，各部门的反馈有助于对软件进行更全面的评估。通过实际操作体验，不仅可以检验软件性能，还可以评估厂商的技术支持和客户服务能力。</p><p>10、结论<br/>别再盲投工具！立即免费试用Zoho Campaigns，15天解锁A/B测试、购物车遗弃自动唤醒、多语言模板等全功能；付费版按发送量计费，最低0元起，ROI看得见。把选择成本降到最低，把营销效果拉到最高，让Zoho Campaigns陪你用数据写下一封封高转化邮件。</p>]]></description></item><item>    <title><![CDATA[真正免费CRM软件推荐：Zoho CRM]]></title>    <link>https://segmentfault.com/a/1190000047402676</link>    <guid>https://segmentfault.com/a/1190000047402676</guid>    <pubDate>2025-11-16 16:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在企业的日常运营中，客户关系管理（CRM）软件扮演着至关重要的角色。然而，对于许多预算有限的企业，尤其是中小型企业来说，昂贵的CRM软件往往成为一道难以跨越的门槛。幸运的是，市场上确实存在一些真正免费的CRM软件，其中Zoho CRM凭借其出色的功能、易用性和扩展性，成为了备受推荐的选择。本文将详细介绍Zoho CRM的功能、优势以及为什么它是免费CRM软件中的佼佼者。<br/><img width="723" height="487" referrerpolicy="no-referrer" src="/img/bVdm3Lm" alt="" title=""/></p><h2>一、为什么需要CRM软件？</h2><p>在深入探讨Zoho CRM之前，我们先来了解一下企业为何需要CRM软件。CRM的核心功能在于帮助企业管理客户关系，具体体现在以下几个方面：</p><h2>1. 集中管理客户信息</h2><p>通过CRM系统，企业可以将客户的联系方式、购买记录、沟通历史等信息集中存储，避免信息分散或丢失，确保客户信息的完整性和准确性。</p><h2>2. 优化销售流程</h2><p>CRM可以帮助销售团队跟踪潜在客户的进展，识别销售机会，并制定更高效的销售策略，从而提升销售业绩。</p><h2>3. 提升客户满意度</h2><p>通过CRM，企业可以更好地了解客户需求，提供个性化的服务，从而提升客户满意度和忠诚度，促进客户复购和口碑传播。</p><h2>4. 数据驱动决策</h2><p>CRM系统通常会提供数据分析功能，帮助企业从客户数据中挖掘有价值的洞察，支持业务决策，推动企业持续发展。</p><p>然而，许多企业，尤其是中小型企业，可能因为预算有限而无法负担昂贵的CRM软件。这时，免费的CRM软件就成为了一个理想的选择。</p><h2>二、市场上的免费CRM软件概览</h2><p>目前市场上有不少免费的CRM软件，如HubSpot CRM、Zoho CRM、Bitrix24等。这些软件各有特色，但在功能全面性、易用性和扩展性方面，Zoho CRM无疑是一个非常出色的选择。</p><h2>三、免费CRM的常见问题</h2><p>在选择免费CRM软件时，企业通常会担心以下几个问题：</p><h2>1. 功能是否有限？</h2><p>很多免费的CRM软件只提供基础功能，无法满足企业的复杂需求，导致企业需要额外购买付费功能或更换系统。</p><h2>2. 是否隐藏收费？</h2><p>有些CRM软件虽然标榜免费，但实际使用中会有很多隐藏收费，比如限制用户数量或功能模块，让企业措手不及。</p><h2>3. 是否易于使用？</h2><p>一些CRM软件的界面复杂、操作繁琐，可能需要花费大量时间学习，影响企业的使用体验和效率。</p><h2>4. 是否支持扩展？</h2><p>随着企业的发展，CRM系统需要支持更多的功能和用户。如果免费版无法扩展，企业可能需要重新更换系统，增加成本和风险。</p><p>Zoho CRM在这些方面表现得非常出色，既提供了强大的免费功能，又支持灵活扩展，是一个真正值得推荐的免费CRM软件。</p><h2>四、为什么选择Zoho CRM？</h2><h2>1. 真正免费，无隐藏收费</h2><p>Zoho CRM的免费版本是真正意义上的免费，没有隐藏收费。它支持多达3名用户，并提供了许多核心功能，包括客户信息管理、潜在客户跟踪、销售流程管理以及基本的报表和分析功能。对于小型团队或初创企业来说，这些功能已经足够满足日常需求。</p><h2>2. 功能全面，满足多种需求</h2><p>即使是免费版本，Zoho CRM也提供了许多强大的功能，涵盖了客户管理、销售自动化、市场营销等多个方面。例如：</p><p>销售自动化：Zoho CRM可以帮助企业自动化重复性任务，比如发送跟进邮件、提醒销售人员联系客户等，提高销售效率。<br/>潜在客户评分：通过Zoho CRM，企业可以根据客户的行为和属性对潜在客户进行评分，帮助销售团队优先跟进高价值客户，提升销售转化率。<br/>任务和日程管理：Zoho CRM内置了任务和日程管理功能，帮助团队更高效地协作，确保各项任务按时完成。</p><h2>3. 易于使用，界面友好</h2><p>Zoho CRM的界面设计简洁直观，即使是没有技术背景的用户也能快速上手。此外，Zoho还提供了丰富的在线教程和技术支持，帮助用户解决使用中的问题，提升用户体验。</p><h2>4. 支持多平台使用</h2><p>Zoho CRM支持在多种设备上使用，包括电脑、手机和平板。无论是在办公室还是外出拜访客户，用户都可以随时随地访问CRM系统，及时处理客户信息和销售任务。</p><h2>5. 灵活扩展，适应企业发展</h2><p>随着企业的发展，用户可以随时升级到Zoho CRM的付费版本，解锁更多高级功能，如高级数据分析、自定义报表、第三方应用集成以及更多用户支持。这种灵活性使得Zoho CRM不仅适合初创企业，也能满足中大型企业的需求。</p><h2>五、Zoho CRM的实际应用场景</h2><p>为了更直观地了解Zoho CRM的优势，我们来看几个实际应用场景：</p><p>场景一：初创企业的客户管理<br/>一家初创企业刚刚成立，团队规模较小，预算有限。他们需要一个工具来管理客户信息和跟踪销售进展。通过Zoho CRM的免费版本，他们可以：</p><p>集中存储客户信息，避免信息丢失。<br/>跟踪潜在客户的沟通记录，确保及时跟进。<br/>使用销售漏斗功能，优化销售流程，提升销售效率。<br/>场景二：小型团队的协作<br/>一个由3人组成的小型销售团队需要一个工具来协作管理客户。通过Zoho CRM，他们可以：</p><p>分配任务和日程，确保团队成员各司其职。<br/>使用潜在客户评分功能，优先跟进高价值客户，提升销售业绩。<br/>通过报表功能，分析销售数据，优化团队绩效，推动团队发展。<br/>场景三：企业的长期发展<br/>一家中型企业在使用Zoho CRM免费版一段时间后，发现业务需求增加，需要更多功能和用户支持。他们可以轻松升级到付费版本，解锁高级功能，而无需更换系统，降低迁移成本和风险。</p><h2>六、如何开始使用Zoho CRM？</h2><p>开始使用Zoho CRM非常简单，只需以下几步：</p><p>注册账户：访问Zoho CRM官网，注册一个免费账户。<br/>设置账户信息：根据企业需求，设置用户权限、销售流程等。<br/>导入客户数据：将现有的客户数据导入Zoho CRM，开始管理客户信息。<br/>开始使用：利用Zoho CRM的功能，优化销售流程，提高客户满意度。</p><h2>七、结语</h2><p>对于预算有限的企业来说，选择一款免费的CRM软件是一个明智的决定。而在众多免费CRM软件中，Zoho CRM凭借其强大的功能、友好的界面和灵活的扩展性，成为了一个非常值得推荐的选择。</p><p>无论是初创企业还是小型团队，Zoho CRM的免费版本都能满足基本需求。而随着企业的发展，Zoho CRM还可以通过付费升级提供更多高级功能，帮助企业实现长期增长。</p><p>如果你正在寻找一款真正免费的CRM软件，不妨试试Zoho CRM。它不仅能帮助你更高效地管理客户，还能为你的业务增长提供强有力的支持</p>]]></description></item><item>    <title><![CDATA[原生开发大模型智能体 成都定制通软件 ]]></title>    <link>https://segmentfault.com/a/1190000047402635</link>    <guid>https://segmentfault.com/a/1190000047402635</guid>    <pubDate>2025-11-16 15:02:09</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <pre><code> 基于OpenWebUI+Ollama+DeepSeek的原生开发技术路线，能高效构建本地化大模型智能体，其前端Svelte与后端Python的技术选型形成了轻量且高效的开发闭环，核心技术栈围绕交互层、模型管理层与推理层深度协同展开。
前端以Svelte为核心构建交互界面，依托其编译时优化特性实现轻量化渲染。OpenWebUI作为前端载体，采用Svelte的writable store实现集中式状态管理，在src/lib/stores/index.ts中定义用户会话、聊天数据等核心状态，确保跨组件数据一致性。通过IndexedDB实现聊天历史本地缓存，即便网络不稳定也能保障数据可访问性。组件开发中，Sidebar等模块通过订阅状态动态渲染列表，并结合窗口监听实现响应式布局切换，配合搜索防抖机制优化交互体验。
后端Python聚焦模型调度与接口适配，核心依赖Ollama的轻量化管理能力。Python通过调用Ollama API实现DeepSeek模型的生命周期管控，支持一键拉取不同参数版本（1.5B/7B/14B）的模型，适配不同硬件性能。借助FastAPI或Flask构建中间服务层，封装Ollama的模型调用接口，实现与前端OpenWebUI的通信适配，处理会话上下文管理与请求转发。同时通过Python脚本实现模型参数自定义配置，动态调整推理精度与速度，平衡性能需求。
技术链路中，OpenWebUI前端通过Python后端提供的API与Ollama交互，Ollama负责加载并运行DeepSeek模型，形成"前端交互-后端调度-模型推理"的完整链路。该路线兼顾本地化部署优势与开发效率，Python的灵活适配与Svelte的轻量高效成为技术核心支撑。
</code></pre>]]></description></item><item>    <title><![CDATA[面向openwebui快速开发智能体 成]]></title>    <link>https://segmentfault.com/a/1190000047402645</link>    <guid>https://segmentfault.com/a/1190000047402645</guid>    <pubDate>2025-11-16 15:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <pre><code>基于OpenWebUI+Ollama+DeepSeek，可以快速开发智能体，下面以开发一个AI药师智能体为例，扼要描述下其过程。
AI药师智能体可实现用药咨询、剂量核算、禁忌提示等核心功能，基于OpenWebUI+Ollama+DeepSeek的技术路线能快速完成本地化部署，兼顾开发效率与使用安全性。以下是完整构建步骤，适配Windows系统，macOS及Linux系统适配性待定，应该还要做一些调整。
第一步是环境前置配置，搭建基础运行框架。硬件需满足：CPU至少8核，内存16GB以上（7B模型），若部署14B模型建议32GB内存并搭配独立显卡。软件方面，先安装Python 3.10+及pip包管理工具，执行pip install fastapi uvicorn requests安装后端依赖；前端无需额外安装编译环境，OpenWebUI已集成Svelte运行时。接着安装Ollama，通过官网对应系统安装包一键部署，完成后在终端执行ollama --version验证，确保版本不低于0.1.30。
第二步为模型部署，加载DeepSeek医疗微调模型。Ollama支持一键拉取适配的DeepSeek医疗模型，终端执行ollama pull deepseek-med:7b（7B轻量版）或ollama pull deepseek-med:14b（14B高精度版），模型会自动存储至本地默认路径。为适配药师场景，需创建模型配置文件modelfile，添加FROM deepseek-med:7b指定基础模型，通过SYSTEM "你是专业AI药师，仅提供用药咨询，不替代医生诊断，需明确提示用药前咨询专业医师"定义角色定位，执行ollama create ai-pharmacist -f modelfile生成专属药师模型。
第三步是前端交互搭建，基于OpenWebUI定制界面。下载OpenWebUI源码后，进入项目目录执行docker-compose up -d启动服务，访问localhost:3000进入界面。在"模型管理"中选择已创建的ai-pharmacist模型，进入"界面定制"模块：添加药品查询、剂量计算等快捷功能按钮，通过Svelte组件修改src/lib/components/ChatInput.svelte，增加剂量输入框及禁忌关键词联想功能；在src/lib/stores/settings.ts中配置医疗场景专属主题，优化专业术语显示效果。
第四步是后端服务集成与调试。使用FastAPI构建中间服务，编写接口封装Ollama模型调用逻辑，通过@app.post("/api/medication-query")定义用药咨询接口，实现症状与药品的关联查询。集成药品数据库（如Drugbank开源数据），通过Python的sqlalchemy库实现数据关联，确保回答的准确性。调试阶段需重点测试：输入"高血压患者用药"等查询，验证模型是否能准确列举适用药物并提示禁忌；模拟儿童、老人等特殊人群用药咨询，检查剂量核算逻辑的正确性，同时确保每次回答都附加"不替代专业诊断"的安全提示。
最后执行系统优化，通过Ollama的ollama config set ai-pharmacist num_ctx=4096扩展上下文长度，提升多轮咨询体验；前端开启缓存优化，减少重复请求。至此，可快速完成兼具专业性与安全性的AI药师智能体构建。
</code></pre>]]></description></item><item>    <title><![CDATA[uniapp微信小程序登录以及获取手机号]]></title>    <link>https://segmentfault.com/a/1190000047402622</link>    <guid>https://segmentfault.com/a/1190000047402622</guid>    <pubDate>2025-11-16 14:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>登录流程如下</h2><p><img width="710" height="720" referrerpolicy="no-referrer" src="/img/bVdm3Km" alt="" title=""/></p><ol><li>登录，<code>wx.login</code>拿到<code>code</code>，调用后端接口</li><li>后端通过<code>appId</code>、<code>appsecret</code>、<code>code</code>获取<code>session_key</code>和<code>openid</code></li><li>后端自定义登录态，与<code>openid</code>、<code>sessiong_key</code>关联，返回自定义登录态给前端</li><li>前端拿到登录态(token)，后续拿<code>token</code>请求接口即可。</li></ol><p><strong>登录的同时要加手机号验证，流程如下：</strong></p><ol><li>前端点击一键登录按钮，按钮绑定<code>open-type="getPhoneNumber"</code></li><li>在<code>@getphonenumber</code>的回调中拿到手机<code>code</code>码</li><li>拿到手机<code>code</code>码后，接着调用<code>wx.login</code>获取登录<code>code</code>码</li><li>调用登录接口，同时将手机<code>code</code>码、登录<code>code</code>码传给后端</li><li>后端首先拿登录<code>code</code>码获取<code>openid</code>、<code>sessiong_key</code>等信息，然后调用<code>getAccessToken</code>接口获取<code>access_token</code></li><li>通过<code>access_token</code>调用获取<code>getPhoneNumber</code>接口获取手机号</li><li>后端自定义登录态，关联手机号，逻辑根据实际情况调整</li><li>返回登录态(token)以及其它附带信息给前端</li></ol><p><img width="723" height="891" referrerpolicy="no-referrer" src="/img/bVdm3Kn" alt="image.png" title="image.png" loading="lazy"/></p><p>登录跟获取手机号可以拆开，有些类型的小程序仅登录就好了，不需要手机号参与，这两个功能在小程序端是分开的模块，如果你的业务里需要登录时验证手机号，可以将登录和获取手机号的逻辑整合到一起。</p><p>参考文档：<br/><a href="https://link.segmentfault.com/?enc=QjYNAUp2X3IX9p2uefQzeA%3D%3D.rXv%2Bij9l52wgDvpK3xpsY%2Fi1dtFIUxTNQu8%2Bvl%2BEhu3OU6jwFQCx5RnAO4iVCjCk57f%2BICityUvjm9mTAZvMQEOppwgVacoXqRx3pohHmLMEgRCWP2gh6uVcq3kkiUsP" rel="nofollow" target="_blank">小程序登录文档</a><br/><a href="https://link.segmentfault.com/?enc=SzkawMkJDB7%2BMfnmmtXPIg%3D%3D.bd43Rgb4%2FHKFJK9O74HW%2B6CXwXgniGe%2Ff7QC969E9DHHzbzNA%2B9VWm644zYbm8JcnEpgCLGlwSVNrMJpWdE%2Bn5p0FQUZ9Efoi8A%2FZjIixOupvptSvYCa9DAdREUgo4PA" rel="nofollow" target="_blank">wx.login</a><br/><a href="https://link.segmentfault.com/?enc=tj22G%2BVlvlktnKij8WKLiA%3D%3D.UDkixPn9C3LxR%2F4rcfSZgYtG7xNil%2Fttdi9fvXnThRh7%2BYye5wg5OFtEdYrrcj2jqZwr4IyLEuZinQ2Y6ShrW4jLrVYPnZ3aLICky3ABmveBpIHNIXwsE5MCN4WgPeZv" rel="nofollow" target="_blank">手机号快速验证组件</a><br/><a href="https://link.segmentfault.com/?enc=VKD%2BxZY%2F%2FgP4g%2BBRCpM1Mg%3D%3D.DW%2FiBmesiw4zfFrLKSkaHVJp%2FbN8VekF9my9cD15JnVSUW7lTx85o5D8N3JrsXZQknirYOjAGQrhDE68u%2B54YyCBt4hCk%2FUcn%2FVZBtQbPlfNrm7sm5lQEeBhQ0hdWbAlBbUOd2k4KxX%2FJ46rQG9LbA%3D%3D" rel="nofollow" target="_blank">快速验证-获取手机号</a><br/><a href="https://link.segmentfault.com/?enc=91gRdI4bblJ%2BIGmc5AYk%2FQ%3D%3D.1jifettF1G03COleAdU%2FhzDMyFbPr9jVR0eCf7afUlN6LKPBwDPD0bJVF3C0arwoaP5Rc7F%2BiAQiFEzKqYiqAhFSPC3koa5ufUzMt7Q9vysN29JeCjM5O%2BLnkZBw6HMx" rel="nofollow" target="_blank">获取接口调用凭据getAccessToken</a><br/><a href="https://link.segmentfault.com/?enc=YyCIJxV6RzZvVLkF9V%2F6gA%3D%3D.mB%2FUPPvEOrb4z1UKqET5zkYguPyRWS6gM0Co%2FO5D6Fz4bv%2FAMYPk7rTPOF6xS0NH7p398jB19%2FX8NAEhxMtcICpSVQaPHoc%2F3dF2BaeG8nP1UjbCtUpGRHqxx4CbBq3Tt08oyiVDfnHwqTYOBGhtgyqY5PoxXTu5eFDFmuUIh%2Bo%3D" rel="nofollow" target="_blank">通过code获取网站授权 access_token</a><br/><a href="https://link.segmentfault.com/?enc=7wNinavC9VD7EFtUO89UqA%3D%3D.GN1uHsKUQzi3502CcuuaPo1%2B%2FEaZvmG%2Bp0wEHI4QdqqFF2Vod86MO7J50vD11fZMPIGncHoUV8XW6%2FUUVxtUpxTgomBJIBgeFUkYMjotWrArRpMIlxv31W3E8P2di49u" rel="nofollow" target="_blank">小程序帐号登录规范要求与修改指引</a></p><h2>获取手机号code</h2><p>通过开放能力<code>open-type</code>实现 <code>open-type="getPhoneNumber" @getphonenumber="getPhoneNumber"</code><br/>需要注意，微信小程序开发者账号必须认证且隐私协议完善后才可以调用该<code>API</code></p><pre><code>&lt;button type="primary" :style="customStyle.sure" open-type="getPhoneNumber" @getphonenumber="getPhoneNumber"&gt;
一键登录
&lt;/button&gt;</code></pre><pre><code>const getPhoneNumber = (e) =&gt; {
    try {
        if (e.detail.errno == 112) {
            return getApp().errFeedback(e.detail);
        }
        if(e.detail.errMsg == 'getPhoneNumber:fail user deny'){
            uni.showToast({
                title: '您已拒绝授权，相关功能将不可用',
                icon: 'none',
                duration: 1000
            });
            return;
        }
            console.log('获取手机号', e.detail.code);
    } catch (err) {
        console.log(err);
    } finally {
    }
};</code></pre><p>同意授权的返回<br/><img width="723" height="262" referrerpolicy="no-referrer" src="/img/bVdm3Kv" alt="" title="" loading="lazy"/><br/>如果拒绝授权，则返回：<br/><img width="723" height="143" referrerpolicy="no-referrer" src="/img/bVdm3Kw" alt="" title="" loading="lazy"/></p><h2>获取AccessToken</h2><p>在这里生成<code>AppSecret</code><br/><img width="723" height="266" referrerpolicy="no-referrer" src="/img/bVdm3Kx" alt="" title="" loading="lazy"/></p><pre><code>const getAccessToken = async (code) =&gt; {
    return new Promise((resolve, reject) =&gt; {
        uni.request({
            method: 'GET',
            url: `https://api.weixin.qq.com/cgi-bin/token`,
            data: {
                grant_type: 'client_credential', // 固定值
                appid: '你的appid',
                secret: '你的AppSecret'
            },
            dataType: 'json',
            success: (response) =&gt; {
        console.log('获取access_token', response);
                if (response.statusCode != 200) {
                    uni.showToast({
                        title: '获取登录凭证失败~',
                        icon: 'none',
                        duration: 1000
                    });
                    return;
                }
                let { data } = response;
                resolve(data.access_token);
            },
            fail: (err) =&gt; {
                console.log('请求失败', err);
            }
        });
    });
};</code></pre><p>成功的响应：<br/><img width="723" height="148" referrerpolicy="no-referrer" src="/img/bVdm3Ky" alt="" title="" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[SseEmitter返回data被双引号]]></title>    <link>https://segmentfault.com/a/1190000047402597</link>    <guid>https://segmentfault.com/a/1190000047402597</guid>    <pubDate>2025-11-16 13:01:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>一、背景</h2><p>最近做接口的性能改造，大概背景如下:<br/>旧: <br/>  1.前端每秒轮询后端接口，接口返回数据状态，前端用状态做判断，变更页面交互。<br/>  2.前端固定调用后端接口，接口阻塞100秒，等待后端随时返回结果，100秒到达后无结果，直接失败。</p><p>新: <br/>  改为<code>ServerSentEvent</code>以<code>text-event-stream</code>固定时间窗口由后端返回处理进度。</p><h2>二、简单对比</h2><p>1.后端服务压力大。尤其在用户量大，并发量大，又是系统核心业务时，不好把控。<br/>2.阻塞<code>Servlet</code>线程, 当前业务同时访问量大时，影响其他业务请求；最大等待时间不好把控，且受HTTP响应超时时间影响。<br/>3.自由简单，且实时性比较强，只要不是高并发入口请求业务就能使用。不占用<code>Servlet</code>线程。</p><h2>三、问题现象</h2><h3>1.主代码展示</h3><blockquote>以下代码均为精简后的最小问题复现demo</blockquote><ul><li>SSE主接口<br/><img width="723" height="535" referrerpolicy="no-referrer" src="/img/bVdm3JS" alt="PixPin_2025-11-16_11-57-06.png" title="PixPin_2025-11-16_11-57-06.png"/></li></ul><h3>2.问题表现</h3><p>通过<code>curl</code>加<code>-N</code>参数调用后，发现返回的<code>data</code>都被双引号包裹，并且前端的<code>EventSource.onmessage</code>无法回调到（总是触发<code>onerror</code>回调）<br/><img width="723" height="609" referrerpolicy="no-referrer" src="/img/bVdm3JT" alt="PixPin_2025-11-16_11-59-00.png" title="PixPin_2025-11-16_11-59-00.png" loading="lazy"/></p><h2>四.问题思考</h2><p>参考并阅读以下文档<br/><a href="https://link.segmentfault.com/?enc=fQrJXkuJ0WXpnt8JJmsAzQ%3D%3D.LY4Kyzvx5OuF7%2FlKgeMfN868QoCx7XwYi%2Bk2SDWAOhmo%2FR6X2C7oV42RncOlYtHkhjXNYvmT%2Fnlq%2BCkjovM5xcVj%2BZNVaL2TACbY%2BtWUvh6LqgVAnZp%2BLrRuMU7d1yMU" rel="nofollow" target="_blank">前端MDN ServerSentEvent文档</a><br/><a href="https://link.segmentfault.com/?enc=hX4QFmSFOXJbTR04wiRFiw%3D%3D.0cqujbtX25ZHZY%2BJZ5CDFCHXeCuPOj65quKeQVeano%2FYujArZxiKs%2FWCdxVYQR24xNrNNhQTZxpEKdCoJsrgTyOuKqvW396Xm6NIqanhAmG%2Ftb6byEE1WudXipT2Q4IPoPpOundS3y%2BUUUsaJbJ3C3XgPGZbyi3CR5%2F%2BXawSrkybN%2F9u0O%2B3tLyxSgY3E7AD8jHN0OqiLtcMSIaOJFwNnMi1w%2FDhoaAhNfWL4x8BGIM%3D" rel="nofollow" target="_blank">Spring ServerSentEvent文档</a></p><p>在前端侧浏览器看到开发者工具内<code>EventStream</code>标签页显示空白， 意识到确实是后端自身问题，观察数据结构后发现，像是返回了JSON结构的<code>String</code>字符串，只有JSON结构下<code>String</code>两侧才会有引号，接着立刻翻源码验证。</p><p>从源码<code>org.springframework.web.servlet.mvc.method.annotation.ResponseBodyEmitterReturnValueHandler.HttpMessageConvertingHandler#sendInternal</code>中找到线索，发现<code>Spring</code>在处理<code>text-event-stream</code>响应时，仍然是从Servlet Web的全局<code>HttpMessageConverter</code>查找，但这里的<code>mediaType</code>值到底是哪个值呢，存在以下三种情况</p><ul><li><code>Controller</code>方法整体的<code>MediaType</code>，这个值固定是<code>text/event-stream</code></li><li><code>SseEmitter#send(java.lang.Object, org.springframework.http.MediaType)</code>方法整体的<code>MediaType</code>，这个值固定是<code>text/plain</code></li><li><code>SseEmitter#send(java.lang.Object, org.springframework.http.MediaType)</code>方法第二个参数传入的<code>MediaType</code>，这个值动态的，我这里是<code>application/json;charset=UTF-8</code></li></ul><p>这里大概率是第二种导致的。<br/><img width="723" height="422" referrerpolicy="no-referrer" src="/img/bVdm3JX" alt="PixPin_2025-11-16_12-09-33.png" title="PixPin_2025-11-16_12-09-33.png" loading="lazy"/></p><h2>五、得到结论</h2><p>由于在K8s内网部署，本机无法启动，关联的中间件和附加Bean太多。到这里为止，其实问题清晰了，结合对Spring源码的理解，<strong>项目中的全局<code>HttpMessageConverter</code>配置肯定有问题</strong>，我们公司前身有很多认为自己很厉害的人，都是从阿里转过来的，酷爱<code>fastjson</code>，项目基建时，肯定干掉了所有的<code>HttpMessageConverter</code>，统一换成了<code>fastjson</code>，接着找这个代码</p><p><img width="723" height="450" referrerpolicy="no-referrer" src="/img/bVdm3J1" alt="PixPin_2025-11-16_12-25-22.png" title="PixPin_2025-11-16_12-25-22.png" loading="lazy"/></p><p>这是2021年，前人留下来的宝藏，只能说这个人复制的时候可能没过脑</p><ul><li>红色框出来的就是根因</li><li>绿色框出来的就是完全无脑，二进制文档，图片，也要Json吗？</li></ul><h3>1.看看上游Spring的处理</h3><blockquote>随即问题来了，Spring默认会有一大堆的<code>HttpMessageConverter</code>自动配置，当前这个是<code>add</code>到<code>List&lt;HttpMessageConverter&lt;?&gt;&gt; converters</code>的第一位吗？默认的还在不在？</blockquote><p>源码如下: <code>org.springframework.web.servlet.config.annotation.WebMvcConfigurationSupport#getMessageConverters</code><br/><img width="723" height="451" referrerpolicy="no-referrer" src="/img/bVdm3J2" alt="PixPin_2025-11-16_12-29-52.png" title="PixPin_2025-11-16_12-29-52.png" loading="lazy"/></p><p><code>org.springframework.web.servlet.config.annotation.WebMvcConfigurationSupport#addDefaultHttpMessageConverters</code>如下<br/>如图就是<code>Spring</code>的解法<br/><img width="723" height="540" referrerpolicy="no-referrer" src="/img/bVdm3J3" alt="PixPin_2025-11-16_12-31-54.png" title="PixPin_2025-11-16_12-31-54.png" loading="lazy"/></p><h2>六、圈定影响</h2><p>那么新的问题来了，如果这个项目中有其他直接返回<code>String</code>的接口，岂不是意味着全部被包了一层双引号？</p><p>恰好想起之前有其他人不听劝，不使用<code>Spring Actuator</code>的健康检查，非要手搓，返回的恰好是<code>String</code>,线上验证一下<br/><img width="723" height="227" referrerpolicy="no-referrer" src="/img/bVdm3J5" alt="PixPin_2025-11-16_12-37-48.png" title="PixPin_2025-11-16_12-37-48.png" loading="lazy"/></p><p>那就是影响到了所有直接返回<code>String</code>的接口。</p><h2>七、问题复现</h2><blockquote>本地不能启动，最小demo，debug一下</blockquote><p>debug启动后发现确实是这里影响的，这里会走两次<br/>一次前面的<code>text/plain</code><br/><img width="723" height="301" referrerpolicy="no-referrer" src="/img/bVdm3JZ" alt="PixPin_2025-11-16_12-17-41.png" title="PixPin_2025-11-16_12-17-41.png" loading="lazy"/><br/>实际的第二个参数的<code>MediaType</code>，值<code>application/json;charset=UTF-8</code><br/><img width="723" height="297" referrerpolicy="no-referrer" src="/img/bVdm3J0" alt="PixPin_2025-11-16_12-18-09.png" title="PixPin_2025-11-16_12-18-09.png" loading="lazy"/></p><p>看看<code>HttpMessageConverter</code>是不是错选了<br/><img width="723" height="435" referrerpolicy="no-referrer" src="/img/bVdm3J7" alt="PixPin_2025-11-16_12-43-27.png" title="PixPin_2025-11-16_12-43-27.png" loading="lazy"/></p><p><strong>根因确定: <code>text/plain</code>错误配置了使用<code>FastJsonHttpMessageConverter</code>,导致返回的不是字符串，而是json字符串</strong></p><h2>八、问题修复</h2><p>修复就非常简单了，删除不合理的<code>MediaType</code>配置，最前面追加<code>StringHttpMessageConverter</code>即可<br/><img width="723" height="304" referrerpolicy="no-referrer" src="/img/bVdm3J9" alt="PixPin_2025-11-16_12-50-20.png" title="PixPin_2025-11-16_12-50-20.png" loading="lazy"/></p><blockquote>当然为了缩小影响范围，只删除<code>MediaType.TEXT_PLAIN</code>配置即可</blockquote><p>至此，问题修复。<br/><img width="723" height="142" referrerpolicy="no-referrer" src="/img/bVdm3Ka" alt="PixPin_2025-11-16_12-52-46.png" title="PixPin_2025-11-16_12-52-46.png" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[【URP】Unity[RendererF]]></title>    <link>https://segmentfault.com/a/1190000047402504</link>    <guid>https://segmentfault.com/a/1190000047402504</guid>    <pubDate>2025-11-16 11:01:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <blockquote><a href="https://link.segmentfault.com/?enc=AhWi7LKTZq84VIp9tBX8hw%3D%3D.iSkMlmTeMMVn3k7HwZ2Vn9yQuIuY%2FaoRISMGemRRE9ZGh87e8K17VRujHdZA2wpkgGrJmevxJkNPoIZIFzb4d7gupyXjp0yQMn%2F39Teg9gQvHCbGCmXAjVVO%2FFA%2Ff5Mzx2HmbzjX2bpBNI36eLLDrRr9qJf%2BWQW3aZu%2BuJVMAFoVzP%2FbsOwJYFJ%2BgbygJvyRzhi3RYCR%2Bnv2WRjoChDv51FoZg2nOrf7ru0bo4BZvPc%3D" rel="nofollow" target="_blank">【从UnityURP开始探索游戏渲染】</a><strong>专栏-直达</strong></blockquote><p>FullScreenPassRendererFeature是Unity URP渲染管线中用于实现全屏后处理效果的核心组件，它允许开发者在渲染流程的特定阶段插入自定义的全屏着色器效果。</p><h2><strong>功能与作用</strong></h2><ul><li>‌<strong>核心功能</strong>‌：通过ScriptableRenderPass在URP管线中注入全屏四边形绘制命令，应用自定义Shader实现屏幕空间特效（如模糊、色调调整等）</li><li><p>‌<strong>典型应用场景</strong>‌：</p><ul><li>屏幕后处理（如Bloom、景深模拟）</li><li>全局滤镜效果（黑白化、夜视模式）</li><li>特殊视觉特效（扫描线、像素化）</li></ul></li></ul><h2><strong>发展历史</strong></h2><ul><li>‌<strong>URP初期</strong>‌：需手动编写完整的ScriptableRendererFeature和ScriptableRenderPass类实现全屏效果</li><li>‌URP 7.0+ ：引入预置的FullScreenPassRendererFeature简化开发流程</li><li>‌<strong>URP 17.0</strong>‌：重构API至RenderGraph系统，优化资源管理机制</li></ul><h2>原理</h2><p>FullScreenPassRendererFeature是Unity URP中用于实现全屏后处理效果的核心组件，其底层原理基于URP的可编程渲染管线架构。</p><h3><strong>核心原理</strong></h3><ul><li>‌<strong>继承关系</strong>‌：继承自<code>ScriptableRendererFeature</code>基类，通过<code>Create()</code>方法初始化自定义的<code>ScriptableRenderPass</code>子类实例</li><li>‌<strong>执行流程</strong>‌：在URP渲染管线的特定阶段（如不透明物体渲染后）插入全屏绘制命令，通过<code>CommandBuffer</code>调用<code>Blit</code>或<code>DrawProcedural</code>实现</li><li>‌<strong>资源管理</strong>‌：使用<code>RTHandle</code>系统动态管理渲染目标，自动处理不同分辨率下的资源分配与释放</li></ul><h3><strong>关键代码示例</strong></h3><p>以下实现一个基础的全屏泛光效果：</p><ul><li><p>BloomFeature.cs</p><pre><code class="csharp">using UnityEngine;
using UnityEngine.Rendering;
using UnityEngine.Rendering.Universal;

[System.Serializable]
public class BloomSettings {
    public float intensity = 1.0f;
    public Color tint = Color.white;
}

public class BloomFeature : ScriptableRendererFeature {
    public BloomSettings settings = new BloomSettings();
    private BloomPass m_Pass;

    public override void Create() {
        m_Pass = new BloomPass(settings);
        m_Pass.renderPassEvent = RenderPassEvent.AfterRenderingPostProcessing;
    }

    public override void AddRenderPasses(
        ScriptableRenderer renderer, 
        ref RenderingData renderingData) {
        renderer.EnqueuePass(m_Pass);
    }
}

class BloomPass : ScriptableRenderPass {
    private Material m_Material;
    private BloomSettings m_Settings;
    private RTHandle m_TempTexture;

    public BloomPass(BloomSettings settings) {
        m_Settings = settings;
        m_Material = CoreUtils.CreateEngineMaterial("Hidden/Blur");
    }

    public override void Configure(CommandBuffer cmd, 
        RenderTextureDescriptor cameraTextureDescriptor) {
        m_TempTexture = RTHandles.Alloc(
            Vector2.one * 0.5f, 
            colorFormat: cameraTextureDescriptor.colorFormat);
    }

    public override void Execute(ScriptableRenderContext context, 
        ref RenderingData renderingData) {
        var cmd = CommandBufferPool.Get("BloomPass");
        Blit(cmd, 
            renderingData.cameraData.renderer.cameraColorTargetHandle,
            m_TempTexture, 
            m_Material, 0);
        Blit(cmd, 
            m_TempTexture,
            renderingData.cameraData.renderer.cameraColorTargetHandle);
        context.ExecuteCommandBuffer(cmd);
        CommandBufferPool.Release(cmd);
    }

    public override void FrameCleanup(CommandBuffer cmd) {
        m_TempTexture.Release();
    }
}</code></pre></li></ul><h3><strong>技术细节</strong></h3><ul><li>‌<strong>材质控制</strong>‌：通过Shader的<code>LightMode</code>标签匹配（如<code>UniversalForward</code>）确定渲染路径</li><li>‌<strong>时序控制</strong>‌：<code>RenderPassEvent</code>枚举精确控制执行时机（如<code>AfterRenderingOpaques</code>）</li><li>‌<strong>多Pass协作</strong>‌：支持通过多个<code>ScriptableRenderPass</code>实现效果叠加，如先提取亮部再模糊</li></ul><h3><strong>性能优化</strong></h3><ul><li>‌<strong>临时纹理复用</strong>‌：通过<code>RTHandle</code>的缩放参数实现动态分辨率渲染</li><li>‌<strong>命令缓冲池</strong>‌：使用<code>CommandBufferPool</code>减少GC开销</li><li>‌<strong>材质实例化</strong>‌：避免每帧创建新材质</li></ul><p>该机制相比传统<code>OnRenderImage</code>方案，在URP中能更好地集成到SRP批处理系统中，且支持XR多通道渲染等高级特性</p><h2><strong>实现流程示例</strong></h2><p>以下为完整实现黑白滤镜效果的URP示例：</p><ul><li><p>GrayFeature.cs</p><pre><code class="csharp">using UnityEngine;
using UnityEngine.Rendering;
using UnityEngine.Rendering.Universal;

public class GrayRenderFeature : ScriptableRendererFeature {
    public RenderPassEvent renderEvent = RenderPassEvent.AfterRendering;
    public Shader shader;
    private Material grayMaterial;
    private GrayPass grayPass;

    public override void Create() {
        grayMaterial = CoreUtils.CreateEngineMaterial(shader);
        grayPass = new GrayPass(grayMaterial, renderEvent);
    }

    public override void AddRenderPasses(ScriptableRenderer renderer, ref RenderingData renderingData) {
        grayPass.SetTarget(renderer.cameraColorTargetHandle);
        renderer.EnqueuePass(grayPass);
    }
}

public class GrayPass : ScriptableRenderPass {
    private Material material;
    private RTHandle source;

    public GrayPass(Material material, RenderPassEvent passEvent) {
        this.material = material;
        this.renderPassEvent = passEvent;
    }

    public void SetTarget(RTHandle colorHandle) {
        source = colorHandle;
    }

    public override void Execute(ScriptableRenderContext context, ref RenderingData renderingData) {
        CommandBuffer cmd = CommandBufferPool.Get("GrayEffect");
        Blitter.BlitCameraTexture(cmd, source, source, material, 0);
        context.ExecuteCommandBuffer(cmd);
        CommandBufferPool.Release(cmd);
    }
}</code></pre></li><li><p>GrayEffect.shader</p><pre><code class="c">Shader "Custom/GrayEffect" {
    Properties {
        _MainTex ("Base (RGB)", 2D) = "white" {}
    }
    SubShader {
        Pass {
            CGPROGRAM
            #pragma vertex vert
            #pragma fragment frag
            #include "UnityCG.cginc"

            struct appdata {
                float4 vertex : POSITION;
                float2 uv : TEXCOORD0;
            };

            struct v2f {
                float2 uv : TEXCOORD0;
                float4 vertex : SV_POSITION;
            };

            sampler2D _MainTex;

            v2f vert (appdata v) {
                v2f o;
                o.vertex = UnityObjectToClipPos(v.vertex);
                o.uv = v.uv;
                return o;
            }

            fixed4 frag (v2f i) : SV_Target {
                fixed4 col = tex2D(_MainTex, i.uv);
                float gray = dot(col.rgb, float3(0.299, 0.587, 0.114));
                return fixed4(gray, gray, gray, col.a);
            }
            ENDCG
        }
    }
}</code></pre></li></ul><h2><strong>参数说明与用例</strong></h2><table><thead><tr><th>参数</th><th>类型</th><th>说明</th><th>典型值</th></tr></thead><tbody><tr><td>renderEvent</td><td>RenderPassEvent</td><td>执行时机</td><td>AfterRenderingOpaques</td></tr><tr><td>shader</td><td>Shader</td><td>效果着色器</td><td>自定义全屏Shader</td></tr><tr><td>intensity</td><td>float</td><td>效果强度</td><td>0.0-1.0</td></tr></tbody></table><p>‌<strong>实际配置步骤</strong>‌：</p><ul><li>创建URP Renderer Asset（若不存在）</li><li>通过Inspector添加FullScreenPassRendererFeature</li><li>指定Material并使用ShaderGraph创建效果</li><li>调整RenderPassEvent控制执行顺序</li></ul><h2><strong>性能优化建议</strong></h2><ul><li>使用RTHandle管理渲染目标避免内存浪费</li><li>复杂效果建议结合Volume系统实现参数动态调整</li><li>移动端需注意带宽占用，推荐使用Half Resolution处理</li></ul><hr/><blockquote><a href="https://link.segmentfault.com/?enc=tpvOW6RgEfm2cQ8nWSENnQ%3D%3D.YQ2xyqHArT4BBYc7VKiD4N2%2BX981moMm3LCQrN7eNfmV9V4Ko6muslUKEAjkqNatqcwpp5z6Ge8CHLhL9WwpUEijyQrzPNCLlEWqLrExrY7PKv62xNFfqpmiCdb0AVX%2F69tFYF7hIECitOSvZziD0sOCkKPUHWBSBA7l8UHVtLN011ZzUAv%2BL%2BPfSX5GwDZ2HLBxlvdRGyyTDmpvkAetzp8eQ0DTH0dtsp91njpzYmE%3D" rel="nofollow" target="_blank">【从UnityURP开始探索游戏渲染】</a><strong>专栏-直达</strong><br/>（欢迎<em>点赞留言</em>探讨，更多人加入进来能更加完善这个探索的过程，🙏）</blockquote>]]></description></item><item>    <title><![CDATA[飞牛 OS 使用 Docker 部署 J]]></title>    <link>https://segmentfault.com/a/1190000047402473</link>    <guid>https://segmentfault.com/a/1190000047402473</guid>    <pubDate>2025-11-16 10:04:08</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>Docker Compose</h2><pre><code>version: '3.8'
services:
  demoService:
    restart: always
    build: . 
    image: demoService:1.0.0            #自定义镜像名和版本号
    container_name: demoService
    volumes:
      - /vol2/1000/docker-data/demoService/logs:/logs
    ports:
      - 9999:9999
    environment:
      - profile=local
      - TZ=Asia/Shanghai</code></pre><h2>Dockerfile</h2><pre><code>FROM java:8u111-jdk-alpine
VOLUME /tmp
COPY demoService-0.0.1-SNAPSHOT.jar demoService-0.0.1-SNAPSHOT.jar
ENTRYPOINT ["java","-jar" ,"-Xms2048m","-Xmx2048m","-Xss512k","-Dspring.profiles.active=${profile}","demoService-0.0.1-SNAPSHOT.jar"]</code></pre>]]></description></item><item>    <title><![CDATA[如何在 Shell 脚本中使用多行注释 ]]></title>    <link>https://segmentfault.com/a/1190000047402476</link>    <guid>https://segmentfault.com/a/1190000047402476</guid>    <pubDate>2025-11-16 10:03:35</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000045412131" alt="How to Create Multiline Comments in Shell Scripts" title="How to Create Multiline Comments in Shell Scripts"/></p><p>在编写 shell 脚本时，添加注释来解释代码的目的和功能是很重要的。shell 脚本中的注释是用散列号“#”表示。但是，有时您可能希望编写跨几行的多行注释。</p><p>在本文中，我们将讨论如何在 shell 脚本中创建多行注释。</p><h3>Using multiple single-line comments</h3><p>在 shell 脚本中创建多行注释的一种方法是使用多个单行注释。</p><pre><code>#!/bin/bash

# This is a multiline comment
# that spans several lines
# and explains the purpose of the script
echo "Hello, world!"</code></pre><h3>Using Here Documents</h3><p>在 shell 脚本中创建多行注释的另一种方法是使用 <strong>Here Documents</strong>，示例如下：</p><pre><code>#!/bin/bash

: &lt;&lt;'COMMENT'
This is a multiline comment
that spans several lines
and explains the purpose of the script
COMMENT

echo "Hello, world!"</code></pre><p>在本例中，我们使用 Here Document 创建一个跨三行的多行注释。Here Document 的语法是 <strong>:&lt;&lt;'STRING'</strong>，其中 STRING 是标记 Here Document 结束的分隔符。在本例中，我们使用 COMMENT 作为分隔符。</p><h3>Using the <code>:</code> command</h3><p>最后，您可以使用 <code>:</code> 命令在 shell 脚本中创建多行注释。<code>: </code> 命令是一个空命令，什么也不做，但它可以用来创建多行注释。这里有一个例子：</p><pre><code>#!/bin/bash

: '
This is a multiline comment
that spans several lines
and explains the purpose of the script
'

echo "Hello, world!"</code></pre><p>在这个例子中，我们使用 <code>:</code> 命令创建一个跨三行的多行注释，注释文本用单引号括起来。</p><h3>我的开源项目</h3><p><a href="https://link.segmentfault.com/?enc=AK89nab7MVyyeb00oXeCzg%3D%3D.oVwJVW8uuXVlntqBJztPEW6XiNnLGd3kzxs8QnuGNp8%3D" rel="nofollow" target="_blank"><img referrerpolicy="no-referrer" src="/img/remote/1460000043302459" alt="酷瓜云课堂-在线教育解决方案" title="酷瓜云课堂-在线教育解决方案" loading="lazy"/></a></p><ul><li><a href="https://link.segmentfault.com/?enc=7ZKjLpc5mADTjyQVAXIIcA%3D%3D.xlVeP8hb9F2pwYZsuwsu72SZcyI9R6ZFZ5t1vO0OJ0RbYRM%2BbANznJquW%2B4iu7vt" rel="nofollow" target="_blank">course-tencent-cloud（酷瓜云课堂 - gitee仓库）</a></li><li><a href="https://link.segmentfault.com/?enc=YuonuMX%2BEZg476dk591M%2Bg%3D%3D.uqAcwviRO%2B30YZGOUFbGTD62TFgKQlCD20F98eiadoxbbMMzdsjylKtvqRq84FzMcxcyg5IyR2e6GjopS8GhYQ%3D%3D" rel="nofollow" target="_blank">course-tencent-cloud（酷瓜云课堂 - github仓库）</a></li></ul>]]></description></item><item>    <title><![CDATA[mysql-5.7.30-linux-g]]></title>    <link>https://segmentfault.com/a/1190000047402480</link>    <guid>https://segmentfault.com/a/1190000047402480</guid>    <pubDate>2025-11-16 10:03:01</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>​第一步：准备工作（找块好地方）</p><ol><li><strong>上传安装包</strong>：<strong>安装包下载：</strong><a href="https://link.segmentfault.com/?enc=GCv%2FqmSXsQ1CJ0GRUA6Juw%3D%3D.QtaM%2BuEERUFx4uycZX11%2Bw%2F8qzyfhvEmWIsy%2BsPeKVceup1%2FV4cEfpANAu1edihg" rel="nofollow" title="https://pan.quark.cn/s/57dcaa6183b0" target="_blank">https://pan.quark.cn/s/57dcaa6183b0</a>，首先，你得把这个 <code>mysql-5.7.30-linux-glibc2.12-x86_64.tar.gz</code>文件传到你的Linux服务器上。比如，你可以用FTP工具或者<code>scp</code>命令把它扔到 <code>/usr/local/src</code>目录下。这个目录通常就是放这些源码包的地方。</li><li><p><strong>检查老版本</strong>：为了防止打架，先看看系统里有没有自带的旧版MySQL。有的话就请它离开。</p><pre><code>rpm -qa | grep mysql</code></pre></li></ol><pre><code>如果上面命令列出了什么包，比如 `mysql-libs`，就用下面的命令卸载掉（以实际查到的名字为准）：

```
rpm -e --nodeps 查到的包名
```


</code></pre><h3>第二步：解压和安排“住处”</h3><ol><li><p><strong>进入目录并解压</strong>：</p><pre><code>cd /usr/local/src
tar -xzf mysql-5.7.30-linux-glibc2.12-x86_64.tar.gz</code></pre></li></ol><ol><li><p><strong>挪到最终位置并改个短名</strong>：解压后会得到一个长长的文件夹名，我们把它挪到 <code>/usr/local</code>下，并改名叫 <code>mysql</code>，这样方便以后操作。</p><pre><code>mv mysql-5.7.30-linux-glibc2.12-x86_64 /usr/local/mysql</code></pre></li></ol><h3>第三步：创建专属用户和目录</h3><ol><li><p><strong>创建mysql用户组和用户</strong>：让MySQL用一个专门的用户来运行，这样更安全。</p><pre><code>groupadd mysql
useradd -r -g mysql -s /bin/false mysql # 创建一个不能登录系统的mysql用户</code></pre></li></ol><ol><li><p><strong>创建数据存放目录</strong>：MySQL的所有数据（比如你建的数据库、表）都会放在这里。通常我们放在 <code>/data/mysql</code>。</p><pre><code>mkdir -p /data/mysql</code></pre></li></ol><ol><li><p><strong>把目录的“所有权”给mysql用户</strong>：</p><pre><code>chown -R mysql:mysql /data/mysql
chown -R mysql:mysql /usr/local/mysql</code></pre></li></ol><h3>第四步：初始化数据库</h3><p>这是最关键的一步，相当于给新MySQL房子置办家具。</p><p>进入MySQL的家，执行初始化命令：</p><pre><code>cd /usr/local/mysql
./bin/mysqld --initialize --user=mysql --datadir=/data/mysql</code></pre><p><strong>注意看屏幕输出！</strong> 命令执行完后，会有一行类似这样的信息：</p><pre><code>[Note] A temporary password is generated for root@localhost: 这里是一串随机密码</code></pre><p><strong>一定拿个小本本把这个临时密码记下来！</strong> 第一次登录全靠它。</p><h3>第五步：配置和启动</h3><ol><li><p><strong>复制配置文件</strong>：MySQL需要一个叫 <code>my.cnf</code>的配置文件。安装包里有现成的模板，我们复制一份。</p><pre><code>cp /usr/local/mysql/support-files/my-default.cnf /etc/my.cnf</code></pre></li></ol><pre><code>如果 `/etc`下已经有一个 `my.cnf`文件，它会问你是否覆盖，你根据情况选择。如果没有现成的，直接复制过去就行。
</code></pre><ol><li><p><strong>复制启动脚本</strong>：让系统知道怎么启动和停止MySQL服务。</p><pre><code>cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysqld</code></pre></li></ol><ol><li><p><strong>启动MySQL服务</strong>：</p><pre><code>service mysqld start</code></pre></li></ol><pre><code>如果看到 `Starting MySQL. SUCCESS!`就说明启动成功了。
</code></pre><h3>第六步：首次登录和修改密码</h3><ol><li><p><strong>用临时密码登录</strong>：现在可以用刚才记下的那个又长又丑的临时密码登录了。</p><pre><code>/usr/local/mysql/bin/mysql -u root -p</code></pre></li></ol><pre><code>输入密码时，屏幕不会显示星号，你正常输入后按回车就行。
</code></pre><ol><li><p><strong>赶紧修改root密码</strong>：一登录成功，马上做这件事，不然什么操作都不让你做。</p><pre><code>SET PASSWORD = PASSWORD('你的新密码');</code></pre></li></ol><pre><code>比如你想把密码改成 `123456`，就写 `SET PASSWORD = PASSWORD('123456');`。当然，实际使用时要用个复杂点的密码。
</code></pre><ol><li><p><strong>让外部机器也能连接（可选）</strong> ：如果你只是本机用，这步可以跳过。如果想让别的电脑也能连这个数据库，需要授权。</p><pre><code>GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY '你的新密码' WITH GRANT OPTION;
FLUSH PRIVILEGES;</code></pre></li></ol><ol><li><p><strong>退出</strong>：</p><pre><code>exit</code></pre></li></ol><p>​</p>]]></description></item><item>    <title><![CDATA[CentOS 7 安装 unzip-6.]]></title>    <link>https://segmentfault.com/a/1190000047402483</link>    <guid>https://segmentfault.com/a/1190000047402483</guid>    <pubDate>2025-11-16 10:02:07</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>​</p><p>本文手把手教你如何在 CentOS 7 系统上安装 <code>unzip-6.0-21.el7.x86_64.rpm</code>这个软件包。内容涵盖了直接用 yum 的省心方法和使用 rpm 命令的步骤，帮你快速搞定 unzip 解压工具的安装。</p><p><strong>安装包下载：</strong><a href="https://link.segmentfault.com/?enc=pJBTPt2vxdj3Oo2oFLdjhw%3D%3D.hEFbhgitS84LEEEO9kv9VGpTyFL7kl9DsuEVibCzuEUvL%2BG5Ub4UzrViRpgpbKHR" rel="nofollow" title="https://pan.quark.cn/s/1077b5d6b2aa" target="_blank">https://pan.quark.cn/s/1077b5d6b2aa</a></p><p><strong>情况一：如果你可以直接使用 yum 安装</strong></p><p>直接在终端里输入下面这行命令，yum 会自动处理依赖关系，最省心：</p><pre><code>sudo yum install unzip-6.0-21.el7.x86_64.rpm</code></pre><p><strong>情况二：如果你只有这个 rpm 文件，需要用 rpm 命令安装</strong></p><p>有时候用 rpm 安装可能会缺少依赖包，如果报错说缺少什么，你得先去找那个包。安装命令是：</p><pre><code>sudo rpm -ivh unzip-6.0-21.el7.x86_64.rpm</code></pre><p>这里的 <code>-ivh</code>参数意思是：安装、显示详细信息和进度。</p><p>​</p>]]></description></item><item>    <title><![CDATA[聚焦模拟架构精髓 星星上的柳树 ]]></title>    <link>https://segmentfault.com/a/1190000047402491</link>    <guid>https://segmentfault.com/a/1190000047402491</guid>    <pubDate>2025-11-16 10:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在高性能 IC 设计中，放大器电路的优化至关重要。本文围绕三类主流架构：全差分放大器（FDA）、Class-AB 音频放大器与Cascode 放大器，深入剖析设计思路、性能优势，以及如何在实际项目中落地实施。</p><p>1、全差分放大器（FDA）——精准噪声抑制利器<br/><img width="630" height="601" referrerpolicy="no-referrer" src="/img/bVdm3Ir" alt="" title=""/><br/>I. 优势：<br/>拒绝共模噪声、提升动态范围与精准度，是高精度高速 ADC 前端的理想选择。</p><p>II. 设计要点：<br/>利用双反馈控制两路输出，同时设定共模输出电压（VOCM），确保输出稳定。<br/>常见拓扑包括折叠结构与 Telescopic，以兼顾增益、带宽与电源压摆幅。</p><p>III. 实操小贴士：<br/>精细调节开环增益与带宽，使闭环增益稳定达标。<br/>搭建 CMFB（共模反馈）电路，确保输出共模不漂移。</p><p>2、Class-AB 音频放大器——失真微调与效率兼顾<br/>I. 优势：<br/>结合 Class-A 与 Class-B 优点，高线性、低失真，效率可达 ~75% <br/>Basic Electronics Tutorials。</p><p>II. 设计方法：<br/>通过微偏置技术让输出晶体管轻微导通，显著降低交越失真。<br/>配置 Darlington 级提升输入阻抗，固化偏置与热稳定性。</p><p>III. 实践建议：<br/>控制静态偏置电流，平衡热安全与音质表现。<br/>添加保护电路（过流、短路保护），提升系统可靠性。</p><p>3、Cascode 放大器——带宽与增益兼得<br/><img width="630" height="601" referrerpolicy="no-referrer" src="/img/bVdm3Ir" alt="" title="" loading="lazy"/><br/>I. 优势：<br/>串联共栅结构有效抑制 Miller 电容带来的增益衰减，提升频响和增益。</p><p>II. 设计技巧：<br/>利用电流镜提供稳定偏置，确保线性区域操作。<br/>适当增加晶体管通道长度（L）以提升输出阻抗与电压增益。</p><p>III. 调优建议：<br/>通过 AC 分析确保带宽与相位裕度满足设计需求。<br/>多次迭代设计，软硬件仿真协同保障性能指标。</p><p>4、为什么 EDA Academy 是你的最佳助力？<br/>想深入掌握上述前沿技术？欢迎访问 EDA Academy（www.eda-academy.com） ——IC 行业领先的专业网课平台！<br/>无论你是想提升模拟架构实战能力，或是系统学习 Cadence Virtuoso 工具链操作，EDA Academy 都有海量、专业、全面、最新的网课可供选择。<br/>作为用户，还能注册成为平台导师，分享技术经验，参与在线授课。<br/>更棒的是：注册邮箱即可免费订阅 newsletter，随时获取技术干货与行业动态。<br/>若你希望将优质课程推荐给他人，还可以加入平台销售联盟计划，凭推荐赚取 20%–50% 佣金。</p>]]></description></item><item>    <title><![CDATA[《Unity游戏多平台上架零驳回：应用商]]></title>    <link>https://segmentfault.com/a/1190000047402289</link>    <guid>https://segmentfault.com/a/1190000047402289</guid>    <pubDate>2025-11-15 23:03:14</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>Unity作为跨平台游戏开发的标杆引擎，凭借其可视化编辑、组件化架构与丰富的生态资源，让无数开发者得以快速将创意落地为可运行的游戏产品，但当开发阶段落幕，真正的考验往往始于上架环节。许多开发者在完成游戏核心功能后，便想当然地认为只需按照各应用商店的官方流程提交即可，却忽视了不同平台在底层架构、生态逻辑与审核标准上的深层差异，这些差异并非简单的流程差异，而是源于平台对用户体验、合规要求与商业利益的不同侧重。有些团队花费数月打磨的游戏，可能因为Unity引擎默认开启的某一敏感权限未做合理说明，或未针对特定机型优化渲染管线，导致审核反复驳回，不仅延误上线时间，还可能因多次驳回影响账号权重；而另一些开发者之所以能实现多平台顺畅上架，核心在于他们没有停留在规则表面，而是深入拆解了各商店的审核逻辑，将Unity的技术特性与平台要求进行精准匹配，在性能优化、合规适配、细节把控等方面提前布局，这背后是无数次试错、复盘后沉淀的实战经验，也是跨平台上架成功的关键所在。</p><p>深入剖析主流应用商店的规则体系，会发现其审核标准的差异本质上是平台生态定位的延伸，只有读懂这些差异背后的逻辑，才能避免陷入被动。海外市场中，Google Play以开放性著称，其审核更注重开发者资质的真实性与内容合规性，对技术适配的包容度相对较高，但对权限滥用、广告违规、隐私泄露等问题的检测极为严格，尤其是针对Unity游戏中常见的第三方SDK集成，会重点核查是否存在私自收集用户信息的行为；而App Store的封闭性使其对应用的品质有着近乎苛刻的要求，除了常规的合规检查，还会对Unity游戏的启动速度、内存占用、后台行为、机型兼容性进行全方位测试，甚至会针对不同iOS版本、不同机型的GPU特性进行专项验证，许多开发者遇到的“性能不佳”驳回，往往是因为游戏在老旧机型上的帧率低于30帧，或后台运行时未及时释放内存。国内主流应用商店则更强调与本土政策的契合，除了必须接入实名认证与防沉迷系统外，对游戏内容的价值观导向、画面表现、文字表述有着明确要求，同时不同厂商的商店还存在个性化的技术适配需求，比如华为应用市场对HarmonyOS的分布式能力适配、小米应用商店对推送服务的接入规范、OPPO应用商店对安装包体积的优化建议等。更重要的是，各商店的规则并非一成不变，会随着政策调整、技术升级与用户反馈持续迭代，开发者不能依赖过时的经验，而应建立动态跟踪机制，通过关注官方开发者社区、分析同类产品的上架动态、加入行业交流群等方式，及时捕捉规则变化，比如某商店近期加强了对广告展示时长的限制，或某平台新增了对隐私政策的具体要求，都需要第一时间调整适配策略，提前规避风险。</p><p>Unity游戏的技术适配是上架过程中最容易出现问题的环节，其核心在于解决引擎特性与平台、设备之间的兼容性矛盾，这也是最能体现开发者技术功底的部分。Unity的跨平台能力虽然强大，但不同平台的底层架构、硬件环境存在显著差异，容易导致游戏在部分设备上出现闪退、卡顿、画面异常等问题。在Android平台，由于机型碎片化严重，不同厂商的GPU型号、系统版本差异极大，Unity默认的shader可能在某些机型上出现编译失败，导致画面花屏或黑屏，这就需要开发者在开发阶段就针对主流GPU型号（如Adreno、Mali）进行专项测试，优化shader代码的兼容性，避免使用过于冷门的渲染特性，同时通过Unity的图形设置面板调整渲染管线，确保在不同配置的设备上都能稳定运行。在iOS平台，内存管理是重中之重，iOS系统对应用的内存占用有着严格限制，尤其是后台切换后，系统会优先回收后台应用的内存，Unity游戏如果没有做好资源加载与释放的优化，容易出现内存溢出导致的闪退，这就需要开发者合理设计资源池，采用异步加载、分场景卸载等策略，将首屏加载资源控制在合理范围，同时避免在后台运行时执行耗内存的操作。此外，权限申请也是技术适配的重要内容，iOS 13以上版本要求敏感权限（如位置、相册、麦克风）的申请必须在用户触发相关功能时进行，且说明文字必须清晰告知权限用途，否则会被驳回；Android平台则需要根据系统版本差异处理动态权限申请，Unity开发者需要利用引擎提供的权限管理接口，结合各平台的要求进行精准适配，比如非必要的权限直接移除，必要权限则在申请时提供明确的使用场景说明，避免因权限申请不当影响审核。</p><p>合规性是Unity游戏上架的“生命线”，一旦触碰红线，几乎没有申诉成功的可能，而合规性的要求远不止表面的内容审核，而是贯穿隐私保护、支付合规、内容安全等多个维度的系统工程。隐私政策是合规性的基础，也是最容易出现问题的环节，许多开发者图方便直接使用网上的模板，导致隐私政策内容与游戏实际收集的用户信息不一致，或未明确告知用户信息的收集目的、使用方式、存储期限与删除路径，这在各应用商店的审核中都会被直接驳回。正确的做法是，逐一梳理游戏中涉及的用户信息收集行为，包括Unity引擎自带的统计功能、第三方SDK（如支付、广告、统计SDK）收集的信息，明确每一项信息的收集目的，比如设备ID用于数据分析、位置信息用于提供本地化服务等，然后按照各商店的隐私政策模板要求，详细、准确地撰写相关内容，同时确保隐私政策的链接能够正常访问，在游戏启动时以弹窗形式提示用户阅读并同意，弹窗设计需清晰易懂，避免使用晦涩的法律术语。支付合规同样不容忽视，不同平台对虚拟货币交易有着严格的规定，App Store要求所有虚拟商品交易必须通过IAP支付，禁止使用第三方支付渠道，且需要准确设置商品价格、描述与分类，避免出现价格欺诈；Google Play允许部分地区使用第三方支付，但需要提前向平台报备并符合相关要求；国内应用商店则要求接入对应的支付SDK，同时遵守虚拟货币管理的相关政策，禁止出现诱导消费、强制付费等行为。内容安全方面，需要严格排查游戏中的画面、文字、音效等元素，避免出现暴力、色情、敏感政治内容，同时要符合平台的价值观导向，比如国内商店对游戏中的角色形象、剧情设定有着明确的正向要求，避免出现违背公序良俗的内容，这些细节都需要在上线前逐一核查，确保万无一失。</p><p>上架流程中的细节把控，往往是决定审核成败的关键，许多开发者因为忽视了这些看似琐碎的环节，导致上架过程一波三折，甚至功亏一篑。包体构建是上架的第一步，也是最容易出现问题的环节之一，不同应用商店对包体的格式、签名、大小有着明确要求。App Store要求包体为IPA格式，必须使用正确的证书签名，签名过程中如果出现证书过期、配置文件错误、Bundle ID不匹配等问题，会直接导致包体无法上传；Google Play则要求包体为Android App Bundle格式，支持动态交付，同时对包体的大小有明确限制，超过150MB的包体需要采用扩展文件的方式处理，且扩展文件的命名与格式必须符合平台要求。Unity开发者在构建包体时，需要针对不同商店的要求进行专项配置，比如关闭不必要的权限、移除冗余的资源与代码、优化资源压缩方式，同时确保包体的签名信息与开发者账号信息一致，避免因签名错误导致审核驳回。渠道包管理也是一个重要环节，当游戏需要上架多个应用商店时，需要为每个商店构建独立的渠道包，在包体中嵌入对应的渠道标识，方便后续的数据分析与运营管理，同时要注意避免渠道包之间的代码冲突，确保各渠道包的功能一致性。此外，上架过程中的信息填写也需要格外谨慎，应用名称、描述、截图、视频等内容不仅要符合各商店的格式要求，还要准确传达游戏的核心特色，避免使用夸大宣传、侵权等违规表述，截图和视频需要真实反映游戏的实际画面，不能存在虚假宣传的情况，比如截图中展示的功能在实际游戏中不存在，或使用与游戏无关的素材，这些都会导致审核驳回。</p><p>面对审核驳回，合理的应对策略与申诉技巧能够极大缩短上架周期，而盲目修改与反复提交只会让情况变得更糟。当收到审核驳回通知时，首先要做的是冷静分析，仔细研读驳回理由，准确把握问题的核心，避免误解审核标准。许多驳回理由看似模糊，比如App Store提到的“性能不佳”，实际上可能是游戏在某一特定机型上的启动时间超过了3秒，或存在内存泄漏问题；而Google Play提到的“内容违规”，可能是游戏内的某一画面、文字或音效不符合当地的文化习俗。此时，开发者需要结合自身的开发经验与对平台规则的理解，针对性地进行排查，必要时可以通过测试工具模拟审核环境，复现问题所在，比如使用Xcode的Instruments工具检测iOS平台的内存占用与启动时间，或使用Android Studio的Profiler工具分析Android平台的性能问题。在修改问题时，不能只做表面文章，而要深入挖掘问题的根源，比如因权限申请不当被驳回，不能简单地删除权限申请，而要判断该权限是否为游戏必需，如果必需则需要优化申请时机与说明文字，如果非必需则直接移除，避免因权限冗余导致的合规风险；如果因性能问题被驳回，则需要从资源优化、代码重构、渲染调整等多个维度进行优化，而不是单纯降低画面质量。</p>]]></description></item><item>    <title><![CDATA[《Unity游戏多平台上架风险管控：预研]]></title>    <link>https://segmentfault.com/a/1190000047402292</link>    <guid>https://segmentfault.com/a/1190000047402292</guid>    <pubDate>2025-11-15 23:02:20</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>许多开发者在创意落地阶段便急于推进功能开发，未提前对接各应用商店的技术基线与审核导向，导致后期适配时发现核心玩法与平台规则冲突，或引擎特性与硬件环境不兼容—比如某团队因未预研iOS的Metal渲染规范，开发后期才发现游戏光影效果无法适配新款机型，被迫重构渲染模块，不仅延误了三个月上线周期，还额外投入了大量重构成本；另一些项目则因第三方SDK未做合规预审核，上架时被检测出数据违规收集，直接驳回且影响账号信用，后续该账号提交的新应用审核周期从常规7天延长至15天，严重影响产品迭代节奏。更有甚者，因预研时未关注某平台对游戏安装包体积的限制，导致包体超出阈值无法上传，只能紧急删减核心资源，反而影响了游戏核心体验。真正顺畅的多平台上架，始于开发初期的精准预研，通过提前拆解平台要求、预判潜在风险、搭建适配框架，将问题解决在萌芽阶段，这也是无数实战案例中总结的核心逻辑，而非单纯依赖后期的规则套用或临时整改。</p><p>平台技术预研是上架成功的前提，其核心在于穿透官方文档的表层信息，挖掘平台底层的技术基线与审核导向差异，形成可落地的适配方案。海外市场中，Google Play的开放生态决定了其审核更侧重“合规底线”，技术上允许一定程度的兼容性波动，但对数据隐私的管控极为严格，预研阶段需重点核查Unity项目中所有第三方SDK的数据收集范围，比如某广告SDK默认开启的设备IMEI收集功能，若未在隐私政策中明确说明，便会直接触发审核驳回；而App Store的闭环生态对“技术品质”要求极高，预研时不仅要确认游戏适配的iOS版本区间（需覆盖近三年主流版本），还需针对不同机型的硬件基线（如老旧机型的内存上限、新款机型的屏幕刷新率）制定适配标准，许多团队忽略了对iPhone SE等低配置机型的预研，导致上架后出现帧率过低的投诉，进而被要求强制优化后重新提交。国内主流应用商店的预研核心则是“政策适配”与“厂商特性”，除了提前对接最新的防沉迷系统接口、实名认证标准，还需关注各厂商的个性化要求—比如OPPO应用商店对后台保活的严格限制，禁止非必要应用长期占用后台资源；小米应用商店对推送权限的分级管理，需根据用户活跃度调整推送频率；荣耀应用商店对HarmonyOS分布式能力的适配建议，支持多设备协同的应用可获得更高推荐权重。更关键的是，预研需形成动态跟踪机制，通过订阅平台技术白皮书、参与厂商开发者沙龙、分析同类产品的上架变动，捕捉规则更新信号，比如某平台新增“未成年人付费限额”政策，或某商店强化对游戏安装包签名的校验标准，都需在预研阶段及时纳入适配框架，建立规则更新台账，明确调整节点与责任人，从源头规避方向性错误。</p><p>Unity引擎的跨平台优化，需以“预研结论”为核心搭建适配框架，而非依赖引擎默认设置，这是解决兼容性问题的关键，也是降低后期整改成本的核心手段。针对Android平台的机型碎片化，预研阶段需通过行业数据分析工具明确目标市场的GPU型号分布（如东南亚市场Mali GPU占比超70%），据此选择适配的渲染管线—比如针对中低端机型的Mali GPU，优先使用URP管线并关闭体积光、屏幕空间反射等复杂光影效果，同时优化Shader变体数量，通过Unity的Shader Variant Collection工具剔除无用变体，避免因编译冗余导致加载卡顿；对于Adreno GPU占比高的欧美市场，则可适当开启高分辨率纹理与后处理效果，平衡性能与视觉体验。此外，Android平台还需适配不同CPU架构（ARMv7、ARM64、x86），预研时需明确目标机型的架构分布，避免因未适配某架构导致部分设备无法安装。iOS平台的预研重点在于“性能阈值控制”，需提前通过Xcode的Instruments工具，测试不同机型的性能极限，确定内存占用上限（如iPhone 12以下机型内存控制在2GB内，iPhone 13及以上可放宽至3GB），开发阶段便采用“资源分级加载”策略：核心场景资源（如主角模型、核心玩法地图）优先加载，非关键资源（如远景装饰、次要NPC模型）延迟加载，后台切换时自动释放闲置资源（如缓存的纹理、未使用的动画片段），从根本上避免内存溢出。同时，需适配iOS的动态刷新率功能，在高刷屏机型上实现60帧稳定运行，在老旧机型上自动降为30帧，确保流畅度。此外，预研阶段还需明确各平台的权限基线，对于非核心功能所需的敏感权限（如位置、麦克风），直接在项目设置中关闭，避免后期因权限冗余触发审核预警；必要权限则提前设计合理的申请场景，比如拍照功能仅在用户触发“自定义头像”操作时才发起权限申请，且说明文字需通俗告知用途（如“允许访问相机以拍摄自定义头像”），杜绝模糊表述（如“需要访问相机以提升体验”）。</p><p>合规性风险的管控，核心在于“前置梳理”与“全流程校验”，而非上架前的临时补救，一旦出现合规问题，不仅会导致审核驳回，还可能影响品牌声誉。数据合规是预研阶段的重点，需逐一梳理Unity项目中的所有数据收集行为：引擎自带的设备信息统计（如设备型号、系统版本）、第三方支付SDK的订单数据、广告SDK的用户画像分析、统计SDK的行为数据，每一项都需明确“收集必要性”与“使用边界”—比如设备型号仅用于兼容性分析，不得用于用户精准画像；游戏进度数据仅本地存储或加密云端同步，不得泄露给第三方。同时，需遵守数据本地化要求，国内平台明确规定用户个人数据需存储在境内服务器，预研时需提前对接合规的云服务厂商，避免因服务器地址问题被驳回。基于梳理结果，提前撰写符合各平台要求的隐私政策，明确数据收集范围、存储期限、删除方式，且必须通过第三方合规工具检测（如工信部指定的隐私政策检测平台），确保无模糊表述或违规条款，政策链接需支持HTTPS协议，可正常访问。支付合规的预研则需对接各平台的支付规范，比如App Store的IAP支付需提前在开发者后台创建商品ID，确保游戏内商品定价、描述与后台一致，禁止出现“终身免费”“永久解锁”等易引发误解的表述；国内平台需提前完成支付SDK的接入测试，确保支付流程闭环（从充值到道具到账无卡顿），同时设置未成年人付费限额（如单次充值不超过50元，每月累计不超过200元），符合政策要求。内容合规方面，预研阶段需建立内容审核清单，明确禁止出现的元素（如暴力场景、敏感符号、宗教相关内容），同时结合目标市场的文化习俗调整内容—比如海外版本避免使用红色作为警示色（部分国家红色代表吉祥），国内版本确保角色形象积极向上、剧情设定传递正能量，开发过程中每一个版本都需同步进行内容校验，避免后期大面积修改，比如某游戏因角色服装设计过于暴露，上架前需重新绘制所有角色立绘，延误了上线时间。</p><p>上架全流程的标准化管控，是降低失误率的关键，需将预研结论转化为可执行的操作规范，覆盖包体构建、测试、信息填写、审核校验等各个环节。包体构建阶段，需根据预研确定的平台要求搭建标准化流程：Android平台需针对不同商店构建独立的渠道包，通过Unity的Build Settings工具嵌入专属渠道标识（如应用宝渠道标识为“yyb”，华为渠道标识为“hw”），同时按照Google Play的要求优化App Bundle格式，将纹理、音效等大体积资源拆分至扩展文件，控制主包体积在150MB内，避免因包体过大影响下载转化率；iOS平台则需严格按照证书配置规范，在Xcode中选择正确的开发证书与发布证书，确保Bundle ID、签名证书、配置文件完全匹配，避免因签名错误导致包体无法上传至App Store Connect，之前有团队因配置文件过期未及时更新，导致包体上传失败，延误了三天审核时间。测试环节需基于预研的机型矩阵，搭建覆盖高中低端设备的测试体系，除了测试核心玩法的兼容性，还需模拟审核场景—比如关闭网络测试离线功能是否正常、切换后台测试恢复稳定性、使用未成年人账号测试防沉迷功能是否生效、模拟弱网环境测试支付流程是否顺畅，每一项测试都需形成书面报告，记录测试机型、测试结果、问题截图，确保无遗漏问题。上架信息填写同样需遵循标准化规范，应用名称需简洁且符合平台命名规则（如iOS禁止使用特殊符号，Android禁止包含竞品名称），描述需准确提炼核心玩法，避免使用“最佳”“顶级”“第一”等夸大词汇；截图与宣传视频需采用实测画面，清晰展示游戏核心机制（如解谜游戏展示关键解谜环节，动作游戏展示战斗玩法），不得添加与实际功能不符的特效或素材，同时确保画面无违规元素，截图尺寸需符合平台要求（如App Store截图需适配不同屏幕尺寸，Android各商店尺寸要求略有差异）。此外，需建立包体与信息的双重审核机制，上架前由技术人员校验包体签名、渠道标识、权限设置，运营人员校验上架信息的准确性与合规性，合规人员再次核查隐私政策、支付流程、内容导向，确认所有环节符合预研要求后再提交，避免因单人操作失误导致驳回。</p><p>风险预判与驳回快速响应机制，是应对突发情况的保障，需基于预研数据搭建问题预案库，确保遇到驳回时能快速响应、高效整改。预研阶段需收集同类产品的常见驳回原因，分类整理为“技术问题”“合规问题”“流程问题”三大类，每一类下再细分具体场景—比如技术类的“闪退驳回”“帧率过低驳回”“兼容性问题驳回”，合规类的“隐私政策不合规驳回”“支付渠道违规驳回”“内容导向问题驳回”，流程类的“包体格式错误驳回”“上架信息填写违规驳回”，针对每一种场景制定详细的应对方案，明确排查步骤、整改方法、测试标准，比如“隐私政策不合规驳回”预案明确：第一步排查是否存在数据收集范围未说明，第二步补充缺失的条款，第三步通过第三方工具检测，第四步进行真机测试确保政策链接可访问。当收到审核驳回通知时，首先对照预案库快速定位问题类型，避免盲目排查；若属于未预判的新问题，则启动紧急响应流程，24小时内组织技术、运营、合规人员召开专项会议，共同分析驳回理由，结合预研阶段的平台规则认知，制定整改方案，明确责任人与整改时限。整改过程中需遵循“最小改动”原则，避免因修改引发新的问题，比如因某一功能违规被驳回，仅关闭该功能或优化该功能的表现形式，而非重构整个模块；整改完成后需进行专项测试，比如修改隐私政策后，测试政策链接是否正常、弹窗提示是否清晰，确保问题彻底解决。</p>]]></description></item><item>    <title><![CDATA[openEuler 24.03 LTS ]]></title>    <link>https://segmentfault.com/a/1190000047402313</link>    <guid>https://segmentfault.com/a/1190000047402313</guid>    <pubDate>2025-11-15 23:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>11月15日，openEuler Summit 2025在北京顺利召开。会上，开源欧拉社区首次发布支持超节点的操作系统版本 openEuler 24.03 LTS SP3，发布 Intelligence BooM全栈开源AI解决方案全新版本“2511 敲鱼面”，联合多家企业和单位共同发布全球首个 Arm CCA机密计算解决方案。华为积极响应，华为ICT战略与业务发展部总裁彭红华更在致辞中倡议社区共筑面向智能时代的超节点操作系统，共建AI与操作系统的融合能力，并宣布华为将贡献超节点操作系统插件及 GMEM、ModelFS 等关键 AI 技术，以提升 openEuler 在 AI 时代的竞争力。</p><p><img width="723" height="458" referrerpolicy="no-referrer" src="/img/bVdm3Fv" alt="" title=""/></p><p>此外，社区邀请到 AMD、Arm、Linaro 等多位全球企业和开源组织的代表分享与openEuler 的合作，加速全球化。AMD、浪潮云和神州数码成为社区捐赠单位，openEuler 学术与教育委员会、异构融合系统软件产学研联盟正式成立，共同推动人才培养和基础软件创新。</p><h3>核心技术突破，引领智能时代操作系统</h3><p>AI 创新业务的全面迸发，正推动核心诉求从单机性能转向超节点异构协同，超节点决定算力上限，而操作系统则掌控效率天花板。开放原子开源欧拉技术委员会主席胡欣蔚表示，openEuler 全球首个超节点的操作系统（openEuler 24.03 LTS SP3）正式发布。该版本对 openEuler 异构融合系统升级，加速释放超节点异构算力。</p><p><img width="723" height="487" referrerpolicy="no-referrer" src="/img/bVdm3Fw" alt="" title="" loading="lazy"/></p><p>面向数据中心场景，开源欧拉社区提供 Intelligence BooM 全栈开源AI解决方案。方案由 openEuler 联合高校、企业及各大社区打造，旨在建立开源的AI生态、赋能行业转型和推动产业协同，让企业级AI触手可及。继 2025 年 7 月发布首个版本“2507 烩面”之后，这次发布全新版本“2511 敲鱼面”。该版本以“低成本、高效率、易落地”为核心，支持 50+ 模型微调，通过异构协同推理效率提升 10%～30%，具备面向 Agentic AI 智能体生态快速适配能力，打造真正原生智能的操作系统。</p><p>在 AI 高速发展的同时，安全挑战也不容忽视。会上，开源欧拉社区联合 Arm、Linaro、百度智能云、麒麟软件、麒麟信安、统信软件、上海交通大学、华中科技大学和全球计算联盟（GCC）等共同发布全球首个 Arm CCA 机密计算解决方案。该解决方案基于 Arm CCA标准实现完整机密虚拟机支持，使 openEuler 成为首个原生支持 CCA 机密虚机的开源操作系统。通过可信I/O通道，将性能损耗控制在5%以内，既保留 openEuler 丰富的软件生态，又无缝融合机密计算生态。</p><p>Linaro CTO Grant Likely 表示，Linaro 长期支持 Arm 生态的发展，2021 年加入openEuler 社区，在长期的合作中，把自己积累的开源经验贡献到 openEuler Arm 架构上，是 openEuler Arm CCA 机密计算解决方案的核心贡献者。</p><p><img width="723" height="488" referrerpolicy="no-referrer" src="/img/bVdm3Fx" alt="" title="" loading="lazy"/></p><h3>与国际企业和组织紧密合作，加速全球化</h3><p>开源六年以来，开源欧拉社区发展迅速，截至目前，社区成员企业已超 2100 家，贡献者突破 2.3 万人，社区用户超过 550 万，兼容 ISV 伙伴超 4000 家，商业 OSV 达到25家，全球开发者 PR 数达 24 万，这些数字充分证明了 openEuler 已成为中国基础软件开源社区的领军力量。</p><p>开放原子开源欧拉委员会主席熊伟指出，社区的发展离不开伙伴的支持。今年，社区迎来新增捐赠单位 AMD、浪潮云和神州数码。至此，英特尔、Arm、AMD 三大芯片企业均成为社区捐赠单位。在全球开源组织协作层面，开源欧拉社区近期与 Zephyr 嵌入式技术基金会、Linux Foundation AI&amp;Data 基金会达成深度技术合作。目前，开源欧拉社区累计与15家全球开源组织在AI、云、大数据、HPC、嵌入式等领域建立紧密合作关系。</p><p>AMD全球副总裁、大中华区大中华区及企业事业部销售总经理唐晓蕾表示，AMD 一直秉承对中国市场开放的态度，并携手 openEuler 共建 AI 产业生态。在服务器处理器方面，已经完成了相关产品和 openEuler 的所有适配，后续将在云计算、机密计算、AI 等方面持续深化与开源欧拉社区合作。</p><p><img width="723" height="487" referrerpolicy="no-referrer" src="/img/bVdm3Fy" alt="" title="" loading="lazy"/></p><p>Arm Fellow、软件社区高级总监、PyTorch 基金会董事的 Andrew Wafaa 表示，Arm公司在提升技术能力的同时，确保相关技术能够兼容开源欧拉社区，持续深耕AI的产业共建。</p><p><img width="723" height="487" referrerpolicy="no-referrer" src="/img/bVdm3Fz" alt="" title="" loading="lazy"/></p><p>人才是每个组织的核心力量。为加强社区与学术、教育界的深度联结，推动系统软件领域人才培养与生态建设，会上，openEuler社区学术与教育委员会正式成立。该委员会将统筹推进学术生态构建、人才激励体系设计及相关标准制定工作，为社区发展提供可持续的智力与人才支撑。</p><p><img width="723" height="488" referrerpolicy="no-referrer" src="/img/bVdm3FA" alt="" title="" loading="lazy"/></p><p>在 openEuler 社区学术与教育委员会的主导下，异构融合系统软件产学研联盟同步成立。算力基础设施向超节点演进将驱动操作系统技术创新，面对当前异构硬件多样化与高速互联技术快速演进所带来的生态碎片化挑战，亟需构建统一的异构融合计算架构与软件生态，凝聚产业共识，把握智能时代的发展机遇。</p><p><img width="723" height="487" referrerpolicy="no-referrer" src="/img/bVdm3FG" alt="" title="" loading="lazy"/></p><p>开发者为开源欧拉社区的持续技术创新与生态繁荣注入智慧和力量。会上，颁发 openEuler 2025 年度突出贡献单位、openEuler 2025 年度项目之星及 openEuler 2025 年度贡献之星。从产学研协同的深化，到核心技术突破，openEuler 正稳步向前，为智能时代构筑算力基础设施的核心基石。</p>]]></description></item><item>    <title><![CDATA[Python 开发必备：tempfile]]></title>    <link>https://segmentfault.com/a/1190000047402180</link>    <guid>https://segmentfault.com/a/1190000047402180</guid>    <pubDate>2025-11-15 22:02:07</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>处理大数据集或者生成报告、创建中间文件的时候，很多文件其实根本不需要永久保存。这时候可以用临时目录来解决这个问题。Python 标准库里的</p><pre><code>tempfile</code></pre><p>模块能创建用完就自动消失的临时文件和目录，省去手动清理的麻烦。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047402182" alt="" title=""/><br/>临时目录就是个生命周期很短的文件夹，专门用来存放那些不需要长期保留的数据。用完之后连同里面的内容一起删掉，文件系统保持干净。</p><p>Python 的</p><pre><code>tempfile</code></pre><p>模块提供了一套完整的解决方案，这些临时文件和目录在不需要的时候会自动清理掉。</p><h2>为什么要用临时目录</h2><p>临时目录在实际开发中有几个明显的好处：</p><p>自动清理机制省去了手动删除的步骤，每个临时目录都有唯一标识避免文件名冲突。系统会自动选择安全的存储位置，Unix 系统用</p><pre><code>/tmp</code></pre><p>，Windows 用</p><pre><code>%TEMP%</code></pre><p>。多线程和多进程环境下也能稳定工作，特别适合测试场景和需要中间存储的情况。</p><h2>什么场景下需要临时目录</h2><p>需要一个临时空间来存放中间计算结果或临时文件。写单元测试的时候模拟文件操作，完了自动清理。下载或解压的数据不需要长期保存。处理用户上传的文件，在保存最终结果之前需要一个缓冲区。构建自动化流程时，要确保不留下任何痕迹。</p><h2>tempfile 模块基础用法</h2><pre><code> import tempfile  
import os  
# Create a temporary directory
with tempfile.TemporaryDirectory() as temp_dir:  
    print(f"Temporary directory created at: {temp_dir}")  
    # Create a temporary file inside the directory
    file_path = os.path.join(temp_dir, "sample.txt")  
    with open(file_path, "w") as f:  
        f.write("Hello, Temporary World!")  
    # Read back the file
    with open(file_path, "r") as f:  
        print(f.read())  
# At this point, the directory and its contents are deleted automatically
 print("Temporary directory cleaned up automatically.")</code></pre><p>输出结果：</p><pre><code> Temporary directory created at: /tmp/tmpabcd1234  
 Hello, Temporary World!  
 Temporary directory cleaned up automatically.</code></pre><p>关键在于</p><pre><code>with</code></pre><p>语句块结束时，目录和文件会自动删除，不需要手动调用</p><pre><code>os.remove()</code></pre><p>或</p><pre><code>shutil.rmtree()</code></pre><p>。</p><h2>手动控制临时目录的生命周期</h2><p>有时候需要更精细的控制，比如临时目录的生命周期超出单个函数作用域，这时候可以用</p><pre><code>tempfile.mkdtemp()</code></pre><p>：</p><pre><code> import tempfile  
import shutil  
import os  
# Create a temporary directory manually
temp_dir = tempfile.mkdtemp()  
print(f"Created temporary directory: {temp_dir}")  
# Work inside it
file_path = os.path.join(temp_dir, "example.txt")  
with open(file_path, "w") as f:  
    f.write("Manual cleanup required!")  
print("Files inside temp dir:", os.listdir(temp_dir))  
# Clean up manually when done
shutil.rmtree(temp_dir)  
 print("Temporary directory removed.")</code></pre><p>这种方式下需要自己负责清理工作，用完记得删除。</p><h2>自定义临时目录的命名和位置</h2><pre><code>tempfile</code></pre><p>支持给临时目录添加前缀和后缀，方便调试时识别：</p><pre><code> import tempfile  
 # Create with custom prefix and suffix
 with tempfile.TemporaryDirectory(prefix="myapp_", suffix="_data") as temp_dir:  
     print(f"Created: {temp_dir}")</code></pre><p>输出类似这样：</p><pre><code> Created: /tmp/myapp_abcd1234_data</code></pre><p>还可以指定父目录：</p><pre><code> with tempfile.TemporaryDirectory(dir="/path/to/parent") as temp_dir:  
     print(temp_dir)</code></pre><p>当系统默认的临时目录权限不够或者空间不足时，这个功能就派上用场了。</p><h2>实战案例：安全处理 ZIP 文件</h2><p>下载大型 ZIP 文件后临时解压处理，处理完就清理掉：</p><pre><code> import tempfile  
import zipfile  
def extract_and_process(zip_path):  
    with tempfile.TemporaryDirectory() as tmp_dir:  
        print(f"Extracting to {tmp_dir}")  
        with zipfile.ZipFile(zip_path, "r") as zip_ref:  
            zip_ref.extractall(tmp_dir)  
        # Process extracted files
        for file in os.listdir(tmp_dir):  
             print("Processing:", file)</code></pre><p>整个流程结束后，解压的文件夹自动删除，磁盘不会留下任何垃圾文件。</p><h2>实战案例：动态生成报告</h2><p>应用程序按需生成报告文件（PDF、CSV 之类），不需要永久存储：</p><pre><code> import tempfile  
import csv  
import os  
def generate_temp_report(data):  
    with tempfile.TemporaryDirectory() as tmp_dir:  
        file_path = os.path.join(tmp_dir, "report.csv")  
        with open(file_path, "w", newline="") as csvfile:  
            writer = csv.writer(csvfile)  
            writer.writerow(["Name", "Age"])  
            writer.writerows(data)  
        print(f"Report generated at: {file_path}")  
         # Here you can upload it, email it, or read the content directly</code></pre><p>生成的报告可以直接上传、发邮件或者读取内容，不会在本地留存。</p><h2>实战案例：单元测试中的文件操作</h2><p>写单元测试时在项目目录下创建很多文件夹显然不是好主意，所以临时目录完美解决这个问题：</p><pre><code> import tempfile  
import unittest  
import os  
class TestFileOperations(unittest.TestCase):  
    def test_temp_directory(self):  
        with tempfile.TemporaryDirectory() as temp_dir:  
            file_path = os.path.join(temp_dir, "test.txt")  
            with open(file_path, "w") as f:  
                f.write("test data")  
              
             self.assertTrue(os.path.exists(file_path))</code></pre><p>每个测试用例都在独立的临时环境中运行，互不干扰，也不需要手动清理。</p><h2>嵌套临时目录</h2><p>复杂场景下可能需要嵌套的临时目录结构：</p><pre><code> import tempfile  
 import os  
 with tempfile.TemporaryDirectory() as root_dir:  
     print(f"Root: {root_dir}")  
     sub_dir = tempfile.mkdtemp(dir=root_dir)  
     print(f"Nested: {sub_dir}")</code></pre><p>多阶段数据处理流程中，每个阶段可以有自己的独立沙箱环境。</p><h2>使用临时目录的几个注意事项</h2><p>始终使用上下文管理器</p><pre><code>with tempfile.TemporaryDirectory()</code></pre><p>来确保自动清理。不要硬编码</p><pre><code>/tmp</code></pre><p>路径，用</p><pre><code>tempfile.gettempdir()</code></pre><p>获取系统临时目录。如果用了</p><pre><code>mkdtemp()</code></pre><p>就必须手动调用</p><pre><code>shutil.rmtree()</code></pre><p>清理。给临时目录加上有意义的前缀方便调试时快速定位。临时数据随时可能被系统清理，不要在里面存放需要持久化的信息。</p><h2>几个实用技巧</h2><p>获取系统临时目录路径：</p><pre><code> importtempfile
 print(tempfile.gettempdir())</code></pre><p>生成唯一文件名（但不创建文件）：</p><pre><code> tempfile.mktemp()</code></pre><p>不过要注意，直接用</p><pre><code>mktemp()</code></pre><p>有安全风险，生产环境建议用</p><pre><code>NamedTemporaryFile</code></pre><p>或</p><pre><code>TemporaryDirectory</code></pre><p>。</p><h2>生产环境中的实际应用</h2><p>下面这段代码展示了如何在 PDF 处理项目中使用临时目录。整个流程包括 PDF 转图片、图片转 Markdown、最后合并成完整文档：</p><pre><code> import os  
import io  
import shutil  
import tempfile  
from pathlib import Path  
from typing import Iterable, Optional, Callable, Tuple  

# Requires: pip install pymupdf pillow  
import fitz  # PyMuPDF  
 from PIL import Image  </code></pre><pre><code> def process_pdfs_to_markdown(  
    pdf_paths: Iterable[str | os.PathLike],  
    output_dir: str | os.PathLike,  
    *,  
    page_image_dpi: int = 200,  
    image_format: str = "PNG",  
    llm_page_markdown_fn: Optional[Callable[[Path], str]] = None,  
) -&gt; Tuple[list[Path], list[Path]]:  
    """  
    Convert each input PDF into page images using a temporary workspace, run an LLM on each page image to get  
    Markdown, save one MD per page (still in a temp workspace), then merge the per-PDF Markdown into a single  
    non-temporary Markdown file per PDF in `output_dir`.  
      
    Non-temp file handling is kept simple (write final merged .md into `output_dir`), while the heavy lifting  
    uses temp directories that auto-clean on success or error.  
      
    Parameters  
    ----------  
    pdf_paths : Iterable[str | PathLike]  
        Paths to PDF files to process.  
    output_dir : str | PathLike  
        Directory where FINAL merged Markdown files (non-temp) will be written.  
    page_image_dpi : int, optional  
        Rendering resolution for converting PDF pages to images. Higher DPI → sharper (default 200).  
    image_format : str, optional  
        Image format for page renders (e.g., "PNG", "JPEG"). Default "PNG".  
    llm_page_markdown_fn : Callable[[Path], str], optional  
        A callable that takes a Path to a page image and returns Markdown text for that page.  
        If not provided, a placeholder stub will be used.  
      
    Returns  
    -------  
    Tuple[list[Path], list[Path]]  
        A tuple (final_markdown_files, per_page_markdown_files_flattened)  
        - final_markdown_files: list of merged Markdown file paths written in output_dir (non-temp)  
        - per_page_markdown_files_flattened: flattened list of all per-page MD files (in temp, ephemeral)  
          (Returned for inspection/logging; these will be deleted when temp dir goes away.)  
      
    Notes  
    -----  
    - Uses a single top-level TemporaryDirectory for the whole batch to keep structure neat.  
    - For each PDF, creates `/tmp/.../&lt;pdf_stem&gt;/images` and `/tmp/.../&lt;pdf_stem&gt;/md`.  
    - Each page is rendered to an image file named `page-&lt;index&gt;.&lt;ext&gt;`.  
    - Each page's Markdown is saved to `page-&lt;index&gt;.md`.  
    - Finally, merges all page MDs for that PDF into `&lt;output_dir&gt;/&lt;pdf_stem&gt;.md` (non-temp).  
    - Replace `llm_stub_markdown_from_image` with your actual LLM call (OpenAI, local VLM, etc.).  
      
    Pseudocode hint for real LLM integration  
    ----------------------------------------  
    def llm_page_markdown_fn(img_path: Path) -&gt; str:  
        # pseudo:  
        # bytes = img_path.read_bytes()  
        # resp = my_llm_client.vision_to_md(image=bytes, system_prompt="Extract content as Markdown.")  
        # return resp.markdown  
        pass  
    """  
    output_dir = Path(output_dir)  
    output_dir.mkdir(parents=True, exist_ok=True)  

    # --- Local helper: default LLM stub (replace this with your LLM call) ---  
    def llm_stub_markdown_from_image(img_path: Path) -&gt; str:  
        # This is a placeholder. Swap with a real LLM/VLM call to convert the image to Markdown.  
        # You can pass the image bytes and ask the model to produce clean Markdown with headings, tables, lists, etc.  
        return f"# Page extracted (stub)\n\n_Image: {img_path.name}_\n\n&gt; Replace this with real LLM Markdown output."  

    # Choose the LLM function (user-supplied or stub)  
    llm_to_md = llm_page_markdown_fn or llm_stub_markdown_from_image  

    final_markdown_files: list[Path] = []  
    per_page_markdown_files_flattened: list[Path] = []  

    # Top-level temp root for the entire run  
    with tempfile.TemporaryDirectory(prefix="pdf2img-md_") as temp_root:  
        temp_root = Path(temp_root)  

        for pdf_path in map(Path, pdf_paths):  
            if not pdf_path.exists() or pdf_path.suffix.lower() != ".pdf":  
                # Skip invalid entries gracefully; alternatively raise ValueError  
                continue  

            pdf_stem = pdf_path.stem  
            pdf_temp_dir = temp_root / pdf_stem  
            images_dir = pdf_temp_dir / "images"  
            md_dir = pdf_temp_dir / "md"  
            images_dir.mkdir(parents=True, exist_ok=True)  
            md_dir.mkdir(parents=True, exist_ok=True)  

            # --- 1) Render pages to images in temp ---  
            # Using PyMuPDF: fast, no external poppler dependency  
            pages_rendered: list[Path] = []  
            with fitz.open(pdf_path) as doc:  
                # scale based on DPI (PyMuPDF normally uses zoom factors; convert DPI to zoom)  
                # Base DPI ~72; zoom = target_dpi / 72  
                zoom = page_image_dpi / 72.0  
                mat = fitz.Matrix(zoom, zoom)  

                for page_index in range(doc.page_count):  
                    page = doc.load_page(page_index)  
                    pix = page.get_pixmap(matrix=mat, alpha=False)  # no alpha for standard formats  
                    img_bytes = pix.tobytes(output=image_format.lower())  

                    img_name = f"page-{page_index + 1}.{image_format.lower()}"  
                    img_path = images_dir / img_name  

                    # Save via PIL to ensure consistent headers/metadata if needed  
                    with Image.open(io.BytesIO(img_bytes)) as im:  
                        im.save(img_path, format=image_format)  

                    pages_rendered.append(img_path)  

            # --- 2) For each page image, call LLM to get Markdown; save per-page MD in temp ---  
            page_md_files: list[Path] = []  
            for img_path in pages_rendered:  
                md_text = llm_to_md(img_path)  # &lt;-- your real LLM call here  
                md_path = md_dir / (img_path.stem + ".md")  
                md_path.write_text(md_text, encoding="utf-8")  
                page_md_files.append(md_path)  
                per_page_markdown_files_flattened.append(md_path)  

            # --- 3) Merge per-page MD into a FINAL non-temp Markdown file (one per PDF) ---  
            final_md_path = output_dir / f"{pdf_stem}.md"  
            # If you want sophisticated merging rules, implement here (e.g., front matter, TOC).  
            # Pseudocode for richer post-processing could be:  
            #   combined = render_front_matter(pdf_path) + "\n" + concatenate_markdown(page_md_files) + "\n" + add_toc()  
            #   final_md_path.write_text(combined, encoding="utf-8")  
            with final_md_path.open("w", encoding="utf-8") as fout:  
                fout.write(f"&lt;!-- Source PDF: {pdf_path.name} --&gt;\n")  
                fout.write(f"# {pdf_stem}\n\n")  
                for i, md_file in enumerate(sorted(page_md_files, key=lambda p: p.name), start=1):  
                    fout.write(f"\n\n---\n\n&lt;!-- Page {i} --&gt;\n\n")  
                    fout.write(md_file.read_text(encoding="utf-8"))  

            final_markdown_files.append(final_md_path)  

        # NOTE:  
        # All temp content (images &amp; per-page MDs) is automatically cleaned up on exit.  

     return final_markdown_files, per_page_markdown_files_flattened</code></pre><p>这段代码的亮点在于所有中间文件（图片、单页 Markdown）都存放在临时目录里，处理完自动清理，只保留最终合并后的文档。整个流程非常干净，不会在磁盘上留下任何垃圾文件。</p><p>实际使用时把</p><pre><code>llm_stub_markdown_from_image</code></pre><p>替换成真正的 LLM 调用（比如 OpenAI 的 Vision API 或者本地视觉模型），就能实现完整的 PDF 文档处理流程。</p><h2>总结</h2><p>临时目录在 Python 开发中确实是个实用的工具，文件处理更高效也更安全。不管是处理用户上传、写单元测试还是构建数据流水线，</p><pre><code>tempfile.TemporaryDirectory()</code></pre><p>都能让代码更简洁、更可靠。掌握它的用法能省不少麻烦，代码质量也能上个台阶。</p><p><a href="https://link.segmentfault.com/?enc=c0vHXP8END5Ss%2FinLxgoyg%3D%3D.o92Vv2F0nY5kWeRjlwtRjcURA2Xga2dSGhLc09TViXLUfYdkc4kVorgeGYK3AH8eShRfrISL5iWfsfoVK1tZ5Q%3D%3D" rel="nofollow" target="_blank">https://avoid.overfit.cn/post/ee53c91b40f844d5b6faed7a637515ca</a></p><p>作者 Sravanth</p>]]></description></item><item>    <title><![CDATA[银行中外汇的由来（金融产品经理必读） 东]]></title>    <link>https://segmentfault.com/a/1190000047402192</link>    <guid>https://segmentfault.com/a/1190000047402192</guid>    <pubDate>2025-11-15 22:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>经常听到我们国家有多少多少亿美元的外汇储备，是否有这样的疑问，外汇储备是什么，它又是怎么来的，银行又是如何处理外汇储备的，今天就闲聊一下。</p><h2>外汇管理</h2><h4>常见概念</h4><p><strong>现汇：</strong> 通俗来讲，就是<strong>在银行账户里</strong>可以自由买卖、自由兑换成其他国家货币，还能方便地用于国际结算的外汇资金。</p><p><strong>现钞：</strong> 现钞就是我们日常生活中能实实在在拿到手、看得见摸得着的外国货币纸币和硬币。比如你去银行用人民币换了一些美元纸币，并且拿回家，这时候它们就是现钞。</p><p><strong>存放同业：</strong> 是指商业银行等金融机构将资金存放在其他银行或非银行金融机构的行为，从存放资金的金融机构角度来看，这笔资金是其资产，因为它把钱存到其他机构，拥有对这笔资金的所有权和支配权，只是暂时存放在别处。</p><p><strong>同业存放：</strong> 对于接受同业存放的金融机构来说，其目的主要是增加资金来源，充实自身的资金实力，以便更好地开展贷款、投资等业务。同时，通过吸收同业存放资金，也可以加强与其他金融机构的业务联系，提升在金融市场中的影响力。</p><h4>外汇管制</h4><p>我国禁止外汇在国内流通，为什么要进行外汇管制呢？因为管制可以<strong>维护国际收支平衡、稳定人民币汇率、保障国家金融安全、促进经济结构调整和产业发展</strong>。</p><h5>外汇管制有哪些手段？</h5><p><strong>不能以外汇标价：</strong> 比如你开个超市，你不能标1瓶酱油1美元，只能标价xx元。<br/><strong>禁止用于结算：</strong> 你购进一批货物，你手里没有人民币，但是你手里有美元，但是你不能直接把美元转给他。<br/><strong>企业使用外汇控制：</strong> 企业如需使用外汇（超过了规定的自有额度）时，需要向外管局进行申请。<br/><strong>人出入境控制：</strong> 个人出入境，也要控制外币额度，限制金额，并且要申报。</p><p>上述只是一些基础手段，实际情况远远不止这些，有兴趣的同学可以自行去查证。</p><h4>自贸区</h4><p>外汇使用起来较为麻烦，这也影响了企业的正常经营以及效率，为此国家进一步改革开放，局部地放松外汇管制，这就创立了所谓的自贸区。</p><blockquote>目前，中国有21 个自由贸易试验区，分别是上海、广东、天津、福建、辽宁、浙江、河南、湖北、重庆、四川、陕西、海南、山东、江苏、河北、云南、广西、黑龙江、北京、湖南、安徽自由贸易试验区。<br/>此外，中国还有海南自由贸易港，它与自由贸易试验区在本质上存在差异，自贸港是 “境内关外”，实行更加开放的政策，涵盖人才流动自由、资金流动自由和低税率等方面，而自贸区主要是指货物贸易的自由化。</blockquote><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047402195" alt="" title=""/></p><p>通过上图我们可以看到，实际上一个企业在自贸区的话，需要开一个自贸区新账户。<strong>原有账户：</strong> 与非自贸区进行交易，有外汇限制。<strong>新开的自贸区账户：</strong> 可以与境外进行自由交易，没有外汇限制。</p><p>自贸区账户其实就相当于在境外的企业，原有账户和自贸区账户之间是隔离的。</p><h2>外汇储备</h2><p><strong>那外汇储备怎么来的呢？</strong> 当出口大于进口（所谓顺差），外汇余额就要流到国内银行体系中，最终流到央行，而央行要拿人民币来买这些外汇，形成所谓的国家“外汇储备”。</p><blockquote>为方便理解，下面的例子中我们假设人民币兑美元的汇率是1:1</blockquote><h4>出口商出口商品</h4><p>那我们举个例子，A企业和境外的B企业做生意，A企业将货物出口到B企业所在的国家（比如说美国），B企业需要把钱给A企业，但是A和B在不同的国家并且不属于同一个会计核算主体，因此<strong>不能简单的用下面的会计分录来处理</strong>。</p><pre><code>借：B企业活期
贷：A企业活期</code></pre><p>这时候需要借助于银行间的“同业存放”和“存放同业”进行中转。实际上就是国内的银行，在国外银行开了一个户，然后进口商买了货物，要把钱给出口商，由对应的银行进行中转再给出口商。付钱其实就是把钱给同业存放，收钱就是从存放同业中拿钱，这就是所谓的现汇。</p><p>把例子举的更具体一些，A企业通过招商银行中转收钱，招商银行在美国花旗银行开了一个账户，在招商银行的会计体系中，有个科目叫做<strong>存放同业</strong>，属于招商银行的<strong>资产类科目</strong>，则相应的在花旗银行会计体系中有个科目叫做<strong>同业存放</strong>，属于花旗银行的<strong>负债类科目</strong>。</p><p>相应的会计分录，可以简单的写作以下两组分录。</p><h5>花旗银行侧</h5><pre><code>借：B企业活期（美元）
贷：同业存放-招商银行（美元）</code></pre><h5>招商银行侧</h5><pre><code>借：存放同业-花旗银行（美元）
贷：A企业活期（美元）</code></pre><p>由于外汇不能直接在境内流通，以及央行需要进行强制结汇，因此需要把外汇卖给央行。</p><h4>把外汇卖给央行</h4><p>招商银行的外汇，实际是存放在花旗银行的<strong>同业存放</strong>里面，所以如果要把外汇卖给央行，那么央行也必须在花旗银行开一个<strong>同业存放</strong>的账户，也就是说，从花旗银行的“招商银行同业存款”转到“央行同业存款”中。总的来说，分为如下几个步骤：</p><ul><li>招商银行在花旗银行存的美元，变成了央行在花旗银行存的美元。那么在花旗侧的会计分录：</li></ul><pre><code>借：同业存放-招商银行（美元）
贷：同业存放-央行（美元）</code></pre><ul><li>招商银行的“存放境外的美元”，变成了“存放央行的人民币”；在招商银行侧有会计分录：</li></ul><pre><code>借：存放央行（人民币）
贷：存放同业-花旗银行（美元）</code></pre><ul><li>央行多了一笔“存放境外的美元”，以及一笔“招商银行存放的人民币”，在央行侧有会计分录：</li></ul><pre><code>借：存放同业-花旗银行（美元）
贷：同业存放-招商银行（人民币）</code></pre><ul><li>出口商的“活期存款美元”，变成了“活期存款人民币”。在招商银行侧有会计分录：</li></ul><pre><code>借：A企业活期（美元）
贷：A企业活期（人民币）</code></pre><p>最后的状态是：A企业在招商银行有出口的钱（人民币），央行在花旗银行有存放同业（美元），招商银行在央行有存放同业（人民币）。最后变成了外汇，也就是我们国家外汇储备的主要由来。</p><p>为了方便理解，仅从便于理解的角度进行说明，在实际操作中，与本节描述的内容有比较大的不同。比如，实际上央行不一定在境外银行开立账户，可以由指定的商业银行代持。另外，外汇资产通常由境外存款转化为其他外汇资产（如，购买美国国债、股票、货币市场工具、黄金等等）</p><h4>外汇的好处与坏处</h4><h5>好处：</h5><p>我国可以动用这些钱购买国外的资产。</p><h5>坏处：</h5><ul><li>导致人民币通货膨胀：企业和个人获得的外汇卖给指定银行，银行再将多余的外汇卖给中央银行，中央银行则需要发行相应的人民币来购买这些外汇，这就增加了基础货币的投放。从而推动物价上涨，引发通货膨胀。不过咱们央妈有很多来避免或者减少相关的政策。</li><li>汇率风险：这个就不用多收了，汇率变化可能导致我们手里的美元不值钱了。</li></ul>]]></description></item><item>    <title><![CDATA[智能招聘新范式 爱跑步的香蕉_cKtiN]]></title>    <link>https://segmentfault.com/a/1190000047402096</link>    <guid>https://segmentfault.com/a/1190000047402096</guid>    <pubDate>2025-11-15 20:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>智能招聘新范式<br/>人才战争下半场：AI重构精准招聘新范式</p><p>当生成式AI从炫技工具变为生产力标配，企业竞争已悄然进入“人机协同”的深水区。数据显示，仍沿用传统方式招聘的企业，正以每年15%的速度流失人才竞争力。招聘的终极战场，早已从“找到更多人”升级为“精准识别对的人”。</p><p>现实中，大多数HR团队仍陷在简历海啸中，用人类宝贵的情感判断力，去完成本应由AI处理的数据筛选。这种角色错位，正是人机协同失败的开端。</p><p>人机协同的本质：专业分工，各展所长</p><p>在招聘博弈中，人与AI有着明确的能力疆界：</p><p>•人类不可替代：候选人动机深度判断、用人部门需求洞察、团队冲突调解<br/>•AI天生擅长：海量数据处理、标准化流程执行、精准信息匹配、7×24小时自动化</p><p>真正的智能招聘，不是用AI取代HR，而是用AI将HR从机械劳动中解放出来，让其专注于需要人类智慧的核心决策。</p><p>精准招聘的核心：从“识别”到“理解”的质变</p><p>当多数AI面试产品还停留在“关键词匹配”时，先进的AI招聘技术已实现从“识别”到“理解”的跨越，其精准度经得起严苛的心理学验证：</p><p>•通过效标效度与重测稳定信度双重考验<br/>•支持“背靠背”人机对比实验<br/>•打分结果可直接作为招聘决策依据，无需人工二次解读</p><p>这标志着招聘决策彻底告别“凭感觉”，进入“凭数据”的科学化时代。</p><p>四大核心技术，贯穿招聘全流程</p><p>1.一问多能：单道题目同步评估多项胜任力，评估效率提升50%以上，无缝衔接HR初筛与技术复试<br/>2.自由追问：基于候选人回答即时生成针对性问题，如资深面试官般捕捉关键信息，杜绝能力误判<br/>3.简历深度挖掘：自动抓取简历关键信息与模糊点，通过递进式提问杜绝信息造假，避免错失优质人才<br/>4.全维度考察：覆盖通用胜任力与专业领域能力评估，同时解放HR与专业面试官</p><p>候选人体验升级：重塑面试价值</p><p>传统AI面试的“机械感”容易劝退优秀人才，新一代AI招聘技术重新设计了全流程体验：</p><p>•懂情绪的智能交互：精准捕捉语速、情绪与潜台词，引导候选人充分展现实力<br/>•无断点流畅体验：自动识别回答状态，全程如面对面交流般自然<br/>•沉浸式视觉体验：语音与口型匹配精度大幅提升，告别“纸片人”疏离感<br/>•多轮对话答疑：候选人可随时提问，AI准确解答职位与公司信息，提升入职意愿</p><p>全流程智能革命：从“找人”到“识人”</p><p>先进的AI人才寻访系统，实现了招聘初筛的完全自动化，真正达成从“找人”到“识人”的跨越：</p><p>•30-60秒快速初始化，即刻投入工作<br/>•智能筛选：自主操作页面，按预设条件精准识别候选人<br/>•动态沟通：模拟人类语气互动，发现不合适即时退出<br/>•全覆盖回复：遍历所有未读消息，个性化回复不漏人<br/>•系统同步：自动完成从下载简历到ATS上传的全流程</p><p>这不仅是操作环节的提效，更是通过大模型技术将“经验型判断”升级为“数据型决策”，推动整个招聘决策体系的科学化变革。</p><p>人才战争的号角已经吹响，企业的选择将决定其竞争力走向：是沿用昨天的工具应对明天的挑战，还是拥抱已被验证的智能招聘新范式，实现人才竞争力的跨越式提升。<br/>AI得贤招聘官</p>]]></description></item><item>    <title><![CDATA[怎么查公司邮箱？2个技巧 遭老罪的程序猿]]></title>    <link>https://segmentfault.com/a/1190000047401819</link>    <guid>https://segmentfault.com/a/1190000047401819</guid>    <pubDate>2025-11-15 19:02:14</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在企业间往来、业务沟通、客户支持等多种业务场景下，常常需要获得一家公司的企业邮箱。那么，公司邮箱要去哪里查？有哪些实用方式？本文将详细介绍。<br/><img width="723" height="443" referrerpolicy="no-referrer" src="/img/bVdm3xC" alt="" title=""/></p><h2>一、什么是企业邮箱</h2><h2>企业邮箱的定义</h2><p>企业邮箱，是以公司自有域名（如<a href="mailto:xxx@yourcompany.com" target="_blank">xxx@yourcompany.com</a>）为后缀的邮箱系统。它区别于个人常用的免费邮箱，大多需要部署在专业邮件服务平台上，如Zoho、Gmail（Google Workspace）等。这种邮箱不仅用于日常的邮件收发，更是公司对外展示正规形象的标配。</p><h2>企业邮箱的作用</h2><p>企业邮箱是公司通信、业务往来、客户服务、合作跟进等各个流程的核心通道。</p><p>基于域名的邮箱提升公司业务联系的可信度。<br/>有利于统一的邮件管理、信息备份与数据安全。<br/>可以设置部门、人员分级管理，实现高效的业务协作和员工信息整合。<br/>许多企业采用Zoho邮箱建立专属域名邮箱，维护品牌形象，兼顾数据安全和管理便捷。</p><h2>企业邮箱与普通邮箱的区别</h2><p>企业邮箱与个人邮箱最大的区别在于邮箱后缀归属于企业自有域名。个人邮箱如<a href="mailto:xxx@163.com" target="_blank">xxx@163.com</a>、<a href="mailto:xxx@gmail.com" target="_blank">xxx@gmail.com</a>主要满足个人通信需求，而企业邮箱如<a href="mailto:xxx@company.com" target="_blank">xxx@company.com</a>或<a href="mailto:xxx@yourbrand.cn" target="_blank">xxx@yourbrand.cn</a>体现组织身份。此外，企业邮箱通常具备更高的安全级别、更大的存储空间、更完善的管理和备份机制。普通邮箱则在安全、管理和品牌形象上存在一定局限，无法满足企业规模化、多部门、多终端的需求。</p><h2>二、如何查找企业邮箱</h2><p>企业邮箱公开程度视公司政策而定，但通过以下两种渠道，基本能高效获取所需企业邮箱信息。</p><h2>1. 通过公司官网查找</h2><p>查找官网的联系方式页面<br/>最直接的方式是打开企业的官方网站。绝大多数正规公司都会在首页下方或明显位置设置“联系方式”页面，这里会详细列出公司官方邮箱、服务热线、传真等联络方式，多为业务、合作、招聘、客服等细分邮箱。</p><h2>检查官网的“联系我们”板块</h2><p>不管是中小企业还是世界500强，他们的网站基本都设有“联系我们”一栏。此处通常会以清晰的表格或列表形式给出企业邮箱、联系地址、业务专员邮箱等，可以一目了然地获取对外公开的邮箱信息。</p><h2>检索官网的客户服务页面</h2><p>除了一般的联系方式，企业还会专门设有“客户服务”或“技术支持”等页面。特别是互联网、软件、云服务类企业，在这些页面往往会公布工单邮箱、技术支持邮箱及客户关怀邮箱等，更贴合业务沟通的具体场景。</p><h2>2. 利用搜索引擎查找</h2><p>输入公司名称和关键词组合<br/>如果在官网找不到明确的邮箱联系方式，可以巧用搜索引擎，比如百度、Google等。将公司名称结合关键词如“邮箱”、“contact”、“customer service email”进行检索，能够筛选外部发布的信息。关键词可灵活组合提升检索精度，例如“公司名+邮箱”、“公司名+客服邮箱”。</p><h2>查看搜索结果中的邮箱信息</h2><p>搜索结果页上，常可出现第三方网站、行业黄页、招聘网站、新闻稿件等处的企业邮箱线索。例如，大型企业参与展会、发起新闻活动时，会以邮箱作为联系渠道。同时还可进入权威第三方平台（如天眼查、企查查）查看企业公开资料，有时亦会披露企业邮箱。</p><h2>验证搜索结果的准确性</h2><p>通过多渠道搜集到的企业邮箱，务必核实其是否为官方邮箱，尤其是遇到个人博客、第三方论坛等不稳定来源。可以对比官网信息或直接通过官方渠道确认，避免误用、被钓鱼邮件冒用等风险。</p><h2>3. 通过社交媒体查找</h2><p>查找公司官方社交媒体账号<br/>现代企业普遍注重品牌传播与客户互动，多会在微信、微博、LinkedIn、Facebook、Twitter等平台注册公司账号。可以在这些平台搜索公司官方账号。</p><h2>检查社交媒体上的联系方式</h2><p>不少企业在社交媒体主页或简介栏直接写明企业邮箱，有些则通过发布固定动态、置顶推文等方式分享官方联系邮箱。</p><h2>发送私信或留言确认邮箱</h2><p>如遇到社交平台未直接公开邮箱，您还可主动发私信或在评论区联系官方账号客服，索要业务对应的邮箱信息，以获得最新和一手的企业邮箱。</p><h2>三、推荐使用 Zoho 邮箱</h2><p>Zoho 邮箱的优势<br/>Zoho邮箱目前在全球服务超过1800万企业级客户，已稳居全球邮箱排行榜前三，是企业信赖的邮件服务首选。作为专业域名邮箱提供商，Zoho邮箱具备多重独特优势：</p><p>安全性高：内置先进的反垃圾邮件、病毒查杀和邮件加密机制，能有效保障企业数据安全，并支持多重身份认证，保护内部信息不泄露。<br/>功能强大：不仅仅是常规的邮件收发，Zoho邮箱还集成日历、任务、笔记、云存储、团队协作等功能，适配多场景办公。配合移动端应用，随时随地管理公司邮箱。<br/>易于管理：后台支持多账户统一管理、员工邮箱批量分配、权限设置、邮件日志追踪等功能；管理员可轻松为新员工快速分配专属域名邮箱，高效应对组织变更和信息审计。</p><h2>如何注册 Zoho 邮箱</h2><p>访问 Zoho 官网：首先打开Zoho邮箱官网，即可进入企业邮箱注册入口。<br/>选择企业邮箱服务：在页面中选择“企业邮箱”，了解不同套餐和功能介绍，并明确选用域名邮箱服务，便于企业邮箱后缀和品牌保持一致。<br/>按照注册步骤完成注册：注册流程非常简明：输入管理员信息，绑定企业专属域名，设置管理员和首批员工邮箱，按照注册步骤持续操作。Zoho邮箱自助引导页面十分友好，国内外企业均可顺畅开通并投入使用。</p><h2>Zoho 邮箱的使用技巧</h2><p>邮件分类与管理：支持自定义文件夹、标签、邮件规则，让员工能高效地整理日常邮件，大幅提升信息处理效率。<br/>邮件安全设置：管理员可设置账号安全策略，启用多因素登录验证，限制可用设备等，保障邮箱账号不易被非法访问。<br/>团队协作功能：除标准邮件功能外，还内嵌团队聊天、共享日历、通讯录共享等，可满足跨部门沟通需求。此外，通过域名邮箱，所有团队成员的邮箱均带有相同公司域名，进一步增强专业形象。</p><h2>总结</h2><p>查找一个公司的企业邮箱并不复杂。主要需借助公司官网查找联系方式、客户服务板块，或结合搜索引擎和社交媒体平台多方确认，最终获取最权威的企业邮箱信息。值得一提的是，目前越来越多企业选用Zoho邮箱作为官方沟通渠道。Zoho邮箱不仅以1800万企业级客户、全球前三的业界地位获得认可，还因其安全性、域名邮箱优势与便捷注册步骤满足了从初创团队到大型企业的全面需求。如果正在为企业选型邮箱，不妨考虑Zoho邮箱，为公司通信、客户互动和信息安全提供坚实保障。</p>]]></description></item><item>    <title><![CDATA[2025国际邮箱排行榜TOP5 遭老罪的]]></title>    <link>https://segmentfault.com/a/1190000047401830</link>    <guid>https://segmentfault.com/a/1190000047401830</guid>    <pubDate>2025-11-15 19:01:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在国际商务和个人沟通中，选择一款好用的邮箱平台至关重要。2025年，被全球用户广泛认可并持续占据主导地位的国际邮箱服务主要集中在五家：Gmail、Outlook、Zoho邮箱、Yahoo Mail和ProtonMail。本文将具体介绍这些邮箱各自的亮点特性、适用场景及选择建议，帮助用户在多元化需求下做出适合自己的明智决策。<br/><img width="723" height="443" referrerpolicy="no-referrer" src="/img/bVdm3xJ" alt="" title=""/></p><h2>一、2025年国际认可度高的邮箱排名</h2><h2>Gmail：全球领先的邮箱服务</h2><p>强大的搜索功能与智能分类：依托于Google强大的搜索技术，Gmail使用户查找邮件、附件变得异常高效。通过标签、自动分类等方式，Gmail可以智能识别广告、社交、重要邮件，有效降低信息干扰，提升查找效率。<br/>安全性与隐私保护优势：利用两步验证、AI反垃圾邮件技术以及强大的服务器加密能力，守护用户数据安全。谷歌致力于不断更新安全协议，有效阻止钓鱼攻击，使用户账户安全系数持续走高。<br/>丰富的插件与扩展功能：支持与Google Workspace深度整合，同时开放多种浏览器扩展插件。例如日历、任务、第三方文件管理、甚至客户关系管理CRM插件，极大地扩展了邮箱的日常效率与应用场景。</p><h2>Outlook：微软旗下的全能邮箱</h2><p>与办公软件的无缝集成：作为微软生态系统的核心产品之一，Outlook可以与Word、Excel、PowerPoint等办公套件无缝对接。通过一站式管理日历、任务和邮件，极大提升团队与个人的工作效率。<br/>跨平台同步与便捷管理：无论在Windows、Mac还是移动端，Outlook都实现了高效同步。即使用户在多个设备间切换，也可随时访问最新邮件记录，实现云端数据的全程保障。<br/>企业级安全与可靠性：配备多重身份验证及反病毒、反钓鱼技术，并支持邮件加密，为企业客户提供银行级的安全防护措施，是全球众多大型企业的首选邮箱之一。</p><h2>Zoho邮箱：崛起的商务邮箱新秀</h2><p>高级安全功能与数据加密：采用多层加密和严格的数据隔离标准，支持端到端加密，让企业邮件实现数据自主可控；结合AI反垃圾技术有效隔离恶意邮件，全面保障信息安全。<br/>强大的协作与团队管理工具：提供企业级通讯录、任务协作、日历与文件管理，支持多域名邮箱统一管理，方便企业根据业务需要设置角色、权限和审批流程，提升团队协作效率。<br/>高性价比与定制化服务：为企业和个人用户提供灵活的套餐选择及高度定制化服务，涵盖从个人免费版到大中型企业的专属高级版，大大提升投入产出比。特别是针对中国及海外两地企业推出的域名邮箱方案，极大便利跨境通讯。<br/>全球排行榜与企业采用现状：2025年，Zoho邮箱凭借全球1800万企业级客户，已跻身全球邮箱排行前三，在欧美、东南亚和新兴市场的企业用户中尤其受到青睐。其完善的注册步骤极大降低了企业开通与维护门槛，无需繁琐流程，即可便捷接入国际商务通讯网络。</p><h2>Yahoo Mail：历史悠久的邮箱服务</h2><p>简洁的界面与易用性：以简明直观的界面和高兼容性著称，新用户上手门槛低，收件、发件等操作流畅顺手，特别适合偏好基础功能的用户群体。<br/>个性化定制与丰富的主题：提供丰富多样的界面主题、头像和自定义设置，可根据个人兴趣个性化邮箱外观；日历、天气、新闻等内容可一键集成，在邮件管理之余获取更多信息服务体验。<br/>社交媒体集成与互动性：支持与Facebook、Twitter等社交媒体对接，使用户无需离开邮箱即可便捷发布、转发信息，提升全场景的信息管理与社交互动效率。</p><h2>ProtonMail：注重隐私的加密邮箱</h2><p>零访问权限的隐私保护：总部位于瑞士，遵循全球严格的数据隐私法规。其最大亮点是连公司自身都无法解密用户邮件，为用户提供最高级别的数据保护。<br/>端到端加密技术：每一封邮件在用户设备端即被加密，即便第三方拦截邮件内容也无法破解，有效保障个人及企业敏感信息的绝对安全。<br/>简洁的用户界面与易用性：界面简洁明了，支持网页、移动端多平台同步，适合追求极致隐私和安全保护的企业或个人用户使用。<br/>2025国际邮箱前五对比表<br/>邮箱名称    所属公司    核心安全特色    团队协作能力    支持域名邮箱    注册步骤复杂度    主要用户群<br/>Gmail    Google    全面加密防护、AI反垃圾    强    支持    简单    个人、企业<br/>Outlook    微软    多层身份验证、反病毒    极强    支持    简单    企业、教育<br/>Zoho邮箱    Zoho    数据隔离、端到端加密    极强    强    最简单    企业<br/>Yahoo Mail    Yahoo    标准加密、垃圾邮件拦截    中等    支持    一般    个人、家庭<br/>ProtonMail    Proton AG    全面端到端加密    一般    不支持    一般    隐私重视者</p><h2>二、选择国际邮箱的关键因素</h2><h2>安全性与隐私保护</h2><p>对于企业级与个人用户，邮箱的安全性一直是首要考虑。比如Gmail、Outlook均采用高标准身份验证与数据加密，ProtonMail则以极端隐私保护著称，银企用户会优先关注反垃圾、信息隔离与加密能力。而以Zoho邮箱为代表的新一代国际邮箱，采用多重安全机制结合人工智能过滤技术，既能阻挡垃圾邮件又能确保敏感信息不外泄，更适合对数据安全要求极高的企业客户。</p><h2>功能丰富性与易用性</h2><p>国际主流邮箱无不强调插件、协作与移动端支持能力：Outlook因与Office套件的整合成为办公领域的宠儿；Gmail因智能分箱和扩展插件备受个人及创意型企业青睐；而Zoho邮箱则支持企业级别的域管理、灵活应用扩展以及团队协作，是当下最具成长力的メール解决方案。</p><h2>服务稳定性与可靠性</h2><p>除安全外，服务后台的稳定与可靠性也是评判一款国际邮箱优劣的重要标准。Gmail和Outlook依托全球化服务器，实现全年全天候高可用；Zoho邮箱亦实现了多节点冗余备份，业务不中断，保障邮件流通流程万无一失。</p><h2>价格与性价比</h2><p>多数国际邮箱均提供个人免费版与企业收费版。Zoho邮箱以高性价比著称，灵活的套餐体系让新创及中小企业低成本获取国际化协作工具，且支持快速开通域名邮箱，注册门槛极低。Gmail、Outlook虽然整体成熟，但企业版定价及定制灵活度略逊一筹。ProtonMail则以付费换取极致隐私，目标人群更加聚焦。</p><h2>三、常见问题及解答</h2><h2>如何选择适合自己的国际邮箱？</h2><p>需结合用户自身需求和预算。高度重视数据主权和管理灵活性的企业用户，推荐优先选择拥有完善注册步骤和批量域名邮箱管理能力的Zoho邮箱。个人用户可以根据日常互动和功能扩展偏好选择Gmail、Yahoo Mail；如果对办公生态整合有高要求，则Outlook更适合。</p><h2>不同邮箱的安全性有哪些差异？</h2><p>Gmail、Outlook的安全机制成熟，适合大多数商务与个人用户。Zoho邮箱采用业内领先的数据隔离及多重防护技术，能有效防止信息泄露。ProtonMail则是端到端加密的极致典范，适合注重隐私的用户群体。</p><h2>如何确保邮箱的长期稳定使用？</h2><p>定期更换密码、启用双重认证，避免在公共网络中频繁登录，首选具备冗余备份和全球服务器资源的国际邮箱平台。企业用户建议每年评估邮箱账号权限和员工离职后的信息管理，与IT管理团队协同维护。</p><h2>结尾总结</h2><p>综上，Gmail、Outlook、Zoho邮箱、Yahoo Mail和ProtonMail是2025年国际上用户最为认可和使用广泛的五大主流邮箱。企业级用户尤为看重邮箱的安全性、扩展性和高性价比，而Zoho邮箱凭借域名邮箱、简单便捷的注册步骤，以及在全球1800万企业级客户中的口碑，证明了其领先地位。不论是个人还是企业，不同需求都能在上述五款国际邮箱中找到最优选项。</p>]]></description></item><item>    <title><![CDATA[2025 年最佳 SEO 学习路线和书籍]]></title>    <link>https://segmentfault.com/a/1190000047401615</link>    <guid>https://segmentfault.com/a/1190000047401615</guid>    <pubDate>2025-11-15 14:03:16</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>你是不是也收藏了一堆 “SEO圣经”、“终极指南”，但再也没打开过？<br/>别搞花里胡哨的，就三步走，踏踏实实学完就能用</p><p>原文：<a href="https://link.segmentfault.com/?enc=c5xHbxoRXvdgdhxRwSX2Kw%3D%3D.qXraPcHzPwgU6yAna%2FIAmVaG14wqkemWgtA3qMfYLo5ScVEhYuRd2y0A9cnTkCOl" rel="nofollow" target="_blank">https://bysocket.com/best-seo-books-in-2025/</a></p><p>先自荐下，我在开源写的《SEO for AI Website · User Growth Playbook 》、</p><p><a href="https://link.segmentfault.com/?enc=Nj4AKMYeujxyp%2Ff14tprKg%3D%3D.nFQVVOvR3QuB6ZV%2FUlBGk3jGVfR%2BZ%2BS6fBcnrMcPsVsj9ceC6iIM8usMu%2BYksZXgWynq%2BdewKK3D91FE1aJbMg%3D%3D" rel="nofollow" target="_blank">https://usdunlunl.feishu.cn/sync/L19ydnVSKs23HFbN7NMcWBChn2o</a></p><h2>第一步：从零开始，把基础打牢</h2><h3>Ahrefs 的免费 SEO 基础教程（有中文版）</h3><p><a href="https://link.segmentfault.com/?enc=7yaO%2BmhXttqk5dlrfKP5Cw%3D%3D.cqJrs9BXzdjq0gxpiCyV%2F0fIcZQQBZa0ui0idN2QQqc%3D" rel="nofollow" target="_blank">https://ahrefs.com/zh/seo</a></p><p>就像学做菜先认调料和厨具一样，学 SEO 你得先知道最基本的概念都是啥。这套教程就像个耐心的老师，从什么是搜索引擎开始，一点点把你教明白，帮你建立起完整的知识框架<br/>把这份教程从头到尾看一遍，不用死记硬背，理解最重要</p><h2>第二步：动手干，别自己瞎搞</h2><h3>Google搜索官方文档（有中文版）</h3><p><a href="https://link.segmentfault.com/?enc=NzcvK9qhn7qwjacG1ZKgxA%3D%3D.coH5AjSSOdaX%2Be0o8PBG3iyOxN9rCumhY0NZipp3ftjtJahldKZT5t0E6WoDPwmyHyI0HwTOZ9oDbSdn16v%2B1g%3D%3D" rel="nofollow" target="_blank">https://developers.google.com/search/docs?hl=zh-cn</a></p><p>该上手了。但最怕的就是你自己瞎琢磨，方向错了全白搭。这时候，你就得把 Google 的官方文档当成程序猿的 “API 文档”。<br/>比如，你想优化网页标题，不知道怎么写好，就去文档里查 “title” 该怎么做。它说啥，你就照着做，这是最不会出错的方法。</p><p>上手记住这个顺序：</p><ul><li>先挖词儿： 想想用户会搜什么关键词来找你的内容</li><li>再想内容： 用户搜这个词，真正想看的是什么？你的内容能提供什么别人没有的价值？</li><li>写和优化： 规划好内容结构，然后写好标题、正文，把网站内部链接整理好</li></ul><p>以上都做完了，再去搞外链： 找别的网站来推荐你</p><h2>第三步：持续升级，跟上潮流</h2><p>几个行业里公认的牛逼博客</p><h3>Ahrefs Blog</h3><p><a href="https://link.segmentfault.com/?enc=Q0xqxsNDEJvKlewcM4c%2Bdw%3D%3D.uczzExhWPJFCHoH7eJy9db222gEqdapHsX3T3Ho1eKk%3D" rel="nofollow" target="_blank">https://ahrefs.com/blog/</a></p><h3>Semrush Blog</h3><p><a href="https://link.segmentfault.com/?enc=GS2FD9ElU%2FHiPnTSe5bZPg%3D%3D.RvNHIknEdELIGPmJRKlzH9uolsgWL6ipqfoVLGblDSU%3D" rel="nofollow" target="_blank">https://www.semrush.com/blog/</a></p><h3>Search Engine Land</h3><p><a href="https://link.segmentfault.com/?enc=8AWzDEEUJFr94VSMdwk5bg%3D%3D.uv%2F7X6AFdJImBex8BqpKUh9ZrqyEC1Xcf1CgF9NHW4w%3D" rel="nofollow" target="_blank">https://searchengineland.com/</a></p><p>SEO 在 AI 时代总是在变，你得持续学习。这几个博客就像是行业老炮儿的聚集地，他们经常分享最新的案例、技巧和行业动态。<br/>不用天天看，每周抽点时间逛逛，看看有什么新东西</p><p>看，就三步：用 Ahrefs 打基础  → 干活时查 Google 官方说明书 → 看大佬博客保持进步</p><h2>四、最后想找人交流？关注这些人</h2><h3>中文圈（主要聊出海）</h3><p>哥飞（@gefei55）<br/><a href="https://link.segmentfault.com/?enc=v9rWa8Qk2r1AuTwUajAkkQ%3D%3D.u7ubC3IwQ%2BxaKKuBBUSNQELpdnsVriGwrLl6r79082I%3D" rel="nofollow" target="_blank">https://x.com/gefei55</a></p><p>大罗SEO（@daluoseo）<br/><a href="https://link.segmentfault.com/?enc=vYFvsLiTg%2Fe4x2lQ68bagw%3D%3D.Yj1qUmrVSm%2Bkb7zlCzCHvNDOI9fiHIFM5jaKmSWyjTo%3D" rel="nofollow" target="_blank">https://x.com/daluoseo</a></p><h3>国际大神： 国外高手，可以看看他们都在聊啥</h3><p>Lily Ray（@lilyraynyc）<br/><a href="https://link.segmentfault.com/?enc=6GHyzU0jDyPnD8QMF%2BSo5A%3D%3D.qGqXZVV63X3bWuLWpf4NRhnZFmXrx8XLgmyre3uteEU%3D" rel="nofollow" target="_blank">https://x.com/lilyraynyc</a></p><p>Glenn Gabe（@glenngabe）<br/><a href="https://link.segmentfault.com/?enc=3ikLMqIL6P61bnuDOux7eg%3D%3D.RxlXTBjd9JC77XtnOPiPAqvfsl7L1nOa8DlGhlF6hIQ%3D" rel="nofollow" target="_blank">https://x.com/glenngabe</a></p><p>Brodie Clark（@brodieseo）<br/><a href="https://link.segmentfault.com/?enc=twOuU%2BmJ%2FhGRCImiXxIVkA%3D%3D.XxWDaXVZYbIcdpO0uS2N1feQQkFP3xy0Fh0%2FWqZy30M%3D" rel="nofollow" target="_blank">https://x.com/brodieseo</a></p><p>Marie Haynes（@Marie_Haynes）<br/><a href="https://link.segmentfault.com/?enc=KIoAQzPOQ0GNoErbnSp6%2Fw%3D%3D.N6fcL3hCDS%2BiYE%2B%2F0X%2FD8h7GB9tCTf%2F3SuyGc4XPC1w%3D" rel="nofollow" target="_blank">https://x.com/Marie_Haynes</a></p><p>Barry Schwartz（@rustybrick）<br/><a href="https://link.segmentfault.com/?enc=AgeiFULX8ZVeIdEmFzFqlg%3D%3D.YyjYxcPvwmBeldiZUKV5%2BILdq%2Fr2XJswuCFej%2FjmuF8%3D" rel="nofollow" target="_blank">https://x.com/rustybrick</a></p><p>Aleyda Solís（@aleyda）<br/><a href="https://link.segmentfault.com/?enc=cIiIMHu%2Bz%2B%2B%2FNBJpsglzVQ%3D%3D.7EPG8BnYO4K%2BN9rYoqRwoD7zPdwhbEfR7R2GGRaXLXk%3D" rel="nofollow" target="_blank">https://x.com/aleyda</a></p><p>Kevin Indig（@Kevin_Indig）<br/><a href="https://link.segmentfault.com/?enc=Zh4cbdjqq9h4S7JYIi%2BJ5A%3D%3D.Jm5K2OENZDjEs29sscqsIb1j3VPQmHhnSrAvovBvlc4%3D" rel="nofollow" target="_blank">https://x.com/Kevin_Indig</a></p><p>Cyrus Shepard（@CyrusShepard）<br/><a href="https://link.segmentfault.com/?enc=ZcmaGo7TQnCCPHEtf1bGTg%3D%3D.CGR8V076uaF5d%2BcVx88RBe1%2Fy54emECUCJhiEqLFDyg%3D" rel="nofollow" target="_blank">https://x.com/CyrusShepard</a></p><p>Patrick Stox（@patrickstox）<br/><a href="https://link.segmentfault.com/?enc=CEbmuxmc00O%2Fu1y7nzRhgQ%3D%3D.JYfhxaKMBAO2TzVUVyjLUKs7tZHQAGrzfa346u5WrYU%3D" rel="nofollow" target="_blank">https://x.com/patrickstox</a></p><p>Rand Fishkin（@randfish）<br/><a href="https://link.segmentfault.com/?enc=ThVMlWrdz94GjByLlWFRLA%3D%3D.nmjF9C9zi9eiXzL3ESoNjXqE4NAB8gKwfXRobvs%2BOh8%3D" rel="nofollow" target="_blank">https://x.com/randfish</a></p><p>Google Search Central（X）<br/><a href="https://link.segmentfault.com/?enc=80wUnrl6GYzC1%2FIdOSmcUA%3D%3D.EyXMctwJuopK4YsHSD9a6OKQM0Ku74%2BVIYR1a5smnl8%3D" rel="nofollow" target="_blank">https://x.com/googlesearchc</a></p><p>官方 YouTube 频道<br/><a href="https://link.segmentfault.com/?enc=TsvZKuhoM8bUOUzzSbRrTA%3D%3D.h8pyq8l1KpV3yt5mxP50LkJqIN52fncC1oV9NWKIbgdX1hCt3JudJFG%2FRLl9SzLQ" rel="nofollow" target="_blank">https://www.youtube.com/@GoogleSearchCentral</a></p><p>大会，目前只参加过深圳 SEO 大会（官网）<br/><a href="https://link.segmentfault.com/?enc=3%2FYEk81SZ%2FOjPbh70t0Pvw%3D%3D.vuy7G%2Fn8mNOr2Skmb7rzhvA6BJW1ll0gI%2B%2Fhmbn53pBKhK99iSJld7ePQxDFH7Eu" rel="nofollow" target="_blank">https://shenzhenseoconference.com/</a></p><p>资源也都是长期更新的，不会让你学完就过时<br/>一步步来，几个月后你就能摸到门道了</p>]]></description></item><item>    <title><![CDATA[实战教程：手把手教你用Sora2 API]]></title>    <link>https://segmentfault.com/a/1190000047401623</link>    <guid>https://segmentfault.com/a/1190000047401623</guid>    <pubDate>2025-11-15 14:02:46</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>📖 实战教程：手把手教你用Sora2 API生成10分钟一致性视频<br/>理论说了一千遍，不如亲手运行一遍。本文将带你从零开始，完成一次完整的“视频续写”操作。</p><p>在上一篇文章《Sora2重磅升级：视频续写可达10分钟，角色场景一致性迎来突破！》中，我们介绍了Sora2视频续写的核心价值。本文将成为其<strong>实战篇</strong>，详细讲解如何调用速创API，一步步实现视频的延续创作。</p><p>一、准备工作</p><ol><li>获取API密钥<br/>访问速创API平台，注册账号并登录。在控制台的「密钥管理」中，你将获得唯一的 key，这是你调用所有API的凭证。</li><li>理解核心流程<br/>视频续写遵循一个清晰的“<strong>首轮生成 → 获取PID → 续写请求</strong>”流程。下图清晰地展示了这一过程：</li></ol><p>flowchart LR</p><pre><code>A[第一步</code></pre><p>提交初始生成请求] --&gt;|返回原视频PID| B[第二步<br/>使用remixTargetId续写]</p><pre><code>B --&gt; C{续写完成？}
C --&gt;|是| D[获得一致性续写视频]
C --&gt;|否| E[排查参数与网络]</code></pre><p>二、步骤详解：从零生成你的第一个视频续作<br/>我们将通过一次真实的API调用来演示。</p><p>步骤 1：生成初始视频<br/>首先，我们需要一个作为“种子”的原始视频。这里我们生成一段“一个大哥穿着鞋子登雪山，鞋子特写”的视频。<br/><img width="723" height="332" referrerpolicy="no-referrer" src="/img/bVdm3uq" alt="" title=""/><br/>请求示例：</p><p>curl -X POST "https://api.wuyinkeji.com/api/sora2/submit" \<br/>-H "Authorization: duYwo59iXS4b3mHoeuXpinIXSdz" \<br/>-H "Content-Type: application/x-www-form-urlencoded;charset:utf-8;" \<br/>-d "prompt=一个大程序键子重置，鞋子补写&amp;url=<a href="https://link.segmentfault.com/?enc=2OPV7Repqi%2BFZfi%2Fh3cyXw%3D%3D.50VqAZYnKYAGTgqLZD39UCyCeQcHpFsb5uEVJ0JEffgxldZ8kZgE6C7rSCmteNrcBjdpm8rizO1x%2FcGpE7M2G%2BM8EeqQY4mtS7YOQ%2FIlvzjrHt31nwiGeLZns3J%2FdLdnCmhLaPVhwB83bog9IMNuLw%3D%3D" rel="nofollow" target="_blank">https://openpt1.oss-cn-shanghai.aliyuncs.com/?d9d0e5a60074&amp;as...</a>l"<br/>关键响应：</p><p>{<br/>  "code": 200,<br/>  "msg": "成功",<br/>  "data": {</p><pre><code>"content": "一个大哥穿着鞋子登雪山，鞋子特写",
"status": 1,
"remote_url": "https://openptl.oss-cn-shanghai.aliyuncs.com/dcb30910e8d34628b97c310a2ea6ca19.mp4",
"pid": "s_6917df60la3c8191819b64e55b5771ff", // ！务必保存这个PID
"id": "287a512a-elcf-44da-b073-49ab3385aabe"</code></pre><p>}<br/>}<br/>请务必妥善保存响应数据中的 pid 值**，它是我们进行视频续写的唯一依据。</p><p>步骤 2：进行视频续写（核心）<br/>现在，我们假设想让这位大哥“继续穿着鞋子爬上火山”。这时，就需要使用上一步获取的 pid 作为 remixTargetId 参数。<br/><img width="723" height="398" referrerpolicy="no-referrer" src="/img/bVdm3ur" alt="" title="" loading="lazy"/><br/>请求示例：</p><p>curl -X POST "https://api.wuyinkeji.com/api/sora2/submit" \<br/>-H "Authorization: duYwo59iXS4b3mHoeuXpinIXSdz" \<br/>-H "Content-Type: application/x-www-form-urlencoded;charset:utf-8;" \<br/>-d "prompt=大哥继续穿着鞋子爬上火山，鞋子特写&amp;remixTargetId=s_6917df60la3c8191819b64e55b5771ff&amp;aspectRatio=9:16&amp;duration=15&amp;size=small"<br/>成功响应：</p><p>{<br/>  "code": 200,<br/>  "msg": "成功",<br/>  "data": {</p><pre><code>"content": "大哥继续穿着鞋子爬上火山，鞋子特写",
"status": 1,
"pid": "s_6917e64333748191b491a8c7e2302772",
"remixTargetId": "s_6917df60la3c8191819b64e55b5771ff", // 指向了原始视频的PID
"remote_url": "https://openptl.css-cn-shanghai.aliyuncs.com/554cc6748f79434fb69794aab3e4bfd2.mp4"</code></pre><p>}<br/>}<br/>响应中的 remixTargetId 字段确认了本次生成是基于哪个原始视频进行的续写。新生成的视频 (s_6917e64333...) 在人物、画风和鞋子的特写上，都会与原始视频 (s_6917df60la...) 保持高度一致。</p><p>三、关键技巧与避坑指南</p><ol><li>Prompt 描述技巧：<br/>一致性：续写时，对角色、服装、核心物体的描述应与原提示词保持一致。<br/>连贯性：场景变化要自然，如“登雪山”后“爬火山”是合理的运动场景切换，而不是突然跳到“在办公室喝咖啡”。</li><li>参数误区：<br/>remixTargetId 是<strong>视频PID</strong>，不是任务ID id，别搞混了。<br/>url 参数是<strong>参考图片</strong>，用于辅助定义风格，与 remixTargetId 是两种不同的控制方式，续写时通常不需要重复传入。</li><li>任务状态查询：<br/>提交任务后，若未立即返回视频链接，可通过返回的 id 调用「任务状态查询接口」轮询结果，直到 status 变为 1（成功）或 2（失败）。</li></ol><p>四、结语与展望<br/>通过以上两个步骤，你就可以轻松实现高质量的视频续写。这种“滚雪球”式的生成能力，为<strong>AI短剧、互动剧情、产品长视频</strong>等需要高度一致性的场景提供了强大的技术基础。</p><p>随着 veo3.1-pro、Runway aleph 等更强模型的接入，未来我们甚至可以期待实现<strong>分镜级控制</strong>的長視頻生成。</p><p>🔗 相关资源：<a href="https://link.segmentfault.com/?enc=QI%2F3bS6Ma6l7ISj8E9JWjg%3D%3D.zq9RhWQyApT93KNInZLn%2BF9%2B%2F55zliveiahzPzP3wfs%3D" rel="nofollow" target="_blank">速创API</a></p>]]></description></item><item>    <title><![CDATA[番茄叶片病害检测数据集（千张图片已划分）]]></title>    <link>https://segmentfault.com/a/1190000047401646</link>    <guid>https://segmentfault.com/a/1190000047401646</guid>    <pubDate>2025-11-15 14:02:09</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>番茄叶片病害检测数据集（千张图片已划分）| AI训练适用于目标检测任务</h2><h2>概述</h2><p>在农业领域，植物病害检测是确保作物健康和提高农业生产效率的关键任务之一。随着计算机视觉技术的快速发展，基于深度学习的目标检测方法成为了病害识别的主流手段。为此，专门针对番茄叶片病害检测任务，我们推出了一个经过精心设计的番茄叶片病害检测数据集。该数据集包含了10,853张带标签的图像，覆盖了10种常见的番茄叶片病害类型，支持YOLO等先进的目标检测模型训练，旨在帮助研究人员和开发者提高农作物病害自动化检测的能力。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047401648" alt="在这里插入图片描述" title="在这里插入图片描述"/></p><h3>数据集获取</h3><blockquote>链接:<a href="https://link.segmentfault.com/?enc=dDCUI1tyKq7ZnTaz3WnY%2Fw%3D%3D.CYaJxrE2NvNPOh3aOuOye4VlnTEZ5Sia7rzsF2MUL8EYoAaqecFJoKNXf%2FYJMSRb2CMJ09QNq%2FQfrBp6o4sTZg%3D%3D" rel="nofollow" target="_blank">https://pan.baidu.com/s/196FdQ7RhzgulM0j4-dW0ng?pwd=v59n</a> <br/>提取码:v59n 复制这段内容后打开百度网盘手机App，操作更方便哦</blockquote><p>该数据集专为使用YOLOv8进行番茄叶片病害检测而设计。它包含10,853 张带标签的图像，涵盖10 种不同类型的番茄叶片状况，包括病毒、细菌和真菌感染，以及健康叶片。</p><p>数据集详细信息<br/>图片总数：10,853<br/>训练集：7,842 张图片（72%）<br/>验证集：1,960 张图像（18%）<br/>测试集：1,051 张图片（10%）<br/>图像分辨率：调整为640x640（拉伸）<br/>注释格式：YOLO<br/>类别（10 个类别）<br/>番茄细菌性斑点病<br/>番茄早疫病<br/>番茄晚疫病<br/>番茄叶霉<br/>番茄叶斑病<br/>番茄红蜘蛛（二斑叶螨）<br/>番茄目标点<br/>番茄黄化卷叶病毒<br/>番茄健康<br/>番茄花叶病毒</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047401649" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h3>背景</h3><p>随着全球气候变化的加剧，农业病害的发生变得越来越复杂和难以预测，尤其是针对番茄等重要农作物。番茄叶片病害不仅影响作物的生长发育，还可能导致产量的大幅下降。因此，如何快速、准确地诊断病害，成为了农业科技研究中的重要课题。</p><p>传统的病害识别方法依赖于农业专家的经验和人工检查，但这一过程不仅耗时且容易出错。随着计算机视觉技术的发展，AI技术特别是深度学习方法在植物病害检测中的应用日益增多，能够大大提高检测效率和准确率。此时，良好的数据集便成为训练高效AI模型的基础。</p><h3>数据集详细信息</h3><p>数据集共包含10,853张高质量的图像，这些图像经过严格筛选，确保标注的准确性。图像涵盖了番茄植物的多个生长阶段及不同类型的病害，具有极高的代表性，适合用于AI模型训练和验证。</p><h4>数据集划分</h4><p>为了支持不同阶段的训练和验证，我们对数据集进行了合理的划分：</p><ul><li><strong>训练集</strong>：7,842张图片，占数据集的72%</li><li><strong>验证集</strong>：1,960张图片，占数据集的18%</li><li><strong>测试集</strong>：1,051张图片，占数据集的10%</li></ul><p>这种划分方式保证了训练模型时数据的多样性，同时能够有效评估模型在未知数据上的表现。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047401650" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><p>图像分辨率</p><p>所有图像的分辨率已调整为640x640，便于YOLOv8等深度学习模型的输入。为了保持图像的质量和细节，我们采用了拉伸的方法来调整图像的尺寸，以便适应不同的计算资源需求。</p><p>注释格式</p><p>该数据集采用了YOLO格式的注释，适配YOLOv8等常用目标检测框架。每张图像都包含多个标签和对应的边界框，这些标签详细描述了图像中的病害类型和位置。</p><p>类别（10个类别）</p><p>本数据集包含了10种不同类型的番茄叶片病害，涵盖了病毒、细菌、真菌感染等多种病害类型。这些类别包括：</p><ol><li><strong>番茄细菌性斑点病</strong></li><li><strong>番茄早疫病</strong></li><li><strong>番茄晚疫病</strong></li><li><strong>番茄叶霉</strong></li><li><strong>番茄叶斑病</strong></li><li><strong>番茄红蜘蛛（二斑叶螨）</strong></li><li><strong>番茄目标点</strong></li><li><strong>番茄黄化卷叶病毒</strong></li><li><strong>番茄健康</strong></li><li><strong>番茄花叶病毒</strong></li></ol><p>每个类别都代表了番茄植物可能遭遇的不同类型病害，能够帮助研究人员精确识别番茄叶片的健康状况及其病变类型。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047401651" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h3>数据集概述</h3><p>这个番茄叶片病害检测数据集专门为基于YOLOv8的目标检测任务而设计，涵盖了从健康到多种病害的图像样本。每张图像都包含了详细的标注信息，支持YOLOv8模型对叶片病害进行准确定位和分类。数据集的设计考虑到了病害的多样性和复杂性，包含了不同光照、角度和背景下的番茄叶片图像，旨在增强模型的泛化能力。</p><p>通过使用这个数据集，开发者可以训练出具备较高准确度的AI模型，自动识别并分类番茄叶片的病害类型，从而为农业病害管理提供有力支持。</p><h3>数据集详情</h3><ol><li><strong>数据集来源</strong>：所有图像均来自真实的农业种植环境，确保数据的真实性和实用性。</li><li><strong>数据质量</strong>：图像清晰，细节丰富，病害部位标注准确，为目标检测模型提供了高质量的训练样本。</li><li><strong>多样性</strong>：数据集包含了各种不同环境下拍摄的图像，能够有效增强模型的适应性。</li><li><strong>标签系统</strong>：每个图像都经过人工标注，包含了精确的边界框和对应的病害类型标签，符合YOLOv8的输入要求。</li></ol><h3>适用场景</h3><p>该数据集主要适用于以下几个场景：</p><ol><li><strong>病害自动化检测</strong>：帮助农业从业者通过AI技术自动识别番茄叶片的健康状况及病害类型。</li><li><strong>农作物健康监控</strong>：利用训练好的AI模型，实时监控番茄种植区域的病害状况，提前预警病害传播。</li><li><strong>精准农业</strong>：为精准农业提供数据支持，实现高效、节能、低污染的病害防治。</li><li><strong>科研支持</strong>：为农业科研提供宝贵的病害检测数据，推动相关领域的技术研究和发展。</li></ol><h3>目标检测</h3><p>YOLOv8作为当前目标检测领域最先进的深度学习模型之一，具有优异的检测性能和高效的推理速度，尤其适合应用于资源有限的农业领域。利用YOLOv8模型对番茄叶片病害进行检测，能够实现高精度、高速度的病害定位与分类。</p><p>该数据集经过精心设计，符合YOLOv8的训练要求，帮助用户快速部署和训练出具备高效病害识别能力的AI模型。借助YOLOv8的优势，可以实现以下目标：</p><ol><li><strong>高精度病害检测</strong>：通过YOLOv8对图像中的病害进行精准定位和分类，有效提高农作物病害的诊断准确性。</li><li><strong>实时病害预警</strong>：基于YOLOv8的高效推理速度，能够在农业生产过程中实时监控并发现潜在病害问题。</li><li><strong>大规模应用</strong>：借助YOLOv8的高效性能，能够应对大规模农田监控任务，为大面积的番茄种植区提供智能化支持。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047401652" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047401653" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></li></ol><h3>结语</h3><p>随着人工智能技术在农业领域的深入应用，番茄叶片病害检测数据集为AI模型的训练和研究提供了宝贵的资源。通过本数据集，研究人员和开发者可以利用YOLOv8等先进的目标检测算法，快速构建高效的病害检测系统，推动农业科技的发展。</p><p>无论是农业病害的实时监控，还是精准农业的实施，本数据集都能够为实际应用提供强大的技术支持。未来，随着AI技术的不断进步和数据集的不断更新，我们有理由相信，农业病害检测将变得更加智能化、高效化，为全球农业发展带来深远影响。</p>]]></description></item><item>    <title><![CDATA[Ollama本地电脑运行无限制AI模型超]]></title>    <link>https://segmentfault.com/a/1190000047401661</link>    <guid>https://segmentfault.com/a/1190000047401661</guid>    <pubDate>2025-11-15 14:01:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>想在本地用一款 “无拘无束” 的 AI 模型？Ollama 能帮你轻松实现，但先得说清楚：这类 “越狱模型” 虽自由，却可能藏着不少小麻烦。</p><h2>一、手把手装 Abliterated 无限制模型</h2><h3>1. 先搭好 Ollama 基础</h3><p>不管用什么系统，先把 Ollama 装上 —— 它是本地跑模型的 “底座”，操作很简单：</p><ul><li><strong>Windows/macOS</strong>：去<a href="https://link.segmentfault.com/?enc=xJPHO9dUAPYRIt2PCuyRtQ%3D%3D.I%2F1Uf7D3Hcc5mm2O0kqFBVYGn5MyZR48yVEKfF1%2FhZY%3D" rel="nofollow" target="_blank">Ollama 官网</a>下载对应安装包，双击后一路 “下一步” 即可（Windows 用户记得按提示开启 WSL2，跟着引导点几下就行）。</li><li><p><strong>Linux</strong>：打开终端，复制粘贴这行命令，回车后自动完成安装：</p><p>bash</p><pre><code>curl -fsSL https://ollama.com/install.sh | sh</code></pre></li></ul><h3>2. 找模型、跑模型，两步到位</h3><p>Ollama 自带模型市场，搜 “无限制” 相关模型很方便：</p><ol><li>打开模型市场，搜关键词 <strong>abliterated</strong>：<a href="https://link.segmentfault.com/?enc=2w98a7NBKjVt9a71YyXT5g%3D%3D.UryiaCKCmyNQHc%2Ff3fAmYkcsVhsex72h4Dlr1aM689Jk6I6w9NBiKD9kL8QXdZB2" rel="nofollow" target="_blank">https://ollama.com/search?q=abliterated</a>；</li><li>选一个看起来靠谱的（比如 <code>huihui_ai/gemma3-abliterated</code>）。这里特别提一下，huihui_ai这位大佬团队改造的模型还挺多，他们专注于无限制模型改造，不仅在 Ollama 平台（链接：<a href="https://link.segmentfault.com/?enc=qOC5%2FpDNV0Zma%2BmzyFR3Rg%3D%3D.JFnTe%2FoHr1t3V7mlu1bPbY2%2BDP9tbHIEsRoWAOOWITF7joKOq6zKEfP37UsD2M8ALLDzt2If87PyZqTrHxGAOJsa73qaEOy46NyeF8Z75wNLM59sznKjJirNDXm0w8qP2%2B%2BmGx1TtTPjtGP4QWItf8%2FcN6muwOeT%2BLBMyRuulZlHbvqlipeiwcFA8ZijdHv3" rel="nofollow" target="_blank">https://ollama.com/huihui_ai）上线了大量模型，在HuggingFace社...</a>）。</li><li><p>选好模型后，在终端里输命令启动：</p><p>bash</p><pre><code>ollama run huihui_ai/gemma3-abliterated</code></pre></li><li>首次运行会自动下载模型（稍等几分钟，大小看模型参数），完成后直接进入对话界面 —— 全程本地运行，没有内容过滤限制。</li></ol><h2>二、得知道：Abliterated 模型是啥？为啥容易 “抽风”？</h2><p>Abliterated 直译是 “被移除限制的”，说白了就是给原生模型（比如 Llama、Mistral）“越狱”：把官方加的内容过滤机制（比如防暴力、防违法的限制）给删掉了。</p><p>但问题出在 “怎么删” 上：市面上大多这类模型是网友自行修改的，而非专业团队优化。原生模型的 “内容限制” 和 “核心逻辑”（比如语义理解、逻辑推理）其实是深度绑定的 —— 就像手机的 “安全锁” 和 “主板” 焊在一起，非专业拆解很容易拆坏核心部件。</p><p>结果就是：删限制时可能误删了模型的逻辑模块，导致回答颠三倒四、胡言乱语，甚至简单问题都答不对（比如算错 1+1）。Ollama 市场里不少 Abliterated 模型都有这毛病，经常 “抽风” 输出残缺或混乱的内容。</p><h2>三、法律风险：用无限制模型的两大风险</h2><ol><li><strong>法律与责任风险</strong>没了内容过滤，不代表能 “为所欲为”。生成违法、侵权、造谣内容，照样要承担法律责任 —— 各国对 AI 生成内容都有明确监管，别踩红线。</li><li><strong>模型质量风险</strong>如前面所说，非专业修改可能让模型 “变笨”，输出错误信息（比如搞错常识、逻辑抽风）。如果用它处理重要任务（比如写方案、做分析），很容易掉坑里。</li></ol><h2>四、拓展：Ollama 还能跑其他平台的模型</h2><p>除了 Ollama 市场，Hugging Face 等平台的模型也能导入：</p><ol><li>下载模型文件（带 <code>.bin</code>/<code>.pth</code> 后缀的权重文件）；</li><li><p>本地新建文件夹（比如 “my-model”），放入模型文件，再创建一个无后缀的 <code>Modelfile</code>，写入配置（示例）：</p><p>plaintext</p><pre><code>FROM ./my-model  # 指向模型文件路径
PARAMETER temperature 0.7  # 可自定义参数</code></pre></li><li>终端进入文件夹，输 <code>ollama create 模型名 -f Modelfile</code> 导入，之后用 <code>ollama run 模型名</code> 启动即可。</li></ol><h2>最后提醒</h2><p>如果只是想体验 “无限制”，尽量挑下载量高、评价好的模型如果要正经用，优先选官方模型 —— 虽然有约束，但至少 “聪明” 且可靠。毕竟，AI 的 “自由” 和 “好用”，往往得选一个。</p>]]></description></item><item>    <title><![CDATA[飞牛 Nas 部署 Docker Ngi]]></title>    <link>https://segmentfault.com/a/1190000047401608</link>    <guid>https://segmentfault.com/a/1190000047401608</guid>    <pubDate>2025-11-15 13:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>使用 Docker Compose 方式部署</p><p>在 /vol2/1000/docker-data/nginx/ 目录下，创建 nginx.conf</p><pre><code>worker_processes  1;
events {
    worker_connections  1024;
}
http {
    include       /etc/nginx/mime.types;
    server {
      listen       80;
      server_name  localhost;
      location / {
        root   /usr/share/nginx/html;
        index  index.html index.htm;
      }
    }
    access_log /var/log/nginx/access.log;
    error_log /var/log/nginx/error.log;
}</code></pre><pre><code class="yaml">version: '3'
services:
  nginx:
    restart: always
    container_name: nginx
    image: nginx
    ports:
      - 5555:80
      - 443:443
    volumes:
      - /vol2/1000/docker-data/nginx/html:/usr/share/nginx/html
      - /vol2/1000/docker-data/nginx/www:/var/www
      - /vol2/1000/docker-data/nginx/logs:/var/log/nginx
      - /vol2/1000/docker-data/nginx/nginx.conf/:/etc/nginx/nginx.conf
      - /vol2/1000/docker-data/nginx/etc/cert:/etc/nginx/cert
      - /vol2/1000/docker-data/nginx/conf.d:/etc/nginx/conf.d
    environment:
      - NGINX_PORT=80
      - TZ=Asia/Shanghai
    privileged: true</code></pre><p>执行以下命令，让其有权限</p><pre><code class="shell">chmod -R 777 /vol2/1000/docker-data/nginx/html/</code></pre>]]></description></item><item>    <title><![CDATA[住宅代理 vs 数据中心代理：核心技术差]]></title>    <link>https://segmentfault.com/a/1190000047401471</link>    <guid>https://segmentfault.com/a/1190000047401471</guid>    <pubDate>2025-11-15 12:04:41</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在企业网络业务中，住宅代理与数据中心代理是最常见的两类代理类型。它们都能提供替代 IP，但其底层技术结构、被风控识别的概率、速度表现、稳定性和使用场景却完全不同。<br/> 很多企业在选型时只看到价格差异，忽略了技术特征，从而在后期遇到封号、访问异常、成功率下降等问题。本文将从技术角度深入解析住宅代理与数据中心代理的本质差异，帮助企业正确选择适合自己的代理类型。</p><h2>一、IP 来源本质不同：决定两者“身份”的根本差异</h2><p>住宅代理的 IP 是由家庭宽带运营商分配，也就是说，它们来自真实用户的网络环境。<br/> 而数据中心代理的 IP 则来自各类机房、云服务器提供商，如 AWS、GCP、阿里云等。这些 IP 在大多数平台的识别系统里默认属于“服务器流量”，而非真实用户节点。也正是这一点，使得数据中心代理更容易被认定为非自然访问，而住宅代理的访问行为更符合普通用户特征。</p><h2>二、风控识别倾向：两个类型的“天然标签”不同</h2><p>在现代风控系统中，IP 类型只是判断的第一步。平台还会结合 ASN、访问行为、频率、DNS 查询模式、历史行为等综合识别。<br/>数据中心代理由于来自机房，具备以下典型特征：<br/>●IP 密集在同一网段，来源集中<br/>●经常被用于爬虫或批量访问<br/>●高频率请求特征明显</p><p>因此平台往往对其风险等级评估较高，很容易触发验证码、限制登录、访问被拒绝等情况。<br/>相比之下，住宅代理来自家庭网络，数量分散、来源自然，在平台风控模型中属于低风险类别，访问更稳定、更少被拦截。</p><h2>三、网络性能差异明显：速度和稳定性的取舍</h2><p>从硬件和网络环境来看，数据中心代理的速度通常远高于住宅代理。机房带宽往往以 Gbps 计，适合大量并发、大批量请求、低延迟任务。<br/>住宅代理由于依赖真实家庭网络，速度取决于具体用户的宽带情况，并且 IP 节点不固定，稳定性偶尔会受影响。<br/> 尽管如此，在许多企业级场景中，稳定的“用户级行为”比高速访问更重要，因为风控容错度更高。企业需要在速度和隐蔽性之间做选择，如果访问目标平台风控强，速度优势往往无法弥补识别风险。</p><h2>四、成本结构决定了价格差异</h2><p>数据中心代理的成本主要是服务器租赁和 IP 成本，因此价格低廉，可大规模、低成本使用。<br/>住宅代理则依赖大量真实用户设备参与节点网络，涉及设备激励、SDK 部署和多区域网络管理，成本更高，因此价格比机房代理贵数倍。<br/>这就是为什么住宅代理更贵，但仍是许多企业优先选择的原因——它解决的是“访问是否被允许”这个更关键的问题。</p><h2>五、适用场景：决定企业是否需要住宅代理的核心因素</h2><p>两类代理的适用场景差异非常明显。<br/>数据中心代理更适合需要大量并发和高速访问的任务，例如：<br/>●价格监控<br/>●大规模爬虫<br/>●CDN 和网络测试<br/>●SEO 数据抓取<br/>●高频 API 访问</p><p>这些任务对速度敏感，对“真实用户行为”不敏感，适合使用机房 IP。<br/>而住宅代理更适合需要模拟真实用户、风控敏感、地理测试要求高的场景，如：<br/>●跨境电商店铺管理<br/>●广告投放与验证<br/>●社交媒体多账号运营<br/>●不同国家的内容测试<br/>●高风控平台（如 App、票务、广告平台）<br/>●防屏蔽访问</p><p>在这些场景下，使用数据中心代理几乎必然导致验证码频发、账号风险增加甚至无法访问。</p><h2>六、风控风险差异：住宅代理的优势体现在长期稳定性上</h2><p>数据中心代理由于其来源特征，长期访问容易被平台列入高风险 IP 段，访问体验可能越来越差。<br/>住宅代理的优势则体现在长期的可持续性，平台难以对其进行大规模封禁，因为那等同于封禁普通用户。<br/>对于需要持续访问某平台的企业来说，住宅代理的长期稳定性往往才是最关键的价值。</p><h2>七、企业如何选择？三个关键问题决定方向</h2><p>企业在选择代理类型前，可以通过三个问题快速判断：<br/>第一，访问的平台风控是否强？如果强烈依赖用户行为（如社交媒体、电商平台），应优先考虑住宅代理。<br/>第二，任务是否需要高速大并发？如需持续高速抓取，数据中心代理更合适。<br/>第三，访问是否需要模拟真实用户？如果必须模拟真实环境或避免风控识别，住宅代理是必要选项。</p><h2>结语：两者没有绝对优劣，关键在于业务需求</h2><p>住宅代理和数据中心代理代表着两种完全不同的技术路径：<br/> 一种追求速度和规模，一种追求真实性和通过率。对于企业来说，正确的决策不是选最贵的那种，也不是选最快的那种，而是选择最符合业务目标的类型。<br/>随着全球互联网环境和风控体系不断发展，企业对住宅代理的需求正在持续上升，未来将成为更多智能业务、跨境业务的核心基础设施。</p>]]></description></item><item>    <title><![CDATA[精通射频电路设计：走进无线通信的核心 星]]></title>    <link>https://segmentfault.com/a/1190000047401475</link>    <guid>https://segmentfault.com/a/1190000047401475</guid>    <pubDate>2025-11-15 12:03:47</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在当今无线通信无处不在的时代，从智能手机、物联网设备，到雷达与卫星系统，射频（RF）电路设计都是支撑这一切的核心技术。它决定了信号能否高效、稳定地传输，是现代电子系统的“隐形引擎”。掌握RF电路设计，不仅意味着理解复杂的电磁世界，更是打开未来无线技术大门的关键。<br/><img width="723" height="487" referrerpolicy="no-referrer" src="/img/bVdm3r4" alt="" title=""/><br/>1、射频电路设计的本质<br/>射频电路是指工作在几千赫兹到数吉赫兹范围内的电路，它们是无线通信系统的核心单元。无论是接收端还是发射端，电路设计的每一个细节都直接影响到系统的整体性能。因此，设计师需要在性能、可靠性和灵活性之间找到理想的平衡。</p><p>2、面临的挑战<br/>RF电路设计最大的难点在于高频特性带来的复杂性。阻抗匹配、噪声控制、电磁干扰等问题，稍有疏忽就可能导致系统失效。与此同时，随着应用场景越来越广泛，电路必须在更高频率和更苛刻的条件下保持稳定工作，这对设计水平提出了极高的要求。</p><p>3、创新技术与设计方法<br/>面对这些挑战，工程师们发展出一系列创新设计方法。分布参数电路、阻抗匹配网络、射频滤波器等，都是保证电路性能的关键手段。而先进的仿真工具，则让设计师能够在虚拟环境中快速迭代、优化电路性能，从而大幅缩短设计周期并提升成果可靠性。</p><p>4、最佳实践路径<br/>优秀的RF电路设计不仅依赖理论知识，更需要在细节上追求极致。例如，合理选择器件参数、确保接地与屏蔽的正确性，以及全面的测试与验证流程，都是保证电路长期稳定运行的关键。只有在这些实践中积累经验，设计师才能不断提升自身的专业能力。</p><p>5、学习与成长的机会<br/>对于想要深入RF电路设计的工程师或学生来说，系统化学习与实践结合是最优路径。如果你正在寻找一个专业而全面的学习平台，EDA Academy（www.eda-academy.com）无疑是值得推荐的选择。</p><p>在 EDA Academy，你可以：<br/>学习海量最新、权威、系统化的在线课程，涵盖RF电路设计、IC设计及EDA工具应用；<br/>注册成为导师，将自己的专业经验转化为课程，与全球学习者分享；<br/>使用邮箱免费订阅newsletter，定期获取行业前沿知识和学习资料；<br/>加入销售联盟计划，通过推荐课程获得 20%-50%的佣金，实现学习与收益的双赢。</p><p>射频电路设计是一门挑战性极高的学科，但正是这些挑战造就了它的价值。只有不断学习、不断实践，才能真正掌握这项技术，推动无线通信的未来。如果你渴望快速提升自己的专业能力，不妨立即开启在 EDA Academy 的学习之旅，成为引领无线时代的设计者。</p>]]></description></item><item>    <title><![CDATA[飞牛 Nas 安装 Redis 和开启公]]></title>    <link>https://segmentfault.com/a/1190000047401492</link>    <guid>https://segmentfault.com/a/1190000047401492</guid>    <pubDate>2025-11-15 12:02:57</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>安装</h2><p><img width="723" height="428" referrerpolicy="no-referrer" src="/img/bVdm3se" alt="image.png" title="image.png"/></p><p>直接应用中心下载即可</p><h2>设置公网</h2><p>编辑 redis.conf,这里需要注意下 extra.conf 内部的配置，它会覆盖 redis.conf 中的配置。</p><pre><code class="shell">cd /var/apps/redis/etc/
vim redis.conf</code></pre><pre><code class="shell"># 支持 IPV6 和 IPV4
bind 0.0.0.0 ::
protected-mode no</code></pre><h2>重启服务</h2><p>直接应用中心，停用启用即可</p>]]></description></item><item>    <title><![CDATA[低代码架构的演进：从模型到执行的工程化与]]></title>    <link>https://segmentfault.com/a/1190000047401502</link>    <guid>https://segmentfault.com/a/1190000047401502</guid>    <pubDate>2025-11-15 12:02:16</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在近期的开源浪潮中，开发者社区再次展现出开放协作的力量。诸如 DeepSeek 等项目的出现，为国内技术生态提供了新的参照，也提醒我们：</p><blockquote><strong>当技术以开放为基础、以社区为土壤时，创新将获得更大的生长空间。</strong></blockquote><p>在这一背景下，低代码技术的研究与实践正在经历从“工具视角”向“软件工程方法论视角”的转变。</p><p><img width="723" height="976" referrerpolicy="no-referrer" src="/img/bVdm3st" alt="" title=""/></p><p>行业的关注点已不再局限于可视化开发界面，而更多聚焦于其背后的模型化能力、元数据体系以及运行时可塑性等关键议题。这些技术基础决定了低代码能否真正支持复杂业务、适应快速迭代，并在多场景中保持可演化性。</p><h2>模型驱动的软件构建：从表达方式到执行方式的统一</h2><p>当前低代码与模型驱动架构呈现出一个显著的趋势：开发者不再直接操作底层代码，而是通过抽象模型定义系统，通过运行时引擎动态解释和执行模型，形成所谓的“Model-to-Execution”闭环机制。这一 paradigm shift 不仅改变了软件开发的操作方式，也重新定义了系统的构建逻辑和工程管理方式。</p><p><img width="723" height="976" referrerpolicy="no-referrer" src="/img/bVdm3su" alt="" title="" loading="lazy"/></p><p>在该机制下，核心组件包括：</p><ul><li>模型（Model）：承担业务逻辑、界面布局与数据流转的抽象表达。模型不仅是一种设计工具，更是一种可执行的知识表示（Knowledge Representation），它将复杂业务逻辑与界面元素以高层语义封装，降低了开发者的认知负荷。</li><li>元数据（Metadata）：作为系统结构与语义的载体，元数据不仅描述系统对象、属性及其关系，还为模型的动态执行提供规则和约束信息，实现了系统的自描述性（Self-Descriptiveness）。</li><li>运行时引擎（Runtime Engine）：负责解析模型与元数据，将高层抽象转换为实际操作行为，实现界面渲染、数据流管理及业务逻辑执行。引擎可在系统运行时即时生效，支持动态修改与即时迭代，提供了系统的运行时可塑性（Runtime Adaptability）。</li></ul><h4>技术与工程价值</h4><p>这种架构的核心优势在于：系统能够摆脱传统编译—部署的周期依赖，实时响应业务需求的变化。它将软件从静态构建物转变为可塑性系统，使复杂项目在长期维护周期中仍能保持持续演化能力。具体表现为：</p><p><img width="723" height="384" referrerpolicy="no-referrer" src="/img/bVdm3sv" alt="" title="" loading="lazy"/></p><ul><li>开发效率与迭代加速：模型驱动减少了重复编码与低层实现的复杂度，开发者能够快速生成原型并进行业务验证。</li><li>可维护性与扩展性：高层抽象模型为系统提供了清晰的语义结构，降低了系统演化过程中的耦合风险，使模块化、组件化管理成为可能。</li><li>复杂系统管理：通过模型与元数据的统一描述，运行时引擎能够实现跨模块、跨业务的逻辑协调和数据一致性管理，提升复杂系统的可控性。</li><li>工程方法学创新：这种以模型为核心的范式，不仅适用于低代码场景，也为软件工程的持续交付（Continuous Delivery）、DevOps 自动化和敏捷开发提供了新的方法论基础。</li></ul><h2>开源协作与社区推动：从单点工具到技术生态</h2><p>低代码技术的真正价值不仅体现在单一工具的开发效率上，更依赖于开放、透明且可参与的生态环境。在这一生态中，社区的关注、反馈与协作作用，超越了简单的使用量增长，形成了技术演化的驱动力：</p><p><img width="723" height="367" referrerpolicy="no-referrer" src="/img/bVdg9cM" alt="" title="" loading="lazy"/></p><ul><li>方案验证与持续改进：社区成员可以对技术方案进行公开检视、讨论与比较，从而推动架构与功能的不断优化；</li><li>真实场景下的架构验证：开放环境允许模型体系、元数据结构与运行时机制在多样化应用场景中持续测试，确保技术方案的可行性与可靠性；</li><li>专业研究与实践深化：开发者围绕模型抽象、元数据表达及执行引擎的机制进行深入探索，从而推动低代码方法论的理论化与工程化发展。</li></ul><p>在这一过程中，开源不仅是一种发布形式，更是促进技术进步的基础设施。开放接口、可复用组件、标准化文档以及跨组织协作，构成了低代码生态形成的核心要素，为技术创新提供了稳健的制度保障和协同机制。</p><h4>未来发展重点</h4><p>为进一步增强生态建设与技术成熟度，未来发展可聚焦以下几个方向：<br/>运行时引擎性能与稳定性：通过优化执行效率与系统可靠性，实现大规模、复杂应用场景下的高效运作；</p><p><img width="723" height="517" referrerpolicy="no-referrer" src="/img/bVdhiLy" alt="" title="" loading="lazy"/></p><ul><li>模型语义的丰富性与扩展性：支持更高层次的业务逻辑表达和复杂数据关系建模，提高系统适应性与可重用性；</li><li>开放 API 与可插拔组件体系的完善：通过标准化接口与组件化机制，降低开发门槛，促进跨组织协作与技术复用；</li><li>教育与研究协作：与高校、研究机构及培训机构建立合作关系，推动软件工程模型化理念的普及与教学实践，形成理论与工程实践的闭环。</li></ul><h2>面向未来的软件工程：开放、协作与可塑性的持续推进</h2><p>低代码开发已成为现代软件工程的重要变革范式，正在重塑复杂系统的概念化、设计与实现方式。</p><p>与传统以代码为中心的开发模式不同，低代码平台强调模型驱动设计、基于元数据的执行以及运行时可调性，使开发者能够在更高层次的抽象下定义业务逻辑、用户界面和数据流。</p><p>这一转变不仅加快了开发流程，也提升了系统的可维护性和长期适应性，为大规模、持续演化的软件系统提供了有效解决方案。</p><p><img width="723" height="355" referrerpolicy="no-referrer" src="/img/bVdfI6b" alt="" title="" loading="lazy"/></p><p>同样重要的是，开放协作与社区驱动开发在低代码生态中扮演了关键角色。开源实践提供了持续反馈、迭代改进和集体验证技术方案的环境。</p><p>通过共享知识、复用组件和标准化接口，开发者和组织能够构建更加稳健、可扩展且适应性强的软件系统。</p>]]></description></item><item>    <title><![CDATA[vue3使用mitt事件管理 兔子先森 ]]></title>    <link>https://segmentfault.com/a/1190000047401573</link>    <guid>https://segmentfault.com/a/1190000047401573</guid>    <pubDate>2025-11-15 12:01:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>注册mitt</h2><p><code>main.ts</code>注册</p><pre><code>import { createApp } from 'vue';
import App from './App.vue';

// 导入mitt
import mitt from 'mitt';

const app = createApp(App);

app.config.globalProperties.$mitt = mitt();
app.mount('#app');</code></pre><p>封装管理器</p><pre><code>// 定义事件类型映射
export const mittEvents = {
  EVENT_TEST: 'event:test', // 测试事件
};

/**
 * 卸载监听事件
 * emit 只是触发事件，不涉及监听器的注册，所以只需要移除监听即可
 * @param mitt mitt实例
 * @param eventList 事件列表
 */
export const unloadMitt = (mitt: any, eventList: { eventName: string; callback?: (...args: any[]) =&gt; void }[]) =&gt; {
  eventList.forEach(({ eventName, callback }) =&gt; {
    if (callback) {
      mitt.off(eventName, callback);
    } else {
      mitt.off(eventName);
    }
  });
};</code></pre><p>定义事件类型映射的作用是用来做全局的事件映射和处理，如果你在页面中随意的派发和监听emit事件，会导致事件混乱，意图不明确，所以我们需要统一在某个位置集中管理事件，至少知道对应的事件的作用是什么。<br/>卸载监听事件的作用是用来卸载对某个事件的on监听，这是很关键的一步操作，如果不卸载的话可能会造成on事件的重复监听，下面我来详细说明一下：<br/>1、组件内使用mitt.on，在销毁组件时需要卸载，根据具名函数卸载<br/>2、页面级别的mitt.on也需要卸载，在onBeforeUnmount或者onUnmounted内卸载</p><h2>全局监听与卸载</h2><p>页面使用：<br/><strong>触发端</strong></p><pre><code>import { getCurrentInstance } from "vue; 
import { mittEvents, unloadMitt } from '@/utils/mittManage';

const { proxy } = getCurrentInstance() as any;

const onTest = () =&gt; {
  proxy.$mitt.emit(mittEvents.EVENT_TEST, { text: '发送事件' });
};</code></pre><p><strong>接收端</strong></p><pre><code>import { getCurrentInstance } from "vue; 
import { mittEvents } from '@/utils/mittManage';

const { proxy } = getCurrentInstance() as any;

proxy.$mitt.on(mittEvents.EVENT_TEST, (data: any) =&gt; {
  console.log('接收事件', data);
});</code></pre><p>使用的时候需要注意，<code>vue</code>的页面都可以看成是一个组件，如果组件 <code>渲染 -&gt; 卸载 -&gt; 渲染</code> （包括组件卸载、页面未<code>keep-alive</code>的跳转）后，<code>mitt.on</code>事件会被反复创建，如果你没有使用<code>mitt.off</code>卸载上一次的<code>mitt.on</code>监听的话，下一次渲染又会再次创建一个<code>mitt.on</code>监听，这样创建了多个<code>mitt.on</code>监听会导致同一个<code>mitt.emit</code>派发，<code>mitt.on</code>重复执行<br/>正确的做法是在你<code>mitt.on</code>的页面里，在<code>onBeforeUnmount</code>或<code>onUnmounted</code>生命周期内卸载对应的监听，比如这样：</p><pre><code>import { getCurrentInstance, onBeforeUnmount } from "vue; 
import { mittEvents, unloadMitt } from '@/utils/mittManage';

const { proxy } = getCurrentInstance() as any;

proxy.$mitt.on(mittEvents.EVENT_TEST, (data: any) =&gt; {
  console.log('接收事件', data);
});

// 卸载监听
onBeforeUnmount(() =&gt; {
  unloadMitt(proxy.$mitt, [{eventName: mittEvents.EVENT_TEST}]);
});</code></pre><p>这样，当你的页面卸载掉后，当前的监听也卸载了。<br/>注意：在上面的示例中，<code>mitt.on</code>是匿名函数监听，并且卸载时也仅提供了事件名，这会导致项目中所有对应的事件名一并卸载，如果你在不同的页面引入了相同的组件，在该组件内卸载了监听，会导致其它页面无法使用，因为监听被统一卸载掉了。</p><h2>只卸载当前组件监听（推荐）</h2><p>我们有时候需要把一个组件当成一个独立的环境，我们卸载监听时，只需要卸载当前组件的监听，不影响其它位置，此时可以用具名函数只移除当前组件的监听器，如下：</p><pre><code>import { getCurrentInstance, onBeforeUnmount } from "vue; 
import { mittEvents, unloadMitt } from '@/utils/mittManage';

const { proxy } = getCurrentInstance() as any;

const eventTest = (data: any) =&gt; {
  console.log('接收事件', data);

proxy.$mitt.on(mittEvents.EVENT_TEST, eventTest);

// 卸载监听
onBeforeUnmount(() =&gt; {
  unloadMitt(proxy.$mitt, [{eventName: mittEvents.EVENT_TEST, callback: eventTest}]);
});</code></pre><p>在事件系统中（如 <code>mitt</code> 或类似的事件总线），监听器的识别基于函数引用，而不是函数名或内容。<br/>使用具名函数时：</p><ol><li><code>eventTest</code>是一个固定的函数引用</li><li>每个组件实例都有自己的 <code>eventTest</code> 函数实例</li><li>使用 <code>mitt.off(eventName, event)</code> 可以精确移除特定的监听器函数</li><li>不会影响其他组件注册的监听器</li></ol><p>具名函数与匿名函数的区别</p><pre><code>// 匿名函数 - 每次都是不同的引用
() =&gt; {} === () =&gt; {} // false

// 具名函数 - 在同一作用域内是相同引用
function handler() {}
handler === handler // true

const handler2 = () =&gt; {}
handler2 === handler2 // true</code></pre><p>匿名函数：每次创建都是不同的函数实例，无法精确指定要移除哪一个<br/>具名函数：在同一作用域内保持相同的引用，可以精确指定要移除的监听器</p><p>这就是为什么使用具名函数并配合 mitt.off(eventName, event)可以只移除当前组件的监听器，而不会影响其他组件的原因。</p>]]></description></item><item>    <title><![CDATA[uniapp 下载网络pdf，并且打开 ]]></title>    <link>https://segmentfault.com/a/1190000047401319</link>    <guid>https://segmentfault.com/a/1190000047401319</guid>    <pubDate>2025-11-15 11:06:21</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>uniapp 下载网络pdf,或者后端返回的pdf链接，下载并且打开</p><pre><code>    downPDF() {
      uni.showLoading({ title: '下载中' });
      console.log('uni.env.USER_DATA_PATH', uni.env.USER_DATA_PATH);
      uni.downloadFile({
        url:
          'https://www.xxxx.com/static/xxx_static/MiniApp/static/test/test.pdf',
        success: res =&gt; {
          uni.getFileSystemManager().saveFile({
            tempFilePath: res.tempFilePath,
            filePath: `${uni.env.USER_DATA_PATH}/certificate_${Date.now()}.pdf`, // 目标路径（可选）
            success: res1 =&gt; {
              uni.showModal({
                title: '是否打开文件',
                content: '存储地址为' + res1.savedFilePath,
                showCancel: true,
                success: res2 =&gt; {
                  if (res2.confirm) {
                    uni.openDocument({
                      filePath: res1.savedFilePath,
                      success: res3 =&gt; {
                        console.log(res3, 'res3');
                      },
                    });
                  }
                },
              });
            },
            fail: err =&gt; {
              console.log(err, 'errrrrrr');
              uni.hideLoading();
            },
            complete: () =&gt; {
              uni.hideLoading();
            },
          });
        },
      });
    },</code></pre>]]></description></item><item>    <title><![CDATA[社区来稿丨RTE 大会带给我的 AI A]]></title>    <link>https://segmentfault.com/a/1190000047401323</link>    <guid>https://segmentfault.com/a/1190000047401323</guid>    <pubDate>2025-11-15 11:05:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>上周末参加了 RTE 的年度大会，听到一场让我印象深刻的分享。 讲者介绍了 TEN Framework 如何让一个 AI Agent 真正以系统级的方式运行。当 Agent 不再只是“跑模型”，而要面对真实世界的延迟、负载、协同、上线、监控……这就不再是算法问题，而是<strong> AI Agent Infrastructure </strong>的问题。虽然 TEN Framework 聚焦在 Voice Agent，但我觉得它对其他对实时性稳定性要求高的 AI Agent 项目的 <strong>Infra 架构</strong>都有参考价值，也希望同你分享。</p><p>这篇文章，我想聊聊我从这次演讲里得到的Agent Infra启发—— 包括 Runtime、模块化、测试与架构设计的思考；本文阅读大约需 6 分钟。</p><hr/><h2><strong>跨语言协同：用统一 Runtime，而非统一语言</strong></h2><p>现实中的 AI 系统从不单一。 推理在 Python，音视频在 C++，交互在 JS—— 每一次跨语言通信（IPC），都是延迟与性能的代价。</p><p>更好的思路，是构建一个能容纳多语言模块的统一 Runtime 层。 模块之间共享内存、共享状态，而非频繁“对话”。</p><p>这并不是炫技，而是一种更深层的设计哲学：</p><blockquote>不追求代码统一，而追求执行环境统一。</blockquote><p>这种“多语言互信”让团队既能保持语言多样性， 又能获得系统级的一致性与高效协同。</p><h2><strong>模块化积木：让复杂系统具备自我演化能力</strong></h2><p>一个真正工程化的 Agent Infra， 不该是一条死板的管线，而应是一组可以拼接的“积木”。每个功能（识别、生成、控制、存储）都应是独立模块， 能够被自由组合、复用和热插拔。</p><p>关键在于让每个模块具备三性：</p><ul><li>可组合（Composable）：像拼积木一样动态组装；</li><li>可扩展（Scalable）：能根据负载灵活伸缩；</li><li>可观测（Observable）：随时自报状态，便于监控与调优。</li></ul><p>当系统具备这三性后，Agent 不再是一个静态程序， 而是一套能自我调节、持续进化的动态生态。</p><p><strong>为什么不是微服务？</strong></p><p>很多人会问：既然都是多模块协同，为什么不直接用微服务？</p><p>表面上，微服务（Microservices）看起来完美： 模块独立、职责清晰、可横向扩展。</p><p>但问题在于——实时 AI 系统（尤其是语音、视频、多模态场景） 需要频繁传递流式数据与上下文状态。 这意味着：</p><ul><li>每一次调用都要序列化 / 反序列化；</li><li>每一个 RPC 都带来几十毫秒延迟；</li><li>每一层网络 hop 都可能打断上下文连续性。</li></ul><blockquote>微服务强调“隔离”，而实时 Agent 强调“同步”。</blockquote><p>结果就是：语音延迟上升、状态同步复杂、上下文频繁丢失。 因此，高实时要求的工程团队会选择另一种路径——<strong>用统一 Runtime 替代多进程架构。</strong></p><p><strong>微服务 vs Runtime 架构</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047401325" alt="" title=""/></p><p>微服务解决的是「组织级可维护性」， Runtime 追求的是「系统级响应速度」。</p><p>两者并不冲突，但适用于不同的目标空间：</p><ul><li>如果你要的是稳定、分布式、独立部署 → 选微服务；</li><li>如果你要的是实时、同步、多模态交互 → 选统一 Runtime。</li></ul><h2><strong>独立测试：让每个模块都能自己“活”</strong></h2><p>许多团队的痛点在于：要验证一个功能，必须跑整条 pipeline。 这让开发迭代极慢，也让模块复用变得困难。</p><p>真正的工程化思维是： 每个模块都应具备自己的测试入口与模拟上下文（mock environment）， 能够在独立运行时中完成自检、自愈。</p><p>这样的设计带来三重收益：</p><ol><li><strong>开发层面：</strong> 模块间解耦，可并行推进；</li><li><strong>质量层面：</strong> 错误可定位、可回放；</li><li><strong>运维层面：</strong> 生产 bug 可直接复现到单模块测试。</li></ol><p>这就像在系统里植入“单元级神经反射”——任何一块出问题，系统都能感知、修复、继续运转。</p><p>在和分享的 Halajohn 老师（TEN framework creator）的线下交流中，<strong>我提出了一个问题</strong>： “AI 系统的不可控性，意味着独立模块的测试可能无法捕捉链路级的漂移。当所有环节叠加起来，微小偏差可能被放大成系统级偏差。那么是不是，AI Agent 的整条链路测试应该比传统软件更‘频繁’，甚至要进化成一种持续性监控？”</p><p>Halajohn 老师认同确实会存在这个问题，并补充道：整条链路中除了模型部分，还有许多固定模块，这些部分完全可以进行独立测试。所以关键不是“要不要独立测”，而是——<strong>如何做好模块化，让能独立测试的部分尽量独立。</strong><em>*</em>*</p><h2><strong>模板与标准化：让 Infra 成为共享资产</strong></h2><p>模板化不是偷懒，而是让基础设施“长出形状”的过程。</p><p>一个好的 Agent Infra， 应该让开发者可以用模板快速生成标准模块： 模板中包含骨架代码、测试用例、接口协议、监控钩子。</p><p>这种 “Template + Test” 体系带来了三个好处：</p><ul><li>新人能一分钟上手；</li><li>团队能共享最佳实践；</li><li>Infra 本身能被复用与演化。</li></ul><p>模板让经验可视化，让复杂性被管理， 最终让整个团队的工程能力沉淀为可复用的资产。</p><p>AI Agent 的竞争不只在模型层，还在工程层。Runtime、模块化、测试、模板化——这些决定了一个系统能否“持续运行”，而不仅仅是“能运行”。  当然，不同场景下也会有不同的 Infra 选择。  我也很期待和正在阅读这篇文章的你，一起交流、碰撞更多的实践经验。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047401326" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047401327" alt="" title="" loading="lazy"/><br/><a href="https://link.segmentfault.com/?enc=igWNc2%2FbSvbJvFygsHE9Vg%3D%3D.f6jPnAxDNCChKcnhofAOZTtrJk09gU344F4rSHMAhjM%3D" rel="nofollow" target="_blank">阅读更多 Voice Agent 学习笔记：了解最懂 AI 语音的头脑都在思考什么</a></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047401328" alt="" title="" loading="lazy"/></p>]]></description></item>  </channel></rss>