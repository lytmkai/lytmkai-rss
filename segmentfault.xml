<?xml version="1.0" encoding="UTF-8"?><rss version="2.0">  <channel>      <title>SegmentFault - 最近文章</title>      <link>https://segmentfault.com/blogs/newest</link>      <description>SegmentFault 思否</description>      <generator>python segmentfault.py @Pi20</generator>      <item>    <title><![CDATA[如何在 Powershell 中使用 SMTP 发送邮件 ？ 本文系转载，阅读原文
https://]]></title>    <link>https://segmentfault.com/a/1190000047459799</link>    <guid>https://segmentfault.com/a/1190000047459799</guid>    <pubDate>2025-12-09 10:13:09</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000045456444" alt="Powershell Script for Sending Email via Remote SMTP" title="Powershell Script for Sending Email via Remote SMTP"/></p><p>发送电子邮件是系统管理员的一项基本任务。在本文中，我们将为您提供一个 PowerShell 脚本，通过远程SMTP 自动发送电子邮件。</p><p>下面是一个 PowerShell 脚本的具体内容，用于通过远程 SMTP 发送电子邮件。</p><pre><code># Define the sender, recipient, subject, and body of the email
$From = "sender@example.com"
$To = "recipient@example.com"
$Subject = "Test Email"
$Body = "This is a test email sent via remote SMTP using PowerShell."
 
# Define the SMTP server details
$SMTPServer = "smtp.example.com"
$SMTPPort = 587
$SMTPUsername = "username"
$SMTPPassword = "password"
 
# Create a new email object
$Email = New-Object System.Net.Mail.MailMessage
$Email.From = $From
$Email.To.Add($To)
$Email.Subject = $Subject
$Email.Body = $Body
# Uncomment below to send HTML formatted email
#$Email.IsBodyHTML = $true
 
# Create an SMTP client object and send the email
$SMTPClient = New-Object System.Net.Mail.SmtpClient($SMTPServer, $SMTPPort)
$SMTPClient.EnableSsl = $true
 
$SMTPClient.Credentials = New-Object System.Net.NetworkCredential($SMTPUsername, $SMTPPassword)
$SMTPClient.Send($Email)
 
# Output a message indicating that the email was sent successfully
Write-Host "Email sent successfully to $($Email.To.ToString())"</code></pre><h3>我的开源项目</h3><p><a href="https://link.segmentfault.com/?enc=AD%2Bj2EA9%2B46jBZUPKPM5bw%3D%3D.iTjbsBYdkq1BdwbmsPxIROTDeNnpzq8fTSPMXx9IIX4%3D" rel="nofollow" target="_blank"><img referrerpolicy="no-referrer" src="/img/remote/1460000043426502" alt="酷瓜云课堂-开源知识付费解决方案" title="酷瓜云课堂-开源知识付费解决方案" loading="lazy"/></a></p><ul><li><a href="https://link.segmentfault.com/?enc=z9tM5%2BJWfHJYfyeRCZQo%2Fg%3D%3D.gSc%2F%2FsVXPP4%2BYI4g0ZyxloiicqsJThqaXbTVemtmHZ5dH3tXSzQjMu8QZXlbIrMw" rel="nofollow" target="_blank">course-tencent-cloud（酷瓜云课堂 - gitee仓库）</a></li><li><a href="https://link.segmentfault.com/?enc=Bi0wGJskiNTsHgaAY1s22g%3D%3D.qI5cKWxoU1eUe7l2YVJ2mqkq23kgr%2B%2Bd8UxpDALmHNIHY56uPoKnyoCBxvxZxHLtVpoK2kcqCZRAOiGmyv3qQQ%3D%3D" rel="nofollow" target="_blank">course-tencent-cloud（酷瓜云课堂 - github仓库）</a></li></ul>]]></description></item><item>    <title><![CDATA[阁下 AI 多模型协同能力解析，有哪些方面？ 阁下AI ]]></title>    <link>https://segmentfault.com/a/1190000047459803</link>    <guid>https://segmentfault.com/a/1190000047459803</guid>    <pubDate>2025-12-09 10:12:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>阁下 AI 作为全球首个 AI 工具智能体平台，其多模型协同能力体现在五大核心维度，构建了超越单体模型的 "超级智能体" 系统：</p><p>一、异构模型智能整合  <br/>核心能力：无缝集成全球顶级大模型，构建 "模型联邦"  <br/>多元模型池：内置 NanoBanana Pro、Gemini3、DeepSeek 等 10 + 顶级大模型，覆盖语言理解、图像生成、代码编写等全领域能力  <br/>智能模型选择：通过自研 "意图解析引擎"，在 1 秒内分析用户需求，自动匹配合适模型组合  <br/>动态路由机制：根据任务复杂度、响应延迟和模型负载，智能分配请求，实现 "最强大脑" 与 "最适工具" 的精准匹配  <br/>技术实现：独创 "模型适配器" 技术，将不同模型接口统一标准化，实现 "一次调用、多模型响应"，避免用户手动切换的繁琐</p><p>二、任务智能拆解与流水线执行  <br/>核心能力：将复杂任务分解为原子操作，构建自动化执行链路  <br/>需求深度理解：将用户输入的自然语言需求（如 "制作产品发布会视频"）解析为完整的任务图谱，识别所需的文本创作、视觉设计、视频合成等子任务  <br/>工作流自动编排：像资深架构师一样，智能连接所需模型（如文案生成→视觉设计→视频合成），创建高效执行管道  <br/>执行节点无缝衔接：前一模型输出自动成为下一模型输入，全程无需人工干预，实现 "一键式" 全流程自动化  <br/>应用案例：用户创建 "照片修复上色" 工具时，系统自动串联图像识别、破损修复、色彩重建等模型，完成从模糊老照片到高清彩色图像的完美转换</p><p>三、多模态协同与融合推理  <br/>核心能力：打破模态壁垒，实现文本、图像、音频、视频的协同理解与创作  <br/>跨模态感知：支持多类型数据联合分析，例如：  <br/>上传菜品照片→AI 识别食材→生成食谱（图像 + 文本协同）  <br/>输入文字描述→生成对应场景图像→添加语音旁白（文本 + 图像 + 音频协同）  <br/>多模型交叉验证：对复杂问题，同时调用多个模型并行处理，通过结果比对生成可信度 &gt; 92% 的最终答案，降低单一模型误判风险  <br/>协同创作：实现 "你构思、AI 实现" 的全链路创作，如输入 "制作科幻风格产品海报"，系统自动协调文案模型、图像生成模型、排版模型共同完成作品</p><p>四、智能体协作系统  <br/>核心能力：构建 "AI 团队"，实现专业化分工与协作  <br/>角色化智能体：  <br/>总指挥智能体（Manager）：分析需求、规划任务、分配职责  <br/>专业技能智能体（Worker）：如文案专家、设计大师、数据分析员，各擅所长  <br/>记忆智能体（Memory）：保存对话历史和知识，确保上下文一致性  <br/>任务动态分发：根据实时负载和模型专长，将子任务精准分配给最合适的智能体，形成 "流水线式" 高效协作  <br/>执行监控与异常处理：协调智能体（Controller）实时监督执行进度，遇故障自动切换备用路径，确保任务完成率  <br/>应用实例：创建 "智能数据分析仪表盘" 时，系统自动安排：  <br/>数据智能体清洗整合多源数据  <br/>分析智能体生成可视化图表  <br/>报告智能体撰写分析结论  <br/>设计智能体美化界面，最终输出完整可交互的仪表盘</p><p>五、工具创造与自主扩展  <br/>核心能力：将 "模型能力" 转化为 "用户可用工具"，实现能力的指数级增长  <br/>自然语言驱动的工具生成：输入 "创建一个 AI 简历优化工具"，系统自动完成：  <br/>需求分析→界面设计→模型集成→代码生成→完整工具部署，全程无需编程  <br/>模型能力自由组合：像搭积木一样，将不同模型的能力（如文本生成 + 图像识别 + 数据可视化）组合成全新工具，满足用户独特需求  <br/>持续进化：系统通过用户反馈自动优化模型协作策略，使工具越用越智能，形成良性循环  <br/>价值提升：这种 "多模型协同 + 工具创造" 的模式，让用户不仅是 AI 功能的使用者，更成为 AI 能力的 "创造者"，将 AI 从单一服务升级为 "能力生产平台"</p><p>总结：阁下 AI 的多模型协同能力不是简单的 "模型叠加"，而是构建了一个有机智能体生态，让不同模型像交响乐团般协同演奏，将 AI 从 "单一工具" 升级为 "全能助手"。这种能力使阁下 AI 能够解决任何复杂度的任务，为用户提供 "所想即所得" 的终极 AI 体验，真正实现 "一个平台，解决所有智能需求" 的愿景。</p>]]></description></item><item>    <title><![CDATA[怎么申请免费SSL证书 冷姐Joy ]]></title>    <link>https://segmentfault.com/a/1190000047459835</link>    <guid>https://segmentfault.com/a/1190000047459835</guid>    <pubDate>2025-12-09 10:11:43</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h4><strong>一、什么是SSL证书？为什么你需要它？</strong></h4><p>简单来说，SSL证书是一个数字文件，它有两个核心作用：</p><ol><li><strong>数据加密</strong>：将你在网站上输入的密码、银行卡号等信息变成乱码，只有指定的服务器才能解密，确保传输过程中不被黑客窃取。</li><li><strong>身份验证</strong>：向访客证明你的网站是真实可信的，而不是一个仿冒的钓鱼网站。</li></ol><p><strong>拥有SSL证书的好处：</strong></p><ul><li><strong>提升安全性</strong>：保护用户和网站的数据。</li><li><strong>获取信任</strong>：浏览器地址栏会显示“锁”的标识，告诉用户此网站安全。</li><li><strong>利于SEO</strong>：谷歌等搜索引擎会给启用HTTPS的网站更高的搜索排名。</li><li><strong>满足合规要求</strong>：许多在线支付系统都要求网站必须使用HTTPS。</li></ul><h3>直接访问JoySSL，注册一个账号记得填写注册码230973获取免费证书。</h3><p><img width="614" height="404" referrerpolicy="no-referrer" src="/img/bVdisvl" alt="" title=""/></p><h4><strong>二、申请SSL证书的详细步骤</strong></h4><p>整个过程可以概括为：提交申请 -&gt; 验证身份 -&gt; 安装证书。</p><h5><strong>1. 选择类型并提交申请</strong></h5><p>根据你的需求，选择合适的SSL证书类型：</p><ul><li><strong>域名型DV</strong>：<strong>只验证域名所有权</strong>，申请最快，通常几分钟到几小时。适合个人网站、博客。</li><li><strong>企业型OV</strong>：<strong>需要验证企业真实性</strong>，地址栏会显示公司名称，信任度更高。适合企业官网。</li><li><strong>增强型EV</strong>：<strong>最严格的验证</strong>，地址栏会<strong>绿色显示公司名称</strong>，安全级别最高。适合银行、金融、电商平台。</li></ul><p><strong>选择证书颁发机构</strong>： 你可以从<strong>付费CA</strong>（如DigiCert）或<strong>免费CA</strong>（如JoySSL，Let‘s Encrypt）处获取证书。</p><ul><li><strong>免费推荐</strong>：提供免费的DV证书，非常适合个人和小型网站。许多主机商现已内置支持，一键即可申请。</li><li><strong>付费选择</strong>：如果需要OV或EV证书，或更长的有效期和专业的技术支持，则需购买付费证书。</li></ul><p>选定后，在证书服务商的网站上提交申请，并将上一步生成的<strong>CSR代码粘贴</strong>到指定位置。</p><h5><strong>2. 完成域名/所有权验证</strong></h5><p>提交申请后，CA需要确认你确实拥有这个域名。验证方式通常有三种：</p><ul><li><strong>DNS验证</strong>：按照CA的要求，在你的域名DNS解析中添加一条特定的TXT记录。<strong>这是最常见的方式。</strong></li><li><strong>文件验证</strong>：在网站的根目录下放置一个特定的验证文件。</li><li><strong>邮箱验证</strong>：向域名WHOIS信息中的管理员邮箱发送验证邮件。</li></ul><p><strong>完成验证后，CA就会审核并签发证书。</strong>  你会收到一个包含证书文件（通常是.crt或.pem格式）的邮件。</p><h5><strong>3. 安装到你的服务器</strong></h5><p>现在，你需要将收到的证书文件“安装”到你的网站服务器上。</p><ul><li><strong>对于虚拟主机用户</strong>：这通常非常简单。登录主机控制面板，找到“安装SSL证书”的选项，上传你收到的证书文件，很多主机商提供“一键安装”功能。</li><li><strong>对于VPS/独立服务器用户</strong>：你需要将证书文件和第一步生成的私钥文件上传到服务器指定目录，并在Web服务器（如Nginx, Apache）的配置文件中进行配置，然后重启服务。</li></ul><p><strong>安装成功后，访问你的网站，地址栏应该会出现一把“小锁”，URL也变成了 <code>https://</code> 开头。</strong></p><h4><strong>三、总结与后续</strong></h4><p>申请SSL证书的核心流程就是：<strong>生成CSR -&gt; 提交验证 -&gt; 安装生效</strong>。</p><p><strong>重要提醒：</strong></p><ul><li><strong>私钥安全</strong>：第一步生成的私钥是最高机密，一旦丢失或泄露，证书就失效了。</li><li><strong>注意有效期</strong>：SSL证书不是永久的（免费证书通常3个月，付费证书1年），<strong>务必在到期前续费或重新申请</strong>，否则网站会显示为“不安全”。</li></ul>]]></description></item><item>    <title><![CDATA[Gartner Magic Quadrant for Hybrid Mesh Firewall 20]]></title>    <link>https://segmentfault.com/a/1190000047459843</link>    <guid>https://segmentfault.com/a/1190000047459843</guid>    <pubDate>2025-12-09 10:10:45</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>Gartner Magic Quadrant for Hybrid Mesh Firewall 2025</p><p>Gartner 魔力象限：混合网格防火墙 2025</p><p>请访问原文链接：<a href="https://link.segmentfault.com/?enc=QiVN%2FqH3PwByY3rByt%2FMGA%3D%3D.9hrFRZjFGJ2vIACJOnEVYP29PswhsrhxJJEYKfSi2s1CWNeQ%2FyzH4jvU%2BXK%2FLOIGtT3DKwI0CeEfT%2B6R4IcI4Q%3D%3D" rel="nofollow" target="_blank">https://sysin.org/blog/gartner-magic-quadrant-firewalls-2025/</a> 查看最新版。原创作品，转载请保留出处。</p><p>作者主页：<a href="https://link.segmentfault.com/?enc=jheNQ7J7IOHSnJEJt7Ueww%3D%3D.8kMqLZICUV1sAd3yhUg1gsq0MhRgDbbEuFtS7iDd6Ik%3D" rel="nofollow" target="_blank">sysin.org</a></p><hr/><p>Gartner Magic Quadrant for Hybrid Mesh Firewall 2025</p><p>Published 25 August 2025</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459845" alt="Magic Quadrant" title="Magic Quadrant"/></p><h2>魔力象限</h2><p>Hybrid Mesh Firewall 魔力象限</p><p>25 August 2025</p><p>本魔力象限分析了 Hybrid Mesh Firewall（HMF），这些产品在硬件、虚拟与云部署中提供统一的云端管理。厂商可以利用本研究了解能够支持混合环境、具备高级 CI/CD 集成、原生云能力以及强大威胁防御的 HMF。</p><p><strong>市场定义/描述</strong>：</p><p>Hybrid Mesh  Firewall（HMF）是一种多部署模式的防火墙，包括硬件、虚拟设备和基于云的选项，并具有统一的云端管理平面。HMF  旨在通过提供成熟的持续集成/持续交付（CI/CD）管道集成、原生云集成，以及可扩展至 Internet of Things（IoT）设备和  DNS 攻击的高级威胁防御功能 (sysin)，以支持混合环境和不断演进的使用场景。</p><p>随着混合环境的普及，客户倾向于使用同一家防火墙厂商，通过集中管理和跨环境的策略可视性来简化管理并降低运维复杂性。因此，来自同一本地防火墙厂商的 Cloud Firewall 的需求和采用量正在增长。Hybrid Mesh Firewall  通过硬件、虚拟和专用云防火墙部署形式，以及基于云的集中可视化与管理能力，来支持这一场景。</p><p>Hybrid Mesh Firewall 支持多云和混合环境中的防火墙使用场景  (sysin)，包括数据中心、企业边界与分支办公室。它们提供高级威胁防御，例如 DNS security 和 IoT  security。CI/CD 集成以及与云原生控制集成的能力支持 Cloud Firewall  部署场景。基于云的集中管理器可对这些以不同形式（硬件/虚拟/云）部署在混合环境中的防火墙提供可视性与控制能力。</p><p><strong>必备功能</strong>（Mandatory Features）</p><ul><li>可由单一管理接口管理的硬件/虚拟与专用 cloud firewall 部署形式。</li><li>具备自动调优与策略推荐能力的云端集中管理器。</li><li>防火墙能力（状态检测、Secure Sockets Layer [SSL] 解密、URL filtering、app control、threat prevention）。</li><li>针对 IoT 和 DNS 攻击的高级威胁防御 (sysin)。</li><li>安全远程访问（例如 SSL VPN、IPsec VPN、zero-trust network access（ZTNA））。</li><li>CI/CD 集成。</li><li>与云原生基础架构的集成。</li></ul><p><strong>常见功能</strong>（Common Features）</p><ul><li>对云原生网络安全控制的集中可视性</li><li>Zero-touch 家庭办公防火墙设备</li><li>对云原生微分段控制的集中可视性</li><li>集中可视性以及微分段与第三方的集成</li><li>从集中管理平台中可选地编排 firewall as a service（FWaaS）</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459846" alt="Hybrid Mesh Firewall 魔力象限" title="Hybrid Mesh Firewall 魔力象限" loading="lazy"/></p><p><strong>领导者（Leaders）</strong>：（无变化）</p><ul><li>Palo Alto Networks</li><li>Fortinet</li><li>Check Point</li></ul><p><strong>挑战者（Challengers）</strong>：</p><ul><li>Juniper（HPE）</li></ul><p><strong>有远见者（Visionaries）</strong>：</p><ul><li>Cisco</li></ul><p><strong>特定领域者（Niche Players）</strong>：见图</p><p>查看完整报告（限期公开）：<a href="https://link.segmentfault.com/?enc=K0Mo4ypFy5y2Gse4sZKy8g%3D%3D.vU5NilhMsNM%2B%2B7GL26cquR3ClDpF9cax0hVqyqPvsCLjQzLeHM3S05D7apFotrDLD80WBsnpTfwvikN%2FKFkIdA%3D%3D" rel="nofollow" target="_blank">https://sysin.org/blog/gartner-magic-quadrant-firewalls-2025/</a></p><h2>如何选择</h2><p>主要技术市场上有哪些竞争参与者？他们如何为您提供长期帮助？Gartner  魔力象限是对特定市场的巅峰研究，可帮您广泛了解市场竞争对手的相对位置 (sysin)。利用图示法和一系列统一的评估标准，魔力象限可帮助您快速确定技术提供商执行其既定愿景的情况，并参照 Gartner  的市场观点了解其表现。</p><p><strong>如何使用 Gartner 魔力象限？</strong></p><p>面对特定投资机会考虑技术提供商时，请借助 Gartner 魔力象限迈出第一步。</p><p>请记住，专注于领导者象限不一定是最好的行动方案。有充分的理由考虑市场挑战者。特定领域者可能比市场领导者更能满足您的需求。这完全取决于提供商如何与您的业务目标保持一致。</p><p><strong>Gartner 魔力象限如何发挥作用？</strong></p><p>面对快速增长和提供商差异化明显的众多市场，Gartner 魔力象限用图形化方法划分出四类提供商：</p><ul><li>领导者很好地执行了当前愿景 (sysin)，并为未来做好了充分准备</li><li>有远见者了解市场发展方向，或者有改变市场规则的设想，但执行效果不尽如人意。</li><li>特定领域者成功专注于一个小的细分市场，或者目标不明确，创新和表现未能超越竞争对手。</li><li>挑战者当前表现很好，或者可能在大部分细分市场占据主导地位，但未表现出对市场方向的了解。</li></ul><h2>相关产品下载</h2><p>下载试用<strong>领导者</strong>产品：<a href="https://link.segmentfault.com/?enc=0bzsrItCi%2BrW8YogNKg4jA%3D%3D.loEegxZ4SoGvkS8LTWDElnX88zDzWztraV3xdtu2ObLWnRGGJbP%2ByBQmU%2BrKvPJE" rel="nofollow" target="_blank">Firewall 产品链接汇总</a></p>]]></description></item><item>    <title><![CDATA[告别“不安全”警告：一文读懂SSL证书部署全攻略 魁梧的松鼠 ]]></title>    <link>https://segmentfault.com/a/1190000047459850</link>    <guid>https://segmentfault.com/a/1190000047459850</guid>    <pubDate>2025-12-09 10:09:47</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>当您在浏览器中输入网址，期待看到熟悉的网站界面时，突然出现的红色“不安全”警告无疑令人不安。这个刺眼的提示不仅影响用户体验，更可能让潜在客户对网站的可信度产生怀疑。今天，让我们深入探究这一现象背后的原因，并系统性地解决SSL证书相关问题。</p><h3>为什么会出现“不安全”警告？</h3><p><img width="723" height="323" referrerpolicy="no-referrer" src="/img/bVdmVAD" alt="" title=""/></p><p>现代浏览器（如Chrome、Edge、Firefox）对网站安全性有着严格标准。当您访问一个使用HTTP而非HTTPS协议的网站，或HTTPS网站存在证书问题时，浏览器就会发出警告。这并非系统错误，而是浏览器在尽职提醒：您与该网站之间的连接可能被第三方窥探或篡改。</p><p>其核心原因主要围绕SSL/TLS证书：</p><ul><li>网站未安装SSL证书（仍使用HTTP协议）</li><li>SSL证书已过期（通常证书有效期为1年）</li><li>证书与域名不匹配（如证书为<a href="https://link.segmentfault.com/?enc=P%2FzoQYPWwCZ581QTR7tJdg%3D%3D.EeStXg%2BVXIsxlitFlR5oXipYfH%2FVRNdljeNfJeAj%2Bw4%3D" rel="nofollow" target="_blank">www.domain.com</a>，但访问的是<a href="https://link.segmentfault.com/?enc=0zHFN3waXYyOZlDz9yMMaQ%3D%3D.Z5xXYOum%2FUVYnybV9rkjknCFLUOCsGO1byPIqJZdUvE%3D" rel="nofollow" target="_blank">domain.com</a>）</li><li>证书由不受浏览器信任的机构签发</li><li>网站包含混合内容（HTTPS页面中引用了HTTP资源）</li></ul><h3>SSL证书：网络世界的“数字身份证”</h3><p>SSL证书好比网站的数字身份证，它通过加密技术在用户浏览器和网站服务器之间建立安全通道，确保传输数据（如登录凭证、支付信息）不被窃取或篡改。当浏览器检测到有效证书时，地址栏会显示锁形图标和“安全”字样，使用户安心访问。</p><h3>四步解决SSL证书问题</h3><h4>第一步：获取合适的SSL证书  <a href="https://link.segmentfault.com/?enc=BcHZMD0dOH7VE%2ByV2oLcDg%3D%3D.YZWjB7Zk5MM3fg8mZ%2FZurxizcJkoVQU8VW%2FphPE6li%2BvwNeiLLxpOC5yzTImFTNkQggzE%2BYd8uo9UlYZkBcYWJN%2F5YFu1OE2%2FfS6vU55hKM%3D" rel="nofollow" target="_blank"> 申请入口</a></h4><h4>获取SSL证书渠道：<strong><em>打开JoySSL证书官网，填写注册码230970获取技术支持</em></strong></h4><p>根据网站需求选择证书类型：</p><ul><li><strong>域名验证（DV）证书</strong>：基础加密，验证域名所有权，适合个人网站、博客</li><li><strong>组织验证（OV）证书</strong>：验证企业真实性，适合企业官网</li><li><strong>扩展验证（EV）证书</strong>：最高级别验证，地址栏显示公司名称，适合电商、金融机构</li><li><strong>通配符证书</strong>：保护主域名及其所有子域名</li><li><strong>多域名证书</strong>：单一证书保护多个不同域名</li></ul><h4>第二步：正确安装与配置证书</h4><ol><li><strong>生成CSR（证书签名请求）</strong> ：在服务器上生成包含网站信息和公钥的CSR文件</li><li><strong>提交CSR并验证</strong>：向CA提交CSR，按要求完成域名或组织验证</li><li><strong>安装证书</strong>：收到CA颁发的证书后，安装到服务器</li><li><strong>强制HTTPS重定向</strong>：修改网站配置，将所有HTTP请求重定向到HTTPS</li></ol><h4>第三步：排查混合内容问题</h4><p>即使启用了HTTPS，如果网页中引用了HTTP资源（如图片、脚本、样式表），浏览器仍可能显示“不安全”。使用浏览器开发者工具（F12）的“控制台”或“安全”选项卡，可识别混合内容。解决方案是更新所有资源引用为HTTPS或使用相对协议（如“//<a href="https://link.segmentfault.com/?enc=T2vGsSLkKkiZjfWYdkHRoQ%3D%3D.wcgMffwP6D2C%2FuX1Jbj%2FCMLa9Cxy2KdXtl03sEZoEOmWBjBDHvpFO2TfmXlXdaCT" rel="nofollow" target="_blank">example.com/resource.jpg”</a>）。</p><h4>第四步：验证与测试</h4><p>部署完成后，使用以下工具验证：</p><ul><li><strong>SSL Labs SSL Test</strong>（<a href="https://link.segmentfault.com/?enc=Mh0gaTKdrj6Y75%2Bdu6uSkQ%3D%3D.gCu20gdku6aVSZBVP6jV%2FS6Wr9IwCwB0lSykXP5Q3fs%3D" rel="nofollow" target="_blank">ssllabs.com/ssltest</a>）：全面检测证书配置和安全性</li><li><strong>浏览器开发者工具</strong>：检查安全状态和证书详情</li><li><strong>Why No Padlock</strong>（<a href="https://link.segmentfault.com/?enc=QzpRnOG4JWvN0pAZ4sd9EQ%3D%3D.gQDcLzEuX5le2wpaOAcbHY82t3K4toe7%2BcPIVQee464%3D" rel="nofollow" target="_blank">whynopadlock.com</a>）：专门检测混合内容问题</li></ul><h3>结语：安全是信任的基石</h3><p>解决HTTPS“不安全”警告不仅是技术调整，更是对访客安全的郑重承诺。在数据泄露频发的数字时代，一个简单的锁形图标代表着网站运营者对用户隐私的尊重和保护。投资SSL证书就是投资用户信任——这份信任，正是任何在线业务最宝贵的资产。</p><p>无论您是个人站长还是企业IT管理员，花少量时间部署和维护SSL证书，都将为您的网站访客构筑一道坚固的安全防线。在这个细节决定体验的时代，让每一处“安全”提示，成为您专业性与责任感的无声宣言。</p>]]></description></item><item>    <title><![CDATA[一文详细讲解CRM系统（附架构图、流程、功能、主流厂商） 程序员老叶 ]]></title>    <link>https://segmentfault.com/a/1190000047459852</link>    <guid>https://segmentfault.com/a/1190000047459852</guid>    <pubDate>2025-12-09 10:08:52</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>过去十年，企业花了巨额预算做广告投放、活动营销，却越来越常说一句话：<strong>“获客成本越来越高，成交率却上不去。”</strong>  <br/>问题往往不在流量，而在「管理」。于是，CRM（客户关系管理系统）从“小工具”升级成了很多企业的“增长中枢”。</p><p>这篇文章，我们用一篇长文，把 <a href="https://link.segmentfault.com/?enc=SXouU1uUZocImZg1UZq9yg%3D%3D.xnkDW37AkrjyB%2Brm9PYdtG6hK%2Fey8NgYOGeV3vrUOHZYCYhcUtCwfaIJRHTh7mbQ" rel="nofollow" target="_blank">CRM系统</a> 讲清楚：</p><ul><li>CRM系统 是什么、到底解决哪些问题？</li><li>一套 CRM 系统的<strong>典型架构图长什么样？</strong></li><li>从线索到回款，<strong>完整业务流程如何在 CRM 落地？</strong></li><li>一个成熟 CRM 应该包含哪些<strong>核心功能模块？</strong></li><li>市面上有哪些<strong>主流 CRM 厂商</strong>，适合什么阶段的企业？</li></ul><p>下面按逻辑顺序展开。</p><h2><img width="723" height="610" referrerpolicy="no-referrer" src="/img/bVdniC0" alt="image.png" title="image.png"/></h2><h2>一、什么是 CRM？为什么几乎所有公司都在用？🧭</h2><h3>1. CRM 的基本定义</h3><p>CRM（Customer Relationship Management），中文是<strong>客户关系管理系统</strong>。  <br/>一句人话概括：</p><blockquote><strong>CRM 就是把“人”的信息和整个成交过程系统化管理，帮企业用更低成本、更高效率地获得和留住客户。</strong></blockquote><p>从表面看，它是一个软件系统；  <br/>从本质看，它是企业对客户全生命周期管理的一套方法论与数据平台。</p><h3>2. CRM 解决的典型痛点</h3><p>在没有 CRM 的公司里，常见现象有：</p><ul><li>客户信息散落在：销售个人微信、Excel、钉钉群、邮箱里</li><li>老销售一离职，<strong>客户资源直接“人走客走”</strong></li><li>同一个客户，被不同销售<strong>重复电话打扰、体验极差</strong></li><li>线索来源不清楚，<strong>钱到底花在哪个平台最有效完全看感觉</strong></li><li>销售数据全靠人填日报、周报，领导看报表<strong>滞后又不准确</strong></li></ul><p>CRM 的核心就是解决这些问题，让客户和销售过程<strong>在线化、可追踪、可复盘、可优化</strong>。</p><h3>3. CRM 带来的核心价值</h3><p>用一句公式概括 CRM 的价值：</p><blockquote><strong>更多合格线索 × 更高转化率 × 更高客单价 × 更长客户生命周期</strong></blockquote><p>落到实际，可以拆成几类价值：</p><ul><li><strong>获客效率提升</strong>：打通官网、广告、表单、线下活动等，线索自动进入系统并分配</li><li><strong>销售转换率提升</strong>：统一销售流程、自动提醒跟进，减少“忘记跟进”和“乱跟进”</li><li><strong>管理可视化</strong>：领导随时看销售漏斗、预测业绩，调整策略有依据</li><li><strong>客户体验提升</strong>：客户资料和沟通记录完整沉淀，不再“你是谁、我们之前聊过吗？”</li><li><strong>组织抗风险能力提升</strong>：客户和业绩不再高度依赖某几位销售个人</li></ul><hr/><h2>二、CRM 系统架构图：从“流量入口”到“业务中台”🏗️</h2><p>为了更直观，先看一张抽象后的<strong>CRM 典型架构图</strong>思路说明（本文用文字+结构化方式来描述）：</p><hr/><h3>1. 经典 CRM 高层架构（逻辑示意）</h3><p>可以将 CRM 系统拆成四层：</p><ol><li><p><strong>渠道与触点层（最上层）</strong></p><ul><li>官网、落地页、表单</li><li>在线聊天工具（如网站 IM、WhatsApp 等）</li><li>电话、邮件、短信</li><li>广告平台（百度、Google、Facebook、抖音等）</li><li>线下展会、门店、活动</li></ul></li><li><p><strong>业务应用层（中间）</strong>  <br/>核心就是 CRM 的各业务模块：</p><ul><li>线索管理</li><li>商机 / 交易管理</li><li>客户（公司与联系人）管理</li><li>活动 / 任务管理</li><li>报价、订单、合同、回款管理</li><li>服务工单 / 客服管理（如果与服务模块整合）</li></ul></li><li><p><strong>数据与规则层</strong></p><ul><li>客户数据模型（客户、联系人、账户关系等）</li><li>业务规则（线索分配规则、审批流、计分规则）</li><li>自动化流程（工作流、邮件/短信自动触发）</li><li>报表与分析（销售漏斗、业绩预测、多维分析）</li></ul></li><li><p><strong>集成与平台层（底层）</strong></p><ul><li>与 <strong>邮件系统</strong>（如 Gmail、Outlook）集成</li><li>与 <strong>电话系统/呼叫中心</strong> 集成</li><li>与 <strong>财务/ERP</strong> 系统对接（同步订单、发票、回款）</li><li>与 <strong>营销自动化工具</strong>、表单工具、BI 工具等对接</li><li>API / Webhook 对外开放，支持定制开发</li></ul></li></ol><hr/><h3>2. CRM系统架构图</h3><p><img width="723" height="610" referrerpolicy="no-referrer" src="/img/bVdniC2" alt="image.png" title="image.png" loading="lazy"/></p><hr/><h2>三、CRM 里的完整业务流程：从线索到回款🔁</h2><p>理解 CRM，最重要的是看清一条主线：<strong>客户从“陌生”到“成交”再到“复购”的全过程</strong>。<br/><img width="723" height="616" referrerpolicy="no-referrer" src="/img/bVdniC4" alt="image.png" title="image.png" loading="lazy"/><br/>下面以典型 B2B 企业为例，把流程拆开讲。</p><h3>1. 线索获取与导入</h3><p><strong>入口很多，目标只有一个：让线索不再“散落各处”。</strong></p><p>常见来源：</p><ul><li>官网/落地页表单（自动写入 CRM 线索模块）</li><li>广告平台（通过 API 或表格导入）</li><li>线下活动/展会（扫描名片或 Excel 导入）</li><li>公众号/小程序留资（通过中间件或接口打通）</li><li>手工录入（如客户电话进来，前台/销售登记）</li></ul><p>在 Zoho CRM 这样的系统中，可以设置规则：</p><ul><li>自动识别来源渠道</li><li>自动打标签（比如“展会 XX”、“百度搜索”、“老客户转介绍”）</li><li>自动分配给对应团队或销售人员</li></ul><hr/><h3>2. 线索分配与跟进</h3><p>线索进来之后，下一步是：<strong>尽快分配给对的人，并开始跟进</strong>。</p><p>常见分配方式：</p><ul><li><strong>按区域</strong>：华东给 A 团队，华南给 B 团队</li><li><strong>按行业</strong>：教育、制造、互联网金融，各自有团队</li><li><strong>按来源</strong>：大客户渠道给资深销售，小 B 客户给电销团队</li><li><strong>轮询分配</strong>：按照顺序自动轮流分配，防止“抢资源”</li></ul><p>分配之后，销售在 CRM 中进行：</p><ul><li>拨打电话、发短信、发邮件（部分 CRM 支持系统内一键呼叫/发信）</li><li>记录沟通要点、客户需求、预算、时间计划</li><li>预约下次跟进时间，系统自动提醒</li></ul><p>这一步的目标：<strong>确认意向，进行初步资格评估</strong>。</p><hr/><h3>3. 线索转化为客户 + 商机</h3><p>当确认某个线索是“值得继续深度跟进的”，就会在 CRM 中做一次关键动作：<strong>转化（Convert）</strong>。</p><p>通常会自动生成：</p><ul><li>一个“客户（公司）”记录</li><li>对应的“联系人”记录（决策人/使用人等）</li><li>可选：一个“商机 / 交易”记录（包含预计成交金额、预计成交日期等）</li></ul><p>从这一刻起，这个对象已经不再是“海量线索池里的一条记录”，而是进入了<strong>正式销售流程</strong>。</p><hr/><h3>4. 商机阶段推进（销售漏斗）</h3><p>商机是 CRM 的“心脏”。  <br/>每一个商机，就像一条在漏斗里往下流的机会。</p><p>典型阶段包括（可按企业自定义）：</p><ol><li>初步接触</li><li>需求沟通</li><li>方案／报价</li><li>商务谈判</li><li>合同审批</li><li>成交 / 失单</li></ol><p>在 CRM 中，销售可以：</p><ul><li>更新商机阶段、金额、预计签单日期</li><li>记录每一次会议、拜访、Demo 结果等</li><li>附件上传：方案文档、报价单等</li><li>关联相关联系人（决策人、技术评审、财务等）</li></ul><p>系统则会：</p><ul><li>自动计算销售漏斗（不同阶段金额）</li><li>自动生成业绩预测（比如本月有多少可能成交）</li><li>自动识别卡在某阶段时间过长的商机，提醒处理</li></ul><hr/><h3>5. 报价、合同、订单与回款</h3><p>到了后期阶段，就会涉及到钱：<strong>报价、合同、订单、发货、回款</strong>。</p><p>在很多 CRM（包括 Zoho CRM）中，这一部分可以这样落地：</p><ul><li>在商机下直接生成<strong>报价单</strong>（可用产品目录、折扣规则）</li><li>报价需要审批时，走<strong>价格/折扣审批流程</strong></li><li>确认后生成<strong>销售订单 / 合同</strong></li><li>订单对接 ERP / 财务系统，完成<strong>发货、开票、回款记录</strong></li><li>回款数据回写到 CRM，形成完整闭环</li></ul><p>这样做有几个好处：</p><ul><li>销售不开“空头支票”，折扣有边界可控</li><li>订单和回款与商机一一对应，<strong>后续复盘“哪种客户更容易回款”</strong>有数据支持</li><li>财务、销售、运营看的是同一套事实数据</li></ul><hr/><h3>6. 售后与二次营销（客户成功）</h3><p>成交只是开始，长期价值在后面。  <br/>优秀的 CRM 还会延伸到：</p><ul><li><strong>服务/工单模块</strong>：记录客户问题、处理进度、满意度</li><li><strong>续费/增购提醒</strong>：按产品到期时间自动提醒销售或客服</li><li><strong>交叉销售 / 向上销售机会挖掘</strong>：通过数据分析识别潜在增购客户</li></ul><p>CRM 与客服系统、邮件营销工具、在线工单打通后，企业可以真正做到：</p><blockquote>从获客 → 成交 → 售后 → 续费 → 口碑转介绍的完整闭环管理。</blockquote><hr/><h2>四、CRM 核心功能模块全梳理📦</h2><p>下面系统地列一列，一套成熟 CRM 的典型功能构成。</p><h3>1. 客户与线索管理</h3><ul><li>线索管理：导入、分配、打分、去重、转化</li><li><p>客户管理：</p><ul><li>公司/账户（Account）</li><li>联系人（Contact）：职位、角色、决策权重</li><li>客户标签：行业、规模、阶段、等级（A/B/C）等</li></ul></li><li>历史记录：所有电话记录、邮件往来、会议、备注等</li></ul><h3>2. 销售过程管理（商机 &amp; 活动）</h3><ul><li><p>商机 / 交易管理：</p><ul><li>阶段设置与推进</li><li>预计签单金额、概率、日期</li><li>与产品/报价关联</li></ul></li><li><p>活动 &amp; 任务：</p><ul><li>电话、会议、拜访、跟进任务</li><li>待办提醒、日程安排、同步到日历</li></ul></li><li><p>销售节奏模板：</p><ul><li>标准化的跟进节奏（例如 T+1 电话、T+3 邮件等）</li></ul></li></ul><h3>3. 报价、订单、合同、回款</h3><ul><li>产品目录管理（SKU、价格、成本、税率）</li><li>报价单生成与审批</li><li>订单管理（可与库存、发货对接）</li><li>合同管理（合同版本、审批流、电子签集成）</li><li>发票与回款记录（可对接财务系统）</li></ul><h3>4. 自动化与工作流</h3><ul><li>线索自动分配规则（按来源、地区、行业、渠道等）</li><li>自动化跟进（例如：新线索 10 分钟未跟进自动提醒销售）</li><li>阶段变更触发动作（发邮件、创建任务、通知经理）</li><li>审批流（折扣审批、合同审批、费用申请）</li></ul><h3>5. 报表、仪表盘与预测</h3><ul><li>销售漏斗分析（不同阶段数量与金额）</li><li>业绩报表（按个人、团队、区域、产品维度）</li><li>渠道 ROI 分析（不同渠道线索转化与订单金额）</li><li>回款与逾期情况分析</li><li>业绩预测（预测本月/季度收入）</li></ul><h3>6. 协同与权限管理</h3><ul><li>团队协作：共享客户、@同事评论、分工跟进</li><li><p>权限控制：</p><ul><li>按角色控制可见字段和数据范围</li><li>敏感数据脱敏（如仅部分人员可看客户电话）</li></ul></li><li>审计日志：谁看了哪些数据、做了哪些修改</li></ul><h3>7. 集成与扩展</h3><ul><li>邮件集成（收发邮件自动关联到对应客户）</li><li>电话系统集成（弹屏、通话录音、通话记录）</li><li>表单工具、营销自动化、工单系统集成</li><li>ERP/财务/进销存对接</li><li>API、Webhook、自定义函数（支持二次开发）</li></ul><hr/><h2>五、主流 CRM 厂商盘点与对比（含 Zoho CRM）📊</h2><p>下面用一个简单表格，把主流 CRM 厂商做一个高层对比（侧重国内常见认知，并适度提及国际）。</p><blockquote>注意：具体功能适配、价格、实施模式等会随着时间调整，这里只做思路级概览。</blockquote><h3>1. 典型 CRM 厂商对比表</h3><table><thead><tr><th><strong>厂商</strong></th><th><strong>定位与特点</strong></th><th><strong>适合企业阶段</strong></th></tr></thead><tbody><tr><td><a href="https://link.segmentfault.com/?enc=oYya5Kz1YWOosWGBSikoLA%3D%3D.%2B4h3%2F9PvVlNHRTViQBkXE%2B%2BtIYROsvInbc14KVbIrQE%3D" rel="nofollow" target="_blank">Zoho CRM</a></td><td>全球化 SaaS CRM，功能全面、性价比高；支持销售+营销+客服一体化，生态产品丰富</td><td>中小企业、成长型企业、出海企业、注重性价比的团队</td></tr><tr><td>Salesforce</td><td>全球 CRM 龙头，平台能力极强，高度可定制，生态庞大，但价格与实施成本较高</td><td>中大型企业、跨国集团、有复杂流程和 IT 团队</td></tr><tr><td>Microsoft Dynamics 365</td><td>与 Office、Teams、Azure 深度集成，适合已大量使用微软生态的企业</td><td>中大型企业，尤其是已有微软体系的客户</td></tr><tr><td>HubSpot CRM</td><td>以入站营销著称，营销+销售+服务一体化，使用体验友好，对内容营销型公司很友好</td><td>中小企业、营销驱动的 SaaS 或服务企业</td></tr><tr><td>国内本土厂商（泛指）</td><td>针对本地业务场景优化，如本地化流程、对接本地 IM/企微/钉钉、电商等</td><td>各阶段企业，看重本地服务与本土生态</td></tr></tbody></table><p>（具体国内厂商如纷享销客、销售易、XTools、神州云动等，这里不逐一展开，可按行业选择落地经验多的厂商。）</p><h2><img width="723" height="548" referrerpolicy="no-referrer" src="/img/bVdniDB" alt="image.png" title="image.png" loading="lazy"/></h2><h3>2. 为什么很多成长型企业会选择 Zoho CRM？</h3><p>站在 Zoho CRM 市场视角，可以客观列一下自身在众多 CRM 里的位置：</p><ul><li><strong>全球化经验</strong>：在 150+ 国家有用户，对出海企业、跨国团队的多语言、多币种、多时区支持比较成熟</li><li><strong>模块覆盖全面</strong>：从线索、客户、商机，到报价、订单、回款，再到客服、项目，多模块打通</li><li><strong>高度可配置</strong>：字段、布局、流程、审批、自动化都可以配置，无需大量代码</li><li><strong>价格相对友好</strong>：相比部分国际巨头，成本压力更小，对中小和成长型企业更友好</li><li><strong>生态丰富</strong>：可与 Zoho 旗下其他产品（如营销自动化、工单、表单、BI 等）打通，形成一体化业务系统</li></ul><p>简而言之：<strong>不是“功能最贵最大”的那一类，而是“够用、好用、可扩展、性价比高”的那一类。</strong></p><hr/><h2>六、企业在选型 CRM 时应关注什么？🧩</h2><p>讲完系统和厂商，落到执行层面，很多企业真正的难点在于：<strong>“我家到底该选哪一个？”</strong><br/><img width="723" height="567" referrerpolicy="no-referrer" src="/img/bVdniC5" alt="image.png" title="image.png" loading="lazy"/><br/>这里给一个简洁的选型 checklist：</p><h3>1. 业务匹配度</h3><ul><li>是否支持你当前的销售模式？（To B / To C / 线下门店 / 渠道分销…）</li><li>是否能支持你“未来两三年”的业务形态？（比如从单一产品到多产品线、从国内到海外）</li></ul><h3>2. 易用性与落地难度</h3><ul><li>前线销售是否愿意用、用得顺手？  <br/>（界面复杂度、移动端体验、操作步骤等）</li><li>是否需要大量定制开发，还是配置就能满足大部分需求？</li></ul><h3>3. 集成能力</h3><ul><li>能否平滑对接现有系统？（财务、ERP、官网、表单、IM 等）</li><li>是否提供标准 API、是否有成熟的对接案例（尤其是你所在行业）</li></ul><h3>4. 成本与 ROI</h3><ul><li><p>不只是“许可证价格”，还包括：</p><ul><li>实施服务费</li><li>培训成本</li><li>内部运营人力投入</li></ul></li><li>是否支持先小规模试点，再逐步扩展？</li></ul><h3>5. 安全与合规</h3><ul><li>数据安全与隐私保护（加密、权限、日志）</li><li>是否符合所在地监管要求（如跨境数据、多地区存储等）</li></ul><hr/><h2>七、写在最后：CRM 不只是一个系统，更是一种运营思维✨</h2><p>很多企业上线 CRM 后有两种截然不同的结局：</p><ul><li>一种是：系统上了，没人用，最后变成“高价买来的高级 Excel”</li><li>另一种是：持续迭代管理流程，CRM 真正成为“企业增长中枢”</li></ul><p>区别往往不在软件本身，而在企业有没有把 CRM 当作一个<strong>持续运营工程</strong>：</p><ul><li>领导层是否重视，用 CRM 来对齐目标和过程？</li><li>销售、营销、客服团队有没有统一共识和规范？</li><li>是否有人负责长期优化字段、流程、自动化规则和报表？</li></ul><p>当你把 CRM 视作企业的“客户关系操作系统”，而不只是一个记录工具，它就会反过来推动组织的进步：</p><ul><li>从以“拍脑袋”决策 → 走向以数据决策</li><li>从“个人英雄主义” → 走向可复制的团队能力</li><li>从“单次成交” → 走向可持续的客户生命周期价值</li></ul><hr/><p>如果你正在考虑为团队搭建或升级 CRM，希望这篇「一文讲清」式的拆解，能帮助你更系统地理解：  <br/><strong>一套好的 CRM，应该长什么样、怎么跑起来、由谁来用好。</strong></p>]]></description></item><item>    <title><![CDATA[JoySSL一年期免费证书申请教程：手把手教你快速部署 追风的苦咖啡 ]]></title>    <link>https://segmentfault.com/a/1190000047459864</link>    <guid>https://segmentfault.com/a/1190000047459864</guid>    <pubDate>2025-12-09 10:08:22</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>JoySSL一年期免费证书申请与部署全攻略</h2><p>在2025年的今天，网络安全的重要性日益凸显。尽管许多云服务商已停止提供一年期的免费SSL证书，但国产自主品牌JoySSL依然为广大用户提供了安全可靠的选择。</p><h3>一、准备工作：注册账号与关键步骤</h3><p><img width="650" height="407" referrerpolicy="no-referrer" src="/img/bVdmdBK" alt="" title=""/></p><p>首先，打开浏览器访问 JoySSL官方网站。点击右上角的“注册”按钮创建新账户。<strong>请注意，这是整个流程中最为关键的一步</strong>：在注册页面的“邀请码”或“注册码”字段中，务必准确填写官方提供的特定代码（如 <code>230959</code>），这是解锁一年期免费证书申请权限的必要条件。完成信息填写后提交注册，并登录到您的新账户。</p><h3>二、选择并申请免费的SSL证书</h3><p>登录成功后，进入SSL证书选购页面。在众多证书类型中，找到标注为“免费一年期”或“政务版/教育版”的证书产品。根据搜索结果显示，JoySSL目前主要向个人站长、教育机构及非营利组织等用户提供此类免费资源。选择适合您网站性质的证书类型后，点击“立即申请”或“0元下单”。虽然系统会引导您走支付流程，但实际上不会产生任何费用，此举仅为形成正式订单。</p><h3>三、填写详细的申请信息</h3><p>接下来进入域名信息填报阶段。您需要精确输入希望保护的主域名（例如 <code>www.yourdomain.com</code>）。随后完善单位或个人资料，包括但不限于联系人姓名、联系电话以及有效的电子邮箱地址。所有带星号(*)的项目均为必填项，且直接影响后续验证环节能否顺利进行，因此请务必保证内容的完整性和准确性。</p><h3>四、验证域名所有权</h3><p>提交申请之后，系统会自动跳转至域名控制权验证界面。JoySSL提供了两种主流的验证方法供用户选用：</p><ul><li><strong>DNS记录解析验证</strong>: 根据后台提示添加一条特定的TXT记录或者CNAME记录到你域名的DNS设置里。完成后返回控制台点击我已操作按钮等待系统检测通过即可签发证书。该方法适用于绝大多数情况并且无需接触服务器文件更加便捷安全。</li><li><strong>服务器文件上传验证</strong>: 下载由系统生成的一个独一无二的文本文件并将其上传至你所管理网站的根目录下然后再通过访问特定路径来证明对该站点的操作权限以此完成校验过程。此方式对于那些熟悉FTP操作的用户来说也是一个可靠的备选方案。</li></ul><p>任选其一完成上述操作后静待片刻通常几分钟内就能收到邮件通知告知你的证书已经成功签发下来了！</p><h3>五、下载与安装SSL证书</h3><p>一旦证书签发成功便可前往JoySSL的用户后台查找对应的订单详情页从中下载包含完整密钥对及证书链压缩包的文件解压后根据自身使用的Web服务器环境挑选合适的配置文件进行安装即可常见的NginxApacheIIS等均有详尽的配置指引可供参考遵循标准化流程导入相应证书重启服务使改动生效最终实现整站HTTPS加密访问的目标达成！</p>]]></description></item><item>    <title><![CDATA[面向学科领域的网络信息资源深度聚合与服务研究_目录（qbit学习记录） qbit ]]></title>    <link>https://segmentfault.com/a/1190000047459873</link>    <guid>https://segmentfault.com/a/1190000047459873</guid>    <pubDate>2025-12-09 10:07:40</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>图书信息</h2><ul><li>《面向学科领域的网络信息资源深度聚合与服务研究》<br/><img width="345" height="441" referrerpolicy="no-referrer" src="/img/bVdniDt" alt="" title=""/></li><li>作者: <code>孙建军 等</code></li><li>出版社: <code>南京大学出版社</code></li><li>ISBN: <code>9787305252778</code></li><li><p>项目背景</p><pre><code>本书是国家社科基金重大项目“面向学科领域的网络信息资源深度聚合与服务研究”的结项成果，
孙建军教授是该项目的首席专家。</code></pre></li><li><p>内容简介</p><pre><code>书稿主要探讨学科发展尤其是人文社会科学研究在大数据时代的发展问题，
认为大数据的运用将进一步推动学术技术分析服务、数据服务的发展，
传统承担文献资料服务和普通信息服务的图书馆、情报服务机构等将向数据委托服务、计算分析服务转型。
随着人文社会科学数据的快速增长以及大数据分析技术的日益完善，
人文社会科学的大数据研究必然会成为人文社会科学的主流领域，
但不会替代现有的人文社会科学研究，而是相互补充，相得益彰。</code></pre></li><li><p>作者简介</p><pre><code>孙建军，博士，南京大学信息管理学院教授，院长。
主要研究领域为：信息经济、信息学教育、信息资源管理与网络计量。
全国核心期刊上发表专业文章120余篇，独著、参著、编、译书20余本。</code></pre></li></ul><h2><a href="https://segmentfault.com/a/1190000047459876" target="_blank">第一部分 概述</a></h2><h3>1 学科资源聚合与网络导航</h3><h2>第二部分 学术网络资源特征及利用</h2><h3>2 学术网络资源特征、分步及模式</h3><h3>3 学术网络资源利用特征——以我国人文社会科学领域为例</h3><h2>第三部分 学科网络资源采集与获取</h2><h3>4 学科网络资源采集与预处理</h3><h3>5 学科网络信息的集成</h3><h2>第四部分 学科网络资源深度标注</h2><h3>6 本体学习和资源深度标准理论基础</h3><h3>7 概念学习</h3><h3>8 关系学习</h3><h3>9 学科资源语义标注</h3><h2>第五部分 学科网络资源聚合</h2><h3>10 学科网络资源的主题聚合</h3><h3>11 学科网络资源的语义聚合</h3><h2>第六部分 学科网络资源导航机制及可视化</h2><h3>12 网络导航建设现状</h3><h3>13 学科网络导航认知行为特征及影响因素</h3><h3>14 学科网络资源导航改进与可视化</h3><blockquote>本文出自 <a href="https://segmentfault.com/blog/qbit" target="_blank">qbit snap</a></blockquote>]]></description></item><item>    <title><![CDATA[面向学科领域的网络信息资源深度聚合与服务研究——Part1（qbit学习记录） qbit ]]></title>    <link>https://segmentfault.com/a/1190000047459876</link>    <guid>https://segmentfault.com/a/1190000047459876</guid>    <pubDate>2025-12-09 10:07:03</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <blockquote>本文出自 <a href="https://segmentfault.com/blog/qbit" target="_blank">qbit snap</a></blockquote>]]></description></item><item>    <title><![CDATA[2026年CRM系统市场全景：5大趋势与7款主流产品深度解析 Python最棒 ]]></title>    <link>https://segmentfault.com/a/1190000047459888</link>    <guid>https://segmentfault.com/a/1190000047459888</guid>    <pubDate>2025-12-09 10:06:30</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>根据当前市场数据和行业预测，2026年CRM系统将呈现 <strong>AI深度整合、行业垂直化和SaaS主导</strong> 三大核心趋势。本文将从市场格局、技术趋势、厂商路线和选型建议四个维度进行解析，帮助企业构建中长期CRM规划。<br/><img width="723" height="579" referrerpolicy="no-referrer" src="/img/bVdniEa" alt="image.png" title="image.png"/></p><h2>一、2026年CRM系统市场格局</h2><p>全球CRM市场预计在2026年将突破 <strong>960亿美元</strong>，年复合增长率（CAGR）约 <strong>10.2%</strong>。  <br/>中国市场则在全球竞争格局下呈现本地化与国际化并行的特点。</p><h3>1. 全球与中国市场体量</h3><ul><li>全球市场规模：<strong>&gt;960亿美元（2026E）</strong></li><li>年复合增长率：<strong>10.2%</strong></li><li>SaaS模式成为主流交付形态，中国市场中本土厂商加速崛起</li></ul><h3>2. 主要厂商市场份额与优势（节选）</h3><p>下面是调整完「全球市场份额」和「中国市场份额」列顺序后的版本（仍然按中国市场份额由高到低排序），你可以直接整体替换原文对应表格👇</p><hr/><h3>2. 主要厂商市场份额与优势（节选）</h3><p>下表为部分典型CRM厂商在全球及中国市场的表现（按中国市场份额排序）：</p><table><thead><tr><th><strong>排名（中国）</strong></th><th><strong>CRM系统</strong></th><th><strong>中国市场份额</strong></th><th><strong>全球市场份额</strong></th><th><strong>核心优势</strong></th></tr></thead><tbody><tr><td>1</td><td><strong>Zoho CRM</strong></td><td><strong>25.18%</strong></td><td>5.3%</td><td>「全球化 + 本地化」策略，针对大中小企业提供差异化版本，覆盖营销、销售、服务全流程</td></tr><tr><td>2</td><td>Microsoft Dynamics 365</td><td>12.5%</td><td>18.2%</td><td>与微软生态（Office、Azure、Teams）深度集成，适合跨国集团及大型组织</td></tr><tr><td>3</td><td>Salesforce</td><td>8.3%</td><td>21.7%</td><td>AI驱动（Einstein AI）、全模块一体化解决方案，生态成熟</td></tr><tr><td>4</td><td>纷享销客</td><td>5.7%</td><td>-</td><td>连接型CRM，强化内外部协同，适配以渠道与终端管理为主的中型企业场景</td></tr></tbody></table><p><img width="723" height="584" referrerpolicy="no-referrer" src="/img/bVdniD4" alt="image.png" title="image.png" loading="lazy"/></p><h2>二、2026年CRM系统五大核心趋势</h2><p>2026年的CRM不再只是“客户信息管理系统”，而是逐步演变为 <strong>“智能增长中枢”</strong>。以下五大趋势将深刻影响产品形态与企业选型。<br/><img width="723" height="562" referrerpolicy="no-referrer" src="/img/bVdniD5" alt="image.png" title="image.png" loading="lazy"/></p><h3>1. AI深度整合 🤖</h3><ul><li><strong>智能决策普及</strong>：  <br/>预计 <strong>70% 以上的CRM系统</strong> 将内置智能决策引擎，用于线索评分、成交预测、客户流失预警等。</li><li><p><strong>典型厂商数据</strong>：</p><ul><li>Salesforce <strong>Einstein AI</strong>：销售预测准确率可达 <strong>82%</strong></li><li>Microsoft Dynamics 365 <strong>AI Agent</strong>：正在向“从线索到回款”的 <strong>全流程自动化</strong> 演进</li></ul></li></ul><h3>2. 行业垂直化加速</h3><ul><li>制造业、金融业、汽车等 <strong>高复杂度行业</strong> 的定制化需求明显上升。</li><li><p>行业案例：</p><ul><li><strong>SAP</strong> 在汽车行业市占率超过 <strong>30%</strong></li><li><strong>Zoho CRM</strong> 在制造行业服务宝马、华为、万达等大型客户，聚焦“营销+销售+服务”一体化场景</li></ul></li></ul><h3>3. SaaS主导市场</h3><ul><li>全球CRM <strong>SaaS渗透率已达 75%</strong></li><li><p>市场规模：</p><ul><li>2025年前后整体市场规模预计突破 <strong>960亿美元</strong></li><li>维持约 <strong>10.2%</strong> 的年复合增长率</li></ul></li><li>企业更倾向于订阅模式与按需扩容，以降低前期IT投入与运维成本。</li></ul><h3>4. 多模态交互成为标配 🎙️</h3><ul><li><p>支持 <strong>语音、视频、IM</strong> 等多通道融合交互：</p><ul><li>语音机器人与智能外呼系统，有效缓解传统电销“封号”“低接通率”等痛点</li><li>可视化、3D化数据分析界面逐步普及，管理层可通过“看图决策”</li></ul></li><li>客户沟通不再局限于电话与邮件，而是全渠道统一管理。</li></ul><h3>5. 数据安全与合规升级</h3><ul><li><strong>区块链</strong>：用于客户数据存证与追踪，保障数据不可篡改</li><li><strong>隐私计算</strong>：实现数据“<strong>可用不可见</strong>”，在不暴露原始数据的前提下进行联合分析</li><li><strong>信创市场</strong>：  <br/>中国信创CRM市场份额预计增长至 <strong>38%</strong>，国产替代与合规要求推动本土厂商快速发展。</li></ul><hr/><h2>三、7款主流CRM系统的2026发展路线</h2><p>以下为全球与中国市场具有代表性的7款CRM系统的产品发展重点梳理。</p><h3>1. Zoho CRM</h3><ul><li><p>持续打磨内置AI助手 <strong>Zia</strong>：</p><ul><li>提供智能推荐、自动记录、邮件建议等功能</li></ul></li><li><p>本地生态集成：</p><ul><li>深化与 <strong>微信、飞书</strong> 等中国本地生态的连接</li></ul></li><li><p>市场策略：</p><ul><li>主攻 <strong>大中企业市场</strong>，强调性价比与轻量部署</li></ul></li></ul><h3>2. Salesforce</h3><ul><li><p>持续强化 <strong>AI能力</strong>，重点聚焦：</p><ul><li>客服云（Service Cloud）</li><li>平台云（Platform Cloud）</li></ul></li><li><p>2025财年AI相关业务增长：</p><ul><li>客服云：<strong>+9%</strong></li><li>平台云：<strong>+19.5%</strong></li></ul></li><li><p>核心方向：</p><ul><li>预测分析（销售预测、流失预测）</li><li>自动化工作流（From Lead to Cash完整链路自动化）</li></ul></li></ul><h3>3. Microsoft Dynamics 365</h3><ul><li><p><strong>AI Agent</strong> 能力升级：</p><ul><li>从销售线索管理、订单创建到报告生成的 <strong>端到端自动化</strong></li></ul></li><li><p>与 <strong>Power Platform</strong> 深度整合：</p><ul><li>Power BI、Power Apps、Power Automate 联动，支持业务自助搭建与可视化分析</li></ul></li><li><p>新兴方向：</p><ul><li>扩展可持续发展模块，如 <strong>碳排放追踪</strong>、ESG数据管理</li></ul></li></ul><h3>4. Oracle CRM</h3><ul><li>战略重心：<strong>AI数据库 + 企业私有数据价值挖掘</strong></li><li><p>推出支持数据向量化的AI数据库：</p><ul><li>有利于在私有数据上构建专属智能助手和推荐引擎</li></ul></li><li><p>定位：</p><ul><li>“<strong>全球最大高价值私有企业数据托管方</strong>”，强化在大型集团与跨国企业的优势</li></ul></li></ul><h3>5. 销氪CRM</h3><ul><li>产品理念：<strong>AI驱动、主动获客</strong></li><li><p>核心能力：</p><ul><li>集成 <strong>3亿+企业线索数据库</strong></li><li>搭配智能外呼系统，解决电销“封号难”“效率低”问题</li></ul></li><li><p>适用场景：</p><ul><li>大规模电话获客、地推团队与电销团队为主的业务模型</li></ul></li></ul><h3>6. 超兔CRM</h3><ul><li><p>功能亮点：</p><ul><li><strong>AI跟单智能体</strong>，销售跟进效率提升可达 <strong>30%</strong></li></ul></li><li><p>技术架构：</p><ul><li>“<strong>一体云架构</strong>”打通CRM与进销存、生产系统，减少信息孤岛</li></ul></li><li><p>行业聚焦：</p><ul><li>专注 <strong>制造业解决方案</strong>，适用于订单复杂、生产周期长的企业</li></ul></li></ul><h3>7. 纷享销客</h3><ul><li><p>架构特点：</p><ul><li><strong>连接型架构</strong>，强化销售、服务、供应链之间的协同</li></ul></li><li><p>数据能力：</p><ul><li>提供 <strong>600+ API接口</strong>，打造企业级数据闭环</li></ul></li><li><p>客户群体：</p><ul><li>主要服务 中小型企业，适合强调“渠道+终端+总部协同”的组织。</li></ul></li></ul><hr/><h2>四、企业选型的4大关键建议</h2><p>在2026年的技术与监管环境下，CRM选型需要同时考虑 <strong>业务复杂度、组织规模、行业属性以及数据安全要求</strong>。<img width="723" height="628" referrerpolicy="no-referrer" src="/img/bVdniD6" alt="image.png" title="image.png" loading="lazy"/></p><h3>1. 按企业类型的选型建议</h3><ul><li><p><strong>跨国企业</strong></p><ul><li>优先考虑：<strong>Zoho CRM、Salesforce、Microsoft Dynamics 365</strong></li><li>理由：全球部署能力强，多语言多地区支持完善，与现有IT生态（Office、ERP等）集成成熟。</li></ul></li><li><p><strong>中国大中型企业</strong></p><ul><li>推荐：<strong>销氪CRM、Zoho CRM</strong></li><li>理由：兼顾本地化服务、国产化与信创要求，支持复杂流程与高度定制。</li></ul></li><li><p><strong>制造业企业</strong></p><ul><li>推荐：<strong>Zoho CRM、超兔CRM</strong></li><li>理由：更适配“订单—生产—交付—售后”的闭环场景，支持BOM、多工厂、多仓库等复杂业务模型。</li></ul></li><li><p><strong>中小企业</strong></p><ul><li>推荐：<strong>Zoho Bigin、HubSpot CRM</strong></li><li>理由：上手快、成本可控，适合以销售线索管理、简单流程自动化为主的团队。</li></ul></li></ul><h3>2. 实施与验证建议</h3><ul><li><p>在正式铺开前，建议进行 <strong>3–6个月的 POC（概念验证）</strong>：</p><ul><li>小范围试点：选取1–2个典型业务部门</li><li><p>验证内容：</p><ul><li>与现有系统（ERP、财务、人力）集成情况</li><li>关键流程（线索→商机→合同→回款）跑通程度</li><li>报表与管理看板是否满足日常运营与管理决策</li></ul></li></ul></li><li><p>特别关注：</p><ul><li><strong>数据安全与合规</strong>（尤其是涉及跨境数据、隐私数据时）</li><li><strong>二次开发与灵活性</strong>（未来业务变更的可适配性）</li><li><strong>使用体验与培训成本</strong>（销售与客服团队能否快速接受）</li></ul></li></ul><hr/><h2>五、结语：从“买CRM”到“设计增长系统”</h2><p>2026年的CRM将更加 <strong>智能化、行业化、平台化</strong>。  <br/>企业不应只从“买一个系统”的视角出发，而要将CRM视作 <strong>增长引擎与数据底座</strong>，围绕自身行业特性、组织结构与合规要求，规划中长期的系统与数据架构。</p><p>在明确业务目标和关键指标（如线索转化率、复购率、客单价、客户生命周期价值）的前提下，再依据本文的市场格局、趋势和产品路线进行选型，将明显降低试错成本，并提升数字化投入的ROI。</p>]]></description></item><item>    <title><![CDATA[面向学科领域的网络信息资源深度聚合与服务研究——Part2（qbit学习记录） qbit ]]></title>    <link>https://segmentfault.com/a/1190000047459903</link>    <guid>https://segmentfault.com/a/1190000047459903</guid>    <pubDate>2025-12-09 10:05:47</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>图书信息</h2><ul><li>《面向学科领域的网络信息资源深度聚合与服务研究》</li><li><p>项目背景</p><pre><code>本书是国家社科基金重大项目“面向学科领域的网络信息资源深度聚合与服务研究”的结项成果，
孙建军教授是该项目的首席专家。</code></pre></li><li>回<a href="https://segmentfault.com/a/1190000047459873" target="_blank">目录</a></li></ul><h2>第一部分 概述</h2><h3>1 学科资源聚合与网络导航</h3><h2>第二部分 学术网络资源特征及利用</h2><h3>2 学术网络资源特征、分步及模式</h3><h3>3 学术网络资源利用特征——以我国人文社会科学领域为例</h3><h2>第三部分 学科网络资源采集与获取</h2><h3>4 学科网络资源采集与预处理</h3><h3>5 学科网络信息的集成</h3><h2>第四部分 学科网络资源深度标注</h2><h3>6 本体学习和资源深度标准理论基础</h3><h3>7 概念学习</h3><h3>8 关系学习</h3><h3>9 学科资源语义标注</h3><h2>第五部分 学科网络资源聚合</h2><h3>10 学科网络资源的主题聚合</h3><h3>11 学科网络资源的语义聚合</h3><h2>第六部分 学科网络资源导航机制及可视化</h2><h3>12 网络导航建设现状</h3><h3>13 学科网络导航认知行为特征及影响因素</h3><h3>14 学科网络资源导航改进与可视化</h3><blockquote>本文出自 <a href="https://segmentfault.com/blog/qbit" target="_blank">qbit snap</a></blockquote>]]></description></item><item>    <title><![CDATA[面向学科领域的网络信息资源深度聚合与服务研究——Part3（qbit学习记录） qbit ]]></title>    <link>https://segmentfault.com/a/1190000047459910</link>    <guid>https://segmentfault.com/a/1190000047459910</guid>    <pubDate>2025-12-09 10:04:54</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>图书信息</h2><ul><li>《面向学科领域的网络信息资源深度聚合与服务研究》</li><li><p>项目背景</p><pre><code>本书是国家社科基金重大项目“面向学科领域的网络信息资源深度聚合与服务研究”的结项成果，
孙建军教授是该项目的首席专家。</code></pre></li><li>回<a href="https://segmentfault.com/a/1190000047459873" target="_blank">目录</a></li></ul><h2>第一部分 概述</h2><h3>1 学科资源聚合与网络导航</h3><h2>第二部分 学术网络资源特征及利用</h2><h3>2 学术网络资源特征、分步及模式</h3><h3>3 学术网络资源利用特征——以我国人文社会科学领域为例</h3><h2>第三部分 学科网络资源采集与获取</h2><h3>4 学科网络资源采集与预处理</h3><h3>5 学科网络信息的集成</h3><h2>第四部分 学科网络资源深度标注</h2><h3>6 本体学习和资源深度标准理论基础</h3><h3>7 概念学习</h3><h3>8 关系学习</h3><h3>9 学科资源语义标注</h3><h2>第五部分 学科网络资源聚合</h2><h3>10 学科网络资源的主题聚合</h3><h3>11 学科网络资源的语义聚合</h3><h2>第六部分 学科网络资源导航机制及可视化</h2><h3>12 网络导航建设现状</h3><h3>13 学科网络导航认知行为特征及影响因素</h3><h3>14 学科网络资源导航改进与可视化</h3><blockquote>本文出自 <a href="https://segmentfault.com/blog/qbit" target="_blank">qbit snap</a></blockquote>]]></description></item><item>    <title><![CDATA[面向学科领域的网络信息资源深度聚合与服务研究——Part4（qbit学习记录） qbit ]]></title>    <link>https://segmentfault.com/a/1190000047459915</link>    <guid>https://segmentfault.com/a/1190000047459915</guid>    <pubDate>2025-12-09 10:04:04</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>图书信息</h2><ul><li>《面向学科领域的网络信息资源深度聚合与服务研究》</li><li><p>项目背景</p><pre><code>本书是国家社科基金重大项目“面向学科领域的网络信息资源深度聚合与服务研究”的结项成果，
孙建军教授是该项目的首席专家。</code></pre></li><li>回<a href="https://segmentfault.com/a/1190000047459873" target="_blank">目录</a></li></ul><h2>第一部分 概述</h2><h3>1 学科资源聚合与网络导航</h3><h2>第二部分 学术网络资源特征及利用</h2><h3>2 学术网络资源特征、分步及模式</h3><h3>3 学术网络资源利用特征——以我国人文社会科学领域为例</h3><h2>第三部分 学科网络资源采集与获取</h2><h3>4 学科网络资源采集与预处理</h3><h3>5 学科网络信息的集成</h3><h2>第四部分 学科网络资源深度标注</h2><h3>6 本体学习和资源深度标准理论基础</h3><h3>7 概念学习</h3><h3>8 关系学习</h3><h3>9 学科资源语义标注</h3><h2>第五部分 学科网络资源聚合</h2><h3>10 学科网络资源的主题聚合</h3><h3>11 学科网络资源的语义聚合</h3><h2>第六部分 学科网络资源导航机制及可视化</h2><h3>12 网络导航建设现状</h3><h3>13 学科网络导航认知行为特征及影响因素</h3><h3>14 学科网络资源导航改进与可视化</h3><blockquote>本文出自 <a href="https://segmentfault.com/blog/qbit" target="_blank">qbit snap</a></blockquote>]]></description></item><item>    <title><![CDATA[面向学科领域的网络信息资源深度聚合与服务研究——Part5（qbit学习记录） qbit ]]></title>    <link>https://segmentfault.com/a/1190000047459924</link>    <guid>https://segmentfault.com/a/1190000047459924</guid>    <pubDate>2025-12-09 10:03:22</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>图书信息</h2><ul><li>《面向学科领域的网络信息资源深度聚合与服务研究》</li><li><p>项目背景</p><pre><code>本书是国家社科基金重大项目“面向学科领域的网络信息资源深度聚合与服务研究”的结项成果，
孙建军教授是该项目的首席专家。</code></pre></li><li>回<a href="https://segmentfault.com/a/1190000047459873" target="_blank">目录</a></li></ul><h2>第一部分 概述</h2><h3>1 学科资源聚合与网络导航</h3><h2>第二部分 学术网络资源特征及利用</h2><h3>2 学术网络资源特征、分步及模式</h3><h3>3 学术网络资源利用特征——以我国人文社会科学领域为例</h3><h2>第三部分 学科网络资源采集与获取</h2><h3>4 学科网络资源采集与预处理</h3><h3>5 学科网络信息的集成</h3><h2>第四部分 学科网络资源深度标注</h2><h3>6 本体学习和资源深度标准理论基础</h3><h3>7 概念学习</h3><h3>8 关系学习</h3><h3>9 学科资源语义标注</h3><h2>第五部分 学科网络资源聚合</h2><h3>10 学科网络资源的主题聚合</h3><h3>11 学科网络资源的语义聚合</h3><h2>第六部分 学科网络资源导航机制及可视化</h2><h3>12 网络导航建设现状</h3><h3>13 学科网络导航认知行为特征及影响因素</h3><h3>14 学科网络资源导航改进与可视化</h3><blockquote>本文出自 <a href="https://segmentfault.com/blog/qbit" target="_blank">qbit snap</a></blockquote>]]></description></item><item>    <title><![CDATA[KaiwuDB 跨模查询百倍性能提升背后的技术密码 KaiwuDB ]]></title>    <link>https://segmentfault.com/a/1190000047459928</link>    <guid>https://segmentfault.com/a/1190000047459928</guid>    <pubDate>2025-12-09 10:02:49</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在 AIoT、工业互联网场景中，类似"设备元数据（关系数据）+ 传感器数据（时序数据）"这样的联合查询是业务的重要需求之一。然而，在传统多库架构下，这类跨模查询往往意味着 "数据迁移 + 小时级等待"。KaiwuDB 创新自研的跨模优化技术，可将原本可能需要 5 小时的查询任务压缩至 64 秒，场景性能甚至能实现百倍的飞跃。今天就带大家一同探秘，深度拆解 KaiwuDB 跨模查询性能飞跃的核心技术。</p><h2><strong>先看结果------跨模查询的性能起飞</strong></h2><p>我们以能源管道网络物联网场景为测试基准，针对 3 个典型应用跨模优化的查询场景开展对比测试，具体结果如下：</p><p><img width="723" height="325" referrerpolicy="no-referrer" src="/img/bVdniEJ" alt="" title=""/></p><h3><strong>测试场景基础信息</strong></h3><p>本次测试涉及的数据源包括关系型数据库和时序数据库，具体表结构与数据量如下：</p><p><img width="723" height="810" referrerpolicy="no-referrer" src="/img/bVdniEL" alt="" title="" loading="lazy"/></p><h3><strong>测试查询场景 SQL 语句</strong></h3><pre><code class="SQL">Q2：
SELECT si.workarea_name,
       si.site_name,
       t.measure_type,
       time_bucket(t.k_collect_time, '10s') as timebucket,
       AVG(t.monitor_value) AS avg_value,
       MAX(t.monitor_value) AS max_value,
       MIN(t.monitor_value) AS min_value,
       COUNT(t.monitor_value) AS number_of_values
FROM monitor_r.site_info si,                              
     monitor_r.region_info wi,                                
     monitor_r.pipeline_info li,                                    
     monitor_r.point_base_info pi,                                      
     db_monitor.t_monitor_point t                                             
WHERE li.pipeline_id = pi.pipeline_id               
  AND pi.site_id = si.site_id                      
  AND si.region_id = wi.region_id          
  AND t.point_id = pi.point_id                            
  AND li.pipeline_name = 'pipeline_1'                  
  AND wi.region_name in ('work_area_1', 'work_area_2', 'work_area_3')  
  AND t.k_collect_time &gt;= '2023-08-01 01:00:00'     
GROUP BY si.workarea_name,
         si.site_name,
         t.measure_type,
         timebucket;
         
Q3：
SELECT si.site_name,
       COUNT(DISTINCT point_id) AS abnormal_point_count
FROM
     db_monitor.t_monitor_point t,
     monitor_r.pipeline_info li,                               
     monitor_r.site_info si                     
WHERE li.pipeline_id = t.pipeline_id                 
    AND t.site_id = si.site_id                      
    AND li.pipeline_name = 'pipeline_1'                
    AND t.monitor_type = 4                                   
    AND t.k_collect_time &gt;= '2023-08-01 00:00:00'
    AND t.k_collect_time &lt;= '2024-08-01 01:00:00'   
    AND t.monitor_value &lt; 0.5 * (
        SELECT AVG(t1.monitor_value) 
        FROM db_monitor.t_monitor_point t1                            
        WHERE t1.pipeline_id = li.pipeline_id        
          AND t1.monitor_type = 4)                           
GROUP BY
    si.site_name
ORDER BY
    abnormal_point_count DESC;
    
Q8：
SELECT ci1.sub_company_name,
       wi1.region_name,
       si1.site_name,
       t1.measure_type,
       time_bucket(t1.k_collect_time, '10s') as timebucket,
       AVG(t1.monitor_value) AS avg_value,
       MAX(t1.monitor_value) AS max_value,
       MIN(t1.monitor_value) AS min_value,
       COUNT(t1.monitor_value) AS number_of_values
FROM monitor_r.site_info si1,          
     monitor_r.site_info si2,                 
     monitor_r.region_info wi1,            
     monitor_r.region_info wi2,           
     monitor_r.company_info ci1,              
     monitor_r.company_info ci2,              
     monitor_r.pipeline_info li1,                
     monitor_r.pipeline_info li2,                
     monitor_r.point_base_info pi1,                   
     monitor_r.point_base_info pi2,                     
     db_monitor.t_monitor_point t1,                        
     db_monitor.t_monitor_point t2                         
WHERE li1.pipeline_id = pi1.pipeline_id                     
  AND pi1.site_id = si1.site_id                         
  AND si1.branch_id = ci1.branch_id  
  AND si1.region_id = wi1.region_id             
  AND t1.point_id = pi1.point_id                                  
  AND li1.pipeline_name = 'pipeline_1'                         
  AND wi1.region_name in ('work_area_1', 'work_area_2', 'work_area_3')  
  AND ci1.sub_company_name = 'sub_com_1'          
  AND li2.pipeline_id = pi2.pipeline_id                       
  AND pi2.site_id = si2.site_id                         
  AND si2.branch_id = ci2.branch_id  
  AND si2.region_id = wi2.region_id             
  AND t2.point_id = pi2.point_id                                
  AND li1.pipe_start_point = li2.pipe_start_point                           
  AND pi1.signal_type = pi2.signal_type                      
  AND pi1.signal_id = pi2.signal_id                    
  AND li2.pipeline_name = 'pipeline_4'                        
  AND wi2.region_name in ('work_area_7', 'work_area_8', 'work_area_9')  
  AND ci2.sub_company_name = 'sub_com_2'          
  AND t1.k_collect_time &gt;= '2023-08-01 01:00:00'      
  AND t1.k_collect_time = t2.k_collect_time                    
  AND t1.monitor_type = t2.monitor_type                 
  AND t1.monitor_value &gt; t2.monitor_value            
GROUP BY ci1.sub_company_name,
         wi1.region_name,
         si1.site_name,
         t1.measure_type,
         timebucket;</code></pre><h2><strong>"原生多模" 的独有优势</strong></h2><p>百倍级别的性能提升，绝非 "简单调优" 能实现 。其背后的密码是------KaiwuDB 通过<strong>跨模统计信息融合、跨模聚合下推、高速跨模连接算子</strong>这三项优化技术，把 "关系数据 + 时序数据" 的联合查询时间极致缩短。</p><p>目前一些支持 "多模" 的数据库选择的方案，是在关系库上套一个时序插件。这类方案的跨模查询，本质还是 "在关系库中模拟时序计算"，因此性能依然受限。而 KaiwuDB 凭借"原生双引擎 + 算子下推"的跨模性能优势，<strong>从架构层面实现了 "多模数据的存储协同 + 计算协同"</strong>：</p><p><strong>• 存储协同</strong>：时序/关系数据同节点、同实例存储；</p><p><strong>• 计算协同</strong>：算子下推到对应引擎，避免跨库/跨节点的数据移动。</p><h2><strong>KaiwuDB 多模的基础框架</strong></h2><p><img width="723" height="810" referrerpolicy="no-referrer" src="/img/bVdniEL" alt="" title="" loading="lazy"/></p><p>KaiwuDB 的<strong>多模框架是面向 AIoT 场景设计的 "统一 SQL 执行层 + 异构引擎融合 + 分布式协同" 架构</strong>，核心是在一个数据库实例内同时支持时序、关系等多类型数据的统一存储、计算与管理，避免"专库专用" 的复杂度。</p><h4>📌 统一的 SQL 执行层</h4><p>通过 KaiwuDB 客户端接收请求，对外提供标准 SQL 接口（兼容 PostgreSQL 语法），屏蔽多模数据的差异。</p><p>多模 SQL 处理：</p><p><strong>• 解析器</strong>：将 SQL 解析为抽象语法树，识别数据类型（时序 / 关系）；</p><p><strong>• 优化器</strong>：根据数据类型选择引擎（时序引擎 / 关系引擎），并将算子拆分为 "时序算子 + 关系算子"；</p><p><strong>• 执行计划生成与分片</strong>：按节点 / 数据类型生成分布式执行计划，通过 RPC 将子计划分发到对应节点。</p><h4>📌 分布式协同层（RPC stream）</h4><p>• 采用 RPC 作为统一通信协议，实现节点间（如 Node1 与 Node2/Node3）的执行计划分发、数据传输；</p><p>• 每个节点同时具备 RPCClient 和 RPCServer 能力，支持无中心对等通信，保证分布式场景下的多模计算协同。</p><h4>📌 多模存储引擎层（Storage Engine）</h4><p>在每个节点的 Storage Engine 中，集成两种核心引擎，实现多模数据的本地处理。</p><p><strong>• TS Executor + TS Store（时序数据存储引擎）</strong>：负责时序数据的存储与计算；对应架构图中的 "ts local run"，处理本地时序数据的写入/查询。</p><p><strong>• KV Store（关系数据存储引擎）</strong>：基于 MVCC 实现关系型数据的事务处理，采用 B + 树索引保证低延迟点查；处理关系型数据的增删改查，与时序引擎共享存储资源。</p><h2><strong>两大关键多模能力</strong></h2><h4><strong>✅ 多模数据统一管理</strong></h4><p><strong>• 统一存储</strong>：时序数据（如传感器数据）和关系数据（如设备元数据）存储在同一实例中，通过元数据服务区分数据类型；</p><p><strong>• 跨模计算</strong>：支持时序数据与关系数据的联合查询。如：按设备 ID（关系数据）查询某时段的传感器数据（时序数据），无需数据迁移。</p><h4><strong>✅ 自适应引擎协同</strong></h4><p><strong>• 引擎自动选择</strong>：SQL 优化器根据数据类型自动路由到对应引擎（时序数据→TS Store，关系数据→KV Store）；</p><p><strong>• 算子下推</strong>：将计算推近数据（即就地计算），如时序聚合算子直接下推到 TS Store 执行，避免全量数据传输；</p><p><strong>• 跨节点协同</strong>：通过 RPC 将多模算子分发到不同节点的引擎中执行，再汇总结果返回客户端。</p><h2><strong>跨模查询优化技术</strong></h2><p>为了提升跨模查询的性能，KaiwuDB 提出并应用了三种跨模查询优化技术：</p><p><img width="723" height="629" referrerpolicy="no-referrer" src="/img/bVdniER" alt="" title="" loading="lazy"/></p><h3><strong>1、 跨模统计信息和代价估算融合：让优化器"读懂"时序数据</strong></h3><p>传统优化器对时序数据的认知存在盲区，既不了解其"按时间有序存储"的特性，也无法精准掌握数据分布情况，导致生成低效执行计划。KaiwuDB 通过给优化器补充时序专属统计信息，实现了代价估算的精准化。</p><h4><strong>🛠️ 技术原理</strong></h4><p><strong>• 时序统计信息 "模式化"</strong>：给时序数据定义专属统计项（比如 "标签条数"、"某设备的聚合统计信息"、"某设备的时序数据条数"），并和关系数据的统计信息存在同一个元数据系统里；</p><p><strong>• 定制化统计规则</strong>：针对时序数据 "写密集、按时间有序" 的特点，创新统计项（比如 "聚合值预计算结果"）；</p><p><strong>• 自适应采集策略</strong>：即可手动收集时序数据统计信息，也可定时收集时序数据统计信息，tag 表会全量统计，metric 表粗量统计(精确统计表行数、预估列不同值与 null 值)，既保证精度又不占资源；</p><p><strong>• 代价估算融合</strong>：优化器同时参考关系数据和时序数据的统计信息，根据代价估算选择最优的连接顺序以及自动选择 "算子下推/高速连接" 等最优策略。</p><h4><strong>🎯 实战效果（Q1 场景）</strong></h4><blockquote>统计"pipeline_1"管道下，2023-2024 年间测量值低于同管道均值 50% 的异常监测点数量（按站点分组排序）</blockquote><p><strong>无优化流程</strong></p><p>因为不知道某型号设备的时序数据占比，与时序表的连接顺序不是最佳的，会先全量扫描时序表，再和关系表的型号做连接，产生大量的中间数据，导致计算慢，耗时 &gt; 5 小时；</p><p><strong>使用优化流程</strong></p><p>通过时序统计信息知道该型号设备的时序数据远多于关系表，会先让关系表进行连接后再与时序表进行连接，这样的话就减少了大量的中间结果，最终耗时 64 秒，<strong>性能提升 279.1 倍</strong>。</p><h3><strong>2、 跨模聚合下推技术：让计算"贴着"数据跑</strong></h3><p>跨模查询的核心痛点之一是数据在引擎间的无效传输，KaiwuDB 的解决方案是"将计算逻辑推至数据所在引擎，就地计算后再汇总"，从源头减少数据移动。</p><h4><strong>🛠️ 技术原理</strong></h4><p>KaiwuDB 的 SQL 引擎会做 "自底向上的下推判断" 机制：</p><p><strong>• 下推白名单</strong>：提前定义时序引擎支持的算子以及操作（比如 TS Store 支持时序聚合等）。</p><p><strong>• 场景化下推优化</strong>：</p><p>① 时间条件下推到时序表的时间索引，避免全表扫描；</p><p>② 聚合计算下推到时序表扫描阶段，减少中间数据；</p><p>③ 排序/窗口/limit 等算子，结合时序数据的有序性，直接下推到引擎层消除冗余计算。</p><h4><strong>🎯 实战效果（Q2 场景）</strong></h4><blockquote>"统计 2023-08-01 01:00 后，pipeline_1 管道下 work_area_1/work_area_2/work_area_3 作业区所有站点的时序数据：按作业区、站点、测量类型分组，以 10 秒为时间桶，计算每个时间桶内测量值的平均值、最大值、最小值及数据条数"</blockquote><p><strong>无优化流程</strong></p><p>① <strong>时序库全量扫描</strong>：从时序表 db_monitor.t_monitor_point 中读取 2023-08-01 01:00 后的所有数据（无前置过滤，仅按时间范围拉取）；</p><p>② <strong>全量数据传输</strong>：将海量原始时序数据从时序引擎传输到关系引擎（monitor_r 库），涉及大量网络 IO 和数据序列化/反序列化；</p><p>③ <strong>关系引擎多表关联</strong>：在关系引擎中依次关联关系表 ，筛选出 pipeline_1 管道 + 指定作业区的数据；</p><p>④<strong>关系引擎计算聚合</strong>：按作业区、站点、测量类型、10 秒时间桶分组，逐一计算平均值、最大值、最小值、数据条数，无预聚合优化。</p><p>无优化流程最终耗时 356,834 ms。</p><p><strong>使用优化流程</strong></p><p>时序引擎前置过滤 + 预聚合：</p><p>① <strong>将核心条件下推</strong>：把过滤条件"li.pipeline_name = 'pipeline_1' AND wi.region_name in ('work_area_1', 'work_area_2', 'work_area_3') AND t.k_collect_time &gt;= '2023-08-01 01:00:00'" 下推到时序引擎，先筛选出仅符合条件的测点数据；</p><p>② <strong>时序引擎就地聚合</strong>：利用时序表按 k_collect_time 有序存储的特性（时间索引），直接在时序引擎内按 10 秒时间桶、测点 sn 分组，提前计算每个时间桶的平均值、最大值、最小值、数据条数（避免原始数据传输）。</p><p>使用优化流程最终耗时 2,351 ms，<strong>性能提升 151 倍</strong>。</p><h3><strong>3、 高速跨模连接算子技术：用"数据裁剪"换"传输效率"</strong></h3><p>跨模连接的核心成本是 "数据在关系时序引擎间的传输量"------KaiwuDB 的高速连接算子，通过先计算数据量较少的关系数据，再将关系数据传输到数据量巨大的时序引擎中进行计算达到过滤数据量的目的，最终可以把需要传输的数据大量裁剪掉，以此提升效率。</p><h4><strong>🛠️ 技术原理</strong></h4><p><strong>• 自适应连接模式</strong>：通过优化器根据融合的统计信息和代价估算，自动选择是否使用高速连接算子以及连接顺序；</p><p><strong>• 先关系后时序</strong>：通常时序的数据是巨大的，先将关系数据在关系引擎进行计算，然后将结果数据传输到时序引擎中与时序数据进行连接再聚合；</p><p><strong>• 设备级并发</strong>：按设备维度拆分计算任务，多设备的连接/聚合并行执行。</p><h4><strong>🎯 实战效果（Q3 场景）</strong></h4><blockquote>在指定工作区、同一时间戳下的监测数据差异，按 10 秒窗口聚合统计</blockquote><p><strong>无优化流程</strong></p><p>① 两台设备的全量时序数据（如 4500 万条）传到关系库；</p><p>② 与 10 张关系数据做 join 连接；</p><p>③ 最后再做聚合。</p><p>无优化流程最终耗时耗时 1,606,706 ms。</p><p><strong>使用优化流程</strong></p><p>① 先通过跨模统计信息和代价估算，选择最优的连接顺序，将两张时序表放到最后再与关系表，同时选择高速连接算子；</p><p>② 在关系引擎先将 10 张关系表的数据进行计算；</p><p>③ 少量的结果数据传输到时序引擎进行连接再聚合（并发计算），大大减少了时序引擎向关系引擎传输的数据量。</p><p>使用优化流程最终耗时 7,398 ms，<strong>性能提升 216.2 倍</strong>。</p><h2><strong>性能提升的本质 ------让数据"少奔波"</strong></h2><p>从统计信息融合让优化器"选对路"，到聚合下推让计算"贴着数据跑"，再到高速连接算子"削减传输量"， KaiwuDB 三项跨模优化技术的核心逻辑始终一致------<strong>让计算尽可能靠近数据，将"跨库跨引擎的数据传输"转化为"引擎内的就地计算"</strong>。当数据不再需要跨引擎、跨节点"奔波"，自然能够实现从"查得出"到"查得快"的飞跃。</p>]]></description></item><item>    <title><![CDATA[专利战敲响警钟！数字孪生成规避研发风险的“创新试验场” 张老师讲数字孪生 ]]></title>    <link>https://segmentfault.com/a/1190000047458615</link>    <guid>https://segmentfault.com/a/1190000047458615</guid>    <pubDate>2025-12-09 10:02:13</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>2025年10月底，国内激光雷达行业爆发了一场引人瞩目的专利纠纷。头部企业禾赛科技正式起诉同行图达通，指控其新发布的“灵雀E1X”产品涉嫌侵犯多项专利。此案的一个焦点在于，图达通长期以来坚持1550纳米波长技术路线，但其新品却转向了禾赛占据优势的905纳米路线，且产品在接口设计、内部光路结构上存在高度相似性。</p><p>这场发生在图达通冲刺港股上市关键节点的诉讼，不仅关乎企业竞争，更尖锐地揭示了一个行业通病：在面临技术路线转型或市场竞争压力时，企业容易陷入模仿与创新的灰色地带，甚至遭遇核心技术的“卡脖子”风险。这场纠纷为所有高技术赛道敲响了警钟——自主创新与知识产权布局，已从发展问题演变为生存问题。<br/><img width="710" height="822" referrerpolicy="no-referrer" src="/img/bVdnijs" alt="" title=""/></p><p>那么，是否存在一种方法，能够在产品开发的早期阶段，就在虚拟世界中充分验证和迭代创新设计，从而规避后期的专利风险与试错成本？数字孪生技术正为此提供一种前瞻性的解决方案。它通过创建物理实体的高保真虚拟映射，构建了一个安全、高效的“创新试验场”。</p><p>数字孪生规避技术风险、加速正向研发，主要依托于三大技术原理实现：</p><ol><li>多源传感融合与高精度实时建模<br/> 构建与物理世界一致的数字孪生体，首要任务是高精度、高效率地获取三维空间信息。激光雷达（LiDAR）因其能直接获取海量的三维点云数据，成为核心传感器之一。</li></ol><p>一项基于激光雷达与图像融合的数字孪生实时建模方法，系统性地解决了此问题。其技术流程始于同步采集激光雷达点云、相机图像及惯性测量单元（IMU）数据。对点云数据进行降噪与分割，对图像进行去畸变与特征提取后，通过算法将两者融合配准。</p><p>这一过程可简化为一个数据关联优化问题：寻找最优的空间变换矩阵 T（包含旋转R和平移t），使得来自不同传感器的数据特征在统一坐标系下的误差最小。<br/>常用的配准算法如迭代最近点（ICP），其目标函数为：<br/><img width="308" height="84" referrerpolicy="no-referrer" src="/img/bVdnijz" alt="" title="" loading="lazy"/></p><p>其中，( p_i ) 和 ( q_i ) 分别是源点云和目标点云中的对应点。通过求解使 ( E ) 最小的 ( R ) 和 ( t )，实现精准对齐。融合后的数据通过即时定位与地图构建（SLAM）技术，能实时构建并动态更新三维环境模型，为后续仿真奠定几何与物理基础。<br/><img width="723" height="303" referrerpolicy="no-referrer" src="/img/bVdnijA" alt="" title="" loading="lazy"/></p><ol start="2"><li>云端智能处理与自适应数据净化<br/>激光雷达产生的点云数据量巨大，且包含大量背景噪声（如空气中的尘埃、雨雾反射），直接处理对算力要求极高。为了在保证精度的同时实现实时性，云边端协同的智能处理架构至关重要。在这一架构中，边缘计算节点负责第一轮数据预处理，执行如基于距离和密度自适应滤波（DDAF）的算法。</li></ol><p>该算法能根据点云中每个点与周围点的距离和分布密度，动态调整滤波阈值，有效剥离无关的背景噪声点，其核心思想可表述为对每个点 ( P_i ) 计算其局部密度 ( \rho_i ) 和最小距离 ( \delta_i )，并设定自适应阈值进行筛选。净化后的轻量化数据被上传至云端，利用更强大的深度学习模型进行进一步的特征提取、对象识别与场景语义分割，从而实现从原始数据到结构化知识的智能增强。<br/><img width="723" height="481" referrerpolicy="no-referrer" src="/img/bVdnijC" alt="" title="" loading="lazy"/></p><ol start="3"><li>高保真传感器仿真与虚拟验证<br/> 这是数字孪生赋能研发、规避专利风险最直接的环节。在构建好的高精度三维场景中，可以植入完全参数化的虚拟传感器模型进行仿真测试。例如，一个真实的激光雷达模型不仅会仿真其扫描方式（如旋转式或闪光式）、波长（905纳米或1550纳米），还能精确模拟激光在虚拟材料表面的反射特性、在不同天气条件（雨、雾）下的衰减模型，甚至多径传播效应。开发者可以在数字孪生环境中，自由地调整虚拟激光雷达的光路设计、扫描模式和信号处理算法，并对不同设计方案进行海量的、零物理成本的测试与对比。<br/><img width="723" height="410" referrerpolicy="no-referrer" src="/img/bVdm9co" alt="" title="" loading="lazy"/></li></ol><p>所有创新的技术细节，在投入昂贵的物理原型制造和专利申请之前，其性能与独特性已在虚拟世界中得到充分验证和优化。通过上述技术路径，数字孪生将产品研发的核心创新环节，前置并迁移到了虚拟空间。这实质上是将传统的“物理试错-迭代”模式，转变为“虚拟仿真-优化-验证”的新范式。企业可以在数字世界中穷尽各种设计思路，确保最终落地的物理方案不仅是创新的，而且是经过充分验证、知识产权清晰的最优解。<br/><img width="723" height="410" referrerpolicy="no-referrer" src="/img/bVdm9co" alt="" title="" loading="lazy"/></p><p>在这一领域，国内凡拓数创已展开实践。其自主研发的FTE数字孪生引擎，致力于为智慧城市、智能制造等领域提供高精度、可交互的数字孪生底座。该引擎通过了国产化信创适配认证，能够融合多源数据构建三维场景。例如，在智慧水务等项目中，通过构建覆盖全过程的数字孪生感知体系，实现对复杂系统的仿真、分析与优化。这种能力为工业装备、自动驾驶等领域的研发提供了一个可控、可溯的虚拟验证环境，辅助企业在数字空间先行探索技术边界，从源头上筑牢自主创新的防火墙。<br/><img width="723" height="332" referrerpolicy="no-referrer" src="/img/bVdnijF" alt="" title="" loading="lazy"/></p><p>归根结底，禾赛与图达通的诉讼是行业成熟化进程中一次不可避免的阵痛。它警示我们，真正的技术安全与产业主导权，不仅来自于对既有专利的尊重，更源于开辟新路径的能力。数字孪生，作为连接虚拟与现实的桥梁，正将这种“从零到一”的创造性过程，变得前所未有的高效与清晰。它或许不能直接平息专利战场上的硝烟，但却能为下一轮真正意义上的技术跃迁，准备好最先进的“创新工场”。</p>]]></description></item><item>    <title><![CDATA[面向学科领域的网络信息资源深度聚合与服务研究——Part6（qbit学习记录） qbit ]]></title>    <link>https://segmentfault.com/a/1190000047459932</link>    <guid>https://segmentfault.com/a/1190000047459932</guid>    <pubDate>2025-12-09 10:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>图书信息</h2><ul><li>《面向学科领域的网络信息资源深度聚合与服务研究》</li><li><p>项目背景</p><pre><code>本书是国家社科基金重大项目“面向学科领域的网络信息资源深度聚合与服务研究”的结项成果，
孙建军教授是该项目的首席专家。</code></pre></li><li>回<a href="https://segmentfault.com/a/1190000047459873" target="_blank">目录</a></li></ul><h2>第一部分 概述</h2><h3>1 学科资源聚合与网络导航</h3><h2>第二部分 学术网络资源特征及利用</h2><h3>2 学术网络资源特征、分步及模式</h3><h3>3 学术网络资源利用特征——以我国人文社会科学领域为例</h3><h2>第三部分 学科网络资源采集与获取</h2><h3>4 学科网络资源采集与预处理</h3><h3>5 学科网络信息的集成</h3><h2>第四部分 学科网络资源深度标注</h2><h3>6 本体学习和资源深度标准理论基础</h3><h3>7 概念学习</h3><h3>8 关系学习</h3><h3>9 学科资源语义标注</h3><h2>第五部分 学科网络资源聚合</h2><h3>10 学科网络资源的主题聚合</h3><h3>11 学科网络资源的语义聚合</h3><h2>第六部分 学科网络资源导航机制及可视化</h2><h3>12 网络导航建设现状</h3><h3>13 学科网络导航认知行为特征及影响因素</h3><h3>14 学科网络资源导航改进与可视化</h3><blockquote>本文出自 <a href="https://segmentfault.com/blog/qbit" target="_blank">qbit snap</a></blockquote>]]></description></item><item>    <title><![CDATA[剑指offer-47、求1+2+3...+n SevenCoding ]]></title>    <link>https://segmentfault.com/a/1190000047455319</link>    <guid>https://segmentfault.com/a/1190000047455319</guid>    <pubDate>2025-12-09 09:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>题⽬描述</h2><p>求 1+2+3+...+n ，要求不能使⽤乘除法、 for 、 while 、 if 、 else 、 switch 、 case 等关键字及条件判断语句（ A?B:C ）。</p><p>示例<br/>输⼊：5<br/>输出：15</p><h2>思路及解答</h2><h3>用for循环</h3><p>这个问题，如果直接使⽤ for 循环，超级简单，重拳出击，时间复杂度为 O(n) 。代码如下：</p><pre><code class="java">public class Solution {
    public int Sum_Solution(int n) {
        int sum = 0;
        for (int i = 1; i &lt;= n; i++) {
            sum += i;
        }
        return sum;
    }
}</code></pre><p>可是上⾯的明显违反了使⽤for 循环的原则</p><h3>乘除法</h3><p>试试公式法， 1+2+3+...+(n-1)+n = n * (n+1)/2 ,</p><pre><code class="java">public class Solution {
    public int Sum_Solution(int n) {
        if (n &gt;= 0) {
            return n * (n + 1) / 2;
        }
        return 0;
    }
}</code></pre><p>但是上⾯的做法，同样是使⽤乘法，也违反了原则，那么要不使⽤循环，也不适⽤乘法，怎么做呢？</p><h3>递归</h3><p>递归可以模拟出循环，⼏乎所有的for 循环操作，都可以以递归的⽅式实现。每⼀次递归，我们让n 减少1 ，直到减少为0 。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047455321" alt="" title=""/></p><pre><code class="java">public class Solution {
    public int Sum_Solution(int n) {
        if (n &gt;= 0) {
            return n + Sum_Solution(n - 1);
        }
        return 0;
    }
}</code></pre><ul><li>时间复杂度为O(n)</li><li>空间复杂度也是O(n)</li></ul><h3>位运算乘法</h3><p>位运算乘法法：通过位运算实现乘法操作</p><p>思路：将n(n+1)用位运算实现，然后右移1位代替除以2</p><pre><code class="java">public class Solution {
    public int sum(int n) {
        // 计算n*(n+1) using bit manipulation
        int result = multiply(n, n + 1);
        // 右移1位相当于除以2
        return result &gt;&gt; 1;
    }
    
    /**
     * 位运算实现乘法：利用俄罗斯农民算法
     * 原理：a * b = (a &lt;&lt; i)的和，其中i对应b中为1的位
     */
    private int multiply(int a, int b) {
        int result = 0;
        
        // 当a不为0时继续循环
        while (a != 0) {
            // 如果a的最低位是1，则加上对应的b值
            if ((a &amp; 1) != 0) {
                result += b;
            }
            // a右移1位，b左移1位
            a &gt;&gt;= 1;
            b &lt;&lt;= 1;
        }
        
        return result;
    }
    
    // 无循环的位运算乘法版本（符合要求）
    public int sumNoLoop(int n) {
        int res = multi(n, n + 1);
        return res &gt;&gt; 1;
    }
    
    private int multi(int a, int b) {
        int res = 0;
        // 通过多个位判断代替循环
        res += ((a &amp; 1) == 1) ? b : 0;
        a &gt;&gt;= 1;
        b &lt;&lt;= 1;
        
        res += ((a &amp; 1) == 1) ? b : 0;
        a &gt;&gt;= 1; 
        b &lt;&lt;= 1;
        
        // 继续处理更多位...（根据n的范围确定需要处理的位数）
        return res;
    }
}</code></pre><ul><li>时间复杂度：O(log n) - 取决于数字的位数</li><li>空间复杂度：O(1)</li></ul><p>案例解析：</p><pre><code class="text">计算 13 × 9:
13 = 1101(二进制)
9 = 1001(二进制)

13 × 9 = 13 × (1 + 0 + 0 + 1) 按位展开
       = (13&lt;&lt;0) + (13&lt;&lt;3) 对应9中为1的位
       = 13 + 104 = 117</code></pre>]]></description></item><item>    <title><![CDATA[AI巨头连夜亮剑，普通人如何抓住这波技术红利？ 曾经爱过的烤面包 ]]></title>    <link>https://segmentfault.com/a/1190000047459564</link>    <guid>https://segmentfault.com/a/1190000047459564</guid>    <pubDate>2025-12-08 23:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>阿里和华为同日放出技术大招，当行业格局被重新定义，掌握前沿技术不再只是工程师的特权。</p><p>阿里Ovis团队12月3日发布了文本渲染图像生成模型Ovis-Image，专门为高质量文本渲染优化，同时保持低计算成本。这一模型基于Ovis-U1构建，通过增加MMDiT参数和优化结构设计，采用以文本为核心的训练流程，结合大规模预训练与精心设计的后训练优化。</p><p>模型整体由三大核心组件精密咬合而成：作为大脑的Ovis 2.5多模态大模型负责构思；作为手的多模态扩散Transformer负责执行；来自FLUX.1-schnell的变分自编码器则负责视觉信息的压缩与解压，确保视觉特征的稳定性。</p><p>01 <br/>技术突破</p><p>在同一天，华为发布了 openPangu-R-7B-Diffusion，这一模型基于openPangu-Embedded-7B进行少量数据续训练，成功将扩散语言模型的上下文长度扩展至32K。</p><p>它在注意力机制上创新性地融合了自回归的前文因果注意力掩码，从架构层面解决了适配难题。训练策略上延续了BlockDiffusion的思路，但进行了关键优化，拼接带掩码的Block与无掩码的Context，展现出更强的适应性和效率。</p><p>阿里和华为在同一天发布多模态大模型重要进展，标志着AI技术竞赛进入新阶段。高质量文本渲染与长上下文处理能力的突破，正在重塑内容创作、设计、教育等多个行业的边界。</p><p>当技术门槛不断降低，应用场景却呈指数级增长，一个明显的趋势是：掌握这些技术不再局限于研究实验室里的少数专家。</p><p>02 <br/>变革</p><p>模型技术的进步正在产生连锁反应。Ovis-Image的低计算成本特性意味着中小企业和个人开发者也能使用高质量的文本渲染图像生成技术。</p><p>而华为的32K上下文长度突破，则为处理长篇文档、复杂对话和连续创作任务提供了可能。这两项进展共同指向一个方向：多模态AI正从炫技阶段走向实用化、普及化阶段。</p><p>行业变革的节奏超出了大多数人的预期。那些原本需要专业设计师数小时完成的工作，现在可能只需要几句文字描述；复杂的文档分析与生成任务，也能通过长上下文模型高效完成。</p><p>变革的核心逻辑在于，技术突破降低了专业门槛，但提高了应用广度。这意味着非技术背景的人士也有机会借助这些工具创造价值，前提是他们理解这些技术能做什么、不能做什么，以及如何将其融入工作流程。</p><p>03 <br/>技能</p><p>技术快速迭代的背景下，传统技能框架正在失效。过去，掌握单一技能可能足够应对职业挑战；现在，理解技术边界、能够跨领域整合的能力变得尤为重要。</p><p>市场对既懂技术原理又懂应用场景的人才需求急剧增加。企业需要的不再是纯粹的技术专家，而是能够将AI能力转化为实际解决方案的“桥梁型”人才。</p><p>AI技术普及带来了新的职业机会，但也对现有职业构成挑战。内容创作者需要学习如何与文本生成模型协作，设计师需要掌握图像生成工具的新特性。</p><p>产品经理则需要理解多模态技术的可能性与局限性，以设计出真正符合用户需求的产品。这些变化要求从业者保持持续学习的状态，不断更新自己的技能树。</p><p>04 <br/>学习</p><p>面对技术浪潮，系统化学习成为应对不确定性的最佳策略。专业课程的价值不仅在于传授知识，更在于提供经过验证的学习路径和实践机会。</p><p>随着阿里华为等技术巨头持续推进AI边界，行业对掌握多模态大模型应用能力的人才需求将持续增长。那些能够将最新技术转化为实际应用的专业人士，将在这个技术驱动的时代中获得独特优势。</p><p>系统化学习和实战训练为普通人提供了掌握前沿技术的可行路径。当技术门槛降低，理解并应用这些技术的能力将成为新的职业分水岭。行业变革的浪潮中，持续学习是抓住机会的最佳策略。</p><p>选择合适的学习路径，培养跨领域整合能力，普通人也能在这场技术革命中找到自己的位置。</p>]]></description></item><item>    <title><![CDATA[PyTorch推理扩展实战：用Ray Data轻松实现多机多卡并行 本文系转载，阅读原文
https]]></title>    <link>https://segmentfault.com/a/1190000047459515</link>    <guid>https://segmentfault.com/a/1190000047459515</guid>    <pubDate>2025-12-08 22:02:58</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>单机 PyTorch 模型跑推理没什么问题，但数据量一旦上到万级、百万级，瓶颈就暴露出来了：内存不够、GPU 利用率低、I/O 拖后腿，更别说还要考虑容错和多机扩展。</p><p>传统做法是自己写多线程 DataLoader、管理批次队列、手动调度 GPU 资源，这哥工程量可不小，调试起来也麻烦。Ray Data 提供了一个更轻量的方案：在几乎不改动原有 PyTorch 代码的前提下，把单机推理扩展成分布式 pipeline。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047459517" alt="" title=""/></p><h2>原始的 PyTorch 代码</h2><p>典型的推理场景：模型加载、预处理、批量预测，一套下来大概长这样：</p><pre><code> import torch  
import torchvision  
from PIL import Image  
from typing import List

class TorchPredictor:  
    def __init__(self, model: torchvision.models, weights: torchvision.models):  
        self.weights = weights  
        self.model = model(weights=weights)  
        self.model.eval()  
        self.transform = weights.transforms()  
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'  
        self.model.to(self.device)  
    def predict_batch(self, batch: List[Image.Image]) -&gt; torch.Tensor:  
        with torch.inference_mode():  
            batch = torch.stack([  
                self.transform(img.convert("RGB")) for img in batch  
            ]).to(self.device)  
            logits = self.model(batch)  
            probs = torch.nn.functional.softmax(logits, dim=1)  
             return probs</code></pre><p>处理几张图片完全没问题：</p><pre><code> predictor = TorchPredictor(  
    torchvision.models.resnet152,   
    torchvision.models.ResNet152_Weights.DEFAULT  
)

images = [  
    Image.open('/content/corn.png').convert("RGB"),  
    Image.open('/content/corn.png').convert("RGB")  
]  
 predictions = predictor.predict_batch(images)</code></pre><h2>大数据量</h2><p>图片数量从几张变成几万张、几百万张，情况完全不一样了。</p><p>内存撑不住，不可能把所有图一股脑塞进去；GPU 利用率上不去，多卡场景下吞吐量优化是个棘手的问题；万一跑到一半挂了怎么办？分布式部署能不能用上集群资源？还有个容易被忽视的点：数据加载的 I/O 往往才是真正的瓶颈。</p><p>自己从头写一套健壮的 pipeline 处理这些问题，少说得折腾好几天。</p><h2>Ray Data 的思路</h2><p>Ray Data 是个分布式数据处理框架，跟 PyTorch 配合得很好。关键是改造成本极低，原有代码基本不用大动。</p><p><strong>第一步：改造 Predictor 类</strong></p><p>把</p><pre><code>predict_batch</code></pre><p>方法换成</p><pre><code>__call__</code></pre><p>，输入从 PIL Image 列表改成包含 numpy 数组的字典：</p><pre><code> import numpy as np  
from typing import Dict

class TorchPredictor:  
    def __init__(self, model: torchvision.models, weights: torchvision.models):  
        self.weights = weights  
        self.model = model(weights=weights)  
        self.model.eval()  
        self.transform = weights.transforms()  
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'  
        self.model.to(self.device)  
    def __call__(self, batch: Dict[str, np.ndarray]):  
        """Ray Data passes a dict batch with numpy arrays."""  
        # Convert numpy arrays back to PIL Images  
        images = [Image.fromarray(img_array) for img_array in batch["image"]]  
        with torch.inference_mode():  
            tensor_batch = torch.stack([  
                self.transform(img.convert("RGB")) for img in images  
            ]).to(self.device)  
            logits = self.model(tensor_batch)  
            probs = torch.nn.functional.softmax(logits, dim=1)  
              
            # Get top prediction  
            top_probs, top_indices = torch.max(probs, dim=1)  
        return {  
            "predicted_class_idx": top_indices.cpu().numpy(),  
            "confidence": top_probs.cpu().numpy()  
         }</code></pre><p>改动点说明：</p><pre><code>__call__</code></pre><p>替代</p><pre><code>predict_batch</code></pre><p>；输入类型从</p><pre><code>List[Image.Image]</code></pre><p>变成</p><pre><code>Dict[str, np.ndarray]</code></pre><p>；方法内部把 numpy 数组转回 PIL Image；输出改成 dict 格式；结果要搬回 CPU（数据在进程间的移动由 Ray 负责）。</p><p>还有个细节要注意，Ray Data 用 numpy 数组而非 PIL Image，因为 numpy 数组跨进程序列化效率更高。</p><p><strong>第二步：构建 Ray Dataset</strong></p><p>根据场景选择合适的创建方式，小数据集直接从内存构建：</p><pre><code> import ray  
import numpy as np  

ray.init()  

# Convert PIL Images to numpy arrays  
images = [  
    Image.open("/path/to/image1.png").convert("RGB"),  
    Image.open("/path/to/image2.png").convert("RGB")  
]  

# Create Ray Dataset from numpy arrays  
 ds = ray.data.from_items([{"image": np.array(img)} for img in images])</code></pre><p>中等规模数据集推荐从文件路径延迟加载：</p><pre><code> # Create dataset from paths  
image_paths = ["/path/to/img1.png", "/path/to/img2.png"]  
ds_paths = ray.data.from_items([{"path": path} for path in image_paths])  

# Load images lazily  
def load_image(batch):  
    images = [np.array(Image.open(path).convert("RGB")) for path in batch["path"]]  
    return {"image": images}  

 ds = ds_paths.map_batches(load_image, batch_size=10)</code></pre><p>生产环境首选</p><pre><code>read_images()</code></pre><p>，Ray 全权接管：</p><pre><code> # Most efficient - Ray handles everything  
 ds = ray.data.read_images("/path/to/image/directory/")  
 # or with specific files  
 ds = ray.data.read_images(["/path/img1.png", "/path/img2.png"])</code></pre><p><strong>第三步：跑分布式推理</strong></p><p>核心代码如下：</p><pre><code> weights = torchvision.models.ResNet152_Weights.DEFAULT  

# Distributed batch inference  
results_ds = ds.map_batches(  
    TorchPredictor,  
    fn_constructor_args=(torchvision.models.resnet152, weights),  
    batch_size=32,  
    num_gpus=1,  
    compute=ray.data.ActorPoolStrategy(size=4)  # 4 parallel actors  
)  
# Collect results  
results = results_ds.take_all()  
# Process results  
for result in results:  
    class_idx = result['predicted_class_idx']  
    confidence = result['confidence']  
     print(f"Predicted: {weights.meta['categories'][class_idx]} ({confidence:.2%})")</code></pre><p>搞定了。新版 Ray 里</p><pre><code>concurrency</code></pre><p>参数已经废弃，要换成</p><pre><code>compute=ActorPoolStrategy(size=N)</code></pre><p>这种写法。</p><p>改动总结：</p><p>自动分批，Ray 自己决定最优 batch size；</p><p>分布式执行，多 worker 并行跑；</p><p>GPU 调度，自动把卡分配给 worker；</p><p>流式处理，数据在 pipeline 里流动，不用一次性全加载进内存；</p><p>容错机制，worker 挂了会自动重试。</p><h2>生产环境</h2><p>RAY还可以直接读云存储的数据，S3、GCS、Azure Blob 都支持：</p><pre><code> # Read directly from S3, GCS, or Azure Blob  
ds = ray.data.read_images("s3://my-bucket/images/")  

results = ds.map_batches(  
    predictor,  
    batch_size=64,  
    num_gpus=1,  
    concurrency=8  # 8 parallel GPU workers  
 )</code></pre><p>多节点集群也可以用同一套代码，10 台机器还是 100 台机器，根本不用改：</p><pre><code># Connect to your Ray cluster  
ray.init("ray://my-cluster-head:10001")  

# Same code as before  
ds = ray.data.read_images("s3://my-bucket/million-images/")  
results = ds.map_batches(predictor, batch_size=64, num_gpus=1)</code></pre><h2>进阶用法</h2><p>每个 batch 都重新加载模型太浪费了，用 ActorPoolStrategy 让模型实例常驻内存：</p><pre><code>from ray.data import ActorPoolStrategy  

results = ds.map_batches(  
    TorchPredictor,  
    fn_constructor_args=(torchvision.models.resnet152, weights),  
    batch_size=32,  
    num_gpus=1,  
    compute=ActorPoolStrategy(size=4)  # Keep 4 actors alive  
)</code></pre><p>这样吞吐量提升很明显。</p><p>CPU、GPU 资源可以细调</p><pre><code>results = ds.map_batches(  
    TorchPredictor,  
    fn_constructor_args=(torchvision.models.resnet152, weights),  
    batch_size=32,  
    num_gpus=1,  # 1 GPU per actor  
    num_cpus=4,  # 4 CPUs per GPU worker  
    compute=ActorPoolStrategy(size=8)  
)</code></pre><p>推理完直接写到云存储：</p><pre><code>results.write_parquet("s3://my-bucket/predictions/")</code></pre><h2>几个容易踩的坑</h2><p>Ray Data 没法直接序列化 PIL Image 对象，得先转成 numpy 数组：</p><pre><code># ❌ This will fail  
ds = ray.data.from_items([{"image": pil_image}])  

# ✅ This works  
ds = ray.data.from_items([{"image": np.array(pil_image)}])  

# ✅ Or use read_images() (best)  
ds = ray.data.read_images("/path/to/images/")</code></pre><p>Ray 2.51 之后</p><pre><code>concurrency</code></pre><p>不能用了：</p><pre><code># ❌ Deprecated  
ds.map_batches(predictor, concurrency=4)  

# ✅ New way  
ds.map_batches(predictor, compute=ActorPoolStrategy(size=4))</code></pre><p>batch size 太大容易 OOM，保守起见可以从小的开始试：</p><pre><code># Monitor GPU memory and adjust batch_size accordingly  
results = ds.map_batches(  
    predictor,  
    batch_size=16,  # Start conservative  
    num_gpus=1  
)</code></pre><h2>实践建议</h2><p>batch size 可以从小往大试，观察 GPU 显存占用：</p><pre><code># Too small: underutilized GPU  
batch_size=4  

# Too large: OOM errors  
batch_size=256  

# Just right: depends on your model and GPU  
# For ResNet152 on a single GPU, 32-64 works well  
batch_size=32</code></pre><p>ActorPoolStrategy 处理 20 张图大概要 9.7 秒，而原生 PyTorch 跑 2 张图几乎瞬间完成。所以图片量少的时候 Ray Data 的启动开销反而不划算，所以这个方案是几百上千张图的场景才能体现优势。</p><p>Ray 自带 dashboard，默认在 8265 端口：</p><pre><code># Check Ray dashboard at http://localhost:8265  
ray.init(dashboard_host="0.0.0.0")</code></pre><p>代码中可以包一层 try-except 防止单个样本出错拖垮整个任务：</p><pre><code>def safe_predictor(batch: dict):  
    try:  
        return predictor(batch)  
    except Exception as e:  
        return {"error": str(e), "probs": None}</code></pre><p>跑之前加个计时，可以进行性能 profiling：</p><pre><code>import time  

start = time.time()  
results = ds.map_batches(predictor, batch_size=32)  
results.take_all()  
print(f"Processed in {time.time() - start:.2f} seconds")</code></pre><h2>总结</h2><p>适合的场景：数据集太大内存放不下；需要多卡或多机并行；长时间任务需要容错；不想自己写分布式代码。</p><p>不太必要的场景：图片量在百张以内；数据集轻松塞进内存；只有一张卡而且短期内不打算扩展。</p><p>Ray Data 的好处在于迁移成本低。PyTorch 代码改动很小，换个方法签名、把数据包成 Ray Dataset，就能换来从单卡到多机的无痛扩展、自动 batching 和并行优化、内置容错、云存储无缝对接等功能。</p><p>如果你下次写多线程 data loader 或者手动管理 GPU pool 之前，可以先考虑一下这哥方法，把分布式系统的脏活累活交给 Ray，精力留给构建模型本身。</p><p><a href="https://link.segmentfault.com/?enc=6tu94Y5qIzEgz0bmdfip9A%3D%3D.ElinHbZyxfnmA0S2bINuFVYCzHXam4TMb9oA9MRhApxK67fZtC8Q7mI3BJAoanaCcTcy%2BQbtaqFdsK5BkPjNiA%3D%3D" rel="nofollow" target="_blank">https://avoid.overfit.cn/post/6320b9b6e1a14e0ba4c3384c83d06986</a></p><p>作者：Moutasem Akkad</p>]]></description></item><item>    <title><![CDATA[《Nginx在嵌入式场景的高效配置与运维逻辑》 程序员阿伟 ]]></title>    <link>https://segmentfault.com/a/1190000047459530</link>    <guid>https://segmentfault.com/a/1190000047459530</guid>    <pubDate>2025-12-08 22:02:09</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>轻量型Nginx的核心魅力，正在于打破“功能全量加载”的固有思维，通过对核心功能的聚焦与非必要模块的精准剥离，在有限的资源边界内实现高效稳定的服务输出。这种轻量并非妥协式的功能删减，而是基于场景需求的理性取舍，它要求部署者既要深刻理解Nginx的底层架构，清楚每个模块的功能定位与资源消耗，又要精准把握业务的核心诉求，明确哪些功能是不可或缺的，哪些是可替代或暂时不需要的。在长期的技术实践中，这种轻量部署思路不仅解决了边缘场景的实际痛点，技术工具的本质—工具的价值不在于功能的堆砌，而在于与场景的高度适配，这也是轻量架构在边缘计算、嵌入式系统等领域愈发普及的核心原因，更是技术人在复杂环境中寻求高效解决方案的必然选择。</p><p>轻量型Nginx的环境搭建，核心逻辑是“按需构建、资源适配”，这一过程最能体现技术人的取舍智慧与底层认知。不同于传统部署中“一键安装全量依赖”的便捷操作，轻量部署需要从源头把控每一个资源占用环节。首先要明确服务的核心定位，是仅提供静态资源分发，还是需要简单的请求转发、访问控制，不同的定位直接决定了依赖模块的选择。例如，若仅用于嵌入式设备的本地静态配置文件分发，便无需加载SSL、反向代理等模块，仅保留最基础的HTTP核心模块即可，这样能最大程度减少内存占用。在操作系统选择上，轻量部署更倾向于采用Alpine Linux、BusyBox这类精简版系统，它们剔除了普通Linux发行版中大量不必要的预装组件与服务，自身占用资源极低，能为Nginx预留更多运行空间。在依赖安装环节，需要逐一甄别每个依赖包的作用，比如编译依赖中的gcc、make等工具，在编译安装完成后便失去了存在的意义，可及时通过系统自带的包管理工具清理，进一步压缩环境体积；而pcre、zlib等核心依赖，也需选择轻量版本或仅编译必要功能，避免因全量安装带来的资源浪费。这种搭建方式看似繁琐，实则是对资源利用效率的极致追求，每一步操作都围绕“最小资源占用、最大功能输出”的目标，在实践中不断调试、优化，最终形成一套适配资源受限场景的高效部署流程。</p><p>配置环节是轻量型Nginx发挥效能的关键，其核心思路是“功能聚焦、性能适配”，拒绝无意义的配置项堆砌。轻量配置的本质是让每一项设置都有明确的场景指向，每一个参数都能对应具体的性能优化目标，避免因盲目照搬通用配置导致的资源浪费。在实践中，首先要基于业务场景确定配置重心：如果是静态资源服务，配置重点应放在资源缓存策略与传输效率上，比如根据资源类型设置差异化的缓存时长，静态图片、CSS等可设置较长缓存周期，而动态生成的静态文件则缩短缓存时间，同时优化传输模式，启用压缩功能减少数据传输量，降低带宽占用；如果是简单的请求转发场景，则需聚焦于连接管理与响应速度，合理设置连接超时时间，避免无效连接长时间占用资源，同时根据CPU核心数调整工作进程数，让每个进程都能充分利用硬件资源，避免进程过多导致的调度开销。此外，轻量配置还需充分考虑运行环境的资源上限，比如根据可用内存大小设置并发连接数，若内存仅有512MB，便不宜将并发连接数设置过高，否则会导致内存溢出；根据CPU性能调整请求处理模型，在单核CPU环境下采用单进程多线程模型，在多核环境下则可采用多进程模型，实现资源与性能的最佳平衡。这种配置思路要求部署者不仅要熟悉Nginx的配置选项，更要具备对系统资源的敏感度与把控力，在实践中通过反复测试、调试，找到最适合当前场景的配置方案，让轻量Nginx在有限资源下发挥出最优性能。</p><p>轻量型Nginx的动态适配能力，是其在复杂边缘场景中保持竞争力的核心优势，这种适配并非依赖复杂的插件或工具，而是源于对Nginx核心机制的灵活运用与对场景变化的快速响应。在实际部署中，业务需求往往会随时间推移发生变化，比如最初仅需提供静态资源服务，后续可能需要新增简单的API转发功能；或者原本低流量的服务，因业务推广出现阶段性流量峰值。此时，轻量环境的配置调整需要遵循“最小改动、精准扩容”的原则，在保留原有核心配置的基础上，按需添加必要模块与设置，避免因全面重构导致的资源浪费与稳定性风险。例如，当需要新增API转发功能时，无需重新编译安装Nginx，可通过加载轻量的反向代理模块，仅配置必要的转发规则与健康检查参数，即可实现功能扩展，同时避免加载其他无关模块；当流量出现阶段性增长时，可通过调整工作进程数、连接池大小等参数，在不增加额外硬件资源的前提下提升处理能力，若流量峰值持续时间较短，还可设置临时配置文件，峰值过后自动恢复原配置，避免资源长期占用。在实践中，我曾遇到过边缘网关因业务扩展需要新增访问控制功能的场景，最初考虑加载复杂的权限管理模块，但测试后发现会增加近30%的内存占用，后来通过利用Nginx核心配置中的基础规则，结合IP白名单与简单的请求头校验，同样实现了精准的访问控制，且资源占用几乎无明显增加。这种动态适配的思路，核心是“以最小的资源代价满足变化的需求”，它要求部署者深刻理解Nginx的配置逻辑与模块特性，能够快速定位功能扩展的核心关键点，在实践中不断积累调整经验，形成一套灵活高效的适配方法论。</p><p>长期运维中的“轻量坚守”，是保障Nginx环境持续高效运行的关键，这种坚守并非墨守成规，而是在日常维护中始终保持对资源占用与功能冗余的警惕。轻量环境的运维核心是“持续优化、动态清理”，因为即使初始配置再精简，随着业务迭代与环境变化，也可能出现冗余配置、无效模块占用资源的情况。在日常运维中，我会定期对Nginx环境进行“资源体检”，重点关注内存占用、CPU使用率、连接数等核心指标，通过系统自带的监控工具（文字描述功能，无代码）观察资源变化趋势，若发现内存占用持续上升，会逐一排查是否存在未清理的临时配置、冗余模块或无效连接。例如，曾在一次运维中发现，某边缘设备的Nginx内存占用在一周内增长了20%，排查后发现是之前测试时添加的日志模块未及时禁用，该模块会实时记录详细日志，导致内存持续累积，禁用后内存占用迅速恢复正常。日志管理也是轻量运维的重点，默认的日志配置会记录大量冗余信息，不仅占用存储空间，还会增加IO开销，因此我会根据实际需求设置日志级别，仅保留错误日志与核心访问日志，同时配置日志轮转策略，定期压缩归档旧日志，避免日志文件过大占用资源。此外，对于不再使用的模块，我会及时通过编译工具卸载，避免其在后台占用系统资源，同时定期更新Nginx版本，但仅选择轻量版更新，避免新版本中新增的冗余功能增加资源负担。这种运维思路，将“精简高效”的理念贯穿于环境生命周期的每一个环节，通过持续的监控、清理与优化，让轻量Nginx始终保持最佳运行状态，这也是从长期实践中总结出的运维智慧。</p><p>轻量型Nginx的部署与配置，本质上是一场对技术本质的回归，它剥离了冗余的功能外壳与复杂的配置套路，让工具回归到“解决核心问题”的原始定位。在这个过程中，我所积累的不仅是具体的操作方法，更是一种“精准适配”的技术思维—无论是环境搭建时的依赖取舍，还是配置优化中的参数调整，亦或是运维过程中的资源管控，核心都是围绕“场景需求”与“资源上限”进行动态平衡。这种思维不仅适用于Nginx的轻量部署，更可以迁移到其他技术工具的使用中，比如在边缘场景部署数据库时，同样可以采用“核心功能保留、冗余模块剥离”的思路，选择轻量型数据库版本；在开发嵌入式应用时，遵循“最小资源占用”的原则设计架构。技术的发展往往是从“复杂”到“简单”的循环，当我们习惯了各种功能强大的工具与框架后，反而容易陷入“功能依赖”的误区，而轻量部署的实践让我明白，真正高效的技术方案，往往是最贴合场景的方案，它不需要华丽的功能堆砌，只需要精准解决核心问题。</p>]]></description></item><item>    <title><![CDATA[《TXT与专用HSTS记录的浏览器安全通信轻量配置指南》 程序员阿伟 ]]></title>    <link>https://segmentfault.com/a/1190000047459534</link>    <guid>https://segmentfault.com/a/1190000047459534</guid>    <pubDate>2025-12-08 22:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在网络安全架构向轻量化、多场景适配演进的实践中，我们面对的并非复杂的企业级服务集群，而是静态博客、边缘计算节点、无服务器架构应用等资源受限或权限受限的场景，传统的服务器响应头配置方式往往受限于环境约束—比如静态站点无法自定义后端响应头，多域名管理场景下逐一配置服务器过于繁琐，边缘节点缺乏复杂配置的硬件支撑。而通过TXT记录或专用HSTS记录告知浏览器的方式，恰恰以“轻量无侵入”的特性，打破了这些场景限制，它无需深度改造服务架构，无需占用过多系统资源，仅通过简洁的记录配置，就能实现对浏览器访问行为的精准安全引导。这种配置思路的核心价值，在于将安全策略从服务器环境中剥离，转化为可跨场景复用的“信任凭证”，无论是静态资源分发、临时站点部署，还是多域名统一安全管理，都能快速落地。在长期的安全实践中，这种轻量配置方式不仅解决了多类场景的安全痛点，更让我深刻意识到，安全配置的本质是“信任的高效传递”—浏览器与服务器的安全通信，无需依赖复杂的技术堆砌，只需通过标准化的记录约定，就能建立起可靠的信任关系，这也是轻量安全架构在当下多场景部署需求中愈发重要的核心原因。</p><p>要真正掌握这种配置方式，必须先穿透技术表象，理解HSTS的底层信任机制，它的核心并非简单的HTTP强制跳转，而是通过浏览器的本地缓存形成“安全访问记忆”，从根源上阻断非加密访问的可能。当浏览器首次获取到HSTS记录后，会将对应的域名标记为“强制HTTPS访问”对象，并在本地缓存该策略一段时间，在此期间，所有针对该域名的HTTP请求都会被浏览器自动拦截并转换为HTTPS请求，无需等待服务器响应，既提升了访问安全性，又减少了跳转带来的性能损耗。而TXT记录与专用HSTS记录的核心差异，在于信任凭证的存储与传递载体：专用HSTS记录依赖服务器的HTTP响应头，当浏览器发起首次HTTP请求时，服务器通过响应头将安全策略传递给浏览器，适用于具备后端配置权限的场景，生效速度快且兼容性覆盖主流浏览器；TXT记录则将安全策略存储于域名解析系统中，浏览器在解析域名时会同步获取该记录，无需依赖后端服务的响应，这种特性使其成为静态站点、无服务器架构、嵌入式设备等无法自定义响应头场景的最优解。在实践中，这种差异直接决定了配置方案的选择逻辑—有后端配置权限时，优先选择专用HSTS记录以保障兼容性；无配置权限或场景受限，TXT记录则成为安全加固的关键路径，这种“因场景制宜”的选择思维，正是安全技术实践中最核心的底层逻辑。</p><p>通过TXT记录配置HSTS的实践过程，需围绕“规范定义、精准配置、验证闭环”三个核心环节层层推进，每个环节都需兼顾行业标准与场景适配性，避免因细节疏漏导致配置失效。首先是记录内容的规范定义，虽然不能涉及代码，但需明确核心要素的逻辑：记录类型需选择域名解析系统支持的专用安全类型，确保浏览器能够识别；内容需包含四项关键策略—HTTPS强制生效的有效期、是否将子域名纳入策略范围、是否允许浏览器预加载该策略、是否禁用HTTP降级访问，这些要素的设置直接影响安全效果与业务可用性。例如，有效期的设置需要平衡安全性与灵活性，过长可能导致配置错误后难以快速修正，过短则会频繁触发策略重新验证，建议根据业务稳定性调整，静态站点可设置较长有效期，频繁迭代的站点则适当缩短；子域名策略需根据实际需求选择，若多子域名统一管理，可开启子域名包含功能，若仅需保护主域名，则关闭该选项。其次是解析配置环节，需登录域名管理平台，找到DNS解析模块，新增一条TXT记录，准确填入定义好的策略内容，同时注意记录的“主机记录”字段设置，确保覆盖目标域名及所需保护的子域名范围，配置完成后需等待DNS解析全球同步，不同服务商的同步周期从几分钟到几小时不等，期间需避免频繁修改配置。最后是验证闭环环节，解析生效后，可通过两种方式确认配置效果：一是直接访问目标域名的HTTP地址，观察浏览器是否自动跳转至HTTPS，且地址栏显示安全锁标识；二是使用行业认可的在线检测工具，输入域名后查看HSTS策略的识别状态，确认策略中的各项参数是否被正确解析。在实践中，验证环节往往需要多次调试，比如排查记录内容是否存在格式偏差、解析是否完全同步、浏览器缓存是否影响首次验证结果等，这些细节的把控直接决定了配置的成功率，也是技术实践中积累经验的关键过程。</p><p>专用HSTS记录的配置逻辑，更侧重于“后端响应头的精准管控”，适用于具备服务器配置权限的场景，其核心优势在于生效即时性与浏览器兼容性，是企业级服务、动态站点等场景的首选安全方案。与TXT记录不同，专用HSTS记录无需依赖DNS解析，而是通过服务器在处理HTTP请求时，主动在响应头中携带安全策略信息，浏览器首次接收后便缓存该策略，后续访问直接生效。配置的核心环节在于服务器响应头的自定义设置，需根据服务器类型调整配置思路：静态服务器可通过修改配置文件，全局启用HSTS响应头；应用服务器可在应用代码中统一配置响应头，或通过中间件实现策略分发。无论哪种方式，都需确保响应头的名称与内容格式符合行业标准，策略参数与TXT记录保持一致，包括有效期、子域名包含、预加载权限等关键信息。在实践中，配置时需注意“灰度过渡”原则，避免直接启用严格策略导致业务异常：首次配置可设置较短的有效期（如几小时），同时关闭预加载功能，测试主流浏览器的兼容性与业务访问稳定性，确认无异常后，再逐步延长有效期并开启预加载；若业务存在特殊需求，需临时允许HTTP访问，可通过缩短有效期快速调整策略，待需求结束后恢复严格配置。此外，专用HSTS记录支持将域名提交至浏览器厂商维护的HSTS预加载列表，提交通过后，浏览器在首次访问前就已内置该域名的安全策略，无需等待首次HTTP请求，进一步提升安全防护的即时性，尤其适用于用户基数大、安全需求高的场景。</p><p>无论是TXT记录还是专用HSTS记录，配置后的持续优化与动态监控，都是保障安全策略长期有效、适配业务变化的关键，核心在于建立“策略迭代-效果监控-问题修复”的闭环机制。安全策略并非一成不变，需根据业务发展与安全需求动态调整：当域名新增子域名时，需及时更新HSTS记录，将新子域名纳入策略范围，避免出现安全防护盲区；当业务架构调整，如从动态站点转为静态站点，需同步切换配置方案，从专用HSTS记录改为TXT记录；当安全漏洞出现时，可通过缩短有效期快速更新策略，关闭存在风险的配置项。监控环节需聚焦两个核心维度：一是浏览器兼容性监控，定期测试主流浏览器及不同版本的访问情况，确认策略在各类环境中都能正常生效，避免因浏览器版本差异导致策略失效；二是策略执行效果监控，通过分析服务器访问日志，统计HTTP请求的转换率，判断是否存在未被拦截的HTTP请求，同时关注是否有因策略配置导致的访问异常，如HTTPS证书失效时，策略会导致用户无法访问，需及时预警并处理。在实践中，可结合安全监控工具，定期扫描域名的HSTS配置状态，自动检测策略参数是否合规、是否存在配置漏洞，同时建立配置变更记录台账，每次调整后及时记录原因与效果，便于后续追溯与优化。这种“动态优化+持续监控”的思路，体现了安全防护的“主动防御”理念，只有让策略始终适配业务与安全的变化，才能实现长期稳定的安全保障。</p><p>通过TXT记录或专用HSTS记录告知浏览器的配置方式，本质上是轻量安全架构的典型实践，它剥离了传统安全配置的复杂流程与资源消耗，以“最小化干预”实现“最大化安全”，完美适配了当下多场景、轻量化的部署需求。在这个过程中，积累的不仅是具体的操作方法，更是一种“场景化安全”的技术思维—安全配置不应是标准化的模板套用，而应是基于场景特性的精准适配，不同的业务架构、不同的权限边界、不同的用户群体，都需要匹配对应的安全方案。这种思维不仅适用于HSTS配置，更可以迁移到其他安全技术的实践中，比如静态站点的跨域安全配置、边缘节点的访问控制策略等，核心都是“以最小成本实现核心安全需求”。</p>]]></description></item><item>    <title><![CDATA[Pixelmator Pro for Mac v3.5.4.dmg 安装方法｜简单易懂 小童童 ]]></title>    <link>https://segmentfault.com/a/1190000047459382</link>    <guid>https://segmentfault.com/a/1190000047459382</guid>    <pubDate>2025-12-08 21:02:10</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>​</p><p>Pixelmator Pro 是 Mac 上一款很受欢迎的图片编辑软件，界面清爽、操作简单，功能却挺全，像修图、调色、抠图、加特效都能搞定。它支持图层、蒙版、矢量图形这些专业玩法，但对新手也很友好，不用学太多复杂操作就能出效果</p><ol><li>先下好安装包</li></ol><p><strong>安装包下载：</strong><a href="https://link.segmentfault.com/?enc=05q%2FtQohWeq99RjWDSxWKA%3D%3D.wC0xUb3ZYcKXW6RkoQVcRoAu%2Fxdlgkds81eb01oDDqqU8%2BKEpOFVrt43rbLi8v%2Fl" rel="nofollow" title="https://pan.quark.cn/s/537dce9946a1" target="_blank">https://pan.quark.cn/s/537dce9946a1</a>，把 <code>Pixelmator Pro for Mac v3.5.4.dmg</code>下载到电脑里，记住放哪了，别等会儿找不着（一般默认在“下载”文件夹）。</p><h3>2. 打开 DMG 文件</h3><p>找到刚下载的 <code>.dmg</code>文件，双击它！这时候会弹出一个新窗口，里面能看到 Pixelmator Pro 的图标和一个箭头（或者叫“应用程序”文件夹的快捷方式）。</p><h3>3. 拖图标到“应用程序”</h3><p>重点来了：直接按住 Pixelmator Pro 的图标，往右边那个“应用程序”文件夹的快捷方式上拖——拖过去松开鼠标，等它自己复制完（进度条跑完就OK）。</p><h3>4. 等复制完，关掉窗口</h3><p>复制好了之后，把刚才弹出的 DMG 窗口关掉就行，不用留着。</p><h3>5. 打开软件试试</h3><p>现在去“启动台”（屏幕底部火箭图标）找 Pixelmator Pro，点一下打开。第一次开可能会提示“是否信任”，选“打开”就行（Mac 有时候对新软件会多问一句，正常操作）。</p><p>​</p>]]></description></item><item>    <title><![CDATA[腾讯新闻APP的消息推送Push架构技术重构实践 JackJiang ]]></title>    <link>https://segmentfault.com/a/1190000047459419</link>    <guid>https://segmentfault.com/a/1190000047459419</guid>    <pubDate>2025-12-08 21:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>本文由腾讯技术团队颜勇分享，原题“腾讯新闻PUSH架构升级之路”，有修订和重新排版。</p><h2>1、引言</h2><p>68 万行代码精简到8.6 万；Golang 重写大部分 C++模块；解决过度微服务化问题…… 这是新闻 PUSH 架构团队取得的技术收益。PUSH 是腾讯新闻精品资讯的重要分发途径，也是新闻 App 重要的促活手段。作为 PUSH 架构团队，我们一方面在积极支持好新闻护盘，同时也在对 PUSH 架构进行不断的升级与进化，以持续提升 PUSH 系统的稳定性与质量、研发效率，同时持续减少运营成本。<br/>本文主要分享的是腾讯技术团队近年来对腾讯新闻消息推送PUSH系统做的架构优化和技术实践。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459421" alt="图片" title="图片"/></p><h2>2、Push平台介绍</h2><p>2.1 概述PUSH 是腾讯新闻内容重要的分发渠道，新闻 PUSH 平台承担着将新闻资讯触达到新闻用户、满足用户及时获取精品资讯的需求。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459422" alt="图片" title="图片" loading="lazy"/></p><p>总体上，新闻 PUSH 链路分为下面两部分。</p><p>2.2 PUSH触发</p><p>按触发方式的不同，新闻 PUSH 分为三类：<br/>1）人工 PUSH：运营在 push cms 系统指定要发送的文章、要触达的人群包，人工触发push发送；这类 PUSH 目前主要用于推送热点事件/热点资讯等；<br/>2）自动化 PUSH：周期性地给用户计算他可能感兴趣的内容，这类推送由后台自动触发；<br/>3）功能性 PUSH：由业务系统触发，主要是为了实现一些业务功能通知，比如评论通知、关注通知等。</p><p>2.3 PUSH下发</p><p>对于所有 PUSH 触发 的PUSH 进行调度（包括避让、打散和频控等）和触达（通过自有通道或厂商通道推送给用户）。新闻业务对新闻 PUSH 平台最重要的要求是：</p><p>1）要保证精品咨讯触达的及时性：新闻 PUSH 最重要的是要体现“新”，因为腾讯新闻用户有及时获取热点/突发资讯的诉求，用户经常有这样的体感，有热点突发事件时，所有 App 都会尝试第一时间向用户发起推送，用户大概率会点击收到的第一个推送。在了解了相关热点事件后，对于后续其它 App 的推送，对用户而言就没信息量了，大概率会被忽略，甚至可能会被用户视为一种打扰，影响用户体验。从我们实验数据来看，当P USH 下发延迟降低 50%，PUSH 点击量会提升 10%。所以新闻 PUSH 一直以来的目标是：热点资讯需要第一时间触达给用户，要做到“全网首推”。</p><p>2）要保证推送的用户体验和较好的拉起效率：PUSH 是新闻重要的促活手段，需要有较好的促活效率，这要求保证用户较好的推送体验，因为用户如果感觉推送体验不好，用脚投票，把 App 的 PUSH 系统开关给关了，这对 PUSH 而言就基本上就永远丧失了给这个用户推送的机会了。</p><p>这就要求要尽量保证在合适的时间点给推送用户感兴趣的内容，推送要有合理的频次，相邻 PUSH 之间要有合理的时间间隔，推送内容要做合适的打散。</p><p>其实这两个要求其实在一定层面上是有冲突的：<br/>a.如果要保证推送的及时性，就要求尽量减少计算，拿到消息消息后无脑推到消息通道，这个肯定最快；<br/>b.如果要保证良好的推送用户体验，就需要做很多的判断、考量和计算，这些考虑越多就需要做更多的计算和 io 操作，会影响推送的及时性；最近几年，业务成本的考虑也是 PUSH 关注的重点，需要削减使用的机器和资源，就要求用更少的机器如何发得更快更好。<br/>总结而言，之前新闻 PUSH 业务的突出问题主要有两个方面，请继续往下阅读。</p><h2>3、Push平台问题1：推送速度慢</h2><p>我们团队从 2022 年年中开始接手新闻 PUSH 平台。交接工作刚启动，就遇到了一次 S 级热点事件——一个国际级突发新闻。那天晚上，全网用户都在密切关注它的最新进展。这个事件有两个特点：热度极高、且并非完全突发——早在一个月前就已经有明确预告，因此运营部门提前布置了应急预案。我们刚接手系统时，对整个下发链路还不够熟悉，只能凭直觉扩容机器，希望能抗住峰值。结果现实很快给了我们一记当头棒喝。当晚，很多内部同事都装着多个新闻 App，一眼能看到谁家的推送更快。那晚我们的延迟问题非常明显，甚至有用户在热点过去一个多小时后才收到通知。事后有专门的评测团队做了分析，指出“PUSH 下发耗时过长，高活用户 P90 均值达 20 分钟”，报告还发到了高层群里——对我们来说，那无疑是一次刻骨铭心的教训。</p><h2>4、Push平台问题2：开发效率和问题排查效率低</h2><p>之前 PUSH 链路特别长，新闻 PUSH 内部有 30+ 个模块，同时还依赖其它两个跨业务团队。经常一个需求开发要改多个模块，要团队几个人一起开发，约定交互协议，开发后再联调测试，在多个模块起联合实验；然后还得给中台提需求，然后匹配中台的排期后，才能完成需求上线；这一系列操作就拉长了 push 需求的leadtime。线上有 case 时，问题排查也需要串联多个模块，关联多个模块数据，甚至需要跨部门拉上其它这边来一起来排查，排查效率非常低。push case 非常多，比如用户为什么收到了/没收到某条 push 之类的典型 case，之前需要关联链路20来个模块的日志，还要联合中台一起排查，每次 case 排查时间都在天级；之前在case 排查上，每天都耗费我们大量的人力。既要持续提升 PUSH 触达的及时性、又要持续提升推送的用户体验和拉活效率，还要持续降低运营成本，客观而言，在技术上是一个较大的挑战。本文主要详述，我们如何通过技术架构升级来支撑这个既要&amp;又要&amp;还要的目标。</p><h2>5、老Push架构的问题梳理</h2><p>5.1 模块链路过长，内耗过多</p><p>一条快速PUSH，从推送内容过审后，到最终发出去，最长要经过18个模块，另外还需要经过中台多个模块。一条待推送的数据最多要经历 17 次内部 rpc 转发，多个模块之间腾挪流转，各种网络 rpc，各种内耗，肯定发得慢。一个最典型的例子：原架构有个模块叫scheduler，它主要负责决定一个push该不该发，直观上感觉它里面应该囊括了各种过滤策略，但是原架构做成了多个微服务。scheduler 模块里本身有一些过滤逻辑，另外有一个叫做 filter 的模块，专门负责品牌、开关等硬规则过滤；另外有一个叫做 policy 的模块，专门负责配额等软规则过滤；所有过滤规则都通过后，进入一个叫做 channer 模块，就决定下这次推送走哪个通道；然后又走到一个叫 worker 的模块里，而它只做对接下游中台的协议适配。总体上看，原链路就是过度微服务化了：1）模块多会导致数据流转的低效，模块间网络 rpc 会浪费处理耗时；2）其次会影响迭代效率，模块数不是越多越好，因为经常一个需求需要改多个模块，做多次上线；3）同时模块过多也对联调&amp;测试效率，影响线上 case 排查效率。这就违反了“模块内高内聚，模块间低耦合”的架构设计原则，进而会影响业务迭代效率。</p><p>5.2 依赖服务有瓶颈</p><p>上文提到的 S 级热点事件时，我们将下发服务机器扩了一倍，但是下发速度并没有提升，说明瓶颈不在下发服务本身下，而是在依赖服务上；通过链路debug，我们定位到了链路瓶颈：号码包拉取。在发送人工 push，运营会指定受众人群包（几百万到几亿不等），这时候需要分页拉取该号码包数据进行处理。之前老架构使用了底层平台的人群包服务，新闻所有 push 人群包都上传到了该人群包服务，当发送指定人群包，需要请求平台侧接口分页拉取人群包数据，当时因为平台侧人群包功能实现比较复杂，能支持一些比较高级的能力，因此这个分页接口耗时比较长。但其实我们只用到了最简单的数据分页的功能，完全可以采用更简单的实现方案，以减少接口耗时。</p><p>5.3 链路稳定性不好</p><p>5.3.1）容错能力差：之前链路基本无容错能力，发生了过一次因上游未按约定协议跟我们请求交互，导致我们服务挂了半天，是一次典型的 P0 级事故。</p><p>5.3.2）缺少节点自动故障转移：scheduler 负责 push 调度，原架构为了提升处理效率，scheduler 里做了本地缓存；为了避免缓存失效，起了一个服务 dispatch 消费触发侧生产的待推送的消息，然后按照用户设备号一致性哈希来 sharding，通过 rpc 请求对应的 scheduler，scheduler接受到请求后，塞入到它本地的内存队列里，如果队列满了就直接丢弃。它原来存在有这些问题：dispatch无脑往下游转发，sharding规则非常僵硬，一个用户的push一定要打到某个节点，未做故障转移；当某节点异常满载时，dispatch还是会往这个节点打，导致丢消息或者是 push发送得慢。而且当节点满载时，有限的cpu还需要耗费在rpc解包、无法插入内存队列而丢弃之类的无用消耗上。</p><p>5.4 链路处理无优先级区分</p><p>运营人工发的 PUSH 和自动化 PUSH 都使用同一个下发链路，热点突发事件资讯多由运营人工发送，而自动化 PUSH 多发一些用户可能感兴趣的内容，其实它对于推送速度并没那么敏感；当有人工推送的热点突发内容时，自动化 PUSH 会和它一起争抢有限的链路资源。另外，在链路总吞吐量一定的情况下，其实处理顺序可以调整，让链路资源有限保证人工推送的热点突发内容的发送；</p><p>5.5 技术栈不统一</p><p>之前 push 下发链路有 C++/Go 两种技术栈，技术栈不统一不利于代码复用，影响需求迭代效率。push下发链路本质上是一个高 io 型的流程，其实可以完全可以统一到 Golang 技术栈。</p><p>5.6 链路测试效率低</p><p>push 链路业务逻辑比较多，在日常密集业务需求迭代中，新功能我们可以在线上通过构造对应的功能 case 来进行冒烟测试，但是比较难评估是否影响了线上已有的业务逻辑。之前缺乏有效的回归测试手段，由于担心影响线上业务指标，为了验证是否影响线上已有业务逻辑，我们大的修改都会开比较长的小流量实验验证，比如我们在做调度架构升级时，开了一个近两个月的小流量实验，测试效率比较低也会导致需求迭代效率比较低。</p><h2>6、新Push架构优化1：消息通道自建</h2><p>之前新闻 PUSH 依赖于平台侧的消息通道，业务侧主要负责 PUSH 调度，即业务侧决定触发和过滤，平台侧负责 PUSH 触达给用户终端。由于 PUSH 是新闻增长护盘的重点方向，有较频繁的业务迭代，对底层消息通道我们有较多的业务需求，在业务迭代过程中我们发现平台侧需求 leadtime 比较长，无法满足业务侧迭代效率的要求；在经平台侧这边商量且同意后，我们完成新闻push消息通道的自研，直接对接厂商推送并搭建了长链接通道，实现了 push 全链路在业务侧的全闭环。我们在自建 push 消息通道时，对原来的架构做了重写：1）精简链路，模块整合，减少系统复杂度：去掉我们不关心的无用功能，将原链路15个模块，代码 68 万行整合为了6个模块，代码共8.6万行；通过代码精简能减少系统复杂度，有助于提升业务迭代效率；同时能避免模块之间的rpc通信开销，提升链路处理效率。2）客户端/服务端交互接口整合，提升数据通信成功率：以前 PUSH 注册依赖于注册&amp;绑定&amp;上报三个接口请求，任何一次请求出错，push 注册就会失败；我们在新流程里将注册&amp;绑定&amp;上报需要的所有数据，都一起传给新接口，由服务端在一个接口里实现注册、绑定和上报；将注册成功率从90%提升到了99.9%。3）与新闻技术技术架构保持统一：将原架构发现/rpc技术栈的基础组件升级为腾讯新闻自用的基础组件，尽量使用我们熟练使用的技术栈，以提升业务开发&amp;运维效率。4）优化了原来链路一些不合理的地方：对原来链路的限流机制、通道选择策略做了优化，增加了必要的功能，比如小流量实验环境的支持。</p><h2>7、新Push架构优化2：统一技术栈</h2><p>之前 push 链路有 C++/Golang 两种技术栈，除了 push 推荐服务外， 其它 C++链路模块全部使用 Golang 模块进行了重写，以提升业务迭代效率和链路稳定性。</p><h2>8、新Push架构优化3：链路整合升级，提升效率</h2><p>一个架构如果如果过度微服务化了，会带来各种问题：1）模块间耦合严重，影响研发效率：本来是一个模块应该完成的工作，硬拆成了2个模块，有改动需要都需要改两个模块，需要模块间联调测试，影响需求迭代效率。2）架构效率低：拆成微服务后，函数本地调用变成了RPC网络调用，需要增加大量的拆包、解包的操作，资源白白浪费在这些无用的内耗上了。对于频繁迭代的地方，单独抽成单独的微服务是有助于提升迭代效率的；但是我们review历史push需求，都比较分散，没有集中到一个特定的地方，我们按照“一个需求尽量只用改一个模块”的原则，对原来的push链路的所有模块进行了整合升级。具体的升级内容是：a. 触发侧合并为了1个模块：将原来触发侧的5个模块合并为1个模块；b. 调度侧合并为了1个模块：将原来调度侧的5个模块合并为了1个模块；c. 将消息通道侧模块做了整合：如上所述，我们将push消息通道原来15个模块合并为了5个。经过链路整合后：以前一个 PUSH 消息最多要经过 18 个模块，17次内部链路rpc转发；升级后，只用经过 3 个模块，只用经过 2 次 rpc 转发；这样就显著提升了链路效率；而且模块减少后，业务需要迭代无需开发多个模块，避免模块之间联调和测试，提升了业务迭代效率；同时，线上 case 排查时，无需做多模块的日志 join，提升了 case 排查效率。</p><h2>9、新Push架构优化4：自建号码包服务，提升号码包获取速度</h2><p>如上文所述：之前号码包的拉取慢是系统的主要瓶颈所在，而在我们这个场景比较简单，因此我们考虑自建号码包服务，针对于我们自己的需求来定制开发，以提升服务性能。我们的需求只有一个，就是对离线包进行分页，并提供服务接口返回指定页的数据。1）画像中台圈选兴趣包，并按页切成若干个小文件，每个兴趣包一个文件夹，并上传到cos，兴趣包里带着数据版本号；2）构建包管理服务，提供获取指定兴趣包指定页数据的能力；包管理服务定期从cos上check是否有更新的数据（比较本地数据版本和cos最新的数据版本），如果有，则拉取最新的数据更新本地数据；当接收到拉取指定包指定页数据的请求后，则定位到对应文件夹读取对应页文件数据并返回；3）集群有个数据一致性哨兵，定期检查集群节点的数据版本，当发现集群数据版本不一致时，给集群所有节点发信号，强制让每个节点同步cos上的最新数据，让集群所有节点数据跟最新数据保持一致。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459423" alt="图片" title="图片" loading="lazy"/></p><h2>10、新Push架构优化5：在线过滤改成离线预处理，避免在线处理耗时</h2><p>运营在发PUSH时会选择受众人群包，同时会指定系统、品牌等筛选项，之前的处理流程是先把人群包一股脑发到链路里，然后在下发链路里根据用户画像数据，对数据进行实时过滤。在线过滤增加了链路下发的耗时。其实系统&amp;品牌过滤完全可以前置到离线侧，我们将号码包按品牌和系统维度进行了拆分，比如“社会”包按 android/ios、huawei/oppo/vivo/honor/xiaomi，拆成了13个包，当运营选择指定的筛选项时，直接拉取对应的号码包，这样就避免了在线过滤的耗时，减少了下发的延时。</p><h2>11、新Push架构优化6：将单IO操作自动聚合成批量操作</h2><p>push下发链路有大量io操作，比如获取用户维度的多路数据（比如用户系统、品牌、下发&amp;曝光&amp;点击历史等），获取文章维度的多路数据（文章正排数据等）。链路其实主要耗时还是在io部分，如果能提升io吞吐量，就能提升PUSH链路的吞吐量，减少下发延时；io操作批处理肯定能提升吞吐量。但是在具体业务流程中，不同push类型、不用品牌用户，处理逻辑会有不同，因为每个push的处理流程可能都不一样，无法直接批处理。所以之前调度主链路流程是从队列里按单个消费进行处理的。为了提升链路吞吐量，我们对每一类io操作做了一个类，对外暴露一个单个io请求接口，外部调用该接口后，将请求压入一个异步队列，同时开始等待结果的返回；这样该类io请求都会在该异步队列里进行了汇聚。下层会开若干个处理协程，批量从异步队列消费出若干请求任务，拼成批量的io请求，然后拿到批量io结果，按序向上层返回io结果；这样对上层而言，看到的还是单个的同步io接口，上层业务逻辑开发流程无需做改造，底层其实已经自动做了io的批量聚合，显著提升了链路吞吐量。</p><h2>12、新Push架构优化7：优先推送热点突发内容，优先保证高价值用户及时性体验</h2><p>在链路吞吐量一定的情况下，一个推送任务小到几百万，大到一两亿的发送量，都需要处理时间。这时候先处理比后处理的时延要少。</p><p>其实可以考虑对链路发送进行调度：<br/>1）链路优先保障热点突发PUSH的发送，我们建立了任务优先级队列，当有热点突发PUSH在发送时，其它PUSH延迟发送；<br/>2）同一个PUSH任务，对用户推送顺序也做了排序：活跃度高、历史push点击率高、预估商业化价值高、对push时延敏感的用户优先发送。通过优先级调度，最大程度保障了热点突发内容和高价值用户的推送及时性的体感。</p><h2>13、新Push架构优化8：增加自动故障恢复能力</h2><p>为了提升链路吞吐量，调度节点进程通过 LRU cache 缓存了大量数据，所以在推送消息处理的 sharding 方式上采用了按设备号一致性哈希。很多时候某个节点异常时，会出现慢而不死的情况：处理能力陡降，但是节点存活正常。北极星未能把它摘掉，相当一部分设备会打到该节点，即使该节点已经满载了，之前架构为了避免缓存失效而导致处理耗时增加，还是会一致性哈希将流量打往该节点，导致这部分用户处理耗时异常增加，甚至发送失败。新架构对于推送任务sharding做了优化：在一致性哈希的基础上，每个节点计算出4个固定的backup；当某节点的失败率或处理耗时超过一定阈值时，将该节点的流量均匀低分给他的backup。通过这种方式就支持单节点异常时的自动故障恢复。</p><h2>14、新Push架构优化9：构建push链路自动化测试能力</h2><p>构建了接口自动化回归测试流程：1）case覆盖push链路的核心逻辑；2）合并master时自动触发回归测试流程的执行。构建了自动化diff测试流程：diff流程大体思路都类似，通过录制线上流量的真实请求和返回结果，在测试环境进行回放，观察同一请求下，返回结果是否会有差别；如果无差别，说明测试环境跟线上一样，上线不会引起线上数据异常；如果有差别，就需要分析这些差别是否是符合预期的。diff测试基本能回归到线上所有业务逻辑分支，能弥补回归测试覆盖度有限的问题。主要挑战：push依赖的数据变化比较快，导致在同一时间，同一请求的返回结果会不同；比如push为了避免重复下发同一篇文章，会依赖于下发历史数据，线上录制了刚下发的某篇文章，在测试环境去回放肯定就不能下发了，因为线上刚把这篇文章写入到下发历史里，导致回放请求时返回结果是不能下发了，这样自然就产生了diff。解决方案：在流量录制时，除了录制请求之外，同时录制各个依赖数据，在回放时，依赖数据以依赖数据为准，通过这种方案就避免了依赖数据易变而引入diff的问题。</p><h2>15、架构升级后的系统表现</h2><p>1）push运营成本显著降低：通过持续的 push 架构优化，新闻 push 总运营成本下降70%；2）PUSH链路性能（吞吐量）显著提升：通过持续的 push 架构优化，显著提升了 push 链路的性能，push推送量（出口）峰值吞吐量提升了3.5倍；3）热点突发（全国/快速）PUSH全链路耗时下降明显：a. 热点突发（全国/快速）PUSH内部链路耗时P90下降了90%；b. 内部链路耗时指的是从push审核通过到推送给厂商的时间，即我们内部链路总的耗时时长；c. 热点突发（全国/快速）PUSH全链路耗时（包括内部链路耗时和厂商链路耗时）下降了90%d. 全链路耗时指的是从push审核通过到用户收到PUSH时间，即包括内部链路和厂商链路总的耗时时长.我们完成一些架构升级后，还是评测团队对了评测，腾讯新闻的PUSH已经领先于竞品1～4分钟了。4）提升了PUSH点击效果：push推送速度提升后，push点击数据也能看到明显受益，热点突发PUSH点击pv提升了10%，push大盘点击UV也能看到显著的正向收益；线上收不到PUSH的用户客诉也减少到25年H1 0 例，提升了用户产品体验。5）稳定性良好：push链路主要重构完成后，PUSH链路稳定性&amp;质量明显提升，2025.02以后 0 故障。</p><h2>16、参考资料</h2><p>[1] 极光推送系统大规模高并发架构的技术实践分享<br/>[2] 魅族2500万长连接的实时消息推送架构的技术实践分享<br/>[3] 专访魅族架构师：海量长连接的实时消息推送系统的心得体会<br/>[4] 一个基于长连接的安全可扩展的订阅/推送服务实现思路<br/>[5] 实践分享：如何构建一套高可用的移动端消息推送系统？<br/>[6] Go语言构建千万级在线的高并发消息推送系统实践(来自360公司)<br/>[7] 腾讯信鸽技术分享：百亿级实时消息推送的实战经验<br/>[8] 百万在线的美拍直播弹幕系统的实时推送技术实践之路<br/>[9] 京东京麦商家开放平台的消息推送架构演进之路<br/>[10] 技术干货：从零开始，教你设计一个百万级的消息推送系统<br/>[11] 长连接网关技术专题(四)：爱奇艺WebSocket实时推送网关技术实践<br/>[12] 喜马拉雅亿级用户量的离线消息推送系统架构设计实践<br/>[13] 直播系统聊天技术(四)：百度直播的海量用户实时消息系统架构演进实践<br/>[14] 消息推送技术干货：美团实时消息推送服务的技术演进之路<br/>[15] 揭秘vivo百亿级厂商消息推送平台的高可用技术实践<br/>[16] 得物从零构建亿级消息推送系统的送达稳定性监控体系技术实践<br/>[17] B站千万级长连接实时消息系统的架构设计与实践<br/>[18] 转转千万级用户量消息推送系统的架构演进之路<br/>[19] 企业级实时消息推送系统的架构设计，一文即懂！</p><p>即时通讯技术学习：</p><ul><li>移动端IM开发入门文章：《新手入门一篇就够：从零开发移动端IM》</li><li>开源IM框架源码：<a href="https://link.segmentfault.com/?enc=nSoY4erMvS%2FLirrDJKmvoQ%3D%3D.RgJWh1UTnDHCxgVsArJzyPGaZu7shQ1hoYR6eFFVx%2F0dQBozE6ODiH75fZyvJUCa" rel="nofollow" target="_blank">https://github.com/JackJiang2011/MobileIMSDK</a>（备用地址点此）<br/>（本文已同步发布于：<a href="https://link.segmentfault.com/?enc=xpDsbUclHyZOt7Uyt%2Fv1VA%3D%3D.5yhkXMsMVwhJsWE3J%2F%2BsTfSybYiaN6%2B27gT722pYkZYGBCGRb2%2Bwqxr9uxMAZ3Gj" rel="nofollow" target="_blank">http://www.52im.net/thread-4883-1-1.html</a>）</li></ul>]]></description></item><item>    <title><![CDATA[一文了解 openFuyao“低底噪容器底座” openFuyao ]]></title>    <link>https://segmentfault.com/a/1190000047459299</link>    <guid>https://segmentfault.com/a/1190000047459299</guid>    <pubDate>2025-12-08 20:04:36</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>业务痛点</h2><p>在资源受限的运行环境（如单节点、嵌入式）中，Kubernetes（以下简称“K8s”）自身的资源占用与调度瓶颈，制约了业务 Pod 的可靠拉起与预期规模的实现。</p><h2>根因分析</h2><ul><li>K8s 生态集成多种功能，组件较多，架构略重，自身运行需要系统资源较多。</li><li>K8s 组件独立进程运行，APIServer 与 etcd 需通过网络协议通信，流量较高场景中组件间交互成为瓶颈。</li><li>containerd 创建 Pod 同时产生 shim 进程，随 Pod 数量线性占用内存资源，阻碍高密部署场景。</li></ul><h2>低底噪容器底座方案</h2><p>openFuyao 采用从编排系统、容器运行时、操作系统多层次入手，消减容器环境底噪和提升容器环境性能，打造业界首个单节点部署 1000+Pod 容器环境。<br/><img width="723" height="470" referrerpolicy="no-referrer" src="/img/bVdniuG" alt="" title=""/><br/><img width="723" height="457" referrerpolicy="no-referrer" src="/img/bVdniuH" alt="" title="" loading="lazy"/></p><h3>Kubernetes 子系统：</h3><ul><li>将 K8s 及其周边组件整合为单进程，并将 APIServer 和 etcd 的网络通信优化为进程内内存交互，从而显著降低系统底噪，提升容器编排性能。100Pod 场景可降低 500+MB 内存。</li><li>使用文件探测等低成本方式代替传统消息交互方式，降低高密场景下探针消息对 CPU 和网络的影响。</li><li>最小化 K8s 基础功能，裁剪内存占用较多且不使用的特性（如 OpenAPI v3 ）。</li></ul><h3>运行时子系统：</h3><ul><li>消减 shim 进程，支持 containerd 通过 shimless 方式运行，降低底噪，使单节点可部署 1000+Pod，领先业界 4~10 倍。该典型场景可降低 20GB 内存占用。</li><li>通过启用 cgroup v2，为容器提供了更精细、高效的资源管理能力，使得高密部署时容器管理性能不下降。</li></ul>]]></description></item><item>    <title><![CDATA[React项目里，Record<string, any>和{ [key: string]: any ]]></title>    <link>https://segmentfault.com/a/1190000047459303</link>    <guid>https://segmentfault.com/a/1190000047459303</guid>    <pubDate>2025-12-08 20:03:47</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在 React 项目中，<code>Record&lt;string, any&gt;</code> 和 <code>{ [key: string]: any }</code> <strong>在功能层面几乎等价</strong>（都表示「键为字符串、值为任意类型的对象」），但在<strong>类型语义、语法灵活性、TS 内置特性</strong>上存在关键区别，以下是详细拆解（结合 React 实战场景说明）：</p><h3>一、核心结论先明确</h3><table><thead><tr><th>维度</th><th><code>Record&lt;string, any&gt;</code></th><th><code>{ [key: string]: any }</code></th></tr></thead><tbody><tr><td>核心功能</td><td>表示「键类型固定、值类型固定」的对象</td><td>表示「索引签名为字符串、值任意」的对象</td></tr><tr><td>语义侧重</td><td>强调「键值对映射关系」（内置工具类型）</td><td>强调「自定义索引规则」（基础语法）</td></tr><tr><td>语法灵活性</td><td>仅支持「单一键类型 + 单一值类型」</td><td>可扩展（混合固定属性 + 索引签名）</td></tr><tr><td>React 常用场景</td><td>状态/Props 快速声明、对象映射</td><td>自定义组件 Props（混合固定/动态属性）</td></tr><tr><td>类型推导</td><td>无额外扩展能力</td><td>可结合接口/类型别名扩展</td></tr></tbody></table><h3>二、具体区别与 React 实战示例</h3><h4>1. 语义与设计初衷</h4><ul><li><code>Record&lt;K, V&gt;</code> 是 TypeScript <strong>内置工具类型</strong>，设计初衷是「明确表示一个<strong>键类型为 K、值类型为 V 的键值对映射对象</strong>」，语义更聚焦“映射”；</li><li><code>{ [key: string]: V }</code> 是 TypeScript <strong>基础索引签名语法</strong>，设计初衷是「定义对象的索引规则」，语义更聚焦“对象的索引方式”。</li></ul><p>在 React 中，比如声明一个“动态配置对象”：</p><pre><code class="tsx">// Record：语义更清晰（“字符串键 → 任意值”的映射）
const formConfig: Record&lt;string, any&gt; = {
  username: { label: '用户名', required: true },
  password: { label: '密码', type: 'password' },
};

// 索引签名：语义偏“对象的索引规则”，功能等价
const formConfig: { [key: string]: any } = {
  username: { label: '用户名', required: true },
  password: { label: '密码', type: 'password' },
};</code></pre><h4>2. 语法灵活性（React 中最关键的区别）</h4><p><code>{ [key: string]: any }</code> 支持<strong>混合「固定属性 + 动态索引」</strong>，而 <code>Record&lt;string, any&gt;</code> 只能表示「纯动态键值对」—— 这在 React 组件 Props 定义中尤为常用：</p><pre><code class="tsx">// ✅ 合法：索引签名 + 固定属性（React Props 常用）
interface InputProps {
  // 固定属性
  defaultValue: string;
  onChange: (value: string) =&gt; void;
  // 动态属性（兼容其他未显式声明的 props）
  [key: string]: any;
}

// ❌ 非法：Record 无法混合固定属性
interface InputProps extends Record&lt;string, any&gt; {
  defaultValue: string; // 语法上允许，但语义矛盾（Record 是纯动态映射）
  onChange: (value: string) =&gt; void;
}</code></pre><p>比如 React 中封装通用组件时，常需要「固定核心 Props + 兼容任意扩展属性」，此时只能用索引签名，而 Record 做不到这种混合：</p><pre><code class="tsx">// 正确：用索引签名封装通用按钮 Props
interface ButtonProps {
  type: 'primary' | 'default';
  size: 'small' | 'large';
  [key: string]: any; // 兼容 className、style 等原生属性
}

const Button = (props: ButtonProps) =&gt; {
  const { type, size, ...rest } = props;
  return &lt;button className={`btn-${type}-${size}`} {...rest} /&gt;;
};

// 错误：Record 无法区分“固定属性”和“动态属性”
type ButtonProps = Record&lt;string, any&gt;; // 丢失 type/size 的类型校验</code></pre><h4>3. 类型参数扩展（非 React 专属，但影响写法）</h4><p><code>Record&lt;K, V&gt;</code> 的 <code>K</code> 支持<strong>联合类型</strong>（比如 <code>string | number</code>），而索引签名的 <code>key</code> 只能是 <code>string</code>/<code>number</code>/<code>symbol</code> 单一类型（但实际中 <code>number</code> 键会被转为 <code>string</code>，效果等价）：</p><pre><code class="ts">// ✅ Record 支持联合键类型
type MixedKeyObj = Record&lt;string | number, any&gt;;
const obj: MixedKeyObj = {
  name: '张三',
  123: '数字键', // 合法
};

// ✅ 索引签名也支持 number，但实际键会转字符串
type MixedKeyObj2 = { [key: number]: any };
const obj2: MixedKeyObj2 = {
  123: '数字键', // 合法（键实际是 "123"）
  // 'name': '张三' // ❌ 索引签名是 number，不允许字符串键
};</code></pre><h4>4. 代码简洁性</h4><ul><li>当只需声明「字符串键 + 任意值」时，<code>Record&lt;string, any&gt;</code> 比 <code>{ [key: string]: any }</code> 更简洁；</li><li><p>当需要自定义值类型（比如 <code>string | number</code>），两者简洁度相当：</p><pre><code class="ts">// 等价写法
type StrNumObj1 = Record&lt;string, string | number&gt;;
type StrNumObj2 = { [key: string]: string | number };</code></pre></li></ul><h3>三、React 项目中的选择建议</h3><table><thead><tr><th>场景</th><th>推荐写法</th><th>原因</th></tr></thead><tbody><tr><td>临时声明纯动态对象（如 state、临时变量）</td><td><code>Record&lt;string, any&gt;</code></td><td>语义清晰、代码更短</td></tr><tr><td>组件 Props（混合固定属性 + 动态扩展）</td><td><code>{ [key: string]: any }</code></td><td>支持固定属性 + 索引签名，适配 React 原生属性（如 className）</td></tr><tr><td>明确“键值映射”语义（如配置对象、字典）</td><td><code>Record&lt;string, T&gt;</code></td><td>语义更贴合“映射”场景，可读性更高</td></tr><tr><td>需扩展/复用类型（如接口继承）</td><td><code>{ [key: string]: T }</code></td><td>可与接口/类型别名无缝混合，灵活性更高</td></tr></tbody></table><h3>四、避坑提醒（React 中常见误区）</h3><ol><li>不要滥用 <code>any</code>：无论是 <code>Record&lt;string, any&gt;</code> 还是 <code>{ [key: string]: any }</code>，<code>any</code> 会丢失 TypeScript 类型校验，React 中建议尽量指定具体值类型（比如 <code>Record&lt;string, FormItemConfig&gt;</code>）；</li><li><p>函数组件 Props 扩展：如果想兼容 React 原生 HTML 属性，推荐用 <code>React.HTMLAttributes&lt;HTMLElement&gt;</code> 而非纯索引签名，比如：</p><pre><code class="tsx">interface CustomInputProps extends React.HTMLAttributes&lt;HTMLInputElement&gt; {
  value: string;
  onChange: (value: string) =&gt; void;
}</code></pre></li></ol><h3>最终总结</h3><p>在 React 项目中，<code>Record&lt;string, any&gt;</code> 和 <code>{ [key: string]: any }</code> <strong>功能上等价</strong>（都表示字符串键的任意对象），核心差异在：</p><ul><li><code>Record</code> 更简洁、语义聚焦“映射”，适合纯动态对象；</li><li>索引签名更灵活，支持混合固定属性，适合组件 Props 等场景。</li></ul><p>日常开发中可根据“是否需要混合固定属性”选择，无需过度纠结，重点是避免滥用 <code>any</code>，尽量指定具体类型。</p>]]></description></item><item>    <title><![CDATA[VibeCoding 翻新个人站 (Nextjs+Django) alpha94511 ]]></title>    <link>https://segmentfault.com/a/1190000047459306</link>    <guid>https://segmentfault.com/a/1190000047459306</guid>    <pubDate>2025-12-08 20:03:09</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>最近从个人站引来了德国客户，成功开出海外服务第一单✌️，也让我意识到该把自己的古早个人站做个大升级。折腾了几个小时终于把上线，欢迎大家+友链  <a href="https://link.segmentfault.com/?enc=lvvgY6Yh0fQSZuUVs%2FjF3g%3D%3D.8O4I7zjMRGsl1u9iYpI8%2BRsL3G3lp%2FQbqmEiIxoZwOg%3D" rel="nofollow" target="_blank">https://www.hephaestus.fr/</a></p><p>前端 Nextjs部署在 Vercel上<br/>后端 Django+S3+PostgreSQL 部署在了 DigitalOcean上，资源使用了CDN加速</p><p>后续工作主要是SEO优化，持续引流</p>]]></description></item><item>    <title><![CDATA[漏算的 Token：AI 网关限额机制的攻防博弈 spacewander ]]></title>    <link>https://segmentfault.com/a/1190000047459312</link>    <guid>https://segmentfault.com/a/1190000047459312</guid>    <pubDate>2025-12-08 20:02:21</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>攻</h2><p>AI 网关通常有这样的功能：基于 token 消耗量来做限额操作。有些地方叫做 ai-rate-limiting，有些地方叫做 ai-quota。无论名字为何，原理同出一辙，都是基于推理请求结束时返回的 token usage 信息。</p><p>那么绕过限制的方式就显而易见了，只需找找有没有能让网关看不到推理请求结束时的 usage 信息即可。有些时候，用户在无意中就能绕过这些限制。比如在 OpenAI chat 接口里，默认 streaming 的时候就不会返回 usage，除非用户请求时指定了 include_usage：<a href="https://link.segmentfault.com/?enc=G5trmV9jTtPAgCMyhA2EuQ%3D%3D.ZroCVxC7NoOhrMJXG%2FRhRrjq07ZiUzdvDfXpMQqxB%2BqrxZ11FbltNSctbJJMsrwelwB1GUlSJ%2B%2B1huib5lJ00QcQFyObPhcnfGOnd2nwOPoTTBeHpUMiuNtmmNv%2BDG0kn98A89KqtHlgeSe5m5KTwA%3D%3D" rel="nofollow" target="_blank">https://platform.openai.com/docs/api-reference/chat/create#ch...</a>。</p><p>假设模型供应商总是会提供 token usage，抑或网关在处理用户请求时做了点 hack 额外加上 include_usage，保证了 token usage 总是在推理请求结束时存在，那该怎么办了？方法还是有的，让推理请求提前中断即可。我们可以插入一段 prompt，指定在返回结果结束时输出一个 stop word，然后再执行一个耗时的任务。当客户端收到这个 stop word 后，就可以安心地把连接中断掉。只要请求是提前中断的，网关就不会继续保持和上游的请求，自然收不到上游最后发过来的 usage 了。当然有些配置项可以修改这种行为，比如 Nginx 的 proxy_ignore_client_abort。但如果这么做的话，万一是正常的客户端想要提前终止推理，结果因为网关还是继续和上游通信而导致被多算钱就麻烦了。这种小伎俩可以骗过中间件，不过推理引擎侧还是能知道 prefill 时收到多少 input token，decode 时发出了多少 output token。所以最后给到来的账单还是正常的。</p><h2>守</h2><p>上述各种攻击手段，本质上揭示了当前 AI 网关在流式传输场景下的架构痛点：计费的异步性。在传统的 Request-Response 模型中，网关可以轻松拦截并统计流量；但在 LLM 的流式交互中，Token 的消耗是一个随着时间推移动态累加的过程，而精准的 token usage 报告往往滞后于请求的结束。只要网关依赖于“事后”的上报数据，客户端就有机会利用断连等手段制造“计费黑洞”。</p><p>那么有什么可靠的方式，能够不依赖推理请求中的 token usage 信息，自己在通信过程中算出实际的 token 用量？</p><p>最简单粗暴的方法，就是将字节数乘上一个 magic number 系数，作为找不到 token usage 时的 fallback。如果能在准确性上睁一只眼闭一只眼，这倒是开销最小的方案。</p><p>官方的做法，是调用模型提供商自己的 count token 接口。对于开源的推理引擎像是 vllm 或 TensorRT-LLM，也有对应的 tokenize 接口。只是要让网关在每次请求时额外发起多次 HTTP 调用，代价有点高，尤其在流式处理响应的时候。</p><p>一些编码库提供了本地 tokenize 的能力，如：</p><ul><li>huggingface/tokenizers</li><li>openai/tiktoken 和它的 Go 移植：pkoukk/tiktoken-go</li></ul><p>但是这些 tokenizer 在工作时需要知道模型的 tokenizer 配置，而模型提供商大概率不会公布这些数据。不过市面上也有这些私有模型的开源版本，比如 Gemma 之于 Gemini。不知道这些开源版本的 tokenizer 配置和私有的差别有多少，基于它们的 tokenizer 配置和官方的 count token 接口返回结果是否近似。</p><p>如果是自己部署的模型，那么理论上有了 tokenizer 配置就能自己本地做 tokenize，无需依赖一个远程的 tokenizer 服务。</p><p>假设 token usage 不是由本地提供，而是依赖远程的返回结果，出于谨慎起见，最好在基于 token 限额的同时加上基于请求数（或字节数，有的话更好）的限额，这样一旦远端无法返回 token usage，不至于出现完全不设防的情况。</p>]]></description></item><item>    <title><![CDATA[未来应用生态变革趋势探讨 小虫_top ]]></title>    <link>https://segmentfault.com/a/1190000047459352</link>    <guid>https://segmentfault.com/a/1190000047459352</guid>    <pubDate>2025-12-08 20:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>豆包手机助手遭到各方质疑，围绕微信、银行App等与人工智能的对抗成为热议焦点。但我们眼光放长远一些，或许能看到一个更本质的趋势：<strong>未来的应用生态，很可能会从“一个个孤立的产品”逐渐转向“一组组开放的接口”</strong>。</p><p>甚至连App这个概念本身都会慢慢淡化，成为数字发展史上的一个阶段性产物。越来越多的后端服务，应该在经过安全评审之后直接对外开放。面向终端用户的产品形态，也会像今天的阿里云、百度智能云那样——除了依赖固定的界面，也可以通过API的形式提供数据挖掘、图像识别、AI能力等核心功能。<br/><strong>用户无需被既定操作流程束缚</strong>，只需遵循接口规范，就能自主调用、组合这些服务，实现真正个性化的需求。这正是“智能化”走向深水区的体现：<strong>技术不再仅仅是给人用的工具，更成为可被自由调用的“数字积木”</strong>。</p><p>所有人都能感受到近两年大模型的迅猛发展，技术演进的速度远超我们的想象。与其争论“AI是否会取代程序员”，不如看清一个宏观事实：开发一款产品的门槛正在快速降低，周期不断缩短，智能程度持续提高。这意味着，<strong>未来的产品竞争维度必将发生改变</strong>。</p><p>一款优秀的产品，除了需要“直观、简洁、易懂”的人性化交互界面，也必然要提供“开放、安全、高效”的“机性化”可调用接口，这不再是一种选择，而会逐渐成为标配。</p><p>当然，<strong>任何变革都无法一蹴而就</strong>。如果现强行推动这样一场“接口化革命”，对许多依赖现有商业模式的公司来说，无疑会造成巨大冲击，比如现有的广告营收体系，或将面临重构。<strong>但方向已经清晰，新的竞赛其实早已悄然开始</strong>。</p><p>如果今天的独角兽们仍固守封闭的生态思维，执着于现有旧叙事，那么很可能，它们就会成为下一个诺基亚、下一个柯达——<strong>不是败给技术，而是输给了趋势</strong>。</p><p>时代从不停留，而唯一能确定的是：<strong>开放、连接与智能融合，正在重新定义我们与数字世界交互的方式</strong>。</p>]]></description></item><item>    <title><![CDATA[在 Pycharm 中 debug Scrapy 项目 codists ]]></title>    <link>https://segmentfault.com/a/1190000047459002</link>    <guid>https://segmentfault.com/a/1190000047459002</guid>    <pubDate>2025-12-08 19:05:35</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>缘起</h2><p>为什么写这篇文章呢？因为自己想在 Scrapy 项目里 debug, 看看 Response 有哪些属性。但是 Scrapy 的官方文档的 debug 说明只有 VSCode 的，没有 Pycharm 的(详见：<a href="https://link.segmentfault.com/?enc=eBtdfMM8hwzj6h%2BGwrf%2BTw%3D%3D.6sNNIP1co39SaiiTqJF%2B0dt6M5woeG%2FyofyFN%2BAAV3FO26y2ZcBPfMbV62lH%2Fb0OtuaTPAyLtLxUyNzQTQg7LQ%3D%3D" rel="nofollow" target="_blank">https://docs.scrapy.org/en/latest/topics/debug.html</a>)：</p><pre><code>{
    "version": "0.1.0",
    "configurations": [
        {
            "name": "Python: Launch Scrapy Spider",
            "type": "python",
            "request": "launch",
            "module": "scrapy",
            "args": [
                "runspider",
                "${file}"
            ],
            "console": "integratedTerminal"
        }
    ]
}</code></pre><p>当然，如果熟悉 VSCode 的人看到这个配置就明白其实执行方式是：python -m scrapy runspider xxx_spider.py (注：这里的 xxx_spider.py 指 spider 文件，如官方文档里面的 quotes_spider.py)。如果这个人同时还熟悉 Pycharm, 那么他就知道在 Pycharm 里面配置进行 debug：</p><p><img width="723" height="396" referrerpolicy="no-referrer" src="/img/bVdnipG" alt="" title=""/></p><p>很遗憾，我不是这样的人，所以就有了这篇文章。</p><h2>说明</h2><p>时间：2025/12/06</p><p>Pycharm 版本：2025.2.4</p><p>Python 版本：3.12.0</p><p>Scrapy 版本：2.13.4</p><p>Windows 版本：Win 11</p><h2>main.py</h2><p>在与 scrapy.cfg 文件同层级的目录中新建一个名为 main.py 的文件，用于 debug。示例：</p><pre><code># main.py
from scrapy.cmdline import execute


if __name__ == '__main__':
    print(1)
    print(2)
    execute(['scrapy', 'crawl', 'manning'])</code></pre><p>项目结构：</p><p><img width="723" height="234" referrerpolicy="no-referrer" src="/img/bVdnipK" alt="" title="" loading="lazy"/></p><h2>TypeError: 'Task' object is not callable</h2><p>当 Debug'main'时， 出现错误：</p><pre><code>2025-12-06 10:51:15 [asyncio] ERROR: Exception in callback &lt;Task pending name='Task-1' coro=&lt;ExecutionEngine.open_spider() running at D:\Projects\PythonProjects\python-talk\backend\venv\Lib\site-packages\scrapy\core\engine.py:430&gt; cb=[Deferred.fromFuture.&lt;locals&gt;.adapt() at D:\Projects\PythonProjects\python-talk\backend\venv\Lib\site-packages\twisted\internet\defer.py:1255]&gt;()
handle: &lt;Handle &lt;Task pending name='Task-1' coro=&lt;ExecutionEngine.open_spider() running at D:\Projects\PythonProjects\python-talk\backend\venv\Lib\site-packages\scrapy\core\engine.py:430&gt; cb=[Deferred.fromFuture.&lt;locals&gt;.adapt() at D:\Projects\PythonProjects\python-talk\backend\venv\Lib\site-packages\twisted\internet\defer.py:1255]&gt;()&gt;
Traceback (most recent call last):
  File "D:\Apps\Python3.12\Lib\asyncio\events.py", line 84, in _run
    self._context.run(self._callback, *self._args)
TypeError: 'Task' object is not callable</code></pre><p><img width="723" height="145" referrerpolicy="no-referrer" src="/img/bVdnipO" alt="" title="" loading="lazy"/><br/>之所以产生这个问题，不是代码的问题，是 Pycharm debuger 的问题，我还没梳理完，故暂不展开，只讲怎么解决。</p><h2>Debug 方式</h2><h3>方法 1：TWISTED_REACTOR</h3><ol><li>Settings &gt; Python &gt; Debugger，取消 Gevent compitable 的勾选。<br/><img width="723" height="187" referrerpolicy="no-referrer" src="/img/bVdnipP" alt="" title="" loading="lazy"/></li></ol><p>2.在项目的 settings.py 文件里设置 TWISTED_REACTOR = 'twisted.internet.selectreactor.SelectReactor'</p><p><img width="723" height="273" referrerpolicy="no-referrer" src="/img/bVdnipQ" alt="" title="" loading="lazy"/></p><h3>方法 2：python.debug.asyncio.repl</h3><p>1.Settings &gt; Python &gt; Debugger，取消 Gevent compitable 的勾选(这步和方法 1 是一样的)。<br/><img width="723" height="187" referrerpolicy="no-referrer" src="/img/bVdnipP" alt="" title="" loading="lazy"/></p><p>2.双击 Shift 键打开搜索窗口。</p><p>双击 Shift 的意思是“search everywhere，详见 <a href="https://link.segmentfault.com/?enc=q8IEv8FcpgZfiKocEztE2A%3D%3D.D2DsrKtXTM8%2F1uRCX%2FdWDe5DqJvefCJ%2FERPvaKQLD3UiBcFiqFtgagIDwaoMxhUduGkjxsEkyl7hdEZQYc4tNHxRu8sj9mg5osMDHSkuPQo%3D" rel="nofollow" target="_blank">https://www.jetbrains.com/help/pycharm/searching-everywhere.html</a>”。</p><p><img width="723" height="197" referrerpolicy="no-referrer" src="/img/bVdnipR" alt="" title="" loading="lazy"/><br/>3.点击 ALL 选项，输入 registry，最后点击 Regisry 选项。</p><p><img width="723" height="319" referrerpolicy="no-referrer" src="/img/bVdnipS" alt="" title="" loading="lazy"/></p><p>4.找到 python.debug.asyncio.repl，取消勾选 Value 列的方框。 <br/><img width="723" height="431" referrerpolicy="no-referrer" src="/img/bVdnipT" alt="" title="" loading="lazy"/></p><h2>验证</h2><p><img width="723" height="422" referrerpolicy="no-referrer" src="/img/bVdnipU" alt="" title="" loading="lazy"/></p><p>如上图所示，设置后可以 debug。</p><h2>参考资料</h2><p>1.Scrapy 文档, Debugging Spiders: <a href="https://link.segmentfault.com/?enc=iEQOrkid%2B1eoNdACgabyAw%3D%3D.cSxZkF5J7Xp%2BVIiWuz7gf220%2FSq394SZog3jJnu8k4yKwOx7%2BRps5wyiDzj4kO0WhXHqsDkE4e5mtNFg%2FpZ2WA%3D%3D" rel="nofollow" target="_blank">https://docs.scrapy.org/en/latest/topics/debug.html</a></p><p>2.Pycharm 文档，Search for a target by name：<a href="https://link.segmentfault.com/?enc=YyI1Rjbq92AkKo4jaYwFKw%3D%3D.mI97mAjvRoznZLOriWa399OPHYdbtnmZPpZv67xlZ7A5zSo5CranddGipgrYIJfri2CuhXSP2FANyHcFTgzhMOnJWYDJDCPwJxzZbltrnWA%3D" rel="nofollow" target="_blank">https://www.jetbrains.com/help/pycharm/searching-everywhere.html</a><br/><img width="723" height="263" referrerpolicy="no-referrer" src="/img/bVdfTXK" alt="" title="" loading="lazy"/><br/>欢迎搜索及关注：编程人(a_codists)，如有问题请留言。</p>]]></description></item><item>    <title><![CDATA[警惕“上下文污染”：为什么建议你频繁重置 AI 对话？ 飞奔的毛巾 ]]></title>    <link>https://segmentfault.com/a/1190000047459123</link>    <guid>https://segmentfault.com/a/1190000047459123</guid>    <pubDate>2025-12-08 19:05:04</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在使用 LLM 时，我们常遇到“风格漂移”和“逻辑幻觉”。 比如你让 AI 扮演 Python 专家“只写代码不解释”，但因为你中间追问了一次“为什么”，它在后续的回答里就开始喋喋不休地解释。</p><p>这是因为大语言模型的注意力是有限的。 当异质性内容（不同类型的话题）在历史记录中堆积，初始指令的权重就会被不可避免地削弱。</p><p>解决办法：</p><ol><li>一事一议 绝不混用窗口。写代码的窗口别用来写诗，翻译的窗口别用来做数学题。</li><li>物理隔离 任务一旦结束，或者话题一旦转换，立刻关闭当前对话。</li><li>学会“手动垃圾回收” 当你发现 AI 开始不听话，试图通过打字去纠正它（比如“请回到刚才的设定”）通常效果很差，因为这增加更多的噪音。 最高效的方法是：直接开新窗口，重新输入提示词。</li></ol><p>让每一个对话窗口都只为一个明确的目标服务。你会发现，那个“听话、聪明、精准”的AI，又回来了。</p>]]></description></item><item>    <title><![CDATA[SQL Server到Oracle：不同事务机制下的数据一致性挑战 RestCloud ]]></title>    <link>https://segmentfault.com/a/1190000047459136</link>    <guid>https://segmentfault.com/a/1190000047459136</guid>    <pubDate>2025-12-08 19:04:32</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在当今企业数据架构日益复杂的背景下，跨数据库平台的数据同步已成为许多组织的常态化需求。当数据需要从SQL Server迁移至Oracle时，我们不仅面临语法差异的挑战，更需深入理解两大数据库在事务处理机制上的本质区别。本文将深入探讨在异构数据库同步过程中，通过使用ETLCLoud的离线数据集成及实时数据集成功能，确保数据在跨平台传输时的一致性与完整性，为构建可靠的数据流通体系提供实践指导。</p><h3>一、创建数据源连接</h3><p>在平台首页左侧模块菜单栏找到数据源管理模块，下拉选择数据源列表选项。</p><p>右侧面板点击新建数据源按钮创建一个新的数据源连接。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459139" alt="图片 1" title="图片 1"/></p><p>根据自己的数据库类型选择，这里要连接SqlServer。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459140" alt="图片 2" title="图片 2" loading="lazy"/></p><p>根据面板信息填写相关信息，影响能否连接的主要配置有账号、密码、数据库IP端口，注意不能有空格。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459141" alt="图片 1" title="图片 1" loading="lazy"/></p><p>配置完信息后点击保存并测试连接按钮，上方弹出测试成功证明数据库连通。如果连接失败可以到监控中心查看控制台日志。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459142" alt="图片 2" title="图片 2" loading="lazy"/></p><p>再创建一个目标端Oralce的数据源。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459143" alt="图片 1" title="图片 1" loading="lazy"/></p><h3>二、创建离线同步流程</h3><p>在左侧离线数据集成模块找到流程管理，点击新建流程创建一个新的流程。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459144" alt="图片 1" title="图片 1" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459145" alt="图片 2" title="图片 2" loading="lazy"/></p><p>点击流程设计进入流程设计页面。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459146" alt="图片 3" title="图片 3" loading="lazy"/></p><p>从左侧组件栏拖取组件到右侧画布，并用路由线从开始连接到最后。</p><p>这里使用一个库表输入组件从SqlServer表拉取数据，用库表输出组件将数据推送到目标表。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459147" alt="图片 4" title="图片 4" loading="lazy"/></p><p>库表输入配置：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459148" alt="图片 5" title="图片 5" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459149" alt="图片 6" title="图片 6" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459150" alt="图片 7" title="图片 7" loading="lazy"/></p><p>库表输出组件配置：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459151" alt="图片 8" title="图片 8" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459152" alt="图片 9" title="图片 9" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459153" alt="图片 10" title="图片 10" loading="lazy"/></p><p>配置完流程，点击运行按钮运行数据同步任务。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459154" alt="图片 11" title="图片 11" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459155" alt="图片 12" title="图片 12" loading="lazy"/></p><p>等待流程运行，流程运行结束即完成同步任务。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459156" alt="图片 13" title="图片 13" loading="lazy"/></p><p>检查目标表数据</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459157" alt="图片 14" title="图片 14" loading="lazy"/></p><h3>三、实时数据同步</h3><p>离线同步数据后，后续源表如果有增量数据（数据增删改）想要同步到目标表，ETLCloud可以通过采集数据库日志的方式去读取表的增量数据，这样就不必每次同步都读取整张表造成资源的浪费，并且实时数据集成能让源表目标表达到毫秒级的数据一致。</p><p>但是实时数据集成需要对数据库做一下配置，因为主要是采集数据库归档日志，每种数据库开启CDC的步骤不一样，可以到官网帮助文档查看开启方法。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459158" alt="图片 15" title="图片 15" loading="lazy"/></p><p>开启数据库的CDC后，来到实时数据集成模块创建数据库监听器。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459159" alt="图片 16" title="图片 16" loading="lazy"/></p><p>这里源表和目标表表机构一致就采用直接传到到目标的同步方式，如果需要对增量数据做特殊处理可以使用传输到ETL的方式。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459160" alt="图片 17" title="图片 17" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459161" alt="图片 18" title="图片 18" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459162" alt="图片 19" title="图片 19" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459163" alt="图片 20" title="图片 20" loading="lazy"/></p><p>配置好监听器后点击增量启动监听器。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459164" alt="图片 21" title="图片 21" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459165" alt="图片 22" title="图片 22" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459166" alt="图片 23" title="图片 23" loading="lazy"/></p><p>对源表进行数据更改</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459167" alt="图片 24" title="图片 24" loading="lazy"/></p><p>数据库监听器捕获到了源表的变更数据，并且直接将源端的增删改都同步到目标表。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459168" alt="图片 25" title="图片 25" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459169" alt="图片 26" title="图片 26" loading="lazy"/></p><p>检查目标表数据与源表一致。</p><h3>四、最后</h3><p>通过从SQL Server到Oracle的完整同步实践，我们看到在异构数据库环境中维护数据一致性需要系统性的解决方案。无论是离线全量同步还是实时增量同步，关键在于深入理解不同数据库的事务特性，并选择与之匹配的同步策略。ETLCloud通过CDC机制实现了近乎实时的数据同步，有效解决了异构环境下的数据一致性问题。随着企业数据生态的不断发展，掌握跨数据库平台的同步技术将成为数据工程师的核心能力，为构建更加弹性、可靠的数据架构奠定坚实基础。</p>]]></description></item><item>    <title><![CDATA[AI 正在“杀死”敏捷开发？它反而让我们重新读懂敏捷的真谛 悲伤的斑马 ]]></title>    <link>https://segmentfault.com/a/1190000047459203</link>    <guid>https://segmentfault.com/a/1190000047459203</guid>    <pubDate>2025-12-08 19:03:38</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>最近在技术论坛刷到个热门话题：“AI 时代，敏捷开发是不是要凉了？”有人贴出代码生成工具的截图，配文“现在AI 10分钟能写完的代码，还要什么迭代开发？”；也有人悲观预言：“敏捷的核心是‘人’，AI来了，人的价值被稀释了。”</p><p>作为从业8年的产品经理，我亲历过从瀑布模型到敏捷转型的阵痛，也玩过ChatGPT写需求文档、GitHub Copilot生成代码。但越用越觉得：AI不是在替代敏捷，而是在用最直接的方式，把敏捷开发中那些“形式化”的泡沫戳破，逼我们回归最本真的敏捷。</p><p>一、被误解的敏捷：我们早就偏离了初心<br/>先问个问题：你所在的团队，真的在做“敏捷”吗？</p><p>我见过太多“伪敏捷”现场：</p><p>每天站会变成“汇报表演”，15分钟扯皮1小时；<br/>用户故事拆得比分子还细，但没人关心真实需求；<br/>迭代评审会成了“背锅大会”，开发吐槽产品改需求，产品吐槽测试漏bug；<br/>最讽刺的是，有些团队连“敏捷教练”都配齐了，但交付的产品依然离用户十万八千里。<br/>敏捷开发的本质是什么？《敏捷宣言》的四大价值观早就写明白了：<br/>个体与互动 &gt; 流程与工具<br/>可工作的软件 &gt; 全面的文档<br/>客户合作 &gt; 合同谈判<br/>响应变化 &gt; 遵循计划</p><p>但现实中，我们往往把敏捷做成了“流程崇拜”——用Jira看板划分任务状态，用燃尽图证明“我们在敏捷”，用固定两周的迭代周期掩盖对需求的逃避。当敏捷变成一套标准化的SOP，它就已经死了。</p><p>二、AI 来了，先“杀死”的是伪敏捷<br/>现在AI登场了，它最先冲击的，恰恰是这些“形式化敏捷”的痛点。</p><ol><li>代码生成工具：打破“为迭代而迭代”的怪圈<br/>以前我们拆用户故事，总爱把一个功能切成“前端页面”“接口开发”“联调测试”三期，美其名曰“小步快跑”。但AI可以直接生成完整可运行的代码模块，甚至自动补全测试用例。这时候再强行拆解迭代，反而成了效率拖累——敏捷的“快速交付”不是目的，快速验证价值才是。</li><li>需求分析工具：倒逼我们直面真实用户<br/>用AI做用户调研是什么体验？输入“25-30岁一线城市女性，健身爱好者，想通过APP记录饮食”，它能瞬间生成10条用户故事，甚至模拟出使用场景对话。但这些“完美需求”背后，藏着更残酷的真相：如果AI都能替代我们理解用户，那产品经理的核心价值是什么？<br/>答案是：比AI更懂“人”。敏捷强调“客户合作”，但很多团队把“客户”简化成了产品经理自己。AI的出现，逼我们走出办公室，去和真实用户聊天——因为只有人的洞察，才能让需求从“正确”变成“惊艳”。</li><li>自动化测试：让“响应变化”不再昂贵<br/>传统敏捷中，测试是瓶颈：改一行代码可能触发连锁反应，回归测试要花半天。但AI驱动的自动化测试能实时监控代码变更，自动生成测试报告。这意味着什么？我们可以更勇敢地调整需求了——因为试错成本被AI拉低了，敏捷的“响应变化”才能真正落地。</li></ol><p>三、AI 时代，我们需要怎样的敏捷？<br/>说到底，AI不是敏捷的敌人，而是“敏捷升级”的催化剂。它让我们看清：敏捷的核心从来不是“快”，而是“灵活”——灵活地理解需求、灵活地调整方向、灵活地创造价值。</p><p>未来真正稀缺的敏捷团队，会具备这三种能力：</p><ol><li>人类独有的“价值判断力”<br/>AI能生成代码，但判断“这个功能该不该做”“用户会不会买单”的，只能是人。敏捷中的“用户故事”，未来会从“作为XX，我需要XX”变成“作为XX，我愿意为XX付费”——因为AI让试错成本降低，我们可以更聚焦商业价值。</li><li>跨领域的“系统思维”<br/>当AI接管了代码、测试、甚至部分设计工作，团队成员需要跳出单一角色，理解整个产品链路。比如产品经理要懂技术架构，开发要懂用户心理——因为敏捷的“个体与互动”，在AI时代会升级为“多学科碰撞”。</li><li>持续学习的“反脆弱”心态<br/>AI在进化，敏捷团队也必须进化。那些抱着“我懂敏捷流程”吃老本的人，终将被淘汰；但那些把AI当工具、不断拓展能力边界的人，会成为新时代的“敏捷超级个体”。</li></ol><p>最后：敏捷从未过时，过时的是我们对敏捷的想象<br/>20年前，敏捷宣言是对“重型流程”的反叛；20年后，AI是对“形式化敏捷”的反叛。变化的从来不是敏捷本身，而是我们理解敏捷的方式。</p><p>所以下次再有人问你“AI来了，敏捷还重要吗？”，你可以这样回答：<br/>“AI不是在替代敏捷，而是在帮我们撕掉敏捷的‘标签’，回到那个最本质的问题：我们究竟在为什么而敏捷？”</p>]]></description></item><item>    <title><![CDATA[2025年团队知识库与知识管理工具选型指南：评估维度与思维框架 许国栋 ]]></title>    <link>https://segmentfault.com/a/1190000047459231</link>    <guid>https://segmentfault.com/a/1190000047459231</guid>    <pubDate>2025-12-08 19:02:54</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <blockquote>在企业数据驱动转型的过程中，仅靠项目管理、CI/CD、代码仓库工具，往往难以形成系统化的“组织知识资产”。团队知识库成为连接“人—项目—知识—复用”的关键桥梁。本文聚焦主流团队知识库工具，从战略与执行双层视角分析其适用性、优势与局限，并提出“工具之外”的思维框架，帮助中高层研发负责人、PMO、效能管理专家在选型时作出理性决策。</blockquote><h2>为什么知识库建设对现代研发组织至关重要</h2><p>在大型、复杂的 B2B 研发组织中，技术规范、架构设计、需求文档、测试方案、运维流程、项目复盘、新人 onboarding、跨团队协作……这些知识与经验，往往分散在代码仓库、即时通讯、文件共享、项目管理系统、邮件、甚至 “某个老员工脑袋里”。</p><ul><li>这样的分布方式，会导致知识难以检索、沉淀和复用。每当类似问题重复出现，团队无时借鉴，容易“重新造轮子”；</li><li>新员工 onboarding、跨团队合作、知识传承成本高，效率低下；</li><li>当关键人员离职、业务扩展、合规审计、交接与培训出现时，知识流失与风险暴露更为严重。</li></ul><p>研究表明，将组织隐性知识转为显性知识，是企业知识管理的核心任务。</p><p>一个好的知识库，远不应只是“文档存储”的集合——它应该承担组织的“记忆”和“学习”功能。通过结构化、分类、权限、版本控制、搜索、标签／元数据管理、关联项目与任务、与工具链集成、审计与治理机制，一个知识库能真正成为企业的长期知识资产。</p><p>企业实践也表明，系统化知识管理可以显著提升决策效率、减少重复劳动、加速协作、缩短新人成熟周期，并为创新、合规与风险管理提供基础。</p><p>因此，知识库建设，是组织从“项目驱动型”向“能力／资产驱动型”跃迁的重要一步。</p><h2>主流团队知识库工具测评（2025 年终总结）</h2><p>以下是几款当前国内外广泛使用、适合不同发展阶段和组织规模的知识库工具，包括 ONES Wiki、Confluence、GitBook、Tettra、Notion、Nuclino。它们各有定位，没有“万能最优”，关键在于与你组织的阶段、规模、治理水平、战略规划匹配。</p><h4>ONES Wiki——一体化的文档协同和知识库管理工具</h4><p>核心功能：成熟的企业级知识管理平台，能把“文档／知识／经验／流程”组织起来，支持多人协同编辑、版本控制、权限管理、模板机制、与项目/任务管理系统集成、文档关联项目/任务、支持多种内容嵌入（思维导图、代码片段、流程图等）以及内容结构化。支持组织细粒度权限、安全、审计等。</p><p>适用场景：中大型企业、复杂项目 / 多团队协作、有合规／审计／安全要求、需要知识与任务／项目全流程关联、追求长期知识资产积累与治理的组织；尤其适合技术、产品、运维、管理等多角色协作与知识共享。</p><p>优势亮点：<br/>一体化：将知识库与项目任务管理、DevOps／交付流程关联，减少信息孤岛。<br/>权限与治理：支持分类、读写权限、版本控制、模板机制、结构化管理，便于制度化管理与审计。<br/>灵活性与扩展性：支持多种内容类型，可嵌入代码、流程图、表格等，适合复杂业务与混合团队需求。</p><p>【ONES 官网：<a href="https://link.segmentfault.com/?enc=7nrAkJTBvthL7GNMlCAurw%3D%3D.PxOLi5TykxP9YDLaDu%2Fm7gxPs7PVXuQGuMP09wUole8%3D" rel="nofollow" target="_blank">https://ones.cn/</a> 】</p><p><img width="723" height="436" referrerpolicy="no-referrer" src="/img/bVdnirQ" alt="ONES Wiki 文档协同和知识库管理工具" title="ONES Wiki 文档协同和知识库管理工具"/></p><h4>Confluence——稳定的企业级 Wiki</h4><p>核心功能：包括空间（Space）和页面划分、多级页面结构、版本控制、权限管理、模板与蓝本、历史版本、全文搜索、富文本／表格／宏／流程图嵌入等。与项目管理／需求管理工具（如 Jira）在生态中常有集成。</p><p>适用场景：中到大型组织、已有 Atlassian 生态基础、对文档规范、流程文档、制度文档、架构设计、长期技术／管理文档管理有需求；适合文档规范化、流程制度化、需要稳定可靠文档平台的组织。</p><p>优势亮点：<br/>成熟、稳定、功能全面；适合建立系统化文档体系、规范反馈机制、文档审批、审计与版本控制；<br/>与项目管理工具集成，有助于将文档、任务、需求、缺陷等信息统一管理，实现 traceability；<br/>对于技术 / 管理 /制度文档、规范、安全政策文件等，需要严谨格式、统一管理的内容特别适合。</p><p>局限与挑战：<br/>灵活性、现代体验、结构化／数据库式内容支持较弱；不太适合“结构化条目 + 元数据 + 枚举 + 数据 + 文档混合”的复杂知识形式；<br/>对非文档型、快速变化型、需要轻量、快速响应的团队而言，上手和维护成本较高；<br/>如果仅作为“文档仓库”，与项目／交付流程及工具链分离，知识与执行脱节，也降低沉淀和复用价值。<br/>【官网：<a href="https://link.segmentfault.com/?enc=ceKceiEVDqPrL7c7NSWC5A%3D%3D.KNMSujJ39j7dNE650V5Z%2F9PLr5DMk6SjOzqag5Vuj%2Fd%2Br47QHRQiEtBShEBlwawxrzMlJCcOe3%2BVb36g3qxfPQ%3D%3D" rel="nofollow" target="_blank">https://www.atlassian.com/zh/software/confluence</a> 】<br/><img width="723" height="428" referrerpolicy="no-referrer" src="/img/bVdnirR" alt="" title="" loading="lazy"/></p><h4>GitBook—— 开发文档与技术知识库专家</h4><p>核心功能：以 Markdown 为基础的在线文档与知识库平台，支持文档编辑、版本控制、多用户协作、目录／导航结构、全文搜索、导出、历史版本、评论／审核等。适用于技术文档、API 手册、操作手册、对内／对外文档库等维护。</p><p>适用场景：技术团队、产品团队、需要维护 API 文档、技术规范、用户手册、内部／对外技术文档、轻量／中量级文档库的组织。也适合快速搭建文档库、对文档结构有一定规范要求，但对流程／项目管理要求不高的情况。</p><p>优势亮点：<br/>对开发者友好（Markdown + 版本管理 + 与 Git 思维兼容）；<br/>前端简洁、专注文档本身，适合轻量、中量级文档管理；<br/>适合技术文档/规范/说明书等对格式、结构、可读性有要求的内容；易于对外分享。</p><p>局限与挑战：<br/>不具备复杂权限管理、内容治理、版本审批、任务／项目／交付／流程关联、结构化数据管理等能力；<br/>不适合将知识库作为“公司级知识资产管理 + 知识治理 + 持续维护 + 流程闭环”的平台；<br/>【官网：<a href="https://link.segmentfault.com/?enc=5T44I8q5KHLmGX3uIz9TRQ%3D%3D.pkxplMHOQZQnG7EsrPzvrdG4Rnyj5LVUe2CMjviQS7U%3D" rel="nofollow" target="_blank">https://www.gitbook.com/</a> 】<br/><img width="723" height="389" referrerpolicy="no-referrer" src="/img/bVdnirV" alt="" title="" loading="lazy"/></p><h4>Tettra——轻量团队内部知识共享平台</h4><p>核心功能：轻量级团队 Wiki / 知识库平台，强调易用性、快速部署、与协作／沟通工具（例如 Slack）集成、知识 Q&amp;A / FAQ /流程说明、标签／分类、全文搜索、共享与协作。适合快速建立团队内部知识共享机制。</p><p>适用场景：小型／中型团队、初创公司、远程／分布式团队、跨职能协作频繁、需要轻量共享内部经验、流程说明、FAQ、SOP 的场景。适合希望快速搭建知识库并降低维护成本的组织。</p><p>优势亮点：<br/>上手门槛低，部署速度快，适合敏捷、灵活、小规模团队；<br/>与协作 / 沟通工具集成，降低使用门槛，提高知识访问频率；<br/>适合动态知识、经验总结、流程说明、FAQ 等轻量／非结构化内容管理。</p><p>局限与挑战：<br/>权限控制、版本管理、文档生命周期管理、审计、内容结构化、分类／标签治理等能力较弱；<br/>随着团队规模扩大、内容体量增长，容易出现混乱、重复、冗余、难以维护的问题；<br/>难以支撑复杂项目、多团队、多角色、长期知识资产化、治理与合规需求。<br/>【官网：<a href="https://link.segmentfault.com/?enc=9ipp5yXjQEd4FRHOBfJhmQ%3D%3D.rSJKCd4lGSquLt66EoliZOScQc8m8t34nNOcCS8LNYA%3D" rel="nofollow" target="_blank">https://tettra.com/</a> 】<br/><img width="723" height="377" referrerpolicy="no-referrer" src="/img/bVdnirW" alt="" title="" loading="lazy"/></p><h4>Notion——灵活的混合内容与协作空间</h4><p>核心功能：模块化工作空间，包括文档、页面、数据库/表格/看板、页面嵌套、模板、数据库视图、任务管理与内容混合管理。适合文档、数据、任务、协作混合管理。</p><p>适用场景：小型／中型团队、跨职能团队、对灵活性、快速响应、混合内容管理（例如文档 + 数据表 + 流程 +任务）的需求较高的组织；适合研发、产品、设计、运营混合团队；适合快速搭建、迭代、试错。</p><p>优势亮点：<br/>灵活、模块化、高度自定义，能够适应快速变化、需求不确定的业务环境；<br/>支持混合内容（文档 + 数据 +任务 +看板 +流程）；适合多角色、多职能协作团队；<br/>用户友好，界面现代，适合非技术背景的团队成员。</p><p>局限与挑战：<br/>权限治理、结构化治理、审计与合规能力弱，不适合对文档安全性、审批流程、长期维护有严格要求的组织；<br/>随着内容与团队规模扩大，容易出现分类混乱、权限混乱、内容重复与冗余、缺乏结构化治理。<br/>【官网：<a href="https://link.segmentfault.com/?enc=2HpJ2BE0LPa%2Fyr05rScJjg%3D%3D.Vw9w7EdZ9OgLKvhBSljT2or6kvjbCrvsYTaP5%2BgnEE0%3D" rel="nofollow" target="_blank">https://www.notion.com/</a> 】<br/><img width="723" height="474" referrerpolicy="no-referrer" src="/img/bVdnirY" alt="" title="" loading="lazy"/></p><h4>Nuclino——简洁轻量的团队知识库</h4><p>核心功能：轻量团队协作／知识库工具，支持实时协作、多用户编辑、标签／分类、知识图谱／知识关系地图、全文搜索、版本历史、简单结构化与导航。适合构建内部知识库、团队 Wiki、经验共享库。</p><p>适用场景：初创／中小型团队、分布式团队、跨职能协作、希望快速建立知识共享和协作机制、内容体量适中、结构不复杂的组织。</p><p>优势亮点：<br/>界面简洁、上手成本低；适合快速启动知识管理；<br/>支持标签、分类、知识关系图谱／地图，便于知识结构化和关联；<br/>实时协作、多人编辑、快速编辑 / 更新，适合动态、频繁变化的知识内容。</p><p>局限与挑战：<br/>权限控制、内容治理、版本审批、审计、安全合规、长期维护机制缺乏；<br/>对复杂组织结构、多团队、多角色、合规审计、多项目交付的组织支持不足；<br/>【官网：<a href="https://link.segmentfault.com/?enc=D4nS%2BtauHWaaQZ8eW3IRnQ%3D%3D.jfSb63qmV%2FEyqfUZOmyeoltbtVn6V3axvwkEGeGvHz4%3D" rel="nofollow" target="_blank">https://www.nuclino.com/</a> 】<br/><img width="723" height="438" referrerpolicy="no-referrer" src="/img/bVdnir1" alt="" title="" loading="lazy"/></p><h2>从战略视角看：关键维度对比与决策要素</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459233" alt="图片" title="图片" loading="lazy"/></p><h2>工具之外：构建组织知识管理能力的战略框架</h2><p>作为管理者，我建议将知识库建设作为组织战略能力建设的一部分，而不仅仅是工具部署。以下是必须同步建设的能力与机制。</p><h4>知识文化 &amp; 贡献机制 —— 知识不是“写一次就完事”</h4><p>责任与所有权：明确谁负责文档撰写、谁负责审核、谁负责更新／归档。知识不是某个人的副产品，而是组织的资产。</p><p>激励与制度化：通过绩效、考核、奖励机制，鼓励团队贡献与维护文档；将文档／知识产出／更新纳入项目交付／迭代流程 — 即“项目完成 + 文档归档”成为标准步骤。</p><p>标准、模板与规范体系：制定统一文档模板、分类／标签体系、版本管理规则、内容生命周期定义、审查与归档流程。保证文档风格一致、可管理、可检索、易维护。</p><h4>与项目／DevOps／工具链深度融合</h4><p>构建知识 ↔ 流程 ↔ 执行 ↔ 复盘闭环。</p><p>将知识库与代码仓库、CI/CD、测试／发布／运维工具、项目管理系统集成，使经验／方案／决策／复盘／文档与交付流程关联 — 打通“需求 → 设计 → 实施 → 复盘 → 文档／知识沉淀 → 下一轮复用”的闭环。</p><p>确保每个项目、每次交付、每次复盘都有文档与知识沉淀产出，形成可持续的知识积累机制，使知识库真正成为组织基础设施的一部分。</p><h4>数据驱动与知识资产分析 —— 可衡量、可优化</h4><p>对知识库的使用情况（访问频率、文档活跃度、内容覆盖率、过期文档、贡献者分布、更新频率等）进行监控与统计。</p><p>将这些数据与业务 / 项目绩效（交付周期、缺陷率、新人上手速度、重复问题数量等）关联分析，以量化知识库对效率、质量、协作、风险降低等方面的贡献 — 即衡量知识库 ROI。</p><p>基于分析结果，识别知识薄弱领域、制定补充／优化策略、调整文档结构与内容、优化流程与治理机制，推动持续改进。</p><h4>可扩展性 / 未来适应性 —— 为组织长期发展留足弹性</h4><p>随着组织规模增长、团队分布广、业务复杂度提升、合规需求上升、国际化发展，需要支持灵活扩展、模块化治理、多租户／多团队管理、多语言、多地域协作、权限分级、审计合规、知识图谱、多内容类型、移动／云端访问。</p><p>同时，应规划适应未来趋势 — 支持 AI / NLP / 知识图谱 / 智能搜索 / 智能推荐 / 自动分类 / 内容质量检查 / 跨系统同步等能力，使知识库持续进化为“智能知识资产管理平台”。</p><h2>知识库建设，是组织能力建设，而不仅仅是工具部署</h2><p>当下，知识库工具众多，从轻量、灵活、快速部署，到企业级、功能全面、治理规范。关键不在于“哪个工具最流行”，而在于是否与组织的阶段、规模、治理需求、未来规划契合。</p><p>真正能够带来组织效能提升与竞争力增强的，不是某一个好用的工具，而是：</p><ol><li>一个 制度化 + 文化化 的知识贡献与管理机制；</li><li>一个 与项目 / DevOps / 工具链深度融合 的知识闭环体系；</li><li>一个 将知识视为组织资产 的理念体系，具备 数据驱动、可衡量、可治理、可复用、可持续 的知识管理能力；</li><li>一个 具备扩展性与未来适应性 的平台化／架构化布局，为组织长期发展留足空间。</li></ol><p>因此，对于中大型、B2B、业务线复杂、团队多元、强调数据驱动与协同效率的研发组织，应把知识库建设视为战略基础设施 — 把“知识库”当作“知识资产管理 + 组织能力建设”的长期项目来规划。</p><p>与其纠结“今天选择哪个工具”，不如先问自己三个问题：</p><ul><li>我们希望未来的研发组织是什么样子？</li><li>我们希望知识库在未来承载怎样的能力与价值？</li><li>我们是否准备好为知识管理设立制度、流程、责任与文化？</li></ul><p>当你对这些问题有明确答案时，再去选工具、建机制、落实推进 — 将比仅仅选一个“好工具”更具战略价值。</p>]]></description></item><item>    <title><![CDATA[『京墨文库』鸿蒙版上线！ hefengbao ]]></title>    <link>https://segmentfault.com/a/1190000047459251</link>    <guid>https://segmentfault.com/a/1190000047459251</guid>    <pubDate>2025-12-08 19:02:12</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>用了二十多天，边学习边做项目，使用官方提供的 ArkTS、ArkUI、ArkData、ArkWeb、NetworkKit 等技术栈开发的原生 APP，完成了第一个版本的基础功能，相对于 Android 版而言，功能有些单薄，以后一点一点迭代添加了。先发布一个版本，看看使用情况。</p><p>之前使用 Android Jetpack Compose 、 Room 、Datastore(Preference) 等技术实现了 Android 版，对照之下对于 ArkUI、ArkData 等技术理解起来也轻松一点，虽然有些磕磕绊绊，但还是完成了基础的功能。</p><p>申请上架 3 次被驳回，第 4 次终于成功上架华为应用市场，如果使用华为系手机和纯血鸿蒙系统（HarmonyOS  NEXT），感兴趣的话可以下载试一下。</p><p><img width="723" height="222" referrerpolicy="no-referrer" src="/img/bVdnitV" alt="" title=""/></p><p>最低支持的 HarmonyOS 版本选择了 5.1.1(19)，研究了版本变迁列表，这是 HarmonyOS 5 最新的版本，既然都用了 HarmonyOS 5 系统，那升级到最新版也是不错的选择吧😄。</p><p><img width="723" height="414" referrerpolicy="no-referrer" src="/img/bVdnitW" alt="" title="" loading="lazy"/></p><p>项目仍然是开源的：</p><p><a href="https://link.segmentfault.com/?enc=iA0TeZISNnqvM9ri5nuYWA%3D%3D.eaMu4oBFvsYmKeIdUJ4UTelxcHR8jmwDn8%2FcvqsDqolAiJULeX14m70cZWQorIi2zbL%2BN3PWVNxsosjSzi2YAg%3D%3D" rel="nofollow" target="_blank">https://github.com/hefengbao/jingmo-for-HarmonyOS</a></p><p><a href="https://link.segmentfault.com/?enc=qv0ToI6AS54EDKB8hHzlRQ%3D%3D.kFbn3UI8n3DxgluWv87nAmbqUF1yylxvVqwCaKVS96pWGV9AGuc4tY6FZj%2FVMfptBtUnfnpdkl9GO8j1lAUOGA%3D%3D" rel="nofollow" target="_blank">https://gitee.com/hefengbao/jingmo-for-HarmonyOS</a></p><p>另外也附上 Android 版的仓库：</p><p><a href="https://link.segmentfault.com/?enc=57W%2F93L9X0Hj%2Fry7adcUpw%3D%3D.nk1ao%2FQ14kLFyRnqb6J8BSZlsjRbfOL9tAqqxpr7DMgZZoz14m8NLnJcrBeHC3m5" rel="nofollow" target="_blank">https://gihub.com/hefengbao/jingmo</a></p><p><a href="https://link.segmentfault.com/?enc=mGd%2BE%2BB8vI3loAhusZeZeQ%3D%3D.a%2FhBHBqUompydzC%2B8A2TDqx2XzICU4XwpoHo3nYcp%2FBxSPw2TJcNYmR9tziYIGDl" rel="nofollow" target="_blank">https://gitee.com/hefengbao/jingmo</a></p><p>IDE 使用官方提供的 DevEco Studio，模拟器用起来都挺方便。但也遇到过一些问题：</p><p><strong>经检测发现，您的应用使用了HarmonyOS beta版本的API。</strong></p><p>修改建议：为提升消费者使用体验，请使用HarmonyOS release版本的API开发应用，申请上架。请参考版本说明集成release版本API：<a href="https://link.segmentfault.com/?enc=lEty9bw6VUjcTkwAu0LNDw%3D%3D.2D2w1SiZBDOl309DcU%2Fm7EJdS1dqGgkubdvLVCMcwFg4uA17vYNWyxjrBzcOMPmdJ5FHvQkuEEB3n4yjB%2F1Jnun4nzldwpSr3Jpg%2F7%2BFfyGWFrLMiJj8zAZo8d7t0DD%2F" rel="nofollow" target="_blank">https://developer.huawei.com/consumer/cn/doc/harmonyos-releas...</a></p><p>解决：下载使用 release 版本的 IDE</p><p><strong>Navigation 添加了路由后不生效</strong></p><p>点击 “构建” - “清理构建” 后，重新运行项目。</p>]]></description></item><item>    <title><![CDATA[AI 招聘智能体核心功能清单 爱跑步的香蕉_cKtiNz ]]></title>    <link>https://segmentfault.com/a/1190000047459285</link>    <guid>https://segmentfault.com/a/1190000047459285</guid>    <pubDate>2025-12-08 19:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>AI 招聘智能体核心功能清单<br/>AI招聘智能体：重塑招聘决策的智能化变革<br/>传统招聘正逐渐成为企业发展的“隐性天花板”，人才短缺、筛选耗时、复试标准不一、候选人体验不佳等问题频发。与此同时，AI智能体在人力资源管理领域的应用加速渗透，为企业带来降本增效、业务协同、提升员工体验、数据化决策四大核心战略价值，推动招聘行业迎来根本性变革。</p><p>招聘智能化的核心：精准与体验双突破<br/>AI招聘智能体的核心竞争力集中在“精准”与“体验”两大维度，针对性解决传统招聘低效、主观、成本高的核心痛点，成为企业决胜招聘的关键支撑。<br/>精准评估：告别“凭感觉”的科学决策<br/>AI招聘智能体的打分体系经过多重实证验证，不仅能与企业面试官进行一对一“背靠背”比对，还通过效标效度与重测信度双重验证，评估结果可直接作为招聘决策依据，而非单纯的辅助参考。<br/>这种精准性贯穿招聘全环节：<br/>•一问多能，一道题目即可同步评估多项能力，无需HR初筛与技术复试反复衔接，评估效率提升50%以上。<br/>•具备自由追问能力，根据候选人回答生成针对性问题，如同资深面试官般精准捕捉核心能力点。<br/>•自动深度挖掘简历信息，抓取关键亮点与模糊疑点，通过递进式提问杜绝造假行为，同时避免遗漏优质候选人。<br/>•覆盖通用能力与专业领域考察，从沟通协作到编程算法、工程财务等专业技能，均可精准出题评估，大幅减轻HR与专业面试官的工作负担。<br/>体验升级：让面试成为雇主品牌加分项<br/>传统AI面试因机械、生硬的交互模式备受诟病，新一代AI招聘智能体通过“拟人化交互”彻底优化候选人体验：<br/>•能识别候选人的语速、情绪及暗含信息，通过有效引导帮助候选人稳定发挥，展现真实能力。<br/>•自动识别答题状态，无需手动点击操作，全程无打断，营造自然流畅的交流氛围。<br/>•实现语音与口型精准同步，打造沉浸式视觉体验，摆脱“纸片人AI”的刻板印象。<br/>•支持多轮对话答疑，实时回应候选人关于岗位职责、福利待遇、招聘流程等疑问，有效提升入职意愿。<br/>优质的面试体验已不再是附加项，而是企业展示雇主品牌、吸引优质人才的重要竞争力。<br/>从自动化到“自动识人”：招聘全流程智能闭环<br/>AI人才寻访智能体的出现，将招聘流程从单纯的自动化推向“自动识人”的新阶段，构建起完整的智能招聘流水线：<br/>•配置便捷，30-60秒即可启动使用，开启后无需人工值守。<br/>•按年龄、学历、薪资等预设条件自动筛选简历，精准识别符合要求的候选人。<br/>•模拟人类语气与候选人动态沟通，具备提问、交流、筛选淘汰的完整交互能力。<br/>•全覆盖处理未读消息，逐条进行个性化回复，确保沟通无遗漏。<br/>•拟人化交互细节拉满，缺简历时主动请求投递，模仿真实打字节奏交流，增强沟通自然感。<br/>•自动下载简历并上传至企业ATS系统，生成完整候选人档案，同时保障数据流转安全。<br/>这一闭环体系将招聘中的“经验型判断”彻底升级为“数据型决策”，推动招聘流程更科学、更高效。<br/>拥抱AI招聘：把握行业变革机遇<br/>AI技术正在重构招聘行业的底层逻辑，传统依赖人工的招聘模式已难以适应企业快速发展的需求。AI招聘智能体通过精准评估提升招聘质量，通过流程优化降低时间与人力成本，通过体验升级强化雇主品牌，全方位破解传统招聘痛点。<br/>对于企业而言，拥抱招聘智能化已不是可选项，而是在人才竞争中占据优势的必然选择，更是顺应行业发展趋势、突破增长瓶颈的关键举措。</p>]]></description></item><item>    <title><![CDATA[【赵渝强老师】TiDB的备份恢复策略 赵渝强老师 ]]></title>    <link>https://segmentfault.com/a/1190000047458791</link>    <guid>https://segmentfault.com/a/1190000047458791</guid>    <pubDate>2025-12-08 18:12:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>数据库在运行过程中会出现各种故障，因此对数据库进行必要的备份是非常重要的。有了数据库的备份就可以在数据库出现错误时保证数据的安全。因此TiDB数据库提供了强大的数据库备份与恢复机制。</p><p>基于Raft协议和合理的部署拓扑规划，TiDB实现了集群的高可用，当集群中少数节点挂掉时，集群依然能对外提供服务。在此基础上，为了更进一步保证用户数据的安全，TiDB还提供了集群的备份与恢复(Backup &amp; Restore,BR)功能，作为数据安全的最后一道防线，使得集群能够免于严重的自然灾害，提供业务误操作“复原”的能力。</p><p>TiDB备份恢复功能可以用于满足以下业务的需求：</p><ul><li>备份集群数据到灾备系统，并保证Recovery Point Objective(RPO)低至5分钟，减少灾难场景下数据的丢失。</li><li>处理业务数据写错的案例，提供业务操作的“复原”能力。</li><li>审计业务的历史数据，满足司法审查的需求。</li><li>复制(Clone)生产环境，方便问题诊断、性能调优验证、仿真测试等。</li></ul><p>TiDB支持四种备份恢复策略，分别是：全量（快照）备份与恢复、日志备份与恢复、数据的逻辑导出和导入和闪回。下面分别进行介绍。</p><p>视频讲解如下：<br/><a href="https://www.bilibili.com/video/BV1ph2rBKEJG/?aid=115682142328793&amp;cid=34585247791" target="_blank">https://www.bilibili.com/video/BV1ph2rBKEJG/?aid=115682142328...</a></p><h2>一、 全量（快照）备份与恢复</h2><p>全量备份是对集群某个时间点的全量数据进行备份，TiDB的全量备份也可以叫做快照备份。因为TiDB集群快照数据包含某个物理时间点上集群满足事务一致性的所有数据。</p><p>全量备份一般会占用较大的存储空间，且只包含某个时间点的集群数据。执行tiup br backup full命令，可以备份TiDB最新的或者指定时间点的快照数据。执行tiup br backup full --help可获取该命令的使用帮助。下面的步骤将对数据库集群进行全量备份。</p><p>（1）创建一个目录用于保存集群快照备份产生的文件</p><pre><code class="powershell">mkdir -p /backup/snapshot/full
chown -R tidb:tidb /backup/snapshot/full</code></pre><p>（2）执行备份集群快照</p><pre><code class="powershell">tiup br backup full \
    --pd "192.168.79.10:2379" \
    --storage "local:///backup/snapshot/full" \
    --log-file /backup/snapshot/full/backupfull.log
    
# 输出的信息如下：
Starting component br: 
         /root/.tiup/components/br/v8.5.1/br backup full \
         --pd 192.168.79.10:2379 \
         --storage local:///backup/snapshot/full \
         --log-file /backup/snapshot/full/backupfull.log
Detail BR log in /backup/snapshot/full/backupfull.log 
Full Backup &lt;-------------------------------&gt; 100.00%
Checksum &lt;----------------------------------&gt; 100.00%</code></pre><p>（3）查看产生的快照备份文件。</p><pre><code class="powershell">tree /backup/snapshot/full/

# 输出的信息如下：
/backup/snapshot/full/
├── 5
│   ├── ......
│   ├── 32_235_e4f50bb7685_1739865447022_write.sst
│   ├── 32_235_e5f8771bee7_1739865446968_write.sst
│   ├── 32_235_ea38515343d_1739865446917_write.sst
│   ├── 32_235_ed85b58a2c9_1739865447042_default.sst
│   ├── 32_235_ed85b58a2c9_1739865447042_write.sst
│   ├── 32_235_f0f9b1a4aa3_1739865446926_write.sst
│   ├── 32_235_f4dd8b9e556_1739865446922_write.sst
│   ├── 32_235_f70c98a950f_1739865446864_write.sst
│   ├── 32_235_fd54db249c0_1739865446984_write.sst
│   ├── ......
│   └── 32_235_fe4f4fe208b_1739865446841_write.sst
├── backupfull.log
├── backup.lock
├── backupmeta
├── backupmeta.datafile.000000001
├── backupmeta.json
├── backupmeta.schema.000000002
└── checkpoints
    └── backup</code></pre><p>快照备份会产生如下类型文件：</p><ul><li><strong>SST文件</strong>：存储TiKV备份下来的数据信息。单个SST文件大小等于TiKV Region的大小。SST是Static Sorted Table的缩写。</li><li><strong>Backup meta文件</strong>：存储本次备份的元信息，包括备份文件数、备份文件的Key区间、备份文件大小和备份文件Hash(sha256)值。</li><li><strong>backup.lock文件</strong>：用于防止多次备份到同一目录。</li></ul><p>当备份数据到本地磁盘上时，SST文件以下面的格式命名。其中</p><ul><li><strong>regionID</strong>：Region编号</li><li><strong>regionEpoch</strong>：Region版本号</li><li><strong>keyHash</strong>：Range startKey的Hash(sha256)值，以确保唯一性</li><li><strong>timestamp</strong>：TiKV节点生成SST文件名时刻的Unix时间戳</li><li><strong>cf</strong>：RocksDB的列族信息，取值：default或者write</li></ul><p>完整的SST文件名格式如下：</p><pre><code class="powershell">&lt;regionID&gt;_&lt;regionEpoch&gt;_&lt;keyHash&gt;_&lt;timestamp&gt;_&lt;cf&gt;.sst</code></pre><h2>二、 日志备份与恢复</h2><p>全量备份一般会占用较大的存储空间，且只包含某个时间点的集群数据。如果需要灵活地选择恢复的时间点（即：实现PITR，Point in Time Recovery），可以使用日志备份和日志恢复。有了日志备份后，通过tiup br restore point功能，可以指定要恢复的时间点。BR会自动判断和读取恢复需要的数据，然后将这些数据依次恢复到指定的集群。执行tiup br log命令来开启和管理日志备份任务，下面展示了该命令的帮助信息：</p><pre><code class="powershell"># tiup br log --help

Usage:
  br log [command]

Available Commands:
  metadata    查询备份存储中备份数据的元信息
  pause       暂停日志备份任务
  resume      重启暂停的备份任务
  start       启动一个日志备份任务
  status      查询日志备份任务状态
  stop        停止备份任务
  truncate    从备份存储中清理日志备份数据</code></pre><p>执行tiup br log start命令可以在备份集群启动一个日志备份任务。该任务在TiDB集群持续地运行，及时地将KV变更日志保存到备份存储中。执行tiup br log start --help命令可获取该子命令使用介绍：</p><pre><code class="powershell"># tiup br log start --help

start a log backup task

Usage:
  br log start [flags]

Flags:
  -h, --help               展示帮助信息
      --start-ts string   指定开始备份日志的起始时间点。
如果未指定，则选取当前时间作为start-ts
      --task-name string  指定日志备份任务名。
该名称也用于查询备份状态、暂停、重启
和恢复备份任务等操作

Global Flags:
  -u, --pd strings        指定备份集群的PD访问地址。
  -s, --storage string   指定备份存储地址。
  ......</code></pre><p>下面的步骤将启动一个日志备份任务。<br/>（1）创建一个目录用于保存日志备份产生的文件</p><pre><code class="powershell">mkdir -p /backup/log
chown -R tidb:tidb /backup/log</code></pre><p>（2）启动日志备份任务</p><pre><code class="powershell">tiup br log start \
  --task-name=pitr \
  --pd="192.168.79.10:2379" \
  --storage='local:///backup/log'

# 输出的信息如下：
Starting component br: 
  br log start --task-name=pitr \
               --pd=192.168.79.10:2379 \
               --storage=local:///backup/log
Detail BR log in /tmp/br.log.2025-02-18T18.04.50+0800 
[2025/02/18 18:04:50.647 +08:00] [INFO] ["log start success summary"] </code></pre><p>（3）查看目录/backup/log</p><pre><code class="powershell">tree /backup/log

# 输出的信息如下：
/backup/log
├── backup.lock
└── backupmeta</code></pre><p>（4）查看日志备份任务的状态信息。</p><pre><code class="powershell">tiup br log status --task-name=pitr --pd="192.168.79.10:2379"

# 输出的信息如下：
● Total 1 Tasks.
&gt; #1 &lt;
              name: pitr
            status: ● NORMAL
             start: 2025-02-18 18:04:50.561 +0800
               end: 2090-11-18 22:07:45.624 +0800
           storage: local:///backup/log
       speed(est.): 0.00 ops/s
checkpoint[global]: 2025-02-18 18:07:18.411 +0800; gap=47s

命令输出中的字段含义如下：
● status：任务状态，包括NORMAL（正常）、ERROR（异常）和PAUSE（暂停）三种状态。
● start：日志备份任务开始的时间，该值为备份任务启动时候指定的start-ts。
● storage：备份存储。
● speed：日志备份任务的总QPS（每秒备份的日志个数）。
● checkpoint[global]：集群中早于该checkpoint的数据都已经保存到备份存储，它也是备份数据可恢复的最近时间点。</code></pre><p>（5）再次查看目录/backup/log</p><pre><code class="powershell">tree /backup/log

# 输出的信息如下：
/backup/log
├── backup.lock
├── backupmeta
└── v1
    ├── 20250218
    │   └── 10
    │       └── 1
    │           ├── 456097302173712388-2dd0ae7b-e8c7-4656-a497-e0e02d0e4fe4.log
    │           └── 456097333619195905-7bd1f194-ba97-4824-94e9-45f223382d82.log
    ├── backupmeta
    │   ├── 456097317141872643-0af28b08-6cc4-4123-af8a-f8798e967378.meta
    │   └── 456097332870512641-ce854c81-95ab-444e-91fd-e9e9fb8d2e58.meta
    └── global_checkpoint
        ├── 1.ts
        ├── 4.ts
        └── 5.ts

6 directories, 9 files</code></pre><p>日志备份会产生如下类型文件：</p><ul><li><strong>{min_ts}-{uuid}.log文件</strong>：存储备份下来的kv数据变更记录。其中{min_ts}是该文件中所有kv数据变更记录数对应的最小ts；{uuid}是生成该文件的时候随机生成的。</li><li><strong>{checkpoint_ts}-{uuid}.meta文件</strong>：每个TiKV节点每次上传日志备份数据时会生成一个该文件，保存本次上传的所有日志备份数据文件。其中{checkpoint_ts}是本节点的日志备份的checkpoint，所有TiKV节点的最小的checkpoint就是日志备份任务最新的checkpoint；{uuid}是生成该文件的时候随机生成的。</li><li><strong>{store_id}.ts文件</strong>：每个TiKV节点每次上传日志备份数据时会使用global checkpoint ts更新该文件。其中{store_id}是TiKV的storeID。</li><li><strong>v1_stream_truncate_safepoint.txt文件</strong>：保存最近一次通过br log truncate删除日志备份数据后，存储中最早的日志备份数据对应的ts。</li></ul><h2>三、 数据的逻辑导出和导入</h2><p>在备份与恢复场景中，如果需要全量备份少量数据且不要求备份速度，还可以使用Dumpling从TiDB数据库导出数据进行备份，再使用TiDB Lightning将数据导入至TiDB数据库实现恢复。</p><blockquote>Dumpling和TiDB Lightning属于逻辑备份与逻辑恢复，因此适用于数据量较小的情况，例如小于50G的数据。</blockquote><p>数据导出工具Dumpling可以把存储在TiDB或MySQL中的数据导出为SQL或CSV格式，用于逻辑全量备份。Dumpling也支持将数据导出到Amazon S3中。</p><p>TiDB Lightning是用于从静态文件导入TB级数据到TiDB集群的工具，常用于TiDB集群的初始化数据导入。TiDB Lightning 支持的文件类型有：Dumpling生成的文件、CSV文件和Parquet文件</p><h2>四、 TiDB的闪回</h2><p>TiDB修改数据时并不会将旧版本数据之间删除，而是在新旧数据上打上不同的版本号，从而实现了MVCC基准。当旧版本数据满足了GC垃圾回收的触发条件时，TiDB才会将旧版本数据彻底删除。换句话说，在GC垃圾回收旧版本数据之前，任然可以读取旧版本数据从而达到恢复的目的。这就是闪回的核心机制，它是一种轻量级的恢复技术，不需要备份即可完成。通过查询系统变量tidb_gc_life_time可以获取旧版本数据保留的时间，默认10分钟。</p><pre><code class="sql">tidb&gt; select @@tidb_gc_life_time ;
+---------------------+
| @@tidb_gc_life_time |
+---------------------+
| 10m0s               |
+---------------------+</code></pre><p>下面的查询语句将查询当前的安全点（safePoint），即GC已经清理到的时间点。换句话说，该时间点以后的数据都可以恢复。</p><pre><code class="sql">tidb&gt; select * from mysql.tidb where variable_name = 'tikv_gc_safe_point' \G;
*************************** 1. row ***************************
 VARIABLE_NAME: tikv_gc_safe_point
VARIABLE_VALUE: 20250307-21:50:44.781 +0800
       COMMENT: All versions after safe point can be accessed. (DO NOT EDIT)
1 row in set (0.01 sec)</code></pre><p>TiDB中支持闪回集群、闪回数据库和闪回表三种不同的闪回。</p>]]></description></item><item>    <title><![CDATA[云原生网关 Higress 与服务注册 Nacos 的创新结合：打造零代码扩展 AI 工具的能力 阿]]></title>    <link>https://segmentfault.com/a/1190000047458821</link>    <guid>https://segmentfault.com/a/1190000047458821</guid>    <pubDate>2025-12-08 18:11:52</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>作者：陆胤任</p><h2>背景</h2><p>在 AI 大爆发的时代，已经有非常多的 AI 助手，结合 RAG 通过智能问答帮助用户解答问题。单纯地依靠智能问答帮助客户自助解答是远远不够的，我们需要让 AI 助手能够直接调用已有的丰富接口，朝着更强大的智能体演进。我们选用当下最为火热，且已逐步成为标准的 MCP 作为模型和接口之间通信的传输协议。关于 MCP，已有非常多的介绍文章，本文不再赘述。</p><p>在企业对外服务的场景下，MCP Server 需要解决以下几个问题：</p><ol><li>在服务的多实例高可用场景下，使用 SSE 通信方式如何维护 session；</li><li>如何做到动态更新 MCP 工具 Prompt，做到快速更新&amp;调试&amp;验证；</li><li>租户隔离的云服务场景下如何对用户的工具调用进行鉴权。</li></ol><p>Higress 可以很好地解决上面的问题 1，同时还有完善的运维监控体系，可视化易操作的控制台界面。为了解决问题 2，我们引入了 Nacos 负责注册后端服务以及管理维护 MCP 工具的元数据等信息。在整个 MCP 服务中，Higress 担任 MCP Proxy 的角色，Nacos 担任 MCP Registry 的角色。对于问题 3 租户隔离问题，会在下面鉴权章节中进行详细说明。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047458823" alt="image" title="image"/></p><p>Higress 和 Nacos 都是云原生的应用，在部署方面，自然选择使用 K8s 集群进行云原生部署。同时很多企业有自己的专属生产网络环境，一般和外网不通，因此本文会围绕如何利用社区版本的 Higress 和 Nacos（Apache-2.0 开源协议）进行私有化部署。因为内部环境的限制，我们没有办法直接通过 Helm 操作 K8s 集群进行部署，因此本文会围绕如何基于 Higress 和 Nacos 的 docker 镜像在 K8s 集群上进行分角色部署。</p><p>通过这套自建的网关服务，使用配置即可实现零代码扩展 Tool，新应用的注册、应用下面工具的扩展、工具 prompt 更新验证都能通过服务集成的可视化控制台，更新发布配置快速完成，<strong>接入方式极其简单！更新验证极其快速！</strong> 同时利用 Nacos 的命名空间能力可以做到服务和工具集的隔离，给不同的用户提供不同的 MCP 工具集。</p><h2>私有化部署</h2><h3>Higress</h3><p>Higress 支持三种部署方式：Helm、docker compose 和基于 all-in-one 的 docker 镜像进行部署。Higress 官方推荐使用 Helm 的方式进行生产环境的部署，将依赖的模块部署在不同的 pod 上。而因上述环境原因，这里选择使用第三种基于 all-in-one 的 docker 镜像 Dockerfile <strong>[</strong> <strong>1]</strong> 进行部署，将 Higress 依赖的组件以进程的方式部署在同一 pod 上面，通过多副本的方式实现服务高可用，也实现了对 K8s 集群 Ingress 的无侵入式部署。</p><p>我们先尝试直接引用 docker 镜像进行部署时，会报 WASM 的插件错误，查看报错信息是通过 oci 地址去下载 WASM 插件的时候出现了问题。同时 Higress 实现 MCP 功能也依赖了 WASM 插件，这是一个绕不开的问题。﻿</p><pre><code>FROM higress-registry.cn-hangzhou.cr.aliyuncs.com/higress/all-in-one:latest</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047458824" alt="image" title="image" loading="lazy"/></p><h4>WASM 插件独立部署</h4><p>Higress 的 plugin-server <strong>[</strong> <strong>2]</strong> 项目就是为了“解决私有化部署 Higress 网关时拉取插件的痛点，优化了插件的下载与管理效率”，使 Higress 通过 http 的方式去下载独立部署的插件库，而不是通过 oci 去访问外部公开仓库，避免因网络问题导致插件拉取不下来。解决过程主要分为以下三个步骤：</p><p><strong>1）私有化部署 plugin-server</strong></p><pre><code>FROM higress-registry.cn-hangzhou.cr.aliyuncs.com/higress/plugin-server:1.0.0</code></pre><p><strong>2）为 plugin-server 集群申请 K8s Service（Cluster IP）</strong></p><pre><code>apiVersion: v1
kind: Service
metadata:
  name: higress-plugin-server
  namespace: higress-system
  labels:
    app: higress-plugin-server
    higress: higress-plugin-server
spec:
  type: ClusterIP
  ports:
    - port: 80
      protocol: TCP
      targetPort: 8080
  selector:
    app: higress-plugin-server
    higress: higress-plugin-server</code></pre><p>K8s 集群内置的 DNS 为此创建的域名解析记录的格式为 <code>&lt;service-name&gt;.&lt;namespace&gt;.svc.cluster.local</code>。</p><p>在没有 K8s 的场景下也可以为 plugin-server 集群申请内网 VIP 或者 SLB 做好服务发现和负载均衡。</p><p><strong>3）修改 Higress 内置插件下载地址</strong></p><p>依照 github 中的示例，在基于 Higress 镜像的项目 Dockerfile 中声明插件的下载地址。这里有个地方需要注意下，readme 中给出的示例是环境变量的格式。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047458825" alt="image" title="image" loading="lazy"/></p><p>在 Dockerfile 中声明需要转义一下，&amp;dollar;{name}/&amp;dollar;{version} 的形式才可以被正确解析。</p><pre><code>...
# 模版
ENV HIGRESS_ADMIN_WASM_PLUGIN_CUSTOM_IMAGE_URL_PATTERN=http://[申请的k8s service地址]/plugins/\${name}/\${version}/plugin.wasm
# mcp wasm 插件下载地址
ENV MCP_SERVER_WASM_IMAGE_URL=http://[申请的k8s service地址]/plugins/mcp-server/1.0.0/plugin.wasm
...</code></pre><p>配置完独立的插件 HTTP 下载地址后重新部署，在服务器上可以看到 8080 端口以及 8443 端口可以被正常监听，说明 Higress 具备代理和网关功能的核心数据面组件已经可以正常服务了。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047458826" alt="image" title="image" loading="lazy"/></p><p>解决完 WASM 插件下载问题，基于 docker 镜像的 Higress 服务就可以被成功拉起并运行了。只不过基于这种模式部署的<strong>每个 pod 都是独立、对等、包含全部组件、功能完整的 Higress 服务，需要通过多副本的方式实现高可用。</strong></p><p>这种部署模式下，通过 Higress 自身集成的控制台去运维服务&amp;更改配置是不现实的，只能操作一台实例的配置变更，无法让实例间进行配置同步。因此在这种模式下的缺点是，只能通过在项目代码中维护配置文件，需要更改时走发布流程，将配置发布到每台实例上面。不过在我们这个场景下，需要变更配置的情况不多。</p><h4>粘性会话</h4><p>在 MCP SSE 通信方式下，天然需要解决粘性会话的问题，Higress 基于 Redis 帮我们解决了这个问题。提前部署好 Redis 实例之后，打开 Higress 的 MCP 功能，并将 Redis 配置更新进去，重新部署一下就可以使用 MCP 的功能了。</p><pre><code>...
data:
  higress: |-
    mcpServer:
      enable: true
      sse_path_suffix: /sse
      redis:
        address: xxx.redis.zhangbei.rds.aliyuncs.com:6379
        username: ""
        password: "xxx"
        db: 0
...</code></pre><p>这份配置文件可以维护在自己的基于 Higress 镜像的项目中，在部署的时候将配置文件 COPY 到指定目录（这种部署模式下，所有的配置文件都应该这么做）。</p><pre><code>...
# custom config
COPY config/configmaps/higress-config.yaml /data/configmaps/higress-config.yaml
COPY config/mcpbridges/default.yaml /data/mcpbridges/default.yaml
COPY config/secrets/higress-console.yaml /data/secrets/higress-console.yaml
RUN chmod +x /data/configmaps/higress-config.yaml &amp;&amp; \
    chmod +x /data/secrets/higress-console.yaml &amp;&amp; \
    chmod +x /data/mcpbridges/*
...</code></pre><p>当整个 MCP 网关搭建完并使用的时候，在 redis 上通过 PSUBSCRIBE mcp-server-sse:* 命令可以看到如下的调用信息。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047458827" alt="image" title="image" loading="lazy"/></p><h4>自定义构建镜像</h4><p>官方构建出来的镜像一般会要求体积小，满足最小运行要求，所以很多功能其实并不集成在 Higress 的镜像中。如果你的企业有自己约定的通用镜像，或者是想在原本的基础上集成一些新的功能，如使用阿里云的 SLS、云监控等功能，就需要根据 all-in-one 镜像的 Dockerfile 内容进行自定义构建。这里有个注意的点是，Higress 中的 envoy 模块要求的 glibc 是 2.18 及以上版本。</p><p>其实只需要将 Higress 的 Dockerfile 文件内容移植过来就行，然后<strong>再声明下独立部署的 WASM 插件下载地址</strong>，就能实现基于指定镜像进行 Higress 自定义构建打包部署了。</p><p>Higress 服务搭建好后，就可以走对外公网访问的流程了：（1）一个是绑定 8001 端口，通过 Higress 控制台进行查看相关配置的域名，限制为只允许内网访问。注：这种模式下无法通过控制台直接去更改配置；（2）另一个是绑定 8080 端口，对外提供 MCP 网关服务的域名。</p><p>完整的 Dockerfile 如下：</p><pre><code>FROM [企业内部基础镜像]
# 下面为 Higress all-in-one dockerfile中的内容
ARG HUB=higress-registry.cn-hangzhou.cr.aliyuncs.com/higress
...
# 模版
ENV HIGRESS_ADMIN_WASM_PLUGIN_CUSTOM_IMAGE_URL_PATTERN=http://[申请的k8s service地址]/plugins/\${name}/\${version}/plugin.wasm
# mcp wasm 插件下载地址
ENV MCP_SERVER_WASM_IMAGE_URL=http://[申请的k8s service地址]/plugins/mcp-server/1.0.0/plugin.wasm
...
# 注意 dockerfile 中会去 github 下载对应处理器架构下的 yq 模块，企业内网环境下可以提前下载下来
COPY ./yq_linux_[arch] /usr/local/bin/yq
...
# custom config
COPY config/configmaps/higress-config.yaml /data/configmaps/higress-config.yaml
COPY config/mcpbridges/default.yaml /data/mcpbridges/default.yaml
COPY config/secrets/higress-console.yaml /data/secrets/higress-console.yaml
RUN chmod +x /data/configmaps/higress-config.yaml &amp;&amp; \
    chmod +x /data/secrets/higress-console.yaml &amp;&amp; \
    chmod +x /data/mcpbridges/*
...</code></pre><h3>Nacos</h3><p>Nacos 的部署相对简单，除了通过 kubectl 或者 nacos-operator 工具直接操作 K8s 集群部署外，还可以直接基于 nacos-server 的镜像进行部署 Dockerfile <strong>[</strong> <strong>3]</strong> 。因上文提到的内部环境问题，我们这里选择基于 nacos-server 的镜像，将服务部署于 K8s 集群上面。</p><pre><code>FROM nacos-registry.cn-hangzhou.cr.aliyuncs.com/nacos/nacos-server:latest</code></pre><h4>集群模式部署</h4><p>Nacos 集群模式下使用的一致性协议是基于 Raft 实现的，因此最小需要部署 3 台实例。</p><p>在引用 nacos-server 镜像的 dockerfile 中，声明 cluster 的部署模式。我们查看 nacos 的启动脚本，发现在 peer-finder（插件）目录不存在的情况下，如果定义了 $NACOS_SERVERS 变量，会将 $NACOS_SERVERS 变量中的值写入 $CLUSTER_CONF 文件中，$CLUSTER_CONF 文件的默认路径是 /home/nacos/conf/cluster.conf，其中定义的就是 Nacos 集群的静态成员地址列表，它在集群首次启动时会被读取，用于告知每个节点“邻居”在哪，从而让它们能够互相发现、建立连接，并初始化 Raft 一致性协议。</p><pre><code>...
PLUGINS_DIR="/home/nacos/plugins/peer-finder"
function print_servers() {
   if [[ ! -d "${PLUGINS_DIR}" ]]; then
    echo "" &gt;"$CLUSTER_CONF"
    for server in ${NACOS_SERVERS}; do
      echo "$server" &gt;&gt;"$CLUSTER_CONF"
    done
  else
    bash $PLUGINS_DIR/plugin.sh
    sleep 30
  fi
}
...</code></pre><p>因此我们可以在 Dockerfile 中维护当前集群下的 [实例 IP:端口] 列表，供 Nacos 集群启动时读取并初始化。</p><pre><code>...
ENV MODE=cluster
ENV NACOS_AUTH_TOKEN=xxx
ENV NACOS_AUTH_IDENTITY_KEY=xxx
ENV NACOS_AUTH_IDENTITY_VALUE=xxx
ENV NACOS_SERVERS="10.0.0.1:8848 10.0.0.2:8848 10.0.0.3:8848"
# nacos 用户名密码
ENV NACOS_USERNAME=xxx
ENV NACOS_PASSWORD=xxx
...</code></pre><h4>实例间动态发现</h4><p>上面这种固定 IP 列表的方式<strong>缺点是显而易见的</strong>。它是一个静态的配置，当出现集群的扩缩容时，实例是没有办法自动去更新成员 IP 列表的，需要手动修改并发布，整个过程非常繁琐，严重情况下可能会影响线上服务的稳定性；且在云原生容器化背景下，IP 并不是固定的，随时有可能会因为故障迁移而改变 IP，维护静态 IP 列表与云原生的理念背道而驰。线上生产是完全不推荐这种方式的。</p><p>再回到上面 docker-startup.sh 脚本，可以通过 peer-finder 插件来实现集群间实例的发现，取代手动维护 cluster.conf 文件。peer-finder 插件运行依赖于 K8s 集群 Headless Service 域名，会去执行类似于 nslookup 命令查找 Service 下面的所有健康 Pod 的 IP 列表，类比于服务发现的能力 <strong>[</strong> <strong>4]</strong> ，这样就不用再手动去维护实例 IP 列表。</p><p>但是 peer-finder 的运行依赖于 StatefulSet 的实例部署模式，需要每个实例有固定的实例名。因为我们内部环境的限制，我们现在部署的都是无状态的实例，所以没有办法通过 peer-finder 来做这个事情。但是我们可以参照 peer-finder 脚本的实现思路，来自己写一个启动脚本。</p><p><strong>1）首先为 Nacos 集群申请 Headless 的 Service。</strong></p><pre><code>apiVersion: v1
kind: Service
metadata:
  name: nacos-headless
  namespace: mcp-nacos
  labels:
    app: mcp-nacos
    nacos: mcp-nacos
spec:
  clusterIP: None
  ports:
  - name: peer-finder-port
    port: 8848
    protocol: TCP
    targetPort: 8848
  selector:
    app: mcp-nacos
  sessionAffinity: None
  type: ClusterIP</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047458828" alt="image" title="image" loading="lazy"/></p><p><strong>2）这里修改下 nacos-docker 的启动脚本，提供一个简单的实现。（仅供参考）</strong></p><pre><code>...
原docker-startup.sh内容
...
# 新增内容
# 注释掉 JAVA启动命令
# exec $JAVA ${JAVA_OPT}
export JAVA_OPT # export JAVA 启动参数，方面下面读取
HEADLESS_SERVICE_FQDN="xxx.svc.cluster.local"
CLUSTER_CONF_FILE="/home/nacos/conf/cluster.conf"
UPDATE_SCRIPT="/home/nacos/bin/update-cluster.sh" # 原子更新脚本
NACOS_START_CMD="$JAVA $JAVA_OPT"
# 1. 动态创建 update-cluster.sh 脚本
cat &gt; ${UPDATE_SCRIPT} &lt;&lt; 'EOF'
#!/bin/bash
set -e
NACOS_PORT=${NACOS_APPLICATION_PORT:-8848}
CLUSTER_CONF_FILE="/home/nacos/conf/cluster.conf"
TMP_CONF_FILE="/home/nacos/conf/cluster.conf.tmp"
&gt; "${TMP_CONF_FILE}"
# 从标准输入读取 nslookup 的原始输出
awk '
/^Name:/ { flag=1; next }
flag &amp;&amp; /^Address:/ { print $2; flag=0 }
' | while IFS= read -r ip; do
    if [ -n "$ip" ]; then
      echo "${ip}:${NACOS_PORT}" &gt;&gt; "${TMP_CONF_FILE}"
    fi
done
# 排序以确保文件内容的一致性，避免不必要的更新
sort -o "${TMP_CONF_FILE}" "${TMP_CONF_FILE}"
# 只有在新旧配置不同时才执行更新
# 检查旧文件是否存在
if [ ! -f "${CLUSTER_CONF_FILE}" ] || ! cmp -s "${TMP_CONF_FILE}" "${CLUSTER_CONF_FILE}"; then
    echo "[$(date)][update-script] Peer list changed. Updating config."
    mv "${TMP_CONF_FILE}" "${CLUSTER_CONF_FILE}"
    echo "[$(date)][update-script] cluster.conf updated:"
    cat "${CLUSTER_CONF_FILE}"
else
    rm "${TMP_CONF_FILE}"
fi
EOF
chmod +x ${UPDATE_SCRIPT}
# 2. 启动前的初始化循环
MAX_INIT_RETRIES=30
RETRY_COUNT=0
MIN_PEERS=3 # 期望的集群最小副本数量
echo "[INFO] Initializing cluster config. Waiting for at least ${MIN_PEERS} peers to be available..."
while true; do
  # 直接将 nslookup 的输出通过管道传给更新脚本
  nslookup "${HEADLESS_SERVICE_FQDN}" | ${UPDATE_SCRIPT}
  # 检查生成的配置文件行数
  LINE_COUNT=$(wc -l &lt; "${CLUSTER_CONF_FILE}")
  if [ "${LINE_COUNT}" -ge "${MIN_PEERS}" ]; then
    echo "[INFO] Initial cluster.conf is ready with ${LINE_COUNT} peers."
    break
  fi
  RETRY_COUNT=$((RETRY_COUNT+1))
  if [ "${RETRY_COUNT}" -gt "${MAX_INIT_RETRIES}" ]; then
    echo "[WARN] Could not find ${MIN_PEERS} peers after ${MAX_INIT_RETRIES} retries. Starting with ${LINE_COUNT} peers found."
    break
  fi
  echo "[INFO] Found ${LINE_COUNT} peers. Waiting for more... Retrying in 5 seconds."
  sleep 5
done
# 3. 在后台启动我们自己的监控循环
(
  while true; do
    sleep 15 # 每 15 秒检查一次
    echo "[$(date)][monitor] Checking for peer updates..."
    nslookup "${HEADLESS_SERVICE_FQDN}" | ${UPDATE_SCRIPT}
  done
) &amp;
# 4. 启动 Nacos 主进程
echo "[INFO] Starting Nacos server..."
exec sh -c "${NACOS_START_CMD}"</code></pre><p>这样我们 cluster.conf 文件中的成员 IP 列表就实现了自动更新。</p><p>线上生产环境还是推荐使用有状态 StatefulSet 的部署模式，并结合 peer-finder 的能力实现实例间的互相发现。而不是用无状态的实例，自己去写脚本实现。后续我们也会升级到 StatefulSet 的模式进行部署。</p><h4>配置外置 Mysql</h4><p>在集群部署模式下，就无法使用 Nacos 内置的不支持数据共享的 Derby 数据库，需要配置外置的 Mysql 数据库。提前部署好 Mysql 实例之后，按照 Nacos 中的 mysql-schema.sql <strong>[</strong> <strong>5]</strong> 数据库配置文件将表初始化，再将 mysql 配置信息写入 Dockerfile 中即可。</p><pre><code>...
# mysql config
ENV SPRING_DATASOURCE_PLATFORM=mysql
ENV MYSQL_DATABASE_NUM=1
ENV MYSQL_SERVICE_HOST=xxx.mysql.zhangbei.rds.aliyuncs.com
ENV MYSQL_SERVICE_PORT=3306
ENV MYSQL_SERVICE_DB_NAME=nacos
ENV MYSQL_SERVICE_USER=xxx
ENV MYSQL_SERVICE_PASSWORD=xxx
...</code></pre><p>在为 Nacos 做服务暴露的时候，只需要暴露 Nacos 控制台的 8080 端口，且限制为只允许内网访问即可。因为 Nacos 只是内部作为维护管理 MCP 工具元数据信息的 MCP Registry 使用，对用户侧不感知；且 Higress 和 Nacos 都部署在内网的 K8s 集群上面，内部通信通过 K8s 的 Service 即可，无需将 Nacos 的 8848 端口暴露给公网。</p><h4>申请 K8s Service 供 Higress 使用</h4><p>注意 Higress 拉取/订阅 Nacos 中的配置会通过 gRPC 的方式调用，这里的 Service 需要<strong>暴露 8848 和 9848 两个端口</strong>给 Higress 使用。</p><pre><code>apiVersion: v1
kind: Service
metadata:
  name: pre-oss-mcp-nacos-endpoint
  namespace: aso-oss-mcp-nacos
  labels:
    app: mcp-nacos
    nacos: mcp-nacos
spec:
  type: ClusterIP
  ports:
  - name: subscribe-port
    port: 8848
    protocol: TCP
    targetPort: 8848
  - name: grpc-port
    port: 9848
    protocol: TCP
    targetPort: 9848
  selector:
    app: nacos</code></pre><p>同理，如果想使用企业内部的镜像，或者是想在原本的基础上即成一些新的功能，如使用阿里云的 SLS、云监控等功能，也可根据 Nacos 的 Dockerfile 进行自定义构建部署。</p><h2>鉴权</h2><p>Higress 自身提供了丰富的鉴权 <strong>[6</strong> <strong>]</strong> 能力，如果你的企业本身就基于 Higress 搭建了自己的网关并使用了 Higress 提供的鉴权能力，这种场景下直接复用原来的方案即可。</p><p>另一种场景下，企业中会有多个服务 Provider，每个 Provider 有不同的鉴权方式。如下图所示，某个服务提供者会通过拦截器对请求中携带的用户 Cookie 进行 RAM 鉴权；另一个服务提供者会通过 tengine lua 脚本对请求进行自定义鉴权；以及后续注册的服务可能有其他的鉴权方式。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047458829" alt="image" title="image" loading="lazy"/></p><p>一方面，我们并不希望使用 Higress 的鉴权能力去覆盖全部的鉴权场景，开发维护成本过高，我们优先考虑直接复用服务提供者已有的鉴权能力；另一方面，如果通过网关层鉴权需要将 AK 或者认证信息存放在 Higress 服务上，在安全层面也不是一个合适的做法。</p><p>这里推荐的做法是直接在 MCP 工具调用的时候，将鉴权信息透传给服务提供者，让服务提供者完成鉴权。</p><h2>MCP 验证</h2><p>根据文档 <strong>[</strong> <strong>7]</strong> 中的操作示例，我们可以简单做个全链路测试验证。主要分为以下三步：</p><p><strong>1）在 Nacos 中注册服务，并配置 MCP 工具的元数据信息：</strong></p><p>在 public 命名空间下，创建服务信息。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047458830" alt="image" title="image" loading="lazy"/></p><p>在机器上将自己的服务作为永久实例注册进去。（这里为了快速验证黑屏登陆机器操作，线上生产环境还是须要白屏操作）</p><pre><code>curl -X POST 'http://127.0.0.1:8848/nacos/v1/ns/instance?namespaceId=[namespace]&amp;serviceName=[service_name]&amp;groupName=[group_name]&amp;ip=[服务域名]&amp;port=[服务端口]&amp;ephemeral=false'</code></pre><p>注册完之后，就能在 Nacos 控制台上看到注册的服务配置以及健康状态。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047458831" alt="image" title="image" loading="lazy"/></p><p>接着在 Nacos 控制台上配置 MCP 工具，添加一个简单工具，可以选择一个无参数 GET 接口，并发布。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047458832" alt="image" title="image" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047458833" alt="image" title="image" loading="lazy"/></p><pre><code>{
  "requestTemplate": {
    "url": "/xxx/list.json",
    "method": "GET",
    "headers": [],
    "argsToUrlParam": true
  },
  "responseTemplate": {
    "body": "{{.}}"
  }
}</code></pre><p><strong>2）在 Higress 中配置 MCP Nacos 的服务来源：</strong></p><p>这里为了快速测试关闭了 Nacos 的认证，线上环境建议开启 Nacos 的认证。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047458834" alt="image" title="image" loading="lazy"/></p><p><strong>3）在 Cursor/Cherry Studio 中配置对外暴露的 Higress 服务地址和 uri，即可使用 MCP 工具：</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047458835" alt="image" title="image" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047458836" alt="image" title="image" loading="lazy"/></p><h2>设计图</h2><h3>容灾架构</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047458837" alt="image" title="image" loading="lazy"/></p><p>进入浏览器查看原图：<a href="https://link.segmentfault.com/?enc=QYUCpxZ7e5iJtijYt%2FENJA%3D%3D.34IySCM%2FcpXT5nN94p%2BUoVQH8a%2FiOAd9DjOkGdxPn59ChC%2FVbIX888AkrMQ2ABs2PSqLFOKgxxKSfXRGzMuwQA%3D%3D" rel="nofollow" target="_blank">https://img.alicdn.com/imgextra/i2/O1CN0138v82b1L7vNY3RQdo_</a>!!6000000001253-2-tps-6507-5451.png</p><p>在整个 MCP 网关中，通过 uri 来路由不同的 MCP 工具，实现工具的隔离。</p><h3>逻辑模块图</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047458838" alt="image" title="image" loading="lazy"/></p><h3>时序图</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047458839" alt="image" title="image" loading="lazy"/></p><p><strong>附录：</strong></p><p>[1] 基于 all-in-one 的 docker 镜像</p><p><a href="https://link.segmentfault.com/?enc=sQEArVEaBrB3FQ9NDNfsrQ%3D%3D.aOvNrKVs%2FMFp5Oz7ISx6ttTUbgu25Zf7%2Fsu3hvPNNoRKwzehWUEcXm68ONfLS6JVavJuSlRZmuo2iChfEjb80VlDK3Ii2XIuWngFzNjyL3BO9CZsnZMUqWh4vCtY%2Frsx" rel="nofollow" target="_blank">https://github.com/higress-group/higress-standalone/blob/main/all-in-one/Dockerfile</a></p><p>[2] higress-plugin-server</p><p><a href="https://link.segmentfault.com/?enc=mCfrMpmgSWUgScjyfoNkgQ%3D%3D.Fn6B6ffA9QQxtDpvidSAKJ8YIhgCiUJSPayz%2BifELFImcOrhsVSXGyA2rLGqati9" rel="nofollow" target="_blank">https://www.cnkirito.moe/higress-plugin-server/</a></p><p>[3] 基于 nacos-server 的镜像进行部署</p><p><a href="https://link.segmentfault.com/?enc=vWkVUK6F6lROoNLSJZC%2Fug%3D%3D.zwPxGvtJv2lG8hBbjOQkfdWoretRREQTGobJyS6%2FD0jKOPEl1KxYj9MDkcRVPtGXJfPFHhNvx8vUQEjfWDEVn%2F80oHE%2BR%2FY8LUPdkqEq4Lg%3D" rel="nofollow" target="_blank">https://github.com/nacos-group/nacos-docker/blob/master/build/Dockerfile</a></p><p>[4] 脚本源码</p><p><a href="https://link.segmentfault.com/?enc=XRSdxaLI7nEi6HF0yrQTYA%3D%3D.u9SEDlwD4LujnoA%2FSDoLjkqq8bd6dc1YyUr8%2FVsKhd8jDNMAlyY6hUfTrUjR3AIrAiVoEN93wzGoXQ%2BXnvvCAuQNF%2BjY5E51APj0QKSJW9c%3D" rel="nofollow" target="_blank">https://github.com/kmodules/peer-finder/blob/master/peer-finder.go</a></p><p>[5] mysql-schema.sql</p><p><a href="https://link.segmentfault.com/?enc=doqbpbZz6TQ3W5HxWr%2FOKQ%3D%3D.g%2F6l28Kde2tq5mmijpH4NT5U2Kx1PRE%2BWKaqUafp%2FWdu1hhWybhrbPDNKuKjkFp10S2R7XcrlkVj8vqDuUS0OVPN4S9dCUp302bGop%2B4ROSyKsylDlWeFfcT9Q%2Bsiugn" rel="nofollow" target="_blank">https://github.com/alibaba/nacos/blob/develop/distribution/conf/mysql-schema.sql</a></p><p>[6] Higress 提供丰富鉴权能力</p><p><a href="https://link.segmentfault.com/?enc=9yFhiOV2U%2Bn7LKEpkhIB5g%3D%3D.Nj2UN7LCCTDunRwj4C5KilzKw3UzxnLkTEQBgsgdeSKxzmmDf3VIjublvxEbHGco5SxHk2b95rxH13F2A26IYHE7DNu7r3vLNJldMVSdsWA%3D" rel="nofollow" target="_blank">https://higress.cn/docs/latest/plugins/authentication/basic-a...</a></p><p>[7] <a href="https://link.segmentfault.com/?enc=Ki3ht48aN4Aygr%2Fk%2Fr5UYA%3D%3D.m0aeDx9ly4D4RlNMJeIAdax0T240q%2F987Bc%2F80wB61njAx2It0NHvid0tDzQ86zx0C%2BEI0jYy3KT16vtAHCU4vaL6784RnLDZ2k3BonS%2FwbAWYz4FeKuwSwx5najiRCMZC32rlNsK39F62suxFBVi96ramPd43ZoHBF%2BDbJfHajm5kPc95tjWNtP5BqRcMPU" rel="nofollow" target="_blank">基于 Nacos + Higress  的 MCP 开发新范式，手把手教程来了！</a></p><p>[8] <a href="https://link.segmentfault.com/?enc=vJPkjZPODxywqGeTIW7cTQ%3D%3D.gINgQuTxaE%2FuiCLvH2fCq0bl6R3HkeK9PRkvirVyArzfHaJY1CJp8kMUonXtfwIGU071aMoyrjxP5RNfp0x%2BTnTBdcHJjpfJDEHxwzKH17hDmFQ%2FANtXpKBKHeEl5Z4aBpeqjvufs1qNCfkS3FiUrS7OWibhYBXD7gYxkFvzMYI2exiaHkIYq4DsrPZPPeSb" rel="nofollow" target="_blank">Nacos 3.0 正式发布：MCP Registry、安全零信任、链接更多生态</a></p><p>[9] 修改内置插件的镜像地址</p><p><a href="https://link.segmentfault.com/?enc=AnbffnZyTXMn86tFYinS%2BA%3D%3D.EZX%2BkBpSfuHRIi2pbCKH7X%2F7cwndK9jfCbB9cJR%2FcKrvwZECA%2BQn5TC1yySei3E7pWITmabyEwLAHkQlz09slw%3D%3D" rel="nofollow" target="_blank">https://higress.cn/docs/latest/ops/how-tos/builtin-plugin-url/</a></p><p>[10] Nacos 集群模式</p><p><a href="https://link.segmentfault.com/?enc=BqqmezPiLioYJAs7HANN8A%3D%3D.PTrzpAdsWO5f7MhrCPx6w7NCTwrmBuLlqT2nd0aBuYbb%2FkXY%2FTCaqNlmbwo7J3aon%2FA%2BaiQct5pDQdINzawuKdtB5CyiXOaWTULYyGhCyKQ%3D" rel="nofollow" target="_blank">https://nacos.io/docs/latest/manual/admin/deployment/deployme...</a></p>]]></description></item><item>    <title><![CDATA[线下活动速递丨AI 原生应用开源开发者沙龙·杭州站 阿里云云原生 ]]></title>    <link>https://segmentfault.com/a/1190000047458895</link>    <guid>https://segmentfault.com/a/1190000047458895</guid>    <pubDate>2025-12-08 18:11:12</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <ul><li><strong>时间：12 月 12 日（周五）13：30</strong></li><li><strong>地点：杭州阿里巴巴云谷园区 2 号楼访客中心 225 景逸书院</strong></li></ul><p>了解 AI 原生应用开发的前沿趋势和核心产品技术，全面 get 典型应用场景及硬核实战经验。</p><p>现场完成实操，颁发专属证书！</p><p>免费报名链接：<a href="https://link.segmentfault.com/?enc=YyM%2FlL%2FZjMYLw1U3xqV%2B5Q%3D%3D.DoaJrgMlPfBq%2Fj94d1NEabFYzmkeIvkBi3wbGleej8sAAMiMBBE6INFBT42iywRYwItXMEwbWlcQmBF1wufZ4w%3D%3D" rel="nofollow" target="_blank">https://www.aliyun.com/activity/middleware/2025-ai-hangzhou</a></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047458897" alt="image" title="image"/></p>]]></description></item><item>    <title><![CDATA[“答开发者问”之HarmonyOS技术问题解析 第18期 鸿蒙百晓生 ]]></title>    <link>https://segmentfault.com/a/1190000047458900</link>    <guid>https://segmentfault.com/a/1190000047458900</guid>    <pubDate>2025-12-08 18:10:16</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <blockquote>本文原创发布在<a href="https://link.segmentfault.com/?enc=e3gIT8O4tLZ99%2B8d1DIgXA%3D%3D.ImjpEQClcTmc6b%2Fa%2BMkIZRhLi%2BkbWq3tFfPwbZr34N74ljgFwUuPNg8M5QEf5%2BssHWArzRj7X3lLF%2BecpJ%2B7p622aPnBWpEdUFqhGafxOr8Eed1atXOuNAHwEDGZ9x12" rel="nofollow" target="_blank">华为开发者联盟社区</a>，欢迎前往与更多开发者进行互动。<br/>更多相关问题可点击原帖进行交流：<a href="https://link.segmentfault.com/?enc=XCJvLIBu7asmaM%2F%2BNMRPmw%3D%3D.F8lv46PidgKxNl2MWqXkSfe3hdJLpnHDaMuDTVsnasJlMOxNBF%2FE6UzVVECixUXMEWBz4DOISlDAkhpxMTb61eQRgFVsA0AIGn45BFwCX6sfuHd3YOWEcm0cqJ304wgQO29qB1ihWBoMxSTs2Yu1W%2FRJBVYtpv4NTkJygy1IwrKaWL1Cj2vc8nJFASzKPhwn" rel="nofollow" target="_blank">“答开发者问”之HarmonyOS技术问题解析 第18期</a> 。</blockquote><p><strong>本期问题如下：</strong></p><p>1、<a href="https://link.segmentfault.com/?enc=j1Z1UNZzsri1ngP%2FYNZazw%3D%3D.lD%2FraKgxtCrDdLc%2ByVdUxFZr81DksGARGU8OSlPV2g3%2Bz1ykpFPABLEn6948qdIg73bh8vz9sqosHH4oEtDOPP1tw6CKmVPZI%2FDGS06NVecRKfX5TCNJZCpq%2BLHzz16%2BB9IcHugkrcgh4wEAyRONlFbiLtAt6XViMrOTfTUF%2F6mNeNwyzr624VxKx0nVw1Mi" rel="nofollow" target="_blank">如何比较方便的获取设备的UDID？</a></p><p>2、<a href="https://link.segmentfault.com/?enc=h17muGiEwuw1FrtUWoyEwg%3D%3D.HG9JYeQqt7UHXNrE7p8%2FHy6t9x4iY4mPrCTGmpovQKHkaQUt3NtCf9j%2FtUrLobCR3ka%2Bd8T0FGYhVfiSat2MOHWDsKtUqQ05Viv%2F%2FFQV0CKQp5xXAh4Dvjh2HHt3Kaq1XHhyRe%2BwbxMlbd12rD6%2BD0vaIOSf33mN5UJHhFBW57oxLa1jRVkb6NNt%2BSVBGCWL" rel="nofollow" target="_blank">无内购无广告且不联网的游戏上架时是否需要版号？</a></p><p>3、<a href="https://link.segmentfault.com/?enc=a7ljcmcPN%2F8ipIS6klBgoA%3D%3D.UGOM1xbIQevF1EpeGPhI%2B7L5H3G0BAxCZbzF%2BYP2Z65dU9etRh9R4pNA8X58nsouRfZLGAo13gKLJV%2BbobAQbgwhYy6196oaYfnsRcLLIpuqNAyJWyQr6SZf1A1IGb696yT1WmxnWvE0aBg9FcnwR8y4SKS%2FWIkdSe5eNiCN8feZdmuL1nIevX3%2FiFeF%2FUUx" rel="nofollow" target="_blank">怎么实现类似于练字的功能？</a></p><p>4、<a href="https://link.segmentfault.com/?enc=VqfqwUptm3wynqy8YdQB%2Fg%3D%3D.U7Jygs4Wn9jDmXUSc%2FdqBTP1T1Rj0qdLNC9HEH%2Bj3UBuhbnfOR%2F8azZGOYRN3tW%2BsoAhOCRwvdg9ZSAs8UxeVodsYM5SeEE2a8Tg5h6%2F1js3TgEfwgzQIks3tNEtjLkJuzHmWVBIKS36LzFZoHbMkgRPyYfU4JMeEj4dsrpRPHAMdS9jI8O7B%2FVOry2XZSm4" rel="nofollow" target="_blank">Arkweb如何正确加载web的当前title？</a></p><p>5、<a href="https://link.segmentfault.com/?enc=4L6J%2Bkk2ge5wpDOv1g815g%3D%3D.uU%2B8533DXOigjcVcs3Iya%2FxcxRT7Ag%2FwfPdAzS7%2BelZFVkbba36X2LXw0om8vwDpy0KPdpaJRAhEAAfR3H%2FkbwhoDpeAsaVhnzU5BJh58uSRqsgKY22HjgsNY7m4%2FN4g85othyelm69iL%2BaCi3zJGw%3D%3D" rel="nofollow" target="_blank">HarmonyOS NEXT应用测试都有哪些工具可以使用，它们的使用场景有哪些区别？</a></p><p><strong>问题一：如何比较方便的获取设备的UDID？</strong></p><p>使用命令符时出现：'hdc' 不是内部或外部命令，也不是可运行的程序或批处理文件。请问如何通过hdc命令获取设备的UDID？</p><p><strong>解决方案：</strong></p><p>可以使用<code>hdc shell bm get --udid</code>获取设备UDID。</p><p>关于<code>'hdc' 不是内部或外部命令，也不是可运行的程序或批处理文件</code>这个问题，需要将DevEcoStudio的安装目录DevEcoStudio\sdk\default\openharmony\toolchains配置到系统环境变量path里，详情可参考<a href="https://link.segmentfault.com/?enc=jLSXsjjgFu2%2BM2hd9Pi1Uw%3D%3D.Ny8W7Ot2po94PbTHP57nI0R5p%2FwZ4yfEvpc7l2x1B%2BJjGXJQNDJmeoPSnEHMXI2mHhy5vg6d2CIJGezt4zX9ucuinKdJty4DMrtUiRMTCCVzSBtdDPIlPo3gsWZ%2FE%2BSn9MixjOMG0vSnGluIg7qYq6%2B%2FRnZOxKM%2BuZC610spE4xaCAMYbtt49udwWfubnfDN" rel="nofollow" target="_blank">HDC配置</a>。</p><p><strong>原链接：</strong></p><p><a href="https://link.segmentfault.com/?enc=m3w6PMdjSc5zwAC9PjoeLA%3D%3D.rjB3ytt9vt3Gk4nKwbAzJB5vb4WsQ0C7VioxWllqey1QlaDBHLAI2myApiwPbQCBVHUVwec5hC%2Fhd%2FEG%2FAHLOJsiis2skefyfTZQs35YwTbTfTaXqLhxi3mSipwoGmhngnaVbz88PAT18YO7NZtGIyuXfax3%2Fb4De3QTu4o77GkO0gtRjohEOKtL%2FAoz6QJb" rel="nofollow" target="_blank">如何比较方便的获取设备的UDID啊？-华为开发者问答 | 华为开发者联盟 (huawei.com)</a></p><p><strong>问题二：无内购无广告且不联网的游戏上架时是否需要版号？</strong></p><p>我是个人开发者，写了个小游戏，无内购，无广告，也不联网，上架时是否需要版号？</p><p><strong>解决方案：</strong><br/>根据华为应用市场的审核要求，单机游戏需要版号。</p><p>以下是具体说明：<a href="https://link.segmentfault.com/?enc=qY8CD6wHAspQHoj9lx79Vg%3D%3D.hm5BLPwgVzDQTfyl1xoMzpo6pLrVww0cYYIUVd7dqjzaFBRdPKAeLrGJeJcANmxB5u6Mlhicd9qcYelTKanqpjfyXrZ5%2FGwuI0aMJWbEApR%2FbJpm7EBIBlcfXdduSbxKrlb9p1VES9tY9kwBmxLTUQ%3D%3D" rel="nofollow" target="_blank">游戏版权与版号规定</a>：</p><ul><li>华为应用市场明确要求，无论单机还是网络游戏，均需提供 《网络游戏出版物号（ISBN）》或《版号批文》 等合法资质文件。该规定适用于所有在中国大陆地区发布的游戏应用。</li><li>资质审核流程：<br/>游戏上架前必须通过 资质审核，且版号是核心审核项之一。若未提交有效版号，应用将无法通过审核。</li><li><p>常见误区澄清：</p><ol><li>单机游戏是否例外？<br/>否。华为应用市场未对单机游戏豁免版号要求，所有游戏类应用均需遵守国家新闻出版署的版号管理规定。</li><li>未调用联网功能是否影响？<br/>不影响。即使游戏为纯单机模式，仍需提供版号。</li></ol></li></ul><p><strong>原链接：</strong></p><p><a href="https://link.segmentfault.com/?enc=5z8GTqP5VDa%2FmmH3si1y9w%3D%3D.AWfrFxtfaqBZrkBMNY22QNVaBjsUM2REHLB2cnZMLNqXhSt0%2BBVqwogVlojyk%2BEilZyOjsVGYinpjG6aiv4eziobnz717LtjpMoI4t1VaPLGHSPWyY5FIFCXEEZ%2FcLJtaGsXnTKz1hgZikROm0vS6uUWfCF3AI3sT%2FEMuN%2F%2BXXqgbZAIUYa9t1ulOM11vwYh" rel="nofollow" target="_blank">无内购，没有接入广告，不联网的小游戏上架时是否需要版号？-华为开发者问答 | 华为开发者联盟 (huawei.com)</a></p><p><strong>问题三：怎么实现类似于练字的功能？</strong></p><p>想要实现类似于练字的功能，有没有什么好的方法推荐？</p><p><strong>解决方案：</strong><br/>可参考<a href="https://link.segmentfault.com/?enc=%2FA%2F0hI5sZMkt2hofp2d3Aw%3D%3D.xwL1VFcTYtkDbtXz8mpPK85EdTjRbK9540urE%2FOfLOutACHMZKvcdK9Mx%2Bb3qngYSYJbw1QxnGvrDk%2B1zdBmVnd7n5WJypou%2Bv0kehSaaj%2BhVKPfFILDrYCUpyIHB5f%2BVnPQhoWGv1BiH7%2FuLjpA%2F2jVM2UF4pRJN8FADpRH2MDykkUZjqLabYYZuPzRAu1d" rel="nofollow" target="_blank">儿童练字板</a>示例，通过<a href="https://link.segmentfault.com/?enc=UxSboxHo9HIsq58LNoToBg%3D%3D.pmNZpkNGIiLh98N%2BVtsIAP70nD7eFB4nWaVJPF0j3ywCLGPK0J%2BlIw9tkv6wbipe8Dg%2Bxv2fFlsF3NGVrIW03YHyv6AFC97h7wBuar2ZmT9LTucqujrqOiT3iWieMIEmgFiWpo%2BoZczkzuMEA9jcCgZIm4UICiPQILXHLB2Wc5%2BC1RqIlGdbSAISBVO%2BKcLe" rel="nofollow" target="_blank">Canvas</a>展示了儿童练字板场景，为儿童提供了在移动设备上练习书法的机会。</p><ol><li>通过ontouch事件，监听用户手指按下、滑动、抬起，获取触点坐标。</li><li>利用<a href="https://link.segmentfault.com/?enc=VtpNDsDxQLzBlfzcpUSaCw%3D%3D.CwjeCn8ZjKr7DFlxzQRrM%2FJbUV50VFwO1D%2BAwIEn%2BT0PtjHswC8oomqFSc91xYNCeBvLbqLSJh5QLhHkTpBJxxOBzcWXlzhe2cp520AFN6T8y91SBJtuu%2Bz0lhKetPVitOXRo6zRWdoaJhjWiktTEO4wcjOgkYFhioNZxxjIkMM87jJ061sRjgTfGyGgMuwT" rel="nofollow" target="_blank">CanvasRenderingContext2D</a>进行绘制。</li><li>利用clearRect方法删除画布指定区域的内容。</li></ol><pre><code class="TypeScript">// 构造练字板的米字格
drawLine(ctx: CanvasRenderingContext2D, r: number);
// 手绘板的获取
Canvas(this.context){}
.ontouch();
// 删除画布指定区域的内容
context.clearRect(0, 0, this.canvasWidth, this.canvasHeight);</code></pre><p><strong>原链接：</strong></p><p><a href="https://link.segmentfault.com/?enc=fjq5%2FG3dujHCBEW3dwlOXQ%3D%3D.DlQZLClrEBzufDVkGnNKoUclNf5Q3jr3gYUU6A3DVD3eojVXpNA5nhn414%2FVV%2BtinVXvM8Vm47JdWo5Ae1MGYZD8XEUlpSUy05Gb%2BSJdJJunuWbaOp7a%2F6qykzVVDYBg9Cp6Y6fzNaP5XODnG9cPd%2FY7k3I8WoWnoiI00Bm44k5koCDopCzrobRxiWXqfeMI" rel="nofollow" target="_blank">怎么实现类似于练字的功能？-华为开发者问答 | 华为开发者联盟 (huawei.com)</a></p><p><strong>问题四：Arkweb如何正确加载web的当前title？</strong></p><p>使用arkweb的onTitleReceive获取web的title有时候并不是和document.title是一致的，而且onTitleReceive经常会返回url字符串，请问这种问题应该如何应对？</p><p><strong>解决方案：</strong></p><ul><li>方案一：在<a href="https://link.segmentfault.com/?enc=opNboOVhAiDuv1eJCP3JhQ%3D%3D.vW%2FtStY04aIfJDMra3FFqIMzpGRwnYcO5gOaxSHksDDR9GSvDZ2SeB2ckOsl%2F4JVL1%2FADHFMUYRtgvu%2FPEjlMt7pWve1bqKb6HyBN%2F8kWFUMEa9%2BbAfplyirIayG7dGVPZ3fVMq94Q2OYkmVqIT3qkJrofnBJ5gKCBfRSYSk2K%2BukTxrLB3Tz0NFvkQYthPvDR0SulKp1ttR39IEtf%2Fwqw%3D%3D" rel="nofollow" target="_blank">onTitleReceive</a>中通过webController.getTitle()获取网页的标题。</li><li><p>方案二：通过<a href="https://link.segmentfault.com/?enc=1kub7htypTHCzEj98UUBVw%3D%3D.KvOCuR56W10%2FR6%2BGZI6nalZBu%2F34vJvO88zzCmM%2Fzclm0bWpiwevUIc4tYS1%2FHIGs%2BzhsHFRHTjo12a%2F1xXTZ53UFSbr%2FuSb%2F9Nb7PFbZoQq2zNsK8e8W3xwD1qWihBRT%2BTqiHIRlg1oSVZVJYEV0JHpBb%2B%2FF70rxAeCauyIPWrKw5RZGUUdUCImMrbTnOohc%2FVVrwUwQN6JLX2vQnrkGg%3D%3D" rel="nofollow" target="_blank">runJavaScript</a>执行JavaScript代码来获取文档的标题。</p><ul><li>如果getTitle返回的是网页url，那是因为当前网页未设置title。正常来说通过webController.getTitle()获取到的网页标题和document.title是一致，如果遇到不一致的情况，可以自由选择方式一或者二。</li><li>具体参考如下demo:</li></ul></li></ul><pre><code>  import { webview } from '@kit.ArkWeb';
   import { BusinessError } from '@kit.BasicServicesKit';

   @Entry
   @Component
   struct Question2 {
     context: Context = this.getUIContext()?.getHostContext() as Context;
     webviewController: webview.WebviewController = new webview.WebviewController();
     @State title: string = '';

     build() {
       Column() {
         Text("title:" + this.title)
         Web({ src: $rawfile('question/question4.html'), controller: this.webviewController })
           .fileAccess(true)
           .domStorageAccess(true)
           .onTitleReceive((event) =&gt; {
             if (event) {
               // 方式一：在onTitleReceive回调中使用getTitle获取标题
               this.title = this.webviewController.getTitle();

               // 方式二：在onTitleReceive通过runJavaScript执行JavaScript脚本获取标题,和方式一二选一
               this.webviewController.runJavaScript('getTitle()', (error, result) =&gt; {
                 if (error) {
                   console.error(`run JavaScript error, ErrorCode: ${(error as BusinessError).code},  Message: ${(error as BusinessError).message}`);
                   return;
                 }
                 if (result) {
                   this.title = JSON.parse(result);
                 }
               })
             }
           })
       }
       .height('100%')
       .width('100%')
     }
   }</code></pre><pre><code>  &lt;!-- index.html --&gt;
   &lt;!DOCTYPE html&gt;
   &lt;html&gt;
   &lt;title&gt;测试title&lt;/title&gt;
   &lt;head&gt;
       &lt;style&gt;
           #demo {
               font-size: 24px;
               font-weight: 700;
           }
       &lt;/style&gt;
   &lt;/head&gt;
   &lt;body&gt;
   &lt;p id="demo"&gt;&lt;/p&gt;
   &lt;script&gt;
       function getTitle() {
               return document.title;
          }
   &lt;/script&gt;
   &lt;/body&gt;
   &lt;/html&gt;</code></pre><p><strong>原链接：</strong></p><p><a href="https://link.segmentfault.com/?enc=hi3uwlUrTaczdLQLv253wA%3D%3D.xdb2qxXOWhXI0pLvfjW09%2BcBm6JoNwXiLnYScnUnLUqQM2jtGd2%2FqgW6Y%2FcBPI1DkDJWz07zVK3O5CZGX7LijyezLbj7TauGCxd24YAh%2FxuRKUKmBx%2FmTIYy1z%2BFCBrYLN9WjJCp6f0SDPRRH9ZcrL%2Fw9%2BrW5%2Fm7N54SP8I7jbgyeC%2B9WZ2IJua6hwoQx70Y" rel="nofollow" target="_blank">Arkweb如何正确加载web的当前title？-华为开发者问答 | 华为开发者联盟 (huawei.com)</a></p><p><strong>问题五：HarmonyOS NEXT应用测试都有哪些工具可以使用，它们的使用场景有哪些区别？</strong></p><p>目前HarmonyOS NEXT应用测试都有哪些工具，这些工具的使用场景是什么呢？</p><p><strong>解决方案：</strong><br/><strong>【问题现象】</strong><br/>目前HarmonyOS NEXT应用测试都有哪些工具，这些工具的使用场景是什么呢？</p><p><strong>【背景知识】</strong><br/><a href="https://link.segmentfault.com/?enc=FTMqToS4e3OrZpZXlenXMA%3D%3D.i8Y4f6FoAPFcwTKxlCNStTiS5GT%2B4d5g3DvojR3EnC5pTCchaGFc3boT9puuHSytk78335Pll4yDss4UYfnQxX%2BFmGgK8izT%2B8mWzdzCngjtO7GzGNQCNGDDPIDpfTZVtIXB1Imdxv9Ttg4ug1qk7nMtR0tYzvHm2dTNEYXwYIw%3D" rel="nofollow" target="_blank">应用测试概述</a>主要介绍HarmonyOS NEXT应用的单元测试、UI测试和专项测试。</p><p>AppGallery Connect<a href="https://link.segmentfault.com/?enc=eKGwzNkdwAqj2dIRQISThQ%3D%3D.ngzjXxKAIK2w%2Bp7PCMXaG%2B1BrLwTgUTqBWycOjkGpfILb15O5S6eUdtbsHbOCrBkEwcWXtQy18pXzOAFuEe4Glq8TxCekowI3xdyM1CEw6y%2BR4zd2%2FNTmmKeEtF57JRqC9C%2Bsk8OMKcuCvlfTtRV9JvgBMHLwr6ngzyawzu7cnRB5k8uvSZtuP9tAH0C3cn0" rel="nofollow" target="_blank">云测试</a>致力于提供便捷的一站式应用测试服务，解决应用开发、测试过程中面临的成本、技术和效率问题。</p><p><a href="https://link.segmentfault.com/?enc=EkTc3WKOQm1Azqxxs%2FGUGA%3D%3D.788QjzpIgnQb6LHPWJ4gjy1EJVlSaFUtzWbQsiFEjoGQEws0NrlHh6BbH3Xy5opHBeflBiv4bvvXY2D4mOhhAdQm6sB49XDAS9Xyq48BKyw%2B03qX3owKMsD94BYadyBszIoPjW2gt3VXESyV9soV4zMltxCR%2FaVz88H%2Frrzq4f1lYSxpinviTODPZicqI0EO" rel="nofollow" target="_blank">应用体验建议</a>主要介绍基础功能和兼容性、稳定性、功耗、性能、安全和UX这6大核心质量维度在开发阶段和测试阶段需要关注的体验建议。</p><p><strong>【解决方案】</strong><br/>如下图所示，这是应用在开发过程中典型的测试活动模型和测试活动质量目标，一般分为单元测试，集成测试、UI测试、体验测试和用户测试。</p><p><img width="723" height="295" referrerpolicy="no-referrer" src="/img/bVdnim0" alt="image.png" title="image.png"/></p><ul><li><p>单元测试：通过自动化测试保障代码、函数逻辑实现正确，异常处理充分。</p><ul><li>测试工具：开发者可基于DevEco Studio提供的单元测试框架<a href="https://link.segmentfault.com/?enc=iZkWaz6EEh%2BAkBSfdDmG9w%3D%3D.%2FWp8GurUnZTAgGhds3QRD%2B8FYP8ghqLshc20LTujVajwJFXQaD2erqSoRoCfVyR%2BSzeWEUVf3bEdCYdZjfqDgnoEOO9sNfH0vP9mCYu8zzdy5ACtqY5n1Qp6CMc%2B90iXu9JIHr%2BDdE5vrRhp%2FqLVlz0kTiwMqYIbuoj7F5UgPOU%3D" rel="nofollow" target="_blank">JsUnit</a>、UI测试框架<a href="https://link.segmentfault.com/?enc=BIfD3mTPnQshQiF3f831uA%3D%3D.mO9QlNg6cIyQtMl3G34YrcvtwnnYh0K%2BuuICvTYEGAC2rXPMwQ3kf%2FrHdFjZZ%2FWtLmk0uPKOunLsVlpj0QxRteMSnICDmQZpr04dszqBp9SBdygLpJNHxbKvSCCOrDVwIAHkZIx2vcwsVIL8k%2FWx7jG9VYf628%2FoXNVXtgl3kvmAmas3B%2FyKfrrjSVVoODZ6" rel="nofollow" target="_blank">UITest</a>和白盒性能测试框架<a href="https://link.segmentfault.com/?enc=1qvjgz6YHqyO64h5FqEQ7A%3D%3D.VHarOdQKDXIs2Q0mouES%2BUEaT4rFmlbGznU%2BZBVHH47Ed%2Bnz2rYap%2F4QtcVUk7RkSDDFqoxAG4SfISFeUFJJHfAmtWt6WmrsoiMHHB9fZGwrgMbB3ytuxPnxqhn79Hk%2BIlcCa24eBodAAc%2BAO6dfO%2B2TEpdGZwb586L0vis4N4Y%3D" rel="nofollow" target="_blank">PerfTest</a>进行用例编写和自测试，支持<a href="https://link.segmentfault.com/?enc=wF5VZhrjSwfjRZx1O4waFw%3D%3D.DC5FJoujPDc0yGWFju3MiCPY92ix9LP%2BzQlOdle2gMx81n7DD1pHzHp3RTK05A3qklAu0EMQOP6BZs0wueV04aKmTiWUOZhtSsU7ebWzvw4e8xFcmihUzCmS4PeOIDTbOpOVdk21hkZ0i4WuOQL4GNaOMiEXNCmKgO%2Bw7OxQ8LCXsITNhQ9woRzpz6cV6nkK" rel="nofollow" target="_blank">黑盒覆盖率统计</a>和<a href="https://link.segmentfault.com/?enc=rBU4B1NHw58u1r2UCfxcSA%3D%3D.RhZkgXkQ1DoPg%2BCKxG5bxfRO4FXl7zRUOvKvLpUB9pSJKYvBrAQLxBVm4eFbTQ9kckXXidyu856EW4ZrJOZiG%2FHQ6hTtV0sJhDJd%2Bz%2B9namJwfcPxqxEab1POrsObvbFcWoxN0iDVGJVLHWjEo4lTT5uP6BuGw4i5MfLM1RPfGaFQdNdEMOumpSKsgfmZh64" rel="nofollow" target="_blank">Mock能力</a>。</li></ul></li><li><p>集成测试：组件实现符合设计，接口正确和组件完整。</p><ul><li>测试工具：同单元测试，集成测试检查更大子系统的行为，或者多个类和函数的组合。</li></ul></li><li><p>UI测试：应用功能正确实现，用户场景目标可达成。</p><ul><li>测试工具：使用基于Python语言的<a href="https://link.segmentfault.com/?enc=247L%2BVUsnCn4sJD0jz5HQw%3D%3D.YIQJPRfFpDwUQPkmySEAOwC7OO8GOk5DvLkGXdZDMXPJjU7%2Be6HozyQLRNNC4QJhaNMPvzU0O14ajIyXy12O%2BfQWpVYWJ95tkkollTMGJ3ZLz46q5ecIXW5JQ2IPXj56vWLaDq07sTVE3FMOBFrSSsbL0vLEdXAyCnUs0xvEe5U%3D" rel="nofollow" target="_blank">DevEco Testing Hypium</a>进行UI自动化测试，提升测试效率。</li></ul></li><li><p>体验测试：主要包括兼容性、稳定性、安全、性能、功耗、UX等，开发者可通过专项测试工具来保证应用基础体验良好，流畅、精致、安全等。同时开发者在应用上架前可以提前进行上架预检测试，提前发现问题，提高上架审核通过率。</p><ul><li>测试工具：</li><li>如果您本地有HarmonyOS真机设备，可使用<a href="https://link.segmentfault.com/?enc=Odac1Qbt%2FIcm5u%2FJs7SXqA%3D%3D.L6gSuXFsMGs6djUTLSpWQbDkcj5UvodMOo8A9mMpoontOO7eJR3GT3KUTT7lEX%2FEuCnXV6A%2BN1uM64wMte3Mwsb2%2B%2F3tJLyMq10WQbtgUxifpcW6HveQ0pfFATu7%2BrjHDCHln9bnOIkv%2B53KJo241RQ1TOu9FsRYSZShb1QhY5fWfblq2u8VZd%2B4jHalGJ8u" rel="nofollow" target="_blank">DevEco Testing</a>进行专项测试服务。优点：以服务卡片的形式呈现，安装工具后，即插即用，一键执行测试任务。</li><li>如果您本地无HarmonyOS真机设备，可使用<a href="https://link.segmentfault.com/?enc=PFtx%2BacmCxky8Kd28CkO%2BA%3D%3D.pzU78PAFv7pYnPne%2BTVDWQO9zJFgr8DfQpY0FiTugSq0P%2BF3nfJ4lifuv3IDfiNHgloEuDqmzccH%2F%2F%2Bex%2B6TxnFdb6jm0LjTFDLEb%2BcUwqdzjRWecX0BqmrXyQQMK9tajpm%2FRMbOWEIbesSX3qlClT85un%2Fil6k24lSBiD54cN4%3D" rel="nofollow" target="_blank">云测试</a>进行专项测试服务。优点：提供海量远程真机，无需开发者自备真机，可申请多台设备并行测试，解决应用开发、测试过程中面临的成本、技术和效率问题。</li></ul></li><li><p>用户测试：用户感知卓越、好用、爱用。</p><ul><li>测试工具：</li><li>开发团队内进行<a href="https://link.segmentfault.com/?enc=2DbbvdHo%2Fgagk9fxOe0cnw%3D%3D.HqoaUZBiSc8dzynfqiie2YHZds5UNxrUhhNAp%2FujK3ZpacTxEPVxydVk0a0Muf4nDpRdWR7k4%2Bwp7sYIfhTvK36TnhZN08JqC3vq%2F4CdqX%2BmVCjtgg7RtzrAqN74vCmSgAys5l0o8Vi5Egp%2B82O2YOdRUfMuxbodbW1GbTLq3rJ3oD18y6S8o2SWZ7Smi6A%2B" rel="nofollow" target="_blank">内部测试</a>。</li><li>选择特定用户群组进行<a href="https://link.segmentfault.com/?enc=ujQ%2BPdI%2FdAL9s0W6d%2F4%2Fkg%3D%3D.99Itaf0jxuopxyxB5oLLqbRXHnrLhtJ%2FaGRcg9zAP%2F%2BOPGsqwL7e5K1WIA7g%2FQT2quJx1ZPYiXhY3VbvDBU5Fkj8tpCWZMh7OgYRjOsCvhfgv51HPaF6LP9rnMAm4UcLG6Vv0gFJ51GQLd5rAcWqt37m368we5HwIhOjrs1yZ2Y%3D" rel="nofollow" target="_blank">邀请测试</a>。</li><li>面向全网公开招募用户进行<a href="https://link.segmentfault.com/?enc=e89q2vV0uoFMUDhTW3c%2FVw%3D%3D.NYgwP%2BPw5fammaV3LzUaBh2baATfyMu99xE4KBbwZhxi%2FUMqHiHG3KwqtnoQxgchpi9xuxs0k5iKY9Byyd62qNgZBwpzDzOCEj5Aax58XY%2F2XgA61bh%2BhSrrwhRJ6%2FPVLkJFV6j0wzWfaP5WuGDbmImfkD6RJYJYD4O%2FPwSV6Nw%3D" rel="nofollow" target="_blank">公开测试</a>。</li></ul></li></ul><p><strong>原链接：</strong></p><p><a href="https://link.segmentfault.com/?enc=bTbJQxwYlAr6x48SsUSaxw%3D%3D.aOw6cKzm2Pooz67IXMPDUQWOpHnMt3%2BwVltYgaVxjF1Oc%2FcZou7GB6baWHDWscwRL%2Bz8oqpLRnogzh1pLzToJxLn21wJdzH6ye0J0lPHNHyn6EjbEPJrPKLMYx0pV51hEdcCV2wGQHhIgqeqVYJ4rg%3D%3D" rel="nofollow" target="_blank">HarmonyOS NEXT应用测试都有哪些工具可以使用，它们的使用场景有哪些区别？-华为开发者问答 | 华为开发者联盟 (huawei.com)</a></p><p><strong>答开发者问系列汇总：</strong></p><p><a href="https://link.segmentfault.com/?enc=sbHlVXUCk%2B7DbyQc9OSGAg%3D%3D.Sk5XVYTURBgm2xaDUkpz%2FlO1CyfutpW%2FdNmtTeT7m1Qg7vPDXw6Zaj7wY7DmcNj4vHAI%2BFQ2uDSseoP5%2FojzE5kMh7Jgb742cpz0OmaEOYh6HcsxleWl4uai9I%2FuiIFYb6NFT3CGlnrInr9igOXhgOiMbXKZwubFy6fgPKyoPfsIkvPrmK2e5%2F565jv9bIm1" rel="nofollow" target="_blank">“答开发者问”系列汇总（持续更新中...）</a></p><p><strong>往期问题回顾：</strong></p><p><a href="https://link.segmentfault.com/?enc=nzYa8Rb4XO%2B6Eo%2B9qOJGdA%3D%3D.FDH9iap3phL8xkkH2Wll0vGzLlJXEghAKR4Gi3brV8G3bZkXqEq4cKRdqn7EJ7Ogj7rS%2FEmbUVGqRsFCMMsr%2BR%2FZEb8gzABDge32dkhYCE6MsWOS1ec3KRn0s%2B2yZ0SFYx6nYfNofc%2BAPbYO7HZwwb6kDElWMFreNJ88xasUwRjNEdvotmB3M9QLt7hVFbZE" rel="nofollow" target="_blank">“答开发者问”之HarmonyOS技术问题解析 第1期</a></p><p><a href="https://link.segmentfault.com/?enc=SFwQSBz4HcY0VeHC%2Fc7Bzg%3D%3D.jj7th8IS0Lb8nqUFDws7dzUPvHEM03srN%2BkyvAuZrv0%2FppHjVg0E9739G743t9SRD3Gori3U66mFh24KxspuOWSZHhokxMO2S5IvzILo1PRvZrHtnZU8%2BWbPhq8r%2Bbv9X8KI9HH5PFZXZWDFPXMirKPtc9DDbozV8re%2FSRC1uNMlxQNoZ292tJuS0cQB9LGf" rel="nofollow" target="_blank">“答开发者问”之HarmonyOS技术问题解析 第2期</a></p><p><a href="https://link.segmentfault.com/?enc=aKWwlPSo5RCJ69lcGNC9sw%3D%3D.0P6qB%2Fc%2Fpof34%2F86nTQ0tymvu6nXcm9FaVui8v19R2z9e0G%2Fux8uPBRVNyh6i6ag3zA3lz6%2Fr4KtfQ1BCBAaNgPuqHzXo1S%2BqrGAQgqkDsr7veAumd2tsWKGvrgYfJK3hv%2FWLjwFrY89zdWhXUoNrp78X3wTETZK19%2FmnAilJga3sXWxJfTxHqjCEN8DfnQt" rel="nofollow" target="_blank">“答开发者问”之HarmonyOS技术问题解析 第3期</a></p><p><a href="https://link.segmentfault.com/?enc=e43i5mr9CAVh2JaUr2b%2BxA%3D%3D.t7kirSof0P99Yrh1cu%2Fn47f%2BEYSwYmptGRvHoPR8tdTRQ4%2BFQ25j5vt2I0NFl6npgpUl7jZwOfp40gNcMyZ65X5oCFRpyTCa3ys%2BloAgPR7IkbTJIvacQ7njwxfTl%2FGtdeUGJa%2F%2FudDzmZqcof9o924UCdGxMbS6Qub%2B28tpBOrxWWSTyfG7HGTeViKP6Dd8" rel="nofollow" target="_blank">“答开发者问”之HarmonyOS技术问题解析 第4期</a></p><p><a href="https://link.segmentfault.com/?enc=J7pd%2BJEFoJsOyQ25%2F5PX5w%3D%3D.5NNdkF5A%2FEGrOV6CudA%2FqobjG1L4l1VrPD5vV82ZtrU1KgDobfJgGZtuDwYzl2xuVXBKfs5ZjxD1oI3Sos%2B%2BVNP4rvYsArqxMfstu404pQ2UwdrGheCZb13j8b23r1ywpYrOIDGQth00ex0hY26zbsamIZ0g1TTFnudQSL%2FeNNF%2B6U%2F4rv9YaXRlOlidKWPY" rel="nofollow" target="_blank">“答开发者问”之HarmonyOS技术问题解析 第5期</a></p><p><a href="https://link.segmentfault.com/?enc=Mhjt%2FStrnIo7dbJZJTidhw%3D%3D.9NOHWkjG5pW2JeD2cbBmMI%2Fh6zgvxUmUhZJsjVLOdQ4IxrBv89WfHM2IxG%2FsVxAOxEDlJ1W%2FxGsKX8wYu287dH5OpW0mzwOoogUNYlkwjR95wAFTvzOYKww8VIy2q%2BCh1NrrmcFpQB%2BUtGNsIEftolVhCOTgPOx56DPGNpIS3BR7jQTSHZkawfbyrHlAtFt%2B" rel="nofollow" target="_blank">“答开发者问”之HarmonyOS技术问题解析 第6期</a></p><p><a href="https://link.segmentfault.com/?enc=G7i9SAYR5HmHkU7CDW7bbQ%3D%3D.Su6Tht9R1%2BBgpRiXLVbxcW0LVj1Jz3V7Hl0qZ7SZGYzmuaEnAjjbB5mlt0KUrACGv81YPsVunSpNceK4BUBQyuwfhPkiG3RLX1UKexdLuT8wgY7A6gViIEvOnlIfQVrwGLp1ZneHEmit3v6Kacuj3rOo9JVmoFxcYWdaHXJcZ%2F2XfKfiV%2FBqLXsx2TVx%2B9MU" rel="nofollow" target="_blank">“答开发者问”之HarmonyOS技术问题解析 第7期</a></p><p><a href="https://link.segmentfault.com/?enc=pLe2Fjc0zrRwrz5lW9B3eA%3D%3D.gLQEVp3XFwD%2B2JG6P66qp%2BtctHbvVK%2BjzkAKh1HU7n8AjakKvRyCQUB2Q4FEb8Kekbt0fUFNCsmuUth9sbLEUPls7hsRbIMHJlMqrmzBCLKnlpc%2FvfNyrcURCUjInokqv5CmTQj4SEzY80E1gFwacFAU%2FSC53PgP258ZVG7sYhx%2BOP%2BhtwLEx6VgeIU%2BCqBr" rel="nofollow" target="_blank">“答开发者问”之HarmonyOS技术问题解析 第8期</a></p><p><a href="https://link.segmentfault.com/?enc=6OrgSCqG4eC7XD0bXH3xYQ%3D%3D.mAdmZ0vILEOTr5ZSyq9sBbXiXwzOio3nYSgDYA43S491Kj5%2BvSsyrXPYPQy1XJY9eDCOEw2oFGRoIHV1FqW4x9x2xfQzqVMh2SWGo0aGjO5pQDaRZVcIehsBnM3RSU7J%2B%2FY7Gp2xW9uJf7bmauq5xEoF3WxFpr3b5C4QpXvOdMUsc9r4kgWAPwB77wCrliRp" rel="nofollow" target="_blank">“答开发者问”之HarmonyOS技术问题解析 第9期</a></p><p><a href="https://link.segmentfault.com/?enc=QzrDab%2Foa7oUfNyqLxGHig%3D%3D.BSpJrZPdRqSEFDYsHYQNHdljQF4HjJtDOfP8TiT3amMnRn1J3zQSyqtXXnwQMMkwVABynLdlCQ7oW%2Fl2eJs2pVOV4r9NKjHA9qmGhkoB2wnGYKBQEIIBOTQd2LLGVSZ9qzs%2BbUpDLwwTJJtipCqqFdcdkK%2FIKVyZAfHNawTi%2BYfMB3KAs8fMLMhZ130jzjr9" rel="nofollow" target="_blank">“答开发者问”之HarmonyOS技术问题解析 第10期</a></p><p><a href="https://link.segmentfault.com/?enc=ekzfxpU5ogvC%2F%2BiOhyomLw%3D%3D.gOOobZXOdsjQh3KR%2FByrwda%2Fsk7lw4czM0ARhJn86woC84fLkfAt2LHlG1rUWmwN0sEk7576cAIh%2BQIm706ce%2FqEkrM5pO9GqdwNIo6SIzpZ1DzgVg0aVatIhEaDfT4vzBW82duUCnNKd0BCvC7FC7J%2F4wJMOHZCoIaA9J88EYc5tBr%2BlAqRFmeu5L4dAZA6" rel="nofollow" target="_blank">“答开发者问”之HarmonyOS技术问题解析 第11期</a></p><p><a href="https://link.segmentfault.com/?enc=P%2F2U3RQkuPt2Pit%2B%2Ful%2FzQ%3D%3D.ngKBYh%2Fjz5FFIpvzqUE3cASp4N%2F57urBO8QriVhdEfXgrsCbosq%2FZG5nCxvUvX1CpFvlcaqoGjNUZyfhs4j%2BCxT%2FW8F4eb5Y1vQ5P8HMirNDr27PahFfA7%2FieoREe9b8%2Fyxi6YE4T9md91R0RrFjgwAea7VujmhjHG2IvHiHGpdo8SDmNlbC633F7eRL9QzT" rel="nofollow" target="_blank">“答开发者问”之HarmonyOS技术问题解析 第12期</a></p><p><a href="https://link.segmentfault.com/?enc=6lbRs8rYIqyCwo8M9WU8iQ%3D%3D.NVeZgDxG2%2FMvpOkalUMhEFKtP5S9xPrvrAcSjVlVEQ7qaGBlTIIwNQvimEChDqS9e11zVv6MDDL5Xdf6dSyZu7IVizGEXzsfjDLqMW3cSiF5qzRDlLIV2%2FbMUqcZmKjC5VUYRlZ57n5wKCilzxH7hgcQwp30VHbAzDZSdWEGmMVn%2B6g2Cr1FzqAtGm0UHSt4" rel="nofollow" target="_blank">“答开发者问”之HarmonyOS技术问题解析 第13期</a></p><p><a href="https://link.segmentfault.com/?enc=hRWfagFW1NhixN15mjA3gw%3D%3D.VtYPMcKDkNkmdPrPv3ehPE5lsNWoPIIe7UtFJv048yzXDrukWraovFmKoCo4sITFbdC%2BSzv1hvR1MI3r3xmkEndEIpODEBmvRVUfK9YTZU%2BM2%2BD1gBHvNoZK9QJ%2FAl2G45ySb1mDsaUAL0gGTHuPkbUAu0HRSwMmiVDy9tBSN%2B90vJC6huelC57QF0MhIXaC" rel="nofollow" target="_blank">“答开发者问”之HarmonyOS技术问题解析 第14期</a></p><p><a href="https://link.segmentfault.com/?enc=y%2FhZrIg9LGjBD18Xd41GAA%3D%3D.g67vVYpJLRhzeQDjng5tmNGaKrXftMrN%2FE0NAhO3ladGfIkZBBxxLST3QzvGUtsbf2ubuI5g64nWe%2BfnDT7xsOUIxTzuocr1ES5NYalndqNUEcux0JdK%2BOMS%2B55TD4jQSnQehLgk6Vu%2ByC8%2BIiI2KnELWM1O1bit09aHOu6Y1cQWZoD1O%2BMqbVmPPFhXv%2B%2Fp" rel="nofollow" target="_blank">“答开发者问”之HarmonyOS技术问题解析 第15期</a></p><p><a href="https://link.segmentfault.com/?enc=PAFPQ7H874UB%2Fh%2B50F2v2A%3D%3D.OIlbG9i03%2BiQU%2FgYOyfzJXGKyYS1tErfUKRRut3kl6k0z6Np%2Fb2lxr7xsaPrn75VXNu0lNcJBeukMxRD8dleWUt9otyMe4O%2FMGg0EyNGYxPU2ZttAMXxKFGq%2BJ0%2FWx%2B4qfHrmNyLmHBHZBggqfH35uKg1hoJApwGJK6uQyFNRpfx37o78V4n2a1hXOwofmQh" rel="nofollow" target="_blank">“答开发者问”之HarmonyOS技术问题解析 第16期</a></p><p><a href="https://link.segmentfault.com/?enc=h%2BJJlV97%2BtMzhJ4BZHQvmw%3D%3D.YHmBBTJgswTC7kRc7NqdLd0bqoqYEwBKpW3A%2Fvoo2TLda6oyBa1cS2mAfc7DjQzPl1YJG4addQECBlTiuQ1VtOR1p46JkuTRmomjQyTFz%2F0PpIfeImgffLawq3t6jVjCaTLUR9U5ZoeHVx1Pfk3eI%2BEPDRsfRnbt4y52OsTrsVQO6ks2BhRTfevduHEIRhn%2B" rel="nofollow" target="_blank">“答开发者问”之HarmonyOS技术问题解析 第17期</a></p><p><strong>注意：</strong></p><p><a href="https://link.segmentfault.com/?enc=TmrE5PxXXuoe%2FLOAtsZ6fg%3D%3D.hE4oAnJSr7JdCyMdpISJDtxqz9PvkEqbQ%2B2bAuotpuzjgzUNdj80lsug%2FCc3JhGGWwzCeLtbc0UkQiJZ84%2Bw%2B4EPQMjYtBFrhUHG8epjV4HSZLpo1avRcEk%2Bzz%2BhNDDy7opWe3eqKOkw1gtusirVJpITQvF9PZcr544%2F20d8pfz%2FtRaaLhJKZH3Lm9%2BVVZyt" rel="nofollow" target="_blank">开发者小伙伴们，规范提问，高效沟通！更快得到问题答案的秘诀来啦，点击链接直达</a></p>]]></description></item><item>    <title><![CDATA[AIGC项目中的【模板进程】方案的设计实践 京东云开发者 ]]></title>    <link>https://segmentfault.com/a/1190000047458904</link>    <guid>https://segmentfault.com/a/1190000047458904</guid>    <pubDate>2025-12-08 18:09:28</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>1 项目介绍</h2><h3>1.1 项目背景</h3><p>简单一句话：模板进程是流程的子流程；往往用于比较复杂的aigc项目流程中。</p><p>由于一个模板有多个流程，一个运营人员可以操作多个流程，也可创建多个流程。在模板推荐时，就会导致不知道是哪次流程。</p><h3>1.2 项目目标</h3><p>为了区分模板中流程，就需要增加进程的概念（子流程），为了方便运营理解，此处也叫模板进程。</p><h2>2 需求分析</h2><h3>2.1 底层逻辑</h3><p>1、场景模板、指令触发模板均支持实例，模板数据支持根据实例进行隔离（原来启航项目创建多个SC，每次都需要澄清，现在根据进程隔离，当一个进程中存在多个SC时，才需要澄清），公共信息存储需要新增实例查询等能力</p><p>2、进程不会结束，支持移除（逻辑删除，不真实删除），仅进程创建人可删除自己创建的进程，项目管理员可删除所有进场，无权限不显示删除按钮（需要增加埋点，记录操作人及时间）</p><p>3、模板卡片的步骤流程状态，根据进程独立显示。</p><h3>2.2 触发方式</h3><p>1、【自动显示】每次进入项目详情页，若全部进程中存在进程，自动显示此卡片，无进程不显示。</p><p>2、【指令触发】输入：进程/场景进程/模板进程</p><p>3、无进程，用户触发任意步骤，均创建一个新的进程</p><p>4、用户可根据需求选择【新建进程】</p><h3>2.3 进程分类</h3><p>1、区分：全部进程、我的进程</p><p>2、每次触发卡片。默认打开【全部进程】</p><p>3、卡片引导文案，如下</p><p>全部进程：以下当前项目下正在进行中的所有进程，请选择。</p><p>我的进程：以下是您在当前项目下正在进行中的所有进程，请选择。</p><p>4、全部进程显示逻辑：显示当前项目的所有进程，按照创建时间倒序显示</p><h3>2.4 进程详情</h3><p>1、显示字段</p><p>进程名称：默认显示模板名称，支持编辑</p><p>创建时间：进程创建时间，年月日 时分秒</p><p>创建人：显示创建人头像、中文名，点击支持快速唤起京ME进行对话</p><p>模板进度：显示当前模板进程实例中步骤完成情况</p><p>当前步骤信息：显示当前板进程实例中最新的正在操作/代操作的步骤</p><p>当前步骤操作人：若当前步骤有操作人，显示当前操作人信息，像是规则同创建人，若当前步骤操作人不显示该字段信息</p><h3>2.5 进程名称修改</h3><p>1、点击编辑按钮，进程名称可编辑（保留原名称），最多支持1-20汉字长度，支持特殊字符。</p><p>2、删除空内容时，显示提示内容：支持1-20汉字</p><p>3、点击其他区域直接保存内容（若保存时，名称无内容，直接填充原始内容-模板名称）</p><h3>2.6 删除进程</h3><p>1、仅进程创建人可删除自己创建的进程，项目管理员可删除所有进场，无权限不显示删除按钮</p><p>2、点击删除按钮，显示弹窗，二次确认</p><p>弹窗内容：是否确认删除此进程，进程删除后对应产生的数据建无法修改以及编辑，请慎重操作！</p><h3>2.7 新建进程</h3><p>点击新建进程，后自动唤起场景模板引导卡片，新卡片无进程，用户点击任意步骤后，创建新进程实例</p><p>﻿</p><h2>3 概要设计</h2><h3>3.1 系统流程图</h3><p>﻿<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047458906" alt="在这里插入图片描述" title="在这里插入图片描述"/></p><p>﻿</p><h3>3.2 进程设计逻辑</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047458907" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><p>﻿﻿</p><h3>3.3 进程卡片逻辑</h3><p>﻿<img referrerpolicy="no-referrer" src="/img/remote/1460000047458908" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h2>4 详细设计</h2><h3>4.1 各模块实现方案</h3><p>1、<strong>自动卡片展示</strong>：每当用户访问项目详情页面时，系统将自动检测当前是否有任何进程正在运行。若存在进程，则立即显示相应的卡片信息；若当前无进程进行，则卡片不会显示，以保持界面的整洁性。</p><p>2、<strong>指令式激活</strong>：用户可通过输入特定的指令来触发相关功能，这些指令包括“进程”、“场景进程”或“模板进程”。输入任一指令后，系统将根据指令内容执行相应的操作或展示相关信息。</p><p>3、<strong>新建进程机制</strong>：若当前系统检测到没有正在进行的进程，并且用户尝试通过任何方式（如点击按钮、输入指令等）触发与进程相关的操作，系统将自动为用户创建一个全新的进程实例，以满足用户的操作需求。</p><p>4、<strong>用户自定义新建</strong>：此外，为了提供更高的灵活性和便捷性，用户还可以根据自己的具体需求，主动选择【新建进程】的选项来手动创建一个新的进程。这一功能允许用户随时根据自己的工作计划或项目需求，快速启动新的任务或项目进程。</p><p>5、<strong>进程的增删改查</strong>：添加、修改名字、搜索等逻辑。</p><h3>4.2 实现方案详细设计</h3><p>以下为详细设计方案</p><p>﻿<img referrerpolicy="no-referrer" src="/img/remote/1460000047458909" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h3>4.3 模版进程卡片设计</h3><p>卡片样式配置规则</p><p>subType: "subType"</p><p>cardStyle: "subType\_card\_style" （控制样式专用）</p><p>﻿<img referrerpolicy="no-referrer" src="/img/remote/1460000047458910" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><p>﻿﻿</p><p>卡片数据结构</p><pre><code>"cardInfo": {
    "title": "", // 卡片名称
    "subType": "full_work_card", // 卡片标识
    "workItem":{
        "allItem":"全部进程",
        "userItem": "仅我创建",
        "myTurnItem": "轮到我的",
    }
    "newItem":"新建进程",
}
// 返回给后端结构
{
    "ext":{
        "skillCall": {
            "domainCode": "",
            "commandCode": "",
            "workId": ""
        }
    }
}
</code></pre><h2>5 实际效果</h2><p>点击项目详情，聊天助手打开进程卡片：</p><p>﻿<img referrerpolicy="no-referrer" src="/img/remote/1460000047458911" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><p>﻿﻿</p><p>点击 “测2” 进程，进入如下页面：</p><p>﻿<img referrerpolicy="no-referrer" src="/img/remote/1460000047458912" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><p>﻿﻿</p><p>**</p>]]></description></item><item>    <title><![CDATA[移动端设备上稀奇古怪的前端问题收集（一） 京东云开发者 ]]></title>    <link>https://segmentfault.com/a/1190000047458914</link>    <guid>https://segmentfault.com/a/1190000047458914</guid>    <pubDate>2025-12-08 18:08:27</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>作为一名开发者，bug 往往是我们最怕遇见的东西；而比遇到 bug 更可怕的事情，是定位不到 bug。作为一名前端开发者，与业务逻辑相关的 bug 还相对好定位、好解决一些；而一些与语法特性、平台与设备差异相关的 bug 则更令人头疼一些。这里记录下我在工作中遇到过的稀奇古怪的前端问题，作为给自己的记录和提醒。</p><h2><strong>用 vh 定义全屏显示的问题</strong></h2><p>很多页面因为设计效果的需要，要求正好铺满一整个显示界面、也不允许上下滑动。做类似的需求时，往往直觉会使用这样的代码解决问题：</p><pre><code>{
 height: 100vh;
}</code></pre><p>这样的代码看似很优雅，但是往往会有兼容性问题——不同浏览器定义的视口高度的定义不一致，导致 <code>100vh</code> 并不能真正覆盖全视口高度；还有不少浏览器视口高度数值不变但实际视口大小可变，比如移动端 Chrome 浏览器的导航栏时不时隐藏但网页获取的视口高度不变，这都会导致最终显示效果不符合预期。</p><p>如果要实现全屏幕覆盖不可滑动，更为稳妥和保险的方法是使用绝对定位：</p><pre><code>{
 position: fixed;
 top: 0;
 bottom: 0;
 left: 0;
 right: 0;
}</code></pre><h2><strong>带 alpha 通道的 hex 颜色值失效的问题</strong></h2><p>在较新的 web 标准中，hex 格式的颜色代码也可以表示透明度了，只需要在常见的六位 hex 颜色代码后加两位表示透明度的 hex 值，例如 <code>#66ccff</code> 表示一种蓝色，而 <code>#66ccff80</code> 表示透明度 50% 的这种蓝色（80 是 16 进制的 128，是 256 的一半，即 50% 透明度）。虽然直接这样写代码的行为在前端开发中不普遍，但是设计师交付的视觉稿给出的参考值有不少是这种格式。如果直接把这样的颜色代码用于生产中，可能会出现以下两种问题：</p><p>◦如果你编写的项目引入了 less 或者 sass，在进行打包构建的操作时，部分预处理器无法正确识别带 alpha 通道的 hex 颜色值，因此这部分代码无法被正确转译，最终构建出的生产环境代码中这部分颜色可能丢失。</p><p>◦部分移动端浏览器并未适配带 alpha 通道的 hex 颜色值，因此即使是使用原生 css 完成的代码，也有可能出现在部分手机或部分浏览器颜色不正常的问题。</p><h2><strong>生命周期函数不执行的问题</strong></h2><p>在页面刚打开或准备关闭时，我们往往需要进行一些诸如数据初始化、登入登出、数据上报等行为，而这些往往是借助 Vue 或 React 的生命周期函数完成的。不过，生命周期函数不执行也是常被忽略的 bug，详细来说，又可以分为两类原因——</p><h3><strong>组件被 keep alive 导致未被卸载或重新加载</strong></h3><p>如果是 Vue 中使用 <code>keep-alive</code> 包裹的组件，或在 React 中使用类似的第三方库 keep alive 的组件，只会在第一次加载时执行生命周期初始化函数，且不会执行生命周期卸载函数。这导致的不符合预期的行为很好解决，只需要使用 <code>onActivated</code> 代替 <code>onMounted</code> ，用 <code>onDeactivated</code> 代替 <code>onUnmounted</code> 即可。</p><h3><strong>页面被直接关闭导致框架生命周期函数无法执行</strong></h3><p>不管是 Vue 还是 React，生命周期函数的正确执行都依赖于 Vue 或 React 实例的存在。而当用户直接关闭浏览器页面的时候，Vue 或 React 实例已经被销毁了，生命周期卸载函数当然就无法执行了。处理这种情况也并不麻烦，只需要在生命周期初始化函数中添加对 window 卸载事件的监听，然后把想要进行的操作放到 window 卸载事件函数里就好了。</p><pre><code>onMonted(() =&gt; {  
  window.addEventListener('beforeunload', () =&gt; {    
    // 需要执行的代码 
  });
});</code></pre><h2><strong>文本中的 emoji 上下被裁剪</strong></h2><p>UGC 内容中经常出现文本和 emoji 混排的场景，而有时可能遇到 emoji 上下边缘被裁剪的问题。这往往是由于开发页面时为了限定文本高度和间距或其他排版方面的要求，将 line-height 和 font-size 设置为同样的值，且 overflow 属性被设置为 hidden 。如果出现类似情况，建议去除 line-height 的限制，而通过 margin 等方式控制行距，从而避免 emoji 被裁减。</p><h2><strong>输入框被弹起的软键盘覆盖的问题</strong></h2><p>如果移动端页面中有输入框，那么很可能面临输入框被弹起的软键盘覆盖的问题。一般来讲，对于需要弹起软键盘的场景，较新的浏览器或者移动端 app 的 webview 会自动聚焦到输入框中并滚动到相应位置，来保证输入框的正常显示；但是，对于如下两种情况，弹起的软键盘会将输入框覆盖，影响用户输入。</p><h3><strong>浏览器未能主动聚焦到输入框</strong></h3><p>软键盘弹起时，一般会从底部将页面顶起、压缩视口；视口高度变低了，原先处于显示区域的输入框可能就被挤到输入框外了。如果用户使用的浏览器版本较早或 app 内置 webview 较为特殊，有可能在软键盘弹出后浏览器未能主动聚焦到输入框上。这时，开发者必须主动聚焦到输入框并使输入框滚动到视口内。</p><pre><code>const inputEle = document.querySelector('#target-input');inputEle.focus();inputEle.scrollIntoView();</code></pre><h3><strong>软键盘采用覆盖在视口上层而非压缩视口的方式弹出</strong></h3><p>如果浏览器或 webview 版本较为特殊，且输入框处于页面靠下的位置或者针对视口绝对定位于底部，那么可能会面临更加复杂的情况。刚才已经提到，正常情况下，软键盘弹起的标准做法是从底部将页面顶起、压缩视口高度；但是某些情况下，软键盘并不改变视口尺寸，而是直接盖在视口上方。这就导致页面逻辑上是展示完整的、输入框也正常显示在视口中；但软键盘遮挡了半个页面，也就真正意义上“覆盖”在输入框上。目前主流移动端浏览器较新的版本都不会出现这个问题，但是部分 app 内置 webview 会设置为“软键盘覆盖在 webview 上方”；因此要解决这个问题，必须由客户端更改 webview 的软键盘设置。如果是很旧的浏览器版本或者无法推动客户端开发解决问题，那就只能放弃治疗了。</p>]]></description></item><item>    <title><![CDATA[MQ消息乱序问题解析与实战解决方案 京东云开发者 ]]></title>    <link>https://segmentfault.com/a/1190000047458917</link>    <guid>https://segmentfault.com/a/1190000047458917</guid>    <pubDate>2025-12-08 18:07:55</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>1. 背景</h2><p>在分布式系统中，消息队列（MQ）是实现系统解耦、异步通信的重要工具。然而，MQ消费时出现的消息乱序问题，经常会对业务逻辑的正确执行和系统稳定性产生不良影响。本文将详细探讨MQ消息乱序问题的根源，并提供一系列在实际应用中可行的解决方案。</p><h2>2. MQ消息乱序问题分析</h2><p>常见的MQ消息乱序问题的根源主要可以归结为以下几点：</p><h3>2.1 相同topic内的消息乱序</h3><h4>1). 并发消费：</h4><p>在分布式系统中，为了提高消息处理的吞吐量，通常会配置多个消费者实例来并发消费同一个队列中的消息。然而，由于消费者实例的机器性能、网络延迟以及处理速度的差异，可能导致消息的消费顺序与发送顺序不一致。</p><h4>2). 消息分区：</h4><p>为了支持更高效的消息存储和消费，MQ系统通常会采用分区化的设计。然而，当同一业务逻辑的多条消息被分发到不同的分区时，消费者在消费这些消息时就可能出现乱序现象。</p><h4>3). 网络延迟与抖动：</h4><p>消息在传输过程中可能会受到网络延迟和抖动的影响，导致消息到达消费者端的时间顺序与发送顺序不一致。</p><h4>4). 消息重试与故障恢复：</h4><p>当消费者处理消息失败或出现故障时，MQ系统通常会进行消息重试或故障恢复操作。如果重试机制或故障恢复策略设计不当，也可能导致消息乱序。</p><h3>2.2 不同topic的消息乱序</h3><p>从相对时间的视角来审视，消息被消费的顺序并不等同于其被发送的顺序。例如，系统A在12:00时向TopicA发送了消息msgA-12:00，而紧接着系统B在12:01时向TopicB发送了消息msgB-12:01。当系统C同时订阅并消费这两个Topic时，它无法预设msgA-12:00会必然先于msgB-12:01被接收。这是由于消息系统在处理过程中，受到诸如消息分区策略、各个Consumer的处理能力以及其诸如网络、堆积、重试等他综合因素的影响，导致无法确保消息遵循严格的先进先出原则。</p><h2>3. 案例分析</h2><h3>3.1 数据迁移过程中的mq消费乱序场景</h3><p>在数据迁移或同步过程中，尤其是双写场景（即数据既写入旧系统，又通过MQ发送到新系统进行异步处理），MQ乱序可能导致严重的数据不一致问题。</p><p>﻿</p><p>!<a href="" target="_blank"/></p><p>﻿﻿</p><p>具体来说，当数据写入时发送INSERT MQ，数据更新时发送UPDATE MQ，如果UPDATE MQ先于INSERT MQ到达目标系统，目标系统可能会基于一个不存在的数据记录进行更新操作。这会导致以下几种情况：</p><p><strong>数据丢失</strong>：如果目标系统没有处理UPDATE MQ中提到的数据记录（因为该记录尚未通过INSERT MQ创建），则更新操作会失败，可能导致数据变更丢失或遗漏。</p><p><strong>数据覆盖</strong>：在高频修改的情况下，频繁更新可能会面临旧数据覆盖新数据的风险，比如UPDATE MQ携带的是旧数据且先于新数据的UPDATE MQ到达。</p><h3>3.2 业务风险分析</h3><p>MQ乱序对数据迁移和同步过程的影响是深远的：</p><p><strong>数据一致性受损</strong>：最直接的影响是数据一致性受损。目标系统中的数据可能与源系统不一致，导致业务决策基于错误的数据。</p><p><strong>用户体验下降</strong>：数据不一致可能导致用户看到错误的信息或遇到功能故障，从而降低用户体验。</p><p><strong>业务中断</strong>：在严重的情况下，数据不一致可能导致业务中断或系统故障，影响企业的运营和声誉。</p><h2>4. 解决方案</h2><p>为了解决这个问题，可以采取以下措施：</p><h3>4.1 顺序消息</h3><p>消息顺序性保证：虽然Kafka不保证全局消息顺序，但可以通过合理的分区策略和消息键来确保同一账单的消息被发送到同一个分区，从而在一定程度上保证消息的顺序性。</p><p>比如RocketMQ支持顺序消息。但是需要注意这是局部有序，非全局后续。具体实现过程：</p><p>1.发送mq消息时，通过selector将同一个业务主键的消息，发送到同一队列中</p><p>2.消费方使用MessageListenerOrderly消费局部有序的消息</p><p>该方案需要发送方和消费方同步改造。</p><p>生产侧：</p><p>﻿<img referrerpolicy="no-referrer" src="/img/remote/1460000047458919" alt="在这里插入图片描述" title="在这里插入图片描述"/></p><p>消费侧：</p><p>﻿<img referrerpolicy="no-referrer" src="/img/remote/1460000047458920" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><p>﻿</p><h3>4.2 前置检测</h3><p>•在消费者处理消息之前，进行前置条件检查。例如，可以查询一个消息辅助表，确保上一个消息已经被成功消费或存入死信队列中。这种检查可以确保消息按照正确的顺序被处理。</p><p>•另一种方法是，在消息中添加序列号或时间戳，并在消费者端进行验证。如果当前消息的序列号或时间戳不符合预期顺序，则暂停处理并等待正确的消息到达。</p><h3>4.3 状态机</h3><p>在消息处理系统中，状态机可以用来定义和处理消息的顺序。每个状态代表系统当前所处的特定条件或阶段，而状态之间的转换则是由接收到的消息触发的。当系统接收到一个消息时，它会检查当前的状态和消息类型，然后决定是否要转移到另一个状态并执行相应的动作。</p><p>对于消息乱序问题，状态机可以通过以下方式解决：</p><p>1.<strong>定义状态转换规则</strong>：首先，需要定义一套明确的状态转换规则。这些规则应该基于业务逻辑来确定，以确保消息按照正确的顺序被处理。例如，如果系统要求先处理事件A再处理事件B，那么状态机就应该在接收到事件A后转移到能够处理事件B的状态。</p><p>2.<strong>状态检查与消息缓存</strong>：当系统接收到一个消息时，它会检查当前的状态是否允许处理该消息。如果当前状态不允许处理该消息（即消息的顺序不正确），则可以将该消息缓存起来，等待状态机转移到正确的状态后再进行处理。</p><p>3.<strong>状态转移与消息处理</strong>：一旦状态机转移到正确的状态，它就可以处理缓存中的消息。这可以确保消息按照正确的顺序被处理，即使它们最初是以乱序到达的。</p><h3>4.4 监控与报警</h3><p>建立系统的监控和报警机制，及时发现并处理消息错乱等异常情况。</p><p>通过采取以上措施，可以大大降低账单还款系统中消息错乱导致的问题，提高系统的稳定性和用户体验。</p><h2>5. 小结</h2><p>MQ消息乱序是分布式系统的常见难题，影响系统稳定性和业务一致性。本文深入解析问题根源，探讨了顺序消息、前置检查、状态机等实战解决方案，为实际开发中的问题解决提供有力参考。</p><p><em>文章中难免会有不足之处，希望读者能给予宝贵的意见和建议。谢谢！</em></p>]]></description></item><item>    <title><![CDATA[DORA 2025：AI 能力模型与软件研发效能成熟度路线图 PM老周 ]]></title>    <link>https://segmentfault.com/a/1190000047458921</link>    <guid>https://segmentfault.com/a/1190000047458921</guid>    <pubDate>2025-12-08 18:07:06</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <blockquote>在前一篇文章中，我们通过分析 DORA 2025 报告的七类团队画像，帮助企业识别不同团队在 AI 研发效能提升中的位置。本文将深入探讨 DORA 2025 提出的 AI 能力模型，并结合企业的实际情况，构建一个 软件研发效能成熟度路线图，为中高层管理者和 PMO 提供一套分阶段实施的可行方案，确保 AI 投资能够稳定、持续地提升研发效能。</blockquote><h2>从“能力模型”到“成熟度路线图”：理解 AI 研发效能的系统性</h2><p>DORA 2025 报告强调，AI 是放大器，而非万能钥匙。这意味着 AI 不会自动修复组织中的问题，而只是放大已有的优势或短板。这一观点对于很多企业来说，尤其是中国本土企业，具有特别的现实意义。在我与众多企业合作的过程中，我发现很多公司过于依赖工具的引入，而忽视了自身能力基础的建设，导致 AI 在实践中的效果远低于预期。</p><p>DORA 2025 提出的 AI 能力模型 直接回应了这一挑战。它帮助团队从技术基础、流程治理、数据管理等多维度进行自我评估，确保 AI 的引入能够获得实实在在的效益。</p><p><strong>本节小结：</strong>如果你希望通过 AI 获得长期、稳定、可持续的研发提升，就必须先评估自身是否具备“承载 AI 的能力基础”。AI 能力模型，正是量化这个基础的标准。</p><h2>DORA 2025：AI 能力模型的七项关键能力</h2><h4>1. AI 能力模型的框架</h4><p>DORA 2025 提出的七项关键能力涵盖了 AI 成功实施的各个维度，从技术能力到流程管理，再到团队文化和组织结构。这些能力是实现 AI 研发效能的基础，缺一不可。</p><ol><li>明确且已共识的 AI 立场：团队和组织对 AI 的使用政策、目标、权限和控制有清晰的共识。只有当组织全员理解并支持 AI 立场时，才能有效避免冲突和内耗。</li><li>健康的数据生态系统：数据是 AI 的基础，数据治理的规范化、数据质量的提升至关重要。拥有干净、结构化、规范化的数据系统，是确保 AI 提高研发效能的前提。</li><li>AI 可访问的内部数据：AI 工具应能安全访问内部数据系统，包括代码库、文档、知识库等，才能在实际工作中产生真正的效能提升。</li><li>稳健的版本控制与变更管理实践：AI 带来的变更往往更加频繁和大规模，因此在引入 AI 后，确保版本控制和变更管理的稳定性至关重要。</li><li>小批量 / 小颗粒度工作模式：AI 有助于减少传统开发中的大规模变更，通过小步快跑、频繁提交、快速反馈等方式，降低交付不稳定性。</li><li>以用户/价值为中心的优先级与决策机制：团队要始终以用户和产品的实际价值为导向，优先处理最能为用户创造价值的工作。</li><li>高质量内部平台与基础设施：包括 CI/CD 流水线、自动化测试、合规性检查、监控等基础设施，这些系统必须支持快速部署、回滚以及 AI 工具的无缝集成。</li></ol><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047458923" alt="图片" title="图片"/></p><p>我曾多次遇到这样的情况：企业投入了大量的资金购买 AI 工具，并在各个团队中进行推广，然而效果却远不如预期。核心原因在于：工具本身并不决定研发效能，反而是组织的整体能力决定了工具能否发挥真正的价值。</p><p>AI 能力模型的七项能力，正是帮助团队和组织诊断并逐步完善这一能力基础。通过逐步构建这些能力，组织可以确保在 AI 的辅助下，团队效能与研发效能能够持续提升。</p><h2>AI 研发效能成熟度模型：分阶段实施的可行路径</h2><h4>1. AI 研发效能的成熟度分阶段</h4><p>DORA 2025 提出了四个阶段的 AI 研发效能成熟度模型，帮助企业通过阶段性实施，逐步提升 AI 能力和研发效能。每个阶段都有明确的目标与关键行动，确保企业能够稳步推进 AI 的应用，并在实践中积累经验。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047458924" alt="图片" title="图片" loading="lazy"/></p><h4>2. 为什么需要分阶段实施？</h4><p>企业在引入 AI 的过程中，往往会急于追求技术突破和快速见效。然而，技术本身并不会自动解决组织中的复杂问题。分阶段实施成熟度模型可以帮助企业避免盲目加速，同时确保在每个阶段有充分的准备和基础支撑，避免技术落地后的风险。</p><h4>3. 管理层注意事项：</h4><p>从基础开始：从 Level 0 到 Level 1，团队首先需要搭建起稳定的研发基础设施，解决流程瓶颈。</p><p>逐步引入 AI 工具：在 Level 1 和 Level 2 阶段，逐步引入 AI 工具，并将其与已有的开发流程深度融合，保证稳定性。</p><p>强调协同与文化建设：到达 Level 3 阶段时，企业的核心是推动组织文化的变革，确保 AI 工具和团队协作能够无缝结合，实现系统化的研发效能提升。</p><h4>4. 如何落地实施？</h4><p>Level 0 → Level 1：打好基础：重点建设团队基础设施（版本控制、自动化测试、CI/CD 流水线），并为 AI 引入打好基础数据管理和安全权限架构。</p><p>Level 1 → Level 2：工具引入与集成：根据团队画像分析，选择合适的 AI 工具，逐步引入 AI 助手（如代码生成、测试工具、需求分析等），提升研发和交付质量。</p><p>Level 2 → Level 3：全面优化与智能化：整合 AI 进产品设计、需求分析和决策过程中，借助 AI 推动更智能化的产品优化和创新。</p><h2>如何进行组织和团队的 AI 能力评估？</h2><p>为了评估团队的 AI 能力，可以从以下几个维度进行自我诊断：</p><ul><li>AI 立场：团队是否已经达成对 AI 使用的统一认识，是否有明确的使用政策和审批机制？</li><li>数据治理与访问：数据是否结构化，能否方便地接入 AI 工具进行分析？</li><li>平台与基础设施：团队是否具备支持 AI 工具顺利运行的平台和基础设施？</li><li>协作与文化：团队的文化是否支持 AI 的顺利引入，是否具备自我学习和持续优化的能力？</li></ul><p>评估结果将帮助管理者确定当前阶段所在，并制定符合团队实际情况的实施路径。通过分阶段实施，管理者能够清晰地定义每个阶段的目标与行动步骤，确保 AI 工具的引入能够与组织的成熟度相匹配。</p><p>在 DORA 2025 的框架下，我们可以看到 AI 研发效能的提升是一个复杂而渐进的过程。通过明确的 AI 能力模型 和 分阶段的成熟度路线图，团队能够有效地避免盲目跟风，确保 AI 投资能在团队的具体需求下发挥最大价值。</p><p>对于管理者而言，AI 研发效能不仅仅是工具问题，更是组织能力建设和文化变革的系统工程。在 AI 技术日新月异的今天，只有坚持从能力提升和流程优化入手，才能确保 AI 对研发效能的持续增值。</p><p>在下一篇文章中，我们将进一步探讨 AI 驱动的价值流管理与端到端研发效能提升实践，并展示如何将 AI 与价值流管理（VSM）结合，打造具有可持续竞争力的研发体系。</p><p>敬请期待：《DORA 2025：AI 驱动的价值流管理与端到端研发效能提升实践》</p>]]></description></item><item>    <title><![CDATA[【有搜必应】HarmonyOS TOP5热搜技术问题解析第四期 鸿蒙百晓生 ]]></title>    <link>https://segmentfault.com/a/1190000047458951</link>    <guid>https://segmentfault.com/a/1190000047458951</guid>    <pubDate>2025-12-08 18:06:19</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <blockquote>本文原创发布在<a href="https://link.segmentfault.com/?enc=JM6Ro0BiQDxpjAA9gKUHCw%3D%3D.UEPP7TitWsxosLK%2FM5Z8pxnq1cR88llAYs5Yr%2BRJLlMx%2FtTHlwepHbl7eXqEhTG%2BwdzqKprlZN44PtNTq%2F36uVw%2BWtTrqs4T4CTk0Giz0bmNLAQYd5GLMBF%2BCHVqcWix" rel="nofollow" target="_blank">华为开发者联盟社区</a>，欢迎前往与更多开发者进行互动。<br/>更多相关问题可点击原帖进行交流：<a href="https://link.segmentfault.com/?enc=jWXlBhrLzwKuUb0V2EX0Fw%3D%3D.Uu0L%2BjaPOiJaP8eTToCi1H%2F3TY6HeKSbgQtlj8RNhogaNtMyqBeo5hXEBmGYx6QSwSYc2hZaG9ar%2F9NfFdO%2F%2BULJuzmzpqR4EE%2BMdShYjQtlqjMXwpNWqNZP5eaoFb1Hg2H83PvXEiKkJdOT1LA3%2BPhDFHZH3O10dFShh41PEWYV7jOJs%2FBr6cTDigvNIh1Q" rel="nofollow" target="_blank">【有搜必应】HarmonyOS TOP5热搜技术问题解析第四期</a> 。</blockquote><h4>本期热搜揭秘：</h4><p><a href="https://link.segmentfault.com/?enc=tR2C3YLKtDG17mnQf60PMw%3D%3D.dEFge1O6mt9oLeesT2bADJ4vAnNLCIS80YNIYQn%2FOpMFUwjpIQOd0VsjYG%2B5kruHB0TsCAnHYc0Ag7aNL3qx6%2FlVD1e3lv%2B7zOnmLgdsqDxuiMYamV8whYnCDrjipV0X372S%2BURj%2B1L0zgU1M1kPBw%3D%3D" rel="nofollow" target="_blank">【编译工具】打开工程结构为空，且编译报错hvigor ERROR: 00308002 Operation Error</a></p><p><a href="https://link.segmentfault.com/?enc=DI40fmLmJNAZtMcF3xpF6g%3D%3D.BNhn%2F%2FUOJAYr9whyox%2Fe0hONOfS7fhbesJvVl050MkWwNUd%2B%2Bd07feytDaKxmg1y6thssX971Dp0c9DaHYduSR8NIDfkLWxIrZU8J%2BDf5IYKvpRBgXYDq3t4jHIqWDNWohig1oTXEeEb%2BhsjxvHJZQ%3D%3D" rel="nofollow" target="_blank">【编译工具】DevEco Studio 中使用 sys.media 图标报红问题解析</a></p><p><a href="https://link.segmentfault.com/?enc=N12RYIzNVLJ%2FcZZ8NBb7XA%3D%3D.RIN5jwBWhZmasgXOs3vDOvQCcdEBJuEeAjUi9CbPtZ2Y1lNZxxCwFGT14Ww%2F2oqnFd7ZIMTgJR8WFDs8ECft4Mlop6z7PuqUaRLH9BqJGvooAF98eoIc2cSe27HxUY0dsuZ2RogN%2BzN94LvvotIxRb4kD64FHlMtsefEFb7BXwbnvWJt3i56BYbyd%2FmJEoRq" rel="nofollow" target="_blank">【ArkUI】如何在其他组件或者模块中得到windowStage并使用getMainWindow()方法</a></p><p><a href="https://link.segmentfault.com/?enc=F5Pswk8Rve%2BkYkrr0%2Bkr5w%3D%3D.OtTGJM0ji8bnlLDfjsKbcE%2Fz5%2FZXQjoKcYgQQe%2FlFmpEr7wx6vzUxey0ONZm5ZBJoSIk7LSTFK8rFI5at8ENCUHPb7yrSdOe3NmIw%2BMAFY4JaKfC9ya7xKwVPMtHVY1AlYMt0xj%2FCInbeuY6Mkn%2Bb5utOzMQLpdCRYw8MXpSbCPMAHOzBy9%2FfZz2bUQso5EV" rel="nofollow" target="_blank">【ArkUI】V1装饰器如何迁移至V2</a></p><p><a href="https://link.segmentfault.com/?enc=T9%2B1oSsq7RGGt%2FiJHaIZ3Q%3D%3D.1aPNb3qsjdw%2BLAdTbEqkOsHJ2tVLFBlycjeqa5E%2B5Id2lZONXirngD8kpnMAHb6ZycHd7UjffDrtYRHiV2%2FhPNH03HAB%2BjcuextNb7uwoUJNOXGHmwVOlyg37vmyT%2FPErkCY%2F%2BVJUwPStVNuDPj7YJKFzlqrOhQj4qjaup2CToMnVjgLjgBHjJCfWFgNAhpW" rel="nofollow" target="_blank">【媒体&amp;图形】如何将图片保存到本地相册</a></p><p>期待您在论坛中继续发声：无论是提出新的疑惑、发表见解、或分享实战经验，都会为鸿蒙社区注入前行的力量，也是让我们做得更好的动力！若您存在疑惑，可使用社区-问答-"我要提问题"进行提问。<a href="https://link.segmentfault.com/?enc=qnQBQ4IQnQvzlt%2F0vyK%2F4w%3D%3D.%2Fh%2BMOdjvKK8IOgmICGrxoc%2BY6CHJdgfT8N%2Fc797V3xSXh1uqB0qh5nGtUva7GulWHJwF%2BNcl7vOIpkQ3KfdcI4QEYSIScylY4j52i8hPgmvCNguTVXD6g%2FEeS9SR98DL" rel="nofollow" target="_blank">问答专区-华为/鸿蒙开发者论坛</a></p><h4>往期问题回顾：</h4><p><a href="https://link.segmentfault.com/?enc=38FSC30g1u7wXBkhd2h47Q%3D%3D.oje%2BOOXSofmR48zXPzJ5hKv31N%2FjW3gwFYO3fKUXhLqP2LtIIYh%2FjAFWgE0i2q8WpPtk3E5T%2Fqbz4lYtzZzV4dIG1gJCwprjmU10%2BsclczbZnGbI1DIL9bFc3rf4KR%2FKoO7m3gcaY3fJkvALqDXKblZSycaAIvxyCbi%2BeLQsVhSzxdC4jup1VyUO33DHTNds" rel="nofollow" target="_blank">【有搜必应】HarmonyOS 热搜技术问题解析第一期</a></p><p><a href="https://link.segmentfault.com/?enc=CIMrvETCM6JXRIYqkp74fg%3D%3D.DLn5y5jqGaAiQPmOVxSXKYUhOZ%2B%2FTMY9ecmAHdJao5SmedRxNZXCX4LZ%2B66gIxRT0ibl%2FVMURfCmxVcRg7Cr3bJa82g4ebeTF71oHBaIiOKe1J7YQo4NT86EBDnDiA6CZkF5sgCMqSLpbrMM7NdRo951kwEVuvmaRmREpZlrzxKJTBWEnpbZZCQodVu9Tf%2Ba" rel="nofollow" target="_blank">【有搜必应】HarmonyOS 热搜技术问题解析第二期</a></p><p><a href="https://link.segmentfault.com/?enc=fvBHgfHwwaEookVPBY%2BpUg%3D%3D.5A7RzqtTbPlx6bzHxbuEvBxK9k0NlXHzdaKO3THVgbF56sVkYmtk%2FgvZfkjoQEp3Pv%2BDlR2%2BcD983n3bm%2FMlZFTLWY9mw6PFaQmQANk71Rx8EtLTpslKSc7im6cBGvZlC8pUjxwsURWR097ii9Jgpd%2Fb%2BpuyIlDrVeGCr4bM574kmVBfUAL23n8SlC3lolsd" rel="nofollow" target="_blank">【有搜必应】HarmonyOS 热搜技术问题解析第三期</a></p>]]></description></item><item>    <title><![CDATA[【有搜必应】之HarmonyOS热搜技术问题解析 系列汇总（持续更新中...） 鸿蒙百晓生 ]]></title>    <link>https://segmentfault.com/a/1190000047458981</link>    <guid>https://segmentfault.com/a/1190000047458981</guid>    <pubDate>2025-12-08 18:05:46</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <blockquote>本文原创发布在<a href="https://link.segmentfault.com/?enc=gnUXn%2FdszOFkWpoeF89Nzg%3D%3D.Vj36AgbqAy6kL9RWFnTtzy%2BUUcxXZtpS%2F7AUQyM2MoNI30VAAxd5Pjs9rtx7cPhd58XkoC9B6AaueOVtEP4sOJ6KuIyvKWiCS%2FHfl2IDt3mh%2BFL32V%2Fh73EEsxVcSxlI" rel="nofollow" target="_blank">华为开发者联盟社区</a>，欢迎前往与更多开发者进行互动。<br/>更多相关问题可点击原帖进行交流：<a href="https://link.segmentfault.com/?enc=2SEct2sF%2FljoiPUEvH7m4Q%3D%3D.Cy56ahsuiyfZGDNlFbCq8SsbMqNVsJg6V9QF0sQ6968y7nXGV4JjL0%2BQPzdn3LoMNGOhv6cxdBSyDVdH7nZi66S0YOHZgzcnXdpTS%2FhlbxnHpBMZlsFuPpFA1GtBfuIaK5oBTIVEtnvRsrn25QJ5p2u2%2BxByoz72A1gnUpcWSVi13xAUzbG4QUR0vtoD8XZP" rel="nofollow" target="_blank">【有搜必应】之HarmonyOS热搜技术问题解析 系列汇总（持续更新中...）</a> 。</blockquote><p>HarmonyOS开发者小伙伴们，每一个热索词的背后，都是您最迫切的技术问题诉求与最真实的痛点；每一个热搜词的背后，更代表了众多开发者遇到的共性难题。为助力大家扫清Top开发障碍，我们选取了社区高频的热搜问题，进行深入剖析，推出《有搜必应》专栏，旨在集中解决共性问题，为大家勾勒一份鸿蒙开发的“热点地图”。在精准定位问题的基础上，我们将提供一份经过验证的解决方案与最佳实践，化热搜问题为能力提升的阶梯，让每一次技术探索事半功倍，助力大家在鸿蒙开发之路上行得更稳、更远。</p><p>在此，我们由衷地感谢每一位热心参与、乐于分享的开发者，是你们的热情与智慧，让这个社区充满了生机与活力，每一次的解答都是对技术探索精神的最好诠释。同时，我们也诚挚邀请更多的开发者加入到这场智慧碰撞的盛宴中来。无论是抛出难题寻求解答，还是慷慨解囊分享经验，您的每一份参与都将为鸿蒙开发者社区注入新的活力，推动我们共同前行，在技术的海洋中扬帆远航。</p><p>请持续关注我们的《有搜必应》系列帖，我们会定期更新内容，助开发者一臂之力。让我们携手共进，共创鸿蒙开发的辉煌未来！</p><h4>链接直达问题详情及解析：</h4><p><a href="https://link.segmentfault.com/?enc=NMe%2B0tCSVrQe9eYkhv1Piw%3D%3D.YzwKdxMUH0tTnyxSipR1jLRo7emNigWWlqdXiB9NZZW9DF330QICOXuQZUcSUzhPIZv%2BumbV3anguc1%2B3aaLl%2FxzWelQB5j%2B7sLQ28aUzAhpZfV0POemKbplc9WYxy0gYSDEMVvslP7Mmt8dn6GbTUXwv0mmgp2Ab5ryvrjhoes6lA2pmdtM4hTlmo0RxVV3" rel="nofollow" target="_blank">【有搜必应】HarmonyOS 热搜技术问题解析第一期</a></p><p><a href="https://link.segmentfault.com/?enc=ISNRjdKkJFiyq%2FbjnRcNVQ%3D%3D.ULfPFs3Mp5q2tVs714%2BjqCTt8YaDled4h3pbUbzcDI3EVVnhK4k7r9NuegpSBO7tMNmQ1ICcw4UGeTEQyiLdGr5dFIuZaDVwAZBRKwuSpGSkOHkhDzOsVSASzioa9YwUCyR5UkIJqZ8pHs1PiLRanBfk0hK8CSr0N1maDn9hrZDuld8qeofF2sv3z5qDWvZV" rel="nofollow" target="_blank">【有搜必应】HarmonyOS 热搜技术问题解析第二期</a></p><p><a href="https://link.segmentfault.com/?enc=CxwGLGkfdcULWh8UUOxrgA%3D%3D.%2FdttsTyY1oTKVIQMBu%2FPfdL2kInjBm3w%2F9zLjJ4k%2B63cs98pekxtQt0PRpTpKyiIh3GDvHpS2C4qOoH0vkx6BN6QG82UlDyUujdYjGVyBcKReQl%2FFpnkhngDvfcqYT1BHcKQhqAX1R3wxWDRjdMFxAN50XtNtFrnSzr9r0JN9e6JDtqQC0bbOLGOn6XOqEiS" rel="nofollow" target="_blank">【有搜必应】HarmonyOS 热搜技术问题解析第三期</a></p><p><a href="https://link.segmentfault.com/?enc=Uc3cH7EJkO0qKMoW4x8hnw%3D%3D.Xp5JMiXI4fV4aXfTU0a5m6msYhsiPxhNJat4qjLUToSYjL87q1YjseFy%2BNrZ74iwwlvoFXMRekezUNrYxxeNm2aGyuMBts5UFHCIAt2SY8emZ1KG3R7PfXZuOqmKZmutJ%2BOKzEwT%2Fhs2eN%2B5Cd6tL4emi2Nw8Hp6P8bSOJzPUrV0ki9iS%2FZ5SFrZK81z5956" rel="nofollow" target="_blank">【有搜必应】HarmonyOS 热搜技术问题解析第四期</a></p>]]></description></item><item>    <title><![CDATA[从“是什么”到“为什么”：Aloudata Agent 智能归因的底层逻辑与配置指南 Aloudat]]></title>    <link>https://segmentfault.com/a/1190000047458988</link>    <guid>https://segmentfault.com/a/1190000047458988</guid>    <pubDate>2025-12-08 18:05:07</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>当数据看板上销售额那条红色曲线突然掉头向下时，业务主管的第一反应不再是手忙脚乱地召集数据分析师会议，而是转向电脑屏幕，平静地输入一个最直接的问题：“为什么？”</p><p>面对海量指标波动、业务异常或营销效果变化，分析师往往只能回答“发生了什么”（What），却难以深入解释“为什么会这样”（Why）。这种从“What”到“Why”的鸿沟，正是 Aloudata Agent 智能归因功能试图解决的核心问题。</p><p>Aloudata Agent 是 Aloudata 推出的一套分析决策智能体，将 NoETL 明细语义层作为数据底座，以指标为中心进行语义一致的对话式数据分析。通过自然语言即刻获取数据结果，支持智能数据结果解读，以及智能多维归因和因子归因分析，让企业深层次洞察异常数据波动原因。</p><p>本文将深入剖析 Aloudata Agent 智能归因的底层逻辑，并提供一套实用的配置指南，帮助用户真正实现从“是什么”到“为什么”的跃迁。</p><p>01 智能归因：从数据报表到决策引擎<br/>传统 BI 工具擅长展示数据的当前状态和历史趋势，但当业务人员看到指标异常时，仍需依赖经验猜测，或向数据团队提出新的分析需求，这个过程缓慢且低效。</p><p>Aloudata Agent 的智能归因功能，让每一次数据波动分析都具备可组合、可追溯、可解释、可复用的业务价值，真正赋能企业在复杂数据环境中做出敏捷、精准、可执行的决策。</p><p>现代企业面临的数据环境日益复杂，指标间的关联性不断增强。单个业务指标的波动往往由多个维度、多个因子共同作用导致。智能归因系统能够穿透数据表象，在多维业务空间中精准定位问题根源，将数据从静态报表转化为动态决策引擎。</p><p>02 技术基石：NoETL 指标语义层如何支撑可信分析<br/>Aloudata Agent 智能归因功能的核心支撑是其独创的 NoETL 指标语义层。这一技术架构解决了企业数据智能分析中长期存在的“数据幻觉”、口径不一致和灵活性不足等痛点。</p><p>与传统数据分析架构不同，NoETL 指标语义层在物理数据层和应用层之间构建了一个逻辑语义层，系统化管理指标、维度、业务计算逻辑及指标间的血缘关系。</p><p>这张“业务地图”为智能归因提供了统一的语义理解基础，确保不同用户对同一业务概念的理解完全一致。</p><p>当用户进行归因分析时，大模型首先借助语义层理解用户意图，将其转换为包含指标、维度、过滤和时间查询等规范的标准查询请求（MQL），再转化为 100% 准确的、可执行的 SQL 语句。</p><p>这种“NL2MQL2SQL”的技术路径与传统的“NL2SQL”或“NL2DSL2SQL”相比，从根本上保障了分析的一致性与准确性。</p><p>指标语义层在企业数据分析中扮演三大关键角色：一是消除“大宽表依赖”，支持灵活的维度归因下钻；二是沉淀计算逻辑，赋能大模型识别因子关系；三是依据指标类型，智能匹配贡献度算法。</p><p>对于“销售额=客单价×客户数”这样的复合指标，语义层明确定义了计算逻辑，使系统能自动识别指标间的计算关系，并将变化归因于相应因子。</p><p>03 双路径归因：维度拆解与因子追溯的精准诊断<br/>Aloudata Agent 的智能归因功能通过双路径归因框架实现多维度、多层次的根因洞察。这一框架包括维度归因和因子归因两条互补路径，分别从不同角度揭示数据波动的本质。</p><p>维度归因专注于识别影响目标指标变化的关键业务维度，如渠道、区域、品类、门店等。系统通过维度下钻与贡献度计算，量化各维度对整体变化或差异的贡献权重，帮助用户锁定问题焦点。例如当某电商企业发现“ 618 销售额下降”时，Aloudata Agent 通过维度归因识别出两大主因：直播渠道转化率下降 15%、客单价减少 8%。</p><p>因子归因则聚焦驱动目标指标变动的关联因子指标，通过指标间的计算逻辑与影响路径，识别哪些前置因子的变化是导致最终结果差异的根本动因。对于复合指标（如销售额=客流量×转化率×客单价），因子归因能追溯其构成要素的变化，提供更具操作性的改进方向。</p><p>为了全面覆盖业务分析场景，Aloudata Agent 将归因分析需求归纳为四象限场景矩阵，包括“维度归因x时间波动”、“因子归因x时间波动”、“维度归因x同类对比”和“因子归因x同类对比”。</p><p>这种设计确保企业无论面对时间序列波动还是实体间差异，均能快速定位根因。</p><p>04 场景实战：从数据异常到业务决策的闭环分析<br/>以连锁餐饮品牌 A/B 门店业绩差距分析为例，当用户提出“A 门店销售额比 B 门店高 20%，原因是什么？”时，Aloudata Agent 首先进行维度归因，自动拆解至客群结构、促销策略、店员配置等维度，发现 A 门店外卖订单占比高 23%、B 门店高峰时段等位时长多 12 分钟。</p><p>接着进行因子归因，进一步分析构成因子，识别出 A 门店的“外卖客单价”比 B 门店高 15 元、“高峰时段翻台率”低 0.3 次/小时。</p><p>基于这些分析，最终生成策略建议：B 门店优化外卖菜单设计提升客单价，A 门店增加高峰时段人力提升翻台率。整个过程无需数据工程师预处理数据，业务人员通过自然语言交互即可完成分析。</p><p>另一个典型场景是汽车企业分析“毛利率下降”。Aloudata Agent 通过因子归因计算出：原材料成本上涨贡献 60% 影响、生产效率降低贡献 30% 影响。</p><p>进一步拆解发现，原材料成本上涨源于钢材价格波动，而生产效率降低则与生产线故障率上升直接相关。这种层层下钻的分析方法，使企业能够精准定位问题根源，而非停留在表面现象。</p><p>05 配置与实践：构建企业专属的智能归因体系<br/>要充分发挥 Aloudata Agent 智能归因的价值，企业需要系统性地进行配置与落地。这一过程可以分为数据准备、语义构建、场景适配和知识沉淀四个关键阶段。</p><p>首先，企业需要将数仓中的 DWD 层数据接入 NoETL 明细级语义层，标准化定义基础指标和维度。这一步确保数据源的完整性与准确性，为后续分析奠定基础。例如，仅需定义“销售额”这一基础指标，系统便能支持用户围绕时间趋势、渠道分布、品牌表现等多种维度进行灵活查询和分析。</p><p>其次，企业应基于业务逻辑构建指标间的计算关系和因子树。对于 GMV 这样的复合指标，需要在语义层明确定义其计算表达式（如“GMV=客单价×客户数”），使系统能够自动识别和利用这些关系进行因子归因。</p><p>同时，针对比率型指标（如折扣率、利润率），需要配置相应的贡献度算法，以准确计算各维度对变化的具体贡献。</p><p>在场景适配方面，Aloudata Agent 支持创建场景化智能分析助手，如财务分析助手、人资数据助手、区域经营数据助手等。</p><p>每个助手可配置独立的资源管理，确保信息隔离，避免跨业务领域的数据干扰。这种设计让不同业务角色能够更直接地获取所需数据结果和分析报告。</p><p>最后，知识沉淀是确保智能归因持续优化的关键。Aloudata Agent 支持用户维护个人术语知识和分析思路，并将打磨好的报告保存为模板，将个人分析框架转化为团队可复用的数字资产。</p><p>06 核心优势：智能归因如何重塑企业决策逻辑<br/>与传统的归因分析方法相比，Aloudata Agent 的智能归因展现出多维度优势，这些优势共同重塑着企业的数据决策逻辑。</p><p>它解决了传统方法中常见的“指标口径不一致”问题。基于统一的指标语义层，无论谁提问、如何提问，指标的计算口径始终保持一致。这种一致性对于跨部门协作和长期趋势分析至关重要，避免了因口径差异导致的决策偏差。</p><p>智能归因提供了传统方法难以实现的分析灵活性。用户可自由选择分析维度，系统自动检索指标与维度，生成对应的归因查询，无需依赖预先生成的大宽表。这种灵活性使业务人员能够根据实际需求动态组合维度，快速定位影响指标变化的关键因素。</p><p>在查询性能方面，智能物化加速和查询路由改写技术保障了海量数据查询的秒级响应，即使面对百亿级数据，也能稳定产出分析结果。这种性能优势使实时决策成为可能，大幅缩短了从数据异常到行动干预的时间窗口。</p><p>安全可控是智能归因的另一重要优势。基于指标权限管控和行列级数据权限配置，系统能够保障数据查询的安全可控。在归因分析过程中，系统会动态验证用户是否具备访问相关指标及行级数据的权限，确保数据安全合规。</p><p>07 未来演进：智能归因在企业智能化转型中的角色<br/>面向未来，智能归因将与更多的 AI 能力融合，形成更强大的分析决策智能体。Aloudata Agent 已在这方面进行了有益探索，通过“智能融合报告”功能，将归因分析结果自动整合到结构化报告中，生成包含趋势图表、归因结论、文本解读和策略建议的可执行洞察。</p><p>更关键的是，Aloudata Agent 智能融合报告”功能允许分析师自定义报告结构与章节逻辑，将个人分析方法论沉淀为团队可复用的数字资产。这种知识沉淀机制使企业的分析能力不再依赖个人经验，而是转化为可持续迭代的组织能力。</p><p>随着技术发展，智能归因有望实现更高级的预测性分析。基于历史归因数据和业务知识，系统不仅能解释已发生的波动，还能预测潜在风险，提前预警并给出预防建议，真正实现从“事后归因”到“事前预防”的转变。</p>]]></description></item><item>    <title><![CDATA[人才盘点分析解决方案：助力企业精准识才，实现人岗高效匹配 容智信息 ]]></title>    <link>https://segmentfault.com/a/1190000047459005</link>    <guid>https://segmentfault.com/a/1190000047459005</guid>    <pubDate>2025-12-08 18:04:20</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459007" alt="图片" title="图片"/><br/>在人才竞争日趋激烈的市场环境下，企业的人力资源管理正面临前所未有的挑战。某高速成长的科技企业人力资源负责人对此感触颇深：“我们每天需要处理数百份来自不同渠道的简历，但招聘效率却不尽如人意。更关键的是，即便人才入职后，我们也缺乏系统化的方法来评估其真实潜力，导致内部晋升和转岗决策常常依赖管理者的主观印象。”这家公司的困境并非个例。在传统人力资源管理模式中，简历筛选耗时耗力、人才评估标准不一、内部人才透明度不足、人岗匹配度难以量化等问题，已成为制约许多企业组织效能提升的普遍难题。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047459008" alt="图片" title="图片" loading="lazy"/><br/>为系统化解决这些痛点，该公司开始寻求人力资源管理的数字化转型路径。经过多方评估，他们引入了一套智能化人才盘点分析解决方案，旨在通过技术手段提升人才管理的精准性与科学性。该解决方案并非简单地替代人力资源专业人员，而是通过结构化数据处理与智能分析能力，为其提供更全面、更客观的决策支持，将人力资源团队从繁琐的事务性工作中解放出来，专注于更具战略价值的人才规划与发展。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047459009" alt="图片" title="图片" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459010" alt="图片" title="图片" loading="lazy"/><br/>过去，该公司的招聘团队需要手动处理大量不同格式的简历文件，平均每个岗位的初步筛选需耗费1-2个工作日。引入新系统后，情况发生了显著变化。具体应用：系统通过自然语言处理和文档解析技术，能够自动识别并提取简历中的关键信息，包括教育背景、工作经历、专业技能、项目经验等，并将其结构化存入统一的人才数据库。量化成效：原来需要3天完成的300份简历初步筛选工作，现在可缩短至2小时内完成。系统还能根据预设的岗位要求，自动生成包含匹配度评分的候选人短名单，使招聘专员能够快速聚焦于最合适的潜在人选，将核心岗位的平均招聘周期缩短了约40%。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047459011" alt="图片" title="图片" loading="lazy"/><br/>“我们之前对内部人才的了解往往是片面的、零散的，”该公司人力资源负责人坦言，“不同部门对同一位员工的能力评价可能截然不同。”具体应用：该系统整合了员工的绩效数据、项目经历、技能认证、培训记录等多维度信息，构建出统一、全面的人才数字档案。这些档案不仅包含“硬技能”标签，还通过分析项目角色与贡献，识别出员工的协作能力、问题解决风格等“软性特质”。实际价值：在最近一次内部竞聘中，HR部门利用该系统为三位候选人分别生成了详细的能力雷达图与发展建议报告。这份客观的数据支撑，使晋升委员会的讨论更加聚焦、决策过程更加透明，最终入选者也因此获得了更高的团队认可度。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047459012" alt="图片" title="图片" loading="lazy"/><br/>该公司曾面临一个典型困境：某个关键岗位空缺时，是优先考虑外部招聘，还是在内部寻找有潜力的人选进行培养？决策常常在两难中徘徊。具体应用：系统提供两种核心匹配模式。一是“岗位-人才”匹配：当出现岗位空缺时，可基于该岗位的能力模型，从内外部人才库中寻找匹配度最高的候选人。二是“人才-岗位”匹配：针对特定员工，分析其能力特质与组织内其他岗位的适配度，为内部调岗或职业发展提供参考。典型实例：公司希望为新兴的数字营销业务组建团队。通过系统的“相似人才寻找”功能，以现有优秀数字营销专家为标杆，从内部其他部门发现了两位具备相关潜质的员工，经评估后成功转岗。这一方面快速填补了人才缺口，另一方面也提升了员工满意度，实现了双赢。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047459013" alt="图片" title="图片" loading="lazy"/><br/>实施该解决方案六个月后，该公司在人力资源管理的关键指标上取得了显著改善：招聘效率：核心岗位平均招聘周期缩短35%，简历初筛耗时减少80%；人才匹配度：新入职员工半年内绩效达标率提升22%；内部流动性：内部转岗/晋升比例从15%提升至28%，岗位适应期平均缩短30%；管理决策支持：人力资源数据分析报告产出时间从数天缩短至实时可获取。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047459014" alt="图片" title="图片" loading="lazy"/><br/>“这套系统的价值远不止于效率提升，”该公司人力资源负责人在回顾转型历程时总结道，“它正在改变我们人力资源部门与业务部门的对话方式。我们现在能够基于数据，与业务领导者深入讨论人才结构优化、关键岗位继任计划等战略议题，真正从支持部门转型为战略伙伴。”当前，人力资源管理的数字化转型已进入深水区。领先的企业正从简单的事务自动化，迈向基于数据分析的人才战略规划。这种转变的核心，在于将人力资源管理的重心从“流程与事务”转向“人与价值”，通过精准识才、科学用人，最终构建起持续的组织竞争力。<br/>通过智能化工具赋能，人力资源专业人员得以更专注于理解业务需求、设计发展体系、营造组织文化——这些才是人才管理工作中真正创造差异化价值的部分。在这一进程中，技术始终是手段而非目的，其最终价值体现在帮助组织更好地认识、发展和保留其最宝贵的资产：人才。</p>]]></description></item><item>    <title><![CDATA[「实操看我的」征文：聚焦数据库性能优化，分享你的实战方案 墨天轮 ]]></title>    <link>https://segmentfault.com/a/1190000047459035</link>    <guid>https://segmentfault.com/a/1190000047459035</guid>    <pubDate>2025-12-08 18:03:42</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>9月墨天轮社区举办的<a href="https://link.segmentfault.com/?enc=2dfbv0DMtHZM8pTD6wMrgw%3D%3D.VDY7jSd%2FhDoQBi59YBVnLfv%2BjQieXxNZejRDaFF0L83Vtniriyvv6nm%2BLY3wK6wRzOMjYtcegUxS71cSj%2FTmyg%3D%3D" rel="nofollow" target="_blank">「实操看我的」数据库征文活动</a>，收到了很多DBA分享的故障处理、性能优化、安装部署等数据库实操干货，文章也得到了很多读者朋友的收藏。为了让创作者的干货获得更聚焦的认可，我们决定升级栏目形式，举办「实操看我的」多期不同主题的系列征文活动，每期将聚焦一个DBA高频刚需的技术实操方向，集中征集该主题的实战方案、避坑技巧。当然，您的投稿文章亦可同步参与社区常规月度征文活动<a href="https://link.segmentfault.com/?enc=U1q1Fzt4tHKB9x40L0QyZw%3D%3D.jiQy1vEJweUvSncx2C%2BBjqLxwtzgvesF5WSFmzF%2F9HYUO8TRcV82Xl1KdlYU%2BG6O" rel="nofollow" target="_blank">“墨力原创作者计划”</a>。</p><p>首期主题为——<strong>“数据库性能优化”</strong>，不论是慢查询优化、索引设计、参数调优，还是架构层面的性能突破，只要你有真实场景、完整步骤、可复现的调优经验，都欢迎你来分享！</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459037" alt="" title=""/></p><h2>活动时间</h2><p>11月26日-2026年1月25日 （活动期间每人投稿篇数不限）</p><h2>投稿主题</h2><p>需聚焦您在<strong>数据库日常运维实操中遇到的性能优化场景</strong>，可以是真实生产环境的中的案例复盘、也可以是对某个优化语句的实验验证，总之需要时真实可落地的数据库运维实操。</p><p>以下列举了部分可投稿主题，包含但不限于：</p><ul><li><strong>慢查询优化</strong>：SQL 改写技巧、执行计划分析、索引设计、统计信息维护等</li><li><strong>资源参数调优</strong>：内存、CPU、IO、连接数等核心参数调优等</li><li><strong>架构层面优化</strong>：读写分离、分库分表、缓存穿透 / 击穿解决方案、数据库分片策略等</li><li><strong>特殊场景调优</strong>：高并发秒杀场景、大数据量查询优化、OLAP/OLTP 混合场景调优、国产化系统（麒麟 / 统信）适配调优等</li><li><strong>调优工具实战</strong>：AWR/ASH/Performance Schema/Explain Plan/Percona Toolkit 等工具的使用案例</li></ul><p>数据库类型不限，Oracle、MySQL、PG及国产数据库等均可。</p><h2>参与规则</h2><p>原创文章首发于墨天轮，并带上 “数据库实操” “性能优化” “墨力计划” 三个标签，即算成功参与活动。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459038" alt="" title="" loading="lazy"/></p><p>如您不放心，亦可将投稿文章标题及链接评论于本文评论区、或私信发至墨天轮小助手-小墨（VX：modb666）。</p><blockquote>当您加上“墨力计划”标签则默认同步参与“墨力原创作者计划”，可参与当月墨力计划评奖，点击查看<a href="https://link.segmentfault.com/?enc=i%2FIctdSDX8bYGyG%2F7I5cGg%3D%3D.8HA3JmEI3NE4f2R5tuN76c2p5zeij%2F1A3ZXqsJzXXiNQ71nZNANhLwBWd%2FJ20h5f" rel="nofollow" target="_blank">墨力计划奖励情况</a>。</blockquote><h2>合格及评优规则</h2><ul><li><h3>合格要求</h3></li></ul><ol><li><strong>需包含关键技术要素</strong>：活动侧重实操，需结合真实运维场景，包含调优完整步骤，如“问题现象→原因分析→调优方案→实施步骤→效果验证”；  <br/>（ps：如为运维理念讨论、技术原理分析等非实操类主题无法参与本次特别活动，而属墨力计划常规投稿）</li><li><strong>基础要求</strong>：文章需原创、首发，文章字数不少于 500 字（其中代码占比不可超80%）、阅读量需达100；</li></ol><blockquote>不可为搬运文、流水账、翻译文、广告文或AI代写、刷阅读量，其他要求均同墨力计划，点击查看<a href="https://link.segmentfault.com/?enc=AVB5RDvyD0uhrMHuMkuInw%3D%3D.5EoaNG%2FF0dW3E6YQqp4r3pel5szWAqWdw9u1UPr9nd30jdCJPkC14EQvnmFlJGvh" rel="nofollow" target="_blank">墨力计划参与规则及合格要求</a></blockquote><ol start="3"><li><strong>其他</strong>：建议搭配关键截图（执行计划、监控图表等）、核心代码、性能对比数据等，提升内容可信度与可读性。</li></ol><ul><li><h3>评优规则</h3></li></ul><p>1、<strong>调优干货奖</strong></p><p>将根据问题复杂性、步骤完整度、实操主题借鉴意义等质量维度，以及文章受欢迎维度进行对所有合格文章综合评优，评选出若干篇<strong>调优干货奖</strong>。</p><p>ps：人可投稿多篇，最多可重复获得2篇调优干货奖。</p><p>2、<strong>调优先锋奖</strong></p><p>将对投稿作者合格文章进行评优，综合文章质量、受欢迎程度以及发文数量、优质内容占比等维度评选出 3 名<strong>调优先锋奖</strong>。</p><p>ps：该奖项获得者不可重复获得最佳实操奖。</p><h2>奖项设置</h2><table><thead><tr><th>奖项</th><th>奖项数量</th><th>奖品名称</th></tr></thead><tbody><tr><td><strong>合格奖</strong></td><td>若干篇</td><td>在墨力计划合格奖基础上，可额外获得50墨值+墨天轮优化限定勋章（虚拟）</td></tr><tr><td><strong>调优先锋奖</strong></td><td>3名</td><td>调优先锋限定勋章（虚拟）+实物奖品（依次获得以下单项奖品）：第1名-罗技MK540无线键鼠套装；第2名-倍思10合一拓展坞4K60Hz ；第3名-小米充电宝10000mAh（3C认证）</td></tr><tr><td><strong>调优干货奖</strong></td><td>若干篇</td><td>调优干货限定勋章（虚拟）+实物奖品（以下奖品可二选一）：1、墨天轮定制法兰绒毛毯； 2、墨天轮定制墨天轮logo抱枕</td></tr></tbody></table><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047459039" alt="" title="" loading="lazy"/></p><p>此外所有带有“墨力计划”标签的合格文章均可参与月度墨力计划的奖项评选，主要包括优秀文章奖、墨力之星、新人奖、勤更奖等，奖励包含现金、实物奖品等。</p><ul><li>点击查看<a href="https://link.segmentfault.com/?enc=G4ELcGnACA9gBNVjkwudcw%3D%3D.O9h3rI%2FmDQdHaFpX7iYRrUh%2BOKUb4TNyThiDrG9%2BPlHypnGU7mhDhDC8NVtqeTpjM9jIBa2Ns43rp8VJfYkcUQ%3D%3D" rel="nofollow" target="_blank">本次征文活动原帖</a></li><li>点击查看<a href="https://link.segmentfault.com/?enc=vOnK91ggHk7XkiTzNNifnA%3D%3D.YvJLfmI2EcTOXnZX3yDtwuqB9HArxm8z9bptkHgqHdFEOQZ5bsNvnl3Jx7D%2Fiy96" rel="nofollow" target="_blank">墨力计划奖励情况</a>。</li></ul><hr/><p>欲了解更多可浏览<a href="https://link.segmentfault.com/?enc=SY7XfaU79nA7y%2FP%2FZCIteg%3D%3D.EOokmR3Pzn6pJtIFf%2F7X0keqQ3nv9gBDImpXLAuYrrA%3D" rel="nofollow" target="_blank">墨天轮社区</a>，围绕数据人的学习成长提供一站式的全面服务，打造集新闻资讯、在线问答、活动直播、在线课程、文档阅览、资源下载、知识分享及在线运维为一体的统一平台，持续促进数据领域的知识传播和技术创新。</p><p>关注官方公众号： 墨天轮、 墨天轮平台、墨天轮成长营、数据库国产化 、数据库资讯</p>]]></description></item>  </channel></rss>