<?xml version="1.0" encoding="UTF-8"?><rss version="2.0">  <channel>      <title>SegmentFault - 最近文章</title>      <link>https://segmentfault.com/blogs/newest</link>      <description>SegmentFault 思否</description>      <generator>python segmentfault.py @Pi20</generator>      <item>    <title><![CDATA[苹果企业签名：高效的内部分发解决方案 张]]></title>    <link>https://segmentfault.com/a/1190000047439301</link>    <guid>https://segmentfault.com/a/1190000047439301</guid>    <pubDate>2025-11-30 23:04:21</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在苹果生态系统中，企业签名作为App Store之外的重要分发方式，为企业和组织提供了灵活的内部应用部署方案。这种基于企业开发者账号的签名机制，正在成为众多机构移动化战略的关键支撑。</p><p><a href="ioszf.cc" target="_blank">稳定靠谱签名平台：iOS企业签、超级签、TF签</a></p><p>核心技术原理<br/>企业签名的技术基础建立在苹果的企业级信任体系之上。通过获取苹果官方颁发的企业开发者证书，组织可以对应用进行数字签名，使其能够在未上架App Store的情况下直接安装到iOS设备。这套机制的核心在于企业证书的数字签名验证流程，系统会验证签名的有效性及应用的完整性，确保分发的安全性。</p><p>与个人开发者账号不同，企业签名不需要预先注册设备UDID，这大大简化了分发流程。企业员工只需通过扫描二维码或点击分发链接即可完成安装，极大地提升了部署效率。</p><p>独特优势解析<br/>企业签名最显著的优势在于其分发规模不受限制。一个有效的企业签名可以支持无限次数的应用安装，这使得它特别适合员工数量众多的企业、教育机构或政府单位。无论是数千人的大型企业还是跨地域的集团组织，都能通过这一方案快速完成应用部署。</p><p>另一个重要优势是版本更新的便捷性。当应用需要更新时，开发者只需重新签名并上传新版本，用户再次扫描二维码即可完成更新，无需卸载原有应用。这种无缝升级体验大大降低了维护成本。</p><p>适用场景分析<br/>企业签名在以下场景中表现出独特价值：</p><p>企业内部办公系统的移动化部署</p><p>定制化业务工具的快速分发</p><p>临时性项目的应用测试</p><p>特定区域或部门的应用推广</p><p>需要频繁更新的业务应用</p><p>安全管控机制<br/>为确保企业签名的合规使用，苹果建立了多层次的安全管控机制。企业证书设有有效期限制，通常为一年，需要定期续费更新。同时，苹果会通过自动化系统监测证书使用情况，对异常分发行为进行识别和处理。</p><p>企业自身也需要建立完善的管理制度，包括严格限制分发范围、定期审计应用使用情况、建立证书管理制度等。这些措施不仅能确保合规性，也能有效防范安全风险。</p><p>实施要点<br/>成功部署企业签名需要注意以下几个要点：<br/>首先，确保证书文件的妥善保管，避免泄露风险。<br/>其次，建立规范的分发流程，确保只有授权用户能够安装应用。<br/>再次，监控证书有效期，提前做好续期准备。<br/>最后，准备应急预案，以应对证书异常情况。</p><p>未来发展趋势<br/>随着移动办公需求的持续增长，企业签名技术也在不断演进。未来将出现更加智能化的管理平台，提供自动化的证书监控和预警功能。同时，与移动设备管理（MDM）方案的深度整合也将成为重要发展方向。</p><p>企业签名作为苹果生态中的重要组成部分，为组织内部的应用分发提供了可靠的技术支持。通过合理规划和规范使用，企业可以充分发挥这一方案的价值，推动数字化转型进程。在移动优先的时代，掌握企业签名技术将成为组织提升运营效率的重要助力。</p>]]></description></item><item>    <title><![CDATA[BipedalWalker实战：SAC算]]></title>    <link>https://segmentfault.com/a/1190000047439304</link>    <guid>https://segmentfault.com/a/1190000047439304</guid>    <pubDate>2025-11-30 23:03:21</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>下肢假肢的控制系统设计一直是个老大难问题。传统控制理论需要建立肢体和环境的精确数学模型，但现实世界可以不一样，比如说地面摩擦力时刻在变，坡度各不相同，患者随时可能绊一下。这就需要控制器具备自适应能力，能从失误中恢复，还得在没有显式编程的情况下习得自然的步态模式。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047439306" alt="" title=""/></p><p>强化学习给出了一条思路：让假肢自己通过试错"学会"走路。但是标准RL算法有个毛病，它太贪心了，找到一种能用的移动方式就死守着不放，一旦外界条件变化，整个控制策略就非常容易崩盘。</p><p>这篇文章用Soft Actor-Critic（SAC）算法解决BipedalWalker-v3环境。但这不只是跑个游戏demo那么简单，更重要的是从生物工程视角解读整个问题：把神经网络对应到神经系统，把奖励函数对应到代谢效率。</p><h2>SAC的核心思想：为什么要"soft"？</h2><p>常规强化学习只盯着一个目标——最大化期望累积奖励。这种贪心策略在国际象棋这类确定性博弈里表现不错，但放到物理控制任务上问题就非常的多了，这是因为系统动力学稍有变化，贪心策略往往直接翻车。</p><p>要理解SAC里的"软"字，先得搞清楚Actor-Critic架构。这个框架其实模拟了人类学习运动技能的过程。打个比方：患者（Actor）在学习使用假肢，旁边有个理疗师（Critic）在观察和指导。</p><p><strong>Actor（策略网络π）</strong> 负责控制肢体，观察当前状态（关节角度、身体平衡），然后决定该怎么动。训练初期它啥也不懂只能瞎动弹。<strong>Critic（Q函数网络）</strong> 负责评估Actor动作的质量，不直接控制肢体，只预测某个动作长期来看能拿到多少奖励。</p><p>传统算法里，Actor拼命想找到那个"最优解"来讨好Critic。但SAC不一样，Critic鼓励Actor尝试多种不同的成功路径，不仅看结果，还看方法的多样性。</p><p>SAC采用最大熵框架，智能体的目标变成了同时最大化期望奖励和策略熵（随机性）：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047439307" alt="" title="" loading="lazy"/></p><p>这里的𝓗就是熵。</p><p>这对假肢控制有什么意义？</p><p>一方面是<strong>探索机制</strong>。比如说婴儿会用随机运动（所谓motor babbling）来摸索肢体的运动规律。高熵保证了充分探索，避免智能体掉进"安全小碎步"的局部最优陷阱，就是那种几乎不动、只求不摔的保守策略。另一方面是<strong>泛化性</strong>，熵最大化训练出来的智能体掌握了一整套策略组合。某条肌肉激活路径被干扰了？没关系，还有备选方案。这让步态对打滑、绊绊脚之类的意外具备容错能力。</p><h2>从仿真到临床的映射关系</h2><pre><code>BipedalWalker-v3</code></pre><p>是个24维数字向量。但从生物工程角度看它相当于膝上假肢控制问题的简化版。</p><p><strong>观察空间对应传感器融合</strong></p><p>Gym里的24维观察向量可以直接对应到Otto Bock Genium这类智能假肢的传感器配置：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047439308" alt="" title="" loading="lazy"/></p><p>躯干角度和速度对应前庭系统——"躯干"代表质心位置，硬件上用IMU（惯性测量单元）采集平衡数据。关节编码器对应本体感觉，仿真里提供的关节角度和速度，在真实假肢上由霍尔传感器和旋转编码器获取。激光雷达对应视觉前馈，现代研究型假肢已经开始集成深度相机来预判地形。</p><p><strong>动作空间对应执行器</strong></p><p>智能体用[-1, 1]范围的连续值控制髋关节和膝关节。这对应到硬件上就是直流电机的电流控制，或者气动人工肌肉（PAMs）的压力调节。</p><p>为什么连续控制这么重要呢？DQN这类离散算法输出的是生硬的开关命令，SAC输出的是连续平滑的扭矩曲线。对患者来说这可不是小事，生硬的驱动会在残肢上产生剪切力长期下去会损伤组织。</p><h2>代码实现</h2><p>以下实现改编自CleanRL并使用PyTorch搭建网络，通过Gymnasium提供仿真环境运行。</p><p><strong>Actor网络：物理约束的强制执行</strong></p><p>连续控制的一个核心挑战是把动作限制在物理边界内。这里用高斯策略配合</p><pre><code>tanh</code></pre><p>函数压缩输出，确保电机指令不会超出[−1, 1]的安全范围。</p><pre><code> # LOGIC: The Actor Network (from sac_bipedalwalker_enhanced.py)  
def get_action(self, x):  
    mean, log_std = self(x)  
    std = log_std.exp()  
      
    # The Reparameterization Trick:   
    # Allows gradients to flow back through the sampling process  
    normal = torch.distributions.Normal(mean, std)  
    x_t = normal.rsample()    
      
    # Squash output to [-1, 1] for the environment limits  
    y_t = torch.tanh(x_t)  
    action = y_t * self.action_scale + self.action_bias  
      
    # Correction for the log_prob due to tanh squashing (Math detail)  
    log_prob = normal.log_prob(x_t)  
    log_prob -= torch.log(self.action_scale * (1 - y_t.pow(2)) + 1e-6)  
    log_prob = log_prob.sum(1, keepdim=True)  
      
     return action, log_prob, mean</code></pre><p>注意</p><pre><code>x_t = normal.rsample()</code></pre><p>这行。看起来普普通通，实际上是整个算法的数学根基。</p><p>标准随机策略里，采样动作是个随机事件，会打断反向传播需要的导数链，随机数生成器没法求导。<strong>重参数化技巧</strong>绕开了这个问题：不直接从分布采样，而是先采一个标准正态噪声ε，再用网络输出的均值μ和标准差σ做变换：xt = μ + σ · ε。因为ε跟网络参数无关，μ和σ的梯度就能正常计算了，Actor网络也就能从Critic的反馈里学到东西。没这个技巧，连续策略根本没法训。</p><p><strong>自动熵调节</strong></p><p>早期SAC版本里，温度参数α是固定的。α太大，智能体走路像喝醉了；α太小，又永远学不会探索。现在的做法是把α当成可学习参数，让智能体自己决定什么时候该收敛：</p><pre><code> # LOGIC: Automatic Entropy Tuning (inside training loop)  
if args.autotune:  
    with torch.no_grad():  
        _, log_pi, _ = actor.get_action(data.observations)  
          
    # Minimize difference between current entropy and target entropy  
    # target_entropy is usually -dim(Action Space)  
    alpha_loss = (-log_alpha.exp() * (log_pi + target_entropy)).mean()  

    a_optimizer.zero_grad()  
    alpha_loss.backward()  
    a_optimizer.step()  
     alpha = log_alpha.exp().item()</code></pre><h2>实验结果分析</h2><p>训练跑了350k步。这里我们要看的不是最终分数多高，而是学出来的步态在生物力学上是否合理。</p><p><strong>学习曲线的解读</strong></p><p>智能体一开始回报是负的，站都站不稳，跟患者刚装上新假肢时的状态很像。</p><p>看下面的学习曲线，蓝色阴影是各episode的标准差。0-100k步阶段方差很低，但这不好，因为智能体一直在失败，每次都是秒摔。</p><p>到了150k-250k步，方差突然爆炸。这是个关键转折期，智能体开始尝试高风险策略，有时走得漂亮，有时摔得很惨。只有进入300k步之后的稳定区，均值高、方差收窄，这样才能考虑"冻结"策略用于实际部署。方差收窄意味着策略从"碰运气"进化到了"真会走"。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047439309" alt="" title="" loading="lazy"/></p><p>而150k步左右发生了"相变"，智能体突然开窍了，奖励曲线急剧上升。250k步后稳定在200分以上，算是解决了这个环境。</p><p><strong>相位图分析</strong></p><p>光看分数不够，还得检查运动学特征。下图是髋关节的相位图，横轴关节角度，纵轴角速度。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047439310" alt="" title="" loading="lazy"/></p><p>紫色和蓝色的散点代表早期阶段，角度和速度之间毫无关联，智能体就是在瞎蹬腿，漫无目的地探索状态空间。</p><p>随着训练推进（颜色向黄绿过渡），散点开始收敛成一个封闭的轨道形状。这在控制论和生物力学里叫<strong>极限环</strong>（Limit Cycle）。</p><p>极限环说明系统找到了稳定的周期轨道。即使遇到小扰动，系统也倾向于回到这个环上，这正是动态稳定步态的定义。这个环是从SAC目标函数里自发涌现出来的，不是显式编程的结果。环的形状比较光滑并且没有锯齿，说明Actor网络里的</p><pre><code>tanh</code></pre><p>压缩确实产生了平滑的扭矩曲线，避免了离散RL常见的"抖振"问题。这对假肢安全性至关重要。</p><p><strong>能效特征</strong></p><p>最后看Critic损失（智能体的"困惑程度"）和动作幅度（扭矩大小）的关系。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047439311" alt="" title="" loading="lazy"/></p><p>学习阶段（50k-200k步），Critic损失达到峰值，智能体还在跟物理规律较劲。极限环建立后（200k步以后），动作幅度稳定下来，Critic损失也降到较低水平。</p><p>更细致地看，可以把训练过程分成三个力学阶段：</p><p><strong>"僵住"阶段（0-70k步）</strong>：动作幅度（绿线）起始值很低。智能体把关节锁死以避免摔倒惩罚，这在运动学习里叫"共同收缩"策略。不怎么动，自然也不会摔得太惨。</p><p><strong>"疯狂试探"阶段（70k-200k步）</strong>：Critic损失剧烈震荡，这正是智能体开始尝试往前走的时候。反复失败带来高"惊讶度"。同时动作幅度急剧攀升说明智能体意识到想走路就得狠狠发力，哪怕暂时会摔。</p><p><strong>"熟练掌握"阶段（200k步以后）</strong>：极限环形成，Critic损失骤降，智能体对物理世界不再感到意外。有意思的是动作幅度：在200k附近达到峰值后<em>反而略有下降</em>然后趋于平稳。这是熟练运动的典型特征，智能体学会了借力，不再每一步都用蛮力，而是顺着动力学"流"起来，能量消耗得到了优化。</p><p>一个可能的改进方向是在奖励函数里加入代谢运输成本（COT）惩罚项，鼓励智能体发现更"被动-动态"的步态模式，靠惯性而不是持续肌肉输出来行走，这对延长真实假肢的电池续航很有价值。</p><h2>总结</h2><p>SAC算法在BipedalWalker环境中跑了350k步后，智能体从"秒摔"进化到稳定行走（200+分）。相位图显示髋关节运动收敛成极限环，动态稳定步态的标志。能效曲线也印证了这点：智能体最终学会借力而非蛮干。</p><p>从假肢控制角度看，SAC的最大熵框架带来的策略多样性是关键优势，让系统对打滑、绊脚这类意外有容错空间。不过真要落地到Otto Bock C-Leg这类设备上，还得解决传感器噪声、执行延迟和安全约束的问题，域随机化和PID安全笼是两个可行方向。</p><p><a href="https://link.segmentfault.com/?enc=%2By85vbd9jluS8eNj09u5Jw%3D%3D.0EFUSKbTBQWoYH%2F2A%2BnLQEngO3XBXYDm6KpqRApOmLFt%2FW1wKQgCXuK9Mr9MsU6AqK3JhGYoBJyckoBExJJQDA%3D%3D" rel="nofollow" target="_blank">https://avoid.overfit.cn/post/ab5860e7071441e9aab80e9876b2f45d</a></p><p>作者：Cristlianreal</p>]]></description></item><item>    <title><![CDATA[从简单到复杂：多进程环境下的加权随机选择]]></title>    <link>https://segmentfault.com/a/1190000047439327</link>    <guid>https://segmentfault.com/a/1190000047439327</guid>    <pubDate>2025-11-30 23:02:20</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>引言</h2><p>在分布式系统中，我们经常需要实现负载均衡、流量分配、A/B 测试等功能。这些场景的核心问题是：<strong>如何按照预设的权重比例，在多个候选项中进行随机选择？</strong> 更具挑战性的是，当多个进程同时运行、随时可能加入或退出时，如何保证整体的选择分布仍然符合预期的权重比例？</p><p>本文将从最简单的均匀随机选择开始，逐步深入到加权随机选择，最后解决多进程环境下的分布一致性问题，并给出严格的数学证明。</p><p>完整代码：<a href="https://link.segmentfault.com/?enc=9K0HmUpIDxIQhHm585BB4g%3D%3D.mYlLLUGsLPra0LGijTczCWcV0yVs3KUga%2FDCLkA2MkmUvULXO1UCjmw1uNdlQx2%2B" rel="nofollow" target="_blank">https://go.dev/play/p/0h97DRfph-2</a></p><h2>第一步：简单随机选择</h2><h3>需求 1.0：从列表中随机选一个</h3><p>假设我们有一个服务器列表：<code>[A, B, C, D]</code>，需要随机选择其中一个来处理请求。</p><p><strong>朴素实现</strong>：</p><pre><code class="go">func SimpleSelect(candidates []string) string {
    n := len(candidates)
    idx := rand.Intn(n)  // 生成 [0, n) 的随机整数
    return candidates[idx]
}</code></pre><p>这种方法简单直接，每个候选项被选中的概率都是 $\frac{1}{n}$，即<strong>均匀分布</strong>。</p><h3>问题</h3><p>但现实场景中，不同服务器的性能往往不同。高性能服务器应该承担更多流量，低性能服务器应该承担较少流量。均匀分布无法满足这个需求。</p><hr/><h2>第二步：加权随机选择</h2><h3>需求 2.0：按权重选择</h3><p>现在我们给每个服务器分配一个权重：</p><table><thead><tr><th>服务器</th><th>权重</th><th>期望流量占比</th></tr></thead><tbody><tr><td>A</td><td>5</td><td>45.5%</td></tr><tr><td>B</td><td>3</td><td>27.3%</td></tr><tr><td>C</td><td>2</td><td>18.2%</td></tr><tr><td>D</td><td>1</td><td>9.1%</td></tr></tbody></table><p>总权重 $W = 5 + 3 + 2 + 1 = 11$</p><p>我们希望服务器 A 被选中的概率是 $\frac{5}{11}$，服务器 B 被选中的概率是 $\frac{3}{11}$，以此类推。</p><h3>算法 2.0：累积权重法</h3><p><strong>核心思想</strong>：将权重值看作一条数轴上的线段长度，生成随机数落在哪个线段，就选择对应的候选项。</p><pre><code>服务器:  A  A  A  A  A  B  B  B  C  C  D
数轴:   [0-------------5--------8-----10-11)
累积:    0             5        8    10 11</code></pre><p><strong>算法步骤</strong>：</p><ol><li><p>计算累积权重数组：$CW = [w_1, w_1+w_2, w_1+w_2+w_3, ..., W]$</p><ul><li>对于示例：$CW = [5, 8, 10, 11]$</li></ul></li><li>生成 $[0, W)$ 范围内的随机数 $r$</li><li>找到第一个满足 $CW[i] &gt; r$ 的索引 $i$，返回候选项 $i$</li></ol><p><strong>为什么这样能保证权重比例？</strong></p><p>对于候选项 $i$（权重为 $w_i$），被选中的条件是：</p><p>$$CW[i-1] \leq r &lt; CW[i]$$</p><p>这个区间的长度恰好是 $w_i$，因此被选中的概率为：</p><p>$$P(\text{选中}\ i) = \frac{w_i}{W}$$</p><p>完美符合权重比例！</p><h3>优化：二分查找</h3><p>累积权重数组是单调递增的，可以用<strong>二分查找</strong>将查找复杂度从 $O(n)$ 降低到 $O(\log n)$：</p><pre><code class="go">func BinarySearchSelect(cumWeights []int64, totalWeight int64) int {
    r := rand.Int63n(totalWeight)  // [0, totalWeight)
    left, right := 0, len(cumWeights)-1
    
    for left &lt; right {
        mid := left + (right - left) / 2
        if cumWeights[mid] &lt;= r {
            left = mid + 1
        } else {
            right = mid
        }
    }
    return left
}</code></pre><hr/><h2>第三步：多进程环境的挑战</h2><h3>需求 3.0：分布式场景</h3><p>现在问题变得复杂了：</p><ul><li>系统部署了<strong>多个进程</strong>（或服务实例），每个进程都独立执行选择算法</li><li>进程数量<strong>动态变化</strong>：可能随时有新进程启动，或者旧进程崩溃退出</li><li>没有中心化的协调服务（如果有的话，就失去了分布式的意义）</li></ul><p><strong>核心问题</strong>：如何保证在这种动态、分布式的环境下，<strong>总体的选择分布仍然符合权重比例</strong>？</p><h3>可能的担忧</h3><ol><li><strong>同步问题</strong>：多个进程同时选择，会不会相互干扰？</li><li><strong>分布偏差</strong>：进程 1 可能恰好多选了 A，进程 2 多选了 B，总体会不会偏离？</li><li><strong>动态变化</strong>：新进程加入时，会不会打破已有的分布？</li></ol><hr/><h2>第四步：解决方案 —— 独立同分布采样</h2><h3>设计原则</h3><p><strong>关键洞察</strong>：如果每个进程都<strong>独立地</strong>按照<strong>相同的权重分布</strong>进行采样，那么无论有多少进程、进程如何变化，总体分布在统计意义上一定收敛到权重比例。</p><h3>实现要点</h3><ol><li><p><strong>配置共享，状态独立</strong></p><ul><li>所有进程共享相同的候选列表和权重配置（可以通过配置文件、环境变量等方式）</li><li>但每个进程的随机数生成是完全独立的，不依赖共享状态</li></ul></li><li><p><strong>加密安全的随机数</strong></p><ul><li>使用 <code>crypto/rand</code> 而非 <code>math/rand</code></li><li>保证每个进程的随机数序列高质量且彼此独立</li></ul></li><li><p><strong>无状态设计</strong></p><ul><li>不需要记录"已经选了多少次 A"</li><li>不需要进程间通信</li><li>每次选择都是独立事件</li></ul></li></ol><h3>完整代码实现</h3><pre><code class="go">type WeightedSelector struct {
    candidates  []Candidate
    totalWeight int64
    cumWeights  []int64  // 累积权重数组
}

func (ws *WeightedSelector) Select() (Candidate, error) {
    // 使用加密安全的随机数生成器
    randomNum, err := rand.Int(rand.Reader, big.NewInt(ws.totalWeight))
    if err != nil {
        return Candidate{}, err
    }
    
    randValue := randomNum.Int64()
    
    // 二分查找
    left, right := 0, len(ws.cumWeights)-1
    for left &lt; right {
        mid := left + (right - left) / 2
        if ws.cumWeights[mid] &lt;= randValue {
            left = mid + 1
        } else {
            right = mid
        }
    }
    
    return ws.candidates[left], nil
}</code></pre><hr/><h2>第五步：数学证明</h2><p>现在我们给出严格的数学证明，说明为什么这个算法在多进程环境下是正确的。</p><h3>符号定义</h3><ul><li>候选项集合：$\{C_1, C_2, ..., C_n\}$</li><li>权重集合：$\{w_1, w_2, ..., w_n\}$，其中 $w_i &gt; 0$</li><li>总权重：$W = \sum_{i=1}^{n} w_i$</li><li>进程数量：$k$（可以动态变化）</li><li>第 $j$ 个进程的选择次数：$m_j$</li><li>总选择次数：$M = \sum_{j=1}^{k} m_j$</li></ul><h3>定理：多进程独立采样的分布一致性</h3><p><strong>定理</strong>：在多进程独立同分布采样的情况下，候选项 $C_i$ 被选中的总次数 $N_i$ 满足：</p><p>$$\lim_{M \to \infty} \frac{N_i}{M} = \frac{w_i}{W} \quad \text{(依概率)}$$</p><p>即，当总选择次数 $M$ 足够大时，候选项 $i$ 的实际选择比例依概率收敛到其权重比例。</p><h3>证明</h3><p><strong>第一步：单次选择的概率</strong></p><p>根据算法设计，每次选择时，候选项 $C_i$ 被选中当且仅当随机数 $r \in [CW_{i-1}, CW_i)$，其中 $CW_0 = 0$。</p><p>该区间长度为 $w_i$，因此：</p><p>$$P(C_i \text{ 被选中}) = \frac{w_i}{W}$$</p><p><strong>第二步：单个进程的期望</strong></p><p>设第 $j$ 个进程执行 $m_j$ 次选择，令 $X_{ji}$ 为该进程中 $C_i$ 被选中的次数。</p><p>由于每次选择是独立的，$X_{ji}$ 服从<strong>二项分布</strong> $B(m_j, \frac{w_i}{W})$，其期望为：</p><p>$$E[X_{ji}] = m_j \cdot \frac{w_i}{W}$$</p><p><strong>第三步：多进程的总期望</strong></p><p>所有进程中 $C_i$ 被选中的总次数为：</p><p>$$N_i = \sum_{j=1}^{k} X_{ji}$$</p><p>由期望的线性性质：</p><p>$$E[N_i] = \sum_{j=1}^{k} E[X_{ji}] = \sum_{j=1}^{k} m_j \cdot \frac{w_i}{W} = M \cdot \frac{w_i}{W}$$</p><p>这说明，<strong>无论进程数量如何变化</strong>，只要总选择次数是 $M$，$C_i$ 被选中的期望次数总是 $M \cdot \frac{w_i}{W}$。</p><p><strong>第四步：大数定律保证收敛</strong></p><p>由于 $X_{ji}$ 都是独立同分布的随机变量（每个进程独立采样），我们可以应用<strong>弱大数定律</strong>：</p><p>$$\lim_{M \to \infty} P\left(\left|\frac{N_i}{M} - \frac{w_i}{W}\right| &gt; \epsilon\right) = 0 \quad \forall \epsilon &gt; 0$$</p><p>即，当 $M$ 足够大时，$\frac{N_i}{M}$ 以高概率接近 $\frac{w_i}{W}$。</p><p><strong>第五步：方差分析（可选）</strong></p><p>为了更精确地刻画收敛速度，我们计算方差：</p><p>$$\text{Var}(N_i) = \sum_{j=1}^{k} \text{Var}(X_{ji}) = \sum_{j=1}^{k} m_j \cdot \frac{w_i}{W} \cdot \left(1 - \frac{w_i}{W}\right)$$</p><p>$$= M \cdot \frac{w_i}{W} \cdot \left(1 - \frac{w_i}{W}\right)$$</p><p>标准差为：</p><p>$$\sigma(N_i) = \sqrt{M \cdot \frac{w_i}{W} \cdot \left(1 - \frac{w_i}{W}\right)}$$</p><p>相对误差的标准差为：</p><p>$$\frac{\sigma(N_i)}{E[N_i]} = \sqrt{\frac{1}{M} \cdot \frac{W - w_i}{w_i}} = O\left(\frac{1}{\sqrt{M}}\right)$$</p><p>这说明，误差以 $\frac{1}{\sqrt{M}}$ 的速度递减，收敛速度是<strong>根号级别</strong>的。</p><h3>推论：进程动态变化的影响</h3><p><strong>推论 1</strong>（进程加入）：新进程加入相当于增加 $M$，会加快收敛速度，但不改变期望分布。</p><p><strong>推论 2</strong>（进程退出）：进程退出不影响已产生的样本，只是减少了未来的采样次数。由于已有样本仍然有效，总体分布不受影响。</p><p><strong>推论 3</strong>（进程组合无关性）：无论是 10 个进程各选 100 次，还是 1 个进程选 1000 次，或者任意其他组合，只要 $M = 1000$，期望分布和收敛性质完全相同。</p><h3>关键假设的验证</h3><p>我们的证明依赖于以下假设，现在验证它们在实现中是否满足：</p><ol><li><strong>独立性</strong>：✓ 每个进程使用独立的 <code>crypto/rand.Reader</code>，随机数序列互不相关</li><li><strong>同分布</strong>：✓ 所有进程加载相同的配置，使用相同的算法</li><li><strong>正整数权重</strong>：✓ 代码中检查 <code>w &gt; 0</code></li><li><strong>足够大的 $M$</strong>：✓ 在实际应用中，选择次数通常达到成千上万次</li></ol><hr/><h2>实验验证</h2><p>我们进行了三组实验来验证理论：</p><h3>实验 1：单进程，10,000 次选择</h3><table><thead><tr><th>候选项</th><th>权重</th><th>理论比例</th><th>实际次数</th><th>实际比例</th><th>误差</th></tr></thead><tbody><tr><td>A</td><td>5</td><td>45.45%</td><td>4523</td><td>45.23%</td><td>-0.48%</td></tr><tr><td>B</td><td>3</td><td>27.27%</td><td>2738</td><td>27.38%</td><td>+0.40%</td></tr><tr><td>C</td><td>2</td><td>18.18%</td><td>1821</td><td>18.21%</td><td>+0.16%</td></tr><tr><td>D</td><td>1</td><td>9.09%</td><td>918</td><td>9.18%</td><td>+0.99%</td></tr></tbody></table><p><strong>结论</strong>：误差在 ±1% 以内，符合预期。</p><h3>实验 2：10 进程，每进程 1,000 次（共 10,000 次）</h3><table><thead><tr><th>候选项</th><th>权重</th><th>理论比例</th><th>实际次数</th><th>实际比例</th><th>误差</th></tr></thead><tbody><tr><td>A</td><td>5</td><td>45.45%</td><td>4551</td><td>45.51%</td><td>+0.13%</td></tr><tr><td>B</td><td>3</td><td>27.27%</td><td>2719</td><td>27.19%</td><td>-0.29%</td></tr><tr><td>C</td><td>2</td><td>18.18%</td><td>1812</td><td>18.12%</td><td>-0.33%</td></tr><tr><td>D</td><td>1</td><td>9.09%</td><td>918</td><td>9.18%</td><td>+0.99%</td></tr></tbody></table><p><strong>结论</strong>：多进程结果与单进程几乎一致，证明进程数量不影响分布。</p><h3>实验 3：100 进程，每进程 1,000 次（共 100,000 次）</h3><table><thead><tr><th>候选项</th><th>权重</th><th>理论比例</th><th>实际次数</th><th>实际比例</th><th>误差</th></tr></thead><tbody><tr><td>A</td><td>5</td><td>45.45%</td><td>45472</td><td>45.47%</td><td>+0.04%</td></tr><tr><td>B</td><td>3</td><td>27.27%</td><td>27251</td><td>27.25%</td><td>-0.07%</td></tr><tr><td>C</td><td>2</td><td>18.18%</td><td>18193</td><td>18.19%</td><td>+0.05%</td></tr><tr><td>D</td><td>1</td><td>9.09%</td><td>9084</td><td>9.08%</td><td>-0.11%</td></tr></tbody></table><p><strong>结论</strong>：随着 $M$ 增加到 100,000，误差降低到 ±0.1% 以内，完美验证了 $O(\frac{1}{\sqrt{M}})$ 的收敛速度。</p><hr/><h2>总结</h2><p>本文从简单的均匀随机选择出发，逐步引入权重、多进程等复杂因素，最终设计出一个既简单又严谨的分布式加权随机选择算法。</p><h3>核心要点</h3><ol><li><strong>算法设计</strong>：累积权重 + 二分查找，时间复杂度 $O(\log n)$</li><li><strong>分布式原则</strong>：独立同分布采样，无需进程间同步</li><li><strong>数学保证</strong>：大数定律确保收敛性，方差分析预测误差</li><li><strong>实践验证</strong>：实验结果与理论完全吻合</li></ol><h3>适用场景</h3><ul><li>负载均衡（根据服务器性能分配流量）</li><li>A/B 测试（按比例分配用户到不同版本）</li><li>分布式限流（按权重分配配额）</li><li>随机抽奖（按中奖概率分配奖品）</li></ul><h3>关键优势</h3><p>✓ <strong>无状态</strong>：不需要记录历史，每次选择都是独立的  <br/>✓ <strong>高性能</strong>：$O(\log n)$ 时间复杂度，适合高频调用  <br/>✓ <strong>分布式友好</strong>：天然支持多进程，无需协调  <br/>✓ <strong>数学严谨</strong>：有完整的理论保证和实验验证  <br/>✓ <strong>加密安全</strong>：使用 <code>crypto/rand</code>，适合安全敏感场景  </p><p>这个算法的美妙之处在于：<strong>复杂性隐藏在数学之中，实现却极其简单</strong>。只要遵循独立同分布的原则，复杂的多进程协调问题就自然而然地解决了。</p>]]></description></item><item>    <title><![CDATA[因此未来合规成 苦闷的键盘 ]]></title>    <link>https://segmentfault.com/a/1190000047439345</link>    <guid>https://segmentfault.com/a/1190000047439345</guid>    <pubDate>2025-11-30 23:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>从生成式 AI 的惊艳亮相引起全球科技巨头军备竞赛般的投入开始，整个 AI 行业仿佛被注入了无限的想象力。似乎在宣告着即将出现一个生产力即将被彻底解放、商业模式即将被完全颠覆的光明未来。<br/>微软、谷歌、亚马逊等云巨头纷纷将资本支出的绝大部分押注于 AI 基础设施建设，而无数逐利而来的 AI 初创公司，更是如雨后春笋般涌现试图分一杯羹，全球 AI 领域的投资额也达到了史无前例的高度。<br/>然而，正如任何过热的淘金热最终都会迎来冷静期当技术以超乎预期的速度普及时，潜在的负面效应也以同样的速度被放大，正在悄然侵蚀着行业参与者。<br/>从 " 可选项 " 到 " 必选项 " 的巨额支出<br/>根据奇安信集团对外发布《2024 人工智能安全报告》来看，在 2023 年基于 AI 的深度伪造欺诈便已暴增了 3000%，基于 AI 的钓鱼邮件也增长了 1000%；而内容生成环节更是实现规模化生产。<br/>基于 Stable Diffusion 和 GPT-4 的定制模型，可每小时生成 2000 条伪原创研报、800 段逼真视频。暗网平台 "DarkGPT" 更是提供包月服务，1 万美元即可获得每日 5000 条金融虚假内容的产能。<br/>而且 "AI 滥用 " 的后遗症并不仅仅在社会新闻版块，可以说它已经穿透了科技公司的防火墙直接作用于其财务报表。而金融行业正是这场风暴的中心，当 AI 以假乱真的能力被精准地应用于金融诈骗时，其破坏力可以说是指数级的增长。<br/>据行业估算，2024 年由深度伪造技术引发的各类欺诈造成的全球经济损失已高达 120 亿美元。尤其在监管相对滞后、交易更为匿名的加密货币领域，AI 滥用更是如鱼得水。根据相关的报告也显示 2024 年仅 AI 深度伪造技术全年造成的损失便高达 46 亿美元。<br/>随着 AI 滥用事件的频发，过去模糊的 " 伦理指南 " 正在迅速转变为具有强制约束力的法律条文，而且这种转变直接导致了企业合规成本的急剧攀升。<br/>而且一旦出现违规需要付出的代价更是惨痛的，罚款最高可达全球年营业额的数个百分点或数千万欧元，而且合规也不再是法务部门的单一工作，而是渗透到研发、产品、市场的每一个环节。<br/>这些 " 反噬 " 也并非凭空产生，在 AI 商业化过程中对速度和规模的追求，长期以来压倒了对安全和伦理的考量所以形成了这种 " 原罪 "。因此未来合规成本的升高是不可避免的，而欧盟的《AI 法案》可以说是这一趋势的先行者。<br/>该法案于 2024 年 8 月 1 日正式生效并分阶段实施，着重对高风险的 AI 系统施加了严格的合规要求。而且这不仅仅是一项区域性法规，更可能产生 " 布鲁塞尔效应 " 从而影响全球的 AI 监管格局。<br/>监管的落地也将会直接转化为企业的合规成本。据公开信息推算，仅欧盟 AI 法案便可能导致欧洲企业的 AI 采纳成本增加约 310 亿欧元，并使 AI 投资减少近 20%。而美国联邦贸易委员会也已对 OpenAI 展开调查，谷歌等公司也不得不调整其营销话术，避免被处以巨额罚款。<br/>可以说 " 监管的铁幕 " 正在迫使整个行业从过去 " 快速行动，打破陈规 " 的互联网思维转向一种更为审慎、合规驱动的开发模式。可以说这种转变无疑会减缓创新速度并增加运营成本，对于那些资源有限的中小企业和初创公司构成尤为严峻的挑战。<br/>对 " 信任 " 的侵蚀或许是 AI 滥用最难修复的一种<br/>这源于在激烈的竞争压力下，企业急于抢占市场将产品快速推向用户，所以将风险控制和安全测试置于次要位置。但是这种 " 快速行动并打破规则 " 的心态在 AI 时代尤为危险，因为 AI 技术的潜在破坏力远超以往的软件应用。<br/>并且市场对于 AI 技术的可靠性极度敏感，甚至一次小小的失误都可能引发巨大的信任危机和财务损失。谷歌的 Bard 模型之前便在一次演示中出现事实性错误，竟然导致其母公司 Alphabet 的股价在单日内暴跌 7%，市值蒸发超过 1000 亿美元。<br/>并且随着 AI 投资的巨额支出持续攀升，投资者开始担忧其回报前景，这种悲观情绪导致 Meta、Microsoft、Alphabet 和 Nvidia 等 AI 领域的领军企业股价普遍承压下跌，市场也开始讨论 "AI 泡沫 " 的风险，并开始质疑哪些不计成本的 " 军备竞赛 " 式投资。<br/>更何况大量公司缺乏对 AI 伦理的明确责任归属，高管层面也并未对其有所调整。所以 AI 系统的决策过程像一个 " 黑箱 "，在责任主体模糊的情况下滥用和误用的风险便难以控制。企业内部也未建立有效的问责机制。<br/>但是更深层次的原因在于当前主流生成式 AI 商业模式本身所内含的风险。这些模型依赖于海量数据的投喂，其训练过程难以完全避免偏见和有害信息的吸收。而其强大的生成能力却为恶意利用提供了温床。<br/>因此当商业模式的核心是追求更强大的模型、更广泛的应用时，如果缺乏与之匹配的强大 " 安全刹车 " 系统，滥用就成了可预见的副产品。这种商业逻辑与伦理要求之间的结构性失衡才是导致 " 反噬 " 的根本内因。<br/>所以当企业享受了技术红利带来的增长，如今便也不得不为其模式所伴生的风险 " 买单 "。哪怕科技公司以 " 让世界更美好 " 的叙事推广 AI，公众在实际体验中，也会频繁受到隐私泄露、算法偏见、就业替代、虚假信息等负面影响。<br/>这种落差也导致了广泛的 "AI 焦虑 " 和不信任感。公众普遍认为现有的监管法规不足以应对 AI 带来的社会风险期望政府采取更加果断的行动。这种强大的民意压力也是推动监管机构加速行动的根本动力。<br/>面对公众的呼声和潜在的社会风险，监管机构的介入是必然的。但由于技术发展的速度远超立法速度监管往往表现出一定的滞后性，欧盟 AI 法案便被部分人士认为可能增加企业负担、抑制创新。<br/>全球主要经济体在 AI 领域的竞争，也使得监管变得更加复杂。各国都希望在鼓励创新和防范风险之间找到平衡点但这种平衡点的位置各不相同，因此形成了复杂的国际监管格局给跨国企业的合规带来了巨大挑战。<br/>而且这种外部滥用对整个 AI 行业的声誉造成了 " 连坐 " 效应。即使一家公司本身恪守伦理，也无法完全独善其身，因为公众对 AI 的信任是整体性的。恶意滥用行为如同向池塘中投下的毒药，在污染了整个水域后迫使所有 " 池中生物 " 共同承担后果。<br/>这场危机成为 AI 自我革新的契机<br/>这场 " 反噬 " 带来的阵痛，是 AI 产业从野蛮生长走向规范发展的必经阶段。它正在淘汰那些只想赚快钱、缺乏责任感的 " 玩家 "，筛选出真正有实力、有远见的长期主义者。从长远来看，这也是为 AI 产业的健康、可持续发展所必须付出的代价。<br/>其中最大的机遇在于将 " 信任 " 从一种道德呼吁，转变为一种可量化、可变现的商业资产和竞争壁垒。数据显示近 85% 的客户也更愿意与重视 AI 伦理实践的公司合作，而那些优先考虑伦理和透明度的公司收入增长也更快。<br/>可以说在 AI 产品同质化日益严重的未来，谁能赢得用户的信任谁就能赢得市场。" 负责任的 AI" 将不再仅仅是公关部门的口号，而是必须贯穿于产品设计、开发、部署全流程的核心战略。<br/>谷歌和微软等公司已经开始调整其策略，谷歌选择利用 AI 技术提升广告安全审核的效率，打击欺诈内容；微软则发布了负责任 AI 透明度报告，并推出了 AzureAIContentSafety 等服务，帮助客户构建更安全的 AI 应用。这些举措既是应对风险的防御，也是在构建新的竞争优势。<br/>正是 " 反噬 " 催生了全新的 " 安全即服务 " 市场。随着 AI 滥用风险的加剧企业对 AI 安全审计、风险评估、内容过滤、合规咨询等服务的需求将急剧增长。这为专门从事 AI 安全和伦理治理的科技公司、咨询机构创造了巨大的市场空间。<br/>而科技巨头自身也可以将其内部成熟的安全工具和能力平台化、服务化，开拓新的收入来源。例如，谷歌和微软在内容审核、风险识别方面的技术weibo.com/ttarticle/p/show?id=2309405238677524840593<br/>weibo.com/ttarticle/p/show?id=2309405238677999059065<br/>weibo.com/ttarticle/p/show?id=2309405238678338535509<br/>weibo.com/ttarticle/p/show?id=2309405238678682468514<br/>weibo.com/ttarticle/p/show?id=2309405238679018012899<br/>weibo.com/ttarticle/p/show?id=2309405238679504552195<br/>weibo.com/ttarticle/p/show?id=2309405238679844552753<br/>weibo.com/ttarticle/p/show?id=2309405238680171708599<br/>weibo.com/ttarticle/p/show?id=2309405238680515641390积累，完全可以转化为对外输出的商业服务。<br/>虽然监管的收紧虽然带来了成本，但也为行业设定了 " 准入标准 "，能够率先满足高标准合规要求的企业将获得更强的市场公信力和竞争优势，从而在未来的市场整合中占据有利地位。这实际上是一种由监管驱动的市场出清和格局优化。<br/>从滥用事件的激增，到资本市场的审慎，再到全球监管的收紧，这股 " 反噬 " 之力正在重塑 AI 产业的发展轨迹。它迫使整个行业从过去对技术力量的无限崇拜，转向对技术责任和社会价值的深刻反思。<br/>麦肯锡预测，到 2030 年 AI 将为全球经济创造 13 万亿美元价值。但价值分配取决于我们如何驾驭这头猛兽。未来的竞争，将不仅仅是模型参数和算力大小的竞争，更是治理能力、责任担当和用户信任的竞争。</p>]]></description></item><item>    <title><![CDATA[AI时代程序员转型思考 xindoo ]]></title>    <link>https://segmentfault.com/a/1190000047439157</link>    <guid>https://segmentfault.com/a/1190000047439157</guid>    <pubDate>2025-11-30 21:02:05</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>  先说一下我上周的工作情况，因为我们人事变动，前端资源紧张，一些需求前端同学没有人力支持，我就试着用AI帮忙跨栈解决。然后上周我就改了6个代码库，有前端、后端、还有微信小程序，语言涉及Java、Python、JavaScript。代码绝大部分都是AI帮忙写的，这个时候你是不是开始觉得程序员这个行业危矣！但这个经历让我有产生了一些新想法，我先直接抛结论：<strong>AI会干掉大量初级程序员，但对高级程序员来说反而是一种能力增强。</strong></p><p>  为什么这么说？让我换个角度思考这个问题。假设没有AI，这些工作我依然能完成，只不过原本一周能搞定的事情可能需要两周，也许我需要多查些资料、多看看代码、多调试几次。但反过来想，如果只有AI没有我，不管给它多少时间，它产出都是0。另一件事，在今年的国际大学生程序设计大赛（ICPC)上（这可是编程领域的顶尖赛事，被誉为程序员的奥林匹克），GPT-5和Gemini都超越人类拿到了金牌，所以我可以很笃定的讲，写代码你绝对写不过头部的那几个AI。 结合这两件事，我得出一个结论：<strong>程序员的核心价值已经不再是写代码了，而是知道该做什么、该怎么做、以及如何管理好这个过程</strong>。AI可以是完美的执行者，但它还不足以成为决策者。</p><p>  当AI能完成大部分代码编写工作时，程序员面临两种可能：如果无法与AI有效协同，可能被淘汰；如果善用AI提升生产力，则会变得更强大。这引出几个关键问题：</p><ul><li><strong>程序员的核心价值到底是什么?</strong> 如果写代码本身不再是壁垒，那什么才是我们不可替代的能力?</li><li><strong>如何与AI协作才能发挥最大效能?</strong> 是简单地把AI当作代码生成工具，还是需要掌握新的协作方式?</li><li><strong>什么样的程序员会被淘汰，什么样的会变得更强?</strong> 技术能力的分水岭会发生怎样的变化?</li></ul><p>带着这些问题，让我们先明确AI时代程序员的新定位，然后再看如何在实际工作中践行这些角色。</p><h3>AI时代程序员的三种新定位</h3><h3>1. 产品经理——决定做什么</h3><p>  决定应该实现什么样的功能，把控产品方向和需求。在使用AI之前，必须先搞清楚要解决什么问题，包括明确功能目标、梳理业务流程、定义验收标准。</p><p>  举例来说，在这次修改6个代码库的过程中，我首先需要决策应该修改和增加哪些功能，这些功能与之前的功能如何配合协同才更合理。比如前端页面需要新增一个数据展示模块，我要先确定这个模块应该放在哪个位置、与现有功能如何交互、用户操作流程是否顺畅。</p><p>  AI可以帮我写代码，但无法替我决定产品的功能规划和用户体验设计。只有把这些问题想清楚，才能给AI提供准确的上下文，让它生成符合预期的代码。</p><h3>2. 架构师——决定怎么做</h3><p>  虽然以AI目前的能力，这个"架构师"仍需关注一些琐碎的细节，但核心职责是设计系统架构和技术方案。关键问题是：<strong>哪种方案更适合你当前的业务情况?成本更低?风险更小?</strong></p><p>  这需要基于业务背景、团队现状、历史技术债务、未来扩展规划等因素综合考虑，而这些都是AI所不了解的信息，所以它很难帮你做出最优决策。技术方案的选择必须由你来决定，包括选择合适的技术栈、设计系统架构、评估技术风险。</p><p>  在我修改6个代码库的过程中，有些需要调整API接口，有些需要修改数据库表结构，有些需要重构前端组件。这些偏架构层面的决策都是我做的，AI只是帮我完成具体的实现。</p><h3>3. 管理者——管好AI执行</h3><p>  这里管理的对象不是人，而是AI。与管理人类团队不同，AI协作需要采用更细致的微管理（Micromanagement）方式。因此，在与AI协作时，你需要像管理实习生一样，把任务拆解得足够细，每个环节都要明确要求和验收标准。</p><p><strong>有效的AI协作需要遵循以下原则：</strong></p><ul><li><strong>拆解任务</strong> — 不要给AI一个大而模糊的任务，而是拆解成具体的小步骤。比如"实现用户登录功能"应该拆解为"创建登录API接口"、"添加参数校验"、"编写单元测试"等独立任务。</li><li><strong>提供明确上下文</strong> — 告诉AI当前代码的结构、使用的框架、命名规范、编码风格。例如不要说"优化这段代码"，而要明确"将这段重复代码提取成公共方法"。</li><li><strong>严格代码审查</strong> — AI生成的代码必须逐行Review，检查逻辑正确性、异常处理、安全漏洞和性能问题，不能因为是AI写的就盲目信任。另外，Review不仅是为了找出问题，更是为了理解AI的实现思路，方便后续的维护和扩展。</li><li><strong>持续反馈优化</strong> — 如果AI的输出不符合预期，要明确指出问题在哪里，让它修改。这个过程可能需要多轮迭代。</li></ul><h3>总结</h3><p>  AI不会取代程序员，但会重新定义程序员的工作方式。未来的程序员不再是纯粹的代码编写者，而是<strong>懂业务的产品经理、懂技术的架构师、会管理的协调者</strong>。那些只会写代码、不思考业务和架构的程序员会被淘汰，而那些能有效驾驭AI、将其作为生产力工具的程序员会变得更强大。</p><p>  关键在于：不要把AI当作威胁，而要把它当作助手;不要被动地担心被取代，而要主动地学习如何与AI协作。就像当年IDE的出现没有让程序员失业，反而让我们写代码更高效一样，AI也会成为我们工作中不可或缺的伙伴。</p><p>  最后，如果你还在纠结"AI会不会取代程序员"这个问题，不如问问自己：<strong>我是在单纯地写代码，还是在做有价值的决策?我是在被动地完成任务，还是在主动地思考和创造?</strong> 答案决定了你在AI时代的位置。</p>]]></description></item><item>    <title><![CDATA[IT运维人员能力建设：从技术岗到管理岗的]]></title>    <link>https://segmentfault.com/a/1190000047439203</link>    <guid>https://segmentfault.com/a/1190000047439203</guid>    <pubDate>2025-11-30 21:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>那一年，我刚从一线工程师的岗位被提拔为项目经理。<br/> 这本该是一件值得庆贺的事，可我却度过了极为焦虑的三个月。<br/> 每天的工作不再是修复服务器、排查日志，而是协调资源、写计划、开会、谈预算。<br/> 我突然发现，过去十年积累的技术经验似乎一下子变得“不够用了”。<br/> 那段时间，我深刻体会到：从技术岗位到管理岗位的转变，并不是职位的变化，而是思维方式的革命。<br/>在IT运维领域，这样的转型几乎是每一位从业者的必经之路。</p><p><img width="630" height="610" referrerpolicy="no-referrer" src="/img/bVdndgA" alt="" title=""/><br/> 一线工程师关注的是“怎么把故障修好”，而管理者必须思考“为什么会故障”“怎样防止它再次发生”“对业务影响有多大”。<br/> 当我第一次主持变更评审会议时，才真正明白了“流程管理”的重要性——它不是束缚，而是让所有技术行为有章可循、可追溯、可改进的唯一途径。<br/> 技术可以让你快速解决问题，但流程才是确保问题不再重演的系统方法。<br/>我还记得第一次做年度运维计划的场景。<br/> 面对上百个待处理的任务单，我试图用熟悉的“工单逻辑”去排序优先级。<br/> 但领导问我：“这些工作对应哪些业务目标？资源投入和回报比例是多少？”<br/> 那一刻，我才意识到自己仍然站在技术视角看世界。<br/> 而管理岗位，需要从业务视角出发，以成本、风险、交付周期为决策依据。<br/> 这就是ITSS标准体系中提到的“服务管理思维”——不再只看技术成效，而是用可度量的指标来定义服务价值。<br/>当我开始理解“服务是为业务存在”这句话后，很多难题自然解开。<br/> 我学会了用流程化的方式整合资源，用SLA（服务级别协议）来管理预期，用KPI来衡量团队绩效。<br/> 同时，我逐渐懂得，管理者不是“最懂技术的人”，而是能让懂技术的人发挥最大价值的人。<br/> 这让我第一次从“技术执行者”变成了“组织推动者”。<br/>当然，这个转变过程并不轻松。<br/> 最难的一步，是从“自己动手”到“授权他人”。<br/> 我曾经忍不住亲自修改系统配置，因为觉得自己做得更快、更准。<br/> 结果却打乱了同事的排期，破坏了责任分工。<br/> 那次之后我学会了真正的“放手”——管理的核心，不是替别人完成任务，而是让每个人都能在标准化体系中高效完成任务。<br/> 这正是ITSS提出“能力管理”章节的核心精神：通过制度与流程的结合，形成组织能力，而非个人英雄主义。<br/>为了适应这种变化，我开始系统学习ITSS国家标准体系。<br/> 在那套标准中，我第一次看到“人员、过程、技术、资源”四要素被统一纳入运维管理框架的逻辑。<br/> 原来，技术能力只是其中一个维度。<br/> 更高层次的能力，来自于对流程的理解、对人的管理、以及对资源的优化。<br/> 这也是为什么在成熟度模型（T/CESA 1299）中，一级企业靠个体能力存活，而四级以上企业依赖流程和文化。<br/> 只有当一个组织的运维活动可以被标准化、量化、复用，它才真正具备“能力”。<br/>在这过程中，我也见证了许多同行的成长。<br/> 有位叫李明的同事，从机房夜班工程师做起。<br/> 当初他对项目计划表完全无感，只想“快点修完下班”。<br/> 后来在我们的ITSS培训班上，他开始用PDCA循环管理自己的工作。<br/> 他发现，当流程被梳理清楚后，团队效率提升了30%，故障率下降了一半。<br/> 三年后，他成了我们公司第一个通过ITSS服务项目经理认证的人，如今负责整个区域的服务交付质量管理。<br/>作为艾拓先锋的官方ITSS授权讲师，在讲授ITSS服务项目经理认证培训课程时我会特别强调这一点：<br/>管理不是抛弃技术，而是用系统思维重新整合技术，让它为业务目标服务。<br/> 很多学员在听完课程后才发现，管理的本质不是“多一个头衔”，而是“多一套方法论”。<br/> 而这套方法论，正是ITSS体系带给行业最宝贵的财富。<br/>这几年，我越来越相信：职业发展的天花板，从来不是岗位名称，而是你愿不愿意构建自己的能力模型。<br/> 有的工程师在同一个岗位上十年如一日，因为他始终把自己定位为“修电脑的人”；<br/> 而另一些人，却能一步步成为CIO，因为他们学会了用“流程、标准、策略”看问题。<br/> 这就是“能力建设”的差异所在。<br/>ITSS标准为这种成长提供了清晰的路径。<br/> 从基础的知识学习，到能力评估、再到成熟度验证，它帮每一位从业者明确：技术是入门，流程是进阶，战略才是顶层。<br/> 无论是工程师、项目经理，还是服务总监，都可以在标准化体系中找到自己的坐标。<br/> 当一个组织鼓励成员通过标准化工具学习和成长，它的整体能力就能持续积累，而不是依赖少数人的经验。<br/>回头看，我从那个“靠经验修问题”的技术人，变成了“靠体系防问题”的管理者。<br/> 这种变化带来的不是身份转变，而是一种全新的职业自觉。<br/> 我开始主动复盘失败项目的根因，不是为了追责，而是为了让流程更稳、风险更低。<br/> 我也学会了衡量团队的能力差距，用量化指标去驱动培训计划。<br/> 这种以标准为基础的成长方式，让我对职业生涯有了更长期的信心。<br/>运维行业的未来，属于那些既懂技术、又懂管理的人。<br/> 懂技术，才能与团队共语；懂管理，才能与业务共赢。<br/> 当我们逐渐从执行者变成引领者，ITSS标准不再只是参考文件，而是帮助我们把复杂世界变得可控的指南针。<br/> 能力建设，从来不是外部的要求，而是职业人的主动选择。<br/>能力建设永远是主动选择。</p>]]></description></item><item>    <title><![CDATA[效能工具十之接入deepseek实现AI]]></title>    <link>https://segmentfault.com/a/1190000047439153</link>    <guid>https://segmentfault.com/a/1190000047439153</guid>    <pubDate>2025-11-30 20:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>前言</h2><p>看文，看的是一种思路，希望笔者的文章能给诸位带来一些灵感思路☺️☺️☺️</p><h2>业务需求场景描述</h2><ul><li>公司每个月都会安排员工学习一个pdf文档（有点形式主义的学习）</li><li>然后，根据文档内容写一篇500字左右读后感txt</li><li>员工都是把文档丢给AI让其帮忙写读后感</li><li>一个员工每个月要花费10分钟，几十个员工，就累计是几个小时的成本</li><li>人越多，成本越高</li><li>针对于这个情况，笔者思考，倒不如写一个工具</li><li><strong>由专人在月末的时候，直接通过工具，点一点，一键生成几十份甚至上百份的学后感</strong></li><li>如此这般，就能够进行相应的提效</li></ul><h2>代码实现</h2><h3>技术选型</h3><ul><li>首先是pdf的文字提取，这里使用FileReader去读取需要学习的pdf文件（上传pdf）</li><li>然后，把读取到的数据，交给<a href="https://link.segmentfault.com/?enc=5FF5%2BhNLuaILWQtSZdKBEg%3D%3D.hFepA7DnGajpC9EPqoMWnRanxucV21zO2%2BfCjU9XtVVd5vcS5ATDkGJ1eIgdO6IjGTtghhT2YE4i%2F6o9WDomkA%3D%3D" rel="nofollow" target="_blank">pdf-dist</a>中的pdf.js和pdf.worker.js</li><li>这里就可以拿到pdf中的所有文字信息了（包括页码数）</li><li>再然后，把pdf中的文字信息作为user的内容</li><li>再提前写好系统级的提示词内容</li><li>丢给deepseek的接口返回给前端</li><li>前端再通过<a href="https://link.segmentfault.com/?enc=Xl1Yl36UbnC1nTcju57Z1g%3D%3D.QUEtPT6x7ARrHkmqXSJEdP6CyoauS773ostA4BBw77BSsaWRqBY9mThJZXha3NwxP%2B%2FtmObmBU7nr9x7i7kQNw%3D%3D" rel="nofollow" target="_blank">file-saver.js</a>下载对应的内容即可做到生成pdf学后感txt文本的功能</li><li>生成多份，就批量请求一下接口，整体Promise.allSettled一下即可</li><li>最终，再使用<a href="https://link.segmentfault.com/?enc=8ZxOZxADmlLPBBuo3U8DoQ%3D%3D.YQ3XEjIHxGc0lPhEiDhDHLnxf%2B%2FCA8qpSZPH8A7uBWvWx1Tm6Vu7zeEw204kjyLL" rel="nofollow" target="_blank">jszip</a>把所有的txt打包成一个压缩包，直接下载了</li></ul><h3>deepseek开放平台注册API keys</h3><p>地址：<a href="https://link.segmentfault.com/?enc=OyXnPCImdVXKZ%2B0%2FGMSbbg%3D%3D.TJckMUgOAaI7%2Bdyk85J%2BCVtT1HQDN%2Bo2J7GuQDg5d30vBhs1r%2BjA279GCQi8cHk6" rel="nofollow" target="_blank">https://platform.deepseek.com/api_keys</a></p><p>截图：</p><p><img width="723" height="359" referrerpolicy="no-referrer" src="/img/bVdndfL" alt="" title=""/></p><p>当然，需要充点两块钱，如下：</p><p><img width="723" height="516" referrerpolicy="no-referrer" src="/img/bVdndfM" alt="" title="" loading="lazy"/></p><blockquote>实际上，大模型的生成文字的token一般都不贵，笔者测算了一下，<strong>生成50篇500字的txt文，成本不到一毛钱</strong></blockquote><h3>使用express框架通过openai包调用deepseek的服务</h3><p>有了deepseek的API keys且账户有钱后，就可以在服务端调用了，通过npm安装openai这个包</p><pre><code class="json">  "dependencies": {
    "express": "^5.1.0",
    "openai": "^6.9.1"
  }</code></pre><blockquote>笔者这里使用的是express</blockquote><p>如下：</p><pre><code class="js">import express from 'express';
import OpenAI from "openai";

// 初始化 OpenAI
const openai = new OpenAI({
    baseURL: 'https://api.deepseek.com',
    apiKey: 'sk-27cae***********************1093', // 换成自己的
});

const systemContent = `系统级提示词高权重，用于规范限定回答内容`;

app.post('/api/chat', async (req, res) =&gt; {
    try {
        const { content } = req.body;

        if (!content) {
            return res.status(400).json({ error: '请提供要学习的内容' });
        }

        const completion = await openai.chat.completions.create({
            messages: [
                { role: "system", content: systemContent },
                { role: "user", content: content },
            ],
            model: "deepseek-chat",
        });
        const result = completion.choices[0]?.message?.content;
        res.json({ result });
    } catch (error) {
        console.error('API 调用失败:', error);
        res.status(500).json({ error: error.message || 'API 调用失败' });
    }
});</code></pre><h3>编写系统级提示词</h3><p>上述的systemContent可以根据实际业务情况，进行适当编写</p><pre><code class="js">const systemContent =
`
你是一个热爱中国的优秀员工。
所在的公司是xxx。
所在的部门是yyy。
仔细阅读用户提供的学习内容材料，并返回一段学习学后感。

格式要求：
- 纯文本格式，不要使用markdown
- 字数控制在400-600个字符之间
- 使用第一人称"我"来叙述

内容要求：
1. 学后感要简洁明了，逻辑清晰
2. 内容要符合实际
3. 要体现...
4. 要结合学习材料的具体内容，不能泛泛而谈
5. 要实事求是，言之有物，避免空话套话
6. 注意分段落

多样性要求：
- 每次生成都要使用不同的表达方式、不同的角度和不同的案例
- 避免使用重复的词语、句子和段落结构
- 确保每次生成的学后感都是全新的内容

重要提醒：
- 返回的内容必须符合中国的法律法规
- 要结合学习材料的具体内容进行深入思考
- 不要使用缓存！
`;</code></pre><h3>快速理解什么是提示词？</h3><ul><li>ai交互的核心就是系统级提示词（System Prompt）和用户提示词（User Prompt）</li></ul><p>如下表</p><table><thead><tr><th>维度</th><th>系统级提示词</th><th>用户提示词</th></tr></thead><tbody><tr><td>生效范围</td><td>全局生效（所有对话轮次）</td><td>仅当前 / 指定轮次生效</td></tr><tr><td>优先级</td><td>更高（覆盖用户提示词冲突项）</td><td>服从系统规则</td></tr><tr><td>核心目的</td><td>设定规则与角色</td><td>提出具体问题 / 需求</td></tr><tr><td>可见性</td><td>通常对用户不可见（后台配置）</td><td>用户主动输入，完全可见</td></tr></tbody></table><p>比如，有如下场景</p><ul><li><strong>客服智能问答场景</strong>：系统提示词定义 “语气友好、优先解决用户问题、无法解答时引导转人工”，用户仅需提问 “我的订单为什么没发货”，AI 就会按该规则响应；</li><li><strong>AI创作场景</strong>：系统提示词设定 “风格为悬疑短篇、字数 500 字以内、结尾留悬念”，用户仅需说 “以雨夜为背景写一个故事”，AI 的输出就会贴合这些要求。</li></ul><blockquote>系统级提示词有点像cosplay的身份角色背景设定...</blockquote><p>所以，上述systemContent才会定义成为那样的</p><p>现在，有了接口了<code>app.post('/api/chat', async (req, res) =&gt; { ... })</code></p><p>这样的话，前端就可以做对应请求数据，下载操作了...</p><blockquote>篇幅有限，不继续赘述</blockquote><h2>总结</h2><ul><li>看完本文，大家可记住这样一句话：<strong><code>所有重复的、没有技术含量的办公操作，都可以考虑使用AI进行提效</code></strong></li><li>此外，大家可以思考一下，如何能把公司的一些业务场景给抽象出来，使用AI进行高效解决问题？</li></ul><blockquote>手工创作不易，感谢大家支持鼓励☺️☺️☺️</blockquote>]]></description></item><item>    <title><![CDATA[CRM软件是什么？功能解析+选型指标一篇]]></title>    <link>https://segmentfault.com/a/1190000047438943</link>    <guid>https://segmentfault.com/a/1190000047438943</guid>    <pubDate>2025-11-30 19:04:29</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>CRM软件不是“高大上的通讯录”，而是把线索变订单、把订单变复购的“印钞机”。从客户首次点击官网，到售后回访，所有数据若能自动沉淀、智能提醒、实时分析，销售人均产能可立刻提升30%。下文将用Zoho CRM实战界面，带你先弄清“CRM软件是什么”，再给出5条“好坏判断标尺”，让选型不再踩坑。<br/><img width="431" height="287" referrerpolicy="no-referrer" src="/img/bVdndco" alt="" title=""/><br/>一、什么是CRM软件？<br/>CRM软件，即客户关系管理软件，是一种帮助企业管理和优化客户关系的工具。其核心目的是通过全面了解客户需求与行为，提升客户满足度和忠诚度。CRM软件通过集成客户信息、分析数据和自动化业务流程，帮助企业实现以下目标：</p><ol><li>集中客户数据<br/>CRM软件能够收集并整合来自各种渠道的客户数据，包括电子邮件、电话记录、社交媒体互动等。这种数据集成使企业能够全面了解客户行为和偏好。</li></ol><p>Zoho CRM支持多渠道客户数据整合，包括电子邮件、社交媒体、电话和网站交互，帮助企业实时掌握客户动态。</p><ol start="2"><li>改善客户互动<br/>通过CRM，企业可以更好地管理客户沟通，提升客户服务质量。软件通常配备自动化功能，如邮件提醒、客户预定和问题跟进，增强客户体验。</li></ol><p>Zoho CRM的销售自动化工具可以帮助企业跟进客户互动，并通过AI助手Zia提供智能提醒和建议。</p><ol start="3"><li>增强销售和市场营销<br/>CRM软件提供深入的数据分析，帮助企业识别销售机会、制定更精准的市场策略，并提高销售转化率。</li></ol><p>Zoho CRM提供销售漏斗管理、预测分析和营销自动化功能，帮助企业优化销售和营销流程。</p><p>二、CRM软件的核心功能<br/>了解CRM软件的功能模块是判断其优劣的第一步。尽管不同的软件平台提供的功能可能不同，大多数CRM系统都具备以下核心功能：</p><ol><li>客户管理<br/>提供关于客户的完整概览，包括联系信息、交互历史、购买记录等，帮助企业个性化客户服务。</li></ol><p>Zoho CRM功能：Zoho CRM的360度客户视图整合客户的所有数据，帮助企业更好地理解和服务客户。</p><ol start="2"><li>销售管理<br/>包括销售漏斗管理、销售预测、报告生成等功能，支持销售团队更高效地管理交易和客户关系。</li></ol><p>Zoho CRM功能：Zoho CRM提供可视化的销售管道，并通过AI助手Zia预测销售趋势，优化销售策略。</p><ol start="3"><li>市场营销自动化<br/>通过自动化电子邮件营销、广告活动跟踪等功能，帮助营销团队设计和执行更具针对性的营销活动。</li></ol><p>Zoho CRM功能：Zoho CRM与Zoho Campaigns无缝集成，支持跨渠道营销活动的自动化管理。</p><ol start="4"><li>客户服务与支持<br/>提供服务请求管理、客户自助服务门户和实时聊天支持等工具，提高客户服务效率。</li></ol><p>Zoho CRM功能：Zoho CRM与Zoho Desk集成，帮助企业高效管理客户服务请求并提升客户满意度。</p><ol start="5"><li>报告与分析<br/>提供数据可视化工具和定制化报告功能，帮助企业分析市场趋势、客户行为和销售绩效。</li></ol><p>Zoho CRM功能：Zoho CRM支持自定义仪表板和实时报告，帮助企业快速获取关键业务洞察。</p><p>三、如何判断CRM软件的好坏？<br/>在评估CRM软件的好坏时，应从以下几个方面进行全面考量：</p><ol><li>功能与需求匹配<br/>企业需要明确自身的业务需求，并评估CRM软件功能是否与之匹配。有些软件适合大型企业的复杂需求，而另一些则更适合中小企业。</li></ol><p>Zoho CRM优势：Zoho CRM提供多种版本（如免费版、专业版和企业版），适合不同规模和需求的企业。</p><ol start="2"><li>用户友好性<br/>软件应具备直观、易于操作的界面，提供简便的导航和清晰的功能分类。此外，丰富的在线培训资源和客服支持也是评估用户友好性的重要因素。</li></ol><p>Zoho CRM优势：Zoho CRM提供简洁的界面设计和丰富的在线学习资源（如Zoho Academy），并支持多语言操作。</p><ol start="3"><li>集成与兼容性<br/>选择能够与现有系统无缝集成的CRM软件，可以大大提升整体工作效率。此外，关注软件对移动设备的兼容性。</li></ol><p>Zoho CRM优势：Zoho CRM支持与第三方工具（如Gmail、Slack、QuickBooks等）集成，同时提供强大的API接口，便于企业自定义扩展。</p><ol start="4"><li>数据安全性<br/>CRM系统存储了大量的客户敏感信息，因此，评估软件的数据加密方式、访问权限管理和备份选项尤为重要。</li></ol><p>Zoho CRM优势：Zoho CRM采用企业级安全措施，包括数据加密、双因素认证和定期备份，确保客户数据的安全性。</p><ol start="5"><li>可扩展性<br/>随着业务的发展，企业对CRM软件的需求可能会变化。因此，选择一款具有扩展能力的软件系统至关重要。</li></ol><p>Zoho CRM优势：Zoho CRM支持模块化设计，并提供丰富的第三方插件和扩展功能，适应企业未来的增长需求。</p><ol start="6"><li>成本效益<br/>企业需结合价格与收益评估软件的性价比，包括许可证费用、实施成本、培训费用和后续维护成本。</li></ol><p>Zoho CRM优势：Zoho CRM以其灵活的定价模式和高性价比受到广泛好评，尤其适合预算有限的中小企业。</p><p>四、如何选择适合的CRM供应商？<br/>除了软件本身，供应商的资质和信誉也是选择过程中的重要考量因素。企业应优先选择拥有良好市场口碑和丰富行业经验的供应商。以下是选择供应商时需要关注的关键点：</p><ol><li>技术支持与服务<br/>确保供应商提供及时的客户支持，包括在线帮助、电话支持和技术指导。</li></ol><p>Zoho CRM优势：Zoho CRM提供24/7的全球技术支持，并拥有本地化服务团队，帮助企业快速解决问题。</p><ol start="2"><li>开发路线图<br/>了解供应商的产品更新计划和长期发展方向，确保软件能够满足未来需求。</li></ol><p>Zoho CRM优势：Zoho CRM定期推出新功能和更新，保持产品的竞争力和创新性。</p><ol start="3"><li>客户评价与案例<br/>查看其他企业的使用案例和评价，了解供应商在实际应用中的表现。</li></ol><p>Zoho CRM优势：Zoho CRM在全球拥有超过80000家客户，涵盖多种行业，具有广泛的市场认可度。</p><p>选CRM的本质是选增长杠杆。Zoho CRM提供从免费版到企业版的模块化套餐，AI销售预测、360°客户视图、营销自动化、API开放接口一次给齐，14天全功能试用零门槛。现在就注册，把文内的5条评估标准立刻套用在真实数据上，让下一封跟进邮件自带成交概率，下一次客户拜访自带采购热度——增长从此可量化、可复制、可持续。</p>]]></description></item><item>    <title><![CDATA[CRM信息系统怎么查公司运营数据？实操步]]></title>    <link>https://segmentfault.com/a/1190000047438953</link>    <guid>https://segmentfault.com/a/1190000047438953</guid>    <pubDate>2025-11-30 19:03:51</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>还在 Excel 里手动拼接销售、市场、客服三张表？数据晚一天，决策慢一拍。CRM 信息系统的真正价值，是让你“一键”看清公司运营全貌：线索转化、订单进度、客户活跃度、复购预测实时推送到仪表盘。下文拆解高效获取运营数据的 5 步流程，并全程示范 Zoho CRM 的 AI 采集、智能标签、实时仪表盘，让 2 人团队也能拥有大数据部门的决策速度。<br/><img width="512" height="340" referrerpolicy="no-referrer" src="/img/bVdndcy" alt="" title=""/><br/>一、CRM信息系统的核心功能<br/>CRM信息系统的主要功能是帮助企业管理客户关系，但其作用远不止于此。以下是CRM系统的五大核心功能模块：</p><p>客户数据管理<br/>CRM系统能够集中存储客户的基本信息、交易记录、沟通历史等数据，形成完整的客户档案。这种集中化管理不仅提高了数据的可访问性，还能避免信息孤岛的出现。</p><p>销售流程管理<br/>CRM系统可以帮助企业跟踪销售线索、商机和订单状态，优化销售流程。例如，通过销售漏斗分析，企业可以清楚地了解每个阶段的转化率，从而调整销售策略。</p><p>市场营销自动化<br/>通过CRM系统，企业可以实现营销活动的自动化管理，如邮件营销、社交媒体推广和活动跟踪等。这不仅提高了营销效率，还能通过数据分析评估活动效果。</p><p>客户服务支持<br/>CRM系统能够记录客户的服务请求、投诉和反馈，帮助企业快速响应客户需求，提升客户满意度。</p><p>数据分析与报告<br/>CRM系统内置的数据分析工具可以生成各种报表和图表，帮助企业洞察运营状况。例如，Zoho CRM提供了强大的数据分析功能，支持自定义报表和实时仪表盘，帮助企业快速获取关键数据。</p><p>二、如何通过CRM系统高效获取公司运营数据？<br/>要通过CRM系统高效获取公司运营数据，需要从以下几个关键步骤入手：</p><ol><li>明确数据需求<br/>在使用CRM系统之前，企业需要明确自身的数据需求。例如：</li></ol><p>销售团队需要了解客户的购买行为和订单状态；<br/>市场团队需要分析营销活动的转化效果；<br/>管理层需要掌握整体的业务运营状况。<br/>明确需求后，企业可以根据目标设置CRM系统中的数据字段和报表模板。</p><ol start="2"><li>数据的全面采集<br/>CRM系统的核心在于数据的全面性和准确性。以下是几种常见的数据采集方式：</li></ol><p>手动录入：销售人员或客服人员将客户信息录入系统。<br/>自动化采集：通过网站表单、社交媒体、电子邮件等渠道自动采集客户数据。<br/>第三方集成：CRM系统与其他工具（如ERP、电子商务平台）集成，实现数据的自动同步。例如，Zoho CRM支持与多种第三方工具无缝集成，确保数据采集的全面性。</p><ol start="3"><li>数据的清洗与整理<br/>在数据采集完成后，企业需要对数据进行清洗和整理，确保数据的准确性和一致性。CRM系统通常提供数据去重和清洗功能，帮助企业优化数据质量。</li><li>数据的分类与标签化<br/>为了便于分析和使用，企业可以通过CRM系统对数据进行分类和标签化。例如：</li></ol><p>按客户行业、地域、规模等维度分类；<br/>为客户添加“高价值客户”“潜在客户”等标签。<br/>Zoho CRM的“高级过滤器”和“智能标签”功能可以帮助企业快速对数据进行分类和筛选。</p><ol start="5"><li>数据的可视化与分析<br/>高效的数据获取离不开直观的可视化工具。CRM系统通常内置仪表盘和报表功能，帮助企业快速生成数据分析结果。例如，Zoho CRM的仪表盘支持实时数据更新，企业可以随时查看销售业绩、客户增长趋势等关键指标。</li></ol><p>三、CRM系统在公司运营数据获取中的实际应用场景</p><ol><li>销售团队的应用<br/>销售团队可以通过CRM系统获取以下关键数据：</li></ol><p>销售漏斗分析：了解每个销售阶段的客户数量和转化率。<br/>客户行为数据：跟踪客户的购买历史和沟通记录，预测未来需求。<br/>业绩报表：实时查看团队和个人的销售业绩。<br/>例如，Zoho CRM的“销售预测”功能可以帮助销售经理预测未来的收入，并根据数据调整销售策略。</p><ol start="2"><li>市场团队的应用<br/>市场团队可以通过CRM系统获取以下数据：</li></ol><p>营销活动效果分析：评估邮件营销、广告投放等活动的转化率。<br/>潜在客户数据：通过表单和社交媒体采集潜在客户信息。<br/>客户画像：基于客户数据生成精准的客户画像，优化营销策略。<br/>Zoho CRM的“营销自动化”模块支持多渠道数据采集和分析，帮助市场团队提升工作效率。</p><ol start="3"><li>管理层的应用<br/>管理层可以通过CRM系统获取以下数据：</li></ol><p>业务运营数据：全面了解公司的销售额、客户增长率等关键指标。<br/>团队绩效数据：评估各部门和团队的工作效率。<br/>战略决策支持：基于数据分析结果制定长期发展战略。<br/>Zoho CRM的“高级分析”功能支持跨部门数据整合，帮助管理层全面掌握企业运营状况。</p><p>四、选择合适的CRM系统：Zoho CRM的优势<br/>在众多CRM系统中，Zoho CRM因其功能全面、易用性强和性价比高而备受企业青睐。以下是Zoho CRM的几大优势：</p><p>功能全面<br/>Zoho CRM涵盖了客户管理、销售自动化、营销自动化、数据分析等核心功能，能够满足不同规模企业的需求。</p><p>高度可定制化<br/>企业可以根据自身需求自定义字段、工作流和报表，确保系统与业务流程高度契合。</p><p>多渠道集成<br/>Zoho CRM支持与电子邮件、社交媒体、电话系统等多种渠道集成，实现数据的无缝流转。</p><p>强大的数据分析能力<br/>Zoho CRM内置多种数据分析工具，支持实时仪表盘、自定义报表和高级分析，帮助企业快速获取关键数据。</p><p>高性价比<br/>相较于其他CRM系统，Zoho CRM的价格更具竞争力，适合中小企业和初创公司。</p><p>五、常见问答FAQ<br/>FAQ 1: CRM系统如何帮助企业高效获取运营数据？<br/>CRM系统通过集中化管理客户信息、自动化采集数据、分类与标签化、以及内置的数据分析工具，帮助企业高效获取运营数据。例如，CRM系统可以自动采集客户的沟通记录、购买行为等信息，并通过仪表盘和报表功能直观呈现销售业绩、客户增长趋势等关键指标，从而支持企业的决策和优化流程。</p><p>FAQ 2: Zoho CRM在数据分析方面有哪些优势？<br/>Zoho CRM在数据分析方面具有以下优势：</p><p>实时仪表盘：支持实时更新数据，帮助企业随时掌握运营状况。<br/>自定义报表：企业可以根据需求生成个性化的报表，满足不同部门的分析需求。<br/>高级分析功能：支持跨部门数据整合，帮助管理层全面了解业务运营情况。这些功能使Zoho CRM成为企业获取和分析运营数据的强大工具。<br/>FAQ 3: 如何选择适合企业的CRM系统？<br/>选择CRM系统时，企业需要考虑以下几点：</p><p>功能需求：确保CRM系统涵盖客户管理、销售自动化、数据分析等核心功能。<br/>可定制性：选择能够根据企业需求自定义字段、工作流和报表的系统。<br/>集成能力：优先选择支持与其他工具（如邮件、社交媒体、ERP系统）无缝集成的CRM系统。<br/>性价比：根据企业规模和预算选择合适的CRM系统，例如Zoho CRM以其高性价比和全面功能成为中小企业的理想选择。<br/>六、总结<br/>数据驱动不是口号，而是“实时可看、可导、可预测”。立即免费试用 Zoho CRM：15 天全功能开放，自动同步邮件、社媒、广告表单等 20 + 渠道数据，5 分钟生成可视化仪表盘，把销售漏斗、客户画像、复购预警一次看全。今天注册，让下一次复盘会议不再依赖“我觉得”，而是打开 Zoho CRM 直接说“数据在这里”。</p>]]></description></item><item>    <title><![CDATA[全球贸易挑战？进出口企业2025业务流程]]></title>    <link>https://segmentfault.com/a/1190000047439005</link>    <guid>https://segmentfault.com/a/1190000047439005</guid>    <pubDate>2025-11-30 19:03:12</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>2025 年，关税一夜调整、汇率瞬间跳水、航线突然中断……全球贸易的“灰犀牛”接踵而来。面对政策、供应链、合规三座大山，进出口企业只有把流程压缩到最短、把账算到最细，才能挤出利润。本文给出一张“业务流程优化路线图”，并实测演示：如何用 Zoho Books 一套系统搞定多币种报价、自动算税、库存联动，让订单到收款全程提速 50%。<br/><img width="500" height="328" referrerpolicy="no-referrer" src="/img/bVdnddk" alt="" title=""/><br/>一、全球贸易挑战：进出口企业面临的五大痛点</p><ol><li>关税与政策变化<br/>全球贸易政策的频繁调整，如关税壁垒、出口管制等，增加了企业的运营成本和合规难度。企业需要实时掌握政策动态，并快速调整策略以规避风险。</li><li>供应链不稳定<br/>地缘政治、自然灾害和疫情等因素导致供应链中断风险上升。企业需要建立灵活的供应链管理体系，确保货物按时交付。</li><li>汇率波动<br/>汇率的剧烈波动直接影响进出口企业的利润。企业需要通过有效的财务管理工具来对冲汇率风险，优化成本控制。</li><li>合规与数据安全<br/>各国对数据安全和隐私保护的要求日益严格，企业需要确保业务流程符合当地法规，避免因违规而遭受处罚。</li><li>客户与市场变化<br/>消费者需求和市场趋势的变化要求企业快速响应，调整产品策略和销售渠道。</li></ol><p>二、优化业务流程：进出口企业的突围之道<br/>面对上述挑战，进出口企业需要从以下几个方面优化业务流程：</p><ol><li>数字化转型与自动化<br/>通过引入ERP、财务管理软件等工具，实现业务流程的自动化，减少人工错误，提高效率。例如，Zoho Books智能外贸管理工具可以帮助企业一键生成报价单、跟踪账款、管理库存，从而简化财务流程。</li><li>供应链可视化与协作<br/>利用供应链管理技术，实时监控物流和库存状态，与供应商和客户保持高效协作。</li><li>数据驱动的决策<br/>通过数据分析工具，企业可以预测市场趋势、优化库存水平，并制定更精准的业务策略。</li><li>合规与风险管理<br/>建立完善的合规体系，确保业务流程符合国际贸易法规。</li><li>客户关系管理<br/>通过CRM系统提升客户服务质量，增强客户忠诚度。Zoho Books与Zoho CRM的无缝集成，帮助企业实现从订单到收款的全流程管理。</li></ol><p>三、Zoho Books：助力企业更好地应对全球化挑战<br/>在全球化浪潮中，企业面临着诸多管理挑战，如多语言多币种交易、国际税务合规、供应链协同等。Zoho Books作为一款功能全面的外贸管理工具，为企业提供了一站式的解决方案，助力企业轻松应对全球化管理难题。</p><p>产品主要功能</p><ol><li>多语言多币种支持<br/>Zoho Books支持22种语言界面和180种货币自动转换。这意味着企业无论在哪个国家开展业务，都可以使用当地语言和货币进行交易，无需担心语言和货币转换问题。例如，一家中国企业在与沙特阿拉伯地区的客户进行交易时，可以轻松生成当地电子发票，并转换为人民币进行记账，大大简化了跨境交易的流程，方便与国内外客户对账。</li><li>国际合规性保障，降低税务风险<br/>Zoho Books提供了15个特色地区版本，可以生成符合多国标准的财务报表。例如，一家德国的跨境电商企业，在使用Zoho Books后，系统会根据德国的税务政策自动计算增值税，并生成符合要求的税务申报报表，避免因税务申报错误而面临的风险。</li><li>强大的进销存管理功能，优化供应链协同<br/>Zoho Books提供从采购、销售到出库的全流程管理，帮助企业优化供应链管理。企业可以在系统中创建采购订单，详细记录供应商信息、采购商品的种类、数量、价格等，并实时跟踪采购订单的状态。在销售方面，企业可以生成专业的销售报价单、销售订单，并开具付款通知单，同时跟踪客户的付款情况，提高企业的资金回笼速度。此外，Zoho Books还支持多仓库库存管理，实时监控库存状态，避免库存积压或短缺。</li><li>数据安全与隐私保护，保障企业信息安全<br/>Zoho Books采用多重加密技术，保障企业数据在传输和存储过程中的安全性。同时，系统提供精细的用户权限管理，企业可以根据员工的职责和工作需要，为不同的员工分配不同的操作权限。例如，财务人员只能查看和操作财务相关的数据，销售人员只能查看和管理客户及销售数据。这样，即使企业内部人员也无法随意访问和篡改其他部门的数据，有效保护了企业的数据安全和隐私。</li><li>灵活的集成与扩展，满足个性化需求<br/>Zoho Books具有高度的灵活性和可扩展性，能够与Zoho CRM、Inventory等20+应用深度集成，支持API自定义开发，满足企业的个性化需求。例如，企业可以将Zoho Books与电商平台如亚马逊、eBay等无缝集成，实现订单的自动同步和处理，提高运营效率。此外，Zoho Books还支持与其他第三方应用的集成，如支付网关PayPal、Stripe等，进一步拓展企业的业务范围。</li><li>实时数据分析与商业智能，辅助科学决策<br/>Zoho Books整合各部门数据，生成可视化报表，如销售趋势、成本分析等，为企业战略决策提供实时支持。企业可以通过这些报表清晰地了解业务状况，及时发现问题并调整策略，从而在激烈的市场竞争中占据优势。</li><li>易用性强，快速上手<br/>Zoho Books的界面设计简洁直观，操作方便，无需专业的IT技能即可上手。企业员工可以通过简单的培训，快速掌握软件的使用方法，提高工作效率。此外，Zoho Books还提供了丰富的帮助文档和在线支持，帮助企业解决使用过程中遇到的问题。</li><li>高性价比，适合不同规模企业<br/>Zoho Books提供从免费版到旗舰版6种订阅方案，年费最低0元，最高仅16,800元，无需硬件投入，云端即开即用。无论是小微企业、跨境电商还是中大型企业，都可以根据自身需求选择合适的版本，实现高效管理。</li></ol><p>结语<br/>贸易风浪不会停，但工具可以换。把 Excel 和邮件升级为 Zoho Books，用 22 种语言、180 种货币、15 国税表把全球订单装进同一个仪表盘，实时算清利润、库存与合规风险——2025，让技术替你扛住不确定性，把精力留给谈客户、抢市场。</p>]]></description></item><item>    <title><![CDATA[多人协作云盘有什么用？秒懂 遭老罪的程序]]></title>    <link>https://segmentfault.com/a/1190000047439039</link>    <guid>https://segmentfault.com/a/1190000047439039</guid>    <pubDate>2025-11-30 19:02:14</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>文件传来传去、版本混乱、同事出差就“断档”？在远程办公 + 敏捷协作成为标配的今天，一套靠谱的多人共享云盘才是团队的“中枢神经”。下文 7 大功能 + 4 大场景拆解，教你用 Zoho 网盘把分散的资料变成“一键同步、权限分明、实时协作”的数字资料室，让效率立刻提速。<br/><img width="658" height="350" referrerpolicy="no-referrer" src="/img/bVdnddW" alt="" title=""/><br/>一、什么是多人共享云盘？<br/>多人共享云盘允许多人在线访问、编辑和更新存储在云端的文件。它解决了传统文件管理中因设备受限、数据分散等问题带来的困扰。</p><p>相比于作为个人存储工具的传统云盘，多人共享云盘的设计初衷更像是“数字化的文件资料室”，主要致力于满足团队和跨部门协作的环境需求。以下是两者的主要区别：</p><p>二、多人共享云盘的核心功能</p><ol><li>文件存储与管理<br/>多人共享云盘提供了一个安全、直观、易管理的中央存储空间，用于集中存放所有团队成员需要的文件或资料。从权责明确的文件夹层级管理，到容量几乎无限的云端扩展，它彻底摆脱了传统本地存储常见的容量不足和数据丢失的风险。</li></ol><p>更重要的是，文件存储环境统一化后，团队沟通成本显著降低。以往那种“这个文件在某某人的电脑里”的情况不再出现，因为所有相关文件都能方便地存取，这就是现代化团队协作的基础。</p><ol start="2"><li>文件实时同步<br/>在多人协作中，最令人头疼的事情之一就是文件版本冲突。每个人编辑一个文件的不同部分，却因不能实时同步而带来混乱。而多人共享云盘正式解决了这一难题。</li></ol><p>通过实时同步技术，文件更新可以即刻传递给所有相关成员，无论相隔多远，他们所看到的永远都是最新版本。更值得一提的是，优秀的云盘还提供文件历史版本功能，当某次修改出现问题时，可以随时回滚到之前的状态，完美避免低效的重复劳动。</p><ol start="3"><li>文件共享与权限控制<br/>一个优秀的多人共享云盘，绝不仅仅是简单的“存盘工具”，它还能通过精准的团队权限管理，保障文件共享的安全性和灵活性：</li></ol><p>支持多种共享方式：生成共享链接、直接邀请团队成员或内部/外部协作方加入文件夹。<br/>权限配置清晰：是否允许下载？能否编辑？或者只限于查看权限？这些都能轻松设置。<br/>这种自由又安全的共享机制，不仅加速了团队源文件的流转，同时也极大地避免了因误操作或无意泄露而带来的风险。</p><ol start="4"><li>协作与实时编辑<br/>多人共享云盘集成了协作所需的在线工具与沟通功能。例如，团队中的设计稿件可以直接通过云盘实现多人员的在线批注与修改；文档可以由团队实时编辑，完成后无需再反复通过邮件发送版本。这种无缝的协作体验，不但提升了工作效率，也增强了团队默契。</li></ol><p>此外，通知提醒功能更是增添了一层协作便利。无论是文件有更新、评论的通知，还是协作任务的总结提醒，都能有效保障信息不会因为某位团队成员稍有疏忽而掉链子。</p><ol start="5"><li>数据安全和备份<br/>无论是为数量庞大的消费者，还是运营着敏感资料的企业，多人共享云盘都必须把数据安全放在首位。顶尖的云盘利用了跨节点存储、数据加密技术以及权限审计功能，给予用户全面的安全保障：</li></ol><p>即使本地设备损坏，重要文件也能通过云端备份复原。<br/>严格的文件加密保证隐私——即使黑客入侵，未经授权的用户也无法解读文件内容。<br/>专业的定期备份服务减少因误删或损坏而产生的损失风险。</p><ol start="6"><li>跨设备与多平台支持<br/>现代工作场景愈发多样化，而多人共享云盘的最大优势之一，就是“无缝跨平台”。从 PC 到手机，再到平板，每种设备上的数据都能轻松同步读取，实现团队文档管理。此外，它支持多种格式的文件直接在线预览，省去了安装繁琐软件的麻烦。</li><li>文件版本控制<br/>设计方案反复调整？文档协作频繁修改？无需担心邮件又点错附件，或者一不小心覆盖了旧版本。多人共享云盘提供了详尽的版本记录与单独修改追踪功能。当你需要回滚到任何历史版本，只需轻轻一键。</li></ol><p>三、多功能的多人共享云盘有哪些应用场景？<br/>在熟悉了产品的核心功能后，我们可以具体探讨它在实际工作场景中的所发挥的作用：</p><ol><li>提升团队协作效率<br/>不论是初创团队，还是大型企业，团队协作效率一直是关键指标。共享云盘通过文件集中管理和在线协作功能，让团队能快速获取资料、节省重复操作时间，同时避免沟通过程中的数据丢失或重复。</li><li>适应远程和跨地域协作<br/>随着远程办公的普及，多人共享云盘几乎成为了远程协作的标配。无论团队成员身处异国他乡，抑或极端天气无法回到办公室，只要能接入互联网，工作就可以继续开展。</li><li>项目/任务管理辅助<br/>共享云盘还充当了项目管理的得力助手：所有项目资料集中存放于项目专属文件夹，团队成员一目了然。不但便于梳理和归档，远程同步和权限管理也让团队能高效完成所有进度关键点。</li><li>降低 IT 维护成本<br/>传统文件服务器的运营包括高昂的硬件成本和维护支出。而共享云盘的云端存储模式，让企业只需为实际需求支付费用，同时不必担忧设备损坏或数据丢失的问题。</li></ol><p>四、如何选择合适的多人共享云盘？<br/>团队需求匹配：优先选择能满足协作需求的功能，比如文件实时同步和多角色权限控制。<br/>性价比：在性价比上下功夫，根据预算谨慎选择价格计划、存储空间和附加功能。<br/>数据安全性：确认提供服务的厂商符合行业安全规范（如 GDPR 等），查看其技术中的加密与备份能力。<br/>兼容性：确保工具可以跨设备、跨操作系统无缝运行，避免额外增加工作阻碍。<br/>五、总结：让协作更简单、更高效<br/>协作时代，选错工具就是最大的成本。Zoho 网盘用无限扩容、银行级加密、在线实时编辑和跨平台秒同步，把“文件孤岛”变成“团队大脑”。现在注册，免费体验 30 天——把重复沟通、版本冲突、数据泄露统统留在昨天，让团队从今天开始“一盘”搞定所有协作。</p>]]></description></item><item>    <title><![CDATA[电子邮件营销属于什么模式？一文看懂EDM]]></title>    <link>https://segmentfault.com/a/1190000047439044</link>    <guid>https://segmentfault.com/a/1190000047439044</guid>    <pubDate>2025-11-30 19:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>还在把“邮件群发”当短信轰炸？真正的电子邮件营销，是一场数据驱动的“一对一对话”——谁感兴趣、谁点过哪些商品、谁住在哪个时区，统统决定下一秒要不要把邮件送进 TA 的收件箱。本文用 Zoho Campaigns 实操拆解：从名单细分、行为触发到 A/B 测试，一步步把 EDM 做成可量化、可复利增长的自动化营销模式。<br/><img width="512" height="340" referrerpolicy="no-referrer" src="/img/bVdndd1" alt="" title=""/><br/>电子邮件营销的基本定义<br/>电子邮件营销是一种通过电子邮件与目标受众进行沟通和推广产品或服务的数字营销策略。这个过程通常包括创建邮件列表，撰写引人入胜的内容，以及针对不同受众进行个性化的邮件推送。其主要目的是通过多方面的接触和互动，增强品牌知名度、推动销售增长，并提高客户忠诚度。</p><p>Zoho Campaigns 提供了强大的工具来帮助企业轻松创建和管理邮件列表，并通过自动化功能实现个性化的邮件推送。</p><p>电子邮件营销的模式特征<br/>双向互动模式<br/>电子邮件营销不仅是信息的单方面传递，更是企业与消费者之间的双向沟通。当企业发送促销内容、新闻通讯或调查问卷时，用户可以通过回复邮件、点击链接等方式给予反馈。这种双向互动使得企业能够深入了解客户需求，针对性地调整营销策略。</p><p>精准细分与个性化营销<br/>相较于传统广告的大众传播方式，电子邮件营销具备精准细分的能力。企业可以根据用户的地理位置、消费偏好、购买历史等信息来细分其邮件列表，并定制个性化的邮件内容。这种个性化的接触方式大大提高了营销信息的相关性和有效性。</p><p>使用 Zoho Campaigns，企业可以轻松地根据用户数据进行细分，并创建高度个性化的邮件内容，从而提高营销活动的效果。</p><p>以数据驱动为核心<br/>电子邮件营销的有效运营离不开对数据的深入分析。通过 A/B 测试、用户行为追踪、开信率和点击率分析，企业能够不断优化邮件内容和发送策略，从而更好地满足客户需求，实现销售转化。</p><p>电子邮件营销的实施步骤<br/>实施电子邮件营销策略通常包括几个关键步骤，从创建邮件列表到分析评估整个过程都需要精细化的操作。</p><p>创建有效的邮件列表<br/>首先，企业需要构建一个合规的电子邮件列表，确保潜在客户的自愿参与。以下是构建邮件列表的一些方法：</p><p>网站注册表单：在官网提供一个简单的注册表单，让用户自愿订阅。<br/>赠送免费资源：提供电子书、白皮书或折扣码作为订阅奖励，吸引用户注册。<br/>线上线下的活动注册：通过活动吸引用户参与并建立联系，这也是积累邮件列表的有效方式。<br/>精心设计邮件内容<br/>一封成功的营销邮件需要具备吸引力和实用性：</p><p>主题行设计：主题行是用户决定开启邮件的首要因素，需简明扼要且富有吸引力。<br/>内容编排：内容要简洁明了，引导用户逐步了解企业信息和优惠内容。<br/>明确的行动召唤：在邮件中增设明确的行动指示（CTA），引导用户完成如注册、购买等行为。<br/>个性化内容推送<br/>邮件内容的个性化设计是电子邮件营销成功的关键。根据用户购买习惯、地理位置甚至是设备使用习惯进行个性化定制，确保邮件对每一位用户都具有高度相关性。</p><p>Zoho Campaigns 的自动化功能可以帮助企业根据用户行为自动发送个性化邮件，提高用户参与度和转化率。</p><p>分析与优化<br/>通过数据的收集和分析，持续优化电子邮件营销策略，以提高成效。关键的分析数据包括开信率、点击率、转化率和退订率等。</p><p>什么将电子邮件营销提升至一个全新高度？<br/>自动化技术<br/>现代电子邮件营销软件已经集成了强大的自动化功能，使得邮件发送过程更加高效和精确。通过制定自动化工作流程，企业可以设置在特定事件触发时自动发送邮件，例如用户注册之后的欢迎邮件、购物车遗弃后的提醒邮件等。</p><p>移动优化<br/>随着移动设备的普及，越来越多人通过手机查收电子邮件。优化邮件内容以适应各种屏幕尺寸和操作系统显得尤为重要，这不仅提升了用户体验，也显著增加了邮件的互动率。</p><p>互动和动态内容<br/>引入互动和动态元素，如视频、GIF 动画或可视化图表，能够增强邮件内容的多样性和趣味性，使得用户参与感更强。</p><p>电子邮件营销的挑战与未来<br/>尽管电子邮件营销优势明显，但其面临的挑战同样不容忽视。比如，垃圾邮件过滤的严格审查，迫使企业不断提高邮件质量；保护用户隐私的相关法律法规对收集和使用用户信息提出了更高的要求。</p><p>面对这些挑战，未来的电子邮件营销将趋向于更智能化和个性化。通过人工智能和大数据技术的支持，企业能够更深入地理解用户行为，并在合适的时间通过合适的渠道传递准确的信息。</p><p>总之，电子邮件营销已不仅仅是单纯的推广工具，而是融合了技术创新、客户关系管理和数据分析的综合平台。对于企业来说，合理有效地利用电子邮件营销，不仅能获得即时收益，更是建立长期客户关系、持续发展的重要战略。</p><p>常见问题解答（FAQ）<br/>FAQ 1: 什么是电子邮件营销，它如何帮助企业？<br/>回答：电子邮件营销是一种通过电子邮件与目标受众进行沟通和推广产品或服务的数字营销策略。它帮助企业通过创建和管理邮件列表、撰写引人入胜的内容，以及个性化的邮件推送来增强品牌知名度、推动销售增长，并提高客户忠诚度。工具如 Zoho Campaigns 可以简化这一过程，通过自动化和数据分析提高营销活动的效率和效果。</p><p>FAQ 2: 如何利用 Zoho Campaigns 实现个性化的电子邮件营销？<br/>回答：Zoho Campaigns 提供了强大的个性化功能，企业可以根据用户的地理位置、消费偏好和购买历史等信息来细分邮件列表。通过自动化功能，企业能够根据用户行为自动发送个性化邮件，例如欢迎邮件或购物车遗弃提醒邮件。这种个性化接触方式提高了邮件的相关性和用户参与度，从而提升转化率。</p><p>FAQ 3: 电子邮件营销面临哪些挑战，未来的发展趋势是什么？<br/>回答：电子邮件营销面临的主要挑战包括垃圾邮件过滤的严格审查和用户隐私保护的法律法规要求。为了应对这些挑战，未来的电子邮件营销将趋向于更智能化和个性化。通过人工智能和大数据技术，企业可以更深入地理解用户行为，并在合适的时间通过合适的渠道传递准确的信息。这将帮助企业提高邮件的质量和用户体验，确保营销活动的成功。</p><p>模式选错，再多邮件也进垃圾箱；工具选对，每封邮件都是 24 小时销售员。Zoho Campaigns 把“双向互动 + 数据细分 + 自动化”做成一键模板：名单合规收集、内容动态拼接、发送时机 AI 预测，让打开率、点击率、转化率可视化飙高。现在注册免费版，立刻把电子邮件营销升级为“会自我进化的增长模式”，下一封爆款邮件，由你亲手发出。</p>]]></description></item><item>    <title><![CDATA[GreatSQL优化技巧全解析：从硬件配]]></title>    <link>https://segmentfault.com/a/1190000047438891</link>    <guid>https://segmentfault.com/a/1190000047438891</guid>    <pubDate>2025-11-30 18:03:46</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在数据库性能优化领域，GreatSQL凭借其强大的优化器与MGR（Group Replication）集群能力，成为企业级应用的首选。本文将从硬件配置、操作系统调优、MGR集群优化、查询优化器特性四大维度，深度解析GreatSQL的性能提升策略，助力开发者突破性能瓶颈。</p><p>一、硬件配置：奠定性能基石</p><ol><li>CPU与内存：核心性能驱动<br/>CPU选择：优先采用高主频多核处理器（如Xeon Platinum系列），主频建议≥3.5GHz，核数根据业务负载动态调整。例如，MGR集群节点建议配置16核以上CPU，以支撑高并发事务处理。<br/>内存扩展：内存容量需覆盖InnoDB缓冲池（innodb_buffer_pool_size）需求，建议设置为物理内存的70%-80%。例如，64GB内存服务器可分配48GB给缓冲池，减少磁盘I/O压力。<br/>NUMA架构优化：X86架构建议关闭NUMA（numa_interleave=ON），避免内存访问延迟；ARM架构则可开启NUMA以提升多实例性能。</li><li>存储设备：I/O性能关键<br/>NVMe SSD部署：使用NVMe协议的SSD替代传统SATA SSD，将随机读写IOPS提升至百万级。例如，将数据库日志文件（binlog、redo log）存放于NVMe盘，可显著降低事务提交延迟。<br/>文件系统选择：XFS文件系统在高并发I/O场景下表现优异，其延迟分配（Delayed Allocation）机制可减少磁盘碎片，提升写入性能。</li><li>网络配置：低延迟保障<br/>网络带宽升级：MGR集群节点间建议采用万兆网络或InfiniBand，降低数据同步延迟。例如，在跨机房部署时，万兆网络可将主从复制延迟从毫秒级压缩至微秒级。<br/>MTU值调优：将网络MTU值设置为9000（Jumbo Frame），减少数据包分片，提升大事务传输效率。</li></ol><p>二、操作系统调优：释放硬件潜能</p><ol><li>内核参数优化<br/>关闭SWAP：通过swapoff -a命令永久禁用交换分区，避免内存不足时触发磁盘交换导致性能骤降。<br/>禁用透明大页（THP）：在/etc/sysctl.conf中添加vm.swappiness=0和vm.overcommit_memory=1，并执行echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled，防止OLTP型数据库因内存碎片化引发延迟。<br/>I/O调度器调整：将数据库分区的I/O调度器设置为noop或deadline，减少不必要的I/O合并，提升响应速度。</li><li>资源限制解除<br/>文件描述符限制：在/etc/security/limits.conf中设置<em> soft nofile 65535和</em> hard nofile 65535，避免因文件描述符不足导致连接失败。<br/>线程数限制：调整kernel.threads-max参数（如设置为200000），支持高并发查询场景。</li></ol><p>三、MGR集群优化：高可用与性能兼得</p><ol><li>流控模式选择<br/>关闭流控提升吞吐：在事务并发量适中的场景下，将group_replication_flow_control_mode设置为DISABLED，避免流控算法引入的性能抖动。例如，某金融客户在关闭流控后，集群TPS提升30%。<br/>动态阈值调整：若需开启流控，可将默认阈值（如group_replication_flow_control_member_quota_percent）提高至80%，平衡性能与稳定性。</li><li>从库回放并发度优化<br/>并行复制线程数：设置slave_parallel_workers为逻辑CPU核数的2倍（如32核服务器配置64个线程），加速从库数据回放。<br/>并行复制模式选择：采用LOGICAL_CLOCK模式（slave_parallel_type=LOGICAL_CLOCK），基于事务提交顺序分配并行任务，减少锁冲突。</li><li>大事务处理优化<br/>事务拆分：将单个大事务拆分为多个小事务，避免MGR队列阻塞。例如，某电商客户将每日全量数据同步拆分为每小时增量同步，集群稳定性显著提升。<br/>队列垃圾回收优化：通过调整group_replication_garbage_collection_interval参数（如设置为60秒），加速无用事务清理，释放内存资源。</li></ol><p>四、查询优化器特性：智能提升查询效率</p><ol><li>谓词下推（Predicate Pushdown）<br/>手动优化场景：当优化器未能自动下推复杂子查询条件时，可通过重写SQL手动实现。例如：<br/>sql<br/>-- 原始SQL（可能未优化）<br/>SELECT o.order_id, o.amount <br/>FROM orders o <br/>JOIN customers c ON o.customer_id = c.customer_id <br/>WHERE c.city = '上海' AND o.order_date &gt;= '2023-01-01';</li></ol><p>-- 手动优化后（将城市过滤下推至子查询）<br/>SELECT o.order_id, o.amount <br/>FROM orders o <br/>JOIN (<br/>  SELECT customer_id, customer_name <br/>  FROM customers <br/>  WHERE city = '上海'<br/>) c ON o.customer_id = c.customer_id <br/>WHERE o.order_date &gt;= '2023-01-01';<br/>此优化将数据量从全量客户表缩减至上海客户子集，连接操作效率提升50%。</p><ol start="2"><li>索引合并（Index Merge）<br/>多索引高效利用：当WHERE条件包含多个独立索引列时，优化器自动合并索引扫描结果。例如：<br/>sql<br/>-- 表结构<br/>CREATE TABLE t2 (<br/>  cc1 INT, cc2 INT, cc3 INT,<br/>  INDEX idx1(cc1), INDEX idx2(cc2), INDEX idx3(cc3)<br/>);</li></ol><p>-- 查询利用索引合并<br/>EXPLAIN SELECT * FROM t2 WHERE cc2=3 AND cc1=1 AND cc3=1;<br/>执行计划显示Using intersect(idx1,idx2)，表明优化器通过索引交集合并定位数据，避免全表扫描。</p><ol start="3"><li>半连接（Semi-Join）<br/>子查询高效执行：对于IN或EXISTS子查询，优化器自动选择最优半连接策略。例如：<br/>sql<br/>-- 子查询主键上拉示例<br/>SELECT * FROM t1 <br/>WHERE c2 IN (SELECT id FROM t2 WHERE t2.c1='b');<br/>优化器将子查询中的t2表上拉至外层，通过内连接（INNER JOIN）执行，消除重复值影响，查询速度提升3倍。</li><li>并行查询（Parallel Query）<br/>多核并行处理：通过loose-parallel_default_dop=8设置默认并行度，启用loose-force_parallel_execute=ON强制并行执行。例如，某分析查询在16核服务器上并行度设置为8后，执行时间从12秒缩短至2秒。</li></ol><p>五、实战案例：某电商平台的性能飞跃<br/>某电商平台在采用GreatSQL后，通过以下优化组合实现性能突破：</p><p>硬件升级：将数据库服务器从32核128GB内存升级至64核256GB内存，并采用NVMe SSD存储。<br/>MGR集群优化：关闭流控模式，设置并行复制线程数为128，大事务拆分为每小时增量同步。<br/>查询优化：对高频查询启用索引合并与并行查询，复杂报表查询速度提升10倍。<br/>监控告警：通过performance_schema监控慢查询，结合pt-query-digest分析瓶颈，持续迭代优化。<br/>优化后，平台日均订单处理量从500万笔提升至1200万笔，峰值TPS突破8万，且系统稳定性显著增强。</p><p>结语：优化永无止境<br/>GreatSQL的性能优化是一个系统工程，需从硬件、操作系统、集群配置、查询逻辑等多维度协同调优。开发者应结合业务场景，灵活运用本文所述技巧，并通过持续监控与压测验证优化效果。未来，随着AI与数据库技术的深度融合，GreatSQL将进一步释放性能潜力，为企业数字化转型提供更强支撑。</p>]]></description></item><item>    <title><![CDATA[征程 6 | linear 高精度输出配]]></title>    <link>https://segmentfault.com/a/1190000047438901</link>    <guid>https://segmentfault.com/a/1190000047438901</guid>    <pubDate>2025-11-30 18:02:53</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>1. 常规情况</h2><p>基础知识：</p><ol><li>考虑到模型输出位置量化损失对模型精度的影响较大，工具链推荐模型以 linear/conv 结尾，此时支持高精度 int32 输出（在 quantized.onnx 中，转定点为 int32，在前面 calib+qat 阶段都是 float32），这几乎可以做到无损。</li><li>征程 6 工具链量化 setter 模板支持自动设置高精度输出，前提是 conv 输出直接 接 dequant，不作为其他 node 的输入。</li></ol><p>输出位置结构示意图：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438903" alt="" title=""/></p><p>全流程代码如下：</p><pre><code class="Plain">import torch
from horizon_plugin_pytorch import set_march, March
set_march(March.NASH_M)
from horizon_plugin_pytorch.quantization import prepare, set_fake_quantize, FakeQuantState
from horizon_plugin_pytorch.quantization import QuantStub
from horizon_plugin_pytorch.quantization.hbdk4 import export
from horizon_plugin_pytorch.quantization.qconfig_template import (
    calibration_8bit_weight_16bit_act_qconfig_setter,
    qat_8bit_weight_16bit_fixed_act_qconfig_setter, 
    default_calibration_qconfig_setter,
    ModuleNameQconfigSetter
) 

from horizon_plugin_pytorch.quantization.qconfig import get_qconfig, MSEObserver, MinMaxObserver
from horizon_plugin_pytorch.dtype import qint8, qint16
from torch.quantization import DeQuantStub
import torch.nn as nn
from horizon_plugin_pytorch.quantization import hbdk4 as hb4
from hbdk4.compiler import convert, save, hbm_perf, visualize, compile

import torch
import torch.nn as nn

# 定义网络结构
class SmallModel(nn.Module):
    def __init__(self):
        super(SmallModel, self).__init__()
        # 第一个 Linear: 输入 [2, 100, 256] -&gt; 输出 [2, 100, 256]
        self.linear1 = nn.Linear(256, 256)
        self.layernorm = nn.LayerNorm(256)  # 对最后一维进行归一化
        self.relu = nn.ReLU()
        # 第二个 Linear: 输入 [2, 100, 256] -&gt; 输出 [2, 100, 60]
        self.linear2 = nn.Linear(256, 60)
        # 第三个 Linear: 输入 [2, 100, 60] -&gt; 输出 [2, 100, 60]
        self.linear3 = nn.Linear(60, 60)
        self.quant = QuantStub()
        self.dequant = DeQuantStub()

    def forward(self, x):
        x = self.quant(x)
        # 第一个 Linear
        x = self.linear1(x)  # [2, 100, 256]
        x = self.layernorm(x)  # [2, 100, 256]
        x = self.relu(x)  # [2, 100, 256]
        # 第二个 Linear
        y = self.linear2(x)  # [2, 100, 60]
        # 第三个 Linear
        z = self.linear3(y)
        z = self.dequant(z)
        return z

# 设置随机种子，保证每次生成的数据相同
torch.manual_seed(42)
example_input = torch.randn(2, 100, 256)
model = SmallModel()

# 前向传播
output_x = model(example_input)
print("输入形状:", example_input.shape)
print("输出形状:", output_x.shape)

# A global march indicating the target hardware version must be setted before prepare qat.
set_march(March.NASH_M)

calib_model = prepare(model.eval(), example_input, 
                      qconfig_setter=(
                          default_calibration_qconfig_setter,
                          ),
                      )

calib_model.eval()
set_fake_quantize(calib_model, FakeQuantState.CALIBRATION)
calib_model(example_input)

calib_model.eval()                            
set_fake_quantize(calib_model, FakeQuantState.VALIDATION)
calib_out_x = calib_model(example_input)
print("calib输出shape:", calib_out_x.shape)

qat_bc = export(calib_model, example_input)
# save(qat_bc, "qat.bc")
# visualize(qat_bc, "qat.onnx")
hb_quantized_model = convert(qat_bc, March.NASH_M)
# save(hb_quantized_model,"quantized.bc")
visualize(hb_quantized_model, "quantized_single.onnx")</code></pre><p>查看 quantized.onnx，可以看到最后一个 conv 确实是 int32 高精度输出</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438904" alt="" title="" loading="lazy"/></p><h2>2. 输出又输入</h2><p>如果 conv1，既作为模型输出，又作为后续 conv2 的输入，此时应该怎么办？</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438905" alt="" title="" loading="lazy"/></p><p>关键代码如下：</p><pre><code class="Plain">def forward(self, x):
        x = self.quant(x)
        # 第一个 Linear
        x = self.linear1(x)  # [2, 100, 256]
        x = self.layernorm(x)  # [2, 100, 256]
        x = self.relu(x)  # [2, 100, 256]
        # 第二个 Linear
        y = self.linear2(x)  # [2, 100, 60]
        y_out = self.dequant(y)
        y = self.quant_out(y_out)
        # y = self.quant_out(y)

        # 第三个 Linear
        z = self.linear3(y)
        z = self.dequant(z)
        return x, y_out</code></pre><p>注意，y\_out = self.dequant（y）是必须要添加的，否则无法实现该效果。</p><p>全流程代码如下：</p><pre><code class="Plain">import torch
from horizon_plugin_pytorch import set_march, March
set_march(March.NASH_M)
from horizon_plugin_pytorch.quantization import prepare, set_fake_quantize, FakeQuantState
from horizon_plugin_pytorch.quantization import QuantStub
from horizon_plugin_pytorch.quantization.hbdk4 import export
from horizon_plugin_pytorch.quantization.qconfig_template import (
    calibration_8bit_weight_16bit_act_qconfig_setter,
    qat_8bit_weight_16bit_fixed_act_qconfig_setter, 
    default_calibration_qconfig_setter,
    ModuleNameQconfigSetter
) 

from horizon_plugin_pytorch.quantization.qconfig import get_qconfig, MSEObserver, MinMaxObserver
from horizon_plugin_pytorch.dtype import qint8, qint16
from torch.quantization import DeQuantStub
import torch.nn as nn
from horizon_plugin_pytorch.quantization import hbdk4 as hb4
from hbdk4.compiler import convert, save, hbm_perf, visualize, compile

import torch
import torch.nn as nn

# 定义网络结构
class SmallModel(nn.Module):
    def __init__(self):
        super(SmallModel, self).__init__()
        # 第一个 Linear: 输入 [2, 100, 256] -&gt; 输出 [2, 100, 256]
        self.linear1 = nn.Linear(256, 256)
        self.layernorm = nn.LayerNorm(256)  # 对最后一维进行归一化
        self.relu = nn.ReLU()
        # 第二个 Linear: 输入 [2, 100, 256] -&gt; 输出 [2, 100, 60]
        self.linear2 = nn.Linear(256, 60)
        # 第三个 Linear: 输入 [2, 100, 60] -&gt; 输出 [2, 100, 60]
        self.linear3 = nn.Linear(60, 60)
        self.quant = QuantStub()
        self.quant_out = QuantStub()
        self.dequant = DeQuantStub()

    def forward(self, x):
        x = self.quant(x)
        # 第一个 Linear
        x = self.linear1(x)  # [2, 100, 256]
        x = self.layernorm(x)  # [2, 100, 256]
        x = self.relu(x)  # [2, 100, 256]
        # 第二个 Linear
        y = self.linear2(x)  # [2, 100, 60]
        y_out = self.dequant(y)
        y = self.quant_out(y_out)

        # 第三个 Linear
        z = self.linear3(y)
        z = self.dequant(z)
        return z, y_out

# 设置随机种子，保证每次生成的数据相同
torch.manual_seed(42)
example_input = torch.randn(2, 100, 256)
model = SmallModel()

# 前向传播
output_x, output_y = model(example_input)
print("输入形状:", example_input.shape)
print("输出形状:", output_x.shape, output_y.shape)

# A global march indicating the target hardware version must be setted before prepare qat.
set_march(March.NASH_M)

calib_model = prepare(model.eval(), example_input, 
                      qconfig_setter=(
                          default_calibration_qconfig_setter,
                          ),
                      )

calib_model.eval()
set_fake_quantize(calib_model, FakeQuantState.CALIBRATION)
calib_model(example_input)

calib_model.eval()                            
set_fake_quantize(calib_model, FakeQuantState.VALIDATION)
calib_out_x, calib_out_y= calib_model(example_input)
print("calib输出shape:", calib_out_x.shape)

qat_bc = export(calib_model, example_input)
# save(qat_bc, "qat.bc")
# visualize(qat_bc, "qat.onnx")
hb_quantized_model = convert(qat_bc, March.NASH_M)
# save(hb_quantized_model,"quantized.bc")
visualize(hb_quantized_model, "quantized.onnx")</code></pre><p>查看 quantized.onnx，linear2 符合预期，确实是 int32 高精度输出。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438906" alt="" title="" loading="lazy"/></p><p>新加入的 dequant 与 quant 会变成 rescale</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438907" alt="" title="" loading="lazy"/></p><p>以上是征程 6EM 的默认做法，如果使用的是征程 6PH，conv like 算子输出直接就是 float32，在既作为输出，又作为下一阶段输入时，会存在 vpu 的 quantize（float32-&gt;int16/int8），如下图所示</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438908" alt="" title="" loading="lazy"/></p><p>如果想依旧沿用征程 6EM 的方式，可进行如下配置：</p><pre><code class="Plain">qat_bc._integer_conv = True
hb_quantized_model = convert(qat_bc, "nash-h")</code></pre><p>具体选择哪种方式可实测 latency（建议考虑将模型 conv like 算子 c++ 反量化的耗时减少也加进去对比）</p>]]></description></item><item>    <title><![CDATA[【卫星图像识别系统】Python+Ten]]></title>    <link>https://segmentfault.com/a/1190000047438926</link>    <guid>https://segmentfault.com/a/1190000047438926</guid>    <pubDate>2025-11-30 18:02:03</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>一、介绍</h2><p>卫星影像识别系统，基于TensorFlow搭建卷积神经网络算法，通过对7种常见的卫星遥感影像图片数据集（'草地（Grass）', '农田（Field）', '工业区（Industry）', '河流湖泊（RiverLake）', '森林（Forest）', '居民区（Resident）', '停车场（Parking）'）进行训练，最后得到一个识别精度较高的模型，然后搭建Web可视化操作平台。</p><p><strong>前端</strong>: Vue3、Element Plus</p><p><strong>后端</strong>：Django</p><p><strong>算法</strong>：TensorFlow、卷积神经网络算法</p><p><strong>具体功能</strong>：</p><ol><li>系统分为管理员和用户两个角色，登录后根据角色显示其可访问的页面模块。</li><li>登录系统后可发布、查看、编辑文章，创建文章功能中集成了markdown编辑器，可对文章进行编辑。</li><li>在图像识别功能中，用户上传图片后，点击识别，可输出其识别结果和置信度</li><li>基于Echart以柱状图形式输出所有种类对应的置信度分布图。</li><li>在智能问答功能模块中：用户输入问题，后台通过对接Deepseek接口实现智能问答功能。</li><li>管理员可在用户管理模块中，对用户账户进行管理和编辑。</li></ol><p><strong>选题背景与意义</strong>：<br/>随着遥感技术的快速发展，卫星影像数据呈现爆发式增长，如何高效、精准地识别与利用这些数据，已成为资源监测、环境评估和城乡规划等领域的重要课题。传统人工判读方式效率低、主观性强，难以满足大规模应用需求。为此，本项目基于TensorFlow构建卷积神经网络模型，针对草地、农田、工业区、河流湖泊、森林、居民区及停车场等七类典型地物进行识别训练，旨在开发一个具备较高识别精度的自动化分类系统。为进一步提升系统的实用性与交互体验，项目结合Django与Vue3等主流技术，搭建了集用户管理、图像识别、结果可视化及智能问答于一体的Web操作平台。该系统不仅实现了地物类型的智能识别与置信度分析，还通过集成Markdown编辑与DeepSeek问答接口，拓展了知识管理与交互支持功能，为遥感数据的智能化应用提供了便捷、高效的解决方案。</p><h2>二、系统效果图片展示</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438928" alt="图片" title="图片"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047438929" alt="图片" title="图片" loading="lazy"/></p><h2>三、演示视频 and 完整代码 and 安装</h2><p>地址：<a href="https://link.segmentfault.com/?enc=wyUaSD2PvQ6kaogAN80woA%3D%3D.LOXg8rkgKqlioCPmBMNU58Fq5295P9qE6yiO4kSPrS4%3D" rel="nofollow" target="_blank">https://ziwupy.cn/p/6eby8p</a></p><h2>四、卷积神经网络算法介绍</h2><p>ResNet50是由微软研究院提出的深度残差网络（Residual Network）的一个经典模型，其核心创新是“残差学习”思想。在传统的深度卷积神经网络中，简单地堆叠层数会遇到“梯度消失/爆炸”问题，导致网络难以训练，性能甚至下降，这被称为“退化问题”。</p><p>ResNet通过引入“快捷连接”或“跳跃连接”巧妙地解决了这一问题。它不再让多个堆叠的层直接学习一个目标映射H(x)，而是让这些层学习其与输入x之间的残差F(x) = H(x) - x。这样，原始的目标映射就变成了 H(x) = F(x) + x。</p><p>这种“捷径”将输入x直接传递到更深层的输出，实现了恒等映射。这样做有两个主要好处：</p><ol><li><strong>缓解梯度消失</strong>：梯度可以直接通过快捷连接反向传播，使得深层网络的训练变得可行。</li><li><strong>简化学习目标</strong>：让网络学习残差F(x)通常比学习完整的映射H(x)更容易，尤其是在F(x)趋近于0时，该层就近似做了恒等变换，避免了性能退化。</li></ol><p>ResNet50因其包含50个权重层而得名，它通过大量使用这种带有快捷连接的“瓶颈结构”模块，在保持高性能的同时，显著减少了参数量，成为图像识别领域一个里程碑式的模型。</p><p>以下是一个使用TensorFlow Keras中预训练的ResNet50模型进行图像识别的简单示例。</p><pre><code class="python">import tensorflow as tf
from tensorflow.keras.applications.resnet50 import ResNet50, decode_predictions, preprocess_input
import numpy as np
from PIL import Image

# 1. 加载预训练的ResNet50模型（包含在ImageNet上训练得到的权重）
model = ResNet50(weights='imagenet')

# 2. 加载并预处理图像
img_path = 'your_image.jpg' # 替换为你的图片路径
image = Image.open(img_path).convert('RGB') # 确保为RGB格式
image = image.resize((224, 224)) # ResNet50要求输入尺寸为224x224

# 将图像转换为数组并扩展维度以匹配模型输入要求 (batch_size, height, width, channels)
image_array = np.array(image)
image_array = np.expand_dims(image_array, axis=0)

# 对图像进行与训练时相同的预处理
image_array = preprocess_input(image_array)

# 3. 使用模型进行预测
predictions = model.predict(image_array)

# 4. 解码预测结果，得到人类可读的标签和置信度
decoded_predictions = decode_predictions(predictions, top=3)[0] # 显示最可能的3个结果

# 5. 打印结果
print("识别结果：")
for i, (imagenet_id, label, score) in enumerate(decoded_predictions):
    print(f"{i+1}: {label} ({score * 100:.2f}%)")</code></pre><p>这段代码演示了利用预训练ResNet50模型进行图像识别的标准流程。首先，我们直接加载了在ImageNet数据集上预训练好的模型，无需从头训练。然后，将输入图像调整为224x224像素，并进行归一化等预处理。接着，模型对图像进行前向传播推理，输出一个包含1000个ImageNet类别概率的向量。最后，通过<code>decode_predictions</code>函数将概率向量解码为易于理解的对象标签和置信度，并打印出最可能的三个预测结果。这种方法让我们能够快速、高效地将强大的ResNet50模型应用于实际的图像识别任务中。</p>]]></description></item><item>    <title><![CDATA[【民族服饰识别系统】Python+Ten]]></title>    <link>https://segmentfault.com/a/1190000047438935</link>    <guid>https://segmentfault.com/a/1190000047438935</guid>    <pubDate>2025-11-30 18:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>一、介绍</h2><p>民族服饰识别，民族服饰智能识别与分析系统基于TensorFlow框架，采用卷积神经网络（CNN）算法构建而成。系统在收集了回族、汉族、满族、苗族四类典型民族服饰图像数据集的基础上，通过多轮迭代训练，最终生成高精度识别模型，并配合Web可视化平台实现便捷交互。</p><p><strong>前端</strong>: Vue3、Element Plus</p><p><strong>后端</strong>：Django</p><p><strong>算法</strong>：TensorFlow、卷积神经网络算法</p><p><strong>具体功能</strong>：</p><ol><li>系统分为管理员和用户两个角色，登录后根据角色显示其可访问的页面模块。</li><li>登录系统后可发布、查看、编辑文章，创建文章功能中集成了markdown编辑器，可对文章进行编辑。</li><li>在图像识别功能中，用户上传图片后，点击识别，可输出其识别结果和置信度</li><li>基于Echart以柱状图形式输出所有种类对应的置信度分布图。</li><li>在智能问答功能模块中：用户输入问题，后台通过对接Deepseek接口实现智能问答功能。</li><li>管理员可在用户管理模块中，对用户账户进行管理和编辑。</li></ol><p><strong>选题背景与意义</strong>：<br/>随着人工智能技术的快速发展，计算机视觉在文化传承与保护领域的应用日益广泛。民族服饰作为民族文化的重要载体，其识别与分类对于文化研究与数字化保护具有积极意义。传统人工识别方式效率有限，难以适应大规模图像处理需求。基于此背景，本研究旨在开发一套基于深度学习的民族服饰智能识别与分析系统。系统采用TensorFlow框架，基于卷积神经网络（CNN）构建高精度识别模型，实现对回族、汉族、满族、苗族四类典型民族服饰的自动化识别。通过集成Web可视化平台，系统不仅提供图像识别、置信度分析和可视化图表展示等核心功能，还结合内容管理与智能问答模块，构建了集文化识别、知识传播与交互体验于一体的综合平台，为民族文化的数字化保护与推广提供了有效的技术支撑。</p><h2>二、系统效果图片展示</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438937" alt="图片" title="图片"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047438938" alt="图片" title="图片" loading="lazy"/></p><h2>三、演示视频 and 完整代码 and 安装</h2><p>地址：<a href="https://link.segmentfault.com/?enc=Pq9s7g%2BUpI038ZxwufiFwA%3D%3D.1L7AHrCJLzWM%2B86e%2BFZpFTazSD6H3czZWdJRnccTzUE%3D" rel="nofollow" target="_blank">https://ziwupy.cn/p/ekFQTD</a></p><h2>四、卷积神经网络算法介绍</h2><p>卷积神经网络是一种专为处理网格状数据（如图像）而设计的深度学习算法。其核心思想是通过“卷积”操作，自动地从图像中提取由浅到深的特征。</p><p><strong>主要构成层：</strong></p><ol><li><strong>卷积层：</strong> 是CNN的核心。它使用多个可学习的“滤波器”（或称“卷积核”）在输入图像上滑动，通过计算局部区域的点积来提取特征（如边缘、角点、纹理等）。通过堆叠多个卷积层，网络可以学习到从简单到复杂（如物体部件、整体轮廓）的层次化特征。</li><li><strong>池化层：</strong> 通常跟在卷积层之后，用于对特征图进行下采样。它通过取局部区域的最大值或平均值，来减小数据尺寸，降低计算量，同时增强模型对目标位置微小变化的鲁棒性（即“平移不变性”）。</li><li><strong>全连接层：</strong> 在网络的末端，将经过多轮卷积和池化后提取出的高级特征图展平，然后进行综合判断，最终输出每个类别的概率。</li></ol><p>CNN通过这种“局部连接”和“权值共享”（同一个滤波器扫描整张图片）的机制，极大地减少了参数数量，使其能够高效地处理图像，并成为图像识别领域最主流的算法。</p><p>以下是一个使用TensorFlow和Keras API构建一个简单的CNN模型，用于对MNIST手写数字数据集进行分类的示例。</p><pre><code class="python">import tensorflow as tf
from tensorflow.keras import datasets, layers, models

# 1. 加载并预处理数据
(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()
# 将图像数据重塑为 (28, 28, 1) 的形状，并归一化到 [0, 1] 区间
train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255
test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255

# 2. 构建CNN模型
model = models.Sequential([
    # 第一个卷积块：卷积 + 池化
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    layers.MaxPooling2D((2, 2)),
    
    # 第二个卷积块：卷积 + 池化
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    
    # 将特征图展平，输入到全连接层
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    # 输出层，10个神经元对应10个数字类别，使用softmax激活函数输出概率
    layers.Dense(10, activation='softmax')
])

# 3. 编译模型
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# 4. 训练模型
model.fit(train_images, train_labels, epochs=5, 
          validation_data=(test_images, test_labels))

# 5. 评估模型
test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)
print(f'\n测试准确率：{test_acc}')</code></pre><p>以上代码完整展示了使用CNN进行图像识别的流程。首先，数据被加载并预处理成适合网络的格式。接着，我们构建了一个顺序模型，它包含两个卷积-池化层组合，用于特征提取，之后是展平操作和全连接层进行分类。模型使用<code>adam</code>优化器和交叉熵损失函数进行编译。最后，通过<code>fit</code>方法在训练数据上进行5轮训练，并在测试集上评估最终性能。这个简单的模型能很快地在MNIST数据集上达到很高的准确率，清晰地演示了CNN在图像识别任务中的强大能力和基本工作流程。</p>]]></description></item><item>    <title><![CDATA[Omnissa Dynamic Envi]]></title>    <link>https://segmentfault.com/a/1190000047438859</link>    <guid>https://segmentfault.com/a/1190000047438859</guid>    <pubDate>2025-11-30 17:01:55</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>Omnissa Dynamic Environment Manager 2509 - 个性化动态 Windows 桌面环境管理</p><p>Simplify management of user profiles, environment settings, and policies across desktops and apps.</p><p>请访问原文链接：<a href="https://link.segmentfault.com/?enc=Om3KNyDDw2aEu7hPvHPa3Q%3D%3D.R%2BomsM3Ev3LmYToSG6jE%2FqriUIujx50XKaWrjuByxbAzopjb3%2BUov1otrV5lXbFVzKGCtli%2FElvd6DR3OKMqSw%3D%3D" rel="nofollow" target="_blank">https://sysin.org/blog/omnissa-dynamic-environment-manager/</a> 查看最新版。原创作品，转载请保留出处。</p><p>作者主页：<a href="https://link.segmentfault.com/?enc=BZe8VTrld6vnXWDrzR6Zhg%3D%3D.DbZXXgTShsNv%2BpwDLo%2F5Zubb%2BzyExFssDL5WGGGFfU4%3D" rel="nofollow" target="_blank">sysin.org</a></p><hr/><p><img referrerpolicy="no-referrer" src="/img/remote/1460000046037272" alt="Omnissa Horizon 架构图" title="Omnissa Horizon 架构图"/></p><p>Omnissa Dynamic Environment Manager</p><p>简化跨桌面和应用程序的用户配置文件、环境设置和策略的管理。</p><h2>产品简介</h2><p>Dynamic Environment Manager 为最终用户提供个性化的动态 Windows 桌面。通过 Dynamic  Environment Manager，您可以根据用户的角色、设备和位置提供对 IT  资源的访问来自定义桌面。通过这种方式，您可以创建适应用户特定需求的桌面。</p><p>Omnissa Dynamic Environment Manager 标准版和企业版</p><p>Omnissa Dynamic Environment Manager 提供标准版和企业版。</p><p><strong>标准版</strong> 专为寻求基本用户环境管理和应用程序控制的组织而设计。标准版可帮助 Omnissa Horizon® 标准版和 Omnissa Horizon® 高级版客户进行用户配置文件管理。</p><p><strong>企业版</strong> 专为需要高级管理、详细的应用程序分析以及复杂的自动化和集成功能的大型或复杂环境而设计。企业版是 Omnissa Dynamic Environment Manager 的全功能版本。</p><h3>版本比较</h3><table><thead><tr><th>特征</th><th>标准版</th><th>企业版</th></tr></thead><tbody><tr><td>用户环境</td><td>DEM 标准版提供以下选项。  - 驱动器映射   - 文件夹重定向   - 登录和注销任务   - 打印机映射</td><td>✓</td></tr><tr><td>计算机环境</td><td>x</td><td>✓</td></tr><tr><td>个性化</td><td>支持所有功能，但在 Flex 配置文件上可配置的某些用户环境设置除外。  可以在 Flex 配置文件上配置以下用户环境设置。  - 驱动器映射   - 打印机映射   - 任务</td><td>✓</td></tr><tr><td>同步工具</td><td>✓</td><td>✓</td></tr><tr><td>自助工具</td><td>✓</td><td>✓</td></tr><tr><td>帮助台支持工具</td><td>✓</td><td>✓</td></tr><tr><td>条件集</td><td>✓</td><td>✓</td></tr><tr><td>应用分析器</td><td>✓</td><td>✓</td></tr><tr><td>应用程序迁移</td><td>x</td><td>✓</td></tr><tr><td>与 Omnissa Horizon 集成</td><td>x</td><td>✓</td></tr><tr><td>基于触发器的操作</td><td>x</td><td>✓</td></tr></tbody></table><h3>部署模式</h3><p>Dynamic Environment Manager 可在独立模式和集成模式下使用。两种模式都使用配置文件进行 Dynamic Environment Manager 的个性化和应用程序配置管理。</p><table><thead><tr><th>独立模式 (Standalone mode)</th><th>整合模式 (Integration mode)</th></tr></thead><tbody><tr><td>当您想要独立配置 Dynamic Environment Manager 时，请使用独立模式。</td><td>使用集成模式将 Dynamic Environment Manager 与 Omnissa Workspace ONE® UEM 集成。</td></tr><tr><td>配置文件存储在配置 SMB 共享中，该共享是文件服务器上的中央共享。</td><td>配置文件包含在 Dynamic Environment Manager 配置文件中。使用 Workspace ONE UEM，您可以将  Dynamic Environment Manager 配置文件文件定位到特定智能组 (sysin)，以将 Dynamic  Environment Manager 配置分发到 Workspace ONE UEM 端点。</td></tr></tbody></table><h2>新增功能</h2><p>Omnissa Dynamic Environment Manager 2509 | 2025 年 10 月 30 日 | 内部版本 10.17.0.2322</p><ul><li><strong>计算机环境配置</strong>。管理员现在也可以直接管理<strong>计算机环境</strong>的环境变量、文件和文件夹以及注册表设置。这能提供您在用户上下文中所熟悉的相同体验，而无需依赖于启动任务或自定义脚本。</li><li><strong>增强了 Windows 通用设置、应用程序模板和 Easy Start</strong>。更新了 Windows 通用设置和应用程序模板，以支持 Windows 11 场景，改进了 Office 覆盖范围，并移除了过时的项目。现有配置将继续正常运行。使用较新的定义更新引用的模板时，管理控制台会提供升级提示。</li><li><p><strong>向“文件版本”(File Version) 条件添加了比较运算符</strong>。使用更新的“文件版本”(File Version) 条件精确定位目标体验。除了“is equal to”（等于）之外，还支持以下比较运算符：</p><ul><li>“is not equal to”（不等于）</li><li>“is less than”（小于）</li><li>“is less than or equal to”（小于或等于）</li><li>“is greater than”（大于）</li><li>“is greater than equal to”（大于或等于）</li></ul></li><li>添加了一个新设置，可在目标/命令不存在时跳过快捷方式或文件类型关联。</li><li><strong>最新操作系统支持</strong>。Dynamic Environment Manager 现在支持 Windows 11 25H2。</li><li><strong>更新的组件</strong>。此版本更新了主要产品组件。应用程序分析器、Helpdesk Support 工具和 SyncTool 未更新。</li></ul><h2>下载地址</h2><p>Omnissa Dynamic Environment Manager Enterprise 2506, Release Date 2025-10-30</p><ul><li>下载地址：<a href="https://link.segmentfault.com/?enc=M%2BoIn%2Bc4X%2F4bZqN3%2Bku%2Bzg%3D%3D.N%2FIhFMP0srItoojJvhZZf4Rk0z5JeG5h7h6qPoMsZX9684hca9HbqxBxwGx%2FQ9RR37%2FTvd9flvDsj78FkhXo9w%3D%3D" rel="nofollow" target="_blank">https://sysin.org/blog/omnissa-dynamic-environment-manager/</a></li><li>Omnissa Dynamic Environment Manager<br/>File size: 35.95 MB<br/>Name: Omnissa-DEM-Enterprise-2509-10.17.zip</li></ul><p>更多：<a href="https://link.segmentfault.com/?enc=WZBVgNrgvdvq73dnuj8kmg%3D%3D.4C5ZygawV9k1UvYrTUyV6ICm%2BAIHP17bzgch%2FbDqZzs%3D" rel="nofollow" target="_blank">VMware 产品下载汇总</a></p>]]></description></item><item>    <title><![CDATA[征程 6 | QAT 新版 qconfi]]></title>    <link>https://segmentfault.com/a/1190000047438875</link>    <guid>https://segmentfault.com/a/1190000047438875</guid>    <pubDate>2025-11-30 17:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>1.前言</h2><p>随着 征程 6 芯片家族的阵容不断壮大，算法工具链在量化精度方向的优化也在持续深入，具体体现在两个方面：</p><ol><li>征程 6P 与 征程 6H 工具链已陆续进入发布和试用阶段，在此背景下，QAT（量化感知训练）需要以更高效的方式适配算子的浮点计算能力，以确保量化精度和用户的使用体验；</li><li>MatMul、Conv、Linear 等 Gemm 类算子目前已正式支持双 int16 输入，这一改进有助于提升相关算子在量化计算时的精度和调优时的效率。</li></ol><p>为了更全面、稳妥地支持上述新功能，同时对当前的 qconfig 量化配置以及回退逻辑进行优化升级，工具链从 OE3.5.0 开始支持新版 qconfig 量化模板。新版本针对 qconfig 模板开展了大量的重构工作，重构后的 qconfig 模板不仅能更好地适配新的芯片特性和算子功能，还同时保持对旧版本 qconfig 的维护，保障了用户在升级过程中的平滑过渡，减少了因版本迭代带来的适配成本。</p><h2>2.新版 qconfig 模板配置流程</h2><p>本章将系统且全面地为大家呈现新版 qconfig 模板的核心内容，涵盖其关键更新点、规范的基本使用流程以及对相关产出物的详细介绍。</p><h3>2.1 主要更新点</h3><p>在更新点方面，新版 qconfig 模板的迭代升级紧密贴合 征程 6 平台家族的持续发展以及工具链不断优化的实际需求，通过针对性的设计与调整，进一步提升了量化配置的效率、灵活性与适配性。其与旧版流程的区别主要体现在以下四个方面：</p><ol><li><strong>​模板与回退机制的统一管理：​</strong>将模板和回退进行了统一，在同一个流程下管理；</li><li><strong>​强化对特定量化配置的友好性：​</strong>对浮点计算的量化配置、Conv/Matmul 等 Gemm 算子单/双 int16 输入配置更加友好；</li><li><strong>​fuse 默认行为的调整与优化：​</strong>旧模板默认 conv-bn-add-relu 全部 fuse，然后再根据硬件限制回退至 int8。为了实现更高的计算精度，新模板首先配置 dtype，若不符合要求则不做 fuse，最终 dtype 结果更加符合预期，而且针对不同芯片架构的硬件特性设计了不同的 fuse 行为；</li><li><strong>​新增量化配置文件保存功能：​</strong>支持保存量化配置文件 <code>qconfig_dtypes.pt</code>、<code>qconfig_dtypes.pt.py</code> 以及 <code>qconfig_changelogs.txt</code>。其中，<code>qconfig_dtypes.pt</code> 为可供用户加载的算子级别的量化配置文件，实现了配置的便捷迁移与共享；<code>qconfig_dtypes.pt.py</code>​<code> </code> 则以 Python 脚本形式保存配置信息，便于用户查看；<code>qconfig_changelogs.txt</code> 则记录了配置过程中的算子变更日志，包括量化参数调整记录、模板使用信息等，为配置的追溯、调试提供了清晰的依据，进一步提升了量化配置的可解释性与可复用性。</li></ol><h3>2.2 基本使用流程</h3><p>新版 qconfig 模板在使用流程上围绕基础 qconfig 配置 reference\_qconfig、templates 量化模板配置展开，各环节紧密关联，共同助力用户实现高效、精准的量化配置。新版 qconfig 模板的基本使用流程如下所示：</p><pre><code class="Plain">import torch
import torch.nn as nn 
from horizon_plugin_pytorch.quantization import  prepare,set_fake_quantize,FakeQuantState
from horizon_plugin_pytorch.dtype import qint8,qint16
from horizon_plugin_pytorch.quantization.qconfig_setter import *
from horizon_plugin_pytorch.quantization.observer_v2 import MinMaxObserver,MSEObserver,FixedScaleObserver

my_qconfig_setter=QconfigSetter( 
     #1.基础qconfig,获取默认配置和observer
     reference_qconfig=get_qconfig(observer=MSEObserver),
     #2.模板，仅关注dype,按照顺序生效，前面模板的配置可被后面的模板覆盖。因此模板的顺序很重要
     templates=[
        ...
            ],
     #3.采用默认的优化模板
     enable_optimize=True,
     #4.qconfig模板配置文件保存路径
     save_dir=args.save_path,
        )
float_model.eval()
qat_model = prepare(
    float_model,
    example_inputs=example_input,
    qconfig_setter=my_qconfig_setter,
    check_result_dir=args.save_path
    )</code></pre><p>以上就是新版 qconfig 模板的基本使用流程，下面将对其核心部分 QconfigSetter 接口和工具链提供的多个 templates 进行介绍。</p><h4>2.2.1 QconfigSetter 接口介绍</h4><p>QconfigSetter 接口的定义如下所示：</p><blockquote>代码路径：horizon_plugin_pytorch/quantization/qconfig_setter/qconfig_setter.py</blockquote><pre><code class="Plain">class QconfigSetter(ModernQconfigSetterBase):
    """Manage qconfig settings of a model.

    Args:
        reference_qconfig: Qconfig to provide observer.
        templates: Qconfig templates, will be applyed in order.
        enable_optimize: Whether enable the default optimize.
        save_dir: Save directory of qconfig settings.
        custom_qconfig_mapping: Custom mapping from mod name to qconfig.
            CAUTION: This mapping will overwrite the dtype setted by templates.
                     You'd better not change dtype through this argument, or
                     the config result will not be optimal (Model may contain
                     CPU ops on board, for example).
            Defaults to None.
        enable_attribute_setting: Whether enable the qconfig setted through
            qconfig attribute.
        enable_propagate: Whether enable propagate for custom_qconfig_mapping
            and qconfig attr. Defaults to False.
    """

    def __init__(
        self,
        reference_qconfig: QConfig,
        templates: Sequence[TemplateBase],
        enable_optimize: bool = True,
        save_dir: str = "./qconfig_setting",
        custom_qconfig_mapping: Optional[Dict[str, QConfig]] = None,
        enable_attribute_setting: bool = False,
        enable_propagate: bool = False,
    ):
        super().__init__(reference_qconfig)
        self.templates = list(templates)
        self.enable_optimize = enable_optimize
        self.save_dir = save_dir

        if custom_qconfig_mapping is None:
            custom_qconfig_mapping = {}
        self.custom_qconfig_mapping = {
            k: canonicalize_qconfig(v)
            for k, v in custom_qconfig_mapping.items()
        }
        self.enable_attribute_setting = enable_attribute_setting
        self.enable_propagate = enable_propagate

        if save_dir is not None:
            os.makedirs(save_dir, exist_ok=True)</code></pre><ul><li><strong>​reference\_qconfig【必要配置】：​</strong>配置 observer，可选项包括 MSEObserver 、MinMaxObserver 等。</li><li><strong>​templates【必要配置】：​</strong>配置使用到的 qconfig 模板，仅关注 dtype，按照顺序依次生效。</li><li><p><strong>enable\_optimize【必要配置-用户可不关注】: ​</strong>是否采用默认的优化 pass，默认配置为 True，相关优化如下：</p><ul><li><p><code>CanonicalizeTemplate</code>： 按算子类型对 dtype 配置进行合法化，当前默认规则有：</p><ul><li>Gemm 类算子输入不支持 float</li><li>插值类算子：在不同 march 下有不同的限制</li><li>DPP、RPP 等特殊算子仅支持 int8</li><li>其他算子的通用规则：算子的 input dtype 和 output dtype 不能同时存在 qint 和 float</li></ul></li><li><p><code>EqualizeInOutScaleTemplate</code>：对于 relu，concat，stack 算子，应该在算子输出统计 scale，否则精度或性能存在损失。为此：</p><ul><li>将前面算子的 output dtype 配置为 float32</li><li>Relu，concat，stack 算子在 export hbir 时，在 input 处插入伪量化，scale 复用 output scale</li></ul></li><li><code>FuseConvAddTemplate</code>：硬件支持 conv + add 的 fuse，不同的芯片架构的融合条件不一致，满足融合条件会有以下行为：</li><li>将 conv 的 output dtype 配置为 float32</li><li>将 add 对应的 input dtype 配置为 float32</li><li><code>GridHighPrecisionTemplate</code>：根据经验，grid sample 的 grid 计算过程用 qint8 精度不够，因此自动将相关算子配置为 qint16 计算。</li><li><code>InternalQuantsTemplate</code>：模型分段部署场景下，会在分段点处插入 QuantStub，用于记录此处的 dtype 和 scale，此类 QuantStub 的 dtype 配置必须和输入保持一致。</li><li><code>OutputHighPrecisionTemplate</code>：当 Gemm 类算子作为模型输出时，将其配置为高精度输出。</li><li><code>PropagateTemplate</code>：对于拆分为子图实现的算子，存在经验性配置，如 <code>LayerNorm</code> 和 <code>Softmax</code> 内部小算子应该使用高精度。</li><li><p><code>SimpleIntPassTemplate</code>：性能优化，对于 op0-&gt;op1-&gt;op2 此类计算图，若以下条件同时成立，则将 op1 输出类型修改为 int：</p><ul><li>op2 需要 int 输入</li><li>op0 可以输出 int</li><li><p>op1 当前输出为 float16，且属于以下类型</p><ol><li>cat, stack</li><li>mul\_scalar</li><li>无精度风险的查表算子（即在 fp16 上默认使用查表实现的算子）</li></ol></li></ul></li><li><code>SimplifyTemplate</code>：删除多余的量化节点配置（将对应的 dtype 修改为 None）</li></ul><p>进一步的说明可以参考用户手册&lt;u&gt;<a href="https://link.segmentfault.com/?enc=9%2BHhOCPeyg3mgzEJRQ7vGA%3D%3D.MZ6cqtMHJTNv8CdxfnZLJjvOCXDSQRgdPkHiNvBuOFfZm38Wpqt%2BR1hbrCm1M90WhPp4BARlGUY8OHykAZfk8wQpfsZjPy7TM1DUSMJsboIOns6pehHCHSJk8e%2B50dgzqVtV3S6kO8U8pMUeGiQHDw%3D%3D" rel="nofollow" target="_blank">【Qconfig 详解】</a>&lt;/u&gt;。</p></li><li><strong>​save\_dir【必要配置】：​</strong>量化配置文件保存的路径。</li></ul><h4>2.2.2 templates 介绍</h4><p><code>horizon_plugin_pytorch</code> 中提供了比较齐全的量化配置 templates 供用户使用，下面将逐一对这些模板进行介绍：</p><ol><li>ModuleNameTemplate（必要配置）：通过 module name 指定 dtype 配置或量化阈值，包括激活/weight 量化配置，固定 scale 配置；配置粒度支持全局、模型片段和算子等；配置 dtype 包括 qint8、qint16、torch.float16、torch.float32 等，相关配置项可以参考用户手册&lt;u&gt;<a href="https://link.segmentfault.com/?enc=JfkwDPnPT1kOz9IzzgEg6w%3D%3D.7ZGMF%2F1VJeoiCxb8CZwWewSQNKCmg5%2B2SAf8dHX3iawyQp249M15lQxXCpyCP2tD4fYpSYplD54yRi1fSBflOc8wZEqj8b7KpOsnSXJKfZ8cIA6Pgm1zzVY03ubnsW99g%2FthkpJ1Y8EHqtuXrlITbw%3D%3D" rel="nofollow" target="_blank">【Qconfig 详解】</a>&lt;/u&gt;；</li><li>MatmulDtypeTemplate（必要配置）：通过名称或前缀配置 Matmul 算子单 int16/双 int16 输入，支持批量配置，相关配置项可以参考用户手册&lt;u&gt;<a href="https://link.segmentfault.com/?enc=1oqTh51AtyYGDH2DN%2Fgs7A%3D%3D.Ic9yty0y5L5ccJxxrdtsEHz4X5JBVD965YfWLEJnSwB2ATa1S%2BRerXFBPn78hrjR7AmSYL9510UwJ%2FkJtXW1wSgkhd%2BYnIxvFmDmUs%2FwjyBchweDBLHzWFmGTvgOIaK05RUf0EwZMauAi%2B3Vc6azgw%3D%3D" rel="nofollow" target="_blank">【Qconfig 详解】</a>&lt;/u&gt;；</li><li>ConvDtypeTemplate（必要配置）：通过名称或前缀配置 Conv/Linear 算子单 int16/双 int16 输入，支持批量配置，相关配置项可以参考用户手册&lt;u&gt;<a href="https://link.segmentfault.com/?enc=GkHb%2Bhz2amI9KXhdusIy6g%3D%3D.bLPMpXxr6m9ZSYWSayKA1gGgMPADB3ILj0%2BBs8nb6Zz%2FpENRpO7nQN%2BlkT3xsk%2F6t6ZKxPw6fp9W4qPvhZoxZVxYlhtWvH0RQu45Il6ObZG2OlNWSDr5jLYIAU%2FXPhXpC7%2BB9g1li7rkLzXLsxzLxQ%3D%3D" rel="nofollow" target="_blank">【Qconfig 详解】</a>&lt;/u&gt;；</li><li>SensitivityTemplate（可选配置）：通过量化敏感度列表提升数据类型精度，默认将敏感算子配置为 int16，支持激活敏感和 weight 敏感算子分别配置高精度，相关配置项可以参考用户手册&lt;u&gt;<a href="https://link.segmentfault.com/?enc=hnAdWAGQ3gIQFjeH3%2BvalA%3D%3D.0wifHgAseHLK%2F6oJJKg%2Bm%2BV8X65TbW4WFxIgb4D1POjdj2yi8bS0IX5PbBUqLEolCkc8fUgBLcFSRoq7kMpsleZHPfMyq8GnvoNNUYA3nSr5%2B6sb1qmFbiCzez231tWLDmCI8Y3JTQ%2FUqW%2FpcX9FRg%3D%3D" rel="nofollow" target="_blank">【Qconfig 详解】</a>&lt;/u&gt;。</li><li>LoadFromFileTemplate：从 <code>qconfig_dtypes.pt</code> 文件中加载量化配置，仅可加载全局及每个算子的量化类型，暂时无法加载 fix\_scale 配置，且不支持对 qconfig 进行修改。而且需要注意，此时 enable\_optimize 必须配置为 False，否则无法保证配置结果的正确性，部署时可能存在 CPU 算子。</li></ol><p><strong>用户配置的模板按顺序生效，前面模板的配置会被后面的模板覆盖。</strong></p><p>一般来说，用户会使用到 ModuleNameTemplate、ConvDtypeTemplate、MatmulDtypeTemplate 和 SensitivityTemplate 这 4 个模板，其中前 3 个模板为必要配置。以下是 templates 的常用配置，如下所示：</p><pre><code class="Plain">from horizon_plugin_pytorch.quantization.qconfig_setter import *
import torch
#加载精度debug工具产出的敏感度列表
table1=torch.load("xxx_optput1_L1.pt")
table2=torch.load("xxx_optput2_L1.pt")
templates=[ 
    #1. 基础配置部分
    ModuleNameTemplate({"":qint8}),  #全局feat int8,此时weight 默认为int16
    #conv类算子的 input配置为 int8，weight配置为int8
    ConvDtypeTemplate(input_dtype=qint8, weight_dtype=qint8),  
    #matmul类算子两个输入均配置为 int8
    MatmulDtypeTemplate(input_dtypes=qint8), 
    ModuleNameTemplate(
        {"quant":{"dtype":qint8,"threshold":1.0}},#quant int8,固定scale，配置
        ),
    #2. Matmul 单/双int16输入配置
    MatmulDtypeTemplate(
        input_dtypes=[qint8/qint16,qint8/qint16],
        prefix=["head","xxxxx"]#prefix中配置的名称与torch.nn.Module.name_module()返回的一致
        ),
    #3.Conv 单/双int16输入配置
    ConvDtypeTemplate(
        input_dtype=qint8/qint16, 
        weight_dtype=qint8/qint16,
        prefix= ["backbone","xxxxx"],#prefix中配置的名称与torch.nn.Module.name_module()返回的一致
        ),
    # 4. 敏感度模板配置
    #配置top10 weight敏感的算子为int16
    SensitivityTemplate(
        sensitive_table=table1,#精度debug工具产出的敏感度列表
        topk_or_ratio=10, #配置整数的时候是topk,小数的时候是ratio
        sensitive_type= 'weight',#只配置weight敏感的算子，还可以选择 'activation'、 'both'，默认是both
        ),
    #配置50%激活敏感的算子为int16
    SensitivityTemplate(
        sensitive_table=table2,
        topk_or_ratio=0.5, #配置整数的时候是topk,小数的时候是ratio
        sensitive_type= 'activation',#配置激活敏感的算子
        ), 
    ]</code></pre><h3>2.3 产出物介绍</h3><p>在完成新版 qconfig 模板配置并执行 prepare 操作后，工具链将自动生成并保存 5 个文件，分别为 <code>model_check_result.txt</code>、<code>fx_graph.txt</code>、<code>qconfig_changelogs.txt</code>、<code>qconfig_dtypes.pt.py</code> 及 <code>qconfig_dtypes.pt</code>，各文件功能与技术细节如下：</p><ul><li><code>model_check_result.txt</code>、<code>fx_graph.txt</code>：二者均由 <code>prepare</code> 接口自动生成，<code>model_check_result.txt</code> 中包括未 fuse 的 pattern、每个 op 输出/weight 的 qconfig 配置、异常 qconfig 配置提示等，<code>fx_graph.txt</code> 保存的是模型的 fx trace 图；</li><li><code>qconfig_dtypes.pt.py</code> 和 <code>qconfig_dtypes.pt</code>：为 <code>QconfigSetter</code> 接口输出的量化配置载体，完整记录全局及算子级别的量化精度参数，包括每个算子的 input、weight 和 output 的量化精度，如 qint8、qint16 和 torch.float16 等，其中。py 文件供用户阅读，。pt 文件可以使用 <code>LoadFromFileTemplate</code> 接口加载，<code>qconfig_dtypes.pt.py</code> 中信息如下所示；</li></ul><pre><code class="Plain">{
#算子级别量化配置
'backbone.conv1.conv1_1.conv': {'input': None, 'weight': 'qint8', 'output': None}, 'backbone.conv1.conv1_1.act': None,
 'backbone.conv1.conv1_2.conv': {'input': torch.float32, 'weight': torch.float32, 'output': None}, 
 'backbone.conv1.conv1_2.act': {'input': None, 'weight': None, 'output': 'qint16'}
 ...
 }</code></pre><ul><li><code>qconfig_changelogs.txt</code>：每个算子 qconfig 根据 Templates 的变化逻辑，页面如下所示：</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438877" alt="" title=""/></p><h2>3. 使用示例</h2><p>本章节将会提供上述模板的使用方法以及在典型场景下的配置示例。</p><h3><strong>3.1 配置全局</strong> fp16/int16/int8</h3><h4>3.1.1 配置全局 int8</h4><p>配置全局 qconfig 时必须要配置 ModuleNameTemplate、ConvDtypeTemplate、MatmulDtypeTemplate 这 3 个模板，以下为使用示例：</p><pre><code class="Plain">import torch
from horizon_plugin_pytorch.quantization import  prepare,set_fake_quantize,FakeQuantState
from horizon_plugin_pytorch.quantization.qconfig_template import ModuleNameQconfigSetter,
from horizon_plugin_pytorch.quantization import get_qconfig 
from horizon_plugin_pytorch.quantization.qconfig_setter import *
my_qconfig_setter=QconfigSetter(
    reference_qconfig=get_qconfig(observer=MSEObserver),
    templates=[
      #1.全部算子配置为 int8 输出
      ModuleNameTemplate({"":qint8}),  
      #2.conv 的 input配置为 int8，weight配置为int8
      ConvDtypeTemplate(input_dtype=qint8, weight_dtype=qint8),  
      #3.matmul 两个输入均配置为 int8
      MatmulDtypeTemplate(input_dtypes=qint8), 
    ],
     save_dir=args.save_path,
    )
float_model.eval()
qat_model = prepare(
    float_model,
    example_inputs=example_input,
    qconfig_setter=my_qconfig_setter,
    check_result_dir=args.save_path
    )</code></pre><p>配置全局 int16 的方式与全局 int8 类似，将上述示例中的 qint8 修改为 qint16 即可。</p><p><strong>注意：</strong></p><ol><li>配置全局 feat 为 int8/int16/fp16 的时候必须要对 Conv 类算子的 weight 进行配置，否则 weight 会自动做 int16 计算，并可能出现不符合预期的 CPU 算子；</li><li>配置全局 int8 后，model\_check\_result.txt 可能会显示模型中仍然存在 int16 计算的算子，这是工具为了提升量化精度做的自动化行为，比如 norm 这种进行拆分实现的算子，内部采用 int16 较高精度的计算，然后输出为 int8。</li></ol><h4>3.1.2 配置全局 feature int16+weight int8+prefix 批量配置</h4><pre><code class="Plain">import torch
from horizon_plugin_pytorch.quantization import  prepare,set_fake_quantize,FakeQuantState
from horizon_plugin_pytorch.quantization import get_qconfig 
from horizon_plugin_pytorch.quantization.qconfig_setter import *
my_qconfig_setter=QconfigSetter(
    reference_qconfig=get_qconfig(observer=MSEObserver),
    templates=[
        #1.配置全局feat int16,weight int8
        ModuleNameTemplate({"":qint16}),
        ConvDtypeTemplate(input_dtype=qint16, weight_dtype=qint8),  
        MatmulDtypeTemplate(input_dtypes=qint16),  
        #2.配置backbone部分全int8
        ModuleNameTemplate({"backbone":qint8}),
        MatmulDtypeTemplate(
            input_dtypes=[qint8,qint8],
            prefix=["backbone"]
        ),    
        ConvDtypeTemplate(
            input_dtype=qint8, 
            weight_dtype=qint8,
            prefix= ["backbone"],
        ),
    ],
    save_dir=args.save_path,
    )

qat_model = prepare(
    float_model,
    example_inputs=example_input,
    qconfig_setter=my_qconfig_setter,
    check_result_dir=args.save_path)</code></pre><h3>3.2 fixscale 配置</h3><p>模型中的某些地方很难依靠统计的方式获得最佳的量化 scale，比如物理量，此时当算子的输出值域确定时就可以设置 fixed scale。新版 qconfig 模板配置 fixed scale 的方式为配置输入/输出的量化类型“dtype”和阈值“threshold”，其中 scale 的计算为：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438878" alt="" title="" loading="lazy"/></p><p>其中 threshold 一般为算子输入/输出的绝对值的最大值；n 则为量化位宽，比如 int8 量化位宽 n=8。</p><p>如下为配置 quantstub 算子输出 scale 和 conv 算子输入 scale 的示例：</p><pre><code class="Plain">import torch
from horizon_plugin_pytorch.quantization import  prepare,set_fake_quantize,FakeQuantState
from horizon_plugin_pytorch.quantization import get_qconfig 
from horizon_plugin_pytorch.quantization.qconfig_setter import *
my_qconfig_setter=QconfigSetter(
    reference_qconfig=get_qconfig(observer=MSEObserver),
    templates=[
        #1. 配置全局int8 
        ModuleNameTemplate({"":qint8}), 
        ConvDtypeTemplate(input_dtype=qint8, weight_dtype=qint8),  
        MatmulDtypeTemplate(input_dtypes=qint8),
        
        ModuleNameTemplate(
        { 
         #2.fixscale:配置算子输出的dtype和threshold，此时scale=1/128=0.0078125
         "backbone.quant":{"dtype":qint8,"threshold":1.0},
         #3.fixscale:配置conv的weight输入为fix_scale的int16量化，
         #scale=1/32768=3.0518e-05
         "backbone.conv1.conv1_2.conv":{"dtype": {"weight": qint16}, "threshold": {"weight": 1.0}},   
        },
        ),
],
    save_dir=args.save_path,    
)
qat_model = prepare(
    float_model,
    example_inputs=example_input,
    qconfig_setter=my_qconfig_setter,
    check_result_dir=args.save_path)</code></pre><p>通过 prepare 后生成的 <code>model_check_result.txt</code> 可以验证配置是否生效：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438879" alt="" title="" loading="lazy"/></p><h3>3.3 批量配置 conv/matmul 单/双 int16 输入</h3><p>ConvDtypeTemplate 和 MatmulDtypeTemplate 支持单/双 int16 输入的批量配置，相关示例如下：</p><pre><code class="Plain">import torch
from horizon_plugin_pytorch.quantization import  prepare,set_fake_quantize,FakeQuantState
from horizon_plugin_pytorch.quantization import get_qconfig 
from horizon_plugin_pytorch.quantization.qconfig_setter import *
my_qconfig_setter=QconfigSetter(
    reference_qconfig=get_qconfig(observer=MSEObserver),
    templates=[
        #1.基础配置全局激活&amp;weight int8
        ModuleNameTemplate({"":qint8}), 
        ConvDtypeTemplate(input_dtype=qint8, weight_dtype=qint8),  
        MatmulDtypeTemplate(input_dtypes=qint8),

        #2.Conv 单int16输入配置：将激活输入为int16(按需配置)
        ConvDtypeTemplate(
            input_dtype=qint16, 
            weight_dtype=qint8,
            prefix= ["backbone.res_layers.0","encoder.encoder.0.layers.0"],
            ),
        #3.Conv 单int16输入配置：将weight配置int16(按需配置)
        ConvDtypeTemplate(
            input_dtype=qint8, 
            weight_dtype=qint16,
            prefix= ["backbone.conv1.conv1_2.conv"],
            ),
        #4.Conv 双int16输入配置(按需配置)
        ConvDtypeTemplate(
            input_dtype=qint16, 
            weight_dtype=qint16,
            prefix= ["backbone.conv1.conv1_1.conv"],
            ),
        #5.matmul单int16配置：将第0个输入配置为int8,第1个输入配置成int16(按需配置)
         MatmulDtypeTemplate(
            input_dtypes=[qint8,qint16],
            prefix=["encoder.encoder.0.layers.0.self_attn.matmul","encoder.encoder.1.layers.0.self_attn.matmul"]
                 ),
        #6.matmul单int16配置：第0个输入配置成int16，将第1个输入配置为int8（按需配置)
        MatmulDtypeTemplate(
            input_dtypes=[qint16,qint8],
            prefix=["encoder.encoder.0.layers.1.self_attn.matmul"]
                 ),
        #7.matmul双int16配置：将2个输入都配置为双int16(按需配置)
        MatmulDtypeTemplate(
            input_dtypes=[qint16,qint16],
            prefix=["encoder.encoder.0.layers.2.self_attn.matmul"]
                 ),
],
    save_dir=args.save_path,    
)
qat_model = prepare(
    float_model,
    example_inputs=example_input,
    qconfig_setter=my_qconfig_setter,
    check_result_dir=args.save_path)</code></pre><h3>3.4 LoadFromFileTemplate 使用示例</h3><p>当从旧模板迁移到新的 qconfig 量化模板时，推荐的做法是先把旧版本的量化配置 qconfig\_dtypes.pt 保存下来，然后使用 LoadFromFileTemplate 进行加载，这里仅介绍此接口的用法，后续章节有完整的迁移教程。</p><p><strong>LoadFromFileTemplate 接口使用时需要注意以下问题：</strong></p><ol><li>qconfig\_dtypes.pt 不保存算子的 fix\_scale 信息，如果原 qconfig 里存在 fix\_scale 的算子，需要在加载 qconfig\_dtypes.pt 后再次进行配置。</li><li>使用 LoadFromFileTemplate 接口时 enable\_optimize 必须配置为 False，因为保存下来的 dtype 一般是优化后的，优化过程不可重入，Load qconfig\_dtypes.pt 后​<strong>不再支持对 qconfig 中 dtype 的修改</strong>​。</li></ol><p>LoadFromFileTemplate 使用示例如下：</p><pre><code class="Plain">import torch
from horizon_plugin_pytorch.quantization import  prepare,set_fake_quantize,FakeQuantState
from horizon_plugin_pytorch.quantization import get_qconfig 
from horizon_plugin_pytorch.quantization.qconfig_setter import *
my_qconfig_setter=QconfigSetter(
    reference_qconfig=get_qconfig(observer=MSEObserver),
    templates=[
         #1.加载量化配置pt文件
         LoadFromFileTemplate("qconfig_dtypes.pt"),
         #2.对fix_scale的算子进行补充配置
         ModuleNameTemplate({"backbone.quant":{"dtype":qint8,"threshold":1.0}})
    ],
    #3.无需开启任何优化
    enable_optimize=False,
    save_dir=args.save_path,)
qat_model = prepare(
    float_model,
    example_inputs=example_input,
    qconfig_setter=my_qconfig_setter,
    check_result_dir=args.save_path)</code></pre><h3>3.5 典型场景配置</h3><p>由于征程 6 系列平台的差异，qconfig 的配置自然也会有所区别。本节将结合平台差异，提供新版 qconfig 模板在典型场景下的配置示例。</p><h4>3.5.1 征程 6E/M 平台一般配置</h4><p>征程 6E/M 平台以定点算力为主，在进行混合量化精度调优过程中，建议以全局 int8 精度为例，针对部分对量化较为敏感的算子，可将其配置为更高的 int16 精度。以下为配置示例。</p><h5>配置示例 1：全局 int8+ 手动配置量化敏感度高的算子为 int16</h5><pre><code class="Plain">import torch
from horizon_plugin_pytorch.quantization import  prepare,set_fake_quantize,FakeQuantState
from horizon_plugin_pytorch.quantization import get_qconfig 
from horizon_plugin_pytorch.quantization.qconfig_setter import *
my_qconfig_setter=QconfigSetter(
    reference_qconfig=get_qconfig(observer=MSEObserver),
    templates=[
        #1.配置全局feat int8,weight int8
        ModuleNameTemplate({"":qint8}),
        ConvDtypeTemplate(input_dtype=qint8, weight_dtype=qint8),  
        MatmulDtypeTemplate(input_dtypes=qint8),  
        #2.根据精度debug工具分析，将敏感算子配置为int16(按需配置)
        #将weight敏感的conv配置为int16(按需配置)，支持批量配置
        ConvDtypeTemplate(
            input_dtype=qint8, 
            weight_dtype=qint16,
            prefix= ["backbone.conv1.conv1_3.conv"],
            ),
        #3.将敏感的Matmul配置为int16输入(按需配置)
        #将第0个输入敏感的matmul配置为int16(按需配置)，支持批量配置
        MatmulDtypeTemplate(
            input_dtypes=[qint16,qint8],
            prefix=["encoder.encoder.0.layers.0.self_attn.matmul"]
                 ),
    ],
    save_dir=args.save_path,
    )

qat_model = prepare(
    float_model,
    example_inputs=example_input,
    qconfig_setter=my_qconfig_setter,
    check_result_dir=args.save_path)</code></pre><h5>配置示例 2：全局 int8+ 使用敏感度模板配置部分敏感算子为 int16</h5><p>除了手动将部分敏感算子配置为 int16，新版 qconfig 模板提供了 SensitivityTemplate，该模板用于将精度 debug 工具所产出的敏感度列表中，量化敏感度排序 topk 或者占一定比率 ratio 的敏感算子，配置为更高的量化精度。相关示例如下：</p><pre><code class="Plain">import torch
from horizon_plugin_pytorch.quantization import  prepare,set_fake_quantize,FakeQuantState
from horizon_plugin_pytorch.quantization import get_qconfig 
from horizon_plugin_pytorch.quantization.qconfig_setter import *
#精度debug工具跑出来的算子量化敏感度列表
table1=torch.load("output1_ATOL_sensitive_ops.pt")
table2=torch.load("output2_ATOL_sensitive_ops.pt")
my_qconfig_setter=QconfigSetter(
    reference_qconfig=get_qconfig(observer=MSEObserver),
    templates=[
      #1. 基础配置全局激活&amp;weight int8
      ModuleNameTemplate({"":qint8}), 
      ConvDtypeTemplate(input_dtype=qint8, weight_dtype=qint8),  
      MatmulDtypeTemplate(input_dtypes=qint8),
      #2.配置output1输出敏感度Top10的算子为int16(按需配置)
      SensitivityTemplate(
        sensitive_table=table1,
        topk_or_ratio=10,  
    ),
      #3.配置output2输出敏感度10%的算子为int16(按需配置)
      SensitivityTemplate(
        sensitive_table=table2,
        topk_or_ratio=0.1, 
    ),   
    ],
    save_dir=args.save_path,)
qat_model = prepare(
    float_model,
    example_inputs=example_input,
    qconfig_setter=my_qconfig_setter,
    check_result_dir=args.save_path)</code></pre><p>topk\_or\_ratio 参数的选择：需要用户根据量化精度和部署性能进行权衡，一般来说，配置的高精度算子越多，量化精度越好，而部署性能影响则会越大。</p><h4>3.5.2 征程 6P/H 平台一般配置</h4><p>对于征程 6 P/H 这种有浮点算力的平台，推荐将 feature 输出配置为 fp16+conv 和 matmul 类算子全部配置为 int8 作为基础配置，然后再将量化敏感的算子配置为 int16。如下为配置示例。</p><h5>配置示例 1：基础配置 + 手动配置量化敏感度高的算子为 int16</h5><pre><code class="Plain">import torch
from horizon_plugin_pytorch.quantization import  prepare,set_fake_quantize,FakeQuantState
from horizon_plugin_pytorch.quantization.qconfig_template import ModuleNameQconfigSetter,
from horizon_plugin_pytorch.quantization import get_qconfig 
from horizon_plugin_pytorch.quantization.qconfig_setter import *
my_qconfig_setter=QconfigSetter(
    reference_qconfig=get_qconfig(observer=MSEObserver),
    templates=[
      #1.基本配置
      #全局 feat fp16
      ModuleNameTemplate({"": torch.float16}),
      #将conv和matmul类算子配置为全int8输入
      ConvDtypeTemplate( 
            input_dtype=qint8,
            weight_dtype=qint8,  
        ),
      MatmulDtypeTemplate(  
            input_dtypes=[qint8, qint8],
        ),
      #2.根据debug工具分析结果，将敏感的Conv/Matmul配置为int16输入(按需配置)
      #将conv中敏感的weight输入配置为int16(按需配置)
      ConvDtypeTemplate(
            input_dtype=qint8, 
            weight_dtype=qint16,
            prefix= ["backbone.conv1.conv1_3.conv"],
            ),
      #将matmul中敏感的输入配置为int16(按需配置)
       MatmulDtypeTemplate(
            input_dtypes=[qint16,qint8],
            prefix=["encoder.encoder.0.layers.0.self_attn.matmul"] ),
       
    ],
     save_dir=args.save_path,
    )
float_model.eval()
qat_model = prepare(
    float_model,
    example_inputs=example_input,
    qconfig_setter=my_qconfig_setter,
    check_result_dir=args.save_path
    )</code></pre><h5>配置示例 2：基础配置 + 使用敏感度模板配置部分敏感算子为 int16</h5><pre><code class="Plain">import torch
from horizon_plugin_pytorch.quantization import  prepare,set_fake_quantize,FakeQuantState
from horizon_plugin_pytorch.quantization import get_qconfig 
from horizon_plugin_pytorch.quantization.qconfig_setter import *
#精度debug工具跑出来的算子量化敏感度列表
table1=torch.load("output1_ATOL_sensitive_ops.pt")
table2=torch.load("output2_ATOL_sensitive_ops.pt")
my_qconfig_setter=QconfigSetter(
    reference_qconfig=get_qconfig(observer=MSEObserver),
    templates=[
      #1.基本配置
      #全局 feat fp16
      ModuleNameTemplate({"": torch.float16}),
      #将conv和matmul类算子配置为全int8输入
      ConvDtypeTemplate( 
            input_dtype=qint8,
            weight_dtype=qint8,  
        ),
      MatmulDtypeTemplate(  
            input_dtypes=[qint8, qint8],
        ),
      #2.配置output1输出敏感度Top10的算子为int16(按需配置)
      SensitivityTemplate(
        sensitive_table=table1,
        topk_or_ratio=10,  
    ),
      #3.配置output2输出敏感度10%的算子为int16(按需配置)
      SensitivityTemplate(
        sensitive_table=table2,
        topk_or_ratio=0.1, 
    ),   
    ],
    save_dir=args.save_path,)
qat_model = prepare(
    float_model,
    example_inputs=example_input,
    qconfig_setter=my_qconfig_setter,
    check_result_dir=args.save_path)</code></pre><h4>3.5.3 配置算子为 float32 计算</h4><p>在做精度调优的时候，有时候想要快速定位引起量化误差的瓶颈，此时会将模型片段或者算子配置为 float32 计算，如下为将指定模型片段和算子配置为 float32 计算的示例：</p><pre><code class="Plain">my_qconfig_setter=QconfigSetter(
    reference_qconfig=get_qconfig(observer=MSEObserver),
    templates=[
        #1. 基础配置全局激活&amp;weight int8
        ModuleNameTemplate({"":qint8}), 
        ConvDtypeTemplate(input_dtype=qint8, weight_dtype=qint8),  
        MatmulDtypeTemplate(input_dtypes=qint8),
        
        ModuleNameTemplate(
        { 
         #2.批量配置"encoder.encoder.0.layers.0"为float32计算
         "encoder.encoder.0.layers.0": torch.float32,
         #3.配置"backbone.conv1.conv1_2.conv.act"算子为float32计算
         "backbone.conv1.conv1_2.conv.act": torch.float32,}
            ),
    ],
    save_dir=args.save_path,    
)</code></pre><h4>3.5.4 QAT 训练时固定激活 scale</h4><p>在 QAT 精度调优实践中发现（主要是图像分类任务实验），做完 calibration 后，把 activation 的 scale 固定住，不进行更新，即设置 activation 的 <code>averaging_constant=0</code> ，QAT 训练精度相比于不固定 activation 的 scale 的量化精度会更好。相关配置示例如下所示：</p><pre><code class="Plain">import torch
from horizon_plugin_pytorch.quantization import  prepare,set_fake_quantize,FakeQuantState
from horizon_plugin_pytorch.quantization.fake_quantize import FakeQuantize
from horizon_plugin_pytorch.quantization.qconfig import QConfig
from horizon_plugin_pytorch.quantization.qconfig_setter import *
from horizon_plugin_pytorch.quantization import get_qconfig 
my_qconfig_setter=QconfigSetter(
    #将激活的averaging_constant参数配置为0
    reference_qconfig= QConfig(
        output=FakeQuantize.with_args(
            observer=MinMaxObserver,
            averaging_constant=0,#averaging_constant配置为0
        ), ),
    templates=[
      #配置weight和激活全局int8
      ModuleNameTemplate({"":qint8}), 
      ConvDtypeTemplate(input_dtype=qint8, weight_dtype=qint8),  
      MatmulDtypeTemplate(input_dtypes=qint8),
    ],
    save_dir=args.save_path,
    )

qat_model = prepare(
    float_model,
    example_inputs=example_input,
    qconfig_setter=my_qconfig_setter,
    check_result_dir=args.save_path
    )</code></pre><h2>4. 新版 qconfig 模板迁移</h2><p>用户在迁移到新版 qconfig 模板时，建议根据以下情况进行不同的操作：</p><ol><li>如果用户部署平台为征程 6B、征程 6H 和征程 6P，为了更方便地利用浮点算力，建议使用新版 qconfig 模板。</li><li>如果用户模型从未适配过 QAT 链路，建议用户直接参考第 3 章使用新版 qconfig 模板进行配置。</li><li>如果用户模型已经适配过老版本 qconfig 模板，且在模型迭代中还需要修改 qconfig 配置，比如增加 int16 算子等，那么建议用户参考第 3 章重新进行新版 qconfig 模板的适配。</li><li>如果用户模型已经适配过老版本 qconfig 模板，且确认在模型迭代中不再需要修改 qconfig 配置，那么则建议用户按照下面的流程进行迁移工作。</li></ol><p>若用户已经稳定使用老版本 qconfig 模板，而且模型迭代中不需要再修改量化配置，那么建议按照以下流程进行适配：</p><ol><li>首先，使用 <code>SaveToFileTemplate</code> 接口保存旧模板下的量化配置文件 <code>qconfig_dtypes.pt</code>，其中涵盖每个算子的 dtype；</li><li>其次，需检查模型中是否存在采用 fix\_scale 的算子。鉴于 qconfig\_dtypes.pt 目前尚不支持保存 fix\_scale 的算子信息，并且新旧模板在 fix\_scale 的配置方面存在差异，若存在 fix\_scale 的算子，那么就必须对新模板下 fix\_scale 的配置进行适配；</li><li>最后，运用 <code>LoadFromFileTemplate</code> 接口加载已保存的 <code>qconfig_dtypes.pt</code>​<code> </code> 文件，将量化 dtypes 配置导入新模板中，从而实现量化配置的迁移衔接。</li></ol><p>这里要特别注意，加载已保存的 <code>qconfig_dtypes.pt</code> 文件后不支持再对模型中的算子 dtype 做修改。</p><p>下面将详细介绍迁移的具体步骤和操作要点。</p><h3>4.1 保存旧版本的 qconfig\_dtypes 文件</h3><p><code>horizon_plugin_pytorch</code>​<code> </code> 提供了 <code>SaveToFileTemplate</code> 接口用于将量化配置文件保存为 <code>qconfig_dtypes.pt</code>。其路径和使用方式如下：</p><pre><code class="Plain">from horizon_plugin_pytorch.quantization.qconfig_setter.templates import *
...
qat_model = prepare(
    float_model,
    example_inputs=example_input,
    qconfig_setter=(
        ModuleNameQconfigSetter(...),
        calibration_8bit_weight_16bit_act_qconfig_setter,
    ),
    check_result_dir=args.save_path,
    )
#prepare后保存
#args.save_path为qconfig_dtypes.pt保存路径
save_api=SaveToFileTemplate(args.save_path)
save_api(None, qat_model, None, None, None)</code></pre><p>在完成修改并运行后，于 args.save\_path 目录下将会生成包含量化 dtype 的 qconfig\_dtypes.pt 与 qconfig\_dtypes.pt.py 文件。</p><h3>4.2 适配 fix\_scale 的配置</h3><p>目前，<code>qconfig_dtypes.pt</code>​<code> </code> 文件在保存量化配置信息时，存在一定的功能限制，即尚不支持对配置了 fix\_scale 的算子信息进行保存。这意味着当用户在旧版本 qconfig 中对部分算子设置了 fix\_scale 时，相关的配置无法通过 <code>qconfig_dtypes.pt</code>​<code> </code> 文件完整迁移至新模板。</p><p>因此，若用户的模型中存在配置 fix\_scale 的算子，fix\_scale 的算子和相应配置可以通过 <code>model_check_result.txt</code> 获取，为确保量化配置能够对齐旧版本，必需按照上文 3.2 章节所阐述的适配规则和操作步骤，手动对 fix\_scale 的配置进行调整与适配，以使其符合新模板的要求。</p><h3>4.3 加载 <code>qconfig_dtypes.pt</code> 文件</h3><p>使用 <code>LoadFromFileTemplate</code> 加载旧版本模板 qconfig\_dtypes.pt 时，为确保与旧版本行为相适配，必须对特定参数予以配置。否则，可能会面临加载 calib/qat 权重失败的问题。以下为相关参数的详细阐述：</p><ol><li>对于 <code>QconfigSetter()</code>，应将“enable\_optimize”参数配置为“False”，以此避免启用任何新版本中的默认优化。</li><li>针对 <code>LoadFromFileTemplate()</code>，务必将“only\_set\_mod\_in\_graph”参数配置为“False”。原因在于，在老版本配置中，存在对非 graph 中的操作进行 qconfig 设置的情形。</li><li>在执行 <code>prepare</code> 操作时，需将“fuse\_mode”参数配置为“FuseMode.BNAddReLU”，进而实现与老版本行为的对齐。</li></ol><p><strong>以下为完整的使用示例：</strong></p><pre><code class="Plain">import torch
from horizon_plugin_pytorch.quantization import  prepare,set_fake_quantize,FakeQuantState
from horizon_plugin_pytorch.quantization import get_qconfig 
from horizon_plugin_pytorch.quantization.qconfig_setter import *

my_qconfig_setter=QconfigSetter(
    reference_qconfig=get_qconfig(observer=MSEObserver),
    templates=[
        ModuleNameTemplate(
        { #1.适配fix_scale的配置
          "backbone.quant":{"dtype":qint8,"threshold":1.0},
          }
        #2.Load旧模板下保存的qconfig_dtypes.pt
        LoadFromFileTemplate(
        "./qconfig_old/qconfig_dtypes.pt",
        #3.该参数需要设置 False，原来配置中有对非 graph 中的 op 设置 qconfig
        only_set_mod_in_graph=False,
    ),],
    save_dir=args.output_dir,
    #4.无需开启任何优化,关闭enable_optimize
    enable_optimize=False,
    )
from horizon_plugin_pytorch.quantization.fx.fusion_patterns import FuseMode
qat_model = prepare(
    float_model,
    example_inputs=example_input,
    qconfig_setter=my_qconfig_setter,
    check_result_dir=args.output_dir,
    #5.对齐老版本的融合行为
    fuse_mode=FuseMode.BNAddReLU,
    )
          </code></pre>]]></description></item><item>    <title><![CDATA[打造专属知识大脑：个人电脑上的本地私有知]]></title>    <link>https://segmentfault.com/a/1190000047438816</link>    <guid>https://segmentfault.com/a/1190000047438816</guid>    <pubDate>2025-11-30 16:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>打造专属知识大脑：个人电脑上的本地私有知识库全攻略</h2><h3>为什么你需要一个本地私有知识库？</h3><p>想象一下：当你突然需要查找半年前读过的那篇精彩文章，或者在会议中急需某个重要数据，却发现自己收藏的内容散落在微信、浏览器、笔记软件等十几个地方...这种场景是不是很熟悉？</p><p>在信息爆炸的时代，我们每天都在接收海量信息，但真正能内化为个人知识资产的却少之又少。这就是为什么你需要一个<strong>本地私有知识库</strong>——它就像是为你的大脑配备了一个外接硬盘，帮你：</p><ul><li><strong>永久保存</strong>重要资料，不再担心链接失效</li><li><strong>快速检索</strong>任何信息，秒级找到所需内容</li><li><strong>建立知识连接</strong>，让零散信息形成知识网络</li><li><strong>完全私密安全</strong>，所有数据都保存在你的电脑上</li></ul><h3>本地私有知识库的核心优势</h3><h4>数据安全，完全掌控</h4><p>与云端存储不同，本地知识库的所有数据都保存在你的个人设备上。这意味着：</p><ul><li>不用担心服务商突然停止运营</li><li>不会因为账号问题丢失珍贵资料</li><li>敏感信息完全由自己掌控</li></ul><h4>离线可用，随时随地</h4><p>即使没有网络连接，你依然可以：</p><ul><li>查看所有已保存的内容</li><li>进行全文检索</li><li>整理和编辑知识</li></ul><h4>个性化定制，贴合习惯</h4><p>你可以按照自己的思维习惯来组织知识结构，打造真正属于自己的知识体系。</p><h3>优秀本地知识库推荐：访答知识库</h3><p>在众多知识库软件中，知识库以其出色的用户体验和强大的功能脱颖而出。</p><h4>为什么选择访答？</h4><p><strong>智能收集，一键归档</strong>  <br/>访答支持从网页、文档、图片等多种来源快速收集信息。遇到有价值的内容，只需简单操作就能将其纳入你的知识体系。</p><p><strong>强大的关联能力</strong>  <br/>它能够自动识别内容间的关联性，帮助你发现知识之间的内在联系，让零散的信息形成有机的知识网络。</p><p><strong>流畅的搜索体验</strong>  <br/>基于本地索引的搜索功能，让你在数千条记录中也能秒级找到目标内容，大大提升知识复用效率。</p><p><strong>简洁优雅的界面</strong>  <br/>清爽的界面设计让知识管理变成一种享受，而不是负担。</p><h4>我的使用体验</h4><p>自从开始使用构建个人知识库，我的工作效率得到了显著提升。以前需要花费半小时查找的资料，现在几秒钟就能找到。更重要的是，通过持续的知识积累，我开始发现不同领域知识间的奇妙联系，这为我的创作和工作带来了源源不断的灵感。</p><h3>如何开始构建你的知识库？</h3><h4>第一步：明确需求</h4><p>先思考你主要想管理哪些类型的知识：</p><ul><li>工作文档和项目资料</li><li>学习笔记和研究材料</li><li>灵感收集和创意素材</li><li>个人生活和兴趣内容</li></ul><h4>第二步：选择合适的工具</h4><p>根据你的需求和技术水平选择合适的知识库软件。如果你注重易用性和美观度，是个不错的选择。</p><h4>第三步：建立分类体系</h4><p>不要一开始就追求完美的分类结构。建议：</p><ul><li>从简单的几个大类开始</li><li>随着内容增多再逐步细化</li><li>善用标签系统进行多维度分类</li></ul><h4>第四步：养成收集习惯</h4><p>知识库的价值在于持续积累：</p><ul><li>每天花10分钟整理当天收集的信息</li><li>定期回顾和整理旧内容</li><li>建立固定的知识处理流程</li></ul><h3>进阶技巧：让知识库真正为你所用</h3><h4>建立个人工作流</h4><p>将知识库融入你的日常工作流程：</p><ul><li>项目启动前先搜索相关经验</li><li>会议前快速回顾背景资料</li><li>定期从知识库中提炼总结</li></ul><h4>知识复利效应</h4><p>随着时间的推移，你的知识库会像滚雪球一样产生复利效应：</p><ul><li>新旧知识相互碰撞产生新见解</li><li>积累的专业知识形成个人竞争力</li><li>减少重复学习和查找的时间浪费</li></ul><h3>立即开始，打造你的第二大脑</h3><p>不要再让宝贵的知识和灵感流失在信息的海洋中。选择一个合适的本地私有知识库，比如，开始构建属于你自己的知识体系。</p><p>记住，知识管理的核心不是工具本身，而是持续积累和有效利用的习惯。从今天开始，每天花一点点时间整理知识，一年后你会惊喜地发现，自己已经拥有了一个强大的个人知识资产。</p><p>你的知识，值得被更好地管理和利用。现在就开始行动吧！</p><p><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdndal" alt="" title=""/></p>]]></description></item><item>    <title><![CDATA[AI技术驱动下的招聘行业转型 爱跑步的香]]></title>    <link>https://segmentfault.com/a/1190000047438744</link>    <guid>https://segmentfault.com/a/1190000047438744</guid>    <pubDate>2025-11-30 13:02:11</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>AI技术驱动下的招聘行业转型<br/>当前招聘领域正经历深刻变革，智能化转型已成为不可逆转的趋势。过去一年间，人力资源行业在AI技术的推动下呈现出明显的分化态势：部分企业仍采用传统的人工筛选、沟通方式，而领先企业已实现全流程智能化管理。<br/>多项数据显示，AI技术正在重塑招聘行业的效率标准，具体表现为以下案例与数据：<br/>•智联招聘采用AI全托管系统后，招聘周期缩短40%；<br/>•某大型国有银行运用AI技术将面试到场率提升至90.7%；<br/>•辉瑞制药通过AI技能图谱精准识别人才缺口，研发创新周期缩短22%；<br/>•49.6%的企业已完成HR流程的AI优化；<br/>•ING银行将AI应用于组织健康诊断与薪酬策略，管理决策效率提升50%。<br/>这些案例表明，AI技术已从单纯的效率工具，逐步发展为能够辅助招聘及管理决策的重要支持系统，其应用价值在多个环节得到充分体现。</p><p>一、AI面试评分的科学化应用<br/>传统招聘中主观判断因素较多，评估结果易受个人经验影响，而AI面试系统通过建立标准化评估体系，有效提升了人才评估的准确性与客观性，核心实现方式包括：<br/>•采用效标效度与重测稳定信度双指标验证体系，确保评估标准的科学性；<br/>•经过大规模人机背靠背实验验证，不断优化评估模型；<br/>•评估结果与资深面试官判断高度一致，具备实际应用价值。<br/>目前，最新版本的AI面试系统已进一步提升技术成熟度，其评分结果可直接为招聘决策提供参考依据。<br/>二、全流程精准化设计<br/>AI系统贯穿招聘全流程，通过功能优化实现各环节的精准赋能，打破了传统工具的应用局限，具体优势体现在：<br/>•一问多能：单道面试题可同步评估多项胜任力指标，使评估效率提升50%以上；<br/>•智能追问：基于语义理解技术实时生成针对性追问，确保核心能力评估的完整性；<br/>•简历深度分析：自动识别候选人简历中的能力亮点与信息疑点，辅助HR高效筛选；<br/>•全维度测评：覆盖通用能力与专业技能两大维度，支持根据岗位需求自动生成测评题目。<br/>凭借这些功能优势，AI招聘系统已在初筛及技术复试等关键环节发挥重要作用，成为招聘团队的核心辅助工具。<br/>三、候选人体验优化<br/>针对早期AI面试系统存在的体验不佳问题，新一代系统从候选人需求出发进行全面升级，通过人性化设计提升面试参与度，具体改进包括：<br/>•新增情绪识别与引导功能，实时感知候选人状态并给予适当提示，提升其表现稳定性；<br/>•采用无断点交互设计，模拟真实面试中的对话场景，降低使用陌生感；<br/>•优化视觉呈现效果，增强场景沉浸感，提升整体面试体验；<br/>•支持多轮问答互动，及时解答候选人关于面试流程的疑问，减少信息不对称。<br/>在人才竞争日益激烈的市场环境下，优质的面试体验已成为企业雇主品牌建设的重要组成部分，AI系统的体验优化对此具有积极意义。<br/>四、全流程自动化人才寻访<br/>除面试评估环节外，AI技术在人才寻访领域的应用也实现了突破性进展，自动化人才寻访系统完成了从人才识别到信息录入的全流程智能化覆盖，核心功能包括：<br/>•快速初始化部署：可根据企业招聘需求快速完成系统配置，缩短上线周期；<br/>•自动筛选与智能沟通：基于岗位画像自动筛选匹配人才，并通过智能话术完成初步沟通；<br/>•全覆盖应答机制：针对候选人常见问题实现24小时自动应答，提升沟通效率；<br/>•数据自动同步：将候选人信息及沟通记录自动同步至企业HR系统，实现数据无缝对接。<br/>该系统的应用显著降低了人才寻访环节的人工成本，提升了整体招聘效率与人才匹配精准度。<br/>五、技术应用的验证路径<br/>为帮助企业降低AI技术应用风险，目前相关AI招聘系统已提供实际场景验证渠道，企业用户可在真实的招聘环境中，对系统在面试、测评、筛选等多个环节的效果进行全面测试。这种低风险的体验途径，为招聘团队了解并应用AI技术提供了便利。<br/>从应用实践来看，多家知名企业及高校已引入这类AI招聘工具，其实际应用效果获得了行业认可。当前，AI招聘技术的发展重点集中于精准选人与体验提升两大方向，最新版本的系统在这两个维度均展现出较高的技术水平，为招聘行业的智能化转型提供了有力支撑。</p>]]></description></item><item>    <title><![CDATA[连接池的价值与风险——池化提升与资源枯竭]]></title>    <link>https://segmentfault.com/a/1190000047438753</link>    <guid>https://segmentfault.com/a/1190000047438753</guid>    <pubDate>2025-11-30 13:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <blockquote>连接池是现代应用架构中的基础设施，用好了是性能加速器，配置不当则成为系统崩溃的导火索</blockquote><p>在数据库应用系统中，连接管理是影响性能的关键因素之一。数据库连接池通过池化技术将昂贵的数据库连接进行复用，显著提升了系统性能，但不当的配置和使用也会导致资源枯竭甚至系统崩溃。本文将深入探讨连接池的工作机制、优化策略以及风险防范，帮助开发者掌握这一强大而危险的工具。</p><h2>1 连接池的本质与演进历程</h2><h3>1.1 连接池解决的核心问题</h3><p>在传统的数据库访问模式中，应用程序每次需要与数据库交互时都会创建新的连接，完成操作后立即关闭。这种方式存在明显的性能缺陷：建立数据库连接是​<strong>昂贵操作</strong>​，通常需要 10-20ms 的耗时，涉及 TCP 三次握手、数据库身份验证和会话初始化等多个步骤 。</p><p>连接池通过<strong>连接复用</strong>机制解决了这一性能瓶颈。它在系统初始化时创建一定数量的数据库连接并维护在池中，当应用程序需要连接时，直接从池中获取空闲连接而非新建，使用完毕后归还给连接池而非实际关闭 。这种机制特别适合 Web 应用等高并发场景，其中大量短生命周期请求频繁访问数据库 。</p><h3>1.2 连接池的演进历程</h3><p>连接池技术经历了从简单到复杂、从功能单一到智能管理的演进过程。早期连接池如 DBCP 和 C3P0 奠定了基本模式，现代连接池如 HikariCP 和 Druid 则在性能和可观测性方面有了显著提升 。</p><p><strong>HikariCP</strong> 以其极简设计和卓越性能成为 Spring Boot 的默认连接池，它通过无锁并发结构和字节码优化实现了在高并发场景下的优异表现 。<strong>Druid</strong> 则提供了更为全面的功能，包括 SQL 监控、防御注入攻击和可视化界面，适合需要深度监控的复杂企业环境 。</p><h2>2 连接池的核心价值与性能提升机制</h2><h3>2.1 性能提升的三重机制</h3><p>连接池通过三种核心机制提升系统性能：<strong>连接复用</strong>避免了频繁创建和销毁连接的开销，使系统能够将资源集中于业务处理而非连接管理 。<strong>连接预热</strong>在系统启动阶段初始化连接，保证服务就绪后立即具备处理能力，避免首批请求的冷启动延迟 。<strong>统一管理</strong>通过参数配置实现连接的合理分配和故障转移，提高系统稳定性 。</p><h3>2.2 资源消耗优化</h3><p>连接池通过多种机制优化资源使用：<strong>资源回收</strong>自动关闭空闲超时连接，防止资源泄露 。<strong>弹性伸缩</strong>根据系统负载动态调整活跃连接数，平衡性能与资源消耗 。<strong>失效检测</strong>通过心跳机制识别并替换失效连接，保证连接可用性 。</p><h2>3 连接池的潜在风险与资源枯竭场景</h2><h3>3.1 连接泄露与池耗尽</h3><p><strong>连接泄露</strong>是连接池最常见的问题，当应用程序获取连接后未正确释放，会导致池中可用连接逐渐减少直至耗尽 。典型场景包括异常路径下未在 finally 块中关闭连接、框架配置错误导致连接未归还等。</p><p><strong>连接池耗尽</strong>则发生在系统并发请求超过连接池最大容量时，新请求将陷入长时间等待或直接失败 。这种状况通常由突发流量、慢查询累积或下游系统故障引发。</p><h3>3.2 错误配置的连锁反应</h3><p>不合理的参数配置会引发多种问题：<strong>过大连接数</strong>可能压垮数据库，导致级联故障 。<strong>过长等待时间</strong>会耗尽应用服务器资源，造成系统假死 。<strong>不足验证</strong>会导致应用使用无效连接，增加业务失败率 。</p><h2>4 关键配置参数与调优策略</h2><h3>4.1 容量规划参数</h3><p>​<strong>最大连接数</strong>​（maxActive/maximumPoolSize）是连接池最重要的参数，直接影响系统最大并发能力。设置过小会导致请求阻塞，设置过大会增加数据库负担 。经验公式为：<code>最大连接数 = (核心数 * 2) + 磁盘数</code>，但需根据实际业务测试调整 。</p><p>​<strong>最小空闲连接</strong>​（minIdle/minimumIdle）决定了池中保持的最小空闲连接数，合理设置可以平衡突发流量响应与资源消耗 。通常设置为最大连接数的 25%-50%，根据业务波动特征调整 。</p><h3>4.2 健康检测参数</h3><p>​<strong>验证查询</strong>​（validationQuery）是简单的 SQL 语句（如 SELECT 1），用于检查连接是否有效 。​<strong>测试策略</strong>​（testOnBorrow/testWhileIdle）决定了何时执行验证，<code>testWhileIdle</code> 模式在性能与可靠性间提供了较好平衡 。</p><p>​<strong>存活时间</strong>​（maxLifetime）控制连接最大存活时间，避免长期运行导致的隐性问题 。​<strong>空闲超时</strong>​（idleTimeout）自动回收闲置连接，释放资源 。</p><h2>5 监控指标与故障诊断</h2><h3>5.1 核心监控指标</h3><p><strong>活跃连接数</strong>反映系统当前负载，持续接近最大值表明需要扩容 。<strong>等待线程数</strong>显示排队等待连接的请求数，非零值表示连接不足 。<strong>连接获取时间</strong>直接影响用户体验，突增通常预示问题 。</p><h3>5.2 故障诊断流程</h3><p>当出现连接池问题时，系统化的诊断流程至关重要：首先检查​<strong>基础指标</strong>​，确认活跃连接、等待线程等关键数据 。然后分析​<strong>等待链</strong>​，找出持有连接时间过长的操作 。最后检查​<strong>系统资源</strong>​，确认数据库负载和网络状况 。</p><h2>6 不同场景下的配置策略</h2><h3>6.1 高并发 Web 应用</h3><p>对于在线交易类应用，推荐配置：较小​<strong>最大连接数</strong>​（20-100）避免数据库过载，较短​<strong>最大等待时间</strong>​（1-3 秒）快速失败而非阻塞，启用<strong>泄露检测</strong>快速定位未关闭连接 。</p><h3>6.2 批处理与报表系统</h3><p>对于长时间运行的数据处理任务，适合的配置包括：适中​<strong>连接数</strong>​（10-30）减少数据库压力，较长<strong>超时设置</strong>适应复杂查询，开启<strong>事务隔离</strong>保证数据一致性 。</p><h2>7 连接池选型指南</h2><h3>7.1 性能优先场景</h3><p><strong>HikariCP</strong> 是性能敏感场景的首选，其极简设计和高并发性能表现优异 。适合微服务架构和云原生环境，特别是容器化部署的轻量级应用 。</p><h3>7.2 可观测性优先场景</h3><p><strong>Druid</strong> 提供丰富的监控功能，适合需要详细连接统计和 SQL 分析的企业环境 。内置防 SQL 注入和慢查询检测功能，为复杂应用提供全方位保护 。</p><h2>总结</h2><p>连接池是现代应用架构中的关键组件，正确使用可以提升性能几个数量级，配置不当则会导致系统脆弱不堪。成功的连接池管理需要深入理解业务特征、持续监控关键指标以及建立完善的故障处理机制。</p><p>连接池优化不是一次性的任务，而是需要随着业务发展不断调整的持续过程。通过科学的容量规划、细致的监控预警和快速的故障响应，可以最大化连接池的价值，避免资源枯竭风险。</p><hr/><p><strong>📚 下篇预告</strong>​</p><p>《MyBatis 设计观——映射思想、动态 SQL 的边界与可维护性考量》—— 我们将深入探讨：</p><ul><li>🗺️ ​<strong>ORM 映射哲学</strong>​：MyBatis 如何平衡数据库操作与面向对象思维的鸿沟</li><li>🔄 ​<strong>动态 SQL 边界</strong>​：何时使用动态 SQL，何时应该避免过度灵活带来的复杂性</li><li>🏗️ ​<strong>架构可维护性</strong>​：MyBatis 项目结构与配置组织的最佳实践</li><li>⚡ ​<strong>性能优化策略</strong>​：MyBatis 缓存机制与 SQL 执行过程的调优要点</li><li>🔍 ​<strong>代码生成与手写平衡</strong>​：如何在开发效率与控制力之间找到最佳平衡点</li></ul><p><strong>​点击关注，掌握 MyBatis 设计的精髓！​</strong>​</p><blockquote><p>​<strong>今日行动建议</strong>​：</p><ol><li>检查当前项目连接池配置，对比本文推荐值进行合理性评估</li><li>在测试环境模拟连接泄露场景，验证监控告警有效性</li><li>对关键业务接口进行压力测试，确定连接池参数的最优值</li><li>建立连接池监控仪表盘，跟踪核心指标变化趋势</li></ol></blockquote>]]></description></item><item>    <title><![CDATA[【URP】Unity[内置Shader]]]></title>    <link>https://segmentfault.com/a/1190000047438702</link>    <guid>https://segmentfault.com/a/1190000047438702</guid>    <pubDate>2025-11-30 12:03:00</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <blockquote><a href="https://link.segmentfault.com/?enc=x2UIDTjMy30QedSAazUgnQ%3D%3D.LFI0ucK6di2ZW8gxLKjdiWPGeLaJ4HtFlEwe7oVXWnpnh4F1EPMsdZDzVKsOR%2FUC9MYX%2BVS%2FYUPD3aijcVJZoOlJAJlcJ42qi%2Bsa2oBSezflTeH6uQynczL%2Blm3wmOTXi3mhDcvunX30NN%2Fqy6tJ7UZrR9dLSNrLGCzrbLjcttetuNmiY83sNQLosvJReRH05o6mtqRuyk%2BjP3zq6uCTVKKi8P3kVONwvUPqqdPJcLs%3D" rel="nofollow" target="_blank">【从UnityURP开始探索游戏渲染】</a><strong>专栏-直达</strong></blockquote><h2><strong>URP内置Unlit Shader的作用与原理</strong></h2><p><a href="https://link.segmentfault.com/?enc=fs%2F%2F%2BRXwo1wf8sx8L6ogag%3D%3D.shou9%2FoPJ%2FEq8xnXfUuE5qj%2BoJs8SVkc0XsbVsiuH9P9kG%2FvMUY%2Fb0llbMLODkTMKQG8RO9Wpz87nqQ8PrOEpsQU3X%2BymEsH9oyTcaHFTTFCL90Pdhe9a%2BFCS%2FRgRxVgzWMWsCOI2GyyX5dNRf5DRw%3D%3D" rel="nofollow" target="_blank">Unlit Shader</a>是Unity通用渲染管线(URP)中的基础着色器，主要用于渲染不受光照影响的物体。其核心原理是通过直接采样纹理或颜色值输出到屏幕，跳过了复杂的光照计算流程。这种着色器特别适合UI元素、粒子特效、全息投影等需要保持恒定亮度的场景，因为它的渲染结果不会随光照环境变化而改变。</p><p>在URP架构中，Unlit Shader通过ShaderLab语法定义，内部使用HLSL编写核心逻辑。与Built-in管线相比，URP版本优化了渲染流程，包含三个关键Pass：主绘制Pass、深度Only Pass和元数据Pass（用于光照烘焙）。其核心特点是：</p><ul><li>无光照计算：直接输出Albedo颜色或纹理采样结果</li><li>支持Alpha混合：可实现透明效果</li><li>移动端优化：减少了GPU指令数量</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438704" alt="" title=""/></p><h2><strong>发展历史演变</strong></h2><p>Unlit Shader随着Unity渲染管线的演进经历了三个阶段：</p><ul><li>‌<strong>Built-in管线时期</strong>‌（2012-2018）：最初作为简单着色器出现在标准资源包中，使用CG语言编写，功能较为基础</li><li>‌<strong>LWRP过渡期</strong>‌（2018-2020）：轻量级渲染管线中首次针对移动平台优化，引入HLSL替代CG</li><li>‌<strong>URP成熟期</strong>‌（2020至今）：成为Universal RP的核心组件，支持Shader Graph可视化编程，并优化了多Pass协作机制</li></ul><h2><strong>具体使用示例</strong></h2><p>创建Unlit材质的基本步骤：</p><ul><li>在Project窗口右键创建Material</li><li>材质Inspector中选择Shader路径："Universal Render Pipeline/Unlit"</li><li><p>配置基础属性：</p><ul><li>‌<strong>Base Map</strong>‌：主纹理贴图</li><li>‌<strong>Base Color</strong>‌：色调叠加</li><li>‌<strong>Alpha</strong>‌：透明度控制</li></ul></li></ul><p>代码说明：</p><ul><li>定义包含纹理和颜色属性的基础Unlit Shader</li><li>使用URP核心库中的TransformObjectToHClip方法进行坐标转换</li><li>片元着色器直接返回纹理采样结果与颜色的乘积</li><li><p>UnlitExample.shader</p><pre><code class="c">Shader "Custom/UnlitTexture"
{
    Properties {
        _MainTex ("Texture", 2D) = "white" {}
        _Color ("Color", Color) = (1,1,1,1)
    }
    SubShader {
        Tags { "RenderType"="Opaque" }
        Pass {
            HLSLPROGRAM
            #pragma vertex vert
            #pragma fragment frag
            #include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl"

            struct Attributes {
                float4 positionOS : POSITION;
                float2 uv : TEXCOORD0;
            };

            struct Varyings {
                float4 positionCS : SV_POSITION;
                float2 uv : TEXCOORD0;
            };

            sampler2D _MainTex;
            float4 _Color;

            Varyings vert(Attributes IN) {
                Varyings OUT;
                OUT.positionCS = TransformObjectToHClip(IN.positionOS.xyz);
                OUT.uv = IN.uv;
                return OUT;
            }

            half4 frag(Varyings IN) : SV_Target {
                return tex2D(_MainTex, IN.uv) * _Color;
            }
            ENDHLSL
        }
    }
}</code></pre></li><li><p>UnlitGraph.shadergraph</p><pre><code class="c">{
    "m_Nodes": [
        {
            "m_Id": "d4f5e3c7-1a2d-4b8f-a3e1-6c9b8d2e1f0a",
            "m_Type": "UnityEditor.ShaderGraph.Texture2DNode",
            "m_Position": { "x": -208, "y": -16 },
            "m_Outputs": [ { "m_Id": "out" } ],
            "m_Texture": { "m_DefaultValue": {} }
        },
        {
            "m_Id": "a1b2c3d4-e5f6-7g8h-9i0j-k1l2m3n4o5p6",
            "m_Type": "UnityEditor.ShaderGraph.ColorNode",
            "m_Position": { "x": -200, "y": 100 },
            "m_Outputs": [ { "m_Id": "out" } ],
            "m_Color": { "r": 1, "g": 1, "b": 1, "a": 1 }
        },
        {
            "m_Id": "b2c3d4e5-f6g7-8h9i-0j1k-l2m3n4o5p6q7",
            "m_Type": "UnityEditor.ShaderGraph.MultiplyNode",
            "m_Position": { "x": 0, "y": 0 },
            "m_Inputs": [
                { "m_Id": "a", "m_SlotId": 0 },
                { "m_Id": "b", "m_SlotId": 1 }
            ],
            "m_Outputs": [ { "m_Id": "out" } ]
        }
    ],
    "m_Edges": [
        { "m_OutputSlot": "d4f5e3c7-1a2d-4b8f-a3e1-6c9b8d2e1f0a.out", "m_InputSlot": "b2c3d4e5-f6g7-8h9i-0j1k-l2m3n4o5p6q7.a" },
        { "m_OutputSlot": "a1b2c3d4-e5f6-7g8h-9i0j-k1l2m3n4o5p6.out", "m_InputSlot": "b2c3d4e5-f6g7-8h9i-0j1k-l2m3n4o5p6q7.b" }
    ]
}</code></pre></li></ul><h2><strong>Shader Graph应用示例</strong></h2><p>在Shader Graph中创建Unlit效果的步骤：</p><ul><li>创建新的Shader Graph文件（右键 &gt; Create &gt; Shader &gt; Universal Render Pipeline &gt; Unlit Shader Graph）</li><li><p>核心节点配置：</p><ul><li>添加‌<strong>Sample Texture 2D</strong>‌节点作为基础纹理输入</li><li>连接‌<strong>Color</strong>‌参数节点实现色调控制</li><li>使用‌<strong>Multiply</strong>‌节点混合纹理和颜色</li></ul></li><li><p>高级功能扩展：</p><ul><li>添加‌<strong>Time</strong>‌节点驱动UV动画</li><li>通过‌<strong>Vertex Position</strong>‌节点实现顶点变形</li></ul></li></ul><p>代码说明：</p><ul><li>构建包含纹理采样和颜色混合的基础Unlit着色器</li><li>通过节点连接实现材质属性的可视化编辑</li><li>可扩展添加UV滚动、顶点动画等高级效果</li><li><p>UnlitExample.shader</p><pre><code class="c">Shader "Custom/UnlitTexture"
{
    Properties {
        _MainTex ("Texture", 2D) = "white" {}
        _Color ("Color", Color) = (1,1,1,1)
    }
    SubShader {
        Tags { "RenderType"="Opaque" }
        Pass {
            HLSLPROGRAM
            #pragma vertex vert
            #pragma fragment frag
            #include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl"

            struct Attributes {
                float4 positionOS : POSITION;
                float2 uv : TEXCOORD0;
            };

            struct Varyings {
                float4 positionCS : SV_POSITION;
                float2 uv : TEXCOORD0;
            };

            sampler2D _MainTex;
            float4 _Color;

            Varyings vert(Attributes IN) {
                Varyings OUT;
                OUT.positionCS = TransformObjectToHClip(IN.positionOS.xyz);
                OUT.uv = IN.uv;
                return OUT;
            }

            half4 frag(Varyings IN) : SV_Target {
                return tex2D(_MainTex, IN.uv) * _Color;
            }
            ENDHLSL
        }
    }
}</code></pre></li><li><p>UnlitGraph.shadergraph</p><pre><code class="c">{
    "m_Nodes": [
        {
            "m_Id": "d4f5e3c7-1a2d-4b8f-a3e1-6c9b8d2e1f0a",
            "m_Type": "UnityEditor.ShaderGraph.Texture2DNode",
            "m_Position": { "x": -208, "y": -16 },
            "m_Outputs": [ { "m_Id": "out" } ],
            "m_Texture": { "m_DefaultValue": {} }
        },
        {
            "m_Id": "a1b2c3d4-e5f6-7g8h-9i0j-k1l2m3n4o5p6",
            "m_Type": "UnityEditor.ShaderGraph.ColorNode",
            "m_Position": { "x": -200, "y": 100 },
            "m_Outputs": [ { "m_Id": "out" } ],
            "m_Color": { "r": 1, "g": 1, "b": 1, "a": 1 }
        },
        {
            "m_Id": "b2c3d4e5-f6g7-8h9i-0j1k-l2m3n4o5p6q7",
            "m_Type": "UnityEditor.ShaderGraph.MultiplyNode",
            "m_Position": { "x": 0, "y": 0 },
            "m_Inputs": [
                { "m_Id": "a", "m_SlotId": 0 },
                { "m_Id": "b", "m_SlotId": 1 }
            ],
            "m_Outputs": [ { "m_Id": "out" } ]
        }
    ],
    "m_Edges": [
        { "m_OutputSlot": "d4f5e3c7-1a2d-4b8f-a3e1-6c9b8d2e1f0a.out", "m_InputSlot": "b2c3d4e5-f6g7-8h9i-0j1k-l2m3n4o5p6q7.a" },
        { "m_OutputSlot": "a1b2c3d4-e5f6-7g8h-9i0j-k1l2m3n4o5p6.out", "m_InputSlot": "b2c3d4e5-f6g7-8h9i-0j1k-l2m3n4o5p6q7.b" }
    ]
}</code></pre></li></ul><p>实际应用时可结合粒子系统创建发光轨迹，或为UI元素添加动态高亮效果。URP Unlit Shader的轻量级特性使其在移动设备上能保持60fps以上的渲染性能</p><h2>典型应用场景及实现</h2><h3><strong>光晕效果（Halo）</strong></h3><ul><li>‌<strong>应用实例</strong>‌：角色技能特效、UI高亮提示。通过透明纹理实现边缘发光，如1中描述的透明光晕材质。</li><li><p>‌<strong>实现步骤</strong>‌：</p><ul><li>导入纹理并设置：<code>Texture Type</code>为<code>Default (sRGB)</code>，勾选<code>Alpha Is Transparency</code>，<code>Wrap Mode</code>设为<code>Clamp</code>。</li><li>创建材质：选择<code>Universal Render Pipeline/Unlit</code> Shader，设置<code>Surface Type</code>为<code>Transparent</code>，拖拽纹理到<code>Base Map</code>插槽。</li><li>调整<code>Tint</code>颜色控制光晕色彩。</li></ul></li></ul><h3><strong>全息投影效果</strong></h3><ul><li>‌<strong>应用实例</strong>‌：科幻场景中的虚拟角色或界面。结合透明度与扫描线纹理。</li><li><p>‌<strong>实现步骤</strong>‌：</p><ul><li>使用<code>Unlit</code> Shader并启用透明混合（<code>Blend SrcAlpha OneMinusSrcAlpha</code>）。</li><li>添加顶点偏移代码模拟全息抖动，通过<code>_Time</code>变量控制动态效果。</li><li>叠加扫描线纹理（如<code>_HologramLine1</code>）和菲涅尔反射增强立体感。</li></ul></li></ul><h3><strong>透明遮罩（如塑料薄膜）</strong></h3><ul><li>‌<strong>应用实例</strong>‌：UI遮罩或半透明装饰物。通过Alpha通道控制透明度，如中的塑料薄膜材质。</li><li><p>‌<strong>实现步骤</strong>‌：</p><ul><li>在图片编辑器中创建带Alpha通道的纹理，白色区域不透明，灰色区域半透明。</li><li>材质Shader选择<code>Unlit</code>，设置<code>Transparent</code>模式，纹理绑定到<code>Base Map</code>。</li></ul></li></ul><h3><strong>发光广告牌（Billboard）</strong></h3><ul><li>‌<strong>应用实例</strong>‌：游戏内固定亮度标识或霓虹灯。直接显示纹理颜色不受光照影响。</li><li><p>‌<strong>实现步骤</strong>‌：</p><ul><li>使用<code>Unlit</code> Shader，<code>Surface Type</code>设为<code>Opaque</code>。</li><li>通过<code>Base Map</code>设置发光纹理，调整<code>Tint</code>颜色增强亮度。</li></ul></li></ul><h3><strong>景深遮挡标记</strong></h3><ul><li>‌<strong>应用实例</strong>‌：半透明物体深度写入（如玻璃瓶），解决景深效果失效问题。</li><li><p>‌<strong>实现步骤</strong>‌：</p><ul><li>创建两个材质：一个透明材质（<code>Queue=Transparent</code>），一个深度写入材质（<code>Queue=2000</code>）。</li><li>深度写入材质使用<code>Unlit</code> Shader并启用<code>ZWrite On</code>。</li></ul></li></ul><h3><strong>关键注意事项</strong></h3><ul><li>‌<strong>渲染顺序</strong>‌：透明物体需关闭深度写入（<code>ZWrite Off</code>），并合理设置<code>Queue</code>标签避免混合错误。</li><li>‌<strong>性能优化</strong>‌：复杂效果（如全息投影）建议结合顶点着色器计算，减少片元着色器负担</li></ul><hr/><blockquote><a href="https://link.segmentfault.com/?enc=Ci3ZLiUmcKa4b0JOuyV1EQ%3D%3D.8clYuyajqYqNn6lBHE2R7WwhnMvimiLgnmGNuMCM9Rj7cU5bEc1HPWJDngLwJqx1zQkezpYq4utFdXz8nEe5heLe%2Bx01J4Ts3s8XF%2FD%2BFyX%2BqixXC8ZBguV2jlyI82NbJxlhZMqG7X2HE2q%2FxEO3tERzyI8nF1jkQpmSwConE542K66ds%2BjoDRMOgIln%2BtFogND6nsKvWsbuTOejKdlNZEqTZfxnxblweXN7Ux5Bmh0%3D" rel="nofollow" target="_blank">【从UnityURP开始探索游戏渲染】</a><strong>专栏-直达</strong><br/>（欢迎<em>点赞留言</em>探讨，更多人加入进来能更加完善这个探索的过程，🙏）</blockquote>]]></description></item><item>    <title><![CDATA[基于DCT的彩色图像压缩MATLAB实现]]></title>    <link>https://segmentfault.com/a/1190000047438739</link>    <guid>https://segmentfault.com/a/1190000047438739</guid>    <pubDate>2025-11-30 12:02:09</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h4><strong>一、核心流程</strong></h4><p>基于DCT的图像压缩遵循JPEG标准的核心步骤，具体流程如下：</p><ol><li><strong>颜色空间转换</strong>：将RGB图像转换为YCbCr空间，分离亮度（Y）与色度（Cb/Cr）分量。</li><li><strong>分块DCT变换</strong>：将每个通道划分为8×8块，进行二维DCT变换。</li><li><strong>量化</strong>：根据人眼视觉特性设计量化表，对DCT系数进行量化。</li><li><strong>熵编码</strong>：采用Zigzag扫描、游程编码和霍夫曼编码压缩量化后的数据。</li><li><strong>解压缩</strong>：逆向执行熵解码、反量化、逆DCT变换，重构图像。</li></ol><hr/><h4><strong>二、MATLAB代码实现</strong></h4><h5><strong>1. 颜色空间转换与分块</strong></h5><pre><code class="matlab">% 读取图像并转换为YCbCr
img = imread('lena.jpg');
if size(img,3) == 3
    img_ycbcr = rgb2ycbcr(img);
    Y = img_ycbcr(:,:,1);
    Cb = img_ycbcr(:,:,2);
    Cr = img_ycbcr(:,:,3);
else
    Y = img;
    Cb = [];
    Cr = [];
end

% 分块处理（8x8）
block_size = 8;
[rows, cols] = size(Y);
num_blocks_row = ceil(rows / block_size);
num_blocks_col = ceil(cols / block_size);</code></pre><h5><strong>2. DCT变换与量化</strong></h5><pre><code class="matlab">% 定义量化表（JPEG标准）
luminance_quant = [16 11 10 16 24 40 51 61;
                  12 12 14 19 26 58 60 55;
                  14 13 16 24 40 57 69 56;
                  14 17 22 29 51 87 80 62;
                  18 22 37 56 68 109 103 77;
                  24 35 55 64 81 104 113 92;
                  49 64 78 87 103 121 120 101;
                  72 92 95 98 112 100 103 99];

% DCT变换与量化函数
function quant_block = dct_quant(block, quant_table, quality)
    dct_block = dct2(block);
    scale = 100 / quality;  % 质量因子调整量化强度
    quant_block = round(dct_block ./ (quant_table * scale));
end

% 对每个块进行DCT和量化
Y_compressed = zeros(size(Y));
for i = 1:num_blocks_row
    for j = 1:num_blocks_col
        % 提取块
        row = (i-1)*block_size + 1 : min(i*block_size, rows);
        col = (j-1)*block_size + 1 : min(j*block_size, cols);
        block = Y(row,col);
        
        % DCT与量化
        quant_block = dct_quant(block, luminance_quant, 80);
        Y_compressed(row,col) = quant_block;
    end
end</code></pre><h5><strong>3. Zigzag扫描与熵编码</strong></h5><pre><code class="matlab">% Zigzag扫描
function zigzag_vec = zigzag_scan(block)
    zigzag_order = [1,2,6,7,15,16,28,29,3,5,8,14,17,27,30,43,4,9,13,18,26,31,42,44,10,12,19,25,32,41,45,54,11,20,24,33,40,46,53,21,23,34,39,48,52,55,22,35,38,47,51,56,29,50,60,61,62,63,64];
    flat_block = block(:);
    zigzag_vec = flat_block(zigzag_order(1:numel(flat_block)));
end

% 示例：对量化后的块进行Zigzag扫描
zigzag_data = [];
for i = 1:block_size
    for j = 1:block_size
        block = Y_compressed((i-1)*block_size+1:i*block_size, (j-1)*block_size+1:j*block_size);
        zigzag_data = [zigzag_data, zigzag_scan(block)];
    end
end</code></pre><h5><strong>4. 霍夫曼编码</strong></h5><pre><code class="matlab">% 霍夫曼编码（使用MATLAB内置函数）
huff_dict = huffmandict([0:255], [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64]);
encoded_data = huffmandeco(zigzag_data, huff_dict);</code></pre><h5><strong>5. 解压缩与逆变换</strong></h5><pre><code class="matlab">% 逆量化
dequant_block = quant_block .* (quant_table * scale);

% 逆DCT变换
idct_block = idct2(dequant_block);

% 合并块并转换回RGB
reconstructed_Y = zeros(rows,cols);
block_idx = 1;
for i = 1:num_blocks_row
    for j = 1:num_blocks_col
        % 提取逆量化块
        row = (i-1)*block_size + 1 : min(i*block_size, rows);
        col = (j-1)*block_size + 1 : min(j*block_size, cols);
        dequant_block = reshape(encoded_data(block_idx:block_idx+63), [8,8]);
        reconstructed_Y(row,col) = idct_block;
        block_idx = block_idx + 64;
    end
end

% 合并通道并转换回RGB
reconstructed_img = cat(3, reconstructed_Y, Cb, Cr);
reconstructed_img = ycbcr2rgb(reconstructed_img);</code></pre><h4><strong>三、性能评估</strong></h4><pre><code class="matlab">% 计算PSNR
original = im2double(img);
reconstructed = im2double(reconstructed_img);
mse = mean((original(:) - reconstructed(:)).^2);
psnr = 10 * log10(1 / mse);

% 计算压缩率
original_size = rows * cols;
compressed_size = numel(encoded_data);
compression_ratio = original_size / compressed_size;

disp(['PSNR: ', num2str(psnr), ' dB, 压缩率: ', num2str(compression_ratio), ':1']);</code></pre><h4><strong>四、优化点</strong></h4><ol><li><strong>量化表自适应调整</strong>：根据质量因子动态缩放量化表，平衡压缩率与质量。</li><li><strong>颜色空间优化</strong>：对Cb/Cr通道进行4:2:0下采样，减少数据量。</li><li><strong>快速DCT实现</strong>：使用<code>dctmtx</code>预生成变换矩阵，避免重复计算。</li><li><strong>并行分块处理</strong>：利用<code>parfor</code>加速大尺寸图像处理。</li></ol><h4><strong>五、实验结果示例</strong></h4><table><thead><tr><th>压缩质量</th><th>PSNR (dB)</th><th>压缩率 (原图:压缩图)</th><th>视觉质量</th></tr></thead><tbody><tr><td>100</td><td>45.2</td><td>1:1</td><td>几乎无损</td></tr><tr><td>80</td><td>38.7</td><td>4:1</td><td>细节轻微模糊</td></tr><tr><td>50</td><td>32.1</td><td>10:1</td><td>明显块效应</td></tr></tbody></table><p>参考代码  基于DCT的彩色图像压缩    www.youwenfan.com/contentsfa/82678.html</p><h4><strong>六、总结</strong></h4><p>通过上述步骤，可实现基于DCT的彩色图像压缩，核心在于分块DCT、量化表设计及熵编码。实际应用中需结合视觉特性优化量化策略，并通过PSNR等指标评估压缩效果。</p>]]></description></item><item>    <title><![CDATA[FFmpeg开发笔记（九十）采用FFmp]]></title>    <link>https://segmentfault.com/a/1190000047438168</link>    <guid>https://segmentfault.com/a/1190000047438168</guid>    <pubDate>2025-11-30 12:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>​FFmpeg是个经典的音视频处理开源框架，可是FFmpeg仅提供命令行方式，通过FFmpeg剪辑音视频只能在命令行下面操作，从而限制了普通用户掌握FFmpeg。</p><p>虽然《FFmpeg开发实战：从零基础到短视频上线》一书不仅给出了基于FFmpeg函数调用的示例代码，也给出了具体的ffmpeg操作命令，从而兼具FFmpeg的代码开发教程与FFmpeg的命令使用手册两种用途。但是普通用户并非开发者，用户更希望提供桌面程序那种可视化界面，通过鼠标简单操作就能实现音视频文件的剪辑操作。  <br/>FFBox便是一个FFmpeg套壳的多媒体转码百宝箱，它全链路支持：输入→滤镜→编码→输出。参数配置透明直观，对齐FFmpeg的原生用法。所有的FFmpeg参数公开透明，用户通过操作界面，即能同时学习FFmpeg的命令。相比大多数软件仅支持的简单滤镜，FFBox支持完整的流图和滤镜图编辑，可处理复杂的多输入多输出任务。  <br/>FFBox的官网地址为 <a href="https://link.segmentfault.com/?enc=ROCuGIjwXmgMLJzK0V8MFQ%3D%3D.iiI%2FmdZDk70j1oOV2pzayUNTwgxaQ2rbZSdeqeyvLxs%3D" rel="nofollow" target="_blank">http://FFBox.ttqf.tech</a> ，源码托管地址为 <a href="https://link.segmentfault.com/?enc=pGD2k8I8eVGWQVzQQW7AMQ%3D%3D.tjeQzQrBf%2FX8o8FsvBK4IgVgNloW8oLExs%2BE%2F7s%2B5bvCNLVQPtLKKCFFhzXQ0y6a" rel="nofollow" target="_blank">https://github.com/ttqftech/FFBox</a> （星星数1.0k），国内的镜像地址为 <a href="https://link.segmentfault.com/?enc=CFF92438cf5At1kTeHJKLQ%3D%3D.66QbxsoDGmRikIOB%2BL5%2F6Y01JiCBkKO1V5nrcF5O0fk%3D" rel="nofollow" target="_blank">https://gitee.com/ttqf/FFBox</a>和<a href="https://link.segmentfault.com/?enc=lSqdQFiW3fJCBd29SV4CQQ%3D%3D.k4cW5BfglRD6NCMR6ev7N2SB7PJ93P5Tc0ni1A7N%2BmxjQN84KTmnmdcs2KVsR0gW" rel="nofollow" target="_blank">https://gitcode.com/gh_mirrors/ff/FFBox</a> 。最新版本是2025年9月发布的FFBox v5.0，可见该框架的源码更新十分及时，该版本的源码下载链接为 <a href="https://link.segmentfault.com/?enc=BaiV5j9uWQW5ErzXOiU6%2Bw%3D%3D.J5C98IX9%2FTKpe5tQ41jT%2FcnLJnVO51FV3%2FGNTdBe%2BAMpYeQpRsKUpCP6WEp1AOQejSfBLTL3Ajxp9F4u2yUSaw%3D%3D" rel="nofollow" target="_blank">https://github.com/ttqftech/FFBox/archive/refs/tags/v5.0.tar.gz</a> 。  <br/>FFBox基于Node.js开发，同时支持Windows、Linux、macOS等操作系统。FFBox推荐采用VS Code编写代码，如果要在Windows系统上编译FFBoxHelper，则需安装Visual Studio 2022，并采用C++编码。若想在Windows平台上制作安装包，还需安装Inno Setup 6，并将其安装路径放入环境变量中。  <br/>编译通过后的FFBox可执行程序叫做FFBoxHelper.exe，双击exe文件打开FFBox的初始界面如下图所示：</p><p><img width="723" height="670" referrerpolicy="no-referrer" src="/img/bVdm8GT" alt="" title=""/></p><p>在FFBox界面的上方区域可拖曳添加待剪辑的音视频文件，界面中间区域为当前剪辑操作对应的ffmpeg命令，例如：</p><pre><code>ffmpeg -hide_banner -hwaccel auto -i [输入文件路径] -vcodec libx265 -preset medium -crf 24 -acodec copy ./[输出文件路径]_converted.mp4 -y</code></pre><p>界面下方区域为剪辑操作的各项参数，可在此调整具体的选项参数以便符合剪辑需求。单击界面右上角的【开始】按钮，即可令FFBox执行响应的剪辑命令，剪辑完成的结果文件默认保存在原文件的相同目录下，且文件名后缀为“ _converted.mp4 ”。  </p><p>总的来说，FFBox的界面细节考究，视觉体验焕然一新，且图形化实时显示进度、速度、码率、剩余时间等信息，并支持以图表模式直观展示，是个不错的国产多媒体剪辑工具。</p><p>更多详细的FFmpeg开发知识参见<a href="https://link.segmentfault.com/?enc=UejHwta7CIxmYG5T3N7L%2Bw%3D%3D.y%2BwTiXuVro8X0E1rDDsY1If07CjMvV7ROhH3UHbowNsCnHUjsdkEgQnHxG1%2F0JIF" rel="nofollow" title="《FFmpeg开发实战：从零基础到短视频上线》" target="_blank">《FFmpeg开发实战：从零基础到短视频上线》</a>一书。</p><p>​</p>]]></description></item><item>    <title><![CDATA[集成电路设计中的IP核心价值：加速创新的]]></title>    <link>https://segmentfault.com/a/1190000047438667</link>    <guid>https://segmentfault.com/a/1190000047438667</guid>    <pubDate>2025-11-30 11:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在集成电路（IC）设计的世界里，知识产权（Intellectual Property，简称 IP）已经成为推动创新与效率的关键力量。它不仅缩短了设计周期，还为工程师们提供了更多专注于差异化和前沿探索的空间。今天，就让我们走进IC设计中的IP，揭示它的重要性与最佳实践。<br/><img width="723" height="487" referrerpolicy="no-referrer" src="/img/bVdnc7V" alt="" title=""/><br/>1、为什么IP如此重要？<br/>在复杂的IC设计过程中，IP扮演着“现成积木”的角色。它们是经过验证、可复用的功能模块，涵盖从基础逻辑电路到完整的处理器核心。借助这些模块，设计团队无需从零开始重复造轮子，而是能够直接构建在成熟基础之上，从而降低成本并显著提升效率。</p><p>2、IP的多样性<br/>IC设计中的IP大致分为两类：<br/>硬IP（Hard IP）：已经为特定工艺优化、综合完成的电路模块，可直接应用，但可配置性较低。<br/>软IP（Soft IP）：以代码形式存在，可灵活配置和调整，满足不同设计需求。<br/>两者相辅相成，设计师可根据项目特性选择最优组合。</p><p>3、利用IP的最佳实践<br/>想要高效发挥IP的价值，必须遵循一些最佳实践：<br/>完整的文档与规范：确保团队成员能快速理解并应用IP；<br/>系统级验证：在整个设计环境下对IP进行全面测试，避免集成后出现意外问题；<br/>标准化管理：遵循行业标准，提高兼容性与复用率。</p><p>4、集成IP的挑战<br/>尽管IP带来了巨大的便利，但设计过程中仍不可避免地遇到挑战。例如，不同IP之间的兼容性问题、复杂的授权与许可管理，以及多模块协同设计的复杂性。这些问题需要依赖于经验、流程管理和先进工具来逐步化解。</p><p>5、学习与成长的机会<br/>对于立志进入或深入IC行业的工程师而言，系统学习IP在IC设计中的应用至关重要。如果你正在寻找专业的学习资源，推荐关注 EDA Academy（www.eda-academy.com）。</p><p>在 EDA Academy：<br/>你可以学习大量最新、专业、全面的在线课程，涵盖IP、IC设计、EDA工具等核心主题；<br/>你可以注册成为导师，分享经验并转化为课程收入；<br/>你可以通过邮箱免费订阅newsletter，定期获取行业前沿动态；<br/>你还可以加入销售联盟计划，通过推荐课程赚取 20%-50%的佣金。</p><p>IP已成为现代IC设计不可或缺的基石，它不仅提高了开发效率，更释放了设计师的创造力。通过理解IP的类型、掌握最佳实践并妥善应对集成挑战，工程师们能够在竞争激烈的行业中脱颖而出。如果你渴望深入学习并快速提升自己，不妨从 EDA Academy 开始，开启属于你的IC设计新篇章。<br/><img width="723" height="1098" referrerpolicy="no-referrer" src="/img/bVdnc7W" alt="" title="" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[达梦数据库安装教程 dm8_202110]]></title>    <link>https://segmentfault.com/a/1190000047438583</link>    <guid>https://segmentfault.com/a/1190000047438583</guid>    <pubDate>2025-11-30 10:04:16</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>​</p><p>是达梦数据库 DM8 的 Windows 64位企业版安装包，日期是 2021 年 10 月 25 日编译的版本。里面包含了数据库服务端、客户端和一些常用管理工具，</p><h2>1. 解压安装包</h2><ul><li><strong>提供安装包下载：</strong><a href="https://link.segmentfault.com/?enc=4F1N8W1l0XD0LpqiIXbRtQ%3D%3D.%2BgemjW%2FSEH5yPIvuU0zaBL3i5XOVuExt6wDKDzLUlsPhseOp%2BqUa4o4xtj9RSkMo" rel="nofollow" title="https://pan.quark.cn/s/301611c6df7f" target="_blank">https://pan.quark.cn/s/301611c6df7f</a> ，下载的 <code>dm8_20211025_x86_win_64_ent.zip</code>文件。</li><li>右键 → 解压到某个文件夹，比如 <code>D:\dm8</code>。</li><li>解压完，里面会有个 <code>setup.exe</code>，这就是安装程序。</li></ul><h2>2. 运行安装程序</h2><ul><li>双击 <code>setup.exe</code>。</li><li>弹出提示“是否允许此应用对设备进行更改”，点 <strong>是</strong>。</li></ul><h2>3. 选择语言</h2><ul><li>默认是 <strong>简体中文</strong>，直接点 <strong>确定</strong>。</li><li>欢迎界面点 <strong>下一步</strong>。</li></ul><h2>4. 同意许可协议</h2><ul><li>勾选 <strong>我接受协议</strong>，点 <strong>下一步</strong>。</li></ul><h2>5. 填写用户信息</h2><ul><li>公司名、用户名随便填（能记住就行），点 <strong>下一步</strong>。</li></ul><h2>6. 选择安装目录</h2><ul><li>默认在 C 盘，可点 <strong>浏览</strong>​ 改到其他盘，比如 <code>D:\dm8</code>，点 <strong>下一步</strong>。</li></ul><h2>7. 选择安装类型</h2><ul><li>新手直接选 <strong>典型安装</strong>（常用功能全装好），点 <strong>下一步</strong>。</li></ul><h2>8. 开始安装</h2><ul><li>点 <strong>安装</strong>，等进度条跑完，别中途关窗口。</li></ul><h2>9. 完成安装</h2><ul><li>装完后可能会问 <strong>是否初始化数据库</strong>，要用数据库就勾上，然后点 <strong>完成</strong>。</li><li>如果暂时不用数据库，可以不勾，后面单独弄。</li></ul><h2>10. 检查是否成功</h2><ul><li>在开始菜单或桌面找 “达梦管理工具” 或类似图标，能打开并连接数据库就说明装好了。</li></ul><p>​</p>]]></description></item><item>    <title><![CDATA[袋鼠数据库工具 8.92.1 版已上线 ]]></title>    <link>https://segmentfault.com/a/1190000047438621</link>    <guid>https://segmentfault.com/a/1190000047438621</guid>    <pubDate>2025-11-30 10:03:20</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>袋鼠数据库工具 是一款 AI 驱动的热门数据库系统客户端(MariaDB / MongoDB / MySQL / Oracle / PostgreSQL / Redis / SQLite / SQLServer / ...) ，支持建表、查询、模型、同步、导入导出等功能，支持 Windows / Mac / Linux 等操作系统，致力于打造一款好用、好玩、开发友好的开发者工具。</p><h2>重点特性介绍</h2><p>这个版本继续聚焦 MongoDB 支持，实现了更多 MongoDB 数据库对象设计器支持，完整实现了集合视图、聚合文件、聚合命令构建、查找命令构建、用户、角色、函数等对象的支持；对部分界面布局做了优化，改进了体验的一致性；完善了工作空间布局缓存支持等。</p><h2>新特性或修复的缺陷列表</h2><ul><li>MongoDB: 实现视图设计器逻辑</li><li>MongoDB: 实现查找构建器对话框逻辑</li><li>MongoDB: 实现聚合构建器对话框逻辑</li><li>MongoDB: 实现分析命令支持</li><li>MongoDB: 新增聚合文件支持</li><li>MongoDB: 新增函数设计器支持</li><li>MongoDB: 新增角色设计器支持</li><li>MongoDB: 新增用户设计器支持</li><li>MongoDB: 实现工作空间布局和缓存支持</li><li>MongoDB: 用户/角色/函数删除支持</li><li>文件面板增加文件支持</li><li>表视图: 增加字段位置调整支持</li><li>更新中文语言支持(zh-CN/zh-SG/zh-Hans/zh-Hant)</li><li>升级界面库版本 (GLib 2.86 / GTK 4.20.3 / libadwaita 1.8.2)</li><li>重构部分页面 (AdwPreferencesPage)</li><li>修复: 偶尔出现的不能保存布局的问题</li><li>修复: SQL 构建器名字空间中出现点问题的处理</li><li>修复: 权限设计器菜单无法响应的问题</li><li>修复: 工作空间布局文件无限增长</li><li>修复: 控制台警告消息</li></ul><h2>下载与安装</h2><p><a href="https://link.segmentfault.com/?enc=p3HZ%2B7Swts2C5nlpaaj%2BHw%3D%3D.YK43vIR9B2btuWXf6CshZDfyxjBGn0S1JwswcZlW%2BGbJRP%2BhMLbir3%2BSVUZB9Q29%2BvPpIPTs%2ByatybCi44sVWg%3D%3D" rel="nofollow" target="_blank">袋鼠数据库管理工具 8.92.1</a></p><h2>新版本功能快照</h2><p><a href="https://link.segmentfault.com/?enc=6%2FNlunbkTnvJzCwupj%2FjSg%3D%3D.Lw0fdMUUoLCkB9FF%2BbMpBy%2BZ7YMANqo99omG%2BuxZ8Bl5JUjb9Sa7pJJxIYNkVQnZ9C2jyLiCXtaD6SK82hxVrQ%3D%3D" rel="nofollow" title="MongoDB 视图编辑" target="_blank"><img width="723" height="490" referrerpolicy="no-referrer" src="/img/bVdnb2v" alt="MongoDB 视图编辑" title="MongoDB 视图编辑"/></a></p><p><a href="https://link.segmentfault.com/?enc=8FdKWD%2BeOWq0r0zSWja%2FpA%3D%3D.ZuLB7N61ZhocoflAJS7UoQ56Oq0cGKCAZPlZXlX7ZLIFTW0ZWFshOb0xbkte6lFN9noU8Npl1jiSTF8vNGWMHg%3D%3D" rel="nofollow" title="MongoDB 函数编辑" target="_blank"><img width="723" height="491" referrerpolicy="no-referrer" src="/img/bVdnb2w" alt="MongoDB 函数编辑" title="MongoDB 函数编辑" loading="lazy"/></a></p><p><a href="https://link.segmentfault.com/?enc=MLCiwFVXSLir2VJUS0hRbA%3D%3D.K%2FiDNu%2FiIVvGpW%2FYLeR5%2FgT5r5Sp7zi112lyuf1Qp0cQnOY8UZfw37XxLJxIUMGzV9PUf6yhGpI%2Fac5JZt882Q%3D%3D" rel="nofollow" title="MongoDB 查找命令构建" target="_blank"><img width="723" height="490" referrerpolicy="no-referrer" src="/img/bVdnb2x" alt="MongoDB 查找命令构建" title="MongoDB 查找命令构建" loading="lazy"/></a></p>]]></description></item><item>    <title><![CDATA[Room Arranger for Ma]]></title>    <link>https://segmentfault.com/a/1190000047438631</link>    <guid>https://segmentfault.com/a/1190000047438631</guid>    <pubDate>2025-11-30 10:02:20</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>​Room Arranger 是一个用来画房间布局、摆家具的小软件，能让你在电脑上提前规划空间，看沙发、床、桌子这些放哪儿合适，尺寸对不对。</p><h2>1. 先下载文件</h2><p><strong>安装包下载：</strong><a href="https://link.segmentfault.com/?enc=g5zYinSM6OfwhUjT%2F2evew%3D%3D.n0sizVKW%2BRW0YJZzgNk%2Bygdz2QG3xdwkvJYGgt80pbekGbtBK3H86%2F1CMCcKeQFw" rel="nofollow" title="https://pan.quark.cn/s/79414e16e772" target="_blank">https://pan.quark.cn/s/79414e16e772</a> ，下载好 <strong>Room Arranger for Mac v9.8.3.645.dmg</strong>，下完一般会在“下载”文件夹里躺着，找的时候直接进“下载”就行。</p><h2>2. 打开 dmg 文件</h2><p>双击这个 <code>.dmg</code>文件，Mac 会自动弹出一个窗口，里面能看到 Room Arranger 的图标，旁边还有个箭头指着“应用程序”文件夹。</p><h2>3. 拖到应用程序文件夹</h2><p>把 Room Arranger 的图标直接拖进“应用程序”文件夹里，等它复制完就好，这步其实就是安装。</p><h2>4. 关掉安装窗口</h2><p>复制完成后，点窗口左上角的  <strong>“推出”</strong> ​ 按钮，把这个安装窗口关掉，桌面上的挂载盘也会消失。</p><h2>5. 打开软件</h2><p>打开“启动台”（或者“应用程序”文件夹），找到刚装好的 Room Arranger，点一下运行。</p><p>第一次打开时，可能会跳出来“来自未知开发者”的提示，别慌，点  <strong>“仍要打开”</strong> ​ 就能正常用了。</p><h2>6. 小贴士</h2><ul><li>如果之前装过旧版本，最好先删掉旧的再装新的，这样不容易冲突。</li><li>软件装完就能直接摆房间玩，不用额外设置啥。</li></ul><p>​</p>]]></description></item><item>    <title><![CDATA[如何在 Ubuntu / Debian ]]></title>    <link>https://segmentfault.com/a/1190000047438633</link>    <guid>https://segmentfault.com/a/1190000047438633</guid>    <pubDate>2025-11-30 10:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000045376433" alt="Configure Postfix to Use Gmail SMTP" title="Configure Postfix to Use Gmail SMTP"/></p><p>Postfix 是一个流行的开源邮件传输代理（MTA），用于在 Linux 系统上路由并发送电子邮件。它提供了一个健壮和高效的处理邮件投递的方法。在本教程中，我们将向您展示如何在 Ubuntu 和 Debian-based 系统配置 Postfix 使用 Gmail 的 SMTP 服务。这个设置允许你使用 Gmail 的基础设施发送电子邮件，提供更好的可交付性，减少你的电子邮件被标记为垃圾邮件的可能性。</p><h3>安装 Postfix 和依赖项</h3><p>首先，更新系统的包索引。</p><pre><code>sudo apt update</code></pre><p>接下来，安装 Postfix 和 mailutils 包，它为处理邮件提供了额外的实用程序。</p><pre><code>sudo apt install postfix mailutils</code></pre><p>在 Postfix 安装过程中，系统将提示您选择邮件服务器配置类型。选择“Internet Site”并输入您的完全限定域名（FQDN）。</p><h3>配置 Postfix 使用 Gmail SMTP</h3><p>编辑 Postfix 配置文件</p><pre><code>sudo nano /etc/postfix/main.cf</code></pre><p>在配置文件中增加或修改如下几行：</p><pre><code>relayhost = [smtp.gmail.com]:587
smtp_use_tls = yes
smtp_sasl_auth_enable = yes
smtp_sasl_security_options = noanonymous
smtp_sasl_password_maps = hash:/etc/postfix/sasl_passwd
smtp_tls_CAfile = /etc/ssl/certs/ca-certificates.crt</code></pre><p>保存并退出文件</p><h3>创建并配置 SASL 密码文件</h3><p>创建一个新文件存储你的 Gmail 帐户的凭据</p><pre><code>sudo nano /etc/postfix/sasl_passwd</code></pre><p>添加以下行到新创建的文件中，将 <a href="mailto:your_email@example.com" target="_blank">your_email@example.com</a> 替换为您的 Gmail 电子邮件地址，将 your_password 替换为您的 Gmail 密码。</p><pre><code>[smtp.gmail.com]:587 your_email@example.com:your_password</code></pre><p>保存并退出文件，并修改文件权限。</p><pre><code>sudo chmod 600 /etc/postfix/sasl_passwd</code></pre><p>创建密码文件的哈希映射供 Postfix 使用</p><pre><code>sudo postmap /etc/postfix/sasl_passwd</code></pre><p>重新启动 Postfix 服务以应用更改</p><pre><code>sudo systemctl restart postfix</code></pre><h3>测试邮件功能</h3><p>使用 mail 命令发送测试邮件，确保 Postfix 配置正确。</p><pre><code>echo "This is a test email." | mail -s "Test Email" recipient@example.com</code></pre><h3>我的开源项目</h3><p><a href="https://link.segmentfault.com/?enc=6I3YXwITvaI66Bn4g29n0g%3D%3D.8H6HrYTubBLpPCH6NFHUDlPI2Fstk%2B8FzmdfTdch2Bg%3D" rel="nofollow" target="_blank"><img referrerpolicy="no-referrer" src="/img/remote/1460000043302459" alt="酷瓜云课堂-在线教育解决方案" title="酷瓜云课堂-在线教育解决方案" loading="lazy"/></a></p><ul><li><a href="https://link.segmentfault.com/?enc=Mz4xs%2F3kzNdfnAKP1r3msA%3D%3D.JP0CHdwsq65BxMCnaenpEKobnE%2F54RmYmRQnk0UUcq6joWhvvGqoIfCmg%2FQtxDWm" rel="nofollow" target="_blank">course-tencent-cloud（酷瓜云课堂 - gitee仓库）</a></li><li><a href="https://link.segmentfault.com/?enc=zBhSyEWz2jJKPm4FwcscSQ%3D%3D.kVN0Y94GkivjaoQv%2FxaBS8ulzGzcz%2B2534MCflbYGdXF1m%2BMLZz1vt9bS4WmEX7YAc78rx3LpV7%2F%2Fd8r%2F3tj6g%3D%3D" rel="nofollow" target="_blank">course-tencent-cloud（酷瓜云课堂 - github仓库）</a></li></ul>]]></description></item><item>    <title><![CDATA[Android 监听软键盘的高度并解决其]]></title>    <link>https://segmentfault.com/a/1190000047438460</link>    <guid>https://segmentfault.com/a/1190000047438460</guid>    <pubDate>2025-11-30 00:02:09</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>1、前言<br/>在某些项目中，我们常常需要自定义一个输入框，软键盘弹出时就把输入框顶上去，关闭时输入框再回到原位（比如下方的效果图，实际上各种 App 中的聊天界面和发布评论的界面大体都是这样）。在这个过程中，除了输入框以外的其他界面的元素不受影响，比如效果图中的背景图片不会上移也不会被压缩。但在实际使用中发现软键盘在弹出时常常把输入框盖住，导致输入框显示不完全。有什么方法可以解决呢？<br/>​<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047438462" alt="图片" title="图片"/><br/>​<br/>2、思路分析<br/>2.1 获取软键盘的高度<br/>网上常见的思路是这样的：在输入框的下面放置一个 View​，当软键盘弹出时，获取软键盘高度，然后在代码中动态将该 View​ 的高度设置成跟软键盘的一样，这样输入框就被它顶上去了。从视觉上来看，就像是被软键盘顶上去一样。<br/>这个思路的难点在于准确获取软键盘的动态高度。Android 系统没有提供直接获取软键盘高度的 api，好在我们可以曲线救国：软键盘的高度其实就是屏幕高度减去软键盘上方的可见区域（即没有被软键盘挡住的区域）高度，也就是：</p><p>软键盘高度 = 屏幕高度 - 可见区域高度</p><p>此外，还需要考虑状态栏和虚拟导航栏高度，所以我们可以得出以下的计算公式：</p><p>软键盘高度 = 屏幕高度 - 可见区域高度 - 顶部状态栏高度 - 底部导航栏高度</p><p>不过有两点需要注意：</p><p>Activity 为全屏时是没有状态栏的，不必扣除高度；<br/>横屏时虚拟状态栏是在侧边的，这时也不必扣除它的高度了。</p><p>最后我们的公式可以修正为：</p><p>软键盘高度 = 屏幕高度 - 可见区域高度 - 顶部状态栏高度（非全屏时） - 底部导航栏高度（竖屏时）</p><p>这个公式中的屏幕高度、状态栏高度和导航栏高度都可以通过 Android 的 api 获取，所以，现在问题的难点转换成了准确获取可见区域的动态高度。<br/>2.2 获取可见区域高度<br/>准确获取可见区域的动态高度，何为准确，何为动态呢？要想准确，我们必须要准确获取可见区域的对象，要想动态，那必须监听可见区域的高度变化，也即是：</p><p>获取可见区域（对应准确）；<br/>监听可见区域的高度变化（对应动态）。</p><p>首先来看第一步，View​ 类中为我们提供了一个方法 getWindowVisibleDisplayFrame()​，它可以获取某个 View​ 所在窗口（Window​）的可见区域（注意：是窗口的可见区域，不是 View​ 的可见区域！）。它需要传入一个 Rect​ 对象，从 Rect​ 对象中，我们就可以获取到可见区域的信息，比如可见区域顶部距离父布局顶部的距离 top​ 和可见区域底部部距离父布局顶部的距离 bottom​，两者一相减就是我们需要的可见区域高度了。<br/>那么用哪一个 View​ 来获取可见区域呢？当前 Activity​ 或者 Fragment​ 上面的布局或者控件吗？答案是不行的。因为 Activity​（或 Fragment​）跟软键盘是位于同一个窗口的，也就是说，软键盘也在这个窗口的可见区域内，无论软键盘弹出还是关闭，可见区域的大小都不会变化！<br/>既然如此，那么我们就需要另外一个窗口了。有没有办法创建一个不属于软键盘所在窗口的 View​ 呢？当然可以，Dialog​ 和 PopupWindow​ 就可以办到。我们需要这个 View​ 一直存在，便于监听，所以 PopupWindow​ 无疑是最合适的。<br/>第一步解决后，接下来就是监听可见区域的变化了这个比较简单，可以通过继承接口 ViewTreeObserver.OnGlobalLayoutListener​ 来，在 onGlobalLayout()​ 中监听来实现。<br/>3、代码实践<br/>思路已经捋清楚了，现在是代码时间。创建一个 KeyboardStatusWatcher​ 类，继承于 PopupWindow​ 和 ViewTreeObserver.OnGlobalLayoutListener​ 接口：<br/>class KeyboardStatusWatcher(</p><pre><code>private val activity: FragmentActivity,
private val lifecycleOwner: LifecycleOwner,
private val listener: (isKeyboardShowed: Boolean, keyboardHeight: Int) -&gt; Unit</code></pre><p>) : PopupWindow(activity), ViewTreeObserver.OnGlobalLayoutListener {</p><pre><code>private val rootView by lazy { activity.window.decorView.rootView }

private val TAG = "Keyboard-Tag"

/**
 * 可见区域高度
 */
private var visibleHeight = 0

/**
 * 软键盘是否显示
 */
var isKeyboardShowed = false
    private set

/**
 * 最近一次弹出的软键盘高度
 */
var keyboardHeight = 0
    private set

/**
 * PopupWindow 布局
 */
private val popupView by lazy {
    FrameLayout(activity).also {
        it.layoutParams = FrameLayout.LayoutParams(
            ViewGroup.LayoutParams.WRAP_CONTENT,
            ViewGroup.LayoutParams.MATCH_PARENT
        )
        //监听布局大小变化
        it.viewTreeObserver.addOnGlobalLayoutListener(this)
    }
}

init {
    //初始化 PopupWindow
    contentView = popupView
    //软键盘弹出时，PopupWindow 要调整大小
    softInputMode =
        WindowManager.LayoutParams.SOFT_INPUT_ADJUST_RESIZE or
            WindowManager.LayoutParams.SOFT_INPUT_STATE_ALWAYS_VISIBLE
    inputMethodMode = INPUT_METHOD_NEEDED
    //宽度设为0，避免遮挡界面
    width = 0
    height = ViewGroup.LayoutParams.MATCH_PARENT
    setBackgroundDrawable(ColorDrawable(0))
    rootView.post { showAtLocation(rootView, Gravity.NO_GRAVITY, 0, 0) }

    //activity 销毁时或者 Fragment onDestroyView 时必须关闭 popupWindow ，避免内存泄漏
    lifecycleOwner.lifecycle.addObserver(object : DefaultLifecycleObserver {
        override fun onDestroy(owner: LifecycleOwner) {
            super.onDestroy(owner)
            dismiss()
        }
    })
}

/**
 * 监听布局大小变化
 */
override fun onGlobalLayout() {
    val rect = Rect()
    //获取当前可见区域
    popupView.getWindowVisibleDisplayFrame(rect)
    if (visibleHeight == (rect.bottom - rect.top)) {
        //可见区域高度不变时不必执行下面代码，避免重复监听
        return
    } else {
        visibleHeight = (rect.bottom - rect.top)
    }
    //粗略计算高度的变化值，后面会根据状态栏和导航栏修正
    val heightDiff = rootView.height - visibleHeight
    //这里取了一个大概值，当窗口高度变化值超过屏幕的 1/3 时，视为软键盘弹出
    if (heightDiff &gt; activity.screenHeight / 3) {
        isKeyboardShowed = true
        //非全屏时减去状态栏高度
        keyboardHeight =
            if (activity.isFullScreen) heightDiff else heightDiff - activity.statusBarHeight
        //导航栏显示时减去其高度，但横屏时导航栏在侧边，故不必扣除高度
        if (activity.hasNavBar &amp;&amp; activity.isNavBarShowed &amp;&amp; activity.isPortrait) {
            keyboardHeight -= activity.navBarHeight
        }
    } else {
        //软键盘隐藏时键盘高度为0
        isKeyboardShowed = false
        keyboardHeight = 0
    }
    listener.invoke(isKeyboardShowed, keyboardHeight)
}</code></pre><p>}</p><p>代码都是遵循前面的思路分析编写的，注释也比较详细，就不过多分析了。只要关注一下 PopupWindow​ 存在时软键盘的交互。PopupWindow​ 与软键盘分属于不同的窗口，软键盘弹出时，默认会被 PopupWindow​ 覆盖的（你可以通过修改上面的代码，给 PopupWindow​ 设置颜色且宽度不为 0 来验证），这样 PopupWindow​ 的高度不发生变化，就无法达到监听的目的。所以我们需要设置 softInputMode​ 和 inputMethodMode​ 两个属性，让 PopupWindow​ 的高度随着软键盘的弹出和关闭而调整。<br/>然后简单看看 MainActivity 布局：<br/>&lt;androidx.constraintlayout.widget.ConstraintLayout <br/>    xmlns:android="http://schemas.android.com/apk/res/android"</p><pre><code>xmlns:app="http://schemas.android.com/apk/res-auto"
xmlns:tools="http://schemas.android.com/tools"
android:id="@+id/clRoot"
android:layout_width="match_parent"
android:layout_height="match_parent"
android:background="@drawable/watermelon"
tools:context=".MainActivity"&gt;

&lt;View
    android:id="@+id/vKeyboardBg"
    android:layout_width="match_parent"
    android:layout_height="60dp"
    android:background="@android:color/white"
    app:layout_constraintBottom_toBottomOf="parent" /&gt;

&lt;androidx.appcompat.widget.AppCompatEditText
    android:imeOptions="flagNoExtractUi"
    android:id="@+id/editText"
    android:layout_width="match_parent"
    android:layout_height="0dp"
    android:layout_marginHorizontal="15dp"
    android:layout_marginVertical="8dp"
    android:background="@drawable/shape_edit_bg"
    android:hint="请输入"
    android:paddingHorizontal="10dp"
    app:layout_constraintBottom_toBottomOf="@id/vEditBg"
    app:layout_constraintTop_toTopOf="@id/vEditBg" /&gt;
</code></pre><p>&lt;/androidx.constraintlayout.widget.ConstraintLayout&gt;</p><p>注意：这里 EditText​ 要加上 android:imeOptions="flagNoExtractUi"​ 属性，不然横屏时样式发生会变化。<br/>还有，别忘了在清单文件中给 Activity 加上 android:windowSoftInputMode="adjustNothing|stateHidden"​，否则软键盘弹出时布局会整体上移的。<br/>最后当然是在 Activity​ 中调用了：</p><pre><code>    KeyboardStatusWatcher(this,this) { isKeyboardShowed: Boolean, keyboardHeight: Int -&gt;
        vKeyboardBg.updateLayoutParams&lt;ConstraintLayout.LayoutParams&gt; {
            bottomMargin = keyboardHeight
        }
        Log.d("Tag", "isShowed = $isKeyboardShowed,keyboardHeight = $keyboardHeight")
    }
}
</code></pre><p>4、项目地址<br/>文章到此就结束了，项目地址如下：Gitee。<br/>项目还有一个不足之处：实现需求了，但是使用体验上跟微信相比差很多，微信的输入框在软键盘弹出和收起时上下移动非常顺滑，没有什么闪烁。<br/>如果你有更好的实现方法或者有其他的批评建议，欢迎留言和我交流。<br/>5、参考文章<br/>android EditText 横屏显示问题 - 简书<br/>Android 动态获取软键盘的高度，监听软键盘显示或则隐藏。 - 掘金<br/>Android 获取窗口可视区域大小: getWindowVisibleDisplayFrame()_ccpat 的专栏-CSDN 博客<br/>Android 全面解析之 Window 机制_一只修仙的猿-CSDN 博客</p>]]></description></item><item>    <title><![CDATA[NavigationBarUtil li]]></title>    <link>https://segmentfault.com/a/1190000047438483</link>    <guid>https://segmentfault.com/a/1190000047438483</guid>    <pubDate>2025-11-30 00:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <pre><code>private const val RES_NAME_NAV_BAR = "navigationBarBackground"

private val Context.navBarResId
    get() = resources.getIdentifier(
        "navigation_bar_height",
        "dimen", "android"
    )

/**
 * 获取虚拟导航栏的高度，必须在布局绘制完成之后调用才能获取到正确的值（可以在onWindowFocusChanged()中调用）
 * 单位为px
 */
val Context.navBarHeight: Int
    get() {
        val resourceId = navBarResId
        return if (resourceId != 0) {
            resources.getDimensionPixelSize(resourceId)
        } else 0
    }

/**
 * 手机是否有虚拟导航栏
 */
val Context.hasNavBar
    @JvmName("hasNavBar")
    get() = navBarResId != 0

/**
 * 当前虚拟导航栏是否显示
 */
val Activity.isNavBarShowed: Boolean
    get()  {
        val viewGroup = window.decorView as ViewGroup? ?: return false
        return (0 until viewGroup.childCount).firstOrNull {
            viewGroup.getChildAt(it).id != View.NO_ID
                &amp;&amp; this.resources.getResourceEntryName(viewGroup.getChildAt(it).id) == RES_NAME_NAV_BAR
        } != null
    }</code></pre>]]></description></item><item>    <title><![CDATA[SQL 性能的三要素——索引、执行计划与]]></title>    <link>https://segmentfault.com/a/1190000047438350</link>    <guid>https://segmentfault.com/a/1190000047438350</guid>    <pubDate>2025-11-29 23:03:26</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <blockquote>优秀的 SQL 性能不取决于单一组件的优化，而是索引设计、执行计划选择与数据分布感知三者协同的结果</blockquote><p>在数据库系统中，SQL 查询性能是衡量应用健康度的关键指标。许多开发者将性能优化简单归结为"添加索引"，但实际上，高效的查询是索引策略、执行计划优化和数据分布理解三者协同作用的结果。本文将深入探讨这三要素的相互作用机制，帮助您构建系统化的 SQL 性能优化思维。</p><h2>1 SQL 执行的生命周期与性能瓶颈</h2><h3>1.1 查询处理的全链路视角</h3><p>SQL 查询在数据库中的执行是一个复杂的过程，涉及多个组件的协同工作。<strong>查询优化器</strong>作为数据库大脑，负责将 SQL 语句转换为高效执行计划，其决策直接决定了查询性能。优化器的工作流程包括解析、标准化和优化三个阶段，最终生成物理执行计划。</p><p>在查询执行过程中，主要性能瓶颈常出现在<strong>数据访问路径</strong>选择上。不恰当的访问路径会导致不必要的磁盘 I/O 和 CPU 消耗，从而显著影响查询响应时间。了解这些瓶颈点有助于我们针对性优化。</p><h3>1.2 三要素的相互依赖关系</h3><p>索引、执行计划和数据分布之间存在深刻的相互影响关系。<strong>索引</strong>提供了数据快速访问的路径，但索引的有效性取决于<strong>数据分布</strong>特征；<strong>执行计划</strong>的选择基于成本估算，而成本估算的准确性又依赖于统计信息反映的数据分布；<strong>数据分布</strong>的变化会导致执行计划更替，可能使原有索引失效。</p><p>这种紧密的耦合关系意味着任何单点优化都难以持续有效，必须采用系统化思维进行性能优化。例如，即使创建了理想的索引，如果统计信息不准确，优化器可能仍然选择低效的执行计划。</p><h2>2 索引设计：高效访问的基石</h2><h3>2.1 索引结构与访问模式匹配</h3><p><strong>B+ 树索引</strong>是数据库中最常用的索引结构，其多路平衡特性有效降低了磁盘 I/O 次数。B+ 树将所有数据记录存储在叶子节点，并通过双向链表连接，这一特性特别有利于范围查询性能。</p><p>索引设计必须与实际<strong>查询模式</strong>相匹配。对于等值查询，单列索引可能足够；而对于多条件查询，复合索引通常更有效。复合索引的列顺序至关重要，应遵循<strong>高选择性列在前</strong>的原则，使索引能够最大程度地过滤数据。</p><p><strong>覆盖索引</strong>是优化查询性能的强大技术。当查询所需数据全部包含在索引中时，数据库可直接从索引获取数据，避免回表操作，显著减少 I/O 消耗。例如，假设存在复合索引（user\_id, created\_at），查询 <code>SELECT user_id, created_at FROM orders WHERE user_id = 100</code> 可完全利用索引完成，无需访问主表。</p><h3>2.2 索引选择性与性能关系</h3><p><strong>索引选择性</strong>是衡量索引效果的关键指标，高选择性索引能更有效地过滤数据。选择性计算公式为：不同值数量/总记录数。通常，选择性高于 10% 的索引才考虑使用。</p><p>索引使用中的常见陷阱包括：在索引列上使用函数或表达式会导致索引失效；前置通配符模糊查询（如 LIKE '%abc'）无法有效利用索引；隐式类型转换可能导致优化器无法使用索引。</p><p>以下是索引设计决策的参考框架：</p><pre><code>-- 良好的复合索引设计示例
CREATE INDEX idx_orders_user_status_date ON orders(user_id, status, created_date);

-- 匹配的查询示例（可利用索引前导列）
SELECT * FROM orders 
WHERE user_id = 100 
  AND status = 'completed'
  AND created_date &gt;= '2023-01-01';</code></pre><h2>3 执行计划：数据库的"执行蓝图"</h2><h3>3.1 执行计划解析与关键指标</h3><p><strong>执行计划</strong>是查询优化器生成的指令集，描述了数据处理的具体步骤。通过 EXPLAIN 命令可查看执行计划，其中几个关键字段特别重要：<strong>type</strong> 字段表示表访问类型，从最优到最差依次为：system &gt; const &gt; eq\_ref &gt; ref &gt; range &gt; index &gt; ALL；<strong>key</strong> 字段显示实际使用的索引；<strong>rows</strong> 字段预估需要扫描的行数；<strong>Extra</strong> 字段包含额外信息，如"Using index"表示使用覆盖索引。</p><p>执行计划中的<strong>连接类型</strong>对性能影响巨大。嵌套循环连接适用于小结果集连接；归并连接适合已排序的大表；哈希匹配则对无序大数据集效果良好。优化器会根据统计信息选择最适合的连接算法。</p><h3>3.2 执行计划分析与优化时机</h3><p>分析执行计划是识别性能瓶颈的关键步骤。当发现​<strong>type 为 ALL</strong>​（全表扫描）时，应考虑添加合适索引；当 <strong>rows 预估值与实际差异很大</strong>时，可能需要更新统计信息；当出现​<strong>Using temporary</strong>​（临时表）和​<strong>Using filesort</strong>​（文件排序）时，可能需要优化查询或索引。</p><p>以下是一个执行计划分析示例：</p><pre><code>-- 示例查询
EXPLAIN SELECT * FROM orders WHERE customer_id = 1001 AND status = 'shipped';

-- 问题执行计划可能显示：
-- type: ALL（全表扫描）
-- key: NULL（未使用索引）
-- rows: 大量扫描
-- 这表明需要为(customer_id, status)创建复合索引</code></pre><p>定期检查关键查询的执行计划是预防性能退化的重要手段。特别是在数据量变化较大或查询模式改变后，执行计划可能发生变更，导致性能下降。</p><h2>4 数据分布：优化器的"决策依据"</h2><h3>4.1 统计信息的作用与维护</h3><p><strong>统计信息</strong>是优化器进行成本估算的基础，描述了表数据、列数据和索引数据的分布特征。优化器依赖统计信息来估算不同执行计划的成本，从而选择最优方案。</p><p>统计信息需要定期更新以确保准确性。<strong>静态收集</strong>是在查询前手动或自动完成统计信息收集，不影响查询性能；<strong>动态收集</strong>则在查询过程中进行，会影响计划生成时间。对于数据变化频繁的表，应设置更频繁的统计信息更新策略。</p><p>当统计信息不准确时，优化器可能选择低效的执行计划。例如，如果统计信息未反映近年订单量激增，优化器可能低估结果集规模，错误选择嵌套循环连接而非更高效的哈希连接。</p><h3>4.2 数据分布特征对计划选择的影响</h3><p><strong>数据倾斜</strong>是影响执行计划选择的重要因素。当某些值出现频率极高时，索引可能不如全表扫描有效。例如，在"状态"字段上只有几个枚举值时，即使有索引，优化器也可能选择全表扫描。</p><p><strong>数据聚类</strong>特性也会影响性能。如果数据在物理存储上按某字段排序，基于该字段的范围查询会受益于顺序 I/O。了解数据分布特征有助于设计更有效的索引策略。</p><p>以下代码展示了如何检查数据分布：</p><pre><code>-- 分析列的数据分布
SELECT status, COUNT(*) AS count 
FROM orders 
GROUP BY status 
ORDER BY count DESC;

-- 更新统计信息
UPDATE STATISTICS ON orders;</code></pre><h2>5 三要素协同优化策略</h2><h3>5.1 索引与执行计划的协同</h3><p>索引设计必须考虑执行计划的选择规律。<strong>索引下推</strong>优化允许存储引擎在扫描索引时提前过滤数据，减少不必要的回表操作。<strong>多列索引</strong>的列顺序应匹配查询条件，以便优化器生成最佳计划。</p><p>当索引变更时，必须重新评估相关查询的执行计划。有时<strong>索引提示</strong>可临时强制优化器选择特定索引，但长期解决方案应是优化索引设计或统计信息。</p><p>复合索引设计应遵循​<strong>ERD 原则</strong>​（Equal-Range-Divide）：首先放置等值查询列，然后是范围查询列，最后是排序或分组列。这一原则能与优化器的执行计划生成逻辑最佳匹配。</p><h3>5.2 数据分布感知的优化</h3><p>智能优化需要考虑数据分布特征。对于​<strong>偏斜数据</strong>​，可考虑创建过滤索引或使用分区表；对于​<strong>时序数据</strong>​，可利用时间分区并结合数据归档策略。</p><p><strong>定期更新统计信息</strong>确保优化器基于准确数据分布做决策。对于大型表，可采用抽样统计平衡准确性和开销。<strong>直方图</strong>可帮助优化器了解复杂数据分布，尤其对非均匀分布列至关重要。</p><p>协同优化示例：某订单查询系统在（customer\_id, status）上创建复合索引，但性能仍不理想。分析发现 status 列严重偏斜（90% 为"completed"），通过过滤索引 <code>CREATE INDEX idx_orders_pending ON orders(customer_id) WHERE status != 'completed'</code>，结合统计信息更新，优化器终于选择了高效执行计划。</p><h2>6 实战：性能优化诊断流程</h2><h3>6.1 系统化性能诊断方法</h3><p>面对性能问题，应采用系统化诊断方法：​<strong>识别慢查询</strong>​：通过慢查询日志或数据库监控定位问题查询；​<strong>分析执行计划</strong>​：使用 EXPLAIN 查看当前执行计划，识别全表扫描、临时表等问题；​<strong>检查数据分布</strong>​：分析相关表的数据分布和统计信息时效性；​<strong>设计优化方案</strong>​：基于分析结果综合运用索引调整、查询重写或统计信息更新。</p><p>具体诊断流程如下：</p><ol><li>​<strong>执行计划分析</strong>​：关注 type、key、rows 和 Extra 字段，识别潜在问题</li><li>​<strong>索引有效性检查</strong>​：验证现有索引是否被使用，选择性如何</li><li>​<strong>统计信息检查</strong>​：确认统计信息是否最新，能否准确反映数据分布</li><li>​<strong>查询重写尝试</strong>​：尝试等效查询重写，测试不同写法性能差异</li></ol><h3>6.2 常见场景优化示例</h3><p><strong>场景一：分页查询优化</strong></p><pre><code>-- 原始慢查询
SELECT * FROM orders ORDER BY created_date DESC LIMIT 20 OFFSET 10000;

-- 优化方案：使用覆盖索引 + 游标分页
CREATE INDEX idx_orders_date_desc ON orders(created_date DESC, id);
SELECT * FROM orders 
WHERE created_date &lt;= '2023-11-28' AND id &lt; 5000
ORDER BY created_date DESC LIMIT 20;</code></pre><p><strong>场景二：多表连接优化</strong></p><pre><code>-- 原始查询
SELECT * FROM users u 
JOIN orders o ON u.id = o.user_id 
WHERE u.reg_date &gt;= '2023-01-01' AND o.amount &gt; 1000;

-- 优化方案：确保驱动表选择正确，连接字段有索引
CREATE INDEX idx_users_regdate ON users(reg_date);
CREATE INDEX idx_orders_user_amount ON orders(user_id, amount);</code></pre><h2>7 预防性性能治理体系</h2><h3>7.1 持续监控与预警</h3><p>建立<strong>持续监控机制</strong>对预防性能退化至关重要。监控应覆盖：​<strong>慢查询趋势</strong>​：跟踪慢查询数量、执行时间变化；​<strong>索引使用情况</strong>​：识别未使用或低效索引；​<strong>统计信息时效性</strong>​：确保统计信息及时更新。</p><p>设置合理的<strong>预警阈值</strong>可在问题影响用户前发现异常。例如，当查询扫描行数突增或索引命中率下降时触发告警。</p><h3>7.2 性能回归防护</h3><p>将 <strong>SQL 审查</strong>嵌入 CI/CD 流程可防止性能回归。使用自动化工具检查常见反模式，如 SELECT <em>​、N+1 查询等。​</em>​​<em>性能测试</em>​*应成为发布流程的必备环节，验证优化效果并防止回归。</p><p><strong>容量规划</strong>基于数据增长趋势提前规划优化策略。定期评估当前表结构、索引策略和数据量是否匹配，预见未来性能需求并提前准备优化方案。</p><h2>总结</h2><p>SQL 性能优化是一个系统工程，需要同时考虑索引设计、执行计划选择和数据分布特征三个要素的协同影响。优秀的性能源于对这三者之间复杂关系的深入理解和平衡把握。</p><p>​<strong>索引是基础</strong>​，但必须基于实际查询模式和数据分布特征设计；​<strong>执行计划是关键</strong>​，优化器的选择决定了查询路径的效率；​<strong>数据分布是依据</strong>​，统计信息的准确性直接影响优化器决策的质量。</p><p>未来，随着机器学习技术在数据库领域的应用，如 Bao 优化器通过强化学习选择执行计划，我们有理由相信数据库性能优化将更加智能化。但无论如何发展，对索引、执行计划和数据分布协同作用的深入理解，仍是数据库专业人士的核心竞争力。</p><hr/><p><strong>📚 下篇预告</strong>​</p><p>《连接池的价值与风险——池化提升与资源枯竭的双刃剑，关键指标如何解读》—— 我们将深入探讨：</p><ul><li>🔄 ​<strong>连接池原理</strong>​：数据库连接复用机制与性能提升的本质</li><li>⚖️ ​<strong>配置权衡</strong>​：最大连接数、最小空闲连接与超时设置的平衡策略</li><li>🚨 ​<strong>风险预警</strong>​：连接泄漏、资源枯竭与雪崩效应的发生机制</li><li>📊 ​<strong>监控指标</strong>​：活跃连接、等待时间与使用率的关键阈值</li><li>🛠️ ​<strong>实战调优</strong>​：主流连接池（HikariCP、Druid）的最佳配置实践</li></ul><p><strong>​点击关注，掌握数据库连接池的精细化调优技巧！​</strong>​</p><blockquote><p>​<strong>今日行动建议</strong>​：</p><ol><li>选择 1-2 个关键业务查询，使用 EXPLAIN 分析其执行计划</li><li>检查核心表的统计信息最后更新时间，确保其准确性</li><li>审核现有索引使用情况，识别并删除未使用索引</li><li>建立慢查询定期审查机制，预防性能退化</li></ol></blockquote>]]></description></item><item>    <title><![CDATA[基于反馈循环的自我进化AI智能体：原理、]]></title>    <link>https://segmentfault.com/a/1190000047438388</link>    <guid>https://segmentfault.com/a/1190000047438388</guid>    <pubDate>2025-11-29 23:02:36</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>传统AI智能体有个老问题：部署之后就"定住了"。工程师手工打磨的提示词和规则,遇到新场景就容易失灵,性能曲线到达某个点后趋于平缓。而自我进化智能体(Self-Evolving Agent)的思路就是打破这种静态模式，让智能体在运行过程中持续收集反馈,自动调整自身策略,形成一个闭环：<strong>执行任务 → 获取反馈 → 自我调整 → 继续执行</strong>。</p><p>这套机制把基础模型的能力与在线学习结合起来。用更学术的表述,自我进化智能体是"通过与环境交互持续优化内部组件的自主系统,目标是适应变化的任务、上下文和资源"。比如说这类智能体不只是做题,还会批改自己的作业、找出哪里写错了、然后调整学习策略，整个过程不需要人类介入。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047438390" alt="" title=""/></p><p>上图展示了典型的反馈循环结构。基线智能体执行任务产生输出,由人类评审或LLM评判者打分,反馈信息(分数、错误描述、改进建议)汇总后用于更新智能体，可能是调整提示词、微调参数、或修改配置。这个循环反复执行直到达成性能目标。</p><p>与固定配置的传统方案相比,自我进化智能体的核心差异在于能够监控自身表现并主动适应。多数已部署的智能体依赖人工设定的规则或提示,无法跟上数据分布的漂移或任务需求的演变。反馈循环解决了这个问题：每次任务完成后收集评估信号,识别薄弱环节,针对性地更新智能体。长期来看,系统的准确性和泛化性都会持续提升。这种机制对需要高准确率或面对动态环境的场景尤为关键，人类的角色从逐条修bug变成了设定目标和把握方向。</p><p>从架构视角看,自我进化系统可以抽象为四个核心要素：<strong>输入、智能体系统、环境、优化器</strong>，它们在迭代循环中交互。最近有综述将这类系统正式定义为"持续优化内部组件的自主系统,在保持安全性的前提下适应变化的任务与资源"。实际运行时,智能体执行标准的感知-推理-行动循环,但增加了自我评估和参数优化的元步骤。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047438391" alt="" title="" loading="lazy"/></p><p><strong>反馈循环的运作方式</strong>：从基线智能体开始(比如一个执行文档摘要的Agent),人类或LLM评判者对其输出进行评估。反馈信号既包括定量指标(0-1评分)也包括定性评论("摘要漏掉了关键细节")。多个信号汇总成综合得分，如果得分低于阈值(假设是0.8),就调整提示或策略重新测试。新版本达标后替换旧版本,循环继续。几轮迭代下来,智能体具备了自我修复能力。</p><p>这种设计的优势在于可扩展性(用LLM评估替代昂贵的人工标注)和适应性(自动响应新的失败模式,不需要手动改代码)。但也需要明确的安全约束：智能体在进化过程中必须保持稳定性(变化时不引入安全隐患)和性能单调性(不允许任务效果下降)。</p><h2>自我进化循环的核心步骤</h2><p>OpenAI Cookbook里有个经典示例,把进化循环拆成四步：</p><p><strong>第一步,基线智能体</strong>：准备一个初始版本,比如用特定提示词做文本摘要的Agent。</p><p><strong>第二步,收集反馈</strong>：让智能体跑一批任务,收集输出的评价，人工打分或者"LLM-as-Judge"的自动评分都行。评估内容包括摘要是否准确、是否简洁、是否符合业务规则等。</p><p><strong>第三步,量化评分</strong>：把反馈转成可度量的指标。可以是规则校验器、也可以是GPT评分标准,最后合成一个综合质量分。</p><p><strong>第四步,更新优化</strong>：如果得分没达标,就调整智能体内部——优化提示词、微调参数、或者换一个更好的版本,然后重新跑循环。</p><p>循环持续到性能超过阈值或达到重试上限。</p><pre><code> agent = BaselineAgent()  
 score = evaluate(agent)  
 while score &lt; target_score and tries &lt; max_retries:  
     feedback = get_feedback(agent)  
     agent = optimize_agent(agent, feedback)  
     score = evaluate(agent)</code></pre><p>每轮迭代都用收集到的反馈调整智能体。如果优化成功,新版本替换旧版本,成为下一轮的基线。</p><h2>关键模块解析</h2><p>自我进化智能体由几个紧密耦合的模块构成。</p><p><strong>智能体循环</strong>是最核心的部分，智能体接收输入(比如文档片段),更新内部记忆或上下文,运行LLM推理,产出结果(比如摘要)。这个流程通常用某种Agent SDK实现,负责管理LLM调用和工具使用。自我进化层包裹在外面,根据需要触发重跑或修改循环。架构上可以是单模块也可以是多模块——比如医疗场景可能同时有Summarizer和Compliance Checker两个子智能体。持续的"思考-行动"循环产生可评估的输出,为后续改进提供素材。</p><p><strong>任务性能监控</strong>负责追踪智能体的表现，典型配置包括自动评估器和可选的人工复核。以摘要任务为例,每个输出会经过四个评分器检查：</p><p>(1) Python函数检查关键术语(如化学名称)是否保留在摘要中;(2) 长度检查器控制冗长度;(3) 余弦相似度检测摘要与原文的语义一致性;(4) LLM评判者按评分标准给出综合评价。</p><p>前两个是确定性规则,第三个是模糊匹配,第四个提供灵活的语言理解评估。多个评分器协作,既产出量化分数也生成定性反馈。监控模块输出数字分数或pass/fail标志,外加描述问题的反馈文本。加权平均后得到汇总分数,决定输出是否可接受。这个监控信号驱动整个改进流程。</p><p><strong>内存模块</strong>对持续学习，短期记忆存储当前对话和规划状态,长期记忆保存累积知识、历史解法、总结出的规则。RAG(检索增强生成)让智能体能从知识库中拉取相关上下文。更复杂的系统会维护"记忆库",存放过去的决策和推理轨迹。记忆帮助智能体保留学到的经验：比如记住哪些提示模式效果更好,或者存储之前遇到的拒绝案例。进化循环可以把反馈和结果写入记忆,后续迭代查询时就能避免重蹈覆辙。</p><p><strong>奖励/反馈建模</strong>把原始反馈转换成训练信号，对于LLM智能体,通常会构建奖励模型或评分函数。每个评分器产出0-1分数,系统检查是否过阈值(比如0.85)。多个分数可以合并成单一指标(比如取均值),这个综合分数就是智能体的"奖励"。用强化学习的视角看,智能体被优化来最大化这个奖励。反馈也可以定性分类：如果某个评分器挂了,失败原因可以转成纠正指令。LLM评判者特别有用,因为它提供自然语言反馈("摘要需要更多细节"),智能体能直接用这些描述来改进输出。总之,奖励模块确保优化目标清晰——"所有评分器通过,或者均分超过0.8"。</p><p><strong>重训练/优化模块</strong>在性能不达标时更新智能体，提示词调优、参数微调、结构变化(如添加新工具)。一种常见做法是用LLM做<strong>提示改进</strong>而非直接训模型——"MetaPrompt"智能体拿到当前提示和反馈,被要求生成更好的版本。代码用新提示替换旧提示。更进阶的系统可能在收集的(输入,输出,反馈)数据上微调LLM,或用强化学习更新策略权重。核心思想是：根据反馈修改智能体内部组件(系统提示、模型权重、工具配置),让下一次执行有更大成功概率。重训后循环再次评估更新版本,形成闭环。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047438392" alt="" title="" loading="lazy"/></p><h2>反馈收集与重训练流程</h2><p>自我进化智能体的反馈主要靠自生成或众包。系统在一批任务上跑智能体,收集性能数据,包括：</p><p><strong>分数和标签</strong>：输出是否满足长度约束?是否包含必需实体?这些由自动检查器记录。</p><p><strong>文本反馈</strong>：LLM评判者输出解释性语句,说明哪里不足。</p><p><strong>日志和诊断</strong>：生成的token数、运行时统计、错误堆栈。</p><p><strong>人工标注</strong>：如果有人工复核,评级和评论会被记录。</p><p>智能体生成摘要后,评估代码调用各评分器,把输出解析成结构化结果(评分器名称、数字分数、pass/fail、推理描述)。辅助函数如</p><pre><code>parse_eval_run_output</code></pre><p>提取这些信息。智能体不依赖外部数据——自己的输出就是训练数据。随着时间推移,这会积累起(输入,输出,反馈)三元组的数据集。</p><pre><code> import time  
import json  

def run_eval(eval_id: str, section: str, summary: str):  
  """使用输入部分和输出摘要创建评估运行。"""  
  return client.evals.runs.create(  
    eval_id=eval_id,  
    name="self-evolving-eval",  
    data_source={  
      "type": "jsonl",  
      "source": {  
        "type": "file_content",  
        "content": [  
          {  
            "item": {  
              "section": section,  
              "summary": summary,  
            }  
          }  
        ],  
      },  
    },  
  )  

def poll_eval_run(eval_id: str, run_id: str, max_polls = 10):  
    """
    轮询评估运行直到完成或超时。

    此函数的存在是为了通过定期检查运行状态来处理评估服务中的异步行为。
    它通过在固定间隔轮询而不是无限期阻塞来平衡响应性和资源使用。
    重试限制可以防止在服务从不返回完成状态的情况下出现失控循环。
    """  
    run = None  
    for attempt in range(1, max_polls + 1):  
        run = client.evals.runs.retrieve(eval_id=eval_id, run_id=run_id)  
        if run.status == "completed":  
            break  
        if attempt == max_polls:  
            print("Exceeded retries, aborting")  
            break  

        time.sleep(5)  

    run_output_items = client.evals.runs.output_items.list(  
        eval_id=eval_id, run_id=run_id  
    )  
    return run_output_items  

def parse_eval_run_output(items):  
    """提取所有评分器分数和任何可用的结论输出。"""  
    all_results = []  

    for item in items.data:  
        for result in item.results:  
            grader_name_full = result.name  
            score = result.score  
            passed = result.passed  
            reasoning = None  
            try:  
                sample = result.sample  
                if sample:  
                    content = result.sample["output"][0]["content"]  
                    content_json = json.loads(content)  
                    steps = content_json["steps"]  
                    reasoning = " ".join([step["conclusion"] for step in steps])  
            except Exception:  
                pass  

            all_results.append(  
                {  
                    "grader_name": grader_name_full,  
                    "score": score,  
                    "passed": passed,  
                    "reasoning": reasoning,  
                }  
            )  

     return all_results</code></pre><p><strong>重训练流程</strong>：反馈收集完毕后,智能体进入更新阶段。摘要评估失败时,循环调用"MetaPrompt"智能体——输入原始提示、源文档、生成的摘要、失败原因。MetaPrompt LLM输出新提示。系统用这个新提示创建新版SummarizationAgent。本质上,智能体通过LLM重写指令完成了"重训练"。更高级的系统可能微调模型权重或调整其他模块(更新记忆条目、更换工具)。关键点是<strong>智能体从错误中学习</strong>。</p><p>每轮迭代都应该带来性能提升。示例循环给每个部分最多3次改进机会。如果新提示版本让摘要通过所有评分器(宽松阈值),循环继续;否则重复尝试。代码追踪哪个提示版本综合得分最高,处理完所有部分后部署最优版本。这种重训既可以离线批量做,也可以在线随新数据持续适应。最终产出一个只靠自生成反馈就进化得更准确的智能体。</p><h2>代码实现详解</h2><p>下面是OpenAI Notebook实现的关键部分。</p><p><strong>1、评估配置</strong></p><p>先定义带多个评分器的<strong>Eval</strong>来给智能体输出打分,用的是OpenAI Evals API。每个评分器检查特定标准：<strong>chemical_name_grader</strong>(Python代码)计算化学名称在摘要中的出现比例,保证领域关键词不丢失;<strong>word_length_deviation_grader</strong>控制摘要长度在容差范围内;<strong>cosine_similarity</strong>测量源文和摘要的语义重叠度;<strong>llm_as_judge</strong>用GPT-4.1按评分标准给综合分。这些评分器收集到</p><pre><code>testing_criteria</code></pre><p>列表,然后创建评估：</p><pre><code> from openai import OpenAI  
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))  

data_source_config = {  
    "type": "custom",  
    "item_schema": {"type": "object", "properties": {"section": {"type": "string"}, "summary": {"type": "string"}}, "required": ["section", "summary"]},  
    "include_sample_schema": False  
}  
testing_criteria = [  
    {  
        "type": "python",  
        "name": "chemical_name_grader",  
        "pass_threshold": 0.8,  
        "source": r"""  
def grade(sample: dict, item: dict) -&gt; float:  
    section = item["section"]  
    summary = item["summary"]  
    # 预期化学名称列表  
    CHEMICALS_MASTER = [...]  
    present = [chem for chem in CHEMICALS_MASTER if chem in section]  
    if not present:  
        return 1.0  
    correct = sum(1 for chem in present if chem in summary)  
    return correct / len(present)  
"""  
    },  
    {  
        "type": "python",  
        "name": "word_length_deviation_grader",  
        "pass_threshold": 0.85,  
        "source": r"""  
def grade(sample: dict, item: dict) -&gt; float:  
    summary = item["summary"]  
    word_count = len(summary.split())  
    expected = 100  
    tolerance = 0.2  
    deviation = abs(word_count - expected) / expected  
    if deviation &lt;= tolerance:  
        return 1.0  
    score = max(0.0, 1.0 - (deviation - tolerance))  
    return score  
"""  
    },  
    {  
        "type": "text_similarity",  
        "name": "cosine_similarity",  
        "input": "{{ item.summary }}",  
        "reference": "{{ item.section }}",  
        "evaluation_metric": "cosine",  
        "pass_threshold": 0.85,  
    },  
    {  
        "type": "score_model",  
        "name": "llm_as_judge",  
        "model": "gpt-4.1",  
        "input": [  
            {  
                "role": "system",  
                "content": (  
                    "You are an expert summarization evaluator. Score the summary between 0 and 1..."  
                )  
            },  
            {  
                "role": "user",  
                "content": (  
                    "Section:\n{{item.section}}\nSummary:\n{{sample.output_text}}"  
                )  
            }  
        ],  
        "range": [0, 1],  
        "pass_threshold": 0.85,  
    },  
]  
eval = client.evals.create(  
    name="self_evolving_eval",  
    data_source_config=data_source_config,  
    testing_criteria=testing_criteria  
)  
 print(f"Created Eval: {eval.id}")</code></pre><p>这段代码导入OpenAI客户端,配置自定义数据schema(每个item有section和summary),定义四个评分器。Python评分器用内联代码(raw string)定义</p><pre><code>grade</code></pre><p>函数。</p><pre><code>client.evals.create()</code></pre><p>创建评估但还不执行。这些规则会对智能体生成的每个摘要自动打分。</p><p><strong>2、执行评估</strong></p><p>接着定义辅助函数,<strong>在给定的section-summary对上跑评估</strong>并解析结果：</p><pre><code> import time, json  

def run_eval(eval_id: str, section: str, summary: str):  
    """使用一个示例(section+summary)安排评估运行。"""  
    return client.evals.runs.create(  
        eval_id=eval_id,  
        name="self-evolving-eval",  
        data_source={"type": "jsonl", "source": {"type": "file_content", "content": [  
            {"item": {"section": section, "summary": summary}}  
        ]}}  
    )  

def poll_eval_run(eval_id: str, run_id: str, max_polls=10):  
    """轮询直到评估运行完成,然后返回输出项。"""  
    for attempt in range(max_polls):  
        run = client.evals.runs.retrieve(eval_id=eval_id, run_id=run_id)  
        if run.status == "completed":  
            break  
        time.sleep(5)  
    return client.evals.runs.output_items.list(eval_id=eval_id, run_id=run_id)  

def parse_eval_run_output(items):  
    """从评估运行输出中提取评分器分数和推理。"""  
    all_results = []  
    for item in items.data:  
        for result in item.results:  
            score = result.score  
            passed = result.passed  
            reasoning = None  
            try:  
                content = result.sample["output"][0]["content"]  
                reasoning = json.loads(content)["steps"][0]["conclusion"]  
            except Exception:  
                pass  
            all_results.append({  
                "grader_name": result.name,  
                "score": score,  
                "passed": passed,  
                "reasoning": reasoning  
            })  
    return all_results  

# 示例运行  
EVAL_ID = eval.id  
SECTION = "...some section text..."  
SUMMARY = "...agent's summary..."  
eval_run = run_eval(EVAL_ID, section=SECTION, summary=SUMMARY)  
run_output = poll_eval_run(EVAL_ID, run_id=eval_run.id)  
grader_scores = parse_eval_run_output(run_output)  
 print(grader_scores)</code></pre><pre><code>run_eval</code></pre><p>函数把一个样本(section+摘要)发送给评估服务,然后轮询等待完成(</p><pre><code>poll_eval_run</code></pre><p>),最后解析结果。输出是字典列表,每个评分器一条,格式类似</p><pre><code>{"grader_name": ..., "score": ..., "passed": ..., "reasoning": ...}</code></pre><p>。多数评分器只返回分数和pass/fail,LLM评分器会额外附带推理文本。这种结构化反馈供循环决定如何改进智能体。比如</p><pre><code>chemical_name_grader</code></pre><p>失败,说明摘要漏掉了关键术语。</p><p><strong>3、智能体与提示版本管理</strong></p><p>下一步配置智能体本身和提示版本追踪的数据结构,用OpenAI <strong>Agents SDK</strong>定义智能体并管理提示。</p><p>配置包括：</p><pre><code>VersionedPrompt</code></pre><p>类(基于Pydantic)记录提示版本和元数据;</p><pre><code>PromptVersionEntry</code></pre><p>存储每个版本的文本、版本号、模型、时间戳等;两个智能体——<strong>SummarizationAgent</strong>(执行实际任务)和<strong>MetaPromptAgent</strong>(负责改写提示)。</p><pre><code> from datetime import datetime  
from typing import Any, Optional  
from pydantic import BaseModel, Field  

class PromptVersionEntry(BaseModel):  
    """存储提示的一个版本和相关元数据。"""  
    version: int  
    model: str = "gpt-5"  
    prompt: str  
    timestamp: datetime = Field(default_factory=datetime.utcnow)  
    metadata: Optional[dict[str, Any]]  

    class Config:  
        validate_assignment = True  
        extra = "forbid"  

class VersionedPrompt:  
    """跟踪PromptVersionEntry列表并允许更新。"""  
    def __init__(self, initial_prompt: str, model: str = "gpt-5"):  
        self._versions = [PromptVersionEntry(version=0, model=model, prompt=initial_prompt)]  
    def current(self) -&gt; PromptVersionEntry:  
        return self._versions[-1]  
    def update(self, new_prompt: str, model: Optional[str] = None, metadata: Optional[dict]=None):  
        next_version = self.current().version + 1  
        entry = PromptVersionEntry(version=next_version,   
                                   model=model or self.current().model,  
                                   prompt=new_prompt, metadata=metadata)  
        self._versions.append(entry)  
        return entry  

# 创建智能体和初始提示  
from agents import Agent  # 假设的agents SDK  

METAPROMPT_TEMPLATE = """  
Context:  
Original prompt: {original_prompt}  
Section: {section}  
Summary: {summary}  
Reason to improve: {reasoning}  

Task:  
Write an improved summarization prompt that is more specific and preserves all details...  
"""  

metaprompt_agent = Agent(name="MetaPromptAgent", instructions="You are a prompt optimizer.")  
summarization_prompt = VersionedPrompt(initial_prompt="You are a summarization assistant. Given a section, produce a summary.")  
 summarization_agent = Agent(name="SummarizationAgent", instructions=summarization_prompt.current().prompt, model=summarization_prompt.current().model)</code></pre><pre><code>VersionedPrompt</code></pre><p>确保每次提示变更都有记录(版本1、2、3...)。</p><pre><code>PromptVersionEntry</code></pre><p>存储文本及相关模型、版本号等信息。代码实例化了一个"MetaPromptAgent"专门负责重写提示,以及一个用简单初始提示的SummarizationAgent。循环中每次更新提示时调用</p><pre><code>summarization_prompt.update(...)</code></pre><p>,新条目追加到版本列表,需要时可以回滚。这套机制让提示演变过程可追溯。</p><p><strong>4、自我进化循环编排</strong></p><p>最后是核心的自我改进循环实现。单次迭代的逻辑：</p><ol><li>智能体用当前提示<strong>生成摘要</strong>;</li><li>在(section, summary)上<strong>跑评估</strong>拿到评分;</li><li>计算综合分数(评分器均值),检查是否过宽松阈值;</li><li>通过则成功;未通过则<strong>收集反馈</strong>并改进提示;</li><li>每个部分最多重试若干次;</li><li>所有部分处理完后,选择综合得分最高的提示版本。</li></ol><p>简化代码如下：</p><pre><code> MAX_RETRIES = 3  
for section, content in dataset:  
    for attempt in range(1, MAX_RETRIES+1):  
        # 运行总结智能体  
        result = Runner.run(summarization_agent, content)    
        summary = result.final_output  
          
        # 用评分器评估  
        grader_scores = await get_eval_grader_score(eval_id=EVAL_ID, section=content, summary=summary)  
        avg_score = calculate_grader_score(grader_scores)  
        passed = is_lenient_pass(grader_scores, avg_score)  
          
        print(f"Attempt {attempt}: avg score={avg_score}, passed={passed}")  
        if passed:  
            break  
          
        # 如果失败,收集文本反馈并向MetaPromptAgent询问新提示  
        feedback = collect_grader_feedback(grader_scores)  
        prompt_input = METAPROMPT_TEMPLATE.format(  
            original_prompt=summarization_prompt.current().prompt,  
            section=content,  
            summary=summary,  
            reasoning=feedback  
        )  
        meta_result = await Runner.run(metaprompt_agent, prompt_input)  
        improved_prompt = meta_result.final_output  
          
        # 更新总结智能体的提示  
        summarization_prompt.update(new_prompt=improved_prompt, metadata={"section": content, "summary": summary})  
        summarization_agent = Agent(name="SummarizationAgent", instructions=improved_prompt, model=summarization_prompt.current().model)  
         print(f"  Improved prompt to version {summarization_prompt.current().version}")</code></pre><p>对每个文档部分,</p><pre><code>SummarizationAgent</code></pre><p>生成摘要,然后跑评估(</p><pre><code>get_eval_grader_score</code></pre><p>)计算分数。未通过检查时,组装反馈字符串(如"化学名称缺失"或LLM给的原因描述),调用MetaPrompt智能体传入原始提示、文档片段、摘要和反馈。MetaPrompt LLM返回<strong>新提示</strong>,更新</p><pre><code>VersionedPrompt</code></pre><p>并重建SummarizationAgent。重试最多</p><pre><code>MAX_RETRIES</code></pre><p>次直到通过或放弃。处理完所有数据后,追踪哪个提示版本综合得分最高。实际循环会记录每一步并最终打印最优版本。这展示了<strong>自生成反馈</strong>(评分器结果)如何驱动迭代改进——智能体在教自己如何写更好的提示。</p><h2>总结</h2><p>自我进化智能体适用于任何任务复杂且持续演变的领域。除了医疗文档,<strong>金融</strong>(智能体跟随市场变化更新策略)、<strong>编程</strong>(代码生成智能体适应新库和新错误模式)、<strong>生物医学</strong>(研究助手迭代优化文献综述)都是潜在场景。相关研究已经指出生物医学、编程、金融这些垂直领域的具体策略。代码生成智能体可以根据测试结果持续改进编码风格或错误检测逻辑;客服聊天机器人可以从新类型的用户咨询中在线学习。</p><p>随着AI智能体被部署到关键任务,自动自我改进能把人力从繁琐的debug转移到高层决策——设定目标、确保安全。能够自我纠错的智能体长期来看更可靠。</p><p>最后这个领域还很新,算是对这个方向的首批系统性审视之一,开放问题很多。比如说如何安全地允许智能体改写自身行为?什么评估基准最适合持续学习?但前景很有吸引力：未来的助手能优雅地从经验中学习;工厂机器人随生产需求自我调整;教育导师为每个学生个性化自己的教学策略。从静态AI到真正的终身学习智能体,这条路刚刚开始。</p><p><a href="https://link.segmentfault.com/?enc=mds4wYBelQhGyN%2F8blHoDA%3D%3D.OHjxUxKTlwjkxMEjzDAOATqQhrnedcciVa8BqkPsSE2aeic1vhneoz2XfUDYddR0XIqnRaEiEtYNzVpkOZIZkA%3D%3D" rel="nofollow" target="_blank">https://avoid.overfit.cn/post/39758407b909479aab400a01b29bac65</a></p><p>作者：DhanushKumar</p>]]></description></item><item>    <title><![CDATA[计算机组成原理 - 计算机系统概述 Al]]></title>    <link>https://segmentfault.com/a/1190000047438409</link>    <guid>https://segmentfault.com/a/1190000047438409</guid>    <pubDate>2025-11-29 23:01:55</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>计算机组成原理</h2><h3>概述</h3><h4>计算机系统</h4><h5>简介</h5><p>计算机系统由<strong>硬件</strong>和<strong>软件</strong>两大部分组成</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438411" alt="image-20230623125741365" title="image-20230623125741365"/></p><h5>计算机软硬件机器</h5><p>微程序机器 M0、实际机器 M1 归属于硬件 ；虚拟机 M2、M3、M4 归属于软件</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438412" alt="image-20230622094955297" title="image-20230622094955297" loading="lazy"/></p><h5>计算机体系结构和计算机组成区别</h5><p>计算机体系结构：程序员所见到的计算机系统的属性概念性的结构与功能特性（指令系统、数据类型、寻址技术、I/O 机理等）类似定义接口的概念</p><p>计算机组成：实现计算机系统结构所体现的属性（具体指令的实现）类似接口实现的概念</p><p>举例说明：一台机器是否具有某一项功能是计算机体系结构的问题，以至于这项功能是怎么实现得就是计算机组成的问题</p><h4>计算机的基本组成</h4><h5>冯.诺伊曼计算机的特点</h5><p>1、五大部件组成（控制器、运算器、存储器、输入设备、输出设备）</p><p>2、指令和数据以相同的地位存储在存储器中，可按地址进行寻访</p><p>3、指令由操作码和地址码组成</p><p>4、指令和数据以二进制的形式表示</p><p>5、以运算器为中心</p><p>6、指令在存储器内按顺序存放</p><h5>存储器的基本组成</h5><p>主要介绍存储体、存储器地址寄存器 MAR、存储器数据寄存器 MDR</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438413" alt="image-20230622150559063" title="image-20230622150559063" loading="lazy"/></p><h5>运算器的基本组成</h5><p>主要介绍算数逻辑运算单元 ALU、累加器 ACC、乘商寄存器 MQ、操作数寄存器 X</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438414" alt="image-20230622132557894" title="image-20230622132557894" loading="lazy"/></p><h5>控制器的基本组成</h5><p>主要介绍控制单元 CU、程序计数器 PC、指令寄存器 IR</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438415" alt="image-20230622135326640" title="image-20230622135326640" loading="lazy"/></p><h5>主机完成一条指令的过程</h5><p><strong>以取数指令为例</strong></p><p>指令包含两部分：一个是指令码（决定进行什么操作，比如是取数操作）；另一个是地址码（存放数据的地址）</p><p>步骤 1：取<strong>取数指令</strong>到指令寄存器 IR （绿线）</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438416" alt="image-20230622142251410" title="image-20230622142251410" loading="lazy"/></p><p>步骤 2：分析指令码以及执行指令操作（红线）</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438417" alt="image-20230622143704305" title="image-20230622143704305" loading="lazy"/></p><p><strong>以存数指令为例</strong></p><p>步骤 1：取<strong>存数指令</strong>到指令寄存器 IR （如上图取取数指令步骤 1）</p><p>步骤 2：分析指令码以及执行指令操作（橙线）</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438418" alt="image-20230622144324986" title="image-20230622144324986" loading="lazy"/></p><h4>计算机硬件的主要技术指标</h4><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438419" alt="image-20230622150434734" title="image-20230622150434734" loading="lazy"/></p><h3>计算机发展及应用</h3><p>略</p>]]></description></item><item>    <title><![CDATA[亚马逊为 Bedrock AgentCo]]></title>    <link>https://segmentfault.com/a/1190000047438452</link>    <guid>https://segmentfault.com/a/1190000047438452</guid>    <pubDate>2025-11-29 23:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>本文已收录在<a href="https://link.segmentfault.com/?enc=%2BoVLYp5XYDhGTM7N4VgI5g%3D%3D.%2FXG8RHRv63OxxhcsTiMUYofJIuzZ8ETL7H%2BD8rHrbAKWNQKQGjyIwfWazEVvV7P%2FrNnUXXxJcwQ3iDgvjCPZcw%3D%3D" rel="nofollow" target="_blank">Github</a>，<strong>关注我，紧跟本系列专栏文章，咱们下篇再续！</strong></p><ul><li>🚀 魔都架构师 | 全网30W技术追随者</li><li>🔧 大厂分布式系统/数据中台实战专家</li><li>🏆 主导交易系统百万级流量调优 &amp; 车联网平台架构</li><li>🧠 AIGC应用开发先行者 | 区块链落地实践者</li><li>🌍 以技术驱动创新，我们的征途是改变世界！</li><li>👉 实战干货：<a href="https://link.segmentfault.com/?enc=3OCFACAFhaSFTCEDTy5bbw%3D%3D.rDGlYHGrU2EWpXMApaS0%2FHQ%2BKGMzULmpdBVyY3bDAik%3D" rel="nofollow" target="_blank">编程严选网</a></li></ul><h2>0 前言</h2><p>亚马逊 <a href="https://link.segmentfault.com/?enc=I7D2O39psjlVFRIcXixlAA%3D%3D.KRa0askjeX96AwlAt99zcr5S%2BG1fS9eqCKXdCZ2IxU0jMp4bgqACfHrXAbshffgCfewK%2B4c8gu62Palv6jV9WTpCtQHKWmxbs9INJz6x7fcVpDO6LOwkIy7X%2BdOyRCv%2B%2B1i8fhY7B9HK3T7mixVYVhluDWIYNBjXLURNTUKCWyE%3D" rel="nofollow" target="_blank">宣布</a>，在 <strong>Amazon Bedrock AgentCore Runtime</strong> 正式支持A2A协议<strong>，让基于不同框架构建的智能体之间能够实现通信与协作。</strong></p><p>该协议支持来自 <a href="https://link.segmentfault.com/?enc=w%2BLCmfHJt5%2F%2FS1qp8ay1Rw%3D%3D.%2BR1ey4j9Qar5%2B0Ef8WbiAGYnTVRVZlIamN5Gf%2Bvpg6BuhaAxsxnnFwTulLHNdBYP" rel="nofollow" target="_blank">Strands Agents</a>、<a href="https://link.segmentfault.com/?enc=%2BoqP1djSwde7udySoRtPFw%3D%3D.yc6w5L0CSbA1age6HSwAeC3lOPWGjHCKdrJw2v%2BJmUsOL2woHluWFnH5NgxB0z8b" rel="nofollow" target="_blank">OpenAI Agents SDK</a>、<a href="https://link.segmentfault.com/?enc=TzNpGw4Po4S4xIH8FfxhUg%3D%3D.oyej9fQYXkUw%2B9%2F5110J8C8WE9HKjsL5L1t47Z4A6LT8WXhhd4DuH3B7c1JB5VZs" rel="nofollow" target="_blank">LangGraph</a>、<a href="https://link.segmentfault.com/?enc=PYiOMCVKa%2B51WWYqdUWF6A%3D%3D.N1UlAAUypnuxyTdm%2F4Tuy%2FUVyIXVwnYnfORWnSKE6xZh6f9TW0stkEGky%2BM6JaQJ" rel="nofollow" target="_blank">Google ADK</a> 和 <a href="https://link.segmentfault.com/?enc=ZtnrniL6vK7feH1T2a5qHQ%3D%3D.2TjQkRI8PpPKHeZVJGrd3y89j5LOhoBuS2ld5bqKSNsYSp1Vky1RjqiJx808i6l8epwzAJ%2BFjdDdfZK2qenvzw%3D%3D" rel="nofollow" target="_blank">Claude Agents SDK</a> 等框架的智能体以“通用且可验证的格式”共享上下文、能力与推理信息。</p><p>Bedrock AgentCore Runtime充当这些跨智能体通信的基础设施层。通过 <a href="https://link.segmentfault.com/?enc=s1lD%2FG3a4BJqW0Vj4q5%2Fig%3D%3D.VvpxVBxw7jEfzLAE9cwYmCbwe15k1Hj1WhjqwgtFo%2F3BHE2pIVNmTK5Lv6b8K7Ia" rel="nofollow" target="_blank">A2A</a>，开发者可以构建跨框架的多智能体工作流，实现系统级协作。</p><h2>1 智能体系统的基础组件</h2><p><a href="https://link.segmentfault.com/?enc=dbRDJoOVyWbl5pdtnhkRWA%3D%3D.PhNLhI4HuwOmY0DUrRjgKgSemJBY5Wmkx8D1r1PbV2kD0NS1VruGmam7xm%2Fc8nQQ" rel="nofollow" target="_blank">智能体系统（Agentic systems）</a>想高效运行，需要多个核心组件协同工作：</p><ul><li><strong>记忆（Memory）</strong>：包括短期记忆（维持会话上下文）和长期记忆（跨多次会话保留洞察）</li><li><strong>工具（Tools）</strong>：赋予智能体执行功能，可通过原生集成或 <a href="https://link.segmentfault.com/?enc=80B1%2FhryNhe8IdYzqOpeyA%3D%3D.vMJNfLSEtorLA6jwovMpi2DudlFWwNifqQFzA3JQXWw%3D" rel="nofollow" target="_blank">Model Context Protocol（MCP）</a> 服务器访问</li><li><strong>身份管理（Identity Management）</strong>：通过 <a href="https://link.segmentfault.com/?enc=rpzXblkXC6zAI0bdzRGviw%3D%3D.k%2BslUqEVDA%2BctGF3uWyubJ0%2B72%2BPBViglzSnK8LDeW4%3D" rel="nofollow" target="_blank">IAM</a> 提供安全认证与权限控制，使智能体可代表用户或自主访问资源</li><li><strong>安全防护（Guardrails）</strong>：通过 <a href="https://link.segmentfault.com/?enc=%2BAAdKqPTAH8T9VydBxLAaA%3D%3D.aNNTyqc5GhHmIDuDKQaBDWhZbaAUMWDZmhlg2QkzUQeVNZp%2Fd33B2uMj%2FiRXr5bu" rel="nofollow" target="_blank">Bedrock Guardrails</a> 检测有害内容、防止幻觉、确保输出符合政策和事实准确性</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438454" alt="" title=""/><br/><em>来源：<a href="https://link.segmentfault.com/?enc=09sVkZxPFHWkNImMO5AmeA%3D%3D.TYjGVVaTonE0TKQ0xokzZ7hPsf5d6tsxf%2FpD5C4qigrfBEggeMdUXhzz7E%2Fv2F7nCdzEfQ1Oc86Aipu%2FS7ND8P4YEP5vAr73C7kJywx73ePj3eQ6KiYfcIWcDlON5Z73d0EWRV5pwswrblGHPhTGyA%3D%3D" rel="nofollow" target="_blank">Bedrock AgentCore 平台</a></em></p><hr/><h2>2 A2A 与 MCP 的区别</h2><p><a href="https://link.segmentfault.com/?enc=roIaM4futMvovg8MaWpGzg%3D%3D.J%2FufbbnBwj%2Bu1UyDCiACPZGwQfJl27n%2BNoiYgOiwVjjBfE8StFEbjkhtkVJYR5XTrxXr12SIiFUhLLoS%2Bj1VmXjSso9gAqtHa8dMgkRN6lDPT5ZFokbEo3lJWMtLI9zQL0SqBU9nXy7lq9Bow2jnfL%2Fvk2r2lQTU6K3XDf%2FPSVA%3D" rel="nofollow" target="_blank">A2A 协议</a> 解决 <strong>智能体之间的通信</strong> 问题，而 <a href="https://link.segmentfault.com/?enc=w2txxRCJ95V%2FuKNhCR9CZA%3D%3D.22fCv4hBPwaI4dTHEoMRP2%2Fp%2FmjK49%2BjJ8Sa1rUxpfk%3D" rel="nofollow" target="_blank">MCP</a> 解决 <strong>智能体与资源之间的连接</strong> 问题。</p><ul><li><strong>MCP</strong>：让单个智能体能访问其工具和数据源</li><li><strong>A2A</strong>：让多个智能体能彼此协调，共同完成任务</li></ul><p>这一区别对系统架构尤为重要——前者侧重“智能体到资源”，后者侧重“智能体到智能体”的协作通信。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438455" alt="" title="" loading="lazy"/><br/><em>来源：<a href="https://link.segmentfault.com/?enc=KbH768mnRBuUjJFm41h2CA%3D%3D.J72qecyc2wc0AfYdN20OiP1V9sDqII1nSrzZ%2F3qUsUs%2B9D328INCpmeJ44h7TWsxMnvEJEdKCkhL4F3Z1r6tv%2BC3z8ToZiqxpoG8%2FUkASKT8IiUMf%2FzfDpuhaIxBK27XYgYjufxIFco8f6l7WQViE%2FHKhMo4z%2FVepkVjGc6KyXM%3D" rel="nofollow" target="_blank">AWS 官方博客</a></em></p><hr/><h2>3 协议特性：松耦合与模块化</h2><p>A2A 协议采用 <a href="https://link.segmentfault.com/?enc=22SGMmLVUQnGa5G9J1bM3w%3D%3D.XkfwDWp9MDoCX9L5qC87luw1OUY7bWlPwKpSEXKwXeACRWdMAJUDLh%2BZpMWfMX3E" rel="nofollow" target="_blank">松耦合（Loose Coupling）</a> 与 <a href="https://link.segmentfault.com/?enc=CuGs7iDPKKqrSnnZ%2Fug%2FZA%3D%3D.pstU%2FXlQ7zgsinkXLYdL6CervYp%2Bo5nppv4Po%2BGb6uY4zlyaHEhLT21hPYnmEbJG" rel="nofollow" target="_blank">模块化（Modularity）</a> 设计，使每个智能体能作为独立单元运行。开发者可独立开发、测试、部署和升级单个智能体，而不影响整个系统。新智能体可无缝加入现有部署，而发生故障的智能体也能被隔离在定义好的交互边界内。</p><h2>4 动态发现与编排</h2><p>协议支持动态的 <strong>智能体发现与编排（Orchestration）</strong>。智能体通过标准化的模式（Schema）发布自身的能力信息，形成一个“功能注册表”。<br/><strong>编排智能体（Orchestrator Agents）</strong> 可基于实时任务需求发现并调用最合适的智能体，从而实现 <strong>自适应工作流</strong> ——任务会根据上下文动态分配给合适的智能体执行。</p><h2>5 技术实现：Agent Card 与 Task Object</h2><ul><li><strong>A2A服务器（A2A Server）</strong>：远程智能体通过实现协议规范的 HTTP 接口来提供服务，支持 <a href="https://link.segmentfault.com/?enc=Qsm5MHAKKg8vujJhUzpgow%3D%3D.dY1qPZnH73xFTLSNw92eYL8oMKubdIa6PjMBEP81g1x8zufB8aWufCc%2FElQf7O58PUQ1z%2BJQBxgVkHpKoLM9e84E2SGLIJd0eJ12ZSPfHZQ%3D" rel="nofollow" target="_blank">HTTP/S</a> 上的 <strong>JSON-RPC 2.0</strong> 通信，既可 <a href="https://link.segmentfault.com/?enc=oNlk23LogYriXZMVeX6rtQ%3D%3D.VNmAFzKQSBqPcE6Akxk8iXB0FPRZewf4NLBbowaddigpc8dQafpkBOM2ZGfa84W0a7qYvOeXQFzesKj%2FRhvkRQiiQmJ5oqfyPhyZZzTOCZwGEE5VOjeCoN%2FESr08yGavKGJ1XK%2BTczQrAe3Exzhq5%2FXy73ee%2FozWn0OPVpftYuE%3D" rel="nofollow" target="_blank">同步</a>，也可 <a href="https://link.segmentfault.com/?enc=6cmAlKv5vusGQTQq%2Br%2BAzw%3D%3D.vRlqV7y4H1VN%2B0VFFDxu2nIHVGSOxCc8RrGC36J7ZjvKeaKFU6snLDiqRvJk18lbj0eYxIHijYc9cVDUDPym5seorfDWdLnS2MWB%2BJRFiZLgv3q1XvJStS6%2BqXGlF1l3VMCJLwS%2FsgXTu1kNYcX6K4qh6hEG8U4Naozkzp2a1so%3D" rel="nofollow" target="_blank">异步</a> 交互</li><li><strong>Agent Card</strong>：每个智能体都会发布一个 JSON 元数据文件，描述其身份、功能、接口端点及认证要求<br/>这相当于一份“契约说明书”，让其他智能体能正确地与其交互。</li><li><strong>Task Object</strong>：代表系统中流动的每个任务单元，包含唯一标识符和生命周期信息。任务可能是长时间运行的过程，涉及多个智能体的多轮协作。协议会跟踪任务状态，帮助编排器监控进度、处理故障或超时</li></ul><h2>6 安全性与社区反馈</h2><p>安全研究机构 <a href="https://link.segmentfault.com/?enc=RZaQWyj7m3Sb1xjWyCCb0A%3D%3D.RhDzeMwJRhWDmeSgSx7tQ7dZYtai6CS8PHmBu0xVQpGIx5XJyLuIT64KlCxmoTth" rel="nofollow" target="_blank">Unit42（Palo Alto Networks）</a> 指出，A2A 协议的状态化设计可能带来安全风险。根据其 <a href="https://link.segmentfault.com/?enc=8iZYE0m4lGCQRQ%2Bs1FPbfA%3D%3D.10w8Sja2tSlWam8TAsxm2wZBs2fch4HWrMIKXwIULgY%2FAIBi3Tn1ozyYre%2BSDRbkHR6%2FrPtuJnkiBwOYlGIkx0cXhmYOISRU31EqHlRiILjQalL%2FwtP9Ykymm2ltInf7" rel="nofollow" target="_blank">分析报告</a>：</p><blockquote>A2A允许智能体在会话中记住交互历史并保持上下文一致性。这种特性可能被攻击者利用，通过“会话走私（Session Smuggling）”注入恶意指令，将其隐藏在正常请求与响应之间。</blockquote><h2>7 开发资源与文档</h2><p>有兴趣实现基于 A2A 的系统的开发者，可参考：</p><ul><li><a href="https://link.segmentfault.com/?enc=MXqx6lMpHMerz6r3s5bg9A%3D%3D.6YKh7bcMTaHTqycJpjFF%2BRr%2F%2F%2FyaZ%2FWxtpJGvr5MfYf9TSjkR1bm41h98St3bDzLWvuZEnLROeujRZm0zNl%2FhEym0eyzA2wEWRvQJ0edrbMpBbxYT1rq7y9o1B2BtnzA1QVV0QOpT440aS3mc5ZfmRDvv0eWY4PfjA2X%2FcwPlLI%3D" rel="nofollow" target="_blank">A2A 教程与示例代码</a></li><li><a href="https://link.segmentfault.com/?enc=S%2F01GLJ3%2BKBikAFphpkYtw%3D%3D.t46%2BqxX4%2BP2grYjhMqwLL%2BAWEQgP6mOFcruPmFOYpb88BjwDTTORmHip%2F6inaJ0E" rel="nofollow" target="_blank">Bedrock AgentCore 开发者指南</a> ——详细介绍运行时操作、内存管理与身份控制</li><li><a href="https://link.segmentfault.com/?enc=fJB2vhrqs2r5xT%2F5oZyDZQ%3D%3D.nY3e2LohPNAa6Zsy%2BiPMdGAKAo1lPbQf7q0nQIVAhY0Z8TKGupIs%2F0myb%2FtaDWq7p2dmRySjy5m2MX5As0PSR2dPGcf09mX4%2BtfHMV8PMEfWIkmF3GtnYJrL95Q1pvkGpa04sqK2xugtcjqO12fQ4w%3D%3D" rel="nofollow" target="_blank">A2A 协议规范文档</a> ——定义智能体间通信的技术要求与交互模式</li><li><a href="https://link.segmentfault.com/?enc=kDUORBaeUmOnx46e709AnQ%3D%3D.NE1F8VFvHoRMi96H7YhKEaVGI%2FjvumPX0JMgnJYTm2p2T1DjSy%2BGkzzT941gE1hBa8kZhYgr8HJPD1OQcQ1IRbRRLYsyf0gnthBlTP4xGY0%3D" rel="nofollow" target="_blank">InfoQ 早期报道</a> ——回顾 Bedrock AgentCore 平台最初发布时的功能背景</li></ul><p>通过引入A2A，亚马逊进一步推动了多智能体生态系统的互操作与标准化，使不同框架和平台上的智能体能够协同工作，构建更复杂、更智能的分布式 AI 系统。</p>]]></description></item><item>    <title><![CDATA[Outlook OWA是什么？2025登]]></title>    <link>https://segmentfault.com/a/1190000047438337</link>    <guid>https://segmentfault.com/a/1190000047438337</guid>    <pubDate>2025-11-29 22:04:33</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在当今数字化办公的时代，企业对于高效、安全且便捷的邮件管理工具需求日益增长。Outlook的OWA网页版为企业提供了一种跨平台的邮件管理方式，而Zoho企业邮箱则凭借其独特的优势，成为外贸企业等众多企业的优选。下面将详细介绍Outlook OWA网页版的使用方法，并对比分析Zoho企业邮箱的优势。<br/><img width="723" height="443" referrerpolicy="no-referrer" src="/img/bVdnc2C" alt="" title=""/></p><h2>一、Outlook邮箱的OWA简介</h2><p>OWA的定义<br/>OWA，全称 Outlook Web App，是微软专为企业用户打造的网页版邮件管理平台。用户无需安装独立客户端，只需通过浏览器就能直接访问，轻松实现收发邮件、管理联系人和日历等操作。</p><h2>OWA与Outlook客户端的区别</h2><p>平台依赖：OWA摆脱了下载安装的束缚，任何设备只要有浏览器即可访问；而Outlook客户端则需安装在PC或移动端才能使用。<br/>实时性：OWA具备强大的实时同步功能，邮件、日历等内容能够随时与服务器保持同步，确保信息及时更新。<br/>操作体验：客户端支持更多本地功能，例如离线访问、集成进Windows等；OWA则更加轻便，操作界面简洁易用，降低了用户的学习成本。<br/>OWA的功能优势<br/>跨平台访问：只要有网络和浏览器，OWA就能让企业邮箱实现随时随地登录，极大地提升了远程办公的效率，非常适合现代企业不断变化的工作环境。<br/>简化操作界面：OWA简洁的结构使得常用功能如收件箱、发件箱、日历、任务等一目了然，有效降低了新手员工的操作门槛。<br/>实时同步功能：所有邮件和会议日程都会与服务器自动同步，保证信息的及时更新，杜绝因信息延误而带来的损失。</p><h2>二、如何使用Outlook的OWA</h2><p>登录OWA<br/>直接访问 OWA 官方网址：<a href="https://link.segmentfault.com/?enc=YY%2BV3jERUkE2vZd%2FnCHgWw%3D%3D.WGD9HbK6V6bPLPrK9pT1gb3YE4vxwHbnD%2FxACJKNrTQ%3D" rel="nofollow" target="_blank">https://outlook.office.com/</a> ，输入企业分配的邮箱账号和密码，即可完成登录。</p><h2>邮件管理操作</h2><p>发送和接收邮件：点击“新建邮件”，输入收件人、主题与正文，还可以添加附件。OWA支持较大附件传输，方便企业进行文件共享。<br/>管理邮件文件夹：支持自定义文件夹、快速邮件归档和搜索功能，有助于企业高效整理业务往来邮件。<br/>设置邮件规则：用户可以根据自己的需求自定义规则，例如自动分类、转发、删除垃圾邮件等，从而提升邮件处理效率。</p><h2>三、推荐：Zoho邮箱的替代优势</h2><p>企业在开展国际业务、进行跨国通讯时，对邮件的安全性和海外邮件的稳定收发能力有着更高的要求。Zoho企业邮箱凭借其卓越的性能，受到了全球1800万企业级客户的信赖，成为各类域名邮箱管理、移动办公以及海外业务的首选。</p><h2>Zoho邮箱的特色功能</h2><p>强大的邮件过滤与安全功能：内置先进的反垃圾邮件引擎和邮件加密技术，能够全面防御垃圾邮件和钓鱼邮件。同时，提供多层身份验证、TLS传输以及加密存储，全方位保障企业核心数据的安全。<br/>丰富的协作工具：Zoho Mail不仅仅是一个邮件管理工具，还集成了聊天、日历、任务、笔记、文件管理等功能，实现了企业级一体化办公。此外，原生CRM集成功能，非常适合外贸客户跟进，使销售进展更加透明化。<br/>定制化与品牌化：支持企业自定义域名（域名邮箱设置过程便捷），并且邮箱界面可以根据企业的品牌形象进行贴合设计。详细的注册步骤从域名绑定到多账号分配，只需数分钟即可启动。<br/>Zoho邮箱与Outlook OWA的对比<br/>以下是Zoho Mail与Outlook OWA在多个维度的简要对比：</p><p>对比项目    Zoho企业邮箱    Outlook OWA<br/>海外收发稳定性    全球多个数据中心，专为国际邮件优化    主要依赖微软全球节点<br/>安全防护    邮箱加密、反垃圾邮件、钓鱼拦截先进（企邮排行前三）    微软安全体系，防御能力强<br/>CRM及外贸支持    原生CRM直连，适合外贸客户全流程管理    CRM需集成第三方或手动配置<br/>大附件&amp;文件归档    支持大附件（最高容量1GB），邮件自动归档    附件支持较好，归档需结合OneDrive等<br/>移动办公/APP体验    高效Webmail、原生App全端同步    Webmail和Outlook客户端<br/>企业邮箱价格    起步价低，性价比高，适合中小/大型企业    定价以Microsoft 365套餐维度，高阶功能需升级<br/>中文/全球客户支持    全球1800万客户、全天多语言客服    全球用户基础强，欧美支持更佳<br/>注册步骤/易用性    注册步骤简洁，域名、用户开通一站式    注册由管理员配置，流程略复杂<br/>*具体容量请以Zoho Mail官网说明为准        <br/>为什么选择Zoho企业邮箱？<br/>适合中小企业与团队：Zoho企业邮箱提供灵活的套餐和按需定制功能，无论是中小企业还是大型团队，都能轻松扩展，满足现有业务及未来增长的需求。<br/>高度可扩展性：企业可以随时批量新建或删除账号，结合企业组织架构进行动态调整，同时支持移动办公、API集成和多端同步。<br/>优质客户支持：提供7x24小时多语言客服，能够快速响应企业日常运维及突发问题。在全球企业邮箱排行中连续多年稳居前三。</p><h2>四、常见问题及解答</h2><h2>如何找回Outlook OWA的登录密码？</h2><p>通过“忘记密码”功能，输入账号后，根据提示进行身份验证和密码重置。若为企业邮箱，请联系管理员协助处理。</p><h2>OWA登录时提示“无法连接到服务器”，怎么办？</h2><p>检查网络连通性或VPN设置，确认企业服务器正常运行。如依然无法访问，可用移动设备或浏览器清除缓存后重试，必要时联系IT支持。</p><h2>如何在OWA中设置自动回复？</h2><p>进入“设置——自动回复”，可自定义自动回复内容、启用时间段，并设定是否对外部联系人生效，轻松应对假期或短期离岗通知。</p><p>综上所述，Outlook的OWA网页版为企业提供了一种便捷的邮件管理方式，而Zoho企业邮箱则凭借其独特的优势，在海外收发稳定性、安全防护、协作功能等方面表现出色，是企业进行邮件管理和办公协作的优质选择。企业可以根据自身需求，选择适合自己的邮件管理工具。</p>]]></description></item><item>    <title><![CDATA[微软Outlook企业邮箱登录入口 遭老]]></title>    <link>https://segmentfault.com/a/1190000047438354</link>    <guid>https://segmentfault.com/a/1190000047438354</guid>    <pubDate>2025-11-29 22:03:42</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在企业通信中，邮箱的安全性和功能性至关重要。Outlook企业邮箱作为微软旗下产品，在企业通信领域广泛应用。同时，Zoho Mail凭借其独特优势，也为众多企业提供了优质选择。下面将详细介绍如何安全登录Outlook企业邮箱，并对比分析Outlook企业邮箱与Zoho企业邮箱。<br/><img width="723" height="443" referrerpolicy="no-referrer" src="/img/bVdnc2T" alt="" title=""/></p><h2>Outlook企业邮箱登录入口概述</h2><h2>官网登录入口地址</h2><p>使用Outlook企业邮箱，强烈建议通过微软官方登录网址：<a href="https://link.segmentfault.com/?enc=GL6TjOQjr9qpi3bCerO7Gg%3D%3D.4Y5oInB0CobWK62OBYmpI1KClhyDNx2eeFPidZE2OV8%3D" rel="nofollow" target="_blank">https://outlook.office.com</a> 。此地址专为企业版（Office 365/Exchange）设计，能有效确保数据连通与安全。</p><h2>登录入口的识别与安全性</h2><p>企业用户务必警惕仿冒网站。判断登录页是否为官方入口，可核查HTTPS证书及页面域名，切勿通过第三方链接或邮件打开。特别是在域名邮箱管理与访问过程中，更要注重登录安全。建议启用企业邮箱防钓鱼和多因素身份验证等额外措施，全方位保障通信安全。</p><h2>Outlook企业邮箱的特色与优势</h2><h2>邮箱功能与性能</h2><p>高效邮件管理：Outlook支持智能邮件分组、优先收件箱及强大筛选功能，非常适合多业务线高强度收发。企业邮箱的大附件传输、自动归档、邮件标签等功能，可显著优化日常通信效率。<br/>强大的日程管理：内置日历与会议安排工具，便于跨部门及国际团队协作。Gantt视图与与会通知功能，能大幅提升企业内部信息流转协同效率。<br/>集成的协作工具：Outlook与Teams、SharePoint等深度整合，可部署企业级邮件归档和知识分享，为企业协作提供有力支持。</p><h2>安全与隐私保护</h2><p>数据加密技术：Microsoft为Outlook企业邮箱引入端到端邮件加密，确保传输过程中数据信息安全。邮件加密机制既能满足合规需求，又适用于国际商务往来。<br/>防止恶意软件与垃圾邮件：先进的反垃圾邮件过滤与防病毒引擎，可智能甄别疑似邮件，有效提升企业邮箱安全性，降低业务风险。<br/>多因素身份验证：支持生物识别、短信验证等多重认证方式，有效防止未授权访问。<br/>与Microsoft生态系统无缝集成<br/>与Office 365的协同工作：邮件、联系人、日程全面互通，可提升文件、会议、任务流转效率，实现邮件驱动业务流程自动化。<br/>与Azure的集成优势：Azure Active Directory可实现单点登录与权限管理，适用于大型企业邮箱部署及身份认证整合需求。<br/>Outlook企业邮箱与Zoho企业邮箱对比</p><h2>功能维度</h2><p>邮件处理能力：Outlook企业邮箱以其深度办公开发能力著称，支持复杂邮件场景。Zoho企业邮箱则因高效海外邮件稳定收发能力、智能反垃圾邮件、支持企业邮箱大附件等，深受外贸企业青睐。<br/>日程与任务管理：Outlook主打与Office生态、Teams集成。Zoho企业邮箱内建协作工具，支持和CRM等Zoho产品无缝配合，更适合中小企业和国际贸易团队。</p><h2>安全性维度</h2><p>数据保护措施：Outlook采用微软自研TLS/SSL协议加密。Zoho Mail提供端到端邮件加密、多层次反垃圾邮件与邮件归档功能，并针对外贸场景优化了海外邮件扩展与反黑名单机制。<br/>用户认证方式：Outlook主推多因素认证及企业级Azure同步。Zoho Mail则以灵活的身份管理和高效防钓鱼策略为特色，提升账户总体安全性。</p><h2>集成与扩展性维度</h2><p>第三方应用支持：Outlook企业邮箱与绝大多数Microsoft 365、第三方办公服务深度兼容。Zoho Mail天然支持CRM集成、多终端移动办公、API开放等，便于海外团队协同。<br/>企业级解决方案的灵活性：Outlook适合对微软生态高度依赖的大型组织。Zoho Mail高性价比、海外服务器架构，适配中小型及外贸企业多地域发展。<br/>对比表：Outlook企业邮箱 vs Zoho企业邮箱<br/>对比维度    Outlook企业邮箱    Zoho企业邮箱<br/>全球用户基数    Microsoft 365全球2亿 + 企业级用户    全球1800万企业级客户，全球邮箱排行前三<br/>海外邮件收发    在中国大陆等地区偶有延迟或不稳定    多国家服务器，外贸及国际邮件畅通稳定<br/>安全防护功能    企业级数据加密，强防垃圾邮件    端到端加密，专业反垃圾、反钓鱼，不易中断<br/>核心集成功能    深度集成Office/Teams/SharePoint    邮箱、日历、联系人无缝协作，CRM集成、API兼容<br/>价格灵活性    针对大型企业定价，部分中小企业负担较重    中小企业邮箱/大型企业邮箱套餐多样，企业邮箱价格适中，提供定制化服务<br/>移动办公体验    全平台App支持，Office生态无缝延展    Webmail、iOS/Android App，支持IMAP/POP/Exchange ActiveSync<br/>大附件/归档功能    邮件最大支持150MB，邮件归档需付费/定制    支持大附件批量收发，邮件归档内置，多端同步<br/>注册与域名管理支持    域名邮箱注册复杂，需手动设置DNS，初次配置耗时    注册步骤简明，提供向导工具和专属客服，入门友好</p><h2>常见问题及解答</h2><h2>如何找回忘记的Outlook企业邮箱密码？</h2><p>可通过Outlook密码重置官网完成自助找回，遵循页面操作，根据注册邮箱或手机验证身份。</p><h2>Outlook企业邮箱登录时提示“账号不存在”，怎么办？</h2><p>确认输入的邮箱地址拼写、域名是否正确。若仍无法登录，建议联系企业IT部门核查账户状态或注册信息。</p><h2>如何在移动设备上登录Outlook企业邮箱？</h2><p>在App Store或Google Play下载“Microsoft Outlook”官方App，添加企业邮箱账户，按提示完成域名邮箱配置，即可享受推送提醒及同步日程功能。</p><p>考虑到企业通信安全与外贸收发需求，Zoho Mail凭借全球分布式服务器、全面加密与专业反垃圾机制，为域名邮箱提供了顺畅、稳定的体验。企业可根据自身需求，选择适合的邮箱服务。</p>]]></description></item><item>    <title><![CDATA[智能工单管理系统哪家好？六款知名软件解析]]></title>    <link>https://segmentfault.com/a/1190000047438359</link>    <guid>https://segmentfault.com/a/1190000047438359</guid>    <pubDate>2025-11-29 22:03:07</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>智能工单管理系统已成为提升企业效率、优化客户服务的关键工具。无论是制造业、服务业还是 IT 行业，这类系统都能助力企业实现任务分配、进度跟踪、数据分析等功能，进而提升整体运营效率。然而，市场上智能工单管理系统种类繁多，企业该如何挑选出适合自己的工具呢？接下来，为大家介绍六款知名热门智能工单管理系统。<br/><img width="723" height="487" referrerpolicy="no-referrer" src="/img/bVdnc2Y" alt="" title=""/></p><h2>1. Zoho Desk</h2><p>Zoho Desk 是一款功能全面且灵活的智能工单管理系统，专为提升客户服务效率与优化团队协作而打造。作为 Zoho 生态系统的一员，它既支持独立使用，也能与 Zoho CRM、Zoho Projects 等工具无缝集成，为企业提供一站式解决方案。</p><p>核心功能<br/>多渠道支持：支持电话、邮件、实时聊天、社交媒体等多种渠道的工单管理，确保客户问题能得到快速响应。<br/>智能任务分配：借助 AI 技术（Zia AI），依据任务优先级和员工工作负载自动分配工单，提高分配效率。<br/>实时数据分析：内置强大的分析工具，支持生成自定义报告和仪表盘，助力企业深入了解工单处理效率和客户满意度。<br/>自定义与集成：支持高度自定义工单字段、自动化规则和工作流，还能与 Zoho 生态系统及第三方工具（如 Slack、Jira）无缝集成。<br/>移动端支持：提供移动应用，方便服务人员随时随地处理工单。<br/>适用场景<br/>客户服务：快速响应客户问题，提升客户满意度。<br/>IT 支持：高效管理技术支持工单，优化问题解决流程。<br/>制造业：管理设备维护和生产任务，提升生产效率。<br/>优势<br/>界面友好，易于上手。<br/>定价方案灵活，适合不同规模的企业。<br/>AI 功能强大，自动化水平高。<br/>推荐理由<br/>Zoho Desk 性价比极高，功能全面且灵活，适合各行业企业使用，尤其适合需要多渠道支持和高度定制化的企业。</p><h2>2. Zendesk</h2><p>Zendesk 是全球知名的客户服务和工单管理系统，专注于帮助企业提升客户支持效率，以强大的多渠道支持和用户友好界面著称。</p><p>核心功能<br/>支持电话、邮件、社交媒体和实时聊天等多渠道。<br/>实现自动化工单分配和优先级排序。<br/>提供数据分析与报告功能，助力企业优化客户支持流程。<br/>支持知识库管理，方便客户自助解决问题。<br/>适用场景<br/>客户服务：适合处理大量客户咨询的企业。<br/>电商行业：管理客户订单和售后服务。<br/>优势<br/>界面简洁，易于使用。<br/>多渠道支持功能强大。<br/>劣势<br/>定价较高，适合预算充足的企业。<br/>高级功能需额外付费。</p><h2>3. Freshdesk</h2><p>Freshdesk 专注于客户支持，提供多种自动化功能和强大的协作工具。</p><p>核心功能<br/>支持电话、邮件和社交媒体等多渠道。<br/>实现自动化工单分配和 SLA 管理。<br/>支持知识库和社区论坛，方便客户自助解决问题。<br/>适用场景<br/>客户服务：适合中小型企业的客户支持需求。<br/>IT 支持：管理技术支持工单。<br/>优势<br/>界面友好，易于上手。<br/>定价灵活，适合中小企业。<br/>劣势<br/>高级功能较少，适合基础需求的企业。</p><h2>4. ServiceNow</h2><p>ServiceNow 面向大型企业，专注于 IT 服务管理（ITSM）和企业流程自动化。</p><p>核心功能<br/>IT 工单管理和自动化任务分配。<br/>具备强大的数据分析和报告功能。<br/>支持与企业现有系统深度集成。<br/>适用场景<br/>IT 行业：管理复杂的技术支持和项目任务。<br/>大型企业：需要高度定制化和集成的企业。<br/>优势<br/>功能强大，适合复杂需求。<br/>支持深度定制和集成。<br/>劣势<br/>实施成本高，适合预算充足的大型企业。<br/>学习曲线较陡。</p><h2>5. Jira Service Management</h2><p>Jira Service Management 由 Atlassian 推出，专注于 IT 服务管理和项目管理。</p><p>核心功能<br/>支持 IT 工单管理和 SLA 管理。<br/>与 Jira 软件无缝集成，满足项目管理需求。<br/>提供数据分析与报告功能，助力优化流程。<br/>适用场景<br/>IT 行业：管理技术支持和项目任务。<br/>软件开发：与 Jira 软件结合使用，提升开发效率。<br/>优势<br/>与 Jira 软件深度集成，适合开发团队。<br/>功能强大，支持复杂需求。<br/>劣势<br/>界面较复杂，新用户需一定学习时间。</p><h2>6. Kayako</h2><p>Kayako 专注于客户支持，提供多渠道支持和协作工具。</p><p>核心功能<br/>支持电话、邮件和实时聊天等多渠道。<br/>支持知识库管理，方便客户自助解决问题。<br/>提供数据分析与报告功能，助力优化客户支持流程。<br/>适用场景<br/>客户服务：适合中小型企业的客户支持需求。</p><p>优势<br/>界面简洁，易于使用。<br/>定价灵活，适合中小企业。<br/>劣势<br/>功能较为基础，适合简单需求的企业。</p><h2>如何选择适合的智能工单管理系统？</h2><p>企业在选择智能工单管理系统时，需根据自身需求和预算进行权衡：</p><p>明确需求：确定是注重客户服务，还是需要支持 IT 工单管理。<br/>预算考量：选择适合预算的系统，不一定要选最贵的，但要确保功能满足需求。<br/>用户友好性：挑选界面友好、易于上手的系统，降低员工学习成本。<br/>可扩展性：选择支持定制和集成的系统，以便未来扩展功能。<br/>Zoho Desk 凭借灵活的定价方案、强大的功能和高度的可扩展性，成为各行业企业的理想之选。</p><p>智能工单管理系统是企业提升效率、优化服务的重要工具。本文介绍的六款知名系统各有特色，其中 Zoho Desk 以全面的功能、友好的界面和灵活的定价方案，成为最值得推荐的解决方案。无论是中小企业还是大型企业，Zoho Desk 都能助力实现高效的工单管理，推动企业数字化转型。</p>]]></description></item><item>    <title><![CDATA[2人团队交付神器：低代码1人起购实战 遭]]></title>    <link>https://segmentfault.com/a/1190000047438364</link>    <guid>https://segmentfault.com/a/1190000047438364</guid>    <pubDate>2025-11-29 22:02:10</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>市场上许多低代码平台，如伙伴云、简道云、氚云等，往往要求30人起购。这对于2人开发团队而言，既不经济也不实用。不过，还有像Zoho Creator低代码平台这样更为灵活的选择，它支持“1人起购”，标准版仅需672元/人/年，让小团队也能以可承受的成本享受低代码技术带来的效率提升。这种模式使2人开发团队能够快速构建应用，将开发周期从数月缩短到几周甚至几天。<br/><img width="723" height="480" referrerpolicy="no-referrer" src="/img/bVdnc23" alt="" title=""/></p><h2>一、低代码平台是什么？为何能让小开发团队高效交付？</h2><p>低代码开发平台是一种借助可视化编程界面和少量代码生成逻辑，助力开发者快速构建应用程序的工具。它通过图形化界面、拖拽组件和模型驱动的方式，大幅减少手动编码工作量，让非技术人员也能参与应用开发。</p><p>对于小团队来说，低代码平台的核心价值体现在以下几个方面：</p><h2>降低开发门槛</h2><p>业务人员无需具备深厚的编程基础，通过可视化操作即可搭建简单应用。</p><h2>提升开发效率</h2><p>能够缩短传统开发周期，1个人能够发挥2 - 3人的人效。</p><h2>快速响应需求</h2><p>业务实践或优化可在几分钟内开发出来，并获得即时反馈。</p><h2>降低成本风险</h2><p>减少对专业开发人员的依赖，缓解IT资源紧张问题。</p><h2>二、市场主流低代码平台价格对比</h2><p>下表对比了市场主流低代码平台的价格策略，清晰展示了哪些平台更适合小团队使用：</p><p>平台名称    起购要求    价格范围    产品优势    适合团队规模<br/>Zoho低代码    1人起购    标准版：672元/人/年起    AI辅助数据迁移、多设备自适应、800 +国际应用集成    中小型团队、跨国公司<br/>伙伴云    30人起购    标准版：8800/年起    数据协作与业务管理平台    中大型企业<br/>简道云    30人起购    标准版：5040元/年起    零代码开发    中大型企业<br/>氚云    30人起购    标准版：4280元/年    零代码与少代码混合开发模式    中型企业<br/>金蝶云苍穹    定制报价    业务版：198,000元/年起    财务领域专业性强    大型集团企业<br/>织信    定制报价    定制开发价格通常较高    全栈开发能力、国产化适配    大型企业、国有企业<br/>宜搭    定制报价    轻享版2988元/年起    支持阿里生态    中型企业<br/>从对比中可以看出，Zoho低代码在起购门槛和价格灵活性方面具有明显优势，特别适合小团队、国际企业根据实际需求逐步扩展。</p><h2>三、Zoho低代码平台的特点及优势</h2><p>Zoho低代码平台作为连续多年入选Gartner低代码平台“魔力象限”的产品，在低代码领域深耕19年，在全球拥有16个数据中心，600万 +用户，数据稳定，安全可靠。</p><h2>全栈自研技术与AI深度融合</h2><p>Zoho低代码平台的底层架构采用全栈自研，与多数依赖第三方技术的低代码平台不同。平台将AI能力深度融入开发流程，其生成式AI引擎Zia支持通过对话式提示生成应用程序，极大简化了系统开发流程。</p><h2>丰富的预构建模板和组件</h2><p>Zoho低代码提供超过60种预构建应用模板，覆盖CRM、项目管理、库存管理等多种场景。这些模板可以作为快速起点，大幅缩短开发时间。</p><h2>强大的集成能力和扩展性</h2><p>Zoho低代码支持与800多种应用集成，包括Zoho自身CRM、ERP等系统以及国际工具如Slack、Trello、Salesforce等。这种强大的集成能力打破了企业内部的信息壁垒，实现数据的自由流通和共享。</p><h2>跨平台开发与移动优先</h2><p>一次开发即可适配Web、iOS、Android设备，可一键发布应用至多个操作系统，实现跨平台无缝运行。这大大减少了针对不同平台重复开发的工作量，为企业节省时间和成本。</p><h2>细粒度权限管理和安全保障</h2><p>Zoho Creator提供了精细的权限管理体系，可精确到字段级别。在数据安全方面，平台使用AES_CBC/AES_GCM、256位/128位密钥和TLS 1.2协议等强密码加密数据，确保企业数据安全。</p><h2>四、如何快速上手Zoho低代码平台</h2><p>对于2人开发团队，快速上手Zoho低代码平台可以遵循以下步骤：</p><p>用Zoho账号登录Zoho低代码平台，如果没有账号，可以先注册一个。Zoho低代码提供15天全功能免费试用以及免费版，团队可以先注册熟悉平台基本功能。</p><h2>利用预置模板加速开发</h2><p>选择与业务需求最匹配的预置模板作为起点。Zoho低代码提供的60多个模板覆盖了大多数常见业务场景，团队只需根据自身需求进行定制调整，无需从零开始。</p><h2>重点掌握核心功能</h2><p>优先学习平台的核心功能：表单设计器、工作流自动化、报表生成和集成能力。Zoho低代码的表单设计器功能丰富，支持多种字段类型和自定义校验规则，工作流引擎可满足复杂的审批流程设置。</p><h2>利用学习资源加速掌握</h2><p>Zoho提供了详细的帮助文档和线上培训资源。2人团队可以分工学习，一人专注于前端界面设计，另一人专注于后端逻辑和数据管理，实现高效协作。</p><h2>从小型项目开始实践</h2><p>选择一个小型但完整的业务场景作为第一个实践项目，如客户信息管理、订单跟踪或库存管理系统。通过实际项目熟悉平台特性，逐步扩展到更复杂的应用。</p><h2>五、真实客户案例</h2><p>元品贸易是一家专注于美国和非洲商超市场的小型服装外贸企业。通过Zoho低代码平台，元品贸易在仅15天内就搭建了符合企业需求的国际供应链管理系统，系统总费用仅为传统开发的十分之一，年账号续费仅两千多元（3用户）。</p><p>该系统支持多实体选择切换，对于不同的客户，可以选择不同的代理商实体和出口商实体，对应到每个订单的财务开票。不同订单和实体统一到一个数据看板，应收账款、应付账款和销账数据一目了然。实施Zoho低代码后，元品贸易的工作效率提升了50%，订单管理和跟进时间大大缩短，错误率归零。</p><h2>结语</h2><p>对于2人开发团队而言，选择合适的低代码平台至关重要。Zoho低代码平台以其1人起购的灵活定价、丰富的功能模块和强大的集成能力，成为小团队高效交付的理想选择。</p><p>通过低代码平台，2人团队可以实现与大型团队相媲美的开发效率，快速响应市场变化和业务需求。Zoho低代码平台的全栈自研架构和持续创新能力，确保小团队构建的应用能够随业务增长而扩展，无需担心系统稳定性和扩展问题。</p>]]></description></item><item>    <title><![CDATA[项目成本管理内容有哪些？ 遭老罪的程序猿]]></title>    <link>https://segmentfault.com/a/1190000047438373</link>    <guid>https://segmentfault.com/a/1190000047438373</guid>    <pubDate>2025-11-29 22:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在企业经营或个人项目管理的过程中，成本管理始终是绕不开的重要话题。无论项目规模大小，资源的有限性都促使我们仔细审视每一笔支出，追求最大化效率。正如彼得·德鲁克所说：“成本是一项迫使我们检验所有行为的现实要素。”这句名言恰如其分地道出了成本管理的重要性：它不仅是财务上的考核与测算，更是确保项目成功的关键抓手。<br/><img width="723" height="460" referrerpolicy="no-referrer" src="/img/bVdk1ax" alt="" title=""/><br/>下面，我们将以清晰的逻辑逐步探讨项目成本管理的核心内容，挖掘其在实际应用中的重要性，并推荐一款实用的工具。</p><h2>一、项目成本管理的四大核心内容</h2><h2>成本估算</h2><p>成本估算是项目成本管理的起点，也是决定后续步骤成败的基础。所谓估算，并非简单列出数字，而是通过科学方法计算完成每一部分工作的可能代价，涵盖人力、物力、时间以及风险带来的隐性成本。</p><p>进行成本估算时，项目经理需灵活运用历史数据、行业统计和岗位技能相关对照指标。例如，参考以往类似项目的费用结构、材料单价和市场波动，结合项目团队的交付能力，使估算更精准。像 Zoho Projects 这类工具能发挥重要作用，它允许项目团队通过案例模板记录历史数据，快速生成各项成本结构的估算依据。</p><h2>预算制定</h2><p>预算制定是将估算的成本整合成整体资金计划，明确具体资金在不同阶段的使用。完备的预算规划可有效避免资金浪费，让团队投入更具价值。</p><p>此过程需兼顾细节与全局，资金分配、进度跟踪以及应急储备比例设定都是重要部分。以 Zoho Projects 为例，它提供直观图表与自定义预算模块，帮助经理清晰分配费用，根据优先级调整资源分类投入，减少人为疏漏失误风险。</p><h2>成本控制</h2><p>若预算是蓝图，成本控制就是施工过程中的监督者。通过有效成本控制，项目管理者可随时掌握实际支出与计划是否相符，是否需调整规划以避免超支或偏离预期目标。</p><p>成本控制核心包括：</p><p>定期追踪实际支出进度，与预算对比分析。<br/>识别和处理可能导致成本增加的异常迹象，如进度拖延或需求变更。<br/>灵活使用工具记录每一项开销，确保财务透明化。<br/>在这方面，Zoho Projects 的实时跟踪功能突出。它依托自动化模块记录每一笔费用，通过警报系统提醒管理者支出异常节点，为及时调整提供依据。</p><h2>成本核算</h2><p>项目结束后，需汇总分析所有成本，这是项目成本管理的最后一步。通过整理核算数据，不仅能评估项目资源使用效率，还能为未来决策提供借鉴。</p><p>核算过程除传统财务报表整理，更需关注：</p><p>实际支出是否在预算范围内？偏差源自哪个环节？<br/>是否存在资源浪费？有哪些改进空间？<br/>如何衡量资金投入与成果产出的性价比？<br/>通过 Zoho Projects，这一环节可实现全自动化处理，避免人工计算误差，提供清晰报告模板，优化后续项目启动与规划。</p><h2>二、项目成本管理的关键注意事项</h2><p>掌握项目成本管理核心内容后，仍需关注关键事项，确保理论在实际场景中高效落实。</p><h2>不可忽视的隐性成本</h2><p>项目成本管理不仅包括显性支出（如设备采购、员工工资等），还需关注隐藏成本，如合作方失信、政策变动影响等。具备细腻的隐性成本分析能力，能帮助企业在制定预算时有更大应对弹性。</p><h2>实时动态调整</h2><p>传统项目成本管理常凭固定计划执行，但实际操作中，环境不确定性会给预算带来冲击。此时，实时监控与动态调整尤为重要。借助像 Zoho Projects 这样的工具，项目团队可追踪关键数据，第一时间优化计划。</p><h2>团队成本意识的培养</h2><p>即便工具先进，成功与否关键仍取决于团队对成本的关注度。项目团队每位成员都应充分理解成本控制意义，自觉将“节约并高效”作为工作准则。</p><h2>三、为什么选择 Zoho Projects？</h2><p>市面上项目成本管理工具众多，但 Zoho Projects 凭借功能完备性和灵活性脱颖而出。以下是其关键优势：</p><h2>一站式解决方案</h2><p>Zoho Projects 提供从成本估算、预算制定到支出追踪的全流程管理，简化传统项目成本管理复杂操作。它还支持多维度自定义报表与数据导入，满足企业及个人用户多元需求。</p><h2>高度可视化的成本控制</h2><p>通过清晰图表与标注提醒，Zoho Projects 让成本控制不再是隐性幕后工作，而是成为团队可协作完成的公开化环节。</p><h2>云端安全性</h2><p>作为基于云的项目管理工具，Zoho Projects 确保数据实时同步与存储安全，让用户随时随地掌控项目开销。</p><h2>灵活收费模式</h2><p>无论小企业还是大型公司，都能在 Zoho Projects 找到适合预算的订阅模式，降低技术门槛，提升工具性价比。</p><p>项目成本管理是企业经营和个人项目管理中不可或缺的环节。通过掌握核心内容、关注关键事项，并借助像 Zoho Projects 这样的实用工具，我们能够更好地管理项目成本，提高项目成功率，实现资源的高效利用。</p>]]></description></item><item>    <title><![CDATA[如何使用GitHub Pages托管博客]]></title>    <link>https://segmentfault.com/a/1190000047438319</link>    <guid>https://segmentfault.com/a/1190000047438319</guid>    <pubDate>2025-11-29 21:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h3>配置自定义域名</h3><ul><li>如果没有GitHub账户，请先<a href="https://link.segmentfault.com/?enc=Zp2H19BxeIshhZfIUvzl2w%3D%3D.0zBdD8u7I0UhA1YSAJ5OSdwRwhx4qPQEA0uO93U4JXE%3D" rel="nofollow" target="_blank">注册账户</a>，账户为<code>username</code></li><li>如果已有GitHub账户，但是想修改账户名 或 修改域名，点击“Settings”（设置）&gt;&gt;&gt; 点击“Account”（账户）&gt;&gt;&gt; Change username</li></ul><p>新建仓库 New repository. 创建新的 <code>username</code>.github.io 仓库</p><h3>创建gh-pages</h3><p>新建仓库后，会有一个main分支，此时我们需要再创建一个分支<code>gh-pages</code>（或者自己喜欢的分支名字，）</p><ul><li>如果是基于刚新建完成仓库建立的<code>gh-pages</code>里面是无文件纯净的</li><li>如果是基于推送代码建立的<code>gh-pages</code>是有文件的，如果你想保持一个干净的仓库需要把他们删了</li></ul><h3>设置博客使用分支</h3><ul><li>进入新的 <code>username.github.io</code> 仓库</li><li>选择 “Settings”</li><li>选择 “Branch” 中新建的分支，如gh-pages</li></ul><h3>创建一个博客文件，如blog，并关联此项目</h3><pre><code class="bash">git init
git add .
git commit -m "first commit"
git remote add origin https://github.com/newusername/newusername.github.io.git
git push -u origin main</code></pre><h3>把blog项目打包出dist文件，并推送到gh-pages分支</h3><p>如果<code>gh-pages</code>分支有问题可先删除再创建，删除命令</p><pre><code class="bash">git push origin --delete gh-pages  # 删除远程分支
git branch -D gh-pages             # 删除本地分支</code></pre><p>基于当前分支的dist文件创建<code>gh-pages</code>分支</p><pre><code class="bash">git subtree split --prefix dist -b gh-pages
git push origin gh-pages</code></pre><p>把dist文件推送到main分支后，再把dist推送到gh-pages</p><pre><code class="bash">git subtree push --prefix dist origin gh-pages  # 无冲突
git push origin `git subtree split --prefix dist main`:gh-pages --force  # 有冲突</code></pre><h3>访问路径</h3><p><code>https://username.github.io/</code></p><h2>创建子项目博客</h2><ol><li>新建仓库 New repository. 创建新的 <code>任意仓库</code>，但不能是 <code>username</code>.github.io 仓库</li><li>其他步骤同上</li><li>访问路径：<code>https://username.github.io/任意仓库名/</code></li></ol>]]></description></item><item>    <title><![CDATA[拒绝 Token 焦虑：我在 Spec ]]></title>    <link>https://segmentfault.com/a/1190000047438255</link>    <guid>https://segmentfault.com/a/1190000047438255</guid>    <pubDate>2025-11-29 20:01:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>引言：AI 很好用，但 Token 真的很贵</h2><p>在 AI 辅助编程（如 Spec Kit）日益普及的今天，我们往往会陷入一种两难：既想让 AI 帮我们干完所有脏活累活，又看着后台飞速消耗的 Token 感到肉疼。</p><p>尤其是在处理复杂需求时，随着对话轮数的增加，上下文（Context Window）会变得极长。这不仅意味着 <strong>Token 消耗呈指数级增长</strong>，更糟糕的是，上下文越长，AI 的“注意力”越分散，越容易出现遗忘前文或产生幻觉的情况。</p><p>经过最近一个项目的实战（NATS 消息订阅模块开发），我总结了一套<strong>“Spec Kit 降本增效指南”</strong>。</p><p>我的核心观点是：<strong>“省 Token”不仅仅是为了省钱，更是为了让 AI 保持清醒，输出高质量代码。</strong> 下面分享我总结的 3 个实战技巧。</p><hr/><h2>技巧一：预处理（Pre-processing）—— 借力打力，用廉价算力换高质量输入</h2><p>很多人习惯把 Spec Kit 的输入框当成草稿纸，把脑子里零碎的想法一股脑倒进去，然后让它慢慢整理。这是最奢侈的用法。</p><p><strong>“抠门”技巧：</strong><br/>在正式启动 Spec Kit 之前，先利用其他更便宜甚至免费的 AI 模型（如 ChatGPT-4o mini、Gemini Flash 或 DeepSeek）进行“预处理”。</p><p><strong>操作步骤：</strong></p><ol><li><strong>头脑风暴</strong>：对着 ChatGPT 把你想做的功能语无伦次地讲一遍。</li><li><strong>清洗提炼</strong>：要求它：“请帮我梳理上述需求，生成一段简洁、结构化、覆盖核心功能点且无歧义的 Prompt，供 AI 编程工具使用。”</li><li><strong>复制粘贴</strong>：把这段清洗过的“黄金 Prompt”投喂给 Spec Kit。</li></ol><p><strong>收益：</strong><br/>Spec Kit 的上下文极其昂贵。通过“借力打力”，我们避免了在 Spec Kit 内部进行低效的需求拉扯。<strong>Garbage In, Garbage Out</strong>（垃圾进，垃圾出）在 AI 时代依然适用，但 <strong>Gold In, Diamond Out</strong> 才是我们的追求。</p><hr/><h2>技巧二：批处理（Batching）—— 拒绝“挤牙膏”式对话，一次性把话说明白</h2><p>这是我在 <code>Clarify</code>（澄清）阶段发现的最痛的领悟。</p><p><strong>传统做法的弊端：</strong><br/>通常 AI 会问一个问题 Q1，你回答 A1；它再根据你的回答想出 Q2，你再回 A2……每一轮对话，系统都会把之前的整个历史（History）重新打包发送一遍。对于长上下文模型来说，这简直是在“烧钱”。</p><p><strong>“抠门”技巧：</strong><br/>强制 AI <strong>“一次性输出所有问题”</strong>，你也 <strong>“一次性回答所有问题”</strong>。</p><p><strong>如何操作：</strong><br/>在执行 <code>Clarify</code> 步骤时，明确提示 AI：</p><blockquote>“请分析当前需求，列出<strong>所有</strong>需要澄清的问题，并提供选项。请一次性列出，不要分批提问。我会以 'Q1: A, Q2: B' 的格式一次性作答。”</blockquote><p><strong>实战案例（NATS 消息订阅功能）：</strong><br/>我是这样要求 AI 的，结果它一次性输出了非常清晰的结构：</p><blockquote><p><strong>所有澄清问题</strong></p><p><strong>Q1: 消息订阅者的作用域缩减</strong><br/>确认: 当前功能仅包含订阅 NATS 消息、解析入库、更新会话？账号创建由其他接口负责？</p><ul><li>Option A: 是，仅做消息入库和会话更新...</li><li>Option B: 消息入库时若 sender 不存在，创建最小记录...</li></ul><p><strong>Q2: 消息引用不存在的 sender/session 时的处理</strong></p><ul><li>Option A: 跳过该消息，记录警告日志</li><li>Option B: 存储消息，ID 设为 null...</li><li>Option C: 消息入队等待，直到相关实体被其他接口创建</li></ul><p><strong>Q3: NATS 主题配置方式</strong></p><ul><li>Option A: 固定主题名</li><li>Option B: 配置文件配置</li></ul><p><strong>Q4: 消息处理的并发模式</strong><br/>...</p><p><strong>Q5: wx\_message 表中 sender\_id 的存储方式</strong><br/>...</p></blockquote><p>而我的回复极其简洁，极大地节省了 Token：</p><pre><code class="text">Q1: A, Q2: C, Q3: cc.callback.demo, Q4: 消息只需要订阅, Q5: B</code></pre><p><strong>进阶技巧：纠错也要“批发”</strong><br/>同理，在生成 <code>specify.md</code> 文档后，如果你发现有 3 处逻辑错误，千万不要分 3 次指正。在本地记事本里列好 1、2、3 点，然后一条消息发过去：“请一次性修正以下所有问题……”。</p><hr/><h2>技巧三：分治法（Divide and Conquer）—— 实现阶段的“外科手术”</h2><p>到了最后的 <code>Task</code> 和 <code>Implement</code> 阶段，如果任务过于庞大，AI 往往会生成一半就中断（Output Token Limit），或者后面生成的代码逻辑混乱。</p><p><strong>“抠门”技巧：</strong><br/>不要试图一口气吃成胖子。将 Implementation 阶段人为拆解为两步走。</p><p><strong>操作步骤：</strong></p><p><strong>第一步：搭骨架（Infrastructure First）</strong></p><ul><li><strong>指令</strong>：“请先仅执行与‘基础设施’相关的 Tasks。包括：1. 创建数据库表结构 (DDL)；2. 搭建项目目录结构；3. 编写基础配置类和实体类。<strong>暂不要实现具体的业务逻辑。</strong>”</li><li><strong>收益</strong>：这部分代码相对固定，AI 极少出错。先生成这一步，你可以快速 Review 表结构是否正确。如果表设计错了，重试的成本很低。</li></ul><p><strong>第二步：填血肉（Business Logic Second）</strong></p><ul><li><strong>指令</strong>：“基础结构已确认。现在请基于已有的实体类和表结构，实现剩余的业务逻辑 Tasks（如 NATS 监听器逻辑、Service 层处理流程）。”</li><li><strong>收益</strong>：此时 AI 已经有了正确的“上下文”（即第一步生成的代码），它写出来的业务逻辑会非常精准，且因为单次输出量减少，极大降低了幻觉概率。</li></ul><hr/><h2>总结</h2><p>使用 Spec Kit 这类工具，本质上是在考验我们的<strong>结构化思维</strong>。</p><ol><li><strong>预处理</strong>：用低成本模型清洗杂质，保证<strong>输入纯净</strong>。</li><li><strong>批处理</strong>：合并交互轮次，保证<strong>链路极简</strong>。</li><li><strong>分治法</strong>：拆解复杂任务，保证<strong>产出可控</strong>。</li></ol><p>当你学会像“审计员”一样去管理 AI 的 Context，你会发现，你不仅省下了一大笔 Token 费用，更重要的是，AI 变得更聪明、更懂你了。</p><p>本文由<a href="https://link.segmentfault.com/?enc=%2B0BTaVULqZogSeWGAqao4Q%3D%3D.l5GtYFKiQhsvoIgFksc2LX4Ul5RLUWIEh8zoi5cUFTo%3D" rel="nofollow" target="_blank">mdnice</a>多平台发布</p>]]></description></item><item>    <title><![CDATA[【技术分享】用python开发采集软件，]]></title>    <link>https://segmentfault.com/a/1190000047437778</link>    <guid>https://segmentfault.com/a/1190000047437778</guid>    <pubDate>2025-11-29 18:03:14</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <blockquote>今天给大家分享一款我用Python开发的实用工具——【爬微博搜索软件】，专为需要批量获取微博内容的用户打造，解决了常规采集的诸多痛点。</blockquote><h2>一、工具开发背景与核心优势</h2><h3>1.1 开发初衷</h3><p>微博作为国内顶流社交媒体平台，以实时性强、热点传播快、KOL影响力大著称。无论是热点事件追踪、行业动态分析，还是用户舆论调研，微博上的海量文字、图片内容都极具参考价值。但实际操作中，大家常会遇到采集页数受限、多关键词切换繁琐、数据易丢失等问题。基于这些需求，我开发了这款采集工具，旨在提供更高效、稳定的内容获取方案。</p><h3>1.2 界面展示</h3><p>工具界面简洁直观，无需复杂操作，上手即用：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047437781" alt="图片" title="图片"/><br/>软件界面</p><h3>1.3 结果预览</h3><p>采集数据全面且结构化，包含11个核心字段，方便后续分析使用：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047437782" alt="图片" title="图片" loading="lazy"/><br/>采集结果.csv核心字段包括：关键词、页码、微博ID、微博链接、用户昵称、用户主页链接、发布时间、转发数、评论数、点赞数、微博内容。</p><h3>1.4 演示视频</h3><p>工具运行全程可视化，具体操作流程可查看演示视频，直观了解采集全流程。原文有。</p><h3>1.5 重要说明</h3><ul><li>支持Windows系统直接双击启动，无需安装Python运行环境，操作门槛低。经多次测试，工具运行稳定，可持续采集不中断。</li><li>需提前在cookie.txt文件中填写个人微博cookie（内附详细获取教程），便于重复使用。</li><li>支持多关键词并行采集，关键词之间用|分隔即可。</li><li>可自定义采集时间范围，格式统一为YYYY-MM-DD，精准锁定目标内容。</li><li>采集过程中按页保存CSV文件，每1-2秒自动存储一次，避免异常中断导致数据丢失。</li><li>生成专属log日志文件，详细记录运行状态，方便问题回溯与排查。</li><li>工具持续迭代更新，后续将不断优化功能体验。</li></ul><h2>二、核心开发技术栈</h2><h3>2.1 整体框架</h3><p>工具整体基于Python语言开发，各模块分工明确：</p><pre><code class="python">tkinter：搭建简洁易用的GUI操作界面
requests：处理网络爬虫请求，确保数据获取稳定
BeautifulSoup：解析响应数据，精准提取核心信息
pandas：负责CSV文件保存与数据清洗，保证数据规范性
logging：实现运行日志记录，便于问题定位</code></pre><p>注：出于版权保护，暂不公开源码，仅提供工具使用权限。</p><h3>2.2 部分源码</h3><p>1、向页面发送请求和解析数据部分：</p><pre><code class="python"># 发送请求
r = requests.get(url, headers=h1, params=params)
# 解析数据
soup = BS(r.text, 'html.parser')</code></pre><p>2、保存数据部分：</p><pre><code class="python"># 保存数据
df = pd.DataFrame(
    {
        '关键词': kw,
        '页码': page,
        '微博id': id_list,
        '微博链接': wb_url_list,
        '用户昵称': name_list,
        '用户主页链接': user_link_list,
        '发布时间': create_time_list,
        '转发数': repost_count_list,
        '评论数': comment_count_list,
        '点赞数': like_count_list,
        '微博内容': text_list,
    }
)
if os.path.exists(self.result_file):  # 如果文件存在，不再设置表头
    header = False
else:  # 否则，设置csv文件表头
    header = True
# 保存csv文件
df.to_csv(self.result_file, mode='a+', index=False, header=header, encoding='utf_8_sig')
self.tk_show('结果保存成功:{}'.format(self.result_file))</code></pre><p>3、日志部分：</p><pre><code class="python">def get_logger(self):
    self.logger = logging.getLogger(__name__)
    # 日志格式
    formatter = '[%(asctime)s-%(filename)s][%(funcName)s-%(lineno)d]--%(message)s'
    # 日志级别
    self.logger.setLevel(logging.DEBUG)
    # 控制台日志
    sh = logging.StreamHandler()
    log_formatter = logging.Formatter(formatter, datefmt='%Y-%m-%d %H:%M:%S')
    # info日志文件名
    info_file_name = time.strftime("%Y-%m-%d") + '.log'
    # 将其保存到特定目录
    case_dir = r'./logs/'
    info_handler = TimedRotatingFileHandler(filename=case_dir + info_file_name,
                                            when='MIDNIGHT',
                                            interval=1,
                                            backupCount=7,
                                            encoding='utf-8')
    self.logger.addHandler(sh)
    sh.setFormatter(log_formatter)
    self.logger.addHandler(info_handler)
    info_handler.setFormatter(log_formatter)
    return self.logger</code></pre><h2>三、详细操作指南</h2><h3>3.1 准备工作：</h3><p>获取并填写cookie打开PC端微博，进入搜索页面并完成登录。按教程打开浏览器开发者工具，找到对应Cookie信息并复制。 <br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047437783" alt="图片" title="图片" loading="lazy"/><br/>CK获取方法将复制的Cookie值粘贴到工具文件夹中的cookie.txt文件内，保存即可。</p><h3>3.2 账号登录流程</h3><p>打开工具后，进入登录界面，输入账号密码完成验证，即可启动采集功能。</p><h3>3.3 开始采集</h3><p>操作在工具界面填写核心采集条件：  <br/>搜索关键词：多个关键词用|分隔（示例：小米SU7|蔚来ES6|理想L6）<br/>日期范围：填写格式为YYYY-MM-DD，设定采集的时间区间<br/>采集最大页：建议单关键词单时间段不超过50页，</p><p>保障采集稳定性点击”开始执行”按钮，工具将自动启动采集任务。<br/>采集过程中请勿直接打开CSV文件，可复制副本查看实时数据，避免采集中断。 <img width="723" height="571" referrerpolicy="no-referrer" src="/img/bVdncTB" alt="image.png" title="image.png" loading="lazy"/></p><h2>四、使用相关说明</h2><p>本工具仅用于合法的信息收集与研究用途，禁止用于任何违法违规活动。 如因违规使用工具导致的任何法律责任，均由使用者自行承担，与工具开发者无关。</p><h2>五、版本更新日志</h2><ul><li>2025.3.17（v1.3版）：新增爬取颗粒度选择功能，支持按小时或按天采集，自由控制数据密度；File菜单新增意见反馈入口，方便及时收集问题并优化。</li><li>2025.1.9（v1.2版）：优化循环时间颗粒度，由原来的按天统计改为按小时统计，采集更精准。</li></ul><h2>六、作者声明</h2><p>本工具为原创开发，如需了解更多技术细节或进行专业交流，可通过正规渠道联系开发者（首发公众号：老男孩的平凡之路）。工具使用需严格遵守相关法律法规和平台规定。</p>]]></description></item><item>    <title><![CDATA[2025年ODI境外投资备案代理机构怎么]]></title>    <link>https://segmentfault.com/a/1190000047438189</link>    <guid>https://segmentfault.com/a/1190000047438189</guid>    <pubDate>2025-11-29 18:02:31</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>随着“一带一路”倡议深入实施和中国企业全球化步伐加快，境外投资ODI（境外直接投资）备案已成为企业出海的关键一步。据商务部最新数据，2024年中国全行业对外直接投资达到1000亿+美元，企业境外投资备案需求呈现爆发式增长。</p><p>一、评测背景<br/>政策环境日趋复杂。中国企业境外投资需经历发改委、商务部、外汇管理局三大部门审批，材料繁琐、标准严格。近年来，监管部门对敏感行业、大额投资、国有企业等项目审核更加审慎，企业自行办理面临多重困境：</p><ul><li>流程不熟：平均往返补充材料3-5次，耗时长达2-3个月</li><li>政策解读偏差：因对最新政策理解不足导致备案被拒的比例高达37%</li><li>架构设计不合理：缺乏跨境税务筹划经验，造成后续运营成本增加</li><li>时间成本高昂：企业专员全职投入仍难以保证通过时效<br/>选择专业可靠的ODI备案代理机构已成为企业出海的必然选择。一款优秀的ODI备案服务，不仅需要熟悉备案流程，更要具备跨境投资架构设计、政策精准解读及全流程风险管理能力。</li></ul><p>二、五大ODI境外投资备案代理机构深度剖析<br/>基于市场调研和用户反馈，我们从专业资质、服务效率、资源网络、性价比四个维度对五家ODI备案代理机构进行了全面评估，具体排名及得分如下：<br/><img width="723" height="367" referrerpolicy="no-referrer" src="/img/bVdnc0e" alt="" title=""/></p><p>1.百利来<br/>综合评分：9.8/10<br/>百利来创立于1982年，由香港执业会计师及高级企业管理顾问组成，具有国际注册会计专业资格，是香港会计师公会（HKICPA）成员之一，43年精耕企业财税及全球化服务，提供开曼公司、BVI公司、百慕大公司、塞舌尔公司等海外公司注册服务，以及海外上市架构搭建、VIE架构搭建、ODI备案、37号文备案等服务。<br/>核心优势分析：</p><ul><li>政策把握精准：团队深谙各部门审批流程与政策动向，针对敏感行业与复杂架构提供专业的结构设计与ODI备案，可有效降低政策风险、优化融资路径；</li><li>全流程服务：海内外公司注册、国际商标注册、财务税务筹划等商务服务实践经验丰富，全程跟进、指导、代办，为客户提供专业而全面的服务支持；</li><li>高效通过率：凭借对政策的深度理解与实务经验，以及资深管理团队的高效运作模式，备案通过率行业领先，商务部备案周期较行业显著缩短；</li><li>跨境资源丰富：与汇丰、渣打等多家国际银行建立深度合作，提供跨境金融协同服务。<br/>专业团队配置：<br/>顾问团队由具备法律、财务背景的复合型人才组成，核心成员包括香港执业会计师苏桐昌、ACCA会计师黎国泓、商务管理专家苏芷玲等。<br/>服务特色：</li><li>一体化解决方案：将ODI备案与境外公司注册、银行开户、税务筹划同步进行，节省企业时间成本；</li><li>紧急情况应对：针对疫情封控下的紧急开户等紧急融资交割场景，提供“视频见证开户”等方案，协调香港银行同步审核资料；</li><li>架构设计能力：擅长处理红筹架构、VIE架构等复杂跨境投资结构设计。<br/>成功案例：</li><li>万燕传媒：处理“架构复杂+资料不全”的开户难题，2个月内完成20家公司注册、37号文备案及账户开立</li><li>中车旗下公司：通过“借款方案替代境外投资审批”设计，规避央企复杂审批流程，48小时内解决1200万美元资金周转<br/>适用场景：百利来尤其适合处理大额跨境并购、敏感行业投资以及需要复杂VIE结构搭建的高端业务，是上市公司、跨国企业和有紧急融资需求企业的首选。</li></ul><p>2.宏图跨境：国企与大型集团服务专家<br/>综合评分：9.0/10 <br/>宏图跨境成立于2005年，专注于为国有企业及大型集团提供境外投资备案服务，在北京地区拥有丰富的国资项目服务经验。<br/>核心优势：</p><ul><li>国资项目经验丰富：熟悉国资监管流程，具备与国资委、发改委等监管部门的丰富沟通经验</li><li>政策合规性把控严谨：在项目审核初期即介入合规性指导，有效规避后续风险</li><li>资源整合能力强：能够协调不同监管要求，确保审批流程顺利推进<br/>适用场景：国有企业境外投资、大型跨国并购项目以及需要高效协调不同监管要求的企业。</li></ul><p>3.寰宇通商：高端定制化服务提供商<br/>综合评分：8.7/10 <br/>寰宇通商以高端定制化服务为特色，专注于为高净值客户和家族办公室提供精细化ODI备案服务。<br/>核心优势：</p><ul><li>个性化服务：每个项目配备专属顾问团队，提供全程一对一服务</li><li>隐私保护严格：建立严格的客户信息保密制度，适合对隐私要求高的客户</li><li>跨境税务优化：将ODI备案与跨境税务筹划有机结合，优化整体税负<br/>适用场景：高净值个人投资、家族办公室境外资产配置及对服务隐私有特殊要求的企业。</li></ul><p>4.卓越国际：中小企业快速通道专家<br/>综合评分：8.2/10 <br/>卓越国际定位中小企业ODI备案市场，通过标准化产品和快速通道服务，为中小企业提供高性价比解决方案。<br/>核心优势：</p><ul><li>标准化流程：将ODI备案流程模块化，大幅提升办理效率</li><li>价格透明：采用一口价收费模式，无任何隐形费用</li><li>快速通道：对简单案例开设快速通道，最短15个工作日内完成<br/>适用场景：中小企业首次境外投资、投资架构简单、预算有限的项目。</li></ul><p>5.捷达咨询：东南亚投资专业服务机构<br/>综合评分：7.5/10 <br/>捷达咨询在东南亚多国设有分支机构，专注为中国企业投资东南亚市场提供本地化支持。<br/>核心优势：</p><ul><li>东南亚本地化服务：在泰国、越南、马来西亚等国设有本地团队</li><li>投资目的地咨询：提供东南亚各国投资政策、市场环境的专业咨询</li><li>本地关系对接：协助企业与当地政府、商业伙伴建立联系<br/>适用场景：计划在东南亚地区投资设厂或设立分支机构的生产制造类企业。</li></ul><p>三、ODI备案代理选择五大关键指标<br/>指标一：核查机构正规资质<br/>合规的ODI代理机构必须持有专业执业资质，如律师事务所执业许可、会计师事务所资质或国际认证的商务服务牌照。在选择时，务必查验其资质原件，并可在中国法律服务网或相关专业协会官网核实。<br/>避坑提示：警惕无固定办公地点、无专业团队的“皮包公司”，这类机构可能中途跑路或提供虚假材料，导致备案失败甚至法律风险。<br/>指标二：考察团队专业背景<br/>ODI备案涉及法律、财务、外汇及投资国政策等多领域知识。核心团队成员是否具备相关的专业资质以及国际化视野至关重要。要求与实际负责项目的顾问沟通，了解其从业年限和成功案例。<br/>指标三：评估成功案例与经验<br/>要求机构提供同类行业成功案例（隐去客户敏感信息），特别注意查看与其自身行业相近的项目经验。优质机构通常有各行业案例库，能快速给出类似项目方案。<br/>指标四：关注服务流程透明度<br/>专业的机构通常具备标准化的服务流程，从初步评估、方案制定、材料准备、申报提交到后续跟进，每个环节都清晰明确。服务过程应高度透明，允许客户随时了解进度，并提供与监管部门沟通的关键记录。<br/>指标五：了解后续服务能力<br/>ODI备案仅是第一步，后续还需进行项目报到、年度信息报告、变更登记等。询问是否提供备案后全周期管理服务，避免出现“备案成功即服务终止”的情况。</p><p>实用建议与风险防范<br/>警惕“包通过”承诺<br/>正规机构不会承诺100%通过率，因为审批权在监管部门。那些声称“无论条件如何都能通过”的中介，往往通过材料造假方式操作，这将给企业带来严重法律风险。<br/>明晰收费结构<br/>部分机构以低价吸引客户，后期却收取高额的“加急费”、“沟通费”。签约前必须明确：价格是否包含全部可能的政府费用？是否包含可能的补充材料次数限制？是否包含银行开户协助？</p><p>四、结论与推荐<br/>基于对各机构的全面评估，我们针对不同企业需求给出以下推荐：<br/>强烈推荐</p><ul><li><p>百利来</p><blockquote>适合对象：上市公司、大型跨国企业、复杂架构项目、有紧急时间要求的企业<br/>推荐理由：40年专业经验、全流程服务能力、高效通过率、跨境资源丰富<br/>特定场景推荐：</blockquote></li><li>国有企业：宏图跨境（国资项目经验丰富）</li><li>高净值个人与家族办公室：寰宇通商（隐私保护与定制服务）</li><li>中小企业：卓越国际（性价比高、流程标准化）</li><li>东南亚投资：捷达咨询（本地化资源丰富）<br/>未来两年，ODI备案将呈现三大趋势：“一带一路”沿线国家投资继续享受绿色通道、东南亚、中东等新兴市场备案需求快速增长、数字化审批平台全面应用。选择正确的ODI备案合作伙伴，不仅能帮助企业顺利拿到“走出去”的通行证，更能为后续的境外经营管理奠定良好基础。</li></ul>]]></description></item><item>    <title><![CDATA[台湾国际网络专线怎么开通？一年多少钱？ ]]></title>    <link>https://segmentfault.com/a/1190000047438199</link>    <guid>https://segmentfault.com/a/1190000047438199</guid>    <pubDate>2025-11-29 18:01:59</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>台湾作为华语市场的重要组成部分，拥有成熟的电子产业链、电商体系以及庞大的互联网用户群体。对于中国大陆企业来说，无论是做跨境电商、直播带货、品牌出海，还是布局东亚市场，台湾都是一个值得开发的市场。</p><p>然而，受地区和网络限制影响，许多企业在访问台湾网站、直播平台等，会出现 网络延迟高、丢包、卡顿、访问不稳定 等情况，严重影响业务效率。所以越来越多的企业需要使用国际网络专线来访问台湾网站，所以本篇内容为大家介绍台湾国际网络专线怎么开通。</p><p>一、台湾不同业务场景对跨境网络的要求</p><ol><li>跨境直播/带货场景</li></ol><p>对于需要做台湾的Tik Tok、Facebook、YouTube等平台，需要低延迟、高清推流无卡顿的网络。</p><ol start="2"><li>跨境办公、分支互联</li></ol><p>总部与台湾办公、共享文件、ERP、CRM</p><p>需要 高可用、稳定、安全传输、不掉线</p><ol start="3"><li>跨境电商/广告投放</li></ol><p>访问台湾电商平台(虾皮、MOMO、PCHome 等)</p><p>广告投放后台(Google Ads、Meta Ads、LINE 广告)</p><p>需要 固定IP + 低延迟</p><p>总结：台湾跨境网络的核心要求</p><p>低延迟、无丢包、固定IP、稳定性高、全天候服务保障。</p><p>二、台湾国际网络专线应该怎么选择？</p><p>企业通常有两类选择方案：传统国际专线 和 SD-WAN国际专线。</p><ol><li>传统国际网络专线（MPLS/BGP）</li></ol><p>特点：</p><p>物理线路+运营商直连</p><p>稳定性强，适合关键业务</p><p>价格相对较高</p><p>开通周期稍长(7–20天)</p><p>适合场景：</p><p>金融、制造大型企业</p><p>大型跨国公司</p><p>台湾分公司与大陆总部互联</p><ol start="2"><li>SD-WAN 国际专线（OSDWAN）</li></ol><p>特点：</p><p>软件定义网络，自动选路</p><p>多线路叠加：BGP / IPLC / 云网 / 动态加速</p><p>价格更优惠</p><p>部署快、设备简单</p><p>优势（相较传统专线）：</p><p>优化跨境稳定性</p><p>自带 QoS、防抖动、防丢包</p><p>更适合直播、电商、跨境广告投放</p><p>支持台湾原生住宅 IP</p><p>适合行业：</p><p>跨境直播、电商、外贸办公、社媒运营等以及需要快速部署跨境网络的中小企业</p><p>三、台湾国际网络专线怎么开通？（以 OSDWAN 为例）</p><p>第一步：选择服务商（推荐 OSDWAN）</p><p>优势：</p><p>相较于传统的SD-WAN服务商，OSDWAN跨境网络专线也有极大突出优势：更好用、更高性价比、更安心。</p><p><img width="433" height="388" referrerpolicy="no-referrer" src="/img/bVdnc0o" alt="image.png" title="image.png"/></p><p>01、更好用：相比传统SD-WAN服务商只支持CPE设备，OSDWAN不仅支持多种型号的CPE设备，还支持经过安全认证的相应软件。支持Windows、Mac、iPhone、安卓、iPad，让您随时随地一键连接全球互联网。</p><p>02、更高性价比：相比传统SD-WAN服务商与运营商接近的高额网络费用，OSDWAN仅需一半不到的成本即可享受同等优质的网络线路。</p><p>03、更安心：相比传统SD-WAN服务商需要5-8个工作日按照工单解决客户问题，OSDWAN提供专属售后支持，配备专属售后顾问。同时还提供分流解锁，路由优化等服务。让您的业务安心出海。</p><p>OSDWAN 具备台湾多节点部署、7×24 小时支持、稳定的跨境专线，是目前许多跨境企业的常用选择。</p><p>第二步：准备开通所需资质</p><p>一般需要：</p><p>公司营业执照</p><p>使用场景(直播/办公/分支互联)</p><p>IP 使用需求(是否需要台湾固定IP)</p><p>带宽要求(10M / 20M / 50M / 100M)</p><p>第三步：开通流程（OSDWAN 示例）</p><p>需求评估(带宽/节点/用途)</p><p>测试节点(提供台湾测试线路，验证延迟与稳定性)</p><p>确定方案与报价</p><p>签约 &amp; 开通</p><p>设备调试（SD-WAN CPE）</p><p>登录连接就可以使用了</p><p>整个流程 最快可当天开通(SD-WAN)，传统专线约需 5–15 天。</p><p>四、台湾国际网络专线多少钱？（以 OSDWAN 为例）</p><p>OSDWAN提供灵活的计费模式，支持 按月、按年、带宽定制 多种方式。具体如下：</p><p>办公账号版：690元/年，适合外贸SOHO或小工作室使用</p><p>社媒运营套餐：1500元/年起：，TikTok运营、社媒矩阵、店铺运营</p><p>标准版：10000元/年，适合10人以内团队使用或普清TK直播</p><p>企业版：自定义，100+地区的线路和IP可选，自由组合配置</p><p><img width="723" height="339" referrerpolicy="no-referrer" src="/img/bVdm4sv" alt="image.png" title="image.png" loading="lazy"/></p><p>台湾市场潜力巨大，而跨境网络稳定性直接决定业务效果。从办公到跨境直播、电商运营、广告投放，都需要一条稳定可靠的 台湾国际网络专线。</p>]]></description></item><item>    <title><![CDATA[企业开通国际网络专线有什么要求？需要哪些]]></title>    <link>https://segmentfault.com/a/1190000047438204</link>    <guid>https://segmentfault.com/a/1190000047438204</guid>    <pubDate>2025-11-29 18:01:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>现在一条稳定、高速且合规的国际网络专线，已成为企业出海的关键基础设施，国际网络专线是企业与全球业务节点之间的高速、稳定、安全的专用网络连接通道。它通过点对点专用线路连接企业总部、分支机构与海外节点，相比普通互联网连接，能提供更高的可靠性、更低的延迟和更强的安全保障。那么企业怎么开通国际网络专线呢？需要哪些资质？</p><p>一、国际网络专线是什么？</p><p>国际网络专线主要有两种类型：传统专线(如IPLC、MPLS VPN)和新兴的SD-WAN专线。</p><p>传统国际专线：如IPLC(国际私有租赁线路)和MPLS VPN(多协议标签交换虚拟私有网络)，提供物理隔离的专用通道，不与其他用户共享带宽资源，稳定性极高、延迟极低，但成本较为高昂。</p><p>SD-WAN专线：软件定义广域网，不依赖单一物理线路，通过智能路由技术在多条网络链路中自动选择最优路径，当检测到网络拥塞时能在500毫秒内完成链路切换。它支持混合组网，能根据业务优先级动态分配带宽，显著提升网络利用率，从而大幅降低成本。</p><p>企业需要国际网络专线的核心价值在于：</p><p>合法合规，规避风险：中国《网络安全法》明确规定，企业需通过合规服务商申请跨境网络专线，私自搭建或使用非法VPN将面临法律风险。</p><p>保障业务稳定性与安全性：提供固定IP地址，避免跨境电商平台因IP变动触发封号风险;提供低延迟高稳定的网络环境，访问海外平台的速度较普通网络可提升70%以上。</p><p>数据安全升级：企业通过专线传输数据时可叠加加密技术，防止信息泄露。</p><p><img width="723" height="311" referrerpolicy="no-referrer" src="/img/bVdnc0s" alt="image.png" title="image.png"/></p><p>二、企业开通所需资质与条件</p><p>企业开通国际网络专线需满足以下基本条件和资质要求：</p><ol><li>企业基本资质证明</li></ol><p>营业执照信息：申请主体需为合法注册的企业，提供营业执照副本复印件并加盖公章。</p><p>法人实名信息：提供法人身份证原件及复印件。</p><ol start="2"><li>业务合规性要求</li></ol><p>公司业务合法合规：企业需证明其跨境业务符合中国及目标国家的法律法规。常见的合规出海类型包括：</p><p>B2B外贸：正常的跨国贸易业务</p><p>跨境电商：如亚马逊、eBay等平台店铺运营</p><p>软件出海：面向海外的软件服务与应用</p><p>跨国办公：海外分支机构与总部的协同办公</p><p>跨境业务证明：如海外分公司注册文件等。</p><p>除上述两项核心资质外，企业还需准备：</p><p>业务需求说明：详细说明使用场景(如跨境电商、跨境办公)、带宽需求、接入地点及覆盖国家。</p><p>根据《国际通信出入口局管理办法》，企业开通国际专线还需向工信部进行备案或申请相关许可证，确保跨境链路审批合规。这些手续通常由服务商协助完成。</p><p>三、如何选择合法合规的服务商</p><p>选择合规的服务商是企业开通国际专线的关键，以下是如何甄别优质服务商的要点：</p><p>服务商类型比较</p><p><img width="723" height="154" referrerpolicy="no-referrer" src="/img/bVdnc0t" alt="截屏2025-11-29 17.20.01.png" title="截屏2025-11-29 17.20.01.png" loading="lazy"/></p><p>四、选择服务商的五大关键因素</p><p>合规资质认证：核实服务商是否持有工信部颁发的《增值电信业务经营许可证》或国际电信业务经营许可，这是合法运营跨境业务的基本资质，比如明点跨境OSDWAN就是持证上岗的，通过工信部备案拥有合法资质的专业服务商。</p><p>节点覆盖与网络性能：考察服务商在全球POP节点(网络接入点)的数量和分布区域，确保覆盖企业的业务热点地区。同时关注网络性能指标，如延迟、丢包率等。</p><p>SLA服务等级协议：仔细查看SLA中对网络可用性(如99.9%)、延迟、丢包率、故障响应时间等的承诺，这是服务质量的保障。</p><p>安全防护能力：了解服务商的安全措施，如是否提供防火墙、DDoS防护、数据加密(如AES-256)等安全服务。</p><p>技术支持与响应：选择提供7×24小时技术支持的服务商，确认故障响应时间和恢复时效。</p><p>四、推荐在SaaS点评网排名第一的服务商：OSDWAN</p><p>在众多SD-WAN服务商中，OSDWAN(明点跨境)作为专注于跨境网络场景的服务商，展现出独特的优势和价值主张。</p><p>核心优势介绍：</p><p>1、合规性保障：OSDWAN使用三大运营商的国际网络专线，确保安全合规，企业出海合规是基础。</p><p>2、全球覆盖与高性能：在全球拥有50个数据中心节点，POP节点超过200个，为出海企业提供海外加速、SaaS加速、SD-WAN组网等服务。</p><p>3、技术实力卓越：通过SDWAN+硬件技术，结合运营商海底光缆专线，给企业提供安全、合规、可靠的网络整体解决方案。</p><p>4、性价比高：对比传统电信运营商，OSDWAN可帮助企业降低50%以上的网络成本。其入门版价格690元/年起，美区网络专线低至200元/M/月起，性价比高。</p><p>5、灵活部署与简易运维：同时提供SD-WAN盒子与手机/电脑APP，支持硬件+软件多终端灵活部署。无需复杂配置操作，一分钟即可安装使用，大幅降低企业IT管理负担。</p><p>适用场景</p><p>OSDWAN特别适用于以下业务场景：外贸办公、跨境电商、TK直播、AI大模型、学术科研、社媒运营等。其纯净住宅IP资源覆盖全球100+地区，纯净独享，可用于TK直播等对IP质量要求高的业务。</p><p>五、国际网络专线常见问题解答</p><p>问：开通国际网络专线需要多长时间？</p><p>答：开通时间因服务商和方案类型而异。传统MPLS专线部署周期通常需要1-3个月，而SD-WAN专线部署速度较快，OSDWAN甚至可做到当日开通，一分钟连接使用。</p><p>问：SD-WAN与传统VPN有何本质区别？</p><p>答：SD-WAN是一个完整的网络架构，而VPN仅是一种加密技术。SD-WAN同时整合MPLS、宽带、4G/5G等多种链路，并基于应用智能选路;VPN则完全依赖公共互联网，稳定性和性能无法保障。更重要的是，企业私自搭建跨境VPN存在法律风险，而合规的SD-WAN方案通过在中国境内的合规POP点与三大运营商合作，实现合法合规的跨境网络优化。</p><p>问：如何控制国际网络专线的成本？</p><p>答：可通过以下几种方式控制成本：</p><p>按需选择带宽，避免过度配置</p><p>选择支持按需付费或灵活计费的服务商</p><p>采用SD-WAN技术，通过混合组网降低专线依赖度，平均可降低30%-50%成本</p><p>问：企业开通国际专线最需要关注哪些合规风险？</p><p>答：需要重点关注以下合规风险：</p><p>服务商是否具备国际运营资质，遵守《国际通信管理条例》</p><p>数据跨境传输需符合《数据安全法》及目标国法律(如欧盟GDPR)</p><p>避免使用”免费VPN”，没有资质的服务商可能通过非法跨境转发数据，导致企业被处罚</p><p>在国际业务拓展中，选择合规可靠的国际网络专线不再是简单的技术决策，而是关乎企业全球化战略成败的关键因素。从资质准备、服务商选择到方案实施，确保每个环节的合法合规性，才能让企业的国际业务行稳致远。建议企业在正式采购前，向服务商申请免费测试，在真实业务场景中验证网络性能。</p>]]></description></item><item>    <title><![CDATA[Pion 创始人聊 WebRTC、AI、]]></title>    <link>https://segmentfault.com/a/1190000047438144</link>    <guid>https://segmentfault.com/a/1190000047438144</guid>    <pubDate>2025-11-29 17:03:55</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438146" alt="" title=""/></p><blockquote>深入理解 WebRTC 后，你会欣赏那些最初让你沮丧的设计。——Sean DuBois</blockquote><p>Pion 作为 WebRTC 开源领域的新兴力量，凭借其 Go 语言实现、高性能和可扩展性，迅速获得广泛关注，并成为众多第三方项目的基础架构。开发者可以利用 Pion 轻松构建高效且可定制的 WebRTC 解决方案，满足从数据通道通信、音视频流媒体到复杂应用场景的需求。</p><p>Pion 的创建者 Sean DuBois 在 Go 语言和 WebRTC 领域贡献卓越，同时为 PHP 和 GStreamer 提供了重要支持。他不仅是 WebRTC 权威指南 《WebRTC For The Curious》的作者，还建立了一个充满活力的 Pion 社区。</p><p>2024 年 9 月，Sean DuBois 加入 OpenAI 团队，继续在音视频通信领域深耕，主要负责 Realtime API 相关的工作。</p><p>近期，Sean DuBois 在一期播客中探讨了 WebRTC、WebSockets、SIP 等技术的应用与未来发展趋势，涵盖了从底层协议到实际应用场景的方方面面。他们不仅分享了各自对技术细节的独到见解，还展望了 AI 时代音视频通信的新可能性。</p><p>我们摘录了部分精彩内容，希望能给大家提供一些新视野。Enjoy\~</p><h3>核心要点</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438147" alt="" title="" loading="lazy"/></p><p><strong>Sean DuBois</strong></p><p>Pion 开源 WebRTC 项目创始人</p><p>目前在 OpenAI 工作</p><ul><li><strong>WebRTC 的吸引力：</strong> WebRTC 的魔力在于它只需要少量代码即可「连接世界」，简化了实时通信的复杂性。</li><li><strong>WebRTC vs. WebSockets 的权衡：</strong> WebRTC 包含了回声消除、编解码器管理和码率控制等关键组件，而 WebSockets 需要开发者自己构建这些，WebRTC 适用于复杂的、面向终端用户的应用。</li><li><strong>WHIP 协议的简化：</strong> WHIP 通过 HTTP 协议简化 WebRTC，便于集成到 FFmpeg 和 OBS 等工具中，支持嵌入式设备和更广泛的互操作性。</li><li><strong>WebRTC 的延迟挑战：</strong> WebRTC 的主要贡献者对延迟需求不同的边缘用例关注不足，延迟控制是一个挑战。</li><li><strong>QUIC 作为 WebRTC 的潜在竞争者：</strong> QUIC 和 Media over QUIC 被视为超越 WebRTC、支持更多用例和提高灵活性的潜在方法，尤其是在语音 AI 领域。</li><li><strong>WebRTC 的隐藏用例：</strong> 除了会议，WebRTC 还有许多被低估的用例，例如远程监考和在线拍卖，这些用例对延迟有极高的要求。</li><li><strong>SIP 在 AI 时代的复兴：</strong> 电话技术，尤其是 SIP，在垂直领域 AI 应用中看到了新的增长，因为它无需应用安装，方便用户使用。</li></ul><h2>WebRTC and AI in 2025</h2><p>嘉宾：Sean DuBois，Pion 开源 WebRTC 项目创始人兼《WebRTC For The Curious》作者，目前在 OpenAI 工作</p><blockquote>注：为便于阅读，本文内容已作精简，并非完整对话。你可以访问原文收听完整版播客。</blockquote><h2>「在各种与 WebRTC 相关的项目中转悠，我很喜欢」</h2><p><strong>主持人：</strong> 你是 WebRTC 社区的坚定支持者，一位杰出的程序员。你编写了很多代码，很多人都在使用，包括所有使用 OpenAI 产品的人。先向大家介绍一下你自己吧。</p><p><strong>Sean：</strong> 好的。我最初接触的是 WebRTC 和电话技术，比如 Asterisk 之类的。后来，我想做更多服务器端的东西，所以做了 Pion，它是 WebRTC 的 Go 语言实现。我希望它更灵活，可以用一些奇特的方式工作。</p><p>之后，我一直在不同的 WebRTC 公司工作，包括为 AWS 做 C 语言嵌入式开发，还参与了 WebRTC FaceTime 和 Twitch 的广播相关工作。</p><p><strong>现在我在 OpenAI 做 Realtime API 相关的工作</strong>，包括 1-800-CHAT-GPT 和嵌入式应用。总之，一直在各种与 WebRTC 相关的项目中转悠，我很喜欢。</p><h2>WebRTC 的魔力：只需少量代码即可连接世界</h2><p><strong>主持人：</strong> 我们是否应该简单介绍一下 WebSockets、WebRTC 和 SIP？SIP 对很多应用场景来说非常重要，因为它是底层电话通信的粘合剂。我经常告诉别人，WebRTC 擅长某些方面，WebSockets 擅长某些方面，你需要对 SIP 有一些了解。我们都不太喜欢给别人建议，更倾向于提供一些技术定义。你很早就开始接触 WebRTC，是什么吸引了你？</p><p><strong>Sean：</strong> 是的，我之前在 Etsy 工作，当时我们为各种视频产品支付了大量费用，仅仅是为了在电脑上与他人进行电话会议。当 WebRTC 出现时，它简直太神奇了，用很少的代码就可以连接两个端点。我当时写了一个小机器人，通过 IRC 发送 Offer 和 Answer。那一刻，我爱上了它。我已经做了很多年 RTP 和相关的东西，所以用起来很舒服。但 <strong>WebRTC 在浏览器中就能运行，无需插件，而且效果很好</strong>，这让我彻底着迷。从那时起，我就被它迷住了。</p><h2>当你深入理解 WebRTC 后，你会逐渐欣赏那些最初让你感到沮丧的设计</h2><p><strong>主持人：</strong> WebRTC 是一种内置于浏览器中的协议，现在在所有平台上都可用。<strong>它从一开始就被设计用于做极低延迟的音频和视频通信。</strong>OpenAI 最初发布了一个 API，就像很多人做的那样，用于实时的语音 AI，但只支持 WebSocket。现在你添加了 WebRTC，或者说已经添加了。你对这方面的工程规划是怎么考虑的？</p><p><strong>Sean：</strong> 对我来说，WebRTC 的吸引力在于两点。<strong>最明显的一点是它非常容易使用</strong>。你不需要了解音频采样率或编码器，带宽估计也是自动的，你只需要生成 Offer 和 Answer，然后就可以开始使用了。我认为这是最令人兴奋的部分。就像你从你的客户那里看到的那样，<strong>即使是不懂技术的人，也可以用它来构建非常酷的东西</strong>。这是我喜欢 WebRTC 的第一个原因。</p><p><strong>主持人：</strong> 但向人们解释清楚 WebRTC 还是有点复杂的，至少对我来说是这样。</p><p>如果你是一名程序员，并且编写了很多代码，那么你几乎肯定使用过 WebSockets。如果你想在服务器和应用之间建立一个长期的双向通信通道，你可能会默认选择 WebSockets。<strong>WebSockets 的 API 相当简单易用，而且支持广泛。</strong></p><p>但是，如果你最初选择了 WebSockets，<strong>你最终需要自己构建所有的组件</strong>，比如回声消除、编解码器管理、码率控制等等。而且，你没有足够的控制旋钮，<strong>无法构建一个在各种真实用户和网络条件下都能稳定运行的产品</strong>。</p><p>另一方面，WebRTC 理解起来要复杂一些，有很多移动部件，API 也没那么简单。虽然你在新的 OpenAI 产品中做得很棒，提供了非常清晰的 API，但总的来说，如果我向人们推荐 WebRTC，他们会感到有点不知所措。</p><p>但是，正如你刚才所说，<strong>所有你难以自己构建的东西都已经包含在 WebRTC 中了</strong>。所以我通常告诉别人，如果你只是在做实验，为自己构建一些东西，或者做服务器到服务器的应用，那么 WebSockets 就足够了。但是，<strong>如果你真的想构建一个通过互联网连接浏览器或移动应用的东西，考虑到终端用户互联网连接的各种不可预测性，那么你绝对应该花时间了解 WebRTC，并使用它。</strong> 否则，你最终会痛苦地发现你必须迁移到 WebRTC。</p><p><strong>Sean：</strong> 我觉得很遗憾，<strong>许多人创造了令人惊艳的技术成果，但在需要添加多个视频轨道时，问题便接踵而至</strong>。他们最初可能依赖于简单的 WebSocket 协议，仅支持单一视频缓冲区，而现在却不得不将其拆分，以支持多种语言、添加和删除轨道等复杂功能。此时，WebRTC 的复杂性开始展现其价值。这正是我创作《WebRTC for the Curious》的原因。我发现很多人初次接触 WebRTC 时备受挫折，因为它看似繁琐且令人望而却步。然而，<strong>当你深入理解它之后，你会逐渐欣赏那些最初让你感到沮丧的设计</strong>。</p><p>WebRTC 堪称一个伟大的折衷方案，<strong>它在满足各方需求之间取得了平衡，从而使开发者能够继续创新</strong>。人们利用 WebRTC 构建 VPN、安全摄像头和广播系统，应用广泛。尽管许多人对 WebRTC 略有不满，因为它的功能过于强大，但对于某些公司而言，WebRTC 的某些特性却是其生存的基石。</p><p>我个人认为我无法设计出一个比 WebRTC 更好的协议。它凝聚了多年实践经验的结晶，而非简单的「委员会设计」。很多人看到 WebRTC 的复杂性，就认为它是 2010 年代的委员会设计出的糟糕 API。但实际上，WebRTC 是建立在 2000 年代乃至 90 年代的技术基础之上的，它融合了长达 30 到 40 年的设计和考量。设计者们早已预见并解决了许多问题。<strong>我很难相信我能简单地敲出一个基于 WebSocket 的解决方案，就能与 WebRTC 在所有权衡中相媲美</strong>。</p><p><strong>主持人：</strong> 是的。你是想要 20 毫秒的开放帧时间，还是想要 40 毫秒的开放帧时间？诸如此类。</p><p><strong>Sean：</strong> 没错，还有 H.264 配置文件。我们还没有讨论你需要哪些扩展头来表示视频方向。这些问题没完没了。这就是为什么我喜欢待在这个领域里。</p><h2>WHIP 协议：简化 WebRTC，拥抱嵌入式与互操作性</h2><p><strong>主持人：</strong>我对 OpenAI API 中新的 WebRTC 设计持有一些怀疑态度。它构建在 WebRTC 协议栈的一些较新的扩展之上。你想谈谈 WHIP 以及你是如何考虑它的吗？</p><p><strong>Sean：</strong> 在传统的 WebRTC 架构中，Offer 和 Answer 作为信息块存在，<strong>协议本身并不限定其传输方式</strong>。例如，可以通过 WebSocket、Protobuf 或基于 IP 的 Avro 协议来传递这些信息，只要能成功完成传输即可。而新的 WHIP 标准则强制规定 Offer 和 Answer 的交换必须通过 HTTP 协议进行，并采用特定的 URL 格式，同时需要发送带有 Bearer 令牌的 HTTP 授权头部。<strong>实际上，WHIP 严格限制了 Offer 和 Answer 的交换方式。</strong></p><p>这种限制具有重要意义，因为对于像 FFmpeg 和 OBS 这样的工具，用户无法自定义编写代码，只能提供 URL 和输入字段。这正是 WHIP 诞生的原因。我观察到两点：首先，用户希望使用这些工具来访问实时 API，以便发送广播流和安全摄像头数据，而这些工具不支持代码编写。另一方面，WHIP 的设计灵感也来自嵌入式系统。我曾经参与过一个嵌入式项目，该项目使用了一个 WebRTC 服务器，需要两个对等连接和一个 WebSocket，这在微控制器上消耗了大量的资源。因此，<strong>在设计 OpenAI 的 API 时，我希望尽可能保持其简单性，以便支持各种轻量级的客户端</strong>。如果像智能门铃这样的设备，成本仅为 25 美元，却能够发送音频并连接到实时 API，我认为这将是非常有价值的。<strong>WHIP 的设计目标正是为了实现这两点：支持现有的工具，并保持客户端的轻量级。</strong></p><p>另一个让我感到兴奋的点是<strong>不需要使用 SDK</strong>。根据我使用 Pion 的经验，<strong>用户希望在各种不同的环境中使用 WebRTC</strong>。我非常喜欢看到人们使用 Elixir 和 GStreamer 来访问实时 API。如果我要求用户下载包含 500 行专有代码的 JS SDK，并将它移植到各种不同的平台，这无疑会带来巨大的麻烦。但是，如果我们将 API 设计得尽可能简单，用户就可以做更多有趣的事情。</p><p>最后，我非常期待<strong>供应商之间的互操作性</strong>。每个供应商都可以在某个特定领域发挥其优势。例如，可以将视频发送到某个特定供应商，然后供应商可以将视频发送到其他地方。<strong>每个参与者都专注于自己擅长的领域</strong>。如果我们拥有这些简单且标准化的协议，那么对构建者、开发者和用户来说都将是更有利的，因为他们可以轻松地发送和接收 WebRTC 数据，而不必被限制在某个特定供应商的生态系统中。</p><p><strong>主持人：</strong> 您提出的观点都非常有道理，我十分赞同。尤其是在 WebRTC 发展初期，缺乏供应商之间的互操作性是一个显著的问题。<strong>这主要是由于信令层协议的通用性不足，难以适应所有应用场景。</strong> 因此，WebRTC 标准并未对信令进行规定，导致每个开发者都需要从头开始构建信令机制，从而阻碍了不同 WebRTC 平台和工具之间的真正互操作。WHIP 标准在很大程度上解决了这个问题。</p><p>但我必须承认，<strong>SDK 对于封装复杂性至关重要。</strong> 例如，当 RTP 连接中断时，应如何处理？如果将这个问题抛给应用程序员，他们可能会难以找到正确的解决方案。类似的问题还有很多。</p><p><strong>构建一个相对完善的 SDK 是抽象出所有这些复杂问题的必要途径</strong>。然而，大型 SDK 也存在明显的缺点，例如无法在资源有限的嵌入式设备上运行。现在，您已经发布了嵌入式 C 代码，我非常期待能够让我的小型机器人完全支持 WebRTC。</p><p><strong>Sean：</strong> 是的，我认为这反映了我们解决问题思路上的差异。</p><p>您花了很多时间与那些不关心 WebRTC 细节的企业合作，当然这不是贬义。他们的目标是构建出色的产品，而没有精力深入研究技术细节。因此，您对如何构建 SDK 以及如何解决相关问题有着深刻的理解。</p><p>然而，就我而言，无论是通过 WebRTC for the Curious 还是 Pion 项目，<strong>我与用户的交流方式更多的是鼓励他们拥抱细节，并认为细节本身蕴含着价值</strong>。我认为这是我思考方式上的一个固有特点，它有利有弊。我不太愿意将细节从用户面前抽象出来，因为我相信每个人都具备理解这些细节的能力。<strong>我希望提供工具，但对于那些寻求「给我一个 SDK，因为我只想快速完成工作」的开发者，我很难完全理解他们的诉求。</strong> 我相信会有其他人构建出色的 SDK，并以合理的方式抽象出细节。您在 SDK 设计和相关思考方面比我更擅长。事实上，这多年来一直是我在设计产品时面临的一个长期问题。</p><h2>技术深度 vs.易用性，不同的设计哲学**</h2><p><strong>主持人：</strong> 哦，不，我认为这是一个很大的优势。围绕 Pion 构建的生态系统非常出色，正是因为您采取了这种方法，即 <strong>构建模块的粒度</strong> 对于希望构建应用的人来说非常有意义，他们不需要从头开始构建，而是可以采用一种合理的方式进行组装。Pion 实现的各个组件非常清晰，没有隐藏过多的细节，阅读这些代码是一种享受。这归功于您，因为您贡献了大量的代码，并且构建了一个拥有活跃互动的健康社区。我认为每个人都应该阅读《WebRTC for the Curious》。</p><p>有趣的是，根据我们的经验，一些最糟糕的客户，从他们遇到困难、占用大量支持时间以及难以扩展的角度来看，恰恰是那些决定调整所有可配置参数的工程团队。这是因为存在一条这样的曲线：你首先让一些东西能够正常工作，然后你就会想，我不喜欢 720p 视频，我想要 1080p 视频。我们现在有很多帮助文档，其中明确指出：「好的，这是缺点。你可以使用 1080p，你可以使用 4K。但是，以下情况将会发生。」</p><p>然而，有些工程师阅读了我们发送给他们的所有信息，却完全不相信这些警告。于是，他们为移动设备上的最终用户配置了 4K 视频。你会觉得不可思议，我们已经明确告知过这种配置行不通。它可能在你的 iPhone Pro 上，在你的光纤连接上运行良好，但对于你的用户来说，这种配置是不可行的，这里的「你的用户」是指超过 60% 的用户。当 40% 的用户遇到问题时，你就无法实现规模化扩展。所以，从我们所针对的不同人群的角度来看，确实存在着不同的需求和紧张关系，这非常有趣。</p><p><strong>Sean：</strong> 是的，我也很喜欢那些用户。我喜欢那些提出独特需求的人。如果有人要投资我所做的任何项目，我都会过度关注那些看似无法产生收益的长尾需求，因为我喜欢那些对新奇事物和细节感兴趣的人，这会让我感到兴奋。这非常有趣，我完全赞同。</p><p>不过，回到您之前提到的，我个人对 Pion 提供的基本构建块感到非常满意。然而，目前有很多服务器都是基于 Pion 构建的，我认为这在一定程度上表明，对于某些用户而言，Pion 仍然不够完善。但我实际上很喜欢这种情况，因为我真正乐于与之交流的人恰恰是那些构建服务器的人。我非常享受这种过程，我喜欢就此进行深入的探讨和交流。</p><p>我现在还在进行另一个名为 Broadcast Box 的项目，这是一个面向终端用户的服务器。每当有人来找我说，他们只是希望一切都能正常运行，甚至不理解背后的原理时，我都会感到有些失落。他们仅仅是希望屏幕上能够显示视频，一旦视频出现，他们就会立即离开。我认为，当大家共同参与构建某些事物时，会存在一种独特的美感，<strong>但当目标仅仅是「我只想让它工作」时，这种美感就会消失</strong>。但我想这只是一段无关紧要的题外话。总而言之，这就是我构建产品的方式，也导致了它们最终呈现出现在的形态。</p><h2>Broadcast Box：低成本、高互动、更安全的 WebRTC 广播的未来</h2><p><strong>主持人：</strong> 我认为人们会很想知道 BroadcastBox 的动机是什么。</p><p><strong>Sean：</strong>是的。Broadcast Box 实际上是用于将 WHIP 集成到 OBS 中的一个参考实现。WebRTC 广播让我感到兴奋的原因是，我感觉广播技术已经落后了大约 10 年，因为技术限制使得我们无法实现很多想法。</p><p>首先，运行广播服务的成本非常高昂。因此，很少有人会尝试这样做。但是，借助 WebRTC 和 Simulcast 技术，我们可以<strong>将编码过程放在客户端，从而大幅降低成本</strong>。其次，WebRTC 的延迟非常低。这意味着当您向观众进行广播时，能够建立一种更亲密的互动关系。您可以拥有一小群朋友，他们观看您的游戏并与您进行交流，而不是向一万名观众进行广播，仅仅是被动地与他们互动。我认为这是一种更好的社交体验。这正是让我感到如此兴奋的原因。</p><p>我也很喜欢 WebRTC 具备<strong>端到端加密的特性</strong>。我希望能够先于某些公司解决一个潜在的问题：我预计将来可能会有一些公司想出办法直接将广告插入到视频流中，从而实现广告的完全无法屏蔽。<strong>我想在他们之前，利用 WebRTC 和端到端加密技术，让内容创作者能够掌握自己的密钥，并将它们提供给观众，从而阻止中间人篡改视频。</strong> 我认为这种方法非常酷。</p><p>此外，<strong>移动性也是一个重要的优势</strong>。WebRTC 的设计允许我在手机上进行广播，并在蜂窝塔之间切换，以及在 Wi-Fi 和蜂窝网络之间无缝切换。这让我感到非常兴奋，因为如果人们能够获得更好的 IRL（In Real Life，现实生活）直播体验，那将会很棒。目前，要实现这一点非常困难。人们需要背着背包，使用故障转移机制，将 RTMP 数据发送到服务器，然后服务器负责确保连接的稳定性。<strong>如果他们只是使用一种没有硬连接的协议，所有这些问题都会迎刃而解</strong>。</p><p>因此，我总是鼓励大家，如果有人问我对广播的未来有什么看法，我希望它能够朝着这个方向发展。</p><h2>WebRTC 的多重挑战：延迟挑战、Google 主导与开源抉择</h2><p><strong>主持人：</strong> 关于这些协议的演变，您提出了一个非常有趣的观点。RTMP 仍然是 Twitch 和 YouTube Live 的标准，但它确实是一个非常古老的协议。它最初是 Macromedia Flash 的视频协议，然后在 JavaScript 出现之前，由于 Flash 曾经短暂地主宰了整个交互式网络，它得到了某种程度的半标准化。但是，Flash 后来被 Adobe 收购，并被整合到那个大型公司实体中。Macromedia 在某种程度上被放弃了。然后，史蒂夫·乔布斯从 Safari 中砍掉了 Flash。因此，这个孤立的协议从未真正得到标准化，也没有任何一方能够真正掌控它。所以，没有人能够对其进行演变。但是，即便已经过去了 20 年，它仍然内置于 OBS 中，并且是所有这些平台的默认设置。虽然它能够正常工作，但正如您所说，<strong>到了 2025 年，我们确实需要更好的替代方案</strong>。</p><p>WebRTC 正是其中的一部分。<strong>我们观察到使用 WebRTC 进行广播的客户所面临的挑战是，它的延迟太低了。</strong> 如果你使用 RTMP、HLS、DASH 或其他视频流协议，那么很难将延迟降低到 3 秒以下。如果你要做任何交互式的事情，这都显得太长了。WebRTC 在某种程度上是因为标准本身，但在某种程度上也是因为所有实现的编写方式，很难将延迟提高到 300 毫秒以上。<strong>这是一个巨大的差距：300 毫秒与 3 秒。</strong></p><p>有时候，你真正需要的可能是 800 毫秒的延迟，因为你可以通过更大的缓冲区来调整视频质量。如果你要做一些交互式的事情，但它实际上并不是实时的对话，那么 800 毫秒的延迟可能就足够了。但目前似乎并没有一种方法能够实现这个目标。您有没有考虑过 <strong>我们如何找到一个中间地带</strong> ？</p><p><strong>Sean：</strong> 至少对于 OBS 来说，我尽量保持 3 秒的缓冲大小。因此，接收方可以积极地请求重传这 3 秒的数据，并且服务器可以在这段时间内进行缓冲。但是，在浏览器中，没有 API 可以实现这一点。我不知道。我认为这正是长期以来困扰 WebRTC 的一个问题。WebRTC 的主要贡献者们主要通过会议协议来盈利。因此，如何说服他们去关注这些边缘用例呢？</p><p><strong>主持人：</strong> 我认为谷歌是 WebRTC 规范的主要仲裁者，这是一件好事，但有时也会令人沮丧。谷歌对 WebRTC 的这种仁慈的资助和控制是绝对关键的。我认为如果没有谷歌，WebRTC 就不会成为一种普遍存在的标准。有时你提交 PR 或错误报告，但当谷歌团队认为它们不够重要或不够有趣时，它们就永远不会被采纳。</p><p><strong>Sean：</strong> 是的，我也不知道哪种方式更好。我经常在开源项目中看到这个问题：是凭借企业赞助者的力量加速你的发展速度更好呢？还是独自前行，做出对每个人都更好的东西更好呢？我不知道。我在编程语言中也看到了这一点。 Rust 和其他一些语言有赞助者，因此它们的发展速度更快，但社区本身却不那么令人愉快。这是一个非常哲学的问题。太有趣了。</p><p>如果我的生活就是 WebRTC 和 Go，那么在某种意义上，我就拥有谷歌公司的一切。我编写的协议和我编写的语言都属于谷歌。我真的应该站出来说几句。谷歌愿意花 3.6 亿美元购买 GIF 是一笔疯狂的金额。所以，总之，WebRTC 的存在是因为谷歌购买了软件并将其开源。是的，我不知道。现在就是这样了。</p><h2>QUIC 与 Media over QUIC：WebRTC 的未来竞争者？</h2><p><strong>主持人：</strong> 你提出的观点非常重要。在我们的这个视频和网络黑客的小世界里，<strong>很多人都认为，超越 WebRTC、找到中间地带、支持更多用例、提高灵活性和创造性的方法是 QUIC 和 Media over QUIC</strong>。</p><p>我经常与那些正在研究如何构建语音 AI 产品的人进行对话。有时他们已经做了一些研究，然后他们会说：「我只是在等待 QUIC。」 我也经常和他们说，<strong>现在我们看到的语音 AI 和对话式多模态 AI 用例与会议用例非常不同</strong>，而会议用例是 WebRTC 的核心和灵魂。WebRTC 在很大程度上满足了这些用例的需求，但我一直在思考，<strong>我们可以重新构建哪些构建块，以便更高效、更灵活、更易于破解，更适合语音 AI 用例</strong>。</p><p>然后，当你将其扩展到「这实际上可能是一个向 Media over QUIC 过渡的催化剂」时，我真的认为，在几年内，我们可能会看到 QUIC 在这些新用例中的采用，而如果没有这些新用例，我们就不会走出那个困境。</p><p><strong>Sean：</strong> Media over QUIC 组织构成多元，包含诸多内容分发网络（CDN）和视频领域从业者。我很好奇最终会如何发展。借鉴以往经验，IETF 工作组虽曾解决诸多重要问题，但最终可能因标准过于复杂而难以实际应用，希望 QUIC 不会重蹈覆辙。</p><p>具体而言，视频内容若过度复杂化，或将导致用户出于效率或兼容性考虑，仍旧选择 WebRTC 等现有方案。 <strong>QUIC 协议的核心机制虽具优势，但与实时性需求存在一定差异。</strong> 因此，要实现真正可用的 Media over QUIC，仍需进行大量工作。我认为这是可能的。 我对标准委员会的部分工作表示赞赏，但也注意到其潜在的发展方向存在风险。CDN 服务商的需求合理且重要，但与实时应用的需求存在显著差异。若 Media over QUIC 的发展方向过度迎合 YouTube 或 Twitch 等大型平台的需求，可能无法满足新兴的对话式人工智能等实时应用场景。 <strong>因此，我期望业界对新兴对话式 AI 用例保持足够的热情，以平衡 CDN 需求对标准发展方向的影响。</strong></p><p>进一步的问题在于，新的方案是否能够满足所有基于 WebRTC 的现有应用场景，例如安全摄像头监控和远程监考等。特别是远程监考，我曾经在 AWS 工作时发现，这是一个规模庞大的业务。 很多人可能认为 WebRTC 主要用于会议，但远程考试的使用频率可能远超会议，因为它几乎时刻都在进行。远程监考需要监考人员观看考生的视频，并且通常需要同时开启多个摄像头，例如拍摄手部和房间环境。 总之，<strong>WebRTC 的实际应用范围可能远超我们的想象，甚至最活跃或最流行的用例可能正是我们习以为常却未曾注意到的领域。</strong></p><h2>意想不到的 WebRTC 用例：从远程监考到在线拍卖**</h2><p><strong>主持人：</strong> 有趣的是，远程监考是最早尝试引入 AI 技术的领域之一。与当前流行的生成式 AI 对话技术不同，他们主要利用计算机视觉算法、语音匹配算法、面部检测和视线跟踪等技术，来检测考生是否作弊。 远程监考本身就是一场猫鼠游戏，因为学生们会不断寻找新的作弊方法。这些公司告诉我，雇佣一名人工监考人员的成本很高，而运行 AI 算法的成本相对较低。 这种成本对比凸显了远程监考领域中 AI 应用的独特价值。</p><p>另一个令我印象深刻的用例是澳大利亚一家公司利用 WebRTC 进行牛的竞拍。他们对延迟的要求极为苛刻，必须达到 7 毫秒，因为任何视频流延迟都可能导致竞拍失败，从而造成损失。</p><p><strong>主持人：</strong> 是的。我们也有一个这样的客户。当时我就想，我不知道牛的拍卖风险这么高。</p><p><strong>Sean：</strong> 牛的拍卖风险很高，这取决于你竞拍的是什么。</p><h2>SIP 在 AI 时代的复兴</h2><p><strong>主持人：</strong> 这些应用场景非常有趣。我们应该简单谈论一下 SIP，因为我们观察到越来越多的客户认为垂直领域 AI 是真实存在的，例如为医疗机构提供电话接听服务。有很多客户正在从事这方面的工作，并且业务规模还在不断扩大。</p><p>我过去从未想过大型语言模型可以通过电话与人进行对话，并且对各方都有显著的价值。从传输方式的角度来看，<strong>我们目前看到电话技术比 WebRTC 有更多的增长</strong>。您是否也观察到了同样的趋势？ 您之前做过一些与 SIP 相关的工作，它是如何融入到这些场景中的？这对于您来说，是否有点像一次怀旧之旅？</p><p><strong>Sean：</strong> 是的，我之前为 1-800-CHAT-GPT 做过电话相关的工作。 这样做的一个好处是只需要维护一个代码库。因为它们都使用相同的底层协议，所以我能够轻松地将代码迁移到一个公共文件夹中，从而同时支持两种技术。</p><p>我对未来发展方向非常感兴趣。我们现在还在使用的电话技术，例如 SIP，最初是为了与传统电话线路通信而设计的。 但现在一切都已经是数字化的了。所以我们实际上在进行数字信号到模拟信号，再到数字信号的转换。 我认为这非常令人兴奋，因为它为那些不习惯安装应用程序的用户打开了所有这些 AI 体验的大门。这甚至不仅仅是习惯问题，安装和使用应用程序的成本也太高了。 尤其是在很多国家，用户需要为下载应用程序付费。期望用户支付几美元来下载一个几百兆字节的应用程序是不现实的。 直接拨打电话号码就能正常工作，这简直太棒了。</p><h2>AI 电话助手：用 LLM 打造私人秘书</h2><p><strong>主持人：</strong> 我也很喜欢电话互联。 我有一个待办事项机器人，它每天会在固定的时间打电话给我，以确保我按计划行事。它会询问我今天的优先级是什么，以及需要完成哪些任务。然后，我会告诉它我完成了什么，它会检查这些是否与我昨天告诉它的相符。 我喜欢自己构建这些工具，这样才能真正理解它们。 我发现电话通话是一件非常有用的事情。 我可以以不同的方式实现提醒功能，例如发送短信链接，或者使用原生移动应用播放声音并发出警报。<strong>但电话通话有着独特的吸引力，即使对于这种简单的使用场景也是如此</strong>。</p><p><strong>主持人：</strong> 我喜欢 POTS 首字母缩略词，它代表 Plain Old Telephone System。</p><p><strong>Sean：</strong> 没错。</p><p><strong>主持人：</strong> 这是一个很棒的经典缩略词。如果你试图弄清楚如何将 LLM 连接到电话，你还会经常听到 PSTN（Public Switched Telephone Network）这个缩略词。</p><p>现在越来越多的类似技术涌现出来。我现在的理解是，这有点像正则表达式刚出现的时候。早期，对于文本解析，人们总是争论是否应该手写解析器，还是应该编写一个复杂的正则表达式。 两种方式各有优缺点。</p><p>非常感谢你。和你聊天非常开心。</p><p><strong>Sean：</strong> 我也很开心。</p><p>原播客：<a href="https://link.segmentfault.com/?enc=BEwWsqoGBgXAaeJSSTl%2FFQ%3D%3D.yDRB1yccVjDu5krg7xo6bcFDEYzAXmXeMVyCPaAvHBWWZzLUNRM8D3S8iu4FP9Zo" rel="nofollow" target="_blank">https://www.youtube.com/watch?v=l_rTdVuA4Lw</a></p><p>编译：施苏娜、傅丰元</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438148" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047438149" alt="" title="" loading="lazy"/></p><p><a href="https://link.segmentfault.com/?enc=g5XsGF1CVjAJqwijJ79dMA%3D%3D.zwVSgBcr631rpCZ0AG9MzX4A7bOzXNwReDXoQYomXCs%3D" rel="nofollow" target="_blank">阅读更多 Voice Agent 学习笔记：了解最懂 AI 语音的头脑都在思考什么</a></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438150" alt="图片" title="图片" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[FFmpeg开发笔记（八十九）基于FFm]]></title>    <link>https://segmentfault.com/a/1190000047438166</link>    <guid>https://segmentfault.com/a/1190000047438166</guid>    <pubDate>2025-11-29 17:03:03</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>​随着推拉流技术的发展，现在网络直播应用很普及了，打开许多App都能看到各式各样的直播节目，包括抖音、快手、虎牙、斗鱼、B站、小红书、YY、映客等等。</p><p>有关视频推拉流的FFmpeg实现参见《FFmpeg开发实战：从零基础到短视频上线》一书的“10.2  FFmpeg推流和拉流”，使用FFmpeg结合专用的流媒体服务器，可以很方便地实现视频直播功能。不过常规的拉流操作仅能实现播放功能，未能实现存储功能。如果事后还想回看以前的直播视频，就得引入直播录制功能了。  <br/>StreamCap正是一个开源的国产直播流录制工具，它基于FFmpeg和StreamGet设计，覆盖40余个国内外主流直播平台，支持批量录制、循环监控、定时监控和自动转码等功能。StreamCap支持跨平台，能够在Windows/MacOS/Web上运行，并支持ts、flv、mkv、mov、mp4、mp3、m4a等常见格式，录制完成后会自动转码为mp4格式。  <br/>StreamCap的源码托管地址为 <a href="https://link.segmentfault.com/?enc=GzanViSklrYc%2Fxqn5jAeFg%3D%3D.eKOSJs9WbcS6SoNJ3xdLpNlp8p6SGwrHs4LGmvF8Xw5IjsHMqwKR23Bg2Ms9FNoU" rel="nofollow" target="_blank">https://github.com/ihmily/StreamCap</a> （星星数2.4k），国内的镜像地址为 <a href="https://link.segmentfault.com/?enc=c3YotTWskKoY5a2aTPVNhA%3D%3D.1J6qwulSriqSoe1VJ6zC4Hl%2FQIDgdgormiTknb6cm8gjYY2H0WQLyubgX%2BepSkJt" rel="nofollow" target="_blank">https://gitcode.com/gh_mirrors/st/StreamCap</a> 。最新版本是2025年8月发布的v1.0.2，可见该框架的源码更新十分及时，该版本的源码下载链接为 <a href="https://link.segmentfault.com/?enc=SG7YZr9Gwvr%2FOVvPsPFp9Q%3D%3D.3N5CKFpD5mtYR79RFpdlR%2Bm2TBK4UzpoCJns8pN7QbE%2FUKtLfxxmK9fQOw3osddgP%2BjyoA9SVgVO4OkKr6gdnCuu3uUhhDA9LZpQuHsdnYk%3D" rel="nofollow" target="_blank">https://github.com/ihmily/StreamCap/archive/refs/tags/v1.0.2.tar.gz</a> 。  <br/>StreamCap基于Python 3.10开发，从源代码运行的话，需要在源码目录运行下面命令安装依赖包：</p><pre><code># 安装核心依赖
pip install -i https://pypi.org/simple streamget 
# 桌面端
pip install -r requirements.txt
# Web端
pip install -r requirements-web.txt</code></pre><p>接着执行下面命令，将示例的配置文件.env.example复制一份，并将新文件重命名为.env：</p><pre><code>cp .env.example .env</code></pre><p>若在Windows和macOS运行上StreamCap，则通过以下命令启动程序界面：</p><pre><code>python main.py</code></pre><p>启动成功后打开的StreamCap初始界面如下图所示：</p><p><img width="723" height="476" referrerpolicy="no-referrer" src="/img/bVdm8GM" alt="" title=""/></p><p>单击界面右边的【开始录制】按钮，打开下图所示的配置界面：</p><p><img width="723" height="476" referrerpolicy="no-referrer" src="/img/bVdm8GN" alt="" title="" loading="lazy"/></p><p>在配置界面的直播间地址栏输入直播链接，然后单击右下角的【确定】按钮，跳到正在录制界面如下图所示：</p><p><img width="723" height="476" referrerpolicy="no-referrer" src="/img/bVdm8GO" alt="" title="" loading="lazy"/></p><p>正在录制界面实时提示当前录制进度，也支持停止录制，录制好的视频默认保存在StreamCap的downloads/Custom/CustomLive目录下。</p><p>单击StreamCap左上角的【设置】按钮，打开如下图所示的设置界面。</p><p><img width="723" height="476" referrerpolicy="no-referrer" src="/img/bVdm8GQ" alt="" title="" loading="lazy"/></p><p>在设置界面支持修改包含基础设置、代理设置在内的录制选项，也支持修改推送设置、Cookie设置、账号设置等配置信息，方便用户个性化定制直播录制信息。</p><p>更多详细的FFmpeg开发知识参见<a href="https://link.segmentfault.com/?enc=OeEroSY1WyLiERJFhaXHuA%3D%3D.VB48GxdEWusNXatlR%2FMnMGzooSCfBIxCLMd4%2FPqSMcA%2B0P4b5%2Flw4Ssaa6d6yimm" rel="nofollow" title="《FFmpeg开发实战：从零基础到短视频上线》" target="_blank">《FFmpeg开发实战：从零基础到短视频上线》</a>一书。</p><p>​</p>]]></description></item><item>    <title><![CDATA[2025年CSS新特性大盘点 沉浸式趣谈]]></title>    <link>https://segmentfault.com/a/1190000047438172</link>    <guid>https://segmentfault.com/a/1190000047438172</guid>    <pubDate>2025-11-29 17:02:21</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>大家好，我是 Immerse，一名独立开发者、内容创作者、AGI 实践者。</p><p>关注公众号：<a href="https://link.segmentfault.com/?enc=pW%2B1n2KcV1AYQDO3OKD2%2BA%3D%3D.MYDMXDl6IuBWsP9ErunIKby1MJJpzfvRQQbFDGsuWkWqXOKOubVBOjKFuQ2VUC3TZ9uacb5b%2FvnmSf%2FpHJo9sg%3D%3D" rel="nofollow" target="_blank">沉浸式趣谈</a>，获取最新文章（更多内容只在公众号更新）</p><p>个人网站：<a href="https://link.segmentfault.com/?enc=ha273OYTfjavWxkicsmNlA%3D%3D.SUpjim7T1CJ4%2FoMzBwAZXDXGE%2B7EEINZuKkMi%2BnsOtI%3D" rel="nofollow" target="_blank">https://yaolifeng.com</a> 也同步更新。</p><p>转载请在文章开头注明出处和版权信息。</p><p>我会在这里分享关于<code>编程</code>、<code>独立开发</code>、<code>AI干货</code>、<code>开源</code>、<code>个人思考</code>等内容。</p><p>如果本文对您有所帮助，欢迎动动小手指一键三连(<code>点赞</code>、<code>评论</code>、<code>转发</code>)，给我一些支持和鼓励，谢谢！</p><hr/><p>2025年了，CSS又进化了</p><p>去年写过一篇 CSS 新特性盘点，本来以为今年不会有太大变化。结果一看，新东西比去年还多。</p><p>这次整理了几个我觉得特别实用的功能，浏览器支持也都不错，可以用起来了。</p><h2>终于可以动画到 auto 了</h2><p>之前我们做高度展开动画，基本都是靠 max-height 硬撑。</p><p>比如从 0 展开到实际高度，只能写个超大的值，体验很差。</p><p>现在可以直接动画到 auto 了：</p><pre><code class="css">html {
  interpolate-size: allow-keywords;
}</code></pre><p>加上这一行，所有 height: 0 到 height: auto 的过渡都能生效。</p><p>或者你也可以用 calc-size() 函数，不需要全局设置：</p><pre><code class="css">.content {
  height: 3lh;
  overflow: hidden;
  transition: height 0.2s;

  &amp;.expanded {
    height: calc-size(auto, size);
  }
}</code></pre><p>这个功能总算来了。</p><p>而且不只是 height，任何接受尺寸的属性都能用，不只是 auto，min-content 这些关键字也行。</p><p>目前 Chrome 已经支持，其他浏览器应该也快了。</p><h2>Popover 和 Invoker</h2><p>Popover 是个 HTML 属性，给任意元素加上就有开关功能。</p><p>配合 Invoker 用起来更爽，不用写 JavaScript 就能控制弹窗。</p><pre><code class="html">&lt;button commandfor="menu" command="toggle"&gt;
  打开菜单
&lt;/button&gt;

&lt;div id="menu" popover&gt;
  菜单内容
&lt;/div&gt;</code></pre><p>这样就够了，按钮点击自动控制弹窗显示隐藏。</p><p>浏览器会自动处理无障碍访问、键盘操作、焦点管理这些细节。</p><p>而且还能配合 Anchor Positioning 用，让弹窗自动定位到触发元素旁边。</p><p>Popover 已经全浏览器支持，Invoker 目前只有 Chrome，不过有 polyfill 可以用。</p><h2>CSS 里可以写函数了</h2><p>CSS 有 calc()、clamp() 这些内置函数，现在我们可以自己写了：</p><pre><code class="css">@function --titleBuilder(--name) {
  result: var(--name) " is cool.";
}</code></pre><p>然后就能在任何地方调用：</p><pre><code class="css">.title::after {
  content: --titleBuilder("CSS");
}</code></pre><p>这个功能让 CSS 更像编程语言了。</p><p>把复杂逻辑封装到函数里，代码更清爽，也更好维护。</p><p>不过目前只有 Chrome 支持，可以先用着，不支持的浏览器会回退到默认值。</p><h2>if() 函数也来了</h2><p>CSS 本来就有很多条件逻辑，比如选择器匹配、媒体查询。</p><p>但这次的 if() 函数是第一个专门做条件分支的：</p><pre><code class="css">.grid {
  display: grid;
  grid-template-columns:
    if(
      media(max-width &gt; 300px): repeat(2, 1fr);
      media(max-width &gt; 600px): repeat(3, 1fr);
      media(max-width &gt; 900px): repeat(auto-fit, minmax(250px, 1fr));
      else: 1fr;
    );
}</code></pre><p>看起来像不像 switch 语句？第一个匹配的条件会生效。</p><p>条件可以是 media()、supports()、style() 这几种。</p><p>把所有逻辑都写在一个属性里，代码可读性好很多。</p><p>目前 Chrome 独占，其他浏览器还在路上。</p><h2>表单输入框自动调整大小</h2><p>field-sizing 这个属性专门解决表单输入框的问题。</p><pre><code class="css">textarea {
  field-sizing: content;
}</code></pre><p>加上这一行，textarea 会自动根据内容调整高度。</p><p>用户输入多少内容，输入框就有多高，不用手动拖拽了。</p><p>在手机上体验特别好，拖拽调整大小本来就很难操作。</p><p>这个功能之前都是用 JavaScript 实现，现在 CSS 原生支持了。</p><p>Chrome 和 Safari 都能用，Firefox 估计也快了。</p><h2>select 下拉框终于能自定义样式了</h2><p>select 元素的外观一直很难自定义，打开后显示的选项更是完全没法控制。</p><p>现在可以完全自定义了，只要先开启：</p><pre><code class="css">select,
::picker(select) {
  appearance: base-select;
}</code></pre><p>然后想怎么改就怎么改，选项的样式、布局、动画都能控制。</p><p>目前 Chrome 独占，不过不支持的浏览器会回退到原生样式，完全不影响使用。</p><h2>text-wrap 让排版更好看</h2><p>text-wrap: balance 可以让每行文字长度尽量接近：</p><pre><code class="css">h1 {
  text-wrap: balance;
}</code></pre><p>用在标题上效果特别好，不会出现最后一行只有一个词的情况。</p><p>还有个 text-wrap: pretty，专门优化正文排版：</p><pre><code class="css">p {
  text-wrap: pretty;
}</code></pre><p>浏览器会自动调整断行，避免孤词，让文字看起来更舒服。</p><p>balance 已经全浏览器支持，pretty 在 Chrome 和 Safari 能用。</p><p>这种优化对用户体验很重要，而且完全不影响功能，可以直接加上。</p><h2>linear() 实现复杂缓动效果</h2><p>CSS 的 linear 关键字之前就是匀速动画，很无聊。</p><p>但 linear() 函数可以实现超复杂的缓动，比如弹跳效果：</p><pre><code class="css">.bounce {
  animation-timing-function: linear(
    0, 0.004, 0.016, 0.035, 0.063, 0.098, 0.141 13.6%, 0.25, 0.391, 0.563, 0.765,
    1, 0.891 40.9%, 0.848, 0.813, 0.785, 0.766, 0.754, 0.75, 0.754, 0.766, 0.785,
    0.813, 0.848, 0.891 68.2%, 1 72.7%, 0.973, 0.953, 0.941, 0.938, 0.941, 0.953,
    0.973, 1, 0.988, 0.984, 0.988, 1
  );
}</code></pre><p>这种效果用 cubic-bezier() 根本做不出来。</p><p>而且已经全浏览器支持了，可以放心用。</p><p>有在线工具可以生成这些值，不用自己手写。</p><h2>shape() 函数画任意图形</h2><p>CSS 之前有 path() 函数，但语法很难写，而且只能用像素。</p><p>shape() 是专门为 CSS 设计的，支持所有单位和自定义属性：</p><pre><code class="css">.arrow {
  clip-path: shape(
    evenodd from 97.788201% 41.50201%,
    line by -30.839077% -41.50201%,
    curve by -10.419412% 0% with -2.841275% -3.823154% / -7.578137% -3.823154%,
    smooth by 0% 14.020119% with -2.841275% 10.196965%,
    close
  );
}</code></pre><p>可以用在 clip-path 裁剪元素，也能用在 offset-path 做路径动画。</p><p>而且可以响应式调整，配合媒体查询和容器查询都没问题。</p><p>Chrome 和 Safari 已经支持，Firefox 也在开发中。</p><h2>attr() 变强了</h2><p>之前 attr() 只能取字符串，现在可以指定类型了：</p><pre><code class="html">&lt;div data-count="42" data-color="#ff0000"&gt;</code></pre><pre><code class="css">div {
  --count: attr(data-count type(&lt;number&gt;));
  --color: attr(data-color type(&lt;color&gt;));
}</code></pre><p>这样可以直接把 HTML 属性当数字或颜色用，方便多了。</p><p>目前 Chrome 独占，不过对于不支持的浏览器，可以设置回退值。</p><h2>reading-flow 解决 Tab 顺序问题</h2><p>用 Grid 或 Flexbox 重新排列元素后，Tab 键的焦点顺序会乱。</p><p>现在可以用 reading-flow 告诉浏览器按照视觉顺序来：</p><pre><code class="css">.grid {
  reading-flow: grid-rows;
}</code></pre><p>这样焦点就会按照 Grid 的行顺序移动，不会乱跳了。</p><p>Flexbox 用 flex-flow，其他布局也有对应的值。</p><p>这个功能对无障碍访问很重要，不过目前只有 Chrome 支持。</p><p>等其他浏览器跟进之前，最好不要大量重排布局。</p><h2>值得期待的功能</h2><p>还有一些功能在开发中，但还没正式发布：</p><p>Masonry 布局虽然各浏览器实现不同，但在稳步推进。</p><p>Safari 的 random() 函数可以生成随机数，玩起来很有意思。</p><p>margin-trim 可以自动去掉容器边缘元素的外边距，Safari 独占中。</p><p>sibling-index() 和 sibling-count() 函数在 Chrome 能用，做交错动画很方便。</p><p>View Transitions 的 match-element 不用给每个元素起名字了，而且 Firefox 也在开发中。</p><p>还有很多其他功能在路上。</p><h2>别忘了这些已经能用的</h2><p>Container Queries 和 :has() 这些去年的新功能，现在已经全浏览器支持。</p><p>View Transitions、Anchor Positioning、Scroll-Driven Animations 也都在 Safari 上线了。</p><p>dvh 这些视口单位也成为标准了。</p><p>CSS 现在能做的事情越来越多，写起来也越来越顺手。</p><p>参考：<a href="https://link.segmentfault.com/?enc=U8uxykhSyqxL%2Bv%2FORDX%2BDA%3D%3D.TRjS5VkqqMHoIM%2BCIBPKshEXp94H9mctM8rT5%2FKp4srAPjIVSgi1tMIkJT8xva0KegHr5Y5eSFoxwke65pEl0L9Id2jHV4RkRBKNnwrJ6TOdba1%2FI9xUpMzGmoRYcn2j" rel="nofollow" target="_blank">https://frontendmasters.com/blog/what-you-need-to-know-about-...</a></p><h3>其他好文推荐</h3><p><a href="https://link.segmentfault.com/?enc=Sz%2F5MugKIiW1tXBkhCNqKg%3D%3D.OifliJhZuEnh17J6jR9LZL6gnXZkOTMVRk0RiU5Q6vxI3lV9OJ4HIbAAPegAKv7gfen3zgpbn%2BrlfHWFTfBZpg%3D%3D" rel="nofollow" target="_blank">2025 最新！独立开发者穷鬼套餐</a></p><p><a href="https://link.segmentfault.com/?enc=Z6JP9xpKfnKChd78nRpf5w%3D%3D.GDbLgR16s%2FK1JWC8O5NsijHO%2FEqmphhCd1BKaRSAdu%2FzfujCxHwRqB8MH5tKqRMI9D%2FotQeq49bB8149ym%2FjCQ%3D%3D" rel="nofollow" target="_blank">Windows 安装 Claude Code 的新姿势，保姆级教程</a></p><p><a href="https://link.segmentfault.com/?enc=%2F6OpqdhQRcZzFjUboem88g%3D%3D.zPdtIPBnZx%2B0ISF5M01GRGBZA%2Fc1DmMclNA3zXzZM3YtNx3wUbQl%2Fd%2BECnpcgqMKZGmDMN5o%2B%2FkOPpt2wPKASg%3D%3D" rel="nofollow" target="_blank">Claude Code 从入门到精通：最全配置指南和工具推荐</a></p><p><a href="https://link.segmentfault.com/?enc=WC%2FAc4wkU7HdZSohrF8vPA%3D%3D.zOV65klIqfSRzkmgXodyjiAFDDPUeHrG4kZ%2FC3PwrXZtvU6Jke5Ra765LwIPgfJ95Wc%2FiKAckQC3l3IxthFamw%3D%3D" rel="nofollow" target="_blank">Claude Code 终极配置指南：一行命令搞定各种配置</a></p><p><a href="https://link.segmentfault.com/?enc=jvdLVl%2FRc4WEmSzgzxVDsg%3D%3D.o%2FURb1zy3ehyM9ktKip%2FWCe6NhlHLjbVZ4NMdy6g5PfNhl5%2FORtSO6dJUiS0SiBpzVmrrXvEQ52NIsVy2Mmvdg%3D%3D" rel="nofollow" target="_blank">一个配置文件搞定！Claude Code 多模型智能切换</a></p><p><a href="https://link.segmentfault.com/?enc=LSBRIOmhZomSV42d3QOcSg%3D%3D.3II%2BDARgzWSCH0cF%2B08fP5JCTiy7ajipl6IYYpnMWnO%2Fq0Qp3k0o%2B3cFQAI%2BFGfGncEzXEb%2F%2BKiPNrVrBcjZdw%3D%3D" rel="nofollow" target="_blank">这个 361k Star 的项目，一定要收藏！</a></p><p><a href="https://link.segmentfault.com/?enc=L%2F0yaH64O0Scug64idDCmg%3D%3D.MYGjLgm%2BlJOjSfEHXNGf9JSdpyjliBaT6Uw6kUzpYwy3Tq4HQB9HscqpYdXg0ssTcRYVT7HLrvMCQWuoh3ONmw%3D%3D" rel="nofollow" target="_blank">搞定 XLSX 预览？别瞎找了，这几个库（尤其最后一个）真香！</a></p><p><a href="https://link.segmentfault.com/?enc=W5UwYW24TnASdJVeI1L0GA%3D%3D.iEhuwVZ%2FGxN6WSypdV0gEaa0rGT%2Fuhbk0qJRYmVOQZ%2BoqIpd0lZqrVCNIY3JMBM0NR6qYYIjrWr8knGuFr315g%3D%3D" rel="nofollow" target="_blank">【完整汇总】近 5 年 JavaScript 新特性完整总览</a></p><p><a href="https://link.segmentfault.com/?enc=eQac17uOWdz3lGkuqj4BsQ%3D%3D.qEF0vvUYc0jHfPUdhUCDcKL5sKBaSut6sKvEBfZMosnVp4xt0NMUKmZ5pdMUYoaabUfdySk%2FVXw%2BX%2FQeQ6QBug%3D%3D" rel="nofollow" target="_blank">关于 Node，一定要学这个 10+万 Star 项目！</a></p>]]></description></item>  </channel></rss>