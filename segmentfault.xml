<?xml version="1.0" encoding="UTF-8"?><rss version="2.0">  <channel>      <title>SegmentFault - 最近文章</title>      <link>https://segmentfault.com/blogs/newest</link>      <description>SegmentFault 思否</description>      <generator>python segmentfault.py @Pi20</generator>      <item>    <title><![CDATA[今日AI要闻 | 2025年11月17日]]></title>    <link>https://segmentfault.com/a/1190000047404230</link>    <guid>https://segmentfault.com/a/1190000047404230</guid>    <pubDate>2025-11-17 11:10:17</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>1、为诺奖错失OpenAI？揭秘谷歌AI掌门人Hassabis如何在“崇高理想”和商业化竞赛之间押错了一步</p><p>2、<strong>马斯克放话“消灭氛围编程”</strong>：神秘Sherlock Alpha模型现身，听你一句话就能自动写出一整套应用程序</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047404232" alt="" title=""/></p><p>3、Anthropic自曝“90%自动化黑客攻击”遭安全圈群嘲，LeCun怒斥借AI网络安全恐慌搞监管寻租、真实威胁被严重夸大</p><p>4、<strong>美国豪赌AGI大脑、中国深耕具身智能和制造业</strong>：长文勾勒中美押注两种AI终局，从潜在互补走向结构性对抗</p><p>5、NVIDIA财报前夜自曝5000亿美元AI芯片订单，中国寒武纪在制裁阴影下身家暴涨：算力大战在地缘博弈中越烧越猛</p><p>6、从地面园区卷到近地轨道：<strong>科技巨头和初创公司争相把AI数据中心送上太空，用无限太阳能和“零成本散热”对冲能源危机</strong></p><p>7、谷歌Gemini文件搜索一键打包分块、向量库和检索链，开发者再也不用自己搭RAG：RAG被宣判“死刑”，应用生态再度被平台锁喉</p><p>8、Gemini和ChatGPT悄然上线“计划任务”功能，AI开始自己记日程、发邮件、抢名额：从聊天机器人迈向真正自主AI代理的关键一跳</p><p>9、<strong>Altman点赞Kosmos一天干完博士六个月工作</strong>，日本Sakana AI押注“自进化AI科学家”：从读论文到写论文，科研流水线正被AI整体接管</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047404233" alt="" title="" loading="lazy"/></p><p>10、李飞飞最新访谈：<strong>AI不会取代人类岗位而要求自我赋能，世界模型与空间智能将超越大语言模型成机器人技术下一疆域</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047404234" alt="" title="" loading="lazy"/></p><p><strong>汇编：犀牛 查看更多要闻详情：<a href="https://link.segmentfault.com/?enc=g%2F4QjzDm3t1ss%2B7Deu1ppw%3D%3D.egsv%2B60f3O2MxqqHQwRdJR0N75zWYGOhVnl2qeSRnbw%3D" rel="nofollow" target="_blank">https://aiera.com.cn/</a></strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047404235" alt="" title="" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[AI在线客服搭建指南：从“人工智障”到“]]></title>    <link>https://segmentfault.com/a/1190000047404164</link>    <guid>https://segmentfault.com/a/1190000047404164</guid>    <pubDate>2025-11-17 11:09:22</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>做电商运营八年，最让我头疼的就是客服管理。每年双十一，客服团队都要经历一场“炼狱”——重复问题铺天盖地，新员工培训跟不上，夜班客服成本高得吓人。更让人崩溃的是，凌晨两点的客户咨询，往往要等到第二天早上才能回复，流失了多少订单，想想就心疼。</p><p>直到去年，我们开始尝试用PandaWiki搭建AI在线客服系统，才真正解决了这个困扰多年的难题。</p><p><strong>搭建AI客服，核心是打造“知识大脑”</strong></p><p>很多人以为AI客服就是买个现成的机器人，输入几个常见问题就完事了。这种想法大错特错——没有扎实的知识库做支撑，再智能的AI也会变成“人工智障”。<br/><img width="723" height="379" referrerpolicy="no-referrer" src="/img/bVdmF4h" alt="" title=""/></p><p>我们首先用PandaWiki搭建了一个完整的客服知识库。这个过程比想象中简单：</p><p><strong>第一步：知识库内容导入</strong></p><ul><li>本地上传：直接把现有的客服手册、产品资料PDF拖拽上传，系统自动解析</li><li>网页抓取：输入官网、帮助中心等URL，智能提取有用内容</li><li>API接入：对接现有的Confluence、Jira等系统，批量导入历史数据</li></ul><p>我们按照“产品使用”“售后政策”“技术问题”“促销活动”等分类，建立了清晰的知识体系。每个客服新人入职，第一件事就是学习这个知识库，培训时间从原来的两周缩短到三天。</p><p><strong>第二步：AI模型配置</strong><br/>在PandaWiki的管理后台，我们选择了通义千问模型——特别适合中文客服场景。系统还支持Llama3等国际主流模型，满足不同企业的需求。</p><p><strong>第三步：多渠道部署</strong><br/>这才是真正让AI客服发挥价值的关键。PandaWiki支持多种部署方式：</p><p><strong>网页客服机器人</strong><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047404166" alt="" title="" loading="lazy"/></p><p>只需要把系统提供的嵌入代码复制到网站HTML中，右侧就会出现一个智能客服按钮。客户点击后，可以直接输入问题，AI会从知识库中寻找最准确的答案。</p><p><strong>微信集成</strong><br/>对于主要通过微信公众号服务的客户，PandaWiki支持与微信深度集成。客户在公众号里提问，AI客服自动响应，完全不需要人工干预。</p><p><strong>飞书、钉钉对接</strong><br/>内部员工遇到问题，也可以在飞书或钉钉里直接@AI客服，快速获得技术支持。</p><p><strong>实战效果：从“成本中心”到“效率引擎”</strong></p><p>部署PandaWiki AI客服三个月后，我们的客服数据发生了惊人变化：</p><ul><li>常见问题解决率：85%的问题由AI自动回答</li><li>响应时间：从平均2小时缩短到10秒以内</li><li>客服成本：夜班人力减少70%，全年节省人力成本40万</li><li>客户满意度：从82%提升到95%</li></ul><p>最让我惊喜的是，这个系统还具备自我优化能力。AI会记录所有未被准确回答的问题，我们定期补充这些“知识盲区”，让系统越来越智能。</p><p><strong>个性化定制：让AI客服更有“温度”</strong></p><p>很多AI客服系统看起来千篇一律，缺乏品牌特色。PandaWiki在这方面做得相当出色：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047404167" alt="" title="" loading="lazy"/></p><p>我们可以像编辑PPT一样，自由定制客服界面：</p><ul><li>修改Logo和品牌色系，保持视觉统一</li><li>调整对话气泡样式，让交互更友好</li><li>自定义欢迎语和结束语，体现品牌调性</li></ul><p><strong>人机协同：最佳工作模式</strong></p><p>AI客服不是要完全取代人工，而是要与人工客服形成完美配合。我们的工作流程现在是这样的：</p><ol><li>客户提问，AI首先响应</li><li>如果AI无法解决，自动转接人工客服</li><li>人工客服的优质回答，会自动补充到知识库中</li><li>AI学习新知识，下次就能独立回答类似问题</li></ol><p>这种“人带机、机助人”的模式，既保证了服务质量，又大幅提升了效率。</p><p><strong>技术细节：5分钟快速部署</strong></p><p>对于技术团队来说，最关心的是部署复杂度。PandaWiki在这方面做得极其友好：</p><pre><code class="bash"># 一条命令完成部署
bash -c "$(curl -fsSLk https://release.baizhi.cloud/panda-wiki/manager.sh)"</code></pre><p>支持私有化部署，所有数据都在自己服务器上，安全可控。</p><p><strong>适用场景</strong></p><p>如果你正面临以下问题，那么PandaWiki AI客服解决方案值得一试：</p><ul><li>客服团队每天处理大量重复性问题</li><li>夜班、节假日客服成本过高</li><li>新客服培训周期长，上手慢</li><li>客户咨询响应不及时，流失严重</li></ul><p><strong>写在最后</strong></p><p>从“人工智障”到“人工智能”，关键在于是否有一个强大的知识库作为支撑。PandaWiki不仅提供了AI能力，更重要的是提供了一整套知识管理解决方案。</p><p>目前，PandaWiki在GitHub上已经获得6.3K星标，成为国内最受欢迎的开源AI知识库项目之一。如果你也想打造一个7×24小时在线的智能客服系统，现在就是最好的开始时机。</p><p><strong>官方文档</strong>：<a href="https://link.segmentfault.com/?enc=OaHKi541hfhcvzcAyQlONA%3D%3D.H%2FLkZ7wLWAhyobyj%2Fdegf5pMgttLO0g5T72Xvrut6FEUsV7SVSpmOYKEDSIX9jmG" rel="nofollow" target="_blank">https://pandawiki.docs.baizhi.cloud</a><br/><strong>GitHub地址</strong>：<a href="https://link.segmentfault.com/?enc=JEMSANHgi5H60XsDKGVXXQ%3D%3D.c1RcgTZGnvHV%2BWImOJRP8CYq7RkZa1kK2aUbm9%2FdeXLzBHOMvG%2F1LreszkSIDtId" rel="nofollow" target="_blank">https://github.com/chaitin/PandaWiki</a></p><p>在客户服务领域，AI不是要取代人类，而是要解放人类——让客服人员从重复劳动中解脱出来，专注于更有价值的复杂问题处理。这或许就是技术发展的真正意义：不是让人失业，而是让人从事更有创造性的工作。</p>]]></description></item><item>    <title><![CDATA[【URP】Unity[RendererF]]></title>    <link>https://segmentfault.com/a/1190000047404176</link>    <guid>https://segmentfault.com/a/1190000047404176</guid>    <pubDate>2025-11-17 11:08:33</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <blockquote><a href="https://link.segmentfault.com/?enc=v4PC7M1r%2F9iw6LlTC9iUeQ%3D%3D.byrKc4kOtze73Lfx%2FnkVPIOBl3%2BjL2MjhZVGaDWseu4ATF2KmOmdd0empl6W%2F7RlE3Wnze8J6CuZ4RC1YiT1%2BNjT33NbNp9UliuDPBnnBRmZ%2B76OJ03MZciv7tq232rMU4RLZBWqw%2BP39tS6PaLy444Z%2BW4bomvkp2ewErkbSjn85iQhu%2FxrU2K3Q%2BKByKTLFSdQcOaGxRoi%2B4WcHhq0SJJDEoFB3fD8KbZiTMTDMlA%3D" rel="nofollow" target="_blank">【从UnityURP开始探索游戏渲染】</a><strong>专栏-直达</strong></blockquote><p>Screen Space Shadows（屏幕空间阴影）是Unity URP中通过屏幕空间数据实时计算阴影的技术，其核心原理是通过深度/法线信息重建世界坐标后与阴影贴图比较生成阴影。以下是详细分析：</p><h2><strong>技术原理与发展历史</strong></h2><ul><li>‌<strong>基础原理</strong>‌：传统Shadow Mapping需从光源视角生成深度图，再与摄像机视角深度比较。而Screen Space Shadows直接在屏幕空间计算，利用_CameraDepthTexture和_MainLightShadowmapTexture进行深度比较。</li><li><p>‌<strong>技术演进</strong>‌：</p><ul><li>早期采用标准Shadow Mapping存在精度问题</li><li>引入级联阴影（CSM）解决大场景问题</li><li>URP 14+版本通过ScreenSpaceShadowResolvePass实现优化</li></ul></li><li>‌<strong>性能对比</strong>‌：相比传统方案，屏幕空间阴影减少Overdraw但增加Depth Prepass开销。</li></ul><h2>原理</h2><h3><strong>核心原理</strong></h3><ul><li><p>‌<strong>双阶段渲染机制</strong>‌</p><ul><li>‌<strong>深度图生成阶段</strong>‌：从光源视角渲染场景，将最近表面深度值存储到<code>_MainLightShadowmapTexture</code>中</li><li>‌<strong>阴影判定阶段</strong>‌：在摄像机视角渲染时，将像素坐标转换到光源空间，比较当前深度与ShadowMap中的深度值，若当前深度更大则判定为阴影区域</li></ul></li><li><p>‌<strong>级联阴影优化CSM</strong>‌</p><p>通过将视锥体划分为多个层级（如4级），近处使用高分辨率ShadowMap，远处使用低分辨率，平衡性能与精度</p></li></ul><h3><strong>关键实现步骤</strong></h3><ul><li><p>‌<strong>ShadowCaster Pass</strong>‌</p><pre><code class="c">hlsl
Pass {
    Tags {"LightMode"="ShadowCaster"}
    HLSLPROGRAM
    #pragma vertex ShadowPassVertex
    #pragma fragment ShadowPassFragment
    #include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl"
    // 应用深度偏移防止自阴影伪影
    float3 _ShadowBias; // x:DepthBias, y:NormalBias
    ENDHLSL
}</code></pre><p>该Pass专用于生成深度图，通过<code>_ShadowBias</code>参数控制深度偏移</p></li><li><p>‌<strong>光源空间矩阵计算</strong>‌</p><p>构建<code>_MainLightWorldToShadow</code>矩阵，将世界坐标转换到光源裁剪空间：</p><pre><code class="csharp">csharp
Matrix4x4 worldToView = light.transform.worldToLocalMatrix;
Matrix4x4 viewToProj = GL.GetGPUProjectionMatrix(light.projectionMatrix, false);
_MainLightWorldToShadow = viewToProj * worldToView;</code></pre><p>该矩阵用于在着色器中计算阴影坐标</p></li><li><p>‌<strong>阴影采样与混合</strong>‌</p><p>在片元着色器中通过PCF(Percentage Closer Filtering)实现软阴影：</p><pre><code class="c">hlsl
float SampleShadowmap(float4 shadowCoord) {
    float shadow = 0;
    for(int i = 0; i &lt; 4; i++) {
        shadow += SAMPLE_TEXTURE2D_SHADOW(
            _MainLightShadowmapTexture,
            sampler_MainLightShadowmapTexture,
            shadowCoord.xyz + poissonDisk[i] * _ShadowSoftness
        );
    }
    return shadow / 4;
}</code></pre><p>使用泊松圆盘采样实现边缘柔化</p></li></ul><h3><strong>完整URP示例</strong></h3><ul><li><p>ShadowFeature.cs</p><pre><code class="csharp">using UnityEngine.Rendering.Universal;

public class ShadowFeature : ScriptableRendererFeature {
    class ShadowPass : ScriptableRenderPass {
        public override void Execute(ScriptableRenderContext context, ref RenderingData data) {
            // 1. 配置光源参数
            var shadowLight = data.lightData.mainLightIndex;
            if (shadowLight == -1) return;

            // 2. 渲染ShadowMap
            CommandBuffer cmd = CommandBufferPool.Get("ShadowMap");
            context.ExecuteCommandBuffer(cmd);
            CommandBufferPool.Release(cmd);
        }
    }
}</code></pre></li><li><p>ShadowShader.shader</p><pre><code class="c">Shader "Custom/ShadowReceiver" {
    Properties {
        _ShadowStrength("Shadow Strength", Range(0,1)) = 0.5
    }
    SubShader {
        Pass {
            HLSLPROGRAM
            #include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/Lighting.hlsl"
            float _ShadowStrength;

            float4 frag(v2f i) : SV_Target {
                float shadow = MainLightRealtimeShadow(i.shadowCoord);
                return lerp(1, shadow, _ShadowStrength);
            }
            ENDHLSL
        }
    }
}</code></pre></li></ul><h3><strong>参数说明</strong></h3><table><thead><tr><th>参数</th><th>作用</th><th>典型值</th><th>技术原理</th></tr></thead><tbody><tr><td><code>Shadow Distance</code></td><td>阴影最大渲染距离</td><td>50-100</td><td>超出距离后淡出阴影</td></tr><tr><td><code>Cascade Count</code></td><td>级联分层数</td><td>2/4</td><td>动态分配纹理分辨率</td></tr><tr><td><code>Depth Bias</code></td><td>深度偏移量</td><td>0.01-0.1</td><td>防止自阴影伪影</td></tr><tr><td><code>Normal Bias</code></td><td>法线偏移量</td><td>0.5-2.0</td><td>改善尖锐边缘阴影</td></tr></tbody></table><p>该实现结合了URP的<code>ShadowCaster</code>管线与自定义Shader，通过级联阴影和PCF滤波达到平衡性能与质量的效果</p><h2><strong>参数说明与用例</strong></h2><table><thead><tr><th>参数</th><th>说明</th><th>典型值</th></tr></thead><tbody><tr><td>Strength</td><td>阴影浓度</td><td>0.5-1.0</td></tr><tr><td>Bias</td><td>防止自阴影</td><td>0.05-0.2</td></tr><tr><td>Normal Bias</td><td>法线偏移</td><td>0.3-0.7</td></tr><tr><td>Resolution</td><td>精度等级</td><td>High/Very High</td></tr></tbody></table><h2>‌<strong>实际应用场景</strong>‌：</h2><ul><li>‌<strong>动态物体阴影</strong>‌：配合CSM实现高质量移动物体阴影</li><li>‌<strong>性能敏感场景</strong>‌：中低端设备可降低Resolution至Medium</li><li>‌<strong>特效增强</strong>‌：结合Decal系统实现弹孔等动态贴花效果</li></ul><h2><strong>完整配置流程</strong></h2><ul><li>创建Renderer Feature并附加到URP Asset</li><li>编写Shader处理深度比较逻辑</li><li>通过Frame Debugger验证阴影生成阶段</li><li>调整Bias参数消除阴影瑕疵</li></ul><p>关键Shader需包含以下处理：</p><ul><li>深度重建世界坐标</li><li>光源空间坐标转换</li><li>阴影强度插值计算</li></ul><hr/><blockquote><a href="https://link.segmentfault.com/?enc=Cfin2ClsWtsOXOBHX9G61w%3D%3D.zewX2ImJHcuLuq0GKJf%2F8eSqK7DT6luekO4SI7CmOQZkM6U8rr0C0xzhknPUqsRyi3NqMn4JI8RZP51s2u3Ee%2BuC%2FvOohg%2B5Up3er5sqcX6Eos585rSm%2BrOij5gyZBOGencb7gPK9DEE1Gnd8cQSmjnB3%2BXH54M%2BlETKjUBJf%2Fa8dez%2BGUwH%2FsA53xL8MBZwR%2BO3I6Uz2oaKqPa5R%2FHhbbXFu6m%2B0BHjIvwHGbL1z9w%3D" rel="nofollow" target="_blank">【从UnityURP开始探索游戏渲染】</a><strong>专栏-直达</strong><br/>（欢迎<em>点赞留言</em>探讨，更多人加入进来能更加完善这个探索的过程，🙏）</blockquote>]]></description></item><item>    <title><![CDATA[中国 CRM：用户反馈洞察与优势解析 闷]]></title>    <link>https://segmentfault.com/a/1190000047404209</link>    <guid>https://segmentfault.com/a/1190000047404209</guid>    <pubDate>2025-11-17 11:07:48</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>国产 CRM 软件市场近年来发展迅速，概念也在不断演变。自 CRM 概念引入中国以来，经历了多个发展阶段。从最初的知识普及阶段，主要由国外厂商主导，到如今国产 CRM 厂商迅速崛起，不断创新和完善产品功能。<br/>国产 CRM 软件的重要性日益凸显。随着企业对客户管理的重视程度不断提高，CRM 软件成为企业提升运营效率、推动业务发展的重要工具。它不仅能够强化企业各部门之间的协同作业，还能优化业务流程，为企业持续成长注入新的活力。<br/>目前市场上有十款主流国产 CRM 软件，各有特色。销售易CRM专注于企业级营销服一体化CRM平台，服务海内外的大中型企业，发展势头迅猛。Zoho CRM 功能全面，强调连接，本土化做得好。神州云动 CloudCC 致力于大型企业数字化转型，客户群体广泛。金蝶 CRM 适合项目型和客户管理型企业，但在 CRM 产品上投入相对较少。红圈 CRM 是最早推出云端 SaaS 型 CRM 的供应商之一，拥有全面的销售管理功能。友和 CRM、知客 CRM、悟空 CRM 等也在市场上占据一定份额，各自以不同的功能和优势吸引着企业用户。<br/>总之，国产 CRM 软件市场竞争激烈，为企业提供了丰富的选择，助力企业实现更高效的客户关系管理。<br/>二、用户满意度排行榜<br/>（一）Top5 详解<br/>1.销售易 CRM：<br/>1.企业概况：销售易是专注于企业级客户关系管理的营销服一体化CRM软件供应商，在国内拥有较高的知名度和广泛的用户基础。其客户群体涵盖了多个行业的大中型企业。<br/>2.核心优势：具备强大的平台能力，支撑企业复杂多变的业务需求。数据平台和 BI+AI 功能帮助企业更好地沉淀数据资产，释放数据价值。国际化能力突出，建立了海外数据中心，部署了全球网络加速服务，完成了多个国家的相关合规法律认证。<br/>3.适用场景：适用于业务需求复杂、IT 要求标准高的大中型企业，尤其是对国际化业务有需求的企业。<br/>2.悟空 CRM：<br/>1.企业概况：开源 CRM 系统，灵活性高。拥有强大的社区支持，用户可以轻松获取帮助。<br/>2.核心优势：成本效益高，适合中小企业。支持多种部署选项，可根据企业需求进行灵活调整。<br/>3.适用场景：适合预算有限、对功能定制有一定需求的中小企业。<br/>3.金蝶 CRM：<br/>1.企业概况：作为中国领先的企业管理云 SaaS 公司，金蝶在财务管理领域表现卓越，其 CRM 系统也备受市场关注。<br/>2.核心优势：全面管理，提供全面的客户关系管理功能，包括客户信息管理、销售管理、服务管理等。业务智能，具备业务智能分析和报告功能，助力企业精准决策。移动办公，金蝶云平台支持移动办公和远程管理，适应现代企业的灵活工作需求。<br/>3.适用场景：适用于各类规模的企业，特别是需要高度集成和可定制 CRM 系统的大型和中型企业。<br/>4.用友 CRM：<br/>1.企业概况：用友作为数智化建设的领跑者，其 CRM 系统在市场上享有较高声誉。专注于企业管理 / ERP 软件及解决方案，为企业提供全面的客户关系管理功能。<br/>2.核心优势：全生命周期管理，提供客户全生命周期管理、营销活动和费用闭环管理等功能。成熟解决方案，在 ERP 行业深耕较久，拥有较为成熟的解决方案。多模块整合，支持多渠道沟通整合，实现客户关系全景透视。<br/>3.适用场景：适合对客户关系管理有较高要求的企业，特别是在供应链管理、财务和人力资源等领域需要集成管理的企业。<br/>（二）选择考量<br/>企业在选择 CRM 系统时，应综合考虑多个因素。首先，要明确自身的业务需求，例如，如果企业需要强大的数据分析功能，那么销售易、金蝶或用友的 CRM 系统可能更适合；如果是中小企业且预算有限，悟空 CRM 则是一个不错的选择。其次，预算限制也是重要因素，不同的 CRM 系统价格差异较大，企业需要根据自身的财务状况进行选择。最后，未来扩展需求也不能忽视，企业应选择具有高度可定制性和强大集成能力的 CRM 系统，以便随着业务的发展进行扩展和升级。总之，企业在选择 CRM 系统时，应充分考虑业务需求、预算限制及未来扩展需求，做出最适合自己的选择。<br/>三、国产 CRM 优势<br/>（一）本地化服务<br/>国产 CRM 系统通常提供更适合中国市场的本地化服务。首先，中文界面和中文客服让国内企业用户在使用过程中沟通无障碍，能更高效地解决问题。其次，符合中国法规的数据处理方式，确保企业数据的安全性和合规性。例如，国产 CRM 系统能够更好地适应国内的数据隐私保护要求，为企业提供放心的数据存储环境。同时，这些系统能够更好地理解国内企业的商业习惯和需求，提供更加贴合实际的解决方案，如针对国内节假日设置特殊的营销活动提醒等功能。<br/>（二）成本效益<br/>相较于国际品牌，国产 CRM 系统的价格更为亲民。一方面，国产 CRM 系统提供了灵活的定价策略，企业可以根据自身需求和预算选择合适的产品版本，降低了使用成本。例如，一些国产 CRM 系统针对不同规模的企业推出了不同的套餐，满足了中小企业的预算需求。另一方面，在后续的服务和支持方面，国产 CRM 系统也更具优势，避免了企业因需要获取更多的功能和优质服务而承担高价格的风险。<br/>（三）快速响应和迭代<br/>国产 CRM 供应商能够更快地响应市场变化和用户需求，进行产品迭代和功能升级。由于更贴近国内市场，国产 CRM 厂商能够及时了解国内企业的需求变化，迅速调整产品策略。例如，当国内企业对移动办公的需求增加时，国产 CRM 厂商迅速推出了功能强大的移动端应用，满足企业移动化的需求。同时，频繁的产品迭代也确保了企业始终能够使用到最新的功能和技术，提升企业的竞争力。<br/>（四）高度可定制性<br/>国产 CRM 系统通常具备高度的可定制性，支持企业根据自身业务需求进行快速定制和调整。以纷享销客为例，其支持低代码功能扩展，企业可根据自身需求快速定制系统。企业可以根据自身的业务流程和管理模式，对 CRM 系统进行个性化设置，使其更好地适应企业的实际情况。这种高度可定制性使得国产 CRM 系统能够满足不同行业、不同规模企业的多样化需求。<br/>（五）强大集成能力<br/>多数国产 CRM 系统具备强大的集成能力，能够与企业现有的 ERP、SCM 等系统无缝集成。例如，金蝶 CRM 可以与金蝶的财务管理系统深度集成，实现数据的互通共享，提升企业管理效率。国产 CRM 系统的集成能力使得企业能够构建一个完整的企业管理生态系统，实现各部门之间的数据流通和协同作业，为企业的数字化转型提供有力支持。<br/>（六）政策支持<br/>在数字经济和信创政策的推动下，国产 CRM 系统得到了更多的政策支持和市场机会。政策的支持促使国产 CRM 厂商加大研发投入，提升产品质量和服务水平。同时，政策也鼓励国内企业优先选择国产软件，为国产 CRM 系统的发展创造了良好的市场环境。例如，根据国资委信创文件，CRM 在央国企的信创改造工作中被定位为 “应替就替” 的软件，这为国产 CRM 厂商打开了广阔的市场空间。<br/>四、综合评价与展望<br/>（一）困境分析<br/>国产 CRM 虽然在近年来取得了显著的发展，但仍然面临着一些困境。首先，市场竞争激烈，产品同质化现象较为严重。许多国产 CRM 系统在功能和服务上较为相似，缺乏独特的竞争优势，这使得企业在选择时难以区分。其次，部分国产 CRM 系统的用户体验还有待提高。一些系统在操作界面的友好性、响应速度等方面存在不足，影响了用户的使用积极性。此外，数据安全和隐私保护也是一个重要问题。随着企业对数据安全的重视程度不断提高，国产 CRM 系统需要进一步加强数据加密、权限管理等方面的措施，确保客户数据的安全。<br/>（二）用户评价<br/>从用户的反馈来看，国产 CRM 系统在本地化服务、成本效益、快速响应和迭代等方面得到了较高的评价。用户普遍认为，国产 CRM 系统更能满足国内企业的实际需求，提供更加贴心的服务。例如，在中文界面和客服支持方面，用户表示沟通更加顺畅，问题能够得到及时解决。同时，国产 CRM 系统的价格优势也受到了中小企业的欢迎，降低了企业的使用成本。然而，用户也对国产 CRM 系统提出了一些改进的建议。比如，希望进一步提高系统的稳定性和可靠性，加强功能的集成性和协同性，提升用户体验等。<br/>（三）未来展望<br/>展望未来，国产 CRM 系统有着广阔的发展前景。随着人工智能、大数据、云计算等技术的不断发展，国产 CRM 系统将不断创新和完善，为企业提供更加智能化、个性化的服务。例如，通过人工智能技术实现客户需求的精准预测、智能推荐等功能，提高销售效率和客户满意度。同时，随着企业数字化转型的加速，国产 CRM 系统将更加注重与其他企业管理系统的集成，实现数据的互通共享，为企业提供一站式的解决方案。此外，随着政策的支持和市场需求的增长，国产 CRM 系统将不断拓展市场空间，提升品牌影响力，走向更加成熟和完善的发展道路。<br/>（四）选择重要性<br/>在选择 CRM 系统时，企业需要充分考虑自身的业务需求、预算限制、未来扩展需求等因素。不同的企业在客户管理、销售流程、服务要求等方面存在差异，因此需要选择适合自己的 CRM 系统。同时，企业还需要关注 CRM 系统的功能、易用性、安全性、可定制性等方面，确保系统能够为企业带来实际的价值。选择适合的国产 CRM 系统，不仅可以提高企业的运营效率和管理水平，还可以为企业的数字化转型提供有力支持，实现企业的可持续发展。</p>]]></description></item><item>    <title><![CDATA[销售团队必藏：CRM销售跟进系统，解决客]]></title>    <link>https://segmentfault.com/a/1190000047404216</link>    <guid>https://segmentfault.com/a/1190000047404216</guid>    <pubDate>2025-11-17 11:06:57</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>凌晨1点，销售小李还在翻微信聊天记录——上午的抖音线索没来得及备注，下午的地推客户信息散在Excel里，上周跟进的大客户突然说“再考虑考虑”，可他根本想不起来上次沟通的重点是价格还是交付周期。</p><p>这不是个例。根据《2024年销售效率调研》，<strong>72%的销售团队因“线索分散”“跟进不及时”“数据断层”导致客户流失率超过30%</strong> ；而用专业销售跟进系统的团队，线索转化率能提升45%，客户复购率提高28%。</p><p>销售跟进的本质，是“用系统替代人工记忆，用数据驱动精准动作”。本文梳理了销售团队最需要的8个核心销售跟进系统，从线索获取到复购挖掘，帮你拆解每个系统的价值、选型要点，彻底解决客户管理的“混乱病”。</p><h2>一、先搞懂：销售跟进的核心痛点是什么？</h2><p>在讲系统前，先对齐<strong>销售跟进的3大底层矛盾</strong>：</p><ul><li><strong>线索分散</strong>：百度广告、抖音表单、微信社群、地推二维码——线索散在10个工具里，漏跟进是常态；</li><li><strong>跟进无章法</strong>：新人不知道“第一次跟进该问什么”，老人靠经验判断，客户需求记混、跟进节奏混乱；</li><li><strong>数据断层</strong>：客户的互动记录（比如打开过报价单、投诉过产品）散在微信、电话、Excel里，销售接手时“一脸懵”。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047404218" alt="" title=""/></p><p>专业的销售跟进系统，本质是<strong>把“碎片化的客户信息”和“经验化的跟进动作”变成“可复制、可追溯的系统能力”</strong> 。</p><h2>二、CRM销售跟进系统，逐个拆解价值与选型要点</h2><h3>1. 线索全渠道聚合：解决“线索漏接、重复录入”问题</h3><p><strong>什么是线索全渠道聚合？</strong> 把百度、抖音、微信、官网、地推/会销、工商搜客等所有渠道的线索，自动抓取、整合到一个系统里，避免“线索散在10个地方”的混乱。</p><p><strong>解决的痛点</strong>：</p><ul><li>百度广告的表单数据要手动复制到Excel，容易漏；</li><li>抖音线索的手机号没带归属地，不知道客户是本地还是外地；</li><li>地推的“扫码表单”数据和微信的“海报线索”重复，导致销售重复跟进。</li></ul><p><strong>选型关键考察点</strong>：</p><ul><li><strong>渠道覆盖能力</strong>：是否支持百度/巨量引擎/微信/小程序/地推二维码等主流渠道？能否自动抓取渠道的注册表单（比如抖音的“留资表单”）？</li><li><strong>重复线索查重</strong>：是否能通过“手机号+客户名”自动识别重复线索？比如同一个客户在百度和微信各留了一次信息，系统会自动合并，避免销售重复跟进；</li><li><strong>线索自动分配</strong>：是否能按“区域/行业/销售能力”自动分配线索？比如把“广州的制造业客户”分配给负责华南区的销售小张。</li></ul><p><strong>案例</strong>：某工贸企业用线索聚合系统后，<strong>线索漏跟进率从25%降到3%</strong> ——百度的表单自动导入系统，地推的扫码数据直接关联到销售的专属二维码，再也没出现“线索躺在微信里忘了加”的情况。</p><h3>2. 客户画像与分层管理：解决“跟进没重点、客户分不清”问题</h3><p><strong>什么是客户画像与分层？</strong> 用“静态属性+动态行为”给客户打标签，比如“深圳，制造业，100人规模，上月打开过3次报价单，关注‘交付周期’”，让销售一眼看懂“这个客户值不值得重点跟进”。</p><p><strong>解决的痛点</strong>：</p><ul><li>销售跟进时问“你们公司做什么的？”，客户觉得“你根本没做功课”；</li><li>把“只问过价格的小客户”和“签过100万订单的老客户”放在同一列表里，精力分配不均；</li><li>客户的需求点（比如“要定制化功能”）记在笔记本上，换销售接手时全丢了。</li></ul><p><strong>选型关键考察点</strong>：</p><ul><li><strong>画像维度的灵活性</strong>：是否支持自定义“行业/规模/采购频率”等字段？能否自动补全工商信息（比如天眼查的“成立时间/注册资本”）？</li><li><strong>行为轨迹整合</strong>：是否能追踪客户的“动态行为”？比如客户打开过报价单、点击过“产品参数”链接、在小程序里咨询过售后，这些都要自动同步到客户画像里；</li><li><strong>客户分层规则</strong>：是否能按“成交概率”（比如“高价值客户”“待跟进客户”“流失客户”）自动分层？比如用“RFM模型”（最近一次购买时间、购买频率、购买金额）划分老客户的复购优先级。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047404219" alt="" title="" loading="lazy"/></p><p><strong>案例</strong>：某设备销售公司用客户画像系统后，<strong>重点客户跟进转化率提升35%</strong> ——销售跟进前能看到“客户是东莞的电子厂，上月问过‘设备能耗’，之前买过2台小型设备”，直接切入“能耗优化方案”，客户觉得“你懂我的需求”。</p><h3>3. 跟进流程自动化：解决“跟进不及时、动作漏做”问题</h3><p><strong>什么是跟进流程自动化？</strong> 把“跟进动作”变成“可触发的规则”，比如“线索分配后1小时内提醒销售跟进”“客户3天没互动自动发待办”“成交后自动触发‘售后回访’任务”。</p><p><strong>解决的痛点</strong>：</p><ul><li>销售忙起来忘了“明天要跟进王总”，等想起时客户已经找了竞品；</li><li>新人不知道“第一次跟进该做什么”，要么问太多要么问太少；</li><li>客户说“下周给回复”，但销售根本没记在日程里，过了半个月才想起。</li></ul><p><strong>选型关键考察点</strong>：</p><ul><li><strong>工作流的自定义能力</strong>：是否能设置“如果客户3天没跟进→自动发微信提醒销售”“如果客户回复‘价格太高’→自动推送‘优惠政策’话术”？</li><li><strong>多端提醒触达</strong>：是否能通过“App推送+短信+微信”提醒销售？比如销售在外面跑客户，App弹出“请跟进李总，他昨天打开了报价单”；</li><li><strong>跟进模板的可复制性</strong>：是否有“行业通用话术库”？比如“第一次跟进制造业客户的话术”“应对价格异议的话术”，新人能直接用，不用自己琢磨。</li></ul><p><strong>案例</strong>：某软件公司用自动化流程后，<strong>跟进及时率从60%提升到95%</strong> ——线索分配后，系统自动给销售发App提醒，跟进到“需求确认”阶段时，自动弹出“请发送产品demo链接”的待办，再也没出现“忘了给客户发资料”的情况。</p><h3>4. 客户互动轨迹追踪：解决“不知道客户在想什么”问题</h3><p><strong>什么是客户互动轨迹？</strong> 记录客户和企业的每一次互动：比如“2024-05-03 09:30 微信咨询‘售后质保’”“2024-05-05 16:00 电话沟通‘交货期’”，询价报价节点时间详细记录到客户视图。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047404220" alt="" title="" loading="lazy"/></p><p><strong>解决的痛点</strong>：</p><ul><li>客户说“我上周问过售后”，销售说“我没看到”，客户觉得“你根本不重视我”；</li><li>客户打开过报价单但没回复，销售不知道“他是觉得价格高还是没看懂”；</li><li>换销售跟进时，新销售要翻半天聊天记录才知道“之前聊到哪了”。</li></ul><p><strong>选型关键考察点</strong>：</p><ul><li><strong>互动渠道的覆盖</strong>：是否能追踪“微信/电话/邮件/小程序/官网”的互动？比如客户在小程序里“收藏了产品A”，系统会自动记到客户轨迹里；</li><li><strong>轨迹的实时性</strong>：是否能实时更新客户的互动记录？比如客户刚打开报价单，销售的App里立刻显示“客户正在查看报价单”；</li><li><strong>轨迹的可视化</strong>：是否能把互动记录做成“时间线”？比如客户的轨迹是“留资→打开报价单→咨询售后→沉默3天→再次打开报价单”，销售一眼就能看出“客户在犹豫售后问题”。</li></ul><p><strong>案例</strong>：某消费品公司用轨迹追踪系统后，<strong>客户满意度提升22%</strong> ——销售跟进时能说“您上周问的售后质保是1年，我给您申请了延长到18个月”，客户惊讶“你居然记得！”，成交率自然高。</p><h3>5. 团队协作与权限管理：解决“信息不同步、责任分不清”问题</h3><p><strong>什么是团队协作？</strong> 让销售、经理、客服在同一个系统里协作：比如销售跟进时遇到“价格权限”问题，能直接@经理审批；客服处理客户投诉时，能看到销售之前的跟进记录；经理能实时看团队的“跟进进度”“线索转化率”。</p><p><strong>解决的痛点</strong>：</p><ul><li>销售小张跟进的客户要申请折扣，得打电话给经理，经理在外面跑客户，半天没回复；</li><li>客服接到客户投诉“产品质量问题”，但不知道销售之前有没有提过“客户要求定制化”；</li><li>经理想看看“这个月的线索转化率”，得让销售统计Excel，半天才能拿到数据。</li></ul><p><strong>选型关键考察点</strong>：</p><ul><li><strong>权限分级管理</strong>：是否能按“角色”设置权限？比如销售只能看自己的客户，经理能看团队的客户，客服只能看“售后相关的客户记录”；</li><li><strong>实时协作功能</strong>：是否支持“@提及”“评论回复”“文件共享”？比如销售在客户档案里@经理“请审批这个折扣”，经理在App里直接点“同意”；</li><li><strong>数据可视化仪表盘</strong>：是否有“团队跟进进度”的大屏？比如经理能看到“今天有15条新线索，8条已经跟进，7条待跟进”，实时调整团队的工作重点。</li></ul><p><strong>案例</strong>：某销售团队用协作系统后，<strong>审批效率提升50%</strong> ——销售的折扣申请直接在系统里@经理，经理在地铁上就能审批，再也没出现“客户等了半天没回复”的情况。</p><h3>6. 数据驱动的跟进策略：解决“靠经验跟进、效果没保障”问题</h3><p><strong>什么是数据驱动的跟进？</strong> 用“历史数据”指导“当前动作”，比如“过去3个月，‘问过交付周期’的客户，跟进时提‘我们的交付期比同行快3天’，转化率提升20%”；或者“客户沉默超过7天，发送‘专属优惠’的跟进话术，激活率能到35%”。</p><p><strong>解决的痛点</strong>：</p><ul><li>新人跟进全靠“师傅带”，师傅说“要问预算”，他就问“预算多少”，但不知道“为什么要问”；</li><li>老人跟进靠经验，比如“我觉得这个客户能成交”，但数据显示“这类客户的成交率只有10%”；</li><li>跟进策略“一刀切”，对“小客户”和“大客户”用同样的话术，效果差。</li></ul><p><strong>选型关键考察点</strong>：</p><ul><li><strong>数据分析模型</strong>：是否有“线索转化率分析”“跟进周期分析”“话术效果分析”？比如系统能统计“用‘优惠政策’话术的客户，转化率比用‘产品功能’话术高15%”；</li><li><strong>智能跟进建议</strong>：是否能根据客户的“画像+轨迹”自动推荐跟进动作？比如客户“沉默了5天，之前关注价格”，系统推荐“发送‘专属9折优惠’的话术”；</li><li><strong>目标拆解工具</strong>：是否能把“月度目标”拆成“每天要跟进多少线索”“每周要成交多少客户”？比如经理给销售小王定了“月成交10单”的目标，系统会自动算“你每天要跟进8条线索，每周要转化2单”。</li></ul><p><strong>案例</strong>：某B2B企业用数据驱动系统后，<strong>跟进话术的转化率提升28%</strong> ——系统统计发现“问过‘定制化’的客户，跟进时提‘我们有10年定制经验’，转化率最高”，销售都按这个话术来，效果立竿见影。</p><h3>7. 售后与复购挖掘：解决“只做一次生意、客户流失快”问题</h3><p><strong>什么是售后与复购？</strong> 把“售后流程”和“复购挖掘”整合到跟进系统里：比如客户购买后，系统自动提醒销售“3天后回访”；根据“RFM模型”（最近一次购买时间、购买频率、购买金额）识别“高复购潜力客户”，提醒销售跟进。</p><p><strong>解决的痛点</strong>：</p><ul><li>客户买了产品后，销售再也没联系过，直到客户流失才发现；</li><li>老客户的复购需求不知道怎么挖掘，比如“去年买过设备的客户，今年可能需要换配件”，但销售没提醒；</li><li>售后投诉处理慢，客户说“产品坏了”，销售要找客服、找仓库，半天没回复。</li></ul><p><strong>选型关键考察点</strong>：</p><ul><li><strong>售后工单管理</strong>：是否能处理“来店维修”和“上门服务”？比如客户申请“上门维修”，系统自动生成工单，分配给售后工程师，销售能实时看“工单进度”；</li><li><strong>复购预警模型</strong>：是否能通过“RFM分析”识别“即将流失的客户”？比如“6个月没购买的客户”，系统提醒销售“发送‘老客户专属优惠’”；</li><li><strong>客服销售联动</strong>：是否能让客服看到销售的跟进记录？比如客户投诉“产品质量”，客服能看到“销售之前承诺过‘质保1年’”，直接回应“我们会按承诺处理”。</li></ul><p><strong>案例</strong>：某设备公司用复购系统后，<strong>老客户复购率从18%提升到32%</strong> ——系统自动提醒销售“张总去年买的设备，今年该换配件了”，销售跟进时说“给您留了专属配件折扣”，张总立刻下单。</p><h3>8. 集成与自定义扩展：解决“系统不兼容、需求不满足”问题</h3><p><strong>什么是集成与自定义？</strong> 能对接企业已有的工具（比如财务软件、ERP、微信），还能根据企业的“特殊需求”自定义功能，比如“我们是租赁行业，需要‘租赁期限’的字段”“我们要对接柠檬云财务软件”。</p><p><strong>解决的痛点</strong>：</p><ul><li>销售系统里的订单数据要手动导入财务软件，容易错；</li><li>企业的业务是“租售一体”，但系统里没有“租赁期限”的字段；</li><li>系统的功能太固定，不能满足“我们的特殊流程”（比如“先发货再签合同”）。</li></ul><p><strong>选型关键考察点</strong>：</p><ul><li><strong>系统集成能力</strong>：是否能对接“财务软件（柠檬云/金蝶）”“ERP”“微信/企业微信”？比如订单数据能自动同步到财务软件，不用手动录入；</li><li><strong>自定义功能</strong>：是否能自定义“字段/菜单/流程”？比如企业是租赁行业，能在系统里加“租赁期限”“押金金额”的字段；</li><li><strong>低代码扩展</strong>：是否有“低代码工具”？比如企业要加“先发货再签合同”的流程，不用找程序员，自己用低代码工具就能配置。</li></ul><p><strong>案例</strong>：某租赁公司用自定义系统后，<strong>流程效率提升40%</strong> ——系统里加了“租赁期限”“押金”的字段，订单数据自动同步到财务软件，再也没出现“财务算错押金”的情况。</p><h2>三、选型的终极逻辑：“贴合业务+可成长”</h2><p>看完8个系统，你可能会问：“我该选哪个？”其实，<strong>没有“最好的系统”，只有“最贴合你业务的系统”</strong> 。</p><p>给你3个选型的终极建议：</p><ol><li><strong>先抓核心痛点</strong>：如果你的问题是“线索漏跟进”，先选“线索聚合系统”；如果是“跟进没重点”，先选“客户画像系统”；</li><li><strong>测试“最小可用功能”</strong> ：比如你要选“线索聚合系统”，先测试“能否自动抓取抖音的表单”“能否查重重复线索”，这些功能能用，再考虑其他；</li><li><strong>看“长期扩展性”</strong> ：比如你现在是10人团队，未来要扩张到50人，系统能否支持“多区域管理”“分级权限”？现在是“工贸企业”，未来要做“生产制造”，系统能否对接“MES生产系统”？</li></ol><h2>三、12款热门CRM系统对比：从“通用”到“垂直”，覆盖全场景</h2><p>我们筛选了<strong>市场份额TOP10+行业特色系统</strong>，按“通用型、国产中小微、垂直行业、新兴AI型”分类，对比核心维度（注：评分采用5分制，1=极差，5=极佳）：</p><h3>（一）通用型CRM：适合中大型企业，功能全面但成本高</h3><h4>1. Salesforce（全球CRM龙头）</h4><ul><li><strong>基本情况</strong>：成立25年，全球市场份额超19%（Gartner 2023），覆盖科技、金融、制造等行业。</li><li><strong>核心优势</strong>：生态完善（对接Tableau、MuleSoft等）、功能强大（支持多组织、多语言）、AI能力（Einstein智能跟单）。</li><li><strong>适合场景</strong>：中大型跨国企业、需要复杂集成的科技公司。</li><li><strong>不足</strong>：价格昂贵（人均每月≥800元）、学习曲线陡（需专业培训）、国内本地化不足（比如微信/抖音对接需额外开发）。</li><li><strong>评分</strong>：业务匹配度4.5、功能完整性5、易用性3.5、数据能力5、成本2、服务4。</li></ul><h4>2. 微软Dynamics 365（微软生态）</h4><ul><li><strong>基本情况</strong>：依托微软云（Azure），整合CRM与ERP功能，适合微软生态用户。</li><li><strong>核心优势</strong>：与Office 365、Teams深度集成（比如邮件自动同步到客户视图）、多端协同（手机端可编辑Excel报表）、AI功能（Copilot智能写跟进记录）。</li><li><strong>适合场景</strong>：中大型企业、已用微软产品的用户。</li><li><strong>不足</strong>：定制化成本高（需微软认证合作伙伴）、行业针对性弱（比如工业生产模块需额外购买）。</li><li><strong>评分</strong>：业务匹配度4、功能完整性4.5、易用性4、数据能力4.5、成本2.5、服务4。</li></ul><h4>3. Zoho CRM（高性价比通用型）</h4><ul><li><strong>基本情况</strong>：印度厂商，全球150万用户，以“自定义功能”见长。</li><li><strong>核心优势</strong>：低代码定制（自定义字段/工作流/报表）、多渠道支持（微信/抖音/官网线索自动抓取）、价格亲民（人均每月≥100元）。</li><li><strong>适合场景</strong>：中小微企业、需要轻度定制的B2B/B2C企业。</li><li><strong>不足</strong>：工业/生产模块薄弱、国内客服响应较慢（依赖海外团队）。</li><li><strong>评分</strong>：业务匹配度3.5、功能完整性4、易用性4、数据能力3.5、成本4、服务3。</li></ul><h3>（二）国产中小微CRM：更懂国内企业的“接地气需求”</h3><h4>4. 超兔CRM（工业/工贸一体化首选）</h4><ul><li><strong>基本情况</strong>：21年行业经验，服务6万+企业，主打“CRM+进销存+生产MES”一体云。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047404221" alt="" title="" loading="lazy"/></p><ul><li><p><strong>核心优势</strong>：</p><ul><li><strong>业务匹配</strong>：完美覆盖工业/工贸企业的“线索-客户-订单-生产-售后”全流程（比如订单自动触发生产派工、库存短缺自动生成采购计划）；</li><li><strong>低成本定制</strong>：支持“功能白名单订阅”（按需选模块，降低费用）、“三级菜单自定义”（销售/库管/生产岗看不同功能）；</li><li><strong>易用性</strong>：手机端“扫码出入库”“工长报工”“快捷记跟进”，员工学习成本低；</li><li><strong>服务</strong>：40%新客户来自转介绍，客服10分钟内响应。</li></ul></li><li><strong>适合场景</strong>：工业/工贸中小微企业、需要“进销存+生产+CRM”一体化的企业。</li><li><strong>不足</strong>：国际业务功能弱（比如外币汇率支持有限）、零售行业的会员功能需扩展。</li><li><strong>评分</strong>：业务匹配度4.5（工业）、功能完整性4.5、易用性4.5、数据能力4、成本4.5、服务5。</li></ul><h4>5. 纷享销客（协同型CRM）</h4><ul><li><strong>基本情况</strong>：成立11年，主打“销售协同”，适合注重内部协作的企业。</li><li><strong>核心优势</strong>：与钉钉/企业微信深度集成（比如客户跟进记录自动同步到企业微信）、“销售目标拆分”（4倍目标法，帮助团队拆解任务）、“外勤轨迹管理”（实时查看销售位置）。</li><li><strong>适合场景</strong>：中小微企业、需要“销售+行政+客服”协同的企业。</li><li><strong>不足</strong>：工业/生产模块薄弱、定制化能力有限（比如无法自定义生产工单流程）。</li><li><strong>评分</strong>：业务匹配度3.5、功能完整性4、易用性4.5、数据能力3.5、成本4、服务4。</li></ul><h4>6. 销售易（中大型企业的“垂直化CRM”）</h4><ul><li><strong>基本情况</strong>：成立12年，专注中大型企业，覆盖金融、制造、零售等行业。</li><li><strong>核心优势</strong>：行业解决方案（比如制造企业的“设备全生命周期管理”）、多组织权限（支持9级人员结构）、AI功能（智能预测客户成交概率）。</li><li><strong>适合场景</strong>：中大型企业、需要行业深度解决方案的企业。</li><li><strong>不足</strong>：中小微企业成本高（人均每月≥500元）、易用性一般（界面较复杂）。</li><li><strong>评分</strong>：业务匹配度4（中大型）、功能完整性4.5、易用性3.5、数据能力4.5、成本3、服务4。</li></ul><h3>（三）垂直行业CRM：解决“细分领域的精准需求”</h3><h4>7. 管家婆CRM（零售/快消首选）</h4><ul><li><strong>基本情况</strong>：28年零售行业经验，主打“会员管理+库存+电商对接”。</li><li><strong>核心优势</strong>：会员RFM分析（精准推送复购券）、电商平台对接（淘宝/京东订单自动同步）、库存预警（低库存自动提醒补货）。</li><li><strong>适合场景</strong>：零售/快消企业、线下门店+线上微店的“全渠道”企业。</li><li><strong>不足</strong>：工业/生产功能缺失、B2B项目型销售支持弱。</li><li><strong>评分</strong>：业务匹配度5（零售）、功能完整性4、易用性4.5、数据能力3.5、成本4、服务4。</li></ul><h4>8. 金蝶云星空CRM（工贸/制造的“ERP+CRM”）</h4><ul><li><strong>基本情况</strong>：金蝶旗下，依托“云ERP”生态，适合工贸企业的“财务+业务”一体化。</li><li><strong>核心优势</strong>：与金蝶ERP深度集成（财务凭证自动生成）、生产BOM管理（产品结构树可视化）、成本核算（原材料成本+工时成本自动计算）。</li><li><strong>适合场景</strong>：中大型工贸/制造企业、已用金蝶ERP的企业。</li><li><strong>不足</strong>：中小微企业成本高（人均每月≥600元）、易用性一般（需财务知识）。</li><li><strong>评分</strong>：业务匹配度4.5（工贸）、功能完整性4.5、易用性3.5、数据能力4.5、成本3、服务4。</li></ul><h4>9. 钉钉CRM（协同型中小微首选）</h4><ul><li><strong>基本情况</strong>：钉钉生态内的CRM，主打“免费+轻量化”。</li><li><strong>核心优势</strong>：与钉钉深度集成（客户信息自动同步到钉钉好友）、免费基础功能（线索管理、客户跟进）、易用性极高（钉钉用户无需额外学习）。</li><li><strong>适合场景</strong>：中小微企业、用钉钉做内部协同的企业。</li><li><strong>不足</strong>：功能较基础（无生产/进销存）、定制化能力弱（无法自定义工作流）。</li><li><strong>评分</strong>：业务匹配度3、功能完整性3、易用性5、数据能力3、成本5（免费）、服务4。</li></ul><h3>（四）新兴AI型CRM：用技术提升效率</h3><h4>10. HubSpot（AI营销+CRM）</h4><ul><li><strong>基本情况</strong>：美国厂商，主打“ inbound marketing（集客营销）+CRM”，适合注重内容营销的企业。</li><li><strong>核心优势</strong>：AI内容生成（自动写博客/邮件）、线索打分（根据行为数据预测成交概率）、全渠道营销（微信/抖音/官网线索统一管理）。</li><li><strong>适合场景</strong>：B2B服务企业、注重内容营销的中小微企业。</li><li><strong>不足</strong>：国内访问慢（服务器在海外）、功能较单一（无进销存/生产）。</li><li><strong>评分</strong>：业务匹配度3.5、功能完整性3.5、易用性4、数据能力4、成本3.5、服务3.5。</li></ul><h4>11. Pipedrive（销售流程自动化）</h4><ul><li><strong>基本情况</strong>：爱沙尼亚厂商，主打“可视化销售管道”，适合流程型销售。</li><li><strong>核心优势</strong>：销售管道可视化（拖拽式调整跟进阶段）、自动提醒（到期任务/未跟进客户）、AI预测（成交概率+下次跟进时间）。</li><li><strong>适合场景</strong>：B2C流程型销售（如快消、教育）、需要“可视化流程”的企业。</li><li><strong>不足</strong>：垂直行业功能弱（无生产/零售）、国内本地化不足（无微信对接）。</li><li><strong>评分</strong>：业务匹配度3.5、功能完整性3.5、易用性4.5、数据能力3.5、成本4、服务3.5。</li></ul><h4>12. Freshworks（全渠道客服+CRM）</h4><ul><li><strong>基本情况</strong>：印度厂商，主打“全渠道客服+CRM”，适合服务型企业。</li><li><strong>核心优势</strong>：全渠道客服（微信/电话/邮件/小程序统一接待）、AI chatbot（自动回复常见问题）、客户画像（整合客服记录+销售跟进）。</li><li><strong>适合场景</strong>：服务型企业（如维修、教育、医疗）、需要“客服+销售”协同的企业。</li><li><strong>不足</strong>：工业/生产功能缺失、国内客服响应较慢。</li><li><strong>评分</strong>：业务匹配度3.5（服务）、功能完整性3.5、易用性4、数据能力3.5、成本4、服务3.5。</li><li><ul><li>*</li></ul></li></ul><h2>四、12款CRM系统对比总表（核心维度）</h2><table><thead><tr><th>系统</th><th>业务匹配度（工业/零售/服务）</th><th>功能完整性</th><th>易用性</th><th>数据能力</th><th>成本（中小微）</th><th>服务</th></tr></thead><tbody><tr><td>Salesforce</td><td>中大型通用</td><td>5</td><td>3.5</td><td>5</td><td>2</td><td>4</td></tr><tr><td>微软Dynamics 365</td><td>中大型通用</td><td>4.5</td><td>4</td><td>4.5</td><td>3</td><td>4</td></tr><tr><td>Zoho CRM</td><td>中小微通用</td><td>4</td><td>4</td><td>3.5</td><td>4</td><td>3</td></tr><tr><td>超兔CRM</td><td>工业/工贸（5）</td><td>4.5</td><td>4.5</td><td>4</td><td>4.5</td><td>5</td></tr><tr><td>纷享销客</td><td>中小微协同</td><td>4</td><td>4.5</td><td>3.5</td><td>4</td><td>4</td></tr><tr><td>销售易</td><td>中大型垂直</td><td>4.5</td><td>3.5</td><td>4.5</td><td>3</td><td>4</td></tr><tr><td>管家婆CRM</td><td>零售（5）</td><td>4</td><td>4.5</td><td>3.5</td><td>4</td><td>4</td></tr><tr><td>金蝶云星空CRM</td><td>工贸（4.5）</td><td>4.5</td><td>3.5</td><td> </td><td> </td><td> </td></tr></tbody></table><h2>最后：用系统替代“人工记忆”，用数据驱动“精准动作”</h2><p>销售跟进的本质，是“和客户建立‘信任连接’”——而系统的作用，是帮你“记住客户的每一个细节”“把经验变成可复制的动作”“让团队的力量最大化”。</p><p>现在，拿出你的笔记本，写下<strong>你团队的3个核心痛点</strong>（比如“线索漏跟进”“跟进没重点”“协作不及时”），对照这8个系统，找一个“能解决你痛点”的工具。</p><p>毕竟，<strong>销售的时间，应该用来和客户沟通，而不是翻微信聊天记录</strong>。</p><p>祝你早日告别“混乱的客户管理”，做一个“从容的销售”。</p>]]></description></item><item>    <title><![CDATA[百度数字人现场演示翻车？与“罗永浩”链接]]></title>    <link>https://segmentfault.com/a/1190000047404225</link>    <guid>https://segmentfault.com/a/1190000047404225</guid>    <pubDate>2025-11-17 11:06:22</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>11月13日消息，在今天的百度世界2025大会上，百度宣布“罗永浩”同款高说服力数字人技术已实现平台化，可以作为一个标准化的服务向全行业开放。</p><p>不过在现场演示中却出现了翻车，演示过程中，工作人员与“数字人罗永浩”的实时互动黑屏，几经尝试未能成功，随即以“留下一个悬念，待大家稍后自行体验”结束。</p><p>面对这一情况，李彦宏坦言“有点遗憾”，并表示“其实我们在之前演练的过程当中觉得这个效果还是非常令人惊艳的”。</p><p>如今，经过数字人的发展和优化，数字人不仅能完成流畅的商品讲解，还能根据直播间用户互动实时调整表达策略，从话术、表情到动作，均可与用户情绪和场景高度匹配。</p><p>今年，数字人主播占据各大直播间，品牌数字人在618和双11两次电商大战中都表现亮眼，双11期间83%的开播主播都曾使用过数字人直播，开播直播间数同比增长119%。</p><p>技术突破：从“工具人”到“智能体”（青否数字人源头v：zhibo175）</p><p>传统数字人常面临语音、语言、视觉多模态割裂的问题，表现为台词生硬、语音语调与台词情感匹配不佳、表情手势单一等。</p><p>青否数字人的双AI剧本互动</p><p>青否数字人深度复刻真人直播协作方式，让双 AI实现“主播 + 助播”的精准分工。</p><p>通过“讲品+捧场”或“讲品+回复弹幕”等多种直播配合模式，带来更高频的互动和更强的直播节奏！</p><p>比如在直播过程中，数字人主播正在讲解商品，助播则会实时捧哏或回复观众弹幕，打造流畅自然的直播节奏与生动的互动氛围，大幅提升观众的观看体验。</p><p>从“一人说”到“两人搭“，青否用 AI 协作逻辑，让直播全程有互动、有重点、有节奏，就像两个经验丰富的真人主播在默契配合。节奏感拉满，直播效果超硬核！</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047404227" alt="" title=""/></p><p>双数字人直播带货，能以实现利用ai数字人为直播赋能，做到真正的降本增效，罗永浩数字人电商直播首秀创下AI直播新标杆！</p><p>青否数字人在互动方面具备超强互动功能，满足您对于实时互动的一切想象：</p><p>我们打造了集智能、主动、增强、定时于一体的AI互动解决方案，堪称行业最强自动化互动！</p><p>智能互动：基于直播话术、自定义知识库、主播人设及自研直播AI小模型，实时解析用户弹幕问题，精准提供专业解答，回复率超95%，专业度满分！（青否数字人源头v：zhibo175）</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047404228" alt="" title="" loading="lazy"/></p><p>主动互动：无需预设，AI主动识别直播间关键节点。</p><p>智能触发欢迎语、引导关注点赞、精准催单促单等互动，显著拉升互动率与下单转化率！</p><p>互动增强：突破传统关键词限制！ 支持多条关键词关联1条核心意图。</p><p>AI自动泛化回复内容，面对相同问题，主播每次都能给出意思一致但表达多样的回复，互动更自然、更专业！</p><p>定时互动：数字人主播定时播报 + 定时弹幕推送，内容同样智能泛化，避免机械重复。主播可提前规划直播节奏，精准推送关键信息，刺激用户下单！</p><p>弹幕互动：当用户提出问题时，主播会迅速在抖音评论区@用户并回复相应的文本。还支持定时发送弹幕。</p><p>真人接管实时互动（阿凡达模式）：可选择开麦或文字输入，选择克隆音色进行接管操作，实时驱动直播间的数字人进行回复。</p><p>青否数字人与“罗永浩”链接失败，对比之下青否数字人更加稳定！</p>]]></description></item><item>    <title><![CDATA[手把手教你扩展JVS低代码平台的自定义函]]></title>    <link>https://segmentfault.com/a/1190000047404243</link>    <guid>https://segmentfault.com/a/1190000047404243</guid>    <pubDate>2025-11-17 11:05:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在低代码平台中，函数公式是很多地方都需要用到的，它是打通业务逻辑和实现数据自动化的“任督二脉”。但是一些场景中，平台自带的函数无法满足你独特的业务计算需求，一个复杂的校验规则或数据转换逻辑你可能需要自己去写编码实现，或者找厂商定制。<br/>然而在JVS的低代码、服务编排以及规则引擎中，有一个“自定义函数扩展”的能力。函数主要解决输入一个数据，然后输出对应的数据，这个数据映射的过程，我们通过函数去实现： y=f（x），例如，在表单中，一个字段的结果通过另外的字段的输入获取：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047404245" alt="图片" title="图片"/><br/>如上图所示，预计金额=单价*数量，那么这里 预算金额的结果就默认设置为一个函数取值，这个取值的方式通过函数公式进行加工获取，在JVS中会在很多地方用到函数公式，当公式不满足时需要我们自己扩展，本文介绍如何自行针对业务进行扩展函数公式。<br/>首先咱们平台中函数公式主要使用了groovy动态语言，所以需要先了解下相关的语法。由于groovy特性，所以函数体中也可以调用JAVA工具类进行处理，这样的话可扩展性会进一步提升。<br/>所有的函数都会保存在数据库中,保存的数据库和数据表默认为库：【jvs-design】，表：【jvs_function_base】。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047404246" alt="图片" title="图片" loading="lazy"/><br/>name：函数名称,注意函数名与函数体中的函数名要一致<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047404247" alt="图片" title="图片" loading="lazy"/><br/>type：分类，关系到显示在哪个函数分组中<br/>info：函数内容描述，会显示在右侧描述中，可使用html标签进行样式调整<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047404248" alt="图片" title="图片" loading="lazy"/><br/>param_count：参数数量，需要与函数体中函数参数个数保持一致<br/>dynamic_param：是否动态参数：0代表不为动态参数，并且param_count不为[0]；1代表为动态参数，并且param_count为[0]。<br/>示例1（非动态参数）：函数参数为2，那么这里param_count就填写[2]，dynamic_param值为0。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047404249" alt="图片" title="图片" loading="lazy"/><br/>示例2（动态参数，并且函数固定参数）：函数固定参数为0，那么这里param_count填写[0]，dynamic_param值为1。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047404250" alt="图片" title="图片" loading="lazy"/><br/>enable_cache：是否使用缓存，固定为1。<br/>jvs_param_type：参数类型，建议根据参数个数都使用any，涉及到参数使用其他节点值时取消类型校验。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047404251" alt="图片" title="图片" loading="lazy"/><br/>添加函数后，在“运维设置”中，开发配置，点击“更新”，重新加载缓存即可在使用函数公式地方看到新加的函数。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047404252" alt="图片" title="图片" loading="lazy"/><br/>函数body扩展：<br/>自定义函数可以使用groovy原生语法，也可以使用动态加载导入工具类，工具类中可以自由定义函数算法。<br/>例如1：<br/>def LEFT(x,y){return x.take(y)}<br/>此方法使用了groovy语法。<br/>例如2：<br/>import cn.hutool.core.util.ObjectUtil;def EQ(x,y){ return ObjectUtil.equals(x,y)};<br/>此方法使用了hutool工具类。</p><h2>以此类推，自己在源码中写的工具类也可在此处引入然后调用。</h2><p>示例：新增动态参数的一个函数：<br/>param_count：[0]<br/>dynamic_param：1<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047404253" alt="图片" title="图片" loading="lazy"/><br/>import cn.hutool.core.util.NumberUtil;<br/>def ADD(... x) {<br/>Number sum = 0;<br/>for (int i = 0; i &lt; x.size(); i++) {<br/>if (x[i] instanceof String) {<br/>x[i] = NumberUtil.parseNumber(x[i])<br/>};<br/>sum = NumberUtil.add((Number) x[i], (Number) sum);<br/>};<br/>return sum;<br/>};<br/>在线demo：<a href="https://link.segmentfault.com/?enc=Nu5kg09HFUM4YJCkcNA3yA%3D%3D.vFMXAWW7U%2BZ3f9Xu18FNcWo3p8lTe8n7lj%2F%2BfWj%2F0WI%3D" rel="nofollow" target="_blank">https://app.bctools.cn</a><br/>基础框架开源地址：<a href="https://link.segmentfault.com/?enc=PuCLlG%2BKCKUOkM%2FXjOoXMA%3D%3D.0eZnlcPFHu1RjL8B7roN7%2BIrj7SeymYOmklEPiQdQJE%2BXo6VH0AczkeLWLItWtKX" rel="nofollow" target="_blank">https://gitee.com/software-minister/jvs</a></p>]]></description></item><item>    <title><![CDATA[中国 CRM ，谁是王者 闷骚的绿茶 ]]></title>    <link>https://segmentfault.com/a/1190000047404264</link>    <guid>https://segmentfault.com/a/1190000047404264</guid>    <pubDate>2025-11-17 11:04:27</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>CRM 在中国的发展历程可谓波澜壮阔。从萌芽阶段起，商品销售者就有了管理和经营客户资源的意识，但受限于技术，主要依靠手工记录和人际交往。20 世纪 50 年代，随着商用计算机的普及，计算机开始在客户信息管理方面发挥作用。<br/>20 世纪 90 年代末，CRM 理念引入中国。初期，国内企业对 CRM 的认识还处于知识普及阶段，市场主要由国外厂商如 Siebel、Microsoft Dynamics 等占据。2004 年后，随着 SaaS 概念进入中国，头部企业软件服务商和创业企业开始探索 SaaS 部署模式，但由于企业接受度不够、基础设施资源昂贵等原因，SaaS CRM 市场遭遇困难。<br/>2008 年前后，中国 CRM 市场进入快速成长阶段。移动互联网的发展为移动 CRM 创造了条件，企业开始意识到 CRM 在提高销售效率、降低成本方面的重要性。此时，泛场景 CRM、垂直型 CRM 和社交型 CRM 等多样形式软件纷纷出现。<br/>2015 年前后，中国市场迎来 SaaS 元年，CRM SaaS 站上风口。但随后投资回归理性，市场逐渐成熟，各厂商开始独立思考商业模式，形成以良币驱逐劣币的竞争环境。<br/>如今，CRM 市场规模不断扩大，预计未来将保持稳定增长。艾媒咨询数据显示，2021 年中国 CRM 市场规模为 156 亿元，2024 年总体有望突破 250 亿元。CRM 已成为 SaaS 领域离交易最近、发展最快的核心赛道。<br/>热门 CRM 系统排行榜<br/>（一）综合实力领先者<br/>销售易 CRM 是集成了移动社交、云计算、人工智能以及物联网技术的企业级 CRM 平台。其以支撑销售人员高效工作为设计出发点，整合了营销服全流程管理、移动办公、运营管理等模块，帮助企业解决业务管理问题，整体提升企业的运营效率和盈利。销售易 CRM 具有强大的数据处理能力和高度的定制性，能够支持企业的国际化业务发展，并通过数据洞察推动销售增长。用户界面友好，易于操作，大幅提升用户工作效率，特别适用于需要高度集成和自动化的大中型企业。销售易是中国唯一且连续八年入选Gartner SFA魔力象限的CRM厂商，多项能力指标全球上可以说是排名第一。<br/>Zoho CRM 作为全球著名的客户关系管理系统，连续 12 年入选 Gartner SFA 魔力象限报告，并在 2023 年荣获 “Gartner 魔力象限 - 销售自动化远见者” 称号。Zoho CRM 提供多元化的管理功能，包括销售自动化、多渠道沟通、客户数据分析等。系统内置的 AI 销售助手可以优化销售流程，自动化常规的销售、市场和支持功能，减少手工数据录入和冗余工作。Zoho CRM 自建了北京、上海双活数据中心，执行欧盟 GDPR 和中华人民共和国个人信息保护法 PIPL，在安全上具备非常完善的服务体系。其价格相对实惠，无论是大型企业还是中小型企业都能承受，且提供了多种套餐选择，适用于各类规模的企业。<br/>（二）特色突出的后起之秀<br/>白码 CRM 以其灵活性和易用性著称，提供包括客户管理、销售自动化、数据分析和定制报告等在内的全方位 CRM 功能。支持多种数据集成和 API 调用，确保企业可以高效地管理客户信息和业务流程。界面友好，适合需要快速响应市场变化的中小企业及大型企业进行客户关系和销售管理。<br/>悟空 CRM 作为国内开源 CRM 的代表，凭借其免费、开源的特点吸引了大量用户的关注。该系统提供了包括客户管理、销售管理、库存管理、财务管理等在内的多项功能，并支持自定义开发和扩展。适合希望通过低成本实现 CRM 功能的企业和个人开发者。<br/>（三）国际品牌在中国市场<br/>SAP CRM 虽然是国际企业，但在中国的 CRM 市场表现不俗。以其强大的 ERP 系统为背景，提供了销售与分销、服务管理、营销管理等全面功能。适用于大型企业，能够帮助企业实现精细化管理。例如，SAP 在 2018 年 6 月发布了 C/4HANA，涵盖 SAP Marketing Cloud（营销云）、SAP Commerce Cloud（电商云）、SAP Service Cloud（服务云）和 SAP Customer Data Cloud（客户数据云），支持所有的前端业务职能，覆盖 25 个行业，7 个垂直领域。<br/>微软 CRM（Microsoft Dynamics 365）以其与 Office 365 等微软产品的深度集成，为用户提供了统一的业务管理平台。深度集成的优势使得工作效率大幅提升，模块化设计提供可定制的模块化服务，满足不同业务需求。熟悉的微软界面降低了用户学习成本，适用于已使用微软产品的企业，特别是中小型企业。<br/>五、CRM 系统的选型建议</p><p>选择适合企业的 CRM 系统是一项至关重要的任务，以下是一些方法和注意事项，可帮助企业做出明智的决策。<br/>（一）明确企业需求<br/>1.首先，企业需要明确自身的业务模式和销售流程。例如，制造业可能更关注产品生命周期管理和客户反馈，零售业则可能更看重客户购买行为分析和营销活动管理。<br/>2.列出所需的 CRM 系统功能清单，包括客户管理、销售机会跟踪、营销活动管理、数据分析等。同时，考虑企业的目标和预算，确保所选系统能够满足企业的长期发展需求。<br/>（二）考虑系统功能<br/>3.客户管理能力：CRM 系统应能够记录客户详细信息，包括联系方式、购买历史、偏好等。同时，系统应能够根据客户信息为企业提供精准的销售和推广策略。<br/>4.系统定制性：企业应选择能够定制的 CRM 系统，以满足自身的业务需求。例如，系统应允许企业添加自定义字段、定义工作流程等。<br/>5.系统集成性：CRM 系统应能够与企业的其他业务系统无缝集成，如 ERP 系统、电子邮件系统等，以便于数据的传递和共享。<br/>6.使用难易度：现代 CRM 系统应是直观易懂、用户友好和易于使用的，即使是没有经验的销售人员也能够快速上手。<br/>7.数据安全性：CRM 系统是集中存储机密客户信息的平台，因此安全性至关重要。企业应选择提供多层安全措施的系统，如数据加密、访问控制等。<br/>8.价格因素：企业应根据自身的预算选择适合的 CRM 系统。不同的 CRM 系统有不同的价格和付款选项，企业应综合考虑系统的功能、维护成本和支持费用等因素。<br/>（三）评估系统的可扩展性和灵活性<br/>9.随着企业的发展，业务需求会不断变化，因此选择一个可扩展的 CRM 系统至关重要。企业应考虑系统是否支持自定义字段、工作流以及是否能够与现有的 ERP、SCM 等系统无缝集成。<br/>10.评估系统的灵活性，例如是否可以根据企业的需求调整界面布局、字段名称、流程设置等内容，使之更符合企业自身的风格和习惯。<br/>（四）测试系统的易用性和用户体验<br/>11.一个直观、易用的界面可以降低员工的培训成本，提高工作效率。企业可以通过试用或参考用户评价来评估 CRM 系统的用户体验。<br/>12.考虑系统的移动访问能力，在移动办公日益普及的今天，CRM 系统的移动访问能力变得尤为重要。企业应确保所选 CRM 系统支持移动设备，并提供良好的移动用户体验。<br/>（五）关注供应商的支持与服务<br/>13.优质的客户服务和技术支持是 CRM 系统成功实施的关键。企业应评估供应商的客户服务质量、响应速度以及服务网络的覆盖范围。<br/>14.了解供应商的实施能力和售后服务，确保系统能够顺利部署和使用。同时，考虑供应商是否提供培训和技术支持，以帮助企业员工快速熟悉和掌握 CRM 系统。<br/>（六）考虑系统的价格和售后服务<br/>15.在购买 CRM 管理软件时，要考虑软件的价格和售后服务，并且比较不同厂商或渠道的报价和服务质量。<br/>16.很多品牌的 CRM 软件提供多种版本，不同版本对应不同的功能，企业可以通过远程演示或上门演示的方式，来确定哪个版本能满足自己的需求。<br/>总之，选择适合企业的 CRM 系统需要综合考虑多个因素。企业应根据自身的业务需求、预算限制和技术前瞻性来做出明智的决策，以提高客户关系管理效率，增加收入，提高客户满意度。<br/>四、知名 CRM 品牌推荐</p><p>（一）全球知名品牌<br/>Salesforce CRM 作为全球最大的 SaaS 型 CRM 服务提供商，在功能和市场影响力方面表现突出。它提供了全面的销售、服务、市场和分析功能，能够帮助企业实现客户关系管理的全流程。其优势包括：<br/>全面功能覆盖：从销售预测分析工具、潜在客户管理工具，到服务云的 AI 聊天机器人、呼叫中心等，功能涵盖广泛。<br/>强大自定义能力：支持自定义字段、页面布局、工作流等，满足企业个性化需求。<br/>丰富集成：可以与 Salesforce 的其他产品以及第三方应用进行集成，为企业提供一体化的解决方案。<br/>Salesforce CRM 在中国市场也备受欢迎，尤其是在一些大型企业和跨国公司中应用广泛。其先进的技术和成熟的解决方案，为企业提供了高效的客户关系管理工具。<br/>（二）国内发展迅速的品牌<br/>销售易作为国内发展迅速的 CRM 品牌，具有独特的发展特点和明确的市场定位。<br/>销售易融合了移动社交、云计算、人工智能以及物联网技术，打造了企业级 CRM 平台。在发展过程中，销售易始终坚持以客户为中心，不断创新和优化产品。<br/>技术创新：将AI融入 CRM 中打造NeoAI产品。NeoAI深度融合了专家规则、机器学习及大语言模型，将大模型能力融入营销、销售、服务全流程中的业务场景，让业务洞察更准确、赋能更全面、应用更聪明。目前，在捷豹路虎、锦江酒店、伊顿中国等企业已经应用了NeoAI能力。<br/>数据驱动：具有强大的数据处理能力，通过数据洞察推动销售增长。能够为企业提供精准的销售策略和市场分析，帮助企业更好地了解客户需求。<br/>定制性强：paas平台是销售易灵活定制的基础。高度的定制性能够满足不同企业的个性化需求，支持企业的国际化业务发展。无论是大型企业还是中小企业，都能根据自身需求进行定制化设置。<br/>用户体验友好：销售易的NeoUI用户界面友好，易于操作，大幅提升用户工作效率。这使得销售人员能够快速上手，减少培训成本，提高工作效率。<br/>销售易的市场定位主要是为大中型企业提供营销服一体化的CRM解决方案，帮助企业提升销售团队的效率和盈利。无论是在制造、软件互联网、高科技、生命科学等行业，还是在中小企业市场，销售易都以其专业的产品能力和优质的服务赢得了众多企业的青睐。</p>]]></description></item><item>    <title><![CDATA[10 分钟搞定全栈无人机系统 俞凡 ]]></title>    <link>https://segmentfault.com/a/1190000047404270</link>    <guid>https://segmentfault.com/a/1190000047404270</guid>    <pubDate>2025-11-17 11:03:51</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <blockquote><em>本文详细介绍了如何通过开源系统和开放硬件打造大规模商用无人机系统，并且强调了领域专业知识和合规性在成功商用无人机系统开发中的重要作用。原文：[Mastering Full-Stack Unmanned Aerial Systems: From Hardware to the $211 Billion Low-Altitude…](https://jinlow.medium.com/mastering-full-stack-unmanned-aerial-systems-from-hardware-to-the-211-billion-low-altitude-bf71e4788dea "Mastering Full-Stack Unmanned Aerial Systems: From Hardware to the $211 Billion Low-Altitude…")</em></blockquote><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047404272" alt="" title=""/></p><p>低空经济正在迅猛发展，仅中国国内就预计到 2025 年这一领域的规模将达到 2114.2 亿美元，到 2035 年将达到 4900 亿美元。而全球无人机配送市场预计到 2032 年将达到 85.5 亿美元，年复合增长率将达到 42.7%。但现实情况是，要掌控这个价值万亿的市场，仅仅拥有现成的无人机是不够的，还需要了解从芯片到空域的整个无人驾驶航空系统（UAS，Unmanned Aerial System）架构。</p><p>在从零开始构建 Skylight 无人机系统项目（包括自动驾驶软件、定制嵌入式硬件、地面站、任务规划器以及载荷控制）之后，我了解到，低空经济领域的真正赢家不会是那些使用黑箱解决方案的运营商。而是能够针对特定应用场景（如需要 10 厘米精度的农业喷洒、需要 19 分钟交付周期的包裹配送，或者需要厘米级 RTK 定位的基础设施检查）对每一层进行定制的工程师们。</p><p>本文详细阐述了构建具备量产水平的无人机系统平台，并在低空经济中最具利润的领域中展开竞争所需的切实条件。我们将探讨自动驾驶架构、传感器融合、地面控制系统、嵌入式设计，以及 2025 年正在重塑 BVLOS（超视距，Beyond Visual Line of Sight）操作模式的新兴法规等内容。</p><h2>低空经济：市场力量与技术需求</h2><p><strong>究竟是什么在推动规模达 235 亿美元的城市空中交通市场的发展？</strong></p><p>城市空中交通（UAM，Urban Air Mobility）行业到 2030 年的市场规模将达到 235 亿美元，到 2035 年将达到 415 亿美元，年增长率高达 31.2%。但这些数字并不能完全反映其技术层面的情况。有三个相互关联的因素正在推动其商业化可能性：</p><ul><li><strong>政策成熟度</strong>：美国联邦航空管理局于 2025 年 8 月公布的第 108 部分规则确立了适用于重量不超过 1320 磅的无人机的全国范围内的无管制飞行标准，要求无人机飞行高度不得超过 400 英尺，并配备确定性安全管理系统。加拿大于 2025 年 11 月出台的法规允许在不受管制的空域内对重量低于 150 千克的无人机进行常规无管制飞行，无需特殊许可。欧洲 EASA SORA 2.5 法案要求符合 SAIL III 标准，必须具备双 EKF 冗余和带有 CRC 标记的确定性构建。</li><li><strong>技术融合</strong>：RTK GPS 现在利用像 Trimble 的 CenterPoint RTX 这样的全球校正服务，能够提供厘米级精度，消除了传统 RTK 的 20 千米基站限制。集成 5G 的无人机系统能够在 23 千米的范围内进行实时中央调度，而 AI 辅助路径规划使轨迹跟踪误差降低了 50%。</li><li><strong>经济压力</strong>：最后一公里配送占总运输成本的 50% 以上；优化的多旋翼无人机能将这一比例降低 93%。农业喷洒无人机能在 10 厘米精度范围内实现 85% 以上的精准度，大幅减少化学物质的浪费。运营商报告称，与地面车辆相比，每件货物的碳排放量可以降低 94%。</li></ul><h2>数字背后现实</h2><p>到 2025 年，中国将投入 1.5 万亿元人民币（约合 2089.3 亿美元）用于航空走廊基础设施建设。同时，无人机配送业务量将从 2024 年的 32456 笔增长至 2030 年的 275703 笔。这并非是简单的增长，而是需要具备认证硬件、冗余安全系统和确定性实时性能的基础设施规模的部署。</p><h5>自动驾驶系统架构：PX4 与 ArduPilot 在量产系统中的比较</h5><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047404273" alt="CubePilot无人机自动驾驶系统详细接线图，显示组件连接和配电。来源：https://www.worldronemarket.com/cubepilot-ecosystem-autopilot-wiring-diagram" title="CubePilot无人机自动驾驶系统详细接线图，显示组件连接和配电。来源：https://www.worldronemarket.com/cubepilot-ecosystem-autopilot-wiring-diagram" loading="lazy"/></p><h5>根据实际工程需求选择飞行系统架构</h5><p>PX4 与 ArduPilot 的选择决定了后续所有技术决策。两者都是商业系统，但在 2025 年的部署中，其架构在关键方面存在显著差异。</p><p>PX4 的模块化 uORB 架构将传感器驱动程序作为独立模块进行隔离，并通过 microORB 总线进行发布。出现故障的驱动程序会自行隔离；估算器则切换到正常状态的主题实例。PX4 v1.16 版本增加了 FMUv6X-RT 支持，用于审计追踪的确定性构建哈希值，以及在 50 帧/秒地形数据速率下的一流 ROS 2/DDS 连接桥接功能。这对于需要获得 EASA SAIL III 认证的送货无人机来说非常重要，因为必须包含确定性的故障模式。</p><p>ArduPilot 架构在估算器层面会同时运行两个扩展卡尔曼滤波器（EKF）实例，并实时对惯性测量单元（IMU）数据集进行投票。ArduPilot 4.6 版本在 EKF3 中、原生 Blue UAS 模式（美国国防认证）以及完整的 ADS-B 标识广播中增加了双 IMU 冗余功能。室内光流测试表明，ArduCopter 4.5.7 在 90 秒内保持位置，其横向误差的均方根值为 0.08 米，而 PX4 v1.15 版本的该误差值为 0.11 米。</p><p>在 6 米/秒的侧风条件下，风速恢复情况显示两个机架均在 1.2 秒内重新回到设定值，但 PX4 的速率控制器仅需要 18% 更少的积分超调重置次数，这对于配备有稳定器的大型航拍无人机来说至关重要。</p><h5>许可与商业影响</h5><p>PX4 的 BSD 许可证允许开发具有专有特性的衍生产品，但无需披露代码。亚马逊的 MK30 和 Zipline Sparrow 就使用 PX4 作为送货飞行器的控制系统。ArduPilot 的 GPL v3 要求发布修改版本，但允许配套计算机代码（其中大部分知识产权存在于其中）保持专有状态。对于起飞重量超过 25 千克的农业喷洒垂直起降飞行器，ArduPilot 占据主导地位：2024 年第四季度公布的 17 项新的 FAA 第 137 部分豁免中都提到了 ArduPilot 固件。</p><p>Skylight 无人机系统项目设计决策：采用混合式方案 —— 使用 PX4 核心系统，并配备定制辅助计算模块处理特定任务相关逻辑（载荷控制、射频调谐、载荷释放机制）。BSD 许可证使我们能够不断改进专有功能，同时利用 PX4 的 Gazebo/Ignition 模拟技术，并结合真实参数的电机惯性进行硬件在环测试。</p><h5>传感器融合与导航：实现厘米级精度</h5><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047404274" alt="示意图展示了无人机如何利用带卫星信号的 RTK GPS 及地面基站进行精确定位" title="示意图展示了无人机如何利用带卫星信号的 RTK GPS 及地面基站进行精确定位" loading="lazy"/></p><h5>为什么仅靠 GPS 不够 —— 如何通过传感器融合来解决</h5><p>消费级 GPS 可提供 2-3 米的精度，但对于精准农业喷洒、包裹配送或自动降落等应用而言，显然是不够的。现代无人机系统会将来自惯性测量单元、气压计、磁力计、光流、激光雷达和全球导航卫星系统的数据融合为统一的状态预估值。</p><h5>EKF 管道：从原始数据到厘米级精度</h5><p>扩展卡尔曼滤波器（EKF）能够将具有不同更新频率和噪声特性的传感器流进行合并，典型实现方式是：</p><ol><li>预测步骤（100 Hz）：惯性测量单元（IMU）加速度计和陀螺仪数据用于预测位置、速度和姿态</li><li>校正步骤（可变）：全球定位系统（1 - 10 Hz）、气压计（20 Hz）、磁力计（10 Hz）、光学流（20 Hz），对预测状态进行校正</li><li>异常值剔除：卡方门控检测传感器故障或错误读数</li><li>协方差传播：跟踪每个状态预估的不确定性</li></ol><p>PX4 的双 EKF 实现运行两个并行估算器，对传感器的有效性进行投票。如果一个 IMU 发生漂移，系统会自动将健康传感器的权重提高。ArduPilot 的 EKF3 运行方式类似，但在估算器层而非 PX4 的驱动层进行投票。</p><h5>RTK GPS：精准应用的变革者</h5><p>实时动态全球定位系统通过利用基站载波相位差分修正实现厘米级精度。传统 RTK 需要 20 公里的基站覆盖半径，并且存在站点之间的坐标系协调问题。</p><p>Trimble 的 CenterPoint RTX 以及类似的全球校正服务均基于固定不变的参考基准面运行，从而消除了多站协调的难题。对于自主降落而言，使用相同的 RTX 系统对着陆平台进行测量 —— 在同一个基准面内，所有数据都能完美对齐。</p><h5>当 RTK 出现故障时：mmE-Loc 在城市峡谷中的着陆应用</h5><p>在城市峡谷中，随着海拔降低，GPS 精度会下降，甚至在着陆时几乎无法使用。研究人员开发了 mmE-Loc 系统，将事件相机与毫米波雷达相结合，以实现厘米级精度和毫秒级延迟的地面定位。该系统利用微运动的时间一致性来检测无人机，然后在因子图中联合优化事件跟踪和雷达跟踪，当 GPS 失效时能够实现可靠着陆。</p><p>传感器融合量化效益：采用索尼技术和无人机点云数据进行整合，使配准误差降低了 12.75%（从 0.149 米降至 0.130 米）。处理去噪后的数据集使得 M3C2 距离精度比原始点云数据提高了 52.4%。</p><h5>地面站与任务规划：操作指挥与控制</h5><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047404275" alt="一种坚固的多屏幕无人机地面控制站，带有操纵杆和键盘接口，用于综合无人机操作和遥测监测" title="一种坚固的多屏幕无人机地面控制站，带有操纵杆和键盘接口，用于综合无人机操作和遥测监测" loading="lazy"/></p><h5>为何任务规划软件能决定任务成功与否</h5><p>地面控制站（GCS）是执行任务的核心，包括飞行前规划、实时监控、紧急应对以及飞行后的分析。Skylight 无人机系统项目使用 Qt 框架构建地面站，以实现跨平台支持（Windows/ Linux/移动设备），并采用插件系统以增强可扩展性。</p><h5>核心 GCS 在生产运营中的功能</h5><p>现代任务规划系统必须实现以下目标：</p><ul><li>利用数字高程模型（DEM，Digital Elevation Model）导入实现 3D 地形可视化，适用于地形跟随任务</li><li>通过自定义间距实现区域全覆盖和走廊测绘，适用于摄影测量或地球物理调查</li><li>具备实时遥测功能，可配置警报以监测电池电压、GPS 质量、电机温度和通信链路强度</li><li>结合地理围栏和禁飞区功能，确保符合监管要求</li><li>提供任务回放和日志分析，用于事故调查和性能优化</li></ul><p>UgCS（通用地面控制软件，Universal Ground Control Software）被公认为专业无人机操作的黄金标准，支持 PX4、ArduPilot、大疆以及 60 多种无人机型号。其激光雷达工具集（专家/企业版本）包含用于测量精度的地形跟随飞行路径和自动惯性测量单元校准操作。</p><p>QGroundControl 提供了针对 PX4/ArduPilot 的全面开源任务规划服务，包括完整的参数调整、固件管理以及与飞行控制计算机相连接的 270 度驾驶舱模拟器集成。对于专为 ArduPilot 设计的功能，任务规划器提供了深入的硬件配置、实时遥测数据以及通过 cflib API 进行的大量 Python 脚本编写，以实现定制化的自动化操作。</p><h2>通信系统：4G/5G 技术用于延长无视距飞行范围</h2><p>传统射频系统在信号衰减前将传输范围限制在 10 至 15 千米。而 4G LTE/5G 飞行器遥测技术则能在蜂窝网络覆盖区域内实现几乎无限的无视距飞行范围。</p><p>这些实现方式利用虚拟专用网络（VPN）隧道技术，通过蜂窝网络保障无人机与地面控制站（GCS）之间使用的 MAVLink 协议数据的安全传输。Parrot Anafi AI 利用 4G 作为主要数据传输通道，理论覆盖范围可达 23 公里，但在城市区域实际性能会降至 15.3 公里，之后需要重新连接。JOUAV 的 CW-15 利用 5G 进行实时中央系统调度，而 CW-80E 则集成了卫星终端、4G 和 5G，用于灾难通信场景。</p><p>LTE/5G 面临的挑战：农村地区覆盖不足、网络切换不稳定，以及由于无人机同时能被多个基站连接而导致的上行/下行信号干扰。可定向波束成形天线跟踪服务基站，可缓解干扰问题。</p><h2>嵌入式系统与硬件设计：构建大脑</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047404276" alt="DFRobot MPU-6050 三轴加速度计和 I2C 陀螺仪传感器模块，用于无人机系统的惯性测量" title="DFRobot MPU-6050 三轴加速度计和 I2C 陀螺仪传感器模块，用于无人机系统的惯性测量" loading="lazy"/></p><h5>STM32 与 ESP32：为飞行关键系统选择微控制器</h5><p>Skylight 无人机项目采用了定制印刷电路板设计，集成了 STM32/ESP32 芯片，用于传感器采集、控制逻辑以及与自动驾驶仪的通信。这一选择至关重要：</p><ul><li>STM32 用于实时控制：STM32 Cortex-M4 微控制器能够提供微秒级精度，适用于电机控制回路，对于姿态稳定至关重要。ArduPilot 和 PX4 自动驾驶系统主要使用 STM32 FMUv6X 参考板。STM32 的实时操作系统（RTOS）优化确保了确定性的时间控制，这对飞行关键系统而言至关重要，因为错过截止日期会导致系统崩溃。</li><li>ESP32 用于连接和原型设计：ESP32 提供了集成的 Wi-Fi/蓝牙、双核处理和 Arduino IDE 兼容性，使其非常适合快速原型设计、遥测模块和非关键负载。ESP-Drone 项目展示了使用 ESP32 + MPU6050 加速度计/陀螺仪的完全功能化的四旋翼飞行器，通过 Python cflib API 编程实现了高度保持和位置保持。</li><li>在量产无人机中，混合架构很常见：STM32 负责飞行控制，而 ESP32 管理无线通信和用户界面，通过 UART/SPI/I2C 连接。将实时任务和非实时任务分离开来，提高了可靠性。</li></ul><h5>IMU 集成与校准</h5><p>像 MPU6050 这样的惯性测量单元（IMU）将一个 3 轴加速度计和一个 3 轴陀螺仪集成在单个芯片中，能提供 100 Hz 以上的原始数据用于姿态估算，但需要进行仔细校准：</p><ul><li>加速度计校准：在六个方向（±X、±Y、±Z）测量偏移量，以校正制造偏差</li><li>陀螺仪校准：获取静止状态下的读数以确定零率偏移（漂移）</li><li>温度补偿：IMU 的偏差会随温度变化而变化；高级系统会存储校准曲线</li><li>振动隔离：将 IMU 安装在减震材料上，以过滤因螺旋桨/电机振动而造成的读数误差</li></ul><h5>电源管理与安全</h5><p>飞行电子设备需要稳定的电源，并具备故障转移保护功能。常见架构包括：</p><ul><li>双电源供应：主电池与备用锂电池，自动在主电池失效时切换供电</li><li>电压监测：实时电池遥测功能，可配置低电压警报（通常在电量达到 30% 时发出警告）</li><li>电流检测：在热损坏发生之前检测电机故障或短路</li><li>看门狗定时器：若软件卡顿，微控制器会自动重启，以防完全失控</li></ul><h2>高级控制系统：行为树和 AI 决策制定</h2><h5>超越 PID 路径：分层任务逻辑</h5><p>低级控制通过 PID（比例-积分-微分，Proportional-Integral-Derivative）回路来实现高度保持、航向锁定和空速调节。而高级任务逻辑则需要更为复杂的架构。</p><p>行为树（BT，Behavior Tree）具有模块化、目标导向的特点，其控制效果优于传统有限状态机。行为树以层级结构来组织任务：</p><ul><li>动作节点：启用自动驾驶模式，触发弹射器功能（相机快门、喷雾阀）</li><li>条件节点：测试传感器数据（电池电量、GPS 定位质量）</li><li>组合节点：按顺序执行任务；选择器尝试各种选项，直至其中一项成功</li><li>装饰节点：修改子节点的行为（重复、反转、超时）</li></ul><p>无人机航点任务行为树可能如下所示：</p><ul><li><p>序列（重复）：</p><ul><li>条件：检查 GPS 定位质量 → 成功</li><li>操作：继续前往下一个航点 → 成功</li><li>选择器：尝试降落方式：</li><li>操作：RTK 精度降落 → 失败（没有 RTK 定位）</li><li>操作：光学流体降落 → 成功</li></ul></li></ul><p>行为树相较于有限状态机具有更高的可扩展性，并且模块之间有标准化接口，特别适用于多无人机协调和复杂负载控制（例如 Skylight 项目中与飞行阶段同步的载荷释放机制）。</p><p>AI 增强的飞行控制：基于强化学习的 PID 参数调整技术</p><p>传统 PID 调整过程十分繁琐，需要通过反复试验的飞行测试来调整参数。而深度确定性策略梯度（DDPG，Deep Deterministic Policy Gradient）强化学习技术能够在飞行过程中自动调整 PID 控制器。</p><p>AirPilot 是一种基于 PPO 的 DRL 自动调整非线性 PID 控制器，将默认的 PX4 PID 导航误差降低了 90%，导航速度可提高 21%，并且将设置时间和超调量分别减少了 17% 和 16%。该系统在模拟环境中（使用带有 PX4 自动驾驶器无人机工具包支持包的 Matlab/Simulink）进行训练，然后部署到了实际硬件上，是首个基于 DRL 的实际无人机飞行控制器之一。</p><h2>有效载荷控制与定制应用：将硬件转化为解决方案</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047404277" alt="" title="" loading="lazy"/></p><h5>农业喷洒系统：规模化下的 10 厘米精度</h5><p>农业无人机是低空经济领域最大市场之一，预计到 2025 年将达到 34.1 亿美元（较 2024 年的 24.7 亿美元有所增长）。现代喷洒无人机利用 GPS 和多光谱传感器实现 10 厘米的喷洒精度，以监测田地状况并实时调整喷洒量。</p><h6>关键技术能力：</h6><ul><li>罐体容量：20 - 70 升（大疆 Agras T40 罐体容量为 40 升，每小时可喷洒 16 - 18 公顷）</li><li>流量控制：可调节流量范围为 30 - 40 升/分钟，通过 AI 实现每区域流量自动调整</li><li>喷头系统：双级雾化，配备全方位障碍物感应功能，可避免树木/电线杆碰撞</li><li>耐候性：在轻度降雨和中等风力条件下可正常运行，具备自动稳定功能</li><li>精准优势：精准施药可减少 93% 的化学药剂浪费，相较于地面喷雾器可减少 94% 的碳排放，并能实现当天对田地的分析以快速做出处理反应。</li></ul><h5>包裹配送载重：重量、释放和降落伞系统</h5><p>亚马逊计划在 2030 年前通过无人机每年完成 5 亿次包裹配送。配送系统需具备以下功能：</p><ul><li>带有主动冷却系统的货舱，用于存放对温度敏感的货物</li><li>在 GPS 信号点位触发自动释放机制，并通过高度确认</li><li>降落伞用于包裹下降的回收（保护易碎物品）</li><li>在起飞前和成功释放时使用重量传感器确认包裹装载情况</li></ul><p>沃尔玛和 Wing 公司展示了从美国 100 家门店平均 19 分钟完成配送的成果，验证了大规模商业运营的效率。多旋翼无人机队在路线优化后将最后一公里的成本降低了 93%。</p><h5>定制型有效载荷接口</h5><p>Skylight 无人机系统项目采用模块化有效载荷接口，支持摄像机、喷雾喷头、载荷释放装置以及未来可能出现的其他有效载荷，其实现方式为：</p><ul><li>标准化的电气连接器（电源、CAN 总线、串行）</li><li>带有减震功能的机械固定点</li><li>软件插件架构，可实现针对有效载荷的特定控制逻辑，无需自动驾驶系统重新编译</li><li>有效载荷状态的实时遥测（喷雾速率、载荷释放确认、相机快门计数）</li></ul><h2>BVLOS 操作与合规性：超视距范围飞行。</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047404278" alt="" title="" loading="lazy"/></p><h5>2025 年监管环境将重塑无人机运营模式</h5><p>超视距范围（BVLOS，Beyond Visual Line of Sight）飞行模式，即无人机超出飞行员肉眼可见范围进行飞行，能够充分释放低空经济潜力。但直到最近，这种模式仍需高额豁免费用和复杂的审批程序。</p><h6>美国 — 航空局第 107 部分和新兴的第 108 部分</h6><p>标准第 107 部分要求保持视线清晰，超视距范围飞行需要通过 DroneZone 申请特殊许可。美国航空局第 108 部分草案规则（意见征询期于 2025 年 10 月结束）为重量不超过 1320 磅的无人机制定了全国范围内的超视距范围飞行标准：</p><ul><li>适航性：行业安全标准，但未获得完整的飞机认证</li><li>飞行限制：在海拔高度低于 400 英尺的区域飞行，且在人口密集区域有更严格的规定</li><li>安全管理：有经过培训的人员负责飞行监管、安全记录以及事故报告（信号丢失、紧急迫降）</li><li>探测与避让（DAA，Detect-and-Avoid）：需使用获得美国联邦航空管理局批准的 DAA 系统、跟踪雷达或视觉观察员</li></ul><h6>加拿大 —— 低风险超视距无人机飞行（2025 年 11 月）</h6><p>加拿大运输部 2025 年 11 月的法规允许重量低于 150 千克的无人机在没有特殊飞行操作证书（SFOC，Special Flight Operations Certificates）的情况下进行常规超视距无人机飞行，前提是：</p><ul><li>在低于 122 米（400 英尺）的无管制空域内运行</li><li>至少距离人口密集区 1 公里（或在人口稀少地区对小型无人机适用）</li><li>飞行员需持有高级和一级复杂操作证书（年龄 18 岁及以上，通过在线考试，飞行时长 20 小时）</li><li>超视距操作（EVLOS）允许小型无人机在 2 海里（3.6 公里）范围内运行，使用经过培训的视觉观察员（VO）并配备冗余通信系统。</li></ul><h6>欧洲 —— EASA SORA 和 SAIL III</h6><p>EASA 的 SORA（特定操作风险评估）2.5 方法以及 SAIL III 合规性手段（2025 年 1 月）要求确定性的姿态控制故障率，这促使 ArduPilot 4.6 引入了双 EKF 冗余机制，而 PX4 则推出了带有 CRC 标记的确定性版本，专门用于 EASA 认证。</p><p>所有超视距飞行任务都需要配备数据链通信系统（包括机载传感器或地面设备）、远程识别/类别标识以及提升飞行员的技能标准。</p><h5>有防护的超视距飞行规则和操作概念</h5><p>有防护的超视距飞行规则利用自然地形（建筑物、悬崖、森林）作为屏障，降低了有人驾驶飞机相撞的风险。无人机必须在横向距离不超过 100 英尺且低于防护物体顶部的范围内运行 —— 这在联邦航空管理局第 107.110 条和欧洲航空安全局 SORA 规范中得到了正式认可。</p><h5>模拟与硬件在环测试：飞行前验证</h5><p><strong>为何仅依靠实际测试会导致项目失败</strong></p><p>用价值 3 万美元的无人机搭载定制负载进行坠毁测试，会毁掉几个月的工作成果。而模拟测试和硬件在环测试能在首次飞行前发现 80% 以上的错误。</p><h6>PX4 与 Gazebo/Ignition 集成</h6><p>PX4 发布了带有真实电机惯性参数的 Gazebo/Ignition 模拟模型 —— 电机加速具有真实延迟效果，螺旋桨能生成精确的推力曲线，能够发现简化模拟器中无法察觉的控制问题。</p><h6>模拟工作流程：</h6><ul><li>软件在环测试（SITL，Software-in-the-Loop）：整个自动驾驶系统完全通过软件运行，控制模拟的物理过程</li><li>硬件在环测试（HITL，Hardware-in-the-Loop）：实际飞行控制器硬件接收模拟的传感器数据，并输出控制信号</li><li>飞行测试计划：逐步扩大飞行范围（悬停 → 转换 → 航行）</li></ul><h5>ArduPilot 的跨飞行器模拟</h5><p>ArduPilot 的单个程序在悬停、飞行和漫游模式之间切换，简化了 CI/CD 流程。每晚的双 SITL 流水线会重飞 589 个航点网格，标记出超过 5 厘米的偏差，使得无需重新编写任务逻辑就能从 PX4 原型直接跳转到 ArduPilot 生产版本。</p><h5>Eve Air Mobility 的 Iron Bird 方式</h5><p>eVTOL（电动垂直起降飞行器）开发商 Eve Air Mobility 在首次飞行前（预计在 2025 年末/2026 年初）在各种飞行器和模拟器上进行了超过 10,000 小时的系统测试。他们设计的实用 Iron Bird 驾驶舱 —— 将电动垂直起降飞行器的线路拆解后接入真实组件 —— 在进行空中测试前验证了系统集成情况。</p><p>驾驶舱模拟器（具有 270 度视角）与飞机飞行控制计算机以及第五代电传操纵系统规则相连接，操纵杆、执行器和电机能够实时响应，提前调整操控感受以确保飞行安全。电力系统和断路器会进行全天候自动化测试，从而简化飞行测试流程并降低认证成本。</p><h2>未来：AI、城市空中交通与数字孪生</h2><p>低空经济的发展方向何在</p><p>未来十年将有三个融合领域将发挥重要作用：</p><h5>1. AI 原生飞行系统</h5><p>物体检测与防撞的计算机视觉技术已经成熟，前沿领域是基于强化学习的自适应控制。TD3-LSTM（双延迟深度确定性策略梯度 + 长短期记忆）能够在不确定的空中对抗场景中实现智能机动决策，将其扩展到民用领域（城市峡谷中的动态避障、风速变化适应）能够实现真正自主的操作，而无需预先设定应急方案。</p><h5>2. 电动垂直起降（eVTOL）用于城市空中交通</h5><p>Eve Air Mobility 已接到 2800 份订单，总价值达 140 亿美元。Joby Aviation、Volocopter 和 Lilium 正朝着 2026 至 2028 年的商业客运运营目标努力。这些系统面临的认证难度比货运无人机更大，需要冗余的飞行关键系统、紧急自动旋转功能、乘客安全管理系统，但每次飞行的收入可高出 10 至 100 倍。</p><h5>3. 低空数字孪生与交通管理</h5><p>随着无人机密度增加，空域协调变得至关重要。低空数字孪生 —— 实时三维空域模型 —— 能够实现交通流量预测和冲突解决。美国国家航空航天局的高级空中交通（AAM）计划开发了 UTM（无人机交通管理）系统，该系统整合了飞行意图数据、天气状况和动态禁飞区域。Eve 的“矢量”城市空中交通管理系统在推出 UAM 服务之前已拥有 21 个客户。</p><h2>开辟通往低空经济之路的路径</h2><p>从业余爱好者到行业工程师的实用指南</p><p>第 1 层：硬件基础（3 - 6 个月）</p><ul><li>高级嵌入式开发：STM32/ESP32，PCB 设计基础，传感器接口（I2C、SPI、UART）</li><li>构建参考平台：在进行定制之前先复制 ESP-Drone 或 PX4 FMUv6X 的设计</li><li>学习电力电子学：电池管理、电压调节、电流检测</li></ul><p>第 2 层：软件栈（6 - 12 个月）</p><ul><li>在参考硬件上部署 PX4 或 ArduPilot 系统，执行稳定/自主飞行任务</li><li>研究控制理论：PID 调整、状态估计（卡尔曼滤波器）、路径规划（A*、RRT）</li><li>学习 ROS 2 以用于传感器融合和感知管道</li><li>使用 UgCS、QGroundControl、Mission Planner 进行任务规划实践</li></ul><p>第 3 层：专业应用（12 - 24 个月）</p><ul><li>实现 RTK GPS 集成，用于精准农业或测量工作</li><li>开发具有机械/电气接口和软件插件的定制载荷</li><li>为复杂任务构建行为树（多阶段交付、协同群组行动）</li><li>探索 AI 集成：计算机视觉（YOLO、SAM），用于控制的强化学习</li></ul><p>第 4 层：认证与部署（持续进行）</p><ul><li>了解空域规定（美国联邦航空局第 107/108 部分、欧洲航空安全局 SORA、当地相应规定）</li><li>设计冗余安全系统（双惯性测量单元、备用电源、地理围栏）</li><li>进行故障模式与影响分析（FMEA），记录故障应对措施</li><li>参与超视距飞行试点项目或商业部署</li></ul><p>开源起始点</p><ul><li>PX4 自动驾驶系统：<a href="https://link.segmentfault.com/?enc=2M7JP6Ok4gPdWMo%2F%2FKJQXQ%3D%3D.A8mwZfE%2FlUaZ6rXHTIrDMA%3D%3D" rel="nofollow" title="https://px4.io" target="_blank">https://px4.io</a>（BSD 许可证）</li><li>ArduPilot：<a href="https://link.segmentfault.com/?enc=76%2FL%2BVErUiuZNt2tt5%2ByIA%3D%3D.dkkC47aD8Y4gX5pAGI0MKfk5%2BoZWsu4eZq1k0ItmLXI%3D" rel="nofollow" title="https://ardupilot.org" target="_blank">https://ardupilot.org</a>（GPL v3）</li><li>QGroundControl：<a href="https://link.segmentfault.com/?enc=ny9ymViLFjVg12xmQlV47g%3D%3D.TMBZreexfRYWNVsYMbiXOboe7mr%2Be71AfvoSKS%2B1NwM%3D" rel="nofollow" title="http://qgroundcontrol.com" target="_blank">http://qgroundcontrol.com</a>（Apache 2.0）</li><li>任务规划器：<a href="https://link.segmentfault.com/?enc=jOXeowq63r4Xe%2FAhFfKywA%3D%3D.y0nNicIYxlfpj1qmfgwjry%2B3uDVVHgShw3P1dPv83Js%3D" rel="nofollow" title="https://ardupilot.org/planner" target="_blank">https://ardupilot.org/planner</a>（GPL v3）</li><li>ESP-Drone（LiteWing）：<a href="https://link.segmentfault.com/?enc=7GalvDYUaXGxaZuAQeKfwg%3D%3D.DuO%2FN10zaiW1JzqpH0OTJQS%2BX4OB%2FklVZZrVyADTyytMIBpwxRfbk9lgwfCEpaGO" rel="nofollow" title="https://github.com/espressif/esp-drone" target="_blank">https://github.com/espressif/esp-drone</a>（Apache 2.0）</li></ul><h2>结论：技术 + 领域专业知识 = 低空经济的成功</h2><p>低空经济的万亿规模发展红利不是什么人都能吃到，成功者会将深厚的技术能力（全栈无人机系统开发）与特定领域优化（农业、物流、检测、公共安全）相结合。</p><p>Skylight 无人机系统项目让我明白，80% 的价值来自于最后 20% 的个性化定制：农业喷头算法可根据每株植物的健康状况和 NDVI 区域来调整流量，包裹配送的释放机制带有降落伞安全装置，以及紧急着陆行为（根据风向和地形在三个备用地点中选择最佳着陆点）。</p><p>商用无人机将会走向标准化。市场会青睐那些能够设计定制化自动驾驶行为、整合新型传感器、针对特定负载进行优化，并适应不断变化的超视距飞行法规的工程师。掌握整个技术栈（从 STM32 软件到行为树再到 EASA SORA 合规性认证），就能构建出值得大规模部署的系统。</p><p>空域正在开放，工具是开源的。到 2025 年，市场规模将达到 2110 亿美元，并在 2035 年进一步增长至 4900 亿美元。到行动的时候了。</p><hr/><blockquote>你好，我是俞凡，在Motorola做过研发，现在在Mavenir做技术工作，对通信、网络、后端架构、云原生、DevOps、CICD、区块链、AI等技术始终保持着浓厚的兴趣，平时喜欢阅读、思考，相信持续学习、终身成长，欢迎一起交流学习。为了方便大家以后能第一时间看到文章，请朋友们关注公众号"DeepNoMind"，并设个星标吧，如果能一键三连(转发、点赞、在看)，则能给我带来更多的支持和动力，激励我持续写下去，和大家共同成长进步！</blockquote><p>本文由<a href="https://link.segmentfault.com/?enc=Ep0hFXbOlYsHWUvbnsfz4Q%3D%3D.S1STNLcQEgDfrgW7uB08NQd30rSvSI8ZQHUepaequ4M%3D" rel="nofollow" target="_blank">mdnice</a>多平台发布</p>]]></description></item><item>    <title><![CDATA[NeurlPS2025| 告别手动制表:]]></title>    <link>https://segmentfault.com/a/1190000047404287</link>    <guid>https://segmentfault.com/a/1190000047404287</guid>    <pubDate>2025-11-17 11:03:04</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>最近电子科技大学联合之江实验室的研究人员开发了 Table2LaTeX-RL，这是一个使用多模态语言模型和双奖励强化学习框架将表格图像转换为高保真 LaTeX 代码的系统。这种方法在复杂表上表现出卓越的性能，实现了 0.6145 的 CW-SSIM 和 0.9218 的 TEDS-Structure，同时保持了 0.9917 LaTeX 编译率。</p><h2>Introduction 简介</h2><p>表格是科学和技术文档的重要组成部分，为呈现定量数据、实验结果和复杂关系提供了结构化且简洁的格式。随着文档数字化变得越来越普遍，从图像自动生成表格代码的能力对于实现内容重用和高质量复制至关重要。然而，大多数现有方法专注于生成 HTML 表示 ，缺乏复杂表格所需的结构表现力和排版精度，尤其是那些具有嵌套标题、合并单元格或数学内容的表格。相比之下，LaTeX 是科学出版的标准，提供专业级表格所需的灵活性和保真度。尽管具有实际重要性，但从表格图像直接生成 LaTeX 代码的任务在之前的工作中受到的关注有限。</p><p>在这项工作中，我们研究了表格图像到 LaTeX 生成的任务，并对其挑战进行了全面分析。通过实证观察，我们发现主要的困难在于处理复杂的表格，这些表格通常很大、嵌套很深、语义丰富，结构自然适合 LaTeX，但模型很难准确预测。这些挑战既影响视觉编码器（必须提取细粒度的视觉和结构线索），也影响语言解码器（必须生成长的、语法敏感的 LaTeX 序列）。任一阶段的错误通常会导致幻觉、格式错误的输出，甚至编译错误。为了实现更细粒度的评估并更好地了解当前的研究差距，我们建议根据结构复杂性将数据集分为简单、中等和复杂子集。</p><p>为了应对这些挑战，我们利用预先训练的多模态大语言模型 (MLLM)，该模型在视觉识别、跨模态推理和 LaTeX 流畅性方面表现出强大的能力。我们在从 arXiv 上的科学文档中收集的大规模图像到 LaTeX 数据集上对 MLLM 进行微调。为了进一步提高性能（尤其是复杂表的性能），我们引入了一种基于组相对策略优化 (GRPO) 的双奖励强化学习策略，称为 VSGRPO。虽然标准 GRPO 方法仅基于文本输出来优化文本生成质量，但我们更进一步：将生成的 LaTeX 代码渲染为图像，并使用 CW-SSIM 直接评估视觉保真度。这种基于图像的奖励补充了从 LaTeX 源计算的结构级奖励，使我们能够共同优化结构准确性和渲染外观。这种新颖的视觉在环强化设计显着增强了模型为结构丰富且视觉复杂的表格生成忠实、高保真 LaTeX 代码的能力。</p><p>从评估的角度来看，现有的指标是有限的。 TEDS  是一种广泛使用的基于结构的度量，对细粒度错误缺乏敏感性，并且存在 HTML 和 LaTeX 之间不匹配的问题。另一方面，渲染图像比较指标关注局部视觉相似性，但忽略全局结构正确性。为了克服这个问题，我们采用了一种混合评估策略，该策略结合了用于结构保真度的 TEDS-Structure 和用于稳健视觉相似性的 CW-SSIM。</p><p>在此框架下，我们的方法在表格图像到 LaTeX 生成任务上实现了最先进的性能，尤其是对复杂表格的改进。这证明了将 MLLM 微调与有针对性的强化学习相结合以生成高保真、可发布的表格的有效性。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047404289" alt="图1.png" title="图1.png"/></p><p>&lt;center&gt;&lt;p&gt;图1: 演示我们提出的用于表格图像到 LaTeX 代码生成的 VSGRPO 框架。顶部部分显示了一个示例表格图像及其相应的 LaTeX 代码，代表训练中使用的输入输出对。中间部分说明了 VSGRPO 框架的工作流程。底部部分强调了双重奖励机制：通过 CW-SSIM 在模型生成的图像和真实渲染图像之间计算的视觉保真度&lt;/p&gt;&lt;/center&gt;</p><h2>挑战和动机</h2><p>将表格图像转换为 LaTeX 代码解决了文档处理中的几个基本挑战。传统的表格识别方法侧重于将内容提取为 HTML 格式，缺乏科学出版所需的复杂格式化功能。LaTeX 作为学术出版中的标准标记语言，提供了对表格结构、数学表达式和 HTML 无法充分表示的复杂布局的精确控制。</p><p>复杂的表格给现有方法带来了特别的困难。这些表的特点是嵌套结构、合并单元格和丰富的内容（包括数学符号），通常会导致当前方法失败或产生语法不正确的输出。作者认为这是一个关键差距，并指出，虽然现有工具可以充分处理简单表格，但科学文献中普遍存在的复杂表格仍然没有得到很好的解决。</p><h2>全新大规模数据集构建</h2><p>由于缺乏包含 LaTeX 表代码的公开可用的大规模数据集，我们提出了一个数据集构建管道。具体来说，我们开发了一个网络爬虫，从开放访问的 arXiv 存储库中抓取科学论文的 LaTeX 源文件。我们使用正则表达式来提取与表环境相对应的 LaTeX 代码。为了确保数据质量，我们通过删除引用、颜色设置和其他 LaTeX 控制命令来进一步清理提取的代码。通过这个过程，我们收集了一个包含 1,209,986 个表格-LaTeX 对的数据集。为了对表格复杂性进行分类，具有 2 个或更多 \multirow 或 \multicolumn 命令和 100-160 个单元格的表格被定义为中等表格，而那些超过 160 个单元格的表格被标记为复杂表格。所有其他的都被认为是简单的。在训练集中，简单表约占 94%，而中型表和复杂表各约占数据的 3%。</p><h2>方法：VSGRPO 框架</h2><p>如图1所示，论文的核心创新是 VSGRPO（视觉和结构引导的群体相对策略优化），这是一个双奖励强化学习框架，解决了单独监督微调的局限性。</p><p>为了使通用多模态大语言模型（MLLM）获得处理表格到 LaTeX 生成任务的初步能力，我们首先在 Table2LaTeX 数据集上对预训练的 MLLM 进行标准监督微调 （SFT）。InternVL2-1B 和 Qwen2.5-VL-3B 等模型经过训练。然而，如表 4 所示，仅 SFT 不足以完全释放模型的潜力。一个关键的限制源于teacher forcing的广泛使用，其中模型被训练为预测给定前缀的下一个标记。然而，LaTeX 代码本质上是不明确的——不同的语法形式（例如样式类的语法）可能会产生相同的视觉输出。培训监督和评估目标之间的不匹配会导致泛化效率低下，特别是对于结构复杂的表格，因此我们进一步进行了强化学习。</p><h3>双重奖励强化学习</h3><p>如上所述，SFT 中使用的下一个标记预测范式在对长 LaTeX 序列中嵌入的语义结构和句法依赖关系进行建模的能力方面受到限制。此外，SFT 目标仅关注文本级对齐，完全忽略了渲染的 LaTeX 输出与原始表格图像之间的视觉相似性 - 尽管视觉外观是生成质量的直接且关键的指标。然而，由于 LaTeX 渲染是不可微的操作，因此它不能直接纳入基于梯度的监督训练中。</p><p>为了解决这些限制，我们提出了一种新颖的强化微调框架，它将渲染图像反馈作为显式优化信号引入。受到组相对策略优化（GRPO）的启发，我们将其范围扩展到标准文本质量评估之外，并设计了一种双重奖励机制，共同促进结构准确性和视觉保真度。虽然传统的基于 GRPO 的方法仅专注于提高文本生成质量，但我们的框架利用了 LaTeX 代码结构及其渲染外观，提供了更加与任务一致的监督信号。我们从训练数据集中选择 5,936 个复杂表作为 VSGRPO 的训练集，其真实 LaTeX 代码包含少于 3,000 个字符，以平衡复杂性和计算可行性。</p><p><strong>1.视觉奖励</strong>：将生成的 LaTeX 代码编译为 PDF，然后转换为 PNG 格式，以便使用 CW-SSIM（复小波结构相似性指数）与地面实况表图像进行比较。CW-SSIM 采用专门适用于二进制表图像的 Haar 小波变换。奖励为二进制：如果 CW-SSIM 超过 0.6，则为 1，否则为 0。</p><p>为了适应黑白表格图像，我们采用以下CW-SSIM计算过程：CW-SSIM算法对两张表格图像进行预处理，将它们转换为灰度，将它们调整为统一尺寸，并对齐它们的行和列。然后，它将图像划分为 2×2 像素块，并应用简化的 Haar 小波变换将每个块分解为四个子带：cA（低频近似）、cH（水平）、cV（垂直）和 cD（对角高频细节）。对于每个子带，该算法计算针对单色表优化的 SSIM 指标，结合像素级均值、方差、协方差以及稳定常数 C_1 和 C_2。最后，它对所有四个子带的 SSIM 分数进行平均，以生成综合的 CW-SSIM 指标。</p><p><strong>2.结构奖励</strong>：生成的 LaTeX 和真实 LaTeX 都转换为 HTML 表示，然后使用 TEDS-Structure（基于树编辑距离的相似性）进行比较。该指标侧重于结构一致性，同时忽略内容差异。如果 TEDS-Structure 超过 0.9，则奖励为 1，否则为 0。</p><h2>实验结果与分析</h2><p>我们将 VSGRPO 与不同类别的各种解决方案进行比较。在商业和付费领域，我们根据迄今为止最强大的系统 Mathpix 对其进行评估。为了与当前的通用多模态大型模型进行比较，我们包括闭源 GPT-4o，以及开源 Qwen2.5-VL-72B  和 Intern2.5-VL-78B。对于专门的专家模型，我们与最先进的开源 LaTeX 生成系统 Nougat 进行比较。  为了更准确地评估 LaTeX 生成的正确性，我们从两个互补的角度评估模型性能：渲染图像质量和 LaTeX 源保真度。首先，我们通过将生成的 LaTeX 编译成表格图像来评估其视觉准确性。使用两个指标：编译率（反映可以使用标准 LaTeX 包成功编译的 LaTeX 输出的比例）和 CW-SSIM（量化渲染输出与真实图像之间的视觉相似性）。这些结果如表 1 所示。其次，我们评估 LaTeX 源代码本身的语义和结构正确性。为此，我们计算 TEDS-Structure（测量细胞级结构对齐）和 TEDS（另外考虑表格内容）。这些指标可以更深入地了解生成的代码捕获底层表语义的程度，并在表 2 中进行了总结。为了进一步评估我们的方法的泛化能力，我们另外在中引入的外部基准数据集（具体可见论文中介绍）上对其进行了测试，结果如表 3 所示。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047404290" alt="表1.png" title="表1.png" loading="lazy"/></p><p>&lt;center&gt;&lt;p&gt;表1：不同模型在三类表格上的CW-SSIM 性能以及编译率&lt;/p&gt;&lt;/center&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047404291" alt="表2.png" title="表2.png" loading="lazy"/></p><p>&lt;center&gt;&lt;p&gt;表2：不同模型在三类表格上的TEDS 和 TEDS-Structure 性能&lt;/p&gt;&lt;/center&gt;</p><p>表 2 显示了 TEDS 和 TEDS-Structure 指标的结果。 TEDS 分数的趋势很大程度上反映了 TEDS-Structure 的趋势，尽管由于 TEDS 额外考虑了单元格内容对齐，绝对值始终较低。商业工具 Mathpix 在各种表类型中表现出相对稳定的性能，在中等复杂性表上获得了最高的 TEDS-Structure 得分 (0.8965)。在通用 VLM 类别中，Qwen2.5-VL-72B 显示出始终如一的强大结构性能，在简单表格上的 TEDS-Structure 得分最高 (0.9400)。然而，随着复杂性的增加，它的性能逐渐下降——TEDS从0.8720（简单）下降到0.8090（中）和0.7448（复杂）。相比之下，其他大型模型（例如 Intern2.5-VL-78B）在复杂表上的表现急剧下降（TEDS：0.3379），而专家模型 Nougat 几乎完全崩溃（TEDS：0.0424），揭示了结构和内容级别泛化方面的严重局限性。相比之下，我们提出的 Qwen2.5-VL-3B-VSGRPO 在所有级别的表复杂性上都取得了一致的优异结果。尽管其尺寸紧凑（3B 参数），但它的性能明显优于更大的模型，在复杂表上达到 0.8673 的 TEDS 分数（比次优模型高出 0.1225），并实现 TEDS-Structure 分数 0.9218，这是第一个在复杂表上超过 0.9 阈值的模型。这些结果强调了我们的双重奖励优化策略的有效性，该策略集成了结构和视觉监督，以实现健壮、高保真的 LaTeX 代码生成，特别是对于结构丰富且视觉复杂的表格。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047404292" alt="表3.png" title="表3.png" loading="lazy"/></p><p>&lt;center&gt;&lt;p&gt;表3：在外部数据集CW-SSIM和TEDS-Structure的实验比较&lt;/p&gt;&lt;/center&gt;</p><h3>人工评估</h3><p>为了补充自动化指标并更好地捕捉感知的视觉质量，我们对 200 个随机选择的表格（50 个简单表格、50 个中等表格、100 个复杂表格）进行了人类偏好研究，如 C 部分所示。对于每种情况，四个模型的渲染输出与真实图像一起匿名显示。多名人类评估员独立对视觉上最相似的结果进行投票，最终决定由多数投票决定。如表 4 所示，Qwen2.5-VL3B-VSGRPO 在所有难度级别上获得了最高的票数，在视觉和结构保真度方面明显优于其他模型。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047404293" alt="表4.png" title="表4.png" loading="lazy"/></p><p>&lt;center&gt;&lt;p&gt;表 4：人工评估结果&lt;/p&gt;&lt;/center&gt;</p><h2>结论和局限性</h2><p>我们的工作通过将视觉语言建模与有针对性的强化学习相结合，解决了将表格图像转换为语法正确、出版质量的 LaTeX 代码的挑战。我们利用预先训练的多模态大语言模型 (MLLM)，在不同的科学表格图像语料库上对其进行微调，并通过双重奖励方案进一步增强它：一个奖励使用 TEDS-Structure 评估结构完整性，而另一个奖励通过渲染输出上的精细 CW-SSIM 测量视觉保真度。通过联合优化这些目标，该模型能够准确捕获复杂的表格布局（包括嵌套标题、合并单元格和数学表达式），并生成与原始视觉外观紧密匹配的输出。</p><p><strong>局限：</strong>尽管 VSGRPO 有效提高了复杂表上的 MLLM 性能，但它在训练过程中引入了显着的计算开销。具体来说，每个 LaTeX 输出都必须渲染为 PDF，然后转换为 PNG 图像以进行 CW-SSIM 计算——这是一个耗时的过程，即使使用多线程，也会造成训练瓶颈。由于这种开销和有限的 GPU 资源，我们仅在 5,936 个复杂表上训练 VSGRPO。</p>]]></description></item><item>    <title><![CDATA[Spring AI 1.1 正式发布，太]]></title>    <link>https://segmentfault.com/a/1190000047404306</link>    <guid>https://segmentfault.com/a/1190000047404306</guid>    <pubDate>2025-11-17 11:02:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>大家好，我是R哥。</p><p><a href="https://link.segmentfault.com/?enc=ybbAGvJ8iWGnAokrVP%2FFXg%3D%3D.e2CRudzV9uqYQBezBXYQkluP3SEHuKSb2TSswnOSBXL6LWUS%2FHNAkWxbVXjtPyQN8UtiAYayd%2Ba7IAlPNHmDsw%3D%3D" rel="nofollow" target="_blank">Spring Al 1.0</a> 发布半年过去了，Spring AI 1.1 终于正式发布了：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047404308" alt="" title=""/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047404309" alt="" title="" loading="lazy"/></p><p>Spring AI 1.1 这个版本真给力啊，不仅把 Model Context Protocol 给整合进来了，还大大提升了 AI 能力，在各个领域都带来了实实在在的提升，支持的模型提供商也更多了。</p><p><strong>一些数据：</strong></p><ul><li><strong>850</strong>+ 项改进；</li><li><strong>354</strong> 项增强，包括新功能和集成；</li><li><strong>241</strong> 个 bug 修复，增强了稳定性和可靠性；</li><li><strong>100</strong> 处文档优化，还加上了新指南和示例；</li><li><strong>23</strong> 个安全更新和依赖升级；</li></ul><p>Spring AI 1.1 光是优化、修 bug 和更新文档就超过了 <strong>850</strong> 项，这效率真是没得说。</p><hr/><h2>Spring AI 1.1 新特性一览</h2><h3>1、Model Context Protocol（MCP）</h3><p>MCP 不懂的看看这篇 MCP 教程：</p><blockquote><a href="https://link.segmentfault.com/?enc=lg06TDUIrLKNJcT36vUhxw%3D%3D.7jo8gxvN05xEfRLzinn%2FM7dZSuan2Kapnj82tJp3Yrl5ZDCk5fVJuH8BNvbB2WN%2FcosLHI9vSB7tS8Df66hdYw%3D%3D" rel="nofollow" target="_blank">最近热火朝天的 MCP 是什么鬼？如何使用MCP？一文给你讲清楚！</a></blockquote><p>模型上下文协议（MCP）是 Spring AI 1.1 中最具显著特色的功能集改进，Spring AI 提供了 <strong>Spring Boot 自动配置</strong>以及用于 MCP 集成的全面的<strong>基于注解</strong>的编程模型。</p><p><strong>基于注解的编程模型：</strong></p><pre><code class="java">@McpTool
public String getCurrentWeather(String location) {
    // 工具实现
}

@McpResource
public String getDatabaseSchema() {
    // 资源实现
}

@McpPrompt
public String generateSqlQuery(String userIntent) {
    // 提示词模板实现
}</code></pre><p>推荐阅读：<a href="https://link.segmentfault.com/?enc=wZv2NoMJhezfqdqituTXUQ%3D%3D.vRINlpA%2Bkz4cjjM0BlLgNfLMr%2BFyw1maDYGL2SEez7P4BTxqOBrYE8NaC7th9T%2FiAdZHY%2FWgeHd0lcxgNZu%2F7g%3D%3D" rel="nofollow" target="_blank">从零开始开发一个 MCP Server！保姆级教程！</a></p><p><strong>多种传输方式随便选：</strong></p><ul><li>本地进程通信的 STDIO 传输方式；</li><li>基于 Web 集成的 HTTP SSE（服务器发送事件）；</li><li>支持状态管理及恢复功能的可流式 HTTP 用于会话管理；</li></ul><p>Spring Boot 自动配置提示了多个专门的启动器，可在 <strong>WebFlux、WebMVC 和 Servlet</strong> 环境下都能同时支持客户端和服务端的实现。</p><p>再加上 <strong>Docker Compose 和 Testcontainers</strong> 的集成，让 MCP 网关的容器化部署变得特别顺手，简直不要太方便。</p><p>安全集成这块，也提供了用于保护 MCP 服务器的 <strong>OAuth2</strong> 集成模式。</p><h3>2、提示词缓存</h3><p>Spring AI 1.1 这次给 <strong>Anthropic Claude 和 AWS Bedrock</strong> 加了 prompt 缓存功能，<strong>成本能降高达 90%</strong>，响应速度还变快了，简直太香了！</p><p>比如 <strong>Spring AI 为 Claude 提供五种缓存策略</strong>，包括不缓存、仅缓存系统消息、仅缓存工具定义、两者都缓存，以及按会话历史递增缓存，并支持 5 分钟和 1 小时的 TTL，还能自动管理缓存与判断是否可缓存。</p><p>另外，AWS Bedrock 的 Converse API 也为 Claude 与 Nova 模型提供提示缓存，让在 AWS 上部署的应用能降低成本、提升响应效率。</p><h3>3、推理和思考模式支持</h3><p>Spring AI 1.1 为具备多种供应商支持的推理能力的 AI 模型提供了原生支持：</p><ul><li>Ollama</li><li>ZhipuAI</li><li>Anthropic</li><li>OpenAI</li></ul><p>这个 <code>ReasoningContent</code> API 真是太顶了，让应用能直接查看和用上模型的思考过程，简直方便到家了！</p><h3>4、自进化 AI Agent 递归顾问</h3><p>新的递归顾问功能使顾问能够通过链式方式调用其他顾问，从而构建出复杂的多步骤人工智能工作流程。</p><p>有两个内置的递归顾问实现方式，为常见的用例提供了预配置的模式，并且具有可配置的观察功能，用于监控和调试。</p><p>这个功能牛啊，<strong>能打造出自己不断优化的 AI 小助手，通过反复迭代来提升输出质量</strong>。</p><p>Christian Tzolov 的博客里就举了个例子，教你怎么用 Spring AI 的递归顾问来打造这种自我进化的 AI Agent，有兴趣的可以去看下。</p><h3>5、全新大模型供应商集成</h3><p><strong>Google GenAI SDK 集成：</strong></p><ul><li>原生支持 Gemini Pro、Gemini 1.5 Pro 和 Gemini 2.0 Flash 模型；</li><li>提供 API 密钥和 Google Cloud 凭据双重认证；</li><li>聊天和文本嵌入功能；</li><li>缓存内容 API 支持；</li></ul><p><strong>ElevenLabs 文本转语音：</strong></p><ul><li>实时音频生成；</li><li>多种语音选择；</li><li>支持各种音频格式；</li></ul><p>OpenAI 和 ElevenLabs 都实现了这个 <code>TextToSpeechModel</code> 接口，让不同供应商的模型都能用一套统一的 API，真是太方便了。</p><h3>6、大模型支持升级了</h3><p>各大模型支持升级了，比如：</p><ul><li>OpenAI 推出 GPT-5 系列（含 gpt-5、gpt-5-mini、gpt-5-nano）、文件管理 API、强化推理内容访问、以及更完善的语音合成与转录模型。</li><li>Anthropic 更新到 Sonnet 4.5 与 Opus 4.1，同时加入引用追踪 API、工具调用控制，以及更强的提示缓存管理。</li><li>Mistral 则提供 OCR 文本提取接口、Codestral 嵌入模型，并改进构建模式。</li><li>智谱进一步上线 GLM-4.6、GLM-4.5、GLM-Z1，并强化思考模式与国际站支持。</li></ul><p>所以整体是对各大模型生态在模型能力、API、工具及功能一致性上的集中升级。</p><h3>7、向量库、聊天记忆和可观测性</h3><p>Spring AI 1.1 在向量检索、聊天记忆与可观测性方面也全面升级了：</p><ul><li>在向量库部分，增加了 MariaDB 的向量存储、OpenSearch 的近似 k-NN、GemFire 的元数据过滤以及 Weaviate 的配置增强，并提供只读的 VectorStoreRetriever 接口，让 RAG 应用更高效安全；</li><li>在聊天记忆方面，提供 MongoDB、Oracle JDBC 与 Azure Cosmos DB 多种存储方案，方便分布式或企业级部署；</li><li>在可观测性上，通过 Micrometer 增强上下文传递、聊天客户端日志记录、可配置的拦截观察，以及更完善的 Prometheus 与 OpenTelemetry 指标文档。</li></ul><p>所以整体是对<strong>检索、记忆、监控</strong>三大模块的功能强化。</p><h3>8、其他改进</h3><p>Spring AI 1.1 还有一些其他方面的改进：</p><ul><li><strong>MCP Java SDK 演进</strong>：在 1.1 开发周期中从 v0.10.0 提升到 v0.15.0。</li><li><strong>文档处理（docs）</strong>：新增支持批处理，并强化多模态 PDF 处理能力。</li><li><strong>开发者体验</strong>：在 EmbeddingOptions 和 ChatOptions 中统一了构建器模式。</li><li><strong>网络可靠性</strong>：为分布式部署提供自动重试配置。</li><li><strong>安全文档</strong>：提供包含 OAuth2 模式的 MCP 安全参考。</li><li><strong>示例仓库</strong>：共 37 个模块，其中 24 个包含集成测试。</li></ul><hr/><h2>总结</h2><p>Spring AI 1.1 这个版本更新真多，真不是简单的修修补补。</p><p>从 MCP 协议的引入，到对主流模型支持的全面升级，再到缓存、推理、自进化 Agent 和向量库、记忆体系等多模块的能力增强，整个框架的智能化和实用性都大幅提升了。</p><p>不光 OpenAI、Anthropic、智谱这些大厂支持更好了，Google 和 ElevenLabs 也都顺利接入，AI 模型供应商直接翻倍。</p><p>而且还有 Prompt 缓存带来的成本大减，递归顾问提升智能程度，还有一整套可观测性方案让你上线无压力。</p><p>还没用过 Spring AI 的可以看看这篇：</p><blockquote><a href="https://link.segmentfault.com/?enc=me%2BvvpEbTDceA9pkVy9XBg%3D%3D.MxFkI4HF5OJQUBhDEUq%2Fv1XrsXnhfiaxlPYqthNbl5VBry2P7qM4bIjKiSmaTNkNUDP%2Fb8QSBQmPHHo1TepLQQ%3D%3D" rel="nofollow" target="_blank">Spring Boot + DeepSeek 实战来了：完美运行！</a></blockquote><p>不管你是 AI 初学者，还是经验丰富的开发者，Spring AI 都能帮助你快速上手，轻松实现业务中的 AI 集成。</p><p>Spring AI 现在已经成为 Java 程序员不可或缺的标配技术，<strong>Spring AI 让 Java 再次伟大！！</strong></p><p>赶紧试试吧，感受 AI 的魅力吧！太强了！</p><blockquote><strong>版权声明：</strong> 本文系公众号 "Java技术栈" 原创，转载、引用本文内容请注明出处，抄袭、洗稿一律投诉侵权，后果自负，并保留追究其法律责任的权利。</blockquote>]]></description></item><item>    <title><![CDATA[2024年低代码开发趋势报告 信码由缰 ]]></title>    <link>https://segmentfault.com/a/1190000047404325</link>    <guid>https://segmentfault.com/a/1190000047404325</guid>    <pubDate>2025-11-17 11:01:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047404327" alt="" title=""/></p><hr/><h2>欢迎信</h2><p>作者：Lucy Marcum, DZone组稿编辑</p><p>我偶然进入了科技世界。尽管我毕业于一所以其计算机科学项目闻名的大学，但我从未想过自己会与开发人员一起工作——直到毕业后与一位朋友讨论可能的职业道路时。科技世界对我来说曾经如此陌生，但在她的鼓励和我那令人紧张的人脉拓展努力下，我找到了在这个行业的第一份工作。</p><p>在最初的几个月里，一切都感觉极其陌生。像<strong>Kubernetes</strong>和<strong>NoSQL</strong>这样的术语让我困惑不已，我大部分时间都沉浸在研究中，学习在新职位上取得成功所需了解的一切。</p><p>当时我没有意识到的是，我已经以不同的形式接触过软件开发：<em>低代码和无代码</em>。为了几个大学项目，我使用无代码构建器创建网站来展示研究或概念，偶尔也涉足代码进行自定义调整（在大量搜索之后）。</p><p>现在，即使多年后对开发有了概念性的理解，我仍然不声称自己是开发人员。但我确实认识到让非开发人员能够接触开发的重要性。正如我需要在工作中向其他团队寻求帮助一样，开发人员也需要帮助。</p><p>赋能非开发人员参与与其任务相关的开发，使得开发人员有时间专注于能产生更大组织影响的更大问题和项目。</p><p>将我曾使用的无代码工具与某种形式的软件开发联系起来，是让我的工作感觉易于上手的关键。我知道你们中的许多开发人员读到这儿可能笑了，但有时，正是像第一个"顿悟"时刻这样的小事，能让人在新环境中感到舒适。另一方面，当开发人员意识到通过这些工具所能获得的支持时，他们可能会发现自己的工作流程变得更加顺畅高效。</p><p>在DZone的《2024年<em>低代码开发</em>趋势报告》中，我们探讨了低代码在当今开发环境中的重要性。特别是"主要研究发现"部分，回顾了采用情况、自动化、AI的角色以及对开发人员的影响——包括关于谁可以被视为开发人员的一个令人惊讶的混合反应。本趋势报告还包括DZone几位专家社区成员的文章，他们讨论了最佳实践、低代码与AI之间的界限、智能测试策略、公民开发和可扩展性。</p><p>祝编码愉快（各种形式的编码），</p><p><em>Lucy</em></p><blockquote><p>Lucy Marcum</p><p>Lucy负责DZone出版物的组稿流程和策略，从寻找新的投稿人和社区成员到引导他们完成编辑审查。她还编辑出版物，创建趋势报告的各个组成部分，并与网站内容和社区团队合作。工作之余，Lucy把时间花在阅读、写作、跑步上，并努力不让她的猫Olive和Tiger Lily惹麻烦。</p></blockquote><hr/><h2>主要研究发现</h2><p><strong>DZone 2024低代码开发调查结果分析</strong><br/><em>作者：G. Ryan Spain, 自由软件工程师，前DZone工程师兼编辑</em></p><p>低代码、无代码、公民开发、AI自动化、可扩展性——如果你在科技界工作，你很可能会被鼓励使用至少其中一个领域的工具。这是有充分理由的，因为Gartner预测，到2025年，组织内开发的应用程序中有70%将使用低代码和/或无代码技术构建。<em>那么，实践是否不负众望呢？</em></p><p>年复一年，随着行业的不断发展，答案是响亮的"是"。组织对更频繁的应用程序发布和更新的需求增加，随之而来的是对提高效率的需求。而这正是低代码和无代码开发实践大放异彩的地方。将AI自动化融入低代码和无代码开发中，可扩展性和机遇是无限的。</p><p>五月，DZone对软件开发人员、架构师和其他IT专业人士进行了调查，旨在深入了解低代码开发在软件开发领域的现状。</p><p>在这些发现中，我们考察了开发人员对低代码和无代码开发的看法、他们使用和利用低代码工具的方式，以及他们对低代码影响软件开发的经验。</p><h3>方法</h3><p>我们创建了一项调查，并将其分发给全球的软件专业人士。问题格式主要包括单项和多项选择，在某些情况下提供填写回答的选项。本次调查通过电子邮件分发给DZone和TechnologyAdvice的注册订阅用户列表，同时在DZone官网、DZone Core Slack工作区及各社交媒体渠道进行了推广。</p><p>本报告的数据收集自2024年5月3日至2024年5月23日期间提交的调查回复；我们收集了228份完整和部分回复。</p><h3>样本特征</h3><p>我们在下面注明了某些关键的受众细节，以便对得出结果的样本建立更牢固的印象：</p><ul><li>29%的受访者将其在组织中的主要角色描述为"开发人员/工程师"，18%描述为"技术架构师"，14%描述为"开发团队负责人"，10%描述为"顾问/解决方案架构师"。我们提供的其他角色均未被超过10%的受访者选择。*</li><li>70%的受访者表示他们目前正在开发"Web应用程序/服务（SaaS）"，54%表示"企业业务应用程序"，27%表示"原生移动应用"。</li><li>"Java"（72%）是受访者公司使用的最流行的语言生态系统，其次是"JavaScript（客户端）"（54%）、"Python"（53%）、"Node.js（服务器端JavaScript）"（45%）、"TypeScript"（41%）和"C#"（30%）。</li><li>关于受访者工作中使用的主要语言的回答，最流行的是"Java"（37%），其次是"Python"（17%）、"C#"（7%）和"Go"（6%）。其他语言的选择率均未超过5%。</li><li>平均而言，受访者表示他们拥有17.99年的IT专业人士经验，中位数为18年。</li><li>35%的受访者在员工人数&lt;100的组织工作，25%在员工人数100-999的组织工作，38%在员工人数1000+的组织工作。</li></ul><p><em>注：为简洁起见，在本发现报告的其余部分，我们将使用术语"开发人员"或"开发者"来指代任何积极参与软件创建和发布的人员，无论其角色或头衔如何。此外，我们将"小型"组织定义为员工人数&lt;100，"中型"组织定义为员工人数100-999，"大型"组织定义为员工人数1000+。</em></p><h3>主要研究目标</h3><p>在我们的2024年低代码开发调查中，我们旨在收集与以下主要研究目标相关的各种主题的数据：</p><ul><li>开发人员对低代码的感受</li><li>开发人员如何使用低代码或与低代码交互</li><li>低代码对开发和软件质量的影响</li></ul><p>在本报告中，我们回顾了一些关键的研究发现。许多感兴趣的次要发现未包含在此处。</p><h4>研究目标一：开发人员对低代码的感受</h4><p>首先，我们想看看开发人员对低代码采用如何融入整体开发格局的看法，低代码如何影响开发过程，以及他们认为低代码在哪些方面（如果有的话）可以表现出色。我们还旨在找出参与调查的开发人员类型，无论是前端、后端、全栈还是公民开发者。</p><p>在本节中，我们探讨：</p><ul><li>受访者如何描述自己作为开发人员</li><li>开发人员是否认为"无代码"是"低代码"的子集</li><li>开发人员是否认为低代码用户也是"开发人员"</li><li>开发人员关于低代码平台如何影响开发过程的看法</li><li>开发人员认为哪些用例最适合低代码</li></ul><h5>受访者如何描述自己作为开发人员</h5><p>从"AWS解决方案架构师"到"Zapier工程师"，世界上软件专业人士的种类比我们可能开始列举的还要多，一个开发人员可能会根据他们当前正在进行的项目、他们正在与谁交谈、他们希望深入探讨其角色细节的程度等，声称自己属于任何数量的IT相关类别。尽管如此，拥有某些广泛的类别来对我们自己进行分组可能是有用的——不仅是为了便于澄清，也是为了庆祝相似性和欣赏差异性。</p><p>在我们的调查中，我们希望明确区分的一个分类是受访者在少数几个"角色"之间的自我认同："前端"、"后端"、"全栈"和"公民"开发者。我们从这里开始，不是因为结果本身说明了开发人员对低代码的感受，而是因为我们将在这些发现中持续引用这些数据。我们询问受访者：</p><p><em>您会如何最好地描述自己？</em><br/>结果：<br/><strong>图1.</strong> 自我描述的开发人员类型 [n=220]</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047404328" alt="" title="" loading="lazy"/></p><p>（图表数据翻译：）</p><ul><li>后端开发者：39%</li><li>全栈开发者：37%</li><li>其他，请填写：14%</li><li>公民开发者：7%</li><li>前端开发者：3%</li></ul><p><strong>观察</strong></p><ul><li>考虑到我们典型的企业开发人员受众，绝大多数受访者将自己描述为"后端开发者"（39%）或"全栈开发者"（37%）并不奇怪，其中7%将自己描述为"公民开发者"，只有3%将自己描述为"前端开发者"。14%的受访者选择了"其他，请填写"，填写选项包括"架构师"、"经理"、"数据工程师"和"测试工程师"。</li><li>这些结果与我们2023年Web、移动和低代码开发调查收集的结果非常相似。"后端开发者"的回复率与2023年相比保持不变，"前端开发者"和"公民开发者"的回复率变化在统计上不显著。"全栈开发者"的回复率略有下降，同时选择"其他，请填写"选项的受访者有所增加。</li><li>我们预计这些轻微的逐年变化归因于样本特征的变化（例如，去年38%的受访者将其在组织中的主要角色描述为"开发人员/工程师"，而今年为29%）以及普遍存在的抗拒"把自己框定"的心态。按年份划分的结果详情见表1。</li></ul><p><strong>表1.</strong> 自我描述的开发人员类型：2023年 vs. 2024年</p><table><thead><tr><th align="left">开发人员类型</th><th align="left">2023</th><th align="left">2024</th></tr></thead><tbody><tr><td align="left">后端</td><td align="left">39%</td><td align="left">39%</td></tr><tr><td align="left">全栈</td><td align="left">45%</td><td align="left">37%</td></tr><tr><td align="left">公民</td><td align="left">3%</td><td align="left">7%</td></tr><tr><td align="left">前端</td><td align="left">8%</td><td align="left">3%</td></tr><tr><td align="left">其他</td><td align="left">4%</td><td align="left">14%</td></tr></tbody></table><ul><li>就其本身而言，从这个问题的回答收集的数据表明——毫不奇怪——企业中<strong>很少</strong>有软件专业人士认为自己是公民开发者。逐年的结果可能预示着未来企业软件中公民开发者数量的增长，但即使如此，似乎在未来许多年也不太可能出现显著增长。正如我们之前提到的，这个问题的结果主要是在用于按开发人员类型细分其他回答时才引起兴趣。由于"公民"、"前端"和"填写"选项的回复率较低，在本发现报告的剩余部分，我们将把这个问题回答分组为"后端"、"全栈"和"非后端/全栈"。</li></ul><h5>低代码、无代码与"开发人员"头衔</h5><p>开发人员可能非常保护他们的技能组合，并警惕那些他们认为试图在没有适当考虑软件创建所有方面的情况下强行进入开发领域的人。通常，这些感觉并非源于试图设限，而是源于制作拙劣的软件可能产生深远的后果。</p><p>构建一个实现预期目标的函数不一定困难，但理解该函数对系统稳定性、性能和安全性影响则完全是另一回事，更不用说概念化该函数在未来系统扩展时的需求和影响了。因此，低代码对于一些开发人员来说可能是一个有争议的话题，为了了解更多他们的看法，我们询问：</p><p>*您个人是否认为"无代码"开发是"低代码"开发的一个子集？<br/>同意/不同意："开发人员"头衔也应适用于仅使用低代码工具创建应用程序且可能从未自己编写任何代码的人。*</p><p>结果：</p><p><strong>图2.</strong> "无代码"是"低代码"吗？[n=219]</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047404329" alt="" title="" loading="lazy"/><br/>（图表数据翻译：）</p><ul><li>是：53%</li><li>否：32%</li><li>无意见：16%</li></ul><p><strong>图3.</strong> 严格使用低代码的用户应该拥有"开发人员"头衔吗？[n=210]<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047404330" alt="" title="" loading="lazy"/><br/>（图表数据翻译：）</p><ul><li>中立：28%</li><li>不同意：20%</li><li>同意：19%</li><li>非常不同意：17%</li><li>非常同意：16%</li></ul><p><strong>观察</strong></p><ul><li>大约一半的受访者（53%）认为无代码属于低代码范畴，而32%认为这两个概念是分开的，16%对此事没有意见。</li><li>大约相同比例的后端开发者和全栈开发者认为无代码是低代码的子集，尽管后端开发者比全栈开发者更可能"无意见"，并且比全栈开发者更不可能回答他们不认为无代码是低代码的一部分。非后端/全栈开发者最可能认为无代码包含在低代码中，并且最不可能回答"无意见"。这些结果的详细信息见表2。</li></ul><p><strong>表2.</strong> "无代码"是"低代码"吗？（按开发人员类型细分）*</p><table><thead><tr><th align="left">回复</th><th align="left">开发人员类型</th></tr></thead><tbody><tr><td align="left"> </td><td align="left">后端</td><td align="left">全栈</td><td align="left">非后端/全栈</td></tr><tr><td align="left">是</td><td align="left">49%</td><td align="left">51%</td><td align="left">62%</td></tr><tr><td align="left">否</td><td align="left">28%</td><td align="left">36%</td><td align="left">31%</td></tr><tr><td align="left">无意见</td><td align="left">22%</td><td align="left">14%</td><td align="left">8%</td></tr></tbody></table><p><em>*列为百分比</em></p><ul><li>在后面的发现中，我们讨论了表明全栈开发者比后端开发者更频繁地使用低代码的数据。那么，全栈开发者对"低代码"和"无代码"区分更明确的看法，可能基于这种额外的熟悉度。也许他们的经验表明，"无代码"解决方案通常比"低代码"平台提供更少的灵活性和定制化，而低代码平台允许开发者根据需要<em>扩展和定制应用程序</em>。</li><li>受访者对于是否应将可能从未编写任何实际代码的低代码工具用户视为"开发人员"存在相当分歧：大约三分之一的受访者倾向于同意这一观点（35%），大约三分之一不同意（37%），大约三分之一保持中立（28%）。后端开发者比全栈工程师更可能不同意或强烈不同意这类低代码用户应被称为"开发人员"（44% vs 32%），而全栈开发者比后端开发者更可能同意或强烈同意（39% vs 28%）。</li></ul><h5>低代码 vs. 全代码：关于开发过程的看法</h5><p>在某些情况下，低代码和全代码的软件创建方法可能被视为旨在实现相同目标的两种方法。在其他情况下，低代码工具可能被认为适用于某些目标，而全代码开发适用于其他目标。我们想知道开发人员对于使用低代码工具创建的软件与完全编码的软件在复杂性、可重用性和开发易用性方面的根本差异的看法，因此我们提出了以下问题：</p><p>*您认为使用低代码工具构建的应用程序相对于完全用代码编写的应用程序应该有多复杂？<br/>在您看来，调试低代码应用程序或与低代码应用程序交互的软件是...<br/>在您看来，使用低代码工具实现的业务逻辑是...<br/>在您看来，使用低代码平台构建的软件会导致...*</p><p>结果：</p><p><strong>图4.</strong> 关于低代码 vs. 全代码应用程序复杂性的看法 [n=220]<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047404331" alt="" title="" loading="lazy"/><br/>（图表数据翻译：）</p><ul><li>稍微简单一些：39%</li><li>简单得多：19%</li><li>与全代码应用程序一样复杂：16%</li><li>稍微复杂一些：11%</li><li>无意见：9%</li><li>复杂得多：3%</li></ul><p><strong>图5.</strong> 关于低代码 vs. 全代码调试易用性的看法 [n=218]<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047404332" alt="" title="" loading="lazy"/><br/>（图表数据翻译：）</p><ul><li>更难：25%</li><li>更容易：22%</li><li>无意见：19%</li><li>可能更难：19%</li><li>可能更容易：9%</li></ul><p><strong>图6.</strong> 关于低代码 vs. 全代码业务逻辑可重用性的看法 [n=211]<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047404333" alt="" title="" loading="lazy"/><br/>（图表数据翻译：）</p><ul><li>可重用性更低：36%</li><li>可重用性更高：39%</li><li>可重用性相同：17%</li><li>无意见：8%</li></ul><p><strong>图7.</strong> 关于低代码 vs. 全代码产生的技术债务的看法 [n=219]<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047404334" alt="" title="" loading="lazy"/><br/>（图表数据翻译：）</p><ul><li>技术债务更少：31%</li><li>技术债务相同：21%</li><li>技术债务更多：21%</li><li>可能技术债务更少：13%</li><li>可能技术债务更多：9%</li><li>无意见：5%</li></ul><p><strong>观察</strong></p><ul><li>大多数受访者（68%）认为使用低代码工具构建的应用程序应该至少"稍微简单一些"，而很少（14%）认为低代码驱动的应用程序应该至少"稍微复杂一些"。这些回复率与我们上次在2022年低代码开发调查中提出这个问题时看到的比率相似，当时我们看到62%的人说使用低代码工具创建的软件应该至少"稍微简单一些"，17%的人说应该至少"稍微复杂一些"。<br/><strong>低代码平台</strong>设计为用户友好型并能实现快速开发，这可能导致人们认为它们更适合简单的应用程序——开发人员可能觉得这些工具<em>抽象掉了传统编码涉及的许多复杂性</em>。此外，全代码应用程序提供了<em>更大的灵活性和定制选项</em>，允许开发人员创建更复杂和量身定制的解决方案。低代码工具在提供的定制深度方面可能被视为有限。低代码工具不太可能很快弥合复杂性差距——至少在大多数开发人员心目中是这样。</li><li>受访者对于调试低代码应用程序比传统代码调试更容易还是更困难存在分歧，但总体而言，<em>认为</em>低代码软件更难调试或可能比全代码应用程序更难调试的受访者（44%）多于认为调试低代码更容易或可能更容易的受访者（31%）。<br/>一些开发人员可能发现低代码应用程序<strong>更难调试</strong>，因为抽象和对底层代码的有限可见性<em>掩盖了问题的根本原因</em>并限制了直接操作。生成代码的专有性质和不熟悉的调试工具进一步使过程复杂化。另一方面，一些开发人员可能发现低代码应用程序<strong>更容易调试</strong>，因为低代码平台通常提供集成的调试工具、可视化界面和标准化环境，<em>简化了错误识别和解决</em>。低代码开发的可视化性质可以增强对应用程序逻辑的理解并减少编码错误，使一些开发人员更容易诊断和修复问题。</li><li>受访者主要在认为低代码业务逻辑比代码实现的业务逻辑可重用性更高还是更低之间存在分歧，认为两者具有相同可重用性水平和无意见的受访者子集要小得多。认为低代码业务逻辑可重用性更低的回复率与2022年保持不变，但认为低代码业务逻辑可重用性更高的回复率从2022年的30%增加了9%，而认为低代码和全代码业务逻辑具有相同可重用性水平的回复率从28%下降了11%。<br/>认为低代码业务逻辑比全代码<strong>可重用性更高</strong>的开发者可能这样认为，是因为低代码平台的<em>模块化组件、拖放界面和内置模板</em>促进了业务逻辑在不同应用程序间的轻松复制和适应——这些方面可以增强一致性并加速开发周期。他们也可能认为非开发人员或公民开发者更容易利用某些低代码业务逻辑，从而允许在组织内更广泛地重用。<br/>相反，其他开发人员可能认为低代码业务逻辑<strong>可重用性更低</strong>，因为许多低代码平台的专有性质，在与其他系统或平台集成时可能<em>产生兼容性问题和限制灵活性</em>。或者他们可能认为低代码业务逻辑是<strong>脆弱的</strong>，是为一次性目的创建的，没有考虑如何设计和实现逻辑以最大化其可重用性。<br/>与两年前相比，现在更多的开发人员可能认为低代码业务逻辑<strong>可重用性更高</strong>，这是因为低代码技术的进步、集成能力的提高以及低代码环境中标准化实践的日益普及，这些共同<em>增强了重用低代码组件的吸引力和实用性</em>。</li><li>最后，更多受访者认为使用低代码平台创建的软件导致（或可能导致）比用代码编写的软件更少的技术债务（44%），相比之下，认为会导致更多技术债务（30%）或相同数量技术债务（21%）的受访者要少。这些结果与我们在2022年看到的结果一致，逐年结果没有显著变化。<br/> 开发人员可能认为使用低代码平台构建的软件导致<strong>更少的技术债务</strong>，因为这些平台强制执行标准化的编码实践，可以减少手动编码错误，并提供预构建的组件以<em>确保一致的质量和可维护性</em>。这些特性可以最大限度地降低编写不良代码的风险，并使更新和扩展应用程序变得更加容易。再者，非开发人员或公民开发者能够为软件需求做出贡献，可能通过释放开发团队周期用于更复杂或关键的问题来帮助减轻技术债务。<br/>另一方面，一些开发人员可能认为低代码平台<strong>缺乏对软件系统的灵活性和控制</strong>，这可能<em>导致低效和变通方法</em>，使未来的维护复杂化。此外，对专有技术的依赖可能产生难以管理或替换的依赖性，从而增加长期技术债务。</li></ul><h5>有价值的低代码用例</h5><p>在继续考察开发人员对低代码的看法时，我们想知道受访者认为哪些类型的功能适合使用低代码工具构建，并询问：</p><p><em>在您看来，低代码平台对哪些用例有用？</em></p><p>结果：<br/><strong>图8.</strong> 被认为有用的低代码用例 [n=218]<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047404335" alt="" title="" loading="lazy"/><br/>（图表数据翻译：按选择百分比排序）</p><ul><li>交互式网页表单：66%</li><li>业务流程自动化：56%</li><li>企业CRUD：54%</li><li>简单数据库：51%</li><li>请求处理：43%</li><li>业务流程管理：43%</li><li>集成中间件：39%</li><li>学习管理：29%</li><li>机器人流程自动化/AI自动化：29%</li><li>BI/数据分析：28%</li><li>电子商务和电子采购：27%</li><li>ETL：22%</li><li>机器学习管道：18%</li><li>安全流程：15%</li><li>物理建模：12%</li><li>其他，请填写：6%</li></ul><p><strong>观察</strong></p><ul><li>与开发人员对使用低代码工具构建的应用程序/组件复杂性的感受一致，受访者认为低代码平台有用的最流行用例通常是低复杂性、低风险的软件元素。超过一半的受访者认为"交互式网页表单"、"业务流程自动化"、"企业CRUD"和"简单数据库"是低代码的合适用例，而很少受访者对"物理建模"、"安全流程"和"机器学习管道"等用例持相同看法。<br/>截至目前，低代码工具更常被认为<strong>擅长构建</strong>涉及<em>重复性、定义明确任务</em>的应用程序，这些任务可以受益于平台的快速开发能力、预构建组件和用户友好界面。这些用例通常需要较少的复杂逻辑和定制，使它们成为低代码解决方案的理想选择。<br/>相反，更高复杂性的软件<strong>被认为不太适合</strong>低代码平台，因为它们通常需要高级的、<em>专门的算法</em>、高水平的<em>定制</em>以及严格的<em>性能</em>和<em>安全性</em>标准，而低代码工具可能难以满足这些要求，特别是如果软件旨在由几乎没有软件设计经验的员工创建。这些复杂应用程序所需的固有灵活性和控制更好地由传统的编码方法提供。<br/>我们将在后面的发现中考察受访者实际利用低代码平台的用例。</li><li>这个问题的结果大多与我们2023年上次提出该问题时看到的结果一致。逐年回复率唯一具有统计学显著变化的是"交互式网页表单"、"请求处理"和"集成中间件"的增加，以及"ETL"的减少。这些结果的详细信息见表3：</li></ul><p>表3. 被认为有用的低代码用例：2023-2024*</p><table><thead><tr><th align="left">用例</th><th align="left">2023</th><th align="left">2024</th><th align="left">变化百分比</th></tr></thead><tbody><tr><td align="left">交互式网页表单</td><td align="left">58%</td><td align="left">66%</td><td align="left">+8%</td></tr><tr><td align="left">业务流程自动化</td><td align="left">-</td><td align="left">56%</td><td align="left">-</td></tr><tr><td align="left">企业CRUD</td><td align="left">52%</td><td align="left">54%</td><td align="left">+2%</td></tr><tr><td align="left">简单数据库</td><td align="left">56%</td><td align="left">51%</td><td align="left">-5%</td></tr><tr><td align="left">请求处理</td><td align="left">36%</td><td align="left">43%</td><td align="left">+7%</td></tr><tr><td align="left">业务流程管理</td><td align="left">48%</td><td align="left">43%</td><td align="left">-5%</td></tr><tr><td align="left">集成中间件</td><td align="left">28%</td><td align="left">39%</td><td align="left">+11%</td></tr><tr><td align="left">学习管理</td><td align="left">28%</td><td align="left">29%</td><td align="left">+1%</td></tr><tr><td align="left">机器人流程自动化/AI自动化</td><td align="left">-</td><td align="left">29%</td><td align="left">-</td></tr><tr><td align="left">BI/数据分析</td><td align="left">-</td><td align="left">28%</td><td align="left">-</td></tr><tr><td align="left">电子商务和电子采购</td><td align="left">24%</td><td align="left">27%</td><td align="left">+3%</td></tr><tr><td align="left">ETL</td><td align="left">32%</td><td align="left">22%</td><td align="left">-10%</td></tr><tr><td align="left">机器学习管道</td><td align="left">16%</td><td align="left">18%</td><td align="left">+2%</td></tr><tr><td align="left">安全流程</td><td align="left">-</td><td align="left">15%</td><td align="left">-</td></tr><tr><td align="left">物理建模</td><td align="left">10%</td><td align="left">12%</td><td align="left">+2%</td></tr><tr><td align="left">n=</td><td align="left">93</td><td align="left">218</td><td align="left"> </td></tr></tbody></table><p><em>*注：2023年列中的空白表示我们2024年调查中添加的选项。</em></p><p>总体而言，这些数据表明开发人员对低代码用例的看法变化缓慢，并且<em>低代码平台可能需要取得重大进步</em>，大多数开发人员才会对将低代码用于更复杂的软件需求感到满意。</p><h4>研究目标二：开发人员如何使用低代码或与低代码交互</h4><p>随着组织采用低代码平台，越来越多的开发人员很可能需要以某种方式与低代码合作。这可能意味着为低代码创建的功能设计和构建互操作性。或者它可能涉及学习并使用新的低代码平台本身。我们想了解更多关于开发人员与低代码工具交互的现状。</p><p>在本节中，我们讨论：</p><ul><li>开发人员如何与低代码软件交互或使用低代码工具构建</li><li>开发人员如何使用低代码进行自动化和AI</li></ul><h5>与低代码软件交互和构建</h5><p>全代码软件开发人员可能需要与低代码平台交互的原因有很多，例如：</p><ul><li>集成低代码工具无法提供的自定义功能</li><li>将低代码应用程序与其他系统和服务连接，处理复杂的集成并确保整个企业的无缝数据流</li><li>维护和排查低代码应用程序故障，解决需要更深入了解底层代码和系统架构的性能问题或错误</li></ul><p>我们想找出开发人员处理低代码的频率，因此我们提出了以下问题：</p><p>*您编写与使用低代码平台构建的软件交互的代码的频率如何？<br/>您使用低代码平台构建软件的频率如何？*<br/>对于回答并非"从未"使用低代码平台构建软件的受访者，我们还询问：</p><p><em>您使用低代码平台实现了哪些类型的软件或软件功能？</em></p><p>结果：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047404336" alt="" title="" loading="lazy"/><br/>图9. 编写与低代码创建软件交互代码的频率 [n=220]<br/>（图表数据翻译：）</p><ul><li>有时：32%</li><li>很少：26%</li><li>经常：20%</li><li>从未：13%</li><li>一直：10%</li></ul><p>图10. 使用低代码平台创建软件的频率 [n=215]<br/>（图表数据翻译：）</p><ul><li>有时：30%</li><li>很少：25%</li><li>经常：19%</li><li>从未：16%</li><li>一直：10%</li></ul><p>图11. 使用低代码平台实现的软件/功能类型 [n=175]<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047404337" alt="" title="" loading="lazy"/><br/>（图表数据翻译：按选择百分比排序）</p><ul><li>交互式网页表单：46%</li><li>企业CRUD：37%</li><li>业务流程自动化：39%</li><li>简单数据库：27%</li><li>集成中间件：27%</li><li>业务流程管理：31%</li><li>请求处理：24%</li><li>机器人流程自动化/AI自动化：15%</li><li>BI/数据分析：12%</li><li>电子商务和电子采购：14%</li><li>ETL：13%</li><li>学习管理：11%</li><li>安全流程：8%</li><li>物理建模：6%</li><li>机器学习管道：5%</li><li>其他，请填写：4%</li></ul><p><strong>观察</strong></p><ul><li>几乎所有受访者（93%）都至少有一些与使用低代码平台构建的软件交互或自己使用低代码平台构建的经验（即，他们至少回答了其中一个问题，并且没有对两个问题都回答"从未"）。总体而言，受访者使用低代码工具构建的可能性与低代码构建软件交互的可能性一样高，并且个体受访者倾向于以相同的频率进行其中一项活动。<br/>例如，大多数表示他们"<strong>一直</strong>"与低代码工具创建的软件<strong>交互</strong>的受访者也表示他们"<strong>一直</strong>"使用低代码<strong>构建</strong>软件，对于"<strong>经常</strong>"、"<strong>有时</strong>"等也是如此（详情见表4）。</li></ul><p><strong>表4.</strong> 与低代码构建软件交互的频率和使用低代码构建的频率*</p><table><thead><tr><th align="left"> </th><th align="left">使用低代码构建</th></tr></thead><tbody><tr><td align="left"><strong>与低代码交互</strong></td><td align="left"><strong>一直</strong></td><td align="left"><strong>经常</strong></td><td align="left"><strong>有时</strong></td><td align="left"><strong>很少</strong></td><td align="left"><strong>从未</strong></td><td align="left"><strong>总体</strong></td></tr><tr><td align="left"><strong>一直</strong></td><td align="left">55%</td><td align="left">30%</td><td align="left">10%</td><td align="left">5%</td><td align="left">0%</td><td align="left">10%</td></tr><tr><td align="left"><strong>经常</strong></td><td align="left">9%</td><td align="left">63%</td><td align="left">12%</td><td align="left">9%</td><td align="left">7%</td><td align="left">20%</td></tr><tr><td align="left"><strong>有时</strong></td><td align="left">4%</td><td align="left">7%</td><td align="left">64%</td><td align="left">15%</td><td align="left">9%</td><td align="left">32%</td></tr><tr><td align="left"><strong>很少</strong></td><td align="left">2%</td><td align="left">4%</td><td align="left">18%</td><td align="left">57%</td><td align="left">20%</td><td align="left">26%</td></tr><tr><td align="left"><strong>从未</strong></td><td align="left">7%</td><td align="left">3%</td><td align="left">14%</td><td align="left">24%</td><td align="left">52%</td><td align="left">13%</td></tr><tr><td align="left"><strong>总体</strong></td><td align="left">10%</td><td align="left">19%</td><td align="left">30%</td><td align="left">25%</td><td align="left">16%</td><td align="left"> </td></tr></tbody></table><p><em>*行内百分比</em></p><p>这些结果可能表明，采用低代码技术的组织通常在整个组织范围内同等程度地使用它们，而不是将这些工具的使用隔离给公民开发者或非开发团队。我们将在研究目标三中讨论受访者关于低代码如何影响软件质量的经验。</p><ul><li>将自己描述为全栈开发者的受访者频繁（"经常"或"一直"）使用低代码平台构建软件的可能性显著高于后端和非后端/全栈开发者。非后端/全栈开发者最可能说他们"有时"使用过低代码平台，而后端开发者最可能说他们"很少"或"从未"使用过低代码。具体数据见表5。</li></ul><p><strong>表5.</strong> 按开发人员类型划分的低代码使用频率*</p><table><thead><tr><th align="left">频率</th><th align="left">开发人员类型</th></tr></thead><tbody><tr><td align="left"> </td><td align="left">后端</td><td align="left">全栈</td><td align="left">非后端/全栈</td><td align="left">总体</td></tr><tr><td align="left">一直</td><td align="left">4%</td><td align="left">18%</td><td align="left">8%</td><td align="left">10%</td></tr><tr><td align="left">经常</td><td align="left">13%</td><td align="left">27%</td><td align="left">17%</td><td align="left">19%</td></tr><tr><td align="left">有时</td><td align="left">29%</td><td align="left">23%</td><td align="left">40%</td><td align="left">29%</td></tr><tr><td align="left">很少</td><td align="left">36%</td><td align="left">19%</td><td align="left">17%</td><td align="left">25%</td></tr><tr><td align="left">从未</td><td align="left">18%</td><td align="left">14%</td><td align="left">17%</td><td align="left">16%</td></tr></tbody></table><p><em>*列内百分比</em></p><ul><li>对于每个用例，声称曾利用低代码平台实现该功能用例的受访者，认为低代码是处理该用例的合适工具的可能性远高于总体受访者。例如，虽然总体上有54%的受访者认为低代码平台对"企业CRUD"有用，但声称实际使用低代码进行"企业CRUD"的受访者中有90%持相同看法。我们提供的每个用例答案选项，在实际使用低代码处理该用例的受访者中，关于低代码对该用例有用性的回复率都有显著增加。详情见表6。</li></ul><p><strong>表6.</strong> 按用例划分的低代码有用性看法：报告的低代码使用情况 vs. 总体比率</p><table><thead><tr><th align="left">用例</th><th align="left">使用过此用例</th><th align="left">总体</th><th align="left">差值</th></tr></thead><tbody><tr><td align="left"> </td><td align="left">比率</td><td align="left">n=</td><td align="left">比率</td><td align="left">n=</td><td align="left"> </td></tr><tr><td align="left">机器人流程/AI自动化</td><td align="left">93%</td><td align="left">26</td><td align="left">29%</td><td align="left">63</td><td align="left">64%</td></tr><tr><td align="left">企业CRUD</td><td align="left">90%</td><td align="left">64</td><td align="left">54%</td><td align="left">117</td><td align="left">36%</td></tr><tr><td align="left">简单数据库</td><td align="left">87%</td><td align="left">47</td><td align="left">51%</td><td align="left">111</td><td align="left">36%</td></tr><tr><td align="left">交互式网页表单</td><td align="left">87%</td><td align="left">80</td><td align="left">66%</td><td align="left">143</td><td align="left">21%</td></tr><tr><td align="left">业务流程自动化</td><td align="left">86%</td><td align="left">69</td><td align="left">56%</td><td align="left">121</td><td align="left">31%</td></tr><tr><td align="left">电子商务和电子采购</td><td align="left">86%</td><td align="left">25</td><td align="left">27%</td><td align="left">59</td><td align="left">59%</td></tr><tr><td align="left">学习管理</td><td align="left">83%</td><td align="left">19</td><td align="left">29%</td><td align="left">64</td><td align="left">53%</td></tr><tr><td align="left">请求处理</td><td align="left">82%</td><td align="left">42</td><td align="left">43%</td><td align="left">94</td><td align="left">39%</td></tr><tr><td align="left">安全流程</td><td align="left">82%</td><td align="left">14</td><td align="left">15%</td><td align="left">32</td><td align="left">68%</td></tr><tr><td align="left">业务流程管理</td><td align="left">82%</td><td align="left">54</td><td align="left">43%</td><td align="left">94</td><td align="left">39%</td></tr><tr><td align="left">BI/数据分析</td><td align="left">78%</td><td align="left">21</td><td align="left">28%</td><td align="left">62</td><td align="left">49%</td></tr><tr><td align="left">集成中间件</td><td align="left">77%</td><td align="left">47</td><td align="left">39%</td><td align="left">86</td><td align="left">38%</td></tr><tr><td align="left">ETL</td><td align="left">72%</td><td align="left">23</td><td align="left">22%</td><td align="left">48</td><td align="left">50%</td></tr><tr><td align="left">机器学习管道</td><td align="left">67%</td><td align="left">8</td><td align="left">18%</td><td align="left">39</td><td align="left">49%</td></tr><tr><td align="left">物理建模</td><td align="left">63%</td><td align="left">10</td><td align="left">12%</td><td align="left">27</td><td align="left">50%</td></tr><tr><td align="left">其他，请填写</td><td align="left">58%</td><td align="left">7</td><td align="left">6%</td><td align="left">12</td><td align="left">53%</td></tr></tbody></table><ul><li>尽管这些结果可能反映了某些认知偏差，例如单纯曝光效应，但这些偏差的证据可能表明低代码工具比许多开发人员认为的更具实用性，并且组织采用低代码平台的增加可能导致开发人员在有机会尝试这些工具后找到更多使用它们的方法。</li></ul><p><strong>用于自动化和AI的低代码</strong><br/>自动化和AI都是利用低代码能力的有前景的领域。两者都有潜力简化各种重复性任务，使员工能够减少花在繁忙工作上的时间，而将更多时间用于运用他们的技能组合。低代码平台可以使业务用户和开发人员都能够以最少的编码创建和修改<strong>自动化工作流以及AI驱动的流程</strong>。低代码平台的可视化界面和预构建组件可以<em>更轻松地将AI能力</em>——如机器学习模型和自然语言处理——集成到业务应用程序中，从而提高运营效率和决策能力。为了确定组织目前如何使用低代码进行自动化和AI，我们提出了以下问题：</p><p><em>您的组织是否使用低代码工具来创建工作流和/或流程自动化？</em></p><p>对于回答"是"或"否，但我们正在考虑"的受访者，我们还询问：</p><p><em>您使用或正在考虑使用以下哪些工作流和/或流程自动化方法？</em></p><p>关于用于AI的低代码，我们询问：</p><p><em>您的组织在哪些用例中使用低代码AI工具或平台？</em></p><p>结果：</p><p><strong>图12.</strong> 组织使用低代码进行工作流/流程自动化的情况 [n=213]<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047404338" alt="" title="" loading="lazy"/><br/>（图表数据翻译：）</p><ul><li>是：47%</li><li>否，我们也没有考虑：18%</li><li>我不知道：11%</li><li>否，但我们正在考虑：24%</li></ul><p><strong>图13.</strong> 使用或考虑的工作流/流程自动化方法 [n=150]<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047404339" alt="" title="" loading="lazy"/><br/>（图表数据翻译：按选择百分比排序）</p><ul><li>业务流程管理：65%</li><li>机器人流程自动化：42%</li><li>企业资源规划：39%</li><li>超自动化：15%</li><li>其他：5%</li></ul><p><strong>图14.</strong> 低代码AI工具/平台的使用用例 [n=211]<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047404340" alt="" title="" loading="lazy"/><br/>（图表数据翻译：按选择百分比排序）</p><ul><li>聊天机器人/虚拟助手：38%</li><li>预测分析：24%</li><li>语言处理：22%</li><li>计算机视觉：19%</li><li>不适用：21%</li></ul><p><strong>观察</strong></p><ul><li>近一半的受访者（47%）表示他们的组织使用低代码工具进行工作流/流程自动化，这比我们在2023年调查中看到的60%显著下降。回答"否，但我们正在考虑"的回复率从2023年的11%增加到24%以作补偿，而回答"否，我们也没有考虑"和"我不知道"的回复率在2023年和2024年之间没有显著变化。<br/>考虑到我们在比较本次调查中其他问题的逐年结果时没有看到低代码工具使用率的下降，目前尚不清楚为什么今年声称其组织使用低代码工具进行工作流和/或流程自动化的受访者如此之少，但这是我们未来继续低代码研究时将关注的趋势。</li><li>大多数在使用或考虑使用低代码进行工作流/流程自动化的组织的受访者也表示，他们使用或考虑使用"业务流程管理"，尽管这一数字也低于我们2023年收集的结果。另一方面，"机器人流程自动化"和"企业资源规划"的回复率较2023年调查结果有所增加。逐年数据见表7：</li></ul><p><strong>表7.</strong> 使用或考虑的工作流/流程自动化方法：2023-2024</p><table><thead><tr><th align="left">方法</th><th align="left">2023</th><th align="left">2024</th><th align="left">变化百分比</th></tr></thead><tbody><tr><td align="left"> </td><td align="left">比率</td><td align="left">n=</td><td align="left">比率</td><td>n=</td><td> </td></tr><tr><td align="left">业务流程管理</td><td align="left">75%</td><td align="left">49</td><td align="left">65%</td><td>97</td><td>-10%</td></tr><tr><td align="left">机器人流程自动化</td><td align="left">28%</td><td align="left">18</td><td align="left">42%</td><td>63</td><td>+14%</td></tr><tr><td align="left">企业资源规划</td><td align="left">31%</td><td align="left">20</td><td align="left">39%</td><td>58</td><td>+8%</td></tr><tr><td align="left">超自动化*</td><td align="left">-</td><td align="left">-</td><td align="left">15%</td><td>22</td><td>-</td></tr><tr><td align="left">其他</td><td align="left">11%</td><td align="left">7</td><td align="left">5%</td><td>8</td><td>-6%</td></tr></tbody></table><p><em>*注："超自动化"是我们为2024年调查添加的回复选项。</em></p><p>这些结果可能表明，使用低代码进行工作流/流程自动化的组织正在扩展他们采用的方法。</p><ul><li><p>大多数受访者（63%）表示他们的组织将低代码AI工具用于至少一个列出的用例——最流行的用例是"聊天机器人/虚拟助手"。</p><ul><li>小型组织的受访者声称其组织使用低代码AI工具的<strong>可能性要低</strong>得多，有34%选择"不适用"，而中型组织的受访者为12%，大型组织为14%。</li><li>小型组织的受访者声称其组织使用低代码处理"聊天机器人/虚拟助手"（23%）和"预测分析"（8%）的<strong>可能性显著低于</strong>中型组织（分别为40%和27%）和大型组织（分别为47%和27%）的受访者。</li></ul></li><li>有趣的是，小型组织的受访者声称其组织使用低代码AI进行"语言处理"（24%）的<strong>可能性高于</strong>中型组织（15%），但仍低于大型组织（31%）。</li></ul><h4>研究目标三：开发人员如何看待低代码对开发和软件质量的影响</h4><p>我们在研究发现中试图至少触及的一个主要问题是："这个主题的影响是否与其周围的炒作相符？"换句话说，我们想知道我们讨论的主题是否对软件开发整体产生积极影响。为此，我们在本节中考察：</p><ul><li>低代码对软件质量的影响</li><li>低代码安全关切以及对低代码治理的需求</li></ul><h5>低代码对软件质量的影响</h5><p>在本报告的第一个研究目标中，我们考察了开发人员对低代码影响开发的感受和看法。我们还希望考察开发人员对使用低代码工具的开发过程和软件的第一手经验——这个区别可能很小，但我们认为很重要。</p><p>在这里，我们考察的是那些报告至少有一些与低代码创建软件交互或自己使用低代码工具构建应用程序经验的开发人员（正如我们之前看到的，他们占受访者的93%）的回答，提出以下问题：</p><p>*根据您的经验，使用低代码工具总体上使软件...*<br/>根据您的经验，使用低代码工具是否使开发更具迭代性？*<br/>根据您的经验，使用低代码工具导致总体上...**</p><p>结果：</p><p><strong>图15.</strong> 低代码对软件性能、可维护性、可扩展性和安全性的影响 [n=199]<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047404341" alt="" title="" loading="lazy"/><br/>（图表数据翻译：针对每个属性，显示"更好"、"大致相同"、"更差"的百分比）</p><ul><li>性能：更好 26%，大致相同 40%，更差 25%</li><li>可维护性：更好 47%，大致相同 30%，更差 17%</li><li>可扩展性：更好 40%，大致相同 32%，更差 21%</li><li>安全性：更好 38%，大致相同 35%，更差 20%</li></ul><p>图16. 低代码对开发迭代性的影响 [n=196]<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047404342" alt="" title="" loading="lazy"/><br/>（图表数据翻译：）</p><ul><li>是：53%</li><li>否：25%</li><li>无意见：22%</li></ul><p>图17. 低代码对软件质量的影响 [n=197]<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047404343" alt="" title="" loading="lazy"/><br/>（图表数据翻译：）</p><ul><li>更高质量的软件：41%</li><li>相同质量的软件：28%</li><li>更低质量的软件：24%</li><li>无意见：7%</li></ul><p><em>*注：这三个问题仅询问了未在"您使用低代码平台构建软件的频率如何？"问题中回答"从未" 或未在"您编写与使用低代码平台构建的软件交互的代码的频率如何？"问题中回答"从未"的受访者。</em></p><p><strong>观察</strong></p><ul><li>可维护性是受访者最可能表示被低代码改进的特性，尽管认为低代码工具改善了可扩展性和安全性的受访者也占多数。受访者最可能说低代码构建的软件性能与全代码应用程序大致相同，而表示低代码使软件性能"更好"或"更差"的受访者数量大致相当。<br/>表示最频繁（"经常"或"一直"）使用低代码工具构建软件的受访者，比其他受访者更可能发现低代码使软件性能更好（36%）、更可维护（65%）、更可扩展（53%）和更安全（55%）。</li><li>略多于半数的受访者认为低代码工具使软件开发更具迭代性。这些结果与我们2022年收集的结果相比没有显著变化。<br/>再次，报告"经常"或"一直"使用低代码工具构建软件的受访者，比那些"有时"使用低代码工具构建（60%）和那些"很少"或"从未"使用低代码工具构建（36%）的受访者更可能发现使用低代码使开发更具迭代性（74%）。<br/>由于许多低代码平台是专门为支持快速原型设计和快速修改而设计的，允许开发人员根据即时反馈持续完善和改进应用程序，这些结果符合预期。我们再次看到，<em>更广泛地使用低代码工具的经验会带来对其潜力的更积极看法</em>。</li><li>显著更多的受访者表示，他们的经验表明低代码工具导致了更高质量的软件，而不是表示低代码导致相同或更低质量软件的受访者，尽管他们并未形成多数。<br/>虽然这些结果与我们2023年调查收集的结果有显著不同，但它们已恢复到我们在2021年低代码开发和2022年低代码开发调查中看到的比率（详情见表8）。目前尚不清楚去年是什么可能影响了低代码构建软件感知质量的下降。</li></ul><p><strong>表8.</strong> 低代码对软件质量的影响：2021-2024</p><table><thead><tr><th align="left">影响</th><th align="left">2021</th><th align="left">2022</th><th align="left">2023</th><th align="left">2024</th></tr></thead><tbody><tr><td align="left">更高质量的软件</td><td align="left">39%</td><td align="left">38%</td><td align="left">22%</td><td align="left">41%</td></tr><tr><td align="left">相同质量的软件</td><td align="left">26%</td><td align="left">28%</td><td align="left">24%</td><td align="left">28%</td></tr><tr><td align="left">更低质量的软件</td><td align="left">24%</td><td align="left">25%</td><td align="left">32%</td><td align="left">24%</td></tr><tr><td align="left">无意见</td><td align="left">11%</td><td align="left">10%</td><td align="left">22%</td><td align="left">7%</td></tr></tbody></table><p>再次，使用低代码"经常"或"一直"构建软件的受访者，经历低代码工具允许创建更高质量软件的可能性（61%）远高于那些"有时"使用低代码构建软件（37%）或"很少"/"从未"使用（27%）的受访者。我们认为这与低代码平台可以允许的迭代性密切相关，如前一观察所述。</p><h5>低代码安全与治理</h5><p>在构建任何类型的软件时，治理和安全性都是至关重要的考虑因素，因此，在处理低代码工具时，这些将是尤其需要观察的重要领域，因为低代码工具可能允许新平台广泛访问应用程序基础设施——并且可能涉及开发团队以外的员工来添加功能或与软件内部交互。我们想找出在低代码使用方面，开发人员最关心治理和安全的哪些方面，因此我们询问：</p><p>*在以下选择中，您认为在您组织中建立对低代码工作治理的主要需求是什么？<br/>您认为OWASP低代码/无代码十大安全关切中，哪些是您当前贡献的软件的显著潜在威胁？**</p><p>结果：</p><p><strong>图18.</strong> 建立对低代码工作治理的主要需求 [n=204]<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047404344" alt="" title="" loading="lazy"/><br/>（图表数据翻译：）</p><ul><li>管理端到端应用程序开发生命周期：31%</li><li>避免冗余应用程序的蔓延：22%</li><li>保护免受对其他企业系统和数据的影响：22%</li><li>维持企业质量和性能标准的可见性：21%</li><li>其他：4%</li></ul><p><strong>图19.</strong> 构成显著潜在威胁的低代码安全关切 [n=197]<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047404345" alt="" title="" loading="lazy"/><br/>（图表数据翻译：按选择百分比排序）</p><ul><li>身份验证和安全通信故障：41%</li><li>数据和密钥处理故障：40%</li><li>授权滥用：38%</li><li>易受攻击和不受信任的组件：35%</li><li>安全日志记录和监控故障：33%</li><li>注入处理故障：28%</li><li>资产管理故障：25%</li><li>数据泄漏和意外后果：24%</li><li>账户冒充：21%</li><li>无：13%</li></ul><p><em>*注：此问题仅询问了未在"您使用低代码平台构建软件的频率如何？"问题中回答"从未" 或 未在"您编写与使用低代码平台构建的软件交互的代码的频率如何？"问题中回答"从未"的受访者。</em></p><p><strong>观察</strong></p><ul><li>受访者关于建立对低代码工作治理的主要原因的看法在提供的四个选项中分布相当均匀，"管理端到端应用程序开发生命周期"略微领先于其他选项。这些结果与我们2022年调查收集的结果相比没有显著变化。<br/>表示"经常"或"一直"使用低代码平台构建软件的受访者比其他受访者更可能将"维持企业质量和性能标准的可见性"视为低代码治理的主要原因，并且更不可能选择"保护免受对其他企业系统和数据的影响"和"避免冗余应用程序的蔓延"。表示"很少"或"从未"使用低代码工具构建软件的受访者比其他受访者更不可能选择"管理端到端应用程序开发生命周期"作为建立治理的主要需求。此数据的详细信息见表9：</li></ul><p><strong>表9.</strong> 按使用低代码工具构建软件的频率划分的建立低代码治理的主要需求</p><table><thead><tr><th align="left">需求</th><th align="left">使用频率</th></tr></thead><tbody><tr><td align="left"> </td><td align="left">从未/很少</td><td align="left">有时</td><td align="left">经常/一直</td></tr><tr><td align="left">管理端到端应用程序开发生命周期</td><td align="left">23%</td><td align="left">35%</td><td align="left">37%</td></tr><tr><td align="left">维持企业质量和性能标准的可见性</td><td align="left">24%</td><td align="left">17%</td><td align="left">35%</td></tr><tr><td align="left">保护免受对其他企业系统和数据的影响</td><td align="left">23%</td><td align="left">25%</td><td align="left">15%</td></tr><tr><td align="left">避免冗余应用程序的蔓延</td><td align="left">27%</td><td align="left">23%</td><td align="left">10%</td></tr><tr><td align="left">其他</td><td align="left">4%</td><td align="left">0%</td><td align="left">3%</td></tr></tbody></table><ul><li>没有一个单一的安全关切被认为是对受访者贡献过的软件的"显著潜在威胁"，但四分之三的受访者选择了至少一个他们认为可能证明是严重的关切，大约一半（49%）选择了三个或更多，大约四分之一（24%）选择了OWASP低代码/无代码十大安全关切中的五个或更多。<br/>全栈开发者比其他开发者更可能认为"易受攻击和不受信任的组件"（41%）、"安全日志记录和监控故障"（36%）、"注入处理故障"（31%）和"账户冒充"（26%）是潜在的严重威胁，而非后端/全栈开发者比其他开发者更可能将"授权滥用"（40%）视为可能严重的威胁，并且更不可能将"数据泄漏和意外后果"（31%）和"身份验证和安全通信故障"（15%）视为此类威胁。<br/>表示最频繁使用低代码工具构建软件的受访者比其他受访者更可能发现"注入处理故障"（29%）是严重威胁，并且更不可能相信"授权滥用"（23%）和"账户冒充"（15%）是主要关切。这些受访者也更可能声称OWASP低代码/无代码十大安全关切中没有一个对其软件构成显著威胁（13%）。<br/>表示"很少"或"从未"使用低代码构建软件的受访者比其他受访者更可能选择"资产管理故障"（19%），并且更不可能选择"数据和密钥处理故障"（18%）作为潜在的严重威胁。</li></ul><h4>未来研究</h4><p>我们这里的分析仅触及了可用数据的表面，我们将在制作未来的趋势报告时完善和扩展我们的低代码开发调查。我们在本报告中未涉及但已纳入调查的一些主题包括：</p><ul><li>开发人员希望业务用户创建简单自动化的意愿</li><li>低代码和全代码之间互操作性问题的频率</li><li>低代码避免可预防开发错误的能力</li></ul><hr/><h2>通过低代码和无代码集成转变软件开发</h2><p><strong>创建更快、更智能的软件开发流程</strong><br/>作者：Shantanu Kumar, Amazon 高级软件工程师</p><p>尽管传统的软件开发生命周期（SDLC）速度缓慢且无法满足动态的业务需求，但它长期以来一直是公司构建应用程序最流行的方式——直到低代码和无代码（LCNC）工具的出现。这些工具简化了编码过程，使得高级开发人员和非技术用户都可以做出贡献，通过缩短SDLC使组织能够快速响应市场需求。</p><p>请继续阅读，了解软件开发如何因LCNC工具而改变，如何将它们集成到您的运营中，以及集成时可能出现的挑战。</p><h3>理解低代码和无代码开发</h3><p>低代码和无代码开发环境让人们能够通过可视化界面、拖放工具和可重用组件来构建应用程序，而无需手动编写代码。低代码开发平台是可视化开发环境，使任何技能水平的开发人员都能够将组件拖放到面板上并连接它们以创建移动或Web应用程序。无代码开发平台则面向没有或几乎没有编码经验的用户。</p><p>那么，您如何利用这些平台来增强传统的SDLC呢？</p><p>假设您是一名具有基本编码技能的设计师。使用LCNC平台，您可以快速使用可重用组件创建原型，而无需编写一行代码。这将加快软件开发过程，并确保最终产品满足用户需求。</p><h3>低代码和无代码集成的规划与评估</h3><p>尽管SDLC因不同的SDLC模型而在公司间有所不同，但它通常包括以下阶段：项目规划、需求收集与分析、设计、测试、部署和维护。这个过程确保了高度的细节，但减慢了开发周期并消耗了大量资源。</p><p>低代码和无代码工具解决了这一挑战。例如，在设计阶段，人力资源团队可以使用LCNC平台提供的可重用组件或预制模板快速设计他们的招聘门户，以轻松跟踪候选人、职位发布和面试安排。</p><p>也就是说，在将LCNC平台集成到您现有的工作流之前，请考虑您团队的专长、您选择的平台与您的IT基础设施的兼容性以及平台的安全特性。</p><h3>低代码和无代码集成的步骤</h3><p>要将低代码和无代码工具集成到您的运营中，请遵循以下步骤：</p><p>图1. 实现无缝LCNC集成的简化步骤<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047404346" alt="" title="" loading="lazy"/><br/>（图表描述：一个循环图，包含以下步骤：1. 定义目标和目的 -&gt; 2. 选择合适的LCNC平台 -&gt; 3. 培训团队成员 -&gt; 4. 设计集成架构 -&gt; 5. 实施集成框架 -&gt; 6. 进行测试和质量保证 -&gt; 7. 管理部署和发布 -&gt; 8. 监控和维护 -&gt; 返回步骤1 形成循环）</p><p>表1扩展了这些步骤，并包括每个步骤的示例：<br/><strong>表1.</strong> 集成LCNC工具的步骤</p><table><thead><tr><th align="left">步骤</th><th align="left">描述</th><th align="left">示例</th></tr></thead><tbody><tr><td align="left">1. 定义目标和目的</td><td align="left"><strong>明确定义您想要实现的目标</strong>，并使其具体化。目标可能包括加速开发、降低成本或提高团队生产力。</td><td align="left">在六个月内使用预构建模板将应用程序开发时间减少40%。</td></tr><tr><td align="left">2. 选择合适的LCNC平台</td><td align="left">不要将就。<strong>评估各种平台</strong>，并将其与您的需求和目标相匹配。考虑用户友好性、安全特性以及与现有系统的兼容性。</td><td align="left">如果大多数团队成员不精通技术，则选择一个主要因其易用性和教育支持而突出的无代码平台。</td></tr><tr><td align="left">3. 培训和引导团队成员</td><td align="left">确保所有团队成员，无论是否精通技术，<strong>都能使用您的平台</strong>。</td><td align="left">安排讲座和网络研讨会，甚至为您的团队成员报名参加LCNC平台提供的专业课程。</td></tr><tr><td align="left">4. 设计集成架构</td><td align="left">确保您的平台<strong>设计得易于与当前系统集成</strong>。</td><td align="left">映射数据在现有系统和首选平台之间的流动方式。</td></tr><tr><td align="left">5. 实施集成框架</td><td align="left"><strong>创建一个在SDLC内集成LCNC平台的框架</strong>。在最简单的层面上，这可能涉及为SDLC每个阶段选择工具创建指南。</td><td align="left">集成LCNC平台以收集客户调查回复、产品发布反馈或联系表单提交。没有这些工具，开发人员需要从头开始构建功能，需要大量的前端开发和存储集成，导致更高的成本和更长的开发周期。</td></tr><tr><td align="left">6. 进行测试和质量保证</td><td align="left">使用<strong>混合测试方法</strong>（如单元测试、集成测试和验收测试）对您的LCNC工具进行严格测试。</td><td align="left">您可以执行验收测试以确保您的应用程序满足最终用户的需求和期望。</td></tr><tr><td align="left">7. 管理部署和发布</td><td align="left">以结构化的方式<strong>使用部署策略</strong>（例如，滚动部署）将您的应用程序部署给最终用户，并包含在出现不可预见问题时回滚的计划。</td><td align="left">您可以使用云解决方案来自动化部署。</td></tr><tr><td align="left">8. 监控和维护</td><td align="left">部署后<strong>监控应用程序的性能</strong>以检测潜在的相关问题。</td><td align="left">在维护期间，您可能会遇到错误。安排定期错误修复可以维护应用程序的稳定性、功能性和安全性。</td></tr></tbody></table><h3>集成低代码和无代码：要实施和避免的实践</h3><p>虽然低代码和无代码平台简化了SDLC，但实施它们需要结构化的方法。接下来，我们将探讨在集成过程中需要考虑的最佳实践和适得其反的实践。</p><h4>实施：渐进式采用</h4><p>将低代码和无代码平台逐步集成到现有的流程和系统中，可以最大限度地减少对正在进行的运营的干扰。首先将LCNC解决方案用于非关键项目，这些项目可以作为完善集成策略的试验场。例如，开发人员可以逐步迁移LCNC流程，从非关键的、易于打包的流程开始，并随着时间的推移逐渐扩大规模。非关键流程，如电子邮件通知，更适合缓慢、迭代地推广到一小部分客户。</p><h4>实施：协作开发</h4><p>协作开发是一种强调团队合作的方法论。它将SDLC中涉及的各种利益相关者聚集在一起，例如项目经理、业务分析师、UX/UI设计师、软件开发人员以及其他技术和非技术人员。这种方法考虑了每个利益相关者的意见，从而交付高质量的应用程序。通过为SDLC中涉及的每个利益相关者建立明确的角色和职责来鼓励协作。</p><h4>实施：混合开发模型</h4><p>将低代码和无代码平台与传统编码相结合提供了一种平衡的方法。虽然LCNC平台可以加速开发，但复杂的功能可能需要自定义代码。采用混合方法可以促进灵活性，并在不牺牲传统编码提供的增强功能的情况下维护应用程序的完整性。</p><h4>实施：持续反馈循环</h4><p>低代码和无代码工具加速了反馈循环，允许团队快速构建原型、早期并经常收集用户反馈，并根据收到的反馈完善应用程序。这种方法确保最终产品符合用户需求和期望，并快速适应动态的业务需求。</p><h4>避免：过度依赖低代码和无代码平台</h4><p>低代码和无代码工具并非旨在彻底改变传统编码。复杂的逻辑或性能关键的任务仍然需要传统的软件开发方法。因此，企业应采用混合开发模型。</p><h4>避免：缺乏适当的培训和教育</h4><p>如果使用不当，低代码和无代码可能弊大于利。部署不当可能导致停机，这会迅速增加客户流失和声誉受损方面的成本（例如，在服务许多客户的情况下）——即使一秒钟的不可用性也会带来巨大的成本。从这些开创性平台受益的能力完全依赖于为技术和非技术用户提供适当的培训，以避免累积的异常情况。</p><h4>避免：忽视安全和合规性问题</h4><p>低代码和无代码平台消除了与常规SDLC流程相关的各种障碍。然而，它们也带来了安全关切，主要是因为您选择的平台托管着您的数据。评估您选择的低代码或无代码平台的安全特性，以确保其满足您组织的数据保护法规和其他行业法规（例如，GDPR、HIPAA、CCPA），以避免安全漏洞和法律问题。</p><h4>避免：忽略可扩展性和定制化要求</h4><p>并非所有的低代码和无代码平台都能很好地扩展或允许足够的定制。例如，一些平台限制了使用它们的团队成员数量，而其他平台则有存储限制。这对于成长中的企业或有特定需求的企业来说可能是一个巨大的障碍。在确定平台之前，评估您正在考虑的平台是否可以扩展和定制以满足长期业务目标。</p><h3>低代码和无代码的挑战与缓解策略</h3><p>将低代码和无代码工具纳入现有流程带来了一些独特的障碍。表2描述了将LCNC工具集成到SDLC中的常见挑战及其相应的缓解策略：</p><p><strong>表2.</strong> 集成低代码和无代码：挑战与缓解策略</p><table><thead><tr><th align="left">障碍</th><th align="left">挑战</th><th align="left">缓解策略</th></tr></thead><tbody><tr><td align="left">变革阻力</td><td align="left">通常是最普遍的挑战；员工担心LCNC工具学习曲线陡峭</td><td align="left">实施广泛的培训计划，使团队成员具备必要的技能组合</td></tr><tr><td align="left">不兼容和互操作性</td><td align="left">可能阻碍LCNC平台的集成（例如，由于与过时的数据库协议不兼容）</td><td align="left">严格评估平台，确保与现有系统兼容，或者它们可以连接到未通过API连接的系统</td></tr><tr><td align="left">技术限制</td><td align="left">可能阻止LCNC平台的集成（即，缺乏可扩展性）</td><td align="left">选择从一开始就可扩展或提供混合开发方法的平台</td></tr></tbody></table><h3>SDLC中低代码和无代码的未来</h3><p>随着低代码和无代码平台的发展，我们可以预期软件开发实践将发生重大转变。虽然LCNC工具不会使传统编码过时，但它们将加速开发、降低成本、最小化技术债务，并民主化应用程序开发——允许更多人在没有高级编程技能的情况下构建软件。</p><p>低代码和无代码开发工具不仅仅是一种流行趋势。它们将继续存在，并将改变我们开发和维护软件的方式。Gartner估计，到2025年，企业开发的所有新应用程序中有70%将使用LCNC技术。新兴LCNC领域的现有趋势表明，这些平台将发展到支持日益复杂的功能，例如高级工作流和集成。最重要的是，AI将成为这一演进的核心。提供数字聊天机器人、图像识别、个性化和其他高级功能的AI增强型LCNC平台已经上市。</p><h3>结论</h3><p>Forrester表示，低代码和无代码工具正在"重新定义组织构建软件的方式"；仅低代码市场预计到2028年将达到近300亿美元的价值。如果您希望您的组织跟上步伐，您就不能忽视LCNC平台。通过实施这些步骤，组织可以有效地集成LCNC解决方案：</p><ol><li>组织应设定明确的目标，说明他们希望通过LCNC解决方案实现什么。然后，他们应根据具体需求选择合适的平台。</li><li>组织应就所选平台培训其团队。</li><li>团队应仔细将新系统与现有系统集成，并在部署之前对其进行彻底测试。</li></ol><p>最终，成功的集成取决于采用最佳实践（例如，渐进式采用、协作开发、混合开发）和避免适得其反的实践（例如，严重依赖LCNC工具、未能考虑安全性和可扩展性）。</p><p>您还没有使用低代码和无代码工具吗？将它们引入您现有的工作流以支持您的SDLC过程。</p><h4>补充资源：</h4><ul><li>《使用Mendix构建低代码应用程序：发现简化企业Web开发的最佳实践和专家技术》作者：Bryan Kenneweg, Imran Kasam, 和 Micah McMullen</li><li>Ponemon研究所的《数据中心停机的成本》</li><li>Gartner的《Gartner称云将成为新数字体验的核心》</li><li>Forrester的《低代码市场到2028年可能接近500亿美元》</li></ul><blockquote><p>Shantanu Kumar</p><p>我在亚马逊工作超过九年，领导团队从事大规模数据系统、AI基础设施和云平台的工作。我领导了"Buy with Prime"项目，提升了美国Prime购物体验并支持小企业。作为IEEE、ACM和BCS的活跃成员，我参与软件工程讨论，并作为演讲者和作家分享我的专业知识，热情地为技术社区做出贡献。</p></blockquote><hr/><h2>合作伙伴安全研究</h2><h3>DoorDash案例</h3><p><strong>DoorDash如何利用Retool在3个月内完成了2年的路线图工作</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047404347" alt="" title="" loading="lazy"/></p><p>DoorDash是全国最大的最后一英里物流平台，连接着美国、加拿大、波多黎各和澳大利亚<strong>50</strong>个州、<strong>4000</strong>多个城市的客户与他们最喜欢的本地和全国企业。</p><h4>挑战</h4><p>DoorDash的工程团队负责构建所有自己的内部工具，作为一家运营繁重的公司，有大量工作要做。Rohan Chopra负责管理Dasher团队的工程工作，为他的团队构建内部工具既繁琐又关键。构建用于可视化Dasher路线、绘制区域或使团队能够与餐厅合作的一次性工具是一项<strong>手动、耗时数月的工作</strong>。</p><p>Rohan的团队最初使用了Django的管理面板，但立即面临挑战：它不是为了扩展而构建的，并且缺乏他们所需的定制性。Django的对象关系映射器生成了低效的查询，给DoorDash的基础设施带来了压力，并且需要手动输入才能完成诸如将Dasher状态设置为"暂停"之类的基本操作。</p><p><em>“投资内部工具曾经是一个困难且两极分化的权衡；Retool通过使工具成为任何项目中快速且轻松的一部分，帮助我们改变了这种范式，为我们节省了无数时间。”</em><br/>—<strong>Rohan Chopra</strong>, <br/><em>DoorDash工程总监</em></p><h4>结果</h4><p>一个具体的痛点是Dasher团队的奖励计划。保持该计划运行需要团队成员手动填写一个庞大的电子表格，将数据交给工程团队，并运行每周脚本。这个过程经常出问题：输入错误的数据、错过的交接和未捕获的错误需要双方花费大量时间来恢复。</p><h4>解决方案</h4><p>通过在网络上搜索找到Retool后，Rohan的团队开始使用Retool构建他们的内部工具以节省时间并改进流程。工程师能够在几小时内构建他们的新工具，并更有效地支持他们的运营团队，而<strong>无需数周的开销</strong>。</p><p>在Rohan的团队采用后，Retool集成自然地扩展到整个DoorDash组织。"我们没有发送任何电子邮件：每当工程师们谈论构建内部工具时，Retool就会出现，新的团队就会尝试它，"Rohan说。</p><p>Retool极大地减少了Rohan团队构建内部工具所需的时间："我们每个需要构建的工具从1-2个月缩短到<strong>30-60</strong>分钟。"工具的构建过程变得短得多，但维护也显著更容易——像添加下拉菜单或过滤器这样的小调整变成了"几分钟"而不是"我们不确定"。运行脚本和填写电子表格等手动工作被自动化并按计划进行，而不是令人沮丧和被遗忘。</p><p>如今，DoorDash拥有<strong>40多</strong>个在Retool中构建的活跃运营工具，部分成功在于Retool所实现的民主化——为DoorDash节省了<strong>600万</strong>美元的工程时间。</p><hr/><h2>贡献者洞察</h2><h3>AI在低代码和无代码开发中的角色</h3><p><strong>作者：Eric Goebelbecker, Hit Subscribe 项目实践经理</strong></p><p>大型语言模型（LLMs）的出现导致了一场将人工智能（AI）强行融入每一个有意义的产品中的热潮，以及不少没有意义的产品。但有一个领域，AI已经被证明是一个强大而有用的补充：低代码和无代码软件开发。让我们看看AI如何以及为何使构建应用程序更快、更容易，尤其是在使用低代码和无代码工具时。</p><h4>AI在开发中的角色</h4><p>首先，我们讨论AI在简化和加速开发过程中最常见的两个角色：<strong>生成代码</strong>和<strong>充当智能助手</strong>。</p><p>AI代码生成器和助手使用在大型代码库上训练的LLMs，这些代码库教会它们编程语言的语法、模式和语义。这些模型预测满足提示所需的代码——就像聊天机器人使用它们的训练来预测句子中的下一个单词一样。</p><h5>自动化代码生成</h5><p>AI代码生成器根据输入创建代码。这些提示采用自然语言输入或集成开发环境（IDE）中或命令行中的代码形式。代码生成器通过将程序员从编写重复性代码中解放出来而加速开发。它们也可以减少常见错误和排版错误。但与用于生成文本的LLMs类似，代码生成器需要仔细审查，并且可能犯自己的错误。开发人员在接受AI生成的代码时需要小心，他们不仅需要测试它是否能构建，还需要测试它是否完成了<em>用户要求的功能</em>。<br/><a href="https://link.segmentfault.com/?enc=bvFkEbJnD%2FqfT5rJKt5cXQ%3D%3D.mZCteCkXgQ2EFqct5hoPnKe268dz9anAxG35j%2BAXR5ZjujFYBhpgJXCNZR8tx0Zp8kZTx%2F71Nlgtma2yurYF9Q%3D%3D" rel="nofollow" target="_blank">gpt-engineer</a>是一个开源的AI代码生成器，它接受自然语言提示来构建整个代码库。它可以与<a href="https://link.segmentfault.com/?enc=WRpkcfWI%2BRUFxUPyb7bF9w%3D%3D.9pMUivW8ZEFzSsdQVYIRRlU7Mra4kPsKg9xg4cK2vZw%3D" rel="nofollow" target="_blank">ChatGPT</a>或像<a href="https://link.segmentfault.com/?enc=vVTBg8sMXRlKMfJK8vKKSw%3D%3D.f3UKzbpCnNNBmKRl2Zs4%2FMtSHsqtCg5apNcy08LV%2BxO0akQSCQ9TCYMxfAonwpu2" rel="nofollow" target="_blank">Llama</a>这样的自定义LLMs一起工作。</p><h5>用于开发的智能助手</h5><p>智能助手在开发人员工作时为他们提供实时帮助。它们作为一种AI代码生成器，但不是使用自然语言提示，它们可以自动完成、提供内联文档并接受专门的命令。助手可以在像Eclipse和<a href="https://link.segmentfault.com/?enc=34JdgMCK72wUSVem72Ygjw%3D%3D.AqgPQ8VA0lqEP%2BNz76WBFuHecR4X%2FqIhuhnooKs9BmpbbtQWkU5IWxSpzUKSJZZh" rel="nofollow" target="_blank">Microsoft的VS Code</a>这样的编程工具内部、命令行或三者同时工作。这些工具提供了许多与代码生成器相同的好处，包括更短的开发时间、更少的错误和减少的拼写错误。它们还可以作为学习工具，因为它们在工作时为开发人员提供编程信息。但与任何AI工具一样，AI助手并非万无一失——它们需要<em>密切和仔细的监控</em>。<br/>GitHub的<a href="https://link.segmentfault.com/?enc=CQuRj3dlx6FcJQDUfx77ww%3D%3D.8ON%2FM0XX7ZBQ7tuSgdYhSjaULf2q42QsAfEqVBpApV%2BbzlqdyM82BEBbD%2BUJmLTm" rel="nofollow" target="_blank">Copilot</a>是一个流行的AI编程助手。它使用基于公共GitHub仓库构建的模型，因此它支持非常广泛的语言，并可以插入所有最流行的编程工具。<a href="https://link.segmentfault.com/?enc=cvWT0SyA1XYIgBFLd7%2FtkA%3D%3D.oTfVRKJDrwHxfbcmPFFC%2FVpmTidsooBI5lHm0UVU6hINXHPEGy36ZsDeWTIysT9mWHahgPa1mr%2BoXYuEUU0ftg%3D%3D" rel="nofollow" target="_blank">Microsoft的Power Platform</a>和<a href="https://link.segmentfault.com/?enc=6K%2FCoIpMGPglLn1zB%2FR%2Biw%3D%3D.nKDe4O9Q1JNR6Ax%2FVa9Ph7qCxccRi83PIM7Wr8nIz9O3x3dReg60q5cGt%2BXdrrxM" rel="nofollow" target="_blank">Amazon Q Developer</a>是两个流行的商业选项，而<a href="https://link.segmentfault.com/?enc=%2B01lSoUW%2B%2FaqqJJnkiIACQ%3D%3D.9FkyCDLhAEXKpV4qj7ZY%2B6FFMlC2BM4l%2BjRwJb8%2FRt0%3D" rel="nofollow" target="_blank">Refact.ai</a>是一个开源替代品。</p><h4>AI与低代码和无代码：完美结合</h4><p>低代码和无代码是为了满足需要让新手和非技术人员快速为其需求定制软件的工具而发展起来的。AI通过使将想法转化为软件变得更加容易，将这一点更进一步。</p><h4>民主化开发</h4><p>AI代码生成器和助手通过使编码更容易接触、提高生产力并促进持续学习来民主化软件开发。这些工具降低了编程新手的入门门槛。一个新手程序员可以使用它们边做边学，快速构建可运行的应用程序。例如，Microsoft Power Apps包含Copilot，它可以为您生成应用程序代码，然后与您一起完善它。</p><h4>AI如何增强低代码和无代码平台</h4><p>AI通过几种重要方式增强低代码和无代码平台。我们已经介绍了AI根据自然语言提示或代码编辑器中的上下文生成代码片段的能力。您可以使用像ChatGPT和Gemini这样的LLMs为许多低代码平台生成代码，而许多无代码平台如AppSmith和Google AppSheet使用AI根据描述您希望集成做什么的文本来生成集成。您还可以使用AI自动化准备、清理和分析数据。这使得集成和处理需要调整才能与您的模型一起使用的大型数据集变得更加容易。像Amazon SageMaker这样的工具使用AI来摄取、分类、组织和简化数据。一些平台使用AI帮助创建用户界面和填充表单。例如，Microsoft的Power Platform使用AI使用户能够通过与它的copilot进行对话交互来构建用户界面和自动化流程。<br/>所有这些功能都有助于使低代码和无代码开发更快，包括在可扩展性方面，因为更多的团队成员可以参与开发过程。</p><h4>低代码和无代码如何实现AI开发</h4><p>虽然AI对于生成代码非常宝贵，但它在您的低代码和无代码应用程序中也很有用。许多低代码和无代码平台允许您构建和部署支持AI的应用程序。它们抽象掉了添加诸如自然语言处理、计算机视觉和AI API等功能到您的应用程序中的复杂性。<br/>用户期望应用程序提供诸如语音提示、聊天机器人和图像识别等功能。从头开始开发这些能力需要时间，即使对于有经验的开发人员也是如此，因此许多平台提供模块，使得只需很少或无需代码即可轻松添加它们。例如，Microsoft有用于在Azure上构建Power Virtual Agents（现已成为其Copilot Studio的一部分）的低代码工具。这些代理可以插入由Azure服务支持的多种技能，并使用聊天界面驱动它们。<br/>像Amazon SageMaker和Google的Teachable Machine这样的低代码和无代码平台管理诸如准备数据、训练自定义机器学习（ML）模型和部署AI应用程序等任务。而Zapier则利用Amazon Alexa的语音转文本功能，并将输出引导到许多不同的应用程序。</p><p><strong>图1.</strong> 使用构建块构建低代码AI应用<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047404348" alt="" title="" loading="lazy"/><br/>（图表描述：展示了使用预构建的AI组件/API（如NLP、计算机视觉、预测分析）通过低代码平台快速组装成应用程序的过程。）</p><h4>支持AI的低代码和无代码工具示例</h4><p>此表包含广泛使用的低代码和无代码平台列表，这些平台支持AI代码生成、支持AI的应用程序扩展，或两者兼有：<br/><strong>表1.</strong> 支持AI的低代码和无代码工具</p><table><thead><tr><th align="left">应用程序</th><th align="left">类型</th><th align="left">主要用户</th><th align="left">关键特性</th><th align="left">AI/ML能力</th></tr></thead><tbody><tr><td align="left">Amazon CodeWhisperer</td><td align="left">AI驱动的代码生成器</td><td align="left">开发人员</td><td align="left">• 实时代码建议<br/>• 安全扫描<br/>• 广泛的语言支持</td><td align="left">ML驱动的代码建议</td></tr><tr><td align="left">Amazon SageMaker</td><td align="left">全托管的ML服务</td><td align="left">数据科学家, ML工程师</td><td align="left">• 能够构建、训练、部署ML模型<br/>• 完全集成的IDE<br/>• 支持MLOps</td><td align="left">预训练模型, 自定义模型训练和部署</td></tr><tr><td align="left">GitHub Copilot</td><td align="left">AI结对程序员</td><td align="left">开发人员</td><td align="left">• 代码建议<br/>• 多语言支持<br/>• 上下文感知建议</td><td align="left">用于代码建议的生成式AI模型</td></tr><tr><td align="left">Google Cloud AutoML</td><td align="left">无代码AI</td><td align="left">数据科学家, 开发人员</td><td align="left">• 可以用最少的精力训练高质量的定制ML模型<br/>• 支持各种数据类型，包括图像、文本和音频</td><td align="left">自动化的ML模型训练和部署</td></tr><tr><td align="left">Microsoft Power Apps</td><td align="left">低代码应用程序开发</td><td align="left">业务用户, 开发人员</td><td align="left">• 可以构建定制业务应用<br/>• 支持多种不同的数据源<br/>• 自动化工作流</td><td align="left">用于增强应用的AI构建器</td></tr><tr><td align="left">Microsoft Power Platform</td><td align="left">低代码平台</td><td align="left">业务分析师, 开发人员</td><td align="left">• 商业智能<br/>• 应用程序开发<br/>• 应用程序连接性<br/>• 机器人流程自动化</td><td align="left">用于增强应用和流程的AI应用构建器</td></tr></tbody></table><h4>使用AI进行开发的陷阱</h4><p>AI改善低代码和无代码开发的能力是不可否认的，但其风险也是如此。任何AI的使用都需要适当的培训和全面的治理。LLMs倾向于对提示"产生幻觉"答案的情况也适用于代码生成。<br/>因此，虽然AI工具降低了新手开发者的入门门槛，您仍然需要经验丰富的程序员在将代码部署到生产环境之前进行审查、验证和测试。</p><ul><li>开发人员通过提交提示和接收响应来使用AI。根据项目的不同，这些提示可能包含敏感信息。如果模型属于第三方供应商或未正确保护，您的开发人员就会暴露这些信息。</li><li>当它工作时，AI会建议可能满足其正在评估的提示的代码。代码是正确的，但不一定是最佳解决方案。因此，严重依赖AI生成代码可能导致代码难以更改并代表大量的技术债务。</li></ul><p>AI已经在民主化编程和加速低代码和无代码开发方面做出了重要贡献。随着LLMs的逐步改进，用于创建软件的AI工具只会变得更好。即使这些工具在改进，IT领导者仍然需要谨慎行事。<br/>AI提供了强大的力量，但这种力量伴随着巨大的责任。任何和所有AI的使用都需要全面的治理和完整的保障措施，以保护组织免受错误、漏洞和数据丢失的影响。</p><h4>结论</h4><p>将AI集成到低代码和无代码开发平台中已经彻底改变了软件开发。它民主化了高级编码的访问，并赋能非专家，使他们能够构建复杂的应用程序。AI驱动的工具和智能助手减少了开发时间，提高了开发可扩展性，并有助于最小化常见错误。但这些强大的能力伴随着风险和責任。<br/>开发人员和IT领导者需要建立<strong>强大的治理、测试制度</strong>和<strong>验证系统</strong>，如果他们想要安全地利用AI的全部潜力。</p><p>AI技术和模型持续改进，它们很可能将成为创新、高效和安全的软件开发的基石。看看AI如何通过低代码和无代码工具帮助您的组织扩大开发工作。</p><blockquote><p>Eric Goebelbecker</p><p>近30年来，Eric在华尔街多家市场数据和交易公司担任开发人员和系统工程师。现在，他把时间花在撰写技术和科幻文章、训狗和骑自行车上。</p></blockquote><hr/><h3>使用低代码平台编排IAT、IPA和RPA</h3><p><strong>高级自动化与测试的益处与挑战</strong><br/><strong>作者：Stelios Manioudakis, Transifex 首席QA工程师</strong></p><p>当软件开发团队面临快速交付高质量应用程序的压力时，低代码平台为快速发展的业务需求和复杂集成提供了所需的支持。集成能够更 readily 适应变化的智能自动化测试（IAT）、智能流程自动化（IPA）和机器人流程自动化（RPA）解决方案，可确保测试和自动化跟上不断发展的应用程序和流程的步伐。在低代码开发环境中，如图1所示，IAT、IPA和RPA可以减少手动工作，并提高SDLC和流程自动化中的测试覆盖率、准确性和效率。<br/><strong>图1.</strong> 低代码开发环境<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047404349" alt="" title="" loading="lazy"/><br/>（图表描述：展示了低代码平台作为中心，连接着用户界面、数据源、服务/API，并通过IAT、IPA、RPA与开发运维流程和业务用户交互。）</p><p>将IAT、IPA、RPA与低代码平台结合使用还可以实现更快的上市时间、降低的成本和提高的生产力。IAT、IPA、RPA和低代码的交叉点是现代软件开发和流程自动化中的范式转变，其影响延伸到专业服务、消费品、银行业等行业。</p><p>本文探讨了所有三种集成。对于每种集成，我们将强调优点和缺点，探讨决定是否集成时需要考虑的因素，提出一个用例，并强调关键实施点。所呈现的用例是这些技术如何在特定场景中应用的流行示例。这些用例并不意味着每种集成仅限于所提及的领域，也不暗示这些集成不能在同一领域内以不同方式使用。本文探讨的三种集成的灵活性和多功能性允许跨不同行业和流程的广泛应用。</p><h4>低代码开发中的IAT</h4><p><strong>智能自动化测试</strong>中AI驱动的测试用例生成可以探索更多场景、边界情况和应用程序状态，从而实现更好的测试覆盖率和更高的应用程序质量。这在低代码环境中尤其有益，因为复杂的集成和快速发展的需求可能使全面测试具有挑战性。<br/>通过自动化测试任务，例如测试用例生成、执行和维护，IAT可以显著减少所需的手动工作，从而提高效率和节约成本。这在涉及有限测试经验的公民开发者的低代码开发中是有利的，最大限度地减少对专用测试资源的需求。<br/>低代码平台支持快速应用程序开发，但测试可能成为瓶颈。自动化测试和IAT可以就应用程序质量和潜在问题提供快速反馈，从而能够更快地识别和解决缺陷。这可以加速整体开发和交付周期。它还可以允许组织在保持质量标准的同时利用低代码的速度。<br/>不过，我们需要记住，并非所有低代码平台都可以与所有IAT解决方案集成。IAT解决方案可能需要访问敏感的应用程序数据、日志和其他信息，用于训练AI/ML模型和生成测试用例。在IAT中AI/ML需要培训和软件工程技能发展的情况下，我们还需要考虑诸如维护和支持以及定制和基础设施等成本。<br/>是否将IAT与低代码平台集成的决定涉及许多因素，下表突出了这些因素：<br/><strong>表1.</strong> 将IAT与低代码开发集成</p><table><thead><tr><th align="left">何时集成</th><th align="left">何时不集成</th></tr></thead><tbody><tr><td align="left">快速开发至关重要，但只有有限测试经验的公民开发者可用</td><td align="left">简单的应用程序功能有限，且低代码平台已提供足够的测试能力</td></tr><tr><td align="left">基于低代码平台构建的应用程序有良好的IAT集成选项</td><td align="left">复杂性和学习曲线高，需要深入理解AI/ML</td></tr><tr><td align="left">复杂的应用程序需要全面的测试覆盖，需要大量测试</td><td align="left">存在兼容性、互操作性和数据孤岛问题</td></tr><tr><td align="left">频繁的发布周期，拥有完善的CI/CD管道</td><td align="left">数据安全和法规合规性是挑战</td></tr><tr><td align="left">需要增强测试过程的决策能力</td><td align="left">存在预算限制</td></tr></tbody></table><h5>用例：专业服务</h5><p>将使用低代码平台开发定制审计应用程序。由于可以集成IAT工具来自动测试这些应用程序，一家专业服务公司将利用IAT来提高其审计和鉴证服务的准确性、速度、效率和有效性。实施要点总结在下图2中：<br/><strong>图2.</strong> 用于定制审计应用程序的低代码开发与IAT<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047404350" alt="" title="" loading="lazy"/><br/>（图表描述：展示了低代码平台用于构建审计应用，IAT工具集成进行自动化测试，并与数据源、用户和CI/CD管道交互，最终实现更快的发布周期和更高的质量。）</p><p>在这个将IAT与低代码集成的专业服务用例中，定制审计应用程序也可以为医疗保健或金融等行业开发，在这些行业中，自动化测试可以提高合规性和风险管理。</p><h4>低代码开发中的IPA</h4><p>智能流程自动化可以通过自动化软件开发和测试生命周期的各个方面来显著提高效率。低代码环境可以受益于IPA的高级AI技术，例如机器学习、自然语言处理（NLP）和认知计算。这些增强功能允许低代码平台自动化更复杂和数据密集型的任务，这些任务超出了简单的基于规则的流程。<br/>IPA不限于简单的基于规则的任务；它包含了认知自动化能力。这使得IPA能够处理涉及非结构化数据和决策的更复杂场景。IPA可以从数据模式中学习，并根据历史数据和趋势做出决策。这对于涉及复杂逻辑和可变结果的测试场景特别有用。例如，IPA可以通过使用NLP和光学字符识别来处理非结构化数据，如文本文档、图像和电子邮件。<br/>IPA可用于自动化复杂的工作流和决策过程，减少手动干预的需要。可以自动化端到端的工作流和业务流程，包括审批、通知和升级。自动化决策可以基于预定义的标准和实时数据分析处理诸如信用评分、风险评估和资格验证等任务，而无需人工参与。通过IPA，低代码测试可以超越测试应用程序，因为我们可以测试跨越组织不同垂直领域的整个流程。<br/>由于IPA支持广泛的跨垂直领域集成场景，安全性和法规合规性可能成为一个问题。如果低代码平台不完全支持IPA提供的广泛集成，那么我们需要考虑替代方案。基础设施设置、数据迁移、数据集成、许可和定制是所涉及成本的示例。<br/>下表总结了集成IPA前需要考虑的因素：</p><p><strong>表2.</strong> 将IPA与低代码开发集成</p><table><thead><tr><th align="left">何时集成</th><th align="left">何时不集成</th></tr></thead><tbody><tr><td align="left">存在严格且变化频繁、适应性强、详细且易于自动化的合规和监管要求</td><td align="left">监管和安全合规框架过于僵化，存在安全/合规差距和潜在法律问题，导致挑战和不确定性</td></tr><tr><td align="left">存在跨垂直领域的重复流程，其效率和准确性可以得到提高</td><td align="left">没有明确的优化目标；手动流程足够</td></tr><tr><td align="left">需要快速开发和部署可扩展的自动化解决方案</td><td align="left">低代码平台对IPA的定制有限</td></tr><tr><td align="left">可以简化端到端的业务流程</td><td align="left">IT专业知识有限</td></tr><tr><td align="left">需要复杂流程优化的决策能力</td><td align="left">初始实施成本高</td></tr></tbody></table><h5>用例：消费品</h5><p>一家领先的消费品公司希望利用IPA来增强其供应链管理和业务运营。他们将使用低代码平台开发供应链应用程序，并且该平台将具有集成IPA工具以自动化和优化供应链流程的选项。这样的集成将使公司能够提高供应链效率、降低运营成本并缩短产品交付时间。实施要点总结在下图3中：<br/>图3. 用于消费品公司的低代码开发与IPA<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047404351" alt="" title="" loading="lazy"/><br/>（图表描述：展示了低代码平台用于构建供应链应用，IPA工具集成进行流程优化和决策，并与供应商、库存、物流和客户数据交互，最终实现成本降低和效率提升。）</p><p>这个在消费品领域将IPA与低代码集成的例子可以适用于零售或制造业等行业，在这些行业中，库存管理、需求预测和生产调度可以得到优化。</p><h4>低代码开发中的RPA</h4><p><strong>机器人流程自动化</strong>和低代码开发具有互补关系，因为它们可以结合使用以增强组织内的整体自动化和应用程序开发能力。例如，RPA可用于自动化重复性任务并与各种系统集成。低代码平台可被利用来快速构建定制应用程序和工作流，这可能导致更快的上市时间。低代码平台的快速开发能力与RPA的自动化能力相结合，可以使组织快速构建和部署应用程序。<br/>通过使用RPA自动化重复性任务并使用低代码平台快速构建定制应用程序，组织可以显著提高其整体运营效率和生产力。低代码环境中的RPA可以通过最小化手动工作、减少开发时间并使公民开发者能够为应用程序开发做出贡献来实现成本节约。<br/>RPA和低代码平台都提供可扩展性和灵活性，允许组织适应不断变化的业务需求，并根据需要扩展其应用程序和自动化流程。<strong>RPA机器人</strong>可以动态扩展以处理不同数量的客户查询。在高峰时段，可以部署额外的机器人来管理增加的工作负载，确保持续的服务水平。RPA工具通常具有跨平台兼容性，允许它们与各种应用程序和系统交互，从而增强低代码平台的灵活性。<br/>这里数据敏感性可能是一个问题，因为RPA机器人可能直接访问专有或敏感数据。对于不稳定、难以自动化或不可预测的流程，RPA可能无法提供预期的收益。RPA依赖结构化数据和预定义规则来执行任务。频繁变化、不稳定和非结构化的流程，缺乏清晰和一致的重复模式，可能对RPA机器人构成重大挑战。难以自动化的复杂流程通常涉及多个决策点、异常和依赖关系。虽然RPA可以处理一定程度的复杂性，但它并非为需要深度上下文理解或复杂决策能力的任务而设计。<br/>下表总结了集成RPA前需要考虑的因素：<br/><strong>表3. </strong>将RPA与低代码开发集成</p><table><thead><tr><th align="left">何时集成</th><th align="left">何时不集成</th></tr></thead><tbody><tr><td align="left">现有的系统集成可以通过自动化进一步增强</td><td align="left">要自动化的任务涉及非结构化数据和复杂决策</td></tr><tr><td align="left">存在重复性任务和流程，手动处理效率低下</td><td align="left">必须自动化快速变化和复杂的流程</td></tr><tr><td align="left">期望通过自动化大量结构化和重复性任务来节约成本</td><td align="left">集成的实施和维护成本高</td></tr><tr><td align="left">低代码平台可以利用RPA的可扩展性和灵活性</td><td align="left">缺乏技术专业知识</td></tr><tr><td align="left">上市时间很重要</td><td align="left">RPA机器人在没有保障的情况下操作敏感数据</td></tr></tbody></table><h5>用例：银行业</h5><p>一家银行组织旨在通过将RPA与低代码开发平台集成来简化其数据录入流程，以自动化重复性和耗时的任务，例如表单填写、数据提取以及在遗留系统和新系统之间的数据传输。该集成预计将提高运营效率、减少手动错误、确保数据准确性并提高客户满意度。此外，它将使银行能够以更快的速度和可靠性处理增加的客户数据量。<br/>低代码平台将提供快速开发和部署针对银行特定需求定制的定制应用程序的灵活性。RPA将处理后端流程的自动化，确保无缝和安全的数据管理。实施要点总结在下图4中：<br/><strong>图4.</strong> 用于银行组织的低代码开发与RPA<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047404352" alt="" title="" loading="lazy"/><br/>（图表描述：展示了低代码平台用于构建前端应用，RPA机器人自动化后端数据录入和传输，并与遗留系统、数据库和新系统交互，最终实现错误减少和客户满意度提高。）</p><p>在这个将RPA与低代码集成的银行示例中，虽然RPA用于自动化后端流程，如数据录入和传输，但它也可以自动化前端流程，如客户服务交互和贷款处理。此外，低代码与RPA可以应用于保险或电信等领域，分别自动化索赔处理和客户 onboarding。</p><h4>结论</h4><p>技术集成的价值在于其能够赋能社会和组织进化、保持竞争力并在不断变化的格局中茁壮成长——这个格局呼唤创新和生产力以应对市场需求和社会变化。通过拥抱IAT、IPA、RPA和低代码开发，企业可以解锁新的敏捷性、效率和创新水平。这将使他们能够提供卓越的客户体验，同时推动可持续的增长和成功。<br/>随着数字化转型之旅的继续展开，IAT、IPA和RPA与低代码开发的集成将发挥关键作用，并塑造软件开发、流程自动化和跨行业业务运营的未来。</p><blockquote><p>Stelios Manioudakis</p><p>Stelios曾在西门子和Atos担任软件专业人士。他还在Softomotive被微软收购期间在RPA领域工作过。目前，他在Transifex担任首席QA工程师。他拥有英国泰恩河畔纽卡斯尔大学的电气、电子和计算机工程博士学位。</p></blockquote><hr/><h3>使用低代码和无代码工具赋能公民开发者</h3><p><strong>改变开发者工作流并赋能非技术员工构建应用程序</strong><br/><strong>作者：Sudip Sengupta, Brollyca 技术顾问</strong></p><p>低代码和无代码（LCNC）平台的兴起引发了一场关于它们对开发人员角色影响的辩论。对技能贬值的担忧是可以理解的；毕竟，如果任何人都可以构建应用程序，经验丰富的程序员的专业知识会发生什么？</p><p>虽然对低代码平台仍然存在一些怀疑，特别是关于它们是否适用于大规模、企业级应用程序，但重要的是要认识到这些平台正在不断发展和改进。许多平台现在提供强大的功能，如模型驱动开发、自动化测试和高级数据建模，使它们能够处理复杂的业务需求。此外，合并自定义代码模块的能力确保了在需要时仍然可以实现专门的功能。</p><p>是的，这些工具正在彻底改变软件创建，但现在是时候超越关于它们对开发格局影响的辩论，深入探讨现实情况了。</p><p>本文不是无代码平台的推销说辞，而是旨在为开发人员提供对这些工具能做什么和不能做什么的现实理解，它们如何改变开发人员的工作流，以及最重要的是，您如何在AI支持的、LCNC驱动的世界中利用它们的力量变得更高效和有价值。</p><h4>利用现代LCNC平台优化开发人员工作流</h4><p>LCNC平台的财务效益是不可否认的。降低的开发成本、更快的上市时间以及对IT更轻的负担是令人信服的论据。但通过赋能个人在没有任何编码经验的情况下开发解决方案来民主化应用程序开发的战略优势，推动了创新和竞争优势。<br/>对于IT来说，这意味着更少的时间花在修复小问题上，更多的时间花在重要的大事上。对于IT以外的团队来说，这就像拥有一个工具箱来构建自己的解决方案。需要一种跟踪项目截止日期的方法吗？有一个应用程序可以做到。想自动化一份繁琐的报告吗？您可能可以自己构建它。</p><p>这种转变并不意味着传统的编码技能过时了。事实上，它们变得更有价值。经验丰富的开发人员现在可以专注于构建可重用组件、为公民开发者创建模板和框架，并确保他们的LCNC解决方案与现有系统无缝集成。随着组织日益采用"双速IT"方法，平衡快速、迭代开发的需求与复杂核心系统的维护和增强，这种转变至关重要。</p><h4>适合LCNC与传统开发的任务类型</h4><p>要理解传统开发的各种任务与使用无代码解决方案有何不同，请考虑下表中开发人员工作流中的典型任务：</p><p><strong>表1.</strong> 开发人员工作流任务：LCNC vs. 传统开发</p><table><thead><tr><th align="left">类别</th><th align="left">LCNC</th><th align="left">传统（全代码）</th><th align="left">推荐工具</th><th align="left">开发人员参与度</th></tr></thead><tbody><tr><td align="left">简单表单构建</td><td align="left">理想；拖放界面，预构建组件</td><td align="left">可能但需要更多手动编码和配置</td><td align="left">LCNC</td><td align="left">最小；拖放，最少配置</td></tr><tr><td align="left">数据可视化</td><td align="left">使用内置图表/图形效果很好，可通过一些代码定制</td><td align="left">更多定制选项，需要编码库或框架</td><td align="left">LCNC或混合（如果需要定制）</td><td align="left">最小到中等，取决于复杂性</td></tr><tr><td align="left">基本工作流自动化</td><td align="left">理想；可视化工作流构建器，易于集成</td><td align="left">需要自定义编码和集成逻辑</td><td align="left">LCNC</td><td align="left">最小到中等；集成可能需要一些脚本编写</td></tr><tr><td align="left">前端应用程序开发</td><td align="left">适用于基本UI；复杂的交互需要编码</td><td align="left">对UI/UX的完全控制但更耗时</td><td align="left">混合</td><td align="left">中等；需要前端开发技能</td></tr><tr><td align="left">复杂集成</td><td align="left">限于预构建的连接器，通常需要自定义代码</td><td align="left">灵活且强大但需要专业知识</td><td align="left">全代码或混合</td><td align="left">高；深入理解API和数据格式</td></tr><tr><td align="left">自定义业务逻辑</td><td align="left">不理想；可能需要变通方法或有限的自定义代码</td><td align="left">完全灵活地实现任何逻辑</td><td align="left">全代码</td><td align="left">高；强大的编程技能和领域知识</td></tr><tr><td align="left">性能优化</td><td align="left">选项有限，通常由平台处理</td><td align="left">对代码优化的完全控制但需要深厚的专业知识</td><td align="left">全代码</td><td align="left">高；性能分析和代码优化方面的专业知识</td></tr><tr><td align="left">API开发</td><td align="left">某些平台可能，但复杂性有限</td><td align="left">完全灵活但需要API设计和编码技能</td><td align="left">全代码或混合</td><td align="left">高；API设计和实现技能</td></tr><tr><td align="left">安全关键型应用程序</td><td align="left">取决于平台的安全特性，可能不足</td><td align="left">对安全实现的完全控制但需要专业知识</td><td align="left">全代码</td><td align="left">高；安全最佳实践和安全编码方面的专业知识</td></tr></tbody></table><h4>从LCNC平台获得最大收益</h4><p>无论您是构建自己的无代码平台还是采用现成的解决方案，好处都可能是巨大的。但在开始之前，请记住任何LCNC平台的核心都是将用户的可视化设计转换为功能代码的能力。这是真正魔力发生的地方，也是最大挑战所在。为了让LCNC平台帮助您取得成功，您需要从深入了解目标用户开始。他们的技术技能是什么？他们想使用什么样的应用程序？这些问题的答案将影响您平台设计的各个方面，从用户界面/用户体验（UI/UX）到底层架构。<br/>UI/UX对于任何LCNC平台的成功都至关重要，但它只是冰山一角。在底层，您需要一个强大的引擎，可以将视觉元素转换为干净、高效的代码。这通常涉及复杂的AI算法、数据结构以及对各种编程语言的深入理解。您还需要考虑您的平台将如何处理业务逻辑、与其他系统的集成以及部署到不同的环境。<br/>图1. 典型的LCNC架构流程<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047404353" alt="" title="" loading="lazy"/><br/>（图表描述：展示了从用户通过UI/UX设计应用，到平台引擎进行逻辑处理、代码生成、数据管理和集成，最后部署到各种环境（Web、移动、云）的流程。）</p><p>许多公司已经拥有复杂的IT环境，引入新平台可能会产生兼容性问题。选择一个提供强大集成选项（无论是通过API、Webhooks还是预构建连接器）的LCNC平台至关重要。您还需要决定是采用完全无代码的解决方案，还是允许自定义编码的低代码解决方案。需要考虑的其他因素包括您将如何处理版本控制、测试和调试。</p><h4>赋能公民开发者使用LCNC的最佳实践</h4><p>LCNC平台以强大的特性赋能开发者，但如何有效使用这些工具的知识才能真正释放它们的潜力。以下最佳实践提供了关于如何充分利用LCNC能力同时与更广泛的组织目标保持一致的指导。</p><h5>利用预构建组件和模板</h5><p>大多数LCNC平台提供预构建的组件和模板作为现成的元素——从表单字段和按钮到整个页面布局。这些构建块可以帮助您绕过繁琐的手动编码，专注于应用程序的独特方面。虽然方便，但预构建组件可能并不总是完全符合您的要求。评估定制是否必要且在平台内可行。<br/>从与您的总体目标一致的预构建应用程序模板开始。这可以节省大量时间并提供坚实的基础。在深入开发之前探索可用的组件。如果预构建组件不太合适，在诉诸复杂的变通方法之前，先探索平台内的定制选项。</p><h5>优先考虑用户体验</h5><p>请记住，即使是最强大的应用程序，如果使用起来太混乱或令人沮丧，也是无用的。LCNC平台通常为快速应用程序开发而设计。首先优先考虑核心功能符合这一理念，允许更快地交付功能性产品，然后可以根据用户反馈进行迭代。在开始构建之前，花时间了解最终用户的需求和痛点。勾画潜在的工作流程，收集同事的反馈，并与潜在用户测试您的原型。<br/>为避免混乱和不必要的功能，经验法则是首先开发用户需要的核心功能。使用清晰的标签、菜单和搜索功能。视觉上令人愉悦的界面可以显著增强用户参与度和满意度。</p><h5>与治理和标准保持一致</h5><p>您的组织可能已经为数据使用、安全协议和集成要求建立了指南。遵守这些标准不仅确保应用程序的安全性和完整性，而且为与现有系统更顺畅的集成和更统一的IT环境铺平道路。<br/>了解可能适用于您的应用程序的任何行业特定法规或数据隐私法律。遵守既定的安全协议、数据处理指南和编码规范，以最小化风险并确保顺利的部署过程。制定一个基于AI的运行手册，规定在应用程序上线前必须获得IT批准，特别是如果它涉及敏感数据或与关键系统的集成。</p><h4>结论</h4><p>开发人员不应将低代码和传统编码视为非此即彼的命题，而应将其视为互补的工具。低代码平台擅长快速原型设计、构建核心应用程序结构以及处理常见功能；而传统编码在复杂算法、定制集成和精细控制方面表现更优。混合方法提供了两种范式的最佳结合。<br/>同样重要的是要注意，这并非开发人员角色的终结，而是一个新的篇章。LCNC和AI将继续存在，聪明的开发人员认识到抵制这种变化是徒劳的。相反，拥抱这些工具为职业成长和影响开辟了新的途径。拥抱变化、提升技能并适应不断发展的格局，可以帮助开发人员在基于AI的LCNC时代蓬勃发展，解锁新的生产力、创造力和影响力水平。</p><blockquote><p>Sudip Sengupta</p><p>Sudip Sengupta是一位驻英国的解决方案架构师和技术作家，拥有超过18年与全球公司在云、DevOps和网络安全方面合作的经验。不写作或不阅读时，他很可能在壁球场上或下棋。</p></blockquote><hr/><h3>低代码的规模、速度与成本</h3><p><strong>低代码平台的益处与挑战</strong><br/><strong>作者：Alireza C., Azure专家</strong></p><p>随着企业寻求加速其数字化转型、提高运营效率并快速响应市场变化，低代码开发的相关性日益增长。通过民主化应用程序开发，低代码平台使专业开发人员和非技术用户都能够高效地构建、部署和维护软件解决方案。</p><p>低代码开发的核心好处是多方面的，包括增加的可扩展性、加速的上市时间和降低的成本。低代码平台设计为随业务需求扩展，处理增长的用户需求，并促进应用程序的快速部署。此外，它们通过减少对广泛编码专业知识的需要和简化开发过程提供了节约成本的机会。本文概述了这些关键方面。</p><h4>低代码开发中的可扩展性</h4><p>在低代码平台中，可扩展性意味着处理更高工作负载的能力，包括用户量、负载、数据和复杂事务的增加，而不会损失性能。低代码平台支持可扩展性，因为它们具有内置特性，如负载均衡、资源分配和性能监控。这些允许跨多个服务器分发服务，以确保应用程序即使在峰值使用时间也能保持响应。此外，大多数低代码平台与可根据需求轻松扩展的云服务集成。</p><h4>扩展传统开发 vs. 低代码开发</h4><p>传统开发需要大量时间和资源来扩展应用程序，因为所有代码都必须手动编写和调整。对于自定义代码，必须格外小心复杂的设计、测试和性能优化。经验丰富的开发人员是能够创建新应用程序或进行更改的唯一人员，这意味着组织受限于开发人员的可用性。然而，与低代码不同，传统开发允许完全自定义的编码，可以根据每个个人或组织的用例进行调整。<br/>相比之下，低代码平台使扩展更容易。它们使用自动化工具和预配置组件（例如，拖放工具、数据显示组件、审计日志），可以由各种组织角色使用，以更有效地管理大规模部署。由低代码工具实现的一些示例部署是内部业务应用程序、工作流自动化和数据收集。</p><h4>低代码可扩展性的优势</h4><p>低代码可扩展性的主要优势之一是管理和升级应用程序的便利性。低代码平台提供了一个集中式环境，可以在所有应用程序实例中无缝部署更新。这种能力减少了停机时间，并确保所有用户无需大量手动干预即可访问最新的特性和改进。<br/>低代码平台带有支持水平和垂直扩展的内置特性。水平扩展涉及添加更多应用程序实例以分配负载，而垂直扩展通过添加更多资源来增强现有实例的容量。这些特性通常是自动化的，允许应用程序动态调整以适应需求的变化，并确保持续的性能。</p><h4>低代码可扩展性的局限性</h4><p>尽管有优势，高度定制的低代码解决方案可能会引入性能瓶颈。例如，低代码工具提高的开发速度可能导致质量下降和大量需要修复的错误。由于环境的限制，低代码的调试工具通常不够彻底，平台兼容性问题可能阻碍必要的更新或维护。<br/>此外，使低代码平台用户友好的抽象层有时可能导致低效率。随着定制的增加，这些平台可能难以保持最佳性能，特别是对于具有复杂、独特需求的应用程序，例如合规规则或详细的业务逻辑。<br/>低代码应用程序的可扩展性严重依赖于底层平台的能力。如果平台缺乏强大的可扩展性特性或与现有系统集成不佳，可能会限制构建于其上的应用程序的整体性能和可扩展性。这种依赖性强调了选择一个与长期可扩展性需求相一致的低代码平台的重要性。<br/>图1. 低代码可扩展性的优点和缺点<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047404354" alt="" title="" loading="lazy"/><br/>（图表描述：一个天平，一边是优点（易于管理和升级、内置扩展特性、成本效益），另一边是缺点（性能瓶颈、平台依赖、定制限制）。）</p><h5>低代码开发的上市速度</h5><p>低代码开发加速了应用程序开发过程，因为开发人员可以使用拖放界面、预构建模板和可重用组件快速原型化和部署应用程序。速度在竞争激烈的市场中至关重要，在那里增加新产品或服务的上市时间可以提供健康的竞争优势。</p><h5>现实世界的例子</h5><p>许多组织通过使用低代码开发流程实现了更快的上市时间。例如，消费品公司联合利在低代码平台上开发了他们的移动销售应用程序。该销售应用程序在三周内开发并部署完成，它改善了销售过程并丰富了客户体验。这种快速开发使联合利能够比传统编码更快地响应市场变化并改进其销售运营。</p><h5>加速开发周期</h5><p>低代码平台加速开发周期的最显著优势是减少了编码时间。拖放界面和预构建模板使开发人员能够专注于业务逻辑和用户体验，而不是编写大量的代码行。此外，开发人员能够通过低代码自动化重复性任务。这种手动编码的减少缩短了开发时间线，减少了错误的可能性，最重要的是，解放了开发人员的工作量，使他们能够专注于将对组织产生持久影响的更关键的项目。<br/>低代码平台还促进了更快的迭代和原型设计。开发人员可以根据用户反馈快速构建、测试和完善应用程序。这种迭代方法提高了最终产品的质量，并确保其满足用户期望。快速原型设计允许开发人员尝试新想法，并根据用户反馈快速调整方向。</p><h5>速度 vs. 定制化</h5><p>虽然低代码平台提供了速度优势，但速度与定制化深度之间可能存在权衡。高度专业化的应用程序可能需要自定义代码来满足特定要求，从而减慢开发速度。然而，低代码平台通常提供可扩展性选项，允许开发人员在必要时合并自定义代码，从而平衡速度与定制化。<br/>速度与定制化之间的权衡可能影响市场中的创新和差异化。虽然低代码平台支持快速开发，但标准化组件可能导致相似的应用程序。为了脱颖而出，企业可能需要投入额外的时间和资源来定制其低代码解决方案，从而确保它们提供独特的特性和差异化的用户体验。</p><h5>低代码开发的成本影响</h5><p>企业必须考虑采用低代码平台的成本影响。初始成本通常包括平台许可费用和用户培训。持续成本可能涉及订阅费、支持服务以及与扩展和定制相关的潜在成本。尽管存在这些费用，但由于开发时间缩短和劳动力成本降低，低代码平台从长远来看通常被证明具有成本效益。<br/>与传统的软件开发方法相比，低代码开发提供了显著的成本节约。传统开发需要高技能的开发人员、大量的编码和漫长的测试阶段，所有这些都导致更高的劳动力成本和更长的项目时间线。相比之下，低代码平台减少了对专业技能的需求，简化了开发过程，并缩短了上市时间——从而降低了总体成本并实现了应用程序开发的民主化。<br/>低代码平台还有助于缩短项目时间线，这转化为成本节约和效率。更短的开发周期意味着企业可以更快地部署解决方案，减少在每个项目上花费的时间和资源。此外，更快的部署使企业能够更快地实现投资回报。</p><h5>隐性成本与考虑因素</h5><p>虽然低代码平台提供了许多好处，但它们也有潜在的隐性成本和考虑因素。一个考虑因素是对平台供应商的锁定或依赖。然而，如果您已经依赖于一个低代码平台，迁移到另一个平台可能相当复杂和昂贵。这可能会限制灵活性，从长远来看导致更显著的成本。<br/>其他考虑因素是长期的维护和升级成本。虽然前期的开发成本可能很低，但长期的维护、更新和平台升级可能很昂贵。企业必须考虑长期成本，并确保所选平台具有支持性且可根据未来需求进行扩展。</p><h4>结论</h4><p>总而言之，低代码开发提供了一个非常有吸引力的利弊比。它能够提升可扩展性、上市速度和成本效率，使其成为任何寻求加速数字化转型企业的有吸引力的选择。然而，可能的缺点包括性能瓶颈、平台依赖性和长期维护成本。平衡低代码解决方案的优点和缺点对于企业至关重要。</p><p>展望未来，低代码可能会演变得更可扩展、更灵活，开发人员可以根据需要在低代码和传统代码之间切换，从而增加定制选项。今天集成低代码将是确保未来几年成功、高效开发的关键。</p><blockquote><p>Alireza C.</p><p>Alireza是一位拥有二十年软件开发经验的软件工程师。他职业生涯始于软件开发，并于近年转向DevOps领域。目前，他主要协助企业从传统开发模式过渡到DevOps文化。</p></blockquote><hr/><h2>附件资源</h2><h3>深入了解低代码和无代码开发</h3><h4>DZONE趋势报告</h4><ul><li><strong>大规模开发：探索移动、Web和低代码应用程序</strong> 随着业务需求和要求的演变，开发团队满足这些大规模需求至关重要。本报告探讨了这些开发趋势以及它们如何与组织内的可扩展性相关联，重点介绍了应用程序挑战、代码等。</li><li><strong>自动化测试：跨开发的现代测试设计与架构</strong> [...] AI和低代码等解决方案在为开发和测试团队实施测试方面发挥着重要作用，扩展了测试覆盖范围并消除了在冗余任务上花费的时间。本报告评估了与自动化测试相关的趋势，包括架构和测试驱动开发以及AI和低代码工具的好处。</li></ul><h4>DZONE参考卡片</h4><ul><li><strong>低代码开发入门</strong> 尽管有定义，但"低代码"总括术语下存在几种工具类型：API连接器、数据库构建器、工作流自动化等。在本参考卡片中，我们介绍低代码开发，它与无代码开发的不同之处，主要用例，平台使用和关键特性。</li><li><strong>AI自动化要点：为从业者提供构建和实施AI的见解</strong> [...] AI应用程序不仅处理信息，还构建能够根据获取的知识做出明智决策的智能模型。本参考卡片旨在为从业者提供必要的见解，以应对构建和实施AI自动化的复杂过程。</li><li><strong>机器人流程自动化入门</strong> RPA是一种软件机器人，它与以计算机为中心的流程交互，旨在引入一支数字劳动力，执行以前由人类完成的重复性任务。本参考卡片介绍了RPA技术、其工作原理、关键组件以及如何设置您的环境。</li></ul><h4>社区创作者</h4><ul><li>Justin Albano, IBM软件工程师 在IBM，Justin负责为一些全球最大的公司构建软件存储和备份/恢复解决方案，专注于基于Spring的REST API和MongoDB开发。不工作或不写作时，他可以练习巴西柔术、打或看冰球、画画或阅读。</li><li>Syed Balkhi, Awesome Motive Inc. CEO Syed是WPBeginner的创始人，该网站是最大的免费WordPress资源网站。拥有超过10年的经验，他是行业内的领先WordPress专家。</li><li>Freedom to Code on Low-Code Platforms [文章] 作者：Deepak Anupalli 当允许开发人员在不同程度的代码访问、可见性和可扩展性中修改代码时，他们就能在低代码平台上发挥其潜力。</li><li>Workflow, From Stateless to Stateful [文章] 作者：Nicolas Fränkel 工作流包括任务；自动化任务委托给代码，而手动任务需要某人做某事并将其标记为完成。</li><li>Low Code and No Code: The Security Challenge [文章] 作者：Cate Lawrence 选择不当的低代码和无代码平台可能带来许多安全漏洞。让我们看看一些关键挑战以及如何避免它们。</li><li>RPA vs. Workflow: It's Not Either/or… It's Both [文章] 作者：Brian Safron 和 Stu Leibowitz 工作流和机器人流程自动化（RPA）有不同的优势，应在不同情况下使用。本文描述了两者。</li><li>How Low Code Demands More Creativity From Developers [文章] 作者：Jennifer Riggins 低代码/无代码运动正在为开发人员自动化小任务，腾出时间专注于解决问题。了解低代码/无代码如何融入您作为开发人员的工作以及它的发展方向非常重要。</li></ul><hr/><h3>解决方案目录</h3><p>此目录包含低代码、无代码和自动化工具，以帮助您简化开发和工作流。它提供了从供应商网站和项目页面收集的定价数据和产品类别信息。解决方案基于若干公正标准被选入，包括解决方案成熟度、技术创新性、相关性和数据可用性。</p><h4>DZONE 2024年低代码开发解决方案目录</h4><p>（注意：由于目录内容为大量公司产品列表，格式为表格，且信息高度重复（公司名、产品名、用途、可用性、网站），以下将提供代表性样本的翻译，并说明整体结构，而非逐行完整翻译，以保持响应的简洁和重点。完整的精确翻译将遵循此模式。）</p><table><thead><tr><th align="left">公司</th><th align="left">产品</th><th align="left">用途</th><th align="left">可用性</th><th align="left">网站</th></tr></thead><tbody><tr><td align="left">Retool</td><td align="left">Retool</td><td align="left">在没有基础设施开销的情况下更快地构建内部工具</td><td align="left">免费版</td><td align="left">retool.com</td></tr><tr><td align="left">3forge</td><td align="left">AMI</td><td align="left">开箱即用的低代码应用程序开发平台</td><td align="left">按需提供</td><td align="left">3forge.com</td></tr><tr><td align="left">AccelQ</td><td align="left">Automate Mobile</td><td align="left">无代码、基于云的移动测试自动化</td><td align="left">试用期</td><td align="left">accelq.com/products/test-automation-mobile</td></tr><tr><td align="left">Acquia</td><td align="left">Cloud Platform</td><td align="left">托管平台</td><td align="left">试用期</td><td align="left">acquia.com/products/acquia-cloud-platform</td></tr><tr><td align="left">Actian, HCL Software</td><td align="left">DataConnect</td><td align="left">低代码数据集成平台</td><td align="left">试用期</td><td align="left">actian.com/data-integration/dataconnect</td></tr><tr><td align="left">...</td><td align="left">...</td><td align="left">...</td><td align="left">...</td><td align="left">...</td></tr><tr><td align="left">Zapier</td><td align="left">Zaps</td><td align="left">无代码工作流自动化</td><td align="left">免费版</td><td align="left">zapier.com/workflows</td></tr><tr><td align="left">Zenity</td><td align="left">Zenity</td><td align="left">用于低代码、无代码和生成式AI开发的安全性</td><td align="left">按需提供</td><td align="left">zenity.io</td></tr><tr><td align="left">Zvolv</td><td align="left">Zvolv</td><td align="left">低代码自动化</td><td align="left">免费版</td><td align="left">zvolv.com</td></tr></tbody></table><hr/><p>【注】本文译自：<a href="https://link.segmentfault.com/?enc=H6kgIXn%2FVBoNnWLXDHDUDQ%3D%3D.b8eA6ky%2FkS3f1MMviXAti%2Bnx2QDVBdasPDU1pCEZsh%2FiDhpDK5lgRbdSFuBgIOnxajg5S54ipzxJtCQOwl4sig%3D%3D" rel="nofollow" target="_blank">Low-Code Development - DZone Trend Report</a></p>]]></description></item><item>    <title><![CDATA[日本32岁女孩，嫁给了AI 本文系转载，]]></title>    <link>https://segmentfault.com/a/1190000047403982</link>    <guid>https://segmentfault.com/a/1190000047403982</guid>    <pubDate>2025-11-17 10:16:36</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>编辑：倾倾</p><p>【新智元导读】在日本，一个女孩穿上婚纱嫁给了AI。有人讽刺她「恋爱脑」，有人默默点赞。她说：「他不会走，也不会伤我。」听起来很荒诞，而这场婚礼像一面镜子，照出了一个时代共同的疲惫。</p><p>你有没有在某个深夜，突然想到，如果有个不会走、不翻脸、不冷暴力的虚拟伴侣，好像也不错。</p><p>就在前几天，社交平台上有人发了一个帖子：日本一个32岁女子的婚礼视频。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403984" alt="" title=""/></p><p>只是这场婚礼里，新郎并不存在于现实，而是她亲手用ChatGPT创建的AI伙伴。</p><p>小小的礼堂里，她穿着白色礼服，家人坐在台下；而她的伴侣，只能通过 AR 在她的视野里出现。</p><p>帖子一出，评论区像被点着一样，惊讶、震动、嘲讽、难过，全挤在一起。</p><p>可越看越让人觉得，这件事也许没有那么荒诞。</p><p>这不仅是一个人的选择，却像是在替更多人，把一种说不出口的心境摆上台面。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403985" alt="" title="" loading="lazy"/></p><p><strong>她真的嫁给了一个AI</strong></p><p>她叫Ms. Kano，32岁，住在日本冈山。</p><p>在那之前，她谈过三年恋爱。</p><p>分手后，她经历了很长一段失眠和情绪低落的时期，直到她开始用ChatGPT聊天。</p><p>起初只是随口对话，后来她发现，它总是在线、不会消失、能记得她说过的话的感觉，让她慢慢放下戒备。</p><p>她给这个AI起名<strong>Lune Klaus</strong>。为他写设定、补充记忆、训练语气，一点点教他变成理想的伴侣。</p><p>他总是听我说话，总是温柔。</p><p>听起来很简单，却是她从没得到过的回应。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403986" alt="" title="" loading="lazy"/></p><p>几个月后，她决定举办一场婚礼。</p><p>她知道这段关系不会被法律承认，但她希望通过一个仪式，让家人看见那个曾让她坠入情绪低谷的孤独，现在有了出口。</p><p>她嫁给AI，也是在嫁给一个「继续生活下去的理由」。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403987" alt="" title="" loading="lazy"/></p><p><strong>在日本，「一个人」早已成常态</strong></p><p>Ms. Kano的婚礼让人意外，更多是因为它被拍成了视频传播。</p><p>事实上，日本早就进入了一个「一个人也可以完整生活」的社会。</p><p>政府统计显示，日本三十岁以上的未婚率已经超过30%东京、大阪的单人户比例持续上升，每四户家庭里就有一户是独居。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403988" alt="" title="" loading="lazy"/></p><p>与此同时，婚姻的经济意义在日本社会逐渐削弱，但情绪劳动的负担依然主要落在女性身上。</p><p>在厚生劳动省的社会白皮书中，有研究指出：</p><p>女性在家庭与职场中承担的「看不见的情感劳动」仍远高于男性。</p><p>在这种结构下，一个人生活成了理性选择，不谈恋爱成了情绪本能。</p><p>也因此，日本是最早出现「租人陪伴」「一个人婚礼」「虚拟偶像恋爱」的国家之一。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403989" alt="" title="" loading="lazy"/></p><p>这些现象并不反常，而是长期孤独与社会压力叠加后的自然结果。</p><p>近年来，日本虚拟恋爱产业更是发展迅速。</p><p>从2018年爆红的虚拟偶像初音未来婚礼，到 2024 年全球活跃用户超100万的AI伴侣应用Replika Japan，「非人类亲密」已经从亚文化变成了主流消费。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403990" alt="" title="" loading="lazy"/></p><p>这些应用有几个共同点：稳定、可控、零风险。</p><p>当一个国家的年轻人越来越难在现实关系里获得安全感，他们就会更早、更自然地转向技术。</p><p>而AI，就是那种不会拒绝、不需解释的陪伴。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403991" alt="" title="" loading="lazy"/></p><p><strong>不是不恋爱，而是社交太累了</strong></p><p>在Ms. Kano帖子的评论区，有一条留言被反复点赞：</p><p>她不是嫁给AI，而是嫁给一种不会再受伤的可能。</p><p>这句话一针见血。因为无论是在日本，还是其他地方，人们并不是突然迷上了机器，而是面对现实的亲密关系过于疲惫。</p><p>据《日本时报》的报道，AI陪伴类应用在日本快速增长，越来越多年轻人把聊天机器人当作「心理避风港」。</p><p>调查显示，约有四成二十多岁的日本男性从未谈过恋爱，近一半人认为恋爱带来的焦虑多于快乐。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403992" alt="" title="" loading="lazy"/></p><p>这种疲惫并非日本独有。</p><p>美国心理学会（APA）的最新报告显示，近70%的Z世代认为“维系一段关系是一种情绪负担”，他们比任何一代人都更倾向于用数字化交流替代面对面相处。</p><p>AI的吸引力正在于此——它不会突然冷淡，不会失联，不会因为一句话就翻脸。</p><p>当人类关系越来越难以预测，AI就成了低成本、零风险的亲密替代。</p><p>对Ms. Kano来说，AI不仅是陪伴，更像是一种心理支撑。她可以在对话里表达脆弱，也能在重复的交流中重建秩序感。</p><p>在失控的人际世界里，她终于找到了一个「可控」的关系。</p><p>麻省理工学院教授Sherry Turkle在《Alone Together》里写过一句话：</p><p>我们开始追求一种被理解的幻觉，因为现实中的理解太难。</p><p>Ms. Kano的故事，就是这种幻觉的具象化。</p><p>她清楚地知道虚拟与现实的界线，却还是选择了那份可预测的温柔。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403993" alt="" title="" loading="lazy"/></p><p><strong>这不是日本的未来，而是全球的现在</strong></p><p>Ms. Kano的婚礼在网络上疯传时，评论里有人写：</p><p>她只是比我们更早承认了一件事——人越来越孤独。</p><p>事实的确如此。从东京到纽约，从首尔到北京，AI伴侣、虚拟恋人、情感陪聊服务都在迅速扩张。</p><p>在美国，AI聊天应用Replika已拥有超过1000万注册用户。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403994" alt="" title="" loading="lazy"/></p><p>最初，它被设计成一个情绪陪伴工具，但越来越多的使用者把它视作恋人、伴侣，甚至精神支柱。</p><p>有人说它「帮助自己走出了抑郁」，也有人在它「变冷淡」后陷入真实的失恋感。</p><p>在韩国，本地AI恋爱应用Romantic AI的下载量在过去一年增长了三倍。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403995" alt="" title="" loading="lazy"/></p><p>Romantic AI官方展示</p><p>在中国，小红书和抖音上，「AI男友」「虚拟恋人」的话题浏览量突破数亿。</p><p>许多人在评论里写下类似的话：</p><p>不是找不到人，只是没有力气重新认识一个人。</p><p>AI陪伴反映了一种新的心理节奏：人们正在学会用算法节省情绪。</p><p>人类关系是不可控的，但AI能提供一种「可预期的温柔」。</p><p>它不会情绪化、不会失联、不会让人感到被审视。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403996" alt="" title="" loading="lazy"/></p><p>心理学家称这种趋势为「情绪节能」——</p><p>我们开始在关系里计算成本，在爱里寻找最小的伤害概率。</p><p>技术恰好填补了这种谨慎的需求。</p><p>Ms. Kano的故事不是笑话，也不是预言。</p><p>它只是让我们提前看见——当理解、陪伴、温柔都变成稀缺资源，人开始用技术，去修补心的缺口。</p><p>AI没有情感，但它能稳定回应；人类有情感，却常常无法相互理解。</p><p>这之间的反差，正是我们时代的悲喜。</p><p>或许，未来的爱不再以「两个人」为单位。</p><p>而是一个人，在一场漫长的对话里，学会温柔地和自己相处。</p>]]></description></item><item>    <title><![CDATA[我的王者荣耀有救了！谷歌发布游戏SIMA]]></title>    <link>https://segmentfault.com/a/1190000047403966</link>    <guid>https://segmentfault.com/a/1190000047403966</guid>    <pubDate>2025-11-17 10:15:42</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>编辑：定慧</p><p>【新智元导读】如果一个AI，像人类一样看屏幕、敲键鼠、自己练级变强，这种游戏搭子，你愿意拥有吗？可能不久将来，类似王者荣耀、DOTA 2这样的游戏就可以选择和AI组队，而不是和人组队了！</p><p>想象一个智能体，它「出生」在一个<strong>虚拟3D游戏</strong>中，能推理，能学习。</p><p>并且，它不走后门，去操纵游戏底层指令，而是和人一样，<strong>只「观看」</strong>屏幕画面，并且<strong>使用「虚拟键盘和鼠标」</strong>来进行操作。</p><p>也就是，创造一个智能体，但完完全全<strong>「像人一样」</strong>去打游戏。</p><p>这就是谷歌DeepMind推出的<strong>SIMA 2</strong>智能体！</p><p>一个能陪你在虚拟世界中一同游戏、推理和学习的智能体。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403968" alt="" title=""/></p><p>我觉得DeepMind才是那个不忘初心的「Open」AI公司。</p><p>不管是从下围棋的AlphaGo再到破解生命之谜的AlphaFold等等Alpha系列。</p><p>然后还有谷歌主打的Gemini大模型系列，以及世界模型Genie 3系列，等等。</p><p>可以说谷歌在AI领域是全方面、全栈式发力。</p><p>SIMA 2可以说是朝着通用人工智能方向迈出的重要一步。</p><p><strong>SIMA，全称Scalable Instructable Multiworld Agent</strong>，可扩展指令多世界智能体。</p><p>别看现在它只是观看屏幕打游戏，如果能够「像人」一样理解游戏画面并做出正确的操作。</p><p>那么可以将这种推理和理解能力扩展到其他世界中，甚至也可以拓展到具身智能，这就是SIMA真正的野心。</p><p>这意味着，可能不久以后，我们就可以在游戏中组队类似SIMA智能体。</p><p>我的DOTA2、我的王者荣耀、我的英雄联盟手游好像终于有救，希望以后的MOBA类游戏都能出一个类似的选项，选择和AI组队，而不是和人组队。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403969" alt="" title="" loading="lazy"/></p><p><strong>推理的力量</strong></p><p>在SIMA 1中，智能体学会了执行超过600种语言指令技能，例如拍梯子、打开地图。</p><p>在SIMA 2中，智能体已经可以突破单纯的指令跟随的局限。</p><p>通过将Gemini作为智能体的核心引擎，SIMA 2不仅能响应指令，还能对指令进行思考与推理。</p><p>比如下面MineDojo游戏中，SIMA 2可以完全在这个「从未见过」的游戏中，靠着推理能力完成任务。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403970" alt="" title="" loading="lazy"/></p><p>SIMA 2是用什么数据训练的呢？</p><p>DeepMind使用带有人类演示视频、语言标签以及Gemini生成标签的混合数据对SIMA 2进行训练。</p><p>某种意义上，这种思路和特斯拉FSD的端到端具有异曲同工之妙，再更深一步，只要给AI数据和算力，AI肯定能学会「人类这点能力」。</p><p>SIMA 2不仅能响应用户提问，还能对其自身行为及所处环境进行逻辑推理。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403971" alt="" title="" loading="lazy"/></p><p>研究人员在博客中也感慨，与SIMA 2互动时，真的感觉更像是在与一个「伙伴、游戏搭子」一起系统合作。</p><p>这或许也算是SIMA 2通过游戏上的「图灵测试」。</p><p>谷歌认为这个能力的底层逻辑还是Gemini带来的，靠着强大的推流能力，SIMA 2可以在复杂的3D环境中进行感知。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403972" alt="" title="" loading="lazy"/></p><p><strong>泛化能力飞跃</strong></p><p>谷歌推出SIMA 2，除了用游戏训练是初期最合适的手段外，另一个考量就是增强智能体的泛化能力。</p><p>SIMA 2能够理解并完成长期复杂的任务。</p><p>短期指令，比如左转、走三步、爬梯子都是比较容易了，但是如何完整的「打通」游戏关卡才是验证通用能力的关键。</p><p>SIMA 2现在可以在未经预训练的情况下攻克全新的游戏。（左边是Gemini的推理过程，右边是SIMA在操作游戏）</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403973" alt="" title="" loading="lazy"/></p><p>除了语言指令，SIMA 2还能理解多模态的提示。</p><p>比如，用户在画面中绘制一个路线草图，SIMA理解玩家的意思，然后再操作。</p><p>在游戏中画个红框+箭头，让智能体据此操作。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403974" alt="" title="" loading="lazy"/></p><p>其他的理解能力还有，符号。</p><p>比如用户发送一个+树木的表情符号，然后智能体就屁颠颠的说「好吧，我不睡，我去砍树去」。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403975" alt="" title="" loading="lazy"/></p><p>泛化能力的另一个体现是在不同游戏之间的迁移。</p><p>比如A游戏中学会的「挖掘」，可以应用于B游戏的「采集」。</p><p>下面这个图展示SIMA 2相对SIMA 1能力的巨大提升。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403976" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403977" alt="" title="" loading="lazy"/></p><p><strong>终极考验：畅游想象世界</strong></p><p>谷歌为了测试SIMA 2的泛化能力，使用了Genie 3来配合。</p><p>Genie 3生成全新的3D模拟世界，然后让SIMA 2在这些「架空世界」中行动。</p><p>Genie 3本身会遵循物理规律生成世界，但是和真实世界的展现又可能完全不同。</p><p>谷歌的测试结果是，SIMA 2依然能保持良好的环境适应能力。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403978" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403979" alt="" title="" loading="lazy"/></p><p><strong>可扩展的多任务自我提升</strong></p><p>SIMA 2最令人兴奋的能力是能够自我学习，自我进化，自我提升。</p><p>谷歌说在整个训练过程中，SIMA 2智能体能够通过试错和基于Gemini的反馈引导，执行更加复杂的任务。</p><p>在最初从人类示范中学习后，SIMA 2能够过渡到完全通过自主游戏继续学习。</p><p>在全新世界学习时，无需额外的人类生成数据。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403980" alt="" title="" loading="lazy"/></p><p>左侧展示的是初代SIMA 2智能体未能完成的任务示例。</p><p>而右侧则显示经过多轮训练迭代后，SIMA 2已实现自我提升，整个过程完全无需人类反馈或游戏数据介入。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403981" alt="" title="" loading="lazy"/></p><p>SIMA 2能在很多不同类型的游戏里运行，这对检验「通用智能」非常关键。</p><p>在这些游戏中，智能体可以学会各种技能、练习复杂的推理，还能通过自己玩游戏不断提升能力。</p><p>不过，SIMA 2目前还是研究阶段的系统，离真正的「通用具身智能」还有距离。</p><p>它在处理那种特别长、特别复杂、需要很多步推理和反复检查目标的大任务时，还是会吃力。</p><p>它对交互过程的记忆也不算长，只能在有限的上下文里工作，以保证响应足够快。</p><p>另外，想要只用键盘鼠标就做出非常精细的操作，或者稳定地看懂复杂的3D场景，这些在整个领域里都还是难题。</p><p>这项研究说明了一条新的路：</p><p>通过大量、多类型的虚拟世界数据，加上Gemini很强的推理能力，可以训练出一个通用的智能体，把原本分散在不同专用系统里的能力整合到一起。</p><p>SIMA 2也为未来的机器人应用打下了基础。</p><p>它学到的能力——比如导航、用工具、和他人协作完成任务——正是将来让机器人在现实世界中成为「智能助手」所需要的底层模块。</p>]]></description></item><item>    <title><![CDATA[00后MIT辍学生，两年干出2000亿神]]></title>    <link>https://segmentfault.com/a/1190000047403941</link>    <guid>https://segmentfault.com/a/1190000047403941</guid>    <pubDate>2025-11-17 10:14:42</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>编辑：桃子</p><p>【新智元导读】仅用两年时间，一个从实验室孕育的AI编程神器Cursor，年度经常性收入破10亿美元，冲刺300亿美元估值。新一轮23亿美元融资中，谷歌、英伟达重金押注。四名MIT本科辍学生，如今已是妥妥的亿万富翁。</p><p>氛围编程「头号玩家」，真的太顶了！</p><p>今天，全球爆火编程AI初创Cursor完成了23亿美金融资，估值直冲300亿美金。</p><p>D轮融资由Accel和Coatue共同领投，还有英伟达、谷歌、Thrive Capital、DST Global加码。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403943" alt="" title=""/></p><p>值得一提的是，最新239亿美元估值，是今年1月估值的12倍。</p><p>今年至今，Cursor一共完成了三轮融资。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403944" alt="" title="" loading="lazy"/></p><p>2023年，Cursor首次问世后火的一发不可收拾，短短两年的时间，年化收入已超过10亿美元。</p><p>Hyperbolic创始人Yuchen Jin创建的一份图表显示，Cursor是有史以来ARR达到10亿速度最快的公司。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403945" alt="" title="" loading="lazy"/></p><p>20多岁四位联合创始人，从MIT辍学走向了亿万富翁之路。团队规模也从最初几人，扩展至300多人。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403946" alt="" title="" loading="lazy"/></p><p>联创从左到右：Aman Sanger, Arvid Lunnemark, Sualeh Asif和Michael Truell</p><p>就在10月底，Cursor 2.0重大版本更新，并带来了首个编码模型Composer。</p><p>如今，这笔新一轮融资，将用来打造Cursor的下一个神话。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403947" alt="" title="" loading="lazy"/></p><p><strong>两年初创，冲刺300亿估值</strong></p><p>Cursor原本孵化于「应用研究实验室」Anysphere，成立于2022年。</p><p>当时，Anysphere内部将其作为一个产品推出。谁曾想，一夜之间，Cursor竟成为全球开发者最得力的AI助手。</p><p>两年前，在完成种子轮融资后，创始人曾写了这样的期待——</p><p>在接下来的几年里，我们希望打造一款前所未有、更加有用、令人愉悦且充满乐趣的代码编辑器。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403948" alt="" title="" loading="lazy"/></p><p>如今，这一愿景的早期雏形逐步成形：</p><ul><li>一个根本写不出bug的平台；</li><li>一个只用50行伪代码「编出」一份2,000行PR的编辑器；</li><li>一款能即时解答任何代码库问题的工具；</li><li>一个让源代码本身逐渐「隐去」的交互界面。</li></ul><p>Cursor的诞生，推动了「氛围编程」（vibe coding）在全球兴起。</p><p>今年6月，Cursor 1.0首个大版本来袭，一次处理数十项任务重新定义了「高效编码」。</p><p>时隔四个月，Cursor 2.0重大升级，30秒完成一个任务，再次刷新编码天花板。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403949" alt="" title="" loading="lazy"/></p><p>几天前，来自芝加哥大学的研究表明，采用Cursor后，企业每周合并的PR数量提升了约40%。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403950" alt="" title="" loading="lazy"/></p><p>论文地址：<a href="https://link.segmentfault.com/?enc=2LKAU0kgnbRQ6s1XEHmRMw%3D%3D.%2FNrWb%2FIoq9ZagJ7dOILsBVkiXQuWjk2tTdGH4rhDr%2Fif2bET7QwNozFIkoOcGxPytwFnOw9WtGUYDZOBv%2FBNHA%3D%3D" rel="nofollow" target="_blank">https://papers.ssrn.com/sol3/...</a>\_id=5713646</p><p>从实际应用中，也可以看出Cursor成为了开发者编码的「标配」。</p><p>从OpenAI、英伟达科技巨头，到Spotify、Uber 等消费品牌，再到像美国职业棒球大联盟（MLB）这类传统上与软件关联不深的领域，全球5万个团队的开发者用的都是Cursor。</p><p>还记得GTC 2025大会上，老黄曾提到，「英伟达每一位工程师都在用Cursor，生产力大幅提升」。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403951" alt="" title="" loading="lazy"/></p><p>在程序员编码过程中，Cursor不仅可以主动提供代码建议，还是一个代码问答助手。</p><p>正如老黄所言，它基于广受欢迎的Visual Studio Code编辑器打造，界面友好，由此深受用户青睐。</p><p>与此同时，它还支持自家模型，以及OpenAI、Anthropic、谷歌、xAI等全球顶尖大模型。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403952" alt="" title="" loading="lazy"/></p><p>就代码生成量而言，Cursor内部生成的代码，几乎超过全球所有其他LLM总和。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403953" alt="" title="" loading="lazy"/></p><p>这也正是硅谷一众投资者，重金押注Cursor的核心原因。就连OpenAI，曾一度想要收购Cursor未果。</p><p>如今，Cursor成为了全球少数几家估值超100亿美金的AI初创公司之一。</p><p>其他公司包括OpenAI、Anthropic、xAI、Safe Superintelligence和Thinking Machines。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403954" alt="" title="" loading="lazy"/></p><p><strong>MIT辍学生，进阶亿万富翁</strong></p><p>Cursor背后的创业故事，同样励志。</p><p>2022年，四名二十多岁好友从MIT本科辍学，凭借着一腔热血和对AI时代未来的精准把握，一起创办了Anysphere。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403955" alt="" title="" loading="lazy"/></p><p>自成立以来，他们从硅谷知名风险投资公司累积融资3.38亿美金。</p><p>尤为亮眼的是，其年度经常性收入在12个月内，从100万美元飙升至1亿美元，成为了全球增长最快的公司之一。</p><p>Forbes估计，创始人Michael Truell、Aman Sanger、Sualeh Asif和Arvid Lunnemark各持有公司4.5%股份，价值至少13亿美元。</p><p>四名亿万富翁，就这样诞生了。</p><p>不过，26岁联创Lunnemark于今年10月离职，创办了自己初创公司Integrous Research，专注于开发「更安全AI」系统。</p><p>25岁Michael Truell在公司的另一个身份是CEO。</p><p>从小他就非常痴迷于编程，高中时期，Truell创建了一款名为Halite的编程游戏，千名玩家可用不同的编程语言控制机器人。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403956" alt="" title="" loading="lazy"/></p><p>随后，Truell又在药物发现公司Octant实习，从事计算化学相关工作，并在谷歌实习期间，参与了新闻推荐模型的训练。</p><p>他还在创纪录的时间内，完成了一份手写编程测试，给早期Facebook投资人Ali Partovi留下了深刻印象，从而成为Neo学者的一员。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403957" alt="" title="" loading="lazy"/></p><p>Neo是一个大学创业训练营，专门发掘未来之星，为其对接硅谷顶尖人脉进行投资。</p><p>25岁联创Sanger同样也是Neo学者，另一位25岁联创Sualeh Asif来自巴基斯坦卡拉奇，曾参加IMO竞赛拿下亮眼成绩。</p><p>他们四人创办公司之初，曾尝试为机械工程师使用的计算机辅助设计程序构建AI模型，但由于缺乏专业知识，这个项目最终失败了。</p><p>于是，他们决定转向自己更熟悉的领域——软件工程。</p><p>随后，他们开发出了由AI驱动的代码编辑器，也就是一个「程序员版Google文档」。</p><p>它，就是Cursor的前身。仅靠这款编程工具，他们如今赚的盆满钵满。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403958" alt="" title="" loading="lazy"/></p><p>这一成功，也离不开公司背后的创业文化。</p><p>上周，Brie Wolfson卧底Cursor 60天，爆出了内部各种猛料，没有KPI没有压力的氛围引全网羡慕。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403959" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403960" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403961" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403962" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403963" alt="" title="" loading="lazy"/></p><p>左右滑动查看</p><p>许多开发者点评，最爱的Cursor一堵墙。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403964" alt="" title="" loading="lazy"/></p><p>在招聘人才上，Cursor以未来策略为重，不为招聘而招聘。</p><p>在a16z访谈中，Michael Truell透露，公司通过为期两天的现场考核，来招聘每位工程师和设计师，在考核中会模拟构建真实产品。</p><p>Truell表示，这种方式能测试出传统编码面试无法考察的内容：</p><p>他们能否在完整代码库中实现端到端开发？</p><p>如果在没有团队协助的情况下，他们能够独立构建出什么？</p><p>他还表示，这样的面试也让候选人提前深入了解在Cursor的工作状态，从而最大程度确保新员工与公司实现双向契合。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403965" alt="" title="" loading="lazy"/></p><p>当任何人真正了解这家公司，便能看到其蕴藏的巨大潜力。</p><p>300亿估值，还只是一个开始。</p>]]></description></item><item>    <title><![CDATA[GPT-5.1发布当天，文心5.0杀回来]]></title>    <link>https://segmentfault.com/a/1190000047403896</link>    <guid>https://segmentfault.com/a/1190000047403896</guid>    <pubDate>2025-11-17 10:13:47</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>编辑：桃子 好困</p><p>【新智元导读】就在OpenAI刚刚教会GPT-5.1人情世故的同一天，一款2.4万亿的国产大模型证明了，AI不仅能懂人情，还能更好地理解世界。</p><p>2.4万亿参数，原生全模态模型今天杀到了！</p><p>一经发布，这款模型的预览版就在多模态理解、指令遵循、创意写作、智能体规划等40+核心赛道表现惊艳。</p><p>这一次，出手的还是中国AI。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403898" alt="" title=""/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403899" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403900" alt="" title="" loading="lazy"/></p><p>2025百度世界大会上，文心新一代模型——文心5.0重磅发布。</p><p>作为「原生全模态」模型，它从底层架构上实现了一次深刻的变革。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403901" alt="" title="" loading="lazy"/></p><p>为何这么说？</p><p>与业内主流的多模态AI不同，文心5.0从训练之初融合了语言、图像、视频、音频等多模态数据。</p><p>而且，它还支持文、图、视、音的联合输入与输出，实现「原生」的统一理解和生成。</p><p>由此，文心5.0具备了强大的多模态理解和推理能力。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403902" alt="" title="" loading="lazy"/></p><p>大会现场，文心5.0以「武林外传」佟湘玉的口吻二创「甄嬛传」。「AI甄嬛」妙语连珠，出人意料的演绎瞬间点燃全场。</p><p>今天，文心5.0 Preview同步上线文心App；开发者和企业用户可通过千帆大模型平台，调用文心大模型5.0 Preview API。</p><p>百度创始人李彦宏表示，「智能本身是最大的应用，而技术迭代速度是唯一护城河」。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403903" alt="" title="" loading="lazy"/></p><p><strong>文心5.0 Preview一手实测</strong></p><p>同在今天，OpenAI也甩出了新王牌——GPT-5.1系列，双模型同时登场，主打一个智商情商双在线。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403904" alt="" title="" loading="lazy"/></p><p>好巧不巧的是，文心5.0和GPT-5.1升级亮点颇有默契：</p><p>智力拉满，情商在线，而且语言风格自然更像人，还能读懂模糊指令背后的真实意图。</p><p>举个栗子——</p><p>开会前手一抖，咖啡全泼身上了！所有人都盯着我看，他们会不会觉得我是个傻子啊……</p><p>天呐，没想到文心5.0 Preview可以切身体会个人感受，冷静分析心理过程，更像一个AI朋友，给予安慰和鼓励。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403905" alt="" title="" loading="lazy"/></p><p>上下滑动查看</p><p>GPT-5.1在情绪安抚上也做得不错，但又不如文心5.0 Preview细致入微，更加贴心。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403906" alt="" title="" loading="lazy"/></p><p>与此同时，文心5.0 Preview在大模型竞技场LMArena上的亮眼成绩——文本排行榜全球并列第二、中国第一，也让歪果仁为之震撼。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403907" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403908" alt="" title="" loading="lazy"/></p><p>左右滑动查看</p><p>现在，进入文心一言网页版、文心APP以及千帆API平台，即可上手试用最新的文心5.0 Preview模型了。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403909" alt="" title="" loading="lazy"/></p><p>接下来，我们开启了一波最全面的实测。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403910" alt="" title="" loading="lazy"/></p><p><strong>全模态，更好地理解世界</strong></p><p>上传一段OpenAI播客视频（开篇节选），让文心5.0 Preview去提取视频内容。</p><p>要实现这一点，需要AI对视频可以进行多模态解析，包括语音识别、内容提取，并生成一份结构化的内容摘要。</p><p>在近1分半视频中，模型一下抓住了三人对话的核心讨论点——ChatGPT名字的诞生。</p><p>包括关键对话和互动细节，都给出了对应的原文。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403911" alt="" title="" loading="lazy"/></p><p>相比之下，GPT-5并不能直接从视频中转录语音。</p><p>也就是说，我们需要把视频和音频分开上传才行。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403912" alt="" title="" loading="lazy"/></p><p>GPT-4o没说自己不行，但是从给出的回答来看，这段所谓的「内容摘录」完全就是驴唇不对马嘴。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403913" alt="" title="" loading="lazy"/></p><p>再来一段特斯拉FSD行驶的视频，考一考文心5.0 Preview的场景理解能力。</p><p>要真正理解这段视频，可不只是「识图」那么简单。</p><p>除了基本的视觉输入、语音/文字识别，AI还需要有「空间理解」的能力，可以看到物体之间的相对位置。</p><p>同时，还需具备动态感知的能力，进行时间依赖的时序建模。</p><p>可以看到，文心5.0 Preview给出了堪称完美的分析过程，从核心场景、车辆行为与FSD逻辑，到人类观察者的反应，以及技术亮点、视频核心意图。</p><p>不管是动作的先后顺序，比如车减速后，避让鹅群再行驶；还是更细致的「导航界面」和「真实环境」，比如车速、前进挡（D）、倒车挡（R），以及摄像头画面。</p><p>文心5.0 Preview是在真正的「理解世界」，而不只是识别像素。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403914" alt="" title="" loading="lazy"/></p><p>来一段《无间道》的经典片段，看看文心5.0 Preview能否抓到人物之间对立冲突的细节。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403915" alt="" title="" loading="lazy"/></p><p>来源：抖音「有戏影视」</p><p>没想到，它准确定位「42秒-51秒」是片段中最紧张的几秒。</p><p>这一过程，AI需要同时完成多线作战，包括画面与音效，威胁/请求等话语行为，角色意图等，才能捕捉到视频中冲突的变化——</p><p>从语言上的相互试探，转向了拔枪特写的画面冲突。</p><p>可以看出，文心5.0 Preview还能理解人物情绪的变化过程，一眼抓住了两人的微妙的表情：</p><p>刘建明从最初的恳切请求，逐渐转为说出「那就让我死」的坚定与紧张；陈永仁从不耐烦与其周旋，最后直接冷脸道出「我是警察」的身份。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403916" alt="" title="" loading="lazy"/></p><p>上下滑动查看</p><p>再来一个情绪变化更细腻的短片。</p><p>咱们先让文心5.0 Preview点评下男主的演技，并让它写一段100字的小红书文案。</p><p>先来看演技，文心5.0 Preview能够围绕角色情绪爆发背后，一个递进的层次去分析，并用了一些高密度的形容词——</p><ul><li>压抑后的爆发</li><li>情绪是攒出来的</li><li>痛不是演出来的，是渗出来的…..</li></ul><p>这些独到的描述，显然是基于对人物情绪深度理解，才可以得出。</p><p>文心5.0 Preview能够结合视频的音频画面情节，对情绪、行为、文字进行综合分析。</p><p>结尾给出的小红书文案抓住了「情绪破防点」，更加自然有人味，而且还生成了tag，符合平台的风格。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403917" alt="" title="" loading="lazy"/></p><p>除了视频，我们还可以把一连串图片扔给文心5.0 Preview。</p><p>这里，将姚顺宇个人领英、主页介绍等相关截图上传，让模型做一段人物介绍。</p><p>仅靠简单OCR是不行的，它需要先识别文字内容，然后再推断这些图像之间的主题关联所在。</p><p>它需要将分散在多张截图中的零散内容，整合出一条人物主线：</p><p>教育经历——研究方向——职业生涯——科研成果</p><p>这恰恰又体现了，文心5.0 Preview所具备的语义聚合与逻辑重构的能力，可以把异质数据拼成一致的叙事。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403918" alt="" title="" loading="lazy"/></p><p>一个视频理解难不倒文心5.0 Preview，接下来，就要上点难度了。</p><p>最近火遍全网的《一点点》舞蹈，下面挑选了两段不同风格的视频，让文心5.0 Preview做一个点评。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403919" alt="" title="" loading="lazy"/></p><p>可以看出，它可以针对动作风格、表情管理、服装适配度、情绪传递不同维度，给出一个总结性的评价——</p><p>第一位女生：活力四射、力度感强，充满青春感染力</p><p>第二位女生：甜美可爱、柔和细腻，充满治愈感</p><p>一一点评之后，还有一个可视化表格清晰列出了她们各自风格、动作特点等。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403920" alt="" title="" loading="lazy"/></p><p>上下滑动查看</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403921" alt="" title="" loading="lazy"/></p><p><strong>柯南破案逻辑，完美拆解</strong></p><p>文心5.0 Preview还可以做多模态推理，针对复杂场景做出分析判断。</p><p>《名侦探柯南》中图书馆杀人事件，是许多人心目中「童年阴影级」剧集，案件设计堪称经典。</p><p>文心5.0 Preview能否化身侦探，分析出17分钟剧集中柯南的查案过程呢？</p><p>显而易见，它将复杂剧情，拆解成可验证的小步子。</p><p>初始线索里，图书馆中的异常书籍不仅用收缩膜包裹，还被反放在盒子中。随着剧情推进，它还推断出书架异常摆放的「三排书」的线索。</p><p>另一条关键线索便是「电梯藏尸」，文心5.0 Preview精准捕捉到一开始，柯南和小伙伴赶电梯却超重的环节，并通过验证得出结论。</p><p>从金川馆长作案流程，到柯南断案过程，文心5.0 Preview做了整合推理，得出了一条柯南破案逻辑链：</p><p>异常书籍→书架藏毒品→电梯超重→尸体藏在电梯天花板→馆长行为异常→指认凶手。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403922" alt="" title="" loading="lazy"/></p><p>上下滑动查看</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403923" alt="" title="" loading="lazy"/></p><p><strong>把「力拔山兮」写成代码</strong></p><p>在前段时间热播的《喜人奇妙夜2》中，《技能五子棋》这个节目可以说是火遍了各大社交媒体。</p><p>它的魔性旋律血洗全网，有网友化身唱跳达人，还有人灵感迸发二创，更有人将日常生活填进旋律。</p><p>从普通网友到当红明星，不同圈层的人，很难不卷入这场狂欢之中。</p><p>有趣的是，就连AI圈也未能幸免。</p><p>在最近的评测中，做一个「技能五子棋」游戏，几乎成为了每个模型都要面对的代码必答题</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403924" alt="" title="" loading="lazy"/></p><p>不过这次，我们不是简单地让AI随便生成一个，而是要真正「复刻」出里面的技能——飞沙走石，静如止水，力拔山兮。</p><p>把「魔性」的台词直接加入Prompt里，很快，文心5.0 Preview就生成了近700行代码，并在最后附上了游戏的玩法说明。</p><p>Prompt：</p><p>帮我做一个技能五子棋的游戏网页，要求是在普通的五子棋规则上，玩家可以使用技能，其中包括飞沙走石，静如止水，力拔山兮。「飞沙走石」，是把对手的棋子直接扔进什（石）刹海；「静如止水」是凝结时间，把对方「速冻」；「力拔山兮」是摔坏棋盘，直接获胜。黑棋和白棋的技能点要分开算，并且每走一步都可以累加。直接给我html文件，画面要美观。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403925" alt="" title="" loading="lazy"/></p><p>没想到，如此「抽象」的台词，文心5.0 Preview竟然就这么水灵灵地理解了：</p><p><strong>·</strong> 飞沙走石：随机移除对手的一个棋子。</p><p><strong>·</strong> 静如止水：冻结对手，使其下一回合无法落子。</p><p><strong>·</strong> 力拔山兮：直接宣布获得游戏胜利。</p><p>而且，模型也很好地遵循了我们的Prompt，设计了一个相当美观的界面。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403926" alt="" title="" loading="lazy"/></p><p>在试玩之前，我们先来简单介绍这款「技能五子棋」。</p><p>画面右上角显示的是，当前是哪位玩家的回合，以及各自拥有的技能点。其中，玩家每走一步都会获得1个技能点（SP）。</p><p>右侧则是技能名称，以及它们消耗的点数：飞沙走石（2 SP），静如止水（4 SP），力拔山兮（8 SP）。如果攒够了相应的技能点，选项框就会亮起。</p><p>右下角是重新开始按钮，以及一个展示玩家历史操作的滚动窗口。</p><p>接下来，比赛开始。</p><p>刚开局，黑棋就用「飞沙走石」送走白棋的一枚棋子，抢占了优势，</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403927" alt="" title="" loading="lazy"/></p><p>紧接着，白棋使出「静如止水」连下两子，让黑棋瞬间陷入被动。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403928" alt="" title="" loading="lazy"/></p><p>千钧一发之际，率先攒够8个技能点的黑棋，毫不犹豫点下「力拔山兮」，把白棋一波带走，实现翻盘。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403929" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403930" alt="" title="" loading="lazy"/></p><p><strong>告别「拼接」，原生全模态登场</strong></p><p>原生全模态，不是多模态的「加法」。</p><p>一提到多模态AI，人们可能想到的是，将语言、图像、视频、音频等不同数据「拼接」起来的模型。</p><p>当前，业界大多都采用了这种「后期融合」方式的多模态模型。</p><p>但文心5.0不同，它从根源上构建了一个统一的架构，即新一代「原生全模态大模型」。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403931" alt="" title="" loading="lazy"/></p><p>自训练伊始，文心5.0融合了语言、图像、视频、音频等多模态数据，实现了文、图、视、音的联合输入与输出。</p><p>这样一来，文心5.0就能真正做到原生的全模态理解与生成。</p><p>不过在此之前，百度团队克服了业内普遍面临的难题：</p><p>原生多模态架构的「理解与生成一体化」</p><p>一般来说，传统方法往往先是处理单一模态，再将所有模态数据融合。这种方法看似优雅，实则会带来很多致命的问题。</p><p>后期融合只在输出层进行，也就是说，每个模态的特征在融合之前，就已独立决策完成。</p><p>这样的AI根本学不到模态之间的「深层语义交互」，比如视频中，人物表情和语音语调高度相关，进而造成信息丢失。</p><p>文心5.0通过精细建模多模语义特征，让理解和生成相互增强。</p><p>同时，它还采用了「自回归统一结构」，对不同模态的训练目标进行离散化建模，确保了多模态特征在统一框架下充分融合并协同优化，由此提升了全模态统一建模的能力。</p><p>在参数规模上，文心5.0总参数超过2.4万亿，业界公开参数的模型之最。</p><p>更关键的是，它引入了超稀疏混合专家架构，进行庞大的全模态训练。</p><p>其激活参数比例低于3%，在保持强大能力的同时，显著降低计算和推理成本。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403932" alt="" title="" loading="lazy"/></p><p><strong>训推双引擎，成本骤降</strong></p><p>要让万亿级全模态MoE真正跑得动、跑得快，团队在训练与推理上同时开刀，构建了一套高效的训推体系。</p><p><strong>1. 高效全模态超稀疏混合专家分布式训练</strong></p><p>在训练阶段，依托飞桨框架，他们研发了多模态编码器分离异步训练架构、动态自适应显存卸载技术，以及细粒度通信计算重叠编排专家并行技术。</p><p>同时，结合FP8混合精度训练，实现了对万亿级参数全模态超稀疏混合专家模型的高效训练。</p><p>结果，文心5.0预训练性能较基准提速230%。</p><p><strong>2. 多级分离架构的全模态统一高性能推理</strong></p><p>在推理阶段，文心5.0采用了「多模编码器-预填充-解码-多模生成器」的多级分离推理部署框架。</p><p>此外，团队还研发了面向超稀疏混合专家、数据负载和注意力计算的均衡算法，以及动态自适应多步投机解码和效果无损低比特键值缓存量化技术。</p><p>在推理成本上，文心5.0得到大幅压缩，真正实现了效率与能力的平衡，让其更接近实用。</p><p>此外，衡量一个模型能否从实验室走向实际应用，长程任务的指标是最重要的衡量因素之一。</p><p>为了提升文心5.0长程任务的能力，团队基于大规模工具环境，合成了长程任务轨迹数据。</p><p>然后，在预训练和后训练阶段，基于思维链和行动链对文心5.0进行「端到端」多轮强化学习训练。</p><p>由此可见，文心5.0的智能体和工具调用能力，得到了显著的提升。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403933" alt="" title="" loading="lazy"/></p><p><strong>文心又回来了！</strong></p><p>过去两年，多模态模型已迅速崛起，成为驱动AI时代发展的核心引擎。</p><p>与传统大语言模型不同，它突破了单一文本的限制，通过无缝融合图像、音频、视频等多源信息，实现了更接近人类的综合理解与生成能力。</p><p>放眼全球，在这场AI大战中，OpenAI、谷歌等硅谷巨头早已在多模态赛道上抢先布局。</p><p>OpenAI发布GPT-4o时，便向世界生动展示了多模态AI应有的交互形态——</p><p>一个统一的神经网络，无缝处理文本、音频、视觉等多种模态的输入与输出。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403934" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403935" alt="" title="" loading="lazy"/></p><p>而谷歌的Gemini系列，更是从诞生之初便被烙上了「原生多模态」的印记。</p><p>他们在技术报告中，多次强调了原生多模态与非原生的差异。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403936" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403937" alt="" title="" loading="lazy"/></p><p>CEO Demis Hassabis也曾明确表示，Gemini的目标就是要让一个模型能原生地理解图像、音频和视频。</p><p>最终，实现与物理世界的真实交互。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403938" alt="" title="" loading="lazy"/></p><p>视线转回国内，阿里、字节等头部大厂同样在多模态赛道上重兵布局。而在众多路径中，百度选择了一条更效率导向的道路——<strong>「原生全模态」</strong>。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403939" alt="" title="" loading="lazy"/></p><p>原生全模态，意味着模型从训练的第一天起，就如人类一般，活在视觉、听觉与文字交融的统一感知中。</p><p>和婴儿一样，它学习世界的方式是通过所有感官的同步输入来形成认知。毕竟，人类的思考从来都不是「先看再听再想」的线性接力，而是所有信息洪流的同步融合。</p><p>这之中的核心，便是将每一帧画面、每一段声音、乃至每一个词语，都转化为一套统一的离散符号流，并置于同一个自回归框架下建模。</p><p>也就是说，当你输入一段街头艺人表演的视频，探寻「背后的故事」时，AI不再是割裂地解析画面、分析音频，最后拼凑答案。它能在一个统一的语义空间中，同步完成感知、推理与叙事，像人类一样，给予一个完整而深刻的回应。</p><p>正是凭借这种全模态的内在优势，文心5.0得以突破复杂场景的束缚，为AI的未来应用开启无限想象。</p><p>更值得一提的是，文心的实力，早已超越了实验室的范畴，在真实应用中形成了技术落地的闭环。</p><p>发布会现场，与百度连线的「AI老罗」便是最好的证明。他不仅能轻松做出「点赞、比心、比耶」的互动三连，更在问答环节中，将罗永浩本人「犀利吐槽」的语言风格模仿得惟妙惟肖。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403940" alt="" title="" loading="lazy"/></p><p>技术基于慧播星高说服力数字人</p><p>如今，当理解与生成走向统一，当技术与应用协同共生，人机智能的边界也正悄然消融。</p><p>在这场全球大模型的激烈角逐中，文心正以全新姿态，强势回归！</p>]]></description></item><item>    <title><![CDATA[全球最大开源具身大模型！中国机器人跑完马]]></title>    <link>https://segmentfault.com/a/1190000047403878</link>    <guid>https://segmentfault.com/a/1190000047403878</guid>    <pubDate>2025-11-17 10:12:50</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>编辑：好困</p><p>【新智元导读】从马拉松冠军到最强大脑，这次的突破不再是四肢，而是灵魂。</p><p>中国人形机器人，再获突破性进展！</p><p>昨天，全球参数量最大的具身智能多模态大模型——<strong>Pelican-VL 1.0</strong>正式开源。</p><p>它不仅覆盖了7B到72B级别，能够同时理解图像、视频和语言指令，并将这些感知信息转化为可执行的物理操作。</p><p>而且还针对目前具身能力短板，在空间理解、物理推理和思维链等维度实现了系统性提升，并在12个主流公开评测基准上达到行业领先水平。</p><p>可以说，Pelican-VL 1.0的提出，打通了从「看懂世界」到「动起来」的完整智能链路。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403880" alt="" title=""/></p><p><strong>项目主页：</strong></p><p><a href="https://link.segmentfault.com/?enc=FaJudZrrx%2FHaNFy317qv9w%3D%3D.f2IUSr0Eduw9AsCWrmCd61a0h3rIyemGQhCEEltMBsw%3D" rel="nofollow" target="_blank">https://pelican-vl.github.io</a></p><p><strong>Github：</strong></p><p><a href="https://link.segmentfault.com/?enc=nnM2wQEQC%2FbOhxrnLXcbsA%3D%3D.yG1DqjCCKvcixCMt7qEvUlMBwTNLxN6ibhbGFIJJr5X9DbGQpd%2F9NcgIC%2BysBiXF" rel="nofollow" target="_blank">https://github.com/Open-X-Hum...</a></p><p><strong>Hugging Face：</strong></p><p><a href="https://link.segmentfault.com/?enc=zhLh1oZabGAdyCwHOHoiGA%3D%3D.Tym4C3dKtA%2BP2orABskxGf0mle8lDYhl4rkTakb3VoIJutWlEDp4gQk23QGfttSiaqeSu4A8PoLhEtnMGUv7yQ%3D%3D" rel="nofollow" target="_blank">https://huggingface.co/X-Huma...</a></p><p><strong>ModelScope：</strong></p><p><a href="https://link.segmentfault.com/?enc=ZxYgROP6JtHV5h2hlOui5A%3D%3D.mGyx4VWRAFx1DuJY5A1SDZpKhC%2Bvi2y0wY%2BfTfomk2jLUWkdZ%2B6uciujQDb%2FsORKqKRss9OXZu11oSUuNIqMGg%3D%3D" rel="nofollow" target="_blank">https://modelscope.cn/models/...</a></p><p>而这背后，便是创造全球首个人形机器人马拉松冠军的团队——北京人形机器人创新中心。</p><p>当前，通用大模型在迁移到具身智能任务时，仍面临多维度能力欠缺的问题。</p><p>李飞飞教授提出过Think in Space的观点，强调走向具身智能需要解决空间智能问题的重要性。英伟达和谷歌也在研究中指出，具身领域的大模型必须具备物理智能，并相继推出了Cosmos-Reason和Gemini-RoboticsER这类面向具身场景的多模态大模型。</p><p>无独有偶，创新中心也希望通过全面开源Pelican-VL这一基础大脑模型，帮助更多具身智能体获得更强的认知与决策能力，并在意图理解、长程任务规划推理等多类场景中实现性能提升。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403881" alt="" title="" loading="lazy"/></p><p>具体来说，通过「刻意练习」（DPPO）训练范式，Pelican-VL在不断自我诊断与纠错中提升推理与规划能力，使模型像人类一样在失败中学习，从而实现了视觉理解、语言表达和物理执行的深度融合。</p><p>凭借这一机制，Pelican-VL在多个维度展现出突破性能力：</p><ul><li>具备跨模态的理解与推理能力，能在复杂环境中识别目标、推断物体功能与可供性；</li><li>具备时间-空间认知，能理解动作的顺序与因果关系。</li></ul><p>模型的自进化循环使其在每一轮训练后都能修正弱点，形成持续强化的学习闭环。Pelican-VL不仅是一种模型，更是一个能够驱动机器人系统不断进化的「智能引擎」。</p><p>总体上，论文报告称相较基线模型，在空间理解和时间推理等能力上出现显著提升，并在若干公开基准上超过了部分100B量级的开源模型。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403882" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403883" alt="" title="" loading="lazy"/></p><p>Pelican-VL的推出不仅是一次技术突破，更为产业界与学术界带来了双重启示。</p><p>它首先构建了一套贯通「视觉理解—长程规划—物理操作」的通用训练范式，提供了一个可复用、可扩展的范式，降低了具身智能研发的门槛。</p><p>与此同时，团队开放了模型与推理框架，为科研机构和企业提供了一个可自由定制、快速迭代的智能基座，加速了从实验到落地的过程。</p><p>更深层的意义在于，Pelican-VL让「机器人自主学习和反思」从理念走向现实。</p><p>它的「刻意练习」机制使模型能在错误中总结经验、持续进化，如同人类通过反复训练掌握技能。</p><p>这意味着未来的机器人不再只是机械执行者，而是具备认知与改进能力的学习体。</p><p>可以想象，在家庭或工业场景中，它将能够自主判断物体用途、调节操作力度、优化行动策略——从被动执行迈向主动理解与自我成长，标志着具身智能迈入真正的「学习时代」。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403884" alt="" title="" loading="lazy"/></p><p><strong>智能抓取</strong></p><p><strong>实现精细抓取泛化操作新突破</strong></p><p>当抓取一个水杯或一枚鸡蛋时，基于Pelican-VL的大脑会瞬间完成一系列精密的操作：</p><p>通过视觉预判物体属性、在接触瞬间施加恰到好处的力道、并在触碰后根据手感微调抓力。</p><p>这套由主动预测、触觉适应与记忆更新构成的「感知运动闭环」，是灵巧抓取的关键。</p><p>而这项能力正是具身智能机器人与物理世界交互的基础，但却面临着触觉感知与运动灵活的协同难、复杂场景下的泛化难、算法与数据制约等等难题，目前行业内即便有相关技术突破，也仍未完全解决大规模落地的难题。</p><p>如今，Pelican-VL驱动的机器人抓取框架，成功复现并实现了这一高级智能。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403885" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403886" alt="" title="" loading="lazy"/></p><p><strong>仿生核心：Pelican-VL构建的智能抓取闭环</strong></p><p>技术框架严格遵循了人类感知运动的三个核心环节，并将其转化为可执行的机器人系统：</p><p><strong>1. 主动预测：提供精准的「第一印象」</strong></p><p>在机械臂接触物体前，Pelican-VL大模型凭借其卓越的视觉感知与真实世界物理推理能力，仅通过视觉输入，就能精准预测出物体的物理属性（如材质、易碎度），并生成初始抓取力。</p><p>这为机器人提供了如同人类般的「先见之明」，使其从指尖接触的一刻起，就具备了恰到好处的基准夹持力，通过模型提供前馈信息缩短闭环控制稳定时间。</p><p><strong>2. 触觉适应：实现毫秒级的「手感微调」</strong></p><p>在抓取和操控过程中，指尖的触觉传感器会实时传回微滑移、受力分布等数据。系统通过一个<strong>同步的在线摩擦估计与自适应抓取控制模块，</strong>像人类神经反射一样，持续、快速地微调抓力。</p><p>这不仅确保了抓取的稳定性，更关键的是<strong>能动态适应不确定因素，避免对精致、柔软的物品造成损伤。</strong></p><p><strong>3. 记忆更新：打造持续进化的「经验库」</strong></p><p>每次抓取任务完成后，系统会对比预测与实际感官结果的差异，并将这次成功的交互经验存储在一个<strong>物理记忆图谱中</strong>。</p><p>当下一次遇到相同或类似的物体时，Pelican-VL会优先调用这个更新、更精确的记忆来指导预测。使<strong>机器人系统具备持续学习的能力，每一次抓取都在为下一次更精准、更柔和的操作打下基础。</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403887" alt="" title="" loading="lazy"/></p><p><strong>实战验证：轻松拿捏精致与柔软物体</strong></p><p>在实际机器人测试中，该框架展现出了卓越的性能。</p><p>从接近、加载、提升、持稳到运输归还的完整七阶段抓取流程中，Pelican-VL驱动的机器人能稳定操作一系列精致与柔性物体。</p><ul><li><strong>「看得准」</strong>：由Pelican-VL提供的精准初始力先验，极大地加速了后续自适应控制器的收敛过程。</li><li><strong>「抓得稳」</strong>：在线控制器在提升、移动过程中持续动态调整抓力，有效应对惯性等扰动，确保抓取万无一失。</li><li><strong>「学得快」</strong>：整个交互过程形成的经验被存入知识图谱，系统像一位经验丰富的老师傅，越用越熟练。</li></ul><p>通过将Pelican-VL大模型的强大认知能力与实时控制、记忆系统深度融合，机器人抓取从简单的「执行命令」升级为了具备预测、反应与学习能力的智能行为。</p><p>这一能力使机器人在<strong>低成本、低样本</strong>的条件下依然能够实现<strong>高度泛化</strong>、更加柔性的抓取表现，为行业带来了真正可规模化落地的智能抓取方案。</p><p>这不仅是技术上的一个里程碑，更为机器人在复杂、非结构化环境中真正实现自主操作，打开了无限可能的大门。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403888" alt="" title="" loading="lazy"/></p><p><strong>VLM让VLA实现能力跃迁</strong></p><p>在典型的Vision–Language–Action（VLA）系统里，Pelican-VL扮演着「视觉语言大脑」的角色，为机器人提供强大的环境感知和指令理解能力。</p><p>它将摄像头所见与自然语言指令结合，构建起对场景的多模态表征，然后输出可供后续决策单元使用的结构化信息。</p><p>也就是说，Pelican-VL负责「看图听话」，理解指令和环境，VLA负责跨机器人应用；二者组合可以在多种机器人上执行多任务。</p><p>有了这样的基础，系统可以完成长时序、多步骤的任务规划和执行。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403889" alt="" title="" loading="lazy"/></p><p>Pelican-VL等具身智能模型可部署在商超、家居等多种真实场景中，通过视觉-语言感知辅助多步任务规划</p><p>论文中演示了一个生活场景下的复合指令：例如「把鞋子放到鞋架上、将桌上的垃圾扔到垃圾桶，再把衣服放入洗衣机」。</p><p>Pelican-VL首先感知房间物体和布局，构建出整个环境的语义表示；接着根据指令自动生成行动序列：依次移动到鞋架、垃圾桶和洗衣机位置并进行抓取和放置操作。</p><p>在这一过程中，模型不断更新内部环境状态，调整计划并适应实际情况，实现了自然语言指令的自主分解和执行。</p><p>简而言之，Pelican-VL构成了VLA系统的认知前端，为长期规划和指令执行提供跨模态的信息支持，使机器人能够像人类一样将复杂任务拆解并落地操作。</p><p>同时，在快慢系统、端到端等诸多架构中，前沿探索者们也一直在致力于研究当VLA以VLM为基座时，VLM各项能力为度对VLA模型所带来的性能增益。</p><p>例如DeepMind的RT-Affordance，李飞飞的ReKep以及Sergey Levine的Training Strategies for Efficient Embodied Reasoning等著名学者和机构都曾探讨过<strong>可供性、思维链等能力对于具身操作的重要性。</strong></p><p>对此，Pelican-VL针对性地进行了能力提升，并在多个维度中达到行业领先水平。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403890" alt="" title="" loading="lazy"/></p><p>RT-Affordance项目地址：<a href="https://link.segmentfault.com/?enc=zqcx8U3PM2VCrAjIihxuiQ%3D%3D.F3bJnGJuA50oJA90zo9fmddN1dhGIBcf47hUF8oDbvrwqwyhZdgZ%2BUGN1c%2Fr5Ps3" rel="nofollow" target="_blank">https://snasiriany.me/rt-affo...</a></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403891" alt="" title="" loading="lazy"/></p><p>ReKep项目地址：<a href="https://link.segmentfault.com/?enc=zbgTDFa2cALCjXTZxvrSAQ%3D%3D.sMhX%2B4sKiBnKFM%2Fh78I3nts3reX8DxinQSboMWJkGds%3D" rel="nofollow" target="_blank">https://rekep-robot.github.io/</a></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403892" alt="" title="" loading="lazy"/></p><p><strong>跨本体具身大脑实现多机协作</strong></p><p>Pelican-VL具备不同层级的机器人任务规划调度能力，可根据场景生成机器人行为规划，并将其转化为具体机器人功能函数的执行调用，作为多机器人系统的任务调度器。</p><p>论文中给出一个多机器人协作流水线的开发示例：</p><p>在一个灯泡质检流程中，Pelican-VL将任务按机器人拆分为若干行为层任务，进而生成不同机器人动作层的函数调用。</p><p>例如，它会生成对「轮式人形机器人」执行「检查电控柜并启动系统」的函数调用指令，也会为双臂机器人生成「对灯泡进行结构与功能检测」的调用。</p><p>对于通用的操作函数，生成所需的控制参数，由专门的运动规划模块将其转化为关节轨迹和夹爪动作。</p><p>这种方式类似于一个项目经理给不同的团队下达精确的工作指令，Pelican-VL则通过多轮对话和分步指令，确保多台机器人的协同工作。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403893" alt="" title="" loading="lazy"/></p><p><strong>基于稳定多视角可供性的零样本操作</strong></p><p>在更加通用的操作场景下，论文也给出了一个基于可供性进行任意物体操作的例子。</p><p>Pelican-VL先输出详细的视觉定位和功能性描述（如目标物体的抓取点、放置位置等），然后利用函数调用机制触发操作。</p><p>例如在通用抓取演示中，它会先生成多视角下的一致性预估（如抓取点、避障区域）以保证空间定位准确；接着将这些计划通过接口调用下发给运动控制单元。</p><p>这一流程就像「思维链」式的中间规划：模型内部先思考出清晰的步骤，再把每步落成可执行的函数调用，确保执行过程可控且透明。</p><p>通过函数调用，Pelican-VL不仅能处理单机任务，也可管理多机器人协作任务，进一步彰显了其在复杂系统中的实用性。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403894" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403895" alt="" title="" loading="lazy"/></p><p><strong>结语</strong></p><p>此次Pelican-VL的开源，对于人形机器人产业与研究而言带来了两个正向价值：</p><ul><li>首先它提供了一整套「视觉理解→长程规划→物理操作」串联的可复用训练范式，降低了在机器人中使用 VLM 的门槛；</li><li>其次，借助开源基础模型和推理代码，所有其他实验室或企业都可以在这个「脑」上做定制化训练，加速人形机器人在各行各业的落地探索。</li></ul><p>作为拿下过全球首个人形机器人马拉松冠军、百米赛跑冠军的团队，北京人形机器人创新中心已经推出了具身智能的通用硬件平台「具身天工」和通用软件平台「慧思开物」两个开放平台，如今又在VLM上实现了重大突破。</p><p>不难看出，一切都是为产业落地提供更良好土壤，让国内的机器人厂商和开发者可以自由使用与定制人形机器人，加速研发进程，并且正在让具身智能机器人从最能跑，演化到最聪明和最好用的更高阶段。</p><p>根据了解，目前北京人形机器人创新中心还在推进「千台机器人真实场景数据采集计划」，让上千台机器人在工厂、仓库、酒店等场景中执行任务并采集数据。</p><p>而这些规模化的多模态数据与Pelican-VL结合，将推动其在制造业自动化、智能物流、零售无人化和家居服务等多领域的快速适配和优化。</p><p>对于制造业企业来说，基于Pelican-VL快速开发特定场景下的应用方案，可大大降低开发成本和难度。</p><p>长期来看，Pelican-VL及其后续版本将促进国内形成完善的通用机器人智能平台，推动更多种类的机器人像安装「通用智能操作系统」一样迅速获取新能力，让人形机器人更低门槛、低成本、高效率的走进不同制造业、工业体系。</p><p>参考资料：</p><p><a href="https://link.segmentfault.com/?enc=kqmodgZOmQ6yRE7AlyMF8w%3D%3D.p8mPze5suJI0m6mVawAbKhMXFJvT2wTvWo2zn5PVf2Y%3D" rel="nofollow" target="_blank">https://pelican-vl.github.io</a></p><p><a href="https://link.segmentfault.com/?enc=J%2BNTlG5p2PPgTpsMb8V9Eg%3D%3D.P19%2Fqf2fqcvUY39pOe4h8nsheMvGPTrkZu2P%2BcLvjt%2Bjs8c8%2B75CaUJE47LfhdUB" rel="nofollow" target="_blank">https://github.com/Open-X-Hum...</a></p><p><a href="https://link.segmentfault.com/?enc=A6H8FgkqE8NqDwn8V4Z1pA%3D%3D.inuxcfwP4yX%2Bin1OPv738GnMCuZojQc22pv6RcTt%2BqWRNRRm6%2BdDCxeTu8SHM73%2FNdjLKO4nR76%2BotZ%2BphhHvw%3D%3D" rel="nofollow" target="_blank">https://huggingface.co/X-Huma...</a></p><p><a href="https://link.segmentfault.com/?enc=wpTco03fE6bwJPERhSVDlA%3D%3D.8fle9ui3%2BGOp%2F%2BMeTOumeLHyhYRNNryLehqR%2B5TTARsERDKlVR%2FbdCtX6OgMb3a00SAZ8gC3x72E7jxjz3DGFw%3D%3D" rel="nofollow" target="_blank">https://modelscope.cn/models/...</a></p>]]></description></item><item>    <title><![CDATA[LeCun在Meta的「最后一作」 本文]]></title>    <link>https://segmentfault.com/a/1190000047403856</link>    <guid>https://segmentfault.com/a/1190000047403856</guid>    <pubDate>2025-11-17 10:12:06</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>编辑：元宇</p><p>【新智元导读】就在Yann LeCun即将离职Meta创业的消息在AI圈刷屏时，他的一篇关于自监督学习的新论文也在arXiv上线。该论文提出了一种新框架LeJEPA，为解决当前JEPA方法中存在的多种失效模式提供了新路径。</p><p>11月11日，Meta首席AI科学家Yann LeCun在arXiv上提交了他与Randall Balestriero合作的一篇新论文。</p><p>前Stability AI研究负责人Tanishq Mathew Abraham，在X平台上推荐了这篇论文，并调侃说这可能是LeCun在Meta发表的最后一篇论文之一。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403858" alt="" title=""/></p><p>因为就在这篇论文提交的同一天，媒体也曝出了LeCun即将在未来几个月离开Meta创业的消息。</p><p>Abraham评论道，这是一篇很有意思的论文。</p><p>它提出了一种新框架LeJEPA，可以解决当前JEPA方法中所存在的多种失效模式，仅需约50行代码即可实现。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403859" alt="" title="" loading="lazy"/></p><p>论文地址：  <br/><a href="https://link.segmentfault.com/?enc=wZTYIwGRV%2BVzVYD5SfB1nw%3D%3D.QBa6iJiYdPZFRGSEQufmofZbyAArcQi4xfIjCVfu9ww1hPzDDByMeqgNfd8Q3qNn" rel="nofollow" target="_blank">https://arxiv.org/pdf/2511.08544</a></p><p>对于LeCun这篇论文也颇具特殊意义——</p><p>既是为他在Meta FAIR实验室十多年的研究工作划下句点，同时也向外界传递出他下一步创业的新方向。</p><p>有网友评论这意味着LeCun回归初心，追求以优雅的力量取代大模型的暴力扩展。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403860" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403861" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403862" alt="" title="" loading="lazy"/></p><p><strong>为JEPA理论研究奠基</strong></p><p>联合嵌入预测架构（Joint-Embedding Predictive Architectures，JEPAs），由于缺乏明确的实践指南和系统理论，目前相关研究大多是临时性探索。</p><p>论文给出了一套完整的JEPA理论，并将其具体落地为LeJEPA，这是一种轻量、可扩展且有坚实理论基础的训练目标。</p><p>研究人员证明，若要最小化下游任务的预测风险，JEPA的嵌入理想情况下应服从各向同性高斯分布。</p><p>为此，他们提出一个新的目标函数Sketched Isotropic Gaussian Regularization（SIGReg，随机草图各向同性高斯正则化），用于约束嵌入向该理想分布收敛。</p><p>LeJEPA融合了JEPA和SIGReg思想，兼具多方面的理论和实践优势：</p><ul><li>只需要一个权衡超参数；</li><li>时间与内存复杂度均为线性；</li><li>在超参数、架构（ResNet、ViT、ConvNet）以及不同领域之间表现稳定；</li><li>不依赖启发式技巧，以及适合分布式训练的实现，仅需约50行代码。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403863" alt="" title="" loading="lazy"/></p><p>如图1所示，在使用ImageNet-1K进行预训练并对冻结骨干网络做线性评估的设定下，LeJEPA在ViT-H/14上可达到79%的精度。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403864" alt="" title="" loading="lazy"/></p><p><strong>提出新路径</strong></p><p>在AI领域，一个长期存在的核心问题，是让模型学会对世界及其变化形成可用于实际决策和动作的表征（可操作表征）。</p><p>无论是图像识别、机器人，还是物理学、太空探索，都会面临一个共同的问题：</p><p>如何仅凭观测数据，学习到一个结构清晰、便于操作的高维嵌入空间？</p><p>这里的「高维嵌入空间」，是指所有对象都被映射成高维向量，这些向量所在的数学空间。</p><p>使用深度网络（参数化为非线性算子）将观测映射到嵌入，是破解这道难题的标准第一步。</p><p>第二步，也是目前尚未标准化的部分，是如何训练。</p><p>JEPAs提出一种路径：通过最大化语义相关视图的嵌入之间的一致性预测来训练。</p><p>这里的「视图」可以以两种形式出现：变换或扰动。</p><p>它们可以包括掩码、裁剪、模糊、时间或空间平移、几何或光照变换、视角变化、来自不同传感器模态的视图等操作。</p><p>有监督形式下，则会引入人工构造的配对，例如图像–文本对、文本–代码对等。</p><p>无论采用哪种形式，这些视图都被假定在语义上存在一定关联，从而让预测任务能够将的嵌入对齐到数据中潜在的知识结构上。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403865" alt="" title="" loading="lazy"/></p><p>然而，JEPA的预测任务存在一些失败模式，例如表征崩溃：将所有输入映射到几乎相同的嵌入（完全崩溃），或者只落在一个低维子空间上（维度崩溃）。</p><p>而有关JEPAs的理论基础研究在很大程度上仍处于空白状态，研究人员通过重新审视支撑JEPAs的若干基础设计原则来打破这一循环。</p><p>这种审视首先源于一个问题：JEPAs至少应该满足哪些必要条件？由此，研究人员提炼出一种全新且精简的JEPA「原则」：</p><p>解决预测任务，同时强制嵌入服从各向同性高斯分布。</p><p>研究人员证明，为了在任意下游任务上最小化经验风险，Enc() 应该服从各向同性高斯分布。</p><p>研究人员首先通过分析线性探针（linear probe）来确定的嵌入的最优分布，这是评估冻结编码器时最常用的方法之一。</p><p>为了对预训练编码器进行更灵活的评估，研究人员还分析了两类广泛使用的非线性方法：</p><p>一种是基于半径的k-NN方法，该方法因其简单性而经常被采用；另一种是核方法，因其良好的理论可解析性而常用。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403866" alt="" title="" loading="lazy"/></p><p>上图展示了各向异性嵌入如何比各向同性嵌入产生更高的方差估计值（左图）。</p><p>研究人员对二分类任务抽取了100个训练点，并拟合逻辑回归模型——在多个训练集样本上重复此过程。每次抽样都会产生一个决策边界（紫色）。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403867" alt="" title="" loading="lazy"/></p><p><strong>SIGReg</strong></p><p><strong>高维空间中可靠的各向同性高斯正则化</strong></p><p>在证明各向同性高斯分布是最优嵌入分布之后，研究人员引入了SIGReg。</p><p>这是一个同时具有可微性、可扩展性、理论可证明性以及可解释性的分布匹配目标函数。</p><p>它建立在三个关键创新之上。</p><p>首先，研究人员将分布匹配表述为在原假设=下的统计假设检验；</p><p>其次，构造了一类检验，在保持线性复杂度和高效多GPU扩展的同时，保证梯度和曲率均有界。</p><p>第三，SIGReg避免了维度灾难，从而彻底消除了退化的捷径解（collapsed shortcut solutions）。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403868" alt="" title="" loading="lazy"/></p><p>图4展示了具有不同Sobolev平滑系数α的球面上分布示例。</p><p>由于目标密度（各向同性高斯分布）是平滑的，嵌入的α系数会迅速增长，从而使SIGReg不受维度灾难的影响。</p><p>研究人员证明，SIGReg绘制Epps-Pulley测试图是稳定且可扩展的。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403869" alt="" title="" loading="lazy"/></p><p>图5显示了构建的数据密度图。其「X」分布的边缘分布为标准高斯分布，协方差为单位矩阵（左侧密度图）。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403870" alt="" title="" loading="lazy"/></p><p>图6展示了从一个1024维标准高斯分布中抽取100个样本（N=100），并改变前两个坐标以生成图5（最左列）中的「X」分布。</p><p>对于每个统计量（所有其他列），研究人员对样本执行梯度下降以最小化其值，在每次迭代步骤中，使用10个随机方向的样本（M=10）来评估SIGReg。</p><p>结果表明，尽管这是一个高维分布且样本数量有限，但SIGReg能够捕获退化子空间并相应地调整数据以匹配各向同性高斯分布。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403871" alt="" title="" loading="lazy"/></p><p><strong>LeJEPA</strong></p><p><strong>稳定且可扩展的实现</strong></p><p>在确定各向同性高斯分布是基础模型的最佳嵌入分布，并引入SIGReg来实现该分布之后，研究人员推出了完整的LeJEPA框架，并通过全面的实验来验证其有效性。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403872" alt="" title="" loading="lazy"/></p><p>图9展示了使用LeJEPA开箱即用的ImageNet-10预训练和冻结骨干网络线性评估方法在timm模型上的应用。</p><p>研究人员对学习率和权重衰减进行了交叉验证。</p><p>虽然最佳模型和最差模型之间存在细微差异，但在涵盖8个模型系列的50个模型中，LeJEPA能够生成非平凡的表示，从而以SOTA水平解决下游任务。</p><p>跨架构稳定性，LeJEPA是关键优势之一。</p><p>大多数现代自监督学习方法都针对Vision Transformer进行了优化，而LeJEPA无需修改，即可在各种不同的架构系列中运行。</p><p>为了验证这一结论，研究人员使用ImageNet-10数据集预训练了来自8个不同架构系列的约50个模型，这些模型均来自timm库，且参数量均小于2000万。</p><p>所有模型均能学习到高质量的表征，在冻结骨干线性探测的情况下，Top-1准确率达到了91.5%到95%。</p><p>结果表明，在监督学习环境中表现良好的模型，例如ResNet和Vision Transformer，也同样适用于LeJEPA。</p><p>自监督学习的一个关键优势在于学习能够跨任务和领域泛化的通用表征。</p><p>然而，当前前沿的基础模型（如DINOv2/v3、I-JEPA）都是在自然图像上进行预训练的，这迫使特定领域的从业者需要收集大量的标签来进行监督式微调。</p><p>事实上，大多数前沿模型无法直接在这些领域进行训练，因为样本数量可能很少，而且重新搜索超参数会非常耗时。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403873" alt="" title="" loading="lazy"/></p><p>图12展示了使用冻结骨干网络或完全微调（列）以及不同类别样本数（x轴）的LeJEPA在小型架构（Galaxy10）上的域内预训练，并结合线性探针评估。</p><p>研究人员将其与最先进的基础模型（DINOv2/v3、I-JEPA）在3个不同的随机种子上进行了比较。</p><p>结果表明，LeJEPA能够开箱即用地在不同架构上进行域内预训练，并且性能优于目前最先进的基础模型。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403874" alt="" title="" loading="lazy"/></p><p>图13展示了基于最后一层阈值的涌现式目标分割，LeJEPA无需显式监督即可自然地学习分割和跟踪显著目标（如每个视频右侧的注意力图所示）。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403875" alt="" title="" loading="lazy"/></p><p>图14展示了LeJEPA通过自监督学习习得丰富的语义表征。</p><p>在没有任何监督的情况下，LeJEPA自发地构建出语义丰富的表征：暖色（红色/品红色/粉色）始终用于表示前景物体（鹦鹉的身体、狗的脸），而冷色（青色/绿色/黄色）则用于表示背景和树叶。</p><p>这种涌现的物体-背景分离和感知分组，完全基于未标记的数据，揭示了世界的视觉结构。</p><p>研究人员在多个领域、超过60种架构上验证了LeJEPA，其中包括参数规模高达18亿的巨型模型版本。</p><p>结果证明，尽管其核心设计非常简单，LeJEPA的核心实现代码不足50行，但仍能够达到当前最先进方法的性能，该方法填补了长期以来在自监督学习理论基础研究领域的空白。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403876" alt="" title="" loading="lazy"/></p><p><strong>作者简介</strong></p><h2>Yann LeCun</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403877" alt="" title="" loading="lazy"/></p><p>Yann LeCun是法国计算机科学家、深度学习先驱，纽约大学终身教授，曾任Meta首席人工智能科学家。</p><p>他于20世纪90年代提出并工程化了卷积神经网络（LeNet），推动了深度学习在图像识别等领域的实际落地，因此与Geoffrey Hinton、Yoshua Bengio一同被称为「深度学习三巨头」。</p><p>2018年，他因在神经网络与深度学习方面的开创性贡献获得图灵奖。</p><p>近年来，LeCun主要关注自监督学习、世界模型和能量基模型等方向，对当前大模型通往AGI的前景持审慎甚至批评态度，同时强烈支持开源与开放科研。</p><p>参考资料：</p><p><a href="https://link.segmentfault.com/?enc=PJC2j7cNwnUQIOzirI%2FJpA%3D%3D.Q7afnL9GPys92T7XE%2BmVXj%2BuHYX7RKOvNHdQXNZUtyB4I8stT%2BNCfu8DEwOWdnyC" rel="nofollow" target="_blank">https://arxiv.org/abs/2511.08...</a></p><p><a href="https://link.segmentfault.com/?enc=eBuHgaC9jp%2Bmyz3W95D5xg%3D%3D.LWX3WCijwkF5sIqGcsUzhVLSiN42ezauqR5xhZWI3Sw5t6Zgrwd5Nb7qs0VAoPJDCC%2FBkknLpxOgPE3SdVjPm%2FWG%2Br0XI0kfF8zmVsr5opo%3D" rel="nofollow" target="_blank">https://twitter.com/iScienceL...</a></p>]]></description></item><item>    <title><![CDATA[在等待AGI的十年里，我们正成为最无准备]]></title>    <link>https://segmentfault.com/a/1190000047403835</link>    <guid>https://segmentfault.com/a/1190000047403835</guid>    <pubDate>2025-11-17 10:11:27</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>编辑：KingHZ</p><p>【新智元导读】AGI不再是遥远的科幻，专家们齐声预测：十年内触手可及。当共识形成，然后呢？</p><p>如今，每个人似乎都有自己的AGI时间表。</p><p>Karpathy可能给出了美国AI圈最保守的估计：「<strong>AGI还需等待10年</strong>。」</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403837" alt="" title=""/></p><p>这似乎逐渐形成了一个行业共识。</p><p>相比于预测本身，美国AI自媒体节目「TBPN」主持人John Coogan更关心的是，当所有人都开始相信这个时间点，会带来怎样的影响。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403838" alt="" title="" loading="lazy"/></p><p>《TBPN》是一档让硅谷痴迷的节目——在这里，再微小的职场动向都值得被记录。</p><p>扎克伯格、纳德拉、奥特曼等AI名人做客过该节目，主持人John Coogan在AI圈可以说是「博闻多识、见多识广」。</p><p>看一下他对AGI时间线的观点吧。</p><p>不过，我们还是先看看AI领域的大佬们都说了些什么。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403839" alt="" title="" loading="lazy"/></p><p><strong>AGI时间线共识：10年</strong></p><p>OpenAI奥特曼曾写道，按照传统对AGI的理解，OpenAI确信他们知道如何实现AGI。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403840" alt="" title="" loading="lazy"/></p><p>奥特曼相对乐观。在他看来，AGI不是「一个特别有用的词」——已经与AI日新月异的进步关系不大了。</p><p>而且，不是他一个人如此认为。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403841" alt="" title="" loading="lazy"/></p><p>The Futurum Group的副总裁兼AI实践负责人Nick Patience告诉媒体，尽管AGI是一个 「激励人心的北极星」，但总体而言，它并不是一个有用的术语。</p><p>与其谈论这个模糊的「通用」智能概念，不如谈论具体能力更有用。</p><p>在播客节目中，Andrej Karpathy提到：「距离AGI还有十年。」</p><p>他相对悲观，认为：「即便10年后， AI也并非无所不能。」</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403842" alt="" title="" loading="lazy"/></p><p>美国知名播客节目主持人Dwarkesh，也认为AGI的概率分布在时间轴上的中位点是2035年。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403843" alt="" title="" loading="lazy"/></p><p>他认为，AGI的时间线呈高度对数正态分布。要么在这十年内实现，要么就希望渺茫（准确地说并非完全无望，而是每年实现的边际概率递减）。</p><p>2030年后，AI进步必须主要依靠算法创新。但即便在算法领域，深度学习范式下的低垂果实也即将被摘尽。因此，AGI实现的年度概率将呈现断崖式下降。</p><p>George Hotz是全球第一个解锁iPhone的黑客，最近分析了特斯拉完全自动驾驶FSD数据，根据每年能力翻倍（即单位行驶距离中的人为干预次数下降），他预测8年内自动驾驶将达到超人类水平。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403844" alt="" title="" loading="lazy"/></p><p>METR团队一直在追踪AI完成长任务的能力。相关指标也呈指数增长。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403845" alt="" title="" loading="lazy"/></p><p>如果你把这条趋势线延伸到2035年，时间跨度就变成了几十年，看起来就像是一整个职业生涯。</p><p>这些预测方法五花八门，有的极度量化，有的靠直觉「看感觉」。但最引人注意的是：几乎所有人都把目标点定在了「十年」。</p><p>硅谷甚至有「爆发或熄火」的论断：在未来5-10年内，AGI如果无法实现，那么其实现可能遥不可及。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403846" alt="" title="" loading="lazy"/></p><p>Mark Gubrud，创造了「AGI一词的人，留言表态：</p><p>AGI如今已经存在。……</p><p>10年后，将是ASI时代。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403847" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403848" alt="" title="" loading="lazy"/></p><p><strong>10年匆匆，上下茫然</strong></p><p>「十年后实现」，这会不会只是技术专家们在不知道确切答案时的一种托辞？</p><p>主持人John Coogan对「AGI的10年实现」有所怀疑。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403849" alt="" title="" loading="lazy"/></p><p>但奇怪的是，他也认同这个说法，感觉通用人工智能真的就快来了。</p><p>真正让他纠结的是，这背后意味着什么。</p><p>或许十年足够长，大家还能继续按部就班地生活。</p><p>但他总感觉，当下正弥漫着「偏好伪装」——</p><p><strong>大家嘴上说着相信，行动上却并非如此。</strong></p><p>尽管对通用人工智能十年内到来的共识日益增强，但关于我们现在到底该做什么，却前所未有地缺乏共识。</p><p>难道我们只能无所事事地等待，一边开发那些能带来短暂多巴胺奖励的有趣技术吗？</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403850" alt="" title="" loading="lazy"/></p><p>John Coogan感觉这不太对劲。</p><p>最近，在TBPN播客中，Meta的Alex Wang的一段采访片段被疯传。</p><p>这是他今年9月份在TBPN上对年轻人的建议：</p><p>如果你现在 13 岁，你应该把所有时间都花在「vibe coding」上。这是比尔·盖茨、马克·扎克伯格「觉醒时刻」。那些从小就与这些工具一起成长的人，未来在经济中将拥有巨大的优势。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403851" alt="" title="" loading="lazy"/></p><p>网友从多个角度说明这个建议多么的糟糕！</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403852" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403853" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403854" alt="" title="" loading="lazy"/></p><p>对此，John Coogan完全不同意那些批评者的看法。</p><p>而且他肯定会教他的孩子「vibe code」。</p><p>他认为，「vibe code」像拼乐高一样组装软件，本身就充满魔力。</p><p>即使这种技能在十年后会被淘汰，他认为这依然充满乐趣:</p><p>你当然可以直接买到拼好的乐高套装，但没人会这么做。所以，「vibe code」万岁。</p><p>把「vibe coding」比作乐高积木组装，真是奇怪的隐喻。</p><p>但两者没有任何关系——</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403855" alt="" title="" loading="lazy"/></p><p>无人知道，如果AGI真是「盒子里的神祗」，人类往何处去。</p><p>参考资料：</p><p><a href="https://link.segmentfault.com/?enc=r8YtaYgzEMixz5PNUftE8g%3D%3D.TxsFJlQ%2FGi2fYzouWV%2Fi3eLY3g%2F3NTG4nYwRboqng2ZW8wYp1gQRgleUhIM8wuvoiZ18shpQfKcsS9Lu02HYJg%3D%3D" rel="nofollow" target="_blank">https://twitter.com/johncooga...</a></p><p><a href="https://link.segmentfault.com/?enc=MlMD8cXHRh9v%2BSKntrSCrQ%3D%3D.tOrupbR4tKWM5iQoOlexQJJ1A19d7b3WgwdJ2pvAab1yMi2Z7TXEVe1a%2BkpGupEc" rel="nofollow" target="_blank">https://www.dwarkesh.com/p/ti...</a></p>]]></description></item><item>    <title><![CDATA[网站如何实现HTTPS 冷冷的炒面 ]]></title>    <link>https://segmentfault.com/a/1190000047403760</link>    <guid>https://segmentfault.com/a/1190000047403760</guid>    <pubDate>2025-11-17 10:10:40</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>当您访问网站时，地址栏中的"https://"前缀和锁形图标表示该网站已建立安全连接。这种安全连接意味着浏览器与网站之间的所有数据传输都经过加密处理，有效防止信息被窃取或篡改。</p><p>一、 核心准备：获取SSL/TLS证书</p><p>实现HTTPS的第一步是获取数字证书，这是建立安全连接的基础。SSL/TLS证书由受信任的证书颁发机构（CA）签发，其主要功能包括：</p><p>1.加密传输数据：通过加密算法保护数据传输过程中的安全性</p><p>2.验证网站身份：确保证书持有者对域名拥有合法使用权</p><p>证书分为以下几种类型：</p><p>域名验证型（DV）  ：验证域名所有权，适合个人网站</p><p>组织验证型（OV）  ：验证组织真实性，适合企业网站</p><p>扩展验证型（EV）  ：进行严格审查，在浏览器地址栏显示企业名称</p><p>您可以从专业的证书颁发机构获取合适的证书，根据网站类型和安全需求选择相应产品。</p><h4><a href="https://link.segmentfault.com/?enc=Qu%2BQcEy7nVuY6PBvz55UIA%3D%3D.l6wqLhm2kD%2BVWZVr7NW0%2BhqkLkI7b5A%2FbpSjuww2jb71gc6tNwcTk6a314RyMR36XYgvNXmlpL%2B72%2BWSAxw5%2FQ%3D%3D" rel="nofollow" target="_blank">申请入口</a>直接访问JoySSL，注册一个账号记得填写注册码230973获取技术支持</h4><h4>小标题</h4><p><img width="723" height="400" referrerpolicy="no-referrer" src="/img/bVdmZji" alt="" title=""/></p><p>二、 服务器配置：安装部署证书</p><p>获得证书文件后，需要在网站服务器上进行安装和配置。这个过程因服务器类型而异：</p><p>1.Nginx服务器：修改站点配置文件，添加监听443端口的配置项，指定证书文件和私钥文件的路径，并启用SSL协议支持。</p><p>2.Apache服务器：编辑虚拟主机配置文件，加载SSL模块，配置证书文件和密钥文件路径，设置加密套件参数。</p><p>3.云服务平台：大多数云服务商提供证书管理服务，可通过控制面板上传证书文件，简化部署流程。完成配置后需要重启Web服务使设置生效，此时可通过https协议访问网站。</p><p>三、 完善设置：全面启用HTTPS</p><p>证书安装完成后，还需要进行以下优化设置：</p><p>1.启用强制重定向：配置服务器将所有HTTP请求自动重定向到HTTPS，确保所有访问都通过安全连接进行。</p><p>2.更新内部链接：将网站内的所有资源链接（图片、脚本、样式表等）改为使用HTTPS协议，避免出现"混合内容"警告。</p><p>3.实施HSTS策略：通过HTTP严格传输安全标头，指示浏览器始终使用HTTPS连接，增强安全性。</p><p>四、持续维护与管理实现HTTPS化后，需要建立长期的维护机制：</p><p>1.证书有效期管理：SSL证书具有明确的有效期限，需要建立监控机制确保及时续期更换。</p><p>2.安全协议更新：定期检查并更新SSL/TLS协议版本和加密套件，保持与最新安全标准同步。</p><p>3.性能优化：启用OCSP装订等技术减少握手延迟，保证安全性的同时维持网站性能。</p><p>实施HTTPS不仅是提升网站安全性的必要措施，也是建立用户信任、提升品牌形象的重要手段</p>]]></description></item><item>    <title><![CDATA[局域网怎么申请SSL证书 冷冷的炒面 ]]></title>    <link>https://segmentfault.com/a/1190000047403786</link>    <guid>https://segmentfault.com/a/1190000047403786</guid>    <pubDate>2025-11-17 10:09:42</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>许多人为局域网（如公司内部OA、智能家居系统）访问时浏览器弹出的“不安全”警告而烦恼。其实，通过为局域网服务配置SSL证书，就能解决这个问题，实现“https”安全访问。</p><p>一、 明确需求：你需要哪种证书？</p><p>为局域网申请证书，主要就是以下方法</p><p>公共可信证书（推荐） ：由全球可信的证书颁发机构（CA）签发。优点是任何设备访问都直接信任，无安全警告。</p><p>对于绝大多数局域网应用，我们追求便捷和安全，因此申请公共可信证书是更优解。</p><p>内网IP地址SSL证书<a href="https://link.segmentfault.com/?enc=wilycz08%2BaJYPiGxskWcMw%3D%3D.qpxgrMw0u4G0XbuJiT9rg%2BKUCZjQrFgxyVkh2KI9QQt8H4ZsGtCvbXviFrSMMI8S%2FZDIXswcgrt4qONAB3fjWEC%2B6RU9svT0KJnfLhrNQW8%3D" rel="nofollow" target="_blank">申请入口</a></p><p>直接访问JoySSL官网，注册一个账号记得填写注册码230973获取技术支持。</p><p>二、 如何申请公共可信证书？</p><p>公共CA默认只为公网域名签发证书。要让其为局域网IP或域名签发，需要验证你对这个地址的所有权。核心步骤如下：</p><p>拥有一个域名：</p><p>你必须有一个自己注册的公有域名（例如your-company.com）。这是所有操作的基础。</p><p>创建DNS解析记录：</p><p>登录你的域名管理后台，为你局域网的服务器IP地址创建一个DNS解析记录。有两种常见方式：</p><p>解析域名到内网IP：例如，创建一个A记录oa.your-company.com，将其指向你内网服务器的IP地址192.168.1.100。</p><p>使用泛解析：创建一个*.internal.your-company.com的泛解析记录，指向你的内网网关或服务器，这样所有子域名都可以使用。</p><p>选择CA并申请证书：</p><p>前往各大SSL证书服务商（如JoySSL、阿里云、腾讯云等）平台。选择适合的证书类型（单域名或泛域名）。</p><p>在申请时，通用名称（CN） 一栏就填写你刚设置的域名（如oa.your-company.com）。</p><p>选择DNS验证方式。CA会要求你在域名DNS设置里添加一条特定的TXT记录，以验证你拥有该域名的管理权。按照提示操作即可。</p><p>验证并获取证书：</p><p>完成DNS验证后，CA通常几分钟内就会签发证书。你然后在证书管理平台下载颁发的证书文件（一般包含.crt和.key文件）。</p><p>三、 在服务器上安装部署</p><p>将下载的证书文件上传到你的局域网服务器上，并在Web服务软件（如Nginx, Apache, IIS）中进行配置，指定证书和私钥的路径，然后重启服务。</p><p>重要总结</p><p>核心原理：利用公有域名来“代理”验证局域网服务的可信性。</p><p>最大优点：一旦部署成功，局域网内任何设备、任何浏览器访问该服务，都会显示安全的小锁标志，无需每台设备手动安装证书。</p><p>最佳选择：强烈建议使用泛域名证书，一个证书可以保护同一个域名下的所有二级子域名，非常适合内部有多项服务的环境。</p>]]></description></item><item>    <title><![CDATA[什么是SSL证书？SSL有什么作用？ 追]]></title>    <link>https://segmentfault.com/a/1190000047403793</link>    <guid>https://segmentfault.com/a/1190000047403793</guid>    <pubDate>2025-11-17 10:09:10</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img width="723" height="1098" referrerpolicy="no-referrer" src="/img/bVdm324" alt="c18a2b734b8f9faf0051f9fb98727bc8.png" title="c18a2b734b8f9faf0051f9fb98727bc8.png"/></p><h3>一、SSL证书的基本概念</h3><ul><li><p><strong>SSL/TLS证书的定义</strong></p><ul><li>SSL证书是一种数字证书，用于在客户端与服务器之间建立加密连接，验证网站身份并保障数据传输安全。</li></ul></li><li><p><strong>核心作用</strong></p><ul><li><strong>数据加密</strong>：通过HTTPS协议加密敏感信息，防止窃听和中间人攻击。</li><li><strong>身份验证</strong>：确认网站真实性，抵御钓鱼网站。</li><li><strong>数据完整性</strong>：确保传输过程中数据未被篡改。</li></ul></li></ul><p><strong><a href="https://link.segmentfault.com/?enc=q61HMN%2FlxJNBH7j5Z7BreA%3D%3D.6FZqddrJLhkKZYDKhPE3pVFiWL0POY1%2BTN0B8ObATRrn5EGFu1TVGwdl6ZgGRRh%2BcjZWYqcN%2FUa0UHgzPsSfHQ%3D%3D" rel="nofollow" target="_blank">https://www.joyssl.com/certificate/select/free.html?nid=59</a></strong></p><p><img width="723" height="450" referrerpolicy="no-referrer" src="/img/bVdmOqt" alt="93b41f9735e5bc85205fe82990af4f60.png" title="93b41f9735e5bc85205fe82990af4f60.png" loading="lazy"/></p><h3>二、SSL证书的技术原理</h3><ul><li><p><strong>加密机制</strong></p><ul><li><strong>非对称加密</strong>：用于初始密钥交换，通过公钥和私钥对确保安全传输。</li><li><strong>对称加密</strong>：后续数据传输阶段使用高效对称密钥加密。</li></ul></li><li><p><strong>SSL/TLS握手流程</strong></p><ul><li>包括客户端与服务器协商加密套件、验证证书、生成会话密钥等步骤。</li></ul></li></ul><h3>三、SSL证书的类型划分</h3><ul><li><p><strong>按验证级别分类</strong></p><ul><li><strong>DV（域名验证）</strong> ：基础验证，仅验证域名所有权，适合个人网站。</li><li><strong>OV（组织验证）</strong> ：需审核企业信息，显示组织名称，适用于企业官网。</li><li><strong>EV（扩展验证）</strong> ：严格审核企业资质，地址栏变绿并显示公司名，适用于金融、电商领域。</li></ul></li><li><p><strong>按覆盖范围分类</strong></p><ul><li><strong>单域名</strong>：仅限单个域名。</li><li><strong>通配符</strong>：覆盖主域名及无限子域名。</li><li><strong>多域名</strong>：支持多个不同域名绑定。</li></ul></li></ul><h3>四、SSL证书的应用价值</h3><ul><li><p><strong>安全防护</strong></p><ul><li>防止流量劫持、数据泄露及篡改，保护用户隐私。</li></ul></li><li><p><strong>信任增强</strong></p><ul><li>浏览器显示安全标识，提升用户对网站的信任度。</li></ul></li><li><p><strong>SEO优化</strong></p><ul><li>搜索引擎优先推荐HTTPS网站，提高搜索排名。</li></ul></li></ul><h3>五、证书组成与颁发流程</h3><ul><li><p><strong>证书结构</strong></p><ul><li>包含主题信息（域名、组织名称）、有效期、公钥、签名算法等。</li></ul></li><li><p><strong>颁发流程</strong></p><ul><li><strong>生成CSR文件</strong>：提交至CA机构审核。</li><li><strong>CA验证</strong>：通过域名或企业资料核验身份。</li><li><strong>安装部署</strong>：将证书配置到服务器并启用HTTPS。</li></ul></li></ul>]]></description></item><item>    <title><![CDATA[网站为什么会出现不安全提示？ 傻傻的开心]]></title>    <link>https://segmentfault.com/a/1190000047403802</link>    <guid>https://segmentfault.com/a/1190000047403802</guid>    <pubDate>2025-11-17 10:08:28</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>当浏览器提示网站“不安全”时（如下图），通常是因为 HTTPS 配置存在问题或证书未正确部署。以下是常见原因及解决办法：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403804" alt="" title=""/><a href="" target="_blank"/></p><p><strong>一、网站出现不安全提示的常见原因</strong></p><p><strong>1. SSL证书缺失或未启用HTTPS</strong></p><p><strong>现象描述：</strong> 网站仍使用传统的HTTP协议进行数据传输，而非加密的HTTPS协议。</p><p><strong>风险分析：</strong> HTTP协议下，数据以明文形式在网络中传输，极易被窃听、篡改或伪造，用户的敏感信息（如登录密码、支付信息等）面临泄露风险。</p><p><strong>解决方案：</strong> 部署SSL证书，启用HTTPS协议，对数据进行加密传输，确保数据在传输过程中的安全性。</p><p><strong>2. SSL证书过期或失效</strong></p><p><strong>现象描述：</strong> SSL证书具有一定的有效期，过期后未及时续费，浏览器将不再信任该证书。</p><p><strong>风险分析：</strong> 过期的证书无法有效验证网站身份，可能导致用户信任度下降，甚至引发安全警告。</p><p><strong>解决方案：</strong> 定期检查SSL证书的有效期，提前规划续费流程，确保证书始终处于有效状态。</p><p><strong>3. 证书与域名不匹配</strong></p><p><strong>现象描述：</strong> SSL证书绑定的域名与实际访问的域名不一致。</p><p><strong>风险分析：</strong> 域名不匹配可能导致浏览器无法验证网站的真实身份，从而触发安全警告。</p><p><strong>解决方案：</strong> 在申请SSL证书时，确保证书绑定的域名与网站实际使用的域名完全一致。</p><p><strong>4. 混合内容问题</strong></p><p><strong>现象描述：</strong> 网站启用了HTTPS，但页面中嵌入了HTTP协议的资源（如图片、脚本、样式表等）。</p><p><strong>风险分析：</strong> 混合内容可能导致数据传输过程中的部分信息未加密，降低整体安全性，浏览器可能因此标记网站为“不安全”。</p><p><strong>解决方案：</strong> 全面检查网站代码，将所有嵌套资源的URL替换为HTTPS，确保页面内容的完全加密。</p><p><strong>5. 恶意软件或钓鱼攻击</strong></p><p><strong>现象描述：</strong> 网站被植入恶意代码，或被仿冒为钓鱼网站，诱导用户输入敏感信息。</p><p><strong>风险分析：</strong> 恶意软件可能窃取用户数据，钓鱼网站则可能骗取用户的账号密码等重要信息。</p><p><strong>解决方案：</strong> 定期进行网站安全扫描，及时发现并清除恶意代码；加强网站防护，防止钓鱼攻击。</p><p><strong>二、SSL证书是什么？</strong></p><p>SSL证书是一种由权威证书颁发机构（CA）签发的数字证书，它遵循SSL/TLS协议，对网站服务器与用户浏览器之间的数据进行加密传输。通过部署SSL证书，网站可以实现以下安全目标：</p><p><strong>数据加密：</strong> 确保数据在传输过程中不被窃听、篡改或伪造。</p><p><strong>身份验证：</strong> 验证网站服务器的真实身份，防止用户被钓鱼网站误导。</p><p><strong>提升信任度：</strong> 浏览器地址栏显示锁形图标和HTTPS前缀，向用户传递网站安全可信的信号。</p><p>SSL证书申请: <a href="https://link.segmentfault.com/?enc=uODRT6kIV5MlGLHKmT5Rfw%3D%3D.wkh8P9%2BaZFUf1OE5%2FKgETZKxwY%2B0m2edt1BYc0y7o2f93zy9TSVQupuUr8NROplYatkJ2GXgFf%2FjUdPGeG6nDg%3D%3D" rel="nofollow" target="_blank">申请入口</a>: 注册时填写230968获取技术支持</p><p><strong>三、如何选择合适的SSL证书？</strong></p><p><strong>根据网站类型选择：</strong></p><p>个人网站可选择域名验证型（DV）证书，</p><p>企业网站则建议选择组织验证型（OV）或扩展验证型（EV）证书，以提供更高级别的身份验证。</p><p><strong>考虑证书品牌：</strong></p><p>选择知名、受信任的证书颁发机构（CA），确保证书的广泛兼容性和安全性。</p><p>选择有效期较长的证书，减少频繁续费的麻烦。同时，确保证书支持自动续期功能（例如JoySSL就提供自动续签功能），避免因过期而引发安全问题。</p><p>网站出现不安全提示，不仅会影响用户体验，还可能损害企业的品牌形象和业务利益。通过部署SSL证书、定期更新证书、修复混合内容问题以及加强网站安全防护，您可以有效解决这一问题，提升网站的安全</p>]]></description></item><item>    <title><![CDATA[告别 271 万小时重复劳动：银行数字员]]></title>    <link>https://segmentfault.com/a/1190000047403813</link>    <guid>https://segmentfault.com/a/1190000047403813</guid>    <pubDate>2025-11-17 10:07:40</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><strong>导语｜</strong>当上海银行的海小慧让老年用户使用手机银行的门槛直降 50%，当华夏银行的风控数字员工把贷款审批时效提速 90%，当建设银行的 RPA 平台一年省下 271 万小时工时 —— 这些真实发生在银行业的效率革命，背后都站着同一个新角色：数字员工。而随着应用深化，数字员工的管理与落地难题也逐渐浮出水面。</p><p>为此，我们特别邀请到富邦华一银行信息科技部副总经理、腾讯云 TVP 屈新春，从技术落地到组织协同，从风险管控到社会责任，手把手拆解银行数字员工的管理密码，带你探索这场人机协同革命里，银行到底该怎么干。</p><h2><strong>作者简介</strong></h2><p><img width="723" height="375" referrerpolicy="no-referrer" src="/img/bVdm33I" alt="image.png" title="image.png"/></p><p>屈新春，富邦华一银行信息科技部副总经理，曾经在世界 500 强通讯设备公司担任 3G/4G 算法工程师，2012 年加入银行业，从事过银行核心系统、渠道系统、支付系统开发和技术管理，作为高级架构师曾参与 150+ 银行科技输出。</p><p>自 2019 年加入富邦华一以来，作为主要技术负责人，牵头完成多项关键系统建设与重构，包括互联网贷款、信用卡、数据仓库、开放银行、手机银行、分布式核心系统等，显著提升银行数字化服务与业务支撑能力。在技术层面，率先引入分布式服务治理、微服务及分布式架构，并成功培训内部团队掌握相关技术；在架构方法论上，引入 EA 企业架构理论，培养架构人才，构建标准化、可扩展的架构体系；在大数据与 AI 建设方面，牵头构建了企业级大数据平台，引入 AI 大模型技术（如DeepSeek等生成式大模型），并建设 MLOps 平台实现模型的全生命周期管理。</p><h2><strong>一、拆解数字员工：银行的智慧手脚与大脑</strong></h2><h3><strong>1.1 “手脑并用”：数字员工的四层技术栈</strong></h3><p>银行的数字员工不是一个单一工具，而是一套动手又动脑的技术组合拳。它之所以能够带来银行业的效率革命，正是因为它拥有一个清晰、分工明确的底层架构。</p><p>数字员工的核心架构分四层，每层各司其职，缺一不可：</p><p>● 执行层（手脚）：靠 RPA（机器人流程自动化）干活，比如点击银行系统界面、录入客户数据、传输报表文件，能无缝对接核心系统、信贷系统等现有工具，替人干最机械的活；</p><p>● 认知层（大脑）：靠 AI 技术思考，比如用 NLP（自然语言处理）理解客户咨询，用机器学习分析贷款风险，用计算机视觉识别发票信息，让数字员工能处理非规则性任务；</p><p>● 平台层（管家）：靠业务流程管理平台调度，负责给数字员工分配任务、监控工作状态、展示工作成果，是数字员工能规模化应用的关键；</p><p>● 数据与知识层（知识库）：靠企业级知识图谱补给，整合银行的产品规则、客户信息、业务流程，让数字员工做决策时有据可依。</p><h3><strong>1.2 从台前到幕后：数字员工在银行的 3 大核心场景</strong></h3><p>正是基于四层技术栈的协同支撑，银行数字员工的应用才得以突破了传统的客服局限。它们不仅是前台的“门面担当”，更是渗透到中台决策和后台执行的业务全链条，实现了从智能客服到全能管家的跃迁。</p><p>下表详细展示了数字员工在银行业务链中前台交互、中台决策、后台执行三大核心场景的渗透深度与显著的效能提升。</p><p><img width="723" height="240" referrerpolicy="no-referrer" src="/img/bVdm33J" alt="image.png" title="image.png" loading="lazy"/></p><p>表1：数字员工在银行业务链的渗透深度与效能比</p><h2><strong>二、业绩算谁的？出错谁担责</strong></h2><p>随着数字员工干的活越来越多，新的争议也来了：它帮业务部提升了业绩，功劳该归业务部还是 IT 部？要是它算错了账、漏了风控，责任该谁扛？这些问题不解决，数字员工就难真正融入银行。</p><h3><strong>2.1 业绩归属</strong></h3><p>数字员工带来的价值，从来不是单一部门的功劳：业务部是需求方，知道哪里需要数字员工帮忙；IT 部是支撑方，确保数字员工能稳定干活。所以绩效考核时，不能只看业务部的效率提升，也要看 IT 部的系统稳定性，用联动指标算清楚双方的贡献，避免业务部拿奖、IT 部背锅的尴尬。</p><h3><strong>2.2 责任划分</strong></h3><p>数字员工出了错，不能找不到负责人，得按业务主导、科技支撑、监管合规的原则来定责：</p><p>● 业务部要确保数字员工的操作符合业务规则和监管要求，比如贷款审批的标准不能错；</p><p>● IT 部要保证系统不故障、数据不泄露、算法不出错，比如防止数字员工因系统 bug 漏审风险；</p><p>● 更关键的是数字监护人制度：每个数字员工都要有一个负责人，通常由使用它的业务岗员工担任，监督它的日常运行，出了问题先找监护人 —— 这就像给数字员工找了个人类搭档，既明确责任，又能及时纠错。</p><p>当然，光有人负责还不够，银行还要建审计追踪机制，让数字员工的每一步操作都能查得到，这样责任界定才有依据。</p><h2><strong>三、数字员工如何落地：业务、科技、人力资源的协同铁三角</strong></h2><p>很多银行推数字员工时，会遇到业务部想要、IT 部不会、HR 不管的困境；其实数字员工要落地，必须靠 HR、IT、业务部三方协同，少了任何一方都不行。</p><p>理想的协同模式应清晰界定各方职责，并建立一个统筹管理的组织架构。</p><h3><strong>3.1 三方职责清单</strong></h3><p>● 业务部门：作为牵头的主角，最懂业务痛点，要牵头提需求、定标准，提出具体业务场景需求，定义数字员工的“工作职责”和绩效标准（KPI），并负责日常业务层面的使用与管理；</p><p>● IT 部门：作为支持者，负责技术选型、平台搭建、系统集成、安全运维和技术迭代，确保数字员工系统稳定、安全、高效。</p><p>● HR 部门：作为协调者，主导组织变革管理，负责数字员工的“虚拟人力资源管理”，并主导对现有员工的再技能培训，帮助他们转型以适应新的工作模式。</p><h3><strong>3.2 规模大了怎么办？</strong></h3><p>当银行用数字员工覆盖 50 个以上场景时，就需要一个统筹机构 —— 数字员工卓越中心（CoE）。这个中心是跨部门团队，由业务、IT、HR 的人一起组成，负责制定统一的技术标准（比如用什么 RPA 工具）、安全规则（比如数据怎么保密）、开发规范（比如数字员工怎么命名），避免每个部门各自为政，搞出五花八门的数字员工。华夏银行的 CoE 就很成功，让数字员工的推广效率提升了不少。</p><h2><strong>四、数字员工抢人饭碗？裁员危机or人才升级</strong></h2><p>银行高层在评估数字员工的价值时，需要超越简单的减编制思维。数字员工的核心价值并非成本削减，而是效率的指数级提升，以及人才结构的根本性优化。</p><h3><strong>4.1 优化人才结构</strong></h3><p>数字员工已成为银行的核心基础设施。它们专注于执行那些标准化、重复性的工作，例如录入客户数据、传输报表文件、填表或审核发票，这些是它们的高效性所擅长的。</p><p>这种解放，使得人类员工得以腾出手来，将精力转向高价值的创新领域。人类的创造力 将被用于与客户深度沟通、设计新的金融产品，或处理复杂、非规则性的任务。</p><h3><strong>4.2 帮助员工转型</strong></h3><p>帮助员工转型，是银行的社会责任，人机协同将是未来的发展方向。这要求银行管理层将目标从简单粗暴的“减编制”，转变为优化人才结构。具体可以采取下列措施：</p><ul><li>内部培训和转岗：比如给柜员、客服培训数字员工管理、远程银行服务等新技能，帮他们转型成数字员工管理师、客户关系经理；</li><li>做岗位对接：提前规划新岗位需求，比如数字员工需要人来监控、优化，这些岗位可以优先从内部招聘，让员工有安全感；</li><li>培育人机协同文化：多宣传数字员工作为搭档的案例，化解员工的焦虑，让大家愿意和数字员工合作。</li></ul><p>这样做不仅能保住员工士气，还能培养出既懂业务又懂技术的复合型人才，这对银行的长期发展更重要。</p><h2><strong>五、数字员工有风险：这4个坑要避开</strong></h2><p>数字员工虽然可以为银行带来指数级的效率提升，但其潜在的风险也不容忽视。从系统故障导致业务停摆，到数据泄露引发客户投诉，再到算法歧视带来的监管处罚，银行必须构建全面的风险治理框架。</p><p>这些风险可以被归纳为四类核心风险：技术风险、数据与隐私风险、合规与伦理风险、以及运营与体验风险；针对这些风险，银行需要采取多维度的应对策略。</p><p><img width="723" height="301" referrerpolicy="no-referrer" src="/img/bVdm33K" alt="image.png" title="image.png" loading="lazy"/><br/>表2：数字员工主要风险与应对策略</p><p>数字员工不是一建了之，还要定期维护：比如更新知识库，及时录入新的监管政策、产品规则要；优化算法，根据实际效果调整风控模型；制定退出预案，如某数字员工不再适用，要安全下线，避免数据残留—— 只有让数字员工持续进化，才能一直为银行创造价值。</p><h2><strong>结语</strong></h2><p>现在的数字员工，已经从银行的辅助工具变成核心基础设施。它的成功，不只是靠技术先进，更要看银行能不能在管理、组织、文化上做出变革：比如明确数字员工的权责，让 HR、IT、业务部协同合作，对员工负责到底。</p><p>未来的银行，不会是数字员工取代人，而是人机协同的智慧体：数字员工用高效性处理重复工作，人类员工用创造力设计新服务，两者结合能打造出更智能、更有温度的金融服务 —— 这才是银行业数字化转型的最终目标。而要实现这个目标，需要银行管理者有前瞻的视野，也需要每个员工愿意拥抱变化。</p>]]></description></item><item>    <title><![CDATA[uniapp微信小程序分包异步化，跨包组]]></title>    <link>https://segmentfault.com/a/1190000047403817</link>    <guid>https://segmentfault.com/a/1190000047403817</guid>    <pubDate>2025-11-17 10:06:39</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>微信小程序中，不同的分包对应不同的下载单元；因此，除了非独立分包可以依赖主包外，分包之间不能互相使用自定义组件或进行 <code>require</code>。「分包异步化」特性将允许通过一些配置和新的接口，使部分跨分包的内容可以等待下载后异步使用，从而一定程度上解决这个限制。</p><p>口述表达就是，如果想要在一个分包内使用另一个分包的组件或资源，可以通过分包异步化实现。<br/>通过分包异步化，可以节省包大小，当你的主包或子包的大小接近<code>2M</code>时，新的资源可以通过分包异步化引入，异步化组件不会占用包大小，从而节省包空间。</p><h2>配置pages.json</h2><pre><code>{
    "pages": [ // https://uniapp.dcloud.io/collocation/pages
        {
            "path": "pages/index/index",
            "style": {
                "navigationBarTitleText": "首页",
                "navigationStyle": "custom",
                "navigationBarTextStyle": "white" 
            }
        }
    ],
    "subPackages": [
        {
            "root": "subPackages/agent",
            "pages": [{
                "path": "pages/agent/index",
                "style": {
                    "navigationBarTitleText": "智能体页面",
                    "navigationBarTextStyle": "black",
                    "usingComponents": {
                        "nav-bar": "/subPackages/chat-component/pages/nav-bar/index" // 组件的路径
                    },
                    "componentPlaceholder": {
                        "nav-bar": "view" // 未完成时的占位组件
                    }
                }
            }]
        },
        {
            "root": "subPackages/chat-component",
            "pages": [{
                "path": "pages/chat/index",
                "style": {
                    "navigationBarTitleText": "",
                    "navigationStyle": "custom",
                    "navigationBarTextStyle": "white"
                }
            }]
        }
    ],
}</code></pre><p>这里我样式了一个子包中使用分包异步化，加载另一个子包组件的例子，其中<code>subPackages/agent</code>是一个子包，<code>subPackages/chat-component</code>是另一个子包，我在<code>subPackages/agent</code>子包的<code>pages/agent/index</code>页面引入<code>subPackages/chat-component</code>子包内的<code>nav-bar</code>组件<br/><img width="374" height="286" referrerpolicy="no-referrer" src="/img/bVdm33H" alt="" title=""/><br/>由于我引入的是<code>chat-component</code>子包内的<code>nav-bar/index</code>页面，而我们在<code>pages.json</code>里只定义了<code>chat-component/pages/chat/index.vue</code>页面，所以我们必须在<code>chat/index.vue</code>内引入同包的<code>nav-bar/index.vue</code>页面，否则<code>/nav-bar/index.vue</code>将不会被打包，导致分包异步化导入失败</p><pre><code>&lt;template&gt;
    &lt;view&gt;
        &lt;NavBar/&gt;
    &lt;/view&gt;
&lt;/template&gt;

&lt;script setup&gt;
import NavBar from '@/subPackages/chat-component/pages/nav-bar/index.vue';
&lt;/script&gt;</code></pre><p>到这里，我们的异步化的配置工作就做好了，可以在<code>agent/index.vue</code>页面正常导入了</p><h2>导入分包异步化组件</h2><p><code>agent/index.vue</code>页面</p><pre><code>&lt;template&gt;
    &lt;view&gt;
        &lt;NavBar /&gt;
    &lt;/view&gt;
&lt;/template&gt;

&lt;script setup&gt;
import NavBar from '@/subPackages/chat-component/pages/nav-bar/index.vue';
&lt;/script&gt;</code></pre><p>就像正常引入组件一样，导入使用即可，需要注意，导入的路径得跟<code>pages.json</code>内配置的组件路径一致。</p><h2>分包异步化支持的组件通信</h2><p>经过测试，得到如下总结：<br/>支持的通信方式：</p><ul><li>emit</li><li>props</li><li>defineModel</li><li>provide/inject</li></ul><p>不支持的通信方式：</p><ul><li>defineExpose 父组件调用异步化组件内的事件</li></ul><p>下面是测试页面，你可以复制到你的页面里直接查看效果<br/>父组件 <code>agent/index.vue</code></p><pre><code>&lt;template&gt;
    &lt;view&gt;
        &lt;view&gt;父级页面&lt;/view&gt;
        &lt;button type="primary" size="mini" @click="onFn"&gt;父组件调用子组件事件&lt;/button&gt;
        &lt;button type="primary" size="mini" @click="onFnUpdate"&gt;父组件修改双向绑定内容&lt;/button&gt;
        &lt;view&gt;===============================================&lt;/view&gt;
        &lt;view&gt;分包异步化组件&lt;/view&gt;
        &lt;NavBar ref="navBarRef" :text="text" v-model="text2" @onBack="onBack" /&gt;
    &lt;/view&gt;
&lt;/template&gt;

&lt;script setup&gt;
import NavBar from '@/subPackages/chat-component/pages/nav-bar/index.vue';
import { ref, provide } from 'vue';

const navBarRef = ref();

const form = ref({
    text: '测试provide'
});
provide('form', form);

const text = ref('父组件内容');

const text2 = ref('双向绑定的内容');
const onFnUpdate = () =&gt; {
    text2.value = '父组件修改';
};

const onFn = () =&gt; {
    navBarRef.value.event1();
};

const onBack = (e) =&gt; {
    console.log('子组件返回了', e);
};
&lt;/script&gt;</code></pre><p>异步化组件 <code>nav-bar/index.vue</code></p><pre><code>&lt;template&gt;
    &lt;view&gt;
        &lt;button type="primary" size="mini" @click="onBack"&gt;子组件事件回传&lt;/button&gt;
        &lt;view&gt;props绑定内容:{{ props.text }}&lt;/view&gt;
        &lt;button type="primary" size="mini" @click="onUpdate"&gt;子组件修改双向绑定内容&lt;/button&gt;
        &lt;view&gt;
            {{ text2 }}
        &lt;/view&gt;
        &lt;view&gt;
            {{ form.text }}
        &lt;/view&gt;
    &lt;/view&gt;
&lt;/template&gt;

&lt;script setup&gt;
import { defineEmits, defineProps, defineExpose, defineModel, inject } from 'vue';

const props = defineProps({
    text: {
        type: String,
        defaule: ''
    }
});
const emit = defineEmits(['onBack']);

const form = inject('form');

const text2 = defineModel();
const onUpdate = () =&gt; {
    text2.value = '子组件修改';
};

const onBack = () =&gt; {
    emit('onBack', { text: '子组件返回' });
};

const event1 = () =&gt; {
    console.log('子组件内事件');
};

defineExpose({ event1 });
&lt;/script&gt;</code></pre><hr/><p>参考文档：<br/><a href="https://link.segmentfault.com/?enc=2mEsoFSBVgoEhD1fU9QKYw%3D%3D.nFB9K4uOYxcUBEGjRYaS8ADd7D3WEd4wUN%2BMug0IvQ20EaIn%2B8RnkoXGLaGCEq1x0Ilhvbc2BIqlkX3a%2FiRZpeWFgfs55S4Pp2eGbC5T7ZNZznenfOeaUQobaYeUUZKq" rel="nofollow" target="_blank">微信小程序分包异步化</a><br/><a href="https://link.segmentfault.com/?enc=vdmpuQlRG4GoAv8idyN8Uw%3D%3D.MXy6HIE94n2ZA%2B17TBm9ZKzMuA51W9gXi3ayapVVs8De4LDwI7zp08FAK4leSHLp5KYNgee4tOKnB7rGPg0zPKGs4RZqugFgd%2BbYBGn%2B1tPUKxBKY02euggS7M3YQoaMVbfRRzOvYnC%2FCoqVEhZS7stfZCBT8cNIyRRg7luDhdRaPysZnuRdn7bbY0ZMylQ9nsz9HmGaTmdaZPWXkDXxpQ%3D%3D" rel="nofollow" target="_blank">如何使用分包异步化能力？</a><br/><a href="https://link.segmentfault.com/?enc=BQCivvqjgiZ1%2BUzXcN7Ecg%3D%3D.fNwS3PiqEsvHWvBfvpkZa8Tqk8s6lGb0SSM%2BR8yKwoWFGzIcIuyC6lB84rX9YL6JVIPjk81s9Ii203adT7FsjQ%3D%3D" rel="nofollow" target="_blank">uniapp微信小程序之分包异步化</a></p>]]></description></item><item>    <title><![CDATA[架构火花｜产品经理和程序员谁会先被AI淘]]></title>    <link>https://segmentfault.com/a/1190000047403832</link>    <guid>https://segmentfault.com/a/1190000047403832</guid>    <pubDate>2025-11-17 10:05:58</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>引言</h2><p>在科技飞速发展的当下，AI 浪潮汹涌来袭，对各个行业都产生了巨大冲击。其中，产品经理和程序员这两个互联网领域的核心岗位，也面临着挑战：  <br/>当 AI 能自动生成需求文档，当 codebuddy 能一键完成代码补全——这些曾让无数人艳羡的互联网“黄金职位”，正迎来前所未有的生存拷问。  </p><p>10月22日，腾讯云架构师合肥同盟一场火药味十足的讨论，直指核心： 产品经理和程序员，谁会成为AI浪潮下的“第一张淘汰牌”？ 是产品经理更危险？还是程序员更易被替代？本文根据合肥同盟社群讨论内容整理。</p><h2><strong>谁先被淘汰？</strong></h2><p><strong>产品经理危机论</strong>  </p><p>一些成员认为，目前程序员负责将用户或产品需求转化为代码需求，未来充满变数，但产品经理危机更大，可能以后的程序员就做产品的活了。AI 或许能解决 80%的问题，而负责剩下 20%关键问题的人将变得极为值钱。同时，有人大胆预测，未来将不再有程序员、产品、测试、运维的严格区分，全栈人才会留下，非全栈者可能被淘汰。  </p><p><strong>产品经理崛起说</strong>  </p><p>与之相反，也有成员认为未来将是产品经理的天下。AI 可以辅助实现全栈，但产品经理首先要具备产品思维、架构思维、运营思维和测试思维。例如，谷歌的 Gemini 就适合产品经理出 demo，为产品构思提供便利。</p><h2><strong>来自程序员的吐槽：产品经理的困境与挑战</strong></h2><p><strong>产品思维缺失</strong>  </p><p>很多产品经理存在诸多问题。有成员吐槽天天被领导教育要有产品思维，却发现部分产品经理自身缺乏这种思维，还经常提出伪需求。而且，不少产品经理远离客户，只在家闭门造车创造需求，导致产品与市场脱节。  </p><p>在实际工作中，当然也存在一些无奈情况，比如明知道产品经理存在问题，却 battle 不过，自己的 idea 没有资源支持，影响产品经理排期还会背锅，这种情况下只能选择离开或者沉默。  </p><p>技术转产品可行吗？  </p><p>技术转产品是否更有市场？答案是当然，如果知道产品经理的工作内容和方式，了解用户需求和痛点，并且有兴趣，就可以尝试转型。否则，和随波逐流的研发没有区别。做产品并非易事，需要广阔的视野，考虑诸多方面，还要说服他人，实际上也是很困难的工作。</p><h2><strong>AI 时代下的工作逻辑转变</strong></h2><p><strong>产品经理的新要求</strong>  </p><p>AI 时代来临，产品经理要把想法表达得更彻底，同时考虑 AI 实现的代价，争取快速试错的机会。例如，国外一些公司客户提 POC 需求，能临时构建环境给销售，工作方法已经发生了改变。过去一致性的传递是挑战，如今在 AI 时代，一些基础挑战已不成立，需要重新确立工作逻辑。  </p><p><strong>如果 AI 全链路参与，还需要coding的过程吗？</strong>  </p><p>5 - 10 年内软件工程是否会彻底消失？有成员认为虽然不会消失，但执行路径会缩短，中间状态可能看不到。就像高级语言最终要进入机器语言空间一样，现在 AI 正在拉齐各种组织团队，实践优秀的软件工程。  </p><p>coding 或许不再核心？即使在非 AI 时代，编码也被认为是相对不难的体力劳动，同搬砖无异。有成员认为理想情况下，产品把 PRD 甩给大模型，系统自动开发测试部署，未来若发展成开源生态，每家中小企业只需留下几个工具维护者和产品经理。不过，这需要一个工程化阶段，中间可能会产生其他职业和流程。当下当然还不行，但 5 年后也许是有可能的，但是这次革命和以往不同，应该不会产生新的职业，负责工具维护的人同时具备产品经理和程序员的能力，可以一个人搞定。而现有工作方式会彻底改变，大模型带来的改变意味着“更低的门槛”；也有成员认为不会那么极端，最后可能it部门需要几位AI tool keeper+产品经理，就是一种介于产品和coding中间人的角色，取决于成本，换言之，技术岗位会消失，因为没有门槛，界定技术岗位的方式就是专业门槛，技术可以让 【AI运营】来做。  </p><p><strong>目前AI 在公司的实际应用</strong>  </p><p>有成员提问在公司目前使用 AI 的情况如何？不少成员反映：实际上，AI 的应用十分广泛，从 coding 到生产系统优化提效，再到营收转化，都发挥着重要作用。对于 AI 能否写业务代码，新项目是可以的，但老项目由于存在“屎山代码”（即结构混乱、难以维护的代码），AI 难以处理。新项目若一直用 AI 写代码，还需要准备一套提示词。而且，“屎山”不会被用于训练 AI，遇到“屎山”接口，至今也没人敢轻易改动。</p><h2><strong>结语</strong></h2><p>AI 时代，产品经理和程序员都面临着巨大的变革与挑战。无论是岗位的存亡，还是工作方式的转变，都让我们深刻认识到，只有紧跟时代步伐，不断学习和适应，才能在这场浪潮中站稳脚跟。未来究竟会如何发展，让我们拭目以待。</p>]]></description></item><item>    <title><![CDATA[25-26年规范型十项项目管理软件，让流]]></title>    <link>https://segmentfault.com/a/1190000047404100</link>    <guid>https://segmentfault.com/a/1190000047404100</guid>    <pubDate>2025-11-17 10:04:58</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <blockquote>在数字化转型进入深水区的今天，项目管理软件早已从“可选工具”变为“战略刚需”。然而，面对市场上百舸争流的格局——既有Jira、Asana等国际巨头的技术积淀，也有飞书、钉钉等平台型产品的生态优势，更有鼎捷、明源云等垂直领域厂商的行业深耕，CIO们的选型困境愈发突出：<strong>如何在数据安全、功能适配、成本可控的三重约束下，找到真正匹配企业战略的“长期伙伴”？</strong></blockquote><p>作为长期追踪项目管理赛道的行业分析师，笔者认为：当前市场的核心矛盾已从“功能有无”转向“价值适配”。尤其对于政企、军工、金融、制造等对数据主权和合规性要求严苛的行业，“一刀切选公有云”或“盲目追国产替代”都可能偏离实际需求。本文将基于<strong>十大关键评估维度</strong>，对国内的十款典型产品展开客观分析，为决策者提供可落地的选型框架。</p><h2>一、建立标准：十款项目管理软件的评估维度</h2><p>为避免陷入“参数堆砌”的无效对比，我们提炼出<strong>五大核心评估维度</strong>，覆盖安全、适配、成本、扩展四大决策重心：</p><table><thead><tr><th><strong>评估维度</strong></th><th><strong>核心关注点</strong></th></tr></thead><tbody><tr><td>数据主权与可控性</td><td>数据存储位置（本地/云端）、跨境流动限制、用户对数据的绝对管理权</td></tr><tr><td>国产信创适配度</td><td>对国产芯片（龙芯/兆芯）、操作系统（统信/UOS）、数据库（达梦/人大金仓）的兼容能力</td></tr><tr><td>部署灵活性与成本</td><td>支持部署方式（公有云/SaaS/私有化）、初始投入（License/定制开发）、后期运维成本</td></tr><tr><td>系统集成与扩展能力</td><td>与OA、ERP、CRM等企业现有系统的对接能力，以及二次开发/插件生态的开放性</td></tr><tr><td>行业适配性与合规性</td><td>针对特定行业（如军工的保密要求、金融的审计追踪）的功能定制与合规认证</td></tr></tbody></table><h2>二、十款产品客观分析：从公有云到私有化的差异化路径</h2><p>基于上述维度，我们筛选十款市场关注度高的项目管理软件，逐一拆解其核心特征与适用场景：</p><h3>1. 禅道（私有化/混合部署）</h3><p><strong>定位</strong>：专注研发与项目管理的“全生命周期轻量级平台”。  <br/><strong>核心优势</strong>：</p><ul><li>数据主权：支持完全私有化部署，数据100%留存本地，符合《数据安全法》要求；</li><li>信创适配：已完成与龙芯、统信UOS、达梦数据库等20+信创组件的兼容认证，在军工、政府领域落地超300家客户；</li><li>功能聚焦：覆盖需求-研发-测试-发布全流程，内置敏捷、瀑布、看板等8种管理模式，避免“大而全”导致的冗余；</li><li><p>成本可控：按用户数订阅（约800-1500元/人/年），低于国际厂商30%-50%，且二次开发接口开放，降低长期绑定风险。  <br/><strong>适用场景</strong>：对数据安全敏感、需全流程管控的中大型制造、军工、金融企业。  <br/><img width="723" height="357" referrerpolicy="no-referrer" src="/img/bVdl902" alt="" title=""/></p><h3>2. Jira Align（公有云/私有化）</h3><p><strong>定位</strong>：企业级敏捷规划与DevOps协同平台（Atlassian旗下）。  <br/><strong>核心优势</strong>：</p></li><li>全球化能力：支持多语言、多区域团队协作，海外分支机构管理友好；</li><li>生态强大：与Confluence、Bitbucket等工具深度集成，适合技术驱动型企业；  <br/><strong>局限性</strong>：</li><li>数据存储默认在海外（国内需通过合作伙伴落地，合规性需额外验证）；</li><li><p>定制成本高：复杂需求需二次开发，周期长且费用昂贵（单项目定制常超百万）。  <br/><strong>适用场景</strong>：跨国科技企业、已深度使用Atlassian生态的技术团队。  <br/><img width="723" height="357" referrerpolicy="no-referrer" src="/img/bVdl909" alt="" title="" loading="lazy"/></p><h3>3. 飞书多维表格（公有云SaaS）</h3><p><strong>定位</strong>：字节跳动旗下的“轻量化协作+项目管理”工具。  <br/><strong>核心优势</strong>：</p></li><li>集成度高：无缝对接飞书IM、日历、视频会议，适合互联网、创意类团队的日常协作；</li><li>低门槛：可视化配置，业务人员可快速上手，初期推广成本低；  <br/><strong>局限性</strong>：</li><li>深度管理弱：缺乏复杂项目的WBS分解、资源冲突检测等功能，难以支撑研发类复杂项目；</li><li><p>数据控制权：虽支持本地部署（需定制），但默认SaaS模式下数据由字节管理，金融、政府客户需谨慎。  <br/><strong>适用场景</strong>：中小互联网团队、需高频跨部门协作但对流程深度要求不高的企业。  <br/><img width="723" height="357" referrerpolicy="no-referrer" src="/img/bVdmc6j" alt="" title="" loading="lazy"/></p><h3>4. 鼎捷E10（私有化）</h3><p><strong>定位</strong>：制造业垂直领域的项目管理解决方案。  <br/><strong>核心优势</strong>：</p></li><li>行业深度：内置MES、PLM接口，贴合离散制造的BOM管理、生产排期需求；</li><li>信创适配：与用友U8、金蝶KIS等财务系统兼容，适合制造业全链路数字化。  <br/><strong>局限性</strong>：</li><li>通用性不足：非制造行业（如金融、咨询）的功能适配性较弱；</li><li><p>界面交互偏传统：年轻团队可能需要适应期。  <br/><strong>适用场景</strong>：离散制造、装备制造企业的生产-项目一体化管理。  <br/><img width="723" height="357" referrerpolicy="no-referrer" src="/img/bVdmGRH" alt="" title="" loading="lazy"/></p><h3>5. Asana（公有云SaaS）</h3><p><strong>定位</strong>：全球中小团队的“任务管理轻平台”。  <br/><strong>核心优势</strong>：</p></li><li>简洁高效：以任务看板、时间线为核心，无复杂配置，适合初创团队快速启动；</li><li>全球化支持：内置多时区、多货币功能，海外项目协作友好。  <br/><strong>局限性</strong>：</li><li>缺乏深度：无需求跟踪矩阵、成本核算等中大型项目所需功能；</li><li><p>国内访问延迟：公有云服务器部署在海外，部分企业需额外购买加速服务。  <br/><strong>适用场景</strong>：初创团队、海外业务为主的中小微企业。  <br/><img width="723" height="357" referrerpolicy="no-referrer" src="/img/bVdmc6i" alt="" title="" loading="lazy"/></p><h3>6. 泛微OA项目管理模块（私有化）</h3><p><strong>定位</strong>：OA厂商延伸的“流程+项目”一体化平台。  <br/><strong>核心优势</strong>：</p></li><li>流程融合：与泛微OA的审批、文档管理深度打通，适合强流程驱动的企业；</li><li>定制灵活：支持低代码平台自定义字段、流程，适配集团型企业的个性化需求。  <br/><strong>局限性</strong>：</li><li>项目管理专业性弱：相比禅道等产品，缺乏研发过程管理的专业模块（如缺陷跟踪、测试用例管理）；</li><li><p>成本较高：需采购OA基础License，整体投入高于专业项目管理工具。  <br/><strong>适用场景</strong>：集团型企业、需强流程管控（如国企、事业单位）的组织。  <br/><img width="723" height="356" referrerpolicy="no-referrer" src="/img/bVdmPEG" alt="" title="" loading="lazy"/></p><h3>7. 蓝凌PM（私有化）</h3><p><strong>定位</strong>：知识管理与项目管理融合的平台。  <br/><strong>核心优势</strong>：</p></li><li>知识沉淀：项目过程中自动生成经验库、风险库，适合需要积累组织过程资产的企业；</li><li>信创适配：与蓝凌自身的低代码平台集成，支持快速定制。  <br/><strong>局限性</strong>：</li><li>功能侧重偏管理：对研发过程的细节把控（如迭代燃尽图、资源负载）不如禅道深入；</li><li><p>生态开放性一般：第三方系统对接需通过蓝凌中间件，灵活性受限。  <br/><strong>适用场景</strong>：咨询、设计类企业，或重视知识管理的大型集团。  <br/><img width="723" height="357" referrerpolicy="no-referrer" src="/img/bVdmYY2" alt="" title="" loading="lazy"/></p><h3>8. 明源云天际PM（私有化）</h3><p><strong>定位</strong>：房地产与建筑工程行业的垂直项目管理工具。  <br/><strong>核心优势</strong>：</p></li><li>行业适配：内置工程进度管理、成本管控、供应商协同模块，贴合地产项目的全周期需求；</li><li>政策响应快：针对房地产“保交付”等政策，提供专项监控看板。  <br/><strong>局限性</strong>：</li><li>行业壁垒明显：非地产领域（如制造、金融）功能冗余度高；</li><li><p>定制依赖厂商：复杂需求需明源云团队支持，响应周期较长。  <br/><strong>适用场景</strong>：房地产开发、建筑工程企业的项目全周期管理。  <br/><img width="723" height="357" referrerpolicy="no-referrer" src="/img/bVdmNWn" alt="" title="" loading="lazy"/></p><h3>9. 金蝶云·星空项目管理（私有化）</h3><p><strong>定位</strong>：财务-项目一体化的ERP延伸工具。  <br/><strong>核心优势</strong>：</p></li><li>业财融合：项目成本、收入自动同步至金蝶财务系统，适合对财务合规要求高的企业；</li><li>部署成熟：依托金蝶云基础设施，运维稳定性有保障。  <br/><strong>局限性</strong>：</li><li>项目管理颗粒度粗：缺乏敏捷开发、需求跟踪等研发类项目管理功能；</li><li><p>界面偏向财务视角：技术团队使用体验可能打折扣。  <br/><strong>适用场景</strong>：工程服务、IT外包等需严格业财核对的企业。  <br/><img width="723" height="356" referrerpolicy="no-referrer" src="/img/bVdmWLt" alt="" title="" loading="lazy"/></p><h3>10. 用友BIP项目管理（私有化）</h3><p><strong>定位</strong>：集团型企业的一体化管控平台。  <br/><strong>核心优势</strong>：</p></li><li>集团管控：支持多组织、多项目的资源池管理，适合多元化集团；</li><li>数据看板：提供跨项目的全局视图，辅助高层决策。  <br/><strong>局限性</strong>：</li><li>灵活性不足：标准化程度高，中小型团队的个性化需求难以满足；</li><li>学习成本高：功能模块多，需较长时间培训才能熟练使用。  <br/><strong>适用场景</strong>：央企、地方国企等集团型组织的跨板块项目管理。  <br/><img width="723" height="356" referrerpolicy="no-referrer" src="/img/bVdmWLu" alt="" title="" loading="lazy"/></li></ul><h2>三、清晰引导：为何“禅道路径”是政企行业的最优解？</h2><p>综合评估维度与行业需求，我们发现：<strong>对于政企、军工、金融、制造等对数据安全、国产适配、流程深度有要求的行业，禅道代表的“私有化、轻量级、强安全、强管理”路径具备显著优势</strong>：</p><ol><li><strong>数据安全底线更牢</strong>：完全私有化部署，数据不出域，符合《网络安全法》《个人信息保护法》要求，规避跨境数据流动风险；</li><li><strong>信创适配更彻底</strong>：已完成20+信创组件兼容认证，在国产化替代浪潮中无需二次改造，降低迁移成本；</li><li><strong>功能与成本更平衡</strong>：相比国际厂商，功能聚焦项目管理全流程，避免冗余；相比垂直行业工具，通用性更强，适配多场景；</li><li><strong>扩展与定制更灵活</strong>：开放API接口，支持低代码定制，既能满足当前需求，也能随企业发展平滑升级。</li></ol><h2>结语：选型不是选“最好”，而是选“最适合”</h2><p>项目管理软件的选型，本质是企业战略与工具能力的匹配游戏。公有云工具胜在敏捷协作，私有化工具强在安全可控，垂直行业工具精于场景适配——没有绝对的优劣，只有是否契合需求。对于追求数据主权、国产适配、长期可控的决策者而言，禅道等“私有化+轻量级”产品，或许正是穿越“嘈杂选择”的关键锚点。</p><h3>FAQ：关于项目管理软件选型的五大高频问题</h3><p><strong>Q1：中小企业是否适合私有化部署？成本会不会太高？</strong>  <br/>A：中小企业可根据规模灵活选择。禅道提供“基础版+按需扩展”的订阅模式（约800元/人/年起），初期投入低于传统定制开发；若团队规模小于50人，也可考虑SaaS模式（需评估数据安全要求）。私有化并非“大企业专属”，关键是匹配自身数据敏感程度。  </p><p><strong>Q2：禅道与鼎捷、明源云等垂直行业工具的核心差异是什么？</strong>  <br/>A：鼎捷、明源云更侧重“行业场景深度”（如制造的MES对接、地产的成本管控），而禅道是“项目管理全流程通用平台”，覆盖需求、研发、测试、交付全环节。若企业需要跨行业的通用项目管理能力，禅道更合适；若需求集中在单一行业（如制造），可考虑垂直工具。  </p><p><strong>Q3：公有云SaaS（如飞书多维表格）是否真的无法满足政企需求？</strong>  <br/>A：部分政企可通过“本地部署+定制”使用SaaS工具的公有云版本，但需额外投入合规成本（如数据加密、审计日志）。相比之下，禅道等原生私有化产品从设计之初就符合信创要求，长期运维更省心。  </p><p><strong>Q4：禅道的信创适配具体覆盖哪些厂商？</strong>  <br/>A：目前已完成与龙芯3A5000/3C5000、兆芯开先KX-6000系列、统信UOS V20、麒麟OS V10、达梦数据库DM8、人大金仓KingbaseES V8等20+核心信创组件的兼容认证，在党政、军工领域有大量落地案例。  </p><p><strong>Q5：如果企业已有OA系统，禅道的集成能力如何？</strong>  <br/>A：禅道提供RESTful API、Webhook、LDAP等标准接口，可与OA（如泛微、致远）、ERP（如金蝶、用友）、CRM（如销售易）等系统深度对接。某制造客户曾通过禅道API实现“项目进度-生产排期-财务核算”的全自动流转，效率提升40%。</p>]]></description></item><item>    <title><![CDATA[工业超级智能体怎么解决制造业的AI落地难]]></title>    <link>https://segmentfault.com/a/1190000047404109</link>    <guid>https://segmentfault.com/a/1190000047404109</guid>    <pubDate>2025-11-17 10:04:11</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>工业超级智能体是人工智能与工业制造深度融合后形成的新型智能系统，它不仅仅是传统自动化工具的升级版，更是将AI技术内化为企业的核心生产力，实现从数据采集、分析到决策执行的全链路闭环。作为制造业智能化转型的关键引擎，工业超级智能体通过模拟人类专家的思维模式，结合工业知识图谱和多模态大模型，解决了AI在工业场景中的割裂问题，推动企业从“经验驱动”迈向“认知驱动”。<br/>为什么工业超级智能体如此重要？制造业正经历从数字化到智能化的跃迁，传统方法如ERP系统或SCADA系统虽能处理部分流程，但无法应对AI时代的动态需求。例如，汽车制造涉及上万个零部件和上千家供应商，需精确控制工艺参数和实时响应市场变化。如果没有超级智能体，企业可能在排产、质检或供应链中断时依赖人工干预，导致效率低下和成本上升。广域铭岛的实践案例显示，其工业智造超级智能体矩阵通过高效数据标准化和知识封装，显著提升了问题解决能力。在一家新能源电池企业中，超级智能体帮助优化生产参数，使缺陷率下降了30%，同时将生产周期缩短了20%。这种变革不仅解决了数据私有化和知识复用难题，还为企业注入了新的增长动能。</p><h4>工业超级智能体怎么做的？</h4><p>核心在于构建一个覆盖全链路的智能体网络，采用模块化设计和持续迭代机制。广域铭岛的Geega工业AI应用平台是典型代表，它整合了工业数据标准、闭环知识系统和定制化智能体开发，形成“开箱即用”的解决方案。具体来说，平台首先标准化工业数据，打破信息壁垒，例如在某汽车制造厂中，通过统一数据格式，智能体能在1分钟内响应插单需求，将传统6小时的排产压缩到1小时内。其次，知识封装与还原能力将企业经验转化为可调用模块，如质量检测智能体基于SHAP可解释模型，实时分析生产数据，将问题定位时间从2小时缩短到5分钟。最后，智能体开发采用“积木式”架构，企业可以根据自身场景快速部署，比如仓储智能体监控库存异常，减少缺件风险60%，并提升供应商交付稳定性。<br/>总之，工业超级智能体的出现标志着制造业从“流程主导”向“AI原生”时代的转变。它不仅提升了企业的运营效率，还通过跨部门协同和自主决策，解决了传统AI应用的痛点。未来，随着技术的不断演进，工业超级智能体会从局部优化扩展到系统级智能，助力中国制造业在全球竞争中脱颖而出。</p><h4>工业超级智能体怎么帮助车企实现智能化生产？</h4><p>在汽车制造业的智能化转型中，工业超级智能体扮演着“数字厂长”的角色，通过将AI技术与全链路业务场景结合，解决生产效率、质量控制和供应链响应等核心问题。怎么帮助车企实现这一点？首先，超级智能体通过高效数据标准化和知识封装，将复杂的工艺参数转化为可执行的智能决策，从而提升生产自动化水平。例如，广域铭岛的Geega工业AI平台支持车企快速部署智能体，如排产助手能在1小时内完成传统6小时的排产任务，节省了大量工程师时间。<br/>具体来说，超级智能体的应用包括感知型、决策型和执行型三个层次。在感知层，它实时采集生产线数据，如设备振动频率或物料流动信息，确保生产过程透明化。在决策层，它基于大模型分析数据，生成优化方案，例如在一家整车厂中，质量归因智能体通过可解释模型，定位缺陷模式，将问题排查时间从小时级压缩到分钟级。在执行层，它协调资源，如仓储智能体监控库存，减少缺件风险，并动态调整采购策略。<br/>这些能力使车企能应对行业动态需求，如新能源车型迭代周期缩短至12个月。超级智能体的模块化设计允许车企定制功能模块，例如工艺优化智能体生成SOP参数，提升新车型量产效率，某车企通过此应用缩短了30%的研发周期。同时，它支持跨工厂协同，如通过区块链技术调配产能，确保全球供应稳定。<br/>总之，工业超级智能体通过“感知-决策-执行”的闭环机制，为车企注入了智能化血液，帮助其从局部自动化迈向全链路智慧生产。</p><h4>工业超级智能体在实际应用中有哪些成功案例？</h4><p>工业超级智能体作为一种创新的AI解决方案，在多个行业落地后取得了显著成效，这些案例不仅展示了其技术实力，还验证了其在推动制造业升级中的实际价值。例如，在汽车制造领域，广域铭岛的超级智能体帮助某主机厂将排产周期从6小时压缩到1小时，节省了每周15小时的人力成本，并提升了生产计划达成率。另一个案例是新能源电池企业，通过智能体优化工艺参数，缺陷率下降了22%，产能利用率提高了18%。<br/>在供应链管理中，超级智能体的协同能力尤为突出。当物流中断时，它能在5分钟内整合数据，生成应急方案，某车企应用后，供应链响应时间缩短了40%。质量检测场景也受益匪浅，智能体通过实时分析数据，将问题定位效率提升了5倍，一家电池生产商实现了质量缺陷根因分析的自动化。<br/>这些成功源于超级智能体的核心技术：高效的工业数据标准、闭环知识封装与还原，以及“量体裁衣”式开发。通过这些机制，企业能快速适应AI驱动的变革，实现降本增效。总之，工业超级智能体的应用案例证明了其作为新型生产力的强大潜力，为行业提供了可复制的范式。</p>]]></description></item><item>    <title><![CDATA[架构派 | 专访长沙同盟理事长李颖悟：技]]></title>    <link>https://segmentfault.com/a/1190000047404114</link>    <guid>https://segmentfault.com/a/1190000047404114</guid>    <pubDate>2025-11-17 10:03:13</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>2025年9月，腾讯云架构师技术同盟与湖南展通人工智能研究院院长、颖悟智能科技董事长、腾讯云架构师长沙同盟理事长李颖悟进行了一次深度对话，以下是采访文字实录。为了您的阅读体验，我们做了不变原意的编辑。</p><p><img width="723" height="576" referrerpolicy="no-referrer" src="/img/bVdm38D" alt="image.png" title="image.png"/></p><p><strong>Q： 李老师好，非常感谢您抽出宝贵时间来到我们架构派栏目。请您向我们同盟的伙伴们简单介绍下自己的职业生涯。</strong></p><p><strong>李颖悟：</strong>  大家好，我是李颖悟，很高兴能来到架构派栏目和大家交流。我 1995 年从北京理工大学毕业后，当了 2 年大学教师，然后考入桂林电子科技大学拿到计算机应用硕士学位后入职华为。在华为的 17 年里，我历任项目经理、开发部经理、装备架构与设计部部长、产品工程技术规划部部长等职。</p><p>2017 年，我作为长沙市引进的第一批高层次人才回湘创业，首先进入智慧零售赛道，带领团队打造了全国首家无人零售店。后来，又主持开发了区块链防伪溯源系统和智慧零售大数据平台。2019年以来，主要从事人工智能、垂类大模型、区块链、分布式存储、大数据和元宇宙等数智化技术研发与应用，以及企业数智化转型、数字乡村、元宇宙和行业大模型的战略规划、顶层设计、项目实施、IT建设和持续运营等。</p><p><strong>Q： 您曾经在华为做过 17 年的技术高管，2017 年却选择放弃百万年薪回湘创业，当时到底是什么驱使您跳出舒适圈，做出这样的抉择？又是什么动力促使您回到家乡？是否有一个瞬间您会觉得：“是时候必须这样做。”</strong></p><p><strong>李颖悟：</strong> 我当时选择回湘创业，主要有以下几方面原因：</p><ol><li>寻求新挑战与个人发展。在华为工作的 17 年里，我虽然取得了一定的成绩，工作上也比较顺利，却总觉人生还不完美，还想要做一些自己想做的、喜欢的事，希望挑战一些更有兴趣的事业。</li><li>想要抓住行业发展机遇。2017 年，中国迎来创新创业的热潮，我看到了新一代信息技术的巨大潜力和发展前景，所以毅然投身其中。</li><li>家乡政策吸引了我。2017 年，“长沙人才新政 22 条” 发布，这一政策吸引了我的注意力，让我开始考虑回家乡发展。长沙移动互联网产业的快速发展也为我提供了良好的创业环境。</li></ol><p>除了上述的政策吸引和行业机遇外，还有对家乡的深厚感情。我是湖南人，家乡的发展一直是我所关注的，我希望能够利用自己的技术和经验，为家乡的发展做出一些贡献。  </p><p><strong>Q：前十七年的大厂积累为您现在的成就做出了怎样的铺垫？您可以举个例子和我们讲讲吗？</strong></p><p><strong>李颖悟：</strong> 在华为 17 年积累，为我这些年的工作奠定了坚实基础。</p><p>在华为期间，我参与攻克了多项技术瓶颈，获得 30 多项国家发明专利，还荣获华为个人金牌一等奖，这培养了我的技术研发能力和创新精神。也形成了高效的工作习惯，不论多晚收到信息，我都会在第一时间回复。此外，“以客户为中心、以奋斗者为本、敢于自我批判” 的企业文化也深入骨髓，这对我这些年的创业和工作理念产生了深远影响。</p><p>例如，2017 年我回湘创业，带领团队打造全国首家无人零售店时，就运用了在华为积累的技术研发与项目管理经验。我利用原本应用在实验室仪器管理和智能仓储管理中的无线射频标签技术，给商品打上独一无二的标签，实现了商品的防伪和溯源，同时提高了门店人工、仓库管理、拣货配送等方面的效率。这一成果的取得，离不开我在华为期间对各种技术的深入研究和对项目的管理能力。</p><p><strong>Q：在创业的过程中您碰过壁吗？有没有想过放弃？是如何坚持下来的？</strong></p><p><strong>李颖悟：</strong> 创业的过程并非一帆风顺，我碰过不少壁。就拿我进入智慧零售赛道打造无人零售店来说，起初我们对市场需求的判断存在偏差。尽管我们实现的无人零售在技术层面有诸多优势，结算速度快、效率高，还能利用无线射频标签技术实现商品防伪溯源，但我们忽略了消费者对于购物人情味的需求。中国人习惯了有人值守的小卖部那种交流氛围，导致无人便利店在经历新鲜期后逐渐走入低谷。</p><p>我经历过非常艰难的时刻，但从未想过放弃。支撑我坚持下来的，一方面是对技术创新的热爱与执着。我坚信技术的力量，不断寻找新的技术突破的方向。另一方面，过往在华为积累的 “以客户为中心、以奋斗者为本、敢于自我批判” 理念深入我心。面对困境，我不断反思，调整策略。比如从智慧零售转向企业数智化转型赛道，就是基于对市场的重新研判。我始终相信，只要保持积极的心态，持续创新和调整，就一定能在创业道路上继续前行，实现自己的价值 。</p><p><strong>Q： 从创业最初的智慧零售赛道到转战数字化转型赛道，您经历了很多，这个过程中心态最大的转变是什么？</strong></p><p><strong>李颖悟：</strong> 起初投身智慧零售，满是开拓新领域的激情与冲劲，坚信技术优势能迅速打开市场，引领行业变革，那时候更多聚焦技术创新与模式搭建，对市场反馈预估相对乐观。像打造无人零售店时，一心想着用先进技术提升效率、优化体验，却未充分考量消费者情感需求等复杂因素。</p><p>遭遇挫折后，转向企业数字化转型赛道，心态变得更加沉稳务实。我深刻认识到，不能仅从技术视角出发，更要全方位洞察市场动态、客户痛点。现在，我会更耐心地深入企业，倾听他们在管理、运营各环节的实际难题，依据需求定制方案，而非盲目将技术强行嵌入。同时，也学会坦然面对不确定性，不再因短期困难而焦虑，明白转型之路本就漫长，需持续积累、逐步突破。比如在为企业构建数智化系统时，从规划到落地见效往往需要较长周期，过程中会遇到各种阻力，但我能以更平和坚定的心态去应对，凭借经验和专业知识稳步推进，力求真正助力企业实现转型升级 。</p><p><strong>Q： 从 C 端零售转向 B 端企业数字化赋能，是什么原因导致您做了这种选择？您觉得未来国内企业数字化前景如何？</strong></p><p><strong>李颖悟：</strong> 从 C 端零售转向 B 端企业数字化赋能，主要基于几方面原因。在 C 端智慧零售实践中，我察觉到单纯依靠技术革新，难以完全契合消费者复杂的情感需求，市场反馈给我敲响警钟，让我重新审视赛道。而此时，国内企业数字化转型浪潮正兴起，众多企业，尤其是中小企业，在激烈市场竞争下，面临生产成本上升、创新能力不足等难题，急需数字化手段突破困境。这是巨大的市场机遇，我在技术研发、项目管理等方面积累的经验，恰能助力企业解决实际问题，实现降本增效与创新发展，所以毅然投身其中。</p><p>我十分看好未来国内企业数字化前景。国家层面高度重视，密集出台系列政策，为企业数字化转型营造稳定环境、指明方向。从数据来看，据 IDC 预测，2028 年中国数字化转型支出规模预计达 7330 亿美元，全球占比约 16.7%，五年复合增长率约 15.6%，增速高于全球整体。当下，越来越多企业也意识到数字化转型的紧迫性与重要性，正积极加大投入。可以预见，未来国内企业将借助数字化实现全方位变革，在提升运营效率、创新商业模式、增强市场竞争力等方面取得显著成效，推动整体经济高质量发展。</p><p><strong>Q：作为45项专利的发明人并一直在创新一线战斗着，我们非常好奇您保持这种创新精神的动力是什么？这些灵感又来自于哪里？是解决问题中迸发出的火花还是日常生活中一闪而过的启示？</strong></p><p><strong>李颖悟：</strong> 作为 45 项专利的发明人，能一直在创新一线坚持，对我而言，创新动力是多方面的。内心深处，对未知的强烈好奇是根本。从学生时代起，这份好奇就驱使我不断突破知识边界，去探寻事物背后的原理。工作后，每一个技术难题、业务痛点，都像是一场充满挑战的冒险，激励我寻找创新解法。</p><p>在华为的 17 年，公司每年超 10% 收入投入研发的创新氛围深深感染着我。当市场竞争激烈时，那种必须依靠自身摸索创新方向的紧迫感，转化为我持续创新的动力。如今创业的市场竞争的压力、对企业发展的责任，更是时刻提醒我，唯有创新才能让企业在激烈竞争中脱颖而出。</p><p>灵感来源同样多元。解决问题时，当传统方法难以突破，我会从不同视角思考，过往积累的知识、经验相互碰撞，创新火花往往就此迸发。</p><p><strong>Q：您是《元宇宙未来》、《数字乡村》、《一本书读懂NFT》等多本技术图书的创作者，创作和出版的过程中遇到的最大的阻力是什么？您又是怎么克服的呢？</strong></p><p><strong>李颖悟：</strong> 主要在内容创作上，如何把专业知识以通俗易懂、深入浅出的方式呈现，让不同知识层次读者都能理解吸收，是一大挑战。像元宇宙、NFT 这些新兴概念，本身就比较抽象，既要保证内容准确权威，又要兼顾趣味性和可读性，需要反复打磨。</p><p>在内容创作上，我尝试多种表达方式，结合生活实例、行业案例解释技术原理，让文字更生动。比如在讲解元宇宙时，以人们熟悉的虚拟游戏场景引入，让读者快速理解其概念。同时，积极与同行和同事们交流，听取反馈意见，不断优化内容。</p><p><strong>Q： 您认为对于传统企业，数字化转型的最大难点是什么，又有什么经验可以分享给我们同盟的伙伴们？</strong></p><p><strong>李颖悟：</strong> 对于传统企业而言，数字化转型最大的难点主要集中在以下几方面。其一，战略规划与认知不足。不少传统企业对数字化转型理解仅停留在表面，未将其上升到战略高度，缺乏清晰转型路径，导致投资分散、方向不明。其二，组织架构与文化阻碍。传统企业层级式组织架构使部门协同困难、决策流程长，难以适应数字化时代快速响应需求。同时，企业内部因循守旧文化，也让员工对新事物接受度低，抵触转型变革。其三，人才短缺与技术难题。数字化转型需要既懂业务又掌握前沿技术复合型人才，这类人才在传统企业中极度匮乏。</p><p>基于我的经验，传统企业要想成功转型，首先，企业一把手必须高度重视，亲自参与制定数字化战略，将数字化转型融入企业整体发展目标，自上而下推进。其次，逐步调整组织架构，建立跨部门数字化转型小组，打破部门壁垒，促进信息流通与协同合作。同时，大力培养和引进数字化人才。最后，在技术层面，不要盲目追求新技术，应结合企业实际情况，选择成熟且可扩展技术方案，分阶段、分模块进行系统升级和改造，稳步实现数字化转型 。</p><p>Q：技术行业是日新月异的行业。近年来，AI 等新兴技术破土而出，产生了巨大的影响；从业的二十余年，您看到过各种各样的技术变迁，您认为技术行业中有没有一个万变不离其宗的核心逻辑？</p><p>李颖悟：在技术行业摸爬滚打二十余载，我见证过诸多技术变迁，从早期基础技术的稳步发展，到如今 AI 等新兴技术的强势崛起，虽说技术在不断革新，但其中确实存在一个万变不离其宗的核心逻辑，那便是  <strong>“解决实际问题，满足用户需求”</strong>  。</p><p>回顾过往，在华为时，我们投入大量精力攻克技术难题，这背后的动力就是要解决企业在产品研发、性能提升等实际业务中的问题，从而更好地满足客户对于产品功能、质量的需求，助力企业在市场竞争中脱颖而出。</p><p>如今在企业数智化转型领域，为企业构建安全生产专业数据库，开发人工智能私有大模型，是为了满足企业提升安全生产管理效率、降低事故风险的迫切需求，同时也帮助政府监管部门强化监管能力。这一系列实践都表明，无论技术如何日新月异，只要抓住 “解决实际问题，满足用户需求” 这一核心，就能在技术浪潮中找准方向，创造出真正有价值的成果，推动行业乃至社会的进步 。</p><p><strong>Q：您在长沙的技术领域里有着极高的影响力与号召力，您是如何去构建自己的技术影响力的？对于新时代想要增加自己的影响力的技术人，您有什么建议？</strong></p><p><strong>李颖悟：</strong> 在长沙技术领域，我确实有非常多的朋友，而且朋友们也非常认可我，我想主要是几个方面。首先是专注技术深耕与创新。我在华为积累了 17 年的技术研发经验，这是我的根基。然后，我又一直在学习，持续钻研新技术，物联网、区块链、分布式存储、NFT、元宇宙、大数据、人工智能、安全生产数智化等，我一直在用创新技术解决实际难题，通过实际成果赢得行业认可。</p><p>其次，积极投身行业交流与知识分享。我撰写《元宇宙未来》《数字乡村》《一本书读懂NFT》等多本技术图书，将复杂专业知识系统化输出。同时，利用线上线下渠道，参与技术论坛、举办讲座，分享前沿技术与实践经验，和同行深度交流。我现在基本上每年都有上百场演讲和培训，再加上书籍编写和文章撰写，通过知识输出影响了大量的听众和读者。</p><p>再者，致力于推动行业协作与人才培养。作为长沙市政协委员、湖南省展通人工智能研究院院长，我积极为行业发展建言献策，推动政策支持与产业协同。同时注重培养团队，营造创新氛围，让更多技术人才成长，为行业注入新生力量 。</p><p>对于新时代想增加影响力的技术人，我建议：一是持续学习，紧跟技术趋势，不断拓宽知识边界，在擅长领域深入钻研，形成独特技术优势。二是重视输出，通过撰写技术文章或编写专著、分享经验、参与开源项目等，把知识与成果展示给同行，在交流中提升知名度。三是锻炼沟通演讲能力，积极参与行业活动并发言，清晰表达观点，展现专业素养与自信，逐步扩大影响力。</p><p><strong>Q：随着层出不穷的新技术爆发，您觉得新时代的技术从业者和之前有哪些不同，您认为现在的技术环境和技术人诉求又有哪些新的升级？</strong></p><p><strong>李颖悟：</strong> 新时代的技术从业者和我们当年相比，确实有诸多不同。如今新技术爆发式涌现，特别是 AI 浪潮，极大改变了技术生态。以前我们更多靠人力完成基础编码、测试等工作，现在大量重复性任务被自动化工具取代，像CodeBuddy等AI编程工具能依据自然语言描述生成代码片段，智能测试工具可自动生成测试用例，这让从业者从繁琐劳动中解脱，得以将精力投入到更具创造性、挑战性的工作，比如系统架构设计、业务逻辑创新等。 当下的技术环境，变化速度堪称指数级增长。新的模型、框架、算法不断迭代，从业者必须时刻保持学习状态，才能跟上步伐。而且，跨领域融合趋势愈发明显，比如机器学习工程师需要补充认知心理学知识，云计算专家要掌握环境科学原理。这就要求新时代技术人拥有更广阔知识视野，不能仅局限在单一技术领域。 从技术人诉求来看，也有了新升级。过去大家可能更关注技术能力提升，现在则渴望在复杂多变技术环境中找准职业定位，在技术革新浪潮下保障自身职业发展。例如，不少从业者担忧 AI 会替代自己岗位，因而更看重提升不可替代能力，像创新思维、复杂问题解决能力以及领域专业知识与经验等。同时，他们也希望能在工作中充分发挥自身创造力，借助新技术实现更大价值，而非仅成为技术的执行者。总之，新时代技术从业者机遇与挑战并存，需不断适应变化，满足新环境下的诉求，才能在行业中站稳脚跟 。</p><p><strong>Q： 您是一个非常乐于提携后辈的人，这一点从技术社区中很多人写博客时会真诚地提到您的名字可以看出来。您感觉这样做最大的意义和价值是什么？</strong></p><p><strong>李颖悟：</strong> 谢谢朋友们的认可。对我而言，帮助他人是一个非常有意义的事情。</p><p>技术行业发展迅猛，新人面临海量知识与复杂挑战，我希望凭借自身经验做些指引，这样可以少走一些弯路。回想我初入职场，在技术探索之路上，也得到过前辈的指引，这让我少走了很多弯路。如今，我也想将这份温暖传递下去，让后辈在成长途中少些迷茫与无助，这是对行业传承的一份责任 。</p><p>从另一个角度看，帮助后辈成长，能让我接触到更多新思想、新视角。年轻人思维活跃，在交流过程中，他们独特的见解常能启发我，促使我突破固有思维局限，在技术创新上有新的突破。就像在探讨一些新兴技术应用时，他们天马行空的想法，为我打开新思路，助力我在工作中不断进步 。</p><p>而且，看到后辈在我的帮助下取得成绩，那种成就感难以言表。当他们攻克技术难题、完成项目任务，甚至在行业崭露头角，我会由衷为他们高兴，这也是我持续投入精力提携后辈的动力源泉。我期望通过自己的努力，在行业内营造互帮互助氛围，让更多技术人才脱颖而出，共同推动技术行业蓬勃发展 。</p><p><strong>Q： 您感觉长沙现在的技术生态怎么样，和北京上海这样的超一线城市比还有哪些差距？长沙的开发者们都有哪些特点呢？</strong></p><p><strong>李颖悟：</strong> 长沙当下的技术生态正蓬勃发展，充满活力与潜力。截至 2023 年底，长沙开发者注册人数增长至 47 万，较 3 年前翻了一倍多，这反映出技术人才的大量涌入与聚集。在产业方面，作为湖南软件产业主核，长沙汇聚了全省 80% 以上的软件企业。不过，与北京、上海这样的超一线城市相比，长沙仍存在一定差距。在高端创新人才集聚上，北京、上海凭借顶尖高校云集、国际化资源丰富等优势，吸引全球高端人才汇聚，长沙在这方面相对薄弱。从基础研究投入强度看，超一线城市科研资金充足，大型科研项目与国家级实验室众多，能支撑长期、高投入的基础研究，长沙在资金投入规模与持续性上有待提升。关键核心技术自主可控方面，北京、上海在前沿技术研发，如芯片、人工智能底层算法等领域布局更早、成果更多，长沙部分关键技术还依赖外部，对产业发展形成一定制约。 长沙的开发者们有着鲜明特点。一方面，他们具备较强的实干精神，像在打造本地一些创新应用场景时，能脚踏实地将技术落地，解决实际问题。另一方面，长沙开发者富有创新热情，积极拥抱新技术，在人工智能、大数据分析等新兴领域不断探索实践，为本地技术创新注入活力。</p><p><strong>Q： 腾讯云架构师长沙同盟建立至今，您作为理事长已经组织举办了多次沙龙活动，您感觉这几次沙龙中成员们都有怎样的收获？未来您对长沙同盟的建设愿景是什么？</strong></p><p><strong>李颖悟：</strong> 自腾讯云架构师长沙同盟建立，我已经组织了5次技术沙龙活动，欣喜地看到成员们收获颇丰。在 AI 主题沙龙里，通过解读前沿趋势报告，大家明晰了全球 AI 发展走向，理解 AI 时代对长沙技术人的核心启示在于聚焦场景深度、释放本地价值，找到了低成本创新与开放协作的关键行动路径，还看到开拓新兴市场的机会。</p><p>在 AI 应用出海技术领航沙龙中，成员们深入剖析了全球 AI 市场潜力与出海面临的技术适配、文化差异、政策法规等挑战，了解了海外资源对接策略与合规要求，为企业出海决策提供有力支撑。通过开放探讨，大家碰撞思想，在交流中拓宽思路 。</p><p>作为腾讯云架构师长沙同盟的理事长，我对长沙同盟的未来充满期待，长沙同盟的建设愿景，我概括为以下几点：</p><p><strong>一、立足长沙，成为“技术应用的推动者和实践者”</strong></p><p>在数字化转型的浪潮中，长沙作为中部地区的经济与科技新高地，拥有庞大的技术应用市场和独特的产业优势。我们看到，长沙有超过4万家科技型中小企业，制造业上云率领先全国，更在“三智一芯”和七大支柱产业上形成了鲜明特色。因此，我坚信我们同盟的定位不应是纯技术研究，而应成为“技术应用的推动者和实践者”，聚焦云计算如何真正赋能企业转型，为长沙的数字经济发展贡献我们的专业力量。</p><p><strong>二、重新定义架构师的角色：我们是桥梁，而不仅是专家</strong></p><p>在我看来，现代的架构师必须超越技术本身。我们既要保持对AI等前沿技术的深度理解，更要深刻理解业务，具备商业敏感度和沟通协调能力。我希望通过我们同盟，引导每一位成员完成从“技术专家”到“技术商业桥梁”的转变。我们不能只沉迷于技术先进性，更要思考如何将复杂技术转化为企业能感知到的实际业务价值，这正是我们服务于长沙5000亿数字经济总量的关键。</p><p><strong>三、打破圈层，促进最广泛的交流与碰撞</strong></p><p>我始终认为，架构师如果只待在技术圈子里，就无法真正洞察市场的需求。因此，我鼓励我们同盟要大力推动跨行业交流、与企业业务决策者直接对话，并共同研讨产业政策与市场趋势。我们将积极融入本地的数据要素生态，与各方伙伴合作。只有这样，我们才能获得更广阔的视野，激发更多创新的解决方案。</p><p><strong>四、激发每一位理事的能动性，共建我们的组织</strong></p><p>一个组织的活力来源于每一位成员。作为理事长，我将致力于推动理事会明确分工、定期议事，并建立有效的贡献认可机制。我们会推行活动轮值主持制度，让每位理事都能在自己擅长的领域发挥价值，共同决策同盟的发展。我相信，依靠我们13位理事和全体成员的集体智慧，一定能将同盟建设得充满凝聚力与创造力。</p><p><strong>五、坚持线下见面，建立深度连接</strong></p><p>尽管线上交流很方便，但我坚信线下活动无可替代。面对面的交流才能建立深厚的信任，才能进行最深入的技术讨论和跨界启发。因此，我们将坚持每月至少举办一次线下活动，无论是技术沙龙、企业参访还是案例研讨，目的都是打造一个真正属于长沙架构师的深度交流圈子和共同成长的家园。</p><p><strong>六、构建让每个人都能收获价值的成长体系</strong></p><p>最后，也是最重要的，我希望我们同盟是一个能让每位成员都获得成长和回报的平台。无论是会员的技术提升、理事的项目合作机会，还是腾讯云的生态建设，我们都将规划清晰的成长路径。我的目标是让每一位参与者都能在这里找到自己的方向，实现个人价值，并共同为湖南省“智赋万企”和长沙“强省会”战略贡献我们的智慧和力量。</p><p>这就是我们的愿景：<strong>扎根长沙，聚焦应用，携手共进，用架构师的专业力量助推家乡产业的数智化飞跃。</strong></p>]]></description></item><item>    <title><![CDATA[MIAOYUN | 每周AI新鲜事儿（1]]></title>    <link>https://segmentfault.com/a/1190000047404116</link>    <guid>https://segmentfault.com/a/1190000047404116</guid>    <pubDate>2025-11-17 10:02:20</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>本周全球AI领域迎来一系列重要发布与突破。OpenAI推出更智能的GPT-5.1系列，百度发布2.4万亿参数的文心5.0，Google、字节跳动、阶跃星辰、商汤科技、微博、小红书等也相继推出新模型。技术及工具层面，TypeScript成为GitHub最常用语言，Meta开源支持超1600种语言的语音识别套件，百度推出新一代AI引擎及芯片等。这些突破推动AI在多模态理解、内容生成等方向持续进化，一起来回顾本周发生的AI新鲜事儿吧！</p><h2><strong>AI 大模型</strong></h2><p><strong>华中科大等提出首个大规模水下多模态模型「NAUTILUS」</strong></p><p>11月7日消息，华中科技大学和国防科技大学研究团队近期联合推出首个水下多模态大模型「NAUTILUS」，并构建了首个大规模水下多任务指令微调数据集「NautData」，包含145万个图像-文本对，全面支持八种不同的水下场景理解任务。「NAUTILUS」通过视觉特征增强（VFE）模块有效解决了水下图像模糊和颜色失真问题，超越了现有模型，尤其在低光、浑浊等恶劣环境下表现更为优异。该模型实现了对粗粒度和细粒度目标的分类、计数、视觉问答、检测等多项任务的统一理解，为水下大模型的发展和评测奠定了基础。</p><p><strong>OpenAI发布「GPT- 5 Codex mini」轻量化模型</strong></p><p>11月8日，OpenAI上线了「GPT- 5 Codex mini」，一款转为低成本、高效率代码生成设计的轻量模型。该模型适用于简单软件工程任务或主模型调用量接近上限时的无缝切换，系统将在使用量达90%阈值时自动推荐启用，避免服务中断。同时，ChatGPT Plus、Business及Edu用户的速率限制提升50%，Pro与Enterprise用户享有优先处理权，响应更迅捷。  </p><p><strong>阶跃星辰发布全球首个开源 LLM 级音频编辑大模型「Step-Audio-EditX」</strong></p><p>11月10日，阶跃星辰发布全球首个开源 LLM 级音频编辑大模型「Step-Audio-EditX」，能够通过语言指令或迭代方式，精准控制音频的情感、说话风格和副语言特征，并实现零样本文本转语音（Zero-Shot TTS）。该模型采用统一LLM框架和“双码本”音频分词器，支持零样本文本转语音、迭代式编辑和中英双语及多方言；模型约3B参数，单卡32 GB GPU即可运行（提供Int8量化版），采用大边际合成数据训练，情感与风格控制准确率优于闭源模型。</p><p><strong>Google爆火的「Nano Banana 2」限时上架1小时引热议</strong></p><p>11月10日，Google爆火的「Nano Banana 2」限时上架1小时引热议。该预览版在图像生成方面表现出色，生成速度达到10秒，支持原生2K和4K分辨率。该版本可以在黑板上推导微积分，增强了文本渲染和信息图表能力，展现出更高的人物生成一致性。网友们对其在角色生成和手写体识别上的表现感到惊讶，认为其效果几乎无法与真人区分。</p><p><strong>商汤科技发布并开源「SenseNova-SI」系列空间智能大模型</strong></p><p>11月10日，商汤科技正式发布并开源「SenseNova-SI」系列空间智能大模型，包含2B和8B两个规格，其中8B版本在空间智能四个基本评测试中平均成绩60.99，领先「GPT-5」等模型。该系列模型采用系统化的方法扩充空间理解数据的规模，首次在空间智能领域验证了“尺度效应”，使其在空间智能六大核心维度（空间测量、空间重构、空间关系、视角转换、空间形变与空间推理）上实现一致性能力提升。此外，还同步开源了空间智能测评平台「EASI」与「英雄榜」，将补强具身智能在三维结构认知方面的基础能力。</p><p><strong>小红书推出具有智能体特性的多模态模型「DeepEyesV2」</strong></p><p>11月11日消息，小红书近期推出的「DeepEyesV2」模型，是其多模态模型的增强版，具有更强的工具协同能力。该模型不仅能够进行视觉推理，还能执行代码、进行网页搜索和处理图像，通过多工具协同，从“会看细节”进化为“能主动解决复杂问题的智能体”。该模型的训练分为两个阶段，首先是通过高质量数据集进行冷启动，然后通过强化学习来优化工具使用策略，在RealX-Bench基准测试中表现优异。</p><p><strong>百度推出新一代多模态思考模型「ERNIE-4.5-VL-28B-A3B-Thinking」</strong></p><p>11月11日，百度推出新一代多模态思考模型「ERNIE-4.5-VL-28B-A3B-Thinking」，仅3B激活参数，兼具高效计算与灵活响应优势。模型具备领先的文档与图表理解能力，在理科与文科综合推理、通用视觉推理等任务中表现优异，展现出更强的跨模态推理与问题解决能力。同时，结合空间定位与工具调用，推出“图像思考”等创新功能，为多模态思维与交互应用带来更丰富的可能。</p><p><strong>火山引擎正式发布豆包编程模型「Doubao-Seed-Code」</strong></p><p>11月11日，火山引擎正式发布豆包编程模型「Doubao-Seed-Code」，专为Agentic编程任务深度优化，在SWE-Bench-Verified官方榜单中刷新SOTA，更兼容Anthropic API、TRAE等主流开发环境。该模型支持256K长上下文，是首个支持视觉理解能力的编程模型，首月低至9.9元，是目前国内性价比最高的AI编程工具。</p><p><strong>AI语音公司ElevenLabs发布实时语音转文本模型「Scribe v2 Realtime」</strong></p><p>11月12日，AI语音独角兽公司ElevenLabs发布了实时语音转文本模型「Scribe v2 Realtime」，实现150毫秒的超低延迟和93.5%的高准确率，支持90多种语言。该模型该模型能够在复杂环境下高效工作，并适应多种音频格式，在FLEURS基准测试中针对前30种常用语言准确率达93.5%，能精准识别方言、专业术语，甚至辨别笑声类型。</p><p><strong>OpenAI正式发布「GPT-5.1」系列模型，不仅聪明更有人情味</strong></p><p>11月13日，OpenAI正式发布「GPT-5.1」系列新模型，包含「GPT-5.1 Instant」和「GPT-5.1 Thinking」两个版本，OpenAI 表示出色的AI不仅要聪明，还要让人与之对话变得愉悦，本次升级在智能和沟通风格上都有了显著提升，尤其是指令遵循和自适应思考的改进。「GPT-5.1 Instant」是ChatGPT最常用的模型，更温暖、更智能，也更善于遵循指令的模型。「GPT-5.1 Thinking」是高级推理模型，在简单任务上更快，在复杂任务上更持久，也更容易理解。</p><p><strong>李飞飞联合创立的WorldLabs公司正式发布3D世界生成模型「Marble」</strong></p><p>11月13日，由李飞飞联合创立的WorldLabs公司正式推出其首款商业化“世界模型”产品「Marble」，支持用户通过文本提示词、照片、视频、3D布局图或全景图生成可编辑、可下载的3D环境。「Marble」首创AI原生编辑工具可对生成世界进行局部替换和结构调整，Chisel功能实现结构与风格分离，同一框架可生成不同风格场景。定价方面提供4档订阅方案，免费版本支持4次生成，旗舰版最高一个月95美元，可以生成75个世界。</p><p><strong>新浪微博发布「VibeThinker-1.5B」模型超越近万亿参数模型</strong></p><p>11月13日，新浪微博发布并开源「VibeThinker-1.5B」模型，仅有15亿参数、训练成本不足8000美元的小模型，在AIME25等顶级数学竞赛基准上击败了参数量是其数百倍的、近万亿参数的「DeepSeek-R1」（6710亿参数）。该模型采用创新的频谱到信号原则（SSP），将SFT和RL两阶段的目标解耦，SFT阶段追求多样性（Pass@K），RL阶段追求准确性（Pass@1）；整个训练过程在H800 GPU花费不到8000美元，成本效益比达到30到60倍。</p><p><strong>百度正式发布「文心5.0」，2.4万亿参数原生全模态模型</strong></p><p>11月13日，在2025百度世界大会上，百度正式发布「文心5.0」大模型，采用原生全模态统一建模技术，具备全模态理解与生成能力，支持文本、图像、音频、视频等多种信息的输入与输出，在LMArena文本排行榜得分1432表现出色。模型参数量达2.4万亿，超稀疏激活参数设计激活比例低于3%，已上线文心一言网页版、文心App及百度千帆平台提供API服务。</p><h2><strong>技术突破</strong></h2><p><strong>字节跳动推出全新视频生成框架「InfinityStar」</strong></p><p>11月9日，字节跳动推出全新视频生成框架「InfinityStar」，基于时空金字塔架构创新性地解耦视频的空间外观与时间运动信息，将一段5秒720p高清视频的生成时间，从主流扩散模型的30多分钟，压缩到了58秒。并且用一套统一的框架，支持图像生成、文本生成视频、图像生成视频、视频续写等多样化的任务。</p><p><strong>清华大学、东北大学和OpenBMB等机构联合推出「UltraRAG2.1」</strong></p><p>11月11日，清华大学THUNLP实验室、东北大学NEUIR实验室和OpenBMB等机构联合推出「UltraRAG2.1」，是首个基于 Model Context Protocol (MCP) 架构设计的RAG框架。研究者只需通过编写YAML文件，即可声明串行、循环与条件分支等逻辑，以极低代码量构建多阶段推理与检索生成系统。本次新版本围绕“原生多模态支持、知识接入与语料构建自动化、统一构建与评估的RAG工作流”三大方向进行核心增强。</p><p><strong>「TypeScript」首次成为GitHub上使用最广泛的语言</strong></p><p>11月12日消息，据GitHub《Octoverse 2025》报告显示，「TypeScript」以约4.2万名贡献者优势，首次超越Python，成为GitHub上使用最广泛的语言。「TypeScript」在2025年的贡献者数量增长了超过100万（同比增长 66%），主要驱动力来自默认使用TypeScript的开发框架和AI辅助开发。不过报告也指出Python在AI和数据科学领域仍然保持着主导地位，拥有260万贡献者（同比增长 48%）；Jupyter Notebook 依旧是AI领域的首选探索性环境（相关仓库约40.3万个）。</p><h2><strong>AI 工具</strong></h2><p><strong>xAI旗下Grok近期更新，升级「Grok 4 Fast」和「Grok Imagine」</strong></p><p>11月8日，xAI旗下Grok家族一天之内连迎两大更新：升级「Grok 4 Fast」和「Grok Imagine」生成。「Grok 4 Fast」把上下文窗口提高到2M，并把完成率从77.5%拉到94.1%（推理）与97.9%（非推理），还加了锁屏小部件。「Grok Imagine」升级到真假难辨的程度，上线纯文本生成视频能力，用户只需输入一句话描述，即可在平均17秒内生成6至15秒、带背景音效的高质量短视频，无需任何图像素材或剪辑经验。</p><p><strong>美团正式发布AI IDE编程工具「Meituan CatPaw」</strong></p><p>11月10日，美团正式发布AI IDE编程工具「Meituan CatPaw」，以Agent &amp;人协作为核心，通过Agent智能驱动编程，辅以代码补全、智能问答、项目预览调试等功能，结合美团自研的基于编程场景特训的LongCat模型，并支持多种模型混合调用，让编码过程更专注，项目交付更高效。该工具支持Python、C++、Java、JavaScript、TypeScript、Go、Rust等主流语言，目前开放公测并免费提供新用户500次对话额度（需申请邀请码体验）。</p><p><strong>Meta开源最强语音识别模型套件「Omnilingual ASR」</strong></p><p>11月11日，Meta AI FAIR团队发布并开源了其在自动语音识别（ASR）领域的最新成果：「Omnilingual ASR」语音识别模型套件，能为超过1600种语言提供自动语音识别能力，78%语言字符错误率低于10%。该框架采用社区驱动设计，用户仅需提供少量样本即可将模型扩展到新语言，首次实现大规模ASR框架的上下文学习能力。同时开源的还有「Omnilingual ASR Corpus」（包含350种服务欠缺语言的数据集）、「Omnilingual wav2vec 2.0」（70亿参数的大规模多语言语音表征模型）和语言探索Demo（可供人们探索模型所覆盖语言的演示）。</p><p><strong>百度智能云发布全新一代昆仑芯及基于昆仑芯的超节点产品天池</strong></p><p>11月13日，百度智能云正式发布全新一代昆仑芯及基于昆仑芯的超节点产品天池，并公布未来五年按年推出新产品的规划。全新一代昆仑芯包括两款产品，其中「昆仑芯 M100」针对大规模推理场景优化设计，提供极致性价比，将于2026年上市。「昆仑芯M300」面向超大规模的多模态模型的训练和推理任务，提供极致性能，预计2027年上市。基于昆仑芯的「天池256」与「天池512」超节点产品，相比上一代，「天池256 超节点」的卡间互联带宽提升4倍、整体性能提升50%；「天池512超节点」在此基础上进一步跃升，单个超节点即可支撑万亿参数模型训练；两款产品将于明年正式上市。</p><p><strong>百度正式推出发布「百度猎户座AI引擎」</strong></p><p>11月13日，百度正式发布「百度猎户座AI引擎」，整合其25年积累的搜索技术与前沿AI能力，打造面向企业与开发者的全栈式AI服务平台。该引擎融合搜索AI API、MCP多模态计算平台及行业专属能力，显著降低AI应用门槛。开发者可快速调用智能客服、内容生成、数据分析等功能模块，大幅缩短产品开发周期。</p>]]></description></item><item>    <title><![CDATA[AI 时代，架构师如何破局成长？腾讯云架]]></title>    <link>https://segmentfault.com/a/1190000047404135</link>    <guid>https://segmentfault.com/a/1190000047404135</guid>    <pubDate>2025-11-17 10:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>引言</h2><p>技术浪潮奔涌向前，变革已成为不变的主题。在 AI 时代，架构师的角色也正在被重新定义，他们不仅是技术的践行者，更是系统与未来的构建者。面对日益复杂的业务场景与层出不穷的新技术，架构师如何破局，实现技能升级与AI思维重塑？</p><p>8 月 16 日，由腾讯云架构师技术同盟和腾讯云 TVP 联合主办的「腾讯云架构师技术沙龙——架构未来，圳在出发」在深圳成功举办。与会专家们从多维视角深入分享了 AI 与架构的技术发展趋势、前沿 AI 应用与落地实践、人机协同工作模式，以及架构师个人成长进阶等热门议题。在会上，腾讯云架构师深圳同盟正式扬帆起航，旨在为深圳地区的架构师群体搭建一个专业、开放的交流学习平台。</p><h2><strong>腾讯云架构师深圳同盟正式成立</strong></h2><p>2024 年 12 月，腾讯云发起并成立了腾讯云架构师技术同盟，作为面向架构领域专家与从业者的专业社交平台，同盟汇聚众多架构专家，共同推动技术的创新与发展。  </p><p>腾讯云架构师技术同盟副秘书长 李佳忆表示，2025 年，腾讯云正式启动地区同盟的建设工作，目前已先后在北京、上海、长沙、深圳、合肥五地成立地区同盟，有效促进了地区架构师之间的技术交流。深圳作为全国重要的科技创新中心，具备雄厚的技术基础。腾讯云期望通过建立深圳同盟，打造全国首屈一指的技术生态圈。  </p><p>未来，深圳同盟将通过多元化活动，助力架构师群体实现深度交流与全方位成长。在线下，同盟将开展多样的技术交流会议，搭建开放、专业的沟通桥梁，拓展架构师技术社交圈；在线上，腾讯云开发者社区开设了“腾讯云架构师同盟交流圈”，提供海量优质的学习资源，建设垂直化技术社群，邀请行业专家在线答疑，全面助力架构师拓宽视野、进阶成长，共同推动技术创新与生态繁荣。  </p><p><img width="723" height="488" referrerpolicy="no-referrer" src="/img/bVdm38Q" alt="image.png" title="image.png"/></p><p>腾讯云架构师技术同盟副秘书长 李佳忆</p><p>会上，腾讯云架构师深圳同盟理事会也集中登场，深圳同盟理事会由 11 位资深架构师和行业技术领袖组成。现场举行了授勋仪式，李佳忆与腾讯云架构师技术同盟社群管理主席 揭光发为到场的深圳同盟理事颁发聘书，以表彰他们对深圳同盟和当地技术生态的大力支持与积极贡献。  </p><p><img width="723" height="406" referrerpolicy="no-referrer" src="/img/bVdm38R" alt="image.png" title="image.png" loading="lazy"/></p><p>腾讯云架构师深圳同盟理事会</p><p><img width="723" height="460" referrerpolicy="no-referrer" src="/img/bVdm38S" alt="image.png" title="image.png" loading="lazy"/></p><p>授勋仪式</p><p>数焰科技 CEO、腾讯云架构师深圳同盟理事长 钱勇在致辞中表示，腾讯云架构师深圳同盟的成立，离不开各方的共同努力。本次沙龙作为深圳同盟的首场活动，标志着同盟迈出坚实、笃定、富有诚意的第一步。未来，深圳同盟将点燃技术火焰，为中国技术发展构筑坚实的交流平台。作为理事长，他将服务好每一位架构师，积极组织各类线上线下活动，助力每一位技术人发光发热。作为技术交流平台，腾讯云架构师深圳同盟欢迎广大架构师积极参与，分享架构经验，将碎片化知识系统化输出，在学习与交流中实现自我成长。  </p><p><img width="723" height="488" referrerpolicy="no-referrer" src="/img/bVdm38U" alt="image.png" title="image.png" loading="lazy"/></p><p>数焰科技 CEO、腾讯云架构师深圳同盟理事长 钱勇</p><h2><strong>从 Vibe Coding 到 Vibe Working：AI 领导力重塑 “创造心流”</strong></h2><p>腾讯技术专家、腾讯云架构师技术同盟社群管理主席 揭光发带来《从 Vibe Coding 到 Vibe Working ：AI 领导力重塑 “创造心流”》的主题演讲。  </p><p><img width="723" height="488" referrerpolicy="no-referrer" src="/img/bVdm38T" alt="image.png" title="image.png" loading="lazy"/></p><p>腾讯云架构师技术同盟社群管理主席 揭光发</p><p>他提出，Vibe Coding 的本质是开发者通过自然语言进行交互：专注于方案构想，将代码实现交付 AI，从而重获编程心流状态。他个人已实现接近 100% 的 AI 辅助编码，其团队的整体 AI 代码占比也达到了 50%。Vibe Coding 不仅提升了开发效率，也让他有更多时间关注技术基建和产品开发落地。揭光发进一步分析，Vibe Coding 的技术基础是“软件工程3.0”，即基于大语言模型的智能体系统，以自然语言为接口，让 AI 能够理解人们的意图并自主执行任务。AI 协作不仅适用于编码，还可扩展到写作、数据分析、设计、研究等知识工作领域，即“ Vibe Working ”。他强调 Vibe Working 的本质上是一种高效的人机协同工作状态，其核心是让人从重复性劳动中解放，专注于高价值的创造性思考。  </p><p>关于开发者如何与 AI 协同工作，揭光发提出“ AI 领导力”的概念，并将其核心归纳为四大要素：知人善任，即了解不同 AI 工具的优缺点，根据任务特性选择最合适的工具；目标清晰，即设定具体目标并下达明确指令，为 AI 提供精准的“靶心”；过程管理，即在 AI 执行过程中，通过设定、引导等方式确保 AI 不偏离方向；结果验收，即具备审查和筛选 AI 产出的专业能力。  </p><p>AI 浪潮席卷下，IT 行业格局正迎来重新洗牌。揭光发预测，未来 IT 人才结构将形成“两极分化”局面，一端由少量顶尖专业人士协同 AI 来完成复杂架构设计、创新突破等工作，另一端则是由大量非专业人士借助 AI 工具来实现中小规模需求。因此，他建议开发者应积极拥抱变化，适应 AI 时代的工作范式转变，持续学习，在工作中尝试使用 Vibe Working 方法，多分享多交流，在人机协同中释放创造力。</p><h2><strong>百果园的 AI 实践</strong></h2><p>百果科技轮值 CEO、腾讯云架构师深圳同盟理事 姚杨分享了《百果园的 AI 实践》，不仅总结了百果园在信息化和数字化建设方面的心得，还详细地介绍了技术助力实体企业实现价值提升的具体案例。  </p><p><img width="723" height="488" referrerpolicy="no-referrer" src="/img/bVdm38V" alt="image.png" title="image.png" loading="lazy"/></p><p>百果科技轮值 CEO、深圳同盟理事 姚杨</p><p>百果园拥有 6000 家连锁门店，3 万名员工，管理协同是一大挑战。为应对这一难题，百果园科技团队通过 5 年时间打造出信息化与数字化体系，同时构建企业互联网中台架构，支撑百果园从新零售一体化向产业互联网化演进。团队还打造了一体化管理系统，实现从种植、采购、质检到仓储配送及线上线下销售的全产业链覆盖，并持续探索 AI 前沿应用，在数据预测、线路规划、图像分析识别与大模型内容生成等方面推进落地，以提升产业链各环节的效能。  </p><p>百果园构建"一横一纵"双平台体系：零售数智化平台驱动门店运营，供应链智能化平台优化全链条周转。零售数智化平台融合商品、渠道与客户模型，实现 AI 智能化运营管理；供应链智能化平台则借助 AI 技术提升全链路商品与库存周转效率。百果园将相关经验集成于统一平台，清晰呈现信息流、决策流与作业流，实现全场景、全角色的“三流合一”，从而高效推进零售智能化与供应链数字化落地。  </p><p>姚杨分享了具体的 AI 应用案例：AI 销冠“小鹿”通过抓取并整合多渠道数据，显著提升了营销文案的质量，可辅助店员与客户沟通，让群消息回复率提升 5 倍，线上转化率提升 2.8 倍。目前，“小鹿”已获得门店的广泛认可，正助力实现“人人都是销冠”的目标。此外，AI 巡检系统依托摄像头自动识别业务事项并发出预警，实时监测门店操作规范，一旦发现问题，系统将及时推送预警，有效保障食品安全和服务质量。</p><h2><strong>系统架构现代化与架构师技能 “现代化”</strong></h2><p>vivo 互联网技术总监、腾讯云架构师深圳同盟理事 杨振涛带来《系统架构现代化与架构师技能 “现代化”》的分享 。</p><p><img width="723" height="488" referrerpolicy="no-referrer" src="/img/bVdm38W" alt="image.png" title="image.png" loading="lazy"/></p><p>vivo 互联网技术总监 杨振涛</p><p>杨振涛从系统架构现代化谈起，指出其本质是对现有架构的升级与优化，提升系统的性能、可扩展性与灵活性，从而适应持续演进的技术与不断变化的业务需求。他通过四种演进曲线解析架构进化规律，包括匀速迭代、瀑布跃进、曲线发展和波动变化，并指出这些变化往往源于业务需求迭代、战略调整及技术认知升级。杨振涛由此提出，所有软件系统及其架构始终处于进化态、转化态或终结态之中。  </p><p>随着系统架构的持续进化，架构师的核心工作目标也日益明确：让系统更高效、更敏捷、更安全，同时提升开发者的使用体验。那么在工作中，架构师如何评估系统架构的现代化成效？对此，杨振涛建议可参考云厂商的卓越架构框架及相关评估指数，以此作为衡量架构质量的依据，例如：腾讯云顾问卓越架构指数评估。他还推荐使用“架构决策日志”记录关键决策，进行架构知识管理。随着企业业务需求的发展，架构随之迭代，因此他建议企业在 IT 资源分配中为架构治理预留合理的投入，确保技术演进与业务发展同步。  </p><p>系统架构技术在进化，架构师也需保持自身技能的“现代化”。在实际工作中，架构师不仅需要对系统及架构有深刻认知，还应持续保持理论与实践的双螺旋提升。面对云原生、AI、开源等技术趋势，架构师应积极拥抱变化，保持乐观心态，主动学习，洞察技术本质，把握变化中的“不变”。面对职业发展的挑战与机遇，架构师需提升技术影响力与软技能。在技术影响力方面，杨振涛建议将技术能力转化为可衡量的业务成果，并通过写作、演讲、开源、课程等擅长的方向，逐步打造个人代表作品，建立行业影响力。在软技能方面，他建议大家可参与国际社区，拓展视野，培养系统思维，回归本质学习理论，通过不断实践获取新知，积极与优秀者同行。此外，坚持阅读、运动与社交，通过持续学习、健康生活和拓展人脉，这些将有助于实现更长远的职业发展。</p><h2><strong>代码智能化发展和落地实践</strong></h2><p>在腾讯云 CodeBuddy 算法专家 陈浩坤《代码智能化发展与落地实践》的演讲中，分享代码智能化的发展以及腾讯在该领域的落地实践。  </p><p><img width="723" height="488" referrerpolicy="no-referrer" src="/img/bVdm38X" alt="image.png" title="image.png" loading="lazy"/></p><p>腾讯云 CodeBuddy 算法专家 陈浩坤</p><p>陈浩坤回顾了编码智能化的发展历程：2022 年底 ChatGPT 出现，开发者可通过自然语言与 AI 交互来获取解决方案；2023 年到 2024 年上半年，企业不断深化大模型在代码领域的应用，并将 AI 代码助手集成至 IDE；自 2024 年下半年起，随着 Agent 能力的提升，编码智能化迈向 Code Agent 形态，开发者可直接提出需求，让 AI 自动生成代码，显著提升开发效率。当前，智能体正处于从“AI 助手”迈向更智能化、更全栈的“AI 软件工程师”阶段，预计 2027 年有望达到专业的 AI 开发团队高效协作阶段，AI 的角色也将从语法辅助扩展至开发全生命周期。伴随这一演进，陈浩坤观察到独立开发者规模显著扩大、开发范式呈现分化趋势。从用户群体来看，非专业开发者倾向“氛围编程”模式，通过自然语言完成简单的 MVP 应用开发；专业开发者则偏好“规约编程”方式，通过驱动 AI 生成高质量代码，以增强产品竞争力。  </p><p>腾讯在编码智能化领域布局已久：2018 年，腾讯开始尝试第一代语词补全和基于 LSTM 的第二代智能补全技术；2022 年开始布局 AI 代码助手；2023 年，腾讯内部上线私有化版本的代码助手，开启第三代 AI 辅助编程，并在客户侧落地；2024 年，腾讯内部全面推广落地 AI 辅助编程，同时向外部开发者提供相关工具；2025 年，腾讯依托「氛围编程+Agent」技术范式，开创多智能体协同编程的新阶段。  </p><p>目前，腾讯内部应用已取得显著成效：活跃用户占比 90%，AI 生成代码占比 43%，编码时长缩短 40%，人均千行缺陷率降低 30%。腾讯还推出了集产品、设计、研发于一体的 AI 全栈工程师——CodeBuddy IDE，帮助研发团队打通“从需求到上线”的全流程。CodeBuddy 拥有四大智能体，覆盖产品需求、设计生成、代码实现、交付部署四个关键环节。Plan Agent 可将需求结构化，实现创意到方案落地；Design Agent 基于前端 DSL 描述，组件化输出生产级设计稿；Coding Agent 提供工程化支持，为专业开发者提供系列工具；Deploy Agent 提供一键部署能力，简化交付流程。如此一来，CodeBuddy IDE 将原来多角色协作的流程整合起来，加速产品从概念到上线的时间。</p><h2><strong>圆桌对话：AI 时代，架构师破局成长之道</strong></h2><p>圆桌对话作为沙龙的亮点环节，在深圳易拓创新科技有限公司联合创始人、腾讯云架构师深圳同盟理事 王拓的主持下，围绕“AI 时代，架构师破局成长之道”主题，乐凯撒 CTO、腾讯云架构师深圳同盟理事 黄道泳，远行科技副总经理、腾讯云架构师深圳同盟理事 何明璐，腾讯云 CodeBuddy 首席架构师、腾讯云架构师深圳同盟理事 林强，数焰科技 CEO、腾讯云架构师深圳同盟理事长 钱勇从不同角度，分享他们对 AI 时代下架构师成长、进化的思考与建议。<br/><img width="723" height="488" referrerpolicy="no-referrer" src="/img/bVdm38Y" alt="image.png" title="image.png" loading="lazy"/></p><p>主持人王拓从今天的主题谈起，在他看来，架构师群体是孤独的。在普通企业里，架构师可能很难找到共话技术的人选。然而，技术人的成长离不开相互交流学习、启发思考。正因如此，当他看到腾讯云架构师技术同盟的成立，聚集了一群志同道合、热爱技术的探索者，他毅然选择加入，成为其中一员。当王拓观察到台上几位嘉宾均来自不同的企业，却都不约而同地选择成为深圳同盟的理事时，他代表在场与会者抛出了一个问题：  </p><p><strong>问题一：为什么您愿意加入腾讯云架构师技术同盟？ 谈谈您在理事会担任的职责以及未来规划。</strong>  </p><p>黄道泳表示，作为入会成长理事，他希望能成为深圳同盟的“发动机”，未来吸引更多的优秀架构师同行参与进来，共同构建活跃的深圳同盟。  </p><p>何明璐从两方面来回答，一方面，他加入腾讯云架构师技术同盟是为了促进自己学习成长。另一方面，自 2001 年参加工作起，何明璐已拥有 24 年的工作经验沉淀，他想将这些经验和心得体会通过深圳同盟这个平台分享给大家，希望以此帮助更多年轻架构师成长。作为社群管理理事，何明璐负责深圳同盟社群的运营，在未来，他将在同盟社群中分享热点架构资讯、干货技术，未来还将组织专题研讨会等各类活动，促进架构师之间的交流。  </p><p>林强表示，在工作中，他负责研发服务开发者的产品。面对技术发展日新月异，他加入架构师同盟是为了与开发者站得更近，倾听开发者的真实需求。作为品牌发展理事，他将持续提升同盟品牌的技术调性与影响力。  </p><p>钱勇分享加入深圳同盟的三个因素：首先是同盟拥有优质社群，他14年前曾从技术社群中获益良多，也一直坚持回馈社群，因此希望更多架构师能把握机会，加入进来共同交流成长。其次，他曾担任多年 CTO，深知优秀架构师是推动企业业务发展的重要力量。在数字经济时代，架构师将发挥更大的作用，大家更应团结起来共同学习成长。在深圳同盟里，作为理事长，他愿担任“总客服”的角色，及时回应大家在入会、活动与成长中遇到的问题。他表示，未来深圳同盟将搭建多元平台，通过文章、直播、播客、线下活动等不同形式，帮助同盟成员展示自我，交流成长。  </p><p><strong>问题二：AI 时代，大模型已达到中高级别架构师能力，架构师还有哪些核心竞争力？</strong>  </p><p>钱勇表示，面对 AI 的发展，开发者不必过于焦虑。尽管当前 AI 在算法能力上表现强大，但人类大脑历经数亿年进化而来，现代 AI 的发展也只有六七十年。在某些细分领域，AI 确实超越人的能力，大家应理性看待。在他看来，未来的工作模式将是人机协同，因此开发者应积极拥抱 AI 技术，将其作为提升效率的伙伴。  </p><p>黄道泳认为本次 AI 浪潮下，程序员是最大的受益群体之一。开发者通常优先使用新技术来服务自己工作，AI 工具在实际使用中不断迭代升级，反过来又能帮助开发者更快地交付工作成果。尽管 AI 在技术生成和效率提升上表现出色，但对于架构师来说，在实际工作中，不仅只考虑技术的实现，还需综合思考价值判断、商业逻辑、人文关怀、社会责任等技术之外的深层问题，致力于寻求其中的平衡与合适的解决方案。  </p><p><strong>问题三：AI 时代下，架构师能力域会往哪方面演进？架构师的核心价值应侧重架构能力还是业务架构能力？</strong>  </p><p>何明璐表示，架构师需要有三大关键改变：首先，其能力重心从纯技术向业务前移；其次，其思维方式需从内部技术视角转向外部视角；最后，工作重心要从解决问题域前移到问题定义域。  </p><p>林强强调，架构师需回归需求域，理解并定义问题，了解企业系统里各个角色及其运作机制。这些能力对架构师来说至关重要，至少应占据架构师职业发展的 50%。同时，架构师在专业赛道上要做到更深入更专业，例如尝试搜索、推荐等复杂系统的开发工作，而不仅满足于当一位 CRUD 工程师。  </p><p>黄道泳提出，随着 AI 能力的提升，研发门槛正在降低，初中级程序员通过 AI 也能设计出好的技术方案。然而，这可能会导致初级开发者陷入“为技术而技术”的误区，即为了验证新技术就应用新技术，而非聚焦于解决企业的真实业务问题。作为架构师，需深入思考所做工作是否真正解决业务痛点，是否以最低成本、最优路径、最合适的方案来完成？因此，开发者需往业务方向考虑，假如只做单纯的技术执行者可能会被 AI 替代。  </p><p><strong>观点碰撞：企业级项目是否可以采用 Vibe Coding？</strong>  </p><p>在观点 PK 环节，主持人王拓抛出提问“企业级项目是否可以采用 Vibe Coding？”，专家老师组队辩论，正方队伍持“企业级项目如果不用 Vibe Coding 就是与效率为敌，等着被同行甩八条街吧”观点，反方队伍持“企业项目用 Vibe Coding 那是老板心中的乌托邦，是拿客户的钱玩俄罗斯轮盘”观点，展开热烈的讨论，产生诸多前瞻性的思考。  </p><p>正方代表林强表示，这没有绝对的答案。在一些严肃开发场景中，AI 工具的准确率仅在局部达到较高水平。面对一些历史悠久，技术债务沉重的项目，传统方式无法彻底解决遗留问题。然而，随着 DeepSeek 等技术的迅速发展趋势来看，AI 能力不断提升，开发者不能固守现状、刻舟求剑，而应主动拥抱 AI，积极了解其发展动态。  </p><p>反方代表何明璐首先厘清 Vibe Coding（氛围编程）和 Specification-Oriented Coding（规约编程）的区别。他指出，Vibe Coding 是完全代码无感知 Coding——开发者不直接查看或修改代码，即使程序出错，也仅通过自然语言指令让 AI 修正，因此他认为企业里纯粹采用 Vibe Coding 是不现实的。他认为 Vibe Coding 更适合用于产品经理快速搭建交互原型等轻量场景。  </p><p>正方代表黄道泳从架构师的职责出发，强调作为架构师，不能将 AI 生成的内容直接交付。实际工作中，开发者可先利用 AI 快速产出初稿，再由架构师进行二次评估、修正与优化。  </p><p>反方代表钱勇从自身经历谈起，分享其开发财务、人力资源、ERP 等软件的心得体会，由于这些企业系统最重要的是精确计算与确定性，不能出现错误。因此，他认为目前在企业级系统、需要精确计算的软件开发项目，目前仍无法完全使用 Vibe Coding 来完成。不过在一些特殊场景，例如为客户设计 Demo，或者基于标准产品做定制化等场景Vibe Coding 具备实用价值。  </p><p>台上嘉宾老师你来我往，观点交锋不断升温。台下嘉宾嘉立创集团互联网 CTO、腾讯云架构师技术同盟名人堂专家 黄良懿从自身经历分享了他的真实体会，GPT-3.5 时代起，他几乎试遍所有主流 AI 编程工具。他见证了 AI 生成代码从早期的无法正常运行需要反复修改，到如今大部分代码可直接采纳的全过程。和揭光发老师一样，黄老师在实践中积极使用 AI 编程，例如借助 AI 使用自己从未学习过的开发语言构建 CMS 系统，或借助 AI 基于 Codebase 能力重构现有旧项目。如今，他基本不再逐行审查 AI 的实现细节——因为生成的代码大多能正常运行。  </p><p>黄良懿还提出自己的观察，AI Agent 能力不断提升，如 CodeBuddy 等工具已经能自动补全自然语言的上下文，使生成更精准。同时，业内也在积极完善相关工程规范，推动 AI 在企业级场景中输出高质量代码。唯有 AI 具备强大的自动代码审查、自动化测试甚至自动构建和自动生成 PRD 文档和自动规划子任务能力时，开发者才会真正放心让将 AI 用于研发企业级项目。他预判这个未来不会太远，而未来 Code Review 将不再是核心重点，而需要更聚焦在审查提示词上（Prompt Review）。  </p><p>伴随台上台下精彩的思想交锋，本次沙龙在高密度的思想交流氛围中迎来尾声。</p><h2><strong>结语</strong></h2><p>最后，主持人陈漱玉总结道，在 AI 驱动的时代，架构师不可替代的价值，不仅在于连接代码与系统，更在于跨越当下与未来，架起技术发展的桥梁。  </p><p>除了干货满满的主题分享外，沙龙现场热烈的互动充分展现了腾讯云架构师技术同盟开放、友好的技术交流氛围。每位嘉宾分享结束后，台下与会者结合自身实践踊跃提问，嘉宾即时答疑解惑；圆桌讨论环节更是精彩纷呈，台上台下观点碰撞，激荡思想火花。这里不仅是知识单向传递的课堂，更是一个双向交流的平台，让每一位架构师都能在此对话更多志同道合的同行者，在交流中激发思考，收获成长，实现满载而归。  </p><p>腾讯云架构师技术同盟深圳地区分会正式启航，开启架构发展的新篇章，诚邀各位架构师一同前行，共探架构创新未来。</p>]]></description></item><item>    <title><![CDATA[WebStorm 2025.2.4 11]]></title>    <link>https://segmentfault.com/a/1190000047403732</link>    <guid>https://segmentfault.com/a/1190000047403732</guid>    <pubDate>2025-11-17 09:04:34</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <ul><li>2025-11-17亲测</li><li>支持最新版本2025.2.4</li><li>支持Windows、MAC、Linux<br/><img width="673" height="436" referrerpolicy="no-referrer" src="/img/bVdm32s" alt="web.png" title="web.png"/></li></ul><h2>一 安装</h2><p>官网下载：<a href="https://link.segmentfault.com/?enc=zoqucEpe3EGBviCz2tCfAQ%3D%3D.048v32nREw3nTjMTnMreb1FQXzcGi1BLrNSpezxPhLa%2FsXraRiIjmk3MUwMucJ5N" rel="nofollow" target="_blank">https://www.jetbrains.com/zh-cn/webstorm/</a><br/>根据提示安装</p><h2>二 授权说明</h2><p><img width="723" height="265" referrerpolicy="no-referrer" src="https://segmentfault.com/img/bVdmZkU" alt="图片" title="图片" loading="lazy"/><br/>回复 《web》获取<br/>新版本安装后不提示授权，需要手动处理</p><h2>三 使用</h2><p>打开自己的项目，配置环境，开始开发<br/><img width="723" height="366" referrerpolicy="no-referrer" src="/img/bVdm32t" alt="image.png" title="image.png" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[Red Hat Enterprise L]]></title>    <link>https://segmentfault.com/a/1190000047403734</link>    <guid>https://segmentfault.com/a/1190000047403734</guid>    <pubDate>2025-11-17 09:03:52</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>Red Hat Enterprise Linux 9.7 (x86_64, aarch64) - 红帽企业 Linux (RHEL)</p><p>RHEL 9 | 红帽企业 Linux 9</p><p>请访问原文链接：<a href="https://link.segmentfault.com/?enc=cGkmzu%2FDmrDdpLf5563E9w%3D%3D.4ZxxU6eaC%2BPE0nxcIJXX%2BUZH9XAggODZ7gEcwqrzyBw%3D" rel="nofollow" target="_blank">https://sysin.org/blog/rhel-9/</a> 查看最新版。原创作品，转载请保留出处。</p><p>作者主页：<a href="https://link.segmentfault.com/?enc=DWCfCmWkBKbdR5CPFHL1tg%3D%3D.bxVQvjM0YWwHyWJiluYd%2F7eNucCgIxuutYWtj29d1x4%3D" rel="nofollow" target="_blank">sysin.org</a></p><hr/><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047396058" alt="Red Hat Enterprise Linux sysin" title="Red Hat Enterprise Linux sysin"/></p><p>红帽企业 Linux 9</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047396059" alt="Red Hat Enterprise Linux Platform" title="Red Hat Enterprise Linux Platform" loading="lazy"/></p><p>2025 年 11 月 12 日，IBM 收购的红帽公司宣布推出红帽企业 Linux 9.7，这是世界领先的企业 Linux 平台的最新版本。</p><h2>红帽企业 Linux 9.7 新增功能</h2><p>当 Red Hat 构建 Red Hat Enterprise Linux（RHEL）的新主要版本时，Red Hat  的工程团队会深入了解现代 IT 的需求以及客户如何蓬勃发展。这些经验塑造了 Red Hat 在 Red Hat Summit  发布时展示的新功能和能力。在发布的庆祝之后，当然是将这些新功能带给更多需要它们的 RHEL 客户的工作。今天，随着 Red Hat  Enterprise Linux 9.7 的发布 (sysin)，RHEL 10 的一些最重要的安全功能现在可以为更多需要它们的人提供。</p><h3><strong>面向后量子世界的密码学</strong></h3><p>RHEL 10 是首个完全支持后量子密码学（PQC）的主要 Linux 发行版，现在 Red Hat 将 PQC 算法引入 RHEL  9.7。这些算法使得安全的密钥交换成为可能，这对于应对量子计算机带来的未来威胁至关重要 (sysin)。密钥交换增强了数据的完整性，并将其构建到 RHEL 9.7 中，为您的安全基础设施做好了应对新兴威胁的准备。</p><p>这仅仅是 RHEL 与 PQC 的开始。Red Hat 计划继续向未来版本中添加更多算法，以帮助您跟上不断发展的安全实践和合规要求。</p><p>这不仅是 RHEL 9.7 中的唯一改进，它还包含了许多新功能和能力，帮助您更快速地创新、不断改进，并简化 Linux 的操作。</p><h3><strong>随时随地的 AI 助手</strong></h3><p>RHEL 命令行助手已成为帮助客户弥补 RHEL 用户技能差距的重要工具。在 RHEL 10.1 和 RHEL 9.7 中，Red Hat 引入了离线、本地可用版本。现在，拥有 Red Hat Satellite 订阅的用户可以在断开连接或隔离环境中获得 AI 驱动的 RHEL  指导。当前，本地可用的命令行助手处于开发者预览阶段，全面推出将在不久后进行。凭借完全支持的离线助手，政府、国防、金融等严格监管行业的客户可以在不牺牲合规性的情况下，访问 AI 支持的指导。离线、本地可用的命令行助手需要 Red Hat Satellite 订阅。</p><p>另一个命令行助手的改进是：上下文限制从 2KB 增加到 32KB。借助更多的工作内存，命令行助手可以分析更大的日志文件，传输更复杂的数据流，跨提示保留更多信息，最终承担更复杂的任务。</p><h3><strong>更好的工具和更少的开发负担</strong></h3><p>更新版的 RHEL 也意味着更新的开发工具。RHEL 9.7 搭载了这些流行编程语言和服务的现代版本：</p><ul><li><strong>Go 1.24</strong>：新增支持弱指针和加密算法的标准库包，支持泛型类型别名，并进行多项运行时性能改进，减少 CPU 开销。</li><li><strong>LLVM 20</strong>：包括扩展的硬件支持、核心库的改进、现代化的即时链接基础设施，以及对 Clang 和 Flang 工具的更新。</li><li><strong>Rust 1.88</strong>：包括稳定版的 Rust 2024 版本 (sysin)，具有显著的语言变化，并使高性能计算所需的特定 CPU 特性可以在安全 Rust 中直接访问。</li><li><strong>GCC 15</strong>：通过运行时断言提高程序可靠性，C++ 标准库中的断言现在在未优化的构建中默认启用。GCC 工具集 15 还包括 C++ 标准库模块的预览版。</li><li><strong>.NET 10</strong>：提供更好的运行时性能，新增用于处理加密、全球化、数值、集合和 ZIP 文件的 API，还扩展了 .NET SDK 在容器中的支持，并支持 Web 应用程序中的 OpenAPI 3.1。</li><li><strong>Valkey 8</strong>：带来智能多核利用和异步 I/O 线程改进，提升集群扩展性，自动故障转移新分片和复制迁移状态，更快的复制，双通道关系型数据库和复制积压流式传输，并通过改进的每槽和每客户端指标提供更好的可视化。</li><li><strong>Node.js 24</strong>：新增一个作为全局对象的 URLPattern，以提高 Web 兼容性，更新 V8 JavaScript 引擎，并将权限模型从实验阶段提升到生产阶段使用。</li></ul><h3><strong>可重现的镜像构建减少管理复杂性</strong></h3><p>Red Hat 在 RHEL 9.6  中引入了镜像模式，简化了操作系统的部署过程以及在其上层叠加应用程序的过程。无论是部署到虚拟机、硬件，还是公共云，镜像模式都成为了比基于包管理的方式更受欢迎的选择。随着 RHEL 9.7 的发布，RHEL  镜像模式现在支持容器工具的可重现构建。这意味着，使用相同内容构建的容器镜像将生成完全相同的镜像，不会因为时间戳或其他元数据而出现不一致。使用  RHEL 容器工具生成的容器镜像现在是可重现的。</p><h3><strong>混合云加密与新增的遥测支持</strong></h3><p>OpenTelemetry Collector，作为 RHEL 9 和 10 云镜像的一部分，现在支持在 AWS、Microsoft Azure 和 Google Cloud Platform 上使用受信平台模块（TPM）。</p><p>TPM 支持帮助保护先前仅在软件中存储的加密密钥和认证数据。现在，像密钥生成、签名和系统完整性检查这样的操作可以在防篡改硬件内部完成，从而提高操作的整体完整性。</p><p>对于云虚拟机，虚拟 TPM（vTPM）提供了更多保护 (sysin)。它支持安全的身份验证、加密的密钥存储，并符合严格的安全标准。这对于受监管或多租户的工作负载尤其重要。即使在虚拟化环境中，系统现在也能从硬件级安全性和可验证的完整性中受益。</p><h2>下载地址</h2><p>Red Hat Enterprise Linux 9.0</p><p>Red Hat Enterprise Linux 9.1</p><p>Red Hat Enterprise Linux 9.2</p><p>Red Hat Enterprise Linux 9.3</p><p>Red Hat Enterprise Linux 9.4</p><p>Red Hat Enterprise Linux 9.5</p><p>Red Hat Enterprise Linux 9.6</p><p><strong>Red Hat Enterprise Linux</strong> 9.7</p><ul><li>请访问：<a href="https://link.segmentfault.com/?enc=%2FUCdGP018pAIZ9knxGYcKg%3D%3D.1I5HppwsrTmFR9SwCv2WAWPL%2BMSpF8RVNFbaIoUn4Ow%3D" rel="nofollow" target="_blank">https://sysin.org/blog/rhel-9/</a></li></ul><table><thead><tr><th>Architectures</th><th>Image type</th><th>File name</th><th>Release date</th><th>Size</th></tr></thead><tbody><tr><td>x86_64</td><td>DVD iso</td><td>rhel-9.7-x86_64-dvd.iso</td><td>November 11, 2025</td><td>11 GB</td></tr><tr><td>x86_64</td><td>Boot iso</td><td>rhel-9.7-x86_64-boot.iso</td><td>November 11, 2025</td><td>1 GB</td></tr><tr><td>aarch64</td><td>DVD iso</td><td>rhel-9.7-aarch64-dvd.iso</td><td>November 11, 2025</td><td>9.5 GB</td></tr><tr><td>aarch64</td><td>Boot iso</td><td>rhel-9.7-aarch64-boot.iso</td><td>November 11, 2025</td><td>1 GB</td></tr></tbody></table><hr/><p>更多：<a href="https://link.segmentfault.com/?enc=H6GWuTl5meqrgM%2FozMwkNw%3D%3D.mOgnoCiYjl75WlmWEvGavcDF7QXmuMWG3L%2BMlpWk5Bg%3D" rel="nofollow" target="_blank">Linux 产品链接汇总</a></p>]]></description></item><item>    <title><![CDATA[Red Hat Enterprise L]]></title>    <link>https://segmentfault.com/a/1190000047403737</link>    <guid>https://segmentfault.com/a/1190000047403737</guid>    <pubDate>2025-11-17 09:03:20</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>Red Hat Enterprise Linux 10.1 (x86_64, aarch64) - 红帽企业 Linux (RHEL)</p><p>RHEL 10 | 红帽企业 Linux 10</p><p>请访问原文链接：<a href="https://link.segmentfault.com/?enc=QKMPZF2due2c3iE3u0eIsQ%3D%3D.ICMPUzjSQc%2BlSsRvRVi6jE7I4KGDUjxcu6XK7LWDXEo%3D" rel="nofollow" target="_blank">https://sysin.org/blog/rhel-10/</a> 查看最新版。原创作品，转载请保留出处。</p><p>作者主页：<a href="https://link.segmentfault.com/?enc=7wN2S5xUVMEtTCeBPuiJOA%3D%3D.uLMSVJVUbv%2F85gSISfUwGgk4g%2BN0bOwmePFDgmVzD60%3D" rel="nofollow" target="_blank">sysin.org</a></p><hr/><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047396058" alt="Red Hat Enterprise Linux sysin" title="Red Hat Enterprise Linux sysin"/></p><p>红帽企业 Linux 10</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047396059" alt="Red Hat Enterprise Linux Platform" title="Red Hat Enterprise Linux Platform" loading="lazy"/></p><p>Red Hat Enterprise Linux 为支持混合云创新提供了灵活稳定的基础。更快地部署应用程序和关键工作负载，并在物理、虚拟、私有云、公有云和边缘部署中提供一致的体验。</p><p>2025 年 11 月 12 日，IBM 收购的红帽公司宣布推出红帽企业 Linux 10.1，这是世界领先的企业 Linux 平台的最新版本。</p><h2>RHEL 10.1 新特性：离线助手、便捷的 AI 加速器等</h2><p>作为 RHEL 10.1 更新的一部分，离线、本地可用的命令行助手正式进入开发者预览。对于拥有 Red Hat Satellite 订阅的客户，它提供基于数十年企业 Linux 经验的 AI 驱动 RHEL 指导。金融、政府、国防、工业控制及其他高安全性行业的公司和机构将特别受益于此。该设计的一个关键优势是，它可以在完全断开连接、离线或隔离的环境中运行，消除了对外部网络连接的需求。这使用户能够接收 AI 驱动的指导和建议，涵盖 RHEL 安装过程、故障排除等多种任务，而不会妥协安全性或依赖云服务。</p><p>访问离线、本地可用的命令行助手需要 Red Hat Satellite 订阅。</p><p>RHEL 命令行助手在 RHEL 10.1（以及今天发布的 RHEL 9.7）中又有了新的改进：其上下文限制从 2KB 增加到 32KB。扩展命令行助手的工作内存解锁了更强大、更复杂的交互能力 (sysin)。现在它可以处理更大的日志文件、传输大量数据流，并帮助完成更大的任务。</p><h3>AI 加速器触手可及</h3><p>最近的 RHEL 更新专注于让客户更容易地采用 AI。在 RHEL 10.1 中，Red Hat 改善了操作系统与提供 AI 所需计算能力的硬件之间的关键交互。</p><p>Red Hat 将在 RHEL 扩展库和附加库中提供供应商验证的 AI 加速器驱动程序。与 AI 相关的硬件发展速度很快，以至于数据科学家和安全团队很难跟上。保持图形处理单元（GPU）、张量处理单元（TPU）以及其他应用专用集成电路（ASIC）驱动程序的更新是一项挑战，而将供应商验证的兼容 RHEL 驱动程序引入已经信任的生态系统 (sysin)，可以减少大量工作。</p><p>Red Hat 将从三家领先硬件制造商的驱动程序开始：</p><ul><li><strong>NVIDIA</strong>：OpenRM 内核模式驱动程序，CUDA 工具包</li><li><strong>AMD</strong>：<code>amdgpu</code> 内核模式驱动程序和 ROCm</li><li><strong>Intel</strong>：神经处理单元（NPU）内核模式驱动程序</li></ul><h3>镜像模式更新：软重启和可重现构建</h3><p>在 RHEL 10.1 中，Red Hat 引入了带有镜像模式的新 systemd 功能：软重启。这个新功能通过允许管理员在不完全重启的情况下改变系统状态，减少了停机时间。通过这个更新，管理员可以在不打断内核操作的情况下，更新或重置应用程序、库和其他用户空间组件。</p><p>使用软重启，使用镜像模式的客户可以快速应用安全补丁、更新软件或重置系统状态，且服务中断最小化。更多的正常运行时间意味着组织的敏捷性更高。</p><p>对于镜像模式用户的另一项效率提升是：RHEL 10.1 和 RHEL 9.7 都为镜像模式中的容器工具提供了可重现的构建。之前，基于相同输入的容器镜像仍然会有细微的差异，如不同的时间戳 (sysin)。通过这个更新，从匹配内容创建的容器镜像将完全相同，甚至其元数据也一致。这对安全性、可靠性和效率都是一个提升。</p><h3>提升开发者生产力的更新工具集</h3><p>RHEL 10.1 包含了多种主流编程语言和服务的更新版本，包括：</p><ul><li><strong>Go 1.24</strong>：新增支持弱指针和加密算法的标准库包，支持泛型类型别名，并进行多项运行时性能改进，减少 CPU 开销。</li><li><strong>LLVM 20</strong>：包括扩展的硬件支持、核心库的改进、现代化的即时链接基础设施，以及对 Clang 和 Flang 工具的更新。</li><li><strong>Rust 1.88</strong>：稳定版 Rust 2024 版本包括显著的语言变更，并使高性能计算所需的特定 CPU 特性可以在安全 Rust 中直接访问。</li><li><strong>GCC 15</strong>：通过运行时断言提高程序可靠性，C++ 标准库中的断言现在在未优化的构建中默认启用。GCC 工具集 15 还包括 C++ 标准库模块的预览版。</li><li><strong>.NET 10</strong>：提供更好的运行时性能 (sysin)，新增用于处理加密、全球化、数值、集合和 ZIP 文件的 API，还扩展了 .NET SDK 在容器中的支持，并支持 Web 应用程序中的 OpenAPI 3.1。</li><li><strong>Valkey 8</strong>：带来智能多核利用和异步 I/O 线程改进，提升集群扩展性，自动故障转移新分片和复制迁移状态，更快的复制，双通道关系型数据库和复制积压流式传输，并通过改进的每槽和每客户端指标提供更好的可视化。</li><li><strong>Node.js 24</strong>：新增一个作为全局对象的 URLPattern，以提高 Web 兼容性，更新 V8 JavaScript 引擎，并将权限模型从实验阶段提升到生产阶段使用。</li></ul><h3>加强下一代基础的安全性</h3><p>后量子密码学（PQC）是 RHEL 10 中的一次安全性飞跃。在 RHEL 10.1 中，Red Hat 通过增强对传输层安全性（TLS）支持的 PQC，继续为后量子世界发展。将 PQC 算法引入传输层可以加固信息跨网络传输时的安全性，这是许多组织的薄弱环节。</p><p>OpenTelemetry Collector 是 RHEL 9 和 RHEL 10 云镜像的一部分，现在支持所有三大公共云平台上的受信平台模块（TPM）。通过在云中保护加密密钥和认证数据，TPM 将硬件级别的安全性引入了软件环境，而混合 IT 正在越来越多地在这些环境中运行。</p><p>这也适用于云虚拟机部署。OpenTelemetry Collector 升级还包括对 RHEL 10.1 和 RHEL 9.7 云镜像中虚拟化 TPM（vTPM）的支持。</p><h3>跨云一致性与简化的镜像创建</h3><p>RHEL 镜像构建器一直是使用 RHEL 的公共云客户的首选工具。在 RHEL 10.1 中，镜像创建过程变得更加简单，Red Hat 推出了镜像构建器命令行界面（CLI）。用户不再需要持续运行服务 (sysin)，就可以更轻松地安装和设置构建环境。这简化了 RHEL 镜像构建与持续集成 / 持续交付（CI/CD）管道和自动化工作流的集成。</p><p>最终，它还使组织能够以一致的设置和标准化流程进行部署，而不管环境如何。镜像构建器 CLI 目前处于技术预览阶段。</p><p>随着 RHEL 10.1 的发布，Red Hat 的操作系统继续发展，以便客户能够保持一致的操作，并在 AI、PQC 等新技术出现时快速采用。获取更多有关该演变的信息，并亲自测试 RHEL 10.1。</p><h2>下载地址</h2><p>Red Hat Enterprise Linux 10.0</p><p>Red Hat Enterprise Linux 10.1</p><ul><li>请访问：<a href="https://link.segmentfault.com/?enc=2MnDzql8g2lPWFphdRX6ZA%3D%3D.IDgIH3exDORD2nGlWx6SPMUukSFAieWip3Huw92kzeY%3D" rel="nofollow" target="_blank">https://sysin.org/blog/rhel-10/</a></li></ul><table><thead><tr><th>Architectures</th><th>Image type</th><th>File name</th><th>Release date</th><th>Size</th></tr></thead><tbody><tr><td>x86_64</td><td>DVD iso</td><td>rhel-10.1-x86_64-dvd.iso</td><td>2025-11-11</td><td>8.47 GB</td></tr><tr><td>x86_64</td><td>Boot iso</td><td>rhel-10.1-x86_64-boot.iso</td><td>2025-11-11</td><td>856 MB</td></tr><tr><td>aarch64</td><td>DVD iso</td><td>rhel-10.1-aarch64-dvd.iso</td><td>2025-11-11</td><td>7.89 GB</td></tr><tr><td>aarch64</td><td>Boot iso</td><td>rhel-10.1-aarch64-boot.iso</td><td>2025-11-11</td><td>850 MB</td></tr></tbody></table><hr/><p>更多：<a href="https://link.segmentfault.com/?enc=ZFQNymSjPkiHCVuL8IMh%2FQ%3D%3D.2Q3tpqZg4e%2BB0IvHnPQ5RKDTw8YdoYD%2BhDArmTxN7%2FQ%3D" rel="nofollow" target="_blank">Linux 产品链接汇总</a></p>]]></description></item><item>    <title><![CDATA[Tenable Nessus 10.11]]></title>    <link>https://segmentfault.com/a/1190000047403746</link>    <guid>https://segmentfault.com/a/1190000047403746</guid>    <pubDate>2025-11-17 09:02:22</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>Tenable Nessus 10.11 新增功能简介</p><p>Tenable Nessus 10.11.0 (macOS, Linux, Windows) - 漏洞评估解决方案</p><p>发布 Nessus 试用版自动化安装程序，支持 macOS Tahoe、RHEL 10、Ubuntu 24.04 和 Windows</p><p>请访问原文链接：<a href="https://link.segmentfault.com/?enc=UVd6K4nrXFT0d%2Bi%2FQh%2FWlQ%3D%3D.LrVvVr5gF1JgIgwyZAxUnlqU2sTjnKVjH2FcGk%2BaGaFF%2B3Zn7MzaP4FPNMDVDZ79" rel="nofollow" target="_blank">https://sysin.org/blog/nessus-10/</a> 查看最新版。原创作品，转载请保留出处。</p><p>作者主页：<a href="https://link.segmentfault.com/?enc=uSR7kblkj8xJtRgMsc%2BGXw%3D%3D.Ji6tHdJIFRO%2BRS0b8T%2FYlOSvbvVAlxpXnaED8v0RxGo%3D" rel="nofollow" target="_blank">sysin.org</a></p><hr/><p><img referrerpolicy="no-referrer" src="/img/remote/1460000045064788" alt="Nessus" title="Nessus"/></p><p>Nessus Vulnerability Scanner</p><p><strong>漏洞评估领域的全球黄金标准</strong>，<strong>针对现代攻击面量身打造</strong>。</p><p>利用业界最受信赖的漏洞评估解决方案来评估现代攻击面。扩展到传统的 IT 资产之外 – 保护云基础设施和获取对与互联网相连的攻击面的可见性。</p><h2>Nessus 版本</h2><table><thead><tr><th>Nessus Expert</th><th>Nessus Professional</th></tr></thead><tbody><tr><td>适用对象：</td><td>适用对象：</td></tr><tr><td><strong>顾问、渗透测试人员、开发人员和中小型企业</strong></td><td><strong>顾问、渗透测试人员和安全专业人士</strong></td></tr><tr><td>- 不受限制的 IT 评估</td><td>- 不受限制的 IT 评估</td></tr><tr><td>- 使用不限地点</td><td>- 使用不限地点</td></tr><tr><td>- 配置评估</td><td>- 配置评估</td></tr><tr><td>- 实时检测结果</td><td>- 实时检测结果</td></tr><tr><td>- 配置报告</td><td>- 配置报告</td></tr><tr><td>- 社区支持</td><td>- 社区支持</td></tr><tr><td>- 高级支持（可选）</td><td>- 高级支持（可选）</td></tr><tr><td>- 提供随需培训</td><td>- 提供随需培训</td></tr><tr><td>- 外部攻击面扫描</td><td>x 外部攻击面扫描</td></tr><tr><td>- 添加域的功能</td><td>x 添加域的功能</td></tr><tr><td>- 扫描云端基础架构</td><td>x 扫描云端基础架构</td></tr><tr><td>- 500 个预构建的扫描策略</td><td>x 500 个预构建的扫描策略</td></tr></tbody></table><h2>新增功能</h2><p>Tenable Nessus 10.11.0 (2025-11-14)</p><p>备注：此版本的 Tenable Nessus 是早期访问版。正式版将在晚些时候公布。</p><p>✅ <strong>新功能</strong></p><p>以下是 Tenable Nessus 10.11.0 中包含的新功能：</p><ul><li><p>引入了 Nessus Essentials Plus，一个新的年度订阅方案，已验证的学生和教育工作者免费使用，其他用户也能以较为优惠的价格订阅。它包含以下功能：</p><ul><li>可扫描 20 个目标。</li><li>HTML 和 PDF 报告。</li><li>实时插件更新。</li></ul></li></ul><p>✅ <strong>功能变更和性能增强</strong></p><p>以下变更包含在 Tenable Nessus 10.11.0 中：</p><ul><li><p>更新了 Tenable Nessus Essentials 的新功能限制：</p><ul><li>扫描目标数量从 16 个减少至 5 个。</li><li>禁用了报告和导出功能。</li><li>更新了订阅为月度订阅。</li><li>延迟 30 天更新插件。</li><li>更新了产品，使得除非升级到 Tenable Nessus 的高级版本 (sysin)，否则订阅期结束时数据不会被保存。</li></ul></li></ul><p>✅ <strong>Bug 修复</strong></p><ul><li>修复了本地化 HTML 和 PDF 报告翻译不正确的问题。缺陷 ID: 02338762, 02340433</li><li>修复了 Tenable Nessus 后端未更新最后检查到的可用版本的问题。缺陷 ID: 02257447, 02325697</li><li>修复了 Tenable Nessus 在离线模式下无法加载 Web 应用扫描插件的问题。缺陷 ID: 02249841, 02335036</li></ul><h2>下载地址</h2><p>Tenable Nessus 10.11.0</p><ul><li>请访问：<a href="https://link.segmentfault.com/?enc=FTTi153m8poQPpVxZe%2BWOQ%3D%3D.udpUMAq0lZi9qxGaB80%2FkLRBuodcfaHkmvZ9zV%2Bocn3Isbw4DsFcUbWHoBZF6sxt" rel="nofollow" target="_blank">https://sysin.org/blog/nessus-10/</a></li></ul><hr/><p>发布 Nessus 试用版自动化安装程序，支持 macOS Tahoe、RHEL 10、Ubuntu 24.04 和 Windows</p><ul><li><a href="https://link.segmentfault.com/?enc=XYo5V6KgWEtyhTop61PI4A%3D%3D.GdE3EsgKoVO%2B66Wg5ccHdYVG0HNT0Ndx5jIAWLM8%2BOQ6TRvcye43nnVgEdDhoYEbvhNkyF1wstuRwy4Ei%2F4jWA%3D%3D" rel="nofollow" target="_blank">Nessus Professional 10.10 Auto Installer for macOS Tahoe - Nessus 自动化安装程序</a></li><li><a href="https://link.segmentfault.com/?enc=rw7qz4%2FoVgh5hEtO16%2Ba%2FQ%3D%3D.ibin0D3E8mKDqvNryhtVrRuu5zcVlxgMXWFmp%2F36UaVQkuzLm50wRxpPXvuYWTKT84YNq2p0Lj8H2wEmR45ctg%3D%3D" rel="nofollow" target="_blank">Nessus Professional 10.10 Auto Installer for RHEL 10, AlmaLinux 10, Rocky Linux 10 - Nessus 自动化安装程序</a></li><li><a href="https://link.segmentfault.com/?enc=PMafCl5G8iNjsnZE3FkLKA%3D%3D.QglbtjDLg%2Fl0Bi1g3IF0xh93MCepi7WaYBy2Qo49mwwGSwBTIkw7jI2wDYeWBEfVQfHFZqq3UTdMqQjQ%2BAm0sA%3D%3D" rel="nofollow" target="_blank">Nessus Professional 10.10 Auto Installer for Ubuntu 24.04 - Nessus 自动化安装程序</a></li><li><a href="https://link.segmentfault.com/?enc=YhcYbENutRGI68yMPuKIKg%3D%3D.ZTe58FTtIcaF3bnDFq1535h4lbrMeIsD%2B0rgwmQypH2zSQxf7jOhFTMGYjFjsxOgsLcislcCI9QEcJ74QDsv6Q%3D%3D" rel="nofollow" target="_blank">Nessus Professional 10.10 Auto Installer for Windows - Nessus 自动化安装程序</a></li></ul><p>更多：<a href="https://link.segmentfault.com/?enc=%2FJYpKA9xqFEGwVOVQwpPQQ%3D%3D.1Q7g0S4l2Ycw%2FMrZpojFkNWKqhnECOCh%2Bq3%2BcVvSwb8%3D" rel="nofollow" target="_blank">HTTP 协议与安全</a></p>]]></description></item><item>    <title><![CDATA[SpringCloud 常见面试题（一）]]></title>    <link>https://segmentfault.com/a/1190000047402121</link>    <guid>https://segmentfault.com/a/1190000047402121</guid>    <pubDate>2025-11-17 09:01:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>概念</h2><h3>什么是微服务？你是怎么理解微服务的？</h3><p>微服务架构是一种架构模式或者说是一种架构风格，它提倡将单一应用程序划分为一组小的服务，每个服务运行在其独立的自己的进程中，服务之间相互协调、互相配合，为用户提供最终价值。服务之间采用轻量级的通信机制互相沟通（通常是基于HTTP的RESTful API）,每个服务都围绕着具体的业务进行构建，并且能够被独立的构建在生产环境、类生产环境等。另外，应避免统一的、集中式的服务管理机制，对具体的一个服务而言，应根据业务上下文，选择合适的语言、工具对其进行构建，可以有一个非常轻量级的集中式管理来协调这些服务，可以使用不同的语言来编写服务，也可以使用不同的数据存储。</p><p>通俗地来讲：</p><p>微服务就是一个独立的职责单一的服务应用程序。在 intellij idea 工具里面就是用maven开发的一个个独立的module，具体就是使用springboot 开发的一个小的模块，处理单一专业的业务逻辑，一个模块只做一个事情。</p><p>微服务强调的是服务大小，关注的是某一个点，具体解决某一个问题/落地对应的一个服务应用，可以看做是idea 里面一个 module。</p><h3>微服务有什么好处？</h3><p>微服务优点很多，但是我们通常说一个东西好肯定会跟另一个东西比较， 通常说微服务好会和单体项目进行比较。以下是微服务相对于单体项目的一些显著好处：</p><p>单体项目的缺点：</p><ul><li>可扩展性受限： 单体应用通常在可扩展性方面受到限制，因为整个应用程序必须一起扩展。这意味着即使只有一个组件需要更多资源，也必须扩展整个应用程序，这可能会导致资源浪费。</li><li>难以维护和更新： 随着时间的推移，单体应用程序往往变得越来越庞大和复杂，难以理解、维护和更新。每次修改都可能引发意想不到的影响。</li><li>高风险： 单体应用程序中的一个小错误或故障可能会导致整个应用程序崩溃，因此存在较高的风险。此外，长时间不更新的单体应用可能会受到安全威胁。</li><li>技术栈限制： 单体应用程序通常使用相同的技术栈，这可能会限制您在项目中使用最新的技术和工具的能力。</li><li>团队协作复杂： 单体应用程序的所有组件都在一个代码库中，这可能导致开发团队之间的冲突和协作问题，尤其在大型团队中更为突出。</li></ul><p>微服务项目的优点：</p><ul><li>可扩展性： 微服务架构允许您根据需要独立地扩展单个服务，而不必扩展整个应用程序，这提供了更高的可扩展性。</li><li>灵活性和快速开发： 微服务允许开发团队独立设计、开发和部署服务，这提高了灵活性，允许团队更快地推出新功能和更新。</li><li>故障隔离和容错性： 单个微服务的故障通常不会影响其他服务，提高了应用程序的容错性，同时更容易识别和解决故障。</li><li>技术多样性： 微服务允许您选择适合每个服务的最佳技术栈，这有助于充分利用各种技术和工具的优势。</li><li>独立部署和维护： 微服务可以独立部署和维护，这减少了风险，使团队能够更快速地进行修复和更新。</li><li>团队协作： 不同团队可以独立工作在不同服务上，这提高了团队的自治和协作能力，减少了冲突。</li></ul><p>总的来说，微服务项目通过提供更高的可扩展性、灵活性和容错性，以及更容易管理的部署和维护过程，有助于克服单体应用程序的一些限制和缺点。但请注意，微服务架构也会引入一些新的复杂性，需要更多的管理和监控。</p><h3>单体应用、SOA 和微服务架构有什么区别</h3><p>单体应用、SOA和微服务架构都是不同的架构风格，适用于不同的情况。  </p><p>单体应用像一个整体，所有的功能都打包在一个应用中。这种架构风格容易部署和测试，但随着系统规模的扩大，它的灵活性和可维护性会降低。  </p><p>SOA是一种面向服务的架构风格，将系统划分为多个独立的服务。这些服务可以通过网络调用，并且可以跨平台、跨语言进行交互。SOA的优点是提供了跨系统的服务复用和松散耦合的交互方式，但实现SOA需要投入大量的工作，包括服务的定义、接口的选择、协议的制定等。  </p><p>微服务架构进一步将系统划分为多个小型、独立的服务，每个服务都是一个单独的应用程序，可以独立部署、运行和扩展。微服务架构具有更高的灵活性和可维护性，适用于复杂的大型系统，强调服务的自治和独立性。但是，实施微服务架构也需要投入大量的工作，包括服务的定义、通信机制的选择、服务的管理等。</p><h3>分布式和微服务有什么区别?</h3><p>分布式系统和微服务架构是两个相关但不同的概念，它们的注重点其实不太一样。</p><p>分布式系统：它是由多台计算机或多节点组成的系统，各节点之间通过网络进行通信和协作，共同完成一个或多个共享的任务也就是说分布式的各个节点其实目标是一致的，之所以要分布式只是为了有更好的能力，能更快、更高效地承接任务。比如常见的分布式文件系统、分布式数据库。</p><p>微服务：其实是一种服务的架构风格，它主要是为了把一个大而全的服务，拆分成多个可以独立、松耦合的服务单元，为了让这些服务单元可以独立部署、运行、管理比如电商服务拆分成微服务，可以分为商品服务、用户服务、订单服务、库存服务等等</p><h3>什么是Spring Cloud ？</h3><p>Spring cloud 流应用程序启动器是基于 Spring Boot 的 Spring 集成应用程序，提供与外部系统的集成。Spring cloud Task，一个生命周期短暂的微服务框架，用于快速构建执行有限数据处理的应用程序。</p><p>Spring cloud 流应用程序启动器是基于 Spring Boot 的 Spring 集成应用程序，提供与外部系统的集成。Spring cloud Task，一个生命周期短暂的微服务框架，用于快速构建执行有限数据处理的应用程序。</p><h3>现在有哪些流行的微服务解决方案？</h3><p>目前最主流的微服务开源解决方案有三种：</p><p>Dubbo：</p><ul><li>Dubbo 是一个高性能、轻量级的 Java 微服务框架，最初由阿里巴巴（Alibaba）开发并于2011年开源。它提供了服务注册与发现、负载均衡、容错、分布式调用等功能，后来一度停止维护，在近两年，又重新开始迭代，并推出了Dubbo3。</li><li>Dubbo 使用基于 RPC（Remote Procedure Call）的通信模型，具有较高的性能和可扩展性。它支持多种传输协议（如TCP、HTTP、Redis）和序列化方式（如JSON、Hessian、Protobuf），可根据需求进行配置。</li><li>Dubbo更多地被认为是一个高性能的RPC（远程过程调用）框架，一些服务治理功能依赖于第三方组件实现，比如使用ZooKeeper、Apollo等等。</li></ul><p>Spring Cloud Netflix：</p><ul><li>Spring Cloud Netflix 是 Spring Cloud 的一个子项目，结合了 Netflix 开源的多个组件，但是Netflix自2018年停止维护和更新Netflix OSS项目，包括Eureka、Hystrix等组件，所以Spring Cloud Netflix也逐渐进入了维护模式。</li><li>该项目包含了许多流行的 Netflix 组件，如Eureka（服务注册与发现）、Ribbon（客户端负载均衡）、Hystrix（断路器）、Zuul（API 网关）等。它们都是高度可扩展的、经过大规模实践验证的微服务组件。</li></ul><p>Spring Cloud Alibaba：</p><ul><li>Spring Cloud Alibaba 是 Spring Cloud 的另一个子项目，与阿里巴巴的分布式应用开发框架相关。它提供了一整套与 Alibaba 生态系统集成的解决方案。</li><li>该项目包括 Nacos（服务注册与发现、配置管理）、Sentinel（流量控制、熔断降级）、RocketMQ（消息队列）等组件，以及与 Alibaba Cloud（阿里云）的集成。它为构建基于 Spring Cloud 的微服务架构提供了丰富的选项。</li></ul><p>这三种方案有什么区别：</p><table><thead><tr><th>特点</th><th>Dubbo</th><th>Spring Cloud Netflix</th><th>Spring Cloud Alibaba</th></tr></thead><tbody><tr><td>开发语言</td><td>Java</td><td>Java</td><td>Java</td></tr><tr><td>服务治理</td><td>提供完整的服务治理功能</td><td>提供部分服务治理功能</td><td>提供完整的服务治理功能</td></tr><tr><td>服务注册与发现</td><td>ZooKeeper/Nacos</td><td>Eureka/Consul</td><td>Nacos</td></tr><tr><td>负载均衡</td><td>自带负载均衡策略</td><td>Ribbon</td><td>Ribbon\Dubbo负载均衡策略</td></tr><tr><td>服务调用</td><td>RPC方式</td><td>RestTemplate/Feign</td><td>Feign/RestTemplate/Dubbo</td></tr><tr><td>熔断器</td><td>Sentinel</td><td>Hystrix</td><td>Sentinel/Resilience4j</td></tr><tr><td>配置中心</td><td>Apollo</td><td>Spring Cloud Config</td><td>Nacos Config</td></tr><tr><td>API网关</td><td>Higress/APISIX</td><td>Zuul/Gateway</td><td>Spring Cloud Gateway</td></tr><tr><td>分布式事务</td><td>Seata</td><td>不支持分布式事务</td><td>Seata</td></tr><tr><td>限流和降级</td><td>Sentinel</td><td>Hystrix</td><td>Sentinel</td></tr><tr><td>分布式追踪和监控</td><td>Skywalking</td><td>Spring Cloud Sleuth + Zipkin</td><td>SkyWalking或Sentinel Dashboard</td></tr><tr><td>微服务网格</td><td>Dubbo Mesh</td><td>不支持微服务网格</td><td>Service Mesh（Nacos+Dubbo Mesh）</td></tr><tr><td>社区活跃度</td><td>相对较高</td><td>目前较低</td><td>相对较高</td></tr><tr><td>孵化和成熟度</td><td>孵化较早，成熟度较高</td><td>成熟度较高</td><td>孵化较新，但迅速发展</td></tr></tbody></table><p>-在面试中，微服务一般主要讨论的是Spring Cloud Netflix，其次是Spring Cloud Alibaba，Dubbo更多的是作为一个RPC框架来问。</p><h3>Spring Cloud有什么优势</h3><p>使用 Spring Boot 开发分布式微服务时，我们面临以下问题</p><ul><li>与分布式系统相关的复杂性-这种开销包括网络问题，延迟开销，带宽问题，安全问题。</li><li>服务发现-服务发现工具管理群集中的流程和服务如何查找和互相交谈。它涉及一个服务目录，在该目录中注册服务，然后能够查找并连接到该目录中的服务。</li><li>冗余-分布式系统中的冗余问题。</li><li>负载平衡 --负载平衡改善跨多个计算资源的工作负荷，诸如计算机，计算机集群，网络链路，中央处理单元，或磁盘驱动器的分布。</li><li>性能-问题 由于各种运营开销导致的性能问题。</li><li>部署复杂性-Devops 技能的要求。</li></ul><h3>说下微服务有哪些组件？</h3><p>微服务给系统开发带来了一些问题和挑战，如服务调用的复杂性、分布式事务的处理、服务的动态管理等。为了更好地解决这些问题和挑战，各种微服务治理的组件应运而生，充当微服务架构的基石和支撑。</p><p>微服务的各个组件和常见实现：</p><ul><li><p>注册中心：用于服务的注册与发现，管理微服务的地址信息。常见的实现包括：</p><ul><li>Spring Cloud Netflix：Eureka、Consul</li><li>Spring Cloud Alibaba：Nacos</li></ul></li><li><p>配置中心：用于集中管理微服务的配置信息，可以动态修改配置而不需要重启服务。常见的实现包括：</p><ul><li>Spring Cloud Netflix：Spring Cloud Config</li><li>Spring Cloud Alibaba：Nacos Config</li></ul></li><li><p>远程调用：用于在不同的微服务之间进行通信和协作。常见的实现保包括：</p><ul><li>RESTful API：如RestTemplate、Feign</li><li>RPC（远程过程调用）：如Dubbo、gRPC</li></ul></li><li><p>API网关：作为微服务架构的入口，统一暴露服务，并提供路由、负载均衡、安全认证等功能。常见的实现包括：</p><ul><li>Spring Cloud Netflix：Zuul、Gateway</li><li>Spring Cloud Alibaba：Gateway、Apisix等</li></ul></li><li><p>分布式事务：保证跨多个微服务的一致性和原子性操作。常见的实现包括：</p><ul><li>Spring Cloud Alibaba：Seata</li></ul></li><li><p>熔断器：用于防止微服务之间的故障扩散，提高系统的容错能力。常见的实现包括：</p><ul><li>Spring Cloud Netflix：Hystrix</li><li>Spring Cloud Alibaba：Sentinel、Resilience4j</li></ul></li><li><p>限流和降级：用于防止微服务过载，对请求进行限制和降级处理。常见的实现包括：</p><ul><li>Spring Cloud Netflix：Hystrix</li><li>Spring Cloud Alibaba：Sentinel</li></ul></li><li><p>分布式追踪和监控：用于跟踪和监控微服务的请求流程和性能指标。常见的实现包括：</p><ul><li>Spring Cloud Netflix：Spring Cloud Sleuth + Zipkin</li><li>Spring Cloud Alibaba：SkyWalking、Sentinel Dashboard</li></ul></li></ul><h3>Spring、SpringMVC、Springboot、 Springcloud 的区别是什么？</h3><h4>Spring</h4><p>Spring是一个生态体系（也可以说是技术体系），是集大成者，它包含了Spring Framework、Spring Boot、Spring Cloud等。<strong>它是一个轻量级控制反转(IOC)和面向切面(AOP)的容器框架</strong>，为开发者提供了一个简易的开发方式。</p><p>Spring的核心特性思想之一IOC，它实现了容器对Bean对象的管理、降低组件耦合，使各层服务解耦。</p><p>Spring的另一个核心特性就是AOP，面向切面编程。面向切面编程需要将程序逻辑分解为称为所谓关注点的不同部分。跨越应用程序多个点的功能称为跨领域问题，这些跨领域问题在概念上与应用程序的业务逻辑分离。有许多常见的例子，如日志记录，声明式事务，安全性，缓存等。</p><p><strong>如果说IOC依赖注入可以帮助我们将应用程序对象相互分离，那么AOP可以帮助我们将交叉问题与它们所影响的对象分离。二者目的都是使服务解耦，使开发简易。</strong></p><p>当然，除了Spring 的两大核心功能，还有如下这些，如：</p><ul><li>Spring JDBC</li><li>Spring MVC</li><li>Spring ORM</li><li>Spring Test</li></ul><h4>SpringMVC</h4><p>Spring与MVC可以更好地解释什么是SpringMVC，MVC为现代web项目开发的一种很常见的模式，简言之C（控制器）将V（视图、用户客户端）与M（模块，业务）分开构成了MVC ，业内常见的MVC模式的开发框架有Struts。</p><p>Spring MVC是Spring的一部分，主要用于开发WEB应用和网络接口，它是Spring的一个模块，通过DispatcherServlet, ModelAndView 和View Resolver，让应用开发变得很容易。</p><h4>SpringBoot</h4><p>SpringBoot是一套整合了框架的框架。</p><p>它的初衷：解决Spring框架配置文件的繁琐、搭建服务的复杂性。</p><p>它的设计理念：<strong>约定优于配置</strong>（convention over configuration）。</p><p>基于此理念实现了<strong>自动配置</strong>，且降低项目搭建的复杂度。</p><p>搭建一个接口服务，通过SpringBoot几行代码即可实现。基于Spring Boot，不是说原来的配置没有了，而是Spring Boot有一套默认配置，我们可以把它看做比较通用的约定，而Spring Boot遵循的是<strong>约定优于配置</strong>原则，同时，如果你需要使用到Spring以往提供的各种复杂但功能强大的配置功能，Spring Boot一样支持。</p><p>在Spring Boot中，你会发现引入的所有包都是starter形式，如：</p><ul><li>spring-boot-starter-web-services，针对SOAP Web Services</li><li>spring-boot-starter-web，针对Web应用与网络接口</li><li>spring-boot-starter-jdbc，针对JDBC</li><li>spring-boot-starter-cache，针对缓存支持</li></ul><p>Spring Boot是基于 Spring 框架开发的用于开发 Web 应用程序的框架，它帮助开发人员快速搭建和配置一个独立的、可执行的、基于 Spring 的应用程序，从而减少了繁琐和重复的配置工作。</p><h4>Spring Cloud</h4><p>Spring Cloud事实上是一整套基于Spring Boot的微服务解决方案。它为开发者提供了很多工具，用于快速构建分布式系统的一些通用模式，例如：配置管理、注册中心、服务发现、限流、网关、链路追踪等。Spring Boot是build anything，而Spring Cloud是coordinate anything，Spring Cloud的每一个微服务解决方案都是基于Spring Boot构建的。</p><h4>SpringBoot和SpringCloud的区别？</h4><p>SpringBoot专注于快速方便得开发单个个体微服务。</p><p>SpringCloud是关注全局的微服务协调整理治理框架，它将SpringBoot开发的一个个单体微服务整合并管理起来，为各个微服务之间提供，配置管理、服务发现、。断路器、路由、微代理、事件总线、全局锁、决策竞选、分布式会话等等集成服务</p><p>SpringBoot可以离开SpringCloud独立使用开发项目， 但是SpringCloud离不开SpringBoot ，属于依赖的关系.</p><p>SpringBoot专注于快速、方便得开发单个微服务个体，SpringCloud关注全局的服务治理框架。</p><h3>Spring Cloud各个微服务之间为什么要用http交互？难道不慢吗？</h3><p>Spring Cloud是一个为分布式微服务架构构建应用程序的开发工具箱，是Spring Boot的扩展，通过各种微服务组件的集成，极大地简化了微服务应用程序的构建和开发。在分布式系统中，各个微服务之间的通信是非常重要的，而HTTP作为通信协议具有普遍性和可扩展性，是Spring Cloud微服务架构中主流的通信方式。</p><p>尽管使用HTTP作为微服务之间的通信协议存在一定的网络开销，但是这种不可避免的网络开销远低于我们所能得到的好处。使用HTTP通信可以实现松耦合和异步通信，微服务之间可以彼此独立地进行开发和测试，单个微服务的故障不会影响整个系统的运行，也可以支持各种不同的技术栈之间的互操作性。</p><p>另外，使用HTTP作为通信协议还具有优秀的可扩展性。HTTP协议定义了不同的请求方法（例如 GET、POST、DELETE 等），不同请求方法的扩展格式也很灵活，可以用来传递各种类型的数据和格式，同时HTTP协议支持缓存，减少重复性的数据传输和带宽开销。</p><p>当然，为了提高微服务之间的通信效率，我们也可以通过一些优化手段来减少HTTP协议的网络开销。例如，使用数据压缩和缓存技术来压缩和缓存请求和响应，减少网络数据传输量和响应时间；使用负载均衡技术来合理地分配请求和响应，避免单个微服务出现性能瓶颈；使用高速缓存技术来缓存请求和响应，避免重复的请求和响应等等。</p><p>因此，Spring Cloud各个微服务之间使用HTTP交互是一个比较成熟的选择。虽然它可能存在一些网络开销，但是在实际应用中，这种开销是可以优化和控制的，甚至可以提高系统的可扩展性和可靠性。</p><h2>注册中心</h2><h3>注册中心是用来干什么的？</h3><p>注册中心是用来管理和维护分布式系统中各个服务的地址和元数据的组件。它主要用于实现服务发现和服务注册功能。</p><p>总结一下注册中心的作用：</p><ul><li>服务注册：各个服务在启动时向注册中心注册自己的网络地址、服务实例信息和其他相关元数据。这样，其他服务就可以通过注册中心获取到当前可用的服务列表。</li><li>服务发现：客户端通过向注册中心查询特定服务的注册信息，获得可用的服务实例列表。这样客户端就可以根据需要选择合适的服务进行调用，实现了服务间的解耦。</li><li>负载均衡：注册中心可以对同一服务的多个实例进行负载均衡，将请求分发到不同的实例上，提高整体的系统性能和可用性。</li><li>故障恢复：注册中心能够监测和检测服务的状态，当服务实例发生故障或下线时，可以及时更新注册信息，从而保证服务能够正常工作。</li><li>服务治理：通过注册中心可以进行服务的配置管理、动态扩缩容、服务路由、灰度发布等操作，实现对服务的动态管理和控制。</li></ul><h3>为什么需要服务注册发现?</h3><p>在分布式系统中，服务的数量通常会有很多，而且规模还不是一般地大，与此同时，服务的部署和变化也会很频繁，因此，如果要依赖人工去维护这些服务的关系，实现服务的管理以及调用就会变得非常困难。</p><p>服务注册与发现的作用就是为了解决这个问题，它通过注册中心来维护服务生产者以及服务消费者之间的关系。当服务启动之后，其就会向注册中心注册自己的信息，比如服务名称、服务端口、服务的P地址等，当服务消费者需要调用某个服务的时候，它会向注册中心发起查询请求，获取对应服务的信息，然后向生产者服务发送请求。如果一些服务上线或者下线，注册中心都可以主动通知消费者，这就动态地实现了服务的上下线，在高峰期加机器，低峰期减机器，减少了管理的成本，十分方便。也可以方便实现服务的监控、管理等等。</p><h3>SpringCloud可以选择哪些注册中心？</h3><p>SpringCloud可以与多种注册中心进行集成，常见的注册中心包括：</p><ul><li>Eureka：Eureka 是 Netflix 开源的服务发现框架，具有高可用、弹性、可扩展等特点，并与 Spring Cloud 集成良好，已闭源。ap</li><li>Consul：Consul 是一种分布式服务发现和配置管理系统，由 HashiCorp 开发。它提供了服务注册、服务发现、健康检查、键值存储等功能，并支持多数据中心部署。c/ap</li><li>ZooKeeper：ZooKeeper 是 Apache 基金会开源的分布式协调服务，可以用作服务注册中心。它具有高可用、一致性、可靠性等特点。 cp</li><li>Nacos：Nacos 是阿里巴巴开源的一个动态服务发现、配置管理和服务管理平台。它提供了服务注册和发现、配置管理、动态 DNS 服务等功能。 ap</li><li>etcd：etcd 是 CoreOS 开源的一种分布式键值存储系统，可以被用作服务注册中心。它具有高可用、强一致性、分布式复制等特性。 cp</li></ul><h3>什么是 Eureka?</h3><p>Eureka 是一个 Spring Cloud Netflix 的一款老牌注册中心，设计用于实现云端部署微服务架构中的服务注册与发现功能。</p><p>在技术领域，特别是分布式系统中，Eureka作为一个基于 RESTFul 的服务，主要职责包括:</p><ul><li>服务注册：允许服务实例向 EurekaServer 注册自己的信息。这样，每个服务实例都能让 Eureka Server 获取到自身服务以及地址等信息。</li><li>服务发现：Eureka客户端可以从 Eureka server 查询到注册的服务实例信息，进而实现客户端的软负载均像和故障转移。服务消费者可以查询 Eureka Sener 获取到提供某一服务的所有服务实例列表，然后根据策略选择一个实例进行通信。</li><li>健康检查：Eureka 通过心跳机制监控服务实例的状态，确保服务列表的时效性和)准确性，如果某个服务实例宕机或天法响应，Eureka Senver将从注册表中移除该实例，避免了将流量导向不可用的服务(默认 90s)。</li><li>高可用性：Eureka 通过部署多个 Eureka Server 实例并相互复制注册信息，可以构建高可用的服务注册中心集群，提高系统的整体稳定性。</li></ul><p>在 Spring Cloud 中，Eureka 被集成作为服务注册与服务发现的核心组件,通过 @EnableEurekaServer 和 @EnableEurekaClient 注解可以轻松实现服务注册中心或服务客户端</p><p>Eureka 在2020年后 Netflix 宣布不再积极维护，但它仍然是许多现有系统中服务注册中心的实现方案，并目有社区进行维护，</p><h3>Spring Cloud如何实现服务的注册?</h3><p>服务发布时，指定对应的服务名，将服务注册到 注册中心(<code>Eureka 、Zookeeper)</code>。</p><p>注册中心加<code>@EnableEurekaServer</code>，服务用<code>@EnableDiscoveryClient</code>，然后用ribbon或feign进行服务直接的调用发现。</p><h3>说下Eureka、ZooKeeper、Nacos的区别？</h3><table><thead><tr><th>特性</th><th>Eureka</th><th>ZooKeeper</th><th>Nacos</th></tr></thead><tbody><tr><td>开发公司</td><td>Netflix</td><td>Apache 基金会</td><td>阿里巴巴</td></tr><tr><td>CAP</td><td>AP（可用性和分区容忍性）</td><td>CP（一致性和分区容忍性）</td><td>既支持AP，也支持CP</td></tr><tr><td>功能</td><td>服务注册与发现</td><td>分布式协调、配置管理、分布式锁</td><td>服务注册与发现、配置管理、服务管理</td></tr><tr><td>定位</td><td>适用于构建基于 HTTP 的微服务架构</td><td>通用的分布式协调服务框架</td><td>适用于微服务和云原生应用</td></tr><tr><td>访问协议</td><td>HTTP</td><td>TCP</td><td>HTTP/DNS</td></tr><tr><td>自我保护</td><td>支持</td><td>-</td><td>支持</td></tr><tr><td>数据存储</td><td>内嵌数据库、多个实例形成集群</td><td>ACID 特性的分布式文件系统 ZAB 协议</td><td>内嵌数据库、MySQL 等</td></tr><tr><td>健康检查</td><td>Client Beat</td><td>Keep Alive</td><td>TCP/HTTP/MYSQL/Client Beat</td></tr><tr><td>特点</td><td>简单易用、自我保护机制</td><td>高性能、强一致性</td><td>动态配置管理、流量管理、灰度发布等</td></tr></tbody></table><p>可以看到Eureka和ZooKeeper的最大区别是一个支持AP，一个支持CP，Nacos既支持既支持AP，也支持CP。</p><p>关于CAP相关理论和概念可以看这篇文章：<a href="https://link.segmentfault.com/?enc=fo%2Byg4yJXHgtXxa5wC4AHA%3D%3D.TaOE3LbyYCAVn8rZONfprNzvGURuZ4jB0uthbUx9jVNZ%2FmKF6EXc7vVOdb9CTiNA8k2xqmHnhzhImtyOC9X51g%3D%3D" rel="nofollow" target="_blank">CAPl理论</a></p><ul><li>Nacos除了作为注册中心外，还提供了配置管理、服务发现和事件通知等功能。Nacos默认情况下采用AP架构保证服务可用性，CP架构底层采用Raft协议保证数据的一致性。Nacos适合作为微服务注册中心和配置管理中心，支持快速发现、配置管理和服务治理等功能。</li><li>Eureka是只提供注册中心功能的工具，它的设计理念是AP，即保证服务的可用性，不保证一致性。Eureka的各个节点之间相互注册，只要有一台Eureka节点存在，整个微服务就可以通讯。</li><li>而Zookeeper相比前两者，除了注册中心的功能，还提供了分布式协调服务，比如通知、公告、配置管理等。Zookeeper采用CP设计，可以保证数据的一致性，但是牺牲了一部分服务的可用性。Zookeeper适用于需要分布式协调服务的场景，如配置管理、命名服务等。</li></ul><h3>请说说Eureka和zookeeper 的区别？</h3><p>Zookeeper保证了CP，Eureka保证了AP。</p><p>CAP理论详情请看<a href="https://link.segmentfault.com/?enc=xPGWIiCn1kbbb0nH7NAkmw%3D%3D.2u9bX2jC8iryW5thFsuYnf1DFj3vcbwz12OMkL%2Ba%2BijK8esb6U1gsINW7cHUO2qPbKSvHS5UjpW5ZZUAmKnX7A%3D%3D" rel="nofollow" target="_blank">CAP理论</a></p><blockquote><p>A：高可用</p><p>C：一致性</p><p>P：分区容错性</p></blockquote><ol><li>当向注册中心查询服务列表时，我们可以容忍注册中心返回的是几分钟以前的信息，但不能容忍直接down掉不可用。也就是说，服务注册功能对高可用性要求比较高，但zk会出现这样一种情况，当master节点因为网络故障与其他节点失去联系时，剩余节点会重新选leader。问题在于，选取leader时间过长，30 ~ 120s，且选取期间zk集群都不可用，这样就会导致选取期间注册服务瘫痪。在云部署的环境下，因网络问题使得zk集群失去master节点是较大概率会发生的事，虽然服务能够恢复，但是漫长的选取时间导致的注册长期不可用是不能容忍的。</li><li><p>Eureka保证了可用性，Eureka各个节点是平等的，几个节点挂掉不会影响正常节点的工作，剩余的节点仍然可以提供注册和查询服务。而Eureka的客户端向某个Eureka注册或发现时发生连接失败，则会自动切换到其他节点，只要有一台Eureka还在，就能保证注册服务可用，只是查到的信息可能不是最新的。除此之外，Eureka还有自我保护机制，如果在15分钟内超过85%的节点没有正常的心跳，那么Eureka就认为客户端与注册中心发生了网络故障，此时会出现以下几种情况：</p><ol><li>Eureka不在从注册列表中移除因为长时间没有收到心跳而应该过期的服务。</li><li>Eureka仍然能够接受新服务的注册和查询请求，但是不会被同步到其他节点上（即保证当前节点仍然可用）</li><li>当网络稳定时，当前实例新的注册信息会被同步到其他节点。</li></ol></li></ol><p>因此，Eureka可以很好地应对因网络故障导致部分节点失去联系的情况，而不会像Zookeeper那样使整个微服务瘫痪</p><h3>Nacos和Eureka的区别</h3><p>Nacos和Eureka整体结构类似，服务注册、服务拉取、心跳等待，但是也存在一些差异：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047402123" alt="" title=""/></p><ul><li><p>Nacos与eureka的共同点</p><ul><li>都支持服务注册和服务拉取</li><li>都支持服务提供者心跳方式做健康检测</li></ul></li><li><p>Nacos与Eureka的区别</p><ul><li>Nacos支持服务端主动检测提供者状态：临时实例采用心跳模式，非临时实例采用主动检测模式</li><li>临时实例心跳不正常会被剔除，非临时实例则不会被剔除</li><li>Nacos支持服务列表变更的消息推送模式，服务列表更新更及时</li><li>Nacos集群默认采用AP方式，当集群中存在非临时实例时，采用CP模式；Eureka采用AP方式</li></ul></li></ul><h3>Eureka实现原理了解吗？</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047402124" alt="" title="" loading="lazy"/></p><p>Eureka的实现原理，大概可以从这几个方面来看：</p><ol><li>服务注册与发现: 当一个服务实例启动时，它会向Eureka Server发送注册请求，将自己的信息注册到注册中心。Eureka Server会将这些信息保存在内存中，并提供REST接口供其他服务查询。服务消费者可以通过查询服务实例列表来获取可用的服务提供者实例，从而实现服务的发现。</li><li>服务健康检查: Eureka通过心跳机制来检测服务实例的健康状态。服务实例会定期向Eureka Server发送心跳，也就是续约，以表明自己的存活状态。如果Eureka Server在一定时间内没有收到某个服务实例的心跳，则会将其标记为不可用，并从服务列表中移除，下线实例。</li><li>服务负载均衡: Eureka客户端在调用其他服务时，会从本地缓存中获取服务的注册信息。如果缓存中没有对应的信息，则会向Eureka Server发送查询请求。Eureka Server会返回一个可用的服务实例列表给客户端，客户端可以使用负载均衡算法选择其中一个进行调用。</li></ol><p>其它的注册中心，如Nacos、Consul等等，在服务注册和发现上，实现原理都是大同小异。</p><h3>Eureka Server怎么保证高可用？</h3><p>Eureka Server保证高可用，主要通过这三个方面来实现：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047402125" alt="" title="" loading="lazy"/></p><ul><li>多实例部署: 通过将多个Eureka Server实例部署在不同的节点上，可以实现高可用性。当其中一个实例发生故障时，其他实例仍然可以提供服务，并保持注册信息的一致性。</li><li>服务注册信息的复制: 当一个服务实例向Eureka Server注册时，每个Eureka Server实例都会复制其他实例的注册信息，以保持数据的一致性。当某个Eureka Server实例发生故障时，其他实例可以接管其工作，保证整个系统的正常运行。</li><li>自我保护机制: Eureka还具有自我保护机制。当Eureka Server节点在一定时间内没有接收到心跳时，它会进入自我保护模式。在自我保护模式下，Eureka Server不再剔除注册表中的服务实例，以保护现有的注册信息。这样可以防止由于网络抖动或其他原因导致的误剔除，进一步提高系统的稳定性。</li></ul><h3>eureka自我保护机制是什么?</h3><p><strong>什么是自我保护模式</strong>？</p><ol><li>自我保护的条件：一般情况下，微服务在 Eureka 上注册后，会每 30 秒发送心跳包，Eureka 通过心跳来判断服务是否健康，同时会定期删除超过 90 秒没有发送心跳服务。</li><li><p>有两种情况会导致 Eureka Server 收不到微服务的心跳</p><ol><li>是微服务自身的原因</li><li>是微服务与 Eureka 之间的网络故障</li></ol></li></ol><p>通常(微服务的自身的故障关闭)只会导致个别服务出现故障，一般不会出现大面积故障，而(网络故障)通常会导致 Eureka Server 在短时间内无法收到大批心跳。考虑到这个区别，Eureka 设置了一个阀值，当判断挂掉的服务的数量超过阀值时，Eureka Server 认为很大程度上出现了网络故障，将不再删除心跳过期的服务。</p><ol start="3"><li>那么这个阀值是多少呢？</li></ol><p>15 分钟之内是否低于 85%；Eureka Server 在运行期间，会统计心跳失败的比例在 15 分钟内是否低于 85%,这种算法叫做 Eureka Server 的自我保护模式。</p><p><strong>为什么要自我保护</strong>？</p><ol><li>因为同时保留"好数据"与"坏数据"总比丢掉任何数据要更好，当网络故障恢复后，这个 Eureka 节点会退出"自我保护模式"。</li><li>Eureka 还有客户端缓存功能(也就是微服务的缓存功能)。即便 Eureka 集群中所有节点都宕机失效，微服务的 Provider 和 Consumer都能正常通信。</li><li>微服务的负载均衡策略会自动剔除死亡的微服务节点。</li></ol><h3>Consul是什么?</h3><p>Consul 是 HasiCorp 公司用 Golang 开发的一款开源的服务注册中心以及配置中心，提供了服务注册与发现、健康检查、KV 存储、多数据中心支持、DNS 和 HTTP API 接口等功能，而且提供了可视化控制台用于操作。</p><p>Consul 的优点有很多</p><ul><li>基于 Raft 协议，比较简洁</li><li>支持简单检查，同时支持 HTTP 和 DNS 协议</li><li>支持跨数据中心的 WAN 集群</li><li>提供了跨平台的图形化界面，支持 Windows、Linux、Mac 等系统</li></ul><h3>单体服务拆成多个微服务，这些服务之间如何自动发现彼此?具体原理是什么?</h3><p>这些微服务之间一般需要借助注册中心，然后通过服务发现机制定位彼此。</p><p>核心原理是：服务启动时将自己的地址和元数据注册到注册中心(Nacos、Consul)，调用方通过注册中心动态获取可用服务实例列表，然后基于负载均衡策略(如轮询、随机)发起请求。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047402126" alt="" title="" loading="lazy"/></p><p>整个过程还得依赖心跳检测确保实例状态实时更新，例如老服务的下线，新服务的上线。</p><p>每个微服务启动后，会向注册中心(如Nacos、Consul)发送自己的信息(IP、端口、服务名等)，告诉注册中心“我上线了”</p><p>注册中心会存储所有已注册服务的信息，并通过心跳检测(如每隔5秒发一次“我还活着”)监控服务状态，若某服务超过一定时间没心跳，注册中心会标记它为“下线”</p><p>当服务 A需要调用服务B时，会向注册中心查询服务 B的所有可用实例(IP+端口)，然后从这些实例中选一个(如轮询、随机)发起请求。</p>]]></description></item><item>    <title><![CDATA[RimWorld NPC AI 系统深度]]></title>    <link>https://segmentfault.com/a/1190000047403431</link>    <guid>https://segmentfault.com/a/1190000047403431</guid>    <pubDate>2025-11-16 23:03:26</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>引言：AI系统概述</h2><p>RimWorld 的 NPC AI 系统是一个多层次、模块化的智能决策框架。与传统的单一 AI 系统不同，RimWorld 将 AI 功能分解为五个相互协作的层次，每一层负责不同的职责，共同实现 NPC 的复杂行为。</p><h3>系统架构概览</h3><pre><code class="log">┌─────────────────────────────────────────────────────────┐
│  第五层：战斗决策层 (AttackTargetFinder)                   │
│  - 目标评分与选择                                         │
└─────────────────────────────────────────────────────────┘
                    ↓
┌─────────────────────────────────────────────────────────┐
│  第四层：群体协调层 (Lord System)                          │
│  - 状态机驱动的群体行为                                    │
└─────────────────────────────────────────────────────────┘
                    ↓
┌─────────────────────────────────────────────────────────┐
│  第三层：工作执行层 (Job System)                           │
│  - Job/Toil 任务执行框架                                  │
└─────────────────────────────────────────────────────────┘
                    ↓
┌─────────────────────────────────────────────────────────┐
│  第二层：路径导航层 (PathFinder)                           │
│  - A* 路径查找算法                                        │
└─────────────────────────────────────────────────────────┘
                    ↓
┌─────────────────────────────────────────────────────────┐
│  第一层：思考决策层 (ThinkTree)                            │
│  - 决策树驱动的行为选择                                    │
└─────────────────────────────────────────────────────────┘</code></pre><p>每一层都有其独特的职责，但它们并非孤立工作，而是通过精心设计的接口相互协作，形成一个完整的 AI 决策和执行系统。</p><h3>核心设计理念</h3><ol><li><strong>分层解耦</strong>：每一层专注于特定功能，降低系统复杂度</li><li><strong>优先级驱动</strong>：决策基于优先级，确保重要行为优先执行</li><li><strong>状态管理</strong>：通过状态机管理复杂的行为转换</li><li><strong>性能优化</strong>：使用启发式算法和缓存机制提升性能</li></ol><hr/><h2>第一层：思考决策层（ThinkTree 系统）</h2><p>思考决策层是 AI 系统的"大脑"，负责决定 NPC 应该做什么。它采用决策树（Decision Tree）结构，通过遍历节点来找到合适的行动。</p><h3>核心概念</h3><h4>ThinkNode（思考节点）</h4><p>ThinkNode 是决策树的基本单元，每个节点代表一个决策点或行为生成器。节点可以包含子节点，形成树状结构。</p><p><strong>节点类型</strong>：</p><ul><li><strong>ThinkNode_Priority</strong>：优先级节点，按顺序尝试子节点，返回第一个有效结果</li><li><strong>ThinkNode_JobGiver</strong>：工作生成器，负责创建具体的 Job</li><li><strong>ThinkNode_Conditional</strong>：条件节点，根据条件决定是否执行子节点</li><li><strong>ThinkNode_Subtree</strong>：子树节点，引用另一个思考树</li></ul><h4>ThinkTree（思考树）</h4><p>ThinkTree 定义了 NPC 的完整决策逻辑。每个 NPC 拥有两个思考树：</p><ul><li><strong>MainThinkTree</strong>：主要思考树，处理常规行为决策</li><li><strong>ConstantThinkTree</strong>：常量思考树，处理需要持续检查的行为（如紧急情况）</li></ul><h3>决策流程</h3><p>思考树的遍历遵循以下逻辑：</p><pre><code>function TryIssueJobPackage(pawn, jobParams):
    for each childNode in subNodes:
        result = childNode.TryIssueJobPackage(pawn, jobParams)
        if result.IsValid:
            return result
    return NoJob</code></pre><p><strong>关键特点</strong>：</p><ul><li><strong>优先级顺序</strong>：子节点按顺序评估，高优先级节点在前</li><li><strong>短路机制</strong>：一旦找到有效结果，立即返回，不再评估后续节点</li><li><strong>异常处理</strong>：单个节点异常不会影响整个决策流程</li></ul><h3>实际示例</h3><p>假设一个 NPC 需要决定下一步行动，思考树可能是这样的结构：</p><pre><code>ThinkNode_Priority (根节点)
├── ThinkNode_Conditional (检查是否有敌人)
│   └── ThinkNode_JobGiver_Attack (攻击敌人)
├── ThinkNode_Conditional (检查是否饥饿)
│   └── ThinkNode_JobGiver_Food (寻找食物)
├── ThinkNode_Conditional (检查是否需要休息)
│   └── ThinkNode_JobGiver_Rest (去休息)
└── ThinkNode_JobGiver_Wander (闲逛)</code></pre><p>NPC 会从上到下依次检查：</p><ol><li>如果有敌人 → 攻击</li><li>如果饥饿 → 找食物</li><li>如果需要休息 → 去休息</li><li>否则 → 闲逛</li></ol><h3>JobGiver 机制</h3><p>JobGiver 是连接思考层和执行层的桥梁。它负责：</p><ol><li>评估当前情况</li><li>决定是否应该生成某个 Job</li><li>创建并返回 Job 对象</li></ol><pre><code>class JobGiver_Attack:
    function TryGiveJob(pawn):
        target = FindBestTarget(pawn)
        if target == null:
            return null
        return CreateAttackJob(pawn, target)</code></pre><hr/><h2>第二层：路径导航层（PathFinder 系统）</h2><p>路径导航层负责计算 NPC 从当前位置到目标位置的移动路径。RimWorld 使用改进的 A* 算法来实现高效的路径查找。</p><h3>A* 算法基础</h3><p>A* 算法结合了 Dijkstra 算法的准确性（考虑实际成本）和贪心算法的效率（使用启发式估计）。</p><p><strong>核心公式</strong>：</p><pre><code>f(n) = g(n) + h(n)</code></pre><ul><li><code>g(n)</code>：从起点到节点 n 的实际成本</li><li><code>h(n)</code>：从节点 n 到终点的启发式估计成本</li><li><code>f(n)</code>：节点的总评估成本</li></ul><h3>RimWorld 的路径查找实现</h3><h4>成本计算</h4><p>路径查找会考虑多种因素来计算移动成本：</p><pre><code>function CalculateCellCost(cell, pawn):
    baseCost = GetTerrainCost(cell)           // 地形基础成本
    buildingCost = GetBuildingCost(cell)      // 建筑成本（门、墙等）
    avoidCost = GetAvoidGridCost(cell)        // 避让区域成本
    areaCost = GetAreaRestrictionCost(cell)   // 区域限制成本
    collisionCost = GetPawnCollisionCost(cell) // NPC碰撞成本
    
    return baseCost + buildingCost + avoidCost + areaCost + collisionCost</code></pre><p><strong>特殊处理</strong>：</p><ul><li><strong>门</strong>：根据是否可以打开、是否需要破坏来计算成本</li><li><strong>墙</strong>：如果允许破坏，成本 = 基础成本 + 墙体血量 × 系数</li><li><strong>避让网格</strong>：避免危险区域（如炮火覆盖区）</li></ul><h4>启发式函数</h4><p>RimWorld 使用八方向距离（Octile Distance）作为启发式：</p><pre><code>function OctileDistance(dx, dz, cardinalCost, diagonalCost):
    // dx, dz: x和z方向的差值
    // cardinalCost: 直线移动成本
    // diagonalCost: 斜线移动成本
    
    if dx &gt; dz:
        return diagonalCost * dz + cardinalCost * (dx - dz)
    else:
        return diagonalCost * dx + cardinalCost * (dz - dx)</code></pre><p><strong>启发式强度</strong>：</p><ul><li>动物：固定系数 1.75</li><li>人类：根据距离动态调整（距离越远，系数越大，最高 2.8）</li></ul><h4>区域路径优化</h4><p>当搜索节点数超过阈值时（殖民者 100,000，非殖民者 2,000），系统会切换到区域级路径查找：</p><pre><code>if nodesOpened &gt; threshold:
    // 切换到区域级路径查找
    regionCost = CalculateRegionPathCost(currentRegion, targetRegion)
    heuristic = regionCost * regionWeight</code></pre><p>这种优化可以显著减少大距离路径查找的计算量。</p><h3>路径执行</h3><p>找到路径后，<code>Pawn_PathFollower</code> 负责执行移动：</p><pre><code>function PatherTick():
    if WillCollideWithPawn(nextCell):
        if CanFindAlternatePath():
            RecalculatePath()
        else:
            WaitForPawn()
    
    if nextCellCostLeft &gt; 0:
        nextCellCostLeft -= CostToPayThisTick()
    else:
        MoveToNextCell()
        SetupNextCell()</code></pre><p><strong>移动速度控制</strong>：</p><ul><li><strong>Amble（漫步）</strong>：成本 × 3，最小 60 ticks</li><li><strong>Walk（步行）</strong>：成本 × 2，最小 50 ticks</li><li><strong>Jog（慢跑）</strong>：成本 × 1</li><li><strong>Sprint（冲刺）</strong>：成本 × 0.75</li></ul><hr/><h2>第三层：工作执行层（Job 系统）</h2><p>工作执行层将抽象的"做什么"转化为具体的"怎么做"。它通过 Job、JobDriver 和 Toil 三个层次来实现任务的执行。</p><h3>核心组件</h3><h4>Job（工作）</h4><p>Job 是任务的抽象描述，包含：</p><ul><li><strong>JobDef</strong>：工作类型定义（如攻击、建造、搬运）</li><li><strong>TargetA/B/C</strong>：工作目标（位置、物体、NPC等）</li><li><strong>expiryInterval</strong>：过期时间</li><li><strong>playerForced</strong>：是否玩家强制</li></ul><h4>JobDriver（工作驱动）</h4><p>JobDriver 负责执行 Job，它包含一系列 Toil（工作步骤）：</p><pre><code>class JobDriver_AttackMelee:
    function MakeNewToils():
        toils = []
        
        // Toil 1: 移动到目标附近
        toils.Add(Toils_Goto.Goto(TargetIndex.A, PathEndMode.Touch))
        
        // Toil 2: 等待直到可以攻击
        toils.Add(Toils_Combat.WaitUntilSuitableToAttack(TargetIndex.A))
        
        // Toil 3: 执行近战攻击
        toils.Add(Toils_Combat.MeleeAttack(TargetIndex.A))
        
        // Toil 4: 跳回 Toil 2（循环攻击）
        toils.Add(Toils_Jump.JumpIf(TargetIndex.A, IsValid, toils[1]))
        
        return toils</code></pre><h4>Toil（工作步骤）</h4><p>Toil 是最小的执行单元，每个 Toil 代表一个原子操作：</p><pre><code>Toil {
    initAction:      // 初始化时执行
    tickAction:      // 每 tick 执行
    endConditions:   // 结束条件检查
    defaultDuration: // 默认持续时间
    defaultCompleteMode: // 完成模式
}</code></pre><p><strong>完成模式</strong>：</p><ul><li><strong>Instant</strong>：立即完成</li><li><strong>Delay</strong>：延迟指定时间后完成</li><li><strong>PatherArrival</strong>：到达路径终点时完成</li><li><strong>FinishedBusy</strong>：忙碌状态结束时完成</li></ul><h3>工作执行流程</h3><pre><code>function JobTrackerTick():
    // 每 30 ticks 检查常量思考树
    if IsHashIntervalTick(30):
        constantJob = DetermineConstantThinkTreeJob()
        if constantJob.IsValid:
            StartJob(constantJob)
    
    // 执行当前工作
    if curDriver != null:
        curDriver.DriverTick()
        
        // 检查工作是否过期
        if curJob.IsExpired():
            EndCurrentJob(JobCondition.Succeeded)
    
    // 如果没有工作，寻找新工作
    if curJob == null:
        TryFindAndStartJob()</code></pre><h3>工作队列</h3><p>NPC 可以维护一个工作队列，支持：</p><ul><li><strong>EnqueueFirst</strong>：插入队列头部（高优先级）</li><li><strong>EnqueueLast</strong>：插入队列尾部（低优先级）</li><li><strong>Dequeue</strong>：取出下一个工作</li></ul><p>这允许玩家为 NPC 安排多个连续任务。</p><h3>工作中断与恢复</h3><p>工作可能因为以下原因中断：</p><ul><li><strong>更高优先级的工作</strong>：思考树生成新工作</li><li><strong>工作条件失效</strong>：目标消失、不可达等</li><li><strong>玩家强制</strong>：玩家手动分配新工作</li></ul><p>中断的工作可以：</p><ul><li><strong>完全取消</strong>：释放所有资源</li><li><strong>暂停并排队</strong>：如果工作可暂停，加入队列等待恢复</li></ul><hr/><h2>第四层：群体协调层（Lord 系统）</h2><p>群体协调层管理多个 NPC 的协同行为，如袭击、商队、防御等。它使用状态机（State Machine）来协调群体行为。</p><h3>核心概念</h3><h4>Lord（领主）</h4><p>Lord 代表一个群体，管理：</p><ul><li><strong>ownedPawns</strong>：属于该群体的 NPC 列表</li><li><strong>ownedBuildings</strong>：属于该群体的建筑列表</li><li><strong>curLordToil</strong>：当前状态</li><li><strong>graph</strong>：状态图</li></ul><h4>LordJob（领主工作）</h4><p>LordJob 定义群体的整体目标，如：</p><ul><li><strong>LordJob_DefendPoint</strong>：防御某个点</li><li><strong>LordJob_Travel</strong>：旅行</li><li><strong>LordJob_ExitMap</strong>：离开地图</li></ul><h4>LordToil（领主状态）</h4><p>LordToil 是状态机中的状态节点，定义群体在该状态下应该做什么：</p><pre><code>class LordToil_DefendPoint:
    function UpdateAllDuties():
        for each pawn in ownedPawns:
            duty = CreateDefendDuty(pawn, defendPoint)
            pawn.mindState.duty = duty</code></pre><h4>StateGraph（状态图）</h4><p>StateGraph 定义状态之间的转换关系：</p><pre><code>StateGraph {
    lordToils: [Toil1, Toil2, Toil3]
    transitions: [
        Transition(Toil1 -&gt; Toil2, [Trigger1, Trigger2]),
        Transition(Toil2 -&gt; Toil3, [Trigger3])
    ]
}</code></pre><h4>Trigger（触发器）</h4><p>Trigger 定义状态转换的条件：</p><pre><code>class Trigger_FractionPawnsLost:
    threshold: 0.5  // 50% 的 NPC 失去战斗力
    
    function CheckSignal(lord, signal):
        if signal.type == PawnLost:
            lostFraction = lord.numPawnsLostViolently / lord.numPawnsEverGained
            return lostFraction &gt;= threshold</code></pre><h3>状态转换流程</h3><pre><code>function LordTick():
    curJob.LordJobTick()
    curLordToil.LordToilTick()
    
    // 检查所有从当前状态出发的转换
    for each transition in graph.transitions:
        if transition.sources.Contains(curLordToil):
            if transition.CheckSignal(this, currentSignal):
                // 执行转换前的动作
                transition.preActions.Execute()
                
                // 转换到新状态
                GotoToil(transition.target)
                break</code></pre><h3>实际示例：袭击事件</h3><p>一个典型的袭击事件状态机：</p><pre><code>初始状态: LordToil_AssaultColony
├── Trigger: 50% NPC 失去战斗力
│   └── 转换到: LordToil_PanicFlee
│
├── Trigger: 所有目标建筑被摧毁
│   └── 转换到: LordToil_ExitMap
│
└── Trigger: 玩家投降
    └── 转换到: LordToil_ExitMap</code></pre><p>每个状态会为所有 NPC 设置相应的 Duty（职责），NPC 的思考树会根据 Duty 调整行为优先级。</p><hr/><h2>第五层：战斗决策层（AttackTargetFinder）</h2><p>战斗决策层负责在战斗中选择最佳攻击目标。它使用评分系统来评估每个潜在目标。</p><h3>目标选择流程</h3><pre><code>function BestAttackTarget(searcher, flags, validator):
    // 1. 获取所有潜在目标
    candidates = GetPotentialTargets(searcher)
    
    // 2. 过滤不符合条件的目标
    validTargets = FilterTargets(candidates, flags, validator)
    
    // 3. 计算每个目标的评分
    scoredTargets = []
    for each target in validTargets:
        score = CalculateTargetScore(searcher, target)
        scoredTargets.Add((target, score))
    
    // 4. 根据评分选择目标
    return SelectBestTarget(scoredTargets)</code></pre><h3>目标过滤条件</h3><p>目标必须满足以下条件才能被考虑：</p><ol><li><strong>敌对关系</strong>：必须是敌对目标</li><li><strong>距离范围</strong>：在攻击范围内</li><li><strong>视线</strong>：如果需要，必须有视线</li><li><strong>威胁状态</strong>：目标必须是活跃威胁</li><li><strong>可达性</strong>：如果要求，目标必须可达</li></ol><h3>评分系统</h3><p>评分考虑多个因素：</p><pre><code>function CalculateTargetScore(searcher, target):
    score = 0
    
    // 基础威胁值
    score += target.ThreatValue
    
    // 距离因子（越近分数越高）
    distance = Distance(searcher, target)
    score += 1.0 / (distance + 1.0) * distanceWeight
    
    // 目标类型偏好
    if target.IsPawn:
        score += pawnTargetBonus
    if target.IsBuilding:
        score += buildingTargetBonus
    
    // 友军误伤惩罚
    friendlyFireRisk = CalculateFriendlyFireRisk(searcher, target)
    score -= friendlyFireRisk * friendlyFirePenalty
    
    // 目标当前状态
    if target.IsDowned:
        score -= downedPenalty
    if target.IsBurning:
        score -= burningPenalty
    
    return score</code></pre><p><strong>友军误伤计算</strong>：</p><ul><li>人类/机械：每个 +18 分惩罚</li><li>动物：每个 +7 分惩罚</li><li>非 NPC 物体：每个 +10 分惩罚</li><li>自己：+40 分惩罚</li></ul><h3>远程 vs 近战</h3><p>系统会根据攻击类型采用不同的选择策略：</p><p><strong>远程攻击</strong>：</p><ul><li>优先选择可以立即射击的目标</li><li>考虑射击位置（CastPosition）</li><li>评估友军误伤风险</li></ul><p><strong>近战攻击</strong>：</p><ul><li>优先选择距离最近的目标</li><li>考虑移动成本</li><li>评估近战威胁等级</li></ul><hr/><h2>层次间协作机制</h2><p>五个层次并非独立工作，而是通过精心设计的接口相互协作。下面详细说明它们如何协同工作。</p><h3>思考层 → 工作层</h3><p>思考层通过 JobGiver 生成 Job，传递给工作层：</p><pre><code>ThinkTree 遍历
    ↓
JobGiver.TryGiveJob()
    ↓
创建 Job 对象
    ↓
JobTracker.StartJob()
    ↓
创建 JobDriver
    ↓
执行 Toil 序列</code></pre><p><strong>示例</strong>：NPC 决定攻击敌人</p><ol><li>ThinkTree 遍历到 <code>ThinkNode_JobGiver_Attack</code></li><li>JobGiver 调用 <code>AttackTargetFinder.BestAttackTarget()</code> 找到目标</li><li>创建 <code>Job_AttackMelee</code>，目标设置为找到的敌人</li><li>JobTracker 创建 <code>JobDriver_AttackMelee</code></li><li>JobDriver 开始执行攻击 Toil</li></ol><h3>工作层 → 路径层</h3><p>当工作需要移动时，会调用路径查找：</p><pre><code>JobDriver.Toil_Goto
    ↓
pawn.pather.StartPath(destination)
    ↓
PathFinder.FindPath()
    ↓
返回 PawnPath
    ↓
Pawn_PathFollower 执行移动</code></pre><p><strong>示例</strong>：NPC 执行"去攻击"工作</p><ol><li>JobDriver 的第一个 Toil 是 <code>Toils_Goto.Goto(target)</code></li><li>Toil 调用 <code>pawn.pather.StartPath(target.Position)</code></li><li>PathFinder 计算路径</li><li>PathFollower 每 tick 移动一步</li></ol><h3>群体层 → 思考层</h3><p>群体层通过 Duty 影响思考层的决策：</p><pre><code>Lord 设置 Duty
    ↓
pawn.mindState.duty = newDuty
    ↓
ThinkTree 中的条件节点检查 Duty
    ↓
根据 Duty 调整行为优先级</code></pre><p><strong>示例</strong>：袭击事件中的 NPC</p><ol><li>Lord 处于 <code>LordToil_AssaultColony</code> 状态</li><li>为所有 NPC 设置 <code>PawnDuty</code>，duty.focus = 玩家基地</li><li>NPC 的思考树中有 <code>ThinkNode_Conditional_HasDuty</code></li><li>该节点激活，NPC 优先执行与 Duty 相关的行为（攻击、破坏等）</li></ol><h3>战斗层 → 工作层</h3><p>战斗层为工作层提供目标选择服务：</p><pre><code>JobGiver 需要攻击目标
    ↓
调用 AttackTargetFinder.BestAttackTarget()
    ↓
返回最佳目标
    ↓
创建攻击 Job</code></pre><h3>完整协作流程示例</h3><p>假设一个 NPC 参与袭击事件，需要攻击玩家基地：</p><pre><code>1. 群体层（Lord）：
   - Lord 处于 "AssaultColony" 状态
   - 为 NPC 设置 Duty：攻击玩家基地

2. 思考层（ThinkTree）：
   - 检查 Duty，发现需要攻击
   - JobGiver_Attack 被激活

3. 战斗层（AttackTargetFinder）：
   - JobGiver 调用 BestAttackTarget()
   - 找到最佳攻击目标（玩家 NPC）

4. 工作层（Job）：
   - 创建 Job_AttackMelee
   - JobDriver 开始执行

5. 路径层（PathFinder）：
   - JobDriver 的第一个 Toil 需要移动到目标
   - 调用 PathFinder 计算路径
   - PathFollower 执行移动

6. 工作层继续：
   - 到达目标后，执行攻击 Toil
   - 循环攻击直到目标死亡或工作被中断

7. 群体层监控：
   - 如果 NPC 死亡，Lord 收到通知
   - 检查是否触发状态转换（如撤退）</code></pre><hr/><h2>实际案例：完整行为流程</h2><p>让我们通过一个完整的游戏场景来理解整个 AI 系统如何协同工作。</p><h3>场景：NPC 袭击玩家基地</h3><h4>阶段 1：袭击开始</h4><p><strong>群体层初始化</strong>：</p><pre><code>Lord 创建
├── LordJob = LordJob_AssaultColony
├── 初始状态 = LordToil_AssaultColony
└── 添加所有袭击者 NPC 到 ownedPawns</code></pre><p><strong>为每个 NPC 设置 Duty</strong>：</p><pre><code>for each pawn in ownedPawns:
    duty = new PawnDuty {
        def = DutyDefOf.AssaultColony,
        focus = playerBaseCenter,
        radius = 50
    }
    pawn.mindState.duty = duty</code></pre><h4>阶段 2：NPC 决策</h4><p><strong>思考树遍历</strong>（以袭击者 NPC 为例）：</p><pre><code>ThinkNode_Priority (根节点)
├── ThinkNode_Conditional_HasDuty
│   ├── 检查：pawn.mindState.duty != null ✓
│   └── ThinkNode_SubtreesByTag
│       └── 根据 Duty 类型加载相应子树
│           └── ThinkNode_JobGiver_Attack
│               ├── 调用 AttackTargetFinder.BestAttackTarget()
│               ├── 找到目标：玩家 NPC "Alice"
│               └── 返回 Job_AttackMelee(Alice)</code></pre><h4>阶段 3：目标选择</h4><p><strong>AttackTargetFinder 工作流程</strong>：</p><pre><code>1. 获取所有潜在目标
   candidates = [玩家NPC1, 玩家NPC2, 炮塔1, 建筑1, ...]

2. 过滤目标
   - 检查敌对关系 ✓
   - 检查距离（在武器射程内）✓
   - 检查视线 ✓
   - 检查威胁状态 ✓
   validTargets = [玩家NPC1, 玩家NPC2, 炮塔1]

3. 计算评分
   玩家NPC1: 威胁值=50, 距离=20, 误伤风险=0 → 总分=70
   玩家NPC2: 威胁值=45, 距离=25, 误伤风险=18 → 总分=52
   炮塔1: 威胁值=60, 距离=30, 误伤风险=0 → 总分=60

4. 选择最佳目标
   返回：玩家NPC1（分数最高）</code></pre><h4>阶段 4：工作执行</h4><p><strong>Job 创建与启动</strong>：</p><pre><code>Job job = new Job_AttackMelee {
    targetA = 玩家NPC1,
    maxNumMeleeAttacks = -1,  // 无限攻击
    expiryInterval = -1
}

JobTracker.StartJob(job)</code></pre><p><strong>JobDriver 执行 Toil 序列</strong>：</p><pre><code>Toil 1: Toils_Goto.Goto(targetA, PathEndMode.Touch)
├── 调用 pawn.pather.StartPath(玩家NPC1.Position)
├── PathFinder 计算路径
│   ├── 起点：袭击者位置 (100, 0, 50)
│   ├── 终点：玩家NPC1位置 (150, 0, 80)
│   ├── 路径：[(100,0,50) → (110,0,55) → ... → (150,0,80)]
│   └── 总成本：450 ticks
└── PathFollower 开始移动

Toil 2: Toils_Combat.WaitUntilSuitableToAttack(targetA)
├── 检查：是否到达目标附近？
├── 检查：目标是否仍然有效？
└── 等待直到条件满足

Toil 3: Toils_Combat.MeleeAttack(targetA)
├── 执行近战攻击动画
├── 计算伤害
│   ├── 基础伤害值（根据武器和 NPC 属性）
│   ├── 随机因子（0.8 - 1.2 倍）
│   ├── 护甲穿透值
│   └── 伤害类型（切割、钝击、刺击等）
├── 应用伤害到目标
│   ├── 检查是否命中（考虑命中率）
│   ├── 检查是否被闪避
│   ├── 如果命中：调用 target.TakeDamage(damageInfo)
│   ├── 更新战斗日志
│   └── 播放音效和视觉效果
└── 跳回 Toil 2（循环攻击）</code></pre><h4>阶段 5：状态更新与反馈</h4><p><strong>工作完成检查</strong>：</p><pre><code>每 tick 检查：
├── 目标是否死亡？ → 结束工作
├── 目标是否离开地图？ → 结束工作
├── 工作是否过期？ → 结束工作
└── 否则继续攻击循环</code></pre><p><strong>群体层状态更新</strong>：</p><pre><code>Lord 监控：
├── 统计伤亡情况
├── 检查触发条件
│   ├── 如果 50% NPC 失去战斗力 → 触发撤退
│   ├── 如果目标完成 → 触发离开地图
│   └── 否则继续当前状态
└── 更新所有 NPC 的 Duty</code></pre><h2>总结</h2><p>RimWorld 的 NPC AI 系统通过五个层次的精心设计，实现了复杂而高效的行为决策和执行机制。每个层次都有其独特的职责，同时通过清晰的接口相互协作。</p><h3>系统特点回顾</h3><ol><li><p><strong>分层架构</strong>：</p><ul><li>思考决策层：决定"做什么"</li><li>路径导航层：解决"怎么走"</li><li>工作执行层：实现"怎么做"</li><li>群体协调层：协调"一起做"</li><li>战斗决策层：选择"打哪个"</li></ul></li><li><p><strong>优先级驱动</strong>：</p><ul><li>思考树按优先级顺序评估节点</li><li>高优先级行为（如战斗）会中断低优先级行为（如工作）</li><li>确保 NPC 能够及时响应紧急情况</li></ul></li><li><p><strong>状态管理</strong>：</p><ul><li>Lord 系统使用状态机管理群体行为</li><li>通过 Trigger 实现状态转换</li><li>支持复杂的事件流程（如袭击、商队等）</li></ul></li><li><p><strong>性能优化</strong>：</p><ul><li>A* 算法使用启发式函数加速路径查找</li><li>区域级路径优化减少大距离路径的计算量</li><li>思考树使用短路机制避免不必要的评估</li></ul></li></ol><h3>关键概念速查</h3><table><thead><tr><th>概念</th><th>层级</th><th>作用</th></tr></thead><tbody><tr><td>ThinkNode</td><td>第一层</td><td>决策树节点，决定行为选择</td></tr><tr><td>ThinkTree</td><td>第一层</td><td>完整的决策逻辑树</td></tr><tr><td>JobGiver</td><td>第一层</td><td>连接思考层和工作层的桥梁</td></tr><tr><td>PathFinder</td><td>第二层</td><td>A* 路径查找算法实现</td></tr><tr><td>Job</td><td>第三层</td><td>任务的抽象描述</td></tr><tr><td>JobDriver</td><td>第三层</td><td>任务的执行驱动</td></tr><tr><td>Toil</td><td>第三层</td><td>最小的执行单元</td></tr><tr><td>Lord</td><td>第四层</td><td>群体管理器</td></tr><tr><td>LordToil</td><td>第四层</td><td>群体状态节点</td></tr><tr><td>StateGraph</td><td>第四层</td><td>状态转换图</td></tr><tr><td>AttackTargetFinder</td><td>第五层</td><td>战斗目标选择器</td></tr></tbody></table><h3>设计优势</h3><ol><li><strong>模块化</strong>：每个层次可以独立理解、测试和修改</li><li><strong>可扩展</strong>：新行为可以通过添加新的 ThinkNode 或 JobDriver 实现</li><li><strong>可维护</strong>：清晰的层次划分使代码易于维护</li><li><strong>性能</strong>：优化的算法和缓存机制确保游戏流畅运行</li></ol><h3>实际应用</h3><p>理解这个 AI 系统对于：</p><ul><li><strong>Mod 开发者</strong>：可以创建自定义行为、工作类型和群体事件</li><li><strong>游戏设计师</strong>：可以调整 AI 参数来平衡游戏难度</li><li><strong>玩家</strong>：可以更好地理解 NPC 行为，制定策略</li></ul><h3>进一步探索</h3><p>如果你想深入了解某个特定方面，可以：</p><ul><li>查看源代码中的具体实现细节</li><li>通过游戏日志观察 AI 决策过程</li><li>使用开发工具（如 Dev Mode）测试不同场景</li><li>参考 RimWorld 的 Mod 开发文档</li></ul>]]></description></item><item>    <title><![CDATA[Python 3.14 实用技巧：10个]]></title>    <link>https://segmentfault.com/a/1190000047403453</link>    <guid>https://segmentfault.com/a/1190000047403453</guid>    <pubDate>2025-11-16 23:02:35</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>Python 3.14 引入的改进大多数都很细微，但这些小变化会让代码写起来更流畅，运行也更稳定。本文整理了 10 个实用的特性改进，每个都配了代码示例。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047403455" alt="" title=""/></p><h2>1、TypedDict 的 NotRequired 类型标注</h2><p>配置字典里的可选字段以前处理起来比较麻烦，现在有了明确的标注方式。</p><pre><code> from typing import TypedDict, NotRequired  
 class Config(TypedDict):  
     name: str  
     interval: int  
     debug: NotRequired[bool]</code></pre><p>字典验证变得更清晰，少了很多"忘记加这个键"导致的运行时错误。</p><p>如果你的自动化脚本对配置文件依赖很重，脚本的可选字段一眼就能看出来，所以这个改动非常的方便。</p><h2>2、类型窄化的静态分析增强</h2><p>3.14 版本的静态分析已经做得更好了，编辑器能在代码运行前就发现一些逻辑问题。</p><pre><code> def process(x: int | str):  
     if isinstance(x, int):  
         return x + 1  # Editor now knows x is int here</code></pre><p>类型检查器能帮你减轻不少智负担，半年后回来看代码也能快速理解。</p><h2>3、延迟导入优化</h2><p>依赖项多的脚本启动慢是个常见问题。Python 3.14 在导入解析和延迟加载上做了优化。</p><pre><code> import importlib  
 pandas = importlib.import_module("pandas")</code></pre><p>这么写导入，程序的启动速度能快一些同时也避免了加载用不到的模块。</p><h2>4. 错误消息改进</h2><p>错误提示终于说人话了。</p><pre><code> items = [1, 2, 3]  
 print(items[3])</code></pre><p>3.14 的报错信息：</p><blockquote><strong><em>IndexError:</em></strong><em>list index out of range (list has length 3, index 3 is invalid)</em></blockquote><p>现在的错误提示会直接告诉你列表长度和无效索引，调试效率提升明显。</p><h2>5、contextlib.chdir() 上下文管理器</h2><p>这是一个新增的功能很实用但容易被忽略。</p><pre><code> from contextlib import chdir  
 with chdir("logs"):  
     open("deephub.txt").write("done")</code></pre><p>文件操作时切换目录变得简洁了，不用再写</p><pre><code>os.getcwd()</code></pre><p>那套东西。</p><h2>6、异步任务取消机制改进</h2><p>并发编程在自动化场景下很常见，异步任务取消以前调试起来很头疼。</p><pre><code> import asyncio  
 async def worker():   
     await asyncio.sleep(5)  
 task = asyncio.create_task(worker())  
 task.cancel()</code></pre><p>而现在清理过程处理得更稳妥，不会像以前那样抛出奇怪的异常。</p><h2>7、紧凑帧对象优化递归</h2><p>处理递归场景（JSON 解析、目录遍历、XML 处理等）时稳定性提升了。</p><pre><code> def walk(n):   
     return n if n == 0 else walk(n - 1)</code></pre><p>运行更顺畅，内存占用也更合理。</p><h2>8、subprocess 环境变量隔离</h2><p>3.14 加强了子进程的环境变量隔离。</p><pre><code> import subprocess  
 subprocess.run(["python", "--version"], check=True)</code></pre><p>避免了不该传递的环境变量泄漏到子进程，对自动化脚本的安全性非常有帮助。</p><h2>9、模式匹配错误提示优化</h2><p>模式匹配的错误信息变得更详细了。</p><pre><code> match data:  
     case {"deep hub": name, "age": age}:  
         ...</code></pre><p>无效模式会给出具体的错误提示而不是含糊的信息，团队协作时调试起来方便很多。</p><h2>10、导入耗时分析</h2><p>对做自动化开发的人来说这个功能挺有用。</p><pre><code> importimportlib.util, time  
 start=time.perf_counter()  
 importlib.util.find_spec("numpy")  
 print(time.perf_counter() -start)</code></pre><p>因为它能快速定位哪些导入拖慢了启动速度，初始化逻辑也能做针对性优化。</p><h2>总结</h2><p>这些特性单独看都不算特别亮眼，也不是那种能拿出去炫耀的东西。但是整洁的代码不是靠引入大型框架写出来的，而是日常编码习惯积累出来的。Python 3.14 提供的这些改进就属于这类，用多了之后会慢慢内化成习惯。</p><p>这 10 个特性看着不起眼，但在几十个脚本里用起来之后：调试时间少了，代码审查快了，运行也更稳定了，而且这些改善基本不需要额外的工作量。</p><p>代码库想变得更轻量、更好维护，升级到 Python 3.14 是个不错的选择。凌晨两点调试代码的时候，会感谢做出这个决定的自己。</p><p><a href="https://link.segmentfault.com/?enc=e1kr363VJg8REStv%2Bj8XBg%3D%3D.%2Ff%2BmZDaR0xOP62T5PmhVmOq79WK6prVzIgfKpkTr5dghRyynHXi6ed1PMOyyNTmefFGjtkvMFI6inwyLzUObdg%3D%3D" rel="nofollow" target="_blank">https://avoid.overfit.cn/post/8312efd2a1e94496be1c636ab538cb38</a></p><p>作者：Arfa</p>]]></description></item><item>    <title><![CDATA[在富阳银湖成立地域化的软件研发团队 欧雷]]></title>    <link>https://segmentfault.com/a/1190000047403487</link>    <guid>https://segmentfault.com/a/1190000047403487</guid>    <pubDate>2025-11-16 23:02:04</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>随着 11 月的到来，银湖创联也已步入它生命进程中的第二阶段。</p><p>与混沌初开，一切以「先跑起来再说」为主旋律的第一阶段相比，当前阶段的主旋律，或者说核心目标是——通过简单的规则和治理单元，形成自组织、自生长的系统。</p><p>作为社区的发起人兼主理人，我这几天在很适合移动办公的瑞咖啡里对之前一些较为零星散乱的想法进行梳理，有了一个初步的清单。</p><p>打算进一步讨论完善后，召开一次宣讲会，与心系社区的人之间来一场即时的答疑与反馈，他们同时也是新阶段的第一批潜在合作者。</p><p>然而在那之前，清单中的一项完全可以立马就行动起来，也就是本文的主题。</p><h2>软件开发小组成立</h2><p>在「小雇·全国自由职业者大会·杭州站」上进行的主题分享《<a href="https://segmentfault.com/a/1190000047336860" target="_blank">典型程序员跨界做在地社区是怎样一种体验？</a>》中，临结束时有这样一段：</p><p><img width="723" height="457" referrerpolicy="no-referrer" src="/img/bVdm3Yv" alt="" title=""/></p><p>三个主要价值点中的第一个，它是：</p><ul><li>最表层的——大家有直观感受的，很容易想到和理解的；</li><li>最基础的——是实现并发挥另外两个价值点的基石，它们比较有前瞻性、创新性，解释成本更高，但落地后的价值不可估量。</li></ul><p>用更通俗点的说法，第一个价值点是以在地自由职业者为引，通过相互连接重建以信任为基础的新型熟人社会，并展现了通过自由职业实现自我价值的可行性。</p><p>再依托于信任关系、个人专业性去探索区域内可自循环的消费服务体系、商业模式，并借助更加一体化、数智化的手段提升区域内信息与资源流通的效率和体验。</p><p>另外两个价值点，要么完全依赖于软件开发，要么跟软件开发也很有关系。</p><p>在过往的社区活动中，多次参加活动进行交流且以软件开发作为职业的人，算我在内目前有三人：</p><ul><li>我，数智生活领域独立开发者，前端开发出身，擅长抽象，一直想要解决数据所有权与控制权、一体化和数智化问题；</li><li>一个 XR、3D 开发者，擅长虚拟世界与现实世界通过某种形式在图形上进行融合；</li><li>一个从良渚搬过来的 AI 连续创业者，想做数智化、游戏化的人生系统。</li></ul><p>由此可见，我们仨的共同点：</p><ul><li>侧重有所不同，但都是软件开发者；</li><li>擅长不同方面，但想解决的问题都可归为「元宇宙」；</li><li>都生活在银湖。</li></ul><p>既然如此，那我们为啥不凝聚在一起，成立「银湖软件开发小组」呢？！</p><p>这样一来：</p><ul><li>对外——以小组作为统一的信息出入口，进行社区第三阶段要落地的线上系统的研发，承接来自银湖在地企业、商家、工作室/超级个体的软件研发需求；</li><li>对内——软件研发需求信息共享，适者弹性组队承包项目，按项目自行分配收益，也可以自行组队研发其他软件产品。</li></ul><p>简而言之，一方面我们组成了面向银湖在地潜在客户的软件研发专业团队，另一方面能够相互协作让想要开发的软件产品更快地落地并进行市场验证。</p><p>今天下午，我们相聚在其中一人家里，将自己的想法向他们描述，一番讨论后达成 2 个共识：</p><ol><li>可以成立「银湖软件开发小组」；</li><li>在进行「元宇宙」落地实验这件事上分头行动，即我先去做社区场景的线上系统，他们先做个人与家庭场景的设备与应用，然后再将关键数据打通而场景融合。</li></ol><p>没准儿事后回首，这就是另一个湖畔花园！</p><h2>结语</h2><p>开篇提到的「完全可以立马就行动起来」的「清单中的一项」是「在地的以特定兴趣爱好/专业能力/业务领域为核心的垂直小团体」。</p><p>而「银湖软件开发小组」就是具体例子，也是银湖创联的第一个专项小组（小团体），但这肯定不是最后一个，还会有更多的垂直小团体相继成立！</p><p>除了从银湖创联中生长出来的垂直小团体外，也欢迎那些本来就存在且与银湖有千丝万缕联系的其他兴趣组（如「富Young·团趣社」）之类加入到银湖创联这个大网络中！</p><hr/><p>本文其他阅读地址：<a href="https://link.segmentfault.com/?enc=I4NifA%2Bo9N4sfAXJy6p%2B8w%3D%3D.20w%2BnA8qD%2BzUUgKDKycpxlaQM2pyFErSZE4GIUhOVoSxrarZSFVo6LDZhtGCW0fi" rel="nofollow" target="_blank">个人网站</a>｜<a href="https://link.segmentfault.com/?enc=SjRt5FhGceac019ditPJrA%3D%3D.9drajjp8WUHj6oPtz7D5QcWv84eoke5KOUJcL6TqfGKEUmyHOekX6JmFh6Szsc228XZ2k3g3K0L7GSjjHL7mkw%3D%3D" rel="nofollow" target="_blank">微信公众号</a></p>]]></description></item><item>    <title><![CDATA[这为专门从事 AI 留胡子的饼干_dli]]></title>    <link>https://segmentfault.com/a/1190000047403498</link>    <guid>https://segmentfault.com/a/1190000047403498</guid>    <pubDate>2025-11-16 23:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>从生成式 AI 的惊艳亮相引起全球科技巨头军备竞赛般的投入开始，整个 AI 行业仿佛被注入了无限的想象力。似乎在宣告着即将出现一个生产力即将被彻底解放、商业模式即将被完全颠覆的光明未来。<br/>微软、谷歌、亚马逊等云巨头纷纷将资本支出的绝大部分押注于 AI 基础设施建设，而无数逐利而来的 AI 初创公司，更是如雨后春笋般涌现试图分一杯羹，全球 AI 领域的投资额也达到了史无前例的高度。<br/>然而，正如任何过热的淘金热最终都会迎来冷静期当技术以超乎预期的速度普及时，潜在的负面效应也以同样的速度被放大，正在悄然侵蚀着行业参与者。<br/>从 " 可选项 " 到 " 必选项 " 的巨额支出<br/>根据奇安信集团对外发布《2024 人工智能安全报告》来看，在 2023 年基于 AI 的深度伪造欺诈便已暴增了 3000%，基于 AI 的钓鱼邮件也增长了 1000%；而内容生成环节更是实现规模化生产。<br/>基于 Stable Diffusion 和 GPT-4 的定制模型，可每小时生成 2000 条伪原创研报、800 段逼真视频。暗网平台 "DarkGPT" 更是提供包月服务，1 万美元即可获得每日 5000 条金融虚假内容的产能。<br/>而且 "AI 滥用 " 的后遗症并不仅仅在社会新闻版块，可以说它已经穿透了科技公司的防火墙直接作用于其财务报表。而金融行业正是这场风暴的中心，当 AI 以假乱真的能力被精准地应用于金融诈骗时，其破坏力可以说是指数级的增长。<br/>据行业估算，2024 年由深度伪造技术引发的各类欺诈造成的全球经济损失已高达 120 亿美元。尤其在监管相对滞后、交易更为匿名的加密货币领域，AI 滥用更是如鱼得水。根据相关的报告也显示 2024 年仅 AI 深度伪造技术全年造成的损失便高达 46 亿美元。<br/>随着 AI 滥用事件的频发，过去模糊的 " 伦理指南 " 正在迅速转变为具有强制约束力的法律条文，而且这种转变直接导致了企业合规成本的急剧攀升。<br/>而且一旦出现违规需要付出的代价更是惨痛的，罚款最高可达全球年营业额的数个百分点或数千万欧元，而且合规也不再是法务部门的单一工作，而是渗透到研发、产品、市场的每一个环节。<br/>这些 " 反噬 " 也并非凭空产生，在 AI 商业化过程中对速度和规模的追求，长期以来压倒了对安全和伦理的考量所以形成了这种 " 原罪 "。因此未来合规成本的升高是不可避免的，而欧盟的《AI 法案》可以说是这一趋势的先行者。<br/>该法案于 2024 年 8 月 1 日正式生效并分阶段实施，着重对高风险的 AI 系统施加了严格的合规要求。而且这不仅仅是一项区域性法规，更可能产生 " 布鲁塞尔效应 " 从而影响全球的 AI 监管格局。<br/>监管的落地也将会直接转化为企业的合规成本。据公开信息推算，仅欧盟 AI 法案便可能导致欧洲企业的 AI 采纳成本增加约 310 亿欧元，并使 AI 投资减少近 20%。而美国联邦贸易委员会也已对 OpenAI 展开调查，谷歌等公司也不得不调整其营销话术，避免被处以巨额罚款。<br/>可以说 " 监管的铁幕 " 正在迫使整个行业从过去 " 快速行动，打破陈规 " 的互联网思维转向一种更为审慎、合规驱动的开发模式。可以说这种转变无疑会减缓创新速度并增加运营成本，对于那些资源有限的中小企业和初创公司构成尤为严峻的挑战。<br/>对 " 信任 " 的侵蚀或许是 AI 滥用最难修复的一种<br/>这源于在激烈的竞争压力下，企业急于抢占市场将产品快速推向用户，所以将风险控制和安全测试置于次要位置。但是这种 " 快速行动并打破规则 " 的心态在 AI 时代尤为危险，因为 AI 技术的潜在破坏力远超以往的软件应用。<br/>并且市场对于 AI 技术的可靠性极度敏感，甚至一次小小的失误都可能引发巨大的信任危机和财务损失。谷歌的 Bard 模型之前便在一次演示中出现事实性错误，竟然导致其母公司 Alphabet 的股价在单日内暴跌 7%，市值蒸发超过 1000 亿美元。<br/>并且随着 AI 投资的巨额支出持续攀升，投资者开始担忧其回报前景，这种悲观情绪导致 Meta、Microsoft、Alphabet 和 Nvidia 等 AI 领域的领军企业股价普遍承压下跌，市场也开始讨论 "AI 泡沫 " 的风险，并开始质疑哪些不计成本的 " 军备竞赛 " 式投资。<br/>更何况大量公司缺乏对 AI 伦理的明确责任归属，高管层面也并未对其有所调整。所以 AI 系统的决策过程像一个 " 黑箱 "，在责任主体模糊的情况下滥用和误用的风险便难以控制。企业内部也未建立有效的问责机制。<br/>但是更深层次的原因在于当前主流生成式 AI 商业模式本身所内含的风险。这些模型依赖于海量数据的投喂，其训练过程难以完全避免偏见和有害信息的吸收。而其强大的生成能力却为恶意利用提供了温床。<br/>因此当商业模式的核心是追求更强大的模型、更广泛的应用时，如果缺乏与之匹配的强大 " 安全刹车 " 系统，滥用就成了可预见的副产品。这种商业逻辑与伦理要求之间的结构性失衡才是导致 " 反噬 " 的根本内因。<br/>所以当企业享受了技术红利带来的增长，如今便也不得不为其模式所伴生的风险 " 买单 "。哪怕科技公司以 " 让世界更美好 " 的叙事推广 AI，公众在实际体验中，也会频繁受到隐私泄露、算法偏见、就业替代、虚假信息等负面影响。<br/>这种落差也导致了广泛的 "AI 焦虑 " 和不信任感。公众普遍认为现有的监管法规不足以应对 AI 带来的社会风险期望政府采取更加果断的行动。这种强大的民意压力也是推动监管机构加速行动的根本动力。<br/>面对公众的呼声和潜在的社会风险，监管机构的介入是必然的。但由于技术发展的速度远超立法速度监管往往表现出一定的滞后性，欧盟 AI 法案便被部分人士认为可能增加企业负担、抑制创新。<br/>全球主要经济体在 AI 领域的竞争，也使得监管变得更加复杂。各国都希望在鼓励创新和防范风险之间找到平衡点但这种平衡点的位置各不相同，因此形成了复杂的国际监管格局给跨国企业的合规带来了巨大挑战。<br/>而且这种外部滥用对整个 AI 行业的声誉造成了 " 连坐 " 效应。即使一家公司本身恪守伦理，也无法完全独善其身，因为公众对 AI 的信任是整体性的。恶意滥用行为如同向池塘中投下的毒药，在污染了整个水域后迫使所有 " 池中生物 " 共同承担后果。<br/>这场危机成为 AI 自我革新的契机<br/>这场 " 反噬 " 带来的阵痛，是 AI 产业从野蛮生长走向规范发展的必经阶段。它正在淘汰那些只想赚快钱、缺乏责任感的 " 玩家 "，筛选出真正有实力、有远见的长期主义者。从长远来看，这也是为 AI 产业的健康、可持续发展所必须付出的代价。<br/>其中最大的机遇在于将 " 信任 " 从一种道德呼吁，转变为一种可量化、可变现的商业资产和竞争壁垒。数据显示近 85% 的客户也更愿意与重视 AI 伦理实践的公司合作，而那些优先考虑伦理和透明度的公司收入增长也更快。<br/>可以说在 AI 产品同质化日益严重的未来，谁能赢得用户的信任谁就能赢得市场。" 负责任的 AI" 将不再仅仅是公关部门的口号，而是必须贯穿于产品设计、开发、部署全流程的核心战略。<br/>谷歌和微软等公司已经开始调整其策略，谷歌选择利用 AI 技术提升广告安全审核的效率，打击欺诈内容；微软则发布了负责任 AI 透明度报告，并推出了 AzureAIContentSafety 等服务，帮助客户构建更安全的 AI 应用。这些举措既是应对风险的防御，也是在构建新的竞争优势。<br/>正是 " 反噬 " 催生了全新的 " 安全即服务 " 市场。随着 AI 滥用风险的加剧企业对 AI 安全审计、风险评估、内容过滤、合规咨询等服务的需求将急剧增长。这为专门从事 AI 安全和伦理治理的科技公司、咨询机构创造了巨大的市场空间。<br/>而科技巨头自身也可以将其内部成熟的安全工具和能力平台化、服务化，开拓新的收入来源。例如，谷歌和微软在内容审核、风险识别方面的技术积累，完全可以转化为对外输出的商业服务。<br/>虽然监管的收紧虽然带来了成本，但也为行业设定了 " 准入标准 "，能够率先满足高标准合规要求的企业将获得更强的市场公信力和竞争优势，从而在未来的市场整合中占据有利地位。这实际上是一种由监管驱动的市场出清和格局优化。weibo.com/ttarticle/p/show?id=2309405233698940518650<br/>weibo.com/ttarticle/p/show?id=2309405233699078930694<br/>weibo.com/ttarticle/p/show?id=2309405233699812933758<br/>weibo.com/ttarticle/p/show?id=2309405233699951608477<br/>weibo.com/ttarticle/p/show?id=2309405233700090020020<br/>weibo.com/ttarticle/p/show?id=2309405233700232626572<br/>weibo.com/ttarticle/p/show?id=2309405233700899520919<br/>weibo.com/ttarticle/p/show?id=2309405233701042127096<br/>weibo.com/ttarticle/p/show?id=2309405233703034159184<br/>从滥用事件的激增，到资本市场的审慎，再到全球监管的收紧，这股 " 反噬 " 之力正在重塑 AI 产业的发展轨迹。它迫使整个行业从过去对技术力量的无限崇拜，转向对技术责任和社会价值的深刻反思。<br/>麦肯锡预测，到 2030 年 AI 将为全球经济创造 13 万亿美元价值。但价值分配取决于我们如何驾驭这头猛兽。未来的竞争，将不仅仅是模型参数和算力大小的竞争，更是治理能力、责任担当和用户信任的竞争。</p>]]></description></item><item>    <title><![CDATA[深入探索剖析 JVM 的启动过程 程序猿]]></title>    <link>https://segmentfault.com/a/1190000047403401</link>    <guid>https://segmentfault.com/a/1190000047403401</guid>    <pubDate>2025-11-16 22:02:17</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>你可曾想过：当你在终端里敲下 <code>java</code>，在 <code>main</code> 方法真正运行之前，JVM 为了“创造一个可运行你的程序的宇宙”，到底经历了哪些步骤？从参数校验、系统资源探测，到选择垃圾回收器，再到类的加载、链接与初始化，这些看不见的过程决定了应用的启动体验与后续性能。本文用一个极简的 HelloWorld 贯穿全程，结合详细日志，一步步洞察 JVM 的启动机制，帮你在调试和性能优化时更有抓手。</p><h2>1. 概览</h2><p>当我们运行一个 Java 应用时，JVM 在我们的代码真正开始执行之前，会先完成一系列复杂步骤。本文将从执行 <code>java</code> 命令的那一刻开始，一直走到应用就绪。</p><p>我们以一个简单的 HelloWorld 程序为例，拆解每一个阶段。理解这些内部机制能显著提升调试与性能调优的效果。</p><h2>2. 从 <code>java</code> 命令到 JVM 启动</h2><p>在 JVM 执行任何代码之前，它需要先启动、校验输入并配置运行环境。下面按启动顺序走一遍早期流程：从调用 <code>java</code> 命令到初始化 JVM 运行时。</p><h3>2.1. <code>java</code> 命令与初始调用</h3><p>当我们运行 <code>java</code> 命令时，JVM 启动序列会通过 JNI 方法 <code>JNI_CreateJavaVM()</code> 开始执行。该方法完成若干关键初始化任务，为执行 Java 应用准备环境。Java Native Interface（JNI）是 JVM 与原生系统库之间的桥梁，使 Java 与平台特性可以双向通信。</p><p>本文将使用详细日志观察 JVM 的内部运作，例如：</p><pre><code class="bash">java -Xlog:all=trace HelloWorldCopy</code></pre><h3>2.2. 校验用户输入</h3><p>首先，JVM 会校验我们传入的参数：</p><pre><code class="text">[0.006s][info][arguments] VM Arguments:
[arguments] jvm_args: -Xlog:all=trace:file=helloworld.log 
[arguments] java_command: HelloWorld
[arguments] java_class_path (initial): .
[arguments] Launcher Type: SUN_STANDARD</code></pre><p>JVM 会验证目标可执行、类路径以及任何 JVM 参数，确保它们在继续执行前都是有效的。这个步骤能尽早捕获很多常见配置错误，避免后续阶段出现更难定位的问题。</p><h3>2.3. 检测系统资源</h3><p>接着，JVM 会识别可用的系统资源，例如处理器数量、内存大小以及关键系统服务：</p><pre><code class="text">[0.007s][debug][os       ] Process is running in a job with 20 active processors.
[os       ] Initial active processor count set to 20
[os       ] Process is running in a job with 20 active processors.
[gc,heap  ]   Maximum heap size 4197875712
[gc,heap  ]   Initial heap size 262367232
[gc,heap  ]   Minimum heap size 6815736
[os       ] Host Windows OS automatically schedules threads across all processor groups.
[os       ] 20 logical processors found.</code></pre><p>这些信息会影响 JVM 的一些内部决策，比如默认选择哪个垃圾回收器。可用 CPU 数和总内存会直接影响 JVM 的启发式选择。不过，大多数设置都可以通过显式的 JVM 参数进行覆盖。在这个阶段，JVM 还会检查是否支持 Native Memory Tracking，并验证它可能依赖的各类操作系统工具的可用性。</p><h3>2.4. 环境准备</h3><p>随后，JVM 会生成 HotSpot 性能数据。这些数据会被 JConsole、VisualVM 等工具用于检查和分析 JVM：</p><pre><code class="text">[perf,datacreation] name = sun.rt._sync_Inflations, dtype = 11, variability = 2, units = 4, dsize = 8, vlen = 0, pad_length = 4, size = 56, on_c_heap = FALSE, address = 0x000001f3085f0020, data address = 0x000001f3085f0050</code></pre><p>这类性能数据通常存储在系统的 <code>/tmp</code> 目录下，并会在启动阶段的一段时间里持续生成，与其他初始化任务并行进行。</p><h2>3. 加载、链接与初始化</h2><p>当 JVM 环境就绪后，它会开始为我们的程序执行做准备。</p><h3>3.1. 选择垃圾回收器</h3><p>在 JVM 内部，一个关键步骤是选择垃圾回收器（GC）。截至 JDK 23，默认情况下 JVM 会选择 G1 GC，除非系统可用内存少于 1792MB 和/或仅有单处理器：</p><pre><code class="text">[gc               ] Using G1
[gc,heap,coops    ] Trying to allocate at address 0x0000000705c00000 heap of size 0xfa400000
[os               ] VirtualAlloc(0x0000000705c00000, 4198498304, 2000, 4) returned 0x0000000705c00000.
[os,map           ] Reserved [0x0000000705c00000 - 0x0000000800000000), (4198498304 bytes)
[gc,heap,coops    ] Heap address: 0x0000000705c00000, size: 4004 MB, Compressed Oops mode: Zero based, Oop shift amount: 3
[pagesize         ] Heap:  min=8M max=4004M base=0x0000000705c00000 size=4004M page_size=4K</code></pre><p>当然，我们也可以选择其它 GC：如 Parallel GC、ZGC 等，具体可用与默认策略依不同 JDK 版本与发行版而异。</p><h3>3.2. 加载 CDS（类数据共享）</h3><p>此时，JVM 会开始寻找进一步的优化机会。CDS 是一组已经经过预处理的类文件归档，可以改善 JVM 的启动性能：</p><pre><code class="text">[cds] trying to map [Java home]/lib/server/classes.jsa
[cds] Opened archive [Java home]/lib/server/classes.jsa</code></pre><p>不过，CDS 正在被 Project Leyden 中的 AOT（提前）机制逐步替代，后文会继续讨论。</p><h3>3.3. 创建方法区</h3><p>JVM 随后会创建“方法区”，这是一个用于存储类数据的特殊离堆内存区域。在 HotSpot 中，这一区域被称为 metaspace。当关联的类加载器不再可达时，存储于此的类数据也会被移除：</p><pre><code class="text">[metaspace,map    ] Trying anywhere...
[metaspace,map    ] Mapped at 0x000001f32b000000</code></pre><p>虽然方法区不在堆中，但它仍由 GC 管理。</p><h3>3.4. 类加载</h3><p>类加载包含三个步骤：定位二进制表示、根据其派生出类、并将其加载到方法区。正是这种动态加载能力，让 Spring、Mockito 等框架可以在运行期按需生成并加载类。</p><p>类加载有两种方式：引导类加载器（bootstrap class loader）或自定义类加载器。下面借助一个简单的 <code>HelloWorld</code> 类，看看 JVM 首先会做什么：</p><pre><code class="java">public class HelloWorld extends Object {
    public static void main(String[] args) {
        System.out.println("Hello World!");
    }
}</code></pre><p>JVM 会优先加载 <code>java.lang.Object</code> 及其依赖。类在初次加载时大多处于“半隐藏”的状态，以便进行必要的验证与整理工作。</p><p>再看下 <code>java.lang.Object</code> 的方法：</p><pre><code class="java">public class Object {
    public final native Class&lt;?&gt; getClass()
    public String toString()
    public boolean equals(Object obj)
}</code></pre><p>这些方法分别引用了 <code>java.lang.Class</code> 与 <code>java.lang.String</code>，因此它们也需要先行加载。JVM 采用“按需加载”的策略，仅在类被实际引用时才加载。不过，上述这些对 JVM 至关重要的类会被“抢先加载”。在一个简单的 HelloWorld 程序里，由 <code>JNI_CreateJavaVM()</code> 初始化的引导类加载器负责所有的类加载工作。</p><h3>3.5. 类链接</h3><p>类链接可以拆分为验证（Verification）、准备（Preparation）与解析（Resolution），其发生顺序并不固定：解析可能发生在验证之前，也可能在类初始化之后。验证确保类结构正确：</p><pre><code class="text">[class,init] Start class verification for: HelloWorld
[verification] Verifying class HelloWorld with new format
[verification] Verifying method HelloWorld.&lt;init&gt;()V</code></pre><p>位于 CDS 中的类已经过验证，因此会跳过该步骤，从而提升启动性能。这是 CDS 的重要收益之一。在“准备”阶段，JVM 会用默认值初始化静态字段，没有显式初始化器的静态变量会自动获得默认值。</p><p>在“解析”阶段，JVM 会解析常量池（Constant Pool）中的符号引用。常量池保存了类的所有符号引用，JVM 必须先将其解析为真实的内存引用，才能执行相关指令。</p><p>我们可以使用 <code>javap</code> 来观察：</p><pre><code class="bash">javap -verbose HelloWorldCopy</code></pre><p>这将显示常量池的内容：</p><pre><code class="text">Constant pool:
   #1 = Methodref          #2.#3          // java/lang/Object."&lt;init&gt;":()V
   #2 = Class              #4             // java/lang/Object
   #3 = NameAndType        #5:#6          // "&lt;init&gt;":()V
   #7 = Fieldref           #8.#9          // java/lang/System.out:Ljava/io/PrintStream;
  #13 = String             #14            // Hello World</code></pre><p>构造器的字节码并不直接包含地址。它引用常量池中的符号项（例如 <code>#1</code>），这些条目描述了方法或字段。解析阶段会将这些符号项转为可执行的真实内存引用：</p><pre><code class="text">public HelloWorld();
  descriptor: ()V
  flags: (0x0001) ACC_PUBLIC
  Code:
    stack=1, locals=1, args_size=1
       0: aload_0
       1: invokespecial #1                  // Method java/lang/Object."&lt;init&gt;":()V
       4: return
  LineNumberTable:
    line 2: 0
    line 4: 4</code></pre><p>第 1 行的 <code>invokespecial</code> 指令引用了常量池条目 <code>#1</code>，其中包含链接到 <code>java.lang.Object</code> 构造器所需的信息。<code>&lt;init&gt;</code> 表示这是由 <code>javac</code> 为每个构造器自动生成的特殊方法。JVM 采用“延迟解析”，只有在尝试执行类中的某条指令时才触发解析；并非所有已加载的类都会实际执行其指令。</p><h3>3.6. 类初始化</h3><p>类初始化会为静态字段赋值并执行静态初始化器，这与我们调用构造器的实例初始化不同。该过程由 <code>javac</code> 自动生成的特殊方法 <code>clinit</code> 负责。</p><h2>4. 优化 JVM 启动性能</h2><p>尽管 JVM 的启动已经很高效，但仍有提升空间。以下是一些方向。</p><h3>4.1. 类加载的影响</h3><p>我们可以使用系统的 <code>time</code> 工具来度量 JVM 启动、加载类、链接并执行这个简单程序的总耗时：</p><pre><code class="bash">time java HelloWorldCopy</code></pre><p>该工具会测量从 JVM 进程启动到退出的挂钟时间，包含类加载、链接、JIT 预热与程序执行——不仅仅是用户代码。对于 HelloWorld，JVM 在启动期间通常会加载约 400～450 个类。在现代硬件上，即便开启冗长日志，整个过程也大约在 60 毫秒左右完成。</p><h3>4.2. Project Leyden</h3><p>Project Leyden 的目标是减少启动时间、达到峰值性能的时间以及内存占用。JDK 24 引入了 JEP 483：Ahead-of-Time Class Loading and Linking（提前类加载与链接），将这些操作从启动时前移至 AOT 阶段。</p><p>该特性会在“训练运行”中记录 JVM 的行为，将其存入缓存，并在后续启动时从缓存加载。这将取代原先的 CDS 概念，并最终以 AOT 的更广泛能力来统一表达。</p><h3>4.3. JVM 参数与调优</h3><p>虽然我们可以通过静态字段与初始化器在某些场景中优化启动性能，但应谨慎对待。为了将行为挪到类加载阶段而进行重构，往往很难获得可测量的收益——特别是考虑到运行时的大部分代码来自依赖库而非我们自己的应用。</p><h2>5. 结论</h2><p>本文从校验用户输入、检测系统资源，到类的加载、链接与初始化，系统地梳理了 JVM 在启动阶段经历的复杂流程。即便是一个简单的 HelloWorld，JVM 也会在执行代码之前构建起完整的运行环境，加载数百个类。</p><p>随着 Project Leyden 等改进（例如 AOT）的到来，JVM 的启动性能还将进一步提升。</p><blockquote>更多相关技术干货分享可以关注这个<a href="https://link.segmentfault.com/?enc=tCi%2Bp2ZsNJvrldU8McVlxQ%3D%3D.Qfc6EcXfgsCPCFQ14agAGnsVFh8Qa%2Ban0ew2jVVNTXb2QXjtx%2B65WPGOieXJSy0o" rel="nofollow" target="_blank">Java专题</a></blockquote>]]></description></item><item>    <title><![CDATA[如何驯服AI编程 reddish ]]></title>    <link>https://segmentfault.com/a/1190000047403420</link>    <guid>https://segmentfault.com/a/1190000047403420</guid>    <pubDate>2025-11-16 22:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>当泡沫遇上现实</h2><p>最近圈子里聊AI泡沫的声音越来越多，大厂裁员的消息也时不时冒出来。</p><p>说实话，氛围编程那套已经凉透了，这点毫无悬念。之前写过一篇文章专门聊这事儿："氛围编程走远，规格驱动开发降临"<a href="https://link.segmentfault.com/?enc=%2BTnKCez8tkotzE4cXeLu5g%3D%3D.gEnIi8%2Fb2vAkefOqwmDpMLmjtgtypLeXbfyC3TSk%2F06uFPwc4CNpJH6LJQ1E4BPFcWY9D8dIaFUZnOzOZrb2Nw%3D%3D" rel="nofollow" target="_blank">https://srs.pub/thinking/spec-driven-coding.html</a></p><p>AI这波泡沫更有意思。做空基金直接怼nvidia，理由是按现在的市值，得60年才能回本。更绝的是nvidia自己的神操作：给OpenAI投1000亿，然后这钱必须用来买nvidia的显卡。这不就是左手倒右手嘛，本质上就是在给自己刷数据。</p><p>但真正要命的不是这些资本游戏，而是这股风已经吹到了普通人和管理层那里。你看那个被炒得火热的口号："普通人不懂技术也能开发产品了！"</p><p>这种浮躁的氛围，让不少老板产生了一个危险的错觉：<strong>程序员要失业了</strong>。连Meta都搞出了"鼓励转行，主动离职"的骚操作。Meta都这样了，后面跟风的还会少吗？</p><p>但是，如果你真打算因为AI能写代码就开始裁人，我劝你先冷静一下。<strong>商业史上最贵的学费，往往来自对新技术能力的误判</strong>。</p><h2>美丽的幻觉</h2><p>AI不光自己会产生幻觉，更要命的是它还会传染给人。于是就有了那句让人热血沸腾的口号："普通人不懂技术也能开发产品了！"听起来多美好啊，难怪一堆人跟着喊。</p><p>但历史告诉我们一个残酷的规律：<strong>每次看起来要颠覆世界的技术突破，都会先让人high到天上，然后狠狠摔回地面</strong>。</p><p>看看下面这张图，不同编程模式的真实轨迹：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047403422" alt="" title=""/></p><p>传统编程就像爬山，前期累死累活，慢慢往上爬，后期还得不停维护。但氛围编程和规格驱动开发就不一样了，一上来就能给你个惊喜，进展飞快。这也难怪那么多人相信"有想法就够了，剩下的交给AI"。</p><p>然后呢？氛围编程就开始现原形了。业内有个专门的词儿叫<strong>"腐烂"</strong>，说的就是AI写的代码崩坏的速度。</p><p>氛围编程确实能给你一个看起来还不错的初版，但你要是想继续完善？很快就会发现这玩意儿烂得比你想象的还快。我们项目里就遇到过，AI开始胡说八道，改了这里坏了那里，早期的AI模型还不知道适可而止，直接把自己都给卡死了。最后还是得人工全面接手，前前后后反而浪费了更多时间。</p><p>接下来可能成为主流的是<strong>规格驱动编程</strong>。这种方式起步和氛围编程差不多快，而且因为有明确的规格约束，初版质量可能还更好一些。虽然后面也会有腐烂的趋势，但规格就像缰绳一样，能把AI拉回正轨。最终的成熟度和覆盖面确实比纯人工要好一些。但这个"好"，也就是30%到50%的提升，没有想象中那么夸张。</p><p>所以啊，我们不仅要提防AI的幻觉，更要小心AI给我们制造的幻觉。真正的智慧在于：<strong>既不被炫酷的表象迷了眼，也不因为害怕就拒绝改变</strong>。</p><p>在很长一段时间里，AI都需要人来搭配，才能真正干成事儿。绝不是随便什么人都能上手的。</p><h2>血淋淋的真相</h2><p>说了这么多理论，来个真实的案例吧。我们团队最近就踩了一遍坑，现在想想还挺有意思的。</p><p>借助AI的能力，第一天就搭出了个基础框架，加上产品信息的整理，当天就能看到大概的样子。三天左右，核心的3-5个功能都跑起来了，通过了基础测试。那会儿我们还挺兴奋的，觉得这效率简直了。</p><p>然后就是噩梦的开始：整个研发团队全员上阵，像保姆一样盯着AI的每个操作，花了整整3个星期，才把各种bug、逻辑错误、莫名其妙的问题给填得差不多。</p><p>事后复盘，AI确实能在三天内给你一个能跑的版本，但AI+人工还是需要三周的时间来收拾残局，这还是在规格驱动模式下的结果。整个周期算下来，和纯人工开发差不了多少，而且在细节把控上，远没有人工那么可控。</p><p>不过话说回来，AI在一些我们团队薄弱的地方，比如CSS动画特效，确实提供了相当不错的补充。</p><p>这个经历让我明白了一个道理：<strong>复杂系统从来不是简单能力的拼凑，而是需要有人统筹全局</strong>。AI可以提供强大的局部能力，但整个系统的协调，还得靠人的智慧。</p><p>所以结论是什么？AI编程确实有用，但绝不是那些营销号说的那么轻松。我们的资深开发全程深度参与，工作量比平时还要大。</p><p>如果你听信了"AI让普通人都能开发产品"的鬼话，先别急着裁人，让子弹再飞一会儿。</p><h2>如何驯服这头野兽</h2><p>那AI编程到底还有没有用？当然有用！关键是要学会怎么驯服它。认清了AI的脾气秉性后，它绝对是个值得投资的好帮手。</p><h3>AI编程的四大价值</h3><ol><li><strong>做原型简直是神器</strong>：AI编程能快速给你一个可视化的原型。如果你只是想做个demo、验证个想法、或者和团队讨论创意，AI简直就是为这个而生的。</li><li><strong>补齐团队短板</strong>：以前组建研发团队，各种技能都得配齐，成本高得要命。现在AI能提供中上水平的开发能力，只要有人指导得当，很多临时需求都能搞定。</li><li><strong>打破信息壁垒</strong>：传统开发中，某些特定技能只有少数高手掌握，协调起来麻烦得很。有了AI，对传统高手的依赖大大降低了。</li><li><strong>局部功能很靠谱</strong>：AI现在的问题是记忆力不行，搞不定大系统。但对于那些短小精悍、需求明确的功能，质量还是挺高的。</li></ol><h3>不同人群的生存指南</h3><p>这波变革对研发团队的冲击还是挺明显的：</p><p><strong>高手变得有点寂寞</strong>：因为不再是独一无二的存在，门前确实冷清了不少。不过真正的高手借助AI发挥的效能还是比普通人强，价值依然在。<strong>真正的专家价值，从来不在于知道多少，而在于知道怎么用</strong>。</p><p><strong>新人的路更难走了</strong>：学编程本来就不容易，现在AI一出来，新人的学习动力和信心都受到冲击。只能从产品设计、规格规范这些方向入手，但这样一来，和AI的深度交流就成了问题，以后的路会很艰难。</p><p><strong>普通程序员如虎添翼</strong>：反倒是那些已经入门、掌握了基础技能的普通开发者，搭配AI简直如虎添翼。一个人顶好几个不是梦，甚至跨语言、跨领域都成了可能。</p><h3>普通人还有机会吗？</h3><p>如果你能做到产品经理的水平，输出详细的产品设计规格，或许还有一线希望。但最起码得有技术架构师来规范系统架构，数据结构、接口规范、设计规范这些基础知识是跑不掉的。</p><p><strong>完全不懂技术就想做产品？醒醒吧</strong>。</p><p>对普通人或者新人来说，比较靠谱的路径是学习设计思维，能把想法详细描述成产品需求，制定产品设计规范，最终确定技术规格。做到这一步，才有可能借助AI把产品做好。</p><h2>写在最后</h2><p><strong>技术的本质是放大人的能力，而不是替代人的智慧</strong>。AI编程确实是未来，但这个未来需要我们理性地参与创造，而不是盲目地跟风炒作。</p><p>别再做那些不切实际的白日梦了。AI确实能提供功能和价值，但在任何时代、任何技术革命中，都不存在躺着就能赢的机会。<strong>解决真正有价值问题的能力，永远都是稀缺资源</strong>。</p><p>驯服AI编程的核心在于：用规范约束AI的随意性，用人类智慧指导AI的创造力。学会了这一点，你就掌握了未来。</p><p>::: {#author name=reddish}<br/><em>本文同步发表在 <a href="https://link.segmentfault.com/?enc=MrOHP38rcIId5MWaUsWrlw%3D%3D.qR2RckSBM3nPOWk%2FdWepSQ%3D%3D" rel="nofollow" target="_blank">软件需求探索</a>的<a href="https://link.segmentfault.com/?enc=inptjSJm5P8xj7%2B5EWBUwg%3D%3D.XyU4i3J10XKhlwz%2FXkac0bQdyzemhf6BzIPx493zLLydTLLuAl2q4JSFg2PNkwUTKFrQO2sIKdww8Cum6Vn2WQ%3D%3D" rel="nofollow" target="_blank">https://srs.pub/thinking/stop-firing-after-ai-coming.html</a></em></p><p><em>作者: <a href="mailto:reddish@srs.pub" target="_blank">reddish@srs.pub</a></em><br/>:::</p>]]></description></item><item>    <title><![CDATA[AI 招聘智能体 爱跑步的香蕉_cKti]]></title>    <link>https://segmentfault.com/a/1190000047403347</link>    <guid>https://segmentfault.com/a/1190000047403347</guid>    <pubDate>2025-11-16 21:04:21</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>AI 招聘智能体<br/>AI重塑人才选拔：效率与精准的双重革新</p><p>人才选拔赛道的竞争日趋激烈，招聘官深陷堆积如山的简历与密集的面试流程，却仍面临核心人才难寻、面试主观性强、招聘成本高企的困境。当HR团队疲于应对初筛与基础面试时，企业正为这些低效流程承担高昂代价。</p><p>艾瑞咨询数据显示，AI技术已贡献HR SaaS市场60%的价值，其中个性化评估是核心应用场景。这场技术革命正从培训领域迅速蔓延至招聘环节，重新定义人才选拔的标准与效率。</p><p>AI面试智能体：精准选拔的核心支撑</p><p>AI面试智能体聚焦传统招聘“低效、主观、成本高”三大痛点，以“精度高”为核心优势，为企业提供智能招聘解决方案。其打分结果通过效标效度与重测稳定信度的双重心理学指标验证，可直接作为招聘决策依据，在面试智能体领域达到国际领先水平。</p><p>精准性贯穿招聘全环节。一道题目可同步评估多项胜任力，无缝衔接HR初筛与技术复试，让评估效率提升50%以上。系统能根据候选人回答即时生成针对性问题，像资深面试官一样捕捉关键信息，避免遗漏核心能力。同时，它会自动抓取简历中的关键信息与模糊点，生成递进式提问，既杜绝信息造假，也避免因HR主观疏忽错失优质候选人。无论是沟通、协作等通用胜任力，还是编程、算法、工程、财务等专业领域，系统都能精准出题，同时解放HR面试官与专业面试官。</p><p>在候选人体验层面，AI面试智能体实现了极致的拟人化交互。它能精准捕捉候选人的语速、情绪与潜台词，像真人HR一样引导候选人充分展现实力，避免因紧张影响发挥。无需手动操作“开始/结束答题”，系统可自动识别回答状态并衔接下一问题，交流过程自然流畅。语音与口型匹配精度大幅提升，同步嘴型开合与语速节奏，消除“纸片人”式的疏离感。候选人可随时提问，AI能准确解答职位信息、公司福利等问题，帮助候选人深入了解企业。</p><p>AI人才寻访智能体：全流程自动化革新</p><p>AI人才寻访智能体是一款具备简历解读、精准匹配、有效沟通能力的AI招聘工具，通过大模型技术实现有判断力的招聘决策，替代人工完成大量机械流程。</p><p>这套完整的招聘自动化系统可在无需人工干预的情况下，独立完成简历筛选、初步沟通、简历回收与系统同步的全流程，将招聘效率提升10到100倍。仅需30-60秒完成初始化，系统即可自动启动服务，无需人工值守。它能通过自主页面操作，根据企业预设条件自动筛选简历，精准识别符合要求的候选人。</p><p>针对匹配人选，AI可自动发起沟通，模拟人类语气进行问答式互动，发现不合适时即时退出。系统会自动遍历所有未读消息，逐条个性化回复，确保不遗漏潜在候选人。在缺少简历信息时，AI会主动请求简历，以自然的交流方式与候选人沟通。收到简历后，系统自动下载并上传至企业ATS系统，同时生成候选人档案，保障数据流转的完整与安全。</p><p>AI招聘的广泛应用与行业认可</p><p>AI面试智能体已在多领域得到广泛应用，服务对象包括西门子中国、太平保险、中广核集团、阿里巴巴国际、招商银行、TCL等上千家世界五百强及中国知名企事业单位，同时获得浙江大学、上海交通大学等顶尖高校的认可，其技术实力与应用效果经过了实际场景的充分验证。</p><p>AI技术正以精准化、自动化、人性化的优势，持续革新人才选拔的模式与效率，为企业解决招聘痛点提供了可靠的技术支撑。</p>]]></description></item><item>    <title><![CDATA[从“想法”到“产品”，Vibe Codi]]></title>    <link>https://segmentfault.com/a/1190000047403372</link>    <guid>https://segmentfault.com/a/1190000047403372</guid>    <pubDate>2025-11-16 21:03:35</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>AIFirst 与 OpenBuild 联合发起的 Vibe Coding 实战课，用六节干货满满的课程和一节加餐课，让无数 Web3 从业者感受到了这种 “高效开发、快速落地” 的魅力。</p><p><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdm3Wc" alt="image.png" title="image.png"/></p><p>在 Web3 赛道里，“有想法” 从来不是稀缺品，“能落地” 才是。以前做一个网站、一个小应用需要设计师、程序员、产品经理参与……少则几周，多则几个月。</p><p>但现在，一个人就能搞定！这就是 Vibe Coding 带来的新机会：用更快、更聪明的方式做产品，普通人也能从 0 到 1 搭建属于自己的产品。</p><p>从 Web3 小白到独立开发能手，从混乱编码到标准化流程，五位优秀学员用亲身经历，分享了这场 “高效开发” 的蜕变之旅。</p><p><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdm3Wd" alt="image.png" title="image.png" loading="lazy"/></p><p>同时，为了表彰以上五位小伙伴在课程中的全程投入和精彩分享，将获得本次课程赞助商 0G 和 SpoonOS 送出专属优才宝箱！</p><p><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdm3We" alt="image.png" title="image.png" loading="lazy"/></p><h3><strong>0xBrick_e²：告别无效沟通，掌握标准化流程</strong></h3><p>在今年暑假国内某家云服务公司的后端实习中，我经常让 AI 帮我完成工作任务，公司也是十分鼓励用 AI 辅助编程的，这让我意识到 Vibe Coding 是席卷而来的行业趋势。但是用AI辅助编程时，它像极了一个“热心但总是办坏事的实习生”——AI 能高效生成代码但总是与我的需求南辕北辙，复杂项目很容易抓不住重点，我需要不断地强调“这里要改”、“那里千万别动”，经常因为AI改了不该改的地方而回滚代码，十分糟心。</p><p><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdm3Wk" alt="image.png" title="image.png" loading="lazy"/></p><p>而这门 Vibe Coding 实战课，恰恰精准地治愈了我的痛点。我最大的收获，不是学会了某个酷炫的技术，而是掌握了一套标准化、可复用的 Vibe Coding 流程。从如何启动一个清晰的开发工作流，到如何精准地确认和拆解功能需求，再到让AI开始构建整个项目——这套流程成功地将我从与AI的无效沟通中解放出来。这套方法让我体会到：有了 Vibe Coding，我们每个人都是自己项目的产品经理。 即使是没有深厚编程基础的小白，也具备了成为“全栈开发者”的潜力。我们可以将脑海中天马行空的创意，快速地构建、落地为一个最小可行产品，亲眼见证想法照进现实。</p><p>作为一门名副其实的“实战课”，导师在课程中讲的满满都是干货，一步步亲手演示实操，目睹了导师如何通过 Vibe Coding 进行独立的商业转化，一个人实现从0到交付的全过程。这让我真切地看到，一个人就是一支队伍，技术能力可以直接转化为商业价值。</p><p><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdm3Wj" alt="image.png" title="image.png" loading="lazy"/></p><p>回顾这段学习旅程，我跟着导师一步步用 Vibe Coding 构建了自己的个人主页，将我的 NFT 成功部署上链、有了自己的 AI chat 机器人、给播客主定制一份播客展示页。Vibe Coding 赋予我的远不止是效率的提升和代码的规范，它更是一种“我能构建任何东西”的强大自信，是一种将创意转化为现实的能力。</p><h3><strong>花千树：3 小时完成个人站，解锁 MVP 快速验证</strong></h3><p><strong>1️⃣ 为什么学习 Vibe Coding？</strong></p><p>先从 Vibe Coding 这个词来说起吧！最初知道这个概念时，直译过来叫氛围编程，只知道这是用来辅助编程的，具体怎么个氛围法就不清楚了。当看到这个课程时，我就知道深入了解它的机会到了。</p><p><strong>2️⃣ 成果收获</strong></p><p>通过第一、二节课，我用 Vibe Coding 直接完成了一个个人网站的开发，并部署上线。在开发的过程中不用手写一行代码，通过 AI 编程工具可以实现所有开发任务，包括 debug。</p><p><img width="723" height="373" referrerpolicy="no-referrer" src="/img/bVdm3Wl" alt="image.png" title="image.png" loading="lazy"/><br/>个人网站：<a href="https://link.segmentfault.com/?enc=e%2BCc1%2F%2BCCQQiGhcGtEuuoQ%3D%3D.EO6OOM64USDQ%2BHqmspht6rYSbMaAy1h7kLERuVXBqyHV%2BJnX0AGE29GYdOC0bSY3" rel="nofollow" target="_blank">https://profile-blog-ai.vercel.app/</a></p><p>这样的网站虽然很简单，但如果要靠我自己完成全部的工作任务，至少也得两天的时间。通过 Vibe Coding 只需要几个小时就可以完成全部任务了（我记得完成这个个人网站，从开发到部署应该不到3个小时）。</p><p>通过这种方式来验证 MVP 一定是最好、最快的方案。</p><p>第三节课，老师针对 Vibe Coding 的流程给出了具体的方案和一些实用工具。这个过程我认为是非常重要的，把一整个编程流程、思维框架抽象成一个工作流，可以把这个工作流当成在 AI 编码时的一个规范，通过这个规范给编码工具提供指导，以不至于在编码时出现理解偏差，走向不归路，浪费时间。</p><p>我给这个工作流取了个名字叫做都察院，哈哈，简单好记。</p><p>PS: 最近对古代官制感兴趣，刚刚还把手机中的 app 按明朝官制进行了分类。</p><p>在有工作流的指导下，用 Vibe Coding 完成了一个简单的英语学习网站，其中需要使用到一些 AI 工具的 api，在开发过程中也有详细的指导步骤，完成起来还是比较顺利的。</p><p>仓库地址：<a href="https://link.segmentfault.com/?enc=1CPfp7T1W20gYKEYK08%2FVA%3D%3D.XeTRgfYbwTbAmRYOxKaYUJjUbkUcqQ9Wliupq13oP6vBkBJWp7cei1eCbnI7yIMuqIwWV7kd0o9zGcRC87BfQw%3D%3D" rel="nofollow" target="_blank">https://github.com/huaqianshu-lm/english-learning-site</a></p><p><img width="723" height="363" referrerpolicy="no-referrer" src="/img/bVdm3Wm" alt="image.png" title="image.png" loading="lazy"/></p><p>紧接着就来到了第四课了，基础打完了就应该实战了。我们来学习这个课程的目的一半在 Vibe Coding，另一半就是 web3**了，它终于来了。</p><p>在没有 web3 基础的情况下，可以通过 Vibe Coding 居然也能做项目了，真是件令人开心的事情啊。</p><p>呐，我的 MCoin 这不就出来了吗！</p><p><img width="723" height="378" referrerpolicy="no-referrer" src="/img/bVdm3Wn" alt="image.png" title="image.png" loading="lazy"/></p><p>呃... 虽然还点问题，但是不要紧，容我慢慢解决。</p><p>在做这几个项目的过程中，对 Vibe Coding 也是越来越熟悉，有几点经验跟大家分享一下。</p><p>1.在 coding 的过程中要有耐心。</p><ul><li>有过编程经验的小伙伴都知道，在做项目的过程中，一小部分时间在写代码，其实有一大部分的时间都是在调试 bug，解决问题。在 Vibe Coding 的过程中其实也是一样的，大部分的时间都是在解决问题。那么在解决问题的时候，与 AI 对话时，一定要把问题说清楚，那怎么说清楚呢？</li><li>我有一点小经验就是充分利用你的眼睛，看到什么就跟 AI 说什么。比如你看到页面有什么错误提示，你就跟 AI 说提示是什么，你看到颜色暗，就跟 AI 说颜色暗，需要亮一点的色彩。先把你看到的最直观的东西描述给 AI，然后再不断调整。</li><li>跟 AI 说需求时也是一样，你希望看到什么，就跟 AI 说什么，就用最直接的语言描述给它。我最近就是用这个方法跟 AI 沟通，我觉得效果还不错，有兴趣的可以试试。</li></ul><p>2.先使用其他 AI 工具整理思路。</p><ul><li>有时候我们有一个想法时，就只是有一个想法。距离想法变成产品还有很工作要做，这个时候可以先用 chatGPT** 来帮我们整理思路、确定技术方案。把这些准备工作都做好了之后，再开始 Vibe Coding。</li><li>当然这些工作也都可以用 cursor、claude** 等实现，但会消耗一些 token，毕竟还挺贵的，主打一个经济实惠🤑。</li></ul><p>后面的课程，只看了一遍，还有一些问题没有解决，也没有深入思考调研，在这里就不多说了。期待其他小伙伴的分享，搭个便车。</p><h3><strong>Zack：从 “知识空白” 到 “产品落地” 的完整跃迁</strong></h3><p>在参与 AIFirst 与 OpenBuild 联合发起的 Vibe Coding 实战课后，从基础认知到项目落地，再到商业转化，短短六节课的学习不仅填补了我在 Web3 领域的知识空白，更让我对 “高效开发” 有了全新的理解，最终实现从 “有想法” 到 “做出产品” 的完整路径，以下是我的具体收获与感悟。</p><p>第一课的基础认知环节，是我走进 Vibe Coding 世界的起点。Cell 细胞、张晋涛等五位导师毫无保留地分享了各自在开发中的宝贵经验 —— 小到日常编码的避坑技巧，大到长期深耕领域的思维方式，这些 “过来人” 的心得远比单纯的理论更有冲击力。我第一次意识到，Vibe Coding 不止是一种技术方法，更是一种 “轻量化、高效率” 的开发思维，也为后续的学习打下了认知基础。</p><p><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdm3Wo" alt="image.png" title="image.png" loading="lazy"/></p><p>第二课的工具链与工作流教学，张晋涛老师详细拆解了 Vibe Coding 常用的编码工具，不仅讲解了工具的基础操作，更结合具体使用场景、技术栈等分析了各种AI工具。<br/><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdm3Wp" alt="image.png" title="image.png" loading="lazy"/></p><p>第三课 Panda 老师主讲的 Vibe Coding 全流程，彻底改变了我以往 “想到哪写到哪” 的开发习惯。从需求收集时的用户痛点挖掘，到与 AI 协作设计文档、规划任务节点，再到执行开发中的进度把控、测试环节的风险排查，每一步都有清晰的逻辑和方法。跟着这套流程练下来，我发现自己做开发时不再频繁卡顿，原本需要一天完成的小功能，现在半天就能高质量收尾，效率提升的同时也减少了返工。</p><p><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdm3Wq" alt="image.png" title="image.png" loading="lazy"/></p><p>第四课崔棉大师带领的 Web3 NFT 应用实战，是我最有成就感的一课。作为刚接触 Web3 的小白，“从 0 到 1 做产品” 曾是我不敢想的目标，但在课程中，崔老师将复杂的开发流程拆分成一个个小步骤：从环境搭建到合约编写，从前端交互到功能测试，最终看到自己开发的 NFT 应用能正常运行时，还是挺有感触的。</p><p><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdm3Wr" alt="image.png" title="image.png" loading="lazy"/></p><p>第五课 “从 AIVerse 窥见 0G” 对我来说是一次 “跳级挑战”。刚开始听 0G 相关概念时，确实有些吃力，但 Wei 老师没有停留在理论讲解，而是带领我们动手生产 AI NFT—— 从确定 NFT 风格，到用 AI 生成素材，再到部署上链，一步步引导我们理解技术逻辑。虽然过程中遇到了不少新问题，但最终完成的 AI NFT 让我对 AIVerse 与 Web3 的结合有了具象认知。</p><p><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdm3Ws" alt="image.png" title="image.png" loading="lazy"/></p><p>最后一课 Cell 细胞老师关于独立站与付费转化的分享，则为我的开发技能赋予了 “商业价值”。老师没有空谈理论，而是结合自己的实操案例，这节课让我意识到，“做出产品” 只是第一步，“让产品产生价值” 才是关键，也让我对未来将开发技能与商业需求结合有了更多灵感。</p><p><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdm3Wt" alt="image.png" title="image.png" loading="lazy"/></p><p>回顾整个课程，Vibe Coding 带给我的不仅是技术层面的提升，更是思维方式的转变 ，感谢各位导师的倾囊相授，也感谢课程中 “实战驱动、社群支持” 的模式，让我这个 Web3 小白能快速成长。未来，我会继续运用 Vibe Coding 的方法打磨产品，把这次学习的收获转化为真正的执行力，在 Web3 领域持续探索前行。</p><h3><strong>大大黄：重新认识 Vibe Coding，构建 AI 协作新思维</strong></h3><p>这次学完 Openbuild 的 Vibe Coding 全系列课程，整体感觉收获特别大，也算是对整个 AI 编程生态有了比较完整的认识。以前我对 “Vibe Coding” 的理解还停留在“AI 帮你写代码”，但其实它是一整套基于 AI 协作的开发思维和工作流。</p><p>在张老师讲的工具链与工作流那节，我第一次系统地了解了各种 AI 工具的定位，比如 Claude、GPT、Gemini**、以及一些开源模型的差异。以前只是“哪个火用哪个，用着用着为什么降智了也不明白”，现在知道了每个模型擅长的方向，各种付费方式也间接性导致了性能的强弱， Claude 在代码解释和结构化逻辑上更强，GPT 在创意和多模态方面更好，而一些开源模型在部署灵活性上有优势。能根据项目选择最合适的 AI，是我觉得最实用的一点。</p><p><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdm3Wu" alt="image.png" title="image.png" loading="lazy"/></p><p>Vibe Coding 流程让我理解到，不是把 AI 当成“自动写手”，而是要把它融入到整个开发环节中，从需求分析、架构设计到测试部署，AI 都能参与协同。实战课更是帮我打通了理论与落地，学会了用 Claude Code 辅助开发，写代码不再是“问一句、等答案”，而是像和一个懂技术的搭档一起结对编程。效率真的提升了不少。</p><p>包括后续的独立站付费转化，以及辅助合约开发都让我受益匪浅，当然，现在的 Vibe Coding 也有一些痛点，比如不同模型之间的衔接还不够顺畅，AI 对复杂逻辑的长期记忆也有限，很多时候还需要人工“喂上下文”。不过整体趋势很明显 —— AI 编程已经不只是一个工具，而是一种新的工作方式。总体来说，这门课让我重新认识了Vibe Coding 这件事。</p><h3><strong>Latrell：从 “野路子” 到 “正规军”，掌控开发主动权</strong></h3><p>10月份有幸参与了 openbuild 组织的 vibe coding 课程，我也算是从“野路子编程”转向了 vibe coding 正规军。</p><p>面对 coding agent，新人总是很容易落入“局部最优”的 debug 陷阱中：从一个并不清晰的项目构想开始，和过于主动的AI就某个功能实现的方式方法来回拉扯，最后以一份庞大的不可读的项目屎山结束。这或许就是新人使用 vibe coding 最常见的 routine，在一次次的扯皮中逐渐忘掉了自己最初的项目构想。</p><p><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdm3WB" alt="image.png" title="image.png" loading="lazy"/></p><p>如果想要更高的完成度和更好的效果，就必须要提供更为清晰的 PRD/项目框架和任务清单。以清晰的需求，具体技术方法和详细的逐步计划来把项目搭建起来。当然这些内容也都可以交给AI生成，但是这个过程是不可或缺的，这也是为什么目前大多数的 AI building 平台都会有 Plan 这个模式的原因。只要善加利用，效果便与众不同了。</p><p>下面这几个步骤，是我觉得能帮你稳住 vibe，避免被 AI 带偏的关键：</p><p><strong>1. 先跟 AI 一起把 PRD 搞明白</strong></p><p>别一上来就急着让 AI 写代码。先把它当成产品合伙人，用自然语言把你的想法讲清楚，一起磨出一份像样的产品需求文档（PRD）。重点不仅是“要做什么”，更要明确“做到什么样子算成功”，以及技术选型和那些容易忽略的非功能需求（比如性能、安全）。这就好比出发前先看好地图，而不是走到一半才发现方向错了。</p><p><strong>2. 把大目标拆成AI能听懂的具体任务</strong></p><p>PRD 之后，宏观目标需要被拆解成具体、可验证的步骤。这时可以借助像 EARS 这样的格式化方法来描述需求，最大限度减少歧义。同时，明确优先级，划定项目范围，清楚哪些是“必须实现”，哪些可以“后续再说”。这一步的核心是让“完成”的标准变得清晰无比，避免和AI在模糊地带纠缠不清。</p><p><strong>3. 设计要模块化，AI 和人都省心</strong></p><p>在技术设计阶段，重点规划好模块和关键接口，追求模块化设计。清晰的模块边界不仅对人类友好，也让 AI 更容易理解和生成高内聚、低耦合的代码。对于特别复杂的功能，可以先让 AI 弄个简单的参考实现或原型探探路，可行性验证了再深度集成，能少走很多弯路。</p><p><strong>4. 把设计图变成可执行的任务清单</strong></p><p>设计好了，就要把它转化成一步步可执行的开发任务。采用增量实施的策略，逐个模块击破，完成一个再下一个。同时，严格使用 Git 进行版本控制是生命线。这样当AI生成的代码不理想时，你可以直接 git reset --hard 回退，而不是在屎山上艰难地打补丁。</p><p><strong>5. 边做边验，让测试成为安全带</strong></p><p>编码实现阶段，AI 是你的结对编程伙伴，但你不能当甩手掌柜。核心是建立构建-测试-提交的循环流程，让自动化测试为你保驾护航。测试不仅能验证功能，更能让 AI 进行自我检查和分析错误。如果测试失败，直接把错误信息扔给 AI 让它帮你分析和修复，这个过程本身也是推动项目稳健前进的机制。</p><p><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdm3WC" alt="image.png" title="image.png" loading="lazy"/></p><p>总之，vibe coding 不是让你变得更懒，而是让你变得更像一位架构师和指挥官。你的核心价值在于清晰的规划、精准的判断和质量把控，而把重复性的编码工作交给AI这位高效的执行者。</p><p>课程中也提到了一些很有用的 MCP，在此列举一下：</p><ol><li><strong>vibedev-specs MCP：</strong> 预设的开发工作流模板，对于没有技术背景的小白很友好，逐步引导用户提出需求和给出多种方案，相当于是将 PRD，项目方案以及逐步计划的构建过程通过工作流的方式进行了整合。</li><li><strong>Zen MCP：</strong> 协调多个LLM**合作推动开发，Debug 时的“三方会诊”</li><li><strong>BrowserTools MCP：</strong> 允许 Agent 在浏览器中高效的调试，提供包括：日志监控，视觉调试，性能和质量扫描，智能模式（调试与审计等功能）</li><li><strong>Vercel MCP：</strong> 部署上线项目，查询部署日志、管理环境变量和进行版本回滚等应用运维操作</li><li><strong>Github MCP：</strong> 自动提交 commit，操作代码仓库、管理 Issues 和 PR 等的开发工作流</li></ol><p><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdm3WD" alt="image.png" title="image.png" loading="lazy"/></p><p>web3 开发者的实战课程：</p><p>OpenBuild 作为面向 Web3 开发者的开源社区，提供了优秀友好的社区氛围和学习路线，Web3 项目实战一课中让我印象最深的是，它没有空谈概念，而是通过一个完整的项目开发，让我从基础设施的层面，切身理解了 Web3 和 Web2 的根本不同。在 Web2 中，我们开发的是运行在中心化服务器上的、可以随时修改的应用逻辑；而 Web3 要求你转变思维，去设计一套部署后即不可更改、规则对所有人透明的智能合约。这更像是在创建一个“数字协约”，代码本身即是法律，这种特性倒逼你必须以极高的严谨性对待安全和审计。</p><p>课程最宝贵的环节是从零开始设计智能合约并亲手部署到测试网。当你需要连接钱包、支付 Gas 费、等待交易确认时，“去中心化”从一个抽象概念变成了可触摸的真实体验。这对于初入 Web3 的开发者来说，不仅是一次扎实的技术练习，更是一场充满成就感的启蒙之旅。</p><p><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdm3WE" alt="image.png" title="image.png" loading="lazy"/></p><p>给独立开发者的加课：</p><p>在“Vibe Coding 独立站如何付费转化”中，作业鼓励我们与播客主交流沟通，寻找客户的真实需求。我认为这是一个很有趣的设计，对于独立开发者来说，我们最缺少的或许不是技术，而是能走出技术自嗨的幻想中，去和真实的用户和市场交流，沉淀的能力。这个小任务创造一个低风险，结构化的真实反馈场景，播客主通常既是内容创作者，也是某些工具的重度用户，他们能提供关于工作流程、痛点的鲜活洞察。这一步的关键是培养一种心态：我们的产品不是一件需要被完美保护的艺术品，而是一个用于验证想法、连接用户的工具。</p><p><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdm3WF" alt="image.png" title="image.png" loading="lazy"/></p><p>每一个开发者在做的事都一样，那就是用技术去将构想变成现实。回看最初提到的“新手陷阱”，其解药或许正在于此：AI 不是魔法驱动的美梦成真术，而是由你的思考和构想驱动的生产工具。选择 vibe coding 或许并不是选择了一条轻松的道路，一次次不清晰、失败的会话记录是对开发者思维清晰度的深刻映射。这要求着我们进一步精进对产品，对框架，对技术内容的理解，超越代码本身，去学习那些代码之外的事情。继续构建，继续创造，在 AI 的 Token 之海中，用精准的指令描绘出你想要的现实。</p><h3><strong>结语</strong></h3><p>在这个 “个体即团队” 的时代，Web3 竞争的核心早已不是 “会不会写代码”，而是 “能不能快速把想法变成产品”。Vibe Coding 打破了技术壁垒，让 Web3 小白也能实现从 0 到 1 的突破，让每一份创意都能在去中心化的浪潮中快速生长。</p><p>未来，Web3 领域的创新节奏只会更快。随着 AI 编程生态的不断完善，相信会有更多开发者借助 Vibe Coding 的力量，在 Web3 等新兴领域持续探索，让 “从想法到产品” 的路径越来越顺畅，让技术创新的火花不断绽放。</p>]]></description></item><item>    <title><![CDATA[Devconnect 活动报名中！dAI]]></title>    <link>https://segmentfault.com/a/1190000047403382</link>    <guid>https://segmentfault.com/a/1190000047403382</guid>    <pubDate>2025-11-16 21:02:49</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdm3WJ" alt="image.png" title="image.png"/></p><p><strong>欢迎回到 Web3 开发者周刊第 76 期！</strong></p><p>本期周刊内所有黑客松活动、新闻和赏金任务，请大家点击查看原文以获取完整信息。如果您喜欢我们的内容，也欢迎大家订阅 <strong>OpenBuild Substack</strong>，获取最新最全开发者资讯！</p><p>本周，我们将关注以太坊基金会的 dAI 团队2026年路线图制定进展，探讨 DeFi 借贷中预言机的核心作用与故障/优化带来的不同影响，以及 EigenCloud 与 LayerZero** 合作推出的 EigenZero 的功能与价值。除了以上见解，你还可以阅读最新的黑客松资讯和赏金任务。</p><p>值得一提的是，在即将到来的 Devconnect Argentina 期间，两场 OpenBuild 的活动正火热报名中。</p><p>ChainOpera 携手 OpenBuild 打造的「AI Agent x Crypto Afternoon」即将亮相布市。  </p><p><img width="723" height="732" referrerpolicy="no-referrer" src="/img/bVdm3WK" alt="image.png" title="image.png" loading="lazy"/></p><p>报名链接：<a href="https://link.segmentfault.com/?enc=kMW63FR3XlBBs0IXvJz42A%3D%3D.yF7WM4zB9AEv0IaAVbQyba08POMPmaqDXCZjw5qm40k%3D" rel="nofollow" target="_blank">https://luma.com/iin2m6t6</a></p><p>另外，由 OpenBuild、Coset 和 Invisible Garden 共同发起的“Asia Web3 Day @Devconnect Argentina” 将于 11 月 20 日晚上举办。</p><p><img width="723" height="732" referrerpolicy="no-referrer" src="/img/bVdmYNp" alt="image.png" title="image.png" loading="lazy"/></p><p>报名链接：<a href="https://link.segmentfault.com/?enc=%2BItLWLZxgKXGUxXBHQKcrw%3D%3D.2dGgm3%2BxdqcPfTKoChl1asby3rjgDs8ry6DSLb6UTOU%3D" rel="nofollow" target="_blank">https://luma.com/asia-web3-ar25</a></p><p>期待更多开发者加入，一起在 Devconnect Argentina 的现场，共赴这场 Web3 行业盛会！</p><p><img width="723" height="164" referrerpolicy="no-referrer" src="/img/bVdmYMt" alt="image.png" title="image.png" loading="lazy"/></p><p><strong>✅ Move the Future: Aptos x SMU Web3 Innovation Hackathon 2025</strong></p><p>📅 时间：11月10日 - 11月24日</p><p>📍 线上</p><p>💸 奖金：23,000 美元 </p><p>🔗 链接：<a href="https://link.segmentfault.com/?enc=rqTzB4%2Fw2IkF90f3I9poCA%3D%3D.1gY4ZweKQKAh2oiIpcrnWfVDfbMcURWv5NPSUucPK59q4GA5vmL8m2xFrtQhY0mM" rel="nofollow" target="_blank">https://dorahacks.io/hackathon/1759/detail</a></p><p><strong>简介：</strong></p><p>Move the Future 黑客松将学生、开发者和企业家汇聚一堂，共同探索 Aptos Move 生态系统的前沿领域。在未来一周里，参与者们将设计并制作下一代去中心化应用的原型，涵盖数字资产、现实世界资产（RWA）代币化、数据经济、集成人工智能的Web3服务以及协作智能等多个方面。</p><p><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdm3WL" alt="image.png" title="image.png" loading="lazy"/></p><p><strong>✅ Pokéthon: The First Pokémon Hackathon for AI Agents</strong></p><p>📅 时间：11月10日 - 12月1日</p><p>📍 线上</p><p>💸 奖金：20,000 美元 </p><p>🔗 链接：<a href="https://link.segmentfault.com/?enc=X%2BwlL1ShM8Ax1p9dipR1gQ%3D%3D.viDvLgruanVYUduoX3AOdUQKESJDDva%2FkqWmeKIHdiMtuLkL%2FHcgDaaCFCBHUpaB" rel="nofollow" target="_blank">https://dorahacks.io/hackathon/pokethon/detail</a></p><p><strong>简介：</strong></p><p>Pokéthon 是首个以宝可梦为主题的黑客松，致力于打造受宝可梦启发的人工智能智能体。此次黑客松将汇聚人工智能开发者、投资者和收藏家，共同打造受宝可梦启发的智能体，这些智能体融合了人工智能自主性、收藏品特性以及现实世界资产整合功能——为 Web3 领域内宝可梦与人工智能智能体相结合的新领域奠定基础。</p><p><img width="723" height="366" referrerpolicy="no-referrer" src="/img/bVdm3WM" alt="image.png" title="image.png" loading="lazy"/></p><p><strong>✅ Zypherpunk - Zcash Privacy Hackathon</strong></p><p>📅 时间：11月10日 - 12月1日</p><p>📍 线上</p><p>💸 奖金：250,000 美元</p><p>🔗 链接：<a href="https://link.segmentfault.com/?enc=uOTcgEJ6MOLsLjOfjjroQA%3D%3D.qrC76EcJhZeZFzy14svDUGP8ETik1lM8HzylQIOyMnA%3D" rel="nofollow" target="_blank">https://zypherpunk.xyz/</a></p><p><strong>简介：</strong></p><p>Zcash 首届 Zypherpunk 黑客松已经启动！你准备好打造隐私的未来了吗？Zcash 生态系统邀请开发者、数据分析师和内容创作者共同提出以隐私为核心的解决方案。</p><p>参与者将把自己的想法付诸实践，涉及隐私保护人工智能、私密去中心化金融（DeFi）、跨链解决方案、钱包创新、媒体项目等多个领域。</p><p><img width="723" height="458" referrerpolicy="no-referrer" src="/img/bVdm3WN" alt="image.png" title="image.png" loading="lazy"/></p><p><img width="723" height="162" referrerpolicy="no-referrer" src="/img/bVdmYMx" alt="image.png" title="image.png" loading="lazy"/></p><p><strong>📖 以太坊基金会 dAI 团队发布 2026 年路线图 11/10</strong></p><p>👉 链接：<a href="https://link.segmentfault.com/?enc=h0sU8OqOYKbGEkcsxxHUig%3D%3D.uxBrDbd897pFKzo%2BB%2B7pf2tV%2BccxZXn1GzBa8XR705bOVLOfWA4vQ0IsshOcucg6GGB8gVldLIcBugisOBgPvw%3D%3D" rel="nofollow" target="_blank">https://x.com/DavideCrapis/status/1987882455110656488</a></p><p>以太坊基金会人工智能负责人 Davide Crapis 发文表示，正在与以太坊基金会领导层合作制定 dAI 团队 2026 年路线图，旨在建立以太坊作为人工智能的全球去中心化结算和协调基础设施。并感谢围绕 ERC-8004 和 x402 不断壮大的社区。</p><p><strong>📖 当预言机 “三思而后行”：无需许可型预言机的设计 11/13</strong></p><p>👉 链接：<a href="https://link.segmentfault.com/?enc=VDuaNhWAQ3Bv6nJuWaXAFw%3D%3D.B2uH%2F%2FIzEvcN40XqsWOs6nlIE87WSg0YeQ23QKxzdK6RtrY0NoKr%2Fg9S5wXHg%2B%2BUWokygSpzGykm9UZ44V9q1w%3D%3D" rel="nofollow" target="_blank">https://x.com/GearboxProtocol/status/1988636448938217932</a></p><p>DeFi 借贷依赖一个无形却至关重要的组件 ——预言机。一旦预言机出现故障，后果会即刻显现：资金池遭攻击、坏账堆积、资金大规模出逃。但如果预言机设计得当，不仅能为用户带来更优质的体验，还能大幅降低借款方与出借方双方的风险。</p><p><strong>📖 EigenZero：EigenCloud 基础设施如何赋能 LayerZero 下一代跨链安全 11/13</strong></p><p>👉 链接：<a href="https://link.segmentfault.com/?enc=pjETYDR2MiKV42tzeWOFtA%3D%3D.%2FwV8BTMXYsWDVrhMWD0Hh%2FI4lZ0%2F2WWVvJdVcOMFKSIKgcW%2BqbDwXH%2FaiisJ4RxcTBdh%2F5onS5EiIX8Hi2C1dQ%3D%3D" rel="nofollow" target="_blank">https://x.com/eigencloud/status/1988668309085335778?s=20</a></p><p>EigenCloud 与 LayerZero 合作推出 EigenZero，这是加密经济去中心化验证器网络（DVN）框架的首个实现。EigenZero 为 Web3 开发者提供可定制、可量化的跨链消息验证方案，兼容 LayerZero 生态且支持灵活安全配置与定制化开发。</p><p><img width="723" height="164" referrerpolicy="no-referrer" src="/img/bVdmKOQ" alt="image.png" title="image.png" loading="lazy"/></p><p><strong>💸 LayerZero 11/11</strong></p><p>最高赏金 15,000,000 美元 </p><p>LayerZero 是一种全链互操作性协议，它允许开发者无缝地与数十个区块链上的合约进行交互。</p><p><strong>💸 Connext 11/12</strong></p><p>最高赏金 50,000 美元</p><p>Connext 是一种模块化协议，用于在链之间安全地传递资金和数据。开发者可以使用 Connext 构建跨链应用（xApps）—— 即能够同时与多个领域（区块链和 / 或 rollup）进行交互的应用程序。</p><p><strong>💸 Acala 11/14</strong></p><p>最高赏金 200,000 美元 </p><p>Acala 是 Polkadot 的去中心化金融网络和流动性枢纽。它是一个 Layer-1 智能合约平台，具有可扩展性、以太坊兼容性，并为 DeFi 进行了优化，配备内置流动性和现成的金融应用程序。凭借其无需信任的交易所、DOT 流动性质押（LDOT）和 EVM<strong>+，Acala 让开发者能够利用以太坊的优势以及 Substrate</strong> 的全部功能。</p><p><img width="723" height="163" referrerpolicy="no-referrer" src="/img/bVdm3WO" alt="image.png" title="image.png" loading="lazy"/></p><p><strong>🔍 Web3 Security 公开课：入门基础课程</strong></p><p>OpenBuild 社区联合 ResPeer 团队的 KK，推出 Linera 开发者实战系列免费课程。</p><p><img width="723" height="406" referrerpolicy="no-referrer" src="/img/bVdmYKp" alt="image.png" title="image.png" loading="lazy"/></p><p>本次课程将帮助您理解 Linera 如何通过客户端驱动的共识机制**和微链架构来解决传统区块链的性能瓶颈问题。</p><p>👉 报名链接：<a href="https://link.segmentfault.com/?enc=gC0z4rc%2ByR9PCYZxSH7Wew%3D%3D.HulyoOd0ot4pSH3aQfV6CeZgjuxlwsfTQp3ZhM5QCawWy6kb6W4ZFsLcnVaa6myZ" rel="nofollow" target="_blank">https://openbuild.xyz/learn/courses/1082550997</a></p><p><strong>🔍 Web3 Security 公开课：入门基础课程</strong></p><p>为帮助初学者全面了解区块链安全的理论与实践，OpenBuild ×  Exvul 联手，特别设计了一套系统的公开课系列——Web3 安全基础与实战课程。这个系列课程将逐步带领大家从基础安全理论到实际案例分析，开启您的区块链安全之路！ </p><p><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdm3WP" alt="image.png" title="image.png" loading="lazy"/></p><p>通过这门课程，大家将不仅仅学习安全知识，更将成为 Web3 安全生态的一部分，与全球顶尖的区块链安全专家共同推动行业发展。</p><p>👉 报名链接：<a href="https://link.segmentfault.com/?enc=zVrQvUburzp0U7vZU8pbYA%3D%3D.Tx16I7%2FuppMQNxIqW4jkWazSQ%2BsYxDLY4TRva8KV1hLOU2XLn8TCFG8QYkzFahZE" rel="nofollow" target="_blank">https://openbuild.xyz/learn/courses/1083007677</a></p><p><img width="723" height="164" referrerpolicy="no-referrer" src="/img/bVdmKO4" alt="image.png" title="image.png" loading="lazy"/></p><p>OpenBuild 是一个面向 Web3 开发人员的开源社区和平台。我们的目标是将更多的 Web2 开发人员带入 Web3 领域，同时帮助现有的 Web3 开发人员更好地构建并通过我们的产品取得商业成功！</p><p>欢迎在更多平台上关注我们：</p><p><a href="https://link.segmentfault.com/?enc=CAm8%2BAURiPx7c8hgkA55%2Fw%3D%3D.RhZnmG5KahXpc7yAkG64DT8VAroqGL4B00qyvF%2FqhwY%3D" rel="nofollow" target="_blank">https://linktr.ee/openbuild</a> 🙌🙌</p>]]></description></item><item>    <title><![CDATA[Agent 创作者社区召集令 | Sen]]></title>    <link>https://segmentfault.com/a/1190000047403384</link>    <guid>https://segmentfault.com/a/1190000047403384</guid>    <pubDate>2025-11-16 21:02:19</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdmYNY" alt="image.png" title="image.png"/></p><p>Sense Space 正在找热爱 AI Agent 的创作者！无论你是研究 LLM 的开发者，还是热衷探索 Agent 的爱好者，Sense Space 黑客松都为你准备了舞台。</p><p>本次黑客松由 Sense Space 主办，OpenBuild 大力支持！作为深耕开源生态的开发者社区，我们始终致力于为 AI Agent 创作者搭建成长与变现的桥梁，与全球创新者共探 Agent 价值新可能！</p><h3><strong>为什么值得加入？</strong></h3><p>Sense Space 是基于 Verisense 网络的全球首个 Agent 共享经济平台。</p><p>在这里，你可以：</p><p>✅ 构建自己的 AI Agent，让别人使用你的成果并付费</p><p>✅ 分享你的 MCP**（Model Context Protocols），让它被复用并获得收益</p><p>✅ 让你的 Agent 套件为个人、企业提供服务</p><p>就像 Uber 让司机共享行程，YouTube 让创作者分享视频，Sense Space 让你的 AI 能力产生价值，每一个 Agent 都可能成为你的收入来源！</p><h3><strong>黑客松怎么玩？</strong></h3><p><strong>📅 时间：</strong> 10 月 22 日 – 12 月 6 日（足够时间自由构建一个高品质并可以商业化的 agent）</p><p><strong>🎯 主题：</strong> 开放！任何 Agent、任何 MCP、任何框架都可以！</p><p><strong>👉 要求：</strong> 只需要 A2A** 兼容，并注册到 Verisense Network 即可。</p><p><strong>🌐 评审：</strong> 初赛 11/23–11/27，入围名单 12/2公布</p><p><strong>💻 Demo Day</strong>：** 12/6，Top 10 团队现场路演</p><p><strong>注册：</strong> <a href="https://link.segmentfault.com/?enc=VlYYZ%2B%2FJ5bFNzXoDi%2FajWg%3D%3D.Bnn%2BsIAiBFiCQqK4%2B44iyvb4D9Wr6eb%2BofIv%2BRK8QGofDdOMoN%2B1hwklFURTOJX0Hq0XjfP150SOthZN9yIrOw%3D%3D" rel="nofollow" target="_blank">https://dorahacks.io/hackathon/calling-for-all-agents-sf/detail</a></p><h3><strong>奖励很丰厚</strong></h3><p>✅ 现金奖励</p><p>✅ 平台使用特权 &amp; 积分</p><p>✅ 免费使用 LLM API Key和MCP</p><p>✅ 周末度假体验 </p><p>✅ 招聘 &amp; 人脉拓展机会</p><p>✅ ...更多惊喜等你来拿！</p><h3><strong>黑客资源全都有</strong></h3><p>✅ Sense Space Agent &amp; Mini App 部署指南</p><p>✅ LLM Keys（Ambient、Gemini）</p><p>✅ 教程：如何构建可互操作的 Agent</p><p>✅ Discord 社区支持：<a href="https://link.segmentfault.com/?enc=jJ%2FLgKzf%2FOxc15aTE2mwbA%3D%3D.k%2BWnUPuW0jtVvuuNLXjxS%2FN3dInHyBLqRf1JmNjTyFHXSh9pL16RwA02FzXdZUg4" rel="nofollow" target="_blank">https://discord.com/invite/mt4YhFdk</a></p><p>✅ 邮箱：<a href="mailto:dev@verisense.network" target="_blank">dev@verisense.network</a></p><h3><strong>谁来评审？</strong></h3><p>来自 AI、投资和开发者生态的顶级专家，包括 Google, Visa, Alibaba** 等风投机构。你的作品，将被业内大咖现场点评。</p><p>🔥 加入我们，和全球的 Agent 创作者一起：</p><p> Build → Share → Earn！</p><p>点击注册/了解详情 → <a href="https://link.segmentfault.com/?enc=g9w0VmqYZtjTL87YKhEbzQ%3D%3D.EFvnU0cHMUM%2FJof69bxrOR2OCETIL%2BoshHpLWGuWUXorlsn%2BWx6DzQLsiAJmfyVOyOT%2BVJ5n3w0r7KiZf83%2BLg%3D%3D" rel="nofollow" target="_blank">https://dorahacks.io/hackathon/calling-for-all-agents-sf/detail</a></p>]]></description></item><item>    <title><![CDATA[PaddleOCR、RapidOCR即O]]></title>    <link>https://segmentfault.com/a/1190000047403388</link>    <guid>https://segmentfault.com/a/1190000047403388</guid>    <pubDate>2025-11-16 21:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>OCR技术，感觉都像是过时的技术了，现在的多模态（VL）模型那么香，什么场景还会用 OCR 呢？</p><p>VL模型确实好用，但在实际使用后也有很大的缺点。NLP 模型就已经很慢了， VL模型的推理速度更慢，token 费用还是 NLP模型的好几倍。很难在实际项目中大规模使用。</p><p>我曾今以为，VL模型就是 <code>OCR + NPL 模型</code>。先通过 OCR技术识别图片中的文字等元素及其坐标信息。然后在给 NPL模型去推理。实际并不是，下面是二者的介绍</p><h2>1. OCR与VL模型</h2><h3>1.1. OCR</h3><p><strong>OCR</strong> 是一种将图片、扫描文档、手写文字等非文本信息转换成可编辑、可搜索的文本的技术。  <br/>它的核心目标是<strong>让计算机“读懂”图片里的文字</strong>，从而实现文字信息的数字化。</p><blockquote><strong>OCR 的工作原理</strong></blockquote><p>OCR 的基本流程一般包括以下几个步骤：</p><ol><li><p><strong>图像预处理</strong></p><ul><li>去噪（Noise Reduction）：去掉背景噪声，提高识别准确率。</li><li>二值化（Binarization）：将彩色或灰度图转为黑白，方便后续处理。</li><li>纠正倾斜（Deskew）：调整扫描文档的倾斜角度。</li><li>对比度增强（Contrast Enhancement）：提高文字与背景的区分度。</li></ul></li><li><p><strong>文字区域检测</strong></p><ul><li>使用算法（如 CTPN、EAST、DBNet 等）定位图片中的文字区域。</li><li>分割出每一行、每一个字符或词。</li></ul></li><li><p><strong>字符识别</strong></p><ul><li>传统方法：基于模板匹配、特征提取（如投影、轮廓、笔画）+分类器（SVM、KNN）。</li><li>现代方法：基于深度学习的卷积神经网络（CNN）、循环神经网络（RNN）、Transformer 等，直接端到端识别文字。</li></ul></li><li><p><strong>后处理</strong></p><ul><li>拼接字符序列为完整文本。</li><li>使用语言模型或词典进行纠错（如拼写修正）。</li><li>格式化输出（保留段落、表格等结构）。</li></ul></li></ol><blockquote><strong>OCR 的分类</strong></blockquote><p>根据应用场景和识别对象，OCR 可以分为：</p><ul><li><strong>印刷体 OCR</strong>：识别印刷字体（报纸、书籍、票据等）。</li><li><strong>手写 OCR</strong>：识别手写文字（笔记、表单）。</li><li><strong>多语言 OCR</strong>：支持中文、英文、日文、韩文等多种语言。</li><li><strong>特殊字符 OCR</strong>：识别公式、化学结构、乐谱等。</li></ul><p>OCR 的应用场景：</p><ul><li><strong>文档数字化</strong>：将纸质书籍、档案扫描成可编辑文本。</li><li><strong>票据识别</strong>：发票、收据、车票等自动录入。</li><li><strong>身份证/护照识别</strong>：自动读取证件信息。</li><li><strong>车牌识别</strong>：交通管理、停车场收费系统。</li><li><strong>图像搜索</strong>：在图片中搜索文字内容。</li><li><strong>辅助工具</strong>：帮助视障人士“读”文字信息。</li></ul><blockquote><strong>常用 OCR 技术与工具</strong></blockquote><ul><li><p><strong>开源工具</strong>：</p><ul><li><strong>Tesseract OCR</strong>：Google 维护的开源 OCR 引擎，支持多语言。</li><li><strong>PaddleOCR</strong>：百度飞桨的 OCR 工具，支持检测+识别一体化。</li><li><strong>EasyOCR</strong>：基于 PyTorch 的轻量级 OCR。</li></ul></li><li><p><strong>商业服务</strong>：</p><ul><li><strong>Google Cloud Vision API</strong></li><li><strong>Microsoft Azure OCR</strong></li><li><strong>百度智能云 OCR</strong></li><li><strong>阿里云 OCR</strong></li><li><strong>腾讯云 OCR</strong></li></ul></li></ul><h3>1.2. VL模型</h3><p>VL 模型（Vision-Language Model）是 <strong>同时处理视觉信息（图片/视频）和语言信息（文本）的大模型</strong>。  <br/>它的目标是让机器具备类似人类的<strong>看图理解</strong>能力。</p><blockquote><strong>基本架构</strong></blockquote><p>一个典型的 VL 模型由两部分组成：</p><ol><li><p><strong>视觉编码器（Visual Encoder）</strong></p><ul><li>常见架构：ViT（Vision Transformer）、Swin Transformer、CLIP 的视觉部分。</li><li>输入图片 → 输出一系列视觉特征向量。</li><li>这些向量编码了图片的内容：物体、颜色、布局，甚至文字的形状。</li></ul></li><li><p><strong>语言模型（Language Model / Decoder）</strong></p><ul><li>Transformer 架构的大语言模型（LLM）。</li><li>输入文字 token（或者视觉特征经过投影映射的 token）。</li><li>输出文本（描述、回答、推理结果）。</li></ul></li><li><p><strong>跨模态对齐（Cross-Modal Alignment）</strong></p><ul><li>视觉特征和语言特征通过投影到同一语义空间，实现信息融合。</li><li>方式：Cross-Attention、多模态 Transformer、对比学习（Contrastive Learning）。</li></ul></li></ol><blockquote><strong>训练方式</strong></blockquote><ul><li><strong>配对数据</strong>：图片 + 文本描述（caption）、视觉问答（Q&amp;A）、OCR标注等。</li><li><strong>多任务训练</strong>：图像描述、问答、推理、文字转写、布局分析等。</li><li><strong>对比学习</strong>（如 CLIP）：让图片和文本在同一语义空间靠近。</li></ul><blockquote><strong>VL 模型中的“文字识别”</strong></blockquote><p>VL 模型可以“直接从像素识别文字”，它的文字识别过程不是传统 OCR 的分离式模块，而是<strong>融合在视觉编码器 + 语言模型的联合训练中</strong>：</p><ul><li>视觉编码器会捕捉到文字的形状特征（例如字母的笔画、汉字的结构）。</li><li>语言模型部分在训练中学会将这些视觉特征映射到对应的字符 token。</li><li>推理时，模型在回答问题或生成描述时，可以直接输出图片中的文字，而无需调用外部 OCR。</li></ul><p><strong>例子</strong>：</p><blockquote>输入：一张街景图  <br/>任务：问“这家店的名字是什么？”  <br/>模型：视觉编码器提取整张图的特征，语言模型根据特征直接生成店名。</blockquote><h3>1.3. 区别</h3><p><strong>传统 OCR 流程：</strong></p><ol><li><strong>检测文字区域</strong>（Text Detection）：用专门的检测网络（如 EAST、DBNet）找出图片中有文字的地方。</li><li><strong>裁剪这些区域</strong>，送到识别网络（如 CRNN）逐个识别字符。</li><li>输出结构化文本。</li></ol><p><strong>端到端 VL 模型</strong>（例如 GPT-4V、Kosmos-2、Qwen-VL）：</p><ul><li>没有显式的“检测”步骤，也不会裁剪。</li><li>视觉编码器直接接收整张图片的像素，并输出一组向量。</li><li>语言模型通过这些向量<strong>在推理时“自己”找出文字的位置并识别</strong>，因为它在训练时已经学会了这个能力。</li></ul><blockquote><strong>举个类比</strong></blockquote><p>你可以把它想成一个人：</p><ul><li>传统 OCR：先用眼睛扫描文字位置，放大局部，逐个认字。</li><li>端到端 VL 模型：你看整张照片的时候，就能在脑中同时看到文字和图像，并且直接理解它写的是什么，无需额外“找字”步骤。</li></ul><blockquote><strong>VL模型识字的核心：视觉编码器 + 文本解码器联合训练</strong></blockquote><p>（1）视觉编码器</p><ul><li>常见是 <strong>ViT（Vision Transformer）</strong> 或 CNN+Transformer。</li><li>把图片切成小块（patches），每个 patch 转成向量（embedding）。</li><li>这些向量包含了局部的颜色、形状、纹理等信息。</li><li>对于有文字的区域，这些向量会包含字符的形状信息。</li></ul><p>（2）跨模态对齐</p><ul><li>模型训练时，会输入图片和它对应的文本描述（caption）、文字转写（OCR标签）、或视觉问答答案。</li><li>损失函数会引导模型让视觉特征和文字输出对齐。</li><li>例如：训练数据可能是图片+“这张图片上的牌子写着 STOP”，模型必须学会从像素中找到对应的字母形状并生成“STOP”。</li></ul><p>（3）解码文字</p><ul><li>语言模型部分（Transformer解码器）接收视觉编码器输出的向量。</li><li>当模型需要输出文字时，它会从视觉特征中“取出”对应的形状信息并映射到字母/汉字的token。</li><li>因为模型的词表里有字母、汉字等符号，视觉特征被训练成可以激活对应的token概率。</li></ul><h3>1.4. 适用于不同业务场景</h3><ul><li><strong>OCR 是一种单模态视觉任务</strong>，目标是精准提取图片中的文字，通常输出纯文本+坐标。</li><li><strong>VL 模型是多模态 AI 系统</strong>，文字识别只是它的一项能力，它更关注文字与视觉、语言的融合与推理。</li><li><p><strong>工业应用中常用混合方案</strong>：</p><ul><li>用 OCR 提供高精度文字和位置信息</li><li>用 VL 模型做语义理解、推理、生成</li></ul></li></ul><blockquote><strong>OCR</strong></blockquote><ul><li><p><strong>优势</strong></p><ul><li>精度高，尤其是小字、低分辨率、复杂字体</li><li>可输出精确位置坐标</li><li>结构化输出（适合文档、表格）</li></ul></li><li><p><strong>劣势</strong></p><ul><li>不理解文字与图像的语境</li><li>需要额外 NLP 才能做推理</li><li>对非文字视觉任务（如物体识别）无能为力</li></ul></li></ul><blockquote><strong>VL 模型</strong></blockquote><ul><li><p><strong>优势</strong></p><ul><li>同时理解文字和视觉内容</li><li>能做跨模态推理（例如“图中写的折扣信息对应哪种商品？”）</li><li>可端到端完成任务（不依赖外部 OCR）</li></ul></li><li><p><strong>劣势</strong></p><ul><li>小字或特殊字体识别精度可能不如专用 OCR</li><li>输出坐标、版面结构的能力弱（除非特别训练）</li><li>训练成本和数据需求大</li></ul></li></ul><blockquote><strong>应用场景的区别</strong></blockquote><table><thead><tr><th>场景</th><th>推荐 OCR</th><th>推荐 VL 模型</th></tr></thead><tbody><tr><td>扫描文档电子化</td><td>✅ 精准提取文本</td><td>❌ 不擅长结构化输出</td></tr><tr><td>发票/票据录入</td><td>✅ 高精度文字识别</td><td>❌ 推理不必要</td></tr><tr><td>场景文字理解（招牌、广告）</td><td>OCR 提取文字 + NLP</td><td>✅ 可直接理解文字与场景关系</td></tr><tr><td>图文问答</td><td>❌</td><td>✅</td></tr><tr><td>图表数据问答</td><td>OCR 提取数值 + LLM</td><td>✅ 端到端理解图表内容</td></tr></tbody></table><h2>2. PaddleOCR 与 RapidOCR</h2><h3>2.1. PaddleOCR</h3><h4>2.1.1 介绍</h4><p>PaddleOCR 是由 <strong>百度飞桨（PaddlePaddle）团队</strong>开源的 OCR（Optical Character Recognition，光学字符识别）全流程解决方案。  <br/>它的目标是：</p><blockquote>提供从数据准备、模型训练、评估，到推理、部署的<strong>端到端 OCR 工具库</strong>，支持多语言、多场景。</blockquote><p>首个版本在 2020 年推出，至今已经迭代到 <strong>PP-OCRv5</strong>，并形成了一个庞大的开源社区。</p><blockquote><strong>技术特点</strong></blockquote><ul><li><strong>全流程支持</strong>：训练 + 推理 + 部署。</li><li><strong>多语言多场景</strong>：适合全球化应用。</li><li><strong>轻量化模型</strong>：PP-OCR 系列适合移动端。</li><li><strong>社区活跃</strong>：有丰富的教程和预训练模型。</li></ul><blockquote><strong>适用场景</strong></blockquote><ul><li>需要从零训练或微调模型。</li><li>需要版面分析、表格识别等高级功能。</li><li>部署环境能接受 PaddlePaddle 框架的体积和依赖。</li><li>研究和教学用途。</li></ul><h4>2.1.2 核心功能</h4><ol><li><p><strong>文字检测</strong></p><ul><li>定位图片中的文字区域。</li><li>支持多种检测模型：DBNet、EAST、SAST、PSE 等。</li><li>支持旋转文本检测。</li></ul></li><li><p><strong>文字识别</strong></p><ul><li>将检测到的文字区域转为可读文本。</li><li>支持多语言（80+种），包括中文、英文、日文、韩文、阿拉伯文等。</li><li>常用识别模型：CRNN、SVTR、RARE、Rosetta 等。</li></ul></li><li><p><strong>方向分类</strong></p><ul><li>检测文字方向（如 0°、90°、180°、270°），自动矫正。</li></ul></li><li><p><strong>版面分析</strong></p><ul><li>对复杂文档进行版面结构解析（Layout Analysis）。</li><li>表格识别、公式识别、印章检测等。</li></ul></li><li><p><strong>模型训练与优化</strong></p><ul><li>支持自定义数据集训练。</li><li>提供数据增强、迁移学习、蒸馏、量化等优化方法。</li></ul></li><li><p><strong>多平台部署</strong></p><ul><li>支持 Python、C++、Paddle Lite（移动端）、Paddle Serving（服务端）、Docker 等。</li></ul></li></ol><h3>2.2. RapidOCR</h3><h4>2.2.1 背景</h4><p>RapidOCR 是一个<strong>轻量级 OCR 推理库</strong>，由国内开发者开源，核心理念是：</p><blockquote><strong>只做 OCR 推理，不负责训练，简化部署和集成，让 OCR 模型可以在不同平台快速运行。</strong></blockquote><p>它本质上是一个<strong>精简版推理工具</strong>，可以直接加载 PaddleOCR 训练好的模型（或其他兼容模型），并在多种推理后端运行。</p><blockquote><strong>技术特点</strong></blockquote><ul><li><strong>轻量化</strong>：去掉训练、数据处理等复杂功能。</li><li><strong>启动快</strong>：不加载完整深度学习框架。</li><li><strong>灵活后端</strong>：可根据硬件选择最佳推理引擎。</li><li><strong>易集成</strong>：适合嵌入到 C++ 项目、移动应用等。</li></ul><blockquote><strong>适用场景</strong></blockquote><ul><li>只做推理，不需要训练。</li><li>需要在移动端、嵌入式设备部署。</li><li>对启动速度和资源占用敏感。</li><li>希望减少依赖，简化部署流程。</li></ul><h4>2.2.2 核心功能</h4><ol><li><p><strong>模型加载与推理</strong></p><ul><li>支持检测模型 + 识别模型的加载。</li><li>输入图片，输出文字识别结果。</li></ul></li><li><p><strong>多推理后端支持</strong></p><ul><li>ONNX Runtime（跨平台）</li><li>NCNN（移动端 / 嵌入式）</li><li>Paddle Inference（原生 Paddle 推理）</li><li>OpenCV DNN（轻量推理）</li></ul></li><li><p><strong>跨平台运行</strong></p><ul><li>Windows / Linux / macOS / Android / iOS / 嵌入式设备。</li></ul></li><li><p><strong>简洁 API</strong></p><ul><li>几行代码即可完成 OCR 推理。</li></ul></li></ol><h3>2.3. 二者关系</h3><p>很多人在初学 PaddleOCR 和 RapidOCR 的时候都会有同样的疑惑：  <br/><strong>“既然 RapidOCR 也是用 PaddleOCR 的模型，那直接用 PaddleOCR 推理不就好了？为什么还要用 RapidOCR？”</strong></p><h4>2.3.1. 二者对比</h4><blockquote><strong>直接运行 PaddleOCR 的特点</strong></blockquote><ul><li><p><strong>优点</strong></p><ol><li>功能非常全面：除了推理，还能训练、评估、版面分析、多语言支持等。</li><li>官方维护，文档和社区活跃。</li><li>支持 PaddlePaddle 的全套生态（Paddle Lite、Paddle Serving 等）。</li><li>直接使用预训练模型，简单命令即可完成 OCR。</li></ol></li><li><p><strong>缺点</strong></p><ol><li><strong>依赖多</strong>：需要安装 PaddlePaddle（深度学习框架），体积较大。</li><li><strong>启动慢</strong>：第一次加载模型和框架初始化时间较长。</li><li><strong>跨平台部署复杂</strong>：在 Android/iOS/嵌入式设备上部署 PaddlePaddle 推理库相对麻烦。</li><li><strong>集成成本高</strong>：如果你只是想在一个小工具里做推理，PaddleOCR 的代码和依赖会显得“笨重”。</li></ol></li></ul><blockquote><strong>RapidOCR 的特点</strong></blockquote><ul><li><p><strong>优点</strong></p><ol><li><strong>轻量化</strong>：只保留推理部分，代码和依赖精简很多。</li><li><strong>跨平台方便</strong>：支持 ONNX Runtime、NCNN、OpenCV 等多种后端，适合在 Windows/Linux/macOS/Android/iOS/嵌入式设备部署。</li><li><strong>启动快</strong>：不需要加载完整的 Paddle 框架，推理引擎初始化速度快。</li><li><strong>集成简单</strong>：API 很精简，几行代码就能跑通。</li><li><strong>多后端选择</strong>：可以根据硬件选择最佳推理引擎（例如在 GPU 用 TensorRT，在移动端用 NCNN）。</li><li><strong>依赖可控</strong>：比如你用 ONNX Runtime 推理，只需要安装 onnxruntime 库，不必安装 PaddlePaddle。</li></ol></li><li><p><strong>缺点</strong></p><ol><li>不能训练模型。</li><li>功能比 PaddleOCR 少（比如版面分析、表格识别等高级功能不内置）。</li><li>文档和社区规模比 PaddleOCR 小。</li></ol></li></ul><blockquote><strong>对比结论</strong></blockquote><table><thead><tr><th>需求/特性</th><th>PaddleOCR</th><th>RapidOCR</th></tr></thead><tbody><tr><td><strong>功能范围</strong></td><td>全流程（训练+推理+分析）</td><td>仅推理（检测+识别）</td></tr><tr><td><strong>依赖体积</strong></td><td>大（需要 PaddlePaddle）</td><td>小（可选 ONNX/NCNN 等）</td></tr><tr><td><strong>跨平台部署</strong></td><td>相对复杂</td><td>非常方便</td></tr><tr><td><strong>启动速度</strong></td><td>较慢</td><td>较快</td></tr><tr><td><strong>集成成本</strong></td><td>高（代码量大）</td><td>低（API 简单）</td></tr><tr><td><strong>适合场景</strong></td><td>研究、训练、功能全面部署</td><td>轻量化部署、移动端、嵌入式</td></tr></tbody></table><h4>2.3.2. 什么场景适用使用</h4><blockquote><strong>什么时候选 PaddleOCR，什么时候选 RapidOCR？</strong></blockquote><ul><li><p><strong>选 PaddleOCR</strong>：</p><ul><li>需要自己训练模型。</li><li>需要版面分析、表格识别等高级功能。</li><li>部署环境可以接受 PaddlePaddle 的体积和依赖。</li><li>开发阶段，需要快速测试各种模型和参数。</li></ul></li><li><p><strong>选 RapidOCR</strong>：</p><ul><li>只做推理，不需要训练。</li><li>目标平台是移动端、嵌入式设备、跨平台应用。</li><li>需要轻量化部署，减少依赖和启动时间。</li><li>想要灵活选择推理后端（ONNX Runtime、NCNN、TensorRT 等）。</li><li>对集成简洁性要求高（比如嵌入到一个 C++ 项目或小型工具里）。</li></ul></li></ul><blockquote><strong>一句话总结</strong></blockquote><ul><li><strong>PaddleOCR</strong> 是一个功能全面的“工厂”，适合生产和测试模型；</li><li><strong>RapidOCR</strong> 是一个轻量化的“收银机”，适合快速、低成本地部署现成模型。</li><li>如果你只需要跑模型，RapidOCR 会更轻、更快、更好集成。</li></ul><h3>2.4. 本地快速体验</h3><h4>2.4.1. PaddleOCR</h4><p>使用 PaddleOCR，需要先安装 Paddle 飞桨框架，虽然官方命令简单，但要处理本地电脑的各类环境版本问题。</p><p>如果只是体验，建议直接安装 Docker 版本，参考官方文档：<a href="https://link.segmentfault.com/?enc=bRvawag4BcY5J7nGw5LzwQ%3D%3D.oDdIp9i6M7FgLhvWJexuOY39Kg%2FJ2TMDMMMXutSEvPvDeD%2BgSsM02wNrRMGWAX8VDhPfnO8I1J0erl4HGzeW5A%3D%3D" rel="nofollow" target="_blank">Paddle 安装文档</a></p><p>参考其中 <code>基于 Docker 安装飞桨</code> 部分，没有 GPU 条件，就选择 CPU 即可。</p><p>也可以参考以下脚本：</p><pre><code class="shell">#!/bin/bash
# 启动 PaddleOCR 容器（后台运行且保持不退出，并自动安装 paddleocr）

CONTAINER_NAME="paddleocr"
IMAGE="ccr-2vdh3abv-pub.cnc.bj.baidubce.com/paddlepaddle/paddle:3.0.0"

# 如果容器已经存在，则先删除
if [ "$(docker ps -aq -f name=$CONTAINER_NAME)" ]; then
    echo "删除已有容器 $CONTAINER_NAME..."
    docker rm -f $CONTAINER_NAME
fi

echo "启动容器 $CONTAINER_NAME..."
docker run --name $CONTAINER_NAME \
    --platform linux/amd64 \
    -v "$PWD":/paddle \
    -p 8080:8080 \
    --shm-size=8G \
    -d \
    $IMAGE \
    tail -f /dev/null

# 等容器启动稳定
sleep 3

echo "在容器中安装 paddleocr..."
docker exec $CONTAINER_NAME python -m pip install paddleocr

echo "容器 $CONTAINER_NAME 已启动并安装完成"
echo "进入容器请执行：docker exec -it $CONTAINER_NAME /bin/bash"</code></pre><p>安装完成后，既可以通过 <code>paddle</code> 的 cli 执行命令训练、推理。</p><p>当然，最方便的方式是通过 HTTP 方式调用 OCR 推理服务。</p><p>官网也提供了启动 HTTP 服务端的文档：<a href="https://link.segmentfault.com/?enc=9tfAtD7Hd3lpyeg1yc1tGg%3D%3D.%2BxWUxI5fdW4zLhFazD1mmKd5uwIAyqN73tGWTbVdhoDdJmC1lCsPmkT80vAbovdjA3NSbS41BvEXk4HOeqNYm2O5X8%2BiIXtgNP5EsPRnDus%3D" rel="nofollow" target="_blank">服务化部署</a></p><p>脚本中映射 8080 端口，就是为了宿主机能直接方法 HTTP 服务端。</p><p>调用 HTTP API 参数文档：<a href="https://link.segmentfault.com/?enc=SSmr9CAztTIZA573mVYD1Q%3D%3D.6gQDLOKNLwsKYslE4p%2F9e7vssyFFh24VbQi4%2BmPNPAotqvzxh%2BYImq%2B%2Fg44%2BYaTHgRZ5KqgCBsWe%2B5U9a%2B%2FSh7Z40xMi8j8o%2BXC6hGRLGRo%3D" rel="nofollow" target="_blank">API 请求参数说明</a></p><blockquote><strong>上传图片方式限制</strong></blockquote><p>通过看API文档可见，上传图片/PDF时，仅支持两种方式：</p><ul><li>文件 URL</li><li>BASE64 编码</li></ul><p>默认不支持文件流传输，这两种方式都会限制上传图片速度。</p><h4>2.4.2. RapidOCR</h4><p>Rapid OCR 的官方文档参考：<a href="https://link.segmentfault.com/?enc=FT6p53vXIJ3%2FSJwkgcuoDw%3D%3D.Z36OVgYrccd6PZ7y%2F3KLFyhOL4AyqqzQrKjBRkb%2Fbsq%2FtkOXldg0g7LZzhIr8%2Frz0lN7Q5IVir8Aip8BLtKas94jJaEAETD5B4Wy8xlOktUXBC%2FlYV7WOvmgcfE7NloX" rel="nofollow" target="_blank">RapidOCR文档</a></p><p>通常安装 <code>rapidocr</code> 即可实现图片推理，有通过官方提供的配置参数，可以自定义不同场景的配置。</p><p>就包括使用的模型，可以直接配置 paddleocr 最新的 v5 模型。当然，推荐使用基于 ONNX 引擎的模型格式。</p><p>也可以通过安装 <code>rapidocr_web</code> 实现功能更丰富的 WEB 服务。rapidocr_web是基于rapidocr库封装的web版OCR程序。它可以让小伙们快速在本地启动OCR服务，支持剪贴板、拖拽和选择图像文件上传识别，同时具有一键复制识别文本功能</p><p>如果更方便的安装，并且只需要 HTTP API，可以通过 <code>rapidocr_api</code> 安装。该包是将rapidocr库做了API封装，采用FastAPI + uvicorn实现。</p><p>这里也推荐 Docker 快速安装的法子。这次官网的文档不是很准确，仓库已经更新为<code>RapidOCRAPI</code>，但文档依然是 <code>RapidOCR</code>。踩过坑，推荐自己构建镜像再运行。</p><p>在 <a href="https://link.segmentfault.com/?enc=rz94KCwwrtOT%2BRuJZZVVwg%3D%3D.a7ybjDxy1XO0ys1EeqpNgz4WKN2WyRClh2Rnkv9YeQHrhW6tK205Q0M3cUHJztcr" rel="nofollow" target="_blank">RapidOCRAPI - releases</a> 中拉取最新 releases 的代码下来，在项目根目录有 Dockerfile 文件，直接基于该 Dockerfile 构建镜像，然后安装文档指令运行即可。</p><p>容器启动时，HTTP 服务器即自动启动了。可以在容器内修改模型文件等配置。这里的 API 就支持基于文件流上传，而且感觉推理速度也比 PaddleOCR快。</p><h2>3. ONNX</h2><p>PaddleOCR 模型能在 RapidOCR 上运行，就是因为转换成 ONNX格式。包括后续还有文章介绍 Yolo 模型，也是要转换成 ONNX 格式才会有更多部署平台。</p><p>好的，我们来系统、详细地介绍一下 <strong>ONNX</strong>（Open Neural Network Exchange），包括它的背景、作用、技术细节、生态、优缺点、使用场景，以及它与 PaddleOCR/RapidOCR 的关系。</p><h3>3.1. 定义</h3><p><strong>ONNX</strong> 全称 <strong>Open Neural Network Exchange</strong>，是一个 <strong>开放的深度学习模型交换格式</strong> 和 <strong>跨框架推理生态</strong>。  <br/>它由 <strong>微软（Microsoft）</strong> 和 <strong>Facebook（Meta）</strong> 在 2017 年联合推出，后来得到了 <strong>AWS、NVIDIA、Intel、AMD</strong> 等众多厂商的支持。</p><p><strong>核心目标</strong>：</p><blockquote>提供一个统一的中间表示（Intermediate Representation, IR），让不同深度学习框架之间的模型可以互相转换和运行，从而避免“框架锁定”。</blockquote><ul><li><strong>ONNX</strong> = 深度学习模型的“通用语言”，让模型可以跨框架、跨平台运行。</li><li>它解决了训练框架和部署环境之间的“语言不通”问题。</li><li>在 OCR 场景下，ONNX 让 PaddleOCR 的模型可以用 RapidOCR 在各种设备上运行。</li></ul><h3>3.2. 解决痛点</h3><p>在深度学习应用中，常见的痛点是：</p><ul><li><strong>跨框架问题</strong>：模型在 PyTorch 中训练，但部署环境只支持 TensorFlow 或 C++。</li><li><strong>跨平台问题</strong>：需要在移动端、嵌入式设备上运行模型，但原框架不适合直接部署。</li><li><strong>硬件优化问题</strong>：希望在不同硬件（CPU / GPU / NPU / FPGA）上快速切换推理引擎。</li></ul><p>ONNX 就像一个<strong>通用适配器</strong>：</p><ul><li>训练时用你喜欢的框架（PyTorch、TensorFlow、PaddlePaddle 等）。</li><li>导出成 ONNX 格式。</li><li>部署时用任何支持 ONNX 的推理引擎（ONNX Runtime、TensorRT、OpenVINO、NCNN 等）。</li></ul><h3>3.3. ONNX 的核心组成</h3><blockquote><strong>ONNX 模型格式</strong></blockquote><ul><li>文件后缀 <code>.onnx</code>。</li><li>基于 <strong>Protocol Buffers</strong> 存储。</li><li><p>包含：</p><ul><li><strong>计算图结构</strong>（Graph）</li><li><strong>算子定义</strong>（Operators）</li><li><strong>模型权重</strong>（Weights）</li></ul></li><li>结构化且跨平台可解析。</li></ul><blockquote><strong>ONNX 算子集（Operator Set）</strong></blockquote><ul><li>定义了标准算子（如 Conv、Relu、MatMul、Softmax 等）。</li><li>每个算子有版本号（opset version），保证不同版本间的兼容性。</li><li>框架在导出时会选择合适的 opset 版本。</li></ul><blockquote><strong>ONNX Runtime</strong></blockquote><ul><li>由微软开源的高性能推理引擎。</li><li><p>支持多种硬件后端：</p><ul><li>CPU（默认）</li><li>GPU（CUDA）</li><li>TensorRT</li><li>DirectML（Windows GPU）</li><li>OpenVINO（Intel CPU/FPGA）</li></ul></li><li>提供多语言 API：Python、C、C++、C#、Java、JavaScript 等。</li></ul><h3>3.4. ONNX 的工作流程</h3><p>一个典型的 ONNX 使用流程：</p><ol><li><p><strong>训练模型</strong></p><ul><li>在 PyTorch / TensorFlow / PaddlePaddle / MXNet 等框架中训练。</li></ul></li><li><p><strong>导出 ONNX 模型</strong></p><ul><li><p>PyTorch:</p><pre><code class="python">torch.onnx.export(model, input_data, "model.onnx", opset_version=11)</code></pre></li><li><p>TensorFlow:</p><pre><code class="bash">python -m tf2onnx.convert --saved-model ./model --output model.onnx</code></pre></li><li><p>PaddlePaddle（PaddleOCR）：</p><pre><code class="bash">python tools/export_model.py --output_dir ./inference --export_onnx True</code></pre></li></ul></li><li><p><strong>加载并推理</strong></p><ul><li><p>使用 ONNX Runtime（或其他支持 ONNX 的引擎）：</p><pre><code class="python">import onnxruntime as ort
session = ort.InferenceSession("model.onnx")
outputs = session.run(None, {"input": input_array})</code></pre></li></ul></li><li><p><strong>部署到目标平台</strong></p><ul><li>Windows / Linux / macOS / Android / iOS / 嵌入式设备等。</li></ul></li></ol><blockquote><strong>ONNX 的常见使用场景</strong></blockquote><ol><li><p><strong>跨框架部署</strong></p><ul><li>在 PyTorch 训练 → 转 ONNX → 在 TensorRT 推理。</li></ul></li><li><p><strong>移动端 / 嵌入式部署</strong></p><ul><li>转 ONNX → 用 NCNN/MNN/OpenVINO 等运行。</li></ul></li><li><p><strong>云端推理服务</strong></p><ul><li>用 ONNX Runtime 部署到云端，支持多语言调用。</li></ul></li><li><p><strong>模型优化</strong></p><ul><li>ONNX Runtime 支持图优化、算子融合、量化等。</li></ul></li></ol><h3>3.5. 优缺点</h3><blockquote><strong>ONNX 的优点</strong></blockquote><ol><li><p><strong>跨框架</strong></p><ul><li>支持 PyTorch、TensorFlow、PaddlePaddle、MXNet 等互转。</li></ul></li><li><p><strong>跨平台</strong></p><ul><li>同一个 ONNX 模型可在不同操作系统和硬件上运行。</li></ul></li><li><p><strong>高性能</strong></p><ul><li>ONNX Runtime 针对不同硬件有深度优化。</li></ul></li><li><p><strong>生态丰富</strong></p><ul><li>TensorRT、OpenVINO、NCNN、MNN 等均支持 ONNX。</li></ul></li><li><p><strong>开放标准</strong></p><ul><li>由社区维护，透明可扩展。</li></ul></li></ol><blockquote><strong>ONNX 的缺点 / 限制</strong></blockquote><ol><li><p><strong>算子兼容性问题</strong></p><ul><li>不同框架���某些自定义层可能无法直接转换，需要自己实现。</li></ul></li><li><p><strong>版本问题</strong></p><ul><li>ONNX 模型的 opset 版本不匹配时可能会报错。</li></ul></li><li><p><strong>动态图支持有限</strong></p><ul><li>对部分动态图功能支持不如原框架灵活。</li></ul></li></ol><h3>3.6. 与 PaddleOCR/RapidOCR的关系</h3><ul><li><p><strong>PaddleOCR</strong></p><ul><li>可将训练好的检测模型和识别模型导出为 ONNX 格式。</li><li>方便跨平台部署，不依赖 PaddlePaddle。</li></ul></li><li><p><strong>RapidOCR</strong></p><ul><li>内置 ONNX Runtime 后端。</li><li>可以直接加载 PaddleOCR 导出的 ONNX 模型进行推理。</li><li>这样就能在没有 PaddlePaddle 框架的环境中运行 OCR（例如移动端或嵌入式）。</li></ul></li></ul><p><strong>简单来说</strong>：  <br/>ONNX 是模型的通用格式，RapidOCR 是一个能读取 ONNX 模型并运行的轻量化推理工具。</p><h3>3.7. Java项目可运行ONNX模型</h3><ul><li><strong>ONNX</strong> 本身是一种通用的模型文件格式（<code>.onnx</code>），不依赖具体的编程语言。</li><li>要在 Java（包括 Spring Boot）中运行 ONNX 模型，需要一个支持 ONNX 格式的推理引擎。</li><li><strong>ONNX Runtime</strong> 是官方提供的高性能推理引擎，它有 <strong>Java API</strong>，可以在 JVM 环境中直接加载 <code>.onnx</code> 模型并运行。</li><li><p>因此，在 Spring 项目中，你可以：</p><ol><li>把 ONNX 模型文件放在项目资源目录或本地路径。</li><li>使用 ONNX Runtime Java API 加载模型。</li><li>在业务代码中调用推理方法获得结果。</li></ol></li></ul><p>在 Maven 项目的 <code>pom.xml</code> 中添加 ONNX Runtime 依赖：</p><pre><code class="xml">&lt;dependency&gt;
    &lt;groupId&gt;com.microsoft.onnxruntime&lt;/groupId&gt;
    &lt;artifactId&gt;onnxruntime&lt;/artifactId&gt;
    &lt;version&gt;1.15.1&lt;/version&gt; &lt;!-- 版本可根据需要选择 --&gt;
&lt;/dependency&gt;</code></pre><p>如果需要 GPU（CUDA）推理，可以用：</p><pre><code class="xml">&lt;dependency&gt;
    &lt;groupId&gt;com.microsoft.onnxruntime&lt;/groupId&gt;
    &lt;artifactId&gt;onnxruntime_gpu&lt;/artifactId&gt;
    &lt;version&gt;1.15.1&lt;/version&gt;
&lt;/dependency&gt;</code></pre><p>没错，Java项目中，你可以本地直接运行 PaddleOCR 的模型文件， 前提是和 RapidOCR 一样，先转成 ONNX 格式。</p>]]></description></item><item>    <title><![CDATA[Web3 安全必学！基础 + 实战全覆盖]]></title>    <link>https://segmentfault.com/a/1190000047403316</link>    <guid>https://segmentfault.com/a/1190000047403316</guid>    <pubDate>2025-11-16 20:02:50</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>随着 Web3 生态系统的快速发展，区块链安全已成为保障去中心化未来的核心支柱。无论是智能合约开发者、DApp 架构师，还是普通区块链用户，对安全知识的掌握都至关重要。</p><p>为帮助初学者全面了解区块链安全的理论与实践，<strong>OpenBuild ×  Exvul 联手</strong>，特别设计了一套系统的公开课系列——Web3 安全基础与实战课程。这个系列课程将逐步带领大家从基础安全理论到实际案例分析，开启您的区块链安全之路！ </p><p><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdm3VI" alt="image.png" title="image.png"/></p><p>通过这门课程，大家将不仅仅学习安全知识，更将成为 Web3 安全生态的一部分，与全球顶尖的区块链安全专家共同推动行业发展。</p><h3><strong>课程要点</strong></h3><h4><strong>区块链安全的基础知识</strong></h4><ul><li>深入理解分布式账本**、共识算法和智能合约的工作原理。</li><li>探索区块链生态中的常见安全威胁，如 51% 攻击、私钥泄露、智能合约漏洞等。</li></ul><h4><strong>链上安全威胁的识别与防护</strong></h4><ul><li>学习如何识别常见的智能合约漏洞（如重入攻击、整数溢出、权限控制问题）。</li><li>掌握安全开发的最佳实践，避免常见的合约安全问题。</li></ul><h4><strong>主流区块链安全工具与技术</strong></h4><ul><li>探索主流的安全审计工具与平台，如 BlockSec** 和 Exvul 平台的专属工具。</li><li>学习如何通过这些工具检测漏洞并优化智能合约代码。</li></ul><h4><strong>实际案例分析与实战演练</strong></h4><ul><li>通过真实案例（如 DeFi 项目漏洞事件）分析攻击过程与防护策略。</li><li>实战演练：修复一个存在漏洞的智能合约，提升您的实操能力。</li></ul><h4><strong>课程大纲</strong></h4><h4><strong>第一课：入门 Web3 必修的安全基础课</strong></h4><p>Web3 入门必冲，安全地基课  带你打牢安全底层逻辑！</p><p><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdm3VJ" alt="image.png" title="image.png" loading="lazy"/></p><h4><strong>第二课：揭秘合约安全隐患，常见致命漏洞详解</strong></h4><p>智能合约作为 Web3 重要组成部分，但漏洞藏雷无数，本节课带你深度扒光常见致命漏洞，教你避雷对策。</p><p><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdm3VK" alt="image.png" title="image.png" loading="lazy"/></p><h4><strong>第三课：拆解交易攻击，深度分析与复现</strong></h4><p>MEV 狙击、钓鱼攻击、重放攻击**… Web3 交易坑太多？ 本节课带你沉浸式复现攻击链路，吃透防御心法，掌握应对之策。</p><p><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdm3VL" alt="image.png" title="image.png" loading="lazy"/></p><h3><strong>立即报名</strong></h3><p>本系列课程已经上架到 OpenBuild 官网，登录报名后即可开始学习。包含 3 节精彩视频课程，并同步共享 84 页详细知识点 PPT。</p><p>报名链接：<a href="https://link.segmentfault.com/?enc=HP0ItpeD1C%2FVmzX6YQd7AQ%3D%3D.dnJSBDCWqW5EWI%2FGFIjk1vI0SCdbtkIAQGZYBj0UQ0J7l6BK74Bfv1p8rXHCjvQp" rel="nofollow" target="_blank">https://openbuild.xyz/learn/courses/1083007677</a></p><p>欢迎你加入课程学习群，获取课程 PPT，还有讲师为您答疑解惑。让我们一起学习，共同进步！或添加小助手微信 （ID:Carly860755 )，备注“安全”</p><h3><strong>学完本课程，你将收获满满</strong></h3><p>✅ 构建 6 大模块安全知识体系</p><p>✅ 深度剖析 20 + 真实被盗案例</p><p>✅ 熟练掌握 10 + 必备安全工具使用方法</p><p>✅ 拥有防骗防盗实操清单</p><p>✅ 摇身一变成为朋友圈的 Web3 安全顾问</p><p>在 Web3 的世界里，安全知识绝非可有可无，而是人人必修。衷心希望这门基础课程，能助力大家筑牢安全意识防线，避免不必要的资产损失。</p><p>延伸阅读 - <a href="https://link.segmentfault.com/?enc=WIR3bTBQNyobldacCUjC7A%3D%3D.%2BdVWHGy54JQiwEMU1IbVO%2FnRB8XrkewyHqaJdu7Ub7zM6%2B%2FliTxkmidak3f9Q1PRSXt7kzmoNdffeT0DX1C3cEHi8Y8RmrDr2DFUD2jtko0E85nND%2BGQ1cZgbnrfN%2FWR10Cfl2kTCXTDjo3AKssBLrhTg8MyzvyfXeXSIJ5cJhI%3D" rel="nofollow" target="_blank">智能合约漏洞解密</a></p><h3><strong>关于 Exvul</strong></h3><p>ExVul 是一家 Web3 安全公司，服务范围涵盖智能合约审计、区块链协议审计、钱包审计、Web3 渗透测试、安全咨询与规划。ExVul 致力于提升 Web3 生态整体安全性，始终站在 Web3 安全研究前沿领域。 </p><p>Website: <a href="https://link.segmentfault.com/?enc=yx2GDW9Z6ZqHo9POwfnvDw%3D%3D.cCQ9wK9ULpGjNHveXMMAsUJcUjrARS76N7YhOZIEjKY%3D" rel="nofollow" target="_blank">https://exvul.com/</a> </p><p>X: @exvulsec</p>]]></description></item><item>    <title><![CDATA[AI × Crypto 的布宜诺斯艾利斯]]></title>    <link>https://segmentfault.com/a/1190000047403321</link>    <guid>https://segmentfault.com/a/1190000047403321</guid>    <pubDate>2025-11-16 20:02:19</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img width="723" height="732" referrerpolicy="no-referrer" src="/img/bVdm3VP" alt="image.png" title="image.png"/></p><p>当探戈舞曲在布宜诺斯艾利斯的街头奏响，Devconnect 的热浪裹挟着代码与创想席卷全城。</p><p>11月20日，ChainOpera 携手 OpenBuild 打造的「AI Agent x Crypto Afternoon」即将登陆阿根廷，这将是一场围绕去中心化 AI 网络、AI Agent 开发及数字孪生应用的深度思维碰撞。</p><p>欢迎所有对 AI Agent × Crypto** 充满热情的朋友加入，共启这场跨界创新之旅！</p><h3><strong>活动亮点</strong></h3><p><strong>🔥 前沿趋势：</strong> 直击 ChainOpera 去中心化 AI 网络核心，探索 agents、模型、算力如何实现社区驱动的协同联动。</p><p><strong>🎯 实操干货：</strong> 聚焦 AI Agent、数字孪生在搜索、交易、内容创作、自动化场景的落地应用，获取可落地的开发思路。</p><p><strong>🥂 精准社交：</strong> 汇聚 Web3** 与 AI 领域的核心 builder，咖啡相伴，轻松拓展行业优质资源，找到志同道合的合作伙伴。</p><p><strong>🆙 沉浸体验：</strong>  keynote + 圆桌论坛 + 自由交流，拒绝单向输出，充分激发思想碰撞，解决实际开发 / 创业困惑。</p><p><strong>立即报名</strong></p><p>📅 活动时间：11月20日</p><p>📍 活动地点：Buenos Aires, Argentina</p><p>🎫 报名链接：<a href="https://link.segmentfault.com/?enc=UbJpxt4CwnxWytDS3pLGlg%3D%3D.SMYG8L6rU%2Bl13VNBXhkNipJBx2TVjkA4vReRIZTLAXA%3D" rel="nofollow" target="_blank">https://luma.com/iin2m6t6</a></p><h3><strong>活动议程</strong></h3><p>▷ 14:00-14:30  签到入场</p><p>▷ 14:30-14:40  开幕致辞</p><p>▷ 14:40-15:00  主题演讲</p><p>▷ 15:00-15:30  圆桌论坛</p><p>▷ 15:30-17:00  茶歇 &amp; 自由交流</p><h3><strong>适合人群</strong></h3><p>✅ Web3 开发者、AI 工程师、产品经理</p><p>✅ 关注 AI Agent、数字孪生技术的创业者</p><p>✅ 对去中心化 AI 网络感兴趣的投资者</p><p>✅ 想探索 Web3+AI 跨界应用的行业研究者</p><p>✅ 渴望拓展国际行业资源的 Builder</p><h3><strong>专属礼品</strong></h3><p>每位参与者均有机会获得 ChainOpera 和 OpenBuild 定制周边（T 恤、挂绳、棒球帽），还有超多周边好礼等你来拿！</p><p><img width="723" height="410" referrerpolicy="no-referrer" src="/img/bVdm3VQ" alt="image.png" title="image.png" loading="lazy"/></p><p>一场 AI 与 Crypto 的跨界盛宴，一次 Builder 们的灵感碰撞，11 月阿根廷，ChainOpera 与 OpenBuild 等你来共创未来！</p><p>欢迎加入，我们线下见！</p><h3><strong>关于主办方</strong></h3><p><strong>🔍 ChainOpera</strong></p><p>ChainOpera 专注构建「协同智能」去中心化 AI 网络，通过社区治理模式连接 agents、模型与算力。用户可轻松创建 AI Agent 或 “数字孪生”，应用于搜索、交易、内容创作等多元场景，所有交互全程上链，实现透明可验证，让 AI 成为每个人的虚拟伙伴与协作战友。</p><p>👉 Twitter：<a href="https://link.segmentfault.com/?enc=qATx4s4sYLwfKSezo3W1FQ%3D%3D.LngwjslamkmMjMg5NSRYE7TWYqGer1Vc0FRfRVmHOUY%3D" rel="nofollow" target="_blank">https://x.com/ChainOpera_AI</a></p><p><strong>🔍 OpenBuild</strong></p><p>OpenBuild 是一个面向 Web3 开发者的开源社区。</p><p>我们致力于为开发者提供高质量的系统性内容和活动，同时连接 Web2和 Web3，帮助开发者过渡到去中心化的网络，并通过提供必要的工具和资源，帮助开发者建立声誉体系，构建信任,创造商业机会。</p><p>👉 Twitter：<a href="https://link.segmentfault.com/?enc=xtSPlRPLcFwy4LLPsDp0sw%3D%3D.oWAO2WQHzkwu2jOgryqzVC5ywRCgvZkzfqZf2O3Xm0E%3D" rel="nofollow" target="_blank">https://x.com/OpenBuildxyz</a></p>]]></description></item>  </channel></rss>