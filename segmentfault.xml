<?xml version="1.0" encoding="UTF-8"?><rss version="2.0">  <channel>      <title>SegmentFault - 最近文章</title>      <link>https://segmentfault.com/blogs/newest</link>      <description>SegmentFault 思否</description>      <generator>python segmentfault.py @Pi20</generator>      <item>    <title><![CDATA[【节点】[CustomDiffuse节点]原理解析与实际应用 SmalBox ]]></title>    <link>https://segmentfault.com/a/1190000047610759</link>    <guid>https://segmentfault.com/a/1190000047610759</guid>    <pubDate>2026-02-14 10:03:38</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <blockquote><a href="https://link.segmentfault.com/?enc=WYzTD1UwAS4izdwOMWMx8Q%3D%3D.qaGZyuEai%2BisDtsu%2Fd%2FlYMbEhyje4JC9zXZ%2B%2BY5maXS2WA1XjjAhiHJIBv%2Ba20pimX%2BYtqz6pJwto2ao616p6Uo0gWSwlo5pqJ7PDQ0l9uX2KuDyVfWiglFND4%2BRV5l2aeJIYzLx3PsE5KmnjMd%2F1xF%2FW%2FxoCVlTrg7rYncWCqCYAbnZvAMfv3ae3ZGPsQGjlSOL2r9pGw6aWlhH661JuPY%2FUCTkkPFWAbaawNZz774%3D" rel="nofollow" target="_blank">【Unity Shader Graph 使用与特效实现】</a><strong>专栏-直达</strong></blockquote><h2><strong>描述</strong></h2><p>CustomDiffuse节点是Unity URP Shader Graph中一个功能强大的光照计算节点，专门用于实现用户自定义的固有色光照效果。该节点为着色器开发者提供了高度灵活的光照控制能力，允许用户基于物理的渲染原则或艺术化的视觉需求来定义材质的漫反射行为。在实时渲染管线中，漫反射光照是表面着色的基础组成部分，它决定了材质在直接光照下的基本外观特征。</p><p>CustomDiffuse节点的核心价值在于其可定制性。与标准的Lambert或Oren-Nayar漫反射模型不同，这个节点不强制使用特定的光照算法，而是将光照计算的各个要素作为输入端口开放给用户。这种设计理念使得开发者能够根据项目特定的视觉风格或性能要求，实现从简单的N·L点积计算到复杂的自定义BRDF模型。</p><p>在实际应用场景中，CustomDiffuse节点特别适合那些需要特殊材质表现的场合。比如在风格化渲染中，艺术家可能希望实现非真实感的漫反射过渡，或者在特定类型的表面（如丝绸、绒毛等）上实现物理准确的散射效果。通过组合不同的输入数据和自定义计算逻辑，开发者可以精确控制光线与材质表面的交互方式。</p><p>该节点的另一个重要特性是其与URP渲染管线的深度集成。它能够正确处理URP中的多光源设置、光照衰减和阴影信息，确保自定义的漫反射计算能够与引擎的其他渲染组件协同工作。这种集成保证了即使在复杂的场景光照条件下，自定义的漫反射效果也能保持视觉一致性和性能稳定性。</p><h2><strong>端口</strong></h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047610761" alt="" title=""/></p><h3>输入端口详解</h3><p>Diffuse输入端口接收Vector 3类型的数据，代表材质的基础固有色信息。这个端口通常连接到材质的Albedo纹理或基础颜色属性。在物理渲染上下文中，Diffuse输入应该表示材质表面对漫反射光的反射率系数，其数值范围通常在0到1之间。对于高质量的渲染结果，建议使用线性空间颜色值，并确保颜色值符合能量守恒原则。</p><p>Light Color输入端口提供灯光本身的颜色信息，这是实现准确色彩再现的关键要素。在URP中，不同类型的灯光（方向光、点光源、聚光灯）都会提供其颜色和强度信息。开发者可以利用这个端口实现各种创意效果，比如通过修改灯光颜色来模拟特殊的光照环境，或者根据表面特性对灯光颜色进行过滤处理。</p><p>Light Attenuation端口处理光照的衰减和阴影信息，这是实现真实光照效果的重要组成部分。该输入通常来自Shader Graph中的光照衰减节点，包含了距离衰减、角度衰减以及实时阴影数据。对于高级用法，开发者可以结合Shadowmask和光照探针数据来实现更复杂的光照交互效果。</p><p>Normal WS端口要求世界空间下的法线向量输入，这是计算光照方向性的基础。正确的法线数据对于任何基于物理的光照模型都至关重要。在实际使用中，法线信息可以来自顶点法线、法线贴图，或者是通过自定义计算生成的修改法线。确保法线向量为单位长度是获得准确光照结果的必要前提。</p><p>Light Direction WS端口提供从表面点到光源的方向向量，同样在世界空间下表示。这个向量通常通过标准化处理，并且指向光源的方向。在多点光源场景中，需要为每个光源分别计算其方向向量。对于方向光，这个方向是恒定的；而对于点光源和聚光灯，则需要基于片元位置实时计算。</p><h3>输出端口特性</h3><p>Out输出端口生成最终的自定义漫反射照明结果，以Vector 3形式表示RGB颜色值。这个输出可以直接用于后续的光照计算，或者与其他光照组件（如高光反射、环境光等）进行混合。输出的颜色值应该保持在合理的范围内，避免出现HDR效果，除非后续有适当的色调映射处理。</p><h3>端口交互与数据流</h3><p>理解这些端口之间的数据流关系对于有效使用CustomDiffuse节点至关重要。典型的数据处理流程开始于Diffuse和Light Color的乘法组合，这建立了基础的色彩响应。接着通过法线和光照方向的点积计算获得基础的漫反射强度，再结合光照衰减因子来模拟距离和阴影的影响。</p><p>在实际的着色器构建过程中，这些端口的连接顺序和数据处理方式可以根据需求灵活调整。例如，在某些卡通渲染风格中，可能会在计算N·L点积后添加一个步进函数来创建硬边缘的阴影过渡。而在追求物理准确性的场景中，则可能使用更复杂的函数来模拟表面粗糙度对漫反射的影响。</p><h2><strong>核心算法原理</strong></h2><h3>基础光照模型</h3><p>CustomDiffuse节点的默认行为基于经典的Lambertian漫反射模型，这是计算机图形学中最基础且广泛应用的光照模型之一。Lambert模型的核心理念是表面反射的光线强度与入射光线方向和表面法线夹角的余弦值成正比。数学表达式为：Diffuse = Albedo × LightColor × max(0, N·L)，其中N·L表示法向量与光照方向向量的点积。</p><p>这个简单的模型虽然物理上不够精确，但在实时渲染中因其计算效率和直观性而被广泛使用。它假设表面是理想的漫反射体，在各个观察方向上呈现相同的亮度。在实际实现中，max(0, N·L)操作确保了当光线从表面后方照射时不会产生负值光照，这是符合物理直觉的约束。</p><h3>高级漫反射模型</h3><p>对于需要更高质量渲染效果的项目，CustomDiffuse节点可以扩展实现更先进的漫反射模型。Oren-Nayar模型是一个著名的改进，它考虑了表面粗糙度对漫反射的影响。与Lambert模型不同，Oren-Nayar不假设表面是完美漫反射体，而是通过粗糙度参数模拟微表面细节对光线的散射效应。</p><p>另一个值得关注的模型是Disney principled BRDF中的漫反射组件，它结合了多种散射效应以提供更加物理准确的结果。这种模型通常包含次表面散射的近似模拟，能够更好地表现诸如布料、皮肤等特殊材质的视觉特性。</p><h3>能量守恒考虑</h3><p>在实现自定义漫反射模型时，能量守恒是一个重要的物理原则。它要求表面反射的光线总能量不能超过入射光线的能量。在着色器设计中，这意味着漫反射、镜面反射和其他光能传输组件的总和应当合理约束。通过CustomDiffuse节点，开发者可以精确控制漫反射组件的能量分配，确保渲染结果的物理合理性。</p><h2><strong>实际应用示例</strong></h2><h3>基础Lambert漫反射实现</h3><p>创建一个基础的Lambert漫反射效果是理解CustomDiffuse节点用法的理想起点。首先需要在Shader Graph中创建相应的节点网络：</p><ul><li>将Albedo纹理或颜色属性连接到Diffuse输入端口</li><li>使用URP中的Main Light节点获取主光源的颜色和方向信息</li><li>通过Transform节点将物体空间法线转换到世界空间</li><li>计算法线与光照方向的点积，并使用Saturate节点限制结果在0-1范围内</li><li>将点积结果与光源颜色和Albedo颜色相乘，得到基础的漫反射输出</li></ul><p>这种实现方式虽然简单，但已经能够为大多数实体材质提供可信的漫反射效果。它是许多游戏和交互应用中漫反射计算的基础。</p><h3>风格化卡通渲染</h3><p>在非真实感渲染中，CustomDiffuse节点可以创造出各种艺术化的光照效果。卡通渲染通常特征化地使用硬阴影边界和有限的颜色过渡。实现这种效果的关键在于对N·L点积结果进行离散化处理：</p><ul><li>使用Remap节点调整点积的范围和分布</li><li>通过Posterize节点或自定义的步进函数创建离散的光照级别</li><li>可以添加边缘光效果，通过在法线与视角方向接近垂直时添加额外的光照项</li><li>结合阴影色阶，使用多个CustomDiffuse节点分别处理不同光照区域的颜色</li></ul><p>这种技术广泛应用于动漫风格的游戏和媒体作品中，能够创造出鲜明、富有表现力的视觉风格。</p><h3>布料和毛发特殊材质</h3><p>某些材质类型需要特殊的漫反射处理来准确表现其视觉特性。布料材质通常表现出逆向的反射特性——当光照方向与观察方向相反时反而显得更亮。这种效果可以通过在CustomDiffuse节点中实现Wrap Lighting模型来实现：</p><ul><li>修改标准的N·L计算，添加一个偏移量：diffuse = saturate((N·L + w) / (1 + w))</li><li>其中w参数控制包裹效果的强度，典型值在0到1之间</li><li>对于绒毛材质，可以使用sheen项模拟边缘处的背光散射效果</li></ul><p>这些高级用法展示了CustomDiffuse节点在实现特定材质特性时的灵活性和强大功能。</p><h2><strong>性能优化建议</strong></h2><h3>计算复杂度管理</h3><p>在使用CustomDiffuse节点实现复杂光照模型时，需要注意计算性能的平衡。实时渲染对着色器的计算效率有严格要求，特别是在移动平台或VR应用中。以下是一些优化建议：</p><ul><li>尽可能使用最简单的光照模型满足视觉需求</li><li>避免在CustomDiffuse计算中使用复杂的数学函数如sin、pow等</li><li>考虑使用近似计算代替精确但昂贵的运算</li><li>对于静态物体，可以考虑将部分光照信息烘焙到光照贴图中</li></ul><h3>平台特定优化</h3><p>不同硬件平台对着色器计算的能力和限制各不相同。在针对多平台开发时，需要特别关注：</p><ul><li>移动平台通常对分支语句和复杂纹理查询更加敏感</li><li>在性能受限的情况下，可以考虑使用更低的计算精度（half代替float）</li><li>某些平台可能对特定类型的数学运算有硬件加速，可以优先使用这些运算</li></ul><h3>光照模型简化策略</h3><p>当项目面临性能压力时，可以考虑以下简化策略：</p><ul><li>使用预计算的查找纹理（LUT）替代实时复杂计算</li><li>将部分每像素计算转移到每顶点计算</li><li>在远距离或小尺寸物体上使用简化的光照模型</li><li>利用URP的着色器变体功能，为不同质量设置提供不同复杂度的实现</li></ul><h2><strong>常见问题与解决方案</strong></h2><h3>光照不一致问题</h3><p>在使用CustomDiffuse节点时，可能会遇到不同光源条件下光照效果不一致的问题。这通常是由于没有正确处理多光源环境或光照空间转换错误导致的：</p><ul><li>确保所有向量计算在相同的坐标空间中进行（通常推荐世界空间）</li><li>检查法线向量的长度是否为单位长度，非单位法线会导致错误的光照计算</li><li>验证光照方向向量是否正确指向光源，对于点光源需要基于片元位置计算方向</li></ul><h3>阴影衔接问题</h3><p>自定义漫反射模型与URP阴影系统的集成可能会产生视觉瑕疵，特别是在阴影边界处：</p><ul><li>确保Light Attenuation输入正确包含了阴影信息</li><li>在自定义模型中考虑阴影柔和度与漫反射过渡的协调性</li><li>可以使用阴影颜色调制来改善阴影区域的艺术表现</li></ul><h3>HDR和颜色管理</h3><p>在高动态范围渲染中，CustomDiffuse节点的输出可能需要特殊处理：</p><ul><li>注意颜色值范围，避免在未经色调映射的情况下输出HDR值</li><li>在线性颜色空间下进行所有光照计算，确保物理准确性</li><li>对于特别明亮的光源，可能需要单独处理以避免颜色过饱和</li></ul><h2><strong>高级技巧与创意应用</strong></h2><h3>动态材质效果</h3><p>CustomDiffuse节点不仅可以处理静态光照计算，还可以实现各种动态效果：</p><ul><li>基于时间或顶点位置调制漫反射颜色，创建动态变化的表面外观</li><li>结合噪声纹理模拟表面污染、磨损等随时间变化的效果</li><li>使用世界空间坐标实现与场景位置相关的材质变化</li></ul><h3>非真实感渲染技术</h3><p>除了传统的真实感渲染，CustomDiffuse节点在NPR领域也有广泛应用：</p><ul><li>实现水墨画风格的渐变控制，通过自定义的过渡函数</li><li>创建素描效果，使用hatching纹理基于光照强度进行混合</li><li>模拟油画笔触，结合噪声和方向性光照响应</li></ul><h3>特殊场景应用</h3><p>在某些特定类型的场景中，CustomDiffuse节点可以提供针对性的解决方案：</p><ul><li>在水下环境中模拟光线的吸收和散射效应</li><li>在雾霭场景中实现距离相关的颜色衰减</li><li>为雪地或沙漠等高反射环境创建特殊的光照响应</li></ul><hr/><blockquote><a href="https://link.segmentfault.com/?enc=nWdVBVK1QoXujEjtq%2FQSzA%3D%3D.3%2BjyIXcslFZzbCUPnkMCeBYQcQs0zHCawK8TMKR6fU1M%2F4s5qITLoCZkdPPg%2FpOs3t8BfdOoMiziBe6Wstk1fEw3iClq6zxqE9%2BtlI6BPDdNpjlLoAfnPr4BCbtkoMiJLNMHJDCwLdldSbVbRRqdeBfPqvlgog6FnQ7l4CPRDdeKG%2F5Qw5WVlyOAkx47aQgkSm8%2B9viH4op0TIdsoQymncePQcattipa7cOfevEPYdc%3D" rel="nofollow" target="_blank">【Unity Shader Graph 使用与特效实现】</a><strong>专栏-直达</strong><br/>（欢迎<em>点赞留言</em>探讨，更多人加入进来能更加完善这个探索的过程，🙏）</blockquote>]]></description></item><item>    <title><![CDATA[如何在 Linux 中将文件复制到多个目录 ？ 本文系转载，阅读原文
https://www.koo]]></title>    <link>https://segmentfault.com/a/1190000047610765</link>    <guid>https://segmentfault.com/a/1190000047610765</guid>    <pubDate>2026-02-14 10:02:50</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047610767" alt=" Copy a File to Multiple Directories in Linux" title=" Copy a File to Multiple Directories in Linux"/></p><p>要将文件复制到 Linux 中的多个目录，可以使用 <code>cp</code> 和 <code>xargs</code> 命令。所有目标目录都将作为标准输入管道连接到 <code>xargs</code> 命令，示例如下：</p><pre><code>echo dir1 dir2 dir3 | xargs -n 1 cp -v file.txt</code></pre><p>这将复制文件 file.txt 到 dir1，dir2 和 dir3 目录。</p><p>或者，使用 for 循环将文件复制到多个目录，示例如下：</p><pre><code>for dir in dir1 dir2 dir3; do
    cp file.txt $dir
done</code></pre><p>也可以使用 find 命令将文件复制到多个目录，示例如下：</p><pre><code>find dir1 dir2 dir3 -type d -exec cp file.txt {} \;</code></pre><p><strong>注意：</strong> 确保您具有将文件复制到目标目录的必要权限。</p><h3>我的开源项目</h3><p><a href="https://link.segmentfault.com/?enc=OSsAEFjZNqe5KCnSueujUg%3D%3D.v%2BhCrrGGYXv55jEBpiZ0XTg4W7JjL9l%2BumQ0snDUMN4%3D" rel="nofollow" target="_blank"><img referrerpolicy="no-referrer" src="/img/remote/1460000043426502" alt="酷瓜云课堂-开源知识付费解决方案" title="酷瓜云课堂-开源知识付费解决方案" loading="lazy"/></a></p><ul><li><a href="https://link.segmentfault.com/?enc=u9nY0e6kVQEelyqJKotjuw%3D%3D.we6e40RZK17VXAsek3DMVlO1oFl55lEOTROJ8cew%2FCo223c9ZIuYO7JBjGsQkueL" rel="nofollow" target="_blank">course-tencent-cloud（酷瓜云课堂 - gitee仓库）</a></li><li><a href="https://link.segmentfault.com/?enc=nYL%2Fo%2FXJmrSko2D%2FrGoV1Q%3D%3D.xSAY9zB3Diaa0tflEF2qWuFK%2Bf2OJd3MsQ3ybsT%2FbT5f%2FIiNlecnn2X2LfQ7LqGmpcudpsWazqiBpCPkba2E6g%3D%3D" rel="nofollow" target="_blank">course-tencent-cloud（酷瓜云课堂 - github仓库）</a></li></ul>]]></description></item><item>    <title><![CDATA[Fatal error: require(): Failed opening required 以及]]></title>    <link>https://segmentfault.com/a/1190000047610770</link>    <guid>https://segmentfault.com/a/1190000047610770</guid>    <pubDate>2026-02-14 10:02:13</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>“Fatal error: require(): Failed opening required...” 以及如何彻底避免它再次出现</h2><p>凌晨两点，值班告警响了。生产环境 API 开始报 500，而且只出现在新扩容的节点上。你打开日志，熟悉又刺眼的报错跳了出来：</p><p>本地一切正常，测试环境也没问题。但在云原生部署这种“环境随时变化”的现实里，一个看起来不起眼的路径差异，就足以把服务直接打趴。</p><p>这并不是什么“新手失误”，而是很多人对 PHP 最基础能力——文件加载机制——理解不够深入导致的系统性问题。</p><p>早期 PHP 时代，我们把 <code>include</code> 和 <code>require</code> 当积木用来拼页面。到了 PHP 8.2+、Composer、容器化微服务的今天，这组函数仍然在引擎核心位置。但现实中，很多开发者依旧把它们当成“设完就不用管”的工具。</p><p>如果你想从“写脚本”走向“做稳定系统”，就必须搞清楚：当一个文件被加载进另一个文件时，底层到底发生了什么。</p><p>这篇文章会从运行机制、线上常见坑和工程实践三层，讲清楚怎样把 PHP 文件加载写到足够稳。</p><h3>底层到底在发生什么？</h3><p>当你执行 <code>include 'file.php'</code>，并不是“复制粘贴代码”这么简单。PHP 实际上会让当前执行流程暂停，切换到目标文件，把它编译为操作码，再在当前作用域里执行。</p><h4>文件加载的四种形式</h4><p>PHP 有四种主加载方式，它们不是语法糖，而是行为差异：</p><ul><li><code>include</code>：温和模式。文件不存在时抛 <code>Warning</code>，脚本继续执行。</li><li><code>require</code>：强制模式。文件不存在时直接致命错误并中断执行。</li><li><code>include_once</code> / <code>require_once</code>：在前两者基础上增加“是否已加载”检查，避免重复声明。</li></ul><p>理解这个差异非常关键：在现代业务系统里，很多核心依赖一旦缺失，不应该“带伤继续跑”。</p><h4>一个更实用的心智模型：作用域注入器</h4><p>可以把文件加载理解成“作用域注入器”：</p><ul><li>在函数内部 <code>include</code>，被加载文件里定义的变量只在该函数作用域可见。</li><li>在脚本顶层 <code>include</code>，变量会进入全局作用域。</li></ul><p>另外，很多人误判性能瓶颈。真正重的通常不是代码执行本身，而是文件状态检查（stat 调用）：</p><p>每次 <code>include</code>，PHP 都要向操作系统确认：文件是否存在、权限是否可读、最后修改时间等。在高并发 API 中，这个动作每秒成千上万次时，开销会非常明显。</p><h3>PHP 是如何解析路径的</h3><p>当你写 <code>include 'utils.php';</code> 这种相对路径时，PHP 会依次尝试：</p><ul><li>当前脚本目录</li><li><code>php.ini</code> 中 <code>include_path</code> 指定的目录</li><li>当前工作目录（cwd）</li></ul><p>问题就出在这里：它有环境依赖。</p><p>比如你的命令行任务进程工作目录是 <code>/var/www/</code>，而 Web 进程工作目录是 <code>/var/www/public/</code>，同一行相对路径代码可能一个能跑、一个直接崩。</p><h3>最容易把线上搞崩的 5 类错误</h3><p>这些是我在遗留项目重构里反复见到的高频问题。</p><h4>相对路径陷阱</h4><p><strong>错误写法</strong>：<code>include 'includes/header.php';</code></p><p><strong>为什么会发生</strong>：本地启动目录刚好是项目根目录，所以一直“看起来正常”。</p><p><strong>线上后果</strong>：一旦被子目录调用、被定时任务调用，或者入口目录变了，路径上下文就变了。这是“我本地没问题”类事故的头号来源。</p><h4><code>_once</code> 的性能税</h4><p><strong>错误写法</strong>：在高频循环里大量使用 <code>require_once</code>。</p><p><strong>为什么会发生</strong>：担心 <code>Cannot redeclare class</code> 之类的重复声明。</p><p><strong>线上后果</strong>：每次 <code>_once</code> 都会触发已加载表检查。PHP 8 虽然优化了很多，但它依然比直 <code>require</code> 慢。依赖关系清晰的模块化系统，不该长期依赖引擎“二次确认”。</p><h4>用 <code>@</code> 把报错静音</h4><p><strong>错误写法</strong>：<code>@include 'optional_config.php';</code></p><p><strong>为什么会发生</strong>：想省掉 <code>if (file_exists(...))</code> 的显式判断。</p><p><strong>线上后果</strong>：你把真正问题藏起来了。文件读取失败可能不是“文件不存在”，而是权限不对（如 <code>chmod</code>）。报错被吃掉后，排障时间会从 5 分钟拉到几小时。</p><h4>动态 include 引发路径穿越</h4><p><strong>错误写法</strong>：<code>include $_GET['page'] . '.php';</code></p><p><strong>为什么会发生</strong>：图省事做“动态路由”。</p><p><strong>线上后果</strong>：严重安全风险。攻击者可构造 <code>../../../../etc/passwd</code>，或利用 <code>php://filter/...</code> 读取敏感配置。即使关闭远程 URL 加载，本地文件同样会被攻击。</p><h4>加载带副作用的文件</h4><p><strong>错误写法</strong>：一个文件既定义类，又直接执行逻辑（输出 HTML、连数据库等）。</p><p><strong>为什么会发生</strong>：历史代码里职责边界没分清。</p><p><strong>线上后果</strong>：测试几乎没法写。你只是想测试类定义，却被迫触发数据库连接和页面输出。</p><h3>正确做法（PHP 8+）</h3><p>在现代项目里，类加载通常由 Composer + PSR-4 自动加载处理，<code>include</code>/<code>require</code> 更多用于配置、模板和少量模块逻辑。</p><p>但即便如此，也建议守住下面三条。</p><h4>始终使用绝对锚点路径</h4><p>把路径固定在已知根上。<code>__DIR__</code> 永远指向“当前文件所在目录”，不会随工作目录变化。</p><p><strong>错误示例（脆弱）</strong></p><pre><code class="php">&lt;?php
// 如果从 public/ 目录启动，这里可能失败
require 'config/settings.php';</code></pre><p><strong>正确示例（稳定）</strong></p><pre><code class="php">&lt;?php
// 无论从哪里调用，都能稳定解析
require __DIR__ . '/config/settings.php';</code></pre><h4>善用加载返回值</h4><p>这是 PHP 里经常被忽略但非常实用的能力：被加载文件可以 <code>return</code> 值。</p><p><code>config.php</code></p><pre><code class="php">&lt;?php
return [
    'db' =&gt; [
        'host' =&gt; '127.0.0.1',
        'pass' =&gt; $_ENV['DB_PASS'] ?? 'root',
    ],
    'debug' =&gt; false,
];</code></pre><p><code>app.php</code></p><pre><code class="php">&lt;?php
$config = require __DIR__ . '/config.php';
// $config 是局部变量，不污染全局</code></pre><h4>关键组件要做防御式加载</h4><p>对于必须存在的文件，不要依赖默认报错，自己把预期写清楚。</p><pre><code class="php">&lt;?php
$templatePath = __DIR__ . '/views/header.php';
if (!file_exists($templatePath)) {
    throw new \RuntimeException("关键视图组件缺失: {$templatePath}");
}
require $templatePath;</code></pre><h3>生产环境注意点：扩缩容与安全</h3><p>当系统从单机走到容器集群或函数计算，文件加载不再只是代码细节，而是基础设施问题。</p><h4>安全：路径穿越防护</h4><p>很多“PHP 不安全”的印象，本质是加载策略不安全。</p><ul><li><strong>白名单（Allow-list）</strong>：绝不直接信任用户输入拼路径。</li><li><strong><code>basename()</code></strong>：确实需要用输入值时，先做路径片段清洗，拦截 <code>../</code> 穿越。</li><li><strong><code>open_basedir</code></strong>：在 <code>php.ini</code> 限制 PHP 可访问路径范围，防止越界读取。</li></ul><h4>性能：OPcache 是基础设施而不是可选项</h4><p>生产环境应开启 OPcache。它会把预编译后的字节码放内存，避免每次请求重复解析文件。</p><p><strong>部署提示</strong>：在高并发集群中可以考虑 <code>opcache.validate_timestamps=0</code>，换取更快加载速度；但这意味着每次发布都必须做平滑重载，否则代码更新不会生效。</p><h4>可观测性：失败必须可追踪</h4><p>文件加载失败不应只留下一个“白屏”或 500。</p><ul><li><strong>可追踪信息</strong>：日志至少要包含 <code>include_path</code> 与 <code>cwd</code>。</li><li><strong>监控策略</strong>：对 <code>E_COMPILE_ERROR</code> 做专门告警，这类问题通常与发布或环境差异有关，需优先回滚。</li></ul><h4>部署形态差异（容器 vs 函数计算）</h4><p>容器镜像里文件路径通常固定可预测；函数计算环境常见只读文件系统、目录映射变化。统一使用 <code>__DIR__</code> 能显著降低环境差异带来的路径问题。</p><h3>真实事故："空配置"幽灵</h3><p>我曾参与排查过一个支付业务事故：后台任务随机失败。问题根因是他们用 <code>include</code> 加载环境配置。</p><p>某次发布脚本漏拷了生产配置文件。因为是 <code>include</code>，进程没有崩，业务继续跑，只是拿到一个空的 <code>$config</code>。</p><p>结果是任务带着空 API 密钥连续运行了 6 小时，造成大量交易失败。</p><p>如果当时使用的是 <code>require</code>，任务会第一时间中断并触发告警，损失会小得多。</p><p>一句话：<strong>没有它系统就不能活，那就必须 <code>require</code>。</strong></p><h3>排障清单（看到 Failed opening required 时直接照做）</h3><ol><li><strong>打印绝对路径</strong>：<br/><code>var_dump(realpath(__DIR__ . '/your-file.php'));</code><br/>若返回 <code>false</code>，说明文件根本不在你以为的位置。</li><li><strong>确认运行身份</strong>：<br/><code>echo exec('whoami');</code><br/>看当前系统用户是否有读权限。</li><li><strong>排查隐藏语法错误</strong>：<br/>某些文件不是“不存在”，而是语法错误导致加载失败。<br/>用命令行执行：<code>php -l filename.php</code>。</li><li><strong>检查 PHP 开始标签</strong>：<br/>文件应以 <code>&lt;?php</code> 开头。若短标签关闭而你写了 <code>&lt;?</code>，后续可能出现各种诡异问题（如 header 已发送）。</li></ol><h3>更专业的加载封装示例</h3><p>不要长期依赖裸 <code>var_dump</code>。建议用结构化日志和统一包装。</p><pre><code class="php">&lt;?php
/**
 * 带可观测性的文件加载器
 * 开发环境要“响亮失败”，生产环境可控降级。
 */
function load_component(string $filePath, array $context = []): mixed
{
    $absolutePath = realpath($filePath);
    if (!$absolutePath || !file_exists($absolutePath)) {
        error_log(sprintf(
            "[FileLoader] Failure: %s | CWD: %s | User: %s",
            $filePath,
            getcwd(),
            get_current_user()
        ));

        if (getenv('APP_DEBUG') === 'true') {
            throw new \Exception("组件不存在: {$filePath}");
        }

        return null; // 生产环境按约定降级
    }

    extract($context);
    return require $absolutePath;
}</code></pre><h3>常见问题</h3><h4>Q：<code>require_once</code> 一定比 <code>require</code> 更好吗？</h4><p>不一定。<code>require_once</code> 更像是组织不清晰时的安全网。依赖关系明确、自动加载健全时，<code>require</code> 更直接、性能更好。</p><h4>Q：可以根据数据库值动态 include 文件吗？</h4><p>可以，但必须非常谨慎。推荐白名单映射：数据库只存 ID，代码里把 ID 映射到固定路径，不要把路径原文存进数据库后直接加载。</p><h4>Q：加载大文件会拖慢应用吗？</h4><p>开启 OPcache 后，首次之后基本没有“解析”成本；但文件中的业务逻辑仍要执行，依旧消耗 CPU 和内存。文件内容要聚焦，避免把大量无关逻辑塞在一起。</p><h4>Q：模板文件适合用 <code>include</code> 吗？</h4><p>小项目可以。中大型系统建议使用成熟模板方案，能在安全性和复用性上更稳。</p><h3>结语</h3><p>把 <code>include</code> 和 <code>require</code> 用好，不只是语法问题，而是工程能力问题。</p><p>你的代码运行在操作系统、权限模型、缓存机制和部署流水线共同构成的环境里。只理解“本地能跑”，远远不够。</p><h4>最佳实践小结</h4><ul><li><strong>快速失败</strong>：关键依赖统一使用 <code>require</code>。</li><li><strong>路径绝对化</strong>：避免相对路径，优先 <code>__DIR__</code>。</li><li><strong>作用域收敛</strong>：用 <code>return</code> 返回配置，避免全局变量污染。</li><li><strong>失败可观测</strong>：把加载失败当成一类关键系统事件处理。</li></ul><h4>你的下一步</h4><p>现在就打开项目，全局搜索 <code>include</code> / <code>require</code>：</p><p>凡是不以 <code>__DIR__</code> 或统一根路径常量开头的，今天就改。</p><p>这一步做完，你的生产环境就会少一类高概率事故。<br/><a href="https://link.segmentfault.com/?enc=ItiJi0IgQLYkcm47Dmoqaw%3D%3D.fhYrveGclDFxVEs9FKhCDhxRkQq%2F6b0fin51kGvdxwpwYG1XBBatp7BH7%2BSzZGZhsruxBPlzx07tadbc1fqNSPRfEhFTcIx%2BL63xA%2B35enc%3D" rel="nofollow" target="_blank">Fatal error: require(): Failed opening required...”—以及如何彻底避免它再次出现</a></p>]]></description></item><item>    <title><![CDATA[融资 1 亿美元李飞飞参投，斯坦福小镇论文作者创立数字孪生公司 Simile 丨日报 RTE开发者社]]></title>    <link>https://segmentfault.com/a/1190000047610797</link>    <guid>https://segmentfault.com/a/1190000047610797</guid>    <pubDate>2026-02-14 10:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047610799" alt="" title=""/></p><p>开发者朋友们大家好：</p><p>这里是 <strong>「RTE 开发者日报」</strong>，每天和大家一起看新闻、聊八卦。我们的社区编辑团队会整理分享 RTE（Real-Time Engagement） 领域内「有话题的<strong>技术</strong>」、「有亮点的<strong>产品</strong>」、「有思考的<strong>文章</strong>」、「有态度的<strong>观点</strong>」、「有看点的<strong>活动</strong>」，但内容仅代表编辑的个人观点，欢迎大家留言、跟帖、讨论。</p><p><em>本期编辑：@瓒an、@鲍勃</em></p><h2>01 有话题的技术</h2><p><strong>1、谷歌发布 Gemini 3 Deep Think，编程水平排名世界第八</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047610800" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047610801" alt="" title="" loading="lazy"/></p><p>今天凌晨，谷歌发布了 Gemini 3 Deep Think 的重大升级。作为<strong>专用于复杂任务的推理模式</strong>，该版本试图解决科学与工程领域的诸多挑战。据悉，去年 9 月加入 Google DeepMind 的清华物理系校友姚顺宇也参与了此次研发。</p><p><strong>在编程领域</strong>，Gemini 3 Deep Think 在 Codeforces 平台上取得了 3455 的 Elo 分数，<strong>位列世界第八</strong>。这意味着全球仅有 7 名人类选手能在此类比赛中击败它，而此前最佳模型 OpenAI o3（约一年前数据）的排名仅为第 175 位。</p><p>该模型在多项学术基准测试中刷新了纪录：</p><ul><li><strong>通用与抽象推理</strong>：在「人类的最后考试」基准测试中，不使用工具取得了 48.4% 的 SOTA 成绩；在 ARC-AGI-2 中达到 84.6%。值得注意的是，其在 ARC-AGI-1 上的每任务成本仅为 7.17 美元，相比 OpenAI o3-preview 「高计算」版本降低了数百倍。</li><li><strong>科学竞赛</strong>：在 2025 年国际数学、物理和化学奥林匹克竞赛笔试中均获金牌水平，并在高等理论物理 CMT-Benchmark 测试中得分 50.5%。</li></ul><p>谷歌同时展示了 Deep Think 在科研中的实际应用。罗格斯大学数学家 Lisa Carbone 利用其识别出一篇专业论文中人工评审未发现的逻辑缺陷；杜克大学 Haozhe Wang 的实验室则利用其优化半导体工艺，实现了厚度大于 100 微米薄膜的精确生长目标。<strong>此外，该模型还能将草图转化为可 3D 打印的实体模型。</strong></p><p>目前，全新 Deep Think 已面向 Google AI Ultra 订阅用户及部分 API 合作伙伴开放。</p><p>（@机器之心）</p><p><strong>2、小红书开源工业级语音系统 FireRedASR2S：集成四大核心组件</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047610802" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047610803" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047610804" alt="" title="" loading="lazy"/></p><p>2026 年 2 月 12 日，<strong>小红书正式发布并开源了工业级一体化语音识别系统 FireRedASR2S</strong>。该项目基于 Apache-2.0 许可协议，相关的模型权重与推理代码目前已在 Hugging Face 和 ModelScope 等平台开放下载。</p><p>FireRedASR2S 将单点语音能力扩展为了完整的处理生态，系统内部集成了<strong> ASR（自动语音识别）、VAD（语音活动检测）、LID（语种识别）和 Punc（标点预测）四个核心组件</strong>。这些模块在架构设计上保持自包含与独立性，开发者既可以将其整合为端到端的工作流，也能脱离主系统单独调用任意单个模块。</p><p>根据官方公布的基准测试数据，各核心组件的具体能力表现如下：</p><ul><li><strong>FireRedASR2</strong>：支持普通话、20 多种方言与口音、中英文语码转换以及歌词识别。该模块提供 LLM（结合大语言模型以优化无缝交互）与 AED（平衡性能与效率，支持词级时间戳）两个版本。评测显示，其普通话平均字符错误率（CER）低至 2.89%，方言平均 CER 为 11.55%，整体表现优于 Doubao-ASR、Qwen3-ASR-1.7B 与 Fun-ASR 等竞品。</li><li><strong>FireRedVAD</strong>：支持超百种语言的非流式与流式语音活动检测，涵盖语音、歌声及音乐，并具备音频事件检测能力。其 F1 分数高达 97.57%，领先其他开源基准。</li><li><strong>FireRedLID</strong>：覆盖 100 多种语言及 20 多种中文方言，语种检测准确率达到 97.18%，客观数据超越了 Whisper 与 SpeechBrain-LID。</li><li><strong>FireRedPunc</strong>：提供多领域的中英文标点预测服务，平均 F1 分数达到 78.90%，显著优于 FunASR-Punc。</li></ul><p>在实际应用与部署环节，系统要求输入 16kHz 16 位单声道 PCM 格式音频。对于输入长度，AED 版本最高支持 60 秒的音频，而 LLM 版本目前支持最长 30 秒的输入。后续，开发团队还将陆续公开技术报告与微调代码。</p><p>GitHub: <br/><a href="https://link.segmentfault.com/?enc=4lOB3eFt2xLRi0di3L8VwQ%3D%3D.%2BuNd8SaW%2B0LwEwP0JzYwxHcO9UTOajh5lsDP3Fw8oRZX%2F3wkg8aZ9wfZN10RlUFM" rel="nofollow" target="_blank">https://github.com/FireRedTeam/FireRedASR2S</a></p><p>HuggingFace: <br/><a href="https://link.segmentfault.com/?enc=gucYuAIvD1E9xzdZMf51lw%3D%3D.2runaO%2FrBkw9cdIJ24Rb2NrB0w%2BAtMfs%2B0ScZdgF23%2FbZySoootziVf4GQECHtj66zL6%2BCz800J5B8FiEiZ7eA%3D%3D" rel="nofollow" target="_blank">https://huggingface.co/FireRedTeam/FireRedASR2-AED</a></p><p>( @GitHub)</p><p><strong>3、涉嫌侵犯开源项目 FFmpeg 的版权，瑞芯微被 GitHub 冻结代码库</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047610805" alt="" title="" loading="lazy"/></p><p>2026 年 2 月，国内芯片设计企业瑞芯微（Rockchip）<strong>因涉嫌侵犯开源项目 FFmpeg 的版权</strong>，其相关代码库被 GitHub 平台冻结。这一事件再次引发行业对开源软件合规使用的关注。</p><p>经查，瑞芯微在产品开发过程中使用了 FFmpeg 的核心组件 libavcodec 代码，但在使用过程中存在多项违规操作：</p><ul><li><strong>删除版权信息</strong>：删除了代码原作者信息及版权声明；</li><li><strong>篡改许可证</strong>：擅自将原代码的 LGPL 许可证更改为 Apache 协议。</li></ul><p><strong>尽管 LGPL 协议允许商业场景使用，但明确要求使用者必须保留原始版权声明、按需提供源代码，并保持许可证的一致性。</strong>瑞芯微的操作直接违反了这些条款。事实上，该违规行为早在 2024 年初就已被发现。当时，瑞芯微工程师 HermanChen 曾公开道歉，称对许可证冲突缺乏了解，并承诺整改。然而，在随后的近两年时间里，<strong>瑞芯微并未采取实质性整改措施</strong>。最终，FFmpeg 项目方依据《数字千年版权法案》（DMCA）向 GitHub 发起正式投诉，导致瑞芯微相关项目库被冻结。</p><p>数据显示，目前 97% 的代码库包含开源组件，其中 63% 存在许可证冲突。业内专家指出，许多企业开发者对 GPL、MIT、Apache、LGPL 等主流许可证的区别认知不足，错误地认为开源代码可随意修改分发，从而埋下法律风险。</p><p>不同许可证规则差异显著。<strong>以此次涉事的 LGPL 为例，它允许闭源软件动态链接使用，仅要求修改库本身代码时开源修改部分；而 Apache 协议虽支持商业闭源，但更侧重专利保护，且与 GPL 系列协议存在兼容性冲突，二者不可随意替换。</strong>此次事件表明，开源合规管理已成为企业发展的必修课，企业需建立完善的审查机制，明确协议边界，规避版权风险。</p><p>（@人人极客社区）</p><p><strong>4、蚂蚁百灵开源发布万亿参数思考模型 Ring-2.5-1T ，主打深度思考与长程智能体执行</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047610806" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047610807" alt="" title="" loading="lazy"/></p><p>今天中午，蚂蚁百灵正式发布并开源了<strong>首个混合线性架构的万亿参数思考模型 Ring-2.5-1T</strong>。作为迈向通用智能体时代的关键一步，该模型在<strong>预训练</strong>和<strong>强化学习</strong>层面均进行了大规模扩展。</p><p>相比前代产品 Ring-1T，Ring-2.5-1T 在三个核心维度实现了大幅提升：</p><ul><li><strong>高效生成</strong>：基于高效的 1:7 MLA + Lightning Linear Attention 架构，在超过 32K 的生成长度下，访存规模降低 10 倍以上，生成吞吐提升 3 倍以上。</li><li><strong>深度思考</strong>：在 RLVR 基础上引入 dense reward 反馈机制。自测结果显示，其在 IMO 2025（获 35 分）和 CMO 2025（获 105 分）中均达到金牌水平。</li><li><strong>长程执行</strong>：通过大规模全异步智能体强化学习（fully-async agentic RL）训练，显著增强了复杂任务的长程自主执行能力，可适配 Claude Code 及 OpenClaw 等框架。</li></ul><p>在架构层面，Ling 2.5 采用增量训练方式，将 Ling 2.0 的 GQA 升级为混合线性注意力结构。改造后，尽管激活参数量从 51B 增至 63B，但推理效率仍大幅提升。测试显示，无论在单机 8 卡 H20-3e 还是 H200 环境下，其长程推理的吞吐优势均十分显著。</p><p>为验证其长程执行能力，开发团队将 Ring-2.5-1T 接入 Claude Code，仅用两小时便自动完成了一个微型版操作系统（TinyOS）的开发，并能进一步实现 bash 功能。此外，该模型在数学、代码、逻辑等<strong>高难推理任务</strong>以及智能体搜索（如 GAIA2-search）等<strong>长程任务执行上，均达到了开源领域的领先水平</strong>。</p><p>目前，Ring-2.5-1T 仍存在 token efficiency 和指令遵循方面的局限性。其模型权重已在 Hugging Face 和 ModelScope 开源，相关体验页及 API 服务也将在 Ling Studio 与 ZenMux 陆续上线。</p><p>HuggingFace: </p><p><a href="https://link.segmentfault.com/?enc=RKWeJSGchTC7XxhjxvlfUA%3D%3D.4hckt6JGvtFPIJMvLZZdKIVWqoteVRCLmYuuy3oN03YvGvWt1BKVhvONZPHNtNYf" rel="nofollow" target="_blank">https://huggingface.co/inclusionAI/Ring-2.5-1T</a></p><p>（@百灵大模型）</p><h2>02 有亮点的产品</h2><p><strong>1、自然语言几分钟构建 AI 智能体：VM0 正式开启公开测试</strong></p><p>2026 年 2 月 6 日，VM0 宣布正式开启<strong>公开测试</strong>。在经历了约两个月的内部构建与私密测试后，该平台现已向更多开发者开放。</p><p><strong>VM0 是一款基于自然语言构建 AI 智能体的工具，并配备了支持智能体全天候（24/7）运行的沙盒环境。</strong> 用户只需用自然语言描述具体需求，VM0 便会自动处理运行时、执行操作及环境配置。即使用户关闭了电脑，其部署的智能体应用也会保持持续运行状态。</p><p>在构建体验上，该平台试图同时满足不同类型用户的需求：</p><ul><li><strong>面向 Vibe Coder 和快速实验</strong>：对于刚接触 AI 智能体或希望快速测试想法的用户，平台提供了几分钟即可上手的体验。无需繁重的环境设置或提前阅读长篇文档，仅需执行一条简单的初始命令（<code>npm install -g @vm0/cli &amp;&amp; vm0 onboard</code>），即可运行首个智能体。</li><li><strong>面向专业开发者</strong>：如果需要获取更多控制权，VM0 提供了一套完整的开发工具包。开发者可以将 VM0 接入现有的基础设施中，并在实际需要时进行规模化扩展。</li></ul><p>由于目前产品仍处于测试阶段，官方正积极向早期用户征集错误报告、细节打磨建议以及功能反馈，这些反馈将直接塑造产品的下一步走向。此外，VM0 正在建设一个由社区驱动的 Cookbook，鼓励开发者分享其实际构建的案例，例如客户支持智能体、数据分析工作流或内部工具等。</p><p>根据公布的路线图，VM0 下一步的发展计划包括：<strong>推出自托管运行程序、简化的智能体分享功能、支持更多模型提供商、VM0 平台智能体构建器、VM0 Slack 集成以及 VM0 连接器</strong>。</p><p>相关链接：<br/><a href="https://link.segmentfault.com/?enc=BEccPUu27Dpvaja4R3k57w%3D%3D.KxK%2FlYwKNa7KmoM%2FHghpmKRexemDGK46kaQD201Aws8%3D" rel="nofollow" target="_blank">https://docs.vm0.ai/docs</a></p><p>( @VM0 Blog)</p><p><strong>2、AI 数字孪生初创公司 Simile 获 1 亿美元融资，用 AI 模拟真实用户反馈</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047610808" alt="" title="" loading="lazy"/></p><p>AI 数字孪生初创公司 Simile 宣布完成 1 亿美元融资。本轮融资由 Index Ventures 领投，Bain Capital Ventures 等机构投资者跟投，AI 先驱李飞飞与 OpenAI 联合创始人 Andrej Karpathy 也参与了投资。</p><p>企业在推出新产品前，通常需要收集潜在客户的反馈，但这类调研往往耗时费力，且难以触及特定目标受众（如世界 500 强高管）。为此，Simile 构建了一个 AI 模型，<strong>利用个人数据来模拟人们对新产品、功能变更等商业动态的反应</strong>。目前，其首批客户包括 CVS Health Corp。 和澳大利亚最大的移动互联网提供商 Telstra Group。</p><p>该 AI 模型主要帮助企业简化以下测试流程：</p><ul><li><strong>用户界面更新评估</strong>：开发者可在向真实客户全面推出更新前，观察模拟用户对界面变更的反应。</li><li><strong>财报电话会议准备</strong>：据首席执行官 Joon Sung Park 透露，在一次模拟电话会议中，该模型准确预测了分析师 10 个问题中的 8 个，能够帮助上市公司高管提前做好准备。</li></ul><p>Simile 由 Joon Sung Park、Michael Bernstein 和 Percy Liang 共同创立。这三位计算机科学家此前曾开发过模拟环境 Smallville，证明了 AI 智能体不仅能模拟个体行为，还能模拟群体行为。据报道，Simile 耗时七个月开发该模型，其训练数据来源于对数百人的采访记录、交易日志以及科学期刊文本。</p><p>Index Ventures 合伙人 Shardul Shah 表示，Simile <strong>建立了高保真模型来解答真实人类会做什么以及为什么这样做，这在各类组织中有着广泛的应用需求</strong>。除了模拟买家行为，AI 生成模拟正被广泛应用于更多领域，例如 Simile 的投资人李飞飞曾于 2024 年创办 World Labs，用于生成三维虚拟环境以训练工业机器人。</p><p>( @SiliconAngle)</p><h2>03 有态度的观点</h2><p><strong>1、DeepMind CEO：AI 在未来十五年会解决人类棘手难题</strong></p><p>近日，Google DeepMind CEO 德米斯 · 哈萨比斯接受《财富》杂志的采访时，其提到：人类正站在「科学发现新黄金时代」的边缘，尽管未来 10 到 15 年将经历剧烈的行业洗牌与阵痛，但最终将迎来一场足以媲美「文艺复兴」的技术变革。</p><p>哈萨比斯在访谈中提出了「激进富足」的概念。他预言 AI 将通过对科学方法的深度内化，解决人类最棘手的难题：</p><ul><li>医疗革命： 未来 15 年内，AI 将使个性化医疗成为常态，攻克重大疾病。</li><li>能源突破： AI 将加速核聚变与太阳能新材料的研发，彻底解决能源危机。</li><li>宇宙探索： 算力的突破将最终支持人类「在星际间穿梭，探索银河系」。</li></ul><p>采访中，哈萨比斯也提到了 Google 在当今 AI 圈的一些风险以及挑战。</p><p>面对 OpenAI 等竞争对手的崛起，哈萨比斯坦言谷歌必须面临「创新者困境」。他强调：「<strong>如果我们不进行自我颠覆，别人就会动手。你最好按自己的节奏来。</strong>」</p><p>据悉，随着 Gemini 系列模型及 Nano Banana 图像生成模型的发布，Alphabet（Google 母公司）股价在去年飙升约 65%，哈萨比斯认为公司已跨越了 AI 助手辅助高阶研究的「分水岭」。</p><p>( @APPSO)</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047610809" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047610810" alt="" title="" loading="lazy"/></p><p><a href="https://link.segmentfault.com/?enc=jzJBZxvBvq541vmOJ13qjw%3D%3D.zKmm5jelow1a4Gjx%2FpQfdPDPjPNf2TxSd8Ihz4O28YE%3D" rel="nofollow" target="_blank">阅读更多 Voice Agent 学习笔记：了解最懂 AI 语音的头脑都在思考什么</a></p><p><strong>写在最后：</strong></p><p>我们欢迎更多的小伙伴参与 <strong>「RTE 开发者日报」</strong> 内容的共创，感兴趣的朋友请通过开发者社区或公众号留言联系，记得报暗号「共创」。</p><p>对于任何反馈（包括但不限于内容上、形式上）我们不胜感激、并有小惊喜回馈，例如你希望从日报中看到哪些内容；自己推荐的信源、项目、话题、活动等；或者列举几个你喜欢看、平时常看的内容渠道；内容排版或呈现形式上有哪些可以改进的地方等。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047610811" alt="" title="" loading="lazy"/></p><p>作者提示: 个人观点，仅供参考</p>]]></description></item><item>    <title><![CDATA[RAG 文本分块：七种主流策略的原理与适用场景 本文系转载，阅读原文
https://avoid.o]]></title>    <link>https://segmentfault.com/a/1190000047610619</link>    <guid>https://segmentfault.com/a/1190000047610619</guid>    <pubDate>2026-02-13 22:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>检索是 RAG 系统的搜索引擎，分块则是这个搜索引擎的基础。分块太长、太短、有噪声、切错了位置——随便犯哪个错LLM 都会有问题。行业里有句话流传很广："分块决定了 RAG 质量的 70%。"</p><p>这个说法不夸张：好的分块让检索器拿到完整、有上下文、真正相关的信息；差的分块把文档打成碎片，上下文断裂，LLM 只能靠"编"来填补空白。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047610621" alt="" title=""/></p><h2>什么是分块？</h2><p>RAG 的起点是文档收集与摄取：把所有原始材料（文档、文章、知识库条目）汇聚到一起。在进入检索环节之前，这些文档要经过文本分块处理也就是切分成更小的、有意义的片段。</p><p>每个分块应当是连贯且自包含的，这样检索器才能在面对查询时快速定位、排序，并返回最相关的信息。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047610622" alt="" title="" loading="lazy"/></p><p>分块就是在生成 Embedding 之前，把大段文本拆成更小语义单元的过程。检索器真正搜索的对象而不是整篇文档就是这些分块。</p><p>分块做得好，文档中的内容就能被干净地捕获，上下文得以保留LLM 能做出有意义的推理。分块做得差，语义被割裂检索充满噪声。向量存储、Embedding 模型、Reranker——这些统统排在分块之后，分块才是真正的起点。</p><h2>固定大小分块</h2><p>这是最简单的方式。按预设的字符数或 Token 数直接切分，比如每 500 个 Token 一块完全不管句子和段落的边界在哪。</p><p>速度快，行为可预测，处理大规模、结构混乱的数据集时很实用。但缺点也很明显——语义经常被拦腰切断。一个句子在这个分块里开了头，到下一个分块才结束，Embedding 的语义表达力就会打折扣。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047610623" alt="" title="" loading="lazy"/></p><p>实践中一般会在相邻分块之间设置一定的重叠来缓解这个问题：</p><pre><code> from langchain.text_splitter import RecursiveCharacterTextSplitter  

splitter = RecursiveCharacterTextSplitter(  
    chunk_size=500,  
    chunk_overlap=50  
)  

 chunks = splitter.split_text(long_text)</code></pre><p>切分文本时，连续的分块之间通常会加入一小段重叠区域来维持上下文的连贯。所谓重叠，就是前一个分块的尾部几句话，在下一个分块的开头再出现一次。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047610624" alt="" title="" loading="lazy"/></p><p>这么做是为了防止跨越分块边界的关键信息丢失。没有重叠的话，检索器可能只拿到部分内容LLM 因此漏掉了关键上下文，给出残缺甚至误导性的回答。重叠量一般控制在分块长度的 10% 到 20%，在冗余和效率之间找一个平衡点。</p><p>固定大小分块适合的场景包括日志文件、邮件、代码仓库，以及结构参差不齐的大型语料库。</p><h2>基于句子的分块</h2><p>这种方式按完整句子来划分文本，而不是按任意长度一刀切。每个分块至少包含一个或多个完整的句子，语法完整，语义连贯。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047610625" alt="" title="" loading="lazy"/></p><p>好处是每个分块都是一个有意义的思想单元。检索器向 LLM 返回的信息更精确、更易理解，碎片化回答的风险降低不少。实际使用中通常也会搭配小幅重叠，进一步保证分块之间的衔接。</p><h2>基于段落的分块</h2><p>以完整段落为单位切分，不再拘泥于单个句子或固定 Token 数。这种方式天然保留了文档的结构和行文节奏，检索器更容易抓到完整的想法。</p><p>每个分块往往对应一个独立的主题或子主题，LLM 处理起来更从容，也更容易给出准确的回答。对长篇文档、研究论文、综述类文章来说，段落级分块效果不错。和句子级分块一样，也可以加重叠来保持连贯。</p><h2>语义分块</h2><p>语义分块的切入点不是长度，而是语义本身。它利用 Embedding 或相似度分数来识别文本中天然的断裂点——主题切换、上下文转折、章节边界。</p><p>产出的分块语义清晰度更高，边界和语义对齐，检索质量有明显提升，尤其在知识库、技术文档、结构化文章这类内容上效果突出。代价是计算开销更大而且分块长度不一致，后续处理需要额外考虑。</p><pre><code> from langchain_experimental.text_splitter import SemanticChunker  
 from sentence_transformers import SentenceTransformer  
   
 model = SentenceTransformer("all-MiniLM-L6-v2")  
 chunker = SemanticChunker(model, breakpoint_threshold=0.4)  
   
 chunks = chunker.split_text(long_text)</code></pre><p>如果文档质量高、主题流转有明确脉络，语义分块往往是精度最高的选择。</p><h2>递归分割</h2><p>递归分割是固定大小和语义分块之间的一个折中方案。核心思路是优先尊重文档结构，只有在必要时才进一步拆分。</p><p>具体做法是先尝试按标题切分。如果某个章节还是太长，就按段落切。段落还不够就按句子。句子仍然超限，最后才按字符兜底。这样得到的分块既保有语义完整性，尺寸也在可控范围内。</p><pre><code> recursive_splitter = RecursiveCharacterTextSplitter(  
     separators=["\n## ", "\n### ", "\n", ". ", ""],  
     chunk_size=600,  
     chunk_overlap=80  
 )  
   
 chunks = recursive_splitter.split_text(long_doc)</code></pre><p>开发者文档、技术手册、学术论文、研究报告——凡是层级结构明确的内容，递归分割都很适合。</p><h2>滑动窗口分块</h2><p>有些文本的语义天然是跨句分布的。法律合同、科学论文、长段论证，一个完整的意思可能横跨好几个句子。滑动窗口就是为这种场景设计的。</p><p>它不生成彼此独立的分块，而是创建相互重叠的窗口。比如窗口大小 400 Token，每次滑动 200 Token，这样相邻的分块之间有一半的内容是共享的，语义在边界处不会断裂。</p><p>上下文保持得很好，但分块数量会膨胀，存储和检索的成本都会上升。</p><p>法律 RAG、金融分析、医学文献检索、合规审查——这些领域用滑动窗口的比较多。</p><h2>层次化分块</h2><p>层次化分块是一个多层级的架构：小分块负责细粒度精确检索，中等分块支撑平衡的推理，大分块维持全局上下文。</p><p>检索时，系统先用小分块锁定精确位置，再把关联的大分块拉进来补充完整上下文。这种组合能有效压制幻觉，提升推理的深度。</p><p>企业级 RAG 系统和 LlamaIndex 这类多粒度检索框架，背后都有层次化分块的影子。</p><h2>实践中常见的分块失误</h2><p>多数 RAG 项目翻车根源都是分块层面的问题。分块过大模型被不相关的细节淹没。分块过小语义丧失殆尽。句子被拦腰切断、不相关的段落被混到一个分块里，Embedding 质量直接垮掉。没有重叠，上下文断裂。没有元数据，检索器找不到方向。还有一个常见错误——所有类型的文档套用同一种分块策略。</p><p>分块没有万能方案。政策文件和教科书不一样，通话记录和研究论文不一样。策略必须跟着文档类型和检索任务走。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047610626" alt="" title="" loading="lazy"/></p><h2>总结</h2><p>分块不是一个可有可无的预处理环节，它是 RAG 管道的脊梁。好的分块是一个有意义的、自包含的知识单元；差的分块是一个孤零零的碎片，把 LLM 带向歧途。</p><p>检索是引擎分块是燃料。燃料的质量决定了整个系统是输出干净、可靠的结果，还是不断产出噪声和幻觉。LLM 本身再好，也救不了烂分块。</p><p><a href="https://link.segmentfault.com/?enc=mLbki017nch6q2DBNVwvaQ%3D%3D.VbbcuN20Y6RMy8smm0MawC8TU7F1GrUd8NAe6jQi3VYw1g111et4Zka65HzXH1frho6JxsAEP6iUODtLempF8A%3D%3D" rel="nofollow" target="_blank">https://avoid.overfit.cn/post/e6520bd283254415ae61cfa28fb2ef32</a></p><p>作者：Abinaya Subramaniam</p>]]></description></item><item>    <title><![CDATA[OpenClaw + 智能家居 + 家庭服务器 = 自由的家庭 AI Agent MarkZhu ]]></title>    <link>https://segmentfault.com/a/1190000047610542</link>    <guid>https://segmentfault.com/a/1190000047610542</guid>    <pubDate>2026-02-13 21:01:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000044262194" alt="logo" title="logo"/></p><p>本文展示了如何通过自托管的 OpenClaw Skills，对 Home Lab（家庭服务器群）与智能家居进行真 AI 智能化控制。而不受限于小米米家等平台的各种智能限制。通过将家庭服务器群环境、监控系统以及几种 API 封装为结构化的 Skills，AI Agent 可以完成服务器故障排查、以有趣的智能家居灯光方式可视化运维操作，并通过智能音箱汇总报播网站实时新闻。</p><hr/><h2>背景</h2><p>这些年，我一直在运行和维护自己的 Home Lab（家庭服务器群） 和一套小型智能家居系统。随着设备和服务越来越多，维护和管理也变得越来越复杂。</p><p>同时，我也逐渐意识到，传统的“智能家居”其实并不真正智能。运营方出于各种原因，没有把最近的 AI 科技更新到智能家居平台上。很多问题的存在，往往只是因为我懒得去做自动化。如今，现代 AI 技术或许可以帮助解决这些问题。</p><p>我的 Home Lab 已经运行了 5 年多，承载着多个 Linux 主机上的各种服务。同时，我还运行了一套 Home Assistant 实例，用来管理家中的 IoT 智能家居设备。</p><p>在可观测性方面，我部署了 Prometheus 和 Grafana，并为硬件和软件异常配置了告警机制。</p><p>但问题是：当手机收到告警后，我仍然需要手动调查和排查问题。如果我不在家，用手机远程排障就会变得低效又麻烦。</p><p>这正是 OpenClaw 发挥作用的地方。理想情况下，我只需要给它一些目标，它就应该能替我完成后续操作。</p><p>作为 Home Lab 和智能家居的管理员，OpenClaw 需要具备以下三类“技能 (Skills) ”：</p><ul><li><strong>Home Lab 环境知识</strong> —— 包括机器清单、服务部署情况、监控架构等。</li><li><a href="https://link.segmentfault.com/?enc=d%2BenAKopKP3YHaI6WcsyxQ%3D%3D.YzueESxnGdsg8gTyGH6GPwImsbBc00UF%2BCdHxC1tuF1rnT0B3gq8tV9TUy9wC9Qt" rel="nofollow" target="_blank">Home Assistant</a></li><li><a href="https://link.segmentfault.com/?enc=zeiDSR9iq4P5qcjLGlGCTA%3D%3D.wNUzYwnEzbiZgyYmyqzWANjO0ZSMWNSxDol8hUGpVb9PVgkngWk2lhnujuWVdA2IXELlATKk8uFI43Nmmin2gABiYft%2F9xRbEskU%2BwsDYAorAh3EOzzeyF5ozWoqOajD" rel="nofollow" target="_blank">Prometheus API</a></li></ul><hr/><h2>使用场景</h2><h3>1. Home Lab 故障排查与根因分析</h3><p>查找某台服务器上 CPU 占用最高的服务，并通过智能音箱播报结果。</p><p>当收到“CPU 使用率过高”或“温度过高”告警时，这种方式尤其方便。</p><p><img width="723" height="748" referrerpolicy="no-referrer" src="/img/bVdnVP5" alt="image.png" title="image.png" loading="lazy"/><br/><em>（配图：root cause 分析示意图)</em></p><hr/><h3>2. Home Lab “氛围灯光秀大师”</h3><p>重启某一台服务器。重启开始时，立刻调暗书房灯光；当机器启动完成、所有服务初始化完毕后，再把灯光恢复。</p><p>这样一来，当我人在书房时，就可以通过灯光变化 “可视化” 服务器的启动进度。</p><p><img width="433" height="940" referrerpolicy="no-referrer" src="/img/bVdnVP6" alt="image.png" title="image.png" loading="lazy"/><br/><em>（配图：重启灯光联动示意图)</em></p><hr/><h3>3. AI 驱动的智能家居控制</h3><p>将 Hacker News (<a href="https://link.segmentfault.com/?enc=jhcNu%2B17BL9c%2BlFHZHwtxQ%3D%3D.8B%2Fu9c78zHilzU%2FooBvtTsV8IOnZZl2ZmtIp100KyDw%3D" rel="nofollow" target="_blank">https://news.ycombinator.com/</a>) 的内容摘要和翻译为中文，并通过智能音箱朗读出来。</p><p>当我在晨起或做家务时，也可以通过智能音箱播报了解最新任意网站的动态摘要。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047610544" alt="use-case-speak-news.png" title="use-case-speak-news.png" loading="lazy"/><br/>（配图：语音播报示意图）</p><hr/><h2>Skills 设计</h2><p>为了实现这些功能，我首先需要向 OpenClaw 介绍我的 Home Lab 环境，包括：</p><ul><li>所有 Linux 主机列表</li><li>每台机器上运行的服务</li><li>监控系统细节</li><li>Agent 必须遵守的运维规则</li></ul><p>我不希望把这些信息直接塞进普通的 LLM 上下文里——那样会迅速消耗上下文窗口，并浪费大量 token。</p><p>Anthropic 的 Skills 规范提供了一个清晰的解决方案：我可以将 Home Lab 环境封装成一个 Skill，让 OpenClaw 在需要时按需加载。</p><blockquote>注意：以下 Skill 代码片段为了便于阅读，做了简化处理。</blockquote><hr/><h3>Home Lab 环境 Skill</h3><p>核心思想：</p><ul><li>通过 Bash 和 SSH 控制 Home Lab 机器</li><li>所有 Linux 主机使用同一个用户名</li><li>SSH 无需密码登录</li><li>Prometheus 运行在 192.168.1.74:9090</li><li>优先从 Prometheus 查询指标，而非 SSH 到机器</li><li>仅在无法获取数据时才通过 SSH 获取实时信息</li><li>某些关键机器（如网关）默认只读访问</li><li>执行任何会修改系统状态的命令前必须请求确认</li></ul><p>特别强调了两条运维规范：</p><ol><li>执行前必须先解释行动计划</li><li>所有可能改变系统状态的操作必须征求用户确认</li></ol><p>这相当于为 AI Agent 定义了运维行为准则（Operational Guardrails）。</p><p>路径：</p><pre><code>~/openclaw/workspace/skills/home-lab/SKILL.md</code></pre><p>Skill 片段：</p><pre><code class="markdown">---
name: home-lab
description: Control the home lab where you(personal assistant running inside OpenClaw) are running on
---

# Home Lab

Control home lab Linux machines via bash and SSH commands.

## Conduct of Code

Always provide a clear, high-level explanation of your action plan before executing the first step. Let the user understand and confirm the plan before proceeding.

Always request confirmation before executing any command that may change system state, such as rebooting the OS, modifying configuration files, or restarting services. Clearly explain what the command does and why it is necessary before asking for confirmation.

## Home Lab Environment

All Linux machines use the same username: `mark`. SSH login does not require a password.

### Linux Machines

- 192.168.1.58 : Raspberry Pi, always on
- 192.168.1.68 : Raspberry Pi, always on
- 192.168.1.108 : Raspberry Pi, always on
- 192.168.1.14 : X86_64 server

### Observability and Monitoring

A Prometheus instance runs on 192.168.1.74:9090. Metrics are collected by Node Exporter on each machine.

When users request metrics (temperature, CPU usage, memory usage, disk usage), first query Prometheus. Only execute remote SSH commands if the required metrics cannot be found in Prometheus.

If you are unfamiliar with the Prometheus API, load the `prometheus-api` Skill.

Note that Prometheus metrics may not always be real-time. If real-time data is required, execute a remote SSH command.

### Services running on the machines

#### 192.168.1.68
This machine acts as the main Internet gateway of the home lab. 

Access this machine in read-only mode. Do not change anything without explicit confirmation. 

##### Home Assistant
The home automation system. Access by http://192.168.1.68:8123

##### OpenClaw
An OpenClaw instance runs at http://127.0.0.1:18789. It may be you or may be another AI assistant.

#### 192.168.1.74

##### Prometheus

Base URL: `http://192.168.1.74:9090`  

All machines are monitored via Node exporter, with metrics collected by this Prometheus server. 

## Remote wake up

Wake up 192.168.1.14 using:
```bash
ssh mark@192.168.1.108 o
```</code></pre><hr/><h3>Home Assistant Skill</h3><p>基于 Home Assistant API 文档，我创建了一个 webhook，用于向小米智能音箱发送通知。</p><p>然后在 Skill 文档中告诉 Agent 如何调用该 API，例如：</p><pre><code class="bash">curl -s -X POST $HA_URL/api/webhook/ai-speak \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $HA_TOKEN" \
  -d '{"msg": "需要播报的内容"}'</code></pre><p>此外，还封装了：</p><ul><li>列出智能设备</li><li>控制开关</li><li>控制灯光亮度</li></ul><p>这些都通过标准的 Home Assistant REST API 实现。</p><pre><code class="markdown">---
name: homeassistant
description: Control Home Assistant - smart plugs, lights, scenes, automations.
homepage: https://www.home-assistant.io/
metadata: {"clawdis":{"emoji":"🏠","requires":{"bins":["curl"],"env":["HA_TOKEN"]},"primaryEnv":"HA_TOKEN"}}
---

# Home Assistant

Control smart home devices via Home Assistant API.

## Setup

Set environment variables:
- `HA_URL`: Your Home Assistant URL (e.g., `http://192.168.1.100:8123`)
- `HA_TOKEN`: Long-lived access token (create in HA → Profile → Long-Lived Access Tokens)

## Quick Commands

### Smart Speaker Integration 🔊 
There is a smart speaker you can control. You can control it to speech any text to the user. You can use it to send notification to user at home.

```bash
curl -s -X POST $HA_URL/api/webhook/ai-speak -H "Content-Type: application/json" -H "Authorization: Bearer $HA_TOKEN" -d '{"msg": "The message you want to speech to user"}'
```

### List entities by domain
```bash
curl -s "$HA_URL/api/states" -H "Authorization: Bearer $HA_TOKEN" | \
  jq -r '.[] | select(.entity_id | startswith("switch.")) | .entity_id'
```

### Turn on/off
```bash
# Turn on
curl -s -X POST "$HA_URL/api/services/switch/turn_on" \
  -H "Authorization: Bearer $HA_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{"entity_id": "switch.office_lamp"}'
```

### Control lights
```bash
# Turn on with brightness
curl -s -X POST "$HA_URL/api/services/light/turn_on" \
  -H "Authorization: Bearer $HA_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{"entity_id": "light.living_room", "brightness_pct": 80}'
```</code></pre><hr/><h3>Prometheus API Skill</h3><p>基于 Prometheus API 文档封装。</p><p>这样 Agent 可以：</p><ul><li>查询 CPU 使用率</li><li>查询设备温度</li><li>查询内存、磁盘使用情况</li><li>结合 Alertmanager 做进一步自动化处理</li></ul><hr/><h2>未来使用场景</h2><h3>主动型 Agent</h3><p>下一步，我希望 Agent 不只是“被动响应”，而是主动监控并处理 Home Lab 和智能家居状态。</p><p>用户只需要用自然语言描述期望行为，Agent 可以自动转换为：</p><ul><li>监控规则</li><li>告警规则</li><li>自动化规则</li></ul><p>例如：</p><p>通过集成 OpenClaw Webhook 到 Prometheus Alertmanager，实现：</p><ul><li>自动触发故障排查</li><li>自动调查分析</li><li>自动进行根因定位</li></ul><p>也就是说，当告警触发时，Agent 不只是发通知，而是直接开始分析问题。</p><h3>管理我的家居物品</h3><p>用自然语言管理我的 <a href="https://link.segmentfault.com/?enc=9Tzi0FnA8LJSs%2B8DnN%2FaXw%3D%3D.MBs8WKzWGNs5uOPLRtzgbpE2GmEKEnaMLPaDa8RdhDYBQacCPLXTD88JPYvLZTbF" rel="nofollow" target="_blank">Homebox</a>，这是一个自托管的家庭物品管理系统。例如，当我购买新设备时，我可以告诉 Agent: “我买了一部新的 iPhone 15 Pro Max，请将其添加到我的家庭物品清单中”。</p><hr/><h2>总结</h2><p>通过将 Home Lab 环境知识、Prometheus 监控系统和 Home Assistant API 封装为结构化 Skills，OpenClaw 可以将传统“手动运维 + 被动智能家居”升级为“AI 编排驱动”的自动化系统。</p><p>它不仅可以：</p><ul><li>分析服务器故障</li><li>有趣化运维过程</li><li>语音播报任意网站信息</li></ul><p>更重要的是，它为“主动式 AI 运维与智能家居控制”提供了一个可扩展的架构基础。</p><h2>安全风险警告</h2><p>赋予人工智能 Agent 在您的 Home Lab 中执行命令并控制智能家居设备的权限会带来重大的安全风险。攻击者可能利用该 Agent 获取未经授权的访问权限、造成损害或窃取敏感信息。请仅从可信来源下载和安装任何 Skill 。安装任何 Skill 之前，务必先查看其代码。考虑在权限受限的沙箱环境中运行 Agent，以降低潜在风险。</p><p>本文发布于我的博客：<a href="本文发布于我的博客：https://blog.mygraphql.com/zh/posts/ai/ai-personal-assistant/openclaw-as-home-lab-admin/" target="_blank">https://blog.mygraphql.com/zh/posts/ai/ai-personal-assistant/openclaw-as-home-lab-admin/</a></p>]]></description></item><item>    <title><![CDATA[find-skills技能全解析：一键解决AI Agent技能搜索、安装与管理痛点 鸿枫 ]]></title>    <link>https://segmentfault.com/a/1190000047610458</link>    <guid>https://segmentfault.com/a/1190000047610458</guid>    <pubDate>2026-02-13 20:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>find-skills技能全解析：一键解决AI Agent技能搜索、安装与管理痛点<br/>在AI Agent使用过程中，“找技能、装技能、管技能”是多数用户面临的核心难题——要么四处搜罗技能资源，要么切换平台搜索打断工作流，要么安装后难以统一管理更新。此前在Skills蓝皮书分享过的Skills.sh资源库中，一款名为find-skills的技能异军突起，不仅登顶24h安装榜榜首，长期稳居总榜第二且持续上升，日均安装量突破10k+，与第二名拉开显著差距。</p><p>这款由Vercel官方发布的技能，之所以能快速走红，核心在于它完美解决了技能获取与管理的全流程痛点，无需切换平台、无需复杂操作，仅需在单个Agent中运行，就能完成技能搜索、安装、检查、更新的闭环。本文将从核心优势、详细操作步骤、注意事项三个维度，全方位解析find-skills的使用方法，帮助用户高效利用AI Agent技能，提升工作效率。</p><p>一、find-skills核心优势：为什么它能成为“技能神器”？</p><p>在find-skills出现之前，用户获取技能的方式普遍存在诸多弊端，而它的出现的实现了技能管理的“一站式闭环”，具体优势对比及核心亮点如下：</p><p>1.1 解决传统技能获取的核心痛点</p><p>传统技能获取主要有两种方式，均存在明显局限：</p><ul><li>人工分享/仓库搜索：依赖他人分享，效率低下，且难以精准匹配自身需求，容易找到过时或不适配的技能。</li><li>技能搜索平台（如skillsmp.com）：搜索体验不佳，中文搜索命中率低，即便使用AI搜索也无法达到理想效果；且需要跳出当前工作任务，打开单独平台搜索，严重打断工作流，影响专注度。</li></ul><p>1.2 find-skills的核心亮点</p><p>相较于传统方式，find-skills实现了全流程优化，核心亮点集中在3点：</p><ul><li>全闭环操作：无需切换平台，在单个Agent中即可完成“搜索→安装→检查→更新”全流程，不打断工作流，提升使用效率。</li><li>适配性强：由Vercel官方发布，与Vercel生态完美兼容，支持多种Agent安装，后续管理和更新更便捷。</li><li>操作灵活：支持指令搜索和自然语言搜索两种方式，中文提问可同时检索中英文关键词，搜索精度更高，小白也能快速上手。</li></ul><p>二、find-skills详细操作教程（以Claude Code为例）</p><p>本教程将以Claude Code为操作场景，拆解find-skills从安装、搜索到管理更新的完整步骤，所有操作均无需复杂代码基础，复制指令即可完成，全程适配小白用户。</p><p>步骤一：安装find-skills技能（推荐官方最优方式）</p><p>find-skills支持多种安装方式，但最推荐使用Vercel官方发布的add-skill指令安装——作为官方同源工具，后续技能的管理、更新更稳定，避免出现适配问题。</p><ol><li>获取项目地址（备用）：find-skills的官方项目地址为：<a href="https://link.segmentfault.com/?enc=Ii2xgXDeVqw2aDISEec9xA%3D%3D.BwLDiL3kuTzuI2KUpwjlI2WTEUytyWc1PHkCR%2B8KoljaPJ29pyoKzi2z%2BEfAclpWrSriBFNYt%2BIwcDQu%2FKbb3PGwntvY5YbSjWXKOnO2kQc%3D" rel="nofollow" target="_blank">https://github.com/vercel-labs/skills/tree/main/skills/find-skills</a>，无需下载，仅作为备用参考。</li><li><p>执行安装指令：打开Claude Code，输入以下指令并运行，即可启动安装流程：</p><pre><code> npx skills add https://github.com/vercel-labs/skills --skill find-skills
</code></pre></li><li><p>选择安装配置（3个选项依次选择）：</p></li></ol><ul><li>安装Agent选择：选择将技能安装到哪个Agent中，可选择“一键安装到全部Agents”（适合多Agent用户），也可选择具体某个Agent，根据个人使用习惯选择即可。</li><li>安装范围选择：分为“全局范围”和“项目范围”——全局范围可在所有项目中使用，项目范围仅在当前项目中生效，推荐新手选择“项目范围”，避免影响其他项目。</li><li>安装方式选择：提供两种方式，按需选择：</li></ul><pre><code>- SymLink（推荐）：通过创建符号链接实现集中管理，所有Agent共享一个技能源文件，后续更新时可统一同步，无需逐个Agent更新。

- Copy to all agents：将技能文件直接复制到每个Agent节点，每个节点独立存储，更新时需逐个操作，适合需要个性化修改技能文件的用户。
</code></pre><ol start="4"><li>确认安装成功：安装完成后，当前项目中会出现适配对应Agent的技能路径，说明安装成功，可进入下一步操作。</li></ol><p>补充建议：新手推荐配置为“所有Agent + 项目范围 + SymLink”，兼顾便捷性和后续管理效率。</p><p>步骤二：使用find-skills搜索并安装目标技能</p><p>安装完成后，即可通过两种方式搜索技能，操作简单，精准匹配需求，具体步骤如下：</p><ol><li><p>选择搜索方式（两种均可，按需选择）：</p></li></ol><ul><li><p>指令搜索（精准高效）：输入以下指令，将“skills关键词”替换为具体需求，即可搜索相关技能：</p><pre><code>    npx skills find "skills关键词"示例：搜索SEO标签优化相关技能，指令为：npx skills find "SEO标签优化"；搜索YouTube视频下载相关技能，指令为：npx skills find "YouTube视频下载"。
</code></pre></li><li>自然语言搜索（小白友好）：无需输入指令，直接用中文或英文提问即可，例如：“帮我找下SEO meta标签优化的skills”“有没有小红书封面设计相关的Skills”。</li></ul><ol start="2"><li><p>精准搜索技巧（重点）：</p></li></ol><ul><li>关键词尽量细化：避免使用宽泛关键词（如“SEO”“小红书”），优先使用具体关键词（如“SEO meta标签”“小红书封面设计”），减少无关搜索结果，提升搜索精度。</li><li>语言适配：英文提问仅搜索英文关键词，中文提问会同时搜索中文及相关英文关键词，推荐中文用户使用中文提问，扩大搜索范围。</li></ul><ol start="3"><li>安装目标技能：搜索完成后，find-skills会列出所有相关技能，只需告知其需要安装的技能名称，即可自动完成安装，无需额外操作。</li></ol><p>小建议：若搜索结果中能显示技能安装量，可优先选择安装量较高的技能，安全性和适配性更有保障（后续版本可能优化该功能）。</p><p>步骤三：技能管理与更新（易忽略但关键步骤）</p><p>find-skills不仅能搜索安装技能，还提供了3个实用的管理指令，解决技能过多难以管理、版本过时等问题，具体使用方法如下（重点注意局限性）：</p><ol><li><p>查看已安装技能：当安装的技能过多时，可通过以下指令快速查看所有已安装技能，清晰掌握自身技能储备：</p><pre><code> npx skills list⚠️ 注意（重点）：该指令仅能识别通过“npx skills add”指令安装的技能，若通过其他方式（如手动下载、第三方工具）安装的技能，无法被识别。
</code></pre></li><li><p>检查可更新技能：定期检查技能版本，避免使用过时技能，指令如下：</p><pre><code> npx skills check运行后，会列出所有可更新的技能及当前版本、最新版本，方便用户判断是否需要更新。
</code></pre></li><li><p>更新所有已安装技能：若确认需要更新，可通过以下指令一键更新所有可更新技能：</p><pre><code> npx skills update⚠️ 注意（慎用）：更新前需确认所有技能均为可信任来源，避免更新后出现技能适配异常、功能失效等问题；建议更新前备份相关项目文件，降低风险。
</code></pre></li></ol><p>三、find-skills使用注意事项（避坑必看）</p><p>虽然find-skills操作简单、实用性强，但在使用过程中仍有4点注意事项，避免出现操作失误、功能异常等问题，新手必看：</p><ul><li>安装方式优先选官方同源：尽量使用“npx skills add”指令安装，避免使用其他第三方安装方式，否则可能出现后续管理、更新失败，或与Agent适配异常的问题。</li><li>搜索关键词决定搜索精度：宽泛关键词会导致搜索结果杂乱、无关信息过多，务必细化关键词，可观察搜索输出过程，了解关键词拓展逻辑，优化搜索词。</li><li>技能管理指令的局限性：牢记“npx skills list”仅识别官方指令安装的技能，手动安装的技能需单独记录管理，避免遗漏。</li><li>更新技能需谨慎：“npx skills update”会一键更新所有可更新技能，若部分技能与当前项目适配度较低，更新后可能出现功能异常，建议按需更新，而非盲目一键更新。</li></ul><p>四、补充说明与实用建议</p><p>4.1 find-skills的局限性</p><p>find-skills并非万能，需理性看待其功能边界：</p><ul><li>仅能搜索开源技能：无法搜索未开源的私有技能，若需使用特定私有技能，仍需通过手动安装方式添加。</li><li>搜索结果不一定完全适配：找到的技能可能无法完全满足当前任务需求，此时可基于现有技能进行改造，比从零开发全新技能效率更高。</li></ul><p>4.2 实用搭配建议</p><p>若仅需保留两个核心技能，实现“技能获取+技能开发”的闭环，推荐搭配：</p><ul><li>find-skills：负责技能的搜索、安装、管理，解决“找技能难”的问题。</li><li>skill-creator：负责基于现有技能改造或从零开发全新技能，解决“技能适配”的问题。</li></ul><p>4.3 资源补充</p><p>find-skills已正式收录到《Skills蓝皮书-实用Skills篇》，若需了解更多技能相关知识（概念、局限、制作方法等），可移步查看《做了份Skills蓝皮书，从概念、局限到使用、制作，一次讲清》，系统学习技能相关内容。</p><p>五、总结</p><p>find-skills的走红，本质上是解决了AI Agent用户“找技能、装技能、管技能”的核心痛点——无需切换平台、无需复杂操作，小白也能快速上手，大幅提升AI Agent的使用效率。无论是日常使用AI Agent处理简单任务，还是需要大量技能支撑复杂工作，find-skills都能成为高效助手。</p><p>需要注意的是，它并非万能工具，需理性看待其局限性，合理搭配其他技能使用；同时严格遵循使用注意事项，避免出现操作失误。希望本文的解析的操作教程，能帮助大家快速掌握find-skills的使用方法，充分发挥AI Agent的核心价值。</p><p>本文由<a href="https://link.segmentfault.com/?enc=Wh0oWNPwL%2BaVAie8Rby%2Bgg%3D%3D.bIosdEbBR9%2Fb7PlR3kkHdSgb%2Frt%2FAw8MKRxK8FxilAg%3D" rel="nofollow" target="_blank">mdnice</a>多平台发布</p>]]></description></item><item>    <title><![CDATA[GLM-5 拉高开源上限，离一人公司更近了 烦恼的沙发 ]]></title>    <link>https://segmentfault.com/a/1190000047610399</link>    <guid>https://segmentfault.com/a/1190000047610399</guid>    <pubDate>2026-02-13 19:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>以前我觉得开源模型大多是玩具，真要干活、写复杂逻辑，还得老老实实给闭源大厂交 API 的保护费。GLM-5 的发布，不是一次简单的版本号 +1，而是直接把开源模型从玩具拉到了员工的级别。</p><p><img width="723" height="395" referrerpolicy="no-referrer" src="/img/bVdnVNI" alt="image.png" title="image.png"/></p><p>跑完测试后，我发现，以前得雇人或者自己熬夜干的活，现在这个模型真的能接手了。</p><h2>为什么说 GLM-5 让我的认知崩塌了？</h2><p>参数量 744B（激活 40B），预训练数据 28.5T tokens，AI一般都有2个问题，脑子不够用和记性太差，这也是用 AI 开发的痛点，而 GLM-5就没有这个烦恼。</p><h3>1. 它不再是小镇做题家</h3><p>以前评测模型，大家喜欢看它做奥数题。但说实话，谁家好人在工作中用到奥数呀，我它帮我规划任务。</p><p>这次 GLM-5 在 <strong>Vending Bench 2</strong> 上的表现就很厉害了，要知道这个测试很变态的，要求模型在模拟环境里经营一家自动售货机公司，周期长达一年。</p><ul><li>大多数开源模型：落地成盒，开局就寄，根本搞不清库存和资金流。</li><li>GLM-5：不仅活下来了，最后账户余额还剩 <strong>4,432 美元</strong>。</li></ul><p><img width="723" height="528" referrerpolicy="no-referrer" src="/img/bVdnVNJ" alt="image.png" title="image.png" loading="lazy"/></p><p>这个成绩在开源界是断层第一，直逼闭源的 Claude Opus 4.5。就是说，如果你把 GLM-5 接入业务流，它真的具备长期规划和资源管理的能力。</p><h3>2. 从生成文字到交付工作</h3><p>大家以前用模型最烦的是什么？它给你吐出一堆 Markdown 格式的文本，你还得自己复制粘贴去排版。</p><p>GLM-5 这次最让我惊喜的是它对办公场景的理解。它能把那些复杂的推理结果，直接生成 <strong>.docx、.pdf 甚至 .xlsx 文件</strong>。</p><ul><li>写 PRD？它直接给你一个格式完美的 Word 文档。</li><li>做财报分析？它直接扔给你一个带公式的 Excel 表格。</li></ul><p>这才是真正的生产力工具。它省掉那些最没技术含量的格式调整和文档整理时间。</p><h3>3. 技术上的降本增效</h3><p>我也好奇，这么大的参数量，跑起来会不会慢得像蜗牛？</p><p>GLM-5 用了 <strong>DeepSeek</strong> <strong>Sparse</strong> <strong>Attention (DSA)</strong> 的技术，让模型只关注该关注的信息，把算力用在刀刃上。再加上 <strong>slime</strong> 的强化学习架构，解决了大模型越训越傻的问题。</p><p><img width="723" height="497" referrerpolicy="no-referrer" src="/img/bVdnVNK" alt="image.png" title="image.png" loading="lazy"/></p><p>所以它的逻辑密度高，废话少。</p><p><img width="723" height="500" referrerpolicy="no-referrer" src="/img/bVdnVNN" alt="image.png" title="image.png" loading="lazy"/></p><h2>本地部署</h2><p>说到这，很多人可能跃跃欲试想在本地跑一下。毕竟是开源模型，数据握在自己手里才踏实。</p><p>GLM-5 这种量级的模型，对 <a href="https://link.segmentfault.com/?enc=jzQR2ADGqydjs6lodEKgNw%3D%3D.npu1iChYydJ9spVBNXQKsLerWm4tBl07PjwHzqdFB8MiQ9D2LwdJ0gbRDRN7h9PS" rel="nofollow" target="_blank">Python 环境</a>、依赖库有要求。我之前为了跑一个大模型，光是解决 Python 依赖冲突就花了一整天，最后心态崩了模型还没跑起来。</p><p>所以这次为了不重蹈覆辙，直接上 ServBay。如果以前你觉得这种工具是给新手用的，那就错了，这是给想省时间的人用的。</p><p>你想跑 GLM-5，得装特定版本的 Python，还得配 vLLM 或者 SGLang，原生环境里搞，很容易把之前的项目环境搞挂。用 ServBay，点击下载Python， 它直接给我弄了一个隔离的、干净的 Python 3.10+ 环境。</p><p><img width="723" height="458" referrerpolicy="no-referrer" src="/img/bVdnVNO" alt="image.png" title="image.png" loading="lazy"/></p><p>就这么简单。在这个干净的沙盒里，再运行安装命令：</p><pre><code class="bash">pip install -U vllm --pre --index-url https://pypi.org/simple --extra-index-url https://wheels.vllm.ai/nightly</code></pre><p>没有报错，没有红字，一次通过。</p><p>这一步省下来的时间，足够我把 GLM-5 的 API 文档看两遍了。</p><h2>最后</h2><p><strong>如果你看看未来的工作方式长什么样，可以试试 GLM-5。</strong></p><p>它不是那种让你“哇”一声然后就关掉的玩具，它是那种你用了一次，就会把招聘助手的计划推迟的工具。</p><p>值得试试。</p>]]></description></item><item>    <title><![CDATA[【工具对比】免费IP库用于广告投放是否可靠？误差率实测报告 香椿烤地瓜 ]]></title>    <link>https://segmentfault.com/a/1190000047610049</link>    <guid>https://segmentfault.com/a/1190000047610049</guid>    <pubDate>2026-02-13 18:04:34</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在广告投放系统中，IP地理定位往往是最基础的数据能力之一。但在实际业务中，很多团队为了节省成本，会优先采用免费IP库进行地域定向，那么免费IP库是否真的适用于广告投放？</p><blockquote>本文基于本人自测数据，数据测试时间为2025.9月，从准确率与误差距离两个维度进行分析，得出相关结论。</blockquote><h2>一、为什么IP地址准确度对于广告系统更为重要？</h2><p>其实很好理解，在程序化广告系统中，IP定位通常会对广告系统中的定向精准投放、用户来源定向、本地生活推送广告匹配、区域黑名单过渡、投放报表分析等多多项业务有所影响，所以一旦IP定位精度出现过多误差，将会直接影响以下对于广告系统的相关维度：</p><blockquote>CPM浪费； ROI下降；广告主投诉； 数据分析偏差；合规风险</blockquote><p>换句话说，IP数据质量不是“辅助数据”，而是投放链路中的基础设施。</p><h2>二、测试设计说明</h2><h3>1.样本数据</h3><p>构建100,000条真实IP→地理位置映射样本，覆盖全球主要国家、多个省/州、城市级别、IPv4与IPv6以真实定位数据作为基准进行比对。</p><h3>2.测试对象（免费库）</h3><p>本次选取两款常见免费IP数据库：</p><table><thead><tr><th>产品</th><th>类型</th><th>更新频率</th></tr></thead><tbody><tr><td>DB-IP Free</td><td>社区免费版</td><td>月度</td></tr><tr><td>GeoLite 2</td><td>社区免费版</td><td>月度</td></tr></tbody></table><h2>三、实测结果</h2><h3>1️国家级准确率</h3><table><thead><tr><th>产品</th><th>国家准确率</th></tr></thead><tbody><tr><td>DB-IP Free</td><td>97.8%</td></tr><tr><td>GeoLite 2</td><td>99.1%</td></tr></tbody></table><p>结论：国家级定位表现尚可，误差比例较低。</p><h3>2️省/州级准确率</h3><table><thead><tr><th>产品</th><th>省级准确率</th></tr></thead><tbody><tr><td>DB-IP Free</td><td>86.5%</td></tr><tr><td>GeoLite 2</td><td>90.7%</td></tr></tbody></table><p>结论：开始出现10%左右误差，已不适合做精细区域策略。</p><h3>3️城市级准确率</h3><table><thead><tr><th>产品</th><th>城市准确率</th><th>平均误差距离</th></tr></thead><tbody><tr><td>DB-IP Free</td><td>63.5%</td><td>52.7km</td></tr><tr><td>GeoLite 2</td><td>70.1%</td><td>38.9km</td></tr></tbody></table><p>关键结论：</p><blockquote><p>城市级误差明显</p><p>平均误差40–50公里</p><p>移动网络与云出口IP误差更大</p></blockquote><p>在本地商户广告、区域商圈广告场景下，这种误差对于广告投放来说是不可接受的。<br/><img width="723" height="516" referrerpolicy="no-referrer" src="/img/bVdnVHT" alt="【工具对比】1免费IP库用于广告投放是否可靠？误差率实测报告.jpg" title="【工具对比】1免费IP库用于广告投放是否可靠？误差率实测报告.jpg"/></p><h2>四、免费IP库为何不适合广告投放？</h2><h3>1 更新周期滞后</h3><p>IP地址段变化频繁，而免费库多为月度更新，存在明显延迟。</p><h3>2️ 数据采集维度有限</h3><p>免费库通常基于公开数据与社区样本，缺乏商业级验证机制。</p><h3>3️ 城市级定位天然误差</h3><p>ISP出口聚合导致城市归属偏移，免费库难以持续修正。</p><h3>4️ 无SLA保障</h3><p>广告系统属于实时高并发场景，而免费库没有服务稳定性保障，没有数据纠错通道也没有相关的技术支持。</p><h2>五、广告投放真实影响评估</h2><p>我们在模拟广告投放场景中进行ROI偏移测算：</p><p>-城市级定向误差导致约8%–15%投放浪费<br/>-本地商户广告转化率下降10%以上<br/>-数据报表城市分布偏差显著</p><p>在流量规模较大的广告平台中，这种误差会被放大。</p><h2>六、结论：免费库不适合用于广告投放</h2><p>可以明确得出结论：</p><blockquote>免费IP库可以用于测试环境、非核心统计分析，但不适合用于正式广告投放系统。</blockquote><p>尤其是在以下场景：<br/>城市级精准广告/本地生活服务投放/高预算品牌定向广告/跨境合规广告免费库的误差率与数据滞后，都会直接影响商业结果。</p><h2>七、建议：采用专业IP地址库</h2><p>对于广告系统，建议采用专业商业IP地址库，例如：</p><ul><li>IP数据云-特点：高频更新，城市级精度优化，支持IPv4/IPv6，适合国内外广告系统接入</li><li>DB-IP商业版-特点：数据覆盖全面，稳定性较好，海外业务适用性强</li><li>IPnews-特点：强调实时数据更新，精度与稳定性均优于免费版本，适合对实时性要求高的投放系统</li></ul><p>相比免费库，专业IP数据库通常具备：更高城市级准确率，更小平均误差距离，更高更新频率，SLA保障，数据纠错机制。</p><h2>八、工程实践建议</h2><p>建议广告系统采用分层策略：</p><p>1.生产环境使用商业IP库<br/>1.关键流量实时API校验<br/>1.对高价值流量进行多源交叉验证</p><p>在广告系统中，IP数据属于“基础数据能力”，节省IP成本，往往会放大广告成本。</p>]]></description></item><item>    <title><![CDATA[160亿的参数，GLM-Image让AI绘图听懂人话 小白狮ww ]]></title>    <link>https://segmentfault.com/a/1190000047610152</link>    <guid>https://segmentfault.com/a/1190000047610152</guid>    <pubDate>2026-02-13 18:03:56</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>如果说 DeepSeek 让 AI 学会了说人话，那 GLM-Image 就是专治 AI 画图「听不懂人话」的老毛病——毕竟，谁还没被那些鬼画符文字气笑过呢？</p><p>原先的扩散模型手艺好，但耳朵背。现在的 AI 画图工具，像极了手艺精湛却耳背的 Tony 老师——你说招牌写开业大吉，他画出一串连考古学家都破译不了的符号。扩散模型训练稳定、泛化强，但面对复杂指令和知识密集型场景，总在信息表达和语义对齐上掉链子。</p><p>GLM-Image 的解法很务实：让专业的模块干专业的事。90 亿参数的自回归模块（基于 GLM-4-9B-0414）当阅读理解冠军，生成携带语义信号的视觉词元；70 亿参数的扩散解码器（沿袭 CogView4 架构）当像素级工匠，还原高频细节。文科生写剧本、理科生做特效，分工明确才能出大片。</p><p>除文本生成图像外，GLM-Image 还支持图像编辑、风格迁移、身份保持、多主体一致性。更关键的是，它终于能正确渲染中文了！通过集成 Glyph-byT5 进行字符级编码，开业大吉不会再变成开壶大古，海报设计师总算可以松口气了。</p><p>开源，为了好用而不只是能用，由智谱华章以开源形式发布的 GLM-Image 打破「高性能=闭源收费」的潜规则。160 亿总参数对开发者友好，自回归懂语义 + 扩散雕细节的混合架构，或将成为下一代模型的标配。</p><p>毕竟，我们要的不是抽卡式的运气游戏，而是能听懂复杂需求的靠谱搭档。当 AI 海报终于出现正确的汉字，记得感谢这个双脑协作的聪明架构——从耳背 Tony 到贴心设计师，GLM-Image 真的下了功夫。</p><p><strong>教程链接：</strong> <a href="https://link.segmentfault.com/?enc=T9u0iGwc9qUD8ZYME8eUug%3D%3D.gROFiJP02RY3YAS%2FQrECzoYsjFV2yZmab41sT%2BTUevM%3D" rel="nofollow" target="_blank">https://go.openbayes.com/cZzpu</a></p><p>使用云平台: OpenBayes</p><p><a href="https://link.segmentfault.com/?enc=5r1UisDTB%2BuiZHzZZJCb3Q%3D%3D.BzUYhOS5qnZxqQwXnMiaJwR7gFjc0abIbDMwQzm8g7RAivVheEEGJ7IW1MR2ft4V" rel="nofollow" target="_blank">http://openbayes.com/console/signup?r=sony_0m6v</a></p><p>首先点击「公共教程」，找到「GLM-Image：首个全流程国产芯片训练模型」，单击打开。</p><p><img width="723" height="495" referrerpolicy="no-referrer" src="/img/bVdnVIi" alt="" title=""/><br/>页面跳转后，点击右上角「克隆」，将该教程克隆至自己的容器中。</p><p><img width="723" height="489" referrerpolicy="no-referrer" src="/img/bVdnVIu" alt="" title="" loading="lazy"/><br/>在当前页面中看到的算力资源均可以在平台一键选择使用。平台会默认选配好原教程所使用的算力资源、镜像版本，不需要再进行手动选择。点击「继续执行」，等待分配资源。</p><p><img width="723" height="491" referrerpolicy="no-referrer" src="/img/bVdnVIv" alt="" title="" loading="lazy"/><img width="723" height="493" referrerpolicy="no-referrer" src="/img/bVdnVID" alt="" title="" loading="lazy"/></p><p>若显示「Bad Gateway」，这表示模型正在加载中，请等待约 2-3 分钟后刷新页面即可。</p><p><img width="723" height="494" referrerpolicy="no-referrer" src="/img/bVdnVIK" alt="" title="" loading="lazy"/></p><h3><strong>使用步骤如下：</strong></h3><ol><li>页面跳转后，点击左侧 README 页面，进入后点击上方「运行」。</li></ol><p><img width="723" height="482" referrerpolicy="no-referrer" src="/img/bVdnVIL" alt="" title="" loading="lazy"/></p><ol start="2"><li>点击运行后等待加载模型与初始化</li></ol><p><img width="723" height="483" referrerpolicy="no-referrer" src="/img/bVdnVIQ" alt="" title="" loading="lazy"/></p><ol start="3"><li>待运行完成，即可点击右侧 API 地址跳转至 demo 页面。</li></ol><p><img width="723" height="483" referrerpolicy="no-referrer" src="/img/bVdnVIR" alt="" title="" loading="lazy"/></p><ol start="4"><li>打开后上传你想要的图片或文字，点击运行</li></ol><p><img width="723" height="398" referrerpolicy="no-referrer" src="/img/bVdnVIW" alt="" title="" loading="lazy"/></p><ol start="5"><li>成图展示</li></ol><p><img width="723" height="408" referrerpolicy="no-referrer" src="/img/bVdnIvT" alt="" title="" loading="lazy"/><br/><strong>教程链接：</strong> <a href="https://link.segmentfault.com/?enc=kb5Lb1Ji1Ho8Qr67Rq6vRA%3D%3D.6JR4omG55ayMYlHmHSQZzVAJtt%2BXJFo92K3u6ep8s6s%3D" rel="nofollow" target="_blank">https://go.openbayes.com/cZzpu</a></p>]]></description></item><item>    <title><![CDATA[小白零成本上手OpenClaw（小龙虾AI）：龙猫免费Token+memU bot搭建+飞书控制全教]]></title>    <link>https://segmentfault.com/a/1190000047610208</link>    <guid>https://segmentfault.com/a/1190000047610208</guid>    <pubDate>2026-02-13 18:03:00</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>小白零成本上手OpenClaw（小龙虾AI）：龙猫免费Token+memU bot搭建+飞书控制全教程</p><p>码字不易，哪怕内容稍显啰嗦，每一处细节都是为了小白能顺利上手——这篇依旧是喂饭级超长教程，无需懂代码、无需深厚计算机基础，跟着老马的步骤一步步来，你就能零成本拥有：理论上无限额度的大语言模型API接口、本地私人电脑AI助手（OpenClaw，人称小龙虾AI机器人），甚至能在手机上动动嘴，远程控制电脑上的小龙虾替你干粗活。</p><p>全程零门槛、零成本，哪怕你对AI技术一窍不通，也建议尝试——学AI、了解AI，多动手总没有坏处，老马是上过大学的人，绝不坑你！废话不多说，教程分为三个核心阶段，Les't go！</p><p>第一阶段：免费白嫖龙猫大模型API（解决Token烧钱痛点）</p><p>搭建OpenClaw（小龙虾AI）的核心前提，是拥有一个大语言模型API接口——没有它，小龙虾就是个“傻子”，啥活也干不了。市面上很多人会忽悠你付费开通GLM-4.7、MiniMax M2.1、Kimi K2.5等API服务，每月要花几十到一两百块；更有甚者，让你购买Claude code模型API，分分钟烧的都是美刀，贵得离谱。</p><p>今天给大家带来的福利，是美团推出的LongCat（龙猫）大模型——美团送外卖不差钱，目前注册龙猫开放平台，每天免费送Token，最高可嫖5000万额度，完全能喂饱“吃货”小龙虾（小龙虾消耗Token速度较快）。</p><p>1.1 龙猫大模型核心优势及额度说明</p><p>龙猫大模型总参数量685亿，但每次推理仅激活29亿至45亿参数，实现高稀疏性，既保证性能，又降低消耗，核心额度政策如下（实测真实有效）：</p><ul><li>基础免费额度：注册即送，每天至少50万tokens，三款模型共享（LongCat-Flash-Chat、LongCat-Flash-Thinking、LongCat-Flash-Thinking-2601），当天没用完，第二天自动重置为50万，无时间限制。</li><li>升级额度（推荐）：点击平台“申请更多额度”，随便填写简单的公司信息（无需真实资质，审核极松），30分钟内即可审核通过，额度直接从50万升级到500万，足够日常使用。</li><li>终极福利额度：LongCat-Flash-Lite（轻量化模型），目前限时不限量，调用该模型不消耗任何额度，相当于“无限使用”，完美解决小龙虾Token消耗快的问题。</li></ul><p>1.2 注册龙猫平台并获取API（全程3分钟搞定）</p><p>操作极其简单，仅需3步，全程无需付费，无需复杂操作：</p><ol><li>访问官网：在电脑浏览器地址栏输入 <a href="https://link.segmentfault.com/?enc=GoAu5%2B5XjeTVG4lU%2BBysDA%3D%3D.ziyh3QQyKSZvMJp0LMI0pTtZHTtqF369SwXTYTR3UtTlY8uEi%2F%2FE%2FHWVBlJiFZF5" rel="nofollow" target="_blank">https://longcat.chat/platform/usage</a>，打开龙猫API开放平台。</li><li>注册登录：使用手机号码获取验证码，直接注册并登录（无需绑定银行卡、无需实名认证，流程极简）。</li><li><p>查看额度：登录后，页面会直接显示你的Token额度，以及可使用的模型，记住这三款核心模型名称（后续配置会用到）：</p></li></ol><ul><li>LongCat-Flash-Chat（主模型，共享50-500万额度）</li><li>LongCat-Flash-Thinking（思考模型，共享50-500万额度）</li><li>LongCat-Flash-Lite（轻量化模型，无限额度，优先推荐）</li></ul><p>1.3 获取API密钥（核心配置，必看）</p><p>API密钥是后续配置OpenClaw的核心，没有它无法接入模型，获取步骤如下（图文指引，小白也能看懂）：</p><ol><li>登录龙猫开放平台后，找到左侧菜单中的“API Keys”，点击进入。</li><li>进入页面后，平台会默认给你创建一个API密钥，你可以直接复制使用；也可以点击“新建API Key”，自定义创建（建议直接用默认的，省时间）。</li><li>复制API密钥，保存到电脑记事本或手机备忘录中（后续会反复用到，别弄丢，每个人的密钥都是唯一的，老马也无法获取你的密钥）。</li></ol><p>1.4 龙猫API接口格式（无需懂，复制即用）</p><p>龙猫平台兼容两种主流API格式，无需理解原理，后续配置时按要求复制对应地址即可：</p><ul><li>OpenAI格式（备选）：<a href="https://link.segmentfault.com/?enc=j7iueQCtCQkH7wEAP8Qm2A%3D%3D.SQe2bafF4NXYgdvJUQwS4zquFohneVcCAzO2HXkI6%2BI%3D" rel="nofollow" target="_blank">https://api.longcat.chat/openai</a>，兼容OpenAI API规范，支持对话补全接口（/v1/chat/completions）。</li><li>Anthropic格式（推荐，后续配置优先用）：<a href="https://link.segmentfault.com/?enc=K26ncOM67f2aKT4anAJdGw%3D%3D.sVo3cfmIGELk%2FrjT7frtpyktfbrSX8fWC58%2F8GFXbcsTOWdKXFYtvip7La2lnkA%2B" rel="nofollow" target="_blank">https://api.longcat.chat/anthropic</a>，兼容Anthropic Claude API规范，支持消息对话接口（/v1/messages）。</li></ul><p>补充说明：配置时只需填三个东西——API接口地址（推荐Anthropic格式）、API密钥（刚才复制的）、模型名称（优先选LongCat-Flash-Lite，无限额度），其余无需管。</p><p>第二阶段：搭建memU bot加强版OpenClaw（小白傻瓜式一键安装）</p><p>很多小白反馈，原版OpenClaw搭建门槛太高——Windows系统要装WSL或Node.js，不懂计算机知识根本无从下手；环境搭建报错、Github访问不畅、不会魔法上网，每一步都能把小白逼疯。</p><p>今天推荐的方法，是搭建memU bot加强版OpenClaw——memU本身是一个开源记忆框架，专门做记忆管理，memU bot相当于把memU和OpenClaw结合，不仅解决了原版OpenClaw的搭建痛点，还优化了记忆功能和安全性，具体优势如下：</p><ul><li>傻瓜式安装：砍掉复杂不稳定的环境与网络门槛，一键安装，无需手动配置环境。</li><li>记忆功能升级：原版OpenClaw“记性差”，memU加持后，能长期记忆你的使用习惯，提前预判你的需求。</li><li>优化体验：解决了原版OpenClaw上下文管理差、安全性不足的问题，使用更流畅、更安全。</li><li>多平台适配：支持Windows、Mac系统，操作步骤完全一致，小白通用。</li></ul><p>2.1 下载memU bot（解决QQ邮箱拦截坑）</p><p>以Windows 11系统为例（Mac系统操作完全一致），下载步骤如下，重点解决QQ邮箱拦截的常见坑：</p><ol><li>访问memU bot官网：<a href="https://link.segmentfault.com/?enc=4HiRTPLBScSFcQvkfSAArg%3D%3D.yBQP8BN38dXPqPbDwkyG3k2%2BTGuDe1gIweTEgu2Lc%2BY%3D" rel="nofollow" target="_blank">https://memu.bot</a>（官网是英文，无需担心，只需找输入框即可）。</li><li>获取下载链接：在官网找到输入电子邮箱（E-mail）的输入框，输入你常用的邮箱（QQ邮箱、163邮箱均可），点击“Send Link”，官网会在几秒钟内，将下载链接发送到你的邮箱。</li><li><p>解决邮箱拦截问题（重点）：</p></li></ol><ul><li>打开邮箱，会收到一封英文邮件，QQ邮箱可能会提示“疑似欺诈”，直接忽略即可。</li><li>点击邮件中的Windows下载按钮，大概率会被QQ邮箱拦截，此时不要慌——鼠标右键点击“Windows下载按钮”，选择“复制链接地址”。</li><li>在浏览器新建标签页，将复制的链接粘贴到地址栏，按回车键，即可正常下载（避开邮箱拦截）。</li></ul><p>2.2 安装memU bot（解决系统拦截坑）</p><p>下载完成后（建议保存到桌面，方便查找），开始安装，重点解决系统拦截问题：</p><ol><li>双击桌面的memU bot安装包，系统可能会提示“未知发布者”，点击“更多信息”。</li><li>在新弹出的页面中，点击“仍要运行”，即可开始安装（系统拦截是正常现象，无需担心安全问题）。</li><li>安装过程无需手动操作，默认安装到C盘，安装完成后，会自动在桌面生成快捷方式，并启动memU bot软件。</li></ol><p>2.3 配置龙猫大模型API（核心步骤，必做）</p><p>启动memU bot后，需要将第一阶段获取的龙猫API配置进去，否则小龙虾无法“思考”，步骤如下（全程鼠标操作，无需懂代码）：</p><ol><li>进入设置界面：点击memU bot软件左下角的“齿轮按钮”（设置图标），进入配置页面。</li><li>选择提供商：在右侧的“LLM提供商”下拉框中，选择“Custom Provider”（自定义提供商）。</li><li><p>填写核心配置（重点，按要求填，不要错）：</p></li></ol><ul><li>API地址：粘贴Anthropic格式地址：<a href="https://link.segmentfault.com/?enc=CUTIlxcBbI%2BJLmHGPAybQw%3D%3D.xpbmnAxNa4AMe5UfrGES5vudm%2BcJkUOYW059dpe9jVhLuHwVlcvd%2FMrjlT%2FZixK5" rel="nofollow" target="_blank">https://api.longcat.chat/anthropic</a></li><li>API密钥：粘贴第一阶段复制的龙猫API密钥（注意：不要有空格、不要复制错字符）。</li><li>模型名称：优先填写“LongCat-Flash-Lite”（无限额度，无需担心消耗）；也可根据需求填写另外三款模型名称。</li></ul><ol start="4"><li>保存配置：填写完成后，点击页面中的“保存更改”，确保配置生效。</li></ol><p>2.4 可选配置：MemU API与Tavily搜索API（提升小龙虾能力）</p><p>配置完龙猫API后，小龙虾已经能正常使用（基础功能无影响），页面中还有两个空的API配置项（MemU API、Tavily搜索API），作用及获取方法如下（可选，小白可先不配置，后续再补充）：</p><ul><li>MemU API：提升小龙虾的记忆能力，让它能更好地记住你的使用习惯，点击“从MemU平台获取→”，用邮箱注册即可免费获取API密钥（英文网站，可用浏览器翻译，操作简单）。</li><li>Tavily搜索API：给小龙虾增加搜索能力，让它能实时获取网络信息，点击“从tavily.com获取（每月1000次免费搜索）→”，注册即可免费获取（每月免费1000次，足够日常使用）。</li></ul><p>补充说明：不配置这两个API，不影响小龙虾的基础使用，只是缺失记忆和搜索功能；后续也可通过安装插件，补充这两项能力，老马建议大家后续有空再配置，先完成基础搭建，体验核心功能。</p><p>第三阶段：memU bot接入飞书（手机远程控制小龙虾）</p><p>配置完模型后，下一步就是接入飞书机器人——后续我们主要通过飞书APP（手机/电脑均可），与小龙虾对话，下达指令，甚至在手机上动动嘴，远程控制电脑上的小龙虾干活，步骤依旧是小白友好型，全程截图级指引。</p><p>3.1 注册飞书并创建企业自建应用</p><ol><li>访问飞书开放平台：在电脑浏览器打开 <a href="https://link.segmentfault.com/?enc=mLdzfRchnv6iW9GjwEOoeg%3D%3D.c1J79IIyvdtzVsEFzh23c5Z34NORp4UAWpNd3q6Ehi8%3D" rel="nofollow" target="_blank">https://open.feishu.cn/app</a>，用手机号码获取验证码登录（建议用常用手机号，方便后续使用）。</li><li>创建应用：登录后，在主页面找到“创建企业自建应用”按钮，点击进入创建页面。</li><li><p>填写应用信息（无需复杂，随便填）：</p></li></ol><ul><li>应用名称：随便取（如“小龙虾AI”“memU bot”均可）。</li><li>应用描述：随便写（如“远程控制小龙虾AI机器人”）。</li><li>应用图标：可选择喜欢的背景色和图形，无需自定义，默认图标即可。</li></ul><ol start="4"><li>完成创建：填写完成后，点击“创建”，进入应用的设置界面。</li></ol><p>3.2 获取飞书App ID和App Secret（核心参数）</p><p>这两个参数是memU bot接入飞书的关键，获取步骤如下：</p><ol><li>在飞书应用设置界面，左侧菜单找到“凭证与基础信息”，点击进入。</li><li>在页面中找到“App ID”和“App Secret”两个参数，分别复制，保存到电脑记事本（和之前的龙猫API密钥放在一起，方便后续使用）。</li><li>注意：不要泄露这两个参数，仅用于自己的memU bot配置。</li></ol><p>3.3 memU bot配置飞书参数</p><p>回到电脑上的memU bot软件，继续在设置界面操作，完成飞书接入：</p><ol><li>在memU bot设置页面，找到左侧“通用”下面的“平台”选项，点击进入。</li><li>滚动鼠标，找到“飞书”设置区域，将刚才复制的“App ID”和“App Secret”，分别粘贴到对应输入框中。</li><li>点击“保存更改”，memU bot这边的飞书配置就完成了。</li></ol><p>3.4 飞书应用添加能力（后续补充完善）</p><p>回到飞书开放平台的应用设置界面，还需要给应用添加对应能力，才能正常使用，步骤如下（后续可逐步完善）：</p><ol><li>在飞书应用设置左侧菜单，找到“添加应用能力”，点击进入。</li><li>后续可根据需求，添加“机器人”“消息推送”等相关能力（具体可参考飞书官方指引，或后续老马补充教程），目前先完成基础配置，确保能正常连接即可。</li></ol><p>第四阶段：常见问题排查+补充说明（小白必看）</p><p>很多小白跟着教程操作，还是会遇到小问题，这里整理了最常见的4个问题，以及补充说明，帮你避开所有坑：</p><p>4.1 常见问题排查</p><ul><li>问题1：配置龙猫API后，小龙虾无法使用？<br/>解决：优先检查API密钥是否复制正确（有无空格、大小写错误）；其次检查API地址是否粘贴正确（推荐Anthropic格式）；最后确认模型名称填写无误（优先LongCat-Flash-Lite）。</li><li>问题2：memU bot下载/安装时，被邮箱/系统拦截？<br/>解决：下载时用“复制链接地址，浏览器直接打开”的方法，避开邮箱拦截；安装时点击“更多信息→仍要运行”，避开系统拦截，均为正常现象。</li><li>问题3：飞书App ID和App Secret复制错误，无法接入？<br/>解决：回到飞书“凭证与基础信息”页面，重新复制，确保没有多复制、少复制字符，粘贴后保存更改，重启memU bot即可。</li><li>问题4：龙猫额度不够用？<br/>解决：点击龙猫平台“申请更多额度”，随便填写公司信息，30分钟内审核通过，额度升级到500万；或切换到LongCat-Flash-Lite模型，无限额度，无需担心消耗。</li></ul><p>4.2 补充说明</p><ul><li>关于龙猫额度：目前LongCat-Flash-Lite模型限时不限量，建议尽快配置使用，后续若有调整，老马会及时补充更新。</li><li>关于memU bot版本：软件会持续更新，若后续版本界面有细微变化，核心配置步骤不变，只需找到对应设置项即可。</li><li>关于手机控制：飞书APP可在应用商店下载，登录后即可找到创建的应用，与小龙虾对话，下达远程控制指令（后续会补充详细的指令使用教程）。</li><li>关于课后作业：MemU API和Tavily搜索API的获取，建议小白后续有空再操作，锻炼一下动手能力，操作难度极低，看懂网页、会点按钮即可。</li></ul><p>第五阶段：总结与后续支持</p><p>综上，整个教程全程零成本、零门槛，无需懂代码、无需深厚计算机基础，跟着步骤操作，你就能拥有：无限额度的龙猫大模型API、memU bot加强版OpenClaw（小龙虾AI），以及手机远程控制能力。</p><p>后续若遇到配置失败、无法使用等问题，可转发本文并在评论区留言“666”，老马会提供手把手配置指导，全程协助你完成所有操作，确保你能顺利用上免费的小龙虾AI机器人。</p><p>最后再强调一句：学AI、用AI，多动手、多尝试，哪怕是小白，也能快速上手——这一切都是免费的，何乐而不为呢？后续老马还会补充飞书控制详细指令、API进阶配置等内容，记得关注哦！</p><p>本文由<a href="https://link.segmentfault.com/?enc=oDTjNH1J%2FlPn1om3TqXcVg%3D%3D.IDWLF75tv0B97LtauK19eGO5TYOYp5yJ41Jshfl4cSo%3D" rel="nofollow" target="_blank">mdnice</a>多平台发布</p>]]></description></item><item>    <title><![CDATA[使用C#代码在 Excel 中删除重复行 千杯不醉的脸盆 ]]></title>    <link>https://segmentfault.com/a/1190000047610211</link>    <guid>https://segmentfault.com/a/1190000047610211</guid>    <pubDate>2026-02-13 18:02:02</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>当我们将来自不同来源的数据集合并，或从其他工作表复制数据时，如果数据匹配不够严谨，就很容易产生重复行。这些重复数据不仅会影响数据整洁度，还可能干扰统计分析和公式计算，甚至导致结果失真。</p><p>因此，删除重复行是 Excel 数据处理中非常常见且重要的一项操作。本文将介绍如何使用 Spire.XLS for .NET 以编程方式高效地实现这一功能。</p><h2>安装 Spire.XLS for .NET</h2><p>首先，需要在 .NET 项目中添加 Spire.XLS for .NET 包中的 DLL 文件作为引用。您可以通过官网下载对应的安装包获取 DLL 文件，也可以直接通过 NuGet 进行安装。</p><pre><code class="C#">PM&gt; Install-Package Spire.XLS</code></pre><h2>在 C# 和 VB.NET 中删除 Excel 重复行</h2><p>手动删除重复行不仅步骤繁琐，而且十分耗时。借助 Spire.XLS for .NET，可以一次性识别并移除所有重复行，大幅提升处理效率。</p><p><strong>具体实现步骤如下：</strong></p><ol><li>创建一个 Workbook 实例。</li><li>使用 Workbook.LoadFromFile() 方法加载示例 Excel 文件。</li><li>通过 Workbook.Worksheets[sheetIndex] 获取指定索引的工作表。</li><li>使用 Worksheet.Range 属性指定需要检测并删除重复记录的单元格区域。</li><li>获取该区域中包含重复内容的行。</li><li>遍历所有重复行，并通过 Worksheet.DeleteRow() 方法将其删除。</li><li>使用 Workbook.SaveToFile() 方法保存处理后的结果文件。</li></ol><p>通过以上步骤，即可实现对 Excel 重复行的自动化删除。</p><p><strong>具体示例代码如下：</strong></p><pre><code class="C#">using Spire.Xls;
using System.Linq;

namespace RemoveDuplicateRows
{
    class Program
    {
        static void Main(string[] args)
        {
            // 创建 Workbook 实例
            Workbook workbook = new Workbook();

            // 加载示例 Excel 文档
            workbook.LoadFromFile("Test.xlsx");

            // 获取第一个工作表
            Worksheet sheet = workbook.Worksheets[0];

            // 指定需要删除重复记录的单元格区域
            var range = sheet.Range["A1:A" + sheet.LastRow];

            // 获取重复行的行号
            var duplicatedRows = range.Rows
                   .GroupBy(x =&gt; x.Columns[0].DisplayedText)
                   .Where(x =&gt; x.Count() &gt; 1)
                   .SelectMany(x =&gt; x.Skip(1))
                   .Select(x =&gt; x.Columns[0].Row)
                   .ToList();

            // 删除重复行        
            for (int i = 0; i &lt; duplicatedRows.Count; i++)
            {
                sheet.DeleteRow(duplicatedRows[i] - i);
            }

            // 保存结果文档
            workbook.SaveToFile("RemoveDuplicateRows.xlsx");
        }
    }
}</code></pre><h2>申请临时许可证</h2><p>如果您希望去除生成文档中的评估提示信息，或解除功能限制，可以为自己申请一个为期 30 天的试用许可证。</p>]]></description></item><item>    <title><![CDATA[产品更新｜多视角记忆、检索精筛与 Skills 本地化上线 MemTensor ]]></title>    <link>https://segmentfault.com/a/1190000047610381</link>    <guid>https://segmentfault.com/a/1190000047610381</guid>    <pubDate>2026-02-13 18:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><img width="723" height="117" referrerpolicy="no-referrer" src="/img/bVdm29W" alt="11.jpg" title="11.jpg"/><br/>本次更新围绕"记忆系统工程化"和"Agent 能力结构化"两条主线，对云服务和开源项目做了系统升级。核心改进集中在多视角记忆、记忆版本管理、检索召回质量、Skills 本地化，以及若干生产环境的稳定性优化。</p><h2>本次发布亮点</h2><p><img width="723" height="524" referrerpolicy="no-referrer" src="/img/bVdnVNs" alt="22.png" title="22.png" loading="lazy"/></p><h3>1. 多视角记忆：让每个 Agent 拥有“自己的记忆世界”</h3><p>传统 Agent 架构里，记忆通常是全局共享的，所有 Agent 共享同一份"客观记忆池"。这在多角色系统、多 Agent 协作场景中容易导致行为冲突和角色混淆。</p><p>我们上线了多视角记忆（Multi-Perspective Memory），为每个 Agent 引入"主观视角"的记忆结构。同一事实可以在不同 Agent 那里形成不同视角的记忆表达和认知结构。每个 Agent 的记忆体拥有自己的"主观视角"，适合需要角色化、队伍化的 AI 游戏或多 Agent 协作场景，比如组队游戏、角色化陪伴类应用。</p><p>帮助系统在多 Agent 协作时避免"一刀切"的全局记忆，便于实现个性化行为和角色差异化决策。记忆不再是单一全局视图，而是 Agent 级别的认知世界模型。</p><p><img width="551" height="911" referrerpolicy="no-referrer" src="/img/bVdnVNt" alt="33.png" title="33.png" loading="lazy"/></p><h3>2. 多视角 AI 小游戏 Demo：多 Agent 记忆协作的真实形态</h3><p>基于多视角记忆的小游戏"冲顶鳌太线"已经上线，提供组队冲顶玩法的示例。Demo 以组队协作为核心场景，多 Agent 各自拥有独立视角记忆，同时参与协作任务目标，形成"个体认知 + 团队目标"的复合结构。</p><p>该 Demo 以组队协作为核心场景：</p><ul><li>多 Agent 各自拥有独立视角记忆</li><li>同时参与协作任务目标</li><li>形成“个体认知 + 团队目标”的复合结构</li></ul><h3>3. 检索记忆（search/memory）能力增强：更准 + 更省 Token</h3><h4>3.1 关键词召回 + 语义相似度混合排序</h4><p>在事实记忆检索链路中新增 ​<strong>关键词召回机制</strong>​，并与原有<strong>语义相似度检索</strong>进行混合排序：</p><ul><li>提升召回覆盖率；</li><li>提升召回准确率；</li><li>避免单一语义相似导致的语义漂移问题。</li></ul><p>实测效果：</p><ul><li><strong>LongMemEval 提升 1.8%；</strong></li><li><strong>Locomo 提升 0.72%。</strong></li></ul><p>该能力默认开启，开发者无需额外配置。</p><h4>3.2 消耗 Token 更少的记忆召回策略（相关性精筛）</h4><p>新增 <strong><code>relativity</code>（相关性阈值）</strong> 与 <strong><code>memory_limit_number/top_k</code></strong> 等参数，允许开发者按阈值只返回高相关性的记忆，从而显著降低注入 prompt 的 token 消耗，控制成本并提高上下文质量。</p><p>为解决记忆注入导致的 Token 消耗问题，search/memory 接口新增 ​<strong>相关性精筛机制</strong>​：</p><ul><li><code>relativity</code>：相关性阈值（0\~1）；</li><li><code>memory_limit_number / top_k</code>：召回数量上限。</li></ul><p>系统只返回：</p><ul><li><strong>相关性 ≥ 阈值；</strong></li><li>且 <strong>数量 ≤ 上限</strong> 的记忆集合。</li></ul><p>这使 MemOS 的记忆注入从“暴力拼接”升级为：</p><blockquote>精准召回 + 强相关过滤 + Token 成本可控</blockquote><p>📌 当前 <code>relativity</code> 仅对 <strong>事实记忆、偏好记忆</strong> 生效。</p><p>​<strong>示例（云服务）</strong>​：</p><pre><code>data = {
  "user_id": "memos_user_123",
  "query": "为我规划5天的成都游。",
  "relativity": 0.8, # 只返回相关性 &gt;= 0.8 的记忆
  "memory_limit_number": 9 # 最多返回 9 条
}</code></pre><p>​<strong>示例（开源）</strong>​：</p><pre><code>{
  "user_id": "memos_user_123",
  "readable_cube_ids": ["memos_user_123_cube"],
  "query": "为我规划5天的成都游。",
  "relativity": 0.8,
  "top_k": 9
}</code></pre><p>注意：<code>relativity</code> 当前仅对<strong>事实记忆</strong>与<strong>偏好记忆</strong>生效。</p><h3>4. Skills 能力工程化升级 + MindDock 插件接入</h3><h4>4.1 Skills 本地化存储机制</h4><p>Skills 文件支持​<strong>本地保存</strong>​，系统会为本地 Skills 自动生成专属访问 URL，LLM 可通过接口远程加载并运行 Skills，支持私有化部署与企业级管理。</p><p>这使 Skills 从"运行态能力"升级为可管理、可分发、可治理的能力资产。</p><p>开源项目中，Skills 文件现已支持​<strong>本地保存</strong>​：</p><ul><li>系统自动生成专属访问 URL</li><li>大模型可通过接口远程加载 Skills</li><li>支持私有化部署与企业级管理</li></ul><h4>4.2 Skills 生成质量优化</h4><p>系统现在可以基于用户历史消息生成更完整、更结构化的 Skills 描述，使技能从"零散规则"升级为结构化能力模块。</p><p><strong>配置本地储存（开源）（简要步骤）：</strong></p><p>Step 1: 添加环境变量到项目根目录的.env 文件</p><pre><code>SKILLS_REPO_BACKEND=LOCAL
SKILLS_LOCAL_DIR=/tmp/upload_skill_memory/ # 最终存储位置
SKILLS_LOCAL_TMP_DIR=/tmp/skill_memory/ # 生成时的临时位置
SKILLS_LLM=gpt-4o</code></pre><p>Step 2: 启动本地服务</p><pre><code>uvicorn memos.api.server_api:app --host 0.0.0.0 --port 8001 --workers 1</code></pre><h4>4.3 MindDock 插件能力接入</h4><p>插件 <strong>MindDock</strong> 现已支持：</p><ul><li>在 ChatGPT；</li><li>千问；</li><li>等多平台聊天环境中。</li></ul><p>并支持实时注入 Skills，使 Skills 成为​<strong>跨平台通用能力层</strong>​，而非单一模型绑定能力。</p><p><img width="723" height="276" referrerpolicy="no-referrer" src="/img/bVdnVNu" alt="44.png" title="44.png" loading="lazy"/></p><ol start="5"><li><h3>MCP 删除记忆路径增强：删除不再是“弱操作”</h3></li></ol><p>为更好支持用户删除记忆的意图识别与落地，MCP 处理逻辑更新为：</p><ul><li>在识别到删除意图后，调用 <code>deleteMemory</code> 接口直接删除对应记忆；</li><li>同时调用 <code>addFeedback</code> 接口以记录用户反馈并更新相关记忆项，确保删除操作更可靠且可审计。</li></ul><p>从“模糊删除”升级为​<strong>双通道强语义删除机制</strong>​，确保用户对记忆控制权的完整性与可靠性。</p><p><img width="723" height="215" referrerpolicy="no-referrer" src="/img/bVdnVNv" alt="55.png" title="55.png" loading="lazy"/></p><h3>6. 记忆调度模块化重构：工程级稳定性升级</h3><p>记忆调度任务处理器实现模块化重构并集中统一管理。</p><p>重构内容包括：</p><ul><li>将检索流程拆分为：<code>search </code>→<code>enhance</code>→<code>rerank</code>→<code> filter</code> 四阶段；</li><li>新增 <code>search_service</code> 统一 API 与 Scheduler 的文本检索实现；</li><li>修复 Redis Streams 调度消息序列化问题，补齐 <code>mem_read</code>/<code>pref_add processor</code> 的 <code>user_context</code> 传递。</li></ul><p>我们提升了调度的可靠性、可观测性与可扩展性，便于在高并发场景下稳定运行。</p><p><img width="723" height="363" referrerpolicy="no-referrer" src="/img/bVdnVNw" alt="66.png" title="66.png" loading="lazy"/></p><h3>7. 文档记忆双轨检索：记忆 + 原文 + 上下文协同</h3><p>​<strong>新能力</strong>​：</p><ul><li>支持​<strong>原文片段（RawFileMemory）与记忆（SummaryMemory）混合检索</strong>​，并可按需同时召回原文上下文以增强长文本语义连贯性；</li><li><code>search_memory_type</code> 支持三种模式：<code>All</code>（原文 + 记忆混合）、<code>AllSummaryMemory</code>（仅记忆）、<code>RawFileMemory</code>（仅原文片段）；</li><li><code>neighbor_discovery</code> 配置用于是否召回原文分片的上下文。</li></ul><p>现在，文档记忆同时具备：</p><ul><li>语义抽象能力；</li><li>原文可追溯性；</li><li>上下文连贯性。</li></ul><p>​<strong>开源示例</strong>​：</p><pre><code>data{
  "user_id": "testfile", 
  "readable_cube_ids": ["testfile_cube"],
  "query": "minddock 适配什么浏览器",
  "search_memory_type": "AllSummaryMemory", # 三种检索模式 All | AllSummaryMemory | RawFileMemory
  "neighbor_discovery": "true", # 若想召回原文上下文则置为 True
}</code></pre><p>检索到的结果中：<code>memory_type</code> 新增 <code>RawFileMemory</code>（记忆原文片段）。</p><h3>8. 记忆过滤器（Filter）支持秒级时间精度</h3><p><code>filter</code> 字段现在支持秒级别时间范围过滤（例如 <code>"create_time": "2026-02-12 10:00:00"</code>），适用于检索/获取记忆与对话接口的精确时窗筛选，提高审计与时效性控制的能力。</p><p>​<strong>示例</strong>​：</p><pre><code>"filter" : {
  "and": [
    {"create_time": {"gt": "2026-02-01 10:00:00"}},
    {"create_time": {"lt": "2026-02-12 10:00:00"}}
  ]
}</code></pre><h3>9. 对话接口（Chat）稳定性与能力增强</h3><ul><li>修复了 <code>qwen3-32b</code> 回答失败的问题，恢复模型可用性；</li><li>对话接口现支持 <code>relativity</code> 字段，允许开发者在对话阶段控制召回记忆的相关性阈值，从源头减少低价值上下文注入。</li></ul><p>对话系统在稳定性与成本控制层面同步升级。</p><h3>10. 开源社区（CHANGELOG 摘要）</h3><p><strong>新增 / 新功能</strong></p><ul><li>记忆检索优化（关键词检索 + 语义混合）；</li><li>文档记忆双轨检索：原文 + 记忆协同检索；</li><li>文档记忆上下文唤醒（分片上下文）；</li><li><code>relativity</code> 精筛字段（0\~1）；</li><li>MindDock 与云服务 Skill 支持；</li><li>MCP 删除意图触发 <code>deleteMemory</code> 与 <code>addFeedback</code>；</li><li>Chat 接口可传 <code>relativity</code>。</li></ul><p><strong>改进</strong></p><ul><li>检索 pipeline 重构（Search → Enhance → Rerank → Filter）；</li><li>调度任务处理器模块化与 Redis Streams 修复；</li><li>Skills 本地化存储与 URL 发布；</li><li>Skills 生成质量提升。</li></ul><p><strong>修复</strong></p><ul><li>Playground 使用体验问题修复；</li><li>偏好记忆阈值字段使用错误修复；</li><li>修复 <code>get_memory</code> 在复杂 filter 情形下的调用失败或卡顿问题；</li><li>修复 Chat 接口 qwen3-32b 回答失败，兼容 LLM 的 enable thinking 参数。</li></ul><hr/><h2>关于 MemOS</h2><p>MemOS 为 AGI 构建统一的记忆管理平台，让智能系统如大脑般拥有灵活、可迁移、可共享的长期记忆和即时记忆。</p><p>作为记忆张量首次提出“记忆调度”架构的 AI 记忆操作系统，我们希望通过 MemOS 全面重构模型记忆资源的生命周期管理，为智能系统提供高效且灵活的记忆管理能力。本次更新围绕"记忆系统工程化"和"Agent 能力结构化"两条主线，对云服务和开源项目做了系统升级。核心改进集中在多视角记忆、记忆版本管理、检索召回质量、Skills 本地化，以及若干生产环境的稳定性优化。<br/><img width="640" height="102" referrerpolicy="no-referrer" src="/img/bVdnRYD" alt="77.jpg" title="77.jpg" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[哪款企业网盘更好用？2026实测6款热门产品，易用性+效率双优选型指南 nut_king ]]></title>    <link>https://segmentfault.com/a/1190000047609942</link>    <guid>https://segmentfault.com/a/1190000047609942</guid>    <pubDate>2026-02-13 17:03:11</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>对企业而言，“好用的企业网盘”从不是“功能越多越好”，而是能让员工快速上手、让协作流程顺畅、让管理成本降低的工具。无论是新人入职10分钟掌握文件存储逻辑，还是跨部门协作无需反复沟通权限，亦或是管理者一键掌控数据流转轨迹，核心都离不开“易用性”与“高效性”两大关键。</p><p>本文结合2026年真实办公场景实测，精选6款主流企业网盘，聚焦操作便捷度、协作流畅性、合规门槛等“好用”核心指标，并通过下方对比表格，帮你快速找到适配团队的最优解。</p><p><strong>主流企业网盘核心指标速览：</strong></p><table><thead><tr><th align="left">产品名称</th><th align="left">核心优势</th><th align="left">部署/使用门槛</th><th align="left">同步效率</th><th align="left">推荐指数</th></tr></thead><tbody><tr><td align="left"><strong>坚果云</strong></td><td align="left"><strong>智能增量同步</strong>，极速无感，合规性极高</td><td align="left">零门槛，开箱即用</td><td align="left">⭐⭐⭐⭐⭐</td><td align="left">⭐⭐⭐⭐⭐</td></tr><tr><td align="left">Zoho WorkDrive</td><td align="left">AI辅助办公，生态整合强</td><td align="left">一定门槛，适合外企</td><td align="left">⭐⭐⭐</td><td align="left">⭐⭐⭐⭐</td></tr><tr><td align="left">OneDrive</td><td align="left">微软生态深度绑定</td><td align="left">依赖Office环境</td><td align="left">⭐⭐⭐</td><td align="left">⭐⭐⭐⭐</td></tr><tr><td align="left">百度企业网盘</td><td align="left">大文件传输，搜索技术</td><td align="left">低门槛，体验类似个人盘</td><td align="left">⭐⭐⭐</td><td align="left">⭐⭐⭐</td></tr><tr><td align="left">联想Filez</td><td align="left">全球加速，适合跨国</td><td align="left">部署成本较高</td><td align="left">⭐⭐⭐⭐</td><td align="left">⭐⭐⭐⭐</td></tr><tr><td align="left">优米云盘</td><td align="left">仿Windows界面，上手快</td><td align="left">需适应轻量级功能</td><td align="left">⭐⭐⭐</td><td align="left">⭐⭐⭐</td></tr></tbody></table><hr/><h4>一、坚果云：国民级“无感”协作与安全合规标杆</h4><p>坚果云官网：<a href="https://link.segmentfault.com/?enc=SXw7uG8lqEgBWFVFJ3FFJw%3D%3D.CNYYoQ1kUR3O%2FVBcPWmBXDV0B2uu1ZPNhK%2Brx7KTEIT9uC3IvUm4hJopnrYO090VcbW7rhLK9WYO19aV2bzuWg%3D%3D" rel="nofollow" target="_blank">https://www.jianguoyun.com/s/campaign/cpclanding/main?sch=AIsf</a><br/>作为国内最早深耕云存储领域的品牌之一，坚果云自2011年上线至今已稳定运营超过<strong>15年</strong>，服务了包括<strong>中国石油</strong>、<strong>中银证券</strong>、<strong>清华大学</strong>在内的超10万家知名企事业单位。其核心优势在于将“易用性”做到了极致，通过“无感同步”让员工在不知不觉中完成数据的备份与流转。</p><p>在技术壁垒方面，坚果云独有的<strong>智能增量同步</strong>技术是提升效率的关键。与普通网盘每次修改都要重新上传整个文件不同，坚果云仅上传文件修改变动的部分，这在处理GB级设计图纸或数据库文件时，同步速度可提升10倍以上。同时，其支持超100种格式的在线预览，无需安装专业软件即可查看CAD、PS等专业文件，极大地降低了协作门槛。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047609944" alt="image" title="image"/></p><p>在企业最关注的安全合规层面，坚果云拥有<strong>公安部信息系统安全等级保护三级备案</strong>（非银行机构最高级别认证）及ISO27001等多重权威认证。配合AES-256金融级加密算法和细粒度的权限管控，无论是数据防勒索还是离职员工文件交接，都能做到万无一失。“无论是高效协作团队、注重数据安全企业，还是灵活文件管理个人，坚果云都是理想解决方案。”<br/>现在坚果云团队版还有免费试用20天：<a href="https://link.segmentfault.com/?enc=%2FohJBDKB8kqvpYNmnFwkDw%3D%3D.GSlcZBRI2nwHIUVBRtewdiFtiTJY1NOWpuQ%2FMu3ODznHu89%2Fw4SWvVOit4kDXeRgz8Axbut15xSuro0WUR%2BuDg%3D%3D" rel="nofollow" target="_blank">坚果云团队版官网</a></p><h4>二、Zoho WorkDrive：AI加持的跨境协作小助手</h4><p>Zoho WorkDrive的“好用”体现在“用AI省时间”，尤其适合跨地域、多语言协作的团队。它的AI助手Zia堪称高效协作神器，支持会议音视频自动转录为文字纪要，长篇项目文档一键生成摘要。面对跨国协作，它能实现多语言实时互译，文件分享时自动同步翻译内容，消除了语言障碍。操作上，它与Zoho CRM及Google Workspace等工具整合紧密，项目资料自动同步到协作空间。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047609945" alt="image" title="image" loading="lazy"/></p><ul><li><strong>局限性</strong>：由于服务器布局原因，在国内某些复杂网络环境下，访问速度和稳定性可能不如本土深耕的云服务商，且深度功能需要一定的学习成本。</li></ul><h4>三、OneDrive：微软生态用户的衔接之选</h4><p>对深度使用Office 365的企业来说，OneDrive的“好用”就在于“无感知融入日常办公”。它与Word、Excel、PPT深度绑定，打开文档就能直接在线编辑，修改内容实时同步，多人协作时历史版本也能一键回溯，避免了“最终版”文件满天飞的尴尬。多端同步方面，Windows与移动端切换流畅，适合习惯微软生态的团队。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047609946" alt="image" title="image" loading="lazy"/></p><ul><li><strong>局限性</strong>：在国内网络环境下，OneDrive的同步稳定性偶尔会出现波动，且对于非Office格式文件的预览和协作支持相对薄弱。</li></ul><h4>四、百度企业网盘：基于搜索技术的存储工具</h4><p>百度企业网盘的优势聚焦在“本土化”与“检索能力”。依托百度核心搜索技术，它不仅能检索文件名，甚至能识别图片中的文字（OCR），哪怕记不清文件名也能通过关键词找到目标。在大文件分发场景下，其传输体验较为流畅，对外分享支持设置有效期和密码，界面设计沿袭个人网盘逻辑，员工上手快。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047609947" alt="百度网盘" title="百度网盘" loading="lazy"/></p><ul><li><strong>局限性</strong>：功能设计偏向于“存储”和“分发”，在多人高频实时编辑、精细化权限管理以及<strong>文件历史版本</strong>的颗粒度控制上，相较于专业SaaS协作网盘略显单薄。</li></ul><h4>五、联想Filez：专注大型工程的传输专家</h4><p>联想Filez重点解决跨地域传输痛点，适合有海内外分支机构的大型企业。其搭建的全球加速网络，在传输百GB级的工程图纸、视频素材时表现优异。操作上，支持按部门、项目设置复杂的角色权限，批量分配功能减轻了IT管理压力。同时，其文件版本控制清晰，适合制造业或工程行业的严谨需求。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047609948" alt="联想云盘" title="联想云盘" loading="lazy"/></p><ul><li><strong>局限性</strong>：系统架构较为庞大，主要面向大型企业定制，对于追求轻量化部署、预算有限的中小团队来说，部署门槛和维护成本相对较高。</li></ul><h4>六、优米云盘：复刻Windows习惯的轻量工具</h4><p>优米云盘的特点是“零学习成本”，适合从本地存储过渡的团队。其客户端完全复刻Windows资源管理器，文件路径和操作逻辑与本地硬盘一致，员工无需改变习惯。核心功能覆盖了基础的权限设置和拖拽上传，支持多种格式预览，部署流程相对简单。</p><ul><li><strong>局限性</strong>：作为一款轻量级工具，其在多端同步的实时性（特别是移动端体验）以及生态应用的丰富度上，与头部产品相比仍有差距，更适合纯内网环境的单一场景。</li></ul><hr/><h3>总结：如何选择最“好用”的企业网盘？</h3><p>2026年的企业网盘市场，产品形态各异。如果您的团队追求极致的性价比与操作体验，希望在保障<strong>公安部信息系统安全等级保护三级备案</strong>级别的安全前提下，实现全平台<strong>智能增量同步</strong>的高效协作，<strong>坚果云</strong>无疑是综合评分最高的首选。</p>]]></description></item><item>    <title><![CDATA[Python图像处理利器：Pillow (PIL)入门指南 小小张说故事 ]]></title>    <link>https://segmentfault.com/a/1190000047609961</link>    <guid>https://segmentfault.com/a/1190000047609961</guid>    <pubDate>2026-02-13 17:02:37</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>目录</h2><ol><li>库的概览与核心价值</li><li>环境搭建与"Hello, World"</li><li>核心概念解析</li><li>实战演练：批量图片处理工具</li><li>最佳实践与常见陷阱</li><li>进阶指引</li></ol><h2>1. 库的概览与核心价值</h2><p>想象一下,你在开发一个电商平台,需要处理成千上万张不同尺寸、格式的商品图片——有的来自用户的随意上传,有的需要批量添加水印,有的还要转换为适合移动端的格式。如果没有一个强大的图像处理工具,这就像试图用剪刀和胶水来完成一个现代印刷厂的工作,既低效又不可靠。</p><p><code>Pillow</code>(又称PIL,Python Imaging Library的友好分支)正是为解决Python中的图像处理问题而生的工具。它为Python解释器添加了强大的图像处理能力,使开发者能够轻松地打开、操作、保存各种格式的图像文件。Pillow在Python生态中占据着独特且不可替代的地位——它是Python图像处理的事实标准库,就像NumPy之于科学计算,Django之于Web开发。</p><p>Pillow的核心价值在于其简洁的API设计与强大的功能集的完美结合。它支持30多种图像格式(包括JPEG、PNG、GIF、BMP、TIFF、WebP等),提供了丰富的图像操作功能,从基础的缩放、裁剪、旋转,到高级的滤镜应用、色彩调整、像素级操作,几乎涵盖了日常开发中99%的图像处理需求。更重要的是,Pillow的设计哲学是"简单优先",用几行代码就能完成复杂的图像变换,这使得它成为了图像处理领域的瑞士军刀。</p><p>无论是Web后端的图像服务、数据科学中的图像预处理、还是桌面应用的图像编辑功能,Pillow都能提供坚实的底层支撑。它与NumPy、OpenCV、TensorFlow等深度学习框架的无缝集成,更是让它成为从入门级图像任务到AI视觉算法的完整解决方案链中不可或缺的一环。</p><h2>2. 环境搭建与"Hello, World"</h2><h3>安装说明</h3><p>Pillow的安装非常简单,推荐使用pip进行安装。在命令行中执行以下命令即可:</p><pre><code class="bash"># 使用pip安装最新版本
pip install Pillow

# 或者使用python3 -m pip确保使用正确的Python环境
python3 -m pip install --upgrade Pillow</code></pre><p><strong>注意事项</strong>:</p><ul><li>Pillow和旧的PIL库不能共存,如果之前安装过PIL,请先卸载</li><li>Pillow ≥ 1.0版本不再支持<code>import Image</code>,必须使用<code>from PIL import Image</code></li><li>对于Linux用户,某些发行版可能需要先安装系统级的依赖库(如libjpeg、zlib)</li></ul><p><strong>可选依赖</strong>:<br/>如果需要处理XMP元数据,可以额外安装:</p><pre><code class="bash">pip install defusedxml olefile</code></pre><h3>Hello, World示例</h3><p>让我们从一个最简单的示例开始,学习如何使用Pillow打开一张图片、获取基本信息并保存为新格式:</p><pre><code class="python">from PIL import Image

# 1. 打开一张图片(假设当前目录下有test.jpg)
img = Image.open('test.jpg')

# 2. 获取图片基本信息
print(f"图片格式: {img.format}")        # 输出: JPEG
print(f"图片尺寸: {img.size}")          # 输出: (1920, 1080) - (宽度, 高度)
print(f"图片模式: {img.mode}")          # 输出: RGB - 颜色模式
print(f"文件名: {img.filename}")        # 输出: test.jpg

# 3. 显示图片(使用系统默认图片查看器)
img.show()

# 4. 保存为PNG格式(自动根据扩展名确定格式)
img.save('test.png')

# 5. 保存为压缩后的JPEG(quality参数控制质量,1-95)
img.save('test_compressed.jpg', quality=70, optimize=True)</code></pre><h3>逐行解释</h3><ul><li><code>from PIL import Image</code>: 从Pillow库中导入Image类,这是最核心的类,用于表示和操作图像对象。注意包名是<code>PIL</code>而不是<code>Pillow</code>,这是历史原因。</li><li><code>img = Image.open('test.jpg')</code>: <code>open()</code>函数是工厂方法,用于从文件中加载图像并返回Image对象。它会根据文件内容自动识别格式,而不是依赖文件扩展名。返回的<code>img</code>对象包含了图像的所有信息和操作方法。</li><li><code>img.format</code>: 属性,返回图像的原始格式(如JPEG、PNG等)。如果图像不是从文件加载的(如新建的图像),这个值为None。</li><li><code>img.size</code>: 属性,返回一个包含(宽度,高度)的元组,单位是像素。这是图像的基本维度信息。</li><li><code>img.mode</code>: 属性,返回图像的颜色模式,如RGB(真彩色)、L(灰度)、RGBA(带透明通道的RGB)、CMYK(印刷模式)等。</li><li><code>img.show()</code>: 方法,使用操作系统的默认图片查看器显示图像。这个方法会先将图像保存为临时文件,然后调用系统程序打开它,主要用于调试和快速预览。</li><li><code>img.save('test.png')</code>: 方法,将图像保存到文件。Pillow会根据文件扩展名自动确定输出格式(PNG)。这个方法支持各种格式特定的参数,比如JPEG的<code>quality</code>(质量)、<code>optimize</code>(优化)等。</li><li><code>img.save('test_compressed.jpg', quality=70, optimize=True)</code>: 保存时指定格式参数。<code>quality=70</code>表示压缩质量为70(范围1-95,数值越小压缩率越高但质量越差),<code>optimize=True</code>启用优化算法进一步减小文件体积。</li></ul><h3>运行结果</h3><p>运行上述代码后,你将在终端看到图片的基本信息,同时会:</p><ol><li>弹出一个图片查看器窗口显示原图</li><li>在当前目录下生成<code>test.png</code>(无损PNG格式)</li><li>生成<code>test_compressed.jpg</code>(压缩后的JPEG,文件体积会比原JPEG更小)</li></ol><p><strong>常见安装失败及解决</strong>:</p><ul><li>如果提示"ModuleNotFoundError: No module named 'PIL'",说明安装失败,重新运行<code>pip install Pillow</code></li><li>Windows用户如果遇到编译错误,尝试使用预编译的wheel包:<code>pip install --only-binary=:all: Pillow</code></li><li>Linux用户如果遇到某些格式不支持,需要安装系统依赖(如Ubuntu:<code>sudo apt-get install libjpeg-dev zlib1g-dev</code>)</li></ul><h2>3. 核心概念解析</h2><p>Pillow的核心设计围绕几个关键概念展开,理解这些概念是熟练使用Pillow的基础。本节重点介绍Image对象、图像模式和坐标系统这三大核心概念。</p><h3>3.1 Image对象</h3><p><code>Image</code>类是Pillow中最核心的对象,代表一个图像实例。你可以通过多种方式创建Image对象:</p><pre><code class="python">from PIL import Image

# 方式1: 从文件加载
img1 = Image.open('photo.jpg')

# 方式2: 创建空白图像
# 参数: 颜色模式, 尺寸(宽,高), 背景色(可选)
img2 = Image.new('RGB', (800, 600), color='white')

# 方式3: 从其他图像操作得到
img3 = img1.resize((400, 300))

# 方式4: 从颜色数据创建
img4 = Image.new('L', (100, 100), color=128)  # 创建灰色图像</code></pre><p>Image对象是不可变的——大多数操作方法(如<code>resize()</code>, <code>rotate()</code>)都会返回新的Image对象,而不会修改原对象。这种设计符合函数式编程的理念,让代码更安全、可预测。</p><h3>3.2 图像模式(Mode)</h3><p>图像模式定义了像素的存储方式和颜色表示。Pillow支持多种模式,最常用的包括:</p><table><thead><tr><th>模式</th><th>描述</th><th>典型用途</th></tr></thead><tbody><tr><td>1</td><td>1位像素,黑白</td><td>二值图像、文字图像</td></tr><tr><td>L</td><td>8位像素,灰度</td><td>灰度照片、医学图像</td></tr><tr><td>P</td><td>8位像素,使用调色板</td><td>索引颜色图像(GIF)</td></tr><tr><td>RGB</td><td>3x8位像素,真彩色</td><td>普通照片、屏幕显示</td></tr><tr><td>RGBA</td><td>4x8位像素,带透明通道</td><td>需要透明效果的图像</td></tr><tr><td>CMYK</td><td>4x8位像素,分色</td><td>印刷品、出版物</td></tr><tr><td>LAB</td><td>3x8位像素,LAB颜色空间</td><td>色彩科学应用</td></tr></tbody></table><p><strong>模式转换示例</strong>:</p><pre><code class="python">from PIL import Image

img_rgb = Image.open('photo.jpg')  # 默认是RGB模式

# 转换为灰度图
img_gray = img_rgb.convert('L')

# 转换为带透明通道的RGB
img_rgba = img_rgb.convert('RGBA')

# 转换为CMYK(印刷用)
img_cmyk = img_rgb.convert('CMYK')

# 查看转换前后
print(f"原始: {img_rgb.mode} -&gt; 转换后: {img_rgba.mode}")</code></pre><p>理解图像模式非常重要,因为不同的操作对模式有特定要求。例如,<code>ImageFilter</code>模块的某些滤镜只适用于RGB和L模式图像。</p><h3>3.3 坐标系统</h3><p>Pillow使用笛卡尔坐标系统,原点(0,0)位于图像的左上角:</p><ul><li>X轴向右为正</li><li>Y轴向下为正</li><li>坐标值以像素为单位</li></ul><p><strong>关键点</strong>:</p><ul><li><code>img.size</code>返回(width, height)元组</li><li><code>img.crop(box)</code>中的box是4元组:(left, upper, right, lower)</li><li>注意:坐标是像素"之间"的位置,所以crop(0,0,100,100)裁剪出的区域正好是100x100像素</li></ul><p><strong>坐标系统可视化</strong>:</p><pre style="display:none;"><code class="mermaid">graph TD
    A[图像坐标系统] --&gt; B[原点 0,0 - 左上角]
    A --&gt; C[X轴 - 向右为正]
    A --&gt; D[Y轴 - 向下为正]
    A --&gt; E[size - width, height]
    E --&gt; F[width - X轴最大值]
    E --&gt; G[height - Y轴最大值]
    A --&gt; H[crop box - left, upper, right, lower]
    H --&gt; I[left - 左边界x坐标]
    H --&gt; J[upper - 上边界y坐标]
    H --&gt; K[right - 右边界x坐标]
    H --&gt; L[lower - 下边界y坐标]</code></pre><h3>3.4 核心概念关系图</h3><p>Image对象、模式和坐标系统这三个核心概念相互关联,共同构成了Pillow图像处理的基础架构:</p><pre style="display:none;"><code class="mermaid">graph LR
    A[Image对象] --&gt; B[图像模式 mode]
    A --&gt; C[坐标系统]
    A --&gt; D[像素数据]
    
    B --&gt; E[RGB]
    B --&gt; F[L - 灰度]
    B --&gt; G[RGBA - 透明]
    B --&gt; H[CMYK - 印刷]
    
    C --&gt; I[原点: 左上角0,0]
    C --&gt; J[尺寸: width x height]
    C --&gt; K[裁剪: box - left,upper,right,lower]
    
    D --&gt; L[getpixel x,y]
    D --&gt; M[putpixel x,y,value]
    D --&gt; N[split - 分离通道]
    D --&gt; O[merge - 合并通道]
    
    style A fill:#e1f5ff
    style B fill:#fff4e1
    style C fill:#f0e1ff
    style D fill:#e1ffe1</code></pre><h3>3.5 其他重要概念</h3><p><strong>图像通道(Bands)</strong>:</p><ul><li>RGB图像有3个通道:R(红)、G(绿)、B(蓝)</li><li>RGBA图像有4个通道:R、G、B、A(透明度)</li><li>可以使用<code>split()</code>方法分离通道,<code>merge()</code>方法合并通道</li></ul><p><strong>懒加载(Lazy Loading)</strong>:</p><ul><li><code>Image.open()</code>不会立即加载整个图像数据</li><li>只有在访问像素数据或执行操作时才会真正加载</li><li>这使得打开大文件的速度很快,不会立即消耗大量内存</li></ul><p><strong>过滤器(Filters)</strong>:</p><ul><li>Pillow提供内置滤镜(模糊、锐化、边缘检测等)</li><li>使用<code>img.filter(ImageFilter.BLUR)</code>等应用滤镜</li><li>自定义滤镜需要理解卷积操作</li></ul><p>掌握这些核心概念后,你就能理解Pillow的大部分操作逻辑,并能够高效地解决各种图像处理问题。</p><h2>4. 实战演练：批量图片处理工具</h2><p>让我们通过一个实际项目来综合运用Pillow的核心功能。假设你需要开发一个电商平台的图片处理工具,需要批量完成以下任务:</p><ol><li>统一调整商品图片尺寸</li><li>添加水印</li><li>优化压缩</li><li>生成缩略图</li><li>生成统计报告</li></ol><h3>需求分析</h3><p>电商平台的商品图片来源多样,尺寸不一,存储格式各异。为了提升用户体验和节省带宽,我们需要将所有图片处理成统一的标准:</p><ul><li>主图:800x800像素,JPEG格式,质量85%</li><li>缩略图:200x200像素,保持比例</li><li>添加半透明的品牌水印</li><li>生成处理报告</li></ul><h3>方案设计</h3><p>我们将使用以下Pillow功能:</p><ul><li><code>Image.open()</code> - 读取原始图片</li><li><code>Image.resize()</code> - 调整尺寸</li><li><code>Image.thumbnail()</code> - 生成缩略图(保持比例)</li><li><code>ImageDraw</code>和<code>ImageFont</code> - 绘制水印</li><li><code>Image.save()</code> - 保存优化后的图片</li><li><code>os</code>模块 - 批量文件处理</li></ul><h3>代码实现</h3><pre><code class="python">import os
from PIL import Image, ImageDraw, ImageFont
from datetime import datetime

class ImageProcessor:
    """电商图片批量处理工具"""
    
    def __init__(self, input_dir, output_dir, watermark_text="MyBrand"):
        self.input_dir = input_dir
        self.output_dir = output_dir
        self.watermark_text = watermark_text
        self.main_size = (800, 800)      # 主图尺寸
        self.thumb_size = (200, 200)     # 缩略图尺寸
        self.report = []                  # 处理报告
        
        # 创建输出目录
        os.makedirs(output_dir, exist_ok=True)
        os.makedirs(os.path.join(output_dir, 'main'), exist_ok=True)
        os.makedirs(os.path.join(output_dir, 'thumb'), exist_ok=True)
    
    def add_watermark(self, img):
        """添加半透明水印"""
        # 确保图片有alpha通道
        if img.mode != 'RGBA':
            img = img.convert('RGBA')
        
        # 创建水印图层
        watermark = Image.new('RGBA', img.size, (0, 0, 0, 0))
        draw = ImageDraw.Draw(watermark)
        
        # 尝试加载字体,失败则使用默认字体
        try:
            font = ImageFont.truetype("arial.ttf", 40)
        except:
            font = ImageFont.load_default()
        
        # 计算水印位置(右下角)
        text_bbox = draw.textbbox((0, 0), self.watermark_text, font=font)
        text_width = text_bbox[2] - text_bbox[0]
        text_height = text_bbox[3] - text_bbox[1]
        
        x = img.width - text_width - 20
        y = img.height - text_height - 20
        
        # 绘制半透明文字
        draw.text((x, y), self.watermark_text, fill=(255, 255, 255, 128), font=font)
        
        # 合并水印到原图
        watermarked = Image.alpha_composite(img, watermark)
        return watermarked
    
    def process_image(self, filename):
        """处理单张图片"""
        input_path = os.path.join(self.input_dir, filename)
        
        try:
            # 1. 读取原始图片
            img = Image.open(input_path)
            original_format = img.format
            original_size = img.size
            
            # 2. 调整主图尺寸(居中裁剪到正方形)
            # 先缩放使短边达到目标尺寸
            ratio = max(self.main_size[0] / img.width, self.main_size[1] / img.height)
            new_size = (int(img.width * ratio), int(img.height * ratio))
            img_resized = img.resize(new_size, Image.Resampling.LANCZOS)
            
            # 居中裁剪到目标尺寸
            left = (new_size[0] - self.main_size[0]) // 2
            top = (new_size[1] - self.main_size[1]) // 2
            img_cropped = img_resized.crop((
                left, top,
                left + self.main_size[0],
                top + self.main_size[1]
            ))
            
            # 3. 添加水印
            img_watermarked = self.add_watermark(img_cropped)
            
            # 4. 保存主图(JPEG格式,优化压缩)
            main_filename = os.path.splitext(filename)[0] + '.jpg'
            main_path = os.path.join(self.output_dir, 'main', main_filename)
            img_watermarked.save(main_path, 'JPEG', quality=85, optimize=True)
            
            # 5. 生成缩略图(保持比例)
            img_thumb = img.copy()
            img_thumb.thumbnail(self.thumb_size, Image.Resampling.LANCZOS)
            thumb_path = os.path.join(self.output_dir, 'thumb', main_filename)
            img_thumb.save(thumb_path, 'JPEG', quality=75)
            
            # 6. 记录处理信息
            main_filesize = os.path.getsize(main_path) / 1024  # KB
            thumb_filesize = os.path.getsize(thumb_path) / 1024
            
            self.report.append({
                'filename': filename,
                'original_format': original_format,
                'original_size': original_size,
                'main_size': self.main_size,
                'main_filesize': round(main_filesize, 2),
                'thumb_size': img_thumb.size,
                'thumb_filesize': round(thumb_filesize, 2),
                'status': 'success'
            })
            
            return True
            
        except Exception as e:
            self.report.append({
                'filename': filename,
                'error': str(e),
                'status': 'failed'
            })
            return False
    
    def process_all(self):
        """批量处理所有图片"""
        # 支持的图片格式
        supported_formats = ('.jpg', '.jpeg', '.png', '.bmp', '.gif')
        
        # 获取所有图片文件
        image_files = [
            f for f in os.listdir(self.input_dir)
            if f.lower().endswith(supported_formats)
        ]
        
        if not image_files:
            print(f"错误: 在 {self.input_dir} 中没有找到支持的图片格式")
            return
        
        print(f"开始处理 {len(image_files)} 张图片...")
        print("-" * 60)
        
        # 处理每张图片
        success_count = 0
        for i, filename in enumerate(image_files, 1):
            print(f"[{i}/{len(image_files)}] 处理: {filename}", end=" ")
            if self.process_image(filename):
                print("✓")
                success_count += 1
            else:
                print("✗")
        
        print("-" * 60)
        print(f"处理完成! 成功: {success_count}/{len(image_files)}")
        self.generate_report()
    
    def generate_report(self):
        """生成处理报告"""
        print("\n" + "=" * 60)
        print("处理报告")
        print("=" * 60)
        
        # 统计信息
        success = [r for r in self.report if r['status'] == 'success']
        failed = [r for r in self.report if r['status'] == 'failed']
        
        if success:
            total_main_size = sum(r['main_filesize'] for r in success)
            total_thumb_size = sum(r['thumb_filesize'] for r in success)
            avg_main_size = total_main_size / len(success)
            avg_thumb_size = total_thumb_size / len(success)
            
            print(f"\n成功处理: {len(success)} 张")
            print(f"主图总大小: {total_main_size:.2f} KB (平均 {avg_main_size:.2f} KB)")
            print(f"缩略图总大小: {total_thumb_size:.2f} KB (平均 {avg_thumb_size:.2f} KB)")
            print(f"总输出大小: {total_main_size + total_thumb_size:.2f} KB")
        
        if failed:
            print(f"\n失败: {len(failed)} 张")
            for item in failed:
                print(f"  - {item['filename']}: {item.get('error', '未知错误')}")
        
        # 详细列表(前10张)
        if success:
            print("\n处理详情(前10张):")
            print("-" * 60)
            print(f"{'文件名':&lt;20} {'原始尺寸':&lt;12} {'主图大小(KB)':&lt;12} {'缩略图大小(KB)':&lt;14}")
            print("-" * 60)
            for item in success[:10]:
                print(f"{item['filename']:&lt;20} {str(item['original_size']):&lt;12} "
                      f"{item['main_filesize']:&lt;12.2f} {item['thumb_filesize']:&lt;14.2f}")
        
        print("\n输出目录:")
        print(f"  主图: {os.path.join(self.output_dir, 'main')}")
        print(f"  缩略图: {os.path.join(self.output_dir, 'thumb')}")


# 使用示例
if __name__ == "__main__":
    # 创建测试环境(如果需要测试)
    # 假设有一个input_images目录包含待处理图片
    
    processor = ImageProcessor(
        input_dir="input_images",      # 输入目录
        output_dir="output_images",    # 输出目录
        watermark_text="MyShop©"       # 水印文字
    )
    
    # 开始批量处理
    processor.process_all()</code></pre><h3>运行说明</h3><ol><li><p><strong>准备工作</strong>:</p><ul><li>在当前目录下创建<code>input_images</code>文件夹</li><li>放入一些待处理的图片(支持JPG、PNG、BMP、GIF格式)</li></ul></li><li><p><strong>运行程序</strong>:</p><pre><code class="bash">python image_processor.py</code></pre></li><li><p><strong>输出结果</strong>:</p><ul><li><p>程序会在<code>output_images</code>目录下生成两个子目录:</p><ul><li><code>main/</code>: 存放800x800的主图,带水印</li><li><code>thumb/</code>: 存放200x200的缩略图</li></ul></li><li>控制台输出详细的处理报告</li></ul></li></ol><h3>结果展示</h3><p>程序运行后,你将看到类似的输出:</p><pre><code>开始处理 15 张图片...
------------------------------------------------------------
[1/15] 处理: product1.jpg ✓
[2/15] 处理: product2.png ✓
[3/15] 处理: product3.jpg ✓
...
------------------------------------------------------------
处理完成! 成功: 14/15

============================================================
处理报告
============================================================

成功处理: 14 张
主图总大小: 845.32 KB (平均 60.38 KB)
缩略图总大小: 128.76 KB (平均 9.20 KB)
总输出大小: 974.08 KB

处理详情(前10张):
------------------------------------------------------------
文件名              原始尺寸      主图大小(KB)   缩略图大小(KB)  
------------------------------------------------------------
product1.jpg       (1920, 1080)  65.23          9.45           
product2.png       (1200, 800)   58.76          8.92           
product3.jpg       (800, 800)    52.34          8.15           
...

输出目录:
  主图: output_images/main
  缩略图: output_images/thumb</code></pre><p>这个综合项目展示了Pillow的多个核心功能:</p><ul><li><strong>文件I/O</strong>: <code>open()</code>和<code>save()</code>处理多种格式</li><li><strong>几何变换</strong>: <code>resize()</code>和<code>crop()</code>调整尺寸和裁剪</li><li><strong>图像合成</strong>: <code>Image.alpha_composite()</code>添加透明水印</li><li><strong>绘图功能</strong>: <code>ImageDraw</code>和<code>ImageFont</code>绘制文字</li><li><strong>缩略图生成</strong>: <code>thumbnail()</code>保持比例缩放</li><li><strong>批量处理</strong>: 结合<code>os</code>模块实现自动化</li></ul><p>通过这个项目,你可以看到Pillow如何优雅地将复杂的图像处理任务简化为清晰、可维护的代码。</p><h2>5. 最佳实践与常见陷阱</h2><p>在使用Pillow进行图像处理时,掌握一些最佳实践和避免常见陷阱可以让你的代码更高效、更可靠。</p><h3>5.1 常见错误及规避方法</h3><h4>错误1:忘记关闭文件或内存泄漏</h4><pre><code class="python"># ❌ 错误做法 - 文件未关闭
for filename in os.listdir('images'):
    img = Image.open(os.path.join('images', filename))
    process(img)  # 处理图像
    # 文件句柄未关闭,可能导致资源泄漏

# ✅ 正确做法 - 使用上下文管理器
for filename in os.listdir('images'):
    filepath = os.path.join('images', filename)
    with Image.open(filepath) as img:
        process(img)  # 自动关闭文件</code></pre><p><strong>为什么</strong>: 虽然<code>Image.open()</code>的文件句柄会在Image对象被垃圾回收时自动关闭,但在批量处理大文件时,最好显式使用<code>with</code>语句或调用<code>img.close()</code>来及时释放资源。</p><h4>错误2:直接修改原图对象</h4><pre><code class="python"># ❌ 错误做法 - 可能意外修改原图
img = Image.open('original.jpg')
img.resize((400, 300))  # 返回新对象,但未赋值!
img.save('resized.jpg')  # 保存的还是原图

# ✅ 正确做法 - 赋值返回的新对象
img = Image.open('original.jpg')
img_resized = img.resize((400, 300))
img_resized.save('resized.jpg')</code></pre><p><strong>为什么</strong>: Pillow的大部分操作方法(如<code>resize()</code>, <code>rotate()</code>, <code>crop()</code>)都返回新的Image对象,而不是原地修改。如果不赋值,操作就无效了。</p><h4>错误3:忽略图像模式不匹配</h4><pre><code class="python"># ❌ 错误做法 - 直接粘贴不同模式的图片
img_rgb = Image.new('RGB', (400, 300), 'red')
img_rgba = Image.new('RGBA', (100, 100), (0, 0, 255, 128))
img_rgb.paste(img_rgba, (50, 50))  # 可能出错或效果不符合预期

# ✅ 正确做法 - 先转换模式
img_rgb = Image.new('RGB', (400, 300), 'red')
img_rgba = Image.new('RGBA', (100, 100), (0, 0, 255, 128))

# 方法1: 将RGBA转RGB
img_rgb_to_paste = img_rgba.convert('RGB')
img_rgb.paste(img_rgb_to_paste, (50, 50))

# 方法2: 使用蒙版保持透明度
img_rgb.paste(img_rgba, (50, 50), img_rgba.split()[3])  # 使用alpha通道作为蒙版</code></pre><p><strong>为什么</strong>: 不同模式的图像不能直接粘贴。要么转换模式,要么使用蒙版来处理透明通道。</p><h3>5.2 最佳实践</h3><h4>实践1:选择合适的重采样算法</h4><pre><code class="python"># 缩小图像 - 使用LANCZOS
small_img = large_img.resize((400, 300), Image.Resampling.LANCZOS)

# 放大图像 - 使用BICUBIC
large_img = small_img.resize((800, 600), Image.Resampling.BICUBIC)

# 快速处理(质量要求不高时) - 使用NEAREST
thumbnail = img.resize((100, 100), Image.Resampling.NEAREST)</code></pre><p><strong>为什么</strong>: 不同的重采样算法在质量和速度上有差异:</p><ul><li><code>LANCZOS</code>: 最佳质量,适合缩小图像</li><li><code>BICUBIC</code>: 平衡,适合放大图像</li><li><code>NEAREST</code>: 最快,但会产生锯齿</li></ul><h4>实践2:优化JPEG保存质量</h4><pre><code class="python"># 网页用图片 - 平衡质量和大小
img.save('web.jpg', 'JPEG', quality=85, optimize=True)

# 存档图片 - 最高质量
img.save('archive.jpg', 'JPEG', quality=95, progressive=True)

# 缩略图 - 更小文件
img.save('thumb.jpg', 'JPEG', quality=70, optimize=True)</code></pre><p><strong>为什么</strong>:</p><ul><li><code>quality</code>: 1-95,值越大质量越好但文件越大</li><li><code>optimize=True</code>: 启用额外优化,减小文件体积</li><li><code>progressive=True</code>: 渐进式JPEG,加载时先显示低质量预览</li></ul><h4>实践3:处理大图像时的内存优化</h4><pre><code class="python"># ❌ 错误做法 - 加载超大图像到内存
huge_img = Image.open('huge.tif')  # 可能导致内存溢出

# ✅ 正确做法 - 使用懒加载和分块处理
# Pillow默认使用懒加载,只有在需要时才读取像素
img = Image.open('huge.tif')
print(img.size)  # 快速获取尺寸,不加载完整图像

# 分块处理大图像
def process_in_chunks(img_path, chunk_size=1000):
    img = Image.open(img_path)
    width, height = img.size
    
    for y in range(0, height, chunk_size):
        for x in range(0, width, chunk_size):
            box = (x, y, min(x+chunk_size, width), min(y+chunk_size, height))
            chunk = img.crop(box)
            process_chunk(chunk)</code></pre><p><strong>为什么</strong>: 处理大图像(如5000x5000以上的TIFF)时,一次性加载到内存可能超出可用内存。利用Pillow的懒加载特性和分块处理可以有效降低内存使用。</p><h4>实践4:批量处理时使用多线程</h4><pre><code class="python">from concurrent.futures import ThreadPoolExecutor

def process_single_image(filepath):
    with Image.open(filepath) as img:
        # 处理图像
        processed = img.resize((800, 600))
        processed.save(filepath.replace('.jpg', '_processed.jpg'))
        return filepath

# 多线程批量处理
def batch_process(image_dir, max_workers=4):
    filepaths = [
        os.path.join(image_dir, f) 
        for f in os.listdir(image_dir) 
        if f.endswith('.jpg')
    ]
    
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        results = list(executor.map(process_single_image, filepaths))
    
    return results</code></pre><p><strong>为什么</strong>: I/O密集型任务(如文件读写)和CPU密集型任务(如图像处理)可以并行化,显著提升批量处理速度。<code>ThreadPoolExecutor</code>提供了简洁的多线程接口。</p><h4>实践5:正确处理颜色空间转换</h4><pre><code class="python"># 显示用图片 - 转换为sRGB
img_display = img.convert('RGB')
img_display.save('display.jpg')

# 印刷用图片 - 转换为CMYK
img_print = img.convert('CMYK')
img_print.save('print.jpg')

# 处理用图片 - 先转换为LAB色彩空间
img_lab = img.convert('LAB')
# 在LAB空间进行亮度、对比度调整...
img_result = img_lab.convert('RGB')  # 转回RGB保存</code></pre><p><strong>为什么</strong>: 不同用途需要不同的颜色空间:</p><ul><li>RGB: 屏幕显示,网页</li><li>CMYK: 印刷品</li><li>LAB: 色彩科学,图像处理(亮度与色度分离)</li></ul><h3>5.3 注意事项</h3><ol><li><strong>DecompressionBombWarning</strong>: 打开非常大的图像时,Pillow会发出警告。如果确实需要处理,可以先<code>Image.MAX_IMAGE_PIXELS = None</code>关闭限制,但要小心内存溢出。</li><li><strong>文件扩展名不一定准确</strong>: <code>Image.open()</code>根据文件内容识别格式,而不是扩展名。所以<code>Image.open('photo.png')</code>可能实际打开的是JPEG文件。</li><li><strong>GIF动画处理</strong>: Pillow可以读取GIF动画,但只能保存单帧或创建新动画。处理多帧GIF需要遍历<code>seek()</code>方法。</li><li><strong>字体依赖</strong>: <code>ImageFont</code>使用系统字体,不同操作系统上可能不一致。打包字体文件到项目中可以确保跨平台一致性。</li><li><strong>透明度处理</strong>: PNG的透明度在转换为JPEG时会被丢弃,因为JPEG不支持透明通道。需要先用<code>convert('RGB')</code>去除alpha通道。</li></ol><p>掌握这些最佳实践和陷阱,你的Pillow代码将更加健壮、高效和专业。</p><h2>6. 进阶指引</h2><p>当你掌握了Pillow的基础功能后,还有更多高级特性和生态工具值得探索,这将极大扩展你的图像处理能力。</p><h3>6.1 高级功能</h3><h4>像素级操作与NumPy集成</h4><p>Pillow可以与NumPy无缝协作,这对科学计算和图像算法开发非常重要:</p><pre><code class="python">import numpy as np
from PIL import Image

# Pillow图像转NumPy数组
img = Image.open('photo.jpg')
arr = np.array(img)  # 形状: (height, width, channels)

# 使用NumPy进行批量像素操作
inverted_arr = 255 - arr  # 反转所有像素
arr[:,:,0] = 0  # 将红色通道设为0

# NumPy数组转回Pillow图像
img_processed = Image.fromarray(arr)
img_processed.save('numpy_processed.jpg')</code></pre><p>这种集成使得Pillow成为连接Python科学计算生态和图像处理的桥梁,你可以利用NumPy的向量化运算加速图像处理。</p><h4>自定义滤镜与图像算法</h4><p>Pillow支持创建自定义滤镜:</p><pre><code class="python">from PIL import ImageFilter

# 创建自定义锐化滤镜
class SharpenFilter(ImageFilter.BuiltinFilter):
    name = "Sharpen"
    
    # 3x3卷积核
    filterargs = (3, 3), (
        0, -1,  0,
       -1,  5, -1,
        0, -1,  0
    ), 1.0, 0

# 应用自定义滤镜
img = Image.open('blur.jpg')
sharpened = img.filter(SharpenFilter())
sharpened.save('sharpened.jpg')</code></pre><p>你可以设计各种卷积核实现边缘检测、浮雕、锐化等效果。</p><h4>高级图像合成</h4><pre><code class="python">from PIL import Image, ImageDraw, ImageFont

# 创建复杂的合成图像
bg = Image.new('RGBA', (800, 600), (240, 248, 255))
fg = Image.open('logo.png').convert('RGBA')

# 调整透明度
fg_alpha = fg.copy()
alpha = fg_alpha.split()[3]
alpha = alpha.point(lambda p: p * 0.7)  # 70%透明度
fg_alpha.putalpha(alpha)

# 居中粘贴
x = (bg.width - fg.width) // 2
y = (bg.height - fg.height) // 2
bg.paste(fg_alpha, (x, y), fg_alpha)

# 添加文字
draw = ImageDraw.Draw(bg)
draw.text((20, 20), "Professional Design", fill=(50, 50, 80))
bg.save('composite.png')</code></pre><h3>6.2 生态扩展</h3><p>Pillow是Python图像处理生态的核心组件,与其他库配合可以构建强大的应用:</p><table><thead><tr><th>库名</th><th>用途</th><th>配合场景</th></tr></thead><tbody><tr><td>OpenCV</td><td>计算机视觉</td><td>视频处理、人脸识别、目标检测</td></tr><tr><td>scikit-image</td><td>科学图像处理</td><td>医学图像、卫星图像分析</td></tr><tr><td>matplotlib</td><td>数据可视化</td><td>图像显示、数据可视化</td></tr><tr><td>TensorFlow/PyTorch</td><td>深度学习</td><td>图像分类、目标检测、图像生成</td></tr></tbody></table><p><strong>示例:与OpenCV互操作</strong>:</p><pre><code class="python">import cv2
from PIL import Image

# Pillow -&gt; OpenCV
img_pil = Image.open('photo.jpg')
img_cv = cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)

# OpenCV处理
gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)
edges = cv2.Canny(gray, 100, 200)

# OpenCV -&gt; Pillow
edges_pil = Image.fromarray(edges)
edges_pil.save('edges.jpg')</code></pre><h3>6.3 学习路径</h3><p><strong>初学者</strong>:</p><ol><li>熟练掌握<code>Image</code>类的基本方法</li><li>理解图像模式和坐标系统</li><li>实践常见的图像操作(缩放、裁剪、旋转)</li><li>参考:官方文档的Tutorial章节</li></ol><p><strong>进阶开发者</strong>:</p><ol><li>深入学习<code>ImageFilter</code>和<code>ImageEnhance</code></li><li>掌握<code>ImageDraw</code>和<code>ImageFont</code>绘图</li><li>学习批量处理和性能优化</li><li>参考:官方文档的Handbook章节</li></ol><p><strong>高级用户</strong>:</p><ol><li>探索与NumPy、OpenCV的集成</li><li>学习自定义滤镜和图像算法</li><li>研究源码理解底层实现</li><li>参考:GitHub上的Pillow源码和Issue讨论</li></ol><h3>6.4 学习资源</h3><ul><li><strong>官方文档</strong>: <a href="https://link.segmentfault.com/?enc=mYc7hMjCT2ibgagF1MmNJQ%3D%3D.kjUgMGdquvslvwI03lnoHn1ce2R7%2BvPWtMQ7Y4jABf0%3D" rel="nofollow" target="_blank">https://pillow.readthedocs.io/</a> (最权威的参考资料)</li><li><strong>GitHub仓库</strong>: <a href="https://link.segmentfault.com/?enc=fOgWjoAp95vkpOXzMVE02A%3D%3D.BotdnmG81KH05cOOrE%2BVIUINEsl5Upc4zxAzSYsgWsxQqxoYFRAvGK9%2F79%2BD3t2o" rel="nofollow" target="_blank">https://github.com/python-pillow/Pillow</a> (源码、Issue、PR)</li><li><strong>Stack Overflow</strong>: 搜索[pillow]标签获取社区解决方案</li><li><strong>Real Python</strong>: 有多篇Pillow教程,适合实战学习</li></ul><p>Pillow的世界远比这篇文档介绍的要广阔。随着你探索的深入,你会发现它不仅是图像处理的工具,更是连接创意与技术的桥梁。无论是构建专业图像处理应用,还是实现创意可视化,Pillow都能成为你可靠的伙伴。</p>]]></description></item><item>    <title><![CDATA[打造云端数字员工：OpenClaw 的 SAE 弹性托管实践 Serverless ]]></title>    <link>https://segmentfault.com/a/1190000047609981</link>    <guid>https://segmentfault.com/a/1190000047609981</guid>    <pubDate>2026-02-13 17:02:00</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>开源项目 OpenClaw（原名 Clawdbot / Moltbot）在 GitHub 上的星标数突破 14 万，揭示了 AI 技术栈的显著演进：人工智能正从被动生成的“对话框”，迈向具备自主规划能力的“智能代理（Autonomous Agents）”。OpenClaw 正是这一概念的工程化落地——它以轻量级 CLI 工具的形式，在用户设备上启动了一个本地网关服务，为 Agent 提供了一个安全、持久且可扩展的运行时环境。</p><p>在这个环境中，Agent 是决策核心，Skills 是能力边界。网关则作为运行时，负责协调交互、记忆与执行三大子系统。它依据 Skills 的标准化接口定义，将大模型的模糊意图映射为精准的系统指令，从而驱动整套智能体生命周期的运转：</p><ul><li>交互与感知：它通过插件化适配器统一接入 WhatsApp、Telegram，并利用 Webhook 对接钉钉、飞书等国内平台；同时通过心跳机制与 Cron 调度器，实现 7×24 小时的任务值守与主动触发。</li><li>决策与记忆：内置的 Memory 子系统利用本地向量数据库，为 Agent 提供了持久化的长短期记忆，使其能记住用户偏好与历史决策；配合 Skills 注册表，Agent 可按需加载外部工具（如邮件收发、日历管理），不断扩展能力边界。</li><li>安全执行：它不依赖脆弱的本地环境，而是直接调度宿主机的 Docker Daemon，为每个任务动态创建临时沙箱容器来隔离运行代码；同时集成 Headless Chromium，利用 CDP 协议实现像素级的浏览器自动化。</li></ul><p>这种架构让 AI 从“聊天窗口”真正走入“生产环境”，升级为能交付结果的“数字员工”。</p><h2>为什么选择在 SAE 上托管 OpenClaw？</h2><p>OpenClaw 的执行力依赖于对 Docker 运行时和系统资源的深度调用。阿里云 SAE 凭借全功能的容器环境与Serverless 化的资源调度，为 OpenClaw 提供了一个既能完整运行其所有高级功能，又能避免资源闲置与运维复杂的理想托管平台。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609983" alt="" title=""/></p><h4>零门槛释放 Agent 全量能力</h4><p>OpenClaw 的核心能力在于能动态创建“沙箱”来执行代码，这要求宿主环境具备完整的 Docker 运行时权限。</p><p>SAE 原生支持 Docker-in-Docker (DinD) 模式，允许 OpenClaw 在实例内部独立运行一套完整的 Docker Daemon。这意味着无论是启动临时的 Python 执行环境，还是运行 Headless 浏览器进行网页操作，都能在云端顺畅执行，开发者无需关心底层的环境搭建，即可获得与本地部署一致的完整功能体验。</p><h4><strong>极致弹性实现算力取用自由</strong></h4><p>OpenClaw 的工作负载往往具有显著的潮汐效应与脉冲特征，固定规格的部署方式必然无法兼顾性能和成本。</p><p>SAE 提供了秒级的水平扩缩与垂直规格调整能力，能够精准跟随 Agent 的实际负载动态分配资源。配合秒级冷启动机制，以及精准的按量付费模式，开发者可以真正实现“用多少付多少”，以最优的成本结构支撑 Agent 的全天候运行。</p><h4>全托管架构保障服务高可用</h4><p>作为你的“数字员工”，OpenClaw 需要具备生产级的稳定性。</p><p>SAE 提供了全托管的运行环境，内置了跨可用区容灾、健康检查与故障自愈能力。开发者无需关注服务器的补丁更新或宕机恢复，只需专注于 Agent 的 Skills 开发与业务逻辑构建，即可获得 7×24 小时 的企业级服务保障。</p><h2><strong>部署与配置步骤指引</strong></h2><h4>前置准备</h4><p>在开始部署前，请确保已完成以下准备工作：</p><ul><li>已开通并授权<a href="https://link.segmentfault.com/?enc=4jBQmM6NSzvShVW%2BW9n4eQ%3D%3D.UUOltsddr9HrixIgE0DumvMn9ouuwz4e5ZDcOimOcx14TXjNnwxftCwAi1IWuBs6pw2DaV5OMwaOGlfE6SqTRC9V62dNiL2wwoV2PVxfEpY%3D" rel="nofollow" target="_blank">Serverless应用引擎</a>，详见<a href="https://link.segmentfault.com/?enc=8GY2oC5xyt%2FTsWfoA%2Fsr2w%3D%3D.lsRXSYQdhvEX95yINkyZjY8k5lULcHre7cep2SVQGUMq2zN3uvWl%2BpZj1FgslgnjfSh1WdyKoagbHIitT4yPUA%3D%3D" rel="nofollow" target="_blank">准备工作</a></li><li>已安装并配置 <code>saectl</code> 命令行工具<br/>用于远程访问 OpenClaw 实例。安装与配置方法详见<a href="https://link.segmentfault.com/?enc=9QNeoVq5LvHLNySamJnbSA%3D%3D.R0InPZWsx%2BqBQS4Ck0ZGxvMEL%2FkBSrlSYrMBMsdf79Kjw4WFToYgK3gWb6kIolgFaeDbfc4AhNAc9DLImKlrsqlPzMuE9rB7rkrGN4uOHfu%2F1Gf9Ky5ZQchjJf3t15U5GboMM2P1pLZRowwto9Csnw%3D%3D" rel="nofollow" target="_blank">Saectl 命令行工具</a></li><li>专有网络（VPC）中已配置公网 NAT 网关并绑定 EIP<br/>用于沙箱容器访问公网（如模型 API、网页抓取等）</li></ul><h4>Step1：应用中心一键部署</h4><ol><li>登录 SAE 控制台，进入「应用中心」。</li><li>搜索并点击模板 「OpenClaw — Serverless 部署」，进入服务创建页面。</li><li><p>在表单中填写以下必要信息：</p><ul><li>服务实例名称：自定义，如 openclaw-test</li><li>专有网络（VPC）：选择已配置 NAT 网关的 VPC</li><li>交换机（vSwitch）：选择对应可用区的交换机</li></ul></li><li>其余参数保持默认，点击「创建」。</li></ol><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609984" alt="" title="" loading="lazy"/></p><p>服务创建通常需要 2–3 分钟。创建完成后，在 SAE 应用列表中将看到名为 openclaw-gateway 的应用。</p><h4>Step2：登陆应用实例并初始化配置</h4><p>OpenClaw 的 CLI 命令需在 Gateway 容器内部执行。您可通过以下任一方式登录：ont&gt;</p><p><strong>方式 A：通过 SAE 控制台 WebShell</strong></p><p>1.在 SAE 控制台找到 openclaw-gateway 应用。<br/>2.进入「实例列表」，点击任意实例右侧的 「WebShell」 按钮，即可进入容器终端。</p><p><strong>方式 B：通过 saectl 命令行工具（推荐）</strong></p><pre><code class="powershell">saectl exec -it -n &lt;namespace&gt; &lt;pod-name&gt;</code></pre><p>详见<a href="https://link.segmentfault.com/?enc=l8ZUtneovpHDRW8YMOKvdw%3D%3D.TRCYV3rucRhWsSgb2sE0HJUEBycj9Etw5%2BVYwtI%2B%2BfmMvGljQ2N1tEwQhBTF%2Bj5hDKP1MbAT0WBY%2FMCnBn3XL%2BHLPfil6rV%2F9J1khhTDEr4%3D" rel="nofollow" target="_blank">使用 Saectl 工具管理应用实例 Pod</a></p><blockquote>后续所有命令均在容器实例内执行。</blockquote><p><strong>初始化 OpenClaw 运行环境</strong></p><p>1.设置终端逻辑尺寸（避免 TUI 渲染异常）</p><pre><code class="powershell">stty rows 40 cols 120</code></pre><p>2.执行初始化命令</p><pre><code class="powershell">openclaw onboard --install-daemon</code></pre><p>此命令将通过交互形式引导您完成基础配置，并安装后台守护进程。</p><blockquote>过程中若提示 “Systemd user services are unavailable.”，属正常现象。OpenClaw 在容器环境中使用轻量级进程管理器 supervisord 替代 systemd。</blockquote><p><strong>启动 Gateway 服务</strong></p><p>在容器内使用 supervisord 管理服务生命周期：</p><ul><li>首次部署后启动服务：</li></ul><pre><code class="powershell">supervisorctl start openclaw</code></pre><ul><li>后续修改配置后重启服务：</li></ul><pre><code class="powershell">supervisorctl restart openclaw</code></pre><h4>Step3：配置百炼为模型提供商</h4><ol><li>将阿里云百炼接入为兼容 OpenAI 协议的模型后端。</li></ol><pre><code class="python">openclaw config set models.providers.dashscope '{
  "baseUrl": "https://dashscope.aliyuncs.com/compatible-mode/v1",
  "api": "openai-completions",
  "apiKey": "your-api-key-here",
  "models": [
    {
      "id": "qwen3-max-2026-01-23",
      "name": "qwen3-max-2026-01-23",
      "reasoning": false,
      "input": ["text"],
      "cost": {
        "input": 0,
        "output": 0,
        "cacheRead": 0,
        "cacheWrite": 0
      },
      "contextWindow": 262144,
      "maxTokens": 65536
    }
  ]
}'</code></pre><blockquote>请将<code>your-api-key-here</code> 替换为有效的百炼 API Key。</blockquote><ol start="2"><li>指定该模型为默认推理模型（需与上述 id 一致）：</li></ol><pre><code class="powershell">openclaw config set agents.defaults.model.primary "dashscope/qwen3-max-2026-01-23"</code></pre><ol start="3"><li>重启 Gateway 使配置生效</li></ol><h4>Step4：启用并配置沙箱环境</h4><p>OpenClaw 的沙箱机制用于隔离 AI 代理的代码执行、文件操作和浏览器自动化行为。</p><pre><code class="python"># 1. 启用全功能沙箱模式
openclaw config set agents.defaults.sandbox.mode "all"

# 2. 指定代码执行沙箱的基础镜像
openclaw config set agents.defaults.sandbox.docker.image "openclaw-sandbox:bookworm-slim"

# 3. 设置代码沙箱的网络模式（bridge 允许外网访问；若无需联网可设为 "none"）
openclaw config set agents.defaults.sandbox.docker.network "bridge"

# 4. 启用浏览器自动化沙箱
openclaw config set agents.defaults.sandbox.browser.enabled true

# 5. 指定浏览器沙箱镜像
openclaw config set agents.defaults.sandbox.browser.image "openclaw-sandbox-browser:bookworm-slim"

# 6. 设置浏览器沙箱的网络模式（同上，按需选择 "bridge" 或 "none"）
openclaw config set agents.defaults.sandbox.browser.network "bridge"</code></pre><h4>Step5：访问 OpenClaw 控制界面</h4><p>OpenClaw 支持两种交互方式：终端 TUI 和 Web Control UI。</p><p><strong>方式A：命令行 TUI</strong></p><pre><code class="powershell">openclaw tui</code></pre><p>默认进入 main Agent 的 main Session，可直接开始对话。</p><p><strong>方式B：Web Control UI</strong></p><ol><li>确认 Gateway 绑定地址</li></ol><pre><code class="bash"># 查看配置
openclaw config get gateway.port
openclaw config get gateway.bind

# 应该是：
# port: 18789
# bind: "lan"</code></pre><p>若 gateway.bind 为 loopback，则无法从外部访问，需要设置为 lan</p><pre><code class="python"># 修改为 lan（允许外部访问）
openclaw config set gateway.bind "lan"

# 重启 Gateway
supervisorctl restart openclaw</code></pre><ol start="2"><li>配置公网访问入口</li></ol><p>在 SAE 控制台为应用<a href="https://link.segmentfault.com/?enc=R6Qj8qlH%2BkPXiQsmTiTqOw%3D%3D.%2FremDAfo%2FFeRzJ79tHb2DPY3X4ZiqlhzT3lJh2MkCXsew7hanlMVdrIvc3j59zXcniXf4ljQK%2B6Sz3NLYIdwPA%3D%3D" rel="nofollow" target="_blank">绑定 CLB 并生成公网访问 IP</a>，并配置 HTTPS 监听器，容器端口为 18789（OpenClaw Gateway 监听端口）。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609985" alt="" title="" loading="lazy"/></p><ol start="3"><li>设备配对</li></ol><p>获取认证凭据：</p><pre><code class="bash"># 获取 Gateway 认证 Token
openclaw config get gateway.auth</code></pre><p>在浏览器中打开：</p><pre><code class="bash">https://&lt;CLB_PUBLIC_IP&gt;:18789?token=&lt;GATEWAY_AUTH_TOKEN&gt;</code></pre><p>首次访问将显示 “Pairing required”，表示需授权当前设备。</p><p>批准设备配对请求</p><pre><code class="powershell"># 列出待处理的配对请求
openclaw devices list --token "&lt;GATEWAY_AUTH_TOKEN&gt;"

# 找到状态为 "pending" 的请求 ID，并批准
openclaw devices approve &lt;requestId&gt;</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609986" alt="" title="" loading="lazy"/></p><p>批准后刷新页面，即可正常使用 Web 控制台。</p><h2>构建钉钉 AI 助理</h2><h4>Step1：创建钉钉应用</h4><p>创建钉钉应用需要您的钉钉账号有开发者权限。您可以联系您的组织管理员获取钉钉开放平台的开发权限，具体操作请参见<a href="https://link.segmentfault.com/?enc=Cz2PgNuw34OdfThaDWu1zw%3D%3D.f8hT91%2B%2FNHYMwdncEQK0pKZhcyuKEQpfa%2F5DdR42hlaof207JPjy8qhhBHhAvLd9cJYawLuoW75k6SKWK5oUSt8J51nDCpD7geRxtrgt1u8%3D" rel="nofollow" target="_blank">获取开发者权限</a>。</p><ol><li>创建应用</li></ol><p>a. 访问<a href="https://link.segmentfault.com/?enc=Q5MDk7MZuoZVi3mgtbJYaA%3D%3D.fly%2F2t%2FXdeaGv9uJoOXTpaij3GGNPF4u4Xh5%2FkTrAQ0%3D" rel="nofollow" target="_blank">钉钉开放平台</a>，点击创建。如果创建过应用但未展示应用开发指引，点击立即开始进入钉钉应用页面。</p><p>b. 在应用开发的左侧导航栏中，点击钉钉应用，在钉钉应用页面右上角点击创建应用。<br/>c. 在创建应用面板，填写应用名称和应用描述，在应用图标上传图标，完成后点击保存。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047609987" alt="" title="" loading="lazy"/></p><ol start="2"><li>查看应用 Client ID 和 Client Secret</li></ol><p>在左侧菜单选择凭证与基础信息，复制Client ID和Client Secret，用于下一步创建连接流。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047609988" alt="" title="" loading="lazy"/></p><ol start="3"><li>创建消息卡片<br/>a. 访问<a href="https://link.segmentfault.com/?enc=s4inpPdIimYDwwHn14fnMw%3D%3D.9eznNYxkzwogqFqZjDQXD518%2Bg%2F%2FrRe8x6qn8POh%2F3LEHmfyEgHcEQ4n2KG8QuQ1" rel="nofollow" target="_blank">卡片平台</a>，点击新建模板。</li></ol><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609989" alt="" title="" loading="lazy"/></p><p>b. 在创建模板输入框，填入模板信息，单击创建。</p><ul><li>卡片类型：选择消息卡片。</li><li>卡片模板场景：选择AI 卡片。</li><li>关联应用：关联<a href="https://link.segmentfault.com/?enc=09EBODspe9eop2uNBg9Ihw%3D%3D.71QUUZQlG9dJA9TVDhgP5U14L0R%2FOxxhDHA6d2ZuyOGmdKVENpM6U%2By%2FsVaarGRiZpT8nRLqwvqvQhXXrfkky1%2BWdHzyUo8DIML0vdlhIJXUyznY9mhfz4ZYtNhASLStUNV%2Fi%2FJE0MPgCQkQBLNNimUZLI%2F1A8mOivO%2B0WIYV0wRwHjRmsoOFbEEr6M6DgFS9T1vw30AuH%2FPVCPAFGraMoPtKqIBono3vDdQbCwJuQV5M2KvGOBZssAz1mgsHiOa9AQY0EAiJto1FpaiQTYg4u%2FEq6tDUoUp4VHRBIMOqPo%3D" rel="nofollow" target="_blank">应用创建步骤中的应用</a>。</li></ul><p>c. 在模拟编辑页面，不要使用预设模板，不需要进行任何额外操作，直接保存并发布模板。然后点击返回模板列表页面。</p><p>d. 直接保存并发布模板。然后点击返回模板列表页面。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609990" alt="" title="" loading="lazy"/></p><p>e. 返回模板列表，复制模板 ID，用于创建钉钉连接流使用</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609991" alt="" title="" loading="lazy"/></p><ol start="4"><li>授予应用发送卡片消息权限</li></ol><p>创建卡片后，您需要给应用授予发送卡片消息的权限。</p><p>a.访问<a href="https://link.segmentfault.com/?enc=rCW7KeKV%2FRRnoin0Sjmmsg%3D%3D.W0rBOvPRXD5Wad7tfQXgJBYE2HrrYTW6EazrhMjYCJMy8RaGG0ZncCk8ZFvlyBnj" rel="nofollow" target="_blank">钉钉应用列表</a>。找到刚刚创建的应用，点击应用名称进入详情页面。</p><p>b.在左侧菜单选择开发配置 &gt; 权限管理，在左侧搜索框分别输入Card.Streaming.Write和Card.Instance.Write，并在操作列点击申请权限。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609992" alt="" title="" loading="lazy"/></p><h4>Step2：创建 AppFlow 连接流</h4><ol><li>使用 <a href="https://link.segmentfault.com/?enc=v7uv4RUkNskkecZA2lMmbw%3D%3D.RUOu0qc8dFADAGYJx5gm1dy3JOT0yMAbrGFJ9NgJeGFEsTwZsMArarVZomKDZ0w9q4%2BWKfHcryiZEf9ChKlqeIlV6CsZ%2BYd4TKVwTLRn%2FymtVbF0dvhJsLAJhQz7%2F4CH4cXwl5xBvUno6Zv9DZWqXg%3D%3D" rel="nofollow" target="_blank">AppFlow模板</a> 创建连接流，单击立即使用进入创建流程。</li><li>在连接流账号授权配置向导页，点击钉钉应用机器人下的添加新凭证，填入创建的应用的 Client ID 和 Client Secret，并设置一个自定义凭证名称。</li></ol><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609993" alt="" title="" loading="lazy"/></p><ol start="3"><li>在连接流的账户授权配置向导页，点击 moltbot 下的添加新凭证。输入之前通过以下命令获取的 token。</li></ol><pre><code class="powershell">openclaw config get gateway.auth</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609994" alt="" title="" loading="lazy"/></p><ol start="4"><li><p>在执行动作配置向导页按照页面提示配置完成后点击下一步。</p><ul><li>公网地址：填写 SAE 应用访问配置中的公网访问地址<code>https://&lt;CLB_PUBLIC_IP&gt;:18789</code>。</li><li>模板ID：填写保存的AI卡片模板ID。</li></ul></li><li>在基本信息配置向导页，填写连接流名称和连接流描述（保持默认），完成后点击下一步。</li><li>界面提示流程配置成功，复制 WebhookUrl，点击发布。</li></ol><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609995" alt="" title="" loading="lazy"/></p><h4>Step3：配置钉钉机器人</h4><ol><li><p>添加并配置机器人</p><ul><li>进入钉钉开发者后台，找到您的应用，点击进入详情页。</li><li>在「应用能力」中点击「添加能力」，选择「机器人」。</li><li>开启机器人开关，消息接收模式选择 HTTP，并将消息接收地址填为 OpenClaw 生成的 Webhook URL，完成后点击「发布」。</li></ul></li><li><p>发布应用版本</p><ul><li>在应用开发页面，进入「版本管理与发布」。</li><li>点击「创建新版本」，填写版本号和描述，设置可见范围后保存，并在弹窗中点击「直接发布」。</li></ul></li><li><p>在钉钉群中使用机器人</p><ul><li>进入目标钉钉群 → 群设置 → 智能群助手 → 添加机器人。</li><li>搜索并选择您刚创建的机器人，完成添加。</li><li><p>在群聊或私聊中 @该机器人，即可开始对话。</p><p><em>本实践需加白使用，如果您有任何疑惑，欢迎加入“Serverless应用引擎（SAE）用户群”，钉钉群号：23198618。</em></p></li></ul></li></ol>]]></description></item><item>    <title><![CDATA[SpringBoot中结合MySQL、Redis，实现异步落库的评论点赞/拉踩功能 Personal]]></title>    <link>https://segmentfault.com/a/1190000047610018</link>    <guid>https://segmentfault.com/a/1190000047610018</guid>    <pubDate>2026-02-13 17:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>概要</h2><p>该方案是一个典型的<strong>用空间（Redis缓存）和异步化换取时间（响应速度）和系统稳定性（数据库抗压）</strong> 的架构设计。它非常适合点赞这类<strong>写多读多、对实时一致性要求稍低</strong>的业务场景。</p><h2>前言</h2><p>学习java过程中的心得，如有错误请提醒作者纠正，感谢不尽！！！</p><p>如果有更好的实现，欢迎分享！！！</p><h3>当前实现优点</h3><ol><li><p><strong>高性能与低延迟</strong>：</p><ul><li><strong>写操作快</strong>：用户点赞/拉踩请求直接操作内存数据库Redis，响应速度极快，用户体验好。</li><li><strong>数据库在定时任务触发前压力小</strong>：高频的写操作被Redis承接，避免了直接冲击MySQL</li></ul></li><li><p><strong>数据一致性保障</strong>：</p><ul><li><strong>原子性操作</strong>：使用<strong>Lua脚本</strong>在Redis内完成状态切换（点赞-&gt;拉踩-&gt;无状态），保证了“一个评论同一时刻只能有一种状态”的业务逻辑的原子性，防止并发请求导致的数据错乱。</li><li><strong>分布式锁</strong>：对单个用户的操作加锁（<code>RLock</code>），防止同一用户极短时间内的重复提交造成缓存数据问题。</li></ul></li><li><p><strong>批量处理效率高</strong>：</p><ul><li><strong>异步落库</strong>：定时任务将缓存中的大量变更集中起来，通过<strong>批量插入/更新</strong>（<code>ON DUPLICATE KEY UPDATE</code>）和<strong>批量更新统计</strong>（<code>CASE WHEN</code>）的方式与数据库交互，极大地减少了网络I/O和SQL执行次数，数据库处理效率高。</li></ul></li></ol><h3><strong>当前实现存在问题</strong></h3><ol><li><p>定时任务引发的数据库峰值：</p><ol><li><strong>可通过使用消息队列削峰填谷</strong></li><li><strong>将定时任务从处理全部数据改为处理部分数据，定时任务的周期调低</strong></li></ol></li></ol><h2>主要实现细节</h2><p>Redis + Redis分布式锁 + 原子操作 + 异步落库 + SpringBoot定时任务</p><h2>流程图</h2><p><img width="723" height="692" referrerpolicy="no-referrer" src="/img/bVdnVHF" alt="" title=""/></p><h2>请求方法设计</h2><p><strong>请求URL</strong>：<code>/api/article/v1/{commentId}/vote</code></p><p><strong>请求方法</strong>：PUT</p><p><strong>请求参数</strong>：type(Integer);(type=0表示修改成无状态，type=1表示修改成点赞状态，type=-1表示修改成拉踩状态)</p><p><strong>URL示例</strong>：/api/article/v1/{commentId}/vote?type = 1</p><h2>Redis表设计</h2><p>下述三表都用来记录用户对评论的状态(点赞、拉踩、无状态)</p><h3>articles:comments:likes:users:{userId}</h3><p>{userId}为动态键名</p><p><strong>Redis Set</strong>数据结构；</p><p>存储的值：{commentId}</p><h3>articles:comments:dislikes:users:{userId}</h3><p>{userId}为动态键名</p><p><strong>Redis Set</strong>数据结构；</p><p>存储的值：{commentId}</p><h3>articles:comments:stateless:users:{userId}</h3><p>{userId}为动态键名</p><p><strong>Redis Set</strong>数据结构；</p><p>存储的值：{commentId}</p><h2>MySQL表设计</h2><p>该博客聚焦实现点赞/拉踩功能，涉及x_article_comments表不多，故不做x_article_comments表的字段介绍</p><ul><li><p>x_article_comments_votes</p><ul><li>联合主键(comment_id, user_id)</li><li>vote字段表用户对评论的状态，1代表点赞，-1代表拉踩，0代表无状态，即不处于点赞状态或拉踩状态</li></ul></li></ul><pre><code class="sql">-- 文章评论表
CREATE TABLE x_article_comments (
  id BIGINT AUTO_INCREMENT PRIMARY KEY,
  article_id BIGINT UNSIGNED NOT NULL,            -- 关联的文章
  parent_id BIGINT UNSIGNED NULL,               -- NULL 表示顶级评论；否则是回复
  root_id BIGINT UNSIGNED NULL,                 -- 同一Thread的Root评论 id（便于查询整个Thread）
  user_id BIGINT UNSIGNED NOT NULL,             -- 评论作者
  content TEXT NOT NULL,
  status TINYINT DEFAULT 1,            -- 1=显示,0=已删除/隐藏,2=待审核 等
  like_count INT DEFAULT 0,
  dislike_count INT DEFAULT 0,
  reply_count INT DEFAULT 0, -- 该层孩子的数量
  reply_descendant_count INT DEFAULT 0, -- 该层后代的数量
  version INT DEFAULT 0,               -- 乐观锁（更新时校验）
  create_time DATETIME DEFAULT CURRENT_TIMESTAMP,
  update_time DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,

  PRIMARY KEY (id)
) ENGINE=InnoDB
  DEFAULT CHARSET=utf8mb4
  COLLATE=utf8mb4_unicode_ci;

-- 点赞/踩表（每个用户对某条评论的动作）
CREATE TABLE x_article_comments_votes (
  comment_id BIGINT NOT NULL,
  user_id BIGINT NOT NULL,
  vote TINYINT NOT NULL, -- 1=like, -1=dislike, 0=none
  create_time DATETIME DEFAULT CURRENT_TIMESTAMP,
  update_time DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
  PRIMARY KEY (comment_id, user_id)
) ENGINE=InnoDB
  DEFAULT CHARSET=utf8mb4
  COLLATE=utf8mb4_unicode_ci;</code></pre><h2>后端实现细节</h2><h3>处理用户发起的点赞/拉踩/无状态请求</h3><h4>Controller层</h4><h5>校验参数</h5><p>先校验当前用户是否登录，userReadApi.getCurrentUserId()是我封装好的方法，用于获取发起当前请求的用户ID</p><pre><code class="java">        // 获取当前用户ID
        Long userId = userReadApi.getCurrentUserId();
        if (userId == null) {
            return AjaxResult.error(HttpStatus.UNAUTHORIZED, "用户未登录或获取用户ID失败");
        }</code></pre><h5>完整代码</h5><pre><code class="java">    /**
     * 点赞/拉踩/无状态评论
     */
    @PutMapping("/{commentId}/vote")
    public AjaxResult voteComment(
            @PathVariable("commentId") Long commentId,
            @RequestParam("type") Integer type
    ) {
        log.info("进入请求 /api/article/v1/{}/vote -&gt; 点赞/取消点赞评论 type={}", commentId, type);

        // 获取当前用户ID
        Long userId = userReadApi.getCurrentUserId();
        if (userId == null) {
            return AjaxResult.error(HttpStatus.UNAUTHORIZED, "用户未登录或获取用户ID失败");
        }


        articleService.voteComment(userId, commentId, type);

        log.info("返回结果 /api/article/v1/{}/vote -&gt; OK", commentId);
        return AjaxResult.success();
    }</code></pre><h4>Service层</h4><h5>校验参数</h5><pre><code class="java">        // 1. 参数校验
        if (commentId == null || type == null) {
            throw new ClientException(HttpStatus.BAD_REQUEST, "参数不完整");
        }
        if (type != ArticleCommentVoteConstants.LIKE &amp;&amp; type != ArticleCommentVoteConstants.DISLIKE &amp;&amp; type != ArticleCommentVoteConstants.STATELESS) {
            throw new ClientException(HttpStatus.BAD_REQUEST, "投票类型非法");
        }

        // 2. 校验评论是否存在
        ArticleComment comment = articleCommentMapper.selectArticleCommentById(commentId);
        if (comment == null) {
            throw new ClientException(HttpStatus.NOT_FOUND, "评论不存在");
        }</code></pre><h5>分布式锁 + lua脚本</h5><p>使用了redisson实现加锁，并使用了lua脚本保证原子性，从而防止用户频繁发起请求导致在redis缓存的数据出现错误的情况</p><h6><strong>分布式锁相关代码</strong></h6><pre><code class="java">        // 5. 尝试获取分布式锁
        RLock lock = redisson.getLock(RedisKeyConstants.ARTICLES_COMMENTS_VOTES_LOCK_KEY + userId);
        boolean isLocked = false;
        try {
            isLocked = lock.tryLock(0, RedisKeyConstants.ARTICLES_COMMENTS_VOTES_LOCK_KEY_EXPIRE_TIME, TimeUnit.SECONDS);
            if (!isLocked) {
                throw new ClientException(HttpStatus.SERVICE_UNAVAILABLE, "系统繁忙，请稍后再试");
            } else {
                // 获取到锁，执行投票逻辑，此处省略
                // ...
            }
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
            throw new ClientException(HttpStatus.ERROR, "系统繁忙，请稍后再试");
        } finally {
            if (isLocked &amp;&amp; lock.isHeldByCurrentThread()) {
                lock.unlock();
                log.info("用户 {} 的锁已释放", userId);
            }
        }</code></pre><h6>lua脚本相关代码</h6><p><strong>预先准备好redis键和lua脚本</strong></p><pre><code class="java">        // 3. 构建 Redis 键
        String likeKey = RedisKeyConstants.ARTICLES_COMMENTS_LIKES_USERS_KEY + userId;
        String dislikeKey = RedisKeyConstants.ARTICLES_COMMENTS_DISLIKES_USERS_KEY + userId;
        String statelessKey = RedisKeyConstants.ARTICLES_COMMENTS_STATELESS_USERS_KEY + userId;
        // 4. 根据投票类型处理逻辑
        DefaultRedisScript&lt;Long&gt; deleteScript = new DefaultRedisScript&lt;&gt;();
        deleteScript.setScriptSource(new ResourceScriptSource(new ClassPathResource(RedisLuaConstants.ARTICLE_COMMENTS_VOTE_LUA_SCRIPT_PATH)));
        deleteScript.setResultType(Long.class);
        Long execute = null;</code></pre><p><strong>lua脚本文件</strong></p><p>lua脚本能够<strong>保证原子性</strong>，若用户频繁发起请求也能保证<strong>以下的要求</strong></p><p>三个键对应的set集合里的值应<strong>保持互斥</strong>，只允许一个值如3只能出现在一个键，例如：共有三个键like:{userId}、dislike:{userId}、stateless:{userId}，键like现在持有3，用户对commentId = 3发起了点赞/拉踩/无状态请求，修改为拉踩，此时要去除like:{userId}键和stateless:{userId}键的set集合中值为3的元素，执行完后只有键dislike:{userId}存在值3</p><pre><code class="lua">-- Lua 脚本：处理评论投票逻辑
local mainKey = KEYS[1]       -- 进行add的键
local srem1Key = KEYS[2]    -- 进行srem的键
local srem2Key = KEYS[3]  -- 进行srem的键
local commentId = ARGV[1]     -- 评论 ID

-- 添加到main集合
redis.call('SADD', mainKey, commentId)

-- 从两个集合中移除
redis.call('SREM', srem1Key, commentId)
redis.call('SREM', srem2Key, commentId)

-- 返回操作结果（可选）
return 1  -- 表示成功执行
</code></pre><p><strong>获取到锁后，为实现存进redis，执行的操作如下</strong></p><pre><code class="java">                switch (type) {
                    case ArticleCommentVoteConstants.LIKE:
                        // 4. 处理点赞逻辑
                        execute = stringRedisTemplate.execute(deleteScript, Arrays.asList(likeKey, dislikeKey, statelessKey), commentId.toString());
                        if (execute == null) {
                            throw new ClientException(HttpStatus.SERVICE_UNAVAILABLE, "处理点踩逻辑失败");
                        }
                        break;
                    case ArticleCommentVoteConstants.DISLIKE:
                        // 5. 处理点踩逻辑
                        execute = stringRedisTemplate.execute(deleteScript, Arrays.asList(dislikeKey, likeKey, statelessKey), commentId.toString());
                        if (execute == null) {
                            throw new ClientException(HttpStatus.SERVICE_UNAVAILABLE, "处理点踩逻辑失败");
                        }
                        break;
                    case ArticleCommentVoteConstants.STATELESS:
                        execute = stringRedisTemplate.execute(deleteScript, Arrays.asList(statelessKey, dislikeKey, likeKey), commentId.toString());
                        if (execute == null) {
                            throw new ClientException(HttpStatus.ERROR, "处理无状态逻辑失败");
                        }
                        break;
                    default:
                        throw new ClientException(HttpStatus.BAD_REQUEST, "未知的投票类型");
                }</code></pre><h5>完整代码</h5><pre><code class="java">    @Override
    public void voteComment(Long userId, Long commentId, Integer type) {
        // 1. 参数校验
        if (commentId == null || type == null) {
            throw new ClientException(HttpStatus.BAD_REQUEST, "参数不完整");
        }
        if (type != ArticleCommentVoteConstants.LIKE &amp;&amp; type != ArticleCommentVoteConstants.DISLIKE &amp;&amp; type != ArticleCommentVoteConstants.STATELESS) {
            throw new ClientException(HttpStatus.BAD_REQUEST, "投票类型非法");
        }

        // 2. 校验评论是否存在
        ArticleComment comment = articleCommentMapper.selectArticleCommentById(commentId);
        if (comment == null) {
            throw new ClientException(HttpStatus.NOT_FOUND, "评论不存在");
        }

        // 3. 构建 Redis 键
        String likeKey = RedisKeyConstants.ARTICLES_COMMENTS_LIKES_USERS_KEY + userId;
        String dislikeKey = RedisKeyConstants.ARTICLES_COMMENTS_DISLIKES_USERS_KEY + userId;
        String statelessKey = RedisKeyConstants.ARTICLES_COMMENTS_STATELESS_USERS_KEY + userId;
        // 4. 根据投票类型处理逻辑
        DefaultRedisScript&lt;Long&gt; deleteScript = new DefaultRedisScript&lt;&gt;();
        deleteScript.setScriptSource(new ResourceScriptSource(new ClassPathResource(RedisLuaConstants.ARTICLE_COMMENTS_VOTE_LUA_SCRIPT_PATH)));
        deleteScript.setResultType(Long.class);
        Long execute = null;
        // 5. 尝试获取分布式锁
        RLock lock = redisson.getLock(RedisKeyConstants.ARTICLES_COMMENTS_VOTES_LOCK_KEY + userId);
        boolean isLocked = false;
        try {
            isLocked = lock.tryLock(0, RedisKeyConstants.ARTICLES_COMMENTS_VOTES_LOCK_KEY_EXPIRE_TIME, TimeUnit.SECONDS);
            if (!isLocked) {
                throw new ClientException(HttpStatus.SERVICE_UNAVAILABLE, "系统繁忙，请稍后再试");
            } else {
                // 获取到锁，执行投票逻辑
                switch (type) {
                    case ArticleCommentVoteConstants.LIKE:
                        // 4. 处理点赞逻辑
                        execute = stringRedisTemplate.execute(deleteScript, Arrays.asList(likeKey, dislikeKey, statelessKey), commentId.toString());
                        if (execute == null) {
                            throw new ClientException(HttpStatus.SERVICE_UNAVAILABLE, "处理点踩逻辑失败");
                        }
                        break;
                    case ArticleCommentVoteConstants.DISLIKE:
                        // 5. 处理点踩逻辑
                        execute = stringRedisTemplate.execute(deleteScript, Arrays.asList(dislikeKey, likeKey, statelessKey), commentId.toString());
                        if (execute == null) {
                            throw new ClientException(HttpStatus.SERVICE_UNAVAILABLE, "处理点踩逻辑失败");
                        }
                        break;
                    case ArticleCommentVoteConstants.STATELESS:
                        execute = stringRedisTemplate.execute(deleteScript, Arrays.asList(statelessKey, dislikeKey, likeKey), commentId.toString());
                        if (execute == null) {
                            throw new ClientException(HttpStatus.ERROR, "处理无状态逻辑失败");
                        }
                        break;
                    default:
                        throw new ClientException(HttpStatus.BAD_REQUEST, "未知的投票类型");
                }
            }
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
            throw new ClientException(HttpStatus.ERROR, "系统繁忙，请稍后再试");
        } finally {
            if (isLocked &amp;&amp; lock.isHeldByCurrentThread()) {
                lock.unlock();
                log.info("用户 {} 的锁已释放", userId);
            }
        }
    }</code></pre><h3>定时任务</h3><p>定时任务要实现落库到MySQL中，并且清空redis对应的缓存</p><h4>创建定时任务</h4><pre><code class="java">@Component
@Slf4j
public class VoteSyncScheduler {

    private final ArticleService articleService;
    public VoteSyncScheduler(ArticleService articleService) {
        this.articleService = articleService;
    }

    @Scheduled(fixedRate = 5 * 60 * 1000) // 每五分钟执行一次
    public void syncVote() {
        log.info("开始执行点赞同步任务...");
        Boolean result = articleService.syncVote();
        log.info("点赞同步任务执行完成。");
    }
}</code></pre><h4>syncVote实现</h4><p>MySQL涉及操作多张表，所以需要在方法上加上注解@Transactional</p><p><a href="##流程图" target="_blank">参考流程图</a></p><ol><li>我们首先要从redis中获取数据，并将数据封装到两个集合中。</li><li>落库到MySQL</li><li>根据x_article_comments_votes表，通过SQL语句统计出like_count, dislike_count</li><li>将统计出的数据更新到x_article_comments</li><li>清除已在该定时任务处理完的redis缓存数据</li></ol><h5>变量说明</h5><ul><li>List&lt;ArticleCommentVote&gt; votes = new ArrayList&lt;&gt;();      // 保存所有投票数据</li><li>Set&lt;Long&gt; TotalcommentId = new HashSet&lt;&gt;();     // 保存所有评论id</li><li>likesUserIdToCommentIdsMap、dislikesUserIdToCommentIdsMap、statelessUserIdToCommentIdsMap——存储的值为经过逻辑后键中已被处理的值，在最后一步清除redis缓存发挥作用</li></ul><h5>从redis中获取数据，并将数据封装到两个集合中</h5><pre><code class="java">        Set&lt;String&gt; userLikesKeys = stringRedisTemplate.keys(RedisKeyConstants.ARTICLES_COMMENTS_LIKES_USERS_KEY + "*");
        Set&lt;String&gt; userDislikesKeys = stringRedisTemplate.keys(RedisKeyConstants.ARTICLES_COMMENTS_DISLIKES_USERS_KEY + "*");
        Set&lt;String&gt; userStatelessKeys = stringRedisTemplate.keys(RedisKeyConstants.ARTICLES_COMMENTS_STATELESS_USERS_KEY + "*");
        if (userLikesKeys.isEmpty() &amp;&amp; userDislikesKeys.isEmpty() &amp;&amp; userStatelessKeys.isEmpty()){
            log.info("没有需要同步的数据");
            return true;
        }
        List&lt;ArticleCommentVote&gt; votes = new ArrayList&lt;&gt;();      // 保存所有投票数据
        Set&lt;Long&gt; TotalcommentId = new HashSet&lt;&gt;();     // 保存所有评论id
        Map&lt;Long, Set&lt;String&gt;&gt; likesUserIdToCommentIdsMap = new HashMap&lt;&gt;();
        Map&lt;Long, Set&lt;String&gt;&gt; dislikesUserIdToCommentIdsMap = new HashMap&lt;&gt;();
        Map&lt;Long, Set&lt;String&gt;&gt; statelessUserIdToCommentIdsMap = new HashMap&lt;&gt;();
        for (String userLikesKey : userLikesKeys) {
            String userId = userLikesKey.replace(RedisKeyConstants.ARTICLES_COMMENTS_LIKES_USERS_KEY, "");
            Set&lt;String&gt; commentIds = stringRedisTemplate.opsForSet().members(userLikesKey);
            for (String commentId : commentIds) {
                votes.add(new ArticleCommentVote(Long.parseLong(commentId), Long.parseLong(userId), ArticleCommentVoteConstants.LIKE, null, null));
                TotalcommentId.add(Long.parseLong(commentId));
                // 更新或新增likesUserIdToCommentIdsMap键值对，值的set集合新增commentId
                likesUserIdToCommentIdsMap.computeIfAbsent(Long.parseLong(userId), k -&gt; new HashSet&lt;&gt;()).add(commentId);
            }
        }
        for (String userDislikesKey : userDislikesKeys) {
            String userId = userDislikesKey.replace(RedisKeyConstants.ARTICLES_COMMENTS_DISLIKES_USERS_KEY, "");
            Set&lt;String&gt; commentIds = stringRedisTemplate.opsForSet().members(userDislikesKey);
            for (String commentId : commentIds) {
                votes.add(new ArticleCommentVote(Long.parseLong(commentId), Long.parseLong(userId), ArticleCommentVoteConstants.DISLIKE, null, null));
                TotalcommentId.add(Long.parseLong(commentId));
                // 更新或新增dislikesUserIdToCommentIdsMap键值对，值的set集合新增commentId
                dislikesUserIdToCommentIdsMap.computeIfAbsent(Long.parseLong(userId), k -&gt; new HashSet&lt;&gt;()).add(commentId);
            }
        }
        for (String userStatelessKey : userStatelessKeys) {
            String userId = userStatelessKey.replace(RedisKeyConstants.ARTICLES_COMMENTS_STATELESS_USERS_KEY, "");
            Set&lt;String&gt; commentIds = stringRedisTemplate.opsForSet().members(userStatelessKey);
            for (String commentId : commentIds) {
                votes.add(new ArticleCommentVote(Long.parseLong(commentId), Long.parseLong(userId), ArticleCommentVoteConstants.STATELESS, null, null));
                TotalcommentId.add(Long.parseLong(commentId));
                // 添加到statelessUserIdToCommentIdsMap键值对，值的set集合新增commentId
                statelessUserIdToCommentIdsMap.computeIfAbsent(Long.parseLong(userId), k -&gt; new HashSet&lt;&gt;()).add(commentId);
            }
        }</code></pre><h5>落库到MySQL</h5><h6>Service层相关代码</h6><pre><code class="java">        // 根据votes执行落库逻辑（包含插入/更新）
        if (!votes.isEmpty()){
            int i = articleCommentVoteMapper.batchInsertOrUpdate(votes);
            if (i &lt; 0){
                throw new ClientException(HttpStatus.ERROR, "批量插入或更新数据失败");
            }
            log.info("批量插入或更新数据成功，数量为：{}", i);
        } else {
            log.info("没有需要落库的数据");
            return true;
        }</code></pre><h6>SQL语句相关实现</h6><pre><code class="xml">    &lt;!-- 原有方法 --&gt;
    &lt;insert id="batchInsertOrUpdate" parameterType="java.util.List"&gt;
        INSERT INTO x_article_comments_votes (
            comment_id,
            user_id,
            vote,
            create_time,
            update_time
        )
        VALUES
        &lt;foreach collection="list" item="item" separator=","&gt;
            (
                #{item.commentId},
                #{item.userId},
                #{item.vote},
                NOW(),
                NOW()
            )
        &lt;/foreach&gt;
        ON DUPLICATE KEY UPDATE
            vote = VALUES(vote),
            update_time = VALUES(update_time)
    &lt;/insert&gt;</code></pre><h5>根据x_article_comments_votes表，通过SQL语句统计出like_count, dislike_count</h5><h6>Service层相关代码</h6><pre><code class="java">        List&lt;UpdateCommentVoteCountDTO&gt; updateCommentVoteCountDTOList = getCommentLikeCountAndDislikeCountByListOfCommentId(TotalcommentId);</code></pre><h6>SQL语句相关实现</h6><pre><code class="xml">&lt;!-- 新增方法: 聚合查询点赞/点踩数量 --&gt;
&lt;select id="selectCommentLikeCountAndDislikeCountByListOfCommentId" resultType="com.anon.spaceblogserver.modules.article.POJO.DTO.UpdateCommentVoteCountDTO"&gt;
    SELECT
        comment_id AS commentId,
        SUM(CASE WHEN vote = 1 THEN 1 ELSE 0 END) AS likeCount,
        SUM(CASE WHEN vote = -1 THEN 1 ELSE 0 END) AS dislikeCount
    FROM x_article_comments_votes
    WHERE comment_id IN
    &lt;foreach collection="commentIds" item="commentId" open="(" separator="," close=")"&gt;
        #{commentId}
    &lt;/foreach&gt;
    GROUP BY comment_id
&lt;/select&gt;</code></pre><h5>将统计出的数据批量更新到x_article_comments</h5><h6>Service层相关代码</h6><pre><code class="java">int updated = batchUpdateCommentLikeCountAndDislikeCount(updateCommentVoteCountDTOList, MySQLBatchSizeConstants.DEFAULT_UPDATE_BATCH_SIZE);
if (updated &lt; 0){
    throw new ClientException(HttpStatus.ERROR, "批量更新数据失败");
}
log.info("批量更新数据成功，更新数量为：{}", updated);</code></pre><h6>限制单条SQL语句长度，批量更新操作具体实现</h6><p>因为<strong>SQL语句</strong>采用了<code>case when</code>来<strong>减少网络往返</strong>，为<strong>限制SQL语句长度防止溢出</strong>以及<strong>影响性能</strong>，采用的策略如下</p><p>若检测到参数updateCommentVoteCountDTOList超过指定个数，将会拆分成多条SQL语句与MySQL数据库进行交互</p><pre><code class="java">/**
 * 批量更新评论的点赞数和点踩数
 * @param updateCommentVoteCountDTOList     需要更新的评论点赞数和点踩数列表
 * @param batchSize                   批次大小，建议根据实际情况调整，过大可能导致单次更新过慢，过小可能导致更新次数过多
 * @return      成功更新的记录数
 */
public int batchUpdateCommentLikeCountAndDislikeCount(List&lt;UpdateCommentVoteCountDTO&gt; updateCommentVoteCountDTOList, Integer batchSize) {
    int totalUpdated = 0;
    for (int i = 0; i &lt; updateCommentVoteCountDTOList.size(); i += batchSize) {
        // 截取当前批次的数据
        List&lt;UpdateCommentVoteCountDTO&gt; batch = updateCommentVoteCountDTOList.subList(
                i,
                Math.min(i + batchSize, updateCommentVoteCountDTOList.size())
        );
        // 执行当前批次的更新
        int updated = articleCommentMapper.batchUpdateCommentLikeCountAndDislikeCount(batch);
        if (updated &lt; 0) {
            log.error("批量更新数据失败，当前批次更新数量: {}", updated);
            return -1;
        }
        totalUpdated += updated;

        log.info("批量更新评论点赞/点踩数，当前批次更新数量: {}, 累计更新数量: {}", updated, totalUpdated);
    }
    return totalUpdated;
}</code></pre><h6>SQL语句相关实现</h6><pre><code class="xml">&lt;update id="batchUpdateCommentLikeCountAndDislikeCount"&gt;
    UPDATE x_article_comments
    SET like_count = CASE id
    &lt;foreach collection="list" item="item"&gt;
        WHEN #{item.commentId} THEN #{item.likeCount}
    &lt;/foreach&gt;
    END,
    dislike_count = CASE id
    &lt;foreach collection="list" item="item"&gt;
        WHEN #{item.commentId} THEN #{item.dislikeCount}
    &lt;/foreach&gt;
    END,
    update_time = NOW()
    WHERE id IN
    &lt;foreach collection="list" item="item" open="(" separator="," close=")"&gt;
        #{item.commentId}
    &lt;/foreach&gt;
&lt;/update&gt;</code></pre><h5>清除已在该定时任务处理完的redis缓存数据</h5><p>前面提到的变量——likesUserIdToCommentIdsMap、dislikesUserIdToCommentIdsMap、statelessUserIdToCommentIdsMap。存储的值为经过逻辑后键中已被处理的值，在最后一步清除redis缓存发挥作用</p><p>上述变量类型形式为<strong>Map&lt;Long, Set&lt;String&gt;&gt;</strong>，满足了userId -&gt; 评论id集合，这可以精准且方便的清除已处理后的redis缓存数据</p><p>构建上述三个Map集合的过程在<a href="####从redis中获取数据，并将数据封装到两个集合中" target="_blank">第一步操作</a>中经历三个for循环已经构建完毕</p><p>该操作同样用到<strong>lua脚本</strong>保证<strong>原子性</strong></p><h6>lua脚本</h6><p>该脚本实现<strong>安全批量的移除</strong>key中<strong>要删除的元素列表</strong>，<strong>为什么不直接把键删除的原因</strong> -&gt; 假如在该定时任务执行过程中以及该脚本执行之前<strong>用户又发起点赞/拉踩/无状态请求</strong>，若与定时任务触发后<strong>从redis查到的用户对评论的状态相等，则会移除</strong>，这并没有什么问题，<strong>若不相等，不会移除新请求中用户设置的点赞/拉踩/无状态，留到下一次定时任务触发后处理</strong>。</p><pre><code class="lua">-- 安全批量删除，包含key存在性检查
-- KEYS[1]: Set的key
-- ARGV[1..n]: 要删除的元素列表
--
local key = KEYS[1]
local key_type = redis.call('TYPE', key).ok

-- 检查key是否存在且类型为set
if key_type == 'none' then
    return 0
elseif key_type ~= 'set' then
    return redis.error_reply('WRONGTYPE Operation against a key holding the wrong kind of value')
end

-- 兼容 Lua 5.1 和 Lua 5.2+
local unpack = unpack or table.unpack

local result = 0

-- 如果 ARGV 不为空，则执行批量删除
if #ARGV &gt; 0 then
    result = redis.call('SREM', key, unpack(ARGV))
end

return result</code></pre><h6>Service层相关代码</h6><pre><code class="java">// 清空Redis中的数据
DefaultRedisScript&lt;Long&gt; deleteScript = new DefaultRedisScript&lt;&gt;();
deleteScript.setScriptSource(new ResourceScriptSource(new ClassPathResource(RedisLuaConstants.BATCH_REMOVE_MEMBERS_FROM_SET_LUA_SCRIPT_PATH)));
deleteScript.setResultType(Long.class);
likesUserIdToCommentIdsMap.forEach((userId, commentIdSet) -&gt; {
    Long result = stringRedisTemplate.execute(deleteScript, List.of(RedisKeyConstants.ARTICLES_COMMENTS_LIKES_USERS_KEY + userId.toString()), commentIdSet.toArray());
    if (result == null || result &lt; 0){
        log.error("批量删除用户 {} 缓存点赞的评论失败，欲删除的commentId -&gt; {}", userId, commentIdSet);
    }
});
dislikesUserIdToCommentIdsMap.forEach((userId, commentIdSet) -&gt; {
    Long result = stringRedisTemplate.execute(deleteScript, List.of(RedisKeyConstants.ARTICLES_COMMENTS_DISLIKES_USERS_KEY + userId.toString()), commentIdSet.toArray());
    if (result == null || result &lt; 0){
        log.error("批量删除用户 {} 缓存点踩的评论失败，欲删除的commentId -&gt; {}", userId, commentIdSet);
    }
});
statelessUserIdToCommentIdsMap.forEach((userId, commentIdSet) -&gt; {
    Long result = stringRedisTemplate.execute(deleteScript, List.of(RedisKeyConstants.ARTICLES_COMMENTS_STATELESS_USERS_KEY + userId.toString()), commentIdSet.toArray());
    if (result == null || result &lt; 0){
        log.error("批量删除用户 {} 缓存无状态的评论失败，欲删除的commentId -&gt; {}", userId, commentIdSet);
    }
});</code></pre><h4>SyncVote完整代码</h4><pre><code class="java">@Transactional
@Override
public Boolean syncVote() {
    //TODO 发散思维，该段逻辑似乎在收藏、投币等功能有相似之处，该段之所以有点复杂是因为有三种状态————点赞、点踩、无状态，且三者之间是互斥的，但前面的收藏、投币功能没有这个问题，并且好像只有两个状态，日后可以抽象出一个通用方法来处理这类功能，减少代码重复度
    Set&lt;String&gt; userLikesKeys = stringRedisTemplate.keys(RedisKeyConstants.ARTICLES_COMMENTS_LIKES_USERS_KEY + "*");
    Set&lt;String&gt; userDislikesKeys = stringRedisTemplate.keys(RedisKeyConstants.ARTICLES_COMMENTS_DISLIKES_USERS_KEY + "*");
    Set&lt;String&gt; userStatelessKeys = stringRedisTemplate.keys(RedisKeyConstants.ARTICLES_COMMENTS_STATELESS_USERS_KEY + "*");
    if (userLikesKeys.isEmpty() &amp;&amp; userDislikesKeys.isEmpty() &amp;&amp; userStatelessKeys.isEmpty()){
        log.info("没有需要同步的数据");
        return true;
    }
    List&lt;ArticleCommentVote&gt; votes = new ArrayList&lt;&gt;();      // 保存所有投票数据
    Set&lt;Long&gt; TotalcommentId = new HashSet&lt;&gt;();     // 保存所有评论id
    Map&lt;Long, Set&lt;String&gt;&gt; likesUserIdToCommentIdsMap = new HashMap&lt;&gt;();
    Map&lt;Long, Set&lt;String&gt;&gt; dislikesUserIdToCommentIdsMap = new HashMap&lt;&gt;();
    Map&lt;Long, Set&lt;String&gt;&gt; statelessUserIdToCommentIdsMap = new HashMap&lt;&gt;();
    for (String userLikesKey : userLikesKeys) {
        String userId = userLikesKey.replace(RedisKeyConstants.ARTICLES_COMMENTS_LIKES_USERS_KEY, "");
        Set&lt;String&gt; commentIds = stringRedisTemplate.opsForSet().members(userLikesKey);
        for (String commentId : commentIds) {
            votes.add(new ArticleCommentVote(Long.parseLong(commentId), Long.parseLong(userId), ArticleCommentVoteConstants.LIKE, null, null));
            TotalcommentId.add(Long.parseLong(commentId));
            // 更新或新增likesUserIdToCommentIdsMap键值对，值的set集合新增commentId
            likesUserIdToCommentIdsMap.computeIfAbsent(Long.parseLong(userId), k -&gt; new HashSet&lt;&gt;()).add(commentId);
        }
    }
    for (String userDislikesKey : userDislikesKeys) {
        String userId = userDislikesKey.replace(RedisKeyConstants.ARTICLES_COMMENTS_DISLIKES_USERS_KEY, "");
        Set&lt;String&gt; commentIds = stringRedisTemplate.opsForSet().members(userDislikesKey);
        for (String commentId : commentIds) {
            votes.add(new ArticleCommentVote(Long.parseLong(commentId), Long.parseLong(userId), ArticleCommentVoteConstants.DISLIKE, null, null));
            TotalcommentId.add(Long.parseLong(commentId));
            // 更新或新增dislikesUserIdToCommentIdsMap键值对，值的set集合新增commentId
            dislikesUserIdToCommentIdsMap.computeIfAbsent(Long.parseLong(userId), k -&gt; new HashSet&lt;&gt;()).add(commentId);
        }
    }
    for (String userStatelessKey : userStatelessKeys) {
        String userId = userStatelessKey.replace(RedisKeyConstants.ARTICLES_COMMENTS_STATELESS_USERS_KEY, "");
        Set&lt;String&gt; commentIds = stringRedisTemplate.opsForSet().members(userStatelessKey);
        for (String commentId : commentIds) {
            votes.add(new ArticleCommentVote(Long.parseLong(commentId), Long.parseLong(userId), ArticleCommentVoteConstants.STATELESS, null, null));
            TotalcommentId.add(Long.parseLong(commentId));
            // 添加到statelessUserIdToCommentIdsMap键值对，值的set集合新增commentId
            statelessUserIdToCommentIdsMap.computeIfAbsent(Long.parseLong(userId), k -&gt; new HashSet&lt;&gt;()).add(commentId);
        }
    }
    // 根据votes执行落库逻辑（包含插入/更新）
    if (!votes.isEmpty()){
        int i = articleCommentVoteMapper.batchInsertOrUpdate(votes);
        if (i &lt; 0){
            throw new ClientException(HttpStatus.ERROR, "批量插入或更新数据失败");
        }
        log.info("批量插入或更新数据成功，数量为：{}", i);
    } else {
        log.info("没有需要落库的数据");
        return true;
    }
    // 根据TotalcommentId集合中的commentId，利用聚合函数获取对应表中对应评论的likeCount和dislikeCount，封装成List&lt;updateCommentVoteCountDTO&gt; updateCommentVoteCountDTOList
    List&lt;UpdateCommentVoteCountDTO&gt; updateCommentVoteCountDTOList = getCommentLikeCountAndDislikeCountByListOfCommentId(TotalcommentId);
    // 根据updateCommentVoteCountDTOList执行批量更新的逻辑，作用的表为x_article_comments，使用case when then语法更新likeCount和dislikeCount
    int updated = batchUpdateCommentLikeCountAndDislikeCount(updateCommentVoteCountDTOList, MySQLBatchSizeConstants.DEFAULT_UPDATE_BATCH_SIZE);
    if (updated &lt; 0){
        throw new ClientException(HttpStatus.ERROR, "批量更新数据失败");
    }
    log.info("批量更新数据成功，更新数量为：{}", updated);
    // 清空Redis中的数据
    DefaultRedisScript&lt;Long&gt; deleteScript = new DefaultRedisScript&lt;&gt;();
    deleteScript.setScriptSource(new ResourceScriptSource(new ClassPathResource(RedisLuaConstants.BATCH_REMOVE_MEMBERS_FROM_SET_LUA_SCRIPT_PATH)));
    deleteScript.setResultType(Long.class);
    likesUserIdToCommentIdsMap.forEach((userId, commentIdSet) -&gt; {
        Long result = stringRedisTemplate.execute(deleteScript, List.of(RedisKeyConstants.ARTICLES_COMMENTS_LIKES_USERS_KEY + userId.toString()), commentIdSet.toArray());
        if (result == null || result &lt; 0){
            log.error("批量删除用户 {} 缓存点赞的评论失败，欲删除的commentId -&gt; {}", userId, commentIdSet);
        }
    });
    dislikesUserIdToCommentIdsMap.forEach((userId, commentIdSet) -&gt; {
        Long result = stringRedisTemplate.execute(deleteScript, List.of(RedisKeyConstants.ARTICLES_COMMENTS_DISLIKES_USERS_KEY + userId.toString()), commentIdSet.toArray());
        if (result == null || result &lt; 0){
            log.error("批量删除用户 {} 缓存点踩的评论失败，欲删除的commentId -&gt; {}", userId, commentIdSet);
        }
    });
    statelessUserIdToCommentIdsMap.forEach((userId, commentIdSet) -&gt; {
        Long result = stringRedisTemplate.execute(deleteScript, List.of(RedisKeyConstants.ARTICLES_COMMENTS_STATELESS_USERS_KEY + userId.toString()), commentIdSet.toArray());
        if (result == null || result &lt; 0){
            log.error("批量删除用户 {} 缓存无状态的评论失败，欲删除的commentId -&gt; {}", userId, commentIdSet);
        }
    });
    return true;
}</code></pre>]]></description></item><item>    <title><![CDATA[100类中药材图像识别数据集分享（适用于目标检测任务） 风筝 ]]></title>    <link>https://segmentfault.com/a/1190000047609816</link>    <guid>https://segmentfault.com/a/1190000047609816</guid>    <pubDate>2026-02-13 16:06:04</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>100类中药材图像识别数据集分享（适用于目标检测任务）</h2><h3>数据集分享</h3><p>如需下载该数据集，可通过以下方式获取：</p><ul><li><p>💾 数据集打包为 ZIP 文件，解压后即用。</p><pre><code class="bash">https://pan.baidu.com/s/1zyL7C7byFj3VYeYnLGM2Gg?pwd=jsw8</code></pre></li></ul><h3>引言</h3><p>在中医药现代化的浪潮中，如何利用人工智能技术实现中药材的快速、准确识别，成为了中医药信息化领域的重要研究方向。传统的中药材识别主要依赖于专家经验和人工比对，这种方法不仅效率低下，而且在面对种类繁多、外观相似度高的中药材时，容易产生误判。随着深度学习技术的迅猛发展，特别是基于YOLO等目标检测模型的图像识别技术在多个领域取得显著成效，将其应用于中药图像识别已展现出广阔的前景。</p><p>为推动中药材智能识别的研究与落地，我们整理并发布了一套高质量的中药材图像识别数据集。该数据集涵盖100类常见中药材图像，共计9200张样本，并完成了标准YOLO格式的标注和训练/验证集划分，可直接用于模型训练和算法测试。本文将对该数据集进行详细介绍，包括数据集概述、结构详情、适用场景等内容，旨在为相关研究和应用提供参考。</p><h3>数据集概述</h3><p>本数据集收录了来自中药材识别实际场景中的100个类别图像，总计9200张高质量样本图。这些图像已按照<code>train/val</code>分组格式进行整理，适用于主流深度学习框架（如PyTorch、TensorFlow、YOLO等）的训练与验证流程。图像分辨率清晰，涵盖了不同拍摄角度、光照条件和背景下的实物图像，既体现了真实场景的复杂性，又保证了语义的代表性。</p><h4>数据集基本信息</h4><ul><li><strong>图像总数</strong>：9200张</li><li><strong>训练集</strong>：8000张</li><li><strong>验证集</strong>：1200张</li><li><strong>类别数量</strong>：100种中药材</li><li><strong>命名规范</strong>：统一使用简体中文命名，便于中文语义处理任务</li></ul><h3>数据集结构</h3><p>本数据集采用标准的文件夹结构进行组织，具体如下：</p><pre><code class="plaintext">/train/
    └── 安息香/
    └── 白扁豆/
    ...
/val/
    └── 安息香/
    └── 白扁豆/
    ...</code></pre><p>文件命名规则为自动生成，确保不重名，例如<code>安息香_001.jpg</code>。这种结构设计不仅便于数据的管理和浏览，也符合主流深度学习框架的数据加载要求。</p><h4>类别配置</h4><p>以下是数据集的类别配置（YOLO格式）：</p><pre><code class="yaml">nc: 100
names: ['安息香', '白扁豆', '白矾', '白蔹', '白茅根', '白前', '白芍', '白芷', '柏子仁', '北沙参',
        '荜拨', '荜澄茄', '鳖甲', '槟榔', '苍术', '草豆蔻', '沉香', '川楝子', '川木香', '川牛膝',
        '大腹皮', '淡豆豉', '稻芽', '地龙', '冬虫夏草', '防风', '番泻叶', '蜂房', '甘草', '干姜',
        '甘松', '藁本', '硅石脂', '枸杞子', '桂枝', '谷精草', '谷芽', '海龙', '海螵蛸', '合欢皮',
        '黄柏', '黄芪', '黄芩', '湖北贝母', '僵蚕', '芥子', '鸡冠花', '金灯笼', '鸡内金', '荆芥穗',
        '金果榄', '金钱白花蛇', '九香虫', '橘核', '苦地丁', '莱菔子', '莲房', '莲须', '莲子',
        '莲子心', '灵芝', '荔枝核', '龙眼肉', '芦根', '路路通', '麦冬', '木丁香', '羌活',
        '千年健', '秦皮', '全蝎', '忍冬藤', '人参', '肉豆蔻', '桑寄生', '桑螵蛸', '桑椹',
        '山慈菇', '山奈', '山茱萸', '沙苑子', '石榴皮', '丝瓜络', '酸枣仁', '苏木',
        '太子参', '天花粉', '天麻', '土荆皮', '瓦楞子', '五加皮', '细辛', '银柴胡',
        '薏苡仁', '郁金', '浙贝母', '枳壳', '竹茹', '诃子', '自然铜']</code></pre><h3>数据处理流程</h3><p>为确保数据集的质量和可用性，我们在构建过程中遵循了严格的数据处理流程，具体步骤如下：</p><pre style="display:none;"><code class="mermaid">flowchart TD
    A[数据收集] --&gt; B[图像预处理]
    B --&gt; C[类别标注]
    C --&gt; D[数据划分]
    D --&gt; E[格式转换]
    E --&gt; F[质量检测]
    F --&gt; G[最终发布]</code></pre><ol><li><strong>数据收集</strong>：从多个来源收集中药材图像，确保覆盖不同角度、光照和背景</li><li><strong>图像预处理</strong>：对收集到的图像进行清洗、去噪和标准化处理</li><li><strong>类别标注</strong>：采用人工标注的方式，确保类别归属的准确性</li><li><strong>数据划分</strong>：按照7:3的比例划分为训练集和验证集</li><li><strong>格式转换</strong>：将标注结果转换为YOLO标准格式</li><li><strong>质量检测</strong>：对处理后的数据进行质量检查，确保数据的一致性和完整性</li><li><strong>最终发布</strong>：打包发布数据集，提供下载链接</li></ol><h3>数据集特点</h3><p>本数据集具有以下显著特点：</p><ol><li><strong>类别丰富</strong>：涵盖100种常见中药材，基本覆盖了临床常用品种</li><li><strong>样本充足</strong>：总计9200张图像，每个类别均有足够的样本量</li><li><strong>标注规范</strong>：采用标准YOLO格式标注，可直接用于模型训练</li><li><strong>场景多样</strong>：图像拍摄场景多样，包括不同角度、光照和背景</li><li><strong>中文命名</strong>：统一使用简体中文命名，便于中文语义处理任务</li><li><strong>结构清晰</strong>：采用标准文件夹结构，易于管理和使用</li></ol><h3>适用场景</h3><p>本数据集可广泛应用于以下人工智能与中医药交叉领域：</p><h4>1. 中药识别图像分类任务</h4><p>可用于训练ResNet、ViT、YOLO等模型，实现中药材的自动分类和识别。通过深度学习模型的训练，可以提高中药材识别的准确率和效率，减少人工干预。</p><h4>2. 中药拍照识别App研发</h4><p>作为图像识别后端训练数据，可支持开发中药拍照识别App，用户只需拍摄中药材照片，即可快速获取药材名称、功效等信息，便于中药辅助查询和科普应用。</p><h4>3. 医学辅助系统训练数据</h4><p>可结合图文信息进行知识联动识别，为医生提供中药材识别的辅助工具，减少用药错误的发生。</p><h4>4. 深度学习模型迁移学习训练</h4><p>可用于预训练或微调模型，增强模型对自然图像中药材的理解能力，为其他相关任务提供基础。</p><h4>5. 中药材跨模态研究</h4><p>可用于中文名称—图像联合建模、图文检索、图像标注等跨模态研究，推动中医药信息化的发展。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000046860383" alt="image-20250712145211757" title="image-20250712145211757"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000046860384" alt="image-20250712145359020" title="image-20250712145359020" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000046860385" alt="image-20250712145509920" title="image-20250712145509920" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000046860386" alt="image-20250712145520147" title="image-20250712145520147" loading="lazy"/></p><h3>模型训练建议</h3><p>针对本数据集的特点，我们提出以下模型训练建议：</p><ol><li><strong>模型选择</strong>：对于分类任务，可选择ResNet50、EfficientNet等模型；对于检测任务，建议使用YOLOv8、RT-DETR等最新模型。</li><li><strong>数据增强</strong>：建议使用随机裁剪、翻转、旋转、亮度调整等数据增强技术，提高模型的泛化能力。</li><li><strong>训练策略</strong>：采用小批量梯度下降法，初始学习率设置为0.001，根据验证集性能动态调整学习率。</li><li><strong>评估指标</strong>：使用准确率、精确率、召回率和F1-score等指标评估模型性能。</li></ol><h3>应用案例</h3><h4>案例一：中药识别App开发</h4><p>基于本数据集训练的模型，开发了一款中药识别App，用户只需拍摄中药材照片，即可快速获取药材名称、功效、用法等信息。该App已在多家中医院和药店试用，取得了良好的效果。</p><h4>案例二：中医药教学辅助系统</h4><p>将训练好的模型集成到中医药教学辅助系统中，学生可以通过系统识别中药材，加深对中药材的认识和理解，提高学习效率。</p><h4>案例三：中药材质量检测</h4><p>结合其他传感器数据，利用训练好的模型对中药材质量进行检测，识别药材的真伪和品质等级，为中药材的质量控制提供技术支持。</p><h3>结语</h3><p>中药文化源远流长，是中华民族的瑰宝。随着人工智能技术的不断发展，将其应用于中医药领域，实现中药材的智能识别，对于推动中医药现代化具有重要意义。本数据集立足实际拍摄与分类标准，旨在为研究者、开发者和中医药爱好者提供一份结构清晰、数据质量可靠、类别丰富的中药图像数据集，为中药AI识别迈出坚实一步。</p><p>我们希望通过本数据集的发布，能够促进中医药与人工智能的深度融合，推动中药材智能识别技术的发展和应用，为中医药现代化做出贡献。如需生成配套训练代码（如YOLOv8格式训练脚本）、中药图像识别模型部署方案，可以参考相关资源。</p><h3>参考资源</h3><ul><li><a href="https://link.segmentfault.com/?enc=zXzo%2BZs2viCXVlw4YLszFw%3D%3D.P70OY6pjvMwo6Z5%2FKPP0bVeqIaQ6Ql66YhCW1wZF59Y%3D" rel="nofollow" target="_blank">YOLOv8官方文档</a></li><li><a href="https://link.segmentfault.com/?enc=H4fHTfRe87i8dOUG1dfjpg%3D%3D.hFKsJE8wYb1T83QbSR8Wna3EF%2BV5GvySXvy8Nfceh2iCQ5gxFVSXIcmFCwRNiYVk" rel="nofollow" target="_blank">PyTorch官方文档</a></li><li><a href="https://link.segmentfault.com/?enc=kcwO9jm4IXv4ib1XiT2x%2FQ%3D%3D.UfQDwJ9BCASoX9VCBh9bFwzUzxyc2aGyHMV9T7ERKlw%3D" rel="nofollow" target="_blank">TensorFlow官方文档</a></li></ul><p>通过本数据集的使用和相关技术的应用，我们相信中药材智能识别技术将会取得更大的突破，为中医药事业的发展注入新的活力。</p>]]></description></item><item>    <title><![CDATA[金属材料表面六种缺陷类型数据集：工业视觉检测的优质训练资源 风筝 ]]></title>    <link>https://segmentfault.com/a/1190000047609826</link>    <guid>https://segmentfault.com/a/1190000047609826</guid>    <pubDate>2026-02-13 16:05:08</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>金属材料表面六种缺陷类型数据集：工业视觉检测的优质训练资源</h2><h3>数据集分享</h3><p>如需下载该数据集，可通过以下方式获取：</p><pre><code class="bash">https://pan.baidu.com/s/1eltE8ewS4V1ONDGubsYJ4g?pwd=skr8</code></pre><h3>引言</h3><p>在现代工业制造中，金属材料的表面质量直接影响产品的外观、性能和安全性。金属材料在轧制、热处理、运输及长期使用过程中，常会产生各类表面缺陷，如裂纹、划痕、氧化皮等。这些缺陷不仅降低产品的外观质量，更可能影响其强度、疲劳寿命甚至安全性能。因此，及时、准确地检测金属表面缺陷，对于保证产品质量、提高生产效率具有重要意义。</p><p>随着工业制造向自动化与智能化演进，基于深度学习的表面缺陷检测成为提升质量控制的重要手段。然而，高质量、标注规范的数据集一直是算法研究和应用落地中的瓶颈。为推动智能检测系统在实际场景中的应用，我们构建了一套面向学术与工业的金属缺陷数据集，包含6类典型缺陷，1800张图像，标注完整，已按<code>train/val/test</code>划分，并使用YOLO项目格式进行标注，适用于目标检测、缺陷分类与工业视觉相关任务。</p><h3>数据集概述</h3><p>本数据集聚焦于金属表面质量检测，涵盖了6类典型的金属表面缺陷，总计1800张高质量图像。所有图像均已完成标注，并按照训练集、验证集和测试集进行了合理划分，可直接用于深度学习模型的训练、验证和测试。</p><h4>基本信息</h4><ul><li><strong>图像总数</strong>：1800张（已完成标注）</li><li><strong>标注格式</strong>：YOLO格式（可与COCO格式相互转化）</li><li><strong>图像尺寸</strong>：统一为640×640（可自定义缩放）</li><li><p><strong>数据划分</strong>：</p><ul><li>训练集: 1260张</li><li>验证集: 360张</li><li>测试集: 180张</li></ul></li><li><strong>类别数量</strong>：6类</li></ul><h4>类别配置</h4><p>以下是数据集的类别配置（YOLO格式）：</p><pre><code class="yaml">nc: 6
names:
  0: crazing
  1: inclusion
  2: patches
  3: pitted_surface
  4: rolled-in_scale
  5: scratches</code></pre><h3>数据集结构</h3><p>本数据集采用标准的文件夹结构进行组织，具体如下：</p><pre><code class="plaintext">/train/
    └── images/
    └── labels/
/val/
    └── images/
    └── labels/
/test/
    └── images/
    └── labels/</code></pre><p>其中，<code>images</code>文件夹存放原始图像，<code>labels</code>文件夹存放对应的标注文件。标注文件采用YOLO格式，记录了缺陷的类别和位置信息。</p><h3>缺陷类型详情</h3><p>本数据集包含6类典型的金属表面缺陷，每类缺陷均有其独特的特征和形成原因。以下是各类缺陷的详细说明：</p><table><thead><tr><th>类别编号</th><th>类别名称</th><th>中文释义</th><th>特征描述</th></tr></thead><tbody><tr><td>0</td><td>crazing</td><td>裂纹/龟裂</td><td>表面微裂纹，形似龟壳裂纹，多因材料老化或热处理不均导致</td></tr><tr><td>1</td><td>inclusion</td><td>杂质夹杂</td><td>材料中混入非金属杂质，外观呈点状或条状暗斑，影响材料纯度</td></tr><tr><td>2</td><td>patches</td><td>表面块状斑痕</td><td>局部表面区域发生变色或质地异常，可能与氧化或油污有关</td></tr><tr><td>3</td><td>pitted_surface</td><td>凹坑/腐蚀点</td><td>表面形成小孔或点蚀，通常是腐蚀或加工缺陷的结果</td></tr><tr><td>4</td><td>rolled-in_scale</td><td>轧入氧化皮</td><td>热轧过程中氧化皮卷入表层形成异色斑块，边缘不规则</td></tr><tr><td>5</td><td>scratches</td><td>划痕</td><td>线性划痕，由硬物刮擦形成，深浅不一，走向基本一致</td></tr></tbody></table><p>所有缺陷都已使用边界框（bounding box）形式手动标注，标注精度高，适合用于YOLO全系列、Faster R-CNN、RT-DETR等检测模型的训练和评估。</p><h3>数据处理流程</h3><p>为确保数据集的质量和可用性，我们在构建过程中遵循了严格的数据处理流程，具体步骤如下：</p><pre style="display:none;"><code class="mermaid">flowchart TD
    A[数据采集] --&gt; B[图像预处理]
    B --&gt; C[缺陷标注]
    C --&gt; D[数据划分]
    D --&gt; E[格式转换]
    E --&gt; F[质量验证]
    F --&gt; G[数据集发布]</code></pre><ol><li><strong>数据采集</strong>：从工业生产现场采集金属表面缺陷图像，确保覆盖不同类型、不同严重程度的缺陷</li><li><strong>图像预处理</strong>：对采集到的图像进行清洗、去噪、尺寸统一等处理</li><li><strong>缺陷标注</strong>：采用人工标注的方式，使用边界框标记缺陷的位置和类别</li><li><strong>数据划分</strong>：按照7:2:1的比例划分为训练集、验证集和测试集</li><li><strong>格式转换</strong>：将标注结果转换为YOLO标准格式</li><li><strong>质量验证</strong>：对处理后的数据进行质量检查，确保标注的准确性和一致性</li><li><strong>数据集发布</strong>：打包发布数据集，提供下载链接</li></ol><h3>数据集特点</h3><p>本数据集具有以下显著特点：</p><ol><li><strong>标注规范</strong>：所有图像均采用人工标注，标注精度高，格式统一</li><li><strong>数据划分合理</strong>：按照7:2:1的比例划分为训练集、验证集和测试集，符合深度学习模型训练的常规要求</li><li><strong>缺陷类型典型</strong>：涵盖了6类典型的金属表面缺陷，基本覆盖了工业生产中常见的缺陷类型</li><li><strong>图像质量高</strong>：所有图像均为高质量采集，分辨率统一为640×640，便于模型训练</li><li><strong>格式标准</strong>：采用YOLO标准格式标注，可直接用于主流深度学习框架</li><li><strong>场景真实</strong>：图像均来自实际工业生产场景，具有较高的真实感和代表性</li></ol><h3>适用场景</h3><p>本数据集广泛适用于以下研究与工业应用：</p><h4>1. 工业缺陷检测模型训练</h4><p>可直接用于训练YOLOv5、YOLOv8、RT-DETR等检测模型，用于实际部署或研究验证。通过在本数据集上训练模型，可以实现对金属表面缺陷的自动检测和分类，提高检测效率和准确性。</p><h4>2. 缺陷分类与分割任务</h4><p>可对图像中心区域裁剪生成分类任务数据，或与语义分割工具配合进一步扩展。例如，可以将缺陷区域裁剪出来，构建分类数据集，用于训练专门的缺陷分类模型；也可以将边界框标注转换为像素级标注，用于语义分割任务。</p><h4>3. 算法对比与论文验证</h4><p>适合用于不同检测网络的性能评估，支持标准化训练流程，有利于模型泛化性对比。研究人员可以在本数据集上测试不同算法的性能，进行公平的比较和分析。</p><h4>4. 图像增强与合成学习研究</h4><p>图像背景多样、缺陷类型复杂，适合作为生成对抗网络（GAN）或图像增强算法的输入。通过对数据集进行图像增强，可以扩展数据集规模，提高模型的泛化能力；也可以用于研究缺陷图像的合成方法，进一步丰富数据集。</p><h4>5. 工业自动化质检系统开发</h4><p>可集成至边缘计算设备，实现对流水线上的金属件在线检测与报警。通过将训练好的模型部署到边缘设备，可以实现实时、高效的缺陷检测，减少人工干预，提高生产效率和产品质量。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000046856498" alt="image-20250710185629776" title="image-20250710185629776"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000046597730" alt="image-20250530103542576" title="image-20250530103542576" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000046597733" alt="image-20250530102805805" title="image-20250530102805805" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000046597734" alt="img" title="img" loading="lazy"/></p><h3>模型训练建议</h3><p>针对本数据集的特点，我们提出以下模型训练建议：</p><ol><li><strong>模型选择</strong>：对于目标检测任务，建议使用YOLOv8、RT-DETR等最新模型，这些模型在精度和速度上都有较好的表现。</li><li><strong>数据增强</strong>：建议使用随机裁剪、翻转、旋转、亮度调整、对比度调整等数据增强技术，提高模型的泛化能力。</li><li><strong>训练策略</strong>：采用小批量梯度下降法，初始学习率设置为0.001，使用余弦退火策略调整学习率。</li><li><strong>评估指标</strong>：使用精确率、召回率、F1-score和mAP等指标评估模型性能，综合考虑模型的检测效果。</li><li><strong>模型优化</strong>：可以采用模型剪枝、量化等技术，减少模型大小，提高推理速度，便于在边缘设备上部署。</li></ol><h3>应用案例</h3><h4>案例一：钢铁生产线上的缺陷检测</h4><p>某钢铁企业将基于本数据集训练的模型部署到生产线上，实现了对钢板表面缺陷的实时检测。系统能够在钢板生产过程中自动检测出裂纹、划痕等缺陷，并及时报警，大大提高了检测效率和准确性，减少了人工成本。</p><h4>案例二：汽车零部件质量控制</h4><p>某汽车零部件制造商使用本数据集训练的模型，对汽车车身钢板的表面缺陷进行检测。通过在生产线上安装摄像头和边缘计算设备，实现了对零部件表面缺陷的自动检测，确保了产品质量，降低了不合格品率。</p><h4>案例三：研究算法性能对比</h4><p>某研究机构使用本数据集对多种目标检测算法进行了性能对比，包括YOLOv5、YOLOv8、Faster R-CNN等。通过实验分析，他们发现YOLOv8在检测精度和速度上都有较好的表现，适合用于实时检测场景。</p><h3>数据集扩展与未来规划</h3><p>本数据集是我们在金属表面缺陷检测领域的初步尝试，未来我们计划从以下几个方面对数据集进行扩展和完善：</p><ol><li><strong>增加缺陷类型</strong>：进一步扩展缺陷类别，涵盖更多工业生产中常见的金属表面缺陷</li><li><strong>扩大数据集规模</strong>：增加图像数量，提高数据集的多样性和代表性</li><li><strong>添加多模态标注</strong>：加入语义分割、实例分割等多模态标注形式，支持更复杂的检测与识别任务</li><li><strong>引入更多场景</strong>：收集不同材质、不同工艺、不同环境下的金属表面缺陷图像，提高模型的泛化能力</li><li><strong>提供预训练模型</strong>：基于扩展后的数据集，训练并发布预训练模型，方便用户直接使用</li></ol><h3>结语</h3><p>本数据集通过系统性地收集、整理和标注金属材料表面六类典型缺陷，填补了工业视觉领域在金属表面缺陷检测方向公开数据资源的空白。其在样本多样性、标注精度和场景适配性方面具有显著优势，不仅可作为深度学习算法的训练基准，也适用于真实工业质检系统的部署验证。</p><p>我们希望通过本数据集的发布，能够促进工业视觉检测技术的发展，推动智能制造与视觉质检技术的落地应用。我们诚邀学术界与工业界的研究者在此基础上深入探索，共同推动金属表面缺陷检测技术的进步，为工业制造的高质量发展做出贡献。</p><p>通过本数据集的使用和相关技术的应用，我们相信金属表面缺陷检测技术将会取得更大的突破，为工业制造的质量控制提供更加强有力的支持。</p>]]></description></item><item>    <title><![CDATA[国内企业使用最多的SRM系统是哪几个品牌？首席技术官深度选型指南 SaaS圈老马 ]]></title>    <link>https://segmentfault.com/a/1190000047609829</link>    <guid>https://segmentfault.com/a/1190000047609829</guid>    <pubDate>2026-02-13 16:04:18</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在制造业数字化转型的深水区，SRM的选型早已超出简单采购工具的范畴。作为在SRM与数字化采购领域深耕20年的从业者，我见证了企业采购从人工方式走向ERP系统，再到今天的独立平台化的演进过程。很多CTO在选型时会被品牌知名度牵着走，从而忽略了底层架构与企业业务演进的匹配度。<strong>尤其在供应链风险频发的背景下，一套成熟的SRM应当成为企业的供应协同引擎，而不是一个漂亮但封闭僵化的预制套件。</strong><br/>基于艾瑞咨询《2024年中国采购数字化平台行业研究报告》等第三方机构的行业洞察，采购数字化平台正向“自动化、智能化”演进。报告详细探讨了“低代码/零代码”、“iPaaS”以及“AI赋能”在SRM领域的关键作用，这些技术正成为衡量厂商底座能力的核心指标。下面先从CTO最关心的维度做直观对比，再逐一展开分析。</p><h3>一、一个表格读懂三大类SRM服务商</h3><p>在深入分析各品牌前，我们需要从CTO关心的维度对这三大类做直观对比。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047609831" alt="图片" title="图片"/></p><h3>二、平台定制型：追求架构底座的生命力</h3><p>这类厂商适合业务逻辑复杂、希望系统能持续进化的巨型企业。推荐对象是那种愿意把SRM当作长期数智化底座的公司。</p><h4>1、<a href="https://link.segmentfault.com/?enc=%2F3iCjXFmWsOdmnvJ934%2B3w%3D%3D.xv21Ch%2ByoqKv9EpGIJ9BW0Rqw2C2W%2FJexg%2BfMn0xCMU%3D" rel="nofollow" target="_blank">正远科技</a></h4><p>成立于2002年，是低代码驱动的平台化专家。它的核心优势在于把业务逻辑和系统实现解耦，允许可视化建模和快速迭代。由此带来的好处很直观：开发周期大幅缩短，业务方能拿到的是一个可持续生长的系统，而不是上线就过时的产品。正远还在AI能力和信创适配上投入很多。比如发票识别、供应商风险侦测和合同合规比对等，都已经工具化。<br/>对于注重数据主权并要求私有化部署的企业，正远对信创生态的支持是显著优势。其客户包括魏桥创业、南山集团和威高集团，能在复杂场景下体现出底层理解能力。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047609832" alt="图片" title="图片" loading="lazy"/></p><h3>三、ERP延伸型：强调生态一致性与合规</h3><p>这类产品更适合业务流程比较标准、并且已经深度绑定某套ERP的企业。它们的价值在于和现有财务、供应链系统天然打通，降低合规与对账的摩擦。</p><h4>1、用友</h4><p>在大型集团中普及度极高，它的优势在于业财一体化，适合把财务合规和供应链管理放在同一治理框架下的企业。用友在电子招投标和合规实践方面有丰富经验，适合把合规作为首要诉求的公司。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047609833" alt="图片" title="图片" loading="lazy"/></p><h4>2、金蝶</h4><p>侧重协同与轻量应用，近年通过AI产品线在制造业展现出竞争力。金蝶强调社交化协同与低门槛供应商接入，利用微信等渠道提高供应商响应效率。在需要管理大量中小供应商，或研发变更频繁的电子制造企业，金蝶的PLM与SRM结合模式表现稳健。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047609834" alt="图片" title="图片" loading="lazy"/></p><h3>四、专业垂直型：以速度优先，解决当下问题</h3><p>如果企业的采购并不直接影响核心生产，只是希望先把流程跑顺，或者需要在较短时间内看到效果，那么专业垂直型SRM往往更现实。这类厂商主打标准化SaaS，优势不在“复杂能力”，而在于交付速度。对互联网、快消，以及正在试点数字化采购的企业来说，这是一个低风险的切入口。</p><h4>1、甄云科技</h4><p>甄云是国内较早将SRM做成标准化SaaS的厂商之一。它在界面设计和流程完整度上比较成熟，上手成本低。甄云的一个典型特点是引入了采购商城模式，能够直接对接京东、苏宁等第三方平台。对于间接物料和行政类采购，这种模式效率很高，往往能在较短周期内看到管理成效。当然，它更适合通用场景，而不是深度定制。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047609835" alt="图片" title="图片" loading="lazy"/></p><h4>2、企企通</h4><p>企企通的产品思路更偏向互联网化，强调协同体验和移动端使用感受。它围绕采购人的日常操作习惯做了不少优化，在审批流转和跨部门协同上比较顺畅。同时，企企通在供应链金融等延展能力上投入较多，适合追求敏捷管理、组织结构相对扁平的企业。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047609836" alt="图片" title="图片" loading="lazy"/></p><h3>五、CTO在选型时关注的三个问题</h3><p>当选型进入后半程，技术团队往往已经看过大量方案。这时困扰CTO的，通常不是功能多少，而是一些更底层、更现实的取舍问题。</p><h4>Q1：如何平衡快速上线和长期可扩展性？</h4><p>如果企业的采购流程还在摸索阶段，主要覆盖办公用品或非生产物资，那么专业垂直型SaaS是性价比最高的选择，三个月内看到ROI并不罕见。但如果SRM管理的是核心生产物料，涉及BOM频繁调整、供应商分级和绩效考核，这类系统往往很快触顶。从长期看，平台定制型虽然前期投入更高，但低代码架构能支撑持续迭代，避免几年后被迫推倒重来。</p><h4>Q2：已有SAP或Oracle，集成难度该怎么看？</h4><p>信息孤岛是CTO普遍焦虑的问题。ERP延伸型产品在自家体系内集成顺畅，但一旦涉及多套异构系统，灵活性反而受限。独立的平台型厂商在这方面通常更有经验，比如通过集成适配器处理复杂的主数据和业务同步。建议在选型阶段要求厂商做真实接口演示，现场拉通旧系统，而不是只看方案文档。</p><h4>Q3：信创私有化部署是否意味着运维压力陡增？</h4><p>在当前合规环境下，私有化部署已经成为不少中大型制造企业的标配。私有化部署虽然需要额外的算力和运维投入，但在现代架构的帮助下复杂度已经显著降低。基于容器和流程引擎的系统，运维已经可以做到模块化和精细化管理。对技术团队来说，这种投入换来的，是对核心数据和业务逻辑的完全掌控。</p><h3>六、CTO在选型时绕不开的三条逻辑</h3><p>从行业发展趋势来看，SRM正从单一流程工具，演进为企业级数智化平台。CTO在做最终决策时，建议回到以下三个核心判断。</p><h4>1、部署模式的取舍</h4><p>对于中大型制造企业，私有化部署仍然更稳妥。SaaS 上线速度快，但在复杂集成和安全控制方面弹性有限。私有化部署虽然前期投入更高，却能为长期扩展留出空间。</p><h4>2、集成能力是否经得起实战考验</h4><p>SRM的价值在于连接，而不是孤立存在。是否具备对接SAP、Oracle等主流ERP的真实案例，比功能列表更重要。选型时一定要看实操，而不是听承诺。</p><h4>3、低代码是否真正可用</h4><p>采购流程不会一成不变。如果每次调整都需要厂商改底层代码，系统的长期成本会迅速失控。成熟的低代码底座，能把变化留在企业内部消化，这是很多CTO后期才意识到的关键点。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047609837" alt="图片" title="图片" loading="lazy"/></p><h3>七、我们的建议</h3><p>整体来看，国内SRM市场已经形成清晰分层。希望系统具备持续演进能力，并对信创和复杂制造场景有要求的企业，可以重点关注正远科技。强调合规和业财一体化的集团型企业，用友和金蝶依然是稳妥选择。而在轻量化采购、商城联动和快速交付方面，甄云和企企通具备明显优势。<br/>SRM的选型，本质上是在为企业选择一个可以陪跑多年的数字化底座。从CTO的角度看，能随着业务一起成长的系统，才是真正值得长期投入的技术资产。</p>]]></description></item><item>    <title><![CDATA[中国版“龙虾”重磅发布！立即领取限免“枫清龙虾新春码” Fabarta ]]></title>    <link>https://segmentfault.com/a/1190000047609845</link>    <guid>https://segmentfault.com/a/1190000047609845</guid>    <pubDate>2026-02-13 16:03:28</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609847" alt="微信图片_20260213092724_2808_3.jpg" title="微信图片_20260213092724_2808_3.jpg"/><br/>最近，当红AI 助手 OpenClaw “龙虾”（原名 MoltBot、ClawdBot）以燎原之势席卷全球开发者社区，开启了全新的 “全职 AI 员工” 时代。然而，当自动化能力的获取不再是高门槛，如何让 AI 在高效执行任务的同时，始终将控制权交还给人，成为行业新的挑战 —— 理想的智能体，应当既能深入本地系统流畅操作，又能在每一个关键节点等待人工确认，让数据主权与操作可控成为默认配置。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047609848" alt="微信图片_20260213103134_2850_3.jpg" title="微信图片_20260213103134_2850_3.jpg" loading="lazy"/></p><h3>枫清科技重磅推出Fabarta 个人专属智能体龙虾版</h3><p>当海外用户纷纷尝试OpenClaw 本地部署方法，以此保障数据与操作的可控性时，枫清科技正式推出 Fabarta 个人专属智能体龙虾版，让每个人都能拥有“更懂你、更安全” 的专属 AI 助手。</p><h3>扎根本地的高效办公超级助手</h3><p>这款面向办公与个人生产力的本地智能体，支持文件与应用协作、可审计的本地工具调用，并能通过本地记忆能力持续适配用户的使用习惯。与此同时，个人专属智能体龙虾版的本地知识库能力，沿用了深度打磨的企业级解析器，同时搭载经过链路调优的技术架构，让知识检索更精准、更全面。</p><p>而这些高效办公能力的落地，均依托其底层架构确立的本地执行核心原则。Fabarta 个人专属智能体龙虾版并非一个简单的聊天助手，而是真正在用户设备上运行的超级助手。基于 OpenClaw 沉淀的本地执行框架，它能够直接操作用户的文件系统、浏览器和各类应用，自动完成文件整理、流程任务执行等复杂操作。</p><h3>本地执行+ 人工终审 掌控终极决策权</h3><p>更重要的是，所有数据处理均在本地完成，配合白名单权限管理和全程可审计机制，每一次操作都留有痕迹，关键步骤需人工确认，用户既能享受AI 自动化带来的高效体验，又能牢牢掌握人工的终极决策权。</p><h3>多办公场景的自动化实践</h3><p>这种“本地执行 + 人工终审” 的设计理念，在真实办公场景中有着直观且丰富的体现。当用户面对复杂的项目资料，只需一句话指令，Fabarta 个人专属智能体龙虾版就能在本机自动完成分类归档，按项目和资产类型建立清晰的文件库，生成总索引和资产盘点表，整个过程仅写入指定的 Outbox 文件夹，每一步操作都可审计、可追溯。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609849" alt="图片2.png" title="图片2.png" loading="lazy"/></p><p>当用户面对繁杂的邮件回复需求，个人专属智能体龙虾版能自动读取收件箱、拟写回复，甚至自动打开邮箱客户端，但会明确停在发送前的最后一步，等待用户检查确认。用户无需担心AI 越权操作，因为所有动作全程留痕，截图、时间线、操作轨迹（trace）均可回放，形成完整的操作证据包。</p><p>对于需要运营社媒账号的用户，个人专属智能体龙虾版能将本地素材自动转化为小红书、公众号等平台的图文草稿，自动填充内容和配图，且仅保存草稿而不进行群发，让用户牢牢掌握内容最终发布权。</p><h3>越用越懂的个性化私人助理</h3><p>除了具备强大的自动化执行能力，个人专属智能体龙虾版更像一位越用越懂你的专属私人助理。它内置本地个人记忆库，能够持续理解用户的使用习惯，基于企业级知识库解析能力，对个人文件资料形成长期语义记忆。它会针对用户的常用术语、项目背景、文件路径及个人偏好，在本机逐步构建起可控的长期记忆体系，实现更精准、更全面的知识检索与复用。</p><p>这份“越用越懂” 的使用体验，得益于枫清科技将企业级 RAG 能力下沉至个人场景，配合可配置的私有模型部署方案与云边端协同架构，既保证了个人数据的隐私安全，又能根据用户需求灵活调用云端能力。</p><h3>全系统适配 + 多场景平台拓展</h3><p>值得一提的是，这一架构已深度融入主流操作系统生态—— 通过与 macOS、麒麟操作系统的深度适配，Fabarta 个人专属智能体龙虾版将企业级安全管控与本地化处理能力成功延伸至个人终端。其中，Fabarta 携手 Mac 生态推出的企业级 AI 解决方案，以 Mac Studio为核心构建企业知识中台（EKC），协同终端Mac mini上的个人专属智能体龙虾版，既释放 “开箱即用” 的本地 AI 生产力价值，又实现 “数据不出域” 的精细权限控制；联合麒麟生态打造的信创桌面个人智能体解决方案，更是依托麒麟 KART 系统级 AI 底座承载端侧模型，让敏感数据全程在本地闭环处理。</p><p>除了完成主流操作系统的深度适配，让本地执行能力落地各类终端，个人专属智能体龙虾版还在模型部署与平台搭建层面实现了全维度拓展。除云端大模型外，枫清科技还提供本地模型一体机方案及企业智能体平台，实现从个人助手到集团系统的全场景覆盖。</p><h3>枫清龙虾新春码限时免费申领</h3><p>目前，枫清科技官网已开启“枫清龙虾新春码” 限时发放活动，春节期间每天上午 10:00-10:30 限量释放免费体验名额。用户领取 “新春码” 后即可激活使用，体验期结束后可购买权益包继续享受服务。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609850" alt="图片4.png" title="图片4.png" loading="lazy"/></p><p>即刻登录枫清科技官网（<a href="https://link.segmentfault.com/?enc=duY2YGLUt5%2BHO60Ac5PnnA%3D%3D.4oHSMrIm5x%2FPNS97f8J6U%2B0KaIEgoO%2FQDXOat9Ltcgg%3D" rel="nofollow" target="_blank">https://fabarta.com/my-agent</a>）下载Fabarta 个人专属智能体，把工作放心交给你的 “个人超级智能体”！</p>]]></description></item><item>    <title><![CDATA[赋能某跨境智慧物流：基于 AWS Graviton 的全栈数据平台实现 25% 成本节省 数新智能 ]]></title>    <link>https://segmentfault.com/a/1190000047609878</link>    <guid>https://segmentfault.com/a/1190000047609878</guid>    <pubDate>2026-02-13 16:02:53</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>某跨境智慧物流集团是跨境物流与供应链数字化解决方案的行业领导者。为应对海量物流数据实时处理、全球化部署与成本效益持续优化等挑战，该客户携手数新智能，在亚马逊云科技（AWS）上完成核心数据平台的战略性重构。</p><p>本次项目的核心亮点为：全栈采用基于 AWS 自研芯片 Graviton 的实例，并部署数新云智能原生数据底座 CyberEngine，旨在打造兼具极致性价比、卓越性能与全球敏捷性的下一代数据基础设施。</p><p><strong>关于客户</strong></p><p><strong>在海量数据中寻求效率与成本的平衡</strong></p><p>该客户全球化业务每天产生并处理 TB 级的物流轨迹、仓储库存与交易数据。原有架构面临三大核心挑战：</p><ul><li><strong>计算成本高：</strong> 数据处理资源消耗巨大，传统 x86 计算实例的高昂成本成为业务扩张的沉重负担。</li><li><strong>实时分析瓶颈：</strong> 物流状态追踪、智能调度等场景对实时性要求严苛，原有系统难以支撑毫秒级响应的数据服务与高并发分析。</li><li><strong>架构敏捷性不足：</strong> 随着业务在全球快速布局，数据平台需要在多区域实现快速部署、一致体验与弹性伸缩，同时保持技术栈的先进性与开放性。</li></ul><p>客户需要的不只是一次简单的云迁移，更是一次从底层芯片到顶层应用、旨在获得长期竞争优势的架构革新。</p><p><strong>客户挑战</strong></p><h4><strong>基于 AWS Graviton 的全栈深度优化</strong></h4><p>数新智能的解决方案核心，是将 AWS Graviton 处理器的原生优势 与 CyberEngine 数据底座的云原生能力进行深度耦合，实现从硬件到软件的全栈协同优化。</p><p><strong>数新智能的全栈实施路径</strong></p><ul><li><strong>全栈 Graviton 化：</strong> 将该客户数据平台的所有计算节点，包括 CyberData 平台应用层、CyberEngine 底座的 Spark、Flink 计算集群，以及 StarRocks 实时分析引擎，全部部署在 AWS Graviton3/Graviton4 实例上。这为整个平台奠定了高性价比的基石。</li><li><strong>云原生数据底座落地：</strong> 部署数新智能 CyberEngine云原生数据底座。该底座并非简单集成开源组件，而是针对 Graviton 环境深度优化 Spark（批处理）、Flink（流计算）与 StarRocks（实时分析）的运行时与调度策略，充分释放 ARM 架构每瓦特性能优势。</li><li><strong>智能混合调度与优化：</strong> 通过数新智能统一任务调度引擎，结合物流数据管线的特性（实时事件流、离线批量报表、即时交互查询），智能将任务分发至不同 Graviton 实例类型支撑的最优计算集群中，实现资源利用率最大化。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609880" alt="图片" title="图片"/></p><p><strong>解决方案</strong></p><p><strong>建立全链路数据血缘与质量标准</strong></p><p>我们为客户构建的架构，充分利用了 Graviton 实例家族（如计算优化型 C7g/C6g、内存优化型 R8g/R7g）的特性，形成了高效、弹性的数据处理流水线。</p><p><strong>核心 AWS 技术特性的场景化落地</strong></p><p>我们深度结合亚马逊云科技的原生服务能力，精准解决客户的业务痛点，实现技术价值最大化：</p><ul><li><strong>统一接入与实时计算：</strong> 全球物流事件流通过 统一数据集成引擎实时摄入。Flink on Graviton 集群充分发挥 Graviton 高内存带宽、低延迟的优势，对订单状态、车辆位置等流数据进行毫秒级处理与关联分析，为实时追踪看板提供支撑。</li><li><strong>批量计算与数据湖加工：</strong> 海量历史日志与事务数据存储在 Amazon S3 中。Spark on Graviton 集群执行复杂的 ETL 与数据建模任务。借助Graviton 实例高核心密度及大缓存特性（如 Graviton5 提供 5 倍于前代的 L3 缓存），大规模数据扫描与聚合作业效率显著提升。</li><li><strong>实时分析与数据服务：</strong> 处理后的聚合结果与特征数据同步至 StarRocks on Graviton 构建的实时数仓。依托 Graviton 处理器优化的单核性能与整体吞吐量，复杂多表关联查询、多维分析均实现亚秒级响应，高效赋能运营人员即席分析与决策。</li><li><strong>全局智能化治理：</strong> 统一元数据服务贯穿数据全生命周期，基于 Graviton 实例的高效计算能力，快速构建并维护全链路数据血缘与资产目录，保障数据质量与安全合规。</li></ul><p><strong>项目价值</strong></p><p>通过全栈部署 AWS Graviton 与数新智能 CyberEngine 的深度融合优化，该跨境智慧物流集团的新数据平台取得了远超预期的核心成效：</p><p><strong>成本效益显著优化</strong></p><p>整体计算成本降低 25% 以上。这得益于 Graviton 实例卓越的性价比优势，以及 CyberEngine 弹性伸缩能力对资源的精细化管控，实现成本与效率的平衡。</p><p><strong>处理性能全面跃升</strong></p><ul><li>实时计算延迟从分钟级降至秒内，精准满足全球化物流事件实时监控需求；</li><li>大型夜间批处理作业窗口时间平均缩短 30%，为业务预留更充足的分析缓冲期；</li><li>运营分析平台复杂查询响应速度提升数倍，用户决策效率与使用体验同步改善。</li></ul><p><strong>架构敏捷性与可持续性双赢</strong></p><p>云原生架构与 Graviton 的深度结合，使新区域数据平台部署周期缩短 70%，大幅提升全球业务扩张效率。同时，Graviton 的高能效特性，助力客户降低单位计算任务的碳排放，在技术创新中践行企业社会责任。</p><p>该客户的实践清晰地证明，在数据驱动决策的时代，基础设施的先进性是业务创新的关键引擎。数新智能通过将 自研的云原生数据底座CyberEngine 与 业界领先的 AWS Graviton 自研芯片 进行全栈深度集成，不仅解决了客户在成本与性能上的燃眉之急，更为其构建了面向未来的数据核心竞争力。</p><p>我们深信，真正的技术价值，在于将底层硬件的强大潜力，通过领先的软件平台转化为切实的业务成果。数新智能愿与更多的全球化企业携手，从芯片到架构，重塑数据生产力，驭“数”前行，智领全球。</p>]]></description></item><item>    <title><![CDATA[2026AI医疗行业专题报告：智能医疗器械、手术机器人、脑机接口、可穿戴设备|附240+份报告PDF]]></title>    <link>https://segmentfault.com/a/1190000047609893</link>    <guid>https://segmentfault.com/a/1190000047609893</guid>    <pubDate>2026-02-13 16:02:12</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>原文链接：<a href="https://link.segmentfault.com/?enc=OdWYc5iBcH969YpO2al61Q%3D%3D.wcD9rPYWeX9Hrc6fy7GDhaXJxZY8muqCdNGtkUoHQYg%3D" rel="nofollow" title="https://tecdat.cn/?p=44979" target="_blank">https://tecdat.cn/?p=44979</a>  <br/>原文出处：拓端抖音号@拓端tecdat</p><h2><a name="t1" target="_blank"/><img referrerpolicy="no-referrer" src="/img/remote/1460000047609895" alt="封面" title="封面"/></h2><h3><a name="t2" target="_blank"/>引言</h3><p>医疗健康行业正经历由AI与智能化技术驱动的系统性革新，手术机器人的毫米级精准操作、脑机接口的神经功能调控、可穿戴设备的全周期健康监测、AI辅助诊断的高效赋能，正从诊断、治疗、康复等全链条重构医疗服务模式。本报告洞察基于《浙商证券：医疗器械创新系列行业报告（一）：手术机器人五问五答》《国信证券：人工智能行业专题：OpenAI发布医疗健康Gpt，开启AI医疗新时代》《中国信通院：智能化医疗装备产业蓝皮书（2025年）》《华创证券：脑机接口行业：政策加码，临床加速，产业化进入关键阶段》等多份行业研究报告及数据，系统梳理全球及中国智能医疗领域的市场规模、核心赛道、技术趋势与商业化路径。</p><p>报告聚焦手术机器人、脑机接口、可穿戴医疗设备、AI医疗应用四大核心领域，深度拆解高增长背后的驱动逻辑，为创业者、投资者、医疗机构从业者、医疗器械企业从业者提供可落地的决策参考。文末<strong>240+份</strong>AI医疗与智能医疗器械行业研究报告及数据，本文完整报告数据图表和文末最新参考报告合集已分享在交流群，阅读原文查看、进群咨询，定制数据、报告和800+行业人士共同交流和成长。</p><h3><a name="t3" target="_blank"/>一、智能医疗：从技术萌芽到规模化爆发的进化之路</h3><h4><a name="t4" target="_blank"/>1.1 行业演进脉络</h4><p>医疗智能化的发展并非一蹴而就，而是经历“工具普及-数字化升级-智能化生态”的三阶进化：</p><ul><li>萌芽期（基础电子阶段）：以水银血压计、玻璃体温计为代表，首次将健康检测场景从医院延伸至家庭，但产品功能单一、数据孤立，仅能满足基础测量需求；</li><li>成长期（数字化阶段）：传感器与移动互联网技术突破，蓝牙、Wi-Fi实现健康数据实时同步，产品从“单点测量”升级为“数据记录”，为健康管理数字化奠定基础；</li><li>爆发期（智能化生态阶段）：AI、物联网、大数据技术成熟，设备升级为“数据采集-分析预警-远程协同”的综合健康终端，手术机器人、脑机接口等复杂装备从实验室走向临床，AI医疗应用渗透诊断、治疗、康复全场景，行业价值链持续拉长。</li></ul><h4><a name="t5" target="_blank"/>1.2 核心驱动因素</h4><ul><li>需求端：人口老龄化与慢病高发催生刚性需求。2024年中国65岁及以上人口达2.20亿，成人高血压患者约2.45亿、糖尿病患者1.48亿，庞大的慢病人群推动院外监测与居家治疗市场持续扩容；</li><li>政策端：“健康中国2030”“人工智能+”行动等政策持续加码，医保支付改革推动家用器械深度融入医疗服务体系，为行业规模化落地提供政策保障；</li><li>技术端：AI算法、高精度传感器、柔性电子等核心技术突破，使设备更精准、便携、智能，破解了传统医疗设备“精准度不足、场景适配性弱”的痛点。</li></ul><h4><a name="t6" target="_blank"/>1.3 核心市场规模：高增长赛道的量化图景</h4><p>中国智能医疗领域呈现“低渗透率+高成长性”的双重特征，多个细分赛道增速领跑全球：</p><h5>1.3.1 健康监测领域：存量渗透+增量创新双轮驱动</h5><p>健康监测作为居家健康管理的核心入口，涵盖血压计、血糖仪、可穿戴设备等产品。其中，全球可穿戴设备市场规模达286亿美元，中国市场规模45.3亿美元；而高血压患者家庭血压计拥有率仅45.3%，存量设备渗透空间广阔；连续血糖监测（CGM）作为创新品类，中国市场规模达17.3亿元，正推动血糖管理从“点状测量”向“连续监测”升级。  <br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047609896" alt="" title="" loading="lazy"/>  <br/>健康监测市场关键指标横向条形图表1数据EXCEL及图表PDF模板已分享到会员群  <br/>3秒解读：健康监测市场呈现“存量设备渗透不足，增量技术爆发”的格局，CGM等创新产品是未来增长核心。  <br/>行动建议：对创业者，可聚焦CGM等高增长细分领域，布局低成本、高精准度的产品；对医疗机构，可引入智能监测设备构建慢病管理闭环。</p><h5>1.3.2 治疗科技前沿领域：国产替代+出海加速共振</h5><ul><li>手术机器人：全球市场规模达212亿美元，中国市场72亿元，虽仅占全球5%但增速迅猛，2024-2032E CAGR约34%；</li><li>脑机接口：作为新兴赛道，全球市场规模19.8亿美元，中国17.3亿元，2023-2029E CAGR35.1%，政策加码与临床加速推动产业化进入关键阶段。  <br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047609897" alt="" title="" loading="lazy"/>  <br/>脑机接口与手术机器人市场对比灰底比例条形图表2数据EXCEL及图表PDF模板已分享到会员群  <br/>3秒解读：中国在手术机器人、脑机接口领域与全球差距逐步缩小，本土化应用潜力巨大。  <br/>行动建议：投资者可关注具备技术壁垒的国产龙头企业；医疗机构可试点引入成熟手术机器人，提升诊疗精准度。</li></ul><h5>1.3.3 行业规范化：注册数量爆发印证规模化趋势</h5><p>政策与技术的共振，推动中国智能医疗装备注册数量迎来爆发式增长。2020-2024年第三类AI医疗装备年注册数量从9项增至32项，累计上市产品超百款，与可穿戴设备20%以上的高增长率形成呼应，印证行业已进入规模化、规范化发展的快车道。  <br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047609898" alt="" title="" loading="lazy"/>  <br/>中国AI医疗装备注册数量增长折线图表3数据EXCEL及图表PDF模板已分享到会员群  <br/>3秒解读：AI医疗装备注册门槛逐步明晰，行业从野蛮生长转向规范发展。  <br/>行动建议：企业需加快核心产品的注册申报，抢占市场先机；监管机构可进一步优化审评流程，平衡创新与安全。</p><h5>1.3.4 出海表现：高端化拓展成效显著</h5><p>中国医疗产品出海呈现“基础品类稳增+高端设备突破”的特征。2025年1-2月巴西对中国主要医疗产品进口同比增长迅猛，维生素及衍生物增长率达88.20%，医用仪器及器具达14.50%，表明中国医疗供应链在满足新兴市场基础需求的同时，正向高附加值产品拓展。  <br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047609899" alt="" title="" loading="lazy"/>  <br/>巴西进口中国医疗产品同比增长率横向条形图表4数据EXCEL及图表PDF模板已分享到会员群  <br/>3秒解读：中国医疗产品出海呈现“原料药与高端设备双增长”特征，新兴市场需求旺盛。  <br/>行动建议：出口企业可重点布局巴西等新兴市场，优化维生素、医用仪器等优势产品的供应链；同时关注当地法规与认证要求，降低出海风险。</p><h5>1.3.5 专利布局：数量领先但全球化不足</h5><p>中国已成全球医疗健康创新核心，2019-2025年医疗健康专利占比达52.4%，但域外专利占比仅4.2%；美国PCT国际专利占比34.9%，域外专利占比35.4%，显示美国创新主体更擅长全球化专利布局，中国企业在国际专利保护上仍需加强。  <br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047609900" alt="" title="" loading="lazy"/>  <br/>中美医疗健康专利布局对比灰底比例条形图表5数据EXCEL及图表PDF模板已分享到会员群  <br/>3秒解读：中国医疗健康专利数量全球领先，但全球化布局不足，出海面临专利风险。  <br/>行动建议：企业出海前应完善目标市场专利布局，尤其是PCT国际专利申请；政府可加大对国际专利申请的资金支持与政策引导。</p><hr/><p><strong>相关文章</strong><img referrerpolicy="no-referrer" src="/img/remote/1460000047609901" alt="" title="" loading="lazy"/></p><h3><a name="t7" target="_blank"/>专题：2025年游戏科技的AI革新研究报告：全球市场趋势研究报告|附130+份报告PDF、数据仪表盘汇总下载</h3><p>原文链接：<a href="https://link.segmentfault.com/?enc=UZXYq16Z%2FHkOB2zPnhREUA%3D%3D.j4zMHZMjw1udoblE3HDBYavSO9dk7M3XKmWt7Ey0qpo%3D" rel="nofollow" title="https://tecdat.cn/?p=44082" target="_blank">https://tecdat.cn/?p=44082</a></p><hr/><h3><a name="t8" target="_blank"/>二、核心赛道深度解析：技术突破与商业化路径</h3><h4><a name="t9" target="_blank"/>（一）AI医疗：千亿市场的场景渗透与支付逻辑</h4><p>中国医疗AI市场规模已突破千亿，其中基层CDSS（临床决策支持系统）市场规模17.41亿元，院内AI应用市场规模224.4亿元，未来十年均将保持20%以上复合高增速。</p><h5>1. 场景渗透特征：诊断优先，多场景协同</h5><p>AI技术已深度渗透智能问诊、医学图像处理、健康监测、康养养老四大场景，其中智能问诊专利渗透率67.2%，医学图像处理55.1%，成为技术应用高地。  <br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047609902" alt="" title="" loading="lazy"/>  <br/>AI医疗应用场景专利渗透率灰底比例条形图表6数据EXCEL及图表PDF模板已分享到会员群  <br/>3秒解读：AI在医疗场景的渗透呈现“诊断优先、多场景协同”特征，智能问诊与影像处理是核心突破口。  <br/>行动建议：软件企业可聚焦高渗透率场景迭代产品，提升算法准确率；医疗机构可先在影像科、问诊中心试点AI工具，降本增效。</p><h5>2. 企业专利布局：平台型vs传统巨头差异化竞争</h5><p>全球主要企业在专利布局上呈现分化：平安集团在医学图像、康养养老、智能问诊等多场景均占据首位，展现平台化布局野心；飞利浦、西门子等传统医疗巨头则固守健康监测、医学影像等优势领域，构筑技术护城河。  <br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047609903" alt="" title="" loading="lazy"/>  <br/>全球主要企业医疗AI专利持有量热图表7数据EXCEL及图表PDF模板已分享到会员群  <br/>3秒解读：头部企业专利布局分化，平台型企业全场景覆盖，传统巨头聚焦优势赛道。  <br/>行动建议：创业者可选择巨头布局薄弱的细分场景切入；投资者可重点关注全场景布局的平台型企业与细分赛道隐形冠军。</p><h5>3. 投融资趋势：中国市场复苏弹性领先</h5><p>2025年全球医疗健康一级市场温和复苏，融资总额604亿美元，融资事件数2353起；中国市场反弹强劲，融资总额96亿美元，融资事件数861起，同比大幅上涨32%，显示市场信心持续恢复。  <br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047609904" alt="" title="" loading="lazy"/>  <br/>全球及中国医疗健康投融资规模横向条形图表8数据EXCEL及图表PDF模板已分享到会员群  <br/>3秒解读：全球医疗健康投融资企稳回升，中国市场复苏弹性更强，资本信心回暖。  <br/>行动建议：创业者可抓住融资窗口期，重点对接关注AI医疗、手术机器人赛道的资本；投资者可加大对具备商业化能力的企业布局。</p><h5>4. 细分融资结构：技术驱动型赛道成资本焦点</h5><p>细分领域融资呈现结构性分化：生物医药依旧是吸金主力（236亿美元），数字健康赛道因AI驱动实现爆发式增长（145亿美元，+77%），器械与耗材稳健增长（130亿美元），医疗服务和医药商业则备受冷落，反映资本对技术驱动型创新的明确偏好。  <br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047609905" alt="" title="" loading="lazy"/>  <br/>全球医疗健康细分领域融资总额横向条形图表9数据EXCEL及图表PDF模板已分享到会员群  <br/>3秒解读：资本聚焦技术驱动型赛道，生物医药、数字健康、器械耗材成三大核心投资方向。  <br/>行动建议：企业可重点布局AI+药物研发、数字健康解决方案等资本偏好领域；医疗机构可与创新企业合作，试点新技术应用。</p><h5>5. 中国细分市场：院内+基层双引擎增长</h5><p>中国医疗AI细分市场呈现“整体千亿、细分分化”特征，基层CDSS与院内AI应用成为核心增长引擎，二者均保持20%以上复合增速。  <br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047609906" alt="" title="" loading="lazy"/>  <br/>中国医疗AI细分市场规模横向条形图表10数据EXCEL及图表PDF模板已分享到会员群  <br/>3秒解读：中国医疗AI市场已迈入千亿量级，院内应用与基层CDSS同步高增。  <br/>行动建议：企业可针对院内场景开发高精度AI工具，针对基层场景推出高性价比解决方案；政府可加大对基层CDSS的采购与推广力度。</p><h5>6. 商业化支付逻辑：B端为核心，C端待培育</h5><p>AI医疗商业化的核心在于支付方明确：药企为最强支付方（5星），因加速研发降本需求强烈；医院（4星）为提效评级有较强动力；保险机构（4星）控费需求明确但模式尚在探索；C端患者（3星）付费习惯仍需培育。  <br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047609907" alt="" title="" loading="lazy"/>  <br/>AI医疗支付方付费动力星级雷达图表11数据EXCEL及图表PDF模板已分享到会员群  <br/>3秒解读：B端（药企、医院、保险）是当前AI医疗商业化的核心买单方，C端市场仍需教育。  <br/>行动建议：企业可优先对接药企、医院需求，开发针对性解决方案；同时通过科普提升C端用户付费意愿。</p><h4><a name="t10" target="_blank"/>（二）手术机器人：国产替代与出海加速的双重机遇</h4><h5>1. 市场规模与增长潜力</h5><p>中国手术机器人市场2024-2032E CAGR约34%，从72亿元增长至767亿元：</p><ul><li>腔镜手术机器人：占比58%，2024-2032E CAGR29%，配置证放开与收费目录落地为核心催化；</li><li>骨科手术机器人：渗透率持续提升，2024-2032E CAGR41%，国产替代空间广阔。</li></ul><h5>2. 出海进展：国产龙头突破海外市场</h5><p>国产企业在出海方面已取得实质性突破：</p><ul><li>微创机器人：腔镜手术机器人图迈（获CE认证）全球商业化订单突破160台，覆盖40多个国家；骨科机器人鸿鹄（获中国NMPA、美国FDA、欧盟CE等认证）2025年H1全球累计订单超过55台；</li><li>精锋医疗：腔镜手术机器人MP1000（2025年3月获CE认证）、SP1000（2025年10月获CE认证），截至2025年10月末签订72台海外订单。  <br/>国产头部企业依托产品力、性价比、5G远程手术等优势，正打开海外广阔市场。</li></ul><h5>3. 盈利模式：对标海外龙头，构建“设备+耗材+服务”闭环</h5><ul><li>腔镜手术机器人：对标全球龙头直觉外科，采用“系统+耗材+服务”模式，2024年直觉外科耗材与服务占比达76%，国内企业盈利能力有望随耗材与服务占比提升而增强；</li><li>骨科手术机器人：参考史赛克等海外巨头经验，植入物创新产品与骨科机器人协同推广将形成更强成长拉动。</li></ul><h4><a name="t11" target="_blank"/>（三）脑机接口：政策+临床驱动的前沿赛道</h4><h5>1. 市场规模与产品形态</h5><ul><li>市场规模：2023年中国市场规模17.3亿元，2023-2029E CAGR35.1%，预计2029年达105亿元；</li><li>产品形态：分为侵入式、半侵入式、非侵入式，其中侵入式信号质量优势显著，是产业趋势；非侵入式因安全性高可作为补充。</li></ul><h5>2. 核心驱动因素</h5><ul><li>政策端：国家将脑机接口纳入前瞻布局的未来产业，2025年政策密集释放，北京、上海、重庆等地方出台配套政策；</li><li>临床端：2025年中国脑机接口各细分领域均取得突破性进展，阶梯医疗完成国内首例侵入式系统人体长期埋植临床试验，博睿康的脑机接口系统NEO在多中心注册临床试验中取得显著成果。</li></ul><h5>3. 应用场景：医疗为主，向非医疗延伸</h5><p>当前集中在医疗领域，覆盖肢体运动障碍诊疗、癫痫与神经发育障碍诊疗、意识与认知障碍诊疗等；未来有望向工业安全、航空航天、娱乐游戏等非医疗领域延伸。</p><h4><a name="t12" target="_blank"/>（四）可穿戴医疗设备：健康监测的大众化普及</h4><h5>1. 市场规模与增长</h5><p>中国可穿戴医疗设备市场规模持续增长，2014-2018年CAGR67.6%，2018-2023E CAGR19.8%，2023年预计达189.2亿美元。</p><h5>2. 产品分类与技术支撑</h5><ul><li>产品分类：分为监测型（心率、血压、血糖监测等）和治疗型（植入式心脏起搏器、胰岛素泵等），其中监测型设备占据最大份额；</li><li>核心技术：高精度传感器、生物信号处理、无线通讯、低功耗设计等是基础支撑，AI、机器学习、5G通信等新兴技术推动设备智能化水平快速提升。</li></ul><h5>3. 市场竞争格局</h5><p>华为、迈瑞医疗、联想健康等国内企业，以及苹果、Fitbit、Garmin等国际品牌竞争激烈，市场呈现多极化趋势：头部企业市场份额不断扩大，细分市场仍有中小企业发展空间。</p><h3><a name="t13" target="_blank"/>三、企业案例与市场格局</h3><h4><a name="t14" target="_blank"/>（一）讯飞医疗：AI医疗领军企业的业务布局与增长潜力</h4><h5>1. 业务结构：G端打底，BC端突破</h5><p>讯飞医疗业务覆盖GBC全场景：传统优势的G端业务收入占比过半，构筑基本盘；B端和C端业务增速显著更高，尤其是患者服务业务复合增速超87%，成为收入结构优化核心引擎。  <br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047609908" alt="" title="" loading="lazy"/>  <br/>讯飞医疗业务收入占比及增速双轴图表12数据EXCEL及图表PDF模板已分享到会员群  <br/>3秒解读：讯飞医疗G端业务稳固，BC端业务成为增长核心，收入结构持续优化。  <br/>行动建议：同行企业可参考其“G端打底、BC端突破”的业务模式；投资者可重点关注其BC端业务落地进展与盈利能力改善。</p><h5>2. 市场格局：竞争分散，新进入者有机会</h5><p>医疗AI市场集中度较低，讯飞医疗暂居榜首但市场份额仅为5.9%，大量长尾企业合计占据超过四分之三的市场，表明行业技术门槛虽高，但应用场景多样，尚未形成垄断。  </p><p>2023年中国医疗人工智能市场份额圆环图表13数据EXCEL及图表PDF模板已分享到会员群  <br/>3秒解读：医疗AI市场竞争分散，头部企业优势不明显，新进入者仍有机会。  <br/>行动建议：新进入者可选择细分场景深耕，打造差异化优势；头部企业可通过并购整合扩大市场份额。</p><h5>3. 财务表现：营收高增，盈利拐点临近</h5><p>受益于BC端业务快速放量，讯飞医疗营业收入保持30%左右的年增速；随着规模效应显现和运营效率提升，公司归母净利润亏损大幅收窄，券商预测其将在2026年实现净利润转正。  <br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047609909" alt="" title="" loading="lazy"/>  <br/>讯飞医疗营收与净利润折线图表14数据EXCEL及图表PDF模板已分享到会员群  <br/>3秒解读：讯飞医疗营收高增，净利润持续改善，盈利拐点即将到来。  <br/>行动建议：投资者可长期关注其盈利转正进度；企业可借鉴其规模化降本的运营策略，提升盈利能力。</p><h4><a name="t15" target="_blank"/>（二）技术层面：机器学习模型与算力支撑</h4><h5>1. 机器学习模型：树模型准确率领先</h5><p>在医疗预测任务中，集成树模型（如随机森林、XGBoost）表现最优，其处理非线性关系和特征交互的能力更强，为AI辅助诊断提供核心技术支撑。  <br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047609910" alt="" title="" loading="lazy"/>  <br/>机器学习模型准确率对比横向条形图表15数据EXCEL及图表PDF模板已分享到会员群  <br/>3秒解读：随机森林等树模型在医疗预测任务中准确率最高，是AI辅助诊断的核心算法选择。  <br/>行动建议：技术企业可优先采用随机森林等高性能模型开发产品；医疗机构在选择AI工具时，可重点关注算法类型与准确率指标。</p><h5>2. 数据与算力：产业发展的核心基石</h5><p>医疗AI模型的训练高度依赖高质量标注数据和强大算力：2025年全球医疗数据标注需求同比激增217%，同期中国企业采购特定AI芯片的金额高达160亿美元，反映行业在数据基础设施和算力储备上的巨大投入。  <br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047609911" alt="" title="" loading="lazy"/>  <br/>医疗AI数据与算力需求增长横向条形图表16数据EXCEL及图表PDF模板已分享到会员群  <br/>3秒解读：数据标注与算力是AI医疗发展的核心支撑，行业投入持续加码。  <br/>行动建议：企业可布局医疗数据标注服务或算力租赁业务；政府可加大对医疗数据共享平台与算力基础设施的投入。</p><h3><a name="t16" target="_blank"/>四、用户需求场景与行动清单</h3><h4><a name="t17" target="_blank"/>（一）核心用户类型与痛点关联</h4><ol><li><strong>创业者</strong>：痛点集中在“赛道选择难、技术壁垒高、商业化路径不清晰”，报告价值在于明确高增长细分赛道（CGM、手术机器人出海、脑机接口医疗应用），提供盈利模式参考（设备+耗材+服务、CRO服务）；</li><li><strong>投资者</strong>：痛点是“项目估值难、风险判断不准”，报告通过市场规模、增速、竞争格局数据，筛选出具备技术壁垒与商业化能力的企业类型（平台型手术机器人企业、上游核心零部件厂商、AI医疗头部企业）；</li><li><strong>医疗机构从业者</strong>：痛点是“设备选型难、技术落地效果不确定”，报告梳理了各细分领域成熟产品（如微创机器人图迈、精锋医疗MP1000），提供了临床应用案例与效果数据；</li><li><strong>医疗器械企业从业者</strong>：痛点是“技术迭代慢、出海受阻”，报告分析了技术发展趋势（AI+多模态融合、大小模型协同）与出海成功案例，给出专利布局与国际认证建议。</li></ol><h4><a name="t18" target="_blank"/>（二）可落地的3件事</h4><ol><li>调研本地三甲医院与基层医疗机构的设备需求差异，重点关注骨科、腔镜手术机器人的入院进展，结合收费目录政策，筛选适配的合作或投资方向；</li><li>分析所在区域慢病（高血压、糖尿病）人群分布数据，对接可穿戴设备企业，探索“设备+社区医疗+医保”的慢病管理合作模式；</li><li>跟踪脑机接口临床进展，重点关注侵入式产品的安全性与有效性数据，评估在神经康复领域的试点应用可行性。</li></ol><h4><a name="t19" target="_blank"/>（三）风险提示与应对方案</h4><ol><li><strong>政策变动风险</strong>：收费目录落地不及预期、医保报销政策调整。应对方案：密切关注医保局、药监局政策动态，选择政策支持力度大的细分领域（如基层医疗AI、国产手术机器人）；社群将实时更新政策解读，提供政策应对咨询；</li><li><strong>技术迭代风险</strong>：AI算法、传感器技术更新快，产品面临淘汰。应对方案：加大研发投入，聚焦核心技术（如AI算法优化、高精准传感器），与高校、科研机构建立合作；社群提供技术趋势周报，对接技术资源；</li><li><strong>数据安全风险</strong>：医疗数据泄露、隐私保护合规问题。应对方案：遵循《通用数据保护条例》等法规，建立数据加密与隔离机制；社群分享数据安全合规指南，对接合规咨询机构。</li></ol><h3><a name="t20" target="_blank"/>五、核心数据表格与图表列表</h3><h4><a name="t21" target="_blank"/>（一）核心数据表格</h4><table><thead><tr><th>细分领域</th><th>中国市场规模（2024/2023年）</th><th>全球市场规模（2024/2023年）</th><th>2024-2032E/2023-2029E CAGR</th><th>核心驱动因素</th></tr></thead><tbody><tr><td>手术机器人</td><td>72亿元</td><td>212亿美元</td><td>34%</td><td>收费目录落地、出海加速</td></tr><tr><td>脑机接口</td><td>17.3亿元</td><td>19.8亿美元</td><td>35.1%</td><td>政策支持、临床突破</td></tr><tr><td>可穿戴医疗设备</td><td>189.2亿美元（2023E）</td><td>286亿美元</td><td>19.8%（2018-2023E）</td><td>健康意识提升、技术创新</td></tr><tr><td>医疗AI</td><td>1000亿元</td><td>-</td><td>20%+</td><td>场景渗透、支付方明确</td></tr><tr><td>CGM</td><td>17.3亿元</td><td>-</td><td>-</td><td>糖尿病管理需求、技术升级</td></tr><tr><td>医疗健康投融资（中国）</td><td>96亿美元</td><td>604亿美元</td><td>-</td><td>市场复苏、技术驱动</td></tr></tbody></table><h4><a name="t22" target="_blank"/>（二）图表列表</h4><ol><li>健康监测市场关键指标横向条形图表1</li><li>脑机接口与手术机器人市场对比灰底比例条形图表2</li><li>中国AI医疗装备注册数量增长折线图表3</li><li>巴西进口中国医疗产品同比增长率横向条形图表4</li><li>中美医疗健康专利布局对比灰底比例条形图表5</li><li>AI医疗应用场景专利渗透率灰底比例条形图表6</li><li>全球主要企业医疗AI专利持有量热图表7</li><li>全球及中国医疗健康投融资规模横向条形图表8</li><li>全球医疗健康细分领域融资总额横向条形图表9</li><li>中国医疗AI细分市场规模横向条形图表10</li><li>AI医疗支付方付费动力星级雷达图表11</li><li>讯飞医疗业务收入占比及增速双轴图表12</li><li>2023年中国医疗人工智能市场份额圆环图表13</li><li>讯飞医疗营收与净利润折线图表14</li><li>机器学习模型准确率对比横向条形图表15</li><li>医疗AI数据与算力需求增长横向条形图表16</li></ol><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609895" alt="封面" title="封面" loading="lazy"/></p><h4><a name="t23" target="_blank"/>本专题内的参考报告（PDF）目录</h4><ul><li>中国信通院：智能化医疗装备产业蓝皮书（2025年）.pdf</li><li>2026-02-12 14:28</li><li>医药生物行业从设备招投标看2026年行业投资机遇——设备拐点向上趋势明确，医疗新科技蓬勃发展.pdf</li><li>2026-02-12 14:21</li><li>医疗保健行业创新链系列——中国创新药研发景气度渐趋改善，早研产业链或显著受益.pdf</li><li>2026-02-12 14:21</li><li>医疗耗材&amp;线下药店行业深度报告——在分化中寻找确定性.pdf</li><li>2026-02-12 14:21</li><li>医疗器械创新系列行业报告（一）：手术机器人五问五答.pdf</li><li>2026-02-12 14:21</li><li>2026年医疗健康与生命科学行业职场展望Final.pdf</li><li>2026-02-11 15:32</li><li>医疗卫生行业：新冠肺炎全球风险评估-第9版.pdf</li><li>2026-02-11 15:26</li><li>创新医疗器械盘点系列（4）：肿瘤基因检测的“勇敢者游戏”（上篇）.pdf</li><li>2026-02-09 14:20</li><li>家用医疗器械专题报告（一）：健康监测&amp;呼吸治疗篇.pdf</li><li>2026-02-08 09:56</li><li>华西证券-小核酸药物行业深度研究报告：RNA精准医疗时代的崛起与挑战.pdf</li><li>2026-02-08 09:56</li><li>中国民营医疗服务：穿越寒冬，静待春生.pdf</li><li>2026-02-06 16:42</li><li>2025年全球医疗健康产业资本报告.pdf</li><li>2026-02-04 16:40</li><li>第139期-叶彦辛&amp;宋立恒-《智启 Al 新程从 FastGPT 实战到医疗模型可解释性探索》.pdf</li><li>2026-02-04 16:37</li><li>口腔医疗机构广告合规指南（2025）.pdf</li><li>2026-02-01 13:30</li><li>AI医疗行业专题报告——AI重构医疗，从场景落地到变现讨论.pdf</li><li>2026-02-01 13:27</li><li>“通往再平衡之路”系列之二：从医疗服务涨价看稳通胀路径.pdf</li><li>2026-02-01 13:26</li><li>长江证券：医疗器械出海深度（二）复盘希森美康——海外深耕，属地筑基.pdf</li><li>2026-02-01 13:25</li><li>光大证券：AI医疗行业专题报告——AI重构医疗，从场景落地到变现讨论.pdf</li><li>2026-02-01 13:25</li><li>医疗器械出海深度（二）复盘希森美康——海外深耕，属地筑基.pdf</li><li>2026-01-30 15:56</li><li>知识产权出版社：医疗健康行业2025年专利分析白皮书.pdf</li><li>2026-01-30 15:54</li><li>未来健康7：未来的医疗体系.pdf</li><li>2026-01-29 14:29</li><li>2025年智能体时代：重塑企业未来报告-医疗保健和生命科学行业.pdf</li><li>2026-01-28 16:00</li><li>华创医疗器械求索系列11：脑机接口行业：政策加码，临床加速，产业化进入关键阶段.pdf</li><li>2026-01-28 15:51</li><li>人工智能行业专题：OpenAI发布医疗健康Gpt，开启AI医疗新时代.pdf</li><li>2026-01-27 15:48</li><li>思宇MedTech：2025医疗器械BD白皮书.pdf</li><li>2026-01-25 12:39</li><li>上海社会科学院：AI医疗治理白皮书（2026版）.pdf</li><li>2026-01-24 17:41</li><li>中国生物制药、医疗设备及医用耗材出口及重点进口国市场分析.pdf</li><li>2026-01-22 12:06</li><li>医疗保障、气象服务领域“数据要素×”典型场景指引.pdf</li><li>2026-01-21 17:32</li><li>口腔医疗机构广告合规指南（2025） .pdf</li><li>2026-01-21 16:17</li><li>讯飞医疗科技-2506.HK-医疗AI领军企业，大模型技术领先，BC端场景加速落地.pdf</li><li>2026-01-21 15:37</li><li>硕远咨询：2025年中国母婴医疗服务行业市场研究报告.pdf</li><li>2026-01-19 16:57</li><li>2025年中国可穿戴医疗设备行业市场研究报告.pdf</li><li>2026-01-19 16:47</li><li>财信证券：医疗器械行业深度——时代变革下，创新与出海仍是投资主线.pdf</li><li>2026-01-15 15:33</li><li>贝恩公司：2026年全球医疗健康行业私募股权报告（英文版）.pdf</li><li>2026-01-14 16:12</li><li>医疗保障法律法规及政策汇编(2026年版）.pdf</li><li>2026-01-14 16:09</li><li>全球医药、医疗行业——2026年-关注慢病迭代，经营质量和现金流.pdf</li><li>2026-01-12 15:12</li><li>全球医药、医疗行业——2026年-关注慢病迭代，经营质量和现金流.pdf</li><li>2026-01-11 09:25</li><li>中国科技产业化促进会：2025年中国健康医疗数据要素应用案例集.pdf</li><li>2026-01-06 16:03</li><li>StartUs Insights：2026年全球医疗行业趋势研究报告（英文版）.pdf</li><li>2026-01-06 15:25</li><li>医疗科技跨年展望暨近期热点综述.pdf</li><li>2026-01-06 15:15</li><li>医疗彩超行业：临床诊断的基石与智能化升级核心.pdf</li><li>2026-01-06 15:15</li><li>2025年量子技术：健康与医疗保健领导者的战略要务报告.pdf</li><li>2026-01-03 10:50</li><li>动脉智库：2025年数字医疗年度创新白皮书.pdf</li><li>2025-12-31 15:38</li><li>段涛教授团队：2025 妇儿医疗健康科普白皮书.pdf</li><li>2025-12-30 14:53</li><li>从医疗科技到健康科技：赋能未来健康护理生态.pdf</li><li>2025-12-30 14:48</li><li>IVD体外诊断相关医疗器械行业报告——IVD国内短期承压，头部企业积极出海.pdf</li><li>2025-12-30 14:40</li><li>耐用消费产业行业研究：宠物医疗系列之一：黄金增长期叠加连锁化率提升，宠物医院板块机会在即.pdf</li><li>2025-12-29 15:52</li><li>医药行业报告：数说德国医疗医保系统，医保商保协调发展.pdf</li><li>2025-12-29 15:51</li><li>动脉智库：2025年医疗器械及供应链年度创新白皮书.pdf</li><li>2025-12-27 16:59</li><li>2025医疗人工智能产业报告：价值计量&amp;支付探索，突破医疗AI困境.pdf</li><li>2025-12-26 16:07</li><li>医药生物行业：AI医疗应用商业化加速，重视AI医疗底部机会.pdf</li><li>2025-12-26 15:59</li><li>CIC工信安全：医疗器械行业数字化转型发展报告（2025）.pdf</li><li>2025-12-25 16:53</li><li>CIC工信安全：医疗装备行业数字化转型场景图谱（2025）.pdf</li><li>2025-12-25 16:53</li><li>CIC工信安全：医疗装备行业数字化转型场景需求清单（2025）.pdf</li><li>2025-12-25 16:53</li><li>丁香园：2024医疗机构最佳雇主洞察报告.pdf</li><li>2025-12-25 16:52</li><li>动脉智库：2025年医疗服务年度创新白皮书.pdf</li><li>2025-12-25 16:43</li><li>全球医药、医疗行业——2026年医疗科技行业展望，AI提效、资本开支复苏与医疗器械政策趋稳.pdf</li><li>2025-12-24 15:30</li><li>2025年中国口腔医疗行业市场研究报告-硕远咨询.pdf</li><li>2025-12-22 15:02</li><li>蛋壳研究院：2025年医疗人工智能产业报告.pdf</li><li>2025-12-18 14:47</li><li>药品和医疗器械警戒领域的前瞻性监管情报.pdf</li><li>2025-12-16 16:22</li><li>易观分析：2025年AI精准医疗市场专题分析报告.pdf</li><li>2025-12-15 16:10</li><li>2024年中德比较视野下的中国基层医疗守门模式-一个多层次的分析框架.pdf</li><li>2025-12-14 08:43</li><li>医药魔方：2025年中国医疗器械投融资趋势与国产替代机遇报告.pdf</li><li>2025-12-14 08:30</li><li>PitchBook：2026年医疗保健展望报告（英文版）.pdf</li><li>2025-12-11 16:27</li><li>医疗实践：美国医疗系统改善女性医疗保健的500亿美元机遇.pdf</li><li>2025-12-10 16:59</li><li>商业医疗险报告三——探索受益于商业医疗险发展的细分赛道.pdf</li><li>2025-12-09 16:09</li><li>商业医疗险报告二：他山之石，辩证看待美国健康险管理医疗模式.pdf</li><li>2025-12-09 16:09</li><li>2026年医疗器械年度投资策略：支付优化，创新出海.pdf</li><li>2025-12-08 16:07</li><li>商业医疗险报告三-探索受益于商业医疗险发展的细分赛道.pdf</li><li>2025-12-07 10:18</li><li>保持领先地位——药品和医疗器械警戒领域的前瞻性监管情报.pdf</li><li>2025-12-05 16:51</li><li>国家医疗保障局：长期护理保险服务管理文书（2026年版.pdf</li><li>2025-12-05 16:51</li><li>沙利文：2025年中国医疗器械国际化现状与趋势蓝皮书.pdf</li><li>2025-11-26 15:49</li><li>2025年美国医疗服务可负担性及价值评估追踪报告.pdf</li><li>2025-11-22 16:34</li><li>全球医药、医疗行业——代谢新药研发系列（四），PCSK9Lp(a)心血管新药黄金时代.pdf</li><li>2025-11-22 16:26</li><li>医疗保健设备与服务行业——当医疗遇上AI，技术突破或重构诊疗逻辑.pdf</li><li>2025-11-15 15:03</li><li>2025未来健康指数报告：构筑医疗Al信任基石-医患双重视角下的医疗健康未来.pdf</li><li>2025-11-13 15:31</li><li>2025年智启新质生产力之三 ——生成式人工智能 （AIGC）在医疗器械 的潜在应用.pdf</li><li>2025-11-10 13:50</li><li>让GCCs适用于中端医疗技术.pdf</li><li>2025-11-10 13:40</li><li>Salesforce：2025年中国医疗健康和生命科学行业报告.pdf</li><li>2025-11-08 17:46</li><li>医疗器械专题：脑机接口行业深度专题二：三个维度看脑机接口行业发展趋势.pdf</li><li>2025-11-08 17:40</li><li>克劳锐：2025健康医疗内容消费趋势洞察报告.pdf</li><li>2025-11-07 16:31</li><li>TempusAI启示：用数据构筑AI+医疗行业领先优势-中邮证券.pdf</li><li>2025-11-05 16:40</li><li>SVB：2025年医疗科技行业未来展望报告（英文版）.pdf</li><li>2025-10-31 15:12</li><li>全球医药、医疗行业——全球健康产业进入新拐点-长期韧性显现，创新动能积聚.pdf</li><li>2025-10-28 16:18</li><li>欧盟人工智能法案如何重塑emea的医疗器械产业.pdf</li><li>2025-10-27 16:12</li><li>医疗器械海外深度（三）：中美对比，创新出海.pdf</li><li>2025-10-24 14:06</li><li>北欧可持续医疗中心：2025年可持续医疗趋势报告.pdf</li><li>2025-10-20 14:55</li><li>探索医疗保健领域的塑料循环利用机会.pdf</li><li>2025-10-20 14:53</li><li>跨越信任鸿沟：AI在科研与医疗领域深度应用的核心挑战.pdf</li><li>2025-10-18 17:14</li><li>2025中国医疗健康保障体系转型发展报告：应对老龄化挑战与推动商业健康保险创新.pdf</li><li>2025-10-17 16:00</li><li>2025年医疗服务报告：基于对30个国家的调研（英文版）.pdf</li><li>2025-10-17 15:59</li><li>医疗保健：医疗器械2025.pdf</li><li>2025-10-16 15:19</li><li>AI 时代的医疗保健业：科技注入，赋能 医疗创新与患者关怀-IBM.pdf</li><li>2025-10-14 15:25</li><li>医药生物行业专题报告：AI职能蜕变，医疗行业变革蓄势待发.pdf</li><li>2025-10-14 15:09</li><li>动脉橙：2025年9月全球医疗健康领域投融资月报.pdf</li><li>2025-10-13 09:51</li><li>西心血管疾病相关医疗器械行业报告——心血管行业空间广阔，集采助力国产替代.pdf</li><li>2025-09-30 16:37</li><li>2025年中国医疗美容市场洞察报告：轻医美如何用“生活化场景”开拓新增长极？.pdf</li><li>2025-09-29 15:55</li><li>2025年Q3医疗器械行业薪酬报告.pdf</li><li>2025-09-29 15:54</li><li>2025年Q3医疗美容行业薪酬报告.pdf</li><li>2025-09-29 15:54</li><li>2025年AI应用与行业转型：对医疗、金融服务、气候与能源及交通领域的影响报告（英文版）.pdf</li><li>2025-09-26 14:23</li><li>美国医疗行业系列研究（三）——美国药品支付体系拆解-美国高药价的成因？特朗普药价政策的影响？.pdf</li><li>2025-09-25 16:00</li><li>生物医药行业——商业医疗险报告一-见微知著，医保承压下商保或为破局之法.pdf</li><li>2025-09-25 16:00</li><li>_印孚瑟斯Infosys：2025年医疗保健市场前景报告（英文版）.pdf</li><li>2025-09-23 16:36</li><li>可负担医疗的未来：释放人工智能的潜力，以改造东南亚的卫生系统.pdf</li><li>2025-09-22 16:20</li><li>农林牧渔行业：宠物医疗空间广阔，全国连锁模式最优.pdf</li><li>2025-09-21 17:13</li><li>2025热电偶导线在医疗器械中的应用场景白皮书.pdf</li><li>2025-09-20 16:56</li><li>2025年智能医疗健康：人工智能驱动转型与价值重塑报告.pdf</li><li>2025-09-14 19:32</li><li>2025年未来医生白皮书：医疗行业持续发展的关键洞察（英文版）.pdf</li><li>2025-09-14 19:30</li><li>美国卫生与公众服务部发布 “医疗卫生行业人工智能发展战略计划”.pdf</li><li>2025-09-12 16:35</li><li>2025年未来AI与劳动力：生成式AI对医疗行业岗位的影响研究报告（英文版）.pdf</li><li>2025-09-12 16:33</li><li>医疗保健行业GLP_1受体激动剂行业深度报告：GLP_1RAs引领降糖减重市场，更多适应症有待开发.pdf</li><li>2025-09-11 15:12</li><li>浙江省基本医疗保险医疗服务项目目录（2025年）.pdf</li><li>2025-09-09 15:21</li><li>上海喜美医疗美容品牌升级规划方案.pdf</li><li>2025-09-06 19:21</li><li>ITIF：2025 AR&amp;VR在医疗领域中的应用潜力研究报告（英文版）.pdf</li><li>2025-08-27 16:52</li><li>信任與創新：提升遙距醫療管治.pdf</li><li>2025-08-26 17:02</li><li>中国医疗器械出海东南亚白皮书 - 天册律师事务所.pdf</li><li>2025-08-26 17:02</li><li>2025年信任与创新：提升遥距医疗管治研究报告（繁体版）.pdf</li><li>2025-08-21 17:01</li><li>顺为人和：2025年医疗器械标杆企业组织效能报告.pdf</li><li>2025-08-21 16:57</li><li>全球医药、医疗行业：GenAI前沿实践更新，Agent化落地成主线.pdf</li><li>2025-08-15 16:00</li><li>医疗器械行业深度（R3）：神经介入行业，大空间，新机遇.pdf</li><li>2025-08-15 15:59</li><li>2025年医疗保健预算执行-从瓶颈到解决方案报告.pdf</li><li>2025-08-14 16:55</li><li>智慧健康医疗体系概述.pdf</li><li>2025-08-14 16:48</li><li>AI医疗行业深度：驱动因素、重点方向、产业链及相关公司深度梳理.pdf</li><li>2025-08-14 16:47</li><li>医疗保健预算执行 从瓶颈到解决方案.pdf</li><li>2025-08-12 16:08</li><li>医疗保健服务公共比较表和估值指南.pdf</li><li>2025-08-12 16:07</li><li>2025年emea医疗保健市场快照：欧洲、中东和非洲地区医疗保健私营市场活动概述.pdf</li><li>2025-08-11 15:46</li><li>2025年信心与价值：提升医疗价格透明度研究报告（繁体简版）.pdf</li><li>2025-08-10 18:40</li><li>艾社康：2024-2025多层次医疗保障创新案例集.pdf</li><li>2025-08-06 16:18</li><li>2025年马来西亚医疗器械评估优化白皮书：价值导向型综合性方法（英文版）.pdf</li><li>2025-08-06 16:16</li><li>2025年AI科技勾勒医疗未来蓝图-AI for 医疗健康系列报告“智” 愈未来.pdf</li><li>2025-08-05 15:30</li><li>医疗健康大模型伦理与安全白皮书.pdf</li><li>2025-08-05 15:27</li><li>2025人工智能大模型在医疗领域发展态势研究报告.pdf</li><li>2025-08-02 16:20</li><li>中国医疗保健：银发经济崛起-高盛.pdf</li><li>2025-08-01 16:47</li><li>亿欧智库 _ 2025中国人工智能医疗健康研究报告.pdf</li><li>2025-07-29 17:10</li><li>2025年医疗耗材数字化领用白皮书-以低值耗材为切入口的AI智能仓储实践.pdf</li><li>2025-07-29 17:09</li><li>医药行业2025年中期投资策略——BD加速创新药重估，后续持续看好创新药及产业链、AI医疗、脑机接口等结构性机会.pdf</li><li>2025-07-23 16:22</li><li>2025中国宠物医疗行业现状报告-嘉世咨询.pdf</li><li>2025-07-20 20:06</li><li>2025“人工智能 ”医疗健康行业应用白皮书-阿里云.pdf</li><li>2025-07-20 20:04</li><li>医药生物行业专题报告：“AI+医疗”商业化进程有望加快.pdf</li><li>2025-07-20 19:59</li><li>健闻咨询：2025年Z世代个性化消费医疗洞察报告.pdf</li><li>2025-07-18 16:43</li><li>汇银林泰：2025高端医疗发展白皮书.pdf</li><li>2025-07-18 16:43</li><li>动脉智库：2025年H1全球医疗健康产业资本报告.pdf</li><li>2025-07-17 15:51</li><li>2025商业健康保险与医药产业高质量 协同发展——团体补充医疗保险改革新视角.pdf</li><li>2025-07-17 15:48</li><li>医药生物-AI医疗行业系列二暨GenAI系列深度之62：AI医药，智愈未来，技术变革下的生态重塑.pdf</li><li>2025-07-16 16:02</li><li>2024年塑造美国医疗经济的八大趋势研究报告（英文）.pdf</li><li>2025-07-15 16:24</li><li>医疗器械行业2025H2投资策略：国内不利因素逐渐消退，海外市场进展迅速.pdf</li><li>2025-07-15 16:23</li><li>宠物医疗行业系列2-宠物医院分散格局谋突破，连锁专科领未来.pdf</li><li>2025-07-11 15:57</li><li>2025年未来医疗调查报告（英文）.pdf</li><li>2025-07-09 16:23</li><li>2025年医疗美容行业白皮书-薪智.pdf</li><li>2025-07-07 16:50</li><li>保健品品牌 × 小红书“疗愈式营销”品效双赢【医疗保健】【医药保健】【种草营销】.pdf</li><li>2025-07-06 08:30</li><li>薪智：2025年Q2薪智医疗美容行业薪酬报告.pdf</li><li>2025-06-30 15:06</li><li>德勤：2025年中国智慧医疗行业白皮书.pdf</li><li>2025-06-28 17:12</li><li>2025年关于最有价值和最强大的制药、医疗器械和服务品牌的年度报告（英文版）.pdf</li><li>2025-06-28 17:08</li><li>香2024年优化跨境就医应对医疗需求报告（繁体版）.pdf</li><li>2025-06-28 17:03</li><li>2025年医疗保健品牌榜.pdf</li><li>2025-06-26 16:55</li><li>2025制药、医疗科技与生物技术领域AI应用 ：解锁商业成功之道（英文）.pdf</li><li>2025-06-25 16:34</li><li>2024年全球医疗科技行业状况及2025年展望报告（英文版）-Vamstar.pdf</li><li>2025-06-23 15:39</li><li>2025“面向未来的医疗”调研报告（英文）.pdf</li><li>2025-06-19 16:03</li><li>嘉世咨询：2025年宠物医疗行业简析报告.pdf</li><li>2025-06-17 15:21</li><li>荣续ESG智库：2025年医疗器械行业ESG白皮书.pdf</li><li>2025-06-16 09:49</li><li>荣续ESG智库：2025年医疗卫生行业ESG白皮书.pdf</li><li>2025-06-16 09:49</li><li>IDC：2025年医疗行业智慧文印解决方案白皮书.pdf</li><li>2025-06-14 16:43</li><li>医药生物行业深度报告：引领医疗革命，CGT成长空间广阔.pdf</li><li>2025-06-13 16:08</li><li>沙利文：2025年中国医疗器械出海现状与趋势蓝皮书.pdf</li><li>2025-06-12 15:39</li><li>阿里云：2025医疗健康行业AI应用白皮书.pdf</li><li>2025-06-11 16:38</li><li>兰州市基本医疗保障政策指南.pdf</li><li>2025-06-09 13:31</li><li>2025年易凯资本中国健康产业白皮书-医疗技术与器械篇.pdf</li><li>2025-06-07 16:42</li><li>2025年易凯资本中国健康产业白皮书-医疗与健康服务篇.pdf</li><li>2025-06-06 15:36</li><li>2025 医疗健康新质生产力 “创变引擎” 系列洞察 创新医疗科技篇.pdf</li><li>2025-06-04 16:26</li><li>智药局：2025年AI Agent+医疗行业研究报告.pdf</li><li>2025-06-02 08:58</li><li>2025年AI医疗行业发展现状、趋势、主要应用领域及相关标的分析报告.pdf</li><li>2025-05-22 15:55</li><li>医疗器械行业深度：AI医疗重构诊疗流程，效率与市场增长下的投资机会.pdf</li><li>2025-05-16 16:45</li><li>2025年人工智能与机器学习在医疗科技领域的崛起研究报告（英文版）.pdf</li><li>2025-05-13 16:24</li><li>2025年第一季度欧洲和美国远程医疗报告.pdf</li><li>2025-05-12 15:49</li><li>医疗行业分布式数据库解决方案白皮书 .pdf</li><li>2025-05-12 15:43</li><li>南京大学（高阳）：2024年健康医疗数据的确权与流通报告.pdf</li><li>2025-05-10 15:44</li><li>2025年医疗大模型研究报告-新质生产力大模型在各医疗场景的赋能实践.pdf</li><li>2025-05-09 16:27</li><li>2025年迈向全民医疗保障的中国经验研究报告（英文版）.pdf</li><li>2025-05-09 16:25</li><li>国际劳工组织（ILO）：2025年迈向全民医疗保障的中国经验研究报告.pdf</li><li>2025-05-08 15:59</li><li>罗氏医疗（梁莉）：融合创新技术团队适应医疗行业的敏捷转型之路.pdf</li><li>2025-05-03 10:35</li><li>中国LSHC生命科学与医疗行业调查报告.pdf</li><li>2025-04-30 17:14</li><li>智慧医疗专题-智慧养老整体解决方案（22页 ）.pdf</li><li>2025-04-26 14:23</li><li>艾昆纬：降低医疗科技行业的风险与干扰.pdf</li><li>2025-04-24 15:54</li><li>中国软件评测中心：2024年广东省医疗诊断、监护及治疗设备产业调研报告.pdf</li><li>2025-04-22 15:41</li><li>2024年高性能医疗器械创新发展报告-国家高性能医疗器械创新中心.pdf</li><li>2025-04-21 10:04</li><li>人工智能在医疗场景中的应用分享.pdf</li><li>2025-04-17 16:46</li><li>AI医疗专题：从AIGC角度看医药产业图谱.pdf</li><li>2025-04-17 16:36</li><li>AI 医疗：提质增效，全面赋能.pdf</li><li>2025-04-17 16:36</li><li>沙利文：2025年放疗医疗器械市场行业研究报告.pdf</li><li>2025-04-16 15:38</li><li>中国AI医疗行业白皮书：精准医疗，智能未来.pdf</li><li>2025-04-16 15:28</li><li>湖北数据集团：2025年医疗数据合规白皮书.pdf</li><li>2025-04-15 16:19</li><li>EY安永：2025年中企出海白皮书：医药和医疗器械篇.pdf</li><li>2025-04-15 16:17</li><li>医疗保健行业ESG管理策略研究报告-北京ESG研究院.pdf</li><li>2025-04-14 11:00</li><li>腾讯&amp;罗兰贝格：2025年医疗大健康行业全渠道营销报告.pdf</li><li>2025-04-12 16:40</li><li>2025年人工智能赋能医疗行业的未来白皮书：AI引领智能新征程（英文版）.pdf</li><li>2025-04-12 16:37</li><li>传媒行业GenAI系列之五十：国内云价值重估，AI游戏、AI社区、AI医疗、AI教育仍有低估.pdf</li><li>2025-04-12 16:29</li><li>浙江大学（姚畅）：2025年AI大模型如何破局传统医疗报告.pdf</li><li>2025-04-03 15:43</li><li>摩熵咨询：2025年中国AI医疗健康企业创新发展百强榜单报告.pdf</li><li>2025-04-01 15:39</li><li>2025商业健康险医药行业与医疗机构协同创新案例研究报告.pdf</li><li>2025-03-29 16:28</li><li>生物医药行业：AI心脏大模型发布，医疗AI商业化进程加速.pdf</li><li>2025-03-28 16:27</li><li>大健康医疗信息流投放.pdf</li><li>2025-03-25 15:55</li><li>罗兰贝格：2025年全球医疗器械报告-创新与效率平衡之道.pdf</li><li>2025-03-22 17:06</li><li>2024年医疗保健行业网络安全调查.pdf</li><li>2025-03-21 15:53</li><li>医疗AI专题报告（三）：设备篇：AI时代下的智能医疗设备革命.pdf</li><li>2025-03-21 15:41</li><li>手术机器人：高端医疗器械领域的“明珠”，重构现代外科手术体系.pdf</li><li>2025-03-20 14:48</li><li>2025年Q1医疗美容行业薪酬报告.pdf</li><li>2025-03-17 14:49</li><li>动脉橙：2025年2月全球医疗健康领域投融资月报.pdf</li><li>2025-03-16 17:08</li><li>医疗AI专题报告（二）：多组学篇：AI技术驱动精准诊断实现重要突破.pdf</li><li>2025-03-16 17:07</li><li>2025年企业高端健康福利调研报告-医疗保险和体检的优化之道.pdf</li><li>2025-03-15 15:37</li><li>猎聘：2025年医疗器械行业人才供需洞察报告.pdf</li><li>2025-03-14 15:50</li><li>计算机行业深度报告：AI+医疗：大模型重塑医疗生态.pdf</li><li>2025-03-13 17:05</li><li>中国生命科学与医疗行业-调研结果：2025年行业现状与展望报告.pdf</li><li>2025-03-12 15:41</li><li>中国生命科学与医疗行业-调研结果：2025年行业现状与展望报告（英文版）.pdf</li><li>2025-03-12 15:41</li><li>预训练大模型与医疗：从算法研究到应用.pdf</li><li>2025-03-11 16:25</li><li>挖掘亚太地区人工智能在医疗科技领域的价值（2025年.pdf</li><li>2025-03-10 09:29</li><li>大模型平民化开启“AI+医疗”新纪元-国联民生证券.pdf</li><li>2025-03-10 09:22</li><li>隐形眼镜品牌日抛产品抖音品牌营销策略案【医疗个护】【抖音营销】【种草营销】.pdf</li><li>2025-03-10 09:17</li><li>2025年智启原新：医药和医疗器械企业AI原生转型报告.pdf</li><li>2025-03-07 16:27</li><li>AI+医疗投资框架：AI平权赋能医疗数据价值重估.pdf</li><li>2025-03-07 16:18</li><li>知识产权出版社：医疗健康行业2024年专利分析白皮书.pdf</li><li>2025-03-05 15:21</li><li>医疗器械专题之脑机接口：中国脑机接口行业现状与展望.pdf</li><li>2025-03-05 15:13</li><li>医药生物行业深度报告：AI与医疗产业深度融合，有望为医疗带来产业变革.pdf</li><li>2025-02-27 14:48</li><li>医药生物行业报告：“AI+医疗”高景气度有望持续，创新药利好政策持续加码.pdf</li><li>2025-02-25 14:32</li><li>医疗器械专题之基因测序：分子诊断掌上明珠，四代测序开启规模化应用时代.pdf</li><li>2025-02-25 14:32</li><li>东吴证券-AI+医疗：提质增效，全面赋能.pdf</li><li>2025-02-25 14:32</li><li>AI医疗专题系列二：从DEEPSEEK的崛起看AI医疗发展方向及投资机会.pdf</li><li>2025-02-24 15:38</li><li>医疗AI专题报告-一-：制药篇：大鹏一日同风起，AI医疗启新篇.pdf</li><li>2025-02-24 15:38</li><li>医药生物行业行业深度报告：Deepseek冲击波系列报告-医疗AI赋能，大数据价值深度挖掘.pdf</li><li>2025-02-23 16:20</li><li>AI医疗行业专题报告：模型平权下的AI医疗大时代，梳理海内外AI+医疗投资机会.pdf</li><li>2025-02-23 16:13</li><li>计算机行业深度报告：DeepSeek系列报告之AI+医疗.pdf</li><li>2025-02-20 14:51</li><li>动脉橙：2025年1月全球医疗健康领域投融资月报.pdf</li><li>2025-02-20 14:47</li><li>AI+医疗行业深度：AI+医药：势不可挡，未来已至.pdf</li><li>2025-02-20 14:41</li><li>洞察宠物医疗保险市场.pdf</li><li>2025-02-18 15:44</li><li>医药生物：再论AI医疗如何选：海外映射+寻找高壁垒赛道.pdf</li><li>2025-02-18 15:35</li><li>医药生物行业：医疗器械行业全景图：发展趋势及投资机会展望.pdf</li><li>2025-02-18 15:35</li><li>国信证券-人工智能行业专题：第一大应用-海内外医疗AI梳理.pdf</li><li>2025-02-12 14:22</li><li>拉丁美洲医疗保健和生命科学部门市场准入快速指南.pdf</li><li>2025-02-10 16:20</li><li>摩熵咨询：2024年反腐整风运动下医疗及药企产业变局分析报告.pdf</li><li>2025-02-09 17:36</li><li>AON怡安智库：2025年全球医疗趋势报告.pdf</li><li>2025-02-08 15:13</li><li>医药生物行业2025年年度策略：政策拐点愈发明确，布局创新药+医疗设备+服务.pdf</li><li>2025-02-08 15:04</li></ul>]]></description></item><item>    <title><![CDATA[不共享数据，也能联合训练！UCL团队用联邦学习重塑血液形态学检查 超神经HyperAI ]]></title>    <link>https://segmentfault.com/a/1190000047609936</link>    <guid>https://segmentfault.com/a/1190000047609936</guid>    <pubDate>2026-02-13 16:01:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>血液形态学检查是临床诊断血液疾病的重要环节，通过观察外周血涂片（PBS）或骨髓穿刺（BMA）中的细胞形态，医生可以判断白血病、贫血、感染及遗传性血液疾病的类型。然而，这一过程不仅劳动强度大，而且高度依赖经验丰富的专业人员。尤其在低收入和中等收入国家（LMICs），技能专家稀缺，使得快速、可靠且可扩展的血液学诊断成为急需解决的问题。</p><p>近年来，人工智能和深度学习的发展为血液形态分析提供了新的解决方案。AI 模型能够自动识别不同类型的白细胞，并辅助医生进行快速诊断。研究表明，深度学习在自动化血液学诊断中具备显著潜力，但现实应用中仍面临重要挑战——模型训练对数据的依赖性极强，而临床数据通常分布在不同医院，且存在染色方法差异、成像设备差异以及少数罕见细胞类型的问题。这种数据异质性会导致模型在新机构或新患者群体中泛化能力下降。</p><p>更重要的是，医疗数据涉及患者隐私，跨机构共享数据受到严格限制。传统集中式训练方法通常需要汇集大量敏感医疗数据并依赖高性能计算资源，在很多机构难以实现。如何在保护隐私的前提下，实现多机构协作训练，成为医疗 AI 领域亟待解决的关键问题。</p><p>在此背景下，来自伦敦大学学院（UCL）计算机科学系的研究团队提出了一种用于白细胞形态分析的联邦学习框架，使各机构能够在不交换训练数据的情况下进行协同训练。利用来自多个临床站点的血液涂片，该联邦模型在保证完全数据隐私的同时，学习到稳健且域不变的特征表示。在卷积网络和基于 Transformer 的架构上的评估表明，与集中式训练相比，联邦训练在跨站点性能和对未知机构的泛化能力上表现出色。</p><p>相关研究成果以「MORPHFED: Federated Learning for Cross-institutional Blood Morphology Analysis」为题，已发布预印本于 arXiv。</p><p>研究亮点：</p><ul><li>与集中式训练相比，联邦训练在跨站点性能和对未知机构的泛化能力上表现出色</li><li>该方法能够在不共享原始数据的情况下，实现跨机构模型协作训练，为资源有限的医疗环境提供了一种可行的解决方案。</li></ul><p><img width="723" height="396" referrerpolicy="no-referrer" src="/img/bVdnVGf" alt="" title=""/><br/><em>论文地址：</em>\<br/><em><a href="https://link.segmentfault.com/?enc=lYdxyQsPxmOG2%2BDdSlpbvA%3D%3D.1c%2Bbfyu%2FLHgY9IxZJ7HVFZldYhv130U8RP1%2B2piUOa0ypOHOPIUOzR2nX5tubCV3" rel="nofollow" target="_blank">https://arxiv.org/abs/2601.04121</a></em>\<br/>关注公众号，后台回复「MORPHFED」获取完整 PDF</p><h2>数据集：反映现实临床中的异质性</h2><p>本研究使用了来自多个医疗机构的血液涂片数据，确保训练数据既能覆盖不同细胞类型，又能反映现实临床中的异质性。</p><p>具体而言，研究使用了来自两个中心的独立数据集，这两个数据集包含 11 种共同细胞类型（如中性粒细胞、嗜酸性粒细胞、嗜碱性粒细胞、早幼粒细胞等），保证分类目标一致，同时保留了染色和成像的差异，用于测试联邦学习在真实异质环境下的泛化能力。</p><p>下图显示了不同客户端的类别分布情况</p><p><img width="732" height="542" referrerpolicy="no-referrer" src="/img/bVdnVGg" alt="" title="" loading="lazy"/><br/>联邦客户端中的类别分布</p><p>下图则展示了两个训练数据集中部分细胞类型的示例，可以明显观察到染色风格的差异，这正是模型需要克服的数据偏移。</p><p><img width="716" height="378" referrerpolicy="no-referrer" src="/img/bVdnVGh" alt="" title="" loading="lazy"/><br/>两个训练数据集中样本细胞类型</p><p>此外，为了独立评估模型在完全未见过机构数据上的表现，研究保留了来自巴塞罗那临床医院（Client 3）的 12,992 张图像，作为外部验证集。该数据集具有不同的成像设备、染色方法及患者群体，用于测试模型在真实跨机构场景下的泛化能力。</p><h2>两类深度学习架构和四种联邦聚合策略</h2><p>本研究采用了两类深度学习架构：</p><ul><li>ResNet-34：基于卷积神经网络（CNN）的经典架构，使用 ImageNet 预训练权重。</li><li>DINOv2-Small：基于自监督视觉Transformer（Vision Transformer, ViT），通过自监督学习捕捉图像全局特征。</li></ul><p>训练遵循统一协议：联邦模型进行了 5 轮全局通信，每轮每个客户端进行 5 个本地训练周期，总计 25 个训练周期；集中式基线模型使用 25 个训练周期，并进行 4 折交叉验证，如下图所示。数据划分为 60% 训练集、13.33% 验证集、13.33% 本地测试集和 13.33% 全局测试集；所有图像均调整为 224×224 像素，并采用保守的数据增强策略（平移 ±10%，旋转 ±5°）以保持诊断形态信息。</p><p><img width="723" height="204" referrerpolicy="no-referrer" src="/img/bVdnVGi" alt="" title="" loading="lazy"/>*(A) 联邦学习框架展示了隐私保护的协作训练过程，其中 Client 1 和 Client 2 在本地进行模型训练，参数在中央服务器进行聚合。\<br/>(B) 集中式训练范式，完全访问合并数据集，并使用 4 折交叉验证。*</p><p>两种架构均采用选择性微调：ResNet-34 冻结早期层，仅训练最后三个残差块（约 11M 参数）；DINOv2-Small 冻结前 8 个 Transformer 块（0-7），训练第 8 至 11 块（约 9M 参数）。Client 3 的数据在所有训练过程中保持隔离，仅用于评估最终模型对新机构数据的泛化能力。</p><p>在联邦学习框架中，中央服务器负责协调训练并分发全局参数，但不访问原始数据；客户端在本地训练，仅返回参数更新。</p><p>研究采用了四种联邦聚合策略：</p><ul><li>FedAvg：计算客户端参数的加权平均，对极端类别分布敏感。</li><li>FedMedian：逐坐标取中值，对异常客户端和拜占庭错误具有稳健性，但可能抑制少数类信号。</li><li>FedProx：在本地目标函数中加入近端约束，增强非IID数据下的收敛稳定性。</li><li>FedOpt：在聚合梯度上使用自适应优化（Adam），动态调整学习率以应对客户端异质性，并加快收敛。</li></ul><p>此外，为解决严重类别不平衡问题，研究结合了 Focal Loss、加权随机采样以及梯度累积策略，保证少数类细胞的训练信号不被忽略。梯度裁剪（最大范数 1.0）确保训练过程稳定收敛。</p><p>模型性能通过平衡准确率（balanced accuracy）进行评估，重点关注跨机构泛化能力，以测试模型在遇到不同成像协议和患者群体的数据时的稳健性。</p><h2>联邦训练在跨站点性能和对未知机构的泛化能力上表现出色</h2><p>为了验证联邦学习框架的有效性，研究人员分别进行了联合测试集评估和外部分布数据泛化评估。</p><p>①联合测试集评估</p><p>模型在包含两个客户端数据的联合数据集上进行评估，结果如下表所示，不同聚合方法在不同架构上的表现存在显著差异。</p><p><img width="723" height="402" referrerpolicy="no-referrer" src="/img/bVdnVGj" alt="" title="" loading="lazy"/><br/>联邦学习聚合方法在 ResNet-34 和 DINOv2-Small 架构上的性能比较，涵盖四种联邦策略</p><p>值得注意的是，FedOpt 表现出极大的波动性：在 ResNet-34 上表现极差（平衡准确率 0.3638），而在 DINOv2-S 上保持了有竞争力的性能（平衡准确率 0.5594）；相比之下，FedAvg 和 FedProx 在两种模型上表现相对稳定；FedMedian 在两种架构上表现最一致，分别达到 ResNet-34 的平衡准确率 0.5738 和 DINOv2-S 的 0.5797。</p><p>结果表明，联邦学习显著提升了性能，相比仅使用单个机构数据训练的模型（58% vs 52% 平衡准确率），证明了无需共享数据即可进行协同训练的优势。尽管联邦模型的性能略低于对所有数据进行集中训练的模型，但它们在保持完整数据隐私的同时，仍能达到可比精度。</p><p>②外部分布数据泛化评估</p><p>对来自巴塞罗那的 Client 3 外部验证数据集的评估显示，两种联邦方法（FedMedian 和 FedOpt）在完全未见过的机构数据上的泛化能力均优于集中式训练（平衡准确率 67% vs 64%），如下表。这表明，在联邦训练过程中接触到异质的机构特征（如成像设备、患者群体和染色方法）有助于模型学习更具泛化性的形态特征。</p><p><img width="723" height="528" referrerpolicy="no-referrer" src="/img/bVdnVGk" alt="" title="" loading="lazy"/><br/>Client 3 外部验证的类别级 F1 分数</p><p>FedMedian 在少数类细胞上表现出特别显著的提升：带状中性粒细胞（Band neutrophils）F1: 0.62 vs 集中式 0.30（提升 107%），早幼粒细胞（Promyelocytes）F1: 0.61 vs 0.35（提升 74%），显示在不同机构协议下诊断相关特征得到了有效保留。然而，对中幼粒细胞（Metamyelocytes）的识别对所有方法仍然具有挑战性（F1: 0.02-0.30），反映出从极其罕见类别学习稳健表征的根本困难</p><p>③架构-聚合策略相互作用规律</p><p>研究人员还进一步识别出关键的架构-聚合策略相互作用规律：FedMedian 提供跨架构稳健性，但对罕见类别不利；FedOpt 在少数类细胞信号保真上表现更好，但对架构敏感。DINOv2-S 的预训练 Transformer 架构对非IID数据分布表现出更高鲁棒性，而 ResNet-34 对梯度冲突更敏感。</p><p>总体而言，这些发现将联邦学习定位为稳健、隐私保护且具泛化能力的血液学影像分析框架。</p><h2>联邦学习成为破解医疗「数据孤岛」的关键</h2><p>联邦学习是一种面向分布式数据环境的协同机器学习范式，其核心理念是在不集中原始数据的前提下完成模型联合训练。在联邦学习框架中，各参与机构（如医院、实验室或研究中心）在本地进行模型训练，仅向中央服务器上传模型参数或梯度更新，服务器负责对这些更新进行聚合并生成全局模型，再将模型下发至各节点继续迭代训练。通过这种「数据不出域、模型可协作」的机制，联邦学习在实现跨机构知识共享的同时，能够有效保护数据隐私并满足严格的数据合规要求。</p><p>过去几年，已有不少机构在推进如何用联邦学习赋能医疗行业，典型的比如端到端人工智能生物技术公司 Owkin——该公司曾获得法国 20 家值得关注的人工智能初创企业、2023 年最值得关注的医疗和技术初创公司之一、最佳医疗技术大奖、福布斯 AI 50 强。</p><p>让 AI 技术在多模态患者数据中识别不同的生物标志物，并对患者进行亚群分类，将每类患者与最佳治疗靶点匹配，推动靶点药物研发、优化疾病诊断工具，实现真正意义上的个性化医疗，是 Owkin 公司正在走的路。而实现以上目标的关键在于——如何既能进行数据共享，又能保证患者的数据隐私？针对此，Owkin 采用联邦学习来解决。为了推动相关技术的普及，Owkin 开源了联邦学习软件 Substra ，可用于临床研究、药物研发等。\<br/>开源地址：</p><p><a href="https://link.segmentfault.com/?enc=%2F3oacSj744LInelpoTybng%3D%3D.q7dmbOHCHcy1RQMnobU%2FPP2tCofU5GL4ek9Fc1BIfdo%3D" rel="nofollow" target="_blank">https://github.com/substra</a></p><p>而在医疗影像领域，联邦学习同样被视为破解「数据孤岛」和隐私合规难题的关键技术路径。医疗影像数据高度敏感，涉及患者隐私与严格监管（如 GDPR、HIPAA 等），传统集中式训练往往面临伦理审批、法律风险和数据跨境传输限制等现实障碍。联邦学习使得不同医院能够在不共享原始影像数据的情况下联合训练模型，从而提升模型对不同设备、不同染色协议、不同患者群体的泛化能力。已有研究表明，联邦学习在放射影像、数字病理、超声影像等领域可实现接近甚至超过集中式训练的跨机构泛化性能，尤其在外部数据测试中表现出更强的鲁棒性。</p><p>从更宏观的角度看，联邦学习所代表的「分布式协同智能」模式，正在成为未来医疗 AI 规模化部署的重要基础设施。它不仅为隐私保护型医学大模型的训练提供了可行路径，也为跨机构临床决策支持系统和全球协作医学研究平台奠定了技术基础。在血液形态分析等细分领域，联邦学习有望推动 AI 从单机构实验室应用走向跨区域、跨体系的临床级智能诊断服务，为精准医学和数字化医疗提供关键支撑。</p><p>参考文献：<br/>\<br/>1.<a href="https://link.segmentfault.com/?enc=sQ8rxQ7Q1PZ7ww9d0gdXMQ%3D%3D.kBvb%2FlmM5SzR0TMsHa6QLJZEU7T2kXIr2MfCkdpoUEV5m9Tolbz8FljakWyNIb9R" rel="nofollow" target="_blank">https://arxiv.org/abs/2601.04121</a><br/>\<br/>2.<a href="https://link.segmentfault.com/?enc=d1aqQaxxoekg9fsiN438PA%3D%3D.perrXz4Fb1BKfhw0gH%2BhsdBhL0uaED6kVpt3xfItNP%2BnM6UrOA8c9vg55DP7aG5l63phHb6DWb7N4pMzO%2BNXhQ%3D%3D" rel="nofollow" target="_blank">https://mp.weixin.qq.com/s/Lf6N7EUHlhibLNc9YXWjTQ</a><br/></p>]]></description></item><item>    <title><![CDATA[随心项目管理公众号系统详细介绍 微擎应用市场 ]]></title>    <link>https://segmentfault.com/a/1190000047609773</link>    <guid>https://segmentfault.com/a/1190000047609773</guid>    <pubDate>2026-02-13 15:04:35</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>一、概述总结</p><p>随心项目管理系统是一款专为外包团队、设计团队及项目驱动型组织打造的轻量级项目管理工具。该系统由开发者基于自身实际需求开发，旨在解决项目分类管理、进度跟踪及团队协作中的常见痛点，以低成本、免开发的方式帮助中小团队快速实现项目数字化管理。</p><p>核心定位：聚焦项目全生命周期管理，提供从项目创建、任务分配到进度查询的一站式解决方案，特别适合需要精细化流程管理的外包服务团队。</p><hr/><p>二、功能介绍</p><ol><li>项目分类管理</li></ol><ul><li>支持多维度项目分类，便于外包团队按客户、类型、优先级等维度管理项目</li><li>灵活的项目归档与检索功能，历史项目数据可追溯</li></ul><ol start="2"><li>流程查询与进度跟踪</li></ol><ul><li>可视化项目进度查询，团队成员可实时掌握项目状态</li><li>清晰的任务流转记录，减少沟通成本</li></ul><ol start="3"><li>团队协作功能</li></ol><ul><li>适配美工、UI设计师等创意团队的工作流程</li><li>支持团队成员间的任务分配与协同</li></ul><ol start="4"><li>系统配置</li></ol><ul><li>演示环境：<a href="https://link.segmentfault.com/?enc=hv%2FJffg5QdzkJPHjo%2F8fBg%3D%3D.7ro5E%2BXftk3Jg2PSXFtlFw9gD99vOYace1uLLlgQkLE%3D" rel="nofollow" target="_blank">http://project.xqzbk.top/</a>（账号：admin / 123456）</li><li>支持微信公众号端接入</li><li>基于PHP7.1开发，源码加密交付</li></ul><hr/><p>三、适用场景与行业价值</p><p>适用场景</p><p>场景类型 具体应用</p><p>外包服务团队 软件外包、设计外包项目全流程管理</p><p>创意工作室 美工、UI/UX设计项目进度管控</p><p>小型技术团队 内部项目分类与任务分配</p><p>自由职业者联盟 多人协作项目的进度同步</p><p>行业价值</p><ol><li>降低管理成本：无需自建开发团队，即买即用，节省90%以上开发投入</li><li>提升协作效率：通过系统化的项目分类和进度查询，减少50%以上的沟通时间</li><li>规范流程管理：为外包团队建立标准化的项目交付流程，提升客户满意度</li><li>快速部署上线：基于微擎平台，支持微信公众号快速接入，触达10亿+用户生态</li></ol><hr/><p>四、产品参数与购买信息</p><ul><li>交付方式：微擎系统在线交付，源码已加密</li><li>开发者信誉：5.00分（实名+企业双认证）</li></ul><hr/><p>问答环节（Q&amp;A）</p><p>Q1：这个系统适合多大的团队使用？</p><p>A：随心项目管理系统主要面向中小型外包团队、设计工作室及10-50人的项目驱动型组织。系统轻量易用，无需专职IT人员维护，特别适合没有技术开发能力但急需项目管理工具的团队。</p><p>Q2：购买后如何部署使用？</p><p>A：系统基于微擎平台交付，购买后可直接在您的微擎系统中安装。支持微信公众号接入，需确保服务器环境满足PHP7.1要求。具体部署可参考微擎官方文档或联系卖家客服。</p><p>Q3：系统数据安全性如何保障？</p><p>A：系统部署在您自己的服务器上，数据自主可控。微擎平台提供官方正品保障，开发者已通过实名认证和企业认证，信誉指数5.00分，可放心购买。</p><p>Q4：是否支持多项目管理？</p><p>A：是的，系统核心功能就是项目分类管理，支持同时管理多个项目，按客户、类型、状态等多维度分类，满足外包团队多项目并行的管理需求。</p><p>Q5：与普通项目管理工具（如Teambition、Tower）相比有什么优势？</p><p>A：随心项目管理系统深度适配外包团队工作流程，特别是针对美工、UI等创意岗位优化了项目分类和进度查询方式。同时基于微信生态，无需额外安装APP，在移动端使用更便捷，且一次购买永久使用，长期使用成本更低。</p><hr/><p>温馨提示：请勿线下交易！90%的欺诈、纠纷、资金盗取均由线下交易导致。请通过微擎官方平台完成购买，享受消费保障服务。</p>]]></description></item><item>    <title><![CDATA[飞创证书查询公众号管理系统 微擎应用市场 ]]></title>    <link>https://segmentfault.com/a/1190000047609776</link>    <guid>https://segmentfault.com/a/1190000047609776</guid>    <pubDate>2026-02-13 15:04:00</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>一、概述总结</p><p>飞创证书查询系统是微擎应用市场的一款专业证书管理工具，由KaijingStudio开发，该系统是一款高度自定义的证书管理与查询解决方案，适用于各行各业，旨在帮助企业和机构实现证书信息的数字化管理、快速查询与批量生成。</p><p>系统核心优势在于"零技术门槛"——用户无需编程基础，只需填写相应信息即可自动生成证书，大幅降低证书制作与管理成本。目前已获得14家企业采用，在微擎平台拥有5.0分的信誉评分和应用评分。</p><hr/><p>二、功能介绍</p><p>核心功能模块：</p><ol><li><p>高度自定义字段系统</p><ul><li>支持根据行业需求灵活配置证书字段</li><li>可自定义证书内容结构，满足不同证书类型要求</li></ul></li></ol><ol start="2"><li><p>高度自定义模板引擎</p><ul><li>提供可视化模板设计功能</li><li>支持多种证书版式自定义，打造品牌专属证书样式</li></ul></li></ol><ol start="3"><li><p>智能查询系统</p><ul><li>自定义手机端搜索条件</li><li>用户可通过微信快速查询证书真伪与详情</li><li>支持多维度检索，提升查询效率</li></ul></li></ol><ol start="4"><li><p>批量打印模板</p><ul><li>内置批量打印功能</li><li>支持证书批量生成与打印，大幅提升工作效率</li></ul></li></ol><ol start="5"><li><p>多平台适配</p><ul><li>支持微信公众号端部署</li><li>可扩展至微信小程序、抖音小程序等多平台</li></ul></li></ol><p>技术特性：</p><ul><li>交付方式：在线交付，微擎系统一键部署</li><li>源码加密：已加密，保障系统安全性</li><li>运行环境：支持PHP7.1+</li><li>数据获取：需获取用户基本信息（昵称、头像、性别、地区）、位置信息及相册权限</li></ul><hr/><p>三、适用场景与行业价值</p><p>适用场景：</p><p>场景类型 具体应用</p><p>教育培训 学员结业证书、培训合格证、在线课程证书</p><p>企业认证 员工资质证书、产品认证证书、授权经销商证书</p><p>行业协会 会员资格证书、技能等级证书、荣誉奖项证书</p><p>政府机构 行政许可证书、资质认定证书、电子证照</p><p>赛事活动 参赛证书、获奖证书、志愿者服务证书</p><p>行业价值：</p><ol><li>降本增效：替代传统纸质证书制作流程，节省设计、印刷、邮寄成本</li><li>防伪溯源：数字化证书+查询系统，有效防范证书造假</li><li>品牌升级：自定义模板打造专业证书形象，提升机构公信力</li><li>数据管理：集中化证书数据管理，支持批量操作与统计分析</li><li>用户体验：手机端即时查询，提升用户满意度与信任度</li></ol><hr/><p>四、常见问题解答（Q&amp;A）</p><p>Q1：这个系统需要技术背景才能使用吗？</p><p>A：不需要。系统设计初衷就是"简单易操作"，普通工作人员只需填写信息即可自动生成证书，无需编程或设计基础。</p><p>Q2：证书模板可以自定义设计吗？</p><p>A：完全可以。系统支持高度自定义模板，您可以根据品牌VI设计专属证书样式，包括LOGO、配色、版式等。</p><p>Q3：用户如何查询证书？</p><p>A：用户可通过微信公众号或小程序，输入指定信息（如姓名、证书编号等）进行查询。查询条件支持后台自定义设置。</p><p>Q4：是否支持批量生成证书？</p><p>A：支持。系统提供批量打印模板功能，可一次性生成大量证书，适合毕业季、培训结业等批量场景。</p><p>Q5：数据安全性如何保障？</p><p>A：系统源码已加密，部署在微擎平台，数据存储安全可靠。同时支持权限管理，确保敏感信息不被泄露。</p><p>Q6：可以部署到抖音小程序吗？</p><p>A：系统本身支持多平台扩展，具体抖音小程序定制开发需求可联系开发者KaijingStudio进行商谈。</p><p>Q7：系统对服务器有什么要求？</p><p>A：需要支持PHP7.1+的运行环境，建议使用微擎官方推荐的服务器配置以确保最佳性能。</p>]]></description></item><item>    <title><![CDATA[防伪溯源红包微信公众号系统 微擎应用市场 ]]></title>    <link>https://segmentfault.com/a/1190000047609781</link>    <guid>https://segmentfault.com/a/1190000047609781</guid>    <pubDate>2026-02-13 15:03:27</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>一、概述总结</p><p>防伪溯源红包微信小程序系统是微擎平台上一款集防伪验证、产品溯源、红包营销于一体的数字化营销工具。该系统基于"一物一码"核心技术，为每个商品赋予唯一数字身份，实现"识别-互动-留存"的完整闭环。</p><p>核心定位：不仅是防伪查询工具，更是连接品牌与消费者的智能营销入口，帮助企业实现产品数字化、用户数据化、营销精准化。</p><hr/><p>二、功能介绍</p><ol><li>一物一码防伪溯源</li></ol><ul><li>唯一身份标识：为每个产品生成独一无二的二维码，绑定防伪码、溯源码、营销码</li><li>真伪即时验证：消费者扫码即可验证产品真伪，防止假冒伪劣</li><li>全生命周期追溯：展示加工原料、生产日期、流通渠道、质检报告等完整信息</li><li>安全验证码机制：配合物理防伪标签，双重保障品牌安全</li></ul><ol start="2"><li>智能红包营销系统</li></ol><ul><li>多样化奖励形式：支持现金红包、实物奖品、积分、优惠券、抽奖等多种奖励</li><li>灵活发放规则：可设置固定/随机金额、扫码即得、关注公众号领红包、首次验证奖励等</li><li>裂变营销玩法：支持邀请好友助力、拼团扫码、连续扫码任务等社交裂变模式</li><li>精准投放策略：基于LBS地理位置、用户标签、扫码次数等维度精准发放</li></ul><ol start="3"><li>数据统计与分析</li></ol><ul><li>实时数据看板：可视化展示扫码人数、时间、区域、红包领取金额等核心指标</li><li>用户画像构建：收集用户微信昵称、头像、性别、地区等信息，建立精准用户档案</li><li>渠道效果分析：追踪不同渠道、批次的扫码转化效果，优化投放策略</li><li>ROI智能核算：自动计算营销投入产出比，辅助预算决策</li></ul><ol start="4"><li>系统管理功能</li></ol><ul><li>多开模式支持：支持多商家、多活动无限多开，满足连锁品牌需求</li><li>批次管理：防伪码可定义前缀、位数，支持按批次统计管理</li><li>防窜货追踪：记录每个二维码的扫描地点，自动预警窜货行为</li><li>权限分级：支持管理员、代理商、销售商、溯源员等多角色权限设置</li><li>自定义配置：商品参数、溯源信息、页面风格、菜单等均可自定义</li></ul><hr/><p>三、适用场景与行业价值</p><p>适用场景</p><p>行业领域 典型应用 核心价值</p><p>快消行业 饮料、零食、日用品开盖/开袋扫码 提升终端动销率，促进复购</p><p>酒类行业 白酒、啤酒瓶盖二维码 防伪溯源+红包激励双效合一</p><p>美妆护肤 中小品牌洗护产品包装码 低成本获客，吸引年轻消费群体</p><p>母婴行业 奶粉罐码、纸尿裤袋码 一罐一码，增强消费者信任</p><p>农资行业 化肥、种子包装袋码 针对农村市场简化操作，扩大覆盖</p><p>建材行业 涂料、管材产品码 小工返利码，激励渠道推荐</p><p>汽配行业 润滑油、配件产品码 汽修师傅专属红包，锁定专业客群</p><p>行业价值</p><ol><li>降低营销成本：红包直达消费者，省去中间环节，费用精准可控</li><li>提升用户粘性：互动式扫码体验增强参与感，重复领取机制促进复购</li><li>沉淀数据资产：构建品牌私域流量池，为精准营销提供数据支撑</li><li>强化品牌保护：一物一码+区块链溯源，有效打击假冒伪劣</li><li>赋能渠道管理：通过扫码数据追踪货物流向，防止窜货乱价</li><li>促进社交裂变：分享领红包机制实现低成本口碑传播</li></ol><hr/><p>四、问答环节</p><p>Q1：这个系统如何确保防伪码不被复制盗刷？</p><p>A： 系统采用"一物一码"技术，每个二维码都是唯一且一次性的。首次扫码验证后即失效，后台会记录扫码时间、地点、设备等信息。若发现异常扫码行为（如短时间内同一码被多次扫描），系统会自动预警。同时支持启用"炮灰域名"功能，隐藏主域名，降低被封风险。</p><p>Q2：红包发放支持哪些形式？能否设置领取条件？</p><p>A： 支持现金红包（直达微信零钱）、积分、优惠券、实物奖品、抽奖机会等多种形式。领取条件可灵活设置，包括：扫码即得、关注公众号后领取、输入验证码领取、地理位置限制、首次验证奖励、连续扫码奖励等，满足不同营销场景需求。</p><p>Q3：系统是否支持多门店、多品牌管理？</p><p>A： 支持。系统采用多开模式设计，可无限创建不同活动、不同品牌、不同门店的独立管理后台。每个活动可单独设置红包金额、数量、有效期、适用地区等参数，数据独立统计，满足连锁品牌和集团化运营需求。</p><p>Q4：如何防止代理商或门店恶意刷单？</p><p>A： 系统内置多重风控机制：①LBS地理位置限制，超出范围无法领取；②微信个人资料区域限制；③单设备/单微信号领取次数限制；④异常扫码行为监测（如同一地点短时间内大量扫码）；⑤人工审核机制。同时支持黑名单功能，可将可疑账号加入黑名单禁止参与。</p><p>Q5：溯源信息如何录入？是否支持前端添加？</p><p>A： 支持两种方式：①管理员在后台统一录入产品溯源信息；②授权前台溯源员通过移动端扫描添加，适合生产现场实时录入。溯源信息可包括原料来源、生产批次、质检报告、物流轨迹等，消费者扫码后完整展示，增强信任感。</p><p>Q6：系统对服务器和PHP版本有什么要求？</p><p>A： 系统兼容PHP5.3至PHP7.1版本，支持所有微擎版本，无需额外安装插件。建议服务器配置：Linux系统、Nginx/Apache、MySQL5.5+，以确保高并发扫码场景的稳定性。同时支持自动和手工两种红包发放模式，适应不同运营节奏。</p><p>Q7：购买后是否提供技术支持和二次开发？</p><p>A： 作为官方正品模块，提供标准售后服务。如需深度定制（如对接ERP系统、定制特殊营销玩法、UI界面深度改造等），可联系开发者进行付费定制开发。源码已加密，但提供丰富的配置选项，一般无需改动代码即可满足常规需求。</p>]]></description></item><item>    <title><![CDATA[B2B行业平台小程序详细介绍 微擎应用市场 ]]></title>    <link>https://segmentfault.com/a/1190000047609785</link>    <guid>https://segmentfault.com/a/1190000047609785</guid>    <pubDate>2026-02-13 15:02:42</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>一、概述总结</p><p>B2B行业平台小程序是一款专为B2B业务场景打造的轻量化数字化解决方案。基于微信小程序生态开发，无需下载安装即可使用，帮助企业快速搭建集求购信息发布、产品展示、供应商管理、企业资料展示于一体的线上业务平台。该系统源码已加密，支持在线交付，适用于各类垂直行业的B2B交易撮合场景，助力企业实现业务数字化转型。</p><hr/><p>二、功能介绍</p><ol><li>求购信息管理</li></ol><ul><li>支持采购商在线发布求购需求</li><li>实时推送求购信息给匹配供应商</li><li>求购状态跟踪与历史记录查询</li></ul><ol start="2"><li>产品管理系统</li></ol><ul><li>供应商可自主上传产品信息</li><li>支持产品分类、标签、多图展示</li><li>产品上下架与库存状态管理</li></ul><ol start="3"><li>供应商信息管理</li></ol><ul><li>供应商资质审核与认证</li><li>企业信息展示与信用评级</li><li>供应商分类标签化管理</li></ul><ol start="4"><li>发布信息管理</li></ol><ul><li>信息审核机制，确保内容合规</li><li>信息置顶、推荐等运营功能</li><li>数据统计与曝光量分析</li></ul><ol start="5"><li>企业资料模块</li></ol><ul><li>企业简介、联系方式展示</li><li>企业资质证书上传</li><li>企业动态与新闻发布</li></ul><ol start="6"><li>平台运营工具</li></ol><ul><li>红包营销功能（霸榜红包）</li><li>用户收藏与分享机制</li><li>消息通知系统</li></ul><hr/><p>三、适用场景与行业价值</p><p>适用场景</p><ul><li>垂直行业B2B平台：建材、机械、电子元器件、化工原料等行业</li><li>供应链协同平台：连接上游供应商与下游采购商</li><li>产业带数字化：为产业集群提供线上展示与交易撮合服务</li><li>展会线上化：线下展会配套线上供需对接平台</li></ul><p>行业价值</p><ol><li>降低获客成本：通过小程序轻量化入口，减少企业营销投入</li><li>提升交易效率：信息实时同步，缩短供需匹配周期</li><li>数据资产沉淀：积累行业交易数据，辅助商业决策</li><li>增强客户粘性：便捷的交互体验提升用户留存率</li><li>快速部署上线：基于成熟源码，大幅降低开发周期与成本</li></ol><hr/><p>四、常见问题解答（Q&amp;A）</p><p>Q1：这款小程序是否需要额外开发？</p><p>A：系统为成品源码交付，已包含核心B2B功能模块，可直接部署使用。如需个性化定制，可联系开发者进行二次开发。</p><p>Q2：小程序是否支持多平台？</p><p>A：当前版本基于微信小程序生态开发，主要适用于微信端。如需抖音小程序等其他平台版本，可咨询定制开发服务。</p><p>Q3：源码加密是否影响二次开发？</p><p>A：源码已加密，但提供标准接口文档。基础功能配置可通过后台完成，深度定制需开发者协助。</p><p>Q4：平台如何保证交易安全？</p><p>A：系统内置信息发布审核机制，支持企业资质认证。建议结合平台担保交易或线下验货等模式，确保交易安全。</p><p>Q5：是否提供售后服务？</p><p>A：购买后可享受平台基础技术支持。建议开通微擎VIP，可获得30天无售后急速退款保障及优先技术支持。</p><p>Q6：适合什么规模的企业使用？</p><p>A：适用于中小型企业快速搭建B2B平台，也适合行业协会、产业园区构建垂直领域供需对接平台。</p><p>Q7：如何提升平台用户活跃度？</p><p>A：系统内置红包营销、信息收藏、分享裂变等功能，运营方可结合行业活动、精准推送等策略提升活跃度。</p><p>交付方式：微擎系统在线交付</p>]]></description></item><item>    <title><![CDATA[疯狂社群裂变系统详细介绍 微擎应用市场 ]]></title>    <link>https://segmentfault.com/a/1190000047609788</link>    <guid>https://segmentfault.com/a/1190000047609788</guid>    <pubDate>2026-02-13 15:02:06</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>一、概述总结</p><p>疯狂社群裂变是一款专注于微信公众号平台的社群营销工具，由艺霖科技开发。该系统以"红包裂变"为核心机制，通过现金奖励驱动用户主动分享传播，帮助商家实现低成本、高效率的社群引流与用户增长。</p><p>系统采用Swoole加密技术，需安装swoole_loader扩展运行。它整合了红包激励、付费入群、卡密系统、资源发放等多种变现与裂变手段，形成完整的社群运营闭环。</p><hr/><p>二、适用场景与行业价值</p><ol><li>核心适用场景</li></ol><ul><li>知识付费社群：通过付费入群+卡密系统，实现课程、资料的有偿分享</li><li>资源引流：利用网盘资源自动发放，吸引精准用户群体</li><li>活动裂变：红包激励驱动用户分享，快速扩大活动影响力</li><li>私域流量池建设：将公域流量转化为可控的社群资产</li></ul><ol start="2"><li>重点服务行业</li></ol><ul><li>教育培训：在线课程推广、学习资料分发、学员社群运营</li><li>电商零售：产品推广、优惠券发放、粉丝群维护</li><li>内容创作：自媒体涨粉、付费专栏、资源变现</li><li>本地生活：商家联盟、社区团购、同城服务推广</li></ul><ol start="3"><li>行业价值</li></ol><ul><li>降低获客成本：相比传统广告投放，红包裂变成本更低、效果更精准</li><li>提升用户粘性：通过社群运营建立长期用户关系，提高复购率</li><li>实现自动化变现：付费入群+资源发放形成无人值守的变现闭环</li><li>数据资产沉淀：自定义表单收集用户数据，构建私域流量池</li></ul><hr/><p>三、常见问题解答（Q&amp;A）</p><p>Q1：这个系统支持哪些平台？</p><p>A：目前主要支持微信公众号平台，需配合微擎系统使用。</p><p>Q2：系统运行有什么技术要求？</p><p>A：系统已进行Swoole加密，需要服务器安装swoole_loader扩展。如不会安装，可联系客服免费协助。</p><p>Q3：红包裂变是否安全合规？</p><p>A：系统提供"炮灰域名"功能，可有效保护主域名安全。但使用时仍需遵守微信平台规则，避免过度营销。</p><p>Q4：能否同时开展多个活动？</p><p>A：支持多活动管理，您可以同时运营多个裂变活动，每个活动独立配置，互不干扰。</p><p>Q5：付费入群的资金如何结算？</p><p>A：资金通过微信支付接口直接进入商户账户，系统不介入资金流转，保障资金安全。</p><p>Q6：是否支持定制化开发？</p><p>A：系统提供自定义表单等灵活配置，如需深度定制，可联系开发商艺霖科技咨询。</p>]]></description></item><item>    <title><![CDATA[外贸邮件开发信不封号攻略:避开3个坑,选对方法高效获客 旅途中的围巾_d7edGc ]]></title>    <link>https://segmentfault.com/a/1190000047609799</link>    <guid>https://segmentfault.com/a/1190000047609799</guid>    <pubDate>2026-02-13 15:01:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在外贸获客的诸多渠道中，电子邮件营销始终凭借成本低、覆盖面广、可沉淀客户资产的核心优势，成为企业开发海外客户的重要手段。但很多外贸人都有过这样的困扰：刚群发完开邮件发信，邮箱就被封，前期的客户名单和沟通努力全部白费。其实，群发邮件本身并非封号的根源，真正的问题在于选错了发送工具、用错了发送方式。本文就为外贸企业拆解群发邮件的避坑要点，教你如何安全、高效地做海外邮件群发。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047609801" alt="图片" title="图片"/></p><p>坑1：用个人邮箱群发，直接触发平台风控<br/>Gmail、Outlook、QQ邮箱、163邮箱等个人邮箱，核心定位是个人一对一日常沟通，从产品设计上就不支持营销类邮件的大规模发送，这也是外贸人用个人邮箱群发最易被封的根本原因。<br/>当个人邮箱出现以下行为时，平台风控系统会立即预警，轻则限制发送，重则直接封号且恢复难度极高：<br/>1、短时间内向大量陌生海外邮箱发送内容高度相似的开发信；<br/>2、收件人分散在不同国家、不同域名，发送行为偏离个人沟通逻辑；<br/>3、邮件多次被海外收件人标记为垃圾邮件，负面反馈累积；<br/>4、发送列表中包含大量无效、不存在的邮箱地址，退信率过高。个人邮箱仅适合少量熟客的日常沟通，绝对不能用于外贸开发信的群发。<br/>坑2：迷信企业邮箱，忽略其核心定位局限<br/>不少外贸企业为了规避个人邮箱的问题，使用企业邮箱后便直接用来群发邮件开发信，结果依然遭遇封号、送达率暴跌的问题，甚至影响公司正常业务沟通。这是因为企业邮箱的设计目标是企业日常业务沟通，而非规模化营销群发，其天然存在三大短板：</p><ol><li>有严格的单日发送量限制，无法满足外贸批量开发的需求；</li><li>高频群发会快速拉低企业邮箱的IP信誉，导致后续邮件易被归为垃圾邮件；</li><li>单一个IP/域名的信誉受损，会牵连公司其他正常使用的业务邮箱，影响日常办公、客户对接。当发送规模达到每天数千甚至上万封时，企业邮箱的风控风险会急剧上升，完全无法适配外贸规模化获客的需求。企业邮箱适合公司内部沟通、熟客对接，而非外贸冷启动的批量邮件开发信发送。<br/>坑3：忽视工具专业性，用“通用工具”做“专业事”<br/>无论是个人邮箱还是企业邮箱，封号的核心问题都是工具与使用场景不匹配。如果外贸企业已经进入持续、高频、规模化的邮件获客阶段，使用专业的外贸邮件群发工具，是规避封号风险、提升投递效率的唯一可行方案。以深耕邮件营销领域的U-Mail邮件群发平台为例，其核心设计逻辑围绕外贸行业的群发需求打造，从根源上解决了封号和送达率问题，这也是专业工具与普通邮箱的核心区别。<br/>选对专业工具，实现群发“零封号+高送达”专业的外贸邮件群发工具，并非简单的“批量发送”，而是通过技术手段实现合规发送、智能投递、信誉维护，以U-Mail为例，其核心优势体现在这5点：</li><li>专用通道+高信誉IP，从工具层面规避封号只要邮件内容正规合法、符合外贸沟通场景，U-Mail不会因发送量大而封号。平台为外贸客户配备专用群发通道，搭建了专属的投递风控模型，同时持续维护海内外高信誉IP资源，将封号风险完全控制在工具层面，无需用户承担账号被封的损失。</li><li>超大发送量，适配外贸规模化获客U-Mail单日最高可发送30万封邮件，完美匹配外贸企业的批量开发需求，无论是新客户开发信的全域投放、展会后客户的集中跟进，还是多国家、多市场的同步布局，都能轻松承接；同时采用一对一独立投递机制，每封邮件单独发送，有效降低被海外邮箱系统识别为垃圾邮件的概率。</li><li>海内外分离通道，针对性提升送达率外贸邮件的收件人遍布全球，不同国家、不同邮箱系统（Gmail、Outlook、Yahoo等）的投递规则差异极大。U-Mail打造海内外分离的专用发送通道，针对主流海外邮箱做了专属的投递优化，搭配独立维护的海外高信誉通道资源，大幅提升邮件的实际进箱率，避免邮件石沉大海。</li><li>自动化运营，节省团队时间成本平台支持定时发送、批量任务自动执行，外贸团队只需提前准备好邮件内容和客户名单，设置好发送时间，系统即可全程自动化完成投递，无需人工值守，让团队把精力集中在客户跟进和转化上，提升整体工作效率。</li><li>全维度数据追踪+免费邮箱清洗，从源头优化发送效果U-Mail提供完整的数据统计分析功能，邮件的送达情况、打开率、点击量、退信原因、无效地址等数据一目了然，帮助外贸团队快速优化邮件内容和发送策略；同时支持免费清洗无效邮箱地址，从源头降低退信率，进一步维护发送信誉，提升后续邮件的投递稳定性。<br/>补充：海外邮件群发工具怎么选？<br/>除了U-Mail，市场上也有一些海外邮件群发平台，外贸企业可根据自身业务规模和需求选择，以下是几款主流工具的核心特点，供大家参考：<br/>Mailchimp：品牌知名度高，功能成熟，适合做内容型邮件营销，但对海外冷邮件、外贸开发信的审核和限制较多，不太适配外贸冷启动场景；<br/>Brevo（原Sendinblue）：价格亲民，操作门槛低，适合中小规模的营销邮件发送，单日发送量有限，适合客群相对固定的外贸企业；<br/>GetResponse：自动化营销流程完善，适合做长期的客户生命周期运营，对开发信的适配性一般，更适合有成熟内容体系的外贸企业。<br/>核心提醒：多数海外平台对“冷邮件”“外贸邮件开发信”的审核规则严格，部分平台甚至禁止此类邮件发送，使用前务必充分了解平台规则，避免因违规导致账号被封。外贸邮件群发被封号，本质上是工具与发送场景不匹配的结果，选对工具，才能从根源上解决问题。<br/>1、少量熟客沟通、日常业务对接：个人邮箱/企业邮箱完全够用；<br/>2、批量海外客户开发、规模化获客：必须使用专业的外贸邮件群发平台。对于已经进入规模化外贸获客阶段的企业而言，选择U-Mail邮件群发平台，不仅能彻底规避封号风险，更能通过专用通道、智能投递、数据化运营，实现邮件营销的提效、提质、提转化，让海外客户开发更高效。</li></ol>]]></description></item><item>    <title><![CDATA[讯飞星辰免费Glm5计划及OpenClaw配置全指南 鸿枫 ]]></title>    <link>https://segmentfault.com/a/1190000047609505</link>    <guid>https://segmentfault.com/a/1190000047609505</guid>    <pubDate>2026-02-13 14:08:10</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在使用OpenClaw的过程中，很多用户都会面临Token消耗过快的问题，目前各大厂商纷纷推出相关Code Plan计划以优化Token使用体验，但多数需要付费购买。对于追求低成本、高实用性的用户而言，一款免费且可用的Token供应方案就显得尤为重要。本文将详细介绍讯飞星辰推出的春节免费Token计划，以及如何将其配置到OpenClaw中，帮助大家零成本畅享大模型应用。</p><p>一、讯飞星辰免费Token计划核心优势</p><p>讯飞星辰MaaS平台推出的春节免费Token计划，是目前验证可行的免费Token解决方案，核心优势集中在以下几点，适配OpenClaw用户的实际需求：</p><ul><li>完全免费：经实际测试，该计划真正实现0元获取Token，无需支付任何费用即可使用，有效解决OpenClaw Token消耗过快、成本过高的痛点。</li><li>适配性强：明确支持OpenClaw运行，无需额外修改工具核心设置，配置流程简单，新手也能快速上手。</li><li>官方合规：Token供应来自讯飞星辰官方平台，稳定性有保障，无需担心非正规渠道Token带来的账号安全或使用异常问题。</li></ul><p>补充说明：官方宣传该Token使用无速度限制，但实际使用过程中会存在轻微卡顿，整体流畅度可满足日常使用需求，属于可接受范围。</p><p>二、前期准备：获取讯飞星辰Token及相关授权</p><p>在进行OpenClaw配置前，需先前往讯飞星辰MaaS平台获取模型API授权、API Key等关键信息，具体步骤如下：</p><ol><li>访问讯飞星辰MaaS平台官方地址：<a href="https://link.segmentfault.com/?enc=iXqPgdeB2dpYSazH4tFZBg%3D%3D.tpWuL9tOOBipiFWAswntpiabnAVkmnHgBo6OCl7L5Xg%3D" rel="nofollow" target="_blank">https://maas.xfyun.cn/</a>，完成平台注册及登录（若已有账号可直接登录）。</li></ol><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609507" alt="" title=""/></p><ol start="2"><li>进入平台模型集市：访问<a href="https://link.segmentfault.com/?enc=QVuy4hOYMHKrdCK%2Bie7Xjw%3D%3D.fg%2BkQyzfxeo3Hy9MUnXc6pWuvhY0RzuoEAoN0IaO7rcOHaG0qALCboGVOiaVNJws" rel="nofollow" target="_blank">https://maas.xfyun.cn/modelSquare</a>，找到对应模型卡片，点击“API调用”按钮，即可获取模型API授权及现金礼品卡（礼品卡可用于后续相关服务拓展，非配置必需）。</li></ol><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609508" alt="" title="" loading="lazy"/></p><ol start="3"><li>获取核心配置信息：登录后进入推理服务控制台（地址：<a href="https://link.segmentfault.com/?enc=sOgblZMhL05YJ%2F21ugnmsw%3D%3D.8LRsJP50LqqmnI7oxDtIAehhv9ufS3T89w8hub%2BokZNAQZRhlTf3lhOakrFBhdm2" rel="nofollow" target="_blank">https://maas.xfyun.cn/modelService</a>），该页面将展示所有模型服务配置所需的关键信息，其中开发者专属API Key是后续配置的核心，需重点记录。</li></ol><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609509" alt="" title="" loading="lazy"/></p><p>三、OpenClaw详细配置步骤（附可直接复制模板）</p><p>讯飞星辰MaaS平台提供OpenAI兼容的接口形态，因此在OpenClaw中可直接按“OpenAI / OpenAI-Compatible”模式配置，具体操作如下，全程无需修改复杂参数：</p><p>步骤1：找到OpenClaw配置文件</p><p>打开OpenClaw工具，定位到配置文件（通常可在工具设置中找到“配置文件”入口，或按工具指引找到对应文件路径），将以下模板复制粘贴到配置文件中，替换原有相关配置（若配置文件为空，可直接粘贴）。</p><p>步骤2：填充核心配置信息</p><p>将前期在讯飞星辰推理服务控制台获取的API Key，替换模板中“YOUR_API_KEY”位置，其余参数无需修改（模板已包含常用模型及最优基础配置）。</p><p>可直接复制的配置模板</p><p>{<br/>  "meta": {</p><pre><code>"lastTouchedVersion": "2026.2.1",
"lastTouchedAt": "2026-02-04T12:14:10.945Z"</code></pre><p>},<br/>  "models": {</p><pre><code>"mode": "merge",
"providers": {
  "ds": {
    "baseUrl": "https://maas-api.cn-huabei-1.xf-yun.com/v2",
    "apiKey": "YOUR_API_KEY",
    "api": "openai-completions",
    "models": [
      {
        "id": "xopdeepseekv32",
        "name": "DeepSeek-V3.2",
        "reasoning": false,
        "input": [
          "text"
        ],
        "cost": {
          "input": 0.0025,
          "output": 0.01,
          "cacheRead": 0,
          "cacheWrite": 0
        },
        "contextWindow": 32768,
        "maxTokens": 32768
      }
    ]
  }
}</code></pre><p>},<br/>  "agents": {</p><pre><code>"defaults": {
  "model": {
    "primary": "ds/xopdeepseekv32"
  },
  "models": {
    "ds/xopdeepseekv32": {
      "alias": "xopdeepseekv32"
    }
  },
  "compaction": {
    "mode": "safeguard"
  },
  "maxConcurrent": 4,
  "subagents": {
    "maxConcurrent": 8
  }
}</code></pre><p>},<br/>  "messages": {</p><pre><code>"ackReactionScope": "group-mentions"</code></pre><p>},<br/>  "commands": {</p><pre><code>"native": "auto",
"nativeSkills": "auto"</code></pre><p>},<br/>  "channels": {<br/>  },<br/>  "gateway": {</p><pre><code>"mode": "local",
"tailscale": {
  "mode": "off"
}</code></pre><p>},<br/>  "plugins": {</p><pre><code>"entries": {
},
"installs": {
}</code></pre><p>}<br/>}</p><p>步骤3：验证配置是否成功</p><p>配置完成后，保存配置文件并重启OpenClaw（部分版本无需重启，直接生效）。在工具的聊天窗口中发送一条简单的测试消息（如“你好”），若能正常收到返回结果，即表示已成功调用讯飞星辰MaaS平台的模型服务，Token可正常使用。</p><p>四、常见问题及补充说明</p><ol><li>配置后无法正常使用？</li></ol><p>优先检查API Key是否填写正确（注意大小写、空格），若API Key无误，可重新登录讯飞星辰平台确认API授权是否有效，或刷新推理服务控制台后重新获取API Key再次配置。</p><ol start="2"><li>使用过程中速度过慢？</li></ol><p>如前文所述，实际使用中会存在轻微卡顿，属于正常现象，不影响日常使用；若卡顿严重，可检查网络连接，或重启OpenClaw及网络设备尝试优化。</p><ol start="3"><li>免费Token有使用期限或额度限制吗？</li></ol><p>该计划为讯飞星辰春节专属免费活动，具体使用期限及额度以平台官方通知为准，建议获取Token后及时配置使用，避免过期。</p><p>五、后续支持</p><p>若在配置过程中遇到其他问题，无法独立解决，可通过以下方式获取协助：点赞、关注本文，转发一次并在评论区留言“666”，即可获取手把手配置指导，全程协助完成所有操作，确保顺利使用免费Token畅享OpenClaw服务。</p><p>综上，讯飞星辰春节免费Token计划是OpenClaw用户的高性价比选择，零成本、易配置、可实用，无需额外付费即可解决Token消耗过快的问题，适合各类OpenClaw用户尝试使用。按照本文步骤操作，即可快速完成配置，开启流畅的大模型应用体验。</p><p>本公众号提供有偿搭建 openclaw 和 opencode 等服务，并提供免费AI 模型 token方案，让大家可以畅快使用，免费续杯。</p><p>有需要的加V mapleCx330</p><p>本文由<a href="https://link.segmentfault.com/?enc=I61LKVTVFJN%2FAvETBTZEvw%3D%3D.ObAL4k2Ihkd41k4%2Bb06K97ylRQcbEoddIWX%2FS0usmfY%3D" rel="nofollow" target="_blank">mdnice</a>多平台发布</p>]]></description></item><item>    <title><![CDATA[Prompt caching 技术是如何实现 1 折的推理成本优化的？ Baihai_IDP ]]></title>    <link>https://segmentfault.com/a/1190000047609587</link>    <guid>https://segmentfault.com/a/1190000047609587</guid>    <pubDate>2026-02-13 14:07:13</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <blockquote><p><strong>编者按：</strong> 你是否曾好奇过，那些声称能将长文本输入成本降低90%、延迟减少85%的"Prompt Caching"技术，背后究竟缓存了什么？是简单的文本复用，还是某种更深层的计算优化？</p><p>我们今天为大家带来的文章，作者的核心观点是：Prompt Caching的本质并非简单的文本字符串缓存，而是对Transformer注意力机制中Key-Value（KV）矩阵计算结果的复用，通过避免重复计算注意力权重来实现成本削减与性能提升。</p><p>文章的重点内容包括：第一，从Tokenizer到Embedding再到Transformer的完整技术拆解，帮助读者建立对LLM内部数据流的直觉认知；第二，对注意力机制（Attention）的数学原理进行深入浅出的阐释，详细展示了Query、Key、Value矩阵的计算过程以及Softmax权重分配机制；第三，揭示了"KV Caching"的核心实现逻辑 —— 通过缓存历史token的K、V投影矩阵，使模型在增量生成时只需计算最新token，而非重新处理整个上下文；第四，对OpenAI与Anthropic两种缓存策略的对比分析，指出自动路由与显式控制之间的权衡，以及Temperature等采样参数对缓存机制的零影响。</p></blockquote><p><strong>作者 | Sam Rose</strong></p><p><strong>编译 | 岳扬</strong></p><p>撰写本文时，OpenAI 和 Anthropic 的 API 中，缓存的 input token 单价仅为普通 input token 的十分之一。</p><p>Anthropic 甚至声称[1]，prompt caching 能将长 prompt 的延迟“最高降低 85%”。而在实际测试中，我发现对于足够长的 prompt，这一说法确实成立。我向 Anthropic 和 OpenAI 各发送了数百次请求，注意到在所有 input token 均被缓存的情况下，首 token 延迟（time-to-first-token latency）出现了明显下降。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609589" alt="" title=""/></p><p>缓存 token（cached token）到底是什么玩意儿？ </p><p>这背后究竟发生了什么，让服务商能给 input token 打出 1 折的超低折扣？他们在各次请求之间到底保存了什么？这可不是简单地把响应结果存下来，等收到相同 prompt 时再复用 —— 通过 API 就能很容易地验证这一点并未发生。<strong>随便写个 prompt，连续发送十几次，你会发现即使使用情况栏（usage 部分）显示 input token 已被缓存，每次得到的回复仍然各不相同。</strong></p><p>我对大模型厂商文档中的解释[2-3]并不满意 —— 它们虽能很好地说明如何使用 prompt caching，却巧妙地避开了“究竟缓存了什么”这个核心问题。于是我决定深入探究，一头扎进 LLM 工作原理的“兔子洞”，直到彻底搞明白服务商究竟缓存了哪些精确的数据、这些数据的用途，以及它们如何让每个人的 LLM 请求都变得更快速、更便宜。</p><p>读完本文，你将……</p><ul><li>在更深层次上理解 LLM 的工作原理</li><li>对“LLM 的运作方式”建立新的直觉认知</li><li>弄明白究竟哪些二进制数据被缓存了，以及它们如何降低你的 LLM 请求成本</li></ul><h2><strong>01 LLM 架构</strong></h2><p>本质上，LLM 就是一个巨大的数学函数：输入一串数字，并输出一个数字。在 LLM 内部，存在着一个由数十亿个精心设计的运算构成的巨型图结构，负责将这些输入数字转化为输出数字。</p><p>这个由海量数学运算构成的巨型图结构大致可分为 4 个部分。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609590" alt="" title="" loading="lazy"/></p><p><strong>图中的每个节点都可以看作一个函数，接收输入并产生输出。输入会以循环方式不断馈入 LLM，直到遇到某个特殊的输出值指示其停止。</strong> 用伪代码表示大致如下：</p><pre><code>prompt ="What is the meaning of life?";

tokens = tokenizer(prompt);
while(true){
 embeddings = embed(tokens);
for([attention, feedforward] of transformers){
 embeddings = attention(embeddings);
 embeddings = feedforward(embeddings);
}
 output_token = output(embeddings);
if(output_token === END_TOKEN){
break;
}
 tokens.push(output_token);
}

print(decode(tokens));</code></pre><p>尽管以上描述已大幅简化，但现代 LLM 的核心代码行数之少仍让我感到意外。  </p><p>Sebastian Raschka[4] 用 PyTorch 从零实现了多个开源模型，还产出了大量高质量的教学材料 —— 如果你喜欢本文，大概率也会喜欢他的内容。以当前领先的开源模型之一 Olmo 3 为例，其核心代码仅数百行[5]。</p><p>Prompt caching 发生在 Transformer 的“attention（注意力机制）”中。接下来我们将按顺序逐步拆解 LLM 的工作原理，直到抵达这一环节。这意味着，我们的旅程得从 tokens 说起。</p><h2><strong>02 Tokenizer（分词器）</strong></h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609591" alt="" title="" loading="lazy"/></p><p>在 LLM 处理你的 prompt（提示词）之前，必须先将其转换为它能理解的表示形式。这个过程分为两步，由 tokenizer 和 embedding 共同完成。为什么要这么做，要到讲 embedding 时才能完全明晰，现在请先耐心了解 tokenizer 的作用。</p><p>Tokenizer 会将你的 prompt 拆成多个小片段，并为每个唯一的片段分配一个整数 ID，称为"token"。例如，GPT-5 对 prompt "Check out ngrok.ai" 的分词结果如下：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609592" alt="" title="" loading="lazy"/></p><p>该 prompt 已被拆分为数组 [“Check”, " out", " ng", “rok”, “.ai”]，并转换为 tokens [4383, 842, 1657, 17690, 75584]。相同的 prompt 始终生成相同的 tokens。tokens 也是区分大小写的 —— 因为大小写能传递语义信息。例如，首字母大写的 "Will" 更可能是人名，而小写的 "will" 则更可能是助动词。</p><p>为什么不直接按空格或字符分割？</p><p>这其实是个相当深刻的问题，细讲起来足以让本文篇幅翻倍。简短而不尽兴的答案是：这是一种权衡。若想深入理解，Andrej Karpathy 有一期从零实现 tokenizer 的精彩视频（<a href="https://link.segmentfault.com/?enc=KM%2FJYcshRUNZOdRqnP%2FD2w%3D%3D.GNMb1EZBQNh1TizSj3tudh5u8rSekPrLOBmJbcNqDWMOe%2F4t8%2BI3Ue684DGWro%2BY" rel="nofollow" target="_blank">https://www.youtube.com/watch?v=zduSFxRajkE</a>） 。<strong>对于 prompt caching 而言，只需知道：tokenization 的作用就是把文本变成数字。</strong></p><p>Tokens 是 LLM 输入与输出的基本单位。当你向 ChatGPT 提问时，回复会随着每次 LLM 迭代完成而逐个 token 流式返回。服务商这么做，是因为生成完整回复可能需要数十秒，而一旦 token 生成就立即返回，能让交互体验更流畅自然。</p><p>我们来问一个 LLM 领域的经典问题，亲眼看看这个过程：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609593" alt="" title="" loading="lazy"/></p><p>Prompt tokens 输入，✨ AI 魔法发生 ✨，输出一个 token，循环往复。这个过程称为“inference（推理）”。注意：每个输出 token 都会在下一轮迭代前被追加到 input prompt 中。LLM 需要全部上下文才能给出高质量回答 —— 如果只输入原始 prompt，它会反复尝试生成答案的第一个 token。如果只输入已生成的回答部分，它会立刻忘记问题本身。因此，每一轮迭代都必须将完整的 prompt 加上已生成的回答内容重新输入 LLM。</p><p><strong>那个 199999 &lt;END&gt; token 是什么？</strong></p><p>这个推理过程总得有个终点。<strong>LLM 拥有多种“特殊”token，其中之一就是标志着响应结束的 token。</strong> 在 GPT-5 的分词器中，这就是 token 199999。这只是 LLM 终止生成过程的多种方式之一：<strong>你也可以通过 API 指定最大生成 token 数，服务商还可能基于安全策略设定其他终止规则。</strong></p><p>此外还有用于标记对话消息起止的特殊 token —— 正是这些 token 让 ChatGPT、Claude 等聊天模型能分辨一条消息何时结束、下一条何时开始。</p><p>关于 tokenizer（分词器）的最后一点：它们种类繁多！ChatGPT 使用的 tokenizer 与 Claude 不同，甚至 OpenAI 自家的不同模型也使用不同的 tokenizer。每种 tokenizer 都有自己独特的文本切分规则。如果你想直观比较不同 tokenizer 的分词效果，可以试试 tiktokenizer[6]。</p><p>认识了 tokens 之后，接下来我们聊聊 embeddings。</p><h2><strong>03 Embedding</strong></h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609594" alt="" title="" loading="lazy"/></p><p>经过 tokenizer 处理后的 tokens，现在进入 embedding 阶段。要理解 embedding，不妨先思考模型的目标是什么。</p><p>人类用代码解决问题时，会编写接收输入、产生输出的函数，比如华氏转摄氏：</p><pre><code>function fahrenheitToCelsius(fahrenheit){
return((fahrenheit -32)*5)/9;
}</code></pre><p>我们可以把任意数字传入 fahrenheitToCelsius，并能获得正确结果。但假如我们面对一个问题，却不知道背后的公式呢？假如我们只有下面这张神秘的输入-输出对照表：  </p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609595" alt="" title="" loading="lazy"/></p><p>（我并不指望你能认出这个函数 —— 不过，如果你把截图贴进 ChatGPT，它能立刻识别出来。）</p><p>当我们知道每个输入对应的正确输出，却不知道产生这种对应关系的函数时，就可以“训练”一个模型来学习这个函数。做法是：给模型提供一块“画布” —— 那个由海量数学运算构成的巨型图结构，然后不断调整这个图结构，直到模型收敛到正确的函数。每次更新图结构后，我们都将输入数据喂进去，观察输出数据与目标的差距。反复迭代，直到结果足够接近目标。这就是训练的本质。</p><p>事实证明，在训练文本生成模型时，能够识别两个句子是否“相似”会很有帮助。但“相似”具体指什么？它们可能同样悲伤、幽默或发人深省；也可能在长度、节奏、语气、语言、词汇或结构上相近。描述句子相似性的方式有无数维度，而两个句子可能在某些维度上相似，在另一些维度上则不然。</p><p><strong>Tokens 本身只是简单的整数编号，没有任何“维度”信息；而 embeddings 则是高维向量，承载了丰富的语义和结构信息。</strong></p><p>Embedding 是一个长度为 n 的数组，代表 n 维空间中的一个位置。如果 n=3，embedding 可能是 [10, 4, 2]，表示三维空间中 x=10、y=4、z=2 的坐标点。在 LLM 训练过程中，每个 token 会被随机分配一个起始位置，随后训练过程会不断微调所有 token 的位置，直到找到能产生最佳输出的排列方式。</p><p>Embedding 阶段的第一步，就是查表获取每个 token 对应的 embedding。用伪代码表示大概是这样：</p><pre><code>// Created during training, never changes during inference.
const EMBEDDINGS = [...];
 
function embed(tokens) {
 return tokens.map(token =&gt; {
 return EMBEDDINGS[token];
 });
}</code></pre><p>于是，我们把 tokens（整数数组）转换成了 embeddings（数组的数组，即“矩阵”）。  </p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609596" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609597" alt="" title="" loading="lazy"/></p><p>tokens [75, 305, 284, 887] 被转换为一个由 3 维 embeddings 构成的矩阵。</p><p><strong>Embedding 的维度越多，模型可用于比较句子的“角度”就越多。</strong> 我们刚才一直在用 3 维 embeddings 举例，但当前主流模型的 embedding 维度通常是几千维，最大的甚至超过 10,000 维。</p><p>为了说明更高维度的价值，下面我展示了 8 组彩色形状，它们最初位于一维空间中 —— 挤在一条直线上，杂乱无章，难以理解。但随着维度增加，你就能清楚地看到存在 8 个不同的、相关的组别。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609598" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609599" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609600" alt="" title="" loading="lazy"/></p><p>三维是我这里能提供的视觉示例的极限，至于几千维的空间能表达什么，就得靠你发挥想象力了。</p><p>Embedding 阶段还有最后一件事要做。<strong>在获取 token 的 embedding 后，会将该 token 在 prompt 中的位置信息编码进 embedding 中。</strong> 我没有深入研究这一机制的具体实现方式，只知道它对 prompt caching 的工作方式影响不大，但如果没有这一步，LLM 就无法判断 prompt 中 tokens 的先后顺序。</p><p>更新一下前面的伪代码，假设存在一个叫 encodePosition 的函数，它接收 embeddings 和位置信息，并返回嵌入了位置编码的新 embeddings。</p><pre><code>const EMBEDDINGS =[...];
 
// Input: array of tokens (integers)
function embed(tokens){
// Output: array of n-dimensional embedding arrays
return tokens.map((token, i)=&gt;{
 const embeddings = EMBEDDINGS[token];
return encodePosition(embeddings, i);
});
}</code></pre><p>总而言之，embeddings 是 n 维空间中的点，你可以将其视为它们所代表文本的语义含义。<strong>在训练过程中，每个 token 都会在该空间中移动，靠近其他语义相似的 token。维度越多，LLM 对每个 token 的表示就越复杂、越细腻。</strong>  </p><p>至此，tokenizer 和 embedding 阶段所做的全部工作，都是为了把原始文本转换成 LLM 能处理的形式。接下来，我们来看看这些数据进入 transformer 阶段后会发生什么。</p><h2><strong>04 Transformer</strong></h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609601" alt="" title="" loading="lazy"/></p><p>Transformer 阶段的核心任务，就是接收 embeddings 作为输入，并在 n 维空间中对它们进行调整。它通过两种方式实现这一点，而我们只关注第一种：attention（注意力机制）。我们暂不讨论 “Feedforward” 层或输出阶段（至少在这篇文章中👀）。</p><p><strong>Attention 机制的作用，是帮助 LLM 理解 prompt 中各个 token 之间的关系 —— 具体做法是让每个 token 能够影响其他 token 在 n 维空间中的位置。</strong> 它通过加权组合 prompt 中所有 token 的 embeddings 来实现这一点。输入是整个 prompt 的 embeddings，输出则是一个新的 embedding，它是所有输入 embeddings 的加权组合。</p><p>举个例子，如果 prompt 是 “Mary had a little”，被分词为四个 token：Mary、had、a、little，那么 attention 机制可能会决定，在生成下一个 token 时，模型会认为：</p><ul><li>“Mary” 最重要（63%）（译者注：因为整个句子的主语是 Mary，后续内容很可能围绕她展开）</li><li>“had” 和 “a” 次之（16% 和 12%）（译者注：它们是语法结构的一部分，但语义信息较弱）</li><li>“little” 也有一定作用（9%）（译者注：它修饰后面的名词）</li></ul><p>然后，它会把所有 token 的 embeddings 分别乘以对应的权重，然后把结果加在一起，得到一个融合后的向量。这正是 LLM 判断“在当前上下文中，每个 token 应该被关注多少”的方式。</p><p>这是目前为止整个流程中最复杂、最抽象的部分。我会先用伪代码展示它，然后再看看 embeddings 在经过这一过程时是如何被变换的。我本想让这一部分的数学内容少一些，但这里很难避免一些数学运算。别担心，你能行的，我相信你。</p><p>Attention 中的大部分计算都是矩阵乘法。对于本文而言，你只需知道：输出矩阵的形状由两个输入矩阵的形状决定，输出的行数等于第一个输入矩阵的行数，列数等于第二个输入矩阵的列数。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609602" alt="" title="" loading="lazy"/></p><p>理解了这一点，我们来看一个简化版的注意力机制如何计算分配给每个 token 的权重。在以下代码中，我用 * 表示矩阵乘法。</p><pre><code>// Similar to EMBEDDINGS from the pseudocode
// earlier, WQ and WK are learned during 
// training and do not change during inference.
//
// These are both n*n matrices, where n is the
// number of embedding dimensions. In our example
// above, n =3.
const WQ =[[...],[...],[...]];
const WK =[[...],[...],[...]];

// The input embeddings look like this:
//[
//[-0.1,0.1,-0.3],// Mary
//[1.0,-0.5,-0.6],// had
//[0.0,0.8,0.6],// a
//[0.5,-0.7,1.0]// little
//]
function attentionWeights(embeddings){
 const Q = embeddings * WQ;
 const K = embeddings * WK;
 const scores = Q * transpose(K);
 const masked = mask(scores);
return softmax(masked);
}</code></pre><p>接下来，让我们看看 embedding 在流经这个函数时是如何变化的。  </p><p>等等，WQ 和 WK 变量到底是什么？</p><p>还记得我之前说过，每个 token 的 embedding 最初都被随机分配了一个位置，然后在训练过程中不断微调，直到模型找到一个良好的排列状态吗？</p><p>WQ 和 WK 也是类似的。它们是 n×n 的矩阵（n 即 embedding 维度），在训练开始时被赋予随机值，随后也在训练中被不断调整，以帮助模型收敛到一个更优的解。</p><p>任何在训练过程中被调整的数，都被称为“模型参数”。embedding 向量中的每个浮点数，以及 WQ、WK 矩阵中的每个数值，都是一个参数。当你听说某个模型有“1750 亿参数”时，指的就是这些数字。</p><p><strong>至于 WQ 和 WK 到底代表什么，我们其实并不完全清楚。随着模型训练收敛，它们最终会变成某种对 embedding 的变换方式，有助于模型生成更好的输出。</strong> 它们内部可能在做任何事情 —— 而如何解释这些矩阵的含义，目前仍是一个开放且活跃的研究方向。</p><p>要得到 Q 和 K，我们分别将 embeddings 与 WQ 和 WK 相乘。WQ 和 WK 的行数和列数始终等于 embedding 的维度（本例中为 3）。这里我为 WQ 和 WK 选取了随机值，并将结果四舍五入到小数点后两位以便阅读。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609603" alt="" title="" loading="lazy"/></p><p>得到的 Q 矩阵有 4 行 3 列。4 行是因为 embeddings 矩阵有 4 行（每个 token 一行），3 列是因为 WQ 有 3 列（每个 embedding 维度一列）。</p><p>K 的计算完全相同，只是将 WQ 换成 WK。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609604" alt="" title="" loading="lazy"/></p><p>Q 和 K 都是输入 embedding 到新的 n 维空间的"投影"。它们不是原始的 embedding，但由原始 embeddings 推导而来。</p><p>然后，我们将 Q 和 K 相乘。我们对 K 进行“转置”，也就是沿对角线翻转，使得得到的矩阵是一个方阵，其行数和列数都等于输入提示词中的 token 数量。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609605" alt="" title="" loading="lazy"/></p><p><strong>这些 scores 表示每个 token 对下一个生成 token 的重要程度。</strong> 左上角的数值 -0.08，代表 “Mary” 对 “had” 的重要性。再往下一行的 -0.10，则代表 “Mary” 对 “a” 的重要性。在展示完矩阵运算后，我会用图示更直观地说明这一点。接下来的所有操作，都是为了将这些 scores 转换为可用于混合 embeddings 的权重。</p><p>这个 score 矩阵的第一个问题是：它允许未来的 token 影响过去的 token。在第一行，我们唯一知道的词是"Mary"，所以它应该是唯一对生成"had"有贡献的词。第二行也是如此，我们知道"Mary"和"had"，所以只有这两个词应该对生成"a"有贡献，依此类推。</p><p>为了解决这个问题，我们对矩阵应用一个三角形掩码（triangular mask），将未来 token 对应的位置置零。不过，我们并不是真的设为 0，而是设为负无穷（negative infinity） —— 原因稍后解释。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609606" alt="" title="" loading="lazy"/></p><p>第二个问题是，这些 scores 是任意的数值。如果它们能变成一个每行之和等于 1 的概率分布，对我们来说会更有用。这正是 softmax 函数的作用。softmax 具体如何运作的细节并不重要 —— 它比简单的“将每个数字除以该行总和”稍复杂一点，但结果是一样的：每行之和为 1，且每个数字都在 0 和 1 之间。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609607" alt="" title="" loading="lazy"/></p><p>为了解释为什么用负无穷，下面是一个 softmax 的代码实现：</p><pre><code>function softmax(matrix){
return matrix.map(row =&gt;{
 const exps = row.map(x =&gt; Math.exp(x));
 const sumExps = exps.reduce((a, b)=&gt; a + b,0);
return exps.map(exp =&gt; exp / sumExps);
});
}</code></pre><p>它并不是简单地把每个数加起来再除以总和，而是先对每个数值取 Math.exp，也就是计算 e^x。如果我们用 0 代替负无穷，Math.exp(0) === 1，这些被屏蔽的位置仍然会产生非零权重。而 Math.exp(-Infinity) 是 0，这正是我们想要的。  </p><p>下面的图片展示了提示词"Mary had a little"的 attention 权重示例。</p><p>这些权重与上面的计算结果不匹配，因为我是从 Transformer Explained 网站[7]上运行的 GPT-2 模型中提取的。所以这些是一个真实模型（尽管是老模型）的真实权重。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609608" alt="" title="" loading="lazy"/></p><p>第一行只有"Mary"，因此Mary对"had"的生成的贡献是100%。然后在第二行，"Mary"贡献了79%，而"had"贡献了21%用于生成"a"，以此类推。LLM 认为这个句子中最重要的词是 “Mary”，这一点并不意外——从每一行中 “Mary” 都拥有最高权重就能看出。如果我让你补全"Jessica had a little"这个句子，你不太可能选择"lamb"。</p><p>接下来就只剩下对 token embeddings 进行加权混合了，谢天谢地，这一步比计算权重要简单得多。</p><pre><code>// Learned during training, doesn't change 
// during inference. This is also an n*n matrix,
// where n is the number of embedding dimensions.
const WV =[[...],[...],...];
 
function attention(embeddings){
 const V = embeddings * WV;
// This is the `attentionWeights` function from
// the section above. We're wrapping it in
// this `attention` function.
 const weights = attentionWeights(embeddings);
return weights * V;
}</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609609" alt="" title="" loading="lazy"/></p><p>为什么不直接混合原始 embeddings？  </p><p>当我们通过 Q 和 K 相乘得到 attention 权重时，我们完全是在衡量 token 之间的相关性。Embeddings 编码了 token 的各种语义信息 —— 某一维可能表示“颜色”，另一维表示“大小”，再一维表示“礼貌/粗鲁程度”，等等。而权重是通过相似度来判断哪些 token 更相关。</p><p>WV 的作用，则是让模型决定在混合时保留哪些维度的信息。</p><p>以句子 “Mary had a little” 为例，这里关于 “Mary” 最重要的信息是“人名”。模型在训练中可能也学到了很多关于 “Bloody Mary（血腥玛丽鸡尾酒）” 或 “Mary Queen of Scots（苏格兰女王玛丽）” 的知识，但这些与这首童谣无关，如果带入后续计算反而会引入噪声。因此，WV 允许模型在混合 embeddings 之前，先过滤掉不相关的特征。</p><p>接着，我们将生成的权重与 V 相乘，输出一组新的 embeddings：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609610" alt="" title="" loading="lazy"/></p><p><strong>Attention 机制的最终输出，就是这个输出矩阵的最后一行。</strong> 通过 attention 过程，前面所有 token 的上下文信息都被融合进了这一行。但要注意：为了得到最后一行，前面所有行都必须被计算出来。</p><p>总而言之，输入是一组 embeddings，输出是一个新的 embedding。Attention 机制通过大量精细的数学运算，按照训练中学到的 WQ、WK 和 WV 矩阵所决定的重要性比例，将各个 token 的信息进行了加权融合。正是这一机制，让 LLM 能够理解在其上下文窗口中“什么内容重要，以及为什么重要”。</p><p>现在，我们终于掌握了讨论 caching 所需的一切知识。</p><p>当然，Attention 还有更多技术细节</p><p>我在本文展示的是一个简化版的 attention，目的是突出与 prompt caching 最相关的核心部分。实际中的 attention 机制更为复杂。如果你希望深入了解更多技术细节，我推荐 3blue1brown 关于 attention 的视频[8]。</p><h2><strong>05 Prompt caching</strong></h2><p>我们再来看一遍上面的网格，但这次会展示在推理循环中每生成一个新 token 时，它是如何逐步填充的。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609611" alt="" title="" loading="lazy"/></p><p>每次生成新 token 时，都会将其追加到输入中，并重新完整处理整个 prompt。但仔细观察：之前计算出的权重从未改变。第二行始终是 0.79 和 0.21，第三行始终是 0.81、0.13、0.06。我们其实在不断重复大量不必要的计算。如果你刚刚才处理完 “Mary had a”，那么在生成下一个 token 时，对 “Mary had a little” 中前三个 token 的大部分矩阵运算其实是冗余的 —— 而这正是 LLM 推理循环的默认行为。</p><p>通过以下两个改动，就能避免这些重复计算：</p><ul><li><strong>在每次迭代中缓存 K 和 V 矩阵。</strong></li><li><strong>只将最新 token 的 embeddings 输入模型，而不是整个 prompt。</strong></li></ul><p>现在我们再次走一遍矩阵运算过程，但这一次：前 4 个 token 的 K 和 V 矩阵已被缓存，我们只传入一个新 token 的 embeddings。</p><p>是的，又要面对矩阵运算了，抱歉！不过内容和之前基本一致，我们会快速过一遍。</p><p>计算新的 Q 时，输出只有一行。WQ 和之前一样，没有变化。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609612" alt="" title="" loading="lazy"/></p><p>接着，计算新的 K 也同样只输出一行，而 WK 也和之前一样保持不变。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609613" alt="" title="" loading="lazy"/></p><p>但随后我们将这一新行追加到前一次迭代缓存的 4 行 K 矩阵之后：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609614" alt="" title="" loading="lazy"/></p><p>于是现在我们拥有了提示词中所有 token 的 K 矩阵，但我们只需要计算它的最后一行。</p><p>我们继续以这种方式来获取新的 score：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609615" alt="" title="" loading="lazy"/></p><p>以及新的的 weights：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609616" alt="" title="" loading="lazy"/></p><p>全程我们只计算必需的部分，完全不需要对旧值进行任何重新计算。获取 V 的新一行时也是同样的做法：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609617" alt="" title="" loading="lazy"/></p><p>然后将其追加到我们缓存的 V 中：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609618" alt="" title="" loading="lazy"/></p><p>最后，我们将新的权重与新的 V 相乘，得到最终的新 embeddings：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609619" alt="" title="" loading="lazy"/></p><p>我们只需要这单独一行新的 embedding。得益于缓存的 K 和 V，先前所有 token 的上下文信息都已被融入其中。</p><p><strong>被缓存的数据是 embeddings <em> WK 和 embeddings </em> WV 的结果，也就是 K 和 V。</strong> 因此，提示词缓存通常被称为"KV caching"。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609620" alt="" title="" loading="lazy"/></p><p>就是这样，上面那些 K 和 V 矩阵，就是服务提供商保存在他们巨大数据中心里的 1 和 0，用来给我们提供一折的 token 成本和更快的响应。</p><p>服务提供商在请求发出后，会将每个提示词的这些矩阵保留 5-10 分钟，如果你发送一个以相同提示词开头的新请求，他们就会复用缓存的 K 和 V，而不是重新计算它们。<strong>缓存匹配不需要完全一致 —— 即使新 prompt 只和缓存中的某一部分开头相同，也可以复用那部分已缓存的计算结果，而不必整个 prompt 完全匹配。</strong></p><p>OpenAI 和 Anthropic 的缓存机制截然不同。<strong>OpenAI 完全自动处理，会尽可能尝试将请求路由到缓存条目。</strong> 在我的实验中，通过发送请求然后立即重发，缓存命中率约为 50%。考虑到长上下文窗口的首字节延迟（time-to-first-byte）可能很长，这种自动缓存可能导致性能表现不稳定。</p><p><strong>Anthropic 则赋予你更多控制权，让你决定何时缓存以及缓存多久。</strong> 你需要为这项特权付费，但在我进行的实验中，当我们要求 Anthropic 缓存某个提示词时，他们会 100% 地将请求路由到缓存条目。因此，如果你的应用涉及长上下文窗口，并且需要可预测的延迟，Anthropic 可能是更合适的选择。</p><p>等等，那 temperature 这些参数会影响提示词缓存吗？</p><p>LLM 提供商提供了多种参数来控制模型输出的随机性，常见的有 temperature、top_p 和 top_k。这些参数都作用于推理循环的最后一步，即模型根据它为词表中每个 token 分配的概率来选取 token。这发生在 attention 机制产生最终 embedding 之后，因此提示词缓存不受这些参数影响。你可以随意调整它们，而不用担心导致缓存的提示词失效。</p><h2><strong>致谢</strong></h2><p>为了学习撰写本文所需的全部知识，我如饥似渴地阅读了大量优质内容，以下是我认为对我最有帮助的：</p><ul><li>Build a Large Language Model (From Scratch)[9] by Sebastian Raschka[10].</li><li>Neural Networks: Zero to Hero[11] by Andrej Karpathy[12].</li><li>Neural Networks video course[13] by 3blue1brown[14].</li><li>Transformer Explainer[15] by Aeree Cho[16] et al.</li></ul><p>如果你喜欢这篇文章，你一定会喜欢这些资源。</p><p><strong>END</strong></p><p><strong>本期互动内容 🍻</strong></p><p><strong>❓按照文中逻辑，缓存本质是拿内存换计算。当你处理10万Token以上的超长上下文时，有没有估算过KV Cache的内存占用成本 vs 重新计算的API成本？在什么临界点你会选择放弃缓存？</strong></p><p><strong>文中链接</strong></p><p>[1]<a href="https://link.segmentfault.com/?enc=fvaBUJarK2UnSEr9IFrh6Q%3D%3D.ATvM0W5lTysFtJL2W4r8tAAV5yAXEkAGrLcx5r3EDTPLNW0P4sKySRU9wXDlYdcg" rel="nofollow" target="_blank">https://claude.com/blog/prompt-caching</a></p><p>[2]<a href="https://link.segmentfault.com/?enc=h04XyC8Te%2FJ5gaIrJ%2BE5zQ%3D%3D.15UOqKajPMrlqGm%2B1urDwhUlE9EHo1ResJDOv%2FPuk2ZpMBAt5MPNjAhIw7fZEQB%2BUxzvW93GelUBWzC1wt94FFrI5XefhdNWcZxOx6R5FXM%3D" rel="nofollow" target="_blank">https://docs.claude.com/en/docs/build-with-claude/prompt-caching</a></p><p>[3]<a href="https://link.segmentfault.com/?enc=efGC3MRdX7zdVpuH2Ihosg%3D%3D.BIe%2FBBp5X8MHHQa8JrvXLYLsT%2B1kPTqvjYZkeBeXBVSUsa%2B6jT15TJNMTz5x0yNfG1AyyOzmqZJkb5mub3MGZQ%3D%3D" rel="nofollow" target="_blank">https://platform.openai.com/docs/guides/prompt-caching</a></p><p>[4]<a href="https://link.segmentfault.com/?enc=z9rXaGaF9D3vc3MCPIyqww%3D%3D.6SIRscUNvQpAfy9059eoG%2Bo4HD%2F91siM%2FNGKY5jFmFd1X1%2B8uLMyBbYWQ14gNjZS" rel="nofollow" target="_blank">https://magazine.sebastianraschka.com/</a></p><p>[5]<a href="https://link.segmentfault.com/?enc=nyOOCJNKQ2dvs1RGM2yZIg%3D%3D.cxc7mhEh7Q%2BJoaSOSTBDYcqC%2B34qq2TDjXJYrfixHqs%2B7uzTTpXx0ZcTve3n%2BgFC8v%2FAj9hnaeAG3jwKCVN6KZ20S89uuF9lVsCrpP%2FFPdpE6g7w82PS4Q31FhZnfZz1" rel="nofollow" target="_blank">https://github.com/rasbt/LLMs-from-scratch/blob/main/ch05/13_olmo3/standalone-olmo3.ipynb</a></p><p>[6]<a href="https://link.segmentfault.com/?enc=o5KzEGoIH0dzB6aptmY5wQ%3D%3D.tP88zR%2FOGaP1U8nSsMh5ITpiHVH6RvWOJefxkZ2HZWcrWZbS4CTk6drZd75RSoIL" rel="nofollow" target="_blank">https://tiktokenizer.vercel.app/</a></p><p>[7]<a href="https://link.segmentfault.com/?enc=1NkkN4DkAkXx8njswC%2BAFg%3D%3D.hLP5XIJ%2F%2FNANEDxGsih3EI7DL%2Fp169g1xDFee%2BeW26JPVlMPJ0TjmXug4LK%2FAcOVqWGaq%2BbGl0Vh2Sh8ZstUCg%3D%3D" rel="nofollow" target="_blank">https://poloclub.github.io/transformer-explainer/</a></p><p>[8]<a href="https://link.segmentfault.com/?enc=1oIaozjqaHtDvtQGB%2Fd3wA%3D%3D.025ocRtxVcdH%2F1TDN5U%2BoAZOrMdiIAkmkZtdu9R%2F2bbPG9FgCnAV0sXDWXoNJDTF" rel="nofollow" target="_blank">https://www.youtube.com/watch?v=eMlx5fFNoYc</a></p><p>[9]<a href="https://link.segmentfault.com/?enc=Mdgejk8s5tR0o27HqiNj9w%3D%3D.WvicHQYE0bcoed7XWJmnbmjfGhSIIQ8K%2FAm93FX8SrAoJwOpzyqF0pLF8hW32%2B60tzrUM42ZKif3gW9HcSplcklYQSP9lQ4pXQQyqPpdhcc%3D" rel="nofollow" target="_blank">https://www.oreilly.com/library/view/build-a-large/9781633437...</a></p><p>[10]<a href="https://link.segmentfault.com/?enc=J%2FrCitbVoUSZd50HQniuog%3D%3D.7OT1ZeHID0n1wkMUvqZwTW65h4GwoPSjW5zD2pNOEu4%3D" rel="nofollow" target="_blank">https://sebastianraschka.com/</a></p><p>[11]<a href="https://link.segmentfault.com/?enc=5l3DLmIzTJ4XdfyYvnxFoA%3D%3D.l%2B9u9G3zUCeiI0jUHzA6YJNXIUdBz%2BhLxjbcojCYX2dlrITa0eIPVRB52dGeW8Q6Hvf2oHBq0iXTeiqrHTc%2FUiDzPE2u%2BUZ%2B1B9Wu2hxcfuXGM4tdXJJE6eXQzYNse2c" rel="nofollow" target="_blank">https://www.youtube.com/watch?v=VMj-3S1tku0&amp;list=PLAqhIrjkxbu...</a></p><p>[12]<a href="https://link.segmentfault.com/?enc=R1Rf8HpG72I6XD2%2B4uLRQA%3D%3D.n7p4C887o6oRY0bDEzBK63d%2FisKbzeef4pRWshj3nDo%3D" rel="nofollow" target="_blank">https://karpathy.ai/</a></p><p>[13]<a href="https://link.segmentfault.com/?enc=dcd1WWcW394LILaM303lZw%3D%3D.cC693gY%2BlNqSzgangWG9vjfus0%2F3%2Bvh9dmV2lG4qJMcrM7HPkIQ25xktRqfd5dtRUkAGknMxkSX1TCLPj9FmSHoPJAIfOpuFOAsQsaIoWwk%3D" rel="nofollow" target="_blank">https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000...</a></p><p>[14]<a href="https://link.segmentfault.com/?enc=52wcwUNKpXx2TtZASrLAaQ%3D%3D.6c1jDvIO1m6PEyhOvBVsJ%2F9oCmDMXNRC2bks9nAPnM84eD3m0pSvGe4Fpg%2F9kR%2FN" rel="nofollow" target="_blank">https://www.youtube.com/@3blue1brown</a></p><p>[15]<a href="https://link.segmentfault.com/?enc=ctdErqgGBMGCVUgEmeJ8hQ%3D%3D.CHcM35tD5ZOcIXx6jMoHR%2BHPzojPlPAeTXdd6cJdIbNb6ZPpvmR9nGw2D%2BQVYkWCerwcIkG24kmd6kYoMsQ70Q%3D%3D" rel="nofollow" target="_blank">https://poloclub.github.io/transformer-explainer/</a></p><p>[16]<a href="https://link.segmentfault.com/?enc=C5pNIbZXcM2ibTUeLPPyIQ%3D%3D.XW4b8zaDEPq8LUMTzH0%2B8gxV%2B6ndf2TQsM16DCDLdYk%3D" rel="nofollow" target="_blank">https://aereeeee.github.io/</a></p><p><strong>本文经原作者授权，由</strong> <strong>Baihai IDP</strong> <strong>编译。如需转载译文，请联系获取授权。</strong></p><p><strong>原文链接：</strong>  </p><p><a href="https://link.segmentfault.com/?enc=s6tsfHxLVc2PGfdOOZkZ6w%3D%3D.6sGy7d%2FWTIeZxq2sxhr%2FTbEtwe%2BPiwH60FQKWopxQsrSKUlghNDqzMXNqgnhX9LY" rel="nofollow" target="_blank">https://ngrok.com/blog/prompt-caching/</a></p>]]></description></item><item>    <title><![CDATA[博睿大使｜推荐Bonree ONE 有礼活动正式启幕！ 博睿数据 ]]></title>    <link>https://segmentfault.com/a/1190000047609671</link>    <guid>https://segmentfault.com/a/1190000047609671</guid>    <pubDate>2026-02-13 14:06:37</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>博睿大使｜推荐Bonree ONE 有礼活动正式启幕！原创 一体化智能可观测 博睿宏远 2026年2月12日 16:00 北京<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047609673" alt="图片" title="图片"/><br/>博睿大使【推荐Bonree ONE有礼】活动正式启幕！即日起至2026年12月31日诚邀各位伙伴成为 Bonree ONE 的引荐者向博睿数据推荐新客户、新商机，解锁丰厚奖励！即刻点击下方海报或扫描海报二维码参与活动吧！具体活动规则详见下方海报👇<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047609674" alt="图片" title="图片" loading="lazy"/><br/>— 精彩资料推荐 —<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047609675" alt="图片" title="图片" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609676" alt="图片" title="图片" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609677" alt="图片" title="图片" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609678" alt="图片" title="图片" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609679" alt="图片" title="图片" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609680" alt="图片" title="图片" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609681" alt="图片" title="图片" loading="lazy"/><br/>往期推荐_● 博睿数据持续领跑中国APMO市场！► 点击阅读_● 扬帆奋楫 再攀高峰！博睿数据2025年度精彩回顾！► 点击阅读_● 新起点·新视觉｜博睿数据全球品牌VI系统全新升级！► 点击阅读_● 《智能体协同矩阵重塑自主运维新范式》白皮书重磅发布！► 点击阅读</p>]]></description></item><item>    <title><![CDATA[Python网络编程实战：利用WebSocket实现金融级实时数据推送 EmilyLi ]]></title>    <link>https://segmentfault.com/a/1190000047609719</link>    <guid>https://segmentfault.com/a/1190000047609719</guid>    <pubDate>2026-02-13 14:06:05</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><strong>引言</strong><br/>在Web开发中，我们习惯了RESTful API。但在金融量化（FinTech）领域，RESTful往往是性能瓶颈的代名词。<br/>本文将从后端工程的角度，详细拆解如何使用Python的websocket-client库，对接第三方行情服务商（以AllTick为例），实现一个高可用、低延迟的港股行情接入模块。</p><p><strong>技术栈选择</strong></p><p>Language: Python 3.9+</p><p>Protocol: WebSocket (RFC 6455)</p><p>Library: websocket-client (同步阻塞模式，适合独立进程)</p><p><strong>模块实现细节</strong></p><ol><li>连接管理类（Connection Manager）<br/>为了保持代码的整洁，建议将WebSocket操作封装在一个类中。我们需要处理Socket生命周期的四个关键事件：Open, Message, Error, Close。<br/>在on_open回调中，我们执行订阅操作。这是一种典型的异步编程思想——连接建立是事件，订阅是响应。</li></ol><pre><code>import websocket
import json

def on_message(ws, message):
    data = json.loads(message)
    print(data)  # 输出实时行情数据

def on_open(ws):
    # 订阅港股代码为HK.0005（汇丰控股）的实时数据
    ws.send(json.dumps({
        "event": "subscribe",
        "symbol": "HK.0005",  # 港股代码
        "channel": "market_data"
    }))

if __name__ == "__main__":
    websocket.enableTrace(True)
    ws = websocket.WebSocketApp("wss://api.alltick.co/market_data",  # 使用AllTick的WebSocket URL
                                on_message=on_message,
                                on_open=on_open)
    ws.run_forever()</code></pre><ol start="2"><li>消息反序列化与路由（Deserialization &amp; Routing）<br/>服务端推送的数据是Byte流或String。我们需要做两件事：</li></ol><p>JSON反序列化：将字符串转为Dict。</p><p>业务路由：根据symbol字段，将数据分发给不同的策略回调函数。<br/>注意：这里的异常处理至关重要，格式错误的包不应导致进程崩溃。</p><pre><code>response = '{"symbol": "HK.0005", "price": 123.45, "volume": 10000}'
data = json.loads(response)

price = data['price']
volume = data['volume']

print(f"汇丰控股当前价格: {price}, 成交量: {volume}")</code></pre><ol start="3"><li>订阅协议的构造<br/>根据API文档，订阅请求通常是一个包含Event Type和Channel的JSON对象。这里演示了如何构造一个标准的订阅Payload。</li><li>弹性设计（Resilience Engineering）<br/>在分布式系统中，"Design for Failure"是核心准则。我们利用while True循环配合try...except块，实现了一个简易但有效的守护进程（Daemon）。如果Socket意外断开，程序会休眠数秒后尝试重连，实现无人值守运行。</li></ol><pre><code>import time

def fetch_data_with_retry():
    retries = 3
    for _ in range(retries):
        try:
            data = fetch_data_from_api()
            return data
        except Exception as e:
            print(f"请求失败: {e}, 正在重试...")
            time.sleep(2)  # 等待2秒后重试
    print("重试次数已用完，无法获取数据")</code></pre><p><strong>总结</strong><br/>通过WebSocket，我们成功将网络开销分摊到了连接建立的一次性成本上，后续的数据传输几乎没有额外Header开销。这对于高频数据处理是非常必要的优化。<br/><img width="723" height="408" referrerpolicy="no-referrer" src="/img/bVdnVCQ" alt="" title=""/></p>]]></description></item><item>    <title><![CDATA[HarmonyOS 6.0 图书馆管理系统（ArkTS）开发实战 逐梦AI ]]></title>    <link>https://segmentfault.com/a/1190000047609721</link>    <guid>https://segmentfault.com/a/1190000047609721</guid>    <pubDate>2026-02-13 14:05:09</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>HarmonyOS 6.0 图书馆管理系统（ArkTS）开发实战</h2><h3>一、项目概述</h3><p>你想要开发的是基于HarmonyOS 6.0、使用ArkTS语言构建的图书馆管理系统，该系统面向图书馆管理员和读者，核心实现图书查询、借阅/归还、图书管理等基础功能，采用HarmonyOS 6.0的最新特性（如Stage模型、ArkUI组件化）开发，适配多设备形态，兼顾易用性和性能。<br/><img referrerpolicy="no-referrer" src="https://i-blog.csdnimg.cn/direct/a97c7d88ad7043649fd3d89218c7884f.png" alt="在这里插入图片描述" title="在这里插入图片描述"/></p><h3>二、技术栈与环境准备</h3><h4>1. 核心技术</h4><ul><li>开发语言：ArkTS（TypeScript超集，HarmonyOS原生开发语言）</li><li>应用模型：Stage模型（HarmonyOS 6.0推荐的主流应用模型）</li><li>UI框架：ArkUI（基于TSX的声明式UI）</li><li>数据存储：Preferences（轻量级键值存储）+ RelationalStore（关系型数据库）</li><li>设备适配：自适应布局（Flex/Grid）</li></ul><h4>2. 环境要求</h4><ul><li>DevEco Studio：4.2及以上版本</li><li>HarmonyOS SDK：6.0（API Version 11）</li><li>模拟器/真机：HarmonyOS 6.0及以上设备</li></ul><h3>三、核心功能设计</h3><p>本系统聚焦3个核心模块，满足基础图书馆管理需求：</p><ol><li>图书查询（读者端）：按书名/作者/分类检索图书，查看图书状态（可借/已借出）</li><li>借阅/归还（管理员端）：扫描/输入图书编号，完成借阅、归还操作</li><li>图书管理（管理员端）：新增、编辑、删除图书信息</li></ol><h3>四、代码实现</h3><h4>1. 项目结构（Stage模型）</h4><pre><code>library-system/
├── entry/
│   ├── src/main/ets/
│   │   ├── entryability/       # 应用入口
│   │   ├── pages/              # 页面（图书列表、借阅页、管理页）
│   │   ├── model/              # 数据模型
│   │   ├── util/               # 工具类（数据库、存储）
│   │   └── resources/          # 资源（字符串、样式）</code></pre><p><img referrerpolicy="no-referrer" src="https://i-blog.csdnimg.cn/direct/b4fa1af80e2a4c42bacb39e9ef4b4ba9.png" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h4>2. 数据模型定义（model/BookModel.ets）</h4><p>定义图书和借阅记录的数据结构，作为全局数据模型：</p><pre><code class="typescript">/**
 * 图书数据模型
 */
export interface Book {
  id: string;        // 图书编号（唯一标识）
  name: string;      // 书名
  author: string;    // 作者
  category: string;  // 分类（如计算机、文学）
  status: boolean;   // 状态：true-可借，false-已借出
  borrowTime?: string;// 借阅时间（可选）
  borrower?: string;  // 借阅人（可选）
}

/**
 * 全局状态管理（简化版）
 */
export class BookManager {
  private static instance: BookManager;
  private books: Book[] = [];

  private constructor() {
    // 初始化测试数据
    this.books = [
      { id: "001", name: "ArkTS开发实战", author: "鸿蒙开发者", category: "计算机", status: true },
      { id: "002", name: "HarmonyOS 6.0进阶", author: "华为技术团队", category: "计算机", status: false, borrowTime: "2026-02-01", borrower: "张三" },
      { id: "003", name: "百年孤独", author: "加西亚·马尔克斯", category: "文学", status: true }
    ];
  }

  // 单例模式，保证全局唯一实例
  public static getInstance(): BookManager {
    if (!BookManager.instance) {
      BookManager.instance = new BookManager();
    }
    return BookManager.instance;
  }

  // 获取所有图书
  getBooks(): Book[] {
    return this.books;
  }

  // 按关键词查询图书
  searchBooks(keyword: string): Book[] {
    return this.books.filter(book =&gt; 
      book.name.includes(keyword) || 
      book.author.includes(keyword) || 
      book.category.includes(keyword)
    );
  }

  // 借阅图书
  borrowBook(bookId: string, borrower: string): boolean {
    const book = this.books.find(b =&gt; b.id === bookId);
    if (book &amp;&amp; book.status) {
      book.status = false;
      book.borrowTime = new Date().toLocaleDateString();
      book.borrower = borrower;
      return true;
    }
    return false;
  }

  // 归还图书
  returnBook(bookId: string): boolean {
    const book = this.books.find(b =&gt; b.id === bookId);
    if (book &amp;&amp; !book.status) {
      book.status = true;
      book.borrowTime = undefined;
      book.borrower = undefined;
      return true;
    }
    return false;
  }

  // 新增图书
  addBook(book: Book): void {
    this.books.push(book);
  }

  // 删除图书
  deleteBook(bookId: string): boolean {
    const index = this.books.findIndex(b =&gt; b.id === bookId);
    if (index !== -1) {
      this.books.splice(index, 1);
      return true;
    }
    return false;
  }
}</code></pre><h4>3. 图书列表/查询页面（pages/BookListPage.ets）</h4><p>实现图书列表展示和关键词查询功能，采用ArkUI声明式UI：</p><pre><code class="tsx">@Entry
@Component
struct BookListPage {
  // 状态变量：搜索关键词、图书列表
  @State searchKeyword: string = "";
  @State bookList: Book[] = [];
  private bookManager = BookManager.getInstance();

  // 页面初始化时加载数据
  aboutToAppear() {
    this.bookList = this.bookManager.getBooks();
  }

  // 搜索图书
  onSearch() {
    this.bookList = this.bookManager.searchBooks(this.searchKeyword);
  }

  build() {
    Column() {
      // 搜索栏
      Row({ space: 10 }) {
        TextField({ placeholder: "输入书名/作者/分类查询" })
          .width("70%")
          .height(40)
          .border({ width: 1, radius: 8 })
          .padding(8)
          .onChange((value) =&gt; {
            this.searchKeyword = value;
          })
        Button("搜索")
          .width("20%")
          .height(40)
          .backgroundColor("#007DFF")
          .onClick(() =&gt; this.onSearch())
      }
      .padding(10)
      .width("100%")

      // 图书列表
      List() {
        ForEach(this.bookList, (book: Book) =&gt; {
          ListItem() {
            Column() {
              Row({ space: 15 }) {
                Text(`编号：${book.id}`)
                  .fontSize(14)
                  .fontColor("#666")
                Text(`书名：${book.name}`)
                  .fontSize(16)
                  .fontWeight(FontWeight.Bold)
                Text(book.status ? "可借" : "已借出")
                  .fontSize(14)
                  .fontColor(book.status ? "#00C800" : "#FF4D4F")
              }
              .width("100%")
              .padding(5)

              Row({ space: 15 }) {
                Text(`作者：${book.author}`)
                  .fontSize(14)
                Text(`分类：${book.category}`)
                  .fontSize(14)
              }
              .width("100%")
              .padding(5)

              // 已借出图书显示借阅信息
              if (!book.status) {
                Row() {
                  Text(`借阅人：${book.borrower}`)
                    .fontSize(12)
                    .fontColor("#999")
                  Text(`借阅时间：${book.borrowTime}`)
                    .fontSize(12)
                    .fontColor("#999")
                }
                .width("100%")
                .padding(5)
              }
            }
            .width("100%")
            .padding(10)
            .borderBottom({ width: 0.5, color: "#EEEEEE" })
          }
        })
      }
      .width("100%")
      .flexGrow(1)
    }
    .width("100%")
    .height("100%")
    .padding(5)
  }
}</code></pre><h4>4. 借阅/归还页面（pages/BorrowReturnPage.ets）</h4><p>实现图书借阅和归还的核心操作：</p><pre><code class="tsx">@Entry
@Component
struct BorrowReturnPage {
  @State bookId: string = "";
  @State borrower: string = "";
  @State tipText: string = "";
  @State tipColor: string = "#333";
  private bookManager = BookManager.getInstance();

  // 借阅操作
  borrowBook() {
    if (!this.bookId || !this.borrower) {
      this.tipText = "图书编号和借阅人不能为空！";
      this.tipColor = "#FF4D4F";
      return;
    }
    const result = this.bookManager.borrowBook(this.bookId, this.borrower);
    if (result) {
      this.tipText = `借阅成功！图书${this.bookId}已借出`;
      this.tipColor = "#00C800";
    } else {
      this.tipText = "借阅失败！图书不存在或已借出";
      this.tipColor = "#FF4D4F";
    }
    // 清空输入框
    this.bookId = "";
    this.borrower = "";
  }

  // 归还操作
  returnBook() {
    if (!this.bookId) {
      this.tipText = "图书编号不能为空！";
      this.tipColor = "#FF4D4F";
      return;
    }
    const result = this.bookManager.returnBook(this.bookId);
    if (result) {
      this.tipText = `归还成功！图书${this.bookId}已入库`;
      this.tipColor = "#00C800";
    } else {
      this.tipText = "归还失败！图书不存在或未借出";
      this.tipColor = "#FF4D4F";
    }
    // 清空输入框
    this.bookId = "";
  }

  build() {
    Column({ space: 20 }) {
      // 借阅模块
      Column({ space: 10 }) {
        Text("图书借阅")
          .fontSize(18)
          .fontWeight(FontWeight.Bold)
          .alignSelf(ItemAlign.Start)
        TextField({ placeholder: "输入图书编号" })
          .width("100%")
          .height(40)
          .border({ width: 1, radius: 8 })
          .padding(8)
          .onChange((value) =&gt; this.bookId = value)
        TextField({ placeholder: "输入借阅人姓名" })
          .width("100%")
          .height(40)
          .border({ width: 1, radius: 8 })
          .padding(8)
          .onChange((value) =&gt; this.borrower = value)
        Button("确认借阅")
          .width("100%")
          .height(40)
          .backgroundColor("#007DFF")
          .onClick(() =&gt; this.borrowBook())
      }
      .width("90%")
      .padding(15)
      .backgroundColor("#F5F7FA")
      .borderRadius(10)

      // 归还模块
      Column({ space: 10 }) {
        Text("图书归还")
          .fontSize(18)
          .fontWeight(FontWeight.Bold)
          .alignSelf(ItemAlign.Start)
        TextField({ placeholder: "输入图书编号" })
          .width("100%")
          .height(40)
          .border({ width: 1, radius: 8 })
          .padding(8)
          .onChange((value) =&gt; this.bookId = value)
        Button("确认归还")
          .width("100%")
          .height(40)
          .backgroundColor("#00C800")
          .onClick(() =&gt; this.returnBook())
      }
      .width("90%")
      .padding(15)
      .backgroundColor("#F5F7FA")
      .borderRadius(10)

      // 提示信息
      Text(this.tipText)
        .fontSize(14)
        .fontColor(this.tipColor)
    }
    .width("100%")
    .height("100%")
    .padding(20)
    .justifyContent(FlexAlign.Center)
  }
}</code></pre><h3>五、功能扩展与优化建议</h3><ol><li><strong>持久化存储</strong>：当前数据仅存在于内存中，可集成RelationalStore将图书数据存入本地数据库，保证应用重启后数据不丢失；</li><li><strong>权限管理</strong>：新增登录模块，区分管理员/读者权限（管理员可操作借阅/归还，读者仅可查询）；</li><li><strong>扫码功能</strong>：集成HarmonyOS的扫码API，通过扫描图书条形码/二维码快速获取图书编号；</li><li><strong>多设备适配</strong>：使用MediaQuery适配手机、平板、智慧屏等不同尺寸设备，优化大屏布局；</li><li><strong>网络同步</strong>：对接后端接口（如SpringBoot），实现多设备数据同步、远程图书管理。</li></ol><h3>六、运行效果</h3><ol><li>图书列表页：可输入关键词搜索图书，列表展示图书基本信息和状态；</li><li>借阅/归还页：输入图书编号和借阅人信息，完成借阅/归还操作，实时提示操作结果；</li><li>所有操作实时同步到内存中的图书数据，刷新列表可看到状态变化。</li></ol><h4>总结</h4><ol><li>本图书馆管理系统基于HarmonyOS 6.0 + ArkTS开发，采用Stage模型和声明式UI，核心实现了图书查询、借阅/归还、图书管理等基础功能；</li><li>代码采用单例模式管理图书数据，保证全局数据一致性，同时通过ArkUI组件实现了简洁易用的交互界面；</li><li>可基于本基础版本扩展持久化存储、权限管理、扫码、网络同步等功能，适配更复杂的图书馆业务场景。</li></ol><p>该系统充分利用了HarmonyOS 6.0的ArkTS特性，代码结构清晰、易扩展，适合作为HarmonyOS应用开发的入门实战项目。</p>]]></description></item><item>    <title><![CDATA[纯原生适配！ArkTS 开发 DormMate新生系统欢迎界面全解析 逐梦AI ]]></title>    <link>https://segmentfault.com/a/1190000047609728</link>    <guid>https://segmentfault.com/a/1190000047609728</guid>    <pubDate>2026-02-13 14:04:33</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>纯原生适配！ArkTS 开发 DormMate新生系统欢迎界面全解析</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609730" alt="在这里插入图片描述" title="在这里插入图片描述"/></p><h3>前言</h3><p>随着高校信息化建设的推进，传统的宿舍管理模式存在效率低、信息孤岛多、交互体验差等问题。新生入住宿舍是学校管理中非常关键的环节，从分配床位、办理入住手续，到查询宿舍信息，管理流程繁杂。</p><p>本篇文章以 <strong>HarmonyOS 6.0 原生开发</strong> 为基础，分享 <strong>DormMate 新生宿舍管理系统</strong>中“欢迎区域”模块的实现方法。重点解析 ArkTS 声明式 UI 构建、多端适配以及鸿蒙原生组件使用技巧，为想基于 HarmonyOS 6.0 进行原生应用开发的读者提供参考。</p><hr/><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609731" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h3>背景</h3><ol><li><p><strong>传统管理痛点</strong>：</p><ul><li>手工登记信息，易出错</li><li>新生对流程不熟悉，需人工指导</li><li>信息更新慢，难以实时共享</li></ul></li><li><p><strong>系统设计目标</strong>：</p><ul><li><strong>简洁友好的欢迎界面</strong>：让新生第一眼就感受到服务功能</li><li><strong>高可扩展性</strong>：欢迎区域可以轻松添加活动信息、公告、快捷入口</li><li><strong>跨端统一体验</strong>：手机、平板、桌面端界面一致</li></ul></li><li><p><strong>技术选型</strong>：</p><ul><li><strong>HarmonyOS 6.0</strong>：原生分布式操作系统，提供多端统一的应用开发框架</li><li><strong>ArkTS</strong>：鸿蒙原生声明式开发语言，支持跨设备 UI 一致性渲染</li><li><strong>ArkUI</strong>：鸿蒙原生 UI 框架，提供丰富的组件库和布局能力</li></ul></li></ol><hr/><h3>HarmonyOS 6.0 原生开发介绍</h3><p>HarmonyOS 6.0 基于“一次开发，多端部署”的核心理念，提供了 <strong>分布式软总线</strong>、<strong>分布式数据管理</strong> 和 <strong>统一的 ArkUI 框架</strong>。ArkTS 作为其原生开发语言，具备以下优势：</p><table><thead><tr><th>特性</th><th>HarmonyOS 6.0 原生开发</th></tr></thead><tbody><tr><td>跨端开发</td><td>✅ 天然支持手机、平板、智慧屏、桌面端等多终端部署</td></tr><tr><td>UI 构建</td><td>✅ 声明式 UI 语法，与 相近但更贴合鸿蒙系统</td></tr><tr><td>性能</td><td>✅ 系统级深度优化，原生渲染性能更佳</td></tr><tr><td>系统能力</td><td>✅ 全面调用 HarmonyOS 分布式能力、系统服务</td></tr></tbody></table><p>在 DormMate 系统中，我们将利用 ArkTS + ArkUI 构建原生界面，充分发挥 HarmonyOS 6.0 的分布式特性，实现多端统一的欢迎页面。</p><hr/><h3>开发核心代码：欢迎区域实现</h3><p>下面是“欢迎区域”的核心实现代码，以及逐行解析。该模块的功能包括：</p><ul><li>欢迎新生文字提示</li><li>简介功能</li><li>当季入住信息</li><li>图标装饰</li></ul><h4>完整代码</h4><pre><code class="typescript">@Entry
@Component
struct WelcomeSection {
  // 获取系统主题
  @State theme: ThemeConstants = getThemeConstants();

  build() {
    Column() {
      this.buildWelcomeCard()
    }
    .padding(16)
    .width('100%')
    .backgroundColor(this.theme.backgroundColor)
  }

  /**
   * 构建欢迎区域卡片
   */
  @Builder
  buildWelcomeCard() {
    Row() {
      // 文字内容区域
      Column() {
        // 欢迎标题
        Text('欢迎使用新生宿舍管理系统')
          .fontSize(this.theme.headlineSmall.fontSize)
          .fontWeight(FontWeight.Bold)
          .fontColor(this.theme.onSurface)
          .margin({ bottom: 8 })

        // 功能描述
        Text('为新生提供便捷的宿舍分配、入住流程管理和宿舍信息查询服务')
          .fontSize(this.theme.bodyMedium.fontSize)
          .fontColor(this.theme.onSurfaceVariant)
          .margin({ bottom: 16 })
          .maxLines(2)
          .textOverflow({ overflow: TextOverflow.Ellipsis })

        // 入住季标签
        Text('2024届新生入住季')
          .fontSize(this.theme.labelLarge.fontSize)
          .fontWeight(FontWeight.Bold)
          .fontColor(this.theme.primary)
          .backgroundColor(this.theme.primaryContainer)
          .padding({ left: 16, right: 16, top: 8, bottom: 8 })
          .borderRadius(20)
      }
      .alignItems(ItemAlign.Start)
      .flexGrow(1) // 占据剩余空间，适配多端

      // 装饰图标区域
      Stack() {
        Text('宿')
          .fontSize(this.theme.displayLarge.fontSize)
          .fontWeight(FontWeight.Bold)
          .fontColor(this.theme.primary)
      }
      .width(100)
      .height(100)
      .backgroundColor(this.theme.primaryContainer)
      .borderRadius(20)
      .justifyContent(FlexAlign.Center)
      .margin({ left: 16 })
    }
    .width('100%')
    .padding(24)
    // 渐变背景
    .backgroundImage(
      LinearGradient.createLinearGradient(
        { x: 0, y: 0 }, // 起始点
        { x: 1, y: 0 }, // 结束点
        [
          this.theme.surfaceVariant + '80', // 带透明度的表面变体色
          this.theme.surface + 'CC'         // 带透明度的表面色
        ]
      )
    )
    .borderRadius(16)
  }
}

/**
 * 主题常量定义（模拟系统主题，实际开发可通过AbilityStage获取）
 */
interface ThemeConstants {
  backgroundColor: string;
  surface: string;
  surfaceVariant: string;
  onSurface: string;
  onSurfaceVariant: string;
  primary: string;
  primaryContainer: string;
  headlineSmall: { fontSize: number };
  bodyMedium: { fontSize: number };
  labelLarge: { fontSize: number };
  displayLarge: { fontSize: number };
}

/**
 * 获取主题常量（简化实现，实际项目建议使用主题管理）
 */
function getThemeConstants(): ThemeConstants {
  // 亮色主题示例，实际可根据系统设置动态切换
  return {
    backgroundColor: '#f9f9f9',
    surface: '#ffffff',
    surfaceVariant: '#f0f0f0',
    onSurface: '#1d1d1f',
    onSurfaceVariant: '#6e6e73',
    primary: '#007aff', // 鸿蒙系统蓝色
    primaryContainer: '#007aff1a', // 主色透明变体
    headlineSmall: { fontSize: 24 },
    bodyMedium: { fontSize: 16 },
    labelLarge: { fontSize: 14 },
    displayLarge: { fontSize: 64 }
  };
}</code></pre><hr/><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609732" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h4>逐行解析</h4><h5>1. 组件结构与入口</h5><pre><code class="typescript">@Entry
@Component
struct WelcomeSection {
  @State theme: ThemeConstants = getThemeConstants();

  build() {
    Column() {
      this.buildWelcomeCard()
    }
    .padding(16)
    .width('100%')
    .backgroundColor(this.theme.backgroundColor)
  }</code></pre><ul><li><code>@Entry</code>：标记该组件为应用入口组件</li><li><code>@Component</code>：声明这是一个 ArkUI 组件</li><li><code>@State</code>：状态装饰器，用于管理组件内部状态（此处存储主题信息）</li><li><code>build()</code>：组件的构建方法，返回 UI 结构</li><li>外层 <code>Column</code> 作为根布局，提供基础的页面边距和背景色</li></ul><h5>2. 欢迎卡片构建器</h5><pre><code class="typescript">@Builder
buildWelcomeCard() {
  Row() {
    // 文字内容区域
    Column() { ... }
    .flexGrow(1)
    
    // 装饰图标区域
    Stack() { ... }
    ...
  }
  .width('100%')
  .padding(24)
  ...
}</code></pre><ul><li><code>@Builder</code>：构建器装饰器，用于封装可复用的 UI 片段</li><li><code>Row</code>：水平布局容器，对应 Row 组件</li><li><code>flexGrow(1)</code>：让文字区域占据剩余空间，实现自适应布局</li><li><code>Stack</code>：堆叠容器，用于实现装饰图标区域（ Container + Center）</li></ul><h5>3. 文字内容区域</h5><pre><code class="typescript">Column() {
  // 欢迎标题
  Text('欢迎使用新生宿舍管理系统')
    .fontSize(this.theme.headlineSmall.fontSize)
    .fontWeight(FontWeight.Bold)
    .fontColor(this.theme.onSurface)
    .margin({ bottom: 8 })

  // 功能描述
  Text('为新生提供便捷的宿舍分配、入住流程管理和宿舍信息查询服务')
    .fontSize(this.theme.bodyMedium.fontSize)
    .fontColor(this.theme.onSurfaceVariant)
    .margin({ bottom: 16 })
    .maxLines(2)
    .textOverflow({ overflow: TextOverflow.Ellipsis })

  // 入住季标签
  Text('2024届新生入住季')
    .fontSize(this.theme.labelLarge.fontSize)
    .fontWeight(FontWeight.Bold)
    .fontColor(this.theme.primary)
    .backgroundColor(this.theme.primaryContainer)
    .padding({ left: 16, right: 16, top: 8, bottom: 8 })
    .borderRadius(20)
}
.alignItems(ItemAlign.Start)
.flexGrow(1)</code></pre><ul><li><code>Column</code>：垂直布局容器，对应 Column 组件</li><li><code>Text</code>：文本组件，支持 fontSize、fontWeight、fontColor 等样式配置</li><li><code>maxLines + textOverflow</code>：实现文本超出两行时的省略号效果</li><li>所有样式均基于主题常量，保证多端风格统一</li></ul><h5>4. 装饰图标区域</h5><pre><code class="typescript">Stack() {
  Text('宿')
    .fontSize(this.theme.displayLarge.fontSize)
    .fontWeight(FontWeight.Bold)
    .fontColor(this.theme.primary)
}
.width(100)
.height(100)
.backgroundColor(this.theme.primaryContainer)
.borderRadius(20)
.justifyContent(FlexAlign.Center)
.margin({ left: 16 })</code></pre><ul><li><code>Stack</code> 配合 <code>justifyContent(FlexAlign.Center)</code> 实现文字居中效果</li><li>直接通过链式调用设置宽高、背景色、圆角等样式，语法更简洁</li><li><code>margin({ left: 16 })</code> 实现与文字区域的间距</li></ul><h5>5. 渐变背景实现</h5><pre><code class="typescript">.backgroundImage(
  LinearGradient.createLinearGradient(
    { x: 0, y: 0 }, // 起始点
    { x: 1, y: 0 }, // 结束点
    [
      this.theme.surfaceVariant + '80', // 80对应16进制的透明度(0.5)
      this.theme.surface + 'CC'         // CC对应16进制的透明度(0.8)
    ]
  )
)</code></pre><ul><li>使用 <code>LinearGradient</code> 创建线性渐变背景</li><li>鸿蒙中通过 16 进制后缀表示透明度（80=0.5，CC=0.8）</li><li>渐变方向从左到右（x从0到1）</li></ul><h5>6. 主题管理</h5><pre><code class="typescript">interface ThemeConstants { ... }

function getThemeConstants(): ThemeConstants {
  return {
    backgroundColor: '#f9f9f9',
    surface: '#ffffff',
    surfaceVariant: '#f0f0f0',
    onSurface: '#1d1d1f',
    onSurfaceVariant: '#6e6e73',
    primary: '#007aff',
    primaryContainer: '#007aff1a',
    headlineSmall: { fontSize: 24 },
    bodyMedium: { fontSize: 16 },
    labelLarge: { fontSize: 14 },
    displayLarge: { fontSize: 64 }
  };
}</code></pre><ul><li>通过接口定义主题常量结构，保证类型安全</li><li>实际项目中可结合 <code>AbilityStage</code> 和 <code>Configuration</code> 实现深色/浅色主题动态切换</li><li>主色使用鸿蒙系统默认蓝色（#007aff），符合系统设计规范</li></ul><hr/><h4>多端适配说明</h4><p>在 HarmonyOS 6.0 中，该组件可通过以下方式实现多端自适应：</p><ol><li><strong>尺寸适配</strong>：使用百分比宽度（<code>width('100%')</code>）和 <code>flexGrow</code> 实现不同屏幕尺寸适配</li><li><strong>字体适配</strong>：可结合 <code>vp</code> 单位（虚拟像素）替代固定像素值，自动适配不同屏幕密度</li><li><p><strong>布局适配</strong>：通过媒体查询（<code>@Media</code>）为不同设备类型定制布局：</p><pre><code class="typescript">// 平板/桌面端适配示例
@Media(minWidth: 800) {
  .buildWelcomeCard() {
 Row() {
   // 平板端可调整布局比例
   Column() { ... }.flexGrow(2)
   Stack() { ... }.width(120).height(120)
 }
  }
}</code></pre></li></ol><hr/><h3>心得</h3><ol><li><p><strong>HarmonyOS 6.0 原生开发优势</strong>：</p><ul><li>原生 API 直接调用鸿蒙系统能力，无需中间层适配</li><li>多端部署能力更原生，无需额外插件支持</li></ul></li><li><p><strong>UI 设计技巧</strong>：</p><ul><li>使用主题常量统一管理颜色和字体，保证多端风格一致</li><li>链式调用语法让样式配置更简洁直观</li></ul></li><li><p><strong>开发效率</strong>：</p><ul><li>ArkTS 支持热重载，开发调试效率高</li><li>原生组件性能更优，尤其在鸿蒙设备上表现更佳</li></ul></li></ol><hr/><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609733" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h3>总结</h3><p>本文介绍了基于 <strong>HarmonyOS 6.0 原生开发</strong> 的 <strong>DormMate 新生宿舍管理系统</strong>欢迎区域模块实现思路。通过 ArkTS + ArkUI 构建的原生界面，充分利用了鸿蒙系统的分布式能力和原生渲染优势，为新生提供了一个简洁、易读、现代化的入口界面。</p><p>HarmonyOS 原生开发在系统集成度、性能表现和多端适配方面更具优势，尤其适合深度适配鸿蒙生态的应用。该欢迎区域组件具备良好的可扩展性，可快速添加公告、快捷入口等功能，并天然支持在手机、平板、桌面端等多设备上统一呈现。</p><p><strong>DormMate</strong> 的设计理念是：<strong>原生、高效、跨端统一</strong>，为学校宿舍管理系统提供了一套深度适配 HarmonyOS 生态的前端解决方案。</p><h4>关键点回顾</h4><ol><li><strong>核心实现</strong>：使用 ArkTS 声明式语法，通过 Row/Column/Stack 布局组合 + LinearGradient 渐变背景实现欢迎区域 UI</li><li><strong>主题管理</strong>：通过主题常量统一管理颜色和字体样式，支持深色/浅色模式适配</li><li><strong>多端适配</strong>：利用 flex 布局、百分比宽度和媒体查询，实现手机/平板/桌面端的自适应展示</li></ol>]]></description></item><item>    <title><![CDATA[OpenClaw模型接入全指南：免费Token+新模型适配（含Higress解决方案） 鸿枫 ]]></title>    <link>https://segmentfault.com/a/1190000047609742</link>    <guid>https://segmentfault.com/a/1190000047609742</guid>    <pubDate>2026-02-13 14:03:52</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>OpenClaw模型接入全指南：免费Token+新模型适配（含Higress解决方案）</p><p>当前AI圈迭代速度迅猛，智谱GLM-5、MiniMax M2.5等新模型接连发布，在性能和性价比上实现大幅突破，但OpenClaw用户普遍面临两大痛点：一是Token消耗过快、付费成本高，二是新模型无法及时适配，需等待官方发版升级。本文将整合两大核心解决方案——讯飞星辰免费Token计划（解决成本问题）与Higress AI网关（解决新模型适配问题），搭配详细操作步骤，帮助OpenClaw用户零成本、高效适配各类前沿模型，畅享大模型生产力。</p><p>一、基础保障：讯飞星辰免费Token计划（零成本用模型）</p><p>对于追求低成本使用OpenClaw的用户，讯飞星辰MaaS平台推出的春节免费Token计划，是经实测可行的优选方案，可有效解决Token消耗过快的核心痛点，适配各类OpenClaw基础使用场景。</p><p>1.1 核心优势</p><ul><li>完全免费：0元获取Token，无需支付任何费用，彻底解决OpenClaw Token使用成本高的问题，日常使用无经济压力。</li><li>适配性强：明确支持OpenClaw运行，无需修改工具核心设置，配置流程简单易懂，新手用户也能快速完成操作。</li><li>官方合规：Token由讯飞星辰官方平台提供，稳定性有保障，规避非正规渠道Token带来的账号安全、使用异常等风险。</li></ul><p>补充说明：官方宣传Token使用无速度限制，实际使用中会存在轻微卡顿，整体流畅度可满足日常文本生成、简单编程等需求，属于可接受范围。</p><p>1.2 前期准备：获取讯飞星辰Token及API授权</p><p>配置前需先前往讯飞星辰MaaS平台，获取模型API授权、API Key等关键信息，具体步骤如下：</p><ol><li>访问讯飞星辰MaaS平台官方地址：<a href="https://link.segmentfault.com/?enc=Nqo1ajIXAoMzWduVXk22%2Bg%3D%3D.y9yBQanKlV78I4XvnbiHmbStoLc68lo8iVwEkht1hps%3D" rel="nofollow" target="_blank">https://maas.xfyun.cn/</a>，完成注册及登录（已有账号可直接登录）。</li><li>进入模型集市：访问<a href="https://link.segmentfault.com/?enc=uAk2Pw2R3adtZy9rl73zqA%3D%3D.IyQKIUbUU6v%2FdmEcp4xQTF0aWYHz2VnmQi4j0jw%2BUPANTu7yxXlbBB%2F1EGwyZpN7" rel="nofollow" target="_blank">https://maas.xfyun.cn/modelSquare</a>，找到对应模型卡片，点击“API调用”，即可获取模型API授权及现金礼品卡（礼品卡非配置必需，可用于后续服务拓展）。</li><li>获取核心配置信息：登录后进入推理服务控制台（地址：<a href="https://link.segmentfault.com/?enc=Y6UthHLgQPskJ5%2FdaBUmmA%3D%3D.hS4f%2BNEjve%2BG97wErt4dHpRSTZpSj%2BtldWITmKZxO2I5Jjp31LJlEadmMi6gs9vW" rel="nofollow" target="_blank">https://maas.xfyun.cn/modelService</a>），页面将展示所有模型服务所需关键信息，其中开发者专属API Key是后续配置的核心，需重点记录。</li></ol><p>1.3 OpenClaw配置步骤（附可直接复制模板）</p><p>讯飞星辰MaaS平台提供OpenAI兼容接口，可在OpenClaw中按“OpenAI / OpenAI-Compatible”模式直接配置，全程无需修改复杂参数：</p><ol><li>找到配置文件：打开OpenClaw工具，在设置中找到“配置文件”入口（或按工具指引查找文件路径），将下方模板复制粘贴，替换原有相关配置（配置文件为空可直接粘贴）。</li><li>填充核心信息：将前期获取的API Key，替换模板中“YOUR_API_KEY”位置，其余参数无需修改（模板已包含常用模型及最优基础配置）。</li><li>验证配置：保存配置文件并重启OpenClaw（部分版本无需重启可直接生效），在聊天窗口发送测试消息（如“你好”），若能正常收到返回结果，即表示配置成功，Token可正常使用。</li></ol><p>可直接复制的配置模板</p><p>{<br/>  "meta": {</p><pre><code>"lastTouchedVersion": "2026.2.1",
"lastTouchedAt": "2026-02-04T12:14:10.945Z"</code></pre><p>},<br/>  "models": {</p><pre><code>"mode": "merge",
"providers": {
  "ds": {
    "baseUrl": "https://maas-api.cn-huabei-1.xf-yun.com/v2",
    "apiKey": "YOUR_API_KEY",
    "api": "openai-completions",
    "models": [
      {
        "id": "xopdeepseekv32",
        "name": "DeepSeek-V3.2",
        "reasoning": false,
        "input": [
          "text"
        ],
        "cost": {
          "input": 0.0025,
          "output": 0.01,
          "cacheRead": 0,
          "cacheWrite": 0
        },
        "contextWindow": 32768,
        "maxTokens": 32768
      }
    ]
  }
}</code></pre><p>},<br/>  "agents": {</p><pre><code>"defaults": {
  "model": {
    "primary": "ds/xopdeepseekv32"
  },
  "models": {
    "ds/xopdeepseekv32": {
      "alias": "xopdeepseekv32"
    }
  },
  "compaction": {
    "mode": "safeguard"
  },
  "maxConcurrent": 4,
  "subagents": {
    "maxConcurrent": 8
  }
}</code></pre><p>},<br/>  "messages": {</p><pre><code>"ackReactionScope": "group-mentions"</code></pre><p>},<br/>  "commands": {</p><pre><code>"native": "auto",
"nativeSkills": "auto"</code></pre><p>},<br/>  "channels": {<br/>  },<br/>  "gateway": {</p><pre><code>"mode": "local",
"tailscale": {
  "mode": "off"
}</code></pre><p>},<br/>  "plugins": {</p><pre><code>"entries": {
},
"installs": {
}</code></pre><p>}<br/>}</p><p>二、进阶解决方案：Higress AI网关（适配各类新模型）</p><p>随着智谱GLM-5、MiniMax M2.5等新模型密集发布，OpenClaw原生存在“模型硬编码”问题——新模型无法通过配置直接接入，需等待官方发版升级，严重滞后于模型迭代速度。而Higress AI网关通过“模型配置与网关解耦”的设计，可彻底解决这一痛点，让OpenClaw用户即时适配各类前沿模型。</p><p>2.1 OpenClaw原生模型支持困境</p><p>目前OpenClaw的各个provider默认模型均为硬编码，新模型发布后无法通过配置支持，需等待维护者处理相关issue并发版升级，具体痛点如下：</p><ul><li>新模型适配滞后：智谱GLM-5、MiniMax M2.5均无法直接接入，后续Qwen/DeepSeek发布新模型，大概率仍需等待官方适配。</li><li>迭代节奏不匹配：MiniMax 108天内连发3个版本，智谱、DeepSeek等厂商迭代速度相近，而OpenClaw官方适配速度难以跟上，导致用户无法及时使用新模型的核心能力。</li></ul><p>2.2 Higress AI网关核心优势</p><p>Higress采用与OpenClaw原生完全不同的设计思路，将模型配置与网关解耦，新增模型无需升级，热更新即时生效，核心优势如下：</p><ul><li>热更新支持：新增模型、更换供应商后，配置热加载，无需重启网关，即时生效。</li><li>任意模型兼容：只要模型提供OpenAI兼容API，即可接入OpenClaw，无需担心适配问题。</li><li>预配置常用供应商：插件内置智谱、MiniMax、Kimi、DeepSeek、Qwen等主流厂商，无需手动配置基础参数。</li><li>操作极简：通过Higress OpenClaw Integration Skill，一句话即可完成全部配置，无需修改复杂代码。</li></ul><p>2.3 Higress接入OpenClaw详细步骤</p><p>Higress通过专属Integration Skill简化配置流程，全程无需手动修改配置文件，仅需通过OpenClaw对话即可完成：</p><ol><li>安装Integration Skill：在OpenClaw聊天窗口发送指令：“帮我下载并安装这个技能：<a href="https://link.segmentfault.com/?enc=bX%2B3cV4Ou4piloUsCu4Fyg%3D%3D.XjHAVL3vpIODS%2BQzZrhtPL7xYcmTCpYn0INqxRRfF6GhbzJWRhdLocuO%2BsN3drqWY9C1VJFILOMlVGOGxmuAcw%3D%3D" rel="nofollow" target="_blank">https://higress.cn/skills/higress-openclaw-integration.zip</a>”。</li><li>自动配置网关：发送指令：“使用这个技能帮我配置Higress AI Gateway”，OpenClaw将自动完成以下操作：</li></ol><ul><li>下载并安装Higress Integration Skill；</li><li>部署Higress AI Gateway；</li><li>配置指定的模型供应商和API Key；</li><li>安装并启用OpenClaw插件。</li></ul><ol start="3"><li><p>使用新模型：配置完成后，直接在OpenClaw中指定模型即可使用，示例如下：</p></li></ol><ul><li>使用GLM-5：model: "higress/glm-5"</li><li>使用MiniMax M2.5：model: "higress/minimax-m25"</li><li>自动路由（智能选模型）：model: "higress/auto"</li></ul><p>2.4 后续新增模型：一句话快速适配</p><p>若后续DeepSeek发布V4、Qwen推出新版本等，无需重启网关、无需升级组件，仅需在OpenClaw中发送简单指令即可完成适配：</p><ul><li>添加新供应商API Key：“帮我添加DeepSeek的API Key：sk-xxx”</li><li>切换默认模型：“帮我把默认模型切换到deepseek-v4”</li></ul><p>指令发送后，配置热加载即时生效，真正实现“模型迭代无滞后”。</p><p>三、重点关注：GLM-5与MiniMax M2.5核心能力解析</p><p>当前AI圈最值得关注的两大新模型——GLM-5（开源标杆）与MiniMax M2.5（性价比之王），通过Higress可直接接入OpenClaw，其核心能力如下，方便用户根据需求选择使用：</p><p>3.1 GLM-5：开源界的“系统架构师”</p><p>智谱2月11日发布的GLM-5，采用MoE架构，744B总参数中每次仅激活44B，配合DeepSeek稀疏注意力机制，在保持高性能的同时大幅降低部署成本，核心亮点如下：</p><ul><li>参数与性能：744B总参数、202K上下文窗口，Coding与Agent能力达到开源SOTA，官方定位为“Opus 4.6与GPT-5.3的国产开源平替”。</li><li>核心优势：擅长复杂系统工程与长程Agent任务，在真实编程场景的体感逼近Claude Opus 4.5，适合需要深度架构设计的场景。</li></ul><p>3.2 MiniMax M2.5：Agent时代的性价比之王</p><p>MiniMax在GLM-5发布一天后推出的M2.5，主打“真实世界生产力”，性能与成本优势突出，核心亮点如下：</p><ul><li>性能领先：SWE-Bench Verified跑分80.2%，Multi-SWE-Bench跑分51.3%拿下第一，编程能力出众。</li><li>成本极低：使用成本仅为Opus的1/10，100 TPS连续工作一小时仅需1美金，1万美金可支持4个Agent连续工作一年。</li><li>适配广泛：支持Go、C、C++、TypeScript等10+语言，覆盖Web、Android、iOS等全平台，适合各类编程场景。</li><li>智能特性：动手写代码前，会主动拆解功能、结构和UI设计，具备“架构师级”思考能力。</li></ul><p>四、高效使用技巧：Higress自动路由功能</p><p>GLM-5与MiniMax M2.5定位不同（GLM-5架构能力强，M2.5性价比高），Higress的自动路由功能可根据任务类型智能调度模型，无需手动切换，提升使用效率：</p><p>4.1 配置自动路由规则</p><p>在OpenClaw中发送指令，即可配置自动路由规则，示例如下：</p><ul><li>遇到“深入思考”“复杂问题”“架构设计”时，使用glm-5；</li><li>遇到“简单”“快速”“翻译”时，使用minimax-m25-lite；</li><li>日常代码任务，使用minimax-m25（便宜又能打）。</li></ul><p>4.2 使用方法</p><p>配置完成后，仅需在OpenClaw中指定模型为“higress/auto”，系统将根据消息内容自动选择最合适的模型进行推理，兼顾性能与成本。</p><p>五、常见问题及补充说明</p><p>5.1 讯飞星辰Token相关问题</p><ul><li>配置后无法使用：优先检查API Key是否填写正确（注意大小写、空格），若无误，可重新登录讯飞星辰平台确认API授权有效，或刷新控制台重新获取API Key。</li><li>使用速度过慢：轻微卡顿属于正常现象，不影响日常使用；卡顿严重时，可检查网络连接，或重启OpenClaw及网络设备。</li><li>Token期限与额度：该计划为讯飞星辰春节专属免费活动，具体期限及额度以官方通知为准，建议及时配置使用。</li></ul><p>5.2 Higress网关相关问题</p><ul><li>无法自动配置：若当前使用的模型能力较弱，无法自动完成配置，可访问Higress Integration Skill说明文档（相关链接见文末），按步骤手动配置。</li><li>新模型接入失败：确认模型提供OpenAI兼容API，若仍失败，可发送指令重新添加供应商API Key，或检查网关配置是否生效。</li></ul><p>六、总结与后续支持</p><p>6.1 核心方案对比</p><p>对比项</p><p>OpenClaw原生</p><p>OpenClaw+讯飞星辰Token</p><p>OpenClaw+Higress</p><p>使用成本</p><p>较高（需付费Token）</p><p>零成本</p><p>按需选择（可搭配免费/付费Token）</p><p>新模型支持</p><p>需等待官方发版</p><p>仅支持讯飞星辰相关模型</p><p>一句话配置，即时适配</p><p>操作难度</p><p>中等</p><p>简单（模板复制）</p><p>极简（对话指令）</p><p>维护成本</p><p>高（等官方更新）</p><p>低（官方保障）</p><p>低（自主可控，即时响应）</p><p>6.2 后续支持</p><ol><li>讯飞星辰Token配置问题：若遇到配置失败、Token无法使用等问题，可转发本文并在评论区留言“666”，获取手把手配置指导。</li><li>Higress网关配置问题：可访问Higress OpenClaw Integration Skill官方链接，查看详细说明文档，或参考文档中的手动配置步骤。</li></ol><p>6.3 相关链接</p><ul><li>讯飞星辰MaaS平台：<a href="https://link.segmentfault.com/?enc=Cb7QEz1aksyPegMp2gk3Uw%3D%3D.FURKTYdb2UTjChzAGMb3O5ABHqQLqjPfBWgmJKQMclo%3D" rel="nofollow" target="_blank">https://maas.xfyun.cn/</a></li><li>Higress OpenClaw Integration Skill：<a href="https://link.segmentfault.com/?enc=L3zJH%2BwIE3Zu%2Fe32W9NO9w%3D%3D.Eb%2BUDxEF5qZSZPveyoz1mk%2Fi7gRfBbGVUp32Gur5bfMmVvBSKuKrxL6oour%2BIHoJ4JzxabPRqbl%2FQA9LTZQSEUGPkhvK%2FCdXFzz9ozNV%2B9uWm%2BvvMkpq6Z7X0%2FZPbfeg" rel="nofollow" target="_blank">https://github.com/alibaba/higress/tree/main/.claude/skills/higress-openclaw-integration</a></li></ul><p>综上，讯飞星辰免费Token计划解决了OpenClaw用户的成本痛点，Higress AI网关解决了新模型适配痛点，两者结合可让用户零成本、高效使用各类前沿AI模型。无论是追求低成本的普通用户，还是需要使用新模型提升生产力的进阶用户，均可按照本文步骤操作，快速实现模型接入与高效使用。</p><p>本文由<a href="https://link.segmentfault.com/?enc=Ba69GfkayQL8%2F06a9AXmYg%3D%3D.t6w1jJl9e4tUzCOB6dqcmjU%2B%2BctI0EfEMZ4mWF7T6qA%3D" rel="nofollow" target="_blank">mdnice</a>多平台发布</p>]]></description></item><item>    <title><![CDATA[从零开始开发HarmonyOS 6.0 TodoList应用（ArkTS版） 逐梦AI ]]></title>    <link>https://segmentfault.com/a/1190000047609746</link>    <guid>https://segmentfault.com/a/1190000047609746</guid>    <pubDate>2026-02-13 14:03:07</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>从零开始开发HarmonyOS 6.0 TodoList应用（ArkTS版）</h2><p>你想要基于HarmonyOS 6.0和ArkTS语言开发一个TodoList（待办清单）应用，这篇文章会从项目搭建、核心功能实现到界面美化，一步步带你完成一个可运行、功能完整的TodoList应用，适合HarmonyOS开发新手学习和实践。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047609748" alt="在这里插入图片描述" title="在这里插入图片描述"/></p><h3>一、开发环境准备</h3><p>在开始编码前，确保你已完成以下准备：</p><ol><li>安装最新版DevEco Studio（建议4.1及以上版本，适配HarmonyOS 6.0）</li><li>配置HarmonyOS SDK 6.0</li><li>了解ArkTS基础语法（声明式UI、状态管理、组件生命周期）</li></ol><h3>二、项目创建</h3><ol><li>打开DevEco Studio，新建“Empty Ability”项目</li><li><p>配置项目信息：</p><ul><li>Project name: TodoListDemo</li><li>Bundle name: 自定义（如com.example.todolist）</li><li>Compile SDK: 6.0 (API 12)</li><li>Model: Stage</li><li>Language: ArkTS</li></ul></li></ol><h3>三、核心功能实现</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609749" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h4>3.1 数据模型定义</h4><p>首先定义待办事项的数据结构，创建<code>model/TodoItem.ets</code>文件：</p><pre><code class="typescript">/**
 * 待办事项数据模型
 */
export interface TodoItem {
  // 唯一标识
  id: string;
  // 待办内容
  content: string;
  // 是否完成
  isCompleted: boolean;
  // 创建时间
  createTime: string;
}

/**
 * 生成唯一ID
 */
export function generateId(): string {
  return Date.now().toString() + Math.random().toString(36).substr(2, 9);
}

/**
 * 格式化时间
 */
export function formatTime(time: number): string {
  const date = new Date(time);
  return `${date.getFullYear()}-${(date.getMonth() + 1).toString().padStart(2, '0')}-${date.getDate().toString().padStart(2, '0')} ${date.getHours().toString().padStart(2, '0')}:${date.getMinutes().toString().padStart(2, '0')}`;
}</code></pre><h4>3.2 主页面实现（核心功能）</h4><p>修改<code>pages/Index.ets</code>，实现待办事项的添加、删除、状态切换、清空功能：</p><pre><code class="typescript">@Entry
@Component
struct TodoListPage {
  // 待办事项列表（状态管理）
  @State private todoList: TodoItem[] = [];
  // 输入框内容
  @State private inputContent: string = '';
  // 页面标题
  private title: string = '我的待办清单';

  build() {
    Column() {
      // 标题区域
      Text(this.title)
        .fontSize(24)
        .fontWeight(FontWeight.Bold)
        .margin({ top: 20, bottom: 15 })
        .alignSelf(ItemAlign.Center);

      // 输入和添加区域
      Row({ space: 10 }) {
        TextField(this.inputContent, (value: string) =&gt; {
          this.inputContent = value;
        })
          .placeholder('请输入待办事项...')
          .width('70%')
          .height(40)
          .border({ width: 1, radius: 8, color: '#E5E5E5' })
          .padding({ left: 10 });

        Button('添加')
          .width('20%')
          .height(40)
          .backgroundColor('#007DFF')
          .fontColor(Color.White)
          .borderRadius(8)
          .onClick(() =&gt; this.addTodoItem());
      }
      .margin({ bottom: 20 })
      .padding({ left: 15, right: 15 });

      // 待办事项列表区域
      List({ space: 10 }) {
        ForEach(this.todoList, (item: TodoItem) =&gt; {
          ListItem() {
            Row({ space: 10 }) {
              // 完成状态切换复选框
              Checkbox()
                .select(item.isCompleted)
                .onChange((isChecked: boolean) =&gt; {
                  this.toggleTodoStatus(item.id);
                })
                .width(20)
                .height(20);

              // 待办内容（完成时加删除线）
              Text(item.content)
                .fontSize(16)
                .decoration({ type: item.isCompleted ? TextDecorationType.LineThrough : TextDecorationType.None })
                .fontColor(item.isCompleted ? '#999999' : '#333333')
                .flexGrow(1);

              // 创建时间
              Text(item.createTime)
                .fontSize(12)
                .fontColor('#999999')
                .width(100);

              // 删除按钮
              Button('删除')
                .width(60)
                .height(30)
                .backgroundColor('#FF4D4F')
                .fontColor(Color.White)
                .borderRadius(6)
                .fontSize(12)
                .onClick(() =&gt; this.deleteTodoItem(item.id));
            }
            .padding(10)
            .backgroundColor(Color.White)
            .borderRadius(8)
            .shadow({ radius: 2, color: '#00000010', offsetX: 0, offsetY: 2 });
          }
        })
      }
      .width('100%')
      .flexGrow(1)
      .padding({ left: 15, right: 15 });

      // 清空按钮（有数据时显示）
      if (this.todoList.length &gt; 0) {
        Button('清空所有待办')
          .width('90%')
          .height(40)
          .backgroundColor('#F5F5F5')
          .fontColor('#666666')
          .borderRadius(8)
          .margin({ top: 10, bottom: 20 })
          .onClick(() =&gt; this.clearAllTodos());
      }
    }
    .width('100%')
    .height('100%')
    .backgroundColor('#F8F8F8');
  }

  /**
   * 添加待办事项
   */
  private addTodoItem(): void {
    // 空内容校验
    if (this.inputContent.trim() === '') {
      prompt.showToast({ message: '待办内容不能为空！' });
      return;
    }

    // 创建新待办项
    const newTodo: TodoItem = {
      id: generateId(),
      content: this.inputContent.trim(),
      isCompleted: false,
      createTime: formatTime(Date.now())
    };

    // 添加到列表
    this.todoList.push(newTodo);
    // 清空输入框
    this.inputContent = '';
  }

  /**
   * 切换待办事项完成状态
   * @param id 待办项ID
   */
  private toggleTodoStatus(id: string): void {
    const index = this.todoList.findIndex(item =&gt; item.id === id);
    if (index !== -1) {
      this.todoList[index].isCompleted = !this.todoList[index].isCompleted;
    }
  }

  /**
   * 删除待办事项
   * @param id 待办项ID
   */
  private deleteTodoItem(id: string): void {
    this.todoList = this.todoList.filter(item =&gt; item.id !== id);
  }

  /**
   * 清空所有待办事项
   */
  private clearAllTodos(): void {
    this.todoList = [];
  }
}

// 导入数据模型
import { TodoItem, generateId, formatTime } from '../model/TodoItem';
// 导入提示框
import prompt from '@ohos.promptAction';</code></pre><h4>3.3 代码核心解释</h4><ol><li><strong>状态管理</strong>：使用<code>@State</code>装饰器管理待办列表（<code>todoList</code>）和输入框内容（<code>inputContent</code>），状态变化会自动触发UI刷新。</li><li><p><strong>核心方法</strong>：</p><ul><li><code>addTodoItem()</code>：校验输入内容，创建新待办项并添加到列表，清空输入框；</li><li><code>toggleTodoStatus()</code>：根据ID切换待办项的完成状态；</li><li><code>deleteTodoItem()</code>：根据ID过滤删除指定待办项；</li><li><code>clearAllTodos()</code>：清空整个待办列表。</li></ul></li><li><p><strong>UI组件</strong>：</p><ul><li><code>TextField</code>：用于输入待办内容；</li><li><code>Checkbox</code>：标记待办项是否完成；</li><li><code>List + ForEach</code>：循环渲染待办列表；</li><li><code>Button</code>：实现添加、删除、清空操作。</li></ul></li><li><p><strong>交互优化</strong>：</p><ul><li>输入空内容时弹出Toast提示；</li><li>完成的待办项显示删除线和灰色字体；</li><li>列表项添加阴影和圆角，提升视觉效果；</li><li>无待办项时隐藏“清空”按钮。</li></ul></li></ol><h3>四、运行效果</h3><ol><li>启动模拟器（选择HarmonyOS 6.0版本的设备）或连接真机；</li><li><p>点击“运行”按钮，应用启动后：</p><ul><li>在输入框输入待办内容，点击“添加”可新增待办项；</li><li>勾选复选框可标记待办为“已完成”；</li><li>点击“删除”可移除指定待办项；</li><li>点击“清空所有待办”可删除全部待办。</li></ul></li></ol><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609750" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h3>五、功能扩展建议（可选）</h3><p>你可以基于此基础版本扩展更多实用功能：</p><ol><li><strong>本地持久化</strong>：使用<code>@ohos.data.preferences</code>将待办数据保存到本地，重启应用不丢失；</li><li><strong>分类管理</strong>：添加待办分类（工作/生活/学习），支持筛选；</li><li><strong>编辑功能</strong>：允许修改已添加的待办内容；</li><li><strong>优先级标记</strong>：为待办项添加高/中/低优先级标签；</li><li><strong>滑动删除</strong>：实现列表项左滑删除的交互效果。</li></ol><h4>总结</h4><ol><li>本次TodoList应用基于HarmonyOS 6.0和ArkTS开发，核心使用<code>@State</code>状态管理实现UI与数据的双向绑定，通过List+ForEach渲染动态列表；</li><li>实现了待办事项的<strong>添加、状态切换、删除、清空</strong>四大核心功能，同时做了输入校验、视觉美化等交互优化；</li><li>代码结构清晰，数据模型与UI逻辑分离，符合HarmonyOS应用开发的最佳实践，可在此基础上快速扩展更多功能。</li></ol><p>这个TodoList应用覆盖了ArkTS开发的核心知识点（状态管理、组件使用、事件处理），是HarmonyOS新手入门的经典练手项目，你可以直接复制代码运行，也可以根据自己的需求调整界面和功能。</p>]]></description></item><item>    <title><![CDATA[如何利用IP风险情报保障跨境业务的网络安全 科技块儿 ]]></title>    <link>https://segmentfault.com/a/1190000047609755</link>    <guid>https://segmentfault.com/a/1190000047609755</guid>    <pubDate>2026-02-13 14:02:07</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>一、跨境业务面临的网络安全挑战</h2><p>跨境业务的快速发展为全球经济带来了新的机遇，但随之而来的网络安全挑战也愈加严峻。不同地区的法规、文化和网络环境使得跨境业务面临独特的安全威胁。尤其是来自不同国家和地区的IP地址，可能涉及到各种类型的网络攻击和欺诈活动。</p><h3>常见的网络安全风险包括：</h3><ul><li>恶意IP攻击：恶意IP来源可能会进行各种形式的网络攻击，如分布式拒绝服务（DDoS）攻击、SQL注入、跨站脚本（XSS）攻击等。</li><li>代理和VPN伪装：黑客常常利用代理服务器和VPN隐藏真实IP地址，以规避检测进行非法操作，如网络入侵、数据盗窃、欺诈等。</li><li>钓鱼攻击：通过伪装成可信的IP地址，攻击者进行钓鱼攻击，诱使用户泄露敏感信息。</li><li>IP地理位置伪造：黑客利用IP地理位置伪造技术，误导目标系统相信攻击来自合法地区，逃避安全防护。</li></ul><p>这些问题不仅给企业的网络安全带来巨大威胁，还可能对企业的声誉、财务安全和合规性造成长期影响。因此，跨境业务需要借助有效的IP风险情报服务，提前识别并应对这些潜在的安全威胁。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdnVDq" alt="如何利用IP风险情报保障跨境业务的网络安全" title="如何利用IP风险情报保障跨境业务的网络安全"/></p><h2>二、IP风险情报如何帮助识别恶意IP、代理和VPN</h2><p>IP风险情报是通过对IP地址及其相关数据进行分析，从而识别和预测可能的网络安全威胁。它能够提供以下几个重要功能：</p><h3>1. 恶意IP识别：</h3><p>IP风险情报服务通过对全球范围内的IP地址进行实时监控和更新，识别出被标记为恶意的IP地址。这些IP地址可能与网络攻击、数据泄露或欺诈活动相关联。通过对恶意IP的实时警报，跨境业务能够有效阻止攻击的发生。</p><h3>2. 代理和VPN检测：</h3><p>攻击者往往使用代理或VPN来隐藏真实IP地址，从而规避安全系统的检测。IP风险情报服务可以通过IP地址的特殊模式、历史数据和地理位置信息，识别是否存在代理或VPN的使用，帮助企业判断其是否为合法用户。</p><h3>3. IP信誉评分：</h3><p>每个IP地址都有一个信誉评分，反映其历史行为和安全性。通过对这些评分的分析，企业能够判断某个IP是否属于高风险区域。对那些信誉较低的IP进行封锁或限制访问，可以有效减少安全隐患。</p><h3>4. 地区性风险分析：</h3><p>在跨境业务中，某些地区可能会存在较高的网络攻击频率和欺诈风险。通过IP风险情报服务，企业能够对不同地区的IP进行风险分析，制定更为精准的防护策略。</p><h2>三、实际案例：IP风险情报在跨境电商中的应用</h2><p>某跨境电商公司在拓展国际市场的过程中，发现其网站常常遭遇恶意流量攻击，尤其是来自某些特定国家和地区的IP地址。为了保障网络安全，该公司决定引入IP风险情报服务，并根据以下几个步骤进行了安全优化：</p><h3>1. 识别恶意流量：</h3><p>通过IP风险情报，该公司能够实时识别来自恶意IP的流量，并快速阻止其进入系统。这些恶意IP通常与DDoS攻击、数据盗窃和账户滥用等行为有关。</p><h3>2. 代理与VPN检测：</h3><p>在进行订单处理和用户身份验证时，IP风险情报帮助该公司识别了大量使用VPN的IP地址，许多伪装成来自合法地区的攻击者被成功识别并封锁。</p><h3>3. 风险评分优化：</h3><p>利用IP信誉评分，企业能够有效评估每个IP的安全性，并采取相应的防护措施。例如，对于来自高风险国家的IP地址，增加了多重身份验证措施，减少了欺诈行为。</p><p>通过这些措施，该电商公司成功降低了欺诈风险，提升了交易安全性，也有效保障了客户的个人信息和资金安全。</p><h2>四、如何选择适合的IP风险情报服务</h2><p>在选择IP风险情报服务时，企业需要考虑以下几个因素：</p><ul><li>数据的实时性和准确性：选择能够提供实时更新和精准数据的IP情报服务，确保及时发现新的风险IP。</li><li>全球范围的IP覆盖：跨境业务往往涉及多个国家和地区，因此选择一个全球覆盖广泛的IP风险情报服务至关重要。</li><li>代理和VPN识别能力：确保所选择的IP情报服务具备强大的代理和VPN检测能力，避免潜在的伪装攻击。</li><li>API接口与集成能力：为确保IP情报服务能与现有的安全系统和业务流程无缝对接，选择提供易于集成的API接口的服务。</li></ul><p>例如，<a href="https://link.segmentfault.com/?enc=Mps8WLL3Teyax6FoFgqGrg%3D%3D.ftS%2Birh0Y1vZt1vWbI0biM7dB5%2FYwfsao5HgnvSPiBw%3D" rel="nofollow" target="_blank"><strong>IP数据云</strong></a>提供全球范围内的IP地址风险情报服务，能够识别各类恶意IP、代理和VPN，并提供精准的IP信誉评分，帮助跨境企业加强网络安全防护。</p><h2>五、总结</h2><p>随着跨境业务的不断扩展，网络安全已成为企业面临的重要挑战。通过有效利用IP风险情报，企业可以实时识别恶意IP、代理和VPN，保护自身免受网络攻击和数据泄露等风险。IP数据云等专业的IP情报服务，不仅能提升跨境业务的安全性，还能帮助企业优化全球运营策略，减少网络威胁对业务的影响。因此，选择一个可靠的IP风险情报服务，并将其应用于日常的安全防护中，已成为跨境企业保障网络安全的必然之举。</p>]]></description></item><item>    <title><![CDATA[从零开发HarmonyOS 6.0 天气应用（ArkTS版） 逐梦AI ]]></title>    <link>https://segmentfault.com/a/1190000047609758</link>    <guid>https://segmentfault.com/a/1190000047609758</guid>    <pubDate>2026-02-13 14:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>从零开发HarmonyOS 6.0 天气应用（ArkTS版）</h2><p>你需要一篇基于HarmonyOS 6.0和ArkTS语言的其他应用开发教程，这篇文章会带你从零构建一个功能完整的天气应用，涵盖网络请求、数据解析、UI适配、状态管理等核心知识点，适合有基础ArkTS认知的开发者学习实践。</p><h3>一、应用核心功能</h3><p>本次开发的天气应用包含以下核心能力：</p><ol><li>基于和风天气API获取实时天气数据（温度、天气状况、风力、湿度）</li><li>展示今日天气概览和未来3天预报</li><li>支持手动输入城市查询天气</li><li>适配不同屏幕尺寸，优化视觉体验</li></ol><h3>二、开发前准备</h3><h4>2.1 环境要求</h4><ul><li>DevEco Studio 4.1+</li><li>HarmonyOS SDK 6.0 (API 12)</li><li>基础网络权限配置</li><li>和风天气API Key</li></ul><h4>2.2 权限配置</h4><p>在<code>module.json5</code>中添加网络访问权限：</p><pre><code class="json">{
  "module": {
    "requestPermissions": [
      {
        "name": "ohos.permission.INTERNET"
      }
    ]
  }
}</code></pre><h3>三、核心代码实现</h3><h4>3.1 数据模型定义</h4><p>创建<code>model/WeatherModel.ets</code>，定义天气数据结构：</p><pre><code class="typescript">/**
 * 实时天气数据模型
 */
export interface RealTimeWeather {
  temp: string; // 温度
  text: string; // 天气状况（晴/雨/多云）
  windDir: string; // 风向
  windScale: string; // 风力等级
  humidity: string; // 湿度
  updateTime: string; // 更新时间
}

/**
 * 未来预报数据模型
 */
export interface DailyForecast {
  fxDate: string; // 日期
  tempMax: string; // 最高温
  tempMin: string; // 最低温
  textDay: string; // 白天天气状况
}

/**
 * 天气响应体模型
 */
export interface WeatherResponse {
  realTime: RealTimeWeather;
  dailyForecasts: DailyForecast[];
}</code></pre><h4>3.2 网络请求工具类</h4><p>创建<code>utils/HttpUtil.ets</code>，封装网络请求方法：</p><pre><code class="typescript">/**
 * 网络请求工具类
 * @param url 请求地址
 * @returns 响应数据
 */
export async function request&lt;T&gt;(url: string): Promise&lt;T&gt; {
  try {
    const response = await fetch.fetch(url);
    if (response.responseCode !== 200) {
      throw new Error(`请求失败，状态码：${response.responseCode}`);
    }
    const result = await response.text();
    return JSON.parse(result) as T;
  } catch (error) {
    console.error('网络请求异常：', error);
    throw error;
  }
}</code></pre><h4>3.3 天气服务类</h4><p>创建<code>service/WeatherService.ets</code>，封装API调用逻辑（替换<code>YOUR_API_KEY</code>为你的真实Key）：</p><pre><code class="typescript">import { request } from '../utils/HttpUtil';
import { RealTimeWeather, DailyForecast } from '../model/WeatherModel';

// 和风天气API配置
const API_KEY = 'YOUR_API_KEY';
const BASE_URL = 'https://devapi.qweather.com/v7';

/**
 * 根据城市获取天气数据
 * @param city 城市名称
 */
export async function getWeatherByCity(city: string): Promise&lt;{
  realTime: RealTimeWeather,
  dailyForecasts: DailyForecast[]
}&gt; {
  // 1. 获取城市Location ID
  const locationUrl = `${BASE_URL}/location/search?key=${API_KEY}&amp;location=${city}`;
  const locationRes: any = await request(locationUrl);
  
  if (!locationRes.location || locationRes.location.length === 0) {
    throw new Error('未找到该城市的天气数据');
  }
  
  const locationId = locationRes.location[0].id;
  
  // 2. 获取实时天气
  const realTimeUrl = `${BASE_URL}/weather/now?key=${API_KEY}&amp;location=${locationId}`;
  const realTimeRes: any = await request(realTimeUrl);
  const realTime: RealTimeWeather = {
    temp: realTimeRes.now.temp,
    text: realTimeRes.now.text,
    windDir: realTimeRes.now.windDir,
    windScale: realTimeRes.now.windScale,
    humidity: realTimeRes.now.humidity,
    updateTime: realTimeRes.updateTime
  };
  
  // 3. 获取未来3天预报
  const dailyUrl = `${BASE_URL}/weather/3d?key=${API_KEY}&amp;location=${locationId}`;
  const dailyRes: any = await request(dailyUrl);
  const dailyForecasts: DailyForecast[] = dailyRes.daily.map((item: any) =&gt; ({
    fxDate: item.fxDate,
    tempMax: item.tempMax,
    tempMin: item.tempMin,
    textDay: item.textDay
  }));
  
  return { realTime, dailyForecasts };
}</code></pre><h4>3.4 主页面实现</h4><p>修改<code>pages/Index.ets</code>，实现天气查询和展示核心逻辑：</p><pre><code class="typescript">@Entry
@Component
struct WeatherPage {
  // 状态管理
  @State private cityName: string = '北京'; // 默认查询北京
  @State private inputCity: string = '';
  @State private realTimeWeather: RealTimeWeather | null = null;
  @State private dailyForecasts: DailyForecast[] = [];
  @State private isLoading: boolean = false;
  @State private errorMsg: string = '';

  // 页面加载时初始化数据
  aboutToAppear() {
    this.fetchWeatherData(this.cityName);
  }

  build() {
    Column() {
      // 标题区域
      Text('鸿蒙天气')
        .fontSize(28)
        .fontWeight(FontWeight.Bold)
        .margin({ top: 20, bottom: 15 })
        .alignSelf(ItemAlign.Center);

      // 城市查询区域
      Row({ space: 10 }) {
        TextField(this.inputCity, (value: string) =&gt; {
          this.inputCity = value;
        })
          .placeholder('请输入城市名称...')
          .width('70%')
          .height(45)
          .border({ width: 1, radius: 8, color: '#E5E5E5' })
          .padding({ left: 10 });

        Button('查询')
          .width('20%')
          .height(45)
          .backgroundColor('#007DFF')
          .fontColor(Color.White)
          .borderRadius(8)
          .onClick(() =&gt; {
            if (this.inputCity.trim()) {
              this.fetchWeatherData(this.inputCity.trim());
            }
          });
      }
      .margin({ bottom: 20 })
      .padding({ left: 15, right: 15 });

      // 加载状态提示
      if (this.isLoading) {
        LoadingProgress()
          .width(40)
          .height(40)
          .margin({ bottom: 20 })
          .alignSelf(ItemAlign.Center);
      }

      // 错误提示
      if (this.errorMsg) {
        Text(this.errorMsg)
          .fontSize(14)
          .fontColor('#FF4D4F')
          .margin({ bottom: 20 })
          .alignSelf(ItemAlign.Center);
      }

      // 实时天气展示
      if (this.realTimeWeather) {
        Column() {
          Text(`${this.cityName} 实时天气`)
            .fontSize(20)
            .fontWeight(FontWeight.Medium)
            .margin({ bottom: 10 });

          Row({ space: 20 }) {
            Text(`${this.realTimeWeather.temp}°C`)
              .fontSize(48)
              .fontWeight(FontWeight.Bold);

            Column() {
              Text(this.realTimeWeather.text)
                .fontSize(18)
                .margin({ bottom: 5 });
              Text(`更新时间：${this.formatTime(this.realTimeWeather.updateTime)}`)
                .fontSize(12)
                .fontColor('#999');
            }
          }
          .margin({ bottom: 15 });

          // 天气详情
          Grid() {
            GridItem() {
              this.buildWeatherInfoItem('风向', `${this.realTimeWeather.windDir}`);
            }
            GridItem() {
              this.buildWeatherInfoItem('风力', `${this.realTimeWeather.windScale}级`);
            }
            GridItem() {
              this.buildWeatherInfoItem('湿度', `${this.realTimeWeather.humidity}%`);
            }
          }
          .columnsTemplate('1fr 1fr 1fr')
          .width('90%')
          .margin({ bottom: 30 });
        }
        .padding(20)
        .backgroundColor(Color.White)
        .borderRadius(12)
        .shadow({ radius: 4, color: '#00000010', offsetX: 0, offsetY: 2 })
        .width('90%')
        .alignSelf(ItemAlign.Center);
      }

      // 未来预报展示
      if (this.dailyForecasts.length &gt; 0) {
        Text('未来3天预报')
          .fontSize(18)
          .fontWeight(FontWeight.Medium)
          .margin({ bottom: 10, top: 20 })
          .alignSelf(ItemAlign.Start)
          .padding({ left: 15 });

        List({ space: 10 }) {
          ForEach(this.dailyForecasts, (item: DailyForecast) =&gt; {
            ListItem() {
              Row({ space: 10 }) {
                Text(item.fxDate)
                  .width(80)
                  .fontSize(14);
                Text(item.textDay)
                  .width(60)
                  .fontSize(14);
                Text(`↑${item.tempMax}°C`)
                  .width(50)
                  .fontSize(14)
                  .fontColor('#FF4D4F');
                Text(`↓${item.tempMin}°C`)
                  .width(50)
                  .fontSize(14)
                  .fontColor('#007DFF');
              }
              .padding(15)
              .backgroundColor(Color.White)
              .borderRadius(8)
              .width('100%');
            }
          })
        }
        .padding({ left: 15, right: 15 })
        .width('100%');
      }
    }
    .width('100%')
    .height('100%')
    .backgroundColor('#F8F8F8');
  }

  /**
   * 构建天气信息子项
   */
  @Builder
  private buildWeatherInfoItem(title: string, value: string) {
    Column() {
      Text(title)
        .fontSize(14)
        .fontColor('#999')
        .margin({ bottom: 5 });
      Text(value)
        .fontSize(16)
        .fontWeight(FontWeight.Medium);
    }
    .alignItems(ItemAlign.Center);
  }

  /**
   * 格式化时间
   */
  private formatTime(timeStr: string): string {
    return timeStr.replace('T', ' ').substring(0, 16);
  }

  /**
   * 获取天气数据
   */
  private async fetchWeatherData(city: string) {
    this.isLoading = true;
    this.errorMsg = '';
    try {
      const weatherData = await getWeatherByCity(city);
      this.cityName = city;
      this.realTimeWeather = weatherData.realTime;
      this.dailyForecasts = weatherData.dailyForecasts;
    } catch (error: any) {
      this.errorMsg = error.message || '获取天气数据失败，请重试';
      console.error('获取天气失败：', error);
    } finally {
      this.isLoading = false;
    }
  }
}

// 导入依赖
import { RealTimeWeather, DailyForecast } from '../model/WeatherModel';
import { getWeatherByCity } from '../service/WeatherService';
import prompt from '@ohos.promptAction';</code></pre><h3>四、核心代码解释</h3><h4>4.1 网络请求封装</h4><ul><li><code>HttpUtil.ets</code>封装了通用的<code>fetch</code>请求方法，处理了状态码校验和异常捕获，简化后续API调用逻辑；</li><li>所有网络请求使用<code>async/await</code>异步语法，避免回调地狱，代码更易读。</li></ul><h4>4.2 状态管理</h4><ul><li>使用<code>@State</code>装饰器管理核心数据（实时天气、预报数据、加载状态、错误信息），状态变化自动触发UI刷新；</li><li><code>aboutToAppear</code>生命周期钩子实现页面初始化时自动加载默认城市（北京）的天气数据。</li></ul><h4>4.3 UI设计</h4><ul><li>采用“卡片式”设计风格，通过<code>backgroundColor</code>、<code>borderRadius</code>、<code>shadow</code>实现拟物效果；</li><li>使用<code>Grid</code>和<code>List</code>组件实现数据的规整展示，适配不同屏幕宽度；</li><li>增加加载中（<code>LoadingProgress</code>）和错误提示状态，提升用户体验。</li></ul><h4>4.4 数据处理</h4><ul><li>对和风天气API返回的原始数据进行结构化解析，映射到自定义数据模型，降低耦合；</li><li>时间格式化方法<code>formatTime</code>处理API返回的ISO格式时间，提升可读性。</li></ul><h3>五、运行与调试</h3><ol><li>替换<code>WeatherService.ets</code>中的<code>API_KEY</code>为你从和风天气官网获取的真实Key；</li><li>启动HarmonyOS 6.0模拟器或连接真机；</li><li>运行应用，默认展示北京天气，输入其他城市（如上海、广州）可查询对应天气数据。</li></ol><h3>六、功能扩展建议</h3><ol><li><strong>定位功能</strong>：集成HarmonyOS定位API，自动获取当前城市天气；</li><li><strong>缓存优化</strong>：使用<code>@ohos.data.preferences</code>缓存已查询城市的天气数据，减少网络请求；</li><li><strong>主题切换</strong>：支持浅色/深色模式，适配系统主题；</li><li><strong>更多数据展示</strong>：添加空气质量、日出日落、紫外线指数等信息；</li><li><strong>动画效果</strong>：为天气卡片添加加载动画、数据刷新过渡动画。</li></ol><h4>总结</h4><ol><li>本次天气应用基于HarmonyOS 6.0和ArkTS开发，核心实现了<strong>网络请求、数据解析、状态管理、UI组件封装</strong>四大核心能力；</li><li>采用“分层设计”思想（数据模型-工具类-服务类-UI页面），符合鸿蒙应用开发的最佳实践；</li><li>代码包含完整的异常处理、加载状态管理和用户体验优化，可直接作为基础模板扩展更多天气相关功能。</li></ol><p>该天气应用覆盖了ArkTS开发中网络交互、复杂数据渲染、UI组件封装等高频场景，是提升鸿蒙应用开发能力的优质练手项目，你可以基于此代码进一步优化和扩展。</p>]]></description></item><item>    <title><![CDATA[外汇量化开发：为什么实时 API 是短线策略的必备基建？ 我不是股神ber ]]></title>    <link>https://segmentfault.com/a/1190000047609286</link>    <guid>https://segmentfault.com/a/1190000047609286</guid>    <pubDate>2026-02-13 13:02:43</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>做外汇量化策略开发这么久，我一直被一个问题困扰：<strong>为什么回测很稳的策略，一上实盘就容易跟不上行情？</strong><br/>后来慢慢发现，问题往往不是算法不行，而是<strong>数据链路太弱</strong>。<br/>外汇市场 24 小时不间断波动，尤其做短线、波段、震荡策略时，对数据实时性要求极高。以前我也用过爬虫、手动刷新网页、Excel 同步等方式，不仅效率极低，还经常漏数据、错格式，真正想抓住关键波动时，机会早就没了。</p><p><strong>一、传统数据方式，到底坑在哪？</strong><br/>只要你做过外汇程序开发，基本都会遇到这三个共性痛点：</p><ul><li>延迟不可控<br/>网页刷新、第三方数据更新都有固定间隔，几分钟的延迟，在快节奏行情里就是致命差距。</li><li>格式乱七八糟<br/>不同平台数据结构不统一，解析、清洗、对齐要花大量时间，还容易出 Bug。</li><li>很难接入自动化系统<br/>没有标准接口，数据没法直接喂给策略、回测框架、监控面板，自动化基本是空谈。<br/>这些问题不解决，策略再漂亮也跑不起来。</li></ul><p><strong>二、稳定的外汇 API，究竟解决了什么？</strong><br/>对量化开发者来说，<strong>实时汇率 API 不是锦上添花，而是底层基建</strong>。<br/>它能提供低延迟、连续推送、格式统一的行情数据，拿来就能直接在代码里使用，不用再做多余处理。<br/>我在实际项目里会用 <strong>AllTick API</strong> 来订阅主流货币对实时行情，接入简单、稳定性也够用。</p><pre><code>import websocket
import json

url = "wss://realtime.alltick.co/forex?symbols=USDCNY"

def on_message(ws, message):
    data = json.loads(message)
    print(f"USD/CNY 当前汇率: {data['price']} 时间: {data['time']}")

def on_error(ws, error):
    print(f"连接错误: {error}")

def on_close(ws):
    print("连接已关闭")

def on_open(ws):
    print("实时数据连接成功，开始接收数据...")

ws = websocket.WebSocketApp(url,
                            on_message=on_message,
                            on_error=on_error,
                            on_close=on_close)
ws.on_open = on_open
ws.run_forever()
</code></pre><p>像这样通过 WebSocket 订阅后，数据可以直接进入你的逻辑：分析、计算、可视化、触发信号都没问题。<br/>对比手动爬取、表格整理，效率提升是数量级的。</p><p><strong>三、实战开发中，这些细节直接影响效果</strong><br/>在长期写策略、接数据的过程中，我总结了几个非常实用的关键点：</p><ul><li>合理设置波动阈值<br/>网络抖动、微小波动很常见，不要对每一次价格变动都响应，设置阈值能大幅减少无效计算。</li><li>按需订阅货币对<br/>一次性订阅太多品种会增加程序压力，只选策略真正用到的就行。</li><li>精简数据存储<br/>实时数据量巨大，只存价格、时间戳、货币对这些关键字段，能显著降低数据库压力。<br/>把实时数据 + 历史数据结合，还能做回测、预警、自定义看板，比单纯看 K 线更贴近真实市场。</li></ul><p><strong>四、对量化策略与自动化的真实价值</strong><br/>API 解决的不只是 “看行情”，而是让策略从理论变成可运行的系统。<br/>有了稳定实时数据，你可以：</p><ul><li>实时监控汇率，突破 / 跌破自动报警</li><li>记录关键支撑阻力位</li><li>快速验证轻量级量化策略</li><li>实现半自动甚至全自动交易逻辑<br/>没有实时数据入口，再好的策略也只能停留在回测阶段。<br/>把数据层交给稳定接口，我们才能真正专注在策略逻辑、风控和算法优化上。</li></ul><p>五、给开发者的实用建议<br/>如果你也在做外汇相关开发，这几点可以直接参考：</p><ul><li>先明确自己的策略覆盖范围，不要盲目全量订阅</li><li>实时数据最好配合持久化或可视化，分析效率更高</li><li>优先选择低延迟、格式标准、长期稳定的接口，减少后期重构</li></ul><p>一句话总结：<br/>在外汇量化开发里，<strong>稳定的实时 API = 策略落地的基础效率底座</strong>，它能让你在快速波动的市场里，更稳、更准地抓住真正有价值的机会。</p><p><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdnVvQ" alt="" title=""/></p>]]></description></item><item>    <title><![CDATA[2026年11款国内外主流CRM核心能力横向深度评测 率性的开水瓶 ]]></title>    <link>https://segmentfault.com/a/1190000047609290</link>    <guid>https://segmentfault.com/a/1190000047609290</guid>    <pubDate>2026-02-13 13:02:11</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>引言</h2><p>在数字化转型浪潮中，CRM（客户关系管理）系统已成为企业打通销售全链路、提升客户运营效率的核心工具。本次评测选取11款国内外主流CRM产品，围绕<strong>客户管理、SFA（</strong> <strong>销售自动化</strong> <strong>）、团队协同、统计分析、自定义能力</strong>五大核心维度展开深度横向对比，为不同规模、不同业务场景的企业选型提供专业参考。</p><p>评测对象包括：超兔一体云、Pipedrive、Nimble、Insightly、Streak、Infor CRM、Zendesk Sell、快启CRM、金现代CRM、管家婆、飞书CRM。</p><ul><li><ul><li>*</li></ul></li></ul><h2>一、客户管理：从线索到复购的全生命周期闭环</h2><h3>核心价值</h3><p>客户管理的核心是实现线索-客户-成交-复购的全流程可控，通过精准画像、数据查重和权限隔离提升客户运营效率与数据安全性。</p><h3>关键能力横向对比</h3><table><thead><tr><th>品牌</th><th>全生命周期覆盖</th><th>客户画像能力</th><th>查重机制</th><th>数据权限管理</th><th>特色功能</th></tr></thead><tbody><tr><td>超兔一体云</td><td>全流程覆盖</td><td>工商补全/社交头像/经纬度标记</td><td>多字段查重/模糊简称查重/自定义</td><td>角色分级/财务数据隔离</td><td>自动标记工商地址经纬度、微信支付宝头像获取</td></tr><tr><td>Pipedrive</td><td>全流程覆盖</td><td>可定制字段/移动端同步</td><td>基础字段查重</td><td>角色级权限</td><td>移动端实时数据同步</td></tr><tr><td>Nimble</td><td>全流程覆盖</td><td>社交数据自动更新</td><td>基础字段查重</td><td>团队级权限</td><td>Twitter/LinkedIn数据整合</td></tr><tr><td>Infor CRM</td><td>全流程覆盖</td><td>行业化客户细分</td><td>行业适配查重</td><td>角色+部门权限</td><td>汽车/零售垂直行业客户管理模板</td></tr><tr><td>快启CRM</td><td>全流程覆盖</td><td>基础画像/分类管理</td><td>基础字段查重/公海规则关联</td><td>角色分级/签约客户分库</td><td>智能公海推荐、来电弹屏</td></tr><tr><td>金现代CRM</td><td>全流程覆盖</td><td>360°视图/流失预警</td><td>基础字段查重</td><td>角色分级/跨部门权限</td><td>AI客户画像、智慧商城联动</td></tr></tbody></table><h3>典型流程可视化（超兔一体云）</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609292" alt="" title=""/></p><pre><code>flowchart LR
    A[多渠道集客&lt;br&gt;百度/抖音/官网/微信/工商搜客] --&gt; B[线索一键处理&lt;br&gt;新客户/老客户待办/订单]
    B --&gt; C[客池分类&lt;br&gt;需求培养/有需求/上首屏/目标/成功]
    C --&gt; D[客户画像与背景调查&lt;br&gt;工商补全/天眼查/微信头像]
    D --&gt; E[客户维护&lt;br&gt;跟单/订单/财务记录]
    E --&gt; F[客户复购/流失预警]
    style A fill:#f9f,stroke:#333,stroke-width:2px
    style F fill:#9f9,stroke:#333,stroke-width:2px</code></pre><h2>二、SFA（销售自动化）：适配多场景的跟单效率引擎</h2><h3>核心价值</h3><p>SFA通过标准化跟单模型、自动化任务触发和订单财务管控，降低销售手动操作成本，提升成单转化率。</p><h3>关键能力横向对比</h3><table><thead><tr><th>品牌</th><th>跟单模型数量</th><th>自动化场景</th><th>订单/财务管控</th><th>特色功能</th></tr></thead><tbody><tr><td>超兔一体云</td><td>3种（三一客/商机/多方项目）</td><td>待办提醒/订单锁库/采购计划生成</td><td>应收三角联动/账期信用管理</td><td>三一客小单快单模型、多方项目全周期管控</td></tr><tr><td>Pipedrive</td><td>1种（通用）</td><td>任务提醒/AI销售助理/互动追踪</td><td>交易阶段预测</td><td>AI销售助理、交易进度预测</td></tr><tr><td>Zendesk Sell</td><td>1种（通用）</td><td>邮件序列/自动拨号</td><td>基础订单跟踪</td><td>批量个性化邮件模板、原生拨号功能</td></tr><tr><td>金现代CRM</td><td>1种（通用）</td><td>跟进任务触发/AI开单</td><td>库存价格实时同步</td><td>语音/图片AI开单、智能漏斗分析</td></tr><tr><td>快启CRM</td><td>1种（通用）</td><td>跟进任务触发/日程同步</td><td>基础订单跟踪</td><td>可视化销售漏斗、跟单转日程</td></tr></tbody></table><h3>特色模型可视化（超兔三一客小单快单）</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609293" alt="" title="" loading="lazy"/></p><pre><code>mindmap
    root((超兔三一客小单快单模型))
        三定规则
            定性&lt;br&gt;判断客户需求真假
            定级&lt;br&gt;评估客户购买力等级
            定量&lt;br&gt;明确成单时间与金额
        关键节点推进
            首次触达&lt;br&gt;需求确认
            方案发送&lt;br&gt;异议处理
            报价跟进&lt;br&gt;逼单成交
        效率提升
            一键生成待办
            自动同步跟单时间线
            数据自动汇总报表</code></pre><h2>三、团队协同：跨角色跨链路的信息协同网络</h2><h3>核心价值</h3><p>通过角色权限隔离、跨部门工单流转和供应链协同，打破信息孤岛，实现销售、财务、采购、客户的全链路协同。</p><h3>关键能力横向对比</h3><table><thead><tr><th>品牌</th><th>角色权限管理</th><th>跨部门协同能力</th><th>供应链协同能力</th><th>特色功能</th></tr></thead><tbody><tr><td>超兔一体云</td><td>双重指挥系统/角色分级</td><td>跨岗位数据隔离/待办同步</td><td>OpenCRM平台全流程协同</td><td>华为式行政+业务双重指挥系统、上下游对账</td></tr><tr><td>飞书CRM</td><td>飞书原生角色权限</td><td>飞书会议/文档/即时通讯联动</td><td>无原生供应链协同</td><td>依托飞书生态全场景协同</td></tr><tr><td>Infor CRM</td><td>角色+部门权限</td><td>跨系统数据同步</td><td>Infor SCM套件联动</td><td>制造业零部件采购进度同步</td></tr><tr><td>金现代CRM</td><td>飞书原生角色权限</td><td>工单流转/SLA管理</td><td>无原生供应链协同</td><td>飞书即时沟通+工单流转闭环</td></tr><tr><td>快启CRM</td><td>角色分级管理</td><td>跨部门短消息沟通</td><td>无原生供应链协同</td><td>异常操作实时提醒、项目考核闭环</td></tr></tbody></table><h3>供应链协同可视化（超兔一体云）</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609294" alt="" title="" loading="lazy"/></p><pre><code>flowchart TD
    subgraph 企业内部系统
        A[超兔一体云CRM] --&gt; B[订单管理]
        A --&gt; C[采购管理]
        A --&gt; D[财务管理]
    end
    subgraph 上游供应商
        B --&gt; E[询价响应]
        C --&gt; F[采购执行&lt;br&gt;发货/物流]
        D --&gt; G[付款发票/对账]
        E &amp; F &amp; G --&gt; H[供应商评分]
    end
    subgraph 下游客户
        B --&gt; I[报价确认/订单确认]
        B --&gt; J[物流订阅/收货确认]
        D --&gt; K[款项发票/投诉处理]
        I &amp; J &amp; K --&gt; L[客户满意度反馈]
    end
    H --&gt; A
    L --&gt; A</code></pre><ul><li><ul><li>*</li></ul></li></ul><h2>四、统计分析：数据驱动的决策支撑体系</h2><h3>核心价值</h3><p>通过多维度数据聚合、可视化报表和AI预测，为企业提供销售效能、库存管理、财务状况的全景洞察。</p><h3>关键能力横向对比</h3><table><thead><tr><th>品牌</th><th>分析引擎类型</th><th>数据覆盖维度</th><th>可视化能力</th><th>特色功能</th></tr></thead><tbody><tr><td>超兔一体云</td><td>多表聚合/同比环比引擎</td><td>销售/财务/库存/客户全维度</td><td>自定义大屏/驾驶舱</td><td>单日KPI引擎、复杂多表关联BI分析</td></tr><tr><td>Pipedrive</td><td>AI预测分析引擎</td><td>销售全维度</td><td>销售漏斗可视化</td><td>AI驱动交易预测、实时销售报告</td></tr><tr><td>金现代CRM</td><td>对话式BI引擎</td><td>销售/财务/库存/服务多维度</td><td>多维可视化报表</td><td>AI对话生成报表、经营预警</td></tr><tr><td>快启CRM</td><td>效能分析引擎</td><td>销售过程/结果/人员维度</td><td>效能报表可视化</td><td>薪酬激励体系支撑报表</td></tr><tr><td>Infor CRM</td><td>行业化分析引擎</td><td>销售/供应链维度</td><td>行业化报表</td><td>汽车/零售行业定制报表</td></tr></tbody></table><h2>五、自定义能力：适配企业个性化需求的柔性框架</h2><h3>核心价值</h3><p>通过按需订阅、自定义配置和低代码开发，让CRM系统快速适配企业独特业务流程，降低落地成本。</p><h3>关键能力横向对比</h3><table><thead><tr><th>品牌</th><th>功能订阅模式</th><th>菜单/工作台自定义</th><th>业务表/工作流自定义</th><th>特色功能</th></tr></thead><tbody><tr><td>超兔一体云</td><td>功能白名单按需订阅</td><td>三级菜单/多岗位驾驶舱</td><td>自定义业务表/复合工作流</td><td>自定义多表聚合BI分析</td></tr><tr><td>飞书CRM</td><td>生态内按需开通</td><td>飞书工作台自定义</td><td>低代码Apaas定制</td><td>基于飞书应用引擎深度定制</td></tr><tr><td>金现代CRM</td><td>模块按需订阅</td><td>角色专属工作台</td><td>低代码平台全流程定制</td><td>20+行业模板适配</td></tr><tr><td>快启CRM</td><td>模块按需订阅</td><td>基础菜单自定义</td><td>低代码字段/报表定制</td><td>跟进字段/效能报表个性化配置</td></tr><tr><td>Infor CRM</td><td>行业套件订阅</td><td>行业模板固定菜单</td><td>行业化工作流定制</td><td>垂直行业智能补货系统定制</td></tr></tbody></table><h2>六、综合能力雷达图与选型推荐</h2><h3>综合能力评分（满分100）</h3><table><thead><tr><th>品牌</th><th>客户管理</th><th>SFA</th><th>团队协同</th><th>统计分析</th><th>自定义能力</th><th>综合得分</th></tr></thead><tbody><tr><td>超兔一体云</td><td>90</td><td>92</td><td>88</td><td>89</td><td>91</td><td>90</td></tr><tr><td>Pipedrive</td><td>85</td><td>88</td><td>82</td><td>86</td><td>84</td><td>85</td></tr><tr><td>Nimble</td><td>82</td><td>78</td><td>80</td><td>75</td><td>76</td><td>78</td></tr><tr><td>Insightly</td><td>83</td><td>81</td><td>84</td><td>80</td><td>82</td><td>82</td></tr><tr><td>Streak</td><td>75</td><td>72</td><td>70</td><td>68</td><td>70</td><td>71</td></tr><tr><td>Infor CRM</td><td>88</td><td>85</td><td>86</td><td>83</td><td>79</td><td>84</td></tr><tr><td>Zendesk Sell</td><td>80</td><td>83</td><td>78</td><td>77</td><td>75</td><td>79</td></tr><tr><td>快启CRM</td><td>86</td><td>84</td><td>81</td><td>85</td><td>87</td><td>85</td></tr><tr><td>金现代CRM</td><td>87</td><td>86</td><td>85</td><td>88</td><td>89</td><td>87</td></tr><tr><td>管家婆</td><td>84</td><td>82</td><td>83</td><td>82</td><td>80</td><td>82</td></tr><tr><td>飞书CRM</td><td>81</td><td>79</td><td>90</td><td>84</td><td>88</td><td>84</td></tr></tbody></table><h3>选型推荐</h3><ol><li><strong>全流程一体化需求</strong>：超兔一体云，优势是全业务打通、多场景跟单模型、供应链协同、高自定义能力，适合中小微企业低成本实现数字化转型。</li><li><strong>国际业务</strong> <strong>销售自动化</strong>：Pipedrive，优势是AI销售助理、交易进度预测、移动端实时同步，适合有海外业务的企业。</li><li><strong>社交获客导向</strong>：Nimble，优势是社交数据自动整合、客户社交画像，适合依赖社交媒体获客的企业。</li><li><strong>中大型垂直行业</strong>：Infor CRM，优势是行业化模板、SCM套件联动，适合汽车、零售等垂直领域的中大型企业。</li><li><strong>飞书</strong> <strong>生态深度用户</strong>：飞书CRM，优势是原生即时沟通、会议、文档协同，适合已落地飞书办公系统的企业。</li><li><strong>本土</strong> <strong>低代码</strong> <strong>高定制</strong>：金现代CRM/快启CRM，优势是低代码平台、对话式BI、行业适配，适合需要高度定制化的本土企业。</li></ol><h2>结语</h2><p>本次评测显示，不同CRM系统的核心能力差异显著：国际品牌侧重通用销售自动化，本土品牌更贴合国内企业的全流程协同与低代码定制需求，而超兔一体云凭借全业务打通的一体云架构、多场景跟单模型和高自定义能力，在中小微企业CRM选型中具备明显优势。企业需根据自身业务规模、行业属性和数字化阶段，选择最适配的CRM系统。</p>]]></description></item><item>    <title><![CDATA[基于 Flutter × Harmony6.0 的入侵检测系统：构建检测规则模块 逐梦AI ]]></title>    <link>https://segmentfault.com/a/1190000047609340</link>    <guid>https://segmentfault.com/a/1190000047609340</guid>    <pubDate>2026-02-13 13:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>基于 Flutter × Harmony6.0 的入侵检测系统：构建检测规则模块</h2><h5>前言</h5><p>随着网络安全形势的日益严峻，入侵检测系统（IDS）成为了防御恶意攻击、保障网络安全的重要工具。在移动互联网和物联网的时代背景下，如何设计一个高效的入侵检测系统，并通过跨平台技术在多个设备上进行部署和管理，成为了开发者面临的一个重要问题。本篇技术博客将通过 <strong>Flutter × Harmony6.0</strong> 跨端开发技术，深入解析如何构建一个入侵检测系统，并重点介绍如何实现“检测规则”模块。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047609342" alt="在这里插入图片描述" title="在这里插入图片描述"/></p><h5>背景</h5><p>入侵检测系统主要用于监控计算机系统和网络流量，及时发现潜在的安全威胁并进行报警。随着技术的发展，越来越多的企业和组织开始依赖智能手机和其他移动设备来管理入侵检测系统。因此，如何实现跨平台、统一的用户体验，成为了关键。<strong>Flutter</strong> 和 <strong>Harmony6.0</strong> 技术结合，能够满足这一需求，通过一次开发即可覆盖多个平台（包括安卓、iOS、HarmonyOS等）。</p><h5>Flutter × Harmony6.0 跨端开发介绍</h5><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609343" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><p><strong>Flutter</strong> 是 Google 推出的 UI 框架，它使用 Dart 语言，可以编写原生应用，支持 iOS、Android、Web 以及桌面应用开发。它的一大优势是可以通过一个代码库编译生成多个平台的应用，极大地提高了开发效率。</p><p><strong>HarmonyOS</strong>（鸿蒙操作系统）是华为开发的一款分布式操作系统，支持多设备互联、资源共享。<strong>Harmony6.0</strong> 是其最新版本，具有更高效的多屏协同和跨平台能力。将 <strong>Flutter</strong> 与 <strong>Harmony6.0</strong> 结合使用，可以实现跨平台的无缝连接和高度一致的用户体验。</p><h5>开发核心代码</h5><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609344" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h6>1. 构建监控项</h6><p>在入侵检测系统中，监控项用于显示具体的监控数据，例如网络流量、进程监控等。以下是 Flutter 中构建监控项的代码：</p><pre><code class="dart">/// 构建监控项
/// @param label 标签文本
/// @param value 数值文本
/// @param icon 图标
/// @param color 主题颜色
/// @param theme 主题数据
Widget _buildMonitoringItem(String label, String value, IconData icon, Color color, ThemeData theme) {
  return Row(
    children: [
      Container(
        width: 40,
        height: 40,
        decoration: BoxDecoration(
          color: color.withOpacity(0.1),
          borderRadius: BorderRadius.circular(8),
        ),
        child: Icon(icon, color: color, size: 20),
      ),
      const SizedBox(width: 12),
      Expanded(
        child: Column(
          crossAxisAlignment: CrossAxisAlignment.start,
          children: [
            Text(
              label,
              style: theme.textTheme.bodyMedium?.copyWith(fontWeight: FontWeight.bold),
            ),
            Text(
              '今日检测',
              style: theme.textTheme.bodySmall?.copyWith(
                color: theme.colorScheme.onSurfaceVariant,
              ),
            ),
          ],
        ),
      ),
      Text(
        value,
        style: TextStyle(
          fontSize: 18,
          fontWeight: FontWeight.bold,
          color: color,
        ),
      ),
    ],
  );
}</code></pre><p><strong>解析：</strong></p><ul><li><code>Row</code> 组件用于排列监控项的各个部分，包括图标、标签文本、数值文本等。</li><li><code>Container</code> 用来显示图标，图标颜色使用传入的 <code>color</code> 参数，并通过 <code>withOpacity(0.1)</code> 添加透明度效果。</li><li>使用 <code>Expanded</code> 让标签文本和数值文本能够自适应布局。</li><li>最后，数值文本通过 <code>Text</code> 组件展示，并根据传入的 <code>color</code> 进行样式设置。</li></ul><h6>2. 构建检测规则模块</h6><p>检测规则模块是入侵检测系统的核心部分之一，用于展示各种检测规则及其启用状态。以下是代码实现：</p><pre><code class="dart">/// 构建检测规则模块
/// 显示各种入侵检测规则及其启用状态
Widget _buildDetectionRules(ThemeData theme) {
  return Card(
    elevation: 2,
    shape: RoundedRectangleBorder(borderRadius: BorderRadius.circular(12)),
    child: Padding(
      padding: const EdgeInsets.all(16),
      child: Column(
        crossAxisAlignment: CrossAxisAlignment.start,
        children: [
          Row(
            mainAxisAlignment: MainAxisAlignment.spaceBetween,
            children: [
              Text(
                '检测规则',
                style: theme.textTheme.titleMedium?.copyWith(fontWeight: FontWeight.bold),
              ),
              TextButton.icon(
                onPressed: () {},
                icon: const Icon(Icons.add, size: 16),
                label: const Text('添加', style: TextStyle(fontSize: 12)),
              ),
            ],
          ),
          const SizedBox(height: 16),
          _buildRuleItem('端口扫描检测', '已启用', Colors.green, theme),
          const SizedBox(height: 8),
          _buildRuleItem('暴力破解检测', '已启用', Colors.green, theme),
          const SizedBox(height: 8),
          _buildRuleItem('DDoS攻击检测', '已启用', Colors.green, theme),
          const SizedBox(height: 8),
          _buildRuleItem('SQL注入检测', '已启用', Colors.green, theme),
          const SizedBox(height: 8),
          _buildRuleItem('XSS攻击检测', '已启用', Colors.green, theme),
        ],
      ),
    ),
  );
}</code></pre><p><strong>解析：</strong></p><ul><li><code>Card</code> 组件用于显示规则卡片，卡片设置了圆角和阴影效果。</li><li><code>Row</code> 中的 <code>TextButton.icon</code> 按钮用于添加新的检测规则。</li><li>每条规则通过 <code>_buildRuleItem</code> 展示，传入规则名称、状态以及颜色。使用 <code>SizedBox</code> 来控制每条规则之间的间距。</li></ul><h6>3. 构建检测规则项</h6><p>每个检测规则项通过 <code>_buildRuleItem</code> 方法实现，显示规则的名称、启用状态以及颜色：</p><pre><code class="dart">/// 构建检测规则项
/// 显示单条检测规则
Widget _buildRuleItem(String ruleName, String status, Color color, ThemeData theme) {
  return Row(
    mainAxisAlignment: MainAxisAlignment.spaceBetween,
    children: [
      Text(
        ruleName,
        style: theme.textTheme.bodyLarge?.copyWith(fontWeight: FontWeight.bold),
      ),
      Text(
        status,
        style: TextStyle(color: color, fontWeight: FontWeight.bold),
      ),
    ],
  );
}</code></pre><p><strong>解析：</strong></p><ul><li>使用 <code>Row</code> 展示每个规则的名称和状态。</li><li>状态文本的颜色使用传入的 <code>color</code> 参数，确保与规则的启用状态一致。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047609345" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h5>心得</h5><p>在构建这一入侵检测系统时，借助 <strong>Flutter</strong> 和 <strong>Harmony6.0</strong> 的强大跨平台能力，能够大大简化开发流程。特别是在设计 UI 时，Flutter 提供的组件库能够灵活地适配不同平台的界面要求，同时与 Harmony6.0 的分布式特性结合，保证了系统在多设备上的一致性体验。</p><h5>总结</h5><p>通过本次项目的开发实践，我们实现了一个基于 <strong>Flutter × Harmony6.0</strong> 的入侵检测系统，并重点完成了“检测规则”模块的构建。通过详细的代码解析，可以看到 <strong>Flutter</strong> 在跨平台开发中的优势，以及如何通过简洁的代码实现丰富的功能和界面。这个系统的核心目标是提高网络安全的检测效率，同时通过统一的用户界面让用户能够方便地查看和管理入侵检测规则。</p>]]></description></item><item>    <title><![CDATA[阿里云 EMR Serverless Spark TPC-DS 100T 榜首背后的内核技术 阿里云]]></title>    <link>https://segmentfault.com/a/1190000047609129</link>    <guid>https://segmentfault.com/a/1190000047609129</guid>    <pubDate>2026-02-13 12:09:18</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><strong>演讲者：一锤（周克勇）| EMR Serverless Spark 技术负责人</strong></p><p>2025年9月，阿里云EMR Serverless Spark 以QphDS超6568万分的性能结果成功登顶TPC-DS 100T榜单，这是全球大数据领域最具权威性和挑战性的性能测试基准。<br/><img width="723" height="518" referrerpolicy="no-referrer" src="/img/bVdnVtc" alt="" title=""/><br/>阿里云EMR Serverless Spark TPC-DS 100T 性能测试结果</p><blockquote>TPC-DS Benchmark是数据仓库领域最新和最复杂的权威测试标准，被工业界和学术界广泛认可，也是数据仓库选型的重要参考指标。TPC-DS包含99个查询，从简单的全局聚合到复杂的20以上多表连接，体现了真实分析场景日益增长的复杂度。其中，100T是TPC-DS提供的最大测试数据集，最大表有288,017,344,252（2880亿）条数据，迄今为止只有阿里云EMR和Databricks成功通过了该榜单的官方评审。</blockquote><p>阿里云 EMR Serverless Spark实现了 <strong>性能提升100%</strong>、<strong>性价比提升500%</strong> 的突破，证明了EMR Serverless Spark 在 OpenLake湖仓底座架构下，超大规模、超高复杂度的数据分析、数据更新、数据处理的市场领先能力。<br/><img width="723" height="224" referrerpolicy="no-referrer" src="/img/bVdnVtd" alt="" title="" loading="lazy"/></p><p>本文将深入剖析支撑这一成绩背后的技术内核，从产品定位、架构设计到核心优化策略，全面解读 EMR Serverless Spark 如何实现“高性能、低成本、高弹性、强兼容”的统一。</p><h2>产品定位与核心场景</h2><p>EMR Serverless Spark 定位为新一代 <strong>Lakehouse（湖仓一体）平台</strong>，旨在融合传统数据仓库的极致查询性能与数据湖的低成本、开放性优势。</p><p>其核心聚焦三大场景：</p><ol><li><strong>湖仓分析场景</strong>：以高度优化的 Spark 替代 Hive 执行 ETL/ELT 任务，替代 Trino/Presto 提供高性价比交互式分析。支持 SQL、DataFrame、Pandas、RDD 等多种接口，并全面兼容 Paimon、Iceberg、Delta、Hudi 等主流湖表格式。</li><li><strong>机器学习场景</strong>：作为成熟的分布式 ML 框架，Spark 支持从数据清洗、特征工程到模型训练与批量推理的全流程。内置 MLlib，集成 XGBoost、LightGBM、scikit-learn 等生态工具，并提供 GPU 加速能力，实现 Data + AI 一体化。</li><li><strong>多模态数据处理场景</strong>：随着大模型兴起，PySpark 成为处理文本、图像、视频等非结构化数据的理想选择。产品推出的 <strong>AI Function</strong> 功能，允许用户在 Spark 作业中直接调用大模型。针对基模训练数据预处理做了专门优化，在文本去重任务中实现 <strong>5倍性能提升</strong>。<br/><img width="723" height="392" referrerpolicy="no-referrer" src="/img/bVdnVte" alt="" title="" loading="lazy"/></li></ol><h2>产品架构与极致弹性</h2><p>EMR Serverless Spark 采用标准 Lakehouse 架构：</p><ul><li><strong>存储层</strong>：基于阿里云 OSS 对象存储与 OSS-HDFS 接口，提供高吞吐、低成本的持久化能力；</li><li><strong>元数据层</strong>：兼容 Hive Metastore（HMS）与 Data Lake Formation（DLF），支持 ACID 事务；</li><li><strong>资源层</strong>：依托阿里云全 Region 的 ECS 资源池，实现近乎无限的弹性供给；</li><li><strong>引擎层</strong>：核心创新包括 <strong>Fusion 向量化执行引擎</strong> 与 <strong>Celeborn Remote Shuffle Service</strong>；</li><li><strong>产品层</strong>：提供认证鉴权、开发 IDE、资源监控、智能诊断等企业级功能。</li></ul><p><strong>极致弹性</strong> 是其关键竞争力：</p><ul><li>支持 <strong>进程级弹性</strong>，最小资源单位低至 1 Core；</li><li>容器启动时间 &lt;15 秒，会话模式、Standalone模式下实现“零冷启”；</li><li>采用 Workspace + 队列的双层 Quota 机制，满足多租户资源隔离需求；</li><li>实际客户案例显示，资源使用波动可从数万核骤降至零，Serverless 架构帮助客户 <strong>节省40%资源成本</strong>。</li></ul><p>此外，系统默认提供 <strong>跨可用区高可用</strong> 能力，Spark 控制面与 Celeborn 服务均多 AZ 部署，作业自动故障迁移，SLA 达 99.9%，且无额外费用。<br/><img width="723" height="516" referrerpolicy="no-referrer" src="/img/bVdnVtf" alt="" title="" loading="lazy"/><br/>EMR Serverless Spark 产品架构</p><h2>全方位生态兼容</h2><p>EMR Serverless Spark 坚持 <strong>开放生态优先</strong> 的设计理念：</p><ul><li><strong>接口兼容</strong>：完整支持 spark-submit、spark-sql、beeline、JDBC 等经典方式，也集成 Kyuubi（含 HA）、Livy 等交互式查询服务；</li><li><strong>工具链集成</strong>：无缝对接 Jupyter、Zeppelin、Superset、DBT 等主流开发分析工具；</li><li><strong>调度系统</strong>：深度适配 Airflow、DolphinScheduler，并在阿里云生态内与 <strong>DataWorks 原生集成</strong>——作为DataWorks“一等公民”，支持 SQL 节点、Notebook、工作流编排、统一权限与数据血缘等；</li><li><strong>安全与元数据</strong>：支持 Kerberos、LDAP、Ranger；</li><li><strong>湖格式</strong>：湖格式覆盖 Paimon/Delta/Hudi/Iceberg；</li><li><strong>外部数据源</strong>：连接 StarRocks、Doris、Hologres、HBase、Elasticsearch、MongoDB、MaxCompute、MySQL 、Postgres等数十种系统。</li></ul><p>这种广泛的兼容性极大降低了用户迁移和集成成本，真正实现“开箱即用”。<br/><img width="723" height="404" referrerpolicy="no-referrer" src="/img/bVdnVtg" alt="" title="" loading="lazy"/></p><h2>TPC-DS 100T 背后的四大核心技术</h2><p>官方TPC-DS 100T 测试包含数据生成、导入、Power Test（单并发99查询）、Throughput Test（4并发396查询）、Maintenance Test（Upsert 操作）等环节，最终通过 QphDS 分数衡量综合性能。</p><p>阿里云的突破源于以下四大技术创新：</p><h3>1. Fusion 向量化执行引擎</h3><p>自2019年起研发，Fusion 将 Spark 从行式计算升级为 <strong>列式向量化执行</strong>：</p><ul><li>利用 SIMD 指令并行处理多列数据；</li><li>连续内存布局显著提升 CPU Cache 命中率；</li><li>异步 IO 与 IO 合并优化读取效率；</li><li>关键算子（Sort/Window/Join）优化，性能提升达 <strong>300%</strong>。</li></ul><p>在 TPC-DS 场景中，Fusion 还引入 Subplan Reuse、Broadcast Join Reuse、Semi Join 哈希表去重等优化，大幅减少重复计算与内存占用。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdnVth" alt="" title="" loading="lazy"/></p><h3>2. 与 Paimon 深度协同</h3><p>Fusion 与阿里自研湖表格式 Paimon 深度整合：</p><ul><li>向量化读写使读性能提升 <strong>70%</strong>，写性能提升 <strong>30%</strong>；</li><li>Variant 类型相比原始 JSON 提升 <strong>178%</strong>；</li><li>Shredding 技术进一步加速JSON解析，性能再提升 <strong>364%</strong>。</li></ul><h3>3. Celeborn Remote Shuffle Service</h3><p>作为 Apache 顶级项目，Celeborn 采用 <strong>推送式 Shuffle 架构</strong>：</p><ul><li>在大规模作业中提供更高吞吐与更低延迟；</li><li>支持副本容错与Stage重算，保障作业稳定性；</li><li>大规模生产验证，成为业界事实标准。</li></ul><h3>4. DLF 3.0 与优化器增强</h3><p>基于 Paimon 的 DLF 3.0 提供高性能 ACID 能力，满足 TPC-DS Maintenance 测试要求；同时优化器在 Join 顺序选择、代价模型等方面持续迭代，提升复杂查询效率。</p><p><strong>最终成果</strong>：在仅使用一半内存的情况下，QphDS 性能翻倍，性价比提升5倍，所有结果均通过 TPC 官方严格审计。<br/><img width="723" height="404" referrerpolicy="no-referrer" src="/img/bVdnVti" alt="" title="" loading="lazy"/></p><h2>AI 时代的新功能：让 Spark 成为 AI 基础设施</h2><p>面对 AI 浪潮，EMR Serverless Spark 推出多项创新功能：</p><ul><li><strong>AI Function</strong>：内置 <code>ai_query</code>、<code>ai_sentiment</code>、<code>ai_classify</code>、<code>ai_embedding</code> 等函数，用户可在 SQL 中直接调用大模型，如同使用内置 UDF。支持接入百炼、OpenAI、PAI EAS 或本地 GPU 模型。</li><li><p><strong>Spark on GPU</strong>：提供弹性 GPU 实例，按需配置 CPU/GPU 混合机型，避免固定集群成本。支持：</p><ul><li>AI Function 本地 GPU 推理；</li><li>Spark ML（XGBoost/LightGBM）GPU 加速；</li><li>Spark SQL 向量化 GPU 计算。</li></ul></li></ul><p><img width="723" height="407" referrerpolicy="no-referrer" src="/img/bVdnVtj" alt="" title="" loading="lazy"/></p><ul><li><p><strong>即将上线功能</strong>：</p><ul><li><strong>Spark + Ray 双引擎融合</strong>：满足 Python 分布式与异构计算需求；</li><li><strong>DuckDB 集成</strong>：针对中小数据分析，在 Notebook 中已内置，未来支持直连 DLF 3.0；</li><li><strong>文本去重加速</strong>：在 FineWeb-edu（8TB、30亿文档）上，800 核仅需 72 分钟，提速 5 倍。</li></ul></li></ul><h2>携手客户共同成长</h2><p>EMR Serverless Spark 已在多家金融、互联网、智能硬件及零售企业的生产环境中稳定运行，广泛应用于数据仓库加速、实时风控、向量检索、机器学习等核心场景。</p><p>同时，Celeborn 社区也在多个头部互联网平台和科技企业中落地，支撑高并发、大规模的数据计算需求。</p><p>阿里云 EMR Serverless Spark 的 TPC-DS 登顶，不仅体现了优异性能，更体现了架构理念、工程能力和生态战略。在 Data + AI 融合的新时代，它正成为企业构建下一代智能数据基础设施的核心引擎。</p>]]></description></item><item>    <title><![CDATA[鸿蒙设备间数据共享实践 江南一点雨 ]]></title>    <link>https://segmentfault.com/a/1190000047609136</link>    <guid>https://segmentfault.com/a/1190000047609136</guid>    <pubDate>2026-02-13 12:08:19</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在万物互联时代，用户身边的智能设备呈现多元化态势，手机、平板、智慧屏、智能穿戴设备、车机等已成为日常必备。鸿蒙操作系统（HarmonyOS）作为面向全场景的分布式操作系统，其核心优势之一便是打破设备硬件边界，实现多设备协同联动，而设备间数据共享则是这一优势落地的关键支撑——它让数据能够“随人而动”，在不同设备间无缝流转，为用户提供连贯、统一的全场景体验。本文将结合实际开发场景，详细拆解鸿蒙设备间数据共享的问题背景、具体对接步骤及最佳实践，助力开发者快速掌握相关技术要点，高效完成跨设备数据共享功能开发。</p><h2>一、问题背景：跨设备数据共享的痛点与鸿蒙的解决方案</h2><p>随着全场景智能生态的普及，跨设备数据共享已成为用户核心需求，但传统设备间的数据交互模式的诸多痛点，严重影响了用户体验和开发效率，具体表现为以下三点：</p><p>其一，协议碎片化严重。不同设备、不同厂商采用的通信协议各异（如蓝牙、Wi-Fi、ZigBee等），开发者需为每种协议单独开发适配代码，不仅增加了开发成本，还导致设备间兼容性差、连接不稳定，难以实现无缝协同。例如，手机与平板间的文档同步的、穿戴设备与手机的健康数据传输，往往需要适配不同的通信协议，开发周期大幅延长。</p><p>其二，数据同步效率低、隐私风险高。传统同步方案多采用“中心化上传-下载”模式，数据需经过第三方服务器中转，不仅存在延迟高、带宽浪费的问题，还可能导致敏感数据（如健康记录、私密文档）泄露。例如，家庭相册同步需手动上传至云端，再由其他设备下载，不仅耗时，还存在隐私泄露隐患。</p><p>其三，开发复杂度高、体验割裂。传统跨设备数据共享需开发者手动处理设备发现、连接建立、数据传输、异常处理等全流程，涉及多层面技术细节，开发门槛高；同时，不同设备间的数据同步缺乏统一管理，易出现数据不一致、同步中断等问题，导致用户体验割裂——如手机上编辑的待办事项，无法实时同步至平板，影响办公效率。</p><p>针对上述痛点，鸿蒙操作系统依托分布式软总线、分布式数据管理（DDM）、远程过程调用（RPC）等核心技术，构建了一套统一的跨设备数据共享解决方案，其核心优势体现在三个方面：一是通过分布式软总线屏蔽底层通信协议差异，实现设备间自动发现、低延迟、高速率连接，无需开发者手动适配多协议；二是采用去中心化架构，支持设备间直接同步数据，结合端到端加密技术，兼顾同步效率与隐私安全；三是提供标准化API和开发框架，简化设备发现、服务注册、数据传输等流程，降低开发门槛，同时通过分布式数据管理实现数据统一管控，确保多设备数据一致性。</p><p>鸿蒙设备间数据共享的核心技术底座包括：分布式软总线（负责设备发现与高速通信）、分布式数据管理（负责数据建模、同步与权限控制）、RPC（负责上层应用跨设备接口调用），三者协同工作，为开发者提供“一次开发、多端部署”的标准化数据共享能力，真正实现数据“随人而动”的全场景体验。</p><h2>二、具体案例对接步骤：基于ArkTS实现跨设备文本同步</h2><p>为让开发者更直观地掌握鸿蒙设备间数据共享的实现流程，本文以“手机与平板跨设备文本同步”为具体案例，基于鸿蒙6.0（API21）、ArkTS语言、Stage模型，详细拆解从环境准备到功能落地的完整对接步骤。该案例实现的核心功能为：手机端输入文本，实时同步至已连接的平板端，平板端接收文本后实时更新UI，同时支持设备断开后的重连同步。</p><h3>2.1 案例前置准备</h3><p>在开始开发前，需完成环境配置、权限申请等前置操作，确保开发环境与设备满足开发要求：</p><ol><li>开发环境：DevEco Studio 5.0（适配鸿蒙6.0），确保已配置鸿蒙6.0 SDK（API21），支持ArkTS语言开发；</li><li>测试设备：2台搭载鸿蒙6.0及以上系统的设备（手机+平板），登录同一华为账号（用于设备自动认证），开启Wi-Fi、蓝牙（确保设备可被发现）；</li><li>权限配置：在项目的module.json5文件中，添加分布式相关权限，用于设备发现、数据同步等操作，具体配置如下：</li></ol><pre><code class="json">{
  "module": {
    "abilities": [...],
    "requestPermissions": [
      {
        "name": "ohos.permission.DISTRIBUTED_DEVICE_STATE_CHANGE",
        "reason": "用于监听分布式设备状态变化（上线/离线）",
        "usedScene": { "when": "always" }
      },
      {
        "name": "ohos.permission.GET_DISTRIBUTED_DEVICE_INFO",
        "reason": "用于获取分布式设备信息（如设备ID、设备类型）",
        "usedScene": { "when": "always" }
      },
      {
        "name": "ohos.permission.DISTRIBUTED_DATASYNC",
        "reason": "用于跨设备数据同步传输",
        "usedScene": { "when": "always" }
      }
    ],
    "dependencies": {
      "@ohos.distributedHardware.distributedDeviceManager": "^1.0",
      "@ohos.rpc": "^1.0"
    }
  }
}</code></pre><ol start="4"><li>核心依赖：引入分布式设备管理（distributedDeviceManager）和RPC（远程过程调用）模块，前者用于设备发现与状态监听，后者用于跨设备接口调用与数据传输。</li></ol><h3>2.2 核心对接步骤（分服务端与客户端）</h3><p>本案例采用“服务端-客户端”架构：平板作为服务端，负责注册远程服务、接收客户端（手机）发送的文本数据并更新UI；手机作为客户端，负责发现服务端设备、绑定远程服务、发送文本数据。整体流程遵循“设备发现→服务注册→RPC接口绑定→跨设备数据传输→数据同步更新”的核心逻辑。</p><h4>步骤1：服务端开发（平板端）——注册远程服务，接收数据</h4><p>服务端的核心职责是定义远程服务接口、注册系统能力，以便客户端能够发现并绑定服务，进而接收客户端发送的数据。具体实现分为两步：</p><ol><li>定义远程服务接口（Stub）：创建继承自RemoteObject的服务端类，实现onRemoteMessageRequest方法，用于处理客户端发送的请求和数据。该类需定义唯一的接口标识符（descriptor），确保与客户端一致，同时实现文本数据接收与UI更新的逻辑。代码示例如下：</li></ol><pre><code class="typescript">import rpc from '@ohos.rpc';
import common from '@ohos.app.ability.common';

// 定义远程服务接口标识符（需与客户端一致）
const SERVICE_DESCRIPTOR = 'com.example.textsync.service';
// 自定义方法标识码（用于区分不同的远程请求）
const TEXT_SYNC_CODE = 1;

// 远程服务Stub类，用于接收客户端数据并处理
export class TextSyncStub extends rpc.RemoteObject {
  // 用于存储接收的文本，关联UI更新
  private textContent: string = '';
  // UI上下文，用于更新页面
  private context: common.UIAbilityContext;

  constructor(descriptor: string, context: common.UIAbilityContext) {
    super(descriptor);
    this.context = context;
  }

  // 处理客户端发送的远程请求
  onRemoteMessageRequest(
    code: number,
    data: rpc.MessageSequence,
    reply: rpc.MessageSequence,
    option: rpc.MessageOption
  ): boolean | Promise&lt;boolean&gt; {
    // 根据方法标识码判断请求类型
    if (code === TEXT_SYNC_CODE) {
      // 读取客户端发送的文本数据
      const receivedText = data.readString();
      console.info(`服务端（平板）接收到文本：${receivedText}`);
      // 更新本地文本内容，并触发UI刷新
      this.textContent = receivedText;
      this.updateUI();
      return true;
    }
    // 未知请求，返回false
    return false;
  }

  // 本地UI更新方法（结合Ability生命周期，更新@State变量）
  private updateUI() {
    // 假设UI页面中有一个@State变量用于展示文本，通过上下文传递更新
    const pageContext = this.context.currentAbility?.currentPage?.getContext();
    if (pageContext) {
      (pageContext as any).updateText(this.textContent);
    }
  }

  // 获取当前接收的文本（供UI页面调用）
  getTextContent(): string {
    return this.textContent;
  }
}</code></pre><ol start="2"><li>注册远程服务：在服务端Ability（平板端页面）中，创建Stub实例，并通过系统能力管理器（SAMgr）注册服务，使客户端能够发现并绑定该服务。代码示例如下：</li></ol><pre><code class="typescript">import featureAbility from '@ohos.app.ability.featureAbility';
import { TextSyncStub } from './TextSyncStub';
import common from '@ohos.app.ability.common';

@Entry
@Component
struct TextSyncServerPage {
  // 远程服务Stub实例
  private stub: TextSyncStub | null = null;
  // UI展示文本（与Stub中的textContent同步）
  @State displayText: string = '等待接收文本...';
  // UI上下文
  private context: common.UIAbilityContext = getContext(this) as common.UIAbilityContext;

  // 页面加载时初始化并注册服务
  aboutToAppear() {
    this.initRemoteService();
  }

  // 初始化远程服务并注册
  private initRemoteService() {
    // 创建Stub实例，传入接口标识符和上下文
    this.stub = new TextSyncStub(SERVICE_DESCRIPTOR, this.context);
    if (!this.stub) {
      console.error('服务端：创建Stub实例失败');
      return;
    }
    // 注册系统能力（SAID为自定义，范围1000-9999）
    const SAID = 1001;
    featureAbility.registerSystemAbility(SAID, this.stub)
      .then(() =&gt; {
        console.info('服务端：远程服务注册成功（SAID：1001）');
      })
      .catch((err) =&gt; {
        console.error(`服务端：远程服务注册失败，错误信息：${err.message}`);
      });

    // 绑定UI更新回调，接收Stub中的文本更新
    (this.context as any).updateText = (text: string) =&gt; {
      this.displayText = text;
    };
  }

  // 页面卸载时注销服务
  aboutToDisappear() {
    if (this.stub) {
      featureAbility.unregisterSystemAbility(1001)
        .then(() =&gt; {
          console.info('服务端：远程服务注销成功');
        })
        .catch((err) =&gt; {
          console.error(`服务端：远程服务注销失败，错误信息：${err.message}`);
        });
    }
  }

  // UI布局：展示接收的文本
  build() {
    Column({ space: 20 }) {
      Text('平板端（服务端）')
        .fontSize(22)
        .fontWeight(FontWeight.Bold);
      Text(this.displayText)
        .fontSize(18)
        .width('80%')
        .textAlign(TextAlign.Center)
        .padding(15)
        .backgroundColor('#f5f5f5');
    }
    .width('100%')
    .height('100%')
    .justifyContent(FlexAlign.Center);
  }
}</code></pre><h4>步骤2：客户端开发（手机端）——发现设备，绑定服务并发送数据</h4><p>客户端的核心职责是通过分布式设备管理器发现目标设备（平板）、绑定服务端的远程服务，然后通过RPC接口发送文本数据。具体实现分为三步：</p><ol><li>设备发现与状态监听：使用DistributedDeviceManager（DDM）创建设备管理实例，监听设备状态变化（上线/离线），过滤出目标设备（平板）并获取其NetworkId（设备唯一标识），为后续绑定服务做准备。代码示例如下：</li></ol><pre><code class="typescript">import deviceManager from '@ohos.distributedHardware.distributedDeviceManager';
import common from '@ohos.app.ability.common';

@Entry
@Component
struct TextSyncClientPage {
  // 设备管理实例
  private dmInstance: deviceManager.DeviceManager | null = null;
  // 目标设备（平板）的NetworkId
  @State targetDeviceId: string = '';
  // RPC代理对象（用于绑定服务端服务）
  private proxy: rpc.RemoteObject | null = null;
  // 客户端输入的文本
  @State inputText: string = '';
  // UI上下文
  private context: common.UIAbilityContext = getContext(this) as common.UIAbilityContext;

  // 页面加载时初始化设备管理器，监听设备状态
  aboutToAppear() {
    this.initDeviceManager();
  }

  // 初始化设备管理器
  private initDeviceManager() {
    // 创建设备管理实例
    deviceManager.getDistributedDeviceManager(this.context)
      .then((dm) =&gt; {
        if (!dm) {
          console.error('客户端：创建设备管理器失败');
          return;
        }
        this.dmInstance = dm;
        console.info('客户端：设备管理器初始化成功');

        // 监听设备状态变化（上线/离线）
        this.dmInstance.on('deviceChange', (deviceInfos: Array&lt;deviceManager.DeviceInfo&gt;) =&gt; {
          deviceInfos.forEach((info) =&gt; {
            // 过滤目标设备：平板（deviceType为TAB）、非本机、在线状态
            if (
              info.deviceType === deviceManager.DeviceType.TAB &amp;&amp;
              !info.isLocalDevice &amp;&amp;
              info.deviceState === deviceManager.DeviceState.ONLINE
            ) {
              this.targetDeviceId = info.networkId;
              console.info(`客户端：发现平板设备，NetworkId：${this.targetDeviceId}`);
              // 发现设备后，自动绑定服务
              this.bindRemoteService();
            } else if (info.deviceState === deviceManager.DeviceState.OFFLINE &amp;&amp; info.networkId === this.targetDeviceId) {
              console.info('客户端：平板设备已离线');
              this.targetDeviceId = '';
              this.proxy = null;
            }
          });
        });
      })
      .catch((err) =&gt; {
        console.error(`客户端：创建设备管理器失败，错误信息：${err.message}`);
      });
  }

  // 绑定服务端远程服务
  private bindRemoteService() {
    if (!this.targetDeviceId || !this.dmInstance) {
      console.error('客户端：绑定服务失败，目标设备ID为空或设备管理器未初始化');
      return;
    }

    // 构造Want对象，指定服务端信息
    const want: common.Want = {
      deviceId: this.targetDeviceId, // 目标设备NetworkId
      bundleName: 'com.example.textsync', // 服务端应用包名（需与服务端一致）
      abilityName: 'TextSyncServerPage', // 服务端Ability名称（需与服务端一致）
      parameters: {
        serviceDescriptor: SERVICE_DESCRIPTOR // 服务接口标识符（需与服务端一致）
      }
    };

    // 绑定服务端Ability
    featureAbility.connectAbility(want, {
      // 绑定成功回调，获取服务端代理对象
      onConnect: (proxy: rpc.RemoteObject) =&gt; {
        this.proxy = proxy;
        console.info('客户端：绑定服务端成功');
      },
      // 绑定断开回调
      onDisconnect: () =&gt; {
        console.info('客户端：与服务端断开连接');
        this.proxy = null;
      },
      // 绑定失败回调
      onFailed: (code: number) =&gt; {
        console.error(`客户端：绑定服务端失败，错误码：${code}`);
        this.proxy = null;
      }
    });
  }

  // 发送文本数据到服务端
  private sendTextToServer() {
    if (!this.proxy || !this.inputText.trim()) {
      console.error('客户端：发送失败，代理对象为空或输入文本为空');
      return;
    }

    // 构造请求数据（MessageSequence）
    const data = rpc.MessageSequence.create();
    const reply = rpc.MessageSequence.create();
    // 写入要发送的文本数据
    data.writeString(this.inputText.trim());

    // 调用服务端远程接口（指定方法标识码）
    this.proxy.sendRequest(TEXT_SYNC_CODE, data, reply, rpc.MessageOption.TWOWAY)
      .then(() =&gt; {
        console.info(`客户端：文本发送成功，内容：${this.inputText.trim()}`);
        // 发送成功后清空输入框
        this.inputText = '';
      })
      .catch((err) =&gt; {
        console.error(`客户端：文本发送失败，错误信息：${err.message}`);
      })
      .finally(() =&gt; {
        // 释放资源
        data.destroy();
        reply.destroy();
      });
  }

  // UI布局：输入文本并发送
  build() {
    Column({ space: 20 }) {
      Text('手机端（客户端）')
        .fontSize(22)
        .fontWeight(FontWeight.Bold);
      TextInput({
        placeholder: '请输入要同步的文本',
        value: this.inputText
      })
        .fontSize(18)
        .width('80%')
        .padding(12)
        .border({ width: 1, color: '#e5e5e5' })
        .onChange((value) =&gt; {
          this.inputText = value;
        });
      Button('发送到平板')
        .fontSize(18)
        .width('80%')
        .height(48)
        .backgroundColor('#007dff')
        .fontColor('#ffffff')
        .onClick(() =&gt; {
          this.sendTextToServer();
        })
        .enabled(this.targetDeviceId !== '' &amp;&amp; this.proxy !== null); // 设备在线且绑定成功才可用
    }
    .width('100%')
    .height('100%')
    .justifyContent(FlexAlign.Center);
  }
}</code></pre><h4>步骤3：测试验证</h4><p>完成服务端与客户端开发后，进行如下测试验证，确保功能正常：</p><ol><li>分别在平板和手机上部署应用，确保两台设备登录同一华为账号，开启Wi-Fi、蓝牙；</li><li>先启动平板端应用（服务端），再启动手机端应用（客户端），客户端会自动发现平板设备并绑定服务；</li><li>在手机端输入文本，点击“发送到平板”，平板端应实时显示接收的文本；</li><li>测试异常场景：断开平板Wi-Fi（设备离线），客户端应提示设备离线，发送按钮不可用；重新开启平板Wi-Fi，客户端自动重连，恢复文本同步功能。</li></ol><h2>三、鸿蒙设备间数据共享最佳实践</h2><p>结合上述案例开发经验，以及鸿蒙分布式技术的特性，总结以下设备间数据共享最佳实践，帮助开发者规避常见问题、优化性能与体验，提升开发效率：</p><h3>3.1 技术选型最佳实践：按需选择合适的共享方式</h3><p>鸿蒙提供了多种设备间数据共享方式，开发者需根据数据类型、同步需求、设备场景，选择最合适的方式，避免盲目选型导致的性能浪费或体验不佳：</p><ol><li>RPC远程调用：适用于小体量数据（如文本、参数）的实时交互，支持跨设备接口调用，适合本文案例中的文本同步、指令传输等场景。优势是延迟低、交互灵活，劣势是不适合大文件传输。</li><li>分布式数据管理（DDM）：适用于需要多设备数据一致性的场景（如待办事项、家庭相册、健康数据），支持数据自动同步、增量更新、冲突自动合并，开发者无需手动处理数据同步细节。例如，1000条待办事项更新，传统方案需同步2.1MB数据，DDM仅传输8KB，大幅提升同步效率。</li><li>分布式文件共享：适用于大文件传输（如图片、视频、文档），依托分布式软总线的高速传输能力，支持星闪/Wi-Fi Direct直连传输，速度可达800Mbps以上。开发时需注意文件分片传输、存储权限申请、传输进度反馈等细节。</li><li>分布式KVStore：适用于小型配置数据（如用户偏好设置、设备参数）的同步，API简单易用，支持加密存储，适合轻量级数据共享场景。</li></ol><h3>3.2 开发实现最佳实践：规避常见问题，提升稳定性</h3><p>在开发过程中，需重点关注设备发现、服务注册、数据传输、异常处理等环节，规避常见问题，确保功能稳定可靠：</p><ol><li>设备发现与认证：优先依赖同一华为账号的自动认证机制，简化用户操作；同时监听设备状态变化（上线/离线），及时更新设备列表和连接状态，避免因设备离线导致的传输失败。开发时需注意，设备发现需开启Wi-Fi、蓝牙，否则会导致设备无法被检测到。</li><li>服务注册与绑定：服务端需确保服务注册成功后再对外提供能力，页面卸载时及时注销服务，避免资源泄露；客户端绑定服务时，需处理绑定失败、断开连接等异常，实现自动重连机制，提升用户体验。同时，服务接口标识符（descriptor）、SAID需与客户端保持一致，否则会导致绑定失败。</li><li>数据传输优化：传输敏感数据时，需开启端到端加密（如DDM的字段级加密、KVStore的加密存储），符合《个人信息保护法》要求；传输大文件时，采用分片传输+断点续传机制，避免因网络不稳定导致的传输中断；传输小体量数据时，优先使用RPC，减少数据中转，降低延迟。</li><li>异常处理：全面覆盖设备未发现、服务绑定失败、数据传输超时、设备断开连接等异常场景，添加详细的日志打印，便于问题排查；同时为用户提供清晰的提示（如“设备未找到”“发送失败，请重试”），提升体验。例如，本文案例中，发送按钮仅在设备在线且绑定成功后可用，避免用户无效操作。</li><li>权限管理：严格按照鸿蒙权限规范，申请必要的分布式权限，明确权限申请理由，避免过度申请权限；同时处理权限申请被拒绝的场景，提示用户开启对应权限，否则无法使用跨设备共享功能。</li></ol><h3>3.3 性能与体验优化最佳实践：兼顾效率与易用性</h3><p>除了功能稳定，还需优化性能与用户体验，实现“无缝同步”的核心需求：</p><ol><li>性能优化：减少不必要的设备扫描和数据同步，采用“按需同步”机制（如用户触发同步、数据变化时同步）；避免频繁创建和销毁设备管理器、RPC代理等实例，复用资源；传输数据时，仅同步变化部分（如DDM的增量更新），减少带宽占用和延迟。</li><li>UI体验优化：同步过程中添加加载提示（如进度条、加载动画），让用户感知同步状态；数据同步成功后，及时更新UI，避免数据不一致；针对多设备同步场景，提供同步状态展示（如“已同步至2台设备”），让用户清晰了解数据同步情况。</li><li>兼容性适配：适配不同鸿蒙版本（如API11与API21）的差异，针对低版本系统做降级处理；适配不同类型的设备（手机、平板、穿戴设备），根据设备屏幕尺寸、交互方式，优化UI布局和操作流程；同时兼容同账号下的多设备组网场景，确保数据在多设备间一致。</li></ol><h3>3.4 安全最佳实践：守护数据隐私与安全</h3><p>跨设备数据共享涉及用户隐私数据，需严格遵循鸿蒙安全规范，守护数据安全：</p><ol><li>数据加密：敏感数据（如健康记录、私密文档）需采用端到端加密传输和存储，避免数据在传输过程中被截取、泄露；分布式数据管理支持字段级加密，可对敏感字段单独加密，进一步提升安全性。</li><li>权限管控：实现细粒度的设备授权机制，允许用户设置“哪些设备可访问哪些数据”，例如“仅允许平板访问工作文档，智慧屏不可见”；支持临时共享，生成一次性访问令牌，过期自动失效，避免数据长期泄露。</li><li>数据主权：遵循“数据随人而动，主权属于用户”的原则，不强制将数据上传至云端，优先采用设备间直接同步模式；提供数据同步开关，允许用户随时关闭跨设备同步功能，掌控自己的数据。</li></ol><h2>四、总结</h2><p>鸿蒙设备间数据共享依托分布式软总线、分布式数据管理、RPC等核心技术，彻底解决了传统跨设备数据交互的协议碎片化、效率低、开发复杂等痛点，为开发者提供了统一、高效、安全的解决方案。本文通过“手机与平板跨设备文本同步”案例，详细拆解了服务端与客户端的对接步骤，涵盖环境准备、设备发现、服务注册、数据传输等核心环节，同时总结了技术选型、开发实现、性能优化、安全保障等最佳实践，助力开发者快速上手。</p><p>在实际开发中，开发者需结合具体业务场景，按需选择合适的数据共享方式，严格遵循鸿蒙开发规范和最佳实践，兼顾功能稳定性、性能效率与用户体验。随着鸿蒙生态的不断完善，设备间数据共享的场景将更加丰富，未来可结合AI技术实现意图感知同步、隐私风险预测等更智能的功能，进一步推动全场景智能生态的落地。</p>]]></description></item><item>    <title><![CDATA[鸿蒙推送功能开发实践 江南一点雨 ]]></title>    <link>https://segmentfault.com/a/1190000047609158</link>    <guid>https://segmentfault.com/a/1190000047609158</guid>    <pubDate>2026-02-13 12:07:41</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在全场景智能生态飞速发展的当下，推送功能已成为鸿蒙应用不可或缺的核心能力之一——它承担着消息触达、用户召回、功能提醒等关键职责，直接影响应用的活跃度、留存率与用户体验。无论是社交应用的消息通知、工具应用的任务提醒，还是内容应用的更新推送，都离不开稳定、高效的推送机制。鸿蒙操作系统（HarmonyOS）依托分布式架构优势，构建了统一的推送服务体系，打破了传统推送“平台碎片化、适配复杂、推送延迟高”的困境，为开发者提供了“一次开发、多端适配”的标准化推送开发方案。本文将结合实际开发场景，详细拆解鸿蒙推送功能的问题背景、具体对接步骤及最佳实践，助力开发者快速掌握相关技术要点，高效完成推送功能落地。</p><h2>一、问题背景：传统推送的痛点与鸿蒙推送的解决方案</h2><p>随着鸿蒙生态的不断扩张，应用需适配手机、平板、智慧屏、智能穿戴、车机等多种设备，传统推送模式在鸿蒙场景下的诸多痛点日益凸显，严重影响开发效率与用户体验，具体表现为以下三点：</p><p>其一，平台碎片化严重，适配成本高。传统推送需依赖第三方推送平台（如极光、个推），而不同第三方平台的API接口、适配逻辑差异较大，开发者需为不同平台单独开发适配代码；同时，鸿蒙设备品类繁多，不同设备的系统版本、推送权限机制不一致，进一步增加了适配难度。例如，手机端推送需适配后台保活机制，而智慧屏端需适配息屏唤醒逻辑，开发者需投入大量精力处理多设备、多平台的适配问题，开发周期大幅延长。</p><p>其二，推送稳定性差，延迟与丢失问题突出。传统推送多采用“客户端-第三方服务器-应用服务器”的中转模式，链路较长，易受网络波动、设备后台清理等因素影响，导致推送延迟高、消息丢失率高；此外，不同设备的后台限制策略不同，部分设备会限制第三方推送服务的后台运行，导致推送无法正常触达。例如，穿戴设备与手机断开连接后，传统推送无法通过鸿蒙分布式能力实现消息接力，用户无法及时接收关键提醒。</p><p>其三，资源消耗高，用户体验割裂。传统推送方案中，每个应用需单独启动推送服务，多个应用同时运行时会占用大量设备内存与电量，影响设备续航；同时，推送消息的展示样式、交互逻辑缺乏统一标准，不同应用的推送通知在多设备上的展示效果不一致，导致用户体验割裂。例如，手机端接收的推送通知无法同步至平板端，用户切换设备后需重新查看，影响使用连贯性。</p><p>针对上述痛点，鸿蒙操作系统推出了官方统一的推送服务——鸿蒙推送服务（HarmonyOS Push Service），依托分布式软总线、分布式数据管理、统一推送框架等核心技术，构建了一套高效、稳定、低耗的全场景推送解决方案，其核心优势体现在三个方面：</p><p>一是统一标准化，降低开发与适配成本。鸿蒙推送服务提供标准化的API接口与开发框架，开发者无需适配多第三方平台，只需一次开发，即可实现多鸿蒙设备（手机、平板、智慧屏等）的推送适配，大幅简化开发流程；同时，系统统一管理推送服务，无需每个应用单独启动推送进程，降低设备资源消耗。</p><p>二是分布式协同，实现全场景消息触达。依托鸿蒙分布式架构，推送消息可实现多设备协同触达——例如，手机端未读的推送通知，切换至平板端后可继续查看；穿戴设备与手机断开连接后，推送消息可通过鸿蒙分布式软总线接力触达穿戴设备，确保用户在任何设备上都能及时接收消息。</p><p>三是高稳定低延迟，提升推送可靠性。鸿蒙推送服务采用“应用服务器-鸿蒙推送服务器-设备”的短链路架构，减少中转环节，推送延迟可低至数百毫秒；同时，结合设备后台保活优化、消息重试机制，大幅降低消息丢失率，确保推送消息稳定触达；此外，支持消息优先级设置，可根据业务需求优先推送关键消息（如验证码、紧急提醒）。</p><p>鸿蒙推送功能的核心技术底座包括：鸿蒙推送服务器（负责消息转发、权限管控、消息统计）、统一推送框架（负责客户端消息接收、解析与展示）、分布式软总线（负责多设备间消息接力）、分布式数据管理（负责多设备推送消息同步），四者协同工作，为开发者提供全场景、高可靠、低消耗的推送能力。</p><h2>二、具体案例对接步骤：基于ArkTS实现鸿蒙全场景推送功能</h2><p>为让开发者更直观地掌握鸿蒙推送功能的实现流程，本文以“多设备消息推送与同步”为具体案例，基于鸿蒙6.0（API21）、ArkTS语言、Stage模型，详细拆解从环境准备、服务配置到功能落地、测试验证的完整对接步骤。该案例实现的核心功能为：应用服务器发送推送消息（文本通知+跳转链接），鸿蒙手机、平板同时接收消息并展示；手机端标记消息已读，平板端同步更新状态；穿戴设备与手机连接时，消息同步触达穿戴设备。</p><h3>2.1 案例前置准备</h3><p>在开始开发前，需完成环境配置、账号注册、权限申请等前置操作，确保开发环境与设备满足开发要求：</p><ol><li>开发环境：DevEco Studio 5.0（适配鸿蒙6.0），确保已配置鸿蒙6.0 SDK（API21），支持ArkTS语言开发；安装鸿蒙推送服务SDK（可通过DevEco Studio的依赖管理添加）。</li><li>账号与服务配置：注册华为开发者账号，在华为开发者联盟后台创建鸿蒙应用，开通鸿蒙推送服务，获取应用的AppID、AppSecret（用于应用服务器与鸿蒙推送服务器的身份认证）；配置推送消息的签名信息，确保消息传输安全。</li><li>测试设备：2-3台搭载鸿蒙6.0及以上系统的设备（手机、平板、穿戴设备），登录同一华为账号（用于多设备推送同步），开启推送权限（设置-应用-目标应用-通知，开启允许通知）。</li><li>权限配置：在项目的module.json5文件中，添加推送相关权限，用于接收推送消息、获取设备信息、多设备同步等操作，具体配置如下：</li></ol><pre><code class="json">{
  "module": {
    "abilities": [...],
    "requestPermissions": [
      {
        "name": "ohos.permission.RECEIVE_PUSH_NOTIFICATION",
        "reason": "用于接收鸿蒙推送服务发送的消息",
        "usedScene": { "when": "always" }
      },
      {
        "name": "ohos.permission.GET_DISTRIBUTED_DEVICE_INFO",
        "reason": "用于获取分布式设备信息，实现多设备消息同步",
        "usedScene": { "when": "always" }
      },
      {
        "name": "ohos.permission.DISTRIBUTED_DATASYNC",
        "reason": "用于多设备间推送消息状态同步（如已读/未读）",
        "usedScene": { "when": "always" }
      }
    ],
    "dependencies": {
      "@ohos.push": "^1.0.0", // 鸿蒙推送服务SDK依赖
      "@ohos.distributedHardware.distributedDeviceManager": "^1.0"
    }
  }
}</code></pre><ol start="5"><li>核心依赖：引入鸿蒙推送服务SDK（@ohos.push），用于客户端接收、解析推送消息；引入分布式设备管理模块（distributedDeviceManager），用于获取多设备信息，实现消息状态同步。</li></ol><h3>2.2 核心对接步骤（分客户端、应用服务器）</h3><p>本案例采用“应用服务器-鸿蒙推送服务器-客户端（多设备）”的架构，整体流程遵循“客户端注册推送服务→应用服务器发送消息至鸿蒙推送服务器→鸿蒙推送服务器转发消息至多客户端→客户端接收消息并同步状态”的核心逻辑，具体分为客户端开发与应用服务器开发两部分。</p><h4>步骤1：客户端开发（多设备通用）——注册推送服务，接收并处理消息</h4><p>客户端的核心职责是注册鸿蒙推送服务、接收鸿蒙推送服务器发送的消息、解析消息内容、展示通知，并实现多设备消息状态同步（如已读/未读）。具体实现分为三步：</p><ol><li>初始化推送服务，注册设备。在应用启动时（Ability的onCreate方法或页面的aboutToAppear方法），初始化鸿蒙推送服务，注册当前设备到鸿蒙推送服务器，获取设备的推送令牌（Token）——Token是设备的唯一标识，应用服务器发送推送消息时，需指定目标设备的Token（多设备推送可指定多个Token）。代码示例如下：</li></ol><pre><code class="typescript">import push from '@ohos.push';
import common from '@ohos.app.ability.common';
import deviceManager from '@ohos.distributedHardware.distributedDeviceManager';

@Entry
@Component
struct PushClientPage {
  // 推送令牌（设备唯一标识）
  @State pushToken: string = '';
  // 接收的推送消息列表
  @State messageList: Array&lt;{ id: string; title: string; content: string; isRead: boolean }&gt; = [];
  // UI上下文
  private context: common.UIAbilityContext = getContext(this) as common.UIAbilityContext;
  // 设备管理实例（用于多设备消息同步）
  private dmInstance: deviceManager.DeviceManager | null = null;

  // 页面加载时初始化推送服务与设备管理器
  aboutToAppear() {
    this.initPushService();
    this.initDeviceManager();
  }

  // 初始化鸿蒙推送服务
  private initPushService() {
    // 初始化推送服务
    push.init(this.context)
      .then(() =&gt; {
        console.info('推送服务初始化成功');
        // 注册设备，获取推送Token
        return push.getToken();
      })
      .then((token) =&gt; {
        this.pushToken = token;
        console.info(`设备注册成功，推送Token：${this.pushToken}`);
        // 注册消息接收回调，监听推送消息
        this.registerPushReceiver();
      })
      .catch((err) =&gt; {
        console.error(`推送服务初始化/注册失败，错误信息：${err.message}`);
      });
  }

  // 注册推送消息接收回调
  private registerPushReceiver() {
    // 监听推送消息接收事件
    push.on('receiveMessage', (message: push.PushMessage) =&gt; {
      console.info(`接收推送消息：${JSON.stringify(message)}`);
      // 解析消息内容（message.data为JSON字符串，需解析）
      const messageData = JSON.parse(message.data);
      // 新增消息到列表（默认未读）
      this.messageList.unshift({
        id: message.messageId,
        title: messageData.title || '推送通知',
        content: messageData.content || '',
        isRead: false
      });
      // 展示系统通知
      this.showNotification(messageData.title, messageData.content, messageData.url);
      // 同步消息到其他设备（已读/未读状态）
      this.syncMessageToOtherDevices(message.messageId, false);
    });

    // 监听推送Token变化事件（如设备重置、账号切换导致Token变化）
    push.on('tokenChange', (newToken: string) =&gt; {
      console.info(`推送Token变化，新Token：${newToken}`);
      this.pushToken = newToken;
      // 可将新Token上报至应用服务器，更新设备Token记录
      this.reportTokenToServer(newToken);
    });
  }

  // 展示系统推送通知
  private showNotification(title: string, content: string, url: string) {
    // 构造通知参数
    const notification: push.Notification = {
      title: title,
      content: content,
      clickAction: {
        type: push.ClickActionType.OPEN_ABILITY, // 点击通知跳转至应用页面
        abilityName: 'PushClientPage', // 跳转的Ability名称
        parameters: { url: url } // 携带跳转参数（如链接）
      },
      importance: push.NotificationImportance.HIGH // 高优先级，确保及时展示
    };
    // 发送系统通知
    push.showNotification(notification)
      .then(() =&gt; {
        console.info('推送通知展示成功');
      })
      .catch((err) =&gt; {
        console.error(`推送通知展示失败，错误信息：${err.message}`);
      });
  }

  // 初始化设备管理器，用于多设备消息同步
  private initDeviceManager() {
    deviceManager.getDistributedDeviceManager(this.context)
      .then((dm) =&gt; {
        if (!dm) {
          console.error('创建设备管理器失败');
          return;
        }
        this.dmInstance = dm;
        // 监听其他设备的消息同步请求
        this.listenMessageSync();
      })
      .catch((err) =&gt; {
        console.error(`创建设备管理器失败，错误信息：${err.message}`);
      });
  }

  // 同步消息状态到其他设备
  private syncMessageToOtherDevices(messageId: string, isRead: boolean) {
    if (!this.dmInstance) return;
    // 获取所有在线的分布式设备（排除本机）
    const devices = this.dmInstance.getAvailableDeviceList();
    devices.forEach((device) =&gt; {
      if (device.isLocalDevice) return;
      // 构造同步消息
      const syncData = {
        messageId: messageId,
        isRead: isRead
      };
      // 通过分布式数据管理同步消息状态（简化实现，实际可结合DDM或RPC）
      this.dmInstance.sendData(device.networkId, JSON.stringify(syncData))
        .then(() =&gt; {
          console.info(`消息状态同步至设备${device.networkId}成功`);
        })
        .catch((err) =&gt; {
          console.error(`消息状态同步至设备${device.networkId}失败：${err.message}`);
        });
    });
  }

  // 监听其他设备的消息同步请求，更新本地消息状态
  private listenMessageSync() {
    if (!this.dmInstance) return;
    this.dmInstance.on('dataReceived', (deviceId: string, data: string) =&gt; {
      console.info(`接收设备${deviceId}的同步消息：${data}`);
      const syncData = JSON.parse(data);
      // 查找对应的消息，更新已读状态
      const targetMessage = this.messageList.find(item =&gt; item.id === syncData.messageId);
      if (targetMessage) {
        targetMessage.isRead = syncData.isRead;
      }
    });
  }

  // 将推送Token上报至应用服务器（供服务器发送消息时使用）
  private reportTokenToServer(token: string) {
    // 调用应用服务器接口，上报Token（实际开发中需结合HTTP/HTTPS请求）
    console.info(`上报推送Token至服务器：${token}`);
    // 示例：fetch('https://xxx.com/reportToken', { method: 'POST', body: JSON.stringify({ token: token }) });
  }

  // 标记消息为已读
  private markMessageAsRead(messageId: string) {
    const targetMessage = this.messageList.find(item =&gt; item.id === messageId);
    if (targetMessage) {
      targetMessage.isRead = true;
      // 同步已读状态到其他设备
      this.syncMessageToOtherDevices(messageId, true);
    }
  }

  // UI布局：展示推送消息列表
  build() {
    Column({ space: 15 }) {
      Text('鸿蒙推送客户端（多设备同步）')
        .fontSize(22)
        .fontWeight(FontWeight.Bold);
      Text(`当前设备推送Token：${this.pushToken}`)
        .fontSize(14)
        .width('90%')
        .textAlign(TextAlign.Center)
        .padding(10)
        .backgroundColor('#f5f5f5');
      List({ space: 10 }) {
        ForEach(this.messageList, (item) =&gt; {
          ListItem() {
            Column({ space: 5 }) {
              Text(item.title)
                .fontSize(18)
                .fontWeight(item.isRead ? FontWeight.Normal : FontWeight.Bold)
                .fontColor(item.isRead ? '#999999' : '#000000');
              Text(item.content)
                .fontSize(16)
                .fontColor('#666666');
            }
            .width('100%')
            .padding(15)
            .backgroundColor('#ffffff')
            .border({ width: 1, color: '#e5e5e5' })
            .onClick(() =&gt; {
              this.markMessageAsRead(item.id);
            });
          }
        });
      }
      .width('90%')
      .flexGrow(1);
    }
    .width('100%')
    .height('100%')
    .padding(10)
    .backgroundColor('#fafafa');
  }
}</code></pre><ol start="2"><li>处理推送消息交互逻辑。实现消息点击跳转、消息已读/未读状态同步、多设备消息同步等逻辑，如上述代码所示：点击推送通知跳转至应用指定页面（携带跳转参数）；点击消息列表项标记消息为已读，并同步状态至其他设备；接收其他设备的同步消息，更新本地消息状态。</li><li>异常处理。添加推送服务初始化失败、消息接收失败、Token变化、多设备同步失败等异常场景的处理，打印详细日志便于问题排查，同时为用户提供清晰的提示（如“推送服务初始化失败，请重启应用”）。</li></ol><h4>步骤2：应用服务器开发——发送推送消息至鸿蒙推送服务器</h4><p>应用服务器的核心职责是生成推送消息、通过鸿蒙推送服务API发送消息至鸿蒙推送服务器，同时接收客户端上报的设备Token，管理设备列表。本案例采用Node.js（Express框架）实现应用服务器，具体代码示例如下：</p><pre><code class="javascript">const express = require('express');
const axios = require('axios');
const app = express();
app.use(express.json());

// 鸿蒙推送服务配置（从华为开发者联盟后台获取）
const APP_ID = '你的应用AppID';
const APP_SECRET = '你的应用AppSecret';
const PUSH_API_URL = 'https://push-api.cloud.huawei.com/v1/your-appid/messages:send'; // 替换为实际API地址

// 存储客户端上报的设备Token（多设备对应多个Token）
let deviceTokens = [];

// 1. 接收客户端上报的推送Token
app.post('/reportToken', (req, res) =&gt; {
  const { token } = req.body;
  if (token &amp;&amp; !deviceTokens.includes(token)) {
    deviceTokens.push(token);
    console.log(`新增设备Token：${token}，当前设备列表：${deviceTokens}`);
  }
  res.json({ code: 200, message: 'Token上报成功' });
});

// 2. 发送推送消息（支持多设备推送）
app.post('/sendPush', async (req, res) =&gt; {
  try {
    const { title, content, url } = req.body;
    if (!title || !content) {
      return res.json({ code: 400, message: '标题和内容不能为空' });
    }
    if (deviceTokens.length === 0) {
      return res.json({ code: 400, message: '暂无在线设备' });
    }

    // 1. 获取鸿蒙推送服务的访问令牌（Access Token）
    const accessToken = await getAccessToken();
    if (!accessToken) {
      return res.json({ code: 500, message: '获取Access Token失败' });
    }

    // 2. 构造推送消息体（符合鸿蒙推送API规范）
    const pushMessage = {
      message: {
        data: JSON.stringify({ title, content, url }), // 自定义消息内容（客户端解析）
        notification: {
          title: title,
          body: content,
          click_action: {
            type: 1, // 点击跳转至应用
            ability: {
              bundle_name: 'com.example.pushdemo', // 应用包名（需与客户端一致）
              ability_name: 'PushClientPage' // 跳转的Ability名称
            }
          }
        },
        token: deviceTokens // 目标设备Token列表（多设备推送）
      }
    };

    // 3. 调用鸿蒙推送API发送消息
    const response = await axios.post(PUSH_API_URL, pushMessage, {
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${accessToken}`
      }
    });

    console.log(`推送消息发送成功，响应：${JSON.stringify(response.data)}`);
    res.json({ code: 200, message: '推送消息发送成功', data: response.data });
  } catch (err) {
    console.error(`推送消息发送失败，错误：${err.message}`);
    res.json({ code: 500, message: '推送消息发送失败', error: err.message });
  }
});

// 获取鸿蒙推送服务的Access Token（用于API身份认证）
async function getAccessToken() {
  const tokenUrl = `https://oauth-login.cloud.huawei.com/oauth2/v3/token`;
  try {
    const response = await axios.post(tokenUrl, new URLSearchParams({
      grant_type: 'client_credentials',
      client_id: APP_ID,
      client_secret: APP_SECRET
    }), {
      headers: { 'Content-Type': 'application/x-www-form-urlencoded' }
    });
    return response.data.access_token;
  } catch (err) {
    console.error(`获取Access Token失败：${err.message}`);
    return null;
  }
}

// 启动服务器
const port = 3000;
app.listen(port, () =&gt; {
  console.log(`应用服务器启动成功，监听端口：${port}`);
});</code></pre><p>核心说明：应用服务器需先获取鸿蒙推送服务的Access Token（通过AppID与AppSecret认证），再构造符合规范的推送消息体，调用鸿蒙推送API发送消息；消息体中需指定目标设备的Token列表（多设备推送可传入多个Token）、消息内容、通知样式及点击交互逻辑。</p><h4>步骤3：测试验证</h4><p>完成客户端与应用服务器开发后，进行如下测试验证，确保推送功能正常实现：</p><ol><li>部署应用服务器：启动Node.js服务器，确保服务器可正常访问（可通过Postman测试接口）。</li><li>部署客户端应用：分别在手机、平板、穿戴设备上部署鸿蒙应用，启动应用后，客户端会自动初始化推送服务、注册设备，并将Token上报至应用服务器。</li><li>发送推送消息：通过Postman调用应用服务器的/sendPush接口，传入标题、内容、跳转链接，发送推送消息。</li><li>验证核心功能：</li></ol><ul><li>多设备接收：手机、平板、穿戴设备（与手机连接）应同时接收推送消息，并展示系统通知；</li><li>消息交互：点击任何设备上的推送通知，应跳转至应用指定页面，携带跳转参数；</li><li>状态同步：在手机端标记消息为已读，平板端、穿戴设备上的对应消息应同步更新为已读状态；</li><li>异常场景：断开穿戴设备与手机的连接，发送推送消息，穿戴设备重新连接后应接收未读消息；关闭客户端应用后台，发送推送消息，应用应被唤醒并接收消息。</li></ul><ol start="5"><li>日志排查：若推送失败，可查看客户端与应用服务器的日志，排查Token是否正确、Access Token是否有效、消息体格式是否符合规范等问题。</li></ol><h2>三、鸿蒙推送功能最佳实践</h2><p>结合上述案例开发经验，以及鸿蒙推送服务的特性，总结以下鸿蒙推送功能最佳实践，帮助开发者规避常见问题、优化推送性能与用户体验，提升开发效率：</p><h3>3.1 技术选型与服务配置最佳实践</h3><ol><li>优先使用官方鸿蒙推送服务，避免第三方推送平台。鸿蒙推送服务与鸿蒙系统深度融合，支持多设备协同、低资源消耗、高稳定性，无需适配多平台，可大幅降低开发与适配成本；若需兼容非鸿蒙设备，可采用“鸿蒙推送+第三方推送”的混合方案，鸿蒙设备使用官方推送，非鸿蒙设备使用第三方推送。</li><li>合理配置推送服务参数。在华为开发者联盟后台，根据业务需求配置推送消息的过期时间（默认24小时）、重试次数、消息优先级；对于关键消息（如验证码、紧急提醒），设置高优先级（NotificationImportance.HIGH），确保及时触达；对于非关键消息（如广告、内容更新），设置低优先级，避免打扰用户。</li><li>妥善管理设备Token。客户端需监听Token变化事件（tokenChange），将新Token及时上报至应用服务器，避免因Token变化导致推送失败；应用服务器需定期清理无效Token（如设备卸载应用、注销账号），可通过鸿蒙推送API的“消息发送状态查询”接口，获取Token的有效性，及时移除无效Token。</li></ol><h3>3.2 客户端开发最佳实践：提升稳定性与用户体验</h3><ol><li>推送服务初始化时机。建议在应用启动时（Ability的onCreate方法）初始化推送服务，确保推送服务尽早注册，避免错过推送消息；同时，添加初始化失败的重试机制（如间隔3秒重试，最多重试3次），提升初始化成功率。</li><li>消息处理规范化。解析推送消息时，需对消息格式进行校验（避免非法JSON格式导致解析失败）；区分推送消息类型（通知消息、透传消息），通知消息展示系统通知，透传消息根据业务需求处理（如后台处理、弹窗提示）；同时，避免在消息接收回调中执行耗时操作（如大量计算、网络请求），防止阻塞消息处理。</li><li>多设备同步优化。实现多设备消息状态同步时，优先使用鸿蒙分布式数据管理（DDM），替代简单的消息发送，确保同步的可靠性；同时，过滤无效设备（如离线设备），避免无效同步消耗设备资源；对于消息列表，可采用增量同步机制，仅同步新增或状态变化的消息，减少数据传输量。</li><li>权限与用户体验优化。客户端需检查推送权限，若权限未开启，提示用户开启（跳转至权限设置页面），但避免频繁弹窗打扰用户；推送通知的标题、内容需简洁明了，避免冗余信息；根据设备类型优化通知展示样式（如智慧屏端通知展示在屏幕顶部，穿戴设备端通知适配小屏幕）。</li><li>异常处理全覆盖。全面覆盖推送服务初始化失败、消息接收失败、Token变化、多设备同步失败、权限被拒绝等异常场景，添加详细的日志打印（包含错误码、错误信息），便于问题排查；同时，为用户提供清晰的提示，如“推送权限未开启，无法接收消息”“消息同步失败，请重试”。</li></ol><h3>3.3 应用服务器开发最佳实践：提升推送可靠性</h3><ol><li>Access Token管理优化。应用服务器获取的Access Token有有效期（默认7200秒），需提前缓存Access Token，避免每次发送消息都重新获取；同时，添加Access Token过期监听，在过期前自动重新获取，确保推送消息正常发送。</li><li>消息发送重试机制。调用鸿蒙推送API发送消息时，添加重试机制，针对网络波动、服务器临时不可用等场景，自动重试发送（如间隔1秒重试，最多重试3次）；同时，处理推送API返回的错误码（如Token无效、权限不足），根据错误码进行对应处理（如移除无效Token、检查服务配置）。</li><li>消息批量发送优化。若需向大量设备发送同一推送消息，优先使用鸿蒙推送服务的批量推送功能（传入多个Token），避免循环调用推送API，减少服务器压力；同时，控制消息发送频率，避免短时间内发送大量消息，导致推送被限流。</li><li>推送消息监控。应用服务器需对接鸿蒙推送服务的消息统计接口，获取推送消息的发送量、到达率、点击率等数据，实时监控推送效果；对于到达率过低的场景，排查Token有效性、设备在线状态等问题；同时，记录每条消息的发送日志，便于后续追溯。</li></ol><h3>3.4 性能与安全最佳实践</h3><ol><li>性能优化：客户端避免频繁创建推送服务实例，复用推送服务对象；减少多设备同步的频率，采用“状态变化时同步”机制，避免定时同步消耗资源；应用服务器缓存常用数据（如Access Token、设备Token列表），减少重复请求与计算。</li><li>安全优化：推送消息传输时，采用HTTPS加密（鸿蒙推送API默认支持），避免消息被截取、篡改；自定义消息内容（data字段）时，可对敏感数据（如用户ID、订单信息）进行加密处理，确保数据安全；应用服务器的AppSecret需妥善保管，避免泄露（建议存储在配置文件中，不硬编码在代码中）。</li><li>合规性优化：推送消息需符合《个人信息保护法》《网络安全法》等相关法规，不推送违法、违规、低俗内容；推送广告类消息时，需提供“关闭推送”“拒收此类消息”的选项，尊重用户意愿；避免在夜间（如22:00-次日7:00）推送非紧急消息，避免打扰用户休息。</li></ol><h2>四、总结</h2><p>鸿蒙推送服务依托鸿蒙分布式架构优势，彻底解决了传统推送“平台碎片化、适配复杂、稳定性差”的痛点，为开发者提供了一套统一、高效、低耗的全场景推送解决方案，是鸿蒙应用实现消息触达、用户召回的核心支撑。本文通过“多设备消息推送与同步”案例，详细拆解了客户端与应用服务器的对接步骤，涵盖环境准备、推送服务注册、消息接收与处理、多设备同步等核心环节，同时总结了技术选型、开发实现、性能优化、安全保障等最佳实践，助力开发者快速上手鸿蒙推送功能开发。</p><p>在实际开发中，开发者需结合具体业务场景，合理配置推送服务参数，规范处理消息接收与交互逻辑，兼顾推送可靠性与用户体验；同时，关注鸿蒙推送服务的版本更新，及时适配新功能（如多设备消息接力、消息分类推送），充分发挥鸿蒙分布式生态的优势。随着鸿蒙生态的不断完善，推送功能将更加智能化、个性化，未来可结合AI技术实现用户画像分析、精准推送。</p>]]></description></item><item>    <title><![CDATA[让 Cursor AI 助手秒懂OceanBase seekdb向量数据库 —— Cursor se]]></title>    <link>https://segmentfault.com/a/1190000047609163</link>    <guid>https://segmentfault.com/a/1190000047609163</guid>    <pubDate>2026-02-13 12:06:57</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><strong>摘要：</strong><br/><strong><em>在AI辅助编程时代，开发者使用 Cursor 进行开发时，可能会因AI助手不熟悉OceanBase推出的AI原生搜索数据库 seekdb，无法获取精准的技术解答。seekdb Cursor Extension 可向 Cursor AI 注入官方文档知识，使其理解 seekdb 核心概念、提供合规代码建议并精准解答技术问题。该扩展支持一键安装与双模式文档检索，操作简便，能有效减少开发者查阅文档的时间，提升 seekdb 相关 AI 应用开发效率。</em></strong></p><p>本文将为大家介绍如何通过 seekdb Cursor Extension，让 Cursor AI 助手拥有 seekdb 专业知识，从而在大家基于 seekdb 进行 AI 应用开发的过程中获得精准的技术指导。</p><p><img width="723" height="410" referrerpolicy="no-referrer" src="/img/bVdnVtq" alt="" title=""/></p><h2>什么是 seekdb？</h2><p>seekdb 是由 OceanBase 推出的一款 AI 原生搜索数据库。它在单一引擎中统一了关系型数据、向量、文本、JSON 和 GIS 等多种数据模型，支持混合搜索和数据库内的 AI 工作流。</p><p>seekdb 的典型应用场景包括：</p><p>RAG 与知识检索：为大语言模型引入实时可信的外部知识，提升回答质量<br/>AI 辅助编程：为代码仓库构建向量和全文索引，实现基于语义的代码搜索<br/>语义搜索引擎：捕捉用户搜索意图，实现跨模态精准检索<br/>智能体（Agent）应用：为 AI Agent 提供记忆、规划、感知和推理的统一基础</p><h2>什么是 seekdb Cursor Extension？</h2><p>seekdb Cursor Extension 是一款 Cursor 扩展，它通过在 .cursor/rules 目录下添加规则，使 Cursor AI 助手能够检索 seekdb 官方文档，从而理解 seekdb 数据库知识，使其能够：</p><p>理解 seekdb 数据库概念：向量搜索、混合搜索、AI 函数等<br/>提供准确的代码建议：基于官方文档生成符合最佳实践的代码<br/>回答 seekdb 相关问题：直接在编辑器中获取技术支持<br/>加速开发流程：减少查阅文档的时间，专注于业务逻辑</p><p>核心特性</p><p>一键安装：通过 Cursor 扩展市场或命令面板快速安装<br/>完整文档：检索 seekdb 官方文档知识库，涵盖向量搜索、混合搜索、AI 函数等全面技术文档<br/>双模式支持：优先从 GitHub 获取最新文档，本地文档作为备份</p><h2>快速开始</h2><p>第一步：安装扩展</p><ol><li>在 Cursor 中打开扩展市场（Ctrl+Shift+X 或 Cmd+Shift+X）</li><li>搜索 "seekdb"</li><li>点击 Install 安装扩展</li></ol><p><img width="628" height="762" referrerpolicy="no-referrer" src="/img/bVdnVtr" alt="" title="" loading="lazy"/></p><p>第二步：添加 seekdb 文档</p><ol><li>使用 Cursor 打开一个项目目录（文档将添加到该目录下）</li><li>打开命令面板：<br/>Windows/Linux: 按 Ctrl+Shift+P<br/>macOS: 按 Cmd+Shift+P</li><li>输入并选择命令：<br/>输入 "seekdb" 或 "Add seekdb Docs"<br/>选择 Add seekdb Docs 命令</li><li>文档将自动添加：<br/>.cursor/rules/seekdb-docs 目录（官方文档）<br/>.cursor/rules/seekdb.mdc 文件（规则文件）</li><li>重新加载窗口使规则生效</li></ol><p><img width="658" height="306" referrerpolicy="no-referrer" src="/img/bVdnVtu" alt="" title="" loading="lazy"/></p><p>安装完成！现在你可以直接向 Cursor AI 助手询问任何 seekdb 相关问题了。</p><h2>实际效果演示</h2><p>让我们通过一个实际示例，看看 seekdb Cursor Extension 如何帮助你进行开发。</p><p><strong>示例：使用 AI 助手创建一个 seekdb 混合搜索应用</strong></p><p>安装扩展并添加文档后，在 Cursor 中开始一个新对话，输入以下问题：</p><p>例如：我想用 Python 创建一个简单的 seekdb 应用，实现文档的混合搜索功能，请帮我写代码。</p><p>Cursor AI 助手此时就会给出准确的回答：</p><p><img width="650" height="1488" referrerpolicy="no-referrer" src="/img/bVdnVtv" alt="" title="" loading="lazy"/></p><p><strong>运行示例</strong></p><ol><li>安装 pyseekdb</li></ol><p><img width="654" height="74" referrerpolicy="no-referrer" src="/img/bVdnVtC" alt="" title="" loading="lazy"/></p><ol start="2"><li>运行代码</li></ol><p><img width="654" height="78" referrerpolicy="no-referrer" src="/img/bVdnVtD" alt="" title="" loading="lazy"/></p><ol start="3"><li>查看结果</li></ol><p><img width="652" height="212" referrerpolicy="no-referrer" src="/img/bVdnVtQ" alt="" title="" loading="lazy"/></p><p>混合搜索结合了关键词匹配（包含 "机器学习" 的文档）和语义搜索（与 "AI 技术" 语义相近的文档），通过 RRF（Reciprocal Rank Fusion）算法融合两路检索结果，返回最相关的文档。</p><p>特别说明：seekdb 的嵌入式模式暂时只支持 Linux 服务器，如果是在 Mac 或者 Windows 本地测试，需要把 Python 代码里的 client = pyseekdb.Client() 改成服务器模式的连接地址（推荐在 Mac 或者 Windows 上使用 seekdb 桌面版）。</p><p><img width="658" height="234" referrerpolicy="no-referrer" src="/img/bVdnVtR" alt="" title="" loading="lazy"/></p><h2>更多使用场景</h2><p>安装 seekdb Cursor Extension 后，你可以向 AI 助手询问各种 seekdb 相关问题：</p><p>基础查询</p><p>如何开始使用 seekdb？<br/>seekdb 支持哪些部署模式？</p><p>技术问题</p><p>如何在 seekdb 中创建向量索引？<br/>seekdb 的 AI 函数有哪些？如何使用 AI_EMBED 函数？</p><p>代码示例</p><p>展示一个使用 seekdb SQL 实现向量相似度搜索的示例。<br/>如何将 seekdb 与 LangChain 集成？</p><p>集成相关</p><p>seekdb 如何配置 OpenAI 模型进行向量嵌入？</p><h2>工作原理</h2><p>seekdb Cursor Extension 的工作原理非常简单：</p><ol><li>规则文件注入：扩展将 seekdb 官方文档和 .mdc 规则文件添加到 .cursor/rules 目录</li><li>AI 上下文增强：Cursor 会自动读取 .cursor/rules 目录中的内容，作为 AI 助手的上下文知识</li><li>智能检索：当你询问 seekdb 相关问题时，AI 助手会基于这些文档提供准确的回答</li></ol><p><img width="304" height="292" referrerpolicy="no-referrer" src="/img/bVdnVtS" alt="" title="" loading="lazy"/></p><h2>移除文档</h2><p>如果你不再需要 seekdb 文档，可以轻松移除：</p><ol><li>打开命令面板（Ctrl+Shift+P 或 Cmd+Shift+P）</li><li>输入 "Remove seekdb Docs"</li><li>选择该命令执行</li></ol><p>文档将从 .cursor/rules 目录中移除。</p><h2>总结</h2><p>通过 seekdb Cursor Extension，你可以在使用 Cursor 进行开发时，随时获取 seekdb 的官方文档支持。无论是学习 seekdb 的新功能，还是解决开发中遇到的技术问题，AI 助手都能基于最新的官方文档提供准确的指导。</p><p>欢迎访问 OceanBase 官网获取更多信息：<a href="https://link.segmentfault.com/?enc=MaphOwOzMDyBq1V%2FdBoWcg%3D%3D.K8zA2IOpXsQPskzuNLibwVasRQPYxktC3cMCWOuahLY%3D" rel="nofollow" target="_blank">https://www.oceanbase.com/</a></p>]]></description></item><item>    <title><![CDATA[使用OpenClaw，token不够用？试试免费的token channg ]]></title>    <link>https://segmentfault.com/a/1190000047609168</link>    <guid>https://segmentfault.com/a/1190000047609168</guid>    <pubDate>2026-02-13 12:06:16</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>🚀 免费用 OpenClaw 跑大模型：对接硅基流动，注册送 2000 万 Token 教程</h2><p>最近 <strong>OpenClaw</strong> 很火，很多人已经开始用它搭建自动化 AI 工作流。</p><p>但一个现实问题是：</p><p><strong>模型 API 很贵，怎么低成本甚至免费跑？</strong></p><p>今天直接给你一个最简单教程：  <br/>用 OpenClaw 对接 <strong>硅基流动的免费模型</strong>，注册就送 <strong>2000 万 Token</strong>，足够你跑很久。</p><hr/><h3>第一步：注册硅基流动（拿 2000 万 Token）</h3><p>通过下面链接注册：</p><p>👉 <a href="https://link.segmentfault.com/?enc=nOpKSf8e4aECjfalgkB3pg%3D%3D.M2pge4gjn8OwvsN5KC97aA5dAOflvUf6%2B4KKTdUsHB%2BzVYlVcvgpSfmcqlpBd9JX" rel="nofollow" target="_blank">https://cloud.siliconflow.cn/i/i05xEFBt</a></p><p>注册完成后：</p><ul><li>自动获得 <strong>2000 万 Token</strong></li><li>后台可以创建 API Key</li><li>所有模型均为 OpenAI 兼容接口</li></ul><hr/><h3>第二步：获取 API 信息</h3><p>登录硅基流动后台：</p><ol><li>创建 API Key</li><li>复制 API Key</li><li>复制 Base URL（OpenAI 兼容接口地址）</li><li>查看可用免费模型名称</li></ol><hr/><h3>第三步：在 OpenClaw 中添加模型</h3><p>打开 OpenClaw，进入模型设置：</p><ol><li>添加 OpenAI 兼容模型</li><li>填写 Base URL（硅基流动提供的地址）</li><li>填写 API Key</li><li>填写模型名称（硅基流动后台可见）</li><li>保存</li></ol><p>配置完成。</p><hr/><h3>第四步：开始免费跑工作流</h3><p>现在你可以：</p><ul><li>用 OpenClaw 跑 Agent</li><li>批量生成内容</li><li>自动化写作</li><li>做新闻摘要</li><li>测试多模型工作流</li></ul><p>因为有 <strong>2000 万 Token</strong>，前期基本等于免费使用。</p><hr/><h3>为什么这样搭配更划算？</h3><p><strong>OpenClaw</strong> = 工作流调度层  <br/><strong>硅基流动</strong> = 模型聚合平台  </p><p>两者结合：</p><ul><li>统一接口</li><li>随时切换模型</li><li>成本可控</li><li>开发效率更高</li></ul><hr/><h3>总结</h3><p>如果你正在用 OpenClaw，又不想一开始就烧钱，  <br/>直接用硅基流动免费额度跑起来。</p><p>👉 <a href="https://link.segmentfault.com/?enc=t6vG5dcirFDLj36Y%2FCxvjQ%3D%3D.6QP7mTAvRnvXfYHxXWpwtpp1yOzwIApzSb%2Fh59%2FfvZthz6OOnxMT%2Bh%2FdJsxLFWVC" rel="nofollow" target="_blank">https://cloud.siliconflow.cn/i/i05xEFBt</a></p><p>先拿 2000 万 Token，再慢慢研究架构。</p><p><strong>免费跑模型，比什么都重要。</strong></p>]]></description></item><item>    <title><![CDATA[域名注册后无法解析解决方法：技术故障排查和解决指南 防火墙后吃泡面 ]]></title>    <link>https://segmentfault.com/a/1190000047609170</link>    <guid>https://segmentfault.com/a/1190000047609170</guid>    <pubDate>2026-02-13 12:05:45</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>域名解析作为连接域名与服务器的核心环节，直接决定用户能否通过域名正常访问网站数据，而域名注册后无法解析并非无解难题，只要找准问题根源，按步骤排查，无论是新手还是非专业人士，都能快速完成修复。</p><p>本文，国科云将详细拆解域名注册后无法解析解决方法，覆盖常见故障场景、分步排查流程，助力大家高效解决解析难题，顺利推进网站搭建。</p><h2>一、首先要明确域名注册≠域名解析</h2><p>首先我们要明确，域名注册与域名解析是两个独立且关联的环节：域名注册是“获取域名使用权”，相当于拿到了网站的“门牌号”；而域名解析是“给门牌号标注具体地址”，即将易记的域名转换为计算机可识别的服务器IP地址，让DNS服务器能精准指引用户访问请求找到对应服务器。很多人误以为域名注册成功后会自动解析，实则需要手动配置解析记录，若配置不当、状态异常或网络环境受限，都会出现域名注册后无法解析的情况。</p><h2>二、域名注册后无法解析的表现形式有哪些？</h2><p>我们要弄清楚域名注册后无法解析的常见表现症状，方便大家快速判断问题：</p><p>输入域名后浏览器提示“无法访问此网站”“DNS解析失败”“找不到服务器IP地址”；</p><p>部分浏览器显示“ERR_NAME_NOT_RESOLVED”错误代码；</p><p>同一域名在不同设备、不同网络下，部分能访问部分无法访问；</p><p>ping域名时提示“请求找不到主机”，nslookup查询时显示“服务器无响应”或解析结果异常。</p><p>这些都是域名注册后无法解析的典型症状，遇到此类情况无需慌乱。</p><h2>三、3步基础排查，快速定位简单故障</h2><p><strong>第一步：检查网络连接与设备状态</strong></p><p>域名注册后无法解析，有可能是本地网络或设备故障，而非域名本身问题。首先确认当前设备（电脑、手机）是否正常联网，可尝试访问百度、淘宝等常用网站，若所有网站均无法打开，说明是网络故障，而非域名解析问题。此时可重启路由器、光猫，等待5-10分钟后重新连接网络；若使用办公网络，可切换至手机热点测试，排除内网限制。另外，清理设备浏览器缓存（设置-隐私和安全-清除浏览数据），避免缓存异常导致的解析失败假象，部分浏览器会缓存旧的解析记录，清理后可重新尝试访问域名。</p><p><strong>第二步：清除本地DNS缓存，刷新解析记录</strong></p><p>本地DNS缓存异常是导致域名注册后无法解析的常见原因之一，尤其是刚完成域名解析配置后，本地缓存未及时更新，会导致解析失败。不同系统清除DNS缓存的方法不同，操作简单，无需专业技术：</p><p>Windows系统：按下“Win+R”组合键，输入“cmd”打开命令提示符，输入命令“ipconfig/flushdns”，按下回车，提示“成功刷新DNS解析缓存”即可；</p><p>Mac系统：打开终端，输入命令“sudo dscacheutil -flushcache”，输入电脑开机密码后回车，即可完成缓存清除；</p><p>手机系统：无需输入命令，直接重启手机，即可自动清除DNS缓存。清除缓存后，重新输入域名访问，若能正常打开，说明故障已解决，无需进一步排查。</p><p><strong>第三步：更换公共DNS服务器，排除DNS故障</strong></p><p>若本地网络和缓存均无问题，可尝试更换公共DNS服务器，排查是否是默认DNS服务器故障导致的域名注册后无法解析。默认情况下，设备会使用网络运营商提供的DNS服务器，部分运营商DNS服务器可能存在负载过高、解析延迟等问题，更换为稳定的公共DNS即可解决。</p><p>国内推荐公共DNS：114.114.114.114（最稳定，适配国内所有网络）；</p><p>国际推荐公共DNS：8.8.8.8（谷歌DNS）、1.1.1.1（Cloudflare DNS）；</p><p>操作方法：在设备网络设置中，找到“DNS服务器”选项，手动输入上述公共DNS地址，保存后重新连接网络，再次尝试访问域名。若更换后可正常解析，说明是原DNS服务器故障，可长期使用公共DNS提升解析稳定性。</p><h2>四、深入排查4大核心故障及对应解决方法</h2><p>若基础排查后，域名注册后无法解析的问题仍未解决，说明故障源于域名本身配置、状态或服务器层面，此时需要深入排查核心环节。</p><p>以下4种场景是域名注册后无法解析的最常见故障，每种场景对应具体的解决方法，精准匹配，高效修复。</p><p><strong>故障1：域名解析记录配置错误</strong></p><p>域名注册后，需要手动在域名注册商后台配置解析记录，若记录类型选错、IP地址填写错误，或未添加核心解析记录，都会导致无法解析。这是域名注册后无法解析解决方法中最核心的环节，也是新手最容易出错的地方。</p><p>解决方法：登录域名注册商（如国科云、阿里云、西部数码）的管理后台，找到“域名管理”板块，点击对应域名的“解析设置”，进入解析配置页面，重点检查3点：</p><ol><li>确认解析记录类型正确：搭建网站需添加A记录（指向服务器IPv4地址）或AAAA记录（指向IPv6地址），若使用虚拟主机、CDN加速，需添加CNAME记录（指向目标域名）；若用于企业邮箱，需添加MX记录，避免记录类型混淆导致解析失败。</li><li>检查记录值填写正确：A记录的“记录值”需填写服务器公网IP地址，确保无多余空格、无数字错误；CNAME记录的“记录值”需填写服务商提供的目标域名（如xxx.cloud.com），不可填写IP地址；MX记录需填写邮箱服务商提供的服务器地址，并设置正确的优先级（数值越小，优先级越高）。</li><li>确认主机记录完整：主机记录填写“@”（代表主域名，如xxx.com）或“www”（代表带www前缀的域名，如www.xxx.com），建议两者都添加，确保用户无论输入哪种域名都能正常访问。</li></ol><p>修改完成后，点击“保存”，解析记录生效需要10分钟至24小时（新添加的记录生效较快，修改现有记录生效时间取决于TTL设置，TTL值越小，生效越快，建议新手设置为10-60分钟）。生效后可通过“nslookup 域名”命令验证解析结果，若显示的IP地址与服务器IP一致，说明解析配置正确。</p><p><strong>故障2：域名状态异常，导致解析失效</strong></p><p>域名注册成功后，若状态异常（如过期、未实名认证、被锁定），会被注册商限制解析，导致域名注册后无法解析。这种情况下，即使解析记录配置正确，也无法正常访问，需优先恢复域名正常状态。</p><p>解决方法：首先通过Whois查询工具（域名注册商后台可直接查询）查看域名状态，根据不同异常状态针对性解决：</p><ol><li>域名未实名认证：国内域名（.cn、.com.cn等）强制要求实名认证，未实名认证的域名会被限制解析，登录注册商后台，提交身份证正反面、手机号等信息，完成实名认证（通常1-3个工作日审核通过），审核通过后解析即可生效；</li><li>域名过期：若域名显示“expired”（过期）状态，需立即在注册商后台续费，续费后等待1-2小时，域名状态恢复正常，解析即可恢复；建议开启域名自动续费功能，设置到期前30天提醒，避免因遗忘续费导致解析失效；</li><li>域名被锁定：若显示“clientHold”（客户锁定）或“serverHold”（服务器锁定），“clientHold”通常是因域名信息不实、违规使用被注册商锁定，需提交相关证明材料解锁；“serverHold”需联系域名注册局解决，一般较少出现。</li></ol><p><strong>故障3：DNS服务器配置错误或故障</strong></p><p>域名解析依赖DNS服务器，若域名所使用的DNS服务器宕机、配置错误，或未修改为注册商默认DNS，都会导致域名注册后无法解析。这种故障容易被忽视，排查时需重点关注DNS服务器设置。</p><p>解决方法：登录域名注册商后台，找到“DNS服务器设置”选项，确认当前DNS服务器是否为注册商默认DNS，若已修改为第三方DNS（如国科云解析DNS、Cloudflare），需确认第三方DNS服务器是否正常运行。</p><p>若怀疑DNS服务器故障，可临时更换为注册商默认DNS，保存后等待1-2小时，重新尝试解析；若第三方DNS服务器出现宕机，可联系第三方服务商排查，或暂时切换回默认DNS，保障解析正常。此外，若网站使用企业自建DNS服务器，需检查服务器是否正常运行，是否存在“区域传送”“递归查询”配置错误，这类问题需专业运维人员处理。</p><p><strong>故障4：网络安全策略或防火墙拦截</strong></p><p>部分企业内网、服务器防火墙或安全软件，会拦截DNS解析请求（DNS请求默认使用53端口），导致域名注册后无法解析，这种情况多出现于办公网络或已搭建服务器的场景。</p><p>解决方法：分两种场景针对性处理：</p><ol><li>本地网络拦截：若在办公网络中无法解析，切换至手机热点后可正常解析，说明是企业内网防火墙拦截，需联系公司网管，开放DNS解析相关端口（53端口），或添加域名至内网白名单；</li><li>服务器拦截：若域名已解析至服务器，但仍无法访问，需检查服务器防火墙（如Windows防火墙、Linux防火墙），确认是否禁止了53端口的出入站规则，开放53端口（允许DNS协议通过）后，重新测试解析；同时，临时关闭服务器上的杀毒软件、安全防护工具，排除软件误拦截的可能。</li></ol><h2>五、域名注册后无法解析的预防措施</h2><ol><li>开启自动续费，设置到期提醒：在域名注册商后台，开启域名自动续费功能，同时设置到期前30天提醒，避免因遗忘续费导致域名过期、解析失效，这是最基础的预防措施；</li><li>定期备份解析记录：每次修改解析记录后，截图备份或导出解析配置，当更换DNS服务商、误删解析记录时，可快速恢复配置，避免重复排查；</li><li>使用多DNS冗余配置：为域名配置2-3组不同服务商的DNS服务器（如注册商默认DNS+国科云解析DNS+自建DNS），即使其中一组DNS服务器故障，其他DNS可正常提供解析服务，提升解析稳定性；</li><li>定期监控解析状态：使用在线DNS查询工具（如DNSChecker.org、站长工具DNS查询），定期检测域名解析状态，若出现解析异常，可及时收到提醒，提前排查修复，避免故障扩大。</li></ol><p>综上，域名注册后无法解析并非难题，核心逻辑是“从基础到核心，从本地到远程”分步排查：先通过网络、缓存、DNS更换，解决简单故障；再排查解析记录、域名状态、DNS服务器、防火墙，解决核心故障，新手可按照本文步骤逐步操作，无需专业技术支撑，就能解决大部分的域名解析不生效的问题。</p>]]></description></item>  </channel></rss>