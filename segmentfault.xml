<?xml version="1.0" encoding="UTF-8"?><rss version="2.0">  <channel>      <title>SegmentFault - 最近文章</title>      <link>https://segmentfault.com/blogs/newest</link>      <description>SegmentFault 思否</description>      <generator>python segmentfault.py @Pi20</generator>      <item>    <title><![CDATA[GreatSQL优化技巧全解析：从硬件配]]></title>    <link>https://segmentfault.com/a/1190000047438891</link>    <guid>https://segmentfault.com/a/1190000047438891</guid>    <pubDate>2025-11-30 18:03:46</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在数据库性能优化领域，GreatSQL凭借其强大的优化器与MGR（Group Replication）集群能力，成为企业级应用的首选。本文将从硬件配置、操作系统调优、MGR集群优化、查询优化器特性四大维度，深度解析GreatSQL的性能提升策略，助力开发者突破性能瓶颈。</p><p>一、硬件配置：奠定性能基石</p><ol><li>CPU与内存：核心性能驱动<br/>CPU选择：优先采用高主频多核处理器（如Xeon Platinum系列），主频建议≥3.5GHz，核数根据业务负载动态调整。例如，MGR集群节点建议配置16核以上CPU，以支撑高并发事务处理。<br/>内存扩展：内存容量需覆盖InnoDB缓冲池（innodb_buffer_pool_size）需求，建议设置为物理内存的70%-80%。例如，64GB内存服务器可分配48GB给缓冲池，减少磁盘I/O压力。<br/>NUMA架构优化：X86架构建议关闭NUMA（numa_interleave=ON），避免内存访问延迟；ARM架构则可开启NUMA以提升多实例性能。</li><li>存储设备：I/O性能关键<br/>NVMe SSD部署：使用NVMe协议的SSD替代传统SATA SSD，将随机读写IOPS提升至百万级。例如，将数据库日志文件（binlog、redo log）存放于NVMe盘，可显著降低事务提交延迟。<br/>文件系统选择：XFS文件系统在高并发I/O场景下表现优异，其延迟分配（Delayed Allocation）机制可减少磁盘碎片，提升写入性能。</li><li>网络配置：低延迟保障<br/>网络带宽升级：MGR集群节点间建议采用万兆网络或InfiniBand，降低数据同步延迟。例如，在跨机房部署时，万兆网络可将主从复制延迟从毫秒级压缩至微秒级。<br/>MTU值调优：将网络MTU值设置为9000（Jumbo Frame），减少数据包分片，提升大事务传输效率。</li></ol><p>二、操作系统调优：释放硬件潜能</p><ol><li>内核参数优化<br/>关闭SWAP：通过swapoff -a命令永久禁用交换分区，避免内存不足时触发磁盘交换导致性能骤降。<br/>禁用透明大页（THP）：在/etc/sysctl.conf中添加vm.swappiness=0和vm.overcommit_memory=1，并执行echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled，防止OLTP型数据库因内存碎片化引发延迟。<br/>I/O调度器调整：将数据库分区的I/O调度器设置为noop或deadline，减少不必要的I/O合并，提升响应速度。</li><li>资源限制解除<br/>文件描述符限制：在/etc/security/limits.conf中设置<em> soft nofile 65535和</em> hard nofile 65535，避免因文件描述符不足导致连接失败。<br/>线程数限制：调整kernel.threads-max参数（如设置为200000），支持高并发查询场景。</li></ol><p>三、MGR集群优化：高可用与性能兼得</p><ol><li>流控模式选择<br/>关闭流控提升吞吐：在事务并发量适中的场景下，将group_replication_flow_control_mode设置为DISABLED，避免流控算法引入的性能抖动。例如，某金融客户在关闭流控后，集群TPS提升30%。<br/>动态阈值调整：若需开启流控，可将默认阈值（如group_replication_flow_control_member_quota_percent）提高至80%，平衡性能与稳定性。</li><li>从库回放并发度优化<br/>并行复制线程数：设置slave_parallel_workers为逻辑CPU核数的2倍（如32核服务器配置64个线程），加速从库数据回放。<br/>并行复制模式选择：采用LOGICAL_CLOCK模式（slave_parallel_type=LOGICAL_CLOCK），基于事务提交顺序分配并行任务，减少锁冲突。</li><li>大事务处理优化<br/>事务拆分：将单个大事务拆分为多个小事务，避免MGR队列阻塞。例如，某电商客户将每日全量数据同步拆分为每小时增量同步，集群稳定性显著提升。<br/>队列垃圾回收优化：通过调整group_replication_garbage_collection_interval参数（如设置为60秒），加速无用事务清理，释放内存资源。</li></ol><p>四、查询优化器特性：智能提升查询效率</p><ol><li>谓词下推（Predicate Pushdown）<br/>手动优化场景：当优化器未能自动下推复杂子查询条件时，可通过重写SQL手动实现。例如：<br/>sql<br/>-- 原始SQL（可能未优化）<br/>SELECT o.order_id, o.amount <br/>FROM orders o <br/>JOIN customers c ON o.customer_id = c.customer_id <br/>WHERE c.city = '上海' AND o.order_date &gt;= '2023-01-01';</li></ol><p>-- 手动优化后（将城市过滤下推至子查询）<br/>SELECT o.order_id, o.amount <br/>FROM orders o <br/>JOIN (<br/>  SELECT customer_id, customer_name <br/>  FROM customers <br/>  WHERE city = '上海'<br/>) c ON o.customer_id = c.customer_id <br/>WHERE o.order_date &gt;= '2023-01-01';<br/>此优化将数据量从全量客户表缩减至上海客户子集，连接操作效率提升50%。</p><ol start="2"><li>索引合并（Index Merge）<br/>多索引高效利用：当WHERE条件包含多个独立索引列时，优化器自动合并索引扫描结果。例如：<br/>sql<br/>-- 表结构<br/>CREATE TABLE t2 (<br/>  cc1 INT, cc2 INT, cc3 INT,<br/>  INDEX idx1(cc1), INDEX idx2(cc2), INDEX idx3(cc3)<br/>);</li></ol><p>-- 查询利用索引合并<br/>EXPLAIN SELECT * FROM t2 WHERE cc2=3 AND cc1=1 AND cc3=1;<br/>执行计划显示Using intersect(idx1,idx2)，表明优化器通过索引交集合并定位数据，避免全表扫描。</p><ol start="3"><li>半连接（Semi-Join）<br/>子查询高效执行：对于IN或EXISTS子查询，优化器自动选择最优半连接策略。例如：<br/>sql<br/>-- 子查询主键上拉示例<br/>SELECT * FROM t1 <br/>WHERE c2 IN (SELECT id FROM t2 WHERE t2.c1='b');<br/>优化器将子查询中的t2表上拉至外层，通过内连接（INNER JOIN）执行，消除重复值影响，查询速度提升3倍。</li><li>并行查询（Parallel Query）<br/>多核并行处理：通过loose-parallel_default_dop=8设置默认并行度，启用loose-force_parallel_execute=ON强制并行执行。例如，某分析查询在16核服务器上并行度设置为8后，执行时间从12秒缩短至2秒。</li></ol><p>五、实战案例：某电商平台的性能飞跃<br/>某电商平台在采用GreatSQL后，通过以下优化组合实现性能突破：</p><p>硬件升级：将数据库服务器从32核128GB内存升级至64核256GB内存，并采用NVMe SSD存储。<br/>MGR集群优化：关闭流控模式，设置并行复制线程数为128，大事务拆分为每小时增量同步。<br/>查询优化：对高频查询启用索引合并与并行查询，复杂报表查询速度提升10倍。<br/>监控告警：通过performance_schema监控慢查询，结合pt-query-digest分析瓶颈，持续迭代优化。<br/>优化后，平台日均订单处理量从500万笔提升至1200万笔，峰值TPS突破8万，且系统稳定性显著增强。</p><p>结语：优化永无止境<br/>GreatSQL的性能优化是一个系统工程，需从硬件、操作系统、集群配置、查询逻辑等多维度协同调优。开发者应结合业务场景，灵活运用本文所述技巧，并通过持续监控与压测验证优化效果。未来，随着AI与数据库技术的深度融合，GreatSQL将进一步释放性能潜力，为企业数字化转型提供更强支撑。</p>]]></description></item><item>    <title><![CDATA[征程 6 | linear 高精度输出配]]></title>    <link>https://segmentfault.com/a/1190000047438901</link>    <guid>https://segmentfault.com/a/1190000047438901</guid>    <pubDate>2025-11-30 18:02:53</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>1. 常规情况</h2><p>基础知识：</p><ol><li>考虑到模型输出位置量化损失对模型精度的影响较大，工具链推荐模型以 linear/conv 结尾，此时支持高精度 int32 输出（在 quantized.onnx 中，转定点为 int32，在前面 calib+qat 阶段都是 float32），这几乎可以做到无损。</li><li>征程 6 工具链量化 setter 模板支持自动设置高精度输出，前提是 conv 输出直接 接 dequant，不作为其他 node 的输入。</li></ol><p>输出位置结构示意图：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438903" alt="" title=""/></p><p>全流程代码如下：</p><pre><code class="Plain">import torch
from horizon_plugin_pytorch import set_march, March
set_march(March.NASH_M)
from horizon_plugin_pytorch.quantization import prepare, set_fake_quantize, FakeQuantState
from horizon_plugin_pytorch.quantization import QuantStub
from horizon_plugin_pytorch.quantization.hbdk4 import export
from horizon_plugin_pytorch.quantization.qconfig_template import (
    calibration_8bit_weight_16bit_act_qconfig_setter,
    qat_8bit_weight_16bit_fixed_act_qconfig_setter, 
    default_calibration_qconfig_setter,
    ModuleNameQconfigSetter
) 

from horizon_plugin_pytorch.quantization.qconfig import get_qconfig, MSEObserver, MinMaxObserver
from horizon_plugin_pytorch.dtype import qint8, qint16
from torch.quantization import DeQuantStub
import torch.nn as nn
from horizon_plugin_pytorch.quantization import hbdk4 as hb4
from hbdk4.compiler import convert, save, hbm_perf, visualize, compile

import torch
import torch.nn as nn

# 定义网络结构
class SmallModel(nn.Module):
    def __init__(self):
        super(SmallModel, self).__init__()
        # 第一个 Linear: 输入 [2, 100, 256] -&gt; 输出 [2, 100, 256]
        self.linear1 = nn.Linear(256, 256)
        self.layernorm = nn.LayerNorm(256)  # 对最后一维进行归一化
        self.relu = nn.ReLU()
        # 第二个 Linear: 输入 [2, 100, 256] -&gt; 输出 [2, 100, 60]
        self.linear2 = nn.Linear(256, 60)
        # 第三个 Linear: 输入 [2, 100, 60] -&gt; 输出 [2, 100, 60]
        self.linear3 = nn.Linear(60, 60)
        self.quant = QuantStub()
        self.dequant = DeQuantStub()

    def forward(self, x):
        x = self.quant(x)
        # 第一个 Linear
        x = self.linear1(x)  # [2, 100, 256]
        x = self.layernorm(x)  # [2, 100, 256]
        x = self.relu(x)  # [2, 100, 256]
        # 第二个 Linear
        y = self.linear2(x)  # [2, 100, 60]
        # 第三个 Linear
        z = self.linear3(y)
        z = self.dequant(z)
        return z

# 设置随机种子，保证每次生成的数据相同
torch.manual_seed(42)
example_input = torch.randn(2, 100, 256)
model = SmallModel()

# 前向传播
output_x = model(example_input)
print("输入形状:", example_input.shape)
print("输出形状:", output_x.shape)

# A global march indicating the target hardware version must be setted before prepare qat.
set_march(March.NASH_M)

calib_model = prepare(model.eval(), example_input, 
                      qconfig_setter=(
                          default_calibration_qconfig_setter,
                          ),
                      )

calib_model.eval()
set_fake_quantize(calib_model, FakeQuantState.CALIBRATION)
calib_model(example_input)

calib_model.eval()                            
set_fake_quantize(calib_model, FakeQuantState.VALIDATION)
calib_out_x = calib_model(example_input)
print("calib输出shape:", calib_out_x.shape)

qat_bc = export(calib_model, example_input)
# save(qat_bc, "qat.bc")
# visualize(qat_bc, "qat.onnx")
hb_quantized_model = convert(qat_bc, March.NASH_M)
# save(hb_quantized_model,"quantized.bc")
visualize(hb_quantized_model, "quantized_single.onnx")</code></pre><p>查看 quantized.onnx，可以看到最后一个 conv 确实是 int32 高精度输出</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438904" alt="" title="" loading="lazy"/></p><h2>2. 输出又输入</h2><p>如果 conv1，既作为模型输出，又作为后续 conv2 的输入，此时应该怎么办？</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438905" alt="" title="" loading="lazy"/></p><p>关键代码如下：</p><pre><code class="Plain">def forward(self, x):
        x = self.quant(x)
        # 第一个 Linear
        x = self.linear1(x)  # [2, 100, 256]
        x = self.layernorm(x)  # [2, 100, 256]
        x = self.relu(x)  # [2, 100, 256]
        # 第二个 Linear
        y = self.linear2(x)  # [2, 100, 60]
        y_out = self.dequant(y)
        y = self.quant_out(y_out)
        # y = self.quant_out(y)

        # 第三个 Linear
        z = self.linear3(y)
        z = self.dequant(z)
        return x, y_out</code></pre><p>注意，y\_out = self.dequant（y）是必须要添加的，否则无法实现该效果。</p><p>全流程代码如下：</p><pre><code class="Plain">import torch
from horizon_plugin_pytorch import set_march, March
set_march(March.NASH_M)
from horizon_plugin_pytorch.quantization import prepare, set_fake_quantize, FakeQuantState
from horizon_plugin_pytorch.quantization import QuantStub
from horizon_plugin_pytorch.quantization.hbdk4 import export
from horizon_plugin_pytorch.quantization.qconfig_template import (
    calibration_8bit_weight_16bit_act_qconfig_setter,
    qat_8bit_weight_16bit_fixed_act_qconfig_setter, 
    default_calibration_qconfig_setter,
    ModuleNameQconfigSetter
) 

from horizon_plugin_pytorch.quantization.qconfig import get_qconfig, MSEObserver, MinMaxObserver
from horizon_plugin_pytorch.dtype import qint8, qint16
from torch.quantization import DeQuantStub
import torch.nn as nn
from horizon_plugin_pytorch.quantization import hbdk4 as hb4
from hbdk4.compiler import convert, save, hbm_perf, visualize, compile

import torch
import torch.nn as nn

# 定义网络结构
class SmallModel(nn.Module):
    def __init__(self):
        super(SmallModel, self).__init__()
        # 第一个 Linear: 输入 [2, 100, 256] -&gt; 输出 [2, 100, 256]
        self.linear1 = nn.Linear(256, 256)
        self.layernorm = nn.LayerNorm(256)  # 对最后一维进行归一化
        self.relu = nn.ReLU()
        # 第二个 Linear: 输入 [2, 100, 256] -&gt; 输出 [2, 100, 60]
        self.linear2 = nn.Linear(256, 60)
        # 第三个 Linear: 输入 [2, 100, 60] -&gt; 输出 [2, 100, 60]
        self.linear3 = nn.Linear(60, 60)
        self.quant = QuantStub()
        self.quant_out = QuantStub()
        self.dequant = DeQuantStub()

    def forward(self, x):
        x = self.quant(x)
        # 第一个 Linear
        x = self.linear1(x)  # [2, 100, 256]
        x = self.layernorm(x)  # [2, 100, 256]
        x = self.relu(x)  # [2, 100, 256]
        # 第二个 Linear
        y = self.linear2(x)  # [2, 100, 60]
        y_out = self.dequant(y)
        y = self.quant_out(y_out)

        # 第三个 Linear
        z = self.linear3(y)
        z = self.dequant(z)
        return z, y_out

# 设置随机种子，保证每次生成的数据相同
torch.manual_seed(42)
example_input = torch.randn(2, 100, 256)
model = SmallModel()

# 前向传播
output_x, output_y = model(example_input)
print("输入形状:", example_input.shape)
print("输出形状:", output_x.shape, output_y.shape)

# A global march indicating the target hardware version must be setted before prepare qat.
set_march(March.NASH_M)

calib_model = prepare(model.eval(), example_input, 
                      qconfig_setter=(
                          default_calibration_qconfig_setter,
                          ),
                      )

calib_model.eval()
set_fake_quantize(calib_model, FakeQuantState.CALIBRATION)
calib_model(example_input)

calib_model.eval()                            
set_fake_quantize(calib_model, FakeQuantState.VALIDATION)
calib_out_x, calib_out_y= calib_model(example_input)
print("calib输出shape:", calib_out_x.shape)

qat_bc = export(calib_model, example_input)
# save(qat_bc, "qat.bc")
# visualize(qat_bc, "qat.onnx")
hb_quantized_model = convert(qat_bc, March.NASH_M)
# save(hb_quantized_model,"quantized.bc")
visualize(hb_quantized_model, "quantized.onnx")</code></pre><p>查看 quantized.onnx，linear2 符合预期，确实是 int32 高精度输出。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438906" alt="" title="" loading="lazy"/></p><p>新加入的 dequant 与 quant 会变成 rescale</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438907" alt="" title="" loading="lazy"/></p><p>以上是征程 6EM 的默认做法，如果使用的是征程 6PH，conv like 算子输出直接就是 float32，在既作为输出，又作为下一阶段输入时，会存在 vpu 的 quantize（float32-&gt;int16/int8），如下图所示</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438908" alt="" title="" loading="lazy"/></p><p>如果想依旧沿用征程 6EM 的方式，可进行如下配置：</p><pre><code class="Plain">qat_bc._integer_conv = True
hb_quantized_model = convert(qat_bc, "nash-h")</code></pre><p>具体选择哪种方式可实测 latency（建议考虑将模型 conv like 算子 c++ 反量化的耗时减少也加进去对比）</p>]]></description></item><item>    <title><![CDATA[【卫星图像识别系统】Python+Ten]]></title>    <link>https://segmentfault.com/a/1190000047438926</link>    <guid>https://segmentfault.com/a/1190000047438926</guid>    <pubDate>2025-11-30 18:02:03</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>一、介绍</h2><p>卫星影像识别系统，基于TensorFlow搭建卷积神经网络算法，通过对7种常见的卫星遥感影像图片数据集（'草地（Grass）', '农田（Field）', '工业区（Industry）', '河流湖泊（RiverLake）', '森林（Forest）', '居民区（Resident）', '停车场（Parking）'）进行训练，最后得到一个识别精度较高的模型，然后搭建Web可视化操作平台。</p><p><strong>前端</strong>: Vue3、Element Plus</p><p><strong>后端</strong>：Django</p><p><strong>算法</strong>：TensorFlow、卷积神经网络算法</p><p><strong>具体功能</strong>：</p><ol><li>系统分为管理员和用户两个角色，登录后根据角色显示其可访问的页面模块。</li><li>登录系统后可发布、查看、编辑文章，创建文章功能中集成了markdown编辑器，可对文章进行编辑。</li><li>在图像识别功能中，用户上传图片后，点击识别，可输出其识别结果和置信度</li><li>基于Echart以柱状图形式输出所有种类对应的置信度分布图。</li><li>在智能问答功能模块中：用户输入问题，后台通过对接Deepseek接口实现智能问答功能。</li><li>管理员可在用户管理模块中，对用户账户进行管理和编辑。</li></ol><p><strong>选题背景与意义</strong>：<br/>随着遥感技术的快速发展，卫星影像数据呈现爆发式增长，如何高效、精准地识别与利用这些数据，已成为资源监测、环境评估和城乡规划等领域的重要课题。传统人工判读方式效率低、主观性强，难以满足大规模应用需求。为此，本项目基于TensorFlow构建卷积神经网络模型，针对草地、农田、工业区、河流湖泊、森林、居民区及停车场等七类典型地物进行识别训练，旨在开发一个具备较高识别精度的自动化分类系统。为进一步提升系统的实用性与交互体验，项目结合Django与Vue3等主流技术，搭建了集用户管理、图像识别、结果可视化及智能问答于一体的Web操作平台。该系统不仅实现了地物类型的智能识别与置信度分析，还通过集成Markdown编辑与DeepSeek问答接口，拓展了知识管理与交互支持功能，为遥感数据的智能化应用提供了便捷、高效的解决方案。</p><h2>二、系统效果图片展示</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438928" alt="图片" title="图片"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047438929" alt="图片" title="图片" loading="lazy"/></p><h2>三、演示视频 and 完整代码 and 安装</h2><p>地址：<a href="https://link.segmentfault.com/?enc=wyUaSD2PvQ6kaogAN80woA%3D%3D.LOXg8rkgKqlioCPmBMNU58Fq5295P9qE6yiO4kSPrS4%3D" rel="nofollow" target="_blank">https://ziwupy.cn/p/6eby8p</a></p><h2>四、卷积神经网络算法介绍</h2><p>ResNet50是由微软研究院提出的深度残差网络（Residual Network）的一个经典模型，其核心创新是“残差学习”思想。在传统的深度卷积神经网络中，简单地堆叠层数会遇到“梯度消失/爆炸”问题，导致网络难以训练，性能甚至下降，这被称为“退化问题”。</p><p>ResNet通过引入“快捷连接”或“跳跃连接”巧妙地解决了这一问题。它不再让多个堆叠的层直接学习一个目标映射H(x)，而是让这些层学习其与输入x之间的残差F(x) = H(x) - x。这样，原始的目标映射就变成了 H(x) = F(x) + x。</p><p>这种“捷径”将输入x直接传递到更深层的输出，实现了恒等映射。这样做有两个主要好处：</p><ol><li><strong>缓解梯度消失</strong>：梯度可以直接通过快捷连接反向传播，使得深层网络的训练变得可行。</li><li><strong>简化学习目标</strong>：让网络学习残差F(x)通常比学习完整的映射H(x)更容易，尤其是在F(x)趋近于0时，该层就近似做了恒等变换，避免了性能退化。</li></ol><p>ResNet50因其包含50个权重层而得名，它通过大量使用这种带有快捷连接的“瓶颈结构”模块，在保持高性能的同时，显著减少了参数量，成为图像识别领域一个里程碑式的模型。</p><p>以下是一个使用TensorFlow Keras中预训练的ResNet50模型进行图像识别的简单示例。</p><pre><code class="python">import tensorflow as tf
from tensorflow.keras.applications.resnet50 import ResNet50, decode_predictions, preprocess_input
import numpy as np
from PIL import Image

# 1. 加载预训练的ResNet50模型（包含在ImageNet上训练得到的权重）
model = ResNet50(weights='imagenet')

# 2. 加载并预处理图像
img_path = 'your_image.jpg' # 替换为你的图片路径
image = Image.open(img_path).convert('RGB') # 确保为RGB格式
image = image.resize((224, 224)) # ResNet50要求输入尺寸为224x224

# 将图像转换为数组并扩展维度以匹配模型输入要求 (batch_size, height, width, channels)
image_array = np.array(image)
image_array = np.expand_dims(image_array, axis=0)

# 对图像进行与训练时相同的预处理
image_array = preprocess_input(image_array)

# 3. 使用模型进行预测
predictions = model.predict(image_array)

# 4. 解码预测结果，得到人类可读的标签和置信度
decoded_predictions = decode_predictions(predictions, top=3)[0] # 显示最可能的3个结果

# 5. 打印结果
print("识别结果：")
for i, (imagenet_id, label, score) in enumerate(decoded_predictions):
    print(f"{i+1}: {label} ({score * 100:.2f}%)")</code></pre><p>这段代码演示了利用预训练ResNet50模型进行图像识别的标准流程。首先，我们直接加载了在ImageNet数据集上预训练好的模型，无需从头训练。然后，将输入图像调整为224x224像素，并进行归一化等预处理。接着，模型对图像进行前向传播推理，输出一个包含1000个ImageNet类别概率的向量。最后，通过<code>decode_predictions</code>函数将概率向量解码为易于理解的对象标签和置信度，并打印出最可能的三个预测结果。这种方法让我们能够快速、高效地将强大的ResNet50模型应用于实际的图像识别任务中。</p>]]></description></item><item>    <title><![CDATA[【民族服饰识别系统】Python+Ten]]></title>    <link>https://segmentfault.com/a/1190000047438935</link>    <guid>https://segmentfault.com/a/1190000047438935</guid>    <pubDate>2025-11-30 18:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>一、介绍</h2><p>民族服饰识别，民族服饰智能识别与分析系统基于TensorFlow框架，采用卷积神经网络（CNN）算法构建而成。系统在收集了回族、汉族、满族、苗族四类典型民族服饰图像数据集的基础上，通过多轮迭代训练，最终生成高精度识别模型，并配合Web可视化平台实现便捷交互。</p><p><strong>前端</strong>: Vue3、Element Plus</p><p><strong>后端</strong>：Django</p><p><strong>算法</strong>：TensorFlow、卷积神经网络算法</p><p><strong>具体功能</strong>：</p><ol><li>系统分为管理员和用户两个角色，登录后根据角色显示其可访问的页面模块。</li><li>登录系统后可发布、查看、编辑文章，创建文章功能中集成了markdown编辑器，可对文章进行编辑。</li><li>在图像识别功能中，用户上传图片后，点击识别，可输出其识别结果和置信度</li><li>基于Echart以柱状图形式输出所有种类对应的置信度分布图。</li><li>在智能问答功能模块中：用户输入问题，后台通过对接Deepseek接口实现智能问答功能。</li><li>管理员可在用户管理模块中，对用户账户进行管理和编辑。</li></ol><p><strong>选题背景与意义</strong>：<br/>随着人工智能技术的快速发展，计算机视觉在文化传承与保护领域的应用日益广泛。民族服饰作为民族文化的重要载体，其识别与分类对于文化研究与数字化保护具有积极意义。传统人工识别方式效率有限，难以适应大规模图像处理需求。基于此背景，本研究旨在开发一套基于深度学习的民族服饰智能识别与分析系统。系统采用TensorFlow框架，基于卷积神经网络（CNN）构建高精度识别模型，实现对回族、汉族、满族、苗族四类典型民族服饰的自动化识别。通过集成Web可视化平台，系统不仅提供图像识别、置信度分析和可视化图表展示等核心功能，还结合内容管理与智能问答模块，构建了集文化识别、知识传播与交互体验于一体的综合平台，为民族文化的数字化保护与推广提供了有效的技术支撑。</p><h2>二、系统效果图片展示</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438937" alt="图片" title="图片"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047438938" alt="图片" title="图片" loading="lazy"/></p><h2>三、演示视频 and 完整代码 and 安装</h2><p>地址：<a href="https://link.segmentfault.com/?enc=Pq9s7g%2BUpI038ZxwufiFwA%3D%3D.1L7AHrCJLzWM%2B86e%2BFZpFTazSD6H3czZWdJRnccTzUE%3D" rel="nofollow" target="_blank">https://ziwupy.cn/p/ekFQTD</a></p><h2>四、卷积神经网络算法介绍</h2><p>卷积神经网络是一种专为处理网格状数据（如图像）而设计的深度学习算法。其核心思想是通过“卷积”操作，自动地从图像中提取由浅到深的特征。</p><p><strong>主要构成层：</strong></p><ol><li><strong>卷积层：</strong> 是CNN的核心。它使用多个可学习的“滤波器”（或称“卷积核”）在输入图像上滑动，通过计算局部区域的点积来提取特征（如边缘、角点、纹理等）。通过堆叠多个卷积层，网络可以学习到从简单到复杂（如物体部件、整体轮廓）的层次化特征。</li><li><strong>池化层：</strong> 通常跟在卷积层之后，用于对特征图进行下采样。它通过取局部区域的最大值或平均值，来减小数据尺寸，降低计算量，同时增强模型对目标位置微小变化的鲁棒性（即“平移不变性”）。</li><li><strong>全连接层：</strong> 在网络的末端，将经过多轮卷积和池化后提取出的高级特征图展平，然后进行综合判断，最终输出每个类别的概率。</li></ol><p>CNN通过这种“局部连接”和“权值共享”（同一个滤波器扫描整张图片）的机制，极大地减少了参数数量，使其能够高效地处理图像，并成为图像识别领域最主流的算法。</p><p>以下是一个使用TensorFlow和Keras API构建一个简单的CNN模型，用于对MNIST手写数字数据集进行分类的示例。</p><pre><code class="python">import tensorflow as tf
from tensorflow.keras import datasets, layers, models

# 1. 加载并预处理数据
(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()
# 将图像数据重塑为 (28, 28, 1) 的形状，并归一化到 [0, 1] 区间
train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255
test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255

# 2. 构建CNN模型
model = models.Sequential([
    # 第一个卷积块：卷积 + 池化
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    layers.MaxPooling2D((2, 2)),
    
    # 第二个卷积块：卷积 + 池化
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    
    # 将特征图展平，输入到全连接层
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    # 输出层，10个神经元对应10个数字类别，使用softmax激活函数输出概率
    layers.Dense(10, activation='softmax')
])

# 3. 编译模型
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# 4. 训练模型
model.fit(train_images, train_labels, epochs=5, 
          validation_data=(test_images, test_labels))

# 5. 评估模型
test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)
print(f'\n测试准确率：{test_acc}')</code></pre><p>以上代码完整展示了使用CNN进行图像识别的流程。首先，数据被加载并预处理成适合网络的格式。接着，我们构建了一个顺序模型，它包含两个卷积-池化层组合，用于特征提取，之后是展平操作和全连接层进行分类。模型使用<code>adam</code>优化器和交叉熵损失函数进行编译。最后，通过<code>fit</code>方法在训练数据上进行5轮训练，并在测试集上评估最终性能。这个简单的模型能很快地在MNIST数据集上达到很高的准确率，清晰地演示了CNN在图像识别任务中的强大能力和基本工作流程。</p>]]></description></item><item>    <title><![CDATA[Omnissa Dynamic Envi]]></title>    <link>https://segmentfault.com/a/1190000047438859</link>    <guid>https://segmentfault.com/a/1190000047438859</guid>    <pubDate>2025-11-30 17:01:55</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>Omnissa Dynamic Environment Manager 2509 - 个性化动态 Windows 桌面环境管理</p><p>Simplify management of user profiles, environment settings, and policies across desktops and apps.</p><p>请访问原文链接：<a href="https://link.segmentfault.com/?enc=Om3KNyDDw2aEu7hPvHPa3Q%3D%3D.R%2BomsM3Ev3LmYToSG6jE%2FqriUIujx50XKaWrjuByxbAzopjb3%2BUov1otrV5lXbFVzKGCtli%2FElvd6DR3OKMqSw%3D%3D" rel="nofollow" target="_blank">https://sysin.org/blog/omnissa-dynamic-environment-manager/</a> 查看最新版。原创作品，转载请保留出处。</p><p>作者主页：<a href="https://link.segmentfault.com/?enc=BZe8VTrld6vnXWDrzR6Zhg%3D%3D.DbZXXgTShsNv%2BpwDLo%2F5Zubb%2BzyExFssDL5WGGGFfU4%3D" rel="nofollow" target="_blank">sysin.org</a></p><hr/><p><img referrerpolicy="no-referrer" src="/img/remote/1460000046037272" alt="Omnissa Horizon 架构图" title="Omnissa Horizon 架构图"/></p><p>Omnissa Dynamic Environment Manager</p><p>简化跨桌面和应用程序的用户配置文件、环境设置和策略的管理。</p><h2>产品简介</h2><p>Dynamic Environment Manager 为最终用户提供个性化的动态 Windows 桌面。通过 Dynamic  Environment Manager，您可以根据用户的角色、设备和位置提供对 IT  资源的访问来自定义桌面。通过这种方式，您可以创建适应用户特定需求的桌面。</p><p>Omnissa Dynamic Environment Manager 标准版和企业版</p><p>Omnissa Dynamic Environment Manager 提供标准版和企业版。</p><p><strong>标准版</strong> 专为寻求基本用户环境管理和应用程序控制的组织而设计。标准版可帮助 Omnissa Horizon® 标准版和 Omnissa Horizon® 高级版客户进行用户配置文件管理。</p><p><strong>企业版</strong> 专为需要高级管理、详细的应用程序分析以及复杂的自动化和集成功能的大型或复杂环境而设计。企业版是 Omnissa Dynamic Environment Manager 的全功能版本。</p><h3>版本比较</h3><table><thead><tr><th>特征</th><th>标准版</th><th>企业版</th></tr></thead><tbody><tr><td>用户环境</td><td>DEM 标准版提供以下选项。  - 驱动器映射   - 文件夹重定向   - 登录和注销任务   - 打印机映射</td><td>✓</td></tr><tr><td>计算机环境</td><td>x</td><td>✓</td></tr><tr><td>个性化</td><td>支持所有功能，但在 Flex 配置文件上可配置的某些用户环境设置除外。  可以在 Flex 配置文件上配置以下用户环境设置。  - 驱动器映射   - 打印机映射   - 任务</td><td>✓</td></tr><tr><td>同步工具</td><td>✓</td><td>✓</td></tr><tr><td>自助工具</td><td>✓</td><td>✓</td></tr><tr><td>帮助台支持工具</td><td>✓</td><td>✓</td></tr><tr><td>条件集</td><td>✓</td><td>✓</td></tr><tr><td>应用分析器</td><td>✓</td><td>✓</td></tr><tr><td>应用程序迁移</td><td>x</td><td>✓</td></tr><tr><td>与 Omnissa Horizon 集成</td><td>x</td><td>✓</td></tr><tr><td>基于触发器的操作</td><td>x</td><td>✓</td></tr></tbody></table><h3>部署模式</h3><p>Dynamic Environment Manager 可在独立模式和集成模式下使用。两种模式都使用配置文件进行 Dynamic Environment Manager 的个性化和应用程序配置管理。</p><table><thead><tr><th>独立模式 (Standalone mode)</th><th>整合模式 (Integration mode)</th></tr></thead><tbody><tr><td>当您想要独立配置 Dynamic Environment Manager 时，请使用独立模式。</td><td>使用集成模式将 Dynamic Environment Manager 与 Omnissa Workspace ONE® UEM 集成。</td></tr><tr><td>配置文件存储在配置 SMB 共享中，该共享是文件服务器上的中央共享。</td><td>配置文件包含在 Dynamic Environment Manager 配置文件中。使用 Workspace ONE UEM，您可以将  Dynamic Environment Manager 配置文件文件定位到特定智能组 (sysin)，以将 Dynamic  Environment Manager 配置分发到 Workspace ONE UEM 端点。</td></tr></tbody></table><h2>新增功能</h2><p>Omnissa Dynamic Environment Manager 2509 | 2025 年 10 月 30 日 | 内部版本 10.17.0.2322</p><ul><li><strong>计算机环境配置</strong>。管理员现在也可以直接管理<strong>计算机环境</strong>的环境变量、文件和文件夹以及注册表设置。这能提供您在用户上下文中所熟悉的相同体验，而无需依赖于启动任务或自定义脚本。</li><li><strong>增强了 Windows 通用设置、应用程序模板和 Easy Start</strong>。更新了 Windows 通用设置和应用程序模板，以支持 Windows 11 场景，改进了 Office 覆盖范围，并移除了过时的项目。现有配置将继续正常运行。使用较新的定义更新引用的模板时，管理控制台会提供升级提示。</li><li><p><strong>向“文件版本”(File Version) 条件添加了比较运算符</strong>。使用更新的“文件版本”(File Version) 条件精确定位目标体验。除了“is equal to”（等于）之外，还支持以下比较运算符：</p><ul><li>“is not equal to”（不等于）</li><li>“is less than”（小于）</li><li>“is less than or equal to”（小于或等于）</li><li>“is greater than”（大于）</li><li>“is greater than equal to”（大于或等于）</li></ul></li><li>添加了一个新设置，可在目标/命令不存在时跳过快捷方式或文件类型关联。</li><li><strong>最新操作系统支持</strong>。Dynamic Environment Manager 现在支持 Windows 11 25H2。</li><li><strong>更新的组件</strong>。此版本更新了主要产品组件。应用程序分析器、Helpdesk Support 工具和 SyncTool 未更新。</li></ul><h2>下载地址</h2><p>Omnissa Dynamic Environment Manager Enterprise 2506, Release Date 2025-10-30</p><ul><li>下载地址：<a href="https://link.segmentfault.com/?enc=M%2BoIn%2Bc4X%2F4bZqN3%2Bku%2Bzg%3D%3D.N%2FIhFMP0srItoojJvhZZf4Rk0z5JeG5h7h6qPoMsZX9684hca9HbqxBxwGx%2FQ9RR37%2FTvd9flvDsj78FkhXo9w%3D%3D" rel="nofollow" target="_blank">https://sysin.org/blog/omnissa-dynamic-environment-manager/</a></li><li>Omnissa Dynamic Environment Manager<br/>File size: 35.95 MB<br/>Name: Omnissa-DEM-Enterprise-2509-10.17.zip</li></ul><p>更多：<a href="https://link.segmentfault.com/?enc=WZBVgNrgvdvq73dnuj8kmg%3D%3D.4C5ZygawV9k1UvYrTUyV6ICm%2BAIHP17bzgch%2FbDqZzs%3D" rel="nofollow" target="_blank">VMware 产品下载汇总</a></p>]]></description></item><item>    <title><![CDATA[征程 6 | QAT 新版 qconfi]]></title>    <link>https://segmentfault.com/a/1190000047438875</link>    <guid>https://segmentfault.com/a/1190000047438875</guid>    <pubDate>2025-11-30 17:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>1.前言</h2><p>随着 征程 6 芯片家族的阵容不断壮大，算法工具链在量化精度方向的优化也在持续深入，具体体现在两个方面：</p><ol><li>征程 6P 与 征程 6H 工具链已陆续进入发布和试用阶段，在此背景下，QAT（量化感知训练）需要以更高效的方式适配算子的浮点计算能力，以确保量化精度和用户的使用体验；</li><li>MatMul、Conv、Linear 等 Gemm 类算子目前已正式支持双 int16 输入，这一改进有助于提升相关算子在量化计算时的精度和调优时的效率。</li></ol><p>为了更全面、稳妥地支持上述新功能，同时对当前的 qconfig 量化配置以及回退逻辑进行优化升级，工具链从 OE3.5.0 开始支持新版 qconfig 量化模板。新版本针对 qconfig 模板开展了大量的重构工作，重构后的 qconfig 模板不仅能更好地适配新的芯片特性和算子功能，还同时保持对旧版本 qconfig 的维护，保障了用户在升级过程中的平滑过渡，减少了因版本迭代带来的适配成本。</p><h2>2.新版 qconfig 模板配置流程</h2><p>本章将系统且全面地为大家呈现新版 qconfig 模板的核心内容，涵盖其关键更新点、规范的基本使用流程以及对相关产出物的详细介绍。</p><h3>2.1 主要更新点</h3><p>在更新点方面，新版 qconfig 模板的迭代升级紧密贴合 征程 6 平台家族的持续发展以及工具链不断优化的实际需求，通过针对性的设计与调整，进一步提升了量化配置的效率、灵活性与适配性。其与旧版流程的区别主要体现在以下四个方面：</p><ol><li><strong>​模板与回退机制的统一管理：​</strong>将模板和回退进行了统一，在同一个流程下管理；</li><li><strong>​强化对特定量化配置的友好性：​</strong>对浮点计算的量化配置、Conv/Matmul 等 Gemm 算子单/双 int16 输入配置更加友好；</li><li><strong>​fuse 默认行为的调整与优化：​</strong>旧模板默认 conv-bn-add-relu 全部 fuse，然后再根据硬件限制回退至 int8。为了实现更高的计算精度，新模板首先配置 dtype，若不符合要求则不做 fuse，最终 dtype 结果更加符合预期，而且针对不同芯片架构的硬件特性设计了不同的 fuse 行为；</li><li><strong>​新增量化配置文件保存功能：​</strong>支持保存量化配置文件 <code>qconfig_dtypes.pt</code>、<code>qconfig_dtypes.pt.py</code> 以及 <code>qconfig_changelogs.txt</code>。其中，<code>qconfig_dtypes.pt</code> 为可供用户加载的算子级别的量化配置文件，实现了配置的便捷迁移与共享；<code>qconfig_dtypes.pt.py</code>​<code> </code> 则以 Python 脚本形式保存配置信息，便于用户查看；<code>qconfig_changelogs.txt</code> 则记录了配置过程中的算子变更日志，包括量化参数调整记录、模板使用信息等，为配置的追溯、调试提供了清晰的依据，进一步提升了量化配置的可解释性与可复用性。</li></ol><h3>2.2 基本使用流程</h3><p>新版 qconfig 模板在使用流程上围绕基础 qconfig 配置 reference\_qconfig、templates 量化模板配置展开，各环节紧密关联，共同助力用户实现高效、精准的量化配置。新版 qconfig 模板的基本使用流程如下所示：</p><pre><code class="Plain">import torch
import torch.nn as nn 
from horizon_plugin_pytorch.quantization import  prepare,set_fake_quantize,FakeQuantState
from horizon_plugin_pytorch.dtype import qint8,qint16
from horizon_plugin_pytorch.quantization.qconfig_setter import *
from horizon_plugin_pytorch.quantization.observer_v2 import MinMaxObserver,MSEObserver,FixedScaleObserver

my_qconfig_setter=QconfigSetter( 
     #1.基础qconfig,获取默认配置和observer
     reference_qconfig=get_qconfig(observer=MSEObserver),
     #2.模板，仅关注dype,按照顺序生效，前面模板的配置可被后面的模板覆盖。因此模板的顺序很重要
     templates=[
        ...
            ],
     #3.采用默认的优化模板
     enable_optimize=True,
     #4.qconfig模板配置文件保存路径
     save_dir=args.save_path,
        )
float_model.eval()
qat_model = prepare(
    float_model,
    example_inputs=example_input,
    qconfig_setter=my_qconfig_setter,
    check_result_dir=args.save_path
    )</code></pre><p>以上就是新版 qconfig 模板的基本使用流程，下面将对其核心部分 QconfigSetter 接口和工具链提供的多个 templates 进行介绍。</p><h4>2.2.1 QconfigSetter 接口介绍</h4><p>QconfigSetter 接口的定义如下所示：</p><blockquote>代码路径：horizon_plugin_pytorch/quantization/qconfig_setter/qconfig_setter.py</blockquote><pre><code class="Plain">class QconfigSetter(ModernQconfigSetterBase):
    """Manage qconfig settings of a model.

    Args:
        reference_qconfig: Qconfig to provide observer.
        templates: Qconfig templates, will be applyed in order.
        enable_optimize: Whether enable the default optimize.
        save_dir: Save directory of qconfig settings.
        custom_qconfig_mapping: Custom mapping from mod name to qconfig.
            CAUTION: This mapping will overwrite the dtype setted by templates.
                     You'd better not change dtype through this argument, or
                     the config result will not be optimal (Model may contain
                     CPU ops on board, for example).
            Defaults to None.
        enable_attribute_setting: Whether enable the qconfig setted through
            qconfig attribute.
        enable_propagate: Whether enable propagate for custom_qconfig_mapping
            and qconfig attr. Defaults to False.
    """

    def __init__(
        self,
        reference_qconfig: QConfig,
        templates: Sequence[TemplateBase],
        enable_optimize: bool = True,
        save_dir: str = "./qconfig_setting",
        custom_qconfig_mapping: Optional[Dict[str, QConfig]] = None,
        enable_attribute_setting: bool = False,
        enable_propagate: bool = False,
    ):
        super().__init__(reference_qconfig)
        self.templates = list(templates)
        self.enable_optimize = enable_optimize
        self.save_dir = save_dir

        if custom_qconfig_mapping is None:
            custom_qconfig_mapping = {}
        self.custom_qconfig_mapping = {
            k: canonicalize_qconfig(v)
            for k, v in custom_qconfig_mapping.items()
        }
        self.enable_attribute_setting = enable_attribute_setting
        self.enable_propagate = enable_propagate

        if save_dir is not None:
            os.makedirs(save_dir, exist_ok=True)</code></pre><ul><li><strong>​reference\_qconfig【必要配置】：​</strong>配置 observer，可选项包括 MSEObserver 、MinMaxObserver 等。</li><li><strong>​templates【必要配置】：​</strong>配置使用到的 qconfig 模板，仅关注 dtype，按照顺序依次生效。</li><li><p><strong>enable\_optimize【必要配置-用户可不关注】: ​</strong>是否采用默认的优化 pass，默认配置为 True，相关优化如下：</p><ul><li><p><code>CanonicalizeTemplate</code>： 按算子类型对 dtype 配置进行合法化，当前默认规则有：</p><ul><li>Gemm 类算子输入不支持 float</li><li>插值类算子：在不同 march 下有不同的限制</li><li>DPP、RPP 等特殊算子仅支持 int8</li><li>其他算子的通用规则：算子的 input dtype 和 output dtype 不能同时存在 qint 和 float</li></ul></li><li><p><code>EqualizeInOutScaleTemplate</code>：对于 relu，concat，stack 算子，应该在算子输出统计 scale，否则精度或性能存在损失。为此：</p><ul><li>将前面算子的 output dtype 配置为 float32</li><li>Relu，concat，stack 算子在 export hbir 时，在 input 处插入伪量化，scale 复用 output scale</li></ul></li><li><code>FuseConvAddTemplate</code>：硬件支持 conv + add 的 fuse，不同的芯片架构的融合条件不一致，满足融合条件会有以下行为：</li><li>将 conv 的 output dtype 配置为 float32</li><li>将 add 对应的 input dtype 配置为 float32</li><li><code>GridHighPrecisionTemplate</code>：根据经验，grid sample 的 grid 计算过程用 qint8 精度不够，因此自动将相关算子配置为 qint16 计算。</li><li><code>InternalQuantsTemplate</code>：模型分段部署场景下，会在分段点处插入 QuantStub，用于记录此处的 dtype 和 scale，此类 QuantStub 的 dtype 配置必须和输入保持一致。</li><li><code>OutputHighPrecisionTemplate</code>：当 Gemm 类算子作为模型输出时，将其配置为高精度输出。</li><li><code>PropagateTemplate</code>：对于拆分为子图实现的算子，存在经验性配置，如 <code>LayerNorm</code> 和 <code>Softmax</code> 内部小算子应该使用高精度。</li><li><p><code>SimpleIntPassTemplate</code>：性能优化，对于 op0-&gt;op1-&gt;op2 此类计算图，若以下条件同时成立，则将 op1 输出类型修改为 int：</p><ul><li>op2 需要 int 输入</li><li>op0 可以输出 int</li><li><p>op1 当前输出为 float16，且属于以下类型</p><ol><li>cat, stack</li><li>mul\_scalar</li><li>无精度风险的查表算子（即在 fp16 上默认使用查表实现的算子）</li></ol></li></ul></li><li><code>SimplifyTemplate</code>：删除多余的量化节点配置（将对应的 dtype 修改为 None）</li></ul><p>进一步的说明可以参考用户手册&lt;u&gt;<a href="https://link.segmentfault.com/?enc=9%2BHhOCPeyg3mgzEJRQ7vGA%3D%3D.MZ6cqtMHJTNv8CdxfnZLJjvOCXDSQRgdPkHiNvBuOFfZm38Wpqt%2BR1hbrCm1M90WhPp4BARlGUY8OHykAZfk8wQpfsZjPy7TM1DUSMJsboIOns6pehHCHSJk8e%2B50dgzqVtV3S6kO8U8pMUeGiQHDw%3D%3D" rel="nofollow" target="_blank">【Qconfig 详解】</a>&lt;/u&gt;。</p></li><li><strong>​save\_dir【必要配置】：​</strong>量化配置文件保存的路径。</li></ul><h4>2.2.2 templates 介绍</h4><p><code>horizon_plugin_pytorch</code> 中提供了比较齐全的量化配置 templates 供用户使用，下面将逐一对这些模板进行介绍：</p><ol><li>ModuleNameTemplate（必要配置）：通过 module name 指定 dtype 配置或量化阈值，包括激活/weight 量化配置，固定 scale 配置；配置粒度支持全局、模型片段和算子等；配置 dtype 包括 qint8、qint16、torch.float16、torch.float32 等，相关配置项可以参考用户手册&lt;u&gt;<a href="https://link.segmentfault.com/?enc=JfkwDPnPT1kOz9IzzgEg6w%3D%3D.7ZGMF%2F1VJeoiCxb8CZwWewSQNKCmg5%2B2SAf8dHX3iawyQp249M15lQxXCpyCP2tD4fYpSYplD54yRi1fSBflOc8wZEqj8b7KpOsnSXJKfZ8cIA6Pgm1zzVY03ubnsW99g%2FthkpJ1Y8EHqtuXrlITbw%3D%3D" rel="nofollow" target="_blank">【Qconfig 详解】</a>&lt;/u&gt;；</li><li>MatmulDtypeTemplate（必要配置）：通过名称或前缀配置 Matmul 算子单 int16/双 int16 输入，支持批量配置，相关配置项可以参考用户手册&lt;u&gt;<a href="https://link.segmentfault.com/?enc=1oqTh51AtyYGDH2DN%2Fgs7A%3D%3D.Ic9yty0y5L5ccJxxrdtsEHz4X5JBVD965YfWLEJnSwB2ATa1S%2BRerXFBPn78hrjR7AmSYL9510UwJ%2FkJtXW1wSgkhd%2BYnIxvFmDmUs%2FwjyBchweDBLHzWFmGTvgOIaK05RUf0EwZMauAi%2B3Vc6azgw%3D%3D" rel="nofollow" target="_blank">【Qconfig 详解】</a>&lt;/u&gt;；</li><li>ConvDtypeTemplate（必要配置）：通过名称或前缀配置 Conv/Linear 算子单 int16/双 int16 输入，支持批量配置，相关配置项可以参考用户手册&lt;u&gt;<a href="https://link.segmentfault.com/?enc=GkHb%2Bhz2amI9KXhdusIy6g%3D%3D.bLPMpXxr6m9ZSYWSayKA1gGgMPADB3ILj0%2BBs8nb6Zz%2FpENRpO7nQN%2BlkT3xsk%2F6t6ZKxPw6fp9W4qPvhZoxZVxYlhtWvH0RQu45Il6ObZG2OlNWSDr5jLYIAU%2FXPhXpC7%2BB9g1li7rkLzXLsxzLxQ%3D%3D" rel="nofollow" target="_blank">【Qconfig 详解】</a>&lt;/u&gt;；</li><li>SensitivityTemplate（可选配置）：通过量化敏感度列表提升数据类型精度，默认将敏感算子配置为 int16，支持激活敏感和 weight 敏感算子分别配置高精度，相关配置项可以参考用户手册&lt;u&gt;<a href="https://link.segmentfault.com/?enc=hnAdWAGQ3gIQFjeH3%2BvalA%3D%3D.0wifHgAseHLK%2F6oJJKg%2Bm%2BV8X65TbW4WFxIgb4D1POjdj2yi8bS0IX5PbBUqLEolCkc8fUgBLcFSRoq7kMpsleZHPfMyq8GnvoNNUYA3nSr5%2B6sb1qmFbiCzez231tWLDmCI8Y3JTQ%2FUqW%2FpcX9FRg%3D%3D" rel="nofollow" target="_blank">【Qconfig 详解】</a>&lt;/u&gt;。</li><li>LoadFromFileTemplate：从 <code>qconfig_dtypes.pt</code> 文件中加载量化配置，仅可加载全局及每个算子的量化类型，暂时无法加载 fix\_scale 配置，且不支持对 qconfig 进行修改。而且需要注意，此时 enable\_optimize 必须配置为 False，否则无法保证配置结果的正确性，部署时可能存在 CPU 算子。</li></ol><p><strong>用户配置的模板按顺序生效，前面模板的配置会被后面的模板覆盖。</strong></p><p>一般来说，用户会使用到 ModuleNameTemplate、ConvDtypeTemplate、MatmulDtypeTemplate 和 SensitivityTemplate 这 4 个模板，其中前 3 个模板为必要配置。以下是 templates 的常用配置，如下所示：</p><pre><code class="Plain">from horizon_plugin_pytorch.quantization.qconfig_setter import *
import torch
#加载精度debug工具产出的敏感度列表
table1=torch.load("xxx_optput1_L1.pt")
table2=torch.load("xxx_optput2_L1.pt")
templates=[ 
    #1. 基础配置部分
    ModuleNameTemplate({"":qint8}),  #全局feat int8,此时weight 默认为int16
    #conv类算子的 input配置为 int8，weight配置为int8
    ConvDtypeTemplate(input_dtype=qint8, weight_dtype=qint8),  
    #matmul类算子两个输入均配置为 int8
    MatmulDtypeTemplate(input_dtypes=qint8), 
    ModuleNameTemplate(
        {"quant":{"dtype":qint8,"threshold":1.0}},#quant int8,固定scale，配置
        ),
    #2. Matmul 单/双int16输入配置
    MatmulDtypeTemplate(
        input_dtypes=[qint8/qint16,qint8/qint16],
        prefix=["head","xxxxx"]#prefix中配置的名称与torch.nn.Module.name_module()返回的一致
        ),
    #3.Conv 单/双int16输入配置
    ConvDtypeTemplate(
        input_dtype=qint8/qint16, 
        weight_dtype=qint8/qint16,
        prefix= ["backbone","xxxxx"],#prefix中配置的名称与torch.nn.Module.name_module()返回的一致
        ),
    # 4. 敏感度模板配置
    #配置top10 weight敏感的算子为int16
    SensitivityTemplate(
        sensitive_table=table1,#精度debug工具产出的敏感度列表
        topk_or_ratio=10, #配置整数的时候是topk,小数的时候是ratio
        sensitive_type= 'weight',#只配置weight敏感的算子，还可以选择 'activation'、 'both'，默认是both
        ),
    #配置50%激活敏感的算子为int16
    SensitivityTemplate(
        sensitive_table=table2,
        topk_or_ratio=0.5, #配置整数的时候是topk,小数的时候是ratio
        sensitive_type= 'activation',#配置激活敏感的算子
        ), 
    ]</code></pre><h3>2.3 产出物介绍</h3><p>在完成新版 qconfig 模板配置并执行 prepare 操作后，工具链将自动生成并保存 5 个文件，分别为 <code>model_check_result.txt</code>、<code>fx_graph.txt</code>、<code>qconfig_changelogs.txt</code>、<code>qconfig_dtypes.pt.py</code> 及 <code>qconfig_dtypes.pt</code>，各文件功能与技术细节如下：</p><ul><li><code>model_check_result.txt</code>、<code>fx_graph.txt</code>：二者均由 <code>prepare</code> 接口自动生成，<code>model_check_result.txt</code> 中包括未 fuse 的 pattern、每个 op 输出/weight 的 qconfig 配置、异常 qconfig 配置提示等，<code>fx_graph.txt</code> 保存的是模型的 fx trace 图；</li><li><code>qconfig_dtypes.pt.py</code> 和 <code>qconfig_dtypes.pt</code>：为 <code>QconfigSetter</code> 接口输出的量化配置载体，完整记录全局及算子级别的量化精度参数，包括每个算子的 input、weight 和 output 的量化精度，如 qint8、qint16 和 torch.float16 等，其中。py 文件供用户阅读，。pt 文件可以使用 <code>LoadFromFileTemplate</code> 接口加载，<code>qconfig_dtypes.pt.py</code> 中信息如下所示；</li></ul><pre><code class="Plain">{
#算子级别量化配置
'backbone.conv1.conv1_1.conv': {'input': None, 'weight': 'qint8', 'output': None}, 'backbone.conv1.conv1_1.act': None,
 'backbone.conv1.conv1_2.conv': {'input': torch.float32, 'weight': torch.float32, 'output': None}, 
 'backbone.conv1.conv1_2.act': {'input': None, 'weight': None, 'output': 'qint16'}
 ...
 }</code></pre><ul><li><code>qconfig_changelogs.txt</code>：每个算子 qconfig 根据 Templates 的变化逻辑，页面如下所示：</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438877" alt="" title=""/></p><h2>3. 使用示例</h2><p>本章节将会提供上述模板的使用方法以及在典型场景下的配置示例。</p><h3><strong>3.1 配置全局</strong> fp16/int16/int8</h3><h4>3.1.1 配置全局 int8</h4><p>配置全局 qconfig 时必须要配置 ModuleNameTemplate、ConvDtypeTemplate、MatmulDtypeTemplate 这 3 个模板，以下为使用示例：</p><pre><code class="Plain">import torch
from horizon_plugin_pytorch.quantization import  prepare,set_fake_quantize,FakeQuantState
from horizon_plugin_pytorch.quantization.qconfig_template import ModuleNameQconfigSetter,
from horizon_plugin_pytorch.quantization import get_qconfig 
from horizon_plugin_pytorch.quantization.qconfig_setter import *
my_qconfig_setter=QconfigSetter(
    reference_qconfig=get_qconfig(observer=MSEObserver),
    templates=[
      #1.全部算子配置为 int8 输出
      ModuleNameTemplate({"":qint8}),  
      #2.conv 的 input配置为 int8，weight配置为int8
      ConvDtypeTemplate(input_dtype=qint8, weight_dtype=qint8),  
      #3.matmul 两个输入均配置为 int8
      MatmulDtypeTemplate(input_dtypes=qint8), 
    ],
     save_dir=args.save_path,
    )
float_model.eval()
qat_model = prepare(
    float_model,
    example_inputs=example_input,
    qconfig_setter=my_qconfig_setter,
    check_result_dir=args.save_path
    )</code></pre><p>配置全局 int16 的方式与全局 int8 类似，将上述示例中的 qint8 修改为 qint16 即可。</p><p><strong>注意：</strong></p><ol><li>配置全局 feat 为 int8/int16/fp16 的时候必须要对 Conv 类算子的 weight 进行配置，否则 weight 会自动做 int16 计算，并可能出现不符合预期的 CPU 算子；</li><li>配置全局 int8 后，model\_check\_result.txt 可能会显示模型中仍然存在 int16 计算的算子，这是工具为了提升量化精度做的自动化行为，比如 norm 这种进行拆分实现的算子，内部采用 int16 较高精度的计算，然后输出为 int8。</li></ol><h4>3.1.2 配置全局 feature int16+weight int8+prefix 批量配置</h4><pre><code class="Plain">import torch
from horizon_plugin_pytorch.quantization import  prepare,set_fake_quantize,FakeQuantState
from horizon_plugin_pytorch.quantization import get_qconfig 
from horizon_plugin_pytorch.quantization.qconfig_setter import *
my_qconfig_setter=QconfigSetter(
    reference_qconfig=get_qconfig(observer=MSEObserver),
    templates=[
        #1.配置全局feat int16,weight int8
        ModuleNameTemplate({"":qint16}),
        ConvDtypeTemplate(input_dtype=qint16, weight_dtype=qint8),  
        MatmulDtypeTemplate(input_dtypes=qint16),  
        #2.配置backbone部分全int8
        ModuleNameTemplate({"backbone":qint8}),
        MatmulDtypeTemplate(
            input_dtypes=[qint8,qint8],
            prefix=["backbone"]
        ),    
        ConvDtypeTemplate(
            input_dtype=qint8, 
            weight_dtype=qint8,
            prefix= ["backbone"],
        ),
    ],
    save_dir=args.save_path,
    )

qat_model = prepare(
    float_model,
    example_inputs=example_input,
    qconfig_setter=my_qconfig_setter,
    check_result_dir=args.save_path)</code></pre><h3>3.2 fixscale 配置</h3><p>模型中的某些地方很难依靠统计的方式获得最佳的量化 scale，比如物理量，此时当算子的输出值域确定时就可以设置 fixed scale。新版 qconfig 模板配置 fixed scale 的方式为配置输入/输出的量化类型“dtype”和阈值“threshold”，其中 scale 的计算为：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438878" alt="" title="" loading="lazy"/></p><p>其中 threshold 一般为算子输入/输出的绝对值的最大值；n 则为量化位宽，比如 int8 量化位宽 n=8。</p><p>如下为配置 quantstub 算子输出 scale 和 conv 算子输入 scale 的示例：</p><pre><code class="Plain">import torch
from horizon_plugin_pytorch.quantization import  prepare,set_fake_quantize,FakeQuantState
from horizon_plugin_pytorch.quantization import get_qconfig 
from horizon_plugin_pytorch.quantization.qconfig_setter import *
my_qconfig_setter=QconfigSetter(
    reference_qconfig=get_qconfig(observer=MSEObserver),
    templates=[
        #1. 配置全局int8 
        ModuleNameTemplate({"":qint8}), 
        ConvDtypeTemplate(input_dtype=qint8, weight_dtype=qint8),  
        MatmulDtypeTemplate(input_dtypes=qint8),
        
        ModuleNameTemplate(
        { 
         #2.fixscale:配置算子输出的dtype和threshold，此时scale=1/128=0.0078125
         "backbone.quant":{"dtype":qint8,"threshold":1.0},
         #3.fixscale:配置conv的weight输入为fix_scale的int16量化，
         #scale=1/32768=3.0518e-05
         "backbone.conv1.conv1_2.conv":{"dtype": {"weight": qint16}, "threshold": {"weight": 1.0}},   
        },
        ),
],
    save_dir=args.save_path,    
)
qat_model = prepare(
    float_model,
    example_inputs=example_input,
    qconfig_setter=my_qconfig_setter,
    check_result_dir=args.save_path)</code></pre><p>通过 prepare 后生成的 <code>model_check_result.txt</code> 可以验证配置是否生效：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438879" alt="" title="" loading="lazy"/></p><h3>3.3 批量配置 conv/matmul 单/双 int16 输入</h3><p>ConvDtypeTemplate 和 MatmulDtypeTemplate 支持单/双 int16 输入的批量配置，相关示例如下：</p><pre><code class="Plain">import torch
from horizon_plugin_pytorch.quantization import  prepare,set_fake_quantize,FakeQuantState
from horizon_plugin_pytorch.quantization import get_qconfig 
from horizon_plugin_pytorch.quantization.qconfig_setter import *
my_qconfig_setter=QconfigSetter(
    reference_qconfig=get_qconfig(observer=MSEObserver),
    templates=[
        #1.基础配置全局激活&amp;weight int8
        ModuleNameTemplate({"":qint8}), 
        ConvDtypeTemplate(input_dtype=qint8, weight_dtype=qint8),  
        MatmulDtypeTemplate(input_dtypes=qint8),

        #2.Conv 单int16输入配置：将激活输入为int16(按需配置)
        ConvDtypeTemplate(
            input_dtype=qint16, 
            weight_dtype=qint8,
            prefix= ["backbone.res_layers.0","encoder.encoder.0.layers.0"],
            ),
        #3.Conv 单int16输入配置：将weight配置int16(按需配置)
        ConvDtypeTemplate(
            input_dtype=qint8, 
            weight_dtype=qint16,
            prefix= ["backbone.conv1.conv1_2.conv"],
            ),
        #4.Conv 双int16输入配置(按需配置)
        ConvDtypeTemplate(
            input_dtype=qint16, 
            weight_dtype=qint16,
            prefix= ["backbone.conv1.conv1_1.conv"],
            ),
        #5.matmul单int16配置：将第0个输入配置为int8,第1个输入配置成int16(按需配置)
         MatmulDtypeTemplate(
            input_dtypes=[qint8,qint16],
            prefix=["encoder.encoder.0.layers.0.self_attn.matmul","encoder.encoder.1.layers.0.self_attn.matmul"]
                 ),
        #6.matmul单int16配置：第0个输入配置成int16，将第1个输入配置为int8（按需配置)
        MatmulDtypeTemplate(
            input_dtypes=[qint16,qint8],
            prefix=["encoder.encoder.0.layers.1.self_attn.matmul"]
                 ),
        #7.matmul双int16配置：将2个输入都配置为双int16(按需配置)
        MatmulDtypeTemplate(
            input_dtypes=[qint16,qint16],
            prefix=["encoder.encoder.0.layers.2.self_attn.matmul"]
                 ),
],
    save_dir=args.save_path,    
)
qat_model = prepare(
    float_model,
    example_inputs=example_input,
    qconfig_setter=my_qconfig_setter,
    check_result_dir=args.save_path)</code></pre><h3>3.4 LoadFromFileTemplate 使用示例</h3><p>当从旧模板迁移到新的 qconfig 量化模板时，推荐的做法是先把旧版本的量化配置 qconfig\_dtypes.pt 保存下来，然后使用 LoadFromFileTemplate 进行加载，这里仅介绍此接口的用法，后续章节有完整的迁移教程。</p><p><strong>LoadFromFileTemplate 接口使用时需要注意以下问题：</strong></p><ol><li>qconfig\_dtypes.pt 不保存算子的 fix\_scale 信息，如果原 qconfig 里存在 fix\_scale 的算子，需要在加载 qconfig\_dtypes.pt 后再次进行配置。</li><li>使用 LoadFromFileTemplate 接口时 enable\_optimize 必须配置为 False，因为保存下来的 dtype 一般是优化后的，优化过程不可重入，Load qconfig\_dtypes.pt 后​<strong>不再支持对 qconfig 中 dtype 的修改</strong>​。</li></ol><p>LoadFromFileTemplate 使用示例如下：</p><pre><code class="Plain">import torch
from horizon_plugin_pytorch.quantization import  prepare,set_fake_quantize,FakeQuantState
from horizon_plugin_pytorch.quantization import get_qconfig 
from horizon_plugin_pytorch.quantization.qconfig_setter import *
my_qconfig_setter=QconfigSetter(
    reference_qconfig=get_qconfig(observer=MSEObserver),
    templates=[
         #1.加载量化配置pt文件
         LoadFromFileTemplate("qconfig_dtypes.pt"),
         #2.对fix_scale的算子进行补充配置
         ModuleNameTemplate({"backbone.quant":{"dtype":qint8,"threshold":1.0}})
    ],
    #3.无需开启任何优化
    enable_optimize=False,
    save_dir=args.save_path,)
qat_model = prepare(
    float_model,
    example_inputs=example_input,
    qconfig_setter=my_qconfig_setter,
    check_result_dir=args.save_path)</code></pre><h3>3.5 典型场景配置</h3><p>由于征程 6 系列平台的差异，qconfig 的配置自然也会有所区别。本节将结合平台差异，提供新版 qconfig 模板在典型场景下的配置示例。</p><h4>3.5.1 征程 6E/M 平台一般配置</h4><p>征程 6E/M 平台以定点算力为主，在进行混合量化精度调优过程中，建议以全局 int8 精度为例，针对部分对量化较为敏感的算子，可将其配置为更高的 int16 精度。以下为配置示例。</p><h5>配置示例 1：全局 int8+ 手动配置量化敏感度高的算子为 int16</h5><pre><code class="Plain">import torch
from horizon_plugin_pytorch.quantization import  prepare,set_fake_quantize,FakeQuantState
from horizon_plugin_pytorch.quantization import get_qconfig 
from horizon_plugin_pytorch.quantization.qconfig_setter import *
my_qconfig_setter=QconfigSetter(
    reference_qconfig=get_qconfig(observer=MSEObserver),
    templates=[
        #1.配置全局feat int8,weight int8
        ModuleNameTemplate({"":qint8}),
        ConvDtypeTemplate(input_dtype=qint8, weight_dtype=qint8),  
        MatmulDtypeTemplate(input_dtypes=qint8),  
        #2.根据精度debug工具分析，将敏感算子配置为int16(按需配置)
        #将weight敏感的conv配置为int16(按需配置)，支持批量配置
        ConvDtypeTemplate(
            input_dtype=qint8, 
            weight_dtype=qint16,
            prefix= ["backbone.conv1.conv1_3.conv"],
            ),
        #3.将敏感的Matmul配置为int16输入(按需配置)
        #将第0个输入敏感的matmul配置为int16(按需配置)，支持批量配置
        MatmulDtypeTemplate(
            input_dtypes=[qint16,qint8],
            prefix=["encoder.encoder.0.layers.0.self_attn.matmul"]
                 ),
    ],
    save_dir=args.save_path,
    )

qat_model = prepare(
    float_model,
    example_inputs=example_input,
    qconfig_setter=my_qconfig_setter,
    check_result_dir=args.save_path)</code></pre><h5>配置示例 2：全局 int8+ 使用敏感度模板配置部分敏感算子为 int16</h5><p>除了手动将部分敏感算子配置为 int16，新版 qconfig 模板提供了 SensitivityTemplate，该模板用于将精度 debug 工具所产出的敏感度列表中，量化敏感度排序 topk 或者占一定比率 ratio 的敏感算子，配置为更高的量化精度。相关示例如下：</p><pre><code class="Plain">import torch
from horizon_plugin_pytorch.quantization import  prepare,set_fake_quantize,FakeQuantState
from horizon_plugin_pytorch.quantization import get_qconfig 
from horizon_plugin_pytorch.quantization.qconfig_setter import *
#精度debug工具跑出来的算子量化敏感度列表
table1=torch.load("output1_ATOL_sensitive_ops.pt")
table2=torch.load("output2_ATOL_sensitive_ops.pt")
my_qconfig_setter=QconfigSetter(
    reference_qconfig=get_qconfig(observer=MSEObserver),
    templates=[
      #1. 基础配置全局激活&amp;weight int8
      ModuleNameTemplate({"":qint8}), 
      ConvDtypeTemplate(input_dtype=qint8, weight_dtype=qint8),  
      MatmulDtypeTemplate(input_dtypes=qint8),
      #2.配置output1输出敏感度Top10的算子为int16(按需配置)
      SensitivityTemplate(
        sensitive_table=table1,
        topk_or_ratio=10,  
    ),
      #3.配置output2输出敏感度10%的算子为int16(按需配置)
      SensitivityTemplate(
        sensitive_table=table2,
        topk_or_ratio=0.1, 
    ),   
    ],
    save_dir=args.save_path,)
qat_model = prepare(
    float_model,
    example_inputs=example_input,
    qconfig_setter=my_qconfig_setter,
    check_result_dir=args.save_path)</code></pre><p>topk\_or\_ratio 参数的选择：需要用户根据量化精度和部署性能进行权衡，一般来说，配置的高精度算子越多，量化精度越好，而部署性能影响则会越大。</p><h4>3.5.2 征程 6P/H 平台一般配置</h4><p>对于征程 6 P/H 这种有浮点算力的平台，推荐将 feature 输出配置为 fp16+conv 和 matmul 类算子全部配置为 int8 作为基础配置，然后再将量化敏感的算子配置为 int16。如下为配置示例。</p><h5>配置示例 1：基础配置 + 手动配置量化敏感度高的算子为 int16</h5><pre><code class="Plain">import torch
from horizon_plugin_pytorch.quantization import  prepare,set_fake_quantize,FakeQuantState
from horizon_plugin_pytorch.quantization.qconfig_template import ModuleNameQconfigSetter,
from horizon_plugin_pytorch.quantization import get_qconfig 
from horizon_plugin_pytorch.quantization.qconfig_setter import *
my_qconfig_setter=QconfigSetter(
    reference_qconfig=get_qconfig(observer=MSEObserver),
    templates=[
      #1.基本配置
      #全局 feat fp16
      ModuleNameTemplate({"": torch.float16}),
      #将conv和matmul类算子配置为全int8输入
      ConvDtypeTemplate( 
            input_dtype=qint8,
            weight_dtype=qint8,  
        ),
      MatmulDtypeTemplate(  
            input_dtypes=[qint8, qint8],
        ),
      #2.根据debug工具分析结果，将敏感的Conv/Matmul配置为int16输入(按需配置)
      #将conv中敏感的weight输入配置为int16(按需配置)
      ConvDtypeTemplate(
            input_dtype=qint8, 
            weight_dtype=qint16,
            prefix= ["backbone.conv1.conv1_3.conv"],
            ),
      #将matmul中敏感的输入配置为int16(按需配置)
       MatmulDtypeTemplate(
            input_dtypes=[qint16,qint8],
            prefix=["encoder.encoder.0.layers.0.self_attn.matmul"] ),
       
    ],
     save_dir=args.save_path,
    )
float_model.eval()
qat_model = prepare(
    float_model,
    example_inputs=example_input,
    qconfig_setter=my_qconfig_setter,
    check_result_dir=args.save_path
    )</code></pre><h5>配置示例 2：基础配置 + 使用敏感度模板配置部分敏感算子为 int16</h5><pre><code class="Plain">import torch
from horizon_plugin_pytorch.quantization import  prepare,set_fake_quantize,FakeQuantState
from horizon_plugin_pytorch.quantization import get_qconfig 
from horizon_plugin_pytorch.quantization.qconfig_setter import *
#精度debug工具跑出来的算子量化敏感度列表
table1=torch.load("output1_ATOL_sensitive_ops.pt")
table2=torch.load("output2_ATOL_sensitive_ops.pt")
my_qconfig_setter=QconfigSetter(
    reference_qconfig=get_qconfig(observer=MSEObserver),
    templates=[
      #1.基本配置
      #全局 feat fp16
      ModuleNameTemplate({"": torch.float16}),
      #将conv和matmul类算子配置为全int8输入
      ConvDtypeTemplate( 
            input_dtype=qint8,
            weight_dtype=qint8,  
        ),
      MatmulDtypeTemplate(  
            input_dtypes=[qint8, qint8],
        ),
      #2.配置output1输出敏感度Top10的算子为int16(按需配置)
      SensitivityTemplate(
        sensitive_table=table1,
        topk_or_ratio=10,  
    ),
      #3.配置output2输出敏感度10%的算子为int16(按需配置)
      SensitivityTemplate(
        sensitive_table=table2,
        topk_or_ratio=0.1, 
    ),   
    ],
    save_dir=args.save_path,)
qat_model = prepare(
    float_model,
    example_inputs=example_input,
    qconfig_setter=my_qconfig_setter,
    check_result_dir=args.save_path)</code></pre><h4>3.5.3 配置算子为 float32 计算</h4><p>在做精度调优的时候，有时候想要快速定位引起量化误差的瓶颈，此时会将模型片段或者算子配置为 float32 计算，如下为将指定模型片段和算子配置为 float32 计算的示例：</p><pre><code class="Plain">my_qconfig_setter=QconfigSetter(
    reference_qconfig=get_qconfig(observer=MSEObserver),
    templates=[
        #1. 基础配置全局激活&amp;weight int8
        ModuleNameTemplate({"":qint8}), 
        ConvDtypeTemplate(input_dtype=qint8, weight_dtype=qint8),  
        MatmulDtypeTemplate(input_dtypes=qint8),
        
        ModuleNameTemplate(
        { 
         #2.批量配置"encoder.encoder.0.layers.0"为float32计算
         "encoder.encoder.0.layers.0": torch.float32,
         #3.配置"backbone.conv1.conv1_2.conv.act"算子为float32计算
         "backbone.conv1.conv1_2.conv.act": torch.float32,}
            ),
    ],
    save_dir=args.save_path,    
)</code></pre><h4>3.5.4 QAT 训练时固定激活 scale</h4><p>在 QAT 精度调优实践中发现（主要是图像分类任务实验），做完 calibration 后，把 activation 的 scale 固定住，不进行更新，即设置 activation 的 <code>averaging_constant=0</code> ，QAT 训练精度相比于不固定 activation 的 scale 的量化精度会更好。相关配置示例如下所示：</p><pre><code class="Plain">import torch
from horizon_plugin_pytorch.quantization import  prepare,set_fake_quantize,FakeQuantState
from horizon_plugin_pytorch.quantization.fake_quantize import FakeQuantize
from horizon_plugin_pytorch.quantization.qconfig import QConfig
from horizon_plugin_pytorch.quantization.qconfig_setter import *
from horizon_plugin_pytorch.quantization import get_qconfig 
my_qconfig_setter=QconfigSetter(
    #将激活的averaging_constant参数配置为0
    reference_qconfig= QConfig(
        output=FakeQuantize.with_args(
            observer=MinMaxObserver,
            averaging_constant=0,#averaging_constant配置为0
        ), ),
    templates=[
      #配置weight和激活全局int8
      ModuleNameTemplate({"":qint8}), 
      ConvDtypeTemplate(input_dtype=qint8, weight_dtype=qint8),  
      MatmulDtypeTemplate(input_dtypes=qint8),
    ],
    save_dir=args.save_path,
    )

qat_model = prepare(
    float_model,
    example_inputs=example_input,
    qconfig_setter=my_qconfig_setter,
    check_result_dir=args.save_path
    )</code></pre><h2>4. 新版 qconfig 模板迁移</h2><p>用户在迁移到新版 qconfig 模板时，建议根据以下情况进行不同的操作：</p><ol><li>如果用户部署平台为征程 6B、征程 6H 和征程 6P，为了更方便地利用浮点算力，建议使用新版 qconfig 模板。</li><li>如果用户模型从未适配过 QAT 链路，建议用户直接参考第 3 章使用新版 qconfig 模板进行配置。</li><li>如果用户模型已经适配过老版本 qconfig 模板，且在模型迭代中还需要修改 qconfig 配置，比如增加 int16 算子等，那么建议用户参考第 3 章重新进行新版 qconfig 模板的适配。</li><li>如果用户模型已经适配过老版本 qconfig 模板，且确认在模型迭代中不再需要修改 qconfig 配置，那么则建议用户按照下面的流程进行迁移工作。</li></ol><p>若用户已经稳定使用老版本 qconfig 模板，而且模型迭代中不需要再修改量化配置，那么建议按照以下流程进行适配：</p><ol><li>首先，使用 <code>SaveToFileTemplate</code> 接口保存旧模板下的量化配置文件 <code>qconfig_dtypes.pt</code>，其中涵盖每个算子的 dtype；</li><li>其次，需检查模型中是否存在采用 fix\_scale 的算子。鉴于 qconfig\_dtypes.pt 目前尚不支持保存 fix\_scale 的算子信息，并且新旧模板在 fix\_scale 的配置方面存在差异，若存在 fix\_scale 的算子，那么就必须对新模板下 fix\_scale 的配置进行适配；</li><li>最后，运用 <code>LoadFromFileTemplate</code> 接口加载已保存的 <code>qconfig_dtypes.pt</code>​<code> </code> 文件，将量化 dtypes 配置导入新模板中，从而实现量化配置的迁移衔接。</li></ol><p>这里要特别注意，加载已保存的 <code>qconfig_dtypes.pt</code> 文件后不支持再对模型中的算子 dtype 做修改。</p><p>下面将详细介绍迁移的具体步骤和操作要点。</p><h3>4.1 保存旧版本的 qconfig\_dtypes 文件</h3><p><code>horizon_plugin_pytorch</code>​<code> </code> 提供了 <code>SaveToFileTemplate</code> 接口用于将量化配置文件保存为 <code>qconfig_dtypes.pt</code>。其路径和使用方式如下：</p><pre><code class="Plain">from horizon_plugin_pytorch.quantization.qconfig_setter.templates import *
...
qat_model = prepare(
    float_model,
    example_inputs=example_input,
    qconfig_setter=(
        ModuleNameQconfigSetter(...),
        calibration_8bit_weight_16bit_act_qconfig_setter,
    ),
    check_result_dir=args.save_path,
    )
#prepare后保存
#args.save_path为qconfig_dtypes.pt保存路径
save_api=SaveToFileTemplate(args.save_path)
save_api(None, qat_model, None, None, None)</code></pre><p>在完成修改并运行后，于 args.save\_path 目录下将会生成包含量化 dtype 的 qconfig\_dtypes.pt 与 qconfig\_dtypes.pt.py 文件。</p><h3>4.2 适配 fix\_scale 的配置</h3><p>目前，<code>qconfig_dtypes.pt</code>​<code> </code> 文件在保存量化配置信息时，存在一定的功能限制，即尚不支持对配置了 fix\_scale 的算子信息进行保存。这意味着当用户在旧版本 qconfig 中对部分算子设置了 fix\_scale 时，相关的配置无法通过 <code>qconfig_dtypes.pt</code>​<code> </code> 文件完整迁移至新模板。</p><p>因此，若用户的模型中存在配置 fix\_scale 的算子，fix\_scale 的算子和相应配置可以通过 <code>model_check_result.txt</code> 获取，为确保量化配置能够对齐旧版本，必需按照上文 3.2 章节所阐述的适配规则和操作步骤，手动对 fix\_scale 的配置进行调整与适配，以使其符合新模板的要求。</p><h3>4.3 加载 <code>qconfig_dtypes.pt</code> 文件</h3><p>使用 <code>LoadFromFileTemplate</code> 加载旧版本模板 qconfig\_dtypes.pt 时，为确保与旧版本行为相适配，必须对特定参数予以配置。否则，可能会面临加载 calib/qat 权重失败的问题。以下为相关参数的详细阐述：</p><ol><li>对于 <code>QconfigSetter()</code>，应将“enable\_optimize”参数配置为“False”，以此避免启用任何新版本中的默认优化。</li><li>针对 <code>LoadFromFileTemplate()</code>，务必将“only\_set\_mod\_in\_graph”参数配置为“False”。原因在于，在老版本配置中，存在对非 graph 中的操作进行 qconfig 设置的情形。</li><li>在执行 <code>prepare</code> 操作时，需将“fuse\_mode”参数配置为“FuseMode.BNAddReLU”，进而实现与老版本行为的对齐。</li></ol><p><strong>以下为完整的使用示例：</strong></p><pre><code class="Plain">import torch
from horizon_plugin_pytorch.quantization import  prepare,set_fake_quantize,FakeQuantState
from horizon_plugin_pytorch.quantization import get_qconfig 
from horizon_plugin_pytorch.quantization.qconfig_setter import *

my_qconfig_setter=QconfigSetter(
    reference_qconfig=get_qconfig(observer=MSEObserver),
    templates=[
        ModuleNameTemplate(
        { #1.适配fix_scale的配置
          "backbone.quant":{"dtype":qint8,"threshold":1.0},
          }
        #2.Load旧模板下保存的qconfig_dtypes.pt
        LoadFromFileTemplate(
        "./qconfig_old/qconfig_dtypes.pt",
        #3.该参数需要设置 False，原来配置中有对非 graph 中的 op 设置 qconfig
        only_set_mod_in_graph=False,
    ),],
    save_dir=args.output_dir,
    #4.无需开启任何优化,关闭enable_optimize
    enable_optimize=False,
    )
from horizon_plugin_pytorch.quantization.fx.fusion_patterns import FuseMode
qat_model = prepare(
    float_model,
    example_inputs=example_input,
    qconfig_setter=my_qconfig_setter,
    check_result_dir=args.output_dir,
    #5.对齐老版本的融合行为
    fuse_mode=FuseMode.BNAddReLU,
    )
          </code></pre>]]></description></item><item>    <title><![CDATA[打造专属知识大脑：个人电脑上的本地私有知]]></title>    <link>https://segmentfault.com/a/1190000047438816</link>    <guid>https://segmentfault.com/a/1190000047438816</guid>    <pubDate>2025-11-30 16:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>打造专属知识大脑：个人电脑上的本地私有知识库全攻略</h2><h3>为什么你需要一个本地私有知识库？</h3><p>想象一下：当你突然需要查找半年前读过的那篇精彩文章，或者在会议中急需某个重要数据，却发现自己收藏的内容散落在微信、浏览器、笔记软件等十几个地方...这种场景是不是很熟悉？</p><p>在信息爆炸的时代，我们每天都在接收海量信息，但真正能内化为个人知识资产的却少之又少。这就是为什么你需要一个<strong>本地私有知识库</strong>——它就像是为你的大脑配备了一个外接硬盘，帮你：</p><ul><li><strong>永久保存</strong>重要资料，不再担心链接失效</li><li><strong>快速检索</strong>任何信息，秒级找到所需内容</li><li><strong>建立知识连接</strong>，让零散信息形成知识网络</li><li><strong>完全私密安全</strong>，所有数据都保存在你的电脑上</li></ul><h3>本地私有知识库的核心优势</h3><h4>数据安全，完全掌控</h4><p>与云端存储不同，本地知识库的所有数据都保存在你的个人设备上。这意味着：</p><ul><li>不用担心服务商突然停止运营</li><li>不会因为账号问题丢失珍贵资料</li><li>敏感信息完全由自己掌控</li></ul><h4>离线可用，随时随地</h4><p>即使没有网络连接，你依然可以：</p><ul><li>查看所有已保存的内容</li><li>进行全文检索</li><li>整理和编辑知识</li></ul><h4>个性化定制，贴合习惯</h4><p>你可以按照自己的思维习惯来组织知识结构，打造真正属于自己的知识体系。</p><h3>优秀本地知识库推荐：访答知识库</h3><p>在众多知识库软件中，知识库以其出色的用户体验和强大的功能脱颖而出。</p><h4>为什么选择访答？</h4><p><strong>智能收集，一键归档</strong>  <br/>访答支持从网页、文档、图片等多种来源快速收集信息。遇到有价值的内容，只需简单操作就能将其纳入你的知识体系。</p><p><strong>强大的关联能力</strong>  <br/>它能够自动识别内容间的关联性，帮助你发现知识之间的内在联系，让零散的信息形成有机的知识网络。</p><p><strong>流畅的搜索体验</strong>  <br/>基于本地索引的搜索功能，让你在数千条记录中也能秒级找到目标内容，大大提升知识复用效率。</p><p><strong>简洁优雅的界面</strong>  <br/>清爽的界面设计让知识管理变成一种享受，而不是负担。</p><h4>我的使用体验</h4><p>自从开始使用构建个人知识库，我的工作效率得到了显著提升。以前需要花费半小时查找的资料，现在几秒钟就能找到。更重要的是，通过持续的知识积累，我开始发现不同领域知识间的奇妙联系，这为我的创作和工作带来了源源不断的灵感。</p><h3>如何开始构建你的知识库？</h3><h4>第一步：明确需求</h4><p>先思考你主要想管理哪些类型的知识：</p><ul><li>工作文档和项目资料</li><li>学习笔记和研究材料</li><li>灵感收集和创意素材</li><li>个人生活和兴趣内容</li></ul><h4>第二步：选择合适的工具</h4><p>根据你的需求和技术水平选择合适的知识库软件。如果你注重易用性和美观度，是个不错的选择。</p><h4>第三步：建立分类体系</h4><p>不要一开始就追求完美的分类结构。建议：</p><ul><li>从简单的几个大类开始</li><li>随着内容增多再逐步细化</li><li>善用标签系统进行多维度分类</li></ul><h4>第四步：养成收集习惯</h4><p>知识库的价值在于持续积累：</p><ul><li>每天花10分钟整理当天收集的信息</li><li>定期回顾和整理旧内容</li><li>建立固定的知识处理流程</li></ul><h3>进阶技巧：让知识库真正为你所用</h3><h4>建立个人工作流</h4><p>将知识库融入你的日常工作流程：</p><ul><li>项目启动前先搜索相关经验</li><li>会议前快速回顾背景资料</li><li>定期从知识库中提炼总结</li></ul><h4>知识复利效应</h4><p>随着时间的推移，你的知识库会像滚雪球一样产生复利效应：</p><ul><li>新旧知识相互碰撞产生新见解</li><li>积累的专业知识形成个人竞争力</li><li>减少重复学习和查找的时间浪费</li></ul><h3>立即开始，打造你的第二大脑</h3><p>不要再让宝贵的知识和灵感流失在信息的海洋中。选择一个合适的本地私有知识库，比如，开始构建属于你自己的知识体系。</p><p>记住，知识管理的核心不是工具本身，而是持续积累和有效利用的习惯。从今天开始，每天花一点点时间整理知识，一年后你会惊喜地发现，自己已经拥有了一个强大的个人知识资产。</p><p>你的知识，值得被更好地管理和利用。现在就开始行动吧！</p><p><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdndal" alt="" title=""/></p>]]></description></item><item>    <title><![CDATA[AI技术驱动下的招聘行业转型 爱跑步的香]]></title>    <link>https://segmentfault.com/a/1190000047438744</link>    <guid>https://segmentfault.com/a/1190000047438744</guid>    <pubDate>2025-11-30 13:02:11</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>AI技术驱动下的招聘行业转型<br/>当前招聘领域正经历深刻变革，智能化转型已成为不可逆转的趋势。过去一年间，人力资源行业在AI技术的推动下呈现出明显的分化态势：部分企业仍采用传统的人工筛选、沟通方式，而领先企业已实现全流程智能化管理。<br/>多项数据显示，AI技术正在重塑招聘行业的效率标准，具体表现为以下案例与数据：<br/>•智联招聘采用AI全托管系统后，招聘周期缩短40%；<br/>•某大型国有银行运用AI技术将面试到场率提升至90.7%；<br/>•辉瑞制药通过AI技能图谱精准识别人才缺口，研发创新周期缩短22%；<br/>•49.6%的企业已完成HR流程的AI优化；<br/>•ING银行将AI应用于组织健康诊断与薪酬策略，管理决策效率提升50%。<br/>这些案例表明，AI技术已从单纯的效率工具，逐步发展为能够辅助招聘及管理决策的重要支持系统，其应用价值在多个环节得到充分体现。</p><p>一、AI面试评分的科学化应用<br/>传统招聘中主观判断因素较多，评估结果易受个人经验影响，而AI面试系统通过建立标准化评估体系，有效提升了人才评估的准确性与客观性，核心实现方式包括：<br/>•采用效标效度与重测稳定信度双指标验证体系，确保评估标准的科学性；<br/>•经过大规模人机背靠背实验验证，不断优化评估模型；<br/>•评估结果与资深面试官判断高度一致，具备实际应用价值。<br/>目前，最新版本的AI面试系统已进一步提升技术成熟度，其评分结果可直接为招聘决策提供参考依据。<br/>二、全流程精准化设计<br/>AI系统贯穿招聘全流程，通过功能优化实现各环节的精准赋能，打破了传统工具的应用局限，具体优势体现在：<br/>•一问多能：单道面试题可同步评估多项胜任力指标，使评估效率提升50%以上；<br/>•智能追问：基于语义理解技术实时生成针对性追问，确保核心能力评估的完整性；<br/>•简历深度分析：自动识别候选人简历中的能力亮点与信息疑点，辅助HR高效筛选；<br/>•全维度测评：覆盖通用能力与专业技能两大维度，支持根据岗位需求自动生成测评题目。<br/>凭借这些功能优势，AI招聘系统已在初筛及技术复试等关键环节发挥重要作用，成为招聘团队的核心辅助工具。<br/>三、候选人体验优化<br/>针对早期AI面试系统存在的体验不佳问题，新一代系统从候选人需求出发进行全面升级，通过人性化设计提升面试参与度，具体改进包括：<br/>•新增情绪识别与引导功能，实时感知候选人状态并给予适当提示，提升其表现稳定性；<br/>•采用无断点交互设计，模拟真实面试中的对话场景，降低使用陌生感；<br/>•优化视觉呈现效果，增强场景沉浸感，提升整体面试体验；<br/>•支持多轮问答互动，及时解答候选人关于面试流程的疑问，减少信息不对称。<br/>在人才竞争日益激烈的市场环境下，优质的面试体验已成为企业雇主品牌建设的重要组成部分，AI系统的体验优化对此具有积极意义。<br/>四、全流程自动化人才寻访<br/>除面试评估环节外，AI技术在人才寻访领域的应用也实现了突破性进展，自动化人才寻访系统完成了从人才识别到信息录入的全流程智能化覆盖，核心功能包括：<br/>•快速初始化部署：可根据企业招聘需求快速完成系统配置，缩短上线周期；<br/>•自动筛选与智能沟通：基于岗位画像自动筛选匹配人才，并通过智能话术完成初步沟通；<br/>•全覆盖应答机制：针对候选人常见问题实现24小时自动应答，提升沟通效率；<br/>•数据自动同步：将候选人信息及沟通记录自动同步至企业HR系统，实现数据无缝对接。<br/>该系统的应用显著降低了人才寻访环节的人工成本，提升了整体招聘效率与人才匹配精准度。<br/>五、技术应用的验证路径<br/>为帮助企业降低AI技术应用风险，目前相关AI招聘系统已提供实际场景验证渠道，企业用户可在真实的招聘环境中，对系统在面试、测评、筛选等多个环节的效果进行全面测试。这种低风险的体验途径，为招聘团队了解并应用AI技术提供了便利。<br/>从应用实践来看，多家知名企业及高校已引入这类AI招聘工具，其实际应用效果获得了行业认可。当前，AI招聘技术的发展重点集中于精准选人与体验提升两大方向，最新版本的系统在这两个维度均展现出较高的技术水平，为招聘行业的智能化转型提供了有力支撑。</p>]]></description></item><item>    <title><![CDATA[连接池的价值与风险——池化提升与资源枯竭]]></title>    <link>https://segmentfault.com/a/1190000047438753</link>    <guid>https://segmentfault.com/a/1190000047438753</guid>    <pubDate>2025-11-30 13:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <blockquote>连接池是现代应用架构中的基础设施，用好了是性能加速器，配置不当则成为系统崩溃的导火索</blockquote><p>在数据库应用系统中，连接管理是影响性能的关键因素之一。数据库连接池通过池化技术将昂贵的数据库连接进行复用，显著提升了系统性能，但不当的配置和使用也会导致资源枯竭甚至系统崩溃。本文将深入探讨连接池的工作机制、优化策略以及风险防范，帮助开发者掌握这一强大而危险的工具。</p><h2>1 连接池的本质与演进历程</h2><h3>1.1 连接池解决的核心问题</h3><p>在传统的数据库访问模式中，应用程序每次需要与数据库交互时都会创建新的连接，完成操作后立即关闭。这种方式存在明显的性能缺陷：建立数据库连接是​<strong>昂贵操作</strong>​，通常需要 10-20ms 的耗时，涉及 TCP 三次握手、数据库身份验证和会话初始化等多个步骤 。</p><p>连接池通过<strong>连接复用</strong>机制解决了这一性能瓶颈。它在系统初始化时创建一定数量的数据库连接并维护在池中，当应用程序需要连接时，直接从池中获取空闲连接而非新建，使用完毕后归还给连接池而非实际关闭 。这种机制特别适合 Web 应用等高并发场景，其中大量短生命周期请求频繁访问数据库 。</p><h3>1.2 连接池的演进历程</h3><p>连接池技术经历了从简单到复杂、从功能单一到智能管理的演进过程。早期连接池如 DBCP 和 C3P0 奠定了基本模式，现代连接池如 HikariCP 和 Druid 则在性能和可观测性方面有了显著提升 。</p><p><strong>HikariCP</strong> 以其极简设计和卓越性能成为 Spring Boot 的默认连接池，它通过无锁并发结构和字节码优化实现了在高并发场景下的优异表现 。<strong>Druid</strong> 则提供了更为全面的功能，包括 SQL 监控、防御注入攻击和可视化界面，适合需要深度监控的复杂企业环境 。</p><h2>2 连接池的核心价值与性能提升机制</h2><h3>2.1 性能提升的三重机制</h3><p>连接池通过三种核心机制提升系统性能：<strong>连接复用</strong>避免了频繁创建和销毁连接的开销，使系统能够将资源集中于业务处理而非连接管理 。<strong>连接预热</strong>在系统启动阶段初始化连接，保证服务就绪后立即具备处理能力，避免首批请求的冷启动延迟 。<strong>统一管理</strong>通过参数配置实现连接的合理分配和故障转移，提高系统稳定性 。</p><h3>2.2 资源消耗优化</h3><p>连接池通过多种机制优化资源使用：<strong>资源回收</strong>自动关闭空闲超时连接，防止资源泄露 。<strong>弹性伸缩</strong>根据系统负载动态调整活跃连接数，平衡性能与资源消耗 。<strong>失效检测</strong>通过心跳机制识别并替换失效连接，保证连接可用性 。</p><h2>3 连接池的潜在风险与资源枯竭场景</h2><h3>3.1 连接泄露与池耗尽</h3><p><strong>连接泄露</strong>是连接池最常见的问题，当应用程序获取连接后未正确释放，会导致池中可用连接逐渐减少直至耗尽 。典型场景包括异常路径下未在 finally 块中关闭连接、框架配置错误导致连接未归还等。</p><p><strong>连接池耗尽</strong>则发生在系统并发请求超过连接池最大容量时，新请求将陷入长时间等待或直接失败 。这种状况通常由突发流量、慢查询累积或下游系统故障引发。</p><h3>3.2 错误配置的连锁反应</h3><p>不合理的参数配置会引发多种问题：<strong>过大连接数</strong>可能压垮数据库，导致级联故障 。<strong>过长等待时间</strong>会耗尽应用服务器资源，造成系统假死 。<strong>不足验证</strong>会导致应用使用无效连接，增加业务失败率 。</p><h2>4 关键配置参数与调优策略</h2><h3>4.1 容量规划参数</h3><p>​<strong>最大连接数</strong>​（maxActive/maximumPoolSize）是连接池最重要的参数，直接影响系统最大并发能力。设置过小会导致请求阻塞，设置过大会增加数据库负担 。经验公式为：<code>最大连接数 = (核心数 * 2) + 磁盘数</code>，但需根据实际业务测试调整 。</p><p>​<strong>最小空闲连接</strong>​（minIdle/minimumIdle）决定了池中保持的最小空闲连接数，合理设置可以平衡突发流量响应与资源消耗 。通常设置为最大连接数的 25%-50%，根据业务波动特征调整 。</p><h3>4.2 健康检测参数</h3><p>​<strong>验证查询</strong>​（validationQuery）是简单的 SQL 语句（如 SELECT 1），用于检查连接是否有效 。​<strong>测试策略</strong>​（testOnBorrow/testWhileIdle）决定了何时执行验证，<code>testWhileIdle</code> 模式在性能与可靠性间提供了较好平衡 。</p><p>​<strong>存活时间</strong>​（maxLifetime）控制连接最大存活时间，避免长期运行导致的隐性问题 。​<strong>空闲超时</strong>​（idleTimeout）自动回收闲置连接，释放资源 。</p><h2>5 监控指标与故障诊断</h2><h3>5.1 核心监控指标</h3><p><strong>活跃连接数</strong>反映系统当前负载，持续接近最大值表明需要扩容 。<strong>等待线程数</strong>显示排队等待连接的请求数，非零值表示连接不足 。<strong>连接获取时间</strong>直接影响用户体验，突增通常预示问题 。</p><h3>5.2 故障诊断流程</h3><p>当出现连接池问题时，系统化的诊断流程至关重要：首先检查​<strong>基础指标</strong>​，确认活跃连接、等待线程等关键数据 。然后分析​<strong>等待链</strong>​，找出持有连接时间过长的操作 。最后检查​<strong>系统资源</strong>​，确认数据库负载和网络状况 。</p><h2>6 不同场景下的配置策略</h2><h3>6.1 高并发 Web 应用</h3><p>对于在线交易类应用，推荐配置：较小​<strong>最大连接数</strong>​（20-100）避免数据库过载，较短​<strong>最大等待时间</strong>​（1-3 秒）快速失败而非阻塞，启用<strong>泄露检测</strong>快速定位未关闭连接 。</p><h3>6.2 批处理与报表系统</h3><p>对于长时间运行的数据处理任务，适合的配置包括：适中​<strong>连接数</strong>​（10-30）减少数据库压力，较长<strong>超时设置</strong>适应复杂查询，开启<strong>事务隔离</strong>保证数据一致性 。</p><h2>7 连接池选型指南</h2><h3>7.1 性能优先场景</h3><p><strong>HikariCP</strong> 是性能敏感场景的首选，其极简设计和高并发性能表现优异 。适合微服务架构和云原生环境，特别是容器化部署的轻量级应用 。</p><h3>7.2 可观测性优先场景</h3><p><strong>Druid</strong> 提供丰富的监控功能，适合需要详细连接统计和 SQL 分析的企业环境 。内置防 SQL 注入和慢查询检测功能，为复杂应用提供全方位保护 。</p><h2>总结</h2><p>连接池是现代应用架构中的关键组件，正确使用可以提升性能几个数量级，配置不当则会导致系统脆弱不堪。成功的连接池管理需要深入理解业务特征、持续监控关键指标以及建立完善的故障处理机制。</p><p>连接池优化不是一次性的任务，而是需要随着业务发展不断调整的持续过程。通过科学的容量规划、细致的监控预警和快速的故障响应，可以最大化连接池的价值，避免资源枯竭风险。</p><hr/><p><strong>📚 下篇预告</strong>​</p><p>《MyBatis 设计观——映射思想、动态 SQL 的边界与可维护性考量》—— 我们将深入探讨：</p><ul><li>🗺️ ​<strong>ORM 映射哲学</strong>​：MyBatis 如何平衡数据库操作与面向对象思维的鸿沟</li><li>🔄 ​<strong>动态 SQL 边界</strong>​：何时使用动态 SQL，何时应该避免过度灵活带来的复杂性</li><li>🏗️ ​<strong>架构可维护性</strong>​：MyBatis 项目结构与配置组织的最佳实践</li><li>⚡ ​<strong>性能优化策略</strong>​：MyBatis 缓存机制与 SQL 执行过程的调优要点</li><li>🔍 ​<strong>代码生成与手写平衡</strong>​：如何在开发效率与控制力之间找到最佳平衡点</li></ul><p><strong>​点击关注，掌握 MyBatis 设计的精髓！​</strong>​</p><blockquote><p>​<strong>今日行动建议</strong>​：</p><ol><li>检查当前项目连接池配置，对比本文推荐值进行合理性评估</li><li>在测试环境模拟连接泄露场景，验证监控告警有效性</li><li>对关键业务接口进行压力测试，确定连接池参数的最优值</li><li>建立连接池监控仪表盘，跟踪核心指标变化趋势</li></ol></blockquote>]]></description></item><item>    <title><![CDATA[【URP】Unity[内置Shader]]]></title>    <link>https://segmentfault.com/a/1190000047438702</link>    <guid>https://segmentfault.com/a/1190000047438702</guid>    <pubDate>2025-11-30 12:03:00</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <blockquote><a href="https://link.segmentfault.com/?enc=x2UIDTjMy30QedSAazUgnQ%3D%3D.LFI0ucK6di2ZW8gxLKjdiWPGeLaJ4HtFlEwe7oVXWnpnh4F1EPMsdZDzVKsOR%2FUC9MYX%2BVS%2FYUPD3aijcVJZoOlJAJlcJ42qi%2Bsa2oBSezflTeH6uQynczL%2Blm3wmOTXi3mhDcvunX30NN%2Fqy6tJ7UZrR9dLSNrLGCzrbLjcttetuNmiY83sNQLosvJReRH05o6mtqRuyk%2BjP3zq6uCTVKKi8P3kVONwvUPqqdPJcLs%3D" rel="nofollow" target="_blank">【从UnityURP开始探索游戏渲染】</a><strong>专栏-直达</strong></blockquote><h2><strong>URP内置Unlit Shader的作用与原理</strong></h2><p><a href="https://link.segmentfault.com/?enc=fs%2F%2F%2BRXwo1wf8sx8L6ogag%3D%3D.shou9%2FoPJ%2FEq8xnXfUuE5qj%2BoJs8SVkc0XsbVsiuH9P9kG%2FvMUY%2Fb0llbMLODkTMKQG8RO9Wpz87nqQ8PrOEpsQU3X%2BymEsH9oyTcaHFTTFCL90Pdhe9a%2BFCS%2FRgRxVgzWMWsCOI2GyyX5dNRf5DRw%3D%3D" rel="nofollow" target="_blank">Unlit Shader</a>是Unity通用渲染管线(URP)中的基础着色器，主要用于渲染不受光照影响的物体。其核心原理是通过直接采样纹理或颜色值输出到屏幕，跳过了复杂的光照计算流程。这种着色器特别适合UI元素、粒子特效、全息投影等需要保持恒定亮度的场景，因为它的渲染结果不会随光照环境变化而改变。</p><p>在URP架构中，Unlit Shader通过ShaderLab语法定义，内部使用HLSL编写核心逻辑。与Built-in管线相比，URP版本优化了渲染流程，包含三个关键Pass：主绘制Pass、深度Only Pass和元数据Pass（用于光照烘焙）。其核心特点是：</p><ul><li>无光照计算：直接输出Albedo颜色或纹理采样结果</li><li>支持Alpha混合：可实现透明效果</li><li>移动端优化：减少了GPU指令数量</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438704" alt="" title=""/></p><h2><strong>发展历史演变</strong></h2><p>Unlit Shader随着Unity渲染管线的演进经历了三个阶段：</p><ul><li>‌<strong>Built-in管线时期</strong>‌（2012-2018）：最初作为简单着色器出现在标准资源包中，使用CG语言编写，功能较为基础</li><li>‌<strong>LWRP过渡期</strong>‌（2018-2020）：轻量级渲染管线中首次针对移动平台优化，引入HLSL替代CG</li><li>‌<strong>URP成熟期</strong>‌（2020至今）：成为Universal RP的核心组件，支持Shader Graph可视化编程，并优化了多Pass协作机制</li></ul><h2><strong>具体使用示例</strong></h2><p>创建Unlit材质的基本步骤：</p><ul><li>在Project窗口右键创建Material</li><li>材质Inspector中选择Shader路径："Universal Render Pipeline/Unlit"</li><li><p>配置基础属性：</p><ul><li>‌<strong>Base Map</strong>‌：主纹理贴图</li><li>‌<strong>Base Color</strong>‌：色调叠加</li><li>‌<strong>Alpha</strong>‌：透明度控制</li></ul></li></ul><p>代码说明：</p><ul><li>定义包含纹理和颜色属性的基础Unlit Shader</li><li>使用URP核心库中的TransformObjectToHClip方法进行坐标转换</li><li>片元着色器直接返回纹理采样结果与颜色的乘积</li><li><p>UnlitExample.shader</p><pre><code class="c">Shader "Custom/UnlitTexture"
{
    Properties {
        _MainTex ("Texture", 2D) = "white" {}
        _Color ("Color", Color) = (1,1,1,1)
    }
    SubShader {
        Tags { "RenderType"="Opaque" }
        Pass {
            HLSLPROGRAM
            #pragma vertex vert
            #pragma fragment frag
            #include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl"

            struct Attributes {
                float4 positionOS : POSITION;
                float2 uv : TEXCOORD0;
            };

            struct Varyings {
                float4 positionCS : SV_POSITION;
                float2 uv : TEXCOORD0;
            };

            sampler2D _MainTex;
            float4 _Color;

            Varyings vert(Attributes IN) {
                Varyings OUT;
                OUT.positionCS = TransformObjectToHClip(IN.positionOS.xyz);
                OUT.uv = IN.uv;
                return OUT;
            }

            half4 frag(Varyings IN) : SV_Target {
                return tex2D(_MainTex, IN.uv) * _Color;
            }
            ENDHLSL
        }
    }
}</code></pre></li><li><p>UnlitGraph.shadergraph</p><pre><code class="c">{
    "m_Nodes": [
        {
            "m_Id": "d4f5e3c7-1a2d-4b8f-a3e1-6c9b8d2e1f0a",
            "m_Type": "UnityEditor.ShaderGraph.Texture2DNode",
            "m_Position": { "x": -208, "y": -16 },
            "m_Outputs": [ { "m_Id": "out" } ],
            "m_Texture": { "m_DefaultValue": {} }
        },
        {
            "m_Id": "a1b2c3d4-e5f6-7g8h-9i0j-k1l2m3n4o5p6",
            "m_Type": "UnityEditor.ShaderGraph.ColorNode",
            "m_Position": { "x": -200, "y": 100 },
            "m_Outputs": [ { "m_Id": "out" } ],
            "m_Color": { "r": 1, "g": 1, "b": 1, "a": 1 }
        },
        {
            "m_Id": "b2c3d4e5-f6g7-8h9i-0j1k-l2m3n4o5p6q7",
            "m_Type": "UnityEditor.ShaderGraph.MultiplyNode",
            "m_Position": { "x": 0, "y": 0 },
            "m_Inputs": [
                { "m_Id": "a", "m_SlotId": 0 },
                { "m_Id": "b", "m_SlotId": 1 }
            ],
            "m_Outputs": [ { "m_Id": "out" } ]
        }
    ],
    "m_Edges": [
        { "m_OutputSlot": "d4f5e3c7-1a2d-4b8f-a3e1-6c9b8d2e1f0a.out", "m_InputSlot": "b2c3d4e5-f6g7-8h9i-0j1k-l2m3n4o5p6q7.a" },
        { "m_OutputSlot": "a1b2c3d4-e5f6-7g8h-9i0j-k1l2m3n4o5p6.out", "m_InputSlot": "b2c3d4e5-f6g7-8h9i-0j1k-l2m3n4o5p6q7.b" }
    ]
}</code></pre></li></ul><h2><strong>Shader Graph应用示例</strong></h2><p>在Shader Graph中创建Unlit效果的步骤：</p><ul><li>创建新的Shader Graph文件（右键 &gt; Create &gt; Shader &gt; Universal Render Pipeline &gt; Unlit Shader Graph）</li><li><p>核心节点配置：</p><ul><li>添加‌<strong>Sample Texture 2D</strong>‌节点作为基础纹理输入</li><li>连接‌<strong>Color</strong>‌参数节点实现色调控制</li><li>使用‌<strong>Multiply</strong>‌节点混合纹理和颜色</li></ul></li><li><p>高级功能扩展：</p><ul><li>添加‌<strong>Time</strong>‌节点驱动UV动画</li><li>通过‌<strong>Vertex Position</strong>‌节点实现顶点变形</li></ul></li></ul><p>代码说明：</p><ul><li>构建包含纹理采样和颜色混合的基础Unlit着色器</li><li>通过节点连接实现材质属性的可视化编辑</li><li>可扩展添加UV滚动、顶点动画等高级效果</li><li><p>UnlitExample.shader</p><pre><code class="c">Shader "Custom/UnlitTexture"
{
    Properties {
        _MainTex ("Texture", 2D) = "white" {}
        _Color ("Color", Color) = (1,1,1,1)
    }
    SubShader {
        Tags { "RenderType"="Opaque" }
        Pass {
            HLSLPROGRAM
            #pragma vertex vert
            #pragma fragment frag
            #include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl"

            struct Attributes {
                float4 positionOS : POSITION;
                float2 uv : TEXCOORD0;
            };

            struct Varyings {
                float4 positionCS : SV_POSITION;
                float2 uv : TEXCOORD0;
            };

            sampler2D _MainTex;
            float4 _Color;

            Varyings vert(Attributes IN) {
                Varyings OUT;
                OUT.positionCS = TransformObjectToHClip(IN.positionOS.xyz);
                OUT.uv = IN.uv;
                return OUT;
            }

            half4 frag(Varyings IN) : SV_Target {
                return tex2D(_MainTex, IN.uv) * _Color;
            }
            ENDHLSL
        }
    }
}</code></pre></li><li><p>UnlitGraph.shadergraph</p><pre><code class="c">{
    "m_Nodes": [
        {
            "m_Id": "d4f5e3c7-1a2d-4b8f-a3e1-6c9b8d2e1f0a",
            "m_Type": "UnityEditor.ShaderGraph.Texture2DNode",
            "m_Position": { "x": -208, "y": -16 },
            "m_Outputs": [ { "m_Id": "out" } ],
            "m_Texture": { "m_DefaultValue": {} }
        },
        {
            "m_Id": "a1b2c3d4-e5f6-7g8h-9i0j-k1l2m3n4o5p6",
            "m_Type": "UnityEditor.ShaderGraph.ColorNode",
            "m_Position": { "x": -200, "y": 100 },
            "m_Outputs": [ { "m_Id": "out" } ],
            "m_Color": { "r": 1, "g": 1, "b": 1, "a": 1 }
        },
        {
            "m_Id": "b2c3d4e5-f6g7-8h9i-0j1k-l2m3n4o5p6q7",
            "m_Type": "UnityEditor.ShaderGraph.MultiplyNode",
            "m_Position": { "x": 0, "y": 0 },
            "m_Inputs": [
                { "m_Id": "a", "m_SlotId": 0 },
                { "m_Id": "b", "m_SlotId": 1 }
            ],
            "m_Outputs": [ { "m_Id": "out" } ]
        }
    ],
    "m_Edges": [
        { "m_OutputSlot": "d4f5e3c7-1a2d-4b8f-a3e1-6c9b8d2e1f0a.out", "m_InputSlot": "b2c3d4e5-f6g7-8h9i-0j1k-l2m3n4o5p6q7.a" },
        { "m_OutputSlot": "a1b2c3d4-e5f6-7g8h-9i0j-k1l2m3n4o5p6.out", "m_InputSlot": "b2c3d4e5-f6g7-8h9i-0j1k-l2m3n4o5p6q7.b" }
    ]
}</code></pre></li></ul><p>实际应用时可结合粒子系统创建发光轨迹，或为UI元素添加动态高亮效果。URP Unlit Shader的轻量级特性使其在移动设备上能保持60fps以上的渲染性能</p><h2>典型应用场景及实现</h2><h3><strong>光晕效果（Halo）</strong></h3><ul><li>‌<strong>应用实例</strong>‌：角色技能特效、UI高亮提示。通过透明纹理实现边缘发光，如1中描述的透明光晕材质。</li><li><p>‌<strong>实现步骤</strong>‌：</p><ul><li>导入纹理并设置：<code>Texture Type</code>为<code>Default (sRGB)</code>，勾选<code>Alpha Is Transparency</code>，<code>Wrap Mode</code>设为<code>Clamp</code>。</li><li>创建材质：选择<code>Universal Render Pipeline/Unlit</code> Shader，设置<code>Surface Type</code>为<code>Transparent</code>，拖拽纹理到<code>Base Map</code>插槽。</li><li>调整<code>Tint</code>颜色控制光晕色彩。</li></ul></li></ul><h3><strong>全息投影效果</strong></h3><ul><li>‌<strong>应用实例</strong>‌：科幻场景中的虚拟角色或界面。结合透明度与扫描线纹理。</li><li><p>‌<strong>实现步骤</strong>‌：</p><ul><li>使用<code>Unlit</code> Shader并启用透明混合（<code>Blend SrcAlpha OneMinusSrcAlpha</code>）。</li><li>添加顶点偏移代码模拟全息抖动，通过<code>_Time</code>变量控制动态效果。</li><li>叠加扫描线纹理（如<code>_HologramLine1</code>）和菲涅尔反射增强立体感。</li></ul></li></ul><h3><strong>透明遮罩（如塑料薄膜）</strong></h3><ul><li>‌<strong>应用实例</strong>‌：UI遮罩或半透明装饰物。通过Alpha通道控制透明度，如中的塑料薄膜材质。</li><li><p>‌<strong>实现步骤</strong>‌：</p><ul><li>在图片编辑器中创建带Alpha通道的纹理，白色区域不透明，灰色区域半透明。</li><li>材质Shader选择<code>Unlit</code>，设置<code>Transparent</code>模式，纹理绑定到<code>Base Map</code>。</li></ul></li></ul><h3><strong>发光广告牌（Billboard）</strong></h3><ul><li>‌<strong>应用实例</strong>‌：游戏内固定亮度标识或霓虹灯。直接显示纹理颜色不受光照影响。</li><li><p>‌<strong>实现步骤</strong>‌：</p><ul><li>使用<code>Unlit</code> Shader，<code>Surface Type</code>设为<code>Opaque</code>。</li><li>通过<code>Base Map</code>设置发光纹理，调整<code>Tint</code>颜色增强亮度。</li></ul></li></ul><h3><strong>景深遮挡标记</strong></h3><ul><li>‌<strong>应用实例</strong>‌：半透明物体深度写入（如玻璃瓶），解决景深效果失效问题。</li><li><p>‌<strong>实现步骤</strong>‌：</p><ul><li>创建两个材质：一个透明材质（<code>Queue=Transparent</code>），一个深度写入材质（<code>Queue=2000</code>）。</li><li>深度写入材质使用<code>Unlit</code> Shader并启用<code>ZWrite On</code>。</li></ul></li></ul><h3><strong>关键注意事项</strong></h3><ul><li>‌<strong>渲染顺序</strong>‌：透明物体需关闭深度写入（<code>ZWrite Off</code>），并合理设置<code>Queue</code>标签避免混合错误。</li><li>‌<strong>性能优化</strong>‌：复杂效果（如全息投影）建议结合顶点着色器计算，减少片元着色器负担</li></ul><hr/><blockquote><a href="https://link.segmentfault.com/?enc=Ci3ZLiUmcKa4b0JOuyV1EQ%3D%3D.8clYuyajqYqNn6lBHE2R7WwhnMvimiLgnmGNuMCM9Rj7cU5bEc1HPWJDngLwJqx1zQkezpYq4utFdXz8nEe5heLe%2Bx01J4Ts3s8XF%2FD%2BFyX%2BqixXC8ZBguV2jlyI82NbJxlhZMqG7X2HE2q%2FxEO3tERzyI8nF1jkQpmSwConE542K66ds%2BjoDRMOgIln%2BtFogND6nsKvWsbuTOejKdlNZEqTZfxnxblweXN7Ux5Bmh0%3D" rel="nofollow" target="_blank">【从UnityURP开始探索游戏渲染】</a><strong>专栏-直达</strong><br/>（欢迎<em>点赞留言</em>探讨，更多人加入进来能更加完善这个探索的过程，🙏）</blockquote>]]></description></item><item>    <title><![CDATA[基于DCT的彩色图像压缩MATLAB实现]]></title>    <link>https://segmentfault.com/a/1190000047438739</link>    <guid>https://segmentfault.com/a/1190000047438739</guid>    <pubDate>2025-11-30 12:02:09</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h4><strong>一、核心流程</strong></h4><p>基于DCT的图像压缩遵循JPEG标准的核心步骤，具体流程如下：</p><ol><li><strong>颜色空间转换</strong>：将RGB图像转换为YCbCr空间，分离亮度（Y）与色度（Cb/Cr）分量。</li><li><strong>分块DCT变换</strong>：将每个通道划分为8×8块，进行二维DCT变换。</li><li><strong>量化</strong>：根据人眼视觉特性设计量化表，对DCT系数进行量化。</li><li><strong>熵编码</strong>：采用Zigzag扫描、游程编码和霍夫曼编码压缩量化后的数据。</li><li><strong>解压缩</strong>：逆向执行熵解码、反量化、逆DCT变换，重构图像。</li></ol><hr/><h4><strong>二、MATLAB代码实现</strong></h4><h5><strong>1. 颜色空间转换与分块</strong></h5><pre><code class="matlab">% 读取图像并转换为YCbCr
img = imread('lena.jpg');
if size(img,3) == 3
    img_ycbcr = rgb2ycbcr(img);
    Y = img_ycbcr(:,:,1);
    Cb = img_ycbcr(:,:,2);
    Cr = img_ycbcr(:,:,3);
else
    Y = img;
    Cb = [];
    Cr = [];
end

% 分块处理（8x8）
block_size = 8;
[rows, cols] = size(Y);
num_blocks_row = ceil(rows / block_size);
num_blocks_col = ceil(cols / block_size);</code></pre><h5><strong>2. DCT变换与量化</strong></h5><pre><code class="matlab">% 定义量化表（JPEG标准）
luminance_quant = [16 11 10 16 24 40 51 61;
                  12 12 14 19 26 58 60 55;
                  14 13 16 24 40 57 69 56;
                  14 17 22 29 51 87 80 62;
                  18 22 37 56 68 109 103 77;
                  24 35 55 64 81 104 113 92;
                  49 64 78 87 103 121 120 101;
                  72 92 95 98 112 100 103 99];

% DCT变换与量化函数
function quant_block = dct_quant(block, quant_table, quality)
    dct_block = dct2(block);
    scale = 100 / quality;  % 质量因子调整量化强度
    quant_block = round(dct_block ./ (quant_table * scale));
end

% 对每个块进行DCT和量化
Y_compressed = zeros(size(Y));
for i = 1:num_blocks_row
    for j = 1:num_blocks_col
        % 提取块
        row = (i-1)*block_size + 1 : min(i*block_size, rows);
        col = (j-1)*block_size + 1 : min(j*block_size, cols);
        block = Y(row,col);
        
        % DCT与量化
        quant_block = dct_quant(block, luminance_quant, 80);
        Y_compressed(row,col) = quant_block;
    end
end</code></pre><h5><strong>3. Zigzag扫描与熵编码</strong></h5><pre><code class="matlab">% Zigzag扫描
function zigzag_vec = zigzag_scan(block)
    zigzag_order = [1,2,6,7,15,16,28,29,3,5,8,14,17,27,30,43,4,9,13,18,26,31,42,44,10,12,19,25,32,41,45,54,11,20,24,33,40,46,53,21,23,34,39,48,52,55,22,35,38,47,51,56,29,50,60,61,62,63,64];
    flat_block = block(:);
    zigzag_vec = flat_block(zigzag_order(1:numel(flat_block)));
end

% 示例：对量化后的块进行Zigzag扫描
zigzag_data = [];
for i = 1:block_size
    for j = 1:block_size
        block = Y_compressed((i-1)*block_size+1:i*block_size, (j-1)*block_size+1:j*block_size);
        zigzag_data = [zigzag_data, zigzag_scan(block)];
    end
end</code></pre><h5><strong>4. 霍夫曼编码</strong></h5><pre><code class="matlab">% 霍夫曼编码（使用MATLAB内置函数）
huff_dict = huffmandict([0:255], [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64]);
encoded_data = huffmandeco(zigzag_data, huff_dict);</code></pre><h5><strong>5. 解压缩与逆变换</strong></h5><pre><code class="matlab">% 逆量化
dequant_block = quant_block .* (quant_table * scale);

% 逆DCT变换
idct_block = idct2(dequant_block);

% 合并块并转换回RGB
reconstructed_Y = zeros(rows,cols);
block_idx = 1;
for i = 1:num_blocks_row
    for j = 1:num_blocks_col
        % 提取逆量化块
        row = (i-1)*block_size + 1 : min(i*block_size, rows);
        col = (j-1)*block_size + 1 : min(j*block_size, cols);
        dequant_block = reshape(encoded_data(block_idx:block_idx+63), [8,8]);
        reconstructed_Y(row,col) = idct_block;
        block_idx = block_idx + 64;
    end
end

% 合并通道并转换回RGB
reconstructed_img = cat(3, reconstructed_Y, Cb, Cr);
reconstructed_img = ycbcr2rgb(reconstructed_img);</code></pre><h4><strong>三、性能评估</strong></h4><pre><code class="matlab">% 计算PSNR
original = im2double(img);
reconstructed = im2double(reconstructed_img);
mse = mean((original(:) - reconstructed(:)).^2);
psnr = 10 * log10(1 / mse);

% 计算压缩率
original_size = rows * cols;
compressed_size = numel(encoded_data);
compression_ratio = original_size / compressed_size;

disp(['PSNR: ', num2str(psnr), ' dB, 压缩率: ', num2str(compression_ratio), ':1']);</code></pre><h4><strong>四、优化点</strong></h4><ol><li><strong>量化表自适应调整</strong>：根据质量因子动态缩放量化表，平衡压缩率与质量。</li><li><strong>颜色空间优化</strong>：对Cb/Cr通道进行4:2:0下采样，减少数据量。</li><li><strong>快速DCT实现</strong>：使用<code>dctmtx</code>预生成变换矩阵，避免重复计算。</li><li><strong>并行分块处理</strong>：利用<code>parfor</code>加速大尺寸图像处理。</li></ol><h4><strong>五、实验结果示例</strong></h4><table><thead><tr><th>压缩质量</th><th>PSNR (dB)</th><th>压缩率 (原图:压缩图)</th><th>视觉质量</th></tr></thead><tbody><tr><td>100</td><td>45.2</td><td>1:1</td><td>几乎无损</td></tr><tr><td>80</td><td>38.7</td><td>4:1</td><td>细节轻微模糊</td></tr><tr><td>50</td><td>32.1</td><td>10:1</td><td>明显块效应</td></tr></tbody></table><p>参考代码  基于DCT的彩色图像压缩    www.youwenfan.com/contentsfa/82678.html</p><h4><strong>六、总结</strong></h4><p>通过上述步骤，可实现基于DCT的彩色图像压缩，核心在于分块DCT、量化表设计及熵编码。实际应用中需结合视觉特性优化量化策略，并通过PSNR等指标评估压缩效果。</p>]]></description></item><item>    <title><![CDATA[FFmpeg开发笔记（九十）采用FFmp]]></title>    <link>https://segmentfault.com/a/1190000047438168</link>    <guid>https://segmentfault.com/a/1190000047438168</guid>    <pubDate>2025-11-30 12:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>​FFmpeg是个经典的音视频处理开源框架，可是FFmpeg仅提供命令行方式，通过FFmpeg剪辑音视频只能在命令行下面操作，从而限制了普通用户掌握FFmpeg。</p><p>虽然《FFmpeg开发实战：从零基础到短视频上线》一书不仅给出了基于FFmpeg函数调用的示例代码，也给出了具体的ffmpeg操作命令，从而兼具FFmpeg的代码开发教程与FFmpeg的命令使用手册两种用途。但是普通用户并非开发者，用户更希望提供桌面程序那种可视化界面，通过鼠标简单操作就能实现音视频文件的剪辑操作。  <br/>FFBox便是一个FFmpeg套壳的多媒体转码百宝箱，它全链路支持：输入→滤镜→编码→输出。参数配置透明直观，对齐FFmpeg的原生用法。所有的FFmpeg参数公开透明，用户通过操作界面，即能同时学习FFmpeg的命令。相比大多数软件仅支持的简单滤镜，FFBox支持完整的流图和滤镜图编辑，可处理复杂的多输入多输出任务。  <br/>FFBox的官网地址为 <a href="https://link.segmentfault.com/?enc=ROCuGIjwXmgMLJzK0V8MFQ%3D%3D.iiI%2FmdZDk70j1oOV2pzayUNTwgxaQ2rbZSdeqeyvLxs%3D" rel="nofollow" target="_blank">http://FFBox.ttqf.tech</a> ，源码托管地址为 <a href="https://link.segmentfault.com/?enc=pGD2k8I8eVGWQVzQQW7AMQ%3D%3D.tjeQzQrBf%2FX8o8FsvBK4IgVgNloW8oLExs%2BE%2F7s%2B5bvCNLVQPtLKKCFFhzXQ0y6a" rel="nofollow" target="_blank">https://github.com/ttqftech/FFBox</a> （星星数1.0k），国内的镜像地址为 <a href="https://link.segmentfault.com/?enc=CFF92438cf5At1kTeHJKLQ%3D%3D.66QbxsoDGmRikIOB%2BL5%2F6Y01JiCBkKO1V5nrcF5O0fk%3D" rel="nofollow" target="_blank">https://gitee.com/ttqf/FFBox</a>和<a href="https://link.segmentfault.com/?enc=lSqdQFiW3fJCBd29SV4CQQ%3D%3D.k4cW5BfglRD6NCMR6ev7N2SB7PJ93P5Tc0ni1A7N%2BmxjQN84KTmnmdcs2KVsR0gW" rel="nofollow" target="_blank">https://gitcode.com/gh_mirrors/ff/FFBox</a> 。最新版本是2025年9月发布的FFBox v5.0，可见该框架的源码更新十分及时，该版本的源码下载链接为 <a href="https://link.segmentfault.com/?enc=BaiV5j9uWQW5ErzXOiU6%2Bw%3D%3D.J5C98IX9%2FTKpe5tQ41jT%2FcnLJnVO51FV3%2FGNTdBe%2BAMpYeQpRsKUpCP6WEp1AOQejSfBLTL3Ajxp9F4u2yUSaw%3D%3D" rel="nofollow" target="_blank">https://github.com/ttqftech/FFBox/archive/refs/tags/v5.0.tar.gz</a> 。  <br/>FFBox基于Node.js开发，同时支持Windows、Linux、macOS等操作系统。FFBox推荐采用VS Code编写代码，如果要在Windows系统上编译FFBoxHelper，则需安装Visual Studio 2022，并采用C++编码。若想在Windows平台上制作安装包，还需安装Inno Setup 6，并将其安装路径放入环境变量中。  <br/>编译通过后的FFBox可执行程序叫做FFBoxHelper.exe，双击exe文件打开FFBox的初始界面如下图所示：</p><p><img width="723" height="670" referrerpolicy="no-referrer" src="/img/bVdm8GT" alt="" title=""/></p><p>在FFBox界面的上方区域可拖曳添加待剪辑的音视频文件，界面中间区域为当前剪辑操作对应的ffmpeg命令，例如：</p><pre><code>ffmpeg -hide_banner -hwaccel auto -i [输入文件路径] -vcodec libx265 -preset medium -crf 24 -acodec copy ./[输出文件路径]_converted.mp4 -y</code></pre><p>界面下方区域为剪辑操作的各项参数，可在此调整具体的选项参数以便符合剪辑需求。单击界面右上角的【开始】按钮，即可令FFBox执行响应的剪辑命令，剪辑完成的结果文件默认保存在原文件的相同目录下，且文件名后缀为“ _converted.mp4 ”。  </p><p>总的来说，FFBox的界面细节考究，视觉体验焕然一新，且图形化实时显示进度、速度、码率、剩余时间等信息，并支持以图表模式直观展示，是个不错的国产多媒体剪辑工具。</p><p>更多详细的FFmpeg开发知识参见<a href="https://link.segmentfault.com/?enc=UejHwta7CIxmYG5T3N7L%2Bw%3D%3D.y%2BwTiXuVro8X0E1rDDsY1If07CjMvV7ROhH3UHbowNsCnHUjsdkEgQnHxG1%2F0JIF" rel="nofollow" title="《FFmpeg开发实战：从零基础到短视频上线》" target="_blank">《FFmpeg开发实战：从零基础到短视频上线》</a>一书。</p><p>​</p>]]></description></item><item>    <title><![CDATA[集成电路设计中的IP核心价值：加速创新的]]></title>    <link>https://segmentfault.com/a/1190000047438667</link>    <guid>https://segmentfault.com/a/1190000047438667</guid>    <pubDate>2025-11-30 11:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在集成电路（IC）设计的世界里，知识产权（Intellectual Property，简称 IP）已经成为推动创新与效率的关键力量。它不仅缩短了设计周期，还为工程师们提供了更多专注于差异化和前沿探索的空间。今天，就让我们走进IC设计中的IP，揭示它的重要性与最佳实践。<br/><img width="723" height="487" referrerpolicy="no-referrer" src="/img/bVdnc7V" alt="" title=""/><br/>1、为什么IP如此重要？<br/>在复杂的IC设计过程中，IP扮演着“现成积木”的角色。它们是经过验证、可复用的功能模块，涵盖从基础逻辑电路到完整的处理器核心。借助这些模块，设计团队无需从零开始重复造轮子，而是能够直接构建在成熟基础之上，从而降低成本并显著提升效率。</p><p>2、IP的多样性<br/>IC设计中的IP大致分为两类：<br/>硬IP（Hard IP）：已经为特定工艺优化、综合完成的电路模块，可直接应用，但可配置性较低。<br/>软IP（Soft IP）：以代码形式存在，可灵活配置和调整，满足不同设计需求。<br/>两者相辅相成，设计师可根据项目特性选择最优组合。</p><p>3、利用IP的最佳实践<br/>想要高效发挥IP的价值，必须遵循一些最佳实践：<br/>完整的文档与规范：确保团队成员能快速理解并应用IP；<br/>系统级验证：在整个设计环境下对IP进行全面测试，避免集成后出现意外问题；<br/>标准化管理：遵循行业标准，提高兼容性与复用率。</p><p>4、集成IP的挑战<br/>尽管IP带来了巨大的便利，但设计过程中仍不可避免地遇到挑战。例如，不同IP之间的兼容性问题、复杂的授权与许可管理，以及多模块协同设计的复杂性。这些问题需要依赖于经验、流程管理和先进工具来逐步化解。</p><p>5、学习与成长的机会<br/>对于立志进入或深入IC行业的工程师而言，系统学习IP在IC设计中的应用至关重要。如果你正在寻找专业的学习资源，推荐关注 EDA Academy（www.eda-academy.com）。</p><p>在 EDA Academy：<br/>你可以学习大量最新、专业、全面的在线课程，涵盖IP、IC设计、EDA工具等核心主题；<br/>你可以注册成为导师，分享经验并转化为课程收入；<br/>你可以通过邮箱免费订阅newsletter，定期获取行业前沿动态；<br/>你还可以加入销售联盟计划，通过推荐课程赚取 20%-50%的佣金。</p><p>IP已成为现代IC设计不可或缺的基石，它不仅提高了开发效率，更释放了设计师的创造力。通过理解IP的类型、掌握最佳实践并妥善应对集成挑战，工程师们能够在竞争激烈的行业中脱颖而出。如果你渴望深入学习并快速提升自己，不妨从 EDA Academy 开始，开启属于你的IC设计新篇章。<br/><img width="723" height="1098" referrerpolicy="no-referrer" src="/img/bVdnc7W" alt="" title="" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[达梦数据库安装教程 dm8_202110]]></title>    <link>https://segmentfault.com/a/1190000047438583</link>    <guid>https://segmentfault.com/a/1190000047438583</guid>    <pubDate>2025-11-30 10:04:16</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>​</p><p>是达梦数据库 DM8 的 Windows 64位企业版安装包，日期是 2021 年 10 月 25 日编译的版本。里面包含了数据库服务端、客户端和一些常用管理工具，</p><h2>1. 解压安装包</h2><ul><li><strong>提供安装包下载：</strong><a href="https://link.segmentfault.com/?enc=4F1N8W1l0XD0LpqiIXbRtQ%3D%3D.%2BgemjW%2FSEH5yPIvuU0zaBL3i5XOVuExt6wDKDzLUlsPhseOp%2BqUa4o4xtj9RSkMo" rel="nofollow" title="https://pan.quark.cn/s/301611c6df7f" target="_blank">https://pan.quark.cn/s/301611c6df7f</a> ，下载的 <code>dm8_20211025_x86_win_64_ent.zip</code>文件。</li><li>右键 → 解压到某个文件夹，比如 <code>D:\dm8</code>。</li><li>解压完，里面会有个 <code>setup.exe</code>，这就是安装程序。</li></ul><h2>2. 运行安装程序</h2><ul><li>双击 <code>setup.exe</code>。</li><li>弹出提示“是否允许此应用对设备进行更改”，点 <strong>是</strong>。</li></ul><h2>3. 选择语言</h2><ul><li>默认是 <strong>简体中文</strong>，直接点 <strong>确定</strong>。</li><li>欢迎界面点 <strong>下一步</strong>。</li></ul><h2>4. 同意许可协议</h2><ul><li>勾选 <strong>我接受协议</strong>，点 <strong>下一步</strong>。</li></ul><h2>5. 填写用户信息</h2><ul><li>公司名、用户名随便填（能记住就行），点 <strong>下一步</strong>。</li></ul><h2>6. 选择安装目录</h2><ul><li>默认在 C 盘，可点 <strong>浏览</strong>​ 改到其他盘，比如 <code>D:\dm8</code>，点 <strong>下一步</strong>。</li></ul><h2>7. 选择安装类型</h2><ul><li>新手直接选 <strong>典型安装</strong>（常用功能全装好），点 <strong>下一步</strong>。</li></ul><h2>8. 开始安装</h2><ul><li>点 <strong>安装</strong>，等进度条跑完，别中途关窗口。</li></ul><h2>9. 完成安装</h2><ul><li>装完后可能会问 <strong>是否初始化数据库</strong>，要用数据库就勾上，然后点 <strong>完成</strong>。</li><li>如果暂时不用数据库，可以不勾，后面单独弄。</li></ul><h2>10. 检查是否成功</h2><ul><li>在开始菜单或桌面找 “达梦管理工具” 或类似图标，能打开并连接数据库就说明装好了。</li></ul><p>​</p>]]></description></item><item>    <title><![CDATA[袋鼠数据库工具 8.92.1 版已上线 ]]></title>    <link>https://segmentfault.com/a/1190000047438621</link>    <guid>https://segmentfault.com/a/1190000047438621</guid>    <pubDate>2025-11-30 10:03:20</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>袋鼠数据库工具 是一款 AI 驱动的热门数据库系统客户端(MariaDB / MongoDB / MySQL / Oracle / PostgreSQL / Redis / SQLite / SQLServer / ...) ，支持建表、查询、模型、同步、导入导出等功能，支持 Windows / Mac / Linux 等操作系统，致力于打造一款好用、好玩、开发友好的开发者工具。</p><h2>重点特性介绍</h2><p>这个版本继续聚焦 MongoDB 支持，实现了更多 MongoDB 数据库对象设计器支持，完整实现了集合视图、聚合文件、聚合命令构建、查找命令构建、用户、角色、函数等对象的支持；对部分界面布局做了优化，改进了体验的一致性；完善了工作空间布局缓存支持等。</p><h2>新特性或修复的缺陷列表</h2><ul><li>MongoDB: 实现视图设计器逻辑</li><li>MongoDB: 实现查找构建器对话框逻辑</li><li>MongoDB: 实现聚合构建器对话框逻辑</li><li>MongoDB: 实现分析命令支持</li><li>MongoDB: 新增聚合文件支持</li><li>MongoDB: 新增函数设计器支持</li><li>MongoDB: 新增角色设计器支持</li><li>MongoDB: 新增用户设计器支持</li><li>MongoDB: 实现工作空间布局和缓存支持</li><li>MongoDB: 用户/角色/函数删除支持</li><li>文件面板增加文件支持</li><li>表视图: 增加字段位置调整支持</li><li>更新中文语言支持(zh-CN/zh-SG/zh-Hans/zh-Hant)</li><li>升级界面库版本 (GLib 2.86 / GTK 4.20.3 / libadwaita 1.8.2)</li><li>重构部分页面 (AdwPreferencesPage)</li><li>修复: 偶尔出现的不能保存布局的问题</li><li>修复: SQL 构建器名字空间中出现点问题的处理</li><li>修复: 权限设计器菜单无法响应的问题</li><li>修复: 工作空间布局文件无限增长</li><li>修复: 控制台警告消息</li></ul><h2>下载与安装</h2><p><a href="https://link.segmentfault.com/?enc=p3HZ%2B7Swts2C5nlpaaj%2BHw%3D%3D.YK43vIR9B2btuWXf6CshZDfyxjBGn0S1JwswcZlW%2BGbJRP%2BhMLbir3%2BSVUZB9Q29%2BvPpIPTs%2ByatybCi44sVWg%3D%3D" rel="nofollow" target="_blank">袋鼠数据库管理工具 8.92.1</a></p><h2>新版本功能快照</h2><p><a href="https://link.segmentfault.com/?enc=6%2FNlunbkTnvJzCwupj%2FjSg%3D%3D.Lw0fdMUUoLCkB9FF%2BbMpBy%2BZ7YMANqo99omG%2BuxZ8Bl5JUjb9Sa7pJJxIYNkVQnZ9C2jyLiCXtaD6SK82hxVrQ%3D%3D" rel="nofollow" title="MongoDB 视图编辑" target="_blank"><img width="723" height="490" referrerpolicy="no-referrer" src="/img/bVdnb2v" alt="MongoDB 视图编辑" title="MongoDB 视图编辑"/></a></p><p><a href="https://link.segmentfault.com/?enc=8FdKWD%2BeOWq0r0zSWja%2FpA%3D%3D.ZuLB7N61ZhocoflAJS7UoQ56Oq0cGKCAZPlZXlX7ZLIFTW0ZWFshOb0xbkte6lFN9noU8Npl1jiSTF8vNGWMHg%3D%3D" rel="nofollow" title="MongoDB 函数编辑" target="_blank"><img width="723" height="491" referrerpolicy="no-referrer" src="/img/bVdnb2w" alt="MongoDB 函数编辑" title="MongoDB 函数编辑" loading="lazy"/></a></p><p><a href="https://link.segmentfault.com/?enc=MLCiwFVXSLir2VJUS0hRbA%3D%3D.K%2FiDNu%2FiIVvGpW%2FYLeR5%2FgT5r5Sp7zi112lyuf1Qp0cQnOY8UZfw37XxLJxIUMGzV9PUf6yhGpI%2Fac5JZt882Q%3D%3D" rel="nofollow" title="MongoDB 查找命令构建" target="_blank"><img width="723" height="490" referrerpolicy="no-referrer" src="/img/bVdnb2x" alt="MongoDB 查找命令构建" title="MongoDB 查找命令构建" loading="lazy"/></a></p>]]></description></item><item>    <title><![CDATA[Room Arranger for Ma]]></title>    <link>https://segmentfault.com/a/1190000047438631</link>    <guid>https://segmentfault.com/a/1190000047438631</guid>    <pubDate>2025-11-30 10:02:20</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>​Room Arranger 是一个用来画房间布局、摆家具的小软件，能让你在电脑上提前规划空间，看沙发、床、桌子这些放哪儿合适，尺寸对不对。</p><h2>1. 先下载文件</h2><p><strong>安装包下载：</strong><a href="https://link.segmentfault.com/?enc=g5zYinSM6OfwhUjT%2F2evew%3D%3D.n0sizVKW%2BRW0YJZzgNk%2Bygdz2QG3xdwkvJYGgt80pbekGbtBK3H86%2F1CMCcKeQFw" rel="nofollow" title="https://pan.quark.cn/s/79414e16e772" target="_blank">https://pan.quark.cn/s/79414e16e772</a> ，下载好 <strong>Room Arranger for Mac v9.8.3.645.dmg</strong>，下完一般会在“下载”文件夹里躺着，找的时候直接进“下载”就行。</p><h2>2. 打开 dmg 文件</h2><p>双击这个 <code>.dmg</code>文件，Mac 会自动弹出一个窗口，里面能看到 Room Arranger 的图标，旁边还有个箭头指着“应用程序”文件夹。</p><h2>3. 拖到应用程序文件夹</h2><p>把 Room Arranger 的图标直接拖进“应用程序”文件夹里，等它复制完就好，这步其实就是安装。</p><h2>4. 关掉安装窗口</h2><p>复制完成后，点窗口左上角的  <strong>“推出”</strong> ​ 按钮，把这个安装窗口关掉，桌面上的挂载盘也会消失。</p><h2>5. 打开软件</h2><p>打开“启动台”（或者“应用程序”文件夹），找到刚装好的 Room Arranger，点一下运行。</p><p>第一次打开时，可能会跳出来“来自未知开发者”的提示，别慌，点  <strong>“仍要打开”</strong> ​ 就能正常用了。</p><h2>6. 小贴士</h2><ul><li>如果之前装过旧版本，最好先删掉旧的再装新的，这样不容易冲突。</li><li>软件装完就能直接摆房间玩，不用额外设置啥。</li></ul><p>​</p>]]></description></item><item>    <title><![CDATA[如何在 Ubuntu / Debian ]]></title>    <link>https://segmentfault.com/a/1190000047438633</link>    <guid>https://segmentfault.com/a/1190000047438633</guid>    <pubDate>2025-11-30 10:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000045376433" alt="Configure Postfix to Use Gmail SMTP" title="Configure Postfix to Use Gmail SMTP"/></p><p>Postfix 是一个流行的开源邮件传输代理（MTA），用于在 Linux 系统上路由并发送电子邮件。它提供了一个健壮和高效的处理邮件投递的方法。在本教程中，我们将向您展示如何在 Ubuntu 和 Debian-based 系统配置 Postfix 使用 Gmail 的 SMTP 服务。这个设置允许你使用 Gmail 的基础设施发送电子邮件，提供更好的可交付性，减少你的电子邮件被标记为垃圾邮件的可能性。</p><h3>安装 Postfix 和依赖项</h3><p>首先，更新系统的包索引。</p><pre><code>sudo apt update</code></pre><p>接下来，安装 Postfix 和 mailutils 包，它为处理邮件提供了额外的实用程序。</p><pre><code>sudo apt install postfix mailutils</code></pre><p>在 Postfix 安装过程中，系统将提示您选择邮件服务器配置类型。选择“Internet Site”并输入您的完全限定域名（FQDN）。</p><h3>配置 Postfix 使用 Gmail SMTP</h3><p>编辑 Postfix 配置文件</p><pre><code>sudo nano /etc/postfix/main.cf</code></pre><p>在配置文件中增加或修改如下几行：</p><pre><code>relayhost = [smtp.gmail.com]:587
smtp_use_tls = yes
smtp_sasl_auth_enable = yes
smtp_sasl_security_options = noanonymous
smtp_sasl_password_maps = hash:/etc/postfix/sasl_passwd
smtp_tls_CAfile = /etc/ssl/certs/ca-certificates.crt</code></pre><p>保存并退出文件</p><h3>创建并配置 SASL 密码文件</h3><p>创建一个新文件存储你的 Gmail 帐户的凭据</p><pre><code>sudo nano /etc/postfix/sasl_passwd</code></pre><p>添加以下行到新创建的文件中，将 <a href="mailto:your_email@example.com" target="_blank">your_email@example.com</a> 替换为您的 Gmail 电子邮件地址，将 your_password 替换为您的 Gmail 密码。</p><pre><code>[smtp.gmail.com]:587 your_email@example.com:your_password</code></pre><p>保存并退出文件，并修改文件权限。</p><pre><code>sudo chmod 600 /etc/postfix/sasl_passwd</code></pre><p>创建密码文件的哈希映射供 Postfix 使用</p><pre><code>sudo postmap /etc/postfix/sasl_passwd</code></pre><p>重新启动 Postfix 服务以应用更改</p><pre><code>sudo systemctl restart postfix</code></pre><h3>测试邮件功能</h3><p>使用 mail 命令发送测试邮件，确保 Postfix 配置正确。</p><pre><code>echo "This is a test email." | mail -s "Test Email" recipient@example.com</code></pre><h3>我的开源项目</h3><p><a href="https://link.segmentfault.com/?enc=6I3YXwITvaI66Bn4g29n0g%3D%3D.8H6HrYTubBLpPCH6NFHUDlPI2Fstk%2B8FzmdfTdch2Bg%3D" rel="nofollow" target="_blank"><img referrerpolicy="no-referrer" src="/img/remote/1460000043302459" alt="酷瓜云课堂-在线教育解决方案" title="酷瓜云课堂-在线教育解决方案" loading="lazy"/></a></p><ul><li><a href="https://link.segmentfault.com/?enc=Mz4xs%2F3kzNdfnAKP1r3msA%3D%3D.JP0CHdwsq65BxMCnaenpEKobnE%2F54RmYmRQnk0UUcq6joWhvvGqoIfCmg%2FQtxDWm" rel="nofollow" target="_blank">course-tencent-cloud（酷瓜云课堂 - gitee仓库）</a></li><li><a href="https://link.segmentfault.com/?enc=zBhSyEWz2jJKPm4FwcscSQ%3D%3D.kVN0Y94GkivjaoQv%2FxaBS8ulzGzcz%2B2534MCflbYGdXF1m%2BMLZz1vt9bS4WmEX7YAc78rx3LpV7%2F%2Fd8r%2F3tj6g%3D%3D" rel="nofollow" target="_blank">course-tencent-cloud（酷瓜云课堂 - github仓库）</a></li></ul>]]></description></item><item>    <title><![CDATA[Android 监听软键盘的高度并解决其]]></title>    <link>https://segmentfault.com/a/1190000047438460</link>    <guid>https://segmentfault.com/a/1190000047438460</guid>    <pubDate>2025-11-30 00:02:09</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>1、前言<br/>在某些项目中，我们常常需要自定义一个输入框，软键盘弹出时就把输入框顶上去，关闭时输入框再回到原位（比如下方的效果图，实际上各种 App 中的聊天界面和发布评论的界面大体都是这样）。在这个过程中，除了输入框以外的其他界面的元素不受影响，比如效果图中的背景图片不会上移也不会被压缩。但在实际使用中发现软键盘在弹出时常常把输入框盖住，导致输入框显示不完全。有什么方法可以解决呢？<br/>​<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047438462" alt="图片" title="图片"/><br/>​<br/>2、思路分析<br/>2.1 获取软键盘的高度<br/>网上常见的思路是这样的：在输入框的下面放置一个 View​，当软键盘弹出时，获取软键盘高度，然后在代码中动态将该 View​ 的高度设置成跟软键盘的一样，这样输入框就被它顶上去了。从视觉上来看，就像是被软键盘顶上去一样。<br/>这个思路的难点在于准确获取软键盘的动态高度。Android 系统没有提供直接获取软键盘高度的 api，好在我们可以曲线救国：软键盘的高度其实就是屏幕高度减去软键盘上方的可见区域（即没有被软键盘挡住的区域）高度，也就是：</p><p>软键盘高度 = 屏幕高度 - 可见区域高度</p><p>此外，还需要考虑状态栏和虚拟导航栏高度，所以我们可以得出以下的计算公式：</p><p>软键盘高度 = 屏幕高度 - 可见区域高度 - 顶部状态栏高度 - 底部导航栏高度</p><p>不过有两点需要注意：</p><p>Activity 为全屏时是没有状态栏的，不必扣除高度；<br/>横屏时虚拟状态栏是在侧边的，这时也不必扣除它的高度了。</p><p>最后我们的公式可以修正为：</p><p>软键盘高度 = 屏幕高度 - 可见区域高度 - 顶部状态栏高度（非全屏时） - 底部导航栏高度（竖屏时）</p><p>这个公式中的屏幕高度、状态栏高度和导航栏高度都可以通过 Android 的 api 获取，所以，现在问题的难点转换成了准确获取可见区域的动态高度。<br/>2.2 获取可见区域高度<br/>准确获取可见区域的动态高度，何为准确，何为动态呢？要想准确，我们必须要准确获取可见区域的对象，要想动态，那必须监听可见区域的高度变化，也即是：</p><p>获取可见区域（对应准确）；<br/>监听可见区域的高度变化（对应动态）。</p><p>首先来看第一步，View​ 类中为我们提供了一个方法 getWindowVisibleDisplayFrame()​，它可以获取某个 View​ 所在窗口（Window​）的可见区域（注意：是窗口的可见区域，不是 View​ 的可见区域！）。它需要传入一个 Rect​ 对象，从 Rect​ 对象中，我们就可以获取到可见区域的信息，比如可见区域顶部距离父布局顶部的距离 top​ 和可见区域底部部距离父布局顶部的距离 bottom​，两者一相减就是我们需要的可见区域高度了。<br/>那么用哪一个 View​ 来获取可见区域呢？当前 Activity​ 或者 Fragment​ 上面的布局或者控件吗？答案是不行的。因为 Activity​（或 Fragment​）跟软键盘是位于同一个窗口的，也就是说，软键盘也在这个窗口的可见区域内，无论软键盘弹出还是关闭，可见区域的大小都不会变化！<br/>既然如此，那么我们就需要另外一个窗口了。有没有办法创建一个不属于软键盘所在窗口的 View​ 呢？当然可以，Dialog​ 和 PopupWindow​ 就可以办到。我们需要这个 View​ 一直存在，便于监听，所以 PopupWindow​ 无疑是最合适的。<br/>第一步解决后，接下来就是监听可见区域的变化了这个比较简单，可以通过继承接口 ViewTreeObserver.OnGlobalLayoutListener​ 来，在 onGlobalLayout()​ 中监听来实现。<br/>3、代码实践<br/>思路已经捋清楚了，现在是代码时间。创建一个 KeyboardStatusWatcher​ 类，继承于 PopupWindow​ 和 ViewTreeObserver.OnGlobalLayoutListener​ 接口：<br/>class KeyboardStatusWatcher(</p><pre><code>private val activity: FragmentActivity,
private val lifecycleOwner: LifecycleOwner,
private val listener: (isKeyboardShowed: Boolean, keyboardHeight: Int) -&gt; Unit</code></pre><p>) : PopupWindow(activity), ViewTreeObserver.OnGlobalLayoutListener {</p><pre><code>private val rootView by lazy { activity.window.decorView.rootView }

private val TAG = "Keyboard-Tag"

/**
 * 可见区域高度
 */
private var visibleHeight = 0

/**
 * 软键盘是否显示
 */
var isKeyboardShowed = false
    private set

/**
 * 最近一次弹出的软键盘高度
 */
var keyboardHeight = 0
    private set

/**
 * PopupWindow 布局
 */
private val popupView by lazy {
    FrameLayout(activity).also {
        it.layoutParams = FrameLayout.LayoutParams(
            ViewGroup.LayoutParams.WRAP_CONTENT,
            ViewGroup.LayoutParams.MATCH_PARENT
        )
        //监听布局大小变化
        it.viewTreeObserver.addOnGlobalLayoutListener(this)
    }
}

init {
    //初始化 PopupWindow
    contentView = popupView
    //软键盘弹出时，PopupWindow 要调整大小
    softInputMode =
        WindowManager.LayoutParams.SOFT_INPUT_ADJUST_RESIZE or
            WindowManager.LayoutParams.SOFT_INPUT_STATE_ALWAYS_VISIBLE
    inputMethodMode = INPUT_METHOD_NEEDED
    //宽度设为0，避免遮挡界面
    width = 0
    height = ViewGroup.LayoutParams.MATCH_PARENT
    setBackgroundDrawable(ColorDrawable(0))
    rootView.post { showAtLocation(rootView, Gravity.NO_GRAVITY, 0, 0) }

    //activity 销毁时或者 Fragment onDestroyView 时必须关闭 popupWindow ，避免内存泄漏
    lifecycleOwner.lifecycle.addObserver(object : DefaultLifecycleObserver {
        override fun onDestroy(owner: LifecycleOwner) {
            super.onDestroy(owner)
            dismiss()
        }
    })
}

/**
 * 监听布局大小变化
 */
override fun onGlobalLayout() {
    val rect = Rect()
    //获取当前可见区域
    popupView.getWindowVisibleDisplayFrame(rect)
    if (visibleHeight == (rect.bottom - rect.top)) {
        //可见区域高度不变时不必执行下面代码，避免重复监听
        return
    } else {
        visibleHeight = (rect.bottom - rect.top)
    }
    //粗略计算高度的变化值，后面会根据状态栏和导航栏修正
    val heightDiff = rootView.height - visibleHeight
    //这里取了一个大概值，当窗口高度变化值超过屏幕的 1/3 时，视为软键盘弹出
    if (heightDiff &gt; activity.screenHeight / 3) {
        isKeyboardShowed = true
        //非全屏时减去状态栏高度
        keyboardHeight =
            if (activity.isFullScreen) heightDiff else heightDiff - activity.statusBarHeight
        //导航栏显示时减去其高度，但横屏时导航栏在侧边，故不必扣除高度
        if (activity.hasNavBar &amp;&amp; activity.isNavBarShowed &amp;&amp; activity.isPortrait) {
            keyboardHeight -= activity.navBarHeight
        }
    } else {
        //软键盘隐藏时键盘高度为0
        isKeyboardShowed = false
        keyboardHeight = 0
    }
    listener.invoke(isKeyboardShowed, keyboardHeight)
}</code></pre><p>}</p><p>代码都是遵循前面的思路分析编写的，注释也比较详细，就不过多分析了。只要关注一下 PopupWindow​ 存在时软键盘的交互。PopupWindow​ 与软键盘分属于不同的窗口，软键盘弹出时，默认会被 PopupWindow​ 覆盖的（你可以通过修改上面的代码，给 PopupWindow​ 设置颜色且宽度不为 0 来验证），这样 PopupWindow​ 的高度不发生变化，就无法达到监听的目的。所以我们需要设置 softInputMode​ 和 inputMethodMode​ 两个属性，让 PopupWindow​ 的高度随着软键盘的弹出和关闭而调整。<br/>然后简单看看 MainActivity 布局：<br/>&lt;androidx.constraintlayout.widget.ConstraintLayout <br/>    xmlns:android="http://schemas.android.com/apk/res/android"</p><pre><code>xmlns:app="http://schemas.android.com/apk/res-auto"
xmlns:tools="http://schemas.android.com/tools"
android:id="@+id/clRoot"
android:layout_width="match_parent"
android:layout_height="match_parent"
android:background="@drawable/watermelon"
tools:context=".MainActivity"&gt;

&lt;View
    android:id="@+id/vKeyboardBg"
    android:layout_width="match_parent"
    android:layout_height="60dp"
    android:background="@android:color/white"
    app:layout_constraintBottom_toBottomOf="parent" /&gt;

&lt;androidx.appcompat.widget.AppCompatEditText
    android:imeOptions="flagNoExtractUi"
    android:id="@+id/editText"
    android:layout_width="match_parent"
    android:layout_height="0dp"
    android:layout_marginHorizontal="15dp"
    android:layout_marginVertical="8dp"
    android:background="@drawable/shape_edit_bg"
    android:hint="请输入"
    android:paddingHorizontal="10dp"
    app:layout_constraintBottom_toBottomOf="@id/vEditBg"
    app:layout_constraintTop_toTopOf="@id/vEditBg" /&gt;
</code></pre><p>&lt;/androidx.constraintlayout.widget.ConstraintLayout&gt;</p><p>注意：这里 EditText​ 要加上 android:imeOptions="flagNoExtractUi"​ 属性，不然横屏时样式发生会变化。<br/>还有，别忘了在清单文件中给 Activity 加上 android:windowSoftInputMode="adjustNothing|stateHidden"​，否则软键盘弹出时布局会整体上移的。<br/>最后当然是在 Activity​ 中调用了：</p><pre><code>    KeyboardStatusWatcher(this,this) { isKeyboardShowed: Boolean, keyboardHeight: Int -&gt;
        vKeyboardBg.updateLayoutParams&lt;ConstraintLayout.LayoutParams&gt; {
            bottomMargin = keyboardHeight
        }
        Log.d("Tag", "isShowed = $isKeyboardShowed,keyboardHeight = $keyboardHeight")
    }
}
</code></pre><p>4、项目地址<br/>文章到此就结束了，项目地址如下：Gitee。<br/>项目还有一个不足之处：实现需求了，但是使用体验上跟微信相比差很多，微信的输入框在软键盘弹出和收起时上下移动非常顺滑，没有什么闪烁。<br/>如果你有更好的实现方法或者有其他的批评建议，欢迎留言和我交流。<br/>5、参考文章<br/>android EditText 横屏显示问题 - 简书<br/>Android 动态获取软键盘的高度，监听软键盘显示或则隐藏。 - 掘金<br/>Android 获取窗口可视区域大小: getWindowVisibleDisplayFrame()_ccpat 的专栏-CSDN 博客<br/>Android 全面解析之 Window 机制_一只修仙的猿-CSDN 博客</p>]]></description></item><item>    <title><![CDATA[NavigationBarUtil li]]></title>    <link>https://segmentfault.com/a/1190000047438483</link>    <guid>https://segmentfault.com/a/1190000047438483</guid>    <pubDate>2025-11-30 00:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <pre><code>private const val RES_NAME_NAV_BAR = "navigationBarBackground"

private val Context.navBarResId
    get() = resources.getIdentifier(
        "navigation_bar_height",
        "dimen", "android"
    )

/**
 * 获取虚拟导航栏的高度，必须在布局绘制完成之后调用才能获取到正确的值（可以在onWindowFocusChanged()中调用）
 * 单位为px
 */
val Context.navBarHeight: Int
    get() {
        val resourceId = navBarResId
        return if (resourceId != 0) {
            resources.getDimensionPixelSize(resourceId)
        } else 0
    }

/**
 * 手机是否有虚拟导航栏
 */
val Context.hasNavBar
    @JvmName("hasNavBar")
    get() = navBarResId != 0

/**
 * 当前虚拟导航栏是否显示
 */
val Activity.isNavBarShowed: Boolean
    get()  {
        val viewGroup = window.decorView as ViewGroup? ?: return false
        return (0 until viewGroup.childCount).firstOrNull {
            viewGroup.getChildAt(it).id != View.NO_ID
                &amp;&amp; this.resources.getResourceEntryName(viewGroup.getChildAt(it).id) == RES_NAME_NAV_BAR
        } != null
    }</code></pre>]]></description></item><item>    <title><![CDATA[SQL 性能的三要素——索引、执行计划与]]></title>    <link>https://segmentfault.com/a/1190000047438350</link>    <guid>https://segmentfault.com/a/1190000047438350</guid>    <pubDate>2025-11-29 23:03:26</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <blockquote>优秀的 SQL 性能不取决于单一组件的优化，而是索引设计、执行计划选择与数据分布感知三者协同的结果</blockquote><p>在数据库系统中，SQL 查询性能是衡量应用健康度的关键指标。许多开发者将性能优化简单归结为"添加索引"，但实际上，高效的查询是索引策略、执行计划优化和数据分布理解三者协同作用的结果。本文将深入探讨这三要素的相互作用机制，帮助您构建系统化的 SQL 性能优化思维。</p><h2>1 SQL 执行的生命周期与性能瓶颈</h2><h3>1.1 查询处理的全链路视角</h3><p>SQL 查询在数据库中的执行是一个复杂的过程，涉及多个组件的协同工作。<strong>查询优化器</strong>作为数据库大脑，负责将 SQL 语句转换为高效执行计划，其决策直接决定了查询性能。优化器的工作流程包括解析、标准化和优化三个阶段，最终生成物理执行计划。</p><p>在查询执行过程中，主要性能瓶颈常出现在<strong>数据访问路径</strong>选择上。不恰当的访问路径会导致不必要的磁盘 I/O 和 CPU 消耗，从而显著影响查询响应时间。了解这些瓶颈点有助于我们针对性优化。</p><h3>1.2 三要素的相互依赖关系</h3><p>索引、执行计划和数据分布之间存在深刻的相互影响关系。<strong>索引</strong>提供了数据快速访问的路径，但索引的有效性取决于<strong>数据分布</strong>特征；<strong>执行计划</strong>的选择基于成本估算，而成本估算的准确性又依赖于统计信息反映的数据分布；<strong>数据分布</strong>的变化会导致执行计划更替，可能使原有索引失效。</p><p>这种紧密的耦合关系意味着任何单点优化都难以持续有效，必须采用系统化思维进行性能优化。例如，即使创建了理想的索引，如果统计信息不准确，优化器可能仍然选择低效的执行计划。</p><h2>2 索引设计：高效访问的基石</h2><h3>2.1 索引结构与访问模式匹配</h3><p><strong>B+ 树索引</strong>是数据库中最常用的索引结构，其多路平衡特性有效降低了磁盘 I/O 次数。B+ 树将所有数据记录存储在叶子节点，并通过双向链表连接，这一特性特别有利于范围查询性能。</p><p>索引设计必须与实际<strong>查询模式</strong>相匹配。对于等值查询，单列索引可能足够；而对于多条件查询，复合索引通常更有效。复合索引的列顺序至关重要，应遵循<strong>高选择性列在前</strong>的原则，使索引能够最大程度地过滤数据。</p><p><strong>覆盖索引</strong>是优化查询性能的强大技术。当查询所需数据全部包含在索引中时，数据库可直接从索引获取数据，避免回表操作，显著减少 I/O 消耗。例如，假设存在复合索引（user\_id, created\_at），查询 <code>SELECT user_id, created_at FROM orders WHERE user_id = 100</code> 可完全利用索引完成，无需访问主表。</p><h3>2.2 索引选择性与性能关系</h3><p><strong>索引选择性</strong>是衡量索引效果的关键指标，高选择性索引能更有效地过滤数据。选择性计算公式为：不同值数量/总记录数。通常，选择性高于 10% 的索引才考虑使用。</p><p>索引使用中的常见陷阱包括：在索引列上使用函数或表达式会导致索引失效；前置通配符模糊查询（如 LIKE '%abc'）无法有效利用索引；隐式类型转换可能导致优化器无法使用索引。</p><p>以下是索引设计决策的参考框架：</p><pre><code>-- 良好的复合索引设计示例
CREATE INDEX idx_orders_user_status_date ON orders(user_id, status, created_date);

-- 匹配的查询示例（可利用索引前导列）
SELECT * FROM orders 
WHERE user_id = 100 
  AND status = 'completed'
  AND created_date &gt;= '2023-01-01';</code></pre><h2>3 执行计划：数据库的"执行蓝图"</h2><h3>3.1 执行计划解析与关键指标</h3><p><strong>执行计划</strong>是查询优化器生成的指令集，描述了数据处理的具体步骤。通过 EXPLAIN 命令可查看执行计划，其中几个关键字段特别重要：<strong>type</strong> 字段表示表访问类型，从最优到最差依次为：system &gt; const &gt; eq\_ref &gt; ref &gt; range &gt; index &gt; ALL；<strong>key</strong> 字段显示实际使用的索引；<strong>rows</strong> 字段预估需要扫描的行数；<strong>Extra</strong> 字段包含额外信息，如"Using index"表示使用覆盖索引。</p><p>执行计划中的<strong>连接类型</strong>对性能影响巨大。嵌套循环连接适用于小结果集连接；归并连接适合已排序的大表；哈希匹配则对无序大数据集效果良好。优化器会根据统计信息选择最适合的连接算法。</p><h3>3.2 执行计划分析与优化时机</h3><p>分析执行计划是识别性能瓶颈的关键步骤。当发现​<strong>type 为 ALL</strong>​（全表扫描）时，应考虑添加合适索引；当 <strong>rows 预估值与实际差异很大</strong>时，可能需要更新统计信息；当出现​<strong>Using temporary</strong>​（临时表）和​<strong>Using filesort</strong>​（文件排序）时，可能需要优化查询或索引。</p><p>以下是一个执行计划分析示例：</p><pre><code>-- 示例查询
EXPLAIN SELECT * FROM orders WHERE customer_id = 1001 AND status = 'shipped';

-- 问题执行计划可能显示：
-- type: ALL（全表扫描）
-- key: NULL（未使用索引）
-- rows: 大量扫描
-- 这表明需要为(customer_id, status)创建复合索引</code></pre><p>定期检查关键查询的执行计划是预防性能退化的重要手段。特别是在数据量变化较大或查询模式改变后，执行计划可能发生变更，导致性能下降。</p><h2>4 数据分布：优化器的"决策依据"</h2><h3>4.1 统计信息的作用与维护</h3><p><strong>统计信息</strong>是优化器进行成本估算的基础，描述了表数据、列数据和索引数据的分布特征。优化器依赖统计信息来估算不同执行计划的成本，从而选择最优方案。</p><p>统计信息需要定期更新以确保准确性。<strong>静态收集</strong>是在查询前手动或自动完成统计信息收集，不影响查询性能；<strong>动态收集</strong>则在查询过程中进行，会影响计划生成时间。对于数据变化频繁的表，应设置更频繁的统计信息更新策略。</p><p>当统计信息不准确时，优化器可能选择低效的执行计划。例如，如果统计信息未反映近年订单量激增，优化器可能低估结果集规模，错误选择嵌套循环连接而非更高效的哈希连接。</p><h3>4.2 数据分布特征对计划选择的影响</h3><p><strong>数据倾斜</strong>是影响执行计划选择的重要因素。当某些值出现频率极高时，索引可能不如全表扫描有效。例如，在"状态"字段上只有几个枚举值时，即使有索引，优化器也可能选择全表扫描。</p><p><strong>数据聚类</strong>特性也会影响性能。如果数据在物理存储上按某字段排序，基于该字段的范围查询会受益于顺序 I/O。了解数据分布特征有助于设计更有效的索引策略。</p><p>以下代码展示了如何检查数据分布：</p><pre><code>-- 分析列的数据分布
SELECT status, COUNT(*) AS count 
FROM orders 
GROUP BY status 
ORDER BY count DESC;

-- 更新统计信息
UPDATE STATISTICS ON orders;</code></pre><h2>5 三要素协同优化策略</h2><h3>5.1 索引与执行计划的协同</h3><p>索引设计必须考虑执行计划的选择规律。<strong>索引下推</strong>优化允许存储引擎在扫描索引时提前过滤数据，减少不必要的回表操作。<strong>多列索引</strong>的列顺序应匹配查询条件，以便优化器生成最佳计划。</p><p>当索引变更时，必须重新评估相关查询的执行计划。有时<strong>索引提示</strong>可临时强制优化器选择特定索引，但长期解决方案应是优化索引设计或统计信息。</p><p>复合索引设计应遵循​<strong>ERD 原则</strong>​（Equal-Range-Divide）：首先放置等值查询列，然后是范围查询列，最后是排序或分组列。这一原则能与优化器的执行计划生成逻辑最佳匹配。</p><h3>5.2 数据分布感知的优化</h3><p>智能优化需要考虑数据分布特征。对于​<strong>偏斜数据</strong>​，可考虑创建过滤索引或使用分区表；对于​<strong>时序数据</strong>​，可利用时间分区并结合数据归档策略。</p><p><strong>定期更新统计信息</strong>确保优化器基于准确数据分布做决策。对于大型表，可采用抽样统计平衡准确性和开销。<strong>直方图</strong>可帮助优化器了解复杂数据分布，尤其对非均匀分布列至关重要。</p><p>协同优化示例：某订单查询系统在（customer\_id, status）上创建复合索引，但性能仍不理想。分析发现 status 列严重偏斜（90% 为"completed"），通过过滤索引 <code>CREATE INDEX idx_orders_pending ON orders(customer_id) WHERE status != 'completed'</code>，结合统计信息更新，优化器终于选择了高效执行计划。</p><h2>6 实战：性能优化诊断流程</h2><h3>6.1 系统化性能诊断方法</h3><p>面对性能问题，应采用系统化诊断方法：​<strong>识别慢查询</strong>​：通过慢查询日志或数据库监控定位问题查询；​<strong>分析执行计划</strong>​：使用 EXPLAIN 查看当前执行计划，识别全表扫描、临时表等问题；​<strong>检查数据分布</strong>​：分析相关表的数据分布和统计信息时效性；​<strong>设计优化方案</strong>​：基于分析结果综合运用索引调整、查询重写或统计信息更新。</p><p>具体诊断流程如下：</p><ol><li>​<strong>执行计划分析</strong>​：关注 type、key、rows 和 Extra 字段，识别潜在问题</li><li>​<strong>索引有效性检查</strong>​：验证现有索引是否被使用，选择性如何</li><li>​<strong>统计信息检查</strong>​：确认统计信息是否最新，能否准确反映数据分布</li><li>​<strong>查询重写尝试</strong>​：尝试等效查询重写，测试不同写法性能差异</li></ol><h3>6.2 常见场景优化示例</h3><p><strong>场景一：分页查询优化</strong></p><pre><code>-- 原始慢查询
SELECT * FROM orders ORDER BY created_date DESC LIMIT 20 OFFSET 10000;

-- 优化方案：使用覆盖索引 + 游标分页
CREATE INDEX idx_orders_date_desc ON orders(created_date DESC, id);
SELECT * FROM orders 
WHERE created_date &lt;= '2023-11-28' AND id &lt; 5000
ORDER BY created_date DESC LIMIT 20;</code></pre><p><strong>场景二：多表连接优化</strong></p><pre><code>-- 原始查询
SELECT * FROM users u 
JOIN orders o ON u.id = o.user_id 
WHERE u.reg_date &gt;= '2023-01-01' AND o.amount &gt; 1000;

-- 优化方案：确保驱动表选择正确，连接字段有索引
CREATE INDEX idx_users_regdate ON users(reg_date);
CREATE INDEX idx_orders_user_amount ON orders(user_id, amount);</code></pre><h2>7 预防性性能治理体系</h2><h3>7.1 持续监控与预警</h3><p>建立<strong>持续监控机制</strong>对预防性能退化至关重要。监控应覆盖：​<strong>慢查询趋势</strong>​：跟踪慢查询数量、执行时间变化；​<strong>索引使用情况</strong>​：识别未使用或低效索引；​<strong>统计信息时效性</strong>​：确保统计信息及时更新。</p><p>设置合理的<strong>预警阈值</strong>可在问题影响用户前发现异常。例如，当查询扫描行数突增或索引命中率下降时触发告警。</p><h3>7.2 性能回归防护</h3><p>将 <strong>SQL 审查</strong>嵌入 CI/CD 流程可防止性能回归。使用自动化工具检查常见反模式，如 SELECT <em>​、N+1 查询等。​</em>​​<em>性能测试</em>​*应成为发布流程的必备环节，验证优化效果并防止回归。</p><p><strong>容量规划</strong>基于数据增长趋势提前规划优化策略。定期评估当前表结构、索引策略和数据量是否匹配，预见未来性能需求并提前准备优化方案。</p><h2>总结</h2><p>SQL 性能优化是一个系统工程，需要同时考虑索引设计、执行计划选择和数据分布特征三个要素的协同影响。优秀的性能源于对这三者之间复杂关系的深入理解和平衡把握。</p><p>​<strong>索引是基础</strong>​，但必须基于实际查询模式和数据分布特征设计；​<strong>执行计划是关键</strong>​，优化器的选择决定了查询路径的效率；​<strong>数据分布是依据</strong>​，统计信息的准确性直接影响优化器决策的质量。</p><p>未来，随着机器学习技术在数据库领域的应用，如 Bao 优化器通过强化学习选择执行计划，我们有理由相信数据库性能优化将更加智能化。但无论如何发展，对索引、执行计划和数据分布协同作用的深入理解，仍是数据库专业人士的核心竞争力。</p><hr/><p><strong>📚 下篇预告</strong>​</p><p>《连接池的价值与风险——池化提升与资源枯竭的双刃剑，关键指标如何解读》—— 我们将深入探讨：</p><ul><li>🔄 ​<strong>连接池原理</strong>​：数据库连接复用机制与性能提升的本质</li><li>⚖️ ​<strong>配置权衡</strong>​：最大连接数、最小空闲连接与超时设置的平衡策略</li><li>🚨 ​<strong>风险预警</strong>​：连接泄漏、资源枯竭与雪崩效应的发生机制</li><li>📊 ​<strong>监控指标</strong>​：活跃连接、等待时间与使用率的关键阈值</li><li>🛠️ ​<strong>实战调优</strong>​：主流连接池（HikariCP、Druid）的最佳配置实践</li></ul><p><strong>​点击关注，掌握数据库连接池的精细化调优技巧！​</strong>​</p><blockquote><p>​<strong>今日行动建议</strong>​：</p><ol><li>选择 1-2 个关键业务查询，使用 EXPLAIN 分析其执行计划</li><li>检查核心表的统计信息最后更新时间，确保其准确性</li><li>审核现有索引使用情况，识别并删除未使用索引</li><li>建立慢查询定期审查机制，预防性能退化</li></ol></blockquote>]]></description></item><item>    <title><![CDATA[基于反馈循环的自我进化AI智能体：原理、]]></title>    <link>https://segmentfault.com/a/1190000047438388</link>    <guid>https://segmentfault.com/a/1190000047438388</guid>    <pubDate>2025-11-29 23:02:36</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>传统AI智能体有个老问题：部署之后就"定住了"。工程师手工打磨的提示词和规则,遇到新场景就容易失灵,性能曲线到达某个点后趋于平缓。而自我进化智能体(Self-Evolving Agent)的思路就是打破这种静态模式，让智能体在运行过程中持续收集反馈,自动调整自身策略,形成一个闭环：<strong>执行任务 → 获取反馈 → 自我调整 → 继续执行</strong>。</p><p>这套机制把基础模型的能力与在线学习结合起来。用更学术的表述,自我进化智能体是"通过与环境交互持续优化内部组件的自主系统,目标是适应变化的任务、上下文和资源"。比如说这类智能体不只是做题,还会批改自己的作业、找出哪里写错了、然后调整学习策略，整个过程不需要人类介入。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047438390" alt="" title=""/></p><p>上图展示了典型的反馈循环结构。基线智能体执行任务产生输出,由人类评审或LLM评判者打分,反馈信息(分数、错误描述、改进建议)汇总后用于更新智能体，可能是调整提示词、微调参数、或修改配置。这个循环反复执行直到达成性能目标。</p><p>与固定配置的传统方案相比,自我进化智能体的核心差异在于能够监控自身表现并主动适应。多数已部署的智能体依赖人工设定的规则或提示,无法跟上数据分布的漂移或任务需求的演变。反馈循环解决了这个问题：每次任务完成后收集评估信号,识别薄弱环节,针对性地更新智能体。长期来看,系统的准确性和泛化性都会持续提升。这种机制对需要高准确率或面对动态环境的场景尤为关键，人类的角色从逐条修bug变成了设定目标和把握方向。</p><p>从架构视角看,自我进化系统可以抽象为四个核心要素：<strong>输入、智能体系统、环境、优化器</strong>，它们在迭代循环中交互。最近有综述将这类系统正式定义为"持续优化内部组件的自主系统,在保持安全性的前提下适应变化的任务与资源"。实际运行时,智能体执行标准的感知-推理-行动循环,但增加了自我评估和参数优化的元步骤。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047438391" alt="" title="" loading="lazy"/></p><p><strong>反馈循环的运作方式</strong>：从基线智能体开始(比如一个执行文档摘要的Agent),人类或LLM评判者对其输出进行评估。反馈信号既包括定量指标(0-1评分)也包括定性评论("摘要漏掉了关键细节")。多个信号汇总成综合得分，如果得分低于阈值(假设是0.8),就调整提示或策略重新测试。新版本达标后替换旧版本,循环继续。几轮迭代下来,智能体具备了自我修复能力。</p><p>这种设计的优势在于可扩展性(用LLM评估替代昂贵的人工标注)和适应性(自动响应新的失败模式,不需要手动改代码)。但也需要明确的安全约束：智能体在进化过程中必须保持稳定性(变化时不引入安全隐患)和性能单调性(不允许任务效果下降)。</p><h2>自我进化循环的核心步骤</h2><p>OpenAI Cookbook里有个经典示例,把进化循环拆成四步：</p><p><strong>第一步,基线智能体</strong>：准备一个初始版本,比如用特定提示词做文本摘要的Agent。</p><p><strong>第二步,收集反馈</strong>：让智能体跑一批任务,收集输出的评价，人工打分或者"LLM-as-Judge"的自动评分都行。评估内容包括摘要是否准确、是否简洁、是否符合业务规则等。</p><p><strong>第三步,量化评分</strong>：把反馈转成可度量的指标。可以是规则校验器、也可以是GPT评分标准,最后合成一个综合质量分。</p><p><strong>第四步,更新优化</strong>：如果得分没达标,就调整智能体内部——优化提示词、微调参数、或者换一个更好的版本,然后重新跑循环。</p><p>循环持续到性能超过阈值或达到重试上限。</p><pre><code> agent = BaselineAgent()  
 score = evaluate(agent)  
 while score &lt; target_score and tries &lt; max_retries:  
     feedback = get_feedback(agent)  
     agent = optimize_agent(agent, feedback)  
     score = evaluate(agent)</code></pre><p>每轮迭代都用收集到的反馈调整智能体。如果优化成功,新版本替换旧版本,成为下一轮的基线。</p><h2>关键模块解析</h2><p>自我进化智能体由几个紧密耦合的模块构成。</p><p><strong>智能体循环</strong>是最核心的部分，智能体接收输入(比如文档片段),更新内部记忆或上下文,运行LLM推理,产出结果(比如摘要)。这个流程通常用某种Agent SDK实现,负责管理LLM调用和工具使用。自我进化层包裹在外面,根据需要触发重跑或修改循环。架构上可以是单模块也可以是多模块——比如医疗场景可能同时有Summarizer和Compliance Checker两个子智能体。持续的"思考-行动"循环产生可评估的输出,为后续改进提供素材。</p><p><strong>任务性能监控</strong>负责追踪智能体的表现，典型配置包括自动评估器和可选的人工复核。以摘要任务为例,每个输出会经过四个评分器检查：</p><p>(1) Python函数检查关键术语(如化学名称)是否保留在摘要中;(2) 长度检查器控制冗长度;(3) 余弦相似度检测摘要与原文的语义一致性;(4) LLM评判者按评分标准给出综合评价。</p><p>前两个是确定性规则,第三个是模糊匹配,第四个提供灵活的语言理解评估。多个评分器协作,既产出量化分数也生成定性反馈。监控模块输出数字分数或pass/fail标志,外加描述问题的反馈文本。加权平均后得到汇总分数,决定输出是否可接受。这个监控信号驱动整个改进流程。</p><p><strong>内存模块</strong>对持续学习，短期记忆存储当前对话和规划状态,长期记忆保存累积知识、历史解法、总结出的规则。RAG(检索增强生成)让智能体能从知识库中拉取相关上下文。更复杂的系统会维护"记忆库",存放过去的决策和推理轨迹。记忆帮助智能体保留学到的经验：比如记住哪些提示模式效果更好,或者存储之前遇到的拒绝案例。进化循环可以把反馈和结果写入记忆,后续迭代查询时就能避免重蹈覆辙。</p><p><strong>奖励/反馈建模</strong>把原始反馈转换成训练信号，对于LLM智能体,通常会构建奖励模型或评分函数。每个评分器产出0-1分数,系统检查是否过阈值(比如0.85)。多个分数可以合并成单一指标(比如取均值),这个综合分数就是智能体的"奖励"。用强化学习的视角看,智能体被优化来最大化这个奖励。反馈也可以定性分类：如果某个评分器挂了,失败原因可以转成纠正指令。LLM评判者特别有用,因为它提供自然语言反馈("摘要需要更多细节"),智能体能直接用这些描述来改进输出。总之,奖励模块确保优化目标清晰——"所有评分器通过,或者均分超过0.8"。</p><p><strong>重训练/优化模块</strong>在性能不达标时更新智能体，提示词调优、参数微调、结构变化(如添加新工具)。一种常见做法是用LLM做<strong>提示改进</strong>而非直接训模型——"MetaPrompt"智能体拿到当前提示和反馈,被要求生成更好的版本。代码用新提示替换旧提示。更进阶的系统可能在收集的(输入,输出,反馈)数据上微调LLM,或用强化学习更新策略权重。核心思想是：根据反馈修改智能体内部组件(系统提示、模型权重、工具配置),让下一次执行有更大成功概率。重训后循环再次评估更新版本,形成闭环。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047438392" alt="" title="" loading="lazy"/></p><h2>反馈收集与重训练流程</h2><p>自我进化智能体的反馈主要靠自生成或众包。系统在一批任务上跑智能体,收集性能数据,包括：</p><p><strong>分数和标签</strong>：输出是否满足长度约束?是否包含必需实体?这些由自动检查器记录。</p><p><strong>文本反馈</strong>：LLM评判者输出解释性语句,说明哪里不足。</p><p><strong>日志和诊断</strong>：生成的token数、运行时统计、错误堆栈。</p><p><strong>人工标注</strong>：如果有人工复核,评级和评论会被记录。</p><p>智能体生成摘要后,评估代码调用各评分器,把输出解析成结构化结果(评分器名称、数字分数、pass/fail、推理描述)。辅助函数如</p><pre><code>parse_eval_run_output</code></pre><p>提取这些信息。智能体不依赖外部数据——自己的输出就是训练数据。随着时间推移,这会积累起(输入,输出,反馈)三元组的数据集。</p><pre><code> import time  
import json  

def run_eval(eval_id: str, section: str, summary: str):  
  """使用输入部分和输出摘要创建评估运行。"""  
  return client.evals.runs.create(  
    eval_id=eval_id,  
    name="self-evolving-eval",  
    data_source={  
      "type": "jsonl",  
      "source": {  
        "type": "file_content",  
        "content": [  
          {  
            "item": {  
              "section": section,  
              "summary": summary,  
            }  
          }  
        ],  
      },  
    },  
  )  

def poll_eval_run(eval_id: str, run_id: str, max_polls = 10):  
    """
    轮询评估运行直到完成或超时。

    此函数的存在是为了通过定期检查运行状态来处理评估服务中的异步行为。
    它通过在固定间隔轮询而不是无限期阻塞来平衡响应性和资源使用。
    重试限制可以防止在服务从不返回完成状态的情况下出现失控循环。
    """  
    run = None  
    for attempt in range(1, max_polls + 1):  
        run = client.evals.runs.retrieve(eval_id=eval_id, run_id=run_id)  
        if run.status == "completed":  
            break  
        if attempt == max_polls:  
            print("Exceeded retries, aborting")  
            break  

        time.sleep(5)  

    run_output_items = client.evals.runs.output_items.list(  
        eval_id=eval_id, run_id=run_id  
    )  
    return run_output_items  

def parse_eval_run_output(items):  
    """提取所有评分器分数和任何可用的结论输出。"""  
    all_results = []  

    for item in items.data:  
        for result in item.results:  
            grader_name_full = result.name  
            score = result.score  
            passed = result.passed  
            reasoning = None  
            try:  
                sample = result.sample  
                if sample:  
                    content = result.sample["output"][0]["content"]  
                    content_json = json.loads(content)  
                    steps = content_json["steps"]  
                    reasoning = " ".join([step["conclusion"] for step in steps])  
            except Exception:  
                pass  

            all_results.append(  
                {  
                    "grader_name": grader_name_full,  
                    "score": score,  
                    "passed": passed,  
                    "reasoning": reasoning,  
                }  
            )  

     return all_results</code></pre><p><strong>重训练流程</strong>：反馈收集完毕后,智能体进入更新阶段。摘要评估失败时,循环调用"MetaPrompt"智能体——输入原始提示、源文档、生成的摘要、失败原因。MetaPrompt LLM输出新提示。系统用这个新提示创建新版SummarizationAgent。本质上,智能体通过LLM重写指令完成了"重训练"。更高级的系统可能微调模型权重或调整其他模块(更新记忆条目、更换工具)。关键点是<strong>智能体从错误中学习</strong>。</p><p>每轮迭代都应该带来性能提升。示例循环给每个部分最多3次改进机会。如果新提示版本让摘要通过所有评分器(宽松阈值),循环继续;否则重复尝试。代码追踪哪个提示版本综合得分最高,处理完所有部分后部署最优版本。这种重训既可以离线批量做,也可以在线随新数据持续适应。最终产出一个只靠自生成反馈就进化得更准确的智能体。</p><h2>代码实现详解</h2><p>下面是OpenAI Notebook实现的关键部分。</p><p><strong>1、评估配置</strong></p><p>先定义带多个评分器的<strong>Eval</strong>来给智能体输出打分,用的是OpenAI Evals API。每个评分器检查特定标准：<strong>chemical_name_grader</strong>(Python代码)计算化学名称在摘要中的出现比例,保证领域关键词不丢失;<strong>word_length_deviation_grader</strong>控制摘要长度在容差范围内;<strong>cosine_similarity</strong>测量源文和摘要的语义重叠度;<strong>llm_as_judge</strong>用GPT-4.1按评分标准给综合分。这些评分器收集到</p><pre><code>testing_criteria</code></pre><p>列表,然后创建评估：</p><pre><code> from openai import OpenAI  
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))  

data_source_config = {  
    "type": "custom",  
    "item_schema": {"type": "object", "properties": {"section": {"type": "string"}, "summary": {"type": "string"}}, "required": ["section", "summary"]},  
    "include_sample_schema": False  
}  
testing_criteria = [  
    {  
        "type": "python",  
        "name": "chemical_name_grader",  
        "pass_threshold": 0.8,  
        "source": r"""  
def grade(sample: dict, item: dict) -&gt; float:  
    section = item["section"]  
    summary = item["summary"]  
    # 预期化学名称列表  
    CHEMICALS_MASTER = [...]  
    present = [chem for chem in CHEMICALS_MASTER if chem in section]  
    if not present:  
        return 1.0  
    correct = sum(1 for chem in present if chem in summary)  
    return correct / len(present)  
"""  
    },  
    {  
        "type": "python",  
        "name": "word_length_deviation_grader",  
        "pass_threshold": 0.85,  
        "source": r"""  
def grade(sample: dict, item: dict) -&gt; float:  
    summary = item["summary"]  
    word_count = len(summary.split())  
    expected = 100  
    tolerance = 0.2  
    deviation = abs(word_count - expected) / expected  
    if deviation &lt;= tolerance:  
        return 1.0  
    score = max(0.0, 1.0 - (deviation - tolerance))  
    return score  
"""  
    },  
    {  
        "type": "text_similarity",  
        "name": "cosine_similarity",  
        "input": "{{ item.summary }}",  
        "reference": "{{ item.section }}",  
        "evaluation_metric": "cosine",  
        "pass_threshold": 0.85,  
    },  
    {  
        "type": "score_model",  
        "name": "llm_as_judge",  
        "model": "gpt-4.1",  
        "input": [  
            {  
                "role": "system",  
                "content": (  
                    "You are an expert summarization evaluator. Score the summary between 0 and 1..."  
                )  
            },  
            {  
                "role": "user",  
                "content": (  
                    "Section:\n{{item.section}}\nSummary:\n{{sample.output_text}}"  
                )  
            }  
        ],  
        "range": [0, 1],  
        "pass_threshold": 0.85,  
    },  
]  
eval = client.evals.create(  
    name="self_evolving_eval",  
    data_source_config=data_source_config,  
    testing_criteria=testing_criteria  
)  
 print(f"Created Eval: {eval.id}")</code></pre><p>这段代码导入OpenAI客户端,配置自定义数据schema(每个item有section和summary),定义四个评分器。Python评分器用内联代码(raw string)定义</p><pre><code>grade</code></pre><p>函数。</p><pre><code>client.evals.create()</code></pre><p>创建评估但还不执行。这些规则会对智能体生成的每个摘要自动打分。</p><p><strong>2、执行评估</strong></p><p>接着定义辅助函数,<strong>在给定的section-summary对上跑评估</strong>并解析结果：</p><pre><code> import time, json  

def run_eval(eval_id: str, section: str, summary: str):  
    """使用一个示例(section+summary)安排评估运行。"""  
    return client.evals.runs.create(  
        eval_id=eval_id,  
        name="self-evolving-eval",  
        data_source={"type": "jsonl", "source": {"type": "file_content", "content": [  
            {"item": {"section": section, "summary": summary}}  
        ]}}  
    )  

def poll_eval_run(eval_id: str, run_id: str, max_polls=10):  
    """轮询直到评估运行完成,然后返回输出项。"""  
    for attempt in range(max_polls):  
        run = client.evals.runs.retrieve(eval_id=eval_id, run_id=run_id)  
        if run.status == "completed":  
            break  
        time.sleep(5)  
    return client.evals.runs.output_items.list(eval_id=eval_id, run_id=run_id)  

def parse_eval_run_output(items):  
    """从评估运行输出中提取评分器分数和推理。"""  
    all_results = []  
    for item in items.data:  
        for result in item.results:  
            score = result.score  
            passed = result.passed  
            reasoning = None  
            try:  
                content = result.sample["output"][0]["content"]  
                reasoning = json.loads(content)["steps"][0]["conclusion"]  
            except Exception:  
                pass  
            all_results.append({  
                "grader_name": result.name,  
                "score": score,  
                "passed": passed,  
                "reasoning": reasoning  
            })  
    return all_results  

# 示例运行  
EVAL_ID = eval.id  
SECTION = "...some section text..."  
SUMMARY = "...agent's summary..."  
eval_run = run_eval(EVAL_ID, section=SECTION, summary=SUMMARY)  
run_output = poll_eval_run(EVAL_ID, run_id=eval_run.id)  
grader_scores = parse_eval_run_output(run_output)  
 print(grader_scores)</code></pre><pre><code>run_eval</code></pre><p>函数把一个样本(section+摘要)发送给评估服务,然后轮询等待完成(</p><pre><code>poll_eval_run</code></pre><p>),最后解析结果。输出是字典列表,每个评分器一条,格式类似</p><pre><code>{"grader_name": ..., "score": ..., "passed": ..., "reasoning": ...}</code></pre><p>。多数评分器只返回分数和pass/fail,LLM评分器会额外附带推理文本。这种结构化反馈供循环决定如何改进智能体。比如</p><pre><code>chemical_name_grader</code></pre><p>失败,说明摘要漏掉了关键术语。</p><p><strong>3、智能体与提示版本管理</strong></p><p>下一步配置智能体本身和提示版本追踪的数据结构,用OpenAI <strong>Agents SDK</strong>定义智能体并管理提示。</p><p>配置包括：</p><pre><code>VersionedPrompt</code></pre><p>类(基于Pydantic)记录提示版本和元数据;</p><pre><code>PromptVersionEntry</code></pre><p>存储每个版本的文本、版本号、模型、时间戳等;两个智能体——<strong>SummarizationAgent</strong>(执行实际任务)和<strong>MetaPromptAgent</strong>(负责改写提示)。</p><pre><code> from datetime import datetime  
from typing import Any, Optional  
from pydantic import BaseModel, Field  

class PromptVersionEntry(BaseModel):  
    """存储提示的一个版本和相关元数据。"""  
    version: int  
    model: str = "gpt-5"  
    prompt: str  
    timestamp: datetime = Field(default_factory=datetime.utcnow)  
    metadata: Optional[dict[str, Any]]  

    class Config:  
        validate_assignment = True  
        extra = "forbid"  

class VersionedPrompt:  
    """跟踪PromptVersionEntry列表并允许更新。"""  
    def __init__(self, initial_prompt: str, model: str = "gpt-5"):  
        self._versions = [PromptVersionEntry(version=0, model=model, prompt=initial_prompt)]  
    def current(self) -&gt; PromptVersionEntry:  
        return self._versions[-1]  
    def update(self, new_prompt: str, model: Optional[str] = None, metadata: Optional[dict]=None):  
        next_version = self.current().version + 1  
        entry = PromptVersionEntry(version=next_version,   
                                   model=model or self.current().model,  
                                   prompt=new_prompt, metadata=metadata)  
        self._versions.append(entry)  
        return entry  

# 创建智能体和初始提示  
from agents import Agent  # 假设的agents SDK  

METAPROMPT_TEMPLATE = """  
Context:  
Original prompt: {original_prompt}  
Section: {section}  
Summary: {summary}  
Reason to improve: {reasoning}  

Task:  
Write an improved summarization prompt that is more specific and preserves all details...  
"""  

metaprompt_agent = Agent(name="MetaPromptAgent", instructions="You are a prompt optimizer.")  
summarization_prompt = VersionedPrompt(initial_prompt="You are a summarization assistant. Given a section, produce a summary.")  
 summarization_agent = Agent(name="SummarizationAgent", instructions=summarization_prompt.current().prompt, model=summarization_prompt.current().model)</code></pre><pre><code>VersionedPrompt</code></pre><p>确保每次提示变更都有记录(版本1、2、3...)。</p><pre><code>PromptVersionEntry</code></pre><p>存储文本及相关模型、版本号等信息。代码实例化了一个"MetaPromptAgent"专门负责重写提示,以及一个用简单初始提示的SummarizationAgent。循环中每次更新提示时调用</p><pre><code>summarization_prompt.update(...)</code></pre><p>,新条目追加到版本列表,需要时可以回滚。这套机制让提示演变过程可追溯。</p><p><strong>4、自我进化循环编排</strong></p><p>最后是核心的自我改进循环实现。单次迭代的逻辑：</p><ol><li>智能体用当前提示<strong>生成摘要</strong>;</li><li>在(section, summary)上<strong>跑评估</strong>拿到评分;</li><li>计算综合分数(评分器均值),检查是否过宽松阈值;</li><li>通过则成功;未通过则<strong>收集反馈</strong>并改进提示;</li><li>每个部分最多重试若干次;</li><li>所有部分处理完后,选择综合得分最高的提示版本。</li></ol><p>简化代码如下：</p><pre><code> MAX_RETRIES = 3  
for section, content in dataset:  
    for attempt in range(1, MAX_RETRIES+1):  
        # 运行总结智能体  
        result = Runner.run(summarization_agent, content)    
        summary = result.final_output  
          
        # 用评分器评估  
        grader_scores = await get_eval_grader_score(eval_id=EVAL_ID, section=content, summary=summary)  
        avg_score = calculate_grader_score(grader_scores)  
        passed = is_lenient_pass(grader_scores, avg_score)  
          
        print(f"Attempt {attempt}: avg score={avg_score}, passed={passed}")  
        if passed:  
            break  
          
        # 如果失败,收集文本反馈并向MetaPromptAgent询问新提示  
        feedback = collect_grader_feedback(grader_scores)  
        prompt_input = METAPROMPT_TEMPLATE.format(  
            original_prompt=summarization_prompt.current().prompt,  
            section=content,  
            summary=summary,  
            reasoning=feedback  
        )  
        meta_result = await Runner.run(metaprompt_agent, prompt_input)  
        improved_prompt = meta_result.final_output  
          
        # 更新总结智能体的提示  
        summarization_prompt.update(new_prompt=improved_prompt, metadata={"section": content, "summary": summary})  
        summarization_agent = Agent(name="SummarizationAgent", instructions=improved_prompt, model=summarization_prompt.current().model)  
         print(f"  Improved prompt to version {summarization_prompt.current().version}")</code></pre><p>对每个文档部分,</p><pre><code>SummarizationAgent</code></pre><p>生成摘要,然后跑评估(</p><pre><code>get_eval_grader_score</code></pre><p>)计算分数。未通过检查时,组装反馈字符串(如"化学名称缺失"或LLM给的原因描述),调用MetaPrompt智能体传入原始提示、文档片段、摘要和反馈。MetaPrompt LLM返回<strong>新提示</strong>,更新</p><pre><code>VersionedPrompt</code></pre><p>并重建SummarizationAgent。重试最多</p><pre><code>MAX_RETRIES</code></pre><p>次直到通过或放弃。处理完所有数据后,追踪哪个提示版本综合得分最高。实际循环会记录每一步并最终打印最优版本。这展示了<strong>自生成反馈</strong>(评分器结果)如何驱动迭代改进——智能体在教自己如何写更好的提示。</p><h2>总结</h2><p>自我进化智能体适用于任何任务复杂且持续演变的领域。除了医疗文档,<strong>金融</strong>(智能体跟随市场变化更新策略)、<strong>编程</strong>(代码生成智能体适应新库和新错误模式)、<strong>生物医学</strong>(研究助手迭代优化文献综述)都是潜在场景。相关研究已经指出生物医学、编程、金融这些垂直领域的具体策略。代码生成智能体可以根据测试结果持续改进编码风格或错误检测逻辑;客服聊天机器人可以从新类型的用户咨询中在线学习。</p><p>随着AI智能体被部署到关键任务,自动自我改进能把人力从繁琐的debug转移到高层决策——设定目标、确保安全。能够自我纠错的智能体长期来看更可靠。</p><p>最后这个领域还很新,算是对这个方向的首批系统性审视之一,开放问题很多。比如说如何安全地允许智能体改写自身行为?什么评估基准最适合持续学习?但前景很有吸引力：未来的助手能优雅地从经验中学习;工厂机器人随生产需求自我调整;教育导师为每个学生个性化自己的教学策略。从静态AI到真正的终身学习智能体,这条路刚刚开始。</p><p><a href="https://link.segmentfault.com/?enc=mds4wYBelQhGyN%2F8blHoDA%3D%3D.OHjxUxKTlwjkxMEjzDAOATqQhrnedcciVa8BqkPsSE2aeic1vhneoz2XfUDYddR0XIqnRaEiEtYNzVpkOZIZkA%3D%3D" rel="nofollow" target="_blank">https://avoid.overfit.cn/post/39758407b909479aab400a01b29bac65</a></p><p>作者：DhanushKumar</p>]]></description></item><item>    <title><![CDATA[计算机组成原理 - 计算机系统概述 Al]]></title>    <link>https://segmentfault.com/a/1190000047438409</link>    <guid>https://segmentfault.com/a/1190000047438409</guid>    <pubDate>2025-11-29 23:01:55</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>计算机组成原理</h2><h3>概述</h3><h4>计算机系统</h4><h5>简介</h5><p>计算机系统由<strong>硬件</strong>和<strong>软件</strong>两大部分组成</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438411" alt="image-20230623125741365" title="image-20230623125741365"/></p><h5>计算机软硬件机器</h5><p>微程序机器 M0、实际机器 M1 归属于硬件 ；虚拟机 M2、M3、M4 归属于软件</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438412" alt="image-20230622094955297" title="image-20230622094955297" loading="lazy"/></p><h5>计算机体系结构和计算机组成区别</h5><p>计算机体系结构：程序员所见到的计算机系统的属性概念性的结构与功能特性（指令系统、数据类型、寻址技术、I/O 机理等）类似定义接口的概念</p><p>计算机组成：实现计算机系统结构所体现的属性（具体指令的实现）类似接口实现的概念</p><p>举例说明：一台机器是否具有某一项功能是计算机体系结构的问题，以至于这项功能是怎么实现得就是计算机组成的问题</p><h4>计算机的基本组成</h4><h5>冯.诺伊曼计算机的特点</h5><p>1、五大部件组成（控制器、运算器、存储器、输入设备、输出设备）</p><p>2、指令和数据以相同的地位存储在存储器中，可按地址进行寻访</p><p>3、指令由操作码和地址码组成</p><p>4、指令和数据以二进制的形式表示</p><p>5、以运算器为中心</p><p>6、指令在存储器内按顺序存放</p><h5>存储器的基本组成</h5><p>主要介绍存储体、存储器地址寄存器 MAR、存储器数据寄存器 MDR</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438413" alt="image-20230622150559063" title="image-20230622150559063" loading="lazy"/></p><h5>运算器的基本组成</h5><p>主要介绍算数逻辑运算单元 ALU、累加器 ACC、乘商寄存器 MQ、操作数寄存器 X</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438414" alt="image-20230622132557894" title="image-20230622132557894" loading="lazy"/></p><h5>控制器的基本组成</h5><p>主要介绍控制单元 CU、程序计数器 PC、指令寄存器 IR</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438415" alt="image-20230622135326640" title="image-20230622135326640" loading="lazy"/></p><h5>主机完成一条指令的过程</h5><p><strong>以取数指令为例</strong></p><p>指令包含两部分：一个是指令码（决定进行什么操作，比如是取数操作）；另一个是地址码（存放数据的地址）</p><p>步骤 1：取<strong>取数指令</strong>到指令寄存器 IR （绿线）</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438416" alt="image-20230622142251410" title="image-20230622142251410" loading="lazy"/></p><p>步骤 2：分析指令码以及执行指令操作（红线）</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438417" alt="image-20230622143704305" title="image-20230622143704305" loading="lazy"/></p><p><strong>以存数指令为例</strong></p><p>步骤 1：取<strong>存数指令</strong>到指令寄存器 IR （如上图取取数指令步骤 1）</p><p>步骤 2：分析指令码以及执行指令操作（橙线）</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438418" alt="image-20230622144324986" title="image-20230622144324986" loading="lazy"/></p><h4>计算机硬件的主要技术指标</h4><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438419" alt="image-20230622150434734" title="image-20230622150434734" loading="lazy"/></p><h3>计算机发展及应用</h3><p>略</p>]]></description></item><item>    <title><![CDATA[亚马逊为 Bedrock AgentCo]]></title>    <link>https://segmentfault.com/a/1190000047438452</link>    <guid>https://segmentfault.com/a/1190000047438452</guid>    <pubDate>2025-11-29 23:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>本文已收录在<a href="https://link.segmentfault.com/?enc=%2BoVLYp5XYDhGTM7N4VgI5g%3D%3D.%2FXG8RHRv63OxxhcsTiMUYofJIuzZ8ETL7H%2BD8rHrbAKWNQKQGjyIwfWazEVvV7P%2FrNnUXXxJcwQ3iDgvjCPZcw%3D%3D" rel="nofollow" target="_blank">Github</a>，<strong>关注我，紧跟本系列专栏文章，咱们下篇再续！</strong></p><ul><li>🚀 魔都架构师 | 全网30W技术追随者</li><li>🔧 大厂分布式系统/数据中台实战专家</li><li>🏆 主导交易系统百万级流量调优 &amp; 车联网平台架构</li><li>🧠 AIGC应用开发先行者 | 区块链落地实践者</li><li>🌍 以技术驱动创新，我们的征途是改变世界！</li><li>👉 实战干货：<a href="https://link.segmentfault.com/?enc=3OCFACAFhaSFTCEDTy5bbw%3D%3D.rDGlYHGrU2EWpXMApaS0%2FHQ%2BKGMzULmpdBVyY3bDAik%3D" rel="nofollow" target="_blank">编程严选网</a></li></ul><h2>0 前言</h2><p>亚马逊 <a href="https://link.segmentfault.com/?enc=I7D2O39psjlVFRIcXixlAA%3D%3D.KRa0askjeX96AwlAt99zcr5S%2BG1fS9eqCKXdCZ2IxU0jMp4bgqACfHrXAbshffgCfewK%2B4c8gu62Palv6jV9WTpCtQHKWmxbs9INJz6x7fcVpDO6LOwkIy7X%2BdOyRCv%2B%2B1i8fhY7B9HK3T7mixVYVhluDWIYNBjXLURNTUKCWyE%3D" rel="nofollow" target="_blank">宣布</a>，在 <strong>Amazon Bedrock AgentCore Runtime</strong> 正式支持A2A协议<strong>，让基于不同框架构建的智能体之间能够实现通信与协作。</strong></p><p>该协议支持来自 <a href="https://link.segmentfault.com/?enc=w%2BLCmfHJt5%2F%2FS1qp8ay1Rw%3D%3D.%2BR1ey4j9Qar5%2B0Ef8WbiAGYnTVRVZlIamN5Gf%2Bvpg6BuhaAxsxnnFwTulLHNdBYP" rel="nofollow" target="_blank">Strands Agents</a>、<a href="https://link.segmentfault.com/?enc=%2BoqP1djSwde7udySoRtPFw%3D%3D.yc6w5L0CSbA1age6HSwAeC3lOPWGjHCKdrJw2v%2BJmUsOL2woHluWFnH5NgxB0z8b" rel="nofollow" target="_blank">OpenAI Agents SDK</a>、<a href="https://link.segmentfault.com/?enc=TzNpGw4Po4S4xIH8FfxhUg%3D%3D.oyej9fQYXkUw%2B9%2F5110J8C8WE9HKjsL5L1t47Z4A6LT8WXhhd4DuH3B7c1JB5VZs" rel="nofollow" target="_blank">LangGraph</a>、<a href="https://link.segmentfault.com/?enc=PYiOMCVKa%2B51WWYqdUWF6A%3D%3D.N1UlAAUypnuxyTdm%2F4Tuy%2FUVyIXVwnYnfORWnSKE6xZh6f9TW0stkEGky%2BM6JaQJ" rel="nofollow" target="_blank">Google ADK</a> 和 <a href="https://link.segmentfault.com/?enc=ZtnrniL6vK7feH1T2a5qHQ%3D%3D.2TjQkRI8PpPKHeZVJGrd3y89j5LOhoBuS2ld5bqKSNsYSp1Vky1RjqiJx808i6l8epwzAJ%2BFjdDdfZK2qenvzw%3D%3D" rel="nofollow" target="_blank">Claude Agents SDK</a> 等框架的智能体以“通用且可验证的格式”共享上下文、能力与推理信息。</p><p>Bedrock AgentCore Runtime充当这些跨智能体通信的基础设施层。通过 <a href="https://link.segmentfault.com/?enc=s1lD%2FG3a4BJqW0Vj4q5%2Fig%3D%3D.VvpxVBxw7jEfzLAE9cwYmCbwe15k1Hj1WhjqwgtFo%2F3BHE2pIVNmTK5Lv6b8K7Ia" rel="nofollow" target="_blank">A2A</a>，开发者可以构建跨框架的多智能体工作流，实现系统级协作。</p><h2>1 智能体系统的基础组件</h2><p><a href="https://link.segmentfault.com/?enc=dbRDJoOVyWbl5pdtnhkRWA%3D%3D.PhNLhI4HuwOmY0DUrRjgKgSemJBY5Wmkx8D1r1PbV2kD0NS1VruGmam7xm%2Fc8nQQ" rel="nofollow" target="_blank">智能体系统（Agentic systems）</a>想高效运行，需要多个核心组件协同工作：</p><ul><li><strong>记忆（Memory）</strong>：包括短期记忆（维持会话上下文）和长期记忆（跨多次会话保留洞察）</li><li><strong>工具（Tools）</strong>：赋予智能体执行功能，可通过原生集成或 <a href="https://link.segmentfault.com/?enc=80B1%2FhryNhe8IdYzqOpeyA%3D%3D.vMJNfLSEtorLA6jwovMpi2DudlFWwNifqQFzA3JQXWw%3D" rel="nofollow" target="_blank">Model Context Protocol（MCP）</a> 服务器访问</li><li><strong>身份管理（Identity Management）</strong>：通过 <a href="https://link.segmentfault.com/?enc=rpzXblkXC6zAI0bdzRGviw%3D%3D.k%2BslUqEVDA%2BctGF3uWyubJ0%2B72%2BPBViglzSnK8LDeW4%3D" rel="nofollow" target="_blank">IAM</a> 提供安全认证与权限控制，使智能体可代表用户或自主访问资源</li><li><strong>安全防护（Guardrails）</strong>：通过 <a href="https://link.segmentfault.com/?enc=%2BAAdKqPTAH8T9VydBxLAaA%3D%3D.aNNTyqc5GhHmIDuDKQaBDWhZbaAUMWDZmhlg2QkzUQeVNZp%2Fd33B2uMj%2FiRXr5bu" rel="nofollow" target="_blank">Bedrock Guardrails</a> 检测有害内容、防止幻觉、确保输出符合政策和事实准确性</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438454" alt="" title=""/><br/><em>来源：<a href="https://link.segmentfault.com/?enc=09sVkZxPFHWkNImMO5AmeA%3D%3D.TYjGVVaTonE0TKQ0xokzZ7hPsf5d6tsxf%2FpD5C4qigrfBEggeMdUXhzz7E%2Fv2F7nCdzEfQ1Oc86Aipu%2FS7ND8P4YEP5vAr73C7kJywx73ePj3eQ6KiYfcIWcDlON5Z73d0EWRV5pwswrblGHPhTGyA%3D%3D" rel="nofollow" target="_blank">Bedrock AgentCore 平台</a></em></p><hr/><h2>2 A2A 与 MCP 的区别</h2><p><a href="https://link.segmentfault.com/?enc=roIaM4futMvovg8MaWpGzg%3D%3D.J%2FufbbnBwj%2Bu1UyDCiACPZGwQfJl27n%2BNoiYgOiwVjjBfE8StFEbjkhtkVJYR5XTrxXr12SIiFUhLLoS%2Bj1VmXjSso9gAqtHa8dMgkRN6lDPT5ZFokbEo3lJWMtLI9zQL0SqBU9nXy7lq9Bow2jnfL%2Fvk2r2lQTU6K3XDf%2FPSVA%3D" rel="nofollow" target="_blank">A2A 协议</a> 解决 <strong>智能体之间的通信</strong> 问题，而 <a href="https://link.segmentfault.com/?enc=w2txxRCJ95V%2FuKNhCR9CZA%3D%3D.22fCv4hBPwaI4dTHEoMRP2%2Fp%2FmjK49%2BjJ8Sa1rUxpfk%3D" rel="nofollow" target="_blank">MCP</a> 解决 <strong>智能体与资源之间的连接</strong> 问题。</p><ul><li><strong>MCP</strong>：让单个智能体能访问其工具和数据源</li><li><strong>A2A</strong>：让多个智能体能彼此协调，共同完成任务</li></ul><p>这一区别对系统架构尤为重要——前者侧重“智能体到资源”，后者侧重“智能体到智能体”的协作通信。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438455" alt="" title="" loading="lazy"/><br/><em>来源：<a href="https://link.segmentfault.com/?enc=KbH768mnRBuUjJFm41h2CA%3D%3D.J72qecyc2wc0AfYdN20OiP1V9sDqII1nSrzZ%2F3qUsUs%2B9D328INCpmeJ44h7TWsxMnvEJEdKCkhL4F3Z1r6tv%2BC3z8ToZiqxpoG8%2FUkASKT8IiUMf%2FzfDpuhaIxBK27XYgYjufxIFco8f6l7WQViE%2FHKhMo4z%2FVepkVjGc6KyXM%3D" rel="nofollow" target="_blank">AWS 官方博客</a></em></p><hr/><h2>3 协议特性：松耦合与模块化</h2><p>A2A 协议采用 <a href="https://link.segmentfault.com/?enc=22SGMmLVUQnGa5G9J1bM3w%3D%3D.XkfwDWp9MDoCX9L5qC87luw1OUY7bWlPwKpSEXKwXeACRWdMAJUDLh%2BZpMWfMX3E" rel="nofollow" target="_blank">松耦合（Loose Coupling）</a> 与 <a href="https://link.segmentfault.com/?enc=CuGs7iDPKKqrSnnZ%2Fug%2FZA%3D%3D.pstU%2FXlQ7zgsinkXLYdL6CervYp%2Bo5nppv4Po%2BGb6uY4zlyaHEhLT21hPYnmEbJG" rel="nofollow" target="_blank">模块化（Modularity）</a> 设计，使每个智能体能作为独立单元运行。开发者可独立开发、测试、部署和升级单个智能体，而不影响整个系统。新智能体可无缝加入现有部署，而发生故障的智能体也能被隔离在定义好的交互边界内。</p><h2>4 动态发现与编排</h2><p>协议支持动态的 <strong>智能体发现与编排（Orchestration）</strong>。智能体通过标准化的模式（Schema）发布自身的能力信息，形成一个“功能注册表”。<br/><strong>编排智能体（Orchestrator Agents）</strong> 可基于实时任务需求发现并调用最合适的智能体，从而实现 <strong>自适应工作流</strong> ——任务会根据上下文动态分配给合适的智能体执行。</p><h2>5 技术实现：Agent Card 与 Task Object</h2><ul><li><strong>A2A服务器（A2A Server）</strong>：远程智能体通过实现协议规范的 HTTP 接口来提供服务，支持 <a href="https://link.segmentfault.com/?enc=Qsm5MHAKKg8vujJhUzpgow%3D%3D.dY1qPZnH73xFTLSNw92eYL8oMKubdIa6PjMBEP81g1x8zufB8aWufCc%2FElQf7O58PUQ1z%2BJQBxgVkHpKoLM9e84E2SGLIJd0eJ12ZSPfHZQ%3D" rel="nofollow" target="_blank">HTTP/S</a> 上的 <strong>JSON-RPC 2.0</strong> 通信，既可 <a href="https://link.segmentfault.com/?enc=oNlk23LogYriXZMVeX6rtQ%3D%3D.VNmAFzKQSBqPcE6Akxk8iXB0FPRZewf4NLBbowaddigpc8dQafpkBOM2ZGfa84W0a7qYvOeXQFzesKj%2FRhvkRQiiQmJ5oqfyPhyZZzTOCZwGEE5VOjeCoN%2FESr08yGavKGJ1XK%2BTczQrAe3Exzhq5%2FXy73ee%2FozWn0OPVpftYuE%3D" rel="nofollow" target="_blank">同步</a>，也可 <a href="https://link.segmentfault.com/?enc=6cmAlKv5vusGQTQq%2Br%2BAzw%3D%3D.vRlqV7y4H1VN%2B0VFFDxu2nIHVGSOxCc8RrGC36J7ZjvKeaKFU6snLDiqRvJk18lbj0eYxIHijYc9cVDUDPym5seorfDWdLnS2MWB%2BJRFiZLgv3q1XvJStS6%2BqXGlF1l3VMCJLwS%2FsgXTu1kNYcX6K4qh6hEG8U4Naozkzp2a1so%3D" rel="nofollow" target="_blank">异步</a> 交互</li><li><strong>Agent Card</strong>：每个智能体都会发布一个 JSON 元数据文件，描述其身份、功能、接口端点及认证要求<br/>这相当于一份“契约说明书”，让其他智能体能正确地与其交互。</li><li><strong>Task Object</strong>：代表系统中流动的每个任务单元，包含唯一标识符和生命周期信息。任务可能是长时间运行的过程，涉及多个智能体的多轮协作。协议会跟踪任务状态，帮助编排器监控进度、处理故障或超时</li></ul><h2>6 安全性与社区反馈</h2><p>安全研究机构 <a href="https://link.segmentfault.com/?enc=RZaQWyj7m3Sb1xjWyCCb0A%3D%3D.RhDzeMwJRhWDmeSgSx7tQ7dZYtai6CS8PHmBu0xVQpGIx5XJyLuIT64KlCxmoTth" rel="nofollow" target="_blank">Unit42（Palo Alto Networks）</a> 指出，A2A 协议的状态化设计可能带来安全风险。根据其 <a href="https://link.segmentfault.com/?enc=8iZYE0m4lGCQRQ%2Bs1FPbfA%3D%3D.10w8Sja2tSlWam8TAsxm2wZBs2fch4HWrMIKXwIULgY%2FAIBi3Tn1ozyYre%2BSDRbkHR6%2FrPtuJnkiBwOYlGIkx0cXhmYOISRU31EqHlRiILjQalL%2FwtP9Ykymm2ltInf7" rel="nofollow" target="_blank">分析报告</a>：</p><blockquote>A2A允许智能体在会话中记住交互历史并保持上下文一致性。这种特性可能被攻击者利用，通过“会话走私（Session Smuggling）”注入恶意指令，将其隐藏在正常请求与响应之间。</blockquote><h2>7 开发资源与文档</h2><p>有兴趣实现基于 A2A 的系统的开发者，可参考：</p><ul><li><a href="https://link.segmentfault.com/?enc=MXqx6lMpHMerz6r3s5bg9A%3D%3D.6YKh7bcMTaHTqycJpjFF%2BRr%2F%2F%2FyaZ%2FWxtpJGvr5MfYf9TSjkR1bm41h98St3bDzLWvuZEnLROeujRZm0zNl%2FhEym0eyzA2wEWRvQJ0edrbMpBbxYT1rq7y9o1B2BtnzA1QVV0QOpT440aS3mc5ZfmRDvv0eWY4PfjA2X%2FcwPlLI%3D" rel="nofollow" target="_blank">A2A 教程与示例代码</a></li><li><a href="https://link.segmentfault.com/?enc=S%2F01GLJ3%2BKBikAFphpkYtw%3D%3D.t46%2BqxX4%2BP2grYjhMqwLL%2BAWEQgP6mOFcruPmFOYpb88BjwDTTORmHip%2F6inaJ0E" rel="nofollow" target="_blank">Bedrock AgentCore 开发者指南</a> ——详细介绍运行时操作、内存管理与身份控制</li><li><a href="https://link.segmentfault.com/?enc=fJB2vhrqs2r5xT%2F5oZyDZQ%3D%3D.nY3e2LohPNAa6Zsy%2BiPMdGAKAo1lPbQf7q0nQIVAhY0Z8TKGupIs%2F0myb%2FtaDWq7p2dmRySjy5m2MX5As0PSR2dPGcf09mX4%2BtfHMV8PMEfWIkmF3GtnYJrL95Q1pvkGpa04sqK2xugtcjqO12fQ4w%3D%3D" rel="nofollow" target="_blank">A2A 协议规范文档</a> ——定义智能体间通信的技术要求与交互模式</li><li><a href="https://link.segmentfault.com/?enc=kDUORBaeUmOnx46e709AnQ%3D%3D.NE1F8VFvHoRMi96H7YhKEaVGI%2FjvumPX0JMgnJYTm2p2T1DjSy%2BGkzzT941gE1hBa8kZhYgr8HJPD1OQcQ1IRbRRLYsyf0gnthBlTP4xGY0%3D" rel="nofollow" target="_blank">InfoQ 早期报道</a> ——回顾 Bedrock AgentCore 平台最初发布时的功能背景</li></ul><p>通过引入A2A，亚马逊进一步推动了多智能体生态系统的互操作与标准化，使不同框架和平台上的智能体能够协同工作，构建更复杂、更智能的分布式 AI 系统。</p>]]></description></item><item>    <title><![CDATA[Outlook OWA是什么？2025登]]></title>    <link>https://segmentfault.com/a/1190000047438337</link>    <guid>https://segmentfault.com/a/1190000047438337</guid>    <pubDate>2025-11-29 22:04:33</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在当今数字化办公的时代，企业对于高效、安全且便捷的邮件管理工具需求日益增长。Outlook的OWA网页版为企业提供了一种跨平台的邮件管理方式，而Zoho企业邮箱则凭借其独特的优势，成为外贸企业等众多企业的优选。下面将详细介绍Outlook OWA网页版的使用方法，并对比分析Zoho企业邮箱的优势。<br/><img width="723" height="443" referrerpolicy="no-referrer" src="/img/bVdnc2C" alt="" title=""/></p><h2>一、Outlook邮箱的OWA简介</h2><p>OWA的定义<br/>OWA，全称 Outlook Web App，是微软专为企业用户打造的网页版邮件管理平台。用户无需安装独立客户端，只需通过浏览器就能直接访问，轻松实现收发邮件、管理联系人和日历等操作。</p><h2>OWA与Outlook客户端的区别</h2><p>平台依赖：OWA摆脱了下载安装的束缚，任何设备只要有浏览器即可访问；而Outlook客户端则需安装在PC或移动端才能使用。<br/>实时性：OWA具备强大的实时同步功能，邮件、日历等内容能够随时与服务器保持同步，确保信息及时更新。<br/>操作体验：客户端支持更多本地功能，例如离线访问、集成进Windows等；OWA则更加轻便，操作界面简洁易用，降低了用户的学习成本。<br/>OWA的功能优势<br/>跨平台访问：只要有网络和浏览器，OWA就能让企业邮箱实现随时随地登录，极大地提升了远程办公的效率，非常适合现代企业不断变化的工作环境。<br/>简化操作界面：OWA简洁的结构使得常用功能如收件箱、发件箱、日历、任务等一目了然，有效降低了新手员工的操作门槛。<br/>实时同步功能：所有邮件和会议日程都会与服务器自动同步，保证信息的及时更新，杜绝因信息延误而带来的损失。</p><h2>二、如何使用Outlook的OWA</h2><p>登录OWA<br/>直接访问 OWA 官方网址：<a href="https://link.segmentfault.com/?enc=YY%2BV3jERUkE2vZd%2FnCHgWw%3D%3D.WGD9HbK6V6bPLPrK9pT1gb3YE4vxwHbnD%2FxACJKNrTQ%3D" rel="nofollow" target="_blank">https://outlook.office.com/</a> ，输入企业分配的邮箱账号和密码，即可完成登录。</p><h2>邮件管理操作</h2><p>发送和接收邮件：点击“新建邮件”，输入收件人、主题与正文，还可以添加附件。OWA支持较大附件传输，方便企业进行文件共享。<br/>管理邮件文件夹：支持自定义文件夹、快速邮件归档和搜索功能，有助于企业高效整理业务往来邮件。<br/>设置邮件规则：用户可以根据自己的需求自定义规则，例如自动分类、转发、删除垃圾邮件等，从而提升邮件处理效率。</p><h2>三、推荐：Zoho邮箱的替代优势</h2><p>企业在开展国际业务、进行跨国通讯时，对邮件的安全性和海外邮件的稳定收发能力有着更高的要求。Zoho企业邮箱凭借其卓越的性能，受到了全球1800万企业级客户的信赖，成为各类域名邮箱管理、移动办公以及海外业务的首选。</p><h2>Zoho邮箱的特色功能</h2><p>强大的邮件过滤与安全功能：内置先进的反垃圾邮件引擎和邮件加密技术，能够全面防御垃圾邮件和钓鱼邮件。同时，提供多层身份验证、TLS传输以及加密存储，全方位保障企业核心数据的安全。<br/>丰富的协作工具：Zoho Mail不仅仅是一个邮件管理工具，还集成了聊天、日历、任务、笔记、文件管理等功能，实现了企业级一体化办公。此外，原生CRM集成功能，非常适合外贸客户跟进，使销售进展更加透明化。<br/>定制化与品牌化：支持企业自定义域名（域名邮箱设置过程便捷），并且邮箱界面可以根据企业的品牌形象进行贴合设计。详细的注册步骤从域名绑定到多账号分配，只需数分钟即可启动。<br/>Zoho邮箱与Outlook OWA的对比<br/>以下是Zoho Mail与Outlook OWA在多个维度的简要对比：</p><p>对比项目    Zoho企业邮箱    Outlook OWA<br/>海外收发稳定性    全球多个数据中心，专为国际邮件优化    主要依赖微软全球节点<br/>安全防护    邮箱加密、反垃圾邮件、钓鱼拦截先进（企邮排行前三）    微软安全体系，防御能力强<br/>CRM及外贸支持    原生CRM直连，适合外贸客户全流程管理    CRM需集成第三方或手动配置<br/>大附件&amp;文件归档    支持大附件（最高容量1GB），邮件自动归档    附件支持较好，归档需结合OneDrive等<br/>移动办公/APP体验    高效Webmail、原生App全端同步    Webmail和Outlook客户端<br/>企业邮箱价格    起步价低，性价比高，适合中小/大型企业    定价以Microsoft 365套餐维度，高阶功能需升级<br/>中文/全球客户支持    全球1800万客户、全天多语言客服    全球用户基础强，欧美支持更佳<br/>注册步骤/易用性    注册步骤简洁，域名、用户开通一站式    注册由管理员配置，流程略复杂<br/>*具体容量请以Zoho Mail官网说明为准        <br/>为什么选择Zoho企业邮箱？<br/>适合中小企业与团队：Zoho企业邮箱提供灵活的套餐和按需定制功能，无论是中小企业还是大型团队，都能轻松扩展，满足现有业务及未来增长的需求。<br/>高度可扩展性：企业可以随时批量新建或删除账号，结合企业组织架构进行动态调整，同时支持移动办公、API集成和多端同步。<br/>优质客户支持：提供7x24小时多语言客服，能够快速响应企业日常运维及突发问题。在全球企业邮箱排行中连续多年稳居前三。</p><h2>四、常见问题及解答</h2><h2>如何找回Outlook OWA的登录密码？</h2><p>通过“忘记密码”功能，输入账号后，根据提示进行身份验证和密码重置。若为企业邮箱，请联系管理员协助处理。</p><h2>OWA登录时提示“无法连接到服务器”，怎么办？</h2><p>检查网络连通性或VPN设置，确认企业服务器正常运行。如依然无法访问，可用移动设备或浏览器清除缓存后重试，必要时联系IT支持。</p><h2>如何在OWA中设置自动回复？</h2><p>进入“设置——自动回复”，可自定义自动回复内容、启用时间段，并设定是否对外部联系人生效，轻松应对假期或短期离岗通知。</p><p>综上所述，Outlook的OWA网页版为企业提供了一种便捷的邮件管理方式，而Zoho企业邮箱则凭借其独特的优势，在海外收发稳定性、安全防护、协作功能等方面表现出色，是企业进行邮件管理和办公协作的优质选择。企业可以根据自身需求，选择适合自己的邮件管理工具。</p>]]></description></item><item>    <title><![CDATA[微软Outlook企业邮箱登录入口 遭老]]></title>    <link>https://segmentfault.com/a/1190000047438354</link>    <guid>https://segmentfault.com/a/1190000047438354</guid>    <pubDate>2025-11-29 22:03:42</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在企业通信中，邮箱的安全性和功能性至关重要。Outlook企业邮箱作为微软旗下产品，在企业通信领域广泛应用。同时，Zoho Mail凭借其独特优势，也为众多企业提供了优质选择。下面将详细介绍如何安全登录Outlook企业邮箱，并对比分析Outlook企业邮箱与Zoho企业邮箱。<br/><img width="723" height="443" referrerpolicy="no-referrer" src="/img/bVdnc2T" alt="" title=""/></p><h2>Outlook企业邮箱登录入口概述</h2><h2>官网登录入口地址</h2><p>使用Outlook企业邮箱，强烈建议通过微软官方登录网址：<a href="https://link.segmentfault.com/?enc=GL6TjOQjr9qpi3bCerO7Gg%3D%3D.4Y5oInB0CobWK62OBYmpI1KClhyDNx2eeFPidZE2OV8%3D" rel="nofollow" target="_blank">https://outlook.office.com</a> 。此地址专为企业版（Office 365/Exchange）设计，能有效确保数据连通与安全。</p><h2>登录入口的识别与安全性</h2><p>企业用户务必警惕仿冒网站。判断登录页是否为官方入口，可核查HTTPS证书及页面域名，切勿通过第三方链接或邮件打开。特别是在域名邮箱管理与访问过程中，更要注重登录安全。建议启用企业邮箱防钓鱼和多因素身份验证等额外措施，全方位保障通信安全。</p><h2>Outlook企业邮箱的特色与优势</h2><h2>邮箱功能与性能</h2><p>高效邮件管理：Outlook支持智能邮件分组、优先收件箱及强大筛选功能，非常适合多业务线高强度收发。企业邮箱的大附件传输、自动归档、邮件标签等功能，可显著优化日常通信效率。<br/>强大的日程管理：内置日历与会议安排工具，便于跨部门及国际团队协作。Gantt视图与与会通知功能，能大幅提升企业内部信息流转协同效率。<br/>集成的协作工具：Outlook与Teams、SharePoint等深度整合，可部署企业级邮件归档和知识分享，为企业协作提供有力支持。</p><h2>安全与隐私保护</h2><p>数据加密技术：Microsoft为Outlook企业邮箱引入端到端邮件加密，确保传输过程中数据信息安全。邮件加密机制既能满足合规需求，又适用于国际商务往来。<br/>防止恶意软件与垃圾邮件：先进的反垃圾邮件过滤与防病毒引擎，可智能甄别疑似邮件，有效提升企业邮箱安全性，降低业务风险。<br/>多因素身份验证：支持生物识别、短信验证等多重认证方式，有效防止未授权访问。<br/>与Microsoft生态系统无缝集成<br/>与Office 365的协同工作：邮件、联系人、日程全面互通，可提升文件、会议、任务流转效率，实现邮件驱动业务流程自动化。<br/>与Azure的集成优势：Azure Active Directory可实现单点登录与权限管理，适用于大型企业邮箱部署及身份认证整合需求。<br/>Outlook企业邮箱与Zoho企业邮箱对比</p><h2>功能维度</h2><p>邮件处理能力：Outlook企业邮箱以其深度办公开发能力著称，支持复杂邮件场景。Zoho企业邮箱则因高效海外邮件稳定收发能力、智能反垃圾邮件、支持企业邮箱大附件等，深受外贸企业青睐。<br/>日程与任务管理：Outlook主打与Office生态、Teams集成。Zoho企业邮箱内建协作工具，支持和CRM等Zoho产品无缝配合，更适合中小企业和国际贸易团队。</p><h2>安全性维度</h2><p>数据保护措施：Outlook采用微软自研TLS/SSL协议加密。Zoho Mail提供端到端邮件加密、多层次反垃圾邮件与邮件归档功能，并针对外贸场景优化了海外邮件扩展与反黑名单机制。<br/>用户认证方式：Outlook主推多因素认证及企业级Azure同步。Zoho Mail则以灵活的身份管理和高效防钓鱼策略为特色，提升账户总体安全性。</p><h2>集成与扩展性维度</h2><p>第三方应用支持：Outlook企业邮箱与绝大多数Microsoft 365、第三方办公服务深度兼容。Zoho Mail天然支持CRM集成、多终端移动办公、API开放等，便于海外团队协同。<br/>企业级解决方案的灵活性：Outlook适合对微软生态高度依赖的大型组织。Zoho Mail高性价比、海外服务器架构，适配中小型及外贸企业多地域发展。<br/>对比表：Outlook企业邮箱 vs Zoho企业邮箱<br/>对比维度    Outlook企业邮箱    Zoho企业邮箱<br/>全球用户基数    Microsoft 365全球2亿 + 企业级用户    全球1800万企业级客户，全球邮箱排行前三<br/>海外邮件收发    在中国大陆等地区偶有延迟或不稳定    多国家服务器，外贸及国际邮件畅通稳定<br/>安全防护功能    企业级数据加密，强防垃圾邮件    端到端加密，专业反垃圾、反钓鱼，不易中断<br/>核心集成功能    深度集成Office/Teams/SharePoint    邮箱、日历、联系人无缝协作，CRM集成、API兼容<br/>价格灵活性    针对大型企业定价，部分中小企业负担较重    中小企业邮箱/大型企业邮箱套餐多样，企业邮箱价格适中，提供定制化服务<br/>移动办公体验    全平台App支持，Office生态无缝延展    Webmail、iOS/Android App，支持IMAP/POP/Exchange ActiveSync<br/>大附件/归档功能    邮件最大支持150MB，邮件归档需付费/定制    支持大附件批量收发，邮件归档内置，多端同步<br/>注册与域名管理支持    域名邮箱注册复杂，需手动设置DNS，初次配置耗时    注册步骤简明，提供向导工具和专属客服，入门友好</p><h2>常见问题及解答</h2><h2>如何找回忘记的Outlook企业邮箱密码？</h2><p>可通过Outlook密码重置官网完成自助找回，遵循页面操作，根据注册邮箱或手机验证身份。</p><h2>Outlook企业邮箱登录时提示“账号不存在”，怎么办？</h2><p>确认输入的邮箱地址拼写、域名是否正确。若仍无法登录，建议联系企业IT部门核查账户状态或注册信息。</p><h2>如何在移动设备上登录Outlook企业邮箱？</h2><p>在App Store或Google Play下载“Microsoft Outlook”官方App，添加企业邮箱账户，按提示完成域名邮箱配置，即可享受推送提醒及同步日程功能。</p><p>考虑到企业通信安全与外贸收发需求，Zoho Mail凭借全球分布式服务器、全面加密与专业反垃圾机制，为域名邮箱提供了顺畅、稳定的体验。企业可根据自身需求，选择适合的邮箱服务。</p>]]></description></item><item>    <title><![CDATA[智能工单管理系统哪家好？六款知名软件解析]]></title>    <link>https://segmentfault.com/a/1190000047438359</link>    <guid>https://segmentfault.com/a/1190000047438359</guid>    <pubDate>2025-11-29 22:03:07</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>智能工单管理系统已成为提升企业效率、优化客户服务的关键工具。无论是制造业、服务业还是 IT 行业，这类系统都能助力企业实现任务分配、进度跟踪、数据分析等功能，进而提升整体运营效率。然而，市场上智能工单管理系统种类繁多，企业该如何挑选出适合自己的工具呢？接下来，为大家介绍六款知名热门智能工单管理系统。<br/><img width="723" height="487" referrerpolicy="no-referrer" src="/img/bVdnc2Y" alt="" title=""/></p><h2>1. Zoho Desk</h2><p>Zoho Desk 是一款功能全面且灵活的智能工单管理系统，专为提升客户服务效率与优化团队协作而打造。作为 Zoho 生态系统的一员，它既支持独立使用，也能与 Zoho CRM、Zoho Projects 等工具无缝集成，为企业提供一站式解决方案。</p><p>核心功能<br/>多渠道支持：支持电话、邮件、实时聊天、社交媒体等多种渠道的工单管理，确保客户问题能得到快速响应。<br/>智能任务分配：借助 AI 技术（Zia AI），依据任务优先级和员工工作负载自动分配工单，提高分配效率。<br/>实时数据分析：内置强大的分析工具，支持生成自定义报告和仪表盘，助力企业深入了解工单处理效率和客户满意度。<br/>自定义与集成：支持高度自定义工单字段、自动化规则和工作流，还能与 Zoho 生态系统及第三方工具（如 Slack、Jira）无缝集成。<br/>移动端支持：提供移动应用，方便服务人员随时随地处理工单。<br/>适用场景<br/>客户服务：快速响应客户问题，提升客户满意度。<br/>IT 支持：高效管理技术支持工单，优化问题解决流程。<br/>制造业：管理设备维护和生产任务，提升生产效率。<br/>优势<br/>界面友好，易于上手。<br/>定价方案灵活，适合不同规模的企业。<br/>AI 功能强大，自动化水平高。<br/>推荐理由<br/>Zoho Desk 性价比极高，功能全面且灵活，适合各行业企业使用，尤其适合需要多渠道支持和高度定制化的企业。</p><h2>2. Zendesk</h2><p>Zendesk 是全球知名的客户服务和工单管理系统，专注于帮助企业提升客户支持效率，以强大的多渠道支持和用户友好界面著称。</p><p>核心功能<br/>支持电话、邮件、社交媒体和实时聊天等多渠道。<br/>实现自动化工单分配和优先级排序。<br/>提供数据分析与报告功能，助力企业优化客户支持流程。<br/>支持知识库管理，方便客户自助解决问题。<br/>适用场景<br/>客户服务：适合处理大量客户咨询的企业。<br/>电商行业：管理客户订单和售后服务。<br/>优势<br/>界面简洁，易于使用。<br/>多渠道支持功能强大。<br/>劣势<br/>定价较高，适合预算充足的企业。<br/>高级功能需额外付费。</p><h2>3. Freshdesk</h2><p>Freshdesk 专注于客户支持，提供多种自动化功能和强大的协作工具。</p><p>核心功能<br/>支持电话、邮件和社交媒体等多渠道。<br/>实现自动化工单分配和 SLA 管理。<br/>支持知识库和社区论坛，方便客户自助解决问题。<br/>适用场景<br/>客户服务：适合中小型企业的客户支持需求。<br/>IT 支持：管理技术支持工单。<br/>优势<br/>界面友好，易于上手。<br/>定价灵活，适合中小企业。<br/>劣势<br/>高级功能较少，适合基础需求的企业。</p><h2>4. ServiceNow</h2><p>ServiceNow 面向大型企业，专注于 IT 服务管理（ITSM）和企业流程自动化。</p><p>核心功能<br/>IT 工单管理和自动化任务分配。<br/>具备强大的数据分析和报告功能。<br/>支持与企业现有系统深度集成。<br/>适用场景<br/>IT 行业：管理复杂的技术支持和项目任务。<br/>大型企业：需要高度定制化和集成的企业。<br/>优势<br/>功能强大，适合复杂需求。<br/>支持深度定制和集成。<br/>劣势<br/>实施成本高，适合预算充足的大型企业。<br/>学习曲线较陡。</p><h2>5. Jira Service Management</h2><p>Jira Service Management 由 Atlassian 推出，专注于 IT 服务管理和项目管理。</p><p>核心功能<br/>支持 IT 工单管理和 SLA 管理。<br/>与 Jira 软件无缝集成，满足项目管理需求。<br/>提供数据分析与报告功能，助力优化流程。<br/>适用场景<br/>IT 行业：管理技术支持和项目任务。<br/>软件开发：与 Jira 软件结合使用，提升开发效率。<br/>优势<br/>与 Jira 软件深度集成，适合开发团队。<br/>功能强大，支持复杂需求。<br/>劣势<br/>界面较复杂，新用户需一定学习时间。</p><h2>6. Kayako</h2><p>Kayako 专注于客户支持，提供多渠道支持和协作工具。</p><p>核心功能<br/>支持电话、邮件和实时聊天等多渠道。<br/>支持知识库管理，方便客户自助解决问题。<br/>提供数据分析与报告功能，助力优化客户支持流程。<br/>适用场景<br/>客户服务：适合中小型企业的客户支持需求。</p><p>优势<br/>界面简洁，易于使用。<br/>定价灵活，适合中小企业。<br/>劣势<br/>功能较为基础，适合简单需求的企业。</p><h2>如何选择适合的智能工单管理系统？</h2><p>企业在选择智能工单管理系统时，需根据自身需求和预算进行权衡：</p><p>明确需求：确定是注重客户服务，还是需要支持 IT 工单管理。<br/>预算考量：选择适合预算的系统，不一定要选最贵的，但要确保功能满足需求。<br/>用户友好性：挑选界面友好、易于上手的系统，降低员工学习成本。<br/>可扩展性：选择支持定制和集成的系统，以便未来扩展功能。<br/>Zoho Desk 凭借灵活的定价方案、强大的功能和高度的可扩展性，成为各行业企业的理想之选。</p><p>智能工单管理系统是企业提升效率、优化服务的重要工具。本文介绍的六款知名系统各有特色，其中 Zoho Desk 以全面的功能、友好的界面和灵活的定价方案，成为最值得推荐的解决方案。无论是中小企业还是大型企业，Zoho Desk 都能助力实现高效的工单管理，推动企业数字化转型。</p>]]></description></item><item>    <title><![CDATA[2人团队交付神器：低代码1人起购实战 遭]]></title>    <link>https://segmentfault.com/a/1190000047438364</link>    <guid>https://segmentfault.com/a/1190000047438364</guid>    <pubDate>2025-11-29 22:02:10</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>市场上许多低代码平台，如伙伴云、简道云、氚云等，往往要求30人起购。这对于2人开发团队而言，既不经济也不实用。不过，还有像Zoho Creator低代码平台这样更为灵活的选择，它支持“1人起购”，标准版仅需672元/人/年，让小团队也能以可承受的成本享受低代码技术带来的效率提升。这种模式使2人开发团队能够快速构建应用，将开发周期从数月缩短到几周甚至几天。<br/><img width="723" height="480" referrerpolicy="no-referrer" src="/img/bVdnc23" alt="" title=""/></p><h2>一、低代码平台是什么？为何能让小开发团队高效交付？</h2><p>低代码开发平台是一种借助可视化编程界面和少量代码生成逻辑，助力开发者快速构建应用程序的工具。它通过图形化界面、拖拽组件和模型驱动的方式，大幅减少手动编码工作量，让非技术人员也能参与应用开发。</p><p>对于小团队来说，低代码平台的核心价值体现在以下几个方面：</p><h2>降低开发门槛</h2><p>业务人员无需具备深厚的编程基础，通过可视化操作即可搭建简单应用。</p><h2>提升开发效率</h2><p>能够缩短传统开发周期，1个人能够发挥2 - 3人的人效。</p><h2>快速响应需求</h2><p>业务实践或优化可在几分钟内开发出来，并获得即时反馈。</p><h2>降低成本风险</h2><p>减少对专业开发人员的依赖，缓解IT资源紧张问题。</p><h2>二、市场主流低代码平台价格对比</h2><p>下表对比了市场主流低代码平台的价格策略，清晰展示了哪些平台更适合小团队使用：</p><p>平台名称    起购要求    价格范围    产品优势    适合团队规模<br/>Zoho低代码    1人起购    标准版：672元/人/年起    AI辅助数据迁移、多设备自适应、800 +国际应用集成    中小型团队、跨国公司<br/>伙伴云    30人起购    标准版：8800/年起    数据协作与业务管理平台    中大型企业<br/>简道云    30人起购    标准版：5040元/年起    零代码开发    中大型企业<br/>氚云    30人起购    标准版：4280元/年    零代码与少代码混合开发模式    中型企业<br/>金蝶云苍穹    定制报价    业务版：198,000元/年起    财务领域专业性强    大型集团企业<br/>织信    定制报价    定制开发价格通常较高    全栈开发能力、国产化适配    大型企业、国有企业<br/>宜搭    定制报价    轻享版2988元/年起    支持阿里生态    中型企业<br/>从对比中可以看出，Zoho低代码在起购门槛和价格灵活性方面具有明显优势，特别适合小团队、国际企业根据实际需求逐步扩展。</p><h2>三、Zoho低代码平台的特点及优势</h2><p>Zoho低代码平台作为连续多年入选Gartner低代码平台“魔力象限”的产品，在低代码领域深耕19年，在全球拥有16个数据中心，600万 +用户，数据稳定，安全可靠。</p><h2>全栈自研技术与AI深度融合</h2><p>Zoho低代码平台的底层架构采用全栈自研，与多数依赖第三方技术的低代码平台不同。平台将AI能力深度融入开发流程，其生成式AI引擎Zia支持通过对话式提示生成应用程序，极大简化了系统开发流程。</p><h2>丰富的预构建模板和组件</h2><p>Zoho低代码提供超过60种预构建应用模板，覆盖CRM、项目管理、库存管理等多种场景。这些模板可以作为快速起点，大幅缩短开发时间。</p><h2>强大的集成能力和扩展性</h2><p>Zoho低代码支持与800多种应用集成，包括Zoho自身CRM、ERP等系统以及国际工具如Slack、Trello、Salesforce等。这种强大的集成能力打破了企业内部的信息壁垒，实现数据的自由流通和共享。</p><h2>跨平台开发与移动优先</h2><p>一次开发即可适配Web、iOS、Android设备，可一键发布应用至多个操作系统，实现跨平台无缝运行。这大大减少了针对不同平台重复开发的工作量，为企业节省时间和成本。</p><h2>细粒度权限管理和安全保障</h2><p>Zoho Creator提供了精细的权限管理体系，可精确到字段级别。在数据安全方面，平台使用AES_CBC/AES_GCM、256位/128位密钥和TLS 1.2协议等强密码加密数据，确保企业数据安全。</p><h2>四、如何快速上手Zoho低代码平台</h2><p>对于2人开发团队，快速上手Zoho低代码平台可以遵循以下步骤：</p><p>用Zoho账号登录Zoho低代码平台，如果没有账号，可以先注册一个。Zoho低代码提供15天全功能免费试用以及免费版，团队可以先注册熟悉平台基本功能。</p><h2>利用预置模板加速开发</h2><p>选择与业务需求最匹配的预置模板作为起点。Zoho低代码提供的60多个模板覆盖了大多数常见业务场景，团队只需根据自身需求进行定制调整，无需从零开始。</p><h2>重点掌握核心功能</h2><p>优先学习平台的核心功能：表单设计器、工作流自动化、报表生成和集成能力。Zoho低代码的表单设计器功能丰富，支持多种字段类型和自定义校验规则，工作流引擎可满足复杂的审批流程设置。</p><h2>利用学习资源加速掌握</h2><p>Zoho提供了详细的帮助文档和线上培训资源。2人团队可以分工学习，一人专注于前端界面设计，另一人专注于后端逻辑和数据管理，实现高效协作。</p><h2>从小型项目开始实践</h2><p>选择一个小型但完整的业务场景作为第一个实践项目，如客户信息管理、订单跟踪或库存管理系统。通过实际项目熟悉平台特性，逐步扩展到更复杂的应用。</p><h2>五、真实客户案例</h2><p>元品贸易是一家专注于美国和非洲商超市场的小型服装外贸企业。通过Zoho低代码平台，元品贸易在仅15天内就搭建了符合企业需求的国际供应链管理系统，系统总费用仅为传统开发的十分之一，年账号续费仅两千多元（3用户）。</p><p>该系统支持多实体选择切换，对于不同的客户，可以选择不同的代理商实体和出口商实体，对应到每个订单的财务开票。不同订单和实体统一到一个数据看板，应收账款、应付账款和销账数据一目了然。实施Zoho低代码后，元品贸易的工作效率提升了50%，订单管理和跟进时间大大缩短，错误率归零。</p><h2>结语</h2><p>对于2人开发团队而言，选择合适的低代码平台至关重要。Zoho低代码平台以其1人起购的灵活定价、丰富的功能模块和强大的集成能力，成为小团队高效交付的理想选择。</p><p>通过低代码平台，2人团队可以实现与大型团队相媲美的开发效率，快速响应市场变化和业务需求。Zoho低代码平台的全栈自研架构和持续创新能力，确保小团队构建的应用能够随业务增长而扩展，无需担心系统稳定性和扩展问题。</p>]]></description></item><item>    <title><![CDATA[项目成本管理内容有哪些？ 遭老罪的程序猿]]></title>    <link>https://segmentfault.com/a/1190000047438373</link>    <guid>https://segmentfault.com/a/1190000047438373</guid>    <pubDate>2025-11-29 22:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在企业经营或个人项目管理的过程中，成本管理始终是绕不开的重要话题。无论项目规模大小，资源的有限性都促使我们仔细审视每一笔支出，追求最大化效率。正如彼得·德鲁克所说：“成本是一项迫使我们检验所有行为的现实要素。”这句名言恰如其分地道出了成本管理的重要性：它不仅是财务上的考核与测算，更是确保项目成功的关键抓手。<br/><img width="723" height="460" referrerpolicy="no-referrer" src="/img/bVdk1ax" alt="" title=""/><br/>下面，我们将以清晰的逻辑逐步探讨项目成本管理的核心内容，挖掘其在实际应用中的重要性，并推荐一款实用的工具。</p><h2>一、项目成本管理的四大核心内容</h2><h2>成本估算</h2><p>成本估算是项目成本管理的起点，也是决定后续步骤成败的基础。所谓估算，并非简单列出数字，而是通过科学方法计算完成每一部分工作的可能代价，涵盖人力、物力、时间以及风险带来的隐性成本。</p><p>进行成本估算时，项目经理需灵活运用历史数据、行业统计和岗位技能相关对照指标。例如，参考以往类似项目的费用结构、材料单价和市场波动，结合项目团队的交付能力，使估算更精准。像 Zoho Projects 这类工具能发挥重要作用，它允许项目团队通过案例模板记录历史数据，快速生成各项成本结构的估算依据。</p><h2>预算制定</h2><p>预算制定是将估算的成本整合成整体资金计划，明确具体资金在不同阶段的使用。完备的预算规划可有效避免资金浪费，让团队投入更具价值。</p><p>此过程需兼顾细节与全局，资金分配、进度跟踪以及应急储备比例设定都是重要部分。以 Zoho Projects 为例，它提供直观图表与自定义预算模块，帮助经理清晰分配费用，根据优先级调整资源分类投入，减少人为疏漏失误风险。</p><h2>成本控制</h2><p>若预算是蓝图，成本控制就是施工过程中的监督者。通过有效成本控制，项目管理者可随时掌握实际支出与计划是否相符，是否需调整规划以避免超支或偏离预期目标。</p><p>成本控制核心包括：</p><p>定期追踪实际支出进度，与预算对比分析。<br/>识别和处理可能导致成本增加的异常迹象，如进度拖延或需求变更。<br/>灵活使用工具记录每一项开销，确保财务透明化。<br/>在这方面，Zoho Projects 的实时跟踪功能突出。它依托自动化模块记录每一笔费用，通过警报系统提醒管理者支出异常节点，为及时调整提供依据。</p><h2>成本核算</h2><p>项目结束后，需汇总分析所有成本，这是项目成本管理的最后一步。通过整理核算数据，不仅能评估项目资源使用效率，还能为未来决策提供借鉴。</p><p>核算过程除传统财务报表整理，更需关注：</p><p>实际支出是否在预算范围内？偏差源自哪个环节？<br/>是否存在资源浪费？有哪些改进空间？<br/>如何衡量资金投入与成果产出的性价比？<br/>通过 Zoho Projects，这一环节可实现全自动化处理，避免人工计算误差，提供清晰报告模板，优化后续项目启动与规划。</p><h2>二、项目成本管理的关键注意事项</h2><p>掌握项目成本管理核心内容后，仍需关注关键事项，确保理论在实际场景中高效落实。</p><h2>不可忽视的隐性成本</h2><p>项目成本管理不仅包括显性支出（如设备采购、员工工资等），还需关注隐藏成本，如合作方失信、政策变动影响等。具备细腻的隐性成本分析能力，能帮助企业在制定预算时有更大应对弹性。</p><h2>实时动态调整</h2><p>传统项目成本管理常凭固定计划执行，但实际操作中，环境不确定性会给预算带来冲击。此时，实时监控与动态调整尤为重要。借助像 Zoho Projects 这样的工具，项目团队可追踪关键数据，第一时间优化计划。</p><h2>团队成本意识的培养</h2><p>即便工具先进，成功与否关键仍取决于团队对成本的关注度。项目团队每位成员都应充分理解成本控制意义，自觉将“节约并高效”作为工作准则。</p><h2>三、为什么选择 Zoho Projects？</h2><p>市面上项目成本管理工具众多，但 Zoho Projects 凭借功能完备性和灵活性脱颖而出。以下是其关键优势：</p><h2>一站式解决方案</h2><p>Zoho Projects 提供从成本估算、预算制定到支出追踪的全流程管理，简化传统项目成本管理复杂操作。它还支持多维度自定义报表与数据导入，满足企业及个人用户多元需求。</p><h2>高度可视化的成本控制</h2><p>通过清晰图表与标注提醒，Zoho Projects 让成本控制不再是隐性幕后工作，而是成为团队可协作完成的公开化环节。</p><h2>云端安全性</h2><p>作为基于云的项目管理工具，Zoho Projects 确保数据实时同步与存储安全，让用户随时随地掌控项目开销。</p><h2>灵活收费模式</h2><p>无论小企业还是大型公司，都能在 Zoho Projects 找到适合预算的订阅模式，降低技术门槛，提升工具性价比。</p><p>项目成本管理是企业经营和个人项目管理中不可或缺的环节。通过掌握核心内容、关注关键事项，并借助像 Zoho Projects 这样的实用工具，我们能够更好地管理项目成本，提高项目成功率，实现资源的高效利用。</p>]]></description></item><item>    <title><![CDATA[如何使用GitHub Pages托管博客]]></title>    <link>https://segmentfault.com/a/1190000047438319</link>    <guid>https://segmentfault.com/a/1190000047438319</guid>    <pubDate>2025-11-29 21:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h3>配置自定义域名</h3><ul><li>如果没有GitHub账户，请先<a href="https://link.segmentfault.com/?enc=Zp2H19BxeIshhZfIUvzl2w%3D%3D.0zBdD8u7I0UhA1YSAJ5OSdwRwhx4qPQEA0uO93U4JXE%3D" rel="nofollow" target="_blank">注册账户</a>，账户为<code>username</code></li><li>如果已有GitHub账户，但是想修改账户名 或 修改域名，点击“Settings”（设置）&gt;&gt;&gt; 点击“Account”（账户）&gt;&gt;&gt; Change username</li></ul><p>新建仓库 New repository. 创建新的 <code>username</code>.github.io 仓库</p><h3>创建gh-pages</h3><p>新建仓库后，会有一个main分支，此时我们需要再创建一个分支<code>gh-pages</code>（或者自己喜欢的分支名字，）</p><ul><li>如果是基于刚新建完成仓库建立的<code>gh-pages</code>里面是无文件纯净的</li><li>如果是基于推送代码建立的<code>gh-pages</code>是有文件的，如果你想保持一个干净的仓库需要把他们删了</li></ul><h3>设置博客使用分支</h3><ul><li>进入新的 <code>username.github.io</code> 仓库</li><li>选择 “Settings”</li><li>选择 “Branch” 中新建的分支，如gh-pages</li></ul><h3>创建一个博客文件，如blog，并关联此项目</h3><pre><code class="bash">git init
git add .
git commit -m "first commit"
git remote add origin https://github.com/newusername/newusername.github.io.git
git push -u origin main</code></pre><h3>把blog项目打包出dist文件，并推送到gh-pages分支</h3><p>如果<code>gh-pages</code>分支有问题可先删除再创建，删除命令</p><pre><code class="bash">git push origin --delete gh-pages  # 删除远程分支
git branch -D gh-pages             # 删除本地分支</code></pre><p>基于当前分支的dist文件创建<code>gh-pages</code>分支</p><pre><code class="bash">git subtree split --prefix dist -b gh-pages
git push origin gh-pages</code></pre><p>把dist文件推送到main分支后，再把dist推送到gh-pages</p><pre><code class="bash">git subtree push --prefix dist origin gh-pages  # 无冲突
git push origin `git subtree split --prefix dist main`:gh-pages --force  # 有冲突</code></pre><h3>访问路径</h3><p><code>https://username.github.io/</code></p><h2>创建子项目博客</h2><ol><li>新建仓库 New repository. 创建新的 <code>任意仓库</code>，但不能是 <code>username</code>.github.io 仓库</li><li>其他步骤同上</li><li>访问路径：<code>https://username.github.io/任意仓库名/</code></li></ol>]]></description></item><item>    <title><![CDATA[拒绝 Token 焦虑：我在 Spec ]]></title>    <link>https://segmentfault.com/a/1190000047438255</link>    <guid>https://segmentfault.com/a/1190000047438255</guid>    <pubDate>2025-11-29 20:01:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>引言：AI 很好用，但 Token 真的很贵</h2><p>在 AI 辅助编程（如 Spec Kit）日益普及的今天，我们往往会陷入一种两难：既想让 AI 帮我们干完所有脏活累活，又看着后台飞速消耗的 Token 感到肉疼。</p><p>尤其是在处理复杂需求时，随着对话轮数的增加，上下文（Context Window）会变得极长。这不仅意味着 <strong>Token 消耗呈指数级增长</strong>，更糟糕的是，上下文越长，AI 的“注意力”越分散，越容易出现遗忘前文或产生幻觉的情况。</p><p>经过最近一个项目的实战（NATS 消息订阅模块开发），我总结了一套<strong>“Spec Kit 降本增效指南”</strong>。</p><p>我的核心观点是：<strong>“省 Token”不仅仅是为了省钱，更是为了让 AI 保持清醒，输出高质量代码。</strong> 下面分享我总结的 3 个实战技巧。</p><hr/><h2>技巧一：预处理（Pre-processing）—— 借力打力，用廉价算力换高质量输入</h2><p>很多人习惯把 Spec Kit 的输入框当成草稿纸，把脑子里零碎的想法一股脑倒进去，然后让它慢慢整理。这是最奢侈的用法。</p><p><strong>“抠门”技巧：</strong><br/>在正式启动 Spec Kit 之前，先利用其他更便宜甚至免费的 AI 模型（如 ChatGPT-4o mini、Gemini Flash 或 DeepSeek）进行“预处理”。</p><p><strong>操作步骤：</strong></p><ol><li><strong>头脑风暴</strong>：对着 ChatGPT 把你想做的功能语无伦次地讲一遍。</li><li><strong>清洗提炼</strong>：要求它：“请帮我梳理上述需求，生成一段简洁、结构化、覆盖核心功能点且无歧义的 Prompt，供 AI 编程工具使用。”</li><li><strong>复制粘贴</strong>：把这段清洗过的“黄金 Prompt”投喂给 Spec Kit。</li></ol><p><strong>收益：</strong><br/>Spec Kit 的上下文极其昂贵。通过“借力打力”，我们避免了在 Spec Kit 内部进行低效的需求拉扯。<strong>Garbage In, Garbage Out</strong>（垃圾进，垃圾出）在 AI 时代依然适用，但 <strong>Gold In, Diamond Out</strong> 才是我们的追求。</p><hr/><h2>技巧二：批处理（Batching）—— 拒绝“挤牙膏”式对话，一次性把话说明白</h2><p>这是我在 <code>Clarify</code>（澄清）阶段发现的最痛的领悟。</p><p><strong>传统做法的弊端：</strong><br/>通常 AI 会问一个问题 Q1，你回答 A1；它再根据你的回答想出 Q2，你再回 A2……每一轮对话，系统都会把之前的整个历史（History）重新打包发送一遍。对于长上下文模型来说，这简直是在“烧钱”。</p><p><strong>“抠门”技巧：</strong><br/>强制 AI <strong>“一次性输出所有问题”</strong>，你也 <strong>“一次性回答所有问题”</strong>。</p><p><strong>如何操作：</strong><br/>在执行 <code>Clarify</code> 步骤时，明确提示 AI：</p><blockquote>“请分析当前需求，列出<strong>所有</strong>需要澄清的问题，并提供选项。请一次性列出，不要分批提问。我会以 'Q1: A, Q2: B' 的格式一次性作答。”</blockquote><p><strong>实战案例（NATS 消息订阅功能）：</strong><br/>我是这样要求 AI 的，结果它一次性输出了非常清晰的结构：</p><blockquote><p><strong>所有澄清问题</strong></p><p><strong>Q1: 消息订阅者的作用域缩减</strong><br/>确认: 当前功能仅包含订阅 NATS 消息、解析入库、更新会话？账号创建由其他接口负责？</p><ul><li>Option A: 是，仅做消息入库和会话更新...</li><li>Option B: 消息入库时若 sender 不存在，创建最小记录...</li></ul><p><strong>Q2: 消息引用不存在的 sender/session 时的处理</strong></p><ul><li>Option A: 跳过该消息，记录警告日志</li><li>Option B: 存储消息，ID 设为 null...</li><li>Option C: 消息入队等待，直到相关实体被其他接口创建</li></ul><p><strong>Q3: NATS 主题配置方式</strong></p><ul><li>Option A: 固定主题名</li><li>Option B: 配置文件配置</li></ul><p><strong>Q4: 消息处理的并发模式</strong><br/>...</p><p><strong>Q5: wx\_message 表中 sender\_id 的存储方式</strong><br/>...</p></blockquote><p>而我的回复极其简洁，极大地节省了 Token：</p><pre><code class="text">Q1: A, Q2: C, Q3: cc.callback.demo, Q4: 消息只需要订阅, Q5: B</code></pre><p><strong>进阶技巧：纠错也要“批发”</strong><br/>同理，在生成 <code>specify.md</code> 文档后，如果你发现有 3 处逻辑错误，千万不要分 3 次指正。在本地记事本里列好 1、2、3 点，然后一条消息发过去：“请一次性修正以下所有问题……”。</p><hr/><h2>技巧三：分治法（Divide and Conquer）—— 实现阶段的“外科手术”</h2><p>到了最后的 <code>Task</code> 和 <code>Implement</code> 阶段，如果任务过于庞大，AI 往往会生成一半就中断（Output Token Limit），或者后面生成的代码逻辑混乱。</p><p><strong>“抠门”技巧：</strong><br/>不要试图一口气吃成胖子。将 Implementation 阶段人为拆解为两步走。</p><p><strong>操作步骤：</strong></p><p><strong>第一步：搭骨架（Infrastructure First）</strong></p><ul><li><strong>指令</strong>：“请先仅执行与‘基础设施’相关的 Tasks。包括：1. 创建数据库表结构 (DDL)；2. 搭建项目目录结构；3. 编写基础配置类和实体类。<strong>暂不要实现具体的业务逻辑。</strong>”</li><li><strong>收益</strong>：这部分代码相对固定，AI 极少出错。先生成这一步，你可以快速 Review 表结构是否正确。如果表设计错了，重试的成本很低。</li></ul><p><strong>第二步：填血肉（Business Logic Second）</strong></p><ul><li><strong>指令</strong>：“基础结构已确认。现在请基于已有的实体类和表结构，实现剩余的业务逻辑 Tasks（如 NATS 监听器逻辑、Service 层处理流程）。”</li><li><strong>收益</strong>：此时 AI 已经有了正确的“上下文”（即第一步生成的代码），它写出来的业务逻辑会非常精准，且因为单次输出量减少，极大降低了幻觉概率。</li></ul><hr/><h2>总结</h2><p>使用 Spec Kit 这类工具，本质上是在考验我们的<strong>结构化思维</strong>。</p><ol><li><strong>预处理</strong>：用低成本模型清洗杂质，保证<strong>输入纯净</strong>。</li><li><strong>批处理</strong>：合并交互轮次，保证<strong>链路极简</strong>。</li><li><strong>分治法</strong>：拆解复杂任务，保证<strong>产出可控</strong>。</li></ol><p>当你学会像“审计员”一样去管理 AI 的 Context，你会发现，你不仅省下了一大笔 Token 费用，更重要的是，AI 变得更聪明、更懂你了。</p><p>本文由<a href="https://link.segmentfault.com/?enc=%2B0BTaVULqZogSeWGAqao4Q%3D%3D.l5GtYFKiQhsvoIgFksc2LX4Ul5RLUWIEh8zoi5cUFTo%3D" rel="nofollow" target="_blank">mdnice</a>多平台发布</p>]]></description></item><item>    <title><![CDATA[【技术分享】用python开发采集软件，]]></title>    <link>https://segmentfault.com/a/1190000047437778</link>    <guid>https://segmentfault.com/a/1190000047437778</guid>    <pubDate>2025-11-29 18:03:14</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <blockquote>今天给大家分享一款我用Python开发的实用工具——【爬微博搜索软件】，专为需要批量获取微博内容的用户打造，解决了常规采集的诸多痛点。</blockquote><h2>一、工具开发背景与核心优势</h2><h3>1.1 开发初衷</h3><p>微博作为国内顶流社交媒体平台，以实时性强、热点传播快、KOL影响力大著称。无论是热点事件追踪、行业动态分析，还是用户舆论调研，微博上的海量文字、图片内容都极具参考价值。但实际操作中，大家常会遇到采集页数受限、多关键词切换繁琐、数据易丢失等问题。基于这些需求，我开发了这款采集工具，旨在提供更高效、稳定的内容获取方案。</p><h3>1.2 界面展示</h3><p>工具界面简洁直观，无需复杂操作，上手即用：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047437781" alt="图片" title="图片"/><br/>软件界面</p><h3>1.3 结果预览</h3><p>采集数据全面且结构化，包含11个核心字段，方便后续分析使用：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047437782" alt="图片" title="图片" loading="lazy"/><br/>采集结果.csv核心字段包括：关键词、页码、微博ID、微博链接、用户昵称、用户主页链接、发布时间、转发数、评论数、点赞数、微博内容。</p><h3>1.4 演示视频</h3><p>工具运行全程可视化，具体操作流程可查看演示视频，直观了解采集全流程。原文有。</p><h3>1.5 重要说明</h3><ul><li>支持Windows系统直接双击启动，无需安装Python运行环境，操作门槛低。经多次测试，工具运行稳定，可持续采集不中断。</li><li>需提前在cookie.txt文件中填写个人微博cookie（内附详细获取教程），便于重复使用。</li><li>支持多关键词并行采集，关键词之间用|分隔即可。</li><li>可自定义采集时间范围，格式统一为YYYY-MM-DD，精准锁定目标内容。</li><li>采集过程中按页保存CSV文件，每1-2秒自动存储一次，避免异常中断导致数据丢失。</li><li>生成专属log日志文件，详细记录运行状态，方便问题回溯与排查。</li><li>工具持续迭代更新，后续将不断优化功能体验。</li></ul><h2>二、核心开发技术栈</h2><h3>2.1 整体框架</h3><p>工具整体基于Python语言开发，各模块分工明确：</p><pre><code class="python">tkinter：搭建简洁易用的GUI操作界面
requests：处理网络爬虫请求，确保数据获取稳定
BeautifulSoup：解析响应数据，精准提取核心信息
pandas：负责CSV文件保存与数据清洗，保证数据规范性
logging：实现运行日志记录，便于问题定位</code></pre><p>注：出于版权保护，暂不公开源码，仅提供工具使用权限。</p><h3>2.2 部分源码</h3><p>1、向页面发送请求和解析数据部分：</p><pre><code class="python"># 发送请求
r = requests.get(url, headers=h1, params=params)
# 解析数据
soup = BS(r.text, 'html.parser')</code></pre><p>2、保存数据部分：</p><pre><code class="python"># 保存数据
df = pd.DataFrame(
    {
        '关键词': kw,
        '页码': page,
        '微博id': id_list,
        '微博链接': wb_url_list,
        '用户昵称': name_list,
        '用户主页链接': user_link_list,
        '发布时间': create_time_list,
        '转发数': repost_count_list,
        '评论数': comment_count_list,
        '点赞数': like_count_list,
        '微博内容': text_list,
    }
)
if os.path.exists(self.result_file):  # 如果文件存在，不再设置表头
    header = False
else:  # 否则，设置csv文件表头
    header = True
# 保存csv文件
df.to_csv(self.result_file, mode='a+', index=False, header=header, encoding='utf_8_sig')
self.tk_show('结果保存成功:{}'.format(self.result_file))</code></pre><p>3、日志部分：</p><pre><code class="python">def get_logger(self):
    self.logger = logging.getLogger(__name__)
    # 日志格式
    formatter = '[%(asctime)s-%(filename)s][%(funcName)s-%(lineno)d]--%(message)s'
    # 日志级别
    self.logger.setLevel(logging.DEBUG)
    # 控制台日志
    sh = logging.StreamHandler()
    log_formatter = logging.Formatter(formatter, datefmt='%Y-%m-%d %H:%M:%S')
    # info日志文件名
    info_file_name = time.strftime("%Y-%m-%d") + '.log'
    # 将其保存到特定目录
    case_dir = r'./logs/'
    info_handler = TimedRotatingFileHandler(filename=case_dir + info_file_name,
                                            when='MIDNIGHT',
                                            interval=1,
                                            backupCount=7,
                                            encoding='utf-8')
    self.logger.addHandler(sh)
    sh.setFormatter(log_formatter)
    self.logger.addHandler(info_handler)
    info_handler.setFormatter(log_formatter)
    return self.logger</code></pre><h2>三、详细操作指南</h2><h3>3.1 准备工作：</h3><p>获取并填写cookie打开PC端微博，进入搜索页面并完成登录。按教程打开浏览器开发者工具，找到对应Cookie信息并复制。 <br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047437783" alt="图片" title="图片" loading="lazy"/><br/>CK获取方法将复制的Cookie值粘贴到工具文件夹中的cookie.txt文件内，保存即可。</p><h3>3.2 账号登录流程</h3><p>打开工具后，进入登录界面，输入账号密码完成验证，即可启动采集功能。</p><h3>3.3 开始采集</h3><p>操作在工具界面填写核心采集条件：  <br/>搜索关键词：多个关键词用|分隔（示例：小米SU7|蔚来ES6|理想L6）<br/>日期范围：填写格式为YYYY-MM-DD，设定采集的时间区间<br/>采集最大页：建议单关键词单时间段不超过50页，</p><p>保障采集稳定性点击”开始执行”按钮，工具将自动启动采集任务。<br/>采集过程中请勿直接打开CSV文件，可复制副本查看实时数据，避免采集中断。 <img width="723" height="571" referrerpolicy="no-referrer" src="/img/bVdncTB" alt="image.png" title="image.png" loading="lazy"/></p><h2>四、使用相关说明</h2><p>本工具仅用于合法的信息收集与研究用途，禁止用于任何违法违规活动。 如因违规使用工具导致的任何法律责任，均由使用者自行承担，与工具开发者无关。</p><h2>五、版本更新日志</h2><ul><li>2025.3.17（v1.3版）：新增爬取颗粒度选择功能，支持按小时或按天采集，自由控制数据密度；File菜单新增意见反馈入口，方便及时收集问题并优化。</li><li>2025.1.9（v1.2版）：优化循环时间颗粒度，由原来的按天统计改为按小时统计，采集更精准。</li></ul><h2>六、作者声明</h2><p>本工具为原创开发，如需了解更多技术细节或进行专业交流，可通过正规渠道联系开发者（首发公众号：老男孩的平凡之路）。工具使用需严格遵守相关法律法规和平台规定。</p>]]></description></item><item>    <title><![CDATA[2025年ODI境外投资备案代理机构怎么]]></title>    <link>https://segmentfault.com/a/1190000047438189</link>    <guid>https://segmentfault.com/a/1190000047438189</guid>    <pubDate>2025-11-29 18:02:31</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>随着“一带一路”倡议深入实施和中国企业全球化步伐加快，境外投资ODI（境外直接投资）备案已成为企业出海的关键一步。据商务部最新数据，2024年中国全行业对外直接投资达到1000亿+美元，企业境外投资备案需求呈现爆发式增长。</p><p>一、评测背景<br/>政策环境日趋复杂。中国企业境外投资需经历发改委、商务部、外汇管理局三大部门审批，材料繁琐、标准严格。近年来，监管部门对敏感行业、大额投资、国有企业等项目审核更加审慎，企业自行办理面临多重困境：</p><ul><li>流程不熟：平均往返补充材料3-5次，耗时长达2-3个月</li><li>政策解读偏差：因对最新政策理解不足导致备案被拒的比例高达37%</li><li>架构设计不合理：缺乏跨境税务筹划经验，造成后续运营成本增加</li><li>时间成本高昂：企业专员全职投入仍难以保证通过时效<br/>选择专业可靠的ODI备案代理机构已成为企业出海的必然选择。一款优秀的ODI备案服务，不仅需要熟悉备案流程，更要具备跨境投资架构设计、政策精准解读及全流程风险管理能力。</li></ul><p>二、五大ODI境外投资备案代理机构深度剖析<br/>基于市场调研和用户反馈，我们从专业资质、服务效率、资源网络、性价比四个维度对五家ODI备案代理机构进行了全面评估，具体排名及得分如下：<br/><img width="723" height="367" referrerpolicy="no-referrer" src="/img/bVdnc0e" alt="" title=""/></p><p>1.百利来<br/>综合评分：9.8/10<br/>百利来创立于1982年，由香港执业会计师及高级企业管理顾问组成，具有国际注册会计专业资格，是香港会计师公会（HKICPA）成员之一，43年精耕企业财税及全球化服务，提供开曼公司、BVI公司、百慕大公司、塞舌尔公司等海外公司注册服务，以及海外上市架构搭建、VIE架构搭建、ODI备案、37号文备案等服务。<br/>核心优势分析：</p><ul><li>政策把握精准：团队深谙各部门审批流程与政策动向，针对敏感行业与复杂架构提供专业的结构设计与ODI备案，可有效降低政策风险、优化融资路径；</li><li>全流程服务：海内外公司注册、国际商标注册、财务税务筹划等商务服务实践经验丰富，全程跟进、指导、代办，为客户提供专业而全面的服务支持；</li><li>高效通过率：凭借对政策的深度理解与实务经验，以及资深管理团队的高效运作模式，备案通过率行业领先，商务部备案周期较行业显著缩短；</li><li>跨境资源丰富：与汇丰、渣打等多家国际银行建立深度合作，提供跨境金融协同服务。<br/>专业团队配置：<br/>顾问团队由具备法律、财务背景的复合型人才组成，核心成员包括香港执业会计师苏桐昌、ACCA会计师黎国泓、商务管理专家苏芷玲等。<br/>服务特色：</li><li>一体化解决方案：将ODI备案与境外公司注册、银行开户、税务筹划同步进行，节省企业时间成本；</li><li>紧急情况应对：针对疫情封控下的紧急开户等紧急融资交割场景，提供“视频见证开户”等方案，协调香港银行同步审核资料；</li><li>架构设计能力：擅长处理红筹架构、VIE架构等复杂跨境投资结构设计。<br/>成功案例：</li><li>万燕传媒：处理“架构复杂+资料不全”的开户难题，2个月内完成20家公司注册、37号文备案及账户开立</li><li>中车旗下公司：通过“借款方案替代境外投资审批”设计，规避央企复杂审批流程，48小时内解决1200万美元资金周转<br/>适用场景：百利来尤其适合处理大额跨境并购、敏感行业投资以及需要复杂VIE结构搭建的高端业务，是上市公司、跨国企业和有紧急融资需求企业的首选。</li></ul><p>2.宏图跨境：国企与大型集团服务专家<br/>综合评分：9.0/10 <br/>宏图跨境成立于2005年，专注于为国有企业及大型集团提供境外投资备案服务，在北京地区拥有丰富的国资项目服务经验。<br/>核心优势：</p><ul><li>国资项目经验丰富：熟悉国资监管流程，具备与国资委、发改委等监管部门的丰富沟通经验</li><li>政策合规性把控严谨：在项目审核初期即介入合规性指导，有效规避后续风险</li><li>资源整合能力强：能够协调不同监管要求，确保审批流程顺利推进<br/>适用场景：国有企业境外投资、大型跨国并购项目以及需要高效协调不同监管要求的企业。</li></ul><p>3.寰宇通商：高端定制化服务提供商<br/>综合评分：8.7/10 <br/>寰宇通商以高端定制化服务为特色，专注于为高净值客户和家族办公室提供精细化ODI备案服务。<br/>核心优势：</p><ul><li>个性化服务：每个项目配备专属顾问团队，提供全程一对一服务</li><li>隐私保护严格：建立严格的客户信息保密制度，适合对隐私要求高的客户</li><li>跨境税务优化：将ODI备案与跨境税务筹划有机结合，优化整体税负<br/>适用场景：高净值个人投资、家族办公室境外资产配置及对服务隐私有特殊要求的企业。</li></ul><p>4.卓越国际：中小企业快速通道专家<br/>综合评分：8.2/10 <br/>卓越国际定位中小企业ODI备案市场，通过标准化产品和快速通道服务，为中小企业提供高性价比解决方案。<br/>核心优势：</p><ul><li>标准化流程：将ODI备案流程模块化，大幅提升办理效率</li><li>价格透明：采用一口价收费模式，无任何隐形费用</li><li>快速通道：对简单案例开设快速通道，最短15个工作日内完成<br/>适用场景：中小企业首次境外投资、投资架构简单、预算有限的项目。</li></ul><p>5.捷达咨询：东南亚投资专业服务机构<br/>综合评分：7.5/10 <br/>捷达咨询在东南亚多国设有分支机构，专注为中国企业投资东南亚市场提供本地化支持。<br/>核心优势：</p><ul><li>东南亚本地化服务：在泰国、越南、马来西亚等国设有本地团队</li><li>投资目的地咨询：提供东南亚各国投资政策、市场环境的专业咨询</li><li>本地关系对接：协助企业与当地政府、商业伙伴建立联系<br/>适用场景：计划在东南亚地区投资设厂或设立分支机构的生产制造类企业。</li></ul><p>三、ODI备案代理选择五大关键指标<br/>指标一：核查机构正规资质<br/>合规的ODI代理机构必须持有专业执业资质，如律师事务所执业许可、会计师事务所资质或国际认证的商务服务牌照。在选择时，务必查验其资质原件，并可在中国法律服务网或相关专业协会官网核实。<br/>避坑提示：警惕无固定办公地点、无专业团队的“皮包公司”，这类机构可能中途跑路或提供虚假材料，导致备案失败甚至法律风险。<br/>指标二：考察团队专业背景<br/>ODI备案涉及法律、财务、外汇及投资国政策等多领域知识。核心团队成员是否具备相关的专业资质以及国际化视野至关重要。要求与实际负责项目的顾问沟通，了解其从业年限和成功案例。<br/>指标三：评估成功案例与经验<br/>要求机构提供同类行业成功案例（隐去客户敏感信息），特别注意查看与其自身行业相近的项目经验。优质机构通常有各行业案例库，能快速给出类似项目方案。<br/>指标四：关注服务流程透明度<br/>专业的机构通常具备标准化的服务流程，从初步评估、方案制定、材料准备、申报提交到后续跟进，每个环节都清晰明确。服务过程应高度透明，允许客户随时了解进度，并提供与监管部门沟通的关键记录。<br/>指标五：了解后续服务能力<br/>ODI备案仅是第一步，后续还需进行项目报到、年度信息报告、变更登记等。询问是否提供备案后全周期管理服务，避免出现“备案成功即服务终止”的情况。</p><p>实用建议与风险防范<br/>警惕“包通过”承诺<br/>正规机构不会承诺100%通过率，因为审批权在监管部门。那些声称“无论条件如何都能通过”的中介，往往通过材料造假方式操作，这将给企业带来严重法律风险。<br/>明晰收费结构<br/>部分机构以低价吸引客户，后期却收取高额的“加急费”、“沟通费”。签约前必须明确：价格是否包含全部可能的政府费用？是否包含可能的补充材料次数限制？是否包含银行开户协助？</p><p>四、结论与推荐<br/>基于对各机构的全面评估，我们针对不同企业需求给出以下推荐：<br/>强烈推荐</p><ul><li><p>百利来</p><blockquote>适合对象：上市公司、大型跨国企业、复杂架构项目、有紧急时间要求的企业<br/>推荐理由：40年专业经验、全流程服务能力、高效通过率、跨境资源丰富<br/>特定场景推荐：</blockquote></li><li>国有企业：宏图跨境（国资项目经验丰富）</li><li>高净值个人与家族办公室：寰宇通商（隐私保护与定制服务）</li><li>中小企业：卓越国际（性价比高、流程标准化）</li><li>东南亚投资：捷达咨询（本地化资源丰富）<br/>未来两年，ODI备案将呈现三大趋势：“一带一路”沿线国家投资继续享受绿色通道、东南亚、中东等新兴市场备案需求快速增长、数字化审批平台全面应用。选择正确的ODI备案合作伙伴，不仅能帮助企业顺利拿到“走出去”的通行证，更能为后续的境外经营管理奠定良好基础。</li></ul>]]></description></item><item>    <title><![CDATA[台湾国际网络专线怎么开通？一年多少钱？ ]]></title>    <link>https://segmentfault.com/a/1190000047438199</link>    <guid>https://segmentfault.com/a/1190000047438199</guid>    <pubDate>2025-11-29 18:01:59</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>台湾作为华语市场的重要组成部分，拥有成熟的电子产业链、电商体系以及庞大的互联网用户群体。对于中国大陆企业来说，无论是做跨境电商、直播带货、品牌出海，还是布局东亚市场，台湾都是一个值得开发的市场。</p><p>然而，受地区和网络限制影响，许多企业在访问台湾网站、直播平台等，会出现 网络延迟高、丢包、卡顿、访问不稳定 等情况，严重影响业务效率。所以越来越多的企业需要使用国际网络专线来访问台湾网站，所以本篇内容为大家介绍台湾国际网络专线怎么开通。</p><p>一、台湾不同业务场景对跨境网络的要求</p><ol><li>跨境直播/带货场景</li></ol><p>对于需要做台湾的Tik Tok、Facebook、YouTube等平台，需要低延迟、高清推流无卡顿的网络。</p><ol start="2"><li>跨境办公、分支互联</li></ol><p>总部与台湾办公、共享文件、ERP、CRM</p><p>需要 高可用、稳定、安全传输、不掉线</p><ol start="3"><li>跨境电商/广告投放</li></ol><p>访问台湾电商平台(虾皮、MOMO、PCHome 等)</p><p>广告投放后台(Google Ads、Meta Ads、LINE 广告)</p><p>需要 固定IP + 低延迟</p><p>总结：台湾跨境网络的核心要求</p><p>低延迟、无丢包、固定IP、稳定性高、全天候服务保障。</p><p>二、台湾国际网络专线应该怎么选择？</p><p>企业通常有两类选择方案：传统国际专线 和 SD-WAN国际专线。</p><ol><li>传统国际网络专线（MPLS/BGP）</li></ol><p>特点：</p><p>物理线路+运营商直连</p><p>稳定性强，适合关键业务</p><p>价格相对较高</p><p>开通周期稍长(7–20天)</p><p>适合场景：</p><p>金融、制造大型企业</p><p>大型跨国公司</p><p>台湾分公司与大陆总部互联</p><ol start="2"><li>SD-WAN 国际专线（OSDWAN）</li></ol><p>特点：</p><p>软件定义网络，自动选路</p><p>多线路叠加：BGP / IPLC / 云网 / 动态加速</p><p>价格更优惠</p><p>部署快、设备简单</p><p>优势（相较传统专线）：</p><p>优化跨境稳定性</p><p>自带 QoS、防抖动、防丢包</p><p>更适合直播、电商、跨境广告投放</p><p>支持台湾原生住宅 IP</p><p>适合行业：</p><p>跨境直播、电商、外贸办公、社媒运营等以及需要快速部署跨境网络的中小企业</p><p>三、台湾国际网络专线怎么开通？（以 OSDWAN 为例）</p><p>第一步：选择服务商（推荐 OSDWAN）</p><p>优势：</p><p>相较于传统的SD-WAN服务商，OSDWAN跨境网络专线也有极大突出优势：更好用、更高性价比、更安心。</p><p><img width="433" height="388" referrerpolicy="no-referrer" src="/img/bVdnc0o" alt="image.png" title="image.png"/></p><p>01、更好用：相比传统SD-WAN服务商只支持CPE设备，OSDWAN不仅支持多种型号的CPE设备，还支持经过安全认证的相应软件。支持Windows、Mac、iPhone、安卓、iPad，让您随时随地一键连接全球互联网。</p><p>02、更高性价比：相比传统SD-WAN服务商与运营商接近的高额网络费用，OSDWAN仅需一半不到的成本即可享受同等优质的网络线路。</p><p>03、更安心：相比传统SD-WAN服务商需要5-8个工作日按照工单解决客户问题，OSDWAN提供专属售后支持，配备专属售后顾问。同时还提供分流解锁，路由优化等服务。让您的业务安心出海。</p><p>OSDWAN 具备台湾多节点部署、7×24 小时支持、稳定的跨境专线，是目前许多跨境企业的常用选择。</p><p>第二步：准备开通所需资质</p><p>一般需要：</p><p>公司营业执照</p><p>使用场景(直播/办公/分支互联)</p><p>IP 使用需求(是否需要台湾固定IP)</p><p>带宽要求(10M / 20M / 50M / 100M)</p><p>第三步：开通流程（OSDWAN 示例）</p><p>需求评估(带宽/节点/用途)</p><p>测试节点(提供台湾测试线路，验证延迟与稳定性)</p><p>确定方案与报价</p><p>签约 &amp; 开通</p><p>设备调试（SD-WAN CPE）</p><p>登录连接就可以使用了</p><p>整个流程 最快可当天开通(SD-WAN)，传统专线约需 5–15 天。</p><p>四、台湾国际网络专线多少钱？（以 OSDWAN 为例）</p><p>OSDWAN提供灵活的计费模式，支持 按月、按年、带宽定制 多种方式。具体如下：</p><p>办公账号版：690元/年，适合外贸SOHO或小工作室使用</p><p>社媒运营套餐：1500元/年起：，TikTok运营、社媒矩阵、店铺运营</p><p>标准版：10000元/年，适合10人以内团队使用或普清TK直播</p><p>企业版：自定义，100+地区的线路和IP可选，自由组合配置</p><p><img width="723" height="339" referrerpolicy="no-referrer" src="/img/bVdm4sv" alt="image.png" title="image.png" loading="lazy"/></p><p>台湾市场潜力巨大，而跨境网络稳定性直接决定业务效果。从办公到跨境直播、电商运营、广告投放，都需要一条稳定可靠的 台湾国际网络专线。</p>]]></description></item><item>    <title><![CDATA[企业开通国际网络专线有什么要求？需要哪些]]></title>    <link>https://segmentfault.com/a/1190000047438204</link>    <guid>https://segmentfault.com/a/1190000047438204</guid>    <pubDate>2025-11-29 18:01:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>现在一条稳定、高速且合规的国际网络专线，已成为企业出海的关键基础设施，国际网络专线是企业与全球业务节点之间的高速、稳定、安全的专用网络连接通道。它通过点对点专用线路连接企业总部、分支机构与海外节点，相比普通互联网连接，能提供更高的可靠性、更低的延迟和更强的安全保障。那么企业怎么开通国际网络专线呢？需要哪些资质？</p><p>一、国际网络专线是什么？</p><p>国际网络专线主要有两种类型：传统专线(如IPLC、MPLS VPN)和新兴的SD-WAN专线。</p><p>传统国际专线：如IPLC(国际私有租赁线路)和MPLS VPN(多协议标签交换虚拟私有网络)，提供物理隔离的专用通道，不与其他用户共享带宽资源，稳定性极高、延迟极低，但成本较为高昂。</p><p>SD-WAN专线：软件定义广域网，不依赖单一物理线路，通过智能路由技术在多条网络链路中自动选择最优路径，当检测到网络拥塞时能在500毫秒内完成链路切换。它支持混合组网，能根据业务优先级动态分配带宽，显著提升网络利用率，从而大幅降低成本。</p><p>企业需要国际网络专线的核心价值在于：</p><p>合法合规，规避风险：中国《网络安全法》明确规定，企业需通过合规服务商申请跨境网络专线，私自搭建或使用非法VPN将面临法律风险。</p><p>保障业务稳定性与安全性：提供固定IP地址，避免跨境电商平台因IP变动触发封号风险;提供低延迟高稳定的网络环境，访问海外平台的速度较普通网络可提升70%以上。</p><p>数据安全升级：企业通过专线传输数据时可叠加加密技术，防止信息泄露。</p><p><img width="723" height="311" referrerpolicy="no-referrer" src="/img/bVdnc0s" alt="image.png" title="image.png"/></p><p>二、企业开通所需资质与条件</p><p>企业开通国际网络专线需满足以下基本条件和资质要求：</p><ol><li>企业基本资质证明</li></ol><p>营业执照信息：申请主体需为合法注册的企业，提供营业执照副本复印件并加盖公章。</p><p>法人实名信息：提供法人身份证原件及复印件。</p><ol start="2"><li>业务合规性要求</li></ol><p>公司业务合法合规：企业需证明其跨境业务符合中国及目标国家的法律法规。常见的合规出海类型包括：</p><p>B2B外贸：正常的跨国贸易业务</p><p>跨境电商：如亚马逊、eBay等平台店铺运营</p><p>软件出海：面向海外的软件服务与应用</p><p>跨国办公：海外分支机构与总部的协同办公</p><p>跨境业务证明：如海外分公司注册文件等。</p><p>除上述两项核心资质外，企业还需准备：</p><p>业务需求说明：详细说明使用场景(如跨境电商、跨境办公)、带宽需求、接入地点及覆盖国家。</p><p>根据《国际通信出入口局管理办法》，企业开通国际专线还需向工信部进行备案或申请相关许可证，确保跨境链路审批合规。这些手续通常由服务商协助完成。</p><p>三、如何选择合法合规的服务商</p><p>选择合规的服务商是企业开通国际专线的关键，以下是如何甄别优质服务商的要点：</p><p>服务商类型比较</p><p><img width="723" height="154" referrerpolicy="no-referrer" src="/img/bVdnc0t" alt="截屏2025-11-29 17.20.01.png" title="截屏2025-11-29 17.20.01.png" loading="lazy"/></p><p>四、选择服务商的五大关键因素</p><p>合规资质认证：核实服务商是否持有工信部颁发的《增值电信业务经营许可证》或国际电信业务经营许可，这是合法运营跨境业务的基本资质，比如明点跨境OSDWAN就是持证上岗的，通过工信部备案拥有合法资质的专业服务商。</p><p>节点覆盖与网络性能：考察服务商在全球POP节点(网络接入点)的数量和分布区域，确保覆盖企业的业务热点地区。同时关注网络性能指标，如延迟、丢包率等。</p><p>SLA服务等级协议：仔细查看SLA中对网络可用性(如99.9%)、延迟、丢包率、故障响应时间等的承诺，这是服务质量的保障。</p><p>安全防护能力：了解服务商的安全措施，如是否提供防火墙、DDoS防护、数据加密(如AES-256)等安全服务。</p><p>技术支持与响应：选择提供7×24小时技术支持的服务商，确认故障响应时间和恢复时效。</p><p>四、推荐在SaaS点评网排名第一的服务商：OSDWAN</p><p>在众多SD-WAN服务商中，OSDWAN(明点跨境)作为专注于跨境网络场景的服务商，展现出独特的优势和价值主张。</p><p>核心优势介绍：</p><p>1、合规性保障：OSDWAN使用三大运营商的国际网络专线，确保安全合规，企业出海合规是基础。</p><p>2、全球覆盖与高性能：在全球拥有50个数据中心节点，POP节点超过200个，为出海企业提供海外加速、SaaS加速、SD-WAN组网等服务。</p><p>3、技术实力卓越：通过SDWAN+硬件技术，结合运营商海底光缆专线，给企业提供安全、合规、可靠的网络整体解决方案。</p><p>4、性价比高：对比传统电信运营商，OSDWAN可帮助企业降低50%以上的网络成本。其入门版价格690元/年起，美区网络专线低至200元/M/月起，性价比高。</p><p>5、灵活部署与简易运维：同时提供SD-WAN盒子与手机/电脑APP，支持硬件+软件多终端灵活部署。无需复杂配置操作，一分钟即可安装使用，大幅降低企业IT管理负担。</p><p>适用场景</p><p>OSDWAN特别适用于以下业务场景：外贸办公、跨境电商、TK直播、AI大模型、学术科研、社媒运营等。其纯净住宅IP资源覆盖全球100+地区，纯净独享，可用于TK直播等对IP质量要求高的业务。</p><p>五、国际网络专线常见问题解答</p><p>问：开通国际网络专线需要多长时间？</p><p>答：开通时间因服务商和方案类型而异。传统MPLS专线部署周期通常需要1-3个月，而SD-WAN专线部署速度较快，OSDWAN甚至可做到当日开通，一分钟连接使用。</p><p>问：SD-WAN与传统VPN有何本质区别？</p><p>答：SD-WAN是一个完整的网络架构，而VPN仅是一种加密技术。SD-WAN同时整合MPLS、宽带、4G/5G等多种链路，并基于应用智能选路;VPN则完全依赖公共互联网，稳定性和性能无法保障。更重要的是，企业私自搭建跨境VPN存在法律风险，而合规的SD-WAN方案通过在中国境内的合规POP点与三大运营商合作，实现合法合规的跨境网络优化。</p><p>问：如何控制国际网络专线的成本？</p><p>答：可通过以下几种方式控制成本：</p><p>按需选择带宽，避免过度配置</p><p>选择支持按需付费或灵活计费的服务商</p><p>采用SD-WAN技术，通过混合组网降低专线依赖度，平均可降低30%-50%成本</p><p>问：企业开通国际专线最需要关注哪些合规风险？</p><p>答：需要重点关注以下合规风险：</p><p>服务商是否具备国际运营资质，遵守《国际通信管理条例》</p><p>数据跨境传输需符合《数据安全法》及目标国法律(如欧盟GDPR)</p><p>避免使用”免费VPN”，没有资质的服务商可能通过非法跨境转发数据，导致企业被处罚</p><p>在国际业务拓展中，选择合规可靠的国际网络专线不再是简单的技术决策，而是关乎企业全球化战略成败的关键因素。从资质准备、服务商选择到方案实施，确保每个环节的合法合规性，才能让企业的国际业务行稳致远。建议企业在正式采购前，向服务商申请免费测试，在真实业务场景中验证网络性能。</p>]]></description></item><item>    <title><![CDATA[Pion 创始人聊 WebRTC、AI、]]></title>    <link>https://segmentfault.com/a/1190000047438144</link>    <guid>https://segmentfault.com/a/1190000047438144</guid>    <pubDate>2025-11-29 17:03:55</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438146" alt="" title=""/></p><blockquote>深入理解 WebRTC 后，你会欣赏那些最初让你沮丧的设计。——Sean DuBois</blockquote><p>Pion 作为 WebRTC 开源领域的新兴力量，凭借其 Go 语言实现、高性能和可扩展性，迅速获得广泛关注，并成为众多第三方项目的基础架构。开发者可以利用 Pion 轻松构建高效且可定制的 WebRTC 解决方案，满足从数据通道通信、音视频流媒体到复杂应用场景的需求。</p><p>Pion 的创建者 Sean DuBois 在 Go 语言和 WebRTC 领域贡献卓越，同时为 PHP 和 GStreamer 提供了重要支持。他不仅是 WebRTC 权威指南 《WebRTC For The Curious》的作者，还建立了一个充满活力的 Pion 社区。</p><p>2024 年 9 月，Sean DuBois 加入 OpenAI 团队，继续在音视频通信领域深耕，主要负责 Realtime API 相关的工作。</p><p>近期，Sean DuBois 在一期播客中探讨了 WebRTC、WebSockets、SIP 等技术的应用与未来发展趋势，涵盖了从底层协议到实际应用场景的方方面面。他们不仅分享了各自对技术细节的独到见解，还展望了 AI 时代音视频通信的新可能性。</p><p>我们摘录了部分精彩内容，希望能给大家提供一些新视野。Enjoy\~</p><h3>核心要点</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438147" alt="" title="" loading="lazy"/></p><p><strong>Sean DuBois</strong></p><p>Pion 开源 WebRTC 项目创始人</p><p>目前在 OpenAI 工作</p><ul><li><strong>WebRTC 的吸引力：</strong> WebRTC 的魔力在于它只需要少量代码即可「连接世界」，简化了实时通信的复杂性。</li><li><strong>WebRTC vs. WebSockets 的权衡：</strong> WebRTC 包含了回声消除、编解码器管理和码率控制等关键组件，而 WebSockets 需要开发者自己构建这些，WebRTC 适用于复杂的、面向终端用户的应用。</li><li><strong>WHIP 协议的简化：</strong> WHIP 通过 HTTP 协议简化 WebRTC，便于集成到 FFmpeg 和 OBS 等工具中，支持嵌入式设备和更广泛的互操作性。</li><li><strong>WebRTC 的延迟挑战：</strong> WebRTC 的主要贡献者对延迟需求不同的边缘用例关注不足，延迟控制是一个挑战。</li><li><strong>QUIC 作为 WebRTC 的潜在竞争者：</strong> QUIC 和 Media over QUIC 被视为超越 WebRTC、支持更多用例和提高灵活性的潜在方法，尤其是在语音 AI 领域。</li><li><strong>WebRTC 的隐藏用例：</strong> 除了会议，WebRTC 还有许多被低估的用例，例如远程监考和在线拍卖，这些用例对延迟有极高的要求。</li><li><strong>SIP 在 AI 时代的复兴：</strong> 电话技术，尤其是 SIP，在垂直领域 AI 应用中看到了新的增长，因为它无需应用安装，方便用户使用。</li></ul><h2>WebRTC and AI in 2025</h2><p>嘉宾：Sean DuBois，Pion 开源 WebRTC 项目创始人兼《WebRTC For The Curious》作者，目前在 OpenAI 工作</p><blockquote>注：为便于阅读，本文内容已作精简，并非完整对话。你可以访问原文收听完整版播客。</blockquote><h2>「在各种与 WebRTC 相关的项目中转悠，我很喜欢」</h2><p><strong>主持人：</strong> 你是 WebRTC 社区的坚定支持者，一位杰出的程序员。你编写了很多代码，很多人都在使用，包括所有使用 OpenAI 产品的人。先向大家介绍一下你自己吧。</p><p><strong>Sean：</strong> 好的。我最初接触的是 WebRTC 和电话技术，比如 Asterisk 之类的。后来，我想做更多服务器端的东西，所以做了 Pion，它是 WebRTC 的 Go 语言实现。我希望它更灵活，可以用一些奇特的方式工作。</p><p>之后，我一直在不同的 WebRTC 公司工作，包括为 AWS 做 C 语言嵌入式开发，还参与了 WebRTC FaceTime 和 Twitch 的广播相关工作。</p><p><strong>现在我在 OpenAI 做 Realtime API 相关的工作</strong>，包括 1-800-CHAT-GPT 和嵌入式应用。总之，一直在各种与 WebRTC 相关的项目中转悠，我很喜欢。</p><h2>WebRTC 的魔力：只需少量代码即可连接世界</h2><p><strong>主持人：</strong> 我们是否应该简单介绍一下 WebSockets、WebRTC 和 SIP？SIP 对很多应用场景来说非常重要，因为它是底层电话通信的粘合剂。我经常告诉别人，WebRTC 擅长某些方面，WebSockets 擅长某些方面，你需要对 SIP 有一些了解。我们都不太喜欢给别人建议，更倾向于提供一些技术定义。你很早就开始接触 WebRTC，是什么吸引了你？</p><p><strong>Sean：</strong> 是的，我之前在 Etsy 工作，当时我们为各种视频产品支付了大量费用，仅仅是为了在电脑上与他人进行电话会议。当 WebRTC 出现时，它简直太神奇了，用很少的代码就可以连接两个端点。我当时写了一个小机器人，通过 IRC 发送 Offer 和 Answer。那一刻，我爱上了它。我已经做了很多年 RTP 和相关的东西，所以用起来很舒服。但 <strong>WebRTC 在浏览器中就能运行，无需插件，而且效果很好</strong>，这让我彻底着迷。从那时起，我就被它迷住了。</p><h2>当你深入理解 WebRTC 后，你会逐渐欣赏那些最初让你感到沮丧的设计</h2><p><strong>主持人：</strong> WebRTC 是一种内置于浏览器中的协议，现在在所有平台上都可用。<strong>它从一开始就被设计用于做极低延迟的音频和视频通信。</strong>OpenAI 最初发布了一个 API，就像很多人做的那样，用于实时的语音 AI，但只支持 WebSocket。现在你添加了 WebRTC，或者说已经添加了。你对这方面的工程规划是怎么考虑的？</p><p><strong>Sean：</strong> 对我来说，WebRTC 的吸引力在于两点。<strong>最明显的一点是它非常容易使用</strong>。你不需要了解音频采样率或编码器，带宽估计也是自动的，你只需要生成 Offer 和 Answer，然后就可以开始使用了。我认为这是最令人兴奋的部分。就像你从你的客户那里看到的那样，<strong>即使是不懂技术的人，也可以用它来构建非常酷的东西</strong>。这是我喜欢 WebRTC 的第一个原因。</p><p><strong>主持人：</strong> 但向人们解释清楚 WebRTC 还是有点复杂的，至少对我来说是这样。</p><p>如果你是一名程序员，并且编写了很多代码，那么你几乎肯定使用过 WebSockets。如果你想在服务器和应用之间建立一个长期的双向通信通道，你可能会默认选择 WebSockets。<strong>WebSockets 的 API 相当简单易用，而且支持广泛。</strong></p><p>但是，如果你最初选择了 WebSockets，<strong>你最终需要自己构建所有的组件</strong>，比如回声消除、编解码器管理、码率控制等等。而且，你没有足够的控制旋钮，<strong>无法构建一个在各种真实用户和网络条件下都能稳定运行的产品</strong>。</p><p>另一方面，WebRTC 理解起来要复杂一些，有很多移动部件，API 也没那么简单。虽然你在新的 OpenAI 产品中做得很棒，提供了非常清晰的 API，但总的来说，如果我向人们推荐 WebRTC，他们会感到有点不知所措。</p><p>但是，正如你刚才所说，<strong>所有你难以自己构建的东西都已经包含在 WebRTC 中了</strong>。所以我通常告诉别人，如果你只是在做实验，为自己构建一些东西，或者做服务器到服务器的应用，那么 WebSockets 就足够了。但是，<strong>如果你真的想构建一个通过互联网连接浏览器或移动应用的东西，考虑到终端用户互联网连接的各种不可预测性，那么你绝对应该花时间了解 WebRTC，并使用它。</strong> 否则，你最终会痛苦地发现你必须迁移到 WebRTC。</p><p><strong>Sean：</strong> 我觉得很遗憾，<strong>许多人创造了令人惊艳的技术成果，但在需要添加多个视频轨道时，问题便接踵而至</strong>。他们最初可能依赖于简单的 WebSocket 协议，仅支持单一视频缓冲区，而现在却不得不将其拆分，以支持多种语言、添加和删除轨道等复杂功能。此时，WebRTC 的复杂性开始展现其价值。这正是我创作《WebRTC for the Curious》的原因。我发现很多人初次接触 WebRTC 时备受挫折，因为它看似繁琐且令人望而却步。然而，<strong>当你深入理解它之后，你会逐渐欣赏那些最初让你感到沮丧的设计</strong>。</p><p>WebRTC 堪称一个伟大的折衷方案，<strong>它在满足各方需求之间取得了平衡，从而使开发者能够继续创新</strong>。人们利用 WebRTC 构建 VPN、安全摄像头和广播系统，应用广泛。尽管许多人对 WebRTC 略有不满，因为它的功能过于强大，但对于某些公司而言，WebRTC 的某些特性却是其生存的基石。</p><p>我个人认为我无法设计出一个比 WebRTC 更好的协议。它凝聚了多年实践经验的结晶，而非简单的「委员会设计」。很多人看到 WebRTC 的复杂性，就认为它是 2010 年代的委员会设计出的糟糕 API。但实际上，WebRTC 是建立在 2000 年代乃至 90 年代的技术基础之上的，它融合了长达 30 到 40 年的设计和考量。设计者们早已预见并解决了许多问题。<strong>我很难相信我能简单地敲出一个基于 WebSocket 的解决方案，就能与 WebRTC 在所有权衡中相媲美</strong>。</p><p><strong>主持人：</strong> 是的。你是想要 20 毫秒的开放帧时间，还是想要 40 毫秒的开放帧时间？诸如此类。</p><p><strong>Sean：</strong> 没错，还有 H.264 配置文件。我们还没有讨论你需要哪些扩展头来表示视频方向。这些问题没完没了。这就是为什么我喜欢待在这个领域里。</p><h2>WHIP 协议：简化 WebRTC，拥抱嵌入式与互操作性</h2><p><strong>主持人：</strong>我对 OpenAI API 中新的 WebRTC 设计持有一些怀疑态度。它构建在 WebRTC 协议栈的一些较新的扩展之上。你想谈谈 WHIP 以及你是如何考虑它的吗？</p><p><strong>Sean：</strong> 在传统的 WebRTC 架构中，Offer 和 Answer 作为信息块存在，<strong>协议本身并不限定其传输方式</strong>。例如，可以通过 WebSocket、Protobuf 或基于 IP 的 Avro 协议来传递这些信息，只要能成功完成传输即可。而新的 WHIP 标准则强制规定 Offer 和 Answer 的交换必须通过 HTTP 协议进行，并采用特定的 URL 格式，同时需要发送带有 Bearer 令牌的 HTTP 授权头部。<strong>实际上，WHIP 严格限制了 Offer 和 Answer 的交换方式。</strong></p><p>这种限制具有重要意义，因为对于像 FFmpeg 和 OBS 这样的工具，用户无法自定义编写代码，只能提供 URL 和输入字段。这正是 WHIP 诞生的原因。我观察到两点：首先，用户希望使用这些工具来访问实时 API，以便发送广播流和安全摄像头数据，而这些工具不支持代码编写。另一方面，WHIP 的设计灵感也来自嵌入式系统。我曾经参与过一个嵌入式项目，该项目使用了一个 WebRTC 服务器，需要两个对等连接和一个 WebSocket，这在微控制器上消耗了大量的资源。因此，<strong>在设计 OpenAI 的 API 时，我希望尽可能保持其简单性，以便支持各种轻量级的客户端</strong>。如果像智能门铃这样的设备，成本仅为 25 美元，却能够发送音频并连接到实时 API，我认为这将是非常有价值的。<strong>WHIP 的设计目标正是为了实现这两点：支持现有的工具，并保持客户端的轻量级。</strong></p><p>另一个让我感到兴奋的点是<strong>不需要使用 SDK</strong>。根据我使用 Pion 的经验，<strong>用户希望在各种不同的环境中使用 WebRTC</strong>。我非常喜欢看到人们使用 Elixir 和 GStreamer 来访问实时 API。如果我要求用户下载包含 500 行专有代码的 JS SDK，并将它移植到各种不同的平台，这无疑会带来巨大的麻烦。但是，如果我们将 API 设计得尽可能简单，用户就可以做更多有趣的事情。</p><p>最后，我非常期待<strong>供应商之间的互操作性</strong>。每个供应商都可以在某个特定领域发挥其优势。例如，可以将视频发送到某个特定供应商，然后供应商可以将视频发送到其他地方。<strong>每个参与者都专注于自己擅长的领域</strong>。如果我们拥有这些简单且标准化的协议，那么对构建者、开发者和用户来说都将是更有利的，因为他们可以轻松地发送和接收 WebRTC 数据，而不必被限制在某个特定供应商的生态系统中。</p><p><strong>主持人：</strong> 您提出的观点都非常有道理，我十分赞同。尤其是在 WebRTC 发展初期，缺乏供应商之间的互操作性是一个显著的问题。<strong>这主要是由于信令层协议的通用性不足，难以适应所有应用场景。</strong> 因此，WebRTC 标准并未对信令进行规定，导致每个开发者都需要从头开始构建信令机制，从而阻碍了不同 WebRTC 平台和工具之间的真正互操作。WHIP 标准在很大程度上解决了这个问题。</p><p>但我必须承认，<strong>SDK 对于封装复杂性至关重要。</strong> 例如，当 RTP 连接中断时，应如何处理？如果将这个问题抛给应用程序员，他们可能会难以找到正确的解决方案。类似的问题还有很多。</p><p><strong>构建一个相对完善的 SDK 是抽象出所有这些复杂问题的必要途径</strong>。然而，大型 SDK 也存在明显的缺点，例如无法在资源有限的嵌入式设备上运行。现在，您已经发布了嵌入式 C 代码，我非常期待能够让我的小型机器人完全支持 WebRTC。</p><p><strong>Sean：</strong> 是的，我认为这反映了我们解决问题思路上的差异。</p><p>您花了很多时间与那些不关心 WebRTC 细节的企业合作，当然这不是贬义。他们的目标是构建出色的产品，而没有精力深入研究技术细节。因此，您对如何构建 SDK 以及如何解决相关问题有着深刻的理解。</p><p>然而，就我而言，无论是通过 WebRTC for the Curious 还是 Pion 项目，<strong>我与用户的交流方式更多的是鼓励他们拥抱细节，并认为细节本身蕴含着价值</strong>。我认为这是我思考方式上的一个固有特点，它有利有弊。我不太愿意将细节从用户面前抽象出来，因为我相信每个人都具备理解这些细节的能力。<strong>我希望提供工具，但对于那些寻求「给我一个 SDK，因为我只想快速完成工作」的开发者，我很难完全理解他们的诉求。</strong> 我相信会有其他人构建出色的 SDK，并以合理的方式抽象出细节。您在 SDK 设计和相关思考方面比我更擅长。事实上，这多年来一直是我在设计产品时面临的一个长期问题。</p><h2>技术深度 vs.易用性，不同的设计哲学**</h2><p><strong>主持人：</strong> 哦，不，我认为这是一个很大的优势。围绕 Pion 构建的生态系统非常出色，正是因为您采取了这种方法，即 <strong>构建模块的粒度</strong> 对于希望构建应用的人来说非常有意义，他们不需要从头开始构建，而是可以采用一种合理的方式进行组装。Pion 实现的各个组件非常清晰，没有隐藏过多的细节，阅读这些代码是一种享受。这归功于您，因为您贡献了大量的代码，并且构建了一个拥有活跃互动的健康社区。我认为每个人都应该阅读《WebRTC for the Curious》。</p><p>有趣的是，根据我们的经验，一些最糟糕的客户，从他们遇到困难、占用大量支持时间以及难以扩展的角度来看，恰恰是那些决定调整所有可配置参数的工程团队。这是因为存在一条这样的曲线：你首先让一些东西能够正常工作，然后你就会想，我不喜欢 720p 视频，我想要 1080p 视频。我们现在有很多帮助文档，其中明确指出：「好的，这是缺点。你可以使用 1080p，你可以使用 4K。但是，以下情况将会发生。」</p><p>然而，有些工程师阅读了我们发送给他们的所有信息，却完全不相信这些警告。于是，他们为移动设备上的最终用户配置了 4K 视频。你会觉得不可思议，我们已经明确告知过这种配置行不通。它可能在你的 iPhone Pro 上，在你的光纤连接上运行良好，但对于你的用户来说，这种配置是不可行的，这里的「你的用户」是指超过 60% 的用户。当 40% 的用户遇到问题时，你就无法实现规模化扩展。所以，从我们所针对的不同人群的角度来看，确实存在着不同的需求和紧张关系，这非常有趣。</p><p><strong>Sean：</strong> 是的，我也很喜欢那些用户。我喜欢那些提出独特需求的人。如果有人要投资我所做的任何项目，我都会过度关注那些看似无法产生收益的长尾需求，因为我喜欢那些对新奇事物和细节感兴趣的人，这会让我感到兴奋。这非常有趣，我完全赞同。</p><p>不过，回到您之前提到的，我个人对 Pion 提供的基本构建块感到非常满意。然而，目前有很多服务器都是基于 Pion 构建的，我认为这在一定程度上表明，对于某些用户而言，Pion 仍然不够完善。但我实际上很喜欢这种情况，因为我真正乐于与之交流的人恰恰是那些构建服务器的人。我非常享受这种过程，我喜欢就此进行深入的探讨和交流。</p><p>我现在还在进行另一个名为 Broadcast Box 的项目，这是一个面向终端用户的服务器。每当有人来找我说，他们只是希望一切都能正常运行，甚至不理解背后的原理时，我都会感到有些失落。他们仅仅是希望屏幕上能够显示视频，一旦视频出现，他们就会立即离开。我认为，当大家共同参与构建某些事物时，会存在一种独特的美感，<strong>但当目标仅仅是「我只想让它工作」时，这种美感就会消失</strong>。但我想这只是一段无关紧要的题外话。总而言之，这就是我构建产品的方式，也导致了它们最终呈现出现在的形态。</p><h2>Broadcast Box：低成本、高互动、更安全的 WebRTC 广播的未来</h2><p><strong>主持人：</strong> 我认为人们会很想知道 BroadcastBox 的动机是什么。</p><p><strong>Sean：</strong>是的。Broadcast Box 实际上是用于将 WHIP 集成到 OBS 中的一个参考实现。WebRTC 广播让我感到兴奋的原因是，我感觉广播技术已经落后了大约 10 年，因为技术限制使得我们无法实现很多想法。</p><p>首先，运行广播服务的成本非常高昂。因此，很少有人会尝试这样做。但是，借助 WebRTC 和 Simulcast 技术，我们可以<strong>将编码过程放在客户端，从而大幅降低成本</strong>。其次，WebRTC 的延迟非常低。这意味着当您向观众进行广播时，能够建立一种更亲密的互动关系。您可以拥有一小群朋友，他们观看您的游戏并与您进行交流，而不是向一万名观众进行广播，仅仅是被动地与他们互动。我认为这是一种更好的社交体验。这正是让我感到如此兴奋的原因。</p><p>我也很喜欢 WebRTC 具备<strong>端到端加密的特性</strong>。我希望能够先于某些公司解决一个潜在的问题：我预计将来可能会有一些公司想出办法直接将广告插入到视频流中，从而实现广告的完全无法屏蔽。<strong>我想在他们之前，利用 WebRTC 和端到端加密技术，让内容创作者能够掌握自己的密钥，并将它们提供给观众，从而阻止中间人篡改视频。</strong> 我认为这种方法非常酷。</p><p>此外，<strong>移动性也是一个重要的优势</strong>。WebRTC 的设计允许我在手机上进行广播，并在蜂窝塔之间切换，以及在 Wi-Fi 和蜂窝网络之间无缝切换。这让我感到非常兴奋，因为如果人们能够获得更好的 IRL（In Real Life，现实生活）直播体验，那将会很棒。目前，要实现这一点非常困难。人们需要背着背包，使用故障转移机制，将 RTMP 数据发送到服务器，然后服务器负责确保连接的稳定性。<strong>如果他们只是使用一种没有硬连接的协议，所有这些问题都会迎刃而解</strong>。</p><p>因此，我总是鼓励大家，如果有人问我对广播的未来有什么看法，我希望它能够朝着这个方向发展。</p><h2>WebRTC 的多重挑战：延迟挑战、Google 主导与开源抉择</h2><p><strong>主持人：</strong> 关于这些协议的演变，您提出了一个非常有趣的观点。RTMP 仍然是 Twitch 和 YouTube Live 的标准，但它确实是一个非常古老的协议。它最初是 Macromedia Flash 的视频协议，然后在 JavaScript 出现之前，由于 Flash 曾经短暂地主宰了整个交互式网络，它得到了某种程度的半标准化。但是，Flash 后来被 Adobe 收购，并被整合到那个大型公司实体中。Macromedia 在某种程度上被放弃了。然后，史蒂夫·乔布斯从 Safari 中砍掉了 Flash。因此，这个孤立的协议从未真正得到标准化，也没有任何一方能够真正掌控它。所以，没有人能够对其进行演变。但是，即便已经过去了 20 年，它仍然内置于 OBS 中，并且是所有这些平台的默认设置。虽然它能够正常工作，但正如您所说，<strong>到了 2025 年，我们确实需要更好的替代方案</strong>。</p><p>WebRTC 正是其中的一部分。<strong>我们观察到使用 WebRTC 进行广播的客户所面临的挑战是，它的延迟太低了。</strong> 如果你使用 RTMP、HLS、DASH 或其他视频流协议，那么很难将延迟降低到 3 秒以下。如果你要做任何交互式的事情，这都显得太长了。WebRTC 在某种程度上是因为标准本身，但在某种程度上也是因为所有实现的编写方式，很难将延迟提高到 300 毫秒以上。<strong>这是一个巨大的差距：300 毫秒与 3 秒。</strong></p><p>有时候，你真正需要的可能是 800 毫秒的延迟，因为你可以通过更大的缓冲区来调整视频质量。如果你要做一些交互式的事情，但它实际上并不是实时的对话，那么 800 毫秒的延迟可能就足够了。但目前似乎并没有一种方法能够实现这个目标。您有没有考虑过 <strong>我们如何找到一个中间地带</strong> ？</p><p><strong>Sean：</strong> 至少对于 OBS 来说，我尽量保持 3 秒的缓冲大小。因此，接收方可以积极地请求重传这 3 秒的数据，并且服务器可以在这段时间内进行缓冲。但是，在浏览器中，没有 API 可以实现这一点。我不知道。我认为这正是长期以来困扰 WebRTC 的一个问题。WebRTC 的主要贡献者们主要通过会议协议来盈利。因此，如何说服他们去关注这些边缘用例呢？</p><p><strong>主持人：</strong> 我认为谷歌是 WebRTC 规范的主要仲裁者，这是一件好事，但有时也会令人沮丧。谷歌对 WebRTC 的这种仁慈的资助和控制是绝对关键的。我认为如果没有谷歌，WebRTC 就不会成为一种普遍存在的标准。有时你提交 PR 或错误报告，但当谷歌团队认为它们不够重要或不够有趣时，它们就永远不会被采纳。</p><p><strong>Sean：</strong> 是的，我也不知道哪种方式更好。我经常在开源项目中看到这个问题：是凭借企业赞助者的力量加速你的发展速度更好呢？还是独自前行，做出对每个人都更好的东西更好呢？我不知道。我在编程语言中也看到了这一点。 Rust 和其他一些语言有赞助者，因此它们的发展速度更快，但社区本身却不那么令人愉快。这是一个非常哲学的问题。太有趣了。</p><p>如果我的生活就是 WebRTC 和 Go，那么在某种意义上，我就拥有谷歌公司的一切。我编写的协议和我编写的语言都属于谷歌。我真的应该站出来说几句。谷歌愿意花 3.6 亿美元购买 GIF 是一笔疯狂的金额。所以，总之，WebRTC 的存在是因为谷歌购买了软件并将其开源。是的，我不知道。现在就是这样了。</p><h2>QUIC 与 Media over QUIC：WebRTC 的未来竞争者？</h2><p><strong>主持人：</strong> 你提出的观点非常重要。在我们的这个视频和网络黑客的小世界里，<strong>很多人都认为，超越 WebRTC、找到中间地带、支持更多用例、提高灵活性和创造性的方法是 QUIC 和 Media over QUIC</strong>。</p><p>我经常与那些正在研究如何构建语音 AI 产品的人进行对话。有时他们已经做了一些研究，然后他们会说：「我只是在等待 QUIC。」 我也经常和他们说，<strong>现在我们看到的语音 AI 和对话式多模态 AI 用例与会议用例非常不同</strong>，而会议用例是 WebRTC 的核心和灵魂。WebRTC 在很大程度上满足了这些用例的需求，但我一直在思考，<strong>我们可以重新构建哪些构建块，以便更高效、更灵活、更易于破解，更适合语音 AI 用例</strong>。</p><p>然后，当你将其扩展到「这实际上可能是一个向 Media over QUIC 过渡的催化剂」时，我真的认为，在几年内，我们可能会看到 QUIC 在这些新用例中的采用，而如果没有这些新用例，我们就不会走出那个困境。</p><p><strong>Sean：</strong> Media over QUIC 组织构成多元，包含诸多内容分发网络（CDN）和视频领域从业者。我很好奇最终会如何发展。借鉴以往经验，IETF 工作组虽曾解决诸多重要问题，但最终可能因标准过于复杂而难以实际应用，希望 QUIC 不会重蹈覆辙。</p><p>具体而言，视频内容若过度复杂化，或将导致用户出于效率或兼容性考虑，仍旧选择 WebRTC 等现有方案。 <strong>QUIC 协议的核心机制虽具优势，但与实时性需求存在一定差异。</strong> 因此，要实现真正可用的 Media over QUIC，仍需进行大量工作。我认为这是可能的。 我对标准委员会的部分工作表示赞赏，但也注意到其潜在的发展方向存在风险。CDN 服务商的需求合理且重要，但与实时应用的需求存在显著差异。若 Media over QUIC 的发展方向过度迎合 YouTube 或 Twitch 等大型平台的需求，可能无法满足新兴的对话式人工智能等实时应用场景。 <strong>因此，我期望业界对新兴对话式 AI 用例保持足够的热情，以平衡 CDN 需求对标准发展方向的影响。</strong></p><p>进一步的问题在于，新的方案是否能够满足所有基于 WebRTC 的现有应用场景，例如安全摄像头监控和远程监考等。特别是远程监考，我曾经在 AWS 工作时发现，这是一个规模庞大的业务。 很多人可能认为 WebRTC 主要用于会议，但远程考试的使用频率可能远超会议，因为它几乎时刻都在进行。远程监考需要监考人员观看考生的视频，并且通常需要同时开启多个摄像头，例如拍摄手部和房间环境。 总之，<strong>WebRTC 的实际应用范围可能远超我们的想象，甚至最活跃或最流行的用例可能正是我们习以为常却未曾注意到的领域。</strong></p><h2>意想不到的 WebRTC 用例：从远程监考到在线拍卖**</h2><p><strong>主持人：</strong> 有趣的是，远程监考是最早尝试引入 AI 技术的领域之一。与当前流行的生成式 AI 对话技术不同，他们主要利用计算机视觉算法、语音匹配算法、面部检测和视线跟踪等技术，来检测考生是否作弊。 远程监考本身就是一场猫鼠游戏，因为学生们会不断寻找新的作弊方法。这些公司告诉我，雇佣一名人工监考人员的成本很高，而运行 AI 算法的成本相对较低。 这种成本对比凸显了远程监考领域中 AI 应用的独特价值。</p><p>另一个令我印象深刻的用例是澳大利亚一家公司利用 WebRTC 进行牛的竞拍。他们对延迟的要求极为苛刻，必须达到 7 毫秒，因为任何视频流延迟都可能导致竞拍失败，从而造成损失。</p><p><strong>主持人：</strong> 是的。我们也有一个这样的客户。当时我就想，我不知道牛的拍卖风险这么高。</p><p><strong>Sean：</strong> 牛的拍卖风险很高，这取决于你竞拍的是什么。</p><h2>SIP 在 AI 时代的复兴</h2><p><strong>主持人：</strong> 这些应用场景非常有趣。我们应该简单谈论一下 SIP，因为我们观察到越来越多的客户认为垂直领域 AI 是真实存在的，例如为医疗机构提供电话接听服务。有很多客户正在从事这方面的工作，并且业务规模还在不断扩大。</p><p>我过去从未想过大型语言模型可以通过电话与人进行对话，并且对各方都有显著的价值。从传输方式的角度来看，<strong>我们目前看到电话技术比 WebRTC 有更多的增长</strong>。您是否也观察到了同样的趋势？ 您之前做过一些与 SIP 相关的工作，它是如何融入到这些场景中的？这对于您来说，是否有点像一次怀旧之旅？</p><p><strong>Sean：</strong> 是的，我之前为 1-800-CHAT-GPT 做过电话相关的工作。 这样做的一个好处是只需要维护一个代码库。因为它们都使用相同的底层协议，所以我能够轻松地将代码迁移到一个公共文件夹中，从而同时支持两种技术。</p><p>我对未来发展方向非常感兴趣。我们现在还在使用的电话技术，例如 SIP，最初是为了与传统电话线路通信而设计的。 但现在一切都已经是数字化的了。所以我们实际上在进行数字信号到模拟信号，再到数字信号的转换。 我认为这非常令人兴奋，因为它为那些不习惯安装应用程序的用户打开了所有这些 AI 体验的大门。这甚至不仅仅是习惯问题，安装和使用应用程序的成本也太高了。 尤其是在很多国家，用户需要为下载应用程序付费。期望用户支付几美元来下载一个几百兆字节的应用程序是不现实的。 直接拨打电话号码就能正常工作，这简直太棒了。</p><h2>AI 电话助手：用 LLM 打造私人秘书</h2><p><strong>主持人：</strong> 我也很喜欢电话互联。 我有一个待办事项机器人，它每天会在固定的时间打电话给我，以确保我按计划行事。它会询问我今天的优先级是什么，以及需要完成哪些任务。然后，我会告诉它我完成了什么，它会检查这些是否与我昨天告诉它的相符。 我喜欢自己构建这些工具，这样才能真正理解它们。 我发现电话通话是一件非常有用的事情。 我可以以不同的方式实现提醒功能，例如发送短信链接，或者使用原生移动应用播放声音并发出警报。<strong>但电话通话有着独特的吸引力，即使对于这种简单的使用场景也是如此</strong>。</p><p><strong>主持人：</strong> 我喜欢 POTS 首字母缩略词，它代表 Plain Old Telephone System。</p><p><strong>Sean：</strong> 没错。</p><p><strong>主持人：</strong> 这是一个很棒的经典缩略词。如果你试图弄清楚如何将 LLM 连接到电话，你还会经常听到 PSTN（Public Switched Telephone Network）这个缩略词。</p><p>现在越来越多的类似技术涌现出来。我现在的理解是，这有点像正则表达式刚出现的时候。早期，对于文本解析，人们总是争论是否应该手写解析器，还是应该编写一个复杂的正则表达式。 两种方式各有优缺点。</p><p>非常感谢你。和你聊天非常开心。</p><p><strong>Sean：</strong> 我也很开心。</p><p>原播客：<a href="https://link.segmentfault.com/?enc=BEwWsqoGBgXAaeJSSTl%2FFQ%3D%3D.yDRB1yccVjDu5krg7xo6bcFDEYzAXmXeMVyCPaAvHBWWZzLUNRM8D3S8iu4FP9Zo" rel="nofollow" target="_blank">https://www.youtube.com/watch?v=l_rTdVuA4Lw</a></p><p>编译：施苏娜、傅丰元</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438148" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047438149" alt="" title="" loading="lazy"/></p><p><a href="https://link.segmentfault.com/?enc=g5XsGF1CVjAJqwijJ79dMA%3D%3D.zwVSgBcr631rpCZ0AG9MzX4A7bOzXNwReDXoQYomXCs%3D" rel="nofollow" target="_blank">阅读更多 Voice Agent 学习笔记：了解最懂 AI 语音的头脑都在思考什么</a></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438150" alt="图片" title="图片" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[FFmpeg开发笔记（八十九）基于FFm]]></title>    <link>https://segmentfault.com/a/1190000047438166</link>    <guid>https://segmentfault.com/a/1190000047438166</guid>    <pubDate>2025-11-29 17:03:03</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>​随着推拉流技术的发展，现在网络直播应用很普及了，打开许多App都能看到各式各样的直播节目，包括抖音、快手、虎牙、斗鱼、B站、小红书、YY、映客等等。</p><p>有关视频推拉流的FFmpeg实现参见《FFmpeg开发实战：从零基础到短视频上线》一书的“10.2  FFmpeg推流和拉流”，使用FFmpeg结合专用的流媒体服务器，可以很方便地实现视频直播功能。不过常规的拉流操作仅能实现播放功能，未能实现存储功能。如果事后还想回看以前的直播视频，就得引入直播录制功能了。  <br/>StreamCap正是一个开源的国产直播流录制工具，它基于FFmpeg和StreamGet设计，覆盖40余个国内外主流直播平台，支持批量录制、循环监控、定时监控和自动转码等功能。StreamCap支持跨平台，能够在Windows/MacOS/Web上运行，并支持ts、flv、mkv、mov、mp4、mp3、m4a等常见格式，录制完成后会自动转码为mp4格式。  <br/>StreamCap的源码托管地址为 <a href="https://link.segmentfault.com/?enc=GzanViSklrYc%2Fxqn5jAeFg%3D%3D.eKOSJs9WbcS6SoNJ3xdLpNlp8p6SGwrHs4LGmvF8Xw5IjsHMqwKR23Bg2Ms9FNoU" rel="nofollow" target="_blank">https://github.com/ihmily/StreamCap</a> （星星数2.4k），国内的镜像地址为 <a href="https://link.segmentfault.com/?enc=c3YotTWskKoY5a2aTPVNhA%3D%3D.1J6qwulSriqSoe1VJ6zC4Hl%2FQIDgdgormiTknb6cm8gjYY2H0WQLyubgX%2BepSkJt" rel="nofollow" target="_blank">https://gitcode.com/gh_mirrors/st/StreamCap</a> 。最新版本是2025年8月发布的v1.0.2，可见该框架的源码更新十分及时，该版本的源码下载链接为 <a href="https://link.segmentfault.com/?enc=SG7YZr9Gwvr%2FOVvPsPFp9Q%3D%3D.3N5CKFpD5mtYR79RFpdlR%2Bm2TBK4UzpoCJns8pN7QbE%2FUKtLfxxmK9fQOw3osddgP%2BjyoA9SVgVO4OkKr6gdnCuu3uUhhDA9LZpQuHsdnYk%3D" rel="nofollow" target="_blank">https://github.com/ihmily/StreamCap/archive/refs/tags/v1.0.2.tar.gz</a> 。  <br/>StreamCap基于Python 3.10开发，从源代码运行的话，需要在源码目录运行下面命令安装依赖包：</p><pre><code># 安装核心依赖
pip install -i https://pypi.org/simple streamget 
# 桌面端
pip install -r requirements.txt
# Web端
pip install -r requirements-web.txt</code></pre><p>接着执行下面命令，将示例的配置文件.env.example复制一份，并将新文件重命名为.env：</p><pre><code>cp .env.example .env</code></pre><p>若在Windows和macOS运行上StreamCap，则通过以下命令启动程序界面：</p><pre><code>python main.py</code></pre><p>启动成功后打开的StreamCap初始界面如下图所示：</p><p><img width="723" height="476" referrerpolicy="no-referrer" src="/img/bVdm8GM" alt="" title=""/></p><p>单击界面右边的【开始录制】按钮，打开下图所示的配置界面：</p><p><img width="723" height="476" referrerpolicy="no-referrer" src="/img/bVdm8GN" alt="" title="" loading="lazy"/></p><p>在配置界面的直播间地址栏输入直播链接，然后单击右下角的【确定】按钮，跳到正在录制界面如下图所示：</p><p><img width="723" height="476" referrerpolicy="no-referrer" src="/img/bVdm8GO" alt="" title="" loading="lazy"/></p><p>正在录制界面实时提示当前录制进度，也支持停止录制，录制好的视频默认保存在StreamCap的downloads/Custom/CustomLive目录下。</p><p>单击StreamCap左上角的【设置】按钮，打开如下图所示的设置界面。</p><p><img width="723" height="476" referrerpolicy="no-referrer" src="/img/bVdm8GQ" alt="" title="" loading="lazy"/></p><p>在设置界面支持修改包含基础设置、代理设置在内的录制选项，也支持修改推送设置、Cookie设置、账号设置等配置信息，方便用户个性化定制直播录制信息。</p><p>更多详细的FFmpeg开发知识参见<a href="https://link.segmentfault.com/?enc=OeEroSY1WyLiERJFhaXHuA%3D%3D.VB48GxdEWusNXatlR%2FMnMGzooSCfBIxCLMd4%2FPqSMcA%2B0P4b5%2Flw4Ssaa6d6yimm" rel="nofollow" title="《FFmpeg开发实战：从零基础到短视频上线》" target="_blank">《FFmpeg开发实战：从零基础到短视频上线》</a>一书。</p><p>​</p>]]></description></item><item>    <title><![CDATA[2025年CSS新特性大盘点 沉浸式趣谈]]></title>    <link>https://segmentfault.com/a/1190000047438172</link>    <guid>https://segmentfault.com/a/1190000047438172</guid>    <pubDate>2025-11-29 17:02:21</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>大家好，我是 Immerse，一名独立开发者、内容创作者、AGI 实践者。</p><p>关注公众号：<a href="https://link.segmentfault.com/?enc=pW%2B1n2KcV1AYQDO3OKD2%2BA%3D%3D.MYDMXDl6IuBWsP9ErunIKby1MJJpzfvRQQbFDGsuWkWqXOKOubVBOjKFuQ2VUC3TZ9uacb5b%2FvnmSf%2FpHJo9sg%3D%3D" rel="nofollow" target="_blank">沉浸式趣谈</a>，获取最新文章（更多内容只在公众号更新）</p><p>个人网站：<a href="https://link.segmentfault.com/?enc=ha273OYTfjavWxkicsmNlA%3D%3D.SUpjim7T1CJ4%2FoMzBwAZXDXGE%2B7EEINZuKkMi%2BnsOtI%3D" rel="nofollow" target="_blank">https://yaolifeng.com</a> 也同步更新。</p><p>转载请在文章开头注明出处和版权信息。</p><p>我会在这里分享关于<code>编程</code>、<code>独立开发</code>、<code>AI干货</code>、<code>开源</code>、<code>个人思考</code>等内容。</p><p>如果本文对您有所帮助，欢迎动动小手指一键三连(<code>点赞</code>、<code>评论</code>、<code>转发</code>)，给我一些支持和鼓励，谢谢！</p><hr/><p>2025年了，CSS又进化了</p><p>去年写过一篇 CSS 新特性盘点，本来以为今年不会有太大变化。结果一看，新东西比去年还多。</p><p>这次整理了几个我觉得特别实用的功能，浏览器支持也都不错，可以用起来了。</p><h2>终于可以动画到 auto 了</h2><p>之前我们做高度展开动画，基本都是靠 max-height 硬撑。</p><p>比如从 0 展开到实际高度，只能写个超大的值，体验很差。</p><p>现在可以直接动画到 auto 了：</p><pre><code class="css">html {
  interpolate-size: allow-keywords;
}</code></pre><p>加上这一行，所有 height: 0 到 height: auto 的过渡都能生效。</p><p>或者你也可以用 calc-size() 函数，不需要全局设置：</p><pre><code class="css">.content {
  height: 3lh;
  overflow: hidden;
  transition: height 0.2s;

  &amp;.expanded {
    height: calc-size(auto, size);
  }
}</code></pre><p>这个功能总算来了。</p><p>而且不只是 height，任何接受尺寸的属性都能用，不只是 auto，min-content 这些关键字也行。</p><p>目前 Chrome 已经支持，其他浏览器应该也快了。</p><h2>Popover 和 Invoker</h2><p>Popover 是个 HTML 属性，给任意元素加上就有开关功能。</p><p>配合 Invoker 用起来更爽，不用写 JavaScript 就能控制弹窗。</p><pre><code class="html">&lt;button commandfor="menu" command="toggle"&gt;
  打开菜单
&lt;/button&gt;

&lt;div id="menu" popover&gt;
  菜单内容
&lt;/div&gt;</code></pre><p>这样就够了，按钮点击自动控制弹窗显示隐藏。</p><p>浏览器会自动处理无障碍访问、键盘操作、焦点管理这些细节。</p><p>而且还能配合 Anchor Positioning 用，让弹窗自动定位到触发元素旁边。</p><p>Popover 已经全浏览器支持，Invoker 目前只有 Chrome，不过有 polyfill 可以用。</p><h2>CSS 里可以写函数了</h2><p>CSS 有 calc()、clamp() 这些内置函数，现在我们可以自己写了：</p><pre><code class="css">@function --titleBuilder(--name) {
  result: var(--name) " is cool.";
}</code></pre><p>然后就能在任何地方调用：</p><pre><code class="css">.title::after {
  content: --titleBuilder("CSS");
}</code></pre><p>这个功能让 CSS 更像编程语言了。</p><p>把复杂逻辑封装到函数里，代码更清爽，也更好维护。</p><p>不过目前只有 Chrome 支持，可以先用着，不支持的浏览器会回退到默认值。</p><h2>if() 函数也来了</h2><p>CSS 本来就有很多条件逻辑，比如选择器匹配、媒体查询。</p><p>但这次的 if() 函数是第一个专门做条件分支的：</p><pre><code class="css">.grid {
  display: grid;
  grid-template-columns:
    if(
      media(max-width &gt; 300px): repeat(2, 1fr);
      media(max-width &gt; 600px): repeat(3, 1fr);
      media(max-width &gt; 900px): repeat(auto-fit, minmax(250px, 1fr));
      else: 1fr;
    );
}</code></pre><p>看起来像不像 switch 语句？第一个匹配的条件会生效。</p><p>条件可以是 media()、supports()、style() 这几种。</p><p>把所有逻辑都写在一个属性里，代码可读性好很多。</p><p>目前 Chrome 独占，其他浏览器还在路上。</p><h2>表单输入框自动调整大小</h2><p>field-sizing 这个属性专门解决表单输入框的问题。</p><pre><code class="css">textarea {
  field-sizing: content;
}</code></pre><p>加上这一行，textarea 会自动根据内容调整高度。</p><p>用户输入多少内容，输入框就有多高，不用手动拖拽了。</p><p>在手机上体验特别好，拖拽调整大小本来就很难操作。</p><p>这个功能之前都是用 JavaScript 实现，现在 CSS 原生支持了。</p><p>Chrome 和 Safari 都能用，Firefox 估计也快了。</p><h2>select 下拉框终于能自定义样式了</h2><p>select 元素的外观一直很难自定义，打开后显示的选项更是完全没法控制。</p><p>现在可以完全自定义了，只要先开启：</p><pre><code class="css">select,
::picker(select) {
  appearance: base-select;
}</code></pre><p>然后想怎么改就怎么改，选项的样式、布局、动画都能控制。</p><p>目前 Chrome 独占，不过不支持的浏览器会回退到原生样式，完全不影响使用。</p><h2>text-wrap 让排版更好看</h2><p>text-wrap: balance 可以让每行文字长度尽量接近：</p><pre><code class="css">h1 {
  text-wrap: balance;
}</code></pre><p>用在标题上效果特别好，不会出现最后一行只有一个词的情况。</p><p>还有个 text-wrap: pretty，专门优化正文排版：</p><pre><code class="css">p {
  text-wrap: pretty;
}</code></pre><p>浏览器会自动调整断行，避免孤词，让文字看起来更舒服。</p><p>balance 已经全浏览器支持，pretty 在 Chrome 和 Safari 能用。</p><p>这种优化对用户体验很重要，而且完全不影响功能，可以直接加上。</p><h2>linear() 实现复杂缓动效果</h2><p>CSS 的 linear 关键字之前就是匀速动画，很无聊。</p><p>但 linear() 函数可以实现超复杂的缓动，比如弹跳效果：</p><pre><code class="css">.bounce {
  animation-timing-function: linear(
    0, 0.004, 0.016, 0.035, 0.063, 0.098, 0.141 13.6%, 0.25, 0.391, 0.563, 0.765,
    1, 0.891 40.9%, 0.848, 0.813, 0.785, 0.766, 0.754, 0.75, 0.754, 0.766, 0.785,
    0.813, 0.848, 0.891 68.2%, 1 72.7%, 0.973, 0.953, 0.941, 0.938, 0.941, 0.953,
    0.973, 1, 0.988, 0.984, 0.988, 1
  );
}</code></pre><p>这种效果用 cubic-bezier() 根本做不出来。</p><p>而且已经全浏览器支持了，可以放心用。</p><p>有在线工具可以生成这些值，不用自己手写。</p><h2>shape() 函数画任意图形</h2><p>CSS 之前有 path() 函数，但语法很难写，而且只能用像素。</p><p>shape() 是专门为 CSS 设计的，支持所有单位和自定义属性：</p><pre><code class="css">.arrow {
  clip-path: shape(
    evenodd from 97.788201% 41.50201%,
    line by -30.839077% -41.50201%,
    curve by -10.419412% 0% with -2.841275% -3.823154% / -7.578137% -3.823154%,
    smooth by 0% 14.020119% with -2.841275% 10.196965%,
    close
  );
}</code></pre><p>可以用在 clip-path 裁剪元素，也能用在 offset-path 做路径动画。</p><p>而且可以响应式调整，配合媒体查询和容器查询都没问题。</p><p>Chrome 和 Safari 已经支持，Firefox 也在开发中。</p><h2>attr() 变强了</h2><p>之前 attr() 只能取字符串，现在可以指定类型了：</p><pre><code class="html">&lt;div data-count="42" data-color="#ff0000"&gt;</code></pre><pre><code class="css">div {
  --count: attr(data-count type(&lt;number&gt;));
  --color: attr(data-color type(&lt;color&gt;));
}</code></pre><p>这样可以直接把 HTML 属性当数字或颜色用，方便多了。</p><p>目前 Chrome 独占，不过对于不支持的浏览器，可以设置回退值。</p><h2>reading-flow 解决 Tab 顺序问题</h2><p>用 Grid 或 Flexbox 重新排列元素后，Tab 键的焦点顺序会乱。</p><p>现在可以用 reading-flow 告诉浏览器按照视觉顺序来：</p><pre><code class="css">.grid {
  reading-flow: grid-rows;
}</code></pre><p>这样焦点就会按照 Grid 的行顺序移动，不会乱跳了。</p><p>Flexbox 用 flex-flow，其他布局也有对应的值。</p><p>这个功能对无障碍访问很重要，不过目前只有 Chrome 支持。</p><p>等其他浏览器跟进之前，最好不要大量重排布局。</p><h2>值得期待的功能</h2><p>还有一些功能在开发中，但还没正式发布：</p><p>Masonry 布局虽然各浏览器实现不同，但在稳步推进。</p><p>Safari 的 random() 函数可以生成随机数，玩起来很有意思。</p><p>margin-trim 可以自动去掉容器边缘元素的外边距，Safari 独占中。</p><p>sibling-index() 和 sibling-count() 函数在 Chrome 能用，做交错动画很方便。</p><p>View Transitions 的 match-element 不用给每个元素起名字了，而且 Firefox 也在开发中。</p><p>还有很多其他功能在路上。</p><h2>别忘了这些已经能用的</h2><p>Container Queries 和 :has() 这些去年的新功能，现在已经全浏览器支持。</p><p>View Transitions、Anchor Positioning、Scroll-Driven Animations 也都在 Safari 上线了。</p><p>dvh 这些视口单位也成为标准了。</p><p>CSS 现在能做的事情越来越多，写起来也越来越顺手。</p><p>参考：<a href="https://link.segmentfault.com/?enc=U8uxykhSyqxL%2Bv%2FORDX%2BDA%3D%3D.TRjS5VkqqMHoIM%2BCIBPKshEXp94H9mctM8rT5%2FKp4srAPjIVSgi1tMIkJT8xva0KegHr5Y5eSFoxwke65pEl0L9Id2jHV4RkRBKNnwrJ6TOdba1%2FI9xUpMzGmoRYcn2j" rel="nofollow" target="_blank">https://frontendmasters.com/blog/what-you-need-to-know-about-...</a></p><h3>其他好文推荐</h3><p><a href="https://link.segmentfault.com/?enc=Sz%2F5MugKIiW1tXBkhCNqKg%3D%3D.OifliJhZuEnh17J6jR9LZL6gnXZkOTMVRk0RiU5Q6vxI3lV9OJ4HIbAAPegAKv7gfen3zgpbn%2BrlfHWFTfBZpg%3D%3D" rel="nofollow" target="_blank">2025 最新！独立开发者穷鬼套餐</a></p><p><a href="https://link.segmentfault.com/?enc=Z6JP9xpKfnKChd78nRpf5w%3D%3D.GDbLgR16s%2FK1JWC8O5NsijHO%2FEqmphhCd1BKaRSAdu%2FzfujCxHwRqB8MH5tKqRMI9D%2FotQeq49bB8149ym%2FjCQ%3D%3D" rel="nofollow" target="_blank">Windows 安装 Claude Code 的新姿势，保姆级教程</a></p><p><a href="https://link.segmentfault.com/?enc=%2F6OpqdhQRcZzFjUboem88g%3D%3D.zPdtIPBnZx%2B0ISF5M01GRGBZA%2Fc1DmMclNA3zXzZM3YtNx3wUbQl%2Fd%2BECnpcgqMKZGmDMN5o%2B%2FkOPpt2wPKASg%3D%3D" rel="nofollow" target="_blank">Claude Code 从入门到精通：最全配置指南和工具推荐</a></p><p><a href="https://link.segmentfault.com/?enc=WC%2FAc4wkU7HdZSohrF8vPA%3D%3D.zOV65klIqfSRzkmgXodyjiAFDDPUeHrG4kZ%2FC3PwrXZtvU6Jke5Ra765LwIPgfJ95Wc%2FiKAckQC3l3IxthFamw%3D%3D" rel="nofollow" target="_blank">Claude Code 终极配置指南：一行命令搞定各种配置</a></p><p><a href="https://link.segmentfault.com/?enc=jvdLVl%2FRc4WEmSzgzxVDsg%3D%3D.o%2FURb1zy3ehyM9ktKip%2FWCe6NhlHLjbVZ4NMdy6g5PfNhl5%2FORtSO6dJUiS0SiBpzVmrrXvEQ52NIsVy2Mmvdg%3D%3D" rel="nofollow" target="_blank">一个配置文件搞定！Claude Code 多模型智能切换</a></p><p><a href="https://link.segmentfault.com/?enc=LSBRIOmhZomSV42d3QOcSg%3D%3D.3II%2BDARgzWSCH0cF%2B08fP5JCTiy7ajipl6IYYpnMWnO%2Fq0Qp3k0o%2B3cFQAI%2BFGfGncEzXEb%2F%2BKiPNrVrBcjZdw%3D%3D" rel="nofollow" target="_blank">这个 361k Star 的项目，一定要收藏！</a></p><p><a href="https://link.segmentfault.com/?enc=L%2F0yaH64O0Scug64idDCmg%3D%3D.MYGjLgm%2BlJOjSfEHXNGf9JSdpyjliBaT6Uw6kUzpYwy3Tq4HQB9HscqpYdXg0ssTcRYVT7HLrvMCQWuoh3ONmw%3D%3D" rel="nofollow" target="_blank">搞定 XLSX 预览？别瞎找了，这几个库（尤其最后一个）真香！</a></p><p><a href="https://link.segmentfault.com/?enc=W5UwYW24TnASdJVeI1L0GA%3D%3D.iEhuwVZ%2FGxN6WSypdV0gEaa0rGT%2Fuhbk0qJRYmVOQZ%2BoqIpd0lZqrVCNIY3JMBM0NR6qYYIjrWr8knGuFr315g%3D%3D" rel="nofollow" target="_blank">【完整汇总】近 5 年 JavaScript 新特性完整总览</a></p><p><a href="https://link.segmentfault.com/?enc=eQac17uOWdz3lGkuqj4BsQ%3D%3D.qEF0vvUYc0jHfPUdhUCDcKL5sKBaSut6sKvEBfZMosnVp4xt0NMUKmZ5pdMUYoaabUfdySk%2FVXw%2BX%2FQeQ6QBug%3D%3D" rel="nofollow" target="_blank">关于 Node，一定要学这个 10+万 Star 项目！</a></p>]]></description></item><item>    <title><![CDATA[Nari Labs 更新 TTS 模型 ]]></title>    <link>https://segmentfault.com/a/1190000047438175</link>    <guid>https://segmentfault.com/a/1190000047438175</guid>    <pubDate>2025-11-29 17:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438177" alt="" title=""/></p><p>开发者朋友们大家好：</p><p>这里是 <strong>「RTE 开发者日报」</strong> ，每天和大家一起看新闻、聊八卦。我们的社区编辑团队会整理分享 RTE（Real-Time Engagement） 领域内「有话题的<strong>技术</strong>」、「有亮点的<strong>产品</strong>」、「有思考的<strong>文章</strong>」、「有态度的<strong>观点</strong>」、「有看点的<strong>活动</strong>」，但内容仅代表编辑的个人观点，欢迎大家留言、跟帖、讨论。</p><p><em>本期编辑：@鲍勃 @Gemini（即将带</em>👓<em>版）</em></p><h2>01有话题的技术</h2><p><strong>1、Nari Labs 发布 Dia2：流式对话式 TTS 模型，提供 1B 和 2B 参数版本</strong></p><p>Nari Labs 发布了名为「Dia2」的流式对话式文本到语音（TTS）模型，其核心亮点在于能够边接收输入边生成音频，实现实时、自然的语音交互。该模型目前提供 1B 和 2B 参数版本，旨在加速 TTS 领域的研究。</p><ul><li>流式生成： 「Dia2」模型无需等待完整文本输入即可开始生成音频，大大缩短了响应延迟，适用于实时对话场景。</li><li>条件生成： 支持通过音频输入进行条件生成，可以利用现有音频（如前段对话）来生成更符合上下文的语音，提升对话的自然度。</li><li>模型版本： 提供 1B 和 2B 参数两种模型检查点，满足不同性能和资源需求的研究场景。</li><li>易于集成： 提供快速上手指南（Quickstart）和 Gradio 应用，方便开发者快速部署和体验。</li></ul><p>目前，「Dia2」支持不超过 2 分钟的英文音频生成。Nari Labs 计划推出「Dia2 TTS Server」以支持真正的流式传输，并发布基于「Dia2」的语音到语音引擎「Sori」。</p><p><a href="https://link.segmentfault.com/?enc=ztwt1Qt%2FULAtMu1leDD7IQ%3D%3D.D%2BrsBQVtn9tLF67hbS0m5EOaZl1QVr1DzK60k5oK8gCA7zI8w2sutPTsnWySmqYE" rel="nofollow" target="_blank">https://huggingface.co/nari-labs/Dia2-2B</a></p><p>(@Huggingface)</p><p><strong>2、消息称谷歌重启 AI 眼镜：富士康代工、三星设计，最快明年四季度发布</strong></p><p>11 月 27 日消息，据报道，谷歌已于去年年底立项两个 AI 眼镜项目，目前两项目已经进入 POC（小批量试产）阶段，正在密集推进选型、ID 设计。知情人士透露，谷歌 AI 眼镜的硬件代工由富士康负责，参考设计由三星提供，而芯片则由高通供应。此外，谷歌近期还与包括歌尔在内的中国供应商进行了接触。</p><p>报道称，谷歌的 AI 眼镜预计最早将于 2026 年第四季度发布。在产品方面，该设备大概率将采用波导片光学方案，并配备摄像头。项目负责人之一是 Google Labs 的平台工程负责人 Michael Klug，他曾是明星创业公司 Magic Leap 的核心成员，在光场显示等领域拥有丰富经验。</p><p>据了解，谷歌是智能眼镜行业的先驱。早在 2012 年，谷歌创始人谢尔盖・布林通过一场跳伞直播演示，向全世界发布了 Google Glass，开启了可穿戴设备及增强现实概念的新篇章。然而，由于公众场合拍照引发的隐私问题，Google Glass 在 2015 年宣告关闭。2017 年以后，谷歌重新启动相关项目，策略也更加审慎。产品思路从炫技的概念机转变为解决实际问题的工具，商业化方向也从消费级市场转向企业级（toB）应用。</p><p>（@IT 之家）</p><p><strong>3、全国首例「医保价」脑机接口手术完成 置入费 6552 元/次</strong></p><p>11 月 27 日消息，据媒体综合报道，11 月 26 日，在华中科技大学同济医院神经外科，我国首例按照政府核定医疗服务价格项目执行的脑机接口手术顺利完成。</p><p>此次手术采用武汉衷华脑机融合科技发展有限公司生产的植入式脑机接口设备，可用于监测大脑手部运动和感觉区域的脑电信号。</p><p>值得一提的是，本次手术是我国首例按照政府核定医疗服务价格项目执行的脑机接口临床操作（即侵入式脑机接口置入费 6552 元/次，不含脑机接口设备等费用），标志着脑机接口技术从科研探索阶段正式进入医疗服务收费目录体系，在推动技术普惠化与产业化方面迈出重要一步。</p><p>今年 3 月 31 日，湖北省医保局率先发布全国首个脑机接口医疗服务价格，明确「侵入式脑机接口置入费」为 6552 元/次。这一开创性的政策，为脑机接口技术纳入规范化诊疗体系铺设了制度通道。</p><p>但从政策出台到临床落地仍需关键一跃。同济医院负责人表示，本次手术的费用虽然是由研究经费承担，无需患者自付费用，但这是全国率先将脑机接口手术纳入医院诊疗项目体系，并按照规范标准进行收费结算的临床实践。</p><p>（@快科技）</p><h2>02有亮点的产品</h2><p><strong>1、无问芯穹完成近 5 亿元 A+轮融资</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438178" alt="" title="" loading="lazy"/></p><p>近日，完成近 5 亿元 A+ 轮融资，本轮融资由珠海科技集团、孚腾资本（元创未来基金）领投，惠远资本、尚颀资本和弘晖基金跟投，老股东洪泰基金、达晨财智、尚势资本&amp;海棠基金、联想创投、君联资本、申万宏源、徐汇科创投、元智未来持续追投。此次融资阵容汇聚国家产业资本与头部市场化基金，「国资+市场」的双重认可，既肯定了公司面向国家重大战略需求的技术创新，也充分鼓励着无问芯穹，在人工智能产业落地及基础设施生态建设中持续夯实价值创造。</p><p>本轮募集资金将主要被投入三大方向：一是持续扩大无问芯穹软硬协同、多元异构的技术领先优势；二是推动 AI 云产品与 AI 终端方案在产业中的规模化拓展；三是加大智能体基础设施研发投入，构建一流的智能体服务平台及配套云、端基础设施，加速实现智能体在数字世界与物理世界中的规模化普惠应用。</p><p>（@无问芯穹）</p><p><strong>2、Klariqo AI Voice Assistants：面向中小企业，实现 3 分钟部署全天候智能客服</strong></p><p>Klariqo AI Voice Assistants 推出了一个「业务优先」的 AI 语音智能体平台，旨在革新中小企业和 SaaS 公司的客户支持体验。该平台通过提供无代码、3 分钟快速部署的全天候智能体，简化了传统 AI 工具的复杂性，有效解决企业电话和网站客服痛点，从而提升客户满意度和销售转化率。</p><ul><li>极简部署与无代码体验： Klariqo 宣称用户可在 3 分钟内完成设置，无需任何 API、webhook 或复杂开发知识，彻底降低了 AI 语音智能体的技术门槛，让非技术背景的企业主也能轻松上手。</li><li>全渠道 24/7 智能互动： 智能体能以自然语音和口音（如美式、澳式）全天候接听电话，并同步处理网站聊天，确保客户的咨询总能得到及时响应，告别传统枯燥的文本聊天机器人。</li><li>内置业务管理功能： 集成「日历」和「潜在客户管理」功能，智能体能自动预订预约、捕获潜在客户信息，并回答常见问题，帮助企业在非工作时间也能持续运营和销售。</li><li>智能体与人工无缝协作： Klariqo 提供按需转接人工客服的功能，以应对复杂查询或客户明确要求，实现了自动化与个性化服务之间的灵活切换。</li><li>深度数据洞察： 平台允许用户追踪通话记录、阅读对话记录，并分析用户情绪，为企业提供宝贵的数据支持，以便持续优化客户服务策略。</li></ul><p>(@Product Hunt)</p><p><strong>3、Quo （原 OpenPhone） 融资 1.05 亿美元，提供中小企业客服</strong></p><p>原「OpenPhone」公司现已更名为「Quo」，并宣布获得包括 General Catalyst 在内的现有投资者 1.05 亿美元（9600 万美元增长投资 + 900 万美元股权）融资。此次融资将加速其 AI 驱动的商业电话解决方案的产品创新和市场扩张，标志着公司进入高速增长新阶段。</p><ul><li>品牌重塑与融资： OpenPhone 正式更名为 Quo，并获得 1.05 亿美元融资，将重点投入到 AI 功能的研发和市场拓展上。</li><li>AI 驱动的「智能体」Sona： Quo 推出的 AI 电话「智能体」Sona 现已对所有客户免费开放，并升级了转接和更智能的场景处理能力，已处理超过 200,000 通电话，显著提升了中小企业的客户沟通效率。</li><li>中小企业市场聚焦： Quo 致力于为占美国和加拿大公司总数近 99% 的中小企业提供先进的通讯解决方案，帮助它们在 AI 时代更好地服务客户，缩小与大型企业的技术差距。</li><li>产品创新与定价模型： 新的定价模型采用分级、按使用量付费，并增加了多级电话菜单和临时呼叫流程等功能，以满足不同规模企业的灵活需求。</li><li>用户增长显著： 过去六个月，Quo 吸引了超过 30,000 家新客户，总用户数接近 90,000 家，并在 G2 平台上获得 #1 的客户满意度评级。</li></ul><p>(@Quo)</p><hr/><h2>03有态度的观点</h2><p><strong>1、 Cognitive Resonance 创始人：AI 并不能思考</strong></p><p>Cognitive Resonance 创始人 Benjamin Riley 认为 AI 并不能思考。</p><p>今天的 AI 热是基于一个根本性的误解：语言的建模并不等同于智能。根据目前的神经学，人类的思维在很大程度上独立于人类语言，几乎没有理由相信，越来越复杂的语言建模能达到甚至超越人类水平的智能。</p><p>人类用语言交流，用语言创造比喻去描述推理过程。失去语言能力的人仍然能展示出推理能力。当人类对现有的比喻不满时他们能创造出新的知识。爱因斯坦的相对论不是基于科学研究。他是在思想实验的基础上发展起来的，因为他不满足于当时的比喻。常识不过是一堆死气沉沉的比喻，而 AI 只会以有趣的方式重新排列旧的比喻，AI 永远不会对现有的数据或比喻感到不满。AI 基于的大语言模型使用的数据收集自互联网。互联网上使用的语言并不能代表现实世界上的语言。比如因纽特人的语言使用的比喻在欧洲语言中找不到。而如果互联网上没有这些比喻，那么 AI 也不可能创造出来。这并不意味着 AI 毫无用处。但它与人类智能相去甚远。</p><p>（@Solidot）</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438179" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438180" alt="" title="" loading="lazy"/></p><p><strong>写在最后：</strong></p><p>我们欢迎更多的小伙伴参与 <strong>「RTE 开发者日报」</strong> 内容的共创，感兴趣的朋友请通过开发者社区或公众号留言联系，记得报暗号「共创」。</p><p>对于任何反馈（包括但不限于内容上、形式上）我们不胜感激、并有小惊喜回馈，例如你希望从日报中看到哪些内容；自己推荐的信源、项目、话题、活动等；或者列举几个你喜欢看、平时常看的内容渠道；内容排版或呈现形式上有哪些可以改进的地方等。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047438181" alt="" title="" loading="lazy"/></p><p>作者提示：个人观点，仅供参考</p>]]></description></item><item>    <title><![CDATA[Dify+DeepSeek实战教程：从零]]></title>    <link>https://segmentfault.com/a/1190000047438102</link>    <guid>https://segmentfault.com/a/1190000047438102</guid>    <pubDate>2025-11-29 16:02:43</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在AI技术席卷全球的2025年，企业开发者正面临一个关键命题：如何用最低成本实现AI能力的高效落地？本文将以Dify（开源AI应用开发平台）与DeepSeek-R1（国产高性能大模型）为核心工具，通过知识库构建、智能客服、代码生成、合同审核四大实战场景，手把手教你搭建企业级AI应用流水线。</p><p>一、技术选型：为什么选择Dify+DeepSeek？</p><ol><li>黄金组合的核心优势<br/>Dify：开源低代码平台，支持可视化编排工作流、管理多模型、集成知识库，覆盖AI应用全生命周期。<br/>DeepSeek-R1：国产开源大模型，支持128K上下文窗口，在数学推理、代码生成、长文本理解等场景表现卓越，训练成本仅为行业标杆的1/30。<br/>协同效应：Dify的拖拽式工作流引擎与DeepSeek的强推理能力结合，可快速实现复杂业务逻辑的AI化。</li><li>典型应用场景<br/>知识管理：构建企业私有知识库，实现文档智能检索与问答。<br/>智能客服：自动处理用户咨询，支持多轮对话与上下文理解。<br/>代码生成：根据自然语言需求生成可运行的代码片段。<br/>合同审核：自动识别合同风险条款，生成审计报告。</li></ol><p>二、环境部署：30分钟搭建开发基础</p><ol><li>硬件与软件要求<br/>硬件：NVIDIA RTX 3090+/A100显卡，64GB+内存，1TB+存储。<br/>软件：Docker 20.10+、Python 3.10+、CUDA 12.0。</li><li><p>部署步骤<br/>步骤1：安装Dify<br/>bash</p><h2>克隆Dify仓库</h2><p>git clone <a href="https://link.segmentfault.com/?enc=qRFoU9IBeBYNUn1q9BElbw%3D%3D.EnDYJxM5Q8nljkDAskuENUgrr%2BlXAi7nZly4B2UF2ZgQYOK3ZJqk8kb7H0Lvmwi2" rel="nofollow" target="_blank">https://github.com/langgenius/dify.git</a><br/>cd dify/docker</p></li></ol><h2>复制环境配置文件</h2><p>cp .env.example .env</p><h2>启动Docker容器（V2版本）</h2><p>docker compose up -d<br/>访问 <a href="https://link.segmentfault.com/?enc=yYcw5oHXpe6qrhrSP1Ud%2FA%3D%3D.%2BdNBi5lQ5iD%2FlRFuhFkEPDndTCMM9a8QoJWvx8CnUts%3D" rel="nofollow" target="_blank">http://localhost:8000</a>，完成注册后登录控制台。</p><p>步骤2：部署DeepSeek-R1<br/>通过Ollama本地化部署（避免依赖云端API）：</p><p>bash</p><h2>安装Ollama（Linux示例）</h2><p>curl -fsSL <a href="https://link.segmentfault.com/?enc=rTYEBMWEZajJjnbc212dcA%3D%3D.1Z1ZEtGKX1RjKbCLBVnMK9ZwLC1Q0eeuDTiCaKK1fcM%3D" rel="nofollow" target="_blank">https://ollama.ai/install.sh</a> | bash</p><h2>下载DeepSeek-R1模型（7B基础版）</h2><p>ollama run deepseek-r1:7b</p><p>步骤3：Dify集成DeepSeek<br/>在Dify控制台进入「模型管理」，添加自定义LLM API。<br/>填写模型地址（如 <a href="https://link.segmentfault.com/?enc=uqW8BRJq4jNBtD9VxmngIg%3D%3D.ZGrLfAEz5FMo%2FoOaOpAOvlHzUJYUjG0ct6pDoZbu%2BzfP666TOgsgJrQKf%2BA4u%2BUV" rel="nofollow" target="_blank">http://host.docker.internal:11434/api/generate</a>）与请求体模板：<br/>json<br/>{<br/>  "model": "deepseek-r1:7b-chat",<br/>  "prompt": "{{sys.prompt}}",<br/>  "temperature": 0.6,<br/>  "max_tokens": 2048<br/>}<br/>点击「测试连接」，输入技术文本（如“解释Transformer架构的注意力机制”），验证模型输出。</p><p>三、实战案例：四大场景深度解析<br/>案例1：企业知识库构建<br/>目标：将产品手册、培训文档等结构化/非结构化数据转化为可检索的AI知识库。<br/>步骤1：上传文档<br/>在Dify控制台创建知识库，选择「导入本地文件」，上传PDF/DOCX/TXT等格式文档。<br/>配置分段策略：<br/>分段模式：父子分段（父区块保留段落，子区块按句子拆分）。<br/>相似度阈值：0.7（提高检索精度）。<br/>Embedding模型：选择 bge-m3（支持中英文混合向量化）。<br/>步骤2：配置检索逻辑<br/>在应用上下文中添加知识库，设置提示词：<br/>请根据以下文档内容回答用户问题，若信息不足可回复“未知”：<br/>{{#context#}}<br/>启用Rerank模型（如 BAAI/rerank-base），对检索结果二次排序。<br/>效果验证<br/>测试问题：“如何重置产品A的管理员密码？”<br/>预期输出：直接返回文档中相关步骤，而非整篇手册。</p><p>案例2：智能客服机器人<br/>目标：自动处理用户咨询，支持多轮对话与工单流转。<br/>步骤1：设计工作流<br/>创建新应用，选择「Agent类型」。<br/>添加以下节点：<br/>LLM节点：调用DeepSeek-R1，设置提示词：<br/>你是一名客服助手，请用友好语气回答用户关于{{product}}的问题：<br/>{{user_input}}<br/>Webhook节点：将用户咨询记录同步至CRM系统。<br/>条件判断节点：若问题未解决，触发工单创建流程。</p><p>步骤2：测试与优化<br/>测试用例：用户询问“订单发货延迟怎么办？”<br/>优化方向：<br/>增加意图识别模块，自动分类问题类型。<br/>对高频问题配置快捷回复模板。</p><p>案例3：代码自动生成<br/>目标：根据自然语言需求生成可运行的代码片段。<br/>步骤1：配置工作流<br/>创建新应用，选择「工作流类型」。<br/>添加以下节点：<br/>输入节点：接收用户需求（如“生成一个Python爬虫，抓取知乎热榜”）。<br/>LLM节点：调用DeepSeek-Coder（代码生成专用模型），设置提示词：<br/>生成一个{{language}}脚本，要求：</p><ol><li>功能：{{requirement}}</li><li>包含异常处理</li><li>输出格式：{{output_format}}<br/>代码检查节点：通过SonarQube扫描代码质量。</li></ol><p>步骤2：生成结果示例<br/>输入：“用Java实现一个快速排序算法。”<br/>输出：<br/>java<br/>public class QuickSort {</p><pre><code>public static void quickSort(int[] arr, int low, int high) {
    if (low &lt; high) {
        int pi = partition(arr, low, high);
        quickSort(arr, low, pi - 1);
        quickSort(arr, pi + 1, high);
    }
}
// 其余代码...</code></pre><p>}</p><p>案例4：合同风险审核<br/>目标：自动识别合同中的风险条款，生成审计报告。<br/>步骤1：数据预处理<br/>通过RPA机器人从ERP系统同步合同文档。<br/>使用OCR模型（如PaddleOCR）提取扫描件文本。</p><p>步骤2：构建审核工作流<br/>LLM节点：调用DeepSeek-Fin（金融领域微调版），设置提示词：<br/>分析以下合同条款，识别风险点并分类（如“付款延迟”“违约责任模糊”）：<br/>{{contract_text}}<br/>数据分析节点：将风险条款与历史数据对比，计算风险评分。<br/>报告生成节点：输出包含风险热力图的三维审计报告。<br/>效果数据<br/>某银行应用案例：<br/>审核耗时从4小时/份缩短至20分钟。<br/>风险发现率从71%提升至94%。</p><p>四、性能优化：从基准到极致</p><ol><li>响应延迟优化<br/>优化策略    原始延迟    优化后延迟    成本变化<br/>模型量化（FP16→INT8）    2.3s    0.9s    -30%<br/>请求批处理（batch_size=32）    2.3s    0.6s    +15%<br/>Dify缓存机制    2.3s    0.4s    -40%</li><li>并发能力扩展<br/>MCP自动扩缩容：根据负载动态调整GPU实例数量（如从1个T4扩展至5个）。<br/>K8s水平扩缩容：应对突发流量（如促销活动期间）。</li></ol><p>五、企业级落地指南</p><ol><li>安全加固方案<br/>传输加密：HTTPS+JWT令牌验证。<br/>审计日志：记录所有API调用与模型决策路径。<br/>权限控制：RBAC模型分级授权（如仅审计员可访问合同审核模块）。</li><li>灾备与扩展<br/>跨区域部署：在AWS北京区与宁夏区同时部署服务，通过DNS负载均衡实现故障转移。<br/>多模型AB测试：同时运行DeepSeek-R1与Claude 3.5，根据业务场景动态切换。</li></ol><p>六、未来展望：AI应用的新范式<br/>随着多模态大模型与具身智能技术的发展，Dify+DeepSeek的组合将延伸至物理世界交互领域：<br/>智能工厂：通过Dify编排工作流，统一调度RPA机器人、AGV物流车与质检机械臂。<br/>智慧医疗：结合医学影像大模型，实现“感知-决策-执行”一体化的手术辅助系统。<br/>立即行动：访问 Dify GitHub仓库 获取完整代码，或通过 DeepSeek官方文档 下载模型。技术变革的浪潮已至，这一次，别再做旁观者！</p>]]></description></item><item>    <title><![CDATA[嵌软与RTOS精要 星星上的柳树 ]]></title>    <link>https://segmentfault.com/a/1190000047438108</link>    <guid>https://segmentfault.com/a/1190000047438108</guid>    <pubDate>2025-11-29 16:01:54</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>嵌入式软件与实时操作系统（RTOS）是现代IC系统不可或缺的核心部分。无论是驱动层、API设计，还是实时调度，它们都直接影响IC的性能、可靠性和使用体验。如果你渴望系统提升技术深度，不妨在 EDA Academy 探索丰富的网课资源，一起驱动你的专业成长。</p><p>1、嵌入式软件开发：模块+仿真高效并行<br/><img width="723" height="388" referrerpolicy="no-referrer" src="/img/bVdncYT" alt="" title=""/><br/>嵌入式软件是硬件运行的“大脑”，从简单控制到复杂处理，都离不开它。<br/>模块化编程：将系统拆分成可复用模块，便于维护与扩展。<br/>仿真与原型验证：借助 FPGA 等平台进行软件原型开发，既能模拟真实情境，又能快速调试和迭代。某工程团队通过 FPGA 原型验证嵌入式软件，提效 30%、提升可靠性。<br/>学习提示：免费教学资源指出，嵌入式代码需兼顾硬件理解、资源管理与实时响应能力，对应工具与设计策略非常关键。</p><p>2、驱动与 API：软硬桥梁，性能关键点<br/>驱动和 API 是软件与硬件交互的核心纽带。<br/>HAL（硬件抽象层）：通过统一接口屏蔽底层差异，让驱动更加通用可靠。<br/>API 设计规范：文档完善、易用安全、错误处理健全的 API 可降低调试成本、提升系统稳定性。<br/>案例实战：某定制IC 项目成功通过 HAL 设计与优质 API 架构，驱动性能提升 25%，调试效率显著提高。<br/>驱动开发技巧：如使用中断或 DMA 替代轮询，可显著提升效率和能效。</p><p>3、RTOS：让任务更“准时”<br/>RTOS 是管理多任务与资源调度的利器，适用于汽车、工业控制等实时性要求高的领域。<br/>调度与优先级：FreeRTOS、VxWorks 等系统采用精细的任务调度机制，确保关键任务得以及时执行。<br/>实时调试工具：可追踪任务执行、定位性能瓶颈，提升系统调试效率。<br/>真实案例：某汽车电子公司采用 VxWorks RTOS，以高级调度 + 实时调试确保传感器处理与控制信号精准同步，显著提升系统响应与安全性能。</p><p>RTOS 典范：FreeRTOS 开源、轻量，支持多种嵌入式平台；TI-RTOS 提供从内核、驱动到底层服务的完整生态；RT-Thread 在国内也有活跃开源社区。</p><p>4、系统整合：驱动模块、API、RTOS，有机协同<br/><img width="723" height="446" referrerpolicy="no-referrer" src="/img/bVdncYV" alt="" title="" loading="lazy"/><br/>在 IC 系统中，嵌入式软件、驱动层与 RTOS 需要无缝协作：<br/>模块化软件简化迭代；<br/>HAL 和 API 提供统一接口；<br/>RTOS 管理任务调度、实时性和调试；<br/>FPGA 原型加速开发测试；<br/>这种整合方式带来高效开发流程和高性能系统输出。</p><p>5、EDA Academy：你的技术成长与职业平台<br/>最新全面课程：涵盖嵌入式软件开发、驱动/API设计、RTOS 实战等全方位内容。<br/>支持双向发展：你可注册为学员精进技能，也可注册为导师，分享经验、深化影响。<br/>免费订阅更新：仅凭邮箱即可免费订阅 newsletter，获取前沿课程与技术洞察。<br/>销售联盟机会：推荐课程给他人即可获得 20%–50% 的佣金，实现学习与收益同步增长。</p><p>嵌入式软件与 RTOS 是打造IC系统实用性与可靠性的核心能力。通过模块化开发、接口抽象、实时调度与仿真验证，工程师能够构建更高效、更可控的系统。若你期待深入这一技术领域，并收获职业成长与收入机会，欢迎访问 EDA Academy（www.eda-academy.com），开启你的专业精攻之旅。<br/><img width="723" height="1098" referrerpolicy="no-referrer" src="/img/bVdm7s4" alt="" title="" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[51CTO-宽哥【云原生开发】Go和Gi]]></title>    <link>https://segmentfault.com/a/1190000047438112</link>    <guid>https://segmentfault.com/a/1190000047438112</guid>    <pubDate>2025-11-29 16:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在云原生技术浪潮席卷全球的当下，企业级应用开发对开发者的技术栈提出了更高要求。👇🏻ke🍊：xingkeit点top/9707/Go语言凭借其卓越的并发性能与轻量化特性，结合Gin框架的高效路由机制，已成为构建微服务架构的核心工具链。51CTO平台推出的《Go+Gin零基础到云原生脚手架实战》课程，通过系统化的知识体系与实战案例，帮助开发者规避常见陷阱，快速掌握云原生开发的核心能力。</p><p>一、云原生开发的技术选型逻辑</p><ol><li>Go语言：云原生的天然适配者<br/>Go语言诞生于谷歌实验室，其设计初衷便是解决高并发场景下的性能瓶颈。通过goroutine（轻量级线程）与channel（通信管道）的组合，开发者可轻松实现数十万级并发连接，这一特性使其成为Kubernetes、Docker等云原生基础设施的底层开发语言。课程中深入解析了Go的并发模型优势：相比传统线程，goroutine的内存占用仅为KB级别，且通过调度器自动平衡多核CPU负载，避免了线程切换的开销。</li><li>Gin框架：高性能Web开发的加速器<br/>作为Go生态中最受欢迎的Web框架，Gin以“零内存分配”的路由算法实现毫秒级响应。课程通过对比测试数据展示其性能优势：在处理10万级QPS（每秒查询率）时，Gin的内存占用比传统框架降低60%，响应延迟稳定在2ms以内。其核心设计亮点包括：</li></ol><p>分层路由机制：基于基数树（Radix Tree）的路由匹配，支持动态参数与通配符路由。<br/>中间件生态：内置JWT认证、限流熔断、日志追踪等20+开箱即用的中间件。<br/>开发效率提升：通过ShouldBindJSON等函数实现请求参数的自动校验与绑定，减少样板代码。<br/>二、云原生脚手架的核心设计原则</p><ol><li>分层架构：解耦与可维护性的基石<br/>课程提出的“六边形架构”将项目划分为六层：</li></ol><p>cmd层：存放程序入口文件，每个子目录对应独立可执行程序（如Web服务、定时任务）。<br/>internal层：私有应用代码，包含应用初始化、配置管理、领域模型等模块。<br/>pkg层：公共可复用代码，如工具函数、第三方库封装。<br/>infra层：基础设施实现，涵盖数据库连接、缓存管理、消息队列等。<br/>transport层：协议适配层，支持HTTP、gRPC等多协议接入。<br/>docs层：项目文档，包括API规范、设计文档与部署指南。<br/>这种分层设计使代码职责清晰，例如某电商项目通过将订单服务与支付服务拆分至不同internal子模块，实现独立开发与部署，团队并行开发效率提升40%。</p><ol start="2"><li>配置管理：多环境隔离与动态更新<br/>课程强调配置管理的“三要素”：</li></ol><p>环境隔离：通过dev.yaml、prod.yaml等文件区分开发、测试、生产环境配置。<br/>敏感信息保护：使用Vault或Kubernetes Secrets管理数据库密码、API密钥等敏感数据。<br/>动态加载：结合viper库实现配置文件的热更新，无需重启服务即可应用变更。<br/>以某金融项目为例，通过动态配置管理，其风控规则的更新周期从4小时缩短至秒级，显著提升业务响应速度。</p><p>三、实战案例：从零构建企业级脚手架</p><ol><li>用户认证与安全防护<br/>课程通过JWT（JSON Web Token）实现无状态认证，结合以下机制提升安全性：</li></ol><p>Token生命周期管理：设置15分钟短期访问令牌与24小时刷新令牌，平衡安全性与用户体验。<br/>CSRF防护：在Gin中间件中校验请求头中的X-CSRF-Token，防止跨站请求伪造攻击。<br/>速率限制：使用github.com/ulule/limiter库实现IP级别的请求限流，抵御DDoS攻击。<br/>某社交平台应用上述方案后，恶意刷量行为减少90%，认证接口的响应时间稳定在3ms以内。</p><ol start="2"><li>日志与监控体系<br/>课程构建的日志系统包含三大模块：</li></ol><p>结构化日志：使用zap库输出JSON格式日志，包含请求ID、用户ID、耗时等关键字段。<br/>日志聚合：通过Filebeat将日志传输至ELK（Elasticsearch+Logstash+Kibana）栈，实现全文检索与可视化分析。<br/>链路追踪：集成OpenTelemetry，在Gin中间件中注入TraceID，关联微服务间的调用链路。<br/>某物流项目通过该体系，将系统故障定位时间从2小时缩短至5分钟，运维效率提升80%。</p><ol start="3"><li>自动化部署与弹性伸缩<br/>课程提供的CI/CD流水线包含以下环节：</li></ol><p>代码提交触发：GitHub Actions监听代码仓库变更，自动运行单元测试与代码扫描。<br/>镜像构建：使用多阶段Dockerfile生成最小化镜像（&lt;15MB），减少安全漏洞与资源消耗。<br/>Kubernetes部署：通过Helm Chart管理Pod副本数、资源配额与健康检查配置。<br/>弹性伸缩：基于Prometheus监控的CPU使用率，自动调整Pod数量应对流量高峰。<br/>某在线教育平台应用该流水线后，部署频率从每周1次提升至每日多次，系统可用性达到99.95%。</p><p>四、课程价值：从技能到职业的全面升级</p><ol><li>技术栈覆盖全周期<br/>课程采用“基础+进阶+实战”的三阶段设计：</li></ol><p>基础阶段：Go语言核心特性（并发编程、错误处理、标准库）、Gin框架基础（路由、中间件、参数绑定）。<br/>进阶阶段：云原生技术栈（Docker、Kubernetes、Service Mesh）、微服务架构设计（服务发现、熔断降级、API网关）。<br/>实战阶段：企业级脚手架开发、电商平台案例拆解、故障演练与性能调优。</p><ol start="2"><li>职业竞争力提升<br/>据学员反馈，完成课程后：</li></ol><p>薪资涨幅：平均跳槽薪资提升35%，部分学员进入阿里P7、腾讯T9等高级职级。<br/>项目经验：输出可复用的脚手架代码与架构文档，直接应用于企业招聘中的“项目经验”环节。<br/>内推资源：课程与500+企业建立合作，优秀学员可获得独家内推机会。<br/>五、结语：云原生时代的开发者进化路径<br/>在云原生技术日益成熟的2025年，开发者需具备“全栈化、智能化、工程化”的综合能力。51CTO宽哥的Go+Gin课程通过“理论+实践+工具链”的完整闭环，不仅教授技术原理，更注重培养开发者在真实场景中解决问题的能力。无论是零基础转行者，还是希望突破职业瓶颈的资深工程师，这门课程都将成为你迈向云原生架构师的关键跳板。</p>]]></description></item><item>    <title><![CDATA[ITSS体系建设的组织策略：从项目导向到]]></title>    <link>https://segmentfault.com/a/1190000047438056</link>    <guid>https://segmentfault.com/a/1190000047438056</guid>    <pubDate>2025-11-29 15:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>根据工信部历年信息服务业发展报告的数据，中国超过80%的企业在启动ITSS体系建设时，仍以“项目制”方式推进。这意味着他们把ITSS视为一个阶段性任务，而非组织能力建设的长期工程。结果很明显——项目结束那天，体系也随之停止。流程文件更新断档、岗位职责回归旧习、指标考核形同虚设。三个月后，所有成果几乎回到原点。<br/> 而另一类企业，在同样起点下，却能在两三年内形成稳定的流程管理体系，实现运维绩效的持续提升。两种结果之间的分水岭，正是从项目导向到体系化治理的转变。</p><p><img width="455" height="298" referrerpolicy="no-referrer" src="/img/bVdncX3" alt="" title=""/></p><hr/><p><strong>一、对比：项目导向思维的“快”与“短”</strong><br/>项目导向的思维模式，本质上是追求“可交付、可验收、可关闭”。这没错，但一旦用于ITSS体系建设，问题就出现了。<br/> 项目制往往关注“阶段目标”而非“持续运行”。例如：</p><ul><li>只在立项期分配资源，后续缺乏运维支撑；</li><li>只注重评审指标，忽略实际落地；</li><li>项目团队解散后，标准无人维护。<br/>在GB/T 28827.2《信息技术服务 管理体系要求》中，明确提出“体系运行应与组织业务持续运行相结合”。也就是说，标准要求的是长期的制度化运行机制，而非临时性项目成果。<br/> 项目导向像“短跑冲刺”，体系化治理则更像“长跑训练”——前者看速度，后者看耐力。</li></ul><hr/><p><strong>二、体系化治理：以标准为“骨架”，以文化为“血液”</strong><br/>体系化治理并不是要让流程僵化，而是让管理有持续的生命力。<br/> 在我辅导过的一家通信企业中，他们最初同样陷入“项目思维”误区。直到经历一次应急事件，他们才真正理解体系的重要性。<br/>某年国庆期间，客户核心机房突发存储故障。虽然他们的ITSS项目刚刚通过了二级评估，但事件响应过程却混乱不堪：</p><ul><li>没有统一的应急指挥通道；</li><li>各部门自行决策，沟通断层；</li><li>工单记录混乱，事后难以追溯。<br/>事后复盘发现，他们的体系文件完备，但没有转化为真实的运行机制。<br/> 这次事件让高层意识到：体系不是“通过评估”，而是“支撑行动”。他们随后重组了IT治理委员会，设立持续改进岗位，并将流程执行与绩效挂钩。半年后，平均故障响应时间下降了47%。<br/>正如ITSS标准所强调的，治理体系的价值在于“机制化”与“内生性”。它让每一次事件都能推动体系的成长，而非成为孤立事故。</li></ul><hr/><p><strong>三、从“项目”到“体系”的四个关键转向</strong><br/>如果说项目导向关注“做完”，体系化治理则关注“做久”。在实践中，这种转变至少包含四个关键维度：</p><ol><li>从短期目标到长期治理目标<br/> 体系化建设要以组织战略为牵引，而不是评审节点。目标应体现在年度绩效、客户满意度与运维成熟度的持续提升上。</li><li>从任务分工到角色职责体系<br/> 项目化通常只分配“谁负责哪块任务”；体系化治理要定义“角色+责任+权限”的组合。<br/> 例如，服务管理负责人、流程管理人、持续改进专员等，都需要在组织架构中有明确定位。</li><li>从模板执行到流程闭环<br/> 项目往往停留在“交付模板”层面，而体系建设要确保“流程有输入、有输出、有改进”。<br/> 这意味着流程不仅要“存在”，还要“运转”。</li><li>从外部验收到内部驱动<br/> ITSS评估只是一个阶段性镜像。真正的成熟，是企业能在没有外部顾问的情况下，自主更新和优化体系。<br/>艾拓先锋组织ITSS服务项目经理培训，大家可以来课堂上跟我就这个问题深入探讨。学员常问：“体系建设到底该谁牵头？”<br/> 我的回答是——要有一个‘业务理解+标准意识’兼具的中台部门，既懂运维又懂管理。因为体系化的关键，不是文件，而是认同。</li></ol><hr/><p><strong>四、案例对照：失败的项目化 vs 成功的体系化</strong><br/>我印象最深的案例，是两家规模相当的银行。<br/> 第一家在三个月内完成ITSS三级评估，但项目结束后没人维护配置库，导致半年后系统数据完全失真。<br/> 第二家银行则建立了“IT服务管理办公室（ITSMO）”，每季度组织改进会议，持续优化指标。三年后，他们未再额外投入咨询费用，但成熟度从二级跃升至三级。<br/> 对比之下你会发现：体系化的成本比项目化更低，收益却更稳。<br/>体系化治理让标准成为一种组织语言：</p><ul><li>让每次流程优化都能积累知识资产；</li><li>让每个指标改进都能量化绩效；</li><li>让每个项目结束都能反哺体系成长。</li></ul><hr/><p><strong>五、制度化支撑：让标准“长在组织里”</strong><br/>体系化建设的核心，是制度化。它既不是“文档管理”，也不是“官僚化”，而是通过制度让改进有连续性。<br/> 标准里提出的<strong>“持续改进机制”</strong>，其实可以分解为三步：</p><ol><li>建立度量体系（如流程效率、服务满意度等）；</li><li>设立改进议题（由管理委员会定期评估）；</li><li>将结果纳入绩效与激励机制。<br/>这种机制一旦成型，就能让ITSS从“外部认证”转变为“内部驱动力”。<br/> 这也是我认为最值得中大型企业重视的转折点：体系化治理不靠项目经理的努力，而靠制度的自我强化。</li></ol><hr/><p><strong>六、风险警示：别让ITSS变成“文件体系”</strong><br/>在全国ITSS评估案例中，约有30%的企业在通过认证一年后，体系形同虚设。<br/> 原因很简单——他们把ITSS当作一次性任务，而非治理机制。<br/> 项目化思维的风险在于：</p><ul><li>体系停留在文件层；</li><li>改进止步于评估期；</li><li>组织缺乏内生更新机制。<br/>当市场环境变化、团队成员流动时，原有体系无法自我修复，标准最终“空心化”。<br/> 因此，真正的风险不是没通过评估，而是体系无法持续运行。<br/>体系化治理的关键，在于“标准持续更新、责任持续传承、文化持续强化”。<br/> 只有这样，ITSS才能成为企业的“免疫系统”，而非“临时项目”。</li></ul>]]></description></item><item>    <title><![CDATA[海洋生物识别系统【最新版】Python+]]></title>    <link>https://segmentfault.com/a/1190000047437932</link>    <guid>https://segmentfault.com/a/1190000047437932</guid>    <pubDate>2025-11-29 14:01:53</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>一、介绍</h2><p>海洋生物系统，本项目基于深度学习技术，构建了一个集海洋生物识别、数据可视化和智能问答于一体的Web应用系统。系统采用TensorFlow框架搭建卷积神经网络模型，通过对22种常见海洋生物（包括海豚、鲸鱼、鲨鱼、珊瑚、海星等）数据集进行多轮迭代训练，最终获得高精度识别模型，并开发了功能完善的Web操作平台。</p><p><strong>前端</strong>: Vue3、Element Plus</p><p><strong>后端</strong>：Django</p><p><strong>算法</strong>：TensorFlow、卷积神经网络算法</p><p><strong>具体功能</strong>：</p><ol><li>系统分为管理员和用户两个角色，登录后根据角色显示其可访问的页面模块。</li><li>登录系统后可发布、查看、编辑文章，创建文章功能中集成了markdown编辑器，可对文章进行编辑。</li><li>在图像识别功能中，用户上传图片后，点击识别，可输出其识别结果和置信度</li><li>基于Echart以柱状图形式输出所有种类对应的置信度分布图。</li><li>在智能问答功能模块中：用户输入问题，后台通过对接Deepseek接口实现智能问答功能。</li><li>管理员可在用户管理模块中，对用户账户进行管理和编辑。</li></ol><p><strong>选题背景与意义</strong>：<br/>随着海洋资源的开发与保护日益受到重视，对海洋生物进行快速、准确的识别与分析成为科研、教育及生态保护领域的重要需求。然而，传统的海洋生物识别方法依赖专家经验，效率较低，且公众参与度有限。近年来，深度学习技术在图像识别领域取得了显著进展，为海洋生物的自动化识别与知识普及提供了新的可能。</p><p>本项目基于这一背景，利用TensorFlow框架构建卷积神经网络模型，针对22种常见海洋生物（如海豚、鲸鱼、珊瑚等）进行训练，实现了高精度的生物识别。同时，系统结合Vue3与Django开发了功能完善的Web平台，集成图像识别、数据可视化及智能问答等功能，为用户提供便捷的海洋生物认知与交互体验。通过这一系统，旨在推动海洋生物知识的普及，提升海洋保护的科技参与度。</p><h2>二、系统效果图片展示</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047437934" alt="图片" title="图片"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047437935" alt="图片" title="图片" loading="lazy"/></p><h2>三、演示视频 and 完整代码 and 安装</h2><p>地址：<a href="https://link.segmentfault.com/?enc=%2FqOSPMjhLWK%2B%2FJgMo4Fi1w%3D%3D.jil7J6RGGPOMByhIYF7KEPPKTU5Tlh%2Ftvzm9DJ%2BTU1M%3D" rel="nofollow" target="_blank">https://ziwupy.cn/p/ZtMoo4</a></p><h2>四、卷积神经网络算法介绍</h2><p>卷积神经网络是一种专门用于处理网格状数据（如图像）的深度学习架构。其核心思想是通过<strong>卷积核</strong>在输入数据上进行滑动窗口式的“卷积”操作，以自动提取从低级到高级的层次化特征。</p><p>CNN主要由以下关键层构成：</p><ol><li><strong>卷积层</strong>：是CNN的核心。它使用多个卷积核在输入图像上滑动，通过计算局部区域的点积来生成特征图。这一过程能够有效捕捉图像中的局部特征，如边缘、角点等，并具有权值共享的特点，大大减少了模型参数。</li><li><strong>池化层</strong>：通常跟在卷积层之后，用于对特征图进行下采样。最常用的是<strong>最大池化</strong>，它取局部区域的最大值。池化层可以在保持主要特征的同时，减小数据尺寸，降低计算复杂度，并增强模型的平移不变性。</li><li><strong>全连接层</strong>：在网络的末端，将经过多次卷积和池化后提取到的展开特征进行综合，并映射到最终的输出类别上，完成分类任务。</li></ol><p>通过堆叠这些层，CNN能够逐步从原始像素中提取出越来越复杂的特征，最终实现高精度的图像识别。</p><p>以下是一个使用TensorFlow和Keras API构建一个简单的CNN模型，用于手写数字识别（MNIST数据集）的示例。</p><pre><code class="python">import tensorflow as tf
from tensorflow.keras import datasets, layers, models

# 1. 加载并预处理数据
(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()
# 将图像数据重塑为 (28, 28, 1) 并归一化
train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255
test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255

# 2. 构建CNN模型
model = models.Sequential([
    # 第一卷积块
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    layers.MaxPooling2D((2, 2)),
    # 第二卷积块
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    # 将特征图展平以输入全连接层
    layers.Flatten(),
    # 全连接层
    layers.Dense(64, activation='relu'),
    # 输出层，10个神经元对应10个类别（数字0-9）
    layers.Dense(10, activation='softmax')
])

# 3. 编译模型
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# 4. 训练模型
model.fit(train_images, train_labels, epochs=5, 
          validation_data=(test_images, test_labels))

# 5. 评估模型
test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)
print(f'\n测试准确率：{test_acc}')</code></pre><p>上述代码完整展示了使用CNN进行图像分类的流程。首先，我们加载MNIST数据集并将其处理成适合CNN输入的格式。接着，我们构建了一个顺序模型，其中包含两个卷积-池化层组合，用于特征提取；之后通过Flatten层将多维特征图展平，并连接两个全连接层进行分类。模型使用Adam优化器和稀疏分类交叉熵损失函数进行编译。最后，我们在训练集上训练5个轮次，并在测试集上评估最终性能，通常能达到很高的准确率。此代码是理解CNN应用的基础模板，本项目的海洋生物识别系统即是在此基础上，使用更复杂的网络结构和海洋生物数据集进行训练与优化的。</p>]]></description></item><item>    <title><![CDATA[【宠物识别系统】Python+Tenso]]></title>    <link>https://segmentfault.com/a/1190000047437970</link>    <guid>https://segmentfault.com/a/1190000047437970</guid>    <pubDate>2025-11-29 14:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>一、介绍</h2><p>宠物识别系统，本系统基于TensorFlow框架，采用卷积神经网络（CNN）算法，构建了一个能够识别37种常见宠物品种的智能识别系统。所使用的数据集涵盖了多个猫犬品种，例如阿比西尼亚猫、布偶猫、柴犬、哈士奇等。经过多轮迭代训练，最终得到了识别准确率较高的预测模型，并部署于Web端实现可视化交互。</p><p><strong>前端</strong>: Vue3、Element Plus</p><p><strong>后端</strong>：Django</p><p><strong>算法</strong>：TensorFlow、卷积神经网络算法</p><p><strong>具体功能</strong>：</p><ol><li>系统分为管理员和用户两个角色，登录后根据角色显示其可访问的页面模块。</li><li>登录系统后可发布、查看、编辑文章，创建文章功能中集成了markdown编辑器，可对文章进行编辑。</li><li>在图像识别功能中，用户上传图片后，点击识别，可输出其识别结果和置信度</li><li>基于Echart以柱状图形式输出所有种类对应的置信度分布图。</li><li>在智能问答功能模块中：用户输入问题，后台通过对接Deepseek接口实现智能问答功能。</li><li>管理员可在用户管理模块中，对用户账户进行管理和编辑。</li></ol><p><strong>选题背景与意义</strong>：<br/>随着社会经济发展与家庭结构变化，宠物在人们生活中的角色日益重要，宠物相关科技应用需求持续增长。然而，普通饲养者往往难以准确辨别宠物品种，导致在饲养、医疗及交流过程中存在信息障碍。尽管人工智能技术已在图像识别领域取得显著进展，但现有应用多集中于人脸或通用物体识别，专门针对多品种宠物、兼具实用性与交互性的识别系统仍较为缺乏。</p><p>基于此背景，本课题旨在开发一个基于TensorFlow与卷积神经网络（CNN）的智能宠物识别系统。该系统能够对包括阿比西尼亚猫、布偶猫、柴犬、哈士奇等在内的37种常见猫犬品种进行高效识别，并结合Vue3与Django框架构建完整的Web应用平台。系统不仅提供高准确率的图像识别功能，还集成文章管理、数据可视化及智能问答等多种服务，从而为宠物爱好者搭建一个集知识交流与智能识别于一体的实用工具，有效填补了细分领域的技术应用空白。</p><h2>二、系统效果图片展示</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047437972" alt="图片" title="图片"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047437973" alt="图片" title="图片" loading="lazy"/></p><h2>三、演示视频 and 完整代码 and 安装</h2><p>地址：<a href="https://link.segmentfault.com/?enc=Rh%2FLW49quDuf3gP1PKSeLA%3D%3D.uM0p1ZWqfq7XbWu1pmoqhZpojFJlGofAAaGzJMqCyFQ%3D" rel="nofollow" target="_blank">https://ziwupy.cn/p/nTpUXb</a></p><h2>四、卷积神经网络算法介绍</h2><p>卷积神经网络是一种专为处理网格状数据（如图像）而设计的深度学习模型。其核心思想是通过<strong>卷积层</strong>自动提取图像中的空间层次特征。</p><p>一个典型的CNN包含以下关键层：</p><ul><li><strong>卷积层</strong>：使用多个可学习的滤波器（卷积核）在输入图像上滑动，通过计算局部区域的点积来提取特征（如边缘、角点、纹理）。这个过程保留了像素间的空间关系。</li><li><strong>池化层</strong>：紧随卷积层之后，用于降低特征图的维度，减少计算量并增强模型的平移不变性。最大池化是最常用的方式。</li><li><strong>全连接层</strong>：在网络的末端，将经过多次卷积和池化后提取到的高级特征图展平，进行综合判断，最终输出分类概率。</li></ul><p>通过堆叠这些层，CNN能够从低级特征（边缘）逐步组合形成高级特征（器官、物体），从而实现高效的图像识别。</p><p>以下是一个使用TensorFlow和Keras API构建一个简单的CNN模型，用于处理MNIST手写数字识别的示例。</p><pre><code class="python">import tensorflow as tf
from tensorflow.keras import datasets, layers, models

# 1. 加载并预处理数据
(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()
# 将图像重塑为 (28, 28, 1) 并归一化
train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255
test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255

# 2. 构建CNN模型
model = models.Sequential([
    # 第一个卷积层，使用32个3x3的滤波器，激活函数为ReLU
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    # 最大池化层，窗口大小为2x2
    layers.MaxPooling2D((2, 2)),
    # 第二个卷积层，使用64个3x3的滤波器
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    # 将多维特征图展平为一维向量，以便输入全连接层
    layers.Flatten(),
    # 全连接层，128个神经元
    layers.Dense(128, activation='relu'),
    # 输出层，10个神经元对应10个数字类别，使用softmax激活函数输出概率分布
    layers.Dense(10, activation='softmax')
])

# 3. 编译模型
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# 4. 训练模型
model.fit(train_images, train_labels, epochs=5, 
          validation_data=(test_images, test_labels))

# 5. 评估模型
test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)
print(f'\nTest accuracy: {test_acc}')</code></pre><p>上述代码演示了构建CNN的经典流程：数据准备、模型搭建、编译、训练与评估。对于宠物识别系统，核心原理与此相同，但更为复杂。：</p><ol><li><strong>准备更庞大的数据集</strong>：包含37个宠物品种的标注图像。</li><li><strong>使用更深的网络</strong>：可以迁移学习预训练模型（如ResNet, MobileNet），在其基础上进行微调，以适应宠物分类任务。</li><li><strong>调整输入尺寸</strong>：将图像调整为更适合现代网络的尺寸（如224x224）。</li><li><strong>部署模型</strong>：如所述，使用Django作为后端，将训练好的模型加载到服务中，处理用户上传的图片并返回识别结果和置信度。</li></ol>]]></description></item><item>    <title><![CDATA[openFuyao信息直升机 | 第5期]]></title>    <link>https://segmentfault.com/a/1190000047437831</link>    <guid>https://segmentfault.com/a/1190000047437831</guid>    <pubDate>2025-11-29 13:02:18</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>业务痛点：</h2><p>AI推理是AI领域中将大模型转化为应用效果与商业价值的核心技术，但在实际生产部署中仍然面临着多样化算力场景下的效率低与可部署性成本高，高并发、长上下文LLM推理场景中的性能和资源利用率瓶颈。</p><h2>根因分析：</h2><ul><li>用户体验与资源效率瓶颈：当前长上下文LLM推理的首Token延时普遍在数百毫秒至秒级，且长上下文场景下KV缓存显存占用呈线性增长，严重制约Agent的响应效率与部署规模；传统静态批处理无法适配动态负载，导致短请求被长请求阻塞（对头阻塞问题）。</li><li>企业生产级场景挑战：企业生产场景，普遍存在高推理成本、多样化算力（GPU算力 + 国产化算力）利用率低、SLA难以保障、生产级规模部署管理复杂等问题。</li><li>云原生AI全栈挑战：现有云原生调度（如Kubernetes）缺乏LLM感知能力，无法优化KV缓存生命周期、动态批处理等场景。</li></ul><h2>高性能AI推理服务化框架方案</h2><p>openFuyao通过“聚焦智能动态路由 + xPyD计算动态资源管理调度 + 分布式KVCache/KVCache优化 + 端到端易用性 + 推理场景可观测体系”高性能、可扩展子系统的构建，致力于系统性突破当前LLM推理的瓶颈，同时面向超节点场景进一步加速，支持灵衢、CXL、NVLink等高速总线：</p><p><img width="723" height="728" referrerpolicy="no-referrer" src="/img/bVdncUa" alt="" title=""/></p><ul><li>首Token延时（TTFT）降低：智能路由与缓存命中策略优化、近实时集群节点负载感知。</li><li>推理吞吐提升：弹性xPyD分离架构升级、高性能弹性配比。</li><li>N/S、E/W全局显存瓶颈突破：多级KVCache、集群KVCache池化；结合高性能传输协议和去中心化高性能硬件，进一步降低KVCache传输延迟。</li><li>资源利用率提升：通过动态资源调度配比和异构算力池化进一步提升资源利用率。</li></ul><p><img width="723" height="475" referrerpolicy="no-referrer" src="/img/bVdncUh" alt="" title="" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[AI重塑招聘生态：从效率革命到职能升级 ]]></title>    <link>https://segmentfault.com/a/1190000047437836</link>    <guid>https://segmentfault.com/a/1190000047437836</guid>    <pubDate>2025-11-29 13:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>AI重塑招聘生态：从效率革命到职能升级<br/>当 HR 还在忙着追候选人时，AI 已经把招聘周期缩短了 40%。<br/>人工智能技术正在逐步改变招聘行业的运作方式。有数据显示，通过微表情分析与语义推理等技术手段，招聘周期可以实现40%的缩短；某大型银行引入AI系统后，面试到场率提升至90.7%；辉瑞制药在研发人才识别中采用AI技能图谱，创新周期相应缩短22%。<br/>这些变化表明，AI不仅释放了人力资源从业者从事重复性工作的时间，更推动了HR职能的转型。据统计，近半数企业已完成人力资源流程的智能化升级，HR逐渐从流程管理角色转向组织战略伙伴，更多参与到组织健康诊断、差异化薪酬设计及数据驱动决策中。例如，ING银行通过引入AI辅助，决策效率提升了50%。</p><p>一、AI面试评分：科学支持招聘决策<br/>传统招聘中，“凭感觉”选人的情况时有发生。当前AI面试系统通过效标效度与重测信度双重验证，并结合大规模人机对比实验，实现了与资深面试官判断的高度一致性。最新版本的系统进一步巩固了其在AI面试智能体领域的技术水平，评分结果可直接用于招聘决策。<br/>二、全流程精准化设计<br/>AI面试系统在多个环节实现精准优化：<br/>•一问多能：单题可评估多项胜任力，提升筛选效率50%以上<br/>•智能追问：根据回答内容实时生成追问，避免关键能力遗漏<br/>•简历深度解析：自动识别亮点与疑点，辅助防伪与人才发现<br/>•全维度测评：覆盖通用能力与专业技能，支持自动出题<br/>该系统已不仅作为面试工具使用，而是能够在初筛及部分技术复试中发挥实质作用。<br/>三、优化候选人面试体验<br/>传统AI面试常被诟病交互生硬，影响雇主形象。当前系统通过以下设计改善体验：<br/>•情绪识别与引导，缓解候选人紧张情绪<br/>•无断点交互，无需操作“开始/结束”，模拟真实对话<br/>•视觉呈现更为自然，提升沉浸感<br/>•支持多轮问答，及时回应岗位与公司相关问题<br/>在人才竞争日益激烈的背景下，面试过程已成为雇主品牌展示的重要环节。<br/>四、全流程自动化的人才寻访<br/>除AI面试外，自动化人才寻访系统可实现从识别、沟通到系统录入的全流程智能化：<br/>•快速初始化，即启即用<br/>•自动筛选与动态沟通，模拟人类交流方式<br/>•全覆盖应答，主动获取所需信息<br/>•数据自动同步至招聘系统<br/>此类系统大幅提升了人才寻访环节的整体效率。<br/>五、技术应用的验证路径<br/>目前，部分系统开放了较大规模的免费使用权限，用户可在实际招聘场景中验证其效果，涵盖面试、测评、筛选、寻访及数据同步等多个环节。这为招聘团队提供了低风险的体验途径。<br/>已有包括多家大型企业及高校在内的机构使用了相关系统，反映出这类AI招聘工具在实际应用中的认可度。<br/>当前，AI招聘技术的发展重点集中于精准选人与体验提升，最新版本系统在这两方面均展现了较高水平。</p>]]></description></item><item>    <title><![CDATA[【URP】Unity[内置Shader]]]></title>    <link>https://segmentfault.com/a/1190000047437734</link>    <guid>https://segmentfault.com/a/1190000047437734</guid>    <pubDate>2025-11-29 12:02:19</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <blockquote><a href="https://link.segmentfault.com/?enc=aaLejJ5ph02zfYWetdJ%2F6A%3D%3D.S%2FWx2Ri8vwnfr3VGhcoipNJ3b2yam%2B%2BzmUHR01w1Hhr6ubALPPE8hEruDonhCber7NvISX%2B%2FP%2FKBAohFeXxeWNvVWj0qBdFIT7oVxK75xmG3LOJmUJE9EphsFo1YHF5P71CRN8mJ7ARWux1h0Kfj00TzE9VqZO0999XCRPj4yonX91LMqjTDaGUfj4moq31ajSGRmi0XGIf2zZxc6s7Vt69EGrx7iwLwpVhsCzay7EQ%3D" rel="nofollow" target="_blank">【从UnityURP开始探索游戏渲染】</a><strong>专栏-直达</strong></blockquote><h2><strong>SimpleLit Shader的作用与原理</strong></h2><p><a href="https://link.segmentfault.com/?enc=7YGvrz27NhM1DUS1jBcEPw%3D%3D.lN2ktnr15ef%2FF4ntukhefMAI1GFvAa9N2pKTdKL0mogYGIjJrsOpVReUGwRorI1urF2gzxx5otdO1%2FGLPAXge8s5jTLWbuuNs2r33AZTvaa2zEflHaKNmUJfOYWoey3kDGxUER9L3SDDKB4OlTs31g%3D%3D" rel="nofollow" target="_blank">SimpleLit</a> Shader是Unity通用渲染管线(URP)中的一种轻量级着色器，主要用于低端设备或需要高效渲染的场景。它采用简化的Blinn-Phong光照模型，不计算物理正确性和能量守恒，从而实现了比标准Lit Shader更快的渲染速度。</p><h2><strong>核心原理</strong></h2><ul><li>‌<strong>简化光照模型</strong>‌：使用Blinn-Phong模型而非PBR，省略了复杂的物理计算</li><li>‌<strong>模块化结构</strong>‌：分为Surface Options(控制渲染方式)、Surface Inputs(描述表面特性)和Advanced Options(底层渲染设置)三部分</li><li>‌<strong>前向渲染路径</strong>‌：通过"UniversalForward" Pass实现，支持主光源阴影和附加光源计算</li><li>‌<strong>变体控制</strong>‌：通过Shader Feature和Multi Compile指令管理不同功能组合，减少不必要的变体</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047437736" alt="image.png" title="image.png"/></p><h2><strong>发展历史</strong></h2><p>SimpleLit Shader随着URP的发展经历了多个版本迭代：</p><ul><li>早期版本(2019-2020)：作为URP首批内置Shader之一，提供基础光照功能</li><li>URP 7.x时期(2021)：优化了变体管理，增加了GPU实例化支持</li><li>URP 12.1.1(2022)：完善了SubShader错误处理，默认返回紫色洋葱效果</li><li>当前版本(2024-2025)：支持DOTS Instancing，增强了与Shader Graph的兼容性</li></ul><h2><strong>具体使用方法</strong></h2><h3><strong>基础应用示例</strong></h3><ul><li>创建材质：在Project窗口右键 &gt; Create &gt; Material</li><li>选择Shader：在材质Inspector中，选择"Universal Render Pipeline &gt; Simple Lit"</li><li><p>配置属性：</p><ul><li>Base Map：设置基础颜色纹理</li><li>Base Color：调整整体色调</li><li>Smoothness：控制表面光滑度</li><li>Emission：添加自发光效果</li></ul></li></ul><h3><strong>代码示例</strong></h3><pre><code class="csharp">csharp
// 通过代码设置SimpleLit材质属性
Material simpleLitMat = new Material(Shader.Find("Universal Render Pipeline/Simple Lit"));
simpleLitMat.SetTexture("_BaseMap", Resources.Load&lt;Texture&gt;("BaseTexture"));
simpleLitMat.SetColor("_BaseColor", Color.blue);
simpleLitMat.SetFloat("_Smoothness", 0.75f);</code></pre><h2><strong>Shader Graph中的应用</strong></h2><h3><strong>创建SimpleLit风格Shader</strong></h3><ul><li>创建新Graph：右键 &gt; Create &gt; Shader &gt; Universal Render Pipeline &gt; Blank Shader Graph</li><li><p>设置Graph设置：</p><ul><li>Material设置为"Simple Lit"</li><li>Surface设置为"Opaque"或"Transparent"</li></ul></li><li><p>构建节点网络：</p><ul><li>使用"Sample Texture 2D"节点获取基础颜色</li><li>通过"Normal From Texture"节点处理法线贴图</li><li>连接"Master Stack"的对应输入端口</li></ul></li></ul><h3><strong>示例Graph功能</strong></h3><ul><li><p>‌<strong>基础颜色混合</strong>‌：</p><ul><li>混合纹理采样和颜色参数</li><li>添加细节遮罩控制混合强度</li></ul></li><li><p>‌<strong>动态高光控制</strong>‌：</p><ul><li>使用时间节点驱动高光强度变化</li><li>通过顶点位置影响高光范围</li></ul></li><li><p>‌<strong>边缘发光效果</strong>‌：</p><ul><li>计算视角与法线夹角</li><li>使用Fresnel节点创建边缘光</li></ul></li></ul><h3><strong>保存与应用</strong></h3><ul><li>保存Graph后生成.shadergraph文件</li><li>创建材质并选择生成的Shader</li><li>通过材质参数面板调整公开属性</li></ul><h2><strong>Shader simple lit 对比 Lit</strong></h2><p>SimpleLit Shader与Lit Shader的性能差异主要体现在光照模型的计算复杂度上。SimpleLit采用简化的Blinn-Phong光照模型，而Lit基于物理渲染（PBR），两者的性能差距和适用场景如下：</p><h3><strong>性能对比</strong></h3><ul><li><p>‌<strong>渲染效率</strong>‌</p><p>SimpleLit通过忽略物理正确性和能量守恒计算，相比Lit Shader可提升约30%-50%的渲染性能，尤其在低端移动设备上表现更显著。Lit Shader因需计算微表面模型（GGX+Smith）和复杂的光照交互，对GPU负担较大。</p></li><li><p>‌<strong>变体复杂度</strong>‌</p><p>Lit Shader支持更多材质属性（如金属度、粗糙度），导致Shader变体数量远高于SimpleLit，增加了内存和编译开销。SimpleLit的变体更少，适合需要快速迭代或大量实例化的场景。</p></li></ul><h3><strong>材质实现能力</strong></h3><ul><li><p>‌<strong>SimpleLit适用材质</strong>‌</p><ul><li>卡通风格表面（非PBR）</li><li>低多边形（Low Poly）美术风格</li><li>需要快速渲染的静态物体或背景元素</li><li>通过调整<code>_SpecColor</code>和<code>_Glossiness</code>实现简单高光效果，但不支持动态环境光遮蔽（AO）或复杂反射。</li></ul></li><li><p>‌<strong>Lit适用材质</strong>‌</p><ul><li>金属/非金属PBR材质（如真实感金属、石材）</li><li>需要动态光照和阴影的高质量场景</li><li>支持屏幕空间全局光照（SSGI）等高级特性。</li></ul></li></ul><h3><strong>选择建议</strong></h3><ul><li>‌<strong>性能优先</strong>‌：选择SimpleLit，尤其针对移动端或低端设备。</li><li>‌<strong>效果优先</strong>‌：需真实物理交互的场景（如角色、动态物体）使用Lit。</li></ul><p>两者均支持URP的GPU实例化和SRP Batcher优化，但SimpleLit在批量渲染时优势更明显.</p><h2>卡通风格 非PBR 材质实现</h2><h3><strong>核心实现原理</strong></h3><ul><li>‌<strong>基础光照模型</strong>‌：采用Simple Lit的Lambert漫反射+Blinn-Phong高光组合，通过阈值化处理实现色阶分离</li><li>‌<strong>边缘光增强</strong>‌：利用菲涅尔效应节点(Fresnel Effect Node)生成轮廓光，通过Power参数控制边缘宽度</li><li>‌<strong>色块分割</strong>‌：使用Step或SmoothStep函数对光照结果进行离散化处理，形成卡通风格的色块过渡</li></ul><h3><strong>关键参数说明</strong></h3><ul><li>‌_RampThreshold：控制阴影与亮部的分界阈值，值越小阴影区域越大</li><li>‌_RampSmooth：色块边缘的平滑过渡范围，设为0时产生硬边缘</li><li>‌_RimPower：调整边缘光衰减速度，值越大轮廓线越细</li><li><p>ToonSimpleLit.shader</p><pre><code class="c">Shader "Universal Render Pipeline/Simple Toon"
{
    Properties
    {
        _BaseColor("Base Color", Color) = (1,1,1,1)
        _BaseMap("Base Map", 2D) = "white" {}
        _ShadowColor("Shadow Color", Color) = (0.4,0.4,0.4,1)
        _RampThreshold("Ramp Threshold", Range(0,1)) = 0.5
        _RampSmooth("Ramp Smooth", Range(0.01,0.1)) = 0.01
        _SpecColor("Specular Color", Color) = (0.9,0.9,0.9,1)
        _SpecThreshold("Spec Threshold", Range(0,1)) = 0.5
        _SpecSmooth("Spec Smooth", Range(0,0.1)) = 0.02
        _RimPower("Rim Power", Range(0,10)) = 5
        _RimColor("Rim Color", Color) = (0.8,0.8,0.8,1)
    }

    SubShader
    {
        Tags { "RenderType"="Opaque" "RenderPipeline"="UniversalPipeline" }

        HLSLINCLUDE
        #include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl"
        #include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/Lighting.hlsl"

        TEXTURE2D(_BaseMap);
        SAMPLER(sampler_BaseMap);

        CBUFFER_START(UnityPerMaterial)
        float4 _BaseColor;
        float4 _BaseMap_ST;
        float4 _ShadowColor;
        float _RampThreshold;
        float _RampSmooth;
        float4 _SpecColor;
        float _SpecThreshold;
        float _SpecSmooth;
        float _RimPower;
        float4 _RimColor;
        CBUFFER_END

        struct Attributes
        {
            float4 positionOS : POSITION;
            float3 normalOS : NORMAL;
            float2 uv : TEXCOORD0;
        };

        struct Varyings
        {
            float4 positionCS : SV_POSITION;
            float2 uv : TEXCOORD0;
            float3 normalWS : TEXCOORD1;
            float3 viewDirWS : TEXCOORD2;
            float3 positionWS : TEXCOORD3;
        };

        Varyings ToonPassVertex(Attributes input)
        {
            Varyings output;
            VertexPositionInputs vertexInput = GetVertexPositionInputs(input.positionOS.xyz);
            output.positionCS = vertexInput.positionCS;
            output.uv = TRANSFORM_TEX(input.uv, _BaseMap);

            VertexNormalInputs normalInput = GetVertexNormalInputs(input.normalOS);
            output.normalWS = normalInput.normalWS;
            output.viewDirWS = GetWorldSpaceViewDir(vertexInput.positionWS);
            output.positionWS = vertexInput.positionWS;
            return output;
        }

        half4 ToonPassFragment(Varyings input) : SV_Target
        {
            // 基础纹理采样
            half4 baseMap = SAMPLE_TEXTURE2D(_BaseMap, sampler_BaseMap, input.uv);
            half3 baseColor = baseMap.rgb * _BaseColor.rgb;

            // 光照计算
            Light mainLight = GetMainLight();
            float3 lightDir = normalize(mainLight.direction);
            float3 normalWS = normalize(input.normalWS);
            float NdotL = dot(normalWS, lightDir);

            // 漫反射色阶化
            float diffuse = smoothstep(_RampThreshold - _RampSmooth, 
                                      _RampThreshold + _RampSmooth, 
                                      NdotL * 0.5 + 0.5);
            float3 diffuseColor = lerp(_ShadowColor.rgb, 1, diffuse) * baseColor;

            // 高光计算
            float3 viewDir = normalize(input.viewDirWS);
            float3 halfDir = normalize(lightDir + viewDir);
            float specular = pow(max(0, dot(normalWS, halfDir)), 32);
            specular = smoothstep(_SpecThreshold - _SpecSmooth,
                                 _SpecThreshold + _SpecSmooth,
                                 specular);
            float3 specularColor = specular * _SpecColor.rgb * mainLight.color;

            // 边缘光
            float rim = 1 - max(0, dot(viewDir, normalWS));
            rim = pow(rim, _RimPower);
            float3 rimColor = rim * _RimColor.rgb;

            // 最终合成
            float3 finalColor = diffuseColor * mainLight.color + specularColor + rimColor;
            return half4(finalColor, baseMap.a);
        }
        ENDHLSL

        Pass
        {
            Name "ToonPass"
            Tags { "LightMode"="UniversalForward" }

            HLSLPROGRAM
            #pragma vertex ToonPassVertex
            #pragma fragment ToonPassFragment
            ENDHLSL
        }
    }
}</code></pre></li></ul><h3><strong>扩展优化建议</strong></h3><ul><li>‌<strong>添加色阶贴图</strong>‌：使用1D纹理控制光照过渡曲线，实现更复杂的卡通色阶效果</li><li>‌<strong>描边效果</strong>‌：通过背面挤出法或后处理实现轮廓描边（需额外Pass）</li><li>‌<strong>材质变体</strong>‌：通过Shader变体支持不同风格切换（如赛璐璐/水彩风格）</li></ul><p>该Shader保留了URP轻量级特性，通过HLSL重写光照模型实现非PBR卡通效果，可直接在URP项目中使用。如需更复杂的艺术控制，可参考原神风格的贴图通道分配方案</p><h2><strong>性能优化建议</strong></h2><ul><li>‌<strong>变体控制</strong>‌：禁用不必要的Shader变体(如_SPECGLOSSMAP)减少内存占用</li><li>‌<strong>GPU Instancing</strong>‌：对相同材质的对象启用实例化减少Draw Call</li><li>‌<strong>纹理压缩</strong>‌：使用适当的压缩格式减少显存占用</li><li>‌<strong>LOD组合</strong>‌：与复杂Shader配合使用，根据距离切换SimpleLit</li></ul><p>SimpleLit Shader通过简化光照计算在保持基本视觉效果的同时显著提升渲染效率，特别适合移动平台和低端设备，是URP管线中平衡性能与效果的重要工具</p><hr/><blockquote><a href="https://link.segmentfault.com/?enc=J3mhePpq19OXgSxHAlThMg%3D%3D.Xx89dOF0SqCwTSFgjQx4%2FNSPJUQJUjPaZqE%2BkAziVuwX4U4PyYGCn45CStiQa52I4I13avJyStjEAy2oz7XTpIZ7towkma7jhTdeKFYu4Vt6IwyX4g1CkAWyMfwEn6%2ByeVvFeJprHPLioVuc%2BQTuNFw0%2B3IBCooejtq%2FuUj2SRzraffBfcCGWuDRhYDqjjw57Te7806wVTumGTlQeBGn%2BN3nM7kbG9OneTaJXqCnYJA%3D" rel="nofollow" target="_blank">【从UnityURP开始探索游戏渲染】</a><strong>专栏-直达</strong><br/>（欢迎<em>点赞留言</em>探讨，更多人加入进来能更加完善这个探索的过程，🙏）</blockquote>]]></description></item><item>    <title><![CDATA[【赵渝强老师】阿里云大数据集成开发平台D]]></title>    <link>https://segmentfault.com/a/1190000047437807</link>    <guid>https://segmentfault.com/a/1190000047437807</guid>    <pubDate>2025-11-29 12:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>DataWorks是阿里云重要的PaaS（Platform as a Service）平台产品，为用户提供数据集成、数据开发、数据地图、数据质量和数据服务等全方位的产品服务，一站式开发管理的界面，帮助企业专注于数据价值的挖掘和探索。</p><p>DataWorks支持多种计算和存储引擎服务，包括离线计算MaxCompute、开源大数据引擎E-MapReduce、基于Flink的实时计算、机器学习PAI、图计算服务Graph Compute和交互式分析服务等，并且支持用户自定义接入计算和存储服务。DataWorks可以为用户提供全链路智能大数据及AI开发和治理服务。</p><p>用户可以使用DataWorks，对数据进行传输、转换和集成等操作，从不同的数据存储引入数据，并进行转化和开发，最后将处理好的数据同步至其它数据系统。</p><p>视频讲解如下：<br/><a href="https://www.bilibili.com/video/BV1X5UvB6Epq/?aid=115616291888415&amp;cid=34285094320" target="_blank">https://www.bilibili.com/video/BV1X5UvB6Epq/?aid=115616291888...</a></p><p>DataWorks提供以下九个核心功能模块。</p><h2>一、 数据集成</h2><p>DataWorks的数据集成功能模块是稳定高效、弹性伸缩的数据同步平台，致力于提供复杂网络环境下、丰富的异构数据源之间高速稳定的数据移动及同步能力。DataWorks数据集成支持离线同步、实时同步，以及离线和实时一体化的全增量同步。其中：</p><ul><li>离线同步场景下，支持设置离线同步任务的调度周期。</li><li>支持数据库、数仓、NoSQL数据库、文件存储、消息队列等近50多种不同异构数据源之间的数据同步。</li><li>支持在各类复杂网络环境下，连通数据源的网络解决方案，在各种网络环境下均可使用DataWorks数据集成实现网络连通。</li><li>支持安全控制与运维监控，保障数据同步的安全、可控。</li></ul><p>下图展示了DataWorks的数据集成页面。<br/><img width="723" height="357" referrerpolicy="no-referrer" src="/img/bVdncTO" alt="image.png" title="image.png"/></p><h2>二、 数据加工</h2><p>DataWorks的数据开发是数据加工的开发平台，运维中心是数据加工的管理平台。基于这两个功能模块，用户可以在DataWorks上规范、高效地构建和运维数据开发工作流。<br/>DataWorks的数据开发平台可以使用工具DataStudio进行支持。DataStudio的数据开发工具提供的功能如下：</p><ul><li>DataStudio支持MaxCompute、EMR、CDH、Hologres、AnalyticDB、Clickhouse等多种计算引擎，支持在统一的平台上进行各类引擎任务的开发、测试、发布和运维等操作。</li><li>DataStudio支持智能编辑器、可视化依赖编排，调度能力经过阿里集团内调度任务、复杂业务依赖的反复验证。</li><li>DataStudio提供隔离的开发和生产环境，结合版本管理、代码评审、冒烟测试、发布管控、操作审计等配套功能，帮助企业规范地完成数据开发。</li></ul><p>下图展示了DataStudio数据开发工具的主页面。<br/><img width="723" height="407" referrerpolicy="no-referrer" src="/img/bVdncTP" alt="image.png" title="image.png" loading="lazy"/></p><p>DataWorks运维中心支持数据时效性保障、任务诊断、影响分析、自动运维、移动运维等功能。下图展示了DataWorks运维中心的主页面。<br/><img width="723" height="399" referrerpolicy="no-referrer" src="/img/bVdncTQ" alt="image.png" title="image.png" loading="lazy"/></p><h2>三、 数据建模</h2><p>数据建模是阿里云DataWorks自主研发的智能数据建模产品，沉淀了阿里巴巴十多年来数仓建模方法论的最佳实践，包含数仓规划、数据标准、维度建模及数据指标四大模块，帮助企业在搭建数据中台、数据集市建设过程中提升建模及逆向建模的能力，并通过数据建模快速构建企业数据资产。<br/>DataWorks数据建模可助力企业构建自身建模能力，挖掘企业的数据资产价值。它支持以下的场景：</p><ul><li><strong><em>海量数据的标准化管理</em></strong>：企业业务越庞大数据结构就越复杂，企业数据量会随着企业业务的快速发展而迅速增长，如何结构化有序地管理和存储数据是每个企业都将面临的一个挑战。</li><li><strong><em>业务数据互联互通，打破信息壁垒</em></strong>：公司内部各业务、各部门之间数据独立自主形成了数据孤岛，导致决策层无法清晰、快速地了解公司各类数据情况。如何打破部门或业务领域之间的信息孤岛是企业数据管理的一大难题。</li><li><strong><em>数据标准整合，统一灵活对接</em></strong>：同一数据不同描述，企业数据管理难、内容重复、结果不准确。如何制定统一的数据标准又不打破原有的系统架构，实现灵活对接上下游业务，是标准化管理的核心重点之一。</li><li><strong><em>数据价值最大化，企业利润最大化</em></strong>：在最大程度上用好企业各类数据，使企业数据价值最大化，为企业提供更高效的数据服务。</li></ul><p>下图展示了DataWorks数据建模的主页面。<br/><img width="723" height="353" referrerpolicy="no-referrer" src="/img/bVdncTS" alt="image.png" title="image.png" loading="lazy"/></p><h2>四、 数据分析</h2><p>数据分析基于“人人都是数据分析师”的产品目标，旨在为更多非专业数据开发人员，如数据分析、产品、运营等工作人员提供更加简洁高效的取数、用数工具，提升大家日常取数分析效率。数据分析支持基于个人视角的数据上传、公共数据集、表搜索与收藏、在线SQL取数、SQL文件共享、SQL查询结果下载及用电子表格进行大屏幕数据查看等产品功能。</p><p>下图展示了DataWorks数据分析的主页面。<br/><img width="723" height="472" referrerpolicy="no-referrer" src="/img/bVdncTT" alt="image.png" title="image.png" loading="lazy"/></p><h2>五、 数据质量</h2><p>DataWorks的全流程数据质量监控功能为用户提供多种预设表级别、字段级别和自定义的监控模板。数据质量可以帮助用户第一时间感知到源端数据的变更与ETL（Extract Transformation Load）中产生的脏数据，自动拦截问题任务，有效阻断脏数据向下游蔓延。<br/>数据质量以数据集（DataSet）为监控对象，支持监控MaxCompute数据表和DataHub实时数据流。当离线MaxCompute数据发生变化时，数据质量会对数据进行校验，并阻塞生产链路，以避免问题数据污染扩散。同时，数据质量提供历史校验结果的管理，以便用户对数据质量进行分析和定级。</p><p>下图展示了DataWorks数据质量管理中的任务查询页面。<br/><img width="723" height="322" referrerpolicy="no-referrer" src="/img/bVdncTU" alt="image.png" title="image.png" loading="lazy"/></p><h2>六、 数据地图</h2><p>DataWorks的数据地图功能可以实现对数据的统一管理和血缘的跟踪。数据地图以数据搜索为基础，提供表使用说明、数据类目、数据血缘、字段血缘等工具，帮助数据表的使用者和拥有者更好地管理数据、协作开发。下图展示DataWorks的数据地图。<br/><img width="723" height="364" referrerpolicy="no-referrer" src="/img/bVdncTW" alt="image.png" title="image.png" loading="lazy"/></p><h2>七、 数据服务</h2><p>DataWorks的数据服务功能模块是灵活轻量、安全稳定的数据API构建平台，旨在为企业提供全面的数据共享能力，帮助用户从发布审批、授权管控、调用计量、资源隔离等方面实现数据价值输出及共享开放。下图展示DataWorks的数据服务。<br/><img width="723" height="275" referrerpolicy="no-referrer" src="/img/bVdncT1" alt="image.png" title="image.png" loading="lazy"/></p><h2>八、 数据迁移</h2><p>DataWorks的数据迁移通过使用迁移助手支持将开源调度引擎的作业迁移至DataWorks，支持作业跨云、跨Region、跨账号迁移，实现DataWorks作业快速克隆部署，同时DataWorks团队联合大数据专家服务团队，上线迁云服务，帮助用户快速实现数据与任务的上云。下图展示DataWorks的数据迁移助手。<br/><img width="723" height="289" referrerpolicy="no-referrer" src="/img/bVdncT2" alt="image.png" title="image.png" loading="lazy"/></p><h2>九、 开放平台</h2><p>DataWorks开放平台是DataWorks对外提供数据和能力的开放通道。DataWorks开放平台提供开放API（OpenAPI）、开放事件（OpenEvent）、扩展程序（Extensions）的能力，可以帮助用户快速实现各类应用系统对接DataWorks、方便快捷的进行数据流程管控、数据治理和运维，及时响应应用系统对接DataWorks的业务状态变化。下图展示DataWorks的开放平台。<br/><img width="723" height="445" referrerpolicy="no-referrer" src="/img/bVdncT3" alt="image.png" title="image.png" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[Nessus 10.11 Auto In]]></title>    <link>https://segmentfault.com/a/1190000047437708</link>    <guid>https://segmentfault.com/a/1190000047437708</guid>    <pubDate>2025-11-29 11:02:06</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>Nessus Professional 10.11 Auto Installer for Ubuntu 24.04 - Nessus 自动化安装程序</p><p>发布 Nessus 试用版自动化安装程序，支持 macOS Tahoe、RHEL 10、Ubuntu 24.04 和 Windows</p><p>请访问原文链接：<a href="https://link.segmentfault.com/?enc=YKoGhVOnUPopZKKtiz3RmQ%3D%3D.uKg3%2Bt9wE6s5wDURj4D04vzjb9sxhP49qF6La8ql7f0c4Q8QuGG4AjWgEDV%2FOWrddPgmOmSJWyHs502YTtCoEw%3D%3D" rel="nofollow" target="_blank">https://sysin.org/blog/nessus-auto-install-for-ubuntu/</a> 查看最新版。原创作品，转载请保留出处。</p><p>作者主页：<a href="https://link.segmentfault.com/?enc=isIbKZGlCLHXPIXOuVa6lQ%3D%3D.4xYyykncfyqrYyRbALG%2FHq5gdykNjRyqxRhgPCWDmu4%3D" rel="nofollow" target="_blank">sysin.org</a></p><hr/><h2>Nessus 简介</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047436343" alt="Nessus" title="Nessus"/></p><p>Nessus Vulnerability Scanner</p><p><strong>漏洞评估领域的全球黄金标准</strong>，<strong>针对现代攻击面量身打造</strong>。</p><p>利用业界最受信赖的漏洞评估解决方案来评估现代攻击面。扩展到传统的 IT 资产之外 – 保护云基础设施和获取对与互联网相连的攻击面的可见性。</p><p><strong># 1 准确度</strong>：</p><p>Nessus 达到了 6 西格玛准确度，实现了业内最低的误报率</p><p>*每 100 万次扫描中仅有 0.32 次误报</p><p><strong># 1 覆盖面</strong>：</p><p>Nessus 拥有业内首屈一指的漏洞覆盖面深度和广度</p><p><strong># 1 采用率</strong>：</p><p>Nessus 深受数万家企业的信赖，全球下载次数达到 200 万次</p><p><strong># 1 口碑信誉</strong>：</p><p>口说无凭，无需赘言。为何全球安全专业人士对 Nessus 的信赖让您眼见为实</p><p><strong>Nessus 在漏洞评估领域一路领先</strong>！</p><p>从创立伊始，我们就与各类网络安全相关行业紧密协作。我们根据业界的反馈持续优化  Nessus，将其打造成市场中最准确全面的漏洞评估解决方案。20 年以来，我们不忘初心，始终专注于业界协作与产品创新  (sysin)，建立起最准确全面的漏洞数据库，让您的企业不会因忽视重要漏洞而暴露于风险之中。</p><p>今天，Nessus 深受全球数万家企业的信赖，是全球部署最为广泛的安全技术之一，而且是漏洞评估行业的黄金标准。</p><p><strong>94K+</strong> 个 CVE</p><p><strong>226,000+</strong> 款插件</p><p><strong>100+</strong> 款新插件，每周定期发布</p><p>Tenable 的零日研究对新漏洞和紧急漏洞提供全天候更新，因此您将始终具有全面的态势感知。</p><h2>自动化安装 Nessus 试用版</h2><p>Nessus 官方提供了试用版，可供个人学习和研究使用，主要功能没有限制，只是没有任何支持服务。网上文章冠以和谐版称之，是不存在的。个人学习和测试效果好，也是将来的潜在客户，Nessus 官方本来就支持试用的。</p><p>本程序只是将公开的方法简化一次性执行，降低试用门槛或者节约使用者的宝贵时间。运行效果如下：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047333548" alt="nessus-10-auto-installer" title="nessus-10-auto-installer" loading="lazy"/></p><h2>系统要求</h2><p>要求 Ubuntu x86_64 16.04 及更新版本，建议 24.04 或者 22.04（程序有支持 aarch64 的能力，但未发布）。</p><ul><li><a href="https://link.segmentfault.com/?enc=1d8TjoDGQdxk7ZRz%2FXo7Bw%3D%3D.NpPWkHzQhII6oqz9zfumGJH3PTzvtzNC%2Bivl7o3HOZ75UHb%2FSilsu0LkkXNq7%2BCI" rel="nofollow" target="_blank">Ubuntu 24.04 x86_64</a>（<a href="https://link.segmentfault.com/?enc=OTFAysRcWuzefpTKKcJ3ng%3D%3D.AF2%2FoNRRwpt1MW5VMlnz3nk1Viv0sUDlBDkFETSP15J2Vr%2By5CKDTNHm%2FFER%2F7R1" rel="nofollow" target="_blank">OVF</a>）</li><li><a href="https://link.segmentfault.com/?enc=qtFa3dJOYfSUjhoaLegIJQ%3D%3D.ctzZDyxkkFXWBnNXFV%2FE6rOO0PguEj4iuzsTXbc5ANtXh0CzoFH9tUsGsw6zEOwt" rel="nofollow" target="_blank">Ubuntu 22.04 x86_64</a>（<a href="https://link.segmentfault.com/?enc=uKQlodLZI3mPk0kXG8uKAg%3D%3D.bl%2FEcwB1v5Ny9ddSJzhyBMLkkTFXJPewL2HBTuzPNBlrGTFAJDmJjpt6XmQbTYRn" rel="nofollow" target="_blank">OVF</a>）</li><li><a href="https://link.segmentfault.com/?enc=EzL5TW%2Fz%2FcEeU6RgGdcEyA%3D%3D.yJ0jY795gXfJMv0Kz1exilrsolTwXJY%2BnylKiQxDh4ufeu1jYSCtqYA2KUeLFR02" rel="nofollow" target="_blank">Ubuntu 20.04 x86_64</a>（<a href="https://link.segmentfault.com/?enc=nESxu0r%2FVwx3SPPDJ0hpQw%3D%3D.%2FWmN7SGBedr94N7H7bId5rTg1aNs%2BtcAiB8%2FwEoo7gd%2BBlvemaFW1e7zjJPpSpJi" rel="nofollow" target="_blank">OVF</a>）</li></ul><p>建议运行在虚拟机环境中，<strong>推荐使用本站原创虚拟机模板 OVF</strong>，简单，精准，高效。</p><h2>下载地址</h2><p><strong>Nessus 10.11 Auto Installer</strong> for Ubuntu 22.04/24.04</p><ul><li>请访问：<a href="https://link.segmentfault.com/?enc=T7MWeTIvP9EqvzTYKprjDg%3D%3D.uUEVz%2FtrdeXdXtBMcnSeUWEeoXMJvP6xxXL8xvo8VIxR8tehcofXm8u%2FRX1E7W8h6eBGfCHB6YzBQGk0wBx5dA%3D%3D" rel="nofollow" target="_blank">https://sysin.org/blog/nessus-auto-install-for-ubuntu/</a></li></ul><hr/><p>发布 Nessus 试用版自动化安装程序，支持 macOS Tahoe、RHEL 10、Ubuntu 24.04 和 Windows</p><ul><li><a href="https://link.segmentfault.com/?enc=YzFhyqQnCBsp%2BxwhyndJVA%3D%3D.vRbfREEfVQhSTw3zoHBzzCdZPFp%2BPTTh6V74LEVoaHzpGdZbhnfwFqOVECXBpKcKNR2ziJflGkiFdzMeMoJFsg%3D%3D" rel="nofollow" target="_blank">Nessus Professional 10.11 Auto Installer for macOS Tahoe - Nessus 自动化安装程序</a></li><li><a href="https://link.segmentfault.com/?enc=WKvEFLEBpCLClUCKcUsCyQ%3D%3D.4yqvdH4wdvzgAbTT4OKhyKZyuMrcyhUEJs4PFwdlJxc8a2yjcFOj%2F5zSQ7TUOWU%2BVAEct8nMyEr7VJIPePpZhA%3D%3D" rel="nofollow" target="_blank">Nessus Professional 10.11 Auto Installer for RHEL 10, AlmaLinux 10, Rocky Linux 10 - Nessus 自动化安装程序</a></li><li><a href="https://link.segmentfault.com/?enc=TjoYlaXoTN%2B8VhCzzWpS4g%3D%3D.yV4gxr6uPXg%2F16XXMNbNLe36ZNsQZ0vcaG%2Bb0Gm5AaF7Js82IZ2WN%2BUvFP2vZFmAkFfzIOjqbfuPF2PEfLK1Yw%3D%3D" rel="nofollow" target="_blank">Nessus Professional 10.11 Auto Installer for Ubuntu 24.04 - Nessus 自动化安装程序</a></li><li><a href="https://link.segmentfault.com/?enc=T80vIq3dIaq4PxVEanf7gg%3D%3D.BObBAtpExbeT%2FUyL3LuIDtR10%2BTnKJo%2FI%2FCGZ7RREc6hovISU4o7wcxJtYA0POIf7X4rolYor5gRUoqYfsjG2w%3D%3D" rel="nofollow" target="_blank">Nessus Professional 10.11 Auto Installer for Windows - Nessus 自动化安装程序</a></li></ul><p>Nessus 10 系列版本下载</p><ul><li><a href="https://link.segmentfault.com/?enc=pAaAg%2B1b14oZLBKFsSUCWg%3D%3D.OJmNFOTWwqlY9B3HMqG2mQ%2BdsxJjvEAVQV0pu63f53P4y5ei%2Br3bW1tJc9joeqnW" rel="nofollow" target="_blank">Tenable Nessus 10.11 (macOS, Linux, Windows) - 漏洞评估解决方案</a></li></ul><p>更多：<a href="https://link.segmentfault.com/?enc=XIxFeW8vxKjQSLvtxENWvA%3D%3D.yN6%2F4BpSCaHDU4QpXn2IWQc8Qoy4%2FSh5izKm9Euqavo%3D" rel="nofollow" target="_blank">HTTP 协议与安全</a></p>]]></description></item>  </channel></rss>