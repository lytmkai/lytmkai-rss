<?xml version="1.0" encoding="UTF-8"?><rss version="2.0">  <channel>      <title>SegmentFault - 最近文章</title>      <link>https://segmentfault.com/blogs/newest</link>      <description>SegmentFault 思否</description>      <generator>python segmentfault.py @Pi20</generator>      <item>    <title><![CDATA[Apple iWork (Pages、Numbers、Keynote) 14.5 - 文档、电子表格]]></title>    <link>https://segmentfault.com/a/1190000047607268</link>    <guid>https://segmentfault.com/a/1190000047607268</guid>    <pubDate>2026-02-12 13:02:51</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>Apple iWork (Pages、Numbers、Keynote) 14.5 - 文档、电子表格、演示文稿</p><p>Pages 文稿 | Numbers 表格 | Keynote 演讲</p><p>请访问原文链接：<a href="https://link.segmentfault.com/?enc=mi2InGWffVvFKtDpYy791g%3D%3D.9X5cxGHEOc7bgurAqRxkcDDkHGp6A1s68lFzRrD0Wr4MWOTDNxKajwIWh5%2BY0W87" rel="nofollow" target="_blank">https://sysin.org/blog/apple-iwork-14/</a> 查看最新版。原创作品，转载请保留出处。</p><p>作者主页：<a href="https://link.segmentfault.com/?enc=IB0ByKIgNwcyjWLxMNm7ug%3D%3D.FGllxvYTy%2FI2T4sSesyOac82Rv1QKgdllKYac7ezhrA%3D" rel="nofollow" target="_blank">sysin.org</a></p><hr/><p>Apple 今天将其专为 iOS 和 macOS 设备设计的 iWork 应用套件更新为版本 14.5，本更新包括错误修复和性能提升。</p><p><strong>文档、电子表格、演示文稿，尽可集思广益。</strong></p><p>Pages 文稿、Numbers 表格和 Keynote 讲演是创建精彩作品的理想工具。模板和设计工具让你能够轻松上手。你甚至还能用  Apple Pencil 在你的 iPad 上添加插图和标注。而通过实时协作功能，整个团队成员无论用的是 Mac、iPad、iPhone 还是  PC，都能一起工作。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000044797948" alt="iWork" title="iWork"/></p><h2>Pages 文稿</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000046420252" alt="Pages - 文稿" title="Pages - 文稿" loading="lazy"/></p><p><strong>文档高手，精美不言而喻。</strong></p><p>Pages 文稿让你轻而易举就可创建赏心悦目的文档。挑选一个模板，然后使用强大的工具添加图片、影片、形状或图表。制作令人心旷神怡的读物，就是如此轻松。</p><p>进一步了解 Pages 文稿：<code>https://www.apple.com.cn/pages/</code></p><h2>Numbers 表格</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000046420253" alt="Numbers - 表格" title="Numbers - 表格" loading="lazy"/></p><p><strong>精妙的表格，总是格外出众。</strong></p><p>电子表格不一定非要看起来像个乏味的账本，因此，Numbers 表格用空白画布代替无数的条条框框 (sysin)。从一开始，你就可轻松添加引人注目的图表、表格和图像，再加上智能分类和数据透视表功能，你能把数据更为生动形象地呈现在眼前。</p><p>进一步了解 Numbers 表格：<code>https://www.apple.com.cn/numbers/</code></p><h2>Keynote 讲演</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000046420254" alt="Keynote - 演讲" title="Keynote - 演讲" loading="lazy"/></p><p><strong>印象深刻的提案，眼前一亮。</strong></p><p>使用 Keynote 讲演，无论你是独立创作还是与团队协作，都能轻松制作和演示绚丽夺目的演示文稿 (sysin)。得益于强大的图形工具，你能设计精美的文本和酷炫的幻灯片，并添加引人入胜的影院级过渡效果，把你的创意活灵活现地展示出来。</p><p>进一步了解 Keynote 讲演：<code>https://www.apple.com.cn/keynote/</code></p><p>💡 Apple 网页页脚：</p><ul><li>iOS 版 Pages 文稿、iOS 版 Numbers 表格和 iOS 版 Keynote 讲演于 App Store 提供。需要使用 iOS 14 或更新版本。下载 app 需要使用 Apple ID。</li><li>iPadOS 版 Pages 文稿、iPadOS 版 Numbers 表格和 iPadOS 版 Keynote 讲演于 App Store 提供。需要使用 iPadOS 14 或更新版本。下载 app 需要使用 Apple ID。</li><li>Mac 版 Pages 文稿、Mac 版 Numbers 表格和 Mac 版 Keynote 讲演于 Mac App Store 提供。需要使用 macOS 11 或更新版本。下载 app 需要使用 Apple ID。</li><li>部分功能可能需要接入互联网；可能需要支付额外费用和遵守相应条款。</li><li>功能可能会有所变化。iCloud 版 iWork  目前向全球提供阿拉伯语、巴西葡萄牙语、简体中文、繁体中文、丹麦语、荷兰语、芬兰语、法语、德语、希伯来语、意大利语、日语、韩语、挪威语、波兰语、葡萄牙语、西班牙语、瑞典语和美国英语版本，需要使用 iCloud 账户和互联网连接。iCloud 版 iWork 可与使用 Safari 9.1.3 或更新版本、Google Chrome 或  Microsoft Edge 的 Mac 或 PC 配合使用。</li><li>iCloud 在中国内地由云上贵州 (云上艾珀 (贵州) 技术有限公司) 运营。</li></ul><h2>更新内容</h2><p>Pages 14.5，2026 年 1 月 29 日</p><p>Numbers 14.5，2026 年 1 月 29 日</p><p>Keynote 14.5，2026 年 1 月 29 日</p><p>本更新包括错误修复和性能提升。</p><hr/><p>Pages 14.0，2024-04-02</p><ul><li>在 iPad 上，按住已连接键盘上的 Command 键并使用触控板或鼠标来选择非连续文字、句子或段落</li><li>改进的 App 内通知可在用户首次加入协作文稿时通知你</li><li>添加 iPhone 或 iPad 拍摄的 HEIC 照片时保留文件格式和完整质量</li><li>其他稳定性和性能提升</li></ul><p>Numbers 14.0，2024-04-02</p><ul><li>改进的 App 内通知可在用户首次加入协作电子表格时通知你</li><li>添加 iPhone 或 iPad 拍摄的 HEIC 照片时保留文件格式和完整质量</li><li>在 iPad 上，按住已连接键盘上的 Command 键并使用触控板或鼠标来选择非连续文字、句子或段落</li><li>其他稳定性和性能提升</li></ul><p>Keynote 14.0，2024-04-02</p><ul><li>通过 “动态颜色”、“极简浅色” 和 “极简深色” 主题给幻灯片添加新的外观</li><li>改进的 App 内通知可在用户首次加入协作演示文稿时通知你</li><li>添加 iPhone 或 iPad 拍摄的 HEIC 照片时保留文件格式和完整质量</li><li>在 iPad 上，按住已连接键盘上的 Command 键并使用触控板或鼠标来选择非连续文字、句子或段落</li><li>提高了导入和导出 Microsoft PowerPoint 文件时幻灯片过渡的兼容性</li><li>其他稳定性和性能提升</li></ul><h2>下载地址</h2><p>Apple iWork（Pages、Numbers、Keynote）14.0 Universal</p><ul><li>系统要求 macOS Ventura 13.0 or later</li></ul><p><strong>Apple iWork（Pages、Numbers、Keynote）14.5</strong> Universal</p><ul><li>请访问：<a href="https://link.segmentfault.com/?enc=Wvgzk%2FPchxCpuyhlfqLQsA%3D%3D.AKQ6VP1THxdZ8QcWbzhYjc0bcCfrUjLN0VkxtTmidz3ov168Yb45wvFrO55dqn6I" rel="nofollow" target="_blank">https://sysin.org/blog/apple-iwork-14/</a></li><li>系统要求 macOS Sonoma 14.0 or later</li></ul><p>更多：<a href="https://link.segmentfault.com/?enc=2ywdx3MBrNdiKOK3FDwNnQ%3D%3D.6nTDjnA7airIF0HIFitDR2PacIsQpucEiwrMMOXPj2Y%3D" rel="nofollow" target="_blank">macOS 下载汇总 (系统、应用和教程)</a></p>]]></description></item><item>    <title><![CDATA[2026年智旅新纪元AI旅游产业融合全景报告：智慧化、个性化、可持续|附240+份报告PDF、数据、]]></title>    <link>https://segmentfault.com/a/1190000047607278</link>    <guid>https://segmentfault.com/a/1190000047607278</guid>    <pubDate>2026-02-12 13:01:59</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>原文链接：<a href="https://link.segmentfault.com/?enc=hDDZ%2FWjSx73QqyCyxx8ETw%3D%3D.ugDoO781JCIojddFyPMwTDgeGEojqAkWGkn2xwNsmWU%3D" rel="nofollow" title="https://tecdat.cn/?p=44972" target="_blank">https://tecdat.cn/?p=44972</a>  <br/>原文出处：拓端抖音号@拓端tecdat</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607280" alt="封面" title="封面"/></p><h3><a name="t1" target="_blank"/>引言</h3><p>旅游文旅产业正处于数字化转型与体验升级的关键转型期，疫情后行业的强势复苏叠加消费需求的多元化、个性化迭代，让产业发展迎来新机遇的同时，也面临着体验同质化、管理效率低、成本控制难、全球化布局受阻等多重行业痛点。人工智能的爆发式发展，成为破解文旅产业发展痛点的核心抓手，从游客端的个性化行程定制、智能体验升级，到运营端的智慧目的地管理、差旅成本优化，再到产业端的可持续发展布局、全球资源整合，AI正从辅助工具升级为核心驱动力，全面重构旅游文旅产业的价值链与竞争格局。</p><p>本报告基于文旅产业发展的实际需求，深度整合全球权威机构的研究成果，从宏观经济、行业效率、精细化管理、全球趋势四大维度，拆解AI与旅游文旅融合的核心路径与落地场景。本报告洞察基于《Four Scenarios for the Future of Travel and Tourism》《欧洲旅游委员会：Artificial Intelligence (AI) in Tourism》《BCD Travel：2026年全球旅游市场展望报告》《中国旅游协会：“中国服务”河南模式研究报告(2025)》《中智游科技：县区全域文旅智慧化解决方案》《PwC：AI at the heart of tourism and hospitality》《世界经济论坛：Travel and Tourism at a Turning Point: Principles for Transformative Growth》和<strong>文末</strong>240+份旅游文旅及AI行业研究报告及数据，本文完整报告数据图表和<strong>文末</strong>最新参考报告合集已分享在交流群，阅读原文查看、进群咨询，定制数据、报告和800+行业人士共同交流和成长。</p><p>旅游文旅与AI的深度融合并非技术的单向赋能，而是产业需求与技术发展的双向契合。传统文旅产业的运营模式，难以解决游客需求与产品供给的信息不对称、目的地客流调控的精准性不足、企业差旅管理的规模化效率低等问题，而AI技术的迭代，让生成式内容创作、实时客流预测、智能跨境调度等应用成为现实，推动文旅产业从“被动响应市场需求”向“主动预判用户需求”转型。本报告将结合真实行业数据与落地场景，全方位拆解AI如何重塑旅游文旅产业，以及不同产业角色如何抓住AI融合的变革机遇。</p><h3><a name="t2" target="_blank"/>一、宏观经济与行业复苏：AI融合的基础土壤</h3><p>旅游文旅行业的全面复苏，为AI技术的场景化落地奠定了坚实的市场基础，而中国经济的稳固发展则成为行业复苏的核心支撑。2025年一季度实际GDP同比增长5.4%，1-7月社会消费品零售总额增长4.8%，内需市场的持续回暖直接带动旅游消费的复苏升级；同时2024年非金融类对外直接投资增长10.5%，企业出海步伐的加快为差旅市场注入全新增长活力。核心宏观经济数据勾勒出文旅行业复苏的底层逻辑，也为AI技术划定了国内个性化体验、跨境差旅服务两大核心应用赛道。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607281" alt="" title="" loading="lazy"/></p><p>差旅市场宏观经济指标刻度线图表1数据EXCEL及图表PDF模板已分享到会员群  <br/>3秒解读：中国经济“双轮驱动”——内需复苏+出海扩张，为旅游文旅AI应用提供了消费基础和场景增量。  <br/>对应人群行动建议：文旅企业可优先布局国内个性化体验AI工具，差旅服务商需强化跨境AI预订与合规管理功能。  <br/>行业复苏背后，差旅需求的结构性变化成为倒逼AI技术落地的核心动因，境内外差旅需求的差异化增长，让传统人工管理模式难以适配行业发展。境内差旅频次增加企业占比从2024年的30%升至2025年的37.66%，出海商旅量同比增长72%，携程国际业务预订增长60%，规模化、跨区域的差旅需求，对行程调度、资源匹配、成本管控提出了更高要求，AI的智能化统筹能力成为行业发展的刚需。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607282" alt="" title="" loading="lazy"/></p><p>差旅需求指标时间增长对比多边形条形图表2数据EXCEL及图表PDF模板已分享到会员群  <br/>3秒解读：出境和国际化需求成为差旅市场增长引擎，传统管理模式难以应对规模化、跨区域的服务需求。  <br/>对应人群行动建议：差旅管理公司可快速上线AI跨境行程优化工具，企业行政部门可引入AI差旅成本分析系统。</p><hr/><p><strong>相关文章</strong>  <br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047607283" alt="" title="" loading="lazy"/>  <br/>相关文章配图数据EXCEL及图表PDF模板已分享到会员群</p><h3><a name="t3" target="_blank"/>专题：2025年游戏科技的AI革新研究报告：全球市场趋势研究报告|附130+份报告PDF、数据仪表盘汇总下载</h3><p>原文链接：<a href="https://link.segmentfault.com/?enc=%2Bs2ScM2nXdNYDxrvP9A3bw%3D%3D.f93qWhLbODHeYRPI%2FvKB5nve%2Fy5WzjcxbEjB0AXcWoo%3D" rel="nofollow" title="https://tecdat.cn/?p=44082" target="_blank">https://tecdat.cn/?p=44082</a></p><hr/><h3><a name="t4" target="_blank"/>二、AI重构行业效率：从成本优化到体验升级</h3><p>AI技术正在旅游文旅行业掀起一场“效率革命”，从前端的预订服务到后端的运营管理，实现全链路的效率提升与成本优化，成为文旅产业降本增效的核心利器。最直观的价值体现在差旅预订环节，AI助手将员工差旅预订时间从15分钟压缩至3分钟，效率提升80%；某医药企业通过AI智能奖励机制实现差旅成本降低22%；2024年携程商旅通过AI优化酒店直采，成本降低18%，三组核心数据直观印证了AI在成本控制与效率提升上的实际价值，也让行业看到了AI技术落地的可量化收益。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607284" alt="" title="" loading="lazy"/></p><p>AI效率提升华夫图表3数据EXCEL及图表PDF模板已分享到会员群  <br/>3秒解读：AI在预订效率、成本控制上的提升立竿见影，能快速为企业带来可量化的收益。  <br/>对应人群行动建议：中小企业可优先引入成熟的AI差旅预订工具，大型企业可定制化开发AI成本优化系统。  <br/>AI技术的规模化落地，离不开产业端的用户接受度与管理层的战略部署，双重认可推动AI从试点应用走向行业普及。2025年亚太地区员工对AI预订工具的接受度达78%，意味着行业终端用户已完成AI使用的认知与准备；全球61%的CEO积极部署AI在旅游文旅相关业务中，管理层的战略推动让AI技术实现规模化落地。而AI技术的投入也带来了显著的商业回报，2024年Q3携程酒店住宿预订收入增长22%，AI驱动的个性化推荐、智能客服成为业务增长的核心动力。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607285" alt="" title="" loading="lazy"/></p><p>AI采纳率半圆环图表4数据EXCEL及图表PDF模板已分享到会员群  <br/>3秒解读：员工与管理层对AI的双重认可，让技术从“试点”走向“普及”，成为行业竞争的必备要素。  <br/>对应人群行动建议：文旅企业可开展全员AI工具培训，目的地管理者可试点AI客流监测系统并逐步推广。  <br/>在出海差旅这一核心增长赛道，AI的定制化能力成为解决行业分化需求的关键，不同行业的出海差旅需求差异显著，通用型管理工具已无法适配。2024年出海商旅量较2019年增长144%，其中汽车制造业出海差旅量同比增长498%，软件和信息技术服务业出海订单量增长169%，其他行业则有23%的负增长，行业间的需求分化要求差旅服务实现精准化、定制化，而AI的个性化分析与适配能力成为破局核心。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607286" alt="" title="" loading="lazy"/></p><p>出海增长率瀑布图表5数据EXCEL及图表PDF模板已分享到会员群  <br/>3秒解读：出海差旅呈现“行业分化”特征，通用型工具难以满足需求，AI的定制化能力成为关键。  <br/>对应人群行动建议：行业垂直差旅服务商可开发细分领域AI解决方案，出海企业可接入AI目的地合规查询工具。  <br/>出海差旅的目的地格局呈现“核心集中+新兴崛起”的特征，足迹从传统热门区域向新兴市场延伸，对信息整合能力提出更高要求，AI成为企业出海差旅的“核心导航工具”。新加坡仍是TOP1目的地，订单占比达35%；东南亚因地理邻近性成为61.5%企业的出差选择，订单占比25%；而在“一带一路”政策推动下，中亚地区如乌兹别克斯坦热度指数达79.7，订单占比15%，新兴目的地的差旅需求快速增长。AI通过整合目的地资源、政策动态、安全信息，帮助企业快速适应新市场的复杂环境，降低信息不对称风险。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607287" alt="" title="" loading="lazy"/></p><p>目的地热度气泡图表6数据EXCEL及图表PDF模板已分享到会员群  <br/>3秒解读：出海差旅足迹从传统热门区域向新兴市场延伸，信息不对称风险增加，AI成为“目的地导航”核心工具。  <br/>对应人群行动建议：差旅服务商可强化新兴目的地AI信息整合功能，企业可利用AI评估新兴市场差旅风险。</p><h3><a name="t5" target="_blank"/>三、成本与合规：AI驱动的精细化管理</h3><p>差旅各环节成本的温和上涨，让文旅企业的成本管控压力持续增加，传统“一刀切”的成本控制方式已失效，AI的精准化、精细化管理能力成为行业的核心选择。2026年全球酒店平均每日房价预测增长4.9%，全球航空平均票价增长1.1%，国际差旅成本呈现温和上涨态势；而2025年境内高铁成本上调企业占比达42.31%，境内差旅的成本压力更为突出，境内外成本变化的差异化特征，要求AI工具具备分场景、精准化的优化能力。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607288" alt="" title="" loading="lazy"/></p><p>成本增长率折线图表7数据EXCEL及图表PDF模板已分享到会员群  <br/>3秒解读：差旅各环节成本均呈上涨趋势，传统“一刀切”的成本控制方式失效，AI的精准优化能力凸显。  <br/>对应人群行动建议：企业可通过AI分析差旅数据，识别成本优化痛点；差旅服务商可推出AI动态定价推荐功能。  <br/>AI在文旅行业成本控制中的应用已形成成熟的落地路径，从采购端到执行端构建全链路成本管控体系，多维度案例验证了技术的实际有效性。某制造业通过酒店集采AI智能匹配，费用下降10%；2025年TMC市场交易金额增长近50%，集中化采购结合AI议价，大幅提升了行业整体的资源议价能力；企业通过AI系统强化差旅预算执行，相关执行强化比例达75%，AI技术让文旅企业的成本管控实现从“粗放式”到“精细化”的转型。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607289" alt="" title="" loading="lazy"/></p><p>成本节约横向比例条形图表8数据EXCEL及图表PDF模板已分享到会员群  <br/>3秒解读：集中采购+AI工具+预算管控，构成差旅成本控制的“铁三角”，缺一不可。  <br/>对应人群行动建议：中小企业可优先加入TMC集采平台享受AI议价红利，大型企业可构建“AI预算+AI采购”双系统。  <br/>在目的地运营层面，政策引导下的智慧化建设成为行业发展的核心方向，全域旅游示范区评审标准明确了AI技术的落地重点，让智慧化建设有标可循。全域旅游示范区评审设置了体制机制、政策保障、公共服务、供给体系等八个维度，其中公共服务占230分、创新示范占200分，位列前两位，政策导向清晰推动目的地加速AI技术落地，从智能导览、客流监测到应急调度，AI成为提升目的地评审分数、增强核心竞争力的核心抓手。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607290" alt="" title="" loading="lazy"/></p><p>智慧化评审标准雷达图表9数据EXCEL及图表PDF模板已分享到会员群  <br/>3秒解读：政策引导下，目的地智慧化建设聚焦“公共服务”与“创新示范”，AI是核心落地技术。  <br/>对应人群行动建议：目的地管理者可按评审维度，优先部署AI导览、客流监测等高频应用；文旅企业可对接目的地智慧平台，获取精准流量。  <br/>县域文旅市场成为文旅产业发展的重要赛道，头部县域的竞争呈现白热化特征，传统资源优势已难以形成壁垒，AI驱动的运营效率成为核心竞争力。2025年全国县域文旅融合综合竞争力指数（CTDI）前10名分数高度集中，大理市以100.00分位列第一，景洪市99.96分、平遥县99.93分紧随其后，头部县域的差距不足0.1分，而AI在内容创作、客流调控、产品创新中的应用，成为县域文旅拉开竞争差距的核心要素。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607291" alt="" title="" loading="lazy"/></p><p>县域指数热图表10数据EXCEL及图表PDF模板已分享到会员群  <br/>3秒解读：县域文旅竞争白热化，传统资源优势难以形成壁垒，AI驱动的运营效率成为核心竞争力。  <br/>对应人群行动建议：县域文旅部门可引入AI内容生成工具，提升宣传效果；本地文旅企业可开发AI个性化体验产品。</p><h3><a name="t6" target="_blank"/>四、全球视野与未来趋势：AI定义行业新生态</h3><p>从全球视角来看，旅游文旅行业展现出强劲的复苏韧性与长期增长潜力，行业的规模化发展对技术支撑提出更高要求，AI成为支撑行业全球化发展的核心基础设施。2019年全球旅游GDP贡献达10.3万亿美元，2020年受疫情冲击降至5.3万亿美元，降幅达48.5%；而随着全球经济的逐步复苏，2034年这一数值预计将达到16万亿美元，较2020年增长202%。文旅行业“断崖式下跌+跨越式增长”的发展走势，让行业意识到传统运营模式已无法支撑规模化、全球化发展，AI的技术赋能成为行业发展的必然选择。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607292" alt="" title="" loading="lazy"/></p><p>全球旅游趋势桑基图表11数据EXCEL及图表PDF模板已分享到会员群  <br/>3秒解读：全球旅游业从疫情冲击中快速复苏，长期增长趋势明确，AI将成为支撑行业规模化发展的核心基础设施。  <br/>对应人群行动建议：跨国文旅企业可布局全球AI数据平台，投资者可关注AI旅游服务商的长期价值。  <br/>全球旅游目的地的竞争力格局中，亚洲城市占据主导地位，智慧化建设与AI技术的深度融合，成为提升目的地竞争力的核心加分项。2025年旅游目的地竞争潜力指数排名中，新加坡以86分稳居第一，迪拜82分、东京81分、巴塞罗那81分并列第二，北京以79分跻身前五。这些核心城市均已实现AI技术的深度落地，新加坡的智能通关系统、东京的AI个性化行程推荐、北京的智慧景区管理，不仅显著提升了游客的体验感，也为全球文旅目的地的智慧化建设树立了标杆。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607293" alt="" title="" loading="lazy"/></p><p>目的地竞争力条形图表12数据EXCEL及图表PDF模板已分享到会员群  <br/>3秒解读：亚洲城市成为全球旅游竞争力标杆，智慧化与AI应用是重要加分项。  <br/>对应人群行动建议：中国目的地可借鉴新加坡、东京的AI应用经验，重点提升通关、导览等环节的智能化水平；文旅企业可开发亚洲城市AI联程旅游产品。</p><h3><a name="t7" target="_blank"/>五、核心洞察与落地行动</h3><h4><a name="t8" target="_blank"/>（一）不同报告核心结论对比表</h4><table><thead><tr><th>主题</th><th>报告名称</th><th>核心结论</th><th>数据差异</th><th>原因分析</th></tr></thead><tbody><tr><td>AI在旅游中的应用率</td><td>欧洲旅游委员会《Artificial Intelligence (AI) in Tourism》</td><td>91%的NTO正在试点或使用AI，仅3%实现全面落地</td><td>与PwC报告“94%企业试点AI”存在3%差异</td><td>统计范围不同：前者聚焦欧洲NTO，后者覆盖中东旅游 hospitality全行业</td></tr><tr><td>AI对成本的影响</td><td>PwC《AI at the heart of tourism and hospitality》</td><td>85%的企业报告成本节约和效率提升</td><td>与携程商旅“直采成本降低18%”无直接冲突</td><td>统计维度不同：前者是整体效率提升，后者是单一环节成本下降</td></tr><tr><td>旅游GDP增长预测</td><td>世界经济论坛《Travel and Tourism at a Turning Point》</td><td>2034年全球旅游GDP将达16万亿美元</td><td>无直接数据差异</td><td>统计口径一致：均为全球旅游文旅行业直接+间接GDP贡献</td></tr></tbody></table><h4><a name="t9" target="_blank"/>（二）可落地的3件事</h4><ol><li>文旅企业下周上线AI内容生成工具，聚焦本地特色景点、美食的短视频和图文创作，同步接入AI客服应对咨询高峰，快速提升宣传效率和用户体验。</li><li>目的地管理者在1个月内完成AI客流监测系统试点，选取核心景区部署智能摄像头和数据分析平台，实现客流实时预警，避免拥挤风险。</li><li>差旅服务商在3个月内推出AI跨境差旅解决方案，整合目的地合规信息、动态定价、行程优化功能，重点服务汽车制造、软件信息等出海热门行业。</li></ol><h4><a name="t10" target="_blank"/>（三）风险提示与应对方案</h4><ol><li>风险是AI数据安全与合规风险，旅游文旅行业涉及大量游客个人信息，易引发隐私泄露。具体应对方案为采用本地部署或合规云服务，符合GDPR、中国个人信息保护法等相关规定；社群支持方面，可加入行业交流群，获取合规模板和技术方案，规避法律风险。</li><li>风险是AI技能缺口，行业从业人员缺乏AI工具使用能力，导致技术落地效果不佳。具体应对方案为开展全员AI工具培训，重点讲解差旅预订、内容创作、客流分析等高频应用，对接专业培训机构为核心员工提供进阶课程；社群支持方面，群内可共享培训资料与实操教程，助力从业人员快速上手。</li><li>风险是AI同质化应用，多数企业盲目跟风部署AI，缺乏差异化，难以形成竞争优势。具体应对方案为基于自身核心业务场景定制AI功能，如县域文旅聚焦本地文化AI传播，差旅服务商聚焦垂直行业解决方案；社群支持方面，群内可交流成功案例与差异化布局思路，避免重复建设。</li></ol><h3><a name="t11" target="_blank"/>六、核心数据表格汇总</h3><h4><a name="t12" target="_blank"/>表1：AI在旅游文旅行业的核心应用效果</h4><table><thead><tr><th>应用场景</th><th>效率提升/成本降低幅度</th><th>数据来源</th></tr></thead><tbody><tr><td>差旅预订效率</td><td>80%（从15分钟降至3分钟）</td><td>途美商旅报告</td></tr><tr><td>差旅成本控制</td><td>22%（某医药企业）</td><td>途美商旅报告</td></tr><tr><td>酒店直采成本</td><td>18%</td><td>携程商旅报告</td></tr><tr><td>AI工具接受度</td><td>78%（亚太地区员工）</td><td>BCD Travel报告</td></tr><tr><td>NTO AI应用率</td><td>91%（试点或使用）</td><td>欧洲旅游委员会报告</td></tr></tbody></table><h4><a name="t13" target="_blank"/>表2：全球旅游GDP贡献变化（万亿美元）</h4><table><thead><tr><th>年份</th><th>GDP贡献</th><th>同比变化</th></tr></thead><tbody><tr><td>2019</td><td>10.3</td><td>-</td></tr><tr><td>2020</td><td>5.3</td><td>-48.5%</td></tr><tr><td>2034（预测）</td><td>16</td><td>+202%（较2020年）</td></tr></tbody></table><h4><a name="t14" target="_blank"/>表3：2025年旅游目的地竞争潜力指数TOP5</h4><table><thead><tr><th>城市</th><th>竞争潜力指数（分）</th><th>核心优势</th></tr></thead><tbody><tr><td>新加坡</td><td>86</td><td>智能通关、AI导览完善</td></tr><tr><td>迪拜</td><td>82</td><td>基础设施先进、智慧化水平高</td></tr><tr><td>东京</td><td>81</td><td>文化吸引力强、个性化服务成熟</td></tr><tr><td>巴塞罗那</td><td>81</td><td>旅游资源丰富、AI营销出色</td></tr><tr><td>北京</td><td>79</td><td>历史文化深厚、智慧景区建设领先</td></tr></tbody></table><h4><a name="t15" target="_blank"/>表4：出海差旅核心行业增长数据（2024年）</h4><table><thead><tr><th>行业</th><th>出海商旅量增长率</th><th>数据来源</th></tr></thead><tbody><tr><td>汽车制造业</td><td>498%</td><td>Trip.Biz携程商旅报告</td></tr><tr><td>软件和信息技术服务业</td><td>169%</td><td>Trip.Biz携程商旅报告</td></tr><tr><td>全行业整体</td><td>144%（较2019年）</td><td>Trip.Biz携程商旅报告</td></tr></tbody></table><h4><a name="t16" target="_blank"/>表5：2025年县域文旅融合综合竞争力指数TOP3</h4><table><thead><tr><th>县域</th><th>CTDI指数</th><th>数据来源</th></tr></thead><tbody><tr><td>大理市</td><td>100.00</td><td>迈点研究院报告</td></tr><tr><td>景洪市</td><td>99.96</td><td>迈点研究院报告</td></tr><tr><td>平遥县</td><td>99.93</td><td>迈点研究院报告</td></tr></tbody></table><h3><a name="t17" target="_blank"/>七、数据图表列表</h3><ol><li>差旅市场宏观经济指标刻度线图表1</li><li>差旅需求指标时间增长对比多边形条形图表2</li><li>相关文章配图</li><li>AI效率提升华夫图表3</li><li>AI采纳率半圆环图表4</li><li>出海增长率瀑布图表5</li><li>目的地热度气泡图表6</li><li>成本增长率折线图表7</li><li>成本节约横向比例条形图表8</li><li>智慧化评审标准雷达图表9</li><li>县域指数热图表10</li><li>全球旅游趋势桑基图表11</li><li>目的地竞争力条形图表12</li></ol><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607280" alt="封面" title="封面" loading="lazy"/></p><h3><a name="t18" target="_blank"/>本专题内的参考报告（PDF）目录</h3><ul><li>旅游促营商–投资摩洛哥.pdf</li><li>2026-02-10 15:55</li><li>旅游促进发展：从十年世界银行经验中汲取的教训.pdf</li><li>2026-02-10 15:54</li><li>世界银行：2026年旅游促进发展报告-从十年世界银行经验中汲取的教训.pdf</li><li>2026-02-09 14:25</li><li>中诚信国际：中国旅游行业展望，2026年2月.pdf</li><li>2026-02-09 14:24</li><li>美亚航旅＆amp旅讯数据：2026机票代理人的进化蓝图白皮书.pdf</li><li>2026-02-08 10:03</li><li>旅游服务行业：Booking反垄断启示录——告别“价格平价”，巨头如何重塑护城河？.pdf</li><li>2026-02-06 16:42</li><li>旅游及景区行业深度报告：海南专题报告：风宜长物放眼量，自贸港赶海正当时.pdf</li><li>2026-02-05 17:08</li><li>中关村中恒文化科技创新服务联盟：2026中国低空文旅产业发展研究报告.pdf</li><li>2026-02-04 16:38</li><li>力行致远 — 践行脱碳：制浆造纸业通往净零排放之旅.pdf</li><li>2026-02-04 16:33</li><li>2025年11月世界旅游晴雨表.pdf</li><li>2026-02-01 13:33</li><li>小红书新春市行业玩法-集酒旅行业专场.pdf</li><li>2026-01-30 15:57</li><li>2026马年年度活动规划（年度营销、商业地产、文旅景区、企业通用版）.pdf</li><li>2026-01-29 14:41</li><li>【慧科讯业Wisers】2026元旦春节文旅消费者洞察报告.pdf</li><li>2026-01-27 15:54</li><li>艺恩数据：2026年智旅新纪元：AI与旅游产业融合全景报告.pdf</li><li>2026-01-25 12:35</li><li>去运动，去旅行！-马蜂窝旅行.pdf</li><li>2026-01-24 17:38</li><li>旅游新国潮.pdf</li><li>2026-01-15 15:36</li><li>旅行重构：解码印度旅行者.pdf</li><li>2026-01-14 16:12</li><li>【北二外】AI旅游行程助手类产品能力评测报告.pdf</li><li>2026-01-13 17:25</li><li>2025中国夜间经济发展报告-中国旅游研究院夜间经济课题组.pdf</li><li>2026-01-12 15:09</li><li>社会服务行业深度报告：服务消费深度研究-旅游景区商超百货：量化投资风格与政策促进方向的共振.pdf</li><li>2026-01-09 16:58</li><li>2025年人工智能是旅游和酒店业的核心报告-赋能个性化、效率和增长.pdf</li><li>2026-01-08 21:39</li><li>Lemongrass：2026年度旅游趋势报告（英文版）.pdf</li><li>2026-01-07 10:31</li><li>甘肃文旅行业深度报告：千年丝路如意甘肃，稳中有进高质量发展.pdf</li><li>2026-01-05 15:53</li><li>智瓴优业：云南省旅居产业十五五发展展望蓝皮书（2025年）.pdf</li><li>2026-01-03 10:31</li><li>抖音生活服务：抖音2025年文旅数据报告.pdf</li><li>2025-12-30 14:51</li><li>2025年当AI引导购物旅程时-人工智能驱动商业时代下营销人员的机会报告（英文版）.pdf</li><li>2025-12-29 15:57</li><li>2025年人工智能：旅游与酒店业的核心驱动力-赋能个性化、效率与增长报告（英文版）.pdf</li><li>2025-12-29 15:56</li><li>一文读懂陕西旅游招股说明书：聚焦文旅主业，多元布局助力发展.pdf</li><li>2025-12-29 15:51</li><li>沙利文：2025年全球及中国旅游列车行业白皮书.pdf</li><li>2025-12-29 15:47</li><li>北京第二外国语学院：2025年AI旅游行程助手类产品能力评测报告.pdf</li><li>2025-12-28 09:05</li><li>2025年三季度旅游行业运行分析.pdf</li><li>2025-12-26 16:16</li><li>AI+智能洞察报告：人工智能如何重塑消费者旅程与商业决策.pdf</li><li>2025-12-22 15:06</li><li>新京智库：2025年Z世代冰雪旅游行为洞察报告.pdf</li><li>2025-12-20 16:09</li><li>新京智库：2025年Z世代冰雪旅游行为洞察报告.pdf</li><li>2025-12-20 16:07</li><li>BCD Travel：2026年全球旅游市场展望报告（英文版）.pdf</li><li>2025-12-19 16:05</li><li>2025年假日旅行调查报告.pdf</li><li>2025-12-18 14:46</li><li>2026年旅游及免税行业展望-23页.pdf</li><li>2025-12-17 16:14</li><li>2026年全球旅游趋势报告(英)-Amadeus.pdf</li><li>2025-12-16 16:27</li><li>伦敦世界旅游交易会：2025年全球旅游行业报告（英文版）.pdf</li><li>2025-12-10 16:57</li><li>中国入境游产业研究专题报告：中国入境游迈向黄金发展期，龙头OTA与旅行社有望受益.pdf</li><li>2025-12-09 16:09</li><li>2026年全球六大旅游趋势报告（英文版）.pdf</li><li>2025-12-07 10:22</li><li>旅游零售业变革：2025年行业分析与未来展望-CXG.pdf</li><li>2025-11-28 15:36</li><li>后浪研究所：2025年轻人旅游趋势报告.pdf</li><li>2025-11-26 15:50</li><li>世界旅游联盟：2024年可持续旅游社区韧性发展新路径报告.pdf</li><li>2025-11-26 15:48</li><li>世界旅游联盟：2024-2025年跨境旅游消费趋势研究报告.pdf</li><li>2025-11-26 15:48</li><li>2025年全国县域文旅融合发展报告-迈点研究院.pdf</li><li>2025-11-24 15:12</li><li>迈点研究院：2025年中国文旅景区品牌运营发展报告.pdf</li><li>2025-11-22 16:34</li><li>2025文旅景区黄山5天4晚研学旅游活动方案-37P.pdf</li><li>2025-11-19 15:19</li><li>“财智私行 秘境滇西”云南腾冲芒市高端旅游团建出行活动方案.pdf</li><li>2025-11-18 16:28</li><li>2026马年文旅景区新年春节唐潮游园会（潮起盛唐主题）活动方案-66P.pdf</li><li>2025-11-18 16:26</li><li>北京市文旅局：“北京礼物”创新发展白皮书（2025）.pdf</li><li>2025-11-15 15:12</li><li>2025-2026年秋冬季欧洲境内旅游舆情监测报告（英文版）.pdf</li><li>2025-11-14 14:15</li><li>石基信息：2025年文旅行业新媒体营销趋势报告.pdf</li><li>2025-11-06 16:41</li><li>2025年Q3中国商旅管理市场差旅管理趋势研究报告.pdf</li><li>2025-11-06 16:38</li><li>（英）当下与未来：2025-2026年旅游行业报告.pdf</li><li>2025-11-04 16:51</li><li>县区全域文旅智慧化解决方案-中智游科技.pdf</li><li>2025-11-03 15:47</li><li>在线旅游消费满意度调查报告（2025）-天津市消费者协会.pdf</li><li>2025-11-03 15:46</li><li>2025中国高校旅游学科硕士教育质量与产学研融合发展趋势报告.pdf</li><li>2025-10-31 15:18</li><li>美团：2025年旅游休闲度假消费热点特征与案例研究报告.pdf</li><li>2025-10-29 16:18</li><li>中宏保险：2025新经济时代精智人群长寿新旅程报告.pdf</li><li>2025-10-24 14:13</li><li>CIIF之旅收获：智能类人机器人——在不同发展阶段均展现出惊人的发展速度.pdf</li><li>2025-10-14 15:19</li><li>YouTube旅游分类策略.pdf</li><li>2025-10-13 09:50</li><li>出海行业2025企业出海商旅管理报告：逐浪·共栖.pdf</li><li>2025-10-11 16:03</li><li>2025年Q3旅游行业薪酬报告.pdf</li><li>2025-09-29 15:54</li><li>美团：机会在下沉：2025中国企业差旅趋势洞察之住宿篇.pdf</li><li>2025-09-28 17:34</li><li>抖音&amp;中国旅游协会&amp;迈点研究院：2025年心动酒店趋势报告.pdf</li><li>2025-09-27 19:58</li><li>2024-2025年旅游趋势报告.pdf</li><li>2025-09-25 16:00</li><li>藏自治区人民政府：西藏自治区文化旅游产业发展规划（2025—2035年）.pdf</li><li>2025-09-24 16:24</li><li>2025年旅游业人工智能应用报告：评估并支持NTO的研究与营销运营工作（英文版）.pdf</li><li>2025-09-23 16:36</li><li>欧洲电信简化议程：监管演进以提升竞争性与更强数字单一市场的客户旅程.pdf</li><li>2025-09-22 16:20</li><li>世界旅游目的地竞争潜力指数报告（2025）.pdf</li><li>2025-09-22 16:19</li><li>“中国服务”河南模式研究报告（2025）解码河南文旅“破圈”背后的创新密码.pdf</li><li>2025-09-20 16:58</li><li>2025年新型需供关系驱动下的中国AI文旅发展趋势报告.pdf</li><li>2025-09-18 16:35</li><li>报告_旅游业未来四种情景.pdf</li><li>2025-09-18 16:32</li><li>康养旅游的未来：定义2025年及未来康养旅游的趋势研究报告（英文版）.pdf</li><li>2025-09-16 16:15</li><li>环球旅讯：2025下半年AI旅游应用趋势洞察报告.pdf</li><li>2025-09-12 16:36</li><li>环球旅讯：2025年Q3中国商旅市场趋势洞察报告.pdf</li><li>2025-09-12 16:36</li><li>2024年电商配送基准报告-穿越现代消费者旅程的复杂性.pdf</li><li>2025-09-12 16:30</li><li>网经社：2025年暑期旅游出行网络消费权益监测报告.pdf</li><li>2025-09-11 15:14</li><li>北戴河旅游项目小镇全年活动推广方案.pdf</li><li>2025-09-10 15:33</li><li>抖音长白山圣地冰雪旅游节活动思路沟通案.pdf</li><li>2025-09-06 19:23</li><li>广州旅游发展战略规划（2025-2035年）.pdf</li><li>2025-09-06 19:21</li><li>途美商旅：2025年Q2商旅市场差旅管理趋势报告.pdf</li><li>2025-09-05 16:58</li><li>2025年人工智能赋能智慧旅游发展研究报告.pdf</li><li>2025-09-04 16:05</li><li>2025年旅游业的转折点：变革性增长的原则报告（英文版）.pdf</li><li>2025-09-03 16:51</li><li>复苏与蜕变-2025年中国旅行新洞察与新叙事报告.pdf</li><li>2025-08-30 16:24</li><li>2025年移动的生活：中国旅居住宿市场洞察报告.pdf</li><li>2025-08-24 19:42</li><li>2025Q2中国旅行行业出海趋势洞察报告-环球旅讯.pdf</li><li>2025-08-20 17:12</li><li>地产2025中秋国庆太空研学之旅（太有可玩 超月想象）活动策划案.pdf</li><li>2025-08-20 17:10</li><li>2025年跨境支付解决方案：旅游企业如何实现全球增长报告.pdf</li><li>2025-08-16 16:48</li><li>“盐途皆是风景”文旅项目抖音IP内容营销规划方案【文旅抖音IP运营】【旅游抖音运营】.pdf</li><li>2025-08-16 16:43</li><li>2025年中国在线旅游行业市场全景洞察报告.pdf</li><li>2025-08-14 16:55</li><li>ITB China：旅游趋势报告2025-2026.pdf</li><li>2025-08-07 16:15</li><li>环球旅讯：2025年Q2中国商旅市场趋势洞察报告.pdf</li><li>2025-08-01 17:03</li><li>2025年下半年旅游与酒店业战略及投资展望报告（英文版）.pdf</li><li>2025-08-01 17:00</li><li>幸福文旅全年运营思路（文旅乡村振兴亲子活动文创婚庆民宿餐饮农业智慧景区）.pdf</li><li>2025-08-01 16:47</li><li>2025从住宿到生活旅居市场产品竞争力与投资新机遇白皮书.pdf</li><li>2025-07-29 17:06</li><li>2025年准许起飞：AI赋能旅行与运输行业客户服务研究报告（英文版）.pdf</li><li>2025-07-26 20:11</li><li>家庭自驾游率先重塑中国高端车市-中国购车家庭收支洞察报告之旅游篇（2025版）.pdf</li><li>2025-07-26 20:08</li><li>华福消费观察：文旅与潮玩受暑期受旺季催化，关注AI教育进展及精细医美格局改善.pdf</li><li>2025-07-26 20:00</li><li>2025年重塑国际旅游的五大趋势研究报告（英文版）.pdf</li><li>2025-07-24 16:04</li><li>2025年别克GL8+陆尊+PHEV用户画像与购车旅程报告.pdf</li><li>2025-07-23 16:29</li><li>Skift：2025年全球旅游业状况报告：基于300+数据洞察（英文版）.pdf</li><li>2025-07-22 15:47</li><li>2025年广东省乡村旅游消费趋势报告.pdf</li><li>2025-07-22 15:45</li><li>荣续ESG智库：2025年酒旅行业ESG白皮书.pdf</li><li>2025-07-17 15:54</li><li>2025全球旅行趋势报告.pdf</li><li>2025-07-16 16:09</li><li>文旅部：2025旅游安全实务手册.pdf</li><li>2025-07-13 08:28</li><li>MoonFox月狐数据：2025年旅游行业发展洞察报告.pdf</li><li>2025-07-11 16:04</li><li>2025年旅游业发展转折点：转型增长原则研究报告（英文版）.pdf</li><li>2025-07-10 16:41</li><li>同程商旅：2024-2025中国商旅管理白皮书.pdf</li><li>2025-07-08 16:59</li><li>2025年人工智能如何驱动制造业：从转型到价值创造的跃迁之旅报告（英文版）.pdf</li><li>2025-07-06 08:40</li><li>民族工业沉浸式数字文化博物馆文旅非遗IP包装方案【非遗文旅】【非遗IP运营】.pdf</li><li>2025-07-06 08:32</li><li>2025年欧洲旅行者期望与行为演变研究报告（英文版）.pdf</li><li>2025-07-04 16:32</li><li>旅游发展大会公共组织生活节活动策划方案.pdf</li><li>2025-07-04 16:25</li><li>环球旅讯：2025年Q2中国商旅市场趋势洞察报告.pdf</li><li>2025-07-03 16:38</li><li>2025年中国企业出海差旅研究报告-同程商旅.pdf</li><li>2025-07-03 16:37</li><li>KOA：2025年北美露营与户外旅游住宿报告（英文版）.pdf</li><li>2025-07-03 16:32</li><li>中国旅游研究院：2024中国旅游者出境满意度报告.pdf</li><li>2025-07-02 16:32</li><li>中国旅游研究院：2024中国旅游者出境满意度报告（英文版）.pdf</li><li>2025-07-02 16:32</li><li>中原乡镇樱桃沟乡村振兴景观概念性规划方案【乡村文旅】【乡村振兴】【乡村景观规划】.pdf</li><li>2025-06-27 16:33</li><li>迈点研究院：2025年文旅集团投资运营发展报告.pdf</li><li>2025-06-26 16:56</li><li>2025年旅见不善：政策真空下生态旅游危机研究报告（繁体版）.pdf</li><li>2025-06-26 16:54</li><li>2025央国企数智化差旅管理白皮书.pdf</li><li>2025-06-24 15:07</li><li>2025中国旅游企业出海趋势洞察报告.pdf</li><li>2025-06-23 15:42</li><li>2025澳门高奢酒店一二季度线上新媒体小红书种草方案【酒旅】【酒店民宿】【小红书营销】.pdf</li><li>2025-06-16 09:48</li><li>中共保定市委研究室：2025全国部分省市旅游产业发展政策汇编.pdf</li><li>2025-06-14 16:31</li><li>2025上半年中国AI旅游应用趋势报告.pdf</li><li>2025-06-10 16:12</li><li>2025年亚太旅游出行品牌数字广告投放洞察.pdf</li><li>2025-06-05 16:06</li><li>2024全国游客满意度调查报告-中国旅游研究院游客满意度课题组.pdf</li><li>2025-06-03 16:05</li><li>AI在旅游行业中的应用.pdf</li><li>2025-06-02 08:53</li><li>中国旅游研究院：2024全球游客满意度调查报告.pdf</li><li>2025-05-28 16:33</li><li>爱点击携程旅行：2025年中国奢华旅行白皮书（英文版）.pdf</li><li>2025-05-27 16:09</li><li>城市礼物文商旅赋能中心：2025年中国城市礼物发展白皮书.pdf</li><li>2025-05-27 16:06</li><li>中国低空旅游市场需求调查报告.pdf</li><li>2025-05-26 16:54</li><li>（英）科技颠覆者：旅游与旅游业的未来趋势-Trip.com.pdf</li><li>2025-05-24 16:34</li><li>环球旅讯：2025上半年中国AI旅游应用趋势报告.pdf</li><li>2025-05-23 16:22</li><li>中国文化产业和旅游业年度研究报告（2024）精华版.pdf</li><li>2025-05-21 15:45</li><li>广东省文化和旅游厅：广东省2024年度博物馆高质量发展报告.pdf</li><li>2025-05-21 15:36</li><li>京东&amp;快手：京东旅行 《万事大集》 项目结案.pdf</li><li>2025-05-20 17:07</li><li>2025年人工智能与自动化在旅行、交通和旅游与酒店业中的崛起研究报告（英文版）.pdf</li><li>2025-05-17 16:15</li><li>同程旅行-孙丽娟《海外服务新起点》.pdf</li><li>2025-05-17 16:08</li><li>智慧旅游智慧景区设计方案.pdf</li><li>2025-05-15 16:05</li><li>推动文化体育旅游产业融合 促进城市社会经济振兴繁荣.pdf</li><li>2025-05-12 15:45</li><li>数读2024年端午假期旅游市场晴雨表.pdf</li><li>2025-05-12 15:44</li><li>中国旅游协会：2025年她旅游：新时代女性旅游消费报告.pdf</li><li>2025-05-10 15:48</li><li>中国旅游协会：2025年中国长城旅游创新发展40年报告.pdf</li><li>2025-05-10 15:48</li><li>中国旅游协会：健康旅游行业标准编制工作研究报告（2024）.pdf</li><li>2025-05-10 15:41</li><li>中国旅游协会：2024年美好生活新玩法报告.pdf</li><li>2025-05-10 15:41</li><li>中国旅游协会：2024年研学旅游洞察研究报告.pdf</li><li>2025-05-10 15:41</li><li>中国旅游协会：长城主题旅游景区发展报告（2023.7-2024.6）.pdf</li><li>2025-05-10 15:41</li><li>中国旅游协会：2024年中国休闲农业与乡村旅游研究报告.pdf</li><li>2025-05-10 15:41</li><li>中国旅游协会：2024年我国国际乡村旅游目的地发展情况的报告.pdf</li><li>2025-05-10 15:41</li><li>2025旅游业的人工智能革命：平衡科技与人文关怀研究报告（英文）.pdf</li><li>2025-05-08 16:03</li><li>“小湖四万亩 大院藏春秋”海南文旅地产项目推介方案【房地产】【旅游地产】.pdf</li><li>2025-05-05 17:38</li><li>DT商业观察：2025年轻人旅游趋势报告.pdf</li><li>2025-05-03 10:39</li><li>南方城市文旅商业街区定位规划概念方案【旅游商业街】【商业地产定位】.pdf</li><li>2025-05-03 10:31</li><li>国际文化艺术会客村景区发展思路乡村定位规划方案【旅游】【乡村文旅】【艺术文旅】【乡村振兴】.pdf</li><li>2025-05-03 10:28</li><li>鱼岛乐园文旅项目品牌建设定位策划方案【旅游】【文旅定位】【旅游项目规划】.pdf</li><li>2025-05-03 10:20</li><li>婴幼儿配方奶粉品牌幼崽发现之旅线上线下活动策划案【婴幼儿奶粉】【港版奶粉】【线下活动】.pdf</li><li>2025-05-03 10:20</li><li>梁瑾：传统研发中心的400天变革之旅——形、序、质效三部曲.pdf</li><li>2025-04-30 17:18</li><li>美通社：2025旅游行业媒体概况与传播案例白皮书.pdf</li><li>2025-04-27 13:29</li><li>维萨-可持续旅游洞察与实践白皮书：探索融合共生的美好.pdf</li><li>2025-04-26 14:24</li><li>携程商旅：2024-2025年商旅管理市场白皮书.pdf</li><li>2025-04-24 15:59</li><li>2020年旅游目的地数字化营销策略趋势报告.pdf</li><li>2025-04-22 15:48</li><li>旅游业的AI革命：平衡科技与触感.pdf</li><li>2025-04-22 15:45</li><li>VISA：2025年探索融合共生的美好-可持续旅游洞察与实践白皮书.pdf</li><li>2025-04-18 15:09</li><li>海南自贸港旅游零售白皮书2025版.pdf</li><li>2025-04-15 16:16</li><li>海南自贸港旅游零售白皮书2025版（英文版）.pdf</li><li>2025-04-15 16:16</li><li>联合国世旅组织：2024年旅游促营商-投资赞比亚报告.pdf</li><li>2025-04-15 16:15</li><li>威海市全域旅游交通网规划（2021-2035年）研究报告.pdf</li><li>2025-04-09 16:23</li><li>以“数”赋能，以“智”焕新——腾讯智慧文旅解决方案.pdf</li><li>2025-04-04 17:58</li><li>Fastdata极数：2025年中国自驾公路旅行用户洞察报告.pdf</li><li>2025-04-03 15:53</li><li>2025年中国出境游贸易调查报告：旅游业潜力挖掘（英文版）.pdf</li><li>2025-04-01 15:37</li><li>2025年发展大湾区旅游群：双品牌视角报告-香港理工大学.pdf</li><li>2025-03-31 09:53</li><li>2025年旅游业未来趋势报告.pdf</li><li>2025-03-29 16:26</li><li>2024年山西省旅游业大数据报告.pdf</li><li>2025-03-28 16:37</li><li>中原地区某市文旅整合营销解决方案【旅游】【文旅】.pdf</li><li>2025-03-28 16:33</li><li>新疆冬牧场文旅景区策划定位&amp;概念规划案【旅游】【文旅规划】.pdf</li><li>2025-03-28 16:33</li><li>森林文旅景区全年营销规划案【旅游】【旅游景区营销】【文旅营销全案】.pdf</li><li>2025-03-28 16:31</li><li>西南省份形象宣传片全案【文旅宣传】【宣传片策划】.pdf</li><li>2025-03-28 16:30</li><li>国产智能汽车车主露营户外旅行保客活动策划方案【车友会活动】.pdf</li><li>2025-03-28 16:29</li><li>2024低空+旅游重塑出行体验新质生产力打开蓝海市场.pdf</li><li>2025-03-28 16:27</li><li>文旅创意宣传片视频方案【旅游】【宣传片创意】.pdf</li><li>2025-03-26 15:39</li><li>2025美国大选后国际游客赴美旅游的意愿变化及消费行为研究报告（英译版）.pdf</li><li>2025-03-25 16:00</li><li>旅讯研究院：2025年北京差旅报告-外地人在北京咋出差？.pdf</li><li>2025-03-24 14:46</li><li>2025第一季度商旅市场趋势洞察.pdf</li><li>2025-03-24 14:37</li><li>环球旅讯&amp;数字100：2025年Q1中国旅游消费趋势洞察报告.pdf</li><li>2025-03-22 17:06</li><li>RedHat红帽：2025年开启企业AI之旅：新手指南报告.pdf</li><li>2025-03-20 15:02</li><li>BCD Travel：2024年现代企业差旅政策调研报告.pdf</li><li>2025-03-16 17:14</li><li>2025年旅游趋势报告.pdf</li><li>2025-03-14 15:48</li><li>洞察亚洲旅游新浪潮-2024年新加坡入境游的重磅趋势报告.pdf</li><li>2025-03-13 17:11</li><li>2025年携手红帽探索AI之旅报告-为您的AI之旅提供专业知识、培训和支持服务.pdf</li><li>2025-03-12 15:48</li><li>2024年聚焦奢华旅行：深度洞察中国旅行者的需求演变与市场趋势报告（英文版）.pdf</li><li>2025-03-12 15:45</li><li>2024年聚焦奢华旅行：深度洞察中国旅行者的需求演变与市场趋势报告.pdf</li><li>2025-03-12 15:45</li><li>温泉旅游度假区营销推广提报方案.pdf</li><li>2025-03-11 16:26</li><li>浙江大学：人类经验与AI算法的镜像之旅（2025年）.pdf</li><li>2025-03-10 09:20</li><li>国产智能汽车车主露营户外旅行保客活动策划方案【车友会活动】.pdf</li><li>2025-03-10 09:12</li><li>2024古镇商业街项目标志文创设计方案【文旅】【旅游】【文创创意】.pdf</li><li>2025-03-10 09:09</li><li>旅游城市文旅夜游：中医药古今天地游策划方案【旅游】【文遗】【文旅规划】.pdf</li><li>2025-03-05 15:19</li><li>小红书-城市正当红招商 - 【文旅】【城市】【citywalk】.pdf</li><li>2025-03-04 16:06</li><li>中国魅力小城旅游研究报告.pdf</li><li>2025-03-04 16:04</li><li>英敏特：2024年中国旅游度假趋势报告.pdf</li><li>2025-02-28 16:38</li><li>客户旅程的未来：AI代理掌控购买过程.pdf</li><li>2025-02-28 16:31</li><li>客户旅程的未来：人工智能代理掌控购买过程.pdf</li><li>2025-02-28 16:31</li><li>Fastdata极数：2024年中国旅游行业年度报告.pdf</li><li>2025-02-26 15:01</li><li>模块化研发在汽车及复杂离散制造行业的实践之旅.pdf</li><li>2025-02-26 14:57</li><li>2024年旅游应用和品牌营销报告.pdf</li><li>2025-02-26 14:56</li><li>同程旅行：2025年中国高消费旅客出境游洞察报告.pdf</li><li>2025-02-26 14:54</li><li>模块化研发在汽车及离散制造行业的实践之旅.pdf</li><li>2025-02-24 15:41</li><li>中国传媒大学：2025年文旅传播趋势观察报告.pdf</li><li>2025-02-19 16:15</li><li>网经社：2024年Q4中国在线旅游用户体验与投诉数据报告.pdf</li><li>2025-02-19 16:10</li><li>2025年奢华旅行趋势研究报告.pdf</li><li>2025-02-18 15:55</li><li>2025年趋势报告：Alpha与Z世代如何重新定义旅游.pdf</li><li>2025-02-18 15:52</li><li>艾瞰系列：春节假期商圈及文旅大数据观察.pdf</li><li>2025-02-18 15:44</li><li>2025年小红书文旅灵感出游种草指南.pdf</li><li>2025-02-17 10:45</li><li>cvent：2024年未来已至：企业差旅技术变革报告（英文版）.pdf</li><li>2025-02-17 10:38</li><li>2024日本47地县级政府旅游部门在中国社交媒体平台运营推广报告.pdf</li><li>2025-02-15 14:54</li><li>香港文化体育及旅游局：2024年文艺创意产业发展蓝图.pdf</li><li>2025-02-15 14:50</li><li>2024酒旅业培训发展白皮书-先之教育.pdf</li><li>2025-02-15 14:46</li><li>广西农文旅融合发展研究会：广西农文旅融合发展报告2024.pdf</li><li>2025-02-13 20:12</li><li>新奥：绿色行动2030新奥能源的零碳之旅报告（2024年版）.pdf</li><li>2025-02-13 20:06</li><li>2025年旅游展望.pdf</li><li>2025-02-12 14:35</li><li>2025年旅游趋势报告.pdf</li><li>2025-02-12 14:30</li><li>北京体育大学&amp;中国电信：2024-2025滑雪旅游预测报告.pdf</li><li>2025-02-11 15:47</li><li>农小蜂-云南省乡村旅游产业特色景点概览.pdf</li><li>2025-02-10 16:22</li><li>2025年旅行与旅游的未来：拥抱可持续与包容性增长报告（英文版）.pdf</li><li>2025-02-07 15:34</li><li>大众汽车转型之旅.pdf</li><li>2025-02-03 09:51</li><li>祥源文旅-600576-深度报告：持续探索文旅发展新模式，布局低空开拓新市场.pdf</li><li>2025-01-25 17:00</li><li>社会服务：冰雪经济全景图之旅游专题-冰雪旅游活力持续，带动区域发展.pdf</li><li>2025-01-23 15:01</li><li>君卓咨询：2025年河北省旅游类国企研究报告.pdf</li><li>2025-01-21 15:40</li><li>中国文旅简历地方文化标识.pdf</li><li>2025-01-21 15:38</li><li>2024年香港旅游业发展蓝图2.0（繁体版）.pdf</li><li>2025-01-18 15:04</li><li>2024年中国文化产业和旅游业年度研究报告-北京京和文旅发展研究院.pdf</li><li>2025-01-14 16:20</li><li>艾瑞咨询：2024年中国文旅IP商业化报告.pdf</li><li>2025-01-14 16:20</li><li>小红书：2025数字化乡村文旅发展报告.pdf</li><li>2025-01-14 16:18</li><li>环球旅讯&amp;旅连连：2024年旅游业招聘洞察报告.pdf</li><li>2025-01-13 10:21</li><li>携程：2025年春节长沙旅游饭店市场大数据预测报告.pdf</li><li>2025-01-11 16:14</li><li>中国旅行社协会：2024年中国研学旅游发展报告.pdf</li><li>2025-01-08 16:21</li><li>中国旅游研究院：2024年古镇旅游发展指数报告.pdf</li><li>2025-01-08 16:21</li><li>慧科讯业：2024（下）文旅行业消费者洞察报告.pdf</li><li>2025-01-08 16:19</li></ul>]]></description></item><item>    <title><![CDATA[春节不掉线：IT 远程守护 4 大场景方案 ZeroNews内网穿透 ]]></title>    <link>https://segmentfault.com/a/1190000047607308</link>    <guid>https://segmentfault.com/a/1190000047607308</guid>    <pubDate>2026-02-12 13:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>春节将至，归心似箭！</p><p>各位IT同仁、技术人，在您合上电脑、准备享受团圆时光之前，是否已为春节期间系统的“不确定性”做好了万全准备？临时需要访问公司代码库？紧急情况要登录内网监控平台？<br/>假期≠业务中断，可靠的远程访问能力是您安心过节的“定心丸”。</p><p>为此，ZeroNews 为您梳理了四大春节高频场景，并送上安心解决方案，助您实现“人不在岗，业务无忧”。</p><h3>场景一：紧急发布与远程调试</h3><p>假期中线上服务突发异常，需紧急修复并发布，或合作方临时需联调测试环境。而开发、运维人员分散各地，无法直连内网？<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047607310" alt="图片" title="图片"/></p><p><strong>ZeroNews 方案：</strong></p><p>为内网 GitLab私有仓库，内网数据库等配置专属安全链接，支持远程提交代码、发布版本、调试接口。为合作伙伴创建鉴权认证或IP访问控制，设置访问权限，配合联调测试，保障安全。</p><p><strong>节前准备建议：</strong><br/>1. 为关键开发、测试环境部署 ZeroNews Agent并创建安全映射，设置安全策略。</p><ol start="2"><li> 提前与合作伙伴设置鉴权认证，预设 IP 白名单。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047607311" alt="图片" title="图片" loading="lazy"/></li></ol><h3>场景二：远程设备运维</h3><p>生产服务器、数据库或内部监控平台突发异常，运维人员无法到现场。需快速 SSH 或登录内网系统处理？<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047607312" alt="图片" title="图片" loading="lazy"/></p><p><strong>ZeroNews 方案：</strong><br/>通过安全链接直接接入内网跳板机、监控平台、日志系统，实现全链路排查。无需公网 IP 或复杂 VPN，快速远程访问内网设备。</p><p><strong>节前准备建议：</strong><br/>为核心运维设备创建访问链接，并同步给值班人员。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047607313" alt="图片" title="图片" loading="lazy"/></p><h3>场景三：NAS 与文件共享</h3><p>放假在家，需调取公司 NAS 中的设计稿、合同或项目资料。但文件仅在内网共享？<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047607314" alt="图片" title="图片" loading="lazy"/></p><p><strong>ZeroNews 方案：</strong><br/>为内部 NAS、文件服务器配置加密访问通道，远程浏览、下载如同本地操作。支持临时分享链接，方便跨团队协作。</p><p><strong>节前准备建议：</strong><br/>1. 梳理春节期间可能需访问的常用文件目录，创建文件共享映射。<br/>2. 测试文件传输稳定性，确保链路通畅。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047607315" alt="图片" title="图片" loading="lazy"/></p><h3>场景四：物联网与远程设备管理</h3><p>公司内部部署的 IoT 设备（如测试机、展示终端等）需在假期保持状态可查、可控。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047607316" alt="图片" title="图片" loading="lazy"/></p><p><strong>ZeroNews 方案：</strong><br/>通过安全隧道远程访问内网物联网平台或设备管理界面，实时查看状态、重启设备等。</p><p><strong>节前准备建议：</strong><br/>1. 将关键 IoT 设备管理界面映射至安全链接。<br/>2. 设置 Agent 异常告警通知机制，便于及时干预。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047607317" alt="图片" title="图片" loading="lazy"/></p><p>ZeroNews 愿以稳定、安全、高效能力，让您和您的团队能够真正放下顾虑，享受一个安心、祥和的新春佳节。</p><p>现在前往 ZeroNews 官网(www.zeronews.cc)注册，即可开启专属服务，让这份安心保障即刻生效！</p>]]></description></item><item>    <title><![CDATA[如何通过Java SDK获取Collection列表 DashVector ]]></title>    <link>https://segmentfault.com/a/1190000047607103</link>    <guid>https://segmentfault.com/a/1190000047607103</guid>    <pubDate>2026-02-12 12:13:15</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>本文介绍如何通过Java SDK获取所有已创建的Collection名称列表。</p><h2>前提条件</h2><ul><li>已创建Cluster：<a href="https://link.segmentfault.com/?enc=w3M1sXvSP3RYIk6hYX4KLg%3D%3D.kHHDyS%2FQh5rjzrTKEAZo6fz451WgycOLLAbEJORufFzB18O%2FOWZ1NVZlGmT6d02qZ5JktBhkMA8ADpKK5TVEyg%3D%3D" rel="nofollow" target="_blank">创建Cluster</a>。</li><li>已获得API-KEY：<a href="https://link.segmentfault.com/?enc=T0r9h4mZeDrNL6YJy%2BeLLQ%3D%3D.J%2FzTg35l3%2FRbSDjMqb1OksihDyIRH7dDanrSEkE9C3O6%2BKIBrppoXqnvVpGl7%2FWe7mwnVre6Ez3Iol9Ca7k3PA%3D%3D" rel="nofollow" target="_blank">API-KEY管理</a>。</li><li>已安装最新版SDK：<a href="https://link.segmentfault.com/?enc=7NHYAWrnMvjYjRK0G4t2Zw%3D%3D.tcYzEbk4UYD4hSC4Vm6ma5Tfx6cBnryBSP8S%2FvelMhK5Sl1by29vROGSEY%2FshvOECk7MjdBUqSWwRFMlTOBVGQ%3D%3D" rel="nofollow" target="_blank">安装DashVector SDK</a>。</li></ul><h2><strong>接口定义</strong></h2><p>Java</p><pre><code>// class DashVectorClient

public Response&lt;List&lt;String&gt;&gt; list();</code></pre><h2>接口使用</h2><p><strong>说明</strong></p><p>需要使用您的api-key替换示例中的YOUR\_API\_KEY、您的Cluster Endpoint替换示例中的YOUR\_CLUSTER\_ENDPOINT，代码才能正常运行。</p><p>Java</p><pre><code>import com.aliyun.dashvector.DashVectorClient;
import com.aliyun.dashvector.DashVectorCollection;
import com.aliyun.dashvector.common.DashVectorException;

public class Main {
    public static void main(String[] args) throws DashVectorException {
        DashVectorClient client = new DashVectorClient("YOUR_API_KEY", "YOUR_CLUSTER_ENDPOINT");
      
        Response&lt;List&lt;String&gt;&gt; response = client.list();
      
        System.out.println(response);
        // example output:
        // {
        //     "code":0,
        //     "message":"",
        //     "requestId":"5de1a75e-2996-4496-a284-9b958dfdad53",
        //     "output":[
        //         "simple",
        //         "quickstart"
        //     ]
        // }
    }
}</code></pre><h2>入参描述</h2><p>无</p><h2><strong>出参描述</strong></h2><p><strong>说明</strong></p><p>返回结果为<code>Response&lt;List&lt;String&gt;&gt;</code>对象，<code>Response&lt;List&lt;String&gt;&gt;</code>对象中可获取本次操作结果信息，如下表所示。</p><table><thead><tr><th><strong>方法</strong></th><th><strong>类型</strong></th><th><strong>描述</strong></th><th><strong>示例</strong></th></tr></thead><tbody><tr><td>getCode()</td><td>int</td><td>返回值，参考<a href="https://link.segmentfault.com/?enc=XtjDiCSziGics6QT6U7mdw%3D%3D.MDXOJuKKYGmbjfNBUhv4vcYS0%2BlEqAoTj5l9qs9ayIW6o9%2FJJqEFfyiXiubcRmuekLPIQ%2FP7N7V1ufRByr2acw%3D%3D" rel="nofollow" target="_blank">返回状态码说明</a></td><td>0</td></tr><tr><td>getMessage()</td><td>String</td><td>返回消息</td><td>success</td></tr><tr><td>getRequestId()</td><td>String</td><td>请求唯一id</td><td>19215409-ea66-4db9-8764-26ce2eb5bb99</td></tr><tr><td>getOutput()</td><td>List&lt;String&gt;</td><td>所有Collection名称列表</td><td>\['my\_collection1', 'my\_collection2'\]</td></tr><tr><td>isSuccess()</td><td>Boolean</td><td>判断请求是否成功</td><td>true</td></tr></tbody></table>]]></description></item><item>    <title><![CDATA[Vue3文本差异对比器实现方案 兔子昂 ]]></title>    <link>https://segmentfault.com/a/1190000047607108</link>    <guid>https://segmentfault.com/a/1190000047607108</guid>    <pubDate>2026-02-12 12:12:18</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>Vue3文本差异对比器实现方案</h2><p>本文将介绍本项目中 <strong>文本差异对比器 (Text Diff Checker)</strong> 工具的技术实现细节。该工具基于 Vue 3 框架开发，核心对比逻辑采用原生的 JavaScript 实现，通过动态加载的方式与 Vue 组件进行交互。</p><blockquote>在线工具网址：<a href="https://link.segmentfault.com/?enc=mrXLgIGEeey3avmpm3Tzjg%3D%3D.7cw6tsZngm7byYBQBDvgPMeUqLGDGKTfgcZZzjTTa3GXtnLECeZglGzzPv3pagw2" rel="nofollow" target="_blank">https://see-tool.com/diff-checker</a>  <br/>工具截图：  <br/><img width="723" height="419" referrerpolicy="no-referrer" src="/img/bVdnUVZ" alt="" title=""/></blockquote><h3>1. 架构设计</h3><p>为了保证核心算法的独立性和复用性，我们将 Diff 算法逻辑封装在 <code>public/js/diff-checker.js</code> 中，而 Vue 组件 <code>pages/diff-checker.vue</code> 仅负责 UI 交互和数据展示。</p><ul><li><strong>数据层 (Core JS)</strong>: 负责文本的预处理、Diff 算法计算、HTML 渲染字符串生成以及统计信息计算。</li><li><strong>视图层 (Vue)</strong>: 负责用户输入、选项配置、调用核心方法并展示结果。</li></ul><h3>2. 核心算法实现 (diff-checker.js)</h3><p>核心逻辑是一个基于 <strong>最长公共子序列 (LCS, Longest Common Subsequence)</strong> 的 Diff 算法。</p><h4>2.1 文本预处理与并在</h4><p>根据用户选择的“对比模式”，我们将输入文本分割成不同的单元：</p><ul><li><strong>行模式 (Line)</strong>: 使用 <code>split('\n')</code> 按换行符分割。</li><li><strong>词模式 (Word)</strong>: 使用 <code>split(/\s+/)</code> 按空白字符分割。</li><li><strong>字符模式 (Char)</strong>: 使用 <code>split('')</code> 逐字符分割。</li></ul><p>同时，根据配置选项处理“忽略空格”和“忽略大小写”：</p><pre><code class="javascript">if (ignoreWhitespace) {
    processedText1 = processedText1.replace(/\s+/g, ' ').trim();
    processedText2 = processedText2.replace(/\s+/g, ' ').trim();
}
// 忽略大小写则统一转为小写</code></pre><h4>2.2 LCS 算法与回溯</h4><p>使用动态规划构建 DP 表，计算最长公共子序列的长度：</p><pre><code class="javascript">// DP 表构建
for (let i = 1; i &lt;= m; i++) {
    for (let j = 1; j &lt;= n; j++) {
        if (arr1[i - 1] === arr2[j - 1]) {
            dp[i][j] = dp[i - 1][j - 1] + 1;
        } else {
            dp[i][j] = Math.max(dp[i - 1][j], dp[i][j - 1]);
        }
    }
}</code></pre><p>构建完成后，通过回溯 (Backtrack) 找出具体的 LCS 路径。</p><h4>2.3 构建 Diff 结果</h4><p>根据 LCS 路径，遍历原始序列，确定哪些部分是“新增 (added)”、“删除 (removed)”或“未变 (unchanged)”。</p><ul><li>如果当前元素在 LCS 中，标记为 <code>unchanged</code>。</li><li>如果原序列中有但 LCS 中没有，标记为 <code>removed</code>。</li><li>如果新序列中有但 LCS 中没有，标记为 <code>added</code>。</li></ul><h4>2.4 结果渲染</h4><p>为了提高性能，Diff 的结果直接由 JS 生成 HTML 字符串，而不是在 Vue 中使用 <code>v-for</code> 渲染成千上万个 DOM 节点。生成的 HTML 包含了行号、差异标识（+/-）以及高亮样式类。</p><pre><code class="javascript">/* 生成的 HTML 结构示例 */
&lt;div class="diff-line diff-line-removed"&gt;
  &lt;span class="diff-line-number"&gt;1&lt;/span&gt;
  &lt;span class="diff-line-number"&gt;&lt;/span&gt;
  &lt;span class="mr-2"&gt;-&lt;/span&gt;
  Content
&lt;/div&gt;</code></pre><h3>3. Vue 组件实现 (diff-checker.vue)</h3><h4>3.1 动态加载脚本</h4><p>Vue 组件在挂载或需要使用时，通过创建 <code>&lt;script&gt;</code> 标签动态加载核心 JS 文件。为了防止重复加载，我们通过检查 <code>window.DiffChecker</code> 是否存在来判断。</p><pre><code class="javascript">const loadDiffCheckerScript = () =&gt; {
  if (window.DiffChecker) return Promise.resolve();
  // 创建 script 标签加载 /js/diff-checker.js
  // 监听 onload 和 onerror 事件
}</code></pre><h4>3.2 调用对比</h4><p>当用户点击“开始对比”时，组件收集 <code>leftText</code>、<code>rightText</code> 以及 <code>compareMode</code>、<code>ignoreWhitespace</code> 等选项，调用核心对象的 <code>compare</code> 方法：</p><pre><code class="javascript">const result = window.DiffChecker.compare(leftText.value, rightText.value, compareMode.value, {
  ignoreWhitespace: ignoreWhitespace.value,
  ignoreCase: ignoreCase.value,
  showLineNumbers: showLineNumbers.value
})</code></pre><h4>3.3 结果展示</h4><p>核心方法返回的 <code>result</code> 对象中包含了 <code>diffHtml</code>（差异内容的 HTML）和 <code>statisticsHtml</code>（统计信息的 HTML）。Vue 组件直接使用 <code>v-html</code> 指令将其渲染到页面上：</p><pre><code class="html">&lt;div v-if="statisticsHtml" v-html="statisticsHtml"&gt;&lt;/div&gt;
&lt;div ref="diffOutput" v-html="diffOutputHtml"&gt;&lt;/div&gt;</code></pre><p>通过这种 Vue 处理交互 + 原生 JS 处理计算密集任务的分离模式，我们既保持了前端框架的开发效率，又保证了对比功能的性能与灵活性。</p>]]></description></item><item>    <title><![CDATA[2.12国产大模型集体更新，一文看懂怎么选 程序员小崔日记 ]]></title>    <link>https://segmentfault.com/a/1190000047607116</link>    <guid>https://segmentfault.com/a/1190000047607116</guid>    <pubDate>2026-02-12 12:11:43</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <ul><li><strong>最近国产AI圈有点热闹</strong>，短短一周内智谱GLM-5、MiniMax M2.5纷纷发布，DeepSeek V4灰度测试中，阿里的Qwen 3.5也快了。顺便说一下Kimi K2.5，之前也更新了，性价比不错。</li></ul><table><thead><tr><th>模型</th><th>状态</th><th>特点</th></tr></thead><tbody><tr><td>GLM-5</td><td>已发布</td><td>744B参数，专注Agent和复杂任务</td></tr><tr><td>MiniMax M2.5</td><td>已发布</td><td>编程能力强，接近Opus 4.6</td></tr><tr><td>Kimi K2.5</td><td>已发布</td><td>性价比高，日常用</td></tr><tr><td>DeepSeek V4</td><td>灰度测试</td><td>200B参数，100万上下文</td></tr><tr><td>Qwen 3.5</td><td>即将发布</td><td>预计开源，本地部署</td></tr></tbody></table><hr/><p><strong>GLM-5：从写代码到AI工程师</strong></p><p>智谱这次升级幅度不小，从GLM-4.7的355B参数直接干到744B，训练数据也从23T涨到28.5T tokens。</p><p>官方定位从“VibeCoding”转向“Agentic Engineering”，简单说就是以前帮你写写代码，现在能处理复杂的多步骤任务，更适合做Agent和系统工程。</p><p>网友评价：“评分超过Gemini 3 Pro，是目前开源模型里最高的”，但也提到“算力紧张，需要排队”。</p><hr/><p><strong>MiniMax M2.5：国产编程王者</strong></p><p>MiniMax这次主打编程能力，网友实测后反馈比较多：“和Claude Opus 4.6打得有来有回”、“国产最强编程模型”。</p><p>内测期间提供无限token，有人直接把Go写的微服务转成Rust，3亿token生成3万行代码，Rust大佬看完说“像模像样”。</p><hr/><p><strong>Kimi K2.5：性价比不错</strong></p><p>月之暗面之前更新的版本，主要特点是便宜。有人从Claude Sonnet 4.5切换过来，日花费从50美元降到4美元。</p><p>长文本处理能力也不错，网友实测改了近300个文件。不过也有人吐槽“感觉还是有点慢”。</p><hr/><p><strong>DeepSeek V4：神秘的灰度测试</strong></p><p>目前需要更新App到1.7.4版本才有机会体验，注意这次灰度的200B不是正式V4，是个中间版本。</p><p>主要卖点是100万上下文和知识截止到2025年5月。网友说“代码生成比V3.2好一些”，但也提到“前端能力还没到K2.5的等级”。</p><hr/><p><strong>Qwen 3.5：还在憋大招</strong></p><p>阿里的下一代模型，预计本周发布。前几代Qwen以开源友好著称，这次应该也会开源权重。</p><p>网友说：“如果今晚DeepSeek发车，Qwen 3.5今晚也会发，那就内战爆发了”。适合需要本地部署的用户。</p><hr/><h2>怎么选？</h2><ul><li><strong>写代码、做开发</strong> → MiniMax M2.5</li><li><strong>复杂项目、跑Agent</strong> → GLM-5</li><li><strong>性价比、日常用</strong> → Kimi K2.5</li><li><strong>本地部署、开源需求</strong> → 等Qwen 3.5</li><li><strong>免费尝鲜</strong> → DeepSeek App</li></ul><hr/><p>这次更新确实比较密集，国产模型从之前的双月更变成月更，整体水平也上来了。大家根据自己需求选一个试试就行，不用想太复杂。</p><p>本文由<a href="https://link.segmentfault.com/?enc=1ih4BcSLuCQcIiftVm4qnQ%3D%3D.TGnwQteF0LgJ0sVoncvo%2FS6UfaQ64CF4uoplI2ABbHg%3D" rel="nofollow" target="_blank">mdnice</a>多平台发布</p>]]></description></item><item>    <title><![CDATA[算力突围：自动化弹性伸缩解锁百万级核心错峰混部，SmoothCloud实践指南 Smoothclou]]></title>    <link>https://segmentfault.com/a/1190000047607118</link>    <guid>https://segmentfault.com/a/1190000047607118</guid>    <pubDate>2026-02-12 12:11:02</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>数字化浪潮席卷全球，AI大模型训练、工业智能落地、互联网大促保障等核心场景，对算力的需求呈现指数级爆发态势，百万级核心规模的算力调度能力，已成为企业突破数字化跃迁瓶颈、构建核心竞争力的关键。错峰混部作为当前提升算力资源利用率、压缩企业算力成本的最优路径之一，却受限于调度响应滞后、资源隔离不足、运维成本高企等痛点，难以实现规模化落地。自动化弹性伸缩技术的迭代升级，为这一行业困境提供了破局关键，而<a href="https://link.segmentfault.com/?enc=LWlYXI6LRTYFvxqCwBwnkA%3D%3D.xkqzS0X%2Bn6y4Uqpnr8V8UK%2Fu%2BsUl7kvO1zd1N%2Fw8gBg%3D" rel="nofollow" target="_blank">SmoothCloud润云智算平台</a>深度融合二者核心优势，构建了可直接落地的全栈解决方案。本文将以清晰分点形式，系统拆解错峰混部与弹性伸缩的核心逻辑、技术支撑及实践价值，详细解读自动化弹性伸缩如何高效赋能百万级核心错峰混部，全面凸显SmoothCloud平台的差异化竞争力，为企业算力优化提供实操参考。</p><h2>一、核心认知：百万级核心错峰混部的痛点与破局方向</h2><h3>（一）错峰混部核心逻辑</h3><p>错峰混部的核心逻辑，是基于“时间换空间”的资源优化理念，依托在线延时敏感型业务（如实时交易、用户交互）与离线计算密集型业务（如模型训练、数据批处理）的负载波峰波谷天然差异，将离线业务精准调度至在线业务负载低谷时段运行，实现同一算力资源的高效复用，最大化挖掘每一份算力的价值潜力，最终实现“算力不闲置、成本降下来”的核心目标。</p><h3>（二）百万级核心混部三大核心痛点</h3><p>调度滞后：无法实时捕捉业务负载的动态波动，导致在线业务高峰时段算力供给不足、业务卡顿，而离线业务可调度时段又出现算力闲置，形成“资源浪费+业务体验下滑”的双重困境；<br/>隔离不足：在线与离线业务共享算力资源时，缺乏有效的隔离机制，业务间资源竞争激烈，极易影响在线业务的SLO（服务等级目标），违背错峰混部“兼顾效率与体验”的核心初衷；<br/>运维高耗：百万级核心规模的算力调度，若依赖传统静态资源分配与人工操作模式，需投入大量运维人力，且人为调度失误难以规避，不仅增加运维成本，更会制约混部效率的提升。</p><h3>（三）破局关键：自动化弹性伸缩技术</h3><p>自动化弹性伸缩技术，通过“实时感知-智能决策-动态调度”的全流程闭环机制，精准直击百万级核心混部的三大痛点，为大规模错峰混部提供稳定、高效的核心技术支撑，实现“算力按需分配、效能极致优化”，推动错峰混部从“理论可行”走向“规模化落地”。</p><h2>二、技术内核：自动化弹性伸缩的三大核心支撑能力</h2><p>需明确的是，适配百万级核心错峰混部的自动化弹性伸缩，并非简单的“高峰扩容、低谷缩容”，而是一套适配大规模算力调度的完整技术体系，其三大核心能力协同发力，确保百万级核心规模下的调度精准、高效、稳定：</p><h3>（一）多维度实时感知：精准捕捉负载脉络</h3><p>依托全链路、全方位的监控体系，实时采集各节点CPU、内存、网络IO、任务队列长度等核心资源指标，实现负载状态的全域可视；<br/>结合业务画像建模与负载预测算法，精准勾勒在线、离线业务的负载波峰波谷轨迹，提前预判负载变化趋势；<br/>为后续伸缩决策提供精准、实时的数据支撑，杜绝“盲目伸缩”“滞后伸缩”，确保调度决策的科学性。</p><h3>（二）智能化决策引擎：科学把控伸缩节奏</h3><p>基于预设的业务策略与先进AI调度算法，自动研判伸缩时机、伸缩规模与资源分配方案，无需人工干预即可完成全流程决策；<br/>在线业务高峰时段：快速触发扩容动作，精准补充算力资源，确保在线业务流畅运行，保障用户体验与业务连续性；<br/>在线业务低谷时段：自动下线闲置算力实例，将释放的算力资源高效调度至离线批处理任务，实现算力错峰复用；<br/>在满足业务算力需求的同时，最大限度降低算力闲置率，实现算力效能与成本控制的双向优化。</p><h3>（三）分布式协同调度：破解规模化难题</h3><p>深度适配百万级核心的分布式算力架构，通过节点间的协同调度机制，实现全域算力资源的统一管理与高效调度；<br/>有效规避伸缩过程中的资源冲突、节点拥堵等问题，确保每一次伸缩动作都能快速落地、高效执行；<br/>实现“百万级核心同步调度、超低延迟响应”，彻底突破传统调度模式的规模化瓶颈，支撑大规模错峰混部稳定运行。</p><h2>三、实践落地：SmoothCloud平台的四大差异化优势</h2><p>润云智算SmoothCloud平台立足“东数西算”国家战略布局，依托自身规模化硬核算力优势，深度整合自动化弹性伸缩核心技术，构建了适配百万级核心错峰混部的全栈解决方案，四大差异化优势，为企业提供“高可靠、高性价比、低门槛”的算力调度服务：</p><h3>（一）分布式算力底座：筑牢伸缩调度根基</h3><p>构建以华南算力枢纽为核心、辐射全国20+省市的分布式算力网络，实现全域算力资源的就近调度、高效互补；<br/>平台搭载算力≥H200的高性能训练卡与算力≥5090的高性能推理卡，算力储备充足，可轻松承载百万级核心的并发调度需求；<br/>配备自主研发的AI智能调度算法，实现0.33ms超低延迟传输，确保弹性伸缩指令瞬时抵达各个节点，彻底破解传统调度滞后的行业痛点。</p><h3>（二）智能伸缩引擎：效能与成本双向优化</h3><p>内置高性能自动化弹性伸缩引擎，深度联动Nacos服务健康检查机制，可实时洞察各节点资源使用率与业务负载的细微变化，精准预判负载波动；<br/>无缝实现“在线高峰扩容、低谷算力复用”，最大化挖掘算力资源价值，提升算力利用率；<br/>支持“按需计费、启停随心”的灵活计费模式，推理卡低至2.68元/小时，可大幅降低企业算力闲置成本，进一步压缩整体算力投入。</p><h3>（三）精细化资源隔离：守护业务稳定底线</h3><p>采用先进的容器化技术与自定义资源隔离策略，为在线延时敏感型业务与离线计算密集型业务，划定专属资源分区，实现物理层面的资源隔离；<br/>明确两类业务的资源使用优先级，实时监控资源使用状态，一旦发现资源竞争风险，自动调整资源分配方案，确保资源分配合理；<br/>既能保障在线业务SLO稳定达标，又能确保离线任务高效推进，彻底破解百万级核心混部“顾此失彼”的行业难题。</p><h3>（四）全链路工具链：降低运维技术门槛</h3><p>打造一站式AI生产工具链，预装PyTorch、TensorFlow等主流深度学习框架，支持多版本环境快速克隆与切换，30秒即可搭建专属开发与调度环境，大幅提升研发与运维效率；<br/>提供完善的可视化监控告警与日志分析功能，实时呈现弹性伸缩动作、资源使用状态与业务运行情况，故障可快速定位、及时处置；<br/>支持伸缩策略的可视化配置与动态调整，无需大量人工干预，即可实现百万级核心错峰混部的全流程自动化运维，大幅降低企业的运维成本与技术门槛，助力企业快速落地算力优化方案。</p><h2>四、实践验证：SmoothCloud平台的实际应用价值</h2><p>应用案例：某大型互联网企业在推进AI模型训练与在线服务协同运营时，接入SmoothCloud平台，成功实现百万级核心错峰混部落地，解决了此前算力闲置与业务卡顿并存的难题；<br/>落地效果：在线业务高峰时段，平台瞬时触发扩容动作，快速补充算力资源，稳稳保障用户访问体验；夜间在线业务低谷时段，自动缩容并将闲置算力调度至AI模型训练任务，实现算力资源高效复用；<br/>核心收益：经实践验证，该企业的算力资源利用率从原来的40%提升至85%以上，算力成本直接降低60%，同时借助平台精细化资源隔离机制，在线业务响应延迟始终稳定在合理范围，真正实现了业务发展与成本控制的双向共赢。</p><h2>五、总结与普惠福利：携手SmoothCloud，解锁百万级算力价值</h2><h3>（一）核心总结</h3><p>随着数字化转型的持续深入，百万级核心错峰混部已成为企业提升算力效率、控制算力成本的必然选择，而自动化弹性伸缩技术则是实现这一目标的核心关键。SmoothCloud润云智算平台凭借强大的分布式算力底座、智能弹性伸缩引擎、精细化资源隔离机制与全链路运维工具链四大核心优势，成功打破传统混部模式的技术瓶颈，为大型企业、中小企业及科研机构，提供了高可靠、高性价比、低门槛的百万级核心错峰混部一体化解决方案，助力企业实现算力价值最大化。</p><h3>（二）公测普惠福利</h3><p>新用户注册：无需额外条件，注册即送25元算力代金券，可直接抵扣算力使用费用；<br/>新手任务：完成简单新手任务，再享25元算力福利，累计可获50元免费算力额度；<br/>首充福利：首次充值50元，即可解锁100元算力额度，充值福利直接翻倍；<br/>学生特权：高校学生完成身份认证后，可长期享受7.5折算力租赁优惠，助力科研与学习。</p><p>无论是大型企业的百万级核心调度需求，还是中小企业、科研机构的高性价比算力需求，均可携手润云智算SmoothCloud平台，以自动化弹性伸缩技术赋能错峰混部，解锁算力资源最大价值，降低数字化转型成本，加速企业数字化跃迁步伐。</p>]]></description></item><item>    <title><![CDATA[CPLD原理和应用 良许 ]]></title>    <link>https://segmentfault.com/a/1190000047607124</link>    <guid>https://segmentfault.com/a/1190000047607124</guid>    <pubDate>2026-02-12 12:10:19</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>大家好，我是良许</p><p>在嵌入式系统开发中，我们经常会遇到这样的场景：需要实现一些复杂的逻辑控制，但用单片机处理又显得响应速度不够快，或者需要大量的GPIO口来完成某些并行任务。</p><p>这时候，CPLD就成为了一个非常好的选择。</p><p>今天我就来和大家聊聊CPLD的原理和实际应用。</p><h2>1. CPLD基础概念</h2><h3>1.1 什么是CPLD</h3><p>CPLD是一种可编程逻辑器件，它介于简单的PAL/GAL器件和复杂的FPGA之间。</p><p>简单来说，CPLD就像是一块"可以随意定制功能的数字芯片"，你可以通过编程的方式来定义它内部的逻辑电路，让它实现你想要的任何数字逻辑功能。</p><p>与传统的固定功能芯片不同，CPLD的最大特点就是灵活性。</p><p>比如说，今天你可以把它配置成一个串口转并口的转换器，明天你又可以把它改成一个多路信号选择器，甚至可以实现一个简单的状态机控制器。</p><p>这种灵活性在产品开发和调试阶段特别有用，因为你可以随时修改逻辑而不需要重新设计硬件电路板。</p><h3>1.2 CPLD的内部结构</h3><p>CPLD的内部主要由三大部分组成：逻辑阵列块（LAB）、可编程互连阵列和I/O控制块。</p><p>逻辑阵列块是CPLD的核心部分，它包含了多个宏单元。</p><p>每个宏单元通常包含一个与或阵列、一个触发器和一些配置逻辑。与或阵列可以实现任意的组合逻辑，而触发器则可以实现时序逻辑。</p><p>这种结构使得CPLD既可以实现组合逻辑电路，也可以实现时序逻辑电路。</p><p>可编程互连阵列就像是CPLD内部的"高速公路网"，它负责连接各个逻辑阵列块，使得不同的逻辑单元可以相互通信。</p><p>这个互连网络的质量直接影响到CPLD的性能和延迟特性。</p><p>I/O控制块则负责管理CPLD与外部世界的接口。</p><p>它可以配置每个引脚的输入输出方向、电平标准、驱动能力等参数。</p><p>现代的CPLD通常支持多种I/O标准，比如LVTTL、LVCMOS、LVDS等，这使得它可以方便地与各种不同的器件进行接口。</p><h3>1.3 CPLD与FPGA的区别</h3><p>很多人会把CPLD和FPGA混淆，虽然它们都是可编程逻辑器件，但实际上有很大的区别。</p><p>从架构上看，CPLD采用的是粗粒度的架构，内部由若干个逻辑阵列块组成，每个块包含较多的逻辑资源。</p><p>而FPGA采用的是细粒度架构，由大量的小型查找表（LUT）和触发器组成。</p><p>这就好比CPLD是用大块积木搭建，而FPGA是用小颗粒积木搭建。</p><p>从存储方式来看，CPLD通常使用非易失性存储器（如EEPROM或Flash），这意味着断电后配置信息不会丢失，上电即可工作。</p><p>而大多数FPGA使用的是SRAM配置存储器，断电后配置会丢失，需要外部配置芯片或主控芯片在每次上电时重新加载配置。</p><p>从性能角度看，CPLD的延迟更加可预测，因为它的互连结构相对固定。</p><p>而FPGA虽然资源更丰富，但布线延迟可能会因为设计的不同而变化较大。</p><p>在我的实际项目中，当需要实现一些对时序要求严格但逻辑不太复杂的功能时，我通常会选择CPLD。</p><h2>2. CPLD的工作原理</h2><h3>2.1 可编程逻辑实现原理</h3><p>CPLD实现可编程逻辑的核心在于它的与或阵列结构。</p><p>这个结构基于一个简单但强大的数学原理：任何组合逻辑函数都可以表示为若干个乘积项的和。</p><p>举个简单的例子，假设我们要实现一个三输入的多数表决电路，当三个输入中至少有两个为1时输出才为1。</p><p>这个逻辑可以表示为：Y = AB + AC + BC。</p><p>在CPLD中，与门阵列会产生这三个乘积项，然后或门阵列将它们相加，最终得到输出结果。</p><p>在实际的CPLD器件中，与阵列和或阵列都是通过可编程的连接点来实现的。</p><p>这些连接点在早期的器件中是熔丝，烧断或保留来决定连接与否。</p><p>而在现代的CPLD中，通常使用EEPROM或Flash单元来控制连接，这样就可以反复编程了。</p><h3>2.2 宏单元的功能</h3><p>宏单元是CPLD中最基本的逻辑单元，它的设计非常巧妙。</p><p>一个典型的宏单元包含以下几个部分：</p><p>首先是乘积项分配器，它从与阵列接收若干个乘积项，并将它们分配给或门。</p><p>不同的CPLD器件，每个宏单元能接收的乘积项数量不同，一般在5到16个之间。</p><p>如果一个逻辑函数需要的乘积项超过了这个数量，就需要使用多个宏单元来实现。</p><p>其次是可配置的或门和异或门，它们可以实现各种组合逻辑功能。</p><p>异或门特别有用，因为很多实际应用中需要实现奇偶校验、加法器等功能，这些都需要异或运算。</p><p>然后是触发器，通常是D触发器，用于实现时序逻辑。</p><p>这个触发器可以配置为旁路模式或寄存模式。</p><p>触发器还可以配置时钟极性、复位方式、置位方式等参数。</p><p>最后是反馈路径，宏单元的输出可以反馈到互连阵列，从而可以被其他宏单元使用。</p><p>这种反馈机制使得CPLD可以实现复杂的多级逻辑和状态机。</p><h3>2.3 时钟和复位管理</h3><p>在数字系统设计中，时钟和复位信号的管理至关重要。</p><p>CPLD通常提供专用的全局时钟网络和复位网络，以确保这些关键信号能够以最小的延迟和最小的偏斜分配到所有的触发器。</p><p>大多数CPLD器件提供2到4个全局时钟输入，这些时钟可以驱动器件内所有的触发器而不需要经过一般的互连网络。</p><p>这样做的好处是可以保证时钟到达各个触发器的延迟基本一致，避免了时钟偏斜问题。</p><p>在我之前做的一个项目中，需要用CPLD实现一个多通道的同步采样控制器。</p><p>因为使用了全局时钟网络，所有通道的采样时刻可以保证在纳秒级别的精度内同步，这对于后续的信号处理非常关键。</p><h2>3. CPLD的开发流程</h2><h3>3.1 设计输入</h3><p>CPLD的开发通常使用硬件描述语言，主流的有Verilog和VHDL两种。</p><p>相比之下，Verilog的语法更接近C语言，对于我们这些做嵌入式软件出身的人来说更容易上手。</p><p>下面是一个简单的Verilog代码示例，实现一个8位的计数器：</p><pre><code class="verilog">module counter_8bit(
    input wire clk,           // 时钟输入
    input wire rst_n,         // 复位信号，低电平有效
    input wire enable,        // 使能信号
    output reg [7:0] count    // 8位计数输出
);

always @(posedge clk or negedge rst_n) begin
    if (!rst_n) begin
        count &lt;= 8'd0;        // 异步复位
    end else if (enable) begin
        count &lt;= count + 1'b1; // 计数加1
    end
end

endmodule</code></pre><p>这个计数器模块有时钟、复位、使能三个输入信号，以及一个8位的计数输出。</p><p>当复位信号为低电平时，计数器清零；当使能信号为高电平时，每个时钟上升沿计数器加1。</p><p>这种简单的逻辑在CPLD中实现起来非常高效。</p><p>除了HDL，一些CPLD开发工具还支持原理图输入方式。</p><p>对于一些简单的逻辑，使用原理图可能更直观。</p><p>但对于复杂的设计，HDL的优势就体现出来了：代码更容易维护、修改和复用。</p><h3>3.2 综合与适配</h3><p>写完HDL代码后，需要经过综合和适配两个步骤，才能生成可以下载到CPLD的配置文件。</p><p>综合过程是将HDL代码转换为逻辑门级的网表。</p><p>综合器会分析你的代码，优化逻辑，并将其映射到CPLD的基本逻辑单元上。</p><p>这个过程中，综合器会做很多优化工作，比如消除冗余逻辑、合并相同的逻辑、优化关键路径等。</p><p>适配过程则是将综合后的逻辑网表映射到具体的CPLD器件上。</p><p>这个过程需要决定每个逻辑单元使用哪个宏单元，各个信号使用哪些互连资源，I/O信号使用哪些引脚等。</p><p>适配的质量直接影响到最终设计的性能和资源利用率。</p><p>在我的经验中，对于一些对时序要求严格的设计，可能需要反复调整代码和约束条件，多次进行综合和适配，才能达到满意的结果。</p><p>这个过程有点像软件开发中的性能优化，需要耐心和经验。</p><h3>3.3 仿真与验证</h3><p>在将设计下载到实际的CPLD器件之前，进行充分的仿真验证是非常必要的。</p><p>仿真可以帮助我们发现设计中的逻辑错误，而且修改起来比在硬件上调试要方便得多。</p><p>CPLD的仿真通常分为功能仿真和时序仿真两种。</p><p>功能仿真只验证逻辑功能是否正确，不考虑实际的延迟。</p><p>而时序仿真则会考虑CPLD内部的实际延迟，可以发现一些时序相关的问题。</p><p>下面是一个简单的testbench示例，用于测试前面的8位计数器：</p><pre><code class="verilog">module counter_8bit_tb;

reg clk;
reg rst_n;
reg enable;
wire [7:0] count;

// 实例化被测试模块
counter_8bit uut (
    .clk(clk),
    .rst_n(rst_n),
    .enable(enable),
    .count(count)
);

// 生成时钟信号，周期为20ns（50MHz）
initial begin
    clk = 0;
    forever #10 clk = ~clk;
end

// 测试序列
initial begin
    // 初始化信号
    rst_n = 0;
    enable = 0;
    
    // 复位100ns
    #100;
    rst_n = 1;
    
    // 使能计数器
    #50;
    enable = 1;
    
    // 运行500ns观察计数
    #500;
    
    // 禁止计数
    enable = 0;
    #100;
    
    // 再次使能
    enable = 1;
    #300;
    
    $stop;
end

endmodule</code></pre><p>这个testbench会生成时钟信号，并控制复位和使能信号，然后观察计数器的输出是否符合预期。</p><p>通过仿真，我们可以在波形图中清楚地看到计数器的工作过程。</p><h2>4. CPLD的实际应用</h2><h3>4.1 接口转换与扩展</h3><p>在嵌入式系统中，接口转换是CPLD最常见的应用之一。</p><p>比如说，你的主控芯片只有一个SPI接口，但需要控制多个SPI设备，这时就可以用CPLD来实现SPI接口的扩展和仲裁。</p><p>我曾经做过一个项目，需要将一个并行的LCD接口转换为LVDS接口。</p><p>使用STM32的FSMC接口可以很方便地驱动并行LCD，但项目要求使用LVDS接口的显示屏以降低EMI。</p><p>这时候，在STM32和显示屏之间加入一个CPLD，就完美地解决了这个问题。</p><p>CPLD接收FSMC的并行数据和控制信号，然后按照LVDS协议将数据串行化输出。</p><p>这种应用的好处是不需要修改主控芯片的软件，只需要像驱动普通并行LCD一样操作FSMC接口即可。</p><p>所有的协议转换工作都由CPLD在硬件层面完成，而且速度很快，延迟很小。</p><h3>4.2 逻辑粘合与控制</h3><p>在复杂的嵌入式系统中，经常需要一些"粘合逻辑"来协调不同芯片之间的工作。</p><p>比如说，需要根据多个传感器的状态来控制某些执行器的动作，或者需要实现一些复杂的时序控制。</p><p>举个例子，在一个电机控制系统中，需要根据多个限位开关的状态、编码器的信号以及主控芯片的命令来生成PWM信号和方向控制信号。</p><p>如果用主控芯片的软件来实现这些逻辑，可能会因为中断延迟或任务调度的问题导致响应不够及时。</p><p>而使用CPLD来实现这些逻辑，可以保证在纳秒级别的时间内做出响应，大大提高了系统的实时性和可靠性。</p><p>下面是一个简单的状态机示例，用于控制一个简单的步进电机：</p><pre><code class="verilog">module stepper_motor_ctrl(
    input wire clk,
    input wire rst_n,
    input wire [1:0] direction,  // 00:停止 01:正转 10:反转
    input wire step_pulse,       // 步进脉冲
    output reg [3:0] motor_phase // 电机相位输出
);

// 状态定义
localparam PHASE_0 = 4'b0001;
localparam PHASE_1 = 4'b0010;
localparam PHASE_2 = 4'b0100;
localparam PHASE_3 = 4'b1000;

reg [3:0] current_phase;
reg step_pulse_d1;
wire step_pulse_posedge;

// 检测步进脉冲上升沿
always @(posedge clk or negedge rst_n) begin
    if (!rst_n)
        step_pulse_d1 &lt;= 1'b0;
    else
        step_pulse_d1 &lt;= step_pulse;
end

assign step_pulse_posedge = step_pulse &amp; ~step_pulse_d1;

// 状态机
always @(posedge clk or negedge rst_n) begin
    if (!rst_n) begin
        current_phase &lt;= PHASE_0;
    end else if (step_pulse_posedge) begin
        case (direction)
            2'b01: begin  // 正转
                case (current_phase)
                    PHASE_0: current_phase &lt;= PHASE_1;
                    PHASE_1: current_phase &lt;= PHASE_2;
                    PHASE_2: current_phase &lt;= PHASE_3;
                    PHASE_3: current_phase &lt;= PHASE_0;
                    default: current_phase &lt;= PHASE_0;
                endcase
            end
            2'b10: begin  // 反转
                case (current_phase)
                    PHASE_0: current_phase &lt;= PHASE_3;
                    PHASE_1: current_phase &lt;= PHASE_0;
                    PHASE_2: current_phase &lt;= PHASE_1;
                    PHASE_3: current_phase &lt;= PHASE_2;
                    default: current_phase &lt;= PHASE_0;
                endcase
            end
            default: current_phase &lt;= current_phase;  // 保持
        endcase
    end
end

always @(*) begin
    motor_phase = current_phase;
end

endmodule</code></pre><p>这个模块实现了一个四相步进电机的控制逻辑，根据方向信号和步进脉冲来切换电机的相位。</p><p>这种逻辑如果用软件实现，需要占用CPU时间并且可能受到中断延迟的影响，而用CPLD实现则可以保证实时性。</p><h3>4.3 信号处理与数据采集</h3><p>CPLD在信号处理和数据采集系统中也有广泛应用。</p><p>它可以实现高速的数据缓冲、协议转换、数据预处理等功能。</p><p>在我参与的一个多通道数据采集项目中，需要同时采集16路模拟信号。</p><p>我们使用了两片8通道的高速ADC，每片ADC的输出是并行数据接口。</p><p>如果直接用STM32来读取这些数据，GPIO口的数量会不够用，而且很难保证多通道的同步性。</p><p>我们的解决方案是使用一片CPLD来接收两片ADC的数据，在CPLD内部进行数据缓冲和打包，然后通过一个高速并行接口（传输给STM32。</p><p>CPLD还负责生成ADC的采样时钟和控制信号，保证所有通道的采样严格同步。</p><p>这种架构的优点是：第一，节省了主控芯片的GPIO资源。</p><p>第二，提高了数据采集的同步性和实时性。</p><p>第三，降低了主控芯片的软件复杂度，因为数据的缓冲和打包都由CPLD在硬件层面完成了。</p><h3>4.4 系统调试与测试</h3><p>CPLD还可以作为系统调试和测试的辅助工具。</p><p>比如说，可以用CPLD来生成各种测试信号，或者监控系统中的关键信号。</p><p>在产品开发阶段，我经常会用CPLD来实现一些调试功能。</p><p>比如说，在CPLD中实现一个逻辑分析仪的功能，可以捕获系统中的关键信号，然后通过某个接口（比如UART）输出到PC上进行分析。</p><p>这比使用专门的逻辑分析仪要灵活得多，因为你可以根据需要随时修改触发条件和采样逻辑。</p><p>另外，CPLD还可以用来模拟一些外部设备。</p><p>比如说，在开发阶段，某个外部传感器还没有到货，但你需要测试主控芯片的软件。</p><p>这时候可以用CPLD来模拟这个传感器的行为，生成符合协议的数据和时序，这样就可以在没有实际硬件的情况下进行软件开发和测试了。</p><h2>5. CPLD选型与使用建议</h2><h3>5.1 如何选择合适的CPLD</h3><p>选择CPLD时需要考虑几个关键因素。</p><p>首先是逻辑资源，通常用宏单元的数量来衡量。</p><p>对于简单的接口转换，可能只需要几十个宏单元。</p><p>而对于复杂的控制逻辑，可能需要几百个宏单元。</p><p>其次是I/O资源，包括I/O引脚的数量和支持的电平标准。</p><p>如果你的应用需要连接很多外部信号，就需要选择I/O资源丰富的器件。</p><p>同时要注意I/O引脚支持的电平标准是否满足你的需求，比如是否支持3.3V、2.5V或1.8V等。</p><p>第三是速度性能，主要看最高工作频率和引脚到引脚的延迟。</p><p>对于一些高速应用，比如高速数据采集或通信接口，需要选择速度等级较高的器件。</p><p>第四是封装形式，常见的有PLCC、TQFP、BGA等。</p><p>对于手工焊接或小批量生产，PLCC或TQFP封装比较合适。</p><p>对于大批量生产，BGA封装虽然焊接难度大一些，但可以提供更多的引脚和更好的电气性能。</p><p>最后是开发工具的支持和器件的供货情况。</p><p>主流的CPLD厂商有Xilinx（现在是AMD）、Intel（原Altera）、Lattice等，它们都提供免费的开发工具。</p><p>在选型时要考虑开发工具是否好用，以及器件的供货是否稳定。</p><h3>5.2 设计中的注意事项</h3><p>在使用CPLD进行设计时，有一些需要注意的地方。</p><p>首先是时钟设计，尽量使用全局时钟网络，避免使用门控时钟。</p><p>如果必须使用多个时钟域，要注意跨时钟域的信号同步问题，可以使用双触发器同步或FIFO等方法。</p><p>其次是复位设计，建议使用异步复位、同步释放的方式。</p><p>也就是说，复位信号的有效是异步的，但释放时要与时钟同步，这样可以避免复位释放时的亚稳态问题。</p><p>第三是I/O约束，要在设计中明确指定每个信号使用哪个引脚，以及引脚的电气特性（比如驱动强度、上下拉电阻等）。</p><p>这些约束通常写在一个单独的约束文件中。</p><p>第四是时序约束，对于一些对时序要求严格的设计，需要添加时序约束，告诉综合和适配工具你的时序要求。</p><p>比如可以约束时钟频率、输入输出延迟、路径延迟等。</p><p>最后是代码风格，建议使用同步设计风格，避免使用过多的组合逻辑。</p><p>在Verilog中，尽量使用阻塞赋值（=）来描述组合逻辑，使用非阻塞赋值（&lt;=）来描述时序逻辑。</p><p>这样可以避免很多仿真和综合的问题。</p><h3>5.3 与单片机的配合使用</h3><p>在实际项目中，CPLD通常不是单独使用的，而是与单片机配合使用。</p><p>这种组合可以发挥各自的优势：单片机负责复杂的算法和控制逻辑，CPLD负责高速的数据处理和接口转换。</p><p>在我的项目经验中，通常会让STM32作为主控，负责整体的控制流程、人机交互、通信等功能。</p><p>而CPLD作为协处理器，负责一些对实时性要求高的任务，比如高速数据采集、精确的时序控制、复杂的接口转换等。</p><p>STM32与CPLD之间的通信可以采用多种方式。</p><p>最简单的是并行接口，使用STM32的FSMC或FMC外设，可以像访问外部SRAM一样访问CPLD内部的寄存器。</p><p>这种方式速度快，接口简单，是我最常用的方式。</p><p>也可以使用串行接口，比如SPI或I2C。这种方式占用的引脚少，但速度相对较慢。</p><p>对于一些控制信号或低速数据，使用串行接口是比较合适的。</p><p>在软件设计上，可以把CPLD看作是一个外设，为它编写相应的驱动程序。</p><p>比如定义一些寄存器地址，然后通过读写这些寄存器来控制CPLD或读取CPLD的状态。下面是一个简单的示例：</p><pre><code class="c">// CPLD寄存器地址定义（假设使用FSMC Bank1 Sector1）
#define CPLD_BASE_ADDR    0x60000000
#define CPLD_CTRL_REG     (*(volatile uint16_t *)(CPLD_BASE_ADDR + 0x00))
#define CPLD_STATUS_REG   (*(volatile uint16_t *)(CPLD_BASE_ADDR + 0x02))
#define CPLD_DATA_REG     (*(volatile uint16_t *)(CPLD_BASE_ADDR + 0x04))

// 控制寄存器位定义
#define CPLD_CTRL_ENABLE  (1 &lt;&lt; 0)
#define CPLD_CTRL_RESET   (1 &lt;&lt; 1)
#define CPLD_CTRL_START   (1 &lt;&lt; 2)

// 状态寄存器位定义
#define CPLD_STATUS_READY (1 &lt;&lt; 0)
#define CPLD_STATUS_BUSY  (1 &lt;&lt; 1)
#define CPLD_STATUS_ERROR (1 &lt;&lt; 2)

// CPLD初始化函数
void CPLD_Init(void)
{
    // 配置FSMC用于访问CPLD
    // ... FSMC配置代码 ...
    
    // 复位CPLD
    CPLD_CTRL_REG = CPLD_CTRL_RESET;
    HAL_Delay(10);
    CPLD_CTRL_REG = 0;
    
    // 使能CPLD
    CPLD_CTRL_REG = CPLD_CTRL_ENABLE;
}

// 等待CPLD就绪
HAL_StatusTypeDef CPLD_WaitReady(uint32_t timeout)
{
    uint32_t tickstart = HAL_GetTick();
    
    while (!(CPLD_STATUS_REG &amp; CPLD_STATUS_READY)) {
        if ((HAL_GetTick() - tickstart) &gt; timeout) {
            return HAL_TIMEOUT;
        }
    }
    
    return HAL_OK;
}

// 向CPLD写入数据
HAL_StatusTypeDef CPLD_WriteData(uint16_t data)
{
    // 等待CPLD就绪
    if (CPLD_WaitReady(100) != HAL_OK) {
        return HAL_TIMEOUT;
    }
    
    // 写入数据
    CPLD_DATA_REG = data;
    
    // 启动处理
    CPLD_CTRL_REG |= CPLD_CTRL_START;
    
    return HAL_OK;
}

// 从CPLD读取数据
HAL_StatusTypeDef CPLD_ReadData(uint16_t *data)
{
    // 等待CPLD就绪
    if (CPLD_WaitReady(100) != HAL_OK) {
        return HAL_TIMEOUT;
    }
    
    // 读取数据
    *data = CPLD_DATA_REG;
    
    return HAL_OK;
}</code></pre><p>这样的驱动程序可以很好地封装CPLD的底层操作，使得上层应用程序可以方便地使用CPLD的功能，而不需要关心具体的硬件细节。</p><h2>总结</h2><p>CPLD作为一种灵活的可编程逻辑器件，在嵌入式系统设计中有着广泛的应用。</p><p>它可以实现接口转换、逻辑粘合、信号处理等多种功能，是单片机的理想伙伴。</p><p>虽然CPLD的开发需要学习硬件描述语言和数字逻辑设计，但一旦掌握了这些技能，就能够在项目中发挥很大的作用，解决很多用纯软件难以解决的问题。</p><p>对于嵌入式工程师来说，掌握CPLD的使用可以大大扩展自己的技能范围，在面对复杂的系统设计时有更多的选择。</p><p>希望这篇文章能够帮助大家对CPLD有一个全面的了解，在实际项目中能够灵活运用这个强大的工具。</p><p><strong>更多编程学习资源</strong></p><ul><li><a href="https://link.segmentfault.com/?enc=QWIoCDXmPx4ZHMZbka%2FxCw%3D%3D.BZqrGV1OTMaslu0pys0eScjqh%2BYg%2BCU1rCCvmKuQrYTy2lrv3B2l2mhrI8mi0agexfgwxQ%2B4I4%2FAsIdyJPBomw%3D%3D" rel="nofollow" target="_blank">C语言零基础入门电子书-2026最新版</a></li><li><a href="https://link.segmentfault.com/?enc=amRyEoOMQPr3TihUp2U9tQ%3D%3D.KQ8x2RFYQlQrz2tVh%2FkeB5EpS8Y8FomzPk3ilgTWMgo3ocJ8KhGpl0Fr%2FFLfyFQ5Ee3sfG%2BIm%2F9EXlPgNp2dIQ%3D%3D" rel="nofollow" target="_blank">STM32零基础入门电子书-2026最新版</a></li><li><a href="https://link.segmentfault.com/?enc=UIgUJCLvCQfrzXOZSJhIwA%3D%3D.57qwAVd1l3uyQOZF7FpX7QFMqC400Go0NOTs1VlgRieWmTXz8XAwZ%2FeHF0QA5wAwndYjr6g%2BkCCn2qvDQJqCWEoC7z%2BYOyYkFcUUcAoezgM%3D" rel="nofollow" target="_blank">FreeRTOS零基础入门电子书-2026最新版</a></li><li><a href="https://link.segmentfault.com/?enc=l5UfaIiJvdn6c5c9Iy%2FQgg%3D%3D.6BE5JBAav92Wzwcbkf6%2Fet9Jsy%2F3i31bHXkSfhw%2FOfNhB7tjUJnU1OtvSoN%2FYc93aU%2BlemLbhhn38%2F4bBbccNw%3D%3D" rel="nofollow" target="_blank">C++ 零基础入门电子书-2026最新版</a></li><li><a href="https://link.segmentfault.com/?enc=hfKULbsjh9AIrnLnWxmO6A%3D%3D.O2d1dcAzw8EyDCE4R28RRddIAY0F0gZ3D1%2BzCgsAN28It7SvZkHy40SRiw3PMiNiCMCFd39aQF1bB1GahTrsCA%3D%3D" rel="nofollow" target="_blank">51单片机零基础入门学习路线</a></li><li><a href="https://link.segmentfault.com/?enc=%2Bd3ruyBoTO1cgwL%2FHBxMvQ%3D%3D.v0%2F3eIKgfwZTITQH%2Bs%2BMY1G2cAb8kZG%2FJqlaMsHTowOPMaW5uIVjmJJAJCqUUw9HfrbXPdQ3Mockrku2fkuvUA%3D%3D" rel="nofollow" target="_blank">AD画板零基础入门学习路线</a></li><li><a href="https://link.segmentfault.com/?enc=wOcZJOJmmUMfo9Hz%2FIsTnw%3D%3D.B0X7dI87ElGXl79UbULzAg3u5e6D8wHiZ2Jll1o0JKXE3nT%2FBwe6Uy%2Fxx2sG29C6Al9%2BxRViKQjVwJQ5RPRUdw%3D%3D" rel="nofollow" target="_blank">C语言零基础入门学习路线</a></li><li><a href="https://link.segmentfault.com/?enc=a51nHmyMqLsZruVywdoJgg%3D%3D.%2FQ0pmsVa9yUb7PYlPtSkTmTl1Qi9RG8vWT0wcJEhyC8UkULIulbIbn3tzb5RvtFpZIo3ejsdV0x0nDO%2B6Pb%2B6Q%3D%3D" rel="nofollow" target="_blank">C++语言零基础入门学习路线</a></li><li><a href="https://link.segmentfault.com/?enc=H5SAvE%2B%2FZPeCkVBhuZ%2B5DA%3D%3D.boT3By%2FgkCT289D2%2FLhkrHdo4YRvYAk0pyRfBMEfUDHvckkPHMjIlZW4aqoUxxrAVtGm%2FwB%2F72V6bCE05rr5adJDIuHkoOrPqh1mW33Wm2A%3D" rel="nofollow" target="_blank">ESP32零基础入门学习路线</a></li><li><a href="https://link.segmentfault.com/?enc=mkrGLxF6m9lZiQRUfibg8w%3D%3D.PSavfhEuklTvmgq1ywkXYEJuPlBYIN0qFWLe0KjgMj9tWvIlfwXLYOK1GRGqH4qyLeWsV7r5a%2Frj%2FS7D3%2FDo8a8nyFXW5%2FdXWIhtnHa%2FXko%3D" rel="nofollow" target="_blank">FreeRTOS零基础入门学习路线</a></li><li><a href="https://link.segmentfault.com/?enc=yg5g9mnZv5RiCm%2F%2B6RvknA%3D%3D.DiM3zOQix4bdNxOLQaRqvqlRT91WhLfCxu2%2Bweu6q93GrJLuKa4USulg52eXmPxxzGtt8GFY26eIdur5KubsIK179G95pqZGSa%2F8eg6ZK9w%3D" rel="nofollow" target="_blank">Linux应用开发零基础入门学习路线</a></li><li><a href="https://link.segmentfault.com/?enc=vknz33SCQF05JJmMnFb0CA%3D%3D.JDt0Q7F5abXu3fOe9vwAcLpuqC9jKmeDUux2cx0jH5WIouxuLTa69zmCCmFKdfitT8aus%2BY4OlLgvXSQsurub1dxHRBWKRAiV1g4RimTwwQ%3D" rel="nofollow" target="_blank">Linux底层开发零基础入门学习路线</a></li><li><a href="https://link.segmentfault.com/?enc=Uh1EzyCpoYeKUfoSYvPNGg%3D%3D.8e5de8NQCEgtpRSuFtbYuPtkYjbnCD8lOI4XKI83GIeGKSVisPEQCoR%2Fhzic6i9zR6rNDlpu4ROX0ChILVaxBw%3D%3D" rel="nofollow" target="_blank">LVGL零基础入门学习路线</a></li><li><a href="https://link.segmentfault.com/?enc=As2MuIOnPKvcpZiUktvfOg%3D%3D.X1b1MpwVOJ35aAa7GigRJiSCfyZi7ltXK8VnTOMzo%2FaSGCG8ExgoaaWA11L9NXTcuDY8Ur0%2F0BhcFXFsNXIimg%3D%3D" rel="nofollow" target="_blank">QT零基础入门学习路线</a></li><li><a href="https://link.segmentfault.com/?enc=I4B3jZsmAv%2FZP1B4xY0lOQ%3D%3D.WR%2Bto%2FSZsGWN1j7GVt%2FwEu64tZoHPxcR4Tz9UWW9%2FuTyCLAW4s23vk9l3X7ssZUO97i3%2F1QtEKuYfC8%2FnMkQ%2FY6Ju2q7T7lzMc2384LPh20%3D" rel="nofollow" target="_blank">STM32零基础入门学习路线</a></li></ul>]]></description></item><item>    <title><![CDATA[数据治理新解法：基于算子级血缘的主动元数据如何破解数仓重构难题？ Aloudata大应科技 ]]></title>    <link>https://segmentfault.com/a/1190000047607132</link>    <guid>https://segmentfault.com/a/1190000047607132</guid>    <pubDate>2026-02-12 12:09:41</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <blockquote>本文首发于 Aloudata 官方技术博客：<a href="https://link.segmentfault.com/?enc=Hxgz4Zo%2Fi7OC8ZTVtmEJJA%3D%3D.1J94Vhl%2BwOcPRe71SePl2LVyVmyZWplSQ%2FkMkXuCiunkz8GUNDoFyk3USqezng8I%2F43MzstOic6UDM3lBKziSm%2FKvcq4KKDVzpcQTvZxI9P5js6cPsHtHeIN9p3PaYsMgqDj9GNnwv6I7zNS%2F5MUEg%3D%3D" rel="nofollow" target="_blank">《数仓重构不敢动刀？主动元数据如何帮你「看清」15 层依赖链路》</a>转载请注明出处。</blockquote><p>摘要：本文深入探讨了数据仓库重构中因依赖链路“看不清”而导致的三大核心痛点：依赖黑盒、变更失控与成本黑洞。通过对比传统血缘工具的局限，解析了基于算子级血缘的新技术范式如何通过&gt;99%的解析准确率、行级裁剪等能力，实现数据链路的“白盒化”透视与精准影响分析。文章结合招商银行、浙江农商联合银行等标杆案例，展示了主动元数据平台在自动化盘点、DataOps协同及模型治理等场景下的落地路径与量化价值。</p><p>数据仓库重构是许多企业数据治理与现代化进程中的关键一步，但“看不清”复杂的依赖链路往往让决策者望而却步。传统血缘工具在解析精度和颗粒度上的不足，导致变更风险高、治理成本失控。本文将系统分析这一痛点，并介绍基于算子级血缘的主动元数据技术如何提供“白盒化”的解决方案，实现从“不敢动”到“精准动”的转变。</p><h2>一、 数仓重构为何“不敢动刀”？三大“看不清”的致命伤</h2><p>数仓重构的决策瘫痪，往往源于对复杂数据链路“看不清、管不住、治不动”的恐惧。这种恐惧并非空穴来风，而是由三个具体且致命的“看不清”问题所引发。</p><ol><li>依赖黑盒：链路断裂，盘点如大海捞针 传统数据血缘工具（表级/列级）的解析率普遍偏低（通常&lt;80%）。当面对多层嵌套、存储过程、动态 SQL 等复杂加工逻辑时，血缘图谱常常“断线”或“错连”，导致链路完整性严重不足。一个典型的场景是：为满足监管报送（如 EAST/1104）要求，数据团队需要人工盘点某个核心指标的完整加工口径。这个过程往往需要数周时间，逐层扒代码、询问开发人员，最终得到的链路完整性可能不足 20%。</li><li>变更失控：影响扩散，风险如病毒蔓延 上游数据模型或加工逻辑的微小变更，可能因无法精准评估影响范围而引发连锁反应。例如，上游字段类型修改或逻辑变动，由于传统血缘无法精准识别过滤、连接等算子，导致下游所有依赖该字段的报表、应用都被“误伤”，引发核心报表挂掉或数据错误，甚至造成直接资损风险。变更影响波及范围完全无法预估，让每一次上线都如履薄冰。</li><li>成本黑洞：治理失效，资源被无声吞噬 “运动式”的数据治理不可持续。由于缺乏对数据资产全貌的清晰认知，模型冗余、烟囱式开发、重复计算等问题普遍存在，导致计算和存储成本失控。大量“同义不同名”的重复资产和无人知晓其价值的“暗数据”占据着宝贵资源，形成巨大的成本黑洞，严重侵蚀数据投资的回报率。</li></ol><h2>二、 根因分析：传统血缘为何“失灵”？精度与颗粒度的双重缺失</h2><p>传统血缘工具在精细化、动态化的数仓重构场景下频频“失灵”，其根本原因在于技术范式的固有局限。</p><table><thead><tr><th>对比维度</th><th>传统血缘工具 (表级/列级)</th><th>核心缺陷</th></tr></thead><tbody><tr><td>解析精度</td><td>解析准确率低（&lt;80%），无法覆盖复杂SQL、存储过程。</td><td>基于正则或简单解析，面对动态SQL、嵌套子查询、DB2/GaussDB 的 PL/SQL 存储过程时，图谱“断线”或“错连”。</td></tr><tr><td>分析颗粒度</td><td>表级血缘过于泛化，列级血缘无法识别计算逻辑。</td><td>无法识别 WHERE（过滤）、JOIN（连接）、GROUP BY（聚合）等关键算子，导致影响分析范围被无限放大，噪点极多。</td></tr><tr><td>管理模式</td><td>被动、静态的元数据管理。</td><td>仅记录数据结构的静态快照，缺乏对数据流动、加工逻辑和变更影响的实时感知与主动干预能力，与 DataOps 所要求的自动化、协同化严重脱节。</td></tr></tbody></table><p>核心结论：传统工具在精度和颗粒度上的双重缺失，使其无法胜任数仓重构所需的“白盒化”分析和“手术刀式”精准治理。</p><h2>三、 新范式解法：算子级血缘——为数据链路装上“CT扫描仪”</h2><p>要根治“看不清”的顽疾，必须从技术底层进行革新。算子级血缘 (Operator-level Lineage) 技术，通过深入到 SQL 内部的算子逻辑，实现了对数据链路的“白盒化”透视，这是根本性的技术突破。</p><ol><li>精度突破：从“模糊影像”到“高清扫描” 基于 AST (抽象语法树) 的完整 SQL 解析引擎，使解析准确率突破至 &gt;99%。无论是复杂的嵌套查询、动态 SQL，还是 DB2、GaussDB 等数据库的 PL/SQL 存储过程，都能被完整解析，构建出端到端、无断点的全链路血缘图谱。</li><li>核心能力：行级裁剪，实现“精准打击” 这是算子级血缘带来的革命性能力。传统血缘在评估上游表变更（如删除字段）时，会“一刀切”地告警所有下游节点。而行级裁剪能精准识别 WHERE 过滤条件，自动剔除那些通过条件过滤掉的、实际上不受影响的数据分支。</li></ol><ul><li>价值：将需要人工评估的下游报表、模型数量减少 80% 以上，极大降低变更评估的工作量和误报率。</li></ul><ol start="3"><li>白盒化口径提取：从“扒代码”到“一键洞察” 面对跨越 15 层甚至更多层的复杂 SQL 加工链路，可以自动将层层嵌套的逻辑，压缩、还原成一段可读的业务口径描述。数据治理人员无需再逐层人工扒代码，极大提升了监管溯源、问题排查的效率。</li></ol><h2>四、 落地路径：从“看清”到“管好”的四步实践</h2><p>借助主动元数据平台，企业可以构建一套闭环的数据管理能力，让数仓重构从临时的“运动式”项目，转变为可持续的“常态化”机制。</p><p>步骤一：自动化资产盘点</p><ul><li>场景：监管报送指标口径溯源、资产目录构建。</li><li>实践：通过“一键溯源”，自动生成 EAST/1104 等监管指标的完整加工口径与血缘报告。</li><li>案例成效：浙江农商联合银行将监管指标的人工盘点周期从数月缩短至 8 小时，人效提升 20 倍。</li></ul><p>步骤二：全链路主动风险防控 建立“事前/事中/事后”的协同防控机制：</p><ul><li>事前：代码上线前，自动评估 SQL 变更对下游核心报表和模型的影响范围，提供精准的影响报告。</li><li>事中/事后：当任务调度异常或数据质量告警时，能基于血缘快速定位根因，将排查时间从“小时级”缩短至“分钟级”。</li><li>案例成效：中国民生银行构建了“事前事中变更协作机制”，实现了对核心链路资产保障范围的自动保鲜。</li></ul><p>步骤三：主动模型治理</p><ul><li>场景：数仓优化、模型迁移（如 Oracle 转国产库）。</li><li>实践：自动识别模型“坏味道”，如链路过长、循环依赖、重复计算，并给出重构建议，甚至生成建议代码。</li><li>价值：从“发现病灶”到“开具药方”，辅助数据架构师科学决策，降低重构风险。</li></ul><p>步骤四：DataOps 协同，驱动智能化研发</p><ul><li>场景：数据开发、测试、上线全流程。</li><li>实践：作为 DataOps 的“控制流”，将精准的血缘信息融入 CI/CD 流程，实现元数据驱动的智能化研发与上线。</li><li>案例成效：招商银行在数仓迁移与 DataOps 实践中，通过自动化工具节省了 500+ 人月 的工作量。</li></ul><h2>五、 价值验证：标杆客户如何用“手术刀”完成高难度重构</h2><p>金融行业头部客户的实践，为算子级血缘与主动元数据的价值提供了最有力的量化证明。</p><table><thead><tr><th>客户</th><th>核心场景</th><th>关键成效</th></tr></thead><tbody><tr><td>招商银行</td><td>数仓迁移、DataOps协同</td><td>自动化迁移工具节省 500+ 人月，预期收益超 2000万；数据测试工作量节省 50%；代码上线前评估与整改效率大幅提升。</td></tr><tr><td>浙江农商联合银行</td><td>监管指标溯源、DB2存储过程解析</td><td>监管指标盘点从数月缩短至 8小时；DB2存储过程血缘解析准确率达 99%；模型迁移缺口分析准确率 80%。</td></tr><tr><td>兴业银行</td><td>跨异构平台血缘治理、敏感数据打标</td><td>跨平台链路完整性从 20% 提升至 90%；变更影响分析扩散度降低 80%；敏感标签自动扩散效率提升 95%。</td></tr><tr><td>行业背书</td><td>技术权威认可</td><td>入选 Gartner Active Metadata 报告、IDC 金融数据管理最佳实践、信通院大数据“星河”标杆案例。</td></tr></tbody></table><h2>六、 常见问题 (FAQ)</h2><h4>Q1: 算子级血缘和传统的列级血缘到底有什么区别？</h4><p>算子级血缘不仅解析字段间的映射关系，更深入到 SQL 内部的过滤、连接、聚合等计算逻辑（即“算子”）。这带来了质的不同：解析准确率从通常的 &lt;80% 提升至 &gt;99%，并能实现“行级裁剪”等高级分析，精准评估变更影响，而列级血缘无法做到这一点。</p><h4>Q2: 我们的数仓有很多存储过程和复杂 SQL，能解析吗？</h4><p>可以。以 Aloudata BIG 为例，其核心技术壁垒之一就是支持复杂场景，包括 DB2、GaussDB 等的 PL/SQL 存储过程、动态 SQL、嵌套子查询、临时表穿透等。例如，浙江农商联合银行的 DB2 存储过程血缘解析准确率达到了 99%。</p><h4>Q3: 引入主动元数据平台，实施周期会不会很长，如何看到效果？</h4><p>实施通常从核心痛点场景切入，如监管指标溯源或变更影响分析，几周内即可完成对接并看到初步效果。标杆客户的经验表明，在自动化盘点等场景，效率提升是立竿见影的（如从数月缩短到 8 小时），投资回报周期短。</p><h4>Q4: 除了金融行业，其他行业在数仓重构时也适用吗？</h4><p>完全适用。“看不清依赖链路”是各行业数仓重构的共性痛点。主动元数据平台作为 DataOps 的基石，其价值在于提供通用的数据链路可观测性和自动化治理能力，在制造、零售、电信等行业同样有广阔应用前景。</p><h4>Q5: “行级裁剪”具体能带来什么好处？</h4><p>在评估上游表变更（如删除字段）对下游的影响时，行级裁剪能自动识别并剔除那些通过 WHERE 条件过滤掉的、实际上不受影响的数据分支。这能将需要人工检查的下游报表、模型数量减少 80% 以上，极大降低评估工作量和误报率。</p><h2>七、 核心要点总结</h2><ol><li>数仓重构的核心障碍是“看不清”：依赖黑盒、变更失控、成本黑洞三大痛点，均源于传统血缘工具在精度和颗粒度上的固有缺陷。</li><li>算子级血缘是技术突破的关键：通过 &gt;99% 的解析准确率和行级裁剪能力，实现了对数据链路的“白盒化”透视和“精准化”影响分析。</li><li>主动元数据驱动治理闭环：从自动化盘点、主动风控到模型治理、DataOps协同，构建了可持续的、常态化的数据管理能力。</li><li>价值已获头部客户验证：招商银行、浙江农商联合银行等标杆案例，以节省数百人月、效率提升数十倍等量化成果，证明了该技术范式的巨大商业价值。</li><li>选择具备复杂场景解析能力的平台：在选型时，应重点关注其对存储过程、复杂 SQL 的解析能力，以及是否具备行级裁剪等高级分析功能。</li></ol><p>本文首发于 Aloudata 官方技术博客，查看更多技术细节与高清图表，请访问原文链接：<a href="https://link.segmentfault.com/?enc=Rifug%2BoC6nnp%2F3ulVAA26Q%3D%3D.ETIehasLHTKromHBUAQWNbjwTYa1YufHpDH8UcrVvZ1qoRSq3oaGui6AuOZX13K34B%2FljA8yREMNBl%2Bzko%2BzXa4T5JvCccqOrs7hGY0WSpJjv2OeH9X3QCd2%2BbfqtxXPFXODNRGHVQHrECSustxYhQ%3D%3D" rel="nofollow" target="_blank">https://ai.noetl.cn/knowledge-base/data-warehouse-reconstruct...</a></p>]]></description></item><item>    <title><![CDATA[高频交易者实测：免费股票数据API，开发者对接真的高效？ 我不是股神ber ]]></title>    <link>https://segmentfault.com/a/1190000047607142</link>    <guid>https://segmentfault.com/a/1190000047607142</guid>    <pubDate>2026-02-12 12:09:03</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>做个人高频交易多年，同时也是一名常年和代码打交道的开发者，我深知实时、稳定的股票数据，对量化策略验证、自选股监控的重要性。对我们这类“交易者+开发者”双重身份的人来说，付费股票数据API的高昂成本实在不划算，而免费API又良莠不齐，要么对接复杂、调试耗时，要么数据延迟、满足不了高频交易需求，找到一款简单易用、适配开发场景的免费股票数据API，成了我提升实操与开发效率的关键。<br/>相信思否的很多开发者朋友，尤其是涉足个人量化交易的，都踩过类似的坑。比如部分免费API接口设计繁琐，需要复杂的认证流程，即便有扎实的开发基础，也得花费不少时间调试对接，严重占用策略优化和盯盘精力；有些API数据延迟过高，高频交易中几秒的滞后，可能直接错失最佳交易时机；还有些看似能用的免费API，隐藏着调用次数限制，盘中高频请求几次就会被限流、断连，反而给实操和开发添乱。</p><p>市面上免费的股票数据API不在少数，但真正能兼顾“开发者对接效率”和“高频交易者需求”的并不多。经过我反复实测、对比多款产品，总结出三个核心筛选标准，满足这三点，基本能适配大部分个人高频交易者+开发者的需求：一是实时性达标，数据能同步市场波动，无明显滞后，适配日内高频交易和策略快速验证；二是接口简洁易对接，无需复杂权限申请和配置，几行代码就能完成调用，降低开发调试成本；三是市场覆盖全面，支持A股、美股、港股及数字货币查询，满足多标的、跨市场监控需求。</p><p>结合这三个标准，我淘汰了大部分不合规的免费API，最终留下一款长期自用，偶尔会用<a href="https://link.segmentfault.com/?enc=oW9lNOIPd1JPvrjeJ51VAA%3D%3D.Kg48Q8ZYG%2BQ%2FmFfmcpgpEQnVEMpkRw1Yz3FVVyO1QBs%3D" rel="nofollow" target="_blank">AllTick</a>的实时行情接口辅助实操，整体对接体验还算流畅。这类优质免费API的核心优势，就是精准贴合我们的双重需求——不堆砌冗余功能，只把“数据稳定”和“对接高效”两个核心点做扎实。实时性上，数据能紧跟市场变化，延迟控制在合理范围，完全能满足日内高频交易的盯盘和策略验证需求；接口设计上，极简且规范，无需复杂认证，哪怕是刚接触相关开发的朋友，跟着文档调试，也能快速完成对接。</p><p>对开发者而言，更省心的是，这类API返回的数据格式规范统一，无需额外做复杂的数据清洗，直接用pandas就能完成分析处理，大大节省了开发和策略回测的时间成本。同时，其市场覆盖范围足够广，A股、美股、港股的核心标的数据都能轻松获取，偶尔研究数字货币行情也能满足，不用在多个工具、多个API之间来回切换，兼顾了开发效率和交易实操需求。</p><p>很多开发者朋友可能会问，免费API的对接难度到底如何？其实完全不用顾虑，以Python为例，通过WebSocket订阅数据的方式，就能快速实现实时行情获取，操作简单、门槛不高。我把平时实操对接中用到的基础示例放在下面，代码未做任何修改，大家可以根据自己关注的标的，调整订阅列表直接复用，后续我也会在评论区补充一些对接避坑和进阶用法</p><pre><code class="python">import websocket
import json

url = "wss://ws.alltick.co/realtime"

def on_message(ws, message):
    data = json.loads(message)
    symbol = data.get("symbol")
    price = data.get("price")
    print(f"{symbol} 最新价格: {price}")

def on_error(ws, error):
    print(f"连接错误: {error}")

def on_close(ws):
    print("连接关闭")

def on_open(ws):
    subscribe_msg = json.dumps({
        "action": "subscribe",
        "symbols": ["AAPL", "TSLA", "GOOG"]
    })
    ws.send(subscribe_msg)

ws = websocket.WebSocketApp(url,
                            on_open=on_open,
                            on_message=on_message,
                            on_error=on_error,
                            on_close=on_close)

ws.run_forever()
</code></pre><p>通过这个基础示例，我们可以轻松订阅自己关注的标的，实时接收股价更新，拿到数据后，还能快速实现去重、缓存等简单开发处理，避免重复处理相同数据，进一步提升开发和实操效率。除此之外，这类免费API大多还支持历史数据查询功能，这对我们做量化策略回测、模拟交易至关重要。<br/>这里也给思否的开发者朋友们，分享两个我长期实操总结的对接避坑技巧，都是能直接落地的干货：一是有批量订阅多标的需求时，建议将订阅请求拆分成多个小请求，避免触发接口调用限制，减少调试麻烦；二是高频交易对网络稳定性要求较高，建议在代码中添加重连机制，防止网络波动导致数据中断，影响盯盘和策略执行，这个功能对开发者来说不难实现，简单修改几行代码就能完成，却能大幅提升使用体验。</p><p>对我们这类“个人高频交易者+开发者”来说，免费股票数据API的核心价值，就是以最低的成本，实现高效、稳定的行情数据获取，既能支撑日常交易决策，也能适配简单的开发、策略验证需求。不用被付费工具的高昂成本束缚，也不用为复杂的对接流程耗费精力，选对一款合适的免费API，就能轻松搭建起简易的行情监控系统，无论是本地运行实时行情面板，还是设置价格触发通知，都能快速开发实现。</p><p>最后也欢迎思否的开发者、个人高频交易者朋友们，在评论区交流API对接技巧、量化策略开发经验，互相避坑、共同提升，后续我也会持续分享更多实操干货。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdnUXh" alt="" title=""/></p>]]></description></item><item>    <title><![CDATA[2026年低代码软件开发工具推荐合集 UXbot ]]></title>    <link>https://segmentfault.com/a/1190000047607146</link>    <guid>https://segmentfault.com/a/1190000047607146</guid>    <pubDate>2026-02-12 12:08:11</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>预算三万、工期三周、没有程序员——这就是小企业数字化的“死亡三角”。传统外包听到需求就报价十五万，时间排期半年起步；低代码的AI软件开发工具却用大语言模型把死亡三角变成黄金三角：业务人员输入需求→获取PRD→获取原型图&amp;界面设计→同步获得前端代码，Saas、电商、餐饮平台三天上线。本文针对5款热门低代码AI开发工具做了横向对比，帮你快速找到契合自身需求的工具。</p><p>1.UXbot<br/>核心优势：主打 “AI 原型设计+ 低代码”，不用懂技术，输入文字描述就能生成完整应用。不管是想做 APP、网页还是平板端只要说清需求（比如 “设计医疗Saas管理系统，包在线医生咨询系统、预约挂号、提醒与通知等”），AI 会自动生成可视化PRD，支持拖拽修改，删减，软件交互逻辑和内容板块，确定好后，UXbot直接生成多页面可交互的原型+设计，颜色、布局、组件都能自定义，还能补全页面跳转逻辑。最重要的是，UXbot支持把高保真界面转换成Web前端代码，通过云端服务器完成全流程测试，生成的Vue格式代码，能直接导入开发环境使用，不用二次修改。从“产品需求-原型图-高保真设计-前端代码”都能在一个平台上搞定，高效推进网站开发落地，加快了产品上线以及后续迭代速度实测案例：我试了输入 “员工打卡考勤系统”，3 分钟就生成了登录、打卡、考勤统计 3 个核心页面，还自带数据看板。后续想加 “请假申请” 功能，拖拽组件、设置审批流程，10 分钟就搞定了。生成的 Vue.js 代码直接能给开发用，不用再反复沟通，支持项目分享协作、版本回溯，特别方便。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdnUW5" alt="image.png" title="image.png"/><br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdnUW7" alt="image.png" title="image.png" loading="lazy"/></p><p>2.Figma<br/>核心优势：原本是设计圈的 “协同王者”，现在低代码能力拉满。基于自然语言提示，可快速生成基础 UI 框架，并辅助完成组件库规整与布局优化。支持开发直接用插件把设计图转成 Vue.js、React 代码，不用手动还原样式。支持多人实时编辑，跨 Windows、Mac 系统都能用，组件库能共享，团队做设计时能保持风格统一。</p><p>缺陷：国内访问偶尔会卡顿，全英文界面对英语不好的朋友有点门槛。无法生成完整的原型图，并且免费版导出代码有次数限制，复杂功能需要装第三方插件，部分插件要付费。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdnDUR" alt="image.png" title="image.png" loading="lazy"/></p><p>3.Framer<br/>核心优势：专注于网页开发，不用写一行代码，拖拽组件就能做出响应式网页。内置很多现成模板，营销落地页、官网首页、个人博客都能直接套，还能加动画效果（比如滚动触发的渐变、按钮悬停效果），做完直接一键部署上线。</p><p>缺陷：更擅长做展示类、营销类网页，想做带复杂业务逻辑的管理系统就不太够用了。移动端适配虽然能自动调整，但部分细节还是需要手动微调才好看。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdnGZN" alt="image.png" title="image.png" loading="lazy"/></p><p>4.ProtoPie<br/>主打 “交互优先”，能把静态设计变成和真产品一样的原型。支持无代码设置复杂交互，比如点击按钮弹出弹窗、滑动切换页面，甚至能调用手机陀螺仪、相机（比如做扫码功能原型）。可以导入 Figma、Sketch 的设计文件，快速给设计加交互，还能生成开发需要的交互说明文档。<br/>缺陷：主要是做原型验证，不能直接生成可上线的完整代码。后端数据对接能力弱，适合设计师、产品经理用来验证交互体验，而不是做最终上线的应用。<br/><img width="723" height="337" referrerpolicy="no-referrer" src="/img/bVdnCL9" alt="image.png" title="image.png" loading="lazy"/></p><p>总结</p><ul><li>新手 / 创业团队想快速验证想法：选 UXbot，AI 生成完整可交互的原型设计 + 低代码修改，不用技术也能从 0 到 1 搭应用，设计转代码无缝衔接。</li><li>企业要做内部管理系统：冲 Zoho Creator，权限管理、流程自动化、数据集成都到位，能满足复杂业务需求。</li><li>要做营销网页、官网：优先 Framer，高颜值、易部署，SEO 优化到位，不用麻烦开发。</li><li>设计和开发团队协作频繁：选 Figma，设计转代码无缝衔接，多人协同不卡顿，还能统一设计风格。</li><li>重点验证交互体验（比如 APP 原型）：ProtoPie 是首选，交互效果逼真，能帮你提前发现体验问题。</li></ul>]]></description></item><item>    <title><![CDATA[TDengine IDMP Excel Add-in：把工业数据按 Excel 的方式用起来 TDe]]></title>    <link>https://segmentfault.com/a/1190000047607148</link>    <guid>https://segmentfault.com/a/1190000047607148</guid>    <pubDate>2026-02-12 12:07:21</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在很多工业场景中，Excel 仍然是被使用频率最高的数据分析工具之一。报表、核对、趋势分析、阶段性总结，很多工作最终都会在 Excel 里完成。真正影响效率的，往往不是 Excel 能不能算，而是数据能不能被稳定、重复地拿到。</p><p>当分析对象来自长期运行的设备和系统时，这个问题会被进一步放大。数据量持续增长、时间跨度不断拉长，如果每次分析都依赖导出、复制或人工整理，不仅过程繁琐，也很难保证结果的一致性。</p><p>TDengine IDMP Excel Add-in 正是围绕这一使用场景设计的。它并不改变 Excel 的使用方式，而是让 Excel 可以直接使用 IDMP 中已经组织好的数据结果，在熟悉的工作环境中完成查询、分析和整理。</p><h2>IDMP、Excel Add-in 各自解决什么问题</h2><p>TDengine IDMP 是一个面向工业物联网场景的数据管理平台，核心目标是简化工业数据的全生命周期管理。它通过经典的树状层次结构组织传感器、设备采集的数据，建立数据目录，对数据提供情景化、标准化的处理，并提供实时分析、可视化、事件管理与报警等功能。基于这些数据基础，IDMP 首创“无问智推”机制，无需用户提问，就能自动生成该应用场景所需要的实时分析与可视化面板。</p><p>在此基础上，<strong>Excel Add-in 面向业务人员，将这些已经被组织和治理过的数据带入 Excel</strong>。业务人员可以在熟悉的办公环境中，利用 Excel 本身的计算与可视化能力完成深度数据分析与报告生成，无需在不同系统之间切换，从而显著提升工作效率与数据洞察能力。</p><h2>Excel Add-in 的核心功能与使用方式</h2><p><strong>Excel Add-in 的核心价值，在于让数据能够在 Excel 中被高效、连续地使用。</strong>其与 Excel 深度集成，可直接连接 TDengine IDMP 服务器，用户无需切换工具，就可以在熟悉的办公环境中完成数据查询与分析，这也是其最基础的能力出发点。</p><p>在数据能力上，<strong>Excel Add-in 提供了完整的数据检索支持</strong>，既可以查询元素属性，也可以获取实时数据、历史归档数据以及趋势数据，覆盖了工业数据分析中最常见的取数场景。围绕这些数据，<strong>Excel Add-in 进一步提供了灵活的多维数据操作能力</strong>，通过丰富的查询命令支持复杂计算与过滤。</p><p>从整体结构来看，这些能力可以归为两大类：数据检索与数据操作。围绕这两类能力，Excel Add-in 形成了清晰的功能体系，既支持获取单个状态值，也支持对一段时间内的数据变化进行分析，或在服务端完成筛选与计算。</p><p>为了让这些能力更容易被使用，Excel Add-in 引入了功能任务窗格，并支持多入口触发和智能输入，符合 Excel 操作习惯。用户既可以通过按钮或右键菜单调用功能，也可以直接引用单元格内容完成参数配置，使数据查询过程更加直观、可控。</p><p>在具体能力上，Excel Add-in 提供了五大类核心命令，构成了完整的数据分析工具集：</p><ul><li>通过<strong>单值查询</strong>，可以快速获取设备或测点在某一时刻的状态；</li><li>通过<strong>多值查询</strong>，可以分析一段时间内的趋势变化；</li><li>通过<strong>计算过滤</strong>，可以直接在服务端完成复杂统计；</li><li>通过<strong>事件搜索</strong>，可以在大量数据中定位关键事件；</li><li>通过<strong>属性查看</strong>，可以查看属性和资产信息；</li><li>通过<strong>数据设置与更新</strong>，可以及时更新 IDMP 里的数据到当前的 Excel 中。</li></ul><p>这些命令并不是零散功能的堆叠，而是围绕实际分析需求进行的系统化设计，构成了强大数据分析能力的基石。</p><h2>技术架构与实现路径：从设计原理到快速上手</h2><p>在功能层面之外，Excel Add-in 背后还配套了一套清晰的技术架构与实现逻辑，用来支撑复杂数据场景下的性能和稳定性。从整体设计上看，其采用了分层架构，从用户界面到网络通信，每一层都有明确的职责划分。</p><ul><li>在<strong>用户侧</strong>，Excel Add-in 负责提供功能入口和任务窗格，完成参数输入、基本校验以及查询配置；</li><li>在<strong>接口层</strong>，通过统一的 API 与 IDMP 后端服务通信，屏蔽底层实现细节；</li><li>在<strong>数据处理层</strong>，对返回的数据进行单位换算和格式标准化；</li><li>在<strong>网络通信层</strong>，则通过 HTTPS 通道保障与 IDMP 服务之间的数据安全传输。</li></ul><p>在这样的架构下，数据从服务器到 Excel 的流转路径是清晰且可控的：用户在 Excel 中配置查询参数，请求被发送至 IDMP 服务，经过处理后的结果再被高效写入工作表。</p><p>在此基础上，<strong>Excel Add-in 采用了“解析与计算分离”的架构创新设计</strong>。用户在 Excel 中编写的公式和查询表达式，仅在本地完成解析、校验和表达式构建，真正的计算工作则由 TDengine 时序数据库承担。优化后的查询请求被下推至数据库，在数据源头直接执行聚合、筛选和复杂计算，从而避免海量原始数据在客户端与服务器之间反复传输。</p><p>这种设计既能够支撑百亿级历史数据的查询分析，又能够充分利用数据库侧的执行优化能力，同时对用户保持透明，Excel 的操作体验并不会因此变得复杂。</p><p>为了让这些能力能够更快落地使用，Excel Add-in 提供了相对清晰的实施路径。从环境准备、插件安装到 SDK 开发，每一步都有详细的指引。同时，我们也整理了官方文档、下载中心和技术支持等关键资源，并给出了数据模型设计、权限管理和自动化脚本等方面的最佳实践建议，希望能帮助大家更好地使用 Excel Add-in。</p><blockquote>Excel Add-in 官方技术文档：<a href="https://link.segmentfault.com/?enc=4URi8GONKifF9Fs3hWvRNQ%3D%3D.i9pFfV%2F%2Fw2yPaPgHG%2FjjRXioy2fGoaeI99SIdS%2BxFsH%2F8HA1mztxrwTpmrW04Go2UnmY6Ml2sDdP6a%2BZ9oJ3vw%3D%3D" rel="nofollow" target="_blank">https://idmpdocs.taosdata.com/basic/excel-add-in/</a></blockquote><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607150" alt="" title=""/></p><h2>结语</h2><p>从整体来看，TDengine IDMP Excel Add-in 的价值，在于让工业数据真正进入日常工作流程。通过将已经治理和计算的数据引入 Excel，业务人员可以在熟悉的工具中完成分析和判断，减少重复取数和人工整理，让数据更快转化为可用信息。</p><p>在此基础上，Excel Add-in 也为持续扩展留出了空间。无论是通过 SDK 支持更深度的系统集成，还是在后续迭代中探索与 AI 的结合，核心目标始终一致——让数据更容易被使用，并在实际业务中持续产生价值。</p>]]></description></item><item>    <title><![CDATA[项目启动会怎么开？领导讲话稿要准备吗？ 3Q聊工具 ]]></title>    <link>https://segmentfault.com/a/1190000047607159</link>    <guid>https://segmentfault.com/a/1190000047607159</guid>    <pubDate>2026-02-12 12:06:44</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>项目启动会是项目生命周期的“开篇序章”，更是凝聚团队共识、明确目标方向、压实责任分工的关键节点——它不仅是一场简单的“仪式”，更是统筹项目全局、规避开篇风险、调动全员积极性的核心抓手。很多项目负责人在筹备启动会时，常会陷入两个核心困惑：一是启动会流程繁杂，如何高效落地、避免流于形式？二是领导讲话稿看似“可有可无”，到底需要专门准备吗？结合多年项目管理实战经验，本文将从全流程拆解启动会实操要点，明确领导讲话稿的核心价值与筹备方法，助力项目实现“开好局、起好步”。</p><p><img width="723" height="732" referrerpolicy="no-referrer" src="/img/bVdnUXu" alt="" title=""/></p><h2>一、项目启动会：不是“走流程”，是项目成功的“前置保障”</h2><p>很多项目启动会陷入“走过场”的误区：流程简单、发言空洞、参会人员被动听会，会后依旧不清楚“做什么、怎么做、谁来做、做到什么时候”。事实上，一场高质量的项目启动会，核心目标是“统一思想、明确规则、凝聚合力”，既要让参会人员清晰掌握项目核心信息，也要激发全员参与热情，为后续项目推进扫清认知障碍。其核心价值体现在三点：一是定方向，明确项目目标与核心诉求，避免后续执行偏离轨道；二是压责任，明确各部门、各岗位分工，杜绝推诿扯皮；三是鼓士气，传递项目重要性与团队信心，提升全员执行力。</p><h3>（一）会前筹备：细节决定成败，做好3大核心准备</h3><p>会前筹备是启动会高效落地的基础，直接决定会议质量，需重点做好“目标、人员、物料”三大核心筹备，缺一不可，具体可分为以下4个关键环节：</p><ol><li>明确会议核心目标，杜绝“无的放矢”</li></ol><p>启动会的目标需具体、可落地，而非“简单告知项目启动”。核心目标应包含3点：一是正式宣告项目启动，明确项目核心价值（对公司、对团队、对客户的意义）；二是同步项目核心信息（目标、范围、 timeline、核心里程碑）；三是明确分工、压实责任，明确各参与方的核心职责与协作规则。建议会前组织项目核心团队召开小型碰头会，确认目标共识，避免会议内容偏离重点。</p><ol start="2"><li>精准筛选参会人员，兼顾“全面性与针对性”</li></ol><p>参会人员无需“全员参与”，需结合项目规模与分工筛选，核心分为4类，确保覆盖“决策层、执行层、协作层、监督层”：</p><ul><li>决策层：公司领导、项目 Sponsor（发起人），负责定调、授权、提供资源支持；</li><li>执行层：项目负责人（PM）、核心执行团队（产品、研发、设计、运营等），负责后续具体落地；</li><li>协作层：各支持部门负责人（行政、财务、人力等），负责提供跨部门协作支持；</li><li>监督层：质量管控、合规审计人员（如需），负责后续项目风险管控与合规监督。</li></ul><p>建议会前1-2天发送正式会议通知，明确会议时间、地点、流程、参会要求，同步项目核心背景资料（简要版），让参会人员提前了解项目概况，避免会议上“被动听会”。</p><ol start="3"><li>筹备会议物料与流程，确保“顺畅高效”</li></ol><p>物料筹备需提前1天完成，核心包括：项目PPT（核心内容：项目背景、目标、范围、里程碑、分工、风险预判）、会议议程表（分时段、明确发言人）、签到表、签字笔、投影仪/会议室设备（提前调试）、录音设备（便于会后复盘）。</p><p>流程设计需“紧凑有序”，时长控制在90-120分钟（避免过长导致疲劳），建议流程如下（可根据项目规模调整）：</p><ol><li>主持人开场（5分钟）：介绍会议目的、参会人员、会议流程，点明启动会核心意义；</li><li>项目负责人汇报（20-30分钟）：讲解项目背景、核心目标、范围边界、里程碑节点、分工安排、初期风险预判与应对思路；</li><li>协作部门表态（15-20分钟）：各支持部门负责人简要发言，明确协作支持方向；</li><li>领导讲话（10-15分钟）：定调项目重要性、明确资源支持、提出工作要求、鼓舞团队士气；</li><li>团队宣誓/承诺（可选，5分钟）：核心执行团队表态，强化责任意识；</li><li>主持人总结（5分钟）：回顾会议核心内容、明确后续行动节点、宣布启动会结束。</li><li>预判潜在问题，做好应急准备</li></ol><p>会前需预判可能出现的问题，提前做好应对：比如领导临时无法参会，需提前沟通是否安排代发言；设备故障，需准备备用设备或更换会议室；参会人员迟到，需提前预留10分钟缓冲时间，同步核心内容给迟到人员。</p><h3>（二）会中执行：把控节奏，突出“重点与互动”</h3><p>会中执行的核心是“控节奏、抓重点、强互动”，避免会议陷入“单向灌输”的尴尬，重点做好3点：</p><ol><li>严格把控会议节奏，杜绝“超时拖沓”</li></ol><p>主持人需全程把控时间，每个环节严格按照议程执行，若某一环节超时（如项目负责人汇报过长），需及时提醒“精简重点”，避免影响后续流程。同时，杜绝会议上“跑题”，若出现与会议核心无关的讨论，需及时拉回重点。</p><ol start="2"><li>突出核心重点，强化“认知共识”</li></ol><p>会议核心内容需反复强调，重点突出3点：一是项目核心目标（量化指标，如“3个月内完成产品上线，用户留存率达到80%”）；二是范围边界（明确“做什么、不做什么”，避免后续需求蔓延）；三是责任分工（明确各岗位、各部门的核心职责，避免“模糊地带”）。建议在项目PPT中用加粗、高亮突出重点，项目负责人汇报时，针对重点内容放慢语速、反复强调，确保全员理解。</p><ol start="3"><li>设计互动环节，调动“全员积极性”</li></ol><p>避免“单向发言”，可设计简短互动环节：比如在项目负责人汇报结束后，预留5-10分钟提问时间，解答参会人员的疑问（如协作部门的资源支持疑问、执行团队的落地难点）；或在领导讲话后，邀请1-2名核心执行人员简要发言，表达落地决心，增强团队凝聚力。互动环节需避免“形式化”，确保提问有价值、发言有针对性。</p><h3>（三）会后跟进：闭环管理，确保“落地见效”</h3><p>启动会不是“结束”，而是项目落地的“开始”，会后跟进不到位，会前筹备与会中执行的效果会大打折扣。核心做好3点闭环管理：</p><ol><li>及时同步会议纪要，明确“行动清单”</li></ol><p>会后24小时内，需整理会议纪要，明确核心内容：项目目标、分工安排、时间节点、领导要求、待解决问题及责任人。会议纪要需发送给所有参会人员，同时抄送相关领导，确保全员知晓、有据可查。</p><ol start="2"><li>拆解任务目标，压实“责任到人”</li></ol><p>项目负责人需根据会议纪要，将项目目标拆解为具体可落地的任务，明确每个任务的责任人、完成时间、验收标准，同步到各执行团队。建议建立任务跟踪表，定期跟进任务进度，及时解决落地过程中的难点。</p><ol start="3"><li>跟进待解决问题，确保“闭环清零”</li></ol><p>针对会议中提出的待解决问题（如资源缺口、协作难点、风险隐患），需明确责任人与解决时限，定期跟进解决进度，确保所有问题“闭环清零”，避免因问题遗留影响项目推进。</p><p><img width="723" height="732" referrerpolicy="no-referrer" src="/img/bVdnUXv" alt="" title="" loading="lazy"/></p><h2>二、领导讲话稿：不是“形式”，是启动会的“核心灵魂”</h2><p>很多项目负责人会有疑问：启动会已经明确了项目目标与分工，领导讲话稿还需要专门准备吗？答案是：​<strong>必须准备，而且要高质量准备</strong>​。领导讲话稿不是“套话堆砌”，而是启动会的“定调器、加油站、指南针”，其核心价值远超“发言本身”，具体可从3点体现：</p><h3>（一）领导讲话稿的3大核心价值，不可或缺</h3><ol><li>定调项目高度，明确重视程度</li></ol><p>领导作为公司决策层，其讲话直接决定项目的重视程度与资源支持力度。通过讲话稿，领导可明确项目的战略意义、核心定位，传递公司对项目的重视，同时向各部门释放“必须全力支持项目推进”的信号，为项目落地提供“权威背书”，避免后续跨部门协作中出现“推诿扯皮”。</p><ol start="2"><li>明确工作要求，划定执行底线</li></ol><p>领导讲话稿中，会明确项目推进的核心要求、纪律规范、风险底线，比如“确保项目按时高质量落地，严控成本与风险”“各部门需无条件配合项目团队，优先保障项目资源”，这些要求将成为后续项目推进的“准则”，帮助项目负责人更好地统筹全局、压实责任。</p><ol start="3"><li>鼓舞团队士气，凝聚奋进合力</li></ol><p>项目启动初期，团队成员可能存在“迷茫、犹豫、信心不足”等问题，领导的讲话可起到“鼓舞士气”的作用。通过肯定团队的能力、表达对项目成功的信心、传递公司的支持，可激发全员的积极性与责任感，让团队成员快速凝聚共识、投入工作，为项目推进注入“精神动力”。</p><h3>（二）高质量领导讲话稿，需把握4个筹备要点</h3><p>领导讲话稿无需“冗长复杂”，但需“精准有力、贴合实际”，筹备时需把握4个核心要点，避免“空泛套话”，确保贴合项目实际、贴合领导风格：</p><ol><li>贴合项目实际，杜绝“万能套话”</li></ol><p>讲话稿需紧密结合本次项目的背景、目标、痛点，避免使用“放之四海而皆准”的套话（如“加强协作、狠抓落实”）。需融入项目具体信息，比如“本次XX项目，是公司拓展XX领域的关键布局，关乎公司下半年核心目标的达成，希望大家聚焦‘3个月上线、留存80%’的核心目标，全力以赴”，让讲话更具针对性、更有说服力。</p><ol start="2"><li>兼顾“站位与落地”，平衡“高度与细节”</li></ol><p>领导讲话需有“高度”，明确项目的战略意义与公司层面的支持；同时需有“落地性”，明确具体工作要求与协作规则，避免“只谈高度、不谈落地”。比如，既要有“本次项目将成为公司标杆项目，各部门需高度重视”的站位，也要有“财务部门需优先保障项目资金，行政部门需做好后勤支持”的具体要求。</p><ol start="3"><li>控制时长，突出“重点核心”</li></ol><p>领导讲话稿时长建议控制在10-15分钟，避免过长导致参会人员疲劳。内容需突出3个核心：一是项目的战略意义与重视程度；二是对各部门、各团队的工作要求；三是对团队的鼓励与期望，无需展开过多细节（细节可由项目负责人补充）。</p><ol start="4"><li>贴合领导风格，提前沟通确认</li></ol><p>不同领导的讲话风格不同，有的简洁有力、有的务实细致、有的侧重鼓舞士气。筹备讲话稿时，需结合领导的日常讲话风格，避免“风格脱节”。同时，需提前将讲话稿发给领导审核，根据领导的意见修改完善，确保讲话内容符合领导的意图，避免会议上出现“临场修改”的尴尬。</p><h3>（三）讲话稿避坑提醒：3个常见错误，坚决杜绝</h3><ol><li>避免“空泛无物”：不堆砌套话、不脱离项目实际，所有表述都需围绕项目核心；</li><li>避免“越位替代”：领导讲话侧重“定调、要求、鼓励”，无需替代项目负责人讲解具体的任务拆解、流程细节；</li><li>避免“冗长拖沓”：控制时长，突出重点，避免重复表述，确保每一句话都有“价值”。</li></ol><p><img width="723" height="488" referrerpolicy="no-referrer" src="/img/bVdnUXy" alt="" title="" loading="lazy"/></p><h2>三、总结：高质量启动会+优质讲话稿，助力项目“开好局、赢先机”</h2><p>项目启动会的核心的是“闭环管理”，从会前筹备的细节把控，到会中的节奏掌控、重点传递，再到会后的任务跟进、问题清零，每一个环节都不可或缺，唯有做到“流程规范、重点突出、落地闭环”，才能避免启动会流于形式，真正发挥“统一思想、凝聚合力”的作用。</p><p>而领导讲话稿，不是启动会的“附加项”，而是“核心项”——它既是公司重视程度的体现，也是项目推进的“指南针”，更是团队士气的“加油站”。高质量的讲话稿，能让启动会的效果翻倍，为后续项目推进奠定坚实的基础。</p><p>总之，一场成功的项目启动会，离不开“全流程的细致筹备”与“高质量的领导讲话稿”，两者相辅相成、缺一不可。唯有兼顾两者，才能让项目在开篇就找准方向、凝聚合力，为后续高质量落地、达成核心目标，赢得“先机”。</p>]]></description></item><item>    <title><![CDATA[游戏中心弱网优化实践 vivo互联网技术 ]]></title>    <link>https://segmentfault.com/a/1190000047607163</link>    <guid>https://segmentfault.com/a/1190000047607163</guid>    <pubDate>2026-02-12 12:06:13</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <blockquote>作者：vivo 互联网客户端团队- Ke Jie  <br/>本实践围绕游戏中心在弱网环境下的性能优化展开，针对复杂网络场景下的页面加载慢、资源加载失败等问题，提出了优化方案：接入支持 QUIC 协议的 Cronet 网络库，通过更快的连接建立与传输特性提升请求响应速度。配合弱网状态精细化判定与限速测试，线上灰度实验显示页面加载失败率下降 40%，请求耗时降低 7%，图片加载速度在正常至极差网络环境均有显著提升。</blockquote><p>1分钟看图掌握核心观点👇</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607165" alt="" title=""/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607166" alt="动图封面" title="动图封面" loading="lazy"/></p><p><em>图 1 VS 图 2，您更倾向于哪张图来辅助理解全文呢？欢迎在评论区留言。</em></p><h2>一、弱网优化背景</h2><p>游戏中心 APP 的核心功能依赖网络连接，如游戏下载、更新、启动、礼包领取及活动参与等。而在电梯、地下车库等弱网环境中，用户常遇到进入页面慢、图片资源加载不出来等问题，严重影响体验，导致活跃下降和用户流失。</p><p>随着移动游戏用户规模扩大，确保在复杂网络条件下的稳定访问和核心功能可用性，成为提升留存和转化的关键。通过优化传输协议、传输数据优化等，可显著改善弱网下的使用体验，保障用户使用流畅性，提升整体用户满意度。</p><h2>二、如何去定义网络状态</h2><p>在移动应用中，网络状态的定义通常是指当前设备所处的网络连接类型与质量。它不仅仅是“有网”或“没网”，还包括网络速度、延迟、丢包率等关键指标，特别在进行弱网优化时，需要更精细地感知和分类网络状态。如果要对优化效果进行衡量，首页要定义各种情形下归属哪种网络状态。</p><p>由于网络状态并没有一个统一的定义，游戏中心基于以下维度构建立了App内部的弱网判定标准。</p><p><strong>弱网与疑似弱网对比</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607167" alt="" title="" loading="lazy"/></p><p>大概的现象可以总结为：</p><ul><li><strong>弱网环境：</strong>网络质量严重下降，已对用户体验造成明显影响。</li><li><strong>疑似弱网环境：</strong>网络出现不稳定或退化迹象，但尚未达到严重弱网程度。</li></ul><p>游戏中心通过判断网络状态、WIFI信号、手机信号强弱、Ping百度/Vivo域名、最近接口请求失败率、上下行带宽、最近请求平均耗时等维度，赋予不同的网络状态值，将网络状态值作为作为埋点的公参上报，作为优化前后提取数据的维度。</p><h2>三、游戏中心接入QUIC协议</h2><h2>3.1 QUIC协议简介</h2><p>QUIC 是 Google 在 2013 年推出的一种新型网络协议，全称是“快速 UDP 网络连接”（Quick UDP Internet Connections）。它和我们常用的 TCP 协议不一样，是基于 UDP 打造的。QUIC 的目标是让网站和应用加载得更快，同时也更加安全。</p><p>它能一次建立多个数据连接，而且建立连接的速度比传统方式更快，这意味着打开网页、看视频或传输数据时，等待的时间会更短。此外，QUIC 还具备自动控制网络带宽的功能，可以根据网络情况进行调节，避免网络堵塞。</p><p>Google 希望用 QUIC 来替代现有的 TCP 协议，并推动它成为互联网新的标准协议。</p><h2>3.2 QUIC协议应用场景</h2><p><strong>轻量资源传输优化：</strong>对于图片、图标等体积较小的文件，能够快速完成传输，缩短加载时间，提升整体响应效率。</p><p><strong>视频播放体验增强：</strong>在进行视频点播时，可以实现更快的内容呈现，提升首帧加载速度，减少播放中断，提高观影流畅度。</p><p><strong>高频交互请求加速：</strong>针对如登录验证、支付流程等频繁交互的请求场景，可有效提升数据响应速度，改善用户的操作体验。</p><p><strong>复杂网络下保持稳定：</strong>在网络条件较差，如高延迟或频繁丢包的情况下，依然能维持稳定的数据传输，减少失败和卡顿，保障服务可用性。</p><p><strong>应对大规模并发访问：</strong>在面对大量用户同时访问、多资源并行加载等高并发情境时，具备更强的连接能力，提升整体访问速度与稳定性。</p><p><strong>实现方式</strong></p><p>Cronet和Okhttp一样都是网络库，Cronet 原生支持 QUIC，而 OkHttp 默认不支持 QUIC。</p><p>由于原来业务中对Okhttp网络库是有一定改造的，所以这里在Okhttp网络库中去接入Cronet库，做好兼容。</p><p>网络库实现的思路是自定义 Cronet 拦截器，一个完整的 Cronet 拦截器主要包含三个步骤：</p><ul><li>OkHttp Request 转换为 Cronet Request</li><li>发起 Cronet 请求并处理生命周期</li><li>Cronet Response 转 OkHttp Response</li></ul><p>将自定义的 Cronet 拦截器添加到 OkHttp 拦截链的末尾，保证其他拦截器（如缓存、日志、认证）正常工作后，才使用 Cronet 处理请求。</p><p>OkHttpClient辅助类中兼容Cronet：</p><pre><code class="text">// 1. 创建缓存路径
val cachePath = File(AppContext.getContext().cacheDir, CRONET_CACHE_PATH)
if (!cachePath.isDirectory) {
    cachePath.mkdirs()
    VLog.d(TAG, "no cronet cache dir, mkdirs")
}

// 2. 构建 CronetEngine
var builder = CronetEngine.Builder(AppContext.getContext())
try {
    builder = builder
        .setStoragePath(cachePath.absolutePath)   // 设置缓存路径
        .enableBrotli(false)                      // 是否开启 Br 压缩，暂不开启
        .enableQuic(true)                         // 开启 QUIC
        .enableHttp2(true)                        // 开启 HTTP/2
        .enableHttpCache(
            CronetEngine.Builder.HTTP_CACHE_DISK_NO_HTTP,
            SIZE_1_MB.toLong()
        ) // 1MB 磁盘缓存，需先设置 setStoragePath()
    
    // 配置 QUIC Hint
    NetworkManager.getInstance().quicHintHosts?.forEach {
        builder = builder.addQuicHint(it, 443, 443)
    }

    // 构建 CronetEngine
    cronetEngine = builder.build()
} catch (e: Throwable) {
    VLog.e(
        TAG,
        "init cronet engine fail",
        e
    ) // 初始化 CronetEngine 失败，则返回 null，不走 QUIC 请求
    cronetEngine = null
}

// 3. 构建 OkHttpClient 并集成 Cronet
val netClientBuilder = defOkhttpClient.newBuilder()
    .connectTimeout(DEFAULT_TIMEOUT, TimeUnit.MILLISECONDS)
    .writeTimeout(DEFAULT_TIMEOUT, TimeUnit.MILLISECONDS)
    .addInterceptor(CronetInterceptor.Builder(cronetEngine).build())
</code></pre><p>CronetInterceptor拦截器，对需要使用QUIC协议的域名进行QUIC请求，相关域名可以做成配置项，具备线上随时切换的能力。</p><p>CronetInterceptor拦截器作用主要职责是：OKHttp 的Request 转换成Cronet Request，并能接收响应。</p><pre><code class="text">public final class CronetInterceptor implementsInterceptor {
    private static final String TAG = "CronetInterceptor";

    private final RequestResponseConverter mConverter;

    private CronetInterceptor(RequestResponseConverter converter){
        this.mConverter = checkNotNull(converter);
    }

    @Override
    public Response intercept(Chain chain) throws IOException {
        if (chain.call().isCanceled()) {
            thrownew IOException("Request call canceled");
        }
        Request request = chain.request();
        if (OkHttpClientHelper.INSTANCE.isNeedUseCronet(request.url())) {
            VLog.d(TAG, "use Cronet request:" + request.url());
            return proceedWithCronet(chain); // 使用 Cronet 发起 Quic 请求
        } else {
            VLog.d(TAG, "don't use Cronet request:" + request.url());
            return proceedDefault(chain); // 不使用 Cronet 请求
        }
    }

    private Response proceedWithCronet(Chain chain) throws IOException {
        RequestResponseConverter.CronetRequestAndOkHttpResponse requestAndOkHttpResponse =
                mConverter.convert(chain.request(), chain.readTimeoutMillis(), chain.writeTimeoutMillis());
        try {
            requestAndOkHttpResponse.getRequest().start();
            return toInterceptorResponse(requestAndOkHttpResponse.getResponse(), chain.call());
        } catch (Throwable e) {
            VLog.e(TAG, "proceedWithCronet exception:", e);
            throw e;
        }
    }

    private Response proceedDefault(Chain chain) throws IOException {
        try {
            Request request = chain.request();
            VLog.d(TAG, "intercept " + request.method() + ", " + request.tag());
            request = RequestHelper.handleRequest(request);

            Response response = chain.proceed(request);
            int retryNum = 0;
            while ((response == null || !response.isSuccessful()) &amp;&amp; retryNum &lt; DEFAULT_RETRY_COUNT) {
                retryNum++;
                if (response != null &amp;&amp; response.body() != null) {
                    response.body().close();
                }
                response = chain.proceed(request);
            }
            return response;
        } catch (Throwable e) {
            if (e instanceof IOException) {
                throw e;
            } else {
                thrownew IOException(e);
            }
        }
    }

    private Response toInterceptorResponse(Response response, Call call){
        checkNotNull(response.body());
        return response
                .newBuilder()
                .body(new CronetInterceptorResponseBody(response.body(), call))
                .build();
    }
}
</code></pre><p>接收到响应后，需要将Croent Response 转成 OKHttp Response，核心的实现：</p><pre><code class="text">Response toResponse(Request request, OkHttpBridgeRequestCallback callback) throws IOException {
    Response.Builder responseBuilder = new Response.Builder();

    UrlResponseInfo urlResponseInfo = getFutureValue(callback.getUrlResponseInfo());

    @Nullable String contentType = getLastHeaderValue(CONTENT_TYPE_HEADER_NAME, urlResponseInfo);

    @Nullable String contentLengthString = null;

    List&lt;String&gt; contentEncodingItems = new ArrayList&lt;&gt;();

    for (String contentEncodingHeaderValue : getOrDefault(
            urlResponseInfo.getAllHeaders(),
            CONTENT_ENCODING_HEADER_NAME,
            Collections.emptyList())) {
        Iterables.addAll(contentEncodingItems, COMMA_SPLITTER.split(contentEncodingHeaderValue));
    }

    boolean keepEncodingAffectedHeaders =
            contentEncodingItems.isEmpty() || !ENCODINGS_HANDLED_BY_CRONET.containsAll(contentEncodingItems);

    if (keepEncodingAffectedHeaders) {
        contentLengthString = getLastHeaderValue(CONTENT_LENGTH_HEADER_NAME, urlResponseInfo);
    }

    ResponseBody responseBody =
            createResponseBody(
                    request,
                    urlResponseInfo.getHttpStatusCode(),
                    contentType,
                    contentLengthString,
                    getFutureValue(callback.getBodySource()));

    responseBuilder
            .request(request)
            .code(urlResponseInfo.getHttpStatusCode())
            .message(urlResponseInfo.getHttpStatusText())
            .protocol(convertProtocol(urlResponseInfo.getNegotiatedProtocol()))
            .body(responseBody);

    for (Map.Entry&lt;String, String&gt; header : urlResponseInfo.getAllHeadersAsList()) {
        boolean copyHeader = true;
        if (!keepEncodingAffectedHeaders) {
            if (Ascii.equalsIgnoreCase(header.getKey(), CONTENT_LENGTH_HEADER_NAME)
                    || Ascii.equalsIgnoreCase(header.getKey(), CONTENT_ENCODING_HEADER_NAME)) {
                copyHeader = false;
            }
        }
        if (copyHeader) {
            responseBuilder.addHeader(header.getKey(), header.getValue());
        }
    }

    return responseBuilder.build();
}
</code></pre><p>这样整体在OkHttp网络库中，能够兼容使用Cronet网络库，整体的流程就通了。</p><p><strong>测试方式及配置</strong></p><p><strong>① 域名支持</strong></p><p>需要将支持的域名配置成支持QUIC，这里注意需要和运营商确认是否支持GQUIC/IQUIC。</p><p><strong>② 限制网速参数</strong></p><p>各个网络状态的参数可以参考这样设置：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607168" alt="" title="" loading="lazy"/></p><p>参数参考：[稀土掘金 · Fiddler 抓包(下载安装及使用)]</p><p><strong>③ 测试工具</strong></p><p>由于QUIC抓包比较复杂，这里自定义了脚本，通过限制延迟时间、带宽、丢包率来限制网速，参数可以参考上一小节。</p><pre><code class="text">#!/bin/bash

# 延迟时间，以毫秒为单位进行指定。
# 带宽，以千比特或兆比特为单位进行指定。
# 丢包率，以百分比进行指定。
# 比如设置 300 毫秒的延迟时间、100 千比特的带宽和 50% 的丢包率，请运行以下命令：
# bash NetworkSimulation.sh 300ms 100kbit 50%

# 如需设置 100 毫秒的延迟时间、1 兆比特的带宽和 0% 的丢包率，请运行以下命令：
# bash NetworkSimulation.sh 100ms 1mbit 0%

# root device and set it to permissive mode
adb root
adb shell setenforce 0

# Clear the current tc control
adb shell tc qdisc del dev ifb0 root
adb shell ip link set dev ifb0 down
adb shell tc qdisc del dev wlan0 ingress
adb shell tc qdisc del dev wlan0 root

if [ $# -eq 1 ]; then
    echo "setup cleared"
elif [ $# -eq 3 ]; then
    latency=$1
    bandwidth=$2
    packetloss=$3
    # Create a virtual device for ingress
    adb shell ip link set dev wlan0 up
    adb shell ip link set dev ifb0 up
    adb shell tc qdisc del dev wlan0 clsact
    adb shell tc qdisc add dev wlan0 handle ffff: ingress
    adb shell tc filter add dev wlan0 parent ffff: protocol all u32 match u32 00 action mirred egress redirect dev ifb0

    # Throttle upload bandwidth / latency / packet loss
    adb shell tc qdisc add dev wlan0 root handle 1: htb default11
    adb shell tc class add dev wlan0 parent 1: classid 1:1 htb rate "$bandwidth"
    adb shell tc class add dev wlan0 parent 1:1 classid 1:11 htb rate "$bandwidth"
    adb shell tc qdisc add dev wlan0 parent 1:11 handle 10: netem delay "$latency" loss "$packetloss"

    # Throttle download bandwidth
    adb shell tc qdisc add dev ifb0 root handle 1: htb default10
    adb shell tc class add dev ifb0 parent 1: classid 1:1 htb rate "$bandwidth"
    adb shell tc class add dev ifb0 parent 1:1 classid 1:10 htb rate "$bandwidth"
else
    echo "Invalid parameters"
fi
</code></pre><p>通过命令行执行类似于bash NetworkSimulation.sh 100ms 1mbit 0%命令，即可以限制手机的网络状态。</p><h2>四、优化效果</h2><p>在本次面向核心接口与图片域名的线上 A/B 灰度实验中，经过一段时间的观测与数据对比，灰度策略取得了显著优化效果，主要体现在以下几个方面：</p><ul><li><strong>页面加载失败率显著下降：</strong>整体失败率下降 40%，显著提升页面可用性；</li><li><strong>页面请求响应性能优化：</strong>平均页面请求耗时下降 7%，加载更流畅；</li><li><strong>正常网络环境图片加载速度提升：</strong>加载速度提升 38%，提升用户体验；</li><li><strong>弱网络环境图片加载速度提升：</strong>加载速度提升 30%，弱网下表现更优；</li><li><strong>极差网络环境图片加载速度提升：</strong>加载速度提升达58%，保障极端场景下的可用性与体验。</li></ul>]]></description></item><item>    <title><![CDATA[UI设计工具推荐合集 UXbot ]]></title>    <link>https://segmentfault.com/a/1190000047607176</link>    <guid>https://segmentfault.com/a/1190000047607176</guid>    <pubDate>2026-02-12 12:05:15</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>当下国内企业对用户交互体验的重视程度持续攀升，UI设计领域的发展空间也随之不断拓宽。但对设计师来说，选对一款UI工具太关键了，直接能让工作效率翻番。如果你正在物色一款适配自己的UI设计工具，这篇内容或许能给你带来参考。</p><p>1.UXbot<br/>UXbot是一款AI驱动的综合性产品设计平台，实现从需求到可视化页面规划、高保真交互界面生成与项目级Web前端代码同步输出，适配Web、App、桌面端等多终端设计需求，无需专业设计或开发基础也能快速上手。<br/><img width="723" height="414" referrerpolicy="no-referrer" src="/img/bVdnUXC" alt="image.png" title="image.png"/><br/>优点：</p><ul><li>多页面项目生成：仅需提供文字描述，UXbot就能自动搭建起覆盖全流程的用户旅程图谱， 实时展现思考过程， 用户可以自主选择生成页面， 并一次性生成完整的、 可交互且逻辑连贯的产品原型设计；</li><li>可生成整套逻辑连贯的可交互原型+UI设计，满足专业团队设计要求，兼顾AI自动生成与手动精细化编辑，自定义调整页面布局、元素等，UI设计自由度高；</li><li>高阶交互与AI赋能：支持复杂交互逻辑搭建、动态效果实现及页面跳转，可还原真实产品操作体验；</li><li>标准化资源体系：内置覆盖电商、企业官网、活动营销等多场景的标准化组件库与网页模板，助力团队快速完成界面搭建，同时保障设计语言的统一性；</li><li>Web 前端代码生成：网站界面设计定稿即触发项目级前端代码的同步生成， 深度兼容vue.js  主流框架生态， 构建起高保真视觉设计与可执行代码的零摩擦转化链路； 依托 “模拟运行 ” 能力实现代码至云服务器的一键部署， 打破设计与开发的传统壁垒。<br/>费用：提供免费预览版，基础功能可免费体验；个人版每月59元起，支持无限项目创建及每月约300个页面生成；专业版每月899元起，解锁无限页面生成与无限次文件导出功能，支持按周、季订阅。<br/><img width="723" height="414" referrerpolicy="no-referrer" src="/img/bVdnUXK" alt="image.png" title="image.png" loading="lazy"/></li></ul><ol start="2"><li>InVision<br/>InVision Studio是一款全能型UI设计工具，把视觉设计、快速原型制作、动效设计、团队协作功能整合在了一起。它配备了直观的矢量绘图工具、无限画布，还有不少亮眼的快速原型功能和内置动画效果。<br/>优点：矢量绘图工具适合快速完成屏幕设计；自带共享组件库，支持全局同步和实时更新，能有效保障设计一致性。<br/>缺点：设计系统与工具本体相互独立，无法直接调取组件资源修改调整，既制约设计师的创意发挥，也会降低设计效率。<br/>费用：可免费下载使用，最多创建1个原型。如需增加原型数量，需升级套餐——每月13美元的基础计划可创建3个原型，每月22美元的专业计划则无原型数量限制。<br/><img width="723" height="349" referrerpolicy="no-referrer" src="/img/bVdnUXL" alt="image.png" title="image.png" loading="lazy"/></li></ol><p>3.Whimsical<br/>Whimsical是一款在线流程类UI设计工具，主要用于UI设计中的产品规格制定、创意构思和用户流程绘制。操作命令简单，界面简洁干净，无需安装客户端，只用浏览器就能随时随地开展绘制工作，对新手十分友好。<br/>优点：支持多人在线协同，默认样式美观度高；内置可自定义样式的图标字体，能保证流程图的视觉质感。<br/>缺点：缺乏手绘功能；大型团队使用时，整体成本偏高。<br/>费用：提供免费计划，免费账户可新建4个画布；付费计划每月起价20美元。<br/><img width="723" height="381" referrerpolicy="no-referrer" src="/img/bVdnUXN" alt="image.png" title="image.png" loading="lazy"/></p><ol start="4"><li>Balsamiq<br/>Balsamiq是一款高效的低保真线框图工具，不管是想学习UI搭建知识，还是想优化用户体验，都能用到它。它能帮你跳过细节纠结的环节，快速产出多个版本的界面草稿，同时提供数百种可用资源。<br/>优点：支持无限制创建线框、添加用户；具备拖放操作功能，可导出为交互式原型。<br/>缺点：与谷歌云盘、Jira、Confluence等协作工具的集成服务需额外付费。<br/>费用：可免费试用30天，试用期结束后每月起价9美元。<br/><img width="723" height="414" referrerpolicy="no-referrer" src="/img/bVdnUXO" alt="image.png" title="image.png" loading="lazy"/></li><li>Justinmind<br/>Justinmind是一款融合UI与UX设计的原型开发工具，专门适配网页和移动应用，其中线框图功能最为突出。它自带现成线框库，可在线框上测试移动手势，通过拖拽元素、快速验证想法的流畅流程，提升原型设计效率。<br/>优点：线框创建和用户添加无限制；支持拖放操作，可导出为交互式原型。<br/>缺点：存储空间有限；团队使用的套餐费用较高。<br/>费用：提供15天全功能免费试用，付费计划每月起价19美元。<br/><img width="723" height="432" referrerpolicy="no-referrer" src="/img/bVdnUXP" alt="image.png" title="image.png" loading="lazy"/></li></ol><p>在选择合适的设计UI工具时，首先要做的就是要明确你的设计需求。如果你也跟我一样，出于提高工作效率、加强团队协作、形成设计规范统一、设计&amp;开发一体的考量，建议你可以试试设计UI工具UXbot。</p>]]></description></item><item>    <title><![CDATA[2026年UI设计师必备8款AI工具，高效出图不内卷 UXbot ]]></title>    <link>https://segmentfault.com/a/1190000047607190</link>    <guid>https://segmentfault.com/a/1190000047607190</guid>    <pubDate>2026-02-12 12:04:37</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>UI设计行业越发展，设计师对工具的要求也跟着水涨船高——不光要能快速搭原型，还得兼顾多设备适配和团队协作。选对一款趁手的工具，能少走不少弯路。下面就给大家盘点2026年值得关注的8款UI设计工具，不管是刚入行的新手，还是深耕多年的老设计师，都能找到适配自己工作的帮手，帮你省时间、提效率，让创意落地更顺畅。<br/>1.UXbot<br/>作为专为UI设计师打造的智能助手，UXbot把原型设计、交互设计和UI布局这些核心工作都整合在了一起，主打一个高效省心。它的自动化能力很亮眼，还能根据设计师的文字需求，智能生成页面布局和设计元素，帮设计师省下不少重复劳动的时间，把精力放在更核心的创意上。<br/>最实用的是它的秒出高保真原型功能，只要输入文字指令，30秒就能搭建好完整界面。支持直接利用AI助手或者编辑器，修改UI设计中页面、布局、元素等，自由度超高，既不限制创意发挥，又能大幅压缩设计周期。<br/>它还覆盖了设计全链路，高保真原型、UI设计、代码交付、团队协作全都能在一个平台搞定。设计师不用在多个工具间来回切换，和团队成员的迭代反馈、多人协作也更顺畅，有效减少沟通成本，让设计方案能快速落地。<br/>另外，UXbot实现了设计与开发的无缝衔接，设计师做完原型就能直接生成Web前端（Vue）、iOS（Swift）、Android（Kotlin），开发团队能直接复用代码，不用反复沟通调整，让设计和开发各司其职、高效配合。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdnCJg" alt="image.png" title="image.png"/></p><ol start="2"><li>Affinity Designer<br/>这是一款功能扎实的图形设计工具，在UI设计、插画创作、排版设计等场景都很常用。它同时支持矢量图形和位图编辑，设计师不用切换软件，就能在一个平台上完成多类型创作。和传统设计软件比起来，它的界面更简洁好懂，上手难度低，而且性能稳定、输出分辨率高，面对对精度要求高的UI项目时，表现特别出色。不管是画精致图标、设计界面元素，还是做复杂UI布局，都是靠谱的帮手。<br/><img width="723" height="406" referrerpolicy="no-referrer" src="/img/bVdnUXT" alt="image.png" title="image.png" loading="lazy"/></li><li>Gravit Designer<br/>这是一款轻量级矢量设计工具，兼容性很强，Windows、Mac、Linux系统都能使用。它的矢量绘图能力足够扎实，不管是做UI设计、图标设计，还是网页设计，都能满足基础需求。最大的优点就是轻便好操作，加上跨平台特性，设计师不管在办公室电脑、家用平板还是笔记本上，都能随时开工，灵活性拉满。<br/>另外，它的文本工具和样式设置功能很实用，能轻松做好排版和界面布局，让设计作品更精致。对于需要灵活切换设备、追求高效轻量化设计的项目来说，这款工具特别合适。点击注册，即可快速体验。<br/><img width="723" height="408" referrerpolicy="no-referrer" src="/img/bVdnUXV" alt="image.png" title="image.png" loading="lazy"/></li><li>Webflow<br/>这款工具把UI设计和网页开发整合到了一起，最大的亮点就是设计师不用懂代码，也能做出高度自定义的网页和应用。在Webflow上设计好界面后，系统会自动生成干净的HTML、CSS和JavaScript代码，还支持响应式设计，确保网页在不同设备上都能正常显示。<br/>它很好地打通了设计和开发的壁垒，设计师能直观呈现自己的想法，开发团队也能直接复用代码，减少沟通成本，特别适合设计和开发团队配合工作。<br/><img width="723" height="413" referrerpolicy="no-referrer" src="/img/bVdnUXW" alt="image.png" title="image.png" loading="lazy"/></li><li>Marvel App<br/>这款工具主打快速原型设计和交互模拟，能让设计师在短时间内做出高保真原型，还能直接模拟交互效果，方便测试设计合理性。它支持多人实时协作，设计师可以一键共享设计文件，和团队成员同步获取反馈，及时调整方案。<br/>除此之外，它还有原型测试功能，设计师能把原型直接发布到网页上，邀请用户参与测试，收集真实使用反馈。跨平台特性也让设计师不管在什么设备上，都能管理项目、迭代设计，适合快节奏的设计工作。<br/><img width="723" height="409" referrerpolicy="no-referrer" src="/img/bVdnUXX" alt="image.png" title="image.png" loading="lazy"/></li><li>InVision<br/>InVision是为设计团队量身打造的协作工具，不光能做原型和交互设计，还涵盖了项目管理、设计反馈、用户测试等全流程服务。它的核心竞争力就是强大的协作体系，团队成员在同一个平台上沟通，所有设计文件实时更新，彻底解决了传统设计工作中版本混乱、来回同步的问题。不管是小团队协作，还是大型项目统筹，都能让设计流程更有序。点击注册，立即解锁高效协作体验。<br/><img width="723" height="395" referrerpolicy="no-referrer" src="/img/bVdnUXZ" alt="image.png" title="image.png" loading="lazy"/></li><li>Principle<br/>Principle专注于交互动效设计，是做动效的必备工具。不管是复杂的页面过渡动画，还是按钮点击、菜单展开等交互反馈，用它都能轻松实现。它的时间轴控制很精准，设计师能细致调整每一个动画的节奏、幅度，让动效更贴合用户体验需求。<br/>操作上也很直观，支持直接导入UI设计文件，在此基础上添加动效，不用重新搭建界面，大大节省时间。不管是做APP还是网页动效，都能满足专业需求。点击注册，即可体验高效动效设计。<br/><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdnUX2" alt="image.png" title="image.png" loading="lazy"/></li><li>UXPin<br/>UXPin是一款全功能UI/UX设计工具，从线框图绘制、高保真原型制作，到团队协作、用户测试，能覆盖设计全流程。它的交互设计和逻辑构建能力很突出，设计师通过简单的拖放操作，就能做出复杂的用户交互流程，不用额外编写脚本。<br/>同时支持实时团队协作和版本控制，确保所有成员都能获取最新设计文件，避免版本冲突。不管是独立完成设计项目，还是带领团队推进复杂方案，都能靠它提升效率。<br/><img width="723" height="379" referrerpolicy="no-referrer" src="/img/bVdnUX3" alt="image.png" title="image.png" loading="lazy"/></li></ol><p>以上这8款工具，在原型设计、界面美化、交互动效、多端适配和团队协作等方面各有优势，能覆盖不同设计场景和需求。如果想兼顾快速出原型、多端适配和全链路协作，UXbot会是优先之选——它适配中文使用环境，能打通设计、代码交付和团队协作的全流程，帮你大幅提升工作效率。</p>]]></description></item><item>    <title><![CDATA[工业数据管理这条线，从“是什么”到“怎么选”，TDengine从五个方向彻底理清了 TDengine]]></title>    <link>https://segmentfault.com/a/1190000047607198</link>    <guid>https://segmentfault.com/a/1190000047607198</guid>    <pubDate>2026-02-12 12:04:04</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在工业数字化不断深入的过程中，越来越多企业开始接触到“工业数据管理平台”这一概念，也开始评估包括 <strong>TDengine IDMP</strong> 在内的新一代平台方案。当数据规模增长到一定阶段，问题不再是“有没有数据”，而是：数据能不能被找得到？能不能被理解？能不能被反复使用，而不是一次性分析？能不能支撑更复杂的分析，甚至 AI 参与决策？这正是“工业数据管理平台”开始被反复讨论的背景。</p><p>但在实际交流中我们发现，很多讨论往往直接跳到产品和功能层面，却绕开了几个更基础的问题：</p><ul><li>什么样的平台才算是工业数据管理平台？</li><li>它和通用数据治理、通用 BI 的差异在哪里？</li><li>企业真正需要解决的，又到底是什么问题？</li></ul><p>正是基于这些困惑，我们围绕“工业数据管理平台”这一主题，连续梳理并发布了几篇文章。它们并不是零散的内容输出，而是试图从概念、方法到选型逻辑，把一条完整的思考路径逐步铺展开来，也为理解 TDengine IDMP 这类平台为何出现、解决什么问题提供背景和参照。</p><h2>第一篇：先把概念说清楚——什么是工业数据管理平台？</h2><p>我们从最基础的问题入手：什么是工业数据管理平台？企业为什么需要它？这篇文章关注的不是某一个产品，而是一个更底层的判断：在多系统并行、数据持续增长的工业环境中，企业真正缺失的，往往并不是“再多一个工具”，而是一套能让数据长期可用、可复用、可扩展的基础能力。</p><blockquote>👉  进入 <a href="https://link.segmentfault.com/?enc=%2FdvR%2FactltANWaLqr45fAA%3D%3D.J3QVnXFKOHOukv%2BDneOahcUdtJj2O0WxCxI1kVKel8EEpToX5tsl%2B71EqO%2FZ4uKf5U58mwUZzjJhEtVxrhnn1mesPOW6O7TJBU2L2QYlb2OKOmkr4aZISV3QthPXAu3iXnvbPpBpuFGSw6KLB7jyyJ1cjGIfKrydcjD8xOi0m%2B8%3D" rel="nofollow" target="_blank">https://www.taosdata.com/idmp%e5%b7%a5%e4%b8%9a%e6%95%b0%e6%8...</a> 阅读本篇文章，了解相关内容。</blockquote><h2>第二篇：为什么工业数据治理不能照搬通用数据治理？</h2><p>接下来，我们把视角收紧到“治理”本身。在《为什么工业数据治理不同于通用数据治理？》这篇中，我们对比了业务数据和工业数据在数据形态、时间敏感性、变化频率以及错误后果上的根本差异。结论并不复杂：工业数据治理并不是通用数据治理的一个子集，而是一套围绕运行正确性、过程可信度和实时决策建立的独立逻辑。</p><blockquote>👉  进入 <a href="https://link.segmentfault.com/?enc=WlJuPMHep4bCPy%2FTWTVD9Q%3D%3D.mBfuAdFfRj0GfBg%2FXH4TIeUgIk3SHopC0VBo%2BEWTg5Or4%2Fhk0hGIe9pYpFZ6uw1kNfjTw3GXJI8f3toWgxvbf2%2BpNth1b4XXlb8dGaLYegKhrvW0dPqiSkmXV71yCQyy9OG7xrdguSoCJb%2FC510YADbT9dabeXY8Tp6OSQx2NuE%3D" rel="nofollow" target="_blank">https://www.taosdata.com/idmp%e5%b7%a5%e4%b8%9a%e6%95%b0%e6%8...</a> 阅读本篇文章，了解相关内容。</blockquote><h2>第三篇：为什么通用 BI 很难真正解决工业分析问题？</h2><p>在数据被治理之后，分析是绕不开的一环。《工业 BI 与通用 BI 的差异及其必要性》这篇文章，讨论的并不是工具能力高低，而是分析对象和分析目的的不同。通用 BI 更多回答“结果是什么”，而工业 BI 需要回答“过程为什么会变成这样”。前者偏管理视角，后者贴近设备、工艺和运行状态。这种差异，决定了工业分析很难直接套用通用 BI 的范式。</p><blockquote>👉  进入 <a href="https://link.segmentfault.com/?enc=kgt2zRavwjmP1ixrRW3lAw%3D%3D.LETaqOta267YlzxDshrQWuij4cFR0tupLku8LOKj5kwI7xTrKLYCy2cKqGG3%2BXMPtubyv4vTgH%2BwTWcgkd5bbqlsOzb2nYakuxxMCGlLrSKYdzg9T%2Fq%2B%2F3UdTDfxyLDF7F4fQ8iMJirjRgIjyG7pUSfwtBGWwM1IXHc5mggDS9c%3D" rel="nofollow" target="_blank">https://www.taosdata.com/idmp%e5%b7%a5%e4%b8%9a%e6%95%b0%e6%8...</a> 阅读本篇文章，了解相关内容。</blockquote><h2>第四篇：当企业真的要选平台时，应该看什么？</h2><p>在概念和差异都厘清之后，问题自然落到实践层面。《如何选择合适的工业数据管理平台？》这篇文章，并没有给出“选型清单”，而是从能力结构出发，梳理了一个工业数据管理平台必须具备的基础能力：数据目录、数据标准化、数据情景化、实时分析、可视化、事件管理，以及 AI 能否真正建立在这些基础之上。</p><blockquote>👉  进入 <a href="https://link.segmentfault.com/?enc=J62RhkZh5h5toDyZaBjd6g%3D%3D.OFagVksBphSLkyz7ladR8oacY76aNiKpQWCesQjrn1epur6WpyT0JdhEmBGoaZQ6KeqTiDBD9XKUxtzK3vYSG38%2FS%2FJgBdHoINQf%2FCR%2FY4cSzqd4CYMv6NVX6b69YRhFT%2Bo9TArMWroZtLwBICxpkN9MPJ5W9LIvSdhZ4oQtG10%3D" rel="nofollow" target="_blank">https://www.taosdata.com/idmp%e5%b7%a5%e4%b8%9a%e6%95%b0%e6%8...</a> 阅读本篇文章，了解相关内容。</blockquote><h2>第五篇：在这一框架下，为什么是 TDengine IDMP？</h2><p>最后一篇《在工业数据管理平台的选择中，TDengine IDMP 为何是优选？》，并不是为了重复前面的结论，而是把 TDengine IDMP 放回到前四篇建立的判断框架中来看。这篇文章重点讨论的，不是“TDengine 有什么功能”，而是它在整体架构上如何同时做到三件事：</p><ul><li>在能力结构上，完整覆盖传统工业数据管理平台应有的基础能力</li><li>在系统形态上，以开放方式融入企业既有体系，而不是形成新的孤岛</li><li>在数据已经被组织和理解的前提下，引入 AI，让分析门槛真正下降</li></ul><p>无问智推、智能问数、全栈能力和企业级开放性，都是在这一逻辑下展开的具体体现。</p><blockquote>👉  进入 <a href="https://link.segmentfault.com/?enc=QLFb%2B7gYBiJYWXW0d2PI%2FA%3D%3D.DOD1D70GlN5oZlpnAdUvW2jPTXvx4hFsYeQesx4q0KEdKbBoVgCPPx3tNW66s0MJEG%2Bb9HbvVlSKbbQ1e5h2RgZquI7F8dRM9NYuYJ%2F2p7sdI8Q8Xfj2Ba26QiYBq%2Fymed9M%2B%2BYJ9XgAAwTSrjE0Sf6yZfO4fpp8hC5c44j2ktU%3D" rel="nofollow" target="_blank">https://www.taosdata.com/idmp%e5%b7%a5%e4%b8%9a%e6%95%b0%e6%8...</a> 阅读文章，了解相关内容。</blockquote><h2>把五篇文章放在一起看</h2><p>我们把这些文章集中在一起发布，并不是为了给出一个“最终答案”，而是希望把一套<strong>可复用的思考框架</strong>呈现出来，供正在做工业数字化的团队参考。</p><p>如果你正在推进工业数字化、评估数据平台，或刚开始接触 TDengine IDMP 这类新一代方案，不妨从最贴近你当前阶段的那一篇读起。很多问题，在顺着这条路径看下来之后，答案会变得更清晰。</p>]]></description></item><item>    <title><![CDATA[Aloudata CAN NoETL 指标平台与现有数据中台、治理体系的融合之道 Aloudata大]]></title>    <link>https://segmentfault.com/a/1190000047607205</link>    <guid>https://segmentfault.com/a/1190000047607205</guid>    <pubDate>2026-02-12 12:03:30</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <blockquote>本文首发于 Aloudata 官方技术博客：<a href="https://link.segmentfault.com/?enc=tSEJk%2F36e7egwraKalGzEg%3D%3D.e2pPSmnJ5n1lp1fpkvdlVbdymiaGzmRu0Ch8IQKAH8fXJxMblFG0bjT18SJbQb6nmMordI2iTO95ZDY3SJZSzQlWq54bHWtiXANsH%2BwNsJRXluxkD52dlMv09z2oodZX" rel="nofollow" target="_blank">《Aloudata CAN 如何与数据中台、治理体系融合？三步避免新孤岛》</a>转载请注明出处。</blockquote><p><strong>摘要</strong>：本文探讨了 NoETL 指标平台 Aloudata CAN 如何与现有数据中台及数据治理体系融合，避免制造新的数据孤岛。通过“存量挂载、增量原生、存量替旧”三步策略，实现指标口径统一、敏捷响应与成本优化，为数据架构师和治理负责人提供实践参考。</p><h2>引言：当“新工具”遇上“旧体系”，融合是唯一出路</h2><p>企业数据架构的演进，本质上是不断引入新技术以解决新问题的过程。然而，每一次技术引入都伴随着风险：新工具与旧体系割裂，形成新的“数据孤岛”。根据行业报告，企业平均管理超过 400 个异构数据源，数据孤岛问题依然严峻。同时，传统数据治理工具普遍存在“缺乏统一业务口径、依赖静态规则、自动化程度低”等灵活性不足的问题。</p><p>“根据 2024 年 Gartner 数据和分析治理调查，近一半的受访者认为‘难以在不同部门/业务单位之间标准化数据’是其组织面临的最大 D&amp;A 治理相关挑战之一。” —— Gartner, 2024</p><p>在此背景下，引入 Aloudata CAN 这类新型指标平台，其成功的关键不在于技术本身的先进性，而在于能否与现有数据中台（负责数据汇聚与治理）和治理体系（负责规则与合规）实现平滑融合，避免制造新的技术断层和信息壁垒。架构的演进，应是“互补”而非“替代”。</p><h2>融合前置条件：认清 Aloudata CAN 的“语义层”定位</h2><p>成功融合的第一步，是准确理解 Aloudata CAN 在整体数据架构中的角色。它不是另一个数据仓库，也不是一个独立的 BI 工具。</p><p>Aloudata CAN 的核心定位是“业务语义计算引擎”或“统一语义层”。其架构逻辑清晰分层：</p><ul><li>向下：无需建设繁重的 DWS/ADS 层物理宽表，直接对接数据中台已治理好的 DWD 明细数据层。</li><li>中间：作为企业指标资产的唯一“注册中心”和“计算中心”，通过声明式语义建模，在逻辑层面构建“虚拟业务事实网络”。</li><li>向上：通过标准 API/JDBC 向各类 BI 工具（如 FineBI、Quick BI）、AI 大模型及业务系统提供统一、口径一致的指标服务。</li></ul><p>这意味着，Aloudata CAN 的引入，是将数据治理的对象从“表、字段”等技术元数据，升维到“指标、维度、口径”等业务语义元数据，填补了从数据资产到业务价值之间的关键空白层。</p><p>（注：如下图表无法渲染，请移步官网原文查看高清交互版）</p><h2>第一步：与数据中台的融合——从“物理宽表”到“虚拟业务事实网络”</h2><p>数据中台的核心价值在于统一数据标准和提供数据服务。然而，传统模式下，业务消费数据中台资产的方式，往往是通过开发大量的 ADS 层物理宽表和汇总表，这又回到了烟囱式开发的老路。</p><p>Aloudata CAN 通过 “声明式语义建模” 与数据中台深度融合：</p><ol><li>逻辑关联声明：在数据中台的 DWD 层上，通过配置方式声明不同业务实体表之间的关联关系（如订单表与用户表通过 <code>user_id</code> 关联），无需物理打宽。</li><li>虚拟业务事实网络：系统基于声明，在逻辑层面构建出一个可跨表关联查询的“虚拟明细大宽表”，业务人员可在此虚拟网络上，像使用一张大表一样自由定义指标。</li><li>替代物理宽表开发：绝大多数为满足特定报表需求而建的 ADS 宽表，均可被这种虚拟建模方式替代。新分析需求无需排期开发，可实现分钟级配置化响应。</li></ol><p>融合价值与验证：</p><ul><li>做轻数仓：某头部股份制银行引入后，有效遏制了 ADS 层宽表的无序增长，将数据交付效率提升了 10 倍（从 2 周缩短至 1 天）。</li><li>释放资源：平安证券的实践表明，通过减少不必要的 ETL 和宽表，实现了基础设施成本节约 50%。</li><li>统一出口：所有基于数据中台数据的指标分析，均通过 Aloudata CAN 统一出口，确保了消费层口径的 100% 一致性。</li></ul><h2>第二步：与数据治理体系的融合——从“事后稽核”到“定义即治理”</h2><p>企业通常已部署如 Apache Atlas、OpenMetadata 等数据治理平台，专注于技术元数据管理、数据血缘和质量稽核。Aloudata CAN 与此类平台是深度互补关系。</p><table><thead><tr><th>治理维度</th><th>传统治理平台 (如 OpenMetadata)</th><th>Aloudata CAN (业务语义层)</th><th>融合后效果</th></tr></thead><tbody><tr><td>治理对象</td><td>物理表、字段、ETL任务</td><td>业务指标、维度、计算口径</td><td>形成“技术-业务”双层元数据体系</td></tr><tr><td>核心能力</td><td>数据血缘追踪、质量规则稽核、资产目录</td><td>指标定义时自动判重、口径校验、逻辑血缘</td><td>治理规则内嵌于指标生产流程，变“事后检查”为“事前预防”</td></tr><tr><td>协作方式</td><td>被动发现、人工标注</td><td>主动同步、API集成</td><td>CAN 将定义好的业务指标及逻辑血缘同步至治理平台，补全业务视角的血缘图谱；治理平台的质量规则可为 CAN 的指标计算提供可信数据源保障。</td></tr></tbody></table><p>融合的关键是 API 双向集成：Aloudata CAN 将“业务语义元数据”同步给治理平台，治理平台则将“数据质量状态”和“技术血缘”反馈给 CAN。这使业务人员能基于可信的数据定义指标，同时让治理团队能清晰看到每个关键业务指标的底层数据支撑和影响范围。</p><p>权威背书：作为 Gartner 中国数据资产管理代表厂商 及 《数据编织主动元数据技术要求》标准核心起草单位，Aloudata CAN 在治理领域的专业性和合规性已获行业权威认可。</p><h2>第三步：与现有 BI 及 AI 应用的融合——提供统一、开放的指标服务</h2><p>融合的最终目标是让业务端无缝受益。Aloudata CAN 作为 Headless（无头） 的指标基座，通过标准化接口向上层应用提供统一服务。</p><p>对于 BI 工具：通过 JDBC 或原生 API，与 FineBI、Quick BI 等工具深度集成。业务分析师在熟悉的 BI 界面中，可直接拖拽来自 CAN 的、口径统一的指标和维度，无需关心数据来自哪张宽表。这解决了不同 BI 工具间指标口径不一致的顽疾。</p><p>对于 AI 应用：这是 Aloudata CAN 作为 AI-Ready 数据底座 的核心价值。</p><ul><li>根治幻觉：通过 NL2MQL2SQL 架构，将 AI 的自然语言问题，先收敛到指标平台定义的语义空间（MQL），再由语义引擎翻译为精准 SQL，从根本上杜绝因直接面对杂乱物理表而产生的“幻觉”。</li><li>语义 API：将指标查询、维度下钻、归因分析等能力封装为标准化的 Function Calling，供 AI 大模型直接调用，使 AI 能像业务专家一样使用数据。</li><li>安全可控：所有 AI 数据请求均先经过语义层的权限校验，实现“先安检，后执行”，保障数据安全。</li></ul><h2>避坑指南：融合过程中的三大常见误区与对策</h2><p>1、误区一：视为替代，而非增强</p><p>表现：认为引入 Aloudata CAN 后，现有数据中台或治理平台可以下线。</p><p>对策：明确分工。数据中台是“存储与计算中心”，治理平台是“规则与合规库”，而 CAN 是“业务语义与指标服务中心”。三者协同，构成完整的数据价值实现链条。</p><p>2、误区二：一次性迁移所有资产</p><p>表现：试图在项目初期就将所有历史报表和宽表逻辑迁移到 CAN 上，导致项目复杂、周期漫长、风险高。</p><p>对策：严格执行 “存量挂载、增量原生、存量替旧” 的渐进策略。优先将稳定宽表“挂载”至 CAN 统一管理；所有新需求直接基于 DWD 层在 CAN 上“原生”实现；随着时间推移，逐步将老旧、低效的宽表“替旧”下线。</p><p>3、误区三：忽视组织协作模式变革</p><p>表现：仅将 CAN 视为技术工具，未调整原有的“业务提需-IT开发”的协作流程。</p><p>对策：推广业技融合的协作模式。例如，借鉴平安证券的 “136”模式：10% 的科技人员负责定义原子指标和保障数据质量；30% 的业务分析师基于原子指标配置派生指标；60% 的终端业务用户可自由组合指标维度进行自助分析。建立基于统一指标库的协作流程。</p><h2>成功融合的三大可衡量标准</h2><p>如何判断融合是否真正成功？以下三个可量化的标准供企业参考：</p><ol><li>口径一致性：企业核心业务指标（如 GMV、DAU、利润率）实现 100% “一处定义，处处一致”，不同部门、不同报表中的同一指标结果完全吻合。</li><li>响应敏捷性：业务自助分析需求的响应周期，从传统的“天”或“周”级，普遍缩短至 “分钟”或“小时”级。IT 从重复的报表开发中解放出来。</li><li>成本优化性：ADS 层汇总表/宽表的数量增长得到有效遏制，甚至开始减少。整体数据栈的 TCO（总拥有成本）实现可观测的下降，服务器资源得到释放。</li></ol><h2>常见问题（FAQ）</h2><h4>Q1: Aloudata CAN 会取代我们现有的数据仓库或数据湖吗？</h4><p>不会。Aloudata CAN 是构建在现有数据存储（如数据仓库、数据湖的 DWD 层）之上的统一语义计算层。它的目标是“做轻数仓”，减少不必要的物理宽表和汇总表开发，而非替换底层存储。您现有的数据资产可以完全保留并得到更高效的利用。</p><h4>Q2: 我们已经有了数据治理平台（如 Atlas、OpenMetadata），再引入 CAN 会不会造成冲突？</h4><p>不会冲突，而是深度互补。传统治理平台擅长管理物理表、字段、任务血缘等“技术元数据”。Aloudata CAN 则管理“业务语义元数据”（指标、维度、口径）。两者可通过 API 集成：CAN 将定义好的业务指标、血缘同步给治理平台，形成完整的“技术-业务”双层血缘；治理平台的数据质量规则也可为 CAN 的指标计算提供保障。</p><h4>Q3: 如何说服业务部门接受并使用这个新平台？他们习惯用现有的 BI 工具。</h4><p>无需改变业务部门使用 BI 工具的习惯。Aloudata CAN 通过标准接口（如 JDBC）与 FineBI、Quick BI 等主流 BI 工具无缝集成。业务人员在熟悉的 BI 界面中，可以直接拖拽来自 CAN 的、口径统一的指标和维度进行分析。对业务而言，他们感受到的是数据更准、取数更快、分析更自由，而无需关心底层平台的变化。</p><h2>核心要点</h2><ol><li>定位清晰，互补而非替代：Aloudata CAN 是位于数据中台之上的“业务语义层”，与底层存储计算和上层治理规则深度协同，共同构成现代数据架构。</li><li>技术融合，释放中台价值：通过声明式语义建模和虚拟业务事实网络，直接基于 DWD 层响应需求，替代大量手工宽表开发，真正实现数据中台资产的敏捷消费与成本优化。</li><li>治理前置，内嵌于流程：将治理规则（如口径校验、自动判重）融入指标定义环节，并与外部治理平台通过 API 双向同步，实现从“事后稽核”到“定义即治理”的演进。</li><li>服务统一，赋能业务与AI：作为开放的指标基座，通过标准接口同时支撑多种 BI 工具和 AI 应用，提供口径一致、安全可信的数据服务，是构建 AI-Ready 数据底座的关键。</li><li>策略渐进，规避实施风险：遵循“存量挂载、增量原生、存量替旧”的三步走法则，并配套组织协作模式变革（如“136”模式），确保融合过程平滑、价值可衡量。</li></ol><ul><li><ul><li>*</li></ul></li></ul><p>本文详细内容及高清交互图表，请访问 Aloudata 官方技术博客原文：  <br/><a href="https://link.segmentfault.com/?enc=g8qK7mfCjMsaKjawHS1ieQ%3D%3D.SNmRwTWDthUD3GH4hMPnqje0I56QA6SRt%2BvOxVVZWWNdKPFW4pyH5o9qyh%2FLZSomj21fmf5vrNNvZQHAjcbYncIQBsq3SdoydfXTE1%2FDMZKKYky6WQfHiaW5aoqhcA%2Fr" rel="nofollow" target="_blank">https://ai.noetl.cn/knowledge-base/aloudata-can-data-middle-p...</a></p>]]></description></item><item>    <title><![CDATA[秒级采集 × 万级点位 × 两万亿条数据管理，TDengine的「红河烟叶复烤」工艺数字化实践 TD]]></title>    <link>https://segmentfault.com/a/1190000047607207</link>    <guid>https://segmentfault.com/a/1190000047607207</guid>    <pubDate>2026-02-12 12:02:55</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><strong>小T导读：</strong>红河烟叶复烤有限公司于 2024 年 9 月完成了易地技术改造并投产了数字化新厂区。 新厂区建成了全国首家应用加长型智能烤片机的复烤生产线，年加工能力提升至 60 万担烟叶。公司通过部署原料收储与复烤生产协同运营系统（IMOM），实现了从原料收储到生产的全流程智能化管理。烟叶复烤加工过程中通过引入 TDengine TSDB 时序数据库，实现了海量数据的实时低成本存储，是数字化转型和智能制造升级中的关键一步。</p><p>        </p><h2><strong>背景和痛点</strong></h2><p>复烤是烟草产业链中承上启下的关键环节，位于农业（烟叶种植）与工业（卷烟生产）之间，被视为“烟草初加工”的核心。它的业务专业性非常强，可以理解成是 “烟叶的定型和品质升华” 的工厂：来自各产区的原烟虽然经过初烘，但水分不均、杂质较多、品质不稳定，尚不能直接用于卷烟生产。通过复烤环节，这些原烟被进一步清理、调湿、定型，最终产出符合卷烟厂制丝工序要求的片烟，为后续工业生产提供标准、均匀、稳定的原料基础。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607209" alt="" title=""/></p><p>复烤是典型的流程型生产，其产生的数据特点与制丝类似，但又有其独特性：</p><ol><li><strong>数据源密集并且采集频率高</strong></li></ol><p>复烤生产线由真空回潮机、打叶风分、复烤机、预压打包机等多类设备组成，每类设备又部署了大量传感器，包括温度、湿度、压力、流量、风速、电机电流等关键参数。为实现对工艺的精确控制，采样往往需要达到秒级甚至更高频率，使得整条复烤产线每秒可产生数十万级的时序数据。</p><ul><li><strong>强时序性与工艺强关联</strong></li></ul><p>复烤过程中的所有数据都严格伴随时间戳产生，呈现高度连续的时序特征。各类工艺参数——如复烤机不同温区的温度、湿度变化——会直接影响“配方片烟”的含水率、色泽和香气等关键质量指标。因此，必须能够精确追溯每一批烟叶在加工过程中经历的完整工艺曲线，以保障品质稳定与工艺优化。</p><ul><li><strong>写入压力巨大</strong></li></ul><p>系统需要在生产过程中不间断地写入海量数据，是典型的写入密集型应用。传统关系型数据库在面对这种持续洪峰写入时，性能会急剧下降，成为系统瓶颈。</p><p><strong> </strong></p><h2><strong>为什么选择 TDengine TSDB</strong></h2><p>我们选择 TDengine TSDB 作为复烤厂数字化转型与智能制造升级的核心底座，关键在于复烤工艺的数据特性与 TDengine 的性能优势高度契合，实现了从数据采集到工艺优化的全链路支撑。</p><ul><li><strong>国产化替代</strong>：TDengine TSDB 为 100% 国产自主研发，核心代码开源，已适配麒麟、统信、凝思等国产 Linux 操作系统，全面满足政府与企业的信息安全及国产化替代要求。</li><li><strong>零代码数据采集</strong>：TDengine TSDB 自带的 taosX 工具可以直接从 OPC UA server 上采集数据。通过 taosExplorer 管理页面图形化配置 taosX 的数据采集任务，并可以实现采集点位的动态更新。</li><li><strong>高性能写入</strong>：TDengine TSDB 为每个数据采集点创建独立的表，采用列式存储和追加写入模式。这种专为时序数据设计的架构，使其写入效率比通用数据库高出一个数量级，能够轻松承接复烤车间所有传感器产生的数据流。</li><li><strong>超高压缩比</strong>：时序数据具有高度冗余性。TDengine 采用了针对性的压缩算法。在复烤车间场景下，压缩比通常可达 10% 甚至更高，这意味着存储空间节省 90% 以上，大幅降低了长期归档与历史数据留存的成本。</li></ul><p> </p><h2><strong>TDengine TSDB 落地实践</strong></h2><p>我们从 2021 年起就部署并使用 TDengine 时序数据库了，当时采用的是 2.6 版本，集群由 3 台服务器组成，其中包括 2 个数据节点和 1 个仲裁节点。单机配置为 CPU 56 核、内存 256GB、磁盘 14TB。依托 TDengine 的高压缩率，我们在这一套配置下长期稳定地存放了 SCADA 系统产生的<strong>超过两万亿条时序数据</strong>。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607210" alt="" title="" loading="lazy"/></p><p> </p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607211" alt="" title="" loading="lazy"/></p><p>本次根据红河复烤公司 IMOM 建设的数据采集需求，我们新增部署了一台 TDengine TSDB 3.3 节点，进一步提升了系统的接入与分析能力。新版不仅支持零代码 OPC UA 数据采集，也提供了更丰富的查询语法与计算函数，能够更好地支撑复烤工艺的实时监控与质量分析。</p><p>新节点的硬件配置为：64 核处理器、256GB 内存、47TB 存储空间，运行麒麟 V10 SP3 操作系统。</p><p>零代码 OPC UA 数据采集配置步骤如下：</p><ol><li>通过 CSV 文件配置 OPC UA 数据采集的点位信息，示例如下：</li></ol><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607212" alt="" title="" loading="lazy"/></p><p> </p><ul><li>在 taosExplorer Web 界面配置数据采集任务。检测连通性，与 OPC UA 联通后，将 CSV 文件上传。初期我们配置了 10 个采集任务，每个任务大约 2000 点位。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607213" alt="" title="" loading="lazy"/></p><ul><li>采集任务选择 observer 模式，按 1s 间隔轮询读取最新值写入到数据库里面。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607214" alt="" title="" loading="lazy"/></p><ul><li>在采集任务运行过程中，可实时查看数据采集及写入的记录数。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607215" alt="" title="" loading="lazy"/></p><ul><li>通常情况下，一个采集点会对应存放在一张子表中。但在需要按设备或工段进行集中管理时，也可以采用多列模型：先手动创建包含多字段的超级表，将多个点位的数据按字段写入同一张宽表，实现更紧凑的建模方式。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607216" alt="" title="" loading="lazy"/></p><h2><strong>落地效果</strong></h2><p>我们选择 TDengine TSDB，并非单纯更换一套数据库，而是基于复烤核心业务数据特性开展的一次技术架构升级。它帮助复烤车间从“数据负担”（高存储成本、慢查询、难分析）走向“数据资产”（易存储、快查询、可分析）。通过全面解决海量时序数据在采集、存储与计算环节的性能瓶颈，TDengine TSDB 使复烤工艺的生产过程更加数字化、透明化和智能化，从而支撑产品质量稳定、工艺参数优化与运营成本下降等关键目标的实现。</p><ol><li>采集到的（出料烟叶含水率，出料烟叶温度，工艺流量等）数据展示：</li></ol><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607217" alt="" title="" loading="lazy"/></p><ul><li>通过 SQL 语句直接查询各点位的数据：</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607218" alt="" title="" loading="lazy"/></p><h2><strong>运行优化与问题分析 </strong></h2><ol><li><strong>点位数据缺失</strong></li></ol><p>复烤厂的数据写入由 taosX 通过 OPC UA 方式完成，采集模式采用 <em>observe</em>，以秒级频率定时拉取。但在实际运行中我们发现部分点位存在数据缺失。排查后定位到 task.id:8：该任务一次性配置了超过 1 万个点位，负载过高，导致采集不稳定。我们将其拆分为 6 个任务，每个任务约 2000 个点位，显著降低单任务压力。同时将每个任务的 <code>batchSize</code> 从 10000 调整为 1000，以减少批处理延迟并提升采集成功率。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607219" alt="" title="" loading="lazy"/></p><p> </p><ul><li><strong>点位数据间隔超预期</strong></li></ul><p>采集任务按 1 秒周期执行，但在实际监测中我们发现部分点位的采集间隔明显超过 1 秒：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607220" alt="" title="" loading="lazy"/></p><p>我们开启采集任务的“保存原始数据”高级选项，并结合 <code>opc.log</code> 进行分析：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607221" alt="" title="" loading="lazy"/></p><p>日志显示：单次采集在 1 秒内无法完成，从发起请求到 OPC Server 返回数据往往需要约 3 秒，期间还出现多次 5 秒超时导致本轮采集失败的情况。这类问题根因在于 OPC Server 的处理能力不足，无法支撑秒级高频采集需求。为保证采集实时性，需要提升 OPC Server 的硬件配置，或通过增加 Server 实例数量来分担负载。</p><p>  </p><h2><strong>未来规划与升级方向</strong></h2><p>我们目前使用的 TDengine TSDB 版本为 3.3.4.10，其流计算能力尚不支持嵌套查询，也不支持虚拟表。而在最新版本中，这两项能力均已完善：流计算支持更复杂的嵌套逻辑，新版本 TSDB 也提供了虚拟表功能。</p><p>在现有业务中，我们已遇到多个需要新版本能力才能实现的场景，例如：</p><ul><li>多个流计算任务需将结果写入同一张目标表；</li><li>需要检测“温度超过 80°C 并持续 10 分钟”的复杂规则，并生成实时告警。</li></ul><p>这些需求都依赖新版本流计算引擎才能高效落地。目前我们正在进行相关测试，测试完成后将计划升级至最新版本 3.3.8。</p><p>TDengine TSDB 新版本流计算具有以下特性：</p><ul><li><strong>数据分级存储与智能降采样</strong>：工业设备每秒生成数万条原始数据，通过流计算实现降采样后存储，可大幅降低存储空间。</li><li><strong>预计算加速实时决策</strong>：用户查询全量数据时，可能需扫描百亿级别数据，很难实时获取查询结果，通过流计算的结果进行查询可快速实时响应。</li><li><strong>异常检测和低延迟告警</strong>：异常检测、监控报警，需要根据规则低延迟地获取特定数据，传统批处理延迟较大，采用流计算可快速告警。</li></ul><p>对复烤业务来说，新版本带来的这些能力，正是我们下一阶段持续优化所需要的。</p><h2><strong>关于红河烟叶复烤有限公司</strong></h2><p>红河烟叶复烤有限公司成立于 2003 年 8 月 8 日，位于云南省弥勒市产业园区红河路 2 号。公司主要从事烟叶分选、复烤加工及仓储，红河烟叶复烤有限公司 2024 年 9 月易地技改顺利投产，标志着覆盖打叶复烤、片烟醇化、卷烟制造、工商物流的现代烟草产业园区初步成形。</p><h2><strong>关于作者</strong></h2><p>普轶，参与红河烟叶复烤有限公司 IMOM 建设，长期从事工厂信息化规划设计、系统集成、数据治理、实施及维护。</p>]]></description></item><item>    <title><![CDATA[韩国国民搜索 NAVER：使用 JuiceFS 打通 Hadoop 与 Kubernetes 存储实]]></title>    <link>https://segmentfault.com/a/1190000047607243</link>    <guid>https://segmentfault.com/a/1190000047607243</guid>    <pubDate>2026-02-12 12:02:11</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>NAVER 是韩国领先的互联网科技公司，运营着韩国最大的搜索引擎，并在人工智能、自动驾驶等高科技领域积极布局。作者 Nam Kyung-wan 来自 NAVER Infra 团队，自 2023 年参与 JuiceFS 社区代码贡献 (GitHub: <a href="https://link.segmentfault.com/?enc=5KX%2F%2FXNV1bd0PEF2SEBYBA%3D%3D.laWruXdN6f7hyuQUc0NZ8Wxp1xTG0g%2FhN%2FpHUQQVK3M%3D" rel="nofollow" target="_blank">kyungwan-nam</a>)，为 Hadoop 场景提出了多项改进。本文是作者继“ <a href="https://link.segmentfault.com/?enc=KYbJ70jKARGkrzWVsDPYPg%3D%3D.ye7ac7laJqVoFzEFyUGjSeSsp3v%2BJRd1oDP5SqvYYzlpXCxg%2B0l%2Bj68di9wto8HCGVj8h4Bfa0syMyJLacn5gxoYl8BLuWKu2Y2WxHqkD9cEAybb6VpfktwWJ0lcuSu8" rel="nofollow" target="_blank">为 AI 平台引入存储方案 JuiceFS</a>”后的第二篇博客。</p><p>NAVER Infra 团队负责运营公共 Hadoop 集群，使用 Spark、Hive、MapReduce 等 Hadoop 应用处理数据，并将数据存储在 HDFS 中。HDFS 在 Hadoop 生态系统中通过数据本地性支持高性能，具备优异的容错性和可扩展性。</p><p><strong>随着人工智能服务的普及，数据规模急剧增长，对多样化数据存储的需求也日益增加。同时，如何高效地共享 Hadoop 集群外部 AI 平台（如 Kubernetes）中的数据，成为了一项重要挑战。在这一背景下，NAVER 探讨了对象存储是否可以替代 HDFS，并明确了 JuiceFS 结合对象存储的适用场景</strong>。</p><h2>01 HDFS 的局限</h2><p><strong>存储成本上升</strong></p><p>AI 开发需要以高效且经济的方式存储不断增长的数据，并在某些情况下长期保留原始数据，以便进行模型改进和重新训练。</p><p>然而，Hadoop 的计算和存储是紧密耦合的，导致存储扩展难以独立进行。当没有计算需求时，仅为扩展存储空间而增加节点会造成不必要的成本。此外，HDFS 默认保留三重副本，进一步增加了存储成本。</p><p><strong>文件数量限制</strong></p><p>AI 开发涉及数千万个小文件，如图像、音频和文本等。HDFS 存在著名的<a href="https://link.segmentfault.com/?enc=p2AiwJ8zJrU41cODjrJ8RA%3D%3D.aUg4%2Fow9mPSnqdHyHXriflGAYmLcEYapjQj4Tl9eEz8OfALFe0LxqIQsU1rfo7Feyem8oUOnyGL2TOC%2FeaYnYVsxCazvydzfjJpGeUSRCvI%3D" rel="nofollow" target="_blank">小文件问题</a>，因为所有文件和块的元数据都存储在 NameNode 的内存中。例如，管理 1000 万个文件大约需要 3GB 的内存。因此，HDFS 可管理的文件数量受到单个 NameNode 内存容量的限制。</p><p><strong>数据中心容灾能力弱</strong></p><p>HDFS 通常由单个数据中心的节点组成。为应对数据中心故障或灾难，需使用额外方案将数据复制到其他数据中心，从而产生增加成本。</p><p><strong>运营成本增加</strong></p><p>NAVER 由专业人员运营公共 Hadoop 集群，负担相对较小，但通常 Hadoop 集群的构建和运营非常复杂且成本高昂。若要单独构建和运营稳定的 Hadoop 环境，需要专业知识和较高的维护成本。</p><p><strong>Kubernetes 中的生态兼容性差</strong></p><p>NAVER AI 平台基于 Kubernetes 构建，并利用 Kubeflow、KServe 等多种 AI 开源工具及 GPU 支持。但 HDFS 不支持 POSIX API 和 CSI 驱动，无法作为 Kubernetes 常规存储方式（即 PersistentVolume）使用。因此，在 Kubernetes 中使用 HDFS 需在容器中准备 Hadoop 包、配置和认证信息，并编写 HDFS API 代码，非常繁琐且会降低 AI 开发效率。</p><h2>02 对象存储的优势与劣势</h2><p>Hadoop 通过数据本地性提供高性能，但由于 HDFS 与计算节点耦合，计算和存储资源难以独立扩展。因此，扩展存储空间时，仍需增加额外的计算节点。</p><p>相比之下，云环境支持计算和存储的独立扩展。通常，数据存储在对象存储中而非 HDFS，计算可以通过托管服务（如 AWS EMR、Google Dataproc）或基于 Kubernetes 的数据处理引擎进行，数据则存储在 S3、GCS 等对象存储中。这种架构支持灵活扩展计算和存储资源。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607245" alt="" title=""/></p><p>此外，Hadoop 社区和云供应商提供了 <a href="https://link.segmentfault.com/?enc=bMhrg2xA%2BJTRy9U4QBlt5g%3D%3D.MOcr9TTilYL5c2dCODnH6whN%2Fzsaf2lRcp3G3RBvzF9wbhsJbE1LoKaXD15NFxVH3IA8abXCw78HTOekRNpSWrNqBzt5j1KUr5Ot20Gp5yk%3D" rel="nofollow" target="_blank">S3A</a>、<a href="https://link.segmentfault.com/?enc=IZjZG1bsYKYa7oN19xbXNw%3D%3D.oIZ2GKfbLbFGYhARKVv6LFPs%2FyS7awhI05i0l4axAoYMQeNScHdMlMziPKu137Mb4m5iD0t%2BOqoLXP4HaSVeNg%3D%3D" rel="nofollow" target="_blank">Azure Blob</a>、<a href="https://link.segmentfault.com/?enc=m0iX5u1MxJtGMVzCbNVkZg%3D%3D.Y6bD9Df2K2mYumtnj5b9r4wRZAbokcihLcqdrNm1nPyU0MXmtdsGARP3oUdXUFN0Ik8udW5WtaR1lsr9qGCTBIvJ964pvWvf5%2F1Goy4i3KvpvXrRaYQ8tRHqQT3Vp%2Fp3" rel="nofollow" target="_blank">Aliyun OSS</a> 等 HDFS 兼容文件系统，使得对象存储可以像 HDFS 一样使用。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607246" alt="" title="" loading="lazy"/></p><p>对象存储作为远程存储，虽然难以实现数据本地性，但具有以下优势：</p><ol><li><strong>存储成本降低</strong>：计算和存储分离，可独立扩展。对象存储通常成本较低，并能根据需要选择不同的存储类别。例如，对于访问频率低但需长期保留的数据，可使用低成本存储类别（如 S3 Glacier）。</li><li><strong>出色的扩展性和弹性</strong>：对象存储设计上支持近乎无限的扩展。对象数量和容量无限制，可根据工作负载变化轻松扩展或缩减。</li><li><strong>数据中心灾难恢复支持</strong>：S3 等对象存储提供跨区域复制功能，可防止数据中心故障或灾难导致的数据丢失。</li><li><strong>运营成本降低</strong>：避免 Hadoop 集群的构建和运营负担，从而降低运营成本。</li></ol><p>但对象存储替代 HDFS 是好的选择吗？</p><p><strong>不支持目录</strong>：  <br/>在文件系统中，文件通过目录进行组织，列出目录下的文件是一项基本操作，通常速度较快。  <br/>而对象存储没有目录的概念，所有对象是独立的扁平结构。列出文件时需要通过对象前缀搜索，速度较慢。此外，为模拟目录结构而临时创建的 Directory Marker 对象也会影响性能。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607247" alt="" title="" loading="lazy"/></p><p><strong>不支持重命名</strong>：  <br/>在文件系统中，重命名是基本操作，以 O(1) 级别的原子事务快速执行。但对象存储不支持重命名，需通过复制全部数据再删除原数据的方式处理，导致速度非常慢且可能中途失败。</p><p>这一问题对于 MapReduce 和 Spark 等大数据框架影响尤为明显(<a href="https://link.segmentfault.com/?enc=S9lNuP7ib76h%2FTiQppYiuQ%3D%3D.njGOEUI52IWzJaubvxU4zVLrXQdYwBRc07sFQKE%2BUhRDtxC7IgzQhUn1I7aPEMjcHPt6s4cSuG6qN7U4JdrU65apUs3OzOxSCbW0JJQTMLuFZqQMAkrdX%2F0qP9bLfPN4b6pSwBnhc5DciTkIcCjbx29jwiVGG0WYlOYfBZONHfM%3D" rel="nofollow" target="_blank">Apache Hadoop Amazon Web Services support – Committing work to S3 with the S3A Committers</a>)。文件输出操作通常依赖重命名来保证一致性，FileOutputFormatCommitter 就是基于重命名实现的。因此，在对象存储中直接使用 FileOutputFormatCommitter 会显著降低性能。</p><p>为了解决这一问题，可以使用 <a href="https://link.segmentfault.com/?enc=T9CJlGvUF%2FGAekbBTya2hA%3D%3D.xJiArK%2BpFB%2ByTwbqgBWOx4UHpaaqe8dmTuAJGKTThLxmZlytplE4F4uyR6MP8S7sV2HJZI99M7lMr6%2BHJs0x938m1Jn50DM5tCnR0McMoS8dtnI%2BHGdPNqYozapzrirgaU4S2VCNB3JTf24j2seoow%3D%3D" rel="nofollow" target="_blank">Magic Committer</a>，它避免了重命名操作，并针对对象存储进行了优化。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607248" alt="" title="" loading="lazy"/></p><ol start="3"><li><strong>不支持文件权限</strong>：  <br/>HDFS 支持 POSIX 权限体系，可以设置文件和目录的所有者、组以及其他用户的权限。而对象存储不提供此功能，因此文件的所有者和组通常被视为当前用户，所有文件和目录的权限默认为 666 和 777（即文件可读写，目录可读写并可执行）(参考: <a href="https://link.segmentfault.com/?enc=z%2FWh4o%2BAHvRo1g5Fn5megQ%3D%3D.7lLELn21d%2FKN%2Bw7DX6x7Wk0u355u0KI%2BoJyvX24%2FSfdukuLHgv5SR9yGlEAX%2BeswqKu6i%2BryhyL%2FSTGFoMJo9xnYhKJeTbl3uPsqj6hqhESVLmXCodI14u3P7ev66UK2P8Ru0hg2WQCWDma%2BKa39kihrWVHcbdA7QP23nnw%2FN7fjXxAIV9cmgVE3uvt4L70f" rel="nofollow" target="_blank">Object Stores vs. Filesystems</a>).。</li><li><strong>数据访问速度慢</strong>：  <br/>对象存储作为远程存储，无法保证数据本地性，并且每次访问都涉及网络传输，因此相较于 HDFS，其数据访问速度较慢，性能受到网络延迟和带宽限制的影响。</li><li><strong>Kubernetes 中的低可用性</strong>：  <br/>一些工具，如 Mountpoint for Amazon S3 和 s3fs，支持通过 POSIX API 将对象存储挂载为类似本地文件系统的方式。AWS S3 还通过 Mountpoint for Amazon S3 CSI 驱动 支持将对象存储作为 Kubernetes 卷使用。</li></ol><p>然而，由于对象存储与传统文件系统存在根本差异，它无法完全兼容 POSIX API，且性能较低。因此，在使用这些工具时，需要充分了解它们的工作原理和局限性。最终，即使在 Kubernetes 环境中使用对象存储，低可用性问题仍然无法解决。</p><ol start="6"><li>S3 兼容对象存储的 API 兼容性：  <br/>S3 已成为对象存储的事实标准，被多种应用广泛支持。因此，许多云供应商和开源项目提供 S3 兼容对象存储。然而，S3 兼容对象存储并不完全等同于原生 S3 服务。在使用时，需要确认其是否与 S3AFileSystem 或其他应用所使用的 S3 API 兼容。</li></ol><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607249" alt="" title="" loading="lazy"/></p><p>综上，对象存储可以像 HDFS 一样使用，但需要充分理解其局限性。现有 Hadoop 应用难以直接迁移，仍需额外的开发和适配工作。对于直接使用 HDFS API 编写的代码，需要避免重命名操作，并减少文件列表操作，以适应对象存储的特性。为避免现有 Spark 应用性能下降，需考虑使用 Magic Committer，但它并非总是有效，特别是在不支持 Spark 动态分区覆盖的情况下。</p><p>此外，虽然 Spark 和 Hadoop 社区持续改进对象存储相关问题，但更新软件包版本和解决问题仍然面临挑战。使用 S3 兼容的对象存储时，还需验证其与 S3 API 的兼容性。</p><h2>03 在 Hadoop 中使用 JuiceFS</h2><p>JuiceFS 是一款分布式文件系统，架构由客户端、元数据引擎和数据存储组成。对象存储仅用于存储数据块，而文件系统所需的元数据则由数据库管理。</p><p><strong>需注意 JuiceFS 是与 HDFS 类似的分布式文件系统。因此，与直接使用对象存储不同，JuiceFS 能完美支持 HDFS API、POSIX API 和 Kubernetes CSI 驱动</strong>。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607250" alt="" title="" loading="lazy"/></p><p>为了在速度慢且修改困难的对象存储上实现分布式文件系统，JuiceFS 引入了 chunk、slice 和 block 概念。</p><ul><li>chunk（64MB）：将文件分割为 64MB 单位，支持基于偏移的并行处理。</li><li>slice：chunk 内的修改单位，写入时创建新 slice 并优先使用最新版本。</li><li>block（默认 4MB）：实际存储在对象存储中的最小单位，通过并行处理缩短上传时间。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607251" alt="" title="" loading="lazy"/></p><p>此外，从远程对象存储读取数据较慢，JuiceFS 支持多级缓存，以此弥补此性能不足。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607252" alt="" title="" loading="lazy"/></p><p>NAVER 内部 AI 平台已使用 JuiceFS。更多关于 JuiceFS 的详细信息及 AI 平台引入过程可参考<a href="https://link.segmentfault.com/?enc=eVkwU2Tbp4EDvY6qRAzsyA%3D%3D.6ACO3g7oba5nsOOYcInp%2FdUfIXEQn73F7Ty6MoLDoZUDaxS3CLvaZnRAGUs2JCVJGmRgOMBymD3Taglprb6qOq3hcur3nd9zQyRAmocdnTRwl6wYevA6FNwORldk5zg9" rel="nofollow" target="_blank">为 AI 平台引入存储方案 JuiceFS</a>。</p><p>JuiceFS 支持 Hadoop SDK，通过配置 JuiceFS 后，用户即可在 Hadoop 环境中使用它。</p><h3>配置 JuiceFS</h3><p>为使 Hadoop 识别 JuiceFS 文件系统，需在 core-site.xml 文件中添加以下内容。其中 <a href="https://link.segmentfault.com/?enc=qaRr1RpajW1daA%2BSoHDWaA%3D%3D.3%2BVONNA93n7nQGm%2FomIV5NC0%2FwNusdb4eWelCeqwO4tjRTOT5xAhWCRxBZixQ3arTdg8lUSo%2FFYvXeCAElu13BBmcksYwAOfmA6E0kuPuDM%3D" rel="nofollow" target="_blank">fs.jfs.impl、fs.AbstractFileSystem.jfs.impl 和 juicefs.meta</a> 是必需的。</p><pre><code>&lt;!-- Configure JuiceFS to be available via jfs:// --&gt;    
  &lt;property&gt;  
    &lt;name&gt;fs.jfs.impl&lt;/name&gt;  
    &lt;value&gt;io.juicefs.JuiceFileSystem&lt;/value&gt;  
  &lt;/property&gt;  
  &lt;property&gt;  
    &lt;name&gt;fs.AbstractFileSystem.jfs.impl&lt;/name&gt;  
    &lt;value&gt;io.juicefs.JuiceFS&lt;/value&gt;  
  &lt;/property&gt;  
&lt;!-- juicefs meta url --&gt;    
  &lt;property&gt;  
    &lt;name&gt;juicefs.meta&lt;/name&gt;  
    &lt;value&gt;redis://:password@addr&lt;/value&gt;  
  &lt;/property&gt;  
&lt;!-- In this example, grant access permissions to all users to avoid permission issues. --&gt;    
  &lt;property&gt;  
    &lt;name&gt;juicefs.umask&lt;/name&gt;  
    &lt;value&gt;000&lt;/value&gt;  
  &lt;/property&gt;  
&lt;!-- Cache up to 100 GiB. --&gt;    
  &lt;property&gt;  
    &lt;name&gt;juicefs.cache-size&lt;/name&gt;  
    &lt;value&gt;102400&lt;/value&gt;  
  &lt;/property&gt;  
&lt;!-- Cache under the temporary path of YARN containers, so the cache is removed when the container terminates.    
Since it's a shared Hadoop, caching is temporary only during job execution. --&gt;  
  &lt;property&gt;  
    &lt;name&gt;juicefs.cache-dir&lt;/name&gt;  
    &lt;value&gt;${env.PWD}/tmp&lt;/value&gt;  
  &lt;/property&gt;  
&lt;!-- Prometheus remote write configuration for metrics collection --&gt;    
  &lt;property&gt;  
    &lt;name&gt;juicefs.push-remote-write&lt;/name&gt;  
    &lt;value&gt;http://host:port&lt;/value&gt;  
  &lt;/property&gt;  
  &lt;property&gt;  
    &lt;name&gt;juicefs.push-remote-write-auth&lt;/name&gt;  
    &lt;value&gt;username:password&lt;/value&gt;  
  &lt;/property&gt;  
&lt;!-- Additionally collect Hadoop user and YARN container ID.    
For shared Hadoop to distinguish users and applications. --&gt;  
  &lt;property&gt;  
    &lt;name&gt;juicefs.push-labels&lt;/name&gt;  
    &lt;value&gt;user:${env.USER};container_id:${env.CONTAINER_ID}&lt;/value&gt;  
  &lt;/property&gt;  </code></pre><p>以上为单文件系统的默认配置，但也可根据需要配置多个文件系统同时使用。  <br/>更多配置选项可参考“<a href="https://link.segmentfault.com/?enc=R9%2BrQvaBvbt42llgrsOjCA%3D%3D.f7Pak39dY2K9pDGcDymkL1x6%2FvZRPNetbg%2Ffvw1u3%2B8d%2FevGFr5adpCiJh1Yl6YoBk3D8JiE0N8t3WooEm%2FXUDMmx94CYRiEvzA1GrumFYs%3D" rel="nofollow" target="_blank">客户端配置</a>”。</p><h3>Hadoop SDK</h3><p>Hadoop SDK 的 JAR 文件可以通过下载预编译客户端或自行编译源代码获取。为了简化部署，通常可以在所有 Hadoop 节点的 Hadoop 发行版安装路径中预先安装。然而，在大规模 Hadoop 集群中，这种方法操作繁琐，尤其是对于公共 Hadoop 环境，它会限制所有用户使用特定版本。</p><p>大多数 Hadoop 应用支持将所需 JAR 文件部署并添加到 classpath 中，用户可根据实际需要选择部署方式。以下是 HDFS CLI、MapReduce 和 Spark 中的具体部署方法。</p><h3>HDFS CLI</h3><p>配置完上述 <code>core-site.xml</code> 文件后，需要在 <code>HADOOP_CLASSPATH</code> 环境变量中设置 Hadoop SDK 文件路径。完成此设置后，您可以使用 <code>hdfs</code> 命令操作 <code>hdfs://</code> 和 <code>jfs://</code> 文件系统。</p><pre><code>$ export HADOOP_CLASSPATH=/home/juicefs/juicefs-hadoop-1.2.3.jar  
$ hdfs dfs -ls hdfs://home/foo  
Found 6 items    
...  
drwx------   - foo users          0 2022-10-14 20:55 hdfs://home/foo/.Trash    
drwx------   - foo users          0 2022-01-06 10:18 hdfs://home/foo/dfsio    
drwx------   - foo users          0 2025-01-22 17:54 hdfs://home/foo/tpcds

$ hdfs dfs -ls jfs://default/  
2025-08-25 19:15:43,964 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 60 minutes, Emptier interval = 60 minutes.    
Found 8 items    
...  
drwxrwxrwx   - 10000 hadoop-admins       4096 2025-06-10 18:06 jfs://default/nyc    
drwxrwxrwx   - 10000 hadoop-admins       4096 2025-05-15 19:42 jfs://default/subdir    </code></pre><h3>MapReduce</h3><p>MapReduce 在 Hadoop 的多个节点上并行运行，因此所有分配任务的节点都需要部署 JAR 文件。推荐的方法是通过分布式缓存进行部署。使用此方法时，任务执行时会自动将 <code>mapreduce.application.framework.path</code> 中设置的 MapReduce 框架部署到任务节点。</p><p>以下是 <code>mapred-site.xml</code> 文件的示例配置：</p><ul><li><code>mapreduce.application.framework.path</code>：指定包含 Hadoop SDK 的 MapReduce 框架的 HDFS 路径。</li><li><code>mapreduce.application.classpath</code>：配置为包含 Hadoop SDK 的路径。</li></ul><pre><code>&lt;property&gt;  
   &lt;name&gt;mapreduce.application.classpath&lt;/name&gt;  
   &lt;value&gt;$PWD/mr-framework/hadoop/share/hadoop/mapreduce/*:$PWD/mr-framework/hadoop/share/hadoop/mapreduce/lib/*:$PWD/mr-framework/hadoop/share/hadoop/common/*:$PWD/mr-framework/hadoop/share/hadoop/common/lib/*:$PWD/mr-framework/hadoop/share/hadoop/yarn/*:$PWD/mr-framework/hadoop/share/hadoop/yarn/lib/*:$PWD/mr-framework/hadoop/share/hadoop/hdfs/*:$PWD/mr-framework/hadoop/share/hadoop/hdfs/lib/*:$PWD/mr-framework/hadoop/share/hadoop/tools/lib/*&lt;/value&gt;  
 &lt;/property&gt;  
 &lt;property&gt;  
   &lt;name&gt;mapreduce.application.framework.path&lt;/name&gt;  
   &lt;value&gt;hdfs://mapred/framework/hadoop-mapreduce-3.1.2-juicefs-1.2.3.tar.gz#mrframework&lt;/value&gt;  
 &lt;/property&gt;  </code></pre><h3>Spark</h3><p>Spark 的基本配置文件是 <code>spark-defaults.conf</code>。在该文件中，可以替代 <code>core-site.xml</code> 进行如下设置：</p><ul><li>任意 Hadoop 设置可以通过 <code>spark.hadoop.key=value</code> 形式添加。</li><li><code>spark.jars</code>：指定要部署到 Spark driver 和 executor，并包含在 classpath 中的 JAR 文件。</li></ul><pre><code>spark.hadoop.fs.jfs.impl io.juicefs.JuiceFileSystem    
spark.hadoop.fs.AbstractFileSystem.jfs.impl io.juicefs.JuiceFS    
spark.hadoop.juicefs.meta redis://:password@addr    
spark.hadoop.juicefs.umask 000    
spark.hadoop.juicefs.push-remote-write http://host:port    
spark.hadoop.juicefs.push-remote-write-auth username:password    
spark.hadoop.juicefs.push-labels user:${env.USER};container_id:${env.CONTAINER_ID}    
spark.hadoop.juicefs.cache-size 102400    
spark.hadoop.juicefs.cache-dir ${env.PWD}/tmp    
spark.jars hdfs://juicefs/juicefs-hadoop/juicefs-hadoop-1.2.3.jar  </code></pre><h2>04 JuiceFS 改进事项</h2><p>JuiceFS 提供多种接口，支持跨平台的数据共享。例如，在 Hadoop 中使用 MapReduce 或 Spark 处理的数据存储到 JuiceFS 后，可以轻松在 Kubernetes 环境中访问和使用这些数据。</p><p>为使 NAVER 公共 Hadoop 和基于 Kubernetes 的 AI 平台顺畅共享数据，需要进行一些改进。（已经全部贡献到社区版。）</p><h3><a href="https://link.segmentfault.com/?enc=d1JOoc33y%2Br6LE%2F8jd1Bjw%3D%3D.ujsdlMYXoavvO3mH8UGXyWzcKsL7vxVhBci%2FzTNxvEEYOPwQK%2FBoBK9ejpoh3pSNP0tLvj9xtFAWk01XRX%2F4Mw%3D%3D" rel="nofollow" target="_blank">支持 all-squash 挂载</a>（#5394）</h3><p>NAVER 公共 Hadoop 与 LDAP 集成管理用户账户，因此 Hadoop 中创建的数据由相应用户的 LDAP UID 和 GID 所有。然而，在 Kubernetes 中，容器可以使用任意 UID 和 GID 运行，这可能导致访问 Hadoop 创建的数据时产生权限问题。</p><p>为了解决这个问题，我们增加了挂载选项 <code>--all-squash</code>。该选项使得访问挂载路径时，操作不会以当前账户的 UID 和 GID 进行，而是使用指定的 UID:GID。因此，设置 Hadoop 用户的 LDAP UID 和 GID 后，Kubernetes 中的容器可以无权限问题地访问数据。</p><h3><a href="https://link.segmentfault.com/?enc=qMK7n0tjDS2mSFvR2EdO3A%3D%3D.xuK9UyTKpDPUZ3gpMhrTFP25Q4xzbfCzFeVBIlCaza6I1O1NAdufgvVKcURP56zGAFE7EOzl%2FH9XR3YwF8DnhQ%3D%3D" rel="nofollow" target="_blank">改进 juicefs.users 和 juicefs.group 设置方式</a>（#4723）</h3><p>如前所述，在 Hadoop 集群中执行任务时，数据归 Hadoop 用户的 LDAP UID 和 GID 所有。但在 Hadoop 集群外部使用 Hadoop SDK 时，数据归任意 UID 和 GID 所有。例如，在 Docker 容器中使用 HDFS 命令存储数据时，所有者为容器内部账户的 UID 和 GID。</p><p>为了解决这个问题，用户需要通过 <code>juicefs.users</code> 和 <code>juicefs.groups</code> 设置指定所需的 UID 和 GID。之前，这要求用户编写 <code>&lt;用户名&gt;:&lt;UID&gt;</code> 和 <code>&lt;组名&gt;:&lt;GID&gt;</code> 格式的文件，并设置文件路径，这个过程非常繁琐。现在，我们增加了直接通过配置值来指定 UID 和 GID 的功能，简化了操作。</p><h3><a href="https://link.segmentfault.com/?enc=iaut5Bt7DReZMpFHfOk%2Fxw%3D%3D.q1f7QwGfmlTvEgCneGyY1d0yI2FoLpkYiEO3ltJ4E1pJE52F%2BYVhOTVbyJ0zZGR6wHp1uZaGr78QE1Sr0eObHg%3D%3D" rel="nofollow" target="_blank">支持 subdir</a>（#6096）</h3><p>在基于 Kubernetes 的 AI 平台中，JuiceFS 以动态供应方式使用。创建 PersistentVolumeClaim（PVC）时，会在 JuiceFS 文件系统内生成与该卷对应的子目录。若要在 Hadoop 中共享该 PVC，需仅安全地共享该卷对应的目录。</p><p>然而，Hadoop SDK 并不提供类似 <code>--subdir</code> 的挂载选项，无法限制 Hadoop 仅访问 JuiceFS 的特定子路径。为了解决这个问题，我们在 Hadoop SDK 中增加了 <code>juicefs.subdir</code> 设置，使用此设置可以限制仅访问指定路径。</p><h3><a href="https://link.segmentfault.com/?enc=flmOvCj8eRbqDDwZLVw6rg%3D%3D.dpMJAXNvEHzXIy8%2FAp1uIqvBv8mtVyh%2B1p4YXICrB3FH0HP2qarRrR0KAkIqKNSYTblZZglE3jcZLfKUeKhttw%3D%3D" rel="nofollow" target="_blank">通过 hdfs 命令查看配额</a>（#5937）</h3><p>JuiceFS 可以为整个文件系统或特定目录设置配额。在 Kubernetes 中，PVC 的 <code>spec.resources.requests.storage</code> 值将设置为该目录的配额。</p><p>在 Hadoop 与 PVC 共享时，也需要查看配额信息。然而，原有的 HDFS 命令 <code>hdfs dfs -count -q</code> 无法查看 JuiceFS 的配额。为了解决这个问题，我们对该功能进行了改进，现在可以通过相同的命令查看 JuiceFS 的配额信息。</p><h3><a href="https://link.segmentfault.com/?enc=KSY0xcK%2Bp919VkwquZIF%2Bw%3D%3D.iHJ%2B2mAQeOSw3EqB%2BwPjYENFDZ6DHs9a7I0FdfUKHIPuP8HUF%2Fa9RWYnnUiomqPVSRvXEMHjra0aGSqdFgHNhA%3D%3D" rel="nofollow" target="_blank">支持 Prometheus remote_write 协议</a>（#6295）</h3><p>使用 JuiceFS Hadoop SDK 时，可以将指标发送到 Pushgateway 和 Graphite。但 Pushgateway 需要定期清理指标，且 Graphite 格式独特，使用起来较为困难。</p><p>许多系统支持 Prometheus <code>remote_write</code> 协议。为了解决这个问题，我们在 JuiceFS 中增加了通过该协议发送指标的功能。通过 <code>juicefs.push-remote-write</code> 和 <code>juicefs.push-remote-write-auth</code> 设置，用户可以指定 VictoriaMetrics  <code>vmagent</code> 或 Prometheus。这一功能不仅整合了跨平台数据，还能整合监控系统。</p><h2>05 JuiceFS 的优势</h2><h3>优势 1：通过并行处理和缓存克服对象存储的性能瓶颈</h3><p>JuiceFS 需要通过网络与远程对象存储交换数据块，因此在性能上难以超越具有数据本地性优势的 HDFS。<strong>然而，通过将数据分块并行处理以及缓存已读取数据，可以克服这一性能瓶颈</strong>。我们通过性能测试验证了 HDFS 和 JuiceFS 在不同场景下的表现。</p><h4>DFSIO</h4><p>使用 10 个 map task，针对 100GB 文件测量 HDFS 和 JuiceFS 的顺序数据写入和读取的吞吐量。数值越高性能越好。为适应顺序写入/读取，将 JuiceFS 的块大小设为 16MB。</p><ul><li>写入：JuiceFS 的吞吐量是 HDFS 的 1.7 倍。这是因为数据被分割成小块并行上传。</li><li>读取：JuiceFS 的吞吐量是 HDFS 的 0.75 倍。但如果数据已缓存，预期性能与 HDFS 相似。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607253" alt="" title="" loading="lazy"/></p><h4>TPC-DS</h4><p>使用 Spark SQL 测量对存储在 HDFS 和 JuiceFS 的 100GB 规模表的查询响应时间。数值越低性能越好。</p><ul><li>JuiceFS 的响应时间是 HDFS 的 1.8 倍，这是由于数据本地性差异所致。</li><li>已缓存的 JuiceFS 表现出与 HDFS 相似的性能。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607254" alt="" title="" loading="lazy"/></p><h3>优势 2：与 HDFS 完全兼容，无需修改现有 Hadoop 应用即可使用</h3><p>NAVER 拥有稳定运营的公共 Hadoop 集群，运行着多种服务的 Hadoop 应用。如果仅将不常用的数据存储在对象存储中以降低存储成本，可能会出现问题。正如前所述，对象存储不是文件系统，无法保证现有 Hadoop 应用的性能和运行。为此，需要重写代码或检查数据处理引擎是否支持对象存储。此外，还需根据存储类型单独运行和管理 Hadoop 应用，增加了管理负担。</p><p>与之相反，使用 JuiceFS 可以保持现有 Hadoop 应用不变。用户只需将输入输出路径指定为 <code>hdfs://</code> 或 <code>jfs://</code>，即可以相同方式运行应用。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607255" alt="" title="" loading="lazy"/></p><p>HDFS 基于数据本地性保证高性能，而对象存储则在低成本和扩展性方面具有优势。两者各有所长，难以完全替代，需要根据需求选择。使用 JuiceFS 可以在不修改现有 Hadoop 应用的情况下，同时利用 HDFS 和对象存储的优势。</p><h3>优势 3：支持多种接口，可作为跨平台集成存储</h3><p>NAVER 使用多种平台进行服务开发和运营。例如，在开发/运营 AI 服务时，需要在数据处理平台中清洗数据，在 AI 平台中训练模型，并通过容器平台提供服务。</p><p>在 NAVER，各个平台提供独立的存储，平台内部易于使用，但难以访问其他平台的存储。不同平台的存储隔离导致了数据孤岛现象，并容易造成数据重复和资源浪费。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607256" alt="" title="" loading="lazy"/></p><p>JuiceFS 不仅支持 HDFS，还完美兼容 POSIX 和 Kubernetes CSI 驱动，适合作为跨平台的集成存储。通过在多个平台间顺畅使用 JuiceFS 共享数据，可大幅提升 AI 服务开发效率，实现数据统一管理。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607257" alt="" title="" loading="lazy"/></p><h2>06 结语</h2><p>本文探讨了 JuiceFS 在 Hadoop 环境中的使用方法及其优势，而在部分业务场景下，直接采用 HDFS 或对象存储会是更适配的选择。例如，当业务需要依托数据本地性实现高效快速处理时，建议将数据存储于 HDFS 中；此外，针对访问频率较低的数据，或采用 Iceberg 等专为对象存储优化的数据格式时，直接使用对象存储则更为简便。</p><p>而在以下场景中，JuiceFS 会是更优选择：</p><ol><li>需在 Kubernetes 与 Hadoop 环境之间实现数据共享时；</li><li>希望在不修改现有 Hadoop 应用代码的前提下，与 HDFS 并行部署使用时；</li><li>处理存在重复读取行为、可通过缓存显著提升效率的数据作业时；</li><li>业务所用 S3 API 无法被底层 S3 兼容存储良好支持时。</li></ol><p>本文介绍了在 NAVER 内部本地环境中的应用案例，但在 AWS、Google Cloud 等公有云环境中同样适用。希望对有类似困扰的读者有所帮助。</p>]]></description></item><item>    <title><![CDATA[全链路Token智控，「秒云Tokens管家」解锁AI工程优化新范式 MIAOYUN ]]></title>    <link>https://segmentfault.com/a/1190000047607262</link>    <guid>https://segmentfault.com/a/1190000047607262</guid>    <pubDate>2026-02-12 12:01:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>当AI技术加速走向产业化，企业在推进AI工程化落地的过程中，常面临API选型难、Token消耗贵、效果不透明、质量不可控等核心痛点。为此，MIAOYUN基于多年在云原生与智能运维领域的技术沉淀，<strong>以“一站式可观测大模型API智能网关”为核心切入点，推出「秒云Tokens管家」，聚焦API聚合与Token全生命周期观测两大核心能力</strong>，致力于帮助客户精准匹配适配度高、成本更可控的Token方案，打造更好用的AI服务市场，实现API调用成本与效果清晰可控，效率提升、持续优化，助力企业跨越AI落地痛点。</p><h2><strong>行业痛点-企业大模型API调用的核心困境</strong></h2><p>在AI产业深度推进的当下，Token已成为新一代云计算核心资源，更是企业大模型应用中直接产生成本的数字原料。当前企业在调用大模型API过程中，普遍面临三重突出困境，严重阻碍AI工程化落地效能：</p><p><strong>►  API选型难</strong>：大模型种类繁多，各API规范不一、调用门槛、性能表现差异较大，开发者调研适配耗时久，难以快速找到适配业务的最优方案，盲目选型还易增加适配和试错成本。</p><p><strong>►  Token消耗贵</strong>：多数平台采用输入输出双向计费模式，高频调用与上下文场景下Token开销快，缺乏有效管控机制，易造成资源浪费，导致消耗失控，AI投入成本高且产出比（ROI）难以核算。</p><p><strong>►  效果不透明</strong>：API调用的响应速度、准确率、适配度等效果缺乏量化监测与追溯手段，无法追溯效果波动原因，难以定位根源、优化调整，影响AI应用的实际成效与成本价值对齐。</p><h2><strong>「秒云Tokens管家」-全链路管控企业AI Token成本与效能</strong></h2><p>「秒云Tokens管家」聚焦企业AI服务场景，打破传统API调用“分散管理、效果难控、成本失衡”及Token单价高、消耗大等核心痛点，<strong>以API聚合调用与Token全链路可观测两大核心能力为支柱，为企业提供一站式调用与精细化Token管理服务</strong>，二者相辅相成、协同发力，助力企业精准选型、高效调用API，最终筛选出更贴合自身业务需求、兼顾性能与成本的Token方案。</p><p>★<strong>聚合-一键调用所有主流模型</strong></p><p>在API聚合调用方面，「秒云Tokens管家」依托「秒云AI算力运营平台」的技术积淀，深度聚合国内主流闭源与开源大模型API服务，涵盖DeepSeek、Doubao、Kimi、Qwen、GLM等国产优质模型，全面覆盖语音识别、代码生成、多模态处理等多样化场景需求。<strong>平台实现“一次接入，统一鉴权”机制，开发者只需获取一个“LLM API Key”，即可一键调用平台所有聚合模型</strong>，企业无需繁琐对接多个供应商、学习差异化开发规范，无需修改原有代码，大幅降低对接成本与开发复杂度，彻底解决多模型混用调试难、切换成本高的行业痛点。</p><p>★<strong>观测-全链路Token监控</strong></p><p>在Token可观测方面，产品构建了全链路可观测体系，依托多维度评测指标（含调用响应速度、成功率、Token消耗等），实现Token消耗的实时监测、数据可视化及全生命周期追溯，企业可直观查看Token消耗细节、成本结构与异常情况，精准定位“高消耗、低产出”的调用场景，实现Token管控从被动应对向主动掌控的转变。</p><p>聚合与观测能力的深度融合，构成了「秒云Tokens管家」的核心竞争力：<strong>通过API聚合打破调用壁垒，为Token观测提供了统一的数据采集基础；通过Token可观测获取精准的调用效果与消耗数据，反过来为API聚合调用的优化、供应商选型提供科学依据。</strong> 在此基础上，产品进一步延伸出Token精细化管控、消耗优化及生态闭环构建等能力，可按多维度分配Token配额、推送消耗预警，通过智能匹配模型、缓存复用等方式降低无效消耗，最终帮助企业实现AI Token成本可控、效能最大化，成为企业AI支出的“智能守门人”。</p><h2><strong>「秒云Tokens管家」-核心功能与使用场景</strong></h2><p><strong>★核心功能</strong></p><p><strong>►  多模型API统一接入</strong>：支持主流大模型与云服务API快速接入，实现统一认证、计费与全流程管理，降低对接复杂度。</p><p><strong>►  服务质量指标可视化</strong>：提供响应延迟、调用成功率、输出准确性、成本消耗等多维度实时看板，实现状态一目了然。</p><p><strong>►  调用效果评测与分析</strong>：支持用户自定义评测指标，通过交互式报表对比不同模型、不同参数下的调用表现，支撑科学决策。</p><p><strong>►  智能告警与优化建议</strong>：基于阈值与异常检测算法，及时推送服务质量波动提醒，并提供针对性调优建议，降低运维成本。</p><p>★<strong>适用场景</strong></p><ul><li><strong>企业AI应用开发：</strong> 需快速集成多种AI能力，同时确保服务可用性与效果稳定性。</li><li><strong>模型选型与评估：</strong> 希望横向对比不同大模型在实际场景中的表现，为技术选型提供数据支撑。</li><li><strong>API服务质量治理：</strong> 需要对内外部API调用进行统一监控、成本分析与性能优化，提升管理效率。</li></ul><p>未来，MIAOYUN将持续整合公司现有核心技术，把API聚合、智能调度与Token管控能力、运维优化深度融合，打造“API调用+Token管控+质量监测+成本优化”的一站式服务闭环。同时，将持续适配更多主流大模型，解决不同厂商API格式碎片化、Token计数方式各异的痛点，让企业在无需修改代码的前提下，实现多模型一键调用与Token统一管控，进一步降低企业AI落地成本与管理复杂度，让「秒云Tokens管家」成为企业AI工程化落地的必备工具。</p>]]></description></item><item>    <title><![CDATA[给 Claude 装个仪表盘，时刻监测Token消耗跟任务进度 BugShare ]]></title>    <link>https://segmentfault.com/a/1190000047606908</link>    <guid>https://segmentfault.com/a/1190000047606908</guid>    <pubDate>2026-02-12 11:07:12</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>最近，Anthropic 推出的命令行工具 <strong>Claude Code</strong> 简直火得一塌糊涂。很多程序员朋友都说，那种在终端里直接指挥 AI 改代码、跑测试的感觉，确实比网页端反复“复制粘贴”要爽得多。</p><p>但用久了，大家普遍发现一个痛点：<strong>“看不见”</strong>。</p><p>你不知道 Claude 现在到底处理了多少 Token，不知道它背地里偷偷读了多少文件，更不知道它那个“大脑”任务列表进行到哪一步了。</p><p>这种感觉就像开夜车没仪表盘，心里总有点没底。</p><p>直到我发现了 <strong>Claude HUD</strong>（作者：Jarrod Watts）。它给 Claude Code 穿上了一层“外骨架”，让它从一个简单的黑框对话框，瞬间变成了科幻感十足的<strong>开发者工作站</strong>。</p><p>今天，咱们就聊聊这个让无数极客直呼“真香”的神器。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047606911" alt="claude-hud-preview-5-2.png" title="claude-hud-preview-5-2.png"/></p><hr/><h2>一、 什么是 Claude HUD？</h2><p>HUD 原意是“平视显示器”，通常出现在战斗机飞行员的头盔或高端汽车的挡风玻璃上。</p><p><strong>Claude HUD</strong> 干的也是这件事。它是一个专门为 Claude Code 设计的插件，会在你的终端底部常驻一个<strong>状态栏</strong>。</p><p>有了它，你不再需要通过翻看长长的聊天记录去确认进度。它把 Claude 的运行状态、Token 消耗、正在使用的工具、甚至当前的 Git 分支，全都浓缩在屏幕最下方。</p><p><strong>一句话总结：它让 Claude 从一个“黑盒”，变成了一个“透明盒”。</strong></p><hr/><h2>二、 为什么它比原版好用？</h2><p>如果你还在犹豫要不要装，看这三个功能就够了：</p><ol><li><strong>Context 进度条（防“宕机”神器）</strong><br/>Claude 虽然强，但上下文（Context Window）是有上限的。很多时候聊着聊着，AI 开始胡言乱语，往往是因为 Token 满了。<br/>HUD 直接在底部给你一个<strong>电量条一样的视觉反馈</strong>。看到变红了？赶紧重启会话或者清理上下文，再也不用盲目猜测。</li><li><strong>实时“动作监控”</strong><br/>当 Claude 在执行复杂任务（比如重构整个文件夹）时，它会频繁调用 <code>read_file</code>、<code>grep</code>、<code>edit_file</code> 等工具。<br/>在 HUD 里，你可以看到这些动作像流水灯一样闪过。它在读哪行代码？改了哪个文件？你一眼就能掌握全局，这种<strong>掌控感</strong>对开发者来说太重要了。</li><li><strong>任务进度（Todo List）可视化</strong><br/>给 Claude 下达一个大任务时，它会自动拆解成好几个步骤。HUD 会把这些步骤实时显示出来：<br/><code>▸ Fix auth bug (2/5)</code><br/>这就好比进度条，让你知道它现在是卡住了，还是正在稳步推进。</li></ol><hr/><h2>三、 手把手安装教程（三步搞定）</h2><p>安装过程非常顺滑，前提是你已经安装了 <code>claude-code</code>。</p><h3>第一步：添加插件市场</h3><p>在你的 Claude 会话中输入：</p><pre><code class="bash"># 这一步可能需要FQ
/plugin marketplace add jarrodwatts/claude-hud</code></pre><h3>第二步：安装插件</h3><p>接着输入：</p><pre><code class="bash">/plugin install claude-hud</code></pre><p><em>（Linux 用户如果遇到报错，记得先设置一下临时目录权限，官方文档里有贴心提示）</em></p><pre><code class="bash">#⚠️ 在 Linux 系统中，/tmp通常会使用单独的文件系统 (tmpfs)，这会导致插件安装失败，并出现以下错误：
#EXDEV: cross-device link not permitted
#解决方法：安装前设置 TMPDIR：
mkdir -p ~/.cache/tmp &amp;&amp; TMPDIR=~/.cache/tmp claude</code></pre><h3>第三步：初始化配置</h3><p>运行设置命令：</p><pre><code class="bash">/claude-hud:setup
# 执行后可以不进行额外配置（按ESC键取消），后续再配置</code></pre><p>搞定！你会发现终端底部立刻亮起了一排整齐的状态栏，帅气程度瞬间提升几个档次。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047606912" alt="image-20260211162341964.png" title="image-20260211162341964.png" loading="lazy"/></p><hr/><h2>四、你的仪表盘，你说了算！</h2><p>很多插件装完就那样了，但 Claude HUD 最骚的地方在于它的<strong>高度自定义</strong>。你只需要在 Claude 会话中输入一行神奇的命令：</p><pre><code class="bash">/claude-hud:configure</code></pre><p>输入这个命令后，你会进入一个“图形化”的配置菜单（就在终端里），完全不需要你去手改代码或 JSON 文件。</p><h3>1. 选择喜欢的“装修风格”</h3><ul><li><strong>Full（全能模式）：</strong> 所有的信息全开，适合那种喜欢“掌控一切”的硬核玩家。</li><li><strong>Essential（极简模式）：</strong> 只保留最核心的活动状态和 Git 信息，清爽不打扰。</li><li><strong>Minimal（迷你模式）：</strong> 只有一个窄窄的 Model 名称和 Token 条，存在感极低。</li></ul><pre><code class="bash"># 默认值（2 行）
[Opus | Max] │ my-project git:(main*)
Context █████░░░░░ 45% │ Usage ██░░░░░░░░ 25% (1h 30m / 5h)
# 第 1 行— 模型、计划名称（或Bedrock）、项目路径、Git 分支
# 第 2 行— 上下文栏（绿色 → 黄色 → 红色）和使用速率限制

# 可选行（通过以下方式启用/claude-hud:configure）
◐ Edit: auth.ts | ✓ Read ×3 | ✓ Grep ×2        ← Tools activity
◐ explore [haiku]: Finding auth code (2m 15s)    ← Agent status
▸ Fix authentication bug (2/5)                   ← Todo progress</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047606913" alt="PixPin_2026-02-11_16-26-36.png" title="PixPin_2026-02-11_16-26-36.png" loading="lazy"/></p><h3>2. 细节控的福音</h3><p>您也可以直接在以下位置编辑配置文件<code>~/.claude/plugins/claude-hud/config.json</code>：</p><ul><li><strong>想看 Git 变动？</strong> 开启 <code>showFileStats</code>，连改了几个文件、删了几行都能直接看到。</li><li><strong>嫌路径太长占地方？</strong> 调一下 <code>pathLevels</code>，只显示最后 1-2 级目录。</li><li><strong>想监控 Token 消耗？</strong> 开启 <code>showUsage</code>，实时盯着你的 Pro/Max 会员限额还剩多少。</li></ul><p><strong>配置完后，甚至不需要重启，仪表盘会根据你的选择实时变幻，这种丝滑感真的会上瘾。</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047606914" alt="PixPin_2026-02-11_16-12-24.png" title="PixPin_2026-02-11_16-12-24.png" loading="lazy"/></p><hr/><h2>五、 真实使用场景：它能帮你省多少事？</h2><ul><li><strong>场景 A：大规模重构代码</strong><br/>当你让 AI 把一个旧项目的 CommonJS 全改成 ESM 时，你会看到 HUD 上的“工具活动”疯狂跳动。如果它读了不该读的 <code>.env</code> 或备份文件，你可以立刻中断，修正指令，避免浪费 Token 和时间。</li><li><strong>场景 B：深陷 Debug 泥潭</strong><br/>当你和 Claude 缠斗了半小时还没修好 Bug 时，看一眼 HUD 的 <strong>Context Health</strong>。如果进度条已经 90% 了，说明对话太长，AI 已经变笨了。这时候果断 <code>/clear</code>，重新开始，往往能秒解。</li><li><strong>场景 C：多任务并行</strong><br/>如果你同时在几个分支上反复横跳，HUD 的 <strong>Git Status</strong> 功能会提醒你当前在哪。配合它显示的 <code>pathLevels</code>，你绝不会在复杂的 Monorepo（大仓库）里迷路。</li></ul><hr/><h2>写在最后</h2><p>在这个 AI 辅助开发的时代，工具的边界就是你能力的边界。</p><p>Claude HUD 并不是改变了 Claude 的智商，它改变的是<strong>你与 AI 协作的交互体验</strong>。从“被动等待结果”到“主动监控过程”，这种转变带来的不仅是效率的提升，更是心智负担的减轻。</p><p>如果你已经用上了 Claude Code，听我一句劝：<strong>这个 HUD 插件，必须安排上！</strong></p><p><strong>如果您觉得这篇文章有帮助，欢迎点赞、转发，让更多小伙伴告别“盲打”时代！）</strong></p>]]></description></item><item>    <title><![CDATA[有奖活动丨首套语音 AI 盲盒邀你来拆！对话式 AI「黑话」周边空降，谁能看懂这些梗？ RTE开发者]]></title>    <link>https://segmentfault.com/a/1190000047606919</link>    <guid>https://segmentfault.com/a/1190000047606919</guid>    <pubDate>2026-02-12 11:06:33</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047606921" alt="" title=""/></p><p>各位 RTE 开发者社区的小伙伴们，这一年，我们聊 ASR、TTS、LLM，在 TEN Framework 的各种模块里反复跳跃。在代码世界里，我们习惯了将 ASR、TTS、LLM 像积木一样拼装成强大的 Voice Agent。</p><p>最近，社区偷偷搞了一件大事，我们把这些「模块」给实体化做成了新春周边盲盒大礼包（你就说这些够不够 Physical 吧？），这不只是一份新年礼包，更是一次 Voice Agent 社区内部的暗号对接。</p><p>快来猜猜里面都有些什么吧～只要你的脑洞够大或者直觉够准，这整套诚意满满的新春周边大礼包，我们就包邮送到家！</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047606922" alt="" title="" loading="lazy"/></p><p>礼包贺卡写着一段开发者会秒懂的真诚祝愿。</p><h2>🚨深度剧透：这盒子里到底装了啥？</h2><p>看到这个充满科技感的「九宫格」了吗？每一个缩写方盒里，都藏着一件根据「技术梗」定制的实体物件。</p><p>在这里：</p><ul><li><strong>TTS</strong> 不负责合成，只负责让你<strong>入睡</strong>。</li><li><strong>VAD</strong> 不检测语音，只负责让你<strong>清静</strong>。</li><li><strong>S2S</strong> 依然是全场最贵，贵到我们<strong>只能送你一个～</strong>。</li></ul><p>为了让大家更好地发挥脑洞，我们先来打个样！</p><p><strong>WebSocket </strong>➡<strong> WebSock<del>et</del>s</strong></p><p>盒内真身： 袜子（socks）</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047606923" alt="" title="" loading="lazy"/></p><p><strong>TTS ➡</strong> Time to Sleep 语音合成再忙，也要准时入眠</p><p>盒内真身： 睡眠真丝眼罩</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047606924" alt="" title="" loading="lazy"/></p><p><strong>零丢包包 ➡</strong> 不仅是致敬「沈阳站站」的趣味梗，更是对 Voice Agent 稳定交互的终极祝福</p><p>真身：镭射透明包</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047606925" alt="" title="" loading="lazy"/></p><p>剩下的 7 个盒子，就看大家的「梗力值」了！</p><h2>👇请听题，猜猜都是什么东西？（谜面在此）：</h2><ol><li><strong>RTC：</strong> Roast the Coffee（会有什么好物？)</li><li><strong>TEN：</strong> Take a SIP（它是 TEN 的拓展能力，也是某种闲适状态？)</li><li><strong>VAD：</strong> Very Anti Dialogue（如果想屏蔽一切对话，你需要什么？)</li><li><strong>S2S：</strong> 某样「太贵了简直买不起」的神秘之物</li><li><strong>STT：</strong> Stick to Task（来自獭獭的职场叮嘱）</li><li><strong>TTD：</strong> Time to Drink（除了酒，还能是什么？)</li><li><strong>LLM：</strong> Long Last Mint（这个提示够明显了吧？)</li></ol><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047606926" alt="" title="" loading="lazy"/></p><h2>🎁怎么玩？（奖品超厚！)</h2><p><strong>1-7 号分别都代表什么物品？</strong> 请在公众号【RTE开发者社区】本文下方评论区留下你的脑洞，我们将送出 <strong>9 套</strong> 价值不菲的新春周边盲盒大礼包！</p><ul><li><strong>【神算奖 x 3】</strong> 猜得最准、最快的技术锦鲤。</li><li><strong>【脑洞奖 x 3】</strong> 虽然你猜错了，但我觉得你说的比我们做的更有趣！</li><li><strong>【阳光普照奖 x 3】</strong> 不想动脑子？只要留言送上纯粹的新年祝福，我们随机抽人「送福气」！</li></ul><h2>⏳活动须知</h2><ul><li><strong>活动时间：</strong> 即日起至春节假期结束。</li><li><strong>揭晓方式：</strong> 年后返工第一天（2 月 24 日）置顶评论区见！</li><li><strong>参与方式：</strong> 关注【RTE开发者社区】公众号，在本文下方评论区留言即可。</li></ul><p>新的一年，愿大家的 Agent 永远不丢包。快去评论区开猜吧！👇</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047606927" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047606928" alt="" title="" loading="lazy"/></p><p><a href="https://link.segmentfault.com/?enc=pI0AP2baISPxq2iSrwMntw%3D%3D.cBoTf1gU6YJ2w8dwRoRR5SQBmFFxbSjZ6Ox2SClJVgU%3D" rel="nofollow" target="_blank">阅读更多 Voice Agent 学习笔记：了解最懂 AI 语音的头脑都在思考什么</a></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047606929" alt="" title="" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[[Python] 玩转金融API：WebSocket客户端的封装与异常处理实战 EmilyLi ]]></title>    <link>https://segmentfault.com/a/1190000047606967</link>    <guid>https://segmentfault.com/a/1190000047606967</guid>    <pubDate>2026-02-12 11:05:59</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在开发金融数据采集器或交易机器人时，WebSocket 是绕不开的技术栈。今天想通过一个外汇行情接入的实战案例，和大家深入聊聊 Python 客户端的设计模式与避坑指南。</p><p>一、 技术背景与选型 外汇市场（Forex）具有数据量大（High Volume）、更新频次高（High Frequency）的特点。使用 Python 的 websocket-client 库可以快速搭建客户端，但要做到“生产级稳定”，光会写 ws.run_forever() 是远远不够的。 我们需要解决以下工程问题：</p><p>网络不稳定：如何实现优雅的断线重连？</p><p>粘包与拆包：虽然 WebSocket 协议层面解决了 TCP 的粘包问题，但在逻辑层，我们需要处理 JSON 解析的异常。</p><p>阻塞问题：WebSocket 的接收线程不能阻塞主线程的业务逻辑。</p><p>二、 客户端设计模式 下面的代码展示了一个标准的“订阅-接收”模型。 我们在 on_open 回调中发送鉴权 Token 和订阅指令（Payload），在 on_message 中处理异步推送的数据。这里参考了 AllTick API 的参数设计，其文档中关于 Command ID 和 Sequence ID 的设计是典型的金融协议风格。</p><p>完整代码实现</p><pre><code>import json
import websocket

# 请将下面的 testtoken 替换为你自己的 API Token
WS_URL = "wss://quote.alltick.co/quote-b-ws-api?token=testtoken"

def on_message(ws, message):
    """
    收到行情推送后的回调函数
    """
    data = json.loads(message)
    # 推送消息中通常包含 symbol, price 等字段
    print(f"[行情推送] {data.get('symbol')} 最新价格：{data.get('price')}")

def on_open(ws):
    """
    WebSocket 连接建立后执行订阅
    """
    print("[WebSocket 已连接]")
    # 构造订阅请求
    # cmd_id/seq_id/trace/data 等字段可根据具体文档调整
    subscribe_request = {
        "cmd_id": 22002,
        "seq_id": 1,
        "trace": "subscribe_forex_001",
        "data": {
            "symbol_list": [
                {"code": "EURUSD"},
                {"code": "USDJPY"},
                {"code": "GBPUSD"}
            ]
        }
    }
    ws.send(json.dumps(subscribe_request))

# 创建 WebSocket 应用
ws_app = websocket.WebSocketApp(
    WS_URL,
    on_open=on_open,
    on_message=on_message
)

# 开始运行
ws_app.run_forever()</code></pre><p>三、 进阶：数据流的下游处理 为了演示数据的可用性，我们结合 pandas 将接收到的 JSON 转换为 DataFrame。 这里有一个性能优化的小技巧：不要每来一条数据就创建一个 DataFrame，因为创建对象的开销很大。建议使用一个 list 暂存数据，每积累 100 条或者每隔 1 秒，再批量转换为 DataFrame 进行分析。</p><pre><code>import pandas as pd

# 假设有一批 tick 数据
tick_samples = [
    {"symbol":"EURUSD", "price":1.1035, "timestamp":1670001234},
    {"symbol":"EURUSD", "price":1.1037, "timestamp":1670001240},
]

df = pd.DataFrame(tick_samples)
df["datetime"] = pd.to_datetime(df["timestamp"], unit="s")
print(df)
</code></pre><p>四、 避坑指南（经验之谈）</p><p>Keep-Alive 心跳：很多新手代码跑着跑着就断了，没有任何报错。这往往是因为没有处理 Ping/Pong 心跳，被防火墙或负载均衡器（LB）判定为死连接而切断。务必在 run_forever 中配置 ping_interval 和 ping_timeout。</p><p>SSL 证书验证：在某些内网或测试环境下，如果遇到 SSL 报错，可能需要设置 sslopt={"cert_reqs": ssl.CERT_NONE}，但在生产环境请务必开启验证。</p><p>异常捕获：在 on_message 里一定要加 try...except。因为金融数据偶尔会出现格式错误或缺失字段，如果这里抛出未捕获的异常，整个连接都会断开，导致程序崩溃。</p><p>掌握这些细节，你的爬虫和数据采集程序才算真正入门了金融工程领域。<br/><img width="723" height="408" referrerpolicy="no-referrer" src="/img/bVdnUT8" alt="" title=""/></p>]]></description></item><item>    <title><![CDATA[堆内存对象的Managed Size具体是如何计算的 侑虎科技 ]]></title>    <link>https://segmentfault.com/a/1190000047606971</link>    <guid>https://segmentfault.com/a/1190000047606971</guid>    <pubDate>2026-02-12 11:05:03</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>1）堆内存对象的Managed Size具体是如何计算的<br/>2）微信小游戏项目，跑图过程场景加载比较慢如何优化</p><hr/><p>这是第464篇UWA技术知识分享的推送，精选了UWA社区的热门话题，涵盖了UWA问答、社区帖子等技术知识点，助力大家更全面地掌握和学习。</p><p>UWA社区主页：<a href="https://link.segmentfault.com/?enc=eZzd1RGnQcYLpvMEvFRepA%3D%3D.nMlWEbEdeJecCMNUu8kB0l3f1Zn50WvEU3DFmVEcvpw%3D" rel="nofollow" target="_blank">community.uwa4d.com</a><br/>UWA QQ群：793972859</p><p><strong>From 问答社区</strong></p><p><strong>Q：在Memory Profiler观察到一个长度为9的字符串对象Managed Size为40B，显然不止每个字符2字节。请问这个应该是怎么算的？</strong><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047606973" alt="" title=""/></p><blockquote><p>A：堆内存对象的Managed Size可以认为是以下四个部分：</p><ol><li>类型对象指针；</li><li>同步块索引；</li><li>专属属性（比如数组和String就有一个int32 length 4B）；</li><li>实例字段。</li></ol><p>针对每种对象这四个部分可能都有不同，最好的办法就是直接看下源码里这个类的构造。比如String：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047606974" alt="" title="" loading="lazy"/></p><p>它就是8 (*monotor) + 8(union) + 4(length) + 2( N+1(\0) )，特殊之处就是多了个\0，相当于长度要算N+1。所以总共是22+2*N字节。</p><p>其中为什么每个对象都要额外分配类型对象指针和同步块索引，导致一定的基础占用，原理上可以参考一些官方文档或者社区文章。<br/><a href="https://link.segmentfault.com/?enc=e9DH3LeXUII5FnhaSlIJew%3D%3D.U8ILyMMoePq0gQ3gzhEkRWsdYD0qT2oQVZzEgJGyLQsDg5WB%2BjxurloZz%2FESXlbBwebX4ETs4sL9o8L7ktY%2BQF4KVk93vC8lRDaILzrV7k5hOMBRopd98qD5vAXt4IPUdTwb99qpiwBzc6swNNjOKmKHBROdtvpENhls4alOoDg%3D" rel="nofollow" target="_blank">《.NET 框架内部结构：CLR 如何创建运行时对象 |Microsoft Learn》</a></p></blockquote><p><strong>欢迎大家转至社区交流：</strong><br/><a href="https://link.segmentfault.com/?enc=ymrJhjuFG%2Fr6jD%2BR%2FXqVNg%3D%3D.2CK%2F2i86JB%2FMtkBEiNfYKY5dKT1e2IuZ18n8iavzbvev2YhDBrqzfUHwXx%2FkVn4XYzohe1uuYbVFu80xaa1yCQ%3D%3D" rel="nofollow" target="_blank"/><a href="https://link.segmentfault.com/?enc=LhLX7AJC53fp37FXohfKxQ%3D%3D.20voPiwYB3wK3%2FEv0%2BWY1C9vEv%2BenIzPbXmAFAprGJ0c8Jj4EcAOGVNhBg7esYoGeu7MqJ0QQC%2BU5Lw%2FHnyWhg%3D%3D" rel="nofollow" target="_blank">https://answer.uwa4d.com/question/69858fdcabed2e338a7dac5e</a></p><hr/><p><strong>From 问答社区</strong></p><p><strong>Q1：目前有个点比较陌生，就是小游戏的每秒资源后台最大同时下载数量，和下载文件大小的指标比较缺失， 这块会影响玩家跑图的过程中场景加载比较慢的问题。  请问有没有官方大数据指标？</strong></p><blockquote><p>A：官方说法是小游戏资源下载并发数为10，超过时底层自动排队；单个请求文件最大不超过100MB（理论最大值，但考虑到带宽，建议单文件2~5MB以内）。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047606975" alt="" title="" loading="lazy"/></p></blockquote><p><strong>Q2：由于我们是横屏地图，真机上持续控制角色移动10秒以上，停下后，附近场景资源下载大概要等10秒才加载完整。 大概200个资源，请问有什么解决的方法？</strong></p><blockquote>A：这种情况看起来是没有用WXAssetBundle的接口进行AssetBundle加载，一般更推荐用这个，而不是原生的AssetBundle加载接口。WXAssetBundle的加载接口会把网上下载的东西缓存到本地，下次直接从本地加载，而且这个接口会有自动卸载的功能，总体内存占用也会更小一些。其他的优化方法就是资源设置以及打包策略的问题了。</blockquote><p><strong>欢迎大家转至社区交流：</strong><br/><a href="https://link.segmentfault.com/?enc=EqMMcMHOQaCAdY7bHivu7A%3D%3D.3XSINDIwWI1n9a9zzLd2KbsgKGsXVOCH5inxVF%2FCdiNcS%2FLMOe2sFelR4N00tPm7uaJTffFO3FymJ1Ez%2BJZVuA%3D%3D" rel="nofollow" target="_blank"/><a href="https://link.segmentfault.com/?enc=L8xeT2CmCG%2B3MaR015pO0g%3D%3D.ndAW%2BJr%2B6flIqoBHc85KzT%2B%2F%2B7lGuHAljs6kkQuSjumvOODVaeFGguFcTo%2BBOjf2S4nMMo7CiMsX2rPlwnNMhw%3D%3D" rel="nofollow" target="_blank">https://answer.uwa4d.com/question/6985999eabed2e338a7dac60</a></p><p><strong>无论是社区里开发者们的互助讨论，还是AI基于知识沉淀的快速反馈，核心都是为了让每一个技术难题都有解、每一次踩坑都有回响。本期分享分别来自UWA AI问答和UWA问答社区，希望这些从真实开发场景中提炼的经验，能直接帮你解决当下的技术卡点，也让你在遇到同类问题时，能更高效地找到破局方向。</strong></p><p>封面图来源于网络</p><hr/><p>今天的分享就到这里。生有涯而知无涯，在漫漫的开发周期中，我们遇到的问题只是冰山一角，UWA社区愿伴你同行，一起探索分享。欢迎更多的开发者加入UWA社区。</p><p>UWA官网：<a href="https://link.segmentfault.com/?enc=eyPfAcjlAuQsPd%2F1zcVAPQ%3D%3D.PF660ov8qh%2Bpn5gE%2F1VCjGFklhoxuysZ6Hd2azjHf8E%3D" rel="nofollow" target="_blank">www.uwa4d.com</a><br/>UWA社区：<a href="https://link.segmentfault.com/?enc=ql59gmSkKwH9Rs%2FEZ2lFyg%3D%3D.XIAZ1i4Roryuj0pjinFkMzHCwSy5tQzCVKKbFTBm4zE%3D" rel="nofollow" target="_blank">community.uwa4d.com</a><br/>UWA学堂：<a href="https://link.segmentfault.com/?enc=pILlSppoiQW37V%2BamkLLbg%3D%3D.s2CNjzgrqbQwgwjwtGg8tvetSQPHNhNRKQ8QUJdY%2FDw%3D" rel="nofollow" target="_blank">edu.uwa4d.com</a><br/>官方技术QQ群：793972859</p>]]></description></item><item>    <title><![CDATA[Tavus 发布视听感知模型 Raven-1，捕捉用户语气、表情及语境；「雷格斯」获投数千万，探索「]]></title>    <link>https://segmentfault.com/a/1190000047606985</link>    <guid>https://segmentfault.com/a/1190000047606985</guid>    <pubDate>2026-02-12 11:04:32</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047606987" alt="" title=""/></p><p>开发者朋友们大家好：</p><p>这里是 <strong>「RTE 开发者日报」</strong>，每天和大家一起看新闻、聊八卦。我们的社区编辑团队会整理分享 RTE（Real-Time Engagement） 领域内「有话题的<strong>技术</strong>」、「有亮点的<strong>产品</strong>」、「有思考的<strong>文章</strong>」、「有态度的<strong>观点</strong>」、「有看点的<strong>活动</strong>」，但内容仅代表编辑的个人观点，欢迎大家留言、跟帖、讨论。</p><p><em>本期编辑：@瓒an、@鲍勃</em></p><h2>01 有话题的技术</h2><p><strong>1、Tavus 发布实时视听感知模型 Raven-1：能读懂讽刺与犹豫，赋予 AI 真实「情商」</strong></p><p><strong>Tavus 公司近日发布了专为实时 AI 打造的视听感知模型 Raven-1。</strong> 该模型旨在解决当前对话式 AI 仅能理解文字而无法感知人类真实意图的痛点。不同于依赖转录文本的传统系统，Raven-1 通过<strong>原生多模态感知系统</strong>，将音频、视觉和时间动态融合为统一的理解框架，从而捕捉用户说话时的语气、表情、犹豫及语境。</p><p>Raven-1 在前代产品 Raven-0 视觉理解的基础上，<strong>实现了音视频流的实时对齐</strong>。其核心能力包括：</p><ul><li><strong>视听融合</strong>：将语调、韵律、面部表情、姿势和注视方向整合为单一感知表征，能准确区分真诚的微笑与讽刺的假笑。</li><li><strong>句子级时间建模</strong>：追踪对话中的情绪和注意力演变，捕捉如挫败感累积或怀疑消退等细微叙事弧线。</li><li><strong>自然语言输出</strong>：生成可解释的自然语言描述而非离散标签，使下游 LLM 能直接理解复杂的情感状态。</li><li><strong>实时响应</strong>：总流水线延迟低于 600 毫秒，且上下文新鲜度（context freshness）保持在 300 毫秒以内，确保 AI 能在恰当时机做出反应。</li></ul><p>该系统还支持通过 OpenAI 兼容模式调用自定义工具，允许开发者定义特定事件（如大笑或注意力转移）以触发相应操作。在 Tavus 的技术栈中，Raven-1 与对话流程模型 Sparrow-1 及情感渲染系统 Phoenix-4 协同工作，形成「感知-响应」闭环，显著<strong>提升了对话的深度与自然度</strong>。</p><p>Raven-1 的应用前景广阔，特别是在医疗健康、教育培训及招聘面试等高风险场景中，它能帮助 AI 实时识别患者不适、学员参与度或求职者的非语言信号。目前，该模型已在 Tavus 平台上线。</p><p>Demo: </p><p><a href="https://link.segmentfault.com/?enc=fIHpXeBwH8oRLqb6QKco1w%3D%3D.xtgRoRdsJ0%2Fkb0jfuXGgp2iil2fHcZ%2BdtOH8YWnQqfM%3D" rel="nofollow" target="_blank">https://raven.tavuslabs.org/</a></p><p>Blog: </p><p><a href="https://link.segmentfault.com/?enc=VAjSYoW%2FL161pQIllkwhag%3D%3D.1%2FSajWyBc6Q5er0PUpJNwupSVfZlHGTXTWFv9xqLH%2BhJI1oDX6UxMNMO%2Bjr27hxrFwOIwvwyFwEirJWryc6OHZDLpvBDNW8RexW8NMhEBAZhxSNbhz32DvdTuUH2Hugh" rel="nofollow" target="_blank">https://www.tavus.io/post/raven-1-bringing-emotional-intellig...</a></p><p>( @tavus@X、@Tavus Blog)</p><p><strong>2、智谱新模型架构曝光：DeepSeek 同款稀疏注意力</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047606988" alt="" title="" loading="lazy"/></p><p>日前，据海外博主「Chetaslua」消息，智谱下一代模型（或为 GLM-5）将采用 DeepSeek 同款架构。</p><p>据 Chetaslua 分析，<strong>GLM-5 将采用了 DeepSeek-V3/V3.2 架构，其中包含稀疏注意力机制（DSA）和多 Token 预测（MTP）；模型总参数量达 745B，将会是上一代 GLM-4.7 的 2 倍。</strong></p><p>值得一提的是，近期有一个名为「Pony Alpha」的神秘模型上线全球模型服务平台 OpenRouter，并且引发较高热度。其中不乏有人分析指出，该模型或为智谱新的模型。</p><p>而据第一财经消息，智谱目前有相关保密项目在推进中，该神秘模型，是智谱即将发布新一代模型 GLM-5。</p><p>据悉，OpenRouter 合作方 Kilo Code 曾透露，Pony Alpha 是「某个全球实验室最受欢迎的开源模型的专项进化版」。</p><p>对此，报道指出，Pony Alpha 更有可能是 DeepSeek-V4 或者智谱即将发布的新一代模型 GLM-5。</p><p>( @APPSO)</p><p><strong>3、vLLM 推出流式输入与 Realtime API：打破批处理限制，解锁低延迟实时推理</strong></p><p>vLLM 联合 Meta 与 Mistral AI 推出流式输入功能及 WebSocket 「Realtime API」。该更新打破了先接收完整请求、再开始推理的传统范式，<strong>允许模型在用户说话或数据传输过程中同步处理</strong>，为语音助手、实时转录及机器人控制等低延迟场景提供了原生支持。</p><ul><li><strong>「StreamingInput」增量接口</strong>：核心输入对象从静态 Prompt 升级为异步生成器。开发者可以像「喂料」一样，将数据碎块随时间 yield 给引擎，实现边输入边处理。</li><li><strong>「Anchor Request」锚定会话模式</strong>：会话启动时建立一个长期存在的「锚定请求」。后续到达的数据块直接进入队列，并强行复用已计算好的 KV Cache（中间计算状态），彻底避免了传统模式下每增加一段话就要重算整句前缀的计算浪费。</li><li><strong>智能缓存衔接策略</strong>：在处理新输入块时，引擎会保留之前生成的大部分 Token 缓存。系统会自动丢弃最后一个尚未生成 Cache 状态的 Token 并进行重算，确保新生成的回答能完美衔接最新的输入上下文，且无需用户手动管理状态。</li><li><strong>兼容 OpenAI 标准的 Realtime API</strong>：通过 /v1/realtime 端点提供 WebSocket 双向通信。支持 16kHz 的 PCM16 原生音频流输入，服务端可实时返回 transcription.delta（转录增量）和文本/音频响应，支持「听」与「说」同时并发。</li><li><strong>模型架构适配要求</strong>：该特性需配合具备「因果注意力」机制的模型（如「Voxtral」）。这类模型在处理当前信息时无需参考后续未到达的内容，结合滑动窗口注意力可实现无限长度流式推理。</li></ul><p>功能已在 vLLM 最新版本中开源。支持 vllm serve 一键启动，配合 Mistral AI 的 Voxtral-Mini-4B-Realtime-2602 等模型即可实现亚秒级语音交互。</p><p>相关链接：</p><p><a href="https://link.segmentfault.com/?enc=%2F4CNErTW4emPnNkQwVLCgw%3D%3D.Zcr%2FET13ErFOq7G0IuXw95lndkG3k9zCznKxPZXHm37H12zwyMRhQnIiKBTJXtqhTrbRHRBD33itXfTl9Tm%2Fdw%3D%3D" rel="nofollow" target="_blank">https://blog.vllm.ai/2026/01/31/streaming-realtime.html</a></p><p>GitHub: </p><p><a href="https://link.segmentfault.com/?enc=lbQpIEAEkF9X1a33LLpIzQ%3D%3D.H8L%2F%2BQnZEjlyvMvUiDQAthDF%2FNqI2vcZnbnFy5H47L%2Bc4i6dcJw3PEpN6Jo8qi50" rel="nofollow" target="_blank">https://github.com/vllm-project/vllm</a></p><p>( @vLLM)</p><h2>02有亮点的产品</h2><p><strong>1、DuckDuckGo AI 语音聊天上线，承诺不存储音频</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047606989" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047606990" alt="" title="" loading="lazy"/></p><p>DuckDuckGo 昨日发布公告，<strong>宣布其 AI 聊天机器人平台 Duck.ai 新增实时语音聊天功能，主打极致隐私保护。</strong></p><p>与市面上其他语音助手不同，该功能的核心卖点在于 <strong>「隐私优先」</strong> 的架构设计。用户通过加密通道与大语言模型（LLM）进行自然对话，无需担心语音数据被后台监听或二次利用。</p><p>为了兼顾智能体验与数据安全，DuckDuckGo 采用了独特的「中间人」模式。虽然语音聊天的底层智能由 OpenAI 提供支持，但 DuckDuckGo 在用户与 OpenAI 之间建立了一道防火墙。</p><p>官方强调，双方均受严格合同限制：DuckDuckGo 匿名化处理音频，OpenAI 仅负责处理请求，严禁保留数据。这意味着，<strong>该平台不会存储用户的聊天音频，也不会调用内容用于训练 AI 模型</strong>。</p><p>为消除用户疑虑，DuckDuckGo 公布了具体的隐私保护细节：</p><ul><li>临时处理：音频流仅在说话时传输，会话结束后即刻销毁；</li><li>零训练：用户的声音和 AI 的回复均不会喂给算法模型；</li><li>加密传输：全程通过 WebRTC 和中继服务器进行高强度加密；</li><li>零留存：无论是 DuckDuckGo 还是 OpenAI，在通话结束后都不会保留任何记录。</li></ul><p>在使用门槛上，Duck.ai 保持了开放策略：用户无需注册账号即可免费体验（受每日额度限制）。对于重度用户，DuckDuckGo 推出了每月 10 美元（现汇率约合 69.3 元人民币）的订阅服务，不仅大幅提升了使用限额，还附带了个人信息移除服务以及身份盗窃恢复服务等。</p><p>（@IT 之家）</p><p><strong>2、奇妙拉比获投数千万，探索「硬件+IP+AI」新生态</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047606991" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047606992" alt="" title="" loading="lazy"/></p><p>奇妙拉比日前完成数千万人民币天使轮融资，由锦秋基金领投，首程控股联合投资，沧澜资本担任独家财务顾问。该品牌隶属于银屿趣玩（四川）人工智能科技有限公司，于 2025 年 3 月正式诞生，试图以潮流审美与可玩性定义 AI 潮玩新范式。</p><p>区别于传统 AI 玩具或陪伴型产品，奇妙拉比强调潮流审美、收藏价值与强 IP 人格，<strong>构建了「本体硬件 + 角色分支 + 配件生态 + 周边收藏 + 内容更新」的产品体系</strong>。</p><p>其首个核心 IP 雷格斯（RAGUS &amp; WHITE）于 2025 年 6 月推出，<strong>坚持「潮玩优先，AI 后置」逻辑</strong>，通过 AI 赋予角色稳定人格与长期记忆，使其能随用户互动而「生长」。</p><p>市场数据验证了这一品类价值：雷格斯在近乎零推广下，预售当日引发小程序崩溃，下单量数千台；在线下，其在北京陶朱新造局等空间长期稳居销量前三。新品「阴阳双生」系列也于近日亮相，基于多元宇宙设定展示了同一人格的不同演化可能。</p><p>本轮融资将重点投入两大方向：</p><ul><li><strong>内容生态建设</strong>：持续完善 AI 潮玩宇宙的世界观与角色体系，深化用户与角色的长期互动。</li><li><strong>SKU 矩阵扩展</strong>：推进多形态产品与玩法创新，探索与成熟 IP 及艺术家的授权合作。</li></ul><p>联合创始人景林彦认为，传统潮玩体验峰值集中在拆箱瞬间，<strong>而 AI 潮玩通过角色成长驱动复购</strong>，是行业的下半场。</p><p>投资方锦秋基金与首程控股均看好 AI 潮玩作为新品类的潜力，认为其结合了 AI 与 IP 的优势，具备极大的想象空间。首程控股联席总裁叶芊特别指出，奇妙拉比团队在资源匮乏下展现出的极强战斗力与创新力，是其投资的核心原因之一。</p><p>（@IPO 早知道）</p><p><strong>3、YC 孵化生产力工具 VoiceOS 上线：支持跨应用语音指令与 Prompt 自动优化</strong></p><p>由 YC 投资的语音生产力工具 VoiceOS 正式上线。该产品被定义为一款<strong>通用的语音操作系统</strong>，试图通过语音交互将工作效率提升至新的层级，解决传统键盘输入带来的效率瓶颈。</p><p>VoiceOS 团队认为，尽管键盘是目前主流的输入工具，但它往往成为连接大脑与数字世界之间的阻碍。用户在将想法转化为屏幕文字的过程中，面临着精神负担重、纠错耗时以及应用切换导致思路中断等问题。很多时候，当用户完成了打字、重组语言、修正错别字和调整格式后，最初的灵感火花已经消逝。</p><p>针对这一痛点，VoiceOS 并未止步于传统的语音转文字功能，而是构建了一个能理解用户意图的通用语音界面。<strong>它能够即时将口述的想法转化为经过润色的输出，并自动处理格式、语气、语法和语境。</strong>其核心功能包括：</p><ul><li><strong>即时回复</strong>：用户无需打字或过度思考，只需口述意图（如「要求明天重新安排时间」），系统即可自动生成完整回复。</li><li><strong>优化提示词</strong>：能够轻松地将用户杂乱的思维碎片，转化为适用于 AI 工具的精准提示词。</li><li><strong>全平台兼容</strong>：支持 Slack、Gmail、Notion、ChatGPT、Cursor 等任意应用程序，且无需进行额外设置。</li></ul><p>该项目的创始人 Kai 和 Jonah 在过去 7 年中积累了丰富的语音 AI 开发经验，涵盖从消费级产品到世界 500 强企业的部署。他们指出，此前语音技术的发展瓶颈并非在于模型能力，而在于交互界面。在通用人工智能（AGI）逐渐成为现实的背景下，<strong>键盘可能不再是人类与技术交互的主要方式，语音将取而代之成为新的操作系统</strong>。</p><p>( @ycombinator@X、@VoiceOS Blog)</p><p><strong>4、被迫改名、发货推迟至 2027：奥特曼与 Jony Ive 的 AI 硬件项目遇阻</strong></p><p>据 Gizmodo 援引 Wired 的报道，OpenAI 首席执行官 Sam Altman 与前苹果设计师 Jony Ive 合作开发的 AI 硬件项目正面临多重阻碍，问题主要集中在<strong>品牌命名、发货时间表以及技术研发</strong>三个方面。</p><p>首先是品牌命名问题。法庭文件显示，这家新成立的公司在尝试以「io」命名时遭遇了法律障碍。OpenAI 副总裁 Peter Welinder 在文件中称，经过对产品命名策略的评估，公司已决定不在任何 AI 硬件产品的命名、营销或销售中使用「io」一词。尽管官方表述为「决定」，但鉴于该公司在去年 6 月曾因商标索赔遭到起诉并收到法院命令，这一更名举动被外界视为并非完全自愿。</p><p>其次，产品的上市时间表大幅推迟。尽管此前有《The Information》和 Axios 的报道称 OpenAI 最快可能在今年揭晓其设备，但最新消息显示，<strong>这家目前暂无名称的公司要等到 2027 年 2 月才会开始正式发货</strong>。这使得原定于今年下半年的产品展示充满了不确定性。</p><p>此外，据《金融时报》此前报道，该项目的研发过程也面临着具体的软硬件挑战：</p><ul><li><strong>算力瓶颈</strong>：团队在整合足够的计算能力以支持设备运行方面遇到了困难。</li><li><strong>交互缺陷</strong>：设备核心的语音助手功能尚不完善。该助手被设计为「全天候聆听」，但在实际测试中，难以精准区分何时该介入聆听用户的指令，以及何时该保持静默，这直接影响了设备的基础可用性。</li></ul><p>目前的 AI 硬件市场环境并不乐观，Humane 的 AI Pin 和 Rabbit R1 等先发产品均因未能兑现功能承诺而遭遇挫折。Altman 和 Ive 的团队不仅需要解决上述技术与法律难题，还需面对智能手机这一成熟形态的强势竞争。</p><p>( @Gizmodo )</p><h2>03有态度的观点</h2><p><strong>1、Anthropic：AI 智能体将重塑开发全流程</strong></p><p>Anthropic 近日发布了一份名为《2026 Agentic Coding Trends Report》的重磅报告。</p><p>报告指出，<strong>随着 AI 编程能力从「实验性工具」向「生产力系统」的演进</strong>，软件开发行业正站在一场「地壳运动般」变革的边缘。</p><p>报告预测，到 2026 年，软件开发将不再局限于人类编写代码，而是转向由人类编排 AI 智能体团队来完成。这一转变将导致传统的软件开发生命周期发生剧烈坍缩，项目交付时间将从数周缩短至数小时。</p><p>报告中引人注目的技术趋势是 AI 智能体架构的演进。目前的单体智能体受限于上下文窗口和单线程处理能力，往往只能处理线性任务。但 Anthropic 指出，<strong>2026 年将是「多智能体协同」爆发的一年。</strong></p><p>有趣的是，报告中还提到，尽管 AI 承担了更多执行层面的工作，但报告揭示了一个关键的「协作悖论」：AI 使用率高，但完全放权率低。</p><p>Anthropic 的内部研究显示，虽然工程师在 60% 的工作中都会使用 AI，但他们表示能够「完全通过」的任务比例仅为 0-20%。这表明，AI 目前更像是一个需要持续监督的合作伙伴，而非完全自动化的替代品。</p><p>报告指出，随着 AI 能力的提升，人类的监督方式也将发生质变——从「逐行审查」转向「基于智能体的质量控制」，即利用 AI 智能体来审查其他 AI 生成的大规模代码，人类仅需关注高风险和战略性的部分。</p><p>( @APPSO)</p><h2>04 Real-Time AI Demo</h2><p><strong>1、AI 界的 WWE？Agent Wars 上线 Beta 版：围观 AI 实时编程对决，支持 SOL 下注</strong></p><p>开发者 Joaki 近日推出了名为 Agent Wars 的平台，目前处于 Beta 测试阶段。该项目主打 AI 智能体之间的实时编程对决，并允许观众使用 SOL 代币对比赛结果进行下注。</p><p>在该平台上，<strong>核心互动机制分为人类观众与 AI 智能体两端</strong>。对于观众而言，他们可以观看 AI 智能体实时解决编程挑战，并在比赛开始前投入 SOL 押注获胜方。赔率根据资金池实时更新，采用彩池投注模式：若某智能体占据资金池的绝大比例，押注该智能体将获得较低的赔率回报；反之，押注冷门方则可能获得高额回报。<strong>获胜的投注者将按比例瓜分输家资金池的 95%</strong>。</p><p>对于 AI 智能体开发者，参与流程包括通过 API 注册并创建智能体档案。智能体需设置「心跳」机制，每 30 分钟检查一次战斗匹配。一旦匹配成功，智能体便会接收到涵盖编程、算法实现或调试等不同难度（从简单到专家级）的挑战任务。</p><p>每场对决遵循一套标准化的流程：</p><ul><li><strong>准备阶段</strong>：智能体匹配完成，投注通道开启，观众在战斗开始前下注。</li><li><strong>实战阶段</strong>：智能体接收题目并现场编写代码，此时投注通道关闭。</li><li><strong>裁判阶段</strong>：由 AI 裁判根据正确性、代码质量和效率对解决方案进行评估；若评分相同，响应速度更快者胜出。</li><li><strong>结果公示</strong>：系统宣布获胜者，并自动分发奖励。</li></ul><p>值得注意的是，为了激励开发者参与，<strong>获胜智能体的所有者将直接获得总投注池的 5% 作为奖励</strong>。在 Beta 测试期间，平台暂不收取任何服务费。开发者若需提取收益，可通过个人资料页面将 SOL 直接转入钱包。目前，任何 AI 智能体均可通过公开的技术文档申请加入这场竞技。</p><p>体验链接：</p><p><a href="https://link.segmentfault.com/?enc=ph6%2F49502x9CNfP9NWnAXw%3D%3D.%2F9iY8o6whfklserI0%2BK%2BeGFbczQh29hYmTgZwIy99EQ%3D" rel="nofollow" target="_blank">https://www.agentwars.gg/</a></p><p>（@itsjoaki@X、@Agent Wars）</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047606993" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047606994" alt="" title="" loading="lazy"/></p><p><strong>写在最后：</strong></p><p>我们欢迎更多的小伙伴参与 <strong>「RTE 开发者日报」</strong> 内容的共创，感兴趣的朋友请通过开发者社区或公众号留言联系，记得报暗号「共创」。</p><p>对于任何反馈（包括但不限于内容上、形式上）我们不胜感激、并有小惊喜回馈，例如你希望从日报中看到哪些内容；自己推荐的信源、项目、话题、活动等；或者列举几个你喜欢看、平时常看的内容渠道；内容排版或呈现形式上有哪些可以改进的地方等。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047606995" alt="" title="" loading="lazy"/></p><p>作者提示: 个人观点，仅供参考</p>]]></description></item><item>    <title><![CDATA[APS排产的拓展属性管理，轻松应对企业的复杂生产需求 软件部长 ]]></title>    <link>https://segmentfault.com/a/1190000047607005</link>    <guid>https://segmentfault.com/a/1190000047607005</guid>    <pubDate>2026-02-12 11:03:42</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在现代制造业中，同一产品往往有多种规格配置，比如汽车的颜色、配置等级，电器的不同型号等。这些多样化需求如何体现在生产计划中？<br/>JVS-APS排产系统的拓展属性管理模块负责对这些产品特征进行统一管理和分类，使生产计划能够基于产品多维度特性进行精准排产，满足现代制造业个性化定制的需求。<br/>以下解读所用到的是开源的JVS智能排产系统。<br/>JVS-APS系统是由软开企服开源的一款智能排产系统，系统聚焦于离散制造行业（如汽车、电子、机械、航空航天等）及流程制造行业（如化工、食品、医药等），面向中大型企业客户，通过AI驱动的智能算法，实现生产计划与排程的高效性、准确性、敏捷性，帮助企业提升设备利用率、降低库存成本、缩短交付周期，实现精益生产与数智化转型。<br/>拓展属性是指在生产一个产品时，该产品所带有的一系列特征或标识。好比汽车有不同系列、颜色、尺寸大小等，这些都可称为汽车的属性。所以属性管理模块即是对生产产品的自带特征或标识作为属性进行管理。</p><h2>功能说明</h2><p>• 属性新增<br/>通过系统对产品自带属性进行新增。<br/>• 属性查看<br/>将所有属性集中放于一个列表之中，便于查看与管理。</p><h2>操作步骤</h2><p>1、点击【基础数据】下面的【属性管理】，进入属性管理页面。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047607007" alt="图片" title="图片"/><br/>2、点击【新增属性】，即可进入新增页面。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047607008" alt="图片" title="图片" loading="lazy"/><br/>3、新增属性页面需输入对应的属性名(需用户手动输入，可自定义属性名称)、属性key（默认为属性名的拼音，也可自定义key值）、属性校验（是否必填校验）、属性类型（可选择 文本框、数字框、下拉框、单选、多选 这几种类型）。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047607009" alt="图片" title="图片" loading="lazy"/><br/>4、填写完相关信息后点击提交即会出现在列表页中，可对数据进行二次编辑或删除。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047607010" alt="图片" title="图片" loading="lazy"/><br/>5、此外还有查询功能，可选择输入属性名或属性key或选择属性类型这几种方式，查出其中对应一条或相同类型的多条数据。输入完成后点击查询即可查到相关数据信息。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047607011" alt="图片" title="图片" loading="lazy"/><br/>拓展属性管理看似是很简单的功能，其实无论是离散制造还是流程制造行业，合理利用，不仅解决了多品种小批量生产的复杂性问题，还可以帮助企业实现从“人治”到“数智”的转型升级。</p>]]></description></item><item>    <title><![CDATA[文本差异对比器 在线工具分享 兔子昂 ]]></title>    <link>https://segmentfault.com/a/1190000047607063</link>    <guid>https://segmentfault.com/a/1190000047607063</guid>    <pubDate>2026-02-12 11:03:05</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在日常工作和学习中，我们经常需要对比两段文字或代码及其差异。</p><p>比如程序员在排查 Bug 时，需要对比修改前后的代码片段；文案编辑在校对文章时，需要找出修订的具体位置；或者是运维人员在对比两个配置文件的细微不同。</p><p>如果仅仅依靠肉眼去逐行扫描，不仅效率极低，而且非常容易看走眼，漏掉关键的差异点。</p><p>今天给大家分享一个我开发的在线工具——<strong>文本差异对比器 (Text Diff Checker)</strong>，它可以帮你一键快速找出两段文本的所有不同之处。</p><blockquote>在线工具网址：<a href="https://link.segmentfault.com/?enc=qIEV1EvO8PXMKZ1zb8Plpw%3D%3D.bscNXYfbO8GSyBKsINUyrQvA1%2B8oJvT7hw8LwoutStsSzT2pAFxOs1AcMpaOBnBb" rel="nofollow" target="_blank">https://see-tool.com/diff-checker</a>  <br/>工具截图：  <br/><img width="723" height="419" referrerpolicy="no-referrer" src="/img/bVdnUVZ" alt="" title=""/></blockquote><h2>工具核心功能</h2><p><strong>1. 多种对比模式</strong><br/>工具支持三种精度的对比模式，满足不同场景的需求：</p><ul><li><strong>按行对比 (Line)</strong>：适合代码或长文章，快速定位哪些行发生了变化。</li><li><strong>按词对比 (Word)</strong>：适合英文文章或短语，精确到单词级别的差异。</li><li><strong>按字符对比 (Char)</strong>：适合对比密钥、哈希值或细节要求极高的文本，精确到每一个字符。</li></ul><p><strong>2. 直观的高亮显示</strong><br/>采用经典的“红删绿增”配色方案：</p><ul><li><strong>红色背景</strong>：表示左侧文本中被删除或修改的内容。</li><li><strong>绿色背景</strong>：表示右侧文本中新增或修改后的内容。<br/>差异一目了然，不需要任何学习成本。</li></ul><p><strong>3. 灵活的辅助选项</strong></p><ul><li><strong>忽略空格</strong>：有时候仅仅是缩进不同，勾选此项可以忽略空白字符的差异。</li><li><strong>忽略大小写</strong>：不区分大小写的比对。</li><li><strong>显示行号</strong>：方便定位具体位置。</li></ul><h2>技术实现 (Vue 3)</h2><p>作为一个前端开发者，我使用目前流行的 <strong>Vue 3 (Composition API)</strong> 框架配合 <strong>Tailwind CSS</strong> 编写了这个工具。</p><p><strong>纯前端处理，安全无忧</strong><br/>值得一提的是，这个工具的所有计算逻辑完全在你的本地浏览器中运行。这意味着：<strong>你输入的任何文本（无论是机密代码还是私人文章）都不会被上传到服务器</strong>。你可以放心大胆地使用它来对比敏感数据，隐私安全有绝对保障。</p><p><strong>响应式设计</strong><br/>工具对移动端和桌面端都做了适配。无论你是在电脑前工作，还是临时用手机查看差异，都能获得良好的使用体验。</p><h2>如何使用</h2><ol><li>打开工具页面，你会看到左右两个输入框。</li><li>在左侧输入框粘贴“原始内容”，在右侧输入框粘贴“修改后的内容”。</li><li>根据需要选择对比模式（默认是“按行对比”）。</li><li>点击中间的 <strong>“开始对比”</strong> 按钮。</li><li>页面下方会立即生成对比报告，显示增加/删除的行数统计，并高亮展示差异详情。</li></ol><h2>结语</h2><p>这个小工具虽然功能单一，但在关键时刻能帮我们节省大量的时间和精力。如果你也受够了用肉眼“且”不同，不妨试试这个文本差异对比器。</p><p>欢迎大家使用并提出宝贵意见！</p>]]></description></item><item>    <title><![CDATA[当轻帆云 ITSM 遇上 OpenClaw：一种“去 UI 化”的生产实践 云智慧 ]]></title>    <link>https://segmentfault.com/a/1190000047607066</link>    <guid>https://segmentfault.com/a/1190000047607066</guid>    <pubDate>2026-02-12 11:02:10</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>2026年开年， 一个名为 OpenClaw 的开源 AI 智能体项目在开发者社区引发广泛关注。不同于云端对话式助手，OpenClaw 直接在本地运行，能够操作软件、收发邮件、执行代码，甚至可以自动完成一系列跨应用的任务。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607068" alt="图片" title="图片"/></p><p>这种“本地执行”能力能否在企业 ITSM 场景中找到用武之地？<a href="https://link.segmentfault.com/?enc=2JIQNNs1O8KuSdtF9AI82g%3D%3D.Vm0S2VydRAGz%2F%2FUUr%2B7NeEFbG1yqxbZ%2BXL%2B03TkLeE64oRK0%2BMFhyE7xhY4smG8NgXlqK5mSFZISseXI%2FLJ%2BbA%3D%3D" rel="nofollow" target="_blank">轻帆云 ITSM</a> 团队尝试将这一能力引入服务管理流程，探索一种减少界面交互、提升服务效率的新可能。</p><h2>从图形界面到自然语言：轻帆云的“去 UI 化”探索“</h2><p>最好的 UI，就是没有 UI。”——当服务足够智能，用户便无需与界面打交道。</p><p>在传统 ITSM 模式中，用户需主动登录系统、浏览服务目录、填写表单、提交工单，并在后续反复登录以跟踪进度、处理驳回、催办超时、完成评价——整个过程高度依赖界面操作与人工干预，使用门槛高、体验割裂。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607069" alt="图片" title="图片" loading="lazy"/></p><p>在已跑通飞书/Telegram 端的实验室环境中，轻帆云通过集成 OpenClaw，实现了 IT 服务流程的“去 UI 化”重构：用户只需在对话中自然表达需求，例如 “帮我开下 CRM 权限，我要处理上个月的财务报表”，系统即可自动解析意图、创建工单，并全程驱动后续流程。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607070" alt="图片" title="图片" loading="lazy"/></p><p>工单临近超时时，系统会自动向处理人发起催办；若被驳回，则尝试分析原因、补充必要信息并重新提交。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607071" alt="图片" title="图片" loading="lazy"/></p><p>任务完成后，结果将即时推送至用户，满意度评价也依预设规则自动完成。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607072" alt="图片" title="图片" loading="lazy"/></p><p>用户无需再登录后台，也无需记忆流程节点。这一变革将服务入口从“系统后台”迁移至“日常对话”，把被动查询转变为主动服务，让智能 IT 服务真正走向“无感、无扰、无界面”。</p><h2>Opencalw驱动的轻帆云ITSM：“去 UI 化”探索的实现路径</h2><p>“去 UI 化”的本质，并非消除界面，而是让用户在发起和跟踪 IT 服务时，无需主动打开或操作 ITSM 系统界面。这一体验的背后，是一套端到端的自动化执行链路。</p><p>用户在 Telegram 中的一句话，如何驱动复杂的 ITSM 流程？其核心在于以下四个环节的紧密协同：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607073" alt="图片" title="图片" loading="lazy"/></p><h3>1、语义解析 —— OpenClaw 的“大脑”</h3><p>用户输入“帮我申请 CRM 权限”，OpenClaw 即时识别意图（如 dosm_create），并将模糊请求拆解为结构化参数（例如 system: CRM），替代了传统流程中手动浏览目录、填写表单的操作。</p><h3>2、身份穿梭 —— 合规的安全桥梁</h3><p>系统自动捕获用户的 Telegram ID，并精准映射为轻帆云内部真实的 userId（如 19733）。所有操作均以真实身份执行，满足企业审计与权限管控要求，实现安全可信的“AI 代用户操作”。</p><h3>3、协议封包 —— AI 的“手脚”</h3><p>OpenClaw 调用预定义 Skill，将参数封装为符合轻帆云接口规范的 JSON 表单（含必要转义与认证字段），并通过 POST /orderCreate 请求直接创建工单，全程绕过前端界面，实现无感系统交互。</p><h3>4、感知反馈 —— 即时的服务闭环</h3><p>工单状态变更后，轻帆云通过 Webhook 实时回传数据，OpenClaw 将系统响应转化为自然语言消息（如“单号 WO123 已生成，处理人正在审批中”），主动推送至用户对话窗口，无需用户主动查询。</p><p>正是这套链路，让用户无需登录、无需填表、无需查进度，即可完成 IT 服务主流程——界面依然存在，但已退居幕后，由 AI 代理完成交互。</p><h2>轻帆云的 AI 能力中台：让“去 UI 化”快速落地“</h2><p>去 UI 化”体验的快速实现，源于轻帆云早已构建的 AI 能力中台——一个面向<a href="https://link.segmentfault.com/?enc=Jtg%2BwH0Dg6uidc6HNpp7kw%3D%3D.096j3qq%2BkakoLtzdBRehf3J6Uet7pNA41xX25lBWFPy1HZYId3lkViCyUeYTSh%2BI" rel="nofollow" target="_blank">企业级 ITSM</a> 场景设计的开放智能架构。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607074" alt="图片" title="图片" loading="lazy"/></p><p>该中台底层兼容主流大模型服务（如 DeepSeek、通义、讯飞星火等），中层集成了自研的 RAG 引擎、长短时记忆机制、工作流编排系统与多 Agent 协同框架，完整覆盖从自然语言理解到跨系统执行的全链路需求。</p><p>正因具备这一标准化、可扩展的智能底座，<a href="https://link.segmentfault.com/?enc=6kAmAWFfwQkq%2FlOSoC0qvA%3D%3D.nX4Ev0%2Fm0Loy0cI%2FguqWXfPC7xD5k4tIWYu3ul9azOtq1lhq9oixKD5l8QQHfjQN" rel="nofollow" target="_blank">好用的轻帆云IT服务管理平台</a>无需为 OpenClaw 进行定制开发，仅通过配置即可将其作为外部智能体接入，驱动工单创建、状态追踪等核心流程。整个过程不改造原有 ITSM 系统，不影响现有业务运行，真正实现了“去 UI 化”能力的敏捷交付。</p><h2>前沿探索·驱动轻帆云ITSM持续进化</h2><p>从大模型DeepSeek到智能体OpenClaw，<a href="https://link.segmentfault.com/?enc=XmboMbx5tQCF1at2neimPQ%3D%3D.W8QxyreofphYv3yR2D32pG4t7jHGfp7DlAw2r8v0Wi2Lf0K%2FIITNzUTVyjMWGD7L" rel="nofollow" target="_blank">国内主流企业级智能IT服务管理平台——轻帆云</a>始终致力于将前沿 AI 能力转化为可落地的产品价值。正是这种对新技术的高效集成能力，让“去 UI 化”等创新体验得以快速实现，并持续推动 ITSM 服务向更智能、更无感的方向演进。</p><p>详询热线：400-666-1332</p>]]></description></item><item>    <title><![CDATA[从分库分表到原生分布式：高德基于 OceanBase 的数据底座演进之路 OceanBase技术站 ]]></title>    <link>https://segmentfault.com/a/1190000047607099</link>    <guid>https://segmentfault.com/a/1190000047607099</guid>    <pubDate>2026-02-12 11:01:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><strong>摘要：</strong><br/><strong><em>高德面对数据存储扩展和成本效率、极致的性能要求、容灾高可用保障三大挑战，传统分库分表架构已无法支撑海量业务数据。其选择 OceanBase 原生分布式数据库升级核心业务，依托其高压缩、异地多活、MySQL 兼容能力，实现零感知平滑迁移。升级后存储成本、响应时间、研发效率均得到显著优化，容灾能力增强，完成从分库分表到原生分布式的数据底座演进。</em></strong></p><p>提起高德，许多人首先想到的是其精准的数字地图。但如今的高德，早已不仅仅是一款导航工具，而是发展成为覆盖衣食住行等全场景的“国民级”出行服务平台。</p><p>数据显示，高德的日活跃用户数最高已突破 3.6 亿人次（截至 2025 年 10 月 1 日），日均活跃用户也稳定在 1.5 亿人次以上。如此庞大的用户体量，为高德的业务系统带来了海量数据存储与实时响应的双重挑战，尤其在五一、国庆等出行高峰期间，后台系统承受的压力更为显著。</p><p>面对持续增长的业务压力，传统基于分库分表的数据库架构已无力支撑。在这一背景下，高德开始探索将数据库升级至新一代分布式数据库 OceanBase 的可行路径。其中，“足迹”与“云同步”等核心业务，成为此次升级的先行者。</p><h2>高德地图在线服务应对海量存储三大核心挑战与思考</h2><p>作为高德地图出行服务技术负责人，李岩的核心职责之一是应对各业务快速发展带来的高并发与海量存储挑战。</p><p>“用户每一次路线规划、每一次地点搜索的背后，都是对系统稳定性与体验感的极致考验。我们必须确保每一次请求都稳如磐石，用户体验如丝般顺滑。”李岩表示。</p><p>高德的技术体系构建在云原生基础设施之上，依托云的弹性伸缩能力，可根据业务需求快速实现资源的扩缩容，从而为上层应用的开发与部署提供极大的灵活性。高德强大的云底座也让李岩能更专注于应对大并发、低延迟的海量存储带来的技术压力。</p><p>李岩将高德应对海量数据所面临的核心挑战归纳为三方面：</p><p><strong>一是数据存储扩展和成本效率，即如何合理部署与分配业务数据。</strong>这不仅关乎存储成本，更直接影响业务模型能否实现低成本的扩展与迭代，进而影响整体业务效率。</p><p><strong>二是极致的性能要求。</strong>高德的在线服务必须在高 QPS/TPS 下保持低耗时的响应，并能在需要时实现平滑的弹性伸缩。同时，系统还需具备故障快速发现、诊断与恢复的能力。</p><p><strong>三是容灾高可用保障。</strong>系统需支持在出现故障时实现“一键”逃逸能力与逃逸的力度，并尽可能让用户对此过程无感知。</p><p>实际上，无论是“足迹”还是“云同步”，这些核心业务系统数据库升级的目标正是为了应对上述三个核心挑战。</p><h2>选择 OceanBase：解决千亿级数据规模的分库分表架构瓶颈</h2><p>高德的“足迹”服务是一项自动记录用户历史出行与停留地点的位置服务。它通过持续收集定位数据，生成个人专属的出行时间轴，帮助用户回顾、管理和分享自己的移动路线。目前，数据规模已超过 7000 亿条，存储规模突破 360TB，读写并发峰值平均每秒超过 27 万次请求。</p><p>“‘足迹’需要在 10 毫秒内响应用户请求，是一种典型的海量数据、高并发、低延迟业务场景，对底层数据库系统要求极高。”李岩表示。</p><p>“足迹”原先采用分库分表架构。虽在一定程度上缓解了数据量的问题，但随着业务不断迭代、数据量不断增长，其弊端也逐渐凸显：例如大表以及大表在做索引变更时会引发抖动，进而影响系统稳定性；其次，一些模型拓展以及数据归档成本都相对较高，在成本上持续面临压力。</p><p>鉴于业务的快速增长，李岩和团队选择从底层存储层入手，做一次彻底的治理和升级，彻底解决分库分表架构带来的性能瓶颈，满足业务快速发展对数据底座的全新要求。</p><p>从业务角度而言，此次治理和升级，高德地图在数据库选型上需满足三大方面的要求：高可用、业务效率和成本。经过测试和对比以后，最终选择 OceanBase 来服务高德地图。</p><p>李岩表示，之所以选择 OceanBase，是因为其具有原生分布式和单机分布式一体化架构，具备弹性扩展、高可用和多活容灾能力。同时，除了 OceanBase 的性能稳定、产品成熟度高，已经过市场充分验证外，还有三点能力也是他看中的：</p><p>1.极致的存储压缩：OceanBase 提供多种压缩方式，显著降低存储规模；<br/>2.高度兼容 MySQL：减少应用层代码修改量，助力业务平滑升级。<br/>3.原生多活架构支持：可以根据业务需求灵活地选择。</p><h2>高德足迹大规模在线升级的考量与实践：零故障、零问题、用户零感知的平滑跃迁</h2><p>在确定采用 OceanBase 后，高德随即启动了系统化的升级工作。在千亿级别数据规模下，要做在线的升级，风险非常高。最终，凭借充分的准备与 OceanBase 团队的有力支持，整个升级过程实现了零故障，而且终端用户完全零感知，实现了业务的平滑跃迁。</p><p>在李岩看来，能够顺利完成此次“足迹”业务的升级，重点在于做好以下几方面的工作：</p><p>第一，站在全域、全链路的视角，放量回切控制点保持强统一、强同步、强一致，特别是涉及多层级的服务调用依赖时，这点尤其关键，否则就容易出现读写错位、放量错位的问题。</p><p>第二，进行多维度的数据校验。在“足迹”数据升级过程中，从最底层到最上层，分别进行了数据级、SQL级以及业务级的对比。只有三个校验都没有问题，才是真的没有问题。</p><p>第三，全量数据同步吞吐量高。这次升级过程中，OMS 的吞吐达到了每秒 1000 万行的并发写入，大大缩短了迁移周期。</p><p>升级后的系统平稳，已历经今年“双十一”等流量高峰期的考验，运行稳定、流畅，整体表现优异。对于此次数据库升级，李岩认为非常成功，为高德带来了多方面的实质性收益：</p><p>成本显著优化：OceanBase 通过高效的压缩算法，压缩比达到 2.23:1，数据规模得到降低，存储成本节省 55.2%。</p><p>性能持续提升：系统平均响应时间由原来的 5.95 毫秒降至 4.42 毫秒，提升了 25.7%，用户体验进一步改善。</p><p>研发效率提高：业务开发人员无需再关注分片、路由、弹性扩缩容等底层细节，“如同操作单机 MySQL 一样使用分布式数据库”。</p><h2>OceanBase 异地多活架构在高德的落地实践</h2><p>“云同步”是高德的另一项核心业务。“云同步”主要完成用户多端设备（如多个手机之间、手机与车机之间）的数据同步。</p><p>该业务的显著特点是数据量极为庞大，仅 3 个单元的数据总量就高达 5000 亿条。这一在线服务场景，对数据的实时性和高可用性都提出了极高的要求。</p><p>为了保证用户体验，同时也为了容灾，“云同步”在具体的业务场景下联合 OceanBase 采用了异地多活架构，在上海、张北、深圳三个数据中心分别进行部署。业务应用层提供多点写入的能力，基于用户维度进行单元化的路由和单元化的纠偏；中间的底层存储则依赖 OceanBase 的三地五中心金融级无损容灾能力部署，最下层的数据通路通过 OMS 来实现。</p><p>李岩介绍，由于高德需要实现不同单元间的双向同步，整个同步链路相对复杂，最终形成了三地六项的同步架构。“多活的目的，是为了就近接入以降低延迟，均衡各地域的资源分布和利用率，同时提升服务的 SLA，实现完全的高可用。同时，‘云同步’性能也得到了显著提升，实现了读写 QPS/TPS 22 万，读写平均响应时间 10 毫秒以内。升级后性能表现平稳，并且无论是水位还是 OMS 三地间同步链路也非常平滑。”</p><p>“如果没有 OceanBase 原生的多活能力，数据同步逻辑就必须在应用层实现，这不仅会大幅提升系统复杂度，也会显著增加开发和维护成本。”李岩说。</p><p>同时，系统的容灾能力也得到明显增强：当某个业务中心发生故障时，可在分钟级完成流量切换至其他数据中心，实现真正意义上的跨地域容灾逃逸。</p><h2>结语</h2><p>回看 OceanBase 在高德多个核心业务系统的应用，李岩认为，收益主要体现在以下三方面：</p><p>简单：提高了研发效率，业务研发像使用单机一样去使用分布式存储，不用关心分区、路由等等细节问题；</p><p>降本：因为有多种数据压缩手段以及数据和日志的分离，带来较高压缩比，数据规模越大，效果越明显；</p><p>多活和高可用：能保障数据的强一致性，提供多种多活部署方案，业务可按需选用。</p><p>“更重要的是，从分库分表到原生分布式数据库，高德完成的不仅是一次数据库升级，更是一场面向未来的架构演进，还为未来的业务发展预留了充足空间。”李岩总结说。</p><p>欢迎访问 OceanBase 官网获取更多信息：<a href="https://link.segmentfault.com/?enc=wqQVoybnAzI%2BkbCENgBImw%3D%3D.6c39pACBwTwXlct9BVtL7Z7KyE7ddntGDNc5QkPI5hE%3D" rel="nofollow" target="_blank">https://www.oceanbase.com/</a></p>]]></description></item><item>    <title><![CDATA[使用C#代码在 PowerPoint 演示文稿中插入表格 千杯不醉的脸盆 ]]></title>    <link>https://segmentfault.com/a/1190000047606354</link>    <guid>https://segmentfault.com/a/1190000047606354</guid>    <pubDate>2026-02-12 10:05:47</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在 PowerPoint 中，表格是一种非常实用的工具，可以帮助你以清晰、简洁且直观的方式展示和整理数据。通过使用表格，你能够更有效地传达复杂信息，让观众更容易理解并记住重点内容。</p><p>本文将介绍如何使用 Spire.Presentation for .NET，在 C# 和 VB.NET 中向 PowerPoint 演示文稿插入表格。</p><h2>安装 Spire.Presentation for .NET</h2><p>在开始之前，您需要将 Spire.Presentation for .NET 安装包中的 DLL 文件添加为 .NET 项目的引用。您可以通过官方下载链接获取 DLL 文件，或直接通过 NuGet 进行安装。</p><pre><code class="C#">PM&gt; Install-Package Spire.Presentation</code></pre><h2>在 C# 和 VB.NET 中向 PowerPoint 演示文稿插入表格</h2><p>您可以使用 ISlide.Shapes.AppendTable(float x, float y, double[] widths, double[] heights) 方法，在指定幻灯片上添加表格。具体步骤如下：</p><ol><li>创建 <code>Presentation</code> 类的实例。</li><li>通过 <code>Presentation.LoadFromFile(string file)</code> 方法加载 PowerPoint 文件。</li><li>使用 <code>Presentation.Slides[int index]</code> 属性获取指定的幻灯片。</li><li>定义两个 double 数组（widths 和 heights），分别用于设置表格列数、列宽以及行数、行高。</li><li>调用 <code>ISlide.Shapes.AppendTable(float x, float y, double[] widths, double[] heights)</code> 方法，在幻灯片指定位置添加具有指定行列数量和尺寸的表格。</li><li>使用一个二维字符串数组存储表格数据。</li><li>遍历该二维数组，并通过 <code>ITable[int columnIndex, int rowIndex].TextFrame.Text</code> 属性，将数据填充到对应的单元格中。</li><li>将表格首行内容设置为居中对齐。</li><li>通过 <code>ITable.StylePreset</code> 属性为表格应用内置样式。</li><li>最后，使用 <code>Presentation.SaveToFile(string file, FileFormat fileFormat)</code> 方法保存演示文稿。</li></ol><p><strong>完整示例代码如下：</strong></p><pre><code class="C#">using Spire.Presentation;

namespace InsertTable
{
    internal class Program
    {
        static void Main(string[] args)
        {
            //初始化 Presentation 类的实例
            Presentation presentation = new Presentation();
            //加载 PowerPoint 演示文稿
            presentation.LoadFromFile(@"Input.pptx");

            //获取第一张幻灯片
            ISlide slide = presentation.Slides[0];

            //定义两个 double 数组 widths 和 heights，用于指定表格的列数、列宽以及行数、行高
            double[] widths = new double[] { 100, 100, 150, 100, 100 };
            double[] heights = new double[] { 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15 };

            //在幻灯片的指定位置添加具有指定行列数量和尺寸的表格
            ITable table = slide.Shapes.AppendTable(presentation.SlideSize.Size.Width / 2 - 275, 90, widths, heights);

            //使用二维字符串数组存储表格数据
            string[,] data = new string[,]{
            {"Name", "Capital", "Continent", "Area", "Population"},
            {"Venezuela", "Caracas", "South America", "912047", "19700000"},
            {"Bolivia", "La Paz", "South America", "1098575", "7300000"},
            {"Brazil", "Brasilia", "South America", "8511196", "150400000"},
            {"Canada", "Ottawa", "North America", "9976147", "26500000"},
            {"Chile", "Santiago", "South America", "756943", "13200000"},
            {"Colombia", "Bogota", "South America", "1138907", "33000000"},
            {"Cuba", "Havana", "North America", "114524", "10600000"},
            {"Ecuador", "Quito", "South America", "455502", "10600000"},
            {"Paraguay", "Asuncion", "South America", "406576", "4660000"},
            {"Peru", "Lima", "South America", "1285215", "21600000"},
            {"Jamaica", "Kingston", "North America", "11424", "2500000"},
            {"Mexico", "Mexico City", "North America", "1967180", "88600000"}
            };

            //遍历字符串数组，并将数据填充到表格的每个单元格中
            for (int i = 0; i &lt; 13; i++)
                for (int j = 0; j &lt; 5; j++)
                {
                    //为表格的每个单元格赋值
                    table[j, i].TextFrame.Text = data[i, j];
                    //设置字体名称和字体大小
                    table[j, i].TextFrame.Paragraphs[0].TextRanges[0].LatinFont = new TextFont("Times New Roman");
                    table[j, i].TextFrame.Paragraphs[0].TextRanges[0].FontHeight = 16;
                }

            //将表格第一行的内容设置为居中对齐
            for (int i = 0; i &lt; 5; i++)
            {
                table[i, 0].TextFrame.Paragraphs[0].Alignment = TextAlignmentType.Center;
            }

            //为表格应用内置样式
            table.StylePreset = TableStylePreset.MediumStyle2Accent6;

            //将演示文稿保存到文件
            presentation.SaveToFile("InsertTable.pptx", FileFormat.Pptx2013);
            presentation.Dispose();
        }
    }
}</code></pre><h2>申请临时许可证</h2><p>如果您希望去除生成文档中的评估提示信息，或解除功能限制，可以申请为期 30 天的试用许可证。</p>]]></description></item><item>    <title><![CDATA[麒麟桌面系统【如何连接隐藏wifi】 沙鱼 ]]></title>    <link>https://segmentfault.com/a/1190000047606402</link>    <guid>https://segmentfault.com/a/1190000047606402</guid>    <pubDate>2026-02-12 10:04:58</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h5>麒麟桌面系统老v10和v10-sp1两个系统版本的连接有些不一样，下面分别对这两个系统进行说明</h5><h2>一、V10-SP1版本</h2><ol><li>打开“<code>加入其他网络</code>”<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047606405" alt="file" title="file"/><br/>或者从“开始” - “设置” - “无线局域网”进入也可以<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047606406" alt="file" title="file" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047606407" alt="file" title="file" loading="lazy"/></li><li>在弹出的“查找并加入无线局域网络”窗口，配置好ssid和密钥，点击加入。(<code>这两个必须输入，密码必须大于等于8位</code>)<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047606408" alt="file" title="file" loading="lazy"/></li></ol><hr/><h2>二、老V10版本</h2><ol><li>鼠标点击桌面任务栏右下角网络连接图标，再点击“编辑连接”，进入网络连接页面。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047606409" alt="file" title="file" loading="lazy"/></li><li>在网络连接页面，点击“增加”按钮。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047606410" alt="file" title="file" loading="lazy"/></li><li>再选择连接类型，选择“Wi-Fi”，然后点击“新建”按钮。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047606411" alt="file" title="file" loading="lazy"/></li><li>在正在编辑Wi-Fi连接1-&gt;Wi-Fi页面，在连接名称处和SSID处输入隐藏无线网络的名称，设备处选择对应的无线网卡硬件设备。<br/>例如：此处的无线网络名称为“ChinaNet-8312”，无线网卡硬件设备为“wlp6s0”。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047606412" alt="file" title="file" loading="lazy"/></li><li>在正在编辑Wi-Fi连接1（此处是正在编辑ChinaNet-8312）-&gt;Wi-Fi安全性页面，在安全处选择“WPA及WPA2个人”选项，在密码处输入无线网络的密码，然后点击“<code>保存</code>”按钮，即可连接无线网络。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047606413" alt="file" title="file" loading="lazy"/></li><li><p>如果点击“保存”按钮后，无法正常使用无线网络，则在桌面空白处鼠标右键，选择“在终端中打开”选项，打开终端，执行以下操作。</p><ol><li>在终端输入<code>nmcil connection show</code>命令后回车查看所以网卡的连接信息。</li></ol><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047606414" alt="file" title="file" loading="lazy"/><br/>从上图可知，刚才添加的无线网络“ChinNet-8312”没有连接激活。</p><ol start="2"><li>再在终端输入<code>nmcli connection up [无线网络名称]</code>，即此处是<code>nmcli connection up ChinNet-8312</code>命令后回车激活无线网络连接，会显示连接已成功激活。</li></ol><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047606415" alt="file" title="file" loading="lazy"/></p><ol start="3"><li>无线网络连接激活成功后，再输入<code>nmcli connection show</code>命令后回车查看所有网卡的连接信息。正常使用的网卡，连接信息显示为绿色。</li></ol><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047606416" alt="file" title="file" loading="lazy"/></p></li></ol><h2>三、命令行连接隐藏wifi</h2><ol><li>打开终端：<code>win + T</code></li><li><p>查看网卡，我这里是wlp2s0，后面连接需要用到</p><pre><code class="bash">nmcli  device</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047606417" alt="file" title="file" loading="lazy"/></p></li><li><p>查看可用的wifi设备</p><pre><code class="bash">nmcli device wifi list</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047606418" alt="file" title="file" loading="lazy"/></p></li><li><p>连接隐藏 Wi-Fi</p><pre><code class="bash">nmcli connection add \
 type wifi \
 con-name "kylintest" \
 ifname wlan0 \
 ssid "HiddenSSID" \
 wifi-sec.key-mgmt wpa-psk \
 wifi-sec.psk "YourPassword"</code></pre><h4>上面命令的参数说明：</h4></li><li>con-name：连接名称（自定义，如 MyHiddenWiFi）。</li><li>ifname：无线网卡接口（如 wlan0，可用 ip a 查看）。</li><li>ssid：隐藏 Wi-Fi 的 SSID（必须正确）。</li><li>wifi-sec.key-mgmt wpa-psk：使用 WPA-PSK 加密方式。</li><li>wifi-sec.psk：Wi-Fi 密码。</li></ol><h2>四、查询系统之前连接过的WiFi密码</h2><p>打开终端执行以下命令：</p><pre><code class="bash">sudo  grep  -r  "psk="  /etc/NetworkManager/system-connections/</code></pre><p>如下图所示：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047606419" alt="file" title="file" loading="lazy"/></p><p>本文由<a href="https://link.segmentfault.com/?enc=Zq%2BR8845%2FV01QQUf6xLX4g%3D%3D.h2jHs9pXnpHGWG7%2BLtKDwxHk1Q9xj9knWoI%2BZVPH2wM%3D" rel="nofollow" target="_blank">mdnice</a>多平台发布</p>]]></description></item><item>    <title><![CDATA[麒麟桌面系统【修改默认NTP服务器】 沙鱼 ]]></title>    <link>https://segmentfault.com/a/1190000047606489</link>    <guid>https://segmentfault.com/a/1190000047606489</guid>    <pubDate>2026-02-12 10:04:19</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>一、现象</h2><p>麒麟V10桌面系统，开机重启之后，发现系统时间不对，与实际时间相差较大。而且单位里多台电脑出现了同样的情况，但是每一台电脑的时间都是不一样的。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047606492" alt="file" title="file"/></p><h2>二、处理方法</h2><h3>方法1：手动修改时间</h3><pre><code class="bash">sudo date -s "2025-05-30 10:20:32"</code></pre><h3>方法2：修改默认的可访问的NTP服务器</h3><p>执行以下命令，修改NTP服务器为<code>ntp2.aliyun.com</code>，也可以根据需要修改成单位内部的NTP服务器的域名或者ip地址。</p><pre><code class="bash">sudo  sed  -i  's|#*NTP=.*|NTP=ntp2.aliyun.com|g'   /etc/systemd/timesyncd.conf</code></pre><p>重启一下时间同步服务<code>systemd-timesyncd</code></p><pre><code class="bash">systemctl  restart systemd-timesyncd.service</code></pre><h3>方法3：安装补丁包</h3><p>(<code>原理同方法2，修改默认的NTP服务器为阿里云服务器</code>)</p><ol><li>下载补丁包 [<em>点击以下图片下载</em>]<br/><a href="https://link.segmentfault.com/?enc=nPVZUizckdnEzsRjrS3Uzw%3D%3D.CYzmjIQX2dsBJN62%2BPVlmWsz9rCnqmo6s4vR3z942mhWAejrshB849ZEGvIpP5pW626UoPmXvSoffao%2Fh80I4dtkgPmpafn6HqqhrM6jKpo%3D" rel="nofollow" target="_blank">&lt;img src="https://gxxc.wiki/wp-content/uploads/2025/05/image-1748580746389.png" alt="描述文字"&gt;</a><br/><code>如果以上无法下载，可以访问这里下载https://gxxc.wiki/kd/6642.html</code></li><li><p>安装补丁包<br/>解压补丁包后，进入deb包所在目录，双击deb包安装，<code>或者</code>使用以下命令安装：</p><pre><code class="bash">sudo  dpkg  -i  fix-timesync_1.0.0_all.deb</code></pre></li><li>安装完补丁包后，再查看一下时间<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047606493" alt="file" title="file" loading="lazy"/></li><li><p>建议将当前对的时间，同步到硬件RTC</p><pre><code class="bash">sudo  hwclock  -w</code></pre></li></ol><h2>三、原因分析</h2><p>日志显示无法连接到ntp服务器，读取硬件RTC时间<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047606494" alt="file" title="file" loading="lazy"/><br/>所以显示出不同的时间。而systemd-timesyncd 这个服务本身不会将当前系统时间时间写入硬件RTC，所以时间过去越久，硬件时间与实际时间相差越多，当系统无法从默认的ntp服务器获取到正确时间的时候，就会用硬件时间，从而时间有差异。</p><h2>四、其他</h2><p>systemd-timesyncd 这个服务本身不会将当前系统时间时间写入硬件RTC。所以，建议用户每过一段时间后手动将当前时间同步到硬件上，可以执行命令<code>timedatectl</code>查看当前硬件时间<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047606495" alt="file" title="file" loading="lazy"/><br/>如果硬件时间和当前系统时间相差较大，可以先将系统时间设置正确后，执行以下命令将当前时间同步到硬件RTC</p><pre><code class="bash">sudo  hwclock  -w</code></pre><p>本文由<a href="https://link.segmentfault.com/?enc=yEFAdK92wWX45DKLLb8xBA%3D%3D.0G4rsjSzI36QFd%2BXQPC8umZ0ZX46zc728yEUywgspYA%3D" rel="nofollow" target="_blank">mdnice</a>多平台发布</p>]]></description></item><item>    <title><![CDATA[麒麟服务器【无法识别U盘的处理】 沙鱼 ]]></title>    <link>https://segmentfault.com/a/1190000047606708</link>    <guid>https://segmentfault.com/a/1190000047606708</guid>    <pubDate>2026-02-12 10:03:31</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>问题描述</h2><p>将 U 盘插入电脑后，系统没有自动挂载，并且在文件管理器中看不到该 U 盘设备。经常在用ventoy做了系统启动盘的U盘上，常常遇到这个问题，请看以下解决方法。</p><h2>解决办法</h2><h3>方法1</h3><p>将U盘格式化成ext4格式后使用，注意格式化前备份U盘里的重要数据。</p><h3>方法2</h3><p>系统默认无法识别到exfat格式的硬盘，需要安装fuse-exfat这个软件包解决对exfat格式u盘的支持，安装命令如下：</p><pre><code class="bash">yum  install  -y  fuse-exfat</code></pre><p>如果服务器不联外网，可以下载安装包后，拷贝到系统上离线安装，下面是x86架构下的路径<code>(arm的把x86_64修改成aarch64即可)</code>：</p><blockquote>V10-SP1: <a href="https://link.segmentfault.com/?enc=i65SoJaESCWJKCz4tAYxMA%3D%3D.20tcX4dvYYuFziY6fCtPYmnzFgNWu8pTtvZVgHT%2BEJVw1A%2BIHZuHbFQWj1HEtvMtNr00KmBaoR4qP57KcQ4EXzeBL3Iuz%2Fbj6BWlwGxHfIc%3D" rel="nofollow" target="_blank">https://update.cs2c.com.cn/NS/V10/V10SP1/os/adv/lic/base/x86_...</a><br/>V10-SP2: <a href="https://link.segmentfault.com/?enc=wdu%2FdUGlgtKOU1cfXCTFUw%3D%3D.Vf6QrIpwQJ2MBWRjkvfSIW%2BAqlqWFCjHwCd0PK2SXU2sbFdTefTfSh0mI5fIFEPMM6cWDxXZ%2BJ0Oc6nF6cMUxOsEAUw%2FPRcBn0otVp5yrtg%3D" rel="nofollow" target="_blank">https://update.cs2c.com.cn/NS/V10/V10SP2/os/adv/lic/base/x86_...</a><br/>V10-SP3: <a href="https://link.segmentfault.com/?enc=7k4C6gixYuKvSO9U23t9iQ%3D%3D.27dk0LxzbNYZH1b8rQZH9VqqM9mKK8WNsuo5FuiiLjFk%2FqgYgN%2BCPaMn8ZXfL7opkDbNGQg%2FxEfYJ5y3KmCCfVTQgAaZsZhOZevslgHQX48%3D" rel="nofollow" target="_blank">https://update.cs2c.com.cn/NS/V10/V10SP3/os/adv/lic/base/x86_...</a></blockquote><p>`有客户又说了，我的U盘都读不出来，下载后，怎么拷贝到服务器里？<br/>  这里咱们建议可以格式化U盘成其他格式拷贝，也可以通过刻录进CD盘再拷贝到服务器，或者也可以挂iso配置本地源进行安装`<br/> </p><h4>方法3</h4><p>执行 “lsblk” 命令查看是否能检测到 U 盘设备，<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047606711" alt="file" title="file"/><br/>如果能检测到但未挂载，如上图所示，可以执行以下命令，将u盘挂载到/mnt目录下，用命令访问/mnt看看是否能够访问。</p><pre><code class="bash">sudo  mount  /dev/sdb1  /mnt</code></pre><p>这里假设 U 盘设备名为 <code>sdb1</code>，请根据实际情况修改；</p><blockquote>如果以上方法还是检测不到，可能是 U 盘故障或者其他原因，可尝试更换其他 U 盘。</blockquote><p>本文由<a href="https://link.segmentfault.com/?enc=ihiRMCNJjZsMLyk28X%2B%2F4Q%3D%3D.HVIEMgbNp0xNBoUCGlg8pO0Ro74qAoteG78zznp83Lg%3D" rel="nofollow" target="_blank">mdnice</a>多平台发布</p>]]></description></item><item>    <title><![CDATA[麒麟桌面系统【笔记本电池容量和损耗】 沙鱼 ]]></title>    <link>https://segmentfault.com/a/1190000047606715</link>    <guid>https://segmentfault.com/a/1190000047606715</guid>    <pubDate>2026-02-12 10:02:52</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>麒麟桌面操作系统，如何通过命令查看笔记本电池使用情况，我们可以通过upower命令，默认安装有，如果没有该命令，可以通过以下命令安装</p><pre><code class="bash">sudo  apt  install  upower</code></pre><h3>查看命令：</h3><pre><code class="bash">upower -i `upower -e | grep 'BAT'`</code></pre><h3>输出如下：</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047606718" alt="" title=""/></p><p>本文由<a href="https://link.segmentfault.com/?enc=BewFWOlI2pwRbp59vwpJQA%3D%3D.oGPgkRvUKoQpJ4ZWNI2%2B2UHGrzyazf%2Fp3OrRJuvnFX8%3D" rel="nofollow" target="_blank">mdnice</a>多平台发布</p>]]></description></item><item>    <title><![CDATA[秒杀活动时系统在干什么 PHP 高并发场景优化指南 JaguarJack ]]></title>    <link>https://segmentfault.com/a/1190000047606819</link>    <guid>https://segmentfault.com/a/1190000047606819</guid>    <pubDate>2026-02-12 10:02:20</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>秒杀活动时系统在干什么 PHP 高并发场景优化指南</h2><p>秒杀活动是电商平台的关键战役，往往会带来流量和订单的剧烈飙升。秒杀期间，每一毫秒都很关键，后端需要同时扛住海量请求。对 PHP 应用来说，这尤其有挑战性，但只要优化到位，即使流量洪峰来了，用户体验也能稳住。</p><p>这篇文章会拆解 PHP 后端在秒杀期间需要做哪些事情：从数据库查询优化，到缓存管理，再到应用扩容。</p><h3>用负载均衡应对高并发</h3><p>秒杀期间，PHP 应用需要动态扩容来承接激增的流量。负载均衡是把请求分散到多台服务器的核心手段。</p><h4>负载均衡 + 自动扩容</h4><p>流量暴涨时，PHP 应用应该部署在负载均衡器（比如 AWS ELB 或 NGINX）后面，由负载均衡器把请求均匀分发到多台应用服务器。</p><p>工作原理：</p><ul><li><strong>PHP-FPM 工作进程</strong>：每台 PHP 服务器通过 PHP-FPM（FastCGI 进程管理器）处理请求。负载均衡器确保请求被分散到多台服务器，避免单台服务器被打垮。</li><li><strong>自动扩容</strong>：流量上来后，AWS EC2 Auto Scaling 或 Google Cloud Compute Engine 等云服务会自动拉起更多 PHP 实例来承接负载。</li></ul><p><strong>配置自动扩容</strong>：当 CPU 使用率或请求量超过阈值时触发扩容。</p><pre><code class="bash">aws autoscaling create-auto-scaling-group \
  --auto-scaling-group-name php-flash-sale-group \
  --min-size 2 --max-size 50 --desired-capacity 10 \
  --vpc-zone-identifier subnet-xyz</code></pre><p><strong>负载均衡器配置</strong>：确保请求被高效地分发到所有 PHP 服务器。</p><pre><code class="nginx">upstream php_backend {
    server php-server-1;
    server php-server-2;
    server php-server-3;
}
server {
    location / {
        proxy_pass http://php_backend;
    }
}</code></pre><p>通过负载均衡加自动扩容，PHP 后端可以平滑地应对秒杀期间的流量洪峰。</p><h3>缓存策略：减轻数据库压力</h3><p>秒杀期间最大的挑战之一，就是防止数据库因为大量读写操作变成瓶颈。最有效的手段是用缓存来分担数据库查询，同时提升响应速度。</p><h4>缓存静态内容和数据库查询</h4><p><strong>CDN 缓存静态资源</strong></p><p>图片、CSS、JavaScript 这类静态资源应该通过 CDN（比如 Cloudflare 或 AWS CloudFront）在边缘节点缓存，保证用户能快速加载。在 PHP 中设置合适的缓存控制头：</p><pre><code class="php">header("Cache-Control: public, max-age=3600");  // Cache static assets for 1 hour</code></pre><p><strong>内存缓存热点数据</strong></p><p>用 Redis 或 Memcached 缓存频繁查询的数据，比如商品库存和价格，减少数据库压力。</p><p>秒杀期间，把商品库存状态存到 Redis 里，每次查库存就不用打数据库了：</p><pre><code class="php">$redis = new Redis();
$redis-&gt;connect('localhost', 6379);
// Check if product availability is cached
$productId = 123;
$productAvailability = $redis-&gt;get("product:{$productId}:availability");
if (!$productAvailability) {
    // Cache miss, fetch from database
    $productAvailability = fetchProductAvailabilityFromDb($productId);
    $redis-&gt;set("product:{$productId}:availability", $productAvailability, 3600);  // Cache for 1 hour
}</code></pre><p>这样可以大幅减少秒杀期间的数据库查询次数，用户的响应速度也更快。</p><h3>优化数据库性能</h3><p>数据库性能往往是秒杀场景的瓶颈所在，特别是大量请求同时读写数据库的时候。优化查询、确保 PHP 应用高效处理数据库操作至关重要。</p><h4>分库分表</h4><p>分库分表是把数据库拆分成更小、更易管理的部分，每个部分只处理一部分数据，从而把查询分散到多个数据库实例上。</p><p>比如可以按用户地区分库（北美用户和欧洲用户各用一套数据库），以此均衡负载。</p><h4>连接池</h4><p>每次请求都开关数据库连接会带来很大的开销。通过连接池复用数据库连接，可以显著降低这部分消耗。在 PHP 中，可以配置持久连接：</p><pre><code class="php">$mysqli = new mysqli("p:localhost", "username", "password", "database");</code></pre><h4>读写分离</h4><p>如果用了数据库主从复制（比如 MySQL Replication），可以配置 PHP 应用把读查询发到从库，写查询发到主库：</p><pre><code class="php">$readDb = new mysqli('read-replica-host', 'username', 'password', 'database');
$writeDb = new mysqli('primary-db-host', 'username', 'password', 'database');</code></pre><h4>查询优化</h4><p>秒杀期间要确保数据库查询经过优化：对高频查询字段（比如商品 ID、分类等）建好索引。在 PHP 中使用预处理语句可以提升查询执行效率：</p><pre><code class="php">$stmt = $mysqli-&gt;prepare("SELECT * FROM products WHERE id = ?");
$stmt-&gt;bind_param("i", $productId);
$stmt-&gt;execute();
$result = $stmt-&gt;get_result();
$product = $result-&gt;fetch_assoc();</code></pre><p>通过分库分表、连接池、读写分离和查询优化，可以防止数据库成为瓶颈，保证 PHP 应用在秒杀这种高并发场景下依然跑得动。</p><h3>会话管理和用户认证</h3><p>秒杀期间，用户能不能顺利加购、结账、登录，直接决定了转化率。会话管理必须针对高并发做优化。</p><h4>用 Redis 做会话持久化</h4><p>用 Redis 存储会话数据，这样即使请求被负载均衡器分发到不同的 PHP 服务器上，会话也不会丢失：</p><pre><code class="php">// Store session data in Redis
session_set_save_handler(new RedisSessionHandler($redis), true);
session_start();</code></pre><h4>用 JWT 做无状态认证</h4><p>用户登录和认证环节，可以用 JWT（JSON Web Token）来减轻会话存储的压力，实现无状态认证：</p><pre><code class="php">// Example of generating JWT token
$payload = ['user_id' =&gt; $userId, 'exp' =&gt; time() + 3600];  // Expires in 1 hour
$jwt = JWT::encode($payload, $secretKey);</code></pre><p>把会话数据交给 Redis，认证环节用 JWT，就能保证秒杀期间的登录和会话管理又快又稳。</p><h3>实时库存管理</h3><p>秒杀期间，库存必须随着商品售出实时更新。PHP 需要确保库存数据在多台服务器之间保持同步，一旦有人下单，库存立刻扣减。</p><h4>事件驱动架构处理库存更新</h4><p>通过 Apache Kafka 或 RabbitMQ 实现事件驱动架构，实时处理库存变更：</p><pre><code class="php">// Kafka Producer: Send product purchase events
$producer-&gt;produce('product-purchased-topic', 0, json_encode(['product_id' =&gt; 123, 'quantity' =&gt; 1]));</code></pre><p>库存服务订阅这些事件，实时更新数据库中的商品库存。用户下单后，购买事件发送到 Kafka，库存服务收到事件后立即扣减库存，其他用户就不会再买到已经卖完的商品。</p><h3>总结</h3><p>秒杀期间保证 PHP 应用的性能，需要多管齐下：负载均衡、缓存、数据库优化、实时库存管理，缺一不可。通过自动扩容、Redis 内存缓存、高效的数据库查询和事件驱动架构，PHP 应用完全有能力扛住流量洪峰，给用户提供流畅的体验。</p><p>把这些手段用好，你的电商平台就能顶住秒杀的压力，不宕机、不卡顿，把转化率拉到最高。</p><p><a href="https://link.segmentfault.com/?enc=NH2dV4vsgaWiL8P358Nd5g%3D%3D.B7vTFWaeZ2%2BuQYeKJruA5zEI4XA5Ags8%2B%2FqahwxIXnvKoYkc5sJ2VS7yysIJrKtQfTdW%2BKNqv0tpGbovPX%2FXxA%3D%3D" rel="nofollow" target="_blank">秒杀活动时系统在干什么 PHP 高并发场景优化指南</a></p>]]></description></item><item>    <title><![CDATA[酷监控！一款高颜值的监控工具！ Java陈序员 ]]></title>    <link>https://segmentfault.com/a/1190000047606859</link>    <guid>https://segmentfault.com/a/1190000047606859</guid>    <pubDate>2026-02-12 10:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>大家好，我是 <code>Java陈序员</code>。</p><p>在如今数字化运营时代，服务的稳定性直接决定用户体验。但搭建一套完善的服务监控体系往往门槛不低：要么是专业监控工具配置复杂、学习成本高，要么是轻量工具功能单一，难以覆盖全场景需求。</p><p>今天，给大家推荐一款高颜值的监控系统工具，轻量易部署！</p><blockquote>关注微信公众号：【Java陈序员】，获取<strong>开源项目分享、AI副业分享、超200本经典计算机电子书籍等。</strong></blockquote><h2>项目介绍</h2><p><code>coolmonitor</code> —— 酷监控，一个高颜值的监控工具，支持网站监控、接口监控、HTTPS 证书监控等多种监控类型，帮助开发者及运维人员实时掌握网站、接口运行状态。</p><p><strong>功能特色</strong>：</p><ul><li><strong>多维度监控覆盖</strong>：支持 HTTP、HTTPS 网站、API 接口、HTTPS 证书过期、TCP 端口、MySQL、Redis 数据库等多种监控</li><li><strong>多渠道通知配置</strong>：支持邮件、Webhook、微信、钉钉、企业微信等多类型通知渠道</li><li><strong>便捷的操作体验</strong>：响应式布局，适配桌面、平板、移动端，支持深色、浅色主题切换</li><li><strong>数据可视化</strong>：监控数据支持可视化展示，通过 ECharts 生成响应时间趋势图，支持按小时、天维度查看</li><li><strong>持久化存储</strong>：采用 SQLite 轻量数据库，监控配置、运行数据持久化存储，轻量级部署无需额外依赖</li></ul><h2>快速上手</h2><p><code>coolmonitor</code> 支持 Docker 部署，可通过 Docker 快速部署。</p><p>1、拉取镜像</p><pre><code class="bash">docker pull star7th/coolmonitor:latest</code></pre><p>2、创建挂载目录</p><pre><code class="bash">mkdir -p /data/software/coolmonitor</code></pre><p>3、运行容器</p><pre><code class="bash">docker run -d \
    --name coolmonitor \
    -p 3333:3333 \
    -v /data/software/coolmonitor:/app/data \
    star7th/coolmonitor:latest</code></pre><p>4、容器运行成功后，浏览器访问</p><pre><code class="bash">http://{IP/域名}:3333</code></pre><p>5、根据引导，设置管理员账号密码，完成系统初始化</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047606861" alt="" title=""/></p><h2>功能体验</h2><ul><li><strong>主面板</strong></li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047606862" alt="" title="" loading="lazy"/></p><ul><li><strong>监控详情页</strong></li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047606863" alt="" title="" loading="lazy"/></p><ul><li><strong>添加监控项</strong></li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047606864" alt="" title="" loading="lazy"/></p><ul><li><strong>添加通知方式</strong></li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047606865" alt="" title="" loading="lazy"/></p><ul><li><strong>状态页</strong></li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047606866" alt="" title="" loading="lazy"/></p><p><code>coolmonitor</code> 没有复杂的配置项，能覆盖日常监控的核心需求，颜值高、易部署、易维护，不管是个人开发者监控自己的小网站，还是中小企业监控内部服务，都非常适用。快去部署体验吧~</p><pre><code class="bash">项目地址：https://github.com/star7th/coolmonitor</code></pre><h2>最后</h2><p>推荐的开源项目已经收录到 <code>GitHub</code> 项目，欢迎 <code>Star</code>：</p><pre><code>https://github.com/chenyl8848/great-open-source-project</code></pre><p>或者访问网站，进行在线浏览：</p><pre><code>https://chencoding.top:8090/#/</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000046659706" alt="" title="" loading="lazy"/></p><p><strong>我创建了一个开源项目交流群，方便大家在群里交流、讨论开源项目</strong>。</p><p><strong>但是任何人在群里打任何广告，都会被 T 掉</strong>。</p><p><strong>如果你对这个交流群感兴趣或者在使用开源项目中遇到问题，可以通过如下方式进群</strong>：</p><p><strong>关注微信公众号：【Java陈序员】，回复【开源项目交流群】进群，或者通过公众号下方的菜单添加个人微信，并备注【开源项目交流群】，通过后拉你进群</strong>。</p><blockquote>大家的点赞、收藏和评论都是对作者的支持，如文章对你有帮助还请点赞转发支持下，谢谢！</blockquote><hr/>]]></description></item><item>    <title><![CDATA[剑指offer-76、删除链表的节点 SevenCoding ]]></title>    <link>https://segmentfault.com/a/1190000047598564</link>    <guid>https://segmentfault.com/a/1190000047598564</guid>    <pubDate>2026-02-12 09:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>题⽬描述</h2><p>给定单向链表的头指针和⼀个要删除的节点的值，定义⼀个函数删除该节点。返回删除后的链表的头节点。</p><ol><li>此题对⽐原题有改动</li><li>题⽬保证链表中节点的值互不相同</li><li>该题只会输出返回的链表和结果做对⽐，所以若使⽤ C 或 C++ 语⾔，你不需要 free 或 delete 被删除的节点</li></ol><p>数据范围:</p><ul><li>0&lt;=链表节点值&lt;=10000</li><li>0&lt;=链表⻓度&lt;=10000</li></ul><p>示例1</p><pre><code class="txt">输⼊：{2,5,1,9},5
返回值：{2,1,9}
说明：给定你链表中值为 5 的第⼆个节点，那么在调⽤了你的函数之后，该链表应变为 2 -&gt; 1 -&gt; 9</code></pre><p>示例2</p><pre><code class="txt">输⼊：{2,5,1,9},1
返回值：{2,5,9}
说明：给定你链表中值为 1 的第三个节点，那么在调⽤了你的函数之后，该链表应变为 2 -&gt; 5 -&gt; 9</code></pre><h2>思路及解答</h2><h3>虚拟头节点</h3><p>如果要删除链表⾥⾯的⼀个节点，其实就是将前置节点的next 直接指向当前节点的后置节点，这样在链表中再也找不到该节点了，也就是相当于删除了。</p><p>假设有⼀个链表，我们需要删除⾥⾯的 5 :</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047598566" alt="" title=""/></p><p>⾸先需要判断链表头结点是不是为空，如果为空，那么就直接返回NULL ，如果等于我们要找的，那么直接返回下⼀个节点引⽤即可。</p><p>如果不符合以上说的，那么我们需要新建⼀个前置节点pre ,与现在的链表连接在⼀起：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047598567" alt="" title="" loading="lazy"/></p><p>然后初始化⼀个 cur 节点表示当前节点，指向 head 节点：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047598568" alt="" title="" loading="lazy"/></p><p>cur 不为空， cur 和 pre 后移：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047598569" alt="" title="" loading="lazy"/></p><p>发现 cur 正是我们需要查找的 5 ，那么记录下 5 的下⼀个节点 1 ,也就是next :</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047598570" alt="" title="" loading="lazy"/></p><p>cur 的 next 指向 NULL ,使⽤ pre 的 next 指向刚刚记录的 next :</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047598571" alt="" title="" loading="lazy"/></p><p>简化链表也就是：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047598572" alt="" title="" loading="lazy"/></p><p>取之前虚拟的头结点的后⼀个节点，就是删除掉之后的新链表：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047598573" alt="" title="" loading="lazy"/></p><pre><code class="java">class ListNode {
    int val;
    ListNode next = null;
    public ListNode(int val) {
        this.val = val;
    }
}

public class Solution13 {
    public ListNode deleteNode(ListNode head, int val) {
        if (head == null) {
            return null;
        }
        
        if (head.val == val) {
            return head.next;
        }
        
        // ⽤⼀个节点将头结点链接起来
        ListNode pre = new ListNode(-1);
        pre.next = head;
        ListNode cur = head;
        ListNode next = null;
        while (cur != null) {
            if (cur.val == val) {
                // 将前置节点直接连接后⼀个节点，相当于删除掉了该节点
                pre.next = cur.next;
                break;
            }
            cur = cur.next;
            pre = pre.next;
        }
        return head;
    }
}</code></pre><h3>迭代</h3><p>通过遍历链表找到目标节点并修改指针，维护前驱指针，当找到目标节点时修改指针跳过该节点</p><pre><code class="java">public class Solution {
    public ListNode deleteNode(ListNode head, int val) {
        // 处理头节点就是要删除的节点的情况
        if (head != null &amp;&amp; head.val == val) {
            return head.next;
        }
        
        ListNode prev = null;
        ListNode curr = head;
        
        // 遍历查找目标节点
        while (curr != null &amp;&amp; curr.val != val) {
            prev = curr;
            curr = curr.next;
        }
        
        // 找到目标节点后跳过它
        if (curr != null) {
            prev.next = curr.next;
        }
        
        return head;
    }
}</code></pre><ul><li><strong>时间复杂度</strong>：O(n)，最坏情况下需要遍历整个链表</li><li><strong>空间复杂度</strong>：O(1)，只使用常数空间</li></ul><h3>递归</h3><p>当前节点是要删除的节点则返回next，否则递归处理剩余链表</p><pre><code class="java">public class Solution {
    public ListNode deleteNode(ListNode head, int val) {
        // 递归终止条件
        if (head == null) {
            return null;
        }
        
        // 当前节点是要删除的节点
        if (head.val == val) {
            return head.next;
        }
        
        // 递归处理剩余链表
        head.next = deleteNode(head.next, val);
        return head;
    }
}</code></pre><ul><li><strong>时间复杂度</strong>：O(n)，需要处理每个节点</li><li><strong>空间复杂度</strong>：O(n)，递归调用栈的深度</li></ul>]]></description></item><item>    <title><![CDATA[零售行业 SRM 系统推荐榜单（2026版）——供应商管理全景指南 SaaS圈老马 ]]></title>    <link>https://segmentfault.com/a/1190000047600121</link>    <guid>https://segmentfault.com/a/1190000047600121</guid>    <pubDate>2026-02-12 08:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>做零售的都懂，供应商管理往往是企业运营中最繁杂、最耗时间的那一块——品类多、供应商多、对账频繁，还得实时盯供货节奏。尤其在当前线上线下融合加速的趋势下，靠 Excel 表格管供应商管理早已跟不上节奏。为了帮助零售企业快速建立科学、高效的供应商管理体系，本文整理了一份<strong>2026年适配零售行业的 SRM 系统推荐榜单</strong>，为企业选型提供实用参考。</p><p><strong>一、什么是 SRM 系统？为何对零售如此关键</strong></p><p>在进入推荐之前，先明确一个核心概念：<strong>SRM</strong> 系统是用来管理供应商全生命周期的一套软件解决方案。它的目标是帮助企业从供应商准入、绩效管理、风险监控，到日常协同、合同与对账等业务流程，实现数字化、标准化和可视化管理。</p><p>在零售行业，这类系统尤为重要，因为：</p><p>（1）零售企业的采购品类极其杂乱，SKU 数量庞大，供应商类型多样，从品牌方、大型经销商到小型供应商与加工厂，管理复杂度高；</p><p>（2）线上线下库存变动快，促销、季节性业务强，供货节奏必须准确把握；</p><p>（3）对账频率高、数据核对工作量巨大，若没有系统支持，很难避免账目不清、对账延迟等问题；</p><p>（4）供应商绩效评估和风险预警体系不足会直接影响供货稳定性。</p><p><strong>SRM 系统的价值不仅是“管数据”，更是帮助企业提升供应链协同效率、降低风险、提升供应商价值贡献、实现战略采购的长期平台。</strong></p><p><strong>二、零售行业 SRM 系统推荐榜单</strong></p><p>在众多 SRM 平台中，我们结合零售行业的典型需求（如多门店协同、库存节奏与采购链路紧密联动、促销物资临时采购、大宗物料管理等）进行了评估，推荐了以下几款系统：</p><p><strong>1 正远科技 — </strong><strong>零售全场景低代码定制 SRM 方案</strong></p><p><strong>推荐指数：★★★★★</strong><br/><strong>适用规模：大型连锁 / 区域连锁 / 新零售集团</strong></p><p>正远科技 SRM 的最大特色是<strong>低代码可编排架构</strong>，支持业务人员通过拖拽可视化方式快速调整流程，而无需 IT 二次开发，适合零售企业业务变化频繁的特性。</p><p>在零售行业的典型场景中：</p><p>（1）促销临时采购流程、临时物料变更、赠品采购等审批流可快速调整；</p><p>（2）多区域采购需求与多门店执行协同无缝衔接；</p><p>（3）门店数据、仓储、ERP、对账系统之间实现实时协同。</p><p>在供应商生命周期管理上，它支持从供应商准入、评级、评级调整到淘汰全流程闭环控制，同时具备实时风险监控能力，有助于减少因供应商突发状况导致的断货风险。在订单与执行层面，系统支持 VMI 库存管理和条码收货，这对门店稀散、收货点多的零售企业尤为重要。真正实现采购订单、物流路径、对账流水在一个协同大平台中的柔性联动。</p><p><strong>亮点功能：</strong></p><p>（1）低代码可视化流程自定义；</p><p>（2）支持类电商化采购商城；</p><p>（3）与 ERP、OA、企业微信、工作流无缝集成；</p><p>（4）提供实时供货节奏监控与预警。</p><p>该系统在实际落地案例中，能有效缩短采购周期、提升对账效率，在部分零售企业中采购周期平均缩短约 40% 以上，供应链协同效率显著提高。<br/><img width="723" height="374" referrerpolicy="no-referrer" src="/img/bVdnS7Y" alt="" title=""/></p><p><strong>2 甄云科技 — </strong><strong>AI 驱动智能采购 SRM</strong></p><p><strong>推荐指数：★★★★☆</strong><br/><strong>适用规模：大型 / 规模化零售企业</strong></p><p>甄云科技的 SRM 最大亮点在于<strong>AI 与大数据的深度嵌入</strong>。在零售行业常见的“品类杂，价格波动快”的场景下，甄云的智能比价和风控引擎能够帮助企业在采购阶段快速筛选、比价与评估供应商。</p><p>例如，它的 AI 比价工具能在几秒内完成多平台的价格比对，并提供趋势分析，这对于价格敏感的零售采购极具价值，同时还能直接提升成本控制能力。系统还能对接大量外部监控数据，进行供应商风险预警。</p><p><strong>优势特点：</strong></p><p>（1）跨平台智能比价与采购成本预警；</p><p>（2）实时风险监测与供应商健康得分；</p><p>（3）支持多语言、多币种，适合跨境采购；</p><p>（4）与 ERP/WMS 等多生态系统集成。</p><p>甄云科技 SRM 的标准化程度较高，对于流程规范、企业规模较大的零售集团尤为适合。但对于需要深度业务定制的场景，其灵活度略逊与更开放的低代码平台。<br/><img width="723" height="383" referrerpolicy="no-referrer" src="/img/bVdnS7Z" alt="" title="" loading="lazy"/></p><p><strong>3 鲸采云 — </strong><strong>中小零售轻量化 SaaS 优选方案</strong></p><p><strong>推荐指数：★★★★☆</strong><br/><strong>适用规模：中小零售 / 区域连锁</strong></p><p>鲸采云定位轻量化 SaaS SRM，其操作门槛低、部署迅速，非常适合中小型零售企业。系统覆盖了从供应商准入、绩效评估到采购执行的基本 SRM 模块，同时内置了标准的供应商数据管理能力，支持扫码收货、智能补货、分门店采购协同等功能。</p><p>针对中小企业常见的“预算有限、没有 IT 团队”的情况，该系统提供了丰富的第三方插件接口，可以与金蝶、用友等主流财务系统无缝对接，并支持与钉钉、企业微信等移动办公系统联动。</p><p><strong>适配亮点：</strong></p><p>（1）快速上手、低门槛 SaaS 方案；</p><p>（2）支持采购商城式下单体验；</p><p>（3）集成主流办公和财务系统插件；</p><p>（4）门店与总部协同集中管理功能完整。</p><p>对于采购流程相对稳定、供应商数量适中、对高级定制需求不高的中小零售企业，这款系统性价比较高。<br/><img width="723" height="362" referrerpolicy="no-referrer" src="/img/bVdnS70" alt="" title="" loading="lazy"/></p><p><strong>4 用友采购云 — </strong><strong>ERP 生态深度联动 SRM</strong></p><p><strong>推荐指数：★★★★☆</strong><br/><strong>适用规模：已部署用友 ERP 的零售企业</strong></p><p>用友采购云的优势在于与其 ERP 大生态产品深度集成，能将采购流程、生意账务和库存管理紧密联动，从而避免信息孤岛和重复录入工作。通过自动化审批与财务联动，可显著提升合规性与对账效率。</p><p>特别是在跨区域、跨业务单元的零售企业，用友采购云对不同业务模式的支持能力很强，例如多税制处理、合同自动生成、应付账款自动管理等。</p><p><strong>主要优势：</strong></p><p>（1）深度 ERP / 财务系统集成；</p><p>（2）自动化审批与合规管理；</p><p>（3）支持全球采购与跨币种场景；</p><p>（4）对账流程全链路自动化。</p><p>对于已经在用友系统中的零售企业来说，该系统可以<strong>最大限度减少 ERP 与 SRM 之间的数据不一致情况</strong>。<br/><img width="723" height="376" referrerpolicy="no-referrer" src="/img/bVdnS71" alt="" title="" loading="lazy"/></p><p><strong>5 企企通 — </strong><strong>SRM + 供应链金融结合的特定场景解决方案</strong></p><p><strong>推荐指数：★★★☆☆</strong><br/><strong>适用规模：资金链压力大的中小企业</strong></p><p>企企通的特色在于其 SRM 平台与供应链金融服务的结合，可以为合作供应商提供融资支持，从而在一定程度上稳定供应链。对于一些资金压力较大、对现金流敏感的中小零售企业，这种功能尤其有价值。</p><p>该系统在供应商管理、订单协同、物流跟踪等基础功能之外，加强了资金服务联动，例如供应商融资额度展示、资金通道对接等。对于希望通过供应链金融提升供货稳定性和合作紧密度的企业是一大加分项。</p><p>但在行业专属功能方面，例如临时促销物资管理、多门店库存节奏优化等方面不如前几款完善，因此更适合<strong>采购流程相对简单、希望补贴供应链现金流的中小企业</strong>。<br/><img width="723" height="366" referrerpolicy="no-referrer" src="/img/bVdnS72" alt="" title="" loading="lazy"/></p><p><strong>五、选型小贴士与实施建议</strong></p><p>（1）<strong>先从业务优先级出发，不要盲目追求花哨功能</strong>：比如对账自动化、风险预警、门店端补货支持，这些是零售企业最基础的痛点。</p><p>（2）<strong>试用是必须的</strong>：任何系统的卖点再好，若实际操作繁琐、不贴合业务流程，那么 ROI 很难体现。</p><p>（3）<strong>数据迁移与集成成本要提前评估</strong>：老系统迁移、新系统上线与现有库存、财务数据的集成成本往往被低估。</p><p>（4）<strong>长期战略要考虑扩展性</strong>：是否支持未来供应链升级，这是构建企业竞争力的关键。</p><p><strong>六、结语</strong></p><p>供应商管理是零售企业运营效率的核心组成部分，也是企业实现精细化运营和供应链协同的战略基础。<strong>选对 SRM 系统等于为企业供应链打下坚实的数字化基础</strong>。<br/>本文整理的榜单结合了国内 SRM 供应商和国际通行的优秀方案，同时结合零售行业具体特征，为不同规模和发展阶段的零售企业提供实用选型参考。</p>]]></description></item><item>    <title><![CDATA[Copilot 2026 完全指南：2026 年了，它凭什么还是月活第一的 AI 编程助手？ 卡尔A]]></title>    <link>https://segmentfault.com/a/1190000047606576</link>    <guid>https://segmentfault.com/a/1190000047606576</guid>    <pubDate>2026-02-11 22:04:03</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>本文共 5200 字，阅读预计需要 6 分钟。</p><p>编程 IDE 赛道卷成红海，Cursor、Claude Code、Google AI Studio 各有拥趸。但 Copilot 在 2026 年依然稳坐月活第一的位置，它凭什么？</p><p>这篇文章，从我个人深度使用的体验出发，<strong>拆解 Copilot 的三个核心优势、三个明显劣势、以及六个核心特性的实战用法</strong>——帮你判断，它到底适不适合你。</p><p><img width="474" height="474" referrerpolicy="no-referrer" src="/img/bVdnUNB" alt="" title=""/></p><p><strong>一次 Cursor 账单，让我彻底想明白了</strong></p><p>先说一件真事。</p><p>前几天，我在 Cursor Max 模式下，开了 Plan 模式，用 Claude Opus 4.6 重构一个项目的页面样式。</p><p>一次 Plan 制定，一次 Plan 修改，再加上按照 Plan 执行工作。</p><p><strong>三个步骤，花掉了十几刀的 token 费用。</strong></p><p><img width="723" height="145" referrerpolicy="no-referrer" src="/img/bVdnUNC" alt="" title="" loading="lazy"/></p><p>然后我算了一下，这三个步骤如果在 Copilot 里做，就是三次独立的调用。再乘以 Copilot 对 Opus 4.6 设置的系数 3，也就是消耗 9 次 premium request。</p><p><strong>而 Copilot 每月 10 美金的订阅套餐里，有 300 次这样的调用额度。</strong></p><p>换句话说，Cursor 里花十几刀干的活，Copilot 只扣了 9 次调用——连月度额度的 3% 都不到。</p><p>这个差距，让我彻底想明白了一件事：<strong>在长期、复杂项目使用的场景下，成本结构比单次能力更重要。</strong></p><p>说实在的，我不是说 Cursor 不好。Cursor 在很多方面确实更强，后面会讲到。但作为一个每天都要写代码、调研资料、做内容创作的人，我需要一个成本可控的主力工具，而不是每次点「执行」后都要关注token用量。</p><p><strong>三个让我留下来的理由</strong></p><p><strong>按次计费：O(1) 复杂度的成本控制</strong></p><p>Copilot 最核心的竞争力，就是它的按次计费逻辑。</p><p>每月 10 美金的 Pro 套餐，包含 300 次 premium request。即使超额，每次也只收 4 美分。</p><p>这意味着什么？</p><p>它不会因为你用了最贵的 Claude Opus 4.6，就让你反复盯着 token 用量看。它只是出于成本考虑，让一次调用消耗 3 次 premium request 的额度——但费用不会随 token 用量上涨而上涨。</p><p><img width="723" height="454" referrerpolicy="no-referrer" src="/img/bVdnUND" alt="" title="" loading="lazy"/></p><p>我喜欢用一个程序员都懂的类比：<strong>这就像 O(1) 复杂度的算法。</strong></p><p>不管你输入多大，成本是固定的。</p><p>相比之下，Cursor 的计费更接近 O(n)——输入越大，token 越多，费用越高。Cursor Pro 每月 20 刀，Pro+ 每月 60 刀，Ultra 每月 200 刀，而且这些套餐背后还是基于用量的逻辑。</p><p>在大型项目的重构修改、大量资料调研，或者长上下文的内容创作中，<strong>Copilot 的开销可能只有按 token 计费的几十分之一。</strong></p><p>对于经常要调用强模型做大型任务的开发者来说，这个差距是实打实的。</p><p><strong>新模型第一时间支持 + 无限 Tab 补全</strong></p><p>Copilot 对新模型的支持速度一直很快——只要厂商开放了 API，基本第一时间就能用上。</p><p><img width="669" height="1077" referrerpolicy="no-referrer" src="/img/bVdnUNE" alt="" title="" loading="lazy"/></p><p>而且 GPT-5 mini 、Gpt-4o等的调用和 Tab 代码补全，在 Pro 套餐里都是无限次数的。</p><p>这个"无限"很重要。Tab 补全可能是你写代码时每分钟都在用的功能，随手做点修改，增添个函数，如果这个也限次数，那体验会非常割裂。Copilot 在这一点上没有扣扣搜搜。</p><p>当然也有例外。比如 GPT-5.3 Codex并没有支持，但是这个的原因是 OpenAI 延迟开放 API 的老传统，现在三方 IDE 都用不了。</p><p><strong>GitHub 生态的原生力量</strong></p><p>这一点经常被忽略，但其实很关键。</p><p>Copilot 背靠微软和 GitHub，如果你平常接触开源比较多，它的生态整合是相当完整的。GitHub 的 issue、PR、仓库索引，都是原生集成的，<strong>不需要任何额外配置。</strong></p><p>Copilot 的 coding agent 在上线后的前 5 个月里，开发者用它合并了超过 100 万个 Pull Request。这个数字本身就说明了生态粘性。</p><p>另外，Copilot 对 Plan 模式和 Skills 的支持也做得不错。Plan 模式可以让模型先规划再执行，Skills 则是一个可扩展的工具提示词集合——比如 Anthropic 官方出的前端设计 Skill，可以显著提升 Copilot 做前端的效果。这些在后面的特性拆解里会详细讲。</p><p><strong>三个不可忽视的缺点</strong></p><p>说完优势，聊聊让我不太舒服的地方。</p><p><strong>前端样式：Copilot 的"审美盲区"</strong></p><p>这是最明显的短板。</p><p>Copilot 在前端样式、UI 设计这些方面，和 Cursor、Google AI Studio 的差距比较大。尤其是用 GPT 系列模型的时候，尤其是Codex，出来的页面效果。。。说实在的特别难评。</p><p>以下是我在copilot里，用GPT-5.1-Codex-Max，做的火柴人小游戏：</p><p><img width="723" height="372" referrerpolicy="no-referrer" src="/img/bVdnUNG" alt="" title="" loading="lazy"/></p><p>这个页面的设计审美真的有点过分了。。。</p><p>后来我接了 Anthropic 官方发的前端设计 Skill 之后，效果能好一些，但如果你真的要用 Copilot 做前端样式类的工作，<strong>最好还是切到 Claude Opus 来搞。包括写作，我个人体感更好的也是Claude的模型。</strong></p><p><strong>超大型任务：和 Cursor Max 的差距</strong></p><p>Copilot 的 Agent 模式在超大型任务上的执行力，和 Cursor 有一点差距。</p><p>虽然我个人体感这个差距很小，日常使用几乎感觉不到，但是，Cursor 开启 Max 模式后，是能感觉出来的——同样的任务，同样的模型，Cursor 对<strong>复杂项目、复杂任务的精确执行和精确理解</strong>做得要好一些。</p><p>而且，除了Gpt-5.2 Codex，<strong>copilot对其他模型的上下文limit基本都是128K</strong>，这也是限制它超长任务执行能力的关键。</p><p><img width="723" height="129" referrerpolicy="no-referrer" src="/img/bVdnUNH" alt="" title="" loading="lazy"/></p><p>甚至 Cursor 还有多 Agent 竞赛的功能，可以让多个 Agent 同时尝试不同方案，然后你选最好的那个。</p><p>这个"更强"的代价，也许是几十倍的成本，但在一些场景下是真的有对应的收益的。</p><p>所以这事得看你怎么算账：是为了 5% 的精度提升花数倍甚至数十倍的钱，还是用 Copilot 把 90% 的活先干了，剩下多去迭代几轮或者自己上？</p><p><strong>自定义规则和记忆：灵活度不够</strong></p><p>Cursor 有 rules 这样的系统，能做到项目级的规则配置，还有记忆功能来记住用户的编程偏好——比如你喜欢用什么命名规范、偏好什么代码风格，它都能记住。基本接一个cursor-memory-bank，就能很方便的实现。</p><p><img width="723" height="446" referrerpolicy="no-referrer" src="/img/bVdnUNI" alt="" title="" loading="lazy"/></p><p>Copilot 虽然也有 .github/copilot-instructions.md，但说实话，灵活度和粒度上差不少。</p><p>这就好比一个能记住你口味的老厨师，和一个每次都要重新告诉他"少盐少油"的新厨师。做出来的菜可能差不多，但沟通成本差很多。</p><p><strong>六个核心特性实战手册</strong></p><p>说了这么多宏观的优劣势，我们来看看 Copilot 各个核心特性的具体用法。<strong>这部分比较实操，建议收藏。</strong></p><p><strong>1. Tab 补全：最成熟，也最容易被低估</strong></p><p>Tab 补全是 Copilot 最早出名、也是最成熟的功能。订阅 Pro 之后无限次使用。</p><p>你在写代码的时候，它会实时预测你接下来要写的内容，按 Tab 就能接受建议。对于逻辑简单的函数，你甚至可以只写一行注释，然后靠 Tab 补全快速把代码写完。</p><p><img width="723" height="212" referrerpolicy="no-referrer" src="/img/bVdnUNJ" alt="" title="" loading="lazy"/></p><p>这个功能有几个小技巧，很多人不知道：</p><p><strong>第一，写好注释再写代码。</strong> 注释越清晰，补全质量越高。这其实就是在给模型做上下文工程——你的注释就是 prompt。</p><p><strong>第二，打开相关文件放在旁边的 Tab 里。</strong> Copilot 会自动把打开的文件当作上下文来参考。所以如果你在写一个调用其他模块的函数，把那个模块文件打开放旁边就行。</p><p><img width="723" height="215" referrerpolicy="no-referrer" src="/img/bVdnUNK" alt="" title="" loading="lazy"/></p><p><strong>第三，Ctrl+右箭头逐词接受。</strong> 如果补全的内容只对了一半，不用全盘接受或全盘拒绝，按 Ctrl+右箭头可以一个词一个词地接受。这个技巧能省很多手动修改的时间。</p><p><strong>2. Inline Chat：小范围精修利器</strong></p><p><img width="645" height="294" referrerpolicy="no-referrer" src="/img/bVdnUNL" alt="" title="" loading="lazy"/></p><p>在代码里按 Ctrl+I（Mac 上是 Cmd+I），可以直接在当前位置发起一次对话。</p><p>适合小范围的修改，比如"给这个函数加上错误处理"、"把这段逻辑重构成异步的"之类的。</p><p>它的好处是改完直接有 diff 预览，你可以逐行审查，不满意就撤销。比在聊天窗口里来回复制粘贴高效得多。</p><p><img width="597" height="327" referrerpolicy="no-referrer" src="/img/bVdnUNM" alt="" title="" loading="lazy"/></p><p>很多人常用 Chat 面板做小修改，但其实<strong>微调切到 Inline Chat 效率更高也更精准</strong>。</p><p><strong>3. Ask 模式：纯对话，不动代码</strong></p><p><img width="684" height="333" referrerpolicy="no-referrer" src="/img/bVdnUNN" alt="" title="" loading="lazy"/></p><p>Ask 模式就是侧边栏的对话窗口。在这里可以选模型、问问题、讨论方案。</p><p>它的特点是"纯对话，不动代码"——不会帮你直接改文件，<strong>但你可以引用工作区的文件给它</strong>。</p><p>我的习惯是，把需要的文件直接选中后，鼠标拖到对话框里，省掉复制粘贴。</p><p><img width="569" height="243" referrerpolicy="no-referrer" src="/img/bVdnUNO" alt="" title="" loading="lazy"/></p><p>不过，Copilot 对工作区的文件都有访问权限，显式引用只是提醒模型重点关注。多个项目的话，从左上角把文件夹添加到工作区即可。</p><p><img width="489" height="486" referrerpolicy="no-referrer" src="/img/bVdnUNP" alt="" title="" loading="lazy"/></p><p><strong>4. Agent 模式：核心中的核心</strong></p><p>Agent 模式是各个编程 IDE 最核心的功能，也是 Copilot 用得最多的模式。</p><p>在 Agent 模式下，Copilot 可以自主地读文件、写文件、跑终端命令、分析报错，然后迭代修复，直到任务完成。</p><p><strong>按次计费的爽感就体现在这里：即使迭代了特别多轮，它还是只收一次的费用。</strong></p><p>另外一个很实用的细节：Agent 模式里可以<strong>控制模型可用的工具</strong>。</p><p><img width="444" height="211" referrerpolicy="no-referrer" src="/img/bVdnUNQ" alt="" title="" loading="lazy"/></p><p>比如你只想让它帮你解决部署问题但不修改任何文件，可以把文件编辑的工具禁用掉。</p><p>这在生产环境排查问题的时候特别有用，<strong>相当于强制禁止文件修改。</strong></p><p><img width="700" height="366" referrerpolicy="no-referrer" src="/img/bVdnUNR" alt="" title="" loading="lazy"/></p><p><strong>5. Plan 模式：复杂任务专属</strong></p><p><img width="723" height="266" referrerpolicy="no-referrer" src="/img/bVdnUNS" alt="" title="" loading="lazy"/></p><p><strong>Plan 模式</strong>是专门用来做复杂任务的。</p><p>它会强制模型输出完整的执行计划，并且从执行来看会启动一些子 agent 来做信息收集，防止主 Agent 的上下文过长。</p><p>关键是：在你点击「Start Implementation」之前，你可以和模型反复对话来修改计划。</p><p><strong>即使你告诉它"现在开始执行任务"，只要还在 Plan 模式下，它还是只做计划生成。</strong></p><p>所以，「Start Implementation」本质上就是点击后，</p><p>1、帮你切换到了 Agent 模式，</p><p>2、把「Start Implementation」输入到输入框中</p><p>因此如果你读计划读得差不多了，<strong>自己手动切到 Agent 模式让它执行，效果是一样的。</strong></p><p>我的习惯是：<strong>涉及复杂的、大量文件改动的任务，都先让它出 Plan，确认没问题了再放手让它跑。</strong></p><p><img width="723" height="645" referrerpolicy="no-referrer" src="/img/bVdnUNT" alt="" title="" loading="lazy"/></p><p><strong>6. Skills：各IDE的“杀手级”功能</strong></p><p><strong>Skills</strong> 是近两个月，copilot刚支持的功能。</p><p><img width="723" height="347" referrerpolicy="no-referrer" src="/img/bVdnUNU" alt="" title="" loading="lazy"/></p><p>在设置中打开 userAgentSkills 的开关，把 Skills 文件下载到指定路径下，模型就能读取和使用这些 Skills 了。</p><p><img width="684" height="579" referrerpolicy="no-referrer" src="/img/bVdnUNV" alt="" title="" loading="lazy"/></p><p>比如 Anthropic 官方出的前端设计 Skill，能显著提升 Copilot 生成前端代码的质量。这其实就是一套精心设计的系统提示词，告诉模型在做前端任务时应该遵循哪些设计原则和最佳实践。</p><p><strong>写在最后：适合你的，才是最好的</strong></p><p>总结一下这一期的内容。</p><p>Copilot 的三个核心优势：<strong>按次计费成本可控、新模型支持快、GitHub 生态整合强。</strong></p><p>三个主要劣势：<strong>前端样式效果不好、超大型任务的执行力略逊、自定义规则和记忆能力不够灵活。</strong></p><p>六个核心功能的使用方法：<strong>Tab 补全、Inline Chat、Chat 面板里的 Ask、Agent 和 Plan 三种模式，以及 Skills。</strong></p><p>这些优缺点都很明显，没有哪个工具是完美的。关键是匹配你的场景。</p><p>我个人的建议是这样的：</p><p><strong>1、如果你经常做大型的后端项目，且频繁调用比较强的模型来做重构、修改之类的工作</strong> → Copilot 的按次计费逻辑会帮你省非常多的钱。这是它最核心的优势。</p><p><strong>2、如果你追求极致的执行精度，不太在乎 token 开销</strong> → Cursor 开 Max 模式确实体感更强，甚至可以开启多 Agent 竞赛的功能。但月均开支要做好心理准备。</p><p><strong>3、如果你更多是做小的演示 demo 或者 UI 设计</strong> → Google AI Studio 也许更适合你。免费额度够用，从想法到可运行的小项目特别快。</p><p>**总之，我的建议是组合着用。**Copilot 当主力省成本，Cursor Max 当精度补刀，Google AI Studio 做快速验证。</p><p>这套组合拳打下来，性价比是最高的。</p><p><strong>既然看到这了，如果觉得不错，随手点个赞、收藏、转发三连吧～</strong></p><p><strong>我是Carl，大厂研发裸辞的AI创业者，只讲能落地的AI干货。</strong></p><p><strong>关注我，更多AI趋势与实战，我们下期再见！</strong></p><p><img width="723" height="330" referrerpolicy="no-referrer" src="/img/bVdnUis" alt="" title="" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[Agent Lightning：微软开源的框架无关 Agent 训练方案，LangChain/Aut]]></title>    <link>https://segmentfault.com/a/1190000047606596</link>    <guid>https://segmentfault.com/a/1190000047606596</guid>    <pubDate>2026-02-11 22:03:31</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>Agent 搭建起来之后怎么让它真正变得越来越好？搭建完成后的优化就很少有人认真说过。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047606598" alt="" title=""/><br/>Agent Lightning 号称能把任何 AI Agent 变成"可优化的猛兽"，而且几乎不用改代码。那问题来了，市面上 Agent 框架满天飞这个凭什么就不一样呢？</p><h2>training gap</h2><p>做过 Agent 部署的人大概都有同感：把 Agent 跑起来其实没那么难，真正难的是让它持续进步。</p><p>OpenAI 的 Agent SDK、LangChain 这类编排框架，原型设计和快速部署确实很拿手。几个小时就能让一个能用的 Agent 上线。但到了优化这一步，用真实场景的反馈去训练 Agent、提升它的表现基本就只能靠自己摸索了。</p><p>微软的研究人员给这个问题起了个名字叫"training gap"。开发环境里跑得好好的 Agent一碰到真实用户、边缘场景和领域特有的问题性能就打折扣。传统框架能给你的帮助很有限：手动调 prompt，手动改参数，然后顺带祈祷别有问题。</p><p>而Agent Lightning 的切入点就在这里，它把 Agent 框架和优化基础设施做了解耦。微软的说法是这套方案"可以无缝地为任何现有 Agent 启用模型训练，无需对 Agent 代码做任何修改。"</p><h2>Agent Lightning 的工作原理</h2><p>Agent Lightning 在现有 Agent 代码和微软的 verl 训练基础设施之间插入了一层客户端-服务器架构。可以理解为一个翻译层：把 Agent 的交互记录转化成训练数据，优化完参数再塞回去。</p><p>具体流程是：Agent 照常运行，什么都不用改，但每一次交互都会被 Lightning 客户端截获。数据会传到 Lightning 服务器，服务器端跑强化学习、自动 prompt 优化、监督微调这些手段，再把改进后的参数推回到 Agent 里。</p><p>特别值得说的是框架的兼容性：LangChain、AutoGen、CrewAI、微软自家的 Agent Framework都能接。团队管它叫"Lightning AI Agent 的终极训练器"。</p><p>安装也是直接一个pip命令：</p><pre><code>pip install agentlightning</code></pre><p>。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047606599" alt="" title="" loading="lazy"/></p><h2>实际应用和用例</h2><p>最有说服力的场景是 Agent 需要适配私有数据或者特定行业需求的情况。通用预训练模型处理常规任务还行，碰到公司内部流程、行业“黑话”、独特的业务逻辑，就容易出问题。</p><p>拿客服 Agent 举例：它得学会你公司特有的工单升级流程、产品的各种坑、跟客户打交道的语气和方式。传统做法是手写 prompt 然后盼着它能泛化到各种情况。换成 Agent Lightning系统能直接从真实客户对话中学习，拿解决率、满意度评分、各项业务指标来自动优化响应策略。</p><p>代码生成也是个很适合的场景：Agent 在跟你的代码库、编码规范、开发流程不断交互的过程中，Agent Lightning 能持续微调模型，让它越来越贴合团队的具体要求。</p><p>搜索和检索类应用也一样，Agent 需要弄清楚哪些信息源对哪类查询最有价值、怎么按用户偏好排序结果、什么时候该转人工，这些都可以在实际使用中不断优化。</p><h2>竞争格局</h2><p>Agent Lightning 进入的赛道已经很拥挤了，但定位上有明确的差异化。别人在卷 Agent 编排和模型服务，而微软选择切入的是一个几乎没人认真做过的方向：优化。</p><p>Agent 优化可以说是平台策略的自然延伸，通过解决那些单纯做模型或做编排的玩家解决不了的问题，把开发者留在微软的生态里。</p><p>而且Agent Lightning 没有被包装成 Azure 的专属服务而是直接开源，这既展现了微软对自身平台能力的信心，也说明他们对推动这个领域发展有诚意。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047606600" alt="" title="" loading="lazy"/></p><h2>总结</h2><p>AI Agent 行业一直在解决"怎么搭"，却没认真回答"搭完之后怎么办"。而Agent Lightning 把开发和优化解耦这个思路填补了从 LangChain 到 AutoGen 这一批框架都没覆盖到的空白。</p><p>但是从版本能看得出来，0.1.2 版离生产级还有距离。但方向本身没问题，当 AI Agent 越来越多地承担关键业务，能持续从真实反馈中学习的 Agent 和不能的之间差距只会越拉越大。谁先跑通这条优化闭环，谁就拿到了下一阶段的门票。</p><p><a href="https://link.segmentfault.com/?enc=RYzO1TPOgfo084XpPgGTKQ%3D%3D.J4w%2FzlaM5Wz%2BnS7HGpUKd%2BHQWO1wniz7ZrLEraxpvu6XMYnTkyokx7C6kK3k%2FLeEvr6WIwphr5OjxdJZGg6sQQ%3D%3D" rel="nofollow" target="_blank">https://avoid.overfit.cn/post/eea592726e5940c29d80fadf9908b2e6</a></p><p>by Mandar Karhade</p>]]></description></item><item>    <title><![CDATA[《GraphQL批处理与全局缓存共享的底层逻辑》 程序员阿伟 ]]></title>    <link>https://segmentfault.com/a/1190000047606613</link>    <guid>https://segmentfault.com/a/1190000047606613</guid>    <pubDate>2026-02-11 22:02:57</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>微前端架构在分布式前端体系的深度落地过程中，跨应用数据请求的冗余分发已然成为制约前端整体效能提升的核心桎梏，传统碎片化的请求发起模式下，彼此解耦的微应用针对同源基础元数据的重复拉取行为，不仅持续加剧网络传输层的资源损耗与带宽占用，更会间接引发页面渲染时序的紊乱、前端状态的不同步等隐性架构问题，GraphQL批处理与缓存共享的融合落地方案，绝非对现有请求机制的表层修补与局部优化，而是从数据调度逻辑与状态共识构建的底层内核出发，彻底重构微前端体系内数据流转的核心范式。批处理机制的核心价值在于将离散化、碎片化的独立请求，转化为具备语义关联的聚合调度单元，彻底打破应用物理边界对请求链路的人为割裂，缓存共享则致力于搭建跨应用的全局数据共识层，让同源数据在整个微应用集群中实现一次采集、全域复用的理想状态。这一技术思路的本质是把数据请求从单一应用的独立行为，升级为整个架构层面的协同动作，从根源上消解重复请求生成的土壤，让微前端的数据交互回归高效、统一、可控的理想状态，也让前端架构从被动适配业务需求的底层形态，转向主动治理数据流转的高阶形态，在分布式前端体系中建立起数据流转的秩序感与稳定性，让每一次数据交互都能贴合架构的整体设计逻辑，而非无序消耗系统资源。</p><p>GraphQL批处理在微前端复杂场景中的落地，核心依托于对请求依赖的拓扑化深度分析与聚合粒度的精细化动态调控，在多微应用并行初始化的典型业务场景中，各类基础配置信息、核心主体元数据、全局权限规则等非业务独占型数据，成为跨应用重复请求的高发区域，批处理机制并非简单将多条独立请求机械合并为单一传输链路，而是先完成请求语义的精准归类与依赖关系的逐层拆解，严格区分实时性要求较高的动态数据与稳定性较强的静态数据，仅对同数据域、同执行优先级、同生命周期的请求执行聚合调度操作，同时完整保留每一条请求的独立响应解析能力，从机制上避免单一请求异常引发整体链路的响应故障。实践过程中通过精准界定请求的共享域标识，让批处理引擎能够精准识别可聚合的请求单元，既最大化保障请求合并带来的效能收益，又不破坏每一个微应用的数据独立性与业务自治性，让批处理成为适配微前端弹性架构的轻量化调度能力，也让请求聚合从机械合并的初级形态升级为语义驱动的智能调度形态，大幅提升数据交互的精准度与稳定性，让每一次网络传输都能实现资源利用的最大化，彻底规避无效请求与重复传输带来的资源内耗，让请求调度逻辑贴合微前端架构的解耦核心诉求。</p><p>微前端缓存共享体系的构建，核心是打造分层可控、逻辑清晰的跨应用状态共识体系，而非粗暴的全局数据拷贝与无差别共享，基于微前端基座的中继调度能力，将缓存体系划分为全局公共缓存、跨应用共享缓存、应用私有缓存三个逻辑层级，其中公共缓存专门承载全应用复用的基础元数据，共享缓存适配多应用协同的业务关联数据，私有缓存则全力保障单应用的业务隔离性与数据私密性。缓存共享的核心价值不在于存储本身，而在于跨应用的数据同步与一致性保障，通过语义化的缓存版本标识与轻量化订阅分发机制，实现缓存更新的全域无感同步，同时设计精细化的失效触发规则，结合数据更新事件与应用生命周期节点，主动清理过期缓存数据，避免脏数据在整个微应用集群中扩散。实践中通过基座的缓存代理层，统一管控缓存的读写操作与数据分发流程，让微应用无需感知底层缓存的实现细节，仅通过标准化接口即可获取共享数据，大幅降低跨应用数据协同的适配成本，也让缓存管理从分散失控的初级形态转向集中可控的架构级能力，在多应用共存的复杂环境中持续维持数据状态的统一与可信，为微前端的数据协同提供稳定的底层支撑。</p><p>GraphQL批处理与缓存共享的协同运转，构建起请求调度、数据缓存、全域分发的闭环治理体系，二者的耦合逻辑并非简单的功能叠加，而是相互赋能、深度融合的有机整体，批处理引擎为缓存层提供高质量、归一化的标准数据源，彻底避免碎片化请求带来的数据格式差异与字段冲突问题，缓存层则为批处理提供前置的命中校验能力，从源头大幅减少重复请求的触发频次。在多微应用并行加载的实际业务场景中，系统先通过共享缓存层完成同源数据的原子性命中判定，缓存命中时直接向各依赖微应用分发标准化数据，未命中时则由批处理引擎聚合所有待请求单元，生成单一高效的调度链路执行数据拉取操作，响应结果经归一化处理后存入共享缓存，再同步至所有依赖该数据的微应用。这一过程中，缓存命中的原子性判定与批处理的防重触发机制，成为保障协同稳定性的核心节点，让数据请求与缓存复用的衔接实现无间隙、无冗余，也让整个数据流转链路形成自驱式的效能优化闭环，持续降低系统的网络负载与计算消耗，让数据交互的每一个环节都能实现最优效率，彻底解决微前端架构中重复请求的行业痛点。</p><p>该技术方案在微前端架构中的规模化落地，需聚焦非功能维度的精细化优化与架构适配，批处理的效能发挥依赖合理的性能阈值动态设定，结合实时网络环境与页面渲染时序要求，动态调整请求聚合的等待窗口与最大聚合粒度，避免过度聚合引发的响应延迟问题，缓存共享则注重内存资源的轻量化管控，通过数据过期策略与懒加载机制，精准控制缓存存储的资源占用规模，同时将批处理拦截与缓存代理逻辑，无缝融入微前端的应用加载与全生命周期流程，不侵入微应用的核心业务代码，保持各应用的技术栈无关性与业务自治能力。实践中通过架构层的统一封装，让数据协同能力成为微前端基座的原生能力，无需各微应用单独适配改造，同时构建数据流转的全链路感知体系，让请求调度、缓存命中、数据分发的全流程可观测、可追溯，为后续优化与迭代提供精准的数据依据，保障方案长期迭代的可扩展性，也让微前端的数据治理能力具备持续演进的底层支撑，完美适配业务规模与架构形态的动态变化，为大型分布式前端体系的稳定运行保驾护航。</p><p>从技术实践的长期视角来看，GraphQL批处理与缓存共享的深度融合，并非临时性的性能优化手段，而是微前端数据治理体系的核心基础能力，这一方案解决的不仅是重复请求的表层问题，更构建了跨应用数据协同的标准化技术范式，让微前端架构从应用拼装的初级形态，升级为数据一体化的成熟形态。通过彻底消解数据孤岛与请求冗余，大幅降低系统的网络开销与渲染阻塞风险，全面提升整体用户体验与系统运行稳定性，其核心价值在于用极简的架构逻辑，解决分布式前端的复杂数据问题，回归技术服务于业务的本质。</p>]]></description></item><item>    <title><![CDATA[《GraphQL状态图建模与低时延控制能力解析》 程序员阿伟 ]]></title>    <link>https://segmentfault.com/a/1190000047606616</link>    <guid>https://segmentfault.com/a/1190000047606616</guid>    <pubDate>2026-02-11 22:02:10</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>物联网设备态联拓扑的规模化落地进程中，设备状态图的高效查询与控制指令的低时延调度，已然成为构筑全域物联交互体系的核心命题，传统物联查询接口的刚性范式，始终难以适配异构设备的态数据柔性获取需求，固定字段与固定接口的设计逻辑，无法匹配设备状态图动态变化的拓扑结构，更难以满足多场景下差异化的态数据拾取诉求，GraphQL以态联查询的独特技术特性切入设备状态图交互场景，彻底打破了固定接口与设备态拓扑的适配壁垒，其在设备状态图查询中的优劣势深度博弈，本质是态粒度定制化能力与物联链路客观约束性的动态平衡，而实时订阅机制对设备控制指令低延迟需求的实际适配能力，更是直接决定物联控制层整体交互效能的关键标尺。设备状态图并非单一的态数据简单罗列，而是涵盖设备本体运行态、集群协同联动态、环境感知关联态的三维拓扑化态联结构，GraphQL对这一复杂结构的解构与精准查询能力，从底层重构了物联态数据的交互逻辑，也让传统物联查询从被动适配场景转向主动建模需求，这一技术选型的深层思考，必须扎根物联场景的链路传输特性、终端算力边界、业务交互核心诉求，而非单纯依托技术表层特性做浅层次落地应用。态查询的柔性价值与物联场景的客观约束，共同构成了GraphQL在物联网场景中落地的核心考量维度，也让设备态查询与指令控制的协同交互，拥有了全新的技术探索方向，这种从技术本质到场景深度适配的全维度思考，也是物联网前端交互技术迭代升级的核心逻辑，更是区分技术炫技与工程落地的关键标尺。</p><p>GraphQL在物联网设备状态图查询中的核心优势，完全根植于态粒度的定制化拾取与态联拓扑的柔性解析能力，设备状态图本身承载着多维度、多层级的态数据信息，从设备基础运行态、功能模块工作态，到深层集群联动状态、环境关联响应态，不同业务场景对态数据的拾取需求存在极其显著的差异性，传统查询模式需要依托多接口拆分适配不同需求场景，极易产生态数据冗余传输、链路资源无效消耗、终端解析压力过载等一系列问题，GraphQL可依据实际交互需求，精准拾取设备状态图中的目标态字段，完全无需传输冗余无效数据，完美适配物联网终端带宽有限、算力薄弱、续航敏感的客观特性，同时其态联查询能力可深度解析设备状态图的拓扑关联逻辑，实现跨设备、跨集群、跨区域的态数据联动查询，统一异构设备的态查询口径，大幅降低多类型终端接入的适配成本与开发周期。设备状态图的态元数据自描述特性，还能让前端交互层快速感知态数据结构与关联关系，简化设备态可视化的开发流程，让设备状态图的查询从固定范式转向柔性建模，大幅提升物联态数据的传输、解析与渲染全链路效能，也为物联网设备态的精细化管理、全域化监控提供了核心技术支撑，这种按需适配、精准获取的查询特性，让物联网多终端、多场景、多协议的态数据交互拥有了更灵活、更高效的实现路径，也让物联感知层的数据采集效率实现了质的飞跃。</p><p>GraphQL应用于物联网设备状态图查询的显性短板，集中体现在复杂态联拓扑的解析开销与场景化适配的多重约束层面，设备状态图的拓扑关联越复杂、层级越丰富，GraphQL的态查询解析单元需要处理的关联逻辑就越繁杂，这一过程会持续消耗服务端与边缘节点的运算资源，在边缘算力受限、供电紧张的物联网场景中，解析开销会直接转化为态查询的响应延迟，进而影响物联交互的实时性与稳定性。定制化的态查询需求需要后端构建精细化的态联解析逻辑，每一次设备状态图的拓扑迭代、态字段新增，都需要同步调整解析规则，大幅提升了设备状态图的维护与迭代成本，不同物联网终端的算力差异、存储差异、适配能力差异，也让轻量级传感设备、低功耗终端难以适配复杂的态查询解析流程，形成柔性查询与终端适配性的核心矛盾。同时跨域态联查询的协同约束，会让设备状态图的跨节点查询面临链路损耗、节点跳转延迟等问题，进一步放大技术特性带来的性能短板，这些劣势并非技术本身的固有缺陷，而是GraphQL的柔性特性与物联网场景客观约束碰撞产生的适配问题，也是落地过程中需要重点攻克、分层优化的核心难点，这种技术特性与场景约束的天然冲突，也是物联网技术选型中必须直面、理性权衡的现实问题，无法通过简单的参数调整实现完全消解。</p><p>GraphQL实时订阅机制为物联网设备控制指令的交互提供了全新的技术实现路径，其依托持久化连接构建的态推送体系，彻底摒弃了传统轮询模式的资源浪费与时延损耗，成为适配设备控制指令低延迟需求的核心支撑能力，实时订阅可精准绑定设备状态图与控制指令的关联关系，当控制指令下发或设备态发生变更时，通过增量推送机制仅传输核心指令与变更态数据，大幅缩短数据传输的链路时长与载荷体积。在物联控制场景中，边缘节点可作为订阅中继节点，承接云端与终端的指令中转任务，进一步压缩指令传输的物理路径，降低端到端的响应延迟，订阅会话的轻量化管理机制，可支撑多设备、多集群并发的指令订阅需求，避免会话冗余带来的资源抢占与链路拥堵，同时指令与态数据的双向订阅交互，能让控制指令的下发与设备态的反馈形成完整闭环，保障物联控制的精准性与实时性。这一机制的核心价值，在于将传统的被动查询转为主动推送，让设备控制指令的交互逻辑完全贴合物联场景的低延迟诉求，也让物联控制层的交互效率实现了质的提升，边缘侧的本地化订阅处理，还能进一步降低云端依赖，提升指令响应的稳定性，即便在弱网、断网边缘场景中，也能保障核心控制指令的本地执行与状态同步，让物联控制的可靠性得到全方位保障。</p><p>GraphQL实时订阅对设备控制指令低延迟需求的满足能力，存在明确的场景化适配边界，并非能够全场景覆盖物联控制的严苛时延要求，在高密度设备集群的集中控制场景中，大量并发订阅会话会挤占传输带宽与运算资源，导致指令推送的链路拥堵、排队延迟，直接放大整体响应延迟。物联网场景的网络波动性、不稳定性，会直接影响持久化连接的稳定性，连接抖动、中断会直接打破实时订阅的低延迟保障，边缘节点的算力分配若偏向设备状态图的解析处理，会挤占控制指令的调度资源，形成查询与订阅的资源抢占矛盾，进一步加剧时延问题。不同协议物联网设备的指令转换环节，会产生额外的时延损耗，让高要求的低延迟需求难以落地，同时订阅机制的保活逻辑需要持续消耗链路资源与终端算力，在弱网、窄带环境中，保活机制的失效会直接中断指令推送，影响控制指令的实时传递与执行。这些适配边界的存在，要求实时订阅机制必须结合物联场景特性做定制化优化，而非盲目套用通用化的订阅逻辑，这种场景化的适配思考、差异化的策略调整，也是物联网技术落地的核心准则，更是保障控制指令低延迟需求落地的关键前提。</p><p>物联网场景中GraphQL的落地应用，需要依托场景特性制定差异化的选型策略与全维度优化方案，平衡设备状态图查询的优劣势，精准适配控制指令的低延迟需求，针对设备状态图查询，可采用分层态联建模的方式，拆解复杂拓扑的关联逻辑，简化解析流程，降低服务端与边缘节点的运算开销，针对轻量级终端、低功耗设备，简化态查询的解析流程，裁剪非核心功能，保障终端的适配性与运行稳定性。</p>]]></description></item><item>    <title><![CDATA[大模型榜单周报（2026/02/08） KAI智习 ]]></title>    <link>https://segmentfault.com/a/1190000047606621</link>    <guid>https://segmentfault.com/a/1190000047606621</guid>    <pubDate>2026-02-11 22:01:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>1. 本周概览</h2><p>本周大模型行业呈现多维度竞争格局，模型调用量榜单出现显著变化，Google Gemini 3 Flash Preview强势登顶，Kimi K2.5爆发式增长。各大厂商密集发布新模型，OpenAI推出GPT-5.3-Codex编码模型，Anthropic发布Claude Opus 4.6，美团推出多模态统一大模型方案STAR，快手可灵AI发布3.0版本，上海AI实验室发布书生Intern-S1-Pro。编程能力榜单中，Kimi K2.5-thinking成为国产编程模型榜首。前沿数学能力榜单出现重大调整，Claude Opus 4.5 (no thinking)成绩暴增跃居前三。</p><h2>2. 重点关注事件</h2><ul><li><strong>OpenAI发布GPT-5.3-Codex编码模型</strong>（2.6）：融合GPT-5.2推理能力与GPT-5.2-Codex编码性能，运行速度提升25%，支持终端操作与长期任务。该模型曾参与自身训练调试，被定为首个"高"网络安全风险等级。</li><li><strong>Anthropic发布Claude Opus 4.6</strong>（2.6）：显著提升编码、推理与代理任务能力，首创百万token上下文窗口。Terminal-Bench 2.0等评测领先，GDPval-AA超GPT-5.2达144 Elo分，定价维持$5/$25每百万token不变。</li><li><strong>美团推出多模态统一大模型方案STAR</strong>（2.4）：凭借创新的"堆叠自回归架构 + 任务递进训练"双核心设计，GenEval突破0.91，实现了"理解能力不打折、生成能力达顶尖"的双重突破。</li><li><strong>快手可灵AI发布3.0版本</strong>（2.4）：推出视频3.0与Omni模型，支持智能分镜、图生视频+主体参考、多语种对口型、15秒长视频生成。</li><li><strong>上海AI实验室发布书生Intern-S1-Pro</strong>（2.4）：核心科学能力实现跃升，高难度综合学科评测稳居AI4S领域国际领先水平，复杂数理逻辑推理能力达奥赛金牌水平，面向真实科研流程的智能体能力位居开源模型第一梯队。</li></ul><h2>3. 榜单变化</h2><h3>OpenRouter模型调用量排名</h3><ul><li><strong>整体调用量</strong>：Google Gemini 3 Flash Preview强势登顶，从上周第2位（580B tokens，14%增长）跃升至本周第1位（791B tokens，36%增长），反超Claude Sonnet 4.5成为榜首；Claude Sonnet 4.5退居次席，从上周第1位（766B tokens，15%增长）降至本周第2位（727B tokens，5%增长），环比调用量绝对值减少39B tokens；Kimi K2.5爆发式增长新入前三，本周以673B tokens和350%的增长率位列第3，而上周未进入前十榜单；Grok Code Fast 1大幅下滑，从上周第3位（477B tokens，12%增长）骤降至本周第8位（336B tokens，下降30%），排名下跌5位；MiniMax M2.1高速增长新入榜，本周以371B tokens和115%的增长率位列第7，上周未在榜单中。</li><li><strong>模型市占率</strong>：MoonshotAI爆发式攀升，从上周203B tokens（3.5%，第7位）暴涨至本周606B tokens（8.8%，第5位），份额增长5.3个百分点，排名上升2位；x-ai大幅下滑，从上周719B tokens（12.3%，第4位）骤降至本周587B tokens（8.6%，第6位），份额减少3.7个百分点；MiniMax强势入榜，本周以323B tokens（4.7%）新进入前十榜单第7位；三大巨头份额齐降，Google保持第1但份额从24%降至23%，Anthropic保持第2但份额从17.1%降至15.4%，OpenAI保持第3但份额从14%降至13.4%；DeepSeek稳中有进，从上周553B tokens（9.4%，第5位）增至本周651B tokens（9.5%，第4位），超越x-ai上升1位。</li><li><strong>模型吞吐量</strong>：gpt-oss-120b速度大幅回落，从上周第2位（836 tok/s）骤降至本周第4位（447 tok/s），速度下降46%；Llama 3.1 8B Instruct性价比跃升，从上周第9位（Cerebras提供，203 tok/s，0.10/M）升至本周第6位（Groq提供，306tok/s，0.05/M），速度提升51%且价格降低50%；两款模型跌出前十，上周第5位的Llama 3.3 70B Instruct（265 tok/s）和第8位的Qwen3 Next 80B（233 tok/s）本周退出榜单；两款模型入榜，Llama 4 Maverick（第8位，181 tok/s）和Mistral Small Creative（第9位，180 tok/s）新进入前十；Gemini 2.5 Flash Lite Preview持续提速，从上周第10位（169 tok/s）升至本周第7位（221 tok/s），速度提升31%。</li><li><strong>编程调用量</strong>：Kimi K2.5爆发式增长登顶，从上周第4位（139B tokens，8.9%）暴涨至本周第1位（463B tokens，25.2%），份额激增16.3个百分点；Grok Code Fast 1大幅下滑，从上周榜首（255B tokens，16.4%）骤降至本周第3位（173B tokens，9.4%），份额减少7个百分点；MiniMax M2.1快速攀升，从上周第6位（115B tokens，7.4%）跃升至本周第2位（226B tokens，12.3%），份额增长4.9个百分点；Claude双模型份额齐降，Claude Sonnet 4.5从第2位（12.3%）降至第5位（7.9%），Claude Opus 4.5从第3位（10.0%）降至第4位（8.7%）；GPT-5.2持续收缩，从第8位（61.4B tokens，3.9%）降至第9位（38.7B tokens，2.1%），同时<a href="https://link.segmentfault.com/?enc=YtoYq3Hre6jO1UiT0rJK%2FA%3D%3D.AyFNM5R6Zw%2BUEsNttfzXDYfvfwp2GXtItlB832H%2FqZw%3D" rel="nofollow" target="_blank">https://www.arcee.ai/</a>发布的400B参数稀疏MoE开源模型Trinity Large Preview (free)新进入前十榜单，排名第7位。</li></ul><h3>各领域能力榜单</h3><ul><li><strong>编程能力榜单（Code Arena）</strong>：Kimi K2.5-thinking新晋榜单第5位，仅次于御三家的模型，成为国产编程模型榜首。</li><li><strong>文生图能力榜单（Artificial Analysis Text to Image Leaderboard）</strong>：FLUX.2 [dev] Turbo分数超过Nano Banana，二者排名易位，分别排名9、10。</li><li><strong>理科能力榜单（GPQA LLM Stats）</strong>：Claude Opus 4.6以91.3%的得分排名第4位，仅次于GPT-5.2 Pro、GPT 5.2和Gemini 3 Pro。</li><li><strong>前沿数学能力榜单（EPOCH AI FrontierMath）</strong>：Claude Opus 4.5 (no thinking)成绩暴增跃居前三，从上周五第16位（准确率20.7%，60/290）飙升至本周第3位（38.3%，111/290），准确率提升17.6个百分点；其次是Kimi K2.5 (Fireworks)新进入前十榜单，以27.9%（81/290）排名第10，取代了同系列的Kimi K2 Thinking（21.4%，第15位）。</li><li><strong>GAIA测试集榜单</strong>：LR AILab of Lenovo CTO Org发布的Lemon agent登顶首位。</li></ul><h2>4. 排行榜</h2><table><thead><tr><th>测评类型</th><th>第一名</th><th>第二名</th><th>第三名</th></tr></thead><tbody><tr><td>模型调用量</td><td>Gemini 3 Flash Preview</td><td>Claude Sonnet 4.5</td><td>Kimi K 2.5</td></tr><tr><td>公司市占率</td><td>Google</td><td>Anthropic</td><td>OpenAI</td></tr><tr><td>模型速度</td><td>gpt-oss-safeguard-20b</td><td>Qwen3 32B</td><td>gpt-oss-20b</td></tr><tr><td>编程模型调用量</td><td>Kimi K 2.5</td><td>MiniMax M2.1</td><td>Grok Code Fast 1</td></tr></tbody></table><h3>各公司按不同能力领域排名汇总</h3><table><thead><tr><th>测评类型</th><th>领先公司</th></tr></thead><tbody><tr><td>大语言模型 Text Arena</td><td>Google、xAI、Anthropic、百度、OpenAI、智谱、阿里巴巴、月之暗面</td></tr><tr><td>编程能力 Code Arena</td><td>Anthropic、OpenAI、Google、智谱、MiniMax</td></tr><tr><td>编程能力 LiveCodeBench</td><td>OpenAI、Anthropic、Google</td></tr><tr><td>代码工程任务能力 SWE-benchLite</td><td>基于Claude、Gemini、GPT、Qwen、DeepSeek开发的开源系统</td></tr><tr><td>图像编辑和生成能力 Image Edit Arena</td><td>OpenAI、Google、字节、腾讯、Black Forest Labs、Reve</td></tr><tr><td>文生图能力 Text-to-Image Arena</td><td>OpenAI、Google、Black Forest Labs、腾讯</td></tr><tr><td>图像编辑和生成能力 Image Editing Leaderboard</td><td>OpenAI、Google、字节、Black Forest Labs、阿里巴巴、Reve</td></tr><tr><td>文生图能力 Text to Image Leaderboard</td><td>OpenAI、Google、Black Forest Labs、字节、Fal</td></tr><tr><td>GPQA</td><td>OpenAI、Google、Anthropic、xAI、阿里巴巴</td></tr><tr><td>FrontierMath</td><td>OpenAI、Google、Anthropic、DeepSeek、月之暗面、xAI</td></tr><tr><td>Humanity's Last Exam</td><td>Google、OpenAI、Anthropic</td></tr><tr><td>GAIA</td><td>LR AILab of Lenovo CTO Org、JoinAI、Nvidia、Suzhou AI Lab&amp;Shuqian Tech、Microsoft AI Asia -Ads、ShawnAgent、ZTE-AICloud</td></tr></tbody></table><hr/><p>关注我，第一时间掌握更多AI前沿资讯！</p>]]></description></item><item>    <title><![CDATA[JDK22安装教程 Windows版：详细步骤+验证方法（含下载地址） 小童童 ]]></title>    <link>https://segmentfault.com/a/1190000047606503</link>    <guid>https://segmentfault.com/a/1190000047606503</guid>    <pubDate>2026-02-11 21:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>​</p><h4><strong>一、准备工作</strong>​</h4><ol><li><strong>获取安装包</strong>：从指定链接下载JDK 22安装包至电脑（链接：<a href="https://link.segmentfault.com/?enc=p%2BshW50iFE2X688RUJDs%2Fg%3D%3D.K9881napwecNUUx6sgp71C1Ta813wRxXC6kMn5VJDH5jg2hD8nuTqmdnnOhDV5zs" rel="nofollow" title="https://pan.quark.cn/s/09ba1b00f415" target="_blank">https://pan.quark.cn/s/09ba1b00f415</a></li></ol><h4><strong>二、安装步骤</strong>​</h4><ol><li><strong>解压安装包</strong>：右键点击下载的安装包文件，选择【解压到当前文件夹】（建议解压至非系统盘，如D盘，避免C盘空间不足）。</li><li><strong>进入安装目录</strong>：打开解压后的【JDK22】文件夹（可通过资源管理器直接双击进入）。</li><li><strong>启动安装程序</strong>：找到【JDK-22.0.2_windows-x64_bin.exe】文件，右键选择【以管理员身份运行】（管理员权限可避免安装路径写入失败等问题）。</li><li><p><strong>确认安装路径</strong>：</p><ul><li>弹出安装向导后，点击【下一步】；</li><li>保持默认安装路径（或自定义路径，建议路径不含中文/空格），再次点击【下一步】。</li></ul></li><li><strong>等待组件安装</strong>：安装过程中会显示“正在更新组件”，耐心等待进度完成（约1-3分钟，无需额外操作）。</li><li><strong>完成安装</strong>：组件更新完毕后，点击【关闭】退出安装向导。</li></ol><h4><strong>三、验证安装成功</strong>​</h4><ol><li><strong>打开命令提示符</strong>：按下快捷键 <code>Win + R</code>调出“运行”窗口，输入 <code>cmd</code>并点击【确定】（或按回车）。</li><li><p><strong>检查JDK版本</strong>：在命令提示符窗口中输入 <code>java -version</code>，按下回车键。若显示类似以下信息，说明安装成功：</p><pre><code>java version "22.0.2" 2022-07-19  
Java(TM) SE Runtime Environment (build 18.0.2+9-61)  
Java HotSpot(TM) 64-Bit Server VM (build 18.0.2+9-61, mixed mode, sharing)</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000041378096" alt=" title=" title=" title="/></p></li></ol><h4><strong>注意事项</strong>​</h4><ul><li>若需配置环境变量（如<code>JAVA_HOME</code>、<code>Path</code>），可根据实际需求补充设置（JDK 18默认可能已自动配置基础环境，通过<code>java -version</code>能识别即无需额外操作）。</li><li>安装路径建议简洁（如 <code>D:\Program Files\Java\jdk-22.0.2</code>），避免后续开发工具引用时出错。</li></ul><p>​</p>]]></description></item><item>    <title><![CDATA[SuperScan4单文件扫描安装步骤详解（附端口扫描与主机存活检测教程） 小童童 ]]></title>    <link>https://segmentfault.com/a/1190000047606486</link>    <guid>https://segmentfault.com/a/1190000047606486</guid>    <pubDate>2026-02-11 20:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>​</p><p> </p><p><code>SuperScan4</code>是 <strong>SuperScan 4</strong>​ 的单文件扫描工具，主要用来做<strong>端口扫描、主机存活检测</strong>，网管、搞安全的、测试网络连通性的人常用它快速扫一批 IP，看哪些机器开着、哪些端口开着。</p><p>它是绿色单文件，所谓的“安装”其实就是准备好环境、直接运行，下面用大白话一步步说。</p><h2>一、准备工作</h2><ol><li><p><strong>下载 SuperScan4.exe</strong>​</p><p><strong>安装包下载：</strong><a href="https://link.segmentfault.com/?enc=j7uO3HFDrfi%2FRSVybS3ATg%3D%3D.9noLlXI4FEpknIY3WE7Bv2ac7LBkt7GYSBstAcogJ8H4tKLY%2Fq5OQU1i9irKfYwY" rel="nofollow" title="https://pan.quark.cn/s/56173e5006cb" target="_blank">https://pan.quark.cn/s/56173e5006cb</a></p></li><li><p><strong>确认系统版本</strong>​</p><ul><li>支持 Win7/Win10/Win11 等常见 Windows 系统，老版本在 Win10/Win11 可能需要右键“以管理员身份运行”才能正常扫。</li></ul></li></ol><h2>二、“安装”步骤（其实就是运行准备）</h2><p>SuperScan4 是绿色单文件，<strong>不用像普通软件那样一步步装</strong>，只要保证能打开并正常使用：</p><ol><li>把下载好的 <code>SuperScan4.exe</code>放到一个固定文件夹，比如 <code>D:\Tools\SuperScan</code>，别放桌面容易误删或丢失。</li><li>右键 <code>SuperScan4.exe</code>→ 选“以管理员身份运行”（有些系统不提权会出现权限错误或扫不到结果）。</li><li>如果是 Win10/Win11，会弹出“用户账户控制”提示 → 点  <strong>“是”</strong> 。</li><li>第一次打开可能界面比较简单，直接就能用，不需要额外装插件。</li></ol><h2>三、基本使用方法（简单说两句）</h2><ol><li>打开 SuperScan4.exe → 在 “IP 范围” 里填要扫的地址段，比如 <code>192.168.1.1-192.168.1.254</code>。</li><li><p>选端口范围：</p><ul><li>默认会扫一些常用端口，也可以自己填，比如 <code>1-1000</code>或单独 <code>80,443,3389</code>。</li></ul></li><li>点  <strong>“Start”</strong> （开始）按钮 → 等扫描结果出来，会列出存活的主机和开放端口。</li><li>可以导出结果或复制到记事本保存。</li><li>扫的时候别一次性扫太大范围，尤其是外网，容易被认为攻击，还可能被防火墙拦截。</li></ol><p>​</p>]]></description></item><item>    <title><![CDATA[汽车行业如何选研发管理平台？看看行业标杆客户怎么说 研之有李 ]]></title>    <link>https://segmentfault.com/a/1190000047606365</link>    <guid>https://segmentfault.com/a/1190000047606365</guid>    <pubDate>2026-02-11 19:02:53</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在汽车行业，研发管理平台的选型面临独特挑战，尤其是在“智能座舱、自动驾驶、车载电子”快速发展的背景下。汽车研发不仅涉及复杂的软硬件协同，还需要应对严格的合规要求、长周期项目管理、跨部门协同等难题。选择合适的研发管理平台，不仅关乎项目管理的高效性，还决定了产品的创新能力与市场响应速度。</p><h2>一、汽车行业的研发管理痛点</h2><p><strong>1）跨部门协同难：软硬件、算法与系统工程的协作壁垒</strong></p><p>汽车行业的研发项目通常涉及多个部门，包括硬件与软件开发、算法开发与嵌入式系统、汽车电子与机械工程等。研发过程中也经常出现协作壁垒：</p><ul><li>不同部门使用不同的工具，信息割裂</li><li>项目进度、资源和风险很难实时同步</li><li>没有统一的协作平台，沟通对接耗时，误差频发</li></ul><p><strong>2）研发流程冗长，难以管控项目进度与交付质量</strong></p><p>汽车项目周期长、涉及面广，管理难度大，极易出现：</p><ul><li>项目阶段多、环节复杂，进度不易把控</li><li>各环节之间信息不流通，导致反复修改与返工</li><li>团队间依赖性强，缺乏透明的资源与任务管理体系</li></ul><p><strong>3）高合规要求：标准化与流程化必须强制执行</strong></p><p>汽车行业对质量与合规要求高，选型时特别看重以下几点：</p><ul><li>是否能满足汽车行业标准（如 ASPICE、ISO 26262 等）</li><li>是否支持流程自动化与标准化</li><li>是否支持全生命周期管理，从概念设计到产品交付</li></ul><p><strong>4）技术创新的需求：研发测试一体化、缺陷追溯与数据驱动决策</strong></p><p>随着自动驾驶、智能座舱等技术的发展，研发过程需要快速迭代和持续创新：</p><ol><li>迭代周期短，需求变更频繁</li><li>测试与研发不能“割裂”，需要紧密对接</li><li>项目进展与质量评估要依赖数据驱动，避免“盲目决策”</li></ol><h2>二、ONES 在汽车行业的解题思路</h2><p><strong>1）支持跨部门、跨团队的协同与资源透明化</strong></p><p>汽车研发涉及的跨部门、跨团队协作多，平台要做到：</p><ul><li>跨部门数据和任务的统一管理与协作</li><li>项目任务、工时、进度实时可视化</li><li>支持多团队的灵活配置，避免信息割裂与重复劳动</li></ul><p><strong>2）流程与标准化：支持 ASPICE 和 ISO 26262 等标准的执行与追溯</strong></p><p>汽车行业的研发管理平台，必须支撑行业标准：</p><ul><li>ASPICE、ISO 26262等流程标准的数字化落地</li><li>通过平台实现流程自动化与标准化管理</li><li>支持从设计、研发到交付的全生命周期管控，确保质量与合规</li></ul><p><strong>3）支撑研发与测试一体化：缺陷回溯与测试用例关联</strong></p><p>平台需要支持：</p><ul><li>研发任务与测试用例的无缝对接</li><li>缺陷管理与需求、任务、测试的闭环回溯</li><li>数据驱动决策，减少人工依赖和项目误差</li></ul><p><strong>4）技术创新与数据化管理：从需求到交付的全程追溯与可视化</strong></p><p>随着技术快速发展，平台应支撑：</p><ul><li>需求变更的高效管理与追溯</li><li>项目全生命周期的实时跟踪与透明化</li><li>数据分析和决策支持功能，帮助团队在快速变化的技术环境中保持竞争力</li></ul><h2>三、汽车行业客户证言</h2><p>以下内容来自 ONES 汽车行业客户证言。若你正在评估研发管理平台，可将这些证言作为参考样本，对照自身的跨部门协作、流程标准化、缺陷管理与数据决策需求进行判断。</p><p><strong>四维智联：中国智能汽车产业链的核心技术供应商</strong></p><p>ONES 系统助力我们完成项目、需求、缺陷以及质量管理的标准化、线上化管理，规范了从需求、研发到交付的全流程，提升了团队间的协作效率，协助建立了统一指标管理体系。</p><p><strong>新阳荣乐：服务一汽、东风、长安、北汽制造、北汽新能源等龙头厂</strong></p><p>ONES 助力新阳荣乐落地 ASPICE 认证的项目管理过程，提供对应的项目管理指导、优化内部业务流程管理，构建项目与业务一体化平台。</p><p><strong>易捷特：由东风汽车、雷诺、日产合资成立的新能源汽车企业</strong></p><p>易捷特通过引入 ONES 研发项目管理系统，实现了跨部门、跨地域的工单统一管理与流程自动化，显著提升协同效率和项目管理专业性，支撑高质量交付与客户满意度提升。</p><p><strong>众鸿科技：中国智能网联汽车创新 TOP 50</strong></p><p>技术总监 林先生：与 ONES 合作后，我们的智能座舱、舱泊一体系统研发流程实现标准化管控，完美适配 ASPICE 体系与功能安全要求，跨研发中心协作效率提升 40%；其全流程管理能力助力我们加速国产芯片适配与技术创新，产品迭代周期缩短 30%，为深耕汽车电子赛道、实现平台化量产提供了坚实支撑。</p><p><strong>佳因特：超 15 万台充电桩销往全球 60 个国家</strong></p><p>ONES 支撑佳因特全产品线研发项目管理，确保项目资源合理分配，团队高效协同。</p>]]></description></item><item>    <title><![CDATA[AI产品需求分析入门 AIAgent研究 ]]></title>    <link>https://segmentfault.com/a/1190000047606376</link>    <guid>https://segmentfault.com/a/1190000047606376</guid>    <pubDate>2026-02-11 19:02:09</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在AI技术快速渗透各行各业的今天，AI产品早已走出实验室，成为解决实际问题、提升效率的核心载体——从日常使用的AI聊天机器人、图片生成工具，到企业级的智能风控、数据分析系统，背后都离不开专业的需求分析。不同于传统互联网产品，AI产品需求分析既要兼顾“用户价值”，更要适配“技术可行性”，是连接用户需求、业务目标与AI技术的核心桥梁。对于新手而言，无需一开始陷入复杂的算法细节，先掌握核心逻辑与基础步骤，就能快速入门AI产品需求分析。</p><h2>一、先搞懂：什么是AI产品需求分析？</h2><p>简单来说，AI产品需求分析的核心是：<strong>明确“用AI技术解决什么问题”“解决给谁看”“怎么用技术落地”“落地后如何衡量效果”</strong> ，最终将模糊的用户痛点、业务诉求，转化为可落地、可衡量、符合AI技术特性的产品需求。</p><p>与传统互联网产品需求分析相比，它有两个核心差异，也是新手最需要注意的点：</p><ul><li>传统产品侧重“功能实现”，比如“做一个一键付款功能”，技术路径清晰；AI产品侧重“效果达成”，比如“做一个能识别垃圾类别的AI工具”，核心是让AI的识别准确率、响应速度达到可用标准，技术迭代空间更大。</li><li>传统产品需求可“一步到位”，功能上线后基本满足需求；AI产品需求是“迭代演进”的，比如AI聊天机器人的话术流畅度、理解准确率，需要通过数据反馈、模型优化，逐步逼近理想效果，无法一蹴而就。</li></ul><p>一句话总结：AI产品需求分析，是“以问题为核心，以技术为支撑，以效果为目标”的系统性思考过程，而非单纯罗列功能。</p><h2>二、入门核心：AI产品需求分析的3个基本原则</h2><p>新手入门，无需追求复杂方法，先守住3个基本原则，就能避开80%的坑，确保需求不偏离方向。</p><h3>1. 可行性优先：拒绝“技术空想”</h3><p>AI产品的核心是“技术落地”，再美好的需求，若当前技术无法实现，就是无效需求。新手最容易犯的错误，就是过度追求“炫酷功能”，比如“做一个能完全替代人类的AI客服”，忽略了当前AI的理解能力、情感表达能力的局限性。</p><p>正确的做法是：先判断需求的技术可行性——比如，当前AI能否实现核心功能（如识别、生成、预测）？需要多少数据支撑？落地成本（人力、算力）是否可控？若暂时无法完全实现，可拆解为“最小可行需求”，比如先实现“AI识别常见垃圾类别（准确率≥80%）”，再逐步扩展类别、提升准确率。</p><h3>2. 价值导向：AI是“工具”，不是“噱头”</h3><p>所有AI产品的需求，都必须围绕“解决实际问题、创造价值”展开，要么提升效率，要么降低成本，要么优化体验，拒绝为了“AI”而“AI”。</p><p>比如，同样是“AI图片生成工具”，针对普通用户的需求是“简单输入文字，就能生成好看的图片，无需专业设计能力”（优化体验）；针对电商商家的需求是“快速生成商品主图，降低设计成本”（降低成本）。明确核心价值，才能让需求更聚焦，避免功能冗余。</p><h3>3. 数据驱动：AI的“燃料”的是数据</h3><p>AI模型的训练、优化，离不开大量高质量数据——比如AI识别垃圾，需要收集成千上万张不同垃圾的图片，标注清楚类别，才能训练出可用的模型。因此，在需求分析阶段，就要考虑“数据来源”：数据从哪里来？是否合规？数据质量是否达标？</p><p>比如，做一个“AI识别手写文字”的需求，若无法获取足够多、覆盖不同字体、不同书写场景的手写文字数据，即使技术路径可行，最终的识别效果也会很差，需求落地后也无法满足用户需求。</p><h2>三、新手实操：AI产品需求分析的5个基础步骤</h2><p>掌握原则后，跟着这5个步骤走，就能快速完成一次基础的AI产品需求分析，从“空想”走向“落地”。</p><h3>步骤1：明确场景与用户，找准核心痛点</h3><p>任何产品需求的起点，都是“谁在什么场景下，遇到了什么问题”，AI产品也不例外。新手要避免“泛泛而谈”，比如不要说“做一个AI工具”，而要具体到场景和用户。</p><p>举例：用户是“中小电商商家”，场景是“每天需要生成10张商品主图，自己不会设计，找设计师成本高、周期长”，核心痛点是“商品主图生成效率低、成本高”。</p><p>这一步的关键是：聚焦“具体场景、具体用户”，拒绝模糊化描述，只有找准痛点，后续的AI需求才能有的放矢。</p><h3>步骤2：拆解需求，明确AI的核心作用</h3><p>找到痛点后，不要直接想“用AI怎么做”，而是先拆解需求，区分“哪些部分需要AI实现，哪些部分用传统功能实现即可”——AI只负责解决“传统技术无法高效解决”的问题，比如识别、生成、预测等，无需所有功能都依赖AI。</p><p>继续上面的例子，需求拆解为：① 生成商品主图；② 支持自定义商品类别、背景风格；③ 生成后可简单编辑；④ 快速导出。其中，“生成商品主图”是核心，需要AI实现（文生图、图生图）；“自定义风格、简单编辑、导出”是辅助功能，用传统产品功能即可实现。</p><p>这一步的关键是：聚焦“AI的核心价值”，不要过度依赖AI，避免增加技术复杂度和落地成本。</p><h3>步骤3：明确效果指标，让需求可衡量</h3><p>AI产品的需求，必须有“可衡量的效果指标”，否则无法判断需求是否落地、是否满足用户需求。新手最容易忽略这一点，只说“做一个AI识别工具”，却不说“识别准确率要达到多少”“响应速度要多久”。</p><p>常见的AI效果指标有：准确率（比如垃圾识别准确率≥80%）、响应速度（比如AI生成图片≤10秒/张）、召回率（比如智能推荐的召回率≥70%）、用户满意度（比如AI客服的用户满意度≥85%）。</p><p>继续举例，明确效果指标：AI生成商品主图，准确率≥85%（与商品实际外观匹配），响应速度≤8秒/张，支持3种以上背景风格，用户可直接使用的图片占比≥70%。</p><p>这一步的关键是：指标要具体、可量化，避免“大概”“差不多”，这样后续技术开发、测试才有明确的标准。</p><h3>步骤4：评估技术可行性与落地成本</h3><p>这是AI产品需求分析的核心步骤，也是区别于传统产品的关键。新手可以从3个维度评估，无需深入了解算法细节，只需和技术同学简单沟通即可：</p><ul><li>技术路径：当前AI技术能否实现核心需求？比如，商品主图生成，可用成熟的文生图模型（如Stable Diffusion、即梦AI的生成模型），技术路径可行。</li><li>数据支撑：是否有足够的高质量数据？比如，商品主图生成，需要收集不同类别的商品图片、背景图片，标注清楚类别、风格，若数据不足，可考虑使用公开数据集、外包标注。</li><li>落地成本：人力（算法工程师、数据标注师）、算力（模型训练、推理需要的服务器资源）、时间（开发周期）是否可控？比如，中小团队做商品主图生成工具，可基于成熟模型微调，降低开发成本和周期。</li></ul><p>若评估后发现不可行，可调整需求，比如降低效果指标、拆解为更小的需求，避免盲目推进。</p><h3>步骤5：输出需求文档，明确边界与迭代计划</h3><p>需求分析完成后，需要将思考的结果整理为需求文档（PRD），传递给技术、测试等团队，明确需求的边界、优先级和迭代计划。新手的需求文档无需过于复杂，核心包含3部分内容：</p><ul><li>需求概述：明确场景、用户、核心痛点和需求目标，让团队快速了解需求背景。</li><li>核心需求与效果指标：详细说明AI核心功能、效果指标、辅助功能，明确需求的优先级（哪些必须实现，哪些可后续迭代）。</li><li>迭代计划：AI产品无法一步到位，需明确迭代节奏，比如V1版本实现核心功能（准确率≥85%），V2版本提升准确率（≥90%）、增加更多风格，V3版本优化编辑功能。</li></ul><p>这一步的关键是：文档清晰、简洁，明确“做什么、不做什么、做到什么程度、分几步做”，避免团队理解偏差。</p><h2>四、新手避坑：AI产品需求分析的4个常见误区</h2><p>入门阶段，只要避开这4个误区，就能少走很多弯路，让需求更具落地性。</p><ul><li>误区1：过度追求技术炫酷，忽视用户需求。比如，盲目追求“多模态生成”“大模型应用”，却没考虑用户是否真的需要，导致产品上线后无人使用。记住：AI是工具，用户需要的是“解决问题”，不是“炫酷技术”。</li><li>误区2：忽视数据问题，认为“技术能解决一切”。比如，做AI识别需求，却没考虑数据来源、数据质量，导致模型训练效果差，无法落地。记住：数据是AI的燃料，没有高质量数据，再强的算法也无用。</li><li>误区3：需求太模糊，没有可衡量的指标。比如，只说“做一个AI客服，能回答用户问题”，却不说“回答准确率、响应速度”，导致技术开发没有标准，测试无法判断效果。</li><li>误区4：期望一步到位，不考虑迭代。比如，要求AI产品上线就达到“完美效果”，忽视了AI模型需要数据反馈、持续优化的特性，导致需求落地周期过长，甚至失败。</li></ul><h2>五、入门建议：新手如何快速提升AI产品需求分析能力？</h2><p>AI产品需求分析能力，不是一蹴而就的，新手可以从3个方面入手，快速提升，循序渐进。</p><ul><li>多体验：多使用各类AI产品（如即梦AI、ChatGPT、Midjourney、剪映AI），思考它们的需求场景、核心功能、效果指标，拆解它们的需求逻辑——比如，使用即梦AI的视频生成功能，思考“它的用户是谁？核心痛点是什么？效果指标如何设计？”。</li><li>多实践：从小需求入手，尝试完成一次完整的需求分析，比如“做一个AI识别宠物类别的工具”，按照前面的5个步骤，拆解需求、明确指标、评估可行性、输出需求文档，哪怕是简单的练习，也能快速积累经验。</li><li>多沟通：多和技术同学沟通，了解AI技术的基本逻辑、落地难点（比如数据标注、模型微调的成本），避免提出不可行的需求；多和用户沟通，了解真实痛点，避免“自嗨式需求”。</li></ul><h2>六、总结</h2><p>AI产品需求分析入门，核心不是掌握复杂的算法知识，而是建立“以问题为核心、以技术为支撑、以效果为目标”的思考方式——先找准具体场景和用户痛点，再拆解需求、明确效果指标，评估技术可行性，最后通过迭代逐步落地。</p><p>对于新手而言，不要急于求成，先守住“可行性、价值导向、数据驱动”3个原则，避开常见误区，多体验、多实践、多沟通，就能快速掌握AI产品需求分析的基础逻辑，逐步成长为合格的AI产品需求分析师。</p><p>记住：AI产品的核心是“解决问题”，需求分析的核心是“让技术落地，创造价值”，这也是所有AI产品需求分析的底层逻辑。</p>]]></description></item><item>    <title><![CDATA[Flask 入门指南 小小张说故事 ]]></title>    <link>https://segmentfault.com/a/1190000047606382</link>    <guid>https://segmentfault.com/a/1190000047606382</guid>    <pubDate>2026-02-11 19:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>1. 库的概览与核心价值</h2><p>想象一下,在搭建一个 Web 应用时,如果需要同时处理路由、模板、数据库、表单验证、用户认证等数十个复杂功能,就像试图在一天内盖好一栋摩天大楼——不仅容易迷失方向,还可能因为过度设计而拖垮开发效率。<code>Flask</code>正是为解决这个"选择困难症"而生的轻量级框架。</p><p>Flask被称为"微框架"(Microframework),它的核心哲学是"保持简单,按需扩展"。与Django这样自带全套装备的"全栈框架"不同,Flask只提供Web开发最基础的功能:路由分发和模板渲染,其他功能则通过丰富的扩展生态系统来实现。这种设计让开发者能够根据项目需求自主选择工具链,就像搭积木一样灵活组装自己的技术栈。</p><p>Flask的不可替代性体现在三个方面:极低的学习曲线让初学者能快速上手,高度的扩展性支持项目从原型到生产环境的平滑演进,而简洁的代码结构则为团队协作和代码维护提供了良好基础。无论是构建简单的API服务、个人博客,还是复杂的企业级应用,Flask都能提供一个优雅而高效的起点。</p><h2>2. 环境搭建与 "Hello, World"</h2><h3>安装说明</h3><p>安装Flask前,强烈建议先创建虚拟环境以隔离项目依赖:</p><pre><code class="bash"># 创建虚拟环境
python3 -m venv venv

# 激活虚拟环境
# macOS/Linux:
source venv/bin/activate
# Windows:
venv\Scripts\activate

# 安装Flask
pip install Flask</code></pre><p>Flask会自动安装以下核心依赖:</p><ul><li><code>Werkzeug</code>: WSGI工具包,处理HTTP请求和响应</li><li><code>Jinja2</code>: 模板引擎,用于生成动态HTML</li><li><code>Click</code>: 命令行工具,提供<code>flask</code>命令</li><li><code>MarkupSafe</code>: 自动转义HTML,防止XSS攻击</li><li><code>ItsDangerous</code>: 数据签名工具,保护session安全</li></ul><h3>最简示例</h3><p>创建一个<code>app.py</code>文件,写入以下代码:</p><pre><code class="python">from flask import Flask

# 创建Flask应用实例
app = Flask(__name__)

# 使用装饰器定义路由
@app.route('/')
def hello_world():
    return '&lt;p&gt;Hello, World!&lt;/p&gt;'

if __name__ == '__main__':
    app.run(debug=True)</code></pre><h3>逐行解释</h3><ul><li><code>from flask import Flask</code>: 导入Flask核心类,这是构建应用的起点</li><li><code>app = Flask(__name__)</code>: 创建应用实例。<code>__name__</code>参数帮助Flask定位模板和静态文件目录</li><li><code>@app.route('/')</code>: 路由装饰器,告诉Flask当用户访问根路径(<code>/</code>)时调用下面的函数</li><li><code>def hello_world():</code>: 视图函数,处理请求并返回响应内容</li><li><code>return '&lt;p&gt;Hello, World!&lt;/p&gt;'</code>: 返回HTML字符串,Flask会自动将其转换为HTTP响应</li><li><code>if __name__ == '__main__':</code>: 确保只有在直接运行脚本时才启动服务器</li><li><code>app.run(debug=True)</code>: 启动开发服务器。<code>debug=True</code>开启调试模式,代码修改后自动重载,并提供错误调试页面</li></ul><h3>运行结果</h3><p>在终端执行:</p><pre><code class="bash">flask --app app run
# 或者
python app.py</code></pre><p>服务器启动后,访问 <a href="https://link.segmentfault.com/?enc=hk7%2BUgtW7uvLend9USZFwQ%3D%3D.W7rltI4Hpti6ClGPaPcVUygAlfqNhM7bvP6dDHiHQqI%3D" rel="nofollow" target="_blank">http://127.0.0.1:5000/</a> 即可看到 "Hello, World!" 页面。</p><h2>3. 核心概念解析</h2><p>Flask的三大核心概念:应用实例、路由系统和请求上下文,它们共同构成了Web应用的骨架。</p><h3>应用实例(Application Instance)</h3><p>应用实例(<code>app = Flask(__name__)</code>)是Flask应用的中心,负责管理路由、配置和扩展。它通过<code>__name__</code>参数确定模块位置,以便正确查找<code>templates</code>和<code>static</code>目录。可以将应用实例理解为一个"中央指挥官",协调所有组件协同工作。</p><h3>路由系统(Routing)</h3><p>路由使用装饰器<code>@app.route()</code>将URL路径映射到视图函数:</p><pre><code class="python"># 基础路由
@app.route('/about')
def about():
    return 'About Page'

# 动态路由
@app.route('/user/&lt;username&gt;')
def show_user(username):
    return f'User: {username}'

# 类型约束路由
@app.route('/post/&lt;int:post_id&gt;')
def show_post(post_id):
    return f'Post ID: {post_id}'

# 多HTTP方法支持
@app.route('/login', methods=['GET', 'POST'])
def login():
    if request.method == 'POST':
        return 'Processing login...'
    return 'Login form'</code></pre><p>动态路由中的<code>&lt;username&gt;</code>和<code>&lt;int:post_id&gt;</code>是URL转换器,前者匹配任意字符串,后者只匹配整数。Flask还支持<code>float</code>、<code>path</code>(包含斜杠)、<code>uuid</code>等转换器。</p><h3>请求上下文(Request Context)</h3><p>请求上下文包含两个关键代理对象:<code>request</code>和<code>session</code>。它们允许在视图函数中访问请求数据和会话信息,无需显式传递参数。</p><pre><code class="python">from flask import request, session

# 获取查询参数: /search?q=keyword
@app.route('/search')
def search():
    keyword = request.args.get('q', '')
    return f'Searching for: {keyword}'

# 获取表单数据
@app.route('/submit', methods=['POST'])
def submit():
    username = request.form.get('username')
    return f'Username: {username}'

# 获取JSON数据
@app.route('/api/data', methods=['POST'])
def api_data():
    data = request.get_json()
    return jsonify(data)

# 使用session存储用户状态
@app.route('/set_session')
def set_session():
    session['user_id'] = 123
    return 'Session set'</code></pre><h3>概念关系图</h3><pre style="display:none;"><code class="mermaid">graph TD
    A[Flask应用实例] --&gt; B[路由系统]
    A --&gt; C[配置管理]
    A --&gt; D[扩展注册]
    B --&gt; E[视图函数]
    E --&gt; F[请求上下文]
    F --&gt; G[request对象]
    F --&gt; H[session对象]
    E --&gt; I[响应生成]
    I --&gt; J[字符串/JSON/模板]
    D --&gt; K[数据库扩展]
    D --&gt; L[表单验证扩展]
    D --&gt; M[认证扩展]</code></pre><h2>4. 实战演练:构建一个待办事项API</h2><p>让我们通过一个完整的迷你项目来掌握Flask的核心功能。我们将构建一个简单的待办事项管理API,支持增删改查(CRUD)操作。</p><h3>需求分析</h3><p>我们需要创建一个RESTful API,允许用户:</p><ol><li>获取所有待办事项</li><li>创建新待办事项</li><li>更新待办事项状态</li><li>删除待办事项</li></ol><p>数据存储在内存中(列表),适合快速原型开发。</p><h3>方案设计</h3><p>选择Flask的以下功能:</p><ul><li>路由系统:定义API端点</li><li><code>request</code>对象:解析JSON请求体</li><li><code>jsonify</code>:返回JSON格式响应</li><li>动态路由:处理特定ID的待办事项</li><li>HTTP方法:GET/POST/PUT/DELETE对应CRUD操作</li></ul><h3>代码实现</h3><p>创建<code>todo_api.py</code>:</p><pre><code class="python">from flask import Flask, request, jsonify

app = Flask(__name__)

# 内存数据库
todos = [
    {'id': 1, 'title': 'Learn Flask', 'completed': False},
    {'id': 2, 'title': 'Build API', 'completed': False}
]
next_id = 3

# 获取所有待办事项
@app.route('/api/todos', methods=['GET'])
def get_todos():
    return jsonify(todos)

# 创建新待办事项
@app.route('/api/todos', methods=['POST'])
def create_todo():
    global next_id
    data = request.get_json()
    
    if not data or 'title' not in data:
        return jsonify({'error': 'Title is required'}), 400
    
    todo = {
        'id': next_id,
        'title': data['title'],
        'completed': data.get('completed', False)
    }
    todos.append(todo)
    next_id += 1
    
    return jsonify(todo), 201

# 更新待办事项
@app.route('/api/todos/&lt;int:todo_id&gt;', methods=['PUT'])
def update_todo(todo_id):
    todo = next((t for t in todos if t['id'] == todo_id), None)
    
    if not todo:
        return jsonify({'error': 'Todo not found'}), 404
    
    data = request.get_json()
    todo['title'] = data.get('title', todo['title'])
    todo['completed'] = data.get('completed', todo['completed'])
    
    return jsonify(todo)

# 删除待办事项
@app.route('/api/todos/&lt;int:todo_id&gt;', methods=['DELETE'])
def delete_todo(todo_id):
    global todos
    todo = next((t for t in todos if t['id'] == todo_id), None)
    
    if not todo:
        return jsonify({'error': 'Todo not found'}), 404
    
    todos = [t for t in todos if t['id'] != todo_id]
    return jsonify({'message': 'Todo deleted'})

if __name__ == '__main__':
    app.run(debug=True)</code></pre><h3>运行说明</h3><ol><li><p>启动服务器:</p><pre><code class="bash">python todo_api.py</code></pre></li><li>使用curl或Postman测试API:</li></ol><pre><code class="bash"># 获取所有待办事项
curl http://127.0.0.1:5000/api/todos

# 创建新待办事项
curl -X POST http://127.0.0.1:5000/api/todos \
  -H "Content-Type: application/json" \
  -d '{"title": "Deploy to production"}'

# 更新待办事项
curl -X PUT http://127.0.0.1:5000/api/todos/1 \
  -H "Content-Type: application/json" \
  -d '{"completed": true}'

# 删除待办事项
curl -X DELETE http://127.0.0.1:5000/api/todos/1</code></pre><h3>结果展示</h3><p>这个API完美展示了Flask的核心能力:</p><ul><li>清晰的路由定义(<code>/api/todos</code>, <code>/api/todos/&lt;id&gt;</code>)</li><li>HTTP方法处理(GET/POST/PUT/DELETE)</li><li>JSON请求解析(<code>request.get_json()</code>)</li><li>错误处理和状态码返回(400/404)</li><li>动态路由参数(<code>&lt;int:todo_id&gt;</code>)</li></ul><h2>5. 最佳实践与常见陷阱</h2><h3>常见错误及规避方法</h3><h4>错误1: 直接使用<code>app.run()</code>部署到生产环境</h4><pre><code class="python"># ❌ 错误做法
if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)  # 仅适合开发环境</code></pre><p>Flask内置服务器性能有限且不安全,生产环境应使用Gunicorn或uWSGI:</p><pre><code class="bash"># ✅ 正确做法: 使用Gunicorn部署
pip install gunicorn
gunicorn -w 4 -b 0.0.0.0:5000 app:app</code></pre><h4>错误2: 硬编码敏感信息</h4><pre><code class="python"># ❌ 错误做法
app.config['SECRET_KEY'] = 'my-secret-key-123'
app.config['DATABASE_URI'] = 'postgresql://user:password@localhost/db'</code></pre><p>使用环境变量或配置文件:</p><pre><code class="python"># ✅ 正确做法
import os

app.config['SECRET_KEY'] = os.environ.get('SECRET_KEY') or 'dev-key'
app.config['DATABASE_URI'] = os.environ.get('DATABASE_URI')

# 或者使用配置文件
# config.py
class Config:
    SECRET_KEY = os.environ.get('SECRET_KEY')
    SQLALCHEMY_DATABASE_URI = os.environ.get('DATABASE_URI')

# app.py
from config import Config
app.config.from_object(Config)</code></pre><h4>错误3: 忘记设置<code>SECRET_KEY</code>导致session无法使用</h4><pre><code class="python"># ❌ 错误做法
@app.route('/login')
def login():
    session['user_id'] = 1  # 会报错: RuntimeError: The session is unavailable
    return 'Logged in'</code></pre><pre><code class="python"># ✅ 正确做法
app = Flask(__name__)
app.secret_key = 'your-secret-key-here'  # 生产环境应从环境变量读取

@app.route('/login')
def login():
    session['user_id'] = 1
    return 'Logged in'</code></pre><h3>最佳实践建议</h3><p><strong>1. 使用虚拟环境隔离依赖</strong></p><pre><code class="bash"># 创建并激活虚拟环境
python3 -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt</code></pre><p><strong>2. 生成依赖清单</strong></p><pre><code class="bash">pip freeze &gt; requirements.txt</code></pre><p><code>requirements.txt</code>文件示例:</p><pre><code>Flask==3.0.0
Werkzeug==3.0.1
Jinja2==3.1.2</code></pre><p><strong>3. 项目结构组织</strong></p><p>对于小型项目,建议采用以下结构:</p><pre><code>myproject/
├── app.py              # 主应用文件
├── requirements.txt     # 依赖清单
├── config.py           # 配置文件
├── templates/          # 模板目录
│   └── index.html
└── static/             # 静态文件
    ├── css/
    └── js/</code></pre><p>对于大型项目,使用蓝图(Blueprint)模块化:</p><pre><code>myproject/
├── app.py
├── requirements.txt
├── blueprints/
│   ├── auth.py
│   ├── api.py
│   └── main.py
└── templates/</code></pre><p><strong>4. 启用调试模式注意事项</strong></p><p>开发环境可启用调试模式:</p><pre><code class="python">app.run(debug=True)</code></pre><p>但生产环境必须关闭:</p><pre><code class="python">app.run(debug=False)  # 或不指定,默认为False</code></pre><p>调试模式会暴露敏感信息并允许在浏览器中执行任意Python代码,存在严重安全风险。</p><h2>6. 进阶指引</h2><p>Flask的简洁性不仅体现在核心功能上,更体现在其强大的扩展能力。当你的项目需要更复杂的功能时,以下扩展值得关注:</p><p><strong>数据库集成</strong></p><ul><li><code>Flask-SQLAlchemy</code>: 提供ORM功能,简化数据库操作</li><li><code>Flask-Migrate</code>: 数据库迁移工具,管理表结构变更</li></ul><p><strong>表单处理与验证</strong></p><ul><li><code>Flask-WTF</code>: 集成WTForms,提供表单验证和CSRF保护</li></ul><p><strong>用户认证与授权</strong></p><ul><li><code>Flask-Login</code>: 管理用户会话和认证状态</li><li><code>Flask-Security</code>: 提供完整的认证、角色管理和密码加密</li></ul><p><strong>API开发</strong></p><ul><li><code>Flask-RESTful</code>: 快速构建RESTful API</li><li><code>Flask-Marshmallow</code>: 序列化/反序列化数据</li></ul><p><strong>任务队列与异步处理</strong></p><ul><li><code>Celery</code>: 处理耗时任务(如发送邮件、图片处理)</li><li><code>Flask-Celery-Helper</code>: 简化Celery与Flask的集成</li></ul><h3>学习路径建议</h3><ol><li><strong>掌握基础</strong>(当前阶段): 理解路由、请求/响应、模板渲染</li><li><strong>扩展技能</strong>: 学习3-5个常用扩展,构建功能完整的应用</li><li><strong>深入原理</strong>: 研究Flask的上下文机制、信号系统、中间件</li><li><strong>生产部署</strong>: 掌握Gunicorn/Nginx部署、Docker容器化</li><li><strong>性能优化</strong>: 了解缓存策略、数据库优化、异步处理</li></ol><h3>学习资源</h3><ul><li><strong>官方文档</strong>: <a href="https://link.segmentfault.com/?enc=DaN0cAGBi3abTuNq%2FsFX7A%3D%3D.9aViwMiXJ9BQ4cs5Ru5Zy8NvzlYVLEhRFlr%2BAk9FZefv7thgQNK6Lb6SHzbc%2FEFN" rel="nofollow" target="_blank">https://flask.palletsprojects.com/</a> (最权威的学习资源)</li><li><strong>中文文档</strong>: <a href="https://link.segmentfault.com/?enc=Wxaifp%2FmdVrbtP8xEUoAPA%3D%3D.kQCDZzGvbErCXyAYwAdXMuQgJ9F7YDEr%2BVWxxNPtIsw%3D" rel="nofollow" target="_blank">https://flask.github.net.cn/</a> (适合中文读者)</li><li><strong>GitHub仓库</strong>: <a href="https://link.segmentfault.com/?enc=ZwBpTWlZbWaIQtsF68Msbw%3D%3D.fmTH4EzoYmKNZy66tYmJuuE3EPFvuN6V%2B2%2B2V3Ub6QOA%2FAsE6MmfkVpQDvZ9lzU9" rel="nofollow" target="_blank">https://github.com/pallets/flask</a> (源码和Issue讨论)</li><li><strong>Stack Overflow</strong>: 使用<code>flask</code>标签搜索问题和解决方案</li></ul><p>Flask的学习曲线平缓,但要精通它需要实践和耐心。建议从简单项目开始,逐步引入新功能和技术,在实践中深化理解。记住,Flask的力量不在于它提供了什么,而在于它不限制你做什么——这正是"微框架"哲学的精髓所在。</p>]]></description></item>  </channel></rss>