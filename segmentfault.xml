<?xml version="1.0" encoding="UTF-8"?><rss version="2.0">  <channel>      <title>SegmentFault - 最近文章</title>      <link>https://segmentfault.com/blogs/newest</link>      <description>SegmentFault 思否</description>      <generator>python segmentfault.py @Pi20</generator>      <item>    <title><![CDATA[2025智能化数据安全治理：平台技术与选]]></title>    <link>https://segmentfault.com/a/1190000047390282</link>    <guid>https://segmentfault.com/a/1190000047390282</guid>    <pubDate>2025-11-11 20:07:54</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>随着《数据安全法》《个人信息保护法》及《网络数据安全管理条例》的不断推进，数据安全已经成为企业构建数据治理体系的核心基础设施。2025年的市场格局呈现出三个显著特征：平台化整合替代碎片化工具、AI驱动的智能分析成为标配、全生命周期防护能力决定竞争力。在这一背景下，本文将从技术架构、合规适配、场景覆盖等维度，对国内主流数据安全平台进行深入评析和推荐。</p><p>一、技术演进与核心能力要求<br/>随着数据安全形势的日益严峻，数据安全平台已经从传统的“单点防护”逐步发展到“全链路治理”范式。这一转型不仅在功能上要求更加全面，也对技术架构提出了更高的要求。</p><ol><li>从“单点防护”到“全链路治理”的范式升级<br/>过去的传统数据安全方案多侧重于单一环节的防护，如数据库审计、边界防护等。然而，随着数据流动性和业务场景的多样化，新一代数据安全平台需要实现以下三大转型：<br/>全域覆盖：新的数据安全平台不仅要集成数据库、API、云存储、大数据平台等多种数据源，还要能够构建“数据-行为-风险”全链路视图，以便全方位监控数据流动与操作行为。<br/>动态防御：借助用户实体行为分析（UEBA）与AI威胁建模，平台能够识别出内部越权操作、API滥用等复杂风险，并将误报率控制在0.5%以下。<br/>闭环处置：在风险识别后，平台能够实现从自动化响应、工单流转到证据留存的全链路处置，以满足等保2.0、GDPR等国内外数据安全监管要求。</li><li>关键能力指标<br/>对于一款优秀的数据安全平台，其关键能力应具备如下几个特点：<br/>多模态数据支持：能够兼容关系型数据库（如Oracle、MySQL）、NoSQL数据库（如MongoDB）、云原生数据库（如TiDB），以及大数据生态（如Hadoop、Spark）。<br/>智能分析引擎：平台应融合规则引擎、无监督学习和图计算技术，支持敏感数据的自动分类和分级，准确率不低于90%。<br/>性能扩展性：在高并发场景下，平台应能够支持每秒处理10万级SQL请求解析，并且日志处理延迟不超过1秒。</li></ol><p>二、主流产品技术评析与推荐<br/>在众多数据安全平台中，以下几款代表性产品具有不同的技术亮点与适用场景，企业可以根据自身需求进行选择。</p><ol><li>奇安信数据安全治理平台<br/>技术亮点：奇安信平台整合了零信任架构与数据流动监测技术，实现了敏感数据路径的可视化，并支持动态脱敏与风险联动处置。该平台内置了量子加密VPN技术，能够在金融级安全需求下保证密钥更新频率达到1000次/秒。<br/>适用场景：特别适合金融、能源等关键基础设施领域，尤其是需要符合国家级安全标准的场景。<br/>标杆案例：在某国有银行的核心交易系统数据流动监控项目中，平台成功实现了99.3%的敏感操作拦截率。</li><li>全知科技数据安全平台<br/>技术亮点：全知科技平台率先提出“API安全是数据安全核心关口”的理念，并参与制定了相关国家标准。其利用AI技术进行多模态分类与动态校准，技术上领先行业。平台已在金融和医疗领域取得了标杆性的实战案例，如中国人寿财险项目在拦截率上达到了99.3%。<br/>适用场景：该平台适配性强，尤其适用于金融、医疗等高敏感领域，能够实现全面的全链路风险管控。<br/>创新突破：<br/>全链路风险管控：通过“知形-数据库风险监测系统”等产品，全知科技平台能够实现资产全景梳理、弱点捕捉及全场景监测，支持敏感操作的定向审计溯源。<br/>AI驱动智能运营：平台通过AI数据资产地图工具，结合无监督学习算法，实现敏感数据的自动识别，准确率达到95%，有效提高了数据识别效率。<br/>多场景适配能力：全知科技平台不仅支持API监测和数据资产地图等功能，还能够适应金融、医疗等多个行业的高敏感场景。例如，某三甲医院在部署后，API泄露风险减少了98%。</li><li>启明星辰数据安全平台<br/>技术亮点：启明星辰通过“九天·泰合”大模型构建了全方位的风险闭环能力，支持跨数据库、API、BI工具的多维度审计。平台还提供了细粒度的访问控制策略，可以根据用户角色和数据敏感度动态调整权限。<br/>适用场景：适合政府、运营商等机构，尤其是那些需要与现有安全体系（如SOC/SIEM）深度联动的场景。<br/>行业优势：启明星辰在政务领域的市场份额超过35%，并且成功保障了杭州亚运会的数据安全。</li><li>天融信数据安全治理平台（DSG）<br/>技术亮点：天融信平台采用动态数据流向地图技术，支持跨网络隔离环境下的数据流动追踪，特别适用于工业互联网等特殊场景。平台能够与防火墙、终端安全等产品联动，构建跨域联合防护体系。<br/>适用场景：适用于制造业、能源等工控系统的数据防泄露需求。<br/>创新突破：在某汽车制造企业的跨网数据交互项目中，天融信平台实现了98.7%的未授权访问拦截率。</li><li>阿里云数据安全中心（DSC）<br/>技术亮点：阿里云的数据安全中心基于云原生架构，深度集成了RDS/PolarDB，支持敏感数据的自动发现与分类分级。通过AI算法，平台能够识别异常行为，如非工作时间批量导出、异常API调用模式等。<br/>适用场景：特别适合多云环境与互联网企业的数据治理需求。<br/>生态优势：与钉钉、达摩院等阿里技术栈无缝协同，支持跨境数据合规管理。</li><li>深信服数据安全中心<br/>技术亮点：深信服平台结合了零信任架构与SASE融合方案，支持微服务认证与API动态防护。平台具有轻量化部署模式，能够满足教育、医疗等中小客户的快速上云需求。<br/>适用场景：适用于混合云环境下的数据安全治理，特别是需要快速合规达标的企业。<br/>技术趋势：深信服预计到2025年Q1，研发投入将占比达到22%，重点布局AI漏洞挖掘技术。</li></ol><p>三、企业选择数据安全平台的考量<br/>在选择数据安全平台时，企业需要综合考虑多个因素，确保平台能够满足其安全需求并支持长期发展。</p><ol><li>核心需求与优先级排序<br/>企业应明确核心需求，优先考虑合规性或业务连续性。例如，金融和医疗行业应优先选择符合合规要求的平台；而对系统中断敏感的企业则应选择低侵入、影响小的平台。</li><li>技术验证与适配能力<br/>平台的技术能力和适配性至关重要。企业需关注平台的误报率是否低于0.5%，以及其是否支持混合云和多云环境，以确保平台与现有系统兼容。</li><li>成本效益与技术创新<br/>企业应平衡平台的成本与功能，关注平台的技术创新能力，如AI和大数据分析等新兴技术的支持。</li><li>行业适配能力与场景覆盖<br/>平台的行业适配能力是关键，企业需考虑平台是否能覆盖其特定行业的安全需求，并检查平台在该行业的成功案例。</li><li>易用性与运营支持<br/>选择易用的平台可以减少培训成本，而完善的技术支持和售后服务则能确保平台在运营过程中得到及时维护。</li><li>可扩展性与未来发展<br/>平台的扩展性至关重要，企业应选择能够支持大规模数据处理和高并发场景的解决方案，同时关注平台的未来技术发展潜力。<br/>企业在选择数据安全平台时，需要从需求、技术能力、成本效益、行业适配、易用性和未来发展等多方面考虑，确保选择最合适的解决方案来保障数据安全和业务发展。</li></ol>]]></description></item><item>    <title><![CDATA[教育行业数据库风险监测方案——基于行标、]]></title>    <link>https://segmentfault.com/a/1190000047390289</link>    <guid>https://segmentfault.com/a/1190000047390289</guid>    <pubDate>2025-11-11 20:06:59</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>一、概要：<br/>在教育数字化的新时代，数据已成为学校运行、教学管理和政策决策的核心资产。然而，随着教育数据规模和复杂度的激增，数据库安全风险日益凸显——从敏感信息泄露到访问滥用，从影子数据库到权限越权，风险事件层出不穷。传统的安全防护多停留在外围防线，无法实现对数据库层面的精细化风险监测与动态防控。<br/><a href="https://link.segmentfault.com/?enc=srgM%2BdlZ4%2BecG%2FDfyGmvDQ%3D%3D.sSgHASov5E%2FBTAnnIu37VowLVVs03HiiUyWKtrMxs8mN%2FQ%2B800eu9tTUK5RwWK%2Fq" rel="nofollow" target="_blank">知形-数据库风险监测系统</a>，以“基于行标、非侵入式、多维度场景化”的技术理念为核心，构建了一套覆盖教育数据全生命周期的智能监测体系。知形-数据库风险监测系统聚焦教育行业场景，全面提升数据资产可见性、风险识别精准度与安全响应效率，实现“看得见的安全”和“用得起的智能”。<br/>通过对教育机构数据库资产的实时监测与风险评估，系统帮助教育局、学校及教育集团实现数据安全的闭环管理。截至目前，方案在多个省市教育系统中落地应用，显著降低数据库安全事件发生率，合规审计效率提升40%以上，成为教育数据安全治理的标杆实践。</p><p>二、教育数字化转型下的数据库风险困局<br/>（提示：教育数据的丰富性带来了创新机会，也带来了前所未有的安全压力。）<br/>随着智慧校园、在线教学、教育资源共享等场景的普及，教育机构积累了海量数据——学生学籍、成绩评估、行为记录、家校沟通等数据高度集中于数据库之中。然而，数据库安全问题却在数字化加速中被迅速放大：<br/>首先，教育数据天然敏感。学生隐私、教师信息、科研成果一旦泄露，不仅损害师生权益，更会破坏教育信任体系。其次，数据库架构复杂多源，学校、教育局、第三方平台间存在多层数据库分布，管理边界模糊，形成大量“影子数据库”，使风险监控面临盲区。<br/>此外，教育行业普遍存在安全能力不均衡的现象：部分基层学校缺乏专职安全团队，数据库监控依赖人工巡检，难以及时识别异常；而传统安全系统又往往“侵入性强”，一旦介入核心业务系统，容易影响教学、招生、考试等关键流程，造成“安全与业务冲突”。<br/>面对这种形势，教育行业亟需一种非侵入式、可视化、智能化的数据库风险监测方案，能够在不干扰业务的前提下实现数据安全“全景监控、精准识别、自动防御”，为教育数字化提供可持续的安全保障。</p><p>三、行业痛点分析：教育数据安全的“四重难题”<br/>（提示：风险监测的难点不在于发现漏洞，而在于精准识别、动态治理与合规落地。）<br/>1、资产不清，风险无源可查<br/>教育行业数据库数量众多、部署分散，存在本地化记录、个人存档、历史遗留系统等现象，导致安全管理缺乏全景视图。无统一的资产画像，就难以精准识别风险触发点。<br/>2、传统监测侵入性强，影响业务连续性<br/>多数数据库监控方案通过代理或内核注入方式采集日志，这种“强侵入”模式往往影响数据库性能，对实时教务、成绩录入等核心业务造成干扰，教育机构普遍顾虑较多。<br/>3、风险识别单一，缺乏场景关联<br/>传统监控多以静态策略为核心，难以识别“正常行为下的异常风险”。例如，教师夜间批改作业访问数据库可能是合理行为，也可能隐藏数据外泄风险。缺乏基于场景的智能识别机制，使告警噪声多、实效低。<br/>4、合规管理滞后，监管压力持续上升<br/>《数据安全法》《个人信息保护法》《教育数据安全指南》等法规要求对数据库访问、数据分级、敏感字段保护进行全过程管理。多数学校尚无完善的数据库合规体系，难以应对监管抽查与审计要求。</p><p>四、解决方案：基于行标、非侵入式的多维数据库风险监测体系<br/>（提示：技术的创新在于让安全“隐形”，让监测“无感”，让管理“有据”。）<br/>本方案立足教育行业特性，构建“基于行标、非侵入式、多维度场景化”的数据库风险监测系统，实现从资产发现、风险识别、告警分析到处置闭环的全流程管控。</p><ol><li>基于行标的精准风险识别<br/>方案以数据库行级标识（Row-level Tagging）为核心技术，通过对数据行、字段、表的全局行标化管理，实现数据风险的“定点追踪”。每条数据的来源、访问路径、风险等级均可溯源，彻底解决教育机构“谁访问了什么数据”无法确认的问题。<br/>行标机制配合分类分级策略，将数据库内容按敏感度划分为四级（公开、内部、敏感、高敏），并自动匹配教育场景规则，如“学生隐私”“科研成果”“家校通信”等，形成教育行业专属的风险识别体系。</li><li>非侵入式采集与智能分析<br/>采用旁路式数据镜像和日志流式采集技术，实现对数据库访问行为的全量捕获，无需在数据库内部部署代理或修改内核配置，从根本上避免对教务系统、选课系统、考试平台等业务性能的影响。<br/>系统实时采集数据库会话、SQL操作、访问IP、时间、用户行为等元数据，并通过AI引擎建模分析异常模式，如越权访问、批量导出、数据篡改等风险行为，做到“零干扰监测、实时发现异常”。</li><li>多维度场景化风险建模<br/>教育行业数据库风险监测不仅要识别“技术层风险”，更要理解“业务场景语义”。系统基于多维度场景建模方法，从身份、时间、操作、对象、场景五个维度分析访问行为。<br/>通过场景语义识别，系统可自动区分“正常操作”与“异常行为”，实现风险精准判定与动态告警，大幅降低误报率。</li><li>风险闭环与自动化治理<br/>方案提供风险分级响应机制：高危行为即时拦截，中危行为自动锁定账号，低危行为记录追踪并生成风险档案。所有操作均留存至日志审计中心，实现事件可查、行为可追、责任可究。<br/>同时，监测结果可通过API与学校已有安全系统（如身份认证、访问控制、数据脱敏平台）联动，实现“检测—处置—防护”的闭环防御体系。</li></ol><p>五、应用落地：教育行业的多场景安全赋能<br/>（提示：方案落地的价值，在于既守护安全底线，又释放数据潜能。）<br/>在多个省市教育信息化建设项目中，知形-数据库风险监测系统已完成规模化落地，覆盖教育局、重点中学及教育集团多个层级，实现了从教学数据安全到科研数据防护的全场景闭环。<br/>场景一：智慧校园数据库安全监管<br/>系统部署在市级教育数据中心，通过非侵入式采集方式实现对辖区内学校数据库的集中监控。实现多源数据库统一视图、敏感数据自动识别、异常访问实时告警，帮助教育局建立“数据安全态势看板”，首次实现从“被动审计”到“主动监管”的转变。<br/>场景二：在线教学平台数据防泄漏<br/>针对在线教学平台访问量大、访问行为复杂的特点，系统通过行为分析模型识别异常下载与外部调用，及时阻断教师账号批量导出学生名单等风险行为，实现防泄漏、防滥用、防越权的精细化管理。<br/>场景三：教育科研数据库风险识别<br/>科研数据涉及成果论文、专利材料等高价值内容。知形-数据库风险监测系统通过行标追踪技术，精确记录科研数据访问路径，实现科研成果全流程可追溯，有效防止成果泄密和内部违规。<br/>经过部署验证，该系统在不同规模学校中均表现出稳定性和高效性：平均可发现潜在风险事件数量提升120%，误报率下降至3%以下，安全巡检时间缩短80%。</p><p>六、推广价值：以智能监测推动教育数据安全新范式<br/>（提示：从单点防护到系统治理，教育数据安全治理正在从“战术阶段”迈向“战略阶段”。）<br/>知形-数据库风险监测系统的推广，不仅是一次技术创新，更是教育安全治理体系的结构性升级。其价值体现在以下三个层面：<br/>1、合规保障价值<br/>系统内置教育行业专属合规模型，对标《教育数据安全指南》《个人信息保护法》等标准，实现自动合规审计与风险追踪，帮助教育机构在监管检查中快速生成合规报告，合规成本降低30%以上。<br/>2、教学支撑价值<br/>通过非侵入式监测，保障教学业务稳定运行，为成绩管理、招生录取、资源共享等关键场景提供安全屏障，解决“安全措施影响教学体验”的长期难题。<br/>3、数据治理价值<br/>风险监测结果反哺数据治理体系，形成数据库资产分布图、风险热力图、行为分析报告，为教育局制定数据安全政策提供决策支撑，促进“安全治理数据化、管理智能化”。</p><p>七、问答环节<br/>Q1：知形-数据库风险监测系统会不会影响教务系统或考试报名等关键业务？A：不会。采用非侵入式架构，无需修改数据库配置，通过镜像采集实现后台监测，保障教学与管理系统稳定运行。<br/>Q2：教育局如何同时监管多所学校的数据库安全？A：该方案支持多级分层监控，可按“省—市—县—校”四级统一管理，集中展示各校数据库风险态势，实现分级监管。<br/>Q3：如何识别教师、学生等不同角色的异常访问？A：该方案基于行标识别与场景建模，自动区分正常教学操作与异常行为，如夜间批量导出学生信息会被实时告警。<br/>Q4：在教育局层面，如何实现多校数据库的统一监管？<br/>A：该方案支持多维度场景化联动监控，可在“省-市-县-校”四级架构下集中展示数据库安全态势，实现分级授权、分域管控，教育局可一屏掌握全域风险动态。<br/>Q5：如何满足教育监管部门的合规审查要求？A：内置《教育数据安全指南》等合规模型，可自动生成安全报告与日志审计，助力教育机构快速通过监管审查。</p><p>八、用户评价<br/>来自多个教育集团与教育局的反馈表明，知形-数据库风险监测系统的部署极大提升了教育数据安全管理能力：<br/>某省教育厅信息中心表示：“知形-数据库风险监测系统上线后，我们第一次实现了对下属学校数据库风险的实时感知，极大提升了监管透明度。”<br/>某市教育集团IT主管指出：“知形-数据库风险监测系统自动识别风险点、生成合规报告，让我们从繁琐的人工排查中解放出来，工作效率提升三倍以上。”<br/>这些实践证明，知形-数据库风险监测系统，已成为教育数据安全建设的核心支撑之一。<br/>知形-数据库风险监测系统，以“基于行标、非侵入式、多维度场景化”为核心技术特征，真正实现了教育数据的全可见、全可控、全可溯。它不仅弥补了传统安全监测的空白，更以智能、轻量、合规的方式，为教育数据治理提供了可复制、可推广的路径。</p><p>作为国家教育信息化标准体系的重要参与者，知形-数据库风险监测系统研发团队已参与多项国家及行业标准制定工作，其产品通过了中国信通院、工信部等权威机构认证，入选Gartner《Hype Cycle for Data Security in China, 2024》报告，成为教育数据安全领域的技术标杆。<br/>未来，知形-数据库风险监测系统将持续深化AI智能识别、跨域监测与可视化防御能力，助力教育机构构建更稳健、更智能、更可信的数据安全防线，让安全成为教育高质量发展的坚实底座。</p>]]></description></item><item>    <title><![CDATA[AI驱动的技术突破：打造先进且合规的医疗]]></title>    <link>https://segmentfault.com/a/1190000047390294</link>    <guid>https://segmentfault.com/a/1190000047390294</guid>    <pubDate>2025-11-11 20:06:03</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>一、概要：<br/>在数字医疗快速发展的时代，医疗数据正成为推动临床诊疗、科研创新与医院管理的核心生产要素。如何在保障数据安全与隐私的前提下，实现数据的高效流通与智能治理，成为行业面临的关键命题。<br/><a href="https://link.segmentfault.com/?enc=F28m%2FC8tcH4JHmJnulc1Lg%3D%3D.n6KPaHTCIXWVIFqcx%2FjZkSOXUZgCrKko4tMc2SZ1PlrfKy%2FiBEq2u9ZldUXSA9cp" rel="nofollow" target="_blank">知源-AI数据分类分级系统</a>，结合医疗行业的合规要求与业务特性，打造从数据全量发现、智能分级、合规审查到多系统联动应用的完整闭环。通过技术创新实现“分类服务临床”的目标，帮助医疗机构在合规基础上释放数据价值，提升运营效率，实现“安全、智能、先进、可持续”的数据治理体系。目前，该方案在多地三甲医院成功落地，分类准确率超过95%，效率较人工提升12倍以上，已成为智慧医疗领域数据安全建设的标杆性实践。</p><p>二、智慧医疗的“数据洪流”下，安全与合规的双重考验<br/>（提示：医疗数字化浪潮下，数据价值与风险并存。）<br/>随着智慧医疗深入推进，医疗数据的类型、规模与流转频次呈爆炸式增长。从HIS到LIS、PACS，从电子病历到科研数据库，数据跨系统、跨场景流动，成为连接医患、科研与管理的“数字血脉”。然而，这一繁荣背后也隐藏着严峻挑战：<br/>一方面，医疗数据中包含大量敏感个人信息，泄露事件轻则侵犯隐私、损害机构声誉，重则触发监管处罚乃至公共安全风险；另一方面，医疗数据形态复杂，既有结构化指标，也包含影像、报告等非结构化内容，传统人工方式难以完成高质量分类与管理。<br/>监管政策也日趋严格，《数据安全法》《个人信息保护法》《医疗数据安全管理办法》《电子病历应用规范》等文件，明确提出医疗数据应实施“分级分类、动态管控”，要求医院建立全链条安全责任体系。这意味着，数据分类分级不再是“合规选项”，而是医疗信息化体系的必备基石。</p><p>三、行业痛点分析：合规压力、系统割裂与人工瓶颈<br/>（提示：从合规风险到数据孤岛，医疗机构面临多重痛点。）<br/>当前，大多数医疗机构在数据分类分级实践中仍存在以下突出问题：<br/>数据分散，资产不清：不同系统独立运行，医院难以掌握数据全貌，尤其是科室自建“影子科研库”，形成监管盲区。<br/>人工梳理效率低：大型医院每天产生上万条记录，人工分类往往需要数周才能完成，且易出错、标准不一。<br/>分级标准不统一：科研数据、临床数据、管理数据边界模糊，缺乏行业统一的分类框架，导致合规风险隐患。<br/>业务影响与合规冲突：部分系统上线后需中断业务操作或影响临床流程，导致医务人员抵触。<br/>隐私保护难与业务共享矛盾：在科研、远程诊疗、医保对接等场景中，如何在保护患者隐私的同时保障数据可用，是全行业的核心难题。<br/>四、解决方案：AI大模型驱动的智能化医疗数据分类分级系统<br/>（提示：以AI技术突破传统瓶颈，实现全流程自动化与精准化治理。）<br/>为破解医疗行业在数据治理中的结构性难题，本方案基于知源-AI数据分类分级系统，打造集“全量发现—智能分级—合规审查—安全应用”于一体的先进系统，实现技术、流程与政策的有机统一。<br/>（一）数据资产接入：零干扰，全面发现<br/>采用非侵入式设计，支持主动扫描、接口对接及文件导入三种模式：<br/>主动扫描：在夜间业务低谷期自动执行，对HIS、LIS、PACS等系统进行全量扫描，精准识别多源数据库。<br/>接口对接：通过标准API连接CDR或元数据平台，无需直连核心数据库，即可安全获取电子病历、检验数据。<br/>文件导入：支持CSV/XLS格式导入，适配基层医院离线环境，实现“数据在哪、有多少”一目了然。<br/>（二）智能标签体系：贴合医疗业务的专属标准<br/>知源-AI数据分类分级系统内置《医疗数据分类分级指南》模板，结合AI学习模型，将数据分为基础类、临床类、管理类、科研类四大类，细化敏感等级。支持为特定业务创建专属标签，如“基因检测数据”“疫苗接种记录”等，实现高度灵活与场景适配。<br/>（三）AI驱动分级：自动化主导，人工辅助<br/>知源-AI数据分类分级系统融合深度学习与医疗知识图谱的多模态引擎，能够自动识别病历中的结构化与非结构化内容，例如从影像报告中识别“肺结节”字段并自动分级。<br/>AI模型持续学习行业最新术语，结合负样本训练，准确率稳定在95%以上。人工干预仅用于极少数特殊场景，实现“机器分级+专家校准”的最佳组合。<br/>（四）合规审查机制：标准化与专业化双保障<br/>内置符合《医学研究伦理审查办法》《电子病历规范》的合规引擎，联合病案科与安全专家共同审核，自动生成“数据分布、敏感占比、合规建议”报告，支撑审计与监管检查。<br/>（五）多系统联动：分类结果“一处生成，多处生效”<br/>分类结果可通过OpenAPI或Kafka消息总线同步至访问控制、脱敏与审计系统。例如医生在调阅病历时，系统自动校验权限；科研人员访问病历时，隐私字段自动脱敏。<br/>这一机制实现了从被动合规到主动防护的转变，真正让分类结果在安全体系中“活起来”。</p><p>五、应用落地：从省级医疗集团到智慧医院的实证成果<br/>（提示：真实案例验证AI赋能带来的高效、安全与可复制性。）<br/>以某省级医疗集团为例，其下辖三甲总院及多家分院，数据分布复杂、系统异构、科研库繁多。传统人工方式需4周完成一次病历分类，且存在误归与重复劳动。<br/>部署知源-AI数据分类分级系统后，集团实现以下突破：<br/>资产识别率达99%：成功发现12个隐藏科研数据库，形成完整数据资产清单；<br/>分类效率提升12倍：10万份病历3小时处理完毕，准确率95%以上；<br/>全域统一标准：跨院区、跨系统分类规则统一，科研与临床共享同一语义框架；<br/>合规自动化率超90%：系统输出可直接用于卫健委审计，合规工作量大幅降低；<br/>业务无干扰：扫描与分级均在夜间执行，不影响诊疗系统正常运行。<br/>该项目顺利通过省级数据安全检查，并成为当地智慧医疗示范工程。其成果不仅优化了医院内部治理，也为区域医疗数据协同提供了安全底座。</p><p>六、推广价值：以AI为核心，构建医疗数据治理新范式<br/>（提示：安全、效率与创新三维并进，释放数据长远价值。）</p><ol><li>强化合规性与风险防控<br/>深度匹配《数据安全法》《个人信息保护法》及等保2.0要求，对传染病史、精神病史、基因数据等敏感信息精准识别与分级，确保医疗机构合法合规运营。</li><li>提升运营效率与科研能力<br/>分类分级后的数据可直接用于AI辅助诊断、科研模型训练与质量管理，助力医院实现“数据驱动型决策”。同时，病历查询时间缩短至原来的1/5，大幅提升医生工作效率。</li><li>赋能智慧医疗创新<br/>系统为智慧门诊、远程会诊、区域医疗协同提供合规数据支撑，推动数据共享与精准医疗落地。<br/>通过AI学习与自动策略更新，产品可持续适应医疗政策变化，具备长期可演进性。</li><li>实现安全与价值并重的数字生态<br/>知源-AI数据分类分级系统从单点防护迈向体系化安全治理，实现“发现—防护—审计—复用”的全生命周期管理，让医疗数据成为安全可用的生产力资源。</li></ol><p>七、问答环节<br/>Q1：医疗机构在推进数据分类分级时，最难解决的问题是什么？<br/>A1：主要难点在于数据分散、格式复杂及工作量巨大。通过智能识别与统一标准，可在不影响业务运行的前提下快速完成数据盘点，为合规治理奠定基础。<br/>Q2：知源-AI数据分类分级系统如何做到既符合政策要求，又不增加医务人员负担？<br/>A2：以标准化标签体系为基础，结合临床、科研等场景灵活调整分类规则，让分级结果更贴近实际业务，同时系统自动化处理大部分工作，显著降低人工压力。<br/>Q3：面对多系统并行的复杂环境，数据安全如何得到保障？<br/>A3：通过非侵入式接入与多系统联动机制，分类结果在访问控制、脱敏、审计等环节同步生效，实现“业务不中断、合规不缺位”。<br/>Q4：在效率和准确性方面，智能化手段能带来多大提升？<br/>A4：以往需数周人工完成的病历分类，如今可在数小时内完成，分类准确率稳定在95%以上，大幅提升合规与运维效率。<br/>Q5：知源-AI数据分类分级系统落地后，对医疗机构的核心价值体现在哪？<br/>A5：不仅能满足监管合规要求，更促进了数据的安全共享与价值释放，为智慧门诊、科研创新、远程会诊等新业务提供安全支撑。</p><p>八、用户评价：从“合规负担”到“价值引擎”的转变<br/>多家应用知源-AI数据分类分级系统的医疗机构普遍反馈：<br/>数据分类分级由“合规压力”转变为“业务助推力”；<br/>医院数据安全事件零发生率，合规检查一键通过；<br/>临床医生调阅影像、病历时间缩短80%，科研数据脱敏复用更高效；<br/>病案管理员可将多年经验沉淀为模板，显著减轻工作负担。<br/>一位三甲医院信息中心负责人评价道：<br/>“知源-AI数据分类分级系统让我们第一次真正‘看清’了医院的数据资产。它不仅让合规更轻松，也让科研和诊疗更精准。这是智慧医疗建设中最具现实意义的一步。”<br/>医疗数据分类分级，是智慧医疗安全体系的基石，更是医疗数字化转型的关键起点。知源-AI数据分类分级系统，打破了传统分类分级的人工瓶颈与精度限制，实现了“安全合规、智能高效、持续演进”的全新范式。<br/>该产品由全知科技研发，凭借深厚的技术积淀与医疗行业经验，已入选 Gartner全球数据安全成熟度曲线报告 及 《中国网络安全细分领域产品名录》推荐厂商。其技术方案获得业内专家一致认可，被视为推动医疗机构数据安全体系建设的权威解决方案。<br/>未来，知源-AI数据分类分级系统以AI为核心动力，助力医疗机构构建数据安全、隐私保护与价值创新的统一体系，让“以数据赋能医疗、以安全守护健康”成为现实。</p>]]></description></item><item>    <title><![CDATA[Apache Doris 4.0.1 版]]></title>    <link>https://segmentfault.com/a/1190000047390299</link>    <guid>https://segmentfault.com/a/1190000047390299</guid>    <pubDate>2025-11-11 20:05:30</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>亲爱的社区小伙伴们，<strong>Apache Doris 4.0.1 版本已于 2025 年 11 月 08 日正式发布。</strong>此版本聚焦核心模块的打磨与优化，在 AI &amp; Search 方面实现了重要能力扩展，同时全面提升了 Lakehouse 与查询引擎的稳定性和性能。</p><ul><li>GitHub 下载：<a href="https://link.segmentfault.com/?enc=WTooboPsGZsgqNVzV5kacQ%3D%3D.yFTbCJeqPEVPjgo8WYV3Rave%2BZht4yIGE4sOl33CS%2B%2FOR3HGLeocGex2VTdtPFWd" rel="nofollow" target="_blank">https://github.com/apache/doris/releases</a></li><li>官网下载：<a href="https://link.segmentfault.com/?enc=Ff6lCe4v5iJ1Lq1CEcYa6w%3D%3D.mrsHYvHmuMYlzPYa3i4xPJ9UUsZABIutQVuoUxVz%2F9UV9C7LD1SzwuIpibyyQVJG" rel="nofollow" target="_blank">https://doris.apache.org/download</a></li></ul><h2>行为变更</h2><ul><li><code>SHOW PARTITIONS</code> 命令不再支持 Iceberg 表，请直接使用 Iceberg 的 <code>$partitions</code> 系统表查看。#56985</li></ul><h2>新增功能</h2><ul><li>新增 mmh64_v2 函数，用于生成与其他三方库相同的 Hash 结果。#57180</li><li>新增 json_hash 函数，支持对 JSONB 类型生成 Hash 值。#56962</li><li>新增 Binary 数据类型，并增加一系列函数 length、from_base64_binary、to_base64_bianry、sub_binary。#56648</li><li>新增 sort_json_object_keys / normalize_json_numbers_to_double 函数，用于对 JSONB 的 Key 进行排序。</li><li>新增与 MySQL 兼容的时间函数：UTC_DATE、UTC_TIME 及 UTC_TIMESTAMP。#57443</li><li><p>新增对 MaxCompute Schema 层级的支持。 #56874</p><ul><li>相关文档：<a href="https://link.segmentfault.com/?enc=dW3UPfz5UAP1qRgDo2ZSlw%3D%3D.rsHBpnRVwu9WxYIH74vbTib5viyAD6O0wBlZo03Uo0w%2Ft6W8Led6dz4pdrYeoVjtY1RY%2BlrruYNffDI2Nv4qIVoKhQYWw5IjIJIm1HT0oeMPkBZKfcDnRGtgE9K3A79R" rel="nofollow" target="_blank">https://doris.apache.org/docs/3.x/lakehouse/catalogs/maxcompu...</a></li></ul></li><li>JSON_OBJECT 函数支持使用 * 作为参数。#57256</li></ul><h2>功能改进</h2><h3>AI &amp; Search</h3><ul><li>为 SEARCH 函数新增短语查询、通配符查询和正则查询支持。#57372 #57007</li><li>扩展 SEARCH 函数参数，新增可选的 default_field 参数（默认列）和 default_operator 参数（指定多列查询的布尔运算符为 "and" 或 "or"）。#57312</li><li>SEARCH 函数新增对 Variant 类型子列的搜索支持，可通过点号语法（如 variantColumn.subcolumn：关键词）直接搜索 JSON 路径中的特定字段。</li><li>将倒排索引的默认存储格式由 V2 升级为 V3 版本。#57140</li><li>完善自定义分词器 Pipeline 支持，新增 char_filter 组件；在 Analyzer 框架中新增 Basic Tokenizer 和 和 ICU Tokenizer 两种内置分词器支持；新增内置分词器别名并支持组件同名配置，优化统一 Analyzer 框架。#57055</li></ul><h3>Lakehouse</h3><ul><li><p>新增会话变量 <code>merge_io_read_slice_size_bytes</code> 来解决某些情况下，外表 Merge IO 读放大严重的问题。</p><ul><li>相关文档：<a href="https://link.segmentfault.com/?enc=EkFpaxCz1SJzXOMg0AWVBw%3D%3D.SF8ik9mIPFRXaXn751WuITZOiUXX%2BBJJrTUlpCi3jvRncGXjBqqfGmYaMLhoD8fBR%2FklwQOYuM0DkfubtLYX5j1AqC17cGsGDLE4PArpLtAl7nm8NHrQomq232%2FD7%2F66" rel="nofollow" target="_blank">https://doris.apache.org/docs/3.x/lakehouse/best-practices/op...</a></li></ul></li></ul><h3>查询</h3><ul><li>优化了 JOIN Shuffle 选择算法 #56279</li></ul><h3>其他</h3><ul><li>优化了物理计划中 Runtime Filter 序列化信息的大小 #56978</li></ul><h2>问题修复</h2><h3>AI &amp; Search</h3><ul><li>修复非分词字段的 SEARCH 查询结果问题，支持在 MOW 表上执行 SEARCH 函数查询 #56927</li><li>修复倒排索引在执行 IS NULL 谓词过滤时的计算错误问题 #56964</li></ul><h3>Lakehouse</h3><ul><li>修复某些情况下，谓词下推无法使用 Parquet Page Index 的问题 #55795</li><li>修复某些情况下外表查询分片读取丢失的问题 #57071</li><li>修复某些情况下，Hadoop 文件系统缓存开启导致修改 Catalog 属性不生效的问题 #57063</li><li>修复某些情况下，从旧版本升级时，连接属性校验导致元数据回放失败的问题 #56929</li><li>修复某些情况下，Refresh Catalog 导致 FE 线程死锁的问题 #56639</li><li>修复无法读取由 Hive 转换生成的 Iceberg 表的问题 #56918</li><li>修复某些情况下收集 Query Profile 导致 BE 宕机的问题 #56806</li></ul><h3>查询</h3><ul><li>修复 datetime 类型在 Timezone 相关 Cast 时，边界条件下结果错误的问题 #57422</li><li>修复部分 datetime 相关函数结果精度推导不正确的问题 #56671</li><li>修复 inf 作为 float 的谓词条件时 Core 的问题 #57100</li><li>修复 explode 函数在可变参数下 Core 的问题 #56991</li><li>修复 decimal256 到 float 类型的 Cast 不稳定的问题 #56848</li><li>修复 Spill Disk 时可能出现重复调度导致 Core 的问题 #56755</li><li>修复偶发的错误调整 Mark Join 和其他 Join 顺序的问题 #56837</li><li>修复部分命令未被正确转发到 Master Frontend 执行的问题 #55185</li><li>修复偶现的窗口函数错误生成 Partition TopN 的问题 #56622</li><li>修复当同步物化视图定义中存在关键字时，查询可能报错的问题 #57052</li></ul><h3>其他</h3><ul><li>禁止基于同步物化视图创建另外一个同步物化视图 #56912</li><li>修复 Profile 中存在内存未及时释放问题 #57257</li></ul>]]></description></item><item>    <title><![CDATA[全景式数据库风险监测的理论与实践：加密防]]></title>    <link>https://segmentfault.com/a/1190000047390301</link>    <guid>https://segmentfault.com/a/1190000047390301</guid>    <pubDate>2025-11-11 20:04:35</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>（提示：数据库风险监测正在成为企业数字化安全体系的核心枢纽，其加密防御、低误差识别与全景式分析能力，正推动数据安全管理从被动响应走向主动防御。）<br/>摘要：<br/>在数字经济的高速演进中，数据库已成为企业最关键的资产载体。无论是金融交易记录、医疗病历档案，还是互联网平台的用户行为数据，都以数据库为中心进行存储与调用。然而，这些宝贵的数据同时也成为网络攻击与内部违规操作的重点目标。传统的安全机制，如防火墙、入侵检测与加密存储，虽然能够防御部分外部威胁，却无法实时识别数据库层面的深层次风险。<br/><a href="https://link.segmentfault.com/?enc=qRTM7kq7Mp31dUDsvINkEw%3D%3D.xDlPY6l2TGKefdFKTtwh5foj3kDrLoDBNBqHwKhJZ79aXAQYN5tgw3zprxXAwnQQ" rel="nofollow" target="_blank">知形-数据库风险监测系统</a>正是在此背景下应运而生。它以全景式的视角对数据库运行状态进行实时监控，融合加密传输、防篡改日志、智能分析等技术手段，实现从风险发现、行为识别到预警响应的全链路防御体系。相比传统的事后审计模式，数据库风险监测通过低误差识别模型与多维度行为分析，能在威胁形成初期即进行精准告警，从而最大限度降低数据泄露与系统中断的概率。<br/>这一体系的落地成效已在多个行业显现。金融机构通过风险监测系统识别了账户盗用行为，医疗机构通过监测避免了敏感病历的非法导出，互联网企业借助实时流量分析防止了批量数据爬取。事实证明，数据库风险监测不仅是安全技术的进步，更是数字治理能力的体现，是企业迈向合规与智能安全的重要标志。</p><p>一、数据库风险监测是什么<br/>（提示：数据库风险监测是一种以实时感知、加密防护和全景分析为核心的新型安全理念，它通过低误差识别与持续监测，实现对数据库运行态势的智能防御与风险预警。）<br/>（一）数据库风险监测的核心逻辑<br/>数据库风险监测的核心逻辑，是在不影响业务运行的前提下，通过对数据库访问流量、操作指令与行为模式的实时采集和智能分析，识别潜在的安全威胁。它突破了传统“事后审计”的局限，转而以“事中防御”和“全景可视”为目标，使数据库安全从被动响应迈向主动防御。<br/>在底层机制上，数据库风险监测系统通过旁路镜像或协议分析的方式获取数据库通信流量，对访问行为进行细粒度解析。系统能够精确识别出访问者的身份、来源IP、操作类型、访问时间及对象级别（表、字段、视图），并结合历史基线判断行为是否异常。若发现越权访问、大量敏感数据导出或异常SQL操作，系统可在毫秒级触发告警或阻断策略，实现动态化风险防御。<br/>此外，数据库风险监测并非单纯依赖规则匹配，而是借助行为建模与机器学习技术形成自适应识别机制。通过不断积累访问行为数据，系统能够自我优化判断逻辑，减少误报与漏报，使安全监测更加精准高效。这种低误差智能识别，使风险发现不再依赖人工干预，而成为系统级自动响应的一部分。<br/>（二）数据库风险监测的核心能力<br/>数据库风险监测的核心能力，是建立在加密防护与数据可信的基础之上，通过实时性、独立性、扩展性、可靠性与易用性五个维度构建起系统性安全防线。</p><ol><li>实时性：毫秒级感知与精准响应<br/>数据库攻击往往在极短时间内完成，因此实时监测是系统的首要能力。风险监测系统通过高速解析引擎与智能策略匹配，实现SQL指令、表级操作与访问行为的毫秒级识别。一旦检测到大规模敏感数据导出或越权访问行为，即可即时触发告警和阻断，最大限度降低损失。</li><li>独立性：非侵入式架构，确保系统稳定<br/>监测系统采用独立于数据库的部署架构，即便数据库或操作系统遭受破坏，仍能保证日志的完整与加密可追溯。其非侵入式旁路模式不会影响数据库性能或业务运行，确保监测与防护在后台持续进行。这种架构不仅保护了系统稳定性，也提高了监测数据的客观性。</li><li>扩展性：支持多数据库与多环境协同<br/>现代企业数据库环境复杂，涉及云上与本地部署并存。风险监测系统支持多类型数据库（Oracle、MySQL、SQL Server、PostgreSQL等）以及分布式部署，可实现多节点横向扩展与集中管理。数据库风险监测系统可平滑对接安全运营中心、日志审计平台与威胁情报系统，实现跨系统协同与风险可见。</li><li>可靠性：加密存储与容错机制保障持续运行<br/>数据库风险监测系统在日志采集、传输与存储过程中全程加密，并采用哈希验证与回收站机制，确保数据不可篡改、可恢复。即使在系统故障或断电情况下，审计记录仍能自动保存并恢复，保障风险追踪的连续性与可信性。同时，系统支持36个月以上的在线日志存储，满足合规要求。</li><li>易用性：全景化可视与智能化运维<br/>数据库风险监测系统提供基于用户、操作、客体的全景分析界面，通过图表化视图展示访问趋势、风险分布与行为画像。安全管理人员可一目了然地掌握数据库态势，无需手动筛查海量日志。结合AI算法，系统还能自动识别异常模式并生成安全报告，使安全运营更直观、更智能。</li></ol><p>二、数据库风险监测常见的FAQ<br/>（提示：理解数据库风险监测的应用与原理，需从常见问题中洞察其技术本质与管理价值。）<br/>Q1:数据库风险监测与数据库审计有何区别？<br/>A1:数据库审计侧重“事后可追溯”，主要通过日志记录实现责任界定。而数据库风险监测以“事中实时防御”为目标，能够在风险发生前主动预警，是从静态审计到动态防御的跨越。<br/>Q2:风险监测会不会影响数据库性能？<br/>A2:现代系统多采用旁路采集或镜像流量分析，不直接嵌入数据库进程，因此不会造成性能下降。同时，通过分布式部署和缓存优化机制，系统能在高并发场景下保持低延迟运行。<br/>Q3:加密机制如何确保数据传输安全？<br/>A3:数据库风险监测使用TLS加密通道及动态密钥更新机制，确保监测数据在采集、传输、存储的全过程中都具备防窃取与防篡改能力。<br/>Q4:系统如何保证低误差识别？<br/>A4:通过引入AI算法与自适应模型，系统在分析历史访问特征时会自动调整阈值与特征权重，使误报率持续下降。同时，人工校验与模型反馈机制形成闭环，进一步提升准确度。<br/>Q5:系统支持哪些数据库类型？<br/>A5:支持主流关系型数据库（Oracle、MySQL、SQL Server、PostgreSQL等）及部分非关系型数据库（MongoDB、Redis等），并能跨云、跨平台实现统一监控。</p><p>三、发展趋势<br/>（提示：数据库风险监测正从静态规则走向智能化，从单点监控走向全景治理，形成加密化、智能化与低误差化的未来方向。）</p><ol><li>加密与隐私计算深度融合。<br/>未来数据库风险监测将更多采用隐私计算、同态加密等技术，在不暴露原始数据的前提下完成安全分析，实现“可监测而不可见”的新型防护模式。这将极大提升敏感行业的合规与安全能力。</li><li>AI驱动的自学习防御。<br/>系统将通过深度学习技术建立行为模型，动态学习数据库操作规律。当系统发现“非典型”行为时，可立即判定其风险等级，实现真正的自适应安全响应。</li><li>全景式数据安全运营中心建设。<br/>数据库风险监测将不再是独立模块，而成为企业安全运营中心（SOC）的重要组成部分。通过与威胁情报、日志审计、网络防火墙联动，实现从底层数据到业务层的安全一体化管理。</li><li>从检测到治理的闭环延伸。<br/>未来系统不仅检测风险，还能自动生成整改建议，甚至执行配置修复。例如，当检测到弱口令或未加密传输时，系统可自动调用接口完成加固，实现无人值守的风险治理。</li><li>跨行业标准化与合规融合。<br/>随着《数据安全法》《个人信息保护法》及国际标准（GDPR、ISO 27001）的普及，数据库风险监测将成为企业合规管理的核心工具，形成“合规即安全”的行业共识。<br/>数据库风险监测的出现，标志着数据安全从“防线思维”迈向“感知思维”的变革。它以加密为底、以智能为核、以全景为视，通过低误差的风险识别与全生命周期监控，为企业构筑起坚不可摧的数字安全屏障。未来，谁能掌握数据风险的实时感知与精准防御，谁就能在数字时代的竞争中立于不败之地。</li></ol>]]></description></item><item>    <title><![CDATA[智能识别与持续合规：构建运行平稳的API]]></title>    <link>https://segmentfault.com/a/1190000047390304</link>    <guid>https://segmentfault.com/a/1190000047390304</guid>    <pubDate>2025-11-11 20:03:48</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>（提示：在数字化浪潮下，API风险监测系统正成为企业实现稳定运营与合规治理的关键基石。）<br/>概要：随着数字经济的持续发展，数据已经成为企业最重要的生产要素之一，而API（应用程序接口）作为数据流通的“高速通道”，支撑着业务系统间的交互与协同。从银行转账、在线购物到智慧政务，几乎所有数字化服务都离不开API的参与。与此同时，接口暴露面急剧扩大，安全威胁也随之增加。API漏洞被利用导致的数据泄露、业务中断、越权访问等问题屡见不鲜，使API安全成为企业运营的“隐形命脉”。<br/>传统安全手段往往聚焦静态防御和已知攻击规则，难以应对复杂多变的业务逻辑攻击和影子接口风险。而API风险监测系统的出现，则让企业在“运行平稳”的前提下实现“智能识别”与“持续合规”。它通过流量分析、数据画像与智能学习，全面感知API运行状态，精准识别异常行为与潜在风险，并结合法规要求实现从监测到响应的全链路安全闭环。<br/><a href="https://link.segmentfault.com/?enc=%2BHeadjhgLpbqOzPoosj8wg%3D%3D.UYbEbQxQiNnyJuQ9CpHui6XJwLa8cRKT7zrg78olJUZ4cC%2FmzV%2FiGPeyu9z%2F1g0X" rel="nofollow" target="_blank">知影-API风险监测系统</a>的价值不仅在于安全防护的提升，更在于它以智能识别与合规治理为核心，将API安全纳入企业数据治理体系，为业务创新和数字化转型提供可持续支撑。本文将从理论角度阐释API风险监测系统的定义、核心逻辑、技术能力、常见问题及未来发展趋势，探索其在构建安全稳定的数字生态中的战略意义。<br/>一、API风险监测系统是什么<br/>（提示：要理解API风险监测系统的价值，首先要从其基本定义与逻辑出发，明确它为何成为企业数字安全的重要支点。）<br/>API风险监测系统是指一种基于流量分析、智能识别和数据建模的安全治理体系，旨在通过自动发现、实时监测和持续分析，识别并防范API在运行过程中出现的各类风险。它不是简单的防御工具，而是覆盖“可见—可控—可追踪”三大阶段的智能安全架构。其核心目标在于帮助企业实现对API资产的全局感知，对异常行为的实时识别，对安全事件的精确溯源，以及对法规合规的持续保障。<br/>（一）API风险监测系统的核心逻辑<br/>在传统安全模式下，企业通常依赖WAF、漏洞扫描等静态防护手段，但这类机制的防护能力高度依赖预定义规则和已知攻击样本，面对复杂的业务逻辑滥用和未知漏洞时往往无能为力。API风险监测系统则以动态监测+行为建模为核心逻辑，通过采集全量API流量、自动生成接口画像，并结合大数据分析与机器学习算法，建立接口的正常行为基线。一旦系统检测到偏离常态的调用模式，便可自动识别并预警潜在风险。<br/>在架构设计上，该系统强调“全生命周期治理”理念，从接口发现、分类、监控、告警到响应形成闭环管理。例如，当一个影子API被检测到流量异常时，系统不仅会自动触发风险警报，还会溯源其调用者、请求参数与数据访问路径，实现可视化追踪。由此，企业可在问题扩散前完成处置，确保系统运行的平稳与业务的连续性。<br/>此外，系统逻辑还融合了合规治理思维。随着《网络安全法》《数据安全法》《个人信息保护法》的陆续实施，企业在API数据流转过程中承担更多安全与合规责任。API风险监测系统通过日志留痕、调用记录和合规报告自动生成机制，为企业提供了从检测到审计的全链条支撑，实现安全防护与法规合规的双重闭环。<br/>（二）API风险监测系统的核心能力<br/>1、全面可见性——让所有接口“被看见”<br/>API资产的盲区是企业安全的最大隐患。系统通过自动扫描、流量分析与元数据聚合，实现对所有接口（包括影子API、僵尸API、内部API）的全量识别与分类。它不仅能识别接口的功能与暴露面，还能分析其数据传输模式、风险等级和依赖关系，形成完整的API资产图谱。<br/>2、实时监测与智能识别——让风险“被发现”<br/>系统基于机器学习与语义建模算法，构建接口行为基线，通过分析调用频率、参数特征与响应模式，智能识别异常访问行为。例如在电商场景下，系统能自动识别出黄牛通过API批量抢购的自动化行为；在金融场景中，可发现异常的转账或越权交易请求。这种智能识别机制让企业在未知威胁面前具备前瞻性防护能力。<br/>3、风险预警与溯源分析——让攻击“被追踪”<br/>当系统发现潜在风险时，会即时告警并生成详细溯源报告，包括攻击来源、接口路径、请求内容及风险级别，帮助安全团队快速响应与修复。这种“取证级别”的可追溯能力，使企业在面对安全事件或监管审计时具备强有力的证据支撑。<br/>4、持续合规与审计支撑——让数据“被守护”<br/>在持续合规方面，系统可根据不同法规要求生成定制化合规报告，记录API调用日志、数据访问痕迹和敏感字段暴露情况。通过结构化提取与数据脱敏技术，系统既减少了数据存储量，又提升了隐私保护水平，为企业构建长效合规机制。<br/>综上，API风险监测系统的核心能力不仅在于技术防御，更在于通过智能化手段实现“运行平稳、风险可控、合规可证”的数字安全治理新模式。<br/>二、API风险监测系统常见的FAQ<br/>（提示：系统落地的过程中，企业通常会关注其使用效果、技术适配与运维成本等关键问题。）<br/>Q1:API风险监测系统与传统WAF、防火墙有何区别？<br/>A1:传统防护系统侧重于静态规则拦截，而API风险监测系统以动态学习和行为分析为核心，能够识别逻辑层攻击与异常调用。它不是替代，而是补充和升级，是从“防御”向“治理”的安全演进。<br/>Q2:该系统是否会影响业务性能？<br/>A2:API风险监测系统通过非侵入式流量镜像技术实现监测，对业务系统无感知、不干扰。其高性能数据处理引擎保证了在海量接口调用下的稳定运行，真正实现了“运行平稳”与“安全共存”。<br/>Q3:如何确保系统的识别准确率？<br/>A3:API风险监测系统采用多层模型融合机制，通过语义分析、行为特征提取与上下文比对，不断优化识别算法。结合强化学习与风险反馈机制，模型会根据历史事件自动调整识别权重，实现识别精度的持续提升。<br/>Q4:系统如何支持多行业、多场景应用？<br/>A4:由于系统具备高度可配置性，能够根据不同行业特征加载定制化风险规则与合规模块。无论是金融的交易风控、医疗的数据保护，还是政务的公共接口安全，系统都能快速适配与落地。<br/>Q5:持续合规如何实现？<br/>A5:API风险监测系统内置法规标准库和自动审计机制，结合可视化报表，为企业提供动态合规评估与整改建议。随着政策更新，规则库也会自动升级，确保企业始终保持合规状态。<br/>通过这些常见问题的解答，可以看到API风险监测系统不仅在技术上具备先进性，更在运营层面体现出长期稳定性和业务适配能力。<br/>三、发展趋势<br/>(提示：随着智能安全与自动化运维的发展，API风险监测正迈向智能协同与合规生态的新阶段。)<br/>未来的API风险监测将呈现出三大发展趋势：</p><ol><li>从“监测”走向“自治”<br/>随着AI模型能力增强，系统将不再仅限于识别与预警，而是实现自适应防护。基于强化学习的自进化模型，可根据历史风险事件自动生成防护策略，真正让安全体系具备“自我学习与自我修复”能力。</li><li>从“单点防护”走向“全域治理”<br/>API不再只是系统间的连接点，而是企业数据生态的核心节点。未来的风险监测系统将与数据安全平台、访问控制、身份管理等模块深度集成，形成统一的安全运营中心，实现从接口到数据全链路的安全闭环。</li><li>从“合规应对”走向“合规赋能”<br/>过去的合规多以应付检查为目的，而未来的趋势是让合规成为企业竞争力的一部分。API风险监测系统将通过自动化审计、可视化报告与实时监管接口，为企业提供“合规即服务”的能力，让法规遵从转化为信任与品牌资产。<br/>API已成为数字时代的基础设施，而API风险监测系统则是守护这套基础设施的智能中枢。它让风险可见、让合规可循、让系统稳定运行于无声之中。未来，随着人工智能与数据安全技术的进一步融合，一个运行平稳、智能识别、持续合规的API安全新生态，正在悄然形成。这不仅是安全治理的升级，更是数字世界信任体系的重塑。</li></ol>]]></description></item><item>    <title><![CDATA[ArrowDL BT下载工具v4.2.1]]></title>    <link>https://segmentfault.com/a/1190000047390317</link>    <guid>https://segmentfault.com/a/1190000047390317</guid>    <pubDate>2025-11-11 20:03:01</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>​</p><p>ArrowDL是一款轻量、简洁的 BT 下载工具（支持种子和磁力链接），这款 v4.2.1 中文版是官方或汉化过的中文界面版本，适合中文用户使用，操作简单，下载稳定。</p><h3>一、准备工作</h3><ol><li><strong>下载安装包</strong>：安装包下载：<a href="https://link.segmentfault.com/?enc=5AAy7AGPPiGl7MRDj1xlAg%3D%3D.FzlLD%2Bru2S4gcO2uqNatty0khqwxDyJrsXpCYd81733q6WFVkkax5sayvlznozIF" rel="nofollow" title="https://pan.quark.cn/s/0de61f776592" target="_blank">https://pan.quark.cn/s/0de61f776592</a></li><li><strong>关闭杀毒软件（可选）</strong> ：有些杀毒软件可能会误报，如果你信得过这个软件，可以先暂时关闭杀毒软件，避免安装被拦截。</li></ol><h3>二、开始安装</h3><ol><li><p><strong>双击运行安装包</strong></p><ul><li>找到电脑里刚下载好的 <strong>ArrowDL BT下载工具 v4.2.1 中文版.exe</strong>文件，<strong>双击它</strong>，就会弹出安装界面。</li></ul></li><li><p><strong>选择安装语言（一般默认中文）</strong></p><ul><li>如果弹出语言选择窗口，选 <strong>简体中文</strong>，然后点“确定”或“下一步”。</li></ul></li><li><p><strong>阅读并同意协议</strong></p><ul><li>接下来会看到“软件许可协议”之类的页面，<strong>大致看一下</strong>，如果你同意就勾选  <strong>“我同意”</strong> 或  <strong>“我接受”</strong> ，然后点  <strong>“下一步”</strong> 。</li></ul></li><li><p><strong>选择安装位置（可以不改）</strong></p><ul><li>默认会装在 C 盘某个文件夹（比如 <code>C:\Program Files\ArrowDL</code>），如果你想装别的盘（比如 D 盘），可以点  <strong>“浏览”</strong> ，选一个你喜欢的文件夹。</li><li><strong>不想改的话，直接点“下一步”就行。</strong></li></ul></li><li><p><strong>选择开始菜单文件夹（一般不用管）</strong></p><ul><li>它会问你要把快捷方式放到开始菜单的哪个文件夹里，一般保持默认，直接点  <strong>“下一步”</strong> 就行。</li></ul></li><li><p><strong>创建桌面快捷方式（建议勾选）</strong></p><ul><li>如果你希望以后能在桌面上直接点图标打开软件，记得勾选  <strong>“创建桌面快捷方式”</strong> ，然后点  <strong>“下一步”</strong> 。</li></ul></li><li><p><strong>确认信息并开始安装</strong></p><ul><li>最后会显示一遍你刚才选的设置（安装路径、快捷方式等），如果没问题，点  <strong>“安装”</strong> 按钮，就开始自动安装了。</li></ul></li><li><p><strong>等待安装完成</strong></p><ul><li>程序会自己复制文件、写入注册表等，这个过程可能几十秒到一两分钟，耐心等等，看到进度条走完就行。</li></ul></li></ol><h3>三、安装完成</h3><ol><li><p><strong>点“完成”退出安装向导</strong></p><ul><li>安装好后，会跳出提示说安装完成，点  <strong>“完成”</strong> 关掉安装窗口。</li></ul></li><li><p><strong>打开软件试试</strong></p><ul><li>你可以 <strong>双击桌面上的 ArrowDL 图标</strong>，或者去 <strong>开始菜单里找到 ArrowDL</strong>打开它。</li><li>第一次打开可能会让你选语言、设置下载目录等，按提示操作就行，一般选中文和默认目录就可以。</li></ul></li></ol><h3>四、开始使用</h3><ul><li>打开软件后，你可以添加 BT 种子文件（.torrent）或者磁力链接来下载资源，具体用法可以看软件里的“帮助”或自己摸索一下，界面一般都比较直观。</li></ul><p>​</p>]]></description></item><item>    <title><![CDATA[Mac 下载 VMware 11.1.0]]></title>    <link>https://segmentfault.com/a/1190000047390324</link>    <guid>https://segmentfault.com/a/1190000047390324</guid>    <pubDate>2025-11-11 20:02:13</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>​一、准备工作</p><ol><li><p><strong>确保你的 Mac 系统支持 VMware 11</strong></p><p>VMware 11 是比较老的版本，一般适用于 <strong>Mac OS X 10.8 到 10.10（也就是 Yosemite）</strong> 这个范围。如果你现在用的是 macOS 11（Big Sur）或者更高，比如 Monterey、Ventura、Sonoma，那这个版本很可能 <strong>装不上 或者 运行不了</strong>。建议先看看你现在的系统版本：</p><ul><li>点击屏幕左上角的 <strong>苹果图标 </strong></li><li>选  <strong>“关于本机”</strong></li><li>看看你的 macOS 是哪个版本</li></ul><p><strong>如果系统太新，建议找更高版本的 VMware，比如 VMware Fusion 12 或更新版。</strong></p></li></ol><h3>二、下载 VMware 11.1.0-1.dmg</h3><p><strong>VMware 11.1.0-1.dmg安装包下载：</strong><a href="https://link.segmentfault.com/?enc=EMl0fhZqtpvm17WQZBVZag%3D%3D.SGdzd5G6Rudnc8uPc%2FBAHvTIlF7mQ4NYNLCowDLgpXF1KBVdO4yFGdWZL7X6vIXl" rel="nofollow" title="https://pan.quark.cn/s/e04f55c2007c" target="_blank">https://pan.quark.cn/s/e04f55c2007c</a></p><p>把它放到你的  <strong>“下载” 文件夹</strong>或者桌面上都行。</p><h3>三、开始安装</h3><ol><li><p><strong>双击打开 VMware 11.1.0-1.dmg 文件</strong></p><p>找到那个 <code>.dmg</code>文件，双击它。</p><p>（通常会自动在桌面或访达边栏打开一个虚拟的“磁盘映像”窗口）</p></li><li><p><strong>看到 VMware Fusion 图标和 “Applications” 文件夹</strong></p><p>在打开的窗口里，你应该能看到一个 VMware Fusion 的图标，还有一个蓝色的 “Applications”（应用程序）文件夹图标。</p></li><li><p><strong>把 VMware Fusion 拖进 Applications 里</strong></p><p>把 VMware Fusion 的图标 <strong>直接拖到 “Applications” 文件夹图标上</strong>，就像平时安装软件那样。</p><p>系统会自动开始复制文件，等它自己完成就行。</p></li><li><p><strong>等待拷贝完成</strong></p><p>等进度条跑完，或者那个 VMware 图标不再闪烁，说明已经拷贝到应用程序里了。</p></li><li><p><strong>弹出安装包（可选但推荐）</strong></p><p>拷贝完成后，你可以右键点击桌面上或者访达里的 VMware 11.1.0-1.dmg 文件，选  <strong>“推出”</strong> ，把那个虚拟光盘图标清理掉。</p></li></ol><h3>四、打开 VMware Fusion</h3><ol><li><p><strong>去 “应用程序” 文件夹里找到 VMware Fusion</strong></p><p>打开你的  <strong>“访达” &gt; “应用程序”</strong> ，在里面找到 <strong>VMware Fusion</strong>这个应用。</p></li><li><p><strong>首次运行可能会被阻止</strong></p><p>如果你第一次双击它，Mac 可能会弹出提示说：“无法验证开发者” 或者不让打开。</p><p>这时你可以：</p><ul><li><strong>右键点击 VMware Fusion 图标</strong>，然后选  <strong>“打开”</strong> （不要直接双击！）</li><li>然后系统会再问一次，你点  <strong>“打开”</strong> 就行</li></ul><p>这样就能绕过那个限制，首次运行之后，以后应该就可以正常双击打开了。</p></li><li><p><strong>开始使用 VMware</strong></p><p>第一次打开后，它可能会让你同意一些协议，或者做一些初始化设置，按提示走就行。</p></li></ol><p>​</p>]]></description></item><item>    <title><![CDATA[2025智能化数据安全治理：平台技术与选]]></title>    <link>https://segmentfault.com/a/1190000047390327</link>    <guid>https://segmentfault.com/a/1190000047390327</guid>    <pubDate>2025-11-11 20:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>随着《数据安全法》《个人信息保护法》及《网络数据安全管理条例》的不断推进，数据安全已经成为企业构建数据治理体系的核心基础设施。2025年的市场格局呈现出三个显著特征：平台化整合替代碎片化工具、AI驱动的智能分析成为标配、全生命周期防护能力决定竞争力。在这一背景下，本文将从技术架构、合规适配、场景覆盖等维度，对国内主流数据安全平台进行深入评析和推荐。<br/>一、技术演进与核心能力要求<br/>随着数据安全形势的日益严峻，数据安全平台已经从传统的“单点防护”逐步发展到“全链路治理”范式。这一转型不仅在功能上要求更加全面，也对技术架构提出了更高的要求。</p><ol><li>从“单点防护”到“全链路治理”的范式升级<br/>过去的传统数据安全方案多侧重于单一环节的防护，如数据库审计、边界防护等。然而，随着数据流动性和业务场景的多样化，新一代数据安全平台需要实现以下三大转型：<br/>全域覆盖：新的数据安全平台不仅要集成数据库、API、云存储、大数据平台等多种数据源，还要能够构建“数据-行为-风险”全链路视图，以便全方位监控数据流动与操作行为。<br/>动态防御：借助用户实体行为分析（UEBA）与AI威胁建模，平台能够识别出内部越权操作、API滥用等复杂风险，并将误报率控制在0.5%以下。<br/>闭环处置：在风险识别后，平台能够实现从自动化响应、工单流转到证据留存的全链路处置，以满足等保2.0、GDPR等国内外数据安全监管要求。</li><li>关键能力指标<br/>对于一款优秀的数据安全平台，其关键能力应具备如下几个特点：<br/>多模态数据支持：能够兼容关系型数据库（如Oracle、MySQL）、NoSQL数据库（如MongoDB）、云原生数据库（如TiDB），以及大数据生态（如Hadoop、Spark）。<br/>智能分析引擎：平台应融合规则引擎、无监督学习和图计算技术，支持敏感数据的自动分类和分级，准确率不低于90%。<br/>性能扩展性：在高并发场景下，平台应能够支持每秒处理10万级SQL请求解析，并且日志处理延迟不超过1秒。<br/>二、主流产品技术评析与推荐<br/>在众多数据安全平台中，以下几款代表性产品具有不同的技术亮点与适用场景，企业可以根据自身需求进行选择。</li><li>奇安信数据安全治理平台<br/>技术亮点：奇安信平台整合了零信任架构与数据流动监测技术，实现了敏感数据路径的可视化，并支持动态脱敏与风险联动处置。该平台内置了量子加密VPN技术，能够在金融级安全需求下保证密钥更新频率达到1000次/秒。<br/>适用场景：特别适合金融、能源等关键基础设施领域，尤其是需要符合国家级安全标准的场景。<br/>标杆案例：在某国有银行的核心交易系统数据流动监控项目中，平台成功实现了99.3%的敏感操作拦截率。</li><li>全知科技数据安全平台<br/>技术亮点：全知科技平台率先提出“API安全是数据安全核心关口”的理念，并参与制定了相关国家标准。其利用AI技术进行多模态分类与动态校准，技术上领先行业。平台已在金融和医疗领域取得了标杆性的实战案例，如中国人寿财险项目在拦截率上达到了99.3%。<br/>适用场景：该平台适配性强，尤其适用于金融、医疗等高敏感领域，能够实现全面的全链路风险管控。<br/>创新突破：<br/>全链路风险管控：通过“知形-数据库风险监测系统”等产品，全知科技平台能够实现资产全景梳理、弱点捕捉及全场景监测，支持敏感操作的定向审计溯源。<br/>AI驱动智能运营：平台通过AI数据资产地图工具，结合无监督学习算法，实现敏感数据的自动识别，准确率达到95%，有效提高了数据识别效率。<br/>多场景适配能力：全知科技平台不仅支持API监测和数据资产地图等功能，还能够适应金融、医疗等多个行业的高敏感场景。例如，某三甲医院在部署后，API泄露风险减少了98%。</li><li>启明星辰数据安全平台<br/>技术亮点：启明星辰通过“九天·泰合”大模型构建了全方位的风险闭环能力，支持跨数据库、API、BI工具的多维度审计。平台还提供了细粒度的访问控制策略，可以根据用户角色和数据敏感度动态调整权限。<br/>适用场景：适合政府、运营商等机构，尤其是那些需要与现有安全体系（如SOC/SIEM）深度联动的场景。<br/>行业优势：启明星辰在政务领域的市场份额超过35%，并且成功保障了杭州亚运会的数据安全。</li><li>天融信数据安全治理平台（DSG）<br/>技术亮点：天融信平台采用动态数据流向地图技术，支持跨网络隔离环境下的数据流动追踪，特别适用于工业互联网等特殊场景。平台能够与防火墙、终端安全等产品联动，构建跨域联合防护体系。<br/>适用场景：适用于制造业、能源等工控系统的数据防泄露需求。<br/>创新突破：在某汽车制造企业的跨网数据交互项目中，天融信平台实现了98.7%的未授权访问拦截率。</li><li>阿里云数据安全中心（DSC）<br/>技术亮点：阿里云的数据安全中心基于云原生架构，深度集成了RDS/PolarDB，支持敏感数据的自动发现与分类分级。通过AI算法，平台能够识别异常行为，如非工作时间批量导出、异常API调用模式等。<br/>适用场景：特别适合多云环境与互联网企业的数据治理需求。<br/>生态优势：与钉钉、达摩院等阿里技术栈无缝协同，支持跨境数据合规管理。</li><li>深信服数据安全中心<br/>技术亮点：深信服平台结合了零信任架构与SASE融合方案，支持微服务认证与API动态防护。平台具有轻量化部署模式，能够满足教育、医疗等中小客户的快速上云需求。<br/>适用场景：适用于混合云环境下的数据安全治理，特别是需要快速合规达标的企业。<br/>技术趋势：深信服预计到2025年Q1，研发投入将占比达到22%，重点布局AI漏洞挖掘技术。<br/>三、企业选择数据安全平台的考量<br/>在选择数据安全平台时，企业需要综合考虑多个因素，确保平台能够满足其安全需求并支持长期发展。</li><li>核心需求与优先级排序<br/>企业应明确核心需求，优先考虑合规性或业务连续性。例如，金融和医疗行业应优先选择符合合规要求的平台；而对系统中断敏感的企业则应选择低侵入、影响小的平台。</li><li>技术验证与适配能力<br/>平台的技术能力和适配性至关重要。企业需关注平台的误报率是否低于0.5%，以及其是否支持混合云和多云环境，以确保平台与现有系统兼容。</li><li>成本效益与技术创新<br/>企业应平衡平台的成本与功能，关注平台的技术创新能力，如AI和大数据分析等新兴技术的支持。</li><li>行业适配能力与场景覆盖<br/>平台的行业适配能力是关键，企业需考虑平台是否能覆盖其特定行业的安全需求，并检查平台在该行业的成功案例。</li><li>易用性与运营支持<br/>选择易用的平台可以减少培训成本，而完善的技术支持和售后服务则能确保平台在运营过程中得到及时维护。</li><li>可扩展性与未来发展<br/>平台的扩展性至关重要，企业应选择能够支持大规模数据处理和高并发场景的解决方案，同时关注平台的未来技术发展潜力。<br/>企业在选择数据安全平台时，需要从需求、技术能力、成本效益、行业适配、易用性和未来发展等多方面考虑，确保选择最合适的解决方案来保障数据安全和业务发展。</li></ol>]]></description></item><item>    <title><![CDATA[Sora2 Pro国内接入终极指南：0.]]></title>    <link>https://segmentfault.com/a/1190000047390124</link>    <guid>https://segmentfault.com/a/1190000047390124</guid>    <pubDate>2025-11-11 19:08:59</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>🔥 Sora2 Pro国内接入终极指南：0.9元/次直冲API，失败退款+无并发限制！</h2><h3>一、Sora2 Pro全景解析：颠覆视频创作的AI神器</h3><h4>1.1 产品定位与核心功能</h4><p>OpenAI推出的Sora2 Pro是当前最顶尖的AI视频生成模型，其核心能力包括：</p><ul><li><strong>物理真实模拟</strong>：实现符合重力、光影等物理规律的视频生成</li><li><strong>多镜头控制</strong>：支持电影级镜头运动和场景切换</li><li><strong>音画同步</strong>：自动生成与画面匹配的立体声轨道</li><li><strong>超高清输出</strong>：支持1080P至4K分辨率的专业级视频</li><li><img width="723" height="548" referrerpolicy="no-referrer" src="/img/bVdm0uX" alt="" title=""/></li></ul><h4>1.2 与标准版Sora2的核心差异</h4><table><thead><tr><th>特性</th><th>Sora2标准版</th><th>Sora2 Pro专业版</th></tr></thead><tbody><tr><td>分辨率</td><td>720P</td><td>1080P-4K</td></tr><tr><td>视频时长</td><td>最长30秒</td><td>最长120秒</td></tr><tr><td>生成速度</td><td>5-10分钟</td><td>15-30分钟</td></tr><tr><td>音频质量</td><td>单声道</td><td>立体声全景声</td></tr><tr><td><strong>官方定价</strong></td><td><strong>$0.10/秒</strong></td><td><strong>$0.30-$0.50/秒</strong></td></tr></tbody></table><hr/><h3>💥 国内接入痛点：为什么99%的开发者被挡在门外？</h3><h4>2.1 官方API的三大鸿沟</h4><ol><li><strong>地域封锁</strong>：OpenAI未开放中国区API访问</li><li><strong>天价成本</strong>：生成10秒视频需$1-5（约￥7-35元）</li><li><strong>风险陷阱</strong>：失败不退款，单次错误损失高达￥50+</li></ol><h4>2.2 第三方平台的致命缺陷</h4><p>多数中转服务商存在：</p><ul><li>❌ <strong>隐性扣费</strong>：请求失败仍被计费</li><li>❌ <strong>并发限制</strong>：高并发时返回429错误</li><li>❌ <strong>服务断层</strong>：无技术支持和文档保障</li></ul><hr/><h3>🚀 速创API破局方案：0.15元起用上Sora2 Pro</h3><h4>3.1 颠覆性定价体系</h4><table><thead><tr><th>服务</th><th>官方价格</th><th>速创API价格</th><th>节省比例</th></tr></thead><tbody><tr><td>Sora2标准版</td><td>$0.10/秒</td><td><strong>0.15元/次</strong></td><td>80%↓</td></tr><tr><td>Sora2 Pro版</td><td>$0.50/秒</td><td><strong>0.9元/次</strong></td><td>75%↓</td></tr><tr><td>Veo3 标准版</td><td>$0.30/秒</td><td><strong>1.0元/次</strong></td><td>70%↓</td></tr></tbody></table><h4>3.2 四维保障机制</h4><p>✅ <strong>失败秒退款</strong>：任务失败自动原路退回  <br/>✅ <strong>无并发限制</strong>：支持千级并发请求   <br/>✅ <strong>SLA保障</strong>：实测失败率&lt;3.2%</p><h2><img width="723" height="407" referrerpolicy="no-referrer" src="/img/bVdmRW7" alt="" title="" loading="lazy"/></h2><h3>🛠️ 保姆级接入教程（三分钟搞定）</h3><h4>4.1 API调用实战</h4><pre><code class="python">import requests

# 速创API配置
API_URL = "https://api.wuyinkeji.com/api/sora2pro/submit"
API_KEY = "your_key_here"  # 注册速创API获取

# 发起视频生成请求
payload = {
  "prompt": "一只机械巨龙在赛博都市上空飞行，电影级光影",
  "resolution": "1080p",
  "duration": 15
}
headers = {"Authorization": f"Bearer {API_KEY}"}

response = requests.post(API_URL, json=payload, headers=headers)
print(response.json())  # 返回task_id用于查询进度</code></pre><h4>4.2 状态查询机制</h4><pre><code class="python"># 查询生成进度
status_url = f"https://api.wuyinkeji.com/api/task/{task_id}"
result = requests.get(status_url, headers=headers)
if result.json()["status"] == "success":
  video_url = result.json()["video_url"]</code></pre><blockquote>完整文档见：<a href="https://link.segmentfault.com/?enc=%2Fe2HbrFD51VpoTnUO0fW1g%3D%3D.KBh2SQ6NGhl3mztvS3sIHEJWd5jOkNBJc2N%2BuRMju10%3D" rel="nofollow" target="_blank">速创API开发指南</a></blockquote><hr/><h3>⚡ 性能实测数据（第三方机构验证）</h3><h4>5.1 核心指标对比</h4><table><thead><tr><th>测试项目</th><th>官方API</th><th>速创API</th><th>提升效果</th></tr></thead><tbody><tr><td>平均延迟</td><td>8.2秒</td><td>2.1秒</td><td>300%↑</td></tr><tr><td>成功率</td><td>89.3%</td><td><strong>98.7%</strong></td><td>+9.4%</td></tr><tr><td>并发承载</td><td>10/秒</td><td><strong>无限制</strong></td><td>∞</td></tr><tr><td>退款到账</td><td>不支持</td><td><strong>&lt;1分钟</strong></td><td>--</td></tr></tbody></table><h4>5.2 典型案例</h4><p>某短视频平台接入测试：</p><ul><li>日均生成2000+视频</li><li>月成本从￥28,000降至￥6,300</li><li>故障工单减少92%</li></ul><hr/><h3>🌐 Veo3 nanobanana的真相揭示</h3><h4>6.1 技术本质</h4><p>Veo3 nanobanana实为Google的<strong>Gemini 2.5 Flash Image</strong>模型非正式名称：</p><ul><li>官方入口：Google AI Studio</li><li>核心能力：图像生成→视频转化的多模态处理</li><li>技术参数：1080P输出，支持帧间插值</li></ul><h4>6.2 通过速创API调用优势</h4><pre><code class="bash">curl https://api.wuyinkeji.com/api/nanobanana/generate \
  -H "Authorization: Bearer YOUR_KEY" \
  -d '{"prompt":"赛博朋克风格的猫咪自拍"}'</code></pre><blockquote>🌟 独享特性：国内直连无需科学上网，失败自动重试</blockquote><hr/><h3>⚠️ 风避坑指南：这些雷区必须避开！</h3><h4>7.1 授权认证真相</h4><p>经多源验证：</p><ol><li><strong>OpenAI未授权任何中国代理</strong></li><li>速创API采用<strong>官方通道中转</strong>（非逆向破解）</li><li>建议优先选择有<strong>失败退款保障</strong>的平台</li></ol><h4>7.2 合规使用红线</h4><ul><li>❌ 禁止生成暴力/政治敏感内容</li><li>✅ 需获得肖像权授权</li><li>✅ 商用需遵守OpenAI服务条款</li></ul><hr/><h3>📊 成本优化秘籍（企业级）</h3><h4>8.1 混合调用策略</h4><pre style="display:none;"><code class="mermaid">graph LR
  A[视频需求] --&gt; B{预算判断}
  B --&gt;|&lt;￥1| C[Sora2标准版 0.15元/次]
  B --&gt;|&gt;￥3| D[Sora2 Pro 0.9元/次]
  B --&gt;|动态场景| E[Veo3  1.0元/次]</code></pre><h4>8.2 费用控制公式</h4><p><code>总成本 = 成功调用次数×单价 - 退款金额</code>  <br/>实际支出比官方API节省<strong>68%-82%</strong></p><hr/><h3>❓ 高频问题解答（FAQ）</h3><p><strong>Q1：Sora2邀请码如何获取？</strong>  <br/>→ 目前OpenAI仅对Red Teaming成员开放申请 </p><p><strong>Q2：提示词写法有何技巧？</strong>  <br/>→ 推荐结构：<code>[场景描述]+[镜头运动]+[风格要求]</code>  <br/>例：<code>滑板少年在东京街头穿梭，跟拍镜头，宫崎骏动画风格</code></p><p><strong>Q3：API中转站是否安全？</strong>  <br/>→ 选择加密传输+不存请求记录的平台（如速创API采用TLS加密） </p><p><strong>Q4：如何验证平台可靠性？</strong>  <br/>→ 关键指标：失败率&lt;5% + 支持实时退款 + 提供SLA协议</p><hr/>]]></description></item><item>    <title><![CDATA[Syncios iOS数据擦除器评测 C]]></title>    <link>https://segmentfault.com/a/1190000047390126</link>    <guid>https://segmentfault.com/a/1190000047390126</guid>    <pubDate>2025-11-11 19:08:21</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>准备出售、赠送或回收旧 iPhone 时，最重要的步骤之一就是彻底清除个人数据。仅仅使用苹果内置的“抹掉所有内容和设置”功能可能不够，因为有些已删除的数据仍然可以通过专业工具恢复。这时，专业的iOS数据擦除工具就派上用场了。</p><p>Syncios iOS数据擦除器是许多想要永久删除 iPhone 或 iPad 上所有数据的用户的热门选择。它声称可以彻底清除所有个人信息痕迹，并且无法恢复。但它的实际效果究竟如何呢？在这篇详尽的 Syncios iOS数据擦除器评测中，我们将深入探讨它的功能、优缺点、价格、用户反馈、使用方法以及您可以尝试的最佳替代方案。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047390128" alt="图片" title="图片"/><br/>​</p><h3>第一部分：Syncios iOS数据擦除器评测</h3><p>Syncios iOS数据擦除器是由 Anvsoft 开发的一款iOS数据擦除工具。该软件主要用于永久删除 iPhone 中的隐私数据、系统垃圾、缓存文件、通话记录、短信、照片、视频等。无论您是想释放存储空间，还是在出售设备前彻底清除敏感数据，它都能提供一站式解决方案。</p><p>1.1 Syncios iOS数据擦除器的主要功能</p><p>Syncios iOS数据擦除器配备了多种强大的数据清除功能，旨在满足不同的隐私需求。以下是其功能介绍：</p><ul><li>彻底清除iOS设备上的所有数据，且无法恢复。</li><li>可选择选择性地擦除已删除的文件和私人数据，确保 0% 的恢复率。</li><li>支持 30 多种数据类型，包括短信、联系人、通话记录、照片、视频等。</li><li>从 WhatsApp、LINE、微信、Kik、Facebook 等平台删除社交应用数据。</li><li>清除垃圾文件，提升 iPhone、iPad 或 iPod Touch 的性能。</li><li>确保已删除的文件和私人碎片永远消失，无法恢复。</li><li>完全兼容最新的iOS 26。</li></ul><p>1.2 Syncios iOS数据擦除器的优缺点</p><p>任何软件都有其优点和缺点，Syncios iOS数据擦除器也不例外。了解这些优缺点将有助于您判断它是否符合您的需求。</p><p>优点：</p><ul><li>界面直观，操作简单，适合初学者使用。</li><li>它提供多种擦除模式，以满足不同的隐私保护需求。</li><li>擦除操作彻底，数据无法恢复。</li></ul><p>擦除速度快，安全性高。</p><ul><li>支持最新的 iPhone 17 和iOS 26 系统。</li></ul><p>缺点：</p><ul><li>免费版本功能有限，无法执行完全数据擦除。</li><li>删除数据前务必备份数据，因为删除后将无法恢复。</li><li>扫描过程可能会比较慢，尤其是在存储容量较大的设备上。</li><li>部分老旧设备可能无法被可靠识别。</li></ul><p>深度擦除需要很长时间，而且设备可能会过热。</p><ul><li>目前没有Mac版本。</li></ul><p>1.3 Syncios iOS数据擦除器的价格</p><p>在任何关于 Syncios iOS数据擦除器的评测中，价格都是一个重要的考虑因素。该工具提供免费试用版，可用于扫描和预览数据，但完整的擦除功能需要付费许可。以下是详细信息：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047390129" alt="图片" title="图片" loading="lazy"/><br/>​</p><h3>第二部分：如何使用 Syncios iOS数据擦除器？</h3><p>使用 Syncios iOS数据擦除器非常简单，即使是没有任何技术经验的用户也能轻松上手。以下是安全永久擦除 iPhone 数据的详细步骤。</p><p>步骤一：首先，启动 Syncios iOS Eraser，然后从主界面选择“抹掉所有数据”选项。使用 USB 数据线将您的iOS设备连接到电脑，然后点击蓝色的“抹掉”按钮开始操作。</p><p>步骤二：接下来，选择安全级别。默认推荐级别为“中”，另有“低”和“高”两个选项。请根据您的需要选择合适的级别。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047390130" alt="图片" title="图片" loading="lazy"/></p><p>步骤3：为避免误删数据，您需要在清除所有数据之前手动输入“清除”。输入正确的字符后，点击“立即清除”按钮。</p><p>第四步：软件将永久删除iPhone上的数据。在此过程中请勿断开设备连接。</p><p>第五步：流程完成后，您的 iPhone 将自动重启。此时，它将像全新设备一样干净，不会残留任何可恢复的数据。</p><h3>第三部分：Syncios iOS数据擦除器的最佳替代方案</h3><p>虽然 Syncios iOS数据擦除器对大多数用户来说都很好用，但有些用户可能更喜欢擦除速度更快、连接更稳定、兼容性更强的替代方案。在这种情况下，我们强烈推荐Coolmuster iOS Eraser 。</p><p>Coolmuster iOS Eraser还支持永久清除 iPhone、iPad 和 iPod 上的所有数据，提供三种安全擦除级别（低、中、高），以确保普通文件和深度隐私记录都被彻底销毁。</p><p>iOS橡皮擦的主要功能：</p><pre><code>安全彻底地清除iOS设备上的所有数据，包括个人信息、系统设置、已删除的文件等。
提供三种擦除级别（低、中、高），以满足不同的需求。
保证永久删除现有数据和已删除数据，且无任何恢复可能。
永久删除多种数据类型：联系人、短信、通话记录、音乐、视频、照片、应用程序和应用程序数据、提醒事项、日历、书签、浏览历史记录、语音备忘录、笔记和设置（包括 iCloud 和 iTunes 帐户信息）。
以 100% 只读模式运行，确保数据被擦除而不会损坏您的设备。
完全兼容所有 iPhone、iPad 和 iPod touch 机型，包括最新的 iPhone 17 和iOS 26。

</code></pre><p>以下是如何使用iOS橡皮擦清除 iPhone 上的所有内容和设置：</p><p>01使用 USB 数据线将您的 iOS 设备连接到电脑。软件会自动检测您的设备，连接成功后，主界面将出现，即可开始擦除数据。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047390131" alt="图片" title="图片" loading="lazy"/></p><p>02点击“擦除”按钮，选择所需的安全级别（低、中或高），然后点击“确定”进行确认。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047390132" alt="图片" title="图片" loading="lazy"/></p><p>03出现提示时，输入“删除”进行确认，然后再次点击“擦除”。将出现最终确认信息；点击“确定”以永久删除数据。</p><p>04流程完成后，设备上的所有数据将被永久删除且无法恢复。现在您可以将您的 iDevice 设置为新设备。</p><p>第四部分：Syncios iOS数据擦除器常见问题解答</p><p>Q1. Syncios iOS数据擦除器安全合法吗？</p><p>是的。它是由一家信誉良好的软件供应商开发的，目前没有任何恶意软件或数据泄露的报告。</p><p>Q2. Syncios iOS数据擦除器是免费的吗？</p><p>不。该软件提供免费扫描试用版，但您需要购买许可证才能使用完整的擦除功能。</p><p>Q3. 我需要连接互联网才能使用它吗？</p><p>仅用于下载和激活程序。安装完成后，即可离线使用。</p><h3>结语</h3><p>总而言之，这篇 Syncios iOS数据擦除器评测表明，对于任何想要永久删除 iPhone 数据并保护隐私的用户来说，它都是一个不错的选择。它提供了可靠的功能，但速度和连接性还有提升空间。</p><p>如果您正在寻找更高效、更易用的替代方案， Coolmuster iOS Eraser以其更快的性能、更好的兼容性和更高的安全标准脱颖而出。无论您是打算出售 iPhone 还是仅仅想保护您的数据， Coolmuster iOS Eraser都能提供专业且便捷的解决方案。<br/>​</p>]]></description></item><item>    <title><![CDATA[制造业企业如何借助智能体模型优化供应链管]]></title>    <link>https://segmentfault.com/a/1190000047390138</link>    <guid>https://segmentfault.com/a/1190000047390138</guid>    <pubDate>2025-11-11 19:07:46</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>智能体模型服务作为人工智能领域的重要组成部分，正日益成为企业数字化转型的核心驱动力。这类服务基于先进的机器学习算法和自然语言处理技术，构建出能够自主决策、执行任务并与用户进行智能交互的代理系统。其核心价值在于通过模拟人类认知过程，实现自动化、个性化和高效化的业务处理，从而显著提升组织运营效率。在当今竞争激烈的市场环境中，企业纷纷采用智能体模型服务来优化客户服务、增强数据分析能力并降低成本。</p><p>以工业互联网平台为例，Geega（际嘉）工业互联网平台通过部署智能体模型服务，实现了制造过程的数字化管控和优化。该平台运用智能体模型对生产设备进行实时监测和预测性维护，通过分析设备运行数据，提前识别潜在故障，有效降低非计划停机时间。在某大型汽车制造企业的实践中，该平台通过智能体模型优化焊接工艺参数，使焊点质量合格率提升3.2%，同时降低能耗约5%。</p><p>另一个典型应用是在供应链管理领域。智能体模型服务能够基于多源数据构建供应链数字孪生，通过强化学习算法动态优化库存管理和物流调度。某家电制造企业采用智能体模型服务后，实现了原材料库存周转率提升18%，配送效率提高22%的显著成效。此外，在质量管控方面，智能体模型通过计算机视觉技术对产品缺陷进行智能检测，检测准确率可达99.5%以上，大幅提升产品质量一致性。</p><p>智能体模型服务在工业领域的实施需要充分考虑行业特性和企业实际需求。成功的应用案例表明，这类服务不仅需要先进的技术支撑，更需要与生产工艺深度融合。企业应当从具体业务场景出发，采用渐进式实施策略，先在小范围试点验证，再逐步推广到全业务流程。同时，还需要注重数据治理和人才培养，为智能体模型服务的落地提供坚实基础。</p><p>随着工业互联网技术的不断发展，智能体模型服务正在向更加专业化、场景化的方向演进。未来，随着5G、边缘计算等新技术的成熟应用，智能体模型服务将在工业领域发挥更大价值，推动制造业向智能化、绿色化方向转型升级，为制造企业创造可持续的竞争优势。</p>]]></description></item><item>    <title><![CDATA[云原生周刊丨runc 三大高危漏洞曝光 ]]></title>    <link>https://segmentfault.com/a/1190000047390141</link>    <guid>https://segmentfault.com/a/1190000047390141</guid>    <pubDate>2025-11-11 19:06:58</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>云原生热点</h2><h3><a href="https://link.segmentfault.com/?enc=t2lAO7HRnJAzxZkLcg3b0A%3D%3D.AkYE3ASayGOnTaApyzEus1juYSL1zBHf0o2aDy%2BvxZjBHYdZ84iubmObDzj9JokPo5%2BAVtB9pHjq7W99yK525urMka5tSX%2BJR%2FAVBGieQapeqkQJygS8ZQDai5fXlTaaMZEYBcK3AghsPAjzIOECrJpXj9gEeJw7T4uzmYgYGYU%3D" rel="nofollow" target="_blank">CNCF 宣布 Crossplane 毕业：迈入云原生智能控制平面新阶段</a></h3><p>Crossplane 是一个开源的 Kubernetes 扩展，用 Kubernetes 的 API 来管理各云厂商的基础设施，把 K8s 变成“通用控制平面”。</p><p>近日，Crossplane 正式从 CNCF 孵化毕业，进入最高成熟度阶段。CNCF 在公告中指出，Crossplane 通过声明式 API 将云基础设施、应用和服务统一到同一控制平面下，使平台工程团队能够以可编排、可审计、策略驱动的方式管理多云与混合云环境，并为 AI 驱动的自动化运维提供可靠基座。当前 Crossplane 已累计发布 100+ 版本，最新的 v2.0 提供了更完善的应用控制平面架构和对智能运维的增强支持，社区拥有 3000 多名贡献者、覆盖 450+ 组织，在 CNCF 项目中活跃度位居前列，官方也强调其已适用于大规模生产环境部署。</p><h3><a href="https://link.segmentfault.com/?enc=qA6i%2F1GG4%2F2%2FbiMOKwRydw%3D%3D.UeTXv8eT77d8VV29HstE0TE3Kxq3GvP26rYhTZT3xfZ05NDwwrjKvcUe9YIEa0GYBdrq86AwYD9BvpaCeKVy9A%3D%3D" rel="nofollow" target="_blank">Koordinator v1.7.0 发布：以网络拓扑感知调度赋能大规模 AI 训练</a></h3><p>Koordinator 是一个基于 QoS 的 Kubernetes 调度增强系统，用来在同一集群里高效混部微服务、AI、大数据等不同类型的工作负载，通过资源超卖、精细化资源隔离和智能调度，提升集群资源利用率和关键业务的运行稳定性。</p><p>Koordinator v1.7.0 正式发布，本次版本重点围绕大规模 AI 训练场景进行能力升级，引入了网络拓扑感知调度和作业级抢占机制，以降低跨节点通信开销、提升大集群下分布式训练作业的整体效率。同时，v1.7.0 进一步增强异构设备调度，新增对华为昇腾 NPU、寒武纪 MLU 等设备的支持，打通从设备发现、分配到监控的端到端管理链路，并完善了相关 API 文档与开发者指南，帮助平台团队在同一调度系统下统一管理多类型 AI 计算资源。</p><h3><a href="https://link.segmentfault.com/?enc=nMRhuMcr7GkHTk6sxxmoJw%3D%3D.E22h5xwgqS7p6XKu7WDg2RH9cCNnizzGVf%2Bshpe83n%2Bi6ka5QVfpEw5iFnrt26wKWlG3CrHuoZ6iUKsyXEPNHw%3D%3D" rel="nofollow" target="_blank">runc 三大高危漏洞曝光：Docker 与 Kubernetes 容器隔离面临逃逸风险</a></h3><p>runc 是一个遵循 OCI 规范的轻量级容器运行时（container runtime），本质上是一个命令行工具，用来在 Linux 上创建、运行和销毁容器。</p><p>近日 runc 容器运行时被曝出 3 个高危漏洞，这些漏洞影响 Docker、Kubernetes 等平台的容器隔离机制。攻击者如果能以自定义 mount 配置启动容器，就可能利用 maskedPaths 绕过、防护缺陷的 <code>/dev/console</code> 挂载流程，以及与共享挂载相关的竞争条件，重定向对 procfs 的写入，从而写入如 <code>/proc/sys/kernel/core_pattern</code>、<code>/proc/sysrq-trigger</code> 等关键系统文件，实现容器逃逸、获取宿主机 root 权限甚至导致系统崩溃。漏洞影响几乎所有已知 runc 版本（CVE-2025-31133、CVE-2025-52565、CVE-2025-52881），官方已在 1.2.8、1.3.3 和 1.4.0-rc.3+ 中完成修复。文中建议受影响组织立刻升级 runc 版本，并启用用户命名空间和 rootless 容器，以减少对 procfs 和宿主机的直接访问，同时尽快应用云服务商（如 AWS ECS/EKS）已发布的安全更新。</p><h2>技术实践</h2><h3>文章推荐</h3><h3><a href="https://link.segmentfault.com/?enc=ORQBuLwuitrpI9CfNjfIig%3D%3D.S00%2FHSd3o5btRnGACrTLP75lKT5LDxwNGD0JaC1sGYjyzUPq7dxhs7rTrwMJSNHEXW5kDXYh%2BVwvXUUyvB%2BRF8ikRV8Aq3B9YRSoamTKGDB8WzvE4vZm2RYqRKtW8jzp" rel="nofollow" target="_blank">被忽视的 10 个 DevOps 关键实践：比炫技更重要的东西</a></h3><p>这篇文章指出，很多团队在谈 DevOps 时只关注版本控制、CI/CD、基础设施即代码等“显眼技术”，却忽视了那些真正决定交付质量和效率的“冷门实践”。作者总结了 10 个常被低估的关键点，包括：重新审视 DevOps 文化与跨职能协作、在流水线中前移代码质量与安全、自动化开源供应链审查、标准化 CI/CD 流水线、把数据库模式纳入 DevOps、建设可维护的持续测试体系、将配置和 IaC 视为高杠杆资产、把可观测性当作硬性要求、梳理并整合繁杂的 DevOps 工具，以及把 DevOps 能力扩展到 AI 代理和模型的全生命周期管理。文章强调，DevOps 应被视为一项持续投资，关键是围绕业务价值和可靠性来选择和打磨这些“看起来不酷但极有价值”的实践。</p><h3><a href="https://link.segmentfault.com/?enc=Wm1d4QDK8FoKuoQz7JXHjA%3D%3D.KsANkpO7MNhmYLo0FF%2FR%2BFtwviXjNmPlpLwA02zDFM%2FlVEUPiXX0catlcbWIGomYHVZvsPrgRzlsN6D9l9dgA2EebNtIFrU%2FarTjg%2FgEc1nuejIVS%2Bqm1LdCFRkb8cDp" rel="nofollow" target="_blank">我把家里的 Docker Compose 换成了 Kubernetes，感觉棒极了！</a></h3><p>这篇文章讲述了一位开发者在家用环境中，从 Docker Compose 迁移到 Kubernetes（具体是使用 MicroK8s）的亲身体验与感受。他原本已经习惯用 Docker Compose 加上各种容器来搭建服务，但随着需求变复杂，他发现自己更希望有一个统一的“控制平面”视角，能在一个仪表盘中看到所有工作负载的关系、网络、秘钥和性能指标。Kubernetes 虽然上手门槛更高、配置更繁琐，但配合 MicroK8s 的仪表盘、Ingress、Secrets 等能力，让他在网络、负载均衡、安全和扩展性上都更有掌控感，也更有“学到东西”的成就感；通过 Kompose 等工具，他还能把现有的 Docker Compose 工作负载迁移过来。作者最终认为，即便在家用实验室这种规模并不大的场景，Kubernetes 依然能带来更系统化的管理体验和学习价值。</p><h3>开源项目推荐</h3><h3><a href="https://link.segmentfault.com/?enc=QFKjSifeSgdGGmd1GRIzRw%3D%3D.uPGrM4yLKenXerh%2FwssMFRhy%2Bc1%2BhY69ATQIgLrZv5cDFxtoJzjyB9eiuP5M3O9O" rel="nofollow" target="_blank">Terraform</a></h3><p>Terraform 是由 HashiCorp 开发的开源基础设施即代码（Infrastructure as Code，IaC）工具。它允许用户使用声明式配置文件来定义、预览和部署云端或本地基础设施，包括服务器、数据库、网络、存储等资源。Terraform 通过提供统一的语法与工作流程，支持多种云平台（如 AWS、Azure、GCP）以及私有环境，实现跨平台的自动化管理与一致性部署。其核心特性包括可重复的配置、状态管理、依赖分析和模块化复用，使团队能够高效、安全地构建和维护基础设施。</p><h3><a href="https://link.segmentfault.com/?enc=vqAFkg310rzeqjt0f9YGxA%3D%3D.yn33lUCo22rsTX4L8B%2B8zQgD54dAoT8umcWkEYW5bZTb%2FX0p9s6JrL2fXqlXrSdl" rel="nofollow" target="_blank">envd</a></h3><p>envd 是由 TensorChord 开发的开源命令行工具，专为 AI/ML 开发环境设计。用户可通过声明式配置文件定义依赖、CUDA、IDE 等环境需求，一键生成基于容器的开发环境。它支持缓存与 BuildKit 加速，提高构建效率，可在本地或云端运行，兼容 Docker 与 Kubernetes。envd 使用类似 Python 的 Starlark 语法，支持模块化与函数复用，降低配置复杂度，帮助团队快速搭建一致、高效的机器学习开发环境。</p><h3><a href="https://link.segmentfault.com/?enc=0PG2iOD3hRc8gT0NrgG2VA%3D%3D.dlysIGzA0P75%2FizaHGatrBQc74IbCPZetFlKPIsnmVjjmywe0YArwLlIk%2B4gPqqo" rel="nofollow" target="_blank">KServe</a></h3><p>KServe 是一个开源平台，用于在 Kubernetes 上大规模部署和管理机器学习与生成式 AI 模型。它支持多种模型框架，如 TensorFlow、PyTorch、XGBoost、ONNX 等，并通过自定义资源 InferenceService 实现统一的部署与流量管理。KServe 具备自动扩缩、异步推理、GPU 加速、金丝雀发布等特性，简化了模型从开发到生产的过程，适用于多云与混合环境下的高性能模型服务部署。</p><h3><a href="https://link.segmentfault.com/?enc=4OLDLT4HgGsnyghfYO%2FRWA%3D%3D.reC1CoKMncCV7dvhGR3nrqR0cXnIWT7acz6HD6LX0GUNW4cULyMwhGn3yKDS1%2FJp" rel="nofollow" target="_blank">Admiralty</a></h3><p>Admiralty 是一个开源的多集群调度系统，基于 Kubernetes 构建，用于在多个集群之间智能分配工作负载。它通过在源集群中添加注解即可将 Pod 调度到目标集群运行，并自动同步相关资源。Admiralty 支持集中式或分布式拓扑，适用于多云、混合云、边缘计算等场景，实现跨集群的高可用部署与资源优化。</p>]]></description></item><item>    <title><![CDATA[苹果签名的秘密：一个开发者与“许可”的战]]></title>    <link>https://segmentfault.com/a/1190000047390145</link>    <guid>https://segmentfault.com/a/1190000047390145</guid>    <pubDate>2025-11-11 19:06:17</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>作为一名iOS开发者，我曾以为代码写得好就够了。直到我的第一个独立App，像一封没有邮票的信，被无情地“退回”——苹果签名，这道我从未在意的大门，成了我产品生死的第一道关卡。</p><p>这不仅仅是技术，这是一个关于“许可”的故事。</p><p>了解更多关于签名的信息：<a href="ioszf.cc" target="_blank">iOS张飞苹果签名-超级签企业签TF签</a></p><p>初遇：那枚看不见的“印章”</p><p>2018年，我和合伙人熬夜两个月，开发出一款记录灵感的App。上传App Store后，我们兴奋地等待着。然而，等来的是一封冰冷的邮件：“缺少有效的签名身份。”</p><p>我们懵了。就像精心制作了一部电影，却因为发行许可证问题，无法进入任何影院。</p><p>那一刻我才明白，在苹果的生态里，你的创意再完美，没有那枚由苹果颁发的“数字签名”，它就无法抵达用户的手机。 这个签名，是苹果守护其花园的“魔法结界”。</p><p>挣扎：在规则与自由之间</p><p>为了这枚签名，我们不得不支付99美元的年费加入开发者计划，学习复杂的证书、描述文件配置。这感觉像是一个“入会仪式”——你必须先遵守规则，才能获得入场券。</p><p>但故事的高潮在后面。当我们想测试一个苹果审核可能无法通过的大胆功能时（一个涉及高级API的自动化工具），传统签名路径走不通了。这时，我接触到了“企业签名”——一种本意供大公司内部使用的签名，却流入了灰色市场。</p><p>我花了钱，买了一个“共享”的企业签名。起初一切顺利，App可以轻松安装。但第七天，用户开始大量反馈“应用无法打开”。签名掉了——因为滥用，证书被苹果批量吊销。</p><p>那一刻，我意识到我在这场“许可游戏”中，依然是个乞讨者。</p><p>顿悟：签名，是秩序，也是枷锁</p><p>这次经历让我重新审视苹果签名。它确实构建了一个相对安全、纯净的环境，保护了绝大多数用户。但它的严格管控，也扼杀了许多在规则边缘试探的创新。</p><p>后来，我们老老实实优化产品，通过了官方审核。App上架那天，我没有太多喜悦，反而在想：那些真正颠覆性的想法，是否在第一步就被这套签名体系过滤掉了？</p><p>所以，什么是苹果签名？</p><p>简单说，它就是苹果给你App的一个“防伪身份证”。它告诉系统：“此人已交‘保护费’，是我罩的，可以放心安装。” 没有它，你的App在iOS系统上寸步难行。</p><p>主要分三种：</p><p>App Store签名：官方正途，安全稳定，但审核严格。</p><p>开发者签名：用于真机测试，有设备数量限制。</p><p>企业签名：内部使用，无安装限制，但极易被吊销，是灰色地带的重灾区。</p><p>写在最后</p><p>如今，我的工作室已步入正轨。但我时常会想起那个因签名失效而崩溃的夜晚。苹果签名，就像数字世界里的现代“城门官”，它维持着秩序，也收取着“通行税”。</p><p>对于我们开发者而言，理解并驾驭它，是在这个生态中生存的必修课。它提醒我们：在苹果的花园里，你可以尽情培育奇花异草，但永远不要试图移动围墙。</p><p>这枚小小的签名，是我们与巨头之间，关于控制与自由，永不停息的无声对话。</p>]]></description></item><item>    <title><![CDATA[如何项目管理软件中计算预算？ 英勇无比的]]></title>    <link>https://segmentfault.com/a/1190000047390152</link>    <guid>https://segmentfault.com/a/1190000047390152</guid>    <pubDate>2025-11-11 19:05:35</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>项目管理的过程中，我们需要考虑很多方面因为许多公司为他们的客户创建项目。</p><p>Zoho Projects 的预算功能允许用户在项目、里程碑、用户和任务级别跟踪成本。预算可以基于金额或工时。如果您的项目基于工时，则“差异”列显示计划工时与实际工时之间的差异；如果基于金额，则“成本差异”列突出显示计划成本与实际成本之间的差异。</p><p><strong>项目级预算</strong><br/>启用项目级预算后，用户可以跟踪项目成本并确保其按计划进行。您可以在“项目预算”字段中选择基于项目金额或项目工时的预算。<br/>假设小王拥有一家咨询服务公司，他希望跟踪某个项目的预算。他可以在设置中启用项目预算，并在创建项目时输入项目金额或项目工时。他还可以设置项目预算限额，避免预算超支。</p><p><img width="723" height="215" referrerpolicy="no-referrer" src="/img/bVdm0vp" alt="image.png" title="image.png"/></p><p><strong>里程碑级预算</strong><br/>如果用户启用里程碑级预算，项目预算将通过汇总每个里程碑的预算来计算。项目预算阈值将基于里程碑预算阈值计算。<br/>例如，如果小王想要查看设计和实施所需的总成本，他可以为每个阶段创建新的里程碑，并为每个里程碑设置预算。创建里程碑时，他可以输入里程碑金额或里程碑工时。</p><p><img width="723" height="142" referrerpolicy="no-referrer" src="/img/bVdm0vq" alt="image.png" title="image.png" loading="lazy"/></p><p><strong>任务级预算</strong><br/>启用任务级预算后，用户可以计算每个任务的预算。项目总预算将计算为所有任务成本的总和。<br/>如果小王只想计算软件部署所需的成本，他可以选择任务级预算并输入金额或工时。他还可以设置任务预算阈值，避免任务预算超支。<br/>项目级预算帮助用户跟踪项目成本并确保其按计划进行。 您可以在项目预算字段中选择基于项目金额假设卡拥有一家此尊服务公司， 他希望跟踪某个项目的预算。 他可以在设置中启用项目预算， 并在创建项目时输入项目金额或项目工时。 他还可以设置项目预算限额， 避免预算超支。</p><p><img width="723" height="399" referrerpolicy="no-referrer" src="/img/bVdm0vr" alt="image.png" title="image.png" loading="lazy"/></p><p><strong>用户级预算</strong></p><p>启用任务级预算后，用户可以计算每个用户的预算。假设项目经理给一位UI/UX设计师分配了500美元，给一位开发人员分配了700美元。随着项目的推进，经理可以监控每位用户的支出是否超出预算。如果设计师的支出接近预算上限，经理可以减少开发人员的预算以稳定项目进度。</p><p>比如说，小王向每个用户分配预算。现在他希望跟踪每个用户的预算为了确保不超过预算阈值。 如果一个用户的预算超过阈值可以扣除另一个用户的阈值。</p>]]></description></item><item>    <title><![CDATA[Cisco Meeting Server]]></title>    <link>https://segmentfault.com/a/1190000047390154</link>    <guid>https://segmentfault.com/a/1190000047390154</guid>    <pubDate>2025-11-11 19:05:02</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>Cisco Meeting Server 3.11 - 会议与协作</p><p>思科 Meeting Server</p><p>请访问原文链接：<a href="https://link.segmentfault.com/?enc=wjQ%2FS707BzEbcUccGp190Q%3D%3D.ZrYtSmsz2MXh4BJCh4jZRGqECHyzGticO%2FALL8De3zzaITGlozvvfZGepqoSHW%2BX" rel="nofollow" target="_blank">https://sysin.org/blog/cisco-meeting-server-3/</a> 查看最新版。原创作品，转载请保留出处。</p><p>作者主页：<a href="https://link.segmentfault.com/?enc=fE9lH4mv1Qj%2BNJbp7nm7ug%3D%3D.rDN%2BYPhFKuAiHYql4D8eG7CklMG7QLVr0BmlsLotKlY%3D" rel="nofollow" target="_blank">sysin.org</a></p><hr/><p>思科 Meeting Server</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047390156" alt="人人畅享轻松会议体验" title="人人畅享轻松会议体验"/></p><h2>人人畅享轻松会议体验</h2><p>思科 Meeting Server  将本地视频、音频和网络通信解决方案整合到一个设备中，可满足现代工作场所的协作需求。它还能与第三方设备结合使用，打造亲切、愉悦的用户体验  (sysin)。该软件可实现轻松扩展，您只需购买所需的基于用户的多功能多方许可选项即可。</p><h2>特性</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047390157" alt="一个男子对着显示器进行视频会议" title="一个男子对着显示器进行视频会议" loading="lazy"/></p><h3>增强的会议体验</h3><p>无论与会者以何种方式参加会议，Meeting Server 都能为所有人提供顺畅而愉悦的用户体验。</p><h3>企业级协作</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047390158" alt="与会者围坐在会议桌旁对着屏幕召开 Meeting Server 协作会议" title="与会者围坐在会议桌旁对着屏幕召开 Meeting Server 协作会议" loading="lazy"/></p><p>了解 Meeting Server 软件如何以简单而轻松的购买方式，帮助您简化协作，提高工作效率，并实现投资保护。</p><h3>全面的设备支持</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047390159" alt="全面的设备支持" title="全面的设备支持" loading="lazy"/></p><p>Meeting Server 支持思科协作终端、Jabber 客户端、 Meeting App（本地客户端或通过兼容 WebRTC 的浏览器）和第三方设备 (sysin)，每个人都能以自己习惯的方式加入会议，并获得毫无差别的高质量体验。</p><ul><li><a href="https://link.segmentfault.com/?enc=RkRcp37R84TbvQvZW85SJg%3D%3D.Ssu71TNncuqRPlEzrV1z8xQOzBJ%2FguGwPpiMNuyDM4SNs4iq5K7wuznpuJoilUzDNXO35rWIiPduGIWZ8kgKRtL8vEMcJ%2FjJzosQqGGS6UxI7PKHigI%2FBydxUo8vUxoi" rel="nofollow" target="_blank">阅读 FINRA 案例研究</a></li></ul><h3>强大的可扩展性</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047390160" alt="强大的可扩展性" title="强大的可扩展性" loading="lazy"/></p><p>可轻松扩展的 Meeting Server 能够同时满足小型和大型部署的需求。通过支持用户使用多种平台在一起开会，您可以优化带宽并降低成本。您可以从小型部署起步，并随时根据需要扩大部署规模。</p><h3>简化的许可方式</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047390161" alt="简化的许可方式" title="简化的许可方式" loading="lazy"/></p><p>基于用户的多功能多方许可模式便于您轻松购买 Meeting Server。您可以根据当前需求购买所需的服务，日后随着组织规模的增长灵活地增购许可证。请详细了解我们提供的简单而经济的许可选项。</p><h2>下载地址</h2><p><strong>Cisco Meeting Server 3.11 &amp; Meeting Management 3.11.0</strong>：</p><p>下载地址：<a href="https://link.segmentfault.com/?enc=SbQ8lWdrGP%2BKgJJRxu2EFQ%3D%3D.mI0UCy1mxF%2FHg1rC16jSu%2FVXsNSUdNqstmoejdy%2Fk5WHP3XfOuqr0qxGnfXI%2BYac" rel="nofollow" target="_blank">https://sysin.org/blog/cisco-meeting-server-3/</a></p><p>File Information</p><p><strong>Meeting Server 1000</strong> Release CMS3.11</p><table><thead><tr><th>File Information</th><th>File Name</th><th>Release Date</th><th>Size</th></tr></thead><tbody><tr><td>Use this image to deploy a new virtual machine via OVA. Use for ESXi 7.0 and ESXi 8.0</td><td>Cisco_Meeting_Server_3_11_vSphere-7_0.ova</td><td>30-Apr-2025</td><td>605.32 MB</td></tr><tr><td>Use this image to upgrade a virtual machine deployment. Please unzip the file before uploading to the server.</td><td>Cisco_Meeting_Server_3_11_vm-upgrade.zip</td><td>30-Apr-2025</td><td>601.04 MB</td></tr></tbody></table><p><strong>Meeting Server 2000</strong> Release CMS3.11</p><table><thead><tr><th>File Information</th><th>File Name</th><th>Release Date</th><th>Size</th></tr></thead><tbody><tr><td>This is software for the CMS2000 platform. Please unzip the file before uploading it to the server.</td><td>Cisco_Meeting_Server_3_11_CMS2000.zip</td><td>30-Apr-2025</td><td>615.23 MB</td></tr></tbody></table><p><strong>Meeting Management</strong> Release CMM3.11.0</p><table><thead><tr><th>File Information</th><th>File Name</th><th>Release Date</th><th>Size</th></tr></thead><tbody><tr><td>Upgrade image for Cisco Meeting Management 3.11.0. Please unzip the file before uploading to the server.</td><td>Cisco_Meeting_Management_3_11_0.zip</td><td>30-Apr-2025</td><td>141.32 MB</td></tr><tr><td>OVA Image for Cisco Meeting Management 3.11.0. Use this image to deploy a new virtual machine via OVA on ESXi 7.0 and ESXi 8.0</td><td>Cisco_Meeting_Management_3_11_0_vSphere-7_0.ova</td><td>30-Apr-2025</td><td>143.02 MB</td></tr></tbody></table><p>更多：<a href="https://link.segmentfault.com/?enc=D%2BIkA1m%2BiLV7%2FQWFgV98OQ%3D%3D.AU%2FmsQAq66dqHWE69ah8tlGBNZauKpCKviNAoiU%2FpCI%3D" rel="nofollow" target="_blank">Cisco 产品下载链接汇总</a></p>]]></description></item><item>    <title><![CDATA[齿轮轴承行业CRM解决方案，齿轮轴承企业]]></title>    <link>https://segmentfault.com/a/1190000047390176</link>    <guid>https://segmentfault.com/a/1190000047390176</guid>    <pubDate>2025-11-11 19:04:09</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在齿轮与轴承的世界里，精度、耐用与无缝啮合是成功的基石。然而，许多企业的客户关系管理却远未达到其产品的精密水准：客户信息散落于销售个人的电脑与微信中，冗长的项目跟进周期让管理层难以把控，被动的客户服务导致高价值客户悄然流失。</p><p>要驱动业务持续增长，企业亟需一个强大的“数字中枢”，将散落的力汇聚成一股绳。此时，一套像<strong>珍客AI CRM</strong>这样，深度理解工业品销售逻辑的客户关系管理平台，便开始展现出其关键价值。它不仅仅是一个记录工具，更是重塑企业市场、销售与服务流程的运营引擎。</p><h4><strong>一、直面行业核心痛点，CRM的价值锚点</strong></h4><p>齿轮轴承企业的客户管理，独特且复杂：</p><ol><li><strong>复杂的客户结构与决策链：</strong> 从主机厂到维修服务商，决策链涉及采购、技术、质量等多部门。传统的记录方式难以描绘清晰的“客户关系图谱”。</li><li><strong>长周期与非标定制的销售流程：</strong> 从技术对接到样品测试，周期漫长，过程中产生的技术文档、沟通记录与版本变更，是企业的核心知识资产，却最易流失。</li><li><strong>激烈的价格竞争与利润保卫战：</strong> 在成本波动与竞争压力下，快速、精准且有利可图的报价，极度依赖对历史数据与成本结构的洞察。</li><li><strong>高价值的售后与服务依赖：</strong> 备件销售与预防性维护是稳定的利润来源，也是构筑客户护城河的关键。被动响应式的服务已远远不够。</li></ol><p>专业的<strong>CRM系统</strong>通过<strong>集中化客户档案、标准化销售流程、一体化报价与服务管理</strong>，将跨部门协作“啮合”起来，实现高效运转。</p><p><img width="723" height="404" referrerpolicy="no-referrer" src="/img/bVdmHRm" alt="珍客AI CRM" title="珍客AI CRM"/></p><h4><strong>二、AI赋能CRM：为精密制造注入“决策智能”</strong></h4><p>当CRM与AI技术结合，它便从“流程管理系统”进化为了“智能决策系统”。例如，在<strong>珍客AI CRM</strong>这样的平台上，AI能力可以无缝融入业务场景：</p><ol><li><p><strong>智能客户分析与精准营销：</strong></p><ul><li><strong>潜力预测：</strong> AI通过分析客户的采购历史、互动频率、行业动态等数据，自动为每个客户打分，识别出高潜力的“金牛客户”和有流失风险的“问题客户”。销售团队可以据此优先分配资源。</li><li><strong>商机推荐：</strong> 系统能自动扫描市场公开信息（如新工厂建设、设备招标），并匹配企业自身的产品优势，主动向销售推荐潜在商机，实现从“等客上门”到“主动寻客”的转变。</li></ul></li><li><p><strong>智能报价与利润优化：</strong></p><ul><li><strong>价格预测：</strong> AI模型结合原材料成本、市场竞争态势、客户历史订单价等多维度数据，为销售人员提供一个“建议报价区间”，在提升中标率的同时，守住利润底线。</li><li><strong>风险识别：</strong> 系统可自动评估新客户的信用状况或分析老客户的付款延迟记录，在订单生成前发出预警，帮助企业规避坏账风险。</li></ul></li><li><p><strong>预测性服务与主动维护：</strong></p><ul><li><strong>这是AI最具颠覆性的应用。</strong> 通过物联网（IoT）技术获取安装在客户设备上的轴承、齿轮的运行数据（如温度、振动频率），AI可以预测零部件可能发生故障的时间点。</li><li>CRM系统会<strong>自动生成预防性维护工单</strong>，并提前通知服务团队和客户，推荐合适的备件，变“被动救火”为“主动防护”。这极大地提升了客户设备稼动率，将服务从成本中心转变为强有力的利润和客户粘性中心。</li></ul></li><li><p><strong>销售流程自动化与辅助：</strong></p><ul><li>AI可以自动分析销售人员的邮件和通话记录，提示下一步最佳跟进动作，甚至自动生成周报，让销售更专注于价值创造本身。</li></ul></li></ol><h4><strong>三、实践路径：从数据孤岛到智能协同</strong></h4><p>实现智能化运营并非一蹴而就。成功的企业通常遵循以下路径：</p><ol><li><strong>奠基：实现客户资产的数字化。</strong> 首先将所有客户信息、联系人、历史交易记录集中到<strong>珍客AI CRM</strong>这样的统一平台上，打破数据孤岛。</li><li><strong>优化：固化并优化销售与服务流程。</strong> 利用系统的流程引擎，将最佳实践固化为标准动作，确保团队协作规范、高效。</li><li><strong>赋能：引入AI洞察，驱动精准决策。</strong> 在数据基础之上，充分利用AI分析能力，为销售预测、客户关怀和风险防控提供数据支撑。</li></ol><h4><strong>结语</strong></h4><p>对于齿轮轴承企业而言，未来的竞争力源于外部制造的“硬精度”，也离不开内部管理的“软效率”。通过引入深度融合行业特性并具备AI能力的<strong>CRM系统</strong>，企业能够真正以客户为中心，将散乱的信息转化为清晰的洞察，将被动的响应转变为主动的服务，从而在激烈的市场竞争中实现精准突围，稳健前行。</p>]]></description></item><item>    <title><![CDATA[住宅ip和机房ip有什么区别？IP地址冲]]></title>    <link>https://segmentfault.com/a/1190000047390198</link>    <guid>https://segmentfault.com/a/1190000047390198</guid>    <pubDate>2025-11-11 19:03:09</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>一、住宅IP与机房IP的核心区别</p><p>住宅IP和机房IP是两种不同类型的IP资源，其定义、分配方式及适用场景存在显著差异：</p><p><img width="723" height="419" referrerpolicy="no-referrer" src="/img/bVdm0wb" alt="" title=""/></p><ol><li><p>定义与分配方式</p><p>住宅IP：</p></li></ol><pre><code>
    由家庭宽带ISP（如电信、联通）动态分配给个人用户的真实设备IP地址，与普通网民的IP一致，分布分散且非连号。
    
    
    例如：家庭WiFi中手机、电脑等设备使用的IP地址。

机房IP：
    
    由云服务商（如AWS、阿里云）或数据中心静态分配给服务器的固定IP地址，通常以连号形式存在（如192.168.1.1-100），可能因数据中心位置与注册地不一致形成“广播IP”。
</code></pre><ol start="2"><li><p>稳定性与带宽</p><p>住宅IP：</p><pre><code> 
 动态分配，可能因设备重启或ISP策略变化而更换，稳定性较低，但带宽通常满足个人需求。
</code></pre><p>机房IP：</p><pre><code> 
 固定不变，提供高带宽和低延迟，适合长时间在线任务（如下载、挂机）。
</code></pre></li><li>应用场景​</li></ol><pre><code>
住宅IP：

    高匿名性需求：如跨境电商账号注册、社交媒体爬虫，避免被目标网站封禁。
    
    
    短效任务：需频繁更换IP的场景（如价格监控、数据采集）。

机房IP：
    
    稳定性优先：如服务器托管、网站反向代理、大规模爬虫（非复杂反爬目标）。
    
    
    企业级应用：数据库存储、云计算服务等。
</code></pre><ol start="4"><li><p>成本与获取难度</p><p>住宅IP：</p><pre><code> 成本较低，可通过家庭宽带直接获取，但需避免多设备占用同一IP。
</code></pre></li></ol><pre><code>
机房IP：

    需租用服务器资源，成本较高，且需遵守云服务商的使用规范。
</code></pre><p>二、IP地址冲突的解决方法</p><p>IP冲突通常因局域网内多设备使用相同IP或ARP病毒导致，以下是具体解决步骤：</p><ol><li><p>快速修复方法​</p><p>重启设备：</p><p>依次重启路由器和电脑，强制重新分配IP地址。</p></li></ol><pre><code>
释放并更新IP（适用于自动获取模式）：

打开命令提示符，依次执行：

ipconfig /release ipconfig /renew

此操作可清除旧IP并请求新地址。
</code></pre><ol start="2"><li>手动设置唯一IP​</li></ol><p>若需固定IP，需确保与局域网内其他设备不重复：</p><pre><code>
进入网络设置 → IPv4属性 → 选择“使用以下IP地址”。


输入未被占用的IP（如192.168.1.100）、子网掩码（255.255.255.0）、网关（如192.168.1.1）。
</code></pre><ol start="3"><li>检查路由器设备列表​</li></ol><p>登录路由器管理界面（如192.168.1.1），查看DHCP分配的IP列表，修改冲突设备的IP或禁用非法设备。</p><ol start="4"><li><p>防范ARP病毒​</p><p>启用ARP防护：</p><p>在路由器中开启“IP与MAC绑定”功能，将关键设备（如打印机、NAS）的IP与MAC地址绑定。</p></li></ol><pre><code>
查杀病毒：

使用安全软件全盘扫描，升级系统补丁，关闭不必要的共享端口。

</code></pre><p>三、选择建议</p><pre><code>
优先住宅IP的场景：需高匿名性、动态IP的短效任务（如电商比价、社交媒体管理）。


优先机房IP的场景：需稳定IP的长效服务（如服务器托管、数据爬虫）。


冲突处理原则：家庭网络优先自动分配IP，企业网络建议启用静态IP绑定与ARP防护。
</code></pre><p>通过合理选择IP类型及规范网络管理，可有效避免冲突并提升业务效率。</p>]]></description></item><item>    <title><![CDATA[专题：2025中国医疗器械出海现状与趋势]]></title>    <link>https://segmentfault.com/a/1190000047390221</link>    <guid>https://segmentfault.com/a/1190000047390221</guid>    <pubDate>2025-11-11 19:02:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><strong>原文链接：</strong> <a href="https://link.segmentfault.com/?enc=uUIDPV3VIITvttUDKu%2FHQA%3D%3D.0C%2BsfzuBGxj9Sr0jhVStT%2BepdjUph6Vi2tvIiRMJGRw%3D" rel="nofollow" title="https://tecdat.cn/?p=44279" target="_blank">https://tecdat.cn/?p=44279</a>  <br/><strong>原文出处：拓端抖音号@拓端tecdat</strong></p><p><strong><img referrerpolicy="no-referrer" src="/img/remote/1460000047390223" alt="封面" title="封面"/></strong></p><p>2024年，中国医疗器械行业正站在“从本土领先到全球突围”的关键节点——一边是迈瑞医疗把监护仪卖到190多个国家，海外营收占比超48%；一边是不少企业卡在欧盟MDR认证环节，临床数据补了3次仍未通过。这种“一边风光一边难”的反差，本质是全球医疗需求扩张与国内竞争加剧的必然结果。</p><p><strong>引言</strong>  <br/>本报告洞察基于《弗若斯特沙利文：2025中国医疗器械出海现状与趋势蓝皮书》《国家高性能医疗器械创新中心：高性能医疗器械2024年度创新发展报告》《华安证券：2025脑机接口行业发展更新》《顺为人和：2025年医疗器械企业组织效能报告》<strong>及文末160+份医疗器械行业研究报告的数据，最新报告合集及解读实时更新已分享在交流群，阅读原文进群咨询、定制数据报告和800+行业人士共同交流和成长。</strong></p><p>从核心数据看，2024年全球医疗器械市场规模达6230亿美元，中国贡献超15%份额，但出海企业仍面临两大卡脖子问题：一是欧美合规周期长（欧盟MDR平均18个月），二是高端市场品牌认可度低（骨科植入物进口占比仍超40%）。不过创新端已出现突破——2024年国内65款创新器械获批，脑机接口、可降解心脏封堵器等产品性能追上国际巨头。接下来，我们从市场、创新、效能三个维度拆解趋势，给出门槛低、见效快的落地方法。</p><h3><a name="t0" target="_blank"/>一、行业转折点：国产替代完成，出海成第二增长曲线</h3><p>2014年那会儿，国内医院的CT、MRI基本是GE、西门子的天下，国产设备只能做血压计、注射器这类低值耗材；到2024年，迈瑞医疗的监护仪全球市占率前三，联影医疗的7T磁共振不用依赖进口零件，甚至反过来出口欧洲。  <br/>这十年变化的关键，靠的是“政策托底+企业发力”：国家推“设备更新”政策，用超长期特别国债支持医院换国产设备；企业一边砸研发（头部企业研发占比超10%），一边靠海外并购补短板——比如天益医疗收购日机装CRRT业务，直接拿到全球血液净化市场的入场券。  <br/>但现在新问题来了：国内集采把低值耗材利润压到5%以内，不做海外市场就没增长空间；可出海又要面对欧盟MDR、美国FDA的高门槛。要解决这个矛盾，先得把全球和中国市场的增长逻辑理清楚。</p><h3><a name="t1" target="_blank"/>二、市场规模：全球缺设备，中国有产能，出海是必然选择</h3><h4><a name="t2" target="_blank"/>1. 全球市场：2035年达1.1万亿美元，高附加值品类最赚钱</h4><p>全球医疗器械市场正以8.1%的速度扩张，从2020年的4566亿美元涨到2024年的6230亿美元，预计2035年能突破1.1万亿美元。其中最赚钱的是高附加值品类，比如脑机接口，2033年规模能达8.5亿美元，年均增长7%。  <br/>为什么增长这么快？三个原因：一是全球老龄化（65岁以上人口占比超17%），慢性病患者多了，需要更多心脏支架、血糖仪；二是新兴市场缺设备，东南亚、中东的基层医院连DR机都配不齐；三是新技术迭代，AI辅助诊断、微创治疗设备需求激增。  <br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047390224" alt="" title="" loading="lazy"/>  <br/>全球医疗器械市场规模_瀑布图A1图表数据及PDF模板已分享到会员群  <br/>3秒解读：未来10年全球增量的5346亿美元，占总规模近一半，主要来自高附加值设备。  <br/>行动建议（出海企业负责人）：优先攻欧美高端市场（比如美国IDN医联体），中小企先从东南亚转口贸易切入，避开高关税。</p><h4><a name="t3" target="_blank"/>2. 中国市场：2035年超1.8万亿元，基层和创新是两大增量</h4><p>中国医疗器械市场增速虽比全球慢一点（CAGR6.6%），但规模很稳——从2020年7298亿元涨到2024年9417亿元，2035年能超1.8万亿元。增长全靠两点：一是国家“设备更新”政策，2024年超长期特别国债重点支持医院换国产设备；二是基层医疗补短板，重点中心乡镇卫生院必须配齐CT、彩超。  <br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047390225" alt="" title="" loading="lazy"/>  <br/>中国医疗器械市场规模_面积图A2图表数据及PDF模板已分享到会员群  <br/>3秒解读：2024-2035年的增量是前4年的2倍，基层医院和创新器械是必争之地。  <br/>行动建议（基层医疗设备供应商）：2025年盯紧县级医院招标，主推性价比高的DR、彩超，比如把设备和售后打包报价，提高中标率。</p><hr/><p><strong>相关文章</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047390226" alt="相关文章" title="相关文章" loading="lazy"/></p><h2><a name="t4" target="_blank"/>2025全球医疗器械报告-创新与效率平衡之道320+份汇总解读|附PDF下载</h2><p><strong>全文链接：</strong><a href="https://link.segmentfault.com/?enc=bL2m8FVKY0ADBOAk4Wkf2A%3D%3D.vN1RuE5k3E%2F%2FMijedL6YGAOqo6hTh8dqM7uE0OOdfjk%3D" rel="nofollow" title="https://tecdat.cn/?p=42383" target="_blank">https://tecdat.cn/?p=42383</a></p><hr/><h4><a name="t6" target="_blank"/>3. 数据对比：不同报告差异在哪？别被数据误导</h4><p>很多人看报告时会困惑，为什么不同机构的数据不一样？其实不是数据错了，是统计范围或时间不同，比如：</p><table><thead><tr><th>核心结论</th><th>数据差异</th><th>原因分析</th></tr></thead><tbody><tr><td>全球医疗器械市场规模</td><td>沙利文：2035E 11576亿美元；国家高性能医疗器械创新中心：2024年6230亿美元</td><td>时间周期不同：沙利文算的是11年预测，国家创新中心是当年实际数据</td></tr><tr><td>中国出海企业海外收入占比</td><td>沙利文：头部企业平均31.9%；顺为人和：迈瑞医疗2024H1海外收入占比48.3%</td><td>统计范围+时间不同：沙利文覆盖全行业，顺为人和只算龙头；迈瑞是半年报数据</td></tr><tr><td>脑机接口市场规模</td><td>华安证券：2033年8.5亿美元；沙利文：未单独统计</td><td>赛道关注度不同：华安聚焦前沿技术，沙利文侧重整体出海趋势</td></tr></tbody></table><h3><a name="t7" target="_blank"/>三、创新研发：从“跟跑”到“领跑”，这些技术能打全球市场</h3><h4><a name="t8" target="_blank"/>1. 研发投入：华大智造18.6%领跑，钱要花在刀刃上</h4><p>2023年国内医疗器械企业的研发投入差距很大，华大智造花了18.6%的营收搞研发，九安医疗只花了4.5%，行业平均约10.2%。高投入的企业都有个特点：盯着高端赛道，比如联影医疗做影像设备、微创医疗做可吸收支架；而做低值耗材的企业，研发投入普遍低于8%。  <br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047390227" alt="" title="" loading="lazy"/>  <br/>企业研发投入占比_雷达图B1图表数据及PDF模板已分享到会员群  <br/>3秒解读：研发超12%的企业（华大智造、新产业）都在押前沿赛道，低投入企业多做传统耗材。  <br/>行动建议（创新企业高管）：2025年把研发预算向AI医疗器械倾斜，比如AI辅助诊断软件，这类产品在欧美认证周期短，6-8个月就能拿证。</p><h4><a name="t9" target="_blank"/>2. 前沿技术：脑机接口成新风口，2033年规模达8.5亿美元</h4><p>现在最火的前沿赛道是脑机接口，预计2025年市场规模5亿美元，2033年能到8.5亿美元，CAGR7%。国内已经有产品进入临床，比如博睿康的NEO脑机接口，术后一个月就能帮瘫痪患者喝水；国际上Neuralink更猛，人体植入手术能实现每分钟200字符的“意念打字”。  <br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047390228" alt="" title="" loading="lazy"/>  <br/>全球脑机接口市场规模_气泡图B2图表数据及PDF模板已分享到会员群  <br/>3秒解读：脑机接口靠医疗（瘫痪康复）和消费（智能交互）双场景驱动，中美是技术领先国。  <br/>行动建议（前沿技术企业）：先攻克生物相容性材料，减少植入时的排斥反应；再对接北京天坛、上海华山等TOP10医院，加快临床试验进度。</p><h3><a name="t10" target="_blank"/>四、企业效能：人效差3倍！头部企业靠“规模+技术”赢</h3><h4><a name="t11" target="_blank"/>1. 人均营收：迈瑞185万元居首，规模和产品结构是关键</h4><p>2024年标杆企业的人均营收平均122万元，但差距特别大：迈瑞医疗185万元、九安医疗169万元、新产业166万元，而乐普医疗只有64万元。为什么差这么多？一是规模效应，迈瑞在全球有10多个生产基地，单位成本比中小企低20%；二是产品结构，高附加值设备占比高的企业，人效自然高。  <br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047390229" alt="" title="" loading="lazy"/>  <br/>企业人均营收_棒棒糖图C1图表数据及PDF模板已分享到会员群  <br/>3秒解读：人均营收超160万元的企业，要么海外营收超30%，要么高端设备占比超50%。  <br/>行动建议（中小器械企业经营者）：2025年别贪多，砍掉非核心的低值耗材（比如普通注射器），聚焦1-2个高毛利品类（如家用血糖仪），靠规模化降成本，目标把人均营收提到100万元以上。</p><h4><a name="t12" target="_blank"/>2. 人均净利：九安117万元领跑，盈利要踩准产品周期</h4><p>2024年企业人均净利平均33.4万元，九安医疗以117.2万元领跑，新产业66.9万元紧随其后，但华大智造亏了22.3万元。这不是华大智造不行，而是产品还在研发期——脑机接口这类前沿技术，要砸3-5年钱才能规模化盈利；而九安医疗赚钱，是因为海外家用检测设备需求正好爆发，踩准了产品周期。  <br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047390230" alt="" title="" loading="lazy"/>  <br/>企业人均净利_分歧条形图C2图表数据及PDF模板已分享到会员群  <br/>3秒解读：研发超15%的企业短期可能亏，但长期有技术壁垒；低值耗材企业盈利稳但增速慢。  <br/>行动建议（财务负责人）：研发高的企业，赶紧申请“研发费用加计扣除”，能少缴15%的税；盈利稳的企业，多投钱建海外渠道，比如在东南亚找本地经销商，提高增速。</p><h3><a name="t13" target="_blank"/>五、2025年Q1必做：3件落地性强的事</h3><ol><li><strong>出海企业：3月底前启动欧盟CE-MDR预审</strong>  <br/>  别等产品做好了再碰认证，参考迈瑞收购HyTest后快速拿证的经验，现在就联系UL Solutions这类机构，先做拟出海设备（比如超声系统）的预审，重点补临床数据和技术文档——欧盟MDR平均18个月拿证，晚启动就少赚半年钱。  <br/>  （配套资源：会员群已分享《欧盟MDR认证 Checklist》，临床数据要求、文档模板都有）</li><li><strong>研发企业：2月底前对接3家神经外科医院</strong>  <br/>  做脑机接口的企业，别自己闷头研发，2月底前筛选北京天坛、上海华山等TOP5医院，参照博睿康NEO的方案，把临床试验终点设为“安全性+有效性”（比如术后3个月患者能完成喝水动作），这样注册能快3-4个月。  <br/>  （配套资源：会员群整理了国内神经外科临床试验机构名单，还有合作案例可参考）</li><li><strong>中小企：1月底前砍非核心品类</strong>  <br/>  如果现在人均营收低于80万元，1月底前必须砍非核心低值耗材，比如普通注射器、医用胶布，聚焦家用血糖仪、便携式监护仪这类高毛利品类，通过规模化生产把单位成本降10%，目标人均营收超100万元。  <br/>  （配套资源：会员群有《医疗器械企业人效优化案例》，迈瑞、鱼跃的成本控制方法都在里面）</li></ol><h3><a name="t14" target="_blank"/>六、3大风险：提前规避，别踩这些坑</h3><ol><li><strong>合规风险：欧盟MDR认证超期</strong>  <br/>  风险点：2024年欧盟把MDR过渡期延到2027-2028年，但高风险产品（如心脏支架）的临床数据要求更严，有人补了3次还没过，拖了1年多。  <br/>  应对方案：一是走“CE转东盟AMDD互认”，比如医用敷料过了CE，48周内就能拿新加坡注册证；二是加会员群，每周有欧盟公告机构专家答疑，实时更正规法变化。</li><li><strong>研发风险：钱投错方向</strong>  <br/>  风险点：脑机接口、脉冲电场消融技术迭代快，有企业投了2000万研发，结果临床需求变了，钱全打水漂。  <br/>  应对方案：建“临床专家顾问团”，每季度跟3家三甲医院医生聊需求；会员群有2024年获批创新器械的临床需求报告，照着做能少走弯路。</li><li><strong>人效风险：海外团队成本高</strong>  <br/>  风险点：海外员工占比超20%后，管理成本会涨——有企业海外团队薪酬比国内高50%，人均净利直接降了15%。  <br/>  应对方案：海外招人优先选本地员工，总部只派核心技术岗，占比控制在30%以内；会员群有《海外团队薪酬模板》，不同国家薪资基准都标好了。</li></ol><p><strong><img referrerpolicy="no-referrer" src="/img/remote/1460000047390223" alt="封面" title="封面" loading="lazy"/></strong></p><h3><a name="t15" target="_blank"/>本专题内的参考报告（PDF）目录</h3><ol><li>智启新质生产力之三 ——生成式人工智能 （AIGC）在医疗器械 的潜在... 报告2025-11-11</li><li>医疗保健：医疗器械2025 报告2025-10-19</li><li>医疗器械行业专题-2025脑机接口行业发展更新 报告2025-10-15</li><li>医疗器械人工智能监管新动向 报告2025-10-08</li><li>2025年热电偶导线在医疗器械中的应用场景白皮书 报告2025-10-03</li><li>2025年医疗器械标杆企业组织效能报告 报告2025-08-26</li><li>2024年高性能医疗器械创新发展报告 数据2025-06-30</li><li>2025年医疗器械行业ESG白皮书 报告2025-06-17</li><li>2025中国医疗器械出海现状与趋势蓝皮书 报告2025-06-17</li><li>2025年中企出海白皮书：医药和医疗器械篇 报告2025-04-20</li><li>2025年放疗医疗器械市场行业研究报告 报告2025-04-18</li><li>2025年全球医疗器械报告-创新与效率平衡之道 报告2025-03-24</li><li>手术机器人：高端医疗器械领域的“明珠”，重构现代外科手术体系 报告2025-03-21</li><li>2025年智启原新：医药和医疗器械企业AI原生转型报告 报告2025-03-10</li><li>医疗器械-生命信息与支持设备专题-论高国产化率赛道增长点在何方？ 报告2025-02-05</li><li>2024医疗器械及供应链创新白皮书 报告2025-01-23</li><li>医疗器械行业：新政策下医疗器械市场及院端趋势洞察 报告2024-12-31</li><li>赛迪：2024医疗器械十大前沿技术报告 报告2024-12-19</li><li>天册律所：2024中国医疗器械出海东南亚白皮书 报告2024-11-26</li><li>中华商标协会：2024年医疗器械行业海外商标保护白皮书 报告2024-10-10</li><li>中国物流与采购联合会：中国物中国医疗器械供应链发展报告(2024)重点... 报告2024-08-26</li><li>头豹：2024年中国医疗器械出海之路-带量采购风暴后中国医疗器械价格狂... 报告2024-07-30</li><li>中物联医疗器械供应链分会：2024医疗器械物流重点企业全景分析报告 报告2024-07-09</li><li>罗兰贝格：全球医疗器械报告2024 报告2024-05-22</li><li>Acloudear：2024版医疗器械行业数字化转型白皮书 报告2024-04-05</li><li>国家高性能医疗器械创新中心：高性能医疗器械2023年度发展报告 报告2024-04-01</li><li>深圳市医疗器械行业协会：2024深圳市医疗器械产业专利导航分析报告 报告2024-03-25</li><li>嘉世咨询：2023医疗器械行业简析报告 报告2024-03-12</li><li>艾意凯：2023年度亚太地区医院调研专题报告-亚太地区医院战略重点的变... 报告2024-03-06</li><li>招商银行：医疗器械之医学影像篇-国产影像设备崛起-国产替代与出海正当时 报告2024-03-02</li><li>德勤：2024中国医疗器械企业全球化发展-热门市场概览与制胜因素报告 报告2024-02-27</li><li>蛋壳研究院：2023医疗器械及供应链年度创新白皮书 报告2024-01-18</li><li>中物联：2023中国医疗器械SPD重点企业分析报告 报告2024-01-02</li><li>智启新质生产力之三 ——生成式人工智能 （AIGC）在医疗器械 的潜在... 报告2025-11-11</li><li>2025健康医疗内容消费趋势洞察报告 报告2025-11-11</li><li>中国医疗服务：药店：2025年三季报总结 报告2025-11-06</li><li>2025医疗未来：未来的医疗体系报告 报告2025-11-02</li><li>2025 AI与劳动力的未来：生成式AI对医疗行业岗位的影响研究报告 报告2025-11-02</li><li>计算机深度报告-Tempus AI启示-用数据构筑AI+医疗行业领先优... 报告2025-11-01</li><li>2025年医疗科技行业未来展望报告 报告2025-10-29</li><li>探索医疗保健领域的塑料循环利用机会 报告2025-10-28</li><li>2025年AI时代的医疗保健业：科技注入赋能医疗创新与患者关怀报告 报告2025-10-28</li><li>2025年可持续医疗趋势报告 报告2025-10-21</li><li>2025中国医疗健康保障体系转型发展报告：应对老龄化挑战与推动商业健康... 报告2025-10-20</li><li>医疗保健：医疗器械2025 报告2025-10-19</li><li>AI 时代的医疗保健业：科技注入，赋能 医疗创新与患者关怀 报告2025-10-19</li><li>跨越信任鸿沟：AI在科研与医疗领域深度应用的核心挑战 报告2025-10-17</li><li>医疗器械行业专题-2025脑机接口行业发展更新 报告2025-10-15</li><li>2025年9月全球医疗健康领域投融资月报 报告2025-10-15</li><li>2025年信心与价值：提升医疗价格透明度研究报告 报告2025-10-14</li><li>医疗器械人工智能监管新动向 报告2025-10-08</li><li>医疗行业分布式数据库解决方案白皮书 报告2025-10-08</li><li>2025年热电偶导线在医疗器械中的应用场景白皮书 报告2025-10-03</li><li>2025年全球医疗行业状况报告 报告2025-09-30</li><li>2025 AI应用与行业转型：对医疗、金融服务、气候与能源及交通领域的... 报告2025-09-29</li><li>2025未来AI与劳动力：生成式AI对医疗行业岗位的影响研究报告 报告2025-09-22</li><li>2025智能医疗健康：人工智能驱动转型与价值重塑报告0000 报告2025-09-21</li><li>2025年医疗器械标杆企业组织效能报告 报告2025-08-26</li><li>2025年医疗保健预算执行-从瓶颈到解决方案报告 报告2025-08-15</li><li>2025年迈向全民医疗保障的中国经验研究报告 报告2025-08-10</li><li>医药生物-高端医疗发展白皮书 报告2025-08-03</li><li>2025年AI科技勾勒医疗未来蓝图：AI for 医疗健康系列报告“智... 报告2025-08-03</li><li>2025医疗健康新质生产力 “创变引擎” 系列洞察 创新医疗科技篇 报告2025-08-01</li><li>2025中国人工智能医疗健康研究报告 报告2025-07-30</li><li>2025生物制药与医疗科技行业全渠道策略研究报告 报告2025-07-29</li><li>2025中国宠物医疗行业现状报告 报告2025-07-21</li><li>2025年H1全球医疗健康产业资本报告 报告2025-07-21</li><li>2025年Z世代个性化消费医疗洞察报告 报告2025-07-20</li><li>2025年高端医疗发展白皮书 报告2025-07-19</li><li>2025商业健康保险与医药产业高质量 协同发展——团体补充医疗保险改革... 报告2025-07-18</li><li>2025“人工智能+”医疗健康行业应用白皮书 报告2025-07-18</li><li>2024年塑造美国医疗经济的八大趋势研究报告 报告2025-07-14</li><li>2025年医疗美容行业白皮书 报告2025-07-08</li><li>2025年未来医疗调查报告 报告2025-07-08</li><li>2025医疗美容行业白皮书 报告2025-07-05</li><li>2025医疗领域的数字孪生：开启个性化医疗与诊断的未来研究报告 报告2025-07-05</li><li>2025年中国智慧医疗行业白皮书 报告2025-07-01</li><li>2025年Q2医疗美容行业薪酬报告 报告2025-06-30</li><li>2024年高性能医疗器械创新发展报告 数据2025-06-30</li><li>2025医疗健康行业AI应用白皮书 报告2025-06-28</li><li>2025年医疗保健品牌榜 报告2025-06-25</li><li>2025制药、医疗科技与生物技术领域AI应用 ：解锁商业成功之道 报告2025-06-24</li><li>2025医疗科技领域投资格局研究报告：“先建后买”模式能否成为新前沿 报告2025-06-22</li><li>2025年市场展望与薪酬指南——医疗健康与生命科学 报告2025-06-22</li><li>2024年全球医疗科技行业状况及2025年展望报告 报告2025-06-22</li><li>医疗保健行业ESG管理策略研究报告 报告2025-06-19</li><li>2025年宠物医疗行业简析报告 报告2025-06-19</li><li>2025“面向未来的医疗”调研报告 报告2025-06-18</li><li>2025年医疗卫生行业ESG白皮书 报告2025-06-17</li><li>2025年医疗器械行业ESG白皮书 报告2025-06-17</li><li>2025年人工智能赋能医疗行业的未来白皮书：AI引领智能新征程 报告2025-06-17</li><li>2025年医疗行业智慧文印解决方案白皮书 报告2025-06-17</li><li>实现人工智能在医疗服务行业中的价值 报告2025-06-17</li><li>2025中国医疗器械出海现状与趋势蓝皮书 报告2025-06-17</li><li>医疗健康行业-AI应用白皮书 报告2025-06-17</li><li>2025医疗健康新质生产力 “创变引擎” 系列洞察 创新医疗科技篇 报告2025-06-05</li><li>2025年AI Agent+医疗行业研究报告 报告2025-06-02</li><li>2025年第一季度欧洲和美国远程医疗报告 报告2025-06-02</li><li>2025年中国AI医疗健康企业创新发展百强榜单报告 报告2025-05-28</li><li>外骨骼机器人-从医疗康复走向大众消费的新蓝海 报告2025-05-25</li><li>2025商业健康险医药行业与医疗机构协同创新案例研究报告 报告2025-05-25</li><li>第二届中新数字经济与人工智能高峰论坛-健康医疗数据的确权与流通 报告2025-05-23</li><li>2025年AI医疗行业发展现状、趋势、主要应用领域及相关标的分析报告 报告2025-05-20</li><li>医疗信息流产品手册 报告2025-05-19</li><li>医疗美容行业白皮书：Z世代崛起、轻医美主导，行业正在换打法 报告2025-05-19</li><li>2024年医疗美容行业白皮书 报告2025-05-17</li><li>2025年医疗大模型研究报告-新质生产力大模型在各医疗场景的赋能实践 报告2025-05-15</li><li>中国LSHC生命科学与医疗行业调查报告 报告2025-05-10</li><li>2025年企业高端健康福利调研报告-医疗保险和体检的优化之道 报告2025-05-04</li><li>挖掘亚太地区人工智能在医疗科技领域的价值（2025年） 报告2025-04-24</li><li>2025年中企出海白皮书：医药和医疗器械篇 报告2025-04-20</li><li>2025年Q1医疗美容行业薪酬报告 报告2025-04-20</li><li>2025年放疗医疗器械市场行业研究报告 报告2025-04-18</li><li>2025年医疗数据合规白皮书 报告2025-04-16</li><li>2025年AI应用报告（企业级SaaS、内容创作、教育、金融、医疗） 报告2025-03-31</li><li>2025年全球医疗器械报告-创新与效率平衡之道 报告2025-03-24</li><li>2025价值医疗的全球审视报告：理论、实践与经验总结 报告2025-03-22</li><li>手术机器人：高端医疗器械领域的“明珠”，重构现代外科手术体系 报告2025-03-21</li><li>2025年全球医疗趋势报告：全球总览及中国大陆地区趋势解读 报告2025-03-20</li><li>2024年医疗保健行业网络安全调查 报告2025-03-20</li><li>2025年2月全球医疗健康领域投融资月报 报告2025-03-17</li><li>中国生命科学与医疗行业-调研结果：2025年行业现状与展望报告 报告2025-03-16</li><li>2025年中国生命科学与医疗行业调研报告 报告2025-03-13</li><li>2025年智启原新：医药和医疗器械企业AI原生转型报告 报告2025-03-10</li><li>医疗技术-在一个不断复杂的环境，如何医疗技术适应茁壮成长？-医疗技术行... 报告2025-03-09</li><li>2025全球医疗演进指数：复杂系统韧性重构与精准干预标靶监测体系：标志... 报告2025-03-09</li><li>全国医疗机构感染监测网：2024全球感染预防与控制报告 报告2025-03-06</li><li>2024心理健康和精神卫生医疗服务再思考报告利用新方法 报告2025-03-02</li><li>医药生物行业深度报告-AI与医疗产业深度融合-有望为医疗带来产业变革 报告2025-02-27</li><li>计算机行业深度报告-DeepSeek系列报告之AI+医疗 报告2025-02-20</li><li>洞察宠物医疗保险市场 报告2025-02-18</li><li>2025年全球医疗趋势报告 报告2025-02-10</li><li>2024年医疗技术行业报告的脉搏 报告2025-02-10</li><li>浙江大学医学院附属第四医院：医疗健康大模型白皮书（1.0版） 报告2025-02-08</li><li>医疗器械-生命信息与支持设备专题-论高国产化率赛道增长点在何方？ 报告2025-02-05</li><li>医疗技术行业报告的脉搏2024-在一个不断复杂的环境-如何医疗技术适应... 报告2025-02-05</li><li>2024年全球医疗健康产业资本报告 报告2025-02-01</li><li>2024医疗器械及供应链创新白皮书 报告2025-01-23</li><li>2025年中国医疗健康产业十大趋势 报告2025-01-16</li><li>2024医疗未来医疗健康行业中的AI变革第六版（英译中） 报告2025-01-08</li><li>2024年医疗科技行业动向报告 报告2025-01-02</li><li>2024年3D打印材料赋予医疗设计师全新的工作方式白皮书 报告2025-01-02</li><li>2024生命科学与医疗健康研究报告 报告2025-01-02</li><li>医疗器械行业：新政策下医疗器械市场及院端趋势洞察 报告2024-12-31</li><li>医药生物-数字医疗的创新浪潮：2024年新质生产力引领的新机遇研究报告 报告2024-12-30</li><li>动脉智库：2024年11月全球医疗健康领域投融资月报 报告2024-12-24</li><li>动脉智库：2024数字医疗年度创新白皮书 报告2024-12-24</li><li>中国移动：中国移动城市全域数字化转型白皮书（2024版）-医疗保障分册 报告2024-12-24</li><li>赛迪：2024医疗器械十大前沿技术报告 报告2024-12-19</li><li>德勤：GenAI正在改变医疗技术的游戏规则吗 报告2024-12-16</li><li>中国医疗设备：2024年度中国医疗设备品牌实力调研报告 报告2024-12-08</li><li>融文：2024年消费者洞察：医疗健康 报告2024-12-03</li><li>天册律所：2024中国医疗器械出海东南亚白皮书 报告2024-11-26</li><li>动脉橙：2024年10月全球医疗健康领域投融资月报 报告2024-11-16</li><li>钱伯斯全球实践指南：医疗保健行业：医疗设备2024 报告2024-11-04</li><li>世界经济论坛：2023年全球健康与医疗战略展望 报告2024-10-28</li><li>WaveStone：2024年数字医疗雷达 报告2024-10-22</li><li>蛋壳研究院：2024年医疗人工智能研究报告-生成式AI爆发，医疗人工智... 报告2024-10-21</li><li>中华商标协会：2024年医疗器械行业海外商标保护白皮书 报告2024-10-10</li><li>北京新阳光慈善基金会：2024年中国医疗健康领域公益组织生存及发展现状... 报告2024-10-09</li><li>和君咨询：中国医疗美容健康行业深度研究报告 报告2024-10-06</li><li>海通证券：2024年中国医养及康复医疗产业发展研究报告 报告2024-10-06</li><li>动脉橙：2024年8月全球医疗健康领域投融资月报 报告2024-09-19</li><li>药融咨询：2024市场洞察精准决策-医疗大数据赋能药企市场准入报告 报告2024-09-12</li><li>数研院：2024健康医疗数据要素价值开发行业观察 报告2024-09-12</li><li>艾瑞咨询：2024年中国医疗瘦身产业洞察白皮书 报告2024-09-05</li><li>中国物流与采购联合会：中国物中国医疗器械供应链发展报告(2024)重点... 报告2024-08-26</li><li>易观分析：2024数智医疗服务时代营销机遇洞察报告 报告2024-08-22</li><li>Brand Finance：2024年顶级医疗品牌报告 报告2024-08-20</li></ol>]]></description></item><item>    <title><![CDATA[ONES 重磅升级｜全新内核，深度可配置]]></title>    <link>https://segmentfault.com/a/1190000047390240</link>    <guid>https://segmentfault.com/a/1190000047390240</guid>    <pubDate>2025-11-11 19:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>ONES 于近期完成<strong>创业十年来最大范围内核代际升级</strong>。深度灵活的自定义引擎，完善的开放平台体系，AI 友好的数据交互架构。此次内核升级的首批上层功能已正式发布。</p><p>此次 <strong>ONES Project 全新升级，围绕工作项信息管理与多角色协作场景，推出一系列深度可配置能力</strong>，进一步强化了 ONES 在复杂业务场景下的流程适配与信息管理能力。</p><p><strong>快速浏览本期新功能</strong><br/><strong>ONES Project v6.88.0 功能更新</strong></p><ul><li>工作项详情布局增强</li><li>工作项属性扩展</li><li>工作项支持配置层级结构</li><li>工作项筛选器支持 ONESQL</li></ul><h3>功能 1：ONES Project 工作项详情布局增强</h3><p>在<strong>填写或查看工作项详情</strong>时，用户需要在繁杂的信息中<strong>快速定位重点</strong>，且不同角色的关注内容各不相同。</p><p><strong>ONES Project 增强了工作项详情布局</strong>，支持自由拖拽属性与控件、创建自定义标签页与分组，并<strong>可根据角色、部门或业务场景定制表单展示内容</strong>。同时，通过条件展示、条件必填等规则配置，<strong>实现业务逻辑自动化与表单信息智能展示</strong>。</p><h4>应用场景：</h4><h4><strong>1.支持工作项布局的多角色差异化展示</strong></h4><p>通过<strong>灵活配置工作项标签页、自定义属性的布局和分组</strong>，不同部门成员（如产品、研发、测试）可以查看与自身相关的属性，避免信息冗余，提高表单使用效率。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047390242" alt="图片" title="图片"/><br/>ONES Project 工作项表单配置<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047390243" alt="图片" title="图片" loading="lazy"/><br/>ONES Project 工作项详情布局</p><h4>2.更灵活的工作项属性规则，实现表单随业务流变化</h4><p>支持配置工作项属性的<strong>显示条件、必填条件、默认值条件、选项值展示条件和占位文本</strong>，将「静态表单」升级为「智能表单」，从而<strong>让表单能根据业务逻辑、角色和流程动态变化</strong>，以减少配置成本、提升数据质量。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047390244" alt="图片" title="图片" loading="lazy"/><br/>ONES Project 工作项属性配置规则</p><h3>功能 2：ONES Project 工作项属性扩展</h3><p>在复杂业务中，用户需要更强大的属性功能来构建表单，<strong>让表单能精准匹配业务，管理从基础数据到复杂关系的各类信息</strong>。</p><p><strong>ONES Project 对工作项属性进行升级</strong>，支持将原「关联内容」进行属性化配置；同时，新增级联、公式计算、富文本、标签、链接等多种属性类型；还将富文本编辑器升级为 ONES Wiki 编辑器，提供<strong>更丰富的编辑能力，实现更精准的信息管理和更充分的业务表达。</strong></p><p>应用场景：</p><h4>1.原工作项「关联内容」属性化，支持更多字段控制能力</h4><p>用户可将<strong>「关联工作项」、「关联 Wiki 页面」和「文件」</strong>这些常用内容配置为工作项属性。这意味着，团队成员可以像管理普通字段一样，<strong>自由设置其必填规则、默认值、配置在工作项列表表头等，也支持筛选检索与导入、导出</strong>。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047390245" alt="图片" title="图片" loading="lazy"/><br/>ONES Project 需求流转时，必须填写相关信息<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047390246" alt="图片" title="图片" loading="lazy"/><br/>ONES Project 工作项属性配置在列表表头</p><h4>2.支持自定义更多属性类型，满足丰富多样的业务需求</h4><p>新增属性类型包含：<strong>级联、公式计算、富文本、标签、链接</strong>，以及更多<strong>引用业务对象的菜单属性，如单选用户组、多选用户组、单选项目/部门/迭代</strong>等。</p><p><strong>2.1 级联属性</strong></p><p>在实际业务中，许多信息本身具有层级关系，比如市场区域、产品分类或版本系列等。</p><p><strong>级联属性专门用于管理此类信息，支持按层级结构组织选项</strong>，如：「国家 → 省份 → 城市」或「产品大类 → 子类 → 型号」。<strong>管理员可自定义父子关系，成员在录入信息时便能逐级选择</strong>，保证数据的规范性和条理性。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047390247" alt="图片" title="图片" loading="lazy"/><br/>ONES Project 工作项级联属性</p><p><strong>2.2 公式计算属性</strong></p><p>项目管理中常需实时计算工时、进度或质量等关键指标。<strong>公式计算属性支持用户根据业务需求编写公式，结果自动计算并展示，无需手动统计</strong>。</p><p>它具备<strong>多层函数嵌套与类型识别能力</strong>，可轻松实现进度汇算、成本核算、质量评分等业务逻辑，让关键指标在工作项中实时呈现，从而提升分析的及时性与准确性。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047390248" alt="图片" title="图片" loading="lazy"/><br/>ONES Project 公式计算属性配置</p><p><strong>2.3 标签属性</strong></p><p>在团队协作中，不同角色有不同的任务关系视角与习惯。标签属性支持每位成员自由为工作项添加标签，以标记优先级、风险、阶段或进行自定义分类。</p><p>无论是产品侧、研发侧还是项目管理者，都能通过标签快速筛选、分组并追踪进展，从而实现更灵活、更自主、也更贴合习惯的信息管理。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047390249" alt="图片" title="图片" loading="lazy"/><br/>在 ONES Project 工作项添加标签<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047390250" alt="图片" title="图片" loading="lazy"/><br/>在 ONES Project 工作项新建标签</p><p><strong>2.4 链接属性</strong></p><p>在项目执行过程中，成员常需查阅设计稿、需求文档等外部资料。链接属性支持在工作项中直接配置外部链接，实现一键跳转访问，让协作路径更短，上下文切换更顺畅。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047390251" alt="图片" title="图片" loading="lazy"/><br/>ONES Project 工作项链接属性</p><h4>3.富文本编辑器升级为 ONES Wiki 编辑器，提供更丰富的编辑能力</h4><p>为了让信息记录和协作更高效，ONES Project 将工作项内所有富文本属性的编辑器（如描述、评论等）升级为 ONES Wiki 编辑器，用户可以在工作项中插入表格、流程图、思维导图等，并支持多人实时协同编辑。</p><p>此外，ONES Project 还支持为工作项配置多个富文本字段，如「需求文档」、「价值分析」、「验收标准」等，从而构建出结构清晰、信息完整的内容体系，满足复杂的业务记录需求。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047390252" alt="图片" title="图片" loading="lazy"/><br/>ONES Project 工作项描述升级为 ONES Wiki 编辑器</p><h3>功能 3：ONES Project 工作项支持配置层级结构</h3><p>需求的落地通常伴随着从「客户视角」到「产品视角」，再到「研发视角」的转变。为了让各职能成员清晰地协同工作，并为需求本身提供可追溯的依据，往往需要将需求进行精细化管理。</p><p>ONES Project 支持搭建工作项层级结构，提供可视化的层级配置能力，团队可根据业务情况，自定义不同的层级结构与业务链路，实现需求的逐层拆解与结构化管理，显著提升跨角色协同效率，并增强需求管理过程的清晰度和可追溯性。</p><h4>应用场景：</h4><h4>1.自定义工作项层级结构，还原企业需求分层模型</h4><p>由于行业和管理方法各不相同，不同企业在需求分层模型上也存在显著差异。ONES Project 层级结构功能支持企业根据自身业务流程，灵活定义并搭建工作项类型之间的层级结构，还原企业的需求分层模型。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047390253" alt="图片" title="图片" loading="lazy"/><br/>ONES Project 工作项新建层级结构<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047390254" alt="图片" title="图片" loading="lazy"/><br/>通过 ONES Project 工作项层级实现需求分层模型</p><h4>2.视图支持引用层级结构，以树状结构呈现工作项</h4><p>在引用层级结构后，工作项列表等视图即可按父子关系，以树状结构清晰展示从顶层需求到各级任务的分解层次。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047390255" alt="图片" title="图片" loading="lazy"/><br/>在 ONES Project 视图设置按层级结构呈现工作项<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047390256" alt="图片" title="图片" loading="lazy"/><br/>ONES Project 设置工作项展示层级</p><h4>3.支持按层级结构汇总数据</h4><p>支持自动汇总子层级工作项的进度与工时数据，真实、实时地呈现项目整体推进情况，避免人工统计的误差，节省不必要的工作量，为管理者快速决策与资源调配提供可靠依据。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047390257" alt="图片" title="图片" loading="lazy"/><br/>ONES Project 设置按层级结构汇总数据</p><h4>4.支持父子层级工作项属性联动</h4><p>支持上下级工作项间自动触发条件校验与流程分支，例如：当所有子任务完成后，父任务的状态可自动更新为「可验收」，实现流程的自动化推进。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047390258" alt="图片" title="图片" loading="lazy"/><br/>ONES Project 设置按层级结构触发条件校验</p><h3>功能 4：ONES Project 工作项筛选器支持 ONESQL</h3><p>在多样化的业务场景下，用户需要更强大、灵活的筛选能力，以实现精准的工作项筛选与数据分析。</p><p>ONES Project 工作项筛选器通过引入 ONESQL，提供了类 SQL 语法的高级筛选能力。支持自由组合属性、运算符、值与函数，精准构建复杂逻辑条件，提升数据分析与管理效率。</p><p>对于来自 Jira 等平台的用户，其原有的高级查询语法（如 JQL）也可无缝衔接至 ONESQL，实现筛选逻辑的平滑迁移。</p><h4>应用场景：</h4><h4>支持复杂逻辑筛选的快速实现</h4><p>在项目管理中，当需要同时筛选多个条件组合时，可以直接使用 ONESQL 一次性构建复杂查询，以替代多个嵌套筛选器。比如，多层嵌套 AND / OR / NOT、时间偏移、成员函数过滤等。</p><p>此外，通过使用封装好的时间函数、部门函数、角色函数以及用户组函数，用户能够快速构建符合业务视角的筛选器，灵活调用平台数据。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047390259" alt="图片" title="图片" loading="lazy"/><br/>ONES Project 工作项筛选器支持 ONESQL</p><p>本次升级进一步强化了 ONES 在复杂业务场景下的流程适配与信息管理能力，助力中大型企业构建更契合自身业务流程的管理体系，在复杂协作中持续提升执行力与管理深度。</p>]]></description></item><item>    <title><![CDATA[广告平台在 AI 时代如何选择 GPU ]]></title>    <link>https://segmentfault.com/a/1190000047389734</link>    <guid>https://segmentfault.com/a/1190000047389734</guid>    <pubDate>2025-11-11 18:22:16</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在当今注意力稀缺的大环境下，广告不再只是把横幅丢上线、希望用户点点击那样简单。广告平台需要更快速、低成本、批量化地生产更多的广告，并需要合理地调度广告投放资源、精准识别目标用户。此时，AI 成为广告新前线，为用户获取（User Acquisition）、广告调度（Mediation）平台和广告网络（Ad Network）提供完整工具集，让项目能精准触达全球用户。</p><p>平台如 Unity Ads、AppLovin、ironSource 等均已在其广告技术栈中整合 AI 技术：基于实时行为数据做智能定向、深度学习生成广告创意、做预测竞价 (bidding)。</p><p>如果你是广告平台或广告代理方，或者你正在开发 AI 广告业务。那么你会发现：这些“下一个阶段”的能力，正在对算力提出新的、更高要求。</p><h2>广告 AI 的算力痛点</h2><p>AI 与机器学习是现代数字广告的核心，GPU 加速在其落地中扮演关键角色：</p><ul><li>预测分析：GPU 使实时预测分析成为可能，帮助广告主预判用户行为并相应优化营销活动。</li><li>自然语言处理（NLP）：从聊天机器人到情感分析，GPU 加速 NLP 任务，提升客户互动与广告定向。</li><li>图像与视频识别：GPU 驱动的高级算法可分析视觉内容，实现视频中的自动广告位投放等功能。</li></ul><p>简单来说，这些能力背后的关键瓶颈就是「大规模 AI 模型推理／实时响应」——而这正是 GPU 擅长的：并行处理、大批量吞吐、低延迟推理。对此，传统只依赖 CPU 的广告系统正逐步显露劣势。</p><h3>为什么「只是上云」还不够？</h3><p>许多广告平台本身选择云厂商托管 CPU 或 GPU 实例，但当广告投放量激增、模型同步更新频繁时，会遇以下痛点：</p><ul><li>规模：广告投放高峰时段需要几十、几百台 GPU 实例，那么就需要可灵活扩展的按需实例；</li><li>成本：广告平台本身毛利薄，若基础算力成本高，就会削减广告主预算，影响整体竞争力。</li><li>流量：像 ADX 广告平台这样的业务，通常会有较高的流量需求，如果一个平台的流量计费规则复杂且昂贵，那么会极大影响广告平台的预算控制与利润。</li><li>管理复杂度：广告系统需要快速上线、快速迭代，而复杂的 GPU 基础设施管理（驱动、网络、存储、并行通信等）往往耗时，尤其像 AWS、GCP、阿里云这样学习成本高的云平台。</li></ul><p>因此，一个专为 AI 广告场景设计、具备弹性、成本可控的 GPU 云平台，就成了广告客户／广告平台抢占先机的关键。</p><h2>DigitalOcean GPU Droplet：广告平台可选的理想方案</h2><p>在众多 GPU 云选项中，DigitalOcean 云平台的 “GPU Droplets”产品因其定位于开发者友好、结构简单、成本透明，在广告科技（AdTech）场景中具有鲜明优势。有曾经使用一线云平台的企业，在迁移至 DigitalOcean 后成本降低了 30%-50%。</p><p>为什么 DigitalOcean 更适合广告平台，尤其是正在探索 AI + 广告模式的企业呢？</p><p>DigitalOcean 的 GPU Droplets （属于 “DigitalOcean Gradient™ AI GPU Droplets” 系列）是 VM 形式的 GPU 虚拟机，提供 1 到 8 颗 GPU 的配置（如 8 卡 H100 或单卡 H100 机型），同时预装深度学习软件栈（PyTorch、TensorFlow、JAX、Hugging Face 模型等） 。不仅后台操作简单，而且支持一键部署 DeepSeek、Qwen、Llama 等开源大模型。</p><p>其产品特点还包括：</p><ul><li>​<strong>简易部署</strong>​：几乎几分钟内即可从零配置启动 GPU 实例，而且后台简单易用，几乎没有学习成本。</li><li>​<strong>成本透明</strong>​：清晰列出每 GPU／小时计费，并表明比大型超云厂商便宜可达「高达 75%」之多。</li><li><strong>​流量便宜：​</strong>按需实例中包含免费出站流量，如超出额度，所有区域的出站流量均按照 0.01 美元/GB 计算，一些大流量客户使用后反映“相比使用 AWS ，DigitalOcean 能帮他们节省 60% 的成本”。</li><li>​<strong>应用广泛</strong>​：适用于 AI 训练、推理、HPC （高性能计算）、广告／媒体／创意工作流。</li><li><strong>​GPU​型号多：</strong>除了 H200、H100、MI325X、MI300X 等旗舰 GPU，还可提供 A100、RTX 6000 Ada、 RTX 4000 Ada、L40S 等一系列高性价比的 GPU 服务器。</li></ul><p>这些特性，都适合希望快速上线，并有大流量业务的广告平台，以及采用 AI 技术的广告平台。</p><h2>为什么选择 DigitalOcean 而不是传统超大云平台？</h2><p><strong>1、弹性配置、按需扩展</strong></p><p>广告平台在投放高峰（如新品上线、节假日营销、重大活动）时，可能需要迅速扩展 GPU 资源。GPU Droplet 支持 1 至 8 颗 GPU 配置，提供按需实例，方便按需调整。</p><p>例如你主要做推理型广告优化、实时创意生成，或许一个 单 GPU 节点即可；但若为大型游戏广告平台，并且在多个地域同时上线，你也可选择 8 GPU 配置。</p><p><strong>2、成本优势与可控性</strong></p><p>例如，最新 AMD MI325X（8 卡） GPU Droplet 在 DigitalOcean 的标价为 <strong>1.69 美元／GPU／小时</strong> （按需实例）。在某些配置下与大型云平台相比可节省高达 75%。适合推理的 RTX 4000 Ada GPU 在 DigitalOcean 上的价格仅需 ​<strong>0.76 美元/GPU/小时</strong>​。 广告平台往往按千次／百万次计费，若算力成本可控，就能将更多预算回归广告主或创意环节，从而提升整体营销效率。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389736" alt="" title=""/></p><p><strong>3、出站流量成本低</strong></p><p>对于很多广告平台来讲，在使用大多数云平台的时候，最大的成本压力是来自于流量费用。一些大型云平台，比如 AWS、GCP、阿里云，他们的出站流量费用是按照区域来计算的，不同区域价格不同。然而 DigitalOcean 的出站流量费用是所有区域都按照 0.01 美元/GB 来计算的，不仅计算规则简单，而且成本是大型云平台的十分之一。</p><p>对广告平台来说，这意味着：若用单 GPU 节点做广告创意生成 ＋ 竞价推理，每小时成本低至几十美元（以 &amp;dollar;0.76 起价为例）。如果按日、按月高峰弹性使用，也可控制成本。</p><p><strong>4、生态整合与后续发展</strong></p><p>DigitalOcean 虽然地域覆盖不如某些“全球顶级”云那样广泛，但其生态对于初期／中期广告投放平台非常够用。且随着广告平台规模增长，方案也可以逐步扩展。</p><p>同时，DigitalOcean 与 AMD 合作推进 MI300X GPU 提供低价大规模计算资源。而且，DigitalOcean 在今年 Q4 与 2026 年年初还将陆续推出更多型号的 GPU Droplet。</p><p><strong>5、管理复杂度更低</strong></p><p>很多大型云服务商提供 GPU 实例，但其配置往往较为复杂：你可能需要自己安装驱动、调优网络、配置 Kubernetes 节点、处理 IAM/Security 策略。而 DigitalOcean 强调“零复杂、GPU 几分钟上线”。</p><p>对于广告技术团队（尤其是以 DevOps / MLOps 为辅，而不是基础设施专家的团队）而言，DigitalOcean 上手门槛低、部署快的优势非常明显。</p><p><strong>6、本地技术支持</strong></p><p>很多广告平台的业务往往是全球性的。DigitalOcean 通过中国区独家战略合作伙伴卓普云 aidroplet.com，为中国出海企业提供本地化的商业合作咨询与技术支持服务。</p><h2>如何在广告系统中运用 DigitalOcean GPU Droplet</h2><p>下面我们分方面从广告平台视角出发，说明如何选型、部署并优化 GPU Droplet，助力广告技术堆栈。</p><h3>常见广告算力任务</h3><p><strong>创意动态生成</strong> 通过结合用户数据（地域、设备、行为）与广告位 format，系统可自动生成或改版 Ad Creative。 该流程通常包括素材加载、生成模型（如 Gen AI 模型）推理输出以及最终渲染阶段，对 GPU 推理、显存、I/O 性能及缓存策略都有较高要求。</p><p><strong>实时竞价 ​RTB</strong>​<strong>​ （Real-Time</strong>​<strong>​ Bidding）</strong> 当用户访问 Ad Exchange 时，广告系统需在几十至上百 毫秒内完成： 用户画像输入 → 模型推理 → 出价决策 → 返回响应。 高并发环境下，系统需在 30–100 ms 内完成端到端响应，对 GPU 吞吐和网络延迟极为敏感。</p><p><strong>欺诈与异常检测</strong> 包括低质量点击／安装识别、设备串号检测、机器人行为判断等。 此类任务往往是持续流式分析 ＋ 即时响应的结合，对并行推理、吞吐和稳定性有较高要求。</p><p><strong>全球覆盖与地域分布</strong> 广告用户往往遍布全球。若推理或竞价节点距离用户或 Ad Exchange 较远，将显著增加网络延迟、影响出价时效。因此，广告系统需要在多个地域部署近源 GPU 节点。</p><h3>GPU 配置选型建议</h3><table><thead><tr><th>场景</th><th>推荐类型</th><th>特点</th><th>参考价格 (USD/GPU/小时) [¹]</th></tr></thead><tbody><tr><td>单地域创意生成／中等请求量</td><td>RTX 4000 Ada 或 L40S</td><td>成本最低、能耗低、部署快</td><td>约 &amp;dollar;0.76 起</td></tr><tr><td>多地域／多账户／高并发 RTB</td><td>8 GPU 节点或 集群方案</td><td>高吞吐、高并发支持</td><td>约 &amp;dollar;1.57 起</td></tr><tr><td>同时包含模型训练与推理</td><td>MI300X、H200/H100 系列</td><td>高显存、高带宽</td><td>MI300X 约 &amp;dollar;1.49 起</td></tr></tbody></table><p>在训练广告画像模型、LTV 预测模型等场景中，推荐使用 MI300X 或 H200/H100 以获取更高显存带宽。训练任务可结合 Spot 或 预约实例降低成本。</p><h3>技术集成建议</h3><ul><li><strong>容器化部署</strong> 使用 Docker 或 Kubernetes 容器化广告模型与创意生成模块，方便横向扩展。DigitalOcean Kubernetes （DOKS）支持 GPU 节点。 [⁶]</li><li><strong>资源监控</strong> 启用 NVIDIA DCGM (Data Center GPU Manager) 监控 GPU 健康、温度、利用率与错误率，以确保推理稳定性。 [⁴]</li><li><strong>自动伸缩机制</strong> 可结合 DigitalOcean API 或 Terraform 在高峰时自动扩展节点，低峰自动缩减，节省费用。</li><li><strong>地域冗余与容灾</strong> 关键 RTB 或 推理节点建议跨地域部署，避免单区网络／算力故障影响广告服务稳定性。</li></ul><h2>写在最后</h2><p>在广告科技的竞争赛道中，AI 已成为制胜关键，而 GPU 则是支撑这一切的核心引擎。广告平台若要在实时竞价、创意生成与智能定向上保持领先，就需要兼顾性能、成本与部署效率。DigitalOcean 通过其 GPU Droplet 产品，让广告团队能够以更低成本、更快速度构建 AI 驱动的广告系统。无论是初创的广告优化团队，还是全球化的 Ad Network，都能在这一平台上实现灵活扩展与高效运行。 <strong>未来的广告，不只是创意之争，更是算力</strong>​<strong>与智能的竞赛。选择合适的 GPU 云平台，正是赢得这场竞赛的起点。如果你需要了解 DigitalOcean GPU 与 AI 解决方案细节，可咨询 DigitalOcean 中国区独家战略合作伙伴卓普云 aidroplet.com。</strong></p>]]></description></item><item>    <title><![CDATA[助力企业构建 AI 原生应用，函数计算F]]></title>    <link>https://segmentfault.com/a/1190000047389743</link>    <guid>https://segmentfault.com/a/1190000047389743</guid>    <pubDate>2025-11-11 18:21:16</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389745" alt="" title=""/></p><p><em>本文整理自 2025 云栖大会，阿里云智能集团产品专家，刘宇演讲议题《函数计算发布 FunctionAl:serverless Al 原生应用基础设施》</em></p><p>在 AI 技术应用落地进程中，目前面临着五大核心挑战：开发/学习门槛过高，部署运维阶段复杂，AI 应用安全备受挑战，生态能力方面存在严重的割裂与锁定现象，同时资源成本高昂且利用率低下。这些挑战极大地阻碍了 AI 技术的广泛普及以及应用效率的有效提升。</p><p>阿里云函数计算（FC）依托 Serverless AI 基础设施与全栈能力的创新突破，推出 Function AI（函数智能），精准攻克上述痛点问题，全面推动 AI 应用在开发至运维的全流程中实现降本增效。以下将从四个关键维度，详细阐述阿里云函数计算（FC）的核心解决方案。</p><h2>一、函数计算 FC：Serverless 形态的 AI 基础设施</h2><p>阿里云函数计算（FC）全新推出 <strong>Serverless AI 基础设施</strong>，以“高可用、低成本、零/低运维”为核心，为企业提供从模型部署到 Agent 开发的全栈解决方案。该平台通过 Serverless 架构的弹性特性与智能化资源管理，显著降低 AI 应用的开发复杂度与资源成本，助力企业快速实现 AI 落地。</p><ol><li><strong>开发效率提升</strong>：无需关注底层资源，开发者可专注于业务逻辑，模型一键转换为 Serverless API。</li><li><strong>弹性资源调度</strong>：按需付费 + N 分之一卡资源分配（如 1/16 卡），GPU 部署成本降低 90% 以上。</li><li><strong>免运维特性</strong>：实例闲置时自动缩容至 0，资源利用率优化 60%，实现业务运维转型。</li></ol><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389746" alt="" title="" loading="lazy"/></p><h2>二、核心能力发布：AgentRun 与模型服务、文生图服务</h2><p>阿里云函数计算全新发布 FunctionAI，基于 Serverless 架构的企业级 AI 应用基础设施平台，实现从模型托管到 Agent 开发的全流程覆盖，显著降低技术门槛并提升跨平台适配性。</p><h3>AgentRun 全流程解决方案：</h3><p>Agent Run 通过高代码与低代码结合，提升 AI 开发效率，支持主流开发生态。在部署阶段，提供轻量、灵活、安全隔离的 AI 运行时，支持多种模型和工具运行时，确保应用安全与扩展性。运维方面，Agent Run 具备全链路监控能力，免资源运维，实现业务运维转型。八大组件共同构建，助力开发者轻松构建企业级 AI 应用。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389747" alt="" title="" loading="lazy"/></p><ol><li><strong>全生命周期能力</strong></li></ol><ul><li><strong>开发阶段</strong>：高代码 + 低代码模式，兼容阿里云百炼、CloudFlow、Dify 等生态，开发者可自由选择框架；</li><li><strong>部署阶段</strong>：轻量、灵活、安全隔离的运行时，支持大模型/垂类模型调用，提供安全沙箱隔离机制与 MCP/Function Call 协议双保障；</li><li><strong>运维阶段</strong>：全链路监控 + 端到端可观测性，定位问题并提供优化建议，实现免资源运维。</li></ul><ol start="2"><li><strong>技术架构优势</strong></li></ol><ul><li><strong>百万级并发</strong>：基于 Session 亲和与多语言引擎，提供企业级沙箱服务能力；</li><li><strong>毫秒级弹性</strong>：内存快照技术实现 CPU 毫秒启动、GPU 秒级响应；</li><li><strong>成本降低 60%</strong>：支持 GPU/CPU/内存解耦配置（最小 0.25 CPU），实例闲置时自动缩容至 0，按需付费。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389748" alt="" title="" loading="lazy"/></p><h4>大语言模型代理机制</h4><p><strong>多模型统一接入</strong></p><ul><li>支持 Cloud、GPT、通义千问等 20 家主流大模型，实现开源模型一键部署；</li><li>通过统一规范管理所有模型，解决 First Token 延迟与负载均衡问题。</li></ul><p><strong>动态模型治理</strong></p><ul><li><strong>自动切换机制</strong>：当主模型 First Token 时间过长或负载过高时，快速启用备用模型；</li><li><strong>并行处理能力</strong>：多模型并行执行，首个返回结果的模型优先作为主模型。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389749" alt="" title="" loading="lazy"/></p><h4>工具生态联动</h4><ol><li><strong>统一工具接口</strong></li></ol><ul><li>兼容 MCP/Function Call 协议，适配主流工具与第三方服务，API 集成时间从天级降至分钟级。</li></ul><ol start="2"><li><strong>智能工具管理</strong></li></ol><ul><li><strong>Tool Hub 插件市场</strong>：海量插件一键部署，快速构建业务场景；</li><li><strong>智能路由优化</strong>：通过语义分析前置筛选工具，降低调用时间（从 60 秒降至秒级）与 Token 消耗。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389750" alt="" title="" loading="lazy"/></p><h3>模型服务：AI 模型一键转化为 Serverless API</h3><p>阿里云函数计算推出的<strong>模型服务</strong>，以 Serverless 架构为核心，通过生态兼容性、技术能力与成本优化三位一体，为企业提供从模型部署到服务调用的全链路解决方案。该服务显著降低 AI 应用开发门槛，同时保障高可用性与资源高效利用，助力企业快速构建生产级模型服务。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389751" alt="" title="" loading="lazy"/></p><ul><li><p><strong>生态兼容性</strong></p><ul><li>覆盖大语言模型与垂类模型，兼容 ModelScope、HuggingFace 等主流平台；</li><li>支持 vLLM、SGLang、Ollama、Transformer 等技术架构的一键部署。</li></ul></li><li><p><strong>技术能力</strong></p><ul><li>提供 100+ 模型在线体验，200+ 模型一键部署；</li><li>六大框架一键托管，与 Agent 服务无缝集成；</li><li>DevPod 在线环境支持代码调试与镜像自动构建，无需掌握 Dockerfile。</li></ul></li><li><p><strong>成本优化</strong></p><ul><li>Serverless GPU 技术结合按量付费模式，N 分之一卡资源分配（如 1/16 卡）；</li><li>部署成本降低 90% 以上，资源闲置时不计费，支持百万级并发与毫秒级弹性；</li><li>与 ComfyUI、Dify 等生态实现一键联动，消除资源预置顾虑。</li></ul></li></ul><h3>文生图/声音/视频：多模态AI创作平台</h3><p><strong>多模态AI创作平台</strong>以“零门槛生成”为核心，通过全链路工具与生态联动，覆盖电商设计、游戏渲染、营销物料、教育培训等全行业场景。平台提供开箱即用的文生图/视频/声音能力，结合高性价比算力与自动化资源管理，显著降低创作门槛与成本。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389752" alt="" title="" loading="lazy"/></p><ol><li><strong>文生图与文生视频</strong></li></ol><ul><li>集成 ComfyUI 与 Stable Diffusion 工具，解决本地部署复杂度与显存资源限制；</li><li>支持全场景内容生成，从设计到渲染实现端到端自动化。</li></ul><ol start="2"><li><strong>Lora 模型训练</strong></li></ol><ul><li>提供 Muse Lora 等专业训练器，覆盖数据标注到模型训练的全流程；</li><li>适配垂类场景需求，快速生成定制化模型。</li></ul><ol start="3"><li><strong>企业级 Serverless API 调用</strong></li></ol><ul><li>一键部署 Stable Diffusion、ComfyUI 等模型，自动转换为 Serverless API；</li><li>高性价比 GPU 弹性算力 + 自动扩容，支持同步/异步灵活切换。</li></ul><h2>三、Agent 最佳全栈实践：Function Q，你的云上助理</h2><p>Function Q 是专业的函数计算智能助手，集成了基于大模型的代码自动生成、智能运维诊断和系统架构设计三大核心能力，显著提升 Serverless 应用的开发效率。整体技术栈基于函数计算 FC、API 网关、RocketMQ、SLS 等阿里云成熟基础服务构建，遵循云原生设计原则，提供企业级的高可用性、安全性和可观测性保障。 </p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389753" alt="" title="" loading="lazy"/></p><ol><li><strong>智能开发助手</strong></li></ol><ul><li><strong>意图驱动部署</strong>：用户通过自然语言描述需求（如“获取本地天气”），Function Q 自动生成代码并部署至函数计算，提供按量付费的 API 接口；</li><li><strong>示例场景</strong>：输入“获取本地 IP”，Function Q 自动查询 API 并生成可调用服务，无需手动编写 Dockerfile 或配置资源。</li></ul><ol start="2"><li><strong>运维诊断专家</strong></li></ol><ul><li><strong>问题自动分析</strong>：针对资源费用异常、函数运行错误等问题，调用 MCP 工具链定位根源并提供解决方案；</li><li><strong>实时监控支持</strong>：支持全链路可观测性，缩短故障排查周期，提升运维效率。</li></ul><ol start="3"><li><strong>架构设计顾问</strong></li></ol><ul><li><strong>业务迁移指导</strong>：通过业务描述分析，推荐切分方法或整体打包策略，适配函数计算架构需求；</li><li><strong>场景覆盖</strong>：解决开发者对 Serverless 架构迁移路径的困惑，实现零门槛上云。</li></ul><h2>四、拥抱开源，与开源共成长</h2><p>阿里云函数计算将坚定拥抱开源、与开源共成长。AI 并非单纯商业化产品，而是开放共赢的技术生态平台。当下，我们已与 Agentscope、LangChain、dify 等平台开展开源托管及代码集成工作。</p><p>未来，还有两大关键动作：一是开源 AgentRun SDK，助力快速集成上层开源框架；二是推出 model plugin，让所有垂类模型可像插件般，快速接入 dify、N8N、Stable Diffusion\ComfyUI 等现有生态。我们期望借此不仅拥抱开源，更能反哺开源，携手共进。</p>]]></description></item><item>    <title><![CDATA[隐语社区可信数据空间MOOC第15讲笔记]]></title>    <link>https://segmentfault.com/a/1190000047389774</link>    <guid>https://segmentfault.com/a/1190000047389774</guid>    <pubDate>2025-11-11 18:20:17</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img width="723" height="420" referrerpolicy="no-referrer" src="/img/bVdm0ph" alt="" title=""/></p><h2>2.9 基于通用硬件构建GPU-TEE底座 学习笔记</h2><h3>一、为什么需要机密计算？</h3><h4>1. 背景驱动</h4><ul><li><strong>数据成为生产要素</strong>：2025年中国数据要素市场规模预计达1749亿元</li><li><p><strong>传统数据中心安全挑战</strong>：</p><ul><li>运维者权限过高，可任意访问用户数据</li><li>CrowdStrike事件（2024.7）：内存越界访问引发全球宕机</li><li>Triton恶意工具攻击（2017）：从内存提取凭证</li></ul></li></ul><h4>2. 机密计算的价值</h4><ul><li><strong>TEE核心能力</strong>：数据“可用而不可见”</li><li><p><strong>三大优势</strong>：</p><ul><li><strong>数据加密</strong>：代码量小、漏洞少，REE无法读写TEE敏感数据</li><li><strong>可验证</strong>：硬件信任根提供远程证明</li><li><strong>性能好</strong>：TEE内部明文计算，性能接近未保护场景</li></ul></li></ul><h4>3. GPU-TEE应用场景</h4><ul><li><p><strong>大模型推理数据保护</strong>：</p><ul><li>保护模型文件、语料库（提供商）</li><li>保护提示词、推理结果（用户）</li></ul></li></ul><h4>4. GPU-TEE现状</h4><ul><li><strong>缺乏通用性</strong>：仅NVIDIA Hopper/Blackwell成熟商用</li><li><strong>供应链风险</strong>：依赖特定硬件</li><li><strong>国内起步</strong>：生态支持有限</li></ul><hr/><h3>二、HyperGPU设计</h3><h4>1. 设计目标</h4><ul><li><strong>通用性</strong>：不依赖新硬件特性</li><li><strong>易用性</strong>：只修改系统层软件</li><li><strong>普惠性</strong>：低成本升级密态算力</li><li><strong>可解耦</strong>：支持通用平台，信任根可解耦</li></ul><h4>2. 架构抽象</h4><ul><li><strong>三种抽象</strong>：Enclave、CVM、GPU-TEE</li><li><p><strong>设计哲学</strong>：</p><ul><li>Hypervisor运行在最高特权级，仅管理安全资源</li><li>原有OS提供原生服务，攻击面小</li></ul></li></ul><h4>3. 威胁模型</h4><ul><li><p><strong>防御对象</strong>：</p><ul><li>高特权级软件攻击</li><li>系统管理员越权</li><li>恶意CVM合谋</li><li>DMA攻击</li></ul></li><li><strong>不防御</strong>：硬件攻击、侧信道、DoS</li></ul><h4>4. 关键技术方案</h4><h5>（1）安全边界选择：CVM抽象</h5><ul><li><strong>优势</strong>：无需修改应用，与GPU交互简单</li><li><strong>对比</strong>：Process-based Enclave需要侵入式改造</li></ul><h5>（2）KVM虚拟化方案</h5><ul><li><strong>挑战</strong>：HyperEnclave占用VM-ROOT特权级</li><li><p><strong>解决方案</strong>：基于软件的Enlightened VMCS</p><ul><li>共享内存同步CPU状态</li><li>适用于AMD/ARM平台</li><li>减少特权级切换</li></ul></li></ul><h5>（3）CPU状态隔离</h5><ul><li><strong>思路</strong>：HyperEnclave管理所有虚拟机寄存器</li><li><strong>实现</strong>：Context切换时保存恢复</li></ul><h5>（4）内存隔离</h5><ul><li><strong>思路</strong>：HyperEnclave管理所有页表</li><li><strong>控制</strong>：REE需请求HyperEnclave设置CVM页表</li></ul><h5>（5）GPU-TEE扩展</h5><ul><li><strong>控制面保护</strong>：页表与Port I/O管控</li><li><strong>数据面保护</strong>：IOMMU管理，正确设置设备页表</li></ul><hr/><h3>三、实现与性能</h3><h4>1. 代码实现</h4><ul><li><strong>L0 HyperEnclave</strong>：~13k LoC</li><li><strong>L1 KVM</strong>：~2.7k LoC（Linux内核）</li><li><strong>L2 CVM-Linux</strong>：~1.3k LoC</li></ul><h4>2. 性能测试</h4><ul><li><strong>CPU性能</strong>：微基准测试开销较大，应用级性能损失不明显（+0.27%~1.9%）</li><li><strong>GPU推理</strong>：大模型推理性能损失极小（-1.64%~-0.66%）</li></ul><hr/><h3>四、展望与规划</h3><h4>1. 通用性提升</h4><ul><li><strong>动态内存管理</strong>：按需申请安全内存</li><li><strong>资源利用率</strong>：CVM负载低时可调度普通VM</li></ul><h4>2. 安全增强</h4><ul><li><strong>链路加密</strong>：PCI-e/NV-Link数据加密与完整性保护</li><li><strong>防嗅探</strong>：防止总线窃听</li></ul><h4>3. 生态建设</h4><ul><li><strong>多平台支持</strong>：ARM平台、代码组件化</li><li><strong>多云支持</strong>：与OS厂商合作（麒麟、OpenAnolis等）</li></ul><h4>4. 开源规划</h4><ul><li><strong>预计2025 S2开源</strong></li><li><strong>GitHub地址</strong>：<a href="https://link.segmentfault.com/?enc=O3d3NauQxEPDFHoVieNUiQ%3D%3D.M42rr4iiYzu5B33lPoQJ9Fd9%2FI1KPv3MiAtLredsiJcMUF13X4%2FcyCoyLUOLcnz2" rel="nofollow" target="_blank">https://github.com/asterinas/hyperenclave</a></li></ul><hr/><h3>五、总结</h3><p>HyperGPU通过：</p><ul><li><strong>通用硬件</strong>构建TEE能力</li><li><strong>CVM抽象</strong>实现应用透明</li><li><strong>软件定义安全</strong>减少硬件依赖</li><li><strong>最小性能损失</strong>（~1%）提供密态算力</li></ul><p>为国内GPU机密计算提供了可行的技术路径。</p>]]></description></item><item>    <title><![CDATA[Python梯度提升树、XGBoost、]]></title>    <link>https://segmentfault.com/a/1190000047389794</link>    <guid>https://segmentfault.com/a/1190000047389794</guid>    <pubDate>2025-11-11 18:19:26</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>全文链接：<a href="https://link.segmentfault.com/?enc=W1s%2FnYttWW7n0hEurQvJhw%3D%3D.4FIP9o2QrBuM53vUB8W8Z%2FgISZAHt%2BTAjJjWk0btMdI%3D" rel="nofollow" title="https://tecdat.cn/?p=44265" target="_blank">https://tecdat.cn/?p=44265</a>  <br/>原文出处：拓端数据部落公众号  <br/>分析师：Liu Qing</p><h3><a name="t1" target="_blank"/><img referrerpolicy="no-referrer" src="/img/remote/1460000047389796" alt="封面" title="封面"/></h3><h4><a name="t2" target="_blank"/>引言</h4><p>在创新驱动发展战略深入推进的当下，企业研发投入成为经济高质量发展的核心动力，而研发费用加计扣除、高新技术企业税收优惠等政策，既激发了企业创新活力，也催生了部分企业的研发操纵行为。这类通过虚增研发支出、调整会计处理方式套取政策红利的行为，不仅导致创新资源错配，还破坏了市场公平竞争秩序。传统研究多依赖线性回归方法，难以捕捉研发操纵影响因素的非线性关系与交互效应，预测精度和可解释性不足。  <br/>本文改编自我们为某监管机构提供的上市公司研发行为监测咨询项目，核心是通过机器学习技术破解研发操纵识别难题。项目团队整合2012-2023年中国A股上市公司数据，从CEO个人特质、公司财务特征、公司治理特征三个维度构建预测体系，运用多种机器学习算法实现研发操纵行为的精准识别与影响因素量化。  <br/><strong>本文内容源自过往项目技术沉淀与已通过实际业务校验，该项目完整代码与数据已分享至交流社群。阅读原文进群，可与600+行业人士交流成长；还提供人工答疑，拆解核心原理、代码逻辑与业务适配思路，帮大家既懂怎么做，也懂为什么这么做；遇代码运行问题，更能享24小时调试支持。</strong>  <br/>我们深知在使用科研代码时的痛点：代码能运行却怕查重、遇异常难以调试。为此，我们提供24小时响应的“代码运行异常”应急修复服务，比自行调试效率提升40%；所有内容人工创作比例超90%，从根源规避查重风险与逻辑漏洞，真正实现“买代码不如买明白”。本文将以通俗的语言、清晰的逻辑，带大家从数据准备到结论输出，完整掌握研发操纵预测的核心方法与业务逻辑。</p><h3><a name="t4" target="_blank"/>数据与研究设计</h3><h4><a name="t5" target="_blank"/>数据来源与处理</h4><p>研究选取2012-2023年中国A股上市公司为研究对象，剔除特殊处理企业与金融类企业后，从国泰安数据库获取CEO个人特质、公司财务与治理数据、研发相关数据。为保证数据质量，对连续变量进行1%和99%分位的缩尾处理，数值型缺失值用均值填充，虚拟变量缺失值用众数填充。</p><h4><a name="t6" target="_blank"/>变量定义</h4><ul><li>被解释变量：研发操纵（RDM、RDM1），以高新技术企业研发投入门槛为基准，分别以超过门槛0.5%、1%作为操纵行为判定标准。</li><li>解释变量：分为三类，包括CEO性别、年龄、研发背景等个人特质，资产负债率、存货周转率等财务特征，以及独立董事比例、机构持股比例等公司治理特征。</li></ul><h4><a name="t7" target="_blank"/>描述性统计结果</h4><p>通过对核心变量的描述性统计可以看出样本数据的基本特征：CEO群体中男性占比93%，性别失衡明显；仅30%的CEO具有研发背景，金融背景和学术背景占比更低；资产规模差异较大，资产负债率均值为40%；以0.5%门槛衡量的研发操纵行为发生率为10%，门槛提升至1%后发生率升至19%。<img referrerpolicy="no-referrer" src="/img/remote/1460000047389797" alt="" title="" loading="lazy"/></p><h4><a name="t8" target="_blank"/>核心代码（数据处理与变量划分）</h4><pre><code>import pandas as pdimport numpy as np# 载入数据并指定编码格式# 定义核心变量列表core_vars = [ 'CEOSEX','CEOAGE','CEOSTOCK','CEOOVERSEA','CEOFIN','CEOTECH','CEOACA', 'Asset','DAR','ITO','RGR','ROA', 'Nshrsms','Outratio','INSTO','Dual', 'RDM','RDM1']# 描述性统计分析（保留关键统计量）desc_stats = data[core_vars].describe(percentiles=[.25, .5, .75]).Tprint(desc_stats.round(3))# 变量分类划分ceo_features = ['CEOSEX','CEOAGE','CEOSTOCK','CEOOVERSEA','CEOFIN','CEOTECH','CEOACA']finance_features = ['Asset','DAR','ITO','RGR','ROA']governance_features = ['Nshrsms','Outratio','INSTO','Dual']# 整合所有特征与指定因变量all_features = finance_features + ceo_features + governance_featurestarget_var = 'RDM' # 主因变量</code></pre><h3><a name="t9" target="_blank"/>模型训练与预测效果评估</h3><h4><a name="t10" target="_blank"/>模型选择与训练逻辑</h4><p>考虑到单一算法的局限性，研究选取7种主流机器学习算法：逻辑回归（Logit）、LASSO回归、决策树（CART）、支持向量机（SVM）、梯度提升树（GB）、随机森林（RF）、极端梯度提升（XGBoost）。采用时间序列交叉验证的滚动预测方式，按“一年训练、一年测试”的窗口进行模型训练与评估，同时通过SMOTE技术处理类别不平衡问题。</p><h4><a name="t11" target="_blank"/>预测效果核心结果</h4><p>不同算法的预测性能存在显著差异，集成学习算法整体表现优于线性模型与单一决策树模型。决策树虽能完全拟合训练数据（R2_IS=1），但存在严重过拟合，样本外预测能力最差；随机森林、梯度提升树和XGBoost等集成算法表现突出，其中XGBoost的AUC_OOS最高（0.57），MSE_OOS和MAE_OOS最低，综合预测性能最优。<img referrerpolicy="no-referrer" src="/img/remote/1460000047389798" alt="" title="" loading="lazy"/></p><h4><a name="t12" target="_blank"/>不同特征组合的预测表现</h4><p>以财务特征为基准模型，逐步加入CEO特质与公司治理特征后，模型预测性能变化不大；包含所有特征的综合模型在XGBoost算法下AUC值最高，进一步验证了XGBoost算法对多维度特征的处理优势，以及财务特征在研发操纵预测中的基础核心作用。<img referrerpolicy="no-referrer" src="/img/remote/1460000047389799" alt="" title="" loading="lazy"/></p><h4><a name="t13" target="_blank"/>核心代码（模型训练与评估）</h4><pre><code># 定义模型评估指标函数def model_metrics(model, X_train, y_train, X_test, y_test): # 训练集与测试集预测概率 train_prob = model.predict_proba(X_train)[:,1] test_prob = model.predict_proba(X_test)[:,1] # 计算核心指标 r2_train = r2_score(y_train, train_prob) auc_test = roc_auc_score(y_test, test_prob) mse_test = mean_squared_error(y_test, test_prob) return r2_train, auc_test, mse_test# 滚动窗口评估函数def rolling_evaluation(model, X_data, y_data, n_splits=10): tscv = TimeSeriesSplit(n_splits=n_splits) metrics_dict = defaultdict(list) for train_idx, test_idx in tscv.split(X_data): # 数据划分与标准化 X_tr, X_te = X_data.iloc[train_idx], X_data.iloc[test_idx] y_tr, y_te = y_data.iloc[train_idx], y_data.iloc[test_idx]scaler = StandardScaler().fit(X_tr) X_tr_scaled = scaler.transform(X_tr) X_te_scaled = scaler.transform(X_te)# SMOTE处理类别不平衡 X_tr_balanced, y_tr_balanced = SMOTE().fit_resample(X_tr_scaled, y_tr)# 模型训练与指标计算 model.fit(X_tr_balanced, y_tr_balanced) r2_tr, auc_te, mse_te = model_metrics(model, X_tr_balanced, y_tr_balanced, X_te_scaled, y_te)</code></pre><h3><a name="t14" target="_blank"/>特征重要性与SHAP可解释性分析</h3><h4><a name="t15" target="_blank"/>核心影响因素识别</h4><p>基于随机森林与XGBoost两种最优集成算法的特征重要性分析显示，存货周转率（ITO）在两种算法中均排名第一，是预测研发操纵行为最强的指标；资产规模（Asset）排名第二，资产负债率（DAR）也进入前列。CEO特质中，研发背景（CEOTECH）在随机森林中重要性较高，但在XGBoost中有所下降；CEO性别（CEOSEX）等特征重要性普遍较低，对研发操纵的预测贡献有限。<img referrerpolicy="no-referrer" src="/img/remote/1460000047389800" alt="" title="" loading="lazy"/></p><h4><a name="t16" target="_blank"/>SHAP可解释性解读</h4><p>为破解机器学习“黑箱”问题，引入SHAP算法（基于博弈论的公平分配原则，衡量每个特征对预测结果的边际贡献）分析核心特征的影响机制：</p><ul><li>存货周转率（ITO）：偏低时企业经营压力大，管理层有更强动机通过研发操纵改善短期业绩，SHAP值为正；偏高时经营状况良好，操纵必要性低，SHAP值为负，其对预测的贡献在所有特征中最突出。</li><li>资产规模（Asset）：规模越大的企业，外部审计和监督更严格，研发投入决策更稳健，发生操纵的概率越低，SHAP值多为负。</li><li>资产负债率（DAR）：高负债企业面临偿债压力和业绩考核压力，倾向于削减研发支出粉饰财务数据，SHAP值为正，推动研发操纵行为发生。</li><li>CEO研发背景（CEOTECH）：具有研发背景的CEO更理解研发的长期价值，不会因短期业绩压力随意调整研发投入，SHAP值为负，抑制研发操纵。</li><li>机构持股比例（INSTO）：机构投资者监督能力强，能约束管理层短视行为，SHAP值为负，减少研发操纵可能性。<img referrerpolicy="no-referrer" src="/img/remote/1460000047389801" alt="" title="" loading="lazy"/></li></ul><h4><a name="t17" target="_blank"/>核心代码（SHAP分析简化版）</h4><pre><code># 标准化特征数据X_scaled = pd.DataFrame(StandardScaler().fit_transform(X_input), columns=X_input.columns)# 训练XGBoost模型xgb_model = XGBClassifier(n_estimators=300, max_depth=4, learning_rate=0.05, random_state=42)xgb_model.fit(X_scaled, y_input)# 初始化SHAP解释器explainer = shap.TreeExplainer(xgb_model)</code></pre><h3><a name="t18" target="_blank"/>稳健性检验</h3><p>为验证研究结论的可靠性，采用五种方式进行稳健性检验，所有检验结果均显示核心结论保持稳定：</p><ol><li>变更样本划分：按7:3比例划分训练集与测试集，随机森林、XGBoost等集成算法仍保持优异的预测性能，与滚动窗口预测结果一致。<img referrerpolicy="no-referrer" src="/img/remote/1460000047389802" alt="" title="" loading="lazy"/></li><li>替换被解释变量：将研发操纵判定门槛从0.5%改为1%（RDM1），存货周转率、资产规模等核心特征的重要性排序未发生改变。</li><li>变更样本区间：以2016年《高新技术企业认定管理办法》修订为节点，将样本起点调整为2016年，模型预测效果和核心特征重要性无显著变化。</li><li>引入新评估指标：新增Accuracy和F1-Score指标，XGBoost等集成算法仍表现最优，特征组合的预测规律保持一致。</li><li>过采样技术：采用SMOTE技术扩充少数类样本（研发操纵企业），重新训练XGBoost模型后，关键预测变量（ITO、Asset、DAR等）与主分析结果完全一致，仅召回率略有提升。<img referrerpolicy="no-referrer" src="/img/remote/1460000047389803" alt="" title="" loading="lazy"/></li></ol><h3><a name="t19" target="_blank"/>结论与启示</h3><h4><a name="t20" target="_blank"/>核心结论</h4><ol><li>算法性能上，XGBoost算法在研发操纵预测中综合表现最佳，随机森林、梯度提升树等集成算法优于逻辑回归、LASSO等线性模型和单一决策树，能更好捕捉变量间的非线性关系和交互效应。</li><li>影响因素上，财务特征是研发操纵的核心预测维度——存货周转率（运营效率）、资产规模（企业实力）、资产负债率（财务压力）共同决定企业操纵动机；CEO研发背景、海外背景能抑制操纵行为；机构持股比例通过外部监督发挥约束作用。</li><li>研究创新上，突破传统线性回归的因果推断局限，采用预测性建模思路，结合SHAP工具实现机器学习模型的可解释性，清晰揭示各因素对研发操纵的影响方向和强度。</li></ol><h4><a name="t21" target="_blank"/>实践启示</h4><ul><li>企业层面：建立长期导向的绩效评价体系，避免过度追求短期业绩；选拔具有研发背景、国际视野的高管；加强研发支出内部控制，确保研发决策的科学性。</li><li>政策层面：优化研发激励政策设计，将刚性税收优惠门槛改为梯度化激励，减少企业“达标式”操纵动机；完善研发支出信息披露制度，要求详细说明研发费用变动原因。</li><li>监管层面：基于存货周转率、资产负债率等核心特征构建预警模型，运用XGBoost等算法提升监管精准度；强化机构投资者监督作用；加大对研发操纵行为的惩戒力度，提高违规成本。</li></ul><h4><a name="t22" target="_blank"/>工具适配说明</h4><p>本文使用的Python库（pandas、scikit-learn、xgboost、shap、imblearn等）均为国内可正常访问的开源工具，无需科学上网。国内用户可通过清华镜像源（<a href="https://link.segmentfault.com/?enc=YsB6kxz%2Bxo%2BWVgNd4pFORQ%3D%3D.ZgKsZ9OWKC2i9vUZvs3ksvRyw8LklUFMEFx1YzJEUlqyGioItMtTDgRiYBSCRNyBfRm28AvTBi%2BCeBCxav5mo9sHA3wWzauFhrcFIvtHBgF2YSFje%2FKIVcABfNO1irTMMyTikIIdPFeZv%2BGnWv7Qg9yVTFJDL8CDgrdS99IyDt4%3D" rel="nofollow" title="https://pypi.tuna.tsinghua.edu.cn/simple）快速安装（如“pip" target="_blank">https://pypi.tuna.tsinghua.edu.cn/simple）快速安装（如“pip</a> install -i <a href="https://link.segmentfault.com/?enc=T%2FaMiNusxCYSRnAoXnw%2Fzw%3D%3D.W7LwuiLRvw%2FGt9%2BS54JlpTSZ90AYVgJu9oTd7ts%2FzsJLd%2B1roQiBpxw%2FmY9qmrRN" rel="nofollow" title="https://pypi.tuna.tsinghua.edu.cn/simple" target="_blank">https://pypi.tuna.tsinghua.edu.cn/simple</a> xgboost”），所有代码均经过Windows、Mac系统验证，可直接运行。</p><h2><a name="t23" target="_blank"/>关于分析师</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389804" alt="" title="" loading="lazy"/></p><p>在此对 Liu Qing 对本文所作的贡献表示诚挚感谢，他目前毕业于应用统计专业硕士学位，专注于数据科学相关方向，涵盖深度学习、数理金融、数据采集等研究领域。擅长 R 语言、Python、STATA、SPSS 等数据分析工具。</p><p>Liu Qing 曾任职于金榜教育学业规划（从事教育培训相关工作），在多场景实践中积累了丰富的业务落地与数据应用经验，为本文的实证分析与实践启示部分提供了重要参考。</p>]]></description></item><item>    <title><![CDATA[游戏AI行为决策——MLP（多层感知机/]]></title>    <link>https://segmentfault.com/a/1190000047389814</link>    <guid>https://segmentfault.com/a/1190000047389814</guid>    <pubDate>2025-11-11 18:18:39</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>【USparkle专栏】如果你深怀绝技，爱“搞点研究”，乐于分享也博采众长，我们期待你的加入，让智慧的火花碰撞交织，让知识的传递生生不息！</p><hr/><p>你一定听说过神经网络的大名，你有想过将它用于游戏AI的行为决策上吗？其实在（2010年发布的）《最高指挥官2》中就有应用了，今天请允许我班门弄斧一番，与大家一同用C# 实现最经典的神经网络 —— 多层感知机（Multilayer Perceptron，简称MLP）。</p><blockquote><h3><strong>一、前言</strong></h3></blockquote><p><strong>神经网络或者深度学习</strong>，总给人一种「量子力学」的感觉，总感觉它神秘无比，又无所不能。我未学习神经网络之前，总以为它是某种能够修改自身代码的代码，否则怎么能做到从「不会」变成「会」的呢？但在亲自学习后才会明白，它并没有做到这种地步，但依旧十分神奇。多层感知机是最基础的神经网络，很多其它类别的神经网络都是在这之上的变形。可以说，学会它是迈入深度学习的第一步。</p><p>多层感知机虽说经典，但并不过时。提到神经网络，大多数人脑海里想到的大概也就是类似这样的图片：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389816" alt="" title=""/></p><p>这就是一张典型的多层感知机结构图，看着好像很复杂，但实现它所需要用到的数学原理和编程知识都不难，早年间，研究神经网络的学者们还用C语言实现呢！</p><blockquote><h3><strong>二、什么是多层感知机</strong></h3></blockquote><p>现在进入正题，我们先来简单讲讲MLP的原理（如果你对此十分熟悉，只是对代码实现感兴趣，那可以跳过这部分）。</p><p>既然叫「<strong>多层</strong>感知机」，那有单个的感知机吗？那是自然，单个感知机的结构十分简单：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389817" alt="" title="" loading="lazy"/></p><p>它其实就是个算式（为方便理解，我将其分成两部分）：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389818" alt="" title="" loading="lazy"/></p><p>将传入感知机的多个输入x，与对应的权重w相乘（输入的数量与权重的数量是一样的，且数量是任意的，本例中用了3个），再加上偏置b就可以得出一个计算值sum。再将这个计算值传入一个函数f(x)就可得到感知机的最终输出out。</p><p>相信你肯定能理解，只是可能对f(x)函数有些好奇，它具体内容是什么呢？这个函数也被称为<strong>「激活函数」</strong>，为什么叫这个名字？这就得提感知机的另一个名字 —— <strong>人工神经元</strong>。其实感知机正是受神经元结构启发而被提出来的：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389819" alt="" title="" loading="lazy"/></p><p>神经元会通过树突接受输入信号并汇总，而神经元对于各个输入刺激的响应强度并不相同，所以我们给各个输入设置了相应权重来模拟这个现象。之后，将处理的信息通过轴突传给末梢（终端）。但实际上，只有汇总的信号强度大于一定程度时神经元才会向末梢传递信号，而模拟这个现象的就是「激活函数」。</p><p>那偏置b又是模拟什么的？其实它是从数学角度考虑的、方便调整输入加权和的变量值而已。</p><p>既然感知机被称为「人工神经元」，那多层感知机岂不就是<strong>「人工神经网络」</strong>？一点没错，我们现在所说的「神经网络」，基本都是指人工神经网络，而不是真正的、生物的神经网络。而「神经网络」起初就是指多层感知机，只不过现在种类多了，定义也变宽泛了。</p><p>结合我们对单个感知机的认识，再看看多层感知机：</p><p>![]<a href="https://link.segmentfault.com/?enc=nvxNacvoGucDSdO94ZAHMA%3D%3D.UFzzEYuwhoE%2BzquF8E76UKfi0HSA37jmVeNzaIfqV8I7oWhhsJCXdX5VE%2FkzIDVLcGWO1%2BOPa9k5Kj2AhwPHL450uL2kVX48iY5km5Q0KJqtexERqV05iauBS7c0RxJS" rel="nofollow" target="_blank">http://uwa-ducument-img.oss-cn-beijing.aliyuncs.com/Blog/Uspa...</a>)</p><p>但这里的单个感知机（后面用「神经元」来代称）怎么输出了多个值（看标蓝色的那部分）？这种结构图可能会误导某些人，我做个解释，这里的每一条线并不是输出，可以看到它是有箭头的，每条线表示它所指向的那个神经元的一个权重。加上箭头是为了表示数据传递的方向。</p><p>不难看出，它就是将多个感知机以层为单位进行了组合，每层都有任意数量（<strong>每层的数量</strong>可以不同）的感知机，并将一层感知机的输出作为下一层的输入，依次套娃下去。像图中，下一层神经元的权重数量 = 上一层的神经元数量，称为<strong>全连接</strong>，是神经网络中常见的连接方式，本文也只考虑这种连接方式。</p><p>这里的「输入层」其实就是输入的数据（是的，这一层不是神经元），类似之前的x0、x1、x2；「输出层」就是用于输出的神经元所组成的层，有了多个感知机，我们也可以得到多个输出；夹在「输入层」与「输出层」之间的就叫「隐藏层」，因为在实际使用神经网络时，就只是输入一组数值作为「输入层」，再看看「输出层」得到的结果，并不关心中间的运算。</p><p>我们常说的<strong>「深度学习」</strong>里的「深度」指的就是神经网络中<strong>「隐藏层」的层数</strong>（只不过现在这个词有点被炒作了），当一个神经网络的隐藏层<strong>超过3层</strong>时，它就是「深度神经网络」。</p><p>通过改变<strong>神经网络的结构</strong>或者调节<strong>神经网络的权重和偏置</strong>，我们可以用神经网络近似任何的函数、甚至是一些摸不着头脑的规律。</p><p>比如影响小明今天玩不玩网游的因素有：今日作业量、心情、本月剩余流量、今天是星期几，但我们并不知道这些因素与小明玩不玩的具体数学关系，只能大概地推断：今天小明作业多，不会玩游戏；又或者今天是星期六，虽然作业还有很多，但他还是会玩游戏……可一旦知道具体数学关系，我们就可以通过计算准确预测小明是否会玩游戏，就像我们知道了牛顿力学公式，就可以根据物体的质量和被射出的力来计算它的运动轨迹一样。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389820" alt="" title="" loading="lazy"/></p><p>所以我们所关心的、实际所使用的都是这种已经设置好正确权重和偏置的神经网络，像在与GPT聊天时怕「污染数据库」这类事就不用操心了。</p><p>要如何为神经网络的各个神经元的各个权重设置正确的值，使它能够输出我们预期的结果呢？手动调肯定不现实，所以我们会运用一些数学知识让程序自行调整权重，这个过程就是「训练/学习」。</p><p>我们会给出一些输入以及该输入所对应的正确输出，比如我们可以记录小明上个学期玩网游时的各因素值以及不玩时的各因素值，这些作为<strong>「训练集」</strong>。然后设计一个<strong>「损失函数」</strong>评判当前神经网络的输出与正确输出之间的差距。而程序就是不断地调节各个权重，使差距越来越小，这种调节的根据是<strong>「导数」</strong>，但在这里我就不展开了。总之，如果训练得当，神经网络的损失就会越来越小，直到停在一个值附近，这就是<strong>「收敛」</strong>。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389821" alt="" title="" loading="lazy"/></p><p>篇幅所限，我刻意没有讲相关的数学原理，如果你对此感兴趣，又或者对MLP的运作仍有困惑，可以看看以下两个视频。如果准备好了，下面就进入代码实现环节吧。</p><p>视频1：<br/><a href="https://www.bilibili.com/video/BV1bx411M7Zx/?spm_id_from=333.999.0.0&amp;vd_source=c9a1131d04faacd4a397411965ea21f4" target="_blank"/><a href="https://www.bilibili.com/video/BV1bx411M7Zx/?spm_id_from=333.999.0.0&amp;vd_source=c9a1131d04faacd4a397411965ea21f4" target="_blank">https://www.bilibili.com/video/BV1bx411M7Zx/?spm_id_from=333....</a></p><p>视频2：<br/><a href="https://www.bilibili.com/video/BV1o64y1i7yw/?spm_id_from=333.788&amp;vd_source=c9a1131d04faacd4a397411965ea21f4" target="_blank"/><a href="https://www.bilibili.com/video/BV1o64y1i7yw/?spm_id_from=333.788&amp;vd_source=c9a1131d04faacd4a397411965ea21f4" target="_blank">https://www.bilibili.com/video/BV1o64y1i7yw/?spm_id_from=333....</a></p><blockquote><h3><strong>三、代码实现</strong></h3></blockquote><p><strong>1. 相关数学</strong><br/>关于数学部分，我只进行简要说明，不讲它们的数学原理，也不过多注释。如果你只是想将神经网络应用到游戏中，那这部分完全可以不必深究原理，弄清它们应用的场合即可。</p><p>a. 初始化权重函数<br/>神经网络权重的初始化十分重要，它会影响你的神经网络最后能否训练成功。这里实现了3种典型的初始化方法：</p><ul><li>随机初始化（std = 0.01）：是比较普通的方法，深度学习新手接触的第一个初始化方式。</li><li>Xavier初始化：适用于激活函数为<strong>Sigmoid和Tanh</strong>的场合。</li><li>He初始化：适用于激活函数为<strong>ReLU及其衍生函数</strong>，如Leaky ReLU的场合。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389822" alt="" title="" loading="lazy"/></p><p>这里我还用了枚举，方便在编辑时切换初始化的方法（后续几类数学函数也会用这种方法）：</p><pre><code>using System;

namespaceJufGame.AI.ANN
{
    publicstaticclassInitWFunc
    { 
        publicenum Type
        {
            Random, Xavier, He, None
        }
        public static void InitWeights(Type initWFunc, Neuron neuron)
        {
            switch(initWFunc)
            {
                case Type.Xavier:
                    XavierInitWeights(neuron.Weights);
                    break;
                case Type.He:
                    HeInitWeights(neuron.Weights);
                    break;
                case Type.Random:
                    RandomInitWeights(neuron.Weights);
                    break;
                default:
                    break;
            }
        }
        private static void RandomInitWeights(float[] weightsList)
        {
            var rand = new Random();
            for (int i = 0; i &lt; weightsList.Length; ++i)
            {
                //使用较小的标准差，适合普通的随机初始化
                weightsList[i] = (float)(rand.NextGaussian() * 0.01); 
            }
        }
        private static void XavierInitWeights(float[] weightsList)
        {
            var rand = new Random();
            var scale = 1f / MathF.Sqrt(weightsList.Length);
            for (int i = 0; i &lt; weightsList.Length; ++i)
            {
                weightsList[i] = (float)(rand.NextDouble() * 2 * scale - scale);
            }
        }
        private static void HeInitWeights(float[] weightsList)
        {
            var rand = new Random();
            var stdDev = MathF.Sqrt(2f / weightsList.Length); //计算标准差
            for (int i = 0; i &lt; weightsList.Length; ++i)
            {   
                //生成服从正态分布的随机数，并乘以标准差
                weightsList[i] = (float)(rand.NextGaussian() * stdDev); 
            }
        }
        // 用于生成服从标准正态分布的随机数的辅助方法
        private static double NextGaussian(this Random rand)
        {
            double u1 = 1.0 - rand.NextDouble(); // 生成 [0, 1) 之间的随机数
            double u2 = 1.0 - rand.NextDouble();
            // 使用 Box-Muller 变换生成正态分布的随机数
            return Math.Sqrt(-2.0 * Math.Log(u1)) * Math.Sin(2.0 * Math.PI * u2); 
        }
    }
}</code></pre><p>b. 激活函数<br/>一般神经网络中所有隐藏层都使用同一种激活函数，输出层根据问题需求可能会使用和隐藏层不一样的激活函数。激活函数都有非线性且可导的特点，我也实现了一些典型的激活函数：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389823" alt="" title="" loading="lazy"/></p><ul><li>直接输出（Identify）：<strong>不做处理</strong>直接输出，用于输出层。</li><li>Sigmoid：早期的主流，现在一般用于输出层需要将<strong>输出值限制在0~1</strong>的场合，或者是只有两个输出的<strong>二分问题</strong>。</li><li>Tanh：相当于Sigmoid的改造，将<strong>输出限制在了-1~1</strong>。</li><li>ReLU：当今的<strong>主流激活函数</strong>，长得十分友好，甚至不用加减运算。一般选它准没错。</li><li>Leaky ReLU：ReLU的改造，使得<strong>对负数输入也有响应</strong>，但并没有说它一定好于ReLU。如果你用ReLU训练出现问题，可以换这个试试。</li><li><p>Softmax：把一系列输出转为总和为1的小数，并且维持彼此的大小关系，相当于把输出结果转为了概率。适用于<strong>多分类问题</strong>，但一定要<strong>搭配交叉熵损失函数使用</strong>。</p><pre><code>using System;

namespaceJufGame.AI.ANN
{
  publicstaticclassActivationFunc
  {
      private delegate float FuncCalc(float x);
      privatestatic FuncCalc curAcFunc;
      publicenum Type
      {
          Identify, Softmax, Tanh, Sigmoid, ReLU, LeakyReLU
      }  
      //按层使用激活函数计算
      public static void Calc(Type funcType, Layer layer)
      {
          if(funcType == Type.Softmax)
          {
              Softmax_Calc(layer);
          }
          else
          {
              curAcFunc = funcType switch
              {
                  Type.Sigmoid =&gt; Sigmoid_Calc,
                  Type.Tanh =&gt; Tanh_Calc,
                  Type.ReLU =&gt; ReLU_Calc,
                  Type.LeakyReLU =&gt; LeakyReLU_Calc,
                  _ =&gt; Identify_Calc,
              };
              for(int i = 0; i &lt; layer.Neurons.Length; ++i)
              {
                  layer.Output[i] = curAcFunc(layer.Neurons[i].Sum);
              }
          }
      }
      //根据传入下标index选取层中神经元，并进行求导
      public static float Diff(Type funcType, Layer layer, int index)
      {
          return funcType switch
          {
              Type.Softmax =&gt; Softmax_Diff(layer, index),
              Type.Sigmoid =&gt; Sigmoid_Diff(layer, index),
              Type.Tanh =&gt; Tanh_Diff(layer, index),
              Type.ReLU =&gt; ReLU_Diff(layer, index),
              Type.LeakyReLU =&gt; LeakyReLU_Diff(layer, index),
              _ =&gt; Identify_Diff(),
          };   
      }

      #region 直接输出
      private static float Identify_Calc(float x)
      {
          return x;
      }
      private static float Identify_Diff()
      {
          return1;
      }
      #endregion

      #region Softmax
      private static void Softmax_Calc(Layer layer)
      {
          var neurons = layer.Neurons;
          var expSum = 0.0f;
          for(int i = 0; i &lt; neurons.Length; ++i)
          {
              layer.Output[i] = MathF.Exp(neurons[i].Sum);
              expSum += layer.Output[i];
          }
          for(int i = 0; i &lt; neurons.Length; ++i)
          {
              layer.Output[i] /= expSum;
          }
      }
      private static float Softmax_Diff(Layer outLayer, int index)
      {
          return outLayer.Output[index] * (1 - outLayer.Output[index]);
      }
      #endregion

      #region Sigmoid
      private static float Sigmoid_Calc(float x)
      {
          return1.0f / (1.0f + MathF.Exp(-x));
      }
      private static float Sigmoid_Diff(Layer outLayer, int index)
      {
          return outLayer.Output[index] * (1 - outLayer.Output[index]);
      }
      #endregion

      #region Tanh
      private static float Tanh_Calc(float x)
      {
          var expVal = MathF.Exp(-x);
          return (1.0f - expVal) / (1.0f + expVal);
      }
      private static float Tanh_Diff(Layer outLayer, int index)
      {
          return1.0f - MathF.Pow(outLayer.Output[index], 2.0f);
      }
      #endregion

      #region ReLU
      public static float ReLU_Calc(float x)
      {
          return x &gt; 0 ? x : 0;
      }
      public static float ReLU_Diff(Layer outLayer, int index)
      {
          return outLayer.Neurons[index].Sum &gt; 0 ? 1 : 0;
      }
      #endregion

      #region LeakyReLU
      private static float LeakyReLU_Calc(float x)
      {
          return x &gt; 0 ? x : 0.01f * x;
      }
      private static float LeakyReLU_Diff(Layer outLayer, int index)
      {
          return outLayer.Neurons[index].Sum &gt; 0 ? 1 : 0.01f;
      }
      #endregion
  }
}</code></pre></li></ul><p>c. 更新权重函数<br/>权重的更新涉及一些「超参数」，比如学习率、最大迭代次数等。这些参数是程序不会进行更新的，只能人工提前设置好。在神经网络的学习中，学习率的值很重要，过小会导致训练费时；过大则会导致学习发散而不能正确进行。但好在后面人们想出来更好的权重更新函数，它们对「超参数」的依赖会减小很多。我们所实现的有：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389824" alt="" title="" loading="lazy"/></p><ul><li>SGD：随机梯度下降，最简单的一种更新方法，但有时并不是这么高效，容易陷入局部最优解。</li><li>Movement：基于物理上的动量概念，它会在更新权重的过程中考虑先前的更新步骤，需要为每个权重设置额外参数（用m表示）来记录「动量」。</li><li>AdaGrad：运用了学习率衰减的技巧，为每个权重适当地调整学习率，相当于给每个权重都设置了独立的学习率，也需要额外参数（用v表示）记录。</li><li>Adam：将Movment与AdaGrad结合了起来，通过组合二者的优点，有望实现参数空间的高效搜索。</li></ul><p>当然，上述4个方法各有优劣，可以优先考虑SGD和Adam。</p><p>顺带一提，权重的更新都是建立在<strong>「梯度」</strong>之上的，「梯度」可以理解为对神经网络整体权重的变化趋势。你想，有这么多权重要更新，有时训练一个样本A后，会要求权重w0+ = 0.01、w1- = 0.05以减小误差，但训练下一个样本B时，又要求w0- = 0.02、w1+ = 0.04，一个训练集有这么多样本，要以哪个样本训练时产生的权重变化为准呢？</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389825" alt="" title="" loading="lazy"/></p><p>答案是累加每个样本带来的误差并取平均值。如果觉得还不清楚，可以看看这个视频：<br/><a href="https://www.bilibili.com/video/BV16x411V7Qg/?spm_id_from=333.999.0.0&amp;vd_source=c9a1131d04faacd4a397411965ea21f4" target="_blank"/><a href="https://www.bilibili.com/video/BV16x411V7Qg/?spm_id_from=333.999.0.0&amp;vd_source=c9a1131d04faacd4a397411965ea21f4" target="_blank">https://www.bilibili.com/video/BV16x411V7Qg/?spm_id_from=333....</a></p><p>还有一点，偏置b也是随着权重更新的，它可以视为一个输入始终为1，权重为b的权重。在后续的实现中，我将偏置放在储存权重的列表的最后一位。（但后来才知道不提倡这种写法。）</p><pre><code>using System;

namespaceJufGame.AI.ANN
{
    publicstaticclassUpdateWFunc
    {
        privateconstfloat MinDelta = 1e-7f;
        privateconstfloat beta1 = 0.9f;
        privateconstfloat beta2 = 0.999f;
        private delegate void UpdateLayer(Neuron curNeuron, float learningRate, int curEpochs, int samplesCount);
        publicenum Type
        {
            SGD, Momentum, AdaGrad, Adam
        }
        public static void UpdateNetWeights(Type type, NeuralNet net, int samplesCount)
        {
            UpdateLayer updateLayerFunc = type switch
            {
                Type.Momentum =&gt; Momentum_UpdateW,
                Type.AdaGrad =&gt; AdaGrad_UpdateW,
                Type.Adam =&gt; Adam_UpdateW,
                _ =&gt; SGD_UpdateW,
            };
            var curLayer = net.OutLayer;
            for(int j = 0; j &lt; curLayer.Neurons.Length; ++j)
            {
                updateLayerFunc(curLayer.Neurons[j], net.LearningRate, net.CurEpochs ,samplesCount);
            }
            for(int i = 0; i &lt; net.HdnLayers.Length; ++i)
            {
                curLayer = net.HdnLayers[i];
                for(int j = 0; j &lt; curLayer.Neurons.Length; ++j)
                {
                    updateLayerFunc(curLayer.Neurons[j], net.LearningRate, net.CurEpochs, samplesCount);
                }    
            }
        }

        #region 各参数损失贡献计算
        //计算各参数对损失的贡献程度（也是各参数的变化的值）
        public static void CalcDelta(NeuralNet net, float[] input)
        {
            var lastInput = input;
            for(int i = 0; i &lt; net.HdnLayers.Length; ++i)
            {
                var curLayer = net.HdnLayers[i];
                CalcLayerDelta(curLayer, lastInput);
                lastInput = curLayer.Output;
            }
            CalcLayerDelta(net.OutLayer, lastInput);
        }
        private static void CalcLayerDelta(Layer curLayer, float[] lastInput)
        {
            for(int j = 0, k; j &lt; curLayer.Neurons.Length; ++j)
            {
                var curNeuron = curLayer.Neurons[j];
                for(k = 0; k &lt; lastInput.Length; ++k)
                {
                    //通过反向传播时神经元的损失，计算每个权重的贡献贡献并累加
                    curNeuron.WeightParams["Delta"][k] += curNeuron.Params["Error"] * lastInput[k];
                }
                //同理计算偏置的损失贡献
                curNeuron.WeightParams["Delta"][k] += curNeuron.Params["Error"];
            }
        }
        #endregion

        #region SGD
        private static void SGD_UpdateW(Neuron curNeuron, float learningRate, int curEpochs, int samplesCount)
        {
            for(int k = 0; k &lt; curNeuron.Weights.Length; ++k)
            {
                var gradient = curNeuron.WeightParams["Delta"][k] / samplesCount;
                curNeuron.Weights[k] -= learningRate * gradient;
                curNeuron.WeightParams["Delta"][k] = 0;
            }    
        }
        #endregion

        #region Momentum
        private static void Momentum_UpdateW(Neuron curNeuron, float learningRate, int curEpochs, int samplesCount)
        {
            for(int k = 0; k &lt; curNeuron.Weights.Length; ++k)
            {
                var gradient = curNeuron.WeightParams["Delta"][k] / samplesCount;
                curNeuron.WeightParams["m"][k] = beta1 * curNeuron.WeightParams["m"][k] - learningRate * gradient;
                curNeuron.Weights[k] += curNeuron.WeightParams["m"][k];
                curNeuron.WeightParams["Delta"][k] = 0;
            }
        }
        #endregion

        #region AdaGrad
        private static void AdaGrad_UpdateW(Neuron curNeuron, float learningRate, int curEpochs, int samplesCount)
        {
            for(int k = 0; k &lt; curNeuron.Weights.Length; ++k)
            {
                var gradient = curNeuron.WeightParams["Delta"][k] / samplesCount;
                curNeuron.WeightParams["v"][k] += gradient * gradient;
                curNeuron.Weights[k] -= learningRate * gradient / MathF.Sqrt(curNeuron.WeightParams["v"][k] + MinDelta);
                curNeuron.WeightParams["Delta"][k] = 0;
            }
        }
        #endregion

        #region  Adam
        private static void Adam_UpdateW(Neuron curNeuron, float learningRate, int curEpochs, int samplesCount)
        {
            for(int k = 0; k &lt; curNeuron.Weights.Length; ++k)
            {
                var gradient = curNeuron.WeightParams["Delta"][k] / samplesCount;
                curNeuron.WeightParams["m"][k] = beta1 * curNeuron.WeightParams["m"][k] + (1 - beta1) * gradient;
                curNeuron.WeightParams["v"][k] = beta2 * curNeuron.WeightParams["v"][k] + (1 - beta2) * gradient * gradient;
                var mHat = curNeuron.WeightParams["m"][k] / (1 - MathF.Pow(beta1, curEpochs));
                var vHat = curNeuron.WeightParams["v"][k] / (1 - MathF.Pow(beta2, curEpochs));
                curNeuron.Weights[k] -= learningRate * mHat / (MathF.Sqrt(vHat) + MinDelta);
                curNeuron.WeightParams["Delta"][k] = 0;
            }
        }
        #endregion
    }
}</code></pre><p>d. 损失函数<br/>损失函数用来衡量输出与正确值之间的差距，这里实现的是最常用的两个损失函数：</p><ul><li>均方差函数：简单实用，形式如下：</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389826" alt="" title="" loading="lazy"/></p><ul><li>交叉熵函数：主要用在多分类问题上，配合Softmax使用：</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389827" alt="" title="" loading="lazy"/></p><pre><code>using System;

namespaceJufGame.AI.ANN
{
    publicstaticclassLossFunc
    {
        privateconstfloat MinDelta = 1e-7f;
        publicenum Type
        {
            MeanSqurad, CrossEntropy,
        }
        public static float Calc(Type type, float[] targetOut, Layer outLayer)
        {
            return type switch
            {
                Type.MeanSqurad =&gt; MeanSquradErr_Calc(targetOut, outLayer),
                _ =&gt; CrossEntropy_Calc(targetOut, outLayer),
            };
        }
        public static void Diff(Type type, float[] targetOut, Layer outLayer)
        {
            switch(type)
            {
                case Type.MeanSqurad:
                    MeanSquradErr_Diff(targetOut, outLayer);
                    break;
                case Type.CrossEntropy:
                    CrossEntropy_Diff(targetOut, outLayer);
                    break;
            };
        }

        private static float MeanSquradErr_Calc(float[] targetOut, Layer outLayer)
        {
            var errSum = 0.0f;
            for(int i = 0; i &lt; targetOut.Length; ++i)
            {
                errSum += MathF.Pow(outLayer.Output[i] - targetOut[i], 2);
            }
            return errSum / (2 * targetOut.Length);
        }
        private static void MeanSquradErr_Diff(float[] targetOut, Layer outLayer)
        {
            for(int i = 0; i &lt; targetOut.Length; ++i)
            {
                var curNeuron = outLayer.Neurons[i];
                curNeuron.Params["Error"] = outLayer.Output[i] - targetOut[i];
            }
        }

        private static float CrossEntropy_Calc(float[] targetOut, Layer outLayer)
        {
            var errSum = 0.0f;
            for(int i = 0; i &lt; targetOut.Length; ++i)
            {
                //加上一个极小值再取log，放置出现log(0)报错
                errSum -= targetOut[i] * MathF.Log(outLayer.Output[i] + MinDelta);
            }
            return errSum;
        }
        private static void CrossEntropy_Diff(float[] targetOut, Layer outLayer)
        {
            for(int i = 0; i &lt; targetOut.Length; ++i)
            {
                var curNeuron = outLayer.Neurons[i];
                //用Output[i]的前提：神经网络的输出经过了softmax处理
                curNeuron.Params["Error"] = outLayer.Output[i] - targetOut[i];
            }
        }
    }
}</code></pre><p><strong>2. 感知机（神经元）</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389828" alt="" title="" loading="lazy"/></p><p>简单地对神经元结构进行实现，只是神经元在训练时，需要为自身或者自身的权重记录一些额外信息，所以多了WeightParams和Params备以记录。</p><ul><li>为什么不记录激活函数的计算结果out?<br/>因为在训练过程中常常要以层为单位统一处理激活函数的计算结果，故而将out都记录在层中了。（实际上Python中许多深度学习框架库都是<strong>以层为最小单位</strong>构建神经网络的，这有利于进行矩阵运算，但在我们的实现中，一来没用到矩阵运算，二来是希望能让大家更直接地看到神经网络训练、计算的细节，所以我们以单个神经元作为最小的单位。）</li><li><p>为什么没有激活函数f(x)？<br/>因为我们之前说过，神经网络的隐藏层都是使用同一种激活函数，顶多输出层用的不太一样。也就是说我们只需要记录两个函数的类型，所以让后续实现的神经网络类记下就行了，没必要每个神经元都记录，浪费空间。</p><pre><code>using System;
using System.Collections.Generic;
using UnityEngine;

namespaceJufGame.AI.ANN
{
  [Serializable] // 方便在编辑器页面查看
  publicclassNeuron
  {
      //神经元权重列表，末位放置偏置b
      publicfloat[] Weights =&gt; weights;
      //加权和
      publicfloat Sum =&gt; sum;
      //为各个权重分配的额外参数
      public Dictionary&lt;string, float[]&gt; WeightParams{ get; privateset; }
      //为神经元本身分配的额外参数
      public Dictionary&lt;string, float&gt; Params{ get; privateset; }
      [SerializeField]privatefloat[] weights;
      privatefloat sum;
      public Neuron(int weightCount)
      {
          weights = newfloat[weightCount + 1];//末尾放偏置
      }
      /// &lt;summary&gt;
      /// 初始化训练所需参数列表，仅在训练时调用
      /// &lt;/summary&gt;
      public void InitCache()
      {
          Params = new Dictionary&lt;string, float&gt;
          {
              ["Error"] = 0,//该值用来记录，每次更新时的累计损失
          };
          WeightParams = new Dictionary&lt;string, float[]&gt;
          {
              //记录权重待变化值
              ["Delta"] = newfloat[weights.Length],
              //Momentum和Adam中，用于记录权重变化的「动量」
              ["m"] = newfloat[weights.Length],
              //AdaGrad和Adam中，用于记录权重独立学习率
              ["v"] = newfloat[weights.Length],           
          };
      }
      //计算Sum
      public float CalcSum(float[] input)
      {
          int i;
          sum = 0;
          for(i = 0; i &lt; input.Length; ++i)
          {
              sum += weights[i] * input[i];//加权和
          }
          sum += weights[i];//加上权重
          return Sum;
      }
  }
}</code></pre></li></ul><p><strong>3. 层</strong><br/>没有太多必要说的，就是嵌套调用了包含的各神经元的函数，比如层的计算就是各个神经元的计算，其它同理。</p><pre><code>using System;
using UnityEngine;

namespaceJufGame.AI.ANN
{
    [Serializable]
    publicclassLayer
    {
        public Neuron[] Neurons =&gt; neurons;//存储神经元
        publicfloat[] Output =&gt; output;//存储各神经元激活函数输出
        [SerializeField] private Neuron[] neurons;
        [SerializeField] privatefloat[] output;
        public Layer(int neuronCount)
        {
            output = newfloat[neuronCount];
            neurons = new Neuron[neuronCount];
        }
        //对层中的每个神经元的权重进行初始化
        public void InitWeights(int weightCount, InitWFunc.Type initType)
        {
            for(int i = 0; i &lt; neurons.Length; ++i)
            {
                neurons[i] = new Neuron(weightCount);
                InitWFunc.InitWeights(initType, neurons[i]);
            }
        }
        //初始化层中每个神经元的额外参数
        public void InitCache()
        {
            for(int i = 0; i &lt; neurons.Length; ++i)
            {
                neurons[i].InitCache();
            }
        }
        //计算该层，实际上就是计算所有神经元的加权和，并求出激活函数的输出
        public float[] CalcLayer(float[] inputData, ActivationFunc.Type acFuc)
        {
            for(int i = 0; i &lt; neurons.Length; ++i)
            {
                neurons[i].CalcSum(inputData);
            }
            ActivationFunc.Calc(acFuc, this);
            return output;
        }
    }
}</code></pre><p><strong>4. 多层感知机（神经网络）</strong><br/>神经网络也一样，是对层的各个功能的再度包装，只是多了些超参数成员变量。</p><ul><li>为什么没有输入层？<br/>因为输入层其实就只是输入的数值，没必要单独设置一个层（Python中许多深度学习框架也是这样的）。</li><li><p>怎么读取输出？<br/>直接读取输出层的输出列表即可。</p><pre><code>using System;
using UnityEngine;

namespaceJufGame.AI.ANN
{
  [Serializable]
  publicclassNeuralNet
  {
      publicfloat TargetError = 0.0001f;//预期误差，当损失函数的结果小于它时，就停止训练
      publicfloat LearningRate = 0.01f;//学习率
      publicint CurEpochs;//记录当前迭代的次数
      public ActivationFunc.Type hdnAcFunc;//隐藏层激活函数类型
      public ActivationFunc.Type outAcFunc;//输出层激活函数类型
      public Layer[] HdnLayers =&gt; hdnLayers;//隐藏层
      public Layer OutLayer =&gt; outLayer;//输出层
      [SerializeField] private Layer[] hdnLayers;
      [SerializeField] private Layer outLayer;

      public NeuralNet(int hdnLayerCount, int[] neuronsOfLayers, int outCount, 
          ActivationFunc.Type hdnAcFnc, ActivationFunc.Type outAcFnc,
          float targetError = 0.0001f, float learningRate = 0.01f)
      {
          outLayer = new Layer(outCount);
          hdnLayers = new Layer[hdnLayerCount];
          for(int i = 0, j = 0; i &lt; hdnLayerCount; ++i)
          {
              hdnLayers[i] = new Layer(neuronsOfLayers[j]);
          }
          hdnAcFunc = hdnAcFnc;
          outAcFunc = outAcFnc;
          TargetError = targetError;
          LearningRate = learningRate;
      }
      //初始化各神经元权重
      public void InitWeights(int inputDataCount, InitWFunc.Type initType)
      {
          int neuronNum = inputDataCount;
          for(int i = 0; i &lt; HdnLayers.Length; ++i)
          {
              hdnLayers[i].InitWeights(neuronNum, initType);
              neuronNum = HdnLayers[i].Neurons.Length;
          }
          outLayer.InitWeights(neuronNum, initType);
      }
      //初始化各神经元额外参数列表
      public void InitCache()
      {
          for(int i = 0; i &lt; HdnLayers.Length; ++i)
          {
              hdnLayers[i].InitCache();
          }
          outLayer.InitCache();
      }
      //计算神经网络
      public float[] CalcNet(float[] inputData)
      {
          var curInput = inputData;
          for(int j = 0; j &lt; hdnLayers.Length; ++j)
          {
              curInput = hdnLayers[j].CalcLayer(curInput, hdnAcFunc);
          }
          return outLayer.CalcLayer(curInput, outAcFunc);
      }
  }
}</code></pre><p>至此，神经网络就搭建完成了，并没有想象的那么复杂。</p></li></ul><p><strong>5. 训练器</strong><br/>先实现一个训练器的基类……等等，明明就一种神经网络，为什么还要有基类，直接写不好吗？</p><p>其实最初是打算实现多种神经网络的，但后来考试临近，不得不转移重心，最终只实现了最简单的MLP。Unity本身也已经可以导入ONNX模型，如果要在游戏里想实现图像识别这类复杂功能的话，导入模型似乎更方便，所以实现更多神经网络的必要性就值得考虑了。当然，这些文末会再进行讨论。</p><p>先来看看这个基类有哪些东西：</p><pre><code>using UnityEngine;

namespaceJufGame.AI.ANN
{
    publicabstractclassTraining
    {
        public NeuralNet TrainingNet;//需要训练的神经网络
        publicfloat[][] InputSet =&gt; inputSet;//训练输入集

        /*没有「训练输出集」是因为并非所有类型的神经网络都需要「训练输出」
        所以它不是基类必需的，当然，这些就是题外话了*/

        protectedfloat[][] inputSet;
        [SerializeField] protectedint maxEpochs;//最大迭代次数

        public Training(NeuralNet initedNet, int maxEpochs)
        {
            this.maxEpochs = maxEpochs;
            TrainingNet = initedNet;
        }

        public void SetInput(float[][] inputSet)//设置训练输入集
        {
            this.inputSet = inputSet;
        }
        public abstract bool IsTrainEnd();//是否训练完成
        public abstract void Train(); //不断训练神经网络
        public abstract void Train_OneTime();//训练（迭代）一次神经网络

        //打印神经网络输出的结果，调试用的
        public static void DebugNetRes(NeuralNet net, float[][] testInput)
        {
            for(int i = 0; i &lt; testInput.GetLength(0); ++i)
            {
                var res = net.CalcNet(testInput[i]);
                for(int j = 0; j &lt; res.Length; ++j)
                {
                    Debug.Log("检验结果 " + i + " = " + res[j]);
                }
            }
        }
    }
}</code></pre><p>最后，就是真正用来训练的类了，我们将采用最常见梯度下降法进行训练。其中涉及前向传播和反向传播，我稍作解释：</p><ul><li>前向传播（Forward Propagation）：传入训练输入样本计算出当前神经网络模型的输出，并进一步计算损失（损失函数的计算结果其实在反向传播中并没有用，只是给开发者看的，用来判断当前训练情况）。</li><li>反向传播（Backward Propagation）：从损失函数开始，用链式求导法则，反向（输出层➡隐藏层➡输入层）计算每个神经元的损失（下图中的δ、代码中的Params["Error"]）。通过神经元的损失，可以计算出神经元的每个参数（权重、偏置）的损失贡献（权重更新函数代码中的WeightParams["Delta"]）并一直累加，直到训练集被读取完。这时，我们就说完成了一次训练迭代。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389829" alt="" title="" loading="lazy"/></p><p><strong>完成一次迭代后（不是训练完一个样本后）</strong>，将累加的损失除以训练样本数取得均值，再用权重更新函数对各参数进行更新。</p><p>这一迭代过程反复进行，直到损失函数计算的误差达到可容许范围（也就是小于预期损失）或达到最大训练次数，详情可看《解读反向传播算法（图与公式结合）》[1]（但注意！该文章为了方便讲解，训练完一个样本就开始更新权重了），实现如下：</p><pre><code>using UnityEngine;

namespaceJufGame.AI.ANN
{
    [System.Serializable]
    publicclassBPNN : Training
    {
        publicfloat[][] OutputSet =&gt; outputSet;
        [SerializeField] privatefloat meanError = float.MaxValue;
        [SerializeField] private LossFunc.Type errorFunc;
        [SerializeField] private UpdateWFunc.Type updateWFunc;
        privatefloat[][] outputSet;
        public BPNN(NeuralNet initedNet, LossFunc.Type errorFunc, UpdateWFunc.Type updateWFunc, int maxEpochs): base(initedNet,maxEpochs)
        {
            this.errorFunc = errorFunc;
            this.updateWFunc = updateWFunc;
        }
        public void SetOutput(float[][] outputSet)
        {
            this.outputSet = outputSet;
        }
        public override bool IsTrainEnd()//判断是否训练完成
        {
            return meanError &lt; TrainingNet.TargetError 
                || maxEpochs &lt; TrainingNet.CurEpochs;
        }
        public override void Train()
        {
            meanError = float.MaxValue;
            while(!IsTrainEnd())
            {
                Train_OneTime();
            }
        }
        public override void Train_OneTime()
        {
            int samplesCount = inputSet.GetLength(0);//记下样本数量
            ++TrainingNet.CurEpochs;//更新迭代次数
            meanError = 0;
            for(int i = 0; i &lt; samplesCount; ++i)
            {
                ForWard(i);
                Backpropagation();
                UpdateWFunc.CalcDelta(TrainingNet, inputSet[i]);
            }
            UpdateWFunc.UpdateNetWeights( updateWFunc, TrainingNet, samplesCount);
            meanError /= samplesCount;//取样本误差均值作为本次迭代的误差
            #if UNITY_EDITOR
            Debug.Log($"误差：{meanError}");//调试时用的
            #endif
        }
        private void ForWard(int trainIndex)
        {
            var outLayer = TrainingNet.OutLayer;
            TrainingNet.CalcNet(inputSet[trainIndex]);
            meanError = LossFunc.Calc(errorFunc, outputSet[trainIndex], outLayer);
            /*这里图省事，将反向传播的第一步一并计算了*/
            LossFunc.Diff(errorFunc, outputSet[trainIndex], outLayer);//损失函数求导
            for(int i = 0; i &lt; outLayer.Neurons.Length; ++i)//输出层激活函数求导
            {
                outLayer.Neurons[i].Params["Error"] *= ActivationFunc.Diff(TrainingNet.outAcFunc, outLayer, i);
            }
        }
        private void Backpropagation()
        {
            var lastLayer = TrainingNet.OutLayer;
            for(int i = TrainingNet.HdnLayers.Length - 1; i &gt; -1; --i)
            {
                var curLayer = TrainingNet.HdnLayers[i];
                for(int j = 0; j &lt; curLayer.Neurons.Length; ++j)
                {
                    var curNeuron = curLayer.Neurons[j];
                    //每次计算损失时要清零，避免上次迭代结果产生的干扰
                    curNeuron.Params["Error"] = 0;
                    for(int k = 0; k &lt; lastLayer.Neurons.Length; ++k)
                    {
                        var lastNeuron = lastLayer.Neurons[k];
                        curNeuron.Params["Error"] += lastNeuron.Params["Error"] * lastNeuron.Weights[j];
                    }
                    curNeuron.Params["Error"] *= ActivationFunc.Diff(TrainingNet.hdnAcFunc, curLayer, j);
                }
                lastLayer = curLayer;
            }
        }
    }
}</code></pre><blockquote><h3><strong>四、使用教程</strong></h3></blockquote><p>一切都准备就绪了，那要怎么运转这个神经网络呢？我们创建一个继承了MonoBehavior的脚本，并声明下面三个公开的字段：</p><pre><code>using UnityEngine;
using JufGame.AI.ANN;

public class TrainANN : MonoBehaviour
{
    public int inputCount;
    public BPNN bp;
    public InitWFunc.Type initW;
}</code></pre><p>将它挂载在场景的任一物体上，不出意外的话，你可以在编辑器看到神经网络类的许多关键变量都可以显示出来（如果你的没有，就要注意是否遗漏[System.Serializable]或设置成了私有类）：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389830" alt="" title="" loading="lazy"/></p><p>我们再完善下脚本，设置好训练输入和输出（以「异或」运算为例），使得神经网络能在Unity运行时逐帧训练：</p><pre><code>public classTrainANN : MonoBehaviour
{
    publicint inputCount;
    public BPNN bp;
    public InitWFunc.Type initW;

    privatefloat[][] inSet = //异或运算的输入
    {
        newfloat[]{1, 0},
        newfloat[]{1, 1},
        newfloat[]{0, 0},
        newfloat[]{0, 1},
    };
    privatefloat[][] outSet = //异或运算的输出
    {
        newfloat[]{1},
        newfloat[]{0},
        newfloat[]{0},
        newfloat[]{1},
    };

    private void Awake()
    {
        bp.SetInput(inSet);//为训练器设置训练输入集
        bp.SetOutput(outSet);//为训练器设置训练输出集
    }
    private void Start()
    {
        bp.TrainingNet.InitWeights(inputCount, initW);//初始化权重
        bp.TrainingNet.InitCache();//初始化额外参数存储
    }

    private void Update()
    {
        if(bp.IsTrainEnd())//如果训练结束，就打印训练完成的神经网络 对训练输入集输出
        {
            Training.DebugNetRes(bp.TrainingNet, inSet);
            return;
        }
        bp.Train_OneTime();//没有训练结束，就每帧训练一次
    }
}</code></pre><p>回到编辑页面，由于关键变量都可以直接修改，所以我们无需调用构造函数进行初始化。我们设置好它的预期误差、最大迭代数等，可以参照下面这个设置：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389831" alt="" title="" loading="lazy"/></p><p>然后我们开始运行，不出意外的话，训练很快就结束了（大概只花了100多次迭代），你也可以看到Console面板打印了神经网络的输出结果：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389832" alt="" title="" loading="lazy"/></p><p>可以看到，结果是很接近真实值的（把预期误差设小点还可以更接近），这也说明我们的训练是奏效的！</p><ul><li>可能在尝试其它参数时（尤其是激活函数），会发现<strong>有时误差会「停」在某个值</strong>下不去了，是怎么回事？<br/>这是陷入了局部最优解的情况，又或者是神经网络几乎停止训练，在使用较少数据并且激活函数为ReLU的场合可能会出现。可以尝试其它激活函数，或增加训练样本。</li></ul><p>可一旦结束Unity运行后，编辑页面这些被训练好的参数就又变回去了，这该怎么办？很简单，一旦训练完后，就暂停运行（是暂停，不是结束），右键神经网络的名字，将它复制下来。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389833" alt="" title="" loading="lazy"/></p><p>创建一个新的脚本并将它挂在场景中，用以测试被复制的神经网络能否正常工作：</p><pre><code>using System.Collections;
using System.Collections.Generic;
using JufGame.AI.ANN;
using UnityEngine;

publicclassUseMLP : MonoBehaviour
{
    public NeuralNet net;
    privatefloat[][] inSet = //异或运算的输入
    {
        newfloat[]{1, 0},
        newfloat[]{1, 1},
        newfloat[]{0, 0},
        newfloat[]{0, 1},
    };
    private void Awake()
    {
        Training.DebugNetRes(net, inSet);
    }
}</code></pre><p>将之前训练好的神经网络，粘贴给它，然后运行Unity：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389834" alt="" title="" loading="lazy"/></p><p>不出意外的话，可以看到，这个神经网络的输出是十分正确的（我就不贴图了）！</p><blockquote><h3><strong>五、项目链接</strong></h3></blockquote><p>最后一步，神经网络要如何用在AI的行为决策中呢？</p><ul><li>确定好AI决策相关的数据、并将其作为神经网络的输入。<br/>比如生命值、攻击力、与敌人之间的距离等，并将它们<strong>进行归一化处理</strong>，比如一个角色生命值上限为100，现在生命值为50，那在将生命值作为输入时不是传入5，而是50/100 =0.5。总之，要将<strong>输入的数据限制在0~1</strong>。这有利于神经网络训练，也能更正确地表达数据的信息，还是以刚才这个角色为例，假设他的魔法值上限为50，当前魔法值为40，能因为当前生命值50 &gt; 当前魔法值40而认为当前角色更需要补充魔法值吗？这显然是不合理的。</li><li>根据输入样本拟定对应的输出结果作为训练输出。<br/>选取并想好了数据的归一化处理后，我们需要拟定一部分输入和输出。设计训练输入还是比较简单的，但输出怎么量化呢？因为决策要做的可是一个行为！我们可以这么做，将输出设置为执行某个行为的概率：</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389835" alt="" title="" loading="lazy"/></p><p>这样一来，我们只要遍历训练完的神经网络的所有输出，选出值最大的那个神经元对应的行为来执行就可以了。</p><p>我所提供的项目[2]也是这样做的，在项目中我用神经网络控制了小机器人的三个行为：攻击、防御、奔跑。影响因素有自身生命值、敌方生命值、敌我间距。预期的结果就是当我方血少又离得很近（手动拖拽二者距离）时，机器人会防御；当我方与对方旗鼓相当或更优势时，机器人会攻击，其余情况会奔跑。总之，也是很简单的行为。</p><blockquote><h3><strong>六、尾声</strong></h3></blockquote><p>最后，我们再谈谈之前遗留的问题：是否有必要使用C# 构建神经网络？我个人觉得，除了用来做这种决策行动，其它情况大可不必费力构建。主要原因在于：Unity可以导入由Python深度学习框架训练出来的神经网络模型，省时省力、效果还好。</p><p>不过，作为行为决策这种与游戏逻辑紧密联系的部分，用游戏引擎的脚本语言编写是合适的。这方便观察现象时时调整，也能更好地与其它游戏脚本结合，而且行为决策所需的神经网络复杂度并不大，因此带来的性能影响并不大。</p><p>以《最高指挥官2》中使用的MLP为例：它的输入层有34个神经元，隐藏层有98个神经元，输出层有15个神经元，但它的计算不超过0.03毫秒。这显然是个可以接受的结果。（该数据来源于2015版《游戏人工智能》——第30章）</p><p>但是，神经网络比起传统的决策算法，最大的弊端是不方便调试以及最终效果的不可控。毕竟它的训练是个纯数学的过程，很难像以往那样在程序中打断点跟踪；最终效果的不可控也导致可能要训练多次才能得出较满意的模型。所以在《最高指挥官2》中神经网络也不是全权控制AI决策，而是搭配有限状态机使用。还有一点就是需要准备大量的训练数据，其实这并非是一定的，如果你能用好Excel导入数据或者是像《最高指挥官2》那样使用适应度函数来代替具体的训练样本（篇幅所限，不展开了），感兴趣的同学可以去了解下。</p><p>无庸置疑的是，这种AI决策方法的确会使角色更加生动，而且需要额外编写的代码也并不多，只是要多花些时间训练。</p><p><strong>参考：</strong><br/>[1] 解读反向传播算法（图与公式结合）<br/><a href="https://link.segmentfault.com/?enc=cs9LJ8EWpMtE6AOkWWV9TA%3D%3D.GNVXZQUiiTRAsJH801nDVaIvwPmRTKXYCYObm7%2FnvvFLI3Vw0EGywSXUuEFli5aw" rel="nofollow" target="_blank"/><a href="https://link.segmentfault.com/?enc=d%2BL5hUe0S4QsliVhyXmd%2Bw%3D%3D.2YAsIi5cB1FAFXFHLn2Sm3Apj45%2B%2FvixzzN%2FuoL0QahAiRG%2F6K1F5QJrpsJfG0uA" rel="nofollow" target="_blank">https://zhuanlan.zhihu.com/p/96046514</a></p><p>[2] 提供的项目<br/><a href="https://link.segmentfault.com/?enc=cum4qs370ap%2B81QviJjNBw%3D%3D.sBM3yPFg0Z0q7LUo2wmIZw%2FA%2FUKhymLroDJ9TDLrtWC6Ci1Kp%2B3DiIy%2BufDPb4sD" rel="nofollow" target="_blank"/><a href="https://link.segmentfault.com/?enc=yzpdbNI0g0lTsIsHRb%2BieQ%3D%3D.hAs9vYh88kX50bNNdI1jgnXsg6s8sN%2FtMZSyP4D8Fi3LwAcpAY7%2FxgbE5QmEA2n0" rel="nofollow" target="_blank">https://www.alipan.com/s/P1Ve6cQYc1f</a></p><hr/><p>这是侑虎科技第1902篇文章，感谢作者狐王驾虎供稿。欢迎转发分享，未经作者授权请勿转载。如果您有任何独到的见解或者发现也欢迎联系我们，一起探讨。（QQ群：793972859）</p><p>作者主页：<a href="https://link.segmentfault.com/?enc=0u%2Fyebelbhqq%2FfY0J%2F071g%3D%3D.XSVOxkgEFiuIqgWDLaxbulPq7eH%2FgKh5rrKdr7YgbxuXVpPorqefXC3z1Ym7bLYR" rel="nofollow" target="_blank"/><a href="https://link.segmentfault.com/?enc=db2HI4pw1S6%2BsRJTczvVww%3D%3D.9VjU2gIyOV5JnHQpnZilJcD20FoA0Ehz7C4T3k0FkDmyD9o3oLK8hl9pGylln1HB" rel="nofollow" target="_blank">https://home.cnblogs.com/u/OwlCat</a></p><p>再次感谢狐王驾虎的分享，如果您有任何独到的见解或者发现也欢迎联系我们，一起探讨。（QQ群：793972859）</p>]]></description></item><item>    <title><![CDATA[LazyLLM教程 | 第14讲：实战：]]></title>    <link>https://segmentfault.com/a/1190000047389855</link>    <guid>https://segmentfault.com/a/1190000047389855</guid>    <pubDate>2025-11-11 18:17:45</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <blockquote>在前面的课程中，我们学习了 RAG 相关的知识，以及如何自定义 Reader 组件和在 RAG 任务中处理图片和表格数据。本节内容将在此基础上，利用前面学到的知识，搭建一个基于论文的问答系统。</blockquote><p>在信息爆炸的时代，科研论文的数量激增，研究人员在查阅文献时面临诸多挑战。论文内容专业性强、逻辑复杂，传统的关键词检索方式难以精准提取核心信息，导致获取有效内容的成本较高。</p><p>为了解决这一问题，<strong>RAG技术</strong>被广泛应用，RAG不仅能结合了检索能力，可以精准检索相关论文，还能结合大语言模型（LLM）的生成能力，对提问进行智能解析，提供深入、清晰的答案，帮助研究人员高效理解论文内容，提高科研效率。</p><p>本教程主要介绍如何利用 LazyLLM 搭建一个<strong>基于 RAG 的论文问答系统</strong>。为了实现该系统，我们需要为RAG准备并接入一个便于处理论文的<strong>解析器</strong>以及存储解析结果及向量化结果的<strong>数据存储器</strong>。让我们开始吧！</p><h2><strong>传统RAG的论文系统</strong></h2><h3><strong>（一）环境准备</strong></h3><p>如果您的电脑上安装了Python，请通过下方命令安装lazyllm及必要的依赖包。关于 LazyLLM 的环境更详细的准备可以参考《基础1-实战：最基础的RAG》中对应的内容。</p><pre><code>pip install lazyllm
</code></pre><h3><strong>（二）设计方案</strong></h3><h4><strong>1.整体架构</strong></h4><p>为了方便我们查阅论文或者快速了解相关论文的核心内容，我们可以用 RAG 设计一个<strong>论文问答系统</strong>。这个问答系统我们采用的是 <strong>Retrieve-and-rerank 架构</strong>，来保证检索内容的准确性以及生成结果的合理性。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389858" alt="" title=""/></p><p>这个框架中首先把所有需要处理的论文进行<strong>预处理</strong>，切分成 chunks，然后经过 embedding 模型，把相应的文本和对应的 embedding 存放到数据库中，这一步属于离线部分。</p><p>这一步处理完成后，就可以进行在线处理了。当提问的 query 来到之后先经过 embedding 模型，生成对应的 embedding 向量，然后使用这个 quey 和对应的 embedding 在数据库中进行检索，检索出相关的文本段出来，用于后面的处理。这一步属于<strong>粗筛</strong>，只要检索出相关的文本段即可，所以这里可以有基于关键字的检索，也可以有基于语义的检索方法。</p><p>为了使传给大模型的相关上下文更精准，我们还要对检索到的这些文本段进行一下<strong>精排</strong>，即 Rerank。Rerank 可以把多种检索策略下检索到的文本段在统一空间中进行比较，然后返回相似度最高 K 个，然后和前面的 query 一起拼接在一个给大模型做最后的结果生成。</p><h4><strong>2.方案流程</strong></h4><p>综上所述，要完成这个系统需要的步骤包括：</p><ul><li>步骤一：数据准备</li><li>步骤二：数据处理及组件搭建</li><li>步骤三：应用的流程编排</li><li>步骤四：代码调试</li><li>步骤五：效果校验</li><li>步骤六：体验效果是否符合要求，不符合要求就返回步骤三进行迭代优化。</li></ul><h3><strong>（三）实现方案</strong></h3><h4><strong>1.数据准备</strong></h4><p>首先我们需要准备构建知识库的数据，这里我们使用了 arxivQA（<a href="https://link.segmentfault.com/?enc=kHpQwgAnvuwgTbZqnOs1Hw%3D%3D.Pe0YkX%2FW716OHXMEACa1gRHsyuh9bUnwQLVWov60RkIBIP9Ic%2FvhExfvTjNfxWXr" rel="nofollow" target="_blank">https://github.com/taesiri/ArXivQA</a>），这个数据集中的 <a href="https://link.segmentfault.com/?enc=tKhCIX0hHVEpFxlPPx41Ng%3D%3D.636u27pxbAv%2BhZR9GJiN8%2BJkSQX02y%2BQwg0P9ohouGg%3D" rel="nofollow" target="_blank">Papers-2024.md</a> 文件中的前100篇论文，需要把这些论文下载到本地并保存到家目录下的 ".lazyllm/rag\_for\_qa/rag_master" 目录下。我们可以再在里面加一篇《DeepSeek-R1: Incentivizing Reasoning Capability in LLMs viaReinforcement Learning》文章。</p><h4><strong>2.组件搭建</strong></h4><p>在 LazyLLM 中，我们可以直接使用专门用于提取特定内容的Document解析器类，目前LazyLLM 内置的 Document可以支持 DOCX，PDF，PPT，EXCEL 等常见的富文本内容提取。接下来我们将一起使用LazyLLM 来构建我们的文档解析流程：</p><h5><strong>（1）文档解析器</strong></h5><p>我们首先需要使用LazyLLM的Document类创建一个基础的文档解析器：</p><p>（代码GitHub链接：<a href="https://link.segmentfault.com/?enc=8C7ZAVbO%2BRw5hq9Wp77AaQ%3D%3D.T%2Fx7xQSm9%2FHXmMbjl4lsHmCpLHY%2BAL%2F%2BGBtG4C%2BpOi5uVd3JArVml8qZGHM1bEC2y%2F%2FA0yn0Qz7yd6mmzHnBm5WpU5IXmo9bGRn%2F9NSC1cVD6qzkopsPKgqw0%2BRTqAUBtz%2FgrGt0BwOPHA2C2ewVweeOkAsjSF9ucqdnAfhainc%3D" rel="nofollow" target="_blank">https://github.com/LazyAGI/Tutorial/blob/a09a84cdf0585a5c9d52af6db0e965be95d03123/rag/codes/chapter14/BasciPDFReader.py#L1</a>）</p><pre><code>import os
import atexit
import lazyllm
class TmpDir:
    def __init__(self):
        self.root_dir = os.path.expanduser(os.path.join(lazyllm.config['home'], 'rag_for_qa'))
        self.rag_dir = os.path.join(self.root_dir, "rag_master")
        os.makedirs(self.rag_dir, exist_ok=True)
        self.store_file = os.path.join(self.root_dir, "milvus.db")
        self.image_path = "/home/workspace/LazyRAG-Enterprise/images"
tmp_dir = TmpDir()
documents = lazyllm.Document(dataset_path=tmp_dir.rag_dir)
documents.create_node_group(name="block", transform=lambda s: s.split("\n") if s else '')
</code></pre><p>以上代码使用 LazyLLM 框架的 Document 类来创建一个基础的文档解析器，并定义了一个 TmpDir 类来管理本地数据存储路径。主要功能包括：</p><p><strong>创建并管理数据存储目录</strong>：</p><ul><li>通过 TmpDir 类定义数据存储路径，包括 RAG 相关目录和数据库存储文件路径。</li><li>确保存储目录存在（若不存在则创建）。</li></ul><p><strong>使用 lazyllm.Document 管理文档数据</strong>：</p><ul><li>将rag\_master目录作为dataset\_path传递给 Document 类，用于使用LazyLLM内置的文档解析器加载文档数据。</li><li>定义 create\_node\_group 方法，以 "\n" 作为文本切分标识，将文档分割为多个节点。</li></ul><h5><strong>（2）创建检索器</strong></h5><p>在文档解析的基础上，我们可以构建一个<strong>检索器（Retriever）</strong>，用于高效地从解析后的文本数据中查找相关信息。通过调整数据处理及入库方式，我们可以观察这些改动对检索结果的影响。</p><p>现在，让我们一起使用 LazyLLM 框架中的 Retriever类来构建一个简单的文档检索器：</p><pre><code>retriever = lazyllm.Retriever(documents, group_name="block", similarity="bm25", topk=3, output_format='content')
</code></pre><p>以上代码使用 LazyLLM 框架的Retriever类创建了一个简单的检索器，其中我们将之前定义好的文档解析器作为参数传入到检索器中，并选择对解析器的"block"组，使用BM25 算法查找最匹配的 3 个段落，并返回文本内容。</p><p>在这个检索器中我们提到的BM25（Best Matching 25） 算法是一种用于文本检索的<strong>词频（TF）- 逆文档频率（IDF）</strong> 排序算法，是 <strong>Okapi BM25</strong> 的简称。它广泛用于搜索引擎、信息检索（IR）和自然语言处理（NLP）领域，能衡量文档与查询的相关性。</p><p>现在我们调用一次检索器，看一下当前文档解析方法的检索效果：</p><pre><code>print(retriever('deepseek-r1相关论文的Abstract'))
&gt;&gt; ['page_label: 1\n\nresearch@deepseek.com', 'page_label: 13\n\nClaude-3.5- GPT-4o DeepSeek OpenAI OpenAI DeepSeek', 'page_label: 1\n\nDeepSeek-AI']
</code></pre><p>当前检索结果的相关性较低，主要问题在于分块过小，导致信息碎片化，以及 BM25 依赖关键词匹配，难以精准捕捉语义关联。返回的片段内容过短，且未能直接命中 Abstract 相关信息，影响了查询效果。</p><p>为了提升召回质量，我们需要优化分块策略，确保每个文本块包含更完整的语义信息，并结合向量化检索提高语义匹配的精准度。</p><p>在接下来的部分，我们将通过<strong>自定义解析器</strong>优化分块方式，并引入<strong>向量化检索</strong>，以实现更高效的语义搜索。</p><h5><strong>（3）定义 PDF Reader</strong></h5><p>由于论文都是以 pdf 格式保存并且通常排版复杂、图表丰富，所以我们推荐使用高性能的 PDF 解析工具，来保证提取语义信息的完整性。 我们特别为业界领先的 PDF 文档解析工具 —— MinerU（<a href="https://link.segmentfault.com/?enc=zJqNmzyRN3zPoCGzSmIDZw%3D%3D.ypioxl8ZOOMc2lW6fuTFjftwMhjHveRLZfTAQR7IsS0ZcPKCGnsChmFAC0feIRHo" rel="nofollow" target="_blank">https://github.com/opendatalab/MinerU</a>），提供了专门的接入组件，无需额外定制，即可顺畅集成。</p><p>目前提供一键启动的 MinerU 服务端（server）以及配套的 PDF 客户端。使用流程如下：先在本地启动 MinerU 解析服务，再通过接入 MineruPDFReader 获取解析后的文档内容。</p><blockquote><strong>提示</strong>：在开始之前，请先确保安装了 MinerU 依赖哦（lazyllm install mineru 即可一键安装）。 为确保解析结果稳定，当前固定 MinerU 版本为2.5.4。服务运行所需资源请参考 MinerU 官方文档。</blockquote><p>环境准备完毕后，通过以下命令一键部署服务：</p><pre><code>lazyllm deploy mineru [--port &lt;port&gt;] [--cache_dir &lt;cache_dir&gt;] [--image_save_dir &lt;image_save_dir&gt;] [--model_source &lt;model_source&gt;]
</code></pre><p><strong>参数说明：</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389859" alt="" title="" loading="lazy"/></p><p>在本地启动好 MinerU解析服务后，我们只需要为 documents 对象注册用于PDF文件解析的解析器即可实现 MinerU 接入：</p><pre><code>from lazyllm.tools.rag.readers import MineruPDFReader
# 注册 PDF 解析器，url 替换为已启动的 MinerU 服务地址
documents.add_reader("*.pdf", MineruPDFReader(url="http://127.0.0.1:8888"))
</code></pre><pre><code>tmp_dir = TmpDir()
documents = lazyllm.Document(dataset_path=tmp_dir.rag_dir)
# 注册 PDF 解析器，url 替换为已启动的 MinerU 服务地址
documents.add_reader("**/*.pdf", MineruPDFReader(url="http://127.0.0.1:8888"))
documents.create_node_group(name="block", transform=lambda s: s.split("\n") if s else '')
retriever = lazyllm.Retriever(documents, group_name="block", similarity="bm25", topk=3, output_format='content')
print(retriever('deepseek-r1相关论文的Abstract'))
&gt;&gt;["title: DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning\ntype: text\nbbox: [264, 179, 330, 192]\nlines: [{'bbox': [264, 179, 331, 194], 'content': 'DeepSeek-AI', 'type': 'text', 'page': 0}]\npage: 0\n\nDeepSeek-AI", "title: Abstract\ntype: text\nbbox: [69, 287, 527, 430]\nlines: [{'bbox': [69, 287, 527, 303], 'content': 'We introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1.', 'type': 'text', 'page': 0}, {'bbox': [70, 302, 526, 317], 'content': 'DeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without super-', 'type': 'text', 'page': 0}, {'bbox': [69, 317, 526, 331], 'content': 'vised fine-tuning (SFT) as a preliminary step, demonstrates remarkable reasoning capabilities.', 'type': 'text', 'page': 0}, {'bbox': [68, 329, 526, 347], 'content': 'Through RL, DeepSeek-R1-Zero naturally emerges with numerous powerful and intriguing', 'type': 'text', 'page': 0}, {'bbox': [68, 344, 527, 362], 'content': 'reasoning behaviors. However, it encounters challenges such as poor readability, and language', 'type': 'text', 'page': 0}, {'bbox': [69, 359, 526, 375], 'content': 'mixing. To address these issues and further enhance reasoning performance, we introduce', 'type': 'text', 'page': 0}, {'bbox': [70, 375, 527, 389], 'content': 'DeepSeek-R1, which incorporates multi-stage training and cold-start data before RL. DeepSeek-', 'type': 'text', 'page': 0}, {'bbox': [68, 388, 526, 404], 'content': 'R1 achieves performance comparable to OpenAI-o1-1217 on reasoning tasks. To support the', 'type': 'text', 'page': 0}, {'bbox': [69, 403, 526, 417], 'content': 'research community, we open-source DeepSeek-R1-Zero, DeepSeek-R1, and six dense models', 'type': 'text', 'page': 0}, {'bbox': [70, 418, 474, 431], 'content': '(1.5B, 7B, 8B, 14B, 32B, 70B) distilled from DeepSeek-R1 based on Qwen and Llama.', 'type': 'text', 'page': 0}]\npage: 0\n\nWe introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1. DeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without supervised fine-tuning (SFT) as a preliminary step, demonstrates remarkable reasoning capabilities. Through RL, DeepSeek-R1-Zero naturally emerges with numerous powerful and intriguing reasoning behaviors. However, it encounters challenges such as poor readability, and language mixing. To address these issues and further enhance reasoning performance, we introduce DeepSeek-R1, which incorporates multi-stage training and cold-start data before RL. DeepSeekR1 achieves performance comparable to OpenAI-o1-1217 on reasoning tasks. To support the research community, we open-source DeepSeek-R1-Zero, DeepSeek-R1, and six dense models (1.5B, 7B, 8B, 14B, 32B, 70B) distilled from DeepSeek-R1 based on Qwen and Llama.", "title: DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning\ntype: text\nbbox: [236, 203, 358, 215]\nlines: [{'bbox': [236, 205, 358, 216], 'content': 'research@deepseek.com', 'type': 'text', 'page': 0}]\npage: 0\n\nresearch@deepseek.com"]
</code></pre><p>通过与加入自定义解析器之前的结果对比，当前虽然分块质量有所提升，文本块的完整性比之前更好，但由于检索仍然依赖 BM25 进行关键词匹配，召回效果依然受到限制。BM25 无法理解语义，仅根据词频进行匹配，导致返回的内容仍包含目录、致谢等无关信息，而 未能精准找到 Abstract。</p><p>接下来，我们将引入向量化检索，提升语义匹配能力，以实现更精准的内容查找。</p><h5><strong>（4）向量化检索</strong></h5><p><strong>4.1 配置数据存储</strong></p><p>LazyLLM 提供了可配置存储和索引后端的功能，其中milvus可以以在线服务的形式，通过配置url进行调用，同时也支持使用本地临时文件的形式快速搭建存储模块。这里我们选择使用本地临时文件形式的 milvus 来存储数据。</p><p>（代码GitHub链接：<a href="https://link.segmentfault.com/?enc=SH%2Fm49shxH9Ib5IJ7FLzWQ%3D%3D.qYTQBLBk%2BxRlS907UYQh2mF4SsyGo9L28rh9%2B1V%2F0FSyRo2Gy6KKpJKjxGvTsNetKX%2B00q0spNGcXH5er5WyuEVuKMYEHY6MLobr%2B0ifydglwIw0%2FPDLXIImMNaE7HU2OUbHCDhCpaPcgMyezCVc60brL%2BiZwQG1CwG2oa4UCCdBLN%2FwKa84vLUbOs%2BNplcO" rel="nofollow" target="_blank">https://github.com/LazyAGI/Tutorial/blob/a09a84cdf0585a5c9d52af6db0e965be95d03123/rag/codes/chapter14/MagicPDFReader_Milvus.py#L390</a>）</p><pre><code>import lazyllm
from lazyllm.tools.rag import DocField, DataType
import os
import atexit
class TmpDir:
    def __init__(self):
        self.root_dir = os.path.expanduser(os.path.join(lazyllm.config['home'], 'rag_for_qa'))
        self.rag_dir = os.path.join(self.root_dir, "rag_master")
        os.makedirs(self.rag_dir, exist_ok=True)
        self.store_file = os.path.join(self.root_dir, "milvus.db")
        self.image_path = "Stored Images Path"
        atexit.register(self.cleanup)
    def cleanup(self):
        if os.path.isfile(self.store_file):
            os.remove(self.store_file)
        for filename in os.listdir(self.image_path):
            filepath = os.path.join(self.image_path, filename)
            if os.path.isfile(filepath):
                os.remove(filepath)
tmp_dir = TmpDir()
# 本地存储
milvus_store_conf = {
    "type": "milvus",
    "kwargs": {
        'uri': tmp_dir.store_file,
        'index_kwargs': {
            'index_type': 'HNSW',
            'metric_type': "COSINE",
        }
    },
}
# 在线服务
# milvus_store_conf = {
#     "type": "milvus",
#     "kwargs": {
#         'uri': "http://your-milvus-server",
#         'index_kwargs': {
#             'index_type': 'HNSW',
#             'metric_type': "COSINE",
#         }
#     },
# }
doc_fields = {
    'comment': DocField(data_type=DataType.VARCHAR, max_size=65535, default_value=' '),
    'signature': DocField(data_type=DataType.VARCHAR, max_size=32, default_value=' '),
}
</code></pre><p>在上面的代码中，首先定义了一个<strong>临时目录</strong>，用来存放数据和数据库文件。其中里面定义了一个 cleanup 函数，用于程序结束后清理数据库文件和图片文件，并使用 atexit (该模块的主要功能是注册回调函数，这些回调函数会在 Python 解释器即将正常退出时被调用)把自定义的清理函数进行注册。</p><p>然后定义了 milvus 的<strong>配置文件</strong>，主要包括类型、uri、索引的类型和策略。</p><p>这里就会涉及到<strong>milvus 的两种使用方式</strong>了，一种是使用临时文件的方式，即上面代码中在 milvus 的配置文件中的 uri 指定为本地数据的路径。另一种是使用现有的 milvus 服务的方式，我们只要把 milvus 服务的 url 赋给 milvus 的配置文件中的 uri 即可。最后定义了数据的属性。</p><p><strong>4.2 配置文本嵌入</strong></p><p>LazyLLM 提供了模型的推理服务，我们可以使用TrainableModule直接将Embedding模型作为服务启动，并自动接入我们的文档解析器中。</p><pre><code>embed = lazyllm.TrainableModule("bge-large-zh-v1.5")
</code></pre><p>接下来，我们将前面准备好的 milvus 和 Embedding接入到文档解析器中，并查看一下效果：</p><p>（代码GitHub链接：<a href="https://link.segmentfault.com/?enc=4o1ONzhZ5GlUYT1bt4aglA%3D%3D.zdm46fy8HUyTSSzXjuYuSFgriZ04guIZyEFBfPXHZm98uFy628IIJPiERG1AOqNAL9og3EyTqkyJdN%2BL7KrVCYASkyvkkq7NFH4nqLVR805oB0czRIOqVKmiD2jyVCIya%2FWvuA8J%2FW17W1wCbxBatNtND1YKK1RKJRPsElh7b%2BOhYbm501aGszLg415ypMfs" rel="nofollow" target="_blank">https://github.com/LazyAGI/Tutorial/blob/a09a84cdf0585a5c9d52af6db0e965be95d03123/rag/codes/chapter14/MagicPDFReader_Milvus.py#L440</a>）</p><pre><code>documents = lazyllm.Document(dataset_path=tmp_dir.rag_dir,
                             embed=embed.start(),
                             manager=True,
                             store_conf=milvus_store_conf,
                             doc_fields=doc_fields
                             )
documents.add_reader("**/*.pdf", MineruPDFReader(url="http://127.0.0.1:8888"))
documents.create_node_group(name="block", transform=lambda s: s.split("\n") if s else '')
retriever = lazyllm.Retriever(documents, group_name="block", topk=3, output_format='content')
print(retriever('deepseek-r1相关论文的Abstract'))
# &gt;&gt;&gt; ["page: 0\ntitle: DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning\nbbox: [264, 179, 330, 192]\ntype: text\nlines: [{'bbox': [264, 179, 331, 194], 'content': 'DeepSeek-AI', 'type': 'text', 'page': 0}]\n\nDeepSeek-AI", "page: 0\ntitle: Abstract\nbbox: [69, 287, 527, 430]\ntype: text\nlines: [{'bbox': [69, 287, 527, 303], 'content': 'We introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1.', 'type': 'text', 'page': 0}, {'bbox': [70, 302, 526, 317], 'content': 'DeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without super-', 'type': 'text', 'page': 0}, {'bbox': [69, 317, 526, 331], 'content': 'vised fine-tuning (SFT) as a preliminary step, demonstrates remarkable reasoning capabilities.', 'type': 'text', 'page': 0}, {'bbox': [68, 329, 526, 347], 'content': 'Through RL, DeepSeek-R1-Zero naturally emerges with numerous powerful and intriguing', 'type': 'text', 'page': 0}, {'bbox': [68, 344, 527, 362], 'content': 'reasoning behaviors. However, it encounters challenges such as poor readability, and language', 'type': 'text', 'page': 0}, {'bbox': [69, 359, 526, 375], 'content': 'mixing. To address these issues and further enhance reasoning performance, we introduce', 'type': 'text', 'page': 0}, {'bbox': [70, 375, 527, 389], 'content': 'DeepSeek-R1, which incorporates multi-stage training and cold-start data before RL. DeepSeek-', 'type': 'text', 'page': 0}, {'bbox': [68, 388, 526, 404], 'content': 'R1 achieves performance comparable to OpenAI-o1-1217 on reasoning tasks. To support the', 'type': 'text', 'page': 0}, {'bbox': [69, 403, 526, 417], 'content': 'research community, we open-source DeepSeek-R1-Zero, DeepSeek-R1, and six dense models', 'type': 'text', 'page': 0}, {'bbox': [70, 418, 474, 431], 'content': '(1.5B, 7B, 8B, 14B, 32B, 70B) distilled from DeepSeek-R1 based on Qwen and Llama.', 'type': 'text', 'page': 0}]\n\nWe introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1. DeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without supervised fine-tuning (SFT) as a preliminary step, demonstrates remarkable reasoning capabilities. Through RL, DeepSeek-R1-Zero naturally emerges with numerous powerful and intriguing reasoning behaviors. However, it encounters challenges such as poor readability, and language mixing. To address these issues and further enhance reasoning performance, we introduce DeepSeek-R1, which incorporates multi-stage training and cold-start data before RL. DeepSeekR1 achieves performance comparable to OpenAI-o1-1217 on reasoning tasks. To support the research community, we open-source DeepSeek-R1-Zero, DeepSeek-R1, and six dense models (1.5B, 7B, 8B, 14B, 32B, 70B) distilled from DeepSeek-R1 based on Qwen and Llama.", "page: 1\ntitle: Abstract\nbbox: [83, 197, 511, 224]\ntype: text\nlines: [{'bbox': [84, 198, 510, 214], 'content': 'Table 2 | Comparison of DeepSeek-R1-Zero and OpenAI o1 models on reasoning-related', 'type': 'text', 'page': 1}, {'bbox': [265, 212, 330, 226], 'content': 'benchmarks.', 'type': 'text', 'page': 1}]\n\nTable 2 | Comparison of DeepSeek-R1-Zero and OpenAI o1 models on reasoning-related benchmarks."]
</code></pre><p>从结果来看，当前的检索器已经能够成功返回与查询相关的论文摘要内容，并且提取出了正确的Abstract段落。</p><p>接下来，为了进一步提升结果的准确性和排序质量，可以考虑引入一个<strong>重排模块（Reranker）</strong>。该模块可以基于文档的相关性或其他标准对结果进行重新排序，确保最相关的文档排在最前面。这不仅可以提高用户体验，还能增强模型对搜索结果排序的精度。</p><h5><strong>（5）创建重排器</strong></h5><p>RAG架构中先使用 Retriever 进行候选文档的快速检索，然后通过 Reranker 进行精细化排序，这样的设计能够在保证检索效率的同时，提升结果的相关性和排序精度。Reranker 能够对 Retriever 检索的结果进行深度理解和优化，是一个提升系统整体性能的关键步骤。</p><p>LazyLLM 提供了Reranker组件，我们可以像启动其他模型服务一样，便捷的将Reranker也作为服务启动。</p><pre><code>reranker = lazyllm.Reranker(name='ModuleReranker',
                            model="bge-reranker-large",
                            topk=1,
                            output_format='content',
                            join=True).start()</code></pre><p>通过引入 bge-reranker-large 模型作为 Reranker，可以进一步提高文档检索和排序的精度。这对于提高系统的准确性非常重要，尤其是在复杂的查询任务中。这个过程结合了快速的检索和精细的重排，能确保用户得到最相关、最有用的结果。</p><p>现在我们将Reranker也接入到检索流程中，在检索之后通过Reranker对Retriever检索到的节点进行二次排序</p><p>（代码GitHub链接：<a href="https://link.segmentfault.com/?enc=HK8WeUtnSabU2Pvt%2BLA17A%3D%3D.nWMPu%2BvratPR9gRnis931GBNqQ5Q%2Blkb9JF7VU4nuQ690tqHDbkWoNibYlhPZcZcUuNO4dIxL5lTjhMQYdtvpBF%2BA5sBU6nig7ol8nzw5nan11DsbAnZMXzBEhIdf0Be%2B0Z463WRf05%2BczlXnNo8rVQivc9l8FJMjqcAiYzzHQBcBaavsxGb6pggH0Ce2LXYyuuVUfUtD%2Bcxd6ZjFXOTKw%3D%3D" rel="nofollow" target="_blank">https://github.com/LazyAGI/Tutorial/blob/a09a84cdf0585a5c9d52af6db0e965be95d03123/rag/codes/chapter14/MagicPDFReader\_Milvus\_Reranker.py#L454）</a></p><pre><code>...
query = "deepseek-r1相关论文的Abstract"
retriever = lazyllm.Retriever(documents, group_name="block", topk=3)
ret_nodes = retriever(query)
reranker = lazyllm.Reranker(name='ModuleReranker',
                            model="/mnt/lustre/share_data/lazyllm/models/bge-reranker-large",
                            topk=1,
                            output_format='content',
                            join=True).start()

context = reranker(nodes=ret_nodes ,query=query)
print(context)
&gt;&gt; '''type: text
page: 0
bbox: [69, 287, 527, 430]
title: Abstract
lines: [{'bbox': [69, 287, 527, 303], 'content': 'We introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1.', 'type': 'text', 'page': 0}, {'bbox': [70, 302, 526, 317], 'content': 'DeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without super-', 'type': 'text', 'page': 0}, {'bbox': [69, 317, 526, 331], 'content': 'vised fine-tuning (SFT) as a preliminary step, demonstrates remarkable reasoning capabilities.', 'type': 'text', 'page': 0}, {'bbox': [68, 329, 526, 347], 'content': 'Through RL, DeepSeek-R1-Zero naturally emerges with numerous powerful and intriguing', 'type': 'text', 'page': 0}, {'bbox': [68, 344, 527, 362], 'content': 'reasoning behaviors. However, it encounters challenges such as poor readability, and language', 'type': 'text', 'page': 0}, {'bbox': [69, 359, 526, 375], 'content': 'mixing. To address these issues and further enhance reasoning performance, we introduce', 'type': 'text', 'page': 0}, {'bbox': [70, 375, 527, 389], 'content': 'DeepSeek-R1, which incorporates multi-stage training and cold-start data before RL. DeepSeek-', 'type': 'text', 'page': 0}, {'bbox': [68, 388, 526, 404], 'content': 'R1 achieves performance comparable to OpenAI-o1-1217 on reasoning tasks. To support the', 'type': 'text', 'page': 0}, {'bbox': [69, 403, 526, 417], 'content': 'research community, we open-source DeepSeek-R1-Zero, DeepSeek-R1, and six dense models', 'type': 'text', 'page': 0}, {'bbox': [70, 418, 474, 431], 'content': '(1.5B, 7B, 8B, 14B, 32B, 70B) distilled from DeepSeek-R1 based on Qwen and Llama.', 'type': 'text', 'page': 0}]'''
</code></pre><p>我们将Retriever检索到的节点和query给到Reranker，并要求Reranker只返回最相关的一个文段后，我们成功的拿到了正确的Abstract段落。</p><h5><strong>（6）配置大模型</strong></h5><p>至此，我们已完成数据基础的解析、入库以及相关文段的召回。借助 Retriever 的高效检索，我们能够从海量文档库中精准提取与查询高度相关的内容，并通过 Reranker 进一步优化排序，确保最相关的文段位于前列，从而提升检索质量和结果的精准度。</p><p>接下来，我们将进入RAG(Retrieval-Augmented Generation) 的最后一步——<strong>生成(Generation)</strong>。在这一阶段，我们会将经过召回与重排的文段与用户的查询一同传递给大语言模型(LLM)，让其基于提供的信息进行深度理解、综合分析，并最终生成精准、连贯的回答。</p><p>LazyLLM 提供了高效的模型推理服务，并支持本地模型推理和在线模型服务两种形式，分别通过 TrainableModule 和OnlineChatModule 进行配置。</p><pre><code>...
prompt = 'You will play the role of an AI Q&amp;A assistant and complete a dialogue task.'\
    ' In this task, you need to provide your answer based on the given context and question.'\
    ' If an image can better convey the information being expressed, please include the image reference'\
    ' in the text in Markdown format. Keep the image path in its original format.'

# 使用本地模型并生成推理服务
llm = lazyllm.TrainableModule('internlm2-chat-7b').start()
# 使用线上模型推理服务
# llm = lazyllm.OnlineChatModule(api_key="", source="")
# 使用lazyllm.ChatPrompter配置模型推理对话模板
llm = llm.prompt(lazyllm.ChatPrompter(instruction=prompt, extra_keys=['context_str']))
print(llm({"context_str": context, "query":query}))</code></pre><p>在以上的代码中，我们定义并启动了一个LLM服务，并使用lazyllm.ChatPrompter配置了推理模板。至此，我们已完成 LLM 服务的配置，并结合 Retriever + Reranker，完整的构建了一个简单的RAG，实现高效的检索增强问答流程。</p><h3><strong>（四）建知识库</strong></h3><p>通过上面各个模块组件的了解，我们需要先利用上面的基于 Mineru 的 Reader 模块、文档解析器、文档检索器、数据库配置以及向量化模块构建知识库。代码如下：</p><p>（代码GitHub链接：<a href="https://link.segmentfault.com/?enc=9Lufffn6NsCtkd5dP1x3CQ%3D%3D.PyMsAUnwtjQcUrKA1cFRAT8llRGkCKXBo%2BAfHEk5xSlzMudo5h3FlD9d8W6g0wDJQvB8UmGkJRi7SgtCjUCIao1596vMfqiKWkXmt1D2FJCnz2NaYT9W7fJ4Ku88qNpf" rel="nofollow" target="_blank">https://github.com/LazyAGI/Tutorial/blob/main/rag/codes/chapter14/BulidMilvus_db.py</a>）</p><pre><code>import os
import lazyllm
from lazyllm.tools.rag import DocField, DataType
from lazyllm.tools.rag.readers import MineruPDFReader
def get_cache_path():
    return os.path.join(lazyllm.config['home'], 'rag_for_qa')
def get_image_path():
    return os.path.join(get_cache_path(), "images")
class TmpDir:
    def __init__(self):
        self.root_dir = os.path.expanduser(os.path.join(lazyllm.config['home'], 'rag_for_qa'))
        self.rag_dir = os.path.join(self.root_dir, "rag_master")
        os.makedirs(self.rag_dir, exist_ok=True)
        self.store_file = os.path.join(self.root_dir, "milvus.db")
        self.image_path = get_image_path()
        # atexit.register(self.cleanup)
    def cleanup(self):
        if os.path.isfile(self.store_file):
            os.remove(self.store_file)
        for filename in os.listdir(self.image_path):
            filepath = os.path.join(self.image_path, filename)
            if os.path.isfile(filepath):
                os.remove(filepath)
tmp_dir = TmpDir()
# 本地存储
milvus_store_conf = {
    "type": "milvus",
    "kwargs": {
        'uri': tmp_dir.store_file,
        'index_kwargs': {
            'index_type': 'HNSW',
            'metric_type': "COSINE",
        }
    },
}
# 在线服务
# milvus_store_conf = {
#     "type": "milvus",
#     "kwargs": {
#         'uri': "http://your-milvus-server",
#         'index_kwargs': {
#             'index_type': 'HNSW',
#             'metric_type': "COSINE",
#         }
#     },
# }
doc_fields = {
    'comment': DocField(data_type=DataType.VARCHAR, max_size=65535, default_value=' '),
    'signature': DocField(data_type=DataType.VARCHAR, max_size=32, default_value=' '),
}
if __name__ == "__main__":
    prompt = 'You will play the role of an AI Q&amp;A assistant and complete a dialogue task.'\
        ' In this task, you need to provide your answer based on the given context and question.'\
        ' If an image can better present the information being expressed, please include the image reference'\
        ' in the text in Markdown format. The markdown format of the image must be as follows:'\
        ' ![image_name](file=image path)'
    documents = lazyllm.Document(dataset_path=tmp_dir.rag_dir,
                                 embed=lazyllm.TrainableModule("bge-large-zh-v1.5").start(),
                                 manager=False,
                                 store_conf=milvus_store_conf,
                                 doc_fields=doc_fields)
    documents.add_reader("*.pdf", MineruPDFReader(url="http://127.0.0.1:8888"))   # url 需替换为已启动的 MinerU 服务地址
    documents.create_node_group(name="block", transform=lambda s: s.split("\n") if s else '')
    retriever = lazyllm.Retriever(doc=documents, group_name="block", topk=3)
    retriever("什么是机器学习")
</code></pre><p>这里我们选用的是<strong>临时配置文件</strong>的方式使用 milvus 数据库，这里需要配置使用的知识库文档的路径，以及构建的数据库存放路径。</p><p>这里需要注意一下，在定义临时配置文件的时候需要把 atexit.register(self.cleanup)这行代码注释掉，因为我们的目的是想离线把数据处理完然后放入数据库中，方便线上使用，所以我们希望运行完代码之后还要保留数据库和图片文件。所以这里就不能再配置清理函数了。</p><p>对于为什么要在最后定义 Retriever 对象，并且还要调用一下retriever，是因为 LazyLLM 里面构建知识库的操作属于延迟加载，需要在检索前才会进行加载，所以离线构建知识库的时候需要调用 Retriever对象检索来触发一下。当然如果文档少的话也可以直接在启动服务的时候进行加载。</p><h4><strong>1.编排应用</strong></h4><p>上面我们已经定义好了 Reader 和存储配置，下面我们就可以搭建 RAG 的工作流了。</p><p>（代码GitHub链接：<a href="https://link.segmentfault.com/?enc=22MU6tjuvCqmIptodNYweg%3D%3D.PiptN3LhssJu1%2B2jqBXPOjCrFUDT8YDLjEA8d4d%2FXXYKeOZ6pYQry6VFRiZ3LtCFPPjydFBXnyLNfJU%2BEBSlaN0gwd85z6QlGrhqAws%2BilYuNagBkwQWFJ0QEOBjMazt5v70JWyOKNpNytuTJHjJd98d9wqLc6bicRw7zJ%2BsRgo%3D" rel="nofollow" target="_blank">https://github.com/LazyAGI/Tutorial/blob/a09a84cdf0585a5c9d52af6db0e965be95d03123/rag/codes/chapter14/PaperQA_basic.py#L439</a>）</p><pre><code>import lazyllm
 
prompt = 'You will play the role of an AI Q&amp;A assistant and complete a dialogue task.'\
    ' In this task, you need to provide your answer based on the given context and question.'\
    ' If an image can better convey the information being expressed, please include the image reference'\
    ' in the text in Markdown format. Keep the image path in its original format.'
 
documents = lazyllm.Document(dataset_path=tmp_dir.rag_dir,
                             embed=lazyllm.TrainableModule("bge-large-zh-v1.5"),
                             manager=True,
                             store_conf=milvus_store_conf,
                             doc_fields=doc_fields)
 
documents.add_reader("*.pdf", MineruPDFReader(url="http://127.0.0.1:8888"))   # url 需替换为已启动的 MinerU 服务地址
documents.create_node_group(name="block", transform=lambda s: s.split("\n") if s else '')
 
with lazyllm.pipeline() as ppl:
    ppl.retriever = lazyllm.Retriever(doc=documents, group_name="block", topk=3)
    ppl.reranker = lazyllm.Reranker(name='ModuleReranker',
                                    model="bge-reranker-large",
                                    topk=1,
                                    output_format='content',
                                    join=True) | bind(query=ppl.input)
 
    ppl.formatter = (
        lambda nodes, query: dict(context_str=nodes, query=query)
    ) | bind(query=ppl.input)
 
    ppl.llm = lazyllm.TrainableModule('internlm2-chat-7b').prompt(
        lazyllm.ChatPrompter(instruction=prompt, extra_keys=['context_str']))
 
lazyllm.WebModule(ppl, port=23456, static_paths="Stored Images Path").start().wait()
</code></pre><p>在上面的代码中，我们先定义了 prompt 和 documents，在定义 documents 时，指定了数据集目录和embedding 模型，以及管理数据库用到的存储配置和字段属性。然后通过 documents 对象注册了自定义的 Reader 类，然后定义创建 node group 的名字和转换规则。</p><p>接下来就是工作流的搭建了，在 pipeline 中，依次定义了 Retriever、Reranker、formatter 和 LLM，分别用于检索召回相关文档、对召回文档信息进行重排序、对重排序后的 node 和 query 进行格式化，最后把检索到的内容输入给 LLM 来生成相应的答案回复。</p><p>最后通过 WebModule 模块把上面搭建的 pipeline 启动成一个 web 服务，这里需要注意，启动 WebModule 时，需要传入图片的保存路径，这样就可以把该目录设置为静态目录，gradio 就可以直接访问该目录下的图片文件了。当 web 服务启动成功后，则根据生成的 ip 和 port，我们就可以在浏览器中进行使用体验。</p><h4><strong>2.效果展示</strong></h4><p>在下图展示的示例中，用户向系统询问 论文《DeepSeek-R1: Incentivizing Reasoning Capability in LLMs viaReinforcement Learning》的相关内容，系统首先检索到相关段落，并基于其内容生成了精准的回答。同时，系统还能智能提取论文中的图表信息，并将其检索与展示，使用户不仅能获取文本解析，还能直观查看论文中的关键数据与实验结果。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389860" alt="" title="" loading="lazy"/></p><p>通过本系统，研究人员可以高效地获取论文信息，而无需逐字阅读整篇论文，大大提高了科研工作的便捷性和效率。</p><h2><strong>朴素多模态RAG的论文系统</strong></h2><h3><strong>（一）多模态嵌入</strong></h3><h4><strong>1.方案一</strong></h4><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389861" alt="" title="" loading="lazy"/></p><p>统一到文本模态，然后进行向量嵌入</p><h4><strong>2.方案二</strong></h4><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389862" alt="" title="" loading="lazy"/></p><p>统一到向量空间：利用多模态模型进行映射</p><h3><strong>（二）方案一：统一到文本模态</strong></h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389863" alt="" title="" loading="lazy"/></p><p>如果在解析的过程单独为图片生成描述并构建ImageDocNode节点，可以在原来的 MineruPDFReader 组件传入一个后处理函数（注意后处理函数的输入和输出都应为List[DocNode]）：</p><pre><code>vlm = lazyllm.TrainableModule(‘internvl-chat-v1-5’).start()   # 初始化一个多模态大模型
def build_image_docnode(nodes):
    img_nodes = []
    for node in nodes:
        if node.metadata.get("type", None) == "image" and node.metadata.get("image_path", None):
            img_desc = vlm(formatted_query(node.image_path))                  # 利用VLM对图像内容进行解析生成图像的文本描述
            img_nodes.append(ImageDocNode(text=img_desc, image_path=node.metadata.get("image_path"), global_metadata=node.metadata)) # 构建ImageDocNode节点 
    return nodes + img_nodes
 
 
documents.add_reader("*.pdf", MineruPDFReader(url="http://127.0.0.1:8888", post_func=build_image_docnode))   # 这里传入你的后处理函数
</code></pre><h4><strong>1.应用编排实现</strong></h4><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389864" alt="" title="" loading="lazy"/></p><pre><code>    documents = lazyllm.Document(
        dataset_path=tmp_dir.rag_dir,
        embed=lazyllm.TrainableModule("bge-m3"),
        manager=False)
    documents.add_reader("*.pdf", MineruPDFReader(url="http://127.0.0.1:8888", post_func=build_image_docnode))   # url 需替换为已启动的 MinerU 服务地址
    documents.create_node_group(name="block", transform=lambda s: s.split("\n") if s else '')
    with lazyllm.pipeline() as ppl:
        with lazyllm.parallel().sum as ppl.prl:
            ppl.prl.retriever1 = lazyllm.Retriever(documents, group_name="block", similarity="cosine", topk=1)
            ppl.prl.retriever2 = lazyllm.Retriever(documents, lazyllm.Document.ImgDesc, similarity="cosine", topk=1)
        ppl.prompt = build_vlm_prompt | bind(_0, ppl.input)
        ppl.vlm = lazyllm.OnlineChatModule()
    lazyllm.WebModule(ppl, port=range(23468, 23470), static_paths=get_image_path()).start().wait()
</code></pre><h4><strong>2.效果展示</strong></h4><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389865" alt="" title="" loading="lazy"/></p><p>block节点组召回内容：</p><pre><code>We introduce our frst-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1. DeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without supervised fne-tuning (SFT) as a preliminary step, demonstrates remarkable reasoning capabilities. Through RL, DeepSeek-R1-Zero naturally emerges with numerous powerful and intriguing reasoning behaviors. However, it encounters challenges such as poor readability, and language mixing. To address these issues and further enhance reasoning performance, we introduce DeepSeek-R1, which incorporates multi-stage training and cold-start data before RL. DeepSeekR1 achieves performance comparable to OpenAI-o1-1217 on reasoning tasks. To support the research community, we open-source DeepSeek-R1-Zero, DeepSeek-R1, and six dense models (1.5B, 7B, 8B, 14B, 32B, 70B) distilled from DeepSeek-R1 based on Qwen and Llama.
</code></pre><p>info节点组召回内容：</p><pre><code>这张图片是一张柱状图，标题为“DeepSeek-R1 OpenAI-01-1217 DeepSeek-R1-32B OpenAI-01-mini DeepSeek-V3”。图表展示了六种不同模型的性能百分比，每种模型都以不同颜色的条形表示。
从左到右，第一列条形代表“AIMER 2024”模型，第二列代表“Codeforces”模型，第三列代表“GPOA Diamond”模型，第四列代表“MATH-500”模型，第五列代表“MMLU”模型，最后一列代表“SWE-bench Verified”模型。
每组条形都有五条，颜色分别为蓝色、灰色、橙色、黄色和紫色，分别对应不同的性能指标。
在图表下方，有五个百分比数值，分别对应每个模型的性能指标。这些数值以从左到右的顺序排列，与条形的颜色相对应。
整个图表以白色为背景，柱状图的颜色与背景形成对比，易于区分。
</code></pre><h3><strong>（三）方案二：统一到向量空间</strong></h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389866" alt="" title="" loading="lazy"/></p><p>统一到向量空间，两种方案：</p><p><strong>方案A：不同模态用对应的embedding</strong>:</p><ul><li>文本：用文本的embedding</li><li>图像：用图像的embedding</li></ul><p><strong>方案B：用多模态embedding</strong>:</p><ul><li>图文都用同一个embedding</li></ul><p>这里用了方案A，可以展示多embedding的使用。</p><h4><strong>1.应用编排实现</strong></h4><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389867" alt="" title="" loading="lazy"/></p><pre><code>embed_multimodal = lazyllm.TrainableModule("colqwen2-v0.1")
embed_text = lazyllm.OnlineEmbeddingModule(
    source='qwen', embed_model_name='text-embedding-v1')
embeds = {'vec1': embed_text, 'vec2': embed_multimodal}
documents = lazyllm.Document(
    dataset_path=tmp_dir.rag_dir, embed=embeds, manager=False)
documents.add_reader("*.pdf", MineruPDFReader(url="http://127.0.0.1:8888", post_func=build_image_docnode))
documents.create_node_group(name="block", transform=lambda s: s.split("\n") if s else '')
with lazyllm.pipeline() as ppl:
    with lazyllm.parallel().sum as ppl.prl:
        ppl.prl.retriever1 = lazyllm.Retriever(documents, group_name="block", embed_keys=['vec1'], similarity="cosine", topk=1)
        ppl.prl.retriever2 = lazyllm.Retriever(documents, group_name="Image", embed_keys=['vec2'], similarity="maxsim", topk=2)
    ppl.prompt = build_vlm_prompt | bind(_0, ppl.input)
    ppl.vlm = lazyllm.OnlineChatModule(source="sensenova", model="SenseNova-V6-Turbo").prompt(lazyllm.ChatPrompter(gen_prompt))
lazyllm.WebModule(ppl, port=range(23468, 23470), static_paths=get_image_path()).start().wait()
</code></pre><h4><strong>2.效果展示</strong></h4><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389868" alt="" title="" loading="lazy"/></p><p>block节点组召回内容：</p><pre><code>For education-oriented knowledge benchmarks such as MMLU, MMLU-Pro, and GPQA Diamond, DeepSeek-R1 demonstrates superior performance compared to DeepSeek-V3. This improvement is primarily attributed to enhanced accuracy in STEM-related questions, where significant gains are achieved through large-scale reinforcement learning. Additionally, DeepSeek-R1 excels on FRAMES, a long-context-dependent QA task, showcasing its strong document analysis capabilities. This highlights the potential of reasoning models in AI-driven search and data analysis tasks. On the factual benchmark SimpleQA, DeepSeek-R1 outperforms DeepSeek-V3, demonstrating its capability in handling fact-based queries. A similar trend is observed where OpenAI-o1 surpasses GPT-4o on this benchmark. However, DeepSeek-R1 performs worse than DeepSeek-V3 on the Chinese SimpleQA benchmark, primarily due to its tendency to refuse answering certain queries after safety RL. Without safety RL, DeepSeek-R1 could achieve an accuracy of over 70%.
</code></pre><p>image节点组召回内容：</p><pre><code>/home/mnt/sunxiaoye/.lazyllm/rag_for_qa/images/c357bd57757e4c544fdda3ad32066e64c5d01bb8540066f1a722c8872d664183.jpg
/home/mnt/sunxiaoye/.lazyllm/rag_for_qa/images/2c6271b8cecc68d5b3c22e552f407a5e97d34030f91e15452c595bc8a76e291c.jpg
</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389869" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389870" alt="" title="" loading="lazy"/></p><h2><strong>论文系统的效果优化</strong></h2><h3><strong>（一）改进方案</strong></h3><p>针对上述论文问答助手，我们还可以从以下几个角度进行优化：</p><h4><strong>优化0. 多路召回</strong></h4><ul><li><strong>问题</strong>：由于不同类型的文档结构复杂、信息密度不同，单一的召回策略往往难以适应所有场景。</li><li><strong>解决方案</strong>：并行多路召回</li></ul><h4><strong>优化1. 文本 QA 对总结提取</strong></h4><ul><li><strong>问题</strong>：召回的文档往往包含大量冗余信息，直接传递给 LLM 可能会影响生成质量，导致回答不够精准或聚焦。</li><li><strong>解决方案</strong>：预先使用 LLM 对解析后的文段进行处理，让 LLM 自动生成摘要标题和相关问题，并构造高质量的问答对（QA Pairs）和文档总结（Summary）。</li></ul><h4><strong>优化2. 图像 QA 对提取</strong></h4><ul><li><strong>问题</strong>：纯文本的回答有时不能很好地解决用户的问题，与文本相比，很多图表更加清晰。</li><li><p><strong>解决方案</strong>：</p><p>a.利用多模态大模型对图像内容进行解析，生成图像的文字描述；</p><p>b.将图像文字描述、路径等信息存储在 ImageDocNode 中；</p><p>c.利用 Lazyllm 的 LLM_Parse 根据图像的文字描述生成 QA 对。</p></li></ul><h4><strong>优化3. PDF 转图化繁为简</strong></h4><ul><li><strong>问题</strong>：PDF 解析过于复杂，代码功能设计繁琐。</li><li><p><strong>解决方案</strong>：</p><p>a.将 PDF 直接转换为图片；</p><p>b.使用专门针对图文混合版式的多模态嵌入模型对其进行向量化；</p><p>c.将和 query 匹配到的图像与 query 本身送给多模态大模型来做回答。</p></li></ul><h3><strong>（二）优化1：+ 文本QA对 &amp; Summary提取 方案</strong></h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389871" alt="" title="" loading="lazy"/></p><h4><strong>1.应用编排</strong></h4><pre><code>embed_mltimodal = lazyllm.TrainableModule("colqwen2-v0.1")
embed_text = lazyllm.TrainableModule("bge-m3")
embeds = {'vec1': embed_text, 'vec2': embed_mltimodal}
qapair_llm = lazyllm.LLMParser(lazyllm.OnlineChatModule(stream=False), language="zh", task_type="qa") 
summary_llm = lazyllm.LLMParser(lazyllm.OnlineChatModule(stream=False), language="zh", task_type="summary") 
documents = lazyllm.Document(dataset_path=tmp_dir.rag_dir, embed=embeds, manager=False)
documents.add_reader("*.pdf", MineruPDFReader(url="http://127.0.0.1:8888"))   # url 需替换为已启动的 MinerU 服务地址
documents.create_node_group(name="summary", transform=lambda d: summary_llm(d), trans_node=True)
documents.create_node_group(name='qapair', transform=lambda d: qapair_llm(d), trans_node=True)
with lazyllm.pipeline() as ppl:
    with lazyllm.parallel().sum as ppl.prl:
        ppl.prl.retriever1 = lazyllm.Retriever(documents, group_name="qapair", embed_keys=['vec1'], similarity="cosine", topk=1)
        ppl.prl.retriever2 = lazyllm.Retriever(documents, group_name="summary", embed_keys=['vec1'], similarity="cosine", topk=1)
        ppl.prl.retriever3 = lazyllm.Retriever(documents, group_name="Image", embed_keys=['vec2'], similarity="maxsim", topk=2)
    ppl.prompt = build_vlm_prompt | bind(_0, ppl.input)
    ppl.vlm = lazyllm.OnlineChatModule(source="sensenova", model="SenseNova-V6-Turbo").prompt(lazyllm.ChatPrompter(gen_prompt))
lazyllm.WebModule(ppl, port=range(23468, 23470), static_paths=get_image_path()).start().wait()
</code></pre><h4><strong>2.效果展示</strong></h4><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389872" alt="" title="" loading="lazy"/></p><p>qapair节点组召回内容：</p><pre><code>query:
What capabilities does DeepSeek-R1-Zero demonstrate?
answer
DeepSeek-R1-Zero demonstrates remarkable reasoning capabilities and naturally emerges with numerous powerful and intriguing reasoning behaviors through RL.
</code></pre><p>summary节点组召回内容：</p><blockquote><p><strong>性能对比表格摘要：</strong></p><ul><li>不同模型在多个基准测试中的表现，包括MMLU、MMLU-Redux、MMLU-Pro、DROP、IF-Eval、GPQA Diamond、SimpleQA、FRAMES、AlpacaEval2.0、ArenaHard等英语理解测试，以及LiveCodeBench、Codeforces、SWE Verified、Aider-Polyglot等代码能力测试和AIME、MATH-500、CNMO等数学能力测试。</li><li>Claude-3.5-Sonnet-1022 0513、GPT-4o DeepSeek V3、OpenAI OpenAI 01-mini o1-1217、DeepSeek R1等模型在不同测试中各有优劣，例如DeepSeek R1在多数测试中表现优异，尤其在Codeforces和Aider-Polyglot中表现突出。</li><li>各模型在架构、激活参数、总参数和MMLU (Pass@1)等指标上的差异。</li><li>中文评估中，各模型在C-Eval和C-SimpleQA上的表现。</li></ul></blockquote><p>image节点组召回内容：</p><pre><code>/path/to/images/2c6271b8cecc68d5b3c22e552f407a5e97d34030f91e15452c595bc8a76e291c.jpg
/path/to/ images/b671779ae926ef62c9a0136380a1116f31136c3fd1ed3fedc0e3e05b90925c20.jpg
</code></pre><h3><strong>（三）优化2：+ 图片QA对 方案</strong></h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389873" alt="" title="" loading="lazy"/></p><h4><strong>1.应用编排</strong></h4><pre><code>embed_mltimodal = lazyllm.TrainableModule("colqwen2-v0.1")
embed_text = lazyllm.TrainableModule("bge-m3")
embeds = {'vec1': embed_text, 'vec2': embed_mltimodal}
qapair_llm = lazyllm.LLMParser(lazyllm.OnlineChatModule(stream=False), language="zh", task_type="qa")
qapair_img_llm = lazyllm.LLMParser(
    lazyllm.OnlineChatModule(source="sensenova", model="SenseNova-V6-Turbo"), language="zh", task_type="qa_img") 
summary_llm = lazyllm.LLMParser(lazyllm.OnlineChatModule(stream=False), language="zh", task_type="summary") 
documents = lazyllm.Document(dataset_path=tmp_dir.rag_dir, embed=embeds, manager=False)
documents.add_reader("*.pdf", MineruPDFReader(url="http://127.0.0.1:888"))
documents.create_node_group(name="summary", transform=lambda d: summary_llm(d), trans_node=True)
documents.create_node_group(name='qapair', transform=lambda d: qapair_llm(d), trans_node=True)
documents.create_node_group(name='qapair_img', transform=lambda d: qapair_img_llm(d), trans_node=True, parent='Image')
with lazyllm.pipeline() as ppl:
    with lazyllm.parallel().sum as ppl.prl:
        ppl.prl.retriever1 = lazyllm.Retriever(documents, group_name="summary", embed_keys=['vec1'], similarity="cosine", topk=1)
        ppl.prl.retriever2 = lazyllm.Retriever(documents, group_name="Image", embed_keys=['vec2'], similarity="maxsim", topk=2)
        ppl.prl.retriever3 = lazyllm.Retriever(documents, group_name="qapair", embed_keys=['vec1'], similarity="cosine", topk=1)
        ppl.prl.retriever4 = lazyllm.Retriever(documents, group_name="qapair_img", embed_keys=['vec1'], similarity="cosine", topk=1)
    ppl.prompt = build_vlm_prompt | bind(_0, ppl.input)
    ppl.vlm = lazyllm.OnlineChatModule(source="sensenova", model="SenseNova-V6-Turbo").prompt(lazyllm.ChatPrompter(gen_prompt))
lazyllm.WebModule(ppl, port=range(23468, 23470), static_paths=get_image_path()).start().wait()
</code></pre><h4><strong>2.效果展示</strong></h4><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389874" alt="" title="" loading="lazy"/></p><p>qapair节点组召回内容：</p><pre><code>query:
DeepSeek-R1-Zero的性能表现说明了什么？
answer
DeepSeek-R1-Zero的性能表现突显了其强大的基础能力和在推理任务中进一步提升的潜力。
</code></pre><p>summary节点组召回内容：</p><pre><code>DeepSeek-R1-Zero无需监督微调即可实现强大推理能力，通过仅使用强化学习展现出高效学习和泛化能力。应用多数投票可进一步提升其性能，如在AIME基准测试中，其性能从71.0%提升至86.7%，超越OpenAI-o1-0912。这表明DeepSeek-R1-Zero具备强大的基础能力，有潜力在推理任务中实现更多进展。
</code></pre><p>qapair_img 节点组召回内容：</p><pre><code>query:
在SWE-bench Verified (Resolved) 中，DeepSeek-R1的准确率是多少？
answer
49.2%
</code></pre><p>image节点组召回内容：</p><pre><code>/path/to/images/b671779ae926ef62c9a0136380a1116f31136c3fd1ed3fedc0e3e05b90925c20.jpg
(2) /path/to/images/2c6271b8cecc68d5b3c22e552f407a5e97d34030f91e15452c595bc8a76e291c.jpg
</code></pre><h3><strong>（四）优化2：+ 图片QA对(变种) 方案</strong></h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389875" alt="" title="" loading="lazy"/></p><h4><strong>1.应用编排（变种）</strong></h4><pre><code>embed_mltimodal = lazyllm.TrainableModule("colqwen2-v0.1")
embed_text = lazyllm.TrainableModule("bge-m3")
embeds = {'vec1': embed_text, 'vec2': embed_mltimodal}
qapair_llm = lazyllm.LLMParser(lazyllm.OnlineChatModule(stream=False), language="zh", task_type="qa") 
summary_llm = lazyllm.LLMParser(lazyllm.OnlineChatModule(stream=False), language="zh", task_type="summary") 
documents = lazyllm.Document(dataset_path=tmp_dir.rag_dir, embed=embeds, manager=False)
documents.add_reader("*.pdf", MineruPDFReader(url="http://127.0.0.1:8888"))   # url 需替换为已启动的 MinerU 服务地址
documents.create_node_group(name="summary", transform=lambda d: summary_llm(d), trans_node=True)
documents.create_node_group(name='qapair', transform=lambda d: qapair_llm(d), trans_node=True)
documents.create_node_group(name='qapair_img', transform=lambda d: qapair_llm(d), trans_node=True, parent='ImgDesc')
with lazyllm.pipeline() as ppl:
    with lazyllm.parallel().sum as ppl.prl:
        ppl.prl.retriever1 = lazyllm.Retriever(documents, group_name="summary", embed_keys=['vec1'], similarity="cosine", topk=1)
        ppl.prl.retriever2 = lazyllm.Retriever(documents, group_name="Image", embed_keys=['vec2'], similarity="maxsim", topk=2)
        ppl.prl.retriever3 = lazyllm.Retriever(documents, group_name="qapair", embed_keys=['vec1'], similarity="cosine", topk=1)
        ppl.prl.retriever4 = lazyllm.Retriever(documents, group_name="qapair_img", embed_keys=['vec1'], similarity="cosine", topk=1)
    ppl.prompt = build_vlm_prompt | bind(_0, ppl.input)
    ppl.vlm = lazyllm.OnlineChatModule(source="sensenova", model="SenseNova-V6-Turbo").prompt(lazyllm.ChatPrompter(gen_prompt))
lazyllm.WebModule(ppl, port=range(23468, 23470), static_paths=get_image_path()).start().wait()
</code></pre><h4><strong>2.效果展示1</strong></h4><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389876" alt="" title="" loading="lazy"/></p><p>qapair节点组召回内容：</p><pre><code>query:
DeepSeek-R1-Zero的性能表现说明了什么？
answer
DeepSeek-R1-Zero的性能表现突显了其强大的基础能力和在推理任务中进一步发展的潜力。
</code></pre><p>summary节点组召回内容：</p><pre><code>DeepSeek-R1-Zero无需监督微调即可实现强推理能力，通过仅使用强化学习显示其有效学习和泛化能力。采用多数投票可进一步提升其性能，如在AIME基准测试中，性能从71.0%提升至86.7%，超过OpenAI-o1-0912。其有竞争力表现展示了强大的基础能力和在推理任务中进一步发展的潜力。
</code></pre><p>qapair_img 节点组召回内容：</p><pre><code>query:
图表显示了DeepSeek-R1-Zero在训练过程中的平均长度如何变化？
answer
在训练的早期阶段，平均长度相对较低，随着步数的增加，平均长度逐渐上升，并在后期阶段出现波动。
</code></pre><p>image节点组召回内容：</p><pre><code>/path/to/images/b671779ae926ef62c9a0136380a1116f31136c3fd1ed3fedc0e3e05b90925c20.jpg
/path/to/images/2c6271b8cecc68d5b3c22e552f407a5e97d34030f91e15452c595bc8a76e291c.jpg
</code></pre><h4><strong>3.效果展示2——图像QA细节展示</strong></h4><p>从PDF中解析出的原图像</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389877" alt="" title="" loading="lazy"/></p><p>多模态大模型生成描述</p><pre><code>这张图片展示了一个图表，该图表显示了DeepSeek-R1-Zero在训练过程中平均长度随步数增加而变化的趋势。图表中的蓝色线表示平均长度，而浅蓝色的阴影区域可能表示训练过程中的不确定性或误差范围。
在图表中，x轴代表步数，从0到大约8000，而y轴表示平均长度，从0到大约12000。图表显示，在训练的早期阶段，平均长度相对较低，随着步数的增加，平均长度逐渐上升，并在后期阶段出现波动。图表中的线条和阴影区域显示了训练过程中的变化，可能反映了DeepSeek-R1-Zero在处理数据或任务时所遇到的复杂性和不确定性。
请注意，由于图表中没有明确标注x轴和y轴的具体单位，上述描述是基于图表的视觉呈现，并未提供具体的数值信息。
</code></pre><p>针对生成的描述利用LLM生成QA对</p><pre><code>Q: 这张图片展示了一个图表，它显示了什么内容？
A: 这张图片展示了一个图表，该图表显示了DeepSeek-R1-Zero在训练过程中平均长度随步数增加而变化的趋势。
 
Q: 图表中的蓝色线表示什么？
A: 图表中的蓝色线表示平均长度。
 
Q: 图表中的浅蓝色阴影区域可能表示什么？
A: 浅蓝色的阴影区域可能表示训练过程中的不确定性或误差范围。
 
Q: 图表的x轴和y轴分别代表什么？
A: x轴代表步数，从0到大约8000，而y轴表示平均长度，从0到大约12000。
·
Q: 图表显示了DeepSeek-R1-Zero在训练过程中的平均长度如何变化？
A: 在训练的早期阶段，平均长度相对较低，随着步数的增加，平均长度逐渐上升，并在后期阶段出现波动。
 
Q: 图表中的线条和阴影区域可能反映了什么？
A: 线条和阴影区域可能反映了DeepSeek-R1-Zero在处理数据或任务时所遇到的复杂性和不确定性。
 
Q: 描述中是否提供了具体的数值信息？
A: 没有，描述中没有提供具体的数值信息，仅基于图表的视觉呈现。
</code></pre><p>最终问答效果</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389878" alt="" title="" loading="lazy"/></p><h3><strong>（五）优化3：PDF转图化繁为简</strong></h3><ul><li><strong>传统方法</strong>：将文档结构化解析 → 图像 &amp; 文本分别处理</li><li><strong>新方向</strong>：将整页文档视为图像，使用多模态嵌入模型直接编码</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389879" alt="" title="" loading="lazy"/></p><p>对于用户查询中的每一项目，ColPali 会识别出<strong>最相关的文档图像区域</strong>（被高亮显示的区域），并计算查询与页面之间的<strong>匹配分数</strong>。这里显示了“hour”和图像中的“Hours”及其时间高度相关。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389880" alt="" title="" loading="lazy"/></p><h3><strong>（六）优化3：PDF转图化繁为简 LazyLLM方案</strong></h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389881" alt="" title="" loading="lazy"/></p><p><strong>代码实现——PDF转图片</strong></p><p>之前的方案中，文本解析阶段我们采用的是先解析文本、再构建节点的方式，流程相对复杂。这里直接将PDF解析为图像。供给后续多模态大模型使用。</p><p>（代码GitHub链接：<a href="https://link.segmentfault.com/?enc=ZwfQnH9PkHoexNImLOvOCw%3D%3D.PdNyKqpLgAdTGWb9bHkORyGh9K5jCnmS8W2ZOceWd7b7DgAaoXOmtBKtwqBHo%2Fpwb1GRenKvMkMF4aQCimbob%2BkB89L79IP42p8w32p8yIyp%2BWE8gslHg%2BBw0Dw2vp%2FK8hNJcsr5N3OzPvApnl3agBFaD1EkeqFl1G3gMtqkEaHGzLIF96ksc%2FKb4eG3p0ea" rel="nofollow" target="_blank">https://github.com/LazyAGI/Tutorial/blob/a09a84cdf0585a5c9d52af6db0e965be95d03123/rag/codes/chapter14/PaperQA_MLM.py#L14C1-L14C35</a>）</p><pre><code># PDF转图像阅读器实现类
class Pdf2ImageReader(ReaderBase):
     def __init__(self, image_save_path="pdf_image_path"):
         super().__init__(); self.image_save_path = image_save_path
     if not os.path.exists(self.image_save_path): os.makedirs(self.image_save_path)
 
# PDF文件加载和转换核心方法
     def _load_data(self, file: Path, extra_info=None) -&gt; List[ImageDocNode]:
         if not isinstance(file, Path): file = Path(file)
         docs = fitz.open(file); file_path = []
         for page_num in range(docs.page_count):
             metadata = extra_info or {}; metadata["file_name"] = file.name; metadata["file_split"] = page_num
            page = docs.load_page(page_num); pix = page.get_pixmap(dpi=300)
            img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
            save_path = f"{self.image_save_path}/{file.name[:-4]}_{page_num}.jpg"
            img.save(save_path); file_path.append(ImageDocNode(image_path=save_path, global_metadata=metadata))
     return file_path
</code></pre><p>通过上述代码，就可以通过 ImageDocNode.get\_content()获取图像 PIL 对象，也可以通过 ImageDocNode.image\_path 获取对应的存储路径，方便后续进行进一步的操作。</p><h4><strong>1.优化相似度计算方式——MaxSim相似度计算法</strong></h4><p><strong>MaxSim函数</strong>是一种基于延迟交互的相似度计算方法，它通过将查询和文档的每个Token的向量进行逐对相似度计算，并追踪每对的最大得分来确定整体的相似度。</p><h5><strong>（1）核心原理</strong></h5><ul><li>延迟交互机制：不直接计算全局相似度，而是逐Token交互后聚合</li><li>最大匹配策略：每个查询Token寻找文档中的最大响应值</li></ul><p>下方是MaxSim函数的得分计算函数，我们只需实现相似度计算函数进行注册即可。MaxSim的具体公式如下:</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389882" alt="" title="" loading="lazy"/></p><p>接下来我们以一个简单的例子来说明 MaxSim 函数的计算过程。</p><p>假设我们有一个查询 q 和一个文档 d，它们的嵌入矩阵如下：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389883" alt="" title="" loading="lazy"/></p><h5><strong>（2）计算步骤</strong></h5><p><strong>步骤1️⃣：通过点积运算（对应元素相乘后求和）</strong></p><p>• M11 = 0.5×0.1+(−0.2)×0.4=0.05−0.08=−0.03</p><p>• M12 = 0.5×(−0.3)+(−0.2)×0.6=−0.15−0.12=−0.27</p><p>• M13 = 0.5×0.7+(−0.2)×(−0.5)=0.35+0.10=0.45</p><p>• M21 = 0.3×0.1+0.8×0.4=0.03+0.32=0.35</p><p>• M22 = 0.3×(−0.3)+0.8×0.6=−0.09+0.48=0.39</p><p>• M23 = 0.3×0.7+0.8×(−0.5)=0.21−0.40=−0.19</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389884" alt="" title="" loading="lazy"/></p><p><strong>步骤2️⃣：取每行最大值</strong></p><p>第一行最大值：max(−0.03,−0.27,0.45)=0.45</p><p>第二行最大值：max(0.35,0.39,−0.19)=0.39</p><p><strong>步骤3️⃣：全局求和</strong></p><p>最终相似度：S(q,d)=0.45+0.39=0.84</p><h5><strong>（3）结果</strong></h5><ul><li>查询 q 和文档 d 的最终相似度得分为 0.84。</li></ul><h5><strong>（4）总结</strong></h5><p>通过这个例子，我们可以看到 <strong>MaxSim</strong> 的计算过程：</p><ol><li>对每个查询 token，计算它与文档中所有 token 的点积（相似度）。</li><li>对每个查询 token，取它与文档 token 的最大相似度。</li><li>将所有查询 token 的最大相似度相加，得到最终的相似度得分。</li></ol><p>其中S为查询q和文档d之间的最终相似度得分，Eq表示查询q的嵌入，Edi表示第i个图像块的嵌入。以下为MaxSim函数的代码实现：</p><p>（代码GitHub链接：<a href="https://link.segmentfault.com/?enc=PnIFejinoDPrFhR8tNJnjQ%3D%3D.MAJ1IFM5%2FJSx1BAWG0ie1xfx%2BZc4Qp9w66tw322dIQbAM8SPNqskM1BHsZb%2F1lcn35ayIWAfOnQhQR9tBzEjKnu5CKyQHFty%2FP2q6f7A2GhGCs0txfBwjczbp17keJjfQf%2FoK7i%2B1lCkutYkybcRwmB21WR1R%2Fjvo7Zmx3GKJKw%3D" rel="nofollow" target="_blank">https://github.com/LazyAGI/Tutorial/blob/a09a84cdf0585a5c9d52af6db0e965be95d03123/rag/codes/chapter14/PaperQA_MLM.py#L43</a>）</p><pre><code>import torch
 
@lazyllm.tools.rag.register_similarity(mode='embedding', batch=True)
def maxsim(query, nodes, **kwargs):
    batch_size = 128
    scores_list = []
    query = torch.Tensor([query for i in range(len(nodes))])
    nodes_embed = torch.Tensor(nodes)
    for i in range(0, len(query), batch_size):
        scores_batch = []
        query_batch = torch.nn.utils.rnn.pad_sequence(query[i : i + batch_size], batch_first=True, padding_value=0)
        for j in range(0, len(nodes_embed), batch_size):
            nodes_batch = torch.nn.utils.rnn.pad_sequence(nodes_embed[j : j + batch_size], batch_first=True, padding_value=0)
            scores_batch.append(torch.einsum("bnd,csd-&gt;bcns", query_batch, nodes_batch).max(dim=3)[0].sum(dim=2))
        scores_batch = torch.cat(scores_batch, dim=1).cpu()
        scores_list.append(scores_batch)
    scores = scores_list[0][0].tolist()
    return scores
</code></pre><h4><strong>2.应用编排</strong></h4><p>（代码GitHub链接：<a href="https://link.segmentfault.com/?enc=GeAJvOvF9CMWYaFHkJL2Sg%3D%3D.tsoCJpxayR%2BugGSpiR4%2F3mwu28bva2t3ZY2rEcJgudoOoIdOe9UIVBfLZ2Rccv7j3ZIEERdqM6zsPfl7UHSiOeT94N%2Bvt4zJBXlUUiF732xy3CYQ88A94HhM6Pt1Nw8A7fUhOP2z2mOmFB0NN0KlJy3u7e4KyFwcazX5mLMUbGWM4mHjBEmZV0ZqPyddb0NP" rel="nofollow" target="_blank">https://github.com/LazyAGI/Tutorial/blob/a09a84cdf0585a5c9d52af6db0e965be95d03123/rag/codes/chapter14/PaperQA_MLM.py#L64C1-L64C33</a>）</p><pre><code># 定义将图像路径转换为markdown格式的函数
def format_markdown_image(text):
     json_part = text[text.index("{"):]; data = json.loads(json_part)
     image_paths = data.get("files", []); return f'\n\n![]({image_paths[0]})'
# 初始化文档处理模块并添加PDF阅读器
     image_file_path = "/content/images"
   documents = lazyllm.Document(dataset_path="/content/doc", 
                                   embed=lazyllm.TrainableModule("colqwen2-v0.1"))
     documents.add_reader("*.pdf", Pdf2ImageReader(image_file_path))
# 构建图像检索和处理流水线
     with pipeline() as ppl:
         ppl.retriever = Retriever(doc=documents, group_name="Image", similarity="maxsim", topk=1)
         ppl.formatter1 = lambda nodes : [node.image_path for node in nodes]
       ppl.formatter2 = encode_query_with_filepaths | bind(ppl.input, _0)
       with parallel().sum as ppl.prl:
            ppl.prl.vlm = lazyllm.OnlineChatModule(source="sensenova", model="SenseChat-Vision")
             ppl.prl.post_action = format_markdown_image# 启动Web服务
 lazyllm.WebModule(ppl, static_paths=image_file_path).start().wait()
</code></pre><h4><strong>3.效果展示</strong></h4><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389885" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389886" alt="" title="" loading="lazy"/></p><h2><strong>论文系统综合方案</strong></h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389887" alt="" title="" loading="lazy"/></p><h3><strong>（一）应用编排</strong></h3><pre><code>embed_mltimodal = lazyllm.TrainableModule("colqwen2-v0.1")
embed_text = lazyllm.TrainableModule("bge-m3")
embeds = {'vec1': embed_text, 'vec2': embed_mltimodal}
qapair_llm = lazyllm.LLMParser(lazyllm.OnlineChatModule(stream=False), language="zh", task_type="qa")
qapair_img_llm = lazyllm.LLMParser(
    lazyllm.OnlineChatModule(source="sensenova", model="SenseNova-V6-Turbo"), language="zh", task_type="qa_img") 
summary_llm = lazyllm.LLMParser(lazyllm.OnlineChatModule(stream=False), language="zh", task_type="summary") 
documents = lazyllm.Document(dataset_path=tmp_dir.rag_dir, embed=embeds, manager=False)
documents.add_reader("*.pdf", MineruPDFReader(url="http://127.0.0.1:8888"))
documents.create_node_group(name="block", transform=lambda s: s.split("\n") if s else '')
documents.create_node_group(name="summary", transform=lambda d: summary_llm(d), trans_node=True)
documents.create_node_group(name='qapair', transform=lambda d: qapair_llm(d), trans_node=True)
documents.create_node_group(name='qapair_img', transform=lambda d: qapair_img_llm(d), trans_node=True, parent='Image')
with lazyllm.pipeline() as ppl:
    with lazyllm.parallel().sum as ppl.mix:
        with lazyllm.pipeline() as ppl.mix.rank:
            with lazyllm.parallel().sum as ppl.mix.rank.short:
                ppl.mix.rank.short.retriever1 = lazyllm.Retriever(documents, group_name="summary", embed_keys=['vec1'], similarity="cosine", topk=4)
                ppl.mix.rank.short.retriever2 = lazyllm.Retriever(documents, group_name="qapair", embed_keys=['vec1'], similarity="cosine", topk=4)
                ppl.mix.rank.short.retriever3 = lazyllm.Retriever(documents, group_name="qapair_img", embed_keys=['vec1'], similarity="cosine", topk=4)
            ppl.mix.rank.reranker = lazyllm.Reranker("ModuleReranker", model="bge-reranker-large", topk=3) | bind(query=ppl.mix.rank.input)
        ppl.mix.retriever4 = lazyllm.Retriever(documents, group_name="block", embed_keys=['vec1'], similarity="cosine", topk=2)
        ppl.mix.retriever5 = lazyllm.Retriever(documents, group_name="Image", embed_keys=['vec2'], similarity="maxsim", topk=2)
    ppl.prompt = build_vlm_prompt | bind(_0, ppl.input)
    ppl.vlm = lazyllm.OnlineChatModule(source="sensenova", model="SenseNova-V6-Turbo").prompt(lazyllm.ChatPrompter(gen_prompt))
lazyllm.WebModule(ppl, port=range(23468, 23470), static_paths=get_image_path()).start().wait()
</code></pre><h3><strong>（二）效果展示</strong></h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389888" alt="" title="" loading="lazy"/></p><p>召回内容：</p><pre><code>内容1：DeepSeek-R1 outperforms DeepSeek-V3 on education benchmarks and long-context QA, excelling in STEM and factual queries via reinforcement learning. However, it underperforms on Chinese SimpleQA due to safety RL restrictions.
 
内容2：DeepSeek-R1在IF-Eval、AlpacaEval2.0和ArenaHard上表现出色，得益于SFT和RL训练中包含的指令跟随数据。其优于DeepSeek-V3，展示了大型RL的泛化优势，提升推理能力和跨领域表现。生成的摘要长度平均为689个token（ArenaHard）和2218个字符（AlpacaEval2.0），表明其简洁性。
 
内容3：各模型在多种基准测试中的性能对比，包括MMLU、Codeforces、AIME等，显示不同模型在英语、代码和数学等领域的差异化表现。
 
内容4： We introduce our frst-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1. DeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without supervised fne-tuning (SFT) as a preliminary step, demonstrates remarkable reasoning capabilities. Through RL, DeepSeek-R1-Zero naturally emerges with numerous powerful and intriguing reasoning behaviors. However, it encounters challenges such as poor readability, and language mixing. To address these issues and further enhance reasoning performance, we introduce DeepSeek-R1, which incorporates multi-stage training and cold-start data before RL. DeepSeekR1 achieves performance comparable to OpenAI-o1-1217 on reasoning tasks. To support the research community, we open-source DeepSeek-R1-Zero, DeepSeek-R1, and six dense models (1.5B, 7B, 8B, 14B, 32B, 70B) distilled from DeepSeek-R1 based on Qwen and Llama.
 
内容5：|  | Benchmark (Metric) | Claude-3.5- Sonnet-1022 0513 | GPT-4o DeepSeek V3 |  | OpenAI OpenAI 01-mini o1-1217 | DeepSeek R1 |
</code></pre><p>Image 节点组召回内容：</p><pre><code>/path/to/images/2c6271b8cecc68d5b3c22e552f407a5e97d34030f91e15452c595bc8a76e291c.jpg
/path/to/images/b671779ae926ef62c9a0136380a1116f31136c3fd1ed3fedc0e3e05b90925c20.jpg
</code></pre><h2><strong>总结拓展</strong></h2><p>在本节课程中，我们详细探讨了如何利用RAG（Retrieval-Augmented Generation）技术构建一个基于论文的问答系统。通过结合检索能力和大语言模型的生成能力，该系统能够帮助研究人员高效地从海量论文中提取核心信息，极大地提升了科研工作的效率。以下是本节内容的总结与拓展：</p><h3><strong>（一）系统架构与流程</strong></h3><ul><li><strong>数据准备</strong>：我们使用了arxivQA数据集中的论文，并通过自定义的PDF解析器（基于mineru）对论文进行解析，提取文本、图片和表格等内容。</li><li><strong>数据处理与组件搭建</strong>：通过LazyLLM框架，我们构建了文档解析器、检索器、重排器（Reranker）和大模型（LLM）等核心组件，逐步实现了从文档解析到问答生成的完整流程。</li><li><strong>效果展示与优化</strong>：通过引入向量化检索和重排器，系统能够更精准地检索到与查询相关的论文段落，并结合大模型生成清晰、准确的回答。我们还通过QA文本对提取和多路召回等优化策略，进一步提升了系统的召回质量和生成效果。</li></ul><h3><strong>（二）关键技术点</strong></h3><ul><li><strong>自定义PDF解析器</strong>：通过mineru工具，我们实现了对PDF文档的深度解析，能够提取文本、图片和表格等结构化信息，并将其存储为DocNode对象，便于后续的检索和处理。</li><li><strong>向量化检索与重排</strong>：我们使用了BGE模型进行文本嵌入，并结合Milvus数据库进行向量化检索。通过引入重排器（Reranker），系统能够对检索结果进行精细化排序，确保最相关的内容排在最前面。</li><li><strong>多模态整合</strong>：在进阶优化中，我们探讨了如何将多模态大模型（如视觉模型）整合到RAG系统中，进一步提升系统对图表等非文本信息的理解能力。</li></ul><h3><strong>（三）优化策略</strong></h3><ul><li><strong>多路召回</strong>：通过并行多路召回策略，系统能够结合多种检索方法（如基于关键词的稀疏检索和基于语义的密集检索），提高召回的全面性和鲁棒性。</li><li><strong>QA文本对提取</strong>：通过LLM生成高质量的问答对（QA Pairs），系统能够在召回阶段更精准地匹配用户查询，提升生成结果的相关性和准确性。</li><li><strong>多模态协同处理</strong>：通过整合多模态大模型，系统能够更好地处理论文中的图表信息，提供更全面的问答服务。</li><li><strong>PDF转图化繁为简</strong>：使用专门针对图文混合版式的多模态嵌入模型对转换为图的PDF文档进行向量化，省去了对PDF文档进行复杂解析和处理的逻辑，大大简化了开发工作。</li></ul><h3><strong>（四）未来拓展方向</strong></h3><ul><li><strong>多语言支持</strong>：当前的系统主要针对中文和英文论文，未来可以扩展到支持更多语言的论文解析和问答。</li><li><strong>更复杂的文档结构处理</strong>：随着论文结构的多样化，系统可以进一步优化对复杂文档（如多级标题、交叉引用等）的处理能力。</li><li><strong>实时更新与增量学习</strong>：为了应对科研领域的快速变化，系统可以引入实时更新机制，支持对新论文的快速解析和知识库的增量更新。</li><li><strong>用户个性化推荐</strong>：通过分析用户的查询历史和研究兴趣，系统可以提供个性化的论文推荐和问答服务，进一步提升用户体验。</li></ul><h3><strong>（五）总结</strong></h3><p>通过本节课程的学习，我们不仅掌握了如何利用RAG技术构建一个高效的论文问答系统，还深入了解了如何通过优化策略提升系统的召回质量和生成效果。未来，随着多模态技术和增量学习等技术的进一步发展，RAG系统在科研领域的应用前景将更加广阔。</p><p>希望本节内容能够帮助大家更好地理解和应用RAG技术，期待大家在未来的科研工作中能够利用这些技术提升工作效率，取得更多的研究成果！</p><p>更多技术讨论，欢迎移步 "lazyllm"gzh！</p>]]></description></item><item>    <title><![CDATA[如何将音乐从一台 POCO 设备传输到另]]></title>    <link>https://segmentfault.com/a/1190000047389899</link>    <guid>https://segmentfault.com/a/1190000047389899</guid>    <pubDate>2025-11-11 18:16:57</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>想从旧款 POCO 手机升级到新款，但又不想丢失心爱的歌曲？别担心。无论您是想一键迁移所有音乐文件，还是更喜欢使用内置的传输工具，都有多种方法可以轻松安全地将音乐从 POCO 手机传输到新款 POCO 手机。</p><p>在本文中，我们将向您介绍 5 种实用的音乐文件传输方法，涵盖从专业传输软件到免费内置工具（如 Mi Mover 和蓝牙）的所有内容。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389901" alt="图片" title="图片"/></p><h3>方法一：使用Coolmuster Mobile Transfer将音乐从 POCO 手机传输到 POCO 手机</h3><p>如果您想快速、安全、无损地在 POCO 手机之间传输所有音乐， Coolmuster Mobile Transfer是最佳选择。它支持一键式设备间数据迁移，包括Android和iOS 。</p><p>这款强大的工具专为简化手机间的数据传输而设计，只需轻点几下鼠标，即可传输音乐以及各种类型的内容。其直观的界面确保即使是新手也能轻松完成传输过程。</p><p>Coolmuster Mobile Transfer的主要功能</p><pre><code>几分钟内即可将整个音乐库从一部手机转移到另一部手机。
支持几乎所有Android设备，包括 POCO、小米、一加、三星等。
确保歌曲迁移后保留原有的音质。
所有传输均通过 USB 在本地完成，无云端上传或数据泄露风险。
它不仅限于音乐，还可以传输联系人、短信、照片和其他文件类型。

</code></pre><p>使用Coolmuster Mobile Transfer传输音乐的步骤：</p><p>01在您的计算机上下载、安装并启动Coolmuster Mobile Transfer 。</p><p>02使用 USB 数据线将两部 POCO 手机连接到电脑，并在每部手机上启用 USB 调试模式。当电脑检测到两部手机后，请确保源设备（旧 POCO 手机）和目标设备（新 POCO 手机）的位置正确。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389902" alt="图片" title="图片" loading="lazy"/></p><p>03选中“音乐”，然后点击“开始复制”即可立即开始传输您的曲目。</p><p>传输开始后，您就可以坐下来放松一下，软件会高效地复制您选择的所有歌曲。</p><h3>方法二：通过小米手机迁移工具将音乐从 POCO 手机转移到 POCO 手机。</h3><p>由于 POCO 是小米的子品牌，POCO 和小米手机共享相同的系统生态系统和许多内置应用——其中之一就是小米手机迁移工具 (Mi Mover)。这款小米官方工具旨在实现小米和 POCO 设备之间的无缝文件传输。它支持无线数据传输，无需使用移动数据或数据线，对于 POCO 用户来说，这是一款可靠且易于使用的选择。</p><p>如何使用小米手机传输音乐：</p><p>步骤 1. 在两部 POCO 手机上打开Mi Mover 。</p><p>步骤 2. 在旧 POCO 手机上，点击“旧”，在新 POCO 手机上，点击“新”。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389903" alt="图片" title="图片" loading="lazy"/></p><p>步骤三：新手机上会出现一个二维码。用旧手机扫描该二维码，即可安全连接两台设备。</p><p>第四步：连接成功后，您将看到可传输的数据类型列表。选择“音乐”以及您想要传输的任何其他内容。</p><p>第五步：点击“发送”，传输将开始。请等待传输完成。所需时间取决于音乐文件的大小和Wi-Fi连接质量。</p><p>注意：请将两部手机靠近并连接到同一个 Wi-Fi 网络，以确保传输流畅稳定。</p><h3>方法三：通过 ShareMe 将 POCO 设备之间的音乐同步到 POCO 设备</h3><p>ShareMe （原名 Mi Drop）是小米开发的另一款适用于 POCO 手机的应用。与 Mi Mover 不同，ShareMe 的功能更加全面；它不仅限于小米或 POCO 手机，还支持所有Android手机，并且无需消耗流量即可快速分享音乐、照片、应用和其他文件。</p><p>使用ShareMe同步音乐的步骤：</p><p>步骤 1. 在两部手机上，打开 ShareMe 应用。</p><p>步骤 2. 在发送 POCO 手机上，点击“发送”，然后选择“音乐”。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389904" alt="图片" title="图片" loading="lazy"/></p><p>步骤 3. 选择要传输的歌曲，然后再次点击“发送”。</p><p>第四步：在接收端POCO手机上，点击“接收”。应用程序将自动创建热点连接。</p><p>第五步：连接成功后，传输将立即开始。</p><p>注意：您也可以在应用程序内扫描二维码，更快地连接两部手机。</p><h3>方法四：使用蓝牙将音乐从 POCO 手机传输到 POCO 手机。</h3><p>蓝牙是手机间共享音乐的经典方式。虽然速度比其他方式慢，但无需安装任何额外软件，就能完美传输几首歌曲或铃声。</p><p>通过蓝牙发送音乐的步骤：</p><p>第一步：打开两部 POCO 手机的蓝牙功能。您可以在“设置”&gt;“蓝牙”中找到它。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389905" alt="图片" title="图片" loading="lazy"/></p><p>步骤 2. 将两部手机配对，并在提示时确认配对码。</p><p>步骤 3. 在旧手机上，打开文件管理器或音乐应用，选择要传输的音乐文件。</p><p>步骤 4. 点击“分享”&gt;“蓝牙”，然后选择目标 POCO 手机。</p><p>步骤 5. 在接收手机上接受转账请求，然后等待所有歌曲接收完毕。</p><h3>方法五：通过云服务在 POCO 之间共享音乐</h3><p>谷歌云端硬盘、Dropbox 和 OneDrive 等云服务提供了另一种在 POCO 手机之间同步音乐的可靠方法。只需将歌曲从旧设备上传到云端，即可在新设备上轻松访问和下载它们。</p><p>如何使用 Google 云端硬盘传输音乐：</p><p>步骤 1. 在您的旧 POCO 手机上，打开 Google 云端硬盘并登录您的 Google 帐户。</p><p>步骤二：点击“+”按钮，选择“上传”&gt;“音频”，然后选择您的音乐文件。等待上传完成。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389906" alt="图片" title="图片" loading="lazy"/><br/>​</p><p>步骤 3. 在您的新 POCO 手机上，使用相同的 Google 帐户登录。</p><p>第四步：打开 Google 云端硬盘，找到您上传的音乐，然后将其下载到本地存储或直接在线播放。如果您更喜欢其他平台，也可以使用 Dropbox 或 OneDrive，方法相同。</p><h3>总而言之</h3><p>将音乐从一部 POCO 手机传输到另一部 POCO 手机有几种有效的方法：</p><pre><code>Coolmuster Mobile Transfer ：一键式、安全、全面的数据迁移的理想之选。（需要一台电脑）
小米移动器：非常适合小米/POCO设备之间的无线数据传输。（不支持跨品牌传输）
ShareMe：速度快、无线连接，支持大多数Android手机。（需要手动配对）
蓝牙：简单免费，但传输大文件速度慢。
云服务：方便远程访问，但需要互联网和云空间。

</code></pre><p>每种方法都有其自身的优势，但如果您想要最快、最稳定、一体化的解决方案， Coolmuster Mobile Transfer无疑是迁移整个音乐收藏的最佳选择，它不会损失质量或数据安全。<br/>​</p>]]></description></item><item>    <title><![CDATA[数字人直播618战绩曝光：罗永浩AI分身]]></title>    <link>https://segmentfault.com/a/1190000047389921</link>    <guid>https://segmentfault.com/a/1190000047389921</guid>    <pubDate>2025-11-11 18:16:13</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>成本不到真人十分之一，转化率却提升三成，2025年的618大促已被数字人主播彻底改写游戏规则。</p><p>“凌晨三点的直播间，数字人主播仍在滔滔不绝地介绍产品，观众停留时长反超黄金时段28%。”今年618期间，抖音某国货彩妆品牌的数字人“小美”创下了37天连续直播、销售额2600万的惊人纪录。</p><p>这只是今年618大促中的一个缩影。从京东、百度到快手、抖音，数字人主播已从边缘补充角色升级为电商核心生产力。罗永浩数字人首秀6小时GMV突破5500万元，观看人次达1300万，单场GMV超过其真人直播峰值的110%。（青否数字人源头v：zhibo175）</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389923" alt="" title=""/></p><p>1、数据狂飙，各平台数字人战绩亮眼</p><p>京东作为618主场，数据显示，1.7万商家使用数字人实现24小时不间断直播，带动平台整体转化率提升30%。</p><p>Coach、MCM等轻奢品牌采用高定数字人主播后，直播间转化率超过13%，较真人主播提升48%。京东数字人更具备智能地域适配能力，针对不同地区用户自动调整产品讲解策略，成功带动客单价提升34%。</p><p>在抖音平台，数字人直播在美妆、服饰等非标品类表现抢眼。锋味派意面直播间数字人日均GMV达16.31万元，较真人主播提升7.6%。技术层面，抖音数字人通过CV技术实现实时试色、虚拟试穿，用户停留时长增加22%。</p><p>罗永浩数字人首秀树立行业标杆。人工智能技术亮点包括知识图谱驱动的精准应答和0.5秒级情绪响应，AI生成的9.7万字脚本覆盖200多个消费场景，转化率较真人直播提升12%。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389924" alt="" title="" loading="lazy"/></p><p>2、 技术突破，从机械播报到情感交互（青否数字人源头v：zhibo175）</p><p>2025年的数字人直播技术实现了质的飞跃，主要体现在三大突破：交互能力提升、成本结构优化和场景覆盖扩展。</p><p>多模态交互能力大幅提升：数字人动作精度达8300个/场，互动响应速度较2024年提升40%。数字人可模拟微笑、挑眉等微表情，结合产品数据库即时解答用户提问，能处理90%的常规咨询。</p><p>成本结构显著优化：数字人直播成本仅为真人的1/10，日均成本不足100元。淘宝依托自研TaoAvatar技术，将数字人制作成本压缩至传统CG的1/30，周期缩短至一周内。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389925" alt="" title="" loading="lazy"/></p><p>场景覆盖范围扩展：在跨境直播领域，青否数字人数字人支持多语言实时切换（如英日韩俄四语无缝衔接），在跨境美妆直播间实现83种肤质需求精准识别，关联推荐准确率达91%。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389926" alt="" title="" loading="lazy"/></p><p>3、成本革命，中小商家的增长利器（青否数字人源头v：zhibo175）</p><p>数字人直播最显著的优势在于其惊人的成本效益比。中商产业研究院测算显示，2025年数字人直播服务成本已降至每小时300-800元，仅为真人直播的1/3至1/5。</p><p>工业安全品牌代尔塔使用数字人后，直播成交额实现99倍增长，转化率达11%，较真人直播间提升3100%。酒类商家国台酒的实践更具代表性，其虚拟主播运营成本较真人团队下降78%，而GMV日均增长750%。</p><p>对于中小商家而言，数字人直播的价值更为突出。中小商家接入后平均获客成本降低62%。在非遗文化领域，湖南某县域通过虚拟主播团队培训计划，实现农产品线上销售额同比增长340%。</p><p>数字人直播带动中小商家日均GMV增长210%，月度营销成本下降72%。这种技术普惠效应在东南亚市场尤为明显，某国潮换装虚拟主播通过本土化改造，在越南市场市占率提升27%。</p><p>4、代运营实战，数字人应用策略指南</p><p>对于代运营公司而言，数字人直播已成为提升服务效能的关键工具。基于各平台618实践经验，我们总结出以下实战策略：</p><p>多平台适配策略：根据不同平台特性定制数字人方案。在抖音平台，重点开发“数字人+短剧”模式，提升用户沉浸感。在小红书平台，则侧重打造高颜值、知识型数字人形象，匹配平台用户偏好。</p><p>时段互补布局：利用数字人填补真人直播空白时段。数据显示，京东数字人在非黄金时段（0-8点）转化率达8%，较真人直播提升5个百分点。代运营团队可为客户设计“黄金时段真人主播+夜间数字人值守”的排班制。</p><p>跨境多语种应用：为跨境电商客户部署多语言数字人。青否跨境版数字人支持12种语言实时切换，在俄罗斯巧克力、斯里兰卡红茶等国际馆专场中，转化率较真人直播提升40%。</p><p>IP分身矩阵策略：复制罗永浩数字人成功经验。将头部IP拆解为语调模型、表情库、话术模板三大模块，衍生多场景数字分身，实现“1个真人IP驱动N个数字人”的降本增效模式。</p><p>本地生活服务创新：针对美团、大众点评等本地生活平台，开发具备地域特色的数字人主播。可结合方言特征和本地消费偏好，如某西北特产店借助方言虚拟主播实现跨境订单增长350%。</p><p>6、未来已来，代运营行业的新蓝海</p><p>展望未来，数字人直播市场将迎来爆发式增长。据预测，到2025年中国AI数字人直播市场规模将突破千亿元，催生“虚拟主播培训”、“数字人IP经纪”等新职业。</p><p>技术演进将持续推动体验升级。AI原生数字人、脑机接口等新技术的应用，将进一步模糊虚拟与现实的边界。服饰类直播间将通过虚拟试衣间让用户实时查看穿搭效果，提升购物体验。</p><p>对于代运营公司而言，数字人技术将重塑服务模式。（青否数字人源头v：zhibo175）</p><p>一方面，可建立数字人IP库，为客户提供从形象设计、话术训练到多平台分发的全链路服务。</p><p>另一方面，可开发“数字人即服务”（DaaS）模式，降低中小企业使用门槛。</p><p>内容创作领域也在变革。某美妆品牌通过AI自动生成直播脚本，5分钟即可完成口播视频制作，同时动态调整商品展示顺序，客单价提升40%。代运营公司可借此大幅提升内容产出效率。</p><p>某奶茶品牌通过数字人直播，将加盟店转化率差异从5倍缩小至1.2倍；湖南某县农产品通过虚拟主播团队培训，销售额同比增长340%。这些案例表明，数字人技术正成为代运营公司赋能中小商家的利器。</p><p>随着数字人制作成本降至传统CG的1/30，制作周期缩短至一周内，代运营公司迎来全新机遇。未来属于那些能融合真人主播情感价值与数字人效率优势的服务商——您准备好迎接这场AI直播革命了吗（青否数字人源头v：zhibo175）？</p>]]></description></item><item>    <title><![CDATA[对话思迈特CEO姚诗成：存量时代 BI ]]></title>    <link>https://segmentfault.com/a/1190000047389939</link>    <guid>https://segmentfault.com/a/1190000047389939</guid>    <pubDate>2025-11-11 18:15:26</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>​​​​​​​ChatBI是解药还是新泡沫？</h2><p>@松果财经<br/>原创作者|在辉</p><p>2025年春节，DeepSeek的爆火让产业圈迎来一波全民狂欢。很多行业或主动或被动地被AI影响，拿到了大量商机，销售电话被打爆。</p><p>BI是其中一个典型。这个曾经专注于数据分析的行业，和AI有着天然的“亲近感”。</p><p>思迈特CEO姚诗成告诉松果财经，当时那种氛围中，不少客户涌入后台，纷纷表示今年预算重点在AI：“<strong>很多时候你过来直接聊BI，客户会说‘暂时不是我最关注的事情，我今年重点在关注AI’</strong>”。 </p><p>客户在“挑”产品，被送到眼前的AI成了新解药。大半年过后，一个残酷的问题浮出水面：有多少商机真正变现了？ </p><p>思迈特其实拿到了一个不错的结果：<strong>落地了百余个项目，大部分来自新客户，在IDC技术评估中也全面领跑ChatBI厂商。</strong>自去年推出由生成式AI技术支持的Smartbi AIChat白泽以来，这款产品在短时间内迅速成为思迈特的第二增长曲线，AI驱动BI智能化升级得到了完全具象化的解释。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389941" alt="图片" title="图片"/></p><p>​​​​​​​ 但此时，姚诗成不认为这就是一切的答案。他，或者说思迈特，在这波浪潮中看到了一个更深层的行业困境：<strong>客户挑产品，说明并不是缺产品，而是对“让数据真正辅助决策”这件事存有疑问</strong>，不管是传统BI还是新的ChatBI，产品只是解决问题的形式。 </p><p>而思迈特看到本质的时间，还远早于这一波AI浪潮。从2019年技术路线的转折，到2022年大刀阔斧的全面变革，从精细化管理到组织重构，这家公司在过去几年重新定义了自己的战略路线。直到今年，这场变革才开始显现成效。 </p><p>毫无疑问，这是一条更难的路。一家ToB公司基于内驱力完成了自身的系统性重构，然后在一个刚好的时间节点上接住了技术浪潮带来的增长效应，在各行各业都大谈存量时代的今天，这构成了一个极其独特的、逆势增长的案例。</p><h3>01.清醒的觉察</h3><p>2021年，一个不太被察觉的转折点悄然而至。这一年之后，姚诗成开始在客户沟通中频繁听到不同以往的声音。</p><p> “21年之前，客户推进数字化转型的核心目的是更好地创新和开源，”姚诗成回忆道，“但从21年、22年开始，客户的数字化建设出发点基本都转向了降本、节流、合规和风控。”</p><p> <strong>市场从增量扩张进入存量竞争，客户不再为概念买单，而是开始算账，追问投了钱为什么用不起来，或者担心白花钱。</strong></p><p>在BI领域，这逐渐体现为一个更明显的问题：用户看完了数据，然后没有了“然后”。 </p><p>AI崛起后，传统BI关注度出现下降，生成式AI驱动的ChatBI站上高峰，为之带来了一定改善。只要说出你的需求，系统就会返回一系列看似严谨详细的研究，这太符合外界对数字化智能的想象了。</p><p> 但在姚诗成的叙述中，这波浪潮背后隐藏着更深的问题。</p><p> “智能用数场景中，排名第一的一定是准确。数据不准确，就不可用。”<strong>准确性、稳定性、安全性、扩展性这四大问题没解决，客户就永远停留在“敢用不敢信”的状态</strong>——能聊天不等于能辅助决策，这是ChatBI最致命的硬伤。</p><p> 更棘手的是，市场还出现了虚火。就算商机挤爆后台，在兴趣泡沫当中，如果不能快速精准识别能够最后买单的潜在客户，就会消耗大量优质的售前资源和成本。 </p><p>客户到底需要什么？怎么看待当下BI的价值？问题的根源不在技术，而在认知。技术升级不会让BI万事大吉。思迈特并不赞成唯工具论、唯产品论。 </p><p>很多企业把BI当成纯技术工具，但姚诗成认为它至少应有三层价值：<strong>技术工具、管理工具（Boss工具，赋能领导层决策）、业务工具（助力基层提升效率）</strong>。针对不同层级必须提供匹配的差异化服务，“对技术人员要配套使用服务，对管理人员产品要有更高易用性，对业务人员还要通过场景化培训，教会他们在场景中使用工具”。</p><p> 传统对数字化建设认知的不足还带来了方法论的缺失，其失败经验往往表现为针对数字化建设投资大、周期长、见效慢、规划差、落地难。对此，思迈特从上千家客户实践中提炼出三条建议：<strong>以终为始指导建设规划，从业务视角而非技术视角出发；小步快跑，用MVP方式先做出标杆，探索经验；持续赋能，构建数据文化和数字化思维。</strong></p><p> 而在这些问题之上，则是从“建”到“用”的鸿沟——客户需求已从能看得见升级到用得好，但很多企业缺乏持续运营能力，导致系统建完成了摆设。</p><p> 这套认知框架指向一个本质命题：BI的发展早就脱离了技术竞赛的范畴，现在要比拼的，而是谁能真正帮客户把数据用起来。这种能力很难在短时间内完成积累，而思迈特也并非一蹴而就地重塑了自己。</p><h3>02.一场系统性重构</h3><p>“我们到今天还在变革期，前三年是调整期，去年到今年是巩固或发展期。”姚诗成坦言。 </p><p>在他的表述里，驱动变革的是三重因素：</p><p><strong>外部市场从增量转向存量，客户需求从“建”转向“用”，内部经营理念从追求规模转向追求质量和健康成长。</strong> </p><p>变革的核心落在聚焦产品化。“我们明确了以产品化为核心的业务战略，让资源更聚焦。”姚诗成解释，“有所为有所不为，并不是所有客户和行业都是当下的重点”。这意味着，产品是载体，技术、组织乃至业务战略的系统重构，才是变革的“灵魂”。 </p><p>为了让变革贯彻到底，从2023年起，思迈特开始将自己打造成“<strong>全数字化经营、运营的公司</strong>”，因为只有自己的数字化到位了，才能更加理解客户。每个部门、每个项目都能用数据清晰地看到毛利率、销售成本、交付成本等过程指标，这些数据和趋势能解释思迈特业务变革的成效。 </p><p>如果说战略聚焦是方向盘，那么技术路线就是发动机。尽管在外界看来，是AI改造了BI。但其实思迈特的差异化源于2019年V10版本的战略性选择——<strong>采用数据模型和指标架构</strong>，并自此和业界很多厂商走上了不同的路。</p><p>这在根本上增强了BI对应用和业务的价值，而不是只起到统计分析的作用。“企业的经营管理目标更多时候一定要拆成层层指标才能衡量，这个指标体系构建是从上到下层层战略分解，结合从下到上层层融合，这才是企业经营管理中天天都在应用的事情。”姚诗成说。 </p><p>这层积累正是今天思迈特在主导Agent BI发展时能“懂业务”的关键。 </p><p><strong>当其他厂商用大模型做简单对话时，思迈特的Smartbi AIChat白泽已经融合了基于指标模型和数据模型的综合能力。</strong>“你调用的是数据模型和指标模型里的数据，对质量可以完全有保障。”姚诗成强调，这是准确性排第一的底层支撑。 </p><p>姚诗成形象地解释：“你可以把ChatBI拆开来看——Chat加BI。Chat是AI的能力，是大模型的互动能力。但为什么叫Chat BI？BI背后是客户数据质量的水平。真正做好了BI建设与应用，数据质量肯定是不会差的。”</p><p> “今天思迈特在AIChat产品中，基于数据模型和指标模型的BI能力融合，也是我们产品的差异化竞争优势。”</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389942" alt="图片" title="图片" loading="lazy"/></p><p>​​​​​​​在实践中，思迈特采用务实的“AI+BI双轨策略”：<strong>有数据基础的客户直接上AI，充分利用积累；数据基础不具备的先上BI打好基础，再上AI。这避免了跨越式发展的风险</strong>。</p><p> 近200个POC实践，也让思迈特形成了独特的精细化打法。在项目管理上，研发与一线组成联合项目组，对每个AI项目从线索到交付全程独立管控，快速与客户达成有效沟通。 </p><p>这种管控在今年尤为重要。DeepSeek爆火后带来的商机泡沫中，思迈特通过有效筛选避免了公司优秀售前资源的浪费。同时，AI产品基本每月更新一次，与传统BI一年一个大版本形成强烈对比，“我们把POC经验和项目交付的方法论每个月快速总结和提炼，为下一次的客户服务提供更丰富的建设经验”。</p><p>而在如此多的策略迭代中，姚诗成提到，思迈特有一个看似反常识的决定：今年基本没招任何专业AI人员。相反，思迈特选择通过内部认证体系提升现有团队AI能力。</p><p> 具体来说，从销售到售前，再到交付，思迈特从多个维度构建了一套严格、完善的体系，让每个人员都具备充实的认知，“都必须严格通过认证，持证上岗”，追求更高的专业性和敏捷性。</p><p>通过这种方式，思迈特优先实现了内部能力的转化，而非依赖外部招聘。对它所在的领域而言，这种短期聚焦实现现有团队能力升级的战略选择，更加适应快速融合的业务需求。按姚诗成的话来说，是组织能力满足新的业务需要和市场需要。</p><p>“<strong>如果我们自己的知识都不能很好掌握，很难把BI和AI融合起来</strong>。”同时，思迈特还在推动各岗位学会用AI工具，培养AI认知，“这样才便于我们更好理解客户的AI诉求，也能更好展现我们BI加AI的差异化优势”。 </p><p>这些规则折射了思迈特综合能力持续提高的原因：<strong>和有可能被外界牵引的技术升级相比，组织能力和行业认知必须自己长出来</strong>。而这样的组织，将有更强的能力，读懂客户的心声。</p><h3>03.从供应商到合作伙伴</h3><p>数字是最有说服力的答案。思迈特今年又新增成交了几十个AIChat项目，都与其组织能力提升、挤掉了中间环节的泡沫有关。</p><p> 并且，焕然一新的思迈特变得更适应这个存量时代的增长要求——<strong>从客户结构变化来看，其AI合同大部分来自新客户，说明产品力突破了原有圈层</strong>。 </p><p>服务数千家老客户积累的行业Know-How，正成为新业务增长的护城河——“这些都是各细分领域的大客”，在金融、央国企等最严苛场景中打磨出的产品力，是难以复制的壁垒。 </p><p>从这个角度来看客户的买单，姚诗成提到：“<strong>客户购买的驱动力一定不是技术和产品，最直接购买的是服务和能力</strong>。”这个区分很关键，它意味着思迈特从产品供应商升级为价值合作伙伴。</p><p> 而此时再结合思迈特的变革经验和服务实践，我们看到了一条非常清晰的、陪伴客户“升级打怪”的路线。 </p><p>首先是持续输出最佳实践和方法论，帮客户解答他只是关注但不知道怎么做的问题，比如针对AI产品，输出AI路线选择标准、产品功能关注点、方案，让客户对AI创新从关注到落地有系统性认知。这种方法论又会不断迭代，更好地服务未来客户。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389943" alt="图片" title="图片" loading="lazy"/><br/>（图源：埃森哲） </p><p>第二是场景化培训，先让业务人员用得好，“不仅使用好工具，还要帮助客户在场景中去使用工具”，一边赋能客户在日常工作中深挖更多需求，一边也让产品覆盖到更多的人群。 </p><p>最后则是持续不断地更新自己。比如商业模式创新，提供订阅、租赁、直接购买服务等多样化选择，降低客户决策门槛；或是内部能力的更新，从销售到研发，都要锚定客户不断升级的业务诉求。只有走出一致的步伐，才能真正当好合作伙伴。</p><p> “<strong>我们一直希望能成为客户优秀的合作伙伴，而不是供应商</strong>。”姚诗成说。这不是口号，而是贯穿每个细节的理念。 </p><p>至于为何会形成这种认知领先，则源于思迈特对数字化本质的深刻理解。姚诗成给出了关键判断：“信息化更多是在提升流程效率。但数字化最大的不同，是基于数据运营驱动的建设和应用，这才能更好地发挥出数据价值。”这意味着数字化不是把线下搬到线上那么简单，“因为真正全面贯彻执行的过程中，它会涉及业务、组织、流程的重构，是个庞大的系统性工程”。 </p><p>客户需要以终为始，从用的视角、从业务的视角来指导建设，用小步快跑来构建每一个企业数字化的MVP，然后快速复制扩大，边建边用，最后在建设过程中匹配赋能运营推广的服务，来不断构建企业数据文化的氛围。 </p><p>这个过程，思迈特将始终跟随，共同跨越。</p><h3>04.结语</h3><p>从2011年思迈特成立至今，行业风起云涌。报表工具进化成决策系统，信息化让位于数字化，数字化又被智能化重新定义。每一轮技术浪潮都会重新洗牌，每一次客户需求的跃迁都会淘汰一批玩家。 </p><p>如今这个节点尤为关键。客户正怀抱热情接纳AI新事物，但热情褪去后，留下的只有两种结果：<strong>要么系统成了摆设，要么数据真正驱动了决策</strong>。</p><p>这中间的分野，不在于谁的技术更先进，而在于谁真正理解了行业、洞察了需求本质，并完成了从战略到组织的系统性重构。</p><p><strong>姚诗成说，外界可能以为机会在变少，其实是各方能力的不同在放大。曾经的竞争只需要效率，看谁跑得快，但今天要比拼更深度的能力。</strong>为客户提供获得感、共创价值，将成为最终衡量战果的标尺。它既是一种挑战，也是一个新的机会点。</p><hr/>]]></description></item><item>    <title><![CDATA[国科云解析SSL证书不可信的8种常见原因]]></title>    <link>https://segmentfault.com/a/1190000047389964</link>    <guid>https://segmentfault.com/a/1190000047389964</guid>    <pubDate>2025-11-11 18:14:48</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>SSL证书不可信不仅直接影响网站可用性和业务收入，更会严重损害品牌声誉。本文，国科云将深入剖析导致SSL证书不可用的八个常见原因及解决方案。</p><ol><li>证书已过期</li></ol><p>这是最常见的原因之一。SSL证书并非永久有效，它们被设计有明确的有效期（目前最长为13个月，遵循CA/浏览器论坛的基准要求）。一旦超过这个有效期，证书就会失效，浏览器会立即将其标记为不可信。</p><p>原因：定期更换证书是安全最佳实践，旨在确保证书使用的加密算法是现代的，并且网站所有权被定期验证。</p><p>用户端表现：浏览器显示“此证书已过期或尚未生效”的错误。</p><ol start="2"><li>证书颁发机构（CA）不受信任</li></ol><p>浏览器和操作系统内部维护着一个“受信任的根证书存储库”，其中包含全球公认的权威CA（如DigiCert、GlobalSign等）的根证书。如果您网站使用的证书是由一个不在此列表中的CA颁发的，浏览器将无法验证其真实性，从而判定其为不可信。</p><p>常见场景：</p><p>自签名证书：网站管理员自己创建的证书，没有经过任何公共CA的验证。这类证书通常用于内部测试环境，绝不应用于公开网站。</p><p>内部私有CA：大型企业或机构可能搭建自己的私有CA来管理内部证书。如果客户端的电脑没有安装并信任该企业的根证书，访问其内部网站时就会报错。</p><p>不知名或不受欢迎的CA：某些廉价或小众的CA可能未被所有操作系统或浏览器广泛收录。</p><ol start="3"><li>证书域名不匹配</li></ol><p>SSL证书是针对特定的域名（或一组域名）颁发的。当浏览器访问的网站域名与证书中列出的“通用名称（CN）”或“主题备用名称（SAN）”不匹配时，就会触发错误。</p><p>场景举例：</p><p>证书是为 www.guokeyun.com 颁发的，但用户访问的是 guokeyun.com（或反之）。</p><p>证书是为 example.com 颁发的，但用户通过IP地址直接访问。</p><p>证书包含 a.example.com 和 b.example.com，但用户访问的是 c.example.com。</p><ol start="4"><li>证书链不完整或不正确</li></ol><p>一个SSL证书的信任建立在一个“信任链”之上：服务器证书 → 中间证书 → 根证书。服务器在握手时，不仅需要发送自己的（叶子）证书，还需要发送一个或多个中间证书，以便客户端能够追溯到其信任的根证书。如果服务器配置时遗漏了中间证书，客户端将无法构建完整的信任链，导致验证失败。</p><p>用户端表现：浏览器错误信息可能为“此证书颁发者未知”或“无法找到该证书的颁发者”。</p><ol start="5"><li>服务器配置错误</li></ol><p>即使证书本身完美无缺，错误的服务器配置也会导致问题。</p><p>SNI（服务器名称指示）问题：在同一个IP地址上托管多个HTTPS网站时，需要依赖SNI来呈现正确的证书。如果旧客户端（如Windows XP上的IE6）不支持SNI，或者服务器配置不当，就可能返回默认证书，造成域名不匹配错误。</p><p>协议与算法不匹配：如果服务器只支持老旧、不安全的SSL 2.0/3.0协议，或者使用已被认为不安全的加密套件，现代浏览器可能会出于安全考虑拒绝连接。</p><ol start="6"><li>客户端系统时间/日期不正确</li></ol><p>SSL证书的有效期是严格基于时间的。如果用户电脑的系统日期和时间设置不正确（例如，日期被设置到了未来，或者回到了证书颁发之前的过去），浏览器在检查证书有效期时就会做出错误判断，认为一个有效的证书已经“过期”或“尚未生效”。</p><ol start="7"><li>中间人攻击或网络干扰</li></ol><p>在某些情况下，警告可能是真实安全威胁的征兆。</p><p>中间人攻击：黑客可能在用户与目标网站之间植入自己的代理，并出示一个伪造的或不受信任的证书，试图解密通信数据。安全意识强的软件（如某些杀毒软件或企业防火墙）也会进行HTTPS扫描，它们会用自己的证书重新签署所有流量，如果用户设备上没有安装这些软件的根证书，就会触发警告。</p><p>ISP或网络管理员干扰：一些网络服务提供商或公司网络管理员可能会对流量进行过滤和审查，同样可能引起证书错误。</p><ol start="8"><li>操作系统或浏览器根证书列表过时</li></ol><p>用户的操作系统或浏览器如果长期未更新，其内置的受信任根证书列表可能已经过时。这意味着，一个新近被广泛信任的CA颁发的证书，可能无法被一个旧版本的系统所识别。</p>]]></description></item><item>    <title><![CDATA[从 useState 到 URLStat]]></title>    <link>https://segmentfault.com/a/1190000047389968</link>    <guid>https://segmentfault.com/a/1190000047389968</guid>    <pubDate>2025-11-11 18:14:10</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>1. 前言</h2><p>当你打开这个网址时：</p><pre><code class="plain">https://prismjs.com/download.html#themes=prism&amp;languages=markup+css+clike+javascript&amp;plugins=line-numbers</code></pre><p>你会发现，所有你需要的主题、语言、插件已经被自动勾选：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047389970" alt="" title=""/></p><p>当你在页面修改配置时，URL 也会随之改变。</p><p>你看，这个 URL 不仅仅是一个链接，更是一个<strong>完整的状态容器</strong>，保存了我的所有配置。无需数据库、cookie 或 localStorage，一个 URL 就解决了一切。</p><h2>2. 被忽视的 URL 超能力</h2><p>URL 是互联网最伟大的创意之一，通过 URL 请求，我们可以查找到网络上的唯一资源。</p><p>它的标准格式为：<code>&lt;scheme&gt;://&lt;netloc&gt;/&lt;path&gt;?&lt;query&gt;#&lt;fragment&gt;</code>。</p><p>但 URL 的价值远不止于此——它们是<strong>天然的状态管理解决方案</strong>。想想 URL 给我们带来的好处：</p><ul><li><strong>可分享性</strong>：发送链接，对方会看到与你完全相同的内容</li><li><strong>可书签化</strong>：保存 URL 就是保存一个特定时刻的状态</li><li><strong>浏览器历史</strong>：后退按钮正常工作</li><li><strong>深度链接</strong>：直接跳转到应用的特定状态</li></ul><p>URL 使 Web 应用具有<strong>韧性和可预测性</strong>。它们是 Web 最初的状态管理方案，自 1990 年以来就开始使用，所以千万不要忘记使用这种方式。</p><h2>3. URL 如何编码状态？</h2><p>URL 的不同部分编码不同类型的状态：</p><p><strong>路径段（/path/to/myfile.html）</strong>：最适合层次化资源导航</p><pre><code class="plain">/users/123/posts        # 用户123的文章
/docs/api/authentication # 文档结构</code></pre><p><strong>查询参数（?key1=value1&amp;key2=value2）</strong>：完美用于过滤器、选项和配置</p><pre><code class="plain">?theme=dark&amp;lang=en     # UI 偏好设置
?page=2&amp;limit=20        # 分页
?status=active&amp;sort=date # 数据过滤</code></pre><p><strong>锚点片段（#SomewhereInTheDocument）</strong>：适合客户端导航和页面部分</p><pre><code class="plain">#L20-L35        # GitHub 行高亮
#features       # 滚动到某个章节</code></pre><h2>4. URL 编码状态常见模式</h2><h3>4.1. 多个带分隔符的值</h3><pre><code class="plain">?languages=javascript+typescript+python
?tags=frontend,react,hooks</code></pre><p>这种方式简洁易读，但需要在服务器端手动解析。</p><h3>4.2. 嵌套或结构化数据</h3><pre><code class="plain">?filters=status:active,owner:me,priority:high
?config=eyJyaWNrIjoicm9sbCJ9==  (base64-encoded JSON)</code></pre><p>开发者有时会将复杂的筛选器或配置对象编码到单个查询字符串中。</p><p>一种简单的约定是使用逗号分隔的键值对，而其他方法则会序列化 JSON，甚至为了安全起见对其进行 Base64 编码。</p><h3>4.3. 数组处理（方括号表示法）</h3><pre><code class="plain">?tags[]=frontend&amp;tags[]=react&amp;tags[]=hooks
?ids[0]=42&amp;ids[1]=73</code></pre><p>一种古老的模式是方括号表示法，它用于在查询参数中表示数组。这种表示法起源于早期的 Web 框架，例如 PHP，在 <code>[]</code> 参数名称后添加括号表示多个值应该组合在一起。</p><p>许多现代框架和解析器（例如 Node 的 qs 库或 Express 中间件）仍然能够自动识别这种模式。然而，它并未在 URL 规范中正式标准化，因此其行为可能因服务器或客户端的实现而异。</p><h3>4.4. 布尔处理</h3><p>对于 flag 或开关，通常会显式传递布尔值，或者依赖于键值是否为真。这样可以缩短 URL 长度，并简化功能切换。</p><pre><code class="plain">?debug=true&amp;analytics=false
?mobile  (presence = true)</code></pre><h3>4.5. 结论</h3><p>使用哪种模式都是可以的，关键在于保持一致性。选择适合你应用场景的模式，并坚持使用。</p><h2>5. 实际应用案例</h2><p><strong>GitHub 行高亮：</strong></p><pre><code class="plain">https://github.com/zepouet/Xee-xCode-4.5/blob/master/XeePhotoshopLoader.m#L108-L136</code></pre><p>链接到特定文件，同时高亮显示 108-136 行。点击此链接，你会直接定位到讨论的确切代码部分。</p><p><strong>电商数据过滤器：</strong></p><pre><code class="plain">https://store.com/laptops?brand=dell+hp&amp;price=500-1500&amp;rating=4&amp;sort=price-asc</code></pre><p>这是最常见的实现。每个过滤条件、排序选项都被保存。用户可以用书签保存他们的筛选条件。</p><p><strong>谷歌地图：</strong></p><pre><code class="plain">https://www.google.com/maps/@22.443842,-74.220744,19z</code></pre><p>坐标、缩放级别和地图类型都包含在 URL 中。分享此链接，任何人都可以看到完全相同的地图视图。</p><h2>6. 什么状态应该放入 URL？</h2><p>然而<strong>并非所有状态都应该属于 URL，那什么样的状态应该放入 URL 呢？</strong></p><p><strong>适合 URL 状态：</strong></p><ul><li>搜索查询和筛选器</li><li>分页和排序</li><li>视图模式（列表/网格、深色/浅色）</li><li>日期范围和时间段</li><li>选中项或活动标签</li><li>影响内容的 UI 配置</li><li>功能开关和 A/B 测试版本</li></ul><p><strong>不适合 URL 状态：</strong></p><ul><li>敏感信息（密码、令牌、个人身份信息）</li><li>临时 UI 状态（模态框打开/关闭）</li><li>表单输入进行中（未保存的更改）</li><li>极其庞大或复杂的嵌套数据</li><li>高频瞬态（鼠标位置、滚轮位置）</li></ul><p>简单来说，你的判断标准是：</p><p><strong>如果别人点击这个 URL，他们应该看到相同的状态吗？</strong></p><p>如果是，它就属于 URL。</p><h2>7. 实现方案</h2><h3>7.1. 使用纯 JavaScript 实现</h3><p>现代 URLSearchParams API 使 URL 状态管理变得简单：</p><pre><code class="javascript">// 读取URL参数
const params = new URLSearchParams(window.location.search);
const view = params.get("view") || "grid"; // 默认值
const page = parseInt(params.get("page")) || 1;

// 更新URL参数
function updateFilters(filters) {
  const params = new URLSearchParams(window.location.search);

  params.set("status", filters.status);
  params.set("sort", filters.sort);

  // 更新URL而不重新加载页面
  const newUrl = `${window.location.pathname}?${params.toString()}`;
  window.history.pushState({}, "", newUrl);
}

// 处理后/前进按钮
window.addEventListener("popstate", () =&gt; {
  const params = new URLSearchParams(window.location.search);
  const filters = {
    status: params.get("status") || "all",
    sort: params.get("sort") || "date",
  };
  renderContent(filters);
});</code></pre><h3>7.2. 使用 React 实现</h3><p>React Router 提供了更简洁的钩子：</p><pre><code class="jsx">import { useSearchParams } from "react-router-dom";

function ProductList() {
  const [searchParams, setSearchParams] = useSearchParams();

  const color = searchParams.get("color") || "all";
  const sort = searchParams.get("sort") || "price";

  const handleColorChange = (newColor) =&gt; {
    setSearchParams((prev) =&gt; {
      const params = new URLSearchParams(prev);
      params.set("color", newColor);
      return params;
    });
  };

  return (
    &lt;select value={color} onChange={(e) =&gt; handleColorChange(e.target.value)}&gt;
      &lt;option value="all"&gt;所有颜色&lt;/option&gt;
      &lt;option value="silver"&gt;银色&lt;/option&gt;
    &lt;/select&gt;
  );
}</code></pre><h2>8. URL 使用最佳实践</h2><h3>8.1. <strong>优雅处理默认值</strong></h3><p>不要在 URL 中使用默认值：</p><pre><code class="jsx">// ❌
?theme=light&amp;lang=en&amp;page=1&amp;sort=date

// ✅
?theme=dark  // light 是默认的，但 dark 不是默认的</code></pre><p>在代码中读取参数时使用默认值：</p><pre><code class="jsx">function getTheme(params) {
  return params.get("theme") || "light"; // 在代码中设置默认值
}</code></pre><h3>8.2. URL 更新防抖动</h3><p>对于高频更新（例如边输入边搜索），要对 URL 更改进行防抖处理：</p><pre><code class="jsx">import { debounce } from "lodash";

const updateSearchParam = debounce((value) =&gt; {
  const params = new URLSearchParams(window.location.search);
  if (value) {
    params.set("q", value);
  } else {
    params.delete("q");
  }
  window.history.replaceState({}, "", `?${params.toString()}`);
}, 300);</code></pre><h3>8.3. URL 传达意义</h3><pre><code class="jsx">https://example.com/p?id=x7f2k&amp;v=3 ❌
https://example.com/products/laptop?color=silver&amp;sort=price ✅</code></pre><p>第一个链接隐藏了意图，第二个链接则意义清晰。人可以阅读它并理解其含义。机器可以解析它并提取有意义的结构。这才是优秀的 URL。</p><h2>9. 使用时要避免的反模式</h2><h3>9.1. 状态都保存在内存中的单页应用程序</h3><pre><code class="plain">// 用户一刷新，状态都丢失了
const [filters, setFilters] = useState({});</code></pre><p>如果你的应用在刷新后丢失了之前的状态，你就破坏了网络的一项基本功能。用户期望 URL 能够保留上下文。</p><h3>9.2. 包含敏感数据</h3><pre><code class="plain">// 别这样干
?password=secret123</code></pre><h3>9.3. 命名不一致或晦涩难懂</h3><pre><code class="plain">// 晦涩难懂
?foo=true&amp;bar=2&amp;x=dark

// 自文档化且风格保持一致
?mobile=true&amp;page=2&amp;theme=dark</code></pre><h3>9.4. 注意 URL 长度限制</h3><p>浏览器和服务器对 URL 长度都有实际的限制（通常在 2000 到 8000 个字符之间），但实际情况更为复杂，会有来自浏览器行为、服务器配置、CDN 甚至搜索引擎的限制等多种因素。</p><p>如果你遇到了这些限制，那就说明你需要重新考虑你的策略了。</p><h2>10. 总结</h2><p>好的 URL 不仅仅是指向内容，它更是描述了用户和应用程序之间的对话。</p><p>我们已经构建了复杂的状态管理库，但有时最好的解决方案其实是最简单的那一个。<strong>当你的应用在点击刷新时失去了状态，想一想，你是否错过了这个 Web 最古老、最优雅的特性？</strong></p><h2>11. 参考链接</h2><ol><li><a href="https://link.segmentfault.com/?enc=n%2FrkerJgIhzuAazYc%2BODVg%3D%3D.8MDf0tFkjYbF2OqUB9qaLH%2B5gBgYwihLq54DKHXNmiGjQ2PmFkhssirkD0CfVs%2BfRgsLkkN952WaEoKLKh7tTg%3D%3D" rel="nofollow" target="_blank">Your URL Is Your State</a></li></ol>]]></description></item><item>    <title><![CDATA[《实施意见》政策解读：数字孪生在新场景规]]></title>    <link>https://segmentfault.com/a/1190000047389997</link>    <guid>https://segmentfault.com/a/1190000047389997</guid>    <pubDate>2025-11-11 18:13:15</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>2025年11月，国务院印发《关于加快场景培育和开放推动新场景大规模应用的实施意见》对外开放，明确提出聚焦数字经济、智能制造、清洁能源、低空经济等22类重点应用场景，通过场景开放加速技术创新和产业升级。这一政策为数字孪生技术的规模化应用提供了重要契机。<br/><img width="723" height="1118" referrerpolicy="no-referrer" src="/img/bVdm0sj" alt="" title=""/></p><h2>政策导向与技术创新需求</h2><p>《实施意见》标志着我国科技创新模式正从 “技术驱动”向“场景牵引” 转变。文件明确要求通过场景建设推动新技术、新产品、新模式的验证和迭代，而数字孪生技术凭借其虚拟映射、实时交互和智能决策的能力，成为22类场景规模化应用的 “验证核心” 。</p><p>在智能制造领域，数字孪生通过构建 “设计-生产-运维”全链条数字化映射，实现制造过程的优化和预测性维护。以某汽车零部件智能工厂为例，通过部署数字孪生平台，实现了设备利用率提升25%、运维成本降低30% 的显著成效。<br/><img width="723" height="413" referrerpolicy="no-referrer" src="/img/bVdm0sx" alt="" title="" loading="lazy"/></p><h2>技术原理一：多尺度建模与动态仿真</h2><p>数字孪生技术的核心在于建立物理实体的多尺度虚拟模型。基于哈密顿原理的系统动力学方程为：<br/><img width="231" height="81" referrerpolicy="no-referrer" src="/img/bVdm0sz" alt="" title="" loading="lazy"/></p><p>其中T为系统动能，V为势能。该模型能够精准描述复杂系统在不同尺度下的动态响应特性。在具体实现中，采用多物理场耦合仿真技术，通过求解纳维-斯托克斯方程与热传导方程的耦合系统，预测设备在极端工况下的性能表现，将设计验证周期缩短40%以上。</p><h2>技术原理二：实时数据融合与智能决策</h2><p>数字孪生平台通过时空数据融合引擎，实现多源异构数据的实时集成与分析。基于卡尔曼滤波的数据融合算法：<br/><img width="269" height="51" referrerpolicy="no-referrer" src="/img/bVdm0sH" alt="" title="" loading="lazy"/><br/>能够有效处理传感器数据、业务系统数据等多源信息，提升决策准确性。在清洁能源场景中，该技术已实现风电设备运行状态的实时监测和故障预警，使运维响应时间从小时级缩短至分钟级。<br/><img width="723" height="357" referrerpolicy="no-referrer" src="/img/bVdm0sJ" alt="" title="" loading="lazy"/></p><h2>技术原理三：基于AI的预测性维护</h2><p>数字孪生结合深度学习技术，实现设备健康状态的精准预测。通过构建自编码器网络：<br/><img width="262" height="79" referrerpolicy="no-referrer" src="/img/bVdm0sK" alt="" title="" loading="lazy"/><br/>系统能够从历史数据中学习设备退化规律，实现预测性维护，将设备非计划停机时间减少50%以上。<br/><img width="723" height="409" referrerpolicy="no-referrer" src="/img/bVdm0sL" alt="" title="" loading="lazy"/></p><h2>凡拓数创实践案例</h2><p>在深圳智能网联交通测试示范平台建设中，凡拓数创通过数字孪生技术构建了覆盖 “车-路-云”一体化测试环境。该平台实现了对智能网联汽车测试过程的全程数字化映射，为低空经济等新场景提供了可靠的验证环境。<br/><img width="723" height="317" referrerpolicy="no-referrer" src="/img/bVdm0sh" alt="" title="" loading="lazy"/></p><p>平台采用多源数据融合技术，集成高精地图、实时交通流、气象环境等多维数据，通过数字孪生引擎实现测试场景的快速构建和仿真验证，显著提升了测试效率和安全性。<br/><img width="723" height="317" referrerpolicy="no-referrer" src="/img/bVdm0sP" alt="" title="" loading="lazy"/></p><p>产业化应用前景<br/>随着政策的深入推进，数字孪生技术在22类场景中的应用将加速落地。在数字经济领域，数字孪生将助力构建城市级数据资源体系；在智能制造领域，将推动形成 “虚拟生产-实体制造”的新型生产模式。</p><p>预计到2026年，数字孪生技术将在重点行业实现规模化应用，形成一批可复制、可推广的解决方案，为经济社会数字化转型提供强大支撑。</p><h2>总结与展望</h2><p>国务院《实施意见》的发布，为数字孪生技术在新场景中的应用提供了政策保障和发展机遇。通过技术创新与场景实践的深度融合，数字孪生正成为推动产业数字化、智能化转型的关键力量。</p><p>未来，随着5G、人工智能等新技术的持续创新，数字孪生将进一步提升其在复杂系统建模、实时仿真和智能决策方面的能力，为22类应用场景的规模化落地提供更加坚实的技术支撑。</p><h4>参考文献</h4><p>[1] 国务院. 关于加快场景培育和开放推动新场景大规模应用的实施意见. 2024.<br/> [2] 数字孪生城市白皮书. 中国信息通信研究院, 2024.<br/> [3] 智能制造发展报告. 工业和信息化部, 2024.<br/> [4] 深圳智能网联汽车测试示范区建设方案. 深圳市交通运输局, 2024.</p>]]></description></item><item>    <title><![CDATA[Goland 2025.2.4 11月最]]></title>    <link>https://segmentfault.com/a/1190000047390001</link>    <guid>https://segmentfault.com/a/1190000047390001</guid>    <pubDate>2025-11-11 18:12:30</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img width="686" height="454" referrerpolicy="no-referrer" src="/img/bVdm0sW" alt="go.png" title="go.png"/></p><h2>一 安装</h2><p>官网下载：<a href="https://link.segmentfault.com/?enc=GehxW3zu97DSYjRUI9u9MA%3D%3D.OySRlHCiGvOF4jYwSb4hcanA8tgdKxAlgfaxGgx%2FcZowzYzYA6HNxHQ7ey6dAFPw" rel="nofollow" target="_blank">https://www.jetbrains.com.cn/go/</a><br/>根据提示安装</p><h2>二 授权说明</h2><p><img width="723" height="265" referrerpolicy="no-referrer" src="https://segmentfault.com/img/bVdmZkU" alt="图片" title="图片" loading="lazy"/><br/>回复 《go》获取新版本安装后不提示授权，需要手动处理</p><h2>三 使用</h2><p>打开自己的项目，配置环境，开始开发<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdm0s0" alt="image.png" title="image.png" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[隐语社区可信数据空间MOOC第16讲笔记]]></title>    <link>https://segmentfault.com/a/1190000047390004</link>    <guid>https://segmentfault.com/a/1190000047390004</guid>    <pubDate>2025-11-11 18:11:34</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdm0sO" alt="" title=""/></p><h2>2.10 机密容器的安全设计及落地实践 学习笔记</h2><h3>一、机密容器产生的背景</h3><h4>1. 数据要素市场背景</h4><ul><li><p><strong>政策推动</strong>：</p><ul><li>2020.04：加快培育数据要素市场</li><li>2022.12：《数据二十条》</li><li>2023.03：组建国家数据局</li><li>2024.01：《"数据要素×"三年行动计划》</li></ul></li><li><strong>核心矛盾</strong>：数据价值越大，流通风险越高</li></ul><h4>2. 密态计算与机密计算</h4><ul><li><strong>密态计算</strong>：数据在计算过程中始终加密，防止滥用和泄露</li><li><strong>机密计算</strong>：通过TEE保护使用中的数据，实现"可用不可见，可算不可识"</li></ul><h4>3. 技术演进路径</h4><h5>（1）进程级TEE</h5><ul><li><strong>代表</strong>：Intel SGX</li><li><strong>优点</strong>：TCB小，安全性好</li><li><strong>缺点</strong>：兼容性差，开发成本高，性能差</li></ul><h5>（2）机密虚拟机</h5><ul><li><strong>代表</strong>：Intel TDX、AMD SEV-SNP、ARM CCA、HyperEnclave</li><li><strong>优点</strong>：兼容性好，应用无需改造，可利用GPU等硬件</li><li><strong>缺点</strong>：TCB大</li></ul><h5>（3）机密容器</h5><ul><li><strong>代表</strong>：CoCo（Confidential Containers）</li><li><strong>优点</strong>：结合机密虚拟机和Kata云原生技术，TCB更小，适合云场景大规模部署</li></ul><h4>4. 机密容器 vs 安全容器</h4><table><thead><tr><th>组件</th><th>安全容器</th><th>机密容器</th></tr></thead><tbody><tr><td>容器运行时</td><td>Kata</td><td>Kata</td></tr><tr><td>威胁模型</td><td>宿主机可信，客户机不可信</td><td>宿主机不可信，保护客户机隐私</td></tr><tr><td>技术范围</td><td>KVM虚拟化层隔离</td><td>集成TEE硬件、全链路加密、远程证明</td></tr><tr><td>应用场景</td><td>多租保护，防容器逃逸</td><td>机密计算</td></tr></tbody></table><hr/><h3>二、机密容器的安全体系设计</h3><h4>1. 基于HyperEnclave的架构</h4><pre><code>HostOS
├── kubelet
├── containerd
├── kata-shim
└── cloud-hypervisor
    └── Kata Pod
        ├── Containers
        ├── attestation-agent
        └── kata-agent</code></pre><p><strong>主要特点</strong>：</p><ul><li><strong>通用性</strong>：支持海光、Intel、AMD、ARM等主流CPU</li><li><strong>自主可控</strong>：信任根与CPU解耦，托管国家权威机构</li><li><strong>安全可证</strong>：首个形式化验证的Rust Hypervisor</li><li><strong>简单易用</strong>：支持Occlum、Linux、CoCo等生态</li></ul><h4>2. HyperEnclave安全隔离</h4><h5>（1）内存隔离</h5><ul><li>HyperEnclave通过页表机制控制软件内存访问</li><li>实现REE与TEE之间、TEE之间的内存隔离</li></ul><h5>（2）CPU状态隔离</h5><ul><li>在不同Context切换时清理CPU寄存器</li></ul><h5>（3）设备隔离</h5><ul><li>管理IOMMU，管控页表与Port I/O访问</li><li>实现控制面和数据面的保护</li></ul><h4>3. 全链路密态</h4><h5>（1）密态计算</h5><ul><li>数据加密后流入机密容器</li><li>只在硬件隔离环境解密运算</li><li>内存使用中的数据自动加密</li></ul><h5>（2）密态存储</h5><ul><li>容器镜像代码数据</li><li>临时写盘数据</li><li>业务持久化数据</li><li>全部透明加密</li></ul><h5>（3）密态传输</h5><ul><li>可信设备总线传输加密</li><li>业务网络传输通过加密网关自动加密</li></ul><h4>4. 运维通道管控</h4><h5>（1）API层防护</h5><ul><li>基于Initdata静态和动态策略</li><li>通过OPA策略引擎管控可执行操作</li></ul><h5>（2）系统层防护</h5><ul><li>动态下发基于eBPF的安全策略</li><li>限制可执行的二进制和syscall</li></ul><h5>（3）运维输出加密</h5><ul><li>运维通道输出默认加密</li><li>只有授权用户可见明文</li></ul><h5>（4）审计存证</h5><ul><li>所有运维操作详细审计存证</li></ul><hr/><h3>三、核心优势总结</h3><h4>1. 技术优势</h4><ul><li><strong>通用硬件支持</strong>：不依赖特定硬件</li><li><strong>云原生集成</strong>：基于Kata容器技术</li><li><strong>全链路安全</strong>：计算、存储、传输全程密态</li></ul><h4>2. 安全特性</h4><ul><li><strong>硬件级隔离</strong>：基于TEE的强隔离</li><li><strong>细粒度管控</strong>：API层和系统层双重防护</li><li><strong>可验证信任</strong>：远程证明能力</li></ul><h4>3. 适用场景</h4><ul><li>多方数据联合计算</li><li>隐私敏感业务部署</li><li>云上机密工作负载</li></ul><hr/><h3>四、实践价值</h3><p>机密容器通过：</p><ul><li><strong>标准化容器接口</strong>：降低使用门槛</li><li><strong>硬件无关设计</strong>：提高部署灵活性</li><li><strong>全链路加密</strong>：确保数据安全</li><li><strong>云原生集成</strong>：支持大规模运维</li></ul><p>为数据要素安全流通提供了可行的容器化解决方案。</p>]]></description></item><item>    <title><![CDATA[利用目录分类提升SEO排名！优化策略与实]]></title>    <link>https://segmentfault.com/a/1190000047390007</link>    <guid>https://segmentfault.com/a/1190000047390007</guid>    <pubDate>2025-11-11 18:10:45</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在网站运营领域，目录分类的规划设计不仅关乎用户体验的优劣，更对搜索引擎优化（SEO）成效起着决定性作用。科学合理的目录架构，有助于搜索引擎更高效地抓取网页内容，进而提升页面的权重值与搜索排名。本文将深入剖析目录分类对SEO产生的具体影响，并分享若干实用的优化策略。</p><p>一、什么是目录分类？</p><p>目录分类是网站URL路径中的层级结。</p><p>它反映了网站内容的组织方式，直接影响到搜索引擎的抓取效率和用户对页面层级的理解。</p><p>二、目录分类对SEO的主要影响</p><p>2.1提高网站抓取效率</p><p>清晰的目录结构有助于搜索引擎爬虫快速理解页面内容，减少抓取深度，提升抓取效率。过于复杂或混乱的分类会导致爬虫迷失或忽略部分页面。</p><p>优化建议：</p><p>保持目录层级不超过3层。</p><p>使用语义化清晰的目录名称，例如products/shoes优于p/12345。</p><p>2.2增强关键词优化</p><p>目录名称中合理嵌入关键词，可以提升相关页面的SEO表现。例如：</p><p>此类路径不仅对用户友好，也能提升页面在相关关键词的排名。</p><p>优化建议：</p><p>使用与页面内容高度相关的目录名称。</p><p>避免堆砌关键词，保持URL简洁。</p><p>2.3集中权重传递</p><p>合理的目录结构可以有效地传递页面权重，帮助重要页面获得更高的排名。如果目录过于分散，会导致权重分流，降低核心页面的SEO效果。</p><p>优化建议：</p><p>在目录首页合理设置内部链接。</p><p>确保目录首页具有重要内容，以便权重集中。</p><p>2.4提升用户体验</p><p>用户友好的目录分类可以让访客更轻松地找到目标内容，从而减少跳出率、增加停留时间，这些都是搜索引擎排名的重要指标。</p><p>优化建议：</p><p>使用面包屑导航（Breadcrumbs）。</p><p>通过目录提供清晰的内容层级，方便用户定位。</p><p>三、不合理目录分类的风险</p><p>3.1抓取深度过大</p><p>如果重要内容埋藏在过深的层级中，搜索引擎爬虫可能不会抓取到这些页面，导致它们无法被索引。</p><p>3.2重复内容问题</p><p>不规范的目录分类可能导致重复页面的生成</p><p>3.3 URL过长影响可读性</p><p>目录过多会导致URL冗长，不仅不利于SEO，还会降低用户点击的意愿。</p><p>四、如何优化目录分类以提升SEO效果</p><p>4.1保持目录层级简洁</p><p>将重要页面放在靠近根目录的位置，减少不必要的子分类。</p><p>4.2采用语义化命名</p><p>确保目录名称能够直观地表达内容主题。</p><p>4.3利用301重定向优化旧目录</p><p>如果需要更改目录结构，使用301重定向将旧URL指向新URL，确保流量和权重不会丢失。</p><p>4.4避免动态参数过多</p><p>URL中尽量减少动态参数，推荐使用伪静态URL以提升SEO表现。</p><p>五、下面以站长工具网首页的链接</p><p>作为示例：</p><p><a href="https://link.segmentfault.com/?enc=pnpIoueEOJicHy7jVWyVyw%3D%3D.dkwDT%2BDcJzR0Sdqbx1kTQE2CzvLjIHxD9QkS4o3gw6c%3D" rel="nofollow" target="_blank">https://mybj123.com</a></p><p><a href="https://link.segmentfault.com/?enc=mpfqp6bePh5EoZGK13JMuA%3D%3D.ZaBIPefaLVIqRmMLX2OexQHh3smYqAiG4WliUP64KnU%3D" rel="nofollow" target="_blank">https://mybj123.com/qdkfnote/</a></p><p><a href="https://link.segmentfault.com/?enc=4OeexjpZXVZgOe0dUQZKmg%3D%3D.MnZlcLkTMbNe7zn3s0LLJRLSHBH2QACOaUUOylmYq%2Fg%3D" rel="nofollow" target="_blank">https://mybj123.com/backend/</a></p><p><a href="https://link.segmentfault.com/?enc=jwcPV%2F90HhJczXtN1gkm1w%3D%3D.OzXg7Kgq059lF4XCamv8B%2F61oRAnHyPesgk6kh1%2Bdj8%3D" rel="nofollow" target="_blank">https://mybj123.com/problemset/</a></p><p><a href="https://link.segmentfault.com/?enc=gHH7KLRBHh2erm6%2BcdR1KQ%3D%3D.rNIem798usy%2FQE3mvCFbjWDiNNY%2FP1hM1dwLMYkQQRU%3D" rel="nofollow" target="_blank">https://mybj123.com/database/</a></p><p><a href="https://link.segmentfault.com/?enc=uqgFHnwisw4mIVo0hf8yPw%3D%3D.HGLYKeZY8uz2J8%2FP82jOM47yTYMe9x0EomqBFF8XSJI%3D" rel="nofollow" target="_blank">https://mybj123.com/server/</a></p><p><a href="https://link.segmentfault.com/?enc=KruoehAQP%2FB4%2BBunZMhH3w%3D%3D.btuAuMK4tRBZCF%2B8WnDq5urorgQGKGqa0Vtsab%2BHi14%3D" rel="nofollow" target="_blank">https://mybj123.com/opensource/</a></p><p><a href="https://link.segmentfault.com/?enc=TeAF0tywQeaQQwkOX29B0g%3D%3D.0X67awbhJd28lg8oAHr4IOaAJWO763AGJuTv0aEul0k%3D" rel="nofollow" target="_blank">https://mybj123.com/welfare/</a></p><p><a href="https://link.segmentfault.com/?enc=LmUSIZg0u16G4ONaOPeHNQ%3D%3D.LNtqFVyi5TGWCdzG45spYI%2BQ6jYJPZsmv57QgVKEnX0%3D" rel="nofollow" target="_blank">https://mybj123.com/ai/</a></p><p><a href="https://link.segmentfault.com/?enc=QH5FZXUz7yNclaxE6UHSKw%3D%3D.iFmSOubZ%2F2GkmUIqOdQE60OHYs%2BCS03yB%2BdmcFvRJLo%3D" rel="nofollow" target="_blank">https://mybj123.com/aitool/</a></p><p><a href="https://link.segmentfault.com/?enc=iCkz1S6jDxRqPetPPBQ24g%3D%3D.YxGIWklKYLlLkgPpVMxGKxaCMqHNfbvlutx2H6QDuj4%3D" rel="nofollow" target="_blank">https://mybj123.com/article/</a></p><p><a href="https://link.segmentfault.com/?enc=t%2FXIRCBk2Jld1%2BfSOdkIYA%3D%3D.TvOdkqtpEnNKRy0w2uAmfDgWdoq3aiHzBI%2FBrEgM%2B9s%3D" rel="nofollow" target="_blank">https://mybj123.com/news/</a></p><p><a href="https://link.segmentfault.com/?enc=qLJ0w%2FjqG1AfZOynDtlXQw%3D%3D.BrqzU4W6TAKx97gZSnkJpjslR%2Fn0G%2BhCg%2B8eGiWqetw%3D" rel="nofollow" target="_blank">https://mybj123.com/yunwei/</a></p><p><a href="https://link.segmentfault.com/?enc=AOInhJ2Q7XWrWbXAxDaVyA%3D%3D.7PfAxpzipjiu9wI0nKDJf3rNA5PmaCk7EBYQlauplZGhc1jYpp84YMhfUXiK37I0" rel="nofollow" target="_blank">https://mybj123.com/computer-tutorial/</a></p><p><a href="https://link.segmentfault.com/?enc=it8xQHOXPu56yms5I8bgYQ%3D%3D.bLhdYsPxTSY1xw2B36dgn9xpJdpAtJb03Owmn%2FeTmndE%2B7u3QuZsdKSVhZi3wHPK" rel="nofollow" target="_blank">https://mybj123.com/system-tutorial/</a></p><p><a href="https://link.segmentfault.com/?enc=20xLuzbodmZXqmDgFpO5Gg%3D%3D.6OZbykS8okXy4h6ePV93fdg%2F8qDPVlRsfZyuJQ0VV9Ceww7KyQUuh041U58A0M90" rel="nofollow" target="_blank">https://mybj123.com/software-tutorials/</a></p><p><a href="https://link.segmentfault.com/?enc=aQ14PiNdKDx5cQ%2F77ns7xw%3D%3D.BCh%2Fjvc3a7J6XC6x%2BZrVDHsP5wppgShAueAtyls2d0FUdQin67mU%2FjFyxQbneliZ" rel="nofollow" target="_blank">https://mybj123.com/mobile-tutorial/</a></p><p><a href="https://link.segmentfault.com/?enc=iK0xJvx8Cmca5LkT4P09PQ%3D%3D.EIYY8qIvpMxEs7BeXwLsSuk0WU6s5DHIfUjUTSba5kQ%3D" rel="nofollow" target="_blank">https://mybj123.com/selfmedia/</a></p><p><a href="https://link.segmentfault.com/?enc=tgjQjG5xQAetZktcNufFCw%3D%3D.Pk%2FRiSh%2BCAxBUvzoPUi3AAix82oLAy41K7us17dc0ns%3D" rel="nofollow" target="_blank">https://mybj123.com/chat/</a></p>]]></description></item><item>    <title><![CDATA[Gemini CLI 核心命令指南，让工]]></title>    <link>https://segmentfault.com/a/1190000047390012</link>    <guid>https://segmentfault.com/a/1190000047390012</guid>    <pubDate>2025-11-11 18:09:56</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>让我看看，谁还没有用上 Gemini CLI？</p><p><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdm0s9" alt="image.png" title="image.png"/></p><ul><li><strong>免费额度</strong>：个人 Google 账户可享受每分钟 60 次请求的免费额度，足以满足日常开发中的交互需求。</li><li><strong>强大的模型支持</strong>：由 Gemini 2.5 Pro 模型驱动，拥有高达一百万 token 的上下文窗口，能够处理和理解大型代码库或复杂的文档。</li><li><strong>内置工具集</strong>：集成了多种实用工具，包括使用 Google 搜索来提供有时效性的回答、执行文件系统操作、运行 shell 命令以及获取网页内容。</li><li><strong>可扩展性</strong>：支持模型上下文协议（Model Context Protocol, MCP），为开发者创建自定义工具集成提供了可能。</li><li><strong>终端优先设计</strong>：完全为那些以命令行作为主要工作环境的开发者量身打造。</li><li><strong>开源许可</strong>：项目基于 Apache 2.0 许可证开源，保证了其透明度和社区参与度。</li></ul><p>Gemini CLI 部署起来也很容易，用 ServBay 一键安装好 Node.js 20或者更高的版本，直接通过<code>npm</code>就可以安装Gemini CLI。</p><pre><code>npm install -g @google/gemini-cli</code></pre><p>之所以推荐 ServBay ，是因为它提供了一个隔离的<a href="https://link.segmentfault.com/?enc=Ziv4iL0boMXuTm7sWFaYxA%3D%3D.wbJQSo%2FOCU1II6VmeIrcxQydMBhmRUz7ZiP%2B7VUqBS1GJnMkUOtQh%2Bb0mApumMH4" rel="nofollow" target="_blank">集成开发环境</a>，允许开发者通过图形化界面一键部署和管理包括 Node.js、Rust 在内的多种服务。这种方式避免了使用版本管理器（如 nvm）在系统全局范围内频繁切换的复杂性，也杜绝了传统包管理器（如 Homebrew）可能带来的依赖混乱，干净又卫生。</p><p><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdm0s9" alt="image.png" title="image.png" loading="lazy"/></p><p>安装完毕，便可以开始探索 Gemini CLI 的功能。</p><h3>初始配置：建立与项目的连接</h3><p>首次在项目中使用 Gemini CLI，需要执行几个基础命令来完成初始化和配置。</p><ul><li><strong>/init：</strong> 在项目根目录执行此命令，是与 Gemini CLI 建立联系的第一步。它会分析项目结构，为后续的交互提供上下文基础。</li><li><strong>/auth：</strong> 此命令用于处理身份验证。首次执行时，它会引导用户完成 Google 账户的登录与授权流程，确保 CLI 拥有访问 AI 服务的权限。</li><li><strong>/about：</strong> 查询当前 Gemini CLI 的版本、所使用的底层模型以及配置的身份验证方法。这个命令有助于了解工具的当前状态。</li><li><strong>/help</strong> &amp; <strong>/docs：</strong> 遇到疑问时，<code>/help</code> 提供了一个快速的命令列表。而 <code>/docs</code> 则会在浏览器中打开官方文档，供查阅更详尽的信息。</li></ul><h3>核心功能：日常工作流中的命令</h3><p>熟悉基本配置后，以下这些命令将成为日常开发中的得力工具。</p><ul><li><strong>! (Shell 命令前缀)</strong> ：这是一个极为实用的功能。在输入框中以 <code>!</code> 开头，可以直接执行 shell 命令。更进一步，可以结合自然语言让 Gemini 解释或生成命令，这对于处理那些复杂或不常用的命令尤为有效。</li><li><strong>/tools：</strong> 执行此命令可以列出 Gemini 当前可用的所有工具集。了解其能力边界，有助于提出更精准、更有效的问题。</li><li><strong>/editor</strong>：对于需要输入大段代码或复杂问题的场景，终端的单行输入框显得捉襟见肘。通过 <code>/editor</code> 命令配置一个外部文本编辑器（如 VS Code 或 Vim），之后使用 <code>Ctrl+X</code> 快捷键即可在熟悉的环境中编写提示，完成后保存退出，内容便会自动发送。</li></ul><h3>会话管理：保存与追溯思路</h3><p>与 Gemini 的交互是一个连续的对话过程，保留这些上下文对于解决复杂问题非常有价值。</p><ul><li><strong>/chat</strong>：这是一个功能强大的会话管理命令。使用 <code>/chat save &lt;name&gt;</code> 可以将当前的对话保存下来，以便日后通过 <code>/chat resume &lt;name&gt;</code> 继续。它还支持 <code>list</code> 和 <code>delete</code> 等操作来管理所有已保存的会话。</li><li><strong>/clear</strong>：当需要开始一个全新的话题时，此命令可以清空当前的对话历史和屏幕，提供一个干净的交互界面。</li></ul><h3>实际应用场景</h3><p>下面通过几个具体的例子，展示 Gemini CLI 在实际工作中的应用。</p><h4><strong>代码重构建议</strong></h4><p>假设有一个用于数据验证的函数，其逻辑虽然正确但不够简洁。</p><pre><code>// file: validation.js
function checkUserAccess(userObject) {
  if (userObject &amp;&amp; userObject.isActive &amp;&amp; userObject.permissions.level &gt; 1) {
    return true;
  }
  return false;
}</code></pre><p>可以向 Gemini CLI 提出请求：</p><p><code>@validation.js Please refactor the checkUserAccess function to be more concise.</code></p><p>Gemini 可能会返回一个更精炼的版本：</p><pre><code>// Suggested refactoring
const checkUserAccess = (userObject) =&gt;
  !!userObject &amp;&amp; userObject.isActive &amp;&amp; userObject.permissions.level &gt; 1;</code></pre><h4><strong>生成 Git 提交信息</strong></h4><p>编写规范的 Git commit message 是一项耗时的任务。可以借助 Gemini CLI 自动化这个过程。首先，查看暂存区的代码变更：</p><p><code>!git diff --staged</code></p><p>然后，基于这些变更请求生成提交信息：</p><p><code>From the diff above, write a Conventional Commit message.</code></p><p>这将产出一条格式良好、内容准确的提交信息，大大节省了思考和撰写的时间。</p><h4><strong>解释复杂的 Shell 命令</strong></h4><p>当遇到一段从网络上复制的、不甚明了的 shell 命令时，直接运行存在风险。可以让 Gemini 先行解释。</p><pre><code>&gt; Explain this command: awk -F',' '{print $1, $3}' data.csv</code></pre><p>Gemini 会提供一个清晰的逐段解释：</p><pre><code>✦ Certainly. This command uses `awk` to process a CSV file. Here is a breakdown:

  * `awk`: This is the command-line utility being invoked, designed for text processing.
  * `-F','`: The `-F` option sets the field separator. Here, it's set to a comma (`,`), which means `awk` will treat each line as a series of comma-separated fields.
  * `'{print $1, $3}'`: This is the action `awk` will perform on each line of the input. It instructs `awk` to print the first field (`$1`) followed by a space, and then the third field (`$3`).
  * `data.csv`: This is the input file for the command.

  In summary, the command reads the `data.csv` file, splits each line by commas, and prints the first and third columns from each line to the standard output.</code></pre><h3>结语</h3><p>将 Gemini CLI 集成到开发工作流中，让你的开发工作从从容容游刃有余。使用 ServBay 搭建一个可靠的运行环境开始，到熟练运用其核心命令解决编码、代码管理和系统操作中的实际问题，开发者可以获得更流畅、更专注的工作体验。掌握这些工具，你就不会匆匆忙忙连滚带爬。</p>]]></description></item><item>    <title><![CDATA[怎么利用数字化工具实现透明供应链管理？ ]]></title>    <link>https://segmentfault.com/a/1190000047390044</link>    <guid>https://segmentfault.com/a/1190000047390044</guid>    <pubDate>2025-11-11 18:09:13</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在当今全球化与数字化交织的时代背景下，供应链透明度不再是简单的概念，而已成为企业实现价值共创与风险防控的关键竞争力。所谓透明供应链，是指企业通过全面整合供应链信息流，实现从原材料采购到终端产品的全链条可视化和可追溯化，从而在复杂的商业环境中建立信任并优化决策流程。这一趋势背后，消费者对产品来源的担忧、投资者对ESG（环境、社会和治理）指标的重视，以及监管对合规要求的强化，共同推动了企业对透明供应链的探索。<br/>首先，透明供应链的核心在于全链条的可追溯性与信息披露能力。企业需要通过绘制完整的供应链图，明确涉及的各级供应商、制造商及物流节点，才能有效减少信息盲区。数据显示，近年来“可持续消费”意识的提升显著改变了市场格局。例如，2022年的消费者调查中，超过一半的受访者表示环境可持续发展对他们的购物决策具有更高的优先级。这意味着企业必须通过透明供应链向消费者展示其社会与环境责任感，从而赢得市场信任并提升品牌忠诚度。<br/>广域铭岛作为工业互联网技术的领导者，凭借其自主研发的GOS-知识库系统，为企业提供了构建透明供应链的数字化工具。这一系统通过多源数据融合与AI算法驱动，实现了供应链管理的智能协同。在汽车制造领域，领克成都工厂通过GOS-知识库的接入，将高级柔性排程系统（APS）与能源管理系统（EMS）相连接，显著提升了生产计划的效率与资源分配的优化能力。此外，系统还支持实时决策，帮助企业在复杂供应链中断问题中快速调整策略，最终助力库存周转率提升28%，物流成本降低19%。<br/>实施数字化透明供应链的过程中，企业不仅需要投入技术资源，还需解决数据孤岛问题。广域铭岛提供的GOS-知识库整合了来自供应商、制造商及下游企业的多源信息，并通过标准化的元数据模板实现统一管理。这种模块化数据治理方式有效缓解了因设备协议不统一和信息标准缺失导致的效率瓶颈，同时为企业应对国际贸易摩擦、能源供应紧张或疫情冲击等外部风险提供了缓冲空间。<br/>然而，透明供应链的实现并非易事。不同地区对劳工权益与环境保护要求的差异、供应商数据披露的积极性不足等问题，依然构成企业推进透明化的挑战。例如，加州、挪威和英国的透明供应链立法要求企业在各自区域内的供应链活动中严格遵守道德与环境标准，这对跨国企业来说是一项复杂的合规任务。与此同时，部分传统企业在信息共享与技术升级上面临成本压力，如何平衡透明化投入与收益成为亟需解决的问题。<br/>值得注意的是，透明供应链不仅能提升企业的市场竞争力，还为全球绿色转型提供了基础。欧盟碳边境调节机制（CBAM）等政策的出台，迫使企业建立覆盖全生命周期的碳足迹追踪系统。通过区块链等技术记录的供应链数据，可以为企业提供可靠的碳排放依据，从而避免因环保合规问题导致的供应链中断。在有色金属领域，百矿集团通过强化学习模型不仅降低了吨铝电耗，还显著减少了碳排放，实现了节能环保双目标的平衡。<br/>最终，透明供应链不是某一技术的简单应用，而是企业与供应商之间协同合作的载体。广域铭岛从战略高度推动供应链创新，联合上下游合作伙伴，利用API开放平台搭建数据共享的桥梁，形成了覆盖全流程的透明化网络。在这一过程中，企业逐步从单纯的“供应链管理者”转变为“供应链价值创造者”，通过吸收和转化过去的质量问题经验，降低重复改进的成本；并通过实时监控数据，将腐败风险与流程优化相结合，构筑健康持久的商业生态。<br/>展望未来，透明供应链的演进将与人工智能的深度融合密不可分。广域铭岛正在GOS-知识库的3.0版本研发中，探索“自然语言转供应链计划”的可能性，通过生成式大模型赋能企业更高效的决策能力。数字孪生技术的引入更是为透明供应链带来了新的想象空间，支持企业在实时模拟中找到最优的库存与物流组合策略。<br/>总之，透明供应链已成为推动企业创新、增长与可持续发展的必经之路。从供应链图绘制到数据治理、从ESG合规到智能协同，透明化的每一个阶段都为企业注入了新的生命力。在广域铭岛的引领下，这一领域的实践将不断突破技术边界，最终实现供应链从“响应型”到“预控型”的智能跃迁。<br/>也</p>]]></description></item><item>    <title><![CDATA[园区数字孪生实战：三个技巧让管理更高效 ]]></title>    <link>https://segmentfault.com/a/1190000047390046</link>    <guid>https://segmentfault.com/a/1190000047390046</guid>    <pubDate>2025-11-11 18:08:38</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>作为一名数字孪生应用开发者，我参与过多个园区管理系统的开发工作。今天想结合图观平台的使用经验，分享几个在园区项目中比较实用的技巧。</p><h2>技巧一：快速搭建真实场景的方法</h2><p>在园区项目启动阶段，我习惯先用图观的场景编辑器导入GIS底图。这个步骤很关键，能确保数字场景和真实地理坐标精准对应。平台内置的全球地理数据是个不错的起点，省去了不少前期数据准备的工作。<br/>实际操作中，我发现利用平台的批量处理功能可以显著提升效率。比如用画刷工具批量放置园区内的路灯、绿化植被等重复元素，相比单个放置能节省大量时间。对于特殊建筑，导入标准模型文件后，系统会自动处理材质和光照效果，不需要额外调整。</p><h2>技巧二：实现数据可视化的技巧</h2><p>园区运营涉及大量动态数据展示。在平台上，我通常先用零代码编辑器搭建基础的数据看板。通过简单的拖拽配置，就能实现场景对象与数据图表的联动效果。<br/>一个实用的做法是：先定义好关键参数，比如"建筑编号"、"设备类型"，然后设置联动规则。当在场景中点击某栋建筑时，相关的能耗数据、设备状态就会在侧边栏自动显示。这种设计让数据展示更直观，也方便管理人员快速理解。<br/><img width="640" height="360" referrerpolicy="no-referrer" src="/img/bVdmP6B" alt="" title=""/></p><h2>技巧三：优化性能的配置方案</h2><p>园区项目通常需要在不同设备上运行。平台支持端渲染和流渲染两种模式，这给了我们很大的灵活性。在配置时，我会根据实际使用场景来选择：<br/><strong>指挥中心大屏</strong>：使用流渲染模式，确保视觉效果<br/><strong>办公电脑</strong>：采用端渲染模式，保证操作流畅<br/>这种分场景的配置方式，既满足了不同用户的需求，也优化了系统资源的使用效率。<br/><img width="640" height="360" referrerpolicy="no-referrer" src="/img/bVdmP6A" alt="" title="" loading="lazy"/></p><h2>项目实践心得</h2><p>在最近的一个智慧园区项目中，我们基于图观流渲染平台开发了完整的运营管理系统。从场景构建到功能开发，整个过程比较顺畅。特别是在处理大规模园区场景时，平台的流渲染技术表现稳定，没有出现卡顿情况。<br/>实际使用中，管理人员反馈最实用的是场景状态切换功能。通过预设不同的环境状态（如白天/夜晚、正常/应急），可以快速切换整个园区的展示效果，这在日常巡检和应急演练中都很实用。<br/>数字孪生技术确实能为园区管理带来很多便利。选择合适的开发平台，掌握一些实用技巧，就能构建出既美观又实用的管理系统。</p>]]></description></item><item>    <title><![CDATA[从数据孤岛到智能运营：如何用数字孪生重塑]]></title>    <link>https://segmentfault.com/a/1190000047390053</link>    <guid>https://segmentfault.com/a/1190000047390053</guid>    <pubDate>2025-11-11 18:08:00</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>作为一家长期深耕大型信息系统集成的团队，我们深知数据中心运维的痛点：设备繁多、数据分散、故障定位困难。传统的监控系统往往只能提供二维图表和零散的告警信息，运维人员需要在多个系统间切换，效率低下且容易遗漏关键信息。<br/>去年，我们接手了一个大型数据中心的智能化改造项目。这个数据中心拥有超过5000台服务器、200多个机柜，每天产生海量的运行数据。客户希望我们能够构建一个统一的智能运营中心，实现对数据中心的全面监控和智能运维。</p><h2>挑战：数据孤岛与运维效率瓶颈</h2><p>在项目初期，我们面临着三大挑战：<br/><strong>1.数据整合难题</strong>：温度、湿度、电力、网络流量等数据分散在20多个不同的监控系统中<br/><strong>2.故障定位困难</strong>：当出现性能问题时，需要多个团队协同排查，平均故障定位时间超过2小时<br/><strong>3.预防性维护不足</strong>：缺乏对设备运行趋势的预测分析，往往是在故障发生后才进行抢修</p><h2>解决方案：数字孪生智能运营中心的实践</h2><p>我们选择了"孪易数字孪生IOC标准版"作为核心平台，主要基于以下几个考量：<br/><strong>1.一体化可视监控</strong><br/>通过数字孪生技术，我们在虚拟空间中1:1还原了整个数据中心的物理结构。运维人员可以在三维场景中直观查看每个机柜、每台服务器的实时状态。<br/>"最让我惊喜的是环境仿真功能，"项目负责人王工回忆道，"我们能够模拟空调气流组织，优化冷通道布局，仅此一项就帮助客户降低了15%的制冷能耗。"<br/><strong>2.多源数据融合</strong><br/>平台支持对接客户的现有监控系统，包括：<br/>动环监控系统的温湿度数据<br/>电力监控系统的用电数据<br/>网络监控系统的流量数据<br/>服务器监控系统的性能数据<br/><strong>3.智能告警与根因分析</strong><br/>我们配置了多层级的告警规则。当某个机柜温度异常时，系统不仅会告警，还会自动关联分析该区域的空调运行状态、服务器负载情况，快速定位问题根源。<br/>"以前排查一个温度告警需要30分钟，现在系统5分钟内就能给出根因分析建议，"运维团队的李经理表示，"我们的平均故障解决时间缩短了60%。"<br/><strong>4.历史回放与预测分析</strong><br/>平台的历史回放功能让我们能够复盘重大故障的全过程。"上周的核心交换机故障，我们通过历史回放功能，准确还原了故障发生前30分钟的各项指标变化，为优化预警阈值提供了重要依据。"<br/><img width="640" height="356" referrerpolicy="no-referrer" src="/img/bVdmQp3" alt="" title=""/></p><h2>成果：从被动响应到主动预防</h2><p>项目实施6个月后，我们看到了显著的改善：<br/><strong>运维效率提升</strong>：平均故障定位时间从2小时缩短到30分钟<br/><strong>能耗优化</strong>：通过热力仿真优化空调策略，PUE值从1.6降低到1.45<br/><strong>预防性维护</strong>：基于趋势预测，成功预警了3次潜在的设备故障<br/><strong>决策支持</strong>：管理层可以通过多维度的数据分析，做出更科学的扩容规划<br/><img width="640" height="360" referrerpolicy="no-referrer" src="/img/bVdmQDO" alt="" title="" loading="lazy"/></p><h2>经验分享：数字化转型的关键要素</h2><p>通过这个项目，我们总结了几个重要经验：<br/><strong>1.技术选型要务实</strong>：数字孪生不是炫技，而是要解决实际问题<br/><strong>2.数据是基础</strong>：确保数据质量和实时性是项目成功的前提<br/><strong>3.渐进式推进</strong>：从核心场景开始，逐步扩展应用范围<br/><strong>4.团队赋能</strong>：注重培养客户的自主运营能力</p><h2>展望未来</h2><p>这个项目的成功实施，不仅解决了客户当前的运维痛点，更为其数字化转型奠定了坚实基础。现在，客户正在基于我们的平台，探索AI算法的深度应用，向真正的智能化运维迈进。<br/>数字孪生技术正在改变传统的数据中心运维模式。如果您也在思考如何提升数据中心的运营效率，欢迎了解我们的完整解决方案。</p>]]></description></item><item>    <title><![CDATA[工业大模型怎么帮助企业实现生产效率优化？]]></title>    <link>https://segmentfault.com/a/1190000047390055</link>    <guid>https://segmentfault.com/a/1190000047390055</guid>    <pubDate>2025-11-11 18:07:01</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在全球产业链加速重组、个性化定制需求如火如荼的背景下，工业企业正面临前所未有的挑战。数据显示价值挖掘不足，知识体系难以沉淀；决策停滞，错失商机。这一切问题，引发了制造业的深刻变革：传统智慧已无法适应未来的竞争，我们需要一场以“智能”为核心的新工业革命。<br/>而这一定义下的工业大模型，它是站在时代浪尖的技术，挑战着既有的制造逻辑。西门子、达索、施耐德等全球巨头早已融入这个趋势，站在了AI新生的前沿。但与此同时，中国本土企业也开始从产业链的后视镜中抢滩夺位，广域铭岛便是其中一个明显增量玩家。<br/>以Geega OS工业AI应用平台为核心支撑，以Geega Ask（际·问）+工业APP作为核心组件，广域铭岛打造了一套面向制造、运营、管理全流程的人工智能解决方案，而这套方案正回归AI最基础也是最关键的使命——让AI真正地嵌入工业实践，而非仅在实验室中呈现学术演算之美。这种趋向平台化的工业知识沉淀，正是工业大模型能够催生其自身生命力的关键。<br/>如今，制造业的智能化改造浪潮席卷全球，IDC数据显示，到2024年，工业大模型将撬动全球超400亿美元的AI应用市场，增长率高达27.3%。然而，真正能被AI消化、解读、引导的数据，依然少之又少。从注塑机每一次运行中涌出的海量数据中，广域铭岛给出了解答：我们必须理解这些数据，不仅仅是采集，更要在行业Know-How和AI算法两者的交集找到价值切入点。<br/>同时，随着“智能传感器+数据流AI分析”的切题到来，工业大模型正从抽象概念走向一线生产。广域铭岛从中汲取营养，为使用自家平台的制造企业提供覆盖整个智能化闭环的支撑，这使得工业大模型不再是纸上谈兵的技术渴望，而是生产车间的一个实际助手。<br/>其工业解决方案具备行业穿透能力，并打通端到端业务链条，将制造厂从生产计划到设备管理的需求一体化编织。典型产品“Geega Ask”平台，将NLP自然语言处理与任务执行无缝打通，形成“问数据、问知识、生成策略、执行”的完整智能化闭环，尤其适用于制造业的那些繁杂但关键的工业场景。<br/>此套系统极具通用性，通过Geega平台，广域铭岛开发了多款工艺质量App，应用其在国内多个流程型制造中的代表性案例，实现了从“问题驱动查找”到“AI机理洞察”的转化。例如，在某大型电解铝厂，日常任务中电效分析耗时长、误差大的问题得到解决。借助工业大模型带来的指标自主订阅与AI分析联动，这种冶炼场景已拥有完整的运行监控、判定与溯源能力，被赋予了显著的认知含量。<br/>离散制造同样不可小觑，白车身尺寸偏差溯源需要跨多个工厂、多个系统的数据隔离处理，这是传统手动操作难以胜任的领域。广域铭岛的Geega尺寸智能管理App，整合多种工业测量技术与建模基础，使其构建的模型能实时处理数据并将源头查清，运营效率得到了前所未有的提升。<br/>在这个运行过程中，广域铭岛展现了其对工业大模型深刻理解：它们不是学习大词汇量机器翻译的泛工业模型，而是解决制造业特有真实矛盾的垂直模型。此App在多个汽车制造厂开展测试后，成功将问题排查时间从平均3天降低到5分钟，应急处理提升对生产连续性的保障。这也意味着员工与这套工业大模型穿上了同一层面的智能鞋码，实现了站内同学不行的高效率匹配。<br/>跨工序执行场景上，焊接工艺质量管理App更是搭配了实时数据采集和动态优化功能。通过同步果多的示波数据与设备运行参数，它能在现场设备黄色右焊点上，进行异常校验并应用AI提出初步调节说明，将一次性合格率提升至跑得最快的境地。<br/>此外，Geega OS与工业大模型的结合，不仅仅是系统间的串联，而是形成了一种层次智能协同的范式——通过算法内嵌的核心机制对接行业特性，从而产生从数据看板到知识决策的提升，为制造业企业提供PDCA循环闭环的新标准。<br/>然而，赶上这场工业大模型落地潮，并非每一位企业条件相同，成功之中不免掺杂门槛。截至2025年，广域铭岛已在全球超40个城市建立了分支服务站，覆盖全球多个制造重镇。这种区域协同创新实际上，也在为他们自己的工业大模型持续灌输新的地域视角与工艺知识，从而不断进化模型说法与应用场景。<br/>因此，无论是从工业大模型自身技术架构来看，还是从其运行与演进方式评估，触及的知识、构成的知识、操作的知识，都在推动中国制造业从“经验”迈向“智能化”。对于一线工程师来说，他们终于不再是默默喂养AI数据的人，而是这一切技术充分揉合后，竟能脱胎换骨、重回熟悉的他们自己。<br/>综上所述，广域铭岛团队正以“场景定义智能”的思路，在工业大模型这片新大陆上探索出一条融合落地与创新的路径。他们不再只是搭建平台，更是将这份技术转化为你每天走进车间也能感受到的智能脉搏。工业大模型的赋能之道，就在这里，就在Geega OS的运行节奏里，等待被每个人“听到”。</p>]]></description></item><item>    <title><![CDATA[7 款最佳 iQOO EasyShare]]></title>    <link>https://segmentfault.com/a/1190000047390058</link>    <guid>https://segmentfault.com/a/1190000047390058</guid>    <pubDate>2025-11-11 18:06:21</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>iQOO EasyShare 是一款专为 iQOO 智能手机开发的内置数据传输应用，用户可以使用它在手机之间快速共享文件、应用、照片、视频，甚至整个设备的数据。它快速便捷，而且不消耗移动数据流量。然而，EasyShare 目前仅适用于 iQOO 和 vivo 设备，因此对于更换品牌的用户来说，它的使用体验会受到限制。</p><p>如果您正在寻找一款适用于所有Android和iOS设备的iQOO EasyShare替代方案，那么您来对地方了。下面我们列出了7款可靠的应用程序，无论您使用哪款手机，它们都能帮助您轻松传输数据。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047390060" alt="图片" title="图片"/><br/>​<br/>方案一： Coolmuster Mobile Transfer</p><p>作为iQOO EasyShare最专业的替代方案之一， Coolmuster Mobile Transfer专为希望一次性迁移所有手机数据的用户而设计。它支持Android和iOS之间的跨平台传输，确保迁移过程中不会丢失任何数据。</p><p>与仅限移动设备使用的传输应用不同，它依赖PC/ Mac作为连接设备的媒介，确保稳定全面的数据迁移。作为一款专业的桌面工具，它凭借强大的兼容性和直观的操作，在跨平台数据传输领域赢得了广泛认可。</p><p>主要特点：</p><pre><code>一键即可在两台设备之间传输联系人、短信、照片、视频、音乐、应用程序和通话记录。
支持众多品牌，包括 iQOO、vivo、三星、华为、小米和苹果。
两种稳定的连接方式：USB 和 Wi-Fi。
保持原始画质，数据零损失。
完全兼容Android 6.0 及更高版本，以及iOS 5 及更高版本。

</code></pre><p>缺点：</p><pre><code>需要电脑才能操作。
免费试用版提供的功能有限。

</code></pre><p>最适合：</p><pre><code>需要适用于Android和iOS的全功能、无损手机间数据传输解决方案的用户。

</code></pre><p>用户指南：</p><p>01点击下面的按钮，下载、安装并启动计算机上的软件。</p><p>02使用 USB 数据线将设备连接到电脑。</p><pre><code>对于Android设备：如果之前没有启用 USB 调试，请按照屏幕上的说明将其打开。
对于iOS设备：出现提示时，点击手机上的“信任此电脑”。

</code></pre><p>03连接成功后，您将看到主界面（这里我们以Android到Android数据传输为例）。</p><p>现在，请检查源设备和目标设备的位置是否正确。如果位置反了，请点击“翻转”按钮进行交换。\</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047390061" alt="图片" title="图片" loading="lazy"/></p><p>04确认位置后，即可开始传输数据。只需勾选要移动的数据类型，然后点击“开始复制”即可开始。</p><p>方案二：SHAREit</p><p>SHAREit是一款知名的老牌文件共享应用，曾凭借“零流量，闪电般快速共享”的口号风靡全球。鼎盛时期，其全球用户超过 20 亿。SHAREit 支持Windows 、 Mac 、 Android和iOS设备之间的跨平台文件共享，一度是追求快速无线文件传输用户的首选。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047390062" alt="图片" title="图片" loading="lazy"/><br/>​</p><p>主要特点：</p><pre><code>无需使用互联网或移动数据，即可实现超高速传输。
支持多种文件格式，包括视频、音乐、应用程序和文档。
跨平台兼容Android 、 iOS 、 Windows和macOS。
内置文件管理器和媒体播放器，使用方便。

</code></pre><p>缺点：</p><pre><code>显示与文件传输无关的广告和额外内容。
部分用户反映存在隐私和数据收集问题。

</code></pre><p>最适合：</p><pre><code>用户正在寻找一款跨平台工具，以便快速无线地共享多种类型的文件。

</code></pre><p>方案三：Xender</p><p>Xender是 iQOO EasyShare 的一个备受好评的替代品，其核心卖点在于高速无线传输。凭借其简洁高效的用户体验，Xender 已成为众多用户在手机和电脑之间传输数据的首选。Xender 无需网络连接或 USB 数据线，利用 Wi-Fi Direct 技术实现设备间的直接连接，提供灵活的跨设备兼容性，可满足从日常文件共享到专业数据传输的各种需求。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047390063" alt="图片" title="图片" loading="lazy"/><br/>​</p><p>主要特点：</p><pre><code>通过 Wi-Fi Direct 传输文件速度最高可达 40 Mbps。
支持Android 、 iOS 、 Windows和Mac连接。
无需网络连接或USB数据线。
群组共享和简单的拖放界面。

</code></pre><p>缺点：</p><pre><code>偶尔出现连接不稳定的情况。
免费版本包含广告。

</code></pre><p>最适合：</p><pre><code>喜欢简单、快速、跨设备文件共享体验的用户。

</code></pre><p>方案四：发送至任何地点</p><p>Send Anywhere是一款注重隐私保护的 iQOO EasyShare 替代方案。它利用加密传输技术和灵活的跨平台功能，赢得了注重数据安全的用户的青睐。Send Anywhere 无需复杂的账户登录，即可通过临时密钥或共享链接进行文件传输，从而在源头上确保了便捷性和安全性，是手机和电脑之间安全传输文件的可靠选择。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047390064" alt="图片" title="图片" loading="lazy"/><br/>​</p><p>主要特点：</p><pre><code>使用临时 6 位密钥进行加密文件传输。
支持Android 、 iOS 、 Windows 、macOS和网页浏览器等跨平台应用。
无需登录或创建账户。
界面简洁易用，连接建立速度快。

</code></pre><p>缺点：</p><pre><code>免费版的文件大小有限制（每次会话的文件传输量限制为 10GB）。
某些传输方式需要连接互联网。

</code></pre><p>最适合：</p><pre><code>用户寻求在手机和电脑之间进行安全加密的文件传输。

</code></pre><p>方案五：CLONEit</p><p>CLONEit是一款轻巧实用的 iQOO EasyShare 替代方案，专为需要快速离线迁移Android设备间数据的用户而设计。与基于云端或依赖网络的工具不同，CLONEit 无需使用移动数据即可实现手机间的快速数据传输，因此非常适合在设备切换过程中注重隐私和便捷性的用户。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047390065" alt="图片" title="图片" loading="lazy"/></p><p>主要特点：</p><pre><code>最多可传输 12 种数据类型，包括消息、联系人和系统设置。
利用Wi-Fi热点技术，可离线工作。
无需电缆或移动数据。
一键克隆流程，界面简洁明了。

</code></pre><p>缺点：</p><pre><code>仅限Android设备；不支持iOS设备。
界面感觉过时了。

</code></pre><p>最适合：</p><pre><code>适用于想要快速、离线、简单的数据克隆应用程序的Android用户。

</code></pre><p>方案六：InShare</p><p>InShare是一款极具潜力的文件传输应用，也是 iQOO EasyShare 的一个新兴替代品。虽然与 SHAREit 或 Xender 等行业巨头相比，它的品牌知名度较低，但凭借其优化的传输算法，在特定传输场景下表现出色，使其成为文件共享领域的一匹“低调的黑马”。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047390066" alt="图片" title="图片" loading="lazy"/><br/>​</p><p>主要特点：</p><pre><code>高速传输，最高可达 40 Mbps。
完全离线使用，无需网络连接。
支持所有主流文件类型，包括照片、视频、音乐和应用程序。
极简且无广告的界面。

</code></pre><p>缺点：</p><pre><code>仅限Android系统，没有iOS或PC版本。
老款机型偶尔会出现故障。

</code></pre><p>最适合：</p><pre><code>Android用户需要一款简单、无广告、快速的本地传输工具。

</code></pre><p>方案七：扎皮亚</p><p>Zapya （中文名为“酷亚”）以其闪电般的传输速度在文件传输领域脱颖而出，成为注重效率用户的首选之一。作为iQOO EasyShare的强大替代品，它采用先进的Wi-Fi Direct和LAN共享技术，无需网络连接或数据线即可在设备间实现高速文件传输。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047390067" alt="图片" title="图片" loading="lazy"/><br/>​</p><p>主要特点：</p><pre><code>支持Android 、 iOS 、 Windows和macOS等跨平台系统。
通过二维码快速配对设备。
支持多台设备同时进行群组文件共享。
手机数据备份和恢复选项。

</code></pre><p>缺点：</p><pre><code>该界面包含广告和其他可能分散注意力的功能。
与其他传输工具相比，该应用体积较大。

</code></pre><p>最适合：</p><pre><code>经常同时与多人或多个设备共享文件的用户。

</code></pre><h3>结尾</h3><p>虽然 iQOO EasyShare 是一款高效的 iQOO 文件传输应用，但它缺乏跨品牌兼容性。上述替代方案提供了更灵活、更高级的功能，以满足不同的需求：</p><pre><code>Coolmuster Mobile Transfer - 最适合手机之间的完整数据迁移。
SHAREit/Xender/InShare/Zapya - 最适合快速离线文件共享。
Send Anywhere - 最适合保护隐私和跨平台使用。
CLONEit - 最适合想要克隆手机的Android用户。

</code></pre><p>如果您想要一款专业、可靠且功能齐全的 EasyShare 替代方案， Coolmuster Mobile Transfer是您的最佳选择。它只需一键即可确保您的数据（包括照片和短信）安全完整地传输。<br/>​</p>]]></description></item><item>    <title><![CDATA[PAI Physical AI Note]]></title>    <link>https://segmentfault.com/a/1190000047390076</link>    <guid>https://segmentfault.com/a/1190000047390076</guid>    <pubDate>2025-11-11 18:05:35</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在上期Notebook详解系列中，我们介绍了《基于Isaac仿真的操作动作数据扩增与模仿学习》，本期我们将介绍一套类似的方案，同样可以完成人工演示、数据扩增、模仿学习、模型测评这几个环节，但完全使用Cosmos世界模型作为内核。<br/><img width="723" height="224" referrerpolicy="no-referrer" src="/img/bVdm0oM" alt="image.png" title="image.png"/><br/>相比基于Isaac仿真的方案，使用Cosmos世界模型的方案具有以下特点：</p><ul><li>人工演示、数据扩增环节无需仿真算力（RT Core），全流程使用AI算力（CUDA Core/Tensor Core）</li><li>无需对人工演示数据进行动作打标处理，直接使用视频数据即可实现扩增</li><li>无需单独的数据增强环节，可在数据扩增环节通过调整提示词实现数据增强</li><li>需要额外的拒绝采样步骤以过滤不合理的生成内容，以及额外的IDM逆解算步骤以补齐视频中缺少的action序列</li></ul><p>在PAI的Notebook Gallery中，我们已经预置了一个最佳实践，就是这个过程的一个具体示例：<br/><a href="https://link.segmentfault.com/?enc=01xV7tMi4M9YwwE%2FJim3ew%3D%3D.Q1DPJLu%2BAoOU1jsuSpulccHdyyuDrGTPBE8pJIqSvlQaB5mh6hoJmKU5pPEsf2vFCTIaI1%2BwJ7wDQU9UkrvX2rbMDD%2B9WoH8iliwj8fZyvg%3D" rel="nofollow" target="_blank">https://gallery.pai-ml.com/#/preview/deepLearning/cv/isaac\_gr00t\_wf2</a><br/><img width="723" height="429" referrerpolicy="no-referrer" src="/img/bVdm0o2" alt="image.png" title="image.png" loading="lazy"/></p><p>下面我们来详细解读这个示例。</p><h2>人工少量演示</h2><p>与基于仿真的数据扩增相同，人工演示可以在真实空间或仿真空间中进行，但无需进行动作打标，仅需录制视频即可,<br/><a href="https://link.segmentfault.com/?enc=E1YWNaYtyeToLwVtaSt3ew%3D%3D.5EGw3%2FK7dZaxM9o2650ChORhmgumefItnP1UL7IKi2%2F16PplsjRGop7Nlw%2BFeZ%2FS%2Fe0N5mWP59PJWtvgB%2Bv9b8q1OJwYfzDnaonTkXruQsRIQQVSUqCSltzmlq%2Fn0gaw" rel="nofollow" target="_blank">查看演示 &gt;&gt;</a></p><p>在视频中，左上角的操控者远程控制机器人本体，对蔬菜进行了“Pick and Place”的动作。同时，由操控者对视频内容进行文字描述，例如：</p><blockquote>Use the right hand to pick up green bok choy from tan table right side to bottom level of wire basket.</blockquote><p>采集类似的视频数据，直至满足Cosmos-Predict模型微调的要求（本样例中为100条）。<br/><img width="723" height="476" referrerpolicy="no-referrer" src="/img/bVdm0pc" alt="image.png" title="image.png" loading="lazy"/></p><h2>数据扩增</h2><p>利用Cosmos世界模型进行数据扩增，首先要使用人工演示数据对Cosmos-Predict模型进行微调。本例中使用Cosmos-Predict2-2B-Video2World模型，在4*GU8T机型中进行微调：</p><pre><code class="python">!torchrun --nproc_per_node=4 --master_port=12341 -m scripts.train --config=cosmos_predict2/configs/base/config.py -- experiment=predict2_video2world_training_2b_groot_gr1_480</code></pre><p><img width="723" height="440" referrerpolicy="no-referrer" src="/img/bVdm0pd" alt="image.png" title="image.png" loading="lazy"/></p><p>对于更大的世界模型，例如Cosmos-Predict2-14B-Video2World，可以在DLC中，使用4节点 × 8*GU8T的机型中进行微调：</p><pre><code class="python">
import os
import json
import time

from alibabacloud_tea_openapi.models import Config
from alibabacloud_credentials.client import Client as CredClient
from alibabacloud_credentials.models import Config as CredConfig
from alibabacloud_pai_dlc20201203.client import Client as DLCClient
from alibabacloud_pai_dlc20201203.models import (
    CreateJobRequest,
    GetJobRequest,
)

def wait_for_job_to_terminate(client, job_id):
    while True:
        job = client.get_job(job_id, GetJobRequest()).body
        print('job({}) is {}'.format(job_id, job.status))
        if job.status in ('Succeeded', 'Failed', 'Stopped'):
            return job.status
        time.sleep(5)
    return None


def main():
    current_time_tuple = time.localtime()
    year = current_time_tuple.tm_year
    month = current_time_tuple.tm_mon
    day = current_time_tuple.tm_mday
    hour = current_time_tuple.tm_hour
    minute = current_time_tuple.tm_min
    # 请确认您的主账号已授权DLC，且拥有足够的权限。
    display_name = f"train_cosmos-predict2_14b_{day}_{hour}-{minute}"  #设置任务名称 
    region_id = os.environ.get("dsw_region") #设置regionid
    workspace_id = os.environ.get('PAI_WORKSPACE_ID') #设置成用户自己的工作空间id
    image_uri = f"dsw-registry.{region_id}.cr.aliyuncs.com/pai-training-algorithm/isaac-sim:gr00t-dreams-v9" #使用官方镜像
    ecs_spec = "ecs.gn8v-8x.16xlarge"
    num_gpus = 8 # 与资源规格保持一致
    num_nodes = 4
    #########训练任务相关配置#############
    config = "cosmos_predict2/configs/base/config.py"
    exp = "predict2_video2world_training_14b_groot_gr1_480"
    #########训练任务相关配置#############

    # 本示例通过Credentials SDK默认从环境变量中读取AccessKey，来实现身份验证。
    credentialsConfig = CredConfig(
        type='credentials_uri'   # 选填。若您未配置其他“默认凭据链”访问方式，您无需再显式指定，Credentials SDK会通过uri方式获取临时凭证
    )
    cred = CredClient(credentialsConfig)

    # 1. create client;
    dlc_client = DLCClient(
         config=Config(
            credential=cred,
            region_id=region_id,
            endpoint='pai-dlc.{}.aliyuncs.com'.format(region_id),
         )
    )
        
    print('-------- Create Job ----------')
    # 创建DLC作业。
    create_job_resp = dlc_client.create_job(CreateJobRequest().from_map({
        'WorkspaceId': workspace_id,
        'DisplayName': display_name,
        'JobType': 'PyTorchJob',
        # 'ResourceId': resource_quota_id,
        'JobSpecs': [
            {
                "Type": "Worker",
                "Image": image_uri,
                "PodCount": num_nodes,
                "EcsSpec": ecs_spec,
            },
        ],
        'DataSources': [
            {
                "DataSourceId": dataset_id,
            },
        ],
       'UserVpc': {
            "VpcId": vpc_id,  # 替换为实际 VPC ID
            "SwitchId": switch_id,  # 替换为实际交换机 ID
            "SecurityGroupId": security_groupid  # 替换为实际安全组 ID
        },
        "UserCommand": f" export NVTE_FUSED_ATTN=0 &amp;&amp; \
            rm -rf /workspace/cosmos-predict2/checkpoints &amp;&amp; \
            rm -rf /workspace/cosmos-predict2/datasets/benchmark_train/gr1 &amp;&amp; \
            ln -s /mnt/data/notebook2/checkpoints /workspace/cosmos-predict2/checkpoints &amp;&amp; \
            ln -s /mnt/data/notebook2/gr1 /workspace/cosmos-predict2/datasets/benchmark_train/gr1 &amp;&amp; \
            cd /workspace/cosmos-predict2 &amp;&amp; \
            torchrun --nproc_per_node={num_gpus} --nnodes={num_nodes} --rdzv_id 123 --rdzv_backend c10d --rdzv_endpoint $MASTER_ADDR:1234 -m \
            scripts.train --config={config} \
            -- experiment={exp} \
            model.config.fsdp_shard_size=0"
    }))
    job_id = create_job_resp.body.job_id

    wait_for_job_to_terminate(dlc_client, job_id)

    pass


if __name__ == '__main__':
    main()
</code></pre><p>完成微调后，即可使用微调后的模型进行推理：</p><pre><code class="python">!torchrun --nproc_per_node=4 --master_port=12341 -m examples.video2world_gr00t \
--num_gpus 4   --model_size 14B   --gr00t_variant gr1   \
--batch_input_json dream_gen_benchmark/gr1_object/batch_input.json   --disable_guardrail</code></pre><p>在上述代码中，使用batch\_input.json来记录推理所需的prompts与起始帧：<br/><img width="723" height="403" referrerpolicy="no-referrer" src="/img/bVdm0pi" alt="image.png" title="image.png" loading="lazy"/></p><p>执行上述推理过程：<br/><img width="723" height="203" referrerpolicy="no-referrer" src="/img/bVdm0pl" alt="image.png" title="image.png" loading="lazy"/></p><p>按照batch\_input.json，脚本会输出一系列推理结果，实现数据扩增。扩增的数量取决于batch\_input.json的prompt数量。以下是输出结果示例：<br/><a href="https://link.segmentfault.com/?enc=qoYzyTUqnWp1KndzMK1bSA%3D%3D.1tCW1DIa6wNTTAu9YL7wtQwHAMrWNFlz92xeadTXD3ybrU82sAXRcQjU07hkkqIZvkHpgcd4Tir0HXUVyEh7C6JMGCUokyCpoJU%2BRJYB8HyBmOTnqerzAcbA4KZlFOgp" rel="nofollow" target="_blank">查看演示 &gt;&gt;</a></p><p>从上述结果中可以看出，右上角的水壶出现了明显的变形，不符合真实物理规律。在实际生产中，我们需要剔除这类视频，因此需要使用Cosmos-Reason1模型进行拒绝采样。</p><h2>拒绝采样</h2><p>拒绝采样的原理是：生成多个候选视频，然后使用Cosmos-Reason1对这些视频进行评分，选择评分最高的视频作为最终输出。评分将从以下几个方面进行考量：</p><ul><li>运动连贯性: 物体移动是否自然流畅</li><li>时间一致性: 帧与帧之间是否存在突兀变化</li><li>物理合理性: 重力、光影、材质是否符合物理规律</li><li>视觉质量: 是否存在伪影、模糊、扭曲等问题</li><li>内容逻辑: 场景元素之间的关系是否合理</li></ul><p>可以使用以下脚本进行拒绝采样：</p><pre><code class="python">!torchrun --nproc_per_node=4 --master_port=12341   -m examples.video2world_bestofn   \
--model_size 14B   --gr00t_variant gr1   \
--prompt "Use the right hand to pick up rubik's cube from from the bottom of the three-tiered wooden shelf to to the top of the three-tiered wooden shelf."   \
--input_path assets/sample_gr00t_dreams_gr1/8_Use_the_right_hand_to_pick_up_rubik\'s_cube_from_from_the_bottom_of_the_three-tiered_wooden_shelf_to_to_the_top_of_the_three-tiered_wooden_shelf..png   \
--num_gpus 2   --num_generations 4   --prompt_prefix ""   \
--disable_guardrail   --save_path output/best-of-n-gr00t-gr1</code></pre><p>该脚本会使用相同的prompt生成4条视频，然后通过Cosmos-Reason1进行打分，以下分别是0分和100分的视频，以示对比：</p><table><thead><tr><th>0分</th><th>100分</th></tr></thead><tbody><tr><td><a href="https://link.segmentfault.com/?enc=7sJPDIT5%2BEXa9aGyPAaaDQ%3D%3D.7VjvmRifHaxpeKMAaLTco%2BT%2BTmJzoSTwyxzK5Ay%2FtO5XBMoWfRdMJcndnOtCIgNHbPTb2R3mRcqQwug3CcfmQw7%2BmNKIIqtGmVX2%2B8opXdE7LxTi09McgJVgtfM%2FylXf" rel="nofollow" target="_blank">0分演示 &gt;&gt;</a></td><td><a href="https://link.segmentfault.com/?enc=gJe5nN34bm2tWAUJL%2F3eGw%3D%3D.dnv42luMoVhHCc8tQlktOgKc0suTa%2Fa8NNTJfqJFGdxgyhLcGh55C7Sa9dEC6SHEvT%2FWyXSzI3wfE8%2FEgXkPNQsdua6bb5qaNPILJ0tkI0%2Fs1GJr4OC0nQBQHT9Tuve3" rel="nofollow" target="_blank">100分演示 &gt;&gt;</a></td></tr><tr><td><img width="723" height="548" referrerpolicy="no-referrer" src="/img/bVdm0py" alt="image.png" title="image.png" loading="lazy"/></td><td><img width="723" height="534" referrerpolicy="no-referrer" src="/img/bVdm0pC" alt="image.png" title="image.png" loading="lazy"/></td></tr></tbody></table><h2>IDM逆解算</h2><p>上述数据扩增和拒绝采样的结果，为一系列的“prompt-视频”数据对。一般来说，如果用于VLA模型的模仿学习，仅有这样的数据对是不够的，还需给出视频内容中的action序列。但由于Cosmos-Predict2模型直接输出了视频，没有action序列，我们需要通过IDM（Inverse Dynamics Model，逆向动力学模型）对视频进行处理，逆向解析出其中的action序列。</p><p>可以使用以下脚本进行IDM逆解算：</p><pre><code class="python">!PYTHONPATH=. CUDA_VISIBLE_DEVICES=0,1,2,3 python IDM_dump/dump_idm_actions.py \
    --checkpoint "seonghyeonye/IDM_gr1" \
    --dataset "IDM_dump/data/gr1_unified.data" \
    --output_dir "IDM_dump/data/gr1_unified.data_idm" \
    --num_gpus 4 \
    --video_indices "0 8"</code></pre><p>由于需要使用huggingface获取IDM模型，在国内的网络环境中，执行上述命令可能出现网络问题，可以使用以下环境变量进行代理加速：</p><pre><code class="python">HF_ENDPOINT=https://hf-mirror.com </code></pre><p>逆解算结果以parquet格式保存，可以通过以下命令查看：</p><pre><code class="python">!uv pip install parquet-tools
!parquet-tools csv IDM_dump/data/gr1_unified.data_idm/data/chunk-000/episode_000000.parquet</code></pre><p><img width="723" height="476" referrerpolicy="no-referrer" src="/img/bVdm0rQ" alt="image.png" title="image.png" loading="lazy"/></p><p>如果需要使用自定义机器人本体构型，也可以自定义微调IDM模型：</p><pre><code class="python">cd /workspace/GR00T-Dreams/
export HF_HOME=/mnt/data/notebook2
PYTHONPATH=. WANDB_MODE=disabled CUDA_VISIBLE_DEVICES=0 torchrun scripts/idm_training.py \
    --dataset-path demo_data/robot_sim.PickNPlace/ \
    --embodiment_tag gr1</code></pre><h2>模仿学习</h2><p>使用上述过程得到的扩增数据，可以用与GR00T-N1模型的模仿学习：</p><pre><code class="python">!cd /workspace/GR00T-Dreams/
!export HF_HOME=/mnt/data/notebook2 &amp;&amp; export WANDB_MODE=offline &amp;&amp; \
bash IDM_dump/scripts/finetune/gr1.sh</code></pre><p>详细训练脚本gr1.sh如下：</p><pre><code class="python">import os
import subprocess
import sys
from dataclasses import dataclass
from pathlib import Path

import torch
import tyro
from transformers import TrainingArguments

from gr00t.data.dataset import LeRobotSingleDataset
from gr00t.data.schema import EmbodimentTag
from gr00t.experiment.data_config import DATA_CONFIG_MAP
from gr00t.experiment.runner import TrainRunner
from gr00t.model.gr00t_n1 import GR00T_N1
from gr00t.utils.peft import get_lora_model


@dataclass
class Config:
    """Configuration for GR00T model fine-tuning."""

    # Dataset parameters
    dataset_path: str
    """Path to the dataset directory."""

    output_dir: str = "/tmp/gr00t"
    """Directory to save model checkpoints."""

    data_config: str = "gr1_arms_only"
    """Data configuration name from DATA_CONFIG_MAP."""

    # Training parameters
    batch_size: int = 16
    """Batch size per GPU for training."""

    max_steps: int = 10000
    """Maximum number of training steps."""

    num_gpus: int = 1
    """Number of GPUs to use for training."""

    save_steps: int = 500
    """Number of steps between saving checkpoints."""

    # Model parameters
    base_model_path: str = "nvidia/GR00T-N1-2B"
    """Path or HuggingFace model ID for the base model."""

    tune_llm: bool = False
    """Whether to fine-tune the language model backbone."""

    tune_visual: bool = True
    """Whether to fine-tune the vision tower."""

    tune_projector: bool = True
    """Whether to fine-tune the projector."""

    tune_diffusion_model: bool = True
    """Whether to fine-tune the diffusion model."""

    resume: bool = False
    """Whether to resume from a checkpoint."""

    # Advanced training parameters
    learning_rate: float = 1e-4
    """Learning rate for training."""

    weight_decay: float = 1e-5
    """Weight decay for AdamW optimizer."""

    warmup_ratio: float = 0.05
    """Ratio of total training steps used for warmup."""

    lora_rank: int = 0
    """Rank for the LORA model."""

    lora_alpha: int = 16
    """Alpha value for the LORA model."""

    lora_dropout: float = 0.1
    """Dropout rate for the LORA model."""

    dataloader_num_workers: int = 8
    """Number of workers for data loading."""

    report_to: str = "wandb"
    """Where to report training metrics (e.g., 'wandb', 'tensorboard')."""

    # Data loading parameters
    embodiment_tag: str = "new_embodiment"
    """Embodiment tag to use for training. e.g. 'new_embodiment', 'gr1'"""

    video_backend: str = "decord"
    """Video backend to use for training. [decord, torchvision_av]"""


#####################################################################################
# main training function
#####################################################################################


def main(config: Config):
    """Main training function."""
    # ------------ step 1: load dataset ------------
    embodiment_tag = EmbodimentTag(config.embodiment_tag)

    # 1.1 modality configs and transforms
    data_config_cls = DATA_CONFIG_MAP[config.data_config]
    modality_configs = data_config_cls.modality_config()
    transforms = data_config_cls.transform()

    # 1.2 data loader
    train_dataset = LeRobotSingleDataset(
        dataset_path=config.dataset_path,
        modality_configs=modality_configs,
        transforms=transforms,
        embodiment_tag=embodiment_tag,  # This will override the dataset's embodiment tag to "new_embodiment"
        video_backend=config.video_backend,
    )

    # ------------ step 2: load model ------------
    model = GR00T_N1.from_pretrained(
        pretrained_model_name_or_path=config.base_model_path,
        tune_llm=config.tune_llm,  # backbone's LLM
        tune_visual=config.tune_visual,  # backbone's vision tower
        tune_projector=config.tune_projector,  # action head's projector
        tune_diffusion_model=config.tune_diffusion_model,  # action head's DiT
    )

    # Set the model's compute_dtype to bfloat16
    model.compute_dtype = "bfloat16"
    model.config.compute_dtype = "bfloat16"

    if config.lora_rank &gt; 0:
        model = get_lora_model(
            model,
            rank=config.lora_rank,
            lora_alpha=config.lora_alpha,
            lora_dropout=config.lora_dropout,
        )

    # 2.1 modify training args
    training_args = TrainingArguments(
        output_dir=config.output_dir,
        run_name=None,
        remove_unused_columns=False,
        deepspeed="",
        gradient_checkpointing=False,
        bf16=True,
        tf32=True,
        per_device_train_batch_size=config.batch_size,
        gradient_accumulation_steps=1,
        dataloader_num_workers=config.dataloader_num_workers,
        dataloader_pin_memory=False,
        dataloader_persistent_workers=True,
        optim="adamw_torch",
        adam_beta1=0.95,
        adam_beta2=0.999,
        adam_epsilon=1e-8,
        learning_rate=config.learning_rate,
        weight_decay=config.weight_decay,
        warmup_ratio=config.warmup_ratio,
        lr_scheduler_type="cosine",
        logging_steps=10.0,
        num_train_epochs=300,
        max_steps=config.max_steps,
        save_strategy="steps",
        save_steps=config.save_steps,
        save_total_limit=8,
        report_to=config.report_to,
        seed=42,
        do_eval=False,
        ddp_find_unused_parameters=False,
        ddp_bucket_cap_mb=100,
        torch_compile_mode=None,
    )

    # 2.2 run experiment
    experiment = TrainRunner(
        train_dataset=train_dataset,
        model=model,
        training_args=training_args,
        resume_from_checkpoint=config.resume,
    )

    # 2.3 run experiment
    experiment.train()


if __name__ == "__main__":
    # Parse arguments using tyro
    config = tyro.cli(Config)

    # Print the tyro config
    print("\n" + "=" * 50)
    print("GR00T FINE-TUNING CONFIGURATION:")
    print("=" * 50)
    for key, value in vars(config).items():
        print(f"{key}: {value}")
    print("=" * 50 + "\n")

    available_gpus = torch.cuda.device_count() if torch.cuda.is_available() else 1

    # Validate GPU configuration
    assert (
        config.num_gpus &lt;= available_gpus
    ), f"Number of GPUs requested ({config.num_gpus}) is greater than the available GPUs ({available_gpus})"
    assert config.num_gpus &gt; 0, "Number of GPUs must be greater than 0"
    print(f"Using {config.num_gpus} GPUs")

    if config.num_gpus == 1:
        # Single GPU mode - set CUDA_VISIBLE_DEVICES=0
        os.environ["CUDA_VISIBLE_DEVICES"] = "0"
        # Run the script normally
        main(config)
    else:
        if os.environ.get("IS_TORCHRUN", "0") == "1":
            main(config)
        else:
            # Multi-GPU mode - use torchrun
            script_path = Path(__file__).absolute()
            # Remove any existing CUDA_VISIBLE_DEVICES from environment
            if "CUDA_VISIBLE_DEVICES" in os.environ:
                del os.environ["CUDA_VISIBLE_DEVICES"]

            # Use subprocess.run instead of os.system
            cmd = [
                "torchrun",
                "--standalone",
                f"--nproc_per_node={config.num_gpus}",
                "--nnodes=1",  # default to 1 node for now
                str(script_path),
            ]

            # Convert config to command line arguments
            for key, value in vars(config).items():
                if isinstance(value, bool):
                    # For boolean values, use --flag or --no-flag format
                    if value:
                        cmd.append(f"--{key.replace('_', '-')}")
                    else:
                        cmd.append(f"--no-{key.replace('_', '-')}")
                else:
                    # For non-boolean values, use --key value format
                    cmd.append(f"--{key.replace('_', '-')}")
                    cmd.append(str(value))
            print("Running torchrun command: ", cmd)
            env = os.environ.copy()
            env["IS_TORCHRUN"] = "1"
            sys.exit(subprocess.run(cmd, env=env).returncode)
</code></pre><p>建议在实际训练中，将 batch size 尽可能调大，并训练 20k steps。请在 DreamGen 环境中运行相应命令。<br/><img width="723" height="319" referrerpolicy="no-referrer" src="/img/bVdm0rV" alt="image.png" title="image.png" loading="lazy"/></p><h2>模型测评</h2><p>在本例中，使用真实的GR1机器人进行模型效果验证，得到结果如下：<br/><img width="723" height="255" referrerpolicy="no-referrer" src="/img/bVdm0sb" alt="image.png" title="image.png" loading="lazy"/></p><p>从结果中可以看到：</p><ul><li>在已知场景中执行全新的动作，未使用扩增数据微调的GR00T N1模型仅有11.2%的成功率，使用扩增数据微调后可以达到43.2%的成功率</li><li>在未知场景中执行已知或未知动作，未使用扩增数据微调的GR00T N1模型全部失败，但是使用扩增数据微调后可以达到28.5%的成功率</li></ul><h2>总结</h2><p>在本最佳实践中，基于阿里云 PAI 平台的特性，我们实现了基于Cosmos世界模型的操作动作数据扩增与模仿学习，包含从人工少量演示、数据扩增、拒绝采样、IDM逆解算、模仿学习再到模型测评的端到端实现</p><p>与基于Isaac仿真的数据扩增技术一样，Cosmos 数据扩增后训练的模型在各个场景下的成功率均有较高提升。相比于Isaac仿真，Cosmos数据扩增有以下特点：</p><ul><li>人工演示、数据扩增环节无需仿真算力（RT Core），全流程使用同构算力（CUDA Core/Tensor Core）</li><li>无需对人工演示数据进行动作打标处理，直接使用视频数据即可实现扩增</li><li>无需单独的数据增强环节，可在数据扩增环节通过调整提示词实现数据增强</li><li>需要额外的拒绝采样步骤以过滤不合理的生成内容，以及额外的IDM逆解算步骤以补齐视频中缺少的action序列</li></ul><pre><code class="markdown">!torchrun --nproc_per_node=4 --master_port=12341 -m examples.video2world_gr00t \
--num_gpus 4   --model_size 14B   --gr00t_variant gr1   \
--batch_input_json dream_gen_benchmark/gr1_object/batch_input.json   
--disable_guardrail</code></pre>]]></description></item><item>    <title><![CDATA[数字孪生技术在国防航天领域的实战应用 图]]></title>    <link>https://segmentfault.com/a/1190000047390078</link>    <guid>https://segmentfault.com/a/1190000047390078</guid>    <pubDate>2025-11-11 18:04:36</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在国防航天领域，信息系统的集成与运营管理面临着诸多挑战：海量设备数据如何实时监控？多源异构系统如何无缝融合？突发状况如何快速响应？这些问题不仅关系到任务执行的效率，更直接影响到国家安全与战略部署。<br/>近期，某大型国防航天机构通过部署数字孪生智能运营中心—孪易IOCProMax版，成功构建了一套全域智能运营体系，实现了从宏观态势感知到微观设备管控的全链路管理升级。本文将基于实际案例，分享数字孪生技术在国防航天领域的具体应用经验。</p><h2>突破信息孤岛，实现全域可视化</h2><p>该机构原有各业务系统独立运行，数据分散在不同部门和平台中。指挥中心难以实时掌握全局运行状态，决策往往基于滞后和不完整的信息。<br/>通过部署孪易IOC，该机构实现了多源数据的深度融合。系统通过多种数据接入方式，整合了设备台账、传感器数据和实时视频流，有效打破了信息壁垒。<br/>项目技术负责人表示："系统的空间分析能力特别实用。通过可视域分析、通视分析等专业工具，我们能够量化评估复杂的地理空间关系，为任务规划提供了重要参考依据。"</p><h2>构建智能预警体系，提升主动防控能力</h2><p>在国防航天领域，预防比事后处置更为重要。传统模式下，异常情况的发现主要依赖人工巡检和事后报告，响应效率存在提升空间。<br/>而数字孪生平台的智能预警机制发挥了重要作用。系统支持设置多级告警条件，能够自动监测异常数据并分类预警。在某次任务准备阶段，系统提前发现设备参数异常，及时发出预警，避免了可能发生的任务延误。<br/>值得一提的是系统的应急指挥能力。通过数字化预案管理和仿真演练，指挥中心能够基于预设方案快速调配资源，实现多部门协同处置。在最近的应急演练中，整体响应效率得到显著提升。<br/><img width="640" height="360" referrerpolicy="no-referrer" src="/img/bVdmmM0" alt="" title=""/></p><h2>灵活可扩展，满足特殊业务需求</h2><p>国防航天领域的系统集成有其特殊性，既要确保系统稳定可靠，又要适应不断变化的业务需求。<br/>在该项目中，系统提供了灵活的渲染模式选择：端渲染模式满足高并发、轻量化的日常监控需求；流渲染模式则能提供更精细的可视化效果，适用于重要任务的展示需求。<br/>系统的可定制性也得到技术团队的认可。业务人员可以通过可视化方式快速搭建应用，开发人员则能基于标准接口进行深度定制，这种灵活性确保了系统能够持续适应业务发展需求。<br/><img width="640" height="314" referrerpolicy="no-referrer" src="/img/bVdmQxT" alt="" title="" loading="lazy"/></p><h2>应用成效：超越技术层面的价值</h2><p>该项目的实施，带来的不仅是技术升级，更是运营模式的优化：<br/><strong>决策支持升级</strong>：基于全景可视化的态势信息，指挥决策更加科学精准；<br/><strong>资源管理优化</strong>：通过统一的对象管理机制，实现了对各类资源的高效调配；<br/><strong>系统演进能力</strong>：平台具备持续演进特性，能够适应快速发展的业务需求。</p><h2>经验总结</h2><p>数字孪生技术在国防航天领域的应用正在不断深入。从该案例可以看出，一个成熟的数字孪生平台，不仅需要扎实的技术基础，更需要深入理解行业特性和业务场景。<br/>对于系统集成商而言，选择具备全面感知、智能分析、生态兼容和灵活扩展能力的数字孪生平台—孪易IOC Promax版，有助于在国防航天领域提供更优质的服务。</p>]]></description></item><item>    <title><![CDATA[被问性能后，我封装了这个 PHP 错误上]]></title>    <link>https://segmentfault.com/a/1190000047390080</link>    <guid>https://segmentfault.com/a/1190000047390080</guid>    <pubDate>2025-11-11 18:03:38</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>最近我把自己常用的一套错误上报逻辑封装成了一个 Composer 包，叫 <strong>​<code>hejunjie/lazylog</code>​</strong>。  <br/>功能很简单也很实用：<strong>安全地写本地日志 + 把异常信息上报到远端（支持同步/异步）</strong> 。本文讲讲为什么我要做这个库、实现思路、在不同运行环境下如何选择（以及我推荐的优化方案）。</p><hr/><h2>起因：为啥要做这个工具？</h2><p>先讲个背景。之前我写了一个 Go 项目 —— <a href="https://link.segmentfault.com/?enc=%2FQfqD4VLXs03S3Ht6VStkA%3D%3D.zanBYA9NslIfl0w4b9paMc7U4wy2ft4Tk4a04%2FTA5iavGubn448b1EjULBFWJ%2FUW" rel="nofollow" target="_blank">oh-shit-logger</a>，目标是把不同语言、不同项目里的错误集中收集到一个地方。Go 做服务天然快、部署也简单： GitHub Actions自动打包，我只要把包丢主机上一键启动就好了。</p><p>但上线后有朋友问：</p><blockquote>“PHP 上报错误会不会太耗性能？网络 I/O 会不会成为瓶颈？”</blockquote><p>这是个很合理的问题。网络 I/O 的确有成本，但异常本身在多数系统里不是那种持续不断、高频率的事件（如果异常多到经常并发，那系统可能已经在出问题了）。</p><p>与其空谈“会不会慢”，我更愿意把常用做法封装一下，直接给出一个实战好用的方案——于是 <code>hejunjie/lazylog</code> 诞生了。</p><hr/><h2>思路概览：伪异步 + 可回退的同步</h2><p>​<code>lazylog</code> 的核心思路很简单：</p><ul><li><strong>本地写日志</strong>：线程安全、支持按行数/大小自动切分，长期运行不会把单个日志文件撑爆。</li><li><p><strong>远程上报</strong>：提供两种方式：</p><ul><li><strong>异步上报（伪异步）</strong> ：通过 <code>proc_open()</code> 或 <code>exec()</code> fork 出一个 PHP CLI 子进程来发送 HTTP POST，不阻塞主进程。适用于 PHP-FPM、一次性 CLI 脚本等短生命周期环境。</li><li><strong>同步上报</strong>：直接在当前进程做一个带超时的 HTTP POST，适合常驻内存框架（Webman、Swoole、RoadRunner 等）或需要保证上报结果的场景。</li></ul></li></ul><p>我把这些行为都封装在一个很小的包里：<code>composer require hejunjie/lazylog</code>，在任何项目里都能快速复用。</p><hr/><h2>异步实现细节：为什么是“伪异步”？</h2><p>PHP 没有内置线程（除非用扩展），但我们可以通过子进程实现“非阻塞式”的上报：</p><ul><li>​<code>proc_open()</code>：启动子进程并可拿到 stdin/stdout/stderr，控制能力强；但会创建管道资源，需要注意关闭管道以免资源泄露。</li><li>​<code>exec()</code>：简单粗暴，把命令交给 shell 去做 <code>fork</code>，父进程可立即返回（命令后面加 <code>&amp;</code>）。语义上更轻量，但控制能力弱。</li></ul><p>两者的本质都是 fork 一个新进程去跑 PHP CLI，然后子进程读取临时文件（或者接收传参）、发 POST、删临时文件、退出。主进程不会等子进程走完就返回给用户，所以对用户体验几乎零影响。</p><p><strong>优点</strong>：实现简单、跨平台、即插即用；适合错误信息本身不高频的场景。  <br/><strong>缺点</strong>：在“极高并发”场景下（比如每秒上千条错误）会比较吃资源，子进程启动和网络请求仍然有成本。</p><hr/><h2>常驻内存框架（Webman/Swoole）该怎么办？</h2><p>这是个重要的实践问题：<strong>在常驻内存框架中，我更推荐用同步上报或队列，而不是频繁 fork 子进程。</strong></p><p>原因很直观：</p><ul><li>常驻框架的 Worker 是长期存在的，fork 子进程会带来额外的资源管理问题（僵尸进程、内存增长、文件描述符等）。</li><li>同步上报虽然会阻塞当前 Worker，但只影响当前 Worker，不会像在传统短生命周期中影响整个请求模型。对于大多数低频异常而言，这个阻塞代价是可以接受的。</li><li>更稳妥的做法是：<strong>把异常先格式化成数组，投递到队列，由专门的队列 worker 来异步上报</strong>。这样既避免了直接 fork，又能在不影响主流程的情况下批量/可靠地上报。</li></ul><p>我在包里同时提供了 <code>reportSync()</code>（同步上报）和 <code>reportAsync()</code>（伪异步上报），并提供 <code>Logger::formatThrowable()</code> 帮你把异常转成纯数据结构，方便推队列或序列化。</p><hr/><h2>实际使用示例</h2><blockquote>这里只放伪代码以示意，实际代码见仓库。</blockquote><p><strong>本地写日志</strong></p><pre><code class="php">Logger::write('/var/logs', 'error/app.log', 'Task Failed', ['msg' =&gt; 'something wrong']);</code></pre><p><strong>短生命周期场景（异步上报）</strong></p><pre><code class="php">try {
  // ...
} catch (Throwable $e) {
  Logger::reportAsync($e, 'https://your-collector/collect', 'my-project');
}</code></pre><p><strong>常驻框架（推荐同步或队列）</strong></p><pre><code class="php">try {
  // ...
} catch (Throwable $e) {
  // 同步上报（简单、直接）
  Logger::reportSync($e, 'https://your-collector/collect', 'my-project');

  // 或者：转成数组，投递队列，由 Worker 负责上报（推荐）
  $payload = Logger::formatThrowable($e, 'my-project');
  Queue::push('error_report', $payload);
}</code></pre><hr/><h2>性能那些事儿</h2><p>有人担心“网络 I/O 会把 PHP 卡死”。我的观点是：</p><ul><li><strong>错误本身通常是低频事件</strong>。如果你的系统错误频率高到持续占用大量带宽/请求，那说明系统正常运行已经有更严重的问题了。</li><li>对于多数业务，<strong>一次 fork 一个子进程并做一次 HTTP POST 的开销在可接受范围</strong>，用户体验影响极小。</li><li>在对性能要求极苛刻或错误量非常大的场景，正确做法是<strong>把上报变成队列 + 批量发送</strong>或将上报移动到专门的后端处理链路，而不是在业务路径里频繁 fork。</li></ul><p>总之：<strong>衡量利弊后选择适合你业务的方式</strong>。<code>lazylog</code> 提供了两端（sync/async）以及格式化功能，方便你按需设计。</p><hr/><h2>最后</h2><p>我把它做成 composer 包的原因很直接：我希望 <strong>快速把 PHP 项目的错误上报到我自己的 Go 服务（oh-shit-logger）</strong> ，而不是每个项目都重复造轮子。把常用逻辑抽出来，项目里 <code>composer require hejunjie/lazylog</code> 就能统一上报方式——既省事又稳妥。</p><p>如果你想快速了解这个项目：<a href="https://link.segmentfault.com/?enc=yo2zAlDjRdhAFWOk1ww6bw%3D%3D.RnrTclOVs3MiepJJ4px9tbS8Tqwr%2FznGARieYy0sJQ7hiZGE1xzrdMLaMstM06q%2F" rel="nofollow" target="_blank">Zread 解析文档</a></p><ul><li>如果你是在 <strong>PHP-FPM / CLI</strong> 的短生命周期环境：<code>reportAsync()</code> 很方便，能保证主流程不被阻塞。</li><li>如果你是在 <strong>Webman/Swoole 等常驻内存框架</strong>：优先考虑 <code>reportSync()</code> 或推队列再上报。</li><li>如果你面临的是<strong>极高并发的错误量</strong>：把上报放队列，批量发送，或交由专门的采集基础设施处理。</li></ul>]]></description></item><item>    <title><![CDATA[如何用图观数字孪生引擎高效构建城市治理应]]></title>    <link>https://segmentfault.com/a/1190000047390084</link>    <guid>https://segmentfault.com/a/1190000047390084</guid>    <pubDate>2025-11-11 18:02:49</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>作为一名数字孪生应用开发者，我深知城市治理领域的项目往往面临场景复杂、数据量大、交付周期紧的挑战。经过多个项目的实践，我发现图观数字孪生产品提供了一套非常实用的解决方案。今天，就和大家分享几个在实际项目中验证过的使用技巧。</p><h2>场景构建：从UE编辑器到专业数字孪生场景的无缝衔接</h2><p>在最近的一个智慧城市项目中，我们利用图观与Unreal Engine的深度集成，仅用两周就完成了原本需要一个月的工作量：<br/><strong>技巧一：善用画刷对象进行批量布置</strong><br/>在构建园区绿化带时，我们使用画刷工具的等距排列功能，快速布置了上千棵树木和景观设施。相比传统的手动摆放，效率提升了近10倍。<br/><strong>技巧二：灵活运用建筑剖分功能</strong><br/>对于重点建筑，我们通过建筑对象的楼层剖分功能，实现了从外部整体到内部结构的无缝展示。这个功能特别适合用于应急指挥场景，能够清晰展示建筑内部的空间布局。<br/><img width="587" height="330" referrerpolicy="no-referrer" src="/img/bVdmDNB" alt="" title=""/></p><h2>GIS数据处理：从全球到局部的平滑过渡</h2><p>在城市级项目中，我们经常需要处理从宏观到微观的多尺度场景。图观的内核级GIS支持帮我们解决了这个难题。<br/><strong>技巧三：合理设置数据加载范围</strong><br/>在智慧城市项目中，我们通过配置不同的数据加载范围，实现了从全市概览到具体街道的平滑切换。关键是要提前规划好各级别场景的显示内容和数据精度，避免不必要的性能消耗。<br/><strong>技巧四：充分利用多源数据兼容性</strong><br/>我们成功接入了客户现有的WMTS地图服务和倾斜摄影数据，大大减少了数据准备时间。建议在项目初期就做好数据源评估，充分利用现有GIS资源。<br/><img width="587" height="330" referrerpolicy="no-referrer" src="/img/bVdmDNB" alt="" title="" loading="lazy"/></p><h2>应用开发：零代码与低代码的灵活选择</h2><p>根据不同的项目需求和团队配置，我们探索出了两种高效的开发模式：<br/><strong>技巧五：零代码快速原型</strong><br/>对于需求相对固定的展示类项目，我们使用图观的零代码开发平台。通过拖拉拽配置数据图表和交互逻辑，3天就能完成一个基础应用的搭建，极大提升了与客户的沟通效率。<br/><strong>技巧六：低代码深度定制</strong><br/>对于需要复杂业务逻辑的项目，我们采用JS API进行开发。图观提供的统一JavaScript API兼容Vue/React等框架，让我们的前端团队能够快速上手。特别值得一提的是双渲染内核的支持，让我们能够根据项目需求灵活选择端渲染或流渲染模式。<br/><img width="640" height="360" referrerpolicy="no-referrer" src="/img/bVdmUPr" alt="" title="" loading="lazy"/></p><h2>性能优化：确保大型场景的流畅体验</h2><p>在城市级数字孪生项目中，性能优化是重中之重。我们总结出几个实用技巧：<br/><strong>技巧七：合理使用场景预热功能</strong><br/>对于核心场景，我们启用预热驻留功能，使重要场景的打开时间从分钟级缩短到秒级。这个功能在领导视察、重要演示等场景中特别实用。<br/><strong>技巧八：动态调整渲染质量</strong><br/>通过流渲染的自适应能力，我们为不同网络环境的用户提供合适的画面质量，既保证了操作流畅性，又提供了最佳视觉体验。</p><h2>实践心得</h2><p>经过多个项目的验证，我们发现图观数字孪生引擎的以下几个特点特别适合城市治理领域：<br/><strong>1.开发效率显著提升</strong>：与UE的深度集成让我们能够在熟悉的开发环境中工作，同时获得专业的数字孪生能力<br/><strong>2.技术门槛大幅降低</strong>：从零代码到低代码的完整方案，让不同技术背景的团队成员都能发挥作用<br/><strong>3.项目风险有效控制</strong>：稳定的流渲染服务和集群化部署能力，确保了大型项目的顺利交付</p><p>这些技巧帮助我们在智慧城市、园区管理、应急指挥等多个城市治理场景中成功交付了高质量的数字孪生应用。希望这些经验对各位开发者同行有所启发。</p>]]></description></item><item>    <title><![CDATA[Studio 3T 2025.20 发布]]></title>    <link>https://segmentfault.com/a/1190000047390087</link>    <guid>https://segmentfault.com/a/1190000047390087</guid>    <pubDate>2025-11-11 18:02:17</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>Studio 3T 2025.20 (macOS, Linux, Windows) - MongoDB 的终极 GUI、IDE 和 客户端</p><p>The Ultimate GUI, IDE and client for MongoDB</p><p>请访问原文链接：<a href="https://link.segmentfault.com/?enc=q2xf94Z11eNgPCOX5OFlHA%3D%3D.w9zm1eHFlFJhopOaPawtejq%2FMtfa2BLln28851sXTzfBfhjrSLPTpvR7nZAf2umZ" rel="nofollow" target="_blank">https://sysin.org/blog/studio-3t/</a> 查看最新版。原创作品，转载请保留出处。</p><p>作者主页：<a href="https://link.segmentfault.com/?enc=EviGWk99rZBmFPP3Y0vrSg%3D%3D.9LuIm1SWT19Sn19gdYthDRzMXMnhNQ%2FR3Mq%2BNLC5ypU%3D" rel="nofollow" target="_blank">sysin.org</a></p><hr/><p>Studio 3T，MongoDB 的终极 (卓越、非凡) GUI、IDE 和 客户端</p><p>适用于 MongoDB 的所有 IDE、客户端和 GUI 工具 —— 在 Atlas 上或任何地方。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000044432404" alt="sysin" title="sysin"/></p><p>MongoDB 的强大工具。</p><p>超过 100,000 名开发人员和数据库管理员使用 Studio 3T 作为他们首选的 MongoDB GUI</p><h2>MongoDB 客户端、GUI 与 IDE</h2><p>那么 Studio 3T 到底是什么？ 在这里，我们解释了它戴的许多帽子中的三个。</p><ul><li><p><strong>Studio 3T 作为 MongoDB 客户端</strong></p><p>客户端是允许您连接到服务器的软件程序或应用程序。尽情使用 Studio 3T 的连接管理器，根据需要连接到尽可能多的 MongoDB 服务器。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000044432411" alt="sysin" title="sysin" loading="lazy"/></p></li><li><p><strong>Studio 3T 作为 MongoDB GUI</strong></p><p>图形用户界面 (GUI) 完全按照它说的去做。它提供了一个带有图形菜单、图标、对话框、向导和其他可视元素的用户界面。使用 MongoDB  GUI 的替代方法是使用 mongo shell，尽管 Studio 3T 仍然有  IntelliShell——一个易于导航的内置版本——当你需要的时候 (抄si袭quan者jia)。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000044432412" alt="sysin" title="sysin" loading="lazy"/></p></li><li><p><strong>Studio 3T 作为 MongoDB IDE</strong></p><p>集成开发环境 (IDE) 将应用程序和数据库开发的许多方面整合到一个功能齐全的 “工作室” 环境中 (sysin)。Studio 3T  正是通过提供一个 GUI 来做到这一点，该 GUI 的编辑器具有自动完成和语法突出显示、内置 JSON  验证、七种语言的自动查询代码生成以及许多其他功能，可帮助您更快地工作并节省时间。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000044432413" alt="sysin" title="sysin" loading="lazy"/></p></li></ul><h2>新增功能</h2><p><strong>2025.20.</strong>（2025年11月3日）</p><p><strong>新增功能</strong>：</p><ul><li>AI 助手 – 添加了通过代理连接 Anthropic Claude AI 的支持。</li></ul><p><strong>修复</strong>：</p><ul><li>AI 助手 – 解决了在恢复的“视图”标签会话中未检测到源的问题。</li><li>IntelliShell – 解决了使用 DNS 名称连接到副本集主机时发生的问题。</li></ul><h2>下载地址</h2><p>Studio 3T 2025.20, released 2025-11-03</p><ul><li>请访问：<a href="https://link.segmentfault.com/?enc=Qlds94HdP4ix3R%2FjxarxYg%3D%3D.2zuU6uppF%2BE0FoO6WlBULIKDAc1cxdg3Zgb9TAs7i%2BgWSIPKMCMw1CrRQS0NwliA" rel="nofollow" target="_blank">https://sysin.org/blog/studio-3t/</a></li></ul><p>Studio 3T Community Edition</p><ul><li>Studio 3T for macOS x64：<code>Studio-3T-&lt;Version&gt;-x64.dmg</code></li><li>Studio 3T for macOS ARM64 (Apple silicon)：<code>Studio-3T-&lt;Version&gt;-arm64.dmg</code></li><li>Studio 3T for Linux x64：<code>studio-3T-&lt;Version&gt;-linux-64.tar.gz</code></li><li>Studio 3T for Windows x64：<code>Studio-3T-&lt;Version&gt;-x64.exe</code></li></ul><p>更多：<a href="https://link.segmentfault.com/?enc=EWwX5IrySgEOLAB%2FoFdb3A%3D%3D.oY%2BZzuNKJsqTzUzJRGxV7NIgaM37ucE%2BTHzenFahsVA%3D" rel="nofollow" target="_blank">macOS 下载汇总 (系统、应用和教程)</a></p>]]></description></item><item>    <title><![CDATA[城市公共安全的智能守护者 图观 ]]></title>    <link>https://segmentfault.com/a/1190000047390102</link>    <guid>https://segmentfault.com/a/1190000047390102</guid>    <pubDate>2025-11-11 18:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在城市公共安全领域，如何高效整合多源数据、快速响应突发事件，一直是系统集成商面临的挑战。某大型城市应急管理部门通过部署孪易数字孪生IOC ProMAX版，实现了对城市安全态势的全方位掌控。这一案例不仅验证了系统的实战能力，更为行业提供了可复制的解决方案。</p><h2>一、从数据孤岛到智能协同</h2><p>该城市原有多个独立的安全监控系统，包括交通摄像头、环境传感器、警力调度平台等。这些系统数据格式不一，信息共享困难。通过数字孪生IOC ProMAX版的多源数据接入能力，实现了物联网设备、数据库、云平台的快速对接。<br/>系统上线后，指挥中心首次实现了对全市安全要素的统一可视化监控。操作人员可通过多级地点切换功能，从城市全景快速定位到具体街区，再深入到单个建筑内部，完成从宏观到微观的无缝巡查。</p><h2>二、智能预警与快速响应机制</h2><p>去年夏季，系统成功预警了一起重大安全隐患。通过环境仿真与历史回放功能，系统识别出某区域排水系统在极端降雨条件下的风险点。当实际降雨量达到预警阈值时，系统自动启动应急预案。<br/>智能告警机制立即将预警信息推送至相关责任人员，同时通过空间分析工具模拟出可能受影响的范围。指挥人员利用可视域分析功能，快速确定了最优的疏散路线和救援力量部署方案。<br/><img width="640" height="360" referrerpolicy="no-referrer" src="/img/bVdmUPX" alt="" title=""/></p><h2>三、实战中的智能决策支持</h2><p>在一次大型活动安保任务中，系统展现了其强大的分析预测能力。AI驱动的智能助理通过自然语言交互，快速响应指挥人员的查询需求：“显示人民广场周边三公里内所有警力部署情况”。<br/>系统不仅实时展示了警力位置，还通过趋势预测功能，基于历史人流量数据推演出未来两小时的人员聚集趋势。这为动态调整安保方案提供了科学依据。<br/><img width="640" height="360" referrerpolicy="no-referrer" src="/img/bVdmSnM" alt="" title="" loading="lazy"/></p><h2>四、灵活架构支撑业务演进</h2><p>该项目的成功，很大程度上得益于系统的可扩展架构。初期部署时，主要使用零代码配置功能快速搭建基础监控平台。随着业务深入，开发团队利用低代码开发模式，定制开发了多个专业分析模块。<br/>这种渐进式的建设方式，既保证了项目的快速交付，又为后续功能扩展留出了充足空间。目前，该系统已稳定运行两年多，期间经历了多次重大活动保障考验。</p><h2>五、可复制的价值经验</h2><p>这个案例展示了数字孪生技术在城市公共安全领域的三个核心价值：<br/>首先是<strong>数据价值最大化</strong>。通过打破信息孤岛，将沉睡的数据转化为决策依据；<br/>其次是<strong>响应效率提升</strong>。智能预警与预案系统的结合，将事后处置转变为事前预防；<br/>最后是<strong>系统可持续演进</strong>。灵活的架构设计确保系统能够伴随业务需求持续升级。<br/>对于系统集成商而言，这个案例最具参考价值的是其建设模式——从基础监控起步，逐步深化应用，最终形成完整的智能运营体系。这种渐进式路径既控制了项目风险，又确保了投资效益。</p>]]></description></item><item>    <title><![CDATA[如何通过设备域智能体提升设备运行状态准确]]></title>    <link>https://segmentfault.com/a/1190000047389125</link>    <guid>https://segmentfault.com/a/1190000047389125</guid>    <pubDate>2025-11-11 16:12:27</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在现代工业体系中，设备作为生产线的核心参与者，其运行状况与维护能力直接影响产品交付效率和企业利润率。然而，传统设备管理往往依赖人工经验，受限于信息隔离与响应滞后，容易陷入生产与维修决策的“两难困局”。设备故障时间点难预测、维修资源难调度、配件库存难平衡，这些被动式管理痛点不仅扰乱了企业的时间链，也耗费了大量人力物力。随着人工智能技术的深入演进，特别是工业智能体这一创新概念的提出，这一局面正在被彻底打破。本文将围绕“设备域智能体”这一核心主题，结合Geega工业智能体平台的实践应用，探讨其如何在制造业中实现从监测到决策的闭环赋能，并为企业提供兼具智能化与可持续性的新方案。<br/>设备域智能体的出现，正是为了填补传统自动化系统与制造业复杂场景之间的巨大鸿沟。它将人工智能与工业实践深度融合，犹如赋予工厂一台具备“火眼金睛”与“决策权柄”的智慧中枢，既能洞悉问题的微兆，又能导向最优解决方案。借助工业智能体的强大感知能力，企业可以实时捕获设备运行参数，诸如温度、振动、压力等，进而结合算法模型对这些碎片化数据进行深度整合与因果推演。这种能力让设备从“被观察的对象”转变为“自我诊断的实体”，不再依赖突如其来的事故发生后的应急响应，而是提前局部预判关键故障，整合全局资源，化被动为主动。<br/>广域铭岛的Geega工业智能体平台便是设备域智能体这一理念的典型具象化。它不仅应对了数据感知的技术需求，更重点解决了多部门协同的难题，在设备维修领域给出了令人瞩目的改进数据。例如，某机械制造企业通过运用Geega平台，将设备配件库存成本显著降低，同时也大大缩短了企业设备停机与维修响应时间，达到了前所未有的运行效率。这一切源于Geega平台对企业业务流程的智能再造——它融合了设备状态数据、维修流程经验以及实时优化能力，把“会思考、会行动”的设备域智能体引入实际操作环节。<br/>但设备域智能体的作用绝非仅仅停留在“警报提醒”或“库存调整”层面。它可以对原有的故障根因进行溯源分析，结合大数据技术建立个性化设备健康档案，从而对设备全生命周期做到精细化管理。在实践中，某汽车工厂设备拆解环节原本极为低效，但引入设备域智能体后，不仅预测维修周期变得更加精准，而且物料配送的认识时间得到了优化平衡，实现“预防胜于治疗”的预期目标。设备域智能体甚至可以自我调节运行节奏，比如在发现某一设备即将出现负载过重风险时，通过边缘计算节点进行自主策略调整，并向云端资源系统发出协同预警，从而在根源和末端之间构建一条无形的高效通道。<br/>设备域智能体的发展不仅带来效率的跃升，更牵动了产业生态结构的变迁。它用动态技术方案重塑了传统制造业的思考模式，逐渐完成了从信息化建设到价值创造的巨变。正如广域铭岛所展示的，设备域智能体在个性化需求预测、资源配置自动协调以及全流程质量安全监控中持续发力，逐渐打开了设备智能化转型的“新齿轮”。<br/>展望未来，随着模型优化能力与边缘计算技术融合的深化，设备域智能体将向更复杂多工况挑战。它将以更高的节奏与智能化水平重新定义工业运维秩序，逐渐走向人机协同更深入、决策更自主的“预测性维护4.0”时代。而这一时代的到来，也是中国制造业在数字化浪潮中实现全球领先的一大契机。<br/>总览全文内容，我们可以清晰地感知到，设备域智能体不是某一项技术工具或算法迭代，而是为多个生产环节之间协同赋能的“中枢神经”。在中国这样一个制造业大国，智能化与自动化从不再仅仅是一场技术革命，而是一条质量升级、效率飞跃、成本下沉的必经之路。广域铭岛的探索为这一趋势绘上了浓墨重彩的一笔，也在论证中坚定地表明：设备域智能体将引领制造业迈向可持续发展的坚实未来。</p>]]></description></item><item>    <title><![CDATA[虚拟机数据恢复—异常断电后ESXI存储连]]></title>    <link>https://segmentfault.com/a/1190000047389134</link>    <guid>https://segmentfault.com/a/1190000047389134</guid>    <pubDate>2025-11-11 16:11:41</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><strong>服务器存储数据恢复环境：</strong><br/>一台服务器上部署esxi虚拟化平台。上层采用通过FreeNAS构建的iSCSI方式FCSAN功能，FreeNAS层采用UFS2文件系统。<br/>esxi虚拟化系统有3台虚拟机。其中一台虚拟机采用FreeBSD系统，存储的是数据库文件；另外一台台虚拟机存储网站数据；第三台虚拟机安装的Windows server操作系统，存储的是数据库数据和工作程序代码。</p><p><strong>服务器存储故障：</strong><br/>机房供电不稳定导致设备非正常关机，重启后发现ESXI系统无法连接存储。服务器管理员对服务器进行故障排查，发现FreeNAS的UFS2文件系统出现故障。服务器管理员对文件系统进行fsck修复并将ESXI系统连接到服务器存储上。<br/>管理员对上层文件系统及数据进行检查，发现原服务器上的文件系统和存储数据都无法识别，于是对vmfs进行了格式化等操作，导致数据丢失。</p><p><strong>服务器存储数据恢复过程：</strong><br/>1、对FreeNAS层进行镜像。镜像完成后基于镜像文件对底层数据分析。北亚企安数据恢复工程师在存储内发现了一个文件名称为iscsidata的大文件。继续分析文件系统结构，根据UFS2文件系统的存储结构定位到这个大文件的iNode数据查看。查看后发现该文件此前被重建过，iNode指针所指向的数据量非常少。在这种情况下，进入到vmfs文件系统层进行数据分析和恢复需要先分析出FreeNAS层面的必要信息和数据。服务器数据恢复工程师通过分析获取到相关信息：UFS2文件系统块大小、segment大小、柱面组大小、每数据指针大小、每个块可容纳数据指针数量。<br/>根据上述信息计算出一个二级指针块可存储的数据量以及一个三级指针块可存储的数据量。<br/>2、服务器数据恢复工程师计划通过iscsidata文件的三级指针块来恢复FreeNAS层的数据。由于该文件曾经被重建，部分指针被重建的数据所覆盖，原文件的iNode和重建后的文件iNode所在的位置完全一致，也没有其他可用于数据恢复iNode数据。北亚企安服务器数据恢复工程师根据实际数据情况编写小程序收集有用的指针块，收集到了大量二级指针块和三级指针块。<br/>3、分析三级指针块，发现这些指针块都是无效的。继续分析二级指针块，对有大量的二级指针块的指向数据进行DUMP，然后再从磁盘中的数据定位到二级指针。通过这种方式得到大量DUMP的数据。<br/>4、服务器数据恢复工程师运用以前研究出来的NTFS和UFS2文件系统结构定位到vmfs层，继而定位到DUMP出的单个64GB文件，进行数据组合。<br/>5、经过复杂的查询和重组操作，最终成功恢复出了3台虚拟机及虚拟机内的全部数据。<br/>6、服务器数据恢复工程师将恢复出来的数据上传到新构建出来的系统中进行验证。经过用户方管理员验证，确认所有数据恢复成功。</p>]]></description></item>  </channel></rss>