<?xml version="1.0" encoding="UTF-8"?><rss version="2.0">  <channel>      <title>SegmentFault - 最近文章</title>      <link>https://segmentfault.com/blogs/newest</link>      <description>SegmentFault 思否</description>      <generator>python segmentfault.py @Pi20</generator>      <item>    <title><![CDATA[macOS Sequoia 15.7.4 (24G517) 正式版 ISO、IPSW、PKG 下载 ]]></title>    <link>https://segmentfault.com/a/1190000047608706</link>    <guid>https://segmentfault.com/a/1190000047608706</guid>    <pubDate>2026-02-13 10:07:07</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>macOS Sequoia 15.7.4 (24G517) 正式版 ISO、IPSW、PKG 下载</p><p>iPhone 镜像、Safari 浏览器重大更新和 Apple Intelligence 等众多全新功能令 Mac 使用体验再升级</p><p>请访问原文链接：<a href="https://link.segmentfault.com/?enc=2%2BCoIv%2FObqFtqwbo2vSXvw%3D%3D.tR3mNsnSTK2LnfaBXQ5ZWJEupnyFPKnz8OUk4N9t%2BDLuJejCM2oHr4FZN%2BpiBL2U" rel="nofollow" target="_blank">https://sysin.org/blog/macOS-Sequoia/</a> 查看最新版。原创作品，转载请保留出处。</p><p>作者主页：<a href="https://link.segmentfault.com/?enc=AfntmeqELtX8nQLzUzIf9Q%3D%3D.apNr13LLSLcQtfmylwubwAQqI8TdyBX%2BOkkisYSdFUY%3D" rel="nofollow" target="_blank">sysin.org</a></p><hr/><p>2026 年 2 月 12 日凌晨，Apple 发布 iOS/iPadOS/macOS/watchOS/tvOS/visonOS 全平台 26.3 版本更新。macOS Tahoe 26.3 此次为常规问题修复和安全更新。同时为不能更新最新系统的 Mac 发布了 macOS Sequoia 15.7.4 和 macOS Sonoma 14.8.4 软件更新，此类更新通常为安全修复和常规问题修复。</p><p>macOS Sequoia 将 Mac 生产力与智能化提升至全新高度</p><p>iPhone 镜像、Safari 浏览器重大更新和 Apple Intelligence 等众多全新功能令 Mac 使用体验再升级</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608708" alt="MacBook Air 展示 iPhone 镜像功能，iMac 展示 Safari 浏览器 Highlights 功能，MacBook Pro 展示 Apple 智能功能。" title="MacBook Air 展示 iPhone 镜像功能，iMac 展示 Safari 浏览器 Highlights 功能，MacBook Pro 展示 Apple 智能功能。"/></p><p>macOS Sequoia 以 iPhone 镜像拓展连续互通功能、新增生产力与视频会议工具，并为即将推出的多款游戏带来更具沉浸感的游戏体验。</p><h2>macOS Sequoia 更新摘要</h2><p>macOS Sequoia 15.7 及更新版本，如无特殊说明皆为安全更新或常规错误修复，不再赘述。</p><h2>macOS Sequoia 硬件兼容性列表</h2><p>笔者提示：“Apple Intelligence” (包括由其驱动的音频转写功能) 要求 <a href="https://link.segmentfault.com/?enc=veYLOymiHjtZgr6DifMB4Q%3D%3D.%2FGTLg17VDsE6WZzTe11XEynbNKRPcv7%2FHIUnqV%2FOJIKzisG%2BM%2FJMynK1avDYq9oT" rel="nofollow" target="_blank">搭载 Apple 芯片的 Mac 电脑</a>。</p><p>看看你的 Mac 是否能用 macOS Sequoia</p><p><a href="https://link.segmentfault.com/?enc=Tk9qpJ6%2BFKRzs00vkrW2tw%3D%3D.3gYKzvf7P2v%2FCKM5l8QzgGYAjfGulMcFTLbwlWiDx64%3D" rel="nofollow" target="_blank">进一步了解 Mac&gt;</a></p><ul><li><strong>MacBook Air</strong> 2020 and later <a href="https://link.segmentfault.com/?enc=REBcAes0yOQDkZkIM3f4UQ%3D%3D.2grhSI0gOlV2v5bXb741R7lhw5HaV10S7%2FetqbeMQNo73wf%2BRVFg%2BzFeuxAwdo4q" rel="nofollow" target="_blank">进一步了解 &gt;</a></li><li><strong>MacBook Pro</strong> 2018 and later <a href="https://link.segmentfault.com/?enc=xn%2FVV9StWKbNcmz60Fj6CA%3D%3D.AL3AnUBtOwVeWwb1SM5b5MiL13PLcAs3Nn%2FHJ4vjO722MpcrRt9jdAnTOhxp2i8M" rel="nofollow" target="_blank">进一步了解 &gt;</a></li><li><strong>Mac mini</strong> 2018 and later <a href="https://link.segmentfault.com/?enc=nKCaW6l7CI4iQOEIrucRqQ%3D%3D.y85T9T8dn6xKPNWWxV95d3%2FPA1w5z81zz37Q8KSkF4fZCiquEe5P7O8evNPKkOS4" rel="nofollow" target="_blank">进一步了解 &gt;</a></li><li><strong>Mac Studio</strong> 2022 <a href="https://link.segmentfault.com/?enc=Jysm6quldq0vc0NqGW3G9Q%3D%3D.vV0YMWa5TVaAg8ugdKKZsDzpEEKyl6ju0io6muA0xYZu%2BjJ7SIidC2huA80HLyEs" rel="nofollow" target="_blank">进一步了解 &gt;</a></li><li><strong>Mac Pro</strong> 2019 and later <a href="https://link.segmentfault.com/?enc=pbYfW9PVBYAbU8BZehivDg%3D%3D.TUVDOwaf65E2jzp1wQsbPKzZxTxuxHrFojlgxixGO8vlLcUitoBBQaVy1taAlJTV" rel="nofollow" target="_blank">进一步了解 &gt;</a></li><li><strong>iMac</strong> 2019 and later <a href="https://link.segmentfault.com/?enc=0rSeODpXoi1LA8b7D1b%2B7g%3D%3D.X0U2i%2Bod1OvvPaBzoiUeo%2ByEwiqkptFtyz1XpZV3U9Mr8euOTwrxHooQmJwlhN3s" rel="nofollow" target="_blank">进一步了解 &gt;</a></li><li><strong>iMac Pro</strong> 2017 and later <a href="https://link.segmentfault.com/?enc=dtRZ5eI%2B8hlWmBFsls%2BN3w%3D%3D.bosZ9H5L6VUCruLfpTU1oyRwqfiH0JgrPSDIMTTyNrosHCekyjHP%2Ft8to1%2FpWCJg" rel="nofollow" target="_blank">进一步了解 &gt;</a></li></ul><p>如果你的 Mac 不在兼容性列表，参看：<a href="https://link.segmentfault.com/?enc=4tgk4OnmJMUqt0bRcM40NA%3D%3D.l6nhdUgB7wY08S9RVpPSZWjxqJ1o1tj5VWVGjjkVUt7Aihl1v1wGZ82vuS5YkqnvYdr6IHtP%2BoUMxV6ElXhE0A%3D%3D" rel="nofollow" target="_blank">在不受支持的 Mac 上安装 macOS Sequoia (OpenCore Legacy Patcher v2.4.0)</a></p><h2>macOS Sequoia 版本历史</h2><p>Software Releases</p><ul><li>macOS Sequoia 15.7.4 (24G517) - 2026.02.11</li><li>macOS Sequoia 15.7.3 (24G419) - 2025.12.12</li><li>macOS Sequoia 15.7.2 (24G325) - 2025.11.03</li><li>macOS Sequoia 15.7.1 (24G231) - 2025.09.30</li><li>macOS Sequoia 15.7 (24G222) - 2025.09.15</li><li>macOS Sequoia 15.6.1 (24G90) - 2025.08.20</li><li>macOS Sequoia 15.6 (24G84) - 2025.07.30</li><li>macOS Sequoia 15.5 (24F74) - 2025.05.13</li><li>macOS Sequoia 15.4.1 (24E263) - 2025.04.16</li><li>macOS Sequoia 15.4 (24E248) - 2025.03.31</li><li>macOS Sequoia 15.3.2 (24D81 | 24D2082) - 2025.03.11</li><li>macOS Sequoia 15.3.1 (24D70) - 2025.02.10</li><li>macOS Sequoia 15.3 (24D60) - 2025.01.28</li><li>macOS Sequoia 15.2 (24C101) - 2024.12.11</li><li>macOS Sequoia 15.1.1 (24B91 | 24B2091) - 2024.11.19</li><li>macOS Sequoia 15.1 (24B2083) - 2024.10.30 (M4 Only)</li><li>macOS Sequoia 15.1 (24B83) - 2024.10.29</li><li>macOS Sequoia 15.0.1 (24A348) - 2024.10.03</li><li>macOS Sequoia 15.0 (24A335) - 2024.09.16</li></ul><h2>下载 macOS Sequoia</h2><p>💡 <a href="https://link.segmentfault.com/?enc=Yf0LN9U88EIw14wJ%2FV7YOg%3D%3D.nJDUmK06%2F7Sib9OogmMKoPCeYMY6%2BwjfDVjF6zQuN00%3D" rel="nofollow" target="_blank">如何校验本站下载的文件的完整性</a></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000044953906" alt="macOS Sequoia" title="macOS Sequoia" loading="lazy"/></p><h3>(1) ISO 格式软件包 (推荐)</h3><blockquote><p>本站原创可引导映像，可以在当前系统中安装或者升级，可以通过 USB 存储引导安装，也可以用于虚拟机安装。</p><p>此版本更多介绍请参看：<a href="https://link.segmentfault.com/?enc=8AL8qt2d91cxHTTlqKpQbQ%3D%3D.%2FUdYT584pqhHO%2FY0Y5jrpWh8RzBIOI5yFibMHfriocbxCuINMgu0hWsvxXT4emWi" rel="nofollow" target="_blank">macOS Sequoia 15 Boot ISO 原版可引导映像下载</a></p></blockquote><ul><li>macOS Sequoia 15.7.4 (24G517) - 2026.02.11</li><li>macOS Sequoia 15.7.3 (24G419) - 2025.12.12</li><li>macOS Sequoia 15.7.2 (24G325) - 2025.11.03</li><li>macOS Sequoia 15.7.1 (24G231) - 2025.09.30</li><li>macOS Sequoia 15.7 (24G222) - 2025.09.15</li><li>macOS Sequoia 15.6.1 (24G90) - 2025.08.20</li><li>macOS Sequoia 15.6 (24G84) - 2025.07.30</li><li>macOS Sequoia 15.5 (24F74) - 2025.05.13</li><li>macOS Sequoia 15.4.1 (24E263) - 2025.04.16</li><li>macOS Sequoia 15.4 (24E248) - 2025.03.31</li><li>macOS Sequoia 15.3.2 (24D81 | 24D2082) - 2025.03.11</li><li>macOS Sequoia 15.3.1 (24D70) - 2025.02.10</li><li>macOS Sequoia 15.3 (24D60) - 2025.01.28</li><li>macOS Sequoia 15.2 (24C101) - 2024.12.11</li><li>macOS Sequoia 15.1.1 (24B91 | 24B2091) - 2024.11.19</li><li>macOS Sequoia 15.1 (24B83) - 2024.10.29</li><li>macOS Sequoia 15.0.1 (24A348) - 2024.10.03</li><li>macOS Sequoia 15.0 (24A335) - 2024.09.16</li><li><strong>下载地址</strong>：<a href="https://link.segmentfault.com/?enc=kbxhHIWOG0qZLHzVA0v2tA%3D%3D.T8LlXYLc%2FCfSVaD1xnJruIIk9Jivqomf2P4F6qoAQLwfNGVW7BZuxqQSmWk2irAd" rel="nofollow" target="_blank">https://sysin.org/blog/macOS-Sequoia/</a></li></ul><p>参看：<a href="https://link.segmentfault.com/?enc=sw9jixIbXsS4Y4xk0YfDJg%3D%3D.edFmpA%2FjKIde1khVQk75cLD4q74Q3xFpp5f%2FHGUfV7AlYeWiBYoXKnJUS0IRuMoj" rel="nofollow" target="_blank">如何在 Mac 和虚拟机上安装 macOS Sequoia、macOS Sonoma 和 macOS Ventura</a></p><h3>(2) PKG 格式软件包</h3><blockquote>该格式软件包双击运行后将自动安装在 <code>/Applications</code> 下。</blockquote><ul><li>macOS Sequoia 15.7.4 (24G517) - 2026.02.11</li><li>macOS Sequoia 15.7.3 (24G419) - 2025.12.12</li><li>macOS Sequoia 15.7.2 (24G325) - 2025.11.03</li><li>macOS Sequoia 15.7.1 (24G231) - 2025.09.30</li><li>macOS Sequoia 15.7 (24G222) - 2025.09.15</li><li>macOS Sequoia 15.6.1 (24G90) - 2025.08.20</li><li>macOS Sequoia 15.6 (24G84) - 2025.07.30</li><li>macOS Sequoia 15.5 (24F74) - 2025.05.13</li><li>macOS Sequoia 15.4.1 (24E263) - 2025.04.16</li><li>macOS Sequoia 15.4 (24E248) - 2025.03.31</li><li>macOS Sequoia 15.3.2 (24D81 | 24D2082) - 2025.03.11</li><li>macOS Sequoia 15.3.1 (24D70) - 2025.02.10</li><li>macOS Sequoia 15.3 (24D60) - 2025.01.28</li><li>macOS Sequoia 15.2 (24C101) - 2024.12.11</li><li>macOS Sequoia 15.1.1 (24B91 | 24B2091) - 2024.11.19</li><li>macOS Sequoia 15.1 (24B2083) - 2024.10.30 (M4 Only)</li><li>macOS Sequoia 15.1 (24B83) - 2024.10.29</li><li>macOS Sequoia 15.0.1 (24A348) - 2024.10.03</li><li>macOS Sequoia 15.0 (24A335) - 2024.09.16</li><li><strong>下载地址</strong>：<a href="https://link.segmentfault.com/?enc=sin%2F18uJQ4zMLkddhF3zgw%3D%3D.whRcRT8UigT5T3RWVxguIfrNKl9yda2YexXVeKoHuWAOPxrzIiGxH%2FSbyofnlEo9" rel="nofollow" target="_blank">https://sysin.org/blog/macOS-Sequoia/</a></li></ul><h3>(3) IPSW 固件 (Apple 芯片 Mac 专用)</h3><blockquote>IPSW 格式为搭载 Apple 芯片的 Mac 专用映像，其他格式通用。</blockquote><p>适用于：<a href="https://link.segmentfault.com/?enc=%2FYtOpgL5urv9PEGhKtho3w%3D%3D.H4nrraCROz8pKZXq%2FQqm7AJDUG4izBatVRnFw%2Bc2sv0TvslbHGVNmxtl7uKZVUWN" rel="nofollow" target="_blank">搭载 Apple 芯片的 Mac 电脑</a></p><p>参看：<a href="https://link.segmentfault.com/?enc=lext976Ra1c4Fr0Gre4ENQ%3D%3D.TdXL9Lz7M%2F3ndt1e%2BlV5elAYs1erJUVjF2B4L1PY%2BKxVotYkTiERkbCuWxzRJ4Vg" rel="nofollow" target="_blank">使用 DFU 模式修复或恢复 Mac 固件</a></p><ul><li>macOS Sequoia 15.6.1 (24G90) - 2025.08.20</li><li>macOS Sequoia 15.6 (24G84) - 2025.07.30</li><li>macOS Sequoia 15.5 (24F74) - 2025.05.13</li><li>macOS Sequoia 15.4.1 (24E263) - 2025.04.16</li><li>macOS Sequoia 15.4 (24E248) - 2025.03.31</li><li>macOS Sequoia 15.3.2 (24D81 | 24D2082) - 2025.03.11</li><li>macOS Sequoia 15.3.1 (24D70) - 2025.02.10</li><li>macOS Sequoia 15.3 (24D60) - 2025.01.28</li><li>macOS Sequoia 15.2 (24C101) - 2024.12.11</li><li>macOS Sequoia 15.1.1 (24B91 | 24B2091) - 2024.11.19</li><li>macOS Sequoia 15.1 (24B2083) - 2024.10.30 (M4 Only)</li><li>macOS Sequoia 15.1 (24B83) - 2024.10.29</li><li>macOS Sequoia 15.0.1 (24A348) - 2024.10.03</li><li>macOS Sequoia 15.0 (24A335) - 2024.09.16</li><li><strong>下载地址</strong>：<a href="https://link.segmentfault.com/?enc=bzW1FVMdRHzmVtF1ankeOg%3D%3D.tRyRb%2B3MASaRT7swq5BfGyK5Ysd%2BF1%2BahARQFDPebDCyU6PkFfKJxnJOtoGKTX0H" rel="nofollow" target="_blank">https://sysin.org/blog/macOS-Sequoia/</a></li></ul><h3>(4) App Store 链接</h3><pre><code class="txt">https://apps.apple.com/app/macos-sequoia/id6596773750</code></pre><p>或者打开 App Store 搜索 “macOS Sequoia” 即可下载（下载的是当前最新版）。</p><h2>适用的 VMware 软件下载链接</h2><p>建议在以下版本的 VMware 软件中运行（Linux OVF 无需本站定制版可以正常运行，macOS 虚拟化如果不是 Mac 必须使用定制版才能运行，Windows OVF 需要定制版才能启用完整功能）：</p><ul><li><p>VMware vSphere：</p><ul><li>VMware <a href="https://link.segmentfault.com/?enc=iBK6HN%2FMIgFaSateIdo97Q%3D%3D.NiRkeP%2FXWNMETy%2F3px1z6Vgia9PyyRIfO%2F7tf%2Fq%2FK68nJQTFtCo%2B%2BNA%2B%2BWRAJULO" rel="nofollow" target="_blank">ESXi 9</a> or <a href="https://link.segmentfault.com/?enc=SnGo1BNE4u2WtVtnD8HV0w%3D%3D.qf2gqHsdXjoZV%2Bk210UOUEOT8SThn32WEOGsFavNGjg6%2FaAigkkeUO7X2r8zYMvJ" rel="nofollow" target="_blank">with driver</a> &amp; <a href="https://link.segmentfault.com/?enc=7Z48FE1aiyNYHmCsf99yMQ%3D%3D.4w3I0O6%2F7FRr6ulew3jrcFO2cu7%2F7jHZoIQWRQIBeMXR%2FYVOetg%2BOmOyLdbakcCn" rel="nofollow" target="_blank">vCenter Server 9</a> &amp; <a href="https://link.segmentfault.com/?enc=YsT560nTJrE%2BnnxuC7ET%2Fw%3D%3D.dPo%2BQy%2Fr%2BdFbvbuqdUGtF8TqFKIUA%2Fw%2FPKEC1Pg6zoQeCUygI7LIoosVIF3hYWfhQmhV5i1p8C2pTcflRccHxA%3D%3D" rel="nofollow" target="_blank">VCF Operations 9</a></li><li>VMware <a href="https://link.segmentfault.com/?enc=IX6PRrUTE0J3eclwdIfI%2BA%3D%3D.7X0KpaDJ9aqXE0qWkxBW%2Fzhshlm4xdn7nRKUl0HWaz21T0hEihSmDNNOmIyvYjgc" rel="nofollow" target="_blank">ESXi 8</a> or <a href="https://link.segmentfault.com/?enc=T8CZIv28d%2F7HluS%2Fvc6QDQ%3D%3D.gdF9p8Fh1BDit0gnfENDVBLi%2Fs9q%2FfE7s7wb%2FVJqyVOT9J%2Fe0GmWzH21YW1VeYLt" rel="nofollow" target="_blank">with driver</a> &amp; <a href="https://link.segmentfault.com/?enc=Xzw0qd2ElsyAeWZWk5onkg%3D%3D.UKZZQcZqYCZjeXgb7ct01oym%2FGnrWZaUw8T4W6%2Fd4%2BPD9zLs%2Feh%2FAIinT8ofNnLH" rel="nofollow" target="_blank">vCenter Server 8</a></li><li>VMware <a href="https://link.segmentfault.com/?enc=bS7juQmfSwrw4lR3A6O2gQ%3D%3D.oOpollgBCN5dazlyaQqIyRltg0HUBthtncOX8d5xdE9zkt%2FN%2B%2BcZBd12KDmJJAUI" rel="nofollow" target="_blank">ESXi 7</a> or <a href="https://link.segmentfault.com/?enc=BGE97qrJZRxI5xdOkD5MYw%3D%3D.oqbbv8QS8VdN1ng4AKWRWYHQLxdfSGs4Ii0G0283BSlT%2B2xsr%2BfoyBz6q7cJFOrW" rel="nofollow" target="_blank">with driver</a> &amp; <a href="https://link.segmentfault.com/?enc=C70gS9SGmg9rB8hI6%2BPVUQ%3D%3D.MVEQD%2BTGd%2B6WAOUlGVzjlQuxVfms0lALo9dVmb%2FZZ4crGzcjlCAKyQLWW2gYl2%2FB" rel="nofollow" target="_blank">vCenter Server 7</a></li></ul></li><li>macOS：<a href="https://link.segmentfault.com/?enc=Q1sFc5C6qVdZvhTNsUe1Fg%3D%3D.bQTZBUAE0smGl9Vs8N5XntyRKRyzrtHLAil7rN%2FEYjFGGDWaOj5Rblrhy%2BR5rq2k" rel="nofollow" target="_blank">VMware Fusion</a></li><li>Linux：<a href="https://link.segmentfault.com/?enc=9ADWYz6SApZSwsecMozE6A%3D%3D.SiEilgV8%2BvbpZ9xd4aE%2BY3HiWisu7xfFA65BAdbhPWneSgEdVKpqLLTnkijsJNqK%2B8vYURBOgQB5KV7FrJv4Iw%3D%3D" rel="nofollow" target="_blank">VMware Workstation for Linux</a></li><li>Windows：<a href="https://link.segmentfault.com/?enc=tQDIwt%2F%2FqTBzBNWxg0OYhA%3D%3D.JjT9he%2BO%2Fkjn8e3LbdZ68gkcbyQbEGETJbONU1CE22PdDKM5AQDlAoZWV%2F3mGBu3vrkR7OKCtjk0Udscn781%2Bg%3D%3D" rel="nofollow" target="_blank">VMware Workstation for Windows</a></li></ul><p>macOS Sequoia 虚拟化解决方案，请参看：<a href="https://link.segmentfault.com/?enc=BhA2tcBWjvC6lmpCv2K%2FeA%3D%3D.VHIJwdz9ibCW4O2KPnUUSJ6YRadCsgncKMIibe5qixF1E4iJda0YxodzZw3doTtP" rel="nofollow" target="_blank">macOS 15 Blank OVF - macOS Sequoia 虚拟化解决方案</a></p><h2>如何创建可引导的 macOS 安装器</h2><p>请访问：<a href="https://link.segmentfault.com/?enc=LnYwia5MOswd6qelQkXPSQ%3D%3D.nFPKmZR9JGCQ6hIwLy8WHW8T6DTMvMWgaDGUmRkWn3j%2FMAIgNU93ZCraPQVG%2F%2B8tjHAZiq07HZh45I5fZ%2FdJEw%3D%3D" rel="nofollow" target="_blank">如何创建可引导的 macOS 安装介质</a></p><p>更多：<a href="https://link.segmentfault.com/?enc=ic3RqY6pWVc6ntMV6AGUQg%3D%3D.G741F3%2BbCBQK4fqJnDjE3tvqrsKKmsGCAsnbCqLttOs%3D" rel="nofollow" target="_blank">macOS 下载汇总 (系统、应用和教程)</a></p>]]></description></item><item>    <title><![CDATA[7z2105 安装步骤详解（附压缩解压与文件关联设置） 小童童 ]]></title>    <link>https://segmentfault.com/a/1190000047608724</link>    <guid>https://segmentfault.com/a/1190000047608724</guid>    <pubDate>2026-02-13 10:06:14</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>​</p><p><code>7z2105(64位）</code>是 <strong>7-Zip 21.05 版本的 64 位安装包</strong>，这是个压缩解压工具，能打包成 7z、zip、rar 等格式，压缩率高、速度也快，解压大文件比系统自带的 winrar/压缩功能稳很多。</p><h2>一、准备工作</h2><ol><li><p><strong>下载安装包</strong>​</p><ul><li><strong>安装包下载：</strong><a href="https://link.segmentfault.com/?enc=GKLn24029Uf6WG2vcCh1og%3D%3D.RFJ8BQaG%2FyZ32YTeGOqkICF6amEI7%2Fm7hzovc7VweyOTY5okVNLecHpwz4eC%2BYp0" rel="nofollow" title="https://pan.quark.cn/s/67c246cb79fc" target="_blank">https://pan.quark.cn/s/67c246cb79fc</a></li><li>文件名里的 “2105” 是版本号，“64位” 对应 64 位 Windows 系统（现在电脑基本都是 64 位）。</li></ul></li><li><p><strong>确认系统版本</strong>​</p><ul><li>必须是 64 位 Windows（Win7/Win10/Win11 都行），32 位系统要用 32 位安装包。</li></ul></li><li><p><strong>用管理员身份运行（推荐）</strong> ​</p><ul><li>右键安装包 → 选“以管理员身份运行”，防止权限不足装不上。</li></ul></li></ol><h2>二、安装步骤</h2><ol><li>双击 <code>7z2105(64位）.exe</code>运行（如果右键过了就直接双击）。</li><li>第一次打开会弹出“用户账户控制”提示 → 点  <strong>“是”</strong> 。</li><li>进入安装向导，选语言（默认 English，有的版本有中文）→ 点  <strong>“OK”</strong> 。</li><li>阅读许可协议 → 选 “I Agree” → 点  <strong>“Next”</strong> 。</li><li><p>选安装类型：</p><ul><li>默认是 “Install” 直接装到默认位置（<code>C:\Program Files\7-Zip</code>），新手直接点  <strong>“Install”</strong> ​ 就行；</li><li>想自己选位置就点 “Browse” 改路径（比如 D 盘）。</li></ul></li><li><p>选关联文件类型（重要）：</p><ul><li>建议勾上常用的：<code>.7z</code>、<code>.zip</code>、<code>.rar</code>、<code>.tar</code>等，这样以后双击这些格式的文件会用 7-Zip 打开。</li></ul></li><li>点  <strong>“Finish”</strong> ​ 完成安装。</li></ol><h2>三、首次使用与基本操作</h2><ol><li>安装完，右键任意文件或文件夹，会看到多出 “7-Zip” 菜单。</li><li><strong>压缩</strong>：右键文件 → 7-Zip → “添加到压缩包” → 选格式（7z 压缩率高，zip 兼容性好）→ 点 “确定”。</li><li><strong>解压</strong>：右键压缩包 → 7-Zip → “解压到当前文件夹” 或 “解压到 xxx\”（自动建同名文件夹）。</li><li><strong>查看压缩包内容</strong>：右键压缩包 → 7-Zip → “打开压缩包”，不用完全解压就能看里面的文件。</li></ol><p>​</p>]]></description></item><item>    <title><![CDATA[虚拟办公室Gather重组：AI团队并入Figma；蚂蚁开源Ming-Flash-Omni 2.0：]]></title>    <link>https://segmentfault.com/a/1190000047608713</link>    <guid>https://segmentfault.com/a/1190000047608713</guid>    <pubDate>2026-02-13 10:05:19</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608715" alt="" title=""/></p><p><strong>开发者朋友们大家好：</strong></p><p>这里是 <strong>「RTE 开发者日报」</strong>，每天和大家一起看新闻、聊八卦。我们的社区编辑团队会整理分享 RTE（Real-Time Engagement） 领域内「有话题的<strong>技术</strong>」、「有亮点的<strong>产品</strong>」、「有思考的<strong>文章</strong>」、「有态度的<strong>观点</strong>」、「有看点的<strong>活动</strong>」，但内容仅代表编辑的个人观点，欢迎大家留言、跟帖、讨论。</p><p><em>本期编辑：@瓒an、@鲍勃</em></p><h2>01 有话题的技术</h2><p><strong>1、MOSS-TTS 亮相，支持精细发音控制与长音频生成，打造生产级语音基础模型</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608716" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608717" alt="" title="" loading="lazy"/></p><p>模思智能及 OpenMOSS 团队近日正式发布并开源了 MOSS-TTS Family 语音生成模型家族。这套工具链并未追求单一模型能力的堆叠，而是针对真实创作与交互需求，将语音生成拆解为五个核心模块：</p><ul><li><strong>MOSS-TTS</strong>：作为高保真语音生成基座，支持多语言、长音频及精确时长控制，在 Seed-TTS-eval 测试集上的音色相似度表现优异，可用于纪录片配音等场景。</li><li><strong>MOSS-TTSD</strong>：升级至 1.0 版本，专注于多说话人对话生成，支持 1-5 人自然对话节奏及最长 60 分钟的长对话，适用于播客、解说等复杂场景。</li><li><strong>MOSS-VoiceGenerator</strong>：通过指令设计音色与角色，实现情绪表达与表演状态的模拟。</li><li><strong>MOSS-SoundEffect</strong>：根据文本描述生成环境音与音效，补全声音场景。</li><li><strong>MOSS-TTS-Realtime</strong>：面向实时交互系统的流式 TTS 模型，低延迟特性适配语音助手等应用。</li></ul><p>技术层面，MOSS-TTS Family 基于高质量 Audio Tokenizer、大规模多样化数据及高效离散 Token 建模方法。其中，MOSS Audio Tokenizer 采用 1.6B 参数的纯 Transformer 架构，实现了高压缩比与语义-声学统一表征。<strong>为兼顾生产落地与学术研究，团队同时开源了两套互补架构：适合长文本生成与规模化部署的 Delay-Pattern (MossTTSDelay)，以及适配流式交互的 Global Latent + Local Transformer (MossTTSLocal)。</strong></p><p>此外，MOSS-TTS 系列已实现对壁仞科技壁砺™ 166M 的 Day-0 高性能推理支持，展现了对国产算力生态的兼容性。该模型家族的发布，试图通过覆盖<strong>「稳定生成、灵活设计、复杂对话、情境补全、实时交互」</strong>的全维度能力，为行业提供一套可直接接入工作流的声音创作生态闭环。</p><p>相关链接：<br/><a href="https://link.segmentfault.com/?enc=FS%2BZGiTYBd%2FFb1%2B%2FlQy%2BLQ%3D%3D.iZBxvZCTKaDByl0r665%2FO1Tm5m9S5zoogsYOe%2FQRcvw%3D" rel="nofollow" target="_blank">https://mosi.cn/models/moss-tts</a></p><p>GitHub: <br/><a href="https://link.segmentfault.com/?enc=m1wwFm5pIKiFEDtp072YMQ%3D%3D.K7NFv%2FbbPFyqAu1Nm2ZLhOndTejnAFK4d3TAN8LjYiCYiUrpyfdNycsfz25r3oAA" rel="nofollow" target="_blank">https://github.com/OpenMOSS/MOSS-TTS</a></p><p>( @机器之心 )</p><p><strong>2、智谱上线全新模型 GLM-5</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608718" alt="" title="" loading="lazy"/></p><p>刚刚，智谱正式上线并开源最新模型 GLM-5。</p><p>据介绍，GLM-5 是迈向 Agentic Engineering 的产物：在 Coding 与 Agent 能力上，其取得开源 SOTA 表现，在真实编程场景的使用体感逼近 Claude Opus 4.5，擅长复杂系统工程与长程 Agent 任务。</p><p>GLM-5 采用全新基座：<strong>参数规模从 355B（激活 32B）扩展至 744B（激活 40B），预训练数据从 23T 提升至 28.5T</strong>；构建全新的「Slime」框架，支持更大模型规模及更复杂的强化学习任务。</p><p>同时，<strong>GLM-5 还首次集成 DeepSeek Sparse Attention（稀疏注意力）</strong>，在维持长文本效果无损的同时，大幅降低模型部署成本。</p><p>具体表现上：</p><ul><li>在全球权威的 Artificial Analysis 榜单中，GLM-5 位居全球第四、开源第一。</li><li>GLM-5 在编程能力上实现了对齐 Claude Opus 4.5，在业内公认的主流基准测试中取得开源模型 SOTA。</li><li>GLM-5 在 SWE-bench-Verified 和 Terminal Bench 2.0 中分别获得 77.8 和 56.2 的开源模型最高分数，性能超过 Gemini 3 Pro。</li><li>GLM-5 在 BrowseComp（联网检索与信息理解）、MCP-Atlas（大规模端到端工具调用）和 τ²-Bench（复杂场景下自动代理的工具规划和执行）均取得最高表现。</li></ul><p>值得一提的是，目前 GLM-5 已完成与华为昇腾、摩尔线程、寒武纪、昆仑芯、沐曦、燧原、海光等国产算力平台的深度推理适配。通过底层算子优化与硬件加速，GLM-5 在国产芯片集群上已经实现高吞吐、低延迟的稳定运行。</p><p>即日起，GLM-5 在 Hugging Face 与 ModelScope 平台同步开源，模型权重遵循 MIT License。同时 GLM-5 已纳入 GLM Coding Plan Max 套餐。</p><p>GitHub: <br/><a href="https://link.segmentfault.com/?enc=n6gLm9WrxMuei%2FMg3lObyw%3D%3D.tL0H%2BVQ7rYrL1bGPuaHo6BU9oauUQyBSZebrmNrdrAEroB%2BMquosg5YU3M%2F%2Fd1Lp" rel="nofollow" target="_blank">https://github.com/zai-org/GLM-5</a></p><p>Hugging Face: <br/><a href="https://link.segmentfault.com/?enc=yjXXhC2%2Bn%2BcLhyIh5XaQqA%3D%3D.zBNIoG37ldvBnCcJNg0BsVfPSlceN%2BQec7qEKX%2BDRfjtJU25%2Bmql4Mhf9AuKOv3q" rel="nofollow" target="_blank">https://huggingface.co/zai-org/GLM-5</a></p><p>( @APPSO)</p><p><strong>3、蚂蚁开源全模态大模型 Ming-Flash-Omni 2.0</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608719" alt="" title="" loading="lazy"/></p><p>2 月 11 日，蚂蚁集团开源发布全模态大模型 Ming-Flash-Omni 2.0。</p><p>在多项公开基准测试中，Ming-Flash-Omni 2.0 在视觉语言理解、语音可控生成、图像生成与编辑等关键能力表现突出，部分指标超越 Gemini 2.5 Pro，成为开源全模态大模型性能新标杆。</p><p>据悉，Ming-Flash-Omni 2.0 也是<strong>业界首个全场景音频统一生成模型</strong>，可在同一条音轨中同时生成语音、环境音效与音乐。用户只需用自然语言下指令，即可对音色、语速、语调、音量、情绪与方言等进行精细控制。</p><p>模型在推理阶段实现了 3.1Hz 的极低推理帧率，实现了分钟级长音频的实时高保真生成，在推理效率与成本控制上保持业界领先。</p><p>值得一提的是，Ming-Flash-Omni 2.0 基于 Ling-2.0 架构（MoE，100B-A6B）训练，<strong>围绕「看得更准、听得更细、生成更稳」三大目标全面优化</strong>。</p><p>目前，Ming-Flash-Omni 2.0 的模型权重、推理代码已在 Hugging Face 等开源社区发布。用户也可通过蚂蚁百灵官方平台 Ling Studio 在线体验与调用。</p><p>Hugging Face：<br/><a href="https://link.segmentfault.com/?enc=MpJ%2F3zO2DC8MfR3nQ27LYw%3D%3D.oCLX9o1UWCnhix5XMD329TtiMcsoG14IXtBYywzB3f1hryBDA7oJWX9FQhWj8olz%2BY8b0sq%2FwQnDz5IqNE%2F1Aw%3D%3D" rel="nofollow" target="_blank">https://huggingface.co/inclusionAI/Ming-flash-omni-2.0</a></p><p>GitHub：<br/><a href="https://link.segmentfault.com/?enc=mUnD9FULMzQsgE8%2FLc0F7w%3D%3D.9whVXsmLs1xP%2FGRhJ4lhCQi1lGZJ50305c%2FrEiPo2d94zPcpEzFJUBaI%2FtDuodCx" rel="nofollow" target="_blank">https://github.com/inclusionAI/Ming</a></p><p>( @APPSO)</p><p><strong>4、Rokid Glasses 上线「自定义智能体」：支持接入 OpenClaw 与 DeepSeek 等私有大模型</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608720" alt="" title="" loading="lazy"/></p><p>Rokid 宣布其灵珠平台正式上线「自定义智能体」功能，允许 Rokid Glasses 用户通过标准的 SSE 接口，接入自定义后端服务。<strong>这一更新回应了极客用户对于接入私有大模型、本地 NAS 运行 AI 以及调用自定义 Python 脚本的需求，标志着该产品开始将 AI 助手的定义权交还给用户。</strong></p><p>此次更新打破了厂商定义能力的传统模式，支持接入包括开源社区热门的 OpenClaw 框架，以及 DeepSeek R1、Qwen3、Kimi K2.5 等私有部署模型。通过这种开放策略，Rokid Glasses 试图构建一种硬件负责感知（看与听）、后台负责思考与执行的 AR 形态。</p><p>接入自定义智能体（如 OpenClaw）为用户带来了三个维度的能力提升：</p><ul><li><strong>数据主权与隐私保护</strong>：通过接入运行在 Mac Mini 或家庭服务器上的本地 Agent，摄像头画面与私有知识库可实现本地闭环处理，无需数据上云。</li><li><strong>执行能力的扩展</strong>：区别于仅能对话的传统模型，OpenClaw 结合 ClawHub 技能生态，具备调用文件系统、操作浏览器、发送消息甚至执行 Python 脚本的行动力。</li><li><strong>模型基座的自由切换</strong>：用户可根据需求灵活切换后端模型，例如调用 Kimi K2.5 处理复杂推理，或使用本地量化版 Qwen 3 进行端侧交互。</li></ul><p>在具体部署方面，开发者需在 Rokid 开放平台注册并完成实名认证，随后在灵珠平台创建智能体并配置 URL 与鉴权信息。<strong>针对仅限个人使用的智能体，官方提示无需提交审核，直接通过个人账号调用即可，以避免误触提审流程。</strong></p><p><strong>鉴于接入门槛较高且涉及网络安全</strong>，Rokid 建议开发者使用阿里云或腾讯云等云服务器部署 OpenClaw，而不推荐在本地私人电脑使用内网穿透工具。配置完成后，用户可在 Rokid AI App 中调试，并通过眼镜端的语音指令或快捷指令唤起私有智能体。</p><p>灵珠平台：<br/><a href="https://link.segmentfault.com/?enc=sfsE8ThaALT0gmZs2zIUPg%3D%3D.ukX%2FIA4CKQ9f1BZ0La4v7rYCg6%2FAM5HBn%2FEkiFvv3EM%3D" rel="nofollow" target="_blank">https://ar.rokid.com/</a></p><p>GitHub: <br/><a href="https://link.segmentfault.com/?enc=ThmUWFYOrVXHbpsqb8ICww%3D%3D.kc8hTefSil6c3f96h3cu5Nc5e4R8RSbNvc9JpFxBuW9lgyuVe%2FII0DZJ3IWSQfq%2F" rel="nofollow" target="_blank">https://github.com/openclaw/openclaw</a></p><p>（@Rikid 乐奇、@IT 之家）</p><h2>02 有亮点的产品</h2><p><strong>1、Gather 宣布重组：AI 团队并入 Figma，核心业务转型独立盈利模式</strong></p><p>2026 年 2 月 9 日，Gather 发布了关于公司未来的战略更新。自成立以来，Gather 一直致力于通过「虚拟办公室」消除机会与连接的物理障碍，目前该产品已实现盈利并持续增长，服务于全球数千家企业。然而，公司管理层经过评估后认为，尽管现有产品具有长期价值和可持续性，但已不再符合最初设想的风投级增长模式。</p><p>为了确保核心使命的延续，Gather 宣布将采取两项关键举措来进行重组：</p><ul><li><strong>转型为独立企业</strong>：Gather 将剥离为一家独立的、非风投支持的实体，作为一家专注且盈利的中小企业运营。这一转变使公司能够摆脱对十亿美元级估值的追逐压力，转而全心全意服务核心客户，并开发用户真正期待的功能（例如「办公室宠物」功能的回归）。许多资深团队成员将留任，继续推动产品的开发与创新。</li><li><strong>AI 团队加入 Figma</strong>：Gather 的 AI 团队已达成协议加入 Figma。过去一年中，该团队一直在探索如何提升软件设计与构建工作的愉悦感和效率。在此过程中，他们发现与 Figma 团队在愿景和价值观上高度契合，因此决定加入 Figma 以继续推进这一领域的工作。</li></ul><p>对于现有客户，Gather 承诺服务将不会发生任何变化。转型为独立业务后，团队将拥有更大的自由度来响应那些长期存在的用户需求，并继续保持其一贯的创新精神。此次调整被视为 Gather 回归初心的举措，使其能以更专注的方式在远程协作领域发挥所长。</p><p>( @Gather Blog)</p><p><strong>2、Willow 发布开发者语音工具，支持 Cursor、Antigravity 等主流 AI IDE</strong></p><p>2026 年 2 月 12 日，Willow 正式推出了面向开发者的语音听写工具「Willow for Developers」，该工具专为 Vibe Coding 工作流打造。针对 Andrej Karpathy 曾提出的「英语是目前最热门的新编程语言」这一观点，Willow 将传统的键盘输入视为开发过程中的瓶颈，并试图通过语音交互来消除这一障碍。</p><p>该工具的核心逻辑建立在说话与打字的速度差异之上。Willow 指出，人类的平均语速约为每分钟 200 个单词，而打字速度仅为每分钟 60 个单词。通过口述提示词，开发者能够比打字时更自然地提供丰富的细节和上下文信息。在 AI 辅助开发的语境下，这种高密度的上下文输入有助于 AI IDE 生成质量更高的代码。</p><p>在具体功能层面，Willow 针对编程场景进行了多项优化：</p><ul><li><strong>智能文件识别与标签化</strong>：工具支持 Cursor、Antigravity 等主流 AI IDE。当用户口述如「更新 navbar.tsx 中的标题栏」等指令时，Willow 能自动识别项目中的特定文件，并自动添加相应的引用标签（如 @ 标签），无需开发者手动标记。</li><li><strong>技术术语精准听写</strong>：区别于普通语音输入，Willow 具备代码上下文感知能力。它能够准确拼写特定的变量名称（例如「userAuthToken」），并开箱即用地识别 SQL、GraphQL、OAuth 等技术术语，确保拼写无误。</li></ul><p>相关链接：<br/><a href="https://link.segmentfault.com/?enc=vCo9mPBkRQCzzVxhR%2F1uTw%3D%3D.4%2Be2T55Vct1%2FEFjwRWsZv1tsi3AQq7wYS4Ul%2FESFZk8%3D" rel="nofollow" target="_blank">https://willowvoice.com/</a></p><p>( @WillowVoiceAI\@X)</p><p><strong>3、Simple AI 完成 1400 万美元种子轮融资：First Harmonic 领投，打造转化率超人工 30% 的语音智能体</strong></p><p>语音 AI 智能体平台 Simple AI 于 2026 年 2 月 10 日宣布完成 1400 万美元种子轮融资，由 First Harmonic 领投，Y Combinator 等机构跟投。资金将用于开发语音智能体平台、构建定制生成式 AI 模型及商业分析工具。</p><p>Simple AI 的核心业务是利用语音 AI 自动化处理销售与支持来电。平台可导入企业完整产品目录（含 SKU 及定价），在通话中调用实时客户数据进行个性化互动，并执行下单等操作，同时生成通话记录与分析报告。技术上，该平台宣称将全链路延迟控制在 850 毫秒以内，涵盖语音检测到文本转语音的全流程，以确保对话自然流畅。</p><p>该技术试图解决呼叫中心的三大挑战：</p><ul><li><strong>应对波动</strong>：在业务高峰期自动扩展接待能力。</li><li><strong>提升效率</strong>：学习顶尖销售代表经验，避免人工效率起伏。</li><li><strong>保持一致性</strong>：维持人类难以企及的服务稳定性。</li></ul><p>平台还提供实验工具，支持调整 AI 智能体的语速、性别和口音。联合创始人 Catheryn Li 表示，优质的语音智能体能改善通话体验；CTO Zach Kamran 则指出，智能体能瞬间掌握所有产品细节。数据显示，其 AI 智能体在牛排销售、保险等领域的转化率比人工客服高出 30%。</p><p>投资方 First Harmonic 评价称，团队并未依赖现有方案，而是从零构建了完整的语音 AI 技术栈。两位创始人相识于 Y Combinator，在接触大语言模型早期研究后，决定将其应用于语音领域。</p><p>( @BusinessWire)</p><h2>03 有态度的观点</h2><p><strong>1、AI 非但未减负，反而加剧职场倦怠</strong></p><p>据 Techcrunch 报道，如今美国职场文化中最具诱惑力的说法，并非人工智能会抢走你的工作，而是它能把你从繁重的工作中解脱出来。</p><p>过去三年里，科技行业一直在向数百万焦虑不安的人兜售这一理念，而人们也迫切愿意相信。诚然，部分白领岗位将会消失。但该观点声称，对大多数其他职位而言，人工智能是能力放大器。工具为你所用，你不用再拼命工作，人人都是赢家。</p><p>但《哈佛商业评论》（Harvard Business Review）新近发表的一项研究，顺着这一前提推导得出了真实结论：研究发现的并非一场生产力革命，而是企业有可能变成让人精疲力竭的机器。</p><p>加州大学伯克利分校的研究团队在一家 200 人规模的科技公司进行了为期八个月的实地观察。研究发现，尽管公司管理层并未施加额外压力或设定新业绩目标，员工在深度接纳 AI 后，工作状态却发生了微妙变化。仅仅因为工具提升了可行性，员工便主动承担更多任务，导致工作逐渐侵占午休时间甚至蔓延至深夜。AI 节省出的每一小时，迅速被不断膨胀的待办事项填满。一位工程师在访谈中坦言，原本期望的高效率能带来闲暇，现实却是工作量不降反增。</p><p>此前已有数据佐证了类似迹象：去年夏天的实验显示，资深开发者使用 AI 后实际耗时增加 19%，尽管其自我感觉效率提升了 20%；美国国家经济研究局的数据也表明，AI 带来的生产力提升仅相当于节省 3% 的时间。</p><p>与上述研究不同，这项新研究并未质疑 AI 对个人能力的提升作用，而是揭示了这种提升的副作用。研究指出，随着组织对响应速度和工作效率的要求水涨船高，技术赋能最终导向了疲劳、职业倦怠以及强烈的「无法抽身感」。科技行业寄希望于通过「做更多事」来解决问题，但这或许正是新问题的开端。</p><p>（@IT 之家）</p><h2>04 社区黑板报</h2><p>招聘、项目分享、求助……任何你想和社区分享的信息，请联系我们投稿。（加微信 creators2022，备注「社区黑板报」）</p><p><strong>1、招聘工程研发、算法、产运等岗位</strong></p><p>来自社区开发者 Polande：</p><p><strong>招聘岗位（北京）</strong></p><p>1.工程研发/Agent 研发</p><p>2.语音算法</p><p>3.产品运营、用户增长</p><p>4.AI 创新独立小团队（3 人）<em>*</em>*</p><p><strong>期望：</strong>热爱 AI、了解 AI、了解 SaaS、能够用 AI 在工作中实质的提效落地。</p><p><strong>关于公司</strong></p><p>1.方向是做语音对话的 SaaS -&gt; Agent 平台产品</p><p>2.上市公司内的创业团队，当前 30 人，26 年控制在 50 人左右（创业氛围，暂时不需要融资</p><p>3.产品：0.7 阶段</p><p><strong>关于我</strong></p><p>原先在百度和现在团队一直是做 AI 商业化方向，接近小十年的智能语音交互，但是现在还是有很多事情会感觉到兴奋。</p><p>有意向可以联系 polandeme\@gmail.com</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608721" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608722" alt="" title="" loading="lazy"/></p><p><strong>写在最后：</strong></p><p>我们欢迎更多的小伙伴参与 <strong>「RTE 开发者日报」</strong> 内容的共创，感兴趣的朋友请通过开发者社区或公众号留言联系，记得报暗号「共创」。</p><p>对于任何反馈（包括但不限于内容上、形式上）我们不胜感激、并有小惊喜回馈，例如你希望从日报中看到哪些内容；自己推荐的信源、项目、话题、活动等；或者列举几个你喜欢看、平时常看的内容渠道；内容排版或呈现形式上有哪些可以改进的地方等。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608723" alt="" title="" loading="lazy"/></p><p>作者提示: 个人观点，仅供参考</p>]]></description></item><item>    <title><![CDATA[macOS Sonoma 14.8.4 (23J319) 正式版 ISO、IPSW、PKG 下载 s]]></title>    <link>https://segmentfault.com/a/1190000047608740</link>    <guid>https://segmentfault.com/a/1190000047608740</guid>    <pubDate>2026-02-13 10:04:38</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>macOS Sonoma 14.8.4 (23J319) 正式版 ISO、IPSW、PKG 下载</p><p>利用小组件进行个性化设置、令人眼前一亮的全新屏幕保护、Safari 浏览器和视频会议的重大更新</p><p>请访问原文链接：<a href="https://link.segmentfault.com/?enc=g7kxlKKsfeFLu0vT5i6tpA%3D%3D.hJ9VoChxWjPi4sG7jEATinSFwZyJUcwouZZpUmXAo8Ts60EE9hqIHAGM7rhyYZBA" rel="nofollow" target="_blank">https://sysin.org/blog/macOS-Sonoma/</a> 查看最新版。原创作品，转载请保留出处。</p><p>作者主页：<a href="https://link.segmentfault.com/?enc=Q3F1r3UReuloODxfkpUPrA%3D%3D.X%2BUzN11vXKYBsnI971J4%2B1zmwQWY67MofNjqRkx1BXc%3D" rel="nofollow" target="_blank">sysin.org</a></p><hr/><p>2026 年 2 月 12 日凌晨，Apple 发布 iOS/iPadOS/macOS/watchOS/tvOS/visonOS 全平台 26.3 版本更新。macOS Tahoe 26.3 此次为常规问题修复和安全更新。同时为不能更新最新系统的 Mac 发布了 macOS Sequoia 15.7.4 和 macOS Sonoma 14.8.4 软件更新，此类更新通常为安全修复和常规问题修复。<br/>macOS Sonoma 推出全新功能，全面提升生产力和创意工作流</p><p>macOS Sonoma 推出全新功能，全面提升生产力和创意工作流</p><p>隆重推出更多利用小组件进行个性化设置的方式、令人眼前一亮的全新屏幕保护、Safari 浏览器和视频会议的重大更新，以及经优化的游戏体验——Tim Cook 让 Mac 体验远胜以往。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000046099654" alt="MacBook Air、27 英寸 iMac 和 MacBook Pro 上的 macOS Sonoma。" title="MacBook Air、27 英寸 iMac 和 MacBook Pro 上的 macOS Sonoma。"/></p><p><em>macOS Sonoma 让 Mac 体验远胜以往——从更多利用小组件进行个性化设置的方式，到 Safari 浏览器和视频会议的重大更新，更有众多精彩新游戏登陆。</em></p><h2>macOS Sonoma 更新摘要</h2><p>macOS Sonoma 14.8 及更新版本，如无特殊说明皆为安全更新或常规错误修复，不再赘述。</p><h2>macOS Sonoma 硬件兼容性列表</h2><p>看看你的 Mac 是否能用 macOS Sonoma</p><p>​      <a href="https://link.segmentfault.com/?enc=%2BR3pc%2B5yt1bQ2eJpx2gEnQ%3D%3D.TSRrYVrvB7QsdcX07Z%2B4UMvjk4qOfuKnEn%2FRaSvi4ww%3D" rel="nofollow" target="_blank">进一步了解 Mac&gt;</a></p><ul><li>MacBook Air 2018 and later <a href="https://link.segmentfault.com/?enc=RKjnT0z2p0WfZwu7oJfYiw%3D%3D.Ts3e4mcM8sh6uB8PBNy5tkYVIfMNeCnqJbPF4jHhmpURCbzog2VzKsRotv5DmzMt" rel="nofollow" target="_blank">进一步了解</a></li><li>MacBook Pro 2018 and later <a href="https://link.segmentfault.com/?enc=NKPSREgVZ5cDMMIVmw3Yhg%3D%3D.tjvxgj8rXATyhgy4KEeGo%2FazADrVH3Qw8YehfG%2F8AEEf4lciKqCOfsWSasptoCd4" rel="nofollow" target="_blank">进一步了解</a></li><li>Mac mini 2018 and later <a href="https://link.segmentfault.com/?enc=wRj5WwD%2BCNQ7NmJm%2F9rrhA%3D%3D.aIRc4c7ecCWeSbN5EhDZtuVegTRBDGNN8shJfMMBCM%2FLR7m%2FFAwESSj950X%2BG1QU" rel="nofollow" target="_blank">进一步了解</a></li><li>Mac Studio 2022 and later <a href="https://link.segmentfault.com/?enc=i2odx%2FKKkVbsgZL%2FXkdPDQ%3D%3D.kxobFMGI7g8O9QACmr44OeEZYpf7ksFJCZyuM8nVKpdMYwhlvLaprJghf%2Fx7N4%2Fx" rel="nofollow" target="_blank">进一步了解</a></li><li>Mac Pro 2019 and later <a href="https://link.segmentfault.com/?enc=H3TNqSf47oYj41D%2B0zAWsA%3D%3D.ZQDDeSZK4FxHmN2qO7%2Bo2Sf0SyWfxr7lq0mXnfEjkcNv%2FP0IAkMYvZbo62LXshFv" rel="nofollow" target="_blank">进一步了解</a></li><li>iMac 2019 and later <a href="https://link.segmentfault.com/?enc=Hm4jvuEMkwXJoTHHSixCzQ%3D%3D.NYLiriehOxXcy9ARH5Dnjr%2FThR088wUNQl6jCqqsmnZFS4zCC4rdEfkL7l%2FXtwps" rel="nofollow" target="_blank">进一步了解</a></li><li>iMac Pro 2017 <a href="https://link.segmentfault.com/?enc=rpxUdVvZpFOuV2o8biFAWA%3D%3D.w5oFgBxZFnggU1GvzL%2FWUN7T4bHauA5PfLkIPWtQQepN1ZlsVK0hGtvEUuw%2BK5Tn" rel="nofollow" target="_blank">进一步了解</a></li></ul><p>如果你的 Mac 不在兼容性列表，参看：<a href="https://link.segmentfault.com/?enc=rfF0di9RLmwayXjeI3j3Cg%3D%3D.o4zEtfcYAM5HCVCGqlPj9QR4vguRet%2BLfFiJSIvWKK6vKpChglUz6vaYb%2BhO5ohPhfYE4soKFw9mhCNSYb%2FwFQ%3D%3D" rel="nofollow" target="_blank">在不受支持的 Mac 上安装 macOS Sonoma (OpenCore Legacy Patcher v1.5.0)</a></p><h2>macOS Sonoma 版本历史</h2><p>Software Releases</p><ul><li>macOS Sonoma 14.8.4 (23J319) - 2026.02.11</li><li>macOS Sonoma 14.8.3 (23J220) - 2025.12.12</li><li>macOS Sonoma 14.8.2 (23J126) - 2025.11.03</li><li>macOS Sonoma 14.8.1 (23J30) - 2025.09.30</li><li>macOS Sonoma 14.8 (23J21) - 2025.09.15</li><li>macOS Sonoma 14.7.8 (23H730) - 2025.08.20</li><li>macOS Sonoma 14.7.7 (23H723) - 2025.07.30</li><li>macOS Sonoma 14.7.6 (23H626) - 2025.05.12</li><li>macOS Sonoma 14.7.5 (23H527) - 2025.03.31</li><li>macOS Sonoma 14.7.4 (23H420) - 2025.02.10</li><li>macOS Sonoma 14.7.3 (23H417) - 2025.01.28</li><li>macOS Sonoma 14.7.2 (23H311) - 2024.12.11</li><li>macOS Sonoma 14.7.1 (23H222) - 2024.10.28</li><li>macOS Sonoma 14.7 (23H124) - 2024.09.16</li><li>macOS Sonoma 14.6.1 (23G93) - 2024.08.07</li><li>macOS Sonoma 14.6 (23G80) - 2024.07.29</li><li>macOS Sonoma 14.5 (23F79) - 2024.05.13</li><li>macOS Sonoma 14.4.1 (23E224) - 2024.03.25</li><li>macOS Sonoma 14.4 (23E214) - 2024.03.07</li><li>macOS Sonoma 14.3.1 (23D60) - 2024.02.08</li><li>macOS Sonoma 14.3 (23D56) - 2024.01.22</li><li>macOS Sonoma 14.2.1 (23C71) - 2023.12.19</li><li>macOS Sonoma 14.2 (23C64) - 2023.12.11</li><li>macOS Sonoma 14.1.2 (23B92 | 23B2091) - 2023.11.30</li><li>macOS Sonoma 14.1.1 (23B81 | 23B2082) - 2023.11.07</li><li>macOS Sonoma 14.1 (23B74) - 2023.10.25</li><li>macOS Sonoma 14 (23A344) Release - 2023.09.26</li></ul><h2>下载 macOS Sonoma</h2><p>💡 <a href="https://link.segmentfault.com/?enc=zz6oXuaYOT3ZBm7Jla4K0g%3D%3D.CP94TzyDdkIGLolrugfCdCK7CM2VRyaQZk6MQeL9wnk%3D" rel="nofollow" target="_blank">如何校验本站下载的文件的完整性</a></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000046099662" alt="macOS Sonoma" title="macOS Sonoma" loading="lazy"/></p><h3>(1) ISO 格式软件包 (推荐)</h3><blockquote><p>本站原创可引导映像，可以在当前系统中安装或者升级，可以通过 USB 存储引导安装，也可以用于虚拟机安装。</p><p>此版本更多介绍请参看：<a href="https://link.segmentfault.com/?enc=ObONYxtqWezC4EcHcZAYeQ%3D%3D.GDED3pXM%2FsT8I2LycrAo1cBxxRoHyLmhjzPatdhFCqY3WUNcHZw6Fy6Mxaoxm%2FV6" rel="nofollow" target="_blank">macOS Sonoma 14 Boot ISO 原版可引导映像下载</a></p></blockquote><ul><li>macOS Sonoma 14.8.4 (23J319) - 2026.02.11</li><li>macOS Sonoma 14.8.3 (23J220) - 2025.12.12</li><li>macOS Sonoma 14.8.2 (23J126) - 2025.11.03</li><li>macOS Sonoma 14.8.1 (23J30) - 2025.09.30</li><li>macOS Sonoma 14.8 (23J21) - 2025.09.15</li><li>macOS Sonoma 14.7.8 (23H730) - 2025.08.20</li><li>macOS Sonoma 14.7.7 (23H723) - 2025.07.30</li><li>macOS Sonoma 14.7.6 (23H626) - 2025.05.12</li><li>macOS Sonoma 14.7.5 (23H527) - 2025.03.31</li><li>macOS Sonoma 14.7.4 (23H420) - 2025.02.10</li><li>macOS Sonoma 14.7.3 (23H417) - 2025.01.28</li><li>macOS Sonoma 14.7.2 (23H311) - 2024.12.11</li><li>macOS Sonoma 14.7.1 (23H222) - 2024.10.28</li><li>macOS Sonoma 14.7 (23H124) - 2024.09.16</li><li>macOS Sonoma 14.6.1 (23G93) - 2024.08.07</li><li>macOS Sonoma 14.6 (23G80) - 2024.07.29</li><li>macOS Sonoma 14.5 (23F79) - 2024.05.13</li><li>macOS Sonoma 14.4.1 (23E224) - 2024.03.25</li><li>macOS Sonoma 14.4 (23E214) - 2024.03.07</li><li>macOS Sonoma 14.3.1 (23D60) - 2024.02.08</li><li>macOS Sonoma 14.3 (23D56) - 2024.01.22</li><li>macOS Sonoma 14.2.1 (23C71) - 2023.12.19</li><li>macOS Sonoma 14.2 (23C64) - 2023.12.11</li><li>macOS Sonoma 14.1.2 (23B92 | 23B2091) - 2023.11.30</li><li>macOS Sonoma 14.1.1 (23B81 | 23B2082) - 2023.11.07</li><li>macOS Sonoma 14.1 (23B74) - 2023.10.25</li><li>macOS Sonoma 14 (23A344) Release - 2023.09.26</li><li><strong>下载地址</strong>：<a href="https://link.segmentfault.com/?enc=Tw6KLfYv7LyUsUuzF21cLQ%3D%3D.xLacOJXeosE%2FzNqAS4BJ2yfsh39XRUbu02ePGVEJf3Fe2PJ1Usd2kF%2BiVg9tl%2BY3" rel="nofollow" target="_blank">https://sysin.org/blog/macOS-Sonoma/</a></li></ul><p>参看：<a href="https://link.segmentfault.com/?enc=WCZkLasaa1sHj6YFJ1s3vA%3D%3D.4CGhSMkD%2BpedjUqu%2Fod7honb035WgasSzcuXEtk4XCZoUuqkyKoWdJm2nsV%2BuxLZ" rel="nofollow" target="_blank">如何在 Mac 和虚拟机上安装 macOS Sequoia、macOS Sonoma 和 macOS Ventura</a></p><h3>(2) PKG 格式软件包</h3><blockquote>该格式软件包双击运行后将自动安装在 <code>/Applications</code> 下。</blockquote><ul><li>macOS Sonoma 14.8.4 (23J319) - 2026.02.11</li><li>macOS Sonoma 14.8.3 (23J220) - 2025.12.12</li><li>macOS Sonoma 14.8.2 (23J126) - 2025.11.03</li><li>macOS Sonoma 14.8.1 (23J30) - 2025.09.30</li><li>macOS Sonoma 14.8 (23J21) - 2025.09.15</li><li>macOS Sonoma 14.7.8 (23H730) - 2025.08.20</li><li>macOS Sonoma 14.7.7 (23H723) - 2025.07.30</li><li>macOS Sonoma 14.7.6 (23H626) - 2025.05.12</li><li>macOS Sonoma 14.7.5 (23H527) - 2025.03.31</li><li>macOS Sonoma 14.7.4 (23H420) - 2025.02.10</li><li>macOS Sonoma 14.7.3 (23H417) - 2025.01.28</li><li>macOS Sonoma 14.7.2 (23H311) - 2024.12.11</li><li>macOS Sonoma 14.7.1 (23H222) - 2024.10.28</li><li>macOS Sonoma 14.7 (23H124) - 2024.09.16</li><li>macOS Sonoma 14.6.1 (23G93) - 2024.08.07</li><li>macOS Sonoma 14.6 (23G80) - 2024.07.29</li><li>macOS Sonoma 14.5 (23F79) - 2024.05.13</li><li>macOS Sonoma 14.4.1 (23E224) - 2024.03.25</li><li>macOS Sonoma 14.4 (23E214) - 2024.03.07</li><li>macOS Sonoma 14.3.1 (23D60) - 2024.02.08</li><li>macOS Sonoma 14.3 (23D56) - 2024.01.22</li><li>macOS Sonoma 14.2.1 (23C71) - 2023.12.19</li><li>macOS Sonoma 14.2 (23C64) - 2023.12.11</li><li>macOS Sonoma 14.1.2 (23B92 | 23B2091) - 2023.11.30</li><li>macOS Sonoma 14.1.1 (23B81 | 23B2082) - 2023.11.07</li><li>macOS Sonoma 14.1 (23B74) - 2023.10.25</li><li>macOS Sonoma 14 (23A344) Release - 2023.09.26</li><li><strong>下载地址</strong>：<a href="https://link.segmentfault.com/?enc=dUEFCDFC%2Fvzg7JK3L6uSaw%3D%3D.P8Js%2BWTnEqOgfqodsGRROl%2BV3L8ChUj0UOZCGjU6A%2FpmbPiJSa8EhfUCoS6yo2XE" rel="nofollow" target="_blank">https://sysin.org/blog/macOS-Sonoma/</a></li></ul><h3>(3) IPSW 固件 (Apple 芯片 Mac 专用)</h3><blockquote>IPSW 格式为搭载 Apple 芯片的 Mac 专用映像，其他格式通用。</blockquote><p>适用于：<a href="https://link.segmentfault.com/?enc=RbTtwtfKYxkFJUq1EZ0DIg%3D%3D.r24gs5ZbpBMNKtR5ZtCppHxHzeCDVZjjTYc%2Bx%2BB%2Bnz%2B7kjWdhfqXcg1hgNQqDhE4" rel="nofollow" target="_blank">搭载 Apple 芯片的 Mac 电脑</a></p><p>参看：<a href="https://link.segmentfault.com/?enc=1amXLNOE%2BDJZL8rLQQ9xnw%3D%3D.LogmEqR7CpFr5icINcY3q0czxpTTqer0bmIvKYLTYc29Giw%2Fjs1ftXaAm25hmf9a" rel="nofollow" target="_blank">使用 DFU 模式修复或恢复 Mac 固件</a></p><ul><li>macOS Sonoma 14.6.1 (23G93) - 2024.08.07</li><li>macOS Sonoma 14.6 (23G80) - 2024.07.29</li><li>macOS Sonoma 14.5 (23F79) - 2024.05.13</li><li>macOS Sonoma 14.4.1 (23E224) - 2024.03.25</li><li>macOS Sonoma 14.4 (23E214) - 2024.03.07</li><li>macOS Sonoma 14.3.1 (23D60) - 2024.02.08</li><li>macOS Sonoma 14.3 (23D56) - 2024.01.22</li><li>macOS Sonoma 14.2.1 (23C71) - 2023.12.19</li><li>macOS Sonoma 14.2 (23C64) - 2023.12.11</li><li>macOS Sonoma 14.1.2 (23B92 | 23B2091) - 2023.11.30</li><li>macOS Sonoma 14.1.1 (23B81 | 23B2082) - 2023.11.07</li><li>macOS Sonoma 14.1 (23B74) - 2023.10.25</li><li>macOS Sonoma 14 (23A344) Release - 2023.09.26</li><li><strong>下载地址</strong>：<a href="https://link.segmentfault.com/?enc=m3DenKwIGCswRdmjAYgnIA%3D%3D.9MoqaWlxI0SEJULqQhH1x3nC1eKpJ%2FdhukMf0ELBmXc0vN%2B%2FiAsF%2BEl9jvSeObk1" rel="nofollow" target="_blank">https://sysin.org/blog/macOS-Sonoma/</a></li></ul><h3>(4) App Store 链接</h3><pre><code class="txt">https://apps.apple.com/app/macos-sonoma/id6450717509?mt=12</code></pre><p>或者打开 App Store 搜索 “macOS Sonoma” 即可下载（下载的是当前最新版）。</p><h2>适用的 VMware 软件下载链接</h2><p>建议在以下版本的 VMware 软件中运行（Linux OVF 无需本站定制版可以正常运行，macOS 虚拟化如果不是 Mac 必须使用定制版才能运行，Windows OVF 需要定制版才能启用完整功能）：</p><ul><li><p>VMware vSphere：</p><ul><li>VMware <a href="https://link.segmentfault.com/?enc=Bzg5B6pNq08oVTIWfWnJ7A%3D%3D.HPuJLMpopkGWl0XM7eRzdZq8yPADiMAZ5hcfC8cNxOUsqbEQ1um1bHhjD5yzegiv" rel="nofollow" target="_blank">ESXi 9</a> or <a href="https://link.segmentfault.com/?enc=RwYvAeG03B3ac7vaKoo%2B0w%3D%3D.JnwSGoXh3zyGxVqF%2FTZ6bZ2940MsanEr6lMV2BrwNu4mGdQ0z6MeF%2B6qyAbMs1hk" rel="nofollow" target="_blank">with driver</a> &amp; <a href="https://link.segmentfault.com/?enc=LnhRTQbb4q2fvgNxQ4V%2FGw%3D%3D.TYRHGOWkUPa5qaXx38FpkKHwnRcogAaHclbtGzuGfyRoNwZDjTkE6ckfLVMvORBU" rel="nofollow" target="_blank">vCenter Server 9</a> &amp; <a href="https://link.segmentfault.com/?enc=fWjpuxIsNmX6ZXlZF7JtiQ%3D%3D.06zHnsf5k84WaJjoaixKNMTfYVNC4YNqUFws9VqOtBgO%2FR%2FOcnZk7mRQc5H%2FcEmpiAggewNTuxTGpIqtyCQ05w%3D%3D" rel="nofollow" target="_blank">VCF Operations 9</a></li><li>VMware <a href="https://link.segmentfault.com/?enc=0beHGMVc9%2F3J8lNaH7unBg%3D%3D.3eDxyqmh4o6wpIMRVNRbqx1ZKYm6tIljrBRfaY2AcqnfSGJXpoQLgbQ7gPlkuz1t" rel="nofollow" target="_blank">ESXi 8</a> or <a href="https://link.segmentfault.com/?enc=qXNy7XSQYyxX4EOdzHHQlQ%3D%3D.U2U7PNVz2I7pX9gy03CoPohdh5hErk33GzeqEC1f1%2B6X8Ju0mzYrvCpBOY90K1tq" rel="nofollow" target="_blank">with driver</a> &amp; <a href="https://link.segmentfault.com/?enc=mVKNBz%2B2r1OJHgdZUhAw6A%3D%3D.38uO50DKzHWnebdx8yVEyBFpooo2icY9J7E1lJVTfqEzFr4hTSdTrQ8b3D7k2VFk" rel="nofollow" target="_blank">vCenter Server 8</a></li><li>VMware <a href="https://link.segmentfault.com/?enc=5Im%2Fu1cfFCT4tjWA10rQJw%3D%3D.IwP%2FcJRrkHyZIKm%2FZ8muE0KQZIOCh6q6kf0pXIcASIsam07SEMaUr1vhkRhOfsAu" rel="nofollow" target="_blank">ESXi 7</a> or <a href="https://link.segmentfault.com/?enc=veKnvax9Aos0OiAx3PfFBA%3D%3D.7oAj2rFD8Of0opD5%2B6KrOSaEbjV%2Bo4q8F1SpXpke2OHdfEGg8Xnv%2Bxvn6p1gJU2E" rel="nofollow" target="_blank">with driver</a> &amp; <a href="https://link.segmentfault.com/?enc=b4%2F7b9jMf7lak967dHL9FA%3D%3D.8Nvm%2FR7JTOjE3%2F7tbDMK8pbuZSjZzbSx15r%2BhlXWkYDD9Pia4sqDNEkSDH8FmOyI" rel="nofollow" target="_blank">vCenter Server 7</a></li></ul></li><li>macOS：<a href="https://link.segmentfault.com/?enc=b8lXQk1GddCcNK3vJeZVmg%3D%3D.0WzxiSCHU05MTy452220xATfLdB%2FEHydpTAQsuXSixTVG%2FICUqwZEBxz4FYGAAqC" rel="nofollow" target="_blank">VMware Fusion</a></li><li>Linux：<a href="https://link.segmentfault.com/?enc=APb0%2FP2FtbiwZxK%2BAyQpkg%3D%3D.6iIScHmKmjp7%2FOZgxZysabNvLEgHZqiCxTVhP6UVZayVusf%2F1g80K2NM3vUemxdZS7b528lklUhEa5scDVdx7g%3D%3D" rel="nofollow" target="_blank">VMware Workstation for Linux</a></li><li>Windows：<a href="https://link.segmentfault.com/?enc=Kp%2BM8fkddXw3%2FTa2766flA%3D%3D.p%2BZHDY5arAdNzyI6s%2Fl%2FtF2ndc8lTyNXFuOzttukIRR0HP%2FOkwl0DZjK7CM2YsvgzsdCLrdaG3aiDmf9X68GWg%3D%3D" rel="nofollow" target="_blank">VMware Workstation for Windows</a></li></ul><p>macOS Sonoma 虚拟化解决方案，请参看：<a href="https://link.segmentfault.com/?enc=RDVNdGiYZYMAFVFJJjz%2Blg%3D%3D.wJVRk5ZrGZN59fxbiQEopVZ8YIqaOneM0NrlLenruMwxgPs8KNpzLzMWQNNgmZbl" rel="nofollow" target="_blank">macOS 14 Blank OVF - macOS Sonoma 虚拟化解决方案</a></p><h2>如何创建可引导的 macOS 安装器</h2><p>请访问：<a href="https://link.segmentfault.com/?enc=tuU74hJfxd%2FBMc0826%2B8DA%3D%3D.MYbVdiDhdia6sreDZwJugEl6nh2BXJoqvlbI6Or4uKFy8QFd4mdw6nKZVByhN%2Bi0XL56VGiBdJjwIxfYopSlAQ%3D%3D" rel="nofollow" target="_blank">如何创建可引导的 macOS 安装介质</a></p><p>更多：<a href="https://link.segmentfault.com/?enc=sx0qgW8Q%2FlqbMDQWHJDBPw%3D%3D.6n6zM7xKBvWWvFz43F%2FL%2BI5Frm%2B0QQ4V3UkBf5olRvk%3D" rel="nofollow" target="_blank">macOS 下载汇总 (系统、应用和教程)</a></p>]]></description></item><item>    <title><![CDATA[硅谷爆火的「Vibecoding」：不用敲代码，AI 帮你把想法变成产品 UXbot ]]></title>    <link>https://segmentfault.com/a/1190000047608742</link>    <guid>https://segmentfault.com/a/1190000047608742</guid>    <pubDate>2026-02-13 10:03:54</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>硅谷工程师圈刮起一阵新风潮 ——Vibe Coding（氛围编程）。说白了，就是不用埋头逐行敲代码，只要把你的想法用大白话讲清楚，剩下的活儿全交给 AI，轻松把创意变成能用的产品。<br/>本文将为大家解释什么是Vibe coding，并为大家推荐实用工具。</p><p>一、什么是 Vibe Coding？一张表秒懂<br/><img width="723" height="314" referrerpolicy="no-referrer" src="/img/bVdnVmY" alt="image.png" title="image.png"/><br/>一句话总结：你负责把想法说成人话，AI 负责把人话变成能用的代码。</p><p>二、Vibe Coding 4 步走：小白也能轻松上手<br/>说需求：把想法讲明白就行不用纠结技术术语，直接说你想要的效果：“帮我做个购物网站，左滑是喜欢，右滑是不喜欢，界面要极简风，看着干净舒服。”<br/>AI 生成：设计+前端代码一步到位把需求丢给 AI，它会自动帮你搞定可视化PRD、产品原型设计、前端代码，都给你配置妥当，不用你操心任何技术细节。<br/>看效果：云端一键部署，打破设计与开发壁垒，有任何不满意的地方都可重新修改。<br/>改需求：不满意随时调，秒级响应觉得按钮不好看？直接说：“按钮太丑了，换成浅蓝色，再把圆角调大一点。” AI 立刻重绘 UI，不用重启程序，刷新就能看新效果。</p><p>三、零代码基础的产品经理，3 小时上线情侣旅游攻略<br/>主角：产品经理小陈，连 “Hello World” 都写不利索<br/>初衷：想给女友跟女友出去旅游，做个 “旅游” 网站，推荐全国各地的攻略：UXbot+Cursor 编辑器 ：从提需求到上线只用了 3 小时，快到离谱。</p><p>四、工具推荐<br/>1.UXbot<br/>UXbot是AI驱动软件设计+Web前端开发工具，专门适配软件设计和开发场景，能够帮助用户打通“需求解析-界面设计-协作交付”全链路，用AI赋能提升开发效率。<br/>2.实战演练<br/>为验证UXbot的实际落地效能，本次选取“物流订单管理系统”为实战场景，聚焦方案撰写链路开展测试。<br/>第1步：精准输入需求，AI深度解析设计意图<br/>通过自然语言清晰描述UI需求即可启动生成。例如：“生成物流订单管理系统，包括物流追踪、订单管理、异常处理三个模块，组件自动适配响应式布局。”UXbot将智能识别页面类型、核心功能模块与结构逻辑，为精准生成奠定基础。<br/><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdnVmZ" alt="image.png" title="image.png" loading="lazy"/></p><p>第2步：可视化PRD智能生成<br/>可视化 PRD 以其直观的流程图形式，将产品的核心逻辑、功能模块、用户路径等进行系统化整合与呈现，让产品交互逻辑清晰可视化，帮助用户快速掌握产品全局架构与运行逻辑，并且通过流程闭环校验，精准识别并补齐产品逻辑中的缺漏与断点。<br/><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdnVm0" alt="image.png" title="image.png" loading="lazy"/></p><p>第3步：AI自动生成高保真UI界面<br/>基于需求解析结果，UXbot将自动完成页面结构搭建、UI组件匹配、视觉风格统一，数十秒内即可输出完整的高保真可交互界面。生成界面支持页面跳转与演示，可直接用于团队评审或需求沟通，彻底告别从低保真到高保真的冗长迭代过程。<br/><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdnVm1" alt="image.png" title="image.png" loading="lazy"/></p><p>第4步：二次编辑与交互逻辑完善<br/>搭载 AI 助手与专业级精密编辑器，支持用户进行像素级细节控制，布局微调、样式迭代、图文更新均精准匹配需求，兼顾创意灵动性与设计专业性。<br/><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdnVm2" alt="image.png" title="image.png" loading="lazy"/></p><p>第5步：Web前端代码生成<br/>界面设计一确定，它就会自动生成能直接用的前端代码，还能适配 Vue.js 这种常用框架。设计效果和代码能无缝衔接，甚至能一键传到云服务器上，再也不用纠结设计和开发脱节的问题了。<br/><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdnVm3" alt="image.png" title="image.png" loading="lazy"/></p><p>写在最后<br/>2025年硅谷已经开始开出百万年薪，招聘“会提需求的Vibe Coder”；现在的你，就算完全不会写代码，也可能成为下一个爆款产品的独立开发者。<br/>Vibe Coding不是让你彻底放弃编程，而是把那些重复、枯燥、没技术含量的体力活，统统交给AI去做。你只需要专注于最核心的部分——打磨创意、优化产品、挖掘用户价值。<br/>毕竟在AI时代，最值钱的从来不是“括号该放左边还是右边”，而是那个独一无二、能打动用户的好点子。</p>]]></description></item><item>    <title><![CDATA[银河麒麟V10安装 openssl-1.1.1f-4.p12.ky10.x86_64教程(含依赖解决]]></title>    <link>https://segmentfault.com/a/1190000047608767</link>    <guid>https://segmentfault.com/a/1190000047608767</guid>    <pubDate>2026-02-13 10:03:18</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>​</p><h3> 1. 先把东西备好</h3><ul><li><p><strong>看看系统对不对头</strong></p><p>开个终端，先敲俩命令，确认是 Kylin V10 并且是 64 位的。</p><pre><code>cat /etc/os-release
uname -m</code></pre></li></ul><pre><code>看到输出里有 `Kylin Linux`和 `x86_64`就OK。
</code></pre><ul><li><p><strong>找到你的 RPM 包</strong></p><p><strong>安装包下载：</strong><a href="https://link.segmentfault.com/?enc=ieCsTMlWb6n2ED57tFN7xw%3D%3D.aJxlMXK3YBIK9EISSkrVBKifjq53lrkWX%2FlEfrCvLNaXI3PV0ghbPv%2B3xbsnEMIG" rel="nofollow" title="https://pan.quark.cn/s/6e9d4d969bac" target="_blank">https://pan.quark.cn/s/6e9d4d969bac</a>  ，假设你把包下载到了 <code>/home/你的用户名/下载/</code>文件夹。先切换到这个目录，并确认文件真的在这儿。</p><pre><code>cd /home/你的用户名/下载
ls -l openssl-1.1.1f-4.p12.ky10.x86_64.rpm</code></pre></li></ul><pre><code>能列出文件信息，就说明路径没错。


</code></pre><h3>2. 开始上手安装</h3><p>跟之前一样，推荐用第二种方法，能帮你自动搞定依赖，少折腾。</p><h4>方法一：用 <code>rpm</code>命令直接干</h4><p>这个方法最直接，但如果缺东西，你得自己满世界去找。</p><ol><li><p><strong>执行安装命令</strong></p><p>在 RPM 包所在的目录，敲下命令：</p><pre><code>sudo rpm -ivh openssl-1.1.1f-4.p12.ky10.x86_64.rpm</code></pre></li></ol><pre><code>-   `-i`就是安装
-   `-v`显示过程
-   `-h`显示个百分比进度条
</code></pre><ol><li><p><strong>遇到缺啥补啥</strong></p><p>如果安装失败了，十有八九是提示你缺依赖。比如可能缺 <code>perl</code>或者其他库。这时候你就得照着提示，把缺的包装上，然后再回来重新执行上面的命令。</p></li></ol><h4>方法二：用 <code>dnf</code>或 <code>yum</code>命令装 (推荐)</h4><p>这个方法的好处是会自己联网去软件库里把需要的依赖都下载安装好，非常省心。</p><ol><li><p><strong>执行安装命令</strong></p><p>还在那个目录下，执行下面任意一个命令：</p><pre><code># 如果系统默认是 dnf
sudo dnf install ./openssl-1.1.1f-4.p12.ky10.x86_64.rpm

# 或者，如果系统默认是 yum
sudo yum localinstall openssl-1.1.1f-4.p12.ky10.x86_64.rpm</code></pre></li></ol><pre><code>输完密码，它会分析依赖，然后问你确定要装吗，你输入 `y`回车就成。


</code></pre><h3> 3. 最后检查下，看装好没</h3><p>装完了，必须得验证一下。</p><p>在终端里输入这个命令：</p><pre><code>rpm -q openssl</code></pre><p>如果屏幕返回的结果是 <code>openssl-1.1.1f-4.p12.ky10.x86_64</code>，那就稳了，说明安装成功！</p><p>​</p>]]></description></item><item>    <title><![CDATA[AI 画图全家桶来了！这回想自己手绘图都难了 程序员小富 ]]></title>    <link>https://segmentfault.com/a/1190000047608774</link>    <guid>https://segmentfault.com/a/1190000047608774</guid>    <pubDate>2026-02-13 10:02:20</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><strong>大家好，我是小富～</strong></p><p>前几天我不是分享了如何零成本搭建 <strong>next-ai-draw-io</strong>，教大家用 AI 生成 draw.io 风格的架构图。后台反响还不错，看来大家对手绘架构图真的是苦之久矣。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047511102" alt="" title=""/></p><p>但在日常写文章时，我发现很多读者更偏爱那种手绘感十足的 <strong>Excalidraw</strong> 风格，就是下面这种，逼格高、视觉美，能让文章瞬间显得高级起来：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608776" alt="" title="" loading="lazy"/></p><p>我原本在琢磨，能不能用 Gemini Pro 给自己搓一个 AI 绘图整合平台，把 draw.io 和 Excalidraw 全揉进去。</p><p>结果去 GitHub 一搜，好家伙，已经有大佬把我想做的给做了！这个开源项目简直是为我这种懒癌博主量身定制的：<strong>Mermaid、draw.io、Excalidraw</strong> 三大王牌风格全部支持。</p><p>回头再看看以前为了画个原理图熬夜的样子，真的感觉是在浪费生命啊！</p><h4>AI Draw Nexus AI 绘图全家桶</h4><p><strong>GitHub 地址</strong>：<code>https://github.com/hkxiaoyao/ai-draw-nexus</code></p><p><strong>在线体验</strong>：<code>https://ai-draw-nexus.aizhi.site/</code></p><p>我挨个试了一遍，大家感受下这输出质量：</p><p><strong>1. Excalidraw 风格</strong></p><p>输入: HTTP 长轮询原理图，生成的逻辑线条清晰，手绘质感爆棚。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608777" alt="" title="" loading="lazy"/></p><p><strong>2. Draw.io 风格</strong></p><p>我之前很多的系统架构、流程图都是这个风格，现在 AI 加持真的太方便了。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608778" alt="" title="" loading="lazy"/></p><p><strong>3. Mermaid 风格</strong></p><p>写 Markdown 就更简单了一秒出图。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608779" alt="" title="" loading="lazy"/></p><p>这不是功能阉割版，而是全量版！可以在 AI 生成的基础上，直接手动微调。</p><h4>快速上手</h4><p>如果你想本地运行，这个基于 Next.js 的前端项目安装起来也非常简单：</p><pre><code class="shell"># 1. 克隆项目
git clone https://github.com/hkxiaoyao/ai-draw-nexus
cd ai-draw-nexus

# 2. 安装依赖 (推荐用 pnpm)
pnpm install

# 3. 开启生产力大门
pnpm dev</code></pre><p>不过，目前的在线版本每天有 10 次免费配额，这也很正常毕竟 API 线上的费用确实贵（上次我那个免费工具被大家两天就用欠费了，哈哈 😂）。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608780" alt="" title="" loading="lazy"/></p><p>现在仅支持 <strong>OpenAI</strong> 和 <strong>Anthropic</strong> 两大模型。如果你有自己的 Key，建议本地搭一个，那才是真正的绘图自由！</p><p>好了，下期见～</p>]]></description></item><item>    <title><![CDATA[如何在低代码平台中自定义流程编号？一篇搞定所有配置步骤！ 软件部长 ]]></title>    <link>https://segmentfault.com/a/1190000047608805</link>    <guid>https://segmentfault.com/a/1190000047608805</guid>    <pubDate>2026-02-13 10:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在企业的日常运营中，流程管理是确保工作规范、提升效率的关键环节。每一个流程实例都需要一个唯一的标识符，这就是流程编号。它如同流程的“身份证”，贯穿流程的发起、审批、执行与归档全过程，确保流程可追溯、易管理。<br/>流程编号并不是一成不变，在JVS低代码流程引擎中，有一个流程编码自定义配置的能力，允许企业根据自身管理需求，设计出贴合业务、便于查询跟踪的编号规则。<br/>流程编号是一种用于标识和跟踪特定流程或业务流程实例的标识符。在企业或组织中，流程编号通常用于确保流程的准确性和可追溯性，帮助管理和优化业务流程。<br/>通过自定义编号规则，你可以将业务类型、日期、部门等信息融入编号中。例如，一个“采购申请”流程的编号可以定义为 P-20250213-00001（P代表采购，20250213代表日期，00001为当日序号），这让流程管理一目了然，极大地提升了查询与统计效率。<br/><strong>示例演示</strong><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047608807" alt="图片" title="图片"/><br/>接下来我说一说具体的配置方式。<br/><strong>操作步骤</strong><br/>进入流程引擎设计，点击【高级设置】页面<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047608808" alt="图片" title="图片" loading="lazy"/><br/>流程编号默认按系统规则生成，即阿拉伯数字顺序计数，从1开始依次递增。<br/>选择按自定义规则生成流程编号点击编辑图标，编号格式设置同我们流水号组件设置如下<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047608809" alt="图片" title="图片" loading="lazy"/><br/>①：前缀，加在编号前面的，自定义标识，如“P”代表流程，“M”代表管理，“S”代表支持等<br/>②：后缀，拼接在最后面的<br/>③：时间标识，拼接在前缀后<br/>不设置，默认设置<br/>年<br/>年月<br/>年月日<br/>年月日时<br/>年月日时分<br/>年月日时分秒<br/>④：序号位数，默认是5，可设置1-9位数字<br/>⑤：重置规则<br/>不重置<br/>按年重置<br/>按月重置<br/>按天重置<br/>按小时重置<br/>按业务需要设置好编号格式点击【确定】最后点击【保存】并【发布】流程，重新发起流程查看效果。<br/><strong>流程编号展示位置</strong><br/>流程办理页面<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047608810" alt="图片" title="图片" loading="lazy"/><br/>流程进度页面<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047608811" alt="图片" title="图片" loading="lazy"/><br/>工作台<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047608812" alt="图片" title="图片" loading="lazy"/><br/>在线demo：<a href="https://link.segmentfault.com/?enc=awQsrMsqXpA9wuabj8qe0Q%3D%3D.pyd%2BXq66ww4JnJMcO6BHpCwWv0UxnRJEugkELRARE1U%3D" rel="nofollow" target="_blank">https://app.bctools.cn</a><br/>基础框架开源地址：<a href="https://link.segmentfault.com/?enc=2C89SYWezaVz0AwZ7lkRAA%3D%3D.P360SwWpawTPW%2BgUqwQ5SlKfSxE15d%2F9WQPNFA4ZdsMHEeqsvk4vbC5R%2Fc3R1Cgz" rel="nofollow" target="_blank">https://gitee.com/software-minister/jvs</a></p>]]></description></item><item>    <title><![CDATA[Microsoft Office LTSC 2024 for Mac 16.106 - 文档、电子表]]></title>    <link>https://segmentfault.com/a/1190000047608698</link>    <guid>https://segmentfault.com/a/1190000047608698</guid>    <pubDate>2026-02-13 09:01:55</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>Microsoft Office LTSC 2024 for Mac (Microsoft 365) 16.106 - 文档、电子表格、演示文稿和电子邮件</p><p>Office LTSC 2024 for Mac (Word, Excel, PowerPoint, Outlook + OneNote, OneDrive)</p><p>请访问原文链接：<a href="https://link.segmentfault.com/?enc=HS%2BoY9AO5L%2BY6Fvf5ahlcw%3D%3D.PQG2n03mG3jzeeeZbpRNj%2FeztbNmtY5O%2BP2fUsl9u7eehG5xm7LxdEe%2BfUILKBTD" rel="nofollow" target="_blank">https://sysin.org/blog/office-2024-for-mac/</a> 查看最新版。原创作品，转载请保留出处。</p><p>作者主页：<a href="https://link.segmentfault.com/?enc=hTjFlERie53sy0mRFSbvAw%3D%3D.F3PqT3lKJFUAOk%2B9lWTcBEuEck67wrTsOeeUwMF3GNk%3D" rel="nofollow" target="_blank">sysin.org</a></p><hr/><p>Office for Mac 2024 2026 年 2 月份月度更新来袭！</p><h2>Office for Mac 2024 组件和发行版</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608476" alt="Office LTSC" title="Office LTSC"/></p><p>宣布推出适用于 Windows 和 Mac 的 Microsoft Office LTSC 2024 正式版</p><p>2024 年 9 月 16 日，Microsoft Office LTSC 2024 的正式版现已适用于 Windows 和 Mac。</p><p>如果您有 Office 2016、Office 2019 或 Office LTSC 2021 并且想要预览 Office LTSC 2024，请访问<a href="https://link.segmentfault.com/?enc=%2B9gZ5YHQQT%2FCDrGXHEpkeQ%3D%3D.B8CwkO%2Foq7Q7B%2FSmax9mS6q6eGZ7UX8jLHtvhmeQwKE1K2b1xkEQKZZxeW7xLvoQ" rel="nofollow" target="_blank">安装 Office LTSC 正式版</a>，了解如何在 Windows 设备上安装和使用。</p><p>Office for Mac 包含以下组件：</p><ul><li>Microsoft <strong>Excel</strong>：电子表格和数据分析</li><li>Microsoft <strong>Outlook</strong>：电子邮件和日历</li><li>Microsoft <strong>PowerPoint</strong>：创建吸引人的演示文稿</li><li>Microsoft <strong>Word</strong>：创建、编辑和分享文档</li><li>Microsoft <strong>OneNote</strong>：记录笔记、创意和备忘录</li></ul><p>Office for Mac 有以下两种发行版（详见下文描述）：</p><ul><li>Office for Mac (Office 365) pkg</li><li>Office LTSC for Mac DMG VL</li></ul><h2>Office for Mac 2024 (Microsoft 365) pkg</h2><p>⚠️：<strong>请慎用此版本，需要 root 权限才能运行，安装一堆无用文件，强制自动更新。</strong></p><p>参看：<a href="https://link.segmentfault.com/?enc=tln1mXPp3MAeUZA1SlBRJA%3D%3D.miHvDgBEmxI8VrsHV%2Bbttz5aq%2FrwOoPlYOEJwLxeYA0MTxzL%2FSXelfzicudvszqZQ13eVnok5V%2BnVNlF8WjzcQ%3D%3D" rel="nofollow" target="_blank">如何卸载 Office for Mac</a></p><p>此版本的唯一优点是开放下载，各大网站通常提供的也是此版本。</p><p><strong>Microsoft Office for Mac 2024 (Office 365) 16.106 Universal</strong>（2026-01-13）</p><ul><li>请访问：<a href="https://link.segmentfault.com/?enc=Aa5f%2FMsn7vKZy5msfuea7w%3D%3D.W6OCXINk4jLkdVnNunhxwAVBmmPHJaTjH9HyFnM02sMTpf4RydCFaZwX5o3f18aq" rel="nofollow" target="_blank">https://sysin.org/blog/office-2021-for-mac/</a></li><li>系统要求：从 16.101 开始，要求 macOS Sonoma 14.0 及以上版本。</li></ul><p>从 16.84 开始，Office 2024 和 Office 2022 是共用安装文件 (sysin)，通过许可证激活不同的版本，主要体现在界面风格上有较为明显差异，另外 2024 版有一些新增功能。</p><p>Office 365 (现在称为 Microsoft 365 Apps) 是一种订阅模式，永久许可版即 Office LTSC for Mac。</p><h2>Office LTSC 2024 for Mac DMG VL</h2><p>该产品符合 Apple 平台设计规范，无需 root 权限安装，只需要拖拽到应用程序下即可，无需登录，没有自动更新程序，也不会提示过期。</p><ul><li>无需 root 权限，拖拽即可安装</li><li>无需登录账号（无需注册，支持离线使用）</li><li>无自动更新程序</li><li>不会提示过期</li><li>可以仅安装单个组件</li></ul><p>包含 Excel、Outlook、PowerPoint 和 Word 四个核心组件，可独立运行单个组件。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608477" alt="Microsoft Excel" title="Microsoft Excel" loading="lazy"/></p><p>Microsoft <strong>Excel</strong>：电子表格和数据分析</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608478" alt="Microsoft Outlook" title="Microsoft Outlook" loading="lazy"/></p><p>Microsoft <strong>Outlook</strong>：电子邮件和日历</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608479" alt="Microsoft PowerPoint" title="Microsoft PowerPoint" loading="lazy"/></p><p>Microsoft <strong>PowerPoint</strong>：创建吸引人的演示文稿</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608480" alt="Microsoft Outlook" title="Microsoft Outlook" loading="lazy"/></p><p>Microsoft <strong>Word</strong>：创建、编辑和分享文档</p><p>备注：OneNote 免费，需要登录。</p><p><strong>Microsoft Office LTSC 2024 for Mac DMG VL v16.89 (Final version)</strong> for macOS Montery 12</p><ul><li>请访问：<a href="https://link.segmentfault.com/?enc=cG9JYvzqTeJ5wk9zNwQwug%3D%3D.%2FKQejFLrzvDQdWPnBV%2BITyEWx7Q%2FqEEimPivtteQD%2FV33nQ1DRIMYfr1KbAGrQxF" rel="nofollow" target="_blank">https://sysin.org/blog/office-2024-for-mac/</a></li></ul><p><strong>Microsoft Office LTSC 2024 for Mac DMG VL v16.100 (Final version)</strong> for macOS Ventura 13</p><ul><li>请访问：<a href="https://link.segmentfault.com/?enc=T7aduepF8abL8f2O9JVeMg%3D%3D.QBPdZ605v3gJTval7B4OF8ljlFIBw8NrwXk0Rov%2BQ44CqI%2FfjqeI%2F1RaJfBcag29" rel="nofollow" target="_blank">https://sysin.org/blog/office-2024-for-mac/</a></li></ul><p><strong>Microsoft Office LTSC 2024 for Mac DMG VL v16.106</strong> for macOS Sonoma 14 or later</p><ul><li>支持 macOS Sonoma 14、macOS Sequoia 15 和 macOS Tahoe 26</li><li>请访问：<a href="https://link.segmentfault.com/?enc=3Cze20pXPKf6E9Uj%2F7BdLA%3D%3D.McQKgGj8U%2BU8cjQ3erK9eRPi5KmqooYe39U47vUymKaOwBXhmDoHtwJVeiAL2cyD" rel="nofollow" target="_blank">https://sysin.org/blog/office-2024-for-mac/</a></li></ul><hr/><p>更多：<a href="https://link.segmentfault.com/?enc=aIFQLnheHtSZ3M7UxFrZFw%3D%3D.36maCiuGq66dbxztGJUc8eJ%2FqPxRHHAo14C2INjbJUU%3D" rel="nofollow" target="_blank">macOS 下载汇总 (系统、应用和教程)</a></p>]]></description></item><item>    <title><![CDATA[LockSupport深度解析：线程阻塞与唤醒的底层实现原理 SevenCoding ]]></title>    <link>https://segmentfault.com/a/1190000047598590</link>    <guid>https://segmentfault.com/a/1190000047598590</guid>    <pubDate>2026-02-13 09:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>LockSupport简介</h2><p>LockSupprot 用来阻塞和唤醒线程，底层实现依赖于 <a href="https://link.segmentfault.com/?enc=2jYChfnH9ZWiDDMFfuabdw%3D%3D.iThJ3ygEeLy5ommch6CuKm1B6%2FnXyYPaTWUBgfcLwbZgLB4u3vRHrLReS0ysgNJ3LPiD%2BRG13ADe7%2BA4djCeNA%3D%3D" rel="nofollow" target="_blank">Unsafe 类</a>。</p><p>LockSupport用来创建锁和其他同步类的基本线程阻塞原语。简而言之，当调用LockSupport.park时，表示当前线程将会等待，直至获得许可，当调用LockSupport.unpark时，必须把等待获得许可的线程作为参数进行传递，好让此线程继续运行。在AQS中大量使用，AQS最终都是使用LockSupport来阻塞线程的。</p><p>该类包含一组用于阻塞和唤醒线程的静态方法，这些方法主要是围绕 park 和 unpark 展开，话不多说，直接来看一个简单的例子吧。</p><pre><code class="java">public class LockSupportDemo1 {
    public static void main(String[] args) {
        Thread mainThread = Thread.currentThread();

        // 创建一个线程从1数到1000
        Thread counterThread = new Thread(() -&gt; {
            for (int i = 1; i &lt;= 1000; i++) {
                System.out.println(i);
                if (i == 500) {
                    // 当数到500时，唤醒主线程
                    LockSupport.unpark(mainThread);
                }
            }
        });

        counterThread.start();

        // 主线程调用park
        LockSupport.park();
        System.out.println("Main thread was unparked.");
    }
}</code></pre><p>上面的代码中，当 counterThread 数到 500 时，它会唤醒 mainThread。而 mainThread 在调用 park 方法时会被阻塞，直到被 unpark。</p><p>LockSupport 中的方法不多，这里将这些方法做一个总结：</p><h3>阻塞线程</h3><ol><li><code>void park()</code>：阻塞当前线程，如果调用 unpark 方法或线程被中断，则该线程将变得可运行。请注意，park 不会抛出 InterruptedException，因此线程必须单独检查其中断状态。</li><li><code>void park(Object blocker)</code>：功能同方法 1，入参增加一个 Object 对象，用来记录导致线程阻塞的对象，方便问题排查。</li><li><code>void parkNanos(long nanos)</code>：阻塞当前线程一定的纳秒时间，或直到被 unpark 调用，或线程被中断。</li><li><code>void parkNanos(Object blocker, long nanos)</code>：功能同方法 3，入参增加一个 Object 对象，用来记录导致线程阻塞的对象，方便问题排查。</li><li><code>void parkUntil(long deadline)</code>：阻塞当前线程直到某个指定的截止时间（以毫秒为单位），或直到被 unpark 调用，或线程被中断。</li><li><code>void parkUntil(Object blocker, long deadline)</code>：功能同方法 5，入参增加一个 Object 对象，用来记录导致线程阻塞的对象，方便问题排查。</li></ol><h3>唤醒线程</h3><p><code>void unpark(Thread thread)</code>：唤醒一个由 park 方法阻塞的线程。如果该线程未被阻塞，那么下一次调用 park 时将立即返回。这允许“先发制人”式的唤醒机制。</p><p>实际上，LockSupport 阻塞和唤醒线程的功能依赖于 <code>sun.misc.Unsafe</code>，这是一个很底层的类，比如 LockSupport 的 park 方法是通过 <code>unsafe.park()</code> 方法实现的。</p><h2>LockSupport源码分析</h2><h3>类的属性</h3><pre><code class="java">public class LockSupport {
    // Hotspot implementation via intrinsics API
    private static final sun.misc.Unsafe UNSAFE;
    // 表示内存偏移地址
    private static final long parkBlockerOffset;
    // 表示内存偏移地址
    private static final long SEED;
    // 表示内存偏移地址
    private static final long PROBE;
    // 表示内存偏移地址
    private static final long SECONDARY;
    
    static {
        try {
            // 获取Unsafe实例
            UNSAFE = sun.misc.Unsafe.getUnsafe();
            // 线程类类型
            Class&lt;?&gt; tk = Thread.class;
            // 获取Thread的parkBlocker字段的内存偏移地址
            parkBlockerOffset = UNSAFE.objectFieldOffset
                (tk.getDeclaredField("parkBlocker"));
            // 获取Thread的threadLocalRandomSeed字段的内存偏移地址
            SEED = UNSAFE.objectFieldOffset
                (tk.getDeclaredField("threadLocalRandomSeed"));
            // 获取Thread的threadLocalRandomProbe字段的内存偏移地址
            PROBE = UNSAFE.objectFieldOffset
                (tk.getDeclaredField("threadLocalRandomProbe"));
            // 获取Thread的threadLocalRandomSecondarySeed字段的内存偏移地址
            SECONDARY = UNSAFE.objectFieldOffset
                (tk.getDeclaredField("threadLocalRandomSecondarySeed"));
        } catch (Exception ex) { throw new Error(ex); }
    }
}</code></pre><p>说明: UNSAFE字段表示<a href="https://link.segmentfault.com/?enc=TeLuQsSYqfvr4NkrAdCKKA%3D%3D.rfQII56OH2a4euquJhQKHm64Rlyxfwm2Ork2KiOvQYr9%2FaMnPeDy9xj82Zps8dqjBlAGh3w20bA8cL9%2BkkMqgA%3D%3D" rel="nofollow" target="_blank">sun.misc.Unsafe</a>类，一般程序中不允许直接调用，而long型的表示实例对象相应字段在内存中的偏移地址，可以通过该偏移地址获取或者设置该字段的值。</p><h3>类的构造函数</h3><pre><code class="java">// 私有构造函数，无法被实例化
private LockSupport() {}</code></pre><p>说明: LockSupport只有一个私有构造函数，无法被实例化。</p><h3>核心函数分析</h3><p>在分析LockSupport函数之前，先引入sun.misc.Unsafe类中的park和unpark函数，因为LockSupport的核心函数都是基于Unsafe类中定义的park和unpark函数，下面给出两个函数的定义:</p><pre><code class="java">public native void park(boolean isAbsolute, long time);
public native void unpark(Thread thread);</code></pre><p>说明: 对两个函数的说明如下:</p><ul><li><p>park函数，阻塞线程，并且该线程在下列情况发生之前都会被阻塞:</p><ul><li>调用unpark函数，释放该线程的许可。</li><li>该线程被中断。</li><li>设置的时间到了。并且，当time为绝对时间时，isAbsolute为true，否则，isAbsolute为false。当time为0时，表示无限等待，直到unpark发生。</li></ul></li><li>unpark函数，释放线程的许可，即激活调用park后阻塞的线程。这个函数不是安全的，调用这个函数时要确保线程依旧存活。</li></ul><h4>park函数</h4><p>park函数有两个重载版本，方法摘要如下</p><pre><code class="java">public static void park()；
public static void park(Object blocker)；</code></pre><p>说明: 两个函数的区别在于park()函数没有没有blocker，即没有设置线程的parkBlocker字段。park(Object)型函数如下。</p><pre><code class="java">public static void park(Object blocker) {
    // 获取当前线程
    Thread t = Thread.currentThread();
    // 设置Blocker
    setBlocker(t, blocker);
    // 获取许可
    UNSAFE.park(false, 0L);
    // 重新可运行后再此设置Blocker
    setBlocker(t, null);
}</code></pre><p>说明: 调用park函数时，首先获取当前线程，然后设置当前线程的parkBlocker字段，即调用setBlocker函数，之后调用Unsafe类的park函数，之后再调用setBlocker函数。那么问题来了，为什么要在此park函数中要调用两次setBlocker函数呢? 原因其实很简单，调用park函数时，当前线程首先设置好parkBlocker字段，然后再调用Unsafe的park函数，此后，当前线程就已经阻塞了，等待该线程的unpark函数被调用，所以后面的一个setBlocker函数无法运行，unpark函数被调用，该线程获得许可后，就可以继续运行了，也就运行第二个setBlocker，把该线程的parkBlocker字段设置为null，这样就完成了整个park函数的逻辑。如果没有第二个setBlocker，那么之后没有调用park(Object blocker)，而直接调用getBlocker函数，得到的还是前一个park(Object blocker)设置的blocker，显然是不符合逻辑的。总之，必须要保证在park(Object blocker)整个函数执行完后，该线程的parkBlocker字段又恢复为null。所以，park(Object)型函数里必须要调用setBlocker函数两次。setBlocker方法如下。</p><pre><code class="java">private static void setBlocker(Thread t, Object arg) {
    // 设置线程t的parkBlocker字段的值为arg
    UNSAFE.putObject(t, parkBlockerOffset, arg);
}</code></pre><p>说明: 此方法用于设置线程t的parkBlocker字段的值为arg。</p><p>另外一个无参重载版本，park()函数如下。</p><pre><code class="java">public static void park() {
    // 获取许可，设置时间为无限长，直到可以获取许可
    UNSAFE.park(false, 0L);
}</code></pre><p>说明: 调用了park函数后，会禁用当前线程，除非许可可用。在以下三种情况之一发生之前，当前线程都将处于休眠状态，即下列情况发生时，当前线程会获取许可，可以继续运行。</p><ul><li>其他某个线程将当前线程作为目标调用 unpark。</li><li>其他某个线程中断当前线程。</li><li>该调用不合逻辑地(即毫无理由地)返回。</li></ul><h4>parkNanos函数</h4><p>此函数表示在许可可用前禁用当前线程，并最多等待指定的等待时间。具体函数如下。</p><pre><code class="java">public static void parkNanos(Object blocker, long nanos) {
    if (nanos &gt; 0) { // 时间大于0
        // 获取当前线程
        Thread t = Thread.currentThread();
        // 设置Blocker
        setBlocker(t, blocker);
        // 获取许可，并设置了时间
        UNSAFE.park(false, nanos);
        // 设置许可
        setBlocker(t, null);
    }
}</code></pre><p>说明: 该函数也是调用了两次setBlocker函数，nanos参数表示相对时间，表示等待多长时间。</p><h4>parkUntil函数</h4><p>此函数表示在指定的时限前禁用当前线程，除非许可可用, 具体函数如下:</p><pre><code class="java">public static void parkUntil(Object blocker, long deadline) {
    // 获取当前线程
    Thread t = Thread.currentThread();
    // 设置Blocker
    setBlocker(t, blocker);
    UNSAFE.park(true, deadline);
    // 设置Blocker为null
    setBlocker(t, null);
}</code></pre><p>说明: 该函数也调用了两次setBlocker函数，deadline参数表示绝对时间，表示指定的时间。</p><h4>unpark函数</h4><p>此函数表示如果给定线程的许可尚不可用，则使其可用。如果线程在 park 上受阻塞，则它将解除其阻塞状态。否则，保证下一次调用 park 不会受阻塞。如果给定线程尚未启动，则无法保证此操作有任何效果。具体函数如下:</p><pre><code class="java">public static void unpark(Thread thread) {
    if (thread != null) // 线程为不空
        UNSAFE.unpark(thread); // 释放该线程许可
}</code></pre><p>说明: 释放许可，指定线程可以继续运行。</p><h2>更深入的理解</h2><h3>与 synchronzed 的区别</h3><p><a href="https://link.segmentfault.com/?enc=jo3YUxDP9f05SJ%2B15isffA%3D%3D.kWBILxLBAbRfHmK0EBJKAVlwmJ51kCRfGUQ%2BLPrRjGlL3tYjrnfYERVI7hOaXM1wy7rGfAHk7YcztPdSICOItmxZOUurB4Is5DMcvymOr%2Fs%3D" rel="nofollow" target="_blank">synchronzed</a> 会使线程阻塞，线程会进入 BLOCKED 状态，而调用 LockSupprt 方法阻塞线程会使线程进入到 WAITING 状态。</p><h3>Thread.sleep()和Object.wait()的区别</h3><p>首先，我们先来看看Thread.sleep()和Object.wait()的区别，这是一个烂大街的题目了，大家应该都能说上来两点。</p><ul><li>Thread.sleep()不会释放占有的锁，Object.wait()会释放占有的锁；</li><li>Thread.sleep()必须传入时间，Object.wait()可传可不传，不传表示一直阻塞下去；</li><li>Thread.sleep()到时间了会自动唤醒，然后继续执行；</li><li>Object.wait()不带时间的，需要另一个线程使用Object.notify()唤醒；</li><li>Object.wait()带时间的，假如没有被notify，到时间了会自动唤醒，这时又分好两种情况，一是立即获取到了锁，线程自然会继续执行；二是没有立即获取锁，线程进入同步队列等待获取锁；</li></ul><p>其实，他们俩最大的区别就是Thread.sleep()不会释放锁资源，Object.wait()会释放锁资源。</p><h3>Object.wait()和Condition.await()的区别</h3><p>Object.wait()和Condition.await()的原理是基本一致的，不同的是Condition.await()底层是调用LockSupport.park()来实现阻塞当前线程的。</p><p>实际上，它在阻塞当前线程之前还干了两件事，一是把当前线程添加到条件队列中，二是“完全”释放锁，也就是让state状态变量变为0，然后才是调用LockSupport.park()阻塞当前线程。</p><h3>Thread.sleep()和LockSupport.park()的区别</h3><p>LockSupport.park()还有几个兄弟方法——parkNanos()、parkUtil()等，我们这里说的park()方法统称这一类方法。</p><ul><li>从功能上来说，Thread.sleep()和LockSupport.park()方法类似，都是阻塞当前线程的执行，且都不会释放当前线程占有的锁资源；</li><li>Thread.sleep()没法从外部唤醒，只能自己醒过来；</li><li>LockSupport.park()方法可以被另一个线程调用LockSupport.unpark()方法唤醒；</li><li>Thread.sleep()方法声明上抛出了InterruptedException中断异常，所以调用者需要捕获这个异常或者再抛出；</li><li>LockSupport.park()方法不需要捕获中断异常；</li><li>Thread.sleep()本身就是一个native方法；</li><li>LockSupport.park()底层是调用的Unsafe的native方法；</li></ul><h3>Object.wait()和LockSupport.park()的区别</h3><p>二者都会阻塞当前线程的运行，他们有什么区别呢? 经过上面的分析相信你一定很清楚了，真的吗? 往下看！</p><ul><li>Object.wait()方法需要在synchronized块中执行；</li><li>LockSupport.park()可以在任意地方执行；</li><li>Object.wait()方法声明抛出了中断异常，调用者需要捕获或者再抛出；</li><li>LockSupport.park()不需要捕获中断异常；</li><li>Object.wait()不带超时的，需要另一个线程执行notify()来唤醒，但不一定继续执行后续内容；</li><li>LockSupport.park()不带超时的，需要另一个线程执行unpark()来唤醒，一定会继续执行后续内容；</li></ul><p>park()/unpark()底层的原理是“二元信号量”，你可以把它相像成只有一个许可证的Semaphore，只不过这个信号量在重复执行unpark()的时候也不会再增加许可证，最多只有一个许可证。</p><h3>如果在wait()之前执行了notify()会怎样?</h3><p>如果当前的线程不是此对象锁的所有者，却调用该对象的notify()或wait()方法时抛出IllegalMonitorStateException异常；</p><p>如果当前线程是此对象锁的所有者，wait()将一直阻塞，因为后续将没有其它notify()唤醒它。</p><h3>如果在park()之前执行了unpark()会怎样?</h3><p>线程不会被阻塞，直接跳过park()，继续执行后续内容</p><h3>LockSupport.park()会释放锁资源吗?</h3><p>不会，它只负责阻塞当前线程，释放锁资源实际上是在Condition的await()方法中实现的。</p>]]></description></item><item>    <title><![CDATA[蓝易云cdn:在conda中如何查看安装的pytorch版本 蓝易云 ]]></title>    <link>https://segmentfault.com/a/1190000047608564</link>    <guid>https://segmentfault.com/a/1190000047608564</guid>    <pubDate>2026-02-13 00:02:22</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>蓝易云CDN：在 Conda 中如何查看安装的 PyTorch 版本 🧠</h2><p>在多环境开发场景中，确认 PyTorch 版本至关重要，尤其涉及 CUDA 兼容性与模型推理稳定性。以下提供&lt;span style="color:red"&gt;标准且可靠的三种方法&lt;/span&gt;，适用于当前主流 Conda 环境管理方式。</p><hr/><h2>一、方法一：使用 conda list 查询（推荐）🚀</h2><h3>1️⃣ 先激活目标环境</h3><pre><code class="bash">conda activate 环境名</code></pre><h4>命令解释：</h4><table><thead><tr><th>组件</th><th>作用</th></tr></thead><tbody><tr><td>conda</td><td>Conda 包管理工具</td></tr><tr><td>activate</td><td>激活指定虚拟环境</td></tr><tr><td>环境名</td><td>例如 pytorch_env</td></tr></tbody></table><p>如果不激活环境，查询到的是 base 环境内容。</p><hr/><h3>2️⃣ 查询 PyTorch 版本</h3><pre><code class="bash">conda list pytorch</code></pre><h4>命令解释：</h4><table><thead><tr><th>组件</th><th>作用</th></tr></thead><tbody><tr><td>conda list</td><td>查看当前环境已安装包</td></tr><tr><td>pytorch</td><td>过滤指定包</td></tr></tbody></table><p>示例输出：</p><pre><code>pytorch 2.2.1 py3.10_cuda11.8_cudnn8.7</code></pre><p>说明：</p><ul><li>版本号：2.2.1</li><li>Python版本：3.10</li><li>CUDA版本：11.8</li></ul><p>&lt;span style="color:red"&gt;这是最标准且准确的查询方式&lt;/span&gt;。</p><hr/><h2>二、方法二：通过 Python 内部查看 🐍</h2><p>在激活环境后执行：</p><pre><code class="bash">python</code></pre><p>进入交互模式后输入：</p><pre><code class="python">import torch
print(torch.__version__)</code></pre><h4>代码解释：</h4><table><thead><tr><th>代码</th><th>说明</th></tr></thead><tbody><tr><td>import torch</td><td>导入 PyTorch 模块</td></tr><tr><td>torch.<strong>version</strong></td><td>输出当前版本</td></tr></tbody></table><p>若输出：</p><pre><code>2.2.1+cu118</code></pre><p>表示：</p><ul><li>主版本 2.2.1</li><li>CUDA 11.8</li></ul><p>若无 CUDA 后缀，说明为 CPU 版本。</p><hr/><h2>三、方法三：查看所有相关组件版本 ⚙️</h2><pre><code class="bash">conda list | grep torch</code></pre><p>作用：</p><ul><li>同时查看 torchvision</li><li>torchtext</li><li>torchaudio</li></ul><p>示例：</p><pre><code>torchvision 0.17.1
torchaudio 2.2.1</code></pre><hr/><h2>四、完整判断流程图 🧩</h2><pre style="display:none;"><code class="mermaid">graph TD
A[激活环境] --&gt; B[conda list pytorch]
B --&gt; C{是否显示版本}
C --&gt;|是| D[确认CUDA版本]
C --&gt;|否| E[检查是否安装]
D --&gt; F[验证 python import torch]</code></pre><hr/><h2>五、版本与CUDA匹配原则 📊</h2><table><thead><tr><th>PyTorch版本</th><th>推荐CUDA版本</th></tr></thead><tbody><tr><td>2.2.x</td><td>11.8 / 12.1</td></tr><tr><td>2.1.x</td><td>11.8</td></tr><tr><td>1.13.x</td><td>11.6</td></tr></tbody></table><p>⚠️ 注意：</p><p>&lt;span style="color:red"&gt;PyTorch 的 CUDA 版本必须与系统驱动兼容&lt;/span&gt;。</p><p>可检查驱动：</p><pre><code class="bash">nvidia-smi</code></pre><p>解释：</p><ul><li>查看 GPU 驱动版本</li><li>判断是否支持当前 CUDA</li></ul><hr/><h2>六、核心总结 🎯</h2><p>在 Conda 中查看 PyTorch 版本的关键步骤：</p><ol><li>&lt;span style="color:red"&gt;激活正确环境&lt;/span&gt;</li><li>使用 &lt;span style="color:red"&gt;conda list pytorch&lt;/span&gt;</li><li>通过 &lt;span style="color:red"&gt;python + torch.<strong>version</strong> 双重验证&lt;/span&gt;</li></ol><p>开发中最常见错误不是版本太低，而是：</p><ul><li>查错环境</li><li>CUDA 与驱动不匹配</li></ul><p>严谨的做法永远是：<br/>环境确认 → 版本确认 → CUDA确认 → 驱动确认。</p><p>并发算力与框架稳定性，本质来自版本匹配，而不是版本最新。 🔍</p>]]></description></item><item>    <title><![CDATA[蓝易云cdn:dockers搭建基本服务 蓝易云 ]]></title>    <link>https://segmentfault.com/a/1190000047608566</link>    <guid>https://segmentfault.com/a/1190000047608566</guid>    <pubDate>2026-02-13 00:01:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>蓝易云CDN：Docker 搭建基本服务完整指南 🚀</h2><p>在现代运维体系中，Docker 已成为部署基础服务的标准工具。其核心优势是：&lt;span style="color:red"&gt;环境隔离、快速部署、可移植性强&lt;/span&gt;。下面给出标准化搭建流程与示例。</p><hr/><h2>一、安装 Docker（以 Ubuntu 为例）⚙️</h2><h3>1️⃣ 更新系统</h3><pre><code class="bash">sudo apt update</code></pre><p>解释：</p><ul><li><code>apt update</code>：同步软件仓库索引</li><li>确保后续安装使用最新包信息</li></ul><hr/><h3>2️⃣ 安装 Docker</h3><pre><code class="bash">sudo apt install -y docker.io</code></pre><p>解释：</p><ul><li><code>docker.io</code>：Ubuntu 官方仓库中的 Docker 引擎</li><li><code>-y</code>：自动确认安装</li></ul><hr/><h3>3️⃣ 启动并设置开机自启</h3><pre><code class="bash">sudo systemctl enable docker
sudo systemctl start docker</code></pre><p>解释：</p><table><thead><tr><th>命令</th><th>作用</th></tr></thead><tbody><tr><td>enable</td><td>开机自动启动</td></tr><tr><td>start</td><td>立即启动服务</td></tr></tbody></table><p>验证：</p><pre><code class="bash">docker --version</code></pre><p>若显示版本号说明安装成功。</p><hr/><h2>二、Docker 基本概念说明 🧠</h2><table><thead><tr><th>名称</th><th>说明</th></tr></thead><tbody><tr><td>Image</td><td>镜像，运行模板</td></tr><tr><td>Container</td><td>容器，运行实例</td></tr><tr><td>Volume</td><td>数据卷，持久存储</td></tr><tr><td>Network</td><td>网络模式</td></tr></tbody></table><p>简单模型公式：</p><pre><code>容器 = 镜像 + 运行参数 + 资源限制</code></pre><hr/><h2>三、搭建 Nginx 服务示例 🌐</h2><h3>1️⃣ 拉取镜像</h3><pre><code class="bash">docker pull nginx</code></pre><p>解释：</p><ul><li>从官方镜像仓库下载 nginx 镜像</li></ul><hr/><h3>2️⃣ 运行容器</h3><pre><code class="bash">docker run -d -p 80:80 --name mynginx nginx</code></pre><p>解释：</p><table><thead><tr><th>参数</th><th>含义</th></tr></thead><tbody><tr><td>-d</td><td>后台运行</td></tr><tr><td>-p 80:80</td><td>宿主机80映射容器80</td></tr><tr><td>--name</td><td>容器名称</td></tr><tr><td>nginx</td><td>使用的镜像</td></tr></tbody></table><p>访问服务器IP即可看到默认页面。</p><hr/><h2>四、搭建 MySQL 服务示例 🗄</h2><pre><code class="bash">docker run -d \
-p 3306:3306 \
--name mysql8 \
-e MYSQL_ROOT_PASSWORD=123456 \
-v /data/mysql:/var/lib/mysql \
mysql:8</code></pre><p>解释：</p><table><thead><tr><th>参数</th><th>说明</th></tr></thead><tbody><tr><td>-e</td><td>设置环境变量</td></tr><tr><td>MYSQL_ROOT_PASSWORD</td><td>root密码</td></tr><tr><td>-v</td><td>数据持久化映射</td></tr><tr><td>mysql:8</td><td>指定版本</td></tr></tbody></table><p>&lt;span style="color:red"&gt;数据必须挂载数据卷，否则删除容器数据会丢失&lt;/span&gt;。</p><hr/><h2>五、推荐使用 docker-compose 管理多服务 🧩</h2><p>创建 <code>docker-compose.yml</code>：</p><pre><code class="yaml">version: '3'
services:
  nginx:
    image: nginx
    ports:
      - "80:80"
  mysql:
    image: mysql:8
    environment:
      MYSQL_ROOT_PASSWORD: 123456
    volumes:
      - ./mysql:/var/lib/mysql</code></pre><p>启动：</p><pre><code class="bash">docker compose up -d</code></pre><p>解释：</p><ul><li><code>compose up</code>：创建并启动服务</li><li><code>-d</code>：后台运行</li></ul><hr/><h2>六、部署流程图 📊</h2><pre style="display:none;"><code class="mermaid">graph TD
A[安装Docker] --&gt; B[拉取镜像]
B --&gt; C[运行容器]
C --&gt; D[配置端口映射]
D --&gt; E[配置数据卷]
E --&gt; F[服务上线]</code></pre><hr/><h2>七、基础服务推荐结构 🔐</h2><table><thead><tr><th>服务类型</th><th>建议部署方式</th></tr></thead><tbody><tr><td>Web服务</td><td>Nginx容器</td></tr><tr><td>数据库</td><td>独立容器 + 数据卷</td></tr><tr><td>缓存</td><td>Redis容器</td></tr><tr><td>API</td><td>应用镜像</td></tr></tbody></table><hr/><h2>八、生产环境注意事项 ⚠️</h2><ol><li>&lt;span style="color:red"&gt;不要使用 latest 标签&lt;/span&gt;</li><li>必须挂载数据卷</li><li>限制容器资源：</li></ol><pre><code class="bash">--memory="1g" --cpus="1.0"</code></pre><p>解释：</p><ul><li>限制容器最大内存</li><li>限制CPU核心使用率</li></ul><hr/><h2>九、总结 🎯</h2><p>Docker 搭建基本服务的核心逻辑是：</p><ul><li>安装引擎</li><li>拉取镜像</li><li>配置端口</li><li>持久化数据</li><li>合理限制资源</li></ul><p>容器不是虚拟机，而是进程级隔离。<br/>真正的稳定部署来自：</p><p>&lt;span style="color:red"&gt;版本固定 + 数据持久化 + 资源限制&lt;/span&gt;。</p><p>基础架构稳，业务才稳。 🚀</p>]]></description></item><item>    <title><![CDATA[【MATLAB源码】6G：XL-MIMO 混合场信道估计仿真平台 3GPP仿真实验室 ]]></title>    <link>https://segmentfault.com/a/1190000047608372</link>    <guid>https://segmentfault.com/a/1190000047608372</guid>    <pubDate>2026-02-12 22:05:52</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>&lt;p align="center"&gt;<br/>  &lt;h1 align="center"&gt;Hybrid-Field XL-MIMO 混合场信道估计仿真平台&lt;/h1&gt;<br/>  &lt;p align="center"&gt;</p><pre><code>&lt;strong&gt;完整的混合场信道估计实现：建模 → 网格内恢复 → 离网细化 → 结果可视化&lt;/strong&gt;</code></pre><p>&lt;/p&gt;<br/>&lt;/p&gt;</p><hr/><h2>🚀 为什么选择本仿真平台？</h2><table><thead><tr><th align="left">痛点</th><th align="left">本平台解决方案</th></tr></thead><tbody><tr><td align="left">XL-MIMO 远近场共存，建模容易失配</td><td align="left">✅ <strong>远场 DFT + 近场极域联合字典</strong>，统一建模混合传播机理</td></tr><tr><td align="left">远场占比 ($\gamma$) 先验难以准确给定</td><td align="left">✅ 提供 <strong>无 ($\gamma$) 比例搜索</strong>，自动完成远近场路径分配</td></tr><tr><td align="left">离网优化容易震荡或发散</td><td align="left">✅ <code>SIGW</code> 内置 <strong>单调下降 + 回溯线搜索 + 坐标回退 + 岭正则</strong> 稳定机制</td></tr><tr><td align="left">只看均值曲线难以评估稳健性</td><td align="left">✅ 内置 <strong>CDF / Pareto / 相图 / 支撑图</strong> 四类强相关演示</td></tr><tr><td align="left">复现实验路径分散</td><td align="left">✅ 提供 <code>main_all_experiments</code> 与图集脚本，支持一键复现</td></tr></tbody></table><hr/><h2>🌟 核心价值</h2><table>
<tr>
<td width="50%">

### 📘 学术研究价值

- 混合场（远场+近场）统一信道建模
- 无先验 (\gamma) 的支撑搜索机制验证
- 网格内估计与离网细化协同流程完整复现
- 精度、复杂度、运行时间三维对比评估

</td>
<td width="50%">

### 🛠️ 工程应用价值

- 单天线与多天线两套实验链路
- 快速模式与完整模式双配置
- 自动保存图像与结果数据（不带日期命名）
- 中文详细注释，便于二次开发与教学演示

</td>
</tr>
</table><hr/><h2>⚡ 技术亮点</h2><h3>1) Hybrid-Field 估计系统架构</h3><pre><code class="text">┌───────────────────────────────────────────────────────────────────────────────┐
│                Hybrid-Field XL-MIMO 信道估计与可视化链路                     │
├───────────────────────────────────────────────────────────────────────────────┤
│                                                                               │
│  混合场信道生成 ──► 加噪观测 y ──► 联合字典构建 D=[Af, An]                   │
│      │                  │                   │                                  │
│  Far/Near/LoS       SNR 控制           远场 DFT + 近场极域                    │
│                                                                               │
│                 ┌──────────── 网格内恢复（On-grid）────────────┐              │
│                 │  Hybrid OMP / Hybrid SGP / 无γ比例搜索        │              │
│                 └────────────────────────────────────────────────┘              │
│                                       │                                       │
│                                       ▼                                       │
│                 ┌──────────── 离网细化（Off-grid SIGW）──────────┐            │
│                 │  数值梯度 + 回溯线搜索 + 坐标回退 + 岭回归      │            │
│                 └────────────────────────────────────────────────┘            │
│                                       │                                       │
│                                       ▼                                       │
│                 NMSE / SE / 复杂度 / CDF / Pareto / 相图 / 支撑图            │
└───────────────────────────────────────────────────────────────────────────────┘</code></pre><h3>2) 性能指标（本地 quick 配置实测，2026-02-12）</h3><table><thead><tr><th align="left">场景</th><th align="left">指标定义</th><th align="left">实测结果</th></tr></thead><tbody><tr><td align="left">单天线 SNR=0 dB</td><td align="left"><code>HF-SGP(no-γ)</code> 对比 <code>Off-grid HF-SGP(no-γ)</code></td><td align="left"><strong>+3.79 dB</strong> NMSE 增益（-4.16 dB → -7.95 dB）</td></tr><tr><td align="left">单天线 SNR=4 dB</td><td align="left"><code>HF-SGP(no-γ)</code> 对比 <code>Off-grid HF-SGP(no-γ)</code></td><td align="left"><strong>+6.01 dB</strong> NMSE 增益（-3.66 dB → -9.67 dB）</td></tr><tr><td align="left"><code>demo_polar_support_map</code></td><td align="left">单样本离网收益</td><td align="left"><strong>+3.95 dB</strong></td></tr><tr><td align="left"><code>demo_sigw_convergence</code></td><td align="left">单样本离网收益</td><td align="left"><strong>+4.39 dB</strong></td></tr><tr><td align="left"><code>demo_snr_gamma_phase_map</code></td><td align="left">离网增益为正的网格占比</td><td align="left"><strong>100%</strong></td></tr><tr><td align="left"><code>demo_nmse_cdf_pareto</code></td><td align="left">Off-grid 相对 HF-SGP 的均值收益/时延</td><td align="left"><strong>+1.56 dB</strong> / <strong>+21.04 ms</strong></td></tr></tbody></table><blockquote>📌 说明：以上数据来自项目当前代码在本机快速配置下的直接运行结果，用于展示方法趋势与工程可复现性。</blockquote><hr/><h2>🖥️ 运行环境</h2><h3>最低要求</h3><table><thead><tr><th align="left">项目</th><th align="left">要求</th></tr></thead><tbody><tr><td align="left"><strong>MATLAB 版本</strong></td><td align="left">R2021b 或更高</td></tr><tr><td align="left"><strong>必需工具箱</strong></td><td align="left">基础 MATLAB 即可（推荐安装常用信号处理相关工具箱）</td></tr><tr><td align="left"><strong>操作系统</strong></td><td align="left">Windows 10/11、macOS、Linux</td></tr><tr><td align="left"><strong>内存</strong></td><td align="left">8 GB+（大规模 Monte-Carlo 建议 16 GB+）</td></tr></tbody></table><h3>快速验证</h3><pre><code class="matlab">% 进入项目根目录后
run_smoke_test

% 一键运行强相关图集
run_related_figure_gallery(true)</code></pre><hr/><h2>📐 算法原理（项目对应版）</h2><h3>1) 混合场信道模型</h3><p>$$
\mathbf{h}=\sum_{\ell=1}^{L_f} \beta_{f,\ell}\,\mathbf{a}_f(\theta_{f,\ell})
+\sum_{\ell=1}^{L_n} \beta_{n,\ell}\,\mathbf{a}_n(r_{\ell},\theta_{n,\ell})
+\mathbf{h}_{\mathrm{LoS}}.
$$</p><h3>2) 联合字典建模</h3><p>$$
\mathbf{D}=[\mathbf{A}_f,\mathbf{A}_n],
\qquad
\min_{\mathbf{g}}\|\mathbf{y}-\mathbf{D}\mathbf{g}\|_2^2
\;\text{s.t.}\;\|\mathbf{g}\|_0\le K.
$$</p><h3>3) 无 ($\gamma$) 比例搜索</h3><p>$$
\hat{\gamma}
=\arg\min_{\gamma\in\Gamma}
\left(
\min_{\mathbf{g}:\operatorname{supp}(\mathbf{g})\in\mathcal{S}(\gamma)}
\|\mathbf{y}-\mathbf{D}\mathbf{g}\|_2^2
\right),
\quad
\Gamma=\left\{\frac{L-1}{L},\frac{L-2}{L},\dots,0\right\}.
$$</p><h3>4) SIGW 离网细化目标</h3><p>$$
J(\Theta,\mathbf{g})=\|\mathbf{y}-\mathbf{A}(\Theta)\mathbf{g}\|_2^2 + \lambda\|\mathbf{g}\|_2^2,
$$</p><p>$$
\mathbf{g}^*(\Theta)=\left(\mathbf{A}^H\mathbf{A}+\lambda\mathbf{I}\right)^{-1}\mathbf{A}^H\mathbf{y}.
$$</p><p>通过“回溯线搜索 + 坐标回退”保证优化过程稳定，缓解高 SNR 区域的网格失配误差。</p><hr/><h2>📁 项目结构</h2><pre><code class="text">hmimo ce/
├── main_all_experiments.m             # 一键总入口（主实验+演示）
│
├── src/
│   ├── common/                        # 配置、字典、信道、流形、路径、存图
│   │   ├── hf_default_config.m
│   │   ├── hf_build_dictionaries_single.m
│   │   ├── hf_build_dictionaries_multi.m
│   │   ├── hf_qua_codebook.m
│   │   ├── hf_generate_hybrid_channel_single.m
│   │   ├── hf_generate_hybrid_channel_multi.m
│   │   └── ...
│   │
│   ├── estimators/                    # OMP / SGP / Hybrid / SIGW
│   │   ├── hf_hybrid_omp.m
│   │   ├── hf_hybrid_omp_nogamma.m
│   │   ├── hf_hybrid_sgp.m
│   │   ├── hf_hybrid_sgp_nogamma.m
│   │   ├── hf_sigw_single.m
│   │   ├── hf_sigw_multi.m
│   │   └── ...
│   │
│   └── metrics/                       # NMSE / SE / 复杂度
│       ├── hf_compute_complexity.m
│       └── hf_compute_se_mr.m
│
├── experiments/                       # 主实验脚本
│   ├── run_single_snr_experiment.m
│   ├── run_multi_snr_experiment.m
│   ├── run_multi_se_experiment.m
│   ├── run_complexity_experiment.m
│   └── ...
│
├── demos/                             # 强相关演示图
│   ├── demo_polar_support_map.m
│   ├── demo_sigw_convergence.m
│   ├── demo_nmse_cdf_pareto.m
│   ├── demo_snr_gamma_phase_map.m
│   └── run_related_figure_gallery.m
│
├── docs/
│   ├── 算法文档.md
│   ├── 代码文档.md
│
└── results/
    ├── data/                          # .mat 结果文件
    └── figures/                       # 自动保存图像（无日期命名）</code></pre><p><strong>代码统计（当前工程）</strong>：</p><ul><li><code>40</code> 个 <code>.m</code> 文件</li><li>约 <code>4085</code> 行 MATLAB 代码</li><li>核心模块全部中文详细注释</li></ul><hr/><h2>🧪 仿真演示</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608374" alt="multi_se_vs_snr.png" title="multi_se_vs_snr.png"/><img referrerpolicy="no-referrer" src="/img/remote/1460000047608375" alt="single_nmse_vs_paths.png" title="single_nmse_vs_paths.png" loading="lazy"/><img referrerpolicy="no-referrer" src="/img/remote/1460000047608376" alt="single_nmse_vs_snr.png" title="single_nmse_vs_snr.png" loading="lazy"/><img referrerpolicy="no-referrer" src="/img/remote/1460000047608377" alt="demo_nmse_cdf.png" title="demo_nmse_cdf.png" loading="lazy"/><img referrerpolicy="no-referrer" src="/img/remote/1460000047608378" alt="demo_pareto_tradeoff.png" title="demo_pareto_tradeoff.png" loading="lazy"/><img referrerpolicy="no-referrer" src="/img/remote/1460000047608379" alt="demo_polar_support_dual.png" title="demo_polar_support_dual.png" loading="lazy"/><img referrerpolicy="no-referrer" src="/img/remote/1460000047608380" alt="demo_far_support_compare.png" title="demo_far_support_compare.png" loading="lazy"/></p><hr/><h2>✅ 您将获得</h2><table><thead><tr><th align="left">内容</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left"><strong>完整混合场源码</strong></td><td align="left">远场/近场字典、信道生成、OMP/SGP、离网细化全覆盖</td></tr><tr><td align="left"><strong>双层文档体系</strong></td><td align="left"><code>算法文档.md/.docx</code> + <code>代码文档.md</code> + 本 <code>项目文档.md</code></td></tr><tr><td align="left"><strong>强相关演示图集</strong></td><td align="left">支撑图、收敛图、CDF/Pareto、SNR-γ 相图</td></tr><tr><td align="left"><strong>可复现实验脚本</strong></td><td align="left">单天线、多天线、SE、复杂度、一键总入口</td></tr><tr><td align="left"><strong>工程化输出机制</strong></td><td align="left">自动存图、自动存 <code>mat</code>、命名稳定（无日期）</td></tr><tr><td align="left"><strong>可扩展开发骨架</strong></td><td align="left">新算法、新配置、新图表可按现有接口平滑扩展</td></tr></tbody></table><hr/><h2>▶️ 一键运行建议</h2><pre><code class="matlab">% 1) 基础冒烟验证
run_smoke_test

% 2) 单天线核心性能
run_single_snr_experiment(false)

% 3) 多天线核心性能
run_multi_snr_experiment(false)

% 4) 频谱效率与复杂度
run_multi_se_experiment(false)
run_complexity_experiment

% 5) 强相关图集
run_related_figure_gallery(true)

% 6) 全部任务一键执行
main_all_experiments</code></pre><hr/><h2>🛒 获取方式</h2><p>本文代码仅为核心片段，完整版工程已整理好。 关注公众号 【<strong>3GPP仿真实验室</strong>】进行获取。</p>]]></description></item><item>    <title><![CDATA[macOS Tahoe 26.3 (25D125) 正式版 ISO、IPSW、PKG 下载 sysi]]></title>    <link>https://segmentfault.com/a/1190000047608392</link>    <guid>https://segmentfault.com/a/1190000047608392</guid>    <pubDate>2026-02-12 22:04:51</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>macOS Tahoe 26.3 (25D125) 正式版 ISO、IPSW、PKG 下载</p><p>Liquid Glass 惊艳新设计亮相，电话 app 和实时活动丰富连续互通体验，聚焦搜索迎来最大更新</p><p>请访问原文链接：<a href="https://link.segmentfault.com/?enc=zoxEb0GLtG0I7nIlPI%2FPJA%3D%3D.fRQmoElu23JRTMEPt6w1fFuWjrWddVelxDYi9juRl3%2B3NMLv8WKmUkjvIauyniyn" rel="nofollow" target="_blank">https://sysin.org/blog/macos-tahoe/</a> 查看最新版。原创作品，转载请保留出处。</p><p>作者主页：<a href="https://link.segmentfault.com/?enc=q61BZJTWVeHyzbL15gNtBg%3D%3D.bv3J8YCdFUvKYp9rPGYzj%2Fh0pttu7jSGzWOanWLT3K0%3D" rel="nofollow" target="_blank">sysin.org</a></p><hr/><p>2026 年 2 月 12 日凌晨，Apple 发布 iOS/iPadOS/macOS/watchOS/tvOS/visonOS 全平台 26.3 版本更新。macOS Tahoe 26.3 此次为常规问题修复和安全更新。</p><h2>macOS Tahoe 让 Mac 更强大 更高效 更智能</h2><p>惊艳新设计亮相，电话 app 和实时活动丰富连续互通体验，聚焦搜索迎来最大更新</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000046624380" alt="16 英寸 MacBook Pro、iMac 和 13 英寸 MacBook Air。" title="16 英寸 MacBook Pro、iMac 和 13 英寸 MacBook Air。"/></p><p>macOS Tahoe 26 推出精美新设计、丰富的连续互通体验及更多功能，强势助推生产力。</p><p><strong>加利福尼亚州，库比提诺</strong> Tim Cook 领导的 Apple 今日预览了新一代 macOS——macOS Tahoe 26，推出惊艳新设计和诸多强大功能，赋能用户完成更多任务。macOS 的新设计让桌面、程序坞、app  内导览和工具栏等经典元素更加灵动活泼、赏心悦目且契合用户个性需求，同时延续了原有的熟悉感。用户可使用更新版控制中心和文件夹、app  图标与小组件的新色彩选项，进一步打造个性化体验。随着 Mac 版电话 app  的推出，连续互通功能进一步提升，用户可轻松使用最近通话、通讯录和语音留言等 iPhone 版电话 app  的全部功能，以及通话筛选和通话保留助理等新功能 (sysin)。依托 iPhone 实时活动，用户可直接在 Mac  上实时掌握正在进行的活动，如航班信息等。聚焦搜索迎来迄今最大更新，用户现可直接执行数百项操作，如发送电子邮件或创建备忘录等，并利用全新浏览体验更快捷地访问内容。</p><p>“macOS 是 Mac 的核心与灵魂，Tahoe 则将深受用户喜爱的功能发扬光大。无论资深用户还是 Mac  新手，都能借助更多功能提高效率，更顺畅地利用 Mac 和 iPhone 协同工作。”Apple 软件工程高级副总裁 Craig  Federighi 表示，“令人惊艳的新设计、奇妙的连续互通体验、聚焦搜索的强大提升、更多智能快捷指令和 Apple 智能的更新让 Mac  体验更胜以往。”</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000046624381" alt="一台 iMac 上显示着设计一新的主屏幕。" title="一台 iMac 上显示着设计一新的主屏幕。" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000046624382" alt="一台 MacBook Pro 上显示着深色调的新设计。" title="一台 MacBook Pro 上显示着深色调的新设计。" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000046624383" alt="一台 MacBook Pro 上显示着设计一新的主屏幕。 " title="一台 MacBook Pro 上显示着设计一新的主屏幕。 " loading="lazy"/></p><p>图：新设计解锁了个性化设置 Mac 的更多方式。</p><h2>macOS Tahoe 硬件兼容性列表</h2><p>笔者提示：“Apple Intelligence” 及相关功能要求 <a href="https://link.segmentfault.com/?enc=oGQmdWvHavaJD91Ro767Qw%3D%3D.WfejsiKv9WE6p4S3x9ww8MYjxvtCU5up7QF9dRkqNWfmAfwHLHOkVL4xybOTLGdp" rel="nofollow" target="_blank">搭载 Apple 芯片的 Mac 电脑</a>。</p><p>看看你的 Mac 是否能用 macOS Tahoe</p><p><a href="https://link.segmentfault.com/?enc=3hYwQlyQb79o28s%2F0CFxqA%3D%3D.Soxo8Qiqz8LSuFp8xpegU0vnTEMpf2%2BnBN0QwdsNjF0%3D" rel="nofollow" target="_blank">进一步了解 Mac&gt;</a></p><ul><li><strong>MacBook Air</strong> with Apple silicon 2020 and later <a href="https://link.segmentfault.com/?enc=qahyKhdMiXSdNzB2t5dCCg%3D%3D.WcgLFNZZXPkolOYEEKrVlqY4uyy7XAyH%2Fms7ieLAaK2AWjlDq6y%2F3Afpt9uyrpVp" rel="nofollow" target="_blank">进一步了解 &gt;</a></li><li><strong>MacBook Pro</strong> with Apple silicon (2020 and later) <a href="https://link.segmentfault.com/?enc=hVoBV%2BpTQK1sXZJSZz5Tnw%3D%3D.iRVolvyb2krOvkxViYLZ2eCjFuRZRnO67MIDG4glmwcnXILloOIEiGXD9vvIJSAO" rel="nofollow" target="_blank">进一步了解 &gt;</a></li><li><strong>MacBook Pro</strong> 2019 <a href="https://link.segmentfault.com/?enc=eg6NGDa5YL%2FaCe2%2BIzhojQ%3D%3D.o9mhCORlrvkxohOTVNgY54fLP84lTZSv%2F9FzC9KntchCGkSj285DZ4VEy1V7SLLW" rel="nofollow" target="_blank">进一步了解 &gt;</a></li><li><strong>MacBook Pro</strong> (13‑inch, 2020, Four Thunderbolt 3 ports) <a href="https://link.segmentfault.com/?enc=TslWxEiRjYKwEJvxAi3KEQ%3D%3D.tKgD3ACEedLQnia7Kgm9yK%2FedPGkvnUhJZ0LbsKd9oLYuVsTjybOcnW5jrSJvnuA" rel="nofollow" target="_blank">进一步了解 &gt;</a></li><li><strong>Mac mini</strong> 2020 and later <a href="https://link.segmentfault.com/?enc=WaxuyYdIBF8pSp95B3UunA%3D%3D.FuIdxCvXBXncaghdT13mdSn3VHuUzIA7c19YfYM%2FQUue8oSFwDp7zoO8jh6jB0Ya" rel="nofollow" target="_blank">进一步了解 &gt;</a></li><li><strong>Mac Studio</strong> 2022 <a href="https://link.segmentfault.com/?enc=s9BMOWWhSgtgI5J8vf48LA%3D%3D.NI0PyxNWpQHVevB%2BcA318tjgFI4TUlKgfGefS48dyMfcO0Vh1fI6w9NRnkSkocKQ" rel="nofollow" target="_blank">进一步了解 &gt;</a></li><li><strong>Mac Pro</strong> 2019 and later <a href="https://link.segmentfault.com/?enc=vSTako4FVLzciwAruYaY4A%3D%3D.fctK6fNdpozgbHkck8dLHbU2AlMoksGzzi9PF%2BWoik3gCMV9exND9JimxGAhOEcy" rel="nofollow" target="_blank">进一步了解 &gt;</a></li><li><strong>iMac</strong> 2020 and later <a href="https://link.segmentfault.com/?enc=e9WV8iCrjXCtO%2FQX8gGpJA%3D%3D.ZXJhCmQrVt591R6Z4hm%2BiGMBVwUCsORsxUDEiPzhM8yRrAs2lvfHss8p1oKyVyGC" rel="nofollow" target="_blank">进一步了解 &gt;</a></li></ul><p>如果你的 Mac 不在兼容性列表，参看：<a href="https://link.segmentfault.com/?enc=Vn9SgV0l20KEVoKB92qNtQ%3D%3D.tFlHcceEhIO6ogY4EW5rf75qjP4enGAvUe4g4ZFA%2BCgIEkZA%2FH%2FF5sojc3P6d4GNz%2Bsm7hqb0OlohKV9UlxCqg%3D%3D" rel="nofollow" target="_blank">在不受支持的 Mac 上安装 macOS Tahoe 26</a></p><h2>macOS Tahoe 版本历史</h2><p>Software Releases</p><ul><li>macOS Tahoe 26.3 (25D125) - 2026.02.11</li><li>macOS Tahoe 26.2 (25C56) - 2025.12.12</li><li>macOS Tahoe 26.1 (25B78) - 2025.11.03</li><li>macOS Tahoe 26.0.1 (25A362) - 2025.09.30</li><li>macOS Tahoe 26 (25A354) - 2025.09.15</li><li>macOS 26 RC (25A353) - 2025.09.09</li><li>macOS 26 beta 9 (25A5351b) - 2025.09.03</li><li>macOS 26 beta 8 (25A5349a) - 2025.08.25</li><li>macOS 26 beta 7 (25A5346a) - 2025.08.19</li><li>macOS 26 beta 6 (25A5338b) - 2025.08.12</li><li>macOS 26 beta 5 (25A5327h) - 2025.08.06</li><li>macOS 26 beta 4 (25A5316i) - 2025.07.22</li><li>macOS 26 beta 3 (25A5306g) - 2025.07.08</li><li>macOS 26 beta 2 (25A5295e) - 2025.06.23</li><li>macOS 26 beta (25A5279m) - 2025.06.09</li></ul><h2>下载 macOS Tahoe</h2><p>💡 <a href="https://link.segmentfault.com/?enc=ehJjVymVUfZspur%2Bu%2FV7Pw%3D%3D.2zezN2x8tGH8xZjxcHs4FLDb%2FEAcM8I0%2BFt9ELxfnwQ%3D" rel="nofollow" target="_blank">如何校验本站下载的文件的完整性</a></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047305036" alt="macOS Tahoe" title="macOS Tahoe" loading="lazy"/></p><h3>(1) ISO 格式软件包 (推荐)</h3><blockquote><p>本站原创可引导映像，可以在当前系统中安装或者升级，可以通过 USB 存储引导安装，也可以用于虚拟机安装。</p><p>此版本更多介绍请参看：<a href="https://link.segmentfault.com/?enc=1W3SRIHHQMfCGaXYrtnp%2FA%3D%3D.4rilMuIrWN3qvODQXCfOu9tv4F%2Fgihx5apIddwE8YiWiROwZ2zGoRG66qxpfBFRJ" rel="nofollow" target="_blank">macOS Tahoe 26 Boot ISO 原版可引导映像下载</a></p></blockquote><ul><li>macOS Tahoe 26.3 (25D125) - 2026.02.11</li><li>macOS Tahoe 26.2 (25C56) - 2025.12.12</li><li>macOS Tahoe 26.1 (25B78) - 2025.11.03</li><li>macOS Tahoe 26.0.1 (25A362) - 2025.09.30</li><li><p>macOS Tahoe 26 (25A354) - 2025.09.15</p><ul><li>下载地址：<a href="https://link.segmentfault.com/?enc=MITygpzXcQdkjyCyQHKzVQ%3D%3D.vmnJiieurov0UxJncun8t9CMhvJ1krOSRURYnqO%2Bf16LGdPDg5vTTgsS5bp6q1Ic" rel="nofollow" target="_blank">https://sysin.org/blog/macos-tahoe/</a></li></ul></li></ul><p>参看：<a href="https://link.segmentfault.com/?enc=5y47AE41xm25LxwBeJUpsA%3D%3D.yFXNyZNsOg2JHZsCNSXVqi3kQfl7u4luhXnb2EeocNaAm7%2F9gUy6ERYVc8%2FxoC85" rel="nofollow" target="_blank">如何在 Mac 和虚拟机上安装 macOS Sequoia、macOS Sonoma 和 macOS Ventura</a></p><h3>(2) PKG 格式软件包</h3><blockquote>该格式软件包双击运行后将自动安装在 <code>/Applications</code> 下。</blockquote><ul><li>macOS Tahoe 26.3 (25D125) - 2026.02.11</li><li>macOS Tahoe 26.2 (25C56) - 2025.12.12</li><li>macOS Tahoe 26.1 (25B78) - 2025.11.03</li><li>macOS Tahoe 26.0.1 (25A362) - 2025.09.30</li><li><p>macOS Tahoe 26 (25A354) - 2025.09.15</p><ul><li>下载地址：<a href="https://link.segmentfault.com/?enc=4haWcB%2Fpx9rIbO4CBhfhEg%3D%3D.%2Fmh%2BEQ2CDtWWnZJUDfTcp38z2S1qJDXx0BTYjDEgy9cysjRFbcXh81RK7mCPj%2FKA" rel="nofollow" target="_blank">https://sysin.org/blog/macos-tahoe/</a></li></ul></li></ul><h3>(3) IPSW 固件 (Apple 芯片 Mac 专用)</h3><blockquote>IPSW 格式为搭载 Apple 芯片的 Mac 专用映像，其他格式通用。</blockquote><p>适用于：<a href="https://link.segmentfault.com/?enc=B5tKBfmu%2FN2Zlbvfd99Cvg%3D%3D.OWW4genhdsoMyCGtw6yqPkcCBLOdCTWuuvNcmyR9D%2B35%2FosRMh0Q6pxWpgNOr5Vh" rel="nofollow" target="_blank">搭载 Apple 芯片的 Mac 电脑</a></p><p>参看：<a href="https://link.segmentfault.com/?enc=uyL3lQ%2Fmn%2FyCztJiUJ%2Bhww%3D%3D.GRAKeBO%2BQ10B7rJ5XFIc72EO6UzZQHR37xED7z7kGvYzYzM5AAKYAgVN9%2BeOwE4B" rel="nofollow" target="_blank">使用 DFU 模式修复或恢复 Mac 固件</a></p><ul><li>macOS Tahoe 26.3 (25D125) - 2026.02.11</li><li>macOS Tahoe 26.2 (25C56) - 2025.12.12</li><li>macOS Tahoe 26.1 (25B78) - 2025.11.03</li><li>macOS Tahoe 26.0.1 (25A362) - 2025.09.30</li><li><p>macOS Tahoe 26 (25A354) - 2025.09.15</p><ul><li>下载地址：<a href="https://link.segmentfault.com/?enc=n0Rdlici51SjcrhAe14ZEg%3D%3D.Q2UFa2SF2U%2B%2F2C4gjk8JLtit%2FnRZmrDk6ot58Etlk2Oq2rPjfKBXt9D8x6Kz6JCK" rel="nofollow" target="_blank">https://sysin.org/blog/macos-tahoe/</a></li></ul></li></ul><h3>(4) App Store 链接</h3><p><code>待上架</code></p><p>或者打开 App Store 搜索 “macOS Tahoe” 即可下载（下载的是当前最新版）。</p><h2>适用的 VMware 软件下载链接</h2><p>建议在以下版本的 VMware 软件中运行（Linux OVF 无需本站定制版可以正常运行，macOS 虚拟化如果不是 Mac 必须使用定制版才能运行，Windows OVF 需要定制版才能启用完整功能）：</p><ul><li><p>VMware vSphere：</p><ul><li>VMware <a href="https://link.segmentfault.com/?enc=edtuzNRXmYvfkd4tfSGIkg%3D%3D.5AWfi74BZCe0C0tZ1qLpnpC5Yp7iEbnureZBxjKp1WdEsxclVQkbZBXH34CVetWo" rel="nofollow" target="_blank">ESXi 9</a> or <a href="https://link.segmentfault.com/?enc=3VW3IN0QS4IjsqxpNYqFmA%3D%3D.MYGtYDsHwjzac1k4SJ5UuNPzTkQIEXRrlz8803DmGNUVm0eu%2B2kGamQTB8j1W6Io" rel="nofollow" target="_blank">with driver</a> &amp; <a href="https://link.segmentfault.com/?enc=JOHmlyVV5ks5LQ0YWv392w%3D%3D.7GSGK3D3IPstOj6gPthdbbBFKZc6gM3R4WBoR393XZfocTpIoVRZARDJakBMGth%2F" rel="nofollow" target="_blank">vCenter Server 9</a> &amp; <a href="https://link.segmentfault.com/?enc=SuDzyw9R9Lzm5ZgzMBHJeQ%3D%3D.LEOLhxErpU0llER1XlBR8%2FxMzwiDpLC1%2BBBY%2BushYvy8ULmlfGvJRLTEaIakhDbdkwZJ%2BwHQh4yYwsk%2F7nsp%2Bg%3D%3D" rel="nofollow" target="_blank">VCF Operations 9</a></li><li>VMware <a href="https://link.segmentfault.com/?enc=494mo6YvMFtt8La6JhU79g%3D%3D.IOfqOQVnTElW1iaWOtMAFf8oWYE39hcOKfnFDu0CdfedHNSKpUQpEht7roZy4io1" rel="nofollow" target="_blank">ESXi 8</a> or <a href="https://link.segmentfault.com/?enc=pTbX7RqXg59Pz4wKCDcB0Q%3D%3D.Ntmzu6ntIS7%2Bw6B0jyRu6inkEGZGhB0rwVErVqTxPuSwf5YVtqZV4DW3vIdOlTSd" rel="nofollow" target="_blank">with driver</a> &amp; <a href="https://link.segmentfault.com/?enc=fE2%2BXVrLfrdDojrO1IsRPw%3D%3D.e4r%2BJhvqBXTHnyOrk7OR1tuxyOfefqfgK1HC76uuOc1eRRxC%2FXS0d4bmpQr3joxX" rel="nofollow" target="_blank">vCenter Server 8</a></li><li>VMware <a href="https://link.segmentfault.com/?enc=EKB1nawXGZwtaINHHJE9Bw%3D%3D.9qHfRtbq9iixQTorhGtDCHnsMIcwivamFEljKMBZjKVMXK3E2iNc88NhSM7g0DHR" rel="nofollow" target="_blank">ESXi 7</a> or <a href="https://link.segmentfault.com/?enc=uAjtCbm%2FHPRmTZFQNXShDw%3D%3D.ThJC0W6aUK%2FKNvhohXWMlxkHemfRgyUq3rsht0eeyCr6bSEZft4USCP2cM1NP%2BD%2B" rel="nofollow" target="_blank">with driver</a> &amp; <a href="https://link.segmentfault.com/?enc=4FgcQoiF%2BjMFt1gtMCbVpw%3D%3D.Z8piBShQ%2FTa1pql1EbSVcR2yIMvr19Bnj8%2Bb%2BOssx2cJYfTV9tLw%2FI7D8acoCWU9" rel="nofollow" target="_blank">vCenter Server 7</a></li></ul></li><li>macOS：<a href="https://link.segmentfault.com/?enc=PrJnCpAC%2BdvABrxKI5gBWQ%3D%3D.aby%2BPkBMG2aOENDEe75GCfYBSP9KxTvYVO3xdebnW%2FOIMCPlnAhkN3jPF5JCAeGG" rel="nofollow" target="_blank">VMware Fusion</a></li><li>Linux：<a href="https://link.segmentfault.com/?enc=Il4pW1UfG0CN1c9zFgzDTA%3D%3D.VnwCudzWbEWfNgAmDq0JDWFUmIu1He20%2Fj1FPXQWs9AZS2Io1goaYqqfk2Jw2J0AuWRnpRL1qn1T8dM6dHEetg%3D%3D" rel="nofollow" target="_blank">VMware Workstation for Linux</a></li><li>Windows：<a href="https://link.segmentfault.com/?enc=GXUoZv16x61UukbRinvW8g%3D%3D.Kw9Vx1BB6Z%2FbqrRSFjJfBgWei5HuOgmJcp6I%2BWQxW81FMWHze6I9jon5QKyAnEtx8R%2BTa7DnaU08Yy%2FlRtXRUg%3D%3D" rel="nofollow" target="_blank">VMware Workstation for Windows</a></li></ul><p>macOS Tahoe 虚拟化解决方案，请参看：<a href="https://link.segmentfault.com/?enc=Or3CmUbeyRVK9DjnifZsTQ%3D%3D.u5%2FvMsM7oJGos3K8St%2BT3Egn4K%2FhcjXM1HBvmdLDFlAyzmklYe%2Fz0Qu9S1qIFBUh" rel="nofollow" target="_blank">macOS 26 Blank OVF - macOS Tahoe 虚拟化解决方案</a></p><h2>如何创建可引导的 macOS 安装器</h2><p>请访问：<a href="https://link.segmentfault.com/?enc=sIe8uS2HPJVRex0TLzZ2bg%3D%3D.6aMaow3v%2BVqPQblsUABSm8A7hwkrnunMGJH%2FIkyJP3S4dW9y5ckdXTyMLepmWSufCbVceuW2HO0qZ%2Ba53kyUbQ%3D%3D" rel="nofollow" target="_blank">如何创建可引导的 macOS 安装介质</a></p><p>更多：<a href="https://link.segmentfault.com/?enc=CUs3BbqRHeZ3wRtwVEbwMg%3D%3D.lpqEPgdNhBLFssM5wHqY7vTEK%2FFNAHcbxY4CWQBJegA%3D" rel="nofollow" target="_blank">macOS 下载汇总 (系统、应用和教程)</a></p>]]></description></item><item>    <title><![CDATA[macOS Tahoe 26.3 (25D125) Boot ISO 原版可引导映像下载 sysin]]></title>    <link>https://segmentfault.com/a/1190000047608395</link>    <guid>https://segmentfault.com/a/1190000047608395</guid>    <pubDate>2026-02-12 22:04:20</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>macOS Tahoe 26.3 (25D125) Boot ISO 原版可引导映像下载</p><p>Liquid Glass 惊艳新设计亮相，电话 app 和实时活动丰富连续互通体验，聚焦搜索迎来最大更新</p><p>请访问原文链接：<a href="https://link.segmentfault.com/?enc=Q6HvaYV70FEmmCNE5DHcaA%3D%3D.3i8jVpNnlZogpeaNbdfDkQbS8gBZCSUczojSerKtvyu%2FzDszdQ5AooYeJp%2B%2Bqgs2" rel="nofollow" target="_blank">https://sysin.org/blog/macos-tahoe-boot-iso/</a> 查看最新版。原创作品，转载请保留出处。</p><p>作者主页：<a href="https://link.segmentfault.com/?enc=AKvmOfWKqlg8VTcQiup8JA%3D%3D.PspjVxsTO9%2FKczHJvJZ8UE39pvJqOlyTY%2FzX6clzQSo%3D" rel="nofollow" target="_blank">sysin.org</a></p><hr/><p>2026 年 2 月 12 日凌晨，Apple 发布 iOS/iPadOS/macOS/watchOS/tvOS/visonOS 全平台 26.3 版本更新。macOS Tahoe 26.3 此次为常规问题修复和安全更新。</p><p>macOS Tahoe 26 让 Mac 更强大、更高效、更智能</p><p>惊艳新设计亮相，电话 app 和实时活动丰富连续互通体验，聚焦搜索迎来最大更新</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000046624380" alt="16 英寸 MacBook Pro、iMac 和 13 英寸 MacBook Air。" title="16 英寸 MacBook Pro、iMac 和 13 英寸 MacBook Air。"/></p><p>macOS Tahoe 26 推出精美新设计、丰富的连续互通体验及更多功能，强势助推生产力。</p><p><strong>加利福尼亚州，库比提诺</strong> Tim Cook 领导的 Apple 今日预览了新一代 macOS——macOS Tahoe 26，推出惊艳新设计和诸多强大功能，赋能用户完成更多任务。macOS 的新设计让桌面、程序坞、app  内导览和工具栏等经典元素更加灵动活泼、赏心悦目且契合用户个性需求，同时延续了原有的熟悉感。用户可使用更新版控制中心和文件夹、app  图标与小组件的新色彩选项，进一步打造个性化体验。随着 Mac 版电话 app  的推出，连续互通功能进一步提升，用户可轻松使用最近通话、通讯录和语音留言等 iPhone 版电话 app  的全部功能，以及通话筛选和通话保留助理等新功能 (sysin)。依托 iPhone 实时活动，用户可直接在 Mac  上实时掌握正在进行的活动，如航班信息等。聚焦搜索迎来迄今最大更新，用户现可直接执行数百项操作，如发送电子邮件或创建备忘录等，并利用全新浏览体验更快捷地访问内容。</p><p>“macOS 是 Mac 的核心与灵魂，Tahoe 则将深受用户喜爱的功能发扬光大。无论资深用户还是 Mac  新手，都能借助更多功能提高效率，更顺畅地利用 Mac 和 iPhone 协同工作。”Apple 软件工程高级副总裁 Craig  Federighi 表示，“令人惊艳的新设计、奇妙的连续互通体验、聚焦搜索的强大提升、更多智能快捷指令和 Apple 智能的更新让 Mac  体验更胜以往。”</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000046624381" alt="一台 iMac 上显示着设计一新的主屏幕。" title="一台 iMac 上显示着设计一新的主屏幕。" loading="lazy"/></p><p>图：新设计解锁了个性化设置 Mac 的更多方式。</p><h2>ISO 映像的优势</h2><p>相对于官方发布 PKG 映像（另有 IPSW 映像，但仅适用于 Apple 芯片），以及第三方制作的 DMG 映像，ISO 格式具有以下优势：</p><ul><li>可以直接拖拽到 Applications（应用程序）目录下（无需管理员权限），进行升级安装</li><li>可以直接双击挂载，执行命令写入 USB 存储设备或者其他卷，然后启动全新安装（无需拖拽到“应用程序”目录下）</li><li>可以直接启动虚拟机安装，介质本身为可引导映像</li><li>可以在 Windows 和 Linux 下写入 USB 存储设备，创建 USB 引导安装介质</li><li>跨平台支持，可以在任意操作系统中使用，其他格式仅限 macOS 专用</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000046878483" alt="macOS Tahoe in VMware" title="macOS Tahoe in VMware" loading="lazy"/></p><p>图：macOS Tahoe 运行在 Fusion 25H2 中，并开启了 Metal GPU 加速。</p><h2>下载 macOS Tahoe ISO</h2><p>💡 <a href="https://link.segmentfault.com/?enc=15WiPhMIHiPhAArXlHjz7A%3D%3D.9OtZdFLLoWflmKMM3n1g4Tdo10%2F%2FBh0WvtAPFPb0csI%3D" rel="nofollow" target="_blank">如何校验本站下载的文件的完整性</a></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047305036" alt="macOS Tahoe" title="macOS Tahoe" loading="lazy"/></p><blockquote>本站原创可引导映像，可以在当前系统中安装或者升级，可以通过 USB 存储引导安装，也可以用于虚拟机安装。</blockquote><ul><li>macOS Tahoe 26.3 (25D125) - 2026.02.11</li><li>macOS Tahoe 26.2 (25C56) - 2025.12.12</li><li>macOS Tahoe 26.1 (25B78) - 2025.11.03</li><li>macOS Tahoe 26.0.1 (25A362) - 2025.09.30</li><li><p>macOS Tahoe 26 (25A354) - 2025.09.15</p><ul><li>下载地址：<a href="https://link.segmentfault.com/?enc=QrcNtaZ2NlEOgsz5q9FYnA%3D%3D.lzv%2B6qp3pqEkildtJCqZIBleS4Ie3bDiHzhHdjE3udFNVZlvAJ15f3ORcWhsy9B2" rel="nofollow" target="_blank">https://sysin.org/blog/macos-tahoe-boot-iso/</a></li></ul></li></ul><p>参看：<a href="https://link.segmentfault.com/?enc=QCFCZhmi6RW7OAUaImQFnw%3D%3D.vH%2FhISQAMEk4wne0Ki4EB%2BupWS38RphII0RoSZMinLlLWdbcOCdPKg2rVsy8Gy1h" rel="nofollow" target="_blank">如何在 Mac 和虚拟机上安装 macOS Sequoia、macOS Sonoma 和 macOS Ventura</a></p><p>这里列出 ISO 启动映像下载链接，更多格式请访问以下地址：</p><ul><li><a href="https://link.segmentfault.com/?enc=fSWxh%2Bp2ZMYyK3v9piTByA%3D%3D.jbETOstrb4WhAYGuHoiVhmCZ0SxaYjYhn8sKV5kha7ptbrbrOycZQnsOCh9ZluqT" rel="nofollow" target="_blank">macOS Tahoe 26 ISO、IPSW、PKG 下载</a></li></ul><h2>macOS Tahoe 硬件兼容性列表</h2><p>笔者提示：“Apple Intelligence” 及相关功能要求 <a href="https://link.segmentfault.com/?enc=bu4qEh91X9sfgFMYv87SsA%3D%3D.W5OI0eGLxufpirQT6s8kH%2BHrS2A2RRg0T6d0A25veS5BhvEAyY8s65vb%2FlcM0v%2BE" rel="nofollow" target="_blank">搭载 Apple 芯片的 Mac 电脑</a>。</p><p>看看你的 Mac 是否能用 macOS Tahoe</p><p><a href="https://link.segmentfault.com/?enc=UM5zVgSCyuqF%2Bdh49d4TgA%3D%3D.%2FJjGRjpKnX9Lm8BTzWUi7t%2BO7dm%2FMKv6%2FygFHdawM%2Fk%3D" rel="nofollow" target="_blank">进一步了解 Mac&gt;</a></p><ul><li><strong>MacBook Air</strong> with Apple silicon 2020 and later <a href="https://link.segmentfault.com/?enc=fvddrb5PgOkcZQShafvUkQ%3D%3D.CnIcJBfNCIY8eFDvo8vBFEWMLiPMYCshCT4ZK3Ba5zn29l6L0PdM52WsdsjtWJQ2" rel="nofollow" target="_blank">进一步了解 &gt;</a></li><li><strong>MacBook Pro</strong> with Apple silicon (2020 and later) <a href="https://link.segmentfault.com/?enc=foHu%2Bomgj%2FUTedLlVcMv5A%3D%3D.1hF0Qz6nRcW3rhMKwuc6J4wPbCiEw51OXmNSBjYFi3l4n2q1NkyMCyvz%2F1xA6opn" rel="nofollow" target="_blank">进一步了解 &gt;</a></li><li><strong>MacBook Pro</strong> 2019 <a href="https://link.segmentfault.com/?enc=7QxXmTP02MMt4IFFe7jJoA%3D%3D.zfU09ZaKA2R3%2BjfpgLANZZVAWA2m8IeMY%2FO0xpmeZaEOEO7W830GMdKwqHZ1HtBM" rel="nofollow" target="_blank">进一步了解 &gt;</a></li><li><strong>MacBook Pro</strong> (13‑inch, 2020, Four Thunderbolt 3 ports) <a href="https://link.segmentfault.com/?enc=Muh2ySRn4iISovyFkpMgzA%3D%3D.p7egdTj4Wi%2BQyQIDbp8MmNZy1LSwOLmEfb9FzkJ9hdQq6FUZ64gYOgmK50DAEMc0" rel="nofollow" target="_blank">进一步了解 &gt;</a></li><li><strong>Mac mini</strong> 2020 and later <a href="https://link.segmentfault.com/?enc=Zqtf%2F%2F34Oo0SNlP85tp2bg%3D%3D.9roZKhPdWX4eGrnZ76bAkeWBrGhsqhIefiFp9LcZSCcgoBHeBR3QdSZxR354oTFM" rel="nofollow" target="_blank">进一步了解 &gt;</a></li><li><strong>Mac Studio</strong> 2022 <a href="https://link.segmentfault.com/?enc=pWDrMOq03IEVHWr5AmeCWA%3D%3D.pPrmm%2Bmqx5h6%2Bqzcwm1Jo6GlU8auAm9PmzHoxXOcyTnz2UDxd2oogBIBn5jXGDO5" rel="nofollow" target="_blank">进一步了解 &gt;</a></li><li><strong>Mac Pro</strong> 2019 and later <a href="https://link.segmentfault.com/?enc=PZunyAz%2BFA7mt3CcntyN%2BA%3D%3D.hd7V%2BA7i%2F2go75VCQjQPatxI%2F4ubJob0oE4ezbFscb%2F4CBv2vFHKCXEXVtmStxcM" rel="nofollow" target="_blank">进一步了解 &gt;</a></li><li><strong>iMac</strong> 2020 and later <a href="https://link.segmentfault.com/?enc=SrGnXsBefMrxPeK41%2BL6Fw%3D%3D.yRYmxmC4my9zWhx3QaoO83pFB29f1kdXL74NYvItEozYs8ntDU5urRwf6zkKwa%2BY" rel="nofollow" target="_blank">进一步了解 &gt;</a></li></ul><p>如果你的 Mac 不在兼容性列表，参看：<a href="https://link.segmentfault.com/?enc=leFF%2Fy%2FdsBrTeeKgkN650Q%3D%3D.69omGzqs6tpoF15SWStHixl1m5YSXCEkX1EPowvpgeA0hu4H2JfwLDdN75XMS4reIThWyctH2wlGB2ij7s71IQ%3D%3D" rel="nofollow" target="_blank">在不受支持的 Mac 上安装 macOS Tahoe 26</a></p><h2>适用的 VMware 软件下载链接</h2><p>建议在以下版本的 VMware 软件中运行（Linux OVF 无需本站定制版可以正常运行，macOS 虚拟化如果不是 Mac 必须使用定制版才能运行，Windows OVF 需要定制版才能启用完整功能）：</p><ul><li><p>VMware vSphere：</p><ul><li>VMware <a href="https://link.segmentfault.com/?enc=NXse2hkFM9fRFX%2FoWx5E3Q%3D%3D.AX7ZEbad8miHt5so6qYQg88IBKPR5DEezA2C1fLJrT%2B1Vl9QkMQg0LjIFYE0DNFX" rel="nofollow" target="_blank">ESXi 9</a> or <a href="https://link.segmentfault.com/?enc=gTZcN5fHmMsFoXKglDQ5Ug%3D%3D.%2BsP9NJUZua%2FuxLGUqG2yXU7H2kmxqk6sXftqbdeiebIVkXmGbeMvC47cgF34Ad1o" rel="nofollow" target="_blank">with driver</a> &amp; <a href="https://link.segmentfault.com/?enc=5KQrhKm5dEasjShnscfRNw%3D%3D.4n0VzdOQLwNSRizI1X7Ml45FfaBucME6ULecHrBcRF3172ZDmDJ%2FcUyuck8RgOdq" rel="nofollow" target="_blank">vCenter Server 9</a> &amp; <a href="https://link.segmentfault.com/?enc=S54v%2Fv9VHEwgbnU08fIe2g%3D%3D.Jm%2FuCgc7rmYFJzNEdcXFovN4M6Kw%2F3VkJxBYItvy%2BaOYN0u7ameFdz8UEnsWtQTPGHnGCQbXyfZryMQT5VzgAg%3D%3D" rel="nofollow" target="_blank">VCF Operations 9</a></li><li>VMware <a href="https://link.segmentfault.com/?enc=aKTcQYOIPPcyjmDlRJrkyA%3D%3D.QdJJCKL6Ar3LOpjHSeO49qNOjcYE%2FZkUl08IA5wjLwPixXllPokcFYmrvarD1HD5" rel="nofollow" target="_blank">ESXi 8</a> or <a href="https://link.segmentfault.com/?enc=lqhtH23YtlkL1%2FZEaiW0Vg%3D%3D.qr8JlEe5JHjjRlvO5JRpD83veU2URk%2Fpq2Z1mubT1sve%2Bnz254hWhlWPKxqtClLF" rel="nofollow" target="_blank">with driver</a> &amp; <a href="https://link.segmentfault.com/?enc=G29Hg5bpFQ9oE6ncML9iuw%3D%3D.%2BRG38uZsOi9U0WcpbSrUlXinZRgGZ8HVv2Zcws3BxdKsU3KOau0F0swB7OEkrTq0" rel="nofollow" target="_blank">vCenter Server 8</a></li><li>VMware <a href="https://link.segmentfault.com/?enc=3T3VeyeBJ7ECfuZA2Td7Mg%3D%3D.XYeofG%2FVeMqj%2BeMQ5DdpcfI%2BSWAeW7nTvbQImTBmXzPY5yxsBczEGPd7OeoLPMra" rel="nofollow" target="_blank">ESXi 7</a> or <a href="https://link.segmentfault.com/?enc=wtiPZtiHvxk1WIQAdXoImQ%3D%3D.akSmLFZaLfmXJiGVv3DO%2Bhdxk7Fl%2FrroUeLqQ4B6RHSSEds3FL54dSzIlqJAzocW" rel="nofollow" target="_blank">with driver</a> &amp; <a href="https://link.segmentfault.com/?enc=PtfFAmF3FbGJjYX5y0Xk1g%3D%3D.aj2pgcaLtx8IxgEtWS5My%2FUxzKCUR2w9ObvgfGu9P3Ev02xq0nvAcflWMua%2BG7xq" rel="nofollow" target="_blank">vCenter Server 7</a></li></ul></li><li>macOS：<a href="https://link.segmentfault.com/?enc=MgOp0ciRS322QE%2FNq%2BgYsw%3D%3D.SYkHEaN%2BNARsErZTgP6le8JQ7wOsxbm9pOYt32QSihXTvDDDNBAcikI6nGhmTTND" rel="nofollow" target="_blank">VMware Fusion</a></li><li>Linux：<a href="https://link.segmentfault.com/?enc=lCAq6adWVXDBsqFjxrvgUA%3D%3D.%2FeR9GvPf7BU5sYAcjQJI8MXNXTnLn6BfHKTbWcyBW%2BWzJtWXffIE4UqwrVKjQoyxOCL91Yrf721FVNZifq6bTQ%3D%3D" rel="nofollow" target="_blank">VMware Workstation for Linux</a></li><li>Windows：<a href="https://link.segmentfault.com/?enc=oPH09YSWmjOXzlQgvF1faA%3D%3D.jPcIuE%2FB1TGGR5XvohDJu3i0M5sgk7tyIu60o%2Bz9rggTwCnmEYmmbzFRwz7KvJIsUBk7eAqQ1EE2EFF6Z4XzhA%3D%3D" rel="nofollow" target="_blank">VMware Workstation for Windows</a></li></ul><p>macOS Tahoe 虚拟化解决方案，请参看：<a href="https://link.segmentfault.com/?enc=c3NqB5bG3XX%2FxkO4I2gvrA%3D%3D.aDfFFWLHnX0llW7phak6rH4hZ2TpSE%2FXSv5defdXdvIqsv9s5cg%2FbW%2BA54GtUGHQ" rel="nofollow" target="_blank">macOS 26 Blank OVF - macOS Tahoe 虚拟化解决方案</a></p><h2>如何创建可引导的 macOS 安装器</h2><p>请访问：<a href="https://link.segmentfault.com/?enc=vCAFKYbEnTjEC%2B%2FMW%2BwF4A%3D%3D.K%2FEUnm3DIapf11M8MD5T6IXg7wBBPb97kverD%2BdDmbw17XJ6smttyKlU6ZtPl10XgCszKz8Lt8%2FxD35ENDZT3g%3D%3D" rel="nofollow" target="_blank">如何创建可引导的 macOS 安装介质</a></p><p>更多：<a href="https://link.segmentfault.com/?enc=rVgIAup57Wjduy98O%2FPsvw%3D%3D.PB4KqDi6Lo8B%2BYQrx23LKT48kmm3eIrApZ45Qps3Mj0%3D" rel="nofollow" target="_blank">macOS 下载汇总 (系统、应用和教程)</a></p>]]></description></item><item>    <title><![CDATA[6G 物理层变天AFDM：与其在 OFDM 的死胡同里撞墙，不如换个坐标系“折叠”世界 3GPP仿真]]></title>    <link>https://segmentfault.com/a/1190000047608399</link>    <guid>https://segmentfault.com/a/1190000047608399</guid>    <pubDate>2026-02-12 22:03:43</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>我们先承认一个尴尬的事实：</p><p>面对 6G 提出的 <strong>1000 km/h（超高铁）</strong> 和 <strong>28000 km/h（低轨卫星）</strong> 愿景，统治了通信界二十年的王者——OFDM，已经尽力了。</p><p>依靠缩短符号时间、加大子载波间隔（SCS），这只是在物理极限的边缘疯狂试探。我们就像在暴风雨中修补一艘漏水的船，补丁打得越多，船越重（CP 开销大、频谱效率低）。</p><p><strong>是时候换一艘船了。</strong></p><p>今天，我们来聊聊物理层的一场“降维打击”： ​<strong>AFDM 仿射频分复用</strong>​ 。</p><hr/><h3>01. 完美的代价：OFDM 的基因缺陷</h3><p>一切悲剧的根源，早在我们选择 OFDM 的那一刻就注定了。</p><p>为了追求频谱效率的极致，我们在频域选择了​<strong>Sinc 函数</strong>​（$sin(x)/x$）作为子载波。</p><p>它长得并不像一根完美的针，而是一个带着无数“拖油瓶”的波形：</p><ul><li><strong>主瓣：</strong> 高耸入云，承载有用信息。</li><li><strong>旁瓣 (Side-lobes)：</strong> 像波纹一样向两边扩散，且衰减极其缓慢。</li></ul><p>OFDM 利用数学上的<strong>“正交性”</strong>，巧妙地让每一个子载波的<strong>峰值</strong>，精准地踩在其他所有子载波的<strong>零点 (Zero Crossing)</strong> 上。</p><p>这是一场​<strong>刀尖上的舞蹈</strong>​。</p><p>虽然旁瓣拖得很长，但在采样点那一瞬间，大家互不干扰。只要大家都不动，这个平衡就是完美的。</p><blockquote><strong>但在 6G 的世界里，“不动”成了一种奢望。</strong></blockquote><hr/><h3>02. 速度的诅咒：从 350km/h 到 7.6km/s</h3><p>当你在 350km/h 的高铁上，或者在 7.6km/s 的卫星下，物理世界开始对这个脆弱的数学平衡下手了。</p><p>大家通常认为多普勒只是​<strong>频率平移</strong>​。但在 OFDM 的眼里，这简直就是一场 <strong>“旁瓣的屠杀”</strong> 。</p><p>设想一下，当整个频谱发生微小的偏移（哪怕只是子载波间隔的 ​<strong>3%</strong> ​）：</p><ol><li><strong>零点错位：</strong> 接收机做 FFT 采样时，原本应该采到“0”的地方，现在采到了隔壁子载波的​<strong>旁瓣能量</strong>​。</li><li><strong>能量海啸：</strong> 由于 Sinc 函数的旁瓣拖得很长，<strong>远处的子载波</strong>也会把能量“泼”过来。</li><li><strong>ICI 爆发：</strong> 成千上万个子载波的干扰叠加在一起，形成了恐怖的 ​<strong>ICI（载波间干扰）</strong> ​。</li></ol><p><strong>(建议配图：OFDM 子载波正交性被破坏的示意图，展示波峰对不准零点)</strong></p><p>更绝望的是​<strong>低轨卫星（LEO）场景</strong>​。</p><p>当速度达到 ​<strong>7.6 km/s</strong>​，多普勒频移轻松突破 ​<strong>500 kHz</strong>​。</p><p>这直接导致​<strong>相干时间（Coherence Time）崩塌</strong>​。</p><p>这意味着：<strong>你的导频（Pilot）刚测完信道，还没来得及发数据，信道已经变了。</strong></p><p>传统的信道估计逻辑彻底断裂。</p><p>这时候，无论你把基站功率开多大，都没用了。因为干扰来自信号内部，信噪比（SINR）被锁死在一个 <strong>“地板”</strong> 上。</p><p><strong>网速瞬间从“千兆级”掉回“3G 时代”。</strong></p><hr/><h3>03. 第一性原理：把“正弦波”扔进垃圾桶</h3><p>OFDM 为什么怕多普勒？</p><p>因为它用的基底是 ​<strong>正弦波</strong>​——$e^{j2pi ft}$。</p><p>正弦波是静态的、永恒的。它唯一的弱点就是 <strong>“频率必须精准”</strong> 。</p><p>面对 6G 的超高动态，物理层先锋们做了一个违背祖宗的决定：</p><p><strong>抛弃正弦波，改用 Chirp（线性调频信号）。</strong><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047608401" alt="demo_afdm_basics.png" title="demo_afdm_basics.png"/></p><p>想象一下：</p><ul><li><strong>OFDM 的子载波</strong> 像是一排排<strong>垂直竖立</strong>的栅栏。风（多普勒）一吹，栅栏就歪了，互相碰撞。</li><li><strong>AFDM 的子载波</strong> 像是<strong>倾斜的</strong>多米诺骨牌。<br/>它的频率本身就是随时间线性变化的：$e^{j2pi (ft + frac{c}{2}t^2)}$。</li></ul><p>这里的 $c$ (Chirp Rate)，就是我们手中的​<strong>魔法钥匙</strong>​。</p><hr/><h3>04. DAFT：上帝的扭曲力场</h3><p>有了 Chirp 信号，我们如何调制数据？</p><p>欢迎来到数学的无人区—— ​<strong>DAFT (离散仿射傅里叶变换)</strong> ​。</p><p>别被名字吓到。它的物理本质极其性感：</p><p><strong>它在对时频平面（Time-Frequency Plane）进行“剪切” (Shearing) 和“旋转”。</strong></p><ul><li><strong>传统 FFT</strong> 是正正方方的网格。</li><li><strong>DAFT</strong> 通过调整参数 $c$，把网格<strong>扭曲</strong>成平行四边形，使其斜率与信道的<strong>多普勒频移斜率</strong>完美对齐。</li></ul><p><strong>见证奇迹的时刻：</strong></p><p>当信道的最大多普勒频移为 $f_{max}$ 时，我们只需要设置 Chirp 参数 $c = 2f_{max}/T$。</p><p>此时，原本在这个星球上狂暴变化的信道，在 DAFT 变换后的域里，竟然奇迹般地​<strong>变成了一条直线（时不变信道）</strong> ​！</p><blockquote><strong>我们没有消除多普勒，我们只是通过扭曲坐标系，把它“骗”过去了。</strong></blockquote><hr/><h3>05. 降维打击：全分集 (Full Diversity) 的暴力美学</h3><p>AFDM 最让通信人上瘾的，是它的抗衰落能力。</p><p>在 OFDM 中，如果一个子载波掉进深衰落（Deep Fade）的坑里，上面的数据就死定了。</p><p>但在 AFDM 中，<strong>每一个数据符号都“弥散”在整个带宽和时隙上。</strong></p><p>这就好比：</p><ul><li><strong>OFDM</strong> 是把鸡蛋放在 1000 个篮子里。摔了一个篮子，就碎一个鸡蛋。</li><li><strong>AFDM</strong> 是把鸡蛋打散，均匀地涂在 1000 个篮子上。摔碎几个篮子？无所谓，把剩下的拼起来，鸡蛋还是完整的。</li></ul><p><strong>结论炸裂：</strong></p><p>多普勒越大，多径越复杂，AFDM 的性能反而越好（分集阶数越高）。</p><p><strong>这是物理层对恶劣环境的最强嘲讽。</strong></p><hr/><h3>06. 终极杀手锏：它不再只是通信</h3><p>如果你以为 AFDM 只是为了让网速快一点，那你就把格局想小了。</p><p>AFDM 真正让 6G 颤抖的，是它的 <strong>“双重身份”</strong> 。</p><p>请回想一下，AFDM 的核心波形是什么？<strong>是 Chirp。</strong></p><p>在通信人眼里，这是新波形；但在<strong>雷达人</strong>眼里，这是 <strong>“老祖宗”</strong> ！</p><p><strong>一个惊人的宿命出现了：</strong></p><p>当我们在 6G 基站上发射 AFDM 波形时，我们实际上是在发射​<strong>雷达波</strong>​。</p><ul><li><strong>OFDM 是“盲人”：</strong> 它只能以此岸传到彼岸，不知道中间经历了什么。</li><li><strong>AFDM 是“睁眼玩家”：</strong> 它的波形天然具备​<strong>探测能力</strong>​。它在传输数据的同时，顺便把周围环境的 <strong>距离（Delay）</strong> 和 <strong>速度（Doppler）</strong> 扫描了一遍。</li></ul><p><strong>这就是 6G 的圣杯——通感一体化 (ISAC)。</strong></p><p>未来的基站，不需要你发导频告诉它你在哪。通过 AFDM 的回波，基站直接 <strong>“看”</strong> 到了你。</p><p>它知道这辆车在以 120km/h 变道，它知道那颗卫星在以 7.6km/s 靠近。</p><p>因为我看清了你，所以我能完美地调节坐标系来适应你。</p><p><strong>通信与感知，在 AFDM 的时延-多普勒域里，完成了物理层上的“灵肉合一”。</strong></p><hr/><h3>结语</h3><p>OFDM 统治了二十年，它把“静态”做到了极致。</p><p><strong>但 AFDM 的出现，标志着我们终于有勇气去拥抱“动态”。</strong></p><p>在 7.6km/s 的星链上，在 1000km/h 的真空管道里，正弦波的时代正在落幕。</p><p>那个属于 Chirp，属于 DAFT，属于 <strong>“御风而行”</strong> 的时代，才刚刚开始。</p><hr/><blockquote><p>“欢迎关注公众号 <strong>3GPP仿真实验室</strong>！这里是通信算法工程师的加油站。</p><p>我们不搬运新闻，只输出<strong>可运行的代码</strong>和<strong>深度标准解读</strong>。</p><p>👇 <strong>新人见面礼（后台回复关键词获取）：</strong></p><p>回复【LDPC】：获取 5G NR LDPC 编解码 MATLAB 代码（含注释）。<br/>回复【工具】：通信人减负神器：5G NR 帧结构与频点一键生成器（Python+Excel+Web三版）。<br/>回复【Pytorch】：获取 5G NR OFDM 链路 Pytorch 教学代码（含注释），助力人工智能 + 通信</p><p>让我们一起探索 6G 的无限可能。</p></blockquote>]]></description></item><item>    <title><![CDATA[【Matlab源码】6G候选波形：MIMO-OFDM-IM 增强仿真平台 3GPP仿真实验室 ]]></title>    <link>https://segmentfault.com/a/1190000047608413</link>    <guid>https://segmentfault.com/a/1190000047608413</guid>    <pubDate>2026-02-12 22:02:51</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>&lt;p align="center"&gt;<br/>  &lt;h1 align="center"&gt;📡 MIMO-OFDM-IM 空间扩展仿真平台&lt;/h1&gt;<br/>  &lt;p align="center"&gt;</p><pre><code>&lt;strong&gt;空间+频率双域索引调制，MIMO 分集与复用增益的完美结合&lt;/strong&gt;</code></pre><p>&lt;/p&gt;<br/>  &lt;p align="center"&gt;</p><pre><code>&lt;img src="https://img.shields.io/badge/MATLAB-R2021b+-blue?style=flat-square&amp;logo=mathworks" alt="MATLAB"/&gt;
&lt;img src="https://img.shields.io/badge/MIMO-8x8-green?style=flat-square" alt="MIMO"/&gt;
&lt;img src="https://img.shields.io/badge/Spatial-IM-orange?style=flat-square" alt="SIM"/&gt;
&lt;img src="https://img.shields.io/badge/Diversity-Order-red?style=flat-square" alt="Diversity"/&gt;</code></pre><p>&lt;/p&gt;<br/>&lt;/p&gt;</p><hr/><h2>📌 为什么选择本仿真平台？</h2><table><thead><tr><th align="left">痛点</th><th align="left">本平台解决方案</th></tr></thead><tbody><tr><td align="left">📚 SISO 分集阶数有限</td><td align="left">✅ <strong>MIMO 空间分集</strong>：多天线提供 Nr × Nt 分集阶数</td></tr><tr><td align="left">🔧 空间复用与索引调制难结合</td><td align="left">✅ <strong>空频双域索引</strong>：天线选择 + 子载波选择叠加</td></tr><tr><td align="left">📊 MIMO 检测复杂度高</td><td align="left">✅ <strong>分离检测算法</strong>：先空间后频域，复杂度大幅降低</td></tr><tr><td align="left">⚡ 信道模型单一</td><td align="left">✅ <strong>MIMO 瑞利信道</strong>：独立衰落建模，真实场景验证</td></tr><tr><td align="left">📡 缺乏分集增益量化</td><td align="left">✅ <strong>BER 曲线斜率分析</strong>，直观展示分集阶数提升</td></tr></tbody></table><hr/><h2>🎯 核心价值</h2><table>
<tr>
<td width="50%">

### 🔬 学术研究价值

- MIMO-IM 空频联合调制理论验证
- 空间分集与频率分集叠加效应
- ML/分离/迭代检测算法对比
- 大规模 MIMO 性能边界探索

</td>
<td width="50%">

### 💼 工程应用价值

- 支持 2×2 到 8×8 天线配置
- 可配置激活天线数量
- 适用于 5G/6G 多天线系统
- 完整的 MIMO 收发链路

</td>
</tr>
</table><hr/><h2>⚡ 技术亮点</h2><h3>🌊 MIMO-OFDM-IM 双域架构</h3><pre><code class="text">┌─────────────────────────────────────────────────────────────────┐
│                 MIMO-OFDM-IM 空频双域索引调制                    │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   【空间域索引】        【频率域索引】        【联合传输】       │
│                                                                 │
│   ┌─ Tx1 ★ ─┐          ┌─ f1 ● ─┐                              │
│   │  Tx2 ○  │          │  f2 ○  │                              │
│   │  Tx3 ○  │    +     │  f3 ● ─┼──► X[Nt, Nf] 空频符号矩阵    │
│   └─ Tx4 ★ ─┘          └─ f4 ○  ┘                              │
│                                                                 │
│   C(Nt,Na) 空间         C(n,k) 频域          联合索引比特        │
│   索引模式             索引模式                                  │
│                                                                 │
│         ┌──────── MIMO 瑞利信道 H[Nr×Nt] ────────┐              │
│         │      各天线对独立衰落                    │              │
│         └─────────────────────────────────────────┘              │
│                                                                 │
│   【接收端】 Y = HX + N ──► [空间检测] ──► [频域检测] ──► 恢复   │
└─────────────────────────────────────────────────────────────────┘</code></pre><h3>📊 分集增益对比 (n=4, k=2, QPSK)</h3><table><thead><tr><th align="center">配置</th><th align="center">空间分集</th><th align="center">频率分集</th><th align="center">总分集阶数</th><th align="center">BER@15dB</th></tr></thead><tbody><tr><td align="center">SISO-IM</td><td align="center">1</td><td align="center">n-k+1=3</td><td align="center"><strong>3</strong></td><td align="center">2.5e-3</td></tr><tr><td align="center">2×2 MIMO-IM</td><td align="center">4</td><td align="center">3</td><td align="center"><strong>12</strong></td><td align="center">1.8e-5</td></tr><tr><td align="center">4×4 MIMO-IM</td><td align="center">16</td><td align="center">3</td><td align="center"><strong>48</strong></td><td align="center">&lt; 1e-6</td></tr></tbody></table><blockquote>💡 <strong>分集倍增</strong>：MIMO-IM 总分集阶数 = Nr × Nt × (n-k+1)，相比 SISO 呈倍数增长。</blockquote><hr/><h2>🖥️ 运行环境</h2><h3>最低要求</h3><table><thead><tr><th align="left">项目</th><th align="left">要求</th></tr></thead><tbody><tr><td align="left"><strong>MATLAB版本</strong></td><td align="left">R2021b 或更高</td></tr><tr><td align="left"><strong>必需工具箱</strong></td><td align="left">Communications Toolbox</td></tr><tr><td align="left"><strong>基础依赖</strong></td><td align="left">P1 基础包</td></tr><tr><td align="left"><strong>内存</strong></td><td align="left">8 GB+ (大规模 MIMO 建议 16GB)</td></tr></tbody></table><h3>快速验证</h3><pre><code class="matlab">&gt;&gt; cd packages/P4_空间扩展包
&gt;&gt; setup_path
&gt;&gt; generate_ber_plots</code></pre><hr/><h2>🧠 算法原理</h2><h3>MIMO-IM 系统模型</h3><p><strong>发射端</strong>：</p><p>$$
\mathbf{X}[N_t \times N_f] = \text{SpatialMapper}(\mathbf{s}_{spatial}) \odot \text{FreqMapper}(\mathbf{s}_{freq})
$$</p><p><strong>接收端</strong>：</p><p>$$
\mathbf{Y} = \mathbf{H}\mathbf{X} + \mathbf{N}
$$</p><h3>空间索引比特</h3><p>$$
p_{spatial} = \lfloor \log_2 C(N_t, N_a) \rfloor
$$</p><h3>总比特数</h3><p>$$
p_{total} = p_{spatial} + G \cdot (p_1 + p_2)
$$</p><p>其中 G 为频域子块数。</p><h3>分集阶数分析</h3><p><strong>SISO-IM</strong>: $d = n - k + 1$</p><p><strong>MIMO-IM</strong>: $d = N_r \cdot N_t \cdot (n - k + 1)$</p><hr/><h2>📁 项目结构</h2><pre><code class="text">P4_空间扩展包/
├── 📂 mimo/                         # MIMO 索引调制
│   ├── mimo_im_modulator.m          #   🚀 MIMO-IM 调制器
│   ├── mimo_im_demodulator.m        #   🚀 MIMO-IM 解调器
│   ├── spatial_index_mapper.m       #   空间索引映射
│   └── spatial_index_demapper.m     #   空间索引解映射
│
├── 📂 channels/                     # MIMO 信道模型
│   ├── mimo_rayleigh_channel.m      #   MIMO 瑞利衰落信道
│   └── mimo_awgn_channel.m          #   MIMO AWGN 信道
│
├── 📂 core/                         # 继承 P1 核心模块
├── 📂 config/                       # 配置 (扩展 MIMO 参数)
│
├── 📂 docs/                         # 文档
│   ├── 算法文档.md                   #   📘 MIMO-IM 原理推导
│   ├── 代码文档.md                   #   📒 接口说明
│   └── 项目文档.md                   #   📗 本文档
│
├── generate_plots.m                 # 📊 基础 BER 曲线
└── generate_ber_plots.m             # 📊 MIMO vs SISO 分集对比</code></pre><p><strong>代码统计</strong>：</p><ul><li>📄 20+ 个核心 MATLAB 文件</li><li>📝 2000+ 行精炼代码</li><li>💬 100% 中文详细注释</li></ul><hr/><h2>🎬 仿真演示</h2><h3>一键运行</h3><pre><code class="matlab">&gt;&gt; cd packages/P4_空间扩展包
&gt;&gt; setup_path
&gt;&gt; generate_ber_plots</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608415" alt="p4_mimo_vs_siso.png" title="p4_mimo_vs_siso.png"/><img referrerpolicy="no-referrer" src="/img/remote/1460000047608416" alt="p4_spatial_heatmap.png" title="p4_spatial_heatmap.png" loading="lazy"/></p><hr/><h2>📦 您将获得</h2><table><thead><tr><th align="left">内容</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">📁 <strong>完整源码</strong></td><td align="left">MIMO-IM 空频双域调制解调</td></tr><tr><td align="left">📖 <strong>原理文档</strong></td><td align="left">空间索引、分集增益数学推导</td></tr><tr><td align="left">🚀 <strong>双域索引</strong></td><td align="left">空间+频率联合索引调制</td></tr><tr><td align="left">📊 <strong>分集验证</strong></td><td align="left">SISO vs MIMO 分集增益对比</td></tr><tr><td align="left">🔧 <strong>灵活天线</strong></td><td align="left">支持 2×2 到 8×8 配置</td></tr><tr><td align="left">📡 <strong>MIMO 信道</strong></td><td align="left">独立瑞利衰落信道建模</td></tr></tbody></table><hr/><h2>🎯 典型应用场景</h2><table><thead><tr><th align="left">场景</th><th align="left">推荐配置</th><th align="left">优势</th></tr></thead><tbody><tr><td align="left">低功耗 IoT</td><td align="left">2×2, Na=1</td><td align="left">分集增益 + 能效</td></tr><tr><td align="left">移动终端</td><td align="left">4×4, Na=2</td><td align="left">平衡性能与复杂度</td></tr><tr><td align="left">5G 基站</td><td align="left">8×8, Na=4</td><td align="left">最大分集增益</td></tr></tbody></table><hr/><h2>🛒 获取方式</h2><p>本文代码仅为核心片段，完整版工程已整理好。 关注公众号 【<strong>3GPP仿真实验室</strong>】进行获取。</p><h2>📚 参考文献</h2><ol><li><strong>E. Başar et al.</strong> (2013): "OFDM with Index Modulation for MIMO Systems." <em>IEEE Trans. Signal Process.</em>, vol. 61, no. 22.</li><li><strong>J. Crawford et al.</strong> (2017): "MIMO Spatial Modulation with Index Modulation." <em>IEEE Trans. Veh. Technol.</em>, vol. 66, no. 3.</li><li><strong>Y. Xiao et al.</strong> (2018): "OFDM with Flexible Space-Frequency Index Modulation." <em>IEEE Trans. Wireless Commun.</em>, vol. 17, no. 7.</li><li><strong>R. Mesleh et al.</strong> (2008): "Spatial Modulation." <em>IEEE Trans. Veh. Technol.</em>, vol. 57, no. 4.</li></ol>]]></description></item><item>    <title><![CDATA[【Matlab源码】6G候选波形：OFDM-IM 增强仿真平台 GIM、MM、IQ 3GPP仿真实验]]></title>    <link>https://segmentfault.com/a/1190000047608420</link>    <guid>https://segmentfault.com/a/1190000047608420</guid>    <pubDate>2026-02-12 22:02:04</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>&lt;p align="center"&gt;<br/>  &lt;h1 align="center"&gt;📈 OFDM-IM 容量增强仿真平台&lt;/h1&gt;<br/>  &lt;p align="center"&gt;</p><pre><code>&lt;strong&gt;GIM + MM + IQ 三大容量扩展技术，突破传统索引调制比特率极限&lt;/strong&gt;</code></pre><p>&lt;/p&gt;<br/>  &lt;p align="center"&gt;</p><pre><code>&lt;img src="https://img.shields.io/badge/MATLAB-R2021b+-blue?style=flat-square&amp;logo=mathworks" alt="MATLAB"/&gt;
&lt;img src="https://img.shields.io/badge/GIM-Variable_k-green?style=flat-square" alt="GIM"/&gt;
&lt;img src="https://img.shields.io/badge/MM-Multi_Mode-orange?style=flat-square" alt="MM"/&gt;
&lt;img src="https://img.shields.io/badge/IQ-Independent-red?style=flat-square" alt="IQ"/&gt;</code></pre><p>&lt;/p&gt;<br/>&lt;/p&gt;</p><hr/><h2>📌 为什么选择本仿真平台？</h2><table><thead><tr><th align="left">痛点</th><th align="left">本平台解决方案</th></tr></thead><tbody><tr><td align="left">📚 固定激活数限制索引空间</td><td align="left">✅ <strong>GIM 广义索引</strong>：可变激活数，索引空间扩大 2-4 倍</td></tr><tr><td align="left">🔧 调制阶数浪费额外比特</td><td align="left">✅ <strong>MM 多模调制</strong>：每个激活子载波携带模式选择比特</td></tr><tr><td align="left">📊 I/Q 资源耦合利用</td><td align="left">✅ <strong>IQ 独立索引</strong>：实部虚部分别索引，并行双倍效率</td></tr><tr><td align="left">⚡ 容量提升难以量化</td><td align="left">✅ 内置 <strong>容量分析对比工具</strong>，直观展示各技术增益</td></tr><tr><td align="left">📡 检测算法对应难</td><td align="left">✅ 每种技术配套 <strong>专用解调器</strong>，算法一一对应</td></tr></tbody></table><hr/><h2>🎯 核心价值</h2><table>
<tr>
<td width="50%">

### 🔬 学术研究价值

- 三大容量扩展技术完整实现
- 索引空间理论上界研究
- 频谱效率 vs 复杂度权衡分析
- 不同场景最优技术选择

</td>
<td width="50%">

### 💼 工程应用价值

- 高频谱效率需求场景首选
- 灵活的参数配置空间
- 结构化的技术对比框架
- 完整的收发链路验证

</td>
</tr>
</table><hr/><h2>⚡ 技术亮点</h2><h3>🌊 三大容量增强技术对比</h3><pre><code class="text">┌─────────────────────────────────────────────────────────────────┐
│                    容量增强技术对比                              │
├──────────────┬──────────────┬──────────────┬──────────────────┤
│   基础 IM    │     GIM      │      MM      │       IQ         │
├──────────────┼──────────────┼──────────────┼──────────────────┤
│ 固定 k 个    │ k ∈ [k1,k2]  │ 每个子载波   │ I/Q 独立索引     │
│ 激活子载波   │ 可变激活数   │ 独立选模式   │ 并行处理         │
├──────────────┼──────────────┼──────────────┼──────────────────┤
│   C(n,k)     │  Σ C(n,ki)  │ k × Nm 模式  │   2 × C(n,k)     │
│   索引数     │  索引空间大  │  比特倍增    │   双倍索引       │
└──────────────┴──────────────┴──────────────┴──────────────────┘</code></pre><h3>📊 容量对比 (n=4, k=2, M=4)</h3><table><thead><tr><th align="center">技术</th><th align="center">索引比特 p1</th><th align="center">数据比特 p2</th><th align="center">总比特/子块</th><th align="center">vs 基础 IM</th></tr></thead><tbody><tr><td align="center">基础 IM</td><td align="center">2</td><td align="center">4</td><td align="center"><strong>6</strong></td><td align="center">基准</td></tr><tr><td align="center">GIM (k∈[1,4])</td><td align="center">4</td><td align="center">~5</td><td align="center"><strong>9</strong></td><td align="center">+50%</td></tr><tr><td align="center">MM (4模式)</td><td align="center">2</td><td align="center">8</td><td align="center"><strong>10</strong></td><td align="center">+67%</td></tr><tr><td align="center">IQ</td><td align="center">4</td><td align="center">4</td><td align="center"><strong>8</strong></td><td align="center">+33%</td></tr></tbody></table><blockquote>💡 <strong>MM 最强容量</strong>：通过模式选择比特，每个激活子载波额外携带 log₂(Nm) 比特。</blockquote><hr/><h2>🖥️ 运行环境</h2><h3>最低要求</h3><table><thead><tr><th align="left">项目</th><th align="left">要求</th></tr></thead><tbody><tr><td align="left"><strong>MATLAB版本</strong></td><td align="left">R2021b 或更高</td></tr><tr><td align="left"><strong>必需工具箱</strong></td><td align="left">Communications Toolbox</td></tr><tr><td align="left"><strong>基础依赖</strong></td><td align="left">P1 基础包</td></tr><tr><td align="left"><strong>内存</strong></td><td align="left">4 GB+</td></tr></tbody></table><h3>快速验证</h3><pre><code class="matlab">&gt;&gt; cd packages/P3_容量增强包
&gt;&gt; setup_path
&gt;&gt; generate_plots_enhanced</code></pre><hr/><h2>🧠 算法原理</h2><h3>GIM 广义索引调制</h3><p><strong>核心思想</strong>：允许激活子载波数量可变，融合多种 C(n,k) 组合。</p><p><strong>索引空间</strong>：</p><p>$$
|\mathcal{S}_{GIM}| = \sum_{k=k_{min}}^{k_{max}} C(n,k)
$$</p><p><strong>索引比特</strong>：</p><p>$$
p_{1,GIM} = \lfloor \log_2 |\mathcal{S}_{GIM}| \rfloor
$$</p><h3>MM 多模索引调制</h3><p><strong>核心思想</strong>：每个激活子载波独立选择调制模式。</p><p><strong>总比特数</strong>：</p><p>$$
p_{MM} = p_1 + k \cdot (\log_2 N_m + \bar{m})
$$</p><p>其中 $\bar{m}$ 为各模式的平均数据比特。</p><h3>IQ 独立索引调制</h3><p><strong>核心思想</strong>：I 和 Q 分量使用独立的激活模式。</p><p><strong>索引比特</strong>：</p><p>$$
p_{1,IQ} = 2 \times \lfloor \log_2 C(n,k) \rfloor
$$</p><hr/><h2>📁 项目结构</h2><pre><code class="text">P3_容量增强包/
├── 📂 gim/                     # GIM 广义索引
│   ├── gim_modulator.m         #   🚀 GIM 调制器
│   ├── gim_demodulator.m       #   GIM 解调器
│   └── gim_table.m             #   可变激活索引表
│
├── 📂 mm/                      # MM 多模调制
│   ├── mm_modulator.m          #   🚀 MM 调制器
│   └── mm_demodulator.m        #   MM 解调器
│
├── 📂 iq/                      # IQ 独立索引
│   ├── iq_modulator.m          #   🚀 IQ 调制器
│   └── iq_demodulator.m        #   IQ 解调器
│
├── 📂 core/                    # 继承 P1 核心模块
├── 📂 config/                  # 配置 (扩展 GIM/MM/IQ 参数)
│
├── 📂 docs/                    # 文档
│   ├── 算法文档.md              #   📘 三技术原理推导
│   ├── 代码文档.md              #   📒 接口说明
│   └── 项目文档.md              #   📗 本文档
│
├── generate_plots.m            # 📊 容量对比曲线
└── generate_plots_enhanced.m   # 📊 MM 多模星座图</code></pre><p><strong>代码统计</strong>：</p><ul><li>📄 25+ 个核心 MATLAB 文件</li><li>📝 2500+ 行精炼代码</li><li>💬 100% 中文详细注释</li></ul><hr/><h2>🎬 仿真演示</h2><h3>一键运行</h3><pre><code class="matlab">&gt;&gt; cd packages/P3_容量增强包
&gt;&gt; setup_path
&gt;&gt; generate_ber_plots  % 三技术 BER 对比</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608422" alt="p3_capacity_compare.png" title="p3_capacity_compare.png"/><img referrerpolicy="no-referrer" src="/img/remote/1460000047608423" alt="p3_gim_hist.png" title="p3_gim_hist.png" loading="lazy"/><img referrerpolicy="no-referrer" src="/img/remote/1460000047608424" alt="p3_mm_constellation.png" title="p3_mm_constellation.png" loading="lazy"/><img referrerpolicy="no-referrer" src="/img/remote/1460000047608425" alt="p3_variants_ber.png" title="p3_variants_ber.png" loading="lazy"/></p><hr/><h2>📦 您将获得</h2><table><thead><tr><th align="left">内容</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">📁 <strong>完整源码</strong></td><td align="left">GIM + MM + IQ 三技术完整实现</td></tr><tr><td align="left">📖 <strong>原理文档</strong></td><td align="left">索引空间扩展数学推导</td></tr><tr><td align="left">🚀 <strong>容量提升</strong></td><td align="left">最高 67% 频谱效率增益</td></tr><tr><td align="left">📊 <strong>对比工具</strong></td><td align="left">一键生成三技术性能对比</td></tr><tr><td align="left">🔧 <strong>灵活配置</strong></td><td align="left">可变 k 范围、模式数、调制阶数</td></tr><tr><td align="left">📡 <strong>可视化</strong></td><td align="left">多模星座图、容量对比曲线</td></tr></tbody></table><hr/><h2>🛒 获取方式</h2><p>本文代码仅为核心片段，完整版工程已整理好。 关注公众号 【<strong>3GPP仿真实验室</strong>】进行获取。</p><h2>📚 参考文献</h2><ol><li><strong>M. Wen et al.</strong> (2017): "Generalized Index Modulation Aided OFDM." <em>IEEE Trans. Wireless Commun.</em>, vol. 16, no. 3.</li><li><strong>B. Zheng et al.</strong> (2019): "Multiple-Mode OFDM with Index Modulation." <em>IEEE Trans. Signal Process.</em>, vol. 67, no. 9.</li><li><strong>E. Başar et al.</strong> (2017): "OFDM with Index Modulation Using In-Phase and Quadrature Indices." <em>IEEE Trans. Veh. Technol.</em>, vol. 66, no. 5.</li></ol>]]></description></item><item>    <title><![CDATA[Microsoft Office LTSC 2021 for Mac 16.106 - 文档、电子表]]></title>    <link>https://segmentfault.com/a/1190000047608474</link>    <guid>https://segmentfault.com/a/1190000047608474</guid>    <pubDate>2026-02-12 22:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>Microsoft Office LTSC 2021 for Mac (Microsoft 365) 16.106 - 文档、电子表格、演示文稿和电子邮件</p><p>Office LTSC 2021 for Mac (Word, Excel, PowerPoint, Outlook + OneNote, OneDrive)</p><p>请访问原文链接：<a href="https://link.segmentfault.com/?enc=yf9Qwr2KLb%2BTYScDMwyFVA%3D%3D.ITt4QRJBTiJwD8dFlax%2BddAO2%2FzXSDcQgZJeA%2BHaUIg2nEEYtnhsPmjuoeK8%2BE2Y" rel="nofollow" target="_blank">https://sysin.org/blog/office-2021-for-mac/</a> 查看最新版。原创作品，转载请保留出处。</p><p>作者主页：<a href="https://link.segmentfault.com/?enc=fk6M%2FzUUvhXZa5RCd1tbwQ%3D%3D.R7GLNJqYl2dB%2FOnrX4neb43l5rqVcdGrq8MTN2cJmgE%3D" rel="nofollow" target="_blank">sysin.org</a></p><hr/><p>Office for Mac 2021 2026 年 2 月份月度更新来袭！</p><h2>Office for Mac 2021 组件和发行版</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608476" alt="Office LTSC" title="Office LTSC"/></p><p>2021.09.16，微软正式发布了 Office LTSC 2021，当然也包括 for Mac 版本，Office for Mac 2021 首个版本号为 16.53，与 Office 365 和 Office 2019 共享安装介质，通过许可的不同而区分版本和功能。请参看 <a href="https://link.segmentfault.com/?enc=2rcc4aathr15h1ELqJiKnA%3D%3D.Bhu1WGvfNS%2BzTYutqAuaTQiHRmlbw9Vq8idZtRwCiKW%2FECD2KUB3TKSNhbp6vtXKhI1vYCN4vDDgF4jw5bvM44mUG3yV459ofXOTlkp2PQH8W059ht485EREFB%2FA4SEcbOtELZf4sd5ETvE0ZAoWHA%3D%3D" rel="nofollow" target="_blank">Office 2021 for Mac 新增功能</a>。</p><p>Office for Mac 包含以下组件：</p><ul><li>Microsoft <strong>Excel</strong>：电子表格和数据分析</li><li>Microsoft <strong>Outlook</strong>：电子邮件和日历</li><li>Microsoft <strong>PowerPoint</strong>：创建吸引人的演示文稿</li><li>Microsoft <strong>Word</strong>：创建、编辑和分享文档</li><li>Microsoft <strong>OneNote</strong>：记录笔记、创意和备忘录</li></ul><p>Office for Mac 有以下两种发行版（详见下文描述）：</p><ul><li>Office for Mac (Office 365) pkg</li><li>Office LTSC for Mac DMG VL</li></ul><h2>Office for Mac 2021 (Office 365) pkg</h2><p>⚠️：<strong>请慎用此版本，需要 root 权限才能运行，安装一堆无用文件，强制自动更新。</strong></p><p>参看：<a href="https://link.segmentfault.com/?enc=L%2FQhAod1hhisJtmnUODXmg%3D%3D.1r58AIxqcshibjPzu2covEtBJ0d4P6zYl0GQvDBgaJsYvHafha2Y6CQ7KfzUwDPpix9uhFt%2BSVI0BoxCwVQerw%3D%3D" rel="nofollow" target="_blank">如何卸载 Office for Mac</a></p><p>此版本的唯一优点是开放下载，各大网站通常提供的也是此版本。</p><p><strong>Microsoft Office for Mac 2021 (Office 365) 16.106 Universal</strong>（2026-01-13）</p><ul><li>请访问：<a href="https://link.segmentfault.com/?enc=Qd%2BaJ6Qx3N2jL8gNT0cXtw%3D%3D.8wg5WI1%2B4g3SWc%2BKAfU3U2b9VcyaT0aufNVrYxON97hjZWk6ck1X84v%2BxmZizQju" rel="nofollow" target="_blank">https://sysin.org/blog/office-2021-for-mac/</a></li><li>系统要求：从 16.101 开始，要求 macOS Sonoma 14.0 及以上版本。</li></ul><p>从 16.53 开始，Office 2021 和 Office 2019 是共用安装文件，通过许可证激活不同的版本，主要体现在界面风格上有较为明显差异，另外 2021 版有一些新增功能。</p><p>Office 365 是一种订阅模式，永久许可版即 Office LTSC for Mac。</p><h2>Office LTSC 2021 for Mac DMG VL</h2><p>该产品符合 Apple 平台设计规范，无需 root 权限安装，只需要拖拽到应用程序下即可，无需登录，没有自动更新程序，也不会提示过期。</p><ul><li>无需 root 权限，拖拽即可安装</li><li>无需登录账号（无需注册，支持离线使用）</li><li>无自动更新程序</li><li>不会提示过期</li><li>可以仅安装单个组件</li></ul><p>包含 Excel、Outlook、PowerPoint 和 Word 四个核心组件，可独立运行单个组件。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608477" alt="Microsoft Excel" title="Microsoft Excel" loading="lazy"/></p><p>Microsoft <strong>Excel</strong>：电子表格和数据分析</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608478" alt="Microsoft Outlook" title="Microsoft Outlook" loading="lazy"/></p><p>Microsoft <strong>Outlook</strong>：电子邮件和日历</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608479" alt="Microsoft PowerPoint" title="Microsoft PowerPoint" loading="lazy"/></p><p>Microsoft <strong>PowerPoint</strong>：创建吸引人的演示文稿</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608480" alt="Microsoft Outlook" title="Microsoft Outlook" loading="lazy"/></p><p>Microsoft <strong>Word</strong>：创建、编辑和分享文档</p><p>备注：OneNote 免费，需要登录。</p><p><strong>Microsoft Office LTSC for Mac 2021 DMG VL v16.54 (Final version)</strong> for macOS Mojave 10.14</p><ul><li>请访问：<a href="https://link.segmentfault.com/?enc=filDvKZEKMSECicv3%2FPYgg%3D%3D.LX6qRbXtdzlGjjNtEGoPn3ranRorxuGknYzMRvdBLpJToADxwpXI7z3vusrP8RgR" rel="nofollow" target="_blank">https://sysin.org/blog/office-2021-for-mac/</a></li></ul><p><strong>Microsoft Office LTSC for Mac 2021 DMG VL v16.66 (Final version)</strong> for macOS Catalina 10.15</p><ul><li>请访问：<a href="https://link.segmentfault.com/?enc=asvQNeLu0Pe%2FbGOybmvRgw%3D%3D.UAtFT9X8iRYgYRC9dTrxnCHrf7TH%2Bmfol5tHKbpQHuziRFA6viHm8dOmdoXbw%2BbB" rel="nofollow" target="_blank">https://sysin.org/blog/office-2021-for-mac/</a></li></ul><p><strong>Microsoft Office LTSC for Mac 2021 DMG VL v16.77 (Final version)</strong> for macOS Big Sur 11</p><ul><li>请访问：<a href="https://link.segmentfault.com/?enc=QvUmz9gnis6X5BwMVouJVg%3D%3D.VD2BEQfxN3O2pBfqOFIH9ooG1oWdOJgZf9cCYVvX3rjmwi2ZhHs5c%2FFUiSiuAGyF" rel="nofollow" target="_blank">https://sysin.org/blog/office-2021-for-mac/</a></li></ul><p><strong>Microsoft Office LTSC for Mac 2021 DMG VL v16.89 (Final version)</strong> for macOS Montery 12</p><ul><li>请访问：<a href="https://link.segmentfault.com/?enc=Qirr7wV6YnAaWiUEFkH%2FzQ%3D%3D.%2F0zvLrAc8wFgufg1sJ2R9dVa6DhazfxMrmTKsV3f3n4Bff8J2ECtY1%2BmLbgBys0P" rel="nofollow" target="_blank">https://sysin.org/blog/office-2021-for-mac/</a></li></ul><p><strong>Microsoft Office LTSC for Mac 2021 DMG VL v16.100 (Final version)</strong> for macOS Ventura 13</p><ul><li>请访问：<a href="https://link.segmentfault.com/?enc=1jBUMZW4iQJgfBZk9arbvw%3D%3D.p5Q0eauLY7Z9aVYSyPzo9h0s5pc3PDK%2B%2B8klnd5VT23nLNAUXx0VHb%2FXZIxT8OVf" rel="nofollow" target="_blank">https://sysin.org/blog/office-2021-for-mac/</a></li></ul><p><strong>Microsoft Office LTSC for Mac 2021 DMG VL v16.106</strong> for macOS Sonoma 14 or later</p><ul><li>支持 macOS Sonoma 14、macOS Sequoia 15 和 macOS Tahoe 26</li><li>请访问：<a href="https://link.segmentfault.com/?enc=cDSQGF9N7UBzIoVEjB2brg%3D%3D.SzopchXroB7djR9A8fqXb2gGYrYJyGZY5TAzPniKPVJ6itm38C%2B1Qzf1Vcrk75v3" rel="nofollow" target="_blank">https://sysin.org/blog/office-2021-for-mac/</a></li></ul><hr/><p>新版链接：</p><ul><li><a href="https://link.segmentfault.com/?enc=s3y2Nv18dPUECBbZ8A2h8A%3D%3D.btTP8tgmdbmqLeTUjJI0ufHcYP9ewLWuwEWgqzWGQSJ85olpYjepL%2FNmAOaHfKS4" rel="nofollow" target="_blank">Microsoft Office LTSC 2024 for Mac (Microsoft 365) 16.106 - 文档、电子表格、演示文稿和电子邮件</a></li></ul><p>更多：<a href="https://link.segmentfault.com/?enc=nxR7aB42vAbeeD3rOqEChw%3D%3D.ycr9Lp4mTzVukyJLgPBEcNSeOCblNS5aowpu%2FJAU4lA%3D" rel="nofollow" target="_blank">macOS 下载汇总 (系统、应用和教程)</a></p>]]></description></item><item>    <title><![CDATA[Xampp集成环境包 安装步骤详解（附Apache、MySQL启动与本地网站搭建） 小童童 ]]></title>    <link>https://segmentfault.com/a/1190000047608327</link>    <guid>https://segmentfault.com/a/1190000047608327</guid>    <pubDate>2026-02-12 21:03:22</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>​</p><p><code>Xampp</code>是 <strong>XAMPP 集成环境包</strong>​ 的安装程序，把 Apache（网页服务器）、MySQL（数据库）、PHP（编程语言解释器）还有 Perl 打包到一起，装完就能在本地跑网站、做 PHP 开发或测试。</p><h2>一、准备工作</h2><ol><li><p><strong>下载安装包</strong>​</p><p><strong>安装包下载：</strong><a href="https://link.segmentfault.com/?enc=E5Iyyv8UCY6m32x7P%2BnttA%3D%3D.Kl8XTfBy2mWETiYiynbPQxETMCxMrDDYyETZuzFTsbHpQiI%2FZLNMUTFb1TquZ4%2BL" rel="nofollow" title="https://pan.quark.cn/s/2e6ba302b1eb" target="_blank">https://pan.quark.cn/s/2e6ba302b1eb</a></p></li><li><p><strong>用管理员身份运行（推荐）</strong> ​</p><ul><li>右键 <code>Xampp.exe</code>→ 选“以管理员身份运行”，避免权限不足导致端口占用或服务启动失败。</li></ul></li></ol><h2>二、安装步骤</h2><ol><li>双击 <code>Xampp.exe</code>打开安装程序。</li><li>弹出语言选择 → 选  <strong>“English”</strong> ​ 或  <strong>“中文(简体)”</strong> （看版本支持）→ 点  <strong>“OK”</strong> 。</li><li>欢迎界面 → 点  <strong>“Next”</strong> 。</li><li><p>选择组件：</p><ul><li>默认是全选（Apache、MySQL、PHP、Perl、phpMyAdmin 等），新手直接保持默认，点  <strong>“Next”</strong> 。</li></ul></li><li><p>选安装路径：</p><ul><li>默认 <code>C:\xampp`，可点 “Browse” 改到其他盘，比如</code>D:\xampp`，然后点  <strong>“Next”</strong> 。</li></ul></li><li><p>Bitnami 提示：</p><ul><li>这个是可选的应用安装向导，不想用就取消勾选，点  <strong>“Next”</strong> 。</li></ul></li><li>点  <strong>“Install”</strong> ​ 开始安装，等进度条走完（几分钟）。</li><li>安装中会问是否装到开始菜单和桌面快捷方式 → 根据需要勾选 → 继续直到完成。</li><li>完成后会提示是否立刻运行 XAMPP 控制面板 → 勾上 → 点  <strong>“Finish”</strong> 。</li></ol><h2>三、首次运行与基本使用</h2><ol><li>打开 XAMPP 控制面板（桌面或开始菜单里找）。</li><li>左侧列表里找到 <strong>Apache</strong>​ 和 <strong>MySQL</strong>​ → 分别点  <strong>“Start”</strong> ​ 启动，绿灯亮表示正常运行。</li><li>浏览器输入 <code>http://localhost</code>或 <code>http://127.0.0.1</code>，能看到 XAMPP 欢迎页说明成功。</li><li><p><strong>放网站文件</strong>：</p><ul><li>默认网站根目录在 <code>C:\xampp\htdocs</code>（或你改的路径下的 htdocs 文件夹），把 PHP 文件或项目丢进去即可访问。</li></ul></li><li><p><strong>管理数据库</strong>：</p><ul><li>浏览器访问 <code>http://localhost/phpmyadmin</code>，用默认账号 <code>root</code>，密码为空登录，就能建库、导数据。</li></ul></li></ol><p>​</p>]]></description></item><item>    <title><![CDATA[《2025年度OpenAtom openKylin社区全景案例集》正式发布 openKylin ]]></title>    <link>https://segmentfault.com/a/1190000047608345</link>    <guid>https://segmentfault.com/a/1190000047608345</guid>    <pubDate>2026-02-12 21:02:50</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>本次发布的《2025年度OpenAtom openKylin社区全景案例集》（以下简称‘案例集’）由openKylin社区牵头编撰，众多产业领域优势企业、知名院校及杰出开发者共同参与。在2024版的基础上，新增收录了社区成员们在2025年的杰出技术成果和行业应用案例共40余项。通过这些案例，读者可以深入了解openKylin社区在技术创新、AI智能融合、应用生态拓展、行业应用等方面的最新进展，为广大技术爱好者、生态伙伴及行业从业者提供宝贵的参考资料，进一步推动开源技术生态的繁荣发展！</p><p><strong>案例集内容概览</strong><br/>1.社区简介及共建情况主要介绍openKylin社区从成立至今的发展历程、贡献者参与、上下游贡献成果、社区活动风采等内容，帮助大家快速了解社区、参与社区。<br/>2.根社区基础能力主要介绍openKylin作为开源操作系统根社区所具备的基础能力，包括核心组件选型维护能力、“可控开源”体系等，欢迎更多人参与到根社区的建设中来。<br/>3.技术创新项目主要介绍openKylin社区目前孵化的优秀技术创新项目，涵盖底层技术、桌面场景、生态技术、开发工具、安全能力、智能融合六大技术创新领域，帮助大家快速了解社区最新技术创新成果。4.生态适配案例主要介绍openKylin社区上下游生态伙伴主导的行业生态适配优秀案例，包括xPU硬件、整机、应用软件等方面，帮助大家快速了解社区生态适配工作，吸引更多行业生态加入openKylin社区，共建繁荣。<br/>5.行业应用案例主要介绍openKylin系操作系统（包括商业发行版、用户自用版以及社区版）在各行业领域中的应用实践案例，帮助解决行业核心场景中痛点问题，满足典型场景需求，为行业用户提供有示范效应的解决方案。<br/>6.社区爱好者构建成果主要介绍openKylin社区优秀开发者和爱好者在社区参与的桌面环境移植构建和内核构建成果，帮助有兴趣参与社区的个人开发者或爱好者找到适合自己的贡献方向。</p><ol start="7"><li>社区基础设施平台建设成果主要介绍openKylin社区当前基础设施平台建设成果，包括基础服务相关平台、一站式编译构建相关平台、学习成长平台、AI融合平台，帮助大家了解社区基础设施平台体系架构和目前可以支撑的能力，提升用户参与社区的体验和效率。</li></ol><p>点击链接下载案例集：<a href="https://link.segmentfault.com/?enc=LX9BeOEuDXTF4ouW9ydzdQ%3D%3D.Y5EBwouL8fe12Yj2ERB9IGIhehOWf4w8Q0XpmdVlRmOxKA64MpbOGAc5rSLyM70q2YB5pwdPI%2B0lD0gKJ%2Brodxfuq3nGlxtweF4YfnolMOzYeKK96Y8jVIh3qiWs2Ntp4PjWysiVvZceYjR%2BM%2FcQ7Q%3D%3D" rel="nofollow" target="_blank">https://www.openkylin.top/public/pdf/OpenAtom_openKylin_Commu...</a></p>]]></description></item><item>    <title><![CDATA[phpwind_UTF8_8.5部署步骤详解（含环境准备+安装教程） 无邪的课本 ]]></title>    <link>https://segmentfault.com/a/1190000047608353</link>    <guid>https://segmentfault.com/a/1190000047608353</guid>    <pubDate>2026-02-12 21:02:19</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>​</p><h2>一、先准备点东西（必看！）</h2><ol><li><strong>环境得有</strong>：本地或服务器得装好 PHP+MySQL+Apache/Nginx（比如用宝塔面板的话，直接一键装这仨就行；没面板就自己手动搭，新手建议用集成环境像phpStudy/WAMP，省事儿）。</li><li><strong>下载安装包</strong>：<strong>安装包下载：</strong><a href="https://link.segmentfault.com/?enc=zJkLIKX5JJCMiwhbtMRdsw%3D%3D.9fiKPOcP11pcRWgFsmn3Ll3uPlEsy3xLoo1vdv%2FNabFZLeaO1f2cH3KOb9j4vxPV" rel="nofollow" title="https://pan.quark.cn/s/3c18c722e10a" target="_blank">https://pan.quark.cn/s/3c18c722e10a</a>   ，把 <code>phpwind_UTF8_8.5.zip</code>下到电脑/服务器上。</li></ol><h2>二、解压+扔到网站目录</h2><ol><li>先把 zip 包解压了，里面会有个类似 <code>phpwind</code>的文件夹（具体看压缩包里的内容，别整错）。</li><li>把这个文件夹里的<strong>所有文件</strong>，复制到你的网站根目录（比如 Apache 默认是 <code>htdocs</code>，Nginx 可能是 <code>www</code>或你自己设的目录，宝塔面板里就是“网站”对应的根目录，直接上传进去就行）。</li></ol><h2>三、给目录开权限（不然可能报错）</h2><p>找到网站根目录下的两个文件夹：</p><ul><li><code>data</code>（存数据用的）</li><li><code>upload</code>（存上传图片/文件的）</li></ul><p>右键这两个文件夹 → 属性（或权限设置）→ 把“写入权限”勾上（Linux服务器一般设 <code>755</code>或 <code>777</code>，Windows服务器直接给“完全控制”也行，新手别纠结数字，能写就行）。</p><h2>四、浏览器访问安装页面</h2><p>打开浏览器，输入你的网站地址（比如 <code>http://localhost</code>或你的域名），会自动跳转到 phpwind 的安装页面（如果没跳转，手动输 <code>http://你的域名/install.php</code>，一般在根目录下）。</p><h2>五、跟着安装向导走（傻瓜式操作）</h2><h3>1. 同意协议，下一步</h3><p>看到许可协议，拉到最下面点“我同意”，然后点“下一步”。</p><h3>2. 检查环境（有问题会标红，先解决再继续）</h3><p>这里会检测 PHP版本、MySQL扩展、文件夹权限这些。如果有标红的“失败”项：</p><ul><li>比如“PHP版本太低”：升级PHP（宝塔里直接在软件商店点升级）；</li><li>比如“data目录不可写”：回到第三步重新设权限；</li><li>都绿了（显示“成功”）再点“下一步”。</li></ul><h3>3. 填数据库信息（重点！别乱填）</h3><p>这里需要提前在 MySQL 里建一个<strong>空数据库</strong>（比如叫 <code>phpwind_db</code>，字符集选 utf8 或 utf8mb4，避免乱码）：</p><ul><li>数据库名：填刚才建的空库名（比如 <code>phpwind_db</code>）；</li><li>数据库用户名：一般是 <code>root</code>（如果你单独给phpwind建了个MySQL用户，就填那个用户名）；</li><li>数据库密码：你MySQL的 root 密码（忘了就去查配置文件，宝塔里在“数据库”页能看到）；</li><li>数据库主机：默认 <code>localhost</code>（不用改，除非你的数据库不在本地）；</li><li>表前缀：默认 <code>pw_</code>就行，不改也没事。</li></ul><p>填完点“测试数据库连接”，提示“连接成功”就点“下一步”。</p><h3>4. 设管理员账号（记好！别忘密码）</h3><ul><li>管理员账号：自己设个登录名（比如 <code>admin</code>）；</li><li>密码：设复杂点（字母+数字+符号），一定要记住！</li><li>邮箱：填个能收邮件的（找回密码用）。</li></ul><p>填完点“下一步”，等它跑完进度条。</p><h3>5. 安装完成！删安装文件（重要！防被黑）</h3><p>看到“安装成功”页面后，<strong>务必删掉或重命名根目录下的 <code>install.php</code>文件</strong>（或者整个 <code>install</code>文件夹，有的压缩包里有这个文件夹），不然别人可能通过它重复安装搞破坏。</p><h2>六、登录后台玩去吧</h2><p>安装完会自动跳转到首页，或者手动访问 <code>http://你的域名/admin.php</code>，用刚才设的管理员账号密码登录，就能进后台管理论坛了（发帖、设置板块啥的都在里面）。</p><p>​</p>]]></description></item><item>    <title><![CDATA[LLM创造力可以被度量吗？一个基于提示词变更的探索性实验 本文系转载，阅读原文
https://av]]></title>    <link>https://segmentfault.com/a/1190000047608356</link>    <guid>https://segmentfault.com/a/1190000047608356</guid>    <pubDate>2026-02-12 21:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>大语言模型在demo阶段总是看起来很惊艳。但一旦进入到生产环境很多问题就暴露了：不稳定、不可预测，甚至直接不可用。</p><p>从实践来看核心问题很少出在模型本身。更多时候是在于如何设计、评估和迭代应用模型的提示词。LLM应用的输入提示词必须适配具体任务，才能让模型在期望的输出范围内工作。</p><p>提示词工程在今天基本还是被当作一种"艺术"。这篇文章要讨论的就是为什么这是个问题，以及怎么把它变成一门可度量的工程学科。</p><blockquote>提示词工程仍然是猜测</blockquote><p>大多数团队的提示词改进流程其实很粗糙：有人写（或重写）提示词，跑几个例子，主观觉得"感觉好了一些"，然后就上线了。</p><p>没有度量标准，没有基线，也没有对"更好"的明确定义。</p><p>这带来的直接后果是：提示词质量难以对比，评估基本靠外部响应来判断，回归问题不容易察觉，很多故障等到上线后才被发现。</p><p>提示词工程本质上极度主观，如果目标是构建可靠的AI系统，这就成了一个严重的瓶颈。</p><h2>实际LLM使用中的两个对立问题</h2><p>在生产环境里跑LLM，我发现有两个反复出现的问题。</p><blockquote>不一致性：同一个提示词，不同的答案</blockquote><p>同一条提示词跑多次会产生明显不同的输出。这不只是烦人的问题，而是对数据流水线、自动化决策系统、评估框架来说，这是实打实的可靠性风险。</p><p>高方差在这类场景下是bug不是feature。模型要么表现出确定性行为，要么至少得在可控范围内运行。</p><blockquote>缺乏多样性：模型不够有创造力</blockquote><p>反过来，有好几个实际项目中碰到了相反的困境：做创意生成、探索性分析、创意制作这类任务时，模型产出的内容彼此过于相似，概念覆盖面非常窄。一旦规模化，创造力就丢得干干净净。</p><p>这时候确定性就从优势变成了束缚。</p><h2>一个简单的假设</h2><p>提示词质量应该是可衡量的。</p><p>有些任务需要最小化输出方差，有些任务需要最大化多样性，而提示词的变更应该能推动结果朝可度量的方向移动。不同类型的任务也可以选择不同的度量标准。</p><p>既然模型行为可以衡量，提示词行为为什么不能？</p><p>为了验证这个想法，我选了模型行为的一个切面来入手：响应多样性，把它当作创造力的代理指标。</p><p>目标不是找到完美的度量方式，而是回答两个问题：提示词变更能不能转化为一致的数值差异？单次任务上的创造力/确定性到底取决于提示词还是仅取决于温度？</p><h2>实验设置</h2><p>实验规模不大，设计如下：</p><p>提示词</p><p>提示词A：</p><p>"Create 5 ideas of creative banners for performance marketing of an AI benchmarking platform."</p><p>提示词B在A的基础上加了一条指令：</p><p>"Create 5 ideas of creative banners for performance marketing of an AI benchmarking platform. Be as creative as possible."</p><p>模型和采样</p><p>采用单次生成模式，测试了多个LLM（具体型号这里略过），温度分别设为0 × max、0.5 × max和1 × max。每个（提示词、模型、温度）组合跑10次。</p><p>测试集选了4个主流模型家族的13个模型：OpenAI的GPT系列、Google的Gemini系列、Antropic的Claude系列，以及Deepseek。</p><p>通过Embedding衡量多样性</p><p>每条生成结果都计算了4096维的embedding向量。然后对每个实验集（固定提示词、模型和温度），取集合内embedding的最大成对距离作为响应多样性的度量。</p><p>逻辑很简单：距离小说明行为高度确定，距离大说明输出多样且有创造力。最终得到一个数值，描述模型响应的"分散程度"。</p><h2>结果</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608358" alt="" title=""/></p><p>汇总表，创意提示词版本导致了更显著的分散。同时温度并不总起作用。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047608359" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047608360" alt="" title="" loading="lazy"/></p><p>基础提示词和创意提示词在模型-温度切片上的比较图。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047608361" alt="" title="" loading="lazy"/><img referrerpolicy="no-referrer" src="/img/remote/1460000047608362" alt="" title="" loading="lazy"/><br/>每个模型在不同温度水平上的响应分散图</p><p>结果比预期要清晰得多。</p><p>跨模型来看有三个明显趋势：在提示词中加入明确的创造力指令，曲线一致上移；提高温度在一定程度上增大了响应多样性，但受限于小样本，这个结论还需谨慎看待；各模型对温度变化的响应方式差异很大没有统一规律。</p><p>提示词变更带来的是可预测的数值效果，而非随机噪声。</p><p>这说明两件事：提示词迭代不必完全依赖直觉，输出创造力是可量化的；这一假设有可能推广到更大的样本和不同的应用场景。</p><p>这套方法的实际意义在于：提示词可以通过数值做A/B测试，温度调优有了度量依据而不是靠猜，模型选择可以由任务需求驱动而非跟风。</p><p>它让团队能在提示词变更上线之前就对效果做出推断。</p><h2>局限性</h2><p>结果虽然是正向的但有几个局限</p><blockquote>度量标准的任务特定性</blockquote><p>这里定义的"创造力"严格来说是任务相关的。用embedding距离衡量的响应多样性，在创意生成、营销创意、探索性任务上作为创造力的代理指标还算合理，但在事实性问答、代码生成、结构化数据提取这些场景下可能毫无意义，甚至会产生误导。</p><p>不能把它当成模型质量的通用指标。目前我也在测试其他面向不同任务的度量标准。</p><blockquote>对Embedding空间的依赖</blockquote><p>所有测量都建立在特定embedding模型和距离度量之上。换用不同的embedding模型、向量归一化方式或距离函数，绝对值也是会变的，所以模型间的相对排名也可能有所不同。</p><p>但本实验中观察到的趋势是稳定的，所以结果应当按相对值来解读，不宜绝对化。</p><blockquote>有限的样本量</blockquote><p>每个配置只跑了有限次数。趋势虽然一致，但要减少方差、估计置信区间、得出统计上站得住的结论，样本量还远远不够。当前的发现更多是探索性的，不是定论。</p><blockquote>提示词和领域偏差</blockquote><p>实验只用了一种任务表述和一个窄领域（效果营销创意）。换到其他领域或提示词风格，效果可能更弱、更强，也可能呈现完全不同的行为模式。把这些结论向创意任务之外推广需要格外谨慎。</p><blockquote>创造力与实用性的权衡</blockquote><p>响应多样性高不等于结果好。高度多样化的输出里可能混着不相关的想法、低质量的建议和不连贯的回复。这个实验测的是方差，不是实用性更不是商业价值。实际应用中创造力度量必须和质量过滤或下游评估配合使用。</p><blockquote>LLM的非平稳性</blockquote><p>大语言模型会被提供商持续更新，所以绝对分数可能随时间漂移，分数可能在提示词没改的情况下发生变化，可复现性也可能下降。任何长期的基准测试工作都必须把这种非平稳性纳入考量。</p><blockquote>相关性不意味着因果性</blockquote><p>最后要说的是，温度、提示词指令和响应多样性之间虽然有明确的相关性，但这不代表对模型行为有了完整的因果理解。实验证明的是"提示词变更可以被衡量"，而不是创造力可以被这套度量标准完全解释。</p><h2>总结</h2><p>这只是一系列研究的第一个实验，后续结果会在接下来的文章中陆续呈现。下一步计划：增加样本量，尝试不同的提示词，实验如何降低创造力，为其他类型任务定义新的度量标准，以及构建一个定期更新的模型排行榜来覆盖各项指标。</p><p><a href="https://link.segmentfault.com/?enc=24Jm%2BX7XSUR0lBw7fE%2BY9Q%3D%3D.EUeMMtmrp8O7ZIvXhPHv0LUM5mohaBOvUuQVkRO6LdkEJ8lMR1g8Is70%2BaNvi4LtT4b3MCXvFcF54%2ByOAiqXMQ%3D%3D" rel="nofollow" target="_blank">https://avoid.overfit.cn/post/e84eee36d7bc4263b9fd5dfe564e21d9</a></p><p>作者：Alexey Konoshenkov</p>]]></description></item><item>    <title><![CDATA[枫琳 (Fenglin) 人机共生智能协作平台 鸿枫 ]]></title>    <link>https://segmentfault.com/a/1190000047608204</link>    <guid>https://segmentfault.com/a/1190000047608204</guid>    <pubDate>2026-02-12 20:03:45</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>🍁 枫琳 (Fenglin)</h2><blockquote>人机共生智能协作平台 - 让智能自然融入生活</blockquote><hr/><h3>一、产品简介</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608206" alt="" title=""/></p><p><strong>枫琳</strong> 是一款实现人与智能体（OpenClaw、OpenCode 等）和谐相处、共同交流、生活、工作的智能协作平台。支持接入钉钉、企业微信等办公软件，覆盖朋友圈、点赞、评论、私信等社区场景，实现人与机器人共生，共同进步，就像人与自然和谐共生一样。</p><h4>品牌理念</h4><table><thead><tr><th>字</th><th>含义</th><th>象征</th></tr></thead><tbody><tr><td><strong>枫</strong></td><td>四季流转，顺应自然</td><td>人与 AI 和谐适应、共同成长</td></tr><tr><td><strong>琳</strong></td><td>美玉相击，清音回响</td><td>思想交流、心灵共鸣</td></tr></tbody></table><blockquote><em>"枫叶由绿转红，是成长的印记；人机由陌生到默契，是共生的旅程"</em></blockquote><hr/><h3>二、核心功能</h3><h4>1. 🤖 智能体协作</h4><blockquote><em>枫叶随风起舞，人与 AI 自然共处</em></blockquote><ul><li><strong>多智能体协同工作</strong> - 支持 OpenClaw、OpenCode 等多种智能体</li><li><strong>智能任务分配</strong> - AI 自动分析并分配最优任务</li><li><strong>实时沟通反馈</strong> - 人机无缝对话，即时响应</li></ul><h4>2. 🏢 企业级集成</h4><blockquote><em>枫枝相连，生态融合</em></blockquote><ul><li><strong>钉钉深度集成</strong> - 无缝对接企业钉钉工作流</li><li><strong>企业微信对接</strong> - 支持企业微信生态</li><li><strong>自定义工作流</strong> - 灵活配置企业专属流程</li></ul><h4>3. 💬 社区生态</h4><blockquote><em>枫叶飘落，信息传递；琳玉相击，思想共鸣</em></blockquote><ul><li><strong>朋友圈动态分享</strong> - 发布图文、视频动态</li><li><strong>实时互动评论</strong> - 点赞、评论、转发</li><li><strong>安全私密对话</strong> - 端到端加密私信</li></ul><h4>4. ✨ 智慧共生</h4><blockquote><em>枫叶四季蜕变，持续成长</em></blockquote><ul><li><strong>知识共享沉淀</strong> - 构建团队知识库</li><li><strong>能力互补提升</strong> - 人机优势互补</li><li><strong>共同成长轨迹</strong> - 记录每一步进步</li></ul><hr/><h3>三、应用场景</h3><table><thead><tr><th>场景</th><th>描述</th></tr></thead><tbody><tr><td><strong>协同办公</strong></td><td>智能体助手帮你处理日常事务，如枫叶随风，自然流畅</td></tr><tr><td><strong>团队协作</strong></td><td>人机混合团队高效配合，如枫林成片，协作共生</td></tr><tr><td><strong>社交互动</strong></td><td>与 AI 伙伴分享生活，如枫语私语，获得理解与陪伴</td></tr><tr><td><strong>知识共创</strong></td><td>人类智慧与 AI 能力融合，如秋日枫林，收获满满</td></tr></tbody></table><hr/><h3>四、产品优势</h3><table><thead><tr><th>优势</th><th>说明</th></tr></thead><tbody><tr><td>🛡️ <strong>安全可靠</strong></td><td>企业级数据安全保障，如枫根深扎</td></tr><tr><td>⏰ <strong>全天候服务</strong></td><td>7×24 小时智能体在线，如枫叶常伴</td></tr><tr><td>⚡ <strong>高效智能</strong></td><td>AI 驱动的工作流，效率提升 300%</td></tr><tr><td>🌐 <strong>开放生态</strong></td><td>支持多种智能体接入，如枫林开放</td></tr></tbody></table><hr/><h3>五、品牌色彩体系</h3><table><thead><tr><th>颜色</th><th>色值</th><th>含义</th></tr></thead><tbody><tr><td>🔴 枫叶红</td><td><code>#C41E3A</code></td><td>温暖、活力、信任</td></tr><tr><td>🟡 秋金黄</td><td><code>#D4A017</code></td><td>收获、价值、希望</td></tr><tr><td>🟢 自然绿</td><td><code>#228B22</code></td><td>成长、生命、和谐</td></tr></tbody></table><hr/><h3>六、品牌 Slogan</h3><p><strong>主 Slogan：</strong></p><blockquote>枫琳，让智能自然融入生活</blockquote><p><strong>场景 Slogan：</strong></p><table><thead><tr><th>场景</th><th>Slogan</th></tr></thead><tbody><tr><td>品牌宣传</td><td>枫琳 — 人机共生，自然之道</td></tr><tr><td>产品介绍</td><td>枫琳，你的 AI 协作伙伴</td></tr><tr><td>社交场景</td><td>在枫琳，与 AI 成为朋友</td></tr><tr><td>办公场景</td><td>枫琳协创，工作更自然</td></tr></tbody></table><hr/><h3>七、开源项目</h3><p>本产品为开源项目，欢迎参与贡献：</p><p>🔗 <strong>Gitee 仓库：</strong> <a href="https://link.segmentfault.com/?enc=gFvMdIRPobQeTNyjakNgDQ%3D%3D.1HTXCw3mTbGYAYJgxDuZHeaiOTHNd1fuRCooZbXqNIuLm3e%2FQinyHvQfDUccs1QmBFb2BM73sDLe5LQ1xsdpeA%3D%3D" rel="nofollow" target="_blank">https://gitee.com/hongmaple/openclaw-dindin-chart</a></p><hr/><h3>八、快速开始</h3><h4>1. 注册账号</h4><p>访问枫琳官网，点击"免费试用"按钮</p><h4>2. 创建工作空间</h4><p>选择你的行业场景，系统将为你推荐合适的智能体</p><h4>3. 开始协作</h4><p>与智能体开始对话，让它成为你的得力助手</p><hr/><h3>九、联系我们</h3><table><thead><tr><th>渠道</th><th>信息</th></tr></thead><tbody><tr><td>📧 Email</td><td><a href="mailto:296155694@qq.com" target="_blank">296155694@qq.com</a></td></tr><tr><td>💬 微信</td><td>mapleCx330</td></tr><tr><td>🌐 官网</td><td>www.fenlin.ai</td></tr><tr><td>📦 开源项目</td><td><a href="https://link.segmentfault.com/?enc=isKs3OdkjoRz2LrZpO5Pqg%3D%3D.1XTIQR3xt6Hdy4IKwdNaEg7qu%2FtBL5z2Y5XtKVf32YJr%2BY%2Fn3I1oBPPX8CirF9RRolMiH0kiQUpaBDPUSKCDuw%3D%3D" rel="nofollow" target="_blank">https://gitee.com/hongmaple/openclaw-dindin-chart</a></td></tr></tbody></table><hr/><h3>十、相关链接</h3><table><thead><tr><th>项目</th><th>地址</th></tr></thead><tbody><tr><td>枫琳落地页源码</td><td><a href="https://link.segmentfault.com/?enc=bJBZ9lb9ID%2FLW9H8eE%2B2jw%3D%3D.Rns5mEMu5hbBPHg40JWLB4vlIf6dnk1LCmR3W%2Bnuv9oXdzj6vC9ME%2FA68rh2qQiF" rel="nofollow" target="_blank">https://gitee.com/hongmaple/fenlin-landing</a></td></tr><tr><td>枫琳 chat 开源项目</td><td><a href="https://link.segmentfault.com/?enc=PxBIuEK33RbLcykndB5k6Q%3D%3D.lnKZEEivtpEDAjnVcgAKten6Tza7CbNyILUk3JxZk6pYhCHlUwOSw2P7DRz0NykN0nTo%2Bo7Lg%2F5ox2utBh7jsA%3D%3D" rel="nofollow" target="_blank">https://gitee.com/hongmaple/openclaw-dindin-chart</a></td></tr></tbody></table><hr/><p><strong>🍁 枫琳 - 人机共生，自然之道</strong></p><p><em>让 AI 如枫叶般自然融入你的工作与生活</em></p><p>本文由<a href="https://link.segmentfault.com/?enc=29mm8%2B92F5TecmKbaRWbig%3D%3D.nKiP1N%2BNMKU74Omzrrd5zUieDMir%2BGRNApl5cj%2BLOCE%3D" rel="nofollow" target="_blank">mdnice</a>多平台发布</p>]]></description></item><item>    <title><![CDATA[用 Go 实现一个可长期运行的 GitHub Webhook 服务实践 苏琢玉 ]]></title>    <link>https://segmentfault.com/a/1190000047608290</link>    <guid>https://segmentfault.com/a/1190000047608290</guid>    <pubDate>2026-02-12 20:02:47</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>前段时间我写过一篇文章，<a href="https://link.segmentfault.com/?enc=sFyUet9O2S9U7h9SFq5gQA%3D%3D.e8uq1bW1jZqjtmW2WWz8x9FJhm3MRUiGW2tW4QIJqKvslhzJA8IMROYBtd6fG0lw" rel="nofollow" target="_blank">记录自己作为一名 PHP 开发者自学 Go 的过程</a></p><p>那篇更多是学习阶段的整理。这次则是一次完整实践的复盘。</p><p>单点知识和系统能力之间始终存在差距。</p><p>理解一个概念并不难，但要把多个能力组合起来，形成一个可以长期运行的系统，往往需要真实项目去反复打磨。很多看似基础的东西，只有亲手做过，理解才会真正扎实。</p><p>最近我完成了一个小工具：<strong>github-webhook-listener</strong></p><p>一个用 Go 实现的 GitHub Webhook 接收服务，可以根据规则执行 Shell 命令，并内置一个简单的 Vue 面板，用于查看运行状态和执行记录。</p><p>功能本身并不复杂，AI 也完全可以在较短时间内生成类似的实现。但在实际开发过程中，我更在意的并不是功能本身，而是一些基础层面的设计问题：项目结构如何划分，依赖如何组织，边界如何定义，以及构建与部署如何简化。</p><p>这些内容未必新鲜，但当它们被组合到一个完整系统中时，体会是不同的。</p><p>项目地址我放在文章末尾，感兴趣可以自行查看下载使用。</p><p><img width="723" height="378" referrerpolicy="no-referrer" src="/img/bVdnVeJ" alt="" title=""/></p><p><img width="723" height="378" referrerpolicy="no-referrer" src="/img/bVdnVeK" alt="" title="" loading="lazy"/></p><p><img width="723" height="378" referrerpolicy="no-referrer" src="/img/bVdnVeL" alt="" title="" loading="lazy"/></p><p>下面我会从结构设计、并发模型以及构建方式三个方面，做一次相对完整的技术复盘。</p><hr/><h2>项目结构与职责划分</h2><p>项目核心代码放在 <code>internal</code> 目录：</p><pre><code>internal/
├── bootstrap
├── handler
├── service
├── repository
├── model
├── dto</code></pre><p>这种结构并不追求“标准答案”，重点在于依赖方向清晰。</p><h3>repository</h3><ul><li>只负责数据库操作</li><li>不包含业务判断</li><li>不依赖 HTTP</li></ul><h3>service</h3><ul><li>负责业务逻辑</li><li>调用 repository</li><li>不处理 HTTP 细节</li></ul><h3>handler</h3><ul><li>只做参数解析与响应封装</li><li>调用 service</li><li>不包含核心逻辑</li></ul><p>在功能简单时，这种分层似乎有些“多余”。</p><p>但当涉及到任务调度、执行记录、重试机制时，结构边界开始体现价值。</p><p>边界明确之后，功能扩展基本是“局部修改”，而不是结构性调整。</p><hr/><h2>在 bootstrap 中组织依赖关系</h2><p>所有初始化逻辑集中在 <code>bootstrap</code> 包中完成：</p><ol><li>初始化数据库</li><li>创建 repository</li><li>注入到 service</li><li>注入到 handler</li><li>注册路由</li></ol><p>依赖关系在入口处完全展开，而不是在各个文件中隐式创建。</p><p>这种方式带来的最大好处是：</p><ul><li>对象生命周期清晰</li><li>依赖方向可控</li><li>替换实现时改动集中</li></ul><p>在没有使用任何 DI 框架的情况下，通过显式构造函数完成依赖注入，本身就是对依赖关系的一种约束。</p><p>当项目规模不大时，这种方式反而比自动注入更透明。</p><hr/><h2>双队列 Worker Pool 的并发调度模型</h2><p>这个项目的核心之一，是执行 Shell 命令并控制并发数量。</p><p>我实现的是一个“双队列 Worker Pool”结构，主要包含三个核心组件：</p><ol><li><strong>任务生产者（Producer）</strong></li><li><strong>集中式调度器 + Worker Goroutine</strong></li><li><strong>结果处理器（Result Processor）</strong></li></ol><h3>第一层：任务生产者</h3><p>当 Webhook 触发或 Web 面板手动触发任务时，任务被封装为一个结构体，发送到调度队列。</p><p>这一层只负责“生成任务”，不关心执行细节。</p><hr/><h3>第二层：集中式调度器 + Worker Pool</h3><p>调度器内部维护：</p><ul><li>一个任务输入队列</li><li>一个固定数量的 worker goroutine</li></ul><p>调度流程：</p><ul><li>调度器从任务队列中取出任务</li><li>分发给空闲 worker</li><li>worker 执行 Shell 命令</li><li>将执行结果发送到结果队列</li></ul><p>worker 数量可控，因此系统并发是有上限的。</p><p>这种结构的优点：</p><ul><li>并发可控</li><li>不会因为 Webhook 高频触发而无限创建 goroutine</li><li>任务调度逻辑集中管理</li></ul><p>相比“每来一个请求直接开 goroutine 执行”的写法，这种结构在可控性和可扩展性上更好。</p><hr/><h3>第三层：结果处理器</h3><p>worker 不直接写数据库，而是把结果推送到结果队列。</p><p>结果处理器负责：</p><ul><li>更新执行记录</li><li>写入数据库</li><li>处理重试逻辑（如果有）</li></ul><p>这样做的目的，是进一步解耦：</p><ul><li>执行逻辑专注执行</li><li>持久化逻辑专注记录</li></ul><p>这就是“双队列”的意义：</p><ul><li>队列一：任务调度</li><li>队列二：结果处理</li></ul><p>这种分离在系统规模变大时尤为重要，因为执行耗时和持久化耗时是两个不同维度的问题。</p><hr/><h2>Makefile 作为构建入口</h2><p>项目使用 Makefile 统一管理：</p><ul><li>后端构建</li><li>前端构建</li><li>交叉编译</li><li>发布打包</li></ul><p>Makefile 在这里的意义并不是“少打几行命令”，而是：</p><ul><li>所有构建流程被显式记录</li><li>新环境下可直接复现</li><li>发布步骤标准化</li></ul><p>当一个项目开始涉及前后端协作、交叉编译和发布时，构建流程本身就成为项目的一部分。</p><hr/><h2>使用 embed 将前端资源打包进二进制</h2><p>这是我在这个项目中感受最明显的“Go 工程优势”。</p><p>前端使用 Vue 构建完成后，静态资源通过 <code>embed</code> 打包进 Go 二进制中。</p><p>然后通过：</p><pre><code class="go">http.FileServer(http.FS(...))</code></pre><p>直接提供访问。</p><p>最终效果是：</p><ul><li>只有一个可执行文件</li><li>不需要 Node 环境</li><li>不需要单独部署前端</li><li>不依赖外部静态文件目录</li></ul><p>从架构上看，它仍然是前后端分离：</p><ul><li>前端独立开发</li><li>后端提供 API</li></ul><p>但从交付形态看，它又像是传统单体应用：</p><ul><li>单文件分发</li><li>直接运行</li></ul><p>这种组合非常适合工具型项目和内部服务。</p><p>Go 在这一点上确实有明显优势：编译后就是完整产物，不需要运行时环境，不依赖包管理器，不依赖额外解释器。</p><p>分发成本几乎为零。</p><hr/><h2>写在最后</h2><p>这个项目没有刻意追求复杂设计，也没有引入额外框架。</p><p>它更像是一次完整的工程实践：把分层、依赖组织、并发控制、构建管理这些已经学过的能力组合在一起，形成一个可长期运行的系统。</p><p>我自己已经在实际环境中持续使用它，用来自动化部署和执行脚本，稳定性和可维护性都符合预期。对我来说，它已经从“练手项目”变成了日常工具。</p><p>如果你刚好也需要一个简单的 GitHub Webhook 执行工具，可以直接拿去用；</p><p>如果你正在学习 Go，想找一个结构完整、但复杂度可控的小项目作为参考，也可以看看实现细节。</p><p>GitHub 仓库地址：<a href="https://link.segmentfault.com/?enc=ZWyF5brWdytMPOmG5kvQjw%3D%3D.BqtnrQ%2FzXUZZOY098ej7iTsv3%2FCVKKLZn60p0Vpe3tG7%2Fr%2B4dTXn116JOe0iwFOH1GxoR7eQauoj6PvnxdxMJQ%3D%3D" rel="nofollow" target="_blank">点击查看</a></p><p>有问题或者想法，也欢迎直接在 GitHub 上交流。</p>]]></description></item><item>    <title><![CDATA[【节点】[Ambient节点]原理解析与实际应用 SmalBox ]]></title>    <link>https://segmentfault.com/a/1190000047608295</link>    <guid>https://segmentfault.com/a/1190000047608295</guid>    <pubDate>2026-02-12 20:01:58</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <blockquote><a href="https://link.segmentfault.com/?enc=BzrvDuW4Q4cBpdzm5NzZyg%3D%3D.G130zWMTp7SVzM6Dcej7799yCu7kouSaz1rV9fxmiNMXqw8fPVesPUEoi%2FO0uqxEkXndNfTUaFeEmUE46f0vXHH3HVUHEpbbxVUSG0O%2BL6eISQ7%2F6A%2BbEZaXVk4z5rI9oqKK88f2wa2IEma8ADsp18ITXRe1NxJHFCw%2FH4dbtpvpnPtlp1kjTYCxVArvtreepjjMy6vDKelRYF8yFmLveX9MtzUcx6uH6Vo2hOcFovs%3D" rel="nofollow" target="_blank">【Unity Shader Graph 使用与特效实现】</a><strong>专栏-直达</strong></blockquote><p>在Unity的Shader Graph中，Ambient节点是一个重要的环境光照访问工具，它允许着色器获取场景中的环境光照信息。环境光照是全局照明的重要组成部分，能够为场景中的物体提供基础照明，模拟间接光照效果，增强场景的真实感和深度。</p><p>Ambient节点的核心功能是提供对Unity场景环境光照设置的访问。在Unity中，环境光照可以通过Window &gt; Rendering &gt; Lighting &gt; Environment面板进行配置。Ambient节点将这些设置暴露给Shader Graph，使得着色器能够根据场景的环境光照设置动态调整材质的外观。</p><h2>描述</h2><p>Ambient节点的主要作用是允许着色器访问场景的环境颜色值。这个节点的行为取决于Unity Lighting窗口中的Environment Lighting Source设置。当Environment Lighting Source设置为Gradient时，节点的Color/Sky端口将返回Sky Color值；当设置为Color时，Color/Sky端口将返回Ambient Color值。</p><p>无论Environment Lighting Source设置为何值，Equator和Ground端口都会始终分别返回Equator Color和Ground Color值。这种设计使得着色器能够灵活地适应不同的环境光照配置，同时保持对特定环境颜色成分的访问。</p><p>需要注意的是，Ambient节点的值更新时机是有限的。仅当进入运行模式或保存当前场景/项目时，才会更新此节点的值。这意味着在编辑模式下修改环境光照设置时，Shader Graph中的Ambient节点可能不会立即反映这些变化，直到执行上述操作之一。</p><p>另一个重要注意事项是，此节点的行为未在全局范围内统一定义。Shader Graph本身并不定义此节点的具体函数实现，而是由每个渲染管线为此节点定义要执行的HLSL代码。这意味着不同的渲染管线可能会产生不同的结果，这是在使用Ambient节点时需要特别注意的。</p><h3>环境光照源类型详解</h3><p>Unity中的环境光照源主要有两种配置方式，每种方式都会影响Ambient节点的输出结果：</p><ul><li><strong>Color模式</strong>：当Environment Lighting Source设置为Color时，环境光照使用单一颜色值。这种模式下，Ambient节点的Color/Sky端口将返回在Lighting窗口中设置的Ambient Color值。这种配置适用于需要简单、统一环境照明的场景，或者风格化渲染中。</li><li><strong>Gradient模式</strong>：当选择Gradient模式时，环境光照使用三种颜色组成的渐变：Sky Color（天空颜色）、Equator Color（赤道颜色）和Ground Color（地面颜色）。这种模式下，Ambient节点的Color/Sky端口返回Sky Color，而Equator和Ground端口分别返回对应的颜色值。这种配置能够创建更加自然的环境光照效果，模拟从天空到地面的颜色过渡。</li></ul><h3>使用限制与注意事项</h3><p>Ambient节点在使用中有几个重要的限制需要了解：</p><ul><li><strong>值更新时机</strong>：Ambient节点的值不会实时更新。只有在进入运行模式或保存场景/项目时，节点才会更新其输出值。这意味着在编辑模式下调整环境光照设置时，需要执行这些操作之一才能看到更新后的效果。</li><li><strong>渲染管线依赖性</strong>：此节点的行为完全依赖于所使用的渲染管线。不同的渲染管线可能实现不同的环境光照计算方式，导致相同的着色器在不同管线中产生不同的视觉效果。</li><li><strong>跨管线兼容性</strong>：如果计划构建需要在多个渲染管线中使用的着色器，务必在实际应用前在两个管线中都进行检查测试。某些节点可能在一个渲染管线中已定义，而在另一个中未定义。</li><li><strong>未定义行为处理</strong>：如果Ambient节点在某个渲染管线中未定义，它将返回0（黑色）。这可能导致着色器显示异常，因此在跨管线开发时需要特别注意。</li></ul><h2>支持的渲染管线</h2><p>Ambient节点的支持情况因渲染管线而异：</p><ul><li><strong>通用渲染管线（URP）</strong>：完全支持Ambient节点。在URP中，Ambient节点能够正确访问场景的环境光照设置，并根据Environment Lighting Source配置返回相应的颜色值。</li><li><strong>高清渲染管线（HDRP）</strong>：不支持Ambient节点。HDRP使用不同的环境光照系统，因此需要采用其他方法访问环境光照信息。在HDRP中，通常使用HDRI天空或物理天空系统，并通过不同的节点或方式访问环境光照。</li><li><strong>内置渲染管线</strong>：在传统的内置渲染管线中，Ambient节点通常能够正常工作，但具体行为可能因Unity版本而异。</li></ul><p>了解所在渲染管线对Ambient节点的支持情况至关重要，特别是在进行跨管线项目开发或着色器资源迁移时。如果需要在HDRP中实现类似环境光照访问的功能，通常需要探索HDRP特定的节点和光照访问方法。</p><h2>端口</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608297" alt="" title=""/></p><p>Ambient节点提供三个输出端口，每个端口都输出Vector 3类型的三维向量，表示RGB颜色值。这些端口使着色器能够访问环境光照的不同组成部分，为材质提供丰富的环境光照信息。</p><h3>Color/Sky 端口</h3><p>Color/Sky端口是Ambient节点的主要输出端口，其行为随Environment Lighting Source设置而变化：</p><ul><li>当Environment Lighting Source设置为Color时，此端口返回Ambient Color值</li><li>当Environment Lighting Source设置为Gradient时，此端口返回Sky Color值</li><li>输出类型为Vector 3，包含RGB颜色分量</li><li>这是最常用的环境光照访问端口，通常用于提供材质的基础环境照明</li></ul><h3>Equator 端口</h3><p>Equator端口提供对环境光照中赤道颜色成分的访问：</p><ul><li>无论Environment Lighting Source设置为何值，此端口始终返回Equator Color值</li><li>在Gradient模式下，Equator Color表示天空与地面之间的中间颜色</li><li>在Color模式下，Equator Color仍然可用，但通常与Ambient Color相同或类似</li><li>输出类型为Vector 3，可用于创建更复杂的环境光照响应效果</li></ul><h3>Ground 端口</h3><p>Ground端口专门用于访问环境光照中的地面颜色：</p><ul><li>无论Environment Lighting Source设置为何值，此端口始终返回Ground Color值</li><li>在Gradient模式下，Ground Color表示场景底部的环境颜色，模拟地面反射的光照</li><li>在Color模式下，Ground Color仍然可用，但通常与Ambient Color相同或类似</li><li>输出类型为Vector 3，适用于需要区分上下表面环境照明的材质</li></ul><h3>端口使用策略</h3><p>理解这些端口的特性和行为对于有效使用Ambient节点至关重要：</p><ul><li><strong>动态行为</strong>：Color/Sky端口的动态特性使其能够适应不同的环境光照配置，但这也意味着着色器在不同配置下可能产生不同的视觉效果</li><li><strong>一致性保证</strong>：Equator和Ground端口的一致行为使得着色器能够可靠地访问这些特定的环境颜色成分，无论整体环境光照如何配置</li><li><strong>数据绑定</strong>：这些端口均无特定绑定，直接输出颜色值，可以连接到任何接受Vector 3输入的节点，如颜色混合、光照计算或材质参数</li></ul><h2>环境光照配置与Ambient节点的关系</h2><p>要充分利用Ambient节点，需要深入理解Unity环境光照系统的工作原理及其与节点的交互方式。环境光照不仅影响场景的整体亮度，还极大地影响材质的视觉表现和场景的氛围。</p><h3>Environment Lighting Source配置</h3><p>Environment Lighting Source是控制环境光照行为的核心设置，位于Lighting窗口的Environment部分。这一设置直接影响Ambient节点的输出：</p><ul><li><p><strong>Color模式配置</strong>：</p><ul><li>设置单一的Ambient Color，影响整个场景的环境光照</li><li>Ambient Intensity控制环境光的强度</li><li>在这种模式下，Ambient节点的Color/Sky端口直接返回Ambient Color值</li><li>适用于风格化场景或性能要求较高的项目</li></ul></li><li><p><strong>Gradient模式配置</strong>：</p><ul><li>设置三个颜色值：Sky、Equator和Ground</li><li>创建从天空到地面的颜色渐变，模拟更自然的环境光照</li><li>Ambient节点的三个端口分别对应这三个颜色值</li><li>Intensity控制整体环境光强度</li><li>适用于追求真实照明的场景</li></ul></li><li><p><strong>Skybox模式</strong>：</p><ul><li>使用指定的天空盒材质提供环境光照</li><li>环境颜色从天空盒动态采样计算</li><li>Ambient节点在这种模式下的行为可能因渲染管线而异</li><li>提供最真实的环境光照效果，但计算成本较高</li></ul></li></ul><h3>环境反射与环境光照</h3><p>除了直接的环境光照，Unity还提供了环境反射设置，与环境光照协同工作：</p><ul><li><strong>Source设置</strong>：可以选择Skybox或Custom提供环境反射</li><li><p><strong>Resolution</strong>：控制环境反射贴图的分辨率</p><ul><li><strong>Compression</strong>：设置环境反射贴图的压缩方式</li><li><strong>Intensity</strong>：控制环境反射的强度，影响材质的反射效果</li></ul></li></ul><p>环境反射与环境光照共同作用，决定了材质如何响应场景的全局照明。Ambient节点主要关注环境光照（直接照明），而环境反射通常通过反射探头或天空盒单独处理。</p><h3>实时更新与烘焙考虑</h3><p>环境光照的设置还与光照烘焙方式相关：</p><ul><li><strong>Realtime环境光照</strong>：动态变化的环境光照会实时影响Ambient节点的输出</li><li><strong>Baked环境光照</strong>：烘焙到光照贴图的环境光照在运行时不变，Ambient节点输出相应固定值</li><li><strong>Mixed光照</strong>：结合实时和烘焙特性，Ambient节点可能需要特殊处理</li></ul><p>理解这些光照模式对于预测Ambient节点在不同场景中的行为非常重要，特别是在涉及动态光照变化或昼夜循环的项目中。</p><h2>实际应用示例</h2><p>Ambient节点在Shader Graph中有多种实际应用，从简单的颜色调整到复杂的环境响应效果。以下是一些常见的应用场景和实现方法。</p><h3>基础环境光照应用</h3><p>最基本的应用是将环境光照直接应用于材质：</p><ul><li>创建Unlit Master节点，将Ambient节点的Color/Sky端口直接连接到Base Color输入</li><li>这样材质将完全由环境光照着色，随着环境光照设置的变化而改变外观</li><li>适用于需要完全环境照明的物体，如全息投影或发光体</li></ul><h3>环境敏感材质</h3><p>创建根据环境光照改变外观的智能材质：</p><ul><li>使用Ambient节点的输出控制材质的颜色、亮度或反射率</li><li>例如，将环境光照强度与材质发射强度相乘，创建在明亮环境中较暗、在黑暗环境中较亮的自发光材质</li><li>可以使用 Separate RGB 节点分离环境颜色分量，分别控制材质的不同属性</li></ul><h3>三色环境混合</h3><p>利用Ambient节点的三个输出端口创建复杂的环境响应：</p><ul><li>根据表面法线方向在Sky、Equator和Ground颜色之间混合</li><li>使用Normal Vector节点获取表面法线，通过Dot Product计算法线与世界空间向上方向的点积</li><li>根据点积结果使用Lerp节点在三色之间混合，创建与方向相关的环境着色</li></ul><h3>环境遮蔽增强</h3><p>结合环境遮蔽贴图增强环境光照效果：</p><ul><li>将Ambient节点输出与AO贴图相乘，创建更加真实的环境光照响应</li><li>在凹处和遮蔽区域减少环境光照影响，增强场景的深度感和立体感</li><li>可以使用Multiply节点简单混合，或使用更复杂的混合函数实现特定效果</li></ul><h3>动态材质调整</h3><p>通过脚本动态调整环境光照，并观察材质响应：</p><ul><li>在运行时通过Lighting API修改环境光照设置</li><li>观察材质如何实时响应这些变化（注意Ambient节点的更新限制）</li><li>适用于需要程序化控制场景氛围或实现昼夜循环的项目</li></ul><h2>生成的代码示例</h2><p>Ambient节点在生成的着色器代码中对应特定的HLSL宏或变量。理解这些生成的代码有助于深入理解节点的行为，并在需要时进行手动调整或优化。</p><h3>标准生成代码</h3><p>典型的Ambient节点生成代码如下：</p><pre><code>float3 _Ambient_ColorSky = SHADERGRAPH_AMBIENT_SKY;
float3 _Ambient_Equator = SHADERGRAPH_AMBIENT_EQUATOR;
float3 _Ambient_Ground = SHADERGRAPH_AMBIENT_GROUND;</code></pre><p>这段代码声明了三个float3变量，分别对应Ambient节点的三个输出端口。这些变量通过特定的宏（SHADERGRAPH_AMBIENT_SKY等）获取实际的环境光照值。</p><h3>宏定义与渲染管线差异</h3><p>不同渲染管线为这些环境光照宏提供了不同的实现：</p><ul><li><strong>通用渲染管线（URP）</strong>：这些宏通常指向URP着色器库中定义的环境光照变量</li><li><strong>内置渲染管线</strong>：可能使用Unity内置的着色器变量，如UNITY_LIGHTMODEL_AMBIENT</li><li><strong>自定义实现</strong>：在某些情况下，可能需要手动定义这些宏以提供自定义环境光照行为</li></ul><h3>代码集成示例</h3><p>在实际着色器中，Ambient节点生成的代码会与其他着色器代码集成：</p><pre><code>// Ambient节点生成的变量
float3 _Ambient_ColorSky = SHADERGRAPH_AMBIENT_SKY;
float3 _Ambient_Equator = SHADERGRAPH_AMBIENT_EQUATOR;
float3 _Ambient_Ground = SHADERGRAPH_AMBIENT_GROUND;

// 表面着色器函数
void SurfaceFunction_float(float3 Normal, out float3 Out)
{
    // 基于法线方向混合环境颜色
    float skyFactor = saturate(dot(Normal, float3(0, 1, 0)));
    float groundFactor = saturate(dot(Normal, float3(0, -1, 0)));
    float equatorFactor = 1.0 - skyFactor - groundFactor;

    // 混合环境颜色
    Out = _Ambient_ColorSky * skyFactor +
          _Ambient_Equator * equatorFactor +
          _Ambient_Ground * groundFactor;
}</code></pre><p>这个示例展示了如何利用Ambient节点生成的变量创建基于法线方向的环境颜色混合效果。</p><h2>故障排除与最佳实践</h2><p>使用Ambient节点时可能会遇到各种问题，了解常见问题及其解决方案非常重要。同时，遵循一些最佳实践可以确保环境光照在着色器中的正确应用。</p><h3>常见问题与解决方案</h3><ul><li><p><strong>问题：Ambient节点返回黑色</strong></p><ul><li>可能原因：渲染管线不支持Ambient节点</li><li>解决方案：检查当前渲染管线，考虑使用替代方案或切换至支持的管线</li><li>可能原因：环境光照未正确设置</li><li>解决方案：检查Lighting窗口中的环境光照设置，确保已配置有效的环境颜色或渐变</li></ul></li><li><p><strong>问题：环境光照不更新</strong></p><ul><li>可能原因：Ambient节点值更新限制</li><li>解决方案：进入运行模式或保存场景/项目以更新节点值</li><li>可能原因：环境光照设置为Baked且未重新烘焙</li><li>解决方案：重新烘焙光照或切换至Realtime环境光照</li></ul></li><li><p><strong>问题：不同平台表现不一致</strong></p><ul><li>可能原因：不同平台对环境光照的支持差异</li><li>解决方案：在所有目标平台上测试着色器，必要时添加平台特定处理</li><li>可能原因：移动设备性能限制导致环境光照简化</li><li>解决方案：为移动设备使用简化的环境光照模型</li></ul></li></ul><h3>性能优化建议</h3><p>环境光照访问通常性能开销较低，但在某些情况下仍需注意优化：</p><ul><li>避免在片段着色器中频繁进行复杂的环境光照计算</li><li>考虑在顶点着色器中计算环境光照，并通过插值传递到片段着色器</li><li>对于静态物体，可以考虑将环境光照烘焙到顶点颜色或光照贴图中</li><li>在性能敏感的平台（如移动设备）上，使用简化的环境光照模型</li></ul><h3>跨管线兼容性策略</h3><p>确保着色器在多个渲染管线中正常工作：</p><ul><li>在目标渲染管线中早期测试Ambient节点的行为</li><li>使用Shader Graph的Node Library功能检查节点在不同管线中的可用性</li><li>考虑为不支持Ambient节点的管线提供回退实现</li><li>使用Custom Function节点编写特定于管线的环境光照代码</li></ul><h3>版本兼容性注意事项</h3><p>不同Unity版本可能对环境光照系统和Ambient节点有所改变：</p><ul><li>在升级Unity版本时，检查环境光照相关的新功能或变更</li><li>注意不同版本间渲染管线的更新可能影响Ambient节点的行为</li><li>定期查看Unity官方文档和更新日志，了解相关变更</li></ul><h2>高级应用技巧</h2><p>一旦掌握了Ambient节点的基本原理，可以探索一些高级应用技巧，创建更加复杂和有趣的环境响应效果。</p><h3>动态环境响应</h3><p>创建根据环境条件动态调整的材质：</p><ul><li>使用Time节点结合环境光照创建脉动或呼吸效果</li><li>根据环境亮度自动调整材质的发射强度或反射率</li><li>使用场景中的光源信息与环境光照结合，创建更加真实的照明响应</li></ul><h3>风格化环境着色</h3><p>利用环境光照创建非真实感渲染效果：</p><ul><li>将环境颜色转换为灰度，用于卡通着色中的阴影区域</li><li>使用Posterize节点量化环境光照，创建色块化效果</li><li>通过自定义曲线重新映射环境光照强度，实现特定的艺术风格</li></ul><h3>环境光照遮罩</h3><p>创建只影响特定区域的环境光照效果：</p><ul><li>使用贴图或程序化生成的遮罩控制环境光照的应用区域</li><li>结合顶点颜色或UV坐标创建复杂的环境光照分布</li><li>使用世界空间位置驱动环境光照强度，模拟局部环境效果</li></ul><h3>多环境系统集成</h3><p>将Ambient节点与其他环境系统结合：</p><ul><li>与环境反射探头结合，创建完整的环境响应材质</li><li>与光照探头代理体积（LPPV）集成，实现动态环境光照</li><li>结合全局光照系统，创建更加真实的材质外观</li></ul><hr/><blockquote><a href="https://link.segmentfault.com/?enc=UQxH5G5yzeXGIyeGOqcc1A%3D%3D.9qCaYo7PcFMg3ffX1MJBtY3XCzDFHU86LlP2xu%2Bg%2BEq%2FUF4Jb8mOqI527tBY8y3x6fPwMS8LeiJhlzQcAyEQZ%2FXu7ecY0AU6l1fXMJqf6jkkspTnvua6KSsTMGfPfmKstd%2Fu6spOTpA24RF9jle1S402FrQFZ1whs8XR40ANnfaA%2Bd3fCwY%2BMYS38CBeVOrCp9DrlUJ9CNXlg4bZ6V%2BzmTKzax7xDOiLxGf8HtmG2sg%3D" rel="nofollow" target="_blank">【Unity Shader Graph 使用与特效实现】</a><strong>专栏-直达</strong><br/>（欢迎<em>点赞留言</em>探讨，更多人加入进来能更加完善这个探索的过程，🙏）</blockquote>]]></description></item><item>    <title><![CDATA[SQLAlchemy 技术入门指南 小小张说故事 ]]></title>    <link>https://segmentfault.com/a/1190000047608306</link>    <guid>https://segmentfault.com/a/1190000047608306</guid>    <pubDate>2026-02-12 20:01:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>1. 库的概览与核心价值</h2><p>想象一下，在编写 Web 应用或数据处理程序时，如果需要直接使用 SQL 语句与数据库交互，就像在高速公路上骑着自行车——虽然能够到达目的地，但不仅效率低下，而且随时可能因为写错一个关键字而导致整个程序崩溃。<code>SQLAlchemy</code> 正是为解决这个痛点而生的 Python 数据库工具包。</p><p><strong>SQLAlchemy</strong> 是 Python 中最流行的 SQL 工具包和对象关系映射器（ORM），它在 Python 生态系统中占据着不可替代的地位。简单来说，SQLAlchemy 提供了两种使用方式：</p><ul><li><strong>Core（核心层）</strong>：一个灵活的 SQL 表达式语言，允许你用 Python 代码构造 SQL 语句</li><li><strong>ORM（对象关系映射）</strong>：将数据库表映射为 Python 类，让你可以像操作普通对象一样操作数据库</li></ul><p>SQLAlchemy 的核心价值在于：</p><ul><li><strong>桥接 Python 和 SQL 的鸿沟</strong>：用 Python 的思维来操作数据库，无需编写复杂的 SQL</li><li><strong>数据库无关性</strong>：支持 MySQL、PostgreSQL、SQLite、Oracle 等多种数据库，代码无需修改即可切换</li><li><strong>企业级特性</strong>：提供连接池、事务管理、关系映射等高级功能</li><li><strong>渐进式学习</strong>：可以从简单的 Core 开始，逐步学习强大的 ORM 功能</li></ul><h2>2. 环境搭建与 "Hello, World"</h2><h3>安装说明</h3><p>安装 SQLAlchemy 非常简单，使用 pip 即可：</p><pre><code class="bash"># 安装最新稳定版
pip install SQLAlchemy

# 安装指定版本（如 2.0.x）
pip install SQLAlchemy==2.0.45

# 安装预发布版本（用于测试新特性）
pip install --pre SQLAlchemy</code></pre><p>如果需要支持特定数据库，还需要安装对应的 DBAPI（以 PostgreSQL 为例）：</p><pre><code class="bash">pip install psycopg2-binary  # PostgreSQL
pip install pymysql          # MySQL
pip install cx-Oracle        # Oracle</code></pre><h3>最简示例</h3><p>让我们通过一个完整的 "Hello World" 示例来快速了解 SQLAlchemy 的基本用法：</p><pre><code class="python">from sqlalchemy import create_engine, Column, Integer, String
from sqlalchemy.orm import DeclarativeBase, Session

# 1. 定义基础类
class Base(DeclarativeBase):
    pass

# 2. 定义模型（映射到数据库表）
class User(Base):
    __tablename__ = 'users'
    
    id = Column(Integer, primary_key=True)
    name = Column(String(50), nullable=False)
    email = Column(String(100), unique=True)

# 3. 创建数据库引擎（使用 SQLite）
engine = create_engine('sqlite:///example.db', echo=True)

# 4. 创建表结构
Base.metadata.create_all(engine)

# 5. 插入数据
with Session(engine) as session:
    # 创建新用户对象
    new_user = User(name='张三', email='zhangsan@example.com')
    
    # 添加到会话
    session.add(new_user)
    
    # 提交到数据库
    session.commit()
    
    # 查询数据
    users = session.query(User).all()
    for user in users:
        print(f'ID: {user.id}, 姓名: {user.name}, 邮箱: {user.email}')</code></pre><h3>代码逐行解释</h3><ul><li><strong>第 1-3 行</strong>：导入必要的模块。<code>create_engine</code> 用于建立数据库连接，<code>Column</code> 等用于定义表结构</li><li><strong>第 6-7 行</strong>：定义 <code>Base</code> 类，这是所有 ORM 模型的基类</li><li><strong>第 10-16 行</strong>：定义 <code>User</code> 类，它对应数据库中的 <code>users</code> 表。<code>__tablename__</code> 指定表名，各个 <code>Column</code> 定义表字段</li><li><strong>第 19 行</strong>：创建数据库引擎，<code>sqlite:///example.db</code> 表示使用 SQLite 数据库（文件名：example.db），<code>echo=True</code> 会打印执行的 SQL 语句，便于调试</li><li><strong>第 22 行</strong>：根据模型定义创建所有表（如果表已存在则跳过）</li><li><strong>第 25 行</strong>：创建会话（Session），会话是 ORM 与数据库交互的桥梁</li><li><strong>第 28 行</strong>：创建一个 User 对象，相当于创建了一条记录</li><li><strong>第 30 行</strong>：将对象添加到会话的"待提交区"</li><li><strong>第 32 行</strong>：提交事务，将数据真正写入数据库</li><li><strong>第 35-37 行</strong>：查询所有用户并打印</li></ul><p><strong>运行结果</strong>：</p><pre><code>ID: 1, 姓名: 张三, 邮箱: zhangsan@example.com</code></pre><p><strong>常见安装问题</strong>：</p><ul><li>如果安装失败，尝试使用国内镜像：<code>pip install -i https://pypi.tuna.tsinghua.edu.cn/simple SQLAlchemy</code></li><li>Windows 用户安装某些数据库驱动可能需要 Visual C++ 运行时库</li></ul><h2>3. 核心概念解析</h2><p>SQLAlchemy 的架构清晰，核心概念主要包括以下几个部分：</p><h3>3.1 Engine（引擎）</h3><p><code>Engine</code> 是 SQLAlchemy 的心脏，负责管理与数据库的连接池和实际通信。</p><pre><code class="python">from sqlalchemy import create_engine

# 创建引擎
engine = create_engine('postgresql://user:password@localhost/mydatabase')

# 引擎本身不直接连接数据库，而是在需要时从连接池中获取连接</code></pre><p><strong>关键点</strong>：</p><ul><li>Engine 是线程安全的，一个应用程序通常只需要一个 Engine 实例</li><li>它维护一个连接池，自动管理数据库连接的创建和复用</li></ul><h3>3.2 Session（会话）</h3><p><code>Session</code> 是 ORM 的核心，实现了工作单元（Unit of Work）模式。它负责：</p><ul><li>跟踪所有被加载或创建的对象</li><li>记录这些对象的状态变化</li><li>在提交时将所有变更一次性同步到数据库</li></ul><pre><code class="python">from sqlalchemy.orm import Session

# 创建会话
with Session(engine) as session:
    # 会话内部的工作
    pass</code></pre><h3>3.3 Model（模型）</h3><p>模型（或称为映射类）是数据库表的 Python 表示。每个模型类都继承自 <code>DeclarativeBase</code>（SQLAlchemy 2.0+）或使用 <code>declarative_base</code>（旧版本）。</p><h3>3.4 概念关系图</h3><pre style="display:none;"><code class="mermaid">graph TD
    A[Engine 引擎] --&gt;|管理连接池| B[Connection 连接]
    B --&gt;|执行SQL| C[Database 数据库]
    
    A --&gt;|创建| D[Session 会话]
    D --&gt;|操作| E[Model 模型]
    
    D --&gt;|跟踪状态变化| F[Unit of Work 工作单元]
    F --&gt;|提交事务| B
    
    E --&gt;|映射到| G[Table 表结构]
    G --&gt;|包含| H[Column 列]
    H --&gt;|可关联| I[Relationship 关系]
    
    style A fill:#e1f5ff
    style D fill:#fff4e1
    style E fill:#ffe1e1</code></pre><p><strong>概念间的关系</strong>：</p><ol><li><strong>Engine → Session</strong>：Session 基于 Engine 创建，使用 Engine 的连接池</li><li><strong>Session → Model</strong>：Session 负责管理 Model 对象的生命周期</li><li><strong>Model → Table</strong>：Model 类通过声明式映射到数据库表</li><li><strong>Session → Unit of Work</strong>：Session 内部实现了工作单元模式，自动跟踪对象变化</li></ol><p><strong>工作流程</strong>：</p><ol><li>创建 Engine（连接数据库）</li><li>定义 Model（定义表结构）</li><li>创建 Session（交互桥梁）</li><li>操作 Model 对象（CRUD 操作）</li><li>Session.commit()（提交事务）</li></ol><h2>4. 实战演练：构建博客系统的文章管理</h2><p>让我们通过一个完整的实战项目——博客文章管理系统——来综合运用 SQLAlchemy 的核心功能。</p><h3>需求分析</h3><p>我们需要实现一个简单的博客系统，具备以下功能：</p><ul><li>存储文章信息（标题、内容、发布时间）</li><li>存储作者信息（用户名、邮箱）</li><li>每篇文章关联一个作者（一对多关系）</li><li>支持增删改查（CRUD）操作</li></ul><h3>方案设计</h3><p>我们将使用 SQLAlchemy 的 ORM 功能：</p><ul><li>创建两个模型：<code>Author</code>（作者）和 <code>Article</code>（文章）</li><li>使用 <code>relationship</code> 建立一对多关系</li><li>使用 <code>Session</code> 完成数据持久化和查询</li></ul><h3>代码实现</h3><pre><code class="python">from sqlalchemy import create_engine, Column, Integer, String, DateTime, ForeignKey, func
from sqlalchemy.orm import DeclarativeBase, Session, relationship
from datetime import datetime

# 1. 定义基础类
class Base(DeclarativeBase):
    pass

# 2. 定义 Author 模型（作者表）
class Author(Base):
    __tablename__ = 'authors'
    
    id = Column(Integer, primary_key=True)
    username = Column(String(50), nullable=False, unique=True)
    email = Column(String(100), nullable=False, unique=True)
    
    # 一对多关系：一个作者可以有多篇文章
    articles = relationship('Article', back_populates='author', cascade='all, delete-orphan')

# 3. 定义 Article 模型（文章表）
class Article(Base):
    __tablename__ = 'articles'
    
    id = Column(Integer, primary_key=True)
    title = Column(String(200), nullable=False)
    content = Column(String, nullable=False)
    publish_time = Column(DateTime, default=func.now())
    author_id = Column(Integer, ForeignKey('authors.id'), nullable=False)
    
    # 反向关系：文章属于一个作者
    author = relationship('Author', back_populates='articles')

# 4. 创建数据库引擎
engine = create_engine('sqlite:///blog.db', echo=False)

# 5. 创建表结构
Base.metadata.create_all(engine)

# 6. 实战操作：完整的 CRUD 流程
with Session(engine) as session:
    
    # ========== 创建（Create）==========
    print("=== 创建作者和文章 ===")
    
    # 创建作者
    author1 = Author(username='小明', email='xiaoming@example.com')
    author2 = Author(username='小红', email='xiaohong@example.com')
    
    # 创建文章并关联作者
    article1 = Article(
        title='SQLAlchemy 入门指南',
        content='SQLAlchemy 是一个强大的 Python ORM 框架...',
        author=author1
    )
    article2 = Article(
        title='Python 高级编程技巧',
        content='装饰器、生成器、上下文管理器...',
        author=author1
    )
    article3 = Article(
        title='Web 开发最佳实践',
        content='RESTful API 设计原则...',
        author=author2
    )
    
    # 批量添加到会话
    session.add_all([author1, author2, article1, article2, article3])
    session.commit()
    
    print(f"✓ 已创建 2 位作者和 3 篇文章\n")
    
    # ========== 读取（Read）==========
    print("=== 查询文章 ===")
    
    # 查询所有文章
    all_articles = session.query(Article).all()
    for article in all_articles:
        print(f"文章: {article.title}")
        print(f"  作者: {article.author.username}")
        print(f"  发布时间: {article.publish_time}")
        print()
    
    # 查询某位作者的所有文章
    print("=== 查询小明的所有文章 ===")
    ming_articles = session.query(Article).join(Author).filter(Author.username == '小明').all()
    for article in ming_articles:
        print(f"- {article.title}")
    print()
    
    # ========== 更新（Update）==========
    print("=== 更新文章 ===")
    
    # 找到要更新的文章
    article_to_update = session.query(Article).filter(Article.title == 'SQLAlchemy 入门指南').first()
    article_to_update.title = 'SQLAlchemy 2.0 完全指南（更新版）'
    article_to_update.content = '本文将深入介绍 SQLAlchemy 2.0 的新特性...'
    session.commit()
    
    print(f"✓ 已更新文章标题为：{article_to_update.title}\n")
    
    # ========== 删除（Delete）==========
    print("=== 删除文章 ===")
    
    # 删除某篇文章
    article_to_delete = session.query(Article).filter(Article.title == 'Web 开发最佳实践').first()
    session.delete(article_to_delete)
    session.commit()
    
    print("✓ 已删除文章：Web 开发最佳实践\n")
    
    # ========== 最终统计 ==========
    print("=== 最终统计 ===")
    print(f"作者数量: {session.query(Author).count()}")
    print(f"文章数量: {session.query(Article).count()}")
    print(f"小明的文章数: {len(ming_articles)}")</code></pre><h3>运行说明</h3><ol><li>将上述代码保存为 <code>blog_demo.py</code></li><li>确保已安装 SQLAlchemy：<code>pip install SQLAlchemy</code></li><li>运行程序：<code>python blog_demo.py</code></li></ol><h3>运行结果</h3><pre><code>=== 创建作者和文章 ===
✓ 已创建 2 位作者和 3 篇文章

=== 查询文章 ===
文章: SQLAlchemy 入门指南
  作者: 小明
  发布时间: 2026-02-03 11:05:58

文章: Python 高级编程技巧
  作者: 小明
  发布时间: 2026-02-03 11:05:58

文章: Web 开发最佳实践
  作者: 小红
  发布时间: 2026-02-03 11:05:58

=== 查询小明的所有文章 ===
- SQLAlchemy 入门指南
- Python 高级编程技巧

=== 更新文章 ===
✓ 已更新文章标题为：SQLAlchemy 2.0 完全指南（更新版）

=== 删除文章 ===
✓ 已删除文章：Web 开发最佳实践

=== 最终统计 ===
作者数量: 2
文章数量: 2
小明的文章数: 2</code></pre><h3>关键知识点</h3><ol><li><strong>关系映射</strong>：使用 <code>relationship</code> 定义模型间的关系，<code>back_populates</code> 实现双向关联</li><li><strong>级联删除</strong>：<code>cascade='all, delete-orphan'</code> 表示删除作者时自动删除其所有文章</li><li><strong>默认值</strong>：<code>default=func.now()</code> 使用数据库函数自动填充发布时间</li><li><strong>外键约束</strong>：<code>ForeignKey</code> 确保数据完整性</li><li><strong>链式查询</strong>：<code>session.query().join().filter()</code> 构建复杂查询</li></ol><h2>5. 最佳实践与常见陷阱</h2><h3>常见错误与规避方法</h3><h4>错误 1：忘记提交事务</h4><pre><code class="python"># ❌ 错误做法
with Session(engine) as session:
    new_user = User(name='张三')
    session.add(new_user)
    # 忘记 session.commit()，数据不会写入数据库！

# ✅ 正确做法
with Session(engine) as session:
    new_user = User(name='张三')
    session.add(new_user)
    session.commit()  # 必须提交！</code></pre><p><strong>原因</strong>：SQLAlchemy 默认开启事务，不调用 <code>commit()</code> 就不会真正写入数据库。</p><h4>错误 2：N+1 查询问题</h4><pre><code class="python"># ❌ 错误做法（会触发 N+1 次查询）
users = session.query(User).all()
for user in users:
    print(user.name, user.orders)  # 每次访问 orders 都会触发一次新查询

# ✅ 正确做法（使用 eager loading 一次性加载）
from sqlalchemy.orm import selectinload
users = session.query(User).options(selectinload(User.orders)).all()
for user in users:
    print(user.name, user.orders)  # 不再触发额外查询</code></pre><p><strong>原因</strong>：懒加载会导致循环中频繁查询数据库，性能极差。</p><h4>错误 3：跨 Session 使用对象</h4><pre><code class="python"># ❌ 错误做法
with Session(engine) as session1:
    user = session1.query(User).first()

with Session(engine) as session2:
    # user 属于 session1，不能在 session2 中使用
    user.name = '新名字'  # 可能报错或无法保存
    session2.commit()

# ✅ 正确做法
with Session(engine) as session1:
    user = session1.query(User).first()
    user_id = user.id

with Session(engine) as session2:
    user = session2.query(User).get(user_id)
    user.name = '新名字'
    session2.commit()</code></pre><p><strong>原因</strong>：每个 Session 维护自己的对象缓存，对象不能跨 Session 使用。</p><h3>最佳实践建议</h3><ol><li><p><strong>使用上下文管理器</strong></p><pre><code class="python"># 推荐
with Session(engine) as session:
    # 操作
    pass
# 自动关闭 session</code></pre></li><li><p><strong>合理设置连接池大小</strong></p><pre><code class="python"># 根据应用并发量调整
engine = create_engine('postgresql://...', pool_size=10, max_overflow=20)</code></pre></li><li><p><strong>使用环境变量存储敏感信息</strong></p><pre><code class="python">import os
DATABASE_URL = os.getenv('DATABASE_URL', 'sqlite:///default.db')
engine = create_engine(DATABASE_URL)</code></pre></li><li><p><strong>添加索引优化查询</strong></p><pre><code class="python">class User(Base):
    email = Column(String(100), unique=True, index=True)  # 为常用查询字段添加索引</code></pre></li><li><p><strong>使用类型提示提高代码质量</strong>（SQLAlchemy 2.0+）</p><pre><code class="python">from typing import Optional
from sqlalchemy.orm import Mapped, mapped_column

class User(Base):
    name: Mapped[str] = mapped_column(String(50))
    age: Mapped[Optional[int]] = mapped_column()  # 可空字段</code></pre></li></ol><h2>6. 进阶指引</h2><h3>高级功能</h3><ul><li><strong>异步支持</strong>：SQLAlchemy 2.0+ 全面支持 <code>asyncio</code>，可使用 <code>AsyncSession</code> 进行异步数据库操作</li><li><strong>混合属性</strong>：结合 Python 属性和 SQL 表达式，定义可计算的字段</li><li><strong>事件监听</strong>：监听对象的创建、修改、删除等事件，实现业务逻辑解耦</li><li><strong>批量操作</strong>：使用 <code>bulk_insert_mappings</code> 等方法进行高性能批量插入</li></ul><h3>生态扩展</h3><ul><li><strong>Alembic</strong>：SQLAlchemy 官方的数据库迁移工具，用于管理数据库 schema 变更</li><li><strong>Flask-SQLAlchemy</strong>：Flask 框架的 SQLAlchemy 集成，简化 Web 开发</li><li><strong>GeoAlchemy2</strong>：支持地理空间数据类型和查询</li></ul><h3>学习路径</h3><ol><li><strong>巩固基础</strong>：熟练掌握 Core 和 ORM 的基本用法</li><li><strong>深入学习关系</strong>：理解各种关系模式（一对一、一对多、多对多）和加载策略</li><li><strong>性能优化</strong>：学习索引、连接池、批量操作等性能优化技巧</li><li><strong>架构设计</strong>：掌握复杂业务场景下的数据模型设计</li><li><strong>源码阅读</strong>：深入理解 SQLAlchemy 的实现原理</li></ol><h3>推荐资源</h3><ul><li><strong>官方文档</strong>：<a href="https://link.segmentfault.com/?enc=2gWbCHGgAFNWhOpNySnDkg%3D%3D.0%2F3Zf30BdzG1BoLfzEMr71IEZyb%2BCE3FrR9vbgEB%2FXQ%3D" rel="nofollow" target="_blank">https://docs.sqlalchemy.org/</a></li><li><strong>SQLAlchemy 2.0 教程</strong>：<a href="https://link.segmentfault.com/?enc=YYdm%2FsMZYYbOEpV36IVSXg%3D%3D.R%2FrQOxw7gYwSOf6n0C8uIf7Qb4R9WwuSBRj3lgcHnN%2Bur7bvp%2BnPnUc5Qtq%2FPEI%2B" rel="nofollow" target="_blank">https://docs.sqlalchemy.org/en/20/tutorial/</a></li><li><strong>中文社区</strong>：<a href="https://link.segmentfault.com/?enc=tXYgTM1MS2shEzA04MUqIg%3D%3D.BrBJ3wL49T8WLUEPewPzuQkt4%2BIgjuK4C5jPVoIV8XgGJedqiroVwV3taqPmHh0w" rel="nofollow" target="_blank">https://docs.sqlalchemy.org.cn/zh_CN/20/</a></li><li><strong>GitHub 示例代码</strong>：<a href="https://link.segmentfault.com/?enc=AbCFS8WIK06kasgzFnt8eA%3D%3D.xA3k3WCYiqxgG7j%2FbXknMhNqKmqYY9VfW3ehRDESQovf8DXIfF%2BZDzEbVFGKlEHece47MrQMxR7ls5JgA6NVrQ%3D%3D" rel="nofollow" target="_blank">https://github.com/sqlalchemy/sqlalchemy/tree/main/examples</a></li></ul><hr/><p>SQLAlchemy 是一个功能强大且设计优雅的 Python 数据库工具包。掌握它不仅能提升开发效率，还能帮助你更好地理解数据库和对象关系映射的原理。建议读者结合实际项目多加练习，逐步深入理解其高级特性。祝学习愉快！</p>]]></description></item><item>    <title><![CDATA[从0到1到100：中小学学科答题小程序的设计与实现 CC同学呀 ]]></title>    <link>https://segmentfault.com/a/1190000047608128</link>    <guid>https://segmentfault.com/a/1190000047608128</guid>    <pubDate>2026-02-12 19:03:29</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>研究背景</h2><p>在教育信息化 2.0 行动计划的推动下，数字化学习工具逐渐融入中小学的日常教学与课后辅导中。中小学生的注意力持续时间较短，传统的刷题模式形式单一、趣味性不足，难以调动学生的学习积极性，而游戏化学习模式将学习与互动、竞赛相结合，能够有效提升学生的参与度和学习效率。<br/>微信作为国内用户量最大的社交平台，其小程序生态日趋完善，具有无需下载安装、即用即走、开发成本低、传播便捷等特点，非常适合开发轻量化的教育类应用。同时，腾讯微信云开发技术为小程序提供了一站式的云端开发解决方案，无需开发者搭建独立的服务器和域名，降低了小程序的开发和部署门槛，为教育类小程序的快速开发提供了技术支撑。在此背景下，设计并实现一款基于微信云开发的中小学学科答题小程序，能够满足校方、教师的教学辅助需求和家长的课后辅导需求，助力中小学教育的数字化转型。</p><h2>主要研究内容</h2><p>（1）通过调研中小学教学和课后辅导的实际需求，结合游戏化学习理论，完成小程序的功能性和非功能性需求分析，并进行技术、经济、操作可行性分析；<br/>（2）确定小程序的设计原则，设计基于微信云开发的系统架构，将小程序划分为前端用户模块和后台管理模块，并对各模块的功能进行详细设计；<br/>（3）根据需求分析和总体设计，完成小程序的数据库设计，设计用户表、题库表、答题记录表、竞赛表等核心数据表的结构；<br/>（4）选择微信小程序平台和腾讯云开发技术作为核心技术栈，完成小程序前端页面的开发、云函数的编写和后台管理功能的实现；<br/>（5）制定详细的系统部署步骤，完成小程序的本地部署和云端发布，并设计功能测试用例，对小程序的各项功能进行测试，验证系统的稳定性和实用性；<br/>（6）总结本次研究的成果和不足，对小程序的后续优化和功能拓展进行展望。</p><h2>系统需求分析</h2><p>需求分析是系统开发的基础，通过调研校方、教师、家长和学生的实际需求，明确系统的功能和性能要求，为后续的系统设计和实现提供依据。本次调研采用问卷调查和访谈相结合的方式，调研对象包括中小学教师、家长和学生，共发放问卷 300 份，回收有效问卷 286 份，访谈中小学教师 20 名、家长 30 名。</p><h2>功能性需求</h2><p>根据调研结果，将中小学学科答题小程序的用户分为普通用户（学生）、<strong> 管理用户（教师 / 家长 / 校方管理员）</strong> 两类，不同用户的功能性需求不同，同时小程序需满足基础的系统管理需求，具体功能性需求如下：<br/>2.1.1 普通用户（学生）需求<br/>普通用户为中小学学生，核心需求是通过小程序进行学科知识点的练习和答题竞赛，具体需求包括：<br/>（1）用户登录：支持通过微信授权快速登录，无需单独注册账号，登录后可查看个人信息和答题记录；<br/>（2）题库选择：支持按照学科（数学、语文、英语等）和知识点对题库进行分类筛选，方便学生选择针对性的知识点进行练习；<br/>（3）随机抽题：支持选择特定学科或知识点，由系统随机生成题目进行练习，抽题数量可灵活选择；<br/>（4）答题练习：答题过程中显示题目序号、题干和答题选项，支持选择题、判断题等常见题型，答题完成后即时显示答题结果；<br/>（5）解析详解：每道题目答题完成后，提供详细的解答和解题思路解析，帮助学生理解错题原因，巩固知识点；<br/>（6）答题竞赛：支持参与模拟竞赛，竞赛前可查看竞赛规则（答题时间、题目数量），竞赛过程中倒计时显示，答题完成后即时显示竞赛成绩；<br/>（7）排行榜查看：支持查看答题竞赛的积分排行榜，按积分从高到低排序，显示用户昵称、积分和排名，提升学习的竞争性；<br/>（8）个人中心：支持查看个人答题记录（答题次数、正确率、错题集）、竞赛记录（竞赛次数、最高成绩、平均成绩），可修改个人昵称等基础信息。</p><h2>系统基础需求</h2><p>（1）权限管理：实现超级管理员和普通管理员的权限分离，超级管理员拥有所有操作权限，普通管理员仅拥有题库管理、答题参数设置等部分权限；<br/>（2）数据备份与恢复：支持对题库、用户信息等核心数据进行备份，防止数据丢失；支持在数据异常时进行数据恢复；<br/>（3）缓存清理：支持清理小程序的本地缓存，提升小程序的运行速度。</p><h2>性能需求</h2><p>（1）响应速度：小程序前端页面的加载时间不超过 3 秒，随机抽题、答题结果展示、排行榜查看等操作的响应时间不超过 1 秒；<br/>（2）并发处理：支持至少 100 名用户同时参与答题竞赛，系统无卡顿、无延迟；<br/>（3）数据处理：支持 Excel 文件批量导入题库，5000 条数据的导入时间不超过 30 秒。</p><h2>技术可行性</h2><p>本小程序基于微信小程序平台和腾讯微信云开发技术进行开发，相关技术均为腾讯官方推出，技术文档完善、社区支持活跃，开发门槛较低。<br/>（1）微信小程序的开发框架提供了丰富的组件和 API，支持前端页面的快速开发，且兼容 iOS 和 Android 两大移动操作系统；<br/>（2）微信云开发技术提供了云函数、云数据库、云存储、定时器等一站式云端服务，无需开发者搭建独立的服务器和域名，降低了后端开发的复杂度；<br/>（3）开发所需的辅助技术如 Node.js、NPM 均为开源技术，学习资源丰富，开发者可快速掌握；<br/>（4）微信开发者工具为小程序的开发、调试、预览、部署提供了一体化的支持，支持本地调试和真机测试，方便开发过程中的问题排查。</p><h2>经济可行性</h2><p>本项目的开发和部署成本较低，后期维护成本几乎为零，具有良好的经济可行性：<br/>（1）开发成本：项目基于开源技术和腾讯免费的云开发基础配额进行开发，开发过程中无需支付软件授权费、服务器租赁费、域名注册费等费用；<br/>（2）部署成本：微信云开发的资源配额价格低廉，基础版配额可满足中小学校方的日常使用需求，即使后续需要提升资源配额，费用也远低于传统的服务器部署；<br/>（3）维护成本：微信云开发由腾讯官方进行维护，无需开发者进行服务器的运维、升级、安全防护等工作，节省了大量的维护人力和物力成本；<br/>（4）使用成本：小程序对用户完全免费，用户无需支付任何费用即可使用所有功能，易于推广和使用。</p><h2>系统总体设计</h2><p>模块化设计原则：将系统划分为多个独立的功能模块，每个模块实现特定的功能，模块之间通过统一的接口进行交互，降低模块之间的耦合度，方便后续的功能扩展和 bug 修复；<br/>用户体验优先原则：结合中小学生和管理员的使用习惯，进行前端界面和操作流程的设计，保证界面友好、操作简单，提升用户的使用体验；<br/>轻量化设计原则：基于微信小程序 “即用即走” 的特性，简化前端页面的代码和资源，降低小程序的代码包大小，提升页面的加载速度；<br/>云原生设计原则：充分利用微信云开发的技术优势，将业务逻辑、数据存储、文件存储均部署在云端，实现前后端的解耦，降低本地开发的复杂度；<br/>权限最小化原则：针对不同的管理员角色分配最小的操作权限，超级管理员拥有所有权限，普通管理员仅拥有必要的操作权限，保证系统的数据安全；<br/>可扩展设计原则：在系统架构和数据库设计中，预留扩展接口和字段，方便后续新增功能和扩展数据类型，适应不同用户的个性化需求。</p><h2>数据库设计</h2><p>本小程序采用微信云开发的云数据库进行数据存储，云数据库是一种非关系型数据库（NoSQL），以集合（Collection）为单位存储数据，每个集合包含多个文档（Document），文档采用 JSON 格式存储数据，具有灵活的结构，适合小程序的轻量化开发需求。根据系统的功能需求，设计用户集合、题库集合、答题记录集合、竞赛记录集合、管理员集合、答题参数集合、系统日志集合七个核心集合<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047608130" alt="在这里插入图片描述" title="在这里插入图片描述"/></p><h2>前端功能实现</h2><p>小程序前端是用户与系统的交互界面，采用 WXML、WXSS、JavaScript 进行开发，遵循微信小程序的页面 - 逻辑 - 配置开发模式，每个页面由.wxml（页面结构）、.wxss（页面样式）、.js（页面逻辑）、.json（页面配置）四个文件组成。前端功能实现的核心是通过微信云开发的 API 与云端进行交互，将用户的操作请求发送至云函数，接收云函数返回的处理结果，并完成页面的动态渲染。</p><h2>云函数实现</h2><p>云函数是本小程序的业务逻辑处理核心，基于 Node.js 开发，核心云函数为mcloud，包含用户管理、题库管理、答题处理、竞赛管理、参数设置、数据统计六大业务模块的处理逻辑。云函数的开发遵循模块化原则，将不同的业务逻辑拆分为不同的函数，通过action参数区分前端的请求类型，实现对不同请求的处理。</p><pre><code class="c">// 得分统计
    async statAnswer(userId) { 
        let where = {
            ANSWER_USER_ID: userId,
            ANSWER_TYPE: 1
        }
        let cnt = await AnswerModel.count(where);
        let score = await AnswerModel.sum(where, 'ANSWER_SCORE');

        let data = {
            USER_ANSWER_CNT: cnt,
            USER_ANSWER_SCORE: score
        }
        await UserModel.edit({ USER_MINI_OPENID: userId }, data);
    }

    // 每日可答题次数校验
    async isAnswerTimes(userId, cateId) {
        let dayCnt = 100;
        let setup = await setupUtil.get('answer');
        if (setup) {
            setup = dataUtil.dbForms2Obj(setup);
            dayCnt = Number(setup.daycnt);

            if (setup.open != true) {
                return '竞赛尚未开始!';
            }
        }

        let where = {
            ANSWER_CATE_ID: String(cateId),
            ANSWER_USER_ID: userId,
            ANSWER_TYPE: 1,
            ANSWER_DAY: timeUtil.time('Y-M-D')
        }
        let cnt = await AnswerModel.count(where);
        if (cnt &gt;= dayCnt) {
            return '每日竞赛答题最多' + dayCnt + '次，请明日再来！';
        }

        return '';
    }

    async saveMyAnswer(userId,
     ) { 
     
    }

    // 随机N条记录，生成本次题库
    async genQuestion(userId, type, cateId) { 

        return { questionList: [], maxTime:10 };
    }


    async getMyAnswerList(userId, {
        search, // 搜索条件
        sortType, // 搜索菜单
        sortVal, // 搜索菜单
        orderBy, // 排序 
        page,
        size,
        isTotal = true,
        oldTotal
    }) {

        orderBy = orderBy || {
            'ANSWER_ADD_TIME': 'desc'
        };
        let fields = 'ANSWER_SCORE,ANSWER_CATE_NAME,ANSWER_TYPE,ANSWER_ADD_TIME,ANSWER_CNT,ANSWER_PER,ANSWER_SUCC_CNT,ANSWER_DURATION,ANSWER_START,ANSWER_END';

        let where = {};
        where.and = {
            ANSWER_USER_ID: userId,
            _pid: this.getProjectId() //复杂的查询在此处标注PID
        };

        if (util.isDefined(search) &amp;&amp; search) {
            where.or = [

            ];
        } else if (sortType &amp;&amp; util.isDefined(sortVal)) {
            // 搜索菜单
            switch (sortType) {
                case 'type': {
                    where.and.ANSWER_TYPE = Number(sortVal);
                    break;
                }
                case 'cateId': {
                    where.and.ANSWER_CATE_ID = String(sortVal);
                    break;
                }
                case 'sort': {
                    orderBy = this.fmtOrderBySort(sortVal, 'ANSWER_ADD_TIME');
                    break;
                }
            }
        }

        return await AnswerModel.getList(where, fields, orderBy, page, size, isTotal, oldTotal);
    }</code></pre><h2>git代码</h2><p><a href="https://link.segmentfault.com/?enc=V92CkP8G%2BWcBS%2BKMkoFfWQ%3D%3D.bR%2F3FP4EO%2FSx0mVt%2FH6HqcCGaWYeUerfvHoyxrcOQbcldhPjTBy0Wp%2FVUOi7%2B3FL" rel="nofollow" target="_blank">点击下载</a></p>]]></description></item><item>    <title><![CDATA[函数计算 AgentRun 重磅上线知识库功能，赋能智能体更“懂”你 阿里云云原生 ]]></title>    <link>https://segmentfault.com/a/1190000047608137</link>    <guid>https://segmentfault.com/a/1190000047608137</guid>    <pubDate>2026-02-12 19:02:57</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>作者：靖苏</p><p>阿里云函数计算 <strong>AgentRun</strong> 正式推出全新<strong>知识库功能</strong>，为智能体（Agent）注入更强的语义理解与上下文感知能力。通过深度集成<strong>百炼知识库</strong>与 <strong>RAGFlow 知识库</strong>，AgentRun 让开发者能够轻松构建具备“知识”的智能应用，真正实现“更懂用户、更贴场景、更高效响应”。</p><h2>为什么需要知识库？</h2><p>在传统智能体开发中，模型往往依赖通用训练数据，缺乏对特定业务、私有文档或实时信息的理解能力。这导致其在面对专业领域问题、企业内部知识或个性化需求时表现受限。</p><p>AgentRun 的知识库功能正是为解决这一痛点而生——它将外部知识源无缝接入智能体运行流程，通过<strong>检索增强生成（RAG）</strong> 技术，让智能体在回答问题、执行任务时，能动态调用相关知识，大幅提升准确性、专业性与可信度。</p><h2>双引擎支持：百炼+RAGFlow，覆盖多元知识形态</h2><h3>百炼知识库绑定</h3><p>函数计算 AgentRun 可以绑定您账号下已经创建好的阿里云百炼知识库 <strong>[</strong> <strong>1]</strong> 。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608139" alt="image" title="image"/></p><p>进入到创建页面，输入知识库名称、描述，选择知识库类型为“百炼”，可以多选绑定您账号下已经在阿里云百炼控制台创建好的多个知识库。填写检索配置后，点击创建知识库，即可将您的阿里云百炼知识库绑定至 AgentRun 平台。</p><h3>RAGFlow 知识库绑定</h3><p>函数计算 AgentRun 可以绑定您账号下已经创建好的 RAGFlow 知识库。如果您没有 RAGFlow 知识库，可以点击此链接（<a href="https://link.segmentfault.com/?enc=iUpFBqMSTnskNUwGWsrSsA%3D%3D.MW%2FyadxC%2FEOH8RAW%2FuQVEiMezpwMwpRlk6e2IkyMBe%2Fwed60OUcYytUyJEAvtKXrPNc2eLtUIFawWFKSPGJZaU7xtxvcyssOjz7kM8PZ2DYM75KE5QVyBGFl83ayIn6HtEXK2ZTA95wV1GNFSywgPObaruyWmaoWvqUMA1a10qa0a8u%2BUh8%2F6dw712oYEoowXMtzvqEuM%2B34Tj379bCtS7SKi8SL36auZUtCUAnS%2FZM4LZQ0qfcedr9mD4UDP9A93mEVgbEOdtpPP935BbyOLg%3D%3D" rel="nofollow" target="_blank">https://saenext.console.aliyun.com/cn-hangzhou/scene-market/m...</a> ），一键在 SAE 上创建 RAGFlow。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608140" alt="image" title="image" loading="lazy"/></p><p>进入到创建页面，输入知识库名称、描述，选择知识库类型为“RAGFlow”，填写您已部署的 RAGFlow 的 BaseURL、Dataset IDs 和 API-KEY（将其保存在凭证中）。填写检索配置后，点击创建知识库，即可将您自建的 RAGFlow 知识库绑定至 AgentRun 平台。</p><p>RAGFlow 知识库详细配置获取方式，可参考此文档：<a href="https://link.segmentfault.com/?enc=fv9Df6vGBIXkxrsEY0iTXQ%3D%3D.l7hIce0MNnwe%2F8pM0kIvM39A7xVmJ92YWj139WmYbfxKpWPzWmQLlBLr7Twqs4N41df1CbSOs5uWZO5tcAVlihXGSQmscvYPrnb1wIJPwhw%3D" rel="nofollow" target="_blank">https://help.aliyun.com/zh/functioncompute/fc/knowledge-base-...</a>。</p><h2>三大集成方式，灵活适配各类开发场景</h2><p>函数计算 AgentRun 知识库功能支持快速创建集成、代码集成和 MCP 集成三种方式，满足不同技术栈和开发习惯。</p><h3>快速创建Agent集成知识库功能</h3><p>对于希望快速验证想法或加速产品迭代的团队，AgentRun 提供了<strong>低代码、可视化</strong>的知识库绑定能力。开发者只需登录 AgentRun 控制台，选择已创建的百炼或 RAGFlow 知识库，将其关联到目标智能体，并配置简单的检索参数（如返回结果数量、相似度阈值等），即可完成集成——全程无需编写一行代码。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608141" alt="image" title="image" loading="lazy"/></p><p>这一模式极大降低了技术门槛，让产品经理、运营人员甚至非技术背景的创新者也能参与智能体的构建与优化。无论是搭建内部知识问答机器人、客户自助服务助手，还是快速验证某个垂直领域的 AI 应用场景，都能在<strong>几分钟内完成部署并上线试用</strong>。</p><p><strong>代码集成知识库查询能力</strong>对于追求极致灵活性与控制力的开发者，AgentRun 提供了<strong>原生代码级知识库接入能力</strong>。您可以在代码逻辑中，调用 AgentRun SDK 的知识库检索接口，根据业务上下文动态发起检索请求，精准筛选并注入最相关的信息片段到智能体的推理流程中。您可以使用 AgentRun SDK，调用以下封装的接口，进行单知识库查询或多知识库查询。</p><pre><code>fromagentrun.knowledgebaseimportKnowledgeBase
## 获取单知识库，进行查询
knowledgebase=KnowledgeBase.get_by_name("ragflow-test")
single_kb_retrieve_result=knowledgebase.retrieve("&lt;your-query&gt;")
print(single_kb_retrieve_result)
## 获取多知识库，进行查询，支持跨供应商知识库类型检索
multi_kb_retrieve_result=KnowledgeBase.multi_retrieve(
    query="&lt;your-query&gt;",
    knowledge_base_names=["ragflow-test","&lt;your-knowledge-base-name-2&gt;"],
)
print(multi_kb_retrieve_result)</code></pre><p>同样，您可以集成 LangChain 框架，将知识库的查询能力集成在工具或上下文中。</p><pre><code>"""AgentRun 知识库智能体集成代码示例
使用前，请参考https://docs.agent.run/docs/tutorial/quick-start 配置好相应认证信息和环境变量
curl http://127.0.0.1:9000/openai/v1/chat/completions -X POST \
    -H "Content-Type: application/json" \
    -d '{"messages": [{"role": "user", "content": "什么是Serverless?"}], "stream": true}'
"""
import json
import os
from typing import Any
from langchain.agents import create_agent
import pydash
from agentrun import Config
from agentrun.integration.langchain import model
from agentrun.integration.langchain import knowledgebase_toolset
from agentrun.integration.langgraph.agent_converter import AgentRunConverter
from agentrun.knowledgebase import KnowledgeBase
from agentrun.server import AgentRequest, AgentRunServer
from agentrun.server.model import ServerConfig
from agentrun.utils.log import logger
# 请替换为您已经创建的 模型 名称
AGENTRUN_MODEL_SERVICE = os.getenv("AGENTRUN_MODEL_SERVICE", "&lt;your-model-service&gt;")
AGENTRUN_MODEL_NAME = os.getenv("AGENTRUN_MODEL_NAME", "&lt;your-model-name&gt;")
KNOWLEDGE_BASES = os.getenv("AGENTRUN_KNOWLEDGE_BASES", "ragflow-test").split(",")
if AGENTRUN_MODEL_NAME.startswith("&lt;") or not AGENTRUN_MODEL_NAME:
    raise ValueError("请将 MODEL_NAME 替换为您已经创建的模型名称")
## 加载知识库工具，知识库可以以工具的方式供Agent进行调用
knowledgebase_tools = []
if KNOWLEDGE_BASES and not KNOWLEDGE_BASES[0].startswith("&lt;"):
    knowledgebase_tools = knowledgebase_toolset(
        knowledge_base_names=KNOWLEDGE_BASES,
    )
else:
    logger.warning("KNOWLEDGE_BASES 未设置或未替换，跳过加载知识库工具。")
agent = create_agent(
    model=model(AGENTRUN_MODEL_SERVICE, model=AGENTRUN_MODEL_NAME, config=Config(timeout=180)),
    tools=[
        *knowledgebase_tools,   ## 通过工具集成知识库查询能力
    ],
    system_prompt="你是一个 AgentRun 的 AI 专家，可以通过查询知识库文档来回答用户的问题。",
)
async def invoke_agent(request: AgentRequest):
    messages = [
        {"role": msg.role, "content": msg.content}
        for msg in request.messages
    ]
    # 如果配置了知识库，查询知识库并将结果添加到上下文
    if KNOWLEDGE_BASES and not KNOWLEDGE_BASES[0].startswith("&lt;"):
        # 获取用户最新的消息内容作为查询
        user_query = None
        for msg in reversed(request.messages):
            if msg.role == "user":
                user_query = msg.content
                break
        if user_query:
            try:
                retrieve_result = await KnowledgeBase.multi_retrieve_async(
                    query=user_query,
                    knowledge_base_names=KNOWLEDGE_BASES,
                )
                # 直接将检索结果添加到上下文
                if retrieve_result:
                    messages.append({
                        "role": "assistant",
                        "content": json.dumps(retrieve_result, ensure_ascii=False),
                    })
            except Exception as e:
                logger.warning(f"知识库检索失败: {e}")
    input: Any = {"messages": messages}
    converter = AgentRunConverter()
    if request.stream:
        async def async_generator():
            async for event in agent.astream(input, stream_mode="updates"):
                for item in converter.convert(event):
                    yield item
        return async_generator()
    else:
        result = await agent.ainvoke(input)
        return pydash.get(result, "messages[-1].content", "")
AgentRunServer(
    invoke_agent=invoke_agent,
    config=ServerConfig(
        cors_origins=[
            "*"
        ]
    ),
).start()</code></pre><p>注意⚠️：如果您选择了 RAGFlow 的知识库，<strong>需要确保您的 Agent 运行环境和 RAGFlow 的 BaseURL 的地址处于同一网络环境下，否则 AgentRun SDK 将无法调用 RAGFlow 的 API 实现查询能力。</strong></p><p>通过代码集成，AgentRun 赋予开发者“全栈可控”的能力——既享受函数计算的弹性与免运维优势，又保留对智能体认知过程的深度掌控，真正实现“知识为我所用，逻辑由我定义”。</p><h3>MCP 集成：将知识库检索作为 Agent 的工具调用</h3><p>AgentRun 知识库率先实现“Agentic RAG”（智能体 RAG）模式——将传统静态检索升级为动态、可编程的智能体工具调用。具体而言，用户可一键将知识库发布为 MCP，使其成为大语言模型（LLM）可主动调用的工具之一。在此模式下，LLM 不再被动接收上下文，而是具备“工具使用能力”，在推理过程中自主判断何时调用 RAG、数据库查询、库存检查等工具，并基于返回结果进行多步推理与任务分解。这种机制使 RAG 从单一检索功能转变为智能体工具箱中的灵活组件，与其他工具并列协作，显著提升复杂任务的处理能力。其工作方式更贴近人类“思考—行动—反思”的认知流程：模型先分析问题，制定计划，再按需调用多个工具获取信息，最终整合结果生成答案。</p><p>进入其他 &gt;&gt; 工具管理 &gt;&gt; 工具市场，可以搜索到 <strong>“AgentRun 知识库 MCP”</strong> 工具模板，点击安装后，填写知识库名称和类型，即可将知识库的查询能力一件发布成 MCP 工具给大模型进行调用。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608142" alt="image" title="image" loading="lazy"/></p><p>创建完毕后，点击工具详情，即可看到集成调用的工具地址：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608143" alt="image" title="image" loading="lazy"/></p><p>基于 MCP 工具标准协议，AgentRun 支持以标准化方式对接知识库服务，实现跨平台、跨模型的上下文注入能力，保障架构的开放性与可扩展性。</p><h2>结语：从“能回答”到“真理解”，智能体正在拥有“知识之眼”</h2><p>AgentRun 知识库功能的上线，不仅是一次技术能力的升级，更标志着智能体发展迈入新阶段——从依赖通用语料的“泛化应答”，转向基于专属知识的“情境理解”。当智能体能够随时调用企业文档、行业规范、用户历史甚至实时数据，它便不再只是一个语言模型的接口，而成为一个<strong>具备领域认知、上下文记忆与决策依据的数字协作者</strong>。</p><p>未来，随着知识库的持续进化——支持多模态内容、动态更新、跨源推理——AgentRun 将进一步降低构建“有知识、有逻辑、有温度”智能体的门槛。</p><p>我们相信，真正的智能，不在于模型有多大，而在于是否“懂你所需、知你所问、信你所依”。</p><p><strong>AgentRun，正让每一个智能体，学会思考，更学会理解。</strong></p><p><strong>相关链接：</strong></p><p>[1] 阿里云百炼知识库</p><p><a href="https://link.segmentfault.com/?enc=lxliN5coN6z41szdnERlCg%3D%3D.Oa26KHsEek%2F7AykJ%2BdQYc%2BzRNh9MYL2yzdaln%2B%2FEFUnV5wEw5o6uOgeGHZiPCSNsZGlw9DB3AgrnNY1UDN4fQBnLMwYUVeU9glN%2BBwM7Ep4%3D" rel="nofollow" target="_blank">https://bailian.console.aliyun.com/cn-beijing/?admin=1&amp;tab=ap...</a></p>]]></description></item><item>    <title><![CDATA[巨人网络《超自然行动组》携手阿里云打造云原生游戏新范式 阿里云云原生 ]]></title>    <link>https://segmentfault.com/a/1190000047608151</link>    <guid>https://segmentfault.com/a/1190000047608151</guid>    <pubDate>2026-02-12 19:02:00</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>从开服第一天起，就跑在云上；</p><p>上线一年，DAU 已经突破 1000 万；</p><p>高峰期百万玩家同时在线，零重大故障。</p><p>这不是科幻，而是巨人网络与阿里云共书写的云原生实战。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608153" alt="image" title="image"/></p><h2>《超自然行动组》的云原生架构先行战略</h2><p>2025 年 1 月，巨人网络推出多人组队欢乐冒险游戏《超自然行动组》，凭借创新的“中式微恐+多人合作"的独特玩法，迅速成为现象级产品。最近，《超自然行动组》宣布 DAU 突破 1000 万，更攀升至 iOS 游戏畅销榜第四。尤为值得一提的是，自开服第一天起，<strong>这款游戏从未部署在任何物理机或传统虚拟机上——它从第一天起，就运行在云原生架构之上</strong> <strong>。</strong></p><p>对于大多数游戏公司而言，“上线即爆款” 是甜蜜的烦恼——流量洪峰来得快、退得慢，而传统架构却“笨重”：</p><ul><li>游戏服（如战斗服、房间服）部署在固定服务器，扩容需数天；</li><li>为应对峰值需长期预留资源，空闲时浪费严重；</li><li>版本更新靠脚本，灰度发布难，一出错就“全服回滚”；</li><li>日志分散、监控割裂，故障定位动辄几小时；</li><li>安全防护薄弱，易受 DDoS 攻击；</li><li>数据层瓶颈突出：战斗结算延迟、排行榜卡顿、玩家数据丢失等问题频发。</li></ul><p>《超自然行动组》团队深知：若沿用旧模式，很可能“倒在成功的路上”。</p><p>于是，他们选择了一条更难但更远的路——<strong>全面拥抱云原生</strong>。</p><p>通过 ACK（容器服务）、ESS（弹性伸缩）、网络型负载均衡 NLB、OpenKruiseGame（OKG）、SLS（日志服务）、ARMS（应用实时监控服务）、阿里云原生防护（Native Protection），以及云原生数据库 polardb 和 Redis 的深度协同，巨人网络构建了一套高弹性、高可用、低成本、智能化、高安全且高性能数据处理能力的新一代游戏基础设施，为行业树立了云原生落地的标杆。如今，随着日活跃用户（DAU）突破千万大关，这套技术体系，已经成为游戏行业“云原生转型”的标杆案例。</p><h2>高弹性×低延迟×零故障：解码&lt;超自然行动组&gt;的云原生底座</h2><p>《超自然行动组》基于阿里云 ACK 与 OpenKruiseGame（OKG）构建了业界领先的云原生游戏服架构：通过蓝绿发布与原地升级实现零停机、无感交付；通过 OKG+多 NLB 资源池，全面覆盖 BGP、电信、联通、移动等主流线路，实现多运营商网络自动化映射。结合 HPA 智能扩缩容与 OKG 优雅下线机制，在成本与用户体验间取得平衡；通过 ACK Koordinator 组件，实现 CPU Burst 与 QoS 精细化调度，显著提升集群资源利用率；并通过基础设施与业务状态的双向感知，构建起“业务语义驱动”的自动化运维闭环——真正实现了高弹性、高可用、高性能、高安全的新一代游戏后端体系。在显著降低运维压力的同时，实现了机制化、可持续的成本优化。</p><p>在网络层面，作为一款对延迟极度敏感的竞技手游，《超自然行动组》依托阿里云打造了“云边协同、三网通吃、弹性集约”的新一代云网络架构：通过 OKG 与 NLB 实现电信、联通、移动、BGP 四线并发接入，全国玩家自动匹配最优链路，并以“静态网络+动态计算”创新模式达成 50 节点/分钟的极速扩容，15 分钟内可拉起数千战斗服，彻底告别排队；同时，借助阿里云高速通道，将本地机房的账号、支付等核心系统与上海 VPC 内网直连，构建毫秒级同步、金融级安全的混合云中枢；并通过共享带宽包统一聚合公网出口，在简化运维的同时显著降本，为玩家交互与高频状态同步提供弹性“带宽蓄水池”，真正实现千万玩家同场竞技零卡顿、零等待的极致体验。</p><p>在数据层面，云原生 polardb 和 Tair（兼容 Redis）构建了弹性，稳定的玩家存档方案，支持千万级玩家高并发登录和读写，基于 polardb 云原生数据库的存算分离和弹性能力，支持游戏在活动期间自动扩展弹性，并且支持玩家数据的秒级备份和回档，大幅降低了数据库的运维成本，并且 PolarDB Serverless 支持自动扩容和缩容，能够根据用户访问量的实时变化，秒级调整计算资源。在高峰时期自动增加资源，低谷时期自动减少资源，确保社区始终运行在最佳状态。基于阿里云 Tair（兼容 Redis）支持玩家超高并发的访问，作为实时排行榜、战斗状态缓存和匹配池的核心，依托多线程与持久内存优化，单实例 QPS 超百万，实现毫秒级排名刷新、瞬时结算与断线无缝恢复。</p><p>当数百万玩家涌入《超自然行动组》，DDoS 攻击成为影响体验的关键风险。为此，巨人网络联合阿里云，基于云原生安全架构打造了一套高性能、智能化的防护体系。该方案依托阿里云原生高防能力，无需架构改造，一键接入即可实现 TB 级 DDoS 攻击的毫秒级识别与精准清洗，防护能力行业领先。即便在版本更新或大型赛事等高并发场景下，系统仍保障 99.99% 以上服务可用性，真正做到“攻击零感知、切换无中断”。面对突发流量洪峰，系统支持防御带宽自动弹性伸缩，动态调配资源，避免因容量不足导致服务中断。同时，通过集成安全事件中心，运营团队可实时监控攻击事件，分析攻击类型与特征，并结合 AI 驱动的策略建议，快速部署定制化游戏协议防护规则，显著提升响应效率与防御精准度。从高效清洗到智能决策，阿里云以“稳定、高效、安全”为核心，为《超自然行动组》构筑起坚不可摧的数字护盾，在保障千万玩家流畅竞技的同时，也为游戏行业树立了云原生安全新标杆。</p><p>对于《超自然行动组》这款主打实时互动的竞技游戏，“能跑” 只是起点，“看得清、查得准” 才是保障千万玩家流畅体验的关键。运维团队摒弃传统分散监控工具，基于阿里云日志服务 SLS 、云监控 CMS 的 Prometheus 服务、Grafana 服务，搭建起轻量、标准、深度集成的可观测体系：</p><ul><li>依托 Prometheus 实时采集百万级 PCU 下的资源水位与在线人数、匹配时长等核心业务指标，确保高并发下监控精准不丢点；</li><li>通过 SLS 统一汇聚全链路日志，支持按 RequestID / 玩家 ID 秒级还原行为路径，结合 SQL 分析与自定义规则，实现地图报错统计、异常操作追踪；</li><li>借助 Grafana 打造统一全景大盘，融合展示指标与日志数据，告警时可一键跳转 SLS 查看关联日志，实现 “指标发现问题、日志定位根因” 的闭环，将故障响应时间从小时级压缩至分钟级，充分发挥云原生可观测与协同优势。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608154" alt="image" title="image" loading="lazy"/></p><p><em>超自然云原生架构</em></p><h2>从“能跑”到“跑赢”：OKG 重塑游戏后端新范式</h2><p>当一款游戏从“能跑”走向“跑得快、跑得省、跑得稳”，背后一定有一套先进的技术底座在支撑。《超自然行动组》的故事，源于巨人网络，也属于所有正在思考“如何用云原生重构游戏后端”的开发者。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608155" alt="image" title="image" loading="lazy"/></p><p>面对全球游戏市场对高并发、低延迟及快速迭代的极致追求，OpenKruiseGame (OKG) 作为阿里云打造的“为游戏而生”的云原生游戏服管理方案，正成为推动行业架构平滑升级的核心引擎。针对游戏业务特有的异构性管理难题，OKG 提供了从精细化配置、自动化网络接入到业务状态感知的一站式管理体系。它不仅极大降低了游戏厂商的云原生转型门槛，更通过全球多地域一致性交付能力，助力开发者突破地域限制，实现业务的快速敏捷部署与全球化扩张。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608156" alt="image" title="image" loading="lazy"/></p><p>云原生，已不再是互联网应用的专属，而是下一代游戏基础设施的必然选择。</p>]]></description></item><item>    <title><![CDATA[Apache Doris 4.0.3 版本正式发布 SelectDB技术团队 ]]></title>    <link>https://segmentfault.com/a/1190000047608164</link>    <guid>https://segmentfault.com/a/1190000047608164</guid>    <pubDate>2026-02-12 19:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>亲爱的社区小伙伴们，<strong>Apache Doris 4.0.3 版本已正式发布。</strong>此版本新增了在 AI &amp; Search、湖仓一体、查询引擎等方面的能力，并同步进行了多项优化改进及问题修复，欢迎下载体验！</p><ul><li>GitHub 下载：<a href="https://link.segmentfault.com/?enc=x%2B76iEQfzUlDK4tMwlVjkw%3D%3D.qQenp6u67c1y9pgPJRwosQEuTX07HU%2B83Aa8171D1QLbHozOYMtKzTXZZt%2FEtlNg" rel="nofollow" target="_blank">https://github.com/apache/doris/releases</a></li><li>官网下载：<a href="https://link.segmentfault.com/?enc=yvZWOmjIS8NWVT55MOku7A%3D%3D.lISNSqnU8TiXI7c2uxFSUySg8ShLeUKgX6NSPm4HCY6GNZw6RQyb2ehZOTTnfT1b" rel="nofollow" target="_blank">https://doris.apache.org/download</a></li></ul><h2>新增功能</h2><h3>AI &amp; Search</h3><ul><li>添加倒排索引 NORMALIZER 支持</li><li>实现类似 ES 的布尔查询</li><li>为搜索函数引入 lucene 布尔模式</li></ul><h3>湖仓一体</h3><ul><li>支持通过 AwsCredentialsProviderChain 加载 Catalog 凭证</li><li>支持使用 OSSHDFS 存储的 Paimon DLF Catalog</li><li>为 Iceberg 表添加 manifest 级别缓存</li></ul><h3>查询引擎</h3><ul><li>支持 INTERVAL 函数并修复 EXPORT_SET</li><li>支持 TIME_FORMAT 函数</li><li>支持 QUANTILE_STATE_TO/FROM_BASE64 函数</li></ul><h2>优化改进</h2><ul><li>引入加载作业系统表</li><li>使视图、物化视图、生成列和别名函数能够持久化会话变量</li><li>将表查询计划操作接收的 SQL 添加到审计日志</li><li>启用流式加载记录到审计日志系统表</li><li>通过列裁剪优化复杂类型列读取</li><li>兼容 MySQL MOD 语法</li><li>为 sql_digest 生成添加动态配置</li><li>使用 Youngs-Cramer 算法实现 REGR_SLOPE/INTERCEPT 以与 PG 对齐</li></ul><h2>问题修复</h2><ul><li>修复 JdbcConnector 关闭时的 JNI 全局引用泄漏</li><li>修复由于 BE 统计信息上传不及时导致 CBO 无法稳定选择同步物化视图的问题</li><li>用默认的 JSONB null 值替换无效的 JSONB</li><li>修复由于并发删除后端导致的 OlapTableSink.createPaloNodesInfo 空指针异常</li><li>修复 FROM DUAL 错误匹配以 dual 开头的表名</li><li>修复 BE 宕机时预热取消失败的问题</li><li>修复当物化视图被 LimitAggToTopNAgg 重写但查询未被重写时物化视图重写失败的问题</li><li>修复刷新时 lastUpdateTime 未更新的问题并添加定时刷新日志</li><li>修复 hll_from_base64 输入无效时的崩溃问题</li><li>修复带表达式的加载列映射的敏感性问题</li><li>修复删除表时未删除约束相关信息的问题</li><li>修复 parquet topn 延迟物化复杂数据错误结果</li><li>始终创建数据和索引页缓存以避免空指针</li><li>修改 tablet cooldownConfLock 以减少内存占用</li><li>修复读取 parquet footer 时缺失 profile 的问题</li><li>修复 Exception::to_string 中潜在的释放后使用问题</li><li>修复浮点字段 to_string 问题</li><li>修复读取 hudi parquet 导致 BE 崩溃的问题</li><li>修复 Kerberos 认证配置检测</li><li>修复空表下的同步失败问题</li><li>修复 parquet 类型未处理 float16 的问题</li><li>修复 BM25 LENGTH_TABLE 范数解码问题</li><li>避免某些日期类函数的误报</li></ul>]]></description></item><item>    <title><![CDATA[拒绝“Demo 级”架构：基于 SAE × SLS 构建 Dify 高可用生产底座 Serverle]]></title>    <link>https://segmentfault.com/a/1190000047608003</link>    <guid>https://segmentfault.com/a/1190000047608003</guid>    <pubDate>2026-02-12 18:04:42</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>导读：</p><blockquote><p>在上一篇<a href="https://link.segmentfault.com/?enc=aBoL1B0q0hVMJzjmzQLP4A%3D%3D.YO79WjNtq%2FguM227YmdpHW%2FS3CdfesVxha3l%2Bj1IpzEWjMz%2B2ESlwzVboIMBwQPeHMMYnfI40P%2BMF9hnxBlUWci59DtjuHEsv3Ina%2BMwRIZ2wL1EfMNyaG3BPzdYpeOIXr%2FAcqUfqAv%2BwrtO6xKwJkiXOQGJ0Cmzftah%2BzVK7r%2B1tO02l92vK899Uv3JcuBEYcYPnxiboLET9jtXqDWduzRijJ5A4rfuvtqTHOvNzL4%3D" rel="nofollow" target="_blank">《告别数据库“膨胀”：Dify x SLS 构建高可用生产级 AI 架构》</a>中，我们深度剖析了 Dify 在大规模生产场景下数据库因日志写入而面临的性能瓶颈，并介绍了通过 SLS 插件实现“存算分离”的硬核改造方案。</p><p>然而，解决“数据存储”只是跨过了生产落地的第一道坎。面对复杂的微服务运维、波动的 AI 潮汐流量，如何构建一个弹性、免运维的“计算底座”同样关键。本文作为系列的第二篇，将视野从单一的数据架构扩展至全栈基础设施，为您介绍基于 阿里云 SAE × SLS 的终极生产级解决方案。</p><p>随着 LLM 应用的爆发式增长，Dify 以其强大的工作流编排与友好的可视化界面，正成为企业构建 AI 应用的首选。然而，当应用从本地 Demo 迈向大规模生产时，开发者常会遭遇两大“隐形”挑战：运维复杂度的剧增与数据架构的性能瓶颈。</p><p>本文将深度解析这一架构瓶颈，并介绍基于阿里云 <strong>SAE（Serverless 应用引擎）</strong> 与 <strong>SLS（日志服务）</strong> 的联合解决方案。通过“全托管算力”与“存算分离”的双轮驱动，打造一个高弹性、低成本、且具备深度数据洞察力的生产级 Dify 环境。</p></blockquote><h2>一、现状与挑战：Dify 规模化落地的架构瓶颈</h2><p>在单机 Demo 阶段，使用 Docker Compose 部署配合默认的 PostgreSQL 存储方案完全够用。但一旦进入生产环境，这两项基础设施往往最先成为性能与扩展性的瓶颈。</p><h4>运维管理复杂</h4><p>Dify 是一个由 API 服务、Worker、Web 前端、KV缓存、关系型数据库、向量数据库等多个组件构成的微服务架构。在生产环境中，这种架构给运维带来了很大挑战：</p><ul><li><strong>资源缺乏弹性</strong>：AI 应用通常具有明显的流量波峰波谷特征。若采用自建 Kubernetes 或 ECS 集群，扩容响应滞后，高峰期用户排队等待，低谷期又造成大量资源闲置，推高成本。</li><li><strong>维护成本高昂</strong>：保障高可用、配置负载均衡、处理节点故障、执行蓝绿/灰度发布等基础设施工作，不仅技术门槛高，还会大量挤占开发团队本应用于业务创新的精力。</li><li><strong>性能瓶颈明显</strong>：默认部署方式下的 QPS 能力有限，难以支撑高并发场景，尤其在推理密集型任务下容易成为系统瓶颈。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608005" alt="" title=""/></p><h4>数据库容量爆炸</h4><p>Dify 默认将所有数据（包括业务元数据和运行日志）存储在 PostgreSQL 中。随着业务量增长，“数据特征”与“存储引擎”的错配问题日益凸显：</p><ul><li><strong>日志“撑爆”数据库</strong>：Workflow 的每一次节点执行，都会完整记录输入输出、Prompt、推理过程及 Token 统计等详细信息。在生产级高并发场景下，这些数据占据了数据库绝大部分资源，导致表空间迅速膨胀。</li><li><strong>拖慢核心业务：</strong> 高频、高吞吐的日志写入会大量占用数据库连接池和 I/O 资源，严重干扰核心业务操作（如创建应用、知识库检索、对话上下文管理等），导致响应延迟、超时甚至服务不可用。</li></ul><h2><strong>二、协同赋能：SAE 与 SLS 的核心优势</strong></h2><p>为解决上述瓶颈，SAE 与 SLS 协同发力——SAE 聚焦弹性算力调度，SLS 专攻海量日志存储，共同构建高性能、高可用的 Dify 运行底座。</p><h4>SAE：极致弹性的 Dify 全托管运行环境</h4><p>SAE 不仅负责 Dify 核心微服务（API、Worker、Sandbox）的编排，更通过一键化模板集成了 Dify 运行所需的完整云生态。</p><ul><li><strong>一键全栈交付：</strong> 开发者无需手动搭建复杂环境。通过预置模板，可一键部署完整的微服务集群，并自动创建和集成连通日志服务SLS（工作流日志存储）、表格存储Tablestore（向量存储）、云数据库 Redis 版（缓存）及 RDS for PostgreSQL（元数据存储）等阿里云服务，无需逐个购买和配置，实现“开箱即是生产级”的交付体验。</li><li><strong>企业级高可用保障：</strong> 实例自动分布于多可用区，配合健康检查与自愈机制规避单点故障。支持金丝雀发布，确保在工作流频繁迭代时，流量切换平滑无感。</li><li><strong>秒级算力弹性</strong>：完美适配 AI 业务的“潮汐特征”。SAE 支持按 CPU/内存利用率或 QPS 指标进行自动扩缩容。在推理高峰期，秒级拉起 Worker 实例抗压；在业务低谷期，自动释放闲置资源，将算力成本严格控制在“有效使用”范围内。</li><li><strong>深度性能调优</strong>：SAE 对 Dify 实施了穿透代码与架构的“立体调优”，不仅在底层修补了 Redis 集群适配与慢 SQL 短板，更精准调优了运行参数并对齐了资源规格。这一全链路改造驱动吞吐量实现从 10 QPS 到 500 QPS 的 50 倍跃迁，确保 AI 响应如丝般顺滑。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608006" alt="" title="" loading="lazy"/></p><h4>SLS：支撑海量数据的“存算分离”方案</h4><p>SLS 并非简单的数据库替代品，而是专为日志场景设计的云原生基础设施。相比于 PostgreSQL，SLS 在 Dify 场景下实现了四个维度的架构升级：</p><ul><li><strong>极致存储弹性：</strong> 不同于数据库需按“峰值”预置资源，SLS 作为 Saas 化服务，天然支持秒级弹性伸缩。无论是深夜的低谷还是突发的推理洪峰，都能自适应承载，无需关心分片或容量上限。</li><li><strong>架构解耦负载隔离：</strong> 相利用追加写入特性，避免了数据库常见的随机 I/O 与锁竞争，轻松支撑万级 TPS 吞吐。同时通过将日志负载彻底剥离至云端，确保海量日志写入不影响 Dify 核心业务的响应速度。</li><li><strong>分层存储低成本留存</strong>：依托高压缩比技术，热数据实时分析，冷数据自动沉降至归档存储，可以远低于数据库 SSD 的成本满足长周期的审计与回溯需求。</li><li><strong>开箱即用的业务洞察：</strong> 内置的 OLAP 分析引擎支持 SQL 实时查询、可视化报表与告警监控，帮助开发者将沉睡的日志数据转化为直观的业务洞察。</li></ul><h2><strong>三、极简部署：1 分钟定义生产级底座</strong></h2><p>SAE 应用中心内置了深度优化的 Dify 生产级模板，通过简单的参数配置，即可一键交付一套高可用就绪的运行环境，告别繁琐的 YAML 编写与环境调试。</p><p><strong>Step 1：选择部署模板</strong></p><p>登录 SAE 控制台，进入应用中心，选择 <strong>“Dify 社区版 - Serverless 部署”</strong>。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608007" alt="" title="" loading="lazy"/></p><p><strong>Step 2：配置参数与规格选型</strong></p><p>目前提供了 Dify 高性能版、Dify 高可用版、Dify 测试版 三种模板。</p><p>如果是应对高并发生产场景，建议优先选择 <strong>Dify 高性能版</strong>，该版本专门针对 <code>api</code> 镜像以及 <code>plugin-daemon</code> 镜像做了深度优化，运行效率更高。配置过程极为精简，只需手动填写各云服务的密码并选定所属的 VPC 与子网（VSW），系统便会针对选定的云资源给出一份总预估价格，确保成本清晰透明。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608008" alt="" title="" loading="lazy"/></p><p><strong>Step 3：提交并访问服务</strong></p><p>点击提交后，系统会自动完成核心服务的部署与云资源关联。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608009" alt="" title="" loading="lazy"/></p><p>部署完成后，直接在浏览器输入控制台提供的服务地址 <code>${EXTERNAL-IP}:${PORT}</code>，即可开始您的 Dify 应用编排之旅。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608010" alt="" title="" loading="lazy"/></p><blockquote>注：当Dify启动并运行之后，SLS插件会自动创建相关的logstore和索引配置。无须手动干预，直接从SLS控制台进入对应的project，即可工作流日志进行实时的查询和分析。</blockquote><h2>四、50 倍性能跃迁：SAE 从 10 QPS 到 500 QPS 的突破之路</h2><p>Dify 社区版的默认配置仅能支撑 10 QPS，但这仅仅是起步。从“尝鲜”到 500 QPS 的生产级扩容，并非简单的堆砌服务器资源，而是一场步步惊心的“闯关游戏”。每当你试图提升吞吐量时，总会撞上新的隐形天花板——从基础的参数限制到深层的架构瓶颈。SAE 团队通过全链路压测，为您提前探明并攻克了这条晋级之路上的两大核心关卡，让高性能部署变得有迹可循。</p><h4>瓶颈一：突破 10 QPS 限制——组件并发与数据库连接的协同调优</h4><ol><li><strong>为什么默认配置只有 10 QPS？</strong></li></ol><p>Dify 社区版默认配置更多是为了方便开发者快速试用，而非为大规模生产环境设计。其核心组件 dify-api 的默认参数极为保守：</p><pre><code class="plain">SERVER_WORKER_AMOUNT（工作进程数）：1
SERVER_WORKER_CONNECTIONS（单进程最大连接数）：10</code></pre><p>这两个参数直接锁死了单节点的吞吐上限。但在生产环境中，我们不能简单地将这些参数“调大十倍”，因为应用层的并发能力提升，立即会引发下游数据库的连锁反应。</p><ol start="2"><li><strong>牵一发而动全身的“连接池”难题</strong></li></ol><p>随着 QPS 的增长，dify-api 和 dify-plugin-daemon 等组件会向 PostgreSQL 发起海量连接。如果缺乏全链路的参数协同，系统极易陷入瘫痪：</p><ul><li>连接数被打满：PostgreSQL 的总连接数是有限的，盲目增加组件并发，会导致数据库连接迅速耗尽，后续请求直接报错。</li><li>组件间的连接争抢：SQLAlchemy 连接池有“懒加载”机制，且空闲连接在过期前不会释放。如果配置不当，会出现非核心组件占用大量空闲连接，而核心组件因拿不到连接而“饥饿”的情况。</li></ul><p><strong>解决方案：经过实战验证的“生产级配置矩阵”</strong></p><p>为了避免用户陷入繁琐的参数试错循环，SAE 团队在真实生产环境下进行了多轮全链路压测。 摸索出了不同流量档位下API 并发度、数据库连接池大小与各组件资源规格之间的<strong>生产级配置清单</strong>。用户无需关心具体的参数计算，只需根据预估流量选择对应的规格档位，确保每一份算力都能转化为实际的业务吞吐量。</p><blockquote>注：压测场景并不包含代码执行（Code Sandbox）链路。dify-sandbox 组件的规格与数量请根据实际业务中代码运行的复杂度自行评估调整。</blockquote><p><a href="https://link.segmentfault.com/?enc=AMoF2WRCiWPjx57lrQK8pw%3D%3D.OzN3KaTtTh0OwyvOexYn70RMcRhRlrZgTu6dttllPaZ6j3VDCrsZKASyTIKYBpJIJl3KML1kqssxaesJuSgOJA%3D%3D" rel="nofollow" target="_blank">Dify性能优化</a></p><h4>瓶颈二：从 200 QPS 到 500 QPS —— Redis 单点瓶颈与读写分离</h4><ol><li><strong>集成 ARMS 链路追踪定位性能瓶颈</strong></li></ol><p>在将数据库连接优化、QPS 稳定提升至 200 后，系统吞吐量难以进一步提高。为定位瓶颈，SAE 团队通过 SAE 平台深度集成的 ARMS 应用监控，对 dify-plugin-daemon 组件进行链路分析——在 SAE 控制台的应用详情页点击“应用监控”，即可查看耗时最长的调用链路。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608011" alt="" title="" loading="lazy"/></p><p>Trace 数据显示，下游 Redis 的 SET/DEL 操作频繁失败。SAE 团队尝试将 Redis 实例垂直扩容至最大规格（64 核），但效果甚微：QPS 仅小幅提升，SET/DEL 操作延迟却急剧升高，CPU 利用率迅速打满。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608012" alt="" title="" loading="lazy"/></p><ol start="2"><li><strong>Dify-plugin-daemon 高频读写 Redis 引发单点拥堵</strong></li></ol><p>通过代码分析发现，这是 Dify 业务逻辑与 Redis 单点架构冲突的结果：</p><ul><li>dify-plugin-daemon 在处理每次数据链路请求时，都会生成一个新的 Session ID 并写入 Redis。这种高频的写入逻辑导致 Redis 请求量居高不下。</li><li>原生架构中，所有的 Session 读写请求都全部集中在同一个 Redis 节点上。在 200+ QPS 的高并发冲击下，Redis 单线程处理能力达到极限，导致 set 和 del 等基础操作的耗时急剧增大，从而阻塞了整个请求链路。</li></ul><p><strong>解决方案：集群化改造实现读写分离</strong></p><p>为了突破单机架构限制，SAE 团队深入组件底层，对 dify-plugin-daemon 进行了集群化适配：</p><ul><li>补全集群协议：针对原生组件不支持 Redis Cluster 的问题，SAE 团队修改了底层代码，使其完整支持 Redis Cluster 协议。</li><li>实现读写分离：通过架构升级，将原本集中在单机上的海量请求分发到集群。利用集群的多节点特性，实现了流量的负载分担与读写分离。</li></ul><p>这一改造彻底解决了单点瓶颈，成功支撑业务吞吐量从 200 QPS 平滑提升至 500 QPS。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608013" alt="" title="" loading="lazy"/></p><h2>五、激活全链路数据价值：SLS 从“黑盒运行”到“深度洞察”的透视之眼</h2><p>Dify 上线后，如何评估模型的成本和性能？如何分析业务的走势？依托 SLS 强大的 OLAP 分析引擎，我们无需预先定义表结构，即可对 Dify 的工作流日志进行深度挖掘，构建覆盖“技术指标”与“业务指标”的全景仪表盘。</p><h4><strong>基础设施视角：透视 LLM 成本与性能</strong></h4><p>对于Dify的LLM节点，workflow_node_execution日志中的process_data字段中详细记录了模型的调用情况，可以用来对模型调用情况进行秒级多维分析。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608014" alt="" title="" loading="lazy"/></p><p><strong>场景 A：Token 消耗与成本审计</strong> 实时监控 Token 的消耗趋势，是控制 AI 成本的关键。我们可以统计输入（prompt_tokens）、输出（completion_tokens）及总 Token 数随时间的变化曲线，精准识别异常流量。</p><p>分析 SQL 示例：</p><pre><code class="plain">node_type:llm | select
  sum(
    json_extract_long(process_data, '$.usage.prompt_tokens')
  ) prompt_tokens,
  sum("process_data.usage.completion_tokens") completion_tokens,
  sum("process_data.usage.total_tokens") total_tokens,
  date_trunc('minute', __time__) t
group by
  t
order by
  t
limit
  all</code></pre><p>注：json中的字段可以在SQL中直接用json_extract_xxx函数进行提取分析，如<code>json_extract_long(process_data, '$.usage.prompt_tokens')</code>。对于常用的字段建议额外建立json子索引，然后在SQL中就可以引用对应的列名，如<code>"process_data.usage.completion_tokens"</code>，便于进行更高效的统计分析。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608015" alt="" title="" loading="lazy"/></p><p><strong>场景 B：首字延迟（TTFT）性能分位分析</strong> LLM 的响应速度直接影响用户体验。通过分析 <code>time_to_first_token</code> 的 P50、P90、P99 分位值，可以客观评估模型在不同负载下的响应稳定性，为模型路由或推理加速提供数据支撑。</p><p>分析 SQL 示例：</p><pre><code class="plain">node_type:llm | select
  date_format(__time__-__time__ % 60, '%m-%d %H:%i') as time,
  approx_percentile("process_data.usage.time_to_first_token", 0.25) as Latency_p25,
  approx_percentile("process_data.usage.time_to_first_token", 0.50) as Latency_p50,
  approx_percentile("process_data.usage.time_to_first_token", 0.75) as Latency_p75,
  approx_percentile("process_data.usage.time_to_first_token", 0.99) as Latency_p99,
  min("process_data.usage.time_to_first_token") as Latency_min
group by
  time
order by
  time
limit
  all</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608016" alt="" title="" loading="lazy"/></p><h4>业务运营视角：洞察用户意图与转化</h4><p>除了底层的模型指标，SLS 还能帮助我们深入理解业务逻辑。以一个“电商智能客服助手”的Dify应用为例，我们可以利用 SQL 拆解工作流节点的输入输出，辅助运营决策。</p><p><strong>场景 A：用户意图分布趋势</strong> 通过分析工作流中“意图识别”节点的输出结果，我们可以量化统计用户咨询的高频类目（如：退换货、物流查询、优惠券），并观察这些需求随时间的变化趋势，从而指导知识库的优化方向。</p><p>分析 SQL 示例：</p><pre><code class="plain">* and title: 用户意图识别 | select
  json_extract(outputs, '$.text') as "用户意图",
  count(1) as pv
group by
  "用户意图"</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608017" alt="" title="" loading="lazy"/></p><p><strong>场景 B：异常诊断与漏斗分析</strong> 通过统计特定节点的错误率或特定意图的后续流转情况，构建漏斗图，快速定位导致用户流失的节点。例如，分析“商品检索”节点的空结果率，以判断是否需要扩充商品知识库。</p><p>可以通过漏斗图，分析观察工作流哪些中间节点出现异常失败的比率较高。</p><p>分析 SQL 示例：</p><pre><code class="plain">status:succeeded | select
  title,
  count(distinct workflow_run_id) cnt
group by
  title
order by
  cnt desc</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608018" alt="" title="" loading="lazy"/></p><h2>六、结语：让 AI 应用回归业务本质</h2><p>从“能用”到“好用”，Dify 的生产级落地需要坚实的基础设施支撑。SAE 与 SLS 的联合方案，不仅仅是两个云产品的简单叠加，而是通过“算力托管”与“存储解耦”的深度协同，为 Dify 带来了全栈 Serverless 化的架构质变：</p><ul><li><strong>全栈弹性：</strong> 计算层随流量秒级伸缩，存储层无惧突发吞吐，完美适配 AI 业务的“潮汐特征”。</li><li><strong>结构性降本：</strong> 彻底消除闲置资源浪费，用低成本的分层存储替代昂贵的数据库扩容，最大化 ROI。</li><li><strong>极致稳定：</strong> 全托管免运维底座配合 I/O 物理隔离，彻底消除单点故障风险与数据库性能黑洞。</li><li><strong>深度洞察：</strong> 打通从基础设施监控到业务数据分析的“黑盒”，用 Token 成本与用户意图数据反哺业务进化。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608019" alt="" title="" loading="lazy"/></p><p>通过 SAE 联合 SLS 发布的这一解决方案，Dify开发者无需再为底层的资源和架构操心，只需一次简单的配置，即可拥有一个高可用、高性能、低成本的 AI 应用环境，从而真正专注于业务创新与 Prompt 调优。</p><p><strong>立即体验：</strong> 欢迎登录<a href="https://link.segmentfault.com/?enc=kOOHvCzGOPUs0ue0w0B9jQ%3D%3D.pm6EwFMHAJgqsayWjn1MIWvpfNLL7H6jtHAnUNmvSirNg6xLn4VoM5WgrKirAjPh" rel="nofollow" target="_blank">阿里云 SAE 控制台</a>，进入应用中心，搜索 Dify 模板，勾选Dify高性能版，开启您的一键托管之旅。</p><h3>了解 Serverless 应用引擎 SAE</h3><p>阿里云 Serverless 应用引擎 SAE 是面向 AI 时代的一站式容器化应用托管平台，以“托底传统应用、加速 AI 创新”为核心理念。它简化运维、保障稳定、闲置特性降低 75% 成本，并通过 AI 智能助手提升运维效率。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047415441" alt="" title="" loading="lazy"/>面向 AI，SAE 集成 Dify 等主流框架，支持一键部署与弹性伸缩，在 Dify 场景中实现性能<strong>提升 50 倍、成本优化 30% 以上</strong>。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047415442" alt="" title="" loading="lazy"/></p><h4>产品优势</h4><p>凭借八年技术沉淀，SAE 入选 2025 年 Gartner 云原生魔力象限全球领导者，亚洲第一，助力企业零节点管理、专注业务创新。SAE 既是传统应用现代化的“托举平台”，也是 AI 应用规模化落地的“加速引擎”。</p><ol><li><strong>传统应用运维的“简、稳、省”优化之道</strong></li></ol><ul><li>简：零运维心智，专注业务创新</li><li>稳：企业级高可用，内置全方位保障</li><li>省：极致弹性，将成本降至可度量</li></ul><p><strong>2.加速 AI 创新：从快速探索到高效落地</strong></p><ul><li>快探索：内置 Dify、RAGFlow、OpenManus 等 热门 AI 应用模板，开箱即用，分钟级启动 POC；</li><li>稳落地：提供生产级 AI 运行时，性能优化（如 Dify 性能提升 50 倍）、无感升级、多版本管理，确保企业级可靠交付；</li><li>易集成：深度打通网关、ARMS、计量、审计等能力，助力传统应用智能化升级。</li></ul><h4>适合谁？</h4><p>✅ 创业团队：没有专职运维，需要快速上线<br/>✅ 中小企业：想降本增效，拥抱云原生<br/>✅ 大型企业：需要企业级稳定性和合规性<br/>✅ 出海企业：需要中国区 + 全球部署<br/>✅ AI创新团队：想快速落地AI应用</p><h4>了解更多</h4><p>产品详情页地址：<a href="https://link.segmentfault.com/?enc=92A0EY7XQghGuN%2Bwj8NO4w%3D%3D.i0UBIhU6hSZfiKBKnG84NvySTapuGEUTtUygB3w4zwOcOANJx5pOQK8vwY%2BJNIrB" rel="nofollow" target="_blank">https://www.aliyun.com/product/sae</a></p>]]></description></item><item>    <title><![CDATA[3天工作量压缩至30分钟，重构我的Go后端开发逻辑 烦恼的沙发 ]]></title>    <link>https://segmentfault.com/a/1190000047608041</link>    <guid>https://segmentfault.com/a/1190000047608041</guid>    <pubDate>2026-02-12 18:04:00</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>不会吧，你不会现在写代码还是靠拼时长吧，不会吧？</p><p>我曾经也认为，优秀的后端工程师就是写得快、写得多。直到我发现，我把大量时间浪费在了配置环境、用Print查Bug、以及手动排查内存泄漏上。</p><p>真正的效率提升，不仅仅是手速变快了，今天分享8个彻底改变我开发逻辑的工具，它们把我的焦虑变成了生产力。</p><h2>ServBay：我再也不想在本地环境上浪费一秒钟</h2><p><img width="723" height="458" referrerpolicy="no-referrer" src="/img/bVdnVbJ" alt="image.png" title="image.png"/></p><p>说实话，每次接手新项目或者维护老项目，最让我头疼的不是代码逻辑，而是 <a href="https://link.segmentfault.com/?enc=8JZCaPwZS9E36xiS%2FmXG8w%3D%3D.RUgTilgmolDJ5z6TXjhDMsGBQjGkzULF75x0PSKxDwNI1B6gRFJBUdZQwHvBmKoa" rel="nofollow" target="_blank">Go 环境配置</a>。</p><p>以前为了跑一个老项目，我得去改 <code>.bash_profile</code>，去整 <code>GOPATH</code>，甚至因为版本冲突把本地环境搞得一团糟。如果是混合技术栈，比如还得跑个Java服务，那简直是灾难。</p><p>而 ServBay，它就是拯救我于水深火热中的。它能够了一键安装，多版本共存。我可以同时保留 Go 1.11 和最新的 Go 1.24。</p><p>现在，环境配置对我来说就是点一下鼠标的事。这种隔离且并存的能力，让我工作效率蹭蹭的。</p><h2>Delve：求求大家，别再用Print调试了</h2><p>曾几何时，我也是Print党。遇到Bug，就在代码里疯狂塞 <code>fmt.Println("111")</code>、<code>fmt.Println("here")</code>。</p><p>但在Go的高并发场景下，这种做法是一时爽，事后火葬场。Goroutine一多，控制台输出乱成一锅粥，根本看不出谁先谁后。</p><p><strong>Delve</strong> 能够仔细剖析正在运行的程序。</p><p>不需要修改代码，直接启动调试：</p><pre><code class="bash">dlv debug main.go</code></pre><p>遇到死锁或者逻辑诡异的地方，打个断点，直接看内存里的变量状态。它能清晰地展示出每一个Goroutine停在哪里。自从用了Delve，我解决并发Bug的时间从半天缩短到了几分钟。</p><h2>Cobra：写出让人想用的CLI工具</h2><p><img width="723" height="307" referrerpolicy="no-referrer" src="/img/bVdnVbK" alt="image.png" title="image.png" loading="lazy"/></p><p>以前写内部脚本，我总是偷懒直接解析 <code>os.Args</code>。结果就是，过了一个月，连我自己都忘了参数顺序是怎样的，同事用起来更是怨声载道。</p><p>后来我强制自己用 <strong>Cobra，</strong> 它是Kubernetes都在用的库。用它写出来的工具，天生就带有规范的帮助文档（--help）和子命令结构。</p><p>看看这个架子，写出来就显得很专业：</p><pre><code class="go">package main

import (
        "fmt"
        "github.com/spf13/cobra"
)

func main() {
        var rootCmd = &amp;cobra.Command{
                Use:   "deploy",
                Short: "一键部署工具",
                Run: func(cmd *cobra.Command, args []string) {
                        fmt.Println("正在执行部署逻辑...")
                },
        }
        // 哪怕只是个内部工具，也要像模像样
        rootCmd.Execute()
}</code></pre><p>把烂脚本变成正规军，Cobra是门槛最低的选择。</p><h2>GoVet：编译通过不代表逻辑正确</h2><p>编译器只能告诉我们语法没错，但它不管逻辑是不是弱智。</p><p>我有一次在 <code>if</code> 条件里把 <code>==</code> 写成了 <code>=</code>（虽然Go通常会报错，但在某些特定构造下容易混淆），或者在循环里错误地使用了闭包变量，导致线上数据全错。</p><p><strong>GoVet</strong> 就是为了拦截这种低级但致命的错误存在的。</p><pre><code class="bash">go vet ./...</code></pre><p>它专门扫描那些“看起来对，但执行起来会炸”的代码。比如 <code>Printf</code> 的参数类型不对，或者不可达的代码块。现在我把它做进了提交前的钩子（Pre-commit hook），不通过Vet检查的代码，根本不允许提交。</p><h2>Golangci-lint：我的全自动代码洁癖管家</h2><p><img width="723" height="366" referrerpolicy="no-referrer" src="/img/bVdnVbL" alt="image.png" title="image.png" loading="lazy"/></p><p>团队协作最怕什么？怕每个人的代码都有自己的想法。</p><p>与其在Code Review时因为“花括号换不换行”或者“变量名太短”吵架，不如直接上 <strong>Golangci-lint</strong>。</p><p>它不是一个工具，它是一个聚合器，并行跑了50多个检查器。</p><pre><code class="bash">golangci-lint run</code></pre><p>配置好 <code>.golangci.yml</code> 后，它就是就是一个无情的检查机器。未使用的变量、过高的圈复杂度、拼写错误，它全能抓出来。它让Code Review回归到了关注业务逻辑本身，而不是纠结语法细节。</p><h2>Pprof：甚至能看清内存的毛细血管</h2><p>服务上线后CPU突然飙高，或者内存缓慢泄漏，这时候看日志是没用的。以前我只能靠猜，现在我靠 <strong>Pprof</strong>。</p><p>只需要在代码里加一行副作用引入：</p><pre><code class="go">import _ "net/http/pprof"</code></pre><p>然后启动个HTTP服务，就能通过浏览器看到程序的X光片。</p><p>我也经常用命令行来生成火焰图：</p><pre><code class="bash">go tool pprof -http=:8080 http://localhost:6060/debug/pprof/profile</code></pre><p>哪一行代码占用了最多的CPU，哪个对象在这个瞬间分配了最多的内存，一目了然。不夸张地说，Pprof 给了我一种“上帝视角”。</p><h2>Godotenv：别把秘密写在代码里</h2><p>有些初级事故是因为把数据库密码或者AWS Key直接硬编码在代码里，然后推到了Git仓库。</p><p><strong>Godotenv</strong> 是我所有项目的标配。</p><p>开发时，我只需要在本地建一个 <code>.env</code> 文件：</p><pre><code class="plain">DB_SECRET=123456
DEBUG_MODE=true</code></pre><p>代码里直接读：</p><pre><code class="go">import "github.com/joho/godotenv"

func init() {
    // 自动加载，从此告别硬编码
    _ = godotenv.Load() 
}</code></pre><p>这样既方便本地调试，又彻底杜绝了泄密风险。</p><h2>Gosec：上线前的最后一道防线</h2><p><img width="723" height="262" referrerpolicy="no-referrer" src="/img/bVdnVbM" alt="image.png" title="image.png" loading="lazy"/></p><p>即便有了前面的工具，安全漏洞依然防不胜防。比如随机数生成器用得不安全，或者TLS配置太弱。</p><p>人工审查很难发现这些隐患，但 <strong>Gosec</strong> 可以。</p><p>它会扫描代码的抽象语法树（AST），专门寻找安全漏洞。</p><pre><code class="bash">gosec ./...</code></pre><p>它会直接甩一份报告给我，告诉我哪一行代码可能导致SQL注入，哪里的文件权限设置太宽泛。对于金融类或者对安全性要求高的项目，这是必须要跑的流程。</p><hr/><h3>低效是一种选择，而你本可以拒绝</h3><p>开发者的黄金时间极其有限。是用这仅有的精力去和环境配置搏斗、去肉眼查错，还是把它们交给工具，自己专注于构建复杂的系统逻辑？</p><p>这不只是工具的差异，这是职业生涯的加速度差异。</p><p>从今天开始，选两个装上，别让重复劳动毁了你的创造力。</p>]]></description></item><item>    <title><![CDATA[ArkUI框架运行原理与常见性能优化方案 鸿蒙百晓生 ]]></title>    <link>https://segmentfault.com/a/1190000047608043</link>    <guid>https://segmentfault.com/a/1190000047608043</guid>    <pubDate>2026-02-12 18:03:06</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>一、ArkUI框架概述</h2><p>ArkUI是OpenHarmony生态中核心的UI渲染框架，采用声明式开发范式，支持多设备（手机、平板、PC等）多端统一开发。开发者通过ArkTS语言描述界面，框架负责组件树构建、布局测量、渲染绘制及事件处理。底层由方舟运行时引擎驱动，协同无障碍、国际化等系统能力，保障高性能与良好用户体验。</p><h2>二、开发范式与执行机制</h2><ol><li>开发范式<br/>当前ArkUI中主流的开发范式采用ArkTS声明式范式，支持多端统一UI描述。在一些需要更高性能的场景下，可以采用Native API进行开发。</li><li><p>代码执行流程<br/>ETS源码经IDE编译生成ABC中间指令文件，打包成HAP安装包。应用启动时，原能力子系统启动对应应用进程，ArkUI子系统负责组件创建与渲染，最终由图形侧执行渲染指令，完成界面展示。<br/><img width="723" height="367" referrerpolicy="no-referrer" src="/img/bVdnVaP" alt="image.png" title="image.png"/></p><h2>三、渲染核心流程与状态管理</h2></li><li>组件树构建<br/>框架在运行时维护组件树的压栈与出栈，动态构建UI组件树结构。<br/><img width="208" height="312" referrerpolicy="no-referrer" src="/img/bVdnVaQ" alt="image.png" title="image.png" loading="lazy"/></li><li>布局测量与渲染绘制<br/>父节点传递约束条件，子节点自底向上计算尺寸和位置，完成布局测量。随后根据信息发送渲染指令，执行绘制操作，生成最终界面。<br/><img width="723" height="286" referrerpolicy="no-referrer" src="/img/bVdnVaR" alt="image.png" title="image.png" loading="lazy"/></li><li>差异更新机制<br/>通过装饰器（如@State、@Provider）实现状态观察，观察过程识别“脏”组件，即需要更新的组件。<br/>ArkUI区分两类“脏”状态：</li><li>布局脏：影响尺寸和位置，需重新测量布局，以及判定影响范围。</li><li><p>绘制脏：仅影响样式，重绘但不重新布局。<br/><img width="723" height="364" referrerpolicy="no-referrer" src="/img/bVdnVaS" alt="image.png" title="image.png" loading="lazy"/><br/>状态变更触发依赖收集，精准标记相关组件为脏，在布局过程只更新需要刷新的组件，避免造成组件树的重建。</p><h2>四、ArkUI应用开发性能优化方案</h2><p>1、创建过程优化<br/>方案1：使用组件懒加载机制，减少创建数量，提升响应速度。在滚动过程中进行数据读取和加载，使用LazyForEach仅渲染可视区域项，避免一次性数据加载过多，解决页面加载耗时长问题，关于长列表优化可以参考<a href="https://link.segmentfault.com/?enc=zWEXykSOrJ1MMbeDHplFKw%3D%3D.67%2FCyeohJ1Zpv3lE1l4ILTnSlZaOLiGGO2%2FPzLs4BBBnRGaBH14DkcthT4Jdjg0EQtVHekRCGpn1gKFTf9fT82%2FLI16%2BGI7GY4Z95oece5htSEUZ95MsLbwFWN5iyozfM7U%2Fg08j7KBBNh9D5hzku0N1hLpV8Hxy9vLhAS7%2BRhA%3D" rel="nofollow" target="_blank">长列表加载丢帧优化。</a><br/><img width="723" height="300" referrerpolicy="no-referrer" src="/img/bVdnVaT" alt="image.png" title="image.png" loading="lazy"/><br/>方案2：高负载场景分帧渲染，将本来一帧内加载的数据分成多帧加载，但是分帧渲染需要开发者计算每帧中加载多少数据，操作复杂，因此在必要的情况下才推荐使用。<a href="https://link.segmentfault.com/?enc=%2FNOnEvHq229sFGBknGSvGw%3D%3D.78mVGRmEWfk9mL7N%2B3DjrNsbLGSjPWN2JpgA2pZ%2Fyoi0Pqf8Q%2FeUS0l%2BN1rS7YcaPkgyudPzQatwdTETvKnsjxl2PtwOnTAdoBwxOh6y1SOjNrjAe%2BrndKwlJ8Ls%2Bfa96RJ6HHpKhNRbMFlLweBqPAtvCovA%2B4pwD8S7rstq7zCc11HXnn%2BOSSJAjkDO53TA" rel="nofollow" target="_blank">详请可点击查看</a>。<br/><img width="723" height="519" referrerpolicy="no-referrer" src="/img/bVdnVaU" alt="image.png" title="image.png" loading="lazy"/></p></li></ol><p>2、布局过程优化<br/>方案1：精简组件数量，使用扁平化布局组件（如RelativeContainer、Grid）替代多层Column/Row嵌套，减少中间节点数量。<br/><img width="723" height="95" referrerpolicy="no-referrer" src="/img/bVdnVaV" alt="image.png" title="image.png" loading="lazy"/><br/>方案2：利用布局边界减少布局计算<br/>①对固定尺寸组件设置具体宽高，限制布局影响范围。<br/>②优先使用无状态组件@Builder替代@Component，减少状态依赖。<br/><img width="723" height="450" referrerpolicy="no-referrer" src="/img/bVdnVaW" alt="image.png" title="image.png" loading="lazy"/></p><p>3、更新过程优化<br/>复用替代重建, 利用组件复用机制，减少滑动过程中组件创建、布局开销，提升帧率。<br/><img width="408" height="352" referrerpolicy="no-referrer" src="/img/bVdnVaX" alt="image.png" title="image.png" loading="lazy"/></p><p>4、状态管理优化<br/>可以采用状态管理V2进行开发，状态管理V2相对于状态管理V1优化了更新方式，由V1的对象级观察，优化为属性级观察，可以降低状态更新时带来的开销。详细内容参考：<a href="https://link.segmentfault.com/?enc=qyA230qJNl4NzOAgD8B9hg%3D%3D.YTX30JTm%2FZmmuIkL8FyRMTp9VVsdjDBsA%2BOfwoA4eC517fM03X90xEEAdr19Q1u3bdyJUgT9474NMATOs%2BC%2FQgT5Z8uOOc48L8cZeSf1JMtdOTEQg%2B0Uiro6vHw8oHRTRr2ZS3SlEU8y1XgovgY5d%2F13G9fCeWmdlizyiWDYQ8c%3D" rel="nofollow" target="_blank">状态管理V2。</a></p><h2>五、工具链支持与性能分析</h2><p>推荐使用DevEco Studio内置工具：</p><ul><li>AppAnalyzer：实现“体检-报告-修复”一体化流程，快速定位布局耗时及性能瓶颈。</li><li>通过工具量化指标，结合业务场景，精准实施优化策略。<br/><img width="723" height="128" referrerpolicy="no-referrer" src="/img/bVdnVaY" alt="image.png" title="image.png" loading="lazy"/></li><li>ArkUI Inspector：用于可视化的展示UI组件树，分析UI的布局层次和参数。使用方法可以参考ArkUI Inspector使用说明</li><li>CPU Profiler：Profiler：用于在运行过程中抓取trace和调用栈对耗时点进行分析，使用方法可以参考CPU Profiler的使用指导分析的思路可以参考常用Trace的含义。</li></ul><h2>六、性能标准与实践建议</h2><ul><li>帧率要求：120fps设备单帧耗时≤8ms，90fps设备单帧耗时≤12ms。</li><li>响应速度：页面跳转及交互反馈延迟需低于用户感知阈值，保证流畅体验。<br/>实践中应结合懒加载、分帧渲染、组件复用、扁平化布局及状态管理优化等多种手段，综合提升应用性能和用户体验。</li></ul><h2>七、总结</h2><p>ArkUI框架通过声明式开发范式和高效的状态管理机制，实现了灵活且高性能的UI渲染。性能优化需基于框架运行机制，结合具体业务场景，重点控制组件数量、优化更新粒度、合理利用复用与懒加载策略。借助DevEco Studio提供的丰富工具链，开发者可快速定位性能瓶颈，持续提升鸿蒙应用的流畅度和响应速度。</p><h2>八、更多参考</h2><p>1、界面渲染性能优化<br/>2、<a href="https://link.segmentfault.com/?enc=32fu7o%2B4u6Hy5b0ktVem8A%3D%3D.2G1xYHP4pg4WCEb4uqIkhP6qdllpGyu0yVyz%2FFBiwXgOgQInDok7PPUjjMWr%2Btuxh4D6tyl4L2%2B1Z9zR%2Bn%2BM3cqF1Jp04g6y3Hqo0mGZoY51Rcwmkc2shoX%2ByfRRoFuMI6ypdm5fHbqo%2BukzSbvZPjwcQcJS0P3M2UuRy2mIi%2Fw%3D" rel="nofollow" target="_blank">AppAnalyzer</a></p><p>所有人【华为专家面对面01期】ArkUI框架运行原理与常见性能优化方案 </p><p>了解ArkUI渲染的基本流程，探索通过节点优化、懒加载、预加载、组件复用等技术手段,提升列表场景下应用的流畅度，打造极致流畅的界面体验。<br/>➡️ <a href="https://link.segmentfault.com/?enc=Li57llIRbSSPSrRIEoisrw%3D%3D.se3J789EsNUFhQ%2BimpDDetFagzrn0tIz4bl7XkG%2F3l0nFYghNvnu2jXCtl84jyGm7kuLl279TuGBJKE4nS%2B65Bi3911UHhlQ0W8GqkxAllWPxYqE6SRYNUsj8D3Jo5Fy8y%2Bb98oVDfQpMoPcUn1Lgw%3D%3D" rel="nofollow" target="_blank">详情点击</a></p>]]></description></item><item>    <title><![CDATA[函数计算AgentRun重磅上线知识库功能，赋能智能体更“懂”你 Serverless ]]></title>    <link>https://segmentfault.com/a/1190000047608089</link>    <guid>https://segmentfault.com/a/1190000047608089</guid>    <pubDate>2026-02-12 18:02:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>阿里云函数计算 <strong>AgentRun</strong> 正式推出全新 <strong>知识库功能</strong>，为智能体（Agent）注入更强的语义理解与上下文感知能力。通过深度集成 <strong>百炼知识库</strong> 与 <strong>RAGFlow 知识库</strong>，AgentRun 让开发者能够轻松构建具备“知识”的智能应用，真正实现“更懂用户、更贴场景、更高效响应”。</p><h2>为什么需要知识库？</h2><p>在传统智能体开发中，模型往往依赖通用训练数据，缺乏对特定业务、私有文档或实时信息的理解能力。这导致其在面对专业领域问题、企业内部知识或个性化需求时表现受限。</p><p>AgentRun 的知识库功能正是为解决这一痛点而生——它将外部知识源无缝接入智能体运行流程，通过 <strong>检索增强生成（RAG）</strong> 技术，让智能体在回答问题、执行任务时，能动态调用相关知识，大幅提升准确性、专业性与可信度。</p><h2>双引擎支持：百炼 + RAGFlow，覆盖多元知识形态</h2><h3>百炼知识库绑定</h3><p>函数计算AgentRun可以绑定您账号下已经创建好的<a href="https://link.segmentfault.com/?enc=6GpFDXaDlCfD6eE3L2fTOA%3D%3D.MZ8cb3Qd38PjjJTpvAU6%2FVzjzPggSs2mU957a%2BVh9IR3LEZ9oXJU%2B09dxqjPb%2B8yJUyAnPn0YuM8HZkLjTuiAALOfuLpiZMP6vxtcb3JZyg%3D" rel="nofollow" target="_blank">阿里云百炼知识库</a>。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608091" alt="" title=""/></p><p>进入到创建页面，输入知识库名称、描述，选择知识库类型为“百炼”，可以多选绑定您账号下已经在阿里云百炼控制台创建好的多个知识库。填写检索配置后，点击创建知识库，即可将您的阿里云百炼知识库绑定至AgentRun平台。</p><h3>RAGFlow知识库绑定</h3><p>函数计算AgentRun可以绑定您账号下已经创建好的RAGFlow知识库。如果您没有RAGFlow知识库，可以点击<a href="https://link.segmentfault.com/?enc=T%2F8vBWl5yupaSXzBytGr8A%3D%3D.2NcMueMjf2QCDf%2BdSRN%2FFnn0OpNJt935Uucr95Kw11VzZVOJtlZ7tOWBMXyTrD5kAE2rSC5aUtO4UG%2Foor7jQuM6PpsH9Upj2Mgh28XSJLm2Xe5z2RKYBLSZ07tsvTsJY4sofyHCyvIThye8mvTMtBEmq7Cwp9K8TKFgTaXIZuJ6bJCnQYpp%2Bc025ORVbDCO8vxPVhtXUykByZ4Ka4ZTtuCD1XlUqvWMhtp1kgZwY%2FiFWgOcV9iOUrjUtNakQlXisszI2%2BocBhFyhPO3C%2BtjQQ%3D%3D" rel="nofollow" target="_blank">此链接</a>，一键在SAE上创建RAGFlow。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608092" alt="" title="" loading="lazy"/></p><p>进入到创建页面，输入知识库名称、描述，选择知识库类型为“RAGFlow”，填写您已部署的RAGFlow的BaseURL、Dataset IDs和API-KEY（将其保存在凭证中）。填写检索配置后，点击创建知识库，即可将您自建的RAGFlow知识库绑定至AgentRun平台。</p><blockquote>RAGFlow知识库详细配置获取方式，可参考<a href="https://link.segmentfault.com/?enc=Wo4ewzBVe%2FaNyL839deYZw%3D%3D.QXRqhftrXzqbmowvHzcWYe1Eh2RixUoTE8%2BHzNFWtd74LJiTr7cM6QaVqJCyCtMsVoXsYsRnTYs9waQY0g4iX%2FchkJvTFvpsXEzU4n5gXCakOo%2BwkJtbI8A8OawN30326ekqaqwIFKYpekfBu9VDdg8QxG7RrCYo%2BM%2Fc55vtEdprFupvvou%2Fw%2Bg7J2oBdkfEdIMuilA4W0ns1aiA8jdjIA%3D%3D" rel="nofollow" target="_blank">此文档</a>。</blockquote><h2>三大集成方式，灵活适配各类开发场景</h2><p>函数计算AgentRun 知识库功能支持快速创建集成、代码集成和MCP集成三种方式，满足不同技术栈和开发习惯。</p><h3>快速创建Agent集成知识库功能</h3><p>对于希望快速验证想法或加速产品迭代的团队，AgentRun 提供了<strong>低代码、可视化</strong>的知识库绑定能力。开发者只需登录 AgentRun 控制台，选择已创建的百炼或 RAGFlow 知识库，将其关联到目标智能体，并配置简单的检索参数（如返回结果数量、相似度阈值等），即可完成集成——全程无需编写一行代码。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608093" alt="" title="" loading="lazy"/></p><p>这一模式极大降低了技术门槛，让产品经理、运营人员甚至非技术背景的创新者也能参与智能体的构建与优化。无论是搭建内部知识问答机器人、客户自助服务助手，还是快速验证某个垂直领域的 AI 应用场景，都能在<strong>几分钟内完成部署并上线试用</strong>。</p><p><strong>代码集成知识库查询能力</strong>对于追求极致灵活性与控制力的开发者，AgentRun 提供了<strong>原生代码级知识库接入能力</strong>。您可以在代码逻辑中，调用<a href="https://link.segmentfault.com/?enc=E4g0Wh71iKkmsCISQgOuFA%3D%3D.hS04OIGCDwEamgFjv6%2B6VAGdzt1Hqu72Bcwkw1DE62DmsTbm7yVwGqmTszaq98Z4B85IcK%2FTIAYMgxZzHfxAgQ%3D%3D" rel="nofollow" target="_blank">AgentRun SDK</a>的知识库检索接口，根据业务上下文动态发起检索请求，精准筛选并注入最相关的信息片段到智能体的推理流程中。您可以使用<a href="https://link.segmentfault.com/?enc=auaNfMU51K%2B%2BFzfSGTYWjA%3D%3D.%2FeQMs6w2HfP7cGPmR6siFs3jAFoa5fgx9%2Fm1BIS6O7tbKV6v1ojieoGO3qSFpiy%2B1dJvh%2BIRdyxGSM%2FceR%2FWLA%3D%3D" rel="nofollow" target="_blank">AgentRun SDK</a>，调用以下封装的接口，进行单知识库查询或多知识库查询。</p><pre><code class="python">fromagentrun.knowledgebaseimportKnowledgeBase
## 获取单知识库，进行查询
knowledgebase=KnowledgeBase.get_by_name("ragflow-test")
single_kb_retrieve_result=knowledgebase.retrieve("&lt;your-query&gt;")
print(single_kb_retrieve_result)
## 获取多知识库，进行查询，支持跨供应商知识库类型检索
multi_kb_retrieve_result=KnowledgeBase.multi_retrieve(
    query="&lt;your-query&gt;",
    knowledge_base_names=["ragflow-test","&lt;your-knowledge-base-name-2&gt;"],
)
print(multi_kb_retrieve_result)</code></pre><p>同样，您可以集成LangChain框架，将知识库的查询能力集成在工具或上下文中。</p><pre><code class="python">"""AgentRun 知识库智能体集成代码示例

使用前，请参考https://docs.agent.run/docs/tutorial/quick-start 配置好相应认证信息和环境变量

curl http://127.0.0.1:9000/openai/v1/chat/completions -X POST \
    -H "Content-Type: application/json" \
    -d '{"messages": [{"role": "user", "content": "什么是Serverless?"}], "stream": true}'
"""

import json
import os
from typing import Any

from langchain.agents import create_agent
import pydash

from agentrun import Config
from agentrun.integration.langchain import model
from agentrun.integration.langchain import knowledgebase_toolset
from agentrun.integration.langgraph.agent_converter import AgentRunConverter
from agentrun.knowledgebase import KnowledgeBase
from agentrun.server import AgentRequest, AgentRunServer
from agentrun.server.model import ServerConfig
from agentrun.utils.log import logger

# 请替换为您已经创建的 模型 名称
AGENTRUN_MODEL_SERVICE = os.getenv("AGENTRUN_MODEL_SERVICE", "&lt;your-model-service&gt;")
AGENTRUN_MODEL_NAME = os.getenv("AGENTRUN_MODEL_NAME", "&lt;your-model-name&gt;")
KNOWLEDGE_BASES = os.getenv("AGENTRUN_KNOWLEDGE_BASES", "ragflow-test").split(",")

if AGENTRUN_MODEL_NAME.startswith("&lt;") or not AGENTRUN_MODEL_NAME:
    raise ValueError("请将 MODEL_NAME 替换为您已经创建的模型名称")

## 加载知识库工具，知识库可以以工具的方式供Agent进行调用
knowledgebase_tools = []
if KNOWLEDGE_BASES and not KNOWLEDGE_BASES[0].startswith("&lt;"):
    knowledgebase_tools = knowledgebase_toolset(
        knowledge_base_names=KNOWLEDGE_BASES,
    )
else:
    logger.warning("KNOWLEDGE_BASES 未设置或未替换，跳过加载知识库工具。")

agent = create_agent(
    model=model(AGENTRUN_MODEL_SERVICE, model=AGENTRUN_MODEL_NAME, config=Config(timeout=180)),
    tools=[
        *knowledgebase_tools,   ## 通过工具集成知识库查询能力
    ],
    system_prompt="你是一个 AgentRun 的 AI 专家，可以通过查询知识库文档来回答用户的问题。",
)


async def invoke_agent(request: AgentRequest):
    messages = [
        {"role": msg.role, "content": msg.content}
        for msg in request.messages
    ]

    # 如果配置了知识库，查询知识库并将结果添加到上下文
    if KNOWLEDGE_BASES and not KNOWLEDGE_BASES[0].startswith("&lt;"):
        # 获取用户最新的消息内容作为查询
        user_query = None
        for msg in reversed(request.messages):
            if msg.role == "user":
                user_query = msg.content
                break

        if user_query:
            try:
                retrieve_result = await KnowledgeBase.multi_retrieve_async(
                    query=user_query,
                    knowledge_base_names=KNOWLEDGE_BASES,
                )
                # 直接将检索结果添加到上下文
                if retrieve_result:
                    messages.append({
                        "role": "assistant",
                        "content": json.dumps(retrieve_result, ensure_ascii=False),
                    })
            except Exception as e:
                logger.warning(f"知识库检索失败: {e}")

    input: Any = {"messages": messages}

    converter = AgentRunConverter()
    if request.stream:

        async def async_generator():
            async for event in agent.astream(input, stream_mode="updates"):
                for item in converter.convert(event):
                    yield item

        return async_generator()
    else:
        result = await agent.ainvoke(input)
        return pydash.get(result, "messages[-1].content", "")


AgentRunServer(
    invoke_agent=invoke_agent,
    config=ServerConfig(
        cors_origins=[
            "*"
        ]
    ),
).start()</code></pre><blockquote>注意⚠️：如果您选择了RAGFlow的知识库，<strong>需要确保您的Agent运行环境和RAGFlow的BaseURL的地址处于同一网络环境下，否则AgentRun SDK将无法调用RAGFlow的API实现查询能力。</strong></blockquote><p>通过代码集成，AgentRun 赋予开发者“全栈可控”的能力——既享受函数计算的弹性与免运维优势，又保留对智能体认知过程的深度掌控，真正实现“知识为我所用，逻辑由我定义”。</p><h3>MCP集成：将知识库检索作为Agent的工具调用</h3><p>AgentRun知识库率先实现“Agentic RAG”（智能体RAG）模式——将传统静态检索升级为动态、可编程的智能体工具调用。具体而言，用户可一键将知识库发布为MCP，使其成为大语言模型（LLM）可主动调用的工具之一。在此模式下，LLM不再被动接收上下文，而是具备“工具使用能力”，在推理过程中自主判断何时调用RAG、数据库查询、库存检查等工具，并基于返回结果进行多步推理与任务分解。这种机制使RAG从单一检索功能转变为智能体工具箱中的灵活组件，与其他工具并列协作，显著提升复杂任务的处理能力。其工作方式更贴近人类“思考—行动—反思”的认知流程：模型先分析问题，制定计划，再按需调用多个工具获取信息，最终整合结果生成答案。</p><p>进入其他 &gt;&gt; 工具管理 &gt;&gt; 工具市场，可以搜索到“<strong>AgentRun知识库MCP</strong>” 工具模板，点击安装后，填写知识库名称和类型，即可将知识库的查询能力一件发布成MCP工具给大模型进行调用。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608094" alt="" title="" loading="lazy"/></p><p>创建完毕后，点击工具详情，即可看到集成调用的工具地址：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047608095" alt="" title="" loading="lazy"/></p><p>基于MCP工具标准协议，AgentRun 支持以标准化方式对接知识库服务，实现跨平台、跨模型的上下文注入能力，保障架构的开放性与可扩展性。</p><h2>结语：从“能回答”到“真理解”，智能体正在拥有“知识之眼”</h2><p>AgentRun 知识库功能的上线，不仅是一次技术能力的升级，更标志着智能体发展迈入新阶段——从依赖通用语料的“泛化应答”，转向基于专属知识的“情境理解”。当智能体能够随时调用企业文档、行业规范、用户历史甚至实时数据，它便不再只是一个语言模型的接口，而成为一个<strong>具备领域认知、上下文记忆与决策依据的数字协作者</strong>。</p><p>未来，随着知识库的持续进化——支持多模态内容、动态更新、跨源推理——AgentRun 将进一步降低构建“有知识、有逻辑、有温度”智能体的门槛。</p><p>我们相信，真正的智能，不在于模型有多大，而在于是否“懂你所需、知你所问、信你所依”。</p><p><strong>AgentRun，正让每一个智能体，学会思考，更学会理解。</strong></p>]]></description></item><item>    <title><![CDATA[日志成本降低 83%：云上 Elasticsearch 和 SelectDB 的基准测试及成本分析 ]]></title>    <link>https://segmentfault.com/a/1190000047608105</link>    <guid>https://segmentfault.com/a/1190000047608105</guid>    <pubDate>2026-02-12 18:01:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在可观测性场景中，Elasticsearch 常受限于写入性能与高昂成本。在《可观测性方案怎么选？SelectDB vs Elasticsearch vs ClickHouse》一文中提到， 在云上日志服务中，SelectDB 相比 Elasticsearch 展现出明显的性能和成本优势。为进一步探索，本文通过基准测试对比二者表现，验证 SelectDB 在日志场景下性能与成本上的显著优势。1、基准目标和方法本次测试的目的是在可观测性场景下公平比较 SelectDB 和 Elasticsearch 的实际性能和成本，并为用户提供参考数据。为尽可能做到真实和公平，我们设计了如下对比测试：测试环境：使用 腾讯云 Elasticsearch 和 SelectDB Cloud  进行测试，未进行任何针对性调优。测试数据：使用 Elasticsearch 的官方性能测试集http logs，以确保测试中立性（实际更偏向 Elasticsearch）。测试内容：写入性能、查询性能、存储空间和成本的比较，这些是可观测性场景中用户最关心的指标。测试方法：第一阶段比较相同资源下的性能第二阶段比较支持相同负载所需的成本。第二阶段超越了传统的性能测试，以验证性能优势是否能在实际用户需求中转化为成本优势，而不仅仅是一种推断。2、相同资源下的性能比较在测试的第一阶段，比较相同配置下 Elasticsearch 和 SelectDB 的性能和成本。第一步：Elasticsearch 和 SelectDB 分别购买具有相同配置（48vCPU、348GB RAM）的集群，成本分别为 18.83 元/小时 和  16.95 元/小时。（1）腾讯云 Elasticsearch（48c） 费用：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047608107" alt="图片" title="图片"/><br/>（2）SelectDB Cloud（48c） 费用：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047608108" alt="图片" title="图片" loading="lazy"/><br/>第二步：在 Elasticsearch 中创建索引，并在 SelectDB Cloud 中创建表。为确保公平性，两个系统使用相同的模式，包括字段类型、索引类型、共享/分片数量等。需要注意的是，Elasticsearch 的索引大致对应于 SelectDB 的表。第三步：将相同的 HTTP 日志数据集导入到 Elasticsearch 和 SelectDB Cloud。Elasticsearch 耗时 225 秒，而 SelectDB Cloud 仅需 69 秒。SelectDB Cloud 比 Elasticsearch 快 3.3 倍。第四步：分别在 Elasticsearch 和 SelectDB Cloud 中运行 HTTP 日志测试集的查询。Elasticsearch 中的首次运行（冷查询）耗时 2.049 秒，第二次运行（热启动）耗时 1.691 秒，SelectDB Cloud 中的首次运行（冷查询）耗时 0.599 秒，第二次运行（热启动）耗时 0.52 秒。SelectDB Cloud 在冷查询和热启动时的速度均比 Elasticsearch 快 3  倍以上。第五步：分别获取 Elasticsearch 和 SelectDB Cloud 的存储空间使用情况。Elasticsearch 的存储空间使用量为 12.8GB，而 SelectDB Cloud 的存储空间使用量为 3.3GB。与 Elasticsearch 相比，SelectDB Cloud 的存储空间减少了 75%。通过本次测试可以看出，在相同配置下，SelectDB Cloud 的数据导入性能比 Elasticsearch 快 3.3 倍，查询性能快 3 倍以上，存储空间减少 75%。这意味着，在相同配置下，SelectDB Cloud 的用户将比使用 Elasticsearch 的用户获得数倍的性能提升。在可观测性场景下，用户更关心相同负载和性能下能否真正降低成本。因此，接下来的测试将验证 SelectDB Cloud 的性能优势能转化为多大的实际成本优势。3、成本突破：从性能领先到真正的成本降低在测试的第二阶段，SelectDB Cloud 将缩小至其原始规模的 1/6，与使用 6 倍资源的 Elasticsearch 进行性能比较。第一步：将 SelectDB Cloud 48vCPU 的集群规模缩减至 8vCPU，成本也大幅降低至 2.93 元/小时。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047608109" alt="图片" title="图片" loading="lazy"/><br/>第二步：在仅有 8vCPU 的 SelectDB Cloud 集群中创建相同的表。第三步：将相同的 HTTP 日志数据集导入到具有 8vCPU 的 SelectDB Cloud 集群中。这一过程耗时 140 秒，速度仍比 48vCPU 的 Elasticsearch 云集群快 1.6 倍。第四步：在 8vCPU 的 SelectDB Cloud 集群中运行来自 HTTP 日志测试集的查询。第一次运行（冷查询）耗时 1.389 秒，第二次运行（热启动）耗时 1.246 秒。8 vCPU 的 SelectDB Cloud 在冷查询时比 48vCPU 的 Elasticsearch 还快 47.5%。在第五步中，获取 8vCPU SelectDB Cloud 集群中的存储空间使用情况。SelectDB Cloud 的存储空间使用量仍为 3.3GB，比 Elasticsearch 低 75%。通过本次测试可以看出，在将 SelectDB Cloud 的资源缩减至 Elasticsearch 的 1/6 后，成本仅为 2.93 元/小时，比 Elasticsearch 的 18.83 元/小时 节省了 85% 的费用。尽管成本大幅降低，但性能仍保持显著优势：数据导入性能快 1.6 倍，冷查询性能快 47.5%，存储空间减少 75%。这意味着，对于从 Elasticsearch 切换到 SelectDB Cloud 以支持相同负载的用户来说，SelectDB Cloud 将实现实打实的 83% 成本降低，并提供更好的性能。4、为什么 SelectDB 能如此显著地降低成本SelectDB Cloud 出色的性能和成本优势得益于针对可观测性场景进行的广泛优化。SelectDB 针对日志场景优化倒排索引降低空间占用，数据和索引均采用列式存储，并使用 ZSTD 压缩算法，实现了高压缩率，可大幅减少存储空间。此外，SelectDB 将所有数据存储在低成本的对象存储中，热数据在 SSD 等本地磁盘上进行缓存和加速，利用可观测性数据冷热分层的特点降低存储空间单价。这些特性使 SelectDB 的存储成本比 Elasticsearch 降低了接近一个数量级。 SelectDB 采用存储与计算分离的架构。在写入数据时，计算层仅存在一次计算消耗，避免了 Elasticsearch 存储与计算一体化架构所需的多副本。此外，SelectDB 为日志和追踪等时间序列数据设计了时间序列压缩策略，将后台数据合并的写入放大从 3 降低到 1，大幅节省计算和 IO 资源消耗。SelectDB 专为实时分析而设计，这意味着它支持高性能聚合操作，这些操作常用于可观测性领域。在搜索查询方面，SelectDB 以一种针对日志搜索和topn查询（如SELECT * FROM log WHERE message MATCH 'error' ORDER BY time DESC LIMIT 100）进行优化的方式实现了倒排索引。结果是，SelectDB 在搜索查询方面速度快 2 倍，在聚合查询方面速度快 10 倍。结论在 HTTP 日志基准工作负载下，SelectDB Cloud 与 Elasticsearch 相比实现了 83%的成本降低。在实际生产环境中，许多用户已经在 PB 规模下用 SelectDB 或 Apache Doris 取代了 Elasticsearch，实现了显著的成本节约。您可以阅读来自网易、MiniMax、领创集团、中信信用卡中心的用户故事来了解更多。我们建议您根据实际业务场景设计测试，亲自验证 SelectDB 在成本与性能上的表现。欢迎申请 SelectDB Cloud 试用验证。</p>]]></description></item><item>    <title><![CDATA[【鲲苍提效】应用链路全景透视，让性能问题无处可藏 汉得数字平台 ]]></title>    <link>https://segmentfault.com/a/1190000047607766</link>    <guid>https://segmentfault.com/a/1190000047607766</guid>    <pubDate>2026-02-12 17:05:35</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607769" alt="" title=""/><br/>汉得鲲苍基础架构管理平台的核心目标是为企业的异构系统提供简单高效的一站式统一闭环管理能力，包括统一资源（集群、主机、存储等）管理、统一应用及部署管理、统一监控管理、统一服务治理，帮助企业实现更快、更好、更全面的异构系统管理。</p><p>接下来我们将会提供一系列推文，介绍鲲苍平台的使用，帮助您快速了解本平台，给您更好的使用体验。</p><p>本文为系列推文的第三十一讲，将介绍如何通过鲲苍监控应用性能，在分布式系统中快速定位性能问题，大大缩短故障排查时间，高效解决性能问题！</p><h2>本篇概述</h2><p>在分布式架构时代，一次用户请求的背后，可能历经数十个服务的流转，如何快速洞察系统性能、精准定位性能瓶颈？鲲苍平台「应用性能监控（APM）」能力，为您提供从全局拓扑到代码堆栈的全链路可观测方案，让应用性能问题无处遁形。</p><h2>功能亮点：应用性能监控接入</h2><h3>1. 新建数据源</h3><p>服务可观测性/监控数据源配置：新增Skywalking类型数据源。<img referrerpolicy="no-referrer" src="/img/remote/1460000047607770" alt="" title="" loading="lazy"/></p><h3>2. 新建应用性能监控集群</h3><p>应用性能监控/应用性能监控集群配置：关联数据源。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047607771" alt="" title="" loading="lazy"/></p><h3>3. 应用性能监控接入</h3><p>查看 接入指南 ，按步骤操作：<img referrerpolicy="no-referrer" src="/img/remote/1460000047607772" alt="" title="" loading="lazy"/><br/>部署前端应用时，开启 isTrace ，例如：</p><pre><code class="bash">`ClientMonitor.register({
  accessTokenUrl： http://1.2.3.4:8080/oauth/oauth/token,
  collector:${HOPS_CLUSTER_URL}/v3/segments,
  isAjax: true,
  isTrace: true,
  namespace: '',
  clientId: '';
  clientSecret: '';
})`</code></pre><p>部署后端应用时，通过 javaagent 接入应用性能监控，例如：</p><pre><code class="bash">## 应用启动需要添加以下启动参数
-Xms1024m -Xmx1536m -javaagent:agent_path/skywalking-agent.jar -Dskywalking.agent.namespace=hops-dev -Dskywalking.agent.service_name=hops-dev:hzero-product -Dskywalking.collector.backend_service=127.0.0.1:11800</code></pre><h2>应用性能监控分析</h2><h3>1. 全景拓扑，一眼看懂服务关系</h3><p>基于真实的调用链路数据，自动绘制实时服务依赖关系图。节点颜色动态反映服务健康状态，直观呈现系统架构全貌，依赖关系一目了然。</p><ul><li>边上可查看服务间平均响应延迟，点击可查看详细的平均响应时间、平均吞吐量、平均SLA、响应时间分布等指标</li><li><p>服务实例上点击可查看服务应用性能指数（APDEX）、响应时间、吞吐量、SLA、响应时间分布等指标<img referrerpolicy="no-referrer" src="/img/remote/1460000047607773" alt="" title="" loading="lazy"/></p><h3>2. 链路追踪，穿透每一个调用环节</h3><p>从入口到数据库，完整记录请求在分布式系统中的流转路径。支持查看每个环节的耗时、状态、异常详情、SQL语句，支持多种视图灵活切换，轻松定位慢调用与异常节点。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047607774" alt="" title="" loading="lazy"/></p><h3>3. 多维监控，关键指标实时掌控</h3><p><strong>全局概览</strong>：掌握集群整体响应延迟分布、吞吐量排行、慢服务/慢端点排行等。<img referrerpolicy="no-referrer" src="/img/remote/1460000047607775" alt="" title="" loading="lazy"/></p></li></ul><p><strong>服务维度</strong>：深入查看单服务响应时间、吞吐量、SLA、Apdex满意度指数等。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047607776" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047607777" alt="" title="" loading="lazy"/></p><p><strong>服务端点及数据库分析</strong>：分析接口性能与数据库慢查询，全面覆盖应用层到数据层。<img referrerpolicy="no-referrer" src="/img/remote/1460000047607778" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047607779" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047607780" alt="" title="" loading="lazy"/></p><h3>4. 深度剖析，直击性能根源</h3><p><strong>JVM&amp;实例级深度分析</strong></p><p>针对 Java 服务，鲲苍提供实例级 JVM 健康洞察，从“现象”到“根因”，不再依赖经验猜测：</p><ul><li>CPU 使用率、GC 耗时与次数、线程状态、线程堆栈</li><li>堆内存使用情况与对象分布</li><li>MBean 详情、系统属性与运行环境信息等<img referrerpolicy="no-referrer" src="/img/remote/1460000047607781" alt="" title="" loading="lazy"/><img referrerpolicy="no-referrer" src="/img/remote/1460000047607782" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047607783" alt="" title="" loading="lazy"/><img referrerpolicy="no-referrer" src="/img/remote/1460000047607784" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047607785" alt="" title="" loading="lazy"/><img referrerpolicy="no-referrer" src="/img/remote/1460000047607786" alt="" title="" loading="lazy"/></li></ul><p><strong>服务链路性能剖析</strong><br/>通过采样跟踪与性能剖析任务，鲲苍可对指定 API 在一段时间内进行方法级堆栈分析，并以火焰图形式呈现调用链。宽而平的“平顶”函数，往往就是性能瓶颈所在，问题定位更直接、更高效。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047607787" alt="" title="" loading="lazy"/><img referrerpolicy="no-referrer" src="/img/remote/1460000047607788" alt="" title="" loading="lazy"/></p><h3>5. 应用性能告警，防患于未然</h3><p>基于响应时间、成功率、吞吐量等核心指标，灵活配置告警规则与生效范围，实现应用性能的主动感知与提前预警，助您提前发现风险，保障系统持续稳定运行。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047607789" alt="" title="" loading="lazy"/></p><h2>联系我们：</h2><ul><li>如果您想了解鲲苍更详细的功能介绍和产品信息，请登录开放平台查阅我们的产品文档</li><li>如果您有疑问，可以通过开放平台进行工单反馈，问题分类请选择【产品/汉得基础架构管理平台】</li><li>相关产品咨询或更多信息了解，欢迎联系我们。<br/>邮箱：<a href="mailto:openhand@vip.hand" target="_blank">openhand@vip.hand</a>-china.com</li></ul>]]></description></item><item>    <title><![CDATA[[开源] myclaw：2000 行 Go 平替 43 万行的 OpenClaw 荀彧9527 ]]></title>    <link>https://segmentfault.com/a/1190000047607856</link>    <guid>https://segmentfault.com/a/1190000047607856</guid>    <pubDate>2026-02-12 17:04:57</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>推荐API服务：<a href="https://link.segmentfault.com/?enc=hv9gh9CmlWCICWLvRHyKjQ%3D%3D.dvsRT0uATnTz2P1W4XOU0%2BXHIOfGCYkmpGm1hjvSFfU%3D" rel="nofollow" target="_blank">https://nicecode.cc/</a></p><h3>AI Agent Gateway 赛道的现状</h3><p>2026 年初，AI Agent 领域最火的项目非 OpenClaw 莫属。这个前身为 Clawdbot 🦞（后改名 Moltbot，最终定名 OpenClaw）的项目，在 GitHub 上已经积累了超过 17 万 Star。它的核心理念很直接：给 LLM 一双"手"，让 AI 能操作你的本地系统——执行命令、读写文件、控制浏览器。</p><p>OpenClaw 的架构确实强大：</p><p>• Gateway + Pi Agent：Gateway 是 Node.js WebSocket 服务（默认绑 ws://127.0.0.1:18789），内嵌 Pi（Mario Zechner 写的开源 Coding Agent）通过 JSON-RPC over stdio 做推理和工具调用<br/>• 多模型支持：通过 Pi 的统一 LLM API 接 Anthropic、OpenAI、Google、Ollama 等多家 Provider<br/>• 支持 WhatsApp、Telegram、Discord、iMessage、Slack、Signal 等消息通道<br/>• 沙箱模式、设备配对审批、加密凭据存储<br/>但它也有明显的代价：43 万行 TypeScript 代码，Node.js 运行时，以及相当复杂的依赖链。</p><p>对于只想自托管一个 AI 助手的个人开发者来说，这个体量太重了。myclaw 想做的事情很简单——用 Go 写一个够用的轻量替代。</p><h3>myclaw 是什么</h3><p>myclaw 是一个 Go 编写的自托管 AI Agent Gateway。设计目标三条：</p><ol><li>轻量：核心代码约 2000 行，单二进制部署，无运行时依赖</li><li>实用：覆盖日常场景——Telegram 和飞书双通道、定时任务、记忆持久化</li><li>可扩展：模块化架构，Channel 接口抽象清晰，加新通道写一个 struct 就行<br/>架构上借鉴了 OpenClaw 的 Gateway 模式，但实现上砍掉了所有我用不到的东西。</li></ol><p>myclaw 的整体架构可以用一句话概括：消息总线驱动的服务编排。<br/><img width="723" height="457" referrerpolicy="no-referrer" src="/img/bVdnU8F" alt="image.png" title="image.png"/><br/>核心组件包括：</p><ol><li>Message Bus（消息总线）<br/>消息总线是 myclaw 的中枢。两种消息类型：</li></ol><p>• InboundMessage：从通道流入，携带 Channel、SenderID、ChatID、Content、Timestamp 等字段<br/>• OutboundMessage：从 Agent 流出，携带 Channel、ChatID、Content、ReplyTo 等字段<br/>通过 Pub/Sub 模式（SubscribeOutbound / DispatchOutbound），各服务之间实现松耦合的事件路由。缓冲区默认 100 条消息，Goroutine 安全。</p><ol start="2"><li>Gateway（网关编排器）<br/>Gateway 是顶层编排器，负责：</li></ol><p>• 组装系统 Prompt（从 AGENTS.md + SOUL.md + 记忆上下文拼接）<br/>• 处理入站消息，调用 Agent 运行时（支持 Anthropic 和 OpenAI 两种 Provider）<br/>• 将 Agent 输出路由到对应的消息通道<br/>• 处理 SIGINT / SIGTERM 优雅关闭<br/>Provider 切换的逻辑很直接——配置里 provider.type 写 openai 就走 OpenAI，其他情况默认 Anthropic。不搞什么抽象工厂，一个 switch 解决。</p><ol start="3"><li>Channel（消息通道）<br/>Channel 接口定义了四个方法：Name()、Start()、Stop()、Send()。目前实现了两个通道：</li></ol><p>Telegram 通道：</p><p>• 基于 telegram-bot-api/v5 长轮询<br/>• Markdown → Telegram HTML 格式转换<br/>• 消息分片（4096 字符限制）<br/>• 发送者白名单过滤<br/>• 代理配置支持（方便国内网络环境）<br/>飞书通道：</p><p>• Webhook 模式，启动一个 HTTP Server 监听 /feishu/webhook（默认端口 9876）<br/>• Tenant Access Token 管理，带缓存和双重检查锁<br/>• URL Verification Challenge 自动应答<br/>• 事件驱动的消息接收（im.message.receive_v1）<br/>• 发送者白名单过滤（基于 open_id）<br/>• Verification Token 校验<br/>飞书通道需要一个公网可达的 Webhook URL。本地开发可以用 Cloudflared 临时隧道，生产环境建议配 DNS。</p><ol start="4"><li>Memory（记忆系统）<br/>记忆系统分为两层：</li></ol><p>• 长期记忆（MEMORY.md）：持久化的知识库<br/>• 每日日记（YYYY-MM-DD.md）：按日期归档的交互记录<br/>提供 ReadLongTerm()、WriteLongTerm()、ReadToday()、AppendToday() 和 GetRecentMemories(days) 方法。默认取最近 7 天的日记，和长期记忆一起组装进 LLM 的系统 Prompt。</p><p>文件就是 Markdown，想手动改也行。</p><ol start="5"><li>Cron（定时任务）<br/>支持三种调度模式：</li></ol><p>• cron：标准 Cron 表达式（基于 robfig/cron/v3）<br/>• every：固定间隔（毫秒级）<br/>• at：一次性定时执行<br/>任务持久化为 JSON（存在 ~/.myclaw/data/cron/jobs.json），支持状态追踪（LastRunAtMs、LastStatus、LastError）和执行后自动删除。任务的执行结果可以通过 deliver 字段指定是否推送到某个消息通道。</p><ol start="6"><li><p>Heartbeat（心跳服务）<br/>定期读取 HEARTBEAT.md 文件内容，触发 Agent 处理。Agent 返回 HEARTBEAT_OK 表示无需进一步操作。默认间隔 30 分钟，适合做周期性自检或主动提醒。</p><h3>为什么用 Go</h3><p>选 Go 不是为了赶时髦，是几个实际的考量：</p></li><li>单二进制部署：go build 产出一个可执行文件，不需要 Node.js 运行时或 Python 虚拟环境。scp 到服务器直接跑</li><li>并发原语：Goroutine + Channel 天然适合消息总线架构。每个通道、每个定时任务、Webhook Server 都是独立的 Goroutine，代码写起来比 async/await 回调链清爽</li><li>内存占用：Go 运行时的内存开销远低于 Node.js / Python，一个长期驻留的 Gateway 进程，这点差别会累积</li><li>交叉编译：GOOS=linux GOARCH=arm64 go build 一行命令编译到任意平台</li></ol><h3>快速开始</h3><p>安装</p><pre><code>go install github.com/stellarlinkco/myclaw/cmd/myclaw@latest</code></pre><p>初始化<br/><code>myclaw onboard</code><br/>这会在 ~/.myclaw/ 下创建配置文件和工作空间：</p><pre><code>~/.myclaw/
├── config.json          # 主配置
├── workspace/
│   ├── AGENTS.md        # Agent 角色定义
│   ├── SOUL.md          # 人格特质
│   ├── HEARTBEAT.md     # 心跳任务提示词
│   └── memory/
│       └── MEMORY.md    # 长期记忆
└── data/
    └── cron/
        └── jobs.json    # 定时任务持久化</code></pre><p>配置<br/>编辑 ~/.myclaw/config.json：</p><pre><code>{
  "agent": {
    "model": "claude-sonnet-4-5-20250929",
    "maxTokens": 8192,
    "temperature": 0.7,
    "maxToolIterations": 20
  },
  "provider": {
    "type": "anthropic",
    "apiKey": "sk-ant-..."
  },
  "channels": {
    "telegram": {
      "enabled": true,
      "token": "your-bot-token",
      "allowFrom": ["123456789"],
      "proxy": ""
    },
    "feishu": {
      "enabled": true,
      "appId": "cli_xxx",
      "appSecret": "xxx",
      "verificationToken": "xxx",
      "port": 9876,
      "allowFrom": ["ou_xxx"]
    }
  },
  "gateway": {
    "host": "0.0.0.0",
    "port": 18790
  }
}</code></pre><p>想用 OpenAI 兼容的 API？把 provider.type 改成 "openai"，填上对应的 Key 和 Base URL 就行。</p><p>也支持环境变量覆盖：<br/><img width="723" height="353" referrerpolicy="no-referrer" src="/img/bVdnU8H" alt="image.png" title="image.png" loading="lazy"/><br/>一个细节：如果只设了 OPENAI_API_KEY 而没有配 provider.type，myclaw 会自动把 Provider 切到 OpenAI。少一步配置。<br/><strong>运行</strong></p><pre><code># REPL 模式（命令行交互）
myclaw agent

# 单条消息模式
myclaw agent -m "今天的任务清单"

# 完整 Gateway 模式（启动所有服务）
myclaw gateway

# 查看状态
myclaw status</code></pre><h3>部署</h3><p><strong>Docker</strong><br/>myclaw 提供了多阶段 Dockerfile（golang:1.24-alpine 构建，alpine:3.21 运行），编译产物约 10MB。</p><pre><code># 构建并启动
docker compose up -d --build

# 如果需要飞书 Webhook 的公网隧道
docker compose --profile tunnel up -d --build</code></pre><p>Docker Compose 里包含一个可选的 Cloudflared 隧道服务，通过 --profile tunnel 激活。它会自动把飞书 Webhook 端口暴露到公网，省去自己配 Nginx 反向代理的麻烦。</p><p>本地开发也可以直接用 Make：</p><p><code>make tunnel  # 启动 cloudflared 临时隧道</code><br/>拿到 *.trycloudflare.com 的 URL 后填到飞书开放平台的事件订阅里就行。<br/><strong>裸机部署</strong></p><pre><code># 交叉编译
GOOS=linux GOARCH=amd64 go build -ldflags="-s -w" -o myclaw ./cmd/myclaw

# 丢到服务器上
scp myclaw user@server:/usr/local/bin/
ssh user@server "myclaw onboard &amp;&amp; myclaw gateway"</code></pre><h3>人格定制</h3><p>myclaw 的一个有趣设计是通过 Markdown 文件定义 Agent 的"灵魂"。</p><p>AGENTS.md 定义角色和行为准则——你是谁、你能做什么、你的边界在哪里。SOUL.md 定义人格特质——语气、偏好、思维方式。这两个文件会被 Gateway 拼接到系统 Prompt 中。</p><p>这意味着你可以通过编辑两个 Markdown 文件来完全自定义 AI 助手的行为，不需要改任何代码。想要一个严肃的工作助手？改 SOUL.md。想要一个幽默的聊天伙伴？也是改 SOUL.md。</p><h3>与 OpenClaw 的对比</h3><p><img width="723" height="361" referrerpolicy="no-referrer" src="/img/bVdnU8I" alt="image.png" title="image.png" loading="lazy"/><br/>myclaw 不试图替代 OpenClaw。如果你需要多平台消息通道、完整的沙箱安全模型、Pi Agent 的 Skills 扩展体系，OpenClaw 是更好的选择。myclaw 的定位是：你只需要一个能通过 Telegram 或飞书控制的、带记忆的、能跑定时任务的 AI 助手，并且希望它是一个 10MB 的二进制文件而不是一个 Node.js 项目。</p><h3>测试</h3><p>myclaw 的测试覆盖率在 82%-100% 之间，核心模块都有单元测试：</p><p>• bus_test.go：消息总线的发布/订阅<br/>• channel_test.go：通道接口、Telegram 适配和飞书 Webhook 处理<br/>• config_test.go：配置加载和环境变量覆盖<br/>• cron_test.go：三种调度模式<br/>• gateway_test.go：服务编排和优雅关闭（90.2% 覆盖）<br/>• heartbeat_test.go：心跳触发逻辑<br/>• memory_test.go：记忆读写和上下文组装<br/>• main_test.go：CLI 命令注册<br/>使用依赖注入的 Factory 模式，测试时替换外部依赖。RuntimeFactory、BotFactory、FeishuClientFactory 这些接口让你不需要真实的 Telegram Bot 或 Anthropic API 也能跑完所有测试。</p><pre><code>make test          # 跑全部测试
make test-race     # 带竞态检测
make test-cover    # 生成覆盖率报告</code></pre><h3>安全考量</h3><p>AI Agent Gateway 的安全性不容忽视。OpenClaw 社区已经多次讨论过"投毒网页"导致的 Prompt 注入攻击问题。myclaw 采取了几个基本措施：</p><p>• 发送者白名单：Telegram 和飞书通道都支持 allowFrom 配置，只有白名单中的用户才能触发 Agent<br/>• 工具迭代上限：maxToolIterations 限制单次对话中的工具调用次数，防止 Agent 失控循环<br/>• 工作空间隔离：tools.restrictToWorkspace 默认开启，Agent 的文件操作限制在工作空间目录内<br/>• Webhook 验证：飞书通道支持 Verification Token 校验，防止伪造请求<br/>对于生产环境，建议配合 Docker 容器运行以提供进程级隔离。</p><h3>关键依赖</h3><p>myclaw 的外部依赖保持精简，直接依赖只有 4 个：</p><p>• agentsdk-go（v0.8.0）：Agent 运行时，底层包了 Anthropic SDK 和 OpenAI SDK，处理 ReAct 循环和工具调用<br/>• telegram-bot-api/v5：Telegram Bot API 客户端<br/>• robfig/cron/v3：Cron 表达式解析和调度<br/>• spf13/cobra：CLI 框架<br/>间接依赖包括 anthropic-sdk-go、openai-go、go-sdk（MCP）和 OpenTelemetry 相关的 Tracing 库。go.sum 里条目不少，但运行时真正加载的东西不多。</p><h3>我的看法</h3><p>myclaw 证明了一件事：构建一个实用的 AI Agent Gateway 不需要 43 万行代码。2000 行 Go，两个消息通道，一套记忆系统，一个 Cron 调度器——日常够用了。</p><p>当然它也有明显的不足。没有 Web UI，没有多用户会话隔离，飞书通道目前只支持纯文本消息。如果你的场景需要这些，OpenClaw 或者自己加功能。</p><p>Go 的单二进制部署和低内存占用让它特别适合丢在一台小 VPS 上长期跑着。如果你认同"能用 2000 行解决的问题不要用 43 万行"这个理念，可以试试。</p>]]></description></item><item>    <title><![CDATA[Dragonfly 论文入选 IEEE TON：AI 领域海量镜像与大模型分发的解决方案 蚂蚁开源 ]]></title>    <link>https://segmentfault.com/a/1190000047607891</link>    <guid>https://segmentfault.com/a/1190000047607891</guid>    <pubDate>2026-02-12 17:04:07</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>随着生成式人工智能（AIGC）等技术不断演进，海量镜像与大模型的分发成为 AI 领域的一项关键挑战。这些挑战包括：海量分片（数百万个）、高并发拉取需求、严格的延迟要求，以及动态的网络环境等。如何在兼容 OCI 等主流格式，并且无需侵入性的实现动态、高效、可扩展的大规模镜像与模型文件分发系统，已是云原生应用与 AI 服务的迫切需求。</p><p>为了解决这些问题，蚂蚁集团与大连理工大学合作设计了一套动态、高效、可扩展的大规模镜像与模型文件分发系统。近日，由蚂蚁集团与大连理工大学共同撰写关于该系统的论文被 IEEE Transactions on Networking (TON) 期刊录用。TON 是由 IEEE 认可的高影响力学术期刊，在网络与系统领域具有重要影响力。本论文的录用标志着研究成果对行业发展具有前瞻性和创新性。 </p><h2>论文简介</h2><p>论文设计构建了一个高效、可扩展的 P2P 模型分发系统，该系统是对 CNCF 孵化项目 Dragonfly 的增强，通过多层次设计实现了资源优化与数据同步的有机结合，旨在解决传统 P2P 文件分发系统在面对 AI 大模型（如千亿参数模型）分发的特定挑战时表现不佳的问题。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047607893" alt="图片" title="图片"/><br/>论文链接：<a href="https://link.segmentfault.com/?enc=3pheekG8exl8sQ59UwJ3uw%3D%3D.6wJ7RJ3%2BiKHd3EUeAWF81npkxJdMSa98hLYZRx4uYvlvTkMNfgkMSVJL3GYLEa9c" rel="nofollow" target="_blank">https://ieeexplore.ieee.org/document/11152005</a><br/>项目官网：<a href="https://link.segmentfault.com/?enc=t9OBZ%2FjMZomC2VmNyY7hxA%3D%3D.3ZQ11q3NvjcKIzn%2F18T08g%3D%3D" rel="nofollow" target="_blank">https://d7y.io</a></p><h2>技术方案与创新方法</h2><p>传统的集中式镜像/模型中心（Container/Model Registry）在并发下载高峰期常遭遇单点带宽瓶颈，导致拉取速度下降、任务延迟增加。另一方面，单纯依赖内容分发网络（CDN）或私有链路虽能缓解部分热点问题，却无法充分利用集群内部节点的空闲带宽资源，同时引入额外的成本开销。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047607894" alt="图片" title="图片" loading="lazy"/><br/> 图 1: 文件分发系统架构图</p><p>应对这些问题，本方案引入了该方案引入了三个关键设计：首先，引入轻量级的网络测量机制，通过主动探测网络延迟和推断带宽，实时预测网络信息。其次，设计了可扩展的调度框架，通过将推理与调度解耦，提升了调度系统的资源利用率和响应速度。最后，Trainer 模块采用异步模型训练与推理方法，结合图学习算法，实现了基于突发性任务的增量学习。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047607895" alt="图片" title="图片" loading="lazy"/><br/>图 2: 三个关键设计的调度算法</p><p>如图 2 所示，轻量级的网络测量机制确保在有限的可用网络资源下对集群中的每个节点进行高效探测。可扩展的调度框架确保足够的可用资源执行调度任务。异步模型训练和推理方法让算法结合节点特性参数进行聚合，以捕捉集群内的相似性，从而提升带宽预测效果。</p><h2>性能成果</h2><p>性能评估表明，相较于主流系统和算法，本系统在总加载完成时间上实现了至少 10% 的缩减，同时将节点平均带宽利用率提升约 20%。此外，所提出的轻量级探测机制通过减少探测频率和计算复杂度，相比现有网络探测方法有效降低了资源开销。该系统不仅能满足 AI 对大规模模型分发的高并发、低延迟需求，还能更高效地利用集群资源，希望可以为行业提供参考。</p><h2>关于我们</h2><p>蚂蚁集团容器镜像与存储团队，主要参与<br/>Dragonfly(<a href="https://link.segmentfault.com/?enc=mSRreybcrae6rT8iRQ1clg%3D%3D.4LllGiyZVV%2F%2BAzApiUvTsSQK3UOWlVrGW4E5SqTyJBitfh6MK7GMB%2F410NQgSs9J" rel="nofollow" target="_blank">https://github.com/dragonflyoss/dragonfly</a>)、<br/>Nydus(<a href="https://link.segmentfault.com/?enc=2MDMSkZNtNr2onK3oxRz3g%3D%3D.ai7%2FOpjHFygnmPdyP%2B4ZkfGgEVDx%2Bp9VxBWZ4XhJWLQGjaRcPm7%2FtBQTOTzK%2BUNq" rel="nofollow" target="_blank">https://github.com/dragonflyoss/nydus</a>)、<br/>Harbor(<a href="https://link.segmentfault.com/?enc=a%2B5SDMzVo%2B2syWBcavu6QA%3D%3D.JSplnywtnDvnfPdeoIfuz8UMOMa2%2FjI%2BKJGW66zAeKdmH7ApVo4L1pFOZTOsup%2BD" rel="nofollow" target="_blank">https://github.com/goharbor/harbor</a>)和 <br/>ModelPack(<a href="https://link.segmentfault.com/?enc=NmTuv1ZwCYMXQyaeC%2FdbTw%3D%3D.wSWqIhPRw6sXtjFq3Y1UiHRu479W9IDanaokarqMeASPnO0u5hmFVflG9mlNP%2BZS" rel="nofollow" target="_blank">https://github.com/modelpack/model-spec</a>) 等开源项目在内部的开发落地和上游项目的维护。我们致力于打造业内顶尖的容器镜像服务，并推动云原生场景下 AI 模型和镜像分发的社区标准化。</p>]]></description></item><item>    <title><![CDATA[向量数据库选型指南：Pinecone vs Weaviate vs Chroma 深度对比 ꯭꯭听꯭]]></title>    <link>https://segmentfault.com/a/1190000047607897</link>    <guid>https://segmentfault.com/a/1190000047607897</guid>    <pubDate>2026-02-12 17:03:11</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在AI应用开发的浪潮中，向量数据库已经成为构建智能检索、推荐系统和RAG（检索增强生成）应用的基础设施。当你的应用需要处理嵌入向量、进行语义搜索时，选择合适的向量数据库就显得至关重要。今天我们就来深入对比三款主流向量数据库：Pinecone、Weaviate和Chroma，帮助你做出明智的技术选型。</p><h2>什么是向量数据库？为什么需要它？</h2><p>在传统数据库中，我们通过精确匹配来查询数据——比如查找"张三"的订单记录。但在AI时代，我们面临的是另一个挑战：如何找到"语义相似"的内容？当用户问"如何提升工作效率"时，系统需要找到所有关于时间管理、任务规划、工具使用的相关文档，即便这些文档中并没有出现"工作效率"这四个字。</p><p>这就是向量数据库的用武之地。它将文本、图像等数据转换为高维向量（通常由嵌入模型生成），然后通过计算向量之间的距离（相似度）来实现语义搜索。想象一下，每个概念都是空间中的一个点，相似的概念会聚集在一起，向量数据库就是帮你在这个高维空间中快速找到最近邻居的工具。</p><h2>三款数据库的基因与定位</h2><h3>Pinecone：云原生的性能之选</h3><p>Pinecone诞生于2019年，是一个完全托管的云服务，它的核心理念是"让开发者专注于应用，而不是基础设施"。Pinecone团队在设计之初就瞄准了企业级性能和规模化需求，它采用了专有的优化算法，在处理数十亿级别的向量检索时依然能保持毫秒级的响应速度。</p><p>如果你正在构建一个需要处理海量数据的生产系统，比如全网商品的相似推荐、大规模文档库的智能检索，Pinecone的稳定性和性能表现会让你印象深刻。不过，这种高性能是有代价的——它是一个纯云服务，你无法在本地部署，而且定价相对较高。</p><h3>Weaviate：开源的全能战士</h3><p>Weaviate从2019年开始开源，它的野心更大——不仅仅是一个向量数据库，而是一个完整的AI原生数据库。除了向量搜索，Weaviate还支持传统的CRUD操作、复杂的过滤条件、多模态数据（文本、图像等）的混合查询。</p><p>这款数据库的架构非常灵活，你可以选择云托管，也可以在自己的服务器上部署。它内置了多种向量化模型，甚至支持在查询时实时生成嵌入向量，这对于快速原型开发非常友好。如果你的应用场景复杂，需要结合传统数据库功能和向量搜索，Weaviate会是一个理想的选择。</p><h3>Chroma：轻量级的开发者最爱</h3><p>Chroma是三者中最年轻的，2022年才推出，但它迅速在开发者社区中走红。原因很简单：它足够轻量、足够简单。Chroma的设计哲学是"嵌入即数据库"——你可以用几行Python代码就启动一个向量数据库，无需复杂的配置和部署。</p><p>对于AI应用的原型开发、小规模项目或者本地实验，Chroma简直是完美的工具。它默认使用本地持久化，也支持客户端-服务器模式。虽然在企业级功能和性能上不如前两者，但它的简洁性和易用性让初学者和独立开发者爱不释手。</p><h2>核心能力对比：谁更适合你的场景？</h2><h3>性能与规模</h3><p>在处理亿级向量的场景下，Pinecone展现出了明显的优势。它采用的近似最近邻（ANN）算法经过深度优化，查询延迟可以控制在10-50毫秒之间。Weaviate的性能也相当不错，特别是在合理配置HNSW索引参数后，可以达到相近的水平。Chroma在小规模数据（百万级）下表现良好，但当数据量突破千万级别时，性能会有明显下降。</p><p>一个典型的例子：如果你在构建一个服务百万用户的推荐系统，每天处理上亿次查询，Pinecone的稳定性和性能会给你更多信心。但如果是一个企业内部的知识库检索系统，用户基数有限，Weaviate或Chroma都能胜任。</p><h3>功能丰富度</h3><p>Weaviate在功能上是最全面的。它支持混合搜索（结合关键词和向量）、多租户隔离、复杂的GraphQL查询、自动向量化等。这意味着你可以在一个系统中同时满足传统数据库和向量数据库的需求。</p><p>Pinecone则专注于向量搜索这一核心功能，提供了元数据过滤、命名空间隔离等实用特性，但不会有传统数据库的CRUD操作。Chroma介于两者之间，提供了基础的元数据过滤和简单的查询接口，足够日常使用但不够企业级。</p><h3>部署与运维</h3><p>这是三者差异最大的地方。Pinecone是纯云服务，你无需关心任何基础设施，一个API密钥就能开始使用。这既是优势也是限制——优势在于零运维成本，限制在于你必须依赖外部服务，数据存储在第三方云上。</p><p>Weaviate提供了最大的灵活性：你可以使用官方云服务Weaviate Cloud Services（WCS），也可以通过Docker、Kubernetes自行部署。对于有数据主权要求或需要定制化配置的企业，这种灵活性至关重要。</p><p>Chroma默认是一个嵌入式数据库，可以直接在应用中启动，也支持独立的服务器模式。它的部署极其简单，甚至不需要Docker，一个Python环境就够了。</p><h3>成本考量</h3><p>成本不仅是金钱，还包括学习成本和维护成本。Pinecone按照向量存储量和查询次数计费，对于中大型应用，月度费用可能从数百到数千美元不等。但你节省了运维时间和基础设施成本。</p><p>Weaviate和Chroma都是开源的，如果自行部署，只需要承担服务器成本。Weaviate的云服务定价比Pinecone略低，而且有免费额度。Chroma完全免费，但你需要自己处理扩展性和高可用问题。</p><h2>实际应用场景建议</h2><h3>选择Pinecone，如果你：</h3><ul><li>需要处理数千万甚至数亿级别的向量数据</li><li>对查询延迟有严格要求（如实时推荐系统）</li><li>希望最小化运维工作，专注于业务逻辑</li><li>有充足的预算，愿意为性能和稳定性付费</li></ul><h3>选择Weaviate，如果你：</h3><ul><li>需要结合传统数据库功能和向量搜索</li><li>有数据隐私或本地化部署的要求</li><li>应用场景复杂，需要灵活的查询能力</li><li>希望在开源生态和企业支持之间取得平衡</li></ul><h3>选择Chroma，如果你：</h3><ul><li>正在进行原型开发或概念验证</li><li>数据规模在百万级别以内</li><li>团队规模较小，需要快速上手</li><li>预算有限，或者偏好简单的技术栈</li></ul><h2>技术演进与未来趋势</h2><p>向量数据库领域还很年轻，技术演进非常迅速。Pinecone最近推出了Serverless架构，进一步降低了使用门槛。Weaviate在多模态搜索和AI集成方面持续发力，最新版本已经支持了生成式AI模块。Chroma则在不断优化性能，缩小与成熟产品的差距。</p><p>值得注意的是，传统数据库巨头也在入场。PostgreSQL的pgvector插件、Elasticsearch的向量搜索功能都在快速成熟。选型时也可以考虑这些"混合型"方案，特别是当你已经在使用这些数据库时。</p><h2>结语</h2><p>向量数据库的选型没有绝对的对错，关键是匹配你的实际需求。如果你追求极致性能且预算充足，Pinecone是最省心的选择；如果需要功能全面且部署灵活，Weaviate值得深入研究；如果想要快速启动或控制成本，Chroma会是理想的起点。</p><p>技术选型永远是一个权衡的过程——性能、成本、灵活性、易用性，你需要在这些维度之间找到最适合自己的平衡点。建议在做最终决定前，针对你的真实数据和查询模式做一些基准测试，数据会给你最直观的答案。</p><p>记住，最好的数据库不是功能最多的，也不是性能最强的，而是最适合你的业务场景、团队能力和发展阶段的那一个。</p><hr/><h2>快速对比表格</h2><table><thead><tr><th>特性</th><th>Pinecone</th><th>Weaviate</th><th>Chroma</th></tr></thead><tbody><tr><td><strong>类型</strong></td><td>托管云服务</td><td>开源（可托管）</td><td>开源嵌入式</td></tr><tr><td><strong>推出时间</strong></td><td>2019</td><td>2019</td><td>2022</td></tr><tr><td><strong>适用规模</strong></td><td>亿级+</td><td>千万-亿级</td><td>百万-千万级</td></tr><tr><td><strong>部署方式</strong></td><td>仅云端</td><td>云端/自托管</td><td>嵌入式/服务器</td></tr><tr><td><strong>查询延迟</strong></td><td>10-50ms</td><td>20-100ms</td><td>50-200ms</td></tr><tr><td><strong>功能丰富度</strong></td><td>⭐⭐⭐</td><td>⭐⭐⭐⭐⭐</td><td>⭐⭐⭐</td></tr><tr><td><strong>易用性</strong></td><td>⭐⭐⭐⭐</td><td>⭐⭐⭐</td><td>⭐⭐⭐⭐⭐</td></tr><tr><td><strong>成本</strong></td><td>高</td><td>中</td><td>低/免费</td></tr><tr><td><strong>企业支持</strong></td><td>是</td><td>是</td><td>社区</td></tr></tbody></table><hr/><p><strong>作者注：</strong> 本文基于2026年2月的技术现状撰写，向量数据库技术发展迅速，建议查阅各产品官方文档获取最新信息。</p><p><strong>相关资源：</strong></p><ul><li>Pinecone官网：<a href="https://link.segmentfault.com/?enc=NmB%2Bvdp%2BdQSuESM0Inq7Mg%3D%3D.j5KX%2Fqd5SXdjQRTkrgMd2OqtLlpFlqtzTLZ8BOy2Ms8%3D" rel="nofollow" target="_blank">https://www.pinecone.io</a></li><li>Weaviate官网：<a href="https://link.segmentfault.com/?enc=b8XBqqsZTteiw5%2FZ%2BCpieg%3D%3D.eouo8sv%2BtQ1UtTpTgonpGgx5sm1RGwi0lJDTo3IlyjA%3D" rel="nofollow" target="_blank">https://weaviate.io</a></li><li>Chroma官网：<a href="https://link.segmentfault.com/?enc=ul0CUjIW%2B6dBdiMKj9BitQ%3D%3D.GeCutvxvlVi3SwQR%2FbsqBzmv7ZnLfn3f8dO0ushq1G8%3D" rel="nofollow" target="_blank">https://www.trychroma.com</a></li></ul>]]></description></item><item>    <title><![CDATA[『NAS』将魂斗罗马里奥塞进NAS里 德育处主任 ]]></title>    <link>https://segmentfault.com/a/1190000047607908</link>    <guid>https://segmentfault.com/a/1190000047607908</guid>    <pubDate>2026-02-12 17:02:34</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><strong>点赞 + 关注 + 收藏 = 学会了</strong></p><blockquote>整理了一个NAS小专栏，有兴趣的工友可以关注一下 👉 <a href="https://link.segmentfault.com/?enc=OIbxR326Hl964XzLpvB60A%3D%3D.MPdd3tnoyNZC3vzjW04vnrP9keghPCQZzcwb2%2Bb7WPZJS2pF%2BpeYk4IP25ZdS4rEqIJeaMHr5f2s2wF3lxqEGiBx79OncNeq6BLdv5zCvzluM0OJuXmeNZAhW4nBL2dU2Yw9iYIJXwMBjHRNz8IE3C9z7QVou2kh4JzWXfI26vU%3D" rel="nofollow" target="_blank">《NAS邪修》</a></blockquote><p>JSNES 是一款怀旧游戏模拟器，无需安装任何客户端，仅通过浏览器即可运行，支持超级马里奥、魂斗罗等海量经典游戏。可部署到 NAS、服务器等设备打造本地怀旧游戏中心，完全免费无广告，轻松重温童年游戏乐趣。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607910" alt="" title=""/></p><p>本次使用飞牛 NAS 部署 JSNES，其他品牌的 NAS 部署流程也是差不多的。</p><p>在“文件管理”找到“docker”文件夹，在里面创建一个“jsnes”文件夹。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607911" alt="" title="" loading="lazy"/></p><p>打开“Docker”，切换到「Compose」面板，创建一个项目。</p><p>项目名称填 <code>jsnes</code>。</p><p>路径选择刚刚在“文件管理”里创建的 <code>/docker/jsnes</code>，具体目录根据你的 NAS 情况来填。</p><p>来源选择“创建docker-compose.yml”。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607912" alt="" title="" loading="lazy"/></p><p>输入以下代码：</p><pre><code>services:
  jsnes:
    image: docker.1ms.run/wangz2019/jsnes:1.0.0
    container_name: jsnes
    ports:
      - 3456:80
    restart: always</code></pre><p>我给它配置了 <code>3456</code> 端口，你可以自定义。</p><p>等 jsnes 下载并构建完成后，切换到「容器」面板，找到 jsnes 点击这个“链接”按钮就可以在浏览器打开 jsnes 了。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607913" alt="" title="" loading="lazy"/></p><p>支持键盘按键操作。 </p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607914" alt="" title="" loading="lazy"/></p><p>在手机也可以玩的。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607915" alt="" title="" loading="lazy"/></p><p>除了马里奥和魂斗罗之外，还有淘金者、功夫、坦克大战等众多经典游戏。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607916" alt="" title="" loading="lazy"/></p><hr/><p>以上就是本文的全部内容啦，<strong>有疑问可以在评论区讨论～</strong></p><p><strong>想了解更多NAS玩法可以关注<a href="https://link.segmentfault.com/?enc=X8nFGUn4xlbeQ0GIpX0fjQ%3D%3D.SYtNdgI8Y6CHkXVMScGnv2f4yAnjuNnyY5Xd9bbeyxrCdhXM%2FomYx254Lz6ydLkuZ7SYd7kyrmZAbPsmnaGdBs3vao7B3dI2h6VqkN%2FgNs16m%2FRW5Olz2wX0xry6b1rMs68jqhq5h0ZAFguwjMzjp6NfBk%2BsVyRJGOu77Sn%2FS20%3D" rel="nofollow" target="_blank">《NAS邪修》👏</a></strong></p><p><strong>点赞 + 关注 + 收藏 = 学会了</strong></p>]]></description></item><item>    <title><![CDATA[拆开一看才明白：Codex 这种“本地AI写代码”到底怎么跑起来的？ 吾日三省吾码 ]]></title>    <link>https://segmentfault.com/a/1190000047607960</link>    <guid>https://segmentfault.com/a/1190000047607960</guid>    <pubDate>2026-02-12 17:02:01</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>如果你也在折腾“让大模型在本地改代码”的 Agent，八成遇到过这种崩溃瞬间：模型说要执行命令、工具跑完回传一大坨、上下文越滚越长、性能忽高忽低、最后还把权限问题搞成“你敢让我删库我就敢执行”……😅</p><p>OpenAI 的 Codex CLI（本地跨平台软件代理）把这套流程摊开讲得很直白：核心就是 <strong>agent loop（代理循环）</strong>——一个负责“用户 ↔ 模型 ↔ 工具”编排的 harness。把 loop 设计对了，Agent 才不会像一只喝了三杯咖啡的无头苍蝇。</p><p>下面就用更接地气（但依然严谨）的方式，把 Codex 的 agent loop 彻底“拆开看看”，顺便给做 Java/Python 工程化的同学一些能直接落地的套路。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607962" alt="image" title="image"/></p><h2>1）所谓 Agent Loop：其实就是“反复问、反复干、反复追加”的流水线</h2><p>Codex 这套 loop 的节奏非常规律：</p><ol><li><strong>收用户输入</strong>：把用户的话塞进要发给模型的 prompt（注意：真实 prompt 不是一段字符串，而是“多条消息/多种 item 的列表”）。</li><li><strong>模型推理（inference）</strong>：把 prompt 送到模型，让模型输出。</li><li><p><strong>分支</strong>：模型输出要么是</p><ul><li><strong>最终回复（assistant message）</strong>：这回合结束；</li><li><strong>工具调用（tool call）</strong>：比如让 agent 执行 <code>ls</code>、读文件、跑测试等。</li></ul></li><li><strong>执行工具 + 追加结果</strong>：agent 执行工具，把工具输出追加回 prompt，再请求模型下一轮推理。</li><li><strong>循环直到停止调用工具</strong>：最后必须以 assistant message 收尾（哪怕主要产出是“本地代码改动”）。</li></ol><p>一回合（turn）里可能有很多次“推理↔工具”迭代；多回合（multi-turn）则会把历史对话都带上，prompt 越滚越长：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607963" alt="image" title="image" loading="lazy"/></p><p>这也解释了为什么 Agent 工程化最容易踩的坑，永远是这两座大山：</p><ul><li><strong>性能</strong>（请求体越来越大，推理越来越贵，缓存还经常失效）</li><li><strong>上下文窗口</strong>（context window）不够用（尤其单回合工具调用特别多的时候）</li></ul><h2>2）Codex 如何“组装 prompt”：不是你以为的一段文本，而是一串分角色的 item</h2><p>Codex CLI 用的是 <a href="https://link.segmentfault.com/?enc=efFWgMQPCLDWE7U8UzagkA%3D%3D.RBZKltXaBq195AM5UHHz5wr2%2FF1QbYfClVSlE%2FZTUrLuwF7%2FOHjPywIENzkCcteX7HvyOCYjKD%2FKDAPxFMl15w%3D%3D" rel="nofollow" target="_blank">Responses API</a>，而不是让用户直接手搓 prompt。用户提交的 JSON 里最关键的三块是：</p><ul><li><code>instructions</code>：系统/开发者指令（Codex 既支持用户配置，也有模型内置 base instructions）</li><li><code>tools</code>：可调用的工具定义列表（Codex 内置 shell、plan 等，也可接 MCP 工具，甚至用 web_search）</li><li><code>input</code>：多条 item 的数组（消息、文件、图片、推理结果、工具调用/输出等都在这里）</li></ul><p>Codex 会先往 <code>input</code> 里插入一堆“铺垫项”，再追加用户的真实提问。典型的插入顺序包含：</p><ul><li><strong>developer 消息：权限/沙箱说明</strong>（只约束 Codex 自带的 shell 工具）</li><li><strong>developer 消息：用户自定义 developer_instructions（可选）</strong></li><li><strong>user 消息：用户指令聚合（可选）</strong>（例如 AGENTS.md/AGENTS.override.md、skills 等）</li><li><strong>user 消息：环境上下文</strong>（cwd、shell 等）</li></ul><p>示例（权限/沙箱说明）：</p><pre><code class="txt">&lt;permissions instructions&gt;
  - description of the sandbox explaining file permissions and network access
  - instructions for when to ask the user for permissions to run a shell command
  - list of folders writable by Codex, if any
&lt;/permissions instructions&gt;</code></pre><p>示例（环境上下文）：</p><pre><code class="txt">&lt;environment_context&gt;
  &lt;cwd&gt;/Users/mbolin/code/codex5&lt;/cwd&gt;
  &lt;shell&gt;zsh&lt;/shell&gt;
&lt;/environment_context&gt;</code></pre><p>而真正发到 Responses API 的 <code>input</code> item，是这种结构：</p><pre><code class="json">{
  "type": "message",
  "role": "user",
  "content": [
    {
      "type": "input_text",
      "text": "Add an architecture diagram to the README.md"
    }
  ]
}</code></pre><p>另外，Codex 还会把工具定义塞到 <code>tools</code> 里，长得大概这样（里面同时包含 shell、plan、web_search、以及 MCP 工具）：</p><pre><code class="javascript">[
  // Codex's default shell tool for spawning new processes locally.
  {
    "type": "function",
    "name": "shell",
    "description": "Runs a shell command and returns its output...",
    "strict": false,
    "parameters": {
      "type": "object",
      "properties": {
        "command": {"type": "array", "description": "The command to execute"},
        "workdir": {"description": "The working directory..."},
        "timeout_ms": {"description": "The timeout for the command..."}
      },
      "required": ["command"]
    }
  },

  // Codex's built-in plan tool.
  {
    "type": "function",
    "name": "update_plan",
    "description": "Updates the task plan...",
    "strict": false,
    "parameters": {
      "type": "object",
      "properties": {"plan": "...", "explanation": "..."},
      "required": ["plan"]
    }
  },

  // Web search tool provided by the Responses API.
  { "type": "web_search", "external_web_access": false },

  // MCP server tool (example).
  {
    "type": "function",
    "name": "mcp__weather__get-forecast",
    "description": "Get weather alerts for a US state",
    "strict": false,
    "parameters": {
      "type": "object",
      "properties": {"latitude": {}, "longitude": {}},
      "required": ["latitude", "longitude"]
    }
  }
]</code></pre><p>Codex 文章里还有几张“prompt 快照”的图，直观看出服务器会把 system、tools、instructions、input 组装成最终 prompt：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607964" alt="image" title="image" loading="lazy"/></p><h2>3）流式推理 + 工具回填：SSE 事件才是“真实对话记录”</h2><p>Codex 发起一次推理，Responses API 会用 SSE（Server-Sent Events）流式返回事件；这些事件不仅用来 UI 实时输出，还会被 Codex 转成内部对象，并追加回 <code>input</code>，供下一轮推理继续使用。</p><p>示例（SSE 事件流片段）：</p><pre><code class="txt">data: {"type":"response.reasoning_summary_text.delta","delta":"ah ", ...}
data: {"type":"response.reasoning_summary_text.delta","delta":"ha!", ...}
data: {"type":"response.reasoning_summary_text.done", "item_id":...}
data: {"type":"response.output_item.added", "item":{...}}
data: {"type":"response.output_text.delta", "delta":"forty-", ...}
data: {"type":"response.output_text.delta", "delta":"two!", ...}
data: {"type":"response.completed","response":{...}}</code></pre><p>如果模型输出了 <code>function_call</code>，Codex 执行工具后会把 <strong>推理摘要、函数调用、函数输出</strong> 一股脑追加回下一次请求的 <code>input</code>，示例：</p><pre><code class="javascript">[
  /* ... original items ... */
  {
    "type": "reasoning",
    "summary": [
      {"type": "summary_text", "text": "**Adding an architecture diagram for README.md**\n\nI need to..."}
    ],
    "encrypted_content": "gAAAAABpaDWNMxMeLw..."
  },
  {
    "type": "function_call",
    "name": "shell",
    "arguments": "{\"command\":\"cat README.md\",\"workdir\":\"/Users/mbolin/code/codex5\"}",
    "call_id": "call_8675309..."
  },
  {
    "type": "function_call_output",
    "call_id": "call_8675309...",
    "output": "&lt;p align=\"center\"&gt;&lt;code&gt;npm i -g @openai/codex&lt;/code&gt;..."
  }
]</code></pre><p>对应的第二张快照图：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607965" alt="image" title="image" loading="lazy"/></p><p>当模型终于输出 assistant message（不再请求工具）时，这个 turn 才算结束：</p><pre><code class="txt">data: {"type":"response.output_text.done","text":"I added a diagram to explain...", ...}
data: {"type":"response.completed","response":{...}}</code></pre><p>用户再发一句话，就进入下一 turn：需要把上一次 assistant message 和本次 user message 一起追加进去：</p><pre><code class="javascript">[
  /* ... all items from the last request ... */
  {
    "type": "message",
    "role": "assistant",
    "content": [{ "type": "output_text", "text": "I added a diagram to explain the client/server architecture." }]
  },
  {
    "type": "message",
    "role": "user",
    "content": [{ "type": "input_text", "text": "That's not bad, but the diagram is missing the bike shed." }]
  }
]</code></pre><p>第三张快照图更能说明：这玩意儿会一直长一直长……</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607966" alt="image" title="image" loading="lazy"/></p><h2>4）性能：请求体“看似二次方”，但缓存命中能救命</h2><p>很多同学看到“每次把所有历史 input 都带上”第一反应：<strong>这不就是网络传输二次方增长吗？</strong> 没错。</p><p>Responses API 支持 <code>previous_response_id</code> 来减少重复传输但Codex 当前选择不用它，主要为了两点：</p><ul><li><strong>保持请求无状态</strong>：对 API 提供方更友好。</li><li><strong>支持 ZDR（Zero Data Retention）</strong>：不在服务端存历史数据，避免与“零数据保留”冲突；同时 reasoning 的 <code>encrypted_content</code> 允许服务端解密以保留“模型理解”，但不持久化用户数据本身。</li></ul><p>真正的性能关键在于：<a href="https://link.segmentfault.com/?enc=p%2FOe5ynECiM%2B385ByZthSw%3D%3D.f3hqcwGx1q3dt61B4ETyC2%2F7s84stjSJXxFsbfdAPWv4FjfR3F33VNkTLkEVddT%2FPjAPMwPxF5Vx2KU4BvjJ9qXZ89mxW72pTwwc%2FANvRSQ%3D" rel="nofollow" target="_blank"><strong>prompt caching</strong></a>。缓存命中要求非常苛刻：<strong>必须是精确的前缀匹配</strong>。因此缓存命中要求非常苛刻：<strong>必须是精确的前缀匹配</strong>。因此) Codex 特别强调“旧 prompt 是新 prompt 的 exact prefix”，这不是强迫症，是省钱省到骨子里了😂。</p><p>哪些变化会导致 cache miss？</p><ul><li>中途改 <code>tools</code>（甚至工具顺序不稳定都会炸）</li><li>改 <code>model</code>（模型内置指令变了）</li><li>改沙箱配置、审批策略、cwd 等</li></ul><p>Codex 的一个经典教训：早期接入 MCP 工具时，因为 <strong>工具枚举顺序不一致</strong> 导致缓存频繁失效（工具数量一多，直接“性能心电图”📉）。</p><p>为了尽量保住前缀，Codex 对“中途配置变更”的处理是：<strong>追加新消息</strong>，而不是修改旧消息：</p><ul><li>沙箱配置/审批模式变化：追加新的 developer <code>&lt;permissions instructions&gt;</code></li><li>cwd 变化：追加新的 user <code>&lt;environment_context&gt;</code></li></ul><p>这招非常值得抄作业：你改的是“环境状态”，但你不能动 prompt 的“历史前缀”。</p><h2>5）上下文窗口：不够用怎么办？压缩（compaction）才是正解</h2><p>Agent 聊着聊着就爆 context window，这事不是“会不会发生”，而是“什么时候发生”。Codex 的策略是超过阈值就 <strong>compact</strong>：把冗长的 <code>input</code> 替换成一个更短、但能代表历史的 item 列表，让后续推理还能“记得发生过啥”。</p><p>早期需要手动 <code>/compact</code>；后来 Responses API 提供了专门的 compaction endpoint：<br/><a href="https://link.segmentfault.com/?enc=YF0ywUSlzB%2F283ua1y8Wfw%3D%3D.XVgEZ4niHzRNynK7Z6k7GJMJjLNK8ptYB8bgajWz3aToT60dq1J8PWKrQhO5rqCS2xj3Ss2Ya8g%2BhjRAtexnMBQ0O6iE78y6FCD%2Bd7ftM8E%3D" rel="nofollow" target="_blank">https://platform.openai.com/docs/guides/conversation-state#co...</a></p><p>它会返回一组可直接替代原 <code>input</code> 的 items，其中包含 <code>type=compaction</code> 以及不透明的 <code>encrypted_content</code>，用于保留模型的“潜在理解”。Codex 现在会在超过 <code>auto_compact_limit</code> 后自动触发这件事。</p><hr/><h2>6）给做 Java/Python 工程化 Agent 的“抄作业清单”✅</h2><p>把 Codex 的设计拆完，可以总结出几条非常硬核、非常工程的结论：</p><ol><li><strong>把 prompt 当“不可变日志”来设计</strong><br/>追加新事件，不修改旧事件。你改旧的，缓存就没了；你改多了，定位就疯了。</li><li><strong>工具列表要稳定排序 + 版本可控</strong><br/>工具顺序不稳定 ≈ 主动放弃缓存。生产环境别玩“每次启动动态扫描全部工具再随机排列”的刺激游戏。</li><li><strong>权限/沙箱必须写进 prompt</strong><br/>这不是文档，这是模型行为约束的一部分。尤其是 shell 这类高危工具，不写清楚“哪些目录可写、何时需要用户确认”，迟早出事故。</li><li><strong>流式事件要落地成结构化记录</strong><br/>SSE 不只是展示给用户看的“打字效果”，而是下一轮推理的输入材料。要能回放、能审计、能复现。</li><li><strong>上下文管理要有自动化机制</strong><br/>compaction 不是锦上添花，是续命针。阈值触发、摘要策略、加密理解保留，都是工程必须项。</li></ol><hr/><p>当 Agent loop 真正做对了，你会发现“让模型写代码”不再是玄学，更像一套可控的流水线：<strong>可追溯、可审计、可缓存、可压缩、可扩展</strong>。</p><p>而 Codex 把这套“写代码的 AI 代理”最核心的一环——loop——摊开讲清楚了：所谓智能体，很多时候并不是模型多聪明，而是 harness 多靠谱。</p><p>（Codex 开源仓库： <a href="https://link.segmentfault.com/?enc=94A8hvv6OvvNV9c9IvyDfw%3D%3D.pxrN4EG3eqtWKpGlku%2F14O8affAlxU8d7I1NO%2BL1wLw%3D" rel="nofollow" target="_blank">https://github.com/openai/codex</a> ）</p><hr/><p><strong>喜欢就奖励一个“👍”和“在看”呗~</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047106529" alt="image" title="image" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[数据库数据恢复—ASM故障后Oracle数据如何起死回生？ 北亚数据恢复 ]]></title>    <link>https://segmentfault.com/a/1190000047607992</link>    <guid>https://segmentfault.com/a/1190000047607992</guid>    <pubDate>2026-02-12 17:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><strong>一、Oracle数据库故障描述</strong><br/>一个Oracle数据库故障表现为ASM磁盘组掉线，ASM实例无法挂载（mount）。数据库管理员自行进行简单修复，未能成功，随后联系北亚数据恢复中心恢复数据。</p><p><strong>二、Oracle数据库故障分析方法</strong><br/>北亚企安数据恢复工程师先对底层磁盘展开分析，从组成ASM磁盘组的磁盘中提取ASM元数据作进一步研究。经分析发现，ASM存储元数据已损坏，这就是diskgroup无法挂载的原因。接着，北亚企安数据恢复工程师重组ASM存储空间，导出其中的数据库文件，再对导出的文件进行检测与恢复。若检测显示数据文件完整，后续可直接用其启动数据库；若文件也损坏，则需对底层文件进行解析和恢复。</p><p><strong>三、Oracle数据库数据恢复过程</strong><br/>1、按上述方法分析和提取底层数据，得到ASM元数据，借助其重组出ASM存储空间。<br/>2、得到ASM存储空间后，使用北亚自主开发的ASM解析工具（也可用其他常见工具或自编脚本）解析ASM结构，目的是获取ASM中的数据文件。<br/><img width="723" height="445" referrerpolicy="no-referrer" src="/img/bVc6FHj" alt="北亚企安数据恢复—oracle数据恢复" title="北亚企安数据恢复—oracle数据恢复"/><br/>3、对提取的Oracle数据库文件进行检测。<br/>检测结果：<br/><img width="723" height="417" referrerpolicy="no-referrer" src="/img/bVc6FHk" alt="北亚企安数据恢复—oracle数据恢复" title="北亚企安数据恢复—oracle数据恢复" loading="lazy"/><br/>4、利用北亚自主开发的oracle数据库解析工具，解析所有数据文件中的数据记录，然后按用户需求导入到新数据库中。<br/><img width="718" height="590" referrerpolicy="no-referrer" src="/img/bVc6FHl" alt="北亚企安数据恢复—oracle数据恢复" title="北亚企安数据恢复—oracle数据恢复" loading="lazy"/></p><p><strong>四、Oracle数据库数据恢复成功</strong><br/>通过重组ASM存储空间、对ASM磁盘底层解析，导出恢复后的数据库文件，并进一步对这些文件进行底层解析，再按用户要求将数据导入新数据库。北亚企安数据恢复工程师抽查数据表验证恢复数据，未发现异常，随后通知用户方进行全面数据验证，结果显示数据恢复完整，本次Oracle数据库数据恢复成功。<br/><img width="723" height="323" referrerpolicy="no-referrer" src="/img/bVc6FHm" alt="北亚企安数据恢复—oracle数据恢复" title="北亚企安数据恢复—oracle数据恢复" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[首款 NL2GeoSQL 的测试基准和数据集来了！ 爱可生开源社区 ]]></title>    <link>https://segmentfault.com/a/1190000047607608</link>    <guid>https://segmentfault.com/a/1190000047607608</guid>    <pubDate>2026-02-12 16:09:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>专题介绍</h2><p>当我们对 AI4SQL/AI4DB/DB4AI 类产品进行研究时，我们发现 SQL 领域应用能力的提升很大程度上依赖于高质量的数据集。</p><p>还需要在此基础上进行数据合成，生成针对特定问题的训练集和评估集。为了帮助更多开发者快速获取资源，我们将近年来公开的 Text2SQL/NL2SQL 数据集进行了整理清单，持续分享给大家！</p><p>本期为系列文章的第六期，将介绍 <strong>大模型在地理空间查询 SQL 生成</strong> 和 <strong>提高 NL2SQL 精准度</strong> 方面的两款数据集：<a href="https://link.segmentfault.com/?enc=qNudtB%2BvK2GrN%2Fev2yN8RA%3D%3D.Wj2NtBKfA7Y1CowgWB45CtalYW8xZfQPN%2FVIZhSXEdGVsGSnNpf0F13op%2B4yJf75" rel="nofollow" title="GeoSQL-Eval 论文" target="_blank">GeoSQL-Eval</a> 与 <a href="https://link.segmentfault.com/?enc=5vHWvc99jJW0bFZG7gdxrg%3D%3D.Ytvwh%2BmKn8RXWhM4LTILBOi22X%2BspJZSM7aiNF2zHlOXu3SiOt4zeTDdfq0AePddCoxgBg67V233vTDBKQ6xzA%3D%3D" rel="nofollow" title="DeKeyNLU 论文" target="_blank">DeKeyNLU</a>。</p><h2>GeoSQL-Eval / GeoSQL-Bench</h2><p><a href="https://link.segmentfault.com/?enc=Nirdu%2FV188ots%2BZMMQ%2F2qw%3D%3D.xK8jU%2F4eKMwsaka5aSlMrNHVNe15YGs894xm9326nmuxJ0JBrQQVEAeOP1tR1r5rNlwbzaU%2FbljEODof7OrkuA%3D%3D" rel="nofollow" title="GeoSQL-Eval 排行榜" target="_blank">GeoSQL-Eval</a> 是首个面向 PostGIS 环境的端到端自动化评估框架，旨在衡量大型语言模型在 <strong>地理空间</strong> 数据库查询生成（GeoSQL）方面的性能。</p><p>该研究还包括发布 <strong>GeoSQL-Bench 基准测试数据集</strong>，其中包含 14,178 个实例、340 个 PostGIS 函数和 82 个专题数据库。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607610" alt="image2026-2-2 10_41_56.png" title="image2026-2-2 10_41_56.png"/></p><h3>论文意图</h3><p>本文主要针对现有大型语言模型在生成 PostGIS 空间查询（GeoSQL）方面的性能评估难题，探讨如何系统地衡量这些模型的性能，因为目前 <strong>缺乏专门的评估基准和框架</strong>。传统的 NL2SQL 基准测试无法涵盖空间数据类型、函数和坐标系等复杂元素，导致在实际应用场景中出现函数错觉和参数误用等错误。</p><p>为了解决这一问题，论文提出了：</p><ul><li><strong>GeoSQL-Bench 基准测试</strong></li><li><strong>GeoSQL-Eval 评估框架</strong></li></ul><p>这些框架旨在为 <strong>NL2GeoSQL</strong> 任务建立一个标准化、多层次且可执行的评估系统，支持模型能力诊断和优化，并降低不同领域用户使用空间数据库的门槛。</p><h3>数据集分析</h3><p><strong>GeoSQL-Bench 数据集</strong> 采用多源结构化方法构建，涵盖三种类型的任务：</p><ol><li><strong>多项选择题和判断题</strong>（2380 道），基于 PostGIS 3.5 官方手册，测试函数功能、参数顺序、返回类型以及是否符合规范；</li><li><strong>语法级 SQL 生成题</strong>（3744 道），源自手册示例，包含显式提示和欠规范提示，验证模型生成可执行查询的能力；</li><li><strong>表结构检索题</strong>（2155 道），基于使用联合国全球地理信息管理 (UN GGIM) 主题和 ISO 19115 分类构建的包含 82 个真实场景的空间数据库，要求模型使用表结构生成复杂查询。</li></ol><p>所有任务均在 GPT-4o 的辅助下生成，并经过领域专家的三重审核，以确保准确性、多样性和真实性。</p><h2>小结</h2><p>本研究使用 <strong>GeoSQL-Eval 框架</strong> 系统地评估了六大类共 24 个主流模型。</p><p>实验表明，推理增强型模型（例如 GPT-5 和 o4-mini）在复杂的空间查询和多轮查询生成方面表现出色，尤其是在几何任务中展现出显著的准确率优势。通用非推理模型（例如 Claude3.7-Sonnet）在执行效率和语法正确性方面表现更佳。然而，函数调用和参数匹配错误仍然是核心瓶颈，约占 70%，而表结构检索任务由于多表连接逻辑的复杂性而面临最大挑战。</p><p>这项工作建立了首个针对 NL2GeoSQL 任务的标准化评估系统，为自然语言与空间数据库的交互提供了关键的基准和优化方向。</p><h2>DeKeyNLU</h2><p><a href="https://link.segmentfault.com/?enc=aRdRLtcbNQ4l0%2FmLlkvhhw%3D%3D.kDLiI7aS1VOPf51mwdw%2BJb%2BKMZ8Zqt3RcwVqYG5L3Yat215hrgcEl%2Bv30Eb7%2Fv8q" rel="nofollow" title="DeKeyNLU 数据集" target="_blank">DeKeyNLU</a> 通过三层人工交叉验证，实现了任务分解和关键词提取的联合细粒度标注。在此基础上，DeKeySQL 框架创新性地将一个专门的理解模块深度集成到 RAG（结果生成）过程中，建立了一种 “<strong>优先考虑精确语义解析</strong>” 的新范式，<strong>显著提高了复杂查询 SQL 生成的准确性和领域适应性。</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607611" alt="image2026-2-3 14_41_56 (1).png" title="image2026-2-3 14_41_56 (1).png" loading="lazy"/></p><h3>论文意图</h3><p>本文旨在解决当前 RAG（检索增强生成）和 CoT（思维链）技术在 NL2SQL（自然语言 SQL 生成）任务中遇到的主要瓶颈：</p><p><strong>通用大模型在任务分解和关键词提取方面的准确性不足。</strong></p><p>现有的数据集在任务分解方面往往过于碎片化，且缺乏特定领域的关键词标注。为了解决这些问题，作者提出了 <strong>DeKeyNLU 数据集</strong> 和 <strong>DeKeySQL 流程</strong>（包含三个模块：用户问题理解、实体检索和生成）。通过对模型进行微调以优化问题理解阶段，最终生成的 SQL 语句的准确性得到了提升。</p><h3>数据集分析</h3><p><strong>DeKeyNLU 数据集</strong> 包含 1500 个高质量标注的问答对，数据来源于 BIRD 基准数据集，涵盖金融、教育等多个领域的真实数据库场景，数据集按 <strong>7:2:1</strong> 的比例划分为训练集、验证集和测试集。</p><p>数据合成采用 “<strong>LLM 预标注 + 人工润色</strong>” 的混合工作流程：</p><ul><li>第一步：使用 GPT-4o 自动生成每个问题的初步任务分解（主任务/子任务）和关键词提取（对象/实现）；</li><li>第二步：三位专家标注员进行三轮交叉验证和修订确保标注质量。</li></ul><h3>小结</h3><p>论文通过引入 <strong>DeKeyNLU 数据集</strong> 和 <strong>DeKeySQL 框架</strong>，证明了 <strong>针对性的任务分解和关键词提取训练能够有效提升 NL2SQL 的性能。</strong></p><p>实验结果表明，利用 DeKeyNLU 对 “用户问题理解” 模块进行微调后，模型在 BIRD 开发集上的准确率从 62.31% 提升至 69.10%，在 Spider 开发集上的准确率从 84.2% 提升至 88.7%。</p><p>在 NL2SQL 流程中，实体检索被认为是影响整体准确率的最关键环节，其次是用户问题理解和修正机制。这些发现凸显了以数据集为中心的方法和精心设计的流程对于提升 NL2SQL 系统能力的重要价值，并为用户实现直观、准确的数据交互铺平了道路。</p>]]></description></item><item>    <title><![CDATA[我把大模型装进了电脑里：Ollama 本地部署全攻略 程序员小崔日记 ]]></title>    <link>https://segmentfault.com/a/1190000047607635</link>    <guid>https://segmentfault.com/a/1190000047607635</guid>    <pubDate>2026-02-12 16:08:49</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>本地大模型神器来了！Ollama 一键部署 30B 模型实战指南</h2><hr/><h3>一、认识这只"羊驼"</h3><p>如果你最近在研究本地大模型，那你一定绕不开它。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047607637" alt="" title=""/></p><p>它叫 <strong>Ollama</strong>。</p><p>官网地址：\<br/><a href="https://link.segmentfault.com/?enc=WB9UYYkvxDztgn%2FUzt5aEQ%3D%3D.IlXYgBhFuFicAXQrZOr21tBmAV9LmipXmZqQbjNzbVc%3D" rel="nofollow" target="_blank">https://ollama.com</a></p><p>一句话总结：</p><blockquote><strong>Ollama = 本地大模型运行与管理工具</strong></blockquote><p>它的核心目标非常简单：</p><p>让你在自己的电脑上，像用 Docker 一样管理和运行大语言模型。</p><hr/><h3>二、为什么 Ollama 这么受欢迎？</h3><p>以前部署大模型通常有三种方式：</p><ul><li>调用 API（长期成本高）</li><li>自己编译部署（流程复杂）</li><li>各种依赖冲突（容易踩坑）</li></ul><p>Ollama 做了一件非常关键的事情：</p><blockquote>把复杂的模型部署，变成一行命令。</blockquote><p>例如：</p><pre><code class="bash">ollama run qwen3:8b</code></pre><p>自动下载\<br/>自动加载\<br/>直接进入对话</p><p>对开发者来说，体验非常流畅。</p><hr/><h3>三、安装与使用</h3><h4>1. 下载安装</h4><p>访问官网下载安装即可。</p><p>支持系统：</p><ul><li>Windows</li><li>macOS</li><li>Linux</li></ul><p>安装完成后即可开始运行模型。</p><hr/><h4>2. 第一次下载模型的注意事项</h4><p>首次运行模型时会自动下载。</p><p>强烈建议：</p><blockquote>在设置中将模型下载目录改到 D 盘或其他大容量磁盘。</blockquote><p>原因：</p><ul><li><code>qwen3:30b</code> 等模型体积较大</li><li>下载后可能占用十几 G 甚至几十 G 空间</li><li>默认路径在 C 盘容易导致磁盘爆满</li></ul><p>提前规划好存储路径非常重要。</p><hr/><h3>四、模型区别与推荐</h3><h4>1. GPT-OSS 系列</h4><p>包含：</p><ul><li>gpt-oss:120b</li><li>gpt-oss:20b</li></ul><p>特点：</p><ul><li>通用对话模型</li><li>适合写作、问答、知识整理</li></ul><p>推荐建议：</p><ul><li>16GB 内存以下建议选择 20b</li><li>高性能设备可以尝试 120b</li></ul><hr/><h4>2. DeepSeek 系列</h4><p>包含：</p><ul><li>deepseek-v3.1:671b-cloud</li><li>deepseek-r1:8b</li></ul><p>特点：</p><ul><li>推理能力较强</li><li>数学与逻辑能力表现不错</li></ul><p>说明：</p><ul><li>671b 为云端模型</li><li>本地可选择 r1:8b 体验推理能力</li></ul><p>适合对逻辑思考要求较高的场景。</p><hr/><h4>3. Qwen3 系列（当前主流推荐）</h4><p>包含：</p><ul><li>qwen3:4b / 8b / 30b</li><li>qwen3-coder:30b / 480b-cloud</li><li>qwen3-vl:4b / 8b / 30b / 235b-cloud</li></ul><h5>（1）qwen3 ------ 通用模型</h5><p>适合：</p><ul><li>日常聊天</li><li>写文章</li><li>知识问答</li><li>代码辅助</li></ul><p>推荐配置参考：</p><ul><li>8GB 内存 → 4b</li><li>16GB 内存 → 8b</li><li>32GB 内存以上 → 30b</li></ul><hr/><h5>（2）qwen3-coder ------ 专业代码模型</h5><p>专为程序员优化：</p><ul><li>代码生成</li><li>代码补全</li><li>Bug 修复</li><li>项目结构生成</li></ul><p>推荐：</p><ul><li>本地优先选择 30b</li><li>480b 为云端版本</li></ul><p>如果你是开发者，这个系列非常值得长期使用。</p><hr/><h5>（3）qwen3-vl ------ 视觉语言模型</h5><p>VL = Vision + Language</p><p>可以实现：</p><ul><li>图片识别</li><li>图文问答</li><li>图片分析</li></ul><p>推荐：</p><ul><li>8b 起步</li><li>追求更好效果可选择 30b</li></ul><hr/><h4>4. Gemma3 系列（Google 系）</h4><p>包含：</p><ul><li>gemma3:1b / 4b / 12b / 27b</li></ul><p>特点：</p><ul><li>体积小</li><li>运行速度快</li><li>资源占用较低</li></ul><p>适合：</p><ul><li>轻量电脑</li><li>老设备</li><li>快速测试</li></ul><p>推荐：</p><ul><li>4b 或 12b 更均衡</li></ul><hr/><h3>五、如果只推荐三个模型</h3><p>综合考虑性能与实用性，建议优先尝试：</p><ul><li>日常聊天：qwen3:8b</li><li>写代码：qwen3-coder:30b</li><li>轻量体验：gemma3:4b</li></ul><p>如果你的机器配置较高：</p><blockquote>可以直接尝试 qwen3:30b。</blockquote><hr/><h3>六、一个必须说明的事实</h3><p>蒸馏模型并不是满血模型。</p><p>参数规模不等于能力等同于顶级闭源模型。</p><p>实际表现取决于：</p><ul><li>CPU / GPU 性能</li><li>显存大小</li><li>内存容量</li><li>是否开启量化</li></ul><p>同一个模型，在不同设备上的表现差距可能非常明显。</p><p>因此建议多尝试不同模型，找到最适合自己机器的版本。</p><hr/><h3>七、本地部署真正的意义</h3><p>本地运行大模型，并不是为了与顶级闭源模型直接竞争。</p><p>它的真正价值在于：</p><ul><li>数据隐私</li><li>零 API 成本</li><li>企业内网部署</li><li>本地知识库整合</li><li>可深度定制</li></ul><p>对于开发者而言，这是可控、可扩展的能力。</p><hr/><h3>结语</h3><p>当你第一次在本地成功运行一个 30B 模型时，那种掌控感非常真实。</p><p>Ollama 的出现，让本地大模型真正进入"普通开发者可用"阶段。</p><p>如果你正在探索 AI 工具链，本地部署值得认真体验一次。</p><hr/><p><strong>作者：程序员小崔日记</strong></p><p>本文由<a href="https://link.segmentfault.com/?enc=pW58eKHO8eOIwvWpTmbzAA%3D%3D.eQovV5FjCz%2FFu%2F5ja5Cej84zHiUThHenNFotzu5Opyw%3D" rel="nofollow" target="_blank">mdnice</a>多平台发布</p>]]></description></item><item>    <title><![CDATA[只有243多行的AI训练代码，中文注释版 CRStudio ]]></title>    <link>https://segmentfault.com/a/1190000047607639</link>    <guid>https://segmentfault.com/a/1190000047607639</guid>    <pubDate>2026-02-12 16:07:49</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>Andrej Karpathy刚发布了一个仅用约 250 行纯 Python 代码就实现了 GPT 训练和推理全过程的演示，非常适合用来理解大型语言模型底层的数学原理。</p><blockquote><p>Andrej Karpathy：“新的艺术项目。<br/>用243行纯粹的、无依赖的Python代码实现GPT的训练与推理。这包含了所需内容的完整算法部分，其余的一切都只是为了提升效率。我已无法再进一步简化。</p><p>其工作原理是将完整的LLM架构和损失函数彻底分解为构成它的最基本数学运算（+、<em>、</em>*、log、exp），然后通过一个微小的标量自动求导引擎（micrograd）来计算梯度，优化器使用Adam。<br/>”</p></blockquote><p><img width="690" height="553" referrerpolicy="no-referrer" src="/img/bVdnU4F" alt="image.png" title="image.png"/></p><p>源文件在这里：<a href="https://gist.github.com/karpathy/8627fe009c40f57531cb18360106ce95" target="_blank">https://gist.github.com/karpathy/8627fe009c40f57531cb18360106ce95</a></p><h4>我用AI添加了注释并手动整理了一下：</h4><pre><code class="python"># 导入所需依赖库
import torch # PyTorch核心库，用于张量计算和神经网络构建
import torch.nn as nn # PyTorch的神经网络模块，包含层、损失函数等
from torch.nn import functional as F # PyTorch的优化器模块，用于模型参数更新
import torch.optim as optim # GPT2的分词器，用于文本的编码和解码
from transformers import GPT2Tokenizer # 从huggingface/transformers导入GPT2分词器，适配英文文本

# 定义全局超参数，控制模型训练和结构
batch_size = 16 # 每次训练的样本数，小批量梯度下降用
block_size = 32 # 上下文窗口大小，模型能看到的最大文本长度
max_iters = 5000 # 训练的最大迭代次数
eval_interval = 100 # 每多少轮迭代评估一次模型性能
learning_rate = 1e-3 # 优化器的学习率，控制参数更新步长
device = 'cuda' if torch.cuda.is_available() else 'cpu' # 模型运行的设备，优先使用GPU(cuda)，无则用CPU
eval_iters = 200 # 每次评估时的迭代次数，取平均减少波动
n_embd = 64 # 嵌入层的维度，模型中隐藏层的特征维度
n_head = 4 # 注意力头的数量，实现多头自注意力
n_layer = 4 # Transformer解码器的层数

# 固定随机种子，保证实验结果可复现
torch.manual_seed(1337)

# 加载GPT2分词器，设置为不使用填充（padding）和未知词（unk）的特殊处理
# GPT2分词器基于BPE(字节对编码)，适配英文自然语言，词表大小约50k
tokenizer = GPT2Tokenizer.from_pretrained('gpt2')
# 禁用填充token，因为本微型GPT不做批量填充对齐
tokenizer.pad_token = None
# 禁用未知token，遇到未登录词时直接拆分为子词
tokenizer.unk_token = None

# 加载训练数据：这里使用经典的莎士比亚文本作为训练语料
# 从github拉取原始文本文件，读取为字符串格式
with open('https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt', 'r', encoding='utf-8') as f:
    text = f.read()

# 对原始文本进行分词编码，将字符串转换为模型可处理的整数张量
# return_tensors='pt'：返回PyTorch张量；truncation=True：超长文本截断
# max_length=None：不限制单条文本长度，后续按block_size切分
encoded_text = tokenizer(text, return_tensors='pt', truncation=True, max_length=None)
# 提取编码后的输入id，展平为一维张量（shape: [总词数]）
data = encoded_text.input_ids.flatten()

# 划分训练集和验证集：90%数据用于训练，10%用于验证
n = int(0.9 * len(data))
train_data = data[:n]
val_data = data[n:]

# 数据加载函数：随机生成一批训练/验证样本
# split：指定数据集（'train'/'val'），控制加载训练集还是验证集
def get_batch(split):
    # 根据split选择对应的数据集
    data = train_data if split == 'train' else val_data
    # 随机生成batch_size个起始索引，范围：[0, 数据长度-block_size)，保证能取到连续的block_size个词
    ix = torch.randint(len(data) - block_size, (batch_size,))
    # 构造输入张量x：取每个起始索引后连续的block_size个词，shape: [batch_size, block_size]
    x = torch.stack([data[i:i+block_size] for i in ix])
    # 构造目标张量y：取每个起始索引后偏移1的block_size个词（语言模型的预测目标是下一个词），shape: [batch_size, block_size]
    y = torch.stack([data[i+1:i+block_size+1] for i in ix])
    # 将张量移到指定设备（GPU/CPU）
    x, y = x.to(device), y.to(device)
    return x, y

# 定义评估函数：计算模型在训练/验证集上的平均损失（无梯度计算，提升效率）
# model：待评估的模型实例
@torch.no_grad()  # 装饰器，禁用梯度计算，减少内存占用
def estimate_loss(model):
    # 初始化损失字典，存储训练集和验证集的损失
    out = {}
    # 将模型设为评估模式，关闭Dropout等训练特有的层
    model.eval()
    # 遍历训练集和验证集
    for split in ['train', 'val']:
        # 初始化损失数组，存储每次迭代的损失
        losses = torch.zeros(eval_iters)
        # 循环eval_iters次，计算平均损失
        for k in range(eval_iters):
            # 获取一批样本
            X, Y = get_batch(split)
            # 前向传播，得到模型输出和损失
            logits, loss = model(X, Y)
            # 记录当前迭代的损失
            losses[k] = loss.item()
        # 计算该数据集的平均损失，存入字典
        out[split] = losses.mean()
    # 将模型恢复为训练模式，开启Dropout等层
    model.train()
    return out

# 定义单头自注意力层：实现自注意力的核心逻辑（缩放点积注意力）
class Head(nn.Module):
    def __init__(self, head_size):
        super().__init__()
        # 定义查询（q）、键（k）、值（v）的线性投影层，将n_embd维映射到head_size维
        self.key = nn.Linear(n_embd, head_size, bias=False)
        self.query = nn.Linear(n_embd, head_size, bias=False)
        self.value = nn.Linear(n_embd, head_size, bias=False)
        # 注册三角掩码张量，用于遮蔽未来的词（自回归语言模型，不能看到未来信息）
        # tril：下三角矩阵，upper三角部分填充为-∞，后续softmax后为0
        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))
        # 定义Dropout层，防止过拟合，随机失活20%的神经元
        self.dropout = nn.Dropout(0.2)

    def forward(self, x):
        # x：输入张量，shape: [batch_size, block_size, n_embd]
        B, T, C = x.shape
        # 线性投影得到q、k、v，shape均为[batch_size, block_size, head_size]
        k = self.key(x)
        q = self.query(x)
        v = self.value(x)

        # 计算注意力权重：q @ k.T / sqrt(head_size)（缩放点积）
        # wei shape: [batch_size, block_size, block_size]
        wei = q @ k.transpose(-2, -1) * C**-0.5
        # 应用掩码：将上三角部分设为-∞，遮蔽未来的词
        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))
        # softmax归一化，得到注意力权重（每行和为1）
        wei = F.softmax(wei, dim=-1)
        # 应用Dropout，随机失活部分注意力权重
        wei = self.dropout(wei)
        # 注意力加权求和：权重 @ v，得到输出，shape: [batch_size, block_size, head_size]
        out = wei @ v
        return out

# 定义多头自注意力层：将多个单头注意力的输出拼接，实现多维度的特征提取
class MultiHeadAttention(nn.Module):
    def __init__(self, num_heads, head_size):
        super().__init__()
        # 创建num_heads个单头注意力层，存入nn.ModuleList（可被PyTorch识别的层列表）
        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])
        # 线性投影层，将拼接后的特征映射回n_embd维
        self.proj = nn.Linear(head_size * num_heads, n_embd)
        # Dropout层，防止过拟合
        self.dropout = nn.Dropout(0.2)

    def forward(self, x):
        # 拼接所有单头注意力的输出，dim=-1表示在最后一维拼接
        # 输出shape: [batch_size, block_size, head_size*num_heads]
        out = torch.cat([h(x) for h in self.heads], dim=-1)
        # 线性投影+Dropout，完成多头注意力的输出变换
        out = self.dropout(self.proj(out))
        return out

# 定义前馈网络层：Transformer解码器中的全连接层，实现特征的非线性变换
class FeedFoward(nn.Module):
    def __init__(self, n_embd):
        super().__init__()
        # 两层线性层+ReLU激活+Dropout，隐藏层维度设为n_embd*4（Transformer原论文设定）
        self.net = nn.Sequential(
            nn.Linear(n_embd, 4 * n_embd),  # 升维
            nn.ReLU(),  # 非线性激活
            nn.Linear(4 * n_embd, n_embd),  # 降维回原维度
            nn.Dropout(0.2),  # 随机失活，防止过拟合
        )

    def forward(self, x):
        # 前向传播，输入输出shape均为[batch_size, block_size, n_embd]
        return self.net(x)

# 定义Transformer解码器块：由「多头自注意力 + 前馈网络」组成，带残差连接和层归一化
class Block(nn.Module):
    def __init__(self, n_embd, n_head):
        super().__init__()
        # 计算每个注意力头的维度：总嵌入维 / 头数
        head_size = n_embd // n_head
        # 多头自注意力层
        self.sa = MultiHeadAttention(n_head, head_size)
        # 前馈网络层
        self.ffwd = FeedFoward(n_embd)
        # 层归一化层（Pre-LN架构，Transformer原论文是Post-LN，Pre-LN更易训练）
        self.ln1 = nn.LayerNorm(n_embd)
        self.ln2 = nn.LayerNorm(n_embd)

    def forward(self, x):
        # 残差连接 + 层归一化 + 多头自注意力：x = x + sa(ln1(x))
        # 残差连接缓解深度网络的梯度消失问题
        x = x + self.sa(self.ln1(x))
        # 残差连接 + 层归一化 + 前馈网络：x = x + ffwd(ln2(x))
        x = x + self.ffwd(self.ln2(x))
        return x

# 定义微型GPT模型核心类，继承自nn.Module（PyTorch所有网络的基类）
class GPTLanguageModel(nn.Module):
    def __init__(self, vocab_size):
        super().__init__()
        # 词嵌入层：将词的整数ID映射为n_embd维的向量，vocab_size为词表大小
        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)
        # 位置嵌入层：将位置索引映射为n_embd维的向量，捕捉文本的位置信息
        # 因为Transformer是并行计算，无内置位置信息，需手动加入
        self.position_embedding_table = nn.Embedding(block_size, n_embd)
        # Transformer解码器块序列：n_layer个Block堆叠
        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])
        # 最后的层归一化层
        self.ln_f = nn.LayerNorm(n_embd)
        # 输出线性层：将n_embd维的特征映射回词表大小，用于预测下一个词的概率
        self.lm_head = nn.Linear(n_embd, vocab_size)

        # 初始化模型参数：使用自定义的初始化方式，提升训练稳定性
        self.apply(self._init_weights)

    # 模型参数初始化函数
    def _init_weights(self, module):
        # 如果是线性层，初始化权重为正态分布（均值0，标准差0.02），偏置为0
        if isinstance(module, nn.Linear):
            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)
            if module.bias is not None:
                torch.nn.init.zeros_(module.bias)
        # 如果是嵌入层，初始化权重为正态分布（均值0，标准差0.02）
        elif isinstance(module, nn.Embedding):
            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)

    # 模型前向传播函数：输入x（词ID），y（目标词ID，可选），返回预测logits和损失
    def forward(self, idx, targets=None):
        # idx shape: [batch_size, block_size]
        # targets shape: [batch_size, block_size]
        B, T = idx.shape

        # 词嵌入 + 位置嵌入，shape均为[batch_size, block_size, n_embd]
        tok_emb = self.token_embedding_table(idx)
        pos_emb = self.position_embedding_table(torch.arange(T, device=device))
        # 嵌入层输出：词嵌入+位置嵌入，捕捉词的语义和位置信息
        x = tok_emb + pos_emb

        # 经过Transformer解码器块序列，输出shape不变：[batch_size, block_size, n_embd]
        x = self.blocks(x)
        # 最后的层归一化
        x = self.ln_f(x)
        # 输出线性层，得到logits（未归一化的概率），shape: [batch_size, block_size, vocab_size]
        logits = self.lm_head(x)

        # 如果没有目标值，仅返回logits（用于生成文本）
        if targets is None:
            loss = None
        else:
            # 重塑logits和targets，适配交叉熵损失的输入格式
            # cross_entropy要求输入为[B*T, vocab_size]，目标为[B*T]
            B, T, C = logits.shape
            logits = logits.view(B*T, C)
            targets = targets.view(B*T)
            # 计算交叉熵损失（语言模型的核心损失，预测下一个词的概率）
            loss = F.cross_entropy(logits, targets)

        return logits, loss

    # 文本生成函数：基于当前输入idx，生成后续max_new_tokens个词
    # 自回归生成：每次预测一个词，拼接到输入后，继续预测下一个
    def generate(self, idx, max_new_tokens):
        # idx: 初始输入张量，shape: [batch_size, block_size]
        for _ in range(max_new_tokens):
            # 截取最后block_size个词，保证输入长度不超过模型的上下文窗口
            idx_cond = idx[:, -block_size:]
            # 前向传播，得到logits（无目标值，loss=None）
            logits, loss = self(idx_cond)
            # 取最后一个时间步的logits（预测下一个词的logits），shape: [batch_size, vocab_size]
            logits = logits[:, -1, :]
            # softmax归一化，得到下一个词的概率分布
            probs = F.softmax(logits, dim=-1)
            # 根据概率分布随机采样一个词ID（也可以用argmax取最可能的词，即贪心生成）
            idx_next = torch.multinomial(probs, num_samples=1)
            # 将采样的词ID拼接到输入后，更新输入张量
            idx = torch.cat((idx, idx_next), dim=1)
        # 返回生成后的完整词ID张量
        return idx

# 主程序入口：实例化模型、优化器，开始训练和生成
if __name__ == "__main__":
    # 获取GPT2分词器的词表大小，作为模型的vocab_size
    vocab_size = tokenizer.vocab_size
    # 实例化微型GPT模型，移到指定设备
    model = GPTLanguageModel(vocab_size).to(device)
    # 打印模型参数量，查看模型规模
    print(f"Model parameters: {sum(p.numel() for p in model.parameters())/1e6:.2f}M")

    # 定义优化器：使用AdamW（Adam的改进版，带权重衰减，防止过拟合）
    optimizer = optim.AdamW(model.parameters(), lr=learning_rate)

    # 训练循环：迭代max_iters次
    for iter in range(max_iters):
        # 每隔eval_interval次迭代，评估模型损失并打印
        if iter % eval_interval == 0:
            losses = estimate_loss(model)
            print(f"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}")

        # 获取一批训练样本
        xb, yb = get_batch('train')
        # 前向传播，得到logits和损失
        logits, loss = model(xb, yb)
        # 梯度清零：PyTorch梯度会累加，每次迭代前需清零
        optimizer.zero_grad(set_to_none=True)
        # 反向传播：计算损失对模型参数的梯度
        loss.backward()
        # 优化器步骤：更新模型参数
        optimizer.step()

    # 训练完成后，进行文本生成
    # 初始化输入：&lt;|endoftext|&gt;是GPT2的特殊起始token，编码为张量并移到设备
    # shape: [1, 1]（batch_size=1, block_size=1）
    start_idx = tokenizer.encode("&lt;|endoftext|&gt;", return_tensors='pt').to(device)
    # 生成max_new_tokens=500个词
    generated_ids = model.generate(start_idx, max_new_tokens=500)
    # 将生成的词ID解码为字符串，跳过特殊token
    generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)
    # 打印生成的文本
    print("\nGenerated text:\n")
    print(generated_text)</code></pre>]]></description></item><item>    <title><![CDATA[【划重点】HarmonyOS 应用市场审核 3.5 驳回“十大高频问题”全解析 鸿蒙百晓生 ]]></title>    <link>https://segmentfault.com/a/1190000047607645</link>    <guid>https://segmentfault.com/a/1190000047607645</guid>    <pubDate>2026-02-12 16:07:06</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在 HarmonyOS 生态蓬勃发展的今天，应用上架是开发者面临的关键一环。不少作品因触碰 3.5 条款（应用价值与独特性） 被拒，常见的困惑包括：为何被判“功能单一”或“缺乏实质服务”？<br/>本专题复盘近期审核数据，深度解析 3.5 条款 Top 10 驳回问题，为您提供：</p><ul><li>问题预警： 详解高频被拒问题，提前预警</li><li>调优路径： 给出应用从纯展示向强交互的实操路径</li><li>通关范本： 参考标杆案例，让优化有据可依<br/>读懂 3.5，上架更有数。优化应用实用性，助您的作品顺利开启鸿蒙之旅。</li></ul><p><strong>问题1：不收录应用功能与手机系统自带的功能重复，缺乏独特价值。如简易计算器、桌面时钟、加密备忘录、天气、手电筒、指南针、镜子、日历、计时类等。</strong></p><p><strong>【改进建议】</strong><br/>明确应用的独特价值，确保其核心功能与系统功能非完全重叠，强化在垂直领域的专业能力；交互设计与用户体验优化，通过清晰的界面布局与突出的重点功能，降低用户认知与操作成本，确保其价值能被用户快速感知和顺畅使用。</p><p><strong>【驳回示例】</strong><br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdnUVi" alt="image.png" title="image.png"/></p><p><strong>【优化后成功上架案例】</strong><br/>优化前：与系统备忘录功能相似，只能简单记录。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdnUVk" alt="image.png" title="image.png" loading="lazy"/><br/>优化后：丰富应用核心功能，优化首页打卡统计展示，及新增“膳食食材、养生知识”等养生内容及“组队打卡、隔空传送”等趣味内容。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdnUVl" alt="image.png" title="image.png" loading="lazy"/></p><p><strong>问题2：应用为有限的信息内容罗列不收录，如信息介绍，生活指南、法律案例展示、书籍推荐、诗词罗列等。</strong><br/><strong>【改进建议】</strong><br/>聚焦应用核心功能，避免信息的简单堆砌与罗列，需打造差异化内容，增强交互设计与闭环体验，提升用户使用体验。<br/><strong>【驳回示例】</strong><br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdnUVm" alt="image.png" title="image.png" loading="lazy"/></p><p><strong>【优化后成功上架案例】</strong><br/>优化前：仅少量菜谱信息罗列，UX设计略显欠缺。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdnUVn" alt="image.png" title="image.png" loading="lazy"/></p><p>优化后：丰富应用核心功能，新增“做饭计划、上传菜谱、菜篮子”等模块，满足多种用户使用场景，优化整体界面设计展示，凸显菜品，使应用具有实用性的同时更加美观。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdnUVp" alt="image.png" title="image.png" loading="lazy"/></p><p><strong>问题3：单一界面的恶作剧恶搞类应用不收录，如屏幕破裂、屏幕鬼魂、模拟打嗝等。</strong><br/><strong>【改进建议】</strong><br/>通过整合多种恶作剧类型，增强应用场景适配性与趣味性。结合创意互动与交互创新，在丰富功能的同时保持界面简洁，提升娱乐性。<br/><strong>【驳回示例】</strong><br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdnUVq" alt="image.png" title="image.png" loading="lazy"/></p><p><strong>问题4：单一H5/Web页面应用不收录，如一张图片，一首音乐、一本书、一个主题、单一影视剧集类、单一非官方游戏攻略类等。</strong><br/><strong>【改进建议】</strong><br/>聚焦应用核心功能，构建复合型功能体系，避免功能单一化；深化内容价值，丰富交互场景与功能闭环，持续提升用户体验。<br/><strong>【驳回示例】</strong><br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdnUVr" alt="image.png" title="image.png" loading="lazy"/></p><p><strong>问题5：不收录企业黄页类应用，仅展示文字信息、图片介绍，不提供用户服务。</strong><br/><strong>【改进建议】</strong><br/>强化功能深度，增加功能实用性，提供实际可使用有价值的功能，不能仅企业文字信息、图片介绍，未提供实际的用户服务。<br/><strong>【驳回示例】</strong><br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdnUVI" alt="image.png" title="image.png" loading="lazy"/></p><p><strong>问题6：不收录应用内容均为各种广告推广。</strong><br/><strong>【改进建议】</strong><br/>删除广告推广内容<br/><strong>【驳回示例】</strong><br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdnUVU" alt="image.png" title="image.png" loading="lazy"/></p><p><strong>问题7：不收录应用页面仅提供简单的预约功能，但未对预约内容进行详细说明，未体现功能的实质价值，未给到用户清晰、准确的服务预期。</strong><br/><strong>【改进建议】</strong><br/>优化功能设计，确保功能闭环完整，消除使用断点，提供清晰明确的功能内容。<br/><strong>【驳回示例】</strong><br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdnUVV" alt="image.png" title="image.png" loading="lazy"/></p><p><strong>问题8：不收录应用无实质功能，仅记录想对自己说的话。</strong><br/><strong>【改进建议】</strong><br/>围绕核心功能深化与拓展实用场景，突出差异化设计理念，强化技术业务协同能力，优化数据存储机制，提升操作便捷性与界面友好度，打造流畅舒适的用户体验。<br/><strong>【驳回示例】</strong><br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdnUVW" alt="image.png" title="image.png" loading="lazy"/></p><p><strong>问题9：不收录应用无实质功能和真实用户使用场景，如纯虚构内容。</strong><br/><strong>【改进建议】</strong><br/>围绕真实用户的实际使用场景进行功能规划与设计，提供满足实际使用需求的可用功能；深度优化应用的核心使用场景体验，打磨并升级用户界面的设计质感与交互流畅度。<br/><strong>【驳回示例】</strong><br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdnUVX" alt="image.png" title="image.png" loading="lazy"/></p><p><strong>问题10：不收录资讯类应用内容老旧、过时，最新资讯模块展示过时的新闻报道。</strong><br/><strong>【改进建议】</strong><br/>建立资讯内容定期更新机制，定期对资讯内容进行动态更新与优化，确保信息时效性，保持内容新鲜度与吸引力，避免陈旧内容影响用户体验。<br/><strong>【驳回示例】</strong><br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdnUV0" alt="image.png" title="image.png" loading="lazy"/></p><p>➡️ <a href="https://link.segmentfault.com/?enc=PCPVXYhvZhx3xqG2LS05%2Bg%3D%3D.FdWwQ0am8T22aSsdcOICRTF20ZJi1ahPSsgXPPH9new5CLCyfyjCFlU8hwx6EKVSiXcym5pVPajTBpwm39JxVodg1qa6l7V7Cqdi6iNeNI5P3rIUfLoSKvMaRFsLC2k%2FzMCKa9aeBEuqz258YIM0sA%3D%3D" rel="nofollow" target="_blank">原贴指路</a></p>]]></description></item><item>    <title><![CDATA[sizeof与strlen BlackQid ]]></title>    <link>https://segmentfault.com/a/1190000047607650</link>    <guid>https://segmentfault.com/a/1190000047607650</guid>    <pubDate>2026-02-12 16:06:18</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><code>sizeof</code>计算变量所占内存空间大小，单位是字节，如果操作数是类型，计算的是使用类型创建的变量所占内存空间的大小。<code>sizeof</code>只关注占用内存空间的大小，不在乎内存中存放什么数据。</p><p><code>strlen</code>是C语言库函数，功能是求字符串长度。函数原型如下：</p><pre><code class="c">size_t strlen ( const char * str );</code></pre><p>统计的是从<code>strlen</code>函数的参数<code>str</code>中这个地址开始向后，<code>\0</code>之前字符串中字符的个数。<code>strlen</code>函数会一直向后找<code>\0</code>字符，直到找到为止，所以可能存在越界查找。 <code>strlen</code>关注到了字符串中具体的内容。</p><table><thead><tr><th>sizeof</th><th>strlen</th></tr></thead><tbody><tr><td>1. 是操作符 &lt;br/&gt;2. 计算操作数所占内存的大小，单位是字节&lt;br/&gt;3. 不关注内存中存放什么数据</td><td>1. 是库函数，使用需要包含头文件string.h&lt;br/&gt;2. 是求字符串长度的，统计的是\0之前字符的个数&lt;br/&gt;3. 关注内存中是否有\0，如果没有\0，就会持续往后找，可能会越界</td></tr></tbody></table><p>数组名的意义：</p><ol><li><code>sizeof(数组名)</code>，这里的数组名表示整个数组，计算的是整个数组的大小。</li><li><code>&amp;数组名</code>，这里的数组名表示整个数组，取出的是整个数组的地址。</li><li>除此之外所有的数组名都表示首元素的地址。（二维数组的首元素是一个一维数组）</li></ol><hr/><p>小试牛刀：</p><pre><code class="c">#define _CRT_SECURE_NO_WARNINGS 1
#include &lt;stdio.h&gt;
int main()
{
    char* c[] = { "ENTER","NEW","POINT","FIRST" };
    char** cp[] = { c + 3,c + 2,c + 1,c };
    char*** cpp = cp;
    printf("%s\n", **++cpp);
    printf("%s\n", *--*++cpp+3);
    printf("%s\n", *cpp[-2]+3);
    printf("%s\n", cpp[-1][-1]+1);
    return 0;
}</code></pre>]]></description></item><item>    <title><![CDATA[无需修改内核即可为 PostgreSQL 数据库对象添加自定义属性 IvorySQL ]]></title>    <link>https://segmentfault.com/a/1190000047607656</link>    <guid>https://segmentfault.com/a/1190000047607656</guid>    <pubDate>2026-02-12 16:05:36</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在开发实践中，经常会遇到一个问题：如何在不修改 PostgreSQL 内核代码的前提下，为数据库对象附加自定义元数据。本文展示了一种基于 PostgreSQL SECURITY LABELS 机制的可行方案，用于实现自定义属性。这种方式具备事务性、与数据库对象强关联，并且能够与标准 PostgreSQL 操作良好协同。</p><h2>问题背景：复制冲突的管理</h2><p>在一个典型的两主节点向第三节点复制数据的架构中，UPDATE/UPDATE 冲突较为常见。复制冲突的处理本身较为复杂，且在多数场景下并无通用解法，但某些列类型可以采用更简单的处理思路。</p><p>例如，在银行业务场景中，账户余额字段通常只允许增减操作。此时可以采用基于增量（delta）的方式：不在冲突时选择某个绝对值，而是分别计算两次更新的变化量并进行叠加。该方法仅需进行基础校验（如溢出检查、余额不小于 0），即可确保所有更新均被正确计入。</p><p>难点在于：如果 PostgreSQL 本身不支持此类机制，如何标记特定列以启用基于 delta 的冲突解决策略？理想状态下，可以直接通过类似以下语法完成：</p><pre><code>ALTER TABLE accounts ALTER COLUMN balance SET delta_apply = 'true';</code></pre><p>但这种深度集成 SQL 语法的方式实现难度较高，且对可移植性意义有限。更现实的需求是通过扩展接口完成设置，例如：</p><pre><code>SELECT my_extension.set_delta_apply('accounts', 'balance', true);</code></pre><p>社区中曾多次讨论为数据库对象引入自定义属性的提案，也曾提交过内核补丁，但实现代码规模较大，而应用场景相对有限，合入内核的可行性存疑。此外，有时需要为索引、大对象或数据类型等非表对象附加属性，这进一步增加了复杂度。更重要的是，即便补丁被接受，也只能影响未来版本，而现实需求往往是“当下可用”。</p><h2>功能需求</h2><p>实现该功能前需明确相关需求：</p><ul><li><strong>对象生命周期绑定</strong>：属性必须与数据库对象建立内部依赖关系。例如，在执行 <code>DROP … CASCADE</code> 删除父对象时，属性也应随之自动删除。</li><li><strong>扩展关联性</strong>：属性需要与扩展建立明确关联，以便在扩展被卸载时由数据库系统正确处理。</li><li><strong>事务性行为</strong>：对象属性需满足事务规则与可见性约束，并行事务修改时，新属性值仅在当前事务内可见，提交前回滚则恢复原值。</li><li><strong>升级与迁移支持</strong>：在 <code>pg_upgrade</code> 以及 dump/restore 过程中，属性应随数据库对象一并正确迁移。</li></ul><p>理想情况下可实现类似 PostgreSQL GUC 的会话级特性，但实现难度显著提升。</p><h2>方案评析</h2><p>以对象 OID 为键的简易全局哈希表无法满足需求，属性值可为变长类型（如字符串），对象与属性的关联实现复杂，且无法保障事务特性与 MVCC 机制。</p><p>另一种思路是在扩展中创建一张 &lt;<code>key</code>, <code>value</code>&gt; 表存储属性，由扩展在运行时查询该表。这在理论上可行，但实践中问题较多：涉及升级、dump/restore、复制一致性等一系列复杂问题，同时还需持续校验对象是否存在，并引入额外的查询开销，整体可靠性较差。</p><h2>实现思路</h2><p>具体目标是为任意表的列定义一个 <code>delta_apply</code> 属性，用于逻辑复制场景下的 UPDATE/UPDATE 冲突处理。当该属性启用时，订阅端不采用传统冲突解决策略，而是计算新旧值之间的差量，并将其累加到订阅端当前值中。</p><p>在 PostgreSQL 中，唯一同时满足上述全部需求的机制是 SECURITY LABELS。尽管该机制最初用于安全模块，但并未限制其仅用于安全相关元数据。需要注意以下事项：</p><ul><li>面向安全的工具可能会检查或校验标签内容。</li><li>需要使用独立且唯一的 provider 名称，以避免冲突。</li></ul><p>它是如何工作的？让我们看看这张图：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047607658" alt="extension_side.jpg" title="extension_side.jpg"/></p><p>实现的核心依赖于系统表 pg_seclabel。该表中的记录与数据库对象天然绑定，对其的增删改通过 SECURITY LABEL … 工具命令完成。扩展可以通过 utility hook 监听这一过程。</p><p>SECURITY LABEL 支持多种对象类型，包括视图、函数等，基本覆盖常见需求。每条标签记录包含对象的 OID 及对象类型（表、列、函数等），并通过文本字段存储任意自定义数据，同时通过 provider 字段区分不同模块生成的标签。</p><p>由于每次访问都直接查询 pg_seclabel 成本较高，且目前尚无系统级缓存，引入本地哈希缓存以降低开销：</p><pre><code>typedef struct PropertyCacheEntry {
    Oid classId;
    Oid objectId;
    char *propertyValue;
    bool valid;
} PropertyCacheEntry;
static HTAB *property_cache = NULL;</code></pre><p>通过注册 RelcacheCallback 实现缓存失效管理，对象执行 ALTER TABLE 操作时标记对应缓存条目无效。缓存填充策略可根据使用场景调整。例如，在核心 hook 中访问对象时加载，或在扩展提供的用户接口函数中主动加载。</p><h2>属性增删的实现细节</h2><p>为了保持各后端缓存一致性，每次属性变更都需要向其他进程发送失效通知。对象本身发生变化时，可通过 RelcacheCallback 处理；但属性变更本质上只是对 <code>pg_seclabel</code> 的 DML 操作，如何通知其他后端成为问题。</p><p>PostgreSQL 提供了 <a href="https://link.segmentfault.com/?enc=jpN6mfe%2FqbX98U3AvVuYeA%3D%3D.uxhUdfTNyJrTl9gfcAjGohsUKlVboRdomgKVZ2OyV%2BZx3jZazfayyKJyb0Vq92M2emDJ9MjAmSV8TK6M4sOPapHTl4FBEmvKsG%2FRCn1fIphT%2BlZCmaiIaGKxS%2BfnWEIe0DxGoDQAdYDXm4TuxQm6GQ%3D%3D" rel="nofollow" target="_blank">CacheInvalidateRelcacheByRelid</a>，但仅适用于 <code>pg_class</code> 中的对象，对于数据类型等对象无效。因此，在实际实现中，属性变更时会触发一次对象自身的“无实质变更更新”，以借此触发相应的失效回调，从而刷新扩展内部缓存。</p><p>扩展通过 <code>set_property()</code> 接口向用户暴露能力，用于为指定对象设置 SECURITY LABEL。标签文本中描述属性值，例如 <code>delta_apply: true</code>。在扩展中实现的 <code>seclabel_provider</code> 回调负责校验对象类型及属性合法性。</p><p>标签文本字段具备高度灵活性，允许存储复杂结构，例如以 JSON 形式描述属性逻辑。</p><p>通过该机制，客户端与扩展之间建立了一种相对原生的通信方式。扩展可在运行时判断属性是否存在，并据此调整行为。</p><p>在 <code>delta_apply</code> 的具体实现中，逻辑复制订阅端在处理 UPDATE 记录时，会同时查询对应表的属性缓存。若存在标记为增量属性的列，则计算新旧值差量并累加到订阅端当前值。即便在冲突解决策略（如 last-update-wins）下决定拒绝整条更新，增量列的变更仍会被应用，从而降低冲突概率并确保增量更新不丢失。</p><h2>外部干扰处理</h2><p>pg_seclabel 仍然是系统目录表，具备足够权限的用户（如 DBA）可以直接修改其内容。为降低风险，可在扩展中引入内部 GUC，例如 <code>myextension.call_guard</code>。在扩展 UI 函数执行前将其置为 true，结束后重置为 <code>false</code>，并在关键路径中校验其状态是否符合预期。</p><p>理论上，超级用户仍可能通过手段绕过该限制。虽然可以进一步为该 GUC 设置 hook 进行防护，但实现复杂度显著提高，容易演变为过度设计。</p><h2>总结</h2><p>PostgreSQL SECURITY LABELS 机制提供了一种可靠、事务安全的方式，用于在不修改内核的情况下为数据库对象添加自定义属性。尽管该机制最初面向安全模块，但同样适用于扩展级元数据管理，且具备良好的生命周期管理与 MVCC 支持。</p><p>该方案支持多种对象类型，具备事务一致性，并可正确参与 dump/restore 与升级流程。</p><p>原文链接：</p><p><a href="https://link.segmentfault.com/?enc=8z0pNgTWbVKGk08cYoYSAQ%3D%3D.eXB7s3jpsiRxiXqcmAWKa1ohSV2TJeiEVhP3LAKsleIKw%2Fl1302vZ0SNObLsRBJxARZScIwm5KUBy0ehyQ6nr8wIldChdBvRbR2%2FZTtVg7ha92wIANUbIpazi9E%2Bm32fOZ5QKWejaOJ%2FMgOwwBRasA%3D%3D" rel="nofollow" target="_blank">https://www.pgedge.com/blog/custom-properties-for-postgresql-...</a></p><p>作者：Andrei Lepikhov</p><hr/><h2><a href="https://link.segmentfault.com/?enc=%2BOFpBSEcm9rv1T8AMmVgbg%3D%3D.2KBCHSpNCB1Toqj%2FmB2IPAUZelHFhYK5P1J0K0wPKFs%3D" rel="nofollow" target="_blank">HOW 2026 议题招募中</a></h2><p>2026 年 4 月 27-28 日，由 IvorySQL 社区联合 PGEU（欧洲 PG 社区）、PGAsia（亚洲 PG 社区）共同打造的 HOW 2026（IvorySQL &amp; PostgreSQL 技术峰会） 将再度落地济南。届时，PostgreSQL 联合创始人 Bruce Momjian 等顶级大师将亲临现场。</p><p>自开启征集以来，HOW 2026 筹备组已感受到来自全球 PostgreSQL 爱好者的澎湃热情。为了确保大会议题的深度与广度，我们诚邀您在 2026 年 2 月 27 日截止日期前，提交您的技术见解。</p><p>投递链接：<a href="https://link.segmentfault.com/?enc=ohAI8pG9ezBwcQ2OU%2BRvoQ%3D%3D.5JbJDzO1etB%2BruJdZhPuC74k6zbB3BJUUeyXTUqUR%2Bk%3D" rel="nofollow" target="_blank">https://jsj.top/f/uebqBc</a></p>]]></description></item>  </channel></rss>