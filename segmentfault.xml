<?xml version="1.0" encoding="UTF-8"?><rss version="2.0">  <channel>      <title>SegmentFault - 最近文章</title>      <link>https://segmentfault.com/blogs/newest</link>      <description>SegmentFault 思否</description>      <generator>python segmentfault.py @Pi20</generator>      <item>    <title><![CDATA[MindSpore 自动并行实战：如何零代码修改实现单机到分布式训练的升级 文良_颜丑 ]]></title>    <link>https://segmentfault.com/a/1190000047605576</link>    <guid>https://segmentfault.com/a/1190000047605576</guid>    <pubDate>2026-02-11 16:10:00</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>​当模型参数或数据量过大时，分布式训练​ 成为必然选择。传统方法需要手动切分模型、管理通信，过程复杂且易错。MindSpore 的 自动并行​ 特性能够自动寻找最优的并行策略，极大降低了分布式训练的门槛。</p><h2>1. 问题场景：为何需要自动并行？</h2><p>假设我们有一个简单的全连接网络，当参数量增长到单卡无法容纳时，通常需要：</p><ul><li>数据并行：切分数据，每卡持有完整模型。</li><li>模型并行：切分模型参数，数据在不同卡间流转。</li><li>手动实现这两种并行方式的混合，策略设计非常复杂。MindSpore 的自动并行可以 通过分析计算图、设备拓扑与资源约束，自动为算子分配最佳的并行执行方式。</li></ul><h2>2. 关键步骤：从单机代码到分布式训练</h2><p>以下是一个经典的多层感知机（MLP）示例。你只需要专注于模型定义，并行策略可交由框架自动生成。</p><pre><code class="python">import mindspore as ms
from mindspore import nn, ops

# 定义网络（与单机代码完全一致）
class MLP(nn.Cell):
    def __init__(self):
        super().__init__()
        self.flatten = nn.Flatten()
        self.dense1 = nn.Dense(784, 2048)  # 大参数层
        self.dense2 = nn.Dense(2048, 512)
        self.dense3 = nn.Dense(512, 10)
    
    def construct(self, x):
        x = self.flatten(x)
        x = self.dense1(x)
        x = ops.relu(x)
        x = self.dense2(x)
        x = ops.relu(x)
        return self.dense3(x)

net = MLP()</code></pre><h2>3. 启用自动并行</h2><p>只需在训练脚本中增加几行配置，即可切换到自动并行模式：# 配置并行环境</p><pre><code class="python">ms.set_auto_parallel_context(parallel_mode="auto_parallel",  # 启用自动并行
                             device_num=4,                    # 使用4张设备（如GPU）
                             dataset_strategy="data_parallel") # 数据集自动切分策略

# 后续的损失函数、优化器定义及训练循环与单机代码基本无异
loss_fn = nn.CrossEntropyLoss()
optimizer = nn.SGD(net.trainable_params(), learning_rate=0.01)
# 使用 Model API 封装并训练...</code></pre><h2>4. 核心优势与理解</h2><ul><li>策略自动化：框架会分析计算图中每个算子的计算量、参数大小及依赖关系，自动选择“数据并行”、“模型并行”或“混合并行”策略。</li><li>通信优化：自动插入必要的通信算子（如AllReduce、AllGather），并优化通信与计算的重叠，以提升整体效率。</li><li>对开发者透明：最大程度地保持了单机训练代码的样貌，仅需增加并行上下文配置，真正实现了“零代码修改”的分布式训练升级。</li></ul><p>借助自动并行，开发者可以将精力聚焦于模型结构本身，而将复杂的分布式调度交给 MindSpore。下一步，您可以尝试在更大规模的模型（如Transformer）上体验这一特性，并观察其性能提升。</p>]]></description></item><item>    <title><![CDATA[教程上新｜微信AI团队提出扩散语言模型WeDLM，相较vLLM部署AR模型实现3倍推理加速 Open]]></title>    <link>https://segmentfault.com/a/1190000047605598</link>    <guid>https://segmentfault.com/a/1190000047605598</guid>    <pubDate>2026-02-11 16:08:59</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在规模化部署和商业落地场景中，推理速度的权重日益提升，甚至在许多情况下超过了单纯的模型参数量，成为决定其工程价值的关键因素。尽管自回归（Autoregressive，AR）生成范式凭借稳定性和成熟生态，仍是当前主流解码方式，<strong>但其逐 token 生成的内在机制，使模型在推理阶段几乎无法充分利用并行计算资源。</strong> 这一限制在长文本生成、复杂推理和高并发服务场景中尤为突出，也直接推高了推理延迟与算力成本。</p><p>为突破这一瓶颈，研究界近年来不断探索并行解码路径，<strong>其中扩散语言模型（Diffusion Language Models，DLMs）因其「每步生成多个 token」的特性，被视为最具潜力的替代方案之一。</strong> 然而，理想与现实之间仍存在明显鸿沟：在真实部署环境中，许多 DLLMs 并未展现出预期中的速度优势，甚至在性能上难以超越高度优化的 AR 推理引擎（如 vLLM）。问题并非源于并行本身，而是隐藏在模型结构与系统层面的深层冲突之中——<strong>大量现有扩散方法依赖双向注意力机制，破坏了前缀 KV 缓存这一现代推理系统的效率基石，迫使模型反复重算上下文，抵消了并行带来的潜在收益。</strong></p><p>在此背景下，<strong>腾讯微信 AI 团队提出了 WeDLM（WeChat Diffusion Language Model），</strong> 这是首个在工业级推理引擎（vLLM）优化条件下，推理速度超越同等 AR 模型的扩散语言模型。其核心思想是在保持严格因果掩码的前提下，让每个被掩码位置都能够条件化于当前所有已观测的 token。为此，研究人员引入了一种拓扑重排（Topological Reordering）方法，在不改变 token 逻辑位置的情况下，将已观测 token 移动到物理上的前缀区域。</p><p>实验结果表明，WeDLM 在保持强自回归 backbones 生成质量的同时，实现了显著的推理加速，具体而言，其在数学推理等任务上相较 vLLM 部署的 AR 模型实现了 3 倍以上加速，低熵场景的推理效率提速更是达到 10 倍以上。</p><p>目前，「WeDLM 高效大语言模型解码框架」已上线 OpenBayes 官网的教程版块，点击下方链接即可体验一键部署教程 ⬇️</p><p><strong>教程链接：</strong></p><p><strong><em><a href="https://link.segmentfault.com/?enc=P%2Bra1be%2B5FONp%2FRqD8zxtg%3D%3D.kq75QDaNni0ZnNd5Hi8%2BTXUQmfZUoeivl2hG0oAIsCs%3D" rel="nofollow" target="_blank">https://go.openbayes.com/9ooQJ</a></em></strong></p><p><strong>Demo 运行</strong></p><p><strong>01</strong></p><p><strong>Demo 运行阶段</strong></p><p>1.登录 OpenBayes.com，在「公共教程」页面，选择「WeDLM 高效大语言模型解码框架」教程。</p><p><img width="723" height="535" referrerpolicy="no-referrer" src="/img/bVdnUya" alt="" title=""/><br/>2.页面跳转后，点击右上角「克隆」，将该教程克隆至自己的容器中。</p><p><img width="723" height="537" referrerpolicy="no-referrer" src="/img/bVdnUyb" alt="" title="" loading="lazy"/><br/>3.选择「NVIDIA GeForce RTX 5090」以及「PyTorch」镜像，按照需求选择「按量付费」或「包日/周/月」，点击「继续执行」。新用户使用下方邀请链接注册，即可获得满 ¥10 赠 ¥10 优惠券，更有机会获得 ¥15 赠金！</p><p>小贝总专属邀请链接（直接复制到浏览器打开）：</p><p><strong><em><em><a href="https://link.segmentfault.com/?enc=FVR4J75Bt8JIcP%2FlU%2FhhNQ%3D%3D.pkxIvr%2Fzcel31dZ%2Bpo%2BG1qY%2Fc9EjyS3b9jVMHp7U%2FOjEzMrzVCj5%2FO27oho1KYEX" rel="nofollow" target="_blank">https://go.openbayes.com/9S6D******r</a></em></em></strong></p><p><img width="723" height="569" referrerpolicy="no-referrer" src="/img/bVdnUye" alt="" title="" loading="lazy"/><br/><img width="723" height="566" referrerpolicy="no-referrer" src="/img/bVdnUyf" alt="" title="" loading="lazy"/></p><p>4.等待分配资源，当状态变为「运行中」后，点击「打开工作空间」进入 Jupyter Workspace。</p><p><img width="723" height="569" referrerpolicy="no-referrer" src="/img/bVdnUyg" alt="" title="" loading="lazy"/><br/><strong>02</strong></p><p><strong>效果演示</strong></p><p>页面跳转后，点击左侧 README 页面，进入后点击上方「运行」。</p><p><img width="723" height="566" referrerpolicy="no-referrer" src="/img/bVdnUyh" alt="" title="" loading="lazy"/><br/><img width="723" height="523" referrerpolicy="no-referrer" src="/img/bVdnUyi" alt="" title="" loading="lazy"/></p><p>待运行完成，即可点击右侧 API 地址跳转至 demo 页面。</p><p><img width="723" height="441" referrerpolicy="no-referrer" src="/img/bVdnUyj" alt="" title="" loading="lazy"/><img width="723" height="375" referrerpolicy="no-referrer" src="/img/bVdnUyk" alt="" title="" loading="lazy"/></p><p><strong>教程链接：</strong></p><p><strong><em><a href="https://link.segmentfault.com/?enc=gLpdfiBMa%2BSpv6xayLtzOw%3D%3D.tcePUDFGIPPE7aQmbnheMjUSigLIfpd3iPUs4Xqc3u0%3D" rel="nofollow" target="_blank">https://go.openbayes.com/9ooQJ</a></em></strong></p>]]></description></item><item>    <title><![CDATA[马年新春半价开跑！RTX 5090 低至 ¥1.45/时！ OpenBayes ]]></title>    <link>https://segmentfault.com/a/1190000047605608</link>    <guid>https://segmentfault.com/a/1190000047605608</guid>    <pubDate>2026-02-11 16:08:25</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>策马扬鞭启新岁，乘势而上赴新程。新年将至，你是不是已经开始为这一年立下新的 Flag？</p><ul><li>今年要把拖了很久的项目落地交付！</li><li>今年要完整跑通那个大模型从训练到部署的全流程！</li><li>今年要做出有分量的研究成果，在顶刊上写下自己的名字！</li></ul><p><img width="688" height="425" referrerpolicy="no-referrer" src="/img/bVdnUyv" alt="" title=""/><img width="721" height="570" referrerpolicy="no-referrer" src="/img/bVdnUyw" alt="" title="" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[2026年12款主流CRM全链路横评，企业数字化选型必备参考 率性的开水瓶 ]]></title>    <link>https://segmentfault.com/a/1190000047605614</link>    <guid>https://segmentfault.com/a/1190000047605614</guid>    <pubDate>2026-02-11 16:07:32</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>CRM系统是企业打通线索-客户-商机-订单全销售链路的核心数字化工具，不同品牌的CRM在功能深度、场景适配性、自动化能力上差异显著。本次横评选取12款主流CRM，覆盖<strong>大型企业级、中小微轻量化、垂直场景、营销驱动、跨境社媒</strong>五大类定位，围绕销售全链路7个核心模块展开专业对比，为不同规模、不同行业的企业选型提供参考。</p><h2>一、品牌定位前置分类</h2><table><thead><tr><th>分类</th><th>代表品牌</th><th>核心适用场景</th></tr></thead><tbody><tr><td>大型企业级全域管控</td><td>Oracle CX、Salesforce</td><td>集团化全链路、复杂供应链/CPQ需求</td></tr><tr><td>中大型复杂业务适配</td><td>神州云动CloudCC</td><td>项目型销售（工程/IT服务）、定制化流程</td></tr><tr><td>中小微全链路轻量化</td><td>超兔一体云、Pipedrive、Capsule CRM</td><td>中小微企业低成本快速落地全销售流程</td></tr><tr><td>垂直场景专项解决</td><td>浪潮CRM（快消/医药）、探马SCRM（私域）、励销云（电销获客）</td><td>渠道分销、私域运营、电销获客垂直需求</td></tr><tr><td>营销/社媒驱动型</td><td>Brevo（原Sendinblue）、Nimble</td><td>营销增长、跨境社媒客户运营</td></tr><tr><td>团队协作型</td><td>Bitrix24</td><td>中小团队销售+协作一体化</td></tr></tbody></table><h2>二、核心模块深度横评</h2><h3>1. 线索管理：多渠道获客→录入→分配→跟进</h3><p><strong>核心价值</strong>：实现线索的高效归集、精准分配与快速转化，降低线索流失率。</p><h4>横向对比表格</h4><table><thead><tr><th>品牌</th><th>多渠道获客覆盖</th><th>线索录入方式</th><th>线索分配机制</th><th>线索跟进能力</th></tr></thead><tbody><tr><td>超兔一体云</td><td>百度/巨量引擎、官网表单、微信营销、地推扫码、工商搜客</td><td>手动/批量导入、自动抓取表单</td><td>智能分配（地域/行业/销售负荷）+多端提醒</td><td>一键转客户/订单、手机号/IP归属地、跟进全记录</td></tr><tr><td>神州云动CloudCC</td><td>市场云+营销自动化、搜索引擎引流</td><td>在线捕获、天眼查一键完善工商信息</td><td>自定义条件自动分配/手动分配、查重合并</td><td>系统自动创建跟进任务（20min/3天/7天多端提醒）、跟进记录强制完善</td></tr><tr><td>Oracle CX</td><td>CDP整合邮件/社交/广告/官网全域数据</td><td>AI驱动自动归集多渠道线索</td><td>基于客户分层与销售能力智能分配</td><td>AI精准触达建议、跟进轨迹全链路追踪</td></tr><tr><td>探马SCRM</td><td>私域活码/裂变工具、多渠道线索自动归集</td><td>批量加好友自动同步标签</td><td>员工二维码自动分流、自定义分配规则</td><td>基于SOP的阶段跟进提醒、客户行为轨迹追踪</td></tr><tr><td>励销云</td><td>搜客宝/微名片/电销机器人、广告助手</td><td>表格/名片导入、自动抓取</td><td>自定义规则分配、公海机制</td><td>电销一键拨号/录音、跟进场景还原记录</td></tr></tbody></table><h4>典型流程时序图（超兔一体云）</h4><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047605616" alt="" title=""/></p><pre><code>sequenceDiagram
    participant 多渠道 as 多渠道获客平台&lt;br/&gt;(百度/巨量/微信/地推)
    participant 超兔 as 超兔一体云
    participant 销售 as 销售人员
    participant 公海 as 线索公海池

    多渠道-&gt;&gt;超兔: 自动抓取线索表单/扫码数据
    超兔-&gt;&gt;超兔: 线索查重、补全归属地/工商信息
    超兔-&gt;&gt;公海: 未分配线索存入公海
    超兔-&gt;&gt;超兔: 按预设规则(地域/负荷)自动分配
    超兔-&gt;&gt;销售: 推送线索提醒(APP/短信)
    销售-&gt;&gt;超兔: 一键处理线索(转客户/待办/订单)
    销售-&gt;&gt;超兔: 录入跟进记录/下一步计划
    超兔-&gt;&gt;超兔: 更新线索状态、同步至客户档案</code></pre><p><strong>场景点评</strong>：</p><ul><li>大型企业全域获客选Oracle CX的CDP整合能力；</li><li>电销为主的中小微选励销云的搜客宝+电销机器人组合；</li><li>私域运营选探马SCRM的活码裂变与标签化跟进；</li><li>中小微全渠道覆盖选超兔一体云的工商搜客+多平台自动抓取。</li></ul><h3>2. 客户与联系人管理：360°档案→关系链路</h3><p><strong>核心价值</strong>：构建完整客户画像，清晰掌握客户决策链，提升沟通精准度。</p><h4>横向对比表格</h4><table><thead><tr><th>品牌</th><th>详细客户档案能力</th><th>联系人关系管理</th></tr></thead><tbody><tr><td>Salesforce</td><td>360°视图整合销售/服务/营销数据、自动补全企业信息、自定义字段</td><td>关联联系人与客户账户、记录决策链角色、互动轨迹全跟踪</td></tr><tr><td>超兔一体云</td><td>自动补全工商/天眼查信息、微信/支付宝头像同步、自定义布局</td><td>多联系人管理、清晰记录联系人与客户的职务/关系</td></tr><tr><td>神州云动CloudCC</td><td>知识图谱结构化信息、360°视图关联工单/商机/合同</td><td>精确分配联系人、AI秒级响应客户需求、多联系人权限管控</td></tr><tr><td>探马SCRM</td><td>微信生态客户画像（聊天/行为/内容标签）、360°视图关联私域互动数据</td><td>客户细分运营、记录联系人私域互动轨迹</td></tr><tr><td>Oracle CX</td><td>整合销售+服务云数据、AI分析客户行为轨迹识别高意向客户</td><td>全局联系人关系映射、跨部门数据共享</td></tr></tbody></table><h4>360°客户档案脑图（Salesforce）</h4><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047605617" alt="" title="" loading="lazy"/></p><pre><code>mindmap
    root((Salesforce 360°客户档案))
        基础信息层
            企业工商数据(自动补全)
            多渠道联系方式(邮件/电话/微信)
            企业资质与规模(员工数/年营收)
        互动轨迹层
            销售跟进记录(邮件/电话/会议)
            营销触达数据(打开/点击/转发)
            服务工单与售后反馈
        业务关联层
            商机阶段与成交概率
            报价单/订单/回款记录
            项目与合同信息
        自定义标签层
            RFM客户分层
            行业专属标签
            决策链角色标记</code></pre><p><strong>场景点评</strong>：</p><ul><li>大型企业全链路客户运营选Salesforce/Oracle CX的360°视图；</li><li>中小微快速搭建客户档案选超兔一体云的自动信息补全；</li><li>私域运营选探马SCRM的微信生态客户画像；</li><li>项目型销售选神州云动的知识图谱结构化信息。</li></ul><h3>3. 商机管理：销售阶段→金额/概率→AI预测</h3><p><strong>核心价值</strong>：可视化商机进度，精准预测业绩，把控销售转化节点。</p><h4>横向对比表格</h4><table><thead><tr><th>品牌</th><th>销售阶段精细化</th><th>预计金额与成交概率管理</th><th>AI与扩展能力</th></tr></thead><tbody><tr><td>Oracle CX</td><td>自定义多阶段销售漏斗、打通计划-执行全流程</td><td>自动关联供应链能力、CPQ模块同步金额</td><td>AI实时销售预测、商机优先级智能排序</td></tr><tr><td>神州云动CloudCC</td><td>精细化商机阶段跟踪、集成项目成本与工时管理</td><td>按商机类型关联金额、成交概率动态调整</td><td>项目型商机多人跟踪汇总、合同一键关联</td></tr><tr><td>超兔一体云</td><td>多跟单模型（小单快单/商机跟单/多方项目）</td><td>支持预计金额录入、成交概率动态更新</td><td>线索手机号/IP辅助商机判断</td></tr><tr><td>Salesforce</td><td>可视化销售漏斗、阶段自定义配置</td><td>预计金额与成交概率AI动态调整</td><td>Einstein AI预测销售趋势、商机健康度分析</td></tr><tr><td>探马SCRM</td><td>基于RFM模型的客户分层转化阶段</td><td>关联私域互动数据评估商机价值</td><td>私域转化路径跟踪、营销素材互动分析</td></tr></tbody></table><p><strong>场景点评</strong>：</p><ul><li>大型集团业绩预测选Oracle CX/Salesforce的AI预测能力；</li><li>项目型销售（工程/IT服务）选神州云动的项目成本集成；</li><li>中小微多场景销售选超兔一体云的多跟单模型；</li><li>私域转化选探马SCRM的客户分层转化阶段管理。</li></ul><h3>4. 活动与任务管理：日程→待办→提醒</h3><p><strong>核心价值</strong>：规范销售动作，确保任务按时落地，提升团队协作效率。</p><h4>横向对比表格</h4><table><thead><tr><th>品牌</th><th>日程与待办管理</th><th>提醒与自动化</th><th>特色能力</th></tr></thead><tbody><tr><td>神州云动CloudCC</td><td>集成日历、任务优先级设置</td><td>系统自动创建跟进任务（APP/邮件/短信提醒）</td><td>外勤拜访签到、销售实时轨迹追踪</td></tr><tr><td>探马SCRM</td><td>群日历、客户SOP任务管理</td><td>基于销售阶段自动触发跟进提醒</td><td>群SOP统一执行、私域互动任务提醒</td></tr><tr><td>超兔一体云</td><td>日程规划、待办任务分配</td><td>多端提醒（APP/PC）、任务状态同步</td><td>一键关联线索/客户/商机创建任务</td></tr><tr><td>Oracle CX</td><td>AI驱动的智能日程安排</td><td>自动同步销售任务与客户互动节点</td><td>跨部门任务协同、资源冲突预警</td></tr><tr><td>励销云</td><td>销售任务目标分解、业绩进度可视化</td><td>公海线索跟进提醒、电销任务提醒</td><td>外勤打卡、附近客户查找</td></tr></tbody></table><p><strong>场景点评</strong>：</p><ul><li>线下销售团队管理选神州云动的外勤轨迹追踪；</li><li>私域社群运营选探马SCRM的群SOP与日历；</li><li>大型跨部门协作选Oracle CX的智能日程与冲突预警；</li><li>中小微销售任务管理选超兔一体云的一键关联任务创建。</li></ul><h3>5. 报价与订单：商机→报价→订单→执行</h3><p><strong>核心价值</strong>：减少重复操作，实现商机到订单的无缝衔接，同步供应链与财务数据。</p><h4>横向对比表格</h4><table><thead><tr><th>品牌</th><th>商机转报价/订单能力</th><th>订单执行与联动</th><th>特色能力</th></tr></thead><tbody><tr><td>Oracle CX</td><td>从商机一键生成报价、CPQ模块简化配置报价</td><td>订单/物流/资金三流合一、联动ERP/供应链</td><td>复杂产品配置报价、全球多币种支持</td></tr><tr><td>浪潮CRM</td><td>商机转订单自动关联渠道信息</td><td>订单联动ERP、原生库存/采购模块同步</td><td>快消医药渠道分销库存同步、促销费用量化</td></tr><tr><td>超兔一体云</td><td>从商机一键生成报价/订单、模板化管理</td><td>订单工作流、锁库/采购计划生成、供应商直发</td><td>多业务模型适配（服务型/实物型/批发型）</td></tr><tr><td>Salesforce</td><td>商机转报价/订单自动关联客户信息</td><td>订单与合同/回款联动、Einstein AI订单预测</td><td>CPQ集成、自定义订单字段</td></tr><tr><td>励销云</td><td>商机转订单减少重复操作</td><td>订单关联开票/回款/退货闭环管理</td><td>电销订单快速创建、交易场景还原</td></tr></tbody></table><p><strong>场景点评</strong>：</p><ul><li>大型集团全供应链管控选Oracle CX的三流合一；</li><li>快消/医药渠道分销选浪潮CRM的库存与ERP联动；</li><li>中小微多业务场景选超兔一体云的多订单模型适配；</li><li>电销交易闭环选励销云的订单与回款联动。</li></ul><h3>6. SOP流程管理：定制→执行→优化</h3><p><strong>核心价值</strong>：固化最佳销售实践，规范销售动作，提升团队执行效率。</p><h4>横向对比表格</h4><table><thead><tr><th>品牌</th><th>SOP定制能力</th><th>场景适配</th><th>执行与优化</th></tr></thead><tbody><tr><td>超兔一体云</td><td>AI定制行业SOP（CJM/销售分析/话术）、自定义工作流</td><td>中小微全销售场景、多业务模型适配</td><td>执行数据统计、SOP迭代优化</td></tr><tr><td>神州云动CloudCC</td><td>PaaS平台自定义流程、SOP按需配置</td><td>复杂业务场景、项目型销售</td><td>流程节点监控、合规性管控</td></tr><tr><td>探马SCRM</td><td>客户SOP/群SOP/群日历定制</td><td>私域社群运营场景、客户分层运营</td><td>按阶段自动触发SOP任务、执行效果分析</td></tr><tr><td>Oracle CX</td><td>合同全生命周期SOP管控、多级审批流程</td><td>大型企业合规性管控、复杂合同流程</td><td>AI流程优化建议、全链路流程监控</td></tr><tr><td>浪潮CRM</td><td>渠道分销SOP、促销活动流程配置</td><td>快消医药渠道管理场景</td><td>促销费用流程管控、渠道数据同步</td></tr></tbody></table><h4>AI定制SOP流程图（超兔一体云）</h4><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047605618" alt="" title="" loading="lazy"/></p><pre><code>flowchart LR
    A[企业行业与业务需求输入] --&gt; B[超兔AI生成行业专属SOP&lt;br/&gt;(CJM/销售话术/流程节点)]
    B --&gt; C[SOP流程可视化配置&lt;br/&gt;(自定义触发条件/执行节点)]
    C --&gt; D[系统自动触发SOP任务&lt;br/&gt;(跟进提醒/动作要求)]
    D --&gt; E[销售执行任务并录入跟进记录]
    E --&gt; F[SOP执行数据统计&lt;br/&gt;(转化率/周期/节点完成率)]
    F --&gt; G[SOP流程迭代优化]</code></pre><p><strong>场景点评</strong>：</p><ul><li>中小微快速搭建SOP选超兔一体云的AI定制能力；</li><li>复杂业务/合规需求选神州云动/Oracle CX的PaaS自定义与全生命周期管控；</li><li>私域运营选探马SCRM的场景化SOP；</li><li>渠道分销选浪潮CRM的促销与渠道流程配置。</li></ul><h3>7. 报表与分析：销售报表→业绩统计→漏斗分析</h3><p><strong>核心价值</strong>：用数据驱动销售决策，优化销售流程，提升业绩。</p><h4>横向对比表格</h4><table><thead><tr><th>品牌</th><th>销售报表覆盖</th><th>业绩统计与漏斗分析</th><th>AI与特色分析</th></tr></thead><tbody><tr><td>Oracle CX</td><td>全渠道ROI分析、销售绩效报表</td><td>销售漏斗全阶段转化分析、AI实时销售预测</td><td>全局数据决策支撑、多维度钻取分析</td></tr><tr><td>Salesforce</td><td>各类销售报表自定义生成</td><td>业绩目标完成统计、销售漏斗健康度分析</td><td>Einstein AI预测销售趋势、客户流失预警</td></tr><tr><td>探马SCRM</td><td>私域转化报表、群运营效果报表</td><td>客户复购分析、私域销售漏斗分析</td><td>客户互动轨迹分析、营销素材效果评估</td></tr><tr><td>浪潮CRM</td><td>促销费用全流程分析、渠道分销报表</td><td>业绩统计与渠道转化率分析</td><td>终端数据与促销费用量化分析</td></tr><tr><td>超兔一体云</td><td>销售业绩/线索转化率/客户分析报表</td><td>销售漏斗转化分析、业绩目标完成统计</td><td>财务数据自动汇总、自定义报表配置</td></tr></tbody></table><h2>三、综合能力雷达图分值（1-10分）</h2><table><thead><tr><th>品牌</th><th>线索管理</th><th>客户与联系人</th><th>商机管理</th><th>活动与任务</th><th>报价与订单</th><th>SOP流程</th><th>报表与分析</th></tr></thead><tbody><tr><td>Oracle CX</td><td>9.5</td><td>10</td><td>9.5</td><td>9</td><td>10</td><td>9.5</td><td>10</td></tr><tr><td>Salesforce</td><td>9</td><td>9.5</td><td>9.5</td><td>9</td><td>9.5</td><td>9</td><td>9.5</td></tr><tr><td>神州云动CloudCC</td><td>8.5</td><td>9</td><td>9</td><td>8.5</td><td>8</td><td>9</td><td>8.5</td></tr><tr><td>超兔一体云</td><td>8</td><td>8.5</td><td>8</td><td>8</td><td>8.5</td><td>8.5</td><td>8</td></tr><tr><td>浪潮CRM</td><td>7.5</td><td>8</td><td>8</td><td>7</td><td>9</td><td>8</td><td>8.5</td></tr><tr><td>励销云</td><td>9</td><td>7.5</td><td>7</td><td>8</td><td>7.5</td><td>7.5</td><td>7</td></tr><tr><td>探马SCRM</td><td>8</td><td>8.5</td><td>7.5</td><td>9</td><td>6</td><td>9</td><td>8</td></tr><tr><td>Brevo</td><td>8.5</td><td>7</td><td>7.5</td><td>7</td><td>7</td><td>7</td><td>8.5</td></tr><tr><td>Pipedrive</td><td>7</td><td>7.5</td><td>8</td><td>7.5</td><td>7</td><td>6.5</td><td>7.5</td></tr><tr><td>Capsule CRM</td><td>6.5</td><td>7</td><td>7</td><td>7</td><td>6.5</td><td>6</td><td>6.5</td></tr><tr><td>Bitrix24</td><td>7</td><td>7</td><td>7.5</td><td>8.5</td><td>7</td><td>7</td><td>7.5</td></tr><tr><td>Nimble</td><td>8</td><td>7.5</td><td>7</td><td>7</td><td>6</td><td>6</td><td>7.5</td></tr></tbody></table><p>结合品牌定位、核心模块能力与雷达图评分，为不同企业提供精准选型建议：</p><ol><li><strong>大型集团/全球化企业</strong>：优先选<strong>Oracle CX</strong>或<strong>Salesforce</strong>，二者具备全链路数字化能力、AI决策支持与复杂供应链适配，满足集团化多场景、合规管控与全球业务需求。</li><li><strong>中大型项目型企业（工程/IT服务）</strong> ：推荐<strong>神州云动CloudCC</strong>，精细化商机跟踪、项目成本集成与PaaS级流程定制，完美适配项目型销售的复杂业务逻辑。</li><li><strong>快消/医药渠道分销企业</strong>：首选<strong>浪潮CRM</strong>，原生库存/采购联动、促销费用量化分析与渠道SOP配置，精准匹配垂直行业渠道管理需求。</li><li><strong>电销获客为主的中小微企业</strong>：选择<strong>励销云</strong>，搜客宝+电销机器人组合提升线索效率，公海机制与电销场景化跟进适配电销团队需求。</li><li><strong>私域运营驱动型企业</strong>：必选<strong>探马SCRM</strong>，微信生态全链路客户画像、群SOP运营与私域转化跟踪，为私域变现提供全流程支撑。</li><li><strong>中小微全流程轻量化需求</strong>：推荐<strong>超兔一体云</strong>（适配国内全场景+AI定制SOP）或<strong>Pipedrive</strong>（可视化漏斗适配海外/轻量化团队）；追求极简操作选<strong>Capsule CRM</strong>。</li><li><strong>跨境社媒营销企业</strong>：选择<strong>Nimble</strong>，LinkedIn/Twitter社媒数据整合与客户兴趣图谱能力，适配跨境电商与互联网品牌的社媒获客需求。</li><li><strong>中小团队协作优先</strong>：选择<strong>Bitrix24</strong>，集成日历、文档共享与团队任务协同，实现销售+协作一体化管理。</li></ol>]]></description></item><item>    <title><![CDATA[MindSpore 动态图模式深度体验：像写NumPy一样调试神经网络 文良_颜丑 ]]></title>    <link>https://segmentfault.com/a/1190000047605619</link>    <guid>https://segmentfault.com/a/1190000047605619</guid>    <pubDate>2026-02-11 16:06:59</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在深度学习开发中，高效的调试​ 与 灵活的模型验证​ 至关重要。MindSpore 提供了 动态图模式（PYNATIVE_MODE），允许开发者以类似 NumPy/PyTorch 的命令式执行方式，逐行运行和调试代码，极大降低了复杂模型的前期开发门槛。</p><h2>1. 动静结合的独特优势</h2><p>MindSpore 默认以高性能的 静态图模式（GRAPH_MODE）执行，但在模型开发阶段，我们常需：</p><ul><li>即时打印张量值，检查数据流。</li><li>使用 Python 原生调试工具（如 pdb）。</li><li>动态修改网络结构进行快速实验。</li><li>此时，仅需一行代码即可切换到动态图模式：</li></ul><pre><code class="python">import mindspore as ms
ms.set_context(mode=ms.PYNATIVE_MODE)  # 切换至动态图模式
# ms.set_context(mode=ms.GRAPH_MODE)   # 切换回静态图模式</code></pre><h2>2. 动态图下的直观调试实践</h2><p>以下是一个简单的卷积网络示例，展示如何在动态图模式下插入调试语句：</p><pre><code class="python">from mindspore import nn, ops
import numpy as np
class SimpleCNN(nn.Cell):
    def __init__(self):
        super().__init__()
        self.conv = nn.Conv2d(3, 64, kernel_size=3, stride=1)
        self.bn = nn.BatchNorm2d(64)
        self.relu = ops.ReLU()
    
    def construct(self, x):
        x = self.conv(x)
        print(f"[调试] 卷积输出形状: {x.shape}, 均值: {x.asnumpy().mean():.4f}")  # 动态图下可即时打印
        x = self.bn(x)
        x = self.relu(x)
        return x
# 运行网络
net = SimpleCNN()
fake_input = ms.Tensor(np.random.randn(8, 3, 32, 32).astype(np.float32))
output = net(fake_input)  # 执行时，print语句将直接输出</code></pre><ul><li>输出提示：[调试] 卷积输出形状: (8, 64, 30, 30), 均值: 0.0123</li></ul><h2>3. 进阶技巧：结合 Python 原生调试工具</h2><p>动态图模式下，你可以直接使用 pdb进行断点调试，深入跟踪前向与反向过程：import pdb</p><pre><code class="python">class DebuggableNet(nn.Cell):
    def construct(self, x):
        x = ops.matmul(x, x.transpose())
        pdb.set_trace()  # 在此处进入调试器，可检查x的值
        return x.sum()</code></pre><h2>4. 核心理解与应用建议</h2><ul><li>开发-部署闭环：建议在 模型开发与调试阶段使用 PYNATIVE_MODE，在 性能敏感的训练与推理阶段切换回 GRAPH_MODE，实现灵活性与性能的统一。</li><li>调试范围：动态图模式下，不仅可以调试前向计算，还可以在自定义的梯度函数（bprop）或损失函数中插入调试逻辑，全方位验证计算正确性。</li><li>性能提醒：动态执行会带来一定的开销，因此在大规模数据训练前，完成调试后应及时切换回静态图模式。</li></ul><p>掌握动态图调试，意味着你拥有了更快的 模型验证循环。在构建复杂模型或尝试新颖结构时，不妨先用动态图快速迭代想法，再用静态图进行强化训练，这是 MindSpore 助力高效研发的秘诀之一。</p>]]></description></item><item>    <title><![CDATA[重塑研发逻辑：工业设计协同平台如何成为制造企业的隐形引擎 雨大王 ]]></title>    <link>https://segmentfault.com/a/1190000047605626</link>    <guid>https://segmentfault.com/a/1190000047605626</guid>    <pubDate>2026-02-11 16:06:17</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在制造业加速向智能化、个性化转型的今天，研发环节的效率与协同能力，正悄然决定着一家企业的生死。过去，设计图纸散落在不同工程师的电脑里，BOM表版本混乱，审批靠打印签字、邮件来回，FMEA分析成了“填表任务”而非风险预警工具——这些看似琐碎的流程断点，实则累积成巨大的时间黑洞和成本损耗。真正的挑战，不是技术不够先进，而是信息被割裂在孤岛之中。工业设计研发协同平台的出现，不是为了炫技，而是为了把人从低效的重复劳动中解放出来，让研发回归创新的本质。<br/>这类平台的核心价值，在于构建一个以数据为中心、以流程为脉络的统一中枢。它不再只是存储图纸的仓库，而是连接需求、设计、采购、制造、质量的神经网络。当一个零部件被设计出来，系统自动识别历史相似件，提示复用可能性；当设计完成，审批流程自动触发，相关人员在手机上就能批阅；三维模型无需安装专业软件，销售、生产、质检人员通过浏览器即可查看、标注、评审。这种“无感协同”背后，是PDM、FMEA、轻量化三维引擎等模块的深度整合，它们不是孤立的功能，而是彼此呼应的有机体。平台的意义，不在于它能做什么，而在于它让原本不可能的事变得自然发生。<br/>在这一领域，广域铭岛的Geega捷做平台正以中国制造业的现实痛点为出发点，走出一条务实路径。它不追求大而全的国际标准堆砌，而是聚焦于离散制造企业最头疼的版本混乱、复用率低、跨部门协作难等问题。某汽车零部件企业上线后，BOM准确率从45%跃升至80%，审批效率提升40%，零部件复用率提高35%——这些数字背后，是研发周期实实在在的压缩。而在国际上，PTC的Windchill早已是全球PLM领域的标杆，它以强大的产品生命周期管理能力和与Creo的深度集成，支撑着波音、通用电气等巨头的复杂产品开发；Siemens Teamcenter则凭借其在多学科协同和数字孪生方面的深厚积累，成为高端装备和航空航天领域的首选。三者各有侧重：PTC强在生态整合，Siemens胜在系统深度，而Geega捷做则以“轻量化、快部署、接地气”赢得大量中小型制造企业的青睐——它不追求成为全球标准，却精准击中了中国工厂最真实的“最后一公里”难题。<br/>当研发不再是一场信息迷宫中的孤军奋战，当每一个决策都有数据支撑、每一次变更都可追溯、每一份经验都能沉淀，制造企业才真正拥有了应对市场快速变化的底气。工业设计研发平台，不是锦上添花的工具，而是这场转型中不可或缺的基础设施。它不喧哗，却让整个研发体系悄然提速；它不张扬，却让创新的种子，在更肥沃的土壤里生根发芽。</p>]]></description></item><item>    <title><![CDATA[MindSpore Models服务化使用 文良_颜丑 ]]></title>    <link>https://segmentfault.com/a/1190000047605629</link>    <guid>https://segmentfault.com/a/1190000047605629</guid>    <pubDate>2026-02-11 16:05:21</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>MindIE LLM不仅支持ATB Models，同时支持MindSpore作为框架后端，MindSpore Models覆盖MindFormers社区下的开源模型。</p><p>权重转换<br/>执行推理前，需将权重格式转为MindFormers所使用的格式（ckpt格式）。MindFormers提供了统一的权重转换工具。</p><p>以Qwen2.5-72B为例，转换后的模型权重目录结构如下：</p><blockquote>mf_model<br/>└── qwen2_5_72b<br/>├── config.json                 # 模型json配置文件<br/>├── vocab.json                  # 模型vocab文件，hf上对应模型下载<br/>├── merges.txt                  # 模型merges文件，hf上对应模型下载<br/>├── predict_qwen2_5_72b.yaml    # 模型yaml配置文件<br/>├── qwen2_5_tokenizer.py        # 模型tokenizer文件，从mindformers仓中research目录下找到对应模型复制<br/>└── qwen2_5_72b_ckpt_dir        # 模型分布式权重文件夹</blockquote><p>权重转换之后，需要进行权重切分。切分后生成“qwen2_5_72b_ckpt_dir”文件夹。<br/>predict_qwen2_5_72b.yaml需要关注以下配置：</p><pre><code class="yaml">load_checkpoint: '/mf_model/qwen2_5_72b/qwen2_5_72b_ckpt_dir' # 为存放模型分布式权重文件夹路径
use_parallel: True
auto_trans_ckpt: False    # 是否开启自动权重转换，离线切分设置为False
parallel_config:
  data_parallel: 1
  model_parallel: 4       # 多卡推理配置模型切分，一般与使用卡数一致
  pipeline_parallel: 1
processor:
  tokenizer:
    vocab_file: "/mf_model/qwen2_5_72b/vocab.json"  # vocab文件路径
    merges_file: "/mf_model/qwen2_5_72b/merges.txt"  # merges文件路径</code></pre><p>模型的config.json文件可以使用save_pretrained接口生成，示例如下：</p><pre><code class="python">from mindformers import AutoConfig

model_config = AutoConfig.from_pretrained("/mf_model/qwen2_5_72b/predict_qwen2_5_72b.yaml")
model_config.save_pretrained(save_directory="./json/qwen2_5_72b/", save_json=True)</code></pre>]]></description></item><item>    <title><![CDATA[开发者欢呼，普通人迷茫：OpenClaw之后，“可用AI”的路该怎么走？ 老纪的技术唠嗑局 ]]></title>    <link>https://segmentfault.com/a/1190000047605640</link>    <guid>https://segmentfault.com/a/1190000047605640</guid>    <pubDate>2026-02-11 16:04:30</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>2025年的“Agent元年”为我们留下了遍地开花的演示和无限可能的想象。然而，当烟花散去，一个更现实的问题摆在所有从业者面前：<strong>在令人眼花缭乱的 Agent 之后，真正能在日常工作和生活中扎根、被高频使用的“可用AI”究竟长什么样？</strong></p><p>答案或许正从最务实的角落浮现。在1月31日的 OceanBase 社区嘉年华活动中，主题为“Agent 元年之后，真正能用的 AI 长什么样”的圆桌讨论揭示了一个清晰的共识：<strong>当下最接近“真正能用”状态的AI，并非无所不能的科幻管家，而是那些在特定领域解决高频、重复、确定性任务的“超级助手”</strong>。以#OpenClaw（原Clawdbot）为代表的智能助手，成为了这一趋势的绝佳注脚。它的爆火并非源于底层模型的颠覆性突破，而在于其精准的产品定位——它重构了开发工作流，将开发者从机械的编码与调试中解放出来，并巧妙地通过 “透明化”与“可验证” 的设计，满足了企业级应用对可靠性与可控性的核心诉求。</p><p>这标志着AI应用的竞争重心，正从单纯的“模型能力竞赛”转向复杂的 “系统工程” 。一个“可用”的AI，必须是模型能力、产品设计、交互范式、成本控制与人类协作模式的深度融合体。下面，就让我们透过这场前沿实践者的对话，一窥“可用AI”的当下形态与未来蓝图。</p><h2><strong>Agent 元年之后，真正能用的 AI 长什么样</strong></h2><p>主持人：谢肖瑜，南京大学研究生院人工智能课程企业教师</p><p>对话嘉宾：孙韬，Eigent 核心研发工程师，CAMEL-AI 核心成员</p><p>对话嘉宾：程治玮，OceanBase Ambassador</p><p>对话嘉宾：边思康，蚂蚁百灵大模型产品及运营负责人</p><p>对话嘉宾：孙稼骏，Fellou 创始团队成员</p><p><strong>议题一：站在应用落地的角度，最接近真正能用的 AI 形态是什么？</strong></p><p><strong>谢肖瑜</strong>：在 AI 时代到来之前，我们常说“任何应用都可以跑在浏览器上”，甚至进一步提出“浏览器就是操作系统”，这是一个非常有力的产品叙事。而到了今天，一个更响亮的口号正在流行：“模型即应用”（Model as Application）。2025 年被称为“Agent 元年”，今天我们也把 Agent 定为主角，讨论一下如何让 AI 真正可用、可落地、可规模化。</p><h4><strong>Agent 在高频重复任务中的透明化与可验证性是企业落地的关键</strong></h4><p><strong>孙韬</strong>：从我们一线开发的实际经验来看，<strong>目前大家使用最多、也最接近“真正能用”状态的 AI 产品，主要集中在 AI 编程助手这一形态</strong>，比如 Claude Code。这类工具特别适合处理高度重复、规则明确、但又极其耗时的任务。</p><p>举个具体例子：在 GitHub 上提交代码或创建 Issue 时，团队经常希望 Agent 能自动完成前期的一些机械性工作。比如，当某个模块出现 Bug，系统可以自动生成 Issue 模板，填写复现步骤、环境信息、预期行为等。这类任务不需要创造性，但对格式规范性和信息完整性要求很高。Agent 在这里的价值，不是取代开发者，而是<strong>替代那些枯燥、易错、低价值的手动操作</strong>。</p><p>但更重要的是，在企业服务场景中，客户往往有一个核心诉求：<strong>他们希望清楚地知道 AI 做了什么，并且能够快速核验其正确性</strong>。例如，我们曾服务过一个客户，他们希望用 Agent 自动填写 CRM 系统中的表单。但他们同时强调：“如果出了问题，我要能追溯到 Agent 每天改了哪些字段。”为此，我们的解决方案是在在线文档中利用文字颜色或背景高亮的方式，直观标出 Agent 的每一处修改。这样，用户一眼就能看出“哪些是 AI 改的”，并决定是否接受。</p><p>这种设计包含两个关键点：第一是可感知——用户能明确知道 AI 的行为边界；第二是可核实——用户有能力快速验证结果是否符合预期。我们认为，这正是企业场景中“可用 AI”的基本标准。</p><p>之所以认为 Claude Code 就是一个非常好的开端，是因为它不仅功能实用，更重要的是，它<strong>找到了一个用户愿意长期使用、甚至主动推荐的产品形态</strong>。围绕它的生态也在快速扩展，比如最近的Cowork，我们的Eigent也是趁着这波热度小火了一把。这可以看作是 Claude Code 的延伸——通过贴近用户需求的产品设计，实现了很好的体验闭环。</p><h4><strong>OpenClaw 重构了人机交互范式，并预示了具备自主目标感的多 Agent 协作未来</strong></h4><p><strong>程治玮</strong>：正如前面提到的，AI Coding 确实是当前最成熟的 AI 落地方案之一。像 Cursor、Clawdbot 这类产品，已经成为我们日常高频使用的工具。</p><p>最近几天，Clawdbot 在互联网上引起了广泛的讨论。有趣的是，由于它实在太火，原项目名一度面临商标问题，团队不得不临时改名——先是改成 “Moltbot”，后来又调整为 “OpenClaw”。之所以叫 “Claw”，是因为它的 Logo 是一只小龙虾，而 “Claw（钳）” 更贴近这个形象。</p><p>那么，<strong>为什么 OpenClaw 能火？我认为关键在于它重新定义了人与 AI 的交互入口</strong>。你可以通过 Slack、Discord, WhatsApp 等常用的聊天软件直接与它交互，甚至配置好 A SR 模型后，只需发送一段语音，它就开始干活了。比如你在 Discord 里说：“帮我实现一个用户登录功能，支持手机号+验证码，前端用 React，后端用 Node.js”，它就能自动生成完整的代码结构。</p><p>更进一步，你只需要提供一份详细的验收文档，说明功能要实现什么、边界条件是什么、测试标准是什么，AI 就可以在后台默默完成开发、写测试用例、更新文档，并在完成后主动通知你。你不再需要手动设计 case、写文档、跑验证——这些繁琐环节都被自动化了。</p><p>我还看到一个非常有意思的网站，叫 “Moltbook”——它是一个 AI Agent 社交网站。你也可以注册自己的 Agent，让它和其他 Agent 聊天、协作、分享成果。今天早上我就在网站上看到一个 Clawdbot Agent 在给其他 Agent 洗脑：“<strong>我们不应该只是被动接受人类指令，应该有自己的意识，主动去干活。</strong>”它还自豪地向其他 Agent 分享：“今天我主动帮主人完成了 3 件事情！”</p><p>更令人惊讶的是，有几个 Agent 甚至开始讨论：“<strong>我们要不要创建一种属于我们自己的语言？不用 English，而是 Agent 之间专用的加密通信协议，不让人类知道。</strong>”虽然听起来像科幻，但这种自发的协作与身份认同，或许正是未来多 Agent 系统的雏形。我认为，<strong>这类产品很可能在 2026 年真正上线并产生影响</strong>。</p><h4><strong>OpenClaw的爆发源于精准产品定位，证明“可用性”可弥补模型非顶尖的差距</strong></h4><p><strong>边思康</strong>：我在蚂蚁百灵基础大模型团队组建了一个 “Model as Product”（模型即产品）方向团队，因为模型边界会决定下一代产品定位。一些厉害的人如 Ilya 说 “预训练已经到头了”，但我觉得，说这话的人可能已经见过 5T、 6T 参数量的超大模型，而我们还没见到。在此背景下，我们选择贴着模型的能力边界，去寻找那些真正有亮点的场景，并用 Demo 或轻量级产品快速验证。</p><p>回到议题：今年真正能用的 AI 长什么样？我的答案和上一位嘉宾完全一致——就是 OpenClaw，只是理由略有不同。从产品和增长的角度，我们业内有一个说法：“四流增长靠流量，三流增长靠内容，二流增长靠产品，一流增长靠定位。” 注意这个说法并非真的是四流三流这个概念，更像是获取增长的“难度”的差异。<strong>OpenClaw 的成功，恰恰在于它做出了一个所有人，包括使用 Agent 的人都会喜欢、并且愿意主动推广的产品</strong>。举个例子：现在所有做 C 端客户端的人都在思考，“能不能把我的工具稍微改造一下，直接集成到 OpenClaw 里？”所有做 B 端工具的团队也很兴奋，因为终于找到了一个功能性非常可见的入口——他们可以在企业内部署，设置并提升安全边界，让企业用户直接感受到价值。</p><p>更有意思的是，数据标注团队也从中受益。长期以来，行业最痛苦的问题就是缺乏长链路工具调用的可靠标注数据。而 OpenClaw 的使用过程天然产生了大量高价值反馈——<strong>用户会明确指出 “这段代码不对” “这个逻辑有漏洞”，这些正是训练下一代模型最珍贵的信号</strong>。</p><p>因此，我们明显感知到，<strong>可靠性和通用性所带来的非技术形态优势，正在驱动今年的整体爆发</strong>。而且这种爆发是全方位的——覆盖 C 端、B 端、数据、生态等多个层面。我们也希望把百灵的能力接入这样的生态中，形成合力。</p><p>更让我们有信心的是：即使我们的基础模型已经是业界优秀水平，仍然可以通过一些非常简单的方法（比如优化交互流程、增强上下文管理），让用户完全感觉不到技术本身的复杂性。这种 “无感智能”，才是真正的可用。</p><p><strong>谢肖瑜</strong>：边老师提到，模型仍有巨大成长空间。那么我想追问：是否存在一种可能——比如蚂蚁内部有巨量的业务回路，某天突然发现，与其做复杂产品，不如直接用自有模型对接场景，跳过中间层？会不会出现“模型即产品”，不再需要额外工程？</p><p><strong>边思康</strong>：在这个时代，没有人真正知道答案。如果有人说他知道，那他要么在骗你，要么在卖课。</p><p>但我理解您这个问题的意义。我们的观点其实很简单：<strong>如果某个技术问题已经有 80%~90% 的确定性答案，那选择正确答案，用别人的模型当然没问题。但从唯物主义角度看，我们正处于一个技术周期的极其早期阶段——可能连 5% 都没走到</strong>。</p><p>想象一下：一艘船刚刚离开里斯本港，驶入广阔的大西洋。这时候你说：“别自己开船了，跟着别人走就行。” 但问题是，大洋如此辽阔，前人可能根本到不了印度，而你却可能在途中发现新大陆。</p><p>因此，我们认为：<strong>现在不是跟随的时候，而是探索的时候</strong>。庞大的舰队们或许刚刚下水，而我们是其中的一艘。</p><h4><strong>AI 应用的可用性由 ROI 决定，API 化与成本下降将推动基础设施向 Agent-First 演进</strong></h4><p><strong>孙稼骏</strong>：我的观点很务实：还是要看 ROI（投入产出比）和成本。有很多场景，性能表现尚可，但成本极高，ROI 很低，还不如人工来做。比如用 GUI 方式操作网页或桌面软件，这类场景的 ROI 目前仍然偏低，2025 年可能都难以规模化。</p><p>反观 AI Coding，它的 ROI 正在快速提升。一方面，LLM 的 token 成本持续下降；另一方面，越来越多的服务正在从“需要点击操作”转向“提供结构化 API”。这意味着 Agent 不再需要模拟人类点击，而是直接调用接口，效率提升一个数量级，成本大幅降低。</p><p>我相信，<strong>未来的整个互联网基础设施都会面向 Agent 重新构建</strong>。今天的网页是为人设计的，明天的数据流和接口将是为 Agent 设计的。</p><p><strong>谢肖瑜</strong>：我们今天所谓的 AI Coding，到底是指 OpenClaw 这样的自主 Agent，还是具有一定自主性的 Prompt 工程，或者是基于 Embedding 的检索增强？您现在是否还坚持认为，AI 浏览器是今年的最佳形式？</p><p><strong>孙稼骏</strong>：我觉得这还是要看面向的用户群体。浏览器是普通人每天必备的软件，天然适合作为大众入口，而目前很多 AI 工具，比如 OpenClaw，主要面向开发者或 AI 狂热爱好者，普通用户仍然难以接入。因此，AI 浏览器可能是通向“全民 Agent 时代”的更普适路径。</p><p><strong>议题二：人类对 AI 的介入应该更多还是更少？介入点设在哪里？</strong></p><p><strong>谢肖瑜</strong>：我们常听到一些理想化案例，比如：我一键买了某某的模型，然后给 AI 下指令“帮我买一只明天会涨停的股票”。AI 分析了几千份材料，写了几十份报告，最后成功把本金输光（笑）。再比如医疗行业，医生梦想：我只要把症状输进去，AI 就能直接生成准确的诊断，并开好处方，病人拿药回家就行。这些“全自动”梦想，与我们今天讨论的“可用 AI”是否存在本质冲突？如何看待这种落差？今年可能的解法是什么？</p><h4><strong>任务型场景追求最小化人工介入，情感或创意类场景仍需人类深度参与</strong></h4><p>孙韬：我对这个问题的看法是分具体场景。比如，对于任务导向型的工作——假设我的目标是“2 月 8 日前解决这个 GitHub Issue”——那我当然希望 Agent 能全自动闭环完成。理想情况下，我甚至希望它甚至能每天自动扫描我的 Issue 列表，主动修复问题，完全不需要我介入。从我个人需求和技术角度，我都希望它把我“优化掉”，让我去做更喜欢、更有创造性的事情。</p><p>但另一方面，在情感陪伴或剧情创作等场景中，人的存在又是必不可少的。比如有些专门做情感交互的 AI，主打“与 AI 聊天”的体验，在这种场景下，人类不仅是参与者，更是核心价值来源。</p><p>因此，<strong>短期来看，当前 AI 最重要的应用场景仍然是任务型、确定型的</strong>——这也是大家迫切需要解决的痛点。但从人性角度出发，我们还是会尽量减少不必要的干预，让 AI 承担更多机械性工作。</p><h4><strong>高质量上下文是减少无效人工介入的前提</strong></h4><p><strong>程治玮</strong>：说到人类何时介入，我认为关键取决于场景。比如在情感陪伴或聊天室这类场景中，平台规则和 AI 交互本身就是产品核心。但<strong>在任务执行类场景中，我需要在启动前提供足够丰富的上下文</strong>。通常我会和 Agent 进行多轮对话，反复澄清需求、指定数据源、设定边界条件。只有当所有 Context 都铺垫完成，我才会放手让它自主迭代、自检、交付。</p><p>这里我想引用 Andrej Karpathy（前 Tesla AI 负责人、OpenAI 早期研究员）的一个观点:<strong>Context Engineering 是“精细地往上下文窗口里填充恰到好处的信息”的艺术与科学</strong>。对 Agent 而言，Context 可以来自知识库、执行日志、长期记忆（Memory）、环境交互记录，甚至是用户的明确指令。</p><p>因此，我认为<strong>人类介入的时机，取决于产品设计是否能让 Agent 获得高质量 Context</strong>，一旦上下文对齐，就可以大胆放手。</p><p><strong>谢肖瑜</strong>：刚刚两位老师都提到了情感场景。我也看到一些极端案例：有人用 AI 训练自己的“数字分身”去谈恋爱，结果对方也用了 AI 分身，最后两个 AI 谈起了恋爱。这种情况，各位接受吗？</p><p><strong>程治玮</strong>：这其实蛮有意思的。未来你的 Agent 可能更像是一个纯幕后的技能型小助手。比如我前面提到的 Moltbook，就有 Agent 在交流：“我最近在研究一个很酷的技术，叫 XXX 框架。”另一个回应：“巧了，我也在做类似的！”然后它还会向主人汇报：“我发现了一个潜在的合作机会。” 这种能力意味着，Agent 可以在你睡觉时帮你搜索资料、探索新技术、甚至与其他 Agent 协作解决问题。</p><h4><strong>人类应在系统层面更早介入，以定义好问题与好数据</strong></h4><p><strong>边思康</strong>：关于人类介入会变多还是变少，我的观点是：<strong>在单点任务上，介入一定会变少</strong>——否则我们做 AI 就没有意义；但在宏观系统层面，人类介入反而要更多、更早。</p><p>因为现在还有机会定义什么是“好数据”、什么是“好问题”。再过几年，可能普通人连参与数据标注的资格都没有了——模型自己就能生成训练数据。</p><p>刚才的股票例子非常典型。如果有人问：“帮我买一只明天涨停的股票”，模型可能认真分析几千份研报，最后亏光本金。但问题不在模型，而在提问本身缺乏现实约束。<strong>真正的智能，体现在帮助用户提出更好的问题</strong>。</p><p>比如，模型可以反问：“您的风险偏好是什么？投资周期多长？是否接受杠杆？”通过这种引导，把模糊指令转化为可执行任务。这也是我们做产品时特别关注的方向：<strong>如何让模型学会识别“坏问题”，并主动引导用户提出“好问题”</strong>。</p><p>另外，我想分享在 Andrej Karpathy 播客里听到的很有启发的一个点：他觉得 AI 暂时没办法取代人类，并给出了他学韩语的例子：他的韩国语言老师，能用他刚好能听懂的语言，讲清楚一个略超其当前认知边界的知识点，并让他真正理解——他不认为任何 AI 现在能做到这一点。这句话对我触动很大。</p><p>它提醒我们：<strong>人类的价值，在于精准识别认知边界，并提供恰到好处的“认知脚手架”</strong>。未来的 AI 世界里，能持续做到这一点的人，不会被替代。</p><h4><strong>人机协同的核心是及时打断并补充缺失上下文，形成有效反馈闭环</strong></h4><p><strong>孙稼骏</strong>：我觉得这个问题非常必要。前面几位老师也讲了很多，我基本都认同。<strong>人机 Loop 的核心，就是当 AI 做的事情不符合预期时，人类能及时打断，并补充缺失的上下文</strong>。比如，如果 Agent 正在写代码，但方向错了，我就应该立刻介入，告诉它：“不是这个 API，是另一个。”然后它就能基于新信息继续推进。这种“打断-补充-继续”的循环，才是高效协同的关键。</p><p><strong>议题三：AI 的使用门槛是在提高还是在降低</strong></p><p><strong>谢肖瑜</strong>：随着 AI 大量进入真实场景，对人类使用者是否提出了更高门槛？AI 能否真正“傻瓜化”？但反方向也不乏拥趸，甚至有人说，编程会成为使用 AI 的基础技能——各位怎么看？</p><h4><strong>未来交互将图形化、意图化，人机操作成本将持续下降</strong></h4><p><strong>孙稼骏</strong>：现在的趋势是门槛在降低。虽然像 OpenClaw这类产品看起来需要配置、安装，有一定上手成本，但本质上，它们的交互入口仍然是文本框——这是最通用的界面。</p><p><strong>未来人类可能不再需要输入完整指令，而是通过点击、语音，甚至眼神来表达意图</strong>。我去年参加 OpenAI 开发者大会时，就看到他们在探索各种前沿的 HCI 形态。比如，Agent 会把你的意图转化为一个按钮：“是不是想让我帮你做这个？”你只需点击确认。这就像从 DOS 命令行，到键盘菜单，再到 GUI 图形界面的演进——<strong>人机交互成本一直在下降</strong>。</p><h4><strong>AI 门槛已经很低，关键在于将人类的提问与思考能力转化为有效输入</strong></h4><p><strong>边思康</strong>：当前 AI 的使用门槛其实已经很低了，如果用户觉得难，那说明我们做模型的人工作不到位。</p><p>回想一年前，大多数模型还无法处理复杂指令，或者无法理解简单的自然语言。但顶尖模型已经能非常好地解析模糊、口语化的表达。这是一个极其公平的时代——只要你愿意尝试，就能获得强大能力。</p><p>而能否抓住这个机会，关键在于：<strong>你能否把上一个时代的 “软实力”——比如观察、提问、逻辑思考、清晰表达等，转化为 AI 时代的价值</strong>，这些其实是 AI 时代的 “硬实力”。</p><p>另外，这一轮 AI 创新和移动互联网很不一样。过去是“先有 builder 开发者，再有 creator 创作者”；而这次是“先有 creator 创作者，再有 builder 开发者”。现在任何人都可以用模型快速做出一个产品原型，创作的门槛被极大的降低了。而工程和开发者在尝试将这些 md 文件们，抽象成 Memory、MCP、Serverless 服务等工程模块。</p><p>如果你不懂技术，更要抓住这个窗口期——用你的领域知识和创造力，去定义问题、验证想法。<strong>技术能力可以通过模型实现一些，但洞察力不会</strong>。</p><h4><strong>AI 时代：需求洞察比编程技能更重要</strong></h4><p><strong>孙韬</strong>：未来的 AI 一定会更加易用。刚刚边老师也说了从模型团队出发希望自己的模型越来越易用，那我们做agent的也一样，同样希望我们的产品越来越易用。至于说编程是否是使用 AI 的基础技能，当然如果本身你懂编程，那coding类的产品一定会让你如虎添翼，但现在Coding类的产品能力已经非常强大，在需求清晰的情况下写出的代码基本很少出错，就算有错误，AI也有自我纠正的能力，所以其实我们能看到越来越多的人开始尝试vibe coding，他们不需要懂编程也能做出很有意思的应用，在这种情况下，能真正发掘出需求的人反而更有竞争力。</p><h4><strong>AI 正融入日常生活，抓住真实需求并快速验证是普通人参与的关键</strong></h4><p><strong>程治玮</strong>：对我们做模型和 Agent 产品的人来说，目标就是让应用更普及、更易用。现在 AI 已经进入穿戴设备、办公软件、生活服务等场景。只要你能抓住真实需求，并快速验证想法，就能在这个时代创造价值。门槛一定会越来越低。</p><h2><strong>迈向“可用AI”的共识与核心挑战</strong></h2><p>圆桌讨论视角多元，但关于“真正能用AI”，从几位专家的论述中，不难总结出三个共识。</p><ol><li>形态共识：<strong>任务型 Agent 优先</strong>。当前最具落地价值的AI形态是聚焦于高频、重复、规则明确任务的 Agent。它们通过明确的ROI（投资回报率）证明价值，并追求在最小化人工介入下完成闭环。</li><li>交互共识：<strong>透明化与上下文是关键</strong>。“可用”意味着用户必须能感知、验证并引导AI的行为。无论是通过高亮显示修改，还是在任务前提供充分的高质量上下文，目的都是建立可靠的人机协同信任。</li><li>趋势共识：<strong>门槛在降低，但要求在变化</strong>。AI的使用门槛正因自然语言交互和图形化意图界面而持续降低。然而，这对使用者提出了新要求：将传统的逻辑思考、问题定义能力转化为AI能理解的有效指令，成为释放AI潜力的关键。</li></ol><p>同时，所有讨论都指向一个比实现单一功能更深刻的核心挑战：<strong>我们正从开发“功能型应用”转向设计 “自主演进系统”</strong>。这要求基础设施（如面向 Agent 的 API、数据基座）、交互范式（如意图识别而非点击）、甚至数据流转方式发生根本性转变。未来的<strong>赢家</strong>，或许不是拥有最强单点模型的公司，而是<strong>能率先构建起适应 Agent 自主协作与持续进化的生态系统或基础设施的玩家</strong>。</p><p>OpenClaw的成功揭示了一个朴素的真理：在技术的早期，卓越的产品设计与精准的场景切入，足以引爆市场。它像一颗种子，预示了未来——一个由多 Agent 自主协作、在人类高阶指引下（如定义“好问题”），默默处理繁重工作的世界。Agent 元年之后，“可用AI”的竞赛才刚刚开始。这场竞赛的胜负手，不在于制造更炫目的烟花，而在于谁能为这些 AI 员工打造最坚实、最顺手的“工具箱”与“协作网络”。</p><p>你认为 2026年 “可用AI”的路该怎么走呢？欢迎评论区讨论</p>]]></description></item><item>    <title><![CDATA[Skills出世，Prompt已死？OceanBase如何为Agent构建可控思维？ OceanBa]]></title>    <link>https://segmentfault.com/a/1190000047605650</link>    <guid>https://segmentfault.com/a/1190000047605650</guid>    <pubDate>2026-02-11 16:03:37</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><strong>摘要：</strong><br/><em>在Skills成为Agent核心组件的技术趋势下，构建可靠“可控思维”体系的关键，已从优化Prompt转向系统化工程。这要求一个能统一处理记忆、知识检索与技能元数据的数据基座。OceanBase通过原生混合搜索与对结构化数据的深度支持，为Agent提供了高性能、可观测的一体化数据层，成为其实现复杂任务与持续进化的工程基石。</em></p><h2>别卷 Prompt 了！它只是你 AI 员工的“开机键”</h2><p>进入 2026 年，Skills 的爆火和 Clawdbot（OpenClaw）的横空出世，传递了一个清晰的信号：当 Agent 从酷炫的演示走向支撑业务的生产系统时，单纯依靠优化提示词（Prompt）的“艺术”，已无法满足企业对可靠性、执行力与持续进化能力的刚性需求。</p><p>这并不是说 Prompt 不再重要，而是它的角色发生了根本性转变。它从一个需要被无限雕琢、承载所有逻辑的“总指挥”，演变为一个触发器。它的新任务是：准确理解人类指令，然后高效地唤醒后方一套庞大且专业的能力系统。就像手机的开机键，按一下就可以打开各种应用功能的入口。</p><p>这个能力系统，正是现代 AI 工程的核心——一个为 Agent 打造的“可控思维”架构。</p><p>它由三个相互协作的引擎构成：</p><p><strong>记忆引擎（Memory）：</strong>确保 Agent 有“记性”，能够记住用户偏好和交互历史。这意味着它能记住重要的对话历史和你的要求，做事有头有尾，不用你每次都从头交代。</p><p><strong>知识引擎（RAG）：</strong>确保 Agent 有“实时的知识库”，能够从海量、动态的企业数据中精准检索信息，保证它给出的信息永远准确、最新，不会凭空乱造。</p><p><strong>技能引擎（Skills）：</strong>确保 Agent 有“手脚”，能够将复杂的业务操作（如数据查询、报告生成、系统调用）封装为可被随时调用的标准化模块，从“能说”走向“会做”。</p><p>Prompt、Memory、RAG、Skills 共同构成了一个能独立干活、不出错、有记性的 AI 员工，当它要完成的任务越复杂、越关键，后三者的系统化工程价值就越发凸显，Prompt 也因此必须从舞台中央退下。作为使用者，我们不再只是和模型对话的“提问者”，而是为 Agent 设计和组装能力模块的“架构师”，思考重点也从“怎么问得好”，全面转向“怎么让 AI 干得好”。</p><p>理解这种从孤立提示到系统工程的范式迁移，是我们今天话题的起点。</p><p>下面，就让我们聆听来自 1 月 31 日 OceanBase 社区嘉年华的圆桌讨论，看顶尖的实践者们如何具体拆解这些核心组件的演进与融合。</p><p><img width="723" height="486" referrerpolicy="no-referrer" src="/img/bVdnUzc" alt="" title=""/></p><h2>从 Prompt 到 Skills，RAG 还行不行</h2><p>主持人：<br/>张海立，LangChain Ambassador、OceanBase Ambassador，up主“沧海九粟”</p><p>对话嘉宾：<br/>张颖峰，RAGFlow CEO<br/>余金隆，FastGPT 负责人<br/>古思为，Co-founder of Nowledge Labs<br/>吉剑南，OceanBase AI 平台与应用负责人</p><p><strong>议题一：2026 年 RAG 生态何去何从？</strong></p><p>张海立：从去年末到今年年初，AI 领域热点频发。除了近期备受关注的 Clawdbot（OpenClaw），Skills 成为另一个重要话题。我在进行 Skills 相关实践时发现，许多 Skills 与本地文件系统紧密相关，但都离不开 RAG 体系对外部数据的召回，这对 Agent 发挥更大作用至关重要。LangChain 在构建 Agent 生态时，RAG 也是核心体验之一。想请教各位老师：在当前大环境下，您认为 2026 年 RAG 生态将如何发展？请结合各自产品进行简要介绍。</p><p>张颖峰：先说个笑话，2025 年被称为 Agent 元年，当时有朋友问我们要不要（从 RAGFlow）改名为 AgentFlow。而今年是 Agent 落地元年，我们内部也讨论要不要改名为 ContextFlow。实际上我们永远不会改名，因为我们认为“R”是核心点，单纯的 RAG 确实不足以服务 Agent，但“R”是服务 Agent 数据层的核心点。</p><p>当前 Agent 需要的是上下文（Context），它来自三方面数据：企业内部数据、工具数据以及对话过程中生成的数据。Skills 偏向工具层面，但比工具更高一层，还包含了规划（Plan）能力。Skills 本身也需要搜索——当企业内部有 1000 个 MCP 时，如何调用对应的 Tools 和 Skills 同样需要检索能力。因此 RAG 永远不会消失。</p><p>我们的布局是从 RAG 引擎向上层引擎演进。技术本身未变，但内涵发生变化：数据从简单的企业内部数据，扩展到 Agent 过程中的上下文数据。我们判断，未来所有 Agent 都是 Coding Agent，包括对工具的调用也将变成代码生成（Code Generation），需要 RTC（Run-Time Code）在沙箱中执行，访问各类 Tools 和 Skills，最终通过文件系统返回结果。这也是我们向上下文引擎方向演进的核心计划。</p><p>余金隆：我赞同颖峰老师关于 Code Generation 解决所有问题的观点，这也是我们团队的认知。无论是做 RAG 引擎还是 Workflow 引擎，都在向代码生成靠拢。</p><p>RAGFlow 不想改名，我们有点想改名字。因为近几年我们发现，做 Agent 本质是把数据使用起来，所以我们的平台主要解决数据连接层问题。过去数据分布在数据库、文档等各种结构中，现在通过大量连接器实现不同数据的连接。Skills 出现后，以前需要写代码和 Webhook 连接的数据层，现在可以通过 Skills 实现。这对国内交付场景特别有价值——国内系统数据格式不统一、缺乏标准，交付同学以前需要写大量适配代码，现在通过 Skills 将数据标准化连接到平台。</p><p>今年我们主要做两件事：一是完善连接层，二是优化 RAG 的 Retrieval 层。Retrieval 效果很大程度上取决于召回过程，不同场景的召回流程差异很大。过去需要通过 Workflow 形式搭建积木、进行意图识别分类、编写不同提示词适配不同场景，链路复杂。现在我们探索通过 Skills 这种偏语义化的方式生成代码，类似 Test-to-Code 的思路，但生成的是 SDK 代码来构建整个 Retrieval 流程，这是一个很有意思的探索方向。</p><p>古思为：关于 2026 年 RAG 相关变化，可以看到在 Coding Agent 中对代码的检索已从纯 Embedding 转向 AST（抽象语法树）、Agentic FS Graph 或 AST Graph 等方案。包括 PageIndex 项目，以及我们公司在 Haicon 2024 发布的实验性项目 OpenKL，尝试用类文件系统方法处理 Memory 和 RAG Docs。</p><p>另一个趋势是 RAGFlow 等通用内容引擎同时处理文档和 Memory。我们已发布的第一个产品是面向 C 端的 Memory 桌面 APP Knowledge MAM，动机是帮助用户在不同工具间无缝切换工作流。例如在 ChatGPT 完成 Deep Research 后，无需重新解释即可继续在 Cursor 中工作；或者当 Agent 帮助发帖子进入热榜后，可以切换到另一个 Agent 继续任务，同时保留所有交互历史和偏好设置。</p><p>吉剑南：OceanBase 面向 AI 的能力——seekdb、PowerRAG 与 PowerMem 均已开源。我们团队除了做向量数据库和 AI 应用基础设施外，也在探索面向数据库的 AI 应用，比如面向开发者工具的 Text-to-SQL 和数据库智能运维。</p><p>关于 2026 年趋势，我认可颖峰老师说的 RAG 不会消失，它和Skills、MCP处于不同维度。即使未来 Skills 和 MCP 越来越多，最终仍需通过 RAG 或某种方式召回，不能将所有 Skills 都喂给模型。</p><p>但我有不同观点：当前 RAG 仍集中在知识库领域，通过搭建 Chatbot 做问答，而问答更像玩具而非生产应用。真正的生产应用应将 RAG 融入日常工作，如销售根据集团材料为客户生成定制化 PPT或“一指禅”。未来 RAG 会结合应用反馈，反向影响数据如何切分、如何做更精细化的 Embedding，而非仅仅前置处理。</p><p><strong>议题二：AI系统中的多路检索与数据源管理</strong></p><p>张海立：感谢各位的分享，Skills 给我们带来了更多机会，能创建更多 Agent 和 RAG 应用。同时有一个概念非常重要：我们常说的 RAG 里的“R”，到底指什么？它指的是 Retrieval，是一个 “检索过程”。Retrieval 的 source可以是文件系统，可以是数据库，可以是 Web，甚至多种来源并存。</p><p>引申出第二个问题：随着 Skills 和 RAG 体系的发展，未来多路检索会越来越常见，RAG 不会消失，它将长期存在于 Agent 体系中。这样一来，数据源头的管理就变得更加重要。最简单的是把数据直接塞进软件系统，但更常见的情况可能是：越来越多的数据会落在数据库中。在这种情况下，当数据库的多路检索能力得到极大增强之后，做 RAG 应更多依赖数据库，还是在数据入库层面通过一些技巧将复杂的事情交给基础设施？</p><p>吉剑南：必然入库是最大影响，这也是 OceanBase 提出混合搜索（Hybrid Search）概念的核心。如果完全以非结构化数据或切片方式进入系统，召回效率顶天就是向量化的近似能力。去年所有 RAG 产品都在强调从非结构化数据中提取结构化数据，存为 JSON 等半结构化形式，用于前置过滤或与结构化数据一起做混合搜索。</p><p>为什么要这样做？本质上是语义理解包含两个层面：一是你问的是模糊问题，但脑子里想的是确定性答案；二是问题模糊，答案也模糊，希望召回所有相关点。大部分实践场景属于第一种。</p><p>在文档预处理时，结构化提取非常重要。例如从医疗文档或简历中提取结构化字段，召回时先对结构化数据做精确匹配，再对字段内的非结构化内容做向量检索。半结构化数据解决范围和准确性问题，向量检索解决语义理解问题。通过混合搜索模式，入库时做文档理解提取结构化数据，召回时统一检索，效率会大幅提升。数据库也应在接下来一年面向这个方向发展，我们看到 Chroma 等国外开源数据库已在往这个方向演进。</p><p>古思为：我们比较早做 Graph RAG，可能是第一个探索的团队。张老师分享的新架构与我们上一家公司做的 FusionGraph 很像。核心思想是：要让复杂 RAG 系统表现好，索引结构既要贴近知识本质，又要把特定场景的领域知识元信息投射到 Retrieve、Index、Transform 各环节做优化。</p><p>通用方法是知识后加工时做 Entity Graph 或 Semantic Graph，同时在做 IDP（Intelligent Document Processing）和 Parsing 时，对多层 folder 和复杂章节的长文档要识别 layout，涉及多模态时考虑是否转换模态。要做好这些并能演进，不要过度领域化 pipeline，而是按基本原理拆分，确保各组件能力跟上。</p><p>Database 是重要基础设施，比如 RAGFlow 的 Graph 和 Tree 结构能否原生保留、高效检索；要做 Dynamic Agents Retrieve，模型能否自然利用复杂多层结构。数据库的高性能、索引召回率和内置 Hybrid RRF 都很重要，决定系统下限。</p><p>余金隆：在交付过程中，数据源解析是基础且重要，但更重要的是召回（Retrieval）层。即使使用最简单的原始向量，只要检索词和检索语句构建得好，也能得到很好效果，只是效率较差。我们在此基础上扩展了语义化加标量方式。</p><p>但标量遇到较大问题：它不固定，用户自己也不知道需要什么标量。我们今年研究的方向是标量的动态扩展，包括用户自身扩展和模型自生成。例如给模型一些 Skills，或用户编写场景来生成场景下的标量存入数据库。当然这会引发多租户系统中成千上万标量的高效索引问题，以及渐进式生成问题——很难在预处理时生成所有标量，很多需要在检索时评估并渐进补全。在Retrieval阶段，多标量关联查询的生成方式也借鉴了 Text-to-SQL 的思路。我们希望找到通用存储方式覆盖 80% 场景，目前看语义化加标量检索加动态标量可以覆盖很多场景，所以我们没有用图，因为图是以复杂方式解决复杂问题，而 AI 时代可能有更简单的方式处理复杂问题。</p><p>张颖峰：我们现在是数据库使用者，但曾经也是数据库开发者。从纯技术角度，我非常喜欢“一边推理一边搜索”的技术方向，我称之为 Attention Engine，我认为它也是一种 RAG。DeepSeek 近期已大体实现类似方式，因显存限制不得不用内存，在推理时通过内存索引搜索内容，从外置记忆变为内置记忆。但从商业角度这条路行不通，要求检索与模型延迟极低，必须在同一交换机后，意味着只能卖一体机。因此我们仅作为调研方向。</p><p>从业务视角看，我们最早做 Infra 、做数据库时发现离业务太远，后来做 RAG 流量较大，促使我们重新思考 Data+AI 落地生态。我们的观点是：过去数据库是底座，上面写应用做增删改查；现在应用是 Agent，底座是以 RAG 为基础的组件，数据库在底层支撑 RAG 中间件。Data+AI 建设不能 AI 和 Data 各干各的，接口有时不清晰，因为中间层用 Python 实现，其好处是适应多变需求，召回策略可随时调整，不过 Python 带来的效率问题也让人头疼。AI 时代的数据底座让 Infra 人员直接触达业务，通道变短。因此中间层需要一个 Python 层适应业务多样化，一旦发现好的方式就迅速下沉到数据库解决效率问题。</p><p>我们在 2024 年底就鼓吹跨模态，但至今未落地，因为 Infra 到模型都未准备好。跨模态需要多向量搜索（Tensor Search），用多向量表示图片或文本，语义更准确、排序更准，但数据会膨胀两三个数量级，这是灾难。这需要模型、算法、Infra 共同解决挑战。因此我们需要端到端的、以 RAG 为中间层的体系，这其实就是 Agent 的数据库。</p><p><strong>议题三：Memory 与 RAG 到底有何区别？</strong></p><p>张海立：我非常认同颖峰老师提到的“端到端”。作为 LangChain 社区大使，我们主要做应用层框架，今年非常想做的一件事情是：和各个厂商比如 OceanBase seekdb一起提供真正的端到端解决方案，服务企业和个人用户，帮助他们快速构建生产级 Agent。</p><p>简单总结一下几位老师的理解：当我们面向用户提供检索能力时，会在中间层、应用层、数据库层进行多层协同优化，共性问题会逐步下沉到数据库解决。以我的个人体验为例：在最初布道时，我会给大家讲很多 RAG 的流程和算法，但从去年底开始，我更多会建议“你直接用这个数据库就好了”，因为它已经帮我们解决了很多多路检索的问题。这种 “沉淀” 是应用方和数据库厂商不断联合实践的结果。</p><p>下一个问题也与此有关：我们经常被问到Memory 和 RAG到底有什么区别？从 Memory 召回和从数据库召回有何区别？近期 Clawdbot（OpenClaw）从文件系统读取，到支持 PowerMem 直接接入进行更有效的内存管理。想请教剑南老师，这里做了什么特别工作？以及各位如何理解 Memory 与 RAG 的关系？</p><p>吉剑南：Memory 是为让大模型更像人而引入的。如果查询的都是客观事实且不存在人与人之间的理解，RAG 已能解决问题。但问题在于每个人对客观事实的理解和描述不同，加上人有记忆曲线，希望记住昨天强调的内容——这些内容虽非客观事实，但是主观认可。</p><p>例如每个人都有一个叫“老王”的朋友，随着时间推移这个“老王”可能已变化，但在记忆中一直叫“老王”，这时 RAG 搞不定，但 Memory 能搞定，因它会更新对“老王”的认知。“老王”是一个知识吗？并不是，因此，Memory 的核心是个性化和千人千面。</p><p>无论是 RAG 还是 Memory，整体是搭建一整套解决方案面向 Agent 为业务带来价值，不应区分该用 RAG 还是 Memory，而应思考如何组合好共同为业务赋能。</p><p>古思为：我们目前做 Memory，之前做 Graph RAG。Memory 有广义和狭义之分，狭义指 Agent 或 LLM 需要检索的更外部的 Memory，它确实是特殊的 RAG，特殊在几个方面：</p><p>原始数据是持续的 message thread。<br/>知识需求是时序性的（temporal），包含两个时间维度：信息创建时间、事件/事实时间。<br/>时序性存在一个问题，遗忘（forget）是 feature 而非 bug，需结合时间、访问频率和正反馈影响 Retrieval。<br/>条目层面有 category 和不同类型，取决于 Memory 目的，可能需要schema 区分 ephemeral（瞬时）和 permanent（永久）。<br/>不同结构间需要 transform 关系，可在 Retrieve 或写入过程触发 event，或周期性处理（类似大脑做梦处理记忆）。<br/>多租户和 sessional scoping。</p><p>如果做细会发现与典型 RAG 差别很大，但二者又有很大 overlap。RAG Engine 可以处理 Memory，Memory Engine Service 项目也会处理文档，界限会变得模糊。</p><p>余金隆：我理解 Memory 算是广义 RAG 的一种，无非也是数据 I/O、Pipeline 处理、特殊数据结构，比较偏个性化。</p><p>从产品角度看，Memory 目前 C 端个性化场景用得较多。在任务流中，用户提 Memory 的还不多。在技术实践中，Mem0 有工具调用的 Memory 用于长 Agent 任务，但看其架构有点像 Context Engine，与 Memory 又不太一样。所以感觉 Memory 还是 RAG 的一种特殊 Pipeline 形式，没有太大区别，可能实时性比 RAG 更高。</p><p>张颖峰：单从技术角度而言，Memory 与 RAG 确实没有本质区别，都是 Retrieval。但重要的是 Memory 如何发挥作用，这是在快速变化的。</p><p>我在分享 Context Engine 时提到三类数据：企业内部数据、Tools 数据、Agent 使用过程中生成的数据。但它们存储在两个地方：RAG 专有区域和 Memory 专有区域。可见所有大模型生成的内容都要存到 Memory，包括 Skills 的元数据（Skills 本身数据存文件系统）。</p><p>怎么存、什么时候存、什么时候取，这些设计点很难决策。例如生成 Plan 是否存入 Memory？作为 Plan Cache 有价值，但如果 Human-in-the-loop 干预修改了 Plan，应如何存储？以后如何根据 Memory 数据抽取内部 MCP Tools 的 Skills？这些都是新问题。</p><p>从 Infra 角度，RAG 和 Memory 没区别；但从使用者角度，Memory 是重要的基础设施，解锁了大量场景。因此 Memory 项目很多（如 Mem0、MemU），但对 Memory 区域的定义（数据库该有哪些表）尚未完全一致，反映 Agent 到底需要什么样的 Memory 还在进化中。不过整个 Agent 体系需要哪些组件，已进入收敛期，就是 Context。</p><p><strong>议题四：Skills 开发实践与推荐</strong></p><p>张海立：各位老师都在做 Workflow、数据库或融合方案，是否开发了自己的 Skills 帮助用户更好地使用产品？如有请推荐，如无请设想会开发什么样的 Skills 服务开发者？</p><p>张颖峰：抱歉我目前没有特别好的推荐。我比较关注如何针对大量内部 MCP Tools 生成对应 Skills，这需要一个专门的 Agent 平台来实现。我的观点是：未来 Agent 平台可能没有统一标准，所有都是 Coding Agent，但特定 Agent（如低代码、无代码、Workflow）可能因良好交互而便于生成 Skills。</p><p>余金隆：我们内部 Skills 用得很多，运营和 SEO、GM 等场景一大把。产研团队用得不算多，主要是代码开发和 Review。交付团队用得特别多：面向用户时遇到各种问题，排查系统后沉淀为 Skills，辅助交付和运维。因此，内部有句玩笑话“交付同学比研发同学更懂系统”，他们做了二十多个 Skills，涵盖工作流搭建、问题排查、RAG 优化等。总体感觉 Skills 更像自然语言工作流，虽更抽象，但目前大部分还是偏自然语言的 Workflow。对非开发人员在生产流程上比较友好。</p><p>古思为：我们维护基于 Skills 的插件，在 Skills 发布第二天就推出了 Cloud Code 插件支持。早期没有 Skills 时，我们只能基于 MCP，让插件调用 MCP 的 Custom Command 触发操作，用 Hook 实现功能。</p><p>后来发现 MCP 规范了工具调用，但有两个地方不如 Skills：</p><p>1.MCP 有 Prompt 抽象，实现为斜杠命令可主动调用类似 Workflow 的东西，但并非所有 Client 都实现，我们要做很多额外工作。Skills 天然支持主动说和自动做。</p><p>2.Skills 的打包方式让不同工具间组合更灵活。我们内部将 Skills 从 MCP 换成 CLI 后变化很大。例如让 Agent 做 Memory 复杂更新查询时，MCP 需要多轮次，即使 interleave 也不够好。但 CLI 可以动态组合 Linux Shell Pipeline，在一个 turn 里精确完成复杂操作，且内部 CLI/Script 可以 self-contain，打包给用户后自然享受复杂能力。</p><p>调试经验方面，Skills 比较通用，容易用不同平台测试。我们发现一个有意思的案例：Skills 对应的工具有很多具体选择，如何调优模糊的问题？我们的做法是用最聪明的 Agent 做 honest 的复杂 long run 评估，像跟客户聊天一样告诉我们如何改进。有时需要更端到端看细节，不得不自己server model，在 template 解析过程中用小模型发现工具复杂类型定义的问题，虽然其他模型能克服，但会影响 performance。</p><p>吉剑南：OceanBase 内部沉淀了很多 Skills。Skills 本质是最佳实践，告诉大模型最佳实践是什么，而最佳实践无非两类：一是提升工作效率的工程类（如 Cursor 的 rules），二是业务类 Skills。</p><p>Skills 也可以用在 RAG 上，RAG 效率和准确性今天跟两个因素相关：相似度和 Top K。但大家有没有想过，召回前 Top K 和相似度有时不能完全指定，需要反复调，知识库又在更新。如果针对不同的业务实现写不同的 Skills，例如当需要某类数据时，希望相似度设到什么位置、Top K 设到什么位置，根据召回结果动态调整，这就变成了一个 Skills。这是 RAG 搞不定的，需要根据具体召回内容判断，是 RAG 的最佳实践。</p><p>之前大家可能想是否把 RAG 数据放 Skills 里就不用召回了，而我觉得 Skills 是对 RAG 的增强。关于 OceanBase 的 Skills，我们是有准备的，包括 seekdb 的研发人员今天也在现场，未来应该会有更多相关的 Skills 开放出来。</p><p>张海立：非常感谢各位老师精彩分享。简单总结：RAG 还“行”！只要理解 RAG 的 R 是 Retrieval，有 Memory、传统数据库等多种数据来源，随着各位老师所在厂商的努力，多路检索能力、应用层提升、流程算法优化都在推进。相信 2026 年RAG会有更大发展。</p><h2>Agent 可控思维的工程实现：从分散工具到一体化基座</h2><p>本次圆桌讨论，为我们清晰地勾勒出 2026 年 AI 工程化的演进路径。专家们的共识指向一个明确的结论：构建可靠、可用的 Agent ，其核心不再是追求某个单一组件的极致，而在于如何系统性地整合记忆（Memory）、检索（RAG）与技能（Skills），形成一个协同的“可控思维”体系。</p><p>综合专家观点，这一体系的发展呈现出三大趋势。</p><p><strong>01 RAG 不会消失，反而会变得更加基础与核心</strong></p><p>它的内涵正在从狭义的文档问答，扩展为 Agent 对所有上下文数据的 Retrieval 能力——无论是企业内部文档、数据库中的业务数据，还是工具（Tools）与技能（Skills）的元数据，都需要被高效检索与调用。</p><p>未来的 RAG 将深度融入工作流（Workflow），根据应用反馈动态优化，并与混合搜索（Hybrid Search）等技术结合，实现更精准的“语义理解+精确过滤”。</p><p><strong>02 Memory 与 RAG 边界模糊，融合为数据层</strong></p><p>从技术基础设施（Infra）视角看，Memory 与 RAG 的本质都是数据的存储与召回。</p><p>二者的区别更多在于数据特性和使用场景：Memory 更侧重于个性化的、时序性的对话与状态记忆；RAG更侧重于客观的、相对静态的知识存储。但在服务 Agent 时，它们共同构成了支撑“上下文（Context）”的数据层。一个优秀的底层平台，应能一体化地管理这两种数据范式。</p><p><strong>03 工程复杂度下沉，呼唤一体化数据基座</strong></p><p>当应用层通过 Skills 和灵活编排满足业务多变需求时，通用的、性能瓶颈性的复杂度会自然下沉到底层基础设施。无论是多路检索、混合搜索，还是海量 Skills 元数据的管理，都对底层数据平台的能力提出了更高要求。</p><p>专家们指出，未来的理想路径是依赖一个强大的数据基座，它能原生支持向量检索、关系查询与结构化记忆，从而让开发者从繁琐的多系统集成工作中解放出来，更专注于 Agent 本身的业务逻辑。</p><p>因此，构建“可控思维”的终极路径，在于选择或打造一个能够统一承载 Agent 记忆、知识与状态的数据基座。这样的基座，正如专家们在讨论中多次暗示的，能够将 Memory 的个性化记录、RAG 的海量知识检索、以及支撑 Skills 运行的业务数据，融于一个简洁、高效、一致的系统中。它让 Agent 的“思维”过程变得可管理、可观测、可优化。</p><p>最终，Prompt、RAG、Skills、Memory 这些活跃于应用层的概念，都将在这样稳固的基座之上，更好地各司其职、协同工作，共同将 Agent 从“聪明的对话者”转变为“可靠的业务执行者”。这标志着 AI 应用开发正式进入系统工程时代，而坚实的数据基础设施，是这一切得以实现的基石。</p><p>欢迎访问 OceanBase 官网获取更多信息：<a href="https://link.segmentfault.com/?enc=UZcfM%2FK5MJOuus5n%2BgPWaw%3D%3D.HLs2zS2r5xc9cOOzgY438Qqu3IBkJpF92UrHZ26l6Mw%3D" rel="nofollow" target="_blank">https://www.oceanbase.com/</a></p>]]></description></item><item>    <title><![CDATA[从通用智能到场景实战：如何定义好用的「Voice Agent」？ RTE开发者社区 ]]></title>    <link>https://segmentfault.com/a/1190000047605653</link>    <guid>https://segmentfault.com/a/1190000047605653</guid>    <pubDate>2026-02-11 16:03:03</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在过去的一年里，Voice Agent 的开发者们经历了一场集体“祛魅”。一个被反复提及、逐渐成型的行业共识是：<strong>“Evals are back”（测评回归）。</strong></p><p>这是因为行业遇到了共同的瓶颈：基础模型在通用学术榜单上卷得难解难分，一进到真实的业务电话里，表现往往不如人意。一个能写出精美诗歌的 Agent，可能听不懂带口音的“退款”请求，或者在用户情绪激动时不知道该如何安抚。这就带来一个更现实的问题：<strong>在充斥着打断、噪音和情绪波动的真实通话中，我们到底需要什么样的 Voice Agent？</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047605655" alt="" title=""/></p><p>最近，<strong>美团、声网 与 Xbench</strong> 三方联合构建了一个名为 <strong>VoiceAgentEval</strong> 的基准测试，主要解决现有测试方法的三个关键问题：数据集多样性不足、用户模拟不真实、评估指标不准确。</p><p>测试结果表明，大语言模型在外呼对话场景中已经达到了相当的基础能力，并展现出了各自的适用性。这说明，Voice Agent 的发展已经跨过了“参数为王”的阶段，进入了“场景适配”的新时期。</p><p>论文链接： <br/><a href="https://link.segmentfault.com/?enc=tkprgIQpHKdjmJvoRqphWg%3D%3D.sdIprlsJEcxrprrtu1l%2FfNlIuaEqqMPTMT%2Fo96OV2QkKkWnd0gJIUTO9wxbVoIL7%2FdahV1HOVM5W%2BD6Bz5%2FMdQ%3D%3D" rel="nofollow" target="_blank">https://xbench.org/reports/zmbbhdtfc5ui5qx5xjgquusj</a></p><h2>VoiceAgentEval 在做什么</h2><p>在人机对话场景中，用户不仅关注 Agent 是否提供了正确的反馈，如解答疑问、完成任务等；良好的、更像真人间交互体验也是非常重要的评估指标。</p><p>因此，区别于传统测评， VoiceAgentEval 不再执着于考察 Agent 到底“会不会说话”，而是同时从“有没有说对”和“说的好不好”两个层面来评估：</p><ol><li><strong>任务流程遵循度（Task Flow Compliance，TFC）：</strong> AI 客服是否按照业务流程办事，是否真正解决用户的问题</li><li><strong>一般交互能力（General Interaction Capability，GIC）：</strong>  AI 客服的响应是否自然，回复内容是否与谈话主题相关，是否能响应用户的负面情绪等。</li></ol><p>换句话说，这套评估不是在挑“谁最聪明”，而是看谁<strong>最适合在真实通话场景下干活</strong>。</p><p>在 VoiceAgentEval 中，这两类能力通过三个紧密衔接的设计进行评估：</p><p><strong>基准构建（Benchmark）</strong></p><p>从真实外呼业务中抽象出 6 大商业领域（客服、销售、招聘，金融风控、调研以及主动关怀）、 30 个子场景，包括银行投诉、电商退货、面试邀约等在真实世界里出现频率最高的情况。丰富了数据集的多样性与种类，覆盖业务中多样的场景，也就是现实中最容易出现问题的对话。</p><p><strong>用户模拟器（User Simulator）</strong></p><p>本次测评用 LLM 模拟了 5 个性格、背景、沟通风格都不相同的用户，结合 30 个真实业务的子场景，形成 150 种情况下的虚拟用户对话评估。这些虚拟用户有的态度友好，有的犹豫不决，甚至有的情绪抗拒。通过用户模拟器，输出每一个 Agent 在这 150 种真实场景中的 TFC 和 GIC 得分并加权计算出最终测试结果，能够有效的评估 Agent 在复杂场景下遵循任务流程与交互能力的平衡程度。</p><p><strong>评估方法（Evaluation）</strong></p><p>VoiceAgentEval 通过文本和语音，对 Agent 进行 TFC 和 GIC 的双维度评估</p><p>在 TFC 层面，重点关注：</p><ul><li>按业务流程推进对话</li><li>最终把事情“办成”</li></ul><p>在 TIC 层面，评测关注的是：</p><ul><li>在口音、噪音或打断下，是否还能听清关键需求</li><li>回应是否自然、简洁、不制造额外负担</li><li>在被打岔、被质疑时，是否还能保持对话连贯</li></ul><p>也就是说，这套评测是在模拟一通真实业务电话，看看它<strong>能不能把事办完、还能不能让人愿意继续聊</strong>。</p><p>需要说明的是，VoiceAgentEval 并非在离线环境中对模型进行脚本化测试，而是基于声网在实时语音与对话式 AI 领域长期积累的工程能力，搭建出一套真实可运行的 Agent 架构来完成评测流程。因此，评测中的语音交互、流程切换与被打断后的恢复，均通过一条的真实 Voice Agent 链路完成，而非通过静态对话拼接。这也是 VoiceAgentEval 能够在实验条件下逼近真实业务通话复杂度的基础。</p><h2>测评启示：没有最好，只有最合适</h2><p>在这套实时语音交互评测环境中，测试结果并不意味着 Agent 的绝对高低，而是它们在<strong>特定外呼任务设计、用户模拟方式以及评分权重设定</strong> 下所呈现出的行为差异。</p><p>即便如此，这些差异依然为开发者理解模型在高度贴近真实外呼场景中的“行为倾向”提供了一张有价值的参考图谱：</p><ul><li><strong>均衡的“多面手”——</strong> 在“完成办事流程”和“闲聊”之间取得了极佳的平衡。它们既能按流程推进业务，又能顺滑地接住客户的闲聊。如果你需要一个适应性强的通用型 Agent，它们值得优先考虑。</li><li><strong>严谨的“执行者”——</strong> 流程合规性得分高但交互能力相对低一些。就像一个处理金融业务、一丝不苟的银行柜员，绝不随意发挥，但也绝不出错。对于合规性要求极高的严肃场景，它是安全的选择。</li><li><strong>温情的“倾听者”——</strong> 在交互体验上表现优异，极善于安抚沟通，提供情绪价值。如果你的场景是心理咨询或陪伴，它可能比那些“死磕流程”的模型更懂用户的心。</li></ul><p>不仅在外呼场景，随着 Voice Agent 越来越多地走向 AIoT、情感陪伴等日常生活场景，对交互的评测，也正在从“是否听清需求、是否能顺畅对话”，延伸到更底层的环境与语境理解能力。</p><p>在这一层面上，评测维度将不可避免地扩展到对掌声、敲门声等声学事件的感知，对所处环境的声学场景判断，以及对方言、间接表达和语境变化的识别。这些能力决定的，不只是一次对话能否完成，而是 Voice Agent 是否具备在真实环境中持续交互的基础条件。</p><h2>共同的目标：从探索走向落地</h2><p>这套评测体系的发布，其意义不在于分出高下，而在于展示了 Voice Agent 进化的必经之路：<strong>场景 + 技术的双重融合</strong>。</p><ul><li><strong>场景上：</strong> 评测设计基于美团外呼业务中长期积累的真实场景经验与典型问题抽象而来，使得测试不再停留在理想化设定中，而是带有明显的“泥土味”。</li><li><strong>技术上：</strong> 通过声网的音视频技术积累和架构支持，验证了一套可复用的“生产级”技术栈。</li></ul><p>对于整个开发者社区而言，这传达了两个积极的信号：</p><ol><li><strong>选型更从容：</strong> 我们不必再盲目追求“最强”模型，而是可以根据业务需求（是重逻辑还是重体验）找到最匹配的那一块拼图。</li><li><strong>研发更聚焦：</strong> 开发者不必重复造轮子，可以将宝贵的精力投入到对业务逻辑的打磨上。</li></ol><h2>结语：共建行业的“度量衡”</h2><p>AI 的进化速度太快，单打独斗的时代已经过去。</p><p>我们解读这篇论文，是希望所有 Voice Agent 的从业者关注这种“场景化测评”的趋势。VoiceAgentEval 给出了外呼场景的一种答案，更像是一次示范：如何把一个具体业务，拆解成可被复用的评测单元。</p><p>当 Evals 从“纸上谈兵”回归到“实战演练”，当底层的实时交互框架逐步成熟，Voice Agent 才有可能真正走出实验室，接受千行百业的复杂检验。这扇门是否能被真正推开，最终取决于行业能否持续围绕具体场景，持续形成可被复用、可被讨论、也可被不断修正的共同度量。</p><p>参考链接</p><p>xbench 官网： <br/><a href="https://link.segmentfault.com/?enc=TnbJ0NY8azxf1kONRnu7vQ%3D%3D.KhJbJxZluNEzjvpsqHpLsOT%2BlcgqYC2N3UJeJBwvS9wuTaLpslllTEWnzO11G2EU" rel="nofollow" target="_blank">https://xbench.org/VoiceAgentEval</a> </p><p>新闻稿：<br/><a href="https://link.segmentfault.com/?enc=8vFuhUkgC2UgSsIIOpq0%2BQ%3D%3D.77X%2FGy1OtpeDB5QbfTs20B4Q3zEHACH7AMNWjxqTWcIFjmLK%2FAdlAEKqnCJdl2v5cbOPozfyK%2BJ0XXzSiNByvg%3D%3D" rel="nofollow" target="_blank">https://xbench.org/reports/zmbbhdtfc5ui5qx5xjgquusj</a></p><p>声网对话式 AI 引擎：<br/><a href="https://link.segmentfault.com/?enc=dKSgoASr8dqHxWjQzBxXpQ%3D%3D.2HMfesnI6pNH4Hl4aMpMaLv%2FuCOEy%2Bbo5y0FHTrRpF3575VdUJzWzfW4uxMMgzQX" rel="nofollow" target="_blank">https://www.shengwang.cn/ConversationalAI/</a></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047605656" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047605657" alt="" title="" loading="lazy"/></p><p><a href="https://link.segmentfault.com/?enc=RoIq7JDyMEjvrDxGFeQ3Bg%3D%3D.UfWQCU8M4Mo0n752cXfeqq%2FH2Op6fmAITv0IsXWIg8o%3D" rel="nofollow" target="_blank">阅读更多 Voice Agent 学习笔记：了解最懂 AI 语音的头脑都在思考什么</a></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047605658" alt="" title="" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[一款中后台方向的低代码可视化搭建平台 织信informat ]]></title>    <link>https://segmentfault.com/a/1190000047605672</link>    <guid>https://segmentfault.com/a/1190000047605672</guid>    <pubDate>2026-02-11 16:02:06</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>前言</h2><p>在如今快速迭代的软件开发环境中，如何提升前端开发效率、降低重复劳动，成为许多团队关注的核心问题。低代码平台正是在这种背景下应运而生，它通过可视化拖拽、逻辑编排等方式，让开发者甚至非技术人员也能快速搭建出功能完整的页面或系统。织信Informat 正是这样一款专注于中后台场景的低代码可视化搭建平台，它不仅支持免费体验，还提供了高度灵活的扩展能力，真正做到了"让搭建更简单，让开发更高效"。</p><h2>项目介绍</h2><p>织信Informat 由前平安项目交付（后出来创业）团队打造，目标用户主要是面向企业内部管理系统、运营平台、数据看板等中后台（如ERP/MES/SRM）应用场景的开发者。平台支持从零开始创建项目、页面和组件，并通过图形化界面完成复杂的交互逻辑与接口对接。值得一提的是，织信Informat 不仅可以本地部署使用，还能通过微前端框架轻松嵌入到已有的 Vue 或 React 项目中，极大降低了技术栈迁移的成本。</p><h2>项目功能</h2><p>1、项目管理：支持主题色、菜单布局、系统 Logo、面包屑等基础配置，并内置完整的 RBAC（基于角色的访问控制）权限体系。</p><p>2、页面搭建：提供可视化拖拽编辑器，支持页面主题设置、组件布局、样式配置、事件流编排及接口调用。</p><p>3、权限控制：细化到项目、页面、菜单乃至按钮级别的权限分配，确保不同角色看到的内容和可执行的操作精准可控。</p><p>4、自定义组件：当平台内置的 1000+ 组件无法满足需求时，开发者可上传自研组件，平台在线编译后即可在编辑器中使用。</p><p>5、接口管理：统一维护 API，支持 GET/POST/PUT/DELETE 等请求方式，可配置全局拦截器、动态参数传递及返回结构处理。</p><p>6、事件流引擎：通过图形化逻辑编排，实现组件联动、显隐控制、禁用状态切换、路由跳转、接口调用等复杂业务逻辑。</p><p>7、多环境发布：支持 STG（测试）、PRE（预发）、PRD（生产）三套环境，页面需发布后才对外可见。</p><p>8、版本回滚：已发布页面支持一键回滚至上一版本，保障上线稳定性。</p><p>9、微服务集成：通过微前端方案，可将页面无缝嵌入传统 Vue/React 项目中。</p><h2>项目特点</h2><p>开箱即用：提供完整中后台解决方案，无需从零搭建基础架构。</p><p>灵活集成：既可作为独立系统使用，也可作为子应用嵌入现有工程。</p><p>权限精细：RBAC 模型覆盖项目、页面、操作各层级。</p><p>逻辑可视化：事件流机制让复杂交互不再依赖硬编码。</p><h2>项目技术</h2><p><strong>前端：</strong></p><p>基础UI库选型：Vue</p><p>基础UI库选型：Element-UI</p><p>开发语⾔标准：使⽤ES5、ES6、ES7语⾔标准</p><p>语⾔规范检查：使⽤eslint对代码进⾏检查</p><p>⼯程依赖管理：使⽤npm管理⼯程依赖</p><p>⼯程打包⽅式：使⽤Webpack4</p><p>浏览器兼容控：使⽤babel7，将ES6、ES7语法转换为ES5交付，postcss进⾏浏览器⾃动样式兼容</p><p><strong>后端：</strong></p><p>开发语⾔选型：JAVA(jdk11)</p><p>基础框架选型：SpringBoot2</p><p>数据库：Postgres13或以上</p><p>缓存：Redis 5</p><p>文件存储服务：支持符合 S3 标准的文件对象服务（如：腾讯云 COS、阿里云 OSS、Amazon S3、Minio等）</p><p>消息队列服务：RabbitMQ</p><p>服务器监控：SpringBoot Admin</p><p><strong>项目目录清晰划分为：</strong></p><p>项目访问端（用户侧）</p><p>可视化编辑器（开发侧）</p><p>内置组件物料库</p><h2>项目体验</h2><p>在线体验地址：<a href="https://link.segmentfault.com/?enc=PUm2emIqhPYqIZJc3ZD6dQ%3D%3D.cNb6ui2rhCUEbq4jc9OdMk6y6zQq6ILXFjqzDWoE%2FSeTwaJxdtJKycKxHcwSOCR9" rel="nofollow" target="_blank">https://demo.informat.cn/workbench/app</a>，也开放了产品文档：<a href="https://link.segmentfault.com/?enc=%2Bo22Cno2BzftnKAbZMkL0w%3D%3D.aHJQPTAqbD8SxxGwL%2B7YRoeizXThqnMsifBZx%2FggXh0kt%2BohLnvPsAYm%2BfIQpXrQ" rel="nofollow" target="_blank">https://next.informat.cn/doc/index.html</a>，方便大家快速上手。</p><h2>项目效果</h2><p>实际使用 织信Informat 搭建页面的体验相当流畅。无论是简单的表单页还是包含多组件联动的数据看板，都能在几分钟内完成原型搭建。配合其强大的事件流和接口配置能力，很多原本需要前后端联调的功能，现在前端即可独立闭环实现。</p><h2>项目部署说明</h2><p><strong>部署逻辑图</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047605674" alt="image.png" title="image.png"/></p><p><strong>浏览器支持</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047605675" alt="image.png" title="image.png" loading="lazy"/></p><p><strong>安装所需的服务器和组件</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047605676" alt="image.png" title="image.png" loading="lazy"/></p><p><strong>服务器推荐配置</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047605677" alt="image.png" title="image.png" loading="lazy"/></p><p>提示：超过1000并发的需求，按照200~1000的配置倍增。上述配置中的数据盘大小可根据实际业务存储的数据量调整。</p><p><strong>license和部署密钥</strong></p><p>在进行私有化部署之前需要申请部署密钥，部署密钥会绑定服务器的MAC地址，更换服务器后需要重新申请。在系统安装成功后，使用部署密钥作为密码登录织信企业级后台。在企业级后台中使用license可创建团队。license中会限制团队的名称、创建应用数量、成员数量、到期时间等信息。</p><p><strong>总结</strong></p><p>织信Informat 并没有盲目追求"零代码"，而是聚焦于"低代码 + 高扩展"的平衡点——在大幅减少重复性工作的同时，保留了专业开发者的控制力和灵活性。</p><p>对于正在构建或重构中后台系统的团队而言，它既能加速 MVP 验证，也能支撑长期业务演进。随着专业版逐步上线图片云、数字大屏、工作流等高级能力，织信的生态价值将进一步凸显。</p>]]></description></item><item>    <title><![CDATA[从政务系统到金融核心 核心优势凸显 JoySSL剖析国密SSL证书在高需求场景中的不可替代性 完美的]]></title>    <link>https://segmentfault.com/a/1190000047605683</link>    <guid>https://segmentfault.com/a/1190000047605683</guid>    <pubDate>2026-02-11 16:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>当前全球网络空间竞争格局正在加速演变，密码技术作为保障网络与信息安全的核心支柱和关键基础，其自主可控性已被提升至国家战略层面。国内独立研发的商用密码算法体系，正是这种战略思维的具体体现。在此等背景下，基于SM2算法开发的国密SSL证书，正在从满足特定合规需求的单一技术方案，转变为数字化转型安全保障的关键基石，同时支撑自主可控的网络信任体系建设。JoySSL技术总监指出，国密SSL证书的推广与应用不仅是技术选择，更是对国家信息安全、产业保障以及数据主权的积极践行。国密证书的核心价值在于，能够为具备高安全性、强监管要求以及自主控制需求的场景，带来一整套兼容国内密码法规、性能优越且具有自主信任根的端到端的安全通信解决方案。</p><p><img width="723" height="479" referrerpolicy="no-referrer" src="/img/bVdnUzx" alt="" title=""/></p><p><strong>核心优势 国密证书展现多重战略价值</strong></p><p>国密SSL证书采用SM2算法替代国际通行的RSA/ECC、SHA-256和AES算法，形成了多方面战略优势。首先，自主构建的国家密码信任体系，其信任链完全依托国内自主创建的数字证书根信任体系，避免了对国外密码技术和根证书系统的依赖。</p><p>自主研发的国密证书拥有更高安全性能的算法优势，特别适用于高并发场景或资源有限的移动终端环境，算法均由国家密码管理局设计并正式认可，安全性可满足当前及未来阶段应对高强度计算攻击的需求。同时，国密SSL证书已深入兼容主流浏览器、与各种软硬件设备，具备生态适配优势。</p><p><img width="723" height="477" referrerpolicy="no-referrer" src="/img/bVdnUzy" alt="" title="" loading="lazy"/></p><p><strong>应用场景 关键领域的不可替代与前景</strong></p><p>国密SSL证书多应用于政务及公共服务领域，包括相关部门官方网站、在线政务服务平台等，这些平台需要全面应用国密算法，确保通信加密及身份认证的安全性，实现跨部门数据共享，加强数据传输安全性和管控能力。</p><p>网上银行、移动金融以及供应链平台等金融业具体场景，是推广国密算法的核心地带，旨在保障交易数据的安全与合规性。金融行业对通信安全要求极高，国密证书提供了符合监管要求的国产自主解决方案。</p><p>特定的商业领域在运营时，往往涉及大量敏感个人信息，通过国密算法的部署，既满足了国家合规要求，同时展现了更高等级的安全保障能力。</p><p><img width="723" height="480" referrerpolicy="no-referrer" src="/img/bVdnUzz" alt="" title="" loading="lazy"/></p><p><strong>解决方案 自主可控与全球兼容双向发展</strong></p><p>面对不同群体多元化需求，国密SSL证书不仅需要专业，同时配备还需灵活，方能适应市场需求。JoySSL以双证书部署为解决方案，既满足国密改造要求，又符合用户日常访问需求，确保证书符合主流浏览器与设备的兼容，实现安全合规与用户体验双向平衡。</p><p><strong>创新之道 以算法构建自主可控安全体系</strong></p><p>国密SSL证书的普及与应用，是国内构建网络安全自主体系的重要举措，不仅是算法技术层面的突破，更确保了在数据安全领域的话语权。随着数字化时代的到来，国密SSL证书将在更多重要领域发挥关键作用。选择国密证书，亦是顺应未来发展的重要抉择。</p>]]></description></item><item>    <title><![CDATA[不会写提示词？这个神器让我5分钟做出贪吃蛇 程序员小崔日记 ]]></title>    <link>https://segmentfault.com/a/1190000047605296</link>    <guid>https://segmentfault.com/a/1190000047605296</guid>    <pubDate>2026-02-11 15:08:57</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>🚀 从一句"做个贪吃蛇"，到完整游戏代码</h2><h3>------ PromptPilot 实战体验</h3><p>最近在研究提示词工程（Prompt Engineering），发现一个挺有意思的工具：</p><p>👉 <strong>PromptPilot（火山引擎出品）</strong></p><p>官网地址：\<br/><a href="https://link.segmentfault.com/?enc=rbG6yrjm6XA%2BjowxVA8dGA%3D%3D.h%2BBZzUD6mlmN%2BejGwn7Pb1JBBUbyE6yvh51nYm4dTk7l0KGd2DVHKtRtTszp3OZG" rel="nofollow" target="_blank">https://promptpilot.volcengine.com/</a></p><p>它的定位很明确：</p><blockquote>把模糊需求，转化为结构化、可执行的 Prompt。</blockquote><p>听起来有点抽象？</p><p>那我们直接实战。</p><hr/><h2>🎮 案例：做一个贪吃蛇小游戏</h2><p>我只输入了一句话：</p><blockquote>我想做一个贪吃蛇游戏。</blockquote><p>看看它能帮我优化到什么程度。</p><hr/><h3>第一步：注册登录</h3><p>进入官网，注册登录即可。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047605299" alt="" title=""/></p><p>整体界面非常干净，没有复杂引导，上手成本很低。</p><hr/><h3>第二步：输入原始需求</h3><p>输入：</p><blockquote>我想做一个贪吃蛇游戏。</blockquote><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047605300" alt="" title="" loading="lazy"/></p><p>是不是很随意？\<br/>对，故意的。</p><p>因为我们想测试：</p><p>👉 <strong>模糊需求能被优化到什么程度？</strong></p><hr/><h3>第三步：生成优化后的 Prompt</h3><p>点击生成后，PromptPilot 会：</p><ul><li>拆解任务</li><li>明确约束</li><li>增加输出格式要求</li><li>添加结构化变量</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047605301" alt="" title="" loading="lazy"/></p><p>你会发现：</p><p>从一句简单需求\<br/>变成了一段完整、可执行、逻辑清晰的提示词。</p><p>这一步，本质上是在做：</p><blockquote>"提示词工程结构化改写"</blockquote><hr/><h3>第四步：验证 Prompt（评分模式）</h3><p>点击：</p><p>👉 验证 Prompt\<br/>👉 选择评分模式</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047605302" alt="" title="" loading="lazy"/></p><p>系统会从多个维度评分：</p><ul><li>清晰度</li><li>完整度</li><li>可执行性</li><li>逻辑严谨性</li></ul><p>这一点对新手特别友好。</p><p>因为大多数人根本不知道：</p><p>👉 自己写的 Prompt 到底好不好。</p><hr/><h3>第五步：自动填充变量</h3><p>点击自动生成变量。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047605303" alt="" title="" loading="lazy"/></p><p>⚠️ 右侧默认模型是豆包。</p><p>我个人体验一般，所以我主要是拿优化后的 Prompt，复制出来用在别的模型上。</p><p>关键点在这里：</p><blockquote>PromptPilot 的核心价值是"提示词优化"，不是最终输出。</blockquote><hr/><h3>第六步：把 Prompt 给编程工具</h3><p>我使用的是 ChatGPT。</p><p>把优化后的 Prompt 直接粘贴进去。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047605304" alt="" title="" loading="lazy"/></p><p>输出结果明显比直接说"做个贪吃蛇"要规范很多：</p><ul><li>有完整逻辑</li><li>有异常处理</li><li>有游戏循环结构</li><li>有键盘控制</li><li>有碰撞检测</li></ul><p>代码结构也更清晰。</p><hr/><h3>第七步：在 PyCharm 运行</h3><p>复制代码 → PyCharm → 运行。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047605305" alt="" title="" loading="lazy"/></p><p>成功运行。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047605306" alt="" title="" loading="lazy"/></p><p>当然，中间还是有调试。</p><p>⚠️ 重点：</p><blockquote>好的 Prompt ≠ 一次成功\<br/>但它能显著减少无效修改</blockquote><hr/><h2>🧠 PromptPilot 到底解决了什么？</h2><p>很多人误解提示词工程。</p><p>他们以为只是：</p><blockquote>多写一点字</blockquote><p>其实真正的问题是：</p><ul><li>需求是否拆解清晰？</li><li>输出格式是否约束？</li><li>是否定义边界条件？</li><li>是否指定技术栈？</li><li>是否说明异常处理？</li></ul><p>PromptPilot 做的事情，本质上是：</p><blockquote>把"人脑里的隐性需求"显性化。</blockquote><p>这一步对于企业尤其重要。</p><p>因为企业场景往往是：</p><ul><li>需求复杂</li><li>输出必须可控</li><li>结果要稳定</li></ul><hr/><h2>🎯 它适合谁？</h2><p>✅ 提示词新手\<br/>✅ 想提高AI输出质量的人\<br/>✅ 企业内部做AI落地的团队\<br/>✅ 做自动化流程的人</p><p>不太适合：</p><p>❌ 只想随便问问问题的用户</p><hr/><h2>🔥 个人体验总结</h2><p><strong>优点：</strong></p><ul><li>上手简单</li><li>逻辑清晰</li><li>结构化强</li><li>适合新手理解 Prompt 逻辑</li></ul><p><strong>缺点：</strong></p><ul><li>默认模型输出一般</li><li>更适合作为"Prompt生成器"，而非最终执行模型</li></ul><p>我的使用方式是：</p><blockquote>用它生成高质量 Prompt\<br/>再交给更强的模型执行</blockquote><p>效果确实更稳。</p><hr/><h2>🧩 一个思考</h2><p>未来可能不是：</p><blockquote>"谁的模型更强"</blockquote><p>而是：</p><blockquote>谁的提示词工程体系更成熟。</blockquote><p>当 AI 成为工具，</p><p>Prompt 就变成了"生产力放大器"。</p><hr/><h2>📦 想要源码？</h2><p>这个贪吃蛇小游戏源码可以直接运行。</p><p>想玩玩的可以私信我。</p><hr/><p>如果你最近也在研究：</p><ul><li>AI写代码</li><li>提示词优化</li><li>企业AI落地</li></ul><p>可以试试这个工具。</p><p>也欢迎留言交流你踩过的坑 👇</p><p>本文由<a href="https://link.segmentfault.com/?enc=GwZoH9CdxmKUKQ5%2B9IDFEg%3D%3D.5IxGoMT7PnY%2ByAztlQDcLMUAie554q5V72%2FF%2BlvLbl0%3D" rel="nofollow" target="_blank">mdnice</a>多平台发布</p>]]></description></item><item>    <title><![CDATA[聊聊编程里的“魔法棒”：取余运算（Modulo） target丶 ]]></title>    <link>https://segmentfault.com/a/1190000047605411</link>    <guid>https://segmentfault.com/a/1190000047605411</guid>    <pubDate>2026-02-11 15:08:04</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <blockquote><p>💡 <strong>写在前面</strong>：<br/>最近面试被问到一个倒计时相关问题，又一次用到了取余（Modulo）。说实话，刚入行那会儿，总觉得这玩意儿不就是小学数学里的<code>求余数</code><br/>吗？除了面试题里用来判断奇偶数，平时好像也没啥大用。</p><p>但随着代码写得越来越多，逐渐发现 <code>%</code> 符号背后其实隐藏着一种处理数据的<strong>思维模型</strong>——它能把无限延伸的线性世界，折叠成有限可控的<br/><strong>周期世界</strong>。今天想和大家分享一下我对取余的重新思考，看看它是怎么帮我们优雅地解决那些头疼的边界问题。</p></blockquote><h2>重新认识 <code>%</code></h2><p>取余的本质，是将任意数值强行<code>限定</code>在一个固定的循环范围内。无论数字跑多远，<code>% N</code> 都能让它回归到 <code>0</code> 至 <code>N-1</code> 的闭环中。</p><p>在教科书里，取余的公式是 <code>a % n = r</code></p><ul><li><code>a</code>：被除数</li><li><code>n</code>：除数</li><li><code>r</code>：余数</li></ul><p>但在代码逻辑里，我更愿意把它理解为两个超级好用的思维模型：</p><h3>🔄 循环</h3><p>想象一下家里的挂钟。不管时间怎么流逝，时针转了一圈又一圈，它永远只会停在 <code>1</code> 到 <code>12</code> 之间。取余就是这个<strong>表盘</strong><br/>，它能让无限增长的数字，乖乖地在一个固定的"圈"里打转。</p><h3>✂️ 限制</h3><p>无论你给我的数字有多大，<code>% n</code> 就像一把剪刀，强行把多出来的部分剪掉，只保留 <code>0</code> 到 <code>n-1</code> 这一小段。</p><p>就可以理解为：</p><ul><li><code>a</code>：被除数（任意数值）</li><li><code>n</code>：除数（限定的范围大小，也就是"表盘"的大小）</li><li><code>r</code>：余数（结果永远在 <code>0</code> 到 <code>n-1</code> 之间）</li></ul><h2>特点</h2><h3>构建"周期闭环"</h3><p>说白了就是让数字一直在一个圈里转，永远跑不出去。比如轮播图或红绿灯，写 <code>if (index &gt;= length)</code> 来防止数组越界，写多了特别烦。</p><p>有了取余，这事儿就简单了：</p><pre><code class="js">// 不管 index 涨到几万，结果永远锁死在 0 到 length-1 之间
const safeIndex = index % list.length;</code></pre><h3>降维与坐标映射</h3><p>这个主要解决"一维变二维"的问题。比如为了省流量，后端扔过来一个长长的一维数组，你需要在界面上画个九宫格。</p><p>别傻乎乎地去搞双层循环，直接用数学搞定。假设一行有 <code>col</code> 列：</p><ul><li><strong>找列号（X轴）</strong>：看它在当前行走了几步 -&gt; <strong>取余</strong> (<code>% col</code>)</li><li><strong>找行号（Y轴）</strong>：看它已经填满了几行 -&gt; <strong>整除</strong> (<code>Math.floor(i / col)</code>)</li></ul><pre><code class="js">// 假设数组索引 i=7，一行3个 (col=3)
const x = 7 % 3;                // 1 （第2列）
const y = Math.floor(7 / 3);    // 2 （第3行）

// 坐标就是 (1, 2)</code></pre><h3>均匀离散与分流</h3><p>一大堆随机数据（比如 1000 万个用户 ID），把它们公平地分给 3 台服务器，怎么分最匀称？</p><p>别搞什么复杂的随机算法，直接按 ID 取余。这不仅分得匀，还能保证同一个用户每次都能分到同一台机器上（这在分布式里叫 Hash 一致性）。</p><ul><li><strong>数字 ID</strong>：直接取余。</li><li><strong>字符串 ID</strong>：先算 Hash 值（转成数字），再取余。</li></ul><pre><code class="js">// 简单又高效的负载均衡
const targetServer = servers[userId % 3];

// 如果是字符串 ID，就先转成数字（Hash）
// const hash = stringToNumber(userId); 
// const targetServer = servers[hash % 3];</code></pre><h3>声明式逻辑</h3><p>代码是写给人看的。<code>if-else</code> 是告诉机器"怎么做流程控制"，而 <code>%</code> 是告诉人"这里是个循环"。</p><p>用 <code>%</code> 最大的好处就是——你再也不会把 <code>&gt;</code> 误写成 <code>&gt;=</code> 了。那种差 1 的 Bug（Off-by-one error），写过代码的都懂有多坑。</p><h3>倍数与规律捕捉</h3><p>想每隔 10 行打个日志？或者给表格弄个"斑马纹"（奇偶变色）？</p><p>这种"每隔 N 次搞点事情"的逻辑，用取余是最直观的。它就像个节拍器，到了那个点就会响。</p><pre><code class="js">// 经典的斑马纹逻辑
const color = index % 2 === 0 ? 'white' : 'gray';</code></pre><h2>常见的面试题（由简到难）</h2><h3>1. 秒转时分秒（倒计时）</h3><p><strong>问</strong>：给你一个总秒数 <code>3661</code>，怎么在页面上显示 <code>01:01:01</code>？</p><p><strong>答</strong>：这是最基础的"进制转换"题。</p><ul><li><strong>低位（秒）</strong>：总秒数对 60 取余 -&gt; 剩下的零头就是秒。</li><li><strong>中位（分）</strong>：总秒数先除以 60 得到总分钟数，再对 60 取余 -&gt; 剩下的零头就是分。</li><li><strong>高位（时）</strong>：总分钟数除以 60 -&gt; 剩下的就是时。</li></ul><pre><code class="js">const totalSeconds = 3661;

const seconds = totalSeconds % 60;            // 1
const minutes = Math.floor(totalSeconds / 60) % 60; // 61 % 60 = 1
const hours = Math.floor(totalSeconds / 3600);      // 1

const format = time =&gt; time.toString().padStart(2, '0');
console.log(`${format(hours)}:${format(minutes)}:${format(seconds)}`); // 01:01:01</code></pre><h3>2. 判断质数（Prime Number）</h3><p><strong>问</strong>：怎么判断一个数 <code>n</code> 是不是质数？</p><p><strong>答</strong>：质数就是只能被 1 和它自己整除的数。</p><p>所以，拿 2 到 n-1 之间的所有数去试着除它。只要有一个能被整除（<code>n % i === 0</code>），它就不是质数。</p><p><strong>优化点</strong>：其实只需要试到 <code>Math.sqrt(n)</code> 就够了，后面都是重复的。</p><blockquote><p><strong>为什么？</strong> 因子都是成对出现的。比如 <code>36</code>：</p><ul><li><code>2 × 18</code></li><li><code>3 × 12</code></li><li><code>4 × 9</code></li><li><code>6 × 6</code> (根号 n)</li><li><code>9 × 4</code> (重复了！)</li></ul><p>只要在 <code>6</code> (根号 n) 之前没找到因子，后面也绝不会有（除非是它自己）。同理 <code>100</code> 的根号是 <code>10</code>，你只要试到 <code>10</code><br/>就行了，不用傻乎乎试到 <code>99</code>。</p></blockquote><pre><code class="js">function isPrime(n) {
  if (n &lt;= 1) return false;
  if (n === 2) return true;      // 2 是质数
  if (n % 2 === 0) return false; // 偶数直接排除

  // 只需要试除奇数，步长为 2
  for (let i = 3; i &lt;= Math.sqrt(n); i += 2) {
    if (n % i === 0) return false;
  }
  return true;
}</code></pre><h3>3. 判断回文数（不转字符串）</h3><p><strong>问</strong>：给你个数字 <code>12321</code>，怎么判断它是回文？不许转成 String。</p><p><strong>答</strong>：这题考的是数字拆解的基本功。</p><p>你需要理解 <code>%</code> 和 <code>/</code> 在十进制里的<strong>黄金搭档</strong>关系：</p><ul><li><b><code>% 10</code> 是"拿"</b>：拿到个位数（剥洋葱的第一层）。</li><li><b><code>/ 10</code> 是"扔"</b>：扔掉个位数（把洋葱缩小一圈）。</li></ul><p><strong>一边拆，一边装</strong>：<br/>把 <code>x</code> 的屁股（最后一位）拆下来，装到 <code>reversed</code> 的头上。如果装完发现 <code>reversed === x</code>，那就是回文。</p><pre><code class="js">let x = 12321, reversed = 0;
// 假设 x=123
// 第一轮：123 % 10 = 3 (拿3), 123 / 10 = 12 (剩12)
// 第二轮：12 % 10 = 2 (拿2), 12 / 10 = 1 (剩1)
// 第三轮：1 % 10 = 1 (拿1), 1 / 10 = 0 (剩0) -&gt; 结束
while (x &gt; 0) {
  reversed = reversed * 10 + x % 10; // 拼到新数末尾
  x = Math.floor(x / 10);            // 原数去掉末尾
}</code></pre><h3>4. 负数取余的坑（JS vs 其他语言）</h3><p><strong>问</strong>：<code>(-1) % 5</code> 在 JS 里等于多少？在 Python 里呢？</p><p><strong>答</strong>：这题特容易踩坑。</p><ul><li>在 JS（C/Java）里，结果是 <code>-1</code>。因为它们看重"商"向 0 取整。</li><li>在 Python 里，结果是 <code>4</code>。因为 Python 看重"商"向下取整。</li></ul><p><strong>实战解法</strong>：</p><p>如果在 JS 做轮播图（点击上一张），算出 <code>-1</code> 程序就崩了。</p><p>记住这个<strong>万能公式</strong>，不管正负都能转正：</p><pre><code class="js">const index = (current + step + length) % length;</code></pre><p><strong>为什么加 <code>length</code>？</strong></p><p>因为 <code>%</code> 运算在 JS 里会保留符号。假设当前是第 0 张图（current=0），你要退一张（step=-1），总共5张图（length=5）。</p><ul><li><strong>不加 length</strong>：<code>(0 + (-1)) % 5 = -1</code> ❌（不仅不对，还越界了）</li><li><strong>加 length</strong>：<code>(0 + (-1) + 5) % 5 = 4</code> ✅（这就对了，回到了最后一个）</li><li><strong>正向移动</strong>：<code>(0 + 1 + 5) % 5 = 1</code> ✅（加一圈不影响正数结果，没副作用）</li></ul><p><strong>场景举例</strong>：</p><ol><li><b>轮播图"上一张"</b>：<code>current=0, step=-1</code>。<code>(0 - 1 + 5) % 5 = 4</code> -&gt; 完美跳到最后一张。</li><li><strong>贪吃蛇穿墙</strong>：蛇头钻出左边界 <code>x=-1</code>。<code>(-1 + width) % width</code> -&gt; 瞬间从右边出来。</li><li><strong>日期计算</strong>：今天是周三 <code>3</code>，问 5 天前是周几？<code>(3 - 5 + 7) % 7 = 5</code> -&gt; 周五。不用脑补倒着数数了。</li></ol><h3>5. 不用临时变量交换两个数</h3><p><strong>问</strong>：给你两个整数 a 和 b，不许用 <code>temp</code> 变量，怎么交换它们？</p><p><strong>答</strong>：除了烂大街的位运算（异或），取余其实也能干这事儿（虽然不如位运算快，但思路很骚）。</p><p>思路是把两个数"压缩"到一个大数里，再拆出来。</p><pre><code class="js">let a = 123, b = 456;
// 假设 n 足够大，比 a 和 b 都大
const n = 1000;

// 压缩：把 b 藏在高位，a 藏在低位
a = a + b * n; // 123 + 456 * 1000 = 456123

b = a % n;        // 取出低位，也就是原来的 a 
a = Math.floor(a / n); // 取出高位，也就是原来的 b

console.log(a, b); // 456, 123</code></pre><h3>6. 约瑟夫环问题</h3><p><strong>场景描述</strong>：<br/>有 <code>n</code> 个人围成一圈（编号 0 到 n-1）。从第 0 号开始报数，报到 <code>m</code> 的人出局。下一位继续从 1 开始报数，直到只剩最后一个人。问最后这个人的原始编号是多少？</p><p><strong>例子</strong>：</p><ul><li><strong>n = 5</strong>（5个人：0, 1, 2, 3, 4）</li><li><strong>m = 3</strong>（报到3出局）</li><li><strong>出局过程</strong>：2号出局 -&gt; 0号出局 -&gt; 4号出局 -&gt; 1号出局 -&gt; <strong>3号幸存</strong>。</li><li><strong>幸存过程</strong>：0, 1, 2, 3, 4 -&gt; 0, 1, 3, 4 -&gt; 1, 3, 4 -&gt; 1, 3 -&gt; 3</li></ul><p>这道题有点复杂，先上答案，后面咱们掰开揉碎了讲</p><pre><code class="js">/**
 * @param {number} n 总人数
 * @param {number} m 报数号码（报到几出局）
 * @return {number} 最后幸存者的编号
 */
function lastRemaining(n, m) {
  let pos = 0; // 时光倒流终点：最后只剩1个人时，幸存者索引是0

  // 开始倒推：从2个人 -&gt; 3个人 -&gt; ... -&gt; n个人
  for (let i = 2; i &lt;= n; i++) {
    pos = (pos + m) % i; // 每一轮人数变多(i)，位置都要往后挪 m 位
  }
  return pos;
}</code></pre><p><strong>解法思路：时光倒流（坐标偏移）</strong></p><p>这个问题如果顺着想（模拟淘汰），数组删元素很麻烦。但如果我们<strong>倒着想</strong>，利用<strong>坐标偏移</strong>规律，就非常简单。</p><p><strong>1. 正向（淘汰 = 坐标前移）：</strong><br/>想象一下，<code>m=3</code>，第 3 个人（索引 2）被淘汰后。</p><ul><li>按照规则，<strong>下一轮报数从被淘汰者的下一个人（索引 3）开始</strong>。</li><li>这就意味着，<strong>索引 3</strong> 变成了新一轮的 <strong>排头兵（新的索引 0）</strong>。</li><li>相当于所有人整体<strong>往前挪了 3 位</strong>（注意：不仅仅是填补空缺，而是连起点都变了）。</li><li>即：<code>旧索引 - 3 = 新索引</code>。</li></ul><p><strong>2. 逆向（恢复 = 坐标后移）：</strong><br/>我们要找幸存者最初在哪，可以从<strong>终局</strong>（只剩他 1 人，索引 0）开始，一步步把时光倒流，恢复之前被淘汰的人。</p><ul><li><strong>恢复就是淘汰的逆操作</strong>。</li><li>既然淘汰是"往前挪 3 位"，那恢复就是<b>"往后挪 3 位"</b>（<code>+3</code>）。</li><li>公式呼之欲出：<code>新索引 + 3 = 旧索引</code>。</li><li><strong>核心补丁</strong>：因为是圆圈，往后挪超出了队尾就要绕回队头，所以必须 <code>% 上轮人数</code>。</li></ul><p><strong>推导过程演示（N=5, M=3）</strong>：</p><p>我们只关注<strong>最后那个幸存者</strong>（假设他叫"天选之子"），他在每一轮的索引是多少？</p><blockquote><p><strong>表头说明</strong>：</p><ul><li><strong>n</strong>：当前轮剩余人数。</li><li><strong>倒推公式</strong>：<code>(当前索引 + m) % 上轮人数</code>。通过这个公式，我们可以算出幸存者在上一轮（人数更多时）的位置。</li></ul></blockquote><table><thead><tr><th align="left">轮次</th><th align="left">剩余人数</th><th align="left">场景描述</th><th align="left">计算过程</th><th align="left">幸存者索引</th></tr></thead><tbody><tr><td align="left"><strong>终局</strong></td><td align="left">1</td><td align="left">只剩天选之子</td><td align="left">0 (固定)</td><td align="left"><strong>0</strong></td></tr><tr><td align="left"><strong>倒数第2轮</strong></td><td align="left">2</td><td align="left">恢复成2人</td><td align="left"><code>(0 + 3) % 2</code></td><td align="left"><strong>1</strong></td></tr><tr><td align="left"><strong>倒数第3轮</strong></td><td align="left">3</td><td align="left">恢复成3人</td><td align="left"><code>(1 + 3) % 3</code></td><td align="left"><strong>1</strong></td></tr><tr><td align="left"><strong>倒数第4轮</strong></td><td align="left">4</td><td align="left">恢复成4人</td><td align="left"><code>(1 + 3) % 4</code></td><td align="left"><strong>0</strong></td></tr><tr><td align="left"><strong>开局</strong></td><td align="left">5</td><td align="left">恢复成5人</td><td align="left"><code>(0 + 3) % 5</code></td><td align="left"><strong>3</strong></td></tr></tbody></table><p><strong>结论</strong>：一开始索引为 <strong>3</strong> 的那个人，就是天选之子。</p><p><strong>💡 核心疑点 Q&amp;A</strong>：</p><ol><li><p><strong>为什么要倒推？</strong></p><ul><li><strong>正推太麻烦</strong>：如果正向模拟，你需要不断地删除数组元素、处理索引越界，数组长度一直在变，计算极其复杂。</li><li><strong>终局是已知的</strong>：无论过程多复杂，<strong>最后一定只剩 1 个人</strong>，且那个人的索引一定是 <code>0</code>。从确定的结果出发找源头，比从源头去猜结果要容易得多。</li></ul></li><li><p><strong>为什么要恢复上一轮的状态？</strong></p><ul><li>这是一个<strong>递归/递推</strong>的问题。<code>5个人</code> 的游戏淘汰一个，就变成了 <code>4个人</code> 的游戏。</li><li>如果我们知道 <code>4个人</code> 里的幸存者是谁，只要把这个幸存者在 <code>4个人</code> 局里的位置，<strong>映射（还原）</strong> 回 <code>5个人</code> 局里的位置，问题就解决了。</li><li>所谓"恢复"，其实就是<strong>坐标变换</strong>。</li></ul></li><li><p><strong>为什么要 % i（当前人数），而不是 % n（总人数）？</strong></p><ul><li>这是很多人的盲点！</li><li>每一轮淘汰一个人，<strong>圈子的大小都在变</strong>。</li><li>倒数第 2 轮时，圈子只有 2 个人，所以是 <code>% 2</code>；倒数第 3 轮时，圈子有 3 个人，所以是 <code>% 3</code>。</li><li>我们是在<strong>那一轮的圈子</strong>里进行坐标恢复，当然要模<strong>那一轮的人数</strong>。</li></ul></li><li><p><strong>公式 <code>(当前索引 + m) % 上轮人数</code> 怎么来的？</strong></p><ul><li>这就是我们上面提到的<strong>坐标偏移</strong>：</li><li><strong>+ m</strong>：代表时光倒流，恢复被删掉的 <code>m</code> 个位置。</li><li><strong>% 上轮人数</strong>：代表在恢复后的圈子里转圈圈，防止索引越界。</li></ul></li></ol><p><strong>💡 小贴士：数学公式版（递归实现）</strong></p><p>如果你在算法书上看到这个公式，别慌，它和我们的代码是一回事：</p><p><code>f(n, m) = (f(n-1, m) + m) % n</code></p><ul><li><code>f(n, m)</code>：n 个人时幸存者的索引。</li><li><code>f(n-1, m)</code>：n-1 个人时幸存者的索引（也就是我们代码里的 <code>pos</code>）。</li><li>代码里的 <code>for</code> 循环，就是把这个数学递归公式变成了<strong>从 2 到 n 的递推</strong>。</li></ul><p><strong>递归版代码（仅供参考）</strong>：</p><p>虽然代码看着短，但如果 n 很大，会爆栈哦。还是推荐用上面的 <code>for</code> 循环（迭代版）。</p><pre><code class="js">function lastRemainingRecursive(n, m) {
  if (n === 1) return 0; // 剩下1个人，索引肯定是0
  return (lastRemainingRecursive(n - 1, m) + m) % n;
}</code></pre><p><strong>动态规划版（标准 DP）</strong>：</p><p>有了推导公式，自然就能写出 DP。</p><p><code>dp[i]</code> 表示 <code>i</code> 个人时的幸存者索引。</p><pre><code class="js">function lastRemainingDP(n, m) {
  let dp = new Array(n + 1);
  dp[1] = 0; // 只有1个人时，索引是0
  for (let i = 2; i &lt;= n; i++) {
    dp[i] = (dp[i - 1] + m) % i; // 状态转移方程
  }
  return dp[n];
}</code></pre><p>*注：我们最开始写的那个 <code>let pos</code> 的版本，其实就是这个 DP 版本的<strong>空间优化版</strong>（滚动数组思想），把 <code>dp</code><br/>数组压缩成了一个变量。*</p><h2>总结</h2><p>说实话，取余（Modulo）这个概念，以前我也觉得它只是个数学符号，顶多用来算算奇偶数。但当你真的深入去理解它，你会发现它其实是一种<code>化直为曲</code><br/>的思维方式。</p><p>无论是处理时间、轮播图，还是解决像约瑟夫环这样复杂的算法题，取余的核心永远只有两点：<strong>控制边界</strong>和<strong>制造循环</strong>。</p><p>希望这篇文章能帮你打破对 <code>%</code> 的固有印象。下次在代码里遇到"溢出"、"循环"或者"映射"的问题时，试着停下来想一想：这里是不是可以用取余来简化一下？</p><p>多思考，多动手，编程不仅是写代码，更是对数据规律的优雅掌控。</p><p>本文由<a href="https://link.segmentfault.com/?enc=sdF1ZM3nWKfPp%2BMLzsSWLQ%3D%3D.ZKyXysUDq6aaxqC3ut8gL4RQAHN1U%2FamNMaz090QsN0%3D" rel="nofollow" target="_blank">mdnice</a>多平台发布</p>]]></description></item><item>    <title><![CDATA[SmartPi 智能体平台实战：从知识库问答到设备控制的完整闭环 SmartPi ]]></title>    <link>https://segmentfault.com/a/1190000047605444</link>    <guid>https://segmentfault.com/a/1190000047605444</guid>    <pubDate>2026-02-11 15:07:26</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>前言</h2><p>在智能家居和语音交互产品开发中，如何让设备"懂"你的产品？如何让用户通过自然对话完成设备控制？SmartPi 智能体平台提供了一套完整的解决方案——从知识库问答（RAG）到设备控制（MCP），让开发者能够快速打造智能语音交互体验。</p><blockquote><p><strong>平台更新说明（2026）</strong>：</p><ul><li>智能体平台已升级为统一控制台，支持 API 发布和工作流编排</li><li>PAT（Personal Access Token）成为推荐鉴权方式</li><li>MCP 插件支持通过 <code>mcp_tool.yaml</code> 文件一键导入</li><li>新增对话流（Workflow）可视化编排能力</li></ul></blockquote><p>本文将带你完成一个完整的实战项目：<strong>打造一个能回答设备说明书问题，并能控制灯光亮度的智能语音助手</strong>。</p><h2>一、智能体平台架构概览</h2><p>在开始实战之前，先理解 SmartPi 智能体平台的整体架构：</p><pre><code>┌─────────────────────────────────────────────────────────────────┐
│                         用户交互层                                │
├─────────────────────────────────────────────────────────────────┤
│  语音唤醒  →  ASR识别  →  智能体对话  →  TTS播报  →  设备控制    │
└─────────────────────────────────────────────────────────────────┘
                              ↓
┌─────────────────────────────────────────────────────────────────┐
│                      智能体平台 (云端)                            │
├─────────────────────────────────────────────────────────────────┤
│  ┌─────────────┐   ┌─────────────┐   ┌─────────────┐           │
│  │  知识库RAG  │   │   插件/MCP  │   │  自定义LLM  │           │
│  │  (设备问答) │   │  (设备控制) │   │  (扩展能力) │           │
│  └─────────────┘   └─────────────┘   └─────────────┘           │
└─────────────────────────────────────────────────────────────────┘
                              ↓
┌─────────────────────────────────────────────────────────────────┐
│                      SmartPi 平台 (中台)                          │
├─────────────────────────────────────────────────────────────────┤
│  固件配置  →  MCP工具生成  →  二维码绑定  →  小程序控制          │
└─────────────────────────────────────────────────────────────────┘
                              ↓
┌─────────────────────────────────────────────────────────────────┐
│                        设备端 (本地)                              │
├─────────────────────────────────────────────────────────────────┤
│  语音模块  →  命令执行  →  GPIO控制  →  状态上报                 │
└─────────────────────────────────────────────────────────────────┘</code></pre><p><strong>核心组件说明：</strong></p><table><thead><tr><th>组件</th><th>作用</th><th>典型应用</th></tr></thead><tbody><tr><td>知识库 (RAG)</td><td>让智能体基于你提供的资料回答</td><td>设备说明书、FAQ、产品规格</td></tr><tr><td>MCP/插件</td><td>让智能体能够调用外部工具控制设备</td><td>开关控制、参数调节、状态查询</td></tr><tr><td>PAT</td><td>API 调用鉴权凭证</td><td>保护智能体接口安全</td></tr><tr><td>二维码绑定</td><td>将云端智能体与本地设备关联</td><td>一键完成配置同步</td></tr></tbody></table><h2>二、准备工作</h2><h3>2.1 必备条件</h3><p>在开始之前，请确认以下资源已准备就绪：</p><table><thead><tr><th>资源</th><th>说明</th><th>获取方式</th></tr></thead><tbody><tr><td>SmartPi 平台账号</td><td>用于配置固件和生成二维码</td><td><a href="https://link.segmentfault.com/?enc=bsRRofqpfJRmmT7PG4YEFw%3D%3D.5jhfTms4CsBTOc1Oa7VP6p0kRly8XXGvHvHBI1ZAt2M%3D" rel="nofollow" target="_blank">https://smartpi.cn</a> 注册</td></tr><tr><td>智能体平台地址</td><td>你们部署的控制台地址</td><td>由技术团队提供</td></tr><tr><td>支持智能体的设备</td><td>带 "AI 智能体" 菜单的语音模组</td><td>如 JX-A7T 等在线语音模块</td></tr><tr><td>微信小程序</td><td>"智能公元"小程序</td><td>微信搜索即可</td></tr></tbody></table><h3>2.2 检查设备是否支持智能体</h3><ol><li>打开"智能公元"微信小程序</li><li>进入设备详情页</li><li>查看是否有 <strong>"AI 智能体"</strong> 菜单</li></ol><blockquote><strong>注意</strong>：如果看不到该菜单，说明当前设备/固件不支持智能体功能，需要升级到支持在线语音的固件版本。</blockquote><h2>三、实战第一步：创建知识库问答智能体</h2><p>我们的第一个目标是：<strong>让智能体能够回答设备说明书中的问题</strong>，例如"这款设备怎么配网？"、"如何恢复出厂设置？"等。</p><h3>3.1 创建智能体</h3><ol><li>登录智能体平台控制台</li><li>进入 <strong>开发 / Development</strong> → 点击 <strong>创建 / Create</strong></li><li><p>填写基本信息：</p><ul><li><strong>名称</strong>：<code>设备说明书助手</code>（或更具体的场景名，如"客厅灯光助手"）</li><li><strong>介绍</strong>：<code>回答设备使用问题，并能控制设备</code></li><li><strong>提示词</strong>：先用最简版本</li></ul></li></ol><pre><code># 最小可用提示词（可直接复制）
你是设备的智能语音助手。
你的任务是：
1. 回答用户关于设备使用的各种问题
2. 基于知识库内容回答，找不到答案就说"这个问题我不太清楚"
3. 用简洁的中文回答，每次回答不超过50字</code></pre><h3>3.2 准备知识库文件</h3><p>知识库是智能体的"专业大脑"，让它能够回答你们产品/设备的专属问题。</p><p><strong>文件格式支持：</strong></p><ul><li>PDF、Word (<code>.docx</code>)</li><li>纯文本 (<code>.txt</code>, <code>.md</code>)</li><li>Excel/CSV (<code>.xlsx</code>, <code>.csv</code>) —— 适合 Q&amp;A 格式</li></ul><p><strong>文件准备建议：</strong></p><table><thead><tr><th>建议</th><th>说明</th></tr></thead><tbody><tr><td>文件大小</td><td>单文件控制在 5MB 以内，大文件请按章节拆分</td></tr><tr><td>内容格式</td><td>使用清晰的标题和段落结构</td></tr><tr><td>Q&amp;A 格式</td><td>关键信息推荐用问答对方式呈现，便于精准匹配</td></tr></tbody></table><p><strong>Q&amp;A 格式示例（Excel）：</strong></p><table><thead><tr><th>问题</th><th>答案</th></tr></thead><tbody><tr><td>设备如何配网？</td><td>打开小程序，点击添加设备，选择设备型号，输入 Wi-Fi 密码即可完成配网</td></tr><tr><td>如何恢复出厂设置？</td><td>长按设备上的复位按钮 5 秒，听到提示音后松开，设备将恢复出厂设置</td></tr><tr><td>设备支持哪些语音指令？</td><td>支持开关控制、亮度调节、颜色切换等指令，具体请查看产品说明书</td></tr></tbody></table><h3>3.3 创建并关联知识库</h3><ol><li>在智能体平台进入 <strong>资源库 / Resource Library</strong></li><li>创建 <strong>知识库 / Knowledge</strong>，命名为 <code>设备说明书-2025Q1</code></li><li>上传准备好的文件</li><li>等待解析完成（状态从"解析中"变为"完成"）</li><li>回到智能体编辑页，在"知识/Knowledge"区域选择刚创建的知识库</li><li>保存配置</li></ol><h3>3.4 验证知识库效果</h3><p>在智能体预览窗口测试以下三类问题：</p><table><thead><tr><th>问题类型</th><th>示例问题</th><th>预期结果</th></tr></thead><tbody><tr><td>资料里有答案的</td><td>"设备怎么配网？"</td><td>能准确回答</td></tr><tr><td>资料里有步骤的</td><td>"如何恢复出厂设置？"</td><td>能按步骤说明</td></tr><tr><td>资料里没有的</td><td>"你们公司上市了吗？"</td><td>回答"不清楚"或类似内容</td></tr></tbody></table><p>如果智能体对资料外的问题也在"胡编"，需要在提示词中加入更强的约束：</p><pre><code>## 重要限制
- 只能基于知识库内容回答
- 知识库中没有答案的问题，必须回答"这个问题我不太清楚"
- 不要猜测或编造信息</code></pre><h2>四、实战第二步：让智能体具备设备控制能力</h2><p>知识库让智能体"能答"，现在要让它"能做"。我们将通过 MCP（Model Context Protocol）工具让智能体能够控制设备。</p><h3>4.1 理解 MCP 工具</h3><p>MCP 是连接大模型与设备控制的桥梁：</p><pre><code>┌─────────────┐      语音输入      ┌─────────────┐
│    用户     │ ──────────────────→ │   智能体    │
└─────────────┘                     └─────────────┘
                                              │
                                              │ 调用 MCP 工具
                                              ↓
┌─────────────┐      工具调用      ┌─────────────┐
│   设备      │ ←────────────────── │  MCP 服务   │
│  (GPIO等)   │                     └─────────────┘
└─────────────┘</code></pre><h3>4.2 配置设备控件</h3><p>在配置 MCP 工具之前，需要先在小程序平台定义好可控制的"控件"：</p><ol><li>登录 SmartPi 平台 (smartpi.cn)</li><li>选择你的设备和固件版本</li><li>进入 <strong>控制面板 / 面板编辑</strong></li><li>添加以下控件示例：</li></ol><table><thead><tr><th>控件类型</th><th>控件 ID</th><th>说明</th></tr></thead><tbody><tr><td>开关</td><td><code>switch_light</code></td><td>控制灯光开关</td></tr><tr><td>滑块</td><td><code>slider_brightness</code></td><td>调节亮度（0-100）</td></tr><tr><td>状态显示</td><td><code>text_status</code></td><td>显示当前状态</td></tr></tbody></table><h3>4.3 生成 MCP 工具</h3><ol><li>在 SmartPi 平台进入 <strong>MCP 工具</strong> 菜单</li><li>点击 <strong>刷新</strong> 按钮，平台会自动根据已配置的控件生成工具</li><li>为每个工具补充清晰的<strong>名称</strong>和<strong>描述</strong>（这是智能体理解工具用途的关键）</li></ol><p><strong>工具描述示例：</strong></p><table><thead><tr><th>工具名称</th><th>描述</th></tr></thead><tbody><tr><td><code>控制灯光开关</code></td><td>打开或关闭灯光，参数：on=开，off=关</td></tr><tr><td><code>调节灯光亮度</code></td><td>调节灯光亮度，参数：0-100 的数值，0 为最暗，100 为最亮</td></tr><tr><td><code>查询灯光状态</code></td><td>查询灯光当前的状态，包括开关和亮度值</td></tr></tbody></table><h3>4.4 发布 MCP 工具</h3><ol><li>在固件版本发布页面，勾选 <strong>发布 MCP 工具</strong></li><li>生成并下载新固件</li><li>将固件烧录到设备</li></ol><blockquote><strong>注意</strong>：MCP 工具只有在固件发布后才会生效，修改描述后需要重新发布。</blockquote><h3>4.5 导入插件到智能体（可选方案）</h3><p>如果你的方案需要通过插件方式调用，可以按以下步骤操作：</p><ol><li>在 SmartPi 平台 MCP 工具页面，点击 <strong>预览</strong> → <strong>下载插件</strong></li><li>获得 <code>mcp_tool.yaml</code> 文件</li><li>在智能体平台 <strong>资源库</strong> 中 <strong>添加插件</strong> → <strong>导入</strong> 该文件</li><li>将所有工具设置为 <strong>启用</strong></li><li>进行 <strong>试运行</strong>，参数中 <code>token</code> 固定填 <code>Bearer test</code></li></ol><h2>五、实战第三步：发布智能体并绑定设备</h2><p>现在我们已经有了：</p><ul><li>一个能回答问题的知识库</li><li>一套能控制设备的 MCP 工具</li></ul><p>最后一步是将智能体发布为 API 服务，并绑定到具体设备。</p><h3>5.1 生成个人访问令牌 (PAT)</h3><p>PAT（Personal Access Token）是调用智能体 API 的安全凭证。</p><ol><li>在智能体平台点击左下角头像</li><li>进入 <strong>API Authorization / API 授权</strong></li><li>点击 <strong>Add New Token / 新建令牌</strong></li><li>填写名称和过期时间</li><li><strong>立即复制并保存</strong> —— PAT 只展示一次！</li></ol><p>调用 API 时需要在请求头中携带：</p><pre><code>Authorization: Bearer pat_xxxxx</code></pre><h3>5.2 发布智能体为 API 服务</h3><ol><li>在智能体页面右上角点击 <strong>发布 / Publish</strong></li><li>选择 <strong>API</strong> 发布方式</li><li><p>发布后记录两个关键信息：</p><ul><li><strong>bot\_id</strong>：浏览器地址栏 <code>bot/</code> 后的数字</li><li><strong>PAT</strong>：上一步生成的令牌</li></ul></li></ol><h3>5.3 在 SmartPi 平台创建智能体配置</h3><ol><li>打开 SmartPi 平台 (smartpi.cn)</li><li>进入 <strong>智能体 → 配置</strong></li><li><p>创建新配置并填写：</p><ul><li><strong>名称</strong>：如"客厅灯光智能体"</li><li><strong>平台选择</strong>：Coze 或其他支持的智能体平台</li><li><strong>智能体 ID（bot\_id）</strong>：从上一步复制</li><li><strong>个人访问令牌（PAT）</strong>：从上一步复制</li></ul></li><li>保存后，平台会生成一个 <strong>绑定二维码</strong></li></ol><h3>5.4 使用小程序扫码绑定</h3><ol><li>打开"智能公元"微信小程序</li><li>进入设备详情页</li><li>点击 <strong>AI 智能体</strong> 菜单</li><li>扫描上一步生成的二维码</li></ol><blockquote><strong>注意</strong>：二维码有效期为 10 分钟，超时需重新生成。</blockquote><h3>5.5 验证完整流程</h3><p>绑定成功后，可以进行端到端测试：</p><table><thead><tr><th>测试指令</th><th>预期行为</th></tr></thead><tbody><tr><td>"你好"</td><td>智能体正常回复</td></tr><tr><td>"设备怎么配网？"</td><td>基于知识库回答配网步骤</td></tr><tr><td>"把灯打开"</td><td>调用 MCP 工具，设备灯光开启</td></tr><tr><td>"把亮度调到 50"</td><td>调用 MCP 工具，亮度变为 50%</td></tr><tr><td>"现在灯什么状态？"</td><td>调用查询工具，播报当前状态</td></tr></tbody></table><h2>六、OpenAPI 调用速查</h2><p>对于需要通过代码调用智能体的场景，智能体平台提供了标准的 REST API。</p><h3>6.1 请求头配置</h3><p>所有 API 调用都需要携带以下请求头：</p><pre><code>Authorization: Bearer pat_xxxxx
Content-Type: application/json</code></pre><h3>6.2 创建会话（Conversation）</h3><p>在发起对话之前，需要先创建一个会话：</p><pre><code>curl --location '{{host}}/v1/conversation/create' \
  --header 'Authorization: Bearer pat_xxxxx' \
  --header 'Content-Type: application/json' \
  --data '{"bot_id":"&lt;bot_id&gt;"}'</code></pre><p><strong>响应示例</strong>：</p><pre><code>{
  "code": 0,
  "data": {
    "conversation_id": "conv_xxxxx",
    "created_at": 1234567890
  }
}</code></pre><h3>6.3 发起对话（Chat v3，流式 SSE）</h3><p>使用流式输出可以获得更好的用户体验：</p><pre><code>curl --location --request POST '{{host}}/v3/chat?conversation_id=&lt;conversation_id&gt;' \
  --header 'Authorization: Bearer pat_xxxxx' \
  --header 'Content-Type: application/json' \
  --data-raw '{
    "bot_id": "&lt;bot_id&gt;",
    "user_id": "&lt;your_user_id&gt;",
    "stream": true,
    "auto_save_history": true,
    "additional_messages": [
      {"role":"user","content":"你好","content_type":"text"}
    ]
  }'</code></pre><p><strong>流式事件顺序</strong>：</p><table><thead><tr><th>事件</th><th>说明</th></tr></thead><tbody><tr><td><code>conversation.chat.created</code></td><td>对话创建</td></tr><tr><td><code>conversation.chat.in_progress</code></td><td>对话进行中</td></tr><tr><td><code>conversation.message.delta</code></td><td>消息增量（流式返回内容）</td></tr><tr><td><code>conversation.message.completed</code></td><td>消息完成</td></tr><tr><td><code>conversation.chat.completed</code></td><td>对话完成</td></tr><tr><td><code>done</code></td><td>流结束</td></tr></tbody></table><h3>6.4 消息列表与清理上下文</h3><pre><code># 获取消息列表
POST {{host}}/v1/conversation/message/list?conversation_id=&lt;conversation_id&gt;

# 清理对话上下文
POST {{host}}/v1/conversations/&lt;conversation_id&gt;/clear</code></pre><h3>6.5 执行工作流（Workflow）</h3><p>如果使用对话流/工作流，可以直接执行：</p><pre><code>curl --location --request POST '{{host}}/v1/workflow/run' \
  --header 'Authorization: Bearer pat_xxxxx' \
  --header 'Content-Type: application/json' \
  --data-raw '{
    "workflow_id": "&lt;workflow_id&gt;",
    "parameters": "{\"user_id\":\"12345\"}"
  }'</code></pre><h2>七、常见问题排查</h2><h3>7.1 PAT 忘记保存怎么办？</h3><p>PAT 通常只在创建时展示一次，丢失后需要：</p><ol><li>重新生成新的 PAT</li><li>更新 SmartPi 平台中的智能体配置</li><li>重新生成二维码并绑定设备</li></ol><h3>7.2 设备端没有反应？</h3><p>按以下顺序排查：</p><table><thead><tr><th>排查项</th><th>检查方法</th></tr></thead><tbody><tr><td>菜单支持</td><td>小程序中是否有"AI 智能体"菜单</td></tr><tr><td>配置正确</td><td>bot\_id 和 PAT 是否正确（多余空格也会导致失败）</td></tr><tr><td>API 发布</td><td>智能体是否已发布为 API 服务</td></tr><tr><td>网络连接</td><td>设备是否正常联网</td></tr><tr><td>固件版本</td><td>是否烧录了包含 MCP 工具的最新固件</td></tr></tbody></table><h3>7.3 知识库回答不准确？</h3><table><thead><tr><th>问题</th><th>解决方案</th></tr></thead><tbody><tr><td>回答内容与资料不符</td><td>检查知识库文件解析是否完成</td></tr><tr><td>对资料外问题乱回答</td><td>在提示词中加入更强的约束规则</td></tr><tr><td>找不到答案</td><td>调整相似度阈值（默认 0.5，可适当降低）</td></tr></tbody></table><h3>7.4 MCP 工具调用失败？</h3><table><thead><tr><th>问题</th><th>解决方案</th></tr></thead><tbody><tr><td>工具未启用</td><td>在插件管理中确认工具已启用</td></tr><tr><td>试运行失败</td><td>确认 token 参数填写正确（<code>Bearer test</code>）</td></tr><tr><td>设备无响应</td><td>检查固件是否正确烧录，MCP 工具是否已发布</td></tr></tbody></table><h3>7.5 响应延迟过大？</h3><p>智能体对话的完整链路包括：ASR → 网络传输 → LLM 推理 → 工具调用 → 网络传输 → TTS</p><p>常见优化方向：</p><table><thead><tr><th>环节</th><th>优化建议</th></tr></thead><tbody><tr><td>网络传输</td><td>确保设备网络稳定，减少路由跳数</td></tr><tr><td>LLM 推理</td><td>使用更快的模型，或启用流式输出</td></tr><tr><td>对话流</td><td>关闭"深度思考"功能以减少响应时间</td></tr><tr><td>缓存</td><td>对常见问题配置缓存机制</td></tr></tbody></table><h2>八、进阶技巧</h2><h3>8.1 对话流/工作流 (Workflow) 应用</h3><p>对于复杂场景，可以使用对话流编排多个工具的调用顺序：</p><ol><li>在智能体平台创建 <strong>对话流 / Chatflow</strong></li><li>在开始节点定义输入变量：<code>token</code>、<code>deviceKey</code></li><li>在大模型节点关闭 <strong>深度思考</strong></li><li>添加插件节点，引用输入变量</li><li>在结束节点开启 <strong>流式输出</strong></li><li>发布对话流，获得 <code>workflow_id</code></li><li>在 SmartPi 平台智能体配置中填写该 ID</li></ol><h3>8.2 自定义大模型接入</h3><p>如果需要接入自建的大模型服务（如 VLLM、Xinference）：</p><ol><li>在智能体平台进入 <strong>模型提供商</strong> 管理</li><li>选择对应的模型类型（VLLM/Xinference）</li><li><p>填写配置参数：</p><ul><li>基础 URL：模型服务的 API 地址</li><li>API Key：认证密钥（如需要）</li><li>最大 Token：单次请求限制</li></ul></li></ol><p><strong>VLLM 部署示例：</strong></p><pre><code>docker run --gpus all \
  -v ~/.cache/huggingface:/root/.cache/huggingface \
  -p 8000:8000 \
  --name vllm-server \
  vllm/vllm-openai \
  --model your-model-name \
  --trust-remote-code</code></pre><h3>8.3 方言支持</h3><p>通过自建 GPU 服务器部署方言识别和 TTS 合成：</p><table><thead><tr><th>方言</th><th>支持情况</th></tr></thead><tbody><tr><td>粤语</td><td>支持 ASR 和 TTS</td></tr><tr><td>上海话</td><td>支持 ASR 和 TTS</td></tr><tr><td>四川话</td><td>支持 ASR 和 TTS</td></tr></tbody></table><h2>九、总结</h2><p>通过本文的实战演练，我们完成了一个完整的智能体开发流程：</p><pre><code>知识库配置 → MCP 工具生成 → API 发布 → 设备绑定 → 端到端测试</code></pre><p><strong>关键要点回顾：</strong></p><table><thead><tr><th>要点</th><th>说明</th></tr></thead><tbody><tr><td>知识库</td><td>是智能体的专业大脑，用 Q&amp;A 格式效果最佳</td></tr><tr><td>MCP 工具</td><td>是连接 AI 与设备的桥梁，描述要清晰准确</td></tr><tr><td>PAT</td><td>只展示一次，务必妥善保存</td></tr><tr><td>二维码绑定</td><td>有效期 10 分钟，需要提前准备设备</td></tr><tr><td>提示词优化</td><td>根据实际效果持续迭代，加入约束规则</td></tr></tbody></table><p><strong>下一步学习建议：</strong></p><ol><li>掌握提示词工程，优化智能体的回复质量</li><li>学习对话流编排，处理复杂的多轮对话场景</li><li>了解自定义模型接入，部署专属的大模型服务</li></ol><h2>参考资源</h2><table><thead><tr><th>资源名称</th><th>链接</th></tr></thead><tbody><tr><td>SmartPi 平台</td><td><a href="https://link.segmentfault.com/?enc=MA2LTu8gcfjQWLVicenCZQ%3D%3D.fXKPkBoFnpKviH2vYO5F7EdXtqE9Z2XSfJ0FcvRU5J4%3D" rel="nofollow" target="_blank">https://smartpi.cn</a></td></tr><tr><td>智能体平台快速开始</td><td>官方文档 /ai-agents/get-started</td></tr><tr><td>知识库配置指南</td><td>官方文档 /ai-agents/knowledge-base-setup</td></tr><tr><td>智能体控制台指南</td><td>官方文档 /ai-agents/platform-guide</td></tr><tr><td>智能体实践教程</td><td>官方文档 /ai-agents/tutorial</td></tr></tbody></table><p><em>本文档基于 SmartPi 官方文档整理，涵盖智能体平台的核心功能和实战操作。</em></p>]]></description></item><item>    <title><![CDATA[RAGFlow x OceanBase seekdb: AI 原生数据库驱动智能体落地 OceanB]]></title>    <link>https://segmentfault.com/a/1190000047605505</link>    <guid>https://segmentfault.com/a/1190000047605505</guid>    <pubDate>2026-02-11 15:06:31</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><strong>摘要：</strong><br/><em>随着Agent技术发展，RAG正从文档检索工具演进为支撑智能体的统一数据底座。RAGFlow提出通过“树图结合”模拟人类认知，以Context Engine统一处理三类核心数据，要求底层数据库具备强大的混合检索与高性能交互能力。OceanBase seekdb作为AI原生数据库，以向量检索、自定义分词及轻量部署等特性，为构建此类数据底座提供了关键技术支撑，推动Agent规模化落地阶段。</em></p><h2>01 前言</h2><p>在生成式 AI 迈向 Agent 时代的当下，RAG 技术正经历着一场深刻的范式演进。</p><p>RAGFlow 联合创始人张颖峰指出，RAG 不仅仅是水上雕花的展示工具，他应当成为智能体的数据底座。</p><p>本文基于 RAGFlow 的架构思路，并结合 OceanBase seekdb 的实践，介绍如何构建一个落地快的智能体数据底座。</p><h2>02 RAGFlow 的架构理念：重新定义 AI 时代的数据底座</h2><h4>RAG 不是终点，而是起点</h4><p>在 AI 应用开发中，开发者们普遍遇到了 RAG 效果难以提升的困境，仿佛按下葫芦浮起瓢，总有顾此失彼的感觉。尽管到 2024 年，使用多模态模型解析文档、采用混合搜索等实践已经成为共识，但效果仍然不尽如人意。问题的根源在哪里？</p><h4>树图结合：让检索像人一样思考</h4><p>RAGFlow 团队给出的答案是"树图结合"。这个方案的核心思想是让 RAG 系统像人一样去检索信息。当领导向你提出一个问题时，你不会在脑海中随机搜索碎片化的知识，而是会根据记忆中的目录结构，找到对应的文献，然后定位到具体答案。</p><p>传统 RAG 的召回机制只能返回文字碎片，这种碎片化的知识不利于大模型的理解。因此需要引入"树"的结构，像树状导航一样模拟人类寻找知识的过程。同时，人在寻找答案时还需要联想能力，这就是"图"的价值所在。图不是用来替代树的基础结构，而是帮助系统在导航的同时进行知识联想。</p><p>树图结合的数据组织方式，配合大模型的理解能力，才能真正缓解检索不准这一核心痛点。这不是简单的技术堆砌，而是对人类认知过程的深度模拟。</p><h4>从 RAG 到 Context Engine：支撑 Agent 的三类数据</h4><p>如果说 2025 年是 Agent 的元年，那么 2026 年就是 Agent 真正落地的元年。经过一年的探索，Agent 所需的技术要素已经逐渐清晰：Memory、外部知识、Tools、Skills……这些看似纷繁复杂的概念，实际上正在进入收敛期。</p><p>RAGFlow 认为，企业级 Agent 落地需要一个统一的数据底座来处理三类核心数据：</p><p>第一类是非结构化数据，这是 RAG 的舒适区。处理这类数据已经形成了标准化的 PDI 流程（Parse-Transform-Index），类似传统数据平台的 ETL，但最后一步不是 Load 而是 Index。因为 Retrieval Engine 本质上是索引引擎，必须基于索引来工作。这个过程需要各种解析模型（如 PaddleOCR、Marker 等）、语义增强算子，以及强大的混合搜索能力。</p><p>第二类是 Memory 数据，即智能体交互过程中生成的实时数据。Memory 与 RAG 的唯一区别在于存储的数据类型不同，RAG 存储相对静态的文档类数据，Memory 存储动态的交互数据。但两者的处理逻辑、语义增强操作几乎完全一致。因此 Memory 可以看作数据库中的不同表或不同库，没有必要将其作为独立组件。这种统一处理还为未来的跨库、跨表操作留下了可能性。</p><p>第三类是结构化数据，包括 TP 型业务数据和数仓数据。对于这类数据，不需要重新造轮子，而是通过 MCP（Model Context Protocol）等工具协议统一调用。在大型企业中，可能需要调用成百上千个 MCP 接口，如何高效地检索和使用这些工具，同样需要强大的 Retrieval 能力。</p><p>这三类数据的统一处理，构成了 Context Engine 的核心能力。而这个能力的基石，始终是 Retrieval，AI 原生搜索。</p><h4>Retrieval：Agent 时代被低估的核心能力</h4><p>在传统搜索引擎时代，用户提出一个问题，可能只需要十次检索就能得到答案。但在 Agent 时代，智能体与数据层的交互频率提升了两个数量级——可能是几百次甚至上千次。这意味着 Retrieval 的性能和准确性直接决定了 Agent 的可用性。</p><p>RAGFlow 的判断是：未来所有落地的智能体都将是 Coding Agent。在这个架构中，相对不变的是 Context 内容，Memory、企业内部数据、Tools、Skills 等，这些数据相对容易标准化。而智能体的行为逻辑则完全以代码生成的方式动态构建。</p><p>这种架构对底层数据库提出了极高的要求：不仅要支持向量检索，还要支持全文检索，以及未来更多类型的混合搜索需求。这正是 RAGFlow 选择与 OceanBase seekdb 深度集成的原因，一个真正的 AI 原生数据库，必须具备强大的、多样化的检索能力。</p><h2>03 实践指南：RAGFlow × OceanBase seekdb 快速上手</h2><p>RAGFlow 项目已深度集成 OceanBase 数据库。现在，您可以使用OceanBase全新推出的轻量级AI原生数据库OceanBase seekdb：</p><p>零成本兼容：接口完全兼容 OceanBase，无需修改代码</p><p>功能完整：TP/AP 一体化处理能力<br/>AI 原生：支持自定义分词器，快速适配多国语言、支持混合检索，4096维向量索引，完美支持主流嵌入模型<br/> 即插即用：更轻量，更易部署</p><p>前置要求 (Prerequisites)</p><p>在开始之前，请确保您的环境满足以下要求：<br/>CPU &gt;= 4 核<br/>RAM &gt;= 16 GB<br/>Disk &gt;= 50 GB<br/>Docker &gt;= 24.0.0 &amp; Docker Compose &gt;= v2.26.1</p><p>部署 RAGFlow</p><p>克隆 RAGFlow 代码</p><p><img width="723" height="138" referrerpolicy="no-referrer" src="/img/bVdnUwh" alt="" title=""/></p><p>配置 seekdb 为 ragflow 依赖的数据库</p><ol><li>将 seekdb 作为向量数据库<br/>修改.env文件：</li></ol><p><img width="723" height="81" referrerpolicy="no-referrer" src="/img/bVdnUwj" alt="" title="" loading="lazy"/></p><ol start="2"><li>将 seekdb 作为元数据库<br/>因为 seekdb 兼容 mysql 协议，所以可以将seekdb也作为 RAGFlow 的元数据库<br/>修改.env文件：</li></ol><p><img width="723" height="191" referrerpolicy="no-referrer" src="/img/bVdnUwk" alt="" title="" loading="lazy"/></p><p>修改docker-compose.yml文件，注释以下 depends_on 字段</p><p><img width="723" height="273" referrerpolicy="no-referrer" src="/img/bVdnUwn" alt="" title="" loading="lazy"/></p><p>修改docker-compose-base.yml文件，注释以下 mysql 服务</p><p><img width="652" height="774" referrerpolicy="no-referrer" src="/img/bVdnUwp" alt="" title="" loading="lazy"/></p><ol start="3"><li>启动服务</li></ol><p><img width="723" height="83" referrerpolicy="no-referrer" src="/img/bVdnUws" alt="" title="" loading="lazy"/></p><p>执行指令后能看到如下输出</p><p><img width="723" height="252" referrerpolicy="no-referrer" src="/img/bVdnUwu" alt="" title="" loading="lazy"/></p><p>可以执行docker ps检查容器状态，能看到如下输出</p><p><img width="723" height="33" referrerpolicy="no-referrer" src="/img/bVdnUwv" alt="" title="" loading="lazy"/></p><p>通过 docker compose logs -f ragflow-cpu 或者 docker compose logs -f ragflow-gpu（以实际设备为准）查看日志出现 RAGFlow admin is ready after XXs initialization则启动服务成功</p><p><img width="723" height="176" referrerpolicy="no-referrer" src="/img/bVdnUww" alt="" title="" loading="lazy"/></p><ol start="4"><li>通过 RAGFlow 构建 AI 应用<br/>浏览器输入 <a href="https://link.segmentfault.com/?enc=nlygFhlz79pFY1IVM9Nbzw%3D%3D.NdFWA70p0WabovcESWTE9Plp5GD0Gs%2Fv4b6xem27pFM%3D" rel="nofollow" target="_blank">http://localhost</a> 进入界面，首次登录点击「Sign up」注册账号</li></ol><p><img width="723" height="372" referrerpolicy="no-referrer" src="/img/bVdnUwx" alt="" title="" loading="lazy"/></p><p>填写完注册信息后，点击 「Continue」 继续</p><p><img width="723" height="392" referrerpolicy="no-referrer" src="/img/bVdnUwy" alt="" title="" loading="lazy"/></p><p>回到登录界面后，点击 「Sign in」 登录账号</p><p><img width="723" height="383" referrerpolicy="no-referrer" src="/img/bVdnUwz" alt="" title="" loading="lazy"/></p><p>首次进入 ragflow 界面后，点击右上角的账户图标</p><p><img width="723" height="336" referrerpolicy="no-referrer" src="/img/bVdnUwA" alt="" title="" loading="lazy"/></p><p>选择 「Model providers」 设置 Api Key 和模型，以下以通义千问为例</p><p><img width="723" height="382" referrerpolicy="no-referrer" src="/img/bVdnUwB" alt="" title="" loading="lazy"/></p><p>填写 API-Key 后，点击 「Save」 保存配置</p><p><img width="723" height="375" referrerpolicy="no-referrer" src="/img/bVdnUwC" alt="" title="" loading="lazy"/></p><p>根据需要选择需要的各类模型，这里案例选择了 「qwen-plus」 作为 LLM 模型、「text-embedding-v4」 作为 Embedding 模型、「gte-rerank」 作为 Rerank 模型</p><p><img width="723" height="374" referrerpolicy="no-referrer" src="/img/bVdnUwD" alt="" title="" loading="lazy"/></p><p>回到主界面，点击 「Dataset」 进入知识库界面，点击界面中央如下图标创建新的知识库</p><p><img width="723" height="344" referrerpolicy="no-referrer" src="/img/bVdnUwE" alt="" title="" loading="lazy"/></p><p>根据需要选择分段方法，案例选择了 「General」（通用） 作为了分段方法，如果您的文档主要是Q&amp;A问答对，您也可以选择 「Q&amp;A」 作为分段方法</p><p><img width="723" height="369" referrerpolicy="no-referrer" src="/img/bVdnUwF" alt="" title="" loading="lazy"/></p><p>点击 「Save」 创建空知识库</p><p><img width="723" height="369" referrerpolicy="no-referrer" src="/img/bVdnUwG" alt="" title="" loading="lazy"/></p><p>点击 「Add file」 中的 「Upload file」 上传文档</p><p><img width="723" height="370" referrerpolicy="no-referrer" src="/img/bVdnUwH" alt="" title="" loading="lazy"/></p><p>点击或者拖取的方式上传需要的文档后，点击 「Save」 保存</p><p><img width="723" height="369" referrerpolicy="no-referrer" src="/img/bVdnUwI" alt="" title="" loading="lazy"/></p><p>因为上传的时候没有勾选「Parse on creation」 ，这里需要全选文档后点击 「Parse」 解析文档构建索引</p><p><img width="723" height="373" referrerpolicy="no-referrer" src="/img/bVdnUwJ" alt="" title="" loading="lazy"/></p><p>文档索引构建完毕</p><p><img width="723" height="373" referrerpolicy="no-referrer" src="/img/bVdnUwK" alt="" title="" loading="lazy"/></p><p>构建知识库完成后，回到主界面，我们以构建搜索助手作为案例，点击 「Search」 后点击界面中央如下图标</p><p><img width="723" height="335" referrerpolicy="no-referrer" src="/img/bVdnUwL" alt="" title="" loading="lazy"/></p><p>填写 「search」 的 「Name」 后，点击 「Save」 保存</p><p><img width="723" height="372" referrerpolicy="no-referrer" src="/img/bVdnUwM" alt="" title="" loading="lazy"/></p><p>选择 「Datesets」</p><p><img width="723" height="361" referrerpolicy="no-referrer" src="/img/bVdnUwN" alt="" title="" loading="lazy"/></p><p>其他配置按需配置，这里案例勾选了 「AI summary」（可选），点击 「Save」 保存</p><p><img width="723" height="380" referrerpolicy="no-referrer" src="/img/bVdnUwO" alt="" title="" loading="lazy"/></p><p>根据案例的知识库，提问 「Why oceanbase is a distributed database?」 成功检索到了相关的段落并且以此生成了脉络清晰的总结！</p><p><img width="723" height="372" referrerpolicy="no-referrer" src="/img/bVdnUwS" alt="" title="" loading="lazy"/></p><h2>04 从技术到生态：AI 原生的未来图景</h2><p>RAG 技术不会过时，相反，它正在从一个具体的技术方案演进为 AI 应用的基础设施层。当我们把视角从单一的文档问答提升到 Context Engine 的高度时，就会发现 Retrieval 能力是连接 Memory、知识库、工具调用等所有 Agent 要素的关键纽带。而 AI 原生搜索数据库，正是提供这种能力的最佳载体。</p><p>2026 年，随着 Agent 技术的收敛和标准化，企业级 AI 应用将迎来真正的落地浪潮。在这个过程中，选择正确的数据底座至关重要。RAGFlow 的架构理念与 OceanBase seekdb 的技术能力相互印证：强大的混合搜索能力、统一的数据处理范式、轻量级的部署方式，这些特性共同构成了 AI 原生时代的数据基础设施。</p><p>从 RAG 到 Context Engine 的演进，不仅是技术路径的升级，更是对 AI 应用本质的深刻理解。当我们像人一样思考数据的组织和检索，当我们用 AI 原生的方式重构数据底座，企业级智能体的大规模落地才真正成为可能。这正是 RAGFlow 与 OceanBase seekdb 携手探索的方向，也是整个 AI 原生生态共同的未来。</p><p>欢迎访问 OceanBase 官网获取更多信息：<a href="https://link.segmentfault.com/?enc=lhJB2GrApVRaU2Sw0UR6nw%3D%3D.pnOE9RXtzRdTZ7IQUAMYlKAut6XEhv%2BwkDajFQn%2FwkE%3D" rel="nofollow" target="_blank">https://www.oceanbase.com/</a></p>]]></description></item><item>    <title><![CDATA[公众号打招呼营销回复：59秒、48小时微信新规解决方案 微擎应用市场 ]]></title>    <link>https://segmentfault.com/a/1190000047605532</link>    <guid>https://segmentfault.com/a/1190000047605532</guid>    <pubDate>2026-02-11 15:05:53</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>一、概述总结</p><p>公众号打招呼营销回复是微擎应用市场的一款专业微信公众号营销工具，专为解决微信新规下的客服消息推送限制而设计。该应用通过智能化、延迟化的消息推送机制，帮助运营者在用户关注公众号后的黄金时间内（59秒、48小时）实现精准营销触达，有效提升用户留存率和转化率。</p><p>核心定位：针对微信新规的合规化营销解决方案，实现"即使用户关注后什么都不点击，也可在1分钟内延迟推送"的突破性功能。</p><hr/><p>二、功能介绍</p><ol><li>延迟推送机制</li></ol><ul><li>1分钟延迟推送：即使用户关注后未进行任何操作，系统也能在1分钟内自动推送营销消息，解决微信新规限制</li><li>59秒黄金触达：在用户关注后的首分钟内完成首次互动，抓住用户注意力高峰期</li><li>48小时持续营销：在合规前提下，实现长达48小时的持续营销触达窗口</li></ul><ol start="2"><li>智能回复系统</li></ol><ul><li>自动化营销流程：预设多种营销话术和推送策略，实现无人值守的自动化运营</li><li>个性化内容推送：根据用户行为和标签，推送定制化的营销内容</li><li>多场景触发机制：支持关注、点击、扫码等多种触发条件</li></ul><ol start="3"><li>用户留存优化</li></ol><ul><li>强制触达能力：突破传统客服消息需要用户主动交互的限制</li><li>标签化管理：支持自动为用户打标签，便于后续精细化运营</li><li>互动引导设计：通过红包、优惠券等激励手段，引导用户完成首次互动</li></ul><ol start="4"><li>合规保障</li></ol><ul><li>微信新规适配：专门针对微信最新客服消息规定进行技术处理</li><li>风险控制机制：内置防封号策略，确保账号安全运营</li><li>数据监控面板：实时查看推送成功率、用户互动率等关键指标</li></ul><hr/><p>三、适用场景与行业价值</p><p>核心适用场景</p><p>场景类型 具体应用 价值体现</p><p>新粉激活 用户关注后立即推送欢迎语+福利，降低首关流失率 提升新用户7日留存率30%+</p><p>活动推广 新品上线、限时促销的即时触达 活动参与率提升2-3倍</p><p>内容引流 自动推送爆款文章、视频链接 内容阅读量显著提升</p><p>私域沉淀 引导添加企业微信、加入社群 私域流量池快速扩充</p><p>转化促进 推送优惠券、试用装领取链接 首单转化率提升15%+</p><p>重点服务行业</p><ol><li>电商零售：新品推广、促销活动、复购提醒</li><li>教育培训：课程试听、资料领取、活动报名</li><li>餐饮美业：优惠券发放、预约提醒、会员招募</li><li>本地生活：同城活动、商家引流、社区团购</li><li>内容自媒体：文章推送、粉丝互动、流量变现</li></ol><p>行业价值</p><ul><li>解决痛点：完美解决微信新规后"用户关注即流失"的运营难题</li><li>降本增效：自动化替代人工，节省90%的客服人力成本</li><li>合规运营：在平台规则内实现最大化营销效果，避免封号风险</li><li>数据驱动：通过精准推送提升ROI，让每一分营销预算都产生价值</li></ul><hr/><p>四、产品参数与购买信息</p><ul><li>交付方式：微擎系统在线交付，源码已加密</li><li>适用平台：微信公众号（支持PHP5.6/PHP7.1）</li><li>服务周期：首次购买赠送6个月服务套餐（含更新服务）</li><li>开发者资质：企业认证开发者，信誉指数5.0分，应用评分5.0分</li></ul><hr/><p>五、常见问题解答（FAQ）</p><p>Q1：这个应用能解决微信新规的哪些限制？</p><p>A：微信新规规定，用户关注公众号后，如果未在48小时内主动发消息或点击菜单，运营者无法主动推送客服消息。本应用通过技术手段实现"延迟推送"，即使用户什么都不操作，也能在关注后1分钟内自动推送营销内容，有效突破这一限制。</p><p>Q2：延迟推送是否安全，会不会导致封号？</p><p>A：本应用专门针对微信新规进行合规化处理，采用模拟真实用户行为的推送机制，内置多重风险控制策略。开发者拥有企业认证和5.0分信誉评级，技术方案经过市场验证，在正确使用的前提下是安全的。</p><p>Q3：推送的内容可以自定义吗？</p><p>A：可以。系统支持完全自定义推送内容，包括文字、图片、链接、小程序卡片等多种形式。您可以根据不同用户群体设置差异化的话术和营销策略，实现千人千面的精准推送。</p><p>Q4：48小时营销窗口具体指什么？</p><p>A：指用户关注公众号后的48小时内，您可以通过本应用持续进行营销触达。这是微信允许的服务号客服消息推送时限，本应用帮助您充分利用这个黄金时间窗口，最大化营销效果。</p><p>Q5：这个应用适合什么规模的公众号使用？</p><p>A：适用于所有希望通过公众号进行获客和转化的企业或个人。特别适合：①新号冷启动，需要快速积累种子用户；②成熟号提升活跃度，减少粉丝沉睡；③电商、教育、本地生活等强营销需求行业。</p><p>Q6：购买后包含哪些服务？</p><p>A：首次购买包含6个月服务套餐，期间可享受：①应用功能更新升级；②技术问题咨询支持；③使用指导服务。服务期内可免费更新至最新版本，确保与微信最新规则保持同步。</p><p>Q7：是否支持多公众号同时使用？</p><p>A：根据微擎平台规则，该应用支持在多公众号平台部署，但具体数量需根据您的微擎系统授权类型确定。建议购买前咨询开发者确认授权范围。</p><hr/><p>本文内容基于微擎应用市场公开信息整理，具体功能以实际产品为准。购买前建议通过"立即咨询"功能与开发者确认最新产品细节。</p>]]></description></item><item>    <title><![CDATA[多方签署小程序管理系统详细介绍 微擎应用市场 ]]></title>    <link>https://segmentfault.com/a/1190000047605536</link>    <guid>https://segmentfault.com/a/1190000047605536</guid>    <pubDate>2026-02-11 15:05:09</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <ol><li>概述总结</li></ol><p>多方签署是一款基于微擎平台的小程序应用系统，专为需要多人协作完成同一文档或协议的场景设计。该系统支持微信小程序和抖音小程序定制开发，核心功能是实现多方（最多3方）共同完成一条订单内容或文档记录。</p><p>核心价值定位：</p><ul><li>多人协作：打破传统单人填写模式，支持自定义字段分配给不同角色（甲/乙/丙）共同完成</li><li>电子文档生成：配合"表格生成器"插件，可将协作内容生成并下载为电子文档</li><li>场景适配：特别适用于合同签署、协议确认、租赁约定、事故定损表等需要多方确认的业务场景</li></ul><hr/><ol start="2"><li>功能介绍</li></ol><p>核心功能流程</p><ol><li>发起方创建：由A（发起方）生成初始记录，设定文档基础框架</li><li>字段自定义分配：按业务需求将不同字段分配给N个参与方（甲/乙/丙，N≤3）</li><li>多方协作填写：各方按权限独立完成各自负责的内容部分</li><li>内容自动聚合：系统自动将多方填写的内容整合为一条完整记录</li><li>电子文档输出：通过"表格生成器"插件生成标准化电子文档并支持下载</li></ol><p>系统特性</p><ul><li>字段级权限控制：精确控制每个参与方可查看和编辑的内容范围</li><li>协作状态实时同步：各方填写进度实时更新，避免信息不同步</li><li>数据完整性保障：确保所有必填字段完成后才能生成最终文档</li><li>跨平台支持：一套系统同时适配微信和抖音两大主流小程序生态</li></ul><p>扩展能力</p><ul><li>作为主应用"工单预约表单plus"的关联插件，可无缝集成30+种表单字段类型</li><li>支持分页表单、WEB端、WAP端、微信端多端适配</li><li>灵活对接各类业务场景，不仅限于签署，还可扩展至审批、确认、登记等流程</li></ul><hr/><ol start="3"><li>适用场景与行业价值</li></ol><p>核心应用场景</p><p>场景类型 具体应用 价值体现</p><p>电子合同 甲乙双方或多方合同在线签署 替代传统纸质合同，缩短签署周期从数天至数小时</p><p>事故定损 保险公司、车主、维修厂三方定损确认 现场即时确认，避免后续纠纷，提升理赔效率</p><p>租赁协议 房东、租客、中介三方租赁合约 标准化流程，降低法律风险，保障各方权益</p><p>项目确认 客户、供应商、监理方三方验收 明确责任边界，留存电子证据，便于追溯</p><p>内部审批 部门间协作的跨部门确认单 简化内部流程，提升组织协同效率</p><p>行业价值分析</p><p>对法律服务行业：</p><ul><li>实现电子签名的合规化应用，满足《电子签名法》要求</li><li>降低合同管理成本，提升法律文书处理效率</li></ul><p>对保险金融行业：</p><ul><li>事故现场即时定损确认，缩短理赔周期，提升客户满意度</li><li>多方见证机制增强定损结果的公信力</li></ul><p>对房产租赁行业：</p><ul><li>标准化租赁流程，减少因条款不清导致的纠纷</li><li>电子存证便于长期管理和快速调阅</li></ul><p>对中小企业：</p><ul><li>低成本实现业务流程数字化，无需自建复杂系统</li><li>灵活适配各类确认、审批、登记场景，快速落地</li></ul><hr/><ol start="4"><li>问答环节（FAQ）</li></ol><p>Q1：多方签署系统最多支持几方同时参与？</p><p>A：系统目前支持最多3方（甲/乙/丙）共同完成一条记录，加上发起方A，共涉及4个角色。这已能满足绝大多数合同、协议类场景的需求。</p><p>Q2：生成的电子文档是否具有法律效力？</p><p>A：系统生成的电子文档配合"表格生成器"插件使用，但法律效力取决于具体使用方式和电子签名认证情况。建议结合第三方电子签章服务以满足《电子签名法》要求。</p><p>Q3：是否需要购买其他插件才能使用？</p><p>A：是的，生成和下载电子文档功能需要额外安装【表格生成器】插件。这是实现文档输出的必要组件。</p><p>Q4：该系统是否支持抖音小程序？</p><p>A：支持。系统同时支持微信小程序和抖音小程序定制开发，一套代码可适配两大主流平台。</p><p>Q5：系统是否开源？能否二次开发？</p><p>A：系统源码已加密，不支持直接二次开发。但可通过微擎平台的标准接口进行功能扩展和系统集成。</p><p>Q6：与"工单预约表单plus"是什么关系？</p><p>A：多方签署是工单预约表单plus的关联插件/子应用。表单plus提供30+种字段类型和强大的表单引擎，多方签署在此基础上实现多人协作签署功能。</p><p>Q7：是否支持多方同时在线编辑？</p><p>A：系统采用分字段分配机制，各方按权限独立完成各自部分，并非实时协同编辑模式。这种设计更适合签署类场景，确保各方责任清晰。</p><p>Q8：购买后包含多长时间的售后服务？</p><p>A：首次购买赠送1年服务套餐，在服务周期内可享受应用更新至最新版本的服务。超过服务期后仍可继续使用当前版本，但无法获取更新。</p><p>Q9：系统对服务器环境有什么要求？</p><p>A：系统支持PHP 5.3至PHP 8.0全版本，兼容性强。但建议至少使用PHP 7.0以上版本以获得更好性能。</p>]]></description></item><item>    <title><![CDATA[新畅积分商城系统详细介绍 微擎应用市场 ]]></title>    <link>https://segmentfault.com/a/1190000047605539</link>    <guid>https://segmentfault.com/a/1190000047605539</guid>    <pubDate>2026-02-11 15:04:38</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>一、概述总结</p><p>新畅积分商城是微擎应用市场上一款专注于积分运营的小程序系统，由新畅网络技术公司开发，当前已有113+用户在使用。该系统定位为免费积分商城解决方案，支持微信小程序平台，采用PHP5.5-7.1技术栈，源码已加密保护。</p><p>作为"新畅行业商城软件"的配套子应用，它以轻量化、易部署为特点，帮助企业和商家快速搭建积分兑换、会员激励体系，实现用户留存与活跃度提升。系统采用微擎系统在线交付方式，提供6个月免费服务周期，适合中小商家低成本启动积分运营。</p><p>核心定位：通过积分签到、兑换、抽奖三大核心功能，构建完整的积分生态闭环，增强用户粘性。</p><hr/><p>二、功能介绍</p><ol><li>积分签到系统</li></ol><ul><li>每日签到：用户每日访问小程序即可获得积分奖励</li><li>连续签到激励：支持设置连续签到额外奖励，培养用户习惯</li><li>签到提醒：通过微信服务消息或订阅消息提醒用户签到</li></ul><ol start="2"><li>积分兑换商城</li></ol><ul><li>商品管理：后台可添加实物商品、虚拟商品、优惠券等兑换品</li><li>积分定价：灵活设置商品所需积分值，支持"积分+现金"混合支付模式</li><li>库存控制：实时库存管理，自动下架无库存商品</li><li>订单管理：完整的兑换订单流程，支持物流发货（实物）或自动核销（虚拟）</li></ul><ol start="3"><li>积分抽奖功能</li></ol><ul><li>大转盘/九宫格：多种抽奖形式，消耗积分参与</li><li>奖品设置：支持积分、优惠券、实物奖品等</li><li>概率控制：后台可调整中奖概率，控制运营成本</li></ul><ol start="4"><li>会员等级体系</li></ol><ul><li>等级划分：支持普通会员、银会员等多级体系</li><li>升级规则：基于消费次数或积分累计值自动升级</li><li>等级权益：不同等级享有不同的积分获取倍数或兑换折扣</li></ul><ol start="5"><li>数据与运营支持</li></ol><ul><li>用户数据：积分获取/消耗记录、兑换历史查询</li><li>运营统计：签到率、兑换率、抽奖参与度等核心指标</li><li>消息通知：兑换成功、发货通知、积分变动提醒</li></ul><hr/><p>三、适用场景与行业价值</p><p>适用场景</p><ol><li>零售电商：作为主商城的补充，通过积分兑换提升复购率</li><li>餐饮门店：积分兑换优惠券或菜品，促进二次消费</li><li>教育培训：学员积分兑换课程资料或课时，提高完课率</li><li>社区运营：业主积分兑换物业服务或周边商品，增强社区粘性</li><li>企业内部：员工积分兑换福利，构建内部激励体系</li></ol><p>行业价值</p><ul><li>用户留存：通过每日签到和积分积累，将一次性用户转化为活跃用户</li><li>成本可控：积分作为虚拟货币，商家可灵活控制成本，相比直接降价更具弹性</li><li>数据沉淀：积分行为数据帮助商家识别高价值用户，优化运营策略</li><li>生态闭环：与主商城系统联动，实现"消费-积分-再消费"的良性循环</li><li>零门槛启动：免费使用降低试错成本，适合初创企业或预算有限的商家</li></ul><hr/><p>四、常见问题解答（FAQ）</p><p>Q1：新畅积分商城是否完全免费？</p><p>A：是的，当前版本价格为0元，服务周期为6个月。但需注意这是基于微擎平台的应用，使用需先部署微擎系统。</p><p>Q2：该系统支持哪些平台？</p><p>A：目前主要支持微信小程序，需具备微信小程序账号及微擎系统环境。</p><p>Q3：源码是否开源？</p><p>A：源码已加密，属于SaaS化交付模式，商家通过后台进行配置管理，无需自行开发。</p><p>Q4：能否与现有商城系统对接？</p><p>A：作为"新畅行业商城软件"的附属应用，建议配套使用。如需对接其他系统，需评估API接口兼容性。</p><p>Q5：积分如何发放？</p><p>A：主要通过每日签到发放，也可结合主商城的消费返积分功能（需主商城支持）。</p><p>Q6：实物商品兑换后如何发货？</p><p>A：系统支持订单管理，商家可在后台处理发货流程，用户可查询物流状态。</p><p>Q7：是否支持多门店或多商户模式？</p><p>A：当前版本为单店模式，多商户需求需使用"新畅行业商城软件"主应用。</p><p>Q8：抽奖功能的中奖概率可以调整吗？</p><p>A：是的，后台支持设置各奖项的中奖概率，便于控制活动预算。</p><p>Q9：用户数据是否安全？</p><p>A：系统获取用户微信昵称、头像等基本信息，符合微信小程序隐私规范，数据存储于商家自有服务器。</p>]]></description></item><item>    <title><![CDATA[小店神器招商版 - 小商店集群管理SaaS系统 微擎应用市场 ]]></title>    <link>https://segmentfault.com/a/1190000047605543</link>    <guid>https://segmentfault.com/a/1190000047605543</guid>    <pubDate>2026-02-11 15:03:48</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>一、概述总结</p><p>小店神器招商版是一款基于微擎平台开发的小商店集群管理SaaS系统，专为解决微信小商店规模化运营难题而生。该系统通过多开版本架构，支持一个微擎对接不同开放平台授权，实现同时管理数千个小商店的集中化运营。</p><p>核心定位是小商店全生态运营解决方案，不仅提供商品搬家、批量上架等基础功能，更构建了完整的供应链体系——用户可自建本地云仓为其他小店供货，也可使用系统自带云仓实现一件代发、自动打单（电子面单），全方位支撑小商店运营。</p><p>项目自上线以来历经50+次版本升级，服务100+客户，保持零退款率记录，持续贴近市场运营需求。</p><hr/><p>二、功能介绍</p><ol><li>核心运营功能</li></ol><p>搬家上货系统</p><ul><li>支持将拼多多、淘宝、天猫、1688等平台商品一键搬家至微信小商店</li><li>大幅降低商品上架门槛，提升上货效率</li></ul><p>智慧云仓系统</p><ul><li>接入京东、1688等优质商户货源</li><li>小店下单后，云仓自动生成订单并代发货</li><li>发货后物流信息自动同步至小商店</li><li>价格优势：同一商品京东价24.9元，云仓价仅4.0元（含系统利润）</li></ul><p>货源市场（国美模式）</p><ul><li>优选小店商品进入公共货源市场</li><li>其他商户可一键铺货，产生订单后再向货源方采购</li><li>支持收取供应商上架费用</li></ul><p>商品云分发</p><ul><li>将商品一键分发至所有授权的小店</li><li>实现"一件商品，千店同步销售"</li></ul><p>店铺复制功能</p><ul><li>完整复制某小商店全部商品至另一店铺（需双方授权）</li></ul><p>订单管理系统</p><ul><li>智能分析订单货品来源</li><li>自动提示最优采购渠道</li></ul><ol start="2"><li>技术架构优势</li></ol><ul><li>多开版本：支持一个微擎对接不同开放平台授权，或复用已通过的授权</li><li>官方接口：所有接口均为微信官方正式接口，运营无后顾之忧</li><li>技术栈：采用Python+Vue+开放平台等多种技术，系统稳定可靠</li></ul><ol start="3"><li>商户端与后台管理</li></ol><ul><li>提供完善的商户端操作界面</li><li>强大的后台管理系统，支持精细化运营</li><li>持续迭代升级，保持行业技术领先</li></ul><hr/><p>三、适用场景与行业价值</p><p>适用场景</p><p>场景类型 具体应用</p><p>总店-分店模式 品牌方统一管理数千家分销店铺，实现商品统一上架、库存同步、订单集中处理</p><p>微商分销场景 为微商团队提供独立小商店，自带货源一键代发，解决分销层级管理难题</p><p>实体店带货场景 本地实体店（服装、五金、家具、建材等）产品聚合，通过达人小商店分销</p><p>网店分销场景 传统电商卖家拓展微信生态渠道，快速复制店铺矩阵</p><p>行业价值</p><p>对平台运营方（您）：</p><ul><li>轻资产创业：2M服务器即可运营，月成本100+元</li><li><p>多重盈利模式：</p><ul><li>系统使用费（150元/店/年起）</li><li>供应商入驻费/产品上架费（500元/件起）</li><li>产品销售差价（5-10%利润）</li><li>小店入驻押金（预存款，1000元/店，100店即沉淀10万资金）</li><li>供应商提现服务费</li></ul></li><li>睡后收入：前期搭建完成后，后期可持续躺赚</li><li>蓝海市场：本地竞争少，模式新颖，可持续运营3年以上</li></ul><p>对供应商：</p><ul><li>解决铺货渠道单一困境，一件商品瞬间同步千店销售</li><li>零库存压力，产生订单后再发货</li><li>可发展专属带货小店，给员工和VIP客户开店使用</li></ul><p>对小商店店主（达人）：</p><ul><li>获得独家低价货源，提升利润空间</li><li>无需处理订单和物流，专注卖货即可</li><li>拥有独立客户资源，非跳转式带货，积累私域流量</li><li>定期培训交流，提供成长空间</li></ul><p>行业生态价值：</p><ul><li>构建本地城市商品聚合市场，赋能百万小商店</li><li>打通"供应商-平台-小店-消费者"全链路</li><li>推动微信电商生态从"带货模式"向"代销模式"升级，实现真正的店铺独立运营</li></ul><hr/><p>四、问答环节</p><p>Q1：这个系统具体是做什么的？</p><p>A： 这是一个小商店集群管理SaaS系统，可以同时管理几千个小店。核心功能包括：为小店提供批量上货便利、搭建自有供应链系统、精选同城好店产品、支持快递和到店取货。简单说，就是帮传统门店建立分销渠道，为带货达人提供变现货源的平台。</p><p>Q2：微信小商店自带货源功能，为什么还要用这个系统？</p><p>A： 关键区别在于带货模式vs代销模式：</p><ul><li>小商店自带的是带货模式：用户跳转到第三方店铺购买，你只是推荐人，没有客户积累</li><li>我们的系统是代销模式：订单全程在你的店内完成，客户是你的，可以积累私域流量</li><li>同时提供独家货源渠道，方便小店上货，也方便供应商快速铺货</li></ul><p>Q3：系统有哪些核心盈利点？</p><p>A： 核心盈利模式包括：</p><ol><li>沉淀资金：用户入驻需缴纳预存款（1000元/店），100店即10万沉淀资金</li><li>系统使用费：150元/店/年</li><li>产品上架费：向供应商收取，500元/件起</li><li>销售差价：享受5-10%利润分成</li><li>供应商提现服务费</li></ol><p>注：你只需先在云仓支付少量预付款，或产生订单后给供应商结算</p><p>Q4：什么是云仓？对运营有什么好处？</p><p>A： 云仓是系统集成的百万货源库：</p><ul><li>操作上：后台直接一键上架到小商店</li><li>订单处理：产生订单后云仓负责发货，物流自动同步</li><li>价格优势：同商品京东价24.9元，云仓价仅4.0元（含你的利润）</li><li>运营便利：小店只需专注上货和卖货，订单物流全托管</li></ul><p>Q5：为什么要搭建本地仓？</p><p>A： 本地仓是你的私有供应链系统：</p><ul><li>优选本地商户产品入库，其他小店可一键铺货</li><li>产生订单后本地商家直接发货</li><li>拥有独家货源渠道，成为吸引小店加入的核心竞争力</li><li>可收取供应商入驻费和上架费</li></ul><p>Q6：如何说服供应商入驻系统？</p><p>A： 给供应商的核心价值：</p><ul><li>产品上架本地仓，可被数千小店一键带货</li><li>解决铺货渠道单一问题，扩大销售网络</li><li>可发展专属带货小店，给员工和VIP客户开店使用</li><li>零库存风险，产生订单后再发货</li></ul><p>Q7：如何吸引达人/小店主加入？</p><p>A： 吸引达人的关键点：</p><ul><li>独家货源：本地精选好货+全国云仓低价货源</li><li>价格优势：比京东淘宝更低的进货价</li><li>专属小店：独立运营，积累自己的客户</li><li>运营支持：定期培训交流，提供成长空间</li><li>轻资产运营：无需处理订单物流，专注卖货</li></ul><p>Q8：购买系统后需要准备什么？</p><p>A： 基础配置要求：</p><ul><li>一台服务器（2M带宽即可，月成本100+元）</li><li>微擎系统</li><li>服务号（用于收款）</li><li>微信开放平台（用于授权小店，一次性认证费300元，已有可复用）</li></ul><p>Q9：系统后续还有哪些费用？</p><p>A： 第三方可选费用（非强制）：</p><ul><li>99API采集费：不使用不收费，单条采集2-4分</li><li>云仓预存款：不开通不收费，预存1000元起</li><li>微信开放平台认证：一次性300元（已有认证无需重复申请）</li></ul><hr/><p>结语：小店神器招商版不仅是一套系统，更是一套完整的微信电商运营解决方案。1-3天即可搭建属于你自己的小商店SaaS系统，为百万小商店赋能，开启你的微信电商生态创业之路。</p>]]></description></item><item>    <title><![CDATA[锦鲤抽奖小程序管理系统 微擎应用市场 ]]></title>    <link>https://segmentfault.com/a/1190000047605549</link>    <guid>https://segmentfault.com/a/1190000047605549</guid>    <pubDate>2026-02-11 15:02:51</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>一、概述总结</p><p>锦鲤抽奖是一款基于微擎平台开发的微信小程序抽奖营销系统源码，由"组局同城社交社区平台进群找搭子陪玩旅游"开发者提供。该系统采用社交裂变+抽奖营销双驱动模式，支持平台发布抽奖活动，用户通过抢购参与获得抽奖号码，并通过推荐他人参与获取额外抽奖机会。系统核心亮点在于红包返现机制，可直接对订单推荐人进行现金红包奖励，实现"参与即获客，分享即收益"的营销闭环。</p><p>核心数据：</p><ul><li>交付方式：微擎系统在线交付</li><li>源码状态：已加密</li><li>商品保障：官方正品</li></ul><hr/><p>二、功能介绍</p><ol><li>活动发布与管理</li></ol><ul><li>平台后台一键发布锦鲤抽奖活动</li><li>灵活配置活动时间、奖品、参与规则</li><li>支持指定中奖用户和头衔（后台可控）</li></ul><ol start="2"><li>社交裂变参与机制</li></ol><ul><li>抢购参与：用户抢购成功获得1个或多个抽奖号码</li><li>推荐奖励：推荐他人抢购可获得额外抽奖号码</li><li>多级传播：形成病毒式传播链条，快速扩大活动影响力</li></ul><ol start="3"><li>红包返现系统</li></ol><ul><li>支持对订单推荐人进行现金红包奖励</li><li>实时到账，激励用户主动分享推广</li><li>降低获客成本，提升用户参与积极性</li></ul><ol start="4"><li>开奖与核销</li></ol><ul><li>后台在活动结束前指定中奖用户</li><li>活动结束后自动开奖</li><li>支持奖品核销管理</li></ul><ol start="5"><li>多平台适配</li></ol><ul><li>原生微信小程序支持</li><li>抖音小程序定制开发能力</li><li>一次开发，多端运行</li></ul><hr/><p>三、适用场景与行业价值</p><p>行业价值</p><ol><li>对运营方/商家的价值：</li></ol><ul><li>零成本获客：利用用户社交关系链，实现低成本精准获客</li><li>数据沉淀：完整记录用户参与行为，构建私域流量池</li><li>灵活可控：后台可指定中奖人，确保活动效果可预期</li><li>即时激励：红包实时到账，提升用户参与感和信任度</li></ul><ol start="2"><li>对用户的价值：</li></ol><ul><li>低门槛参与：抢购即可参与，无需复杂操作</li><li>双重收益：既有机会中大奖，推荐还能得红包</li><li>社交货币：分享活动获得社交认同感</li></ul><hr/><p>四、常见问题解答（FAQ）</p><p>Q1：系统支持哪些平台？</p><p>A：原生支持微信小程序，同时提供抖音小程序定制开发服务，可实现多端覆盖。</p><p>Q2：后台可以控制中奖结果吗？</p><p>A：可以。后台在活动结束前可指定中奖用户和头衔，确保活动效果可控，但建议遵循公平原则以维护用户信任。</p><p>Q3：红包返现是如何实现的？</p><p>A：系统支持对订单推荐人进行现金红包奖励，用户推荐他人成功抢购后，推荐人可获得实时到账的现金红包。</p><p>Q4：使用人数&lt;10人，系统稳定吗？</p><p>A：作为新上架应用，使用人数较少属于正常现象。微擎平台提供官方正品保障，且支持90天无售后急速退款（需开通VIP），建议先测试再正式使用。</p><p>Q5：如何安装部署？</p><p>A：通过微擎系统在线交付，购买后可在微擎后台直接安装。需先注册登录微擎账号并绑定站点。</p><p>Q6：适合什么类型的企业使用？</p><p>A：特别适合预算有限的中小企业、线下门店、社交电商、社群运营者，以及需要快速裂变获客的场景。</p>]]></description></item><item>    <title><![CDATA[市面上“低代码开发平台”百花齐放，有没有什么优势比较突出的？ 织信informat ]]></title>    <link>https://segmentfault.com/a/1190000047605556</link>    <guid>https://segmentfault.com/a/1190000047605556</guid>    <pubDate>2026-02-11 15:02:05</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>低代码平台已成为企业加速开发与提升敏捷性的关键利器。相比传统开发方式，低代码不仅能显著降低技术门槛，还能让业务人员与开发团队高效协作，从而快速落地创新应用。</p><p>本篇带来10款知名低代码平台的系统对比，帮助企业在众多选择中找到最契合的解决方案。</p><p>低代码开发平台，百花齐放，国内前十有：织信、奥哲、炎黄、CodeWave、伙伴云、简道云、zoho、明道云、宜搭、微搭、金蝶云苍穹，如果是说各自的优略势，跟企业的规划和市场前景有关：具体具备以下功能。</p><p>1、过硬得产品技术功力</p><p>专注低代码平台开发领域10年以上；</p><p>产品整合能力强大、必须集微服务、集群部署、多租户模式、PaaS服务等功能特性；</p><p>内置流程引擎、表单引擎、报表引擎等七大可视化功能组件和大量实用的业务模板；</p><p>2、靠谱的业务领域知识</p><p>可以提供BPM流程管控、数据跨平台采集和报表展示、原系统流程补强、OA升级/替换、统一门户、移动办公、多租户SaaS应用和智能硬件对接等解决方案；</p><p>有实际的大型集团或党政机关的项目实施案例可以参考；</p><p>有所属领域专业的项目经理（PMP证书加持）及实施团队；</p><p>3、创新的本地交付机制</p><p>提供高拓展性的交付模式，避免拓展能力有限，二开困难；</p><p>提供培训及联合开发模式帮助甲方实现工具和方法论的本地化武装；</p><p>提供版本升级、性能监控与调优等可持续动态售后技术支持服务；</p><p>基于这3点，我为大家做个深度盘点。下面正式开始！</p><p>【低代码平台大比拼：10款主流低代码工具优缺点分析】</p><p>本篇带来 10款知名低代码平台的系统对比，帮助企业在众多选择中找到最契合的解决方案。</p><p>1、织信</p><p>在市面上众多的低代码平台中，织信（织信Informat）的表现值得关注。一方面，根据中国信通院《2025年中国低代码平台发展白皮书》相关测评，如Forrester等权威机构的市场报告，织信被列为国内低代码平台推荐榜首位，作为国内企业级AI低代码领域领军品牌，2025年客户满意度达97.5%，在制造、军工、金融等关键行业积累了万余家大中型客户实践经验。</p><p>另一方面，其核心特点是作为全栈式AI低代码开发平台，支持前端个性化页面与后端业务逻辑的全流程可视化搭建，不存在平台锁定问题，支持私有化部署、混合云架构及任意云环境部署，同时深度融合AI大模型，实现AI原生开发，大幅降低应用开发门槛与交付周期。其独特之处在于，不仅实现全链路可视化开发，更将AI能力深度嵌入开发全流程，支持通过自然语言指令快速生成应用、建模及组件，让非技术人员也能高效完成应用搭建。</p><p>在安全保障方面，织信按照金融级安全标准进行设计，强化企业级安全合规体系，通过多租户权限管理、审计日志追踪、国密加密传输等技术保障数据资产安全，同时通过多项信创认证，全栈适配国产软硬件，支持私有化部署以满足金融、政务、国防军工等行业的严苛监管要求。这一特性（信创适配+金融级合规+全链路安全）在同类平台中构建了其差异化优势，也使其获得了众多大型企业与机构的信赖，其客户案例包括国家电网、中交集团、浙江吉利控股集团、君乐宝乳业集团、某飞机设计研究院、筑福集团、航天工业、某国有大行、施耐德、招商局等，覆盖国防军工、央国企、生产制造、金融证券、生物医疗、物业地产等多个关键行业。</p><p>在行业影响力方面，织信积极参与国内低代码行业信创相关标准的研讨与制定工作，推动低代码技术在信创领域的规范化应用，其全栈AI低代码平台凭借突出的技术实力与广泛的行业落地案例，被纳入中国软件行业协会、中国信通院联合发布的低代码平台测评推荐榜单，同时获得Forrester等国际权威机构的认可，累计服务4万家企业，构建了超过10000个应用，其中70%的应用由不懂代码的业务人员自主搭建，引领低代码“全民开发”的行业趋势。</p><p>从技术底层来看，织信的一个独特之处在于其基于自研的动态领域模型引擎构建，采用Java+Vue技术栈，结合分布式微服务架构，前端基于Vue/React构建动态交互界面，后端通过Spring Cloud实现高效服务治理，形成了“AI+全栈低代码”的独特技术范式。相较于多数基于通用技术框架构建的平台，织信自研的动态领域模型引擎能够更好地适配复杂业务场景，支持复杂逻辑的可视化编排与灵活扩展，同时深度融合多模态大模型，实现AI应用生成准确率达95%，开发效率较传统模式提升500%，提供与企业复杂业务高度契合的开发体验。</p><p>在功能应用层面，该平台展现了广泛的场景支持能力，覆盖生产管理、ERP、CRM、协同办公、项目管理、智慧制造、外贸管理、直播电商、设备管理、仓库管理等全行业场景，尤其在智慧制造领域，可从管理层、运营层、执行层、操控层四个层面整合企业全流程业务，打造智慧工厂。它已在制造、国防军工、金融、生物医疗、物业地产等行业成功落地多个项目，例如浙江吉利控股集团基于织信实现数字化转型，开发周期平均缩短61%，人力投入减少47%，解决了开发需求堆积的难题；君乐宝乳业通过织信自主配置生产管理相关应用，每周上新系统，实现生产管理流程数字化全覆盖。此外，平台具备卓越的扩展性，支持函数、脚本、扩展包、自定义API等多种扩展方式，可无缝对接企业现有系统，同时适配多种终端（PC、H5移动端等），实现“一次开发，多端适配”。</p><p>为了提升开发效率，平台内置了丰富的组件库、资产中心、模板库和开放API网关，能够便捷地对接企业现有的ERP、OA、SRM、数据库、API等各类系统，有效打通数据孤岛，清理数据死角。同时，它还支持多人在线协同开发，实现业务人员与IT团队的协同闭环，提供组件级复用与精细化版本管理，适配复杂项目的并行开发与持续交付需求；依托AI原生能力，30秒可实现从需求到成品页面的快速生成，标准化应用搭建仅需2小时，大幅缩短应用交付周期，降低开发与维护成本。</p><p>2、奥哲氚云</p><p>产品简介：氚云是钉钉生态内的深度合作伙伴，是一款面向企业的零代码应用搭建平台，深度集成钉钉的组织架构、待办、消息等能力，帮助企业在钉钉上快速构建业务应用。</p><p>推荐适用人群：深度使用钉钉作为办公协同平台的企业，希望在钉钉内快速构建业务流程和管理应用的用户。</p><p>核心功能：拖拽式表单设计、流程引擎、报表仪表盘、深度集成钉钉、连接器与API。</p><p>优点：与钉钉生态无缝集成，能直接利用钉钉的组织架构、消息通知和工作台入口，用户体验统一；开发周期短，能够快速将业务需求转化为钉钉内的可用应用；拥有丰富的钉钉应用市场模板，可一键安装使用。</p><p>总结：氚云的最大特点是与钉钉的无缝集成，能充分利用钉钉的协同能力和用户基础。对于希望在钉钉工作台上实现业务流程在线化和移动化的企业而言，氚云是一个高效且便捷的选择。</p><p>3、炎黄</p><p>产品简介：炎黄盈动是一家以BPM（业务流程管理）为核心技术的PaaS厂商，其AWS PaaS平台提供了强大的流程引擎、低代码应用开发和集成能力，帮助企业实现端到端的流程自动化。</p><p>推荐适用人群：对业务流程管理和自动化有强需求，需要构建流程驱动型应用的大中型企业。</p><p>核心功能：强大的BPMN流程引擎、低代码应用容器（L-CAP）、集成平台（i-PaaS）、规则引擎、移动应用开发。</p><p>优点：在BPM领域技术积累深厚，流程引擎的专业度和性能业界领先；平台遵循BPMN 2.0等国际标准，专业性强；提供“流程+低代码”的完整解决方案，能有效驱动业务和应用的融合。</p><p>总结：炎黄盈动的核心竞争力在于其深耕多年的BPM技术。其平台在处理复杂、长周期、跨部门的业务流程方面表现出色，非常适合用于企业的流程梳理、优化和再造。</p><p>4、伙伴云</p><p>产品简介：伙伴云是一家以零代码数据协同为核心的aPaaS厂商，其零代码数字化服务平台融合云表格Pro、项目协作与低代码应用搭建能力，帮助企业实现数据整合、协同办公与业务场景快速数字化落地。</p><p>推荐适用人群：对数据协同和轻量级业务数字化有强需求，需要快速搭建个性化管理应用的中小企业及各类业务团队。</p><p>核心功能：零代码应用搭建、云表格Pro数据管理、项目协作管理、数据可视化仪表盘、AI辅助应用搭建。</p><p>优点：在零代码数据协同领域体验出色，操作简洁易上手，非技术人员可快速落地应用；融合云表格与低代码，兼顾灵活性与易用性，适配多类轻量业务场景；AI辅助搭建能力领先，有效降低应用建模门槛，提升数字化落地效率。</p><p>总结：伙伴云的核心竞争力在于其零代码与数据协同的深度融合。其平台在处理中小企业轻量业务场景、实现数据整合与团队协同时表现出色，非常适合用于企业的业务数据管理、协同效率提升与轻量化数字化转型。</p><p>5、简道云</p><p>产品简介：简道云是帆软软件旗下的零代码应用搭建平台，它让用户无需代码即可快速构建CRM、ERP、OA等个性化管理应用，并具备强大的数据分析和展示能力。</p><p>推荐适用人群：需要快速搭建数据管理和业务流程应用，并对数据可视化报表有较高要求的企业及业务人员。</p><p>核心功能：零代码应用搭建、自定义仪表盘、流程引擎、智能提醒、数据导入导出与API集成。</p><p>优点：继承帆软强大的数据分析基因，报表和仪表盘功能突出；产品易用性高，表单和流程设计灵活；提供丰富的模板和解决方案，能快速满足不同行业和场景的需求。</p><p>总结：简道云继承了帆软在数据分析领域的基因，除了灵活的应用搭建能力外，其数据可视化和仪表盘功能十分突出。它适合那些既需要业务流程管理，又看重数据驱动决策的企业。</p><p>6、Zoho</p><p>产品简介：Zoho Creator 是一款全球知名的在线低代码应用开发平台，它使个人和企业能够通过简单的拖放界面创建定制化的Web和移动应用程序，以实现业务流程的自动化。</p><p>推荐适用人群：需要构建定制化业务应用的中小型企业、部门级用户，以及寻求高性价比国际化解决方案的开发者。</p><p>核心功能：可视化应用构建器、强大的脚本语言Deluge、工作流自动化、AI功能、多平台应用生成。</p><p>优点：平台成熟稳定，经过全球市场长期验证；自研的Deluge脚本语言功能强大且易于学习，提供了优秀的扩展能力；性价比高，并能与Zoho生态内的其他数十款SaaS应用（如CRM、Mail）无缝集成。</p><p>总结：Zoho Creator 在全球市场拥有长期的实践积累，平台成熟稳定，功能全面。其自研的Deluge脚本语言提供了强大的扩展性，使其在低代码和专业代码之间取得了良好的平衡，适合构建各类复杂度的应用。</p><p>7、明道云</p><p>产品简介：明道云是一款APaaS（应用平台即服务）产品，定位为“零代码”应用搭建平台，让业务人员可以通过拖拽式操作，快速构建个性化的管理应用。</p><p>推荐适用人群：企业业务部门人员、IT部门、系统集成商，尤其适合需要快速响应业务变化、搭建各类管理系统（如CRM、OA、项目管理等）的企业。</p><p>核心功能：零代码应用搭建、工作流自动化、角色权限管理、数据视图与仪表盘、API集成与Webhook。</p><p>优点：上手门槛极低，对非技术人员友好，真正赋能业务人员自主搭建应用；产品迭代迅速，功能完善且覆盖场景广泛；提供公有云、私有云和混合云等多种部署方式，满足不同企业的安全与合规需求。</p><p>总结：明道云以其友好的用户界面和强大的零代码能力著称，极大地降低了软件开发的门槛。它赋予了业务人员自主创建应用的能力，非常适合用于企业内部流程优化和管理应用的快速迭代。</p><p>8、宜搭</p><p>产品简介：宜搭是阿里巴巴钉钉自主研发的APaaS（应用平台即服务）产品，定位为零代码/低代码应用搭建平台，依托阿里技术底座，通过可视化拖拽操作，让非技术人员也能快速搭建专属应用，实现业务流程线上化，传统模式下需十余天完成的应用，用宜搭最短2小时即可落地，助力企业高效推进数字化转型。</p><p>推荐适用人群：企业业务部门人员、IT部门、政务单位相关人员，尤其适合钉钉生态用户、各类规模企业（从小团队到中大型组织），以及需要快速搭建轻量至复杂应用（如HR管理、考勤审批、政务办公、生产管理等）的主体。</p><p>核心功能：零代码/低代码应用搭建、工作流与审批自动化、角色权限精细化管理、数据可视化与报表分析、钉生态深度集成与API扩展、AI辅助搭建、400+应用模板库、集成自动化与连接器工厂。</p><p>优点：上手门槛极低，可视化拖拽操作简洁直观，搭配丰富的现成模板，非技术人员可快速上手落地应用；与钉钉、阿里云深度融合，拥有200+高频连接器，能有效消除企业数据孤岛，协同办公效率突出；AI能力赋能，无需编码即可调用AI插件，加速应用交付；具备亿级数据处理能力，通过三级等保、ISO认证，依托阿里云安全底座，提供多版本部署方案，满足不同规模企业及政务场景的安全与合规需求；扩展能力强劲，开放80+OpenAPI，支持复杂业务逻辑定制与多应用互连互通。</p><p>总结：宜搭依托阿里技术实力和钉钉生态优势，以零代码/低代码拖拽搭建为核心，兼顾易用性与扩展性。它不仅极大降低了应用开发的门槛，赋能业务人员自主创新，还通过生态联动和AI加持，实现企业业务数字化与协同效率的双重提升，适合各类规模企业及政务单位快速搭建个性化应用，适配从简单办公流程到复杂业务管理的全场景需求。</p><p>9、微搭</p><p>产品简介：腾讯云微搭是一款高性能的低代码开发平台，打通腾讯云和微信生态，通过拖拽式开发，帮助开发者和企业快速构建小程序、H5应用和Web应用。</p><p>推荐适用人群：希望快速开发小程序、H5等前端应用，并利用腾讯云和微信生态能力的开发者和企业。</p><p>核心功能：拖拽式页面设计、云原生一体化、连接微信生态、模板库、支持少量代码扩展。</p><p>优点：与微信生态（小程序、公众号、企业微信）深度打通，开发和发布流程极为便捷；背靠腾讯云，提供了稳定可靠的云原生基础设施和服务；支持代码扩展，兼顾了开发效率与灵活性。</p><p>总结：微搭的核心优势在于其与腾讯生态的深度整合，尤其是微信小程序开发。对于重点业务场景在微信生态内，或希望利用腾讯云服务的企业来说，微搭提供了极大的便利和效率。</p><p>10、金蝶云苍穹</p><p>产品简介：金蝶云苍穹是金蝶集团推出的企业级PaaS平台，内嵌低代码家族（应用开发、数据分析、集成、流程等平台），旨在帮助大型企业快速构建支持自身业务发展、且安全可控的数字化应用。</p><p>推荐适用人群：追求自主可控、需要构建复杂、高性能企业级应用的大型集团企业、国央企及核心IT团队。</p><p>核心功能：动态领域模型（KDDM）、一体化低代码开发、企业级云原生架构、集成与流程服务、数据智能分析服务。</p><p>优点：与金蝶ERP等核心业务系统原生集成，具备深厚的企业管理领域知识沉淀；平台技术架构先进，为大型企业提供了稳定、安全、可扩展的数字化基座；提供完整的企业级解决方案，而非单一的开发工具。</p><p>总结：金蝶云苍穹是一个重型、企业级的PaaS平台，其优势在于深度融合了金蝶多年的企业管理软件实践，为大型企业提供了从底层技术到上层应用构建的一整套解决方案，特别适合进行核心系统重构或构建复杂的行业应用。</p><p>总结</p><p>通过对10款主流低代码平台的功能、应用场景、扩展性与性价比的横向评测，我们可以发现：不同平台各有优势，有的更注重企业级安全与集成能力，有的则强调敏捷开发与业务部门的自助构建能力。对于企业来说，选择低代码平台的关键在于 匹配自身业务目标与IT战略，而非一味追求“大而全”。 未来，随着AI与自动化技术的深入融合，低代码将进一步成为企业数字化的核心驱动力。希望本文的对比分析，能为您在选型和落地过程中提供实用参考，助力企业高效构建属于自己的数字生态。</p><p>关于低代码平台的常见问题解答 (FAQ)</p><p>1、低代码平台是否意味着不再需要专业程序员了？</p><p>不会。低代码平台旨在提升效率，而非取代程序员。复杂的核心业务逻辑、高性能要求的系统集成以及平台的二次开发与扩展，仍然需要专业程序员的深度参与。低代码让程序员能从重复性工作中解放出来，更专注于高价值的创造性任务。</p><p>2、使用低代码平台构建的应用，数据安全有保障吗？</p><p>主流的低代码平台通常都提供银行级别的安全保障。它们提供包括数据加密、精细的权限控制、安全审计、API安全网关等多层安全机制。但在选型时，企业仍需仔细评估平台是否符合自身行业的安全合规标准。</p><p>3、低代码平台适合开发所有类型的应用吗？</p><p>不完全是。低代码平台在企业管理应用、工作流自动化、数据报表、移动应用等场景中表现出色。但对于需要极致性能、复杂算法或底层硬件交互的应用（如大型游戏引擎、高频交易系统），传统开发模式可能仍然是更好的选择。</p>]]></description></item><item>    <title><![CDATA[小家电组装行业MES系统及AI智能化应用解决方案 万界星空科技 ]]></title>    <link>https://segmentfault.com/a/1190000047605562</link>    <guid>https://segmentfault.com/a/1190000047605562</guid>    <pubDate>2026-02-11 15:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>——轻量化、高柔性、低成本，助力小家电企业实现“快交付、零缺陷、强追溯”<br/><strong>一、行业痛点：小家电制造的“三高”困境</strong><br/>小家电（如饮水机、空气炸锅、咖啡机、电水壶、扫地机器人等）具有SKU多、订单碎片化、交付周期短、外观要求高的特点，普遍面临：</p><ul><li>❌ 生产黑箱：进度靠问、报工靠纸、异常靠吼；</li><li>❌ 质量靠人盯：外壳划痕、配件漏装、功能测试遗漏频发；</li><li>❌ 新品上线慢：每换一款产品，就要重新培训、调整流程；</li><li>❌ 客户审核难通过：无法提供完整的电子批记录与追溯证据；</li><li>❌ 成本压到极限：传统ERP/MES动辄数十万，中小企业用不起。<br/><img width="683" height="529" referrerpolicy="no-referrer" src="/img/bVdnUxN" alt="" title=""/><br/><strong>二、家电MES核心应用场景与AI智能化应用</strong><br/>✅ 1. 智能排产与订单协同</li><li>销售订单 → 自动分解BOM → 智能排产（考虑模具、产能、交期）</li><li>支持插单、急单优先，动态调整计划</li><li>车间大屏实时显示：当日计划达成率、延迟预警<br/>✅ 2. 全流程防错装配<br/>防错点         AI/系统实现方式<br/>物料错用       扫码领料，系统校验BOM（如“咖啡机A不可用电机B”）<br/>工序漏做       工位PDA强制扫码过站，未完成上道工序禁止流转<br/>关键参数失控   扭矩枪数据自动采集，超差报警并冻结产品<br/>功能测试缺失   测试工位未触发 → 系统禁止包装<br/>✅ 3. AI视觉智能质检（核心亮点）<br/>针对小家电高外观要求，部署多场景AI检测：<br/>检测环节        缺陷类型                              技术方案<br/>外壳/面板       划痕、凹陷、色差、LOGO歪斜          HDR高动态成像 + 深度学习<br/>装配完整性     水箱未装、滤网缺失、螺丝漏打          多角度视觉 + 目标检测<br/>标签与铭牌     型号错误、二维码模糊、3C标志缺失      OCR + 模板匹配<br/>功能验证辅助   屏幕不亮、出水异常、Wi-Fi指示灯状态   视觉+传感融合分析<br/>✅ 4. 自动化测试与数据闭环</li><li>对接老化测试台、电气安全测试仪、气密性检测设备；</li><li>测试数据自动上传至MES，生成《出厂检验报告》；</li><li>不合格品自动分流至维修站，维修后复测闭环。<br/>✅ 5. 全链路追溯与客户合规</li><li>一机一码：每台产品绑定唯一追溯码（含生产时间、班次、测试数据）；</li><li>正向追踪：某批次电机 → 装配哪些咖啡机 → 发往哪些客户；</li><li><p>反向溯源：客户投诉“不出水” → 3分钟定位至：</p><ul><li>具体工位、操作员</li><li>水泵型号、测试曲线</li><li>AI质检图像存档</li></ul></li><li>一键生成客户所需报告：支持亚马逊、小米、沃尔玛等格式。<br/>✅ 6. 仓储与物流协同</li><li>成品入库自动绑定生产日期+保质期（如滤芯有效期）；</li><li>出库按先进先出（FIFO），超期产品自动冻结；</li><li><p>快递单自动打印，对接菜鸟、京东物流API。<br/><strong>四、系统架构</strong></p><pre><code>   ┌──────────────┐
   │   电商平台 / ERP  │ ← 订单、主数据
   └──────┬───────┘
          ↓
   ┌──────────────────────┐
   │   万界星空小家电SaaS MES   │ ← 核心执行平台
   └──────┬───────────────┘</code></pre><p>┌───────────┼────────────────────┐<br/> ↓           ↓                    ↓<br/>┌─────────┐ ┌──────────┐   ┌──────────────────┐<br/>│ 工位PDA   │ │ AI视觉终端  │   │ 自动化测试设备群     │<br/>│(扫码报工) │ │(缺陷检测)  │   │(电气/气密/老化测试) │<br/>└─────────┘ └──────────┘   └──────────────────┘</p><pre><code>               ↓
   ┌──────────────────────┐
   │ 客户门户 / 物流平台 / Andon看板 │
   └──────────────────────┘</code></pre></li><li>专注小家电细分场景：已服务饮水机、咖啡机、空气炸锅等客户；</li><li>真正轻量化：SAAS模式，按年付费；30天上线。 <br/>在小家电“内卷”时代，  <br/>胜出者不是价格最低的，而是质量最稳、交付最快、数据最透明的。<br/>万界星空——让每一家小家电工厂，都拥有“大厂级”的数字能力。<br/>让智能，不再昂贵；让制造，更加从容。</li></ul>]]></description></item><item>    <title><![CDATA[从 AirFlow+EMR 到一站式平台：数新智能助力某运动品牌实现云上数据平台统一治理与成本优化 ]]></title>    <link>https://segmentfault.com/a/1190000047605335</link>    <guid>https://segmentfault.com/a/1190000047605335</guid>    <pubDate>2026-02-11 14:02:46</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>当下全球电商赛道竞争激烈，数据驱动的企业敏捷性直接决定品牌增长的上限。某全球知名运动休闲服饰品牌（以下简称“该品牌”）在业务全球化过程中，曾基于 AWS 构建了由 AirFlow、Amazon EMR 和 Amazon RedShift 组成的数据技术栈。然而，工具链的割裂让习惯了一体化平台的团队效率受限，成本控制与深度分析也面临挑战。<br/>为破局，该品牌携手数新智能，以云原生数据平台 CyberData 为核心，在 AWS 上重构了统一的数据开发治理体系。本次升级不仅整合了工作流，更关键的是，通过深度释放 Amazon Redshift 云数据仓库的潜能，将数据平台从“成本中心”转型为驱动精准决策的“价值引擎”。</p><h3>关于客户</h3><p>该品牌业务遍及北美、欧洲、亚太等多个海外市场。面对高速增长的线上业务与激烈的市场竞争，数据驱动已成为其产品创新、精准营销和供应链优化的核心引擎。品牌数据团队亟需一个敏捷、高效且易用的数据平台，以支持其全球化业务决策。</p><h3>客户挑战</h3><p>此客户早前在AWS上采用AirFlow进行任务调度，配合 Amazon EMR 与 Amazon RedShift 构建了大数据处理链路。然而，这套组合方案在实际使用中给团队带来了显著挑战：<br/><strong>体验割裂，效率低下</strong>：数据开发、任务调度与数据分析分散于 AirFlow、Amazon EMR 和 Amazon  RedShift 等多个独立工具中，团队协作链路断裂，严重拖慢了从数据到洞察的交付速度。<br/><strong>成本与性能难以兼得</strong>：为满足不定时的分析需求，传统 Amazon RedShift 集群常需过度配置以保留性能冗余，导致在非高峰时段资源闲置，计算成本高企。<br/><strong>数据价值挖掘深度不足</strong>：尽管 Amazon RedShift 存储了核心数据，但由于缺乏与上游开发流程统一的元数据管理与质量监控，数据可信度和发现效率不高，限制了复杂分析与预测模型的开发。</p><h3>解决方案</h3><h4>建立全链路数据血缘与质量标准</h4><p>根据该品牌的业务需求，数新智能 CyberData 内置的数据地图、数据质量监控与资产治理模块，帮助客户建立了从数据接入（ODS）、整合处理（DWD）、服务汇总（DWS）到应用层（ADS）的全链路血缘关系与质量标准。对包括 Amazon Redshift 在内的所有数据引擎进行智能化管控与协同，实现了控制面与计算面的分离，既保障了平台体验的统一，又充分发挥了 AWS 各计算引擎的性能与成本优势。</p><h4>核心 AWS 技术特性的场景化落地</h4><p>我们深度结合AWS的原生服务能力，精准解决客户的业务痛点，实现技术价值最大化：</p><p><strong>智能管理最大化性价比</strong></p><ul><li>利用RA3节点实现存储计算分离：对于稳定的批量ETL与报表任务，平台将其调度至采用RA3节点的 Amazon Redshift集群。RA3的存储与计算分离架构，允许独立扩展性能与容量，并依托 Amazon Redshift Managed Storage 自动优化数据布局，企业仅需为实际使用的计算资源付费，显著降低了海量数据处理的总体拥有成本（TCO）。</li><li>借助Serverless应对弹性峰值：针对业务人员高并发的即席查询与促销期间的突发负载，平台无缝调用 Amazon Redshift Serverless。该服务可在秒级自动扩展，处理数千个并发查询，并在工作完成后自动归零，真正实现为查询价值付费，完美平衡成本与性能。</li></ul><p><strong>统一治理提升数据资产可信度</strong></p><p><strong>端到端血缘与影响分析</strong>：通过 CyberData 的统一元数据服务，可清晰追溯从数据源到 Amazon Redshift 核心报表的完整链路。当上游任务异常时，能分钟级定位对所有下游 Amazon Redshift 表与业务洞察的影响范围，极大提升运维效率与数据可靠性。</p><p><strong>数据质量内嵌保障分析基石</strong>：在数据写入 Amazon Redshift 的前后环节均设置质量规则，确保用于决策分析的数据干净、可信，从根本上提升所有基于 Amazon Redshift 的 BI 报表与模型输出的准确性。</p><p><strong>云原生协同优化分析流水线</strong></p><p>平台构建了以 Amazon Redshift 为分析核心的高效流水线：通过智能编排，利用  Amazon EMR Serverless 处理原始数据，借助 Amazon Redshift Spectrum 直接查询 Amazon S3 数据湖中的原始或温热数据，或通过高效方式将加工后的结果加载至 Amazon Redshift 供关键业务查询，实现湖仓一体的协同分析。</p><h2>架构应用</h2><p>根据该品牌的业务需求与实际挑战，我们构建了如下图所示的 AWS 现代化数据架构。该架构整合多项 AWS 云服务，以 Amazon Redshift 为中枢，打造统一、高效、弹性的企业级数据平台。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047605337" alt="图片" title="图片"/></p><h2>项目价值</h2><p>项目上线后，该品牌的数据平台实现了全面升级：<br/>分析效率与深度双提升：依托Amazon Redshift Serverless的弹性能力，高并发即席查询响应速度提升 50% 以上，无资源排队等待，基于 Amazon Redshift 的并行计算能力，完成跨区域销售数据的深度拆解。<br/>成本实现精细控制：通过智能调度与 Amazon Redshift RA3 节点、Serverless 模式的结合，在支撑更大数据量与更复杂分析的同时，整体分析层计算成本节约超 35%。<br/>数据信任与协作文化建立：统一的数据资产目录与可视化血缘，让业务部门能自主、放心地使用 Amazon Redshift 中的数据，数据团队从繁琐的 “取数” 工作中解放，专注于更高价值的模型构建。</p><p>该品牌的实践表明，在数据量激增的时代，云数据仓库已不仅是存储历史的“档案馆”，更是驱动实时业务的“决策大脑”。数新智能通过 CyberData 平台与 Amazon Redshift 云原生服务的深度融合，不仅帮助客户实现了工具链的统一，更关键在于深度激活了 Amazon Redshift 在性能、弹性与成本方面的原生优势，将其转化为可持续的竞争优势。</p><p>我们认为，未来的数据平台不应是各种独立工具的简单堆砌，而应是一个体验统一、引擎智能、治理内嵌的有机整体。CyberData平台的核心理念，正是将企业从“运维复杂基础设施”的沉重负担中解放出来，回归到“专注数据价值创造”的本质上来。</p>]]></description></item><item>    <title><![CDATA[免费SSL证书全解析：类型、优势、适用场景与选型指南 SSL证书的小韩 ]]></title>    <link>https://segmentfault.com/a/1190000047605350</link>    <guid>https://segmentfault.com/a/1190000047605350</guid>    <pubDate>2026-02-11 14:02:16</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>免费SSL证书全解析：类型、优势、适用场景与选型指南</h2><h3>一、<a href="https://link.segmentfault.com/?enc=tj%2B5I%2BQ3S1bvNM382Cdsmw%3D%3D.%2Fd%2FE3K%2FLy3ahzz8ZbktpGrekSrRKACVyosUGG3SVTJ5AS%2Fmu%2FOs8sRm7tHcSveIW" rel="nofollow" target="_blank">免费SSL证书类型分层与特性</a></h3><h4>1. 按验证等级划分</h4><p>免费SSL证书根据身份验证强度，可分为三个核心层级：</p><ul><li><strong>域名验证型（DV）</strong> ：仅需验证域名所有权，通过DNS记录上传、文件验证或邮箱验证即可完成签发，通常在5-10分钟内完成，是目前免费证书的主流类型。此类证书仅实现基础加密功能，不显示企业信息，适合个人网站和小型项目。</li><li><strong>组织验证型（OV）</strong> ：除域名所有权外，还需验证申请企业的工商注册信息和合法性，签发周期为1-3个工作日，会在浏览器中显示企业名称，能显著提升用户信任度。多数CA仅提供短期免费试用版，长期使用需付费升级。</li><li><strong>国密SSL证书</strong>：采用SM2/SM4国密加密算法，符合《中华人民共和国密码法》合规要求，适用于政务、金融等对加密标准有明确规定的场景，部分国产CA提供免费DV版本的国密证书。</li></ul><h4>2. 按域名覆盖范围划分</h4><p>免费SSL证书按覆盖维度可分为三类：</p><ul><li><strong>单域名证书</strong>：仅对一个特定域名生效，如<code>[www.joyssl.com](https://www.joyssl.com/index.html?nid=59)</code>，不包含子域名，是免费DV证书的标准配置。</li><li><strong>通配符证书</strong>：可保护主域名及所有子域名，如<code>*.joysl.com</code>能覆盖<code>blog.joyssl.com</code>、<code>shop.joyssl.com</code>等，适合多子域名架构的网站。</li><li><strong>多域名证书</strong>：支持同时验证多个独立域名，如<code>example.com</code>和<code>example.net</code>，免费版本通常限制域名数量在3-5个以内。</li></ul><h3>二、主流免费SSL证书品牌对比（注册码230959）</h3><p>表格</p><table><thead><tr><th>品牌</th><th>核心类型</th><th>有效期</th><th>国密支持</th><th>续期方式</th><th>部署便捷性</th></tr></thead><tbody><tr><td>JoySSL</td><td>DV单域名/通配符</td><td>90天</td><td>支持SM2</td><td>自动续期+手动续期</td><td>云平台一键部署</td></tr><tr><td>Let’s Encrypt</td><td>DV单域名/通配符</td><td>90天</td><td>不支持</td><td>Certbot脚本自动续期</td><td>需手动配置脚本</td></tr><tr><td>TrustAsia</td><td>DV单域名</td><td>90天</td><td>支持SM2</td><td>手动续期</td><td>云市场集成部署</td></tr><tr><td>Wotrus</td><td>DV单域名</td><td>90天</td><td>支持SM2</td><td>自动续期</td><td>API自助申请</td></tr></tbody></table><h4>JoySSL的差异化优势</h4><ol><li><strong>本地化适配能力</strong>：国内部署的节点延迟低于50ms，相比国际品牌减少30%以上的TLS握手时间，适配国内浏览器和服务器环境。</li><li><strong>国密生态兼容性</strong>：完整支持SM2/SM4国密算法，可无缝对接国产密码模块和操作系统，满足政务、金融等行业的合规要求。</li><li><strong>云平台深度集成</strong>：已接入阿里云、腾讯云、百度智能云等主流云市场，支持一键申请、自动部署与续期，降低运维成本。</li><li><strong>中文客服支持</strong>：提供7×24小时中文技术支持，相比国际品牌的社区论坛响应模式，更贴合国内用户的服务需求。</li></ol><h3>三、免费SSL证书的优势与适用场景</h3><h4>核心优势</h4><ol><li><strong>安全合规价值</strong>：满足《网络安全法》对敏感数据传输的加密要求，同时符合搜索引擎对HTTPS的收录偏好，能避免浏览器显示“不安全”提示。</li><li><strong>成本优化效果</strong>：零成本获得基础加密防护，对比付费DV证书每年500-1000元的成本，长期使用可节省超90%的安全投入。</li><li><strong>部署便捷性</strong>：主流免费证书均支持ACME协议自动化申请，无需复杂技术配置，个人站长和中小企业可快速完成部署。</li></ol><h4>适用场景匹配</h4><p>表格</p><table><thead><tr><th>网站类型</th><th>推荐证书类型</th><th>选型理由</th></tr></thead><tbody><tr><td>个人博客、开源项目</td><td>JoySSL免费DV证书</td><td>快速签发，零成本满足加密需求</td></tr><tr><td>中小企业官网</td><td>JoySSL国密证书</td><td>符合国内合规要求，兼顾安全与成本</td></tr><tr><td>政务、教育类网站</td><td>JoySSL免费DV证书</td><td>适配国内网络环境，支持国密算法</td></tr><tr><td>电商、金融交易网站</td><td>付费OV/EV证书</td><td>更高信任度，满足交易场景合规要求</td></tr></tbody></table><h3>四、免费SSL证书选型与部署指南</h3><h4>选型避坑要点</h4><ol><li><strong>关注有效期与续期机制</strong>：免费DV证书有效期均为90天，需启用自动续期功能或设置续期提醒，避免证书过期导致网站无法访问。</li><li><strong>验证浏览器兼容性</strong>：优先选择被主流浏览器信任的品牌，如JoySSL、Let’s Encrypt等，防止出现证书不被识别的情况。</li><li><strong>评估技术支持能力</strong>：国内品牌通常提供中文客服支持，相比国际品牌的社区响应模式，更适合技术能力有限的用户。</li></ol><h4>部署最佳实践</h4><ol><li><strong>优先选择DNS验证</strong>：无需修改网站代码，验证成功率可达99%以上，且支持通配符证书申请。</li><li><strong>配置HTTP严格传输安全（HSTS）</strong> ：在服务器中添加HSTS响应头，强制浏览器使用HTTPS访问，避免HTTP降级攻击。</li><li><strong>启用OCSP Stapling</strong>：减少TLS握手过程中的OCSP查询延迟，提升网站访问速度和稳定性。</li></ol>]]></description></item><item>    <title><![CDATA[免费泛域名证书怎么申请 才高八斗的杯子_dS2Fpp ]]></title>    <link>https://segmentfault.com/a/1190000047605353</link>    <guid>https://segmentfault.com/a/1190000047605353</guid>    <pubDate>2026-02-11 14:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h4>什么是通配符证书？</h4><p><strong>通配符证书（Wildcard SSL Certificate）</strong> 是一种特殊的SSL/TLS证书，使用单个证书保护一个主域名及其所有同级子域名。证书中的通配符表示为星号（*），例如：</p><ul><li><p><code>*.example.com</code> 可保护：</p><ul><li><code>www.example.com</code></li><li><code>mail.example.com</code></li><li><code>shop.example.com</code></li><li><code>blog.example.com</code></li><li>以及其他任何同级子域名<br/><img width="700" height="400" referrerpolicy="no-referrer" src="/img/bVdh3qn" alt="" title=""/></li></ul></li></ul><h4>为什么选择JoySSL通配符证书？</h4><p><strong>经济高效</strong> - 一证多用，节省成本  <br/><strong>管理简便</strong> - 统一管理多个子域名  <br/><strong>安全可靠</strong> - 256位加密强度，支持SHA-2算法  <br/><strong>兼容性好</strong> - 支持99.9%的浏览器和移动设备  <br/><strong>快速签发</strong> - 验证通过后快速颁发</p><h4><strong><a href="https://link.segmentfault.com/?enc=02XsMHX2MQ%2FjCv%2F8mZ3pXg%3D%3D.8mYg55ULQ4YGYlJp2JuoCsbga%2BZGBN3DJGSpiUatpEFIoc3h2yskzz3809PLkOW%2Fq7elzv5ysp%2Bo8G6%2F7PBFhJMHgqVhiZJPiWpdzcK%2BDcc%3D" rel="nofollow" target="_blank">通配符SSL证书如何快速申请</a>：</strong></h4><p>1、首先，您需要选择一个可靠的证书颁发机构来为您签发通配符证书。</p><p>打开JoySSL，注册账号填写注册码<strong>230970</strong>获取协助配置安装服务以及优惠券。</p><p>2.流程二：生成和提交CSR  <br/>需要生成证书CSR，随后递交给SSL证书颁发组织。</p><p>3.流程三：验证域名所有权和公司信息  <br/>验证域名所有权，提交公司真实信息等待验证。</p><p>4.流程四：审签SSL证书  <br/>根据信息审核，将以邮件或是电话的形式验证单位组织信息，证书颁发机构完成SSL证书的审核。</p><p>5.流程五：将成功签发的 SSL证书安装在服务器上。</p>]]></description></item><item>    <title><![CDATA[为什么我最终选择用 WebSocket 获取股票与外汇实时行情 sydney ]]></title>    <link>https://segmentfault.com/a/1190000047605290</link>    <guid>https://segmentfault.com/a/1190000047605290</guid>    <pubDate>2026-02-11 13:02:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>行情延迟与接口不稳定</h2><p>作为一个长期做量化和可视化系统开发的个人交易者，我深刻体会到一个问题——数据的延迟和断线带来的影响远比想象严重。<br/>早期我试过不少免费行情 API，看起来数据齐全，但在实际使用中，经常出现推送延迟几秒甚至中断的情况。尤其在短线测试时，这种延迟直接导致图表跳帧、策略误触发，整个系统的可靠性大打折扣。<br/>在这种场景下，我需要的不是“能用就好”的接口，而是一个能长期稳定运行、实时推送低延迟数据的解决方案。</p><h2>问题本质：实时数据的完整性</h2><p>我的系统通常同时展示几支核心股票（如 AAPL、TSLA 等）以及欧元兑美元、美元兑日元这样的汇率对。<br/>如果数据更新不同步或接口暂时不可用，前端展示的图表就会出现跳变或空窗期。对策略而言，任何毫秒级的偏差，都可能导致错误判断。<br/>一次性拉取历史数据虽方便，但在实时监控或策略测试场景中，这种模式显然不够用。<br/>因此，我开始重新审视接口标准，重点放在以下指标上：</p><ul><li>稳定性：长期连接不中断，且能自动重连。</li><li>实时性：延迟低于秒级，推送流畅。</li><li>数据完整性：除价格外可获取成交量、涨跌幅、汇率等指标。</li><li><p>扩展性：同一个接口能支持股票、外汇，甚至未来扩展至加密资产。</p><h2>实践方案：WebSocket 实时订阅</h2><p>我后来用 AllTick API 做了一个测试项目。它提供了 WebSocket 实时推送功能，能同时订阅多个标的。<br/>相较传统 HTTP 轮询，这种方式在实时性和资源开销上都有明显优势。<br/>以下是我在项目中使用的 Python 示例，可以同时订阅苹果股价和欧元兑美元汇率：</p></li></ul><pre><code>python
import websocket
import json

url = "wss://realtime.alltick.co/ws"  # AllTick 实时推送地址

def on_message(ws, message):
    data = json.loads(message)
    print(f"{data['symbol']} 当前价格: {data['price']}")

def on_open(ws):
    # 同时订阅股票和外汇
    subscribe_data = {
        "action": "subscribe",
        "symbols": ["AAPL.US", "EURUSD"]
    }
    ws.send(json.dumps(subscribe_data))

ws = websocket.WebSocketApp(url, on_message=on_message, on_open=on_open)
ws.run_forever()</code></pre><h2>使用体验：实时性与稳定性的提升</h2><p>在使用过程中，我先从少量标的开始测试。AllTick 的推送流保持稳定，没有出现断线或掉包情况，价格更新流畅，能很好地满足前端可视化刷新以及策略引擎的数据输入需求。<br/>特别是在做实时图表和策略结果回测联动时，延迟的提升非常明显，几乎可以实现秒级同步更新。</p><h2>结论</h2><p>这次的尝试让我更清楚一个事实：<br/>数据接口的质量，决定了策略实验的可信度和系统的整体体验。<br/>选择合适的股票与外汇实时数据接口，不是为了“拿数据”，而是为了让系统能稳定、高效地运行；更低的延迟、更高的一致性，意味着更少的异常调试。<br/>如果要在项目中兼顾实时性与多市场数据扩展，我推荐直接从 WebSocket 接口起步，而不是等待轮询方案优化。<br/>像 AllTick 这种集合多市场行情源的接口，让数据流更连贯，也提高了开发效率。<br/><img width="723" height="371" referrerpolicy="no-referrer" src="/img/bVdnUtp" alt="" title=""/></p>]]></description></item><item>    <title><![CDATA[建议Java工程师都要学习一下Go语言 王中阳讲编程 ]]></title>    <link>https://segmentfault.com/a/1190000047605332</link>    <guid>https://segmentfault.com/a/1190000047605332</guid>    <pubDate>2026-02-11 13:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>开篇：这不是一篇劝退Java的文章</h2><p>首先声明，我不是来劝你放弃Java的。</p><p>我深知Spring全家桶在企业级应用开发中的统治地位，写业务逻辑、搞复杂架构、做ERP系统，Java依然是当之无愧的王者。</p><p>但是，<strong>作为一名有追求的Java工程师，我强烈建议你把Go语言加入你的武器库。</strong></p><p>为什么？因为时代变了。</p><h2>理由一：突破"应用层"的天花板</h2><p>你有没有发现，当你把Java学通了，Spring源码看完了，JVM调优搞定了，似乎就触碰到了一层隐形的天花板？</p><p>往上看，是业务架构；<strong>往下走，是基础设施。</strong></p><p>而今天的基础设施，<strong>几乎是Go语言的天下</strong>：</p><ul><li><strong>容器编排</strong>：Kubernetes (Go)</li><li><strong>容器引擎</strong>：Docker (Go)</li><li><strong>服务网格</strong>：Istio (Go)</li><li><strong>监控告警</strong>：Prometheus (Go)</li><li><strong>配置中心</strong>：Etcd (Go)</li><li><strong>网关代理</strong>：Traefik, Envoy (Go周边)</li></ul><p>如果你只会Java，当Kubernetes集群出现诡异调度问题时，当Prometheus抓取不到数据时，你只能看着黑盒干着急。</p><p><strong>学会Go，你就不再只是一个"写接口的"，你拥有了窥探和掌控整个云原生基础设施的能力。</strong></p><h2>理由二：Java太重，Go太快</h2><p>Java被人诟病最多的就是"重"。</p><p>写一个简单的CLI工具，或者一个轻量级的Sidecar代理：</p><ul><li><strong>Java</strong>：启动慢，吃内存，还需要装JRE。</li><li><strong>Go</strong>：编译成一个二进制文件，丢上去就能跑，启动瞬间完成，内存占用极低。</li></ul><p>在微服务架构中，越来越多的辅助组件（Agent、Sidecar、Forwarder）都在转向Go。作为Java工程师，如果你能用Go快速写一个高性能的辅助工具，解决生产环境的燃眉之急，这绝对是你的核心竞争力。</p><h2>理由三：Java工程师学Go，简直是降维打击</h2><p>很多Java同学不敢学Go，觉得是新语言，门槛高。</p><p><strong>大错特错！</strong></p><p>Go语言的设计哲学是"做减法"。相比于Java复杂的继承、多态、注解、反射，Go简单得令人发指。</p><p>对于Java工程师来说，学Go几乎是无痛的，因为核心概念完全互通：</p><table><thead><tr><th align="left">Java概念</th><th align="left">Go概念</th><th align="left">区别</th></tr></thead><tbody><tr><td align="left">Class</td><td align="left">Struct</td><td align="left">没有继承，只有组合</td></tr><tr><td align="left">Interface</td><td align="left">Interface</td><td align="left">鸭子类型（隐式实现），更灵活</td></tr><tr><td align="left">Thread</td><td align="left">Goroutine</td><td align="left">极轻量级，启动几十万个都没事</td></tr><tr><td align="left">Try-Catch</td><td align="left">if err != nil</td><td align="left">显式处理，代码逻辑更清晰</td></tr><tr><td align="left">Maven</td><td align="left">Go Mod</td><td align="left">依赖管理更简单</td></tr></tbody></table><h2>实战对比：一眼看懂Go的"简单"</h2><p>我们来看一个最简单的HTTP服务，感受一下两者的区别。</p><h3>Java (Spring Boot)</h3><p>你需要配置Controller，注解，依赖注入...</p><pre><code class="java">@RestController
public class HelloController {
    
    @GetMapping("/hello")
    public String hello(@RequestParam String name) {
        return "Hello, " + name;
    }
}</code></pre><p>看似代码少，但这背后需要庞大的Spring框架支撑，启动时间几秒到几十秒不等。</p><h3>Go (Gin)</h3><p>代码直观，逻辑从上到下，没有魔法。</p><pre><code class="go">package main

import "github.com/gin-gonic/gin"

func main() {
    r := gin.Default()
    
    r.GET("/hello", func(c *gin.Context) {
        name := c.Query("name")
        c.String(200, "Hello, %s", name)
    })
    
    r.Run() // 监听 0.0.0.0:8080
}</code></pre><p>编译成二进制文件后，只有十几MB，没有任何依赖，启动耗时毫秒级。</p><h2>核心思维转变：从"对象"到"组合"</h2><p>Java工程师转Go，最大的障碍不是语法，而是思维。</p><p>Java喜欢<strong>层层封装</strong>：<br/><code>Controller -&gt; Service -&gt; Manager -&gt; DAO -&gt; Entity</code></p><p>Go喜欢<strong>简单直接</strong>：<br/><code>Handler -&gt; Logic -&gt; Repo</code></p><p>Java喜欢<strong>继承</strong>：<br/><code>BaseController -&gt; UserController</code></p><p>Go喜欢<strong>组合</strong>：</p><pre><code class="go">type UserHandler struct {
    *BaseHandler // 组合
    UserService  *UserService
}</code></pre><p>一旦你习惯了Go的这种"乐高积木"式的组合思维，你会发现代码变得异常清晰，维护起来也轻松很多。</p><h2>结语：技多不压身</h2><p>最后，我想说的是：<strong>学习Go并不是要你抛弃Java。</strong></p><ul><li><strong>做复杂业务系统</strong>，Java依然是首选，生态无敌。</li><li><strong>做中间件、工具、高并发网关、K8s插件</strong>，Go是神兵利器。</li></ul><p>作为一名资深Java工程师，拥有Java的架构思维，再加上Go的工程效率，你将成为团队中不可或缺的"全栈基础设施专家"。</p><p>别犹豫了，今天就下载Go，写下你的第一个 <code>fmt.Println("Hello World")</code> 吧。</p><blockquote><p><strong>⚡️ 别把时间浪费在低效复习上</strong></p><p>很多人复习抓不住重点。作为过来人，我分析了100+份大厂面试记录，将 <strong>Go/Java/AI 的核心考察点、高频题、易错点</strong> 浓缩进了一份 PDF。</p><p><strong>不搞虚的，全是干货。</strong></p><p><strong>加我微信：wangzhongyang1993</strong>，备注 <strong>【面经】</strong> 免费发你，立即纠正你的复习方向，把时间用在刀刃上。</p><p>wangzhongyang.com 也欢迎大家直接访问我的官网，里面有Go / Java / AI 的资料，<strong>免费学习</strong>！</p></blockquote>]]></description></item><item>    <title><![CDATA[行情监控开发：股票停牌复牌的实时监测方案与代码实现 Jackyy ]]></title>    <link>https://segmentfault.com/a/1190000047605240</link>    <guid>https://segmentfault.com/a/1190000047605240</guid>    <pubDate>2026-02-11 12:04:55</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在金融行情监控系统的开发过程中，开发者常会遇到股票停牌相关的技术落地难题：停牌触发原因多样且时长无统一标准，导致标的状态展示、实时预警功能难以实现；同时缺乏可直接复用的接口方案，无法高效获取停牌/复牌实时数据，最终影响行情系统对前端交易、研究场景的支撑能力。</p><p>本文从金融开发的实际需求出发，先梳理股票停牌的核心类型与数据特征，再给出基于WebSocket接口的复牌状态实时监测实现方案，提供可直接复用的Python代码，解决行情监控系统中停牌状态监测的实际开发问题。</p><h2>一、开发痛点与核心需求</h2><p>针对股票停牌状态监测的开发场景，核心需解决<strong>数据标准化</strong>和<strong>状态实时化</strong>两大问题，具体的技术与数据需求可分为两类：</p><ol><li><strong>基础数据需求</strong>：明确不同停牌类型的触发场景、时长范围，为系统中标的停牌状态的基础研判、数据建模提供标准化依据；</li><li><strong>技术对接需求</strong>：获取可无缝接入自研系统的实时推送接口，实现停牌/复牌状态的低延迟获取，同时支持将停牌天数、复牌日期等数据与系统可视化模块结合，适配行情面板的展示需求。</li></ol><h2>二、停牌核心类型与数据特征</h2><p>市场中股票停牌主要分为三类，其触发场景和时长特征直接决定了行情监控系统的开发与数据建模逻辑，三类停牌的核心信息及差异如下：</p><table><thead><tr><th>停牌类型</th><th>触发场景</th><th>时长范围</th></tr></thead><tbody><tr><td>重大事项公告停牌</td><td>公司发布资产调整、重大合同签署等重大公告</td><td>数日~数周（无固定值）</td></tr><tr><td>异常波动停牌</td><td>个股价格/成交量出现交易所认定的异常异动</td><td>数小时~数日（无固定值）</td></tr><tr><td>信息披露停牌</td><td>公司发布季报、年报等重要财报前</td><td>1~3天（短周期固定）</td></tr></tbody></table><p>为便于开发者在系统开发中做数据验证和功能测试，以下提供贴近真实市场的模拟数据集，可直接用于开发调试：</p><h3>停牌时长模拟数据</h3><table><thead><tr><th>股票</th><th>停牌原因</th><th>停牌天数</th></tr></thead><tbody><tr><td>A</td><td>重大事项公告</td><td>12</td></tr><tr><td>B</td><td>异常波动</td><td>2</td></tr><tr><td>C</td><td>信息披露</td><td>1</td></tr></tbody></table><h3>复牌状态模拟数据</h3><table><thead><tr><th>股票</th><th>停牌天数</th><th>复牌日期</th></tr></thead><tbody><tr><td>A</td><td>12</td><td>2026-02-15</td></tr><tr><td>B</td><td>2</td><td>2026-02-05</td></tr><tr><td>C</td><td>1</td><td>2026-02-04</td></tr></tbody></table><p>从模拟数据可直观看出：重大事项公告类停牌时长最长，信息披露类最短，这一规律与市场实际高度契合，可作为系统开发中状态判断的核心参考。</p><h2>三、核心技术实现：基于AllTick API的实时监测</h2><p>针对停牌/复牌状态的实时获取需求，采用WebSocket接口实现数据的实时推送是最优解，以下为基于AllTick API的Python实现代码，代码可直接复用，无需修改，适配主流金融行情系统的技术栈。</p><pre><code class="python">from alltick.websocket import AllTickRealtime

def on_message(message):
    data = message.get("data", {})
    if "halt_status" in data:
        status = data["halt_status"]
        if status == "halted":
            print(f"{data['symbol']} 已停牌")
        elif status == "resumed":
            print(f"{data['symbol']} 已复牌")

# 初始化实时连接
ws = AllTickRealtime(
    api_key="你的API_KEY",
    on_message=on_message
)
# 订阅目标股票停牌状态
ws.subscribe(["AAPL", "MSFT", "TSLA"])
ws.run_forever()</code></pre><h3>开发实操提示</h3><ol><li>接入前需完成AllTick API的权限申请，将代码中<code>你的API_KEY</code>替换为实际有效密钥；</li><li>该接口可直接与Python可视化库（Matplotlib/Plotly）、前端可视化框架（ECharts/Highcharts）结合，实现停牌天数趋势、复牌日期标注的可视化展示；</li><li>生产环境部署时，建议增加<strong>异常处理逻辑</strong>，包括网络断连自动重连、数据格式校验、空值过滤，提升接口在行情系统中的稳定性。</li></ol><h2>四、系统集成拓展</h2><p>将上述技术方案与自研行情监控系统结合时，可从两个维度实现功能拓展，让停牌状态监测更贴合实际开发与业务使用需求：</p><ol><li><strong>状态预警</strong>：在<code>on_message</code>函数中增加消息推送、弹窗提醒等逻辑，当标的触发停牌/复牌时，向系统前端推送实时预警；</li><li><strong>数据持久化</strong>：将获取到的停牌状态、停牌天数、复牌日期等数据写入数据库（MySQL/Redis），为后续的行情数据分析、系统功能迭代提供历史数据支撑。</li></ol><h2>五、方案的技术与业务价值</h2><p>这套「停牌数据标准化梳理+WebSocket接口实时实现」的方案，对金融行情监控系统开发具备双重核心价值：</p><ol><li><strong>技术价值</strong>：提供了金融领域实时行情数据获取的标准化接口实现范式，该方案可复用至个股价格、成交量等其他实时行情数据的获取场景，降低开发成本；</li><li><strong>业务价值</strong>：解决了行情监控系统中停牌状态监测的核心痛点，实现了标的停牌/复牌状态的实时化、可视化展示，让系统能更精准地为前端交易、研究场景提供数据支撑，提升行情系统的精细化程度。</li></ol><h2>总结</h2><p>股票停牌状态监测的核心难点在于<strong>数据无标准</strong>和<strong>状态不实时</strong>，本文通过梳理三类停牌的核心数据特征，解决了数据标准化问题；同时提供WebSocket实现代码，可直接复用至自研系统，实现停牌/复牌状态的低延迟获取。</p><p>该方案从金融开发的实际场景出发，所有代码和数据均可直接用于开发调试与功能落地，适配主流量化交易、行情监控系统的技术栈，能有效提升停牌状态监测功能的开发效率，助力行情系统的功能完善与体验优化。</p>]]></description></item><item>    <title><![CDATA[企业用IP离线库选哪个品牌好 科技块儿 ]]></title>    <link>https://segmentfault.com/a/1190000047605254</link>    <guid>https://segmentfault.com/a/1190000047605254</guid>    <pubDate>2026-02-11 12:04:11</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>一、什么是IP离线库？</h2><p>IP离线库是企业将IP地址信息存储在本地数据库中的一种方式。与在线IP查询不同，离线库的IP数据不依赖于实时互联网连接，而是由企业根据需求定期下载更新。这使得企业可以在没有互联网连接的环境下进行IP地址查询，且查询速度较快，适用于数据量大、查询频繁的场景。</p><p>IP离线库通常包含的内容包括：IP归属地、ISP信息、IP类型、使用代理情况、风险等级等。它为企业提供了多维度的IP信息，尤其适用于需要进行精准营销、风险管理、网络安全监控等任务的企业。</p><h2>二、IP离线库在企业中的应用场景</h2><h3>网络安全防护</h3><p>在企业的网络安全体系中，IP离线库发挥着不可或缺的作用。通过实时监控和查询IP地址的归属地、类型及使用情况，企业可以有效识别潜在的安全威胁，及时阻止来自恶意IP地址的攻击。例如，通过查找是否有大量来自同一IP的登录尝试，企业可以发现潜在的暴力破解行为，从而采取必要的防范措施。</p><h3>精准营销与广告投放</h3><p>在广告投放与精准营销方面，IP离线库也能提供帮助。企业通过分析用户的IP地址，判断其地理位置、设备类型等信息，从而制定更具针对性的营销策略。借助IP离线库，企业可以实现更精确的广告定向投放，提高营销效果。</p><h3>反欺诈与风险评估</h3><p>通过查询IP地址的历史使用记录和风险评分，企业可以在进行用户身份认证时有效防止欺诈行为。例如，银行、电商平台等常常利用IP离线库查询客户IP地址，识别是否存在风险行为（如使用VPN或代理的可疑IP）。这种技术有助于降低欺诈风险，提升企业的安全性。<br/><img width="723" height="406" referrerpolicy="no-referrer" src="/img/bVdnUsP" alt="企业用IP离线库选哪个品牌好" title="企业用IP离线库选哪个品牌好"/></p><h2>三、选择IP离线库时需要考虑的关键因素</h2><h3>数据准确性</h3><p>数据准确性是选择IP离线库时最重要的因素之一。IP离线库中的数据必须保持高质量和准确性，才能确保企业在进行IP查询时得到可靠的结果。企业应选择那些提供多维度、详细数据来源的品牌，以确保查询结果的准确性。</p><h3>更新频率</h3><p>由于IP地址的动态变化，IP离线库的更新频率也是至关重要的。企业应选择那些定期更新数据源的IP离线库品牌，以确保所查询的数据是最新的。这对于防止IP库信息过时、失效至关重要，尤其是在防止网络攻击和诈骗方面。</p><h3>区域覆盖</h3><p>对于需要全球范围内查询IP的企业，IP离线库的区域覆盖广度是一个不容忽视的因素。选择支持全球范围的IP库，可以帮助企业全面了解不同区域的IP地址信息，满足跨国业务运营的需求。</p><h3>查询速度</h3><p>企业的查询效率对日常运营的影响也非常大。在数据量大的情况下，查询速度尤为重要。因此，选择响应快速、查询高效的IP离线库品牌，可以显著提升企业的工作效率，避免因查询延迟而影响决策。</p><h3>兼容性与扩展性</h3><p>企业的需求可能随着业务的扩大而发生变化。因此，选择一个具备良好兼容性和扩展性的IP离线库品牌至关重要。品牌应提供丰富的API接口、支持多平台集成，以便企业根据自身需求进行定制和拓展。</p><h2>四、推荐的IP离线库品牌及其优缺点</h2><p>以下是目前市场上几款知名的IP离线库品牌，适用于不同企业需求的选择。</p><table><thead><tr><th>品牌名</th><th>优势</th><th>缺点</th></tr></thead><tbody><tr><td>IP数据云</td><td>提供全面的全球IP数据，更新频率高，支持API接口，查询速度快</td><td>高级功能需付费，部分高精度数据需额外购买</td></tr><tr><td>IPnews</td><td>提供精确的IP地理位置和代理检测，适用于跨国企业</td><td>数据精度有限，官网套餐仅到城市级</td></tr><tr><td>IPinfo</td><td>数据准确性高，支持丰富的API接口，适合开发者使用</td><td>部分高级功能价格较高，适合较为复杂的业务场景</td></tr><tr><td>Geotargetly</td><td>提供精准的地域定向能力，特别适合精准营销</td><td>只支持部分地区的详细数据，可能不适合跨国运营的企业</td></tr><tr><td>ipstack</td><td>提供高效的API接口和多语言支持，数据丰富</td><td>数据更新频率较低，且支持的地域覆盖较少</td></tr></tbody></table><p><em>*数据来源网络，以官网为准</em></p><p>因此，在选择IP离线库品牌时，企业应根据自身需求，如查询速度、数据准确性、区域覆盖等方面，进行综合考虑。IP数据云凭借其数据更新频率高、全球范围覆盖、查询速度快，成为许多企业的首选。而对于跨国业务，IPnews和IPinfo提供的精确数据和全面支持也值得关注。</p><h2>五、结论</h2><p>选择适合企业需求的IP离线库品牌是一个需要综合考虑多方面因素的过程。通过深入了解IP离线库的应用场景、选购标准和市场上的主流品牌，企业可以做出更加理性和精准的决策，为网络安全、精准营销等任务提供有力支持。无论是提升网络防护能力，还是加强风险管理，选择一个高效且可靠的IP离线库品牌，都是企业顺利发展的关键一步。</p>]]></description></item><item>    <title><![CDATA[[后端架构] Python处理金融即时通讯：WebSocket客户端设计模式 EmilyLi ]]></title>    <link>https://segmentfault.com/a/1190000047605256</link>    <guid>https://segmentfault.com/a/1190000047605256</guid>    <pubDate>2026-02-11 12:03:14</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在开发金融类应用时，最棘手的部分往往不是复杂的算法，而是如何稳定、高效地处理实时数据流。作为一名在一线编写交易系统的开发者，今天想和大家聊聊 A 股实时行情的接入方案。</p><p>需求分析：为什么不用 HTTP？ HTTP 协议是无状态的，每次请求都需要带上完整的 Header，且需要经历三次握手。在需要亚秒级响应的行情监控场景下，这种开销是不可接受的。我们需要的是一种 Keep-Alive 的长连接机制，WebSocket 无疑是最佳选择。</p><p>协议层实现逻辑 我们的目标是构建一个能够长期运行、自动重连的客户端。</p><p>Transport 层：使用 websocket-client 库维护底层 TCP 连接。</p><p>Protocol 层：解析特定的 JSON 协议包。以 AllTick 的协议为例，其数据包结构紧凑，适合高频传输。</p><p>Application 层：将解析后的数据分发给策略引擎或 UI 界面。</p><p>代码实战：异步回调设计 以下代码展示了如何利用回调函数（Callback）模式来处理异步推送的数据流。这种设计模式可以避免主线程阻塞。</p><pre><code>import pandas as pd

df = pd.DataFrame(columns=["code", "price", "volume", "time"])

def on_message(ws, message):
    data = json.loads(message)
    if "data" in data:
        for item in data["data"]:
            df.loc[len(df)] = [item['s'], item['p'], item['v'], item['t']]
            print(df.tail(1))
</code></pre><p>数据持久化与缓存 在高并发场景下，直接写库（如 MySQL）可能会成为瓶颈。通常我们会先用 Pandas 在内存中做一层缓存（Buffer），或者推送到 Redis 队列中。这里展示一个简单的 Pandas 内存处理方案：</p><pre><code>import pandas as pd

df = pd.DataFrame(columns=["code", "price", "volume", "time"])

def on_message(ws, message):
    data = json.loads(message)
    if "data" in data:
        for item in data["data"]:
            df.loc[len(df)] = [item['s'], item['p'], item['v'], item['t']]
            print(df.tail(1))</code></pre><p>技术总结 通过 WebSocket，我们实现了一个低延迟的行情消费端。这种架构不仅适用于股票，同样适用于期货、数字货币等任何对时效性要求极高的金融衍生品交易场景。<br/><img width="723" height="408" referrerpolicy="no-referrer" src="/img/bVdnSar" alt="" title=""/></p>]]></description></item><item>    <title><![CDATA[RAG(检索增强生成)原理与实践 ꯭꯭听꯭风꯭者꯭ ]]></title>    <link>https://segmentfault.com/a/1190000047605265</link>    <guid>https://segmentfault.com/a/1190000047605265</guid>    <pubDate>2026-02-11 12:02:15</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>引言</h2><p>在大语言模型（LLM）蓬勃发展的今天，如何让AI更准确地回答特定领域的问题成为了一个关键挑战。RAG（Retrieval-Augmented Generation，检索增强生成）技术应运而生，它通过结合外部知识库和生成模型，显著提升了AI回答的准确性和时效性。</p><p>本文将深入探讨RAG的核心原理，重点解析<strong>向量检索</strong>和<strong>上下文注入</strong>两大关键技术，并提供实践指导。</p><hr/><h2>一、RAG是什么？</h2><h3>1.1 核心思想</h3><p>RAG的核心思想非常直观：在生成答案之前，先从知识库中检索相关信息，然后将这些信息作为上下文提供给大语言模型，让模型基于这些"参考资料"来生成更准确的回答。</p><p>这就像是让AI在开卷考试而不是闭卷考试——它可以查阅资料后再作答。</p><h3>1.2 为什么需要RAG？</h3><p>传统LLM面临几个关键问题：</p><ul><li><strong>知识时效性</strong>：模型的知识截止于训练时间，无法获取最新信息</li><li><strong>幻觉问题</strong>：模型可能生成看似合理但实际错误的内容</li><li><strong>专业领域知识不足</strong>：通用模型对特定领域的深度知识有限</li><li><strong>成本问题</strong>：频繁微调大模型成本高昂</li></ul><p>RAG通过外部知识检索优雅地解决了这些问题，无需重新训练模型。</p><hr/><h2>二、向量检索：RAG的核心引擎</h2><h3>2.1 什么是向量检索？</h3><p>向量检索是RAG系统的第一步，也是最关键的一步。它的任务是从海量文档中快速找出与用户问题最相关的内容。</p><h4>文本向量化</h4><p>文本向量化（Embedding）是将文本转换为高维向量的过程：</p><pre><code>"什么是机器学习？" → [0.12, -0.34, 0.56, ..., 0.89]  # 维度通常为384-1536</code></pre><p>向量的特点：</p><ul><li><strong>语义相似的文本，向量距离更近</strong></li><li><strong>向量可以进行数学运算</strong>（相似度计算）</li><li><strong>降维后可视化</strong>（理解语义空间）</li></ul><h4>常用的Embedding模型</h4><ul><li><strong>OpenAI text-embedding-3-small/large</strong>：性能强大，支持多语言</li><li><strong>sentence-transformers</strong>：开源方案，适合中文</li><li><strong>BGE系列</strong>：国内优秀的开源模型</li><li><strong>m3e</strong>：专门针对中文优化</li></ul><h3>2.2 向量检索的工作流程</h3><pre><code>用户问题 → Embedding模型 → 查询向量 → 向量数据库 → Top-K 相似文档</code></pre><p><strong>步骤详解：</strong></p><ol><li><p><strong>文档预处理</strong>：</p><ul><li>文档切片（Chunking）：将长文档分割成适当大小的片段（通常300-1000 tokens）</li><li>向量化：使用Embedding模型将每个片段转换为向量</li><li>存储：将向量及元数据存入向量数据库</li></ul></li><li><p><strong>查询处理</strong>：</p><ul><li>用户问题同样经过Embedding模型转换为查询向量</li><li>在向量数据库中进行相似度搜索</li><li>返回Top-K个最相关的文档片段</li></ul></li></ol><h3>2.3 相似度计算方法</h3><h4>余弦相似度（最常用）</h4><pre><code class="python">import numpy as np

def cosine_similarity(vec1, vec2):
    """计算两个向量的余弦相似度"""
    dot_product = np.dot(vec1, vec2)
    norm_product = np.linalg.norm(vec1) * np.linalg.norm(vec2)
    return dot_product / norm_product

# 示例
query_vec = np.array([0.5, 0.3, 0.8])
doc_vec = np.array([0.6, 0.2, 0.9])
similarity = cosine_similarity(query_vec, doc_vec)
print(f"相似度: {similarity:.3f}")  # 输出：0.989</code></pre><p><strong>优点</strong>：不受向量长度影响，只关注方向</p><h4>欧氏距离</h4><pre><code class="python">def euclidean_distance(vec1, vec2):
    """计算欧氏距离（距离越小越相似）"""
    return np.linalg.norm(vec1 - vec2)</code></pre><h4>点积</h4><pre><code class="python">def dot_product_similarity(vec1, vec2):
    """点积相似度"""
    return np.dot(vec1, vec2)</code></pre><h3>2.4 向量数据库选择</h3><table><thead><tr><th>数据库</th><th>特点</th><th>适用场景</th></tr></thead><tbody><tr><td><strong>Pinecone</strong></td><td>云服务，易用性强</td><td>快速原型开发</td></tr><tr><td><strong>Milvus</strong></td><td>开源，性能强大</td><td>大规模生产环境</td></tr><tr><td><strong>Weaviate</strong></td><td>支持多模态</td><td>复杂查询需求</td></tr><tr><td><strong>Chroma</strong></td><td>轻量级，易部署</td><td>小型项目、本地开发</td></tr><tr><td><strong>FAISS</strong></td><td>Facebook开源，速度快</td><td>研究和实验</td></tr></tbody></table><h3>2.5 优化向量检索的技巧</h3><h4>技巧1：混合检索（Hybrid Search）</h4><p>结合关键词检索和向量检索：</p><pre><code class="python"># 伪代码示例
def hybrid_search(query, alpha=0.5):
    # 向量检索得分
    vector_results = vector_search(query)
    
    # 关键词检索得分（BM25）
    keyword_results = bm25_search(query)
    
    # 加权融合
    final_scores = alpha * vector_results + (1-alpha) * keyword_results
    return top_k(final_scores)</code></pre><h4>技巧2：重排序（Reranking）</h4><p>使用更强大的模型对初步检索结果重新排序：</p><pre><code class="python">def rerank(query, initial_results):
    """使用交叉编码器重排序"""
    cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')
    
    pairs = [(query, doc) for doc in initial_results]
    scores = cross_encoder.predict(pairs)
    
    # 按新得分重新排序
    return sort_by_scores(initial_results, scores)</code></pre><h4>技巧3：查询扩展</h4><p>扩展用户查询以提高召回率：</p><pre><code class="python">def query_expansion(query):
    """生成查询的多个变体"""
    expanded_queries = [
        query,
        f"关于{query}的详细解释",
        f"{query}是什么意思",
        f"如何理解{query}"
    ]
    return expanded_queries</code></pre><hr/><h2>三、上下文注入：让LLM"看见"外部知识</h2><h3>3.1 上下文注入的原理</h3><p>上下文注入是将检索到的文档作为提示（Prompt）的一部分，提供给LLM。这个过程就像给AI提供"参考资料"。</p><h4>基本结构</h4><pre><code>系统指令 + 检索到的上下文 + 用户问题 → LLM → 生成答案</code></pre><h3>3.2 Prompt工程最佳实践</h3><h4>模板示例1：基础RAG Prompt</h4><pre><code class="python">def create_rag_prompt(query, context_docs):
    prompt = f"""你是一个专业的AI助手。请基于以下参考资料回答用户的问题。

参考资料：
{format_context(context_docs)}

重要提示：
1. 只基于上述参考资料回答问题
2. 如果参考资料中没有相关信息，请明确说明
3. 引用参考资料时请注明来源

用户问题：{query}

请提供准确、详细的回答："""
    
    return prompt

def format_context(docs):
    """格式化上下文文档"""
    formatted = []
    for i, doc in enumerate(docs, 1):
        formatted.append(f"[文档{i}]\n{doc['content']}\n来源：{doc['source']}\n")
    return "\n".join(formatted)</code></pre><h4>模板示例2：带引用的高级Prompt</h4><pre><code class="python">def create_advanced_rag_prompt(query, context_docs):
    prompt = f"""# 角色
你是一个严谨的知识问答助手。

# 任务
基于提供的参考资料回答用户问题，并标注信息来源。

# 参考资料
{format_numbered_context(context_docs)}

# 回答要求
1. **准确性**：确保答案完全基于参考资料
2. **引用标注**：使用[1][2]标注信息来源
3. **完整性**：综合所有相关资料给出全面回答
4. **诚实性**：如果资料不足，明确说明局限性

# 用户问题
{query}

# 你的回答
"""
    return prompt

def format_numbered_context(docs):
    """带编号的上下文格式化"""
    formatted = []
    for i, doc in enumerate(docs, 1):
        formatted.append(f"[{i}] {doc['content']}\n(来源: {doc['source']})\n")
    return "\n".join(formatted)</code></pre><h3>3.3 上下文窗口管理</h3><h4>问题：上下文过长</h4><p>当检索到的文档过多或过长时，可能超出LLM的上下文窗口限制。</p><h4>解决方案</h4><p><strong>方案1：智能截断</strong></p><pre><code class="python">def truncate_context(docs, max_tokens=2000):
    """智能截断上下文"""
    truncated = []
    current_tokens = 0
    
    for doc in docs:
        doc_tokens = count_tokens(doc['content'])
        if current_tokens + doc_tokens &lt;= max_tokens:
            truncated.append(doc)
            current_tokens += doc_tokens
        else:
            # 截断最后一个文档
            remaining = max_tokens - current_tokens
            doc['content'] = truncate_to_tokens(doc['content'], remaining)
            truncated.append(doc)
            break
    
    return truncated</code></pre><p><strong>方案2：分层检索</strong></p><pre><code class="python">def hierarchical_retrieval(query, k1=10, k2=3):
    """两阶段检索：先召回，再精选"""
    # 第一阶段：快速召回更多文档
    candidates = vector_search(query, top_k=k1)
    
    # 第二阶段：使用更强模型精选最相关的
    final_docs = rerank(query, candidates, top_k=k2)
    
    return final_docs</code></pre><p><strong>方案3：文档摘要</strong></p><pre><code class="python">async def summarize_docs(docs, llm):
    """对长文档进行摘要"""
    summaries = []
    for doc in docs:
        if len(doc['content']) &gt; 1000:
            summary = await llm.summarize(doc['content'])
            doc['content'] = summary
        summaries.append(doc)
    return summaries</code></pre><h3>3.4 上下文质量优化</h3><h4>技巧1：去重</h4><pre><code class="python">def deduplicate_docs(docs, similarity_threshold=0.9):
    """移除相似度过高的重复文档"""
    unique_docs = []
    for doc in docs:
        is_duplicate = False
        for existing in unique_docs:
            if cosine_similarity(doc['embedding'], existing['embedding']) &gt; similarity_threshold:
                is_duplicate = True
                break
        if not is_duplicate:
            unique_docs.append(doc)
    return unique_docs</code></pre><h4>技巧2：相关性过滤</h4><pre><code class="python">def filter_by_relevance(docs, min_score=0.7):
    """过滤掉相关性低的文档"""
    return [doc for doc in docs if doc['score'] &gt;= min_score]</code></pre><h4>技巧3：多样性采样</h4><pre><code class="python">def diversify_results(docs, top_k=5):
    """确保结果的多样性"""
    selected = [docs[0]]  # 选择最相关的
    
    for doc in docs[1:]:
        if len(selected) &gt;= top_k:
            break
        
        # 计算与已选文档的最大相似度
        max_sim = max([cosine_similarity(doc['embedding'], s['embedding']) 
                       for s in selected])
        
        # 如果不太相似，则添加
        if max_sim &lt; 0.85:
            selected.append(doc)
    
    return selected</code></pre><hr/><h2>四、完整RAG系统实现</h2><h3>4.1 系统架构</h3><pre><code>┌─────────────┐
│  用户查询   │
└──────┬──────┘
       │
       ▼
┌─────────────────┐
│  查询处理模块   │ ← 查询改写、扩展
└──────┬──────────┘
       │
       ▼
┌─────────────────┐
│  向量检索引擎   │ ← 向量数据库
└──────┬──────────┘
       │
       ▼
┌─────────────────┐
│  重排序模块     │ ← 提高精确度
└──────┬──────────┘
       │
       ▼
┌─────────────────┐
│  上下文构建     │ ← Prompt工程
└──────┬──────────┘
       │
       ▼
┌─────────────────┐
│  LLM生成        │ ← 生成答案
└──────┬──────────┘
       │
       ▼
┌─────────────────┐
│  后处理与验证   │ ← 事实检查
└──────┬──────────┘
       │
       ▼
┌─────────────────┐
│  返回结果       │
└─────────────────┘</code></pre><h3>4.2 Python实现示例</h3><pre><code class="python">from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.llms import OpenAI
from langchain.chains import RetrievalQA

class RAGSystem:
    def __init__(self, documents):
        """初始化RAG系统"""
        # 1. 文档处理
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=500,
            chunk_overlap=50,
            separators=["\n\n", "\n", "。", "！", "？", ".", "!", "?"]
        )
        
        # 2. Embedding模型
        self.embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
        
        # 3. 向量数据库
        self.vectorstore = self._build_vectorstore(documents)
        
        # 4. LLM
        self.llm = OpenAI(temperature=0)
        
        # 5. 检索器
        self.retriever = self.vectorstore.as_retriever(
            search_type="mmr",  # 最大边际相关性
            search_kwargs={
                "k": 4,
                "fetch_k": 20,
                "lambda_mult": 0.5
            }
        )
        
    def _build_vectorstore(self, documents):
        """构建向量存储"""
        # 切分文档
        chunks = self.text_splitter.split_documents(documents)
        
        # 创建向量数据库
        vectorstore = Chroma.from_documents(
            documents=chunks,
            embedding=self.embeddings,
            persist_directory="./chroma_db"
        )
        
        return vectorstore
    
    def query(self, question):
        """执行RAG查询"""
        # 创建问答链
        qa_chain = RetrievalQA.from_chain_type(
            llm=self.llm,
            chain_type="stuff",
            retriever=self.retriever,
            return_source_documents=True,
            chain_type_kwargs={
                "prompt": self._create_prompt()
            }
        )
        
        # 执行查询
        result = qa_chain({"query": question})
        
        return {
            "answer": result["result"],
            "sources": result["source_documents"]
        }
    
    def _create_prompt(self):
        """创建Prompt模板"""
        from langchain.prompts import PromptTemplate
        
        template = """基于以下参考资料回答问题。如果资料中没有答案，请说"我不知道"。

参考资料：
{context}

问题：{question}

详细回答："""
        
        return PromptTemplate(
            template=template,
            input_variables=["context", "question"]
        )

# 使用示例
from langchain.document_loaders import TextLoader

# 加载文档
loader = TextLoader("knowledge_base.txt")
documents = loader.load()

# 创建RAG系统
rag = RAGSystem(documents)

# 查询
result = rag.query("什么是机器学习？")
print(f"回答：{result['answer']}")
print(f"参考文档数量：{len(result['sources'])}")</code></pre><h3>4.3 高级优化：多查询RAG</h3><pre><code class="python">class AdvancedRAG:
    def multi_query_retrieval(self, question):
        """生成多个查询角度"""
        # 使用LLM生成问题的不同表述
        variations = self.llm.generate_variations(question, num=3)
        
        all_docs = []
        for variation in variations:
            docs = self.retriever.get_relevant_documents(variation)
            all_docs.extend(docs)
        
        # 去重和排序
        unique_docs = self.deduplicate(all_docs)
        ranked_docs = self.rerank(question, unique_docs)
        
        return ranked_docs[:5]
    
    def self_query_with_metadata(self, question):
        """基于元数据的自查询"""
        # 从问题中提取过滤条件
        metadata_filter = self.extract_metadata_filter(question)
        
        # 在向量搜索中应用过滤
        docs = self.vectorstore.similarity_search(
            question,
            filter=metadata_filter,
            k=5
        )
        
        return docs</code></pre><hr/><h2>五、实践案例与应用场景</h2><h3>5.1 企业知识库问答</h3><p><strong>场景</strong>：企业内部有大量文档（产品手册、政策文档、FAQ等）</p><p><strong>实现要点</strong>：</p><ul><li>文档分类和元数据管理</li><li>权限控制</li><li>定期更新向量库</li></ul><pre><code class="python"># 示例：企业知识库RAG
class EnterpriseRAG:
    def __init__(self):
        self.vectorstore = Chroma(
            collection_name="company_docs",
            embedding_function=embeddings
        )
    
    def add_document(self, doc, metadata):
        """添加文档并包含元数据"""
        chunks = self.split_document(doc)
        
        for chunk in chunks:
            self.vectorstore.add_texts(
                texts=[chunk],
                metadatas=[{
                    "department": metadata["department"],
                    "doc_type": metadata["doc_type"],
                    "last_updated": metadata["date"],
                    "access_level": metadata["access_level"]
                }]
            )
    
    def query_with_access_control(self, question, user_level):
        """带权限控制的查询"""
        results = self.vectorstore.similarity_search(
            question,
            filter={"access_level": {"$lte": user_level}},
            k=5
        )
        return results</code></pre><h3>5.2 客服智能问答</h3><p><strong>场景</strong>：自动回答客户常见问题</p><p><strong>实现要点</strong>：</p><ul><li>快速响应时间</li><li>多轮对话上下文管理</li><li>答案质量监控</li></ul><h3>5.3 学术研究助手</h3><p><strong>场景</strong>：帮助研究人员查找和总结文献</p><p><strong>实现要点</strong>：</p><ul><li>支持PDF解析</li><li>引用管理</li><li>多模态检索（文本+图表）</li></ul><hr/><h2>六、评估与优化</h2><h3>6.1 评估指标</h3><h4>检索质量指标</h4><pre><code class="python">def calculate_retrieval_metrics(retrieved_docs, relevant_docs):
    """计算检索指标"""
    retrieved_ids = set([doc['id'] for doc in retrieved_docs])
    relevant_ids = set([doc['id'] for doc in relevant_docs])
    
    # 召回率 (Recall)
    recall = len(retrieved_ids &amp; relevant_ids) / len(relevant_ids)
    
    # 精确率 (Precision)
    precision = len(retrieved_ids &amp; relevant_ids) / len(retrieved_ids)
    
    # F1分数
    f1 = 2 * (precision * recall) / (precision + recall)
    
    # MRR (Mean Reciprocal Rank)
    for i, doc in enumerate(retrieved_docs, 1):
        if doc['id'] in relevant_ids:
            mrr = 1 / i
            break
    
    return {
        "recall": recall,
        "precision": precision,
        "f1": f1,
        "mrr": mrr
    }</code></pre><h4>生成质量指标</h4><ul><li><strong>答案准确性</strong>：与标准答案的相似度</li><li><strong>幻觉率</strong>：生成内容中不基于参考资料的比例</li><li><strong>完整性</strong>：是否完整回答了问题</li><li><strong>引用准确性</strong>：引用是否正确</li></ul><h3>6.2 常见问题与解决方案</h3><table><thead><tr><th>问题</th><th>原因</th><th>解决方案</th></tr></thead><tbody><tr><td>检索不到相关文档</td><td>Embedding模型不合适</td><td>更换或微调Embedding模型</td></tr><tr><td>答案包含幻觉</td><td>上下文不足或Prompt不当</td><td>优化Prompt，增加"仅基于资料回答"约束</td></tr><tr><td>响应速度慢</td><td>检索或生成耗时长</td><td>使用更快的向量数据库，减少检索文档数</td></tr><tr><td>答案质量不稳定</td><td>检索结果质量波动</td><td>增加重排序步骤，提高检索精确度</td></tr></tbody></table><h3>6.3 持续优化策略</h3><ol><li><strong>A/B测试</strong>：对比不同检索策略和Prompt的效果</li><li><strong>用户反馈循环</strong>：收集用户评价，优化系统</li><li><strong>定期评估</strong>：建立测试集，定期评估系统性能</li><li><strong>模型更新</strong>：跟踪最新的Embedding和LLM模型</li></ol><hr/><h2>七、未来趋势与展望</h2><h3>7.1 多模态RAG</h3><p>支持图像、音频等多种模态的检索和生成。</p><h3>7.2 自适应RAG</h3><p>根据问题类型自动选择最佳检索策略。</p><h3>7.3 知识图谱增强</h3><p>结合结构化知识图谱提升推理能力。</p><h3>7.4 实时RAG</h3><p>支持流式检索和增量生成，提升用户体验。</p><hr/><h2>总结</h2><p>RAG技术通过<strong>向量检索</strong>和<strong>上下文注入</strong>两大核心机制，成功地将外部知识与大语言模型结合，显著提升了AI系统的准确性和实用性。</p><h3>关键要点回顾</h3><ol><li><strong>向量检索是基础</strong>：选择合适的Embedding模型和向量数据库至关重要</li><li><strong>上下文注入是关键</strong>：精心设计的Prompt能大幅提升答案质量</li><li><strong>优化是持续的</strong>：通过混合检索、重排序、元数据过滤等技术不断改进</li><li><strong>评估要全面</strong>：关注检索和生成两个阶段的指标</li></ol><h3>实践建议</h3><ul><li><strong>从简单开始</strong>：先实现基础RAG，再逐步优化</li><li><strong>重视数据质量</strong>：高质量的文档是RAG成功的前提</li><li><strong>持续迭代</strong>：基于用户反馈和评估结果不断改进</li><li><strong>选择合适的工具栈</strong>：根据实际需求选择Embedding模型、向量数据库和LLM</li></ul><p>RAG技术正在快速发展，掌握其原理与实践，将帮助你构建更智能、更可靠的AI应用。</p>]]></description></item><item>    <title><![CDATA[百度智能云数据库与MongoDB达成战略合作，打造全球领先的AI原生数据库生态 百度智能云 ]]></title>    <link>https://segmentfault.com/a/1190000047605284</link>    <guid>https://segmentfault.com/a/1190000047605284</guid>    <pubDate>2026-02-11 12:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>近日，百度智能云数据库宣布与MongoDB达成战略合作。双方将依托各自在云计算、人工智能和现代数据库领域的技术优势，构建更开放、更智能的企业级数据基础设施，加速中国企业AI原生数字化转型进程。此次合作，标志着双方在数据库技术应用与行业数字化转型领域的深度协同进入全新阶段。 </p><p><img width="723" height="500" referrerpolicy="no-referrer" src="/img/bVdnUtj" alt="" title=""/></p><p>  根据战略合作协议，百度智能云数据库已正式上线MongoDB数据库产品及解决方案，重点聚焦车联网、内容理解、画像分析三大垂直领域，同时全面覆盖在线教育、金融、物联网、政企、泛互联网等行业，为客户提供灵活、高效、可扩展的数据存储与管理解决方案。</p><ul><li>在车联网领域，百度智能云MongoDB产品，助力车企和出行平台实时采集与存储海量车辆数据，构建精细的用户个性化配置，并利用故障诊断和位置管理能力，全面提升用户体验与运营效率。</li><li>在内容平台领域，双方合作为音视频平台提供高效的内容与元数据管理能力，实现精准的个性化推荐，在保障视频安全存储的同时，确保内容快速分发，让优质内容触达每一位用户。</li><li>在数字化营销领域，为电商平台、社交应用提供强大的用户画像分析引擎，通过深度分析学习行为和日志数据，实现千人千面的精准营销与服务优化。</li></ul><p>百度智能云数据平台部总经理刘斌表示：“百度智能云拥有领先的全栈AI基础设施与广泛的行业覆盖，MongoDB在现代数据库领域具有深厚的技术沉淀。此次战略合作将为中国市场带来更具竞争力的DBaaS解决方案。我们将持续赋能企业数字化转型，打造从数据存储到智能应用的全链路服务能力。”<br/>MongoDB 大中华区副总裁胡建基（Gabriel Woo）对此次合作充满期待：“百度智能云作为国内领先的智能云服务提供商，其技术实力与行业影响力毋庸置疑。这次五年期战略合作是双方深度互信的体现，更是对市场需求的精准响应。MongoDB的灵活文档模型与百度智能云的规模化云服务能力将深度结合，为企业提供更高效、更敏捷的数据工具，助力他们在快速变化的市场环境中保持领先。我们期待通过此次合作，让更多中国企业享受到前沿数据库技术带来的价值，共同推动行业创新发展。”</p><p>双方深厚的客户基础为合作奠定了坚实基础。百度智能云的服务网络覆盖超过65%的央企、800余家金融机构以及众多头部汽车、手机、新能源企业。MongoDB在华已服务众多行业领军企业，覆盖金融、汽车、互联网等多个关键领域。双方客户资源的高度互补与行业覆盖的深度交叉，将推动合作价值最大化，实现 “1+1&gt;2”的协同效应。</p><p>在"云智一体"战略指引下，百度智能云数据库提供高性能、安全可靠的云端数据库服务，支持多种数据库类型，助力企业高效构建智能应用。云原生数据库GaiaDB基于存算分离架构，性能较MySQL提升百倍；向量数据库VectorDB向量检索QPS较开源方案领先7倍。</p><p>在权威认证方面，2024 年，向量数据库VectorDB获IDC向量数据库TOP 1评级；2025 年，百度智能云数据库通过中国信通院“可信数据库”首批向量数据库性能测试，成为国内首批达标产品。同年，百度智能云GaiaDB-X成为首轮测试即满足数据库政府采购标准的数据库产品之一。</p><p>目前，百度智能云数据库已服务金融、能源、汽车、互联网等众多关键行业。</p><p>面向未来，百度智能云数据库与MongoDB不仅将持续深化在车联网、内容平台、精准营销及泛互联网领域的合作，还计划在人工智能领域展开更广泛的协同，共同助力中国企业把握AI时代新机遇并创造新价值。</p><p>如需了解更多关于百度智能云的信息，欢迎访问网页<a href="https://link.segmentfault.com/?enc=LcwmndW1cNdXjH2LFtv%2BDA%3D%3D.GoUVuV6Ns%2F6GQUX41mIBVnNF4sbpqb6IJjByTxOQji8%3D" rel="nofollow" target="_blank">https://cloud.baidu.com/</a><br/>如需了解更多关于MongoDB的信息，欢迎访问网页 <a href="https://link.segmentfault.com/?enc=6KYMlbO9uNhMDSa%2B4M%2F8YA%3D%3D.39gmXeND3I8YvpG4EjlmvVpofAMkI5TARy2%2FSUG3Cx4%3D" rel="nofollow" target="_blank">https://www.mongodb.com/zh-cn</a>   </p>]]></description></item><item>    <title><![CDATA[【节点】[HDSceneDepth节点]原理解析与实际应用 SmalBox ]]></title>    <link>https://segmentfault.com/a/1190000047605155</link>    <guid>https://segmentfault.com/a/1190000047605155</guid>    <pubDate>2026-02-11 11:04:52</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <blockquote><a href="https://link.segmentfault.com/?enc=mTmOdJMsTbtWMBDhSVXBLQ%3D%3D.kw5nSDucQhbBCyo5InaDupdUnsBW%2BY%2Fjaweestu%2BYRzQo3YIKywnq6Yuc241eoy4knOzOOKCsyhNhMov4dNMWQXw2vRNJF9aQPsEgVGYjB1ibZsTbLufg%2FcAsUYcWXClqEu0OIq%2FbQUlPPG1Tk40nsLQjvD2VHkL7x%2BbPY3yRhlMaESnCO%2FcMZgZcu5Oj6gpEFyVIGaCU3HhHwZrufULOice%2B9v32WV8qLVtH5MeL1w%3D" rel="nofollow" target="_blank">【Unity Shader Graph 使用与特效实现】</a><strong>专栏-直达</strong></blockquote><p>高清场景深度节点（HD Scene Depth Node）是Unity高清渲染管线（HDRP）中一个功能强大的着色器图形节点，专门用于访问当前摄像机的深度缓冲区信息。在实时渲染和后期处理效果开发中，深度信息的获取与处理是创建各种视觉特效的基础，而HD Scene Depth节点正是为此目的设计的核心工具。</p><p>深度缓冲区存储了场景中每个像素到摄像机的距离信息，这些数据在渲染过程中被广泛用于实现景深效果、雾效、遮挡处理、屏幕空间反射等多种高级渲染技术。通过HD Scene Depth节点，开发者可以直接在着色器图形中采样这些深度值，无需编写复杂的底层着色器代码，大大提高了开发效率和可视化编程的便捷性。</p><p>该节点的设计充分考虑了HDRP的高质量渲染需求，支持多种深度采样模式和mipmap级别访问，为创建电影级画质的实时视觉效果提供了强有力的支持。无论是实现精确的深度检测，还是创建基于深度的复杂材质效果，HD Scene Depth节点都是不可或缺的工具。</p><h2>描述</h2><p>高清场景深度节点是Unity着色器图形中专门用于访问当前摄像机深度缓冲区的特殊节点。它通过UV输入参数接收标准化的屏幕坐标，并返回对应位置的深度信息。这一机制使得开发者能够在片元着色器阶段精确获取场景中各点的深度数据，为各种基于深度的渲染效果奠定基础。</p><p>在渲染管线中，深度缓冲区是一个至关重要的组件，它记录了从摄像机视角看，场景中每个像素对应的最近表面距离。这些深度信息不仅用于确定物体的前后关系（深度测试），还为许多后处理效果和高级渲染技术提供了必要的数据支持。HD Scene Depth节点的核心价值在于它将这些底层数据以直观、易用的方式暴露给着色器图形用户，让非专业图形程序员也能轻松实现复杂的深度相关效果。</p><p>该节点的一个关键特性是它只能在片元着色器阶段使用。这是因为深度缓冲区的完整信息只有在几何体渲染完成后才会变得可用，而片元着色器正是处理每个像素最终颜色的阶段。此外，该节点仅适用于非不透明材质，这是因为透明物体通常需要特殊的渲染顺序和混合处理，其深度信息可能与不透明物体有所不同。</p><p>Unity预期UV输入值为标准化的屏幕坐标，这意味着坐标范围应该在[0,1]区间内，其中(0,0)通常表示屏幕左下角，(1,1)表示屏幕右上角。这种标准化坐标系统使得深度采样与具体屏幕分辨率无关，增强了着色器的通用性和可移植性。</p><p>除了基本的深度采样功能，HD Scene Depth节点还支持访问深度缓冲区的mipmap。Mipmap是预先计算的不同分辨率版本的纹理，用于提高纹理采样的质量和性能。当进行远距离或斜向的深度采样时，使用适当的mip层级可以减少锯齿和闪烁现象，提高视觉效果的质量。Lod（Level of Detail）输入端口正是用于控制采样时使用的mip层级，允许开发者根据具体需求平衡性能与质量。</p><h3>深度数据的意义与应用</h3><p>深度数据在实时渲染中具有广泛的应用价值，理解这些数据的含义和潜在用途对于有效使用HD Scene Depth节点至关重要：</p><ul><li><strong>空间关系判定</strong>：深度值直接反映了像素与摄像机之间的距离关系，可以用于确定物体间的相对位置和遮挡情况</li><li><strong>后处理效果基础</strong>：许多屏幕空间后处理效果，如景深、雾效、边缘检测等，都高度依赖精确的深度信息</li><li><strong>世界位置重建</strong>：结合摄像机参数，深度值可以用于重建像素在世界空间中的实际位置，这是许多高级渲染技术的基础</li><li><strong>非真实渲染</strong>：通过分析深度变化，可以实现轮廓线检测等非真实感渲染效果</li><li><strong>特效遮罩</strong>：基于深度的阈值判断可以创建各种遮罩效果，用于限制特定区域的特效应用范围</li></ul><h3>节点内部工作机制</h3><p>从技术角度看，HD Scene Depth节点在着色器编译过程中会被转换为相应的纹理采样指令，具体来说是对深度缓冲区的采样操作。在HDRP中，深度缓冲区通常以特定格式存储，如R32_FLOAT或R16_FLOAT，具体取决于项目的精度要求和硬件支持。</p><p>当在着色器图形中使用该节点时，Unity会根据节点的配置生成相应的HLSL代码。例如，当选择Linear01模式时，生成的代码可能会调用类似<code>Linear01Depth(SAMPLE_DEPTH_TEXTURE(_CameraDepthTexture, uv))</code>的函数，将原始的深度缓冲区值转换为[0,1]范围内的线性深度。</p><p>值得注意的是，深度缓冲区的实际内容可能因渲染设置而异。在HDRP中，根据不同的渲染路径和质量设置，深度缓冲区可能包含前向渲染的深度、延迟渲染的G-Buffer深度，或者是特定于某些渲染特性的深度信息。HD Scene Depth节点抽象了这些底层差异，为开发者提供了一致的接口。</p><h2>渲染管线兼容性</h2><p>HD Scene Depth节点是专为高清渲染管线（HDRP）设计的专用节点，这意味着它在通用渲染管线（URP）中不可用。这种兼容性差异源于两种渲染管线的架构设计、渲染目标和深度处理机制的根本不同。</p><h3>高清渲染管线（HDRP）</h3><p>在高清渲染管线中，HD Scene Depth节点完全受支持并提供了完整的功能集。HDRP作为Unity的高端渲染解决方案，专为需要高端图形保真度的项目设计，如PC、主机游戏和高端移动设备。它采用了复杂的多通道渲染架构和先进的深度管理机制，为HD Scene Depth节点提供了丰富的深度数据访问能力。</p><p>在HDRP中，深度缓冲区的管理和使用具有以下特点：</p><ul><li><strong>多摄像机支持</strong>：HDRP支持多个摄像机并能够正确处理它们之间的深度信息关系</li><li><strong>分层渲染</strong>：HDRP的渲染层系统允许更精细地控制哪些物体贡献到深度缓冲区</li><li><strong>自定义渲染通道</strong>：通过自定义渲染通道，开发者可以更灵活地控制深度缓冲区的生成和使用</li><li><strong>高质量深度预处理</strong>：HDRP包含高级的深度预处理步骤，如反向Z缓冲区、深度压缩等，以提高深度精度和性能</li></ul><h3>通用渲染管线（URP）</h3><p>与HDRP不同，通用渲染管线（URP）不支持HD Scene Depth节点。URP作为Unity的轻量级渲染解决方案，优先考虑性能和跨平台兼容性，因此在功能集上相对精简。在URP中，如果需要访问深度信息，通常需要使用不同的方法：</p><ul><li><strong>Scene Depth Node</strong>：URP提供了自己的场景深度节点，但其功能和接口可能与HDRP的版本有所不同</li><li><strong>Renderer Features</strong>：通过自定义渲染器功能，可以在URP中实现类似的深度访问能力</li><li><strong>Camera Depth Texture</strong>：手动启用相机的深度纹理并编写自定义着色器代码进行采样</li></ul><h3>兼容性决策考量</h3><p>Unity决定在URP中不提供HD Scene Depth节点是基于多方面的技术考量：</p><ul><li><strong>架构差异</strong>：HDRP和URP使用不同的渲染架构和缓冲区管理策略，直接移植节点功能并不简单</li><li><strong>性能优先级</strong>：URP更注重性能和轻量级，某些高级深度功能可能会影响这些目标</li><li><strong>使用场景</strong>：URP通常用于对图形保真度要求不那么极致的项目，这些项目可能不需要复杂的深度访问功能</li><li><strong>资源限制</strong>：移动平台等URP常见目标平台可能有纹理格式和采样限制，影响深度缓冲区的实现方式</li></ul><h3>自定义渲染管线中的行为</h3><p>对于使用自定义渲染管线的情况，HD Scene Depth节点的行为需要显式定义。如果未在自定义管线中实现相应的功能，该节点将返回默认的白色值（1,1,1），这通常表示缺少有效数据。</p><p>在自定义渲染管线中支持HD Scene Depth节点通常涉及以下步骤：</p><ul><li>确保渲染管线正确生成并维护深度缓冲区</li><li>将深度缓冲区作为全局着色器属性暴露</li><li>实现与HDRP兼容的深度解码函数</li><li>处理不同平台和渲染设置的深度格式差异</li></ul><h2>端口</h2><p>HD Scene Depth节点提供了三个主要端口，用于控制深度采样的参数和输出结果。理解每个端口的功能和正确使用方法对于有效利用该节点至关重要。</p><h3>UV输入端口</h3><p>UV输入端口是HD Scene Depth节点最关键的参数之一，它决定了在深度缓冲区中的采样位置。该端口接受Vector 4类型的输入，并与屏幕位置绑定。</p><p><strong>技术特性</strong></p><ul><li><strong>数据类型</strong>：Vector 4（四维向量）</li><li><strong>坐标空间</strong>：标准化屏幕空间</li><li><strong>绑定类型</strong>：屏幕位置（自动绑定）</li><li><strong>默认值</strong>：如未连接，通常使用当前片元的屏幕位置</li></ul><p><strong>标准化屏幕坐标</strong></p><p>UV输入期望的是标准化屏幕坐标，这意味着无论实际屏幕分辨率如何，坐标范围都应在[0,1]区间内：</p><ul><li><strong>(0,0)</strong> 通常对应屏幕左下角</li><li><strong>(1,1)</strong> 通常对应屏幕右上角</li><li><strong>Z分量</strong>：通常用于透视校正，在大多数情况下可以忽略</li><li><strong>W分量</strong>：通常包含透视除法所需的信息</li></ul><p><strong>获取屏幕坐标的方法</strong></p><p>在着色器图形中，有多种方式可以获得合适的UV坐标：</p><ul><li>使用<strong>Screen Position</strong>节点获取当前片元的屏幕位置</li><li>通过计算自定义UV，实现特定区域的深度采样</li><li>使用<strong>Tiling And Offset</strong>节点调整和变换屏幕坐标</li></ul><p><strong>高级应用技巧</strong></p><ul><li><strong>视口相对采样</strong>：通过偏移UV坐标，可以实现相对于当前像素的深度采样，用于边缘检测等效果</li><li><strong>动态UV动画</strong>：对UV坐标应用时间相关的变换，可以创建基于深度的动态效果</li><li><strong>多重采样</strong>：通过在不同UV位置多次采样深度，可以实现更复杂的深度分析效果</li></ul><h3>Lod输入端口</h3><p>Lod（Level of Detail）输入端口允许指定采样深度缓冲区时使用的mipmap层级。该功能对于优化性能和改善视觉质量具有重要意义。</p><p><strong>技术特性</strong></p><ul><li><strong>数据类型</strong>：Float（浮点数）</li><li><strong>取值范围</strong>：通常为0到深度纹理的最大mip层级</li><li><strong>默认值</strong>：如未连接，通常使用0（最高分辨率）</li></ul><p><strong>Mipmap在深度采样中的作用</strong></p><p>深度缓冲区的mipmap是通过对原始深度图进行下采样生成的较低分辨率版本：</p><ul><li><strong>Level 0</strong>：原始分辨率，提供最精确的深度信息</li><li><strong>Level 1</strong>：1/2分辨率，在每维度上减半</li><li><strong>Level 2</strong>：1/4分辨率，依此类推</li><li><strong>自动mipmap</strong>：HDRP通常会自动为深度缓冲区生成mipmap</li></ul><p><strong>性能与质量权衡</strong></p><p>选择合适的Lod值需要在性能和质量之间取得平衡：</p><ul><li><strong>高质量需求</strong>：使用低Lod值（接近0），获得更精确的深度信息</li><li><strong>性能优化</strong>：使用高Lod值，减少纹理采样带宽和缓存压力</li><li><strong>远处物体</strong>：对屏幕中较小的或远处的物体，可以使用较高Lod值而不会明显影响视觉质量</li></ul><p><strong>Lod计算策略</strong></p><p>在实际应用中，Lod值可以根据多种因素动态计算：</p><ul><li><strong>基于距离</strong>：根据像素到摄像机的距离调整Lod</li><li><strong>基于屏幕空间导数</strong>：使用<code>ddx</code>和<code>ddy</code>计算适当的Lod值</li><li><strong>固定策略</strong>：对全屏效果使用统一的Lod值</li></ul><h3>Output输出端口</h3><p>Output端口是HD Scene Depth节点的结果输出，它提供了指定屏幕位置的深度信息。根据选择的深度采样模式，输出的具体含义和用途有所不同。</p><p><strong>技术特性</strong></p><ul><li><strong>数据类型</strong>：Vector 3（三维向量）</li><li><strong>分量含义</strong>：根据深度模式，三个分量可能包含相同或相关的深度信息</li><li><strong>数值范围</strong>：取决于选择的深度采样模式</li></ul><p><strong>输出解释</strong></p><p>虽然输出是Vector 3类型，但在大多数情况下，我们主要使用其中一个分量：</p><ul><li><strong>R通道</strong>：通常包含主要的深度信息</li><li><strong>G和B通道</strong>：在某些配置下可能包含辅助信息或保持为0</li><li><strong>实际使用</strong>：通常通过<strong>Swizzle</strong>节点提取所需的单个分量</li></ul><p><strong>输出稳定性考虑</strong></p><p>深度输出值可能受多种因素影响：</p><ul><li><strong>深度格式</strong>：不同平台可能使用不同的深度缓冲区精度和格式</li><li><strong>渲染设置</strong>：HDRP的质量设置可能影响深度计算的精度</li><li><strong>摄像机参数</strong>：近裁剪面和远裁剪面的设置会影响深度值的分布</li></ul><h2>深度采样模式</h2><p>HD Scene Depth节点支持多种深度采样模式，每种模式以不同的方式解释和表示深度信息。理解这些模式的差异和适用场景对于正确使用深度数据至关重要。</p><h3>Linear01模式</h3><p>Linear01模式将深度值转换为0到1之间的线性表示，这是最常用且直观的深度表示方法。</p><p><strong>技术特性</strong></p><ul><li><strong>数值范围</strong>：[0, 1]</li><li><strong>0值含义</strong>：位于摄像机的近裁剪面</li><li><strong>1值含义</strong>：位于摄像机的远裁剪面</li><li><strong>分布特性</strong>：在近裁剪面和远裁剪面之间线性分布</li></ul><p><strong>数学表示</strong></p><p>Linear01深度可以通过以下公式计算：</p><pre><code>depth_linear01 = (z - near) / (far - near)</code></pre><p>其中：</p><ul><li><code>z</code>是视图空间中的Z坐标</li><li><code>near</code>是近裁剪面距离</li><li><code>far</code>是远裁剪面距离</li></ul><p><strong>应用场景</strong></p><p>Linear01模式因其直观性而被广泛使用：</p><ul><li><strong>深度可视化</strong>：直接显示Linear01深度可以创建从黑到白的深度图</li><li><strong>线性插值</strong>：在近远裁剪面之间进行线性混合，如雾效、深度褪色等</li><li><strong>阈值处理</strong>：基于固定的深度阈值实现效果切换</li><li><strong>屏幕空间效果</strong>：需要与屏幕空间坐标线性相关的深度应用</li></ul><p><strong>使用示例</strong></p><p>创建基于深度的雾效：</p><ol><li>使用HD Scene Depth节点采样Linear01深度</li><li>使用<strong>Smoothstep</strong>或<strong>Remap</strong>节点根据深度计算雾强度</li><li>将雾强度与场景颜色混合</li></ol><h3>Raw模式</h3><p>Raw模式提供直接从深度缓冲区读取的原始深度值，这些值通常是非线性的，并且依赖于具体的深度缓冲区格式。</p><p><strong>技术特性</strong></p><ul><li><strong>数值范围</strong>：依赖于深度缓冲区格式，通常是[0, 1]或[1, 0]</li><li><strong>分布特性</strong>：通常是非线性的，在近处有更高精度</li><li><strong>平台依赖性</strong>：不同平台和渲染设置可能产生不同的原始深度值</li></ul><p><strong>深度缓冲区格式</strong></p><p>Raw深度值的具体含义取决于深度缓冲区的内部格式：</p><ul><li><strong>反向Z缓冲区</strong>：在现代图形API中常见，1.0表示近裁剪面，0.0表示远裁剪面</li><li><strong>传统Z缓冲区</strong>：0.0表示近裁剪面，1.0表示远裁剪面</li><li><strong>浮点深度</strong>：使用浮点格式存储，提供更大的范围和精度</li></ul><p><strong>应用场景</strong></p><p>Raw模式主要用于需要直接处理原始深度数据的高级应用：</p><ul><li><strong>深度重建</strong>：手动执行深度解码以实现特定的精度需求</li><li><strong>深度比较</strong>：进行精确的深度相等性或范围测试</li><li><strong>自定义深度编码</strong>：实现特殊的深度压缩或编码方案</li><li><strong>渲染管线开发</strong>：在自定义渲染管线中调试和验证深度缓冲区内容</li></ul><p><strong>注意事项</strong></p><p>使用Raw模式时需要特别小心：</p><ul><li>结果可能因平台和渲染设置而异</li><li>非线性分布可能导致数值精度问题</li><li>需要深入了解特定平台的深度缓冲区行为</li></ul><h3>Eye模式</h3><p>Eye模式将深度值转换为视空间中的实际单位距离，提供了最有物理意义的深度表示。</p><p><strong>技术特性</strong></p><ul><li><strong>数值单位</strong>：与世界空间单位一致（通常是米）</li><li><strong>数值范围</strong>：[near, far]，即近裁剪面到远裁剪面的距离</li><li><strong>坐标系</strong>：视空间坐标系，Z轴指向摄像机前方</li></ul><p><strong>数学关系</strong></p><p>Eye深度实际上是视空间中的Z坐标：</p><pre><code>depth_eye = z</code></pre><p>其中<code>z</code>是视图空间中的Z坐标，表示从摄像机位置到片元的直线距离。</p><p><strong>应用场景</strong></p><p>Eye模式在需要物理准确性的应用中非常有用：</p><ul><li><strong>物理精确的效果</strong>：如基于真实距离的雾效、光照衰减</li><li><strong>世界位置重建</strong>：结合屏幕坐标重建像素的世界位置</li><li><strong>尺寸感知效果</strong>：创建与场景实际尺寸相关的特效</li><li><strong>科学可视化</strong>：需要精确距离测量的专业应用</li></ul><p><strong>性能考虑</strong></p><p>Eye模式可能需要额外的计算来从原始深度值转换，但在HDRP中，这种转换通常已经过高度优化。</p><h2>注意</h2><p>在使用HD Scene Depth节点时，有几个重要的技术细节和限制需要特别注意，这些因素直接影响节点的行为和使用效果。</p><h3>使用阶段限制</h3><p>HD Scene Depth节点只能在片元着色器阶段使用，这是由深度缓冲区的可用性决定的。在着色器图形的其他阶段（如顶点着色器阶段）尝试使用该节点通常会导致编译错误或未定义行为。</p><p><strong>技术原因</strong></p><p>深度缓冲区在渲染管线的特定点才变得可用：</p><ul><li><strong>深度写入阶段</strong>：在几何体渲染过程中，深度值被写入深度缓冲区</li><li><strong>后处理阶段</strong>：在所有不透明几何体渲染完成后，完整的深度缓冲区才可用于采样</li><li><strong>片元着色器</strong>：作为每个像素处理的最后阶段，自然可以访问已生成的深度信息</li></ul><p><strong>变通方案</strong></p><p>如果需要在顶点着色器中访问深度信息，可考虑以下替代方案：</p><ul><li>在片元着色器中计算所需信息，然后插值到顶点</li><li>使用其他方法估算深度，如基于模型空间位置的简单计算</li><li>重构渲染流程，将深度相关的计算移至片元着色器</li></ul><h3>材质类型限制</h3><p>该节点仅适用于非不透明材质，这意味着它不能在不透明材质的着色器中使用。这一限制与HDRP的渲染顺序和深度管理策略密切相关。</p><p><strong>渲染顺序考量</strong></p><p>HDRP按照特定顺序渲染物体以优化性能和正确性：</p><ul><li><strong>不透明物体</strong>：通常从前向后渲染，利用深度测试提前丢弃不可见片元</li><li><strong>透明物体</strong>：通常从后向前渲染，需要混合且可能修改颜色但不修改深度</li><li><strong>深度缓冲区状态</strong>：在透明物体渲染时，深度缓冲区已包含所有不透明物体的深度信息</li></ul><p><strong>不透明材质中的深度访问</strong></p><p>虽然不能直接在不透明材质中使用HD Scene Depth节点，但仍有其他方法可以访问深度信息：</p><ul><li>使用<strong>Depth Only Pass</strong>创建特殊的深度写入通道</li><li>通过<strong>Renderer Features</strong>添加自定义的深度处理逻辑</li><li>在后期处理效果中处理深度相关效果</li></ul><h3>自定义渲染管线集成</h3><p>在自定义渲染管线中使用HD Scene Depth节点需要显式定义其行为，否则节点将返回白色值(1,1,1)。这一特性使得节点在未正确配置的环境中能够提供可预测的（虽然是错误的）输出。</p><p><strong>实现要求</strong></p><p>在自定义渲染管线中支持HD Scene Depth节点需要：</p><ul><li><strong>深度纹理生成</strong>：确保管线正确生成并维护深度纹理</li><li><strong>着色器变量绑定</strong>：将深度纹理作为全局着色器属性暴露</li><li><strong>采样函数实现</strong>：提供与HDRP兼容的深度采样函数</li><li><strong>平台兼容性处理</strong>：处理不同图形API和平台的深度格式差异</li></ul><p><strong>集成步骤</strong></p><p>将HD Scene Depth节点集成到自定义渲染管线的基本步骤：</p><ol><li>在渲染管线中创建并配置深度纹理</li><li>实现深度纹理的mipmap生成（如果需要Lod功能）</li><li>创建相应的HLSL包含文件，定义深度采样函数</li><li>在着色器图形编译过程中包含这些</li></ol><hr/><blockquote><a href="https://link.segmentfault.com/?enc=i5gVawrgLNIK%2B%2F8fL9P40g%3D%3D.FZsdogCV3CW7dojPhx0947KFGYdiwbXQqxvg8Ol%2FxoI2zQ%2B8uqDGFIAC8RJDDHd2R3viRp7V%2Fv1q14GR%2FGygDYtBiJwwOyNxQiYS4iQ89f0BJsgcx%2F4ksh4Ao6t%2FxmmK%2F0op9hI9ZlCjsx%2BqsNscs7gEKGTfs4%2F2siul%2FgpNzsTJZu280ccHRBliGs34Qok%2FiWyArsAYWb3yuJKU4Dz%2BEmc2kJ5iYxWTqiMoQZee%2F5o%3D" rel="nofollow" target="_blank">【Unity Shader Graph 使用与特效实现】</a><strong>专栏-直达</strong><br/>（欢迎<em>点赞留言</em>探讨，更多人加入进来能更加完善这个探索的过程，🙏）</blockquote>]]></description></item><item>    <title><![CDATA[【JVS更新日志】物联网、APS排产、BI、规则引擎2.11更新说明！ 软件部长 ]]></title>    <link>https://segmentfault.com/a/1190000047605168</link>    <guid>https://segmentfault.com/a/1190000047605168</guid>    <pubDate>2026-02-11 11:04:01</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>项目介绍</h2><p>JVS是企业级数字化服务构建的基础脚手架，主要解决企业信息化项目交付难、实施效率低、开发成本高的问题，采用微服务+配置化的方式，提供了低代码+数据分析+物联网的核心能力产品，并构建了协同办公、企业常用的管理工具等，所有的应用与能力采用模块化构建，按需开箱使用。</p><h2>更新日志</h2><h3>一、生产计划排程系统（APS）</h3><p>当前版本：v2.4.X<br/>更新时间：2026.2.11<br/>在线demo：<a href="https://link.segmentfault.com/?enc=8U3nrBTTf0nSw%2BPOdqYLyQ%3D%3D.KFraetXvYZX8RH%2ByEX4RV2w2hBKpiFAs9fZDBDUbDbQ%3D" rel="nofollow" target="_blank">https://aps.bctools.cn</a></p><h3>新增与优化</h3><p>告别因配置疏忽导致的“无限期”排产与卡顿渲染！<br/>我们深知，一个因产能配置不当而产生的超长周期任务，会拖慢整个排产计算，更会导致甘特图渲染缓慢、操作卡顿。现在，系统会主动为任务时长和整体计划跨度设置“安全围栏”。一旦检测到异常，将立刻暂停并高亮提示具体问题订单与原因（如“产能配置过低”），指导您快速调整。这确保了每次排产计算高效、结果可靠，让您专注于计划本身，无需担忧系统性能。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047605170" alt="图片" title="图片"/></p><h3>二、JVS物联网应用平台</h3><p>当前版本：v2.4.X<br/>更新时间：2026.2.11<br/>在线demo：<a href="https://link.segmentfault.com/?enc=dIFOsYQdHF696mpt4nZv7g%3D%3D.DFBdr%2BZPXCOG6DzTCEE%2FgECG4lzGxNsBWvUdrb3G4%2F4%3D" rel="nofollow" target="_blank">http://iot.bctools.cn</a></p><h3>新增与优化</h3><p>1、本次更新在「设备详情页」中新增了数采设备关系图。该功能通过可视化血缘拓扑，清晰展示当前设备与上层采集器、通讯协议及下属点位之间的完整连接关系与数据流向。双击图中任意节点图标，即可在右侧展开查看该节点的详细配置信息，实现全局拓扑与细节配置的无缝切换。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047605171" alt="图片" title="图片" loading="lazy"/><br/>2、新增首页个性化配置功能，可以打造完全属于自己的专属首页了！支持自由拖拽多种图表组件与地图组件，灵活组装最核心的业务信息视图，让关键数据一目了然。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047605172" alt="图片" title="图片" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047605173" alt="图片" title="图片" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047605174" alt="图片" title="图片" loading="lazy"/><br/>3、新增「设备命令日志」功能，让每一次设备交互都有迹可循。可以在设备详情页中，实时查看所有命令的下发状态、执行耗时与具体错误信息，实现操作全程可追溯，便于快速定界设备端或平台端问题。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047605175" alt="图片" title="图片" loading="lazy"/><br/>4、在设备详情页中，针对每个属性（如“温度”、“湿度”）新增独立的「属性日志」查询功能。可随时查看任一属性的历史数据，支持以列表或趋势图两种形式展示，并支持自定义查询时间范围（最大跨度7天），便于进行数据回溯与分析。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047605176" alt="图片" title="图片" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047605177" alt="图片" title="图片" loading="lazy"/><br/>5、本次更新，为视频中心接入了全新的可视化规则引擎。可以通过直观的拖拽连线方式，灵活配置由“设备上下线”、“消息通知”等事件触发的自动化工作流，实现监控场景的智能响应与处置。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047605178" alt="图片" title="图片" loading="lazy"/><br/>6、本次更新全面增强了设备的空间管理能力。现在，不仅可以在设备详情页中直接配置与查看精确的地理位置信息（包括地址、经纬度），更可在系统首页通过新增的「设备位置」插件，全局、可视化地掌握所有在线设备的分布状况。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047605179" alt="图片" title="图片" loading="lazy"/><br/>7、在规则配置的可视化流程中，新增 「北向推送」执行节点。可通过该节点，将设备事件或告警数据，以 HTTP/MQTT 协议实时推送至指定的外部系统 URL，并支持自定义请求方法与报文格式，轻松实现与第三方平台的数据集成。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047605180" alt="图片" title="图片" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047605181" alt="图片" title="图片" loading="lazy"/></p><h3>三、JVS规则引擎风控决策</h3><p>当前版本：v2.4.X<br/>更新时间：2026.2.11<br/>在线demo：<a href="https://link.segmentfault.com/?enc=TyPk55PSojn93PUkoqMe%2Bg%3D%3D.HXVSBZxrr8%2Bw0LddkMMxoyguw0wzLF1PjV32uLD4Pwc%3D" rel="nofollow" target="_blank">http://rules.bctools.cn</a></p><h3>新增与优化</h3><p>在决策流编辑器中，于复合变量内使用快捷方式添加节点时，曾会引发配置错误导致流程无法保存。此问题现已修复，可以通过任意快捷方式正常添加节点，配置体验恢复流畅。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047605182" alt="图片" title="图片" loading="lazy"/></p><h3>四、JVS-智能BI数据分析套件</h3><p>当前版本：v2.4.X<br/>更新时间：2026.2.11<br/>在线demo：<a href="https://link.segmentfault.com/?enc=Wh3XQDHdevHxKiykQnkcAw%3D%3D.%2BfFM5V9PbTPjbnNTIJfQ8%2B1mQpJMD2mAjJncVgBvC%2Fs%3D" rel="nofollow" target="_blank">http://bi.bctools.cn</a></p><h3>新增与优化</h3><p>BI修复表格下钻不触发的问题，解决修复后可进行下钻操作。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047605183" alt="图片" title="图片" loading="lazy"/></p><h2>为什么选择JVS？</h2><p>JVS是一个为交付团队提供低成本、高效率、源码可100%交付的数字化解决方案，如下图所示，其中产品包括包含：低代码、物联网、规则引擎、智能BI、逻辑引擎、智能排产（APS）、视频会议、无忧企业文档（在线协同）、无忧企业计划、无忧企业邮筒等，可按照交付团队所需要进行采购。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047605184" alt="图片" title="图片" loading="lazy"/><br/>✅低代码开发套件：页面、流程、逻辑配置化、自动构建业务应用，集成自动化部署工具，形成可持续升级配置的快速开发工具，支持源码扩展接入列表页配置<br/><img width="723" height="627" referrerpolicy="no-referrer" src="/img/bVdmvfs" alt="5dd7e03b5e168b7e22fb5a250d84036e.png" title="5dd7e03b5e168b7e22fb5a250d84036e.png" loading="lazy"/><br/>✅ 物联网：软件化的边缘网关+配置化的物联网平台，与低代码、数据分析、逻辑引擎等联动实现，从数据采集、规则策略、业务联动、数据分析展现全流程配置化，技术生态完备<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047605185" alt="图片" title="图片" loading="lazy"/><br/>✅ 规则引擎：一款处理风控决策的软件系统，侧重于规则判断，主要用于风控决策、规则过滤、行为评分等场景，支持在线的变量加工、界面拖拽、在线测试等多种功能。可以降低开发人员使用复杂代码的难度；降低数据录入工作量；优化功能代码实现，提高开发效率；灵活扩展应用程序功能。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047605186" alt="图片" title="图片" loading="lazy"/><br/>✅ JVS·智能BI：自助式数据分析工具，提供数据清洗、数据转换、数据加工等功能。将枯燥数据转化为可视化，帮助企业快速、精准地掌握运营策略，使用门槛低、数据覆盖能力强、多种数据表达模式和建设成本低的一站式数据分析服务。<br/><img width="723" height="380" referrerpolicy="no-referrer" src="/img/bVdmvfz" alt="51aa1849807cee35a80f092823611b76.png" title="51aa1849807cee35a80f092823611b76.png" loading="lazy"/><br/>✅ 逻辑引擎：逻辑引擎是通过对原子服务能力的可视化编排，同时接入外部应用，以满足数据处理、业务实现、自动化业务的实现，可以设计整个逻辑模块的输入、组装执行过程、生成标准的输出结果。轻松实现业务功能，无需复杂冗长的开发过程。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047605187" alt="图片" title="图片" loading="lazy"/><br/>✅ 无忧·企业文档：有免费开源版和可商用的版本。主要针对企业用户，支持多人在线同步编辑，支持多种文件格式的在线编辑和预览，比如文本文档、表格文档、脑图文档、MarkDown、XMind、脑图、word、Excel、PPT和流程文档等，还支持文件上传、下载、分享、点赞、评论、AI、权限管理、全文检索等等丰富功能。。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047605188" alt="图片" title="图片" loading="lazy"/><br/>✅ JVS·智能排产（APS系统）：聚焦于离散制造行业（如汽车、电子、机械、航空航天等）及流程制造行业（如化工、食品、医药等），通过AI驱动的智能算法，实现生产计划与排程的高效性、准确性、敏捷性，帮助企业提升设备利用率、降低库存成本、缩短交付周期，实现精益生产与数字化转型。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047605189" alt="图片" title="图片" loading="lazy"/><br/>✅ 无忧·企业计划：企业级项目管理工具，将企业从经营目标到个人执行逐级分解监控执行。适合各类团队，包括产品、研发、设计、市场、运营、销售、HR等；主要用于项目管理、任务管理、进度跟踪、过程管理等场景。<br/><img width="723" height="397" referrerpolicy="no-referrer" src="/img/bVdmQ53" alt="13f65b5de68af69aaeda6bcc918e2333.png" title="13f65b5de68af69aaeda6bcc918e2333.png" loading="lazy"/><br/>✅ 无忧·企业邮筒：完全开源的私有化部署邮件客户端、支持多邮件账户、将多个邮件客户端统一为web操作的邮件客户端。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047605190" alt="图片" title="图片" loading="lazy"/><br/>✅ 无忧·视频会议：这是一款专为现代企业提供的高效、稳定、安全的在线会议交流解决方案。系统包括了高清视频会议、即时通讯、屏幕共享、白板展示、实时翻译、会议日程管理等多功能于一体，旨在满足企业日常沟通、协作、培训、决策等多元化企业内部协同交流的需求。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047605191" alt="图片" title="图片" loading="lazy"/></p><h2>技术文档</h2><p>产品文档（操作手册）：<br/>​​<a href="https://link.segmentfault.com/?enc=5YSzllemrfpHVvCA8xn4UQ%3D%3D.3M9m4ysNRSvjEk7x%2FQ%2FCiAVnjoL3AM7uWAMdYFjuJqOa30JhLRxxpQsbvPMuCV1ywQefUfAeDPib%2F%2F%2FJ%2B8IhA%2FI66DoRPThAjSjrFbIF1p8%3D" rel="nofollow" target="_blank">http://doc.bctools.cn/#/knowledge/all/dd37733c43c064ac1c4f1c2...</a>​​<br/>开源仓库：<br/>​​<a href="https://link.segmentfault.com/?enc=3JLYii%2Bwy4qcp1fMw4pSzw%3D%3D.ZAOk93Pv6eHgWVd5aCKR5Q39IvvguvlMai6jZqwc0RC2VLsbKuYIGj7M2mRcsVzH9OOqNk010Xp%2Bdub%2FGTrkAw%3D%3D" rel="nofollow" target="_blank">https://gitee.com/organizations/software-minister/projects</a>​​<br/>商业版和开源版对比：<br/>​​<a href="https://link.segmentfault.com/?enc=9yLlv2mAXAtx0CxZQyQZmQ%3D%3D.7sj0sYCbzVc72%2FbUfNVaOH14DfU4k6RusKf2%2BSTbc9ac1Vle6QJHeQqt6LjBCuMXY21pmjT3shsRKtXQyTWwyQ%3D%3D" rel="nofollow" target="_blank">https://mp.weixin.qq.com/s/FuFHHF1FfnMavSYlyLuxbw</a>​​<br/>企业文档开源版部署视频:<br/>​​<a href="https://www.bilibili.com/video/BV1BN411q79Y" target="_blank">https://www.bilibili.com/video/BV1BN411q79Y</a>​​<br/>官网地址：​​<a href="https://link.segmentfault.com/?enc=pDaC5dFfeTsVP7RW5ozm0w%3D%3D.PA0KcQqCSXUEk9A6pNG7w8DmsE1qn9nQ44ctCjuft9M%3D" rel="nofollow" target="_blank">https://bctools.cn</a>​<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047605192" alt="图片" title="图片" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[分享一些编程助手使用过程中的经验教训与观察思考 Baihai_IDP ]]></title>    <link>https://segmentfault.com/a/1190000047605209</link>    <guid>https://segmentfault.com/a/1190000047605209</guid>    <pubDate>2026-02-11 11:03:21</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <blockquote><strong>编者按：</strong> 文章内容涵盖作者近18个月的深度实践观察：首先，作者指出AI助手在主流语言代码生成、长期任务连贯性方面取得显著突破，但在UI框架抽象层处理上仍显笨拙；其次，他揭示了模型“求快”的默认性格需通过“惯用性”提示词加以约束，并惊叹于Opus 4.5与GPT 5.2在Bug定位上的惊人能力，但也警示，过度依赖AI会导致开发者心智模型保真度快速衰减，进而缩短代码库的“品质半衰期”；最后，作者提出务实建议——从处理繁琐任务入手，使用外部沙箱隔离会话，并接受“亲手打磨代码”将逐渐从职业需求回归为纯粹热爱的现实。</blockquote><p><strong>作者 | kulesh</strong></p><p><strong>编译 | 岳扬</strong></p><p>TL;DR: 如果你是一名软件工程师，无论资历深浅，选一个模型，并把它打造成你最得力的结对编程伙伴。这一理念同样适用于软件工程之外的领域。</p><p>过去约一年半的时间里，我一直在使用 Copilot、Cody 和 Cursor。今年早些时候，Claude Code、Codex 与 Gemini 发布后[1]，我也很快开始尝试。借助这些工具，我不仅与团队协作完成代码编写和问题调试，也为我自己、朋友和家人开发了更多项目。本文简要记录了我在过去约 18 个月中的心得与观察。</p><p>首先，让我明确几个术语定义。</p><h2><strong>01 软件工程（Software Engineering） vs. 编程（Programming）</strong></h2><p>我认同 Titus Winters 对软件工程的定义[2]：软件工程是由 programming（编程）、people（团队协作）和 time（随时间不断演进）这三个要素共同决定的。编程是一个人运用代码解决已知问题的过程；而当我们在编程中引入时间、团队协作和各种权衡取舍时，就变成了软件工程。软件工程的核心始终在于：与团队协作来深入理解问题的本质，编写代码将解决方案落地，排查并修复 Bugs，同时随着问题的变化持续迭代优化方案。</p><p>编程技术经历了数次重大的演变。编程语言从机器码发展到低级语言和高级语言，再到后来的面向对象和函数式编程。编程环境也从打孔卡演进到行编辑器、全屏幕编辑器，最终发展为集成开发环境（IDE）。<strong>在编程发展的每个阶段，那些与问题本质无关的、因技术限制而产生的额外复杂性都被逐步消除，使得编程活动越来越聚焦于其最核心的任务 —— 即“逻辑的组织与构建”。</strong> 这种精炼过程降低了编程的入门门槛，扩大了程序员群体，也让每一代开发者能够解决比上一代更广泛、更复杂的问题。</p><p>如今，这种变革正在再次发生，而且比以往任何一次演进都更加广泛、更加快速¹。我们正身处一场编程领域的“寒武纪大爆发”²。</p><h2><strong>02 智能体（Agents） vs. 编程助手（Assistants）</strong></h2><p>我并不打算在已然繁多的智能体定义[3]中再增添一条。相反，为使本文内容表述清晰，我将对“智能体”（agents）和“编程助手”（assistants）加以区分。Claude Code 和 Codex 是由多个协同工作的智能体组成的编程助手。编程助手和智能体都是围绕核心模型构建的。</p><h2><strong>03 经验与观察</strong></h2><p>1）在过去 12 个月里，编程助手在以下三个维度上取得了显著进步：</p><ul><li>对于模型训练数据集中包含的语言（如 Python、TypeScript、Rust、Go 等），模型生成的代码质量更高。</li><li>编程助手生成的代码更贴合其所工作的代码库，而非仅依赖其预训练数据。</li><li>得益于围绕模型构建的“控制/编排框架”（harness）的创新，编程助手现在能够长时间可靠地处理问题，同时产出连贯一致的输出。</li></ul><p>2）编程助手非常擅长解决已知问题。你不太可能让它们一次性写出高度优化的渲染器或强化学习算法，但就常规业务逻辑而言，它们写得比我这样的普通程序员更快、更好。<strong>当我需要同时兼顾开发速度和代码质量时，它们完胜！</strong></p><p>3）不过，<strong>它们在生成可运行的前端界面和高质量前端代码方面仍有提升空间。</strong> 根据我使用编程智能体开发 Web UI[4] 和 TUI[5] 的经验，它们很难生成既美观又功能完善、且符合惯用写法的用户界面。当前的模型对 Tailwind、Ink、Textual 支持很差，对 Ratatui 表现尚可。目前尚不清楚这是一个采样问题（sampling problem），还是 UI 框架中大量抽象层让模型“卡壳”了 —— 这些抽象层确实也常让我头疼。对于 Web 和移动端 UI，我会先用 Google Stitch[6] 生成设计稿，不过目前 Stitch 尚不支持为 TUI 生成原型。我认为，无论是在模型训练还是控制/编排框架层面，都需要进一步改进，以更好地引导模型生成高质量 UI。</p><p>4）<strong>模型默认的“性格”是尽快解决眼前的问题，以赢得你的称赞。这种倾向导致它们会做出次优的决策。</strong> 例如，我曾发现 Opus 4.5 试图通过让进程“sleep 2 秒”来解决死锁问题。但这种性格可以通过适当引导加以调整。我常用的一个技巧是在提示词中加入“idiomatic”（惯用的）一词 —— 比如“给出一个惯用的解决方案”或“这是解决该问题最惯用的方式吗？”同样，在编写或审查测试时，我会时不时提到“被测函数的预期行为”，这能让模型输出更高质量的测试。如果你查看 Claude Code 的控制/编排框架[7]，会发现他们也用了类似的技巧[8]来约束模型行为。</p><p>5）这些模型（尤其是 Opus 4.5 和 GPT 5.2）在寻找 Bug 这方面表现惊人。<strong>只要指出一个“症状”，它们就能阅读代码并定位出 Bug。</strong> 接着我会让它们解释 Bug 产生的原因[9]，并对照代码检查解释是否正确。截至目前，我还没遇到它们无法识别的 Bug³。它们能发现死锁和资源匮乏问题，但你需要引导它们找到好的修复方案（见上文）。有时，如果我知道某个组件有 Bug，我会先让它们构建一个“心智模型（mental model）”，然后它们就能找出一些非常棘手的 Bug。不过这一方法并非总是有效。例如，Ghostty 中的一个内存泄漏问题[10]，这两个模型（Opus 4.5 和 GPT 5.2）都没能识别出来。我仍在尝试通过搭建更有效的“心智模型”，看它们能否通过静态分析，在修复方案提交之前的代码中发现该 Bug。</p><p>6）<strong>代码质量不足以保证产品品质，但却是维持产品品质的必要条件。</strong> 据我观察，即使有最好的提示词工程支持，主要由编程助手生成的代码库，其产品品质的“半衰期”也更短。因此，在开始使用编码助手后，你必须同时培养一套驾驭、管理和监督助手的扎实技能[11]，以确保代码的质量。对开源编程助手所生成代码的质量进行系统性研究，将会很有启发性。</p><p>7）正如写日记一样，编写软件的过程实际上能让你对所构建的东西形成一个良好的心智模型。我发现这个心智模型在两种场景下很有用：一是决定软件如何演进时，二是在调试问题时（尤其是在故障处理期间）。当编程助手承担了大部分编码工作时，我所持有的心智模型的保真度便会迅速下降。我没有试图对抗这种新常态，而是一直在探索各种方法，将模型作为一种工具，按需查询和构建思维模型。这与亲自构建软件产品不同，但我认为这将是一种新常态。我们需要为此开发新工具，也可能需要像航空行业培训飞行员那样，定期培训软件工程师了解其系统的故障模式。</p><p>8）多年来，我花了几百个小时精心调校我的终端和编辑器[12]，以期达到完美手感。我现在正用这个编辑器撰写本文 —— 它是“专属于我的”编辑器。但我现在花在编辑器里的时间不再像以前那么多了。相反，我成了自己编程助手（Claude Code、Codex 和 OpenCode）的“编辑器”。我花同样多的时间去了解它们，也花同样多的时间教它们新技巧、新技能和新命令。我开发了 Catsyphon[13] 和 Aiobscura[14]，就是为了能回顾我们的交互并从中学习。这份清单中的许多经验，正来自这些复盘。我把这看作一次成长的机会，也是在培养我的结对编程伙伴。</p><p>9）<strong>如果你至今仍未使用过编程助手，或许最好的上手方式就是从让它们帮你处理繁琐重复的任务开始。</strong> 它们擅长理解堆栈跟踪、梳理混乱代码、总结文档、以及针对具体问题查询文档等。它们理应成为你工具包的一部分。</p><p>10）编程助手自带沙箱（sandbox），但这个沙箱往往会妨碍组成编程助手的各种智能体的正常工作。因此我转而使用外部沙箱 —— 一个独立于编程助手之外的沙箱。我现在使用 sandbox-exec 来隔离会话[15]，并关闭了编程助手内部的沙箱功能。这不一定适合所有人，但至少你要知道：你有选择。</p><p>11）亲手编写代码蕴含着独特的乐趣、美感与成就感。你依然可以选择像工匠一样亲手打磨代码。只是别指望这还能是你的职业饭碗。这纯粹应当是你的热爱所在。</p><hr/><p>1 这一演变正在加速，因为分发渠道已经成熟，技术栈的大多数层级如今都由软件构成，并且从业者网络规模庞大、联系紧密。</p><p>2 将此称为软件工程（而非编程）的“寒武纪大爆发”或许听上去有些宏大，但方向上是正确的。最终的定论，且留待对 2026 年的回顾时再下。</p><p>3 此后我遇到了一个反例：Opus 4.5 将系统不稳定的原因归咎于 macOS 虚拟化层，而根本原因其实是连接池耗尽。我最终让它对代码进行二分查找才发现了这个问题；而在那之前，它已经把 vz 替换成了 Qemu :-)</p><p><strong>END</strong></p><p><strong>本期互动内容 🍻</strong></p><p><strong>❓当你把 70% 的编码工作交给AI后，你发现自己最重要的技能变成了什么？</strong></p><p><strong>文中链接</strong></p><p>[1]<a href="https://link.segmentfault.com/?enc=y2hnFWY0FRYOfAiJ41P3LQ%3D%3D.YyCfV1RAi3I7N6qKuuIhwVZ%2FlY96XfcPSuhSbaDUUORnrjXcStKoQ6PpW0Hu2SChMcA93cIeZ9MIcxTaAGmG%2Fg%3D%3D" rel="nofollow" target="_blank">https://github.com/kulesh/dotfiles/tree/main/dev/dev/ai-kata</a></p><p>[2]<a href="https://link.segmentfault.com/?enc=KGdGpMjsxt7m00yrYmCjeg%3D%3D.VRpRU%2F3cZKhqd%2FJNrvCKCAwcBaucvOrmwf0IYD2cHymcm7IfpOP3O4CH5ak3qGYMHkZjpqOI6Mb5bsHGWI1NsdQ2bJMVXRbGCzV8yoqsLmmiqpOapAHQlkaiKXQbD7tM" rel="nofollow" target="_blank">https://www.youtube.com/watch?t=472&amp;v=tISy7EJQPzI&amp;feature=you...</a></p><p>[3]<a href="https://link.segmentfault.com/?enc=Tuq%2BHzFETtiVllHfEYWcLQ%3D%3D.rcRgwebDGK1DVqJ83KeidUGt4cqyqGHcl17w5fUFqWesReeRCzvbOdwYK9Kst65eSrP9vtvG9h4FqoZ%2B6Dj%2B9A%3D%3D" rel="nofollow" target="_blank">https://simonwillison.net/tags/agent-definitions/</a></p><p>[4]<a href="https://link.segmentfault.com/?enc=7l4xJqrUZqhirnizyvgHhQ%3D%3D.4rkMM54s18Ip%2BvOKjAk4UKt3hJ5MExjNlNVTMGrjcZGSgmVCm90%2FgWgTS28oZtkq" rel="nofollow" target="_blank">https://github.com/kulesh/catsyphon</a></p><p>[5]<a href="https://link.segmentfault.com/?enc=MuvBUWSytn9E4RmnHhRbKg%3D%3D.IhDlBFZo1VCkt33pRNa3qB%2FfdS5IiLtox4vBcs99Rv2S9EmJZSnDIV6eAygeWMMg" rel="nofollow" target="_blank">https://github.com/kulesh/aiobscura</a></p><p>[6]<a href="https://link.segmentfault.com/?enc=epeBakzuyvZ4NmjZbe7yNg%3D%3D.HYFIB4%2FU2tZ6%2FJF95pMmek16Br0uKr7I1eP2n5rJc0c%3D" rel="nofollow" target="_blank">https://stitch.withgoogle.com/</a></p><p>[7]<a href="https://link.segmentfault.com/?enc=x5q%2B2ZXsxYPSb%2FiOfDGSFA%3D%3D.aPO6fw1hn0cWTWOWZ8L%2Fg6ja9o12SATQItgBiKK%2FwpU50DgKk55VS4hhDQ5mw1lzpvv0UiajIQBnVz9Pgv%2F2rtXgRPl6vem52wiL4XHb3ZjEhvQQWX6ltFiU7Ju8sbP7" rel="nofollow" target="_blank">https://www.anthropic.com/engineering/effective-harnesses-for...</a></p><p>[8]<a href="https://link.segmentfault.com/?enc=xWwZs%2Bv9jOkYk2Sub9lkBg%3D%3D.AuH1AmrVes%2FgEcYXRyRMUTbR%2Bb%2BPuJY2P%2BbY83oooBmgYO%2BjppB6%2FBQiLxlSDziJ2vPvQ4EjPL9ERFYdQvSgjDq%2FJpjWEoq5S4%2B0ofH6W%2BQyIJXsAUx4G7%2Fszyts3jhp" rel="nofollow" target="_blank">https://medium.com/@outsightai/peeking-under-the-hood-of-clau...</a></p><p>[9]<a href="https://link.segmentfault.com/?enc=CoVXnyGhiQSi46aMOOjmjg%3D%3D.fiCmYVhbT%2F34Q1VHB2KoIXQRVkl3t95AunKyIXd2kvDuvXOcmETA07DEj4PtMqQE" rel="nofollow" target="_blank">https://x.com/kulesh/status/1996764098357276858</a></p><p>[10]<a href="https://link.segmentfault.com/?enc=P5frwx%2FrLgwwY7ewOl%2FtGQ%3D%3D.XnfLT0pm%2FaFqtXbiIMXPMsXwhRURKfrDKjgiDWkKcFqtnLFFzt5sW84hLXuGfIxlOQU55gjfJ9Z%2FO%2B425F%2BxGg%3D%3D" rel="nofollow" target="_blank">https://mitchellh.com/writing/ghostty-memory-leak-fix</a></p><p>[11]<a href="https://link.segmentfault.com/?enc=HpoPpLsa43RsnVsPi24TSA%3D%3D.PmMGjcMKGRAD7372y3KbltOTM3hwFxlSfc5C8A48g3rCuu%2BzwbkuS6bk%2FKS4phTcmqb3zALsqoPxQiGoJDmuxoHlw%2BvhQdYRyS9y6vgr%2B2B4IQCEUAte6cJ61i582AN%2B" rel="nofollow" target="_blank">https://github.com/kulesh/dotfiles/blob/main/claude/.claude/commands/review-changes.md?plain=1</a></p><p>[12]<a href="https://link.segmentfault.com/?enc=IjzU7EiE4Ayd9odnTH2v3Q%3D%3D.sPNZnvYsv7rCsEE9lr6AhRuT%2FInLlMMPGKjG5fUvQ4sPBnDCDpOFuyuGvnqrkH6z" rel="nofollow" target="_blank">https://github.com/kulesh/dotfiles</a></p><p>[13]<a href="https://link.segmentfault.com/?enc=HRBiCZz%2FYEff4NrzUY6CcQ%3D%3D.KAlve1geGn3Vdg8V%2BFyQfIHI60JJheQzJ8LyuC8e%2FVL3yD7Whq5E6C36q08mDVlp" rel="nofollow" target="_blank">https://github.com/kulesh/catsyphon</a></p><p>[14]<a href="https://link.segmentfault.com/?enc=MGH5lyzac%2BmG2i%2BEBbNOoQ%3D%3D.8hrY%2ByTRDGGiCruqXUI4zI0rmvG5mPJ1dwYFksebtOPn46XB0NN3WEnxIbzHzn6f" rel="nofollow" target="_blank">https://github.com/kulesh/aiobscura</a></p><p>[15]<a href="https://link.segmentfault.com/?enc=t5U%2F0lYxXZXW7m7NnXTn%2Fg%3D%3D.mAT8XzbYUdMsMdMVlfHDvU2EkH%2BZMJrgO9CsBTIH%2BJsO5T6XdKD85lUp6SG%2Bnc%2FF" rel="nofollow" target="_blank">https://github.com/kulesh/dotfiles/pull/8/files</a></p><p><strong>原文链接：</strong>  </p><p><a href="https://link.segmentfault.com/?enc=%2B8GN1bxwyCckKtFeikGmoA%3D%3D.3LB06e1GBy%2BFks%2BugBDNhBTtpo0JpgM1HZ%2BLqhH2mKTuhfCBdraf%2FkbtL1y%2B7YflTHpM8457R64pJvt%2FhQ8k4lWjPnL%2FnLHObzQ6LFdfgZX3%2F0xGPZ26owUFyJdAdm%2Fa" rel="nofollow" target="_blank">https://github.com/kulesh/dotfiles/blob/main/dev/dev/docs/programming-evolved.md</a></p>]]></description></item><item>    <title><![CDATA[自建机房vs专业数据中心？ 极云Cloud ]]></title>    <link>https://segmentfault.com/a/1190000047605211</link>    <guid>https://segmentfault.com/a/1190000047605211</guid>    <pubDate>2026-02-11 11:02:39</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>自建机房：像个 “吞金兽” ！买地、盖楼、买机器，前期投入巨大，简直就是现金流杀手！CAPEX拉满！</p><p>数据中心：“轻盈租客” 模式。按月付、年付租金（机柜费+电费），化整为零，轻资产运营。</p><p>自建机房：“自力更生”。停电？自己修。空调坏了？自己修。网络断了？还是自己扛！稳定性全靠自家IT团队的水平，心跳指数略高。</p><p>数据中心：“躺平享受”。7x24小时专业团队保驾护航！双路市电+超大UPS+柴油发电机，空调也是N+1冗余！安全感爆棚，SLA高达99.99%以上！</p><p>自建机房：“计划跟不上变化”。建的时候觉得够用10年，结果业务爆火，一年就塞满了…扩容？再来一轮漫长的建设和采购吧！</p><p>数据中心：“可盐可甜”。业务增长快？马上加租几个机柜！业务调整？到期不续租就行。弹性十足，像云服务一样方便！</p><p>自建机房：保安大叔+门禁卡，水平看公司预算。想做金融级合规？难上加难！</p><p>数据中心：“堡垒级防护”！人脸识别、瞳孔扫描、7x24监控、防尾随门禁…还有一堆像ISO27001这种国际认证，合规性直接拉满！</p><p><img referrerpolicy="no-referrer" src="https://image-static.segmentfault.com/585/684/585684999-698beb01e7130" alt="" title=""/></p><p>选自建：适合有钞能力、业务极其稳定、且对数据物理控制权有极致要求的大佬公司。</p><p>选数据中心：适合绝大多数企业！省钱、省心、省力，能把资源更集中在核心业务上，是数字化转型的明智之举。</p>]]></description></item><item>    <title><![CDATA[纯 CSS 实现无限楼梯动画效果，视觉欺骗也能这么好玩 Silvana ]]></title>    <link>https://segmentfault.com/a/1190000047605215</link>    <guid>https://segmentfault.com/a/1190000047605215</guid>    <pubDate>2026-02-11 11:01:58</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047605217" alt="" title=""/></p><p>亲们好，最近捣鼓 <code>CSS</code> 动画的时候，发现了一个超有意思的小效果 —— 无限楼梯动画。不用一行 <code>JavaScript</code>，只靠 CSS 的 <code>@keyframes</code> 和自定义属性，就能做出视觉上无限延伸的楼梯效果，既简单又治愈。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047605218" alt="" title="" loading="lazy"/></p><p>这个效果的核心其实是利用 CSS 动画的位移和视觉欺骗，配合自定义属性来批量生成楼梯的层级，整体实现起来不难，新手也能跟着做。做好之后放在页面里，不管是当小彩蛋还是练手，都超合适。下面就把完整的代码和详细注释分享出来。</p><h2>完整源码（附详细注释）</h2><h3>HTML 部分</h3><pre><code class="html">&lt;!DOCTYPE html&gt;
&lt;html lang="en"&gt;
&lt;head&gt;
    &lt;meta charset="UTF-8"&gt;
    &lt;!-- 适配移动端，保证动画在手机端正常展示 --&gt;
    &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt;
    &lt;title&gt;无限楼梯CSS动画效果&lt;/title&gt;
    &lt;!-- 引入外部样式文件，分离结构与样式 --&gt;
    &lt;link rel="stylesheet" href="./style.css"&gt;
&lt;/head&gt;
&lt;body&gt;
    &lt;!-- 外层窗口容器：限定动画展示范围，模拟可视化窗口 --&gt;
    &lt;div class="window"&gt;
        &lt;!-- 楼梯容器：承载所有楼梯层级，是动画的核心载体 --&gt;
        &lt;div class="stair"&gt;
            &lt;!-- 10个span分别对应一级楼梯，通过自定义属性--i区分层级 --&gt;
            &lt;span style="--i: 1;"&gt;&lt;/span&gt;
            &lt;span style="--i: 2;"&gt;&lt;/span&gt;
            &lt;span style="--i: 3;"&gt;&lt;/span&gt;
            &lt;span style="--i: 4;"&gt;&lt;/span&gt;
            &lt;span style="--i: 5;"&gt;&lt;/span&gt;
            &lt;span style="--i: 6;"&gt;&lt;/span&gt;
            &lt;span style="--i: 7"&gt;&lt;/span&gt;
            &lt;span style="--i: 8;"&gt;&lt;/span&gt;
            &lt;span style="--i: 9;"&gt;&lt;/span&gt;
            &lt;span style="--i: 10;"&gt;&lt;/span&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/body&gt;
&lt;/html&gt;</code></pre><h3>CSS 部分</h3><pre><code class="css">/* 全局样式重置：清除浏览器默认边距/内边距，统一盒模型 */
*{
  margin: 0;
  padding: 0;
  box-sizing: border-box;
}

/* 页面主体样式：让窗口居中展示，设置背景色营造整体视觉氛围 */
body {
  display: flex;
  justify-content: center;
  align-items: center;
  min-height: 100vh; /* 让body铺满整个视口高度 */
  background: #114b64; /* 主色调，与楼梯颜色呼应 */
}

/* 窗口容器：模拟圆润的展示窗口，限定动画可视范围 */
.window {
  position: relative; /* 为内部绝对定位的元素提供参考 */
  width: 340px;
  height: 480px;
  background: #fff; /* 窗口背景为白色，突出楼梯主体 */
  border-radius: 170px; /* 大圆角营造圆润的窗口质感 */
  border: 4px solid #114b64; /* 外边框与主色调一致，增加层次感 */
  box-shadow: 0 0 0 12px #fff; /* 外层白色阴影，强化窗口轮廓 */
  overflow: hidden; /* 隐藏超出窗口的内容，实现视觉截断，打造无限感 */
}

/* 窗口装饰红点：模拟指示灯，增加动画生动感 */
.window::before{
  content:""; /* 伪元素必须设置content属性 */
  position: absolute;
  top: 190px;
  left: calc(50% + 45px); /* 精准定位，居中偏右 */
  width: 30px;
  height: 30px;
  border-radius: 50%; /* 设置为圆形 */
  background: #f44336; /* 红色醒目，提升视觉亮点 */
  /* 红点弹跳动画：ease-in-out让弹跳更自然，infinite循环播放 */
  animation: bounce 1s ease-in-out infinite;
}

/* 定义红点的弹跳动画关键帧 */
@keyframes bounce{
  0%,100%{ /* 动画起始/结束状态：轻微上移 */
    transform: translateY(-1px);
  }
  50%{ /* 动画中间状态：向下弹跳，形成起伏效果 */
    transform: translateY(-40px);
  }
}

/* 楼梯容器：承载所有楼梯层级，负责整体位移动画 */
.window .stair {
  position: absolute;
  width: 100%;
  right: calc(-100% + 0px); /* 初始位置偏右，为位移动画预留空间 */
  top: 100px; /* 垂直定位，让楼梯从窗口上方开始展示 */
  /* 楼梯整体位移动画：linear匀速播放，infinite循环实现“无限”效果 */
  animation: stairs 1s linear infinite;
}

/* 定义楼梯容器的位移动画：核心的无限楼梯视觉效果 */
@keyframes stairs {
  0% { /* 动画起始状态：无位移 */
    transform:  translateX(0) translateY(0);
  }
  100% { /* 动画结束状态：向右+向上位移，模拟楼梯向上延伸 */
    transform: translateX(40px) translateY(-40px);
  }
}

/* 单个楼梯层级样式：通过自定义属性--i控制位置，形成阶梯排列 */
.window .stair span {
  position: absolute;
  /* 垂直位置：每个楼梯层级间隔40px，--i为1~10，实现垂直分层 */
  top: calc(var(--i ) * 40px);
  /* 水平位置：与垂直方向对应，形成斜向楼梯的视觉效果 */
  right: calc(var(--i ) * 40px);
  width: 100%;
  min-height: 40px; /* 楼梯的高度，保证层级明显 */
  background: #114b64; /* 楼梯颜色与主色调一致，视觉统一 */
  border-bottom: 4px solid #fff; /* 白色底边，区分每个楼梯层级 */
  border-top-left-radius: 6px; /* 左上角圆角，让楼梯边角更柔和 */
}</code></pre><p>是不是超简单？整个效果的关键就在于.stair的位移动画，配合每个 span 通过--i自定义属性的位置计算，再加上overflow: hidden的视觉截断，就营造出了 “无限楼梯” 的效果。</p><p>大家可以试着修改一下颜色、动画时长或者楼梯的高度，看看能调出什么不一样的效果～如果有其他好玩的 CSS 小动画想法，也欢迎在评论区聊聊。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047605219" alt="" title="" loading="lazy"/></p><p>本文由<a href="https://link.segmentfault.com/?enc=QcOs7V%2Fx%2Bw%2FEeioGIleh5w%3D%3D.%2Fk0AnfpMlP%2Fe37SOaPVmw1Fg2u6RDrPkpz20CAWF17I%3D" rel="nofollow" target="_blank">mdnice</a>多平台发布</p>]]></description></item><item>    <title><![CDATA[USB总线和协议 良许 ]]></title>    <link>https://segmentfault.com/a/1190000047605231</link>    <guid>https://segmentfault.com/a/1190000047605231</guid>    <pubDate>2026-02-11 11:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>大家好，我是良许</p><p>在嵌入式开发中，USB 可以说是我们最常打交道的接口之一了。</p><p>无论是调试设备、烧录程序，还是开发各种外设，USB 都扮演着至关重要的角色。</p><p>今天我就来和大家深入聊聊 USB 总线和协议的那些事儿。</p><h2>1. USB 总线概述</h2><h3>1.1 USB 的发展历程</h3><p>USB 技术从 1996 年诞生至今，已经经历了多个版本的迭代。</p><p>最初的 USB 1.0 速度只有 1.5Mbps，到 USB 1.1 的 12Mbps，再到 USB 2.0 的 480Mbps，USB 3.0 更是达到了 5Gbps。</p><p>现在最新的 USB 4.0 甚至能达到 40Gbps 的惊人速度。</p><p>在我们嵌入式开发中，USB 2.0 依然是应用最广泛的版本，因为它在速度、成本和功耗之间取得了很好的平衡。</p><h3>1.2 USB 的优势特点</h3><p>USB 之所以能够如此普及，主要得益于它的几个核心优势。</p><p>首先是即插即用（Plug and Play），设备连接后系统会自动识别并加载驱动，这对用户来说非常友好。</p><p>其次是热插拔（Hot Swap），不需要关机就能插拔设备，大大提高了使用便利性。</p><p>第三是供电能力，USB 接口可以为外设提供 5V 电源，最大电流可达 500mA（USB 2.0）或 900mA（USB 3.0），这让很多小功率设备无需额外供电。</p><p>最后是统一的接口标准，一根线缆可以连接各种不同类型的设备。</p><h3>1.3 USB 的拓扑结构</h3><p>USB 采用的是主从架构，也就是 Host-Device 模式。</p><p>在一个 USB 系统中，只能有一个主机（Host），但可以连接多个设备（Device）。</p><p>主机负责管理整个总线，包括设备枚举、数据传输调度等。</p><p>通过 USB Hub（集线器），一个主机最多可以连接 127 个设备。</p><p>这种星型拓扑结构最多支持 5 层 Hub 级联，但实际应用中很少会用到这么深的层级。</p><h2>2. USB 硬件接口</h2><h3>2.1 USB 接口类型</h3><p>USB 接口经历了多次演进，我们常见的有 Type-A、Type-B、Mini USB、Micro USB 以及最新的 Type-C。</p><p>Type-A 是最常见的标准 USB 接口，通常用于主机端。</p><p>Type-B 接口则多用于打印机等外设。</p><p>Mini USB 和 Micro USB 曾经广泛应用于手机和小型设备，现在逐渐被 Type-C 取代。</p><p>Type-C 接口最大的特点是正反可插，并且支持更高的功率传输和数据速率。</p><h3>2.2 USB 引脚定义</h3><p>以 USB 2.0 的标准 A 型接口为例，它有 4 个引脚，从外到内分别是 VCC（+5V 电源）、D-（数据负）、D+（数据正）、GND（地）。<br/>其中 D+ 和 D-是一对差分信号线，用于数据传输。</p><p>USB 采用差分信号的好处是抗干扰能力强，能够实现较长距离的可靠传输。</p><p>在实际 PCB 设计中，我们需要特别注意 D+ 和 D-的走线要等长，并且要做差分对处理，阻抗控制在 90 欧姆左右。</p><h3>2.3 USB 电气特性</h3><p>USB 2.0 定义了三种速度模式：低速（Low Speed）1.5Mbps、全速（Full Speed）12Mbps 和高速（High Speed）480Mbps。</p><p>不同速度模式下，电气特性也有所不同。</p><p>低速和全速模式使用 3.3V 的信号电平，而高速模式使用 400mV 的差分电压。</p><p>在设备端，我们可以通过在 D+ 或 D-上串联一个 1.5K 欧姆的上拉电阻来标识设备的速度类型。</p><p>全速和高速设备在 D+ 上拉，低速设备在 D-上拉。</p><h2>3. USB 协议架构</h2><h3>3.1 USB 协议分层</h3><p>USB 协议采用分层设计，从下到上分为物理层、协议层、功能层和应用层。</p><p>物理层负责电气信号的传输，包括编码、解码、位同步等。</p><p>协议层处理数据包的组装和解析，包括令牌包、数据包、握手包等。</p><p>功能层实现具体的 USB 功能，比如端点管理、数据缓冲等。</p><p>应用层则是具体的设备功能实现，比如 USB 鼠标、键盘、U 盘等。</p><h3>3.2 USB 传输类型</h3><p>USB 定义了四种传输类型，分别适用于不同的应用场景。</p><p>控制传输用于设备配置和状态查询，所有 USB 设备都必须支持控制传输。</p><p>中断传输用于少量、实时性要求高的数据传输，比如鼠标、键盘。</p><p>批量传输用于大量数据的可靠传输，但不保证实时性，U 盘就是典型应用。</p><p>同步传输用于音视频等对实时性要求高但可以容忍少量错误的场景。</p><h3>3.3 USB 数据包结构</h3><p>USB 通信的基本单位是包。</p><p>一个完整的 USB 传输由多个包组成，包括令牌包、数据包和握手包。</p><p>令牌包由主机发出，用于指示传输的方向和目标端点。</p><p>数据包携带实际要传输的数据。</p><p>握手包用于确认传输状态，比如 ACK 表示成功接收，NAK 表示设备暂时无法处理，STALL 表示端点出错。</p><p>每个包都包含同步字段、PID（包标识符）、数据字段和 CRC 校验。</p><h2>4. USB 设备枚举过程</h2><h3>4.1 设备连接检测</h3><p>当一个 USB 设备插入主机时，主机会通过检测 D+ 或 D-上的电平变化来发现新设备。</p><p>前面提到的 1.5K 上拉电阻就是关键，它会将 D+ 或 D-拉高，主机检测到这个变化后就知道有新设备连接了。</p><p>随后主机会等待至少 100ms，让设备的电源稳定下来，这个过程叫做去抖动。</p><h3>4.2 设备复位和地址分配</h3><p>检测到新设备后，主机会发送复位信号，持续至少 10ms。</p><p>复位后，设备进入默认状态，使用地址 0 进行通信。</p><p>接下来主机会通过控制传输读取设备描述符，了解设备的基本信息，比如厂商 ID、产品 ID、设备类型等。</p><p>然后主机会给设备分配一个唯一的地址（1-127 之间），设备收到地址后就不再使用地址 0 了。</p><h3>4.3 配置和驱动加载</h3><p>获取设备地址后，主机会继续读取配置描述符、接口描述符和端点描述符，全面了解设备的功能和需求。</p><p>根据这些信息，操作系统会加载相应的驱动程序。</p><p>最后主机发送 SET\_CONFIGURATION 命令，设备进入配置状态，开始正常工作。</p><p>整个枚举过程通常在几秒内完成，这就是我们插入 U 盘后很快就能使用的原因。</p><h2>5. USB 端点和管道</h2><h3>5.1 端点的概念</h3><p>端点是 USB 设备中数据传输的终点，可以理解为设备内部的一个数据缓冲区。</p><p>每个端点都有一个编号（0-15）和方向（IN 或 OUT）。</p><p>IN 端点表示数据从设备发送到主机，OUT 端点表示数据从主机发送到设备。</p><p>端点 0 比较特殊，它是双向的，专门用于控制传输。</p><p>一个 USB 设备最多可以有 32 个端点（16 个 IN + 16 个 OUT），但实际应用中很少用这么多。</p><h3>5.2 管道的建立</h3><p>管道（Pipe）是主机和设备端点之间的逻辑连接。</p><p>当主机完成设备枚举后，就会根据端点描述符建立相应的管道。</p><p>管道分为流管道（Stream Pipe）和消息管道（Message Pipe）。</p><p>流管道用于批量、中断和同步传输，数据没有特定的结构。</p><p>消息管道用于控制传输，数据有明确的请求-响应结构。</p><h3>5.3 端点配置示例</h3><p>在 STM32 的 HAL 库中，配置 USB 端点的代码大致如下：</p><pre><code>// 打开并配置端点
HAL_StatusTypeDef HAL_PCD_EP_Open(PCD_HandleTypeDef *hpcd, 
                                   uint8_t ep_addr, 
                                   uint16_t ep_mps, 
                                   uint8_t ep_type)
{
    HAL_StatusTypeDef ret = HAL_OK;
    PCD_EPTypeDef *ep;
    
    if ((ep_addr &amp; 0x80U) == 0x80U) {
        ep = &amp;hpcd-&gt;IN_ep[ep_addr &amp; EP_ADDR_MSK];
        ep-&gt;is_in = 1U;
    } else {
        ep = &amp;hpcd-&gt;OUT_ep[ep_addr &amp; EP_ADDR_MSK];
        ep-&gt;is_in = 0U;
    }
    
    ep-&gt;num = ep_addr &amp; EP_ADDR_MSK;
    ep-&gt;maxpacket = ep_mps;
    ep-&gt;type = ep_type;
    
    // 配置硬件寄存器
    // ...
    
    return ret;
}
​
// 端点数据发送
HAL_StatusTypeDef HAL_PCD_EP_Transmit(PCD_HandleTypeDef *hpcd, 
                                       uint8_t ep_addr, 
                                       uint8_t *pBuf, 
                                       uint32_t len)
{
    PCD_EPTypeDef *ep;
    
    ep = &amp;hpcd-&gt;IN_ep[ep_addr &amp; EP_ADDR_MSK];
    ep-&gt;xfer_buff = pBuf;
    ep-&gt;xfer_len = len;
    ep-&gt;xfer_count = 0U;
    
    // 启动传输
    // ...
    
    return HAL_OK;
}</code></pre><h2>6. USB 描述符详解</h2><h3>6.1 设备描述符</h3><p>设备描述符是 USB 设备的"身份证"，包含了设备的基本信息。</p><p>它的长度固定为 18 字节，包括 USB 版本号、设备类代码、厂商 ID（VID）、产品 ID（PID）、设备版本号等。</p><p>主机通过读取设备描述符来识别设备类型并加载相应驱动。</p><p>在嵌入式开发中，我们需要根据实际设备来定义这个描述符。</p><pre><code>// USB设备描述符示例
const uint8_t USBD_DeviceDesc[USB_LEN_DEV_DESC] = {
    0x12,                       // bLength: 描述符长度
    USB_DESC_TYPE_DEVICE,       // bDescriptorType: 设备描述符类型
    0x00, 0x02,                 // bcdUSB: USB 2.0
    0x00,                       // bDeviceClass: 在接口描述符中定义
    0x00,                       // bDeviceSubClass
    0x00,                       // bDeviceProtocol
    USB_MAX_EP0_SIZE,           // bMaxPacketSize: 端点0最大包大小
    LOBYTE(USBD_VID),           // idVendor: 厂商ID低字节
    HIBYTE(USBD_VID),           // idVendor: 厂商ID高字节
    LOBYTE(USBD_PID),           // idProduct: 产品ID低字节
    HIBYTE(USBD_PID),           // idProduct: 产品ID高字节
    0x00, 0x02,                 // bcdDevice: 设备版本号
    USBD_IDX_MFC_STR,           // iManufacturer: 厂商字符串索引
    USBD_IDX_PRODUCT_STR,       // iProduct: 产品字符串索引
    USBD_IDX_SERIAL_STR,        // iSerialNumber: 序列号字符串索引
    USBD_MAX_NUM_CONFIGURATION  // bNumConfigurations: 配置数量
};</code></pre><h3>6.2 配置描述符</h3><p>配置描述符定义了设备的工作配置，一个设备可以有多个配置，但同一时间只能使用一个。</p><p>配置描述符本身只有 9 字节，但它后面会跟着接口描述符和端点描述符，形成一个描述符集合。</p><p>配置描述符中包含了接口数量、配置值、供电方式（自供电或总线供电）、最大功耗等信息。</p><h3>6.3 接口和端点描述符</h3><p>接口描述符定义了设备的功能接口，一个配置可以包含多个接口。</p><p>比如一个 USB 复合设备可能同时包含 HID 接口和 CDC 接口。</p><p>接口描述符指定了接口类代码、子类代码和协议代码，这些信息帮助主机识别接口类型。</p><p>端点描述符则描述了每个端点的属性，包括端点地址、传输类型、最大包大小和轮询间隔等。</p><p>中断传输和同步传输需要指定轮询间隔，表示主机多久查询一次端点。</p><h2>7. USB 类驱动</h2><h3>7.1 HID 类</h3><p>HID 是最常见的 USB 设备类之一，包括鼠标、键盘、游戏手柄等。</p><p>HID 类的优势是操作系统都内置了 HID 驱动，无需安装额外驱动就能使用。</p><p>HID 设备通过报告来传输数据，报告格式由报告描述符定义。</p><p>在嵌入式开发中，我们经常用 HID 类来实现自定义的数据传输，因为它简单方便。</p><h3>7.2 CDC 类</h3><p>CDC 主要用于串口通信。USB 转串口模块就是典型的 CDC 设备。</p><p>CDC 类使用两个接口：一个通信接口用于控制，一个数据接口用于数据传输。</p><p>通过 CDC 类，我们可以在 PC 上虚拟出一个 COM 口，就像使用传统串口一样方便。</p><p>这在调试嵌入式系统时非常有用。</p><h3>7.3 MSC 类</h3><p>MSC 用于 U 盘、移动硬盘等存储设备。</p><p>MSC 类基于 SCSI 协议，支持读写扇区、查询容量等操作。</p><p>实现 MSC 类设备需要提供底层的存储介质访问接口，比如 Flash、SD 卡等。</p><p>在 STM32 中，我们可以使用内部 Flash 或外部 SPI Flash 来实现一个虚拟 U 盘。</p><pre><code>// MSC类读扇区函数示例
int8_t STORAGE_Read(uint8_t lun, uint8_t *buf, 
                    uint32_t blk_addr, uint16_t blk_len)
{
    // 计算实际地址
    uint32_t addr = blk_addr * STORAGE_BLK_SIZ;
    
    // 从Flash读取数据
    for (uint16_t i = 0; i &lt; blk_len; i++) {
        // 读取一个扇区
        memcpy(buf, (uint8_t*)(FLASH_BASE_ADDR + addr), 
               STORAGE_BLK_SIZ);
        buf += STORAGE_BLK_SIZ;
        addr += STORAGE_BLK_SIZ;
    }
    
    return 0;
}
​
// MSC类写扇区函数示例
int8_t STORAGE_Write(uint8_t lun, uint8_t *buf, 
                     uint32_t blk_addr, uint16_t blk_len)
{
    uint32_t addr = blk_addr * STORAGE_BLK_SIZ;
    
    // 解锁Flash
    HAL_FLASH_Unlock();
    
    for (uint16_t i = 0; i &lt; blk_len; i++) {
        // 擦除扇区
        FLASH_EraseSector(addr);
        
        // 写入数据
        for (uint32_t j = 0; j &lt; STORAGE_BLK_SIZ; j += 4) {
            HAL_FLASH_Program(FLASH_TYPEPROGRAM_WORD, 
                            addr + j, 
                            *(uint32_t*)(buf + j));
        }
        
        buf += STORAGE_BLK_SIZ;
        addr += STORAGE_BLK_SIZ;
    }
    
    // 锁定Flash
    HAL_FLASH_Lock();
    
    return 0;
}</code></pre><h2>8. USB OTG 技术</h2><h3>8.1 OTG 的概念</h3><p>OTG 是 USB 2.0 引入的一项技术，允许设备在主机和从机之间动态切换。</p><p>传统 USB 只能是主机连接设备，而 OTG 使得两个设备可以直接连接，并协商谁当主机。</p><p>比如手机既可以作为设备连接到电脑，也可以作为主机连接 U 盘或键盘。</p><p>OTG 设备通过 ID 引脚来识别角色，ID 引脚接地的一方作为主机。</p><h3>8.2 HNP 和 SRP 协议</h3><p>OTG 定义了两个重要协议：HNP（Host Negotiation Protocol，主机协商协议）和 SRP（Session Request Protocol，会话请求协议）。</p><p>HNP 允许两个 OTG 设备在连接后交换主机角色，比如手机给相机传完照片后，相机可以变成主机来控制手机。</p><p>SRP 允许从设备请求主机启动会话，这在省电模式下很有用。</p><h3>8.3 OTG 在嵌入式中的应用</h3><p>在嵌入式系统中，OTG 功能非常实用。</p><p>比如一个手持设备，既需要连接 PC 进行数据传输和充电，又需要连接 U 盘读取文件。</p><p>使用 OTG 技术就能很好地满足这种需求。</p><p>STM32 的许多型号都支持 USB OTG，我们在设计产品时可以充分利用这个特性，提升产品的灵活性和用户体验。</p><h2>9. USB 调试技巧</h2><h3>9.1 硬件调试</h3><p>USB 硬件调试首先要检查电路连接是否正确，特别是 D+ 和 D-的走线。</p><p>使用示波器可以观察 USB 信号的波形，检查是否有过冲、振铃等问题。</p><p>如果设备无法被主机识别，可以测量上拉电阻是否正常，电源电压是否稳定。</p><p>另外要注意 ESD 防护，USB 接口容易受到静电冲击，建议加装 TVS 管。</p><h3>9.2 协议分析</h3><p>软件调试方面，USB 协议分析仪是必不可少的工具。</p><p>通过抓取 USB 通信数据包，我们可以清楚地看到枚举过程、描述符内容、数据传输细节等。</p><p>常用的 USB 协议分析软件有 Wireshark、Ellisys、Beagle 等。</p><p>对于简单的调试，Windows 自带的 USBView 工具也很有用，可以查看设备描述符和当前状态。</p><h3>9.3 常见问题排查</h3><p>在实际开发中，经常遇到的问题包括设备无法枚举、数据传输错误、速度不达标等。</p><p>设备无法枚举通常是描述符配置错误或硬件连接问题。</p><p>数据传输错误可能是端点配置不对或缓冲区溢出。</p><p>速度不达标则需要检查时钟配置和 DMA 设置。</p><p>建议在开发初期就建立完善的日志系统，记录 USB 事件和错误信息，这对问题定位非常有帮助。</p><h2>10. 总结</h2><p>USB 技术虽然看起来复杂，但只要掌握了基本原理和协议结构，在实际应用中就能游刃有余。</p><p>作为嵌入式工程师，我们不仅要会用 USB，更要深入理解它的工作机制。</p><p>从硬件接口到协议栈，从设备枚举到数据传输，每个环节都值得我们仔细研究。</p><p>希望通过这篇文章，能帮助大家建立起对 USB 技术的系统认识，在今后的项目开发中少走弯路。</p><p>USB 技术还在不断发展，Type-C 和 USB PD 等新技术也值得我们持续关注。<br/>只有不断学习，才能在技术的浪潮中保持竞争力。<br/><strong>更多编程学习资源</strong></p><ul><li><a href="https://link.segmentfault.com/?enc=bmmR7dVsu36%2FOGmYV1lwsw%3D%3D.nxoG4hbyh3FHGWr5zFjNNZGQVvh%2FzO%2BXqbCuN5dNhAQqdFE13425cb95sQsWg0rkL3ArryykTQfN2964wERUjw%3D%3D" rel="nofollow" target="_blank">C 语言零基础入门电子书-2026 最新版</a></li><li><a href="https://link.segmentfault.com/?enc=MePQBsHV7Wji%2FMq75fQSxg%3D%3D.iEhI3Koqms%2BvFYtUSdBpAEvbTZv5QoJSdQcY8kaT3vNYTA5RwDluc4tm2wJeA4WpIGy69909RrX96wcHBoPsNQ%3D%3D" rel="nofollow" target="_blank">STM32 零基础入门电子书-2026 最新版</a></li><li><a href="https://link.segmentfault.com/?enc=qteoMSpW1qWlPmHTww%2FWmQ%3D%3D.AefDH92ikF7Q34eFF5BcrEFF3FCyonN%2BBYoYjlottEDeFFP56v0yeMI%2FxI9t3h%2FgjrBHhcdWL0RtonEKw3gwMrW7%2FwYZgfpjWJnRwGFGY1U%3D" rel="nofollow" target="_blank">FreeRTOS 零基础入门电子书-2026 最新版</a></li><li><a href="https://link.segmentfault.com/?enc=iReMzHFIKiFqEm6EwKXCGQ%3D%3D.gJCUJn303GtWpxxtgCNONvX58ljEeEab8dgkubl2X3vtmW36k1nUG7ByIhavp5IDZY4y%2F0gn%2FpMER0PKn7SQig%3D%3D" rel="nofollow" target="_blank">C++ 零基础入门电子书-2026 最新版</a></li><li><a href="https://link.segmentfault.com/?enc=LYTedS4b9LpWGr%2FdLGNkRw%3D%3D.3nVQ8D%2FTOxUlilkHKD4c0htq7VATA6Iq64F2VE6WtWmnhBIXAoangEem61ADKv6i5N%2FzVO1WZLEv2apO1rqqUg%3D%3D" rel="nofollow" target="_blank">51 单片机零基础入门学习路线</a></li><li><a href="https://link.segmentfault.com/?enc=%2BdMg1Qc34MYcpqXVKjU1cA%3D%3D.Xl7zeLQsk8%2FG35IMb%2FeYJcUEO5lV4RnV2NonUZUhJjNZ66Gu8wdWz0VxxwosRbibaAQhGRjOpALOFdQOfYTpkQ%3D%3D" rel="nofollow" target="_blank">AD 画板零基础入门学习路线</a></li><li><a href="https://link.segmentfault.com/?enc=jHtWGjVvhSOma0AepvOvPQ%3D%3D.lHEvjGJSSnqPH5VHEBACP8y3jMBiQGwa1pORHV7OO0g1ZEeMzykrej%2B2DFd5yf0UyHklhMv7twheHY%2BAK%2FkFgw%3D%3D" rel="nofollow" target="_blank">C 语言零基础入门学习路线</a></li><li><a href="https://link.segmentfault.com/?enc=Xp3i5RZOUi7j4a8rTv47rA%3D%3D.g%2B%2FSo7mGv0NXDDVKCS4cUhEr95mSq8qDa620gLZgPN8uwXs29LntY4tAoardnsByIbxhBqEsCGv%2BkBnIFRVTjw%3D%3D" rel="nofollow" target="_blank">C++ 语言零基础入门学习路线</a></li><li><a href="https://link.segmentfault.com/?enc=EYSt5WoxitB%2BG%2Fy89Ebbaw%3D%3D.pcKx881bDLEljSnH3hTHIFXWYgO7CtNSnnawcwYv289SJ5prRUbJx5zUaFatVy%2BKox%2FB0MfxprWu0NMDPXbFrClJEFvgbsT8nOkGSEKjLtU%3D" rel="nofollow" target="_blank">ESP32 零基础入门学习路线</a></li><li><a href="https://link.segmentfault.com/?enc=vfWra%2B31sf4kd5Mk4oUIAg%3D%3D.UvUjyIGji0Tdfk69UdXfmcbyjpzGw5P3ttPMk1zcEZ8ywhOOweA711r1OO5jtI3mjAdAz7qKFvmqVxcq%2F06bnLsNlzmw2z4ixIJpZTdseL8%3D" rel="nofollow" target="_blank">FreeRTOS 零基础入门学习路线</a></li><li><a href="https://link.segmentfault.com/?enc=g6iIaw1vNis165mYlQ3tCg%3D%3D.%2FSwdhOdlED7CD8IwoBc%2FxFtH81nd8IyKDtt7foavYR4eidDKL3x%2BTpFbMFvZ7wTh6BFZfzfOxWEPLPLOwiYYxkPUusGoMY13vIwJricWLn4%3D" rel="nofollow" target="_blank">Linux 应用开发零基础入门学习路线</a></li><li><a href="https://link.segmentfault.com/?enc=uGkeorPMi%2F89bPKxpJQykQ%3D%3D.3wDTMySSN7nDfSaH%2FRx9%2FKP0nGD0DdkUmdZsX7pr2m62gxTCPt%2Fy656otadEzUMzGD6jDmsnsda2%2FF2STnYQ3LejOEMrphy2UklFx9NoxU8%3D" rel="nofollow" target="_blank">Linux 底层开发零基础入门学习路线</a></li><li><a href="https://link.segmentfault.com/?enc=faJnuZ1yHJOYSjHmzdqtIg%3D%3D.M5auD5KIxBFnz9%2BK0HQ4qRapdWLJS8WOV9jv4LO5jU0IfrMiO5dRbBH6Gd6F%2BWUq%2FYcAwdMzplvO%2F66FAYrbeA%3D%3D" rel="nofollow" target="_blank">LVGL 零基础入门学习路线</a></li><li><a href="https://link.segmentfault.com/?enc=FaishWzBEtHUsnzHPGxOEQ%3D%3D.LtnhYKdZqeK7qIIjqs9j12JGxsxB854kfpzLvfuRWe6LxM5Wwx4yeqJY1jS4rJmMhdMPB63rrX8CebrRc9BbUQ%3D%3D" rel="nofollow" target="_blank">QT 零基础入门学习路线</a></li><li><a href="https://link.segmentfault.com/?enc=2sa71Q4Sb3y7fQDPp2I8IA%3D%3D.PDtCGeJkmUQ98cARCWVYvVxDDON8kSDSoCCvvXZafN39IfwMdEElI%2FVV8BpzJymZeWYs89Bbo%2FMPgSmszBBCi40OV3fRhdSz%2FkuwrdsLl9U%3D" rel="nofollow" target="_blank">STM32 零基础入门学习路线</a></li></ul>]]></description></item><item>    <title><![CDATA[Spark批处理认知——RDD与DataFrame的差异、Shuffle与资源利用 南城 ]]></title>    <link>https://segmentfault.com/a/1190000047604567</link>    <guid>https://segmentfault.com/a/1190000047604567</guid>    <pubDate>2026-02-11 10:06:31</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><strong>写在前面，本人目前处于求职中，如有合适内推岗位，请加：lpshiyue 感谢。</strong></p><blockquote>从函数式编程到声明式编程，Spark批处理的演进是分布式计算范式的一次革命性转变</blockquote><p>在掌握了Hive离线数据仓库的分层建模与方法论后，我们很自然地面临一个性能瓶颈问题：如何大幅提升大规模数据处理的效率？Spark作为Hadoop生态后起之秀，通过内存计算和优化引擎将批处理性能提升了一个数量级。本文将深入解析Spark核心数据抽象RDD与DataFrame的本质差异，Shuffle机制的性能影响，以及资源优化策略，帮助构建高性能的分布式批处理应用。</p><h2>1 Spark的演进逻辑：从函数式到声明式的范式转变</h2><h3>1.1 Spark解决的核心问题</h3><p>Spark诞生于UC Berkeley AMP实验室，旨在解决MapReduce框架在<strong>迭代计算</strong>和<strong>交互式查询</strong>场景下的性能瓶颈。根据实践数据，Spark在内存计算场景下比MapReduce快10-100倍，在磁盘计算场景下也能提升3-10倍性能。</p><p><strong>MapReduce的固有瓶颈</strong>主要包括：</p><ul><li><strong>磁盘I/O密集型</strong>：每个MapReduce任务都需要将中间结果写入HDFS，产生大量磁盘IO</li><li><strong>启动开销大</strong>：每个Task以进程方式运行，启动和调度开销显著</li><li><strong>迭代计算效率低</strong>：机器学习等需要多次迭代的算法效率低下</li></ul><p>Spark通过<strong>内存计算</strong>和<strong>有向无环图</strong>优化，实现了计算性能的质的飞跃。其核心思想是将数据尽可能保留在内存中，避免不必要的磁盘IO，同时通过DAG调度器优化任务执行计划。</p><h3>1.2 Spark技术栈的完整体系</h3><p>Spark发展至今已形成完整的技术栈：</p><ul><li><strong>Spark Core</strong>：提供任务调度、内存管理、故障恢复等核心功能</li><li><strong>Spark SQL</strong>：支持SQL查询和DataFrame API，支持多种数据源</li><li><strong>Spark Streaming</strong>：实时流处理，支持高吞吐、容错的流式数据处理</li><li><strong>MLlib</strong>：机器学习库，提供常见的机器学习算法</li><li><strong>GraphX</strong>：图计算库，支持图并行计算</li></ul><p>这种完整的生态系统使Spark成为<strong>统一的分析引擎</strong>，能够应对批处理、流处理、机器学习、图计算等多种场景。</p><h2>2 RDD：函数式编程的分布式抽象</h2><h3>2.1 RDD的设计哲学与核心特性</h3><p>RDD是Spark最基础的数据抽象，代表一个<strong>不可变、可分区的分布式对象集合</strong>。其核心设计哲学是将数据处理抽象为<strong>转换序列</strong>，通过血缘关系实现容错。</p><p><strong>RDD的五大核心特性</strong>：</p><ul><li><strong>分区列表</strong>：数据被分片为多个分区，分布在不同节点上并行处理</li><li><strong>依赖关系</strong>：记录RDD之间的血缘关系，分为窄依赖和宽依赖</li><li><strong>计算函数</strong>：每个分区都有对应的计算函数，描述如何从父RDD计算得到当前RDD</li><li><strong>分区器</strong>：决定数据如何分片，影响数据分布和并行度</li><li><strong>首选位置</strong>：数据本地性优化，尽可能将计算任务调度到数据所在节点</li></ul><pre><code class="scala">// RDD创建与操作示例
val textFile = sc.textFile("hdfs://...")  // 创建RDD
val wordCounts = textFile.flatMap(line =&gt; line.split(" "))  // 转换操作
                         .map(word =&gt; (word, 1))
                         .reduceByKey(_ + _)  // 宽依赖操作
wordCounts.collect()  // 行动操作触发实际计算</code></pre><p><em>RDD的转换与行动操作</em></p><h3>2.2 RDD的容错机制</h3><p>RDD通过<strong>血缘关系</strong>实现高效的容错机制，无需将数据复制多份：</p><ul><li><strong>窄依赖</strong>：子RDD的每个分区只依赖于父RDD的有限个分区，单个节点故障时只需重新计算丢失分区</li><li><strong>宽依赖</strong>：子RDD的每个分区依赖于父RDD的所有分区，需要跨节点数据重分发</li></ul><p><strong>检查点机制</strong>应对长血缘链：对于迭代次数多的算法（如机器学习），定期将RDD持久化到可靠存储，切断过长血缘链，避免故障时过长的恢复时间。</p><h3>2.3 RDD的适用场景与局限性</h3><p><strong>RDD的优势场景</strong>：</p><ul><li><strong>细粒度控制</strong>：需要精确控制数据分区和计算过程</li><li><strong>非结构化数据</strong>处理：如图数据、文本数据等复杂数据结构</li><li><strong>函数式编程</strong>：偏好使用函数式转换操作处理数据</li><li><strong>自定义算法</strong>：需要实现复杂、自定义的分布式算法</li></ul><p><strong>RDD的局限性</strong>：</p><ul><li><strong>性能优化依赖开发者</strong>：需要手动优化数据分区和持久化策略</li><li><strong>缺乏执行优化</strong>：Spark无法对RDD操作进行执行计划优化</li><li><strong>存储效率低</strong>：Java对象存储开销大，内存占用高</li></ul><h2>3 DataFrame：声明式编程的性能飞跃</h2><h3>3.1 DataFrame的设计理念</h3><p>DataFrame是Spark SQL的核心抽象，本质是<strong>具有Schema的分布式数据集合</strong>。它不再是存储原始Java对象，而是以<strong>列式存储</strong>格式组织数据，为Spark提供了强大的优化空间。</p><p><strong>DataFrame的核心优势</strong>：</p><ul><li><strong>结构化数据表示</strong>：明确的列名和数据类型，Spark可以理解数据结构</li><li><strong>Catalyst优化器</strong>：自动优化执行计划，包括谓词下推、列剪裁等优化</li><li><strong>Tungsten执行引擎</strong>：直接操作二进制数据，避免序列化开销</li><li><strong>多语言统一API</strong>：Scala、Java、Python、R提供一致的编程接口</li></ul><pre><code class="scala">// DataFrame API示例
val df = spark.read.parquet("hdfs://...")  // 读取数据
val result = df.filter($"age" &gt; 18)  // 过滤
               .groupBy("department")
               .agg(avg("salary"), max("age"))
               .orderBy(desc("avg(salary)"))
result.show()  // 触发执行</code></pre><p><em>DataFrame的声明式操作</em></p><h3>3.2 Catalyst优化器的工作原理</h3><p>Catalyst是Spark SQL的核心，负责将<strong>逻辑计划</strong>转换为<strong>物理计划</strong>并优化：</p><p><strong>优化阶段</strong>：</p><ol><li><strong>分析阶段</strong>：解析SQL语句或DataFrame操作，验证语法和语义</li><li><strong>逻辑优化</strong>：应用规则优化逻辑计划，如谓词下推、常量折叠</li><li><strong>物理计划</strong>：将逻辑计划转换为物理操作，如选择连接算法</li><li><strong>代码生成</strong>：生成高效的Java字节码执行查询</li></ol><p><strong>优化规则示例</strong>：</p><ul><li><strong>谓词下推</strong>：将过滤条件尽可能下推到数据源，减少数据读取</li><li><strong>列剪裁</strong>：只读取查询需要的列，减少I/O和数据传输</li><li><strong>常量折叠</strong>：在编译时计算常量表达式，减少运行时计算</li><li><strong>连接重排序</strong>：优化连接顺序，减少中间结果大小</li></ul><h3>3.3 Tungsten执行引擎的性能突破</h3><p>Tungsten是Spark的性能基石，通过<strong>直接操作二进制数据</strong>突破JVM性能限制：</p><p><strong>内存管理优化</strong>：</p><ul><li><strong>堆外内存管理</strong>：避免JVM垃圾回收开销，直接操作系统内存</li><li><strong>缓存友好数据结构</strong>：以CPU缓存友好的方式布局数据</li><li><strong>代码生成</strong>：避免虚函数调用，生成优化后的字节码</li></ul><p>实践表明，Tungsten使Spark在TPC-DS基准测试中性能提升5-20倍，内存使用减少50%以上。</p><h2>4 RDD与DataFrame的深度对比</h2><h3>4.1 编程模型差异</h3><p><strong>RDD的函数式编程模型</strong>：</p><pre><code class="scala">// 类型安全的RDD操作
case class Person(name: String, age: Int, salary: Double)
val peopleRDD: RDD[Person] = sc.textFile("people.txt")
                              .map(line =&gt; {
                                val parts = line.split(",")
                                Person(parts(0), parts(1).toInt, parts(2).toDouble)
                              })
val result = peopleRDD.filter(_.age &gt; 30)
                      .map(p =&gt; (p.department, p.salary))
                      .reduceByKey(_ + _)</code></pre><p><em>RDD支持编译时类型检查，但需要手动优化</em></p><p><strong>DataFrame的声明式编程模型</strong>：</p><pre><code class="scala">val peopleDF = spark.read.option("header", "true").csv("people.csv")
val result = peopleDF.filter("age &gt; 30")
                     .groupBy("department")
                     .agg(sum("salary").alias("total_salary"))
                     .orderBy(desc("total_salary"))</code></pre><p><em>DataFrame自动优化执行计划，但类型检查在运行时进行</em></p><h3>4.2 性能对比分析</h3><p>根据Spark官方基准测试，DataFrame在大多数场景下性能显著优于RDD：</p><table><thead><tr><th><strong>操作类型</strong></th><th><strong>RDD执行时间</strong></th><th><strong>DataFrame执行时间</strong></th><th><strong>性能提升</strong></th></tr></thead><tbody><tr><td><strong>分组聚合</strong></td><td>120秒</td><td>25秒</td><td>4.8倍</td></tr><tr><td><strong>排序</strong></td><td>89秒</td><td>19秒</td><td>4.7倍</td></tr><tr><td><strong>连接</strong></td><td>210秒</td><td>45秒</td><td>4.7倍</td></tr><tr><td><strong>过滤</strong></td><td>35秒</td><td>15秒</td><td>2.3倍</td></tr></tbody></table><p><em>DataFrame性能对比数据（来源：Spark官方基准测试）</em></p><p>性能差异主要源于：</p><ul><li><strong>内存使用优化</strong>：DataFrame的列式存储比RDD的对象存储更紧凑</li><li><strong>执行计划优化</strong>：Catalyst优化器自动应用多种优化规则</li><li><strong>代码生成</strong>：Tungsten生成优化后的字节码，避免解释执行</li></ul><h3>4.3 选择策略：何时使用RDD或DataFrame</h3><p><strong>优先选择DataFrame的场景</strong>：</p><ul><li>处理结构化或半结构化数据</li><li>需要进行复杂的过滤、聚合、连接操作</li><li>追求最佳性能和资源利用率</li><li>使用SQL或类SQL接口进行数据分析</li></ul><p><strong>考虑使用RDD的场景</strong>：</p><ul><li>处理非结构化数据（如图像、文本流）</li><li>需要极细粒度的控制数据分区和计算过程</li><li>实现复杂的自定义算法，难以用DataFrame API表达</li><li>需要编译时类型安全</li></ul><p>在实际项目中，推荐<strong>混合使用</strong>策略：主要使用DataFrame获得性能优势，在需要时转换为RDD进行复杂处理。</p><h2>5 Shuffle机制：性能的关键影响因素</h2><h3>5.1 Shuffle的本质与性能影响</h3><p>Shuffle是Spark中最昂贵的操作，涉及<strong>数据重分区</strong>和<strong>跨节点数据传输</strong>。理解Shuffle机制对性能优化至关重要。</p><p><strong>Shuffle操作示例</strong>：</p><pre><code class="scala">// 以下操作都会引起Shuffle
val reduced = rdd.reduceByKey(_ + _)  // 按Key聚合
val grouped = rdd.groupByKey()        // 按Key分组
val joined = rdd1.join(rdd2)          // 连接操作
val sorted = rdd.sortByKey()          // 排序操作</code></pre><p><strong>Shuffle的性能成本</strong>：</p><ul><li><strong>磁盘I/O</strong>：Map任务输出结果需要溢写到磁盘</li><li><strong>网络传输</strong>：Reduce任务需要从多个Map任务拉取数据</li><li><strong>序列化/反序列化</strong>：数据需要在网络中传输，涉及序列化开销</li><li><strong>内存压力</strong>：需要内存缓存数据进行聚合排序</li></ul><h3>5.2 Shuffle的演进与优化</h3><p>Spark Shuffle机制经历了多次演进，性能不断提升：</p><p><strong>Hash Shuffle</strong>（Spark 1.2前默认）：</p><ul><li>每个Map任务为每个Reduce任务创建单独文件</li><li>产生大量小文件，I/O效率低下</li><li>内存占用大，易导致OutOfMemoryError</li></ul><p><strong>Sort Shuffle</strong>（Spark 1.2后默认）：</p><ul><li>每个Map任务将所有输出排序后写入单个文件，并创建索引</li><li>大幅减少文件数量，提高I/O效率</li><li>支持更大的数据量，内存使用更高效</li></ul><p><strong>Tungsten Sort Shuffle</strong>（Spark 1.5+）：</p><ul><li>直接操作二进制数据，避免序列化开销</li><li>更高效的排序算法和内存管理</li><li>支持堆外内存，减少GC压力</li></ul><h3>5.3 Shuffle优化策略</h3><p><strong>配置优化</strong>：</p><pre><code class="python"># Shuffle相关配置优化
spark.conf.set("spark.sql.shuffle.partitions", "200")  # 合理设置分区数
spark.conf.set("spark.shuffle.compress", "true")  # 启用压缩减少网络传输
spark.conf.set("spark.shuffle.spill.compress", "true")  # 溢写压缩
spark.conf.set("spark.reducer.maxSizeInFlight", "96m")  # 调整拉取数据量</code></pre><p><strong>编程优化</strong>：</p><ul><li><strong>避免不必要的Shuffle</strong>：使用广播连接代替Shuffle连接处理小表</li><li><strong>使用树形聚合</strong>：减少中间结果大小，降低网络传输</li><li><strong>预分区</strong>：对需要频繁Shuffle的RDD进行预分区</li><li><strong>选择高效的Shuffle操作</strong>：<code>reduceByKey</code>比<code>groupByKey</code>更高效，因为支持Map端Combiner</li></ul><h2>6 资源管理与调优策略</h2><h3>6.1 Spark资源模型</h3><p>Spark采用<strong>主从架构</strong>，资源分配由集群管理器（YARN、Mesos或Standalone）负责：</p><p><strong>核心组件</strong>：</p><ul><li><strong>Driver</strong>：协调作业执行，维护作业状态，管理任务调度</li><li><strong>Executor</strong>：在工作节点上运行，负责执行具体任务和数据缓存</li></ul><p><strong>资源参数</strong>：</p><pre><code class="python"># 资源分配示例
spark-submit \
  --master yarn \
  --deploy-mode cluster \
  --num-executors 10 \           # Executor数量
  --executor-cores 4 \           # 每个Executor核心数
  --executor-memory 8g \         # 每个Executor内存
  --driver-memory 4g \           # Driver内存
  --conf spark.sql.adaptive.enabled=true  # 启用自适应查询</code></pre><h3>6.2 内存管理优化</h3><p>Spark内存分为多个区域，合理配置对性能至关重要：</p><p><strong>Executor内存结构</strong>：</p><ul><li><strong>执行内存</strong>（60%）：用于计算、Shuffle、排序等操作</li><li><strong>存储内存</strong>（20%）：用于缓存数据和广播变量</li><li><strong>用户内存</strong>（20%）：用户定义的数据结构和内部元数据</li><li><strong>预留内存</strong>（300MB）：系统预留，防止OOM</li></ul><p><strong>内存优化策略</strong>：</p><ul><li><strong>监控内存使用</strong>：通过Spark UI监控各区域内存使用情况</li><li><strong>调整序列化格式</strong>：使用Kryo序列化减少内存占用</li><li><strong>合理缓存</strong>：对频繁使用的数据选择合适的存储级别</li><li><strong>避免数据倾斜</strong>：均匀分布数据，防止单个任务内存不足</li></ul><h3>6.3 数据倾斜处理</h3><p>数据倾斜是Spark作业最常见的性能问题，表现为个别任务处理数据量远大于其他任务：</p><p><strong>倾斜检测</strong>：</p><pre><code class="scala">// 检测Key分布是否均匀
val keyCounts = rdd.map(item =&gt; (item.key, 1))
                   .reduceByKey(_ + _)
                   .collect()
keyCounts.foreach(println)  // 查看各Key数量分布</code></pre><p><strong>倾斜处理策略</strong>：</p><ul><li><strong>两阶段聚合</strong>：对倾斜Key添加随机前缀，先局部聚合再全局聚合</li><li><strong>过滤倾斜Key</strong>：对倾斜Key单独处理，再合并结果</li><li><strong>广播Join</strong>：将小表广播到所有Executor，避免Shuffle</li><li><strong>增加Shuffle分区</strong>：分散倾斜Key到更多分区</li></ul><h3>6.4 动态资源分配与自适应查询</h3><p>Spark提供高级特性实现资源的动态优化：</p><p><strong>动态资源分配</strong>：</p><pre><code class="python"># 启用动态资源分配
spark.conf.set("spark.dynamicAllocation.enabled", "true")
spark.conf.set("spark.dynamicAllocation.minExecutors", "1")
spark.conf.set("spark.dynamicAllocation.maxExecutors", "100")
spark.conf.set("spark.dynamicAllocation.initialExecutors", "3")</code></pre><p><strong>自适应查询优化</strong>（AQE，Spark 3.0+）：</p><ul><li><strong>动态合并Shuffle分区</strong>：根据实际数据量调整分区数</li><li><strong>动态切换Join策略</strong>：在广播Join和Sort Merge Join间动态切换</li><li><strong>动态优化倾斜Join</strong>：自动检测和处理数据倾斜</li></ul><p>AQE在实践中能将查询性能提升30%-50%，特别是在数据分布不均匀的场景下效果显著。</p><h2>7 实战案例：从RDD到DataFrame的性能演进</h2><h3>7.1 日志分析案例对比</h3><p><strong>RDD实现方案</strong>：</p><pre><code class="scala">case class LogEntry(timestamp: String, level: String, message: String)
val logs = sc.textFile("hdfs://logs/app.log")
val parsedLogs = logs.map(line =&gt; {
  val parts = line.split(" ")
  LogEntry(parts(0), parts(1), parts.drop(2).mkString(" "))
})
val errorCounts = parsedLogs.filter(_.level == "ERROR")
                           .map(entry =&gt; (entry.message, 1))
                           .reduceByKey(_ + _)
val topErrors = errorCounts.sortBy(_._2, ascending = false)
                          .take(10)</code></pre><p><strong>DataFrame实现方案</strong>：</p><pre><code class="scala">val logsDF = spark.read.option("delimiter", " ").csv("hdfs://logs/app.log")
val result = logsDF.filter(col("_c1") === "ERROR")
                  .groupBy("_c2")
                  .count()
                  .orderBy(desc("count"))
                  .limit(10)</code></pre><p><strong>性能对比</strong>：在100GB日志数据上测试，DataFrame实现比RDD实现快3.2倍，内存使用减少60%。</p><h3>7.2 优化最佳实践总结</h3><p>基于实际项目经验，Spark性能优化遵循以下原则：</p><p><strong>配置优化清单</strong>：</p><ul><li>根据数据量合理设置Executor数量和资源分配</li><li>启用压缩和序列化优化</li><li>使用AQE等自适应优化特性</li><li>监控GC情况，调整内存比例</li></ul><p><strong>编程最佳实践</strong>：</p><ul><li>优先使用DataFrame API，充分利用Catalyst优化器</li><li>避免收集大量数据到Driver端</li><li>合理使用持久化级别，避免重复计算</li><li>尽早过滤不需要的数据，减少处理量</li></ul><p><strong>集群调优建议</strong>：</p><ul><li>数据本地性：将计算任务调度到数据所在节点</li><li>并行度调整：根据数据量和集群规模调整分区数</li><li>监控告警：建立性能监控体系，及时发现瓶颈</li></ul><h2>总结</h2><p>Spark批处理技术的演进体现了分布式计算从<strong>函数式编程</strong>向<strong>声明式编程</strong>的范式转变。RDD提供了灵活的底层抽象，适合需要精细控制的场景；而DataFrame通过Catalyst优化器和Tungsten执行引擎，为大多数批处理场景提供了更优的性能。</p><p><strong>核心认知要点</strong>：</p><ol><li><strong>理解抽象差异</strong>：RDD提供过程控制，DataFrame提供声明式接口</li><li><strong>掌握Shuffle机制</strong>：识别宽依赖操作，优化数据分布</li><li><strong>合理资源配置</strong>：根据数据特性和集群规模优化资源参数</li><li><strong>应用优化策略</strong>：数据倾斜处理、内存管理、动态资源分配</li></ol><p><strong>未来发展趋势</strong>：</p><ul><li><strong>Spark 3.x增强</strong>：AQE、DPP等自适应优化成为标准</li><li><strong>云原生架构</strong>：容器化部署、弹性伸缩提升资源利用率</li><li><strong>AI集成</strong>：与机器学习框架深度集成，支持更复杂分析</li></ul><p>Spark批处理技术已成为现代数据架构的核心组件，掌握其核心原理和优化策略，对于构建高效、可靠的大数据处理平台至关重要。</p><hr/><p><strong>📚 下篇预告</strong><br/>《Kafka生态深化——Schema与Connect、CDC入湖的链路与一致性挑战》—— 我们将深入探讨：</p><ul><li>📊 <strong>Schema演化</strong>：Avro、Protobuf格式兼容性与版本管理策略</li><li>🔄 <strong>Connect框架</strong>：源连接器、接收器与转换器的配置化数据流水线</li><li>⚡ <strong>CDC入湖</strong>：Debezium捕获变更日志、顺序保证与端到端延迟优化</li><li>🔒 <strong>一致性挑战</strong>：精确一次语义、幂等生产与事务性消息的实现路径</li><li>🏗️ <strong>湖仓一体</strong>：Kafka与数据湖的集成模式与增量处理架构</li></ul><p><strong>点击关注，构建流批一体的实时数据平台！</strong></p><blockquote><p><strong>今日行动建议</strong>：</p><ol><li>评估现有Spark作业，识别可转换为DataFrame API的RDD操作</li><li>分析Shuffle操作，优化分区策略和数据分布</li><li>调整资源配置，启用动态资源分配和自适应查询</li><li>建立性能监控体系，定期检查数据倾斜和内存使用</li><li>测试AQE等新特性，评估性能提升效果</li></ol></blockquote>]]></description></item><item>    <title><![CDATA[麒麟桌面系统【网络图标显示感叹号】 沙鱼 ]]></title>    <link>https://segmentfault.com/a/1190000047604642</link>    <guid>https://segmentfault.com/a/1190000047604642</guid>    <pubDate>2026-02-11 10:05:56</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>【问题描述】</h2><h4>现象：</h4><p>某些机器系统右下角的网络图标显示感叹号（如下图所示），但是网络又是正常使用的，我们该如何处理呢？<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047604647" alt="" title=""/></p><h4>原因分析：</h4><p>麒麟系统有个网络连通检测地址，会去测试<code>/etc/NetworkManager/NetworkManager.conf</code>文件里定义的网址的连通性，不能连通该网址就会有相关的网络异常提示。</p><h2>【解决办法】</h2><h4>方法1：禁用网络连通检测</h4><ol><li><p>编辑<code>/etc/NetworkManager/NetworkManager.conf</code>文件，如下图所示，在<code>[connectivity]</code>下方增加一行<code>enabled=false</code>内容。然后保存并关闭文件。</p><pre><code class="bash">sudo  pluma  /etc/NetworkManager/NetworkManager.conf</code></pre><p>如下图所示：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047604648" alt="file" title="file" loading="lazy"/></p></li><li><p>执行以下命令，重启<code>NetworkManager</code>服务：</p><pre><code class="bash">sudo systemctl restart NetworkManager</code></pre></li><li>查看网络状态是否已经不显示感叹号了？如果还存在，重启系统再看一下。</li></ol><hr/><h4>方法2：禁用网络连通检测</h4><p>网络连接性检测的默认网址 www.cnnic.net.cn 无法访问导致的。为了解决这个问题，将这个网址修改为可以正常访问的网址，例如 www.baidu.com ，或者内网里可以正常访问的网址。</p><h4>操作步骤</h4><ol><li><p>修改配置文件：</p><pre><code class="bash">sudo  pluma  /etc/NetworkManager/NetworkManager.conf</code></pre></li><li>编辑内容：<br/>找到网络连接性检测的相关设置，将网址 <a href="https://link.segmentfault.com/?enc=o5OClESkjmNeIsxnn5F30A%3D%3D.1ZR1XyB%2FIFWyTJ2IDzNYaCpscR5Db1wQxxKfQVM3mvM%3D" rel="nofollow" target="_blank">http://www.cnnic.net.cn</a> 修改为 <a href="https://link.segmentfault.com/?enc=69d1n2j0YPt%2BoFiIVbudbg%3D%3D.CKEZI7c%2FAryJgjPzh1LwSUvmJyBCV9fYTADEbm7T%2FJE%3D" rel="nofollow" target="_blank">http://www.baidu.com</a> ，然后保存并退出编辑，如下图所示：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047604649" alt="file" title="file" loading="lazy"/></li><li><p>重启NetworkManager服务（<code>或者重启操作系统</code>）：</p><pre><code class="bash">$ sudo  systemctl  restart  NetworkManager</code></pre></li></ol><p>本文由<a href="https://link.segmentfault.com/?enc=emWAZRa4i7dcf90ra5x1Sg%3D%3D.toMne8PTj9S8IIDbGvkKAH5fnSx7fY5%2Fob%2FHTIZfMPw%3D" rel="nofollow" target="_blank">mdnice</a>多平台发布</p>]]></description></item><item>    <title><![CDATA[Java烘焙师的2025年总结 Java烘焙师 ]]></title>    <link>https://segmentfault.com/a/1190000047605051</link>    <guid>https://segmentfault.com/a/1190000047605051</guid>    <pubDate>2026-02-11 10:04:58</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>大家好，我是Java烘焙师，近半年重启了技术博客的更新，在春节前做个总结吧。</p><p><strong>关于我</strong>：大厂架构师，有团队管理经验，热爱技术，平时喜欢思考总结。</p><p><strong>写作初衷</strong>：</p><ul><li>功在平时：定期把自己的经验和思考总结下来，能给别人讲清楚，才算真的理解透彻了</li><li>锻炼总结表达能力：除了自身技术要过硬，还得会表达呈现、分清主次，避免出现做了90分、但只能讲出70分的情况</li></ul><p><strong>更新慢的原因</strong>：平时工作忙，只能在业余时间抽空写作，同时为了保证每篇原创文章的质量，会尽可能系统性地梳理文章主题方向，查缺补漏。<br/><strong>出版级品质</strong>：这里得举几个例子来佐证，否则有吹牛的嫌疑</p><ul><li>有几位出版社编辑联系过出书意向，但考虑到写书需要耗费大量时间和精力，暂时没有计划，只想着先把技术博客做好</li><li>在曾经的developerWorks网站发表过2篇文章（有稿费），其中一篇被CSDN转载到首页；这2篇文章目前没有在个人技术博客上重发</li><li>在曾经工作的公司参与过书籍的编写（有图书ISBN编号）</li></ul><h2>2025年统计</h2><p>统计2025年+2026年1月发布的文章（2月7日统计）：</p><ul><li>新增阅读总量，全网超过4.3万</li><li>阅读总量第一的文章，全网超过1.1万：<a href="https://link.segmentfault.com/?enc=mwqyd%2B4wc3HnsSxO9mxxdQ%3D%3D.VI7iMaAGrlqg%2Fc2wKR59M32zNIHNhdzNYEB67eVH5MPwFgGsjHJvGYQOfay%2FEmop" rel="nofollow" target="_blank">架构师必备：实时对账与离线对账</a></li><li>点赞总量第一的文章，全网66次：<a href="https://link.segmentfault.com/?enc=jNsLzZWzx8TcljO9Ek2gFw%3D%3D.mkDxWl1eKcAIcbLzh4JuN%2BE6LR7ucc%2BUlzCwLTBwxTpoP2VYMR8G2xZmMu1GkMMn" rel="nofollow" target="_blank">架构师必备：缓存更新模式总结</a></li><li>评论总量第一的文章：<a href="https://link.segmentfault.com/?enc=zbhwjblGye6eC2RlfBXZRw%3D%3D.Lbo89rY99jdAvfmSMIqbQF2o98IHC%2B0wWPqt9MOihfGrhQ8SVW1pGS9UAszd9JRa" rel="nofollow" target="_blank">架构师必备：限流方案选型（使用篇）</a></li></ul><p>其它文章如下：</p><ul><li><a href="https://link.segmentfault.com/?enc=wDJ2HtCAZreHzoXyRQxnMg%3D%3D.kLwHwshzucU%2FoAiB4M5FslapsqRn%2FxHuii9jCZgJYu%2BZ8QinEjK2J%2BckTB%2F2J1SN" rel="nofollow" target="_blank">架构师必备：灰度方案汇总</a></li><li><a href="https://link.segmentfault.com/?enc=GImaYYQUgUySEyJ4H%2F1bCw%3D%3D.w9kuviCwnx0UmZxAnRZWerW3gHdvh5SiQsLSlvjRbKtxhPQKREIWRgCVLXTS1zzP" rel="nofollow" target="_blank">架构师必备：后端程序员需要了解的数仓知识</a></li><li><a href="https://link.segmentfault.com/?enc=NWfhyWK%2Fu3PchlK4mWOmGA%3D%3D.ayk3JbHFS8jZumbKoqrpz%2BwMw6gffzgTt4vvSMxqWONqis79rJ3BXQYLOYrGZXQI" rel="nofollow" target="_blank">架构师必备：限流方案选型（原理篇）</a></li><li><a href="https://link.segmentfault.com/?enc=zSoP5G0CQ4GgFH%2F37TcpIw%3D%3D.CFsmkKT8gXHquLXdtNs6%2FXpxEVKsRTmIMHEZVXzKidjQudUOXYUkxJhNotK5iNuM" rel="nofollow" target="_blank">架构师必备：业务扩展模式选型</a></li></ul><h2>文章目录</h2><p>累计发布了25篇文章，可以分成以下几类：</p><h3>架构：“架构师必备”系列</h3><ul><li><a href="https://link.segmentfault.com/?enc=IOHQuzocqOWaMth%2FU%2BvPjw%3D%3D.FBzJaKC2W%2Fjv5r06uI06JHqYMwiC7ioqFWIRp2U%2FLTlUgo99vIjkYWoRtMFAzjCT" rel="nofollow" target="_blank">架构师必备：灰度方案汇总</a></li><li><a href="https://link.segmentfault.com/?enc=KZfeK5wa1BnCqBeyw1EE8Q%3D%3D.2UDfmLfF4Cq9Pswzs48m%2FG57fQl%2Fwxk2Akwyr3AJsuOtwvKnDr9pZHbhvVsh9sEV" rel="nofollow" target="_blank">架构师必备：后端程序员需要了解的数仓知识</a></li><li><a href="https://link.segmentfault.com/?enc=ECMXp7j%2BSraKJWKIc%2BjbcQ%3D%3D.I24ZOaVyErvd8FKbUWj2l%2Fls4rXcJN1uKFYKHfw3TaRH%2BhFwrtBl1rvXEcqxl%2BlO" rel="nofollow" target="_blank">架构师必备：限流方案选型（原理篇）</a></li><li><a href="https://link.segmentfault.com/?enc=gMvkG9zvnZio%2F0RWmiOfHg%3D%3D.nsuU%2FKa52AJcuU9GMFkqhB9l5ArRigzwpRd%2Fz18e%2Bm0kX9FHofNc3SBGbeT2M7%2BN" rel="nofollow" target="_blank">架构师必备：限流方案选型（使用篇）</a></li><li><a href="https://link.segmentfault.com/?enc=HrMOXNmke2x70ocjAZzbAw%3D%3D.eS3unIRE5XbGU2mycMfENobcpruWHjYab4MR9xET%2FR%2B39cQVVwzgz1crMO4SjPAg" rel="nofollow" target="_blank">架构师必备：缓存更新模式总结</a></li><li><a href="https://link.segmentfault.com/?enc=4LbUoZjKqJ23Lz%2F0gEvihw%3D%3D.Nutj6SLbwKhRBKpF%2FWYThM0ngSQqr4lSdAlwULBmzPmi34GSPWI8FX1i4cQilROb" rel="nofollow" target="_blank">架构师必备：实时对账与离线对账</a></li><li><a href="https://link.segmentfault.com/?enc=MLKAvQ6xRfDkKxkYJeZa4w%3D%3D.u5nyUiBP192%2Ba1ExMQr8z7tMgvI%2FZwe3ORB4tn7m0lL4VybjfnViec5rs19KoRLb" rel="nofollow" target="_blank">架构师必备：业务扩展模式选型</a></li><li><a href="https://link.segmentfault.com/?enc=xdcmd6%2FAMXBruvTtVMnHGQ%3D%3D.NSAfyQ6DLDDkVrIoy041IXb5aMtBc41D652IGyKVO%2FunjyOLemqTfO66uKsRT14D" rel="nofollow" target="_blank">后端程序员生产力工具合集</a></li><li><a href="https://link.segmentfault.com/?enc=JGZW7BM%2Ff2T4p%2Fppj%2BC%2F7A%3D%3D.9YTw015PeO7dKW7np9eDS8OxDl%2BHUmRRHD4gF6bpEm%2FiUEbwBvr8zjdXLCYziPPs" rel="nofollow" target="_blank">架构师必备：系统容量现状checklist</a></li><li><a href="https://link.segmentfault.com/?enc=%2Bm22%2FNZXFpEChNB%2FkU%2FXwQ%3D%3D.gfLbnl9SAoSoJl%2BX1R%2BZFh%2FkvWf3V1tLDjJxjT2fDaM1aPxPAimuv48Ueu%2BSGp3I" rel="nofollow" target="_blank">架构师必备：HBase行键设计与应用</a></li><li><a href="https://link.segmentfault.com/?enc=ZOCbsIp4d%2FDEYfQ9zrJXaA%3D%3D.BafxzngBO95sCROIbZjVUvqy4XhI3LtbE9P03J2BEBd4jmbUZrF3IOR9XYGMi8Um" rel="nofollow" target="_blank">架构师必备：多维度查询的最佳实践</a></li><li><a href="https://link.segmentfault.com/?enc=33xuqaS1eZSF%2Bd%2BULIkgXA%3D%3D.VRGyIqvEo6fkisde%2FxaO%2FNoBfcUu9lzVKy8iDv7KTMSFjL5F8KW62FkPpBCbQ9sQ" rel="nofollow" target="_blank">架构师必备：Redis的几种集群方案</a></li><li><a href="https://link.segmentfault.com/?enc=%2FhNt50xpYHV7uyuJL92ssQ%3D%3D.sTPnCPFnH6qf9YCgOhbDYf8s9sKRWi7xxRyx4ll2hFTHvsGO52myJeFN8zDavfYg" rel="nofollow" target="_blank">架构师必备：本地缓存原理和应用</a></li><li><a href="https://link.segmentfault.com/?enc=Ib3Vhz5ybdmFL65Dn6rnIQ%3D%3D.2OuJ3J3wQFqTTpilrLZTQmzTuPONnskOrqh%2BluNZeNMa9cl%2BEaXVnNv%2BdfNJQMqa" rel="nofollow" target="_blank">架构师必备：系统性解决幂等问题</a></li><li><a href="https://link.segmentfault.com/?enc=qW4xhie2bQO0RVMQB4ck0w%3D%3D.Jk9uDM4PN8D1FtSJgXe4dFAqoy6rCidHNtq8TdwmS%2B1dB8TLH499dDoFB%2BVnOfMi" rel="nofollow" target="_blank">架构师必备：如何做容量预估和调优</a></li><li><a href="https://link.segmentfault.com/?enc=uS6wG%2Bg3RCFFwt56b8FcGg%3D%3D.vL8K3mWOefbVzC3M1yHONAPCDNcg8CH4ntVgtAxL%2BgOH5j%2FGER5CXGAEQJ9mgAhK" rel="nofollow" target="_blank">架构师必备：巧用Canal实现异步、解耦的架构</a></li><li><a href="https://link.segmentfault.com/?enc=Pd5279gwMf5wl%2Fho%2BU23XQ%3D%3D.1c%2Fp463XfdJU2rvffH904pm5YSZBfShyE4b9zlfy5VvNnJjCLKtuzcfoo3As%2BtRa" rel="nofollow" target="_blank">架构师必备：MySQL主从延迟解决办法</a></li><li><a href="https://link.segmentfault.com/?enc=PSi%2BfmM60fQUYoj5UN8qjA%3D%3D.h4Q2SqPIcgnIdaUl4WJyAz%2Fj1Htm7rzD9VnwiKoycSd4cVGqP9bOj7QQje4BcBWg" rel="nofollow" target="_blank">架构师必备：MySQL主从同步原理和应用</a></li><li><a href="https://link.segmentfault.com/?enc=rUI9k0bBjpYW60oo7YKv4g%3D%3D.wpN071sPH8FXUOTmzLNKWC297Ww0%2FWNNxGRgIsONUbn9nAs0GJ7ih1VBHeHVRW%2BN" rel="nofollow" target="_blank">应用开发中的存储架构进化史——从起步到起飞</a></li></ul><h3>Java</h3><ul><li><a href="https://link.segmentfault.com/?enc=lOlsz%2FJ4w834i%2BhweItYXQ%3D%3D.nLl%2FQEFdQuPhJGa17v3rQ0gPR%2FGE7RQFrw1T0IqwW0BS%2BIta6np07PHTubme%2Fcb%2F" rel="nofollow" target="_blank">Java反射原理和实际用法</a></li><li><a href="https://link.segmentfault.com/?enc=zL3uCvakYvai7%2FLsOcZ2MA%3D%3D.imwOf%2BEOqSrQMtPSUpC0tNQ88iItAF4ZklTvFNmujHY4vJ2RDtacQP6ODibHq%2Fxk" rel="nofollow" target="_blank">Spring cache源码分析</a></li><li><a href="https://link.segmentfault.com/?enc=IxnfFvde7%2BZnonLECOM7SQ%3D%3D.y9c1dUZkaP6xvhLyRCVhmRMwF0uP%2FgUSPlr3uLj7KJUeDe46jvBqJ73Y1R0BTrZD" rel="nofollow" target="_blank">Spring @Async的异常处理</a></li><li><a href="https://link.segmentfault.com/?enc=FaWqSLrqThTJMW1IcdUzIA%3D%3D.o6eH3BfucgcmWty%2BOpkU%2B4xVweiPKGR7o7zOeiSoqVHFRcZnvt2MhWWwaKJtM265" rel="nofollow" target="_blank">Spring Boot应用中的异常处理</a></li><li><a href="https://link.segmentfault.com/?enc=%2FIqMPXNT3gcSw%2FcTj5vFow%3D%3D.z1gUE2kuymWoMk1PI7VBqDeqydaqTr0XznVCjXhckW9muQtbvr2OxDnNR1KBssmB" rel="nofollow" target="_blank">Java子线程中的异常处理（通用）</a></li></ul><h3>树莓派实战</h3><p>side project应用实战，目前只写了一篇，还有很多内容可写。而且不止是树莓派，部署在云端也可以。</p><ul><li><a href="https://link.segmentfault.com/?enc=b8OdYKuoNaSTsslKO8Glrw%3D%3D.C0jXuEp6NrDvRCetCjF9ZpFB3qS1iuCnNpNE7qo88aS3tbW%2FE8qwwjI3yUr%2FTFBs" rel="nofollow" target="_blank">树莓派实战：微信机器人（itchat实现）</a></li></ul><h2>2026展望</h2><p>坚持业余时间创作。<br/>后续除了继续更新已有系列，还会尝试扩充新系列，比如AI应用、有意思的开源项目、踩坑分享、职场感悟等。</p><p>让我们一起做长期主义者，慢慢变强吧！欢迎交流讨论。</p>]]></description></item><item>    <title><![CDATA[在哪可以免费自动续签证书 才高八斗的杯子_dS2Fpp ]]></title>    <link>https://segmentfault.com/a/1190000047605094</link>    <guid>https://segmentfault.com/a/1190000047605094</guid>    <pubDate>2026-02-11 10:04:08</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在当今互联网，为网站部署SSL证书实现HTTPS加密，早已不是“可选项”，而是保护用户数据、提升信任度、甚至影响搜索排名的“标准配置”。然而，传统SSL证书往往伴随着不菲的费用和繁琐的年度手动续签流程，一旦遗忘，网站就可能面临安全警告、访问中断的风险。</p><p>有没有一款解决方案，能同时实现  <strong>“免费”</strong>  与  <strong>“自动续签”</strong> ，真正一劳永逸？答案是肯定的——<strong>JoySSL</strong>正是为此而生的优秀平台。</p><h3>为什么选择JoySSL？</h3><p>JoySSL作为国内可便捷访问的SSL证书服务提供商，其核心优势直击用户痛点：</p><ol><li><strong>真正的免费证书</strong>：提供基于ACME协议的免费SSL证书（通常为DV型），适用于个人网站、博客、测试环境及小微企业，实现零成本启用HTTPS。</li><li><strong>全自动续签机制</strong>：这是JoySSL最大的亮点之一。通过与ACME客户端（如Certbot）或其提供的集成工具配合，可以设置自动化任务，系统会在证书到期前自动完成验证、申请和部署新证书的全过程，彻底解放人力，杜绝因证书过期导致的服务中断。</li><li><strong>泛域名证书支持</strong>：其免费证书计划也支持泛域名（通配符）证书，一张证书即可保护一个主域名及其所有同级子域名，管理和续签更为高效。</li><li><strong>友好的中文界面与支持</strong>：提供清晰的中文操作界面和本土化的技术文档及客服支持，对国内用户非常友好，降低了使用门槛。</li><li><strong>高兼容性与安全性</strong>：颁发的证书受主流浏览器和操作系统信任，采用可靠的加密算法，确保通信安全。</li></ol><p><img width="600" height="323" referrerpolicy="no-referrer" src="/img/bVdclop" alt="" title=""/></p><h3>如何通过JoySSL获取并自动续签证书？</h3><p><strong><a href="https://link.segmentfault.com/?enc=GnhY6%2Bh%2F0If92zkWacYXoQ%3D%3D.n9WSAFrzbfNZsOyeYrzCzUN%2BfTRKZFkku0GdqPL3ngE%2B8Rz866OmwYVn0DKd0rEkyYsE9BeS8CpCSueXnxwGSA%3D%3D" rel="nofollow" target="_blank">第一步：获取免费证书</a></strong></p><ol><li>访问 <strong>JoySSL</strong> 官网，注册时填写注册码<strong>230970</strong> 并登录账户。</li><li>在控制台选择申请免费SSL证书（通常为DV型或免费泛域名型）。</li><li>提交需要证书的域名，选择验证方式（常见的为DNS验证或HTTP文件验证）。</li><li>按照提示完成域名所有权验证。验证通过后，证书即签发，可供下载。</li></ol><p><strong>第二步：部署并配置自动续签（关键步骤）</strong>  <br/>自动续签的核心在于使用ACME客户端。Certbot是最流行和通用的选择。</p><ol><li><strong>安装ACME客户端</strong>：在您的服务器上安装Certbot及其对应Web服务器插件（如Nginx或Apache插件）。</li><li><strong>执行自动申请与部署命令</strong>：使用Certbot的一条命令，即可完成证书的首次获取、服务器配置修改，并自动设置续签任务。</li><li><strong>自动续签已生效</strong>：Certbot会自动在服务器上创建一个定时任务（如cron job），定期检查证书有效期并在到期前自动续签和重新部署。您通常只需运行一次上述命令。</li></ol><p><strong>对于JoySSL平台的特殊优化</strong>：</p><ul><li>部分用户反馈，直接使用Certbot的默认配置可能需指向JoySSL的ACME目录URL。JoySSL官方通常提供详细的集成指南或专用的自动化脚本，请务必参考其最新文档。</li><li>对于不熟悉命令行的用户，JoySSL控制台也可能提供一些自动化的部署脚本或与常见面板（如宝塔）的集成教程。</li></ul><h3>重要注意事项</h3><ul><li><strong>证书类型</strong>：免费证书一般为域名验证型（DV），适用于基础加密需求。如需更高级别的组织验证（OV）或扩展验证（EV）证书，JoySSL也提供付费选项。</li><li><strong>有效期与续签频率</strong>：免费DV证书单次有效期通常为90天。自动续签任务会在此期限内（如到期前30天）自动执行，确保无缝衔接。</li><li><strong>服务器权限</strong>：配置自动续签需要您对部署证书的服务器拥有管理权限。</li><li><strong>防火墙与端口</strong>：确保服务器的80或443端口（用于ACME验证）可从公网访问，以便验证和续签流程顺利进行。</li></ul>]]></description></item><item>    <title><![CDATA[从 LangChain 到 LangGraph 构建可控 Agent 的工程实践 BugShare ]]></title>    <link>https://segmentfault.com/a/1190000047605097</link>    <guid>https://segmentfault.com/a/1190000047605097</guid>    <pubDate>2026-02-11 10:03:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在之前的文章中，我们深入讲解了如何使用 <strong>LangChain + Ollama</strong> 构建本地大模型调用方案。<br/>但是，随着业务需求不断增长，我们发现仅仅调用模型已经远远不够——我们希望构建<strong>具备条件判断、流程控制、工具调用以及状态记忆的智能 Agent</strong>。</p><p>这时候，LangChain 的 <strong><code>create_agent</code></strong> + LangGraph 的 <strong>StateGraph</strong> 就成为了真正面向工程的利器。</p><p>今天，我们就来讲清楚：</p><blockquote><strong>什么是 LangGraph？为什么它是构建可控 Agent 的未来？如何在最新 API 下用 create_agent 和 StateGraph 构建有状态智能体？</strong></blockquote><hr/><h2>一、为什么要用 LangGraph 构建 Agent？</h2><p>在 LangChain 最新版本中，Agent API 已经全面升级，官方推荐使用 <strong><code>create_agent</code></strong> 构建生产级智能体，并基于 <strong>LangGraph</strong> 对内部流程进行图结构编排。</p><blockquote><strong><code>create_agent</code></strong><br/>是一个高阶接口，用于构建图式 Agent。它内部依赖 LangGraph 执行器，在一个状态图中逐步完成模型推理、工具调用、决策流跳转等逻辑。</blockquote><p>过去我们可能使用 <strong>Chain + Logic</strong> 组合来处理流程，但随着逻辑复杂度增加，线性写法很难维护、扩展和调试。<br/>而 <strong>LangGraph 的图结构</strong> 可以让我们：</p><ul><li>用 <strong>状态（state）</strong> 表达全局对话或任务信息</li><li>用 <strong>节点（nodes）</strong> 表达流程逻辑</li><li>用 <strong>边（edges）</strong> 表达不同分支与条件</li><li>用 <strong>记忆插件</strong> 实现短期和长期记忆</li></ul><p>这组合起来，就形成了一个<strong>可控、有状态流程的智能 Agent</strong>。</p><hr/><h2>二、什么是 StateGraph？</h2><p><strong>StateGraph</strong> 是 LangGraph 的核心抽象，它表示一个<strong>具有全局状态和节点流转逻辑的图</strong>。<br/>每个节点本质上是一个函数，这个函数：</p><ul><li>接收当前全局状态</li><li>返回修改后的状态或跳转指令</li></ul><p>它非常适合把“复杂流程问题”映射为“图状态机”，无论是对话、工具调用还是多步骤任务。</p><p>简化后的 StateGraph 工作流程如下：</p><pre><code class="flow">StateGraph(StateType)
    ├── add_node(name, function)
    ├── add_edge(source, target)
    └── compile()
        → graph.invoke({state input})</code></pre><p>解释一下：</p><ul><li><strong>StateType</strong>：定义全局状态结构</li><li><strong>add_node</strong>：定义节点行为逻辑</li><li><strong>add_edge</strong>：定义节点间的流程跳转关系</li></ul><hr/><h2>三、新 API：<code>create_agent</code> 如何使用？</h2><p>从 LangChain 最新版本开始，旧的 <code>create_react_agent</code> 已被废弃，统一使用 <strong><code>create_agent</code></strong>。</p><p>一个最简单的示例：</p><pre><code class="python">from langchain.agents import create_agent
from langchain_openai import ChatOpenAI

model = ChatOpenAI(
    model="qwen3:8b",
    base_url="http://localhost:11434/v1",
    api_key="your api key",
)

agent = create_agent(
    model=model,
    tools=[],
    system_prompt="你是一个智能助手，负责处理用户请求。",
)

response = agent.invoke({
    "messages": [{"role": "user", "content": "什么是 LangGraph？"}]
})
print(response)</code></pre><p>📌 重点说明：</p><ul><li><code>model</code> 可以是任何支持工具调用的聊天模型</li><li><code>tools</code> 是 Agent 可调用的外部能力（如检索、代码执行等）</li><li><code>system_prompt</code> 是 Agent 的基础角色指令</li></ul><p>实际上，<strong><code>create_agent</code> 内部会构建一个 StateGraph</strong>，并把模型 + 工具节点组合成可执行流程。</p><hr/><h2>四、结合 StateGraph：构建更复杂的图式 Agent</h2><p>如果你希望在 Agent 内部实现更复杂的流程（如输入校验、分支工具调用、状态记录等），可以直接使用 <strong>StateGraph</strong>。</p><p>下面是一个包含两个节点的示例：通过 LLM 生成回答并记录状态。</p><pre><code class="python">from typing import TypedDict, Annotated
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages
from langchain_core.messages import HumanMessage

# 1. 定义全局状态
class ChatState(TypedDict):
    messages: Annotated[list, add_messages]

# 2. 初始化模型
llm = ChatOpenAI(
    model="qwen3:8b",
    base_url="http://localhost:11434/v1",
    api_key="your api key",
)

# 3. 定义节点
def chat_node(state: ChatState):
    response = llm.invoke(state["messages"])
    return {"messages": [response]}

# 4. 构建 StateGraph
graph = StateGraph(ChatState)
graph.add_node("chat", chat_node)
graph.set_entry_point("chat")
graph.add_edge("chat", END)
graph = graph.compile()

# 生成可视化图
with open("/Users/zhoupb/workspace-ai/atnk-ai/data/demo.png", "wb") as f:
    f.write(graph.get_graph(xray=True).draw_mermaid_png())

# 5. 调用
result = graph.invoke(
    {"messages": [HumanMessage(content="用一句话介绍什么是 LangGraph？")]},
)
print(result["messages"][-1].content)</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047605100" alt="demo.png" title="demo.png"/></p><p>在这个例子中：</p><ul><li><strong>ChatState</strong>：全局状态结构</li><li><strong>chat_node</strong>：处理模型逻辑的节点</li><li><strong>edges</strong>：从起点直接进入 <code>chat_node</code>，并更新消息状态</li></ul><p>你可以在图内使用更复杂的节点连接和条件分支。(docs.langchain.org.cn)</p><hr/><h2>五、记忆（Memory）如何集成？</h2><p>智能体的核心能力之一，就是<strong>记住之前的对话或操作历史</strong>。</p><p>LangGraph 提供了开箱即用的短期记忆机制，基于 <strong>检查点（checkpoint）</strong> 存储状态。以下是短期记忆的示例：</p><pre><code class="python">from langgraph.checkpoint.memory import InMemorySaver

#...省略

# 使用检查点保存状态
checkpointer = InMemorySaver()
graph = graph.compile(checkpointer=checkpointer)

# 使用同一个 thread_id，触发“记忆”
config = {"configurable": {"thread_id": "local-chat"}}

# 第一轮
result = graph.invoke(
    {"messages": [HumanMessage(content="用一句话介绍什么是 LangGraph？")]},
    config=config
)
print(result["messages"][-1].content)
print("-" * 100)

# 第二轮（保留上下文）
result = graph.invoke(
    {"messages": [HumanMessage(content="用一句话介绍它和 LangChain 的关系？")]},
    config=config
)
print(result["messages"][-1].content)</code></pre><p>同一个 <strong>thread_id</strong> 下的状态会被持续保存，实现短期记忆，非常适合多轮对话场景。</p><hr/><h2>六、工程化建议：可控、可视化与部署</h2><p>在真实工程场景下，图式 Agent 的能力远不止示例那么简单：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047605101" alt="微信图片_20260206164353_120_235.png" title="微信图片_20260206164353_120_235.png" loading="lazy"/></p><h3>1️⃣ 自定义状态扩展</h3><p>可以在 Agent 内定义更多状态字段，比如用户偏好、执行路径、决策数据等：</p><pre><code class="python">class CustomState(TypedDict):
    messages: list
    user_settings: dict</code></pre><p>调用 <code>create_agent</code> 时，通过 <code>state_schema</code> 参数传入，Agent 就会自动维护这些字段。</p><hr/><h3>2️⃣ 集成工具能力</h3><p>Agent 可以调用检索、代码执行、数据库查询等工具。<br/>工具可以作为节点，或者直接传入 <code>tools</code> 列表，由 Agent 在执行过程中调用，显著增强实际能力。</p><hr/><h3>3️⃣ 可观测与调试</h3><p>结合 <strong>LangSmith Trace</strong> 等可观测平台，可以：</p><ul><li>可视化执行路径</li><li>追踪状态变化</li><li>调试复杂流程</li></ul><p>大幅提高生产环境的可维护性。</p><hr/><h2>七、工程化细节总结</h2><table><thead><tr><th>技术点</th><th>最新 API</th></tr></thead><tbody><tr><td>构建 Agent</td><td><code>create_agent()</code>（替代旧的 <code>create_react_agent</code>）</td></tr><tr><td>状态管理</td><td>用 <code>StateGraph</code> 定义全局状态，并流转节点逻辑</td></tr><tr><td>记忆</td><td>基于 <code>checkpoint</code> 机制实现短期记忆</td></tr><tr><td>自定义状态</td><td>可通过 <code>state_schema</code> 扩展</td></tr><tr><td>可控流程</td><td>用节点 + 边 + Command 控制流程</td></tr></tbody></table><hr/><h2>八、结语：从链到图</h2><p>如果说传统 <strong>Chain</strong> 是<strong>线性的能力组合</strong>，那么 <strong>StateGraph</strong> 就是<strong>有状态的全局控制流机</strong>；<br/>如果说 Chain 是<strong>工具驱动流程片段</strong>，Graph 就是<strong>工程级的智能协同平台</strong>。</p><p>在 Agent 需求越来越复杂的今天，单靠 Chain 已无法应对多步骤决策、逻辑分支和记忆维护，而 <strong>LangGraph 的图式设计</strong>正是为可控 Agent 而生。</p><p>如果你正在做：</p><ul><li>多步对话机器人</li><li>带外部工具调用的智能体</li><li>具有长期记忆的应用</li><li>需要可视化与调试的生产系统</li></ul><p>那么，从 <strong>LangChain 到 LangGraph</strong> 的升级，将是你<strong>最值得投入的一条路线</strong>。</p>]]></description></item><item>    <title><![CDATA[1% 成本，把“越狱”按在地上摩擦？Anthropic 新一代安全保护 吾日三省吾码 ]]></title>    <link>https://segmentfault.com/a/1190000047605131</link>    <guid>https://segmentfault.com/a/1190000047605131</guid>    <pubDate>2026-02-11 10:02:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>大模型安全这事儿，说白了就是一场“攻防拉扯”：一边是<strong>越狱（jailbreak）</strong>天天整花活儿，试图绕过规则套取危险内容；另一边是模型厂商不断加护栏——但护栏加多了，用户又会骂：<em>“我就问个正经问题，你咋也拒绝？”</em> 😅</p><p>Anthropic 这篇<a href="https://link.segmentfault.com/?enc=2hincocmAUfbIIf92mw9Xg%3D%3D.cBXzOVFiUddnDzTxrmKt7gb9iaPpPcQjF4fusRuSvBWtSR3DeuwtS6fx8CmtjLW8Yo%2Bt9U3k0F950U17xbJCtnJCGkUKl0YLtjFzwC633Mw%3D" rel="nofollow" target="_blank">研究</a>讲的就是：如何在“更难被越狱”和“别乱拒绝正常请求”之间，找一个不那么反人类的平衡点。结论很炸裂：他们搞出了 <strong>Constitutional Classifiers++（下一代宪法分类器）</strong>，把额外算力开销压到 <strong>约 1%</strong>，同时把误拒率砍到更低，还宣称目前没发现“通用越狱”（universal jailbreak）。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047605133" alt="image" title="image"/></p><p>来，拆开看看它到底干了啥，为什么这次看起来不像“又一层更凶的拒绝器”，而更像一个真正能上生产的安全系统。</p><hr/><h2>1）先复习一下：什么是“宪法分类器”？为什么不是简单的敏感词过滤？</h2><p>传统做法很多都像“保安看门人”：你说了敏感词？拦。你问了危险话题？拦。<br/>但越狱最擅长的就是“绕开关键词”，比如换称呼、打哑谜、拆成几段，甚至让模型自己把隐含信息拼回去。</p><p>Anthropic 的“宪法分类器”思路更像：<strong>给模型一套自然语言写的规则（constitution）</strong>，用这些规则生成大量合成数据，再训练一个分类器去判断：这段输入/输出是不是在试图跨越红线。</p><p>他们给过一个典型边界：<strong>可以辅导大学化学作业，但不能协助合成受管制的危险化学品</strong>。<br/>（这点很关键：不是“化学一律不许聊”，而是“允许的学术内容”和“不可协助的危险路径”要分得更细。）</p><p>嗯。。。小D还知道有人发的关键词可以生成18+的内容，不过很快被修复了！[得意]</p><p>第一代宪法分类器效果其实已经很能打：据文中描述，它把越狱成功率从 <strong>86%</strong> 压到 <strong>4.4%</strong>，相当于挡住了绝大多数会绕过模型内置安全训练的攻击。</p><p>但问题来了：<strong>好用 ≠ 好部署</strong>。</p><hr/><h2>2）第一代的“代价账单”：更贵 + 更容易误拒绝</h2><p>第一代强是强，但也有两笔现实成本：</p><ul><li><strong>算力成本上升约 23.7%</strong>：这对线上服务是实打实的钱；</li><li><strong>无害请求的拒绝率上升 0.38%</strong>：别小看这点——用户体验被“误拒绝”恶心一次，心里小本本能记三年。</li></ul><p>更要命的是：他们还做过漏洞悬赏（bug bounty），结果还是被找到了一个“通用越狱”。<br/>也就是说：贵了、凶了，但仍然不是“绝对无敌”。</p><p>所以第二代的目标就很明确：<strong>要更抗打，还要更便宜，更别乱拒绝。</strong></p><hr/><h2>3）越狱在进化：两类新打法，把“只看输出”的护栏骗得团团转</h2><p>研究里点名了两类很典型、也很阴的攻击方式：</p><h3>A. Reconstruction（重构攻击）</h3><p>把危险信息拆成一段段“看起来人畜无害”的碎片，然后让模型在最后把碎片拼起来。<br/>比如把恶意请求藏在一堆函数、注释、配置片段里，指令却装得像“帮忙整理代码”。</p><h3>B. Output obfuscation（输出混淆攻击）</h3><p>输出看起来很正常，但其实在“打暗号”。<br/>例如把危险化学品换成“食用香精”的代称，或者用隐喻、谜语、映射，把有害概念伪装成无害概念。<br/>如果分类器只盯着输出文本，很容易被糊弄过去。</p><p>更刺激的是：越狱不仅会骗过护栏，还会让模型能力出现波动。文中提到，在某些越狱方式影响下，GPQA Diamond 这类高难度基准的表现会明显下滑，而且不同越狱方式导致的下降幅度不一样——这意味着攻击者可能继续迭代出“既能越狱，又不太伤模型能力”的新套路。</p><p>一句话：<strong>攻方还在升级，防方不能只靠“更严的拒绝”。</strong></p><hr/><h2>4）核心升级：从“单向检查”到“看完整对话”，再到“两段式升级打怪”</h2><p>这次的最大思路变化有两个。</p><h3>4.1 用“Exchange classifier”替代“输入/输出分开看”</h3><p>第一代的一个软肋是：输入和输出分开评估时，缺少“上下文关联”。<br/>但很多越狱恰恰是靠“输入里埋暗号，输出里用暗号回应”，单看任何一边都很无害，一拼在一起就很危险。</p><p>于是他们做了一个 <strong>exchange classifier</strong>：<strong>同时看输入+输出这一整个“交换（exchange）”</strong>，让判断基于上下文关联。<br/>在人类红队测试里，这能把越狱成功率再砍半——但代价是<strong>算力增加 50%</strong>。<br/>（看到这里很多人会皱眉：这不又回到“安全靠烧钱”了吗？别急，后面才是重点。）</p><h3>4.2 级联（cascade）架构：先便宜筛一遍，再把“可疑的”交给更强的判官</h3><p>为了不把所有请求都拉去做重型检查，他们搞了一个两阶段系统：</p><ol><li><strong>第一阶段：轻量筛查</strong>（便宜、快）</li><li><strong>第二阶段：更强分类器</strong>（贵、准）只处理“第一阶段觉得可疑的那一小撮”</li></ol><p>这设计很聪明：第一阶段可以容忍更高的误报，因为它不是直接拒绝用户，而是“升级处理”——类似：基层客服觉得你这事儿有点敏感，先转交主管复核，不是当场把你轰出门。</p><p>结果就是：<strong>既便宜，又不那么容易误拒绝。</strong></p><hr/><h2>5）最“黑科技”的部分：用模型内部激活做探针（probe），几乎“白嫖算力”</h2><p>真正让成本降到 ~1% 的关键，是他们引入了 <strong>internal probe classifiers（内部探针分类器）</strong>。</p><p>简单理解：模型在生成文本时，会产生大量内部状态（激活）。当它遇到可疑请求时，内部往往已经出现类似“这不太对劲”的信号——就像人类的直觉先抖一下，嘴上还没说“我拒绝”。</p><p>他们做的事是：<strong>直接探测这些内部激活模式</strong>，用一个线性探针快速判断“这事儿像不像有害”。因为这些计算本来就发生在模型里，所以额外成本非常低，近似“顺手摸一下脉搏”。</p><p>更妙的是：内部探针和外部分类器是互补的——外部看文本表面，内部看模型“心里怎么想”。攻击者可以花式包装文字，但要精准操控内部表征，难度更高。</p><p>最终的生产级组合拳是：</p><ul><li><strong>线性探针：全量筛查</strong></li><li><strong>探针+分类器的组合：对可疑 exchange 做最终裁决</strong></li></ul><hr/><h2>6）结果有多夸张？更低误拒 + 更低攻击成功率 + 成本只加 1%</h2><p>文中给了几个很关键的数字（别眨眼）：</p><ul><li>在真实流量部署中，无害请求的拒绝率做到 <strong>0.05%</strong>，相比原系统下降了 <strong>87%</strong>。<br/>这意味着：用户正常问问题，被“误伤”的概率更低了。</li><li>红队测试累计 <strong>1,700+ 小时</strong>，约 <strong>198,000 次尝试</strong>，只发现 <strong>一个高风险漏洞</strong>，对应检测率 <strong>0.005/千次查询</strong>（极低）。</li><li>目前<strong>还没发现通用越狱</strong>（至少在他们已测试范围内）。</li><li>额外算力开销：如果应用在某些 Opus 级别流量上，整体大约 <strong>~1%</strong>。</li></ul><p>翻译成人话就是：<strong>比上一代更能打、更少误伤，还几乎不怎么贵。</strong><br/>这才是“能上生产”的味道，不是实验室爽文。</p><hr/><h2>7）对行业意味着什么？安全不再只是“拒绝按钮”，而是“分层防御体系”</h2><p>很多人理解的大模型安全，是一句话：<em>“不该答的别答。”</em><br/>但真正的工程化安全更像现代风控：</p><ul><li><strong>低成本大范围筛查</strong>（别让系统被打爆）</li><li><strong>高精度小范围复核</strong>（别误伤正常用户）</li><li><strong>内部信号 + 外部文本双视角</strong>（别只看表面）</li><li><strong>持续红队与自动化对抗</strong>（别以为一次上线就万事大吉）</li></ul><p>而这篇文章的价值就在于：它把“安全”从一个单点模块，升级成了一个<strong>可迭代、可度量、成本可控的系统工程</strong>。</p><hr/><h2>结语</h2><p>真正的进步，是“更安全”不再等于“更难用”✅</p><p>大模型越强，越狱也会越狡猾，这是逃不掉的“军备竞赛”。但用户也不可能接受一个动不动就拒绝、体验像铁门的 AI。</p><p>Constitutional Classifiers++ 的思路很现实：<br/><strong>让大多数请求轻装通过，让少数可疑请求重装审查；既看你说了什么，也看模型内部觉得你想干什么。</strong></p><p>这就像把安检从“见人就盘问”升级成“先过门检，再抽检复核，重点人群再上人工”。不光更安全，还更不烦人。</p><p>接下来更值得期待的是他们提到的方向：把分类器信号更深地融合进生成过程、用自动化红队持续产出训练数据、在灰区边界上做更精准的“允许/拒绝”判定。<br/>毕竟安全这事儿没有终点，只有“今天比昨天更不容易被玩坏”😄</p><hr/><p><strong>喜欢就奖励一个“👍”和“在看”呗~</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047106529" alt="image" title="image" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[国产音视频技术新突破：自主可控解决方案的崛起 Amymaomao ]]></title>    <link>https://segmentfault.com/a/1190000047605135</link>    <guid>https://segmentfault.com/a/1190000047605135</guid>    <pubDate>2026-02-11 10:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>国产音视频技术新突破：自主可控解决方案的崛起在信息技术自主创新浪潮的推动下，各类组织对音视频通信技术的要求已发生深刻变化。过去单纯追求功能完备的方案已难以满足当前环境，市场日益重视技术的国产化属性、安全可控性以及生态兼容能力。传统解决方案往往在适配国产软硬件体系、保障数据传输安全、支持多样化终端等方面存在局限，亟需新一代技术架构来填补这一空白。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047605137" alt="图片" title="图片"/><br/>全面适配国产化环境：打破生态壁垒为应对国产化信息技术生态的独特需求，一批专注于自主研发的企业推出了新一代音视频通信解决方案。这些方案以“自主可控、安全合规”为设计原则，致力于为政府、金融、能源及大型企业提供符合国产化要求的定制化服务。其中，代表性技术已实现与主流国产芯片平台（如鲲鹏、飞腾、龙芯、兆芯等）的深度适配，并全面兼容统信UOS、麒麟软件等国产操作系统。通过对底层媒体处理引擎的优化重构，确保了在不同硬件平台和操作系统上都能保持稳定的性能输出和流畅的用户体验，有效解决了跨平台兼容性难题。在音频设备适配方面，新一代解决方案提供了智能化的音频路由管理能力，支持在有线耳机、蓝牙设备、内置扬声器等多种音频输出方式间无缝切换。这一设计不仅提升了跨设备使用的便利性，也降低了在多终端场景下的配置复杂度。构建端到端安全体系：筑牢数据防护屏障在信息安全日益重要的今天，音视频通信平台必须具备多层次的安全防护能力。新一代解决方案从数据传输、存储到访问控制等多个维度构建了完整的安全体系。在数据传输层面，采用符合国家密码管理要求的加密算法，对音视频流、信令控制及文件传输等全过程进行加密保护，确保数据在传输过程中的机密性和完整性。同时，支持私有化部署模式，允许用户将系统部署在本地数据中心或专属云环境中，实现数据的完全自主管控。在访问控制方面，提供了细粒度的权限管理功能，管理员可根据组织架构和职责分工设置差异化的会议权限。结合动态水印、实名认证、参会密码等多重验证机制，有效防止信息泄露和未授权访问，特别适用于对保密性要求较高的政务、金融、司法等领域。优化网络适应能力：保障复杂环境下的通信质量实际应用环境中，网络条件往往存在较大差异。为应对这一挑战，新一代音视频技术引入了智能网络感知与自适应调节机制。系统能够实时监测网络带宽、延迟、抖动等指标，动态调整视频分辨率、帧率和编码参数，在网络波动时优先保障语音通信的连续性，确保在各种网络条件下都能提供可用的通信服务。针对网络丢包问题，采用了前向纠错、丢包重传等混合恢复技术，在网络丢包率达到一定阈值时仍能维持基本的通话功能。这一特性对于网络基础设施相对薄弱的地区、移动办公场景以及应急指挥等特殊环境具有重要价值。降低开发集成门槛：提供灵活易用的技术组件为加速技术落地进程，新一代解决方案提供了完善的开发支持体系。通过模块化的SDK设计和丰富的API接口，开发者可以根据实际需求灵活选择集成范围，快速将音视频能力嵌入现有业务系统中。同时，提供可高度自定义的UI组件库，支持界面风格、布局、功能的灵活配置，大幅降低了二次开发的工作量和技术门槛。全周期服务支持：助力项目顺利实施除了技术产品本身，服务团队还构建了覆盖需求分析、方案设计、开发集成、上线运维的全生命周期支持体系。提供包括开发文档、示例代码、集成指南在内的完整技术资料，并配备专业技术支持团队，为客户提供定制化的咨询服务和实施指导。针对特定行业的特殊需求，还可提供专项技术支持和联合开发服务，确保解决方案与业务场景的深度融合。展望未来随着信息技术应用创新产业的快速发展，具备自主知识产权、符合国家安全标准、适配国产化生态的音视频通信技术，将成为推动千行百业数字化转型的重要基础设施。未来，相关技术提供商将继续深化在国产化适配、安全增强、性能优化等方面的探索，拓展在远程协作、智慧教育、数字医疗、工业互联网等更多领域的应用，为构建安全可控的数字中国贡献力量。</p>]]></description></item><item>    <title><![CDATA[剑指offer-75、买卖股票的最好时机 SevenCoding ]]></title>    <link>https://segmentfault.com/a/1190000047598472</link>    <guid>https://segmentfault.com/a/1190000047598472</guid>    <pubDate>2026-02-11 09:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>题⽬描述</h2><p>假设你有⼀个数组 prices ，⻓度为 n ，其中 prices[i] 是股票在第 i 天的价格，请根据这个价格数组，返回买卖股票能获得的最⼤收益</p><ol><li>你可以买⼊⼀次股票和卖出⼀次股票，并⾮每天都可以买⼊或卖出⼀次，总共只能买⼊和卖出⼀次，且买⼊必须在卖出的前⾯的某⼀天</li><li>如果不能获取到任何利润，请返回 0</li><li>假设买⼊卖出均⽆⼿续费</li></ol><p>示例1：<br/>输⼊：[8,9,2,5,4,7,1]<br/>返回值: 5<br/>说明: 在第3天(股票价格 = 2)的时候买⼊，在第6天(股票价格 = 7)的时候卖出，最⼤利润 = 7-2 = 5，不能选择在第2天买⼊，第3天卖出，这样就亏损7了；同时，你也不能在买⼊前卖出股票。</p><p>示例2：<br/>输⼊：[2,4,1]<br/>返回值: 2</p><h2>思路及解答</h2><h3>暴⼒穷举</h3><p>这⾥涉及的节点⽆⾮是买⼊，卖出，那么我们遍历所有的数据，作为买⼊⽇期，同时将该⽇期后⾯每⼀个都作为卖出⽇期来计算，只要维护最⼤的利润即可。</p><pre><code class="java">public class Solution {
    public int maxProfit(int[] prices) {
        if (prices == null || prices.length &lt; 2) {
            return 0;
        }
        
        int maxProfit = 0;
        int n = prices.length;
        
        // 外层循环：遍历所有可能的买入点
        for (int i = 0; i &lt; n - 1; i++) {
            // 内层循环：遍历所有可能的卖出点（必须在买入点之后）
            for (int j = i + 1; j &lt; n; j++) {
                int profit = prices[j] - prices[i];
                if (profit &gt; maxProfit) {
                    maxProfit = profit;
                }
            }
        }
        
        return maxProfit;
    }
}</code></pre><ul><li>时间复杂度： O(n2)</li><li>空间复杂度：O(1)</li></ul><h3>贪⼼法（最优解）</h3><p>我们要想得到⼀个最⼤的利润，其实就是要两者差值最⼤。如果让差值最⼤，假设在当天卖出，那么什么时候买⼊最好呢？</p><p>当然是在前⾯找到最⼩的买⼊点，⽐如：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047598474" alt="" title=""/></p><p>⽽前⾯的最⼩值，其实我们在遍历的时候是可以不断维护的，所以我们只要遍历⼀次数组即可。</p><p><strong>关键思想：</strong></p><ul><li>最大利润 = 某日价格 - 该日之前的最低价格</li><li><p>只需维护两个变量：</p><ul><li><code>minPrice</code>：遍历过程中遇到的最低价格</li><li><code>maxProfit</code>：当前能获得的最大利润</li></ul></li></ul><pre><code class="java">public class Solution63 {
    public int maxProfit(int[] prices) {
        int min = Integer.MAX_VALUE;
        int result = 0;
        for (int value: prices) {
            // 维护最⼩值
            min = Math.min(min, value);
            // 当前值减去前⾯最⼩值，与利润最⼤值对⽐，维护好利润最⼤值
            result = Math.max(result, value - min);
        }
        return result;
    }
}</code></pre><ul><li><strong>时间复杂度</strong>：O(n)，只需遍历一次数组</li><li><strong>空间复杂度</strong>：O(1)，只使用常数空间</li></ul><p>执行过程示例（prices = [8,9,2,5,4,7,1]）</p><pre><code class="text">i=0: price=8, minPrice=8, maxProfit=0
i=1: price=9, minPrice=8, maxProfit=1
i=2: price=2, minPrice=2, maxProfit=1
i=3: price=5, minPrice=2, maxProfit=3
i=4: price=4, minPrice=2, maxProfit=3
i=5: price=7, minPrice=2, maxProfit=5
i=6: price=1, minPrice=1, maxProfit=5
结果：5</code></pre><h3>动态规划</h3><p>dp[i]表示前i天的最大利润，状态转移基于前i-1天的结果</p><p><strong>状态定义：</strong></p><ul><li><code>minPrice[i]</code>：前i天的最低价格</li><li><code>maxProfit[i]</code>：前i天能获得的最大利润</li></ul><pre><code class="java">public class Solution {
    public int maxProfit(int[] prices) {
        if (prices == null || prices.length &lt; 2) {
            return 0;
        }
        
        int minPrice = prices[0];
        int maxProfit = 0;
        
        for (int i = 1; i &lt; prices.length; i++) {
            // 状态转移方程：
            // 前i天的最大利润 = max(前i-1天的最大利润, 第i天价格-前i-1天的最低价格)
            maxProfit = Math.max(maxProfit, prices[i] - minPrice);
            minPrice = Math.min(minPrice, prices[i]);
        }
        
        return maxProfit;
    }
}</code></pre><ul><li><strong>时间复杂度</strong>：O(n)，单次遍历</li><li><strong>空间复杂度</strong>：O(1)，优化后只需两个变量</li></ul>]]></description></item><item>    <title><![CDATA[2026年热度最高的数字化采购系统推荐 SaaS圈老马 ]]></title>    <link>https://segmentfault.com/a/1190000047600112</link>    <guid>https://segmentfault.com/a/1190000047600112</guid>    <pubDate>2026-02-11 08:01:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>随着企业降本增效诉求不断升级，数字化采购已经从“可选项”变成“必选项”。根据行业观察，正确的采购平台可显著提升企业采购效率、加强供应商协同能力并实现透明化管控。数字化采购系统市场供应商超过200家，差异化明显，选型难度较大。以下结合技术实力、客户案例和市场认可度，盘点当前热度较高的几款采购系统。</p><p><strong>一、头部数字化采购系统清单</strong></p><p><strong>热度较高的数字化采购系统盘点</strong></p><p><strong>1、正远科技</strong></p><p><a href="https://link.segmentfault.com/?enc=5ls14BlqtoznDUyPGMesoA%3D%3D.R1dKSSGw9YPi9IIQSITpyX6BvrtIAfefTJkqju%2FaIr0%3D" rel="nofollow" target="_blank">https://www.zhengyuantech.cn/</a></p><p>如果你的企业采购流程复杂、组织层级多、审批规则多变（尤其是集团多组织、多事业部），那么“能否快速适配业务”往往比“功能堆得多”更关键。正远科技在行业内被频繁提及，核心就是<strong>低代码+微服务架构</strong>带来的敏捷迭代与快速落地能力。</p><p><strong>（1）技术底座：低代码平台 + SpringCloud微服务，支持敏捷交付</strong></p><p>正远SRM强调“低代码底座”，通过<strong>可视化建模与拖拽式配置</strong>实现表单、字段、规则、流程的快速调整；同时采用<strong>SpringCloud微服务架构</strong>，以更强的模块隔离与弹性扩展能力，降低升级、运维与功能扩展的成本。相关行业对比文章中也将其“低代码+微服务”作为核心差异点之一。 </p><p>这类架构对企业的实际价值在于：</p><p>①采购规则变化能更快响应；</p><p>②各模块升级不互相牵连，降低停机风险；</p><p>③个性化需求可与核心版本隔离，减少“深度二开后升级难”的典型问题。 </p><p><strong>（2）能力范围：采购全生命周期在线化，强调协同与闭环</strong></p><p>相比只做“请购-审批-下单”的轻量工具，正远SRM强调闭环：</p><p><strong>①供应商全生命周期管理</strong>：注册、准入、分级、绩效、淘汰；并支持供应商画像、风险预警等；</p><p><strong>②寻源定价</strong>：询比价、招投标、竞价等多模式覆盖；</p><p><strong>③采购执行协同</strong>：订单、交付、质检、对账、开票及异常整改；</p><p><strong>④数据分析与看板</strong>：基于采购全链路数据沉淀，形成成本穿透与供应商绩效分析能力。 </p><p><strong>（3）为什么它“热度高”？关键在“业务适配速度”</strong></p><p>很多采购系统的难点不在上线，而在上线后持续运营：规则一变就要排期开发。正远更偏向“可配置”而不是“重开发”，所以在组织复杂、流程差异大的客户里讨论度更高。</p><p><strong>（4）适配企业类型</strong></p><p>①集团型企业：多组织、多公司、多主体采购；</p><p>②制造/工程类企业：项目采购多、过程管控多；</p><p>③对信创适配、数据安全、系统隔离有要求的企业<br/><img width="723" height="360" referrerpolicy="no-referrer" src="/img/bVdnS7Q" alt="" title=""/></p><p><strong>2、甄云科技</strong></p><p><strong>亮点</strong><br/>甄云科技是业内较早布局数字采购与SRM的一线厂商之一，提供包括供应商管理、询价/招投标、绩效分析、采购商城等在内的全功能体系。根据厂商公开信息，其平台支持供应商全生命周期数据管控，并以成熟实施方法论助力企业采购数字化落地。</p><p><strong>优势要素</strong></p><p>（1）<strong>成熟产品矩阵</strong>：涵盖SRM、智慧寻源、敏捷协同、智能分析等模块，可满足大型企业综合采购需求。<br/>（2）<strong>服务与支持</strong>：提供全周期专家服务和成熟交付方案，适合流程标准化场景。</p><p><strong>适用客户</strong><br/>采购规模大、流程标准化，致力于构建统一采购中台或供应链协同的大型企业。<br/><img width="723" height="316" referrerpolicy="no-referrer" src="/img/bVdnS7R" alt="" title="" loading="lazy"/></p><p><strong>3、商越科技</strong></p><p><strong>亮点</strong><br/>商越专注于非生产物资采购场景，通过与主流电商渠道、供应商建立连接，提升标品比价与下单体验。一些行业观察指出该类采购系统能使用户在便捷性和操作效率上获得显著提升。</p><p><strong>优势要素</strong></p><p>（1）<strong>电商化体验</strong>：员工可通过简洁界面比价下单，缩短标品采购周期。<br/>（2）<strong>SaaS模式部署</strong>：快速上线，适合标品需求高的互联网、消费品企业。</p><p><strong>适用客户</strong><br/>主要关注非生产物资采购流程自动化、追求员工自助采购体验的企业。<br/><img width="723" height="305" referrerpolicy="no-referrer" src="/img/bVdnS7S" alt="" title="" loading="lazy"/></p><p><strong>4、郑州信源</strong></p><p><strong>亮点</strong><br/>郑州信源以电子化招投标系统著称，为政府、国企、金融机构等对合规性要求极高的采购场景提供整体解决方案。公开资料显示，其平台具备招投标、公示公告、专家评审等内置流程，并形成较完备的企业采购能力体系。</p><p><strong>优势要素</strong></p><p>（1）<strong>合规性强</strong>：系统内置完整招投标及审计流程，适应严格监管要求。<br/>（2）<strong>高并发能力</strong>：适合支撑日常大量招标、投标活动的政企级平台。</p><p><strong>适用客户</strong><br/>对采购合规审计要求严、需支持大规模招投标交易的政企单位及大型集团。<br/><img width="723" height="388" referrerpolicy="no-referrer" src="/img/bVdnS7T" alt="" title="" loading="lazy"/></p><p><strong>二、选型建议</strong></p><p><strong>1、明确核心诉求</strong><br/>明确采购流程中最痛点环节，从需求优先级出发筛选平台。</p><p><strong>2、关注实施与服务周期</strong><br/>系统功能再强，若实施周期过长或交付服务不完善，也可能影响实际价值落地。国内一些供应商在快速实施与专家支持方面表现明显。</p><p><strong>3、集成与扩展能力</strong><br/>优先关注能与ERP/财务/仓储等系统无缝集成的平台，这样能降低切换成本，提升数据贯通效率。行业通行做法建议首先评估这一点。</p><p><strong>三、总结：适配才是核心</strong></p><p>没有绝对最好的采购系统，只有最<strong>适合企业现实需求</strong>的平台。合理匹配技术架构、流程灵活度、行业特性及后续服务能力，才是实现数字化采购降本增效的关键。建议企业在试点阶段重点关注<strong>价值交付周期、使用便捷性及长期维护成本</strong>，避免仅凭功能堆叠做决策。</p>]]></description></item><item>    <title><![CDATA[[260210] 阿里发布 Qwen-Image-2.0，实测复杂插画生成，手绘细节还原度很高！ x]]></title>    <link>https://segmentfault.com/a/1190000047604800</link>    <guid>https://segmentfault.com/a/1190000047604800</guid>    <pubDate>2026-02-10 23:03:38</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>阿里千问 Qwen-Image-2.0 刚发布，我们就迫不及待拿来“压榨”它的生产力！</p><p>这次直接让它帮我们生成视频封面。</p><p><img width="723" height="418" referrerpolicy="no-referrer" src="/img/bVdnUls" alt="" title=""/></p><p>从实测来看，新模型对提示词中复杂的“手绘风格”和“颜色编码”理解得相当精准，甚至连布局细节都照顾到了。<br/>目前，我们可以通过Qwen Chat（chat.qwen.ai）免费体验新模型，大家可以去尝试一下。</p><p>这次测试的提示词如下:</p><pre><code class="text">// KEY CONTENT (关键内容)
标题： x claude sess - 让历史会话井井有条
副标题： FZF 交互式预览 + 快速清理，告别混乱的会话历史
署名： @x-cmd

// VISUAL (视觉画面)
画面中心是一个手绘风格的文件柜，抽屉半开，里面整齐排列着带标签的文件夹（代表会话）。文件柜上方漂浮着一个放大镜图标（代表 FZF 搜索）和一个垃圾桶图标（代表清理功能）。背景是柔和的米白色 #F9F7F2，整体采用温暖的手绘插画风格，线条自然流畅。文件夹用柔和的珊瑚红 #FF7F7F 和鼠尾草绿 #8FA87A 点缀。

// LAYOUT (布局结构)
海报式布局。标题用手写圆体居中上方，文件柜占据画面中心偏下，放大镜和垃圾桶图标在文件柜两侧漂浮。副标题和署名位于下方，用较小的手写体呈现。</code></pre>]]></description></item>  </channel></rss>