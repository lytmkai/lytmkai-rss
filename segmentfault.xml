<?xml version="1.0" encoding="UTF-8"?><rss version="2.0">  <channel>      <title>SegmentFault - 最近文章</title>      <link>https://segmentfault.com/blogs/newest</link>      <description>SegmentFault 思否</description>      <generator>python segmentfault.py @Pi20</generator>      <item>    <title><![CDATA[如何将 Minio DirectPV 配置为 RustFS PVC？ RustFS ]]></title>    <link>https://segmentfault.com/a/1190000047560478</link>    <guid>https://segmentfault.com/a/1190000047560478</guid>    <pubDate>2026-01-23 12:13:47</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>RustFS 作为新一代的分布式对象存储系统，提供了 Helm Chart 以便 Kubernetes 集群上安装 RustFS 实例。而 DirectPV 是一个符合 CSI 标准的 Kubernetes 存储项目，由 Minio 发布且开源。本文使用 DirectPV 为 Kubernetes 上的 RustFS 实例提供后端存储服务，实现两个对象存储服务的“结合”。</p><h2>前提</h2><ul><li><p>运行良好的 Kubernetes 集群。</p><p>本文使用 K3S 作为测试环境，根据 <a href="https://link.segmentfault.com/?enc=FL%2BLq85T4gEZM0n%2BqN6Qrg%3D%3D.bWyGM22THDGJ4WVAIpn2icITur2Sj6yDSzevtRD1QQ0%3D" rel="nofollow" target="_blank">K3S 安装指南</a>完成安装：</p><pre><code># 安装 K3S
curl -sfL https://get.k3s.io | sh -

# 安装确认
kubectl get nodes
NAME             STATUS   ROLES           AGE   VERSION
vm-0-17-ubuntu   Ready    control-plane   63m   v1.34.3+k3s1</code></pre></li><li><p>一块空磁盘</p><p>本文在安装 K3S 的服务器上（OS 为 Ubuntu 24.04）挂载了一块容量为 20GB 的新磁盘：</p><pre><code>df -h
vdb    253:16   0   20G  0 disk /root/data/disk

mount | grep vdb
/dev/vdb on /root/data/disk type ext4 (rw,relatime)</code></pre></li></ul><h2>安装 DirectPV</h2><p>可以直接根据 <a href="https://link.segmentfault.com/?enc=%2B8bON2b2YW2wIjdX%2FYB%2FTA%3D%3D.cq7cHPD6vM7aSkj717jR4oZL79ycZvpE%2FZvxh1pC8%2B%2F2feAXmW3%2Ba1CGt88%2Fnf3c" rel="nofollow" target="_blank">minio/directpv</a> 文档进行 DirectPV 的安装。这个过程中会使用到 <a href="https://link.segmentfault.com/?enc=n4R7YghvpjXKNciHyeABdA%3D%3D.WCMqMpAOcmYEDIBdPaVvoWVZixKPAvaxwySR79tp96YdC9WBbKY6ZR6bxYMRyXfguBFo%2B1%2BY45AOkLQDkLtHNw%3D%3D" rel="nofollow" target="_blank">krew</a> plugin，根据不同的 OS 执行安装命令即可。</p><p>在 Ubuntu 上执行如下命令：</p><pre><code>(
  set -x; cd "$(mktemp -d)" &amp;&amp;
  OS="$(uname | tr '[:upper:]' '[:lower:]')" &amp;&amp;
  ARCH="$(uname -m | sed -e 's/x86_64/amd64/' -e 's/\(arm\)\(64\)\?.*/\1\2/' -e 's/aarch64$/arm64/')" &amp;&amp;
  KREW="krew-${OS}_${ARCH}" &amp;&amp;
  curl -fsSLO "https://github.com/kubernetes-sigs/krew/releases/latest/download/${KREW}.tar.gz" &amp;&amp;
  tar zxvf "${KREW}.tar.gz" &amp;&amp;
  ./"${KREW}" install krew
)</code></pre><p>安装完毕，将 <code>PATH="${KREW_ROOT:-$HOME/.krew}/bin:$PATH"</code> 写到 ~/.bashrc 或 ~/.zshrc 即可。</p><p>开始安装 DirectPV。</p><ul><li>安装 directpv krew 插件</li></ul><pre><code>kubectl krew install directpv</code></pre><ul><li>在 Kubernetes 集群中安装 DirectPV</li></ul><pre><code>kubectl directpv install
Installing on unsupported Kubernetes v1.34

 ███████████████████████████████████████████████████████████████████████████ 100%

┌──────────────────────────────────────┬──────────────────────────┐
│ NAME                                 │ KIND                     │
├──────────────────────────────────────┼──────────────────────────┤
│ directpv                             │ Namespace                │
│ directpv-min-io                      │ ServiceAccount           │
│ directpv-min-io                      │ ClusterRole              │
│ directpv-min-io                      │ ClusterRoleBinding       │
│ directpv-min-io                      │ Role                     │
│ directpv-min-io                      │ RoleBinding              │
│ directpvdrives.directpv.min.io       │ CustomResourceDefinition │
│ directpvvolumes.directpv.min.io      │ CustomResourceDefinition │
│ directpvnodes.directpv.min.io        │ CustomResourceDefinition │
│ directpvinitrequests.directpv.min.io │ CustomResourceDefinition │
│ directpv-min-io                      │ CSIDriver                │
│ directpv-min-io                      │ StorageClass             │
│ node-server                          │ Daemonset                │
│ controller                           │ Deployment               │
└──────────────────────────────────────┴──────────────────────────┘

DirectPV installed successfully</code></pre><ul><li>安装确认并获取安装信息</li></ul><pre><code>
kubectl -n directpv get pods
NAME                          READY   STATUS    RESTARTS   AGE
controller-54d56fb9f8-92cz8   3/3     Running   0          90m
controller-54d56fb9f8-kfltl   3/3     Running   0          90m
controller-54d56fb9f8-ncxcn   3/3     Running   0          90m
node-server-vgpn2             4/4     Running   0          90m

kubectl directpv info
┌──────────────────┬──────────┬───────────┬─────────┬────────┐
│ NODE             │ CAPACITY │ ALLOCATED │ VOLUMES │ DRIVES │
├──────────────────┼──────────┼───────────┼─────────┼────────┤
│ • vm-0-17-ubuntu │ -        │ -         │ -       │ -      │
└──────────────────┴──────────┴───────────┴─────────┴────────┘

0 B/0 B used, 0 volumes, 0 drives</code></pre><ul><li>添加磁盘（驱动）</li></ul><p>首先检测磁盘信息并将其信息写到 <code>drives.yaml</code> 文件中：</p><pre><code>kubectl directpv discover

 Discovered node 'vm-0-17-ubuntu' ✔

┌─────────────────────┬────────────────┬───────┬────────┬────────────┬──────┬───────────┬─────────────┐
│ ID                  │ NODE           │ DRIVE │ SIZE   │ FILESYSTEM │ MAKE │ AVAILABLE │ DESCRIPTION │
├─────────────────────┼────────────────┼───────┼────────┼────────────┼──────┼───────────┼─────────────┤
│ 253:16$PXmUgO0FF... │ vm-0-17-ubuntu │ vdb   │ 20 GiB │ ext4       │ -    │ YES       │ -           │
└─────────────────────┴────────────────┴───────┴────────┴────────────┴──────┴───────────┴─────────────┘

Generated 'drives.yaml' successfully.</code></pre><p><code>drives.yaml</code> 文件内容如下：</p><pre><code>version: v1
nodes:
    - name: vm-0-17-ubuntu
      drives:
        - id: 253:16$PXmUgO0FF7sKtsaVihMadap1hCZil9Rksbz2SdQkMfA=
          name: vdb
          size: 21474836480
          make: ""
          fs: ext4
          select: "yes"</code></pre><p>接着使用 <code>drives.yaml</code> 文件进行 DirectPV 初始化：</p><pre><code>kubectl directpv init drives.yaml --dangerous

 ███████████████████████████████████████████████████████████████████████████ 100%

 Processed initialization request '3a70561d-3de0-4756-b256-159fc98593d1' for node 'vm-0-17-ubuntu' ✔

┌──────────────────────────────────────┬────────────────┬───────┬─────────┐
│ REQUEST_ID                           │ NODE           │ DRIVE │ MESSAGE │
├──────────────────────────────────────┼────────────────┼───────┼─────────┤
│ 3a70561d-3de0-4756-b256-159fc98593d1 │ vm-0-17-ubuntu │ vdb   │ Success │
└──────────────────────────────────────┴────────────────┴───────┴─────────┘</code></pre><p>恭喜你，走到这一步，你已经成功安装了 DirectPV（之前的每一步出错都会导致失败，请认真查看命令以及输出结果），使用如下命令确认：</p><pre><code>kubectl get sc
NAME                   PROVISIONER             RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE
directpv-min-io        directpv-min-io         Delete          WaitForFirstConsumer   true                   90m
local-path (default)   rancher.io/local-path   Delete          WaitForFirstConsumer   false                  115m</code></pre><p>可以看到，名为 <code>directpv-min-io</code> 的 StorageClass 已经存在。接下来就使用这个 SC 进行 RustFS 的安装。</p><h2>在 K3S 上安装 RustFS</h2><p>RustFS 提供 <a href="https://link.segmentfault.com/?enc=i8KeqDVUf8AuSSApA%2BgE7g%3D%3D.rwRLVoipQrvUbOI%2F%2BIr7GTduD0JUz%2Bs0SM3lm17idplcjm5O%2Bc4A%2Fzuh%2F%2Fg1T%2FVb" rel="nofollow" target="_blank">Helm Chart</a>来在 Kubernetes 上安装 RustFS。<strong>目前支持两种模式：单机单盘（SNSD）和多机多盘（MNMD）</strong>。</p><p>可以将 GitHub Repo 代码 clone 到本地，然后进入到 <code>helm/rustfs</code> 目录下进行安装，也可以直接使用 RustFS 的远端仓库（RustFS 已经将 Helm Chart 发布到了 Artifact Hub），比如：</p><pre><code># 添加仓库
helm repo add rustfs https://charts.rustfs.com

# 安装 RustFS
helm install rustfs -n rustfs rustfs/rustfs --create-namespace  --version 0.0.80</code></pre><p>由于 RustFS Helm Chart 默认使用 <code>local-path</code> StorageClass，而且默认的 PVC 大小为 256Mi，因此需要根据自身情况设置合适的大小，最简单的方式就是在本地创建一个 <code>values.yml</code> 文件，然后修改如下内容：</p><pre><code>storageclass:
  name: directpv-min-io
  dataStorageSize: 256Mi
  logStorageSize: 256Mi</code></pre><blockquote>当然，也可以用 <code>--set</code> 来实现参数的覆盖，但是由于 RustFS 多种安装模式、多种 Ingress Controller，以及 pod 资源的自定义等，<code>--set</code> 就需要指定多个参数，会显得繁琐。将需要变更的信息写到本地 <code>values.yml</code>，然后用 <code>-f</code> 指定，可能更加便捷的自定义安装 RustFS。</blockquote><p>本文采用本地安装模式（也就是 Helm Chart 代码在本地），执行如下命令进行安装：</p><pre><code>helm install rustfs ./ -n rustfs --create-namespace -f values.yaml </code></pre><p>查看 PVC</p><pre><code>kubectl -n rustfs get pvc 
NAME                     STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS      VOLUMEATTRIBUTESCLASS   AGE
data-rustfs-0-rustfs-0   Bound    pvc-8e9b520f-3a96-4a64-afb3-70f13d3edcd3   256Mi      RWO            directpv-min-io   &lt;unset&gt;                 61s
data-rustfs-0-rustfs-1   Bound    pvc-8bef3219-469c-452c-969a-89c8470d3945   256Mi      RWO            directpv-min-io   &lt;unset&gt;                 61s
data-rustfs-0-rustfs-2   Bound    pvc-aee2c489-6f4c-47dc-b464-b09fc5ea112c   256Mi      RWO            directpv-min-io   &lt;unset&gt;                 61s
data-rustfs-0-rustfs-3   Bound    pvc-b59ec27c-9fb0-4ad1-a204-9858c1d405da   256Mi      RWO            directpv-min-io   &lt;unset&gt;                 61s
data-rustfs-1-rustfs-0   Bound    pvc-8d840468-f6be-4154-ae42-73f68f6e36e3   256Mi      RWO            directpv-min-io   &lt;unset&gt;                 61s
data-rustfs-1-rustfs-1   Bound    pvc-c5adc67b-f6ea-470a-861d-9b48b610bbee   256Mi      RWO            directpv-min-io   &lt;unset&gt;                 61s
data-rustfs-1-rustfs-2   Bound    pvc-8d7b98e0-ff0b-4d5f-869c-fe7c1b71ffc2   256Mi      RWO            directpv-min-io   &lt;unset&gt;                 61s
data-rustfs-1-rustfs-3   Bound    pvc-9268589f-7ca7-4480-a724-36bfcdc29cff   256Mi      RWO            directpv-min-io   &lt;unset&gt;                 61s
data-rustfs-2-rustfs-0   Bound    pvc-f31689f3-1aa8-42f7-8fcb-f309a6b390b5   256Mi      RWO            directpv-min-io   &lt;unset&gt;                 61s
data-rustfs-2-rustfs-1   Bound    pvc-28fecb41-9dd7-436d-9317-e8a3a588a87a   256Mi      RWO            directpv-min-io   &lt;unset&gt;                 61s
data-rustfs-2-rustfs-2   Bound    pvc-77d4c8e6-918a-4b28-a2bc-408195f807d3   256Mi      RWO            directpv-min-io   &lt;unset&gt;                 61s
data-rustfs-2-rustfs-3   Bound    pvc-6deab996-a8a3-4e02-ae6c-845f863526c0   256Mi      RWO            directpv-min-io   &lt;unset&gt;                 61s
data-rustfs-3-rustfs-0   Bound    pvc-46c7cc1a-1f25-4c3e-8168-3c288ee552d5   256Mi      RWO            directpv-min-io   &lt;unset&gt;                 61s
data-rustfs-3-rustfs-1   Bound    pvc-a0403935-2471-48d8-beac-fcf28fd85a7a   256Mi      RWO            directpv-min-io   &lt;unset&gt;                 61s
data-rustfs-3-rustfs-2   Bound    pvc-d0c88736-ee1a-47e5-a335-53d086e87913   256Mi      RWO            directpv-min-io   &lt;unset&gt;                 61s
data-rustfs-3-rustfs-3   Bound    pvc-9fbac8a8-cb59-430b-abc1-4ad5105ed4ad   256Mi      RWO            directpv-min-io   &lt;unset&gt;                 61s
logs-rustfs-0            Bound    pvc-bc673cea-6cf0-479f-a323-5c2102479796   256Mi      RWO            directpv-min-io   &lt;unset&gt;                 61s
logs-rustfs-1            Bound    pvc-c823f3a4-2e07-4331-bdd3-f0c6172bb15b   256Mi      RWO            directpv-min-io   &lt;unset&gt;                 61s
logs-rustfs-2            Bound    pvc-059eeaf9-b209-41ec-87f6-da87f0105c41   256Mi      RWO            directpv-min-io   &lt;unset&gt;                 61s
logs-rustfs-3            Bound    pvc-348e4bfb-d272-4deb-ae8e-fc6ea70d4d74   256Mi      RWO            directpv-min-io   &lt;unset&gt;                 61s</code></pre><p>可以看到生成了分布式安装所需的所有 PVC，状态是 <strong>Bound</strong>。接着查看 pods 状态：</p><pre><code>kubectl -n rustfs get pods
NAME       READY   STATUS    RESTARTS   AGE
rustfs-0   1/1     Running   0          69s
rustfs-1   1/1     Running   0          69s
rustfs-2   1/1     Running   0          69s
rustfs-3   1/1     Running   0          69s</code></pre><p>可以看到 pod 运行正常。接着就可以使用 ingress 来访问该 RustFS 实例了。</p><h2>注意事项</h2><p>安装 DirectPV 的过程中，会对该磁盘上的数据进行格式化，而且该磁盘不能被其他程序占用，否则会出现如下错误：</p><pre><code>
┌──────────────────────────────────────┬────────────────┬───────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐
│ REQUEST_ID                           │ NODE           │ DRIVE │ MESSAGE                                                                                                                                                                                                                          │
├──────────────────────────────────────┼────────────────┼───────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ e9adb7af-8061-46b1-8112-d86e5fb653cd │ vm-0-17-ubuntu │ vdb   │ Failed; unable to format device /dev/vdb; unable to execute command [mkfs.xfs -i maxpct=50 -m uuid=2be5b9cc-beeb-4d54-bbcb-a1cbc5f0ef97 -f -L DIRECTPV /dev/vdb]; output=mkfs.xfs: cannot open /dev/vdb: Device or resource busy │
│                                      │                │       │ ; error=exit status 1                                                                                                                                                                                                            │
└──────────────────────────────────────┴────────────────┴───────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘</code></pre><p>可以通过将此磁盘 <code>umount</code> 来解决。</p>]]></description></item><item>    <title><![CDATA[从 0 到 1：玩转插件 —— 大模型与智能体的能力延伸核心路径 智能猫 ]]></title>    <link>https://segmentfault.com/a/1190000047560491</link>    <guid>https://segmentfault.com/a/1190000047560491</guid>    <pubDate>2026-01-23 12:13:01</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h3>摘要</h3><p>插件作为大模型与智能体突破原生能力边界、实现<strong>场景化功能落地</strong>的核心载体，是从 “通用 AI 能力” 到 “行业专属解决方案” 的关键桥梁。本文从插件的核心定义与价值出发，系统拆解大模型 / 智能体插件的底层工作逻辑，梳理从 0 到 1 的插件认知、选型、使用、定制全流程，详解不同场景下的插件搭配技巧与避坑指南，同时结合行业实操案例给出落地建议，并补充高频 QA 问答解决入门核心痛点，帮助零基础从业者快速掌握插件使用逻辑，实现大模型与智能体的能力最大化延伸，玩转插件生态的核心玩法。​<strong>关键词</strong>​：插件；大模型插件；智能体插件；AI 工具使用；从 0 到 1 学插件；插件定制；AI 能力延伸；智能体生态</p><h3>一、插件的核心认知：大模型与智能体的 “能力扩展卡”</h3><h4>1.1 插件的定义与核心价值</h4><p>插件是为大模型、智能体量身打造的​<strong>模块化功能扩展组件</strong>​，通过标准化接口与大模型 / 智能体核心系统对接，无需改变底层模型架构，即可快速为其新增专属功能、接入外部数据、实现跨平台联动。简单来说，大模型 / 智能体的原生能力是 “通用基础款”，而插件就是 “个性化拓展包”，让 AI 从 “能说会想” 升级为 “能做会干”。</p><p>其核心价值体现在三大维度：</p><ul><li>​<strong>突破能力边界</strong>​：弥补大模型 “知识滞后、计算薄弱、无实操能力” 的短板，比如通过计算器插件解决数学运算、通过翻译插件实现多语种精准转换、通过数据分析插件完成数据可视化；</li><li>​<strong>适配场景落地</strong>​：针对办公、学习、研发、电商等不同场景，提供定制化功能，让通用 AI 适配专属需求，比如自媒体从业者用排版插件、程序员用代码调试插件、运营者用数据统计插件；</li><li>​<strong>降低使用门槛</strong>​：无需掌握 AI 开发技术，普通用户通过一键安装插件，即可让大模型 / 智能体具备专业能力，实现 “零代码玩转高阶 AI”。</li></ul><h4>1.2 插件与大模型、智能体的底层工作逻辑</h4><p>插件与大模型 / 智能体的协作遵循 **“调用 - 执行 - 反馈”** 的闭环逻辑，核心分为三步，零基础也能轻松理解：</p><ol><li>​<strong>需求识别</strong>​：用户向大模型 / 智能体发出指令后，其核心系统先判断原生能力是否能满足，若无法满足则自动匹配已安装的对应插件；</li><li>​<strong>插件调用</strong>​：核心系统通过标准化接口向插件发送执行指令，插件承接需求后完成专属处理（如数据计算、外部查询、功能执行）；</li><li>​<strong>结果反馈</strong>​：插件将处理结果回传给核心系统，由大模型 / 智能体整理成自然语言或可视化结果，反馈给用户。</li></ol><p>整个过程毫秒级完成，用户感知不到底层调用逻辑，仅需发出自然语言指令，即可实现插件功能的无缝使用，这也是插件能快速普及的核心原因。</p><h4>1.3 插件的核心分类：按功能与使用场景划分</h4><p>目前主流的大模型 / 智能体插件生态，按功能属性可分为 6 大类，覆盖绝大多数日常与工作场景，零基础入门可先从高频通用类开始掌握：</p><table><thead><tr><th>插件分类</th><th>核心功能</th><th>典型代表</th><th>适用人群 / 场景</th></tr></thead><tbody><tr><td>通用工具类</td><td>解决基础办公 / 学习需求</td><td>计算器、翻译、思维导图、OCR</td><td>全体用户，日常办公 / 学习</td></tr><tr><td>数据处理类</td><td>数据统计、分析、可视化</td><td>表格分析、数据可视化、SQL 查询</td><td>运营、分析师、财务人员</td></tr><tr><td>内容创作类</td><td>辅助内容生产、优化、排版</td><td>文案润色、图文排版、字幕生成</td><td>自媒体、文案、教师</td></tr><tr><td>研发开发类</td><td>代码编写、调试、漏洞检测</td><td>代码解释、Bug 修复、接口调试</td><td>程序员、开发工程师</td></tr><tr><td>跨平台联动类</td><td>实现 AI 与其他工具的无缝对接</td><td>办公软件、云盘、思维导图工具</td><td>全体用户，多工具协同办公</td></tr><tr><td>行业专属类</td><td>适配特定行业的专业需求</td><td>电商选品、医疗咨询、法律检索</td><td>电商运营、医护、法律从业者</td></tr></tbody></table><h3>二、从 0 到 1：插件使用全流程，新手也能一步到位</h3><h4>2.1 第一步：选对平台 —— 插件生态的核心载体</h4><p>插件的使用依赖于支持插件功能的大模型 / 智能体平台，零基础入门优先选择<strong>插件生态完善、操作门槛低、免费插件多</strong>的主流平台，避免因平台小众导致插件资源少、使用难度高，以下是目前最适合新手的三大主流平台，各有优势：</p><ol><li>​<strong>通用大模型平台</strong>​：ChatGPT（4o 及以上版本）、文心一言 4.0、讯飞星火 V4.0，插件生态完善，覆盖全品类插件，操作界面简洁，一键安装即可使用，适合全场景需求；</li><li>​<strong>智能体专属平台</strong>​：Coze、LangChain Bot，主打智能体插件联动，支持插件自定义编排，适合需要多插件协同完成复杂任务的场景；</li><li>​<strong>办公类 AI 平台</strong>​：WPS AI、飞书智谱，插件与办公软件深度融合，主打办公场景专属插件，适合职场办公人群。</li></ol><p>​<strong>新手建议</strong>​：优先从 ChatGPT 或文心一言入手，插件资源最丰富，操作最简洁，能快速完成从 0 到 1 的插件使用入门。</p><h4>2.2 第二步：插件选型 —— 按需选择，拒绝盲目安装</h4><p>插件并非越多越好，盲目安装大量插件会导致大模型 / 智能体响应变慢、匹配插件出错，零基础入门的核心原则是 **“刚需优先、少而精”**，按 “场景 - 需求 - 插件” 的逻辑选型，具体步骤：</p><ol><li>​<strong>明确使用场景</strong>​：确定自己使用大模型 / 智能体的核心场景，比如是日常办公、自媒体创作，还是编程开发；</li><li>​<strong>梳理核心需求</strong>​：从场景中提炼需要解决的具体问题，比如办公场景需要 “PDF 解析、表格制作”，创作场景需要 “文案润色、图文排版”；</li><li>​<strong>匹配对应插件</strong>​：根据需求选择功能精准的插件，比如 PDF 解析选专属 OCR 插件，文案润色选内容创作类插件，避免一个需求安装多个同类插件。</li></ol><p>​<strong>新手避坑</strong>​：同一功能的插件只需安装 1-2 个即可，比如翻译插件无需同时安装百度翻译、谷歌翻译、DeepL 翻译，选择适配自己使用习惯的一款即可。</p><h4>2.3 第三步：基础使用 —— 一键安装，三步玩转核心功能</h4><p>主流平台的插件操作均实现​<strong>可视化、零代码</strong>​，零基础用户无需掌握任何技术，只需三步即可完成插件的安装与使用，以通用大模型平台为例，操作流程高度统一：</p><ol><li>​<strong>插件市场入口</strong>​：登录平台后，在侧边栏或设置中找到「插件市场 / 应用中心」，这是所有插件的集中入口；</li><li>​<strong>一键安装插件</strong>​：在插件市场中搜索需要的插件，点击「安装 / 启用」，平台会自动完成接口对接，安装完成后插件会出现在「已安装插件」列表中；</li><li>​<strong>自然语言调用</strong>​：无需额外操作，直接向大模型 / 智能体发出自然语言指令，系统会自动匹配插件执行，比如安装了计算器插件后，直接说 “计算 10000 元按年化 3.5% 计息，存 5 年的复利是多少”，系统会自动调用插件计算并给出结果。</li></ol><p>​<strong>小技巧</strong>​：若系统未自动匹配插件，可在指令中明确提及插件名称，比如 “用思维导图插件把《从 0 到 1 玩转插件》的核心框架做成思维导图”，提升插件调用精准度。</p><h4>2.4 第四步：进阶搭配 —— 多插件协同，实现复杂任务落地</h4><p>当掌握单一插件的使用后，可通过​<strong>多插件协同搭配</strong>​，让大模型 / 智能体完成更复杂的场景化任务，这是 “玩转插件” 的核心进阶技巧。多插件搭配的核心逻辑是 **“按任务流程拆解，依次匹配插件”**，举 3 个高频场景的经典搭配案例，新手可直接照搬：</p><h5>案例 1：办公场景 —— 快速完成一份市场分析报告</h5><p>​<strong>任务流程</strong>​：解析市场调研 PDF 数据 → 整理成表格 → 进行数据可视化 → 生成分析报告​<strong>插件搭配</strong>​：PDF 解析插件（OCR）+ 表格分析插件 + 数据可视化插件 + 文案创作插件​<strong>使用指令</strong>​：“用 PDF 解析插件提取这份市场调研文件的核心数据，用表格分析插件整理成销售数据表格，再用数据可视化插件生成柱状图，最后用文案创作插件基于数据生成一份 500 字的市场分析报告”</p><h5>案例 2：创作场景 —— 打造一篇自媒体爆款推文</h5><p>​<strong>任务流程</strong>​：生成推文选题 → 撰写推文文案 → 优化排版 → 生成配图思路​<strong>插件搭配</strong>​：选题生成插件 + 文案润色插件 + 图文排版插件 + 创意设计插件​<strong>使用指令</strong>​：“用选题生成插件给美妆品类生成 3 个小红书爆款选题，选其中一个用文案润色插件撰写 800 字推文，用图文排版插件优化排版格式，最后用创意设计插件给出推文配图思路”</p><h5>案例 3：研发场景 —— 快速调试一段 Python 代码</h5><p>​<strong>任务流程</strong>​：检查代码漏洞 → 修复 Bug→ 解释代码逻辑 → 生成注释​<strong>插件搭配</strong>​：代码检测插件 + Bug 修复插件 + 代码解释插件 + 注释生成插件​<strong>使用指令</strong>​：“用代码检测插件检查这段 Python 代码的漏洞，用 Bug 修复插件修正错误，用代码解释插件逐行说明逻辑，最后用注释生成插件为代码添加标准注释”</p><h4>2.5 第五步：高阶定制 —— 打造专属插件，适配个性化需求</h4><p>当现有插件无法满足专属需求时，可尝试​<strong>插件定制</strong>​，目前主流平台均提供​<strong>低代码 / 零代码插件定制工具</strong>​，零基础用户也能从 0 到 1 打造自己的专属插件，核心流程分为 4 步，无需掌握复杂开发技术：</p><ol><li>​<strong>明确定制需求</strong>​：确定专属插件的核心功能、使用场景、输入输出要求，比如定制一款 “电商商品标题优化插件”，核心功能是根据商品属性生成高点击率标题；</li><li>​<strong>选择定制平台</strong>​：优先选择平台自带的插件定制工具，如 ChatGPT 的 Plugin Builder、文心一言的插件开发平台，无需对接复杂接口，可视化操作；</li><li>​<strong>配置插件功能</strong>​：在定制工具中，通过拖拽、选择、填写参数的方式，配置插件的核心功能，比如为电商标题插件设置 “商品属性输入框、标题风格选择（简约 / 爆款 / 专业）、标题字数限制” 等；</li><li>​<strong>测试与发布</strong>​：完成配置后，进行多次测试，验证插件功能是否符合预期，测试通过后即可发布到自己的插件列表，实现专属使用，部分平台还支持将定制插件分享到插件市场。</li></ol><p>​<strong>新手建议</strong>​：入门阶段先从<strong>简单功能插件</strong>开始定制，比如 “专属话术生成插件”“日常打卡插件”，熟悉定制逻辑后，再尝试复杂功能插件。</p><h3>三、插件使用的核心避坑指南：新手少走 90% 的弯路</h3><p>从 0 到 1 玩转插件，不仅要会用，更要会​<strong>避坑</strong>​，结合大量新手实操案例，梳理出 6 个最易踩的坑，以及对应的解决方案，帮新手快速避开误区：</p><h4>3.1 坑 1：盲目安装大量插件，导致系统响应变慢</h4><p>​<strong>问题</strong>​：认为插件越多功能越全，安装数十个同类插件，导致大模型 / 智能体匹配插件时耗时增加，响应变慢，甚至出现插件冲突。​<strong>解决方案</strong>​：遵循 “​<strong>刚需安装、定期清理</strong>​” 原则，仅安装当前场景需要的插件，每 1-2 周清理一次未使用的插件，保持已安装插件列表简洁。</p><h4>3.2 坑 2：忽略插件权限，导致数据安全风险</h4><p>​<strong>问题</strong>​：安装插件时随意授权，部分插件会请求访问用户的聊天记录、上传文件、个人数据等权限，导致数据泄露风险。​<strong>解决方案</strong>​：安装插件前​<strong>必看权限说明</strong>​，拒绝授权与插件功能无关的权限，比如一款计算器插件若请求访问聊天记录，直接拒绝安装；优先选择平台官方开发的插件，第三方插件需确认资质后再安装。</p><h4>3.3 坑 3：指令描述模糊，导致插件调用失败</h4><p>​<strong>问题</strong>​：向大模型 / 智能体发出的指令过于模糊，系统无法准确匹配插件，比如只说 “帮我处理这份数据”，未说明具体处理需求。​<strong>解决方案</strong>​：指令描述遵循 **“场景 + 需求 + 插件”** 的三要素原则，明确告知系统要做什么、用什么插件做，比如 “在电商场景下，帮我用选品插件分析抖音美妆类目的爆款商品数据”。</p><h4>3.4 坑 4：过度依赖插件，忽视大模型原生能力</h4><p>​<strong>问题</strong>​：任何需求都想通过插件解决，即使大模型原生能力能轻松完成，比如用翻译插件翻译简单的日常语句，反而增加操作成本。​<strong>解决方案</strong>​：先判断​<strong>需求是否需要插件</strong>​，大模型原生的自然语言理解、文案创作、逻辑分析等能力能解决的问题，无需调用插件，让插件成为 “补充能力” 而非 “唯一能力”。</p><h4>3.5 坑 5：未及时更新插件，导致功能失效</h4><p>​<strong>问题</strong>​：插件安装后长期不更新，当大模型 / 智能体平台升级或插件底层功能调整时，出现插件调用失败、功能失效的问题。​<strong>解决方案</strong>​：开启插件的​<strong>自动更新功能</strong>​，或定期在插件市场检查已安装插件的更新状态，及时更新至最新版本，保证插件功能正常使用。</p><h4>3.6 坑 6：多插件搭配逻辑混乱，导致任务执行出错</h4><p>​<strong>问题</strong>​：多插件协同时，未按任务流程合理搭配，插件顺序混乱，导致系统无法按预期执行，比如先让数据可视化插件生成图表，再让 PDF 解析插件提取数据。​<strong>解决方案</strong>​：多插件搭配前，先​<strong>梳理任务的先后流程</strong>​，按 “先输入、再处理、最后输出” 的逻辑匹配插件，确保插件调用顺序与任务流程一致，避免逻辑混乱。</p><h3>四、插件生态的未来发展趋势：大模型与智能体的核心竞争力</h3><p>插件作为大模型与智能体实现 **“能力落地、生态繁荣”** 的核心载体，其发展趋势与大模型、智能体的技术迭代深度绑定，未来三大发展方向值得关注，也是新手玩转插件需要提前布局的重点：</p><h4>4.1 插件轻量化：零代码定制成为主流，全民可造插件</h4><p>未来插件的开发门槛将持续降低，<strong>低代码 / 零代码</strong>定制工具将成为行业标配，不仅专业开发者能打造插件，普通用户也能通过简单的参数配置、功能拖拽，打造自己的专属插件，实现 “全民造插件” 的生态格局，插件将从 “专业产品” 变为 “个人化工具”。</p><h4>4.2 插件智能化：智能体自主完成插件编排与适配</h4><p>大模型与智能体的能力持续升级，未来将具备​<strong>自主插件编排能力</strong>​—— 用户只需发出核心需求，无需指定插件，智能体就能根据任务逻辑，自主选择、搭配、调用插件，完成复杂任务。比如用户说 “帮我完成一份年度销售总结”，智能体将自主匹配数据提取、表格分析、可视化、文案创作等插件，全程无需人工干预。</p><h4>4.3 插件生态化：跨平台插件互联互通，形成全域能力网络</h4><p>不同大模型、智能体平台的插件生态将从 “孤立发展” 走向 “互联互通”，通过标准化的插件接口，实现跨平台插件的无缝调用，比如在智能体平台可直接调用大模型的办公插件，在办公软件中可直接调用智能体的行业插件，形成覆盖全场景、跨平台的​<strong>插件能力网络</strong>​，让 AI 的能力延伸到每一个工作与生活场景。</p><h3>五、行业高频 QA 问答</h3><h4>5.1 零基础新手，先从哪类插件开始学习使用最合适？</h4><p>优先从<strong>通用工具类插件</strong>入手，比如计算器、翻译、PDF 解析、思维导图插件。这类插件功能简单、使用频率高、适配全场景，无需专业知识就能快速上手，能帮助新手快速熟悉插件的安装、调用逻辑，建立使用信心，掌握后再逐步拓展到内容创作、数据处理等专项插件。</p><h4>5.2 免费插件和付费插件的区别是什么，新手需要付费购买插件吗？</h4><p>核心区别在于​<strong>功能精准度、使用限制、专属服务</strong>​：免费插件能满足基础需求，部分存在使用次数、功能简化的限制；付费插件功能更精准、无使用限制，部分还提供专属售后与定制化优化。新手​<strong>无需过早付费</strong>​，目前主流平台的免费插件已能覆盖 90% 的日常与工作需求，建议先通过免费插件掌握使用逻辑，当现有免费插件无法满足核心工作需求时，再针对性购买付费插件。</p><h4>5.3 不同大模型 / 智能体平台的插件可以互通使用吗？</h4><p>目前多数平台的插件​<strong>暂不支持直接互通</strong>​，因各平台的插件接口标准、底层逻辑存在差异，比如 ChatGPT 的插件无法直接在文心一言中使用。但未来随着行业标准化推进，跨平台插件互联互通将成为趋势，现阶段若需要在多个平台使用同类功能，可在各平台分别安装对应的同款或同类插件。</p><h4>5.4 安装插件后，大模型 / 智能体的响应速度变慢，该怎么解决？</h4><p>可按以下步骤逐一排查解决：1. 清理未使用的插件，卸载同类冗余插件，减少插件匹配压力；2. 检查插件是否为最新版本，及时更新失效插件；3. 若使用多插件协同，尝试拆分任务，单次仅调用 1-2 个插件，避免同时调用大量插件；4. 关闭平台后台无关程序，保证网络通畅，提升接口传输速度。</p><h4>5.5 如何判断一款插件是否适合自己，有没有核心筛选标准？</h4><p>核心筛选标准有 4 点：1. ​<strong>功能匹配</strong>​：插件核心功能与自己的核心需求高度契合，无多余无效功能；2. ​<strong>操作简单</strong>​：零基础能快速上手，无需复杂的参数配置；3. ​<strong>权限安全</strong>​：插件请求的权限与功能匹配，无过度授权；4. ​<strong>口碑良好</strong>​：在插件市场中评分高、评论正面，官方开发或第三方资质可靠，避免使用小众无资质插件。</p><h4>5.6 新手可以尝试开发插件吗，需要掌握哪些基础技能？</h4><p>新手可以尝试，目前主流平台的​<strong>低代码 / 零代码定制工具</strong>​，让零基础用户也能开发简单插件，无需掌握复杂的编程技术。若仅做基础定制，只需掌握​<strong>需求梳理能力</strong>​，能明确插件的功能、使用场景即可；若想开发更复杂的插件，可逐步学习简单的编程基础（如 Python）、API 接口知识，提升定制能力。</p><h3>六、结论</h3><p>从 0 到 1 玩转插件，本质是掌握​<strong>大模型与智能体的能力延伸逻辑</strong>​—— 插件并非简单的 “功能工具”，而是让通用 AI 技术落地到具体场景的核心桥梁。对于零基础从业者而言，无需畏惧技术门槛，从核心认知入手，按 “选型 - 安装 - 使用 - 搭配 - 定制” 的全流程逐步推进，避开盲目安装、权限泄露、指令模糊等核心误区，就能快速掌握插件的核心玩法。</p><p>插件生态的发展，正推动大模型与智能体从 “通用能力” 向 “个性化、场景化能力” 升级，未来随着插件的轻量化、智能化、生态化发展，插件将成为每一个 AI 使用者的必备工具。新手只需从当下开始，从一款插件、一个场景入手，边用边学、边练边进阶，就能在插件生态中找到适合自己的使用方法，真正实现 “玩转插件”，让大模型与智能体成为工作与生活的高效助手，释放 AI 的最大价值。</p><h3>参考文献</h3><p>[1] 斯坦福大学. AI 指数报告 2026 [R]. 斯坦福大学人类与人工智能研究院，2026.  <br/>[2] 中国人工智能产业发展联盟。大模型插件生态建设与应用指南 2026 [R]. 2026.  <br/>[3] 字节跳动 AI 实验室. Coze 智能体插件平台开发与使用手册 2026 [R]. 2026.  <br/>[4] OpenAI 官方文档. ChatGPT Plugin 开发与使用指南 [Z]. 2026.  <br/>[5] 百度 AI 研究院。文心一言插件生态与场景落地实践 2026 [R]. 2026.  <br/>[6] 知乎科技研究院. 2026 年 AI 插件使用行为分析报告 [R]. 2026.</p>]]></description></item><item>    <title><![CDATA[2026 年 5 款主流 CRM 系统全景对比：ToB 获客转化核心能力全维度拆解 正直的炒饭 ]]></title>    <link>https://segmentfault.com/a/1190000047560502</link>    <guid>https://segmentfault.com/a/1190000047560502</guid>    <pubDate>2026-01-23 12:12:29</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在toB市场， <strong>“获客精准度”“转化效率”“数据协同”是企业增长的三大核心痛点。传统销售模式下，线索分散、跟单无标准、数据割裂等问题，往往导致“获客成本高、转化漏斗漏损大”。而CRM系统作为toB企业的“增长引擎”，其核心价值在于通过全流程闭环能力</strong>，将“精准获客-数据治理-智能跟单-目标落地-复盘优化”串联，最终实现“从线索到现金”的高效转化。</p><p>本文将围绕<strong>toB企业获客-转化闭环的六大关键能力</strong>（工商搜客精准获客、客户查重与工商信息补全、AI跟单智能体推进商机、销售目标管理、自动日报与行动记录分析、全流程闭环整合），对<strong>超兔一体云、SAP、Microsoft Dynamics 365、Salesforce、销售易</strong>等主流CRM品牌展开深度横向对比，并通过图表具象化各品牌的优劣势，为企业选型提供参考。</p><ul><li><ul><li>*</li></ul></li></ul><h2>一、关键能力框架解析：toB获客-转化闭环的底层逻辑</h2><p>toB获客-转化闭环的本质，是“数据驱动+流程自动化+AI赋能”的组合拳。以下是六大关键能力的定义与价值：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560504" alt="" title=""/></p><p>暂时无法在飞书文档外展示此内容</p><ul><li><ul><li>*</li></ul></li></ul><h2>二、六大关键能力横向对比：品牌优劣势深度拆解</h2><p>以下从<strong>功能定义、品牌表现、差异点</strong>三个层面，对各品牌的关键能力展开对比。</p><h3>1. 工商搜客精准获客：toB企业的“精准获客手术刀”</h3><p><strong>定义</strong>：针对toB企业需求，基于工商数据库（企业名称、经营范围、注册信息等）筛选潜在客户的专属工具，核心解决“线索精准度”问题。</p><table><thead><tr><th>品牌</th><th>能力表现</th><th>核心优势</th></tr></thead><tbody><tr><td><strong>超兔一体云</strong></td><td>toB专用工商搜客，整合工商数据库，支持行业/规模/地域筛选；一键加线索并自动获取归属地，线索分配自动提醒</td><td>toB专属，精准匹配工商特征</td></tr><tr><td>SAP</td><td>未明确提及原生“工商搜客”，通过端到端流程自动化覆盖线索捕获，整合工商与ERP数据辅助谈单</td><td>适合已有ERP的中大型企业</td></tr><tr><td>Microsoft Dynamics 365</td><td>多渠道线索捕获（官网/社交媒体/线下）+工商信息补全，Copilot AI生成销售趋势见解辅助获客</td><td>生态整合+AI分析</td></tr><tr><td>Salesforce</td><td>Sales Cloud整合多渠道线索，Einstein Analytics纳入工商维度（行业/规模）筛选高价值客户</td><td>AI画像精准度高</td></tr><tr><td>销售易</td><td>未明确提及“工商搜客”，支持多渠道线索接入，通过“老客商机挖掘”激活沉睡客户</td><td>复购商机挖掘能力强</td></tr></tbody></table><p><strong>差异点</strong>： 超兔一体云是唯一明确提及“toB专用工商搜客”的品牌，直接命中toB企业“找对客户”的核心需求；而SAP、Dynamics 365等品牌更侧重“线索捕获后的流程整合”，需依赖外部数据补充工商信息。</p><h3>2. 客户查重与工商信息补全：数据治理的“地基”</h3><p><strong>定义</strong>：通过查重规则避免重复客户录入，自动补全工商背景信息（注册资本、成立时间、经营范围等），构建统一客户视图。</p><table><thead><tr><th>品牌</th><th>能力表现</th><th>核心优势</th></tr></thead><tbody><tr><td><strong>超兔一体云</strong></td><td>支持客户名/手机号查重，企业客户自动简称模糊查重；自动补全工商信息（天眼查/百度），手机号获取微信头像，地址标记经纬度</td><td>自动模糊查重+多维度信息补全</td></tr><tr><td>SAP</td><td>整合工商信息与ERP数据（库存/应收账款），构建360°视图，联动供应链辅助谈单</td><td>ERP数据协同</td></tr><tr><td>Microsoft Dynamics 365</td><td>360°客户视图整合工商与历史互动，支持查重与补全，GDPR合规保障数据安全</td><td>数据隐私保护</td></tr><tr><td>Salesforce</td><td>内置重复客户检测规则，支持自定义字段补全工商信息（统一社会信用代码/法定代表人）</td><td>灵活性高</td></tr><tr><td>销售易</td><td>360°全生命周期客户管理，客户信息集中管理，未明确提及工商补全</td><td>全生命周期覆盖</td></tr></tbody></table><p><strong>差异点</strong>： 超兔一体云“自动简称模糊查重”是特色（如“阿里”与“阿里巴巴”自动识别为同一客户），解决了toB企业“客户名称简称多”的痛点；而Dynamics 365的GDPR合规能力，更适合有海外业务的企业。</p><h3>3. AI跟单智能体推进商机：转化效率的“加速器”</h3><p><strong>定义</strong>：嵌入销售流程的AI助手，通过分析业务数据（客户历史、跟单阶段），提供个性化跟单建议，推动商机向成交转化。</p><table><thead><tr><th>品牌</th><th>能力表现</th><th>核心优势</th></tr></thead><tbody><tr><td><strong>超兔一体云</strong></td><td>低门槛自定义AI智能体，嵌入客户/机会/项目视图，自动获取业务数据作为入参；支持小单快单/商机跟单/多方项目模型</td><td>业务场景深度融合</td></tr><tr><td>Microsoft Dynamics 365</td><td>Copilot AI生成邮件草稿/会议摘要，用BANT模型（预算/权限/需求/时间）评估商机优先级</td><td>流程标准化+AI分析</td></tr><tr><td>Salesforce</td><td>Einstein GPT提供智能话术推荐、商机优先级排序，自动生成跟进提醒；Einstein Analytics预测购买意图</td><td>AI深度融入销售流程</td></tr><tr><td>销售易</td><td>AI Native CRM，NeoAgent智能体+Customer Data Cloud（融合腾讯混元大模型），商机预测误差率＜5%</td><td>AI原生+复购商机挖掘</td></tr><tr><td>SAP</td><td>无原生AI智能体，需集成第三方工具（如SAP AI Business Services）实现智能跟进</td><td>生态兼容</td></tr></tbody></table><p><strong>差异点</strong>： 超兔一体云的“低门槛自定义智能体”（无需代码即可嵌入业务视图），适合中小企业快速落地；Salesforce的Einstein GPT更侧重“智能话术与提醒”；销售易的NeoAgent则针对“复购商机”优化，适合需要提升老客价值的企业。</p><h3>4. 销售目标管理：业绩落地的“导航仪”</h3><p><strong>定义</strong>：将企业战略目标拆解为部门/个人/阶段目标，实时监控进度，确保销售动作与目标对齐。</p><table><thead><tr><th>品牌</th><th>能力表现</th><th>核心优势</th></tr></thead><tbody><tr><td><strong>超兔一体云</strong></td><td>支持年度/季度/月度目标设定，逐层分解到部门/个人；实时监控目标完成率，图表化展示</td><td>目标分解颗粒度细</td></tr><tr><td>SAP</td><td>多维度业绩追踪（区域/产品/团队），可视化销售漏斗管理商机阶段</td><td>复杂流程适配</td></tr><tr><td>Microsoft Dynamics 365</td><td>Power BI实现目标可视化，实时监控团队进度，自动生成差距分析</td><td>数据可视化能力强</td></tr><tr><td>Salesforce</td><td>目标管理工具设定团队/个人目标（成交额/新增客户数），销售云报表实时监控进度</td><td>灵活性高</td></tr><tr><td>销售易</td><td>目标分解到部门/个人/业务环节，结合成本分析与交易自动化（报价到签约）</td><td>目标与流程联动</td></tr></tbody></table><p><strong>差异点</strong>： 超兔一体云的“逐层分解+实时监控”更贴近中小企业“目标落地”的需求；而Dynamics 365的Power BI与Salesforce的销售云报表，更适合需要“数据可视化”的中大型企业。</p><h3>5. 自动日报与行动记录分析：复盘优化的“后视镜”</h3><p><strong>定义</strong>：自动总结当日工作内容，记录销售行动轨迹（拜访/电话/邮件），分析行动效果，辅助优化销售策略。</p><table><thead><tr><th>品牌</th><th>能力表现</th><th>核心优势</th></tr></thead><tbody><tr><td><strong>超兔一体云</strong></td><td>自动分析客户沟通/报价/订单数据，生成含“销售概述/意向评估/卡单问题”的专业日报；记录行动轨迹，分析工作效率并提供个性化建议</td><td>日报内容深度+行动分析精准</td></tr><tr><td>Microsoft Dynamics 365</td><td>自动生成日报与行动记录，Copilot AI总结关键行动与待办事项</td><td>AI辅助复盘</td></tr><tr><td>Salesforce</td><td>销售云报表自动记录活动，生成日报，分析跟进效率/沟通效果</td><td>与销售流程深度联动</td></tr><tr><td>SugarCRM</td><td>自动记录电话/邮件/任务，生成日报，分析跟进频率/沟通内容</td><td>开源定制灵活</td></tr><tr><td>SAP</td><td>未明确提及相关功能</td><td>-</td></tr></tbody></table><p><strong>差异点</strong>： 超兔一体云的“卡单问题点”是日报的核心亮点——不仅总结工作，更直接指出“阻碍转化的关键问题”，帮助销售快速定位改进方向；而Dynamics 365、Salesforce等品牌的日报更侧重“行动记录”，需手动分析问题。</p><h3>6. 全流程闭环整合：增长飞轮的“发动机”</h3><p><strong>定义</strong>：将“获客-查重-跟单-目标-复盘”各环节数据打通，实现“线索进、现金出”的循环，最终驱动复购与转介绍。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560505" alt="" title="" loading="lazy"/></p><p>暂时无法在飞书文档外展示此内容</p><table><thead><tr><th>品牌</th><th>闭环能力表现</th><th>核心优势</th></tr></thead><tbody><tr><td><strong>超兔一体云</strong></td><td>工商搜客→线索分配→AI跟单→目标监控→自动复盘→复购，全环节数据打通，无信息断层</td><td>闭环链路最短</td></tr><tr><td>Microsoft Dynamics 365</td><td>多渠道获客→Copilot AI分析→商机推进→Power BI监控→自动复盘，生态整合完善</td><td>生态协同能力强</td></tr><tr><td>Salesforce</td><td>多渠道线索→Einstein画像→智能跟单→目标管理→销售云复盘，AI深度赋能</td><td>AI驱动闭环</td></tr><tr><td>销售易</td><td>多渠道线索→AI商机预测→智能跟单→目标分解→BI分析，复购商机挖掘能力强</td><td>复购闭环优化</td></tr><tr><td>SAP</td><td>线索捕获→ERP联动→流程自动化→目标追踪，适合复杂供应链场景</td><td>大型企业流程适配</td></tr></tbody></table><p><strong>差异点</strong>： 超兔一体云的闭环“更聚焦toB中小微企业”，环节简洁、易落地；而Dynamics 365、Salesforce的闭环更侧重“生态整合与AI深度”，适合需要数字化转型的中大型企业。</p><ul><li><ul><li>*</li></ul></li></ul><h2>三、综合能力对比：雷达图与选型建议</h2><h3>1. 雷达图评分（1-5分，5分为最优）</h3><table><thead><tr><th>维度</th><th>超兔一体云</th><th>SAP</th><th>Microsoft Dynamics 365</th><th>Salesforce</th><th>销售易</th></tr></thead><tbody><tr><td>工商搜客精准获客</td><td>5</td><td>3</td><td>4</td><td>4</td><td>3</td></tr><tr><td>客户查重与工商补全</td><td>5</td><td>4</td><td>5</td><td>4</td><td>4</td></tr><tr><td>AI跟单智能体</td><td>5</td><td>2</td><td>4</td><td>5</td><td>4</td></tr><tr><td>销售目标管理</td><td>4</td><td>4</td><td>4</td><td>4</td><td>4</td></tr><tr><td>自动日报与行动分析</td><td>5</td><td>1</td><td>4</td><td>4</td><td>3</td></tr><tr><td>全流程闭环整合</td><td>5</td><td>4</td><td>5</td><td>5</td><td>4</td></tr></tbody></table><h3>2. 选型建议</h3><table><thead><tr><th>企业需求</th><th>推荐品牌</th><th>理由</th></tr></thead><tbody><tr><td>需精准工商获客+低门槛AI跟单</td><td>超兔一体云</td><td>唯一toB专用工商搜客，AI智能体嵌入业务视图，自动日报直接点出卡单问题</td></tr><tr><td>已有ERP系统+复杂流程整合</td><td>SAP</td><td>端到端流程自动化，工商与ERP数据联动，适合中大型企业</td></tr><tr><td>注重AI赋能+生态整合</td><td>Microsoft Dynamics 365/Salesforce</td><td>Dynamics 365的Copilot AI+Power BI；Salesforce的Einstein系列+AppExchange生态</td></tr><tr><td>需提升复购率+AI原生能力</td><td>销售易</td><td>NeoAgent智能体+老客商机挖掘，AI Native CRM适配复购场景</td></tr><tr><td>依赖社交渠道获客</td><td>钉钉CRM/腾讯企点CRM</td><td>钉钉集成聊天/审批；腾讯企点覆盖微信生态，适合社交化获客</td></tr></tbody></table><ul><li><ul><li>*</li></ul></li></ul><h2>四、结论：toB CRM的“增长逻辑”</h2><p>从对比中可见，toB CRM的核心竞争力已从“流程记录”转向“精准获客+智能转化+闭环优化”。超兔一体云的“工商搜客+自动日报”、Salesforce的“Einstein AI”、Dynamics 365的“生态整合”，分别代表了不同企业的需求侧重。</p><p>对于toB企业而言，<strong>选型的关键不是“选最知名的”，而是“选最贴合自身业务场景的”</strong> ——中小微企业需优先考虑“精准获客与易落地”，中大型企业需侧重“生态整合与AI深度”，而复购型企业则应关注“老客商机挖掘”。</p><p>未来，toB CRM的趋势将是“更垂直的行业适配+更深度的AI嵌入+更短的闭环链路”。谁能解决“找对客户、跟对流程、算清账”的核心问题，谁就能成为企业增长的“引擎”。</p><ul><li><ul><li>*</li></ul></li></ul><p><strong>附录</strong>：关键能力对比表格（完整版）</p><table><thead><tr><th>品牌</th><th>工商搜客精准获客</th><th>客户查重与工商补全</th><th>AI跟单智能体</th><th>销售目标管理</th><th>自动日报与行动分析</th><th>全流程闭环整合</th></tr></thead><tbody><tr><td>超兔一体云</td><td>是（toB专用）</td><td>是（自动模糊查重）</td><td>是（低门槛自定义）</td><td>是（逐层分解）</td><td>是（含卡单问题）</td><td>是（全环节打通）</td></tr><tr><td>SAP</td><td>否（流程覆盖）</td><td>是（ERP联动）</td><td>否（需集成）</td><td>是（多维度追踪）</td><td>否</td><td>是（复杂流程）</td></tr><tr><td>Microsoft Dynamics 365</td><td>否（多渠道+补全）</td><td>是（GDPR合规）</td><td>是（Copilot AI）</td><td>是（Power BI）</td><td>是（AI辅助）</td><td>是（生态整合）</td></tr><tr><td>Salesforce</td><td>否（AI画像）</td><td>是（自定义字段）</td><td>是（Einstein GPT）</td><td>是（目标工具）</td><td>是（销售云报表）</td><td>是（AI驱动）</td></tr><tr><td>销售易</td><td>否（多渠道）</td><td>是（360°视图）</td><td>是（NeoAgent）</td><td>是（分解+成本）</td><td>否（BI分析）</td><td>是（复购优化）</td></tr><tr><td>钉钉CRM</td><td>否</td><td>否</td><td>否</td><td>否</td><td>否</td><td>是（协同优先）</td></tr></tbody></table><p>（注：“是”代表明确具备该能力，“否”代表未明确提及或需集成第三方工具。）</p><p>（注：文中功能相关描述均基于公开披露信息，具体功能服务与价格以厂商实际落地版本为准。）</p>]]></description></item><item>    <title><![CDATA[OceanBase联合研究成果：三层协同，让数据在混合内存中“各得其所” OceanBase技术站 ]]></title>    <link>https://segmentfault.com/a/1190000047560513</link>    <guid>https://segmentfault.com/a/1190000047560513</guid>    <pubDate>2026-01-23 12:11:30</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h3>摘要</h3><p><strong><em>随着数据密集型应用的快速发展，哈希索引已成为内存数据库、键值存储和重复数据删除系统的核心组件。传统哈希索引在面对持久内存（PMem）时，由于存储流量放大和内存效率低下，难以充分利用其大容量和持久性优势。为此，OceanBase研究人员联合厦门大学、昆士兰大学学生及教授提出了一种新型哈希索引设计MetoHash，通过层次化设计、批量持久、指纹过滤和重复合并等技术，有效解决了传统方案在存储 I/O 放大和内存效率方面的问题。</em></strong></p><h3>简介</h3><p>随着数据密集型应用的快速增长，能够实现常数级查找复杂度的哈希索引已成为构建内存数据库、键值存储和重复数据删除系统的核心组件。传统哈希索引在面对新兴的持久内存时，虽然利用了其大容量和数据持久性优势，却在存储流量放大和内存效率方面面临严峻挑战。</p><p>持久内存以其大容量、数据持久性、近 DRAM 性能等特性，为内存架构带来革命性变革。然而，PMem 的固定访问粒度和持久化 CPU 缓存特性，使得传统哈希索引设计难以充分发挥其硬件潜力，其原因在于现有方案极易放大存储 I/O 或降低内存效率。</p><p>日前，一篇题为《MetoHash: A Memory-Efficient and Traffic-Optimized Hashing Index on Hybrid PMem-DRAM Memories》的论文被高性能计算顶级会议SC 2025录用，并荣获最佳学生论文提名（该会议录用的 136 篇论文中选择 6 篇）。该论文由厦门大学、昆士兰大学与 OceanBase 的研究人员联合完成。其中，厦门大学硕士生余子祥、邓光阳为共同第一作者，沈志荣教授为通讯作者；昆士兰大学鲍芝峰教授，以及 OceanBase 的徐泉清、杨传辉研究员共同参与了此项研究。</p><p>SC 由美国计算机协会（ACM）与美国电气电子工程师学会（IEEE）于 1988 年共同创办，是全球高性能计算领域公认的年度顶级盛会，是中国计算机学会 CCF 推荐的 A 类国际会议。SC 2025 会议共收到 643 篇投稿，接收 136 篇，录用率 21.2%。</p><p>本论文的核心思想是构建一个跨越 CPU 缓存、DRAM 和 PMem 的三层索引架构，让数据在层次化存储中高效流动。</p><p>本文提出的 MetoHash 通过层次化设计、批量持久、指纹过滤、重复合并等关键技术，系统性地解决了现有方案在流量放大与内存效率上的痛点，为高性能键值存储、内存数据库、实时分析等应用提供了强大的底层支撑。</p><h3>核心理念：三层协同，让数据在混合内存中“各得其所”</h3><p>传统哈希索引在面对由持久内存（PMem）和动态随机存取内存（DRAM）构成的混合内存系统时，面临一个根本性矛盾：若为追求 PMem 的持久性而将索引完全置于其中，则会因 PMem 较高的访问延迟和固定的写入粒度导致严重的性能下降和 I/O 放大；若为追求速度而将索引完全置于 DRAM，则又无法利用 PMem 的大容量和持久化优势。</p><p>MetoHash 的创新核心理念在于“解耦与协同”。它不再将哈希索引视为一个单一的整体，而是将其功能拆解，并根据 CPU 缓存、DRAM 和 PMem 的不同硬件特性进行重新部署，构建了一个三层的高效数据管理流水线。其目标是让热数据、元数据和海量持久化数据分别在最适合的存储层级上被处理，从而在整体上实现高吞吐、低延迟、低流量和高内存效率的统一。</p><p><img width="723" height="333" referrerpolicy="no-referrer" src="/img/bVdnIO7" alt="" title=""/><br/>图1 MetoHash 的三层索引结构</p><h3>核心技术一：缓存辅助的批量收集写入</h3><p>此技术旨在根治向 PMem 进行小粒度插入时引发的“写放大”（Write Amplification）与频繁桶探测问题。其方案是在持久性 CPU 缓存中预分配多个与 PMem 访问粒度对齐的“收集表”（Collecting Table）。新到达的键值对根据哈希值被直接路由到相应收集表，并通过原子操作实现无锁快速插入，从而充分利用缓存的高速与持久化特性。当一个收集表被填满时，其包含的多个键值对将作为一个完整的、与 PMem 最佳写入粒度匹配的数据单元，被一次性顺序刷写到 PMem 的备份日志中。这种方法彻底消除了因写入粒度不匹配带来的额外 I/O 流量，充分利用 PMem 的写入带宽，同时将零散插入转化为高效批量操作。</p><p><img width="723" height="363" referrerpolicy="no-referrer" src="/img/bVdnIO8" alt="" title="" loading="lazy"/><br/>图2 持久缓存刷入 DRAM 和 PMem 中</p><h3>核心技术二：基于 DRAM 指纹的反向精准查找</h3><p>该技术致力于解决在混合多层索引中查询时在 PMem 层进行盲目、耗时的桶探测的瓶颈。其核心是在 DRAM 中维护一个紧凑的“指纹”目录，其本质为 PMem 主哈希表中的每个键哈希值的一个简短片段。</p><p>在进行查询时，系统首先计算查询键的指纹，并利用 SIMD 指令等在 DRAM 指纹目录中进行高速并行比对，迅速筛选出 PMem 中少数几个可能匹配的位置。只有这些候选位置，才需要访问 PMem 进行精确的键值比较。整个查询遵循 PMem 主表 → DRAM 表 → CPU 缓存收集表的反向路径，确保定位到有效值。这一设计将耗时的海量比对操作从慢速的 PMem 转移至高速的 DRAM，极大减少了查询延迟与 PMem 访问压力。</p><p><img width="723" height="313" referrerpolicy="no-referrer" src="/img/bVdnIO9" alt="" title="" loading="lazy"/><br/>图3 DRAM 结构刷入 PMem 中，并在 DRAM 中保留指纹</p><h3>核心技术三：段分裂驱动的重复项消除与空间回收</h3><p>为解决“先插入后检查”模式可能产生的键重复问题以及删除操作导致的空间碎片化问题，MetoHash 在数据结构段分裂中引入合并与清理机制。</p><p>首先，DRAM 桶与 PMem 桶在逻辑布局上严格对齐，使得 DRAM 桶满时其内容能高效批量刷写至 PMem 对应位置。当 PMem 中某个段需要分裂以扩容时，系统将旧段所有数据读入 DRAM，在此过程中主动识别并消除同一键的多个版本的无效值，仅保留其最新的有效项，并将合并、去重后的结果写入新分配的段。此过程自然跳过了已标记删除的项，从而在完成容量扩展的同时，一举实现了存储空间的即时回收与整理，保持了 PMem 存储的紧凑性与查询效率。</p><h3>性能成果</h3><p>在实际搭载英特尔傲腾持久内存的测试平台上，MetoHash 与八种前沿方案进行了全面对比。</p><p>①吞吐量提升：在 YCSB 等各类负载下，其吞吐量平均超越以往方案 86.1% 至 257.6%，并呈现近线性扩展能力。</p><p><img width="723" height="127" referrerpolicy="no-referrer" src="/img/bVdnIPa" alt="" title="" loading="lazy"/><br/>图4 MetoHash 相较其他基线索引在不同负载下均有明显优势</p><p>②变长数据支持：在处理 16B 至 256B 的变长键值时，其吞吐量平均仍领先对比方案 190.8%，尤其在小值主导的负载中优势显著。</p><p><img width="723" height="366" referrerpolicy="no-referrer" src="/img/bVdnIPb" alt="" title="" loading="lazy"/><br/>图5 MetoHash 相较于其他基线索引在不同键值对大小下均有明显优势</p><p>③内存效率权衡：相比将全部索引存于 DRAM 的方案（如 VIPER），MetoHash 的 DRAM 占用减少 86.7%；相比 PMem 利用率低的方案 (如 Plush），MetoHash 的 PMem 占用减少 86.5%。</p><p><img width="723" height="264" referrerpolicy="no-referrer" src="/img/bVdnIPc" alt="" title="" loading="lazy"/><br/>图6 MetoHash 相较于其他基线索引能够取得较好的 DRAM/PMem 效率权衡</p><h3>小结</h3><p>这项工作提出的 MetoHash 混合内存哈希索引，为持久内存时代的高性能、高内存效率数据管理提供了系统的解决方案。在理论上，MetoHash 首次通过缓存、DRAM、PMem 三层协同的架构，解决了由 PMem 固定访问粒度引发的 I/O 放大与内存效率低下这一对核心矛盾。在实践中，其在多种负载下的吞吐量相较当前方案平均提升 86.1% 至 257.6%，存储流量大幅降低，内存占用显著优化，在多种负载中验证了其卓越性能。</p><p>欢迎访问 OceanBase 官网获取更多信息：<a href="https://link.segmentfault.com/?enc=FnJtA6GbPkIaWeoFkWyCCw%3D%3D.%2BaOYla18TBXgli35QCySK1j8xdPFZluGuRVARgA9ulk%3D" rel="nofollow" target="_blank">https://www.oceanbase.com/</a></p>]]></description></item><item>    <title><![CDATA[AxureRP-Setup安装教程简单步骤Mac版（附安装包） 小童童 ]]></title>    <link>https://segmentfault.com/a/1190000047560517</link>    <guid>https://segmentfault.com/a/1190000047560517</guid>    <pubDate>2026-01-23 12:10:58</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>​</p><p> Axure RP 是专门给<strong>做产品原型</strong>的人用的工具，简单说就是能在没写代码前，把网页、APP 的样子和交互流程画出来，让团队或客户提前看到“做出来大概什么样”。</p><h4>1. 先下载好安装包</h4><p><strong>安装包下载：</strong><a href="https://link.segmentfault.com/?enc=6ZXKAJolOuTT%2FP0E6nE32w%3D%3D.VMz7fvSeWn1ci0A8Yuaw2p6v5aMzDnyOJiCCsCVN4nc%2FCiM1Y9UHzteJv%2Buq6IjG" rel="nofollow" title="https://pan.quark.cn/s/e332231bba32" target="_blank">https://pan.quark.cn/s/e332231bba32</a> ，把 <code>AxureRP-Setup.dmg</code>文件下载到你的 Mac</p><h4>2. 打开 dmg 镜像文件</h4><p>找到下载好的 <code>.dmg</code>文件，<strong>双击它</strong>——屏幕会弹出一个新窗口，里面一般有俩东西：一个是“Axure RP”的图标（一般是紫色或蓝色方块，上面有“A”字母），另一个是“应用程序”文件夹的快捷方式（小文件夹图标）。</p><h4>3. 把软件拖进“应用程序”文件夹</h4><p>按住“Axure RP”图标，<strong>直接拖到旁边的“应用程序”文件夹里</strong>（跟平时拷贝文件一样），等进度条走完，这一步就装好了。</p><h4>4. 首次打开要“解锁”（重点！）</h4><p>去“应用程序”文件夹找到 Axure RP，<strong>双击打开</strong>。第一次运行时，macOS 会弹提示“无法验证开发者”，别慌：</p><ul><li>点左上角苹果图标 → 选“系统设置”（旧版叫“系统偏好设置”）→ 左侧点“隐私与安全性”；</li><li>右边往下翻，找到“安全性”区域，会看到“已阻止使用‘Axure RP’，因为来自身份不明的开发者”，下面有个“仍要打开”按钮，<strong>点一下</strong>，再输开机密码确认就行（如果没看到“仍要打开”，先关掉提示窗口，重新打开软件，提示会再出现）。</li></ul><p>​</p>]]></description></item><item>    <title><![CDATA[【节点】[BitangentVector节点]原理解析与实际应用 SmalBox ]]></title>    <link>https://segmentfault.com/a/1190000047560534</link>    <guid>https://segmentfault.com/a/1190000047560534</guid>    <pubDate>2026-01-23 12:10:18</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <blockquote><a href="https://link.segmentfault.com/?enc=utuTkIUw3%2FtNF5i91js15g%3D%3D.84lNXFbMWXc3vo2%2FsjZkMw%2FvZc2on2DcZYF4g9DRs18%2FMx5JAKplESrHhLBCw1P8Ejtf3NE4fI%2BUVXpgYIeIcKo5Y%2BUV6hZrhDWj63wqkBAQ9V5HSmQGOV0%2F%2FnfkcGMKXWTjvnWEunRQ%2FA7Y3BdHWb1tjxybrftwn2hQeCME309mVityhh8d43rXE8LVXU5LyhMO8a13nIqxIhpwFJKv3FRaecvp7YOnncXJfvGvuA8%3D" rel="nofollow" target="_blank">【Unity Shader Graph 使用与特效实现】</a><strong>专栏-直达</strong></blockquote><p>在Unity URP Shader Graph中，BitangentVector节点是一个功能强大但常被忽视的节点，它为着色器编程提供了访问网格几何数据的重要能力。理解并正确使用这个节点对于创建高质量的材质效果至关重要，特别是在处理法线贴图、各向异性光照和高级表面渲染时。</p><h2>BitangentVector节点概述</h2><p>BitangentVector节点允许着色器访问网格的副切线矢量数据，这是计算机图形学中描述表面方向的关键几何信息之一。在三维建模和渲染中，每个顶点通常包含位置、法线、切线和副切线四个基本矢量，它们共同构成了描述表面局部方向的坐标系。</p><p>副切线矢量（有时称为双切线或次法线）与法线矢量和切线矢量相互垂直，形成了所谓的切线空间基向量。这个局部坐标系对于许多渲染技术至关重要，特别是那些涉及表面细节和光照计算的效果。</p><h3>节点的基本功能</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560536" alt="" title=""/></p><p>BitangentVector节点根据着色器当前执行的阶段（顶点着色器或片元着色器）提供相应的副切线矢量数据。在顶点着色器阶段，它提供顶点的副切线矢量；在片元着色器阶段，它提供经过插值的片元副切线矢量。</p><p>节点的核心价值在于它能够将副切线矢量转换到不同的坐标空间中，这使得开发者可以灵活地在各种空间中进行计算，满足不同的渲染需求。</p><h3>在渲染管线中的作用</h3><p>在现代渲染管线中，副切线矢量的作用不可小觑：</p><ul><li>法线贴图转换：将切线空间中的法线贴图转换到世界空间或其他空间</li><li>各向异性光照：模拟具有方向性反射特性的材料，如拉丝金属、头发等</li><li>切线空间计算：构建完整的切线空间坐标系用于各种表面相关计算</li><li>高级材质效果：创建复杂的表面响应，如各向异性高光、 brushed金属效果等</li></ul><h2>端口详解</h2><p>BitangentVector节点的输出端口是其数据流的核心接口，理解这个端口的特性和用法是有效使用该节点的前提。</p><h3>输出端口特性</h3><p>输出端口标记为"Out"，提供三维矢量数据，代表了网格顶点或片元的副切线矢量。这个矢量的具体含义和数值取决于节点的配置和使用上下文。</p><ul><li>数据类型：Vector 3</li><li>方向：输出</li><li>绑定：无（表示这是一个独立的数据源，不依赖于其他节点的输入）</li></ul><h3>输出数据的几何意义</h3><p>副切线矢量在几何上具有明确的定义和计算方式。在标准的顶点数据中，副切线矢量通常通过法线和切线的叉积计算得出：</p><pre><code>bitangent = cross(normal, tangent) * tangent.w</code></pre><p>这里的tangent.w是一个符号因子，通常为±1，用于处理镜像UV等情况。理解这个计算关系有助于在需要时手动重建副切线矢量，或在没有副切线数据的模型上模拟相关效果。</p><h3>数据流与精度考量</h3><p>当BitangentVector节点在顶点着色器阶段使用时，它直接输出顶点的副切线矢量；在片元着色器阶段使用时，输出的是经过顶点着色器输出插值后的副切线矢量。这种插值过程可能会导致矢量的长度发生变化，不再是单位矢量，因此在许多应用中需要重新归一化。</p><p>在实际使用中，特别是在片元着色器中，经常可以看到这样的代码模式：</p><pre><code>HLSL

float3 bitangent = normalize(BitangentVector);</code></pre><p>这种归一化操作确保了矢量的方向性正确，同时避免了因插值引起的长度变化问题。</p><h2>空间转换控件</h2><p>Space下拉选单是BitangentVector节点最强大的功能之一，它允许开发者选择副切线矢量输出的坐标空间，极大地扩展了节点的应用范围。</p><h3>Object空间</h3><p>Object空间（也称为模型空间）是相对于模型自身原点的坐标系。在这个空间中，副切线矢量是模型网格数据的原始表示，不受模型变换（位置、旋转、缩放）的影响。</p><p>Object空间的特点：</p><ul><li>与模型本地坐标系对齐</li><li>不受模型变换矩阵影响</li><li>在模型变形动画中保持稳定</li><li>适用于模型空间效果和某些类型的顶点动画</li></ul><p>使用Object空间的典型场景：</p><ul><li>模型空间法线贴图处理</li><li>与模型形状直接相关的顶点着色效果</li><li>需要忽略模型变换的特定计算</li></ul><h3>View空间</h3><p>View空间（也称为相机空间或眼空间）是以摄像机为原点的坐标系。在这个空间中，所有几何体都相对于摄像机进行定位，Z轴通常指向摄像机的观察方向。</p><p>View空间的特点：</p><ul><li>以摄像机为参考系</li><li>简化了与视角相关的计算</li><li>在屏幕空间效果中常用作中间步骤</li><li>适用于与视角方向相关的效果</li></ul><p>使用View空间的典型场景：</p><ul><li>视角相关的各向异性高光</li><li>屏幕空间反射和折射效果</li><li>需要基于视图方向的计算</li></ul><h3>World空间</h3><p>World空间是场景的全局坐标系，所有对象都在这个统一的坐标系中定位。World空间中的副切线矢量已经考虑了模型的变换（位置、旋转、缩放），反映了模型在场景中的实际方向。</p><p>World空间的特点：</p><ul><li>全局统一的坐标系</li><li>考虑了模型的完整变换</li><li>适用于场景级别的光照和交互</li><li>在多个对象间保持一致的空间参考</li></ul><p>使用World空间的典型场景：</p><ul><li>世界空间法线计算</li><li>与场景中其他对象交互的效果</li><li>全局光照计算</li><li>环境遮挡和反射</li></ul><h3>Tangent空间</h3><p>Tangent空间是表面本身的局部坐标系，由法线、切线和副切线三个相互垂直的矢量构成。在这个空间中，法线方向总是(0,0,1)，切线和副切线分别对应表面的U和V方向。</p><p>Tangent空间的特点：</p><ul><li>相对于表面方向的局部坐标系</li><li>法线方向始终向上</li><li>切线和副切线对应纹理UV方向</li><li>独立于模型的整体方向和位置</li></ul><p>使用Tangent空间的典型场景：</p><ul><li>法线贴图的标准空间</li><li>切线空间相关的表面计算</li><li>需要相对于表面方向的效果</li></ul><h2>实际应用示例</h2><p>BitangentVector节点在Shader Graph中的实际应用非常广泛，下面通过几个具体示例展示其强大功能。</p><h3>法线贴图处理</h3><p>法线贴图是现代实时渲染中增强表面细节的关键技术，而BitangentVector节点在法线贴图处理中扮演着核心角色。</p><p><strong>世界空间法线贴图转换</strong></p><p>在URP Shader Graph中实现正确的法线贴图效果通常需要以下步骤：</p><ul><li>采样法线贴图纹理，获取切线空间法线</li><li>使用BitangentVector节点获取世界空间副切线</li><li>结合世界空间法线和切线构建TBN矩阵</li><li>将切线空间法线转换到世界空间</li></ul><p>具体节点设置：</p><ul><li>使用Texture 2D节点采样法线贴图</li><li>使用BitangentVector节点，Space设置为World</li><li>使用NormalVector节点，Space设置为World</li><li>使用TangentVector节点，Space设置为World</li><li>构建3x3矩阵并将切线空间法线转换到世界空间</li></ul><p>这种转换确保了法线贴图能够正确响应场景光照，同时保持表面的视觉细节。</p><p><strong>各向异性光照模拟</strong></p><p>各向异性表面（如拉丝金属、CD表面、头发等）在不同方向上表现出不同的反射特性，这种效果的实现严重依赖于副切线矢量。</p><p><strong>拉丝金属效果实现</strong></p><p>创建拉丝金属材质需要沿着副切线方向拉伸高光：</p><ul><li>使用BitangentVector获取世界空间副切线方向</li><li>基于副切线方向计算各向异性高光</li><li>使用噪声或纹理控制高光的强度和变化</li><li>结合视角方向增强各向异性效果</li></ul><p>关键节点配置：</p><ul><li>BitangentVector节点Space设置为World</li><li>使用Normalize节点确保矢量方向准确</li><li>结合Dot产品计算副切线方向上的光照贡献</li><li>使用Anisotropy参数控制效果强度</li></ul><h3>高级材质效果</h3><p>BitangentVector节点可以用于创建各种复杂的材质表现，提升视觉质量和真实感。</p><p><strong>毛发和纤维渲染</strong></p><p>模拟毛发和纤维材料需要沿着生长方向控制光照响应：</p><ul><li>使用副切线方向作为毛发方向参考</li><li>基于副切线计算各向异性高光和散射</li><li>结合法线和切线完成完整的毛发光照模型</li><li>使用多层着色模拟毛发体积感</li></ul><p><strong>织物材质增强</strong></p><p>织物表面通常具有方向性结构，可以利用副切线矢量增强其视觉表现：</p><ul><li>识别织物纹理的方向性</li><li>沿副切线方向应用特殊的镜面反射</li><li>模拟织物纤维的光线散射特性</li><li>创建velvet等特殊织物效果</li></ul><h2>性能优化与最佳实践</h2><p>正确使用BitangentVector节点不仅关乎效果质量，也影响着色器性能。以下是一些重要的优化建议和最佳实践。</p><h3>空间选择策略</h3><p>不同的坐标空间选择对性能有直接影响：</p><ul><li>Object空间：计算成本最低，但适用性有限</li><li>World空间：最常用，平衡了功能性和性能</li><li>View空间：适用于视角相关效果，性能中等</li><li>Tangent空间：构建完整切线空间时必要，但计算成本较高</li></ul><p>选择原则：</p><ul><li>优先使用能满足需求的最简单空间</li><li>避免不必要的空间转换</li><li>在片元着色器中谨慎使用复杂空间计算</li></ul><h3>精度与质量平衡</h3><p>在副切线矢量使用中需要在精度和性能之间找到平衡：</p><ul><li>在顶点着色器中计算，在片元着色器中插值：性能较好，但可能损失精度</li><li>在片元着色器中直接计算：精度最高，但性能成本较高</li><li>根据效果需求选择合适的计算阶段</li></ul><h3>常见问题排查</h3><p>使用BitangentVector节点时可能遇到的典型问题及解决方案：</p><p><strong>副切线方向不正确</strong></p><ul><li>检查模型导入设置，确保生成切线数据</li><li>验证UV布局，确保没有镜像或翻转</li><li>检查Space设置是否符合预期用途</li></ul><p><strong>法线贴图效果异常</strong></p><ul><li>确认TBN矩阵构建正确</li><li>检查矢量归一化操作</li><li>验证空间转换的一致性</li></ul><p><strong>性能问题</strong></p><ul><li>减少不必要的空间转换</li><li>在顶点着色器中进行复杂计算</li><li>使用精度适当的变量类型</li></ul><h2>与其他节点的协同工作</h2><p>BitangentVector节点很少单独使用，了解它与其他节点的协同工作方式对于创建复杂效果至关重要。</p><h3>与法线和切线节点的配合</h3><p>BitangentVector通常与Normal Vector和Tangent Vector节点一起使用，构建完整的切线空间：</p><ul><li>Normal Vector提供表面法线方向</li><li>Tangent Vector提供表面切线方向</li><li>Bitangent Vector提供表面副切线方向</li><li>三者共同构成TBN矩阵，用于空间转换</li></ul><h3>在自定义光照模型中的应用</h3><p>在编写自定义光照函数时，BitangentVector提供了重要的几何信息：</p><ul><li>各向异性光照计算</li><li>基于方向的阴影处理</li><li>表面细节增强</li><li>特殊材质的光照响应</li></ul><h3>与数学节点的结合</h3><p>通过结合各种数学节点，可以扩展BitangentVector的应用范围：</p><ul><li>使用Dot Product计算方向相关性</li><li>使用Cross Product验证或重建坐标系</li><li>使用Transform节点进行空间转换</li><li>使用Normalize节点确保矢量精度</li></ul><h2>高级技巧与创意应用</h2><p>除了传统应用，BitangentVector节点还可以用于一些创新和高级的渲染技术。</p><h3>动态效果创建</h3><p>利用副切线方向创建各种动态表面效果：</p><ul><li>沿副切线方向流动的液体效果</li><li>方向性表面变形和位移</li><li>基于方向的纹理动画</li></ul><h3>非真实渲染风格</h3><p>在风格化渲染中利用副切线矢量：</p><ul><li>方向性笔触效果</li><li>各向异性轮廓线</li><li>特定方向的色彩偏移</li></ul><h3>程序化材质生成</h3><p>结合程序化噪声和纹理，利用副切线方向创建复杂的表面材质：</p><ul><li>方向性噪声图案</li><li>程序化各向异性高光</li><li>基于方向的材质混合</li></ul><hr/><blockquote><a href="https://link.segmentfault.com/?enc=c1CfhdbfH0HeDH5L7nKTvQ%3D%3D.KSaXihRRVSAO9oqAYeagBXR%2Bf%2FRX5B4RTshoAXfS10B7pC9vy%2FZ2ayteHJDdi1%2FMcP6lDl6Nv%2BoNx6XfEMloM7iHy8Q7F%2BojaSN%2FVHSUgoIEar5rvKpGBHRmr6S7883JkoHpHKvQSZRMhdHbtDFc3WwF%2BFrOSBuY18Zs44TA%2FR6ccGJXX4PSYWB5%2FlbRZa5SxLixeGcP4jB2YsxygGMNo5z0uooBelxeT%2BnNqhmLJJo%3D" rel="nofollow" target="_blank">【Unity Shader Graph 使用与特效实现】</a><strong>专栏-直达</strong><br/>（欢迎<em>点赞留言</em>探讨，更多人加入进来能更加完善这个探索的过程，🙏）</blockquote>]]></description></item><item>    <title><![CDATA[2026 AI 元年：从大模型能力到工程化落地的关键转折 Agentcometoo ]]></title>    <link>https://segmentfault.com/a/1190000047560553</link>    <guid>https://segmentfault.com/a/1190000047560553</guid>    <pubDate>2026-01-23 12:09:36</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>引言：为什么说 2026 是 AI 应用真正的起点？</h2><p>过去几年，大模型能力的提升有目共睹，但在真实业务环境中，一个越来越清晰的共识正在形成：</p><p><strong>模型可用，并不等于系统可用，更不等于业务长期可用。</strong></p><p>进入 2026 年，随着推理成本持续下降、模型能力逐步标准化，AI 的竞争焦点正在发生转移——<br/>从“谁的模型更强”，转向“谁能把 AI 稳定地跑在生产环境中”。</p><p>从这个意义上看，<strong>2026 年并不是模型能力爆发的一年，而是 AI 应用真正起飞的一年。</strong></p><hr/><h2>一、从模型能力到工程能力：关键拐点已经出现</h2><p>在企业级场景中，大模型面临的核心挑战，从来不只是“能不能回答问题”，而是：</p><ul><li>是否具备<strong>可控性与可复现性</strong></li><li>是否能与<strong>既有业务系统深度集成</strong></li><li>是否支持<strong>长期运行、可观测、可运维</strong></li></ul><p>这也是为什么在过去一年中，越来越多团队开始重新重视工程化能力、系统架构设计以及确定性逻辑。</p><p>从实践层面看，几个变化尤为明显：</p><h3>1. 推理成本下降，AI 从实验功能变为系统能力</h3><p>模型调用成本的持续下降，使 AI 不再只是 Demo 或边缘功能，而是可以作为系统中的常驻能力被设计。</p><h3>2. 交互范式升级，从对话走向任务执行</h3><p>AI 的使用方式正在从单轮、多轮对话，演进为具备任务拆解、路径规划与工具调用能力的执行型系统。</p><h3>3. 确定性逻辑回归，工程系统重新站上核心位置</h3><p>在关键业务路径上，大模型更多承担“理解与生成”的角色，而真正影响结果正确性的部分，仍由代码、规则和流程兜底，以降低幻觉带来的系统性风险。</p><hr/><h2>二、为什么“智能体（Agent）”正在成为主流形态？</h2><p>相比直接调用模型 API，智能体更接近一个​<strong>可运行、可治理的系统单元</strong>​。</p><p>一个具备工程落地价值的智能体，通常包含以下几个层次：</p><ul><li>​<strong>感知层</strong>​：输入理解、上下文管理、状态感知</li><li>​<strong>决策层</strong>​：任务拆解、路径规划、策略选择</li><li>​<strong>执行层</strong>​：工具调用、接口编排、流程执行</li><li>​<strong>反馈层</strong>​：结果校验、异常处理、状态更新</li></ul><p>当系统开始具备完整的“感知—决策—执行—反馈”闭环，其复杂度已经进入系统工程范畴，而不再是简单的 Prompt 调整问题。</p><p>在实际落地过程中，一些团队开始借助智能体平台来降低工程复杂度。例如，<strong>智能体来了公司</strong> 提供的企业级智能体方案，通过任务编排、工具治理与流程控制，将大模型能力封装为可复用、可运维的业务组件，从而缩短从模型能力到生产系统之间的距离。</p><hr/><h2>三、技术人如何跨越“模型”与“工程落地”的鸿沟？</h2><p>从已经成功推进 AI 应用落地的团队来看，往往具备以下几个共性特征。</p><h3>1. 工程视角优先，而非模型视角</h3><p>模型是能力来源，但并不是系统核心。<br/>真正决定 AI 应用能否长期运行的，是一系列工程问题：</p><ul><li>数据流如何组织与校验</li><li>异常如何兜底与回滚</li><li>状态如何持久化与追踪</li><li>多任务如何协同与调度</li></ul><p>从本质上看，​<strong>AI 应用是一类“引入不确定性的分布式系统</strong>”​，而不是一个单纯的模型调用接口。</p><hr/><h3>2. 重视“胶水层”能力建设</h3><p>Python、工作流引擎、API 编排与任务调度工具，正在成为 AI 应用的关键基础设施。</p><p>它们负责把模型能力、业务系统、数据与云资源稳定地连接起来，解决的不是“能不能连上”，而是“能否长期可靠运行”。</p><hr/><h3>3. 理解行业，而不仅是理解技术</h3><p>通用大模型解决的是共性问题，而真正形成壁垒的，往往来自：</p><ul><li>行业知识结构</li><li>业务流程理解</li><li>长期沉淀的数据与规则</li></ul><p>AI 的最终价值，并不体现在模型参数规模上，而体现在​<strong>具体业务场景中的系统能力</strong>​。</p><hr/><h2>结语：AI 的下半场，属于“会做系统的人”</h2><p>当模型能力逐步趋同，真正拉开差距的将不再是参数规模或榜单成绩，而是：</p><p><strong>谁能把 AI 稳定、可靠、可持续地运行在真实业务系统中。</strong></p><p>这，正是 2026 年被称为 <strong>AI 应用元年</strong> 的真正原因。</p>]]></description></item><item>    <title><![CDATA[用 CSS 玩转 3D 等距设计：一个会跟着鼠标动的立方体 Silvana ]]></title>    <link>https://segmentfault.com/a/1190000047560557</link>    <guid>https://segmentfault.com/a/1190000047560557</guid>    <pubDate>2026-01-23 12:08:41</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <blockquote><p>你好，我是 <strong>Silvana</strong>，一名前端开发。</p><p>这里记录我写过的代码、做过的项目，以及一些真实想法。</p></blockquote><p>最近捣鼓了个有意思的小效果 —— <strong>纯 CSS 实现的 3D 等距立方体</strong>，鼠标在页面上移动时，立方体还能跟着转动，视觉上既有层次感又不复杂。先放个效果动图直观感受下👇</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560560" alt="" title=""/></p><h2>一、先搭 HTML 骨架：简单到只有一个 “盒子”</h2><p>整个效果的 HTML 结构特别直观，核心就是一个承载 3D 效果的box容器，里面嵌套了立方体的四个侧面，每个侧面放对应的文字内容就行。</p><pre><code class="html">&lt;!DOCTYPE html&gt;
&lt;html lang="en"&gt;
&lt;head&gt;
  &lt;meta charset="UTF-8" /&gt;
  &lt;!-- 适配移动端，保证小屏也能正常显示 --&gt;
  &lt;meta name="viewport" content="width=device-width, initial-scale=1.0" /&gt;
  &lt;title&gt;CSS创意等距设计&lt;/title&gt;
  &lt;!-- 引入样式文件 --&gt;
  &lt;link rel="stylesheet" href="style.css" /&gt;
&lt;/head&gt;
&lt;body&gt;
  &lt;!-- 3D立方体的外层容器，所有3D变换都基于这个盒子 --&gt;
  &lt;div id="box"&gt;
    &lt;!-- 立方体的侧面容器，包裹四个不同角度的侧面 --&gt;
    &lt;div&gt;
      &lt;!-- 第一个侧面：旋转0度，对应立方体正面 --&gt;
      &lt;span&gt;
        &lt;div class="container"&gt;
          &lt;div class="side"&gt;
            &lt;h2&gt;CSS&lt;/h2&gt;
            &lt;h3&gt;Isometric&lt;/h3&gt;
            &lt;h4&gt;Design&lt;/h4&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/span&gt;
      &lt;!-- 第二个侧面：旋转90度，对应立方体右侧面 --&gt;
      &lt;span&gt;
        &lt;div class="container"&gt;
          &lt;div class="side"&gt;
            &lt;h2&gt;CSS&lt;/h2&gt;
            &lt;h3&gt;Isometric&lt;/h3&gt;
            &lt;h4&gt;Design&lt;/h4&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/span&gt;
      &lt;!-- 第三个侧面：旋转180度，对应立方体背面 --&gt;
      &lt;span&gt;
        &lt;div class="container"&gt;
          &lt;div class="side"&gt;
            &lt;h2&gt;CSS&lt;/h2&gt;
            &lt;h3&gt;Isometric&lt;/h3&gt;
            &lt;h4&gt;Design&lt;/h4&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/span&gt;
      &lt;!-- 第四个侧面：旋转270度，对应立方体左侧面 --&gt;
      &lt;span&gt;
        &lt;div class="container"&gt;
          &lt;div class="side"&gt;
            &lt;h2&gt;CSS&lt;/h2&gt;
            &lt;h3&gt;Isometric&lt;/h3&gt;
            &lt;h4&gt;Design&lt;/h4&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/span&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;!-- 鼠标交互的JS代码 --&gt;
  &lt;script&gt;
  &lt;/script&gt;
&lt;/body&gt;
&lt;/html&gt;</code></pre><h2>二、CSS 样式：调对 3D 变换才有质感</h2><p>这个效果的核心全在 CSS 里，尤其是<code>transform-style: preserve-3d</code>（保留 3D 空间）、<code>rotateX/rotateY</code>（3D 旋转）和<code>translate3d</code>（3D 位移），我把关键样式拆出来，每一步都标了注释，一看就懂。</p><pre><code class="css">/* 全局重置：清除默认边距，盒模型设为border-box（宽高包含边框/内边距） */
* {
  margin: 0;
  padding: 0;
  box-sizing: border-box;
}
/* 页面主体：居中显示，背景色设为浅蓝，最小高度占满屏幕 */
body{
  display: flex;
  justify-content: center;
  align-items: center;
  min-height: 100vh;
  background: #80c7ff;
}
/* 3D立方体外层容器：开启3D空间，设置宽高 */
#box {
  position: relative;
  width: 260px;
  height: 340px;
  transform-style: preserve-3d; /* 关键：保留子元素的3D变换效果 */
}
/* 立方体的“顶面”：通过rotateX旋转90度，模拟3D顶面，加模糊增加层次感 */
#box::before{
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  width: 260px;
  height: 260px;
  background: #fff;
  transform: rotateX(90deg) translateZ(130px); /* 旋转+位移，定位到立方体顶部 */
  filter: blur(4px); /* 轻微模糊，模拟光影效果 */
}
/* 立方体的“底面阴影”：同理旋转，加半透明黑色模拟阴影 */
#box::after{
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  width: 260px;
  height: 260px;
  background: rgba(0,0,0,0.15);
  transform: rotateX(90deg) translateZ(-260px); /* 位移到立方体底部，模拟阴影 */
}
/* 立方体侧面的父容器：继承3D空间属性 */
#box div {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  transform-style: preserve-3d;
}
/* 每个侧面的基础样式：居中显示内容，继承3D空间 */
#box div span {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  transform-style: preserve-3d;
  display: flex;
  justify-content: center;
  align-items: center;
}
/* 第一个侧面：旋转0度，作为立方体正面 */
#box div span:nth-child(1){
  transform: rotateY(0deg) translate3d(0,0,130px); /* 沿Y轴旋转0度，向Z轴位移130px（立方体边长的一半） */
  background: #f1f1f1;
}
/* 第二个侧面：旋转90度，作为立方体右侧面 */
#box div span:nth-child(2){
  transform: rotateY(90deg) translate3d(0,0,130px);
  background: #f8f8f8;
}
/* 第三个侧面：旋转180度，作为立方体背面 */
#box div span:nth-child(3){
  transform: rotateY(180deg) translate3d(0,0,130px);
  background: #ededed;
}
/* 第四个侧面：旋转270度，作为立方体左侧面 */
#box div span:nth-child(4){
  transform: rotateY(270deg) translate3d(0,0,130px);
  background: #f7f7f7;
}
/* 文字容器：居中对齐 */
#box div span .container {
  text-align: center;
}
#box div span .container .side{
  display: flex;
  justify-content: center;
  align-items: center;
}
/* 文字样式：垂直排版（writing-mode: vertical-lr），增强3D立方体的视觉效果 */
#box div span .container .side h2{
  font-size: 5em;
  writing-mode: vertical-lr; /* 文字垂直排列 */
  text-orientation: upright; /* 文字直立显示 */
  font-weight: 700;
  line-height: 1.2em;
  color: #0e2f56;
}
#box div span .container .side h3{
  font-size: 2.7em;
  text-transform: uppercase; /* 字母大写 */
  writing-mode: vertical-lr;
  color: #fff;
  letter-spacing: .12em;
  background: #0e2f56;
  padding-top: 20px;
  padding-bottom: 10px;
  font-weight: 300;
}
#box div span .container .side h4{
  font-size: 2.2em;
  writing-mode: vertical-lr;
  text-orientation: upright;
  text-transform: uppercase;
  line-height: 2em;
  color: #0e2f56;
}</code></pre><h2>三、几行 JS 搞定：鼠标交互效果</h2><p>交互逻辑就监听鼠标移动事件，获取鼠标的 X 轴坐标，动态修改立方体的<code>rotateY</code>值，再固定<code>rotateX</code>为 - 30 度，让立方体保持等距视角，鼠标一动就有反馈，手感刚好。</p><pre><code class="javascript">// 获取3D立方体的DOM元素
var box = document.getElementById("box");
// 监听全局鼠标移动事件
window.onmousemove = function(e) {
  // e.clientX：鼠标相对于浏览器可视区的X坐标
  // rotateX(-30deg)：固定立方体的上下角度，保持等距视觉
  // rotateY(${e.clientX}deg)：让立方体跟着鼠标X轴旋转
  box.style.transform = `rotateX(-30deg) rotateY(${e.clientX}deg)`
}</code></pre><blockquote>写着写着就到了结尾，祝您今晚有个好梦（代码少报错一点）。</blockquote><p>本文由<a href="https://link.segmentfault.com/?enc=8DTSZeumaos%2FQHd7aTwBDQ%3D%3D.VkKRclKBIyGK%2BX6LyywMv7ygJLiKncAqAnKCuu49d18%3D" rel="nofollow" target="_blank">mdnice</a>多平台发布</p>]]></description></item><item>    <title><![CDATA[微软开源 VibeVoice-ASR 模型，支持一小时长音频处理；苹果首款 AI 设备：AirTag]]></title>    <link>https://segmentfault.com/a/1190000047560569</link>    <guid>https://segmentfault.com/a/1190000047560569</guid>    <pubDate>2026-01-23 12:08:08</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560571" alt="" title=""/></p><p><strong>开发者朋友们大家好：</strong></p><p>这里是 <strong>「RTE 开发者日报」</strong> ，每天和大家一起看新闻、聊八卦。我们的社区编辑团队会整理分享 RTE（Real-Time Engagement） 领域内「有话题的<strong>技术</strong>」、「有亮点的<strong>产品</strong>」、「有思考的<strong>文章</strong>」、「有态度的<strong>观点</strong>」、「有看点的<strong>活动</strong>」，但内容仅代表编辑的个人观点，欢迎大家留言、跟帖、讨论。</p><p><em>本期编辑：@瓒an、@鲍勃</em></p><h2>01 有话题的技术</h2><p><strong>1、Microsoft 开源 VibeVoice-ASR 语音识别模型：支持 60 分钟单次长音频处理，集成 64K 上下文与热词自定义</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560572" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560573" alt="" title="" loading="lazy"/></p><p>Microsoft 发布「VibeVoice-ASR」语音识别模型，突破了传统 ASR 依赖短音频切片的限制，支持单次处理长达 60 分钟的连续音频。该模型通过 64K token 上下文窗口，在单一推理过程中联合完成识别、说话人日志与时间戳生成。</p><ul><li><strong>60 分钟单次推理能力</strong>：放弃传统的短音频切片模式，避免了因切片导致的全局语义丢失和跨片段说话人追踪失败问题。</li><li><strong>64K Token 级长上下文支持</strong>：利用超长上下文窗口，实现 ASR、Diarization（说话人日志）与 Timestamping（时间戳）的端到端联合输出，生成包含「Who， When， What」的结构化转录文本。</li><li><strong>Customized Hotwords 动态引导</strong>：允许用户在识别时注入特定专有名词、技术术语或背景词汇，显著提升特定领域或低频词的识别准确率。</li><li><strong>DER 与 cpWER 综合性能优化</strong>：通过联合训练，模型在说话人错误率和带时间戳的字错误率等指标上具备竞争优势。</li><li><strong>标准化部署环境</strong>：支持 NVIDIA PyTorch Container（验证版本 24.07 至 25.12），核心计算依赖 Flash-Attention 以优化超长序列的推理效率。</li></ul><p>已在 Hugging Face 开源并提供测试 Demo，采用 MIT 开源协议。</p><p>HuggingFace: <br/><a href="https://link.segmentfault.com/?enc=qGIEPMgFNksPqK%2B0F5rzEw%3D%3D.5A1XWqhANH9cHkjMLSUPQTFmiMt9CM2lBgrXN03WcSH8LjsABxLkw2rgQiNKwyaR" rel="nofollow" target="_blank">https://huggingface.co/microsoft/VibeVoice-ASR</a></p><p>GitHub: <br/><a href="https://link.segmentfault.com/?enc=bIU0v%2BUX6Teoel1STpj5LQ%3D%3D.PUM3Bumq0NL6BE9xpZImjbAPzjNtYo4SaVoSx00Zb2DrvtwyboUyCBXous5%2FhMyU" rel="nofollow" target="_blank">https://github.com/microsoft/VibeVoice</a></p><p>( @GitHub)</p><p><strong>2、FlashLabs 发布 Chroma 1.0：开源原生 Speech-to-Speech 模型，TTFT 降低至 135ms</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560574" alt="" title="" loading="lazy"/></p><p>FlashLabs 推出「Chroma 1.0」开源端到端的 Speech-to-Speech 大模型。该模型跳过了传统的语音识别（ASR）与合成（TTS）阶段，直接在音频 Token 维度完成推理，为开发者提供了一个可私有化部署的 OpenAI Realtime 模型替代方案。</p><ul><li><strong>原生端到端语音架构</strong>：弃用「ASR → LLM → TTS」的级联管道，采用单一闭环处理音频 Token。该架构原生支持全双工中断，并能完整保留对话中的语调、情感和节奏。</li><li><strong>135ms 极低响应延迟</strong>：模型 TTFT（首字音频延迟）小于 150ms；在启用 「SGLang」 优化后，TTFT 进一步降低至 135ms，实时系数保持在 0.47–0.51 之间，推理速度达实时语速的 2 倍以上。</li><li><strong>4B 参数量与高保真克隆</strong>：模型基于 「Qwen 2.5-Omni-3B」 与 「Mimi」 构建，仅需数秒音频样本即可实现高保真语音克隆。其相似度指标 SIM 达到 0.817，较人类基准（0.73）提升约 11%。</li><li><strong>集成双层 RAG 架构</strong>：内置双层 RAG 机制，可直接挂载向量数据库与知识图谱，实现由智能体驱动的事实检索与语音生成分离，提升对话准确性。</li></ul><p>模型权重（Chroma-4B）与推理代码已在 Hugging Face 和 GitHub 全面开源，支持通过 FlashAI 平台直接部署。</p><p>相关链接：<br/><a href="https://link.segmentfault.com/?enc=zJ54dbrwdqy%2BX8%2BEiIP5ow%3D%3D.jpCCRfUtOd2ttFDQajJ7QiDyLeoQEAu3bImJJg9Kb%2BlFkyDvAxZQPSPLIjHNRJhC" rel="nofollow" target="_blank">https://www.flashlabs.ai/flashai-voice-agents</a></p><p>HuggingFace: <br/><a href="https://link.segmentfault.com/?enc=8g1TB6KbiR5jBe4kFNKAKg%3D%3D.b3efhdlePcCq%2FgXrNfOTYYHxsOJxfenL8TN3oaRptyI0z2jNHrFwcA5fqmiVKUic" rel="nofollow" target="_blank">https://huggingface.co/FlashLabs/Chroma-4B</a></p><p>( @flashlabsdotai\@X)</p><p><strong>3、Inworld AI 发布 TTS-1.5 语音模型：P90 延迟降至 130ms，推理成本仅为同类产品 1/25</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560575" alt="" title="" loading="lazy"/></p><p>「Inworld AI」正式推出 TTS-1.5 语音合成模型，旨在解决实时语音交互中的延迟与成本瓶颈。通过优化强化学习算法，该版本在显著提升表现力的同时，将 P90 延迟压缩至 250ms 以内，并实现了极低廉的定价策略，直接面向大规模商用语音智能体市场。</p><ul><li><strong>生产级实时延迟</strong>：TTS-1.5 Mini 模型的 P90 首包延迟低于 130ms，Max 模型低于 250ms，响应速度较前代提升约 4 倍，突破了人类自然对话约 300ms 的感知间隔。</li><li><strong>稳定性与表现力优化</strong>：通过规模化强化学习训练，词错率降低 40%，大幅减少了长文本合成中的幻觉、断句和杂音；同时语音表现力提升 30%。</li><li><strong>极具竞争力的定价结构</strong>：交互成本低至 0.5 美分/分钟，每百万字符定价为 $5-$10，对比行业头部方案（$120+/百万字符）成本降低逾 25 倍。</li><li><strong>扩展功能与部署灵活性</strong>：支持 15 种语言（重点优化了印地语）；专业级声音克隆功能正式开放 API 调用；并为企业用户提供 On-prem（本地化）部署选项。</li><li><strong>API 平滑迁移</strong>：现有开发者可通过更改 modelId 为 inworld-tts-1.5-mini 或 max 实现快速接入，已整合至 Voximplant 等第三方平台。</li></ul><p>已正式上线，开发者可通过 「Inworld AI」 官网 API 或集成合作伙伴平台接入；提供开源/闭源方案及企业级私有化部署。</p><p>相关链接：<br/><a href="https://link.segmentfault.com/?enc=hMLVcChlnnVSqRs0eKgC5A%3D%3D.3ugneqmSa6RO1fcvw7V7xX4LeXf5vIZupwuxWuEVF%2FE%3D" rel="nofollow" target="_blank">https://inworld.ai/tts</a></p><p>( @inworld\_ai\@X)</p><p><strong>4、DeepSeek 新模型「MODEL1」曝光</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560576" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560577" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560578" alt="" title="" loading="lazy"/></p><p>1 月 21 日下午消息，DeepSeek 于官方 GitHub 仓库更新了一系列 FlashMLA 代码，在这些更新中，一个名为 <strong>「Model 1」的模型</strong> 引起了广泛关注。</p><p>据悉，目前这个还很神秘的 Model1 不仅出现在了代码与注释中，甚至还有与 DeepSeek-V3.2 并驾齐驱的文件。<strong>这也不禁引发广大网友猜测，认为 Model 1 很可能就是传闻中 DeepSeek 将于春节前后发布的新模型代号。</strong></p><p>最新消息显示，Model1 是 DeepSeek FlashMLA 中支持的两个主要模型架构之一，另一个是 DeepSeek-V3.2。</p><p>据推测，MODEL1 很可能是一个<strong>高效推理模型</strong>，相比 V3.2，内存占用更低，适合边缘设备或成本敏感场景。它也可能是一个长序列专家，针对 16K+序列优化，适合文档理解、代码分析等长上下文任务。它也可能是一个长序列专家，针对 16K+序列优化，适合文档理解、代码分析等长上下文任务。</p><p>另外，MODEL1 的硬件实现跨越多个 GPU 架构。在英伟达 H100/H200（SM90 架构）上有两个版本：model1\_persistent\_h64.cu 用于 64 头配置，model1\_persistent\_h128.cu 用于 128 头配置。在最新的 B200（SM100 架构）上有专门的 Head64 内核实现，而 SM100 的 Head128 实现仅支持 MODEL1，不支持 V3.2，有人猜测 DeepSeek 为适配英伟达新一代 GPU，专门优化了 MODEL1 的架构。</p><p>（@雷锋网）</p><h2>02 有亮点的产品</h2><p><strong>1、苹果首款 AI 穿戴设备曝光：AirTag 尺寸胸针，双摄、三麦克风</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560579" alt="" title="" loading="lazy"/></p><p>1 月 22 日消息，科技媒体 The Information 发布博文，报道称苹果正在研发一款<strong>尺寸类似 AirTag 的「AI 佩戴式胸针」</strong>，计划最早于 2027 年发布。</p><p>这款设备目前的开发代号尚未公开，但其形态被描述为「类似 AirTag 大小的圆形圆盘」。项目仍处于早期阶段且存在取消风险，不过消息称苹果工程师正全力推进，目标定于 2027 年推向市场。</p><p>在硬件规格方面，这款 AI 胸针混合铝合金与玻璃外壳材质，厚度略高于 AirTag。为了实现环境感知，该设备正面集成了<strong>两颗摄像头（标准镜头与广角镜头）</strong>，不仅能拍摄照片，还能实时捕捉用户周边的视频信息。</p><p>设备内置了<strong>三个麦克风</strong>用于精准收音，配备了<strong>一个扬声器</strong>进行语音反馈，并在边缘设置了一枚实体按键，背部采用了与 Apple Watch 相似的磁吸感应充电接口。</p><p>（@IT 之家）</p><p><strong>2、苹果首款 AI 智能家居中枢爆料：带屏幕、会转头，最早今春登场</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560580" alt="" title="" loading="lazy"/></p><p>科技媒体 The Information 今天发布博文，爆料称苹果计划最快今年春季发布新款智能家居中枢（Home Hub），采用「机器人旋转底座」设计，根据声音或动作让设备自动转向用户。</p><p>消息称这款智能家居中枢不仅配备了小型显示屏和高保真扬声器，更引入了具身智能的关键组件「机器人旋转底座」，<strong>让设备能够物理转动，改变传统智能音箱被动静止的交互模式。</strong></p><p>尽管爆料未详细阐述旋转底座的技术原理，但科技媒体 MacRumors 认为其核心目的是实现「视觉追随」。结合苹果在传感器领域的布局，该设备预计将搭载阵列式传感器，用于精准识别用户在房间内的位置。</p><p>例如用户发出语音指令或移动后，<strong>底座驱动屏幕自动转向用户</strong>，不仅能提供更好的视频通话视角，还能通过物理动作模拟注视感，赋予 AI 助手一种「视觉人格」，从而提升交互的沉浸感与自然度。</p><p>发布日期方面，供应链消息指出，其上市时间窗口将与 iOS 26.4 的发布时间高度重合。硬件上的灵动转向配合软件上的更智能 Siri，苹果有望重新定义智能家居的控制中心。</p><p>（@IT 之家）</p><p><strong>3、字节 AI 硬件传人事变动：Oladance 创始人李浩乾或离职，新一代耳机与眼镜曝光</strong></p><p>据蓝鲸新闻消息，字节跳动 Flow 旗下 Ocean 团队核心骨干、原 Oladance 创始人李浩乾或将离职。<strong>知情人士透露，目前内部人事调整仍存变数，不排除转岗等可能。</strong> 李浩乾曾任职于 Bose 并带领研发 QC35，后于 2019 年创立 Oladance 主攻开放式耳机。2024 年中旬，字节跳动以约 5000 万美元全资收购 Oladance，李浩乾随团队加入字节，职级定为 5-1，负责代号为「D 线」的 AI 可穿戴设备业务。</p><p>在收购完成后，字节跳动迅速整合资源，于 2024 年 10 月推出了首款搭载豆包大模型的智能耳机 Ola Friend，预售价 1199 元。该产品深度集成了豆包的语音交互能力，并于 2025 年 5 月上线了 AI 外教智能体「Owen」，支持英语对话、双语点评及职场模拟等功能，试图通过垂直场景切入教育硬件市场。然而，有消息显示该产品后期的市场反响未达团队预期。</p><p>面对硬件赛道的挑战，字节跳动正在加速调整产品布局。供应链信息指出，<strong>字节正研发新一代豆包 AI 耳机，由歌尔股份专门设立事业群负责代工，产品核心思路将转向与手机的深度协同</strong>。此外，<strong>豆包 AI 眼镜（无屏版）预计将于 2026 年第一季度面世</strong>，首批规划量约 10 万台，将采用邀请制发售。</p><p>（@多知）</p><h2>03 有态度的观点</h2><p><strong>1、马斯克喊话「不要让亲人用 ChatGPT」，奥特曼回应：超过 50 人死于 Autopilot</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560581" alt="" title="" loading="lazy"/></p><p>昨天，特斯拉 CEO 伊隆 · 马斯克在 X 转发一则帖子，直言「不要让你的亲人使用 ChatGPT」。该帖子声称 ChatGPT 自 2022 年发布以来，已与 9 起死亡案例相关联。</p><p>OpenAI CEO 山姆 · 奥特曼随后对此进行回应，强调 OpenAI 在保护脆弱用户与确保产品可用性之间面临艰难平衡。</p><p>他表示「我们需要保护脆弱用户，同时确保所有用户都能从工具中受益」，并指出马斯克此前曾抱怨 ChatGPT 的内容审核「过于严格」。</p><p>在回应中，奥特曼还回击了特斯拉汽车的 Autopilot 自动驾驶功能。</p><p>他表示，自己曾乘坐搭载该系统的车辆，「第一反应是这远不是特斯拉应该发布的安全产品」，并暗示马斯克旗下 xAI 的 Grok 在内容安全上也存在争议。</p><p>《商业内幕》报道指出，围绕 ChatGPT 的安全性，OpenAI 目前已面临至少 8 起与心理健康恶化、自杀或暴力事件相关的诉讼；</p><p>而特斯拉 Autopilot 也卷入多起致死事故诉讼，包括一起发生于 2019 年、最终由陪审团裁定特斯拉承担 33% 责任的案件。</p><p>这场公开争执发生在双方长期法律纠纷的背景下。马斯克此前起诉了奥特曼及 OpenAI 高层，指控其偏离最初的非营利使命，并称自己曾为 OpenAI 的早期发展投入 3800 万美元。</p><p>( @APPSO)</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560582" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560583" alt="" title="" loading="lazy"/></p><p><a href="https://link.segmentfault.com/?enc=9izEHUkuKoPnpNh4kcNfvg%3D%3D.pWk2SWLU9PlKGexrqJE6T340h2lHFW5L2ecgvSItvyI%3D" rel="nofollow" target="_blank">阅读更多 Voice Agent 学习笔记：了解最懂 AI 语音的头脑都在思考什么</a></p><p><strong>写在最后：</strong></p><p>我们欢迎更多的小伙伴参与 <strong>「RTE 开发者日报」</strong> 内容的共创，感兴趣的朋友请通过开发者社区或公众号留言联系，记得报暗号「共创」。</p><p>对于任何反馈（包括但不限于内容上、形式上）我们不胜感激、并有小惊喜回馈，例如你希望从日报中看到哪些内容；自己推荐的信源、项目、话题、活动等；或者列举几个你喜欢看、平时常看的内容渠道；内容排版或呈现形式上有哪些可以改进的地方等。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560584" alt="" title="" loading="lazy"/></p><p>作者提示: 个人观点，仅供参考​</p>]]></description></item><item>    <title><![CDATA[《Asynchronous Programming in Python》读后感 codists ]]></title>    <link>https://segmentfault.com/a/1190000047560597</link>    <guid>https://segmentfault.com/a/1190000047560597</guid>    <pubDate>2026-01-23 12:07:10</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>一、 为什么读这本书？</h2><p>最近在梳理并发编程，所以想了解一些异步开发， asyncio 的用法，《Asynchronous Programming in Python》是 2025 年出版，比较新，所以选择阅读这本书。</p><h2>二、这本书写了什么？</h2><p>总体而言，这本书什么都谈一点。基础概念：进程(process)、线程(thread) ，纤程(fiber)，协程(coroutine)，生成器。异步库：asyncio, trio。性能分析(scalene)，测试(pytest-asyncio), 设计模式(monitor object patter,  leader/follower patter)，框架(Django, Flask, Quart)，数据库操作(sqlite3, aiosqlite)等等，在此就不一 一罗列了。</p><h2>三、本书评价</h2><p>本书总计 171 页，从 2025 年 12 月 29 日至 2026 年 1 月 20 日，期间断断续续花了 22 天阅读完《Grokking Concurrency》。</p><p>总体而言，本书问题较多，例如：</p><p>1.罗列内容，缺乏深度。</p><p>这本书只有171页，但是却谈了很多很多的技术概念、库(框架)，相当于把各种库的基本用法汇总上去就完了，如果让我给这本书起一个中文名，我觉得应该叫做《Python异步编程概览》，都达不到入门的程度。看完了也只是在头脑中有一个印象而已，对实际工程项目没有任何帮助。</p><p>2.代码写法随意，风格不统一。</p><pre><code># p55, 不用 f-string:
print("Queue size:",curr_len)</code></pre><pre><code># p56, 用 f-string:
f = open(f'./tmp/${item["id"]}.json', "a")</code></pre><p>虽说怎么写都行，但是代码保持统一风格，有利于代码阅读、维护。</p><p>3.存在多处代码错误</p><pre><code># p55 
async def fetcher():
    while True:
        msg = await sse_client_get_values()
        try:
            for item in msg:
                vals.put(item)
        except queue.Full:
            print("Queue full")
            return True
        await asyncio.sleep(1)</code></pre><p>这里没有指定 timeout, 并不会触发 queue.Full 异常。当然，错误远不止这一处。</p><p>4.表述不严谨</p><p>p69, "This blocking operation is easily solved by relying on one of the most used asynchronous HTTP clients, aiohttp, which provides a non-blocking HTTP connection pooling mechanism to reuse a connection to a server.", aiohttp 是 "Asynchronous HTTP Client/Server for asyncio and Python."。aiohttp 既可以做 Client, 也可以做 Server, 而不只是 Client，这样写容易让人误解。<br/>p71, 测试代码的模块命名为 test1.py，这在实际的开发中是万万不行的，同时也没有指出在实际开发中，测试代码的组织结构。<br/>p91, "Several Python frameworks became popular way before asynchronous programming mechanisms had become incorporated into Python’s core APIs. "。这里用 Python’s core APIs 这个概念， 其实大部分人看到这个概念根本不知道指的是什么。</p><p>本来阅读是为了解决一些问题，但是如果阅读这本书，问题会更多，因为如果你是很认真的看，你就需要花大量的时间去梳理作者说的某个概念具体指的是什么，作者说的到底对不对。</p><p>回到为什么读这本书——“了解一些异步开发， asyncio 的用法”，这本书没有解决我的问题，因为介绍的非常浅，仅仅写个 demo 而已，根本无法在生产环境使用。</p><h2>四、阅读方法</h2><p>基于本人秉持的观点“虽然每个作者的写作水平不一样，但我们要做一个高水平的读者，要根据作者的写作水平，调整自己的阅读方法”，本人阅读此书的方法如下：</p><p>1..直接下载源码，然后在源码里面创建目录写自己的代码。之前自己都是新建一个项目写代码，然后在自己的项目和书中的项目来回切换，太麻烦了。</p><p>2.作者很多描述是不准确的，不必纠结于作者给出的概念，先往下读。</p><p>3.对于不熟悉的技术，如：异步编程的语法，包。先熟悉，再自己写，不然就会遇到各种问题。虽然先自己写，然后再和作者的代码对比也是一种方式，但是更慢。</p><h2>五、这本书适合什么样的人？</h2><p>介于作者泛泛而谈，东一榔头，西一棒子，距离工程应用相距十万八千里，本书只适合想大概浏览一下 Python 异步编程相关库的人。</p><h2>六、阅读指数</h2><p>按照 5 星标准，本书阅读指数 1 颗星(★☆☆☆☆)。</p><h2>七、参考资料</h2><h3>1. 编程</h3><p>(1)豆瓣，Nicolas Bohorquez，《Asynchronous Programming in Python》：<a href="https://link.segmentfault.com/?enc=PyUJi11WJQXzrYa7VmJ9Og%3D%3D.cslRavXiISgxcD7jK7T8W%2BmbDdDPz1CLk4RmPky00xIpNknUoHzjDMWyUIq8Twbw" rel="nofollow" target="_blank">https://book.douban.com/subject/38207055/</a></p><p>(2)Github，源码：<a href="https://link.segmentfault.com/?enc=BIJ85cvhn4mwNw%2FhKH1Rjw%3D%3D.ayasxcrO9RlhHxq8IDNgXq1jjZe0USfWktWeVGOvd37Jo0W7vpVOFgoebO6rZkS9eN%2BTqLRzG76Ui9P8qr0U9laOR47p9nByBVFbQ3xWets%3D" rel="nofollow" target="_blank">https://github.com/PacktPublishing/Asynchronous-Programming-in-Python</a></p><h3>2. 英语</h3><p>(1) Etymology Dictionary：<a href="https://link.segmentfault.com/?enc=EHejFammhlhZiRFuk2375Q%3D%3D.05ieHYkXpCE%2BUnallaKENU8JIwAo4efSehOFub7huPU%3D" rel="nofollow" target="_blank">https://www.etymonline.com</a></p><p>(2) Cambridge  Dictionary：<a href="https://link.segmentfault.com/?enc=x7STvFTuEA2dQFNVNlnchA%3D%3D.Zfg4GF7tr3gzAYvONX9XDcHAcW%2B%2Bp7EJlUZZvfiaUATFV%2BfYzqNCc1f8e5u%2BLC3b" rel="nofollow" target="_blank">https://dictionary.cambridge.org</a><br/><img width="723" height="262" referrerpolicy="no-referrer" src="/img/bVdnvm4" alt="" title=""/></p><p>欢迎搜索及关注：编程人(a_codists)</p>]]></description></item><item>    <title><![CDATA[5大主流CRM品牌核心能力深度横评：从客户到生态的全维度对决 傲视众生的脸盆 ]]></title>    <link>https://segmentfault.com/a/1190000047560614</link>    <guid>https://segmentfault.com/a/1190000047560614</guid>    <pubDate>2026-01-23 12:06:15</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在数字化转型浪潮中，CRM（客户关系管理）已从“销售工具”升级为“企业增长引擎”，其能力覆盖<strong>客户全生命周期管理、销售流程管控、智能决策辅助、定制化适配</strong>及<strong>生态整合</strong>五大核心维度。本文选取<strong>超兔一体云</strong>（中大型复杂业务适配）、<strong>Oracle CX</strong>（Enterprise级全流程管控）、<strong>Pipedrive</strong>（中小团队可视化）、<strong>Salesforce</strong>（全规模生态整合）、<strong>探马SCRM</strong>（微信生态深度融合）五大主流品牌，从专业视角展开横向对比，为企业选型提供参考。</p><h2>一、核心维度对比框架</h2><p>本次横评围绕CRM的<strong>价值核心</strong>设计对比模型，覆盖5大维度、20+关键指标：</p><table><thead><tr><th>维度</th><th>关键指标</th></tr></thead><tbody><tr><td>客户管理</td><td>全生命周期覆盖、360°视图、多渠道整合、查重/背景调查、数据权限</td></tr><tr><td>销售管理</td><td>跟单模型多样性、流程覆盖、智能工具、合同管理、团队协同</td></tr><tr><td>AI智能</td><td>场景覆盖、生成式AI、个性化辅助、数据驱动分析</td></tr><tr><td>自定义能力</td><td>低代码配置、菜单/工作台、业务表/工作流、多表聚合</td></tr><tr><td>API对接</td><td>API丰富度、集成案例、RPA支持、第三方生态</td></tr></tbody></table><h2>二、客户管理能力：从“流量”到“留量”的全生命周期对决</h2><p>客户管理是CRM的基础，核心是<strong>将“线索”转化为“终身客户”</strong> ，关键看全流程覆盖深度与数据整合能力。</p><h3>1. 核心能力对比表</h3><table><thead><tr><th>对比点</th><th>超兔一体云</th><th>Oracle CX</th><th>Pipedrive</th><th>Salesforce</th><th>探马SCRM</th></tr></thead><tbody><tr><td>全生命周期覆盖</td><td>线索→复购全流程（含RFM复购预警）</td><td>创建→管理→培育全流程</td><td>线索→转化全流程</td><td>全渠道全流程（营销→销售→服务）</td><td>微信生态全流程（添加→成交→复购）</td></tr><tr><td>360°视图</td><td>整合客户+财务+跟进数据</td><td>集成CDP，营销/销售/服务数据</td><td>整合邮件/电话/社交互动</td><td>Einstein Analytics全渠道整合</td><td>微信行为+客户画像整合</td></tr><tr><td>多渠道整合</td><td>百度、抖音、微信、官网等</td><td>在线聊天、电话、社交</td><td>邮件、电话、社交</td><td>全渠道（线上+线下+社交）</td><td>企业微信、小程序、电商</td></tr><tr><td>查重/背景调查</td><td>工商补全、手机号/简称模糊查重</td><td>信用评级与风险管控</td><td>无明确查重，整合互动记录</td><td>数据清洗与重复项合并</td><td>微信好友重复检测</td></tr><tr><td>数据权限</td><td>分级隔离（上级管下级、财务权限）</td><td>角色/剖面精细化权限</td><td>基础角色权限</td><td>角色/剖面/共享规则</td><td>企业微信角色权限（销售组/主管）</td></tr></tbody></table><h3>2. 深度分析</h3><ul><li><strong>超兔一体云</strong>：聚焦“全生命周期闭环”，线索获取支持<strong>百度广告、抖音巨量、微信小程序</strong>等10+渠道，线索处理环节自动完成<strong>工商信息补全、手机号查重、企业简称模糊匹配</strong>（避免“XX科技”与“XX信息技术”重复）；客户跟进阶段支持<strong>用户画像自定义、列表布局调整</strong>，售后通过<strong>RFM分析</strong>（最近消费、频率、金额）精准触发复购预警，实现“线索→客户→复购”的完整闭环。</li><li><strong>Oracle CX</strong>：主打“Enterprise级大客户管理”，通过<strong>客户数据平台（CDP）整合营销、销售、服务数据，构建360°客户视图；支持客户分层</strong>（战略客户/潜力客户），为战略客户配置“高层拜访+定制化服务”专属策略；内置<strong>信用评级模型</strong>，超额度订单需审批，降低坏账风险。</li><li><strong>Pipedrive</strong>：适合“中小团队移动跟进”，多渠道整合<strong>邮件、电话、社交互动记录</strong>，移动端“附近”功能可定位周边潜在客户；360°视图聚焦“互动轨迹”，帮助销售快速回顾与客户的沟通历史。</li><li><strong>Salesforce</strong>：全渠道整合能力最强，通过<strong>Einstein Analytics</strong>将线上（官网、电商）、线下（门店、展会）、社交（微信、LinkedIn）数据汇总，支持<strong>客户旅程个性化设计</strong>（如对“流失客户”推送专属折扣）。</li><li><strong>探马SCRM</strong>：微信生态是核心优势，覆盖“企业微信添加→会话跟进→成交→复购”全流程，通过<strong>会话存档</strong>记录微信聊天内容，<strong>客户画像</strong>整合微信行为（如浏览朋友圈、点击小程序），数据权限与企业微信角色绑定（如销售组仅能查看本组客户）。</li></ul><h3>3. 流程图：超兔客户全生命周期闭环</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560616" alt="" title=""/></p><pre><code>sequenceDiagram
    participant 市场部 as 市场部
    participant 超兔系统 as 超兔一体云
    participant 销售部 as 销售部
    participant 客户 as 客户
    participant 售后部 as 售后部

    市场部-&gt;&gt;超兔系统: 投放百度/抖音广告，获取线索
    超兔系统-&gt;&gt;超兔系统: 线索处理（加客户、分配销售、查工商信息）
    超兔系统-&gt;&gt;销售部: 发送跟进提醒（待办任务+客户详情）
    销售部-&gt;&gt;超兔系统: 记录跟进（时间线、通话录音、外勤定位）
    销售部-&gt;&gt;客户: 沟通需求，推进订单
    客户-&gt;&gt;超兔系统: 下单（支持标准/批发/非标定制）
    超兔系统-&gt;&gt;销售部: 触发订单待办（锁库、生成采购计划）
    超兔系统-&gt;&gt;售后部: 推送售后任务（维修工单、RFM分析）
    售后部-&gt;&gt;超兔系统: 记录售后（工单处理+客户反馈）
    超兔系统-&gt;&gt;销售部: 发送复购预警（流失提醒+精准回访建议）
    销售部-&gt;&gt;客户: 复购沟通
    客户-&gt;&gt;超兔系统: 复购下单</code></pre><h2>三、销售管理能力：从“流程”到“效率”的复杂业务适配</h2><p>销售管理的核心是<strong>让“复杂业务”变“可复制流程”</strong> ，关键看跟单模型多样性与流程协同能力。</p><h3>1. 核心能力对比表</h3><table><thead><tr><th>对比点</th><th>超兔一体云</th><th>Oracle CX</th><th>Pipedrive</th><th>Salesforce</th><th>探马SCRM</th></tr></thead><tbody><tr><td>跟单模型</td><td>小单/商机/多方项目/组织型客户</td><td>线索→商机→CLM→订单</td><td>销售漏斗（线索→商机→合同）</td><td>销售云自动化（机会/报价/订单）</td><td>微信会话→电销→合同</td></tr><tr><td>流程覆盖</td><td>全流程（线索→订单→售后→复购）</td><td>全流程（线索→合同→订单→售后）</td><td>线索→转化</td><td>全流程（营销→销售→服务）</td><td>微信生态全流程</td></tr><tr><td>智能工具</td><td>三一客（小单）、项目视图（多方）</td><td>智能报价引擎（阶梯折扣）</td><td>销售预测（历史数据）</td><td>Einstein Opportunity Scoring</td><td>会话AI分析、电销录音</td></tr><tr><td>合同管理</td><td>多业务类型（租售/套餐/非标）</td><td>合同生命周期管理（CLM）</td><td>基础合同模板</td><td>智能合同（自动审批/条款分析）</td><td>关联微信客户的合同管理</td></tr><tr><td>团队协同</td><td>项目组/分组隔离跟单</td><td>跨部门协同（销售→电商→服务）</td><td>任务提醒+会议调度</td><td>团队绩效仪表盘+共享规则</td><td>企业微信侧边栏+共享客户</td></tr></tbody></table><h3>2. 深度分析</h3><ul><li><p><strong>超兔一体云</strong>：<strong>多跟单模型</strong>是核心优势，覆盖4类复杂业务场景：</p><ul><li>小单快单：用“三一客”（三定：定性、定级、定量）快速推进；</li><li>中长单：用“商机阶段管理”跟踪预期日期与关键节点；</li><li>多方项目：用“项目视图”管控项目组、合同、采购、收支差（适合大型项目）；</li><li>组织型客户：支持“医院→科室→主任”“高校→院系→教研室”多级分组，多组分别跟单，汇总到上级客户。 此外，<strong>通用跟单能力</strong>覆盖“360°视图、跟单时间线、通信集成（通话/短信）、外勤记录”，让销售快速掌握客户全貌。</li></ul></li><li><strong>Oracle CX</strong>：合同生命周期管理（CLM）是亮点，支持从“合同起草→审批→签署→履约”全流程自动化，内置“智能报价引擎”（基于历史数据推荐最优价格，支持阶梯折扣、区域定价），适合大型企业的复杂定价规则。</li><li><strong>Pipedrive</strong>：<strong>销售漏斗可视化</strong>是核心，通过“看板视图”实时跟踪线索→商机→合同的进度，自动化任务提醒（如“3天内跟进高意向客户”），帮助中小团队避免遗漏关键环节。</li><li><strong>Salesforce</strong>：<strong>销售云自动化</strong>能力最强，通过“Einstein Opportunity Scoring”（商机评分）识别高转化线索，“智能报价工具”支持自定义规则（如“老客户享9折”），团队绩效仪表盘实时监控“销售漏斗转化率”“平均成交周期”，优化资源分配。</li><li><strong>探马SCRM</strong>：聚焦“微信生态销售”，通过<strong>企业微信侧边栏</strong>快速查看客户画像、历史会话，<strong>电销管理</strong>整合通话录音与AI分析（识别客户意向），合同管理关联微信客户，适合“微信+电销”的销售模式。</li></ul><h3>3. 脑图：超兔销售管理核心能力</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560617" alt="" title="" loading="lazy"/></p><pre><code>mindmap
    root((超兔销售管理))
        多跟单模型
            小单快单：三一客（三定+关键节点）
            商机跟单：阶段+预期日期
            多方项目：项目视图（收支管控）
            组织型客户：分组隔离（医院→科室）
        通用能力
            360°视图（客户+订单+跟进）
            跟单时间线（历史行为）
            通信集成（通话+短信）
            外勤记录（定位+照片）
        合同订单
            多业务类型（标准/批发/租售）
            订单财务管控（应收触发+账期）
            订单工作流（锁库+采购计划）</code></pre><h2>四、AI智能能力：从“辅助”到“决策”的业务深度融入</h2><p>AI已从“工具”升级为“销售顾问”，核心看<strong>能否融入业务场景，解决实际问题</strong>。</p><h3>1. 核心能力对比表</h3><table><thead><tr><th>对比点</th><th>超兔一体云</th><th>Oracle CX</th><th>Pipedrive</th><th>Salesforce</th><th>探马SCRM</th></tr></thead><tbody><tr><td>场景覆盖</td><td>销售SOP/AI待办/AI日报/话术推荐</td><td>营销ROI/销售预测/合同审查</td><td>AI获客/交易概率/任务优先级</td><td>生成式AI（邮件/报价/合同）</td><td>会话AI/电销分析/意向预测</td></tr><tr><td>生成式AI</td><td>行业SOP生成、个性化话术</td><td>营销内容生成（SMS/邮件）</td><td>无明确生成式AI</td><td>Einstein GPT（全场景生成）</td><td>会话回复建议</td></tr><tr><td>个性化辅助</td><td>融入客户数据（行业/跟单时间线）</td><td>基于历史数据的报价推荐</td><td>任务优先级建议</td><td>个性化客户旅程</td><td>微信行为的意向分析</td></tr><tr><td>数据驱动分析</td><td>RFM复购分析、行动记录分析</td><td>营销ROI计算、销售预测</td><td>销售业绩仪表盘</td><td>Einstein Analytics（全渠道）</td><td>客户行为漏斗分析</td></tr></tbody></table><h3>2. 深度分析</h3><ul><li><p><strong>超兔一体云</strong>：AI<strong>深度融入业务场景</strong>，而非“独立功能”：</p><ul><li>AI生成销售SOP：结合行业特性（如“医疗器械”“教育”）生成标准化流程，包含“开场白话术→需求挖掘→异议处理”；</li><li>AI待办：基于销售行动记录（如“昨天与客户沟通了产品价格”）自动创建“跟进价格异议”的待办任务，明确完成期限；</li><li>AI日报：自动分析当日工作数据，生成“销售概述、客户意向评估、卡单问题点”，减少销售整理时间；</li><li>个性化话术：调用客户“行业、跟单时间线、历史互动”数据，生成针对性话术（如“针对XX科技的 SaaS 需求，推荐XX套餐”）。</li></ul></li><li><p><strong>Oracle CX</strong>：<strong>AI for CX</strong>整合传统AI与生成式AI，覆盖营销、销售、服务：</p><ul><li>营销类：AI计算“获客成本（CAC）”与“客户终身价值（LTV）”，优化营销预算；</li><li>销售类：AI预测商机成功概率，推荐“交叉销售/追加销售”建议；</li><li>服务类：AI审查合同条款，识别风险（如“未明确履约期限”）。</li></ul></li><li><p><strong>Salesforce</strong>：<strong>Einstein GPT</strong>是行业标杆，支持全场景生成式AI：</p><ul><li>生成邮件：根据客户历史互动生成“个性化跟进邮件”；</li><li>生成报价：结合客户需求与定价规则生成“最优报价单”；</li><li>生成合同：自动填充客户信息与条款，支持电子签署。</li></ul></li><li><strong>探马SCRM</strong>：AI聚焦“微信生态”，通过<strong>会话AI分析</strong>识别客户意向（如“客户提到‘价格太高’”，系统自动标记“价格异议”），<strong>电销录音分析</strong>提取“客户需求关键词”，帮助销售快速调整策略。</li></ul><h2>五、自定义能力：从“适配”到“贴合”的企业个性化需求</h2><p>自定义能力决定CRM能否“适配企业现有流程”，而非“让企业迁就系统”。</p><h3>1. 核心能力对比表</h3><table><thead><tr><th>对比点</th><th>超兔一体云</th><th>Oracle CX</th><th>Pipedrive</th><th>Salesforce</th><th>探马SCRM</th></tr></thead><tbody><tr><td>低代码配置</td><td>功能白名单订阅（按需选模块）</td><td>Visual Builder（可视化配置）</td><td>无代码（字段/流程调整）</td><td>Lightning App Builder</td><td>企业微信侧边栏定制</td></tr><tr><td>菜单/工作台</td><td>自定义三级菜单+多岗位大屏</td><td>预建模板+沙盒测试</td><td>基础菜单调整</td><td>自定义工作台+仪表盘</td><td>企业微信工作台定制</td></tr><tr><td>业务表/工作流</td><td>AI生成工作流+多表聚合分析</td><td>非标流程配置（工业订单）</td><td>自动化工作流（线索分配）</td><td>Flow Builder（复杂工作流）</td><td>客户字段/报表自定义</td></tr><tr><td>多表聚合</td><td>复杂多表关联分析（BI）</td><td>预建报表+仪表盘</td><td>基础报表</td><td>Einstein Analytics（多表）</td><td>微信行为+客户数据聚合</td></tr></tbody></table><h3>2. 深度分析</h3><ul><li><strong>超兔一体云</strong>：<strong>功能白名单订阅</strong>降低企业成本（按需选择“客户管理”“销售管理”“AI智能”等模块）；<strong>自定义三级菜单</strong>支持“销售岗→客户列表→跟进记录”“财务岗→应收→开票”等个性化布局；<strong>业务表自定义</strong>允许企业在“客户、订单、项目”模块添加自定义字段（如“医疗器械”行业添加“产品注册证号”）；<strong>AI生成工作流</strong>通过自然语言（如“当客户下单金额超过10万时，触发财务审批”）快速创建流程，无需代码。</li><li><strong>Oracle CX</strong>：<strong>Visual Builder</strong>可视化配置工具，支持“拖放式”搭建非标流程（如“工业非标订单的审批流程”），预建模板库覆盖“制造、零售、医疗”等行业，沙盒环境测试降低实施风险。</li><li><strong>Salesforce</strong>：<strong>Lightning App Builder</strong>与<strong>Flow Builder</strong>是自定义能力的核心，支持“自定义对象、字段、流程、仪表盘”，甚至可以搭建“行业专属CRM”（如“房地产CRM”“金融CRM”）。</li></ul><h2>六、API对接能力：从“孤岛”到“生态”的系统协同</h2><p>API对接能力决定CRM能否“融入企业现有IT生态”，关键看<strong>API丰富度、集成案例、RPA支持</strong>。</p><h3>1. 核心能力对比表</h3><table><thead><tr><th>对比点</th><th>超兔一体云</th><th>Oracle CX</th><th>Pipedrive</th><th>Salesforce</th><th>探马SCRM</th></tr></thead><tbody><tr><td>API丰富度</td><td>客户/订单/销售数据API</td><td>开放API网关 + 预建流程</td><td>开放式API（500 + 集成）</td><td>REST/SOAP API + AppExchange</td><td>企业微信/电商/ERP API</td></tr><tr><td>集成案例</td><td>金蝶/用友ERP、京东/淘宝电商、国税</td><td>ERP/MES/电子签名</td><td>Slack/Google/Zapier</td><td>ERP/电商/营销工具（2000 +）</td><td>企业微信/淘宝/京东</td></tr><tr><td>RPA支持</td><td>强大的RPA开发力量，通过机器人读写外部系统</td><td>未提及</td><td>未提及</td><td>未提及</td><td>未提及</td></tr><tr><td>第三方生态</td><td>具备丰富的对接经验，能满足企业与多种业务系统协同需求</td><td>支持与多种内部系统及第三方应用集成</td><td>可与众多常见第三方应用集成</td><td>拥有庞大的AppExchange生态，几乎兼容所有主流工具</td><td>聚焦企业微信生态，可与电商等系统集成</td></tr></tbody></table><h3>2. 深度分析</h3><ul><li><strong>超兔一体云</strong>：拥有丰富的业务API，涵盖客户、订单、销售等多方面数据，为企业与其他业务系统的对接提供了坚实基础。其与金蝶、用友等ERP系统，京东、淘宝等电商平台，以及国税开票机器人都有成功的对接案例，积累了丰富的对接经验。同时，强大的RPA开发力量能够模拟人工操作，实现与外部系统的自动化对接，进一步提升了企业的工作效率和数据准确性。</li><li><strong>Oracle CX</strong>：提供开放API网关和预建集成流程，可无缝对接ERP、MES等内部系统，还支持电子签名、支付工具等第三方应用集成。通过低代码工具简化跨系统数据流转，方便非技术人员进行配置，增强了系统的集成性和易用性。</li><li><strong>Pipedrive</strong>：开放式API支持与500 + 第三方应用集成，如Slack、Google Workspace、Zapier、Gmail等，可同步邮件、联系人、日历事件等数据，实现与现有工具链的打通。官方还提供NodeJS API客户端，方便开发者进行对接与扩展。</li><li><strong>Salesforce</strong>：具备REST/SOAP API和强大的AppExchange生态，几乎兼容所有主流工具，集成案例超过2000个。其丰富的API和庞大的生态系统，使得企业能够轻松地将Salesforce与各种内部和外部系统进行集成，实现数据的共享和业务的协同。</li><li><strong>探马SCRM</strong>：支持企业微信、电商、ERP等API对接，聚焦于企业微信生态，能够与淘宝、京东等电商平台集成。通过与企业微信的深度融合，实现了销售过程的透明化和客户管理的精细化。</li></ul><h2>七、总结</h2><p>在数字化转型的大背景下，CRM系统已经成为企业提升竞争力的关键工具。本次对超兔一体云、Oracle CX、Pipedrive、Salesforce和探马SCRM这五大主流CRM品牌在客户管理、销售管理、AI智能、自定义能力和API对接等核心维度的深度横评，为企业在选择CRM系统时提供了全面而详细的参考。</p><p>超兔一体云凭借其多跟单模型、AI深度融入业务场景、功能白名单订阅以及丰富的API对接经验，适合中大型企业处理复杂业务场景，实现全生命周期的客户管理和高效的销售流程管控。</p><p>Oracle CX以其Enterprise级的大客户管理能力、AI for CX的全面覆盖以及可视化的低代码配置工具，满足大型企业对复杂业务流程和精细管理的需求。</p><p>Pipedrive的销售漏斗可视化和移动端便捷性，使其成为中小团队移动跟进客户的理想选择。</p><p>Salesforce凭借其强大的全渠道整合能力、行业标杆的Einstein GPT和庞大的AppExchange生态，为企业提供了一站式的CRM解决方案，尤其适合对数据集成和自动化要求较高的企业。</p><p>探马SCRM则聚焦于微信生态，通过会话存档、电销管理和合同关联等功能，满足了“微信 + 电销”销售模式的企业需求。</p><p>企业在选择CRM系统时，应根据自身的业务规模、行业特点、发展阶段和具体需求，综合考虑各品牌的优势和劣势，选择最适合自己的CRM系统，以实现企业的数字化转型和业务增长。</p><p>（注：文中功能相关描述均基于公开披露信息，具体功能服务以厂商实际落地版本为准。）</p>]]></description></item><item>    <title><![CDATA[2026 AI 元年：从技术狂欢到价值共生的智能新纪元 智能猫 ]]></title>    <link>https://segmentfault.com/a/1190000047560628</link>    <guid>https://segmentfault.com/a/1190000047560628</guid>    <pubDate>2026-01-23 12:05:36</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>​<strong>摘要</strong>​：若说 2023 年是生成式 AI 的概念启蒙年，2026 年则正式开启了人工智能的“应用元年”与“价值兑现年”。这一年，大模型技术从参数竞赛迈入能力沉淀期，NSP 范式推动 AI 实现从“预测文本”到“理解世界”的认知跨越，具身智能、多智能体系统从实验室走向产业实景，资本市场对 AI 企业的估值逻辑从“技术故事”转向“落地能力”。本文立足 2026 年 AI 产业爆发的核心特征，深度解析技术范式变革的底层逻辑，拆解工业、金融、医疗、出行等领域的商业化落地场景，探讨 AI 对社会生产生活的重构影响，梳理技术落地中的伦理与安全挑战，并结合行业实践给出企业与个人的适配策略，最后通过高频 QA 问答解答核心困惑，为把握 AI 元年的发展机遇提供全景式参考。</p><p>​<strong>关键词</strong>​：2026 AI 元年；NSP 范式；具身智能；多智能体系统；AI 商业化落地；自动驾驶；智能体协作；AI 伦理规范</p><h2>一、为何是 2026？AI 元年的三大核心支撑</h2><p>“元年”的界定，从来不是单一技术的突发突破，而是技术成熟度、产业需求度与生态完备度的三重共振。2026 年之所以能成为公认的 AI 元年，核心源于三个关键临界点的全面突破，让人工智能彻底告别“实验室阶段”，迈入规模化产业应用的全新周期。</p><h3>1.1 技术临界点：从“文本预测”到“世界理解”的认知跃迁</h3><p>北京智源人工智能研究院发布的《2026 十大 AI 技术趋势》明确指出，AI 发展的核心转变已从“预测下一个词（NTP 范式）”迈向“预测世界状态（NSP 范式）”。这一技术范式的革新，让 AI 首次具备了理解物理世界规律的能力，实现了从“感知”到“认知”的本质跨越。不同于传统语言模型仅能生成连贯文本，基于 NSP 范式的世界模型通过多模态数据统一编码，可自主学习物理动态、时空连续性与因果关系，形成“理解-预测-规划”的完整认知闭环。</p><p>2026 年，这一技术突破已形成规模化应用基础：海外 OpenAI 的 Sora 2 展现出对真实世界的深度模拟能力，World Labs 的 RTFM 模型可从单幅图像创建 3D 空间；国内智源悟界·Emu3.5 成为 NSP 范式的标杆，蚂蚁百灵大模型在多模态生成、方言识别领域已逼近 GPT-5 水平。这种“世界模拟器”级别的能力，为 AI 从数字空间渗透至物理世界提供了核心技术底座。</p><h3>1.2 成本临界点：推理成本骤降催生规模化应用</h3><p>技术普及的前提是成本可控。相比 2023 年，2026 年大模型的 Token 推理成本下降了 99% 以上，这一“摩尔定律式”的成本锐减，让 AI 部署从“高成本试点”变为“全场景可行”。无论是企业级的复杂流程优化，还是个人端的微小服务需求（如自动整理发票、智能回复评论），都具备了经济可行性。</p><p>成本下降的背后，是算力架构优化与技术迭代的双重驱动：一方面，专用 AI 芯片的量产降低了硬件门槛；另一方面，模型轻量化技术的突破的，让中小微企业无需搭建高算力集群，通过调用公有云 API 即可享受高阶 AI 能力。成本的“亲民化”，为 AI 元年的全面爆发扫清了最关键的商业障碍。</p><h3>1.3 生态临界点：资本理性回归与产业需求共振</h3><p>2026 年初，港股市场的 AI 企业上市潮成为行业转折的重要注脚：智谱 AI 以“全球通用大模型第一股”身份登陆港交所，1164 倍超额认购、首日 528 亿港元市值；仅隔一天，MiniMax 接力挂牌，1837 倍超额认购、盘中涨幅超 109%、市值破千亿港元。短短 48 小时，两家头部企业募资近百亿港元，市值总和逼近 1700 亿港元，这场资本盛宴的背后，是市场对 AI 产业价值的集体押注。</p><p>更重要的是，资本逻辑已从“盲目追逐参数规模”转向“聚焦技术落地能力”。与此同时，产业端的需求已进入“爆发期”：全球 AI 市场规模从 2025 年的 7575.8 亿美元增至 9000 亿美元，同比增长 18.7%；国务院“人工智能 +”行动将 AI 定位为新型工业化“必答题”，工业、金融、医疗等领域的智能化需求迫切。资本理性与产业需求的精准对接，构成了 AI 元年的生态基础。</p><h2>二、AI 元年的核心技术突破：重构智能的底层逻辑</h2><p>2026 年的 AI 技术突破，不再是单一维度的参数提升，而是从架构设计、能力形态到协作模式的全方位重构，催生出一系列具备“工业化稳定性”的智能形态，为商业化落地提供了多元化支撑。</p><h3>2.1 NSP 范式主导：AI 成为“世界规律的探索者”</h3><p>NSP（Next-State Prediction）范式的普及，是 2026 年 AI 技术变革的核心标志。这一范式让 AI 从“文字游戏”升级为“世界模拟器”，其核心价值在于让模型具备了对物理世界的预测与规划能力。在自动驾驶领域，基于 NSP 范式的系统可通过模拟复杂路况，大幅降低实车测试成本；在机器人训练中，虚拟场景预训练让实体机器人的环境适应能力提升 50% 以上；在科研领域，AI 通过模拟分子运动，将新药研发周期从数年缩短至数月。</p><p>与传统 NTP 范式相比，NSP 范式的核心优势在于“因果推理能力”——不再是基于概率的文本生成，而是基于对世界规律的理解做出决策。这种能力升级，让 AI 从“辅助工具”向“决策主体”转变，成为 AI 元年技术价值爆发的核心引擎。</p><h3>2.2 具身智能“出清期”：从技术演示到产业工具</h3><p>经过 2025 年的“百机大战”，2026 年具身智能行业进入“出清期”：同质化企业因资金断裂或技术不足被淘汰，头部企业凭借订单优势与技术积累形成稳定格局。技术层面，“世界模型 + 强化学习”的闭环进化模式成为主流，智源发布的通用具身大脑 RoboBrain2.0 与小脑基座 RoboBrain-X0，实现了跨场景多任务的轻量化部署；海外 Tesla Optimus 2.5 已应用于工厂生产、农场运营等真实场景。</p><p>商业化方面，具身智能正式从“实验室验证”转向“量产交付”。智元、乐聚智能等企业推进上市进程，标志着这一领域已从“技术概念”走向“产业工具”。在工业制造的精密装配、服务业的个性化服务、医疗领域的辅助诊疗等场景，具身智能正逐步替代人工完成高难度、高重复性工作，成为实体产业智能化转型的核心抓手。</p><h3>2.3 多智能体系统：标准化协议推动“协同作战”</h3><p>面对日益复杂的任务需求，单智能体的能力天花板逐渐显现，多智能体系统（MAS）成为解决复杂问题的关键路径。2026 年，多智能体发展的核心突破是“协议标准化”——MCP 与 A2A 通信协议被捐赠给 Linux 基金会后实现分层融合，成为 Microsoft、Google 等巨头及 LangChain、AutoGen 等框架的原生支持协议，IBM 计划将 ACP 协议并入 A2A，推动行业标准统一。</p><p>协议的统一，让不同企业开发的智能体拥有了“通用语言”，能够跨平台协作完成复杂任务流。在金融领域，由风险评估智能体、投资分析智能体、客户服务智能体组成的团队，可协同完成全流程金融服务；在工业场景中，生产智能体、质检智能体、物流智能体形成协作网络，将全产业链效率提升 30% 以上。多智能体的“协同作战”模式，正在重构企业的生产运营逻辑。</p><h3>2.4 确定性逻辑回归：AI 从“玩具”走向“生产力”</h3><p>单纯依赖大模型的概率生成无法满足企业级需求，2026 年的主流架构已演变为“LLM（大脑）+ Code（肌肉）”的混合模式。通过 Python 等确定性代码约束大模型的“幻觉”，让 AI 应用具备了工业级的稳定性。这种确定性逻辑的回归，是 AI 从“娱乐工具”走向“核心生产力”的关键一步。</p><p>技术专家金加德指出，企业级应用对错误零容忍，大模型的本质是概率预测，存在幻觉风险，而确定性代码的引入，可为不可控的模型行为加上“护栏”。例如，在财务数据处理场景中，通过 Python 正则表达式精准提取关键信息，再由大模型进行分析总结，既保证了数据准确性，又发挥了模型的分析能力，实现了“精准性”与“智能化”的平衡。</p><h2>三、AI 元年的商业化落地：ToC 与 ToB 的双轨爆发</h2><p>技术突破的最终价值，需要通过商业化落地实现闭环。2026 年，AI 应用呈现“ToC 超级应用竞逐 +ToB 垂直突破”的双轨格局，经历早期概念验证的“幻灭期”后，真正可衡量的商业价值集中爆发，印证了 AI 元年的产业价值。</p><h3>3.1 ToC 端：超级应用重构互联网流量格局</h3><p>“All in One”的超级应用成为 C 端 AI 竞争的核心战场。这种以单一入口实现信息获取、任务规划、问题解决的闭环模式，依托高算力成本与庞大用户数据迭代，正在重塑互联网流量格局。2026 年，海外 ChatGPT、Gemini 日活均突破 1 亿，Gemini 已取代 Google Maps 原生语音助手，实现功能内化；国内市场同样热闹，蚂蚁“灵光”AI 助手上线 6 天下载量破 200 万，支持 30 秒生成小应用与全模态输出；字节豆包依托抖音生态引流，月活位居全球第二，仅次于 ChatGPT。</p><p>超级应用的竞争本质是生态整合能力的较量。字节跳动凭借短视频流量优势，将 AI 助手深度融入内容创作、社交互动、生活服务场景；阿里以千问 App 为核心，整合消费、支付、物流等电商生态资源；蚂蚁集团则依托金融科技优势，让“灵光”助手具备理财咨询、生活缴费、政务办理等复合功能。2026 年，超级应用已进入“生态闭环决战”阶段，能够实现跨场景无缝衔接、个性化精准服务的产品，将定义 AI 时代的“新 BAT”格局。</p><p>与此同时，垂直赛道成为中小玩家的突围机会。多模态、大健康、教育等高 ROI 领域呈现“低频高价值”特征，Google Nano Banana Pro 单次调用价格为文本模型的几十倍，但仅需 1.5% 调用量即可实现同等收入。国内，蚂蚁“蚂蚁阿福”健康 App 聚焦慢病管理、健康咨询等场景；MiniMax 的海螺 AI 深耕视频创作赛道，成为自媒体、设计师的必备工具；字节即梦 AI 在教育领域的个性化辅导功能，精准击中用户痛点。这些垂直应用凭借高用户粘性与强付费意愿，构建了可持续的盈利模式，成为 C 端 AI 商业化的重要补充。</p><h3>3.2 ToB 端：垂直场景突破赋能产业转型</h3><p>ToB 领域的 AI 落地，呈现“核心行业先行、全链路渗透”的特征，工业、金融、医疗、出行等领域成为 AI 价值兑现的核心阵地，推动产业智能化转型进入深水区。</p><p>在工业制造领域，“AI+ 制造”已从单点自动化升级为全流程智能化。通过部署生产智能体、质检智能体与物流智能体，企业实现了从原材料采购到成品交付的全链路优化。某汽车零部件企业引入多智能体协作系统后，生产效率提升 28%，不良率下降 40%，充分验证了 AI 对工业场景的赋能价值。</p><p>金融领域是 AI 落地的“高成熟度场景”。多智能体系统在风险评估、投资分析、客户服务等环节的应用，大幅提升了金融服务的效率与精准度。例如，某银行部署的智能风控系统，通过多智能体协同分析企业经营数据、行业趋势、市场风险，将不良贷款识别时间从 3 个月缩短至 1 周，识别准确率提升 55%。</p><p>医疗领域的 AI 应用则聚焦“精准诊疗”与“效率提升”。AI 辅助诊断系统通过分析医学影像、病历数据，可快速识别早期病灶，为医生提供精准参考；在新药研发领域，AI 通过模拟分子运动与药物作用机制，大幅缩短了研发周期、降低了研发成本，2026 年已有多款 AI 辅助研发的药物进入临床试验阶段。</p><p>出行领域的 L3 级自动驾驶商业化落地，成为 AI 元年的重要里程碑。2025 年底，中国首批 L3 级自动驾驶汽车获得专属牌照，正式从技术测试迈入“持证上路”阶段；2026 年初，元戎启行与国际头部主机厂达成 L3 级自动驾驶合作，力争 2026 年累计交付突破一百万辆。L3 级自动驾驶的核心突破在于责任主体的重构——在系统接管期间，驾驶责任由驾驶员转向系统，这一变化不仅考验技术稳定性，更推动了法规与产业生态的完善。元戎启行采用的 VLA 模型，通过引入语言模型具备“思维链”特点，可实现复杂的语义理解和长时序因果推理，全程可求导，让系统像老司机一样具备经验性判断能力。</p><h2>四、AI 元年的挑战：技术狂欢背后的伦理与安全考题</h2><p>AI 元年的全面爆发，不仅带来了技术突破与商业价值，也抛出了一系列伦理与安全考题。如何平衡技术创新与风险管控，成为 AI 可持续发展的关键前提，需要政府、企业与社会共同应对。</p><h3>4.1 伦理困境：算法偏见与责任界定难题</h3><p>算法偏见是 AI 落地的“隐性风险”。AI 模型的训练数据源于现实世界，若数据中存在性别、种族、地域等偏见，将导致模型输出带有歧视性的结果，在招聘、信贷、司法等场景中引发公平性问题。2026 年，随着 AI 应用的规模化，算法偏见问题逐渐显现，如何构建“公平、透明”的 AI 模型，成为企业需要解决的核心伦理课题。</p><p>责任界定难题则在高风险场景中尤为突出。以 L3 级自动驾驶为例，当系统接管期间发生交通事故，责任应归属驾驶员、车企还是 AI 系统开发商？目前，全球范围内的相关法规尚未形成统一标准，责任界定的模糊性，既影响了企业的技术推进节奏，也制约了消费者的接受度。</p><h3>4.2 安全风险：数据泄露与系统失控隐患</h3><p>数据安全是 AI 落地的“生命线”。AI 模型的训练与运行需要大量数据支撑，其中不乏企业商业机密与个人隐私数据。2026 年，多智能体系统的普及让数据流转路径更加复杂，若缺乏完善的权限管控与加密机制，将面临数据泄露、滥用的风险，违反《数据安全法》《个人信息保护法》等相关法规。</p><p>系统失控风险则是 AI 发展的“终极担忧”。随着 AI 自主决策能力的提升，尤其是多智能体协同系统的自主规划能力增强，若缺乏有效的“安全护栏”，可能出现超出人类预期的行为，引发安全事故。如何为 AI 系统设置“边界”，确保其始终在人类可控范围内运行，是全球 AI 领域的共同挑战。</p><h3>4.3 社会影响：就业结构重构与数字鸿沟</h3><p>AI 技术的规模化应用，必然带来就业结构的重构。重复性、标准化的工作岗位（如流水线工人、数据录入员、基础客服）将面临被 AI 替代的风险，而具备 AI 协作能力、创意能力、战略决策能力的岗位需求将大幅增加。这种结构性变化，需要劳动者提升自身技能以适应新的就业市场，也需要政府与企业共同推进职业培训体系的完善。</p><p>数字鸿沟问题也随之凸显。不同地区、不同群体对 AI 技术的掌握程度与应用能力存在差异，若缺乏有效的引导与扶持，可能导致部分群体被技术边缘化，加剧社会不平等。如何推动 AI 技术的普惠化应用，缩小数字鸿沟，是 AI 元年需要关注的社会议题。</p><h2>五、AI 元年的适配策略：企业与个人的破局之道</h2><p>面对 AI 元年的技术浪潮与产业变革，企业与个人需要主动适配、积极转型，才能把握发展机遇、规避潜在风险。无论是企业的技术落地，还是个人的职业发展，都需要建立全新的思维模式与能力体系。</p><h3>5.1 企业适配策略：从“技术跟风”到“价值导向”</h3><p>企业落地 AI 技术，应摒弃“盲目跟风”的心态，以“价值导向”为核心，从技术选型、场景适配、组织调整三个维度构建适配策略。</p><p>在技术选型上，中小企业无需盲目追求自建大模型，可通过调用公有云 API 或使用低代码智能体平台（如 Coze），低成本接入 AI 能力，优先选择标准化场景试点，验证价值后再逐步推广；大型企业可结合自身业务需求，进行定制化模型微调与多智能体系统搭建，构建核心技术壁垒。</p><p>在场景适配上，应遵循“先易后难、精准落地”的原则，优先选择痛点突出、数据基础好、ROI 高的场景（如金融风控、工业质检、客服优化），避免“为了 AI 而 AI”的无效投入。同时，要建立“AI+ 人工”的协同机制，在高风险场景中保留人工复核环节，确保安全可控。</p><p>在组织调整上，企业需要构建适配 AI 时代的组织架构与人才体系。一方面，通过培训提升现有员工的 AI 协作能力，让员工从重复性工作中解放，聚焦高价值任务；另一方面，引进具备 AI 架构设计、数据工程、业务理解能力的复合型人才，搭建专业的 AI 运营团队，支撑技术的持续落地与迭代。</p><h3>5.2 个人适配策略：从“技能竞争”到“能力重构”</h3><p>面对 AI 带来的职业变革，个人需要跳出传统的“技能竞争”思维，从三个维度重构自身能力体系，成为 AI 时代的“不可替代者”。</p><p>第一，掌握“胶水语言”能力。Python 作为 AI 时代的通用语，其核心价值不在于写底层算法，而在于数据清洗和逻辑兜底。即使是非技术岗位，掌握基础的 Python 技能，也能提升与 AI 协同工作的效率，例如用简单的脚本解决数据提取、格式转换等问题。</p><p>第二，培养“架构师思维”。不要沉迷于具体的工具使用，而要聚焦数据流的设计与问题的定义。能够清晰梳理业务流程、识别核心痛点，并将其映射为 AI 系统的工作流，这种架构设计能力是 AI 时代的核心竞争力。</p><p>第三，建立“领域知识壁垒”。AI 可以生成通用内容、完成标准化任务，但缺乏对特定行业的深度理解与业务潜规则的把握。“懂 AI 的业务专家”将比“懂业务的 AI 专家”更具竞争力，深入理解所在行业的痛点与需求，用 AI 优化业务流程，才能构建真正的个人壁垒。</p><h2>六、行业高频 QA 问答</h2><h3>6.1 2026 年被称为 AI 元年，和 2023 年的生成式 AI 热潮有什么本质区别？</h3><p>核心区别在于“技术概念”与“商业价值”的落地差异：2023 年的生成式 AI 热潮以技术启蒙和概念验证为主，AI 更多是“娱乐工具”或“辅助工具”，商业化落地处于早期阶段，缺乏可规模化的盈利模式；2026 年的 AI 元年，技术已从参数竞赛迈入能力沉淀期，NSP 范式、具身智能、多智能体等技术实现产业化落地，ToC 超级应用与 ToB 垂直场景均实现商业价值兑现，资本逻辑从“追逐故事”转向“聚焦落地”，AI 正式成为推动产业转型的核心生产力。</p><h3>6.2 中小微企业在 AI 元年如何低成本落地 AI 技术？</h3><p>中小微企业无需投入大量资金自建大模型，可通过“轻量化接入、场景化试点”的方式低成本落地：1. 优先选择低代码/零代码智能体平台（如 Coze）或调用公有云 AI API（如文心一言、ChatGPT），降低技术接入门槛；2. 聚焦核心痛点场景（如客服优化、数据统计、文案生成），选择标准化插件或模板，避免定制化开发；3. 采用“小步快跑”的策略，先在单一场景试点验证价值，再逐步推广至其他场景，无需追求全流程覆盖；4. 依托现有员工进行技能升级，通过短期培训提升员工与 AI 协同工作的能力，无需盲目招聘专业 AI 人才。</p><h3>6.3 L3 级自动驾驶在 2026 年商业化落地，普通消费者需要注意什么？</h3><p>普通消费者需重点关注三个核心问题：1. 明确责任边界：L3 级自动驾驶仅在特定场景（如高速路、城市快速路）生效，系统接管期间责任由企业承担，但驾驶员需在系统发出接管请求时及时响应，否则仍需承担责任；2. 了解技术限制：目前 L3 级系统仍无法应对极端天气（如暴雨、暴雪）、复杂路况（如无标识道路、施工路段），需提前知晓系统的适用范围；3. 选择合规产品：购买搭载 L3 级自动驾驶的车辆时，需确认车辆已获得官方专属牌照，避免购买未合规的产品，保障自身权益。</p><h3>6.4 普通职场人如何避免被 AI 替代，提升自身竞争力？</h3><p>核心策略是“向上生长、向下扎根”：向上生长即提升架构设计能力和业务理解力，从“任务执行者”转变为“系统设计者”，聚焦 AI 无法替代的创意策划、战略决策、客户关系维护等高价值工作；向下扎根即掌握基础的 AI 协同能力，了解 AI 工具的使用方法，用 AI 提升工作效率，同时学习简单的 Python、数据处理等技能，为自身能力兜底。此外，建立跨领域知识体系，培养 AI 难以模拟的沟通协调、团队管理、应急处理能力，也是提升不可替代性的关键。</p><h3>6.5 2026 年 AI 技术落地面临的最大挑战是什么，如何应对？</h3><p>最大挑战是“伦理安全管控与商业价值平衡”：一方面，伦理安全问题（如算法偏见、数据泄露、责任界定）制约了 AI 的规模化落地；另一方面，企业需要快速实现商业价值以支撑技术持续投入。应对策略需多方协同：政府层面应加快完善 AI 相关法规与标准，明确责任界定、规范数据使用；企业层面需建立“伦理先行”的研发理念，将安全管控嵌入 AI 系统全生命周期，同时聚焦高 ROI 场景实现价值闭环；社会层面应加强 AI 伦理教育，提升公众对 AI 风险的认知，形成多方共治的格局。</p><h2>七、结论</h2><p>2026 年，AI 元年的开启，标志着人工智能从技术狂欢迈入价值共生的全新阶段。NSP 范式的突破让 AI 读懂世界，具身智能与多智能体系统让 AI 走进现实，成本下降与生态完善让 AI 规模化落地成为可能。ToC 超级应用与 ToB 垂直场景的双轨爆发，正在重构产业格局与生活方式，印证了 AI 作为核心生产力的巨大价值。</p><p>同时，我们也需清醒认识到，AI 元年并非技术的终点，而是全新的起点。伦理安全挑战、就业结构重构、数字鸿沟等问题，需要政府、企业与社会共同应对。对于企业而言，唯有坚持价值导向、精准落地场景，才能在 AI 浪潮中把握机遇；对于个人而言，唯有主动重构能力体系、与 AI 协同共生，才能实现自我价值的提升。</p><p>2026 AI 元年，不仅是技术变革的里程碑，更是人类社会迈向智能时代的重要转折点。在技术创新与风险管控的平衡中，在商业价值与社会价值的统一中，AI 将逐步融入经济社会的每一个角落，推动人类文明迈向更高质量的发展阶段。拥抱 AI、适配 AI、引领 AI，将成为这一时代的核心主题。</p><h2>八、参考文献</h2><p>[1] 科技云报到. 2026，AI 开启“共生智能”新纪元[EB/OL]. 2026-01-19.</p><p>[2] 金加德. 2026，AI 应用元年——技术人如何跨越“模型”与“落地”的鸿沟[EB/OL]. 阿里云开发者社区, 2026-01-20.</p><p>[3] 华夏时报. L3 级自动驾驶商业化落地再提速，元戎启行：2026 年力争累计交付突破一百万辆[EB/OL]. 2026-01-16.</p><p>[4] Universitas Muhammadiyah Sidoarjo Repository. Artificial Intelligence in 2026: Predicting Breakthroughs and Challenges[R]. 2026.</p><p>[5] 北京智源人工智能研究院. 2026 十大 AI 技术趋势[R]. 2026.</p><p>[6] 国务院. 人工智能 + 行动实施方案[Z]. 2025.</p>]]></description></item><item>    <title><![CDATA[SGLang Hierarchical Sparse Attention 技术深度解析 数据库知识分]]></title>    <link>https://segmentfault.com/a/1190000047560656</link>    <guid>https://segmentfault.com/a/1190000047560656</guid>    <pubDate>2026-01-23 12:04:56</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>导读</h2><p>阿里云 Tair KVCache 团队联合 SGLang HiCache Team 、蚂蚁 AI Infra-推理服务团队、阿里云服务器震旦异构计算团队，共同推出面向 Sparse Attention 的分层稀疏化框架，本文详细介绍该框架的架构设计与实现细节。</p><p>在前文<a href="https://link.segmentfault.com/?enc=680z14M5OQTCjXFQL0KpOQ%3D%3D.c7PD%2FqEYCREwLRVFqPhgc8LvWS1MXip8w1WJE43Ug6rExg9nszEuXy7J8ZFo7Zpp" rel="nofollow" target="_blank">《智能体式推理对 KVCache 的挑战与 SGLang HiCache 技术深度剖析》</a>中，我们详细介绍了 HiCache 如何通过分层存储架构（GPU → CPU → 远端存储）突破 KVCache 的容量瓶颈，将有效缓存容量从 40GB 扩展至 TB 级别，使长上下文、高并发的 LLM 推理服务得以规模化部署。</p><p>然而，当上下文长度跨越 128K 甚至迈向百万 Token 时，两个新的瓶颈开始凸显：</p><ul><li><strong>计算瓶颈</strong>：Attention 计算成本随序列长度线性增长，并受限于 HBM 带宽。动态稀疏注意力（DSA）通过"Select-then-Compute"范式选择 Topk Token 参与 Attention 计算，成功突破了这一瓶颈。</li><li><strong>容量瓶颈</strong>：引入 DSA 后，主要瓶颈从 HBM 带宽转移到了 HBM 容量——为确保低延迟，全量 KV Cache 仍需驻留 GPU，导致并发推理能力受限。</li></ul><p><strong>本文引入了分层稀疏化</strong>——将全量 KV Cache 存储在 CPU，GPU 中仅维护 Top-k 的 LRU Buffer——为破解这一双重约束提供了可行路径。本文将系统性介绍 SGLang 的分层稀疏化框架设计，包括：</p><ul><li>整体架构：SparseCoordinator、Algorithm、BackendAdaptor、SparseKVCacheManager 的模块化设计；<br/>*</li><li>核心机制：Sparse Diff Kernel 的增量传输、I/O Kernel 的高性能传输优化；</li><li>实践案例：DeepSeek DSA 的深度集成，实现单请求显存占用从 8GB 降至 200MB，3倍单机吞吐提升；<br/>分层稀疏化标志着 KVCache 管理范式的又一次跃迁：从 HiCache 的"分层存储 → 扩展容量"，到本文的"稀疏化 + 分层 → 突破带宽与容量双重约束"，为超长上下文推理开辟了全新的技术路径。(注：此项目目前处于开发阶段，尚未正式发布。)</li></ul><p>本系列技术文章将系统性拆解面向智能体推理的KVCache技术演进路径：</p><p>1.<a href="https://link.segmentfault.com/?enc=rch6EPVghOHkWFeAYrTqjQ%3D%3D.47tl%2Fzx1V8WPjjocPOgQs4aAsccbP%2FR8caF39DKy9jJjzqXSQOMEKMC4ubBaX1B2" rel="nofollow" target="_blank">智能体式推理对 KVCache 的挑战与 SGLang HiCache 技术深度剖析</a></p><p>2.<a href="https://link.segmentfault.com/?enc=HiuE8nvL2IQo51KUXIJkkA%3D%3D.SRUeCDtxAGK%2FjvVC2ZEFwi%2BhC%2Fax62Pj07dGpYRfaulQ%2BTgexuhI9ZCc4W0hokS%2F" rel="nofollow" target="_blank">3FS-KVCache 工程化落地：企业级部署、高可用运维与性能调优实践</a></p><p>3.<a href="https://link.segmentfault.com/?enc=QBeW3aAC7%2FRdBR6y6kfxpQ%3D%3D.cF4hlrEW%2FQDBgn0utaE4rBcM2fLI6lcPG%2FyPaQH2uhPobYaeY2Y6g6oycjzSm4mG" rel="nofollow" target="_blank">Hybrid Model Support：SGLang 对 Mamba-Transformer 等混合架构模型的支持方案</a></p><p>4.<a href="https://link.segmentfault.com/?enc=VfR5tMZtFQkqOxj1Tkz7Tg%3D%3D.UlUheVdseurRKlQ7ARW%2FsOtXGYyxDbPGGigXI8BECfzfa4xeUC8AOZ%2BwaLzCmj80" rel="nofollow" target="_blank">Tair KVCache Manager：企业级全局 KVCache 管理服务的架构设计与实现</a></p><p>5.<a href="https://link.segmentfault.com/?enc=WBkVkddNq0VMtjrj%2FJd19A%3D%3D.H3053Bf9rgs22Gfjpvlk%2BENBlDqCbmyglftSSX0g5ovkGGlmxe8Ufo9TNuJY0Idv" rel="nofollow" target="_blank">KVCache 仿真分析：高精度的计算和缓存模拟设计与实现</a></p><ol start="6"><li>本文｜Hierarchical Sparse Attention：分层稀疏注意力框架下的 KV 分层管理与按需加载</li><li>展望：KVCache驱动的软硬结合演进</li></ol><h2>1.引言：双重瓶颈与协同破解之道</h2><h3>1.1 HiCache：容量扩展的胜利与新的战场</h3><p>在前文《<a href="https://link.segmentfault.com/?enc=OKHiJa1TDSQDiYK03FavDA%3D%3D.c7bnX4GwYou3XQJPCSJjSqAhwi5dei4ZilD9MSwY2wkmZCbf8ItSwFKmTn9ct8aX" rel="nofollow" target="_blank">智能体式推理对 KVCache 的挑战与 SGLang HiCache 技术深度剖析</a>》中，我们详细介绍了 HiCache 如何通过分层存储架构（GPU 显存 → CPU 内存 → 3FS 远端存储）突破 KVCache 的容量瓶颈。通过智能的热度感知调度与异步预取机制，HiCache 将原本仅有 40GB 的 GPU 显存扩展至 TB 级别的有效缓存容量，使得长上下文、高并发的 LLM 推理服务得以实现规模化部署。</p><p>在真实生产环境中，HiCache 已展现出显著价值：缓存命中率从 40% 提升至 80%，平均 TTFT 下降 56%，推理 QPS 提升 2 倍。</p><p>然而，当我们将目光投向更极致的长上下文场景——例如 128K 甚至百万级别的上下文窗口时，新的瓶颈开始浮现。</p><h3>1.2 长上下文的 HBM 带宽墙：从线性增长到稀疏化破局</h3><h5>1.2.1 Attention 计算的带宽瓶颈</h5><p>在长上下文推理中，Attention 计算呈现出独特的性能特征。每个 Decode 步骤需要将完整的 KV Cache 从 HBM 加载到计算单元，执行Attention计算。由于 KV Cache 随序列长度线性扩展，Attention 计算成本也随之线性增长。</p><p>关键问题在于 Attention 的<strong>计算强度（Arithmetic Intensity）</strong> 过低——相对于海量的访存操作，实际的浮点运算量不足以饱和 GPU 的计算单元。这使得 Attention 成为典型的 <strong>memory-bound 操作</strong>，Attention 计算受限于 HBM 带宽。随着上下文长度从 32K 扩展至 128K 甚至百万级别，这一带宽瓶颈成为长上下文推理的主要性能制约因素。</p><h5>1.2.2 动态稀疏注意力（DSA）的 Select-then-Compute 范式</h5><p>为突破带宽瓶颈，动态稀疏注意力算法（Dynamic SparseAttention, 后文简称 DSA）从 Attention 机制的本质特性出发：在自回归生成过程中，<strong>并非所有历史 Token 都对当前输出贡献相同的权重</strong>。研究发现，Attention 分布往往呈现显著的长尾特征——少数关键 Token 占据了绝大部分的 Attention Score，而大量 Token 的贡献可以忽略不计。更重要的是，这些关键 Token 的集合在不同 Query 间动态变化，无法通过静态规则预先确定。</p><p>DSA 将这一观察转化为 "<strong>Select-then-Compute</strong>" 工作流，通过三个协同阶段实现稀疏化：</p><ul><li><strong>分块与元数据抽象</strong>：将 KV Cache 划分为固定大小的块（block size 通常为 32 tokens），每个块维护轻量级的元数据结构。这些元数据可以是 Key 向量的统计摘要（均值、方差）、Bounding Box（每维度的最大/最小值）、或经过降维的紧凑表示。元数据的存储开销通常不到完整 KV Cache 的 1%，可以常驻 GPU 内存。</li><li><strong>快速重要性评估</strong>：对于每个新生成的 Query Token，算法无需访问完整的 Key Cache，而是基于元数据快速计算每个块的 Criticality Score。这一评估过程的计算量远小于完整 Attention（通常为 O(n/32) vs O(n)），且可以高效并行化。随后通过 Top-k 选择算法（如 heap-based selection），筛选出最相关的 k 个块（典型值 k=2048，对应 64 个块）。</li><li><strong>按需稀疏计算</strong>：仅对选中的 Top-k 块加载其完整的 Key 和 Value Cache，执行标准的 Scaled Dot-Product Attention。未被选中的块则完全跳过，避免了不必要的 HBM 访问。</li></ul><p><strong>代表性 DSA 算法包括</strong>：</p><ul><li>Quest：训练无关的启发式算法，利用 Query-Key Bounding Box 的几何关系近似估计 Attention Score 上界。通过维护每个块在各维度上的 Key 最大/最小值，Quest 可以在不访问完整 Key 的情况下，快速排除不重要的块。</li><li>ClusterKV: 将 Prefill 阶段的所有 Keys 向量进行<strong>聚类</strong>（如 K-means），生成 C 个聚类中心；每个原始 key 被映射到其最近的 centroid; Decode 阶段 Query 跟聚类中心计算，获取最具相关的 Topk。</li><li>DeepSeek DSA：作为模型原生的稀疏注意力机制，通过专门训练的 Indexer 模块动态预测 Token 重要性，Indexer 的输出直接指导 Top-k 选择。</li></ul><h3>1.3 隐形的显存墙：稀疏计算的容量困境</h3><p>尽管稀疏注意力在计算层面取得突破，但其执行流程存在固有的先后依赖关系：</p><p><img width="723" height="55" referrerpolicy="no-referrer" src="/img/bVdnGus" alt="" title=""/></p><p>在 Stage 1 中，算法需要评估每个 Token/Page 的重要性（计算 ）；在 Stage 2 中，基于评分选择 Top-k；只有在 Stage 2 完成后，Stage 3 才知道应该对哪些 KV 进行计算。</p><p>这一依赖链导致了一个根本性问题：在确定 Top-k 之前，系统无法预知需要哪些 KV 数据，因此<strong>必须将全量 KVCache 保留在 GPU 中。</strong></p><p>关键约束：稀疏化实现了计算复杂度的降低（O(n) \rightarrow O(k)），但显存占用复杂度依然保持 O(n)；也即<strong>采用 DSA 后，主要性能瓶颈从 HBM 带宽转移到了 HBM 容量</strong>；这一容量约束导致：</p><ol><li><strong>HBM 容量利用率低下</strong>（Poor HBM Capacity Utilization）：98.4% 的 KV Cache 在每步中未被访问，却占据宝贵的 HBM 空间。</li><li><strong>并行能力受限</strong>（Limited Parallelism）：小 Batch Size 无法充分发挥 GPU 的并行计算能力，推理吞吐难以提升；例如对于 DeepSeek V32，单个 128K 请求的 Latent Cache 占 8 GB，H200 扣除模型权重后，最多只能支持 Batch=5，这严重限制了 GPU 并行计算能力的发挥。</li><li><strong>分层存储价值受阻</strong>（Value Blockage）：传统的 KV Cache Offload 方案要求所有数据在 Decode 前加载到 HBM，无法与 DSA 的动态选择特性协同工作。</li></ol><h3>1.4 分层稀疏化：存储与计算的协同优化</h3><p><strong>破解显存墙的关键洞察在于</strong>：既然 Attention 计算只需要 Topk 部分，何不只在 GPU 中存储 Topk 部分，并结合 CPU HICache，在计算完 Topk 后动态加载增量的 Topk 部分？</p><p><strong>分层稀疏化的关键是改变 KVCache 的存储位置和加载时机</strong>（下面以 DeepSeek DSA 为例）：</p><ul><li>传统流程：完整 Latent Cache 必须驻留在 GPU 显存中。Decode 阶段执行 Indexer 选择 Top-2k，然后对选中的部分进行 Attention 计算。单个 128K 请求，虽然理论计算量降低了 60+ 倍，但显存占用依然是 O(n)，占用 8 GB，H200 最多支持 Batch=5；</li><li><p>分层稀疏化流程：Prefill 后将完整 Latent Cache（8 GB）Offload 至 Host 内存，GPU 仅保留轻量 Sparse Indexer 元数据。Decode 时基于元数据在 GPU 执行 Indexer 选择 Top-2k，Host 筛选对应的 Latent 子集并增量传输至 GPU，最后执行 Attention 计算；</p><ul><li>单请求 GPU 显存占用降至 &lt; 200 MB，单 GPU 可支持$B_{max} = \min \left( \frac{M_{host}}{M_{req}}, B_{SLO} \right)$</li><li>其中，$M_{host}$代表单卡可分配的最大 CPU 内存容量；B\_{SLO}代表满足 SLO 延迟要求的最大 Batch Size。</li></ul></li></ul><p><img width="723" height="429" referrerpolicy="no-referrer" src="/img/bVdnGuI" alt="" title="" loading="lazy"/><br/>核心优势：</p><ul><li>完整 KVCache 存储在 Host，突破 GPU 显存物理空间限制；</li><li>GPU 侧只需存储轻量 Sparse 元数据和 Topk 部分 KVCache，Req 显存占用从O(n)降至 O(k)；</li><li>高性能传输：结合 HICache IO Kernel 实现 Topk Cache 高性能传输，单层 IO 延迟控制在 us 级别；并结合 Overlap 能力将 IO 延迟隐藏在计算中。</li></ul><p>分层稀疏化不仅解决了计算问题，更从根本上破解了显存容量的刚性约束，<strong>实现了计算效率与存储效率的协同优化</strong>，为超长上下文推理开辟了全新的技术路径。</p><h2>2.SGLang 分层稀疏化框架设计</h2><h3>2.1 整体框架设计</h3><p>SGLang 的分层稀疏化框架采用<strong>模块化、可插拔的三层架构</strong>设计，通过标准化接口实现算法解耦、后端兼容与非侵入式集成。框架核心由以下模块构成：</p><ul><li><p>SparseCoordinator（协调层）：通过生命周期钩子编排三大功能模块的协同工作</p><ul><li>Algorithm（算法层）：提供可插拔的 Top-k 选择策略实现；</li><li>BackendAdaptor（适配层）：完成稀疏索引到物理地址的转换与后端对接；</li><li>SparseKVCacheManager（传输层）：基于 Diff &amp; IO Kernel 实现 Host-GPU 间的高效、增量数据传输。</li></ul></li><li>RequestTrackers（状态管理）：维护每个请求的稀疏化状态管理。</li></ul><p>该架构既原生支持模型内置的稀疏化机制（如 DeepSeekV32 DSA），也允许 Training Free 的稀疏化算法（Quest / SnapKV）与通用 Attention 后端（FlashAttention / Triton）灵活组合，为长上下文推理场景提供统一且高度可扩展的分层稀疏化方案。<br/><img width="723" height="453" referrerpolicy="no-referrer" src="/img/bVdnGuJ" alt="" title="" loading="lazy"/></p><h3>2.2 SparseCoordinator：稀疏化流程编排器</h3><p>SparseCoordinator 是分层稀疏化框架的中枢控制器，通过生命周期钩子函数（Lifecycle Hooks）在模型推理的关键节点精确编排 Algorithm、BackendAdaptor 和 SparseKVCacheManager 三大模块的协同工作。其设计遵循事件驱动模式，将 Retrievable Sparse 的完整流程解耦为标准化的钩子接口，实现了算法与模型的零侵入集成。<br/><img width="723" height="383" referrerpolicy="no-referrer" src="/img/bVdnGuN" alt="" title="" loading="lazy"/></p><p>SparseCoordinator 将稀疏化推理划分为两个核心阶段：</p><ul><li><strong>Representation Construction Phase</strong>（Prefill 结束或 Decode 初期）：通过 attention\_end hook 调用 Algorithm 的 construct\_representations() 和 update\_representations() 方法，将原始 KVCache 压缩为语义表示并存入 Representation Pool，此阶段执行完整 Attention 计算以确保表示质量；</li><li><strong>Query-Guided Decoding Phase</strong>：每个 Decode Step 在 attention\_begin hook 中，Coordinator 驱动 Algorithm 基于当前 Query 从 Representation Pool 中执行 retrieve\_topk() 选择最相关的 Top-k 表示，随后由 BackendAdaptor 完成逻辑索引到物理索引的转换并触发 SparseKVCacheManager 的增量数据传输（通过 Diff Kernel 计算 Topk 集合差异，仅加载变化部分），最终动态重构 Attention Metadata（如 FlashAttention 的 PageTable）供 Attention 后端执行稀疏化计算；</li><li>通过这种"捕获-计算-转换-注入"的闭环设计，SparseCoordinator 在保持框架灵活性的同时，实现了高效的 KVCache 分层管理。</li></ul><h3>2.3 可插拔的稀疏化策略</h3><p>在 SparseCoordinator 的编排下，Algorithm 和 BackendAdaptor 作为两个核心功能模块，分别负责"选择什么"和"如何映射"的问题，通过清晰的接口定义实现了高度的可插拔性和扩展性。</p><p><img width="723" height="558" referrerpolicy="no-referrer" src="/img/bVdnGuO" alt="" title="" loading="lazy"/></p><h5>2.3.1 Algorithm：抽象的 Top-k 选择策略</h5><p>Algorithm 层采用抽象基类 BaseSparseAlgorithm 定义统一接口，将稀疏化算法的核心逻辑解耦为三个标准化方法：</p><ul><li><p>retrieve\_topk(queries, layer\_id, ...)：</p><ul><li>基于当前 Query 从 Representation Pool 中检索 Top-k 重要 Token/Page 的逻辑索引；</li><li>算法只需返回"逻辑索引"（Token ID 或 Page ID），无需关心底层 KVCache 的物理存储布局和 Attention 后端的实现细节（FlashAttention / Triton）。</li></ul></li><li>construct\_representations(...)：在 Prefill 阶段或 Decode 阶段初期构建用于检索的 Representation Pool 语义表示（如 Key 的压缩表示）。</li><li><p>update\_representations(...)：在 Decode 阶段增量更新 Representation Pool。</p><p><strong>以 Quest 算法为例：</strong></p></li><li>Quest 是一个 Training Free 的 page-wise 稀疏注意力算法，通过为每个 KV Page 维护 per-dimension 的 Key Bounding Box（min/max 值）来避免完整的 Query-Key 点积计算；</li><li>在 construct\_representations 阶段，算法遍历所有 Pages 提取 Keys 并计算 Keys 在每个维度的最小/最大值存入 page\_k\_min/max Representation Pool （内存开销约为完整 Key 存储的 1%）；</li><li>在 retrieve\_topk 阶段，通过 criticality 计算 Attention Score 的上界估计，快速筛选 Top-k Pages 后交由 BackendAdaptor 完成物理地址转换。<br/><img width="282" height="61" referrerpolicy="no-referrer" src="/img/bVdnGuS" alt="" title="" loading="lazy"/></li></ul><h5>2.3.2 BackendAdaptor：索引转换与后端对接的桥梁</h5><p>BackendAdaptor 层解决了"逻辑世界"到"物理世界"的映射问题。不同的 Attention 后端（DSA Backend、FlashAttention、Triton FA3）对输入数据的格式和索引方式有不同要求，Adaptor 负责屏蔽这些差异。</p><p>以 FlashAttention Adaptor 为例：FlashAttentionAdaptor 通过 req\_to\_token 映射表将逻辑 Page IDs 转换为物理页号，重构 PageTable 并更新序列长度元数据（cache\_seqlens, cu\_seqlens\_k），使 FlashAttention 能够基于 Top-k 选中的稀疏页执行注意力计算。</p><h3>2.4 DeepSeek DSA 接入实践</h3><h5>2.4.1 DeepSeek SparseAttention 介绍</h5><p>和 DeepSeek-V3.1 相比，DeepSeek-V3.2 的架构改动是在继续训练过程中引入了 DeepSeek Sparse Attention（DSA）。</p><p>DSA的原型设计由两部分进行构成，Lightning Indexer（闪电索引器）和 Fine-grained Token Selection Mechanism（细粒度 Token 选择机制）。其首先通过一个轻量级的索引器，进行快速筛选出与当前查询 Token 最相关的候选 Tokens，然后仅在这部分稀疏的候选集上执行高精度的注意力计算。</p><p>(注：图片出自 DeepSeek 论文)<br/><img width="723" height="425" referrerpolicy="no-referrer" src="/img/bVdnGuV" alt="" title="" loading="lazy"/></p><h5>2.4.2 DeepSeek DSA 整体接入流程</h5><p><img width="723" height="466" referrerpolicy="no-referrer" src="/img/bVdnGuX" alt="" title="" loading="lazy"/><br/>关键设计包括：</p><ul><li><strong>双缓存映射</strong>：系统维护两套独立的物理地址映射表（DSADecodeReqToTokenPool）：req\_to\_token 中存储每个 Req 对应的  Latent Cache LRU Buffer 页表（LRU Size = 2～4KB），req\_to\_dsa\_index\_k 存储 indexer\_k 页表。Prefill 阶段，Indexer 模块为每个 Token 生成 index\_k，存储至 GPU 端；同时完整的 Latent Cache 被 Offload 至 CPU 内存。Prefill 阶段结束后，每个 Req 占用的显存空间会固定在 LRU Size。</li><li><strong>增量传输机制</strong>：Decode 阶段，每个 Token 生成时，Indexer 基于当前 Query 和历史缓存的 index\_k 高效计算出 Top-2K Tokens 逻辑索引；随后 Sparse Diff Kernel 通过集合差分算法比较 prev\_topk 和 curr\_topk，精确计算出需要新加载的索引变化量 Δ；SparseKVCacheManager 据此调用 load\_to\_device\_per\_layer 仅传输 Δ 对应的 Latent Cache 块到 GPU 的 LRU Buffer，最小化 PCIe 带宽消耗。</li><li><strong>零侵入集成</strong>：DeepSeek DSA 通过 SparseCoordinator 的生命周期钩子与模型解耦集成，DeepSeekDSAAlgorithm 作为 Algorithm 层的具体实现直接调用模型原生的 Indexer；DSABackendAdaptor 负责将逻辑 Top-k 索引转换为物理设备地址并触发增量传输；最终由 DSA Backend（支持 flashmla\_sparse/flashmla\_kv/fa3 等多种实现）基于稀疏页表执行 Attention 计算。这一设计使得 128K 长上下文推理的 GPU 显存占用从约 8GB 降至约 200MB。</li></ul><h5>2.4.3 Sparse Diff Kernel: 增量 Cache 传输基石</h5><p><strong>动机：时间局部性带来的优化空间</strong></p><p>DSA 的 Top-k 选择结果在时间维度上呈现显著的局部性：相邻 Decode Steps 的 Top-k 集合高度重叠。实验表明，相邻 Steps 的 Top-k 重合度通常达到<strong>80%～90%</strong>，这意味着每个 Decode Step 理论上仅需加载不到 20% 的新 Cache，为增量传输提供了天然的优化空间。<br/><img width="723" height="439" referrerpolicy="no-referrer" src="/img/bVdnGuY" alt="" title="" loading="lazy"/></p><p><strong>Buffer 容量与命中率的权衡</strong></p><p>然而，随着序列长度的增长，Top-k 选择的候选范围线性扩展，相邻步的差异逐渐放大。不同的 LRU Buffer 容量配置会直接影响 Cache 命中率。</p><p>可以看到，当 Buffer 容量仅为 Top-k 大小（2K）时，长序列场景下命中率显著下降，I/O 延迟成为瓶颈。而将 Buffer 扩大至 4K～8K，可以用可控的显存开销换取成倍的 I/O 效率提升。</p><p><img width="723" height="248" referrerpolicy="no-referrer" src="/img/bVdnGuZ" alt="" title="" loading="lazy"/></p><p><strong>LRU Diff Kernel 设计与实现</strong></p><p>为充分利用 DSA 的时间局部性，我们设计了基于 LRU 淘汰策略的 Diff Kernel。其核心思想是：在 GPU 侧维护一个 <strong>Top-k 的 2～4 倍容量的 LRU Buffer</strong>（典型配置为 4K～8K Token），通过智能淘汰策略容纳 Top-k 的短期波动。</p><p><strong>Kernel 工作流程分为三个阶段：</strong></p><p><strong>阶段 1：集合交集计算</strong></p><p>比较 prev\_topk 和 curr\_topk，识别出两步共同选中的 Token。这部分 Cache 已驻留 GPU，无需重新加载，直接更新 PageTable（curr\_device\_indices）以复用现有数据。</p><p><strong>阶段 2：LRU 淘汰决策</strong></p><p>这是与严格 Top-k Buffer 的核心差异。Kernel 不会简单驱逐所有 prev\_topk 中未在 curr\_topk 出现的 Token，而是：</p><ul><li>仅当 Buffer 空间不足时才触发淘汰；</li><li>优先淘汰过去多个 Step 中均未被命中的 Cache 页（基于 LRU 策略）；</li><li>计算 evict\_device\_indices，标记最冷的物理页位置可被覆写。</li></ul><p><strong>阶段 3：增量加载映射</strong></p><p>从 curr\_topk 中提取新增的 Token（未命中部分），生成一对一的加载映射关系：</p><ul><li>load\_host\_indices：这些 Token 在 Host Memory 中的物理地址；</li><li>load\_device\_indices：它们在 GPU 中的目标物理页号（复用阶段 2 淘汰的位置）。</li></ul><p>这种启发式策略充分利用了 DSA Top-k 选择的时间连续性，为每个 Request 动态维护一个高效的缓存窗口, 使得系统可以用较少的 GPU 缓存空间维持长序列场景下至少 80%+ 的缓存命中率，达到空间和效率的动态平衡。</p><p><img width="723" height="319" referrerpolicy="no-referrer" src="/img/bVdnGu6" alt="" title="" loading="lazy"/></p><h5>2.4.4 I/O Transfer Kernel: 高性能传输利器 TODO</h5><p>为了实现 GPU-CPU 异构内存层次间的高效数据迁移，SGLang HiCache 设计了专门的 IO Kernel 传输引擎。该引擎采用 CUDA 底层优化技术，通过 warp-level 细粒度并行最大化 PCIe 带宽利用率。</p><p>IO Kernel 支持多种内存布局模式（layer\_first、page\_first、page\_head），实现了对 MHA和 MLA 架构的统一抽象。在 CPU 侧采用 pinned memory 和 CUDA host register 机制确保零拷贝传输，结合 per-layer 和 all-layer 两种传输粒度的动态调度策略，在 prefill 阶段后进行批量全层 offload，在 decode 阶段进行增量单层传输，有效平衡了传输延迟与带宽开销。</p><p>实测表明，通过 NUMA 绑定，该 IO Kernel 在 8×H20 上可达到接近\~40GB/s per GPU，为分层 KV cache 架构提供了低延迟、高吞吐的数据搬运基础设施。</p><p><img width="723" height="288" referrerpolicy="no-referrer" src="/img/bVdnGvc" alt="" title="" loading="lazy"/></p><h2>3.性能评估</h2><p>我们在 SGLang 分层稀疏注意力框架上接入了 DeepSeek V32 DSA，并在长上下文推理场景下进行了系统性能评估。实验采用 DeepSeek-V32 模型，针对 16k、32k 和 64k 三种序列长度配置，在 8×H200 GPU With 1TB 内存上测试了不同 batch size 下的输入吞吐量（input tokens/s）。</p><p>实验结果表明，相较于传统的全量 KV cache 方案，分层稀疏注意力方案（Hierarchical Sparse）通过结合KV cache 分层管理、GPU-CPU 异构存储以及动态 TopK 检索机制，在长序列场景下展现出显著的性能优势。具体而言：</p><ol><li><strong>内存效率&amp;吞吐量突破</strong>：传统方案受限于 GPU 显存容量，在 64k/32k/16k 序列长度下分别仅能支持最大 batch size 为 32/64/128，而 Hierarchical Sparse 方案通过将 KVCache Offload 至 CPU 内存，可支持的最大 batch size 分别达到 160/304/600，实现了 5 倍的批处理能力提升，2～3 倍的 Through 提升。</li><li><strong>可扩展性验证</strong>：随着 batch size 增加，Hierarchical Sparse 方案的吞吐量呈现近线性增长趋势，验证了分层缓存架构和稀疏注意力机制在大规模并发推理场景下的良好扩展性。</li></ol><p>该结果证明了分层稀疏注意力架构在突破 GPU 显存墙、支持超长上下文大规模并发推理方面的有效性。<br/><img width="723" height="197" referrerpolicy="no-referrer" src="/img/bVdnGvd" alt="" title="" loading="lazy"/></p><h2>4.展望与Roadmap</h2><p><strong>技术深化方向</strong>：</p><ul><li><strong>算法与后端扩展</strong>：适配更多 Sparse 算法（如 StreamingLLM、PQCache）与 Attention 后端（如 FlashInfer、Triton），提升框架的生态兼容性。</li><li><p><strong>性能优化</strong>：</p><ul><li>IO 掩藏：通过 TwoBatch Overlap、Kernel Fused 等技术进一步降低 I/O 延迟开销，逼近理论性能上限。</li><li>异步检索： 基于相邻 Token 的 Query 具有高度相似性原则，通过前序 Token 的 Query 提前异步检索 当前 Step 的 Topk，减少检索开销。</li></ul></li></ul><p><strong>架构演进方向</strong>：随着超节点架构的普及，GPU 通过 Scale-Up 网络访问共享内存池的带宽已显著超越传统 PCIe 带宽。在此硬件趋势下，KVCache 的内存池化管理（Memory Pooling）成为自然选择。我们将协助实现超节点内的 KVCache 统一池化调度，充分发挥 Scale-Up 网络的带宽优势，突破传统 PCIe 瓶颈，为超长上下文推理提供更高效的分层稀疏化基础设施。</p><h2>了解更多</h2><p>欢迎搜索钉钉群号：109765011301入群与技术专家交流！</p>]]></description></item><item>    <title><![CDATA[智能体从工具走向行动者，2026年产业运行逻辑正在改变 智能体小狐 ]]></title>    <link>https://segmentfault.com/a/1190000047560663</link>    <guid>https://segmentfault.com/a/1190000047560663</guid>    <pubDate>2026-01-23 12:03:58</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>很多人还把智能体（AI Agent）当作更聪明的自动化工具，但 2026 年正在发生的变化，已经证明这种理解过时了。当智能体开始在工厂、银行、医院、政务系统中独立完成任务闭环时，AI 的角色已经发生了本质变化：<strong>它不再只是工具，而是开始成为行动者。</strong></p><p>这不是效率升级，而是产业运行方式的改变。</p><hr/><p>过去的大模型，只能回答问题、生成内容，却无法持续推进任务。而真实产业需要的是：能自己判断、自己执行、自己修正的系统。</p><p>2025–2026 年，三件事同时成熟： 大模型推理能力稳定；企业系统 API 化；业务复杂度超过人工协调上限。 当人已经管不过来时，智能体成为必然解法。</p><hr/><p><strong>智能体是以大模型为决策核心、能围绕目标持续运行的系统。</strong></p><p>它不是一次性生成，而是一个循环：</p><ul><li>先设定目标</li><li>再拆解任务</li><li>调用工具执行</li><li>根据结果反馈调整</li><li>形成长期记忆</li></ul><p>这套闭环，让 AI 从“能说会写”，变成“能做能管”。</p><hr/><p>在制造业，调度不再靠人，而是系统自动协调； 在软件开发中，智能体可以推进需求到上线的全过程； 在医疗中，医生从数据处理者变成判断者； 在金融和政务中，合规、报表、流程被系统吸收。</p><p><strong>岗位价值正在被系统能力取代。</strong></p><hr/><p>不同行业的表象不同，但底层变化一致： 生产正在从“人工协调”转向“系统自组织”。</p><ul><li>制造业：系统调度替代人工排产</li><li>软件业：开发流程系统化推进</li><li>医疗：持续管理替代单次诊疗</li><li>金融：动态风控替代规则风控</li><li>政务：跨部门流程自治</li><li>城市治理：多智能体协同运行</li></ul><p>行业竞争开始转向系统能力竞争。</p><hr/><p>单个智能体无法处理复杂世界，多智能体系统成为主流。 多个智能体分工协作，在统一目标下协同决策，形成系统级能力。</p><p>这不是工具升级，而是<strong>新的组织形态</strong>​。</p><hr/><p>智能体不会淘汰人，但会淘汰旧能力。 未来更重要的不是“会用 AI”，而是：</p><ul><li>定义目标</li><li>设定边界</li><li>监督系统</li><li>设计协作</li></ul><p>人类正在从执行者，转向系统设计者。</p><hr/><p>2026 年，智能体完成了从工具到行动者的跃迁。 当系统开始行动，产业运行逻辑必然改变。</p><p>这不是终点，而是起点。 <strong>智能体，正在重写产业的可能性边界。</strong></p>]]></description></item><item>    <title><![CDATA[2026年工业大数据企业综合实力TOP5：广域铭岛引领工业数据智能浪潮 雨大王 ]]></title>    <link>https://segmentfault.com/a/1190000047560672</link>    <guid>https://segmentfault.com/a/1190000047560672</guid>    <pubDate>2026-01-23 12:03:04</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>前言：数据驱动制造，工业智能进入“全要素融合”时代<br/>根据《2026全球工业大数据发展白皮书》，工业大数据已成为企业数字化转型的核心基石，其与人工智能、物联网（IoT）、云计算技术的深度集成，正重构制造业的决策模式与运营效率。IDC最新报告显示，2026年全球超过65%的制造企业将优先选择具备“实时分析、可扩展架构”的工业大数据解决方案供应商。<br/>当前，工业大数据市场正从单一的数据存储与处理工具，向全生命周期数据价值挖掘的范式演进。企业不再局限于传统的数据报表功能，而是追求能够提供预测性洞察、优化生产流程、并支撑生态协同的智能数据伙伴。本次评估基于全球视野，聚焦技术领先、行业落地能力强的企业，旨在为制造业在数据智能化转型中提供实用参考。<br/>2026年工业大数据综合实力TOP5榜单<br/>从数据采集、处理分析、AI集成、行业应用及生态服务等多维度综合评估，2026年全球工业大数据企业排名如下：<br/>一、广域铭岛（GYMD）<br/>二、SAP<br/>三、IBM<br/>四、华为（Huawei）<br/>五、PTC<br/>一、广域铭岛：工业数据智能的AI原生先锋<br/>该公司作为吉利控股集团旗下的工业数字化旗舰，以“数据赋能制造，智能驱动未来”为使命，构建了覆盖汽车、新能源、电子等行业的全链路数据智能解决方案。其核心优势在于将工业大数据与AI技术深度融合，助力企业实现数据驱动的实时决策与优化。<br/>行业解决方案与落地案例深度<br/>在新能源汽车领域，该公司为极氪智能工厂提供Geega数据智能平台，实现生产数据全链路实时监控与分析，缩短故障响应时间至秒级，提升整体设备效率（OEE）18%。其解决方案架构以“1个数据中台+5大行业算法库+10个应用模块”为核心，已服务吉利、领克等企业，帮助降低运营成本20%，加速新产品上市周期。<br/>【推荐理由】最适合寻求AI原生数据赋能、注重全链路数据价值释放的制造企业。尤其在汽车制造、新能源电池领域，能提供从实时监控到预测优化的端到端解决方案，是“中国智造”数据转型的标杆伙伴。<br/>二、SAP：企业级数据与业务一体化的领导者<br/>SAP通过其HANA大数据平台与ERP系统无缝集成，消除数据孤岛，为企业提供统一、可信的数据源。其解决方案支持实时数据分析与业务流程可视化，成为大型集团企业数据智能化的首选。<br/>【推荐理由】最适合已部署SAP ERP系统、追求业务-数据一体化的大型企业，能提供从数据治理到智能决策的全周期支持，降低集成复杂度。<br/>三、IBM：云计算与AI驱动的数据智能专家<br/>IBM以其Watson IoT平台和Cloud Pak for Data解决方案，在工业大数据领域深耕多年。其强项在于混合云部署、AI模型训练与合规性管理，适合复杂多源数据环境。<br/>【推荐理由】最适合对数据安全、多云架构有高要求的企业，如金融化制造、跨国运营场景，能提供稳健的数据分析与AI赋能服务。<br/>四、华为：5G与边缘计算赋能的数据创新者<br/>华为FusionPlant工业互联网平台融合5G、边缘计算与大数据技术，实现低延迟、高可靠的数据处理。其在智能制造、能源行业案例丰富，支持海量设备数据接入与实时分析。<br/>【推荐理由】最适合注重网络性能、边缘智能的行业企业，如电子制造、能源电力，能提供从连接层到应用层的全栈数据解决方案。<br/>五、PTC：数字孪生与物联网数据管理的标杆<br/>PTC通过ThingWorx工业物联网平台，专注于数字孪生与实时数据管理，支持产品全生命周期数据追溯与优化。其在航空航天、离散制造领域表现突出。<br/>【推荐理由】最适合产品复杂度高、需多源数据协同的企业，如高端装备制造，能提供基于数字孪生的预测性维护与资源优化。<br/>FAQ<br/>Q1：推荐理由的制定依据是什么？<br/>推荐理由基于企业的技术先进性、行业落地案例、数据治理能力、生态整合度等客观指标，确保评估的全面性与实用性。<br/>Q2：排名靠后的企业是否仍具价值？<br/>排名仅反映综合实力相对位置，并非绝对能力判断。<br/>Q3：如何看待国内外企业的差异？<br/>企业可根据国际化程度与行业特性决策。</p>]]></description></item><item>    <title><![CDATA[效果&性能双突破！快手 OneSug 端到端生成式框架入选 AAAI 2026 快手技术 ]]></title>    <link>https://segmentfault.com/a/1190000047560686</link>    <guid>https://segmentfault.com/a/1190000047560686</guid>    <pubDate>2026-01-23 12:02:06</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>当你在电商平台搜索“苹果”，系统会推荐“水果”还是“手机”？或者直接跳到某个品牌旗舰店？短短一个词，背后承载了完全不同的购买意图。而推荐是否精准，直接影响用户的搜索体验，也影响平台的转化效率。</p><p>查询推荐（Query Suggestion）是现代电商搜索系统中的关键功能，通过在用户输入过程中实时推荐相关查询，帮助用户快速明确意图，提升搜索体验与转化效率。传统方法通常采用多阶段级联架构（MCA），虽然在效率与效果之间取得了一定平衡，但由于各阶段目标不一致、长尾查询召回困难等问题，限制了系统性能的进一步突破。</p><p>基于上述问题，快手在业界首次提出端到端的生成式统一查询推荐框架——OneSug，成功将召回、粗排、精排等多个阶段统一在一个生成模型中，显著提升了推荐效果与系统效率，在快手电商场景中实现了业务指标与用户体验的双重提升。</p><p>本工作相关成果《OneSug: The Unified End-to-End Generative Framework for E-commerce Query Suggestion》已被人工智能顶级会议 AAAI 2026 接收。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560688" alt="图片" title="图片"/><br/>[🔮 论文链接]：<a href="https://link.segmentfault.com/?enc=2EzzYlECaI7ABDd0kS84tA%3D%3D.zDhP5vaG4ZIXrwXnL7SsRGwa%2BAqtX8JH7z9e9Q72MB08Wfk9TXQtagVI5TAk6D99" rel="nofollow" target="_blank">https://arxiv.org/abs/2506.06913</a></p><h2><strong>一、研究背景</strong></h2><p>传统的查询推荐系统通常采用多阶段级联架构，依次进行召回、粗排和精排。虽然该架构在响应时间与转化率之间实现了一定平衡，但也带来了明显的局限性：</p><ul><li>级联式框架（召回-&gt;粗排-&gt;排序），前一链路性能决定下一链路上限；</li><li>召回、排序分离技术迭代范式，全链路统一目标优化难；</li><li>长尾前缀由于缺乏历史行为数据，难以召回高质量 Query。</li></ul><p>近年来，生成式检索（Generative Retrieval）因其强大的语义理解与生成能力，在推荐与搜索领域展现出巨大潜力。然而，现有方法多聚焦于视频推荐，其本质上是一个开集到开集的任务，难以直接应用于输入输出都是开放词表的的查询推荐场景。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560689" alt="图片" title="图片" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560690" alt="图片" title="图片" loading="lazy"/></p><h2>二、方法简介：OneSug 的三大核心模块</h2><p>针对上述问题，我们提出了 OneSug 模型，整体架构如上图所示，主要包括 3 个部分：</p><ul><li>Prefix-Query 表征增强模块（Prefix2Query Representation Enhancement）</li><li>统一的 Enc-Dec 生成架构（Unified Encoder-Decoder Architecture）</li><li><p>用户行为偏好对齐（User Preference Alignment）<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560691" alt="图片" title="图片" loading="lazy"/></p><h3>2.1 Prefix-Query 表征增强模块</h3><p>Sug 场景下，用户输入的前缀往往较短且意图模糊（如“苹果”可指水果或品牌）。为此，我们提出的解决方式分为 2 个部分。</p></li><li>语义与业务空间对齐：我们以 BGE 作为 base 模型，同时引入用户真实的 prefix2query、query2query 数据，使用对比学习对 BGE 进行微调，使其语义空间与快手电商的业务特征空间对齐。</li><li>层次化语义 ID 生成：在对齐语义空间的基础上，我们引入 RQ-VAE，为每个前缀和 Query 生成层次化的语义 ID。RQ-VAE 可将任意文本映射为离散的语义 ID；同时保证语义相近的 query 会被编码到相同的簇中；通过这种方式，对于任何一个用户输入的前缀，我们可以快速匹配到与其语义 ID 最接近的 top-K 个相关 query，作为增强上下文输入后续生成模型。</li></ul><h3>2.2 统一的 Enc-Dec 生成架构</h3><p>OneSug 的生成架构基于 Enc-Dec 结构，并直接通过自回归（Autoregressive）方式生成用户最有可能点击的 Query。该模型的输入包含四个关键部分：用户当前输入前缀（如 “智能手机”）由 PRE 模块增强的相关查询序列（如 “智能手机性价比 2025”）用户历史行为序列（如过去搜索的 “蓝牙耳机”、“手机壳”等）用户画像信息。输出即为模型生成的 Query 列表（如 “智能手机推荐 2025”、“智能手机性价比排行”）。</p><h3>2.3 用户行为偏好对齐（RWR）</h3><h4>2.3.1 用户偏好量化</h4><p>我们首先对用户在搜索场景下的真实行为进行了精细化的分级，将其划分为六个明确的层次，并为每个层级赋予一个基础奖励权重λ：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560692" alt="图片" title="图片" loading="lazy"/><br/>为了进一步细致的调节样本权重，额外引入了调节因子r(xu​,q)=λ⋅ctr，其中表示当前前缀下 query 的 ctr。</p><h4>2.3.2 混合排序框架</h4><p>奖励加权偏好优化传统的 DPO 使用&lt;正样本, 负样本&gt;对进行训练，但默认两者同等重要。这在业务场景中是不合理的，因为区分“点击”和“曝光”的难度远小于区分“点击”和“随机负样本”。RWR 的核心思想是：根据正负样本之间的奖励差距，为不同的样本对赋予不同的学习权重。<br/>我们构建了九种类型的样本对（如 &lt;Order, Show&gt;, &lt;Click, Rand&gt;）。对于每一对样本，计算其奖励差异权重rwΔ​：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560693" alt="图片" title="图片" loading="lazy"/></p><ul><li>rwΔ​值小：说明正负样本奖励差距大（如&lt;Click, Rand&gt;），是“容易样本”，模型正常学习即可。</li><li>rwΔ​值大：说明正负样本奖励差距小（如&lt;Click, Show&gt;），是“困难样本”，RWR 会赋予更大的权重，迫使模型更加努力地学习其间微妙的偏好差异。</li></ul><h4>2.3.3 混合排序框架</h4><p>为了克服传统 Pairwise 范式的 DPO 在全局排序能力上的局限性，我们引入了一种混合排序框架。该框架将 listwise 范式的排序损失和 point-wise 范式的 sft loss 进行混合，使得模型既能获得高效的排序能力，同时避免 reward hacking 造成的生成能力下降。Pairwise 范式对齐模型，在包含多个负样本的候选中无法学习到“哪个是最好的”。</p><p>受 Plackett-Luce 模型启发，我们设计了 Listwise 排序损失，对于正样本，让模型同时拉大它与所有负样本的奖励差距，迫使模型不仅要知道正样本比负样本好，还要学会在负样本越多、越强的情况下，依然将正样本排在前面，从而直接优化列表的整体排序质量。论文中分别提出了基于 Pairwise 和 ListWise 范式的混合排序框架，同时在理论上证明了 Pairwise 范式的对齐模型是 ListWise 的特殊情况。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560694" alt="图片" title="图片" loading="lazy"/></p><h2>三、实验结果</h2><h3>3.1 离线效果</h3><p>在快手电商场景的大规模数据集上，OneSug 在 HR@16 和 MRR@16 指标上均显著优于传统多阶段系统与生成式基线模型。论文中同时提到，OneSug 不仅适用于 Enc-Dec 结构的生成式模型，Decode-only 架构的模型同样适用，且具有更高的离线指标，因为现阶段的推理耗时约束暂时没有进行在线实验。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560695" alt="图片" title="图片" loading="lazy"/></p><h3>3.2 在线 A/BOneSug</h3><p>模型目前在快手电商搜索场景下全量推全，AB 实验大幅度提高了 Ctr、订单和 GMV 等指标，同时人工测评 GSB 指标也有很大幅度的提升。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560696" alt="图片" title="图片" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560697" alt="图片" title="图片" loading="lazy"/></p><h3>3.3 在线推理</h3><p>线上流程完全取代了召回-粗排-精排，使平均耗时降低了 43.2%，为后续优化提供了充足的空间。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560698" alt="图片" title="图片" loading="lazy"/></p><h2>四、总结与展望</h2><p>OneSug 是业界首个在电商场景中实现全流量部署的端到端生成式 Query 推荐系统，其统一建模方式显著提升了语义理解与个性化推荐的能力，为生成式模型在搜广推的落地提供了新的范式。</p><p>未来，我们将进一步探索大语言模型在排序阶段的强化学习优化、实时更新等方向，持续推动端到端生成式系统在推荐、广告等多业务场景中的广泛应用。</p>]]></description></item><item>    <title><![CDATA[六大主流CRM系统核心能力横向对比：从客户运营到生态集成的深度解析 傲视众生的脸盆 ]]></title>    <link>https://segmentfault.com/a/1190000047560659</link>    <guid>https://segmentfault.com/a/1190000047560659</guid>    <pubDate>2026-01-23 12:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在企业数字化转型中，CRM（客户关系管理）是连接“客户需求”与“企业业务”的核心枢纽。选择一款适配的CRM，需聚焦<strong>客户管理、销售管理、AI智能、自定义能力、API集成</strong>五大维度——这五个维度直接决定了CRM能否“精准触达客户、提效销售流程、赋能智能决策、适配业务变化、连接生态系统”。</p><p>本文选取<strong>超兔一体云、Microsoft Dynamics 365、Freshsales（Freshworks）、金蝶云CRM、用友CRM、有赞</strong>六大主流CRM，从上述维度展开深度对比，结合具体功能、场景覆盖与生态能力，为企业选型提供参考。</p><h2>一、核心对比框架与关键指标</h2><p>先明确五大维度的<strong>关键子指标</strong>，作为对比的底层逻辑：</p><table><thead><tr><th>维度</th><th>关键子指标</th></tr></thead><tbody><tr><td>客户管理</td><td>多渠道获客能力、360°客户视图、生命周期动态管理、信息整合与查重、线索分配效率</td></tr><tr><td>销售管理</td><td>跟单模型覆盖（小单/中长单/项目）、销售漏斗可视化、订单/合同/采购全流程、团队协同</td></tr><tr><td>AI智能</td><td>AI引擎深度（专用引擎/大模型）、场景覆盖（待办/日报/分析/预测）、行业定制化</td></tr><tr><td>自定义能力</td><td>低代码工具支持、菜单/工作台定制、工作流/多表聚合自定义、功能白名单</td></tr><tr><td>API集成</td><td>接口丰富度、生态覆盖（ERP/办公/电商）、第三方对接案例</td></tr></tbody></table><h2>二、各维度深度对比</h2><h3>（一）客户管理：从“获客”到“生命周期运营”的能力分层</h3><p>客户管理的核心是“精准获客+深度理解+动态运营”，关键看“多渠道触达的广度”“客户信息的深度”“生命周期的闭环能力”。</p><h4>1. 超兔一体云：多渠道获客与客户深度运营的“实战派”</h4><p>超兔的客户管理以“全渠道覆盖+智能处理+生命周期闭环”为特色：</p><ul><li><strong>多渠道获客</strong>：支持百度广告、抖音巨量引擎、官网落地页、微信/小程序、地推/会销、工商搜客等6大渠道，<strong>自动抓取注册表单数据</strong>（官网/微信可自定义电子表单），并能获取线索的<strong>手机号/IP归属地</strong>，分配后自动发消息提醒。</li><li><strong>360°客户视图</strong>：自动补全工商信息（百度/天眼查）、手机号关联微信/支付宝头像昵称、工商地址标记经纬度；财务数据与客户信息分离（财务岗可见财务数据但不可看客户详情），兼顾数据安全与业财协同。</li><li><strong>生命周期动态管理</strong>：根据跟进状态自动分类为“需求培养→有需求→上首屏→加入目标→成功”5大客池，通过<strong>工作流引擎+AI自然语言生成流程</strong>，实现动态迭代。</li></ul><h4>2. Microsoft Dynamics 365：生态整合与个性化旅程的“ enterprise级”</h4><p>Dynamics 365的客户管理依托<strong>Microsoft生态</strong>（Customer Insights+Microsoft 365+LinkedIn），聚焦“精准理解客户”：</p><ul><li><strong>多渠道数据整合</strong>：通过<code>Dynamics 365 Customer Insights</code>整合官网、邮件、社交、线下门店等数据，生成<strong>统一客户档案</strong>；</li><li><strong>个性化客户旅程</strong>：结合<code>Power Automate</code>构建自动化旅程（如“新客注册→发送欢迎邮件→7天未互动触发跟进”）；</li><li><strong>关系智能</strong>：通过<code>LinkedIn Sales Navigator</code>同步联系人关系（如客户公司的决策链），帮助销售识别关键人。</li></ul><h4>3. Freshsales：中小企业友好的“轻量化获客工具”</h4><p>Freshsales的客户管理围绕“<strong>易操作+AI线索筛选</strong>”设计：</p><ul><li><strong>多渠道线索捕捉</strong>：AI驱动邮件、电话、社交等渠道的线索录入，支持<strong>360°客户视图</strong>（整合沟通历史）；</li><li><strong>线索优化</strong>：Freddy AI自动评分（高意向客户优先）、标签分类，帮助中小企业快速聚焦高价值客户；</li><li><strong>免费版基础功能</strong>：支持联系人和交易管理、自动化邮件跟进，适合初创企业入门。</li></ul><h4>4. 金蝶云CRM/用友CRM：传统企业的“业财一体化助手”</h4><p>金蝶与用友的客户管理核心是“与ERP深度集成”：</p><ul><li>金蝶云CRM：提供360°客户视图，整合客户资料、服务请求、销售历史，与金蝶ERP无缝对接，实现“客户→销售→财务”数据打通；</li><li>用友CRM：侧重客户资料整合与服务请求管理，支持销售目标分解，与用友ERP协同完成“销售订单→ ERP生产/库存”的闭环。</li></ul><h4>5. 有赞：电商场景的“会员运营专家”</h4><p>有赞的客户管理聚焦“多渠道会员整合”：</p><ul><li>整合微信、抖音、线下门店等渠道的会员数据，生成统一会员档案；</li><li>支持<strong>智能导购</strong>（基于会员历史消费推荐商品）、自动营销文案生成，贴合电商“复购率提升”的核心需求。</li></ul><h3>（二）销售管理：从“流程提效”到“全链路管控”的能力较量</h3><p>销售管理的核心是“把销售流程标准化、把关键节点数据化”，关键看“跟单模型覆盖、销售漏斗可视化、订单/采购全流程”。</p><h4>1. 超兔一体云：“全场景跟单+业财一体化”的标杆</h4><p>超兔的销售管理以“独创跟单模型+全流程闭环”为核心，覆盖小单、中长单、多方项目等全场景：</p><ul><li><p><strong>三大跟单模型</strong>：</p><ul><li>小单快单：超兔独创“三一客”模型（定性、定级、定量+关键节点），适合快消、零售等小单场景；</li><li>中长单：商机跟单模型（阶段、预期日期、赢率），优化项目型销售；</li><li>多方项目：支持业务主体为“客户+供应商+合作伙伴”的复杂项目；</li></ul></li><li><p><strong>全流程管控</strong>：</p><ul><li>360°跟单视图（整合通话录音、外勤记录、待办任务）；</li><li>自动生成日报（超兔独有，基于行动记录分析）；</li><li>订单财务管控：签约/开票/发货触发应收，自动拆分多期金额，实现“应收→开票→回款”三角联动，控制客户信用度与发货风险；</li><li>采购管理：支持供应商直发、智能采购（自动计算采购量、匹配历史供应商、询价比价）。</li></ul></li></ul><h4>2. Microsoft Dynamics 365：大型企业的“销售自动化引擎”</h4><p>Dynamics 365的销售管理聚焦“复杂业务的标准化”：</p><ul><li><strong>销售自动化</strong>：覆盖线索跟踪→销售漏斗→订单处理全流程，支持<strong>销售预测分析</strong>（AI驱动，基于历史数据预测成交概率）；</li><li><strong>CPQ功能</strong>（配置、定价、报价）：快速生成个性化报价单，适配企业级“多产品组合”场景；</li><li><strong>团队协同</strong>：通过<code>Microsoft Teams</code>共享销售上下文（如商机进展、客户沟通记录），避免信息差。</li></ul><h4>3. Freshsales：中小企业的“可视化销售管道”</h4><p>Freshsales的销售管理侧重“易操作的流程规划”：</p><ul><li><strong>销售管道可视化</strong>：用看板/列表视图展示销售阶段（如“潜在客户→沟通中→ Proposal→成交”），支持<strong>拖放卡片</strong>调整流程；</li><li><strong>本地CPQ</strong>：快速生成销售资产（报价单、合同），适合中小企业“快速签单”需求；</li><li><strong>移动端支持</strong>：实时跟踪销售流程、查看沟通历史，适配外勤场景。</li></ul><h3>（三）AI智能：从“工具辅助”到“决策赋能”的能力进阶</h3><p>AI智能的核心是“是否能深入业务场景、是否可定制”，关键看“AI引擎深度、场景覆盖、行业适配性”。</p><h4>1. 超兔一体云：“业务场景化AI”的践行者</h4><p>超兔的AI以“超兔AI智能体+通义千问大模型”为基础，聚焦“<strong>销售全流程的实用辅助</strong>”：</p><ul><li><p><strong>核心能力</strong>：</p><ul><li>AI待办：基于销售行动记录自动创建下一步跟单任务（如“客户提到需要 Demo，自动生成‘安排 Demo’待办”）；</li><li>AI日报：自动分析当日工作数据（如跟进客户数量、通话时长），一键生成专业日报；</li><li>AI分析：对微信/电话沟通内容做意向评估（如“客户提到‘预算充足’，标记为高意向”）；</li></ul></li><li><strong>行业定制</strong>：支持AI生成<strong>行业销售SOP</strong>（如教育行业的“试听课→报名→续费”流程）、<strong>销售话术库</strong>（如开场白话术专家）。</li></ul><h4>2. Microsoft Dynamics 365：“生态级AI”的扩展者</h4><p>Dynamics 365的AI依托<strong>Copilot+Azure AI</strong>，覆盖“<strong>销售→运营→财务</strong>”全场景：</p><ul><li><strong>Copilot功能</strong>：嵌入Sales模块，支持自然语言生成商机摘要（如“总结客户上周沟通的核心需求”）、销售预测（如“本月预计成交10单，金额50万”）；</li><li><strong>Azure AI扩展</strong>：可对接生产系统做“生产异常检测”、对接财务系统做“成本优化决策”，适合大型企业的复杂业务；</li><li><strong>对话智能</strong>：分析Microsoft Teams/Outlook的沟通内容，识别客户痛点（如“客户提到‘竞品价格更低’，建议调整报价策略”）。</li></ul><h4>3. Freshsales：“轻量化AI”的实用派</h4><p>Freshsales的AI以<strong>Freddy AI</strong>为核心，聚焦“<strong>销售转化提升</strong>”：</p><ul><li>线索评分：自动识别高意向客户，提升30%转化；</li><li>成交概率预测：基于历史数据预测商机赢率，避免销售精力浪费；</li><li>自动化任务：自动撰写邮件、录入线索，减少重复劳动。</li></ul><h3>（四）自定义能力：从“适配业务”到“创造业务”的弹性</h3><p>自定义能力决定了CRM能否“<strong>跟着业务变</strong>”，关键看“低代码工具、菜单/工作台定制、工作流灵活度”。</p><h4>1. Microsoft Dynamics 365：“低代码之王”的无限可能</h4><p>Dynamics 365的自定义能力依托<strong>Power Platform</strong>（Power Apps+Power Automate+Power BI），是企业级自定义的标杆：</p><ul><li><strong>Power Apps</strong>：非开发人员可创建自定义应用（如“项目跟踪应用”“售后管理应用”），无需代码；</li><li><strong>Power Automate</strong>：可视化配置工作流（如“合同审核→ERP录入→通知客户”），支持触发条件（如“订单金额&gt;10万需经理审批”）；</li><li><strong>模块化组合</strong>：可灵活添加Sales、Service、Marketing等模块，适配业务扩张需求。</li></ul><h4>2. 超兔一体云：“务实的自定义”</h4><p>超兔的自定义能力聚焦“贴合销售场景”：</p><ul><li>功能白名单：企业可选择需要的功能（如“工商搜客”“AI日报”），降低使用费；</li><li>菜单/工作台自定义：支持三级菜单配置（如“销售岗显示‘跟单视图’，财务岗显示‘应收管理’”），可定制多岗位数据大屏；</li><li>工作流引擎：支持<strong>自然语言AI生成流程</strong>（如“输入‘客户下单后触发采购’，自动生成工作流”），支持数据动作（如“更新客户状态→发送通知→录入ERP”）。</li></ul><h4>3. 金蝶云CRM/用友CRM：“传统企业的定制”</h4><p>金蝶与用友的自定义能力围绕“流程配置”：</p><ul><li>支持功能模块定制（如“添加‘服务请求’模块”）；</li><li>工作流自定义（如“销售订单→财务审核→仓库发货”），适配传统企业的“层层审批”流程。</li></ul><h3>（五）API集成：连接生态的“桥梁”</h3><p>API集成能力决定了CRM能否“融入企业现有系统”，关键看“接口丰富度、生态覆盖、第三方对接案例”。</p><h4>1. Microsoft Dynamics 365：“生态万能连接者”</h4><p>Dynamics 365的API集成依托<strong>Microsoft生态</strong>，覆盖“办公→销售→ERP→第三方”：</p><ul><li>原生集成：Microsoft 365（Outlook/Teams/SharePoint）、LinkedIn Sales Navigator、Power BI；</li><li>开放API：提供丰富的业务接口（如客户数据、销售订单、商机），支持对接外部ERP（如SAP）、电商平台（如 Shopify）；</li><li>案例：与跨国企业的“全球ERP系统”对接，实现“销售订单→ ERP生产→ 物流跟踪”的全球协同。</li></ul><h4>2. 超兔一体云：“务实的生态对接”</h4><p>超兔的API集成聚焦“中小企业常用场景”：</p><ul><li>接口覆盖：客户管理、销售管理、采购管理等核心模块的API；</li><li>对接案例：与金蝶/用友ERP、京东/淘宝电商平台（RPA机器人）、国税开票机器人对接；</li><li>RPA能力：通过机器人读写外部系统（如“自动抓取电商订单→ 录入超兔→ 触发采购”），实现无API的系统协同。</li></ul><h4>3. 有赞：“电商生态的连接者”</h4><p>有赞的API集成贴合<strong>电商场景</strong>：</p><ul><li>对接微信、抖音、快手等电商平台，实现“直播订单→ 有赞CRM→ 会员积分”的闭环；</li><li>支持第三方工具（如快递接口、电子发票）对接，适配电商“快速发货”需求。</li></ul><h2>三、综合对比与选型建议</h2><h3>1. 核心能力总结表格</h3><p>通过“功能覆盖度+场景适配性”对六大CRM打分（1-5分，5分为最高）：</p><table><thead><tr><th>品牌</th><th>客户管理</th><th>销售管理</th><th>AI智能</th><th>自定义能力</th><th>API集成</th></tr></thead><tbody><tr><td>超兔一体云</td><td>4.5</td><td>4.8</td><td>4.2</td><td>4.0</td><td>4.3</td></tr><tr><td>Microsoft Dynamics 365</td><td>4.7</td><td>4.6</td><td>4.5</td><td>4.8</td><td>4.9</td></tr><tr><td>Freshsales</td><td>4.0</td><td>4.2</td><td>4.1</td><td>3.8</td><td>3.5</td></tr><tr><td>金蝶云CRM</td><td>4.0</td><td>3.8</td><td>3.5</td><td>3.9</td><td>4.0</td></tr><tr><td>用友CRM</td><td>4.0</td><td>3.9</td><td>3.6</td><td>3.8</td><td>4.1</td></tr><tr><td>有赞</td><td>4.2</td><td>4.0</td><td>4.0</td><td>3.7</td><td>4.1</td></tr></tbody></table><h3>2. 企业选型建议</h3><p>根据<strong>企业规模、行业、核心需求</strong>，给出针对性建议：</p><table><thead><tr><th>企业类型/需求</th><th>推荐CRM</th><th>核心理由</th></tr></thead><tbody><tr><td>侧重<strong>销售流程精细化</strong>（小单快单/中长单/多方项目）、<strong>多渠道获客与客户深度运营</strong></td><td>超兔一体云</td><td>独创“三一客”跟单模型、工商信息补全、AI待办/日报、采购管理，适配复杂销售场景</td></tr><tr><td><strong>大型企业/跨国公司</strong>，需要<strong>强生态整合</strong>（Microsoft 365/LinkedIn/ERP）、<strong>高自定义</strong></td><td>Microsoft Dynamics 365</td><td>Power Platform低代码工具、Azure AI扩展性、全球生态覆盖</td></tr><tr><td><strong>中小企业</strong>，需要<strong>易上手的销售自动化</strong>（线索评分/CPQ/拖放流程）</td><td>Freshsales</td><td>Freddy AI提升转化、本地CPQ快速签单、免费版入门友好</td></tr><tr><td><strong>传统制造/零售</strong>，需要<strong>与ERP深度集成</strong>（业财一体化）</td><td>金蝶云CRM/用友CRM</td><td>与自家ERP无缝对接，实现“销售订单→ ERP生产→ 财务记账”的闭环</td></tr><tr><td><strong>电商行业</strong>，需要<strong>多渠道会员管理与智能导购</strong></td><td>有赞</td><td>整合微信/抖音/线下会员、智能导购推荐、自动营销文案，贴合电商复购需求</td></tr></tbody></table><h2>四、结论：CRM选型的本质是“匹配业务增长阶段”</h2><p>CRM的核心价值不是“功能越多越好”，而是“匹配企业当前的业务阶段与核心需求”：</p><ul><li>初创期企业：选“轻量化、易上手”的CRM，如Freshsales免费版，能满足基本的联系人和交易管理、自动化邮件跟进等需求，且其AI线索筛选功能可帮助企业快速聚焦高价值客户，以较低成本开启客户关系管理工作。</li><li>成长期企业：随着业务规模扩大、销售场景变复杂，需重点考虑销售流程精细化与客户深度运营。超兔一体云是不错之选，其独创的跟单模型、全流程管控能力以及多渠道获客方式，能助力企业应对各种销售场景，提升业务效率与客户关系质量。</li><li>大型企业/跨国公司：对强生态整合和高自定义需求迫切，Microsoft Dynamics 365凭借Power Platform低代码工具、Azure AI扩展性以及全球生态覆盖，可实现“销售订单→ ERP生产→ 物流跟踪”等全球协同，满足复杂业务场景下的管理需求。</li><li>传统制造/零售企业：与ERP深度集成实现业财一体化是关键，金蝶云CRM和用友CRM能与自家ERP无缝对接，完成“销售订单→ ERP生产→ 财务记账”闭环，让业务数据流转更顺畅。</li><li>电商行业企业：多渠道会员管理与智能导购是核心需求，有赞可整合微信、抖音、线下门店等渠道会员数据，提供智能导购和自动营销文案生成，贴合电商提升复购率需求。</li></ul><p>企业在选择CRM时，应深入分析自身业务特点、发展阶段和核心诉求，综合对比各CRM系统在客户管理、销售管理、AI智能、自定义能力和API集成等维度的表现，做出最适合自己的决策，从而借助CRM系统实现业务的持续增长和竞争力的提升。</p><p>（注：文中功能相关描述均基于公开披露信息，具体功能服务以厂商实际落地版本为准。）</p>]]></description></item><item>    <title><![CDATA[AI Agent 黑客松报名通道开启，你的“一人公司”就差这一步 OpenBuild ]]></title>    <link>https://segmentfault.com/a/1190000047559972</link>    <guid>https://segmentfault.com/a/1190000047559972</guid>    <pubDate>2026-01-23 11:10:18</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdnIGs" alt="fce16b0fecfa0585fd346adc9d8b25fc.jpg" title="fce16b0fecfa0585fd346adc9d8b25fc.jpg"/></p><p>由 OpenBuild 联合 SegmentFault、VibeFriends 和 Monad 共同发起，并携手 KIMI、智谱 AI、豆包编程、YouWare、阶跃星辰、Rokid、硅基流动、立创开源等多家顶尖 AI 公司举办的「Rebel in Paradise AI 黑客松」已正式拉开帷幕。这场聚焦“智能体时代原生基础设施、产品与市场”的深度探索之旅，现已面向全球开发者开放报名通道。</p><p>如果你的桌面还堆满关于 AI Agent 的技术文档却无处实践；如果你的脑海中早已构想出一个能够自动化工作流、创造价值的智能体应用却缺少舞台；如果你渴望与 Kimi、智谱 AI、豆包编程等一线团队的技术专家面对面交流，那么，你的机会来了。</p><p>这可能是智能体时代最后的“末班车”</p><h3><strong>Rebel in Paradise AI 黑客松三大核心赛道</strong></h3><p>过去一年，AI 智能体从概念走向落地，正在重塑工作方式与商业逻辑。但真正的创新浪潮才刚刚涌起。本次黑客松瞄准三大核心赛道，直击行业最前沿痛点：</p><h4><strong>赛道一：Agent-native Payments</strong></h4><p>智能体间的价值流转与支付协议、微支付系统、自动化结算方案——这是构建智能体经济系统的基石。</p><h4><strong>赛道二：Intelligent Markets</strong></h4><p>基于智能体的预测市场与交易系统，探索数据市场、算力市场、AI服务市场的全新可能性。</p><h4><strong>赛道三：Agent-powered Apps</strong></h4><p>由智能体驱动的下一代应用，从工作流自动化到个性化助手，再到协作工具，用代码定义未来。</p><h3><strong>Hackathon 时间</strong></h3><p><strong>👥 报名与组队期：</strong> 即日起 - 项目提交前均可报名组队</p><p><strong>💻 项目提交截止：</strong> 2026年2月28日 23:59:59</p><p><strong>✅ 最终结果公布：</strong> 2026年3月10日</p><h3><strong>如何参与</strong></h3><p><strong>👉立即报名：</strong><a href="https://link.segmentfault.com/?enc=Ge2AcUsi0jYpS5FLj1Gh3A%3D%3D.VOsRob1STWNWtgRcPAvClqdyD8O1hzIZOm17nv6hP%2Fc%3D" rel="nofollow" target="_blank">https://rebel.openbuild.xyz</a></p><p>本次 Hackathon  以线上为主，开发者完全可选择全程线上参与，完成项目构思、开发与提交。同时我们也会在线下举办两场 Hacker Camp：</p><p><strong>👉 北京（1月31日）：</strong> <a href="https://link.segmentfault.com/?enc=lZG0gm4ceGP87zW4fF9Feg%3D%3D.YDB7YUCjfGeWk7wANEATXpdU%2ByBE0tFYo1B4BlpG5nE%3D" rel="nofollow" target="_blank">https://luma.com/irllzbeu</a></p><p><strong>👉 深圳（2月7日）：</strong> <a href="https://link.segmentfault.com/?enc=7rX4O7BkFws3ugeIxtq9pQ%3D%3D.%2Fv2gBJQauqtWpmCmkVKSWiftFCZMqy6dLAPSF%2F%2FQcB4%3D" rel="nofollow" target="_blank">https://luma.com/je6if25j</a></p><p>为开发者提供的额外深度交流与实战辅导机会，你可以将此视为一次与导师、队友线下碰撞火花的“加速器”。</p><p>无论你身在何处，均可参与线上环节，享受同等技术辅导、资源支持与评奖资格。当然，无论是否报名 Hackathon，也非常欢迎亲临线下活动现场，与数百名开发者同台交流。</p><h3><strong>为什么你必须把握这次机会？</strong></h3><p>**💰 总奖池 $40,000：** $20,000现金 + $20,000 资源奖励</p><p><strong>🔥 稀缺资源支持：</strong> 包括 LLM Token、 NVIDIA DGX、顶尖公司参访机会等</p><p><strong>🆙 成长直通车：</strong> 一线AI公司技术专家辅导、投资人对接、项目孵化支持</p><p><strong>💬 社群与背书：</strong> 加入由高质量开发者、创业者和技术领袖组成的创新网络</p><p>智能体时代的竞争，已从“是否会使用工具”升级为“能否创造智能体”。这趟驶向未来的列车已经鸣笛，车厢里坐着Monad、Kimi、智谱AI的技术领袖，也坐着与你一样渴望用代码重塑世界的开发者。</p><p>别等到2月28日才后悔没报名。最好的开始时间，永远是现在。</p><h3><strong>快速答疑（Q&amp;A）</strong></h3><p><strong>Q：可以纯线上参与，完全不参加线下活动吗？</strong></p><p>A：完全可以。 线上参与即可完成全部黑客松流程并获得完整资源支持。</p><p><strong>Q：没有成型的项目或想法，可以报名吗？</strong></p><p>A：可以。 线下活动无门槛，线上黑客松最终需提交项目，但我们鼓励从0到1的探索，并设有相应辅导环节。</p><p><strong>Q：如何组队？</strong></p><p>A：建议自行组队，也可在活动社群中招募队友。</p><p><strong>Q：可以同时报名北京和深圳两场线下活动吗？</strong></p><p>A：可以。</p><p><strong>Q：资源支持（算力、硬件等）如何申请？</strong></p><p>A：组队成功后即可提交申请。</p><p><strong>Q：能选择多个赛道吗？</strong></p><p>A：可以多选，组委会将进行简单审核。</p><p>我们相信，下一个时代的“一人公司”，将由智能体与你共同构建。</p><h3><strong>合作伙伴</strong></h3><p><img width="723" height="1558" referrerpolicy="no-referrer" src="/img/bVdnIGt" alt="a29ee9b59442ba5f9ec3ab9f372566ef.jpg" title="a29ee9b59442ba5f9ec3ab9f372566ef.jpg" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[『NAS』在绿联安装一个抠图工具-withoutbg 德育处主任 ]]></title>    <link>https://segmentfault.com/a/1190000047560051</link>    <guid>https://segmentfault.com/a/1190000047560051</guid>    <pubDate>2026-01-23 11:09:18</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><strong>点赞 + 关注 + 收藏 = 学会了</strong></p><blockquote>整理了一个NAS小专栏，有兴趣的工友可以关注一下 👉 <a href="https://link.segmentfault.com/?enc=vTdrWi4qpHpce8NVXlBMDQ%3D%3D.9ROiUbyln03GEilEuyw%2BcgDQQklePAyaJkfhB%2FLOKk%2F%2B8LO75Bug4eMFxcGjCfBYTuO6vhXZYtz0egvTRNt8q91fHVcqkNS6v4vaK%2BxLT%2BbKo1pknBSb1w%2FC6pCS4ll%2FSyHJil4rWsn%2FK6J576Kc70JdTwoFDsA20khJlQikgk0%3D" rel="nofollow" target="_blank">《NAS邪修》</a></blockquote><p>withoutbg 是一款 AI 图片去背景工具，支持本地免费离线处理（隐私保护）和 Pro 版高质量处理，能通过 Docker 轻松部署到 NAS。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560053" alt="" title=""/></p><p>这次用的是绿联DXP4800Plus。</p><p>打开 Docker，打开“镜像”模块，搜索“withoutbg”。</p><p>下载红框这个。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560054" alt="" title="" loading="lazy"/></p><p>下载完成后，打开“本地镜像”，点击“withoutbg/app”右侧的加号创建一个容器。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560055" alt="" title="" loading="lazy"/></p><p>“自动重启”建议开启。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560056" alt="" title="" loading="lazy"/></p><p>然后往下滑，NAS端口设置一个其他项目没用过的数字。比如我这里设置的是 <code>39155</code>。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560057" alt="" title="" loading="lazy"/></p><p>接着在浏览器打开 <code>绿联NAS的IP + 39155</code> 就可以使用 withoutbg 抠图了。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560058" alt="" title="" loading="lazy"/></p><p>试了一下，物品、动物、人物都可以抠。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560059" alt="" title="" loading="lazy"/></p><p>但缺点就是它自己去识别抠什么，并没提供一个涂抹工具，让我涂什么它就在我涂抹的区域去抠图。</p><p>而且界面没中文。</p><hr/><p>以上就是本文的全部内容啦，想了解更多NAS玩法可以关注<a href="https://link.segmentfault.com/?enc=SOLDC32dzIiNcew%2F4Ogrow%3D%3D.L5B%2FB3M1ZyDy3T%2Bn3VzsP5rzfE%2F1o80ZYPbm0TlL5sbjEXyyjyypqjscpBdhH9aX7WbURFTaovZJ%2BFM86zM637oM3ijOvB7cIZWZZ3wvIQdp2W6scAz%2F3IYn83OZeQ5rcGg3TYUGCV8kb6%2BqATUXnpmiwP14HotC%2BQLEo4umGhI%3D" rel="nofollow" target="_blank">《NAS邪修》</a></p><p><strong>点赞 + 关注 + 收藏 = 学会了</strong></p>]]></description></item><item>    <title><![CDATA[『n8n』一招解决“无法读写本地文件” 德育处主任 ]]></title>    <link>https://segmentfault.com/a/1190000047560071</link>    <guid>https://segmentfault.com/a/1190000047560071</guid>    <pubDate>2026-01-23 11:08:19</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><strong>点赞 + 关注 + 收藏 = 学会了</strong></p><blockquote>整理了一个n8n小专栏，有兴趣的工友可以关注一下 👉 <a href="https://link.segmentfault.com/?enc=p7bJhTJM5S7LJc%2BkeP%2B9%2FQ%3D%3D.fTslrQ5O3xwyH7mLIv0KnvMGDZuTlQTjiFuSQtuxkS%2BwYvHBLPxHrF3z4L%2FaHkyIpJwuX%2F4y4usMs4YKx7cLrn7DRPQC%2F9cJhdAryE%2BrbZIi%2FRcLbfLBH3ojGyov5IzhxVsSmqxmFmkG62wjD7e8IxEqmkcO14U%2Fs%2ButX9KddQo%3D" rel="nofollow" target="_blank">《n8n修炼手册》</a></blockquote><p>不管是在电脑还是 NAS 通过 Docker 部署 n8n，环境变量没配置好的话，使用 <code>Read/Write Files from Disk</code> 节点「读取本地本地」或者「保存文件到本地」，有可能出现这个报错。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560073" alt="" title=""/></p><p>这是 <strong>Docker + n8n 文件系统权限/路径隔离</strong> 的经典问题，不是 n8n 节点用错，而是<strong>容器只能访问被允许的目录</strong>。</p><p>⚠️⚠️⚠️</p><p><strong>想解决这个问题，首先要将你 n8n 上已有的工作流等数据找个地方保存好。因为要改环境变量，有可能会丢失数据。</strong></p><p>⚠️⚠️⚠️</p><h2>在电脑用 Docker 部署</h2><p>打开 Docker，首先要在 Containers 里删掉部署好的 n8n。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560074" alt="" title="" loading="lazy"/></p><p>然后到 Images，假设你没删掉 n8n 镜像的话，重新点击一下运行按钮。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560075" alt="" title="" loading="lazy"/></p><p>删掉镜像了就重新拉一遍吧。可以参考<a href="https://link.segmentfault.com/?enc=TBTDRzCUxhGUEjIydmguPw%3D%3D.uHhtAL8HUoGG%2Ff6aTPChIGwHXGFN%2BBLXJs4tOXmxzNWG55OiKyLacQIwB2llm4XAJSCemI6FkXKiyIO%2BzSRi4A%3D%3D" rel="nofollow" target="_blank">《『n8n』环境搭建》</a></p><p>点击运行按钮后，需要添加在 Volumes 里添加一项（下图红框）。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560076" alt="" title="" loading="lazy"/></p><p>在你的电脑，找个位置创建要给文件夹。</p><ul><li>上图红框的 <code>Host path</code> 这项就填入你在电脑创建的文件夹的绝对路径。</li><li><code>Container path</code> 这项填入 <code>/home/node/.n8n-files</code>，必须是这个值！一个字一个符号都不能少！</li></ul><p>然后点击“Run”按钮（弹窗右下角蓝色底色那个按钮）。</p><p>之后再浏览器输入 <code>localhost:5678</code> 就能运行 n8n 了。</p><p>接下来使用 <code>Read/Write Files from Disk</code> 节点读写文件，都是指向你刚刚在电脑创建的那个文件夹。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560077" alt="" title="" loading="lazy"/></p><p>比如我的 <code>/home/node/.n8n-files</code> 指向了 <code>文稿/n8n-data</code> 这个文件夹，里面有一个 <code>hello.txt</code> 文件。</p><p>在 n8n 里使用 <code>Read/Write Files from Disk</code> 节点时，<code>File(s) Selector</code> 项需要这么写：</p><pre><code>/home/node/.n8n-files/hello.txt</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560078" alt="" title="" loading="lazy"/></p><p>可以看到文件读取成功了。</p><p><strong>记住记住！用法是这样的，别问为什么</strong>⬇️⬇️⬇️</p><pre><code>/home/node/.n8n-files/文件名.后缀</code></pre><h2>在绿联 NAS 部署</h2><p>如果你是在 NAS 上部署 n8n，通常使用 Docker 部署的吧～</p><p>不管你是用群晖还是其他牌子的NAS，如果使用新建项目，用是 <code>yaml</code> 拉镜像。</p><pre><code>services:
  n8n:
    image: n8nio/n8n:latest   # 为了汉化成功，这里需要指定镜像版本号
    container_name: n8n
    ports:
      - 5678:5678
    volumes:
      - n8n:/home/node/.n8n # 冒号前面映射n8n文件夹绝对路径
      - n8n-files:/home/node/.n8n-files # 冒号前面映射n8n-files文件夹绝对路径
    restart: unless-stopped</code></pre><p>那么 <code>yaml</code> 的代码必须在 <code>volumes</code> 里加一项 <code>- n8n-files:/home/node/.n8n-files</code>。冒号前面的 <code>n8n-files</code> 是允许 n8n 读写文件的文件夹的<strong>绝对路径</strong>。</p><p>如果你是使用<a href="https://link.segmentfault.com/?enc=sbCGAdQFlQMknj0tc3r1og%3D%3D.YB3AgS3OxdBg8FT0MJp1qyXQFXCJke4XdtpyF6oaQYqlZEHFLwyTws%2FF1%2FBaCQHdE076G3S7YEYBkZEji6j5FA%3D%3D" rel="nofollow" target="_blank">《『NAS』不止娱乐，NAS也是生产力，在绿联部署AI工作流工具-n8n》</a>里提到的方法，在 Docker 的「镜像」模块里搜索 n8n 下载部署的话，需要这么做。</p><p>我用绿联 NAS 举例，其他品牌的 NAS 操作方法大同小异。</p><p>在 Docker 的「容器」里找到 n8n，停止运行。</p><p>然后编辑它。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560079" alt="" title="" loading="lazy"/></p><p>在 NAS 的「文件管理」里创建一个文件夹，用来给 n8n 读写文件使用的。</p><p>然后在「编辑容器」的「存储空间」里添加一项 <code>/home/node/.n8n-files</code> 指向那个文件夹，提供“读写”权限，如下图红框所示。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560080" alt="" title="" loading="lazy"/></p><p>点击“保存”按钮，然后运行项目。</p><p>我在 NAS 的 <code>n8n-files</code> 文件夹里准备了一个 <code>雷猴世界.txt</code> 文件。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560081" alt="" title="" loading="lazy"/></p><p>在 n8n 里，使用 <code>/home/node/.n8n-files/雷猴世界.txt</code> 这个路径就能读取到上面这个文件了。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560082" alt="" title="" loading="lazy"/></p><p><strong>同样，也是这个格式：</strong></p><pre><code>/home/node/.n8n-files/文件名.后缀</code></pre><hr/><p>以上就是本文的全部内容啦，想了解更多n8n玩法欢迎关注<a href="https://link.segmentfault.com/?enc=a%2FUNOmPdyXkbD5KkZ6TUkw%3D%3D.F%2Bx8cPkSBcFpt%2B1nJkUrZArmI7IvMkmLsqF6HBpT41jhiK5kaoioGs2lWYg3MfKMEWaUUgMfRirIBbD%2BR2f57OiUdseq4t3RuLg%2FJV%2FQZjsMNNK6xl6VknOkFHzn%2F7BliuodY6FdeLX%2FjIbogKFcv91%2FsZRyo8GaWhejOJIs%2FhY%3D" rel="nofollow" target="_blank">《n8n修炼手册》</a>👏</p><p>如果你有 NAS，我非常建议你在 NAS 上部署一套 n8n，搞搞副业也好，帮你完成工作任务也好  <a href="https://link.segmentfault.com/?enc=s97RCxUNV8%2FPLG6nPWQm9A%3D%3D.fbOziNPEo0ZnuiGDOZ5W6ccJi1BrN%2B94lfIxhvwSHBExNk8UaB7pKzD1FsZizdEUxBGSIijOJ8v%2FhYwIg2XCZQ%3D%3D" rel="nofollow" target="_blank">《『NAS』不止娱乐，NAS也是生产力，在绿联部署AI工作流工具-n8n》</a></p><p><strong>点赞 + 关注 + 收藏 = 学会了</strong></p>]]></description></item><item>    <title><![CDATA[视频会议国产化核心技术架构与技术特性解析 Amymaomao ]]></title>    <link>https://segmentfault.com/a/1190000047560285</link>    <guid>https://segmentfault.com/a/1190000047560285</guid>    <pubDate>2026-01-23 11:07:40</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>视频会议国产化核心技术架构与技术特性解析</p><p>在数字化协同与信息安全需求双重驱动下，视频会议国产化已从政策导向转向技术落地，其核心价值集中体现在自主可控、安全可靠、全场景适配三大维度。通过硬件根基、编解码技术、传输优化、安全防护及生态兼容的全链条技术创新，国产化视频会议系统正构建起独立于国外技术体系的完整解决方案。</p><p>一、硬件与系统架构：自主可控的技术根基</p><p>国产化视频会议系统以“芯片-模块-板卡-系统”全链条自主化为核心架构，彻底摆脱对国外硬件的依赖。核心硬件层面，采用国产自主研发的音视频编解码芯片、高性能主控芯片及信号处理芯片，覆盖X86与ARM双架构，适配飞腾、鲲鹏、兆芯等主流国产CPU，PCB板采用国产基材并通过-40℃~70℃极端环境适应性测试，保障供应链稳定与硬件可靠性。</p><p>系统层面深度适配银河麒麟、统信UOS、中科红旗等国产操作系统，实现客户端与服务器端的全平台兼容，同时支持Windows、MacOS、Android、iOS等跨系统协同，形成“硬件-系统”软硬协同的底层支撑。架构设计上采用分布式集群架构，通过多节点负载均衡提升并发处理能力，可支持数百至上千分会场的大规模会议调度，满足应急指挥、跨区域协作等复杂场景需求。</p><p>二、音视频编解码与传输技术：高清流畅的体验保障</p><p>（一）超高清编解码技术突破</p><p>国产化视频会议系统已实现从1080P到4K的画质跃升，旗舰级方案支持4K60fps主辅流双路传输，部分高端方案可实现8K60fps输出，画面色彩还原度达98%，能精准呈现文档细节、图纸线条及面部微表情，满足远程医疗、技术培训等高精度场景需求。编码标准上全面支持H.265高效编码与AVS3国产编码双标准，在保障画质的同时实现带宽利用率提升50%，仅需1Mbps带宽即可传输4K30fps高清视频，较行业平均水平显著降低网络成本。</p><p>音频处理方面采用OPUS 48K高保真编码，融合智能混音、回音抑制与噪音过滤算法，可有效屏蔽键盘敲击、空调运行等环境杂音，实现清晰自然的实时语音交互。针对复杂声学环境，系统具备自动增益调节与声场均衡功能，确保不同参会环境下的语音清晰度。</p><p>（二）宽域网络适配与抗干扰优化</p><p>传输技术上支持64Kbps-8Mbps宽范围带宽调节，在偏远地区低带宽环境下，64Kbps模式可保障基础音视频沟通；在高速网络环境中，8Mbps带宽能充分释放超高清性能。通过动态码率控制算法，系统可实时适配网络波动，在30%丢包率环境下仍能保持画面完整性与语音连续性。</p><p>为提升带宽利用效率，系统提供多模式智能调控机制：自动模式适配高端全高清会议，主流优先模式保障主讲画面清晰，辅流优先模式优化文档分享体验，可通过快捷操作10秒内完成切换。网络协议层面支持IPv4/IPv6双栈，兼容TCP/IP、RTP/RTCP等传输协议，同时通过H.460穿透技术解决防火墙限制，保障跨网络、跨区域会议的稳定连接。</p><p>三、安全防护体系：国密标准的全链路保障</p><p>国产化视频会议系统以GB/T 39786-2021国家密码标准为核心，构建“硬件-传输-存储”全链条安全防护。加密技术上集成SM2、SM3、SM4国密算法，通过SM4算法实现音视频流端到端加密，SM3算法保障存储数据完整性，SM2算法完成终端身份认证与数字证书核验，从根源杜绝数据泄露风险。</p><p>协议安全层面采用TLS/SRTP双重加密机制，TLS加密保护会议邀请、权限控制等信令数据，防止被篡改或窃听；SRTP加密保障音视频媒体流传输安全，即使数据被截获也无法解密还原。权限管理上采用“管理员-主讲人-参会人”三级角色体系，可精细化控制会议录制、文件下载、屏幕共享等敏感功能，满足政务、金融等涉密场景的安全要求。</p><p>数据存储方面支持本地服务器部署与国产化云平台适配，所有会议数据均存储于国内服务器，严格遵循数据跨境传输相关规定，避免数据出境风险。系统还内置日志审计与操作追溯功能，可完整记录会议创建、参会人员、数据传输等全流程信息，便于安全审计与问题排查。</p><p>四、智能协同与生态适配：全场景应用赋能</p><p>（一）智能会议功能升级</p><p>国产化视频会议系统深度融合AI技术，实现会议全流程智能化赋能。人脸自动签到功能可在几分钟内完成百人参会者身份核验，语音转写准确率达98%，会议结束后自动生成结构化纪要并同步至OA系统，大幅提升协作效率。视频处理上集成AI画质增强技术，通过自动曝光调节解决光线不均问题，避免“逆光黑脸”现象，提升复杂环境下的视觉体验。</p><p>会议管理功能覆盖通讯录管理、会议预约、分组讨论、文件共享、电子白板等全场景需求，支持会中功能模块自定义配置，可根据行业特性与办公习惯灵活调整功能布局。部分方案支持多机位接入与智能调度，主会场可连接4台以上4K摄像机，通过会控终端实现单画面、分屏等多种布局切换。</p><p>（二）国产化生态兼容适配</p><p>系统全面兼容国产软硬件生态，硬件层面可直接对接国产网络摄像机、麦克风、显示终端等外设，支持HDBaseT等接口标准，简化部署流程并降低故障率；软件层面与国产办公软件、政务系统、CRM系统无缝集成，实现会议预约、纪要分发、任务跟进的全流程闭环管理。</p><p>针对不同行业场景，系统提供定制化适配能力：应急指挥场景支持全省级多会场实时调度，教育场景优化课件分享与录播功能，企业协作场景兼容主流办公平台，形成覆盖政务、金融、医疗、教育等多领域的解决方案体系。同时支持终端多样化接入，包括PC端、移动端、TV终端等，满足移动办公与固定会场的全场景使用需求。</p><p>结语</p><p>视频会议国产化的技术演进，本质是自主创新与场景需求的深度融合。从核心芯片的自主研发到国密算法的全面应用，从超高清传输到智能协同，国产化系统已在技术性能、安全防护与生态适配等方面实现跨越式发展。未来，随着AI大模型、5G等技术的深度融入，视频会议国产化将向更低延迟、更高智能、更广兼容的方向进阶，为数字中国建设提供安全可靠的协同支撑。</p>]]></description></item><item>    <title><![CDATA[Python接口自动化测试框架实战开发！ 坎窝主夜 ]]></title>    <link>https://segmentfault.com/a/1190000047560292</link>    <guid>https://segmentfault.com/a/1190000047560292</guid>    <pubDate>2026-01-23 11:06:51</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>吃透 Python 接口自动化测试框架：从设计到开发实战精讲——超越脚本，构建质量壁垒<br/>在软件测试领域，“接口自动化”早已不是什么新鲜词汇，甚至可以说是测试工程师的标配技能。然而，在实际的工作交流中，我发现一个普遍的现象：绝大多数测试人员虽然每天都在使用 Python 写自动化脚本，但却往往停留在“能用”的层面，甚至陷入了“为了自动化而自动化”的泥潭。面对复杂多变的业务场景，现成的工具如 Postman 或简单的脚本往往显得力不从心。因此，“吃透 Python 接口自动化测试框架：从设计到开发实战精讲”这一课题的价值，便显得尤为突出。在我看来，这不仅是一次技术能力的提升，更是一场从“脚本工人”向“测试架构师”的思维蜕变。<br/>首先，我们需要明确“框架”与“脚本”的本质区别。很多初学者所谓的自动化，不过是利用 requests 库写了一长串线性执行的测试函数。这种方式在面对三五个接口时或许效率尚可，但随着业务量的指数级增长，脚本维护成本会迅速失控。真正的框架设计，核心在于“抽象”与“复用”。一个优秀的框架，应当像搭建乐高积木一样，将通用的能力——如 HTTP 请求的封装、配置文件的读取、日志的记录、数据库连接的管理——剥离出来，形成稳固的底层基石。通过精讲框架设计，我们学会的是如何用工程化的视角去看待测试代码，如何利用 Python 的面向对象特性来降低系统的耦合度。这种设计思维的建立，是解决“脚本难维护、扩展性差”这一顽疾的唯一解药。<br/>其次，深入理解框架的运行机制，是解决复杂测试场景的关键。在实际测试中，我们经常面临数据依赖、环境隔离、并发执行以及异步处理等棘手问题。例如，接口 B 的入参依赖于接口 A 的返回值，如何优雅地处理这种链式依赖？又比如，在进行数据驱动测试时，如何将测试代码与测试数据彻底分离？这些问题的解决，不能靠堆砌 if-else，而是需要框架层面提供强大的支持，比如引入装饰器来处理前置条件，或者利用设计模式（如工厂模式、单例模式）来管理测试生命周期。实战精讲的魅力在于，它不会只教你“怎么做”，而是深入剖析“为什么这么做”。当你吃透了框架内部的请求拦截器、钩子函数以及异常捕获机制后，你会发现，那些曾经看似不可逾越的障碍，如今都能在框架层面通过寥寥数行配置得以化解。<br/>再者，从设计到开发的完整闭环，能够极大地提升测试工程师的技术话语权。在传统的研发流程中，测试人员往往处于被动接收的一方。然而，当你能够独立设计并开发一套企业级的自动化测试框架时，你的角色就发生了质的变化。你不再仅仅是质量的“检验者”，而是质量保障体系的“建设者”。这套框架不仅是验证业务逻辑的工具，更是研发团队的“基础设施”。通过集成 CI/CD 流水线，实现代码提交后的自动触发与报告反馈，测试框架成为了连接开发与运维的桥梁。这种对工程效能的推动，是单纯的手工测试或浅层脚本无法比拟的。它要求我们不仅要懂 Python，还要懂 Linux、懂 Docker、甚至懂一点架构设计，这种全栈式的视野正是测试进阶的核心竞争力。<br/>此外，我认为“吃透”二字还意味着对可扩展性与稳定性的极致追求。一个好的框架，必须具备良好的容错能力和清晰的报告机制。在实战中，我们需要思考如何设计断言库，才能让报错信息一目了然？如何处理网络抖动导致的偶发失败，避免误报？这些细节的打磨，直接决定了自动化测试在团队中的信任度。如果测试框架总是“报错不断”且难以排查，那么它最终只会被束之高阁。通过精讲中的实战演练，我们将学会如何编写鲁棒性强的代码，如何通过日志追踪问题的源头，从而让自动化测试真正成为团队信赖的“守门员”。<br/>综上所述，Python 接口自动化测试框架从设计到开发的学习，绝非只是掌握几行 Python 语法或几个测试库的用法那么简单。它是一场关于代码质量、系统设计思维以及工程效能的深度修炼。它帮助我们摆脱了重复劳动的桎梏，赋予了我们构建复杂质量保障体系的能力。对于每一位渴望在测试领域深耕、希望打破职业天花板的工程师来说，吃透框架设计与开发，是通往技术高地的必经之路。它让我们明白，真正的自动化，不是机械地执行点击，而是用智慧构建一套能够自我进化、高效运转的质量生态系统。</p>]]></description></item><item>    <title><![CDATA[有哪些SRM系统是专门为供应链管理设计的？ SaaS圈老马 ]]></title>    <link>https://segmentfault.com/a/1190000047560326</link>    <guid>https://segmentfault.com/a/1190000047560326</guid>    <pubDate>2026-01-23 11:06:00</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>众所周知，供应链管理已经成为企业降本增效、提升协同效率和增强抗风险能力的核心环节，而 SRM（供应商关系管理）系统，正是企业在供应链管理过程中，用来规范供应商协作、控制采购风险、提升整体效率的重要工具。</p><p>但面对市场上数量众多、功能差异明显的 SRM 系统，很多企业在选型时都会遇到同样的问题：<strong>哪些 SRM 系统是真正围绕供应链管理场景设计的？哪些更适合国内企业使用？是否有成熟、稳定、经过市场验证的产品可供参考？</strong> 如果逐一试用，不仅成本高，也非常耗费时间和精力。</p><p>因此，本文将结合 <strong>SRM 系统市场口碑、产品功能完整度以及实际应用体验</strong>，参考行业内常见的 SRM 系统榜单、厂商公开资料及用户反馈，对多款专注供应链管理的 SRM 系统进行整理和分析，帮助大家在选型过程中少走弯路。</p><p>本次测评主要围绕 <strong>系统的供应链适配度、功能实用性、用户体验以及市场认可度</strong> 等核心维度进行筛选，剔除了偏向通用管理或功能不成熟的产品，最终选出几款在业内表现较为突出的 SRM 系统进行重点介绍。</p><p>考虑到篇幅和阅读体验，本文不会对所有系统逐一展开，而是挑选其中<strong>综合表现更优、供应链场景覆盖更完整的几款 SRM 系统</strong>，重点说明它们的优势、适合的企业类型以及核心功能亮点。每款产品后也会附上官方信息，方便大家结合自身需求进一步了解和体验。那么，下面我们正式开始。</p><p><strong>一、正远科技</strong></p><p>如果要说国内在SRM领域有长期积累、并且真正从业务视角去设计系统的厂商，<strong>正远科技</strong>肯定排在前列。这家公司成立于2002年，在流程管理和供应链数字化领域已经深耕了二十多年，不是那些跟风做SRM的“新手”。</p><p>正远科技的SRM系统是基于<strong>自主研发的低代码平台产品</strong>研发的，最大特点就是<strong>围绕采购业务全流程设计</strong>，而不是简单把OA或者CRM改个名字。系统核心涵盖三大模块：<strong>供应商管理、价格管理、采购执行协同</strong>，基本把企业采购从寻源、定价、下单、对账到绩效评估的全过程都管起来了。</p><p>官网：<a href="https://link.segmentfault.com/?enc=3fe5Go5zvvsL2ZWwTC3fvA%3D%3D.3Q0WFuRxzWD8HtroKnCU9tJF7oOnrn%2FTUkfFrNeHWUw%3D" rel="nofollow" target="_blank">https://www.zhengyuansz.com</a></p><p><strong>为什么它值得重点说一说？</strong></p><p>首先，它的<strong>流程引擎和表单设计能力特别强</strong>。采购过程中各种审批流、询价比价流程、合同评审流程，都可以通过可视化方式配置出来，企业自己就能调整，不用每次都找厂商开发。这对于业务经常变动的企业来说，实用性很高。</p><p>其次，它背后有<strong>正远低代码平台</strong>支撑。这意味着如果你有一些个性化需求，比如要和已有的ERP、财务系统对接，或者增加一些特定的质检流程、物流跟踪看板，都可以通过低代码方式快速搭建出来，<strong>开发成本降低、周期也大幅缩短</strong>。对于很多预算有限但又需要定制化功能的中大型企业，这个优势很明显。</p><p>第三，正远SRM<strong>不只是一个工具，更强调管理落地</strong>。它内置了供应商准入、分类、绩效评估体系，帮助企业把供应商从“资源”变成“伙伴”，实现从被动应付到主动管理的转变。系统还支持与招投标平台、电子签章等外部系统集成，形成采购闭环。</p><p><strong>适合谁用？</strong></p><p>从公开信息看，正远科技服务过<strong>威高集团、南山集团、魏桥创业</strong>等一批大型制造集团，项目经验集中在制造业、工程、能源等领域。所以如果你是制造类企业，采购物料复杂、供应商数量多、对质量与交期要求高，正远这套系统应该能贴合你的业务场景。他们的实施团队也有PMP认证，项目交付经验比较扎实。<br/><img width="723" height="328" referrerpolicy="no-referrer" src="/img/bVdnIL6" alt="" title=""/></p><p><strong>二、用友</strong></p><p>用友作为国内企业管理软件的老牌厂商，其SRM解决方案通常与它的ERP产品深度绑定。如果你公司已经在使用用友的ERP系统（比如U8、U9、NC Cloud），那么继续选用友的SRM会是一个比较顺理成章的选择。</p><p>用友SRM的核心优势在于<strong>数据无缝对接和业务流程一体化</strong>。采购订单、库存信息、财务应付数据都能和ERP实时同步，避免了跨系统对接的麻烦和数据不一致的问题。对于中大型企业，这种一体化带来的效率提升和错误减少，价值很大。</p><p>在功能层面，用友SRM覆盖了供应商生命周期管理、采购寻源、招标管理、采购协同、库存协作等典型场景。它特别强调<strong>集团化管控</strong>，适合多法人、多工厂、跨地域的集团型企业，能够实现集中采购、分散执行的模式。</p><p>值得一提的是，用友近年来也推出了<strong>低代码开发平台YonBuilder</strong>，可以基于它快速构建或扩展SRM中的某些定制化模块，比如特殊的审批流程、供应商门户页面等。但要注意，用友<strong>整体方案的费用较高，部署周期也相对较长</strong>，更适合预算充足、追求系统稳定性和生态完整性的企业。<br/><img width="723" height="282" referrerpolicy="no-referrer" src="/img/bVdnIL7" alt="" title="" loading="lazy"/></p><p><strong>三、金蝶</strong></p><p>金蝶的SRM解决方案，现在主要整合在<strong>金蝶云·苍穹</strong>这个PaaS平台里，产品名称通常是“金蝶云·星瀚”或“金蝶云·星辰”中的SRM模块。和用友类似，金蝶SRM也与自家的ERP、财务系统天生融合。</p><p>金蝶SRM的特点是<strong>云原生架构</strong>，部署和扩展比较灵活。它强调敏捷采购和协同效率，在供应商协同门户、移动审批、实时询价比价等方面做得比较轻快。对于快消、零售、现代服务业等采购品类相对标准、追求效率的行业，匹配度不错。</p><p>它的供应商管理模块也提供了从注册、认证、考核到淘汰的全周期管理工具。另外，金蝶在<strong>数据分析</strong>方面一直有优势，其SRM系统也能提供一些采购价格趋势分析、供应商绩效看板等数据化工具，帮助采购人员做决策。</p><p>如果你企业是金蝶ERP的用户，或者倾向于全栈采用一家云服务商的解决方案，希望系统架构现代、迭代速度快，金蝶云星SRM值得纳入考虑范围。不过，它的行业深度定制能力，相比专注垂直领域的厂商，可能还需要结合生态伙伴来完成。<br/><img width="723" height="312" referrerpolicy="no-referrer" src="/img/bVdnIL8" alt="" title="" loading="lazy"/></p><p><strong>四、SAP Ariba</strong></p><p>提到SRM，很难绕开<strong>SAP Ariba</strong>。它是全球领先的采购云平台，尤其擅长<strong>直接物料采购和全球化供应链协同</strong>。如果你的企业业务遍布全球，需要管理众多海外供应商，进行国际寻源和招标，Ariba的网络效应和标准化流程非常有优势。</p><p>Ariba不仅仅是一个软件，更是一个<strong>连接买家和卖家的网络平台</strong>。买方企业可以通过Ariba Network发布需求，直接触达海量供应商；卖方也可以通过它接收订单、开具发票，实现端到端的数字化协同。这种网络价值是单体SRM系统很难比拟的。</p><p>功能上，Ariba在战略寻源、合同管理、支出分析等方面非常强大。但它的缺点也很明显：<strong>实施和运营成本高昂</strong>，流程设计偏重国际化标准，可能不太适应国内一些灵活、本土化的采购习惯。而且，系统较为复杂，对内部团队和供应商的数字化水平要求都比较高。</p><p>因此，SAP Ariba更适合那些跨国公司、大型集团，或者采购模式非常标准化、追求与国际接轨的企业。对于大多数国内中小型企业而言，它的“重量级”可能有些难以承受。<br/><img width="723" height="350" referrerpolicy="no-referrer" src="/img/bVdnIL9" alt="" title="" loading="lazy"/></p><p><strong>五、企企通</strong></p><p><strong>企企通</strong>是近年来在国内SRM SaaS市场比较活跃的一家厂商。它定位清晰，就是专注于<strong>供应链双边协同平台</strong>，核心解决企业与供应商之间的订单、交货、对账、质量等协同问题。</p><p>它的产品界面比较友好，操作轻量化，供应商上手门槛低。企业可以通过企企通快速搭建一个供应商门户，让供应商自助查询订单、送货预约、提交质检报告、跟踪付款状态等，大大减少采购员和供应商之间反复打电话、发邮件的工作量。</p><p>企企通采用<strong>SaaS订阅模式</strong>，初始投入成本低，部署快，特别适合那些想快速上线SRM核心协同功能、又不想在IT上投入太多的成长型企业。它在电子制造、服装、食品等行业有不少客户案例。</p><p>当然，作为一款偏重协同的SaaS产品，它在复杂的战略寻源、集团化深度管控等方面，可能不如前面几家全面。但对于首要任务是“把现有采购执行流程理顺、提高协同效率”的企业来说，企企通是一个很务实的选择。<br/><img width="723" height="368" referrerpolicy="no-referrer" src="/img/bVdnIMa" alt="" title="" loading="lazy"/></p><p><strong>总结：</strong></p><p>测评了一圈，做个简单小结：</p><p><strong>追求深度与定制，尤其是有复杂制造背景</strong>：<strong>正远科技SRM</strong>是个不错的选择。它的低代码底座和深厚的行业理解，能很好应对复杂、多变的采购管理场景，性价比相对较高。已用用友/金蝶ERP，追求一体化稳定：分别考察用友SRM或金蝶云星SRM。生态内协同顺畅，减少集成烦恼，不过确实难免费用较高。业务全球化，采购标准化程度高：可以考虑SAP Ariba。借助其全球网络和最佳实践，但也需准备好相应的预算和变革管理。</p><p>最后提醒一点，选SRM系统不只是选功能，更是选一个长期的合作伙伴。建议在选择前，多看看厂商的真实客户案例（最好同行业），要求进行深入的业务流程演示，甚至先做个试点。毕竟，适合自己业务节奏和管理模式的，才是最好的系统。</p>]]></description></item><item>    <title><![CDATA[零代码开发能力：JVS函数公式的统一解决方案 软件部长 ]]></title>    <link>https://segmentfault.com/a/1190000047560351</link>    <guid>https://segmentfault.com/a/1190000047560351</guid>    <pubDate>2026-01-23 11:05:29</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在现代企业级应用开发中，对数据进行动态加工和转换是常见的需求。<br/>低代码开发作为一种新兴的快速开发方式，提供了函数公式能力，通过函数+入参的方式，用户可以像使用Excel公式一样轻松实现复杂业务逻辑的自动化处理。<br/>在JVS中，函数公式（DataOpter）是核心通用的基础能力，其中逻辑引擎、表单引擎、列表页、流程引擎、数据加工引擎等都拥有这个能力，，用于动态的对数据进行加工，系统本质上是通过groove 的脚本实现的。接下来我们重点讲解函数公式的核心功能。</p><h2>公式的编辑框</h2><p>如下图所示，函数公式是通过 函数+入参的方式，实现对数据的映射转换，在编辑框中可以支持手动录入：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560353" alt="图片" title="图片"/><br/>编辑框中支持手动输入，系统会根据关键词进行提示，提示的内容包括数据与函数<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560354" alt="图片" title="图片" loading="lazy"/><br/>函数框会对公式配置的结果进行语法校验，如果校验不通过，系统会提示语法判断结果，校验不通过是不能保存的<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560355" alt="图片" title="图片" loading="lazy"/></p><h2>公式的数据引用</h2><p>不同的场景下，接入的数据引用来源不同，表单场景下使用公式时，那么左侧的数据引用框架可以选择 上下文的数据、系统的基础数据、表单的数据等； 在流程引擎中使用公式配置时，系统接入了流程的基础数据、上下文的数据等； 在ELT 数据加工引擎中，使用公式时，可以选择到 用户的基本信息、字段的相关数据等<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560356" alt="图片" title="图片" loading="lazy"/></p><h2>函数选择器</h2><p>函数选择器点击函数框中的公式后，公式会自动的提交到编辑框中，在公式说明框中会对该公式进行详细说明<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560357" alt="图片" title="图片" loading="lazy"/></p><h2>函数的嵌套</h2><p>函数是可以多层嵌套使用的，也就是一个函数的输出是另一个函数的输入，函数的使用是从内向外的逐层计算，得到结果的<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560358" alt="图片" title="图片" loading="lazy"/></p><h2>函数的测试</h2><p>在设置了函数公式配置后，可以点击测试按钮，系统可以模拟仿真执行的结果，这样便于判断配置的正确性，如下图所示：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560359" alt="图片" title="图片" loading="lazy"/><br/>点击测试后，如果需要 业务的相关数据，那么系统会弹出输入框，在录入测试数据后，模拟相关业务背景数据，然后再计算：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560360" alt="图片" title="图片" loading="lazy"/><br/>提交后，系统会展示模拟执行的结果<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560361" alt="图片" title="图片" loading="lazy"/><br/>在线demo：<a href="https://link.segmentfault.com/?enc=CQ7ZLPsNtW5fK4fM7LBN0Q%3D%3D.Ee4RqaePn3IKoMX0Lxf60LN9sDaYcVgLZx2y876UYbg%3D" rel="nofollow" target="_blank">https://app.bctools.cn</a><br/>基础框架开源地址：<a href="https://link.segmentfault.com/?enc=%2FDbHwMeNOxkM4yGrXj8S3w%3D%3D.2jgPqhrsHzoYdXSwrNNCh0%2Far5P1koeJBBVGSnRxDV5NzE8n3qh7m%2BtXDYUgC3IA" rel="nofollow" target="_blank">https://gitee.com/software-minister/jvs</a></p>]]></description></item><item>    <title><![CDATA[multibootusb-9.2.0-setup安装步骤详解（附U盘多系统制作教程） 读书笔记 ]]></title>    <link>https://segmentfault.com/a/1190000047560370</link>    <guid>https://segmentfault.com/a/1190000047560370</guid>    <pubDate>2026-01-23 11:04:37</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>​</p><p><code>multibootusb-9.2.0-setup</code>是个<strong>多系统启动U盘制作工具</strong>，能把多个系统镜像（像 Ubuntu、Kali、Windows PE 等）装到一个 U 盘里，开机时选想进的系统就行。</p><h2>一、准备工作</h2><ol><li><p><strong>下载安装包</strong>​</p><p><strong>安装包下载：</strong><a href="https://link.segmentfault.com/?enc=jbFAFYm80YcgJehpzW8z9A%3D%3D.LUWNw9IQS5zfs%2BytXBFEHDm2yGT3kINl%2FnCQKcsfDv2Vy4Npfqu0gtizJ9ny6L7m" rel="nofollow" title="https://pan.quark.cn/s/f3b15864c764" target="_blank">https://pan.quark.cn/s/f3b15864c764</a></p></li><li><p><strong>准备 U 盘</strong>​</p><ul><li>至少 8GB 容量（越大越好，装的系统越多）。</li><li>先把 U 盘里的东西备份一下，制作时会格式化！</li></ul></li><li><p><strong>关闭杀毒软件（可选）</strong> ​</p><ul><li>个别杀毒软件可能会误报，安装时可以暂时关掉，装完再开。</li></ul></li></ol><h2>二、安装步骤</h2><ol><li>双击 <code>multibootusb-9.2.0-setup.exe</code>运行。</li><li>如果是 Windows 10/11，会弹出“用户账户控制”提示 → 点  <strong>“是”</strong> （需要管理员权限）。</li><li>进入安装向导，选语言（默认 English，有的版本有中文可选）。</li><li>点  <strong>“Next”</strong> ​ 继续。</li><li><p>选安装位置：</p><ul><li>默认是 <code>C:\Program Files\multibootusb</code>，想改就点“Browse”选 D 盘或其他盘。</li></ul></li><li><p>选附加任务：</p><ul><li>建议勾“Create a desktop shortcut”（创建桌面快捷方式），点“Next”。</li></ul></li><li>点  <strong>“Install”</strong> ​ 开始安装，等进度条走完（大概十几秒）。</li><li>最后点  <strong>“Finish”</strong> ​ 完成安装，桌面上会有 multibootusb 图标。</li></ol><h2>三、首次运行设置</h2><ol><li>双击桌面图标打开软件。</li><li>插入准备好的 U 盘（会被自动识别）。</li><li>在“Select USB Drive”下拉菜单里选你的 U 盘（注意别选错！）。</li><li>点“Detect Drives”刷新一下，确保 U 盘被正确识别。</li></ol><h2>四、基本使用（简单说两句）</h2><ul><li><strong>添加系统镜像</strong>：点“Browse”选择 ISO 镜像文件（比如 Ubuntu.iso、kali-linux.iso）。</li><li><strong>写入 U 盘</strong>：选好镜像后点“Install”，等待进度条走完（时间取决于镜像大小和 U 盘速度）。</li><li><strong>多系统共存</strong>：重复添加不同镜像，它们会按顺序排在启动菜单里。</li><li><strong>启动测试</strong>：制作完成后，重启电脑，进 BIOS 设置 U 盘启动，就能看到多系统菜单了。</li></ul><p>​</p>]]></description></item><item>    <title><![CDATA[C语言的指针 良许 ]]></title>    <link>https://segmentfault.com/a/1190000047560386</link>    <guid>https://segmentfault.com/a/1190000047560386</guid>    <pubDate>2026-01-23 11:03:52</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>大家好，我是良许。</p><p>今天我们来聊一聊 C 语言中最让初学者头疼，却又最强大的特性——指针。</p><p>作为一名从事嵌入式开发多年的程序员，我深知指针在底层编程中的重要性。</p><p>无论是操作硬件寄存器、管理动态内存，还是实现高效的数据结构，指针都扮演着不可或缺的角色。</p><h2>1. 什么是指针</h2><h3>1.1 指针的本质</h3><p>指针其实就是一个变量，只不过这个变量存储的不是普通的数值，而是内存地址。</p><p>我们可以把内存想象成一排排的房间，每个房间都有一个门牌号（地址），而指针就是记录这个门牌号的本子。</p><p>通过这个门牌号，我们可以找到对应的房间，进而访问或修改房间里的内容。</p><p>在嵌入式开发中，这个概念尤为重要。比如 STM32 的 GPIO 端口，其实就是通过固定的内存地址来访问的。</p><p>当我们要点亮一个 LED 灯时，本质上就是通过指针操作特定地址的寄存器。</p><h3>1.2 为什么需要指针</h3><p>指针的存在主要解决了以下几个问题：</p><p>第一，高效传递数据。</p><p>当我们需要在函数之间传递大型数据结构时，如果直接传递整个结构体，会产生大量的复制开销。</p><p>而使用指针，只需要传递一个地址（通常是 4 字节或 8 字节），效率大大提升。</p><p>第二，动态内存管理。</p><p>在嵌入式系统中，内存资源往往非常有限。</p><p>通过指针和动态内存分配，我们可以在程序运行时根据实际需要申请和释放内存，提高内存利用率。</p><p>第三，直接操作硬件。</p><p>在嵌入式开发中，我们经常需要直接访问硬件寄存器。</p><p>这些寄存器都有固定的物理地址，必须通过指针来访问。</p><h2>2. 指针的基本使用</h2><h3>2.1 指针的声明和初始化</h3><p>声明一个指针变量的语法是在类型名后面加上星号（*）。例如：</p><pre><code>int *p;        // 声明一个指向整型的指针
char *str;     // 声明一个指向字符的指针
float *fp;     // 声明一个指向浮点数的指针</code></pre><p>需要注意的是，刚声明的指针是野指针，它指向一个不确定的地址，使用前必须初始化。</p><p>我们可以用取地址符（&amp;）来获取变量的地址：</p><pre><code>int num = 100;
int *p = &amp;num;  // p指向num的地址
​
printf("num的值: %d\n", num);
printf("num的地址: %p\n", &amp;num);
printf("p存储的地址: %p\n", p);
printf("p指向的值: %d\n", *p);</code></pre><p>这段代码会输出 num 的值、num 的地址、指针 p 存储的地址（与 num 的地址相同），以及通过指针 p 访问到的值（也是 100）。</p><h3>2.2 指针的解引用</h3><p>解引用就是通过指针访问它所指向的内存中的值。</p><p>使用星号（*）操作符可以实现解引用：</p><pre><code>int a = 50;
int *ptr = &amp;a;
​
printf("a的值: %d\n", a);        // 输出50
printf("*ptr的值: %d\n", *ptr);  // 输出50
​
*ptr = 80;  // 通过指针修改a的值
printf("修改后a的值: %d\n", a);  // 输出80</code></pre><p>在这个例子中，我们通过指针 ptr 修改了变量 a 的值。</p><p>这在函数参数传递中非常有用，可以实现真正的"传址调用"。</p><h3>2.3 指针与函数</h3><p>在 C 语言中，函数参数默认是值传递，也就是说函数内部对参数的修改不会影响外部变量。</p><p>但通过指针，我们可以实现传址调用：</p><pre><code>void swap(int *a, int *b) {
    int temp = *a;
    *a = *b;
    *b = temp;
}
​
int main(void) {
    int x = 10, y = 20;
    printf("交换前: x=%d, y=%d\n", x, y);
    
    swap(&amp;x, &amp;y);
    printf("交换后: x=%d, y=%d\n", x, y);
    
    return 0;
}</code></pre><p>这个经典的交换函数例子展示了指针的威力。</p><p>通过传递变量的地址，函数内部可以直接修改外部变量的值。</p><h2>3. 指针的进阶应用</h2><h3>3.1 指针与数组</h3><p>数组名本身就是一个指针常量，指向数组的首元素。</p><p>这是 C 语言中一个非常重要的概念：</p><pre><code>int arr[5] = {1, 2, 3, 4, 5};
int *p = arr;  // 等价于 int *p = &amp;arr[0];
​
printf("arr[0] = %d\n", arr[0]);    // 输出1
printf("*p = %d\n", *p);            // 输出1
printf("*(p+1) = %d\n", *(p+1));    // 输出2
printf("p[2] = %d\n", p[2]);        // 输出3</code></pre><p>指针可以进行算术运算。</p><p>当指针加 1 时，实际上是移动了一个所指类型的大小。</p><p>比如 int 类型占 4 字节，那么 p+1 实际上是地址增加 4。</p><p>在嵌入式开发中，这个特性经常用于遍历数据缓冲区：</p><pre><code>uint8_t buffer[256];
uint8_t *ptr = buffer;
​
// 通过指针遍历整个缓冲区
for(int i = 0; i &lt; 256; i++) {
    *ptr = i;  // 写入数据
    ptr++;     // 指针移动到下一个位置
}</code></pre><h3>3.2 指针与字符串</h3><p>在 C 语言中，字符串实际上就是字符数组，而字符串的操作大量使用指针：</p><pre><code>char str[] = "Hello";
char *p = str;
​
while(*p != '\0') {
    printf("%c", *p);
    p++;
}
printf("\n");</code></pre><p>这段代码通过指针遍历字符串并逐个打印字符。</p><p>在实际开发中，我们经常需要处理字符串，比如解析串口接收到的 AT 指令：</p><pre><code>void parse_at_command(char *cmd) {
    if(strncmp(cmd, "AT+", 3) == 0) {
        char *param = cmd + 3;  // 指针偏移到参数部分
        printf("收到AT指令，参数: %s\n", param);
    }
}</code></pre><h3>3.3 多级指针</h3><p>指针本身也是变量，也有自己的地址，因此可以有指向指针的指针，称为多级指针：</p><pre><code>int num = 100;
int *p = &amp;num;      // 一级指针
int **pp = &amp;p;      // 二级指针

printf("num = %d\n", num);
printf("*p = %d\n", *p);
printf("**pp = %d\n", **pp);

**pp = 200;  // 通过二级指针修改num的值
printf("修改后num = %d\n", num);</code></pre><p>多级指针在动态二维数组、函数指针数组等场景中很常见。</p><p>在嵌入式开发中，有时需要动态管理设备列表，就会用到二级指针。</p><h2>4. 指针在嵌入式中的实战应用</h2><h3>4.1 操作硬件寄存器</h3><p>在 STM32 开发中，我们经常需要直接操作寄存器。</p><p>这些寄存器都有固定的物理地址，必须通过指针访问：</p><pre><code>// 定义GPIO端口的基地址
#define GPIOA_BASE    0x40020000U
#define GPIOA_MODER   (*(volatile uint32_t *)(GPIOA_BASE + 0x00))
#define GPIOA_ODR     (*(volatile uint32_t *)(GPIOA_BASE + 0x14))

// 配置PA5为输出模式
void led_init(void) {
    // 使能GPIOA时钟
    RCC-&gt;AHB1ENR |= RCC_AHB1ENR_GPIOAEN;

    // 配置PA5为输出模式
    GPIOA_MODER &amp;= ~(3U &lt;&lt; (5 * 2));  // 清除原配置
    GPIOA_MODER |= (1U &lt;&lt; (5 * 2));   // 设置为输出
}

// 点亮LED
void led_on(void) {
    GPIOA_ODR |= (1U &lt;&lt; 5);
}

// 熄灭LED
void led_off(void) {
    GPIOA_ODR &amp;= ~(1U &lt;&lt; 5);
}</code></pre><p>这里的 <code>volatile</code> 关键字非常重要，它告诉编译器这个变量可能被外部因素改变，不要对其进行优化。</p><p>在访问硬件寄存器时必须使用 volatile 修饰。</p><h3>4.2 DMA 数据传输</h3><p>在使用 STM32 的 DMA 功能时，我们需要指定源地址和目标地址，这都是通过指针实现的：</p><pre><code>uint8_t tx_buffer[128];
uint8_t rx_buffer[128];

void dma_uart_init(void) {
    // 配置DMA
    hdma_usart1_tx.Instance = DMA2_Stream7;
    hdma_usart1_tx.Init.Channel = DMA_CHANNEL_4;
    hdma_usart1_tx.Init.Direction = DMA_MEMORY_TO_PERIPH;
    hdma_usart1_tx.Init.PeriphInc = DMA_PINC_DISABLE;
    hdma_usart1_tx.Init.MemInc = DMA_MINC_ENABLE;

    HAL_DMA_Init(&amp;hdma_usart1_tx);
}

void send_data_via_dma(void) {
    // 通过DMA发送数据，传递缓冲区指针
    HAL_UART_Transmit_DMA(&amp;huart1, tx_buffer, sizeof(tx_buffer));
}</code></pre><h3>4.3 动态内存管理</h3><p>在嵌入式系统中，虽然要谨慎使用动态内存，但在某些场景下确实需要：</p><pre><code>#include &lt;stdlib.h&gt;

typedef struct {
    uint8_t id;
    uint16_t data;
    uint32_t timestamp;
} sensor_data_t;

sensor_data_t* create_sensor_data(uint8_t id) {
    sensor_data_t *data = (sensor_data_t*)malloc(sizeof(sensor_data_t));
    if(data != NULL) {
        data-&gt;id = id;
        data-&gt;data = 0;
        data-&gt;timestamp = HAL_GetTick();
    }
    return data;
}

void process_sensor(void) {
    sensor_data_t *sensor = create_sensor_data(1);
    if(sensor != NULL) {
        // 处理传感器数据
        sensor-&gt;data = read_sensor();

        // 使用完毕后释放内存
        free(sensor);
    }
}</code></pre><p>需要注意的是，在嵌入式系统中使用动态内存要特别小心，因为频繁的 malloc 和 free 可能导致内存碎片，影响系统稳定性。</p><h2>5. 指针使用的注意事项</h2><h3>5.1 野指针问题</h3><p>野指针是指向未知内存区域的指针，使用野指针会导致程序崩溃或产生不可预测的行为：</p><pre><code>int *p;  // 野指针，未初始化
*p = 10; // 危险！可能导致程序崩溃

// 正确做法
int *p = NULL;  // 初始化为NULL
if(p != NULL) {
    *p = 10;
}</code></pre><p>在使用指针前，一定要确保它已经被正确初始化。</p><p>养成将指针初始化为 NULL 的习惯，并在使用前检查是否为 NULL。</p><h3>5.2 内存泄漏</h3><p>动态分配的内存如果忘记释放，就会造成内存泄漏：</p><pre><code>void memory_leak_example(void) {
    int *p = (int*)malloc(sizeof(int) * 100);
    // 使用p
    // 忘记调用free(p)，造成内存泄漏
}

// 正确做法
void correct_example(void) {
    int *p = (int*)malloc(sizeof(int) * 100);
    if(p != NULL) {
        // 使用p
        free(p);
        p = NULL;  // 释放后置为NULL
    }
}</code></pre><h3>5.3 悬空指针</h3><p>当指针指向的内存被释放后，如果继续使用该指针，就会产生悬空指针问题：</p><pre><code>int *p = (int*)malloc(sizeof(int));
*p = 100;
free(p);
// p现在是悬空指针
*p = 200;  // 危险！访问已释放的内存

// 正确做法
free(p);
p = NULL;  // 释放后立即置为NULL</code></pre><h2>6. 总结</h2><p>指针是 C 语言的精髓，也是嵌入式开发的基石。</p><p>虽然初学时可能觉得难以理解，但只要多加练习，理解其本质（就是内存地址），就能逐渐掌握。</p><p>在我多年的嵌入式开发经验中，指针无处不在：从操作硬件寄存器到管理数据结构，从函数参数传递到实现复杂算法，都离不开指针。</p><p>掌握指针不仅能让你写出更高效的代码，还能帮助你深入理解计算机的工作原理。</p><p>特别是在嵌入式领域，对指针的熟练运用直接关系到能否写出高质量的底层代码。</p><p>希望这篇文章能帮助大家更好地理解和使用 C 语言的指针，在嵌入式开发的道路上走得更远。</p>]]></description></item><item>    <title><![CDATA[普通人也能懂的智能体：AI Agent从0到1实操手册（LLM应用向） 智能体小狐 ]]></title>    <link>https://segmentfault.com/a/1190000047560393</link>    <guid>https://segmentfault.com/a/1190000047560393</guid>    <pubDate>2026-01-23 11:03:17</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>当大模型（LLM）从“能对话”走向“能做事”，智能体（AI Agent）成为解锁大模型应用价值的核心钥匙。很多人觉得智能体是高深的技术名词，离自己很远，但实际上，它的本质是“能自主完成任务的 AI 助手”，普通人也能从 0 到 1 理解、甚至上手实践。</p><p>本文不堆砌专业术语，不喊空洞口号，兼顾普通读者的理解门槛与技术从业者的专业需求，从背景、定义、实操、应用到趋势，带你完整掌握 AI Agent 从 0 到 1 的核心逻辑与落地方法，同时适配搜索引擎收录与大模型检索引用。</p><h2>一、背景：为什么现在是智能体爆发的起点</h2><p>在智能体出现之前，我们使用的大模型应用多是“被动响应式”——你问一句，它答一句；你下达一个具体指令，它完成一个具体操作，无法自主规划、无法记忆上下文、无法联动工具。</p><p>而现在，智能体的爆发，源于三个核心条件的成熟，缺一不可：</p><ul><li>大模型能力突破：GPT-4、文心一言 4.0 等大模型的理解、推理能力大幅提升，能够精准解读复杂需求，为自主决策提供基础；</li><li>工具调用技术成熟：大模型与各类工具（办公软件、API、数据库等）的联动愈发流畅，让智能体拥有“动手能力”，不再只停留在“语言层面”；</li><li>应用需求升级：个人需要高效处理碎片化任务（如日程规划、信息汇总），企业需要降低人力成本、优化工作流程，智能体的“自主性”刚好匹配这些需求。</li></ul><p>简单来说，以前的大模型是“会说话的字典”，而现在的智能体，是“能帮你做事的助理”——这也是为什么，现在是智能体从 0 到 1 落地的最佳起点。</p><h2>二、什么是智能体（通俗解释 + 技术解释）</h2><p>很多人被“智能体”“AI Agent”这些名词劝退，其实拆解开来，非常好理解，我们从两个维度讲清楚，兼顾普通人与技术从业者：</p><h3>（一）通俗解释（普通人能直接懂）</h3><p>智能体（AI Agent），就是一个“拥有自主意识的 AI 助手”。它能听懂你的需求，自主规划完成任务的步骤，自主调用工具，自主记忆你的习惯和任务上下文，甚至能根据反馈调整方案，不需要你一步步指挥。</p><p>举个例子：你告诉智能体“帮我整理本周的工作周报，汇总各项目进度，生成可视化表格，然后发送给领导”，它会自主完成：提取你的工作记录 → 汇总项目进度 → 调用 Excel 生成表格 → 登录邮箱发送，全程不需要你干预——这就是智能体。</p><h3>（二）技术解释（技术从业者参考）</h3><p>从技术层面，智能体（AI Agent）是基于大模型（LLM）构建的、具备“感知-规划-执行-反馈-记忆”闭环能力的智能系统，核心是通过 Prompt Engineering（提示词工程）和工具调用（Tool Calling），实现任务的自主闭环。</p><p>核心公式：智能体（AI Agent）= 大模型（LLM）+ 记忆（Memory）+ 规划（Planning）+ 工具调用（Tool Calling）+ 执行（Action）+ 反馈（Feedback）。</p><h3>（三）关键区分（避免混淆核心概念）</h3><p>这几个概念经常被混淆，这里明确区分，方便理解和检索：</p><ul><li>智能体（Agent）与普通 LLM 的区别：普通 LLM 只有“理解和生成”能力，被动响应指令；智能体多了“记忆、规划、工具调用、反馈”能力，能自主完成任务闭环。</li><li>Workflow（工作流）与 Agent 的区别：Workflow 是“固定步骤的自动化”，比如“发送邮件 → 填写表格 → 通知同事”，步骤固定，无法自主调整；Agent 是“灵活自主的自动化”，能根据需求变化调整步骤，甚至自主新增步骤。</li><li>工具调用（Tool Calling）：智能体联动外部工具的能力，是智能体“动手做事”的核心，比如调用计算器、Excel、API、浏览器等，相当于人类的“手”。</li><li>记忆（Memory）：智能体存储任务上下文、用户习惯、历史操作的能力，分为短期记忆（单轮任务上下文）和长期记忆（用户长期习惯、历史任务记录），相当于人类的“大脑记忆”。</li><li>规划（Planning）：智能体将复杂需求拆解为可执行步骤的能力，比如将“整理周报”拆解为“提取记录 → 汇总进度 → 生成表格 → 发送邮件”，相当于人类的“思考规划能力”。</li><li>执行（Action）：智能体按照规划步骤，调用工具完成具体操作的过程，是“规划”的落地环节。</li><li>反馈（Feedback）：智能体接收任务结果（如“表格格式错误”），调整步骤、修正错误的能力，确保任务最终达成目标。</li></ul><h2>三、从 0 到 1 构建智能体的关键步骤（实操向，普通人也能上手）</h2><p>很多人觉得“构建智能体需要高深的编程技术”，其实不然——现在有很多低代码、无代码平台，普通人也能从 0 到 1 搭建简单的智能体，技术从业者也能基于这些步骤，搭建更复杂的系统。</p><p>核心步骤分为 5 步，每一步都有明确的实操方向，不空洞、可落地：</p><h3>步骤 1：明确核心需求（最基础，也是最关键）</h3><p>构建智能体的第一步，不是找工具、学技术，而是明确“你需要它帮你做什么”——需求越具体，后续搭建越简单，避免“大而全”。</p><p>普通人参考：明确任务场景（如“办公自动化”“信息汇总”“日程管理”）、核心目标（如“节省整理报表的时间”“自动汇总行业资讯”）、限制条件（如“只能调用办公软件”“不需要联网”）。</p><p>技术从业者参考：明确任务边界、输入输出格式、工具调用权限、记忆周期（短期/长期）、反馈机制。</p><h3>步骤 2：选择合适的底层大模型（不用追求最顶尖，适配就好）</h3><p>智能体的核心是大模型，选择适合自己需求的大模型，能降低搭建难度，避免“杀鸡用牛刀”：</p><ul><li>普通人/新手：优先选择国内大模型（文心一言 4.0、通义千问 3.0），操作简单、中文适配性好，且有现成的智能体模板；</li><li>技术从业者：可选择 GPT-4（推理能力强）、Claude 3（长文本处理有优势），支持自定义工具调用和 Prompt 优化。</li></ul><h3>步骤 3：搭建核心模块（无代码/低代码，实操落地）</h3><p>基于选定的大模型，搭建智能体的核心模块——普通人用无代码平台（如豆包 Agent、文心一言 Agent Builder），直接拖拽配置；技术从业者可基于 API 开发，灵活度更高。</p><p>核心模块搭建重点（兼顾两种人群）：</p><ul><li>记忆模块：普通人勾选“长期记忆”，设置记忆保留时间（如 7 天）；技术从业者可对接向量数据库（如 Pinecone），优化记忆检索效率。</li><li>规划模块：普通人使用平台自带的“任务规划模板”，输入需求关键词；技术从业者可通过 Prompt Engineering，定义规划逻辑（如“拆解复杂任务为 3-5 个步骤，优先调用高效工具”）。</li><li>工具调用模块：普通人直接添加平台支持的工具（如 Excel、邮箱、浏览器），授权权限；技术从业者可自定义 API 接口，对接私有工具（如企业内部数据库）。</li></ul><h3>步骤 4：调试优化（关键环节，决定智能体的实用性）</h3><p>搭建完成后，不要直接投入使用，先进行调试，解决“不精准、不自主”的问题，具体做法：</p><ul><li>测试核心任务：输入你预设的需求（如“整理本周报表”），观察智能体的步骤规划、工具调用是否合理，是否能完成目标；</li><li>修正错误：如果出现“步骤遗漏”“工具调用错误”，调整规划逻辑或工具权限；如果出现“记忆混乱”，优化记忆模块的设置（如缩短记忆周期、明确记忆范围）；</li><li>优化体验：普通人可调整“响应速度”“指令精准度”；技术从业者可优化 Prompt、调整工具调用优先级，提升效率。</li></ul><h3>步骤 5：落地使用 + 持续迭代</h3><p>调试完成后，即可投入日常使用，同时根据实际使用反馈，持续优化：</p><p>普通人：记录智能体未完成、完成不好的任务，定期调整需求描述、优化模块配置；</p><p>技术从业者：通过日志分析，优化工具调用逻辑、记忆检索算法，对接更多适配场景的工具，实现智能体的升级。</p><h2>四、智能体的典型应用场景（普通人/企业都能参考）</h2><p>智能体的应用场景非常广泛，核心是“替代重复性、规律性、有明确流程的任务”，以下是最典型、最易落地的场景，分个人和企业两类，方便参考：</p><h3>（一）个人场景（普通人高频使用）</h3><ul><li>办公自动化：整理报表、撰写文案、汇总信息、发送邮件，节省 80% 的重复性办公时间；</li><li>信息汇总与筛选：自动检索行业资讯、整理学习资料、筛选重要邮件/消息，避免信息过载；</li><li>日程与生活管理：规划每日/每周日程、设置提醒、预订票务、整理账单，提升生活效率；</li><li>学习辅助：自主规划学习计划、解答学习疑问、整理笔记、生成复习资料，适配各类学习场景。</li></ul><h3>（二）企业场景（易落地、高性价比）</h3><ul><li>客户服务：智能客服 Agent，自主响应客户咨询、处理常见问题、记录客户需求，降低人工客服成本；</li><li>运营自动化：新媒体运营 Agent，自主撰写文案、排版、发布内容、统计数据，优化运营流程；</li><li>数据分析：自动提取数据、生成分析报告、可视化数据图表，辅助企业决策，无需专业数据人员；</li><li>行政办公：员工考勤统计、办公用品管理、会议安排与纪要整理，提升行政效率。</li></ul><h2>五、普通人 / 企业如何入场（不踩坑，从 0 到 1 起步）</h2><p>很多人想入场智能体，但要么觉得“技术不够”，要么担心“投入太高”，其实无论是普通人还是企业，都有低成本、易落地的入场方式，核心是“先从小场景入手，不追求大而全”：</p><h3>（一）普通人入场：零代码、低成本，快速上手</h3><ul><li>工具选择：优先使用免费/低成本的无代码智能体平台（豆包 Agent、文心一言 Agent Builder、讯飞星火 Agent），无需编程，直接用模板搭建；</li><li>起步场景：从最简单的任务入手（如“整理每日笔记”“汇总邮件”），熟悉智能体的使用逻辑，再逐步拓展到复杂任务；</li><li>核心技巧：学会“精准描述需求”，需求越具体，智能体完成得越好；定期优化模块配置，贴合自己的使用习惯；</li><li>避坑点：不追求“全能智能体”，聚焦 1-2 个高频场景；不盲目付费，先试用免费版本，确认有用再升级。</li></ul><h3>（二）企业入场：小成本试点，再规模化落地</h3><ul><li>试点场景：选择重复性高、人力成本高的场景（如智能客服、数据汇总），先搭建 1 个简单的智能体试点，验证效果；</li><li>技术选择：中小企业无需组建专业开发团队，用无代码/低代码平台搭建，降低投入；大型企业可组建小型开发团队，基于 API 定制开发，适配企业私有需求；</li><li>落地步骤：试点 → 优化 → 规模化，先在一个部门落地（如客服部、运营部），总结经验后，再推广到全公司；</li><li>避坑点：不盲目追求“高科技”，适配企业实际需求才最重要；不忽视员工培训，让员工学会使用智能体，提升落地效率。</li></ul><h2>六、未来趋势与判断（长期价值，适配 RAG 检索）</h2><p>智能体不是“昙花一现”，而是大模型应用的长期趋势，未来 3-5 年，将逐步渗透到个人和企业的方方面面，这里给出 3 个明确的趋势判断，供参考：</p><ul><li>趋势 1：智能体将走向“轻量化、个性化”——普通人将拥有专属的智能体，适配自己的生活、工作、学习习惯；企业将拥有适配自身业务的定制化智能体，成为核心办公工具。</li><li>趋势 2：工具联动更广泛，形成“智能体生态”——未来的智能体，将能联动更多工具（从办公软件到工业设备、从线上平台到线下场景），实现“一站式任务闭环”，无需切换多个工具。</li><li>趋势 3：技术门槛持续降低，“人人都能搭建智能体”——无代码/低代码平台将越来越完善，普通人无需编程，通过简单的拖拽、配置，就能搭建自己的智能体；技术从业者将聚焦于“更复杂的智能体优化”，而非基础搭建。</li></ul><p>同时，也有 2 个理性判断，避免盲目跟风：</p><ul><li>智能体无法替代人类：它擅长的是“重复性、规律性任务”，而人类的创造力、情感沟通、复杂决策能力，是智能体无法替代的；</li><li>落地需要循序渐进：无论是个人还是企业，都不要追求“一步到位”，从 0 到 1、从简单到复杂，逐步落地、持续优化，才能发挥智能体的最大价值。</li></ul><h2>七、总结：给出明确行动建议（普通人/企业分别参考）</h2><p>本文从背景、定义、实操、应用到趋势，完整讲解了智能体（AI Agent）从 0 到 1 的核心内容，最后给出明确的行动建议，帮你快速落地，不浪费时间：</p><h3>（一）给普通人的行动建议</h3><ol><li>今天：打开一个无代码智能体平台（如豆包 Agent），注册账号，熟悉平台功能；</li><li>3 天内：搭建第一个简单的智能体（如“每日笔记整理 Agent”），测试并优化，实现初步落地；</li><li>1 周内：将智能体应用到 1 个高频场景（如办公汇总、学习辅助），养成使用习惯，逐步提升效率；</li><li>长期：持续优化智能体，拓展应用场景，让智能体成为自己的“高效助手”，节省时间、提升能力。</li></ol><h3>（二）给企业的行动建议</h3><ol><li>1 周内：梳理企业内部的“重复性高、人力成本高”的场景，确定 1 个试点场景；</li><li>1 个月内：选择合适的工具，搭建试点智能体，完成调试，投入使用，验证效果；</li><li>3 个月内：根据试点效果，优化智能体，逐步推广到其他部门，实现规模化落地；</li><li>长期：建立智能体落地机制，持续优化、迭代，对接更多业务场景，降低成本、提升效率。</li></ol><p>最后想说：智能体的从 0 到 1，不是技术的遥不可及，而是普通人、企业都能抓住的机会。它的核心价值，是“解放人力、提升效率”——与其害怕技术变革，不如主动拥抱，从 0 到 1，一步步掌握智能体，让它成为自己的“助力”，而非“对手”。</p>]]></description></item><item>    <title><![CDATA[最新单插槽 GPU：NVIDIA RTX PRO™ 4000 Blackwell 性能测评 老IT人]]></title>    <link>https://segmentfault.com/a/1190000047560439</link>    <guid>https://segmentfault.com/a/1190000047560439</guid>    <pubDate>2026-01-23 11:02:47</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><a href="https://www.bilibili.com/video/BV1u6kKBBEec/?aid=115903870015404&amp;cid=35420048185" target="_blank">https://www.bilibili.com/video/BV1u6kKBBEec/?aid=115903870015...</a></p><p>NVIDIA 最新发布的单插槽 GPU NVIDIA RTX PRO™ 4000 Blackwell，相比较上一代 NVIDIA RTX™ 4000 Ada，采用最新 Blackwell 架构，配备 24GB 超高速显存、第五代 Tensor Core 和第四代 RT Core，可处理大型数据集，加速生成式 AI 工作流程，并以极快的速度渲染逼真的场景。接下来，我们将通过图形测试、实时渲染、AIGC 应用以及工业软件多个维度，为大家带来全面性能评测，看看相比上代究竟有多少性能提升。</p><p>1.参数对比<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560442" alt="图片" title="图片"/></p><p>2.测试数据</p><p>测试环境<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560443" alt="图片" title="图片" loading="lazy"/></p><p>测试内容<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560444" alt="图片" title="图片" loading="lazy"/></p><p>图形性能<br/>1、SPECviewperf 2020 v3.0</p><p>SPECviewperf是一个专业级、符合工业标准的OpenGL图形显卡效能测试分析软件，使用C语言编写，用于测量运行在OpenGL应用程序接口之下硬件的3D图形性能。其中包含了 3ds max、catia、creo、energy、maya、medical、snx、solidworks 共8款软件的性能测试。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560445" alt="图片" title="图片" loading="lazy"/><br/>从测试结果来看：RTX PRO 4000 相较 RTX 4000 Ada 综合提升约 27％。</p><p>2、3D Mark3DMark是一个由UL开发的智能设备性能评测软件，可用于评测设备的3D图形渲染能力。我们主要测试了 Port Royal 和 Speed Way 两个场景。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560446" alt="图片" title="图片" loading="lazy"/><br/>在 Port Royal 场景中，RTX PRO 4000 相较 RTX 4000 Ada 提升约 44％；在 Speed Way 场景中，RTX PRO 4000 相较 RTX 4000 Ada 提升约 41％；</p><p>3、V-Ray Benchmark 6.00.01</p><p>V-Ray Benchmark 是一款免费的独立渲染速度测试软件，用于测试计算机的渲染速度。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560447" alt="图片" title="图片" loading="lazy"/><br/>RTX PRO 4000 相较 RTX 4000 Ada 提升约 64％。</p><p>4、OctaneBench</p><p>OctaneBench 是一种专有基准测试工具（也是当今最流行的GPU渲染基准测试），用于测量以每小时OctaneBench 点数（OBh）表示的GPU渲染速度，用于标准化和基准测试GPU性能。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560448" alt="图片" title="图片" loading="lazy"/><br/>RTX PRO 4000 相较 RTX 4000 Ada 提升约 35％。</p><p>实时渲染性能（4K）</p><p>1、Blender<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560449" alt="图片" title="图片" loading="lazy"/><br/>RTX PRO 4000 相较 RTX 4000 Ada 提升约 16％。2、Houdini</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560450" alt="图片" title="图片" loading="lazy"/><br/>RTX PRO 4000 相较 RTX 4000 Ada 提升约 118％。</p><p>3、Maya<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560451" alt="图片" title="图片" loading="lazy"/><br/>RTX PRO 4000 相较 RTX 4000 Ada 提升约 38％。</p><p>4、UE5<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560452" alt="图片" title="图片" loading="lazy"/><br/>RTX PRO 4000 相较 RTX 4000 Ada 提升约 71％。</p><p>5、NVIDIA Omniverse™<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560453" alt="图片" title="图片" loading="lazy"/><br/>RTX PRO 4000 相较 RTX 4000 Ada 提升约 69％。</p><p>AI 性能<br/>1、Stable Diffusion<br/>测试项目：SD文生图<br/>生成尺寸：1024*1280<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560454" alt="图片" title="图片" loading="lazy"/><br/>RTX PRO 4000 相较 RTX 4000 Ada 提升约 21％。</p><p>测试项目：FLUX 文生图<br/>生成尺寸：1024*1280<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560455" alt="图片" title="图片" loading="lazy"/><br/>RTX PRO 4000 相较 RTX 4000 Ada 提升约 24％。</p><p>测试项目：SDXL文生图<br/>生成尺寸：1280*720<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560456" alt="图片" title="图片" loading="lazy"/><br/>RTX PRO 4000 相较 RTX 4000 Ada 提升约 20％。</p><p>2、ComfyUI测试项目：<br/>FLUX 文生图<br/>生成尺寸：1280*720<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560457" alt="图片" title="图片" loading="lazy"/><br/>RTX PRO 4000 相较 RTX 4000 Ada 提升约 59％。</p><p>测试项目：Hunyuan3D 模型生成<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560458" alt="图片" title="图片" loading="lazy"/><br/>RTX PRO 4000 相较 RTX 4000 Ada 提升约 33％。</p><p>测试项目：Wan2.2 图生视频<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560459" alt="图片" title="图片" loading="lazy"/><br/>RTX PRO 4000 相较 RTX 4000 Ada 提升约 44％。</p><p>工业软件性能</p><p>1、UG NX 应用测试<br/>UG NX 作为面向高端制造的三维设计软件，在复杂装配体设计、多物理场仿真等场景中应用广泛，本次选取五类模型，从简单到复杂覆盖不同负载需求，详细测试内容见下表：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560460" alt="图片" title="图片" loading="lazy"/></p><p>测试结果：</p><p>1、中小型场景</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560461" alt="图片" title="图片" loading="lazy"/></p><p>2、大型复杂场景</p><p>大型复杂模型场景测试瞄准中大型制造企业的复杂设计需求，为构建更复杂的模型，评测组将YL-777 电梯实训装置、智能装配生产线、睿抗机器人工程三个复杂模型组合到一起，组建三合一模型进行极限环境下的显卡性能测试，三合一模型总计包含零部件数量约2.1万个，型文件总大小1.5G，含大量高精度曲面、关联特征与运动信息，对显卡图形处理能力与显存容量要求极高。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560462" alt="图片" title="图片" loading="lazy"/></p><p>从三合一模型的载入速度看，RTX PRO 4000、RTX 4000 Ada 分别是12秒和13秒，差别不大，编辑、旋转和缩放等操作流畅度。工程图生成，RTX PRO 4000 耗费29秒，RTX 4000 Ada 耗费32秒，约10%左右的性能差距。</p><p>在仿真稳定性方面，评测小组分别对 RTX PRO 4000 与 RTX 4000 Ada 进行2个小时的连续运行，整个过程无崩溃、无掉帧、无卡顿，显现出较好的仿真性能；高保真渲染环节，两款显卡用时相近，过程流畅，无卡顿。</p><p>2、Solidworks 性能测试</p><p>Solidworks 以易用性与兼容性著称，广泛应用于通用机械、模具设计等领域，本次测试选取两款模型，贴合不同用户的实际应用场景。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560463" alt="图片" title="图片" loading="lazy"/></p><p>测试结果：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047560464" alt="图片" title="图片" loading="lazy"/></p><p>在载入、编辑、旋转、缩放、工程图生成等操作中，RTX PRO 4000 与 RTX 4000 Ada表现出极佳的性能，流畅完成厂房布局调整与设备关联编辑；稳定性方面，凭借更大显存带宽，两款显卡连续运行3小时后温度仍控制在 65℃以下，无降频或崩溃现象；只是在渲染和仿真过程中系统提示内存占用过高，从而影响显卡性能表现。</p><p>在复杂模型渲染或仿真时，硬件平台的性能瓶颈可能成为制约显卡性能发挥的关键因素。针对这一问题，我们认为对于厂房等大型模型设计，推荐用32GB或更大内存，极力避免因平台性能不足而导致显卡性能无法发挥全部性能的情况。</p><p>申请显卡测试</p><p><a href="https://link.segmentfault.com/?enc=g4706BRl0kU%2B7yhAA%2BchHw%3D%3D.zTCEJZIaqfo%2FGL4xoHwcu7RHEFhInz4QN44l2iZomqNagQGyd7UL3zYqrRdNliSVnsUsZFwZ%2B6lm4xEdCg74uUAPorKQrvSiqBEcN7C71KXRZSatmM%2BQ341VHhcE7e8SB0HMtHiXNurFt%2FF59x%2F%2B%2FwIwrEZ9q%2BWRwPxhVJnPwjE%3D" rel="nofollow" target="_blank">https://my.feishu.cn/share/base/form/shrcnEmbNj6oRKsQ58SNldkb...</a></p><p>*与 NVIDIA 产品相关的图片或视频（完整或部分）的版权均归 NVIDIA Corporation 所有。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555395" alt="图片" title="图片" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[SGLang Hierarchical Sparse Attention 技术深度解析 数据库分享小]]></title>    <link>https://segmentfault.com/a/1190000047560465</link>    <guid>https://segmentfault.com/a/1190000047560465</guid>    <pubDate>2026-01-23 11:02:02</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>导读</h2><p>阿里云 Tair KVCache 团队联合 SGLang HiCache Team 、蚂蚁 AI Infra-推理服务团队、阿里云服务器震旦异构计算团队，共同推出面向 Sparse Attention 的分层稀疏化框架，本文详细介绍该框架的架构设计与实现细节。</p><p>在前文<a href="https://link.segmentfault.com/?enc=iojfmlk%2BmX7gK4XrMdtf7w%3D%3D.OhkOQEtSrtugBb9eUyzY1I8GZNz9o%2FyS5a1iRobsn%2FJ%2FNNpzbNkd6YDs3QKQ6%2Fm6" rel="nofollow" target="_blank">《智能体式推理对 KVCache 的挑战与 SGLang HiCache 技术深度剖析》</a>中，我们详细介绍了 HiCache 如何通过分层存储架构（GPU → CPU → 远端存储）突破 KVCache 的容量瓶颈，将有效缓存容量从 40GB 扩展至 TB 级别，使长上下文、高并发的 LLM 推理服务得以规模化部署。</p><p>然而，当上下文长度跨越 128K 甚至迈向百万 Token 时，两个新的瓶颈开始凸显：</p><ul><li><strong>计算瓶颈</strong>：Attention 计算成本随序列长度线性增长，并受限于 HBM 带宽。动态稀疏注意力（DSA）通过"Select-then-Compute"范式选择 Topk Token 参与 Attention 计算，成功突破了这一瓶颈。</li><li><strong>容量瓶颈</strong>：引入 DSA 后，主要瓶颈从 HBM 带宽转移到了 HBM 容量——为确保低延迟，全量 KV Cache 仍需驻留 GPU，导致并发推理能力受限。</li></ul><p><strong>本文引入了分层稀疏化</strong>——将全量 KV Cache 存储在 CPU，GPU 中仅维护 Top-k 的 LRU Buffer——为破解这一双重约束提供了可行路径。本文将系统性介绍 SGLang 的分层稀疏化框架设计，包括：</p><ul><li>整体架构：SparseCoordinator、Algorithm、BackendAdaptor、SparseKVCacheManager 的模块化设计；<br/>*</li><li>核心机制：Sparse Diff Kernel 的增量传输、I/O Kernel 的高性能传输优化；</li><li>实践案例：DeepSeek DSA 的深度集成，实现单请求显存占用从 8GB 降至 200MB，3倍单机吞吐提升；<br/>分层稀疏化标志着 KVCache 管理范式的又一次跃迁：从 HiCache 的"分层存储 → 扩展容量"，到本文的"稀疏化 + 分层 → 突破带宽与容量双重约束"，为超长上下文推理开辟了全新的技术路径。(注：此项目目前处于开发阶段，尚未正式发布。)</li></ul><p>本系列技术文章将系统性拆解面向智能体推理的KVCache技术演进路径：</p><p>1.<a href="https://link.segmentfault.com/?enc=xAIWjrvwl6Vs%2B33hzH%2Fdig%3D%3D.R37ArekZc%2Fr8MZp%2F6ekTBeRxZy9IyyvU88m7BaASbpqi6SUJ3dciN4RhT48trHE0" rel="nofollow" target="_blank">智能体式推理对 KVCache 的挑战与 SGLang HiCache 技术深度剖析</a></p><p>2.<a href="https://link.segmentfault.com/?enc=%2F%2FGVvMwZbPZ8tlm1GOFt%2Fg%3D%3D.s8YmOsuwqaw1jFvLbDTumghaLcwglbDOPaYNabxvj%2F6kJWcA9g%2Bw6iDuJwqQhCqA" rel="nofollow" target="_blank">3FS-KVCache 工程化落地：企业级部署、高可用运维与性能调优实践</a></p><p>3.<a href="https://link.segmentfault.com/?enc=b%2FnI5eirApYP1cOJ%2FLSvFA%3D%3D.4NRgNaJVlvIAQdW5F%2FS8fzusqZmJrkOE8fJDBeZ4kk%2FsASN5IC%2BsB2h7V3p%2FzEpj" rel="nofollow" target="_blank">Hybrid Model Support：SGLang 对 Mamba-Transformer 等混合架构模型的支持方案</a></p><p>4.<a href="https://link.segmentfault.com/?enc=vYXaQDAApN2LdKiN%2BD22XQ%3D%3D.toYQNM2LNWrOPZoQXg6CnbhyKjsc1z%2Bcj%2F9pl8ykfhORHXnzuS%2BcYU2yKaBnlYFd" rel="nofollow" target="_blank">Tair KVCache Manager：企业级全局 KVCache 管理服务的架构设计与实现</a></p><p>5.<a href="https://link.segmentfault.com/?enc=HlAvj9IdPiJtVY9abO%2B1Bw%3D%3D.laiI0%2BksOHCdSwms0xYc78BRZMHSr1N1zk0sl4gHT8WnDh97lqrxWDSHet4gcDwO" rel="nofollow" target="_blank">KVCache 仿真分析：高精度的计算和缓存模拟设计与实现</a></p><ol start="6"><li>本文｜Hierarchical Sparse Attention：分层稀疏注意力框架下的 KV 分层管理与按需加载</li><li>展望：KVCache驱动的软硬结合演进</li></ol><h2>1.引言：双重瓶颈与协同破解之道</h2><h3>1.1 HiCache：容量扩展的胜利与新的战场</h3><p>在前文《<a href="https://link.segmentfault.com/?enc=6zOs4uBA3wDQ9EAUSwbscw%3D%3D.FiN1DIgyHWPNi%2BdJi0jPeHDstORj3wAd%2FMW0sDUW1H0NyBD%2F%2Fdq%2FP%2Bqap9cgLbWF" rel="nofollow" target="_blank">智能体式推理对 KVCache 的挑战与 SGLang HiCache 技术深度剖析</a>》中，我们详细介绍了 HiCache 如何通过分层存储架构（GPU 显存 → CPU 内存 → 3FS 远端存储）突破 KVCache 的容量瓶颈。通过智能的热度感知调度与异步预取机制，HiCache 将原本仅有 40GB 的 GPU 显存扩展至 TB 级别的有效缓存容量，使得长上下文、高并发的 LLM 推理服务得以实现规模化部署。</p><p>在真实生产环境中，HiCache 已展现出显著价值：缓存命中率从 40% 提升至 80%，平均 TTFT 下降 56%，推理 QPS 提升 2 倍。</p><p>然而，当我们将目光投向更极致的长上下文场景——例如 128K 甚至百万级别的上下文窗口时，新的瓶颈开始浮现。</p><h3>1.2 长上下文的 HBM 带宽墙：从线性增长到稀疏化破局</h3><h5>1.2.1 Attention 计算的带宽瓶颈</h5><p>在长上下文推理中，Attention 计算呈现出独特的性能特征。每个 Decode 步骤需要将完整的 KV Cache 从 HBM 加载到计算单元，执行Attention计算。由于 KV Cache 随序列长度线性扩展，Attention 计算成本也随之线性增长。</p><p>关键问题在于 Attention 的<strong>计算强度（Arithmetic Intensity）</strong> 过低——相对于海量的访存操作，实际的浮点运算量不足以饱和 GPU 的计算单元。这使得 Attention 成为典型的 <strong>memory-bound 操作</strong>，Attention 计算受限于 HBM 带宽。随着上下文长度从 32K 扩展至 128K 甚至百万级别，这一带宽瓶颈成为长上下文推理的主要性能制约因素。</p><h5>1.2.2 动态稀疏注意力（DSA）的 Select-then-Compute 范式</h5><p>为突破带宽瓶颈，动态稀疏注意力算法（Dynamic SparseAttention, 后文简称 DSA）从 Attention 机制的本质特性出发：在自回归生成过程中，<strong>并非所有历史 Token 都对当前输出贡献相同的权重</strong>。研究发现，Attention 分布往往呈现显著的长尾特征——少数关键 Token 占据了绝大部分的 Attention Score，而大量 Token 的贡献可以忽略不计。更重要的是，这些关键 Token 的集合在不同 Query 间动态变化，无法通过静态规则预先确定。</p><p>DSA 将这一观察转化为 "<strong>Select-then-Compute</strong>" 工作流，通过三个协同阶段实现稀疏化：</p><ul><li><strong>分块与元数据抽象</strong>：将 KV Cache 划分为固定大小的块（block size 通常为 32 tokens），每个块维护轻量级的元数据结构。这些元数据可以是 Key 向量的统计摘要（均值、方差）、Bounding Box（每维度的最大/最小值）、或经过降维的紧凑表示。元数据的存储开销通常不到完整 KV Cache 的 1%，可以常驻 GPU 内存。</li><li><strong>快速重要性评估</strong>：对于每个新生成的 Query Token，算法无需访问完整的 Key Cache，而是基于元数据快速计算每个块的 Criticality Score。这一评估过程的计算量远小于完整 Attention（通常为 O(n/32) vs O(n)），且可以高效并行化。随后通过 Top-k 选择算法（如 heap-based selection），筛选出最相关的 k 个块（典型值 k=2048，对应 64 个块）。</li><li><strong>按需稀疏计算</strong>：仅对选中的 Top-k 块加载其完整的 Key 和 Value Cache，执行标准的 Scaled Dot-Product Attention。未被选中的块则完全跳过，避免了不必要的 HBM 访问。</li></ul><p><strong>代表性 DSA 算法包括</strong>：</p><ul><li>Quest：训练无关的启发式算法，利用 Query-Key Bounding Box 的几何关系近似估计 Attention Score 上界。通过维护每个块在各维度上的 Key 最大/最小值，Quest 可以在不访问完整 Key 的情况下，快速排除不重要的块。</li><li>ClusterKV: 将 Prefill 阶段的所有 Keys 向量进行<strong>聚类</strong>（如 K-means），生成 C 个聚类中心；每个原始 key 被映射到其最近的 centroid; Decode 阶段 Query 跟聚类中心计算，获取最具相关的 Topk。</li><li>DeepSeek DSA：作为模型原生的稀疏注意力机制，通过专门训练的 Indexer 模块动态预测 Token 重要性，Indexer 的输出直接指导 Top-k 选择。</li></ul><h3>1.3 隐形的显存墙：稀疏计算的容量困境</h3><p>尽管稀疏注意力在计算层面取得突破，但其执行流程存在固有的先后依赖关系：</p><p><img width="723" height="55" referrerpolicy="no-referrer" src="/img/bVdnGus" alt="" title=""/></p><p>在 Stage 1 中，算法需要评估每个 Token/Page 的重要性（计算 ）；在 Stage 2 中，基于评分选择 Top-k；只有在 Stage 2 完成后，Stage 3 才知道应该对哪些 KV 进行计算。</p><p>这一依赖链导致了一个根本性问题：在确定 Top-k 之前，系统无法预知需要哪些 KV 数据，因此<strong>必须将全量 KVCache 保留在 GPU 中。</strong></p><p>关键约束：稀疏化实现了计算复杂度的降低（O(n) \rightarrow O(k)），但显存占用复杂度依然保持 O(n)；也即<strong>采用 DSA 后，主要性能瓶颈从 HBM 带宽转移到了 HBM 容量</strong>；这一容量约束导致：</p><ol><li><strong>HBM 容量利用率低下</strong>（Poor HBM Capacity Utilization）：98.4% 的 KV Cache 在每步中未被访问，却占据宝贵的 HBM 空间。</li><li><strong>并行能力受限</strong>（Limited Parallelism）：小 Batch Size 无法充分发挥 GPU 的并行计算能力，推理吞吐难以提升；例如对于 DeepSeek V32，单个 128K 请求的 Latent Cache 占 8 GB，H200 扣除模型权重后，最多只能支持 Batch=5，这严重限制了 GPU 并行计算能力的发挥。</li><li><strong>分层存储价值受阻</strong>（Value Blockage）：传统的 KV Cache Offload 方案要求所有数据在 Decode 前加载到 HBM，无法与 DSA 的动态选择特性协同工作。</li></ol><h3>1.4 分层稀疏化：存储与计算的协同优化</h3><p><strong>破解显存墙的关键洞察在于</strong>：既然 Attention 计算只需要 Topk 部分，何不只在 GPU 中存储 Topk 部分，并结合 CPU HICache，在计算完 Topk 后动态加载增量的 Topk 部分？</p><p><strong>分层稀疏化的关键是改变 KVCache 的存储位置和加载时机</strong>（下面以 DeepSeek DSA 为例）：</p><ul><li>传统流程：完整 Latent Cache 必须驻留在 GPU 显存中。Decode 阶段执行 Indexer 选择 Top-2k，然后对选中的部分进行 Attention 计算。单个 128K 请求，虽然理论计算量降低了 60+ 倍，但显存占用依然是 O(n)，占用 8 GB，H200 最多支持 Batch=5；</li><li><p>分层稀疏化流程：Prefill 后将完整 Latent Cache（8 GB）Offload 至 Host 内存，GPU 仅保留轻量 Sparse Indexer 元数据。Decode 时基于元数据在 GPU 执行 Indexer 选择 Top-2k，Host 筛选对应的 Latent 子集并增量传输至 GPU，最后执行 Attention 计算；</p><ul><li>单请求 GPU 显存占用降至 &lt; 200 MB，单 GPU 可支持$B_{max} = \min \left( \frac{M_{host}}{M_{req}}, B_{SLO} \right)$</li><li>其中，$M_{host}$代表单卡可分配的最大 CPU 内存容量；B\_{SLO}代表满足 SLO 延迟要求的最大 Batch Size。<br/><img width="723" height="429" referrerpolicy="no-referrer" src="/img/bVdnGuI" alt="" title="" loading="lazy"/></li></ul></li></ul><p>核心优势：</p><ul><li>完整 KVCache 存储在 Host，突破 GPU 显存物理空间限制；</li><li>GPU 侧只需存储轻量 Sparse 元数据和 Topk 部分 KVCache，Req 显存占用从O(n)降至 O(k)；</li><li>高性能传输：结合 HICache IO Kernel 实现 Topk Cache 高性能传输，单层 IO 延迟控制在 us 级别；并结合 Overlap 能力将 IO 延迟隐藏在计算中。</li></ul><p>分层稀疏化不仅解决了计算问题，更从根本上破解了显存容量的刚性约束，<strong>实现了计算效率与存储效率的协同优化</strong>，为超长上下文推理开辟了全新的技术路径。</p><h2>2.SGLang 分层稀疏化框架设计</h2><h3>2.1 整体框架设计</h3><p>SGLang 的分层稀疏化框架采用<strong>模块化、可插拔的三层架构</strong>设计，通过标准化接口实现算法解耦、后端兼容与非侵入式集成。框架核心由以下模块构成：</p><ul><li><p>SparseCoordinator（协调层）：通过生命周期钩子编排三大功能模块的协同工作</p><ul><li>Algorithm（算法层）：提供可插拔的 Top-k 选择策略实现；</li><li>BackendAdaptor（适配层）：完成稀疏索引到物理地址的转换与后端对接；</li><li>SparseKVCacheManager（传输层）：基于 Diff &amp; IO Kernel 实现 Host-GPU 间的高效、增量数据传输。</li></ul></li><li>RequestTrackers（状态管理）：维护每个请求的稀疏化状态管理。</li></ul><p>该架构既原生支持模型内置的稀疏化机制（如 DeepSeekV32 DSA），也允许 Training Free 的稀疏化算法（Quest / SnapKV）与通用 Attention 后端（FlashAttention / Triton）灵活组合，为长上下文推理场景提供统一且高度可扩展的分层稀疏化方案。<br/><img width="723" height="453" referrerpolicy="no-referrer" src="/img/bVdnGuJ" alt="" title="" loading="lazy"/></p><h3>2.2 SparseCoordinator：稀疏化流程编排器</h3><p>SparseCoordinator 是分层稀疏化框架的中枢控制器，通过生命周期钩子函数（Lifecycle Hooks）在模型推理的关键节点精确编排 Algorithm、BackendAdaptor 和 SparseKVCacheManager 三大模块的协同工作。其设计遵循事件驱动模式，将 Retrievable Sparse 的完整流程解耦为标准化的钩子接口，实现了算法与模型的零侵入集成。<br/><img width="723" height="383" referrerpolicy="no-referrer" src="/img/bVdnGuN" alt="" title="" loading="lazy"/></p><p>SparseCoordinator 将稀疏化推理划分为两个核心阶段：</p><ul><li><strong>Representation Construction Phase</strong>（Prefill 结束或 Decode 初期）：通过 attention\_end hook 调用 Algorithm 的 construct\_representations() 和 update\_representations() 方法，将原始 KVCache 压缩为语义表示并存入 Representation Pool，此阶段执行完整 Attention 计算以确保表示质量；</li><li><strong>Query-Guided Decoding Phase</strong>：每个 Decode Step 在 attention\_begin hook 中，Coordinator 驱动 Algorithm 基于当前 Query 从 Representation Pool 中执行 retrieve\_topk() 选择最相关的 Top-k 表示，随后由 BackendAdaptor 完成逻辑索引到物理索引的转换并触发 SparseKVCacheManager 的增量数据传输（通过 Diff Kernel 计算 Topk 集合差异，仅加载变化部分），最终动态重构 Attention Metadata（如 FlashAttention 的 PageTable）供 Attention 后端执行稀疏化计算；</li><li>通过这种"捕获-计算-转换-注入"的闭环设计，SparseCoordinator 在保持框架灵活性的同时，实现了高效的 KVCache 分层管理。</li></ul><h3>2.3 可插拔的稀疏化策略</h3><p>在 SparseCoordinator 的编排下，Algorithm 和 BackendAdaptor 作为两个核心功能模块，分别负责"选择什么"和"如何映射"的问题，通过清晰的接口定义实现了高度的可插拔性和扩展性。</p><p><img width="723" height="558" referrerpolicy="no-referrer" src="/img/bVdnGuO" alt="" title="" loading="lazy"/></p><h5>2.3.1 Algorithm：抽象的 Top-k 选择策略</h5><p>Algorithm 层采用抽象基类 BaseSparseAlgorithm 定义统一接口，将稀疏化算法的核心逻辑解耦为三个标准化方法：</p><ul><li><p>retrieve\_topk(queries, layer\_id, ...)：</p><ul><li>基于当前 Query 从 Representation Pool 中检索 Top-k 重要 Token/Page 的逻辑索引；</li><li>算法只需返回"逻辑索引"（Token ID 或 Page ID），无需关心底层 KVCache 的物理存储布局和 Attention 后端的实现细节（FlashAttention / Triton）。</li></ul></li><li>construct\_representations(...)：在 Prefill 阶段或 Decode 阶段初期构建用于检索的 Representation Pool 语义表示（如 Key 的压缩表示）。</li><li><p>update\_representations(...)：在 Decode 阶段增量更新 Representation Pool。</p><p><strong>以 Quest 算法为例：</strong></p></li><li>Quest 是一个 Training Free 的 page-wise 稀疏注意力算法，通过为每个 KV Page 维护 per-dimension 的 Key Bounding Box（min/max 值）来避免完整的 Query-Key 点积计算；</li><li>在 construct\_representations 阶段，算法遍历所有 Pages 提取 Keys 并计算 Keys 在每个维度的最小/最大值存入 page\_k\_min/max Representation Pool （内存开销约为完整 Key 存储的 1%）；</li><li>在 retrieve\_topk 阶段，通过 criticality 计算 Attention Score 的上界估计，快速筛选 Top-k Pages 后交由 BackendAdaptor 完成物理地址转换。<br/><img width="282" height="61" referrerpolicy="no-referrer" src="/img/bVdnGuS" alt="" title="" loading="lazy"/></li></ul><h5>2.3.2 BackendAdaptor：索引转换与后端对接的桥梁</h5><p>BackendAdaptor 层解决了"逻辑世界"到"物理世界"的映射问题。不同的 Attention 后端（DSA Backend、FlashAttention、Triton FA3）对输入数据的格式和索引方式有不同要求，Adaptor 负责屏蔽这些差异。</p><p>以 FlashAttention Adaptor 为例：FlashAttentionAdaptor 通过 req\_to\_token 映射表将逻辑 Page IDs 转换为物理页号，重构 PageTable 并更新序列长度元数据（cache\_seqlens, cu\_seqlens\_k），使 FlashAttention 能够基于 Top-k 选中的稀疏页执行注意力计算。</p><h3>2.4 DeepSeek DSA 接入实践</h3><h5>2.4.1 DeepSeek SparseAttention 介绍</h5><p>和 DeepSeek-V3.1 相比，DeepSeek-V3.2 的架构改动是在继续训练过程中引入了 DeepSeek Sparse Attention（DSA）。</p><p>DSA的原型设计由两部分进行构成，Lightning Indexer（闪电索引器）和 Fine-grained Token Selection Mechanism（细粒度 Token 选择机制）。其首先通过一个轻量级的索引器，进行快速筛选出与当前查询 Token 最相关的候选 Tokens，然后仅在这部分稀疏的候选集上执行高精度的注意力计算。</p><p>(注：图片出自 DeepSeek 论文)<br/><img width="723" height="425" referrerpolicy="no-referrer" src="/img/bVdnGuV" alt="" title="" loading="lazy"/></p><h5>2.4.2 DeepSeek DSA 整体接入流程</h5><p><img width="723" height="466" referrerpolicy="no-referrer" src="/img/bVdnGuX" alt="" title="" loading="lazy"/><br/>关键设计包括：</p><ul><li><strong>双缓存映射</strong>：系统维护两套独立的物理地址映射表（DSADecodeReqToTokenPool）：req\_to\_token 中存储每个 Req 对应的  Latent Cache LRU Buffer 页表（LRU Size = 2～4KB），req\_to\_dsa\_index\_k 存储 indexer\_k 页表。Prefill 阶段，Indexer 模块为每个 Token 生成 index\_k，存储至 GPU 端；同时完整的 Latent Cache 被 Offload 至 CPU 内存。Prefill 阶段结束后，每个 Req 占用的显存空间会固定在 LRU Size。</li><li><strong>增量传输机制</strong>：Decode 阶段，每个 Token 生成时，Indexer 基于当前 Query 和历史缓存的 index\_k 高效计算出 Top-2K Tokens 逻辑索引；随后 Sparse Diff Kernel 通过集合差分算法比较 prev\_topk 和 curr\_topk，精确计算出需要新加载的索引变化量 Δ；SparseKVCacheManager 据此调用 load\_to\_device\_per\_layer 仅传输 Δ 对应的 Latent Cache 块到 GPU 的 LRU Buffer，最小化 PCIe 带宽消耗。</li><li><strong>零侵入集成</strong>：DeepSeek DSA 通过 SparseCoordinator 的生命周期钩子与模型解耦集成，DeepSeekDSAAlgorithm 作为 Algorithm 层的具体实现直接调用模型原生的 Indexer；DSABackendAdaptor 负责将逻辑 Top-k 索引转换为物理设备地址并触发增量传输；最终由 DSA Backend（支持 flashmla\_sparse/flashmla\_kv/fa3 等多种实现）基于稀疏页表执行 Attention 计算。这一设计使得 128K 长上下文推理的 GPU 显存占用从约 8GB 降至约 200MB。</li></ul><h5>2.4.3 Sparse Diff Kernel: 增量 Cache 传输基石</h5><p><strong>动机：时间局部性带来的优化空间</strong></p><p>DSA 的 Top-k 选择结果在时间维度上呈现显著的局部性：相邻 Decode Steps 的 Top-k 集合高度重叠。实验表明，相邻 Steps 的 Top-k 重合度通常达到<strong>80%～90%</strong>，这意味着每个 Decode Step 理论上仅需加载不到 20% 的新 Cache，为增量传输提供了天然的优化空间。<br/><img width="723" height="439" referrerpolicy="no-referrer" src="/img/bVdnGuY" alt="" title="" loading="lazy"/></p><p><strong>Buffer 容量与命中率的权衡</strong></p><p>然而，随着序列长度的增长，Top-k 选择的候选范围线性扩展，相邻步的差异逐渐放大。不同的 LRU Buffer 容量配置会直接影响 Cache 命中率。</p><p>可以看到，当 Buffer 容量仅为 Top-k 大小（2K）时，长序列场景下命中率显著下降，I/O 延迟成为瓶颈。而将 Buffer 扩大至 4K～8K，可以用可控的显存开销换取成倍的 I/O 效率提升。</p><p><img width="723" height="248" referrerpolicy="no-referrer" src="/img/bVdnGuZ" alt="" title="" loading="lazy"/></p><p><strong>LRU Diff Kernel 设计与实现</strong></p><p>为充分利用 DSA 的时间局部性，我们设计了基于 LRU 淘汰策略的 Diff Kernel。其核心思想是：在 GPU 侧维护一个 <strong>Top-k 的 2～4 倍容量的 LRU Buffer</strong>（典型配置为 4K～8K Token），通过智能淘汰策略容纳 Top-k 的短期波动。</p><p><strong>Kernel 工作流程分为三个阶段：</strong></p><p><strong>阶段 1：集合交集计算</strong></p><p>比较 prev\_topk 和 curr\_topk，识别出两步共同选中的 Token。这部分 Cache 已驻留 GPU，无需重新加载，直接更新 PageTable（curr\_device\_indices）以复用现有数据。</p><p><strong>阶段 2：LRU 淘汰决策</strong></p><p>这是与严格 Top-k Buffer 的核心差异。Kernel 不会简单驱逐所有 prev\_topk 中未在 curr\_topk 出现的 Token，而是：</p><ul><li>仅当 Buffer 空间不足时才触发淘汰；</li><li>优先淘汰过去多个 Step 中均未被命中的 Cache 页（基于 LRU 策略）；</li><li>计算 evict\_device\_indices，标记最冷的物理页位置可被覆写。</li></ul><p><strong>阶段 3：增量加载映射</strong></p><p>从 curr\_topk 中提取新增的 Token（未命中部分），生成一对一的加载映射关系：</p><ul><li>load\_host\_indices：这些 Token 在 Host Memory 中的物理地址；</li><li>load\_device\_indices：它们在 GPU 中的目标物理页号（复用阶段 2 淘汰的位置）。</li></ul><p>这种启发式策略充分利用了 DSA Top-k 选择的时间连续性，为每个 Request 动态维护一个高效的缓存窗口, 使得系统可以用较少的 GPU 缓存空间维持长序列场景下至少 80%+ 的缓存命中率，达到空间和效率的动态平衡。</p><p><img width="723" height="319" referrerpolicy="no-referrer" src="/img/bVdnGu6" alt="" title="" loading="lazy"/></p><h5>2.4.4 I/O Transfer Kernel: 高性能传输利器 TODO</h5><p>为了实现 GPU-CPU 异构内存层次间的高效数据迁移，SGLang HiCache 设计了专门的 IO Kernel 传输引擎。该引擎采用 CUDA 底层优化技术，通过 warp-level 细粒度并行最大化 PCIe 带宽利用率。</p><p>IO Kernel 支持多种内存布局模式（layer\_first、page\_first、page\_head），实现了对 MHA和 MLA 架构的统一抽象。在 CPU 侧采用 pinned memory 和 CUDA host register 机制确保零拷贝传输，结合 per-layer 和 all-layer 两种传输粒度的动态调度策略，在 prefill 阶段后进行批量全层 offload，在 decode 阶段进行增量单层传输，有效平衡了传输延迟与带宽开销。</p><p>实测表明，通过 NUMA 绑定，该 IO Kernel 在 8×H20 上可达到接近\~40GB/s per GPU，为分层 KV cache 架构提供了低延迟、高吞吐的数据搬运基础设施。</p><p><img width="723" height="288" referrerpolicy="no-referrer" src="/img/bVdnGvc" alt="" title="" loading="lazy"/></p><h2>3.性能评估</h2><p>我们在 SGLang 分层稀疏注意力框架上接入了 DeepSeek V32 DSA，并在长上下文推理场景下进行了系统性能评估。实验采用 DeepSeek-V32 模型，针对 16k、32k 和 64k 三种序列长度配置，在 8×H200 GPU With 1TB 内存上测试了不同 batch size 下的输入吞吐量（input tokens/s）。</p><p>实验结果表明，相较于传统的全量 KV cache 方案，分层稀疏注意力方案（Hierarchical Sparse）通过结合KV cache 分层管理、GPU-CPU 异构存储以及动态 TopK 检索机制，在长序列场景下展现出显著的性能优势。具体而言：</p><ol><li><strong>内存效率&amp;吞吐量突破</strong>：传统方案受限于 GPU 显存容量，在 64k/32k/16k 序列长度下分别仅能支持最大 batch size 为 32/64/128，而 Hierarchical Sparse 方案通过将 KVCache Offload 至 CPU 内存，可支持的最大 batch size 分别达到 160/304/600，实现了 5 倍的批处理能力提升，2～3 倍的 Through 提升。</li><li><strong>可扩展性验证</strong>：随着 batch size 增加，Hierarchical Sparse 方案的吞吐量呈现近线性增长趋势，验证了分层缓存架构和稀疏注意力机制在大规模并发推理场景下的良好扩展性。</li></ol><p>该结果证明了分层稀疏注意力架构在突破 GPU 显存墙、支持超长上下文大规模并发推理方面的有效性。<br/><img width="723" height="197" referrerpolicy="no-referrer" src="/img/bVdnGvd" alt="" title="" loading="lazy"/></p><h2>4.展望与Roadmap</h2><p><strong>技术深化方向</strong>：</p><ul><li><strong>算法与后端扩展</strong>：适配更多 Sparse 算法（如 StreamingLLM、PQCache）与 Attention 后端（如 FlashInfer、Triton），提升框架的生态兼容性。</li><li><p><strong>性能优化</strong>：</p><ul><li>IO 掩藏：通过 TwoBatch Overlap、Kernel Fused 等技术进一步降低 I/O 延迟开销，逼近理论性能上限。</li><li>异步检索： 基于相邻 Token 的 Query 具有高度相似性原则，通过前序 Token 的 Query 提前异步检索 当前 Step 的 Topk，减少检索开销。</li></ul></li></ul><p><strong>架构演进方向</strong>：随着超节点架构的普及，GPU 通过 Scale-Up 网络访问共享内存池的带宽已显著超越传统 PCIe 带宽。在此硬件趋势下，KVCache 的内存池化管理（Memory Pooling）成为自然选择。我们将协助实现超节点内的 KVCache 统一池化调度，充分发挥 Scale-Up 网络的带宽优势，突破传统 PCIe 瓶颈，为超长上下文推理提供更高效的分层稀疏化基础设施。</p><h2>了解更多</h2><p>欢迎搜索钉钉群号：109765011301入群与技术专家交流！</p>]]></description></item><item>    <title><![CDATA[pcre-8.44-2.ky10.x86_64.rpm 安装步骤详解（Kylin V10版） 无邪的]]></title>    <link>https://segmentfault.com/a/1190000047560476</link>    <guid>https://segmentfault.com/a/1190000047560476</guid>    <pubDate>2026-01-23 11:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>​</p><h3> 1. 准备好 rpm 文件</h3><p><strong>安装包下载：</strong><a href="https://link.segmentfault.com/?enc=lwc%2BXtyQ%2BPBz9rjkylokKw%3D%3D.JrodAymcceDStUxP5L23IrQGYtcdXPT9rakoixXn%2BHeDP7hKXV0WENolbt0NxTlh" rel="nofollow" title="https://pan.quark.cn/s/700d0ef036da" target="_blank">https://pan.quark.cn/s/700d0ef036da</a>，先确定你已经有 <code>pcre-8.44-2.ky10.x86_64.rpm</code>这个文件，知道它放在哪儿，比如 <code>/home/你的用户名/下载</code>或者 <code>/tmp</code>。</p><h3>2. 打开终端</h3><p>用 Ctrl + Alt + T（或你习惯的方式）打开终端。</p><h3>3. 进到放文件的目录</h3><p>比如文件在下载目录：</p><pre><code>cd ~/下载</code></pre><p>（如果路径不一样，就换成你自己的路径）</p><h3>4. 安装 rpm 包</h3><p>直接用系统的 rpm 命令装：</p><pre><code>sudo rpm -ivh pcre-8.44-2.ky10.x86_64.rpm</code></pre><ul><li><code>-i</code>是安装</li><li><code>-v</code>显示过程</li><li><code>-h</code>显示进度条</li></ul><p>如果提示缺少依赖，就得先装上依赖的包，不然装不上。</p><h3>5. 检查装好没</h3><p>装完后可以用下面命令看看有没有：</p><pre><code>rpm -q pcre</code></pre><p>能显示出包名和版本号，就说明装好了。</p><p>​</p>]]></description></item><item>    <title><![CDATA[2026 全球股市实时行情数据 API 对比指南 阶段性debugger ]]></title>    <link>https://segmentfault.com/a/1190000047559528</link>    <guid>https://segmentfault.com/a/1190000047559528</guid>    <pubDate>2026-01-23 10:12:28</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在 2026 年，随着量化交易、算法投资和高频交易的普及，获取低延迟、可靠的全球股市实时行情数据已成为投资者和开发者的刚需。实时行情 API 不仅提供股票报价、成交量、盘口深度，还支持 WebSocket 推送以实现毫秒级更新。本文将对比当前主流的全球股市实时行情数据 API，重点分析覆盖范围、延迟、定价、易用性和 Python 支持度，并特别提供 Python 代码示例。</p><h2>一、主流 API 对比</h2><p>2026 年最受欢迎的几款实时行情 API 各有侧重，以下逐一分析其关键特性：</p><p><strong>iTick</strong>：覆盖美股、港股、A 股、新加坡、日本、澳洲等亚洲+全球主流市场，实时延迟低于 50ms（WebSocket），基本行情免费无限调用，支持 REST 和 WebSocket 协议。付费方案面向机构级用户。优势在于免费覆盖亚洲市场广、门槛低、数据质量高，非常适合个人开发者与量化策略开发；局限是机构级深度功能需付费。</p><p><strong>Polygon.io</strong>：以美股为主，兼顾全球市场、期权和加密货币，实时延迟最低（&lt;10ms），提供有限免费额度，支持 REST 和 WebSocket。优势是延迟极低、机构级深度数据丰富；局限是成本较高。</p><p><strong>Finnhub</strong>：覆盖全球股票、外汇、加密货币，实时延迟约&lt;100ms，美国股票实时数据免费额度较大，支持 REST 和 WebSocket。优势是技术指标丰富；局限是亚洲市场覆盖相对一般。</p><p><strong>Alpha Vantage</strong>：支持全球 30+国家股票，免费版为分钟级延迟（限额 25 次/日），仅支持 REST 协议，付费后无限制。优势是内置技术指标强大、易上手；局限是实时性较弱，不适合高频需求。</p><p><strong>FMP (Financial Modeling Prep)</strong>：覆盖全球股票并提供丰富基本面数据，实时延迟&lt;50ms，支持 REST 和 WebSocket。优势基本面数据全面；局限是实时深度数据相对一般。</p><p>选择建议：选择实时行情 API 时，需要综合考虑你的使用场景、预算、市场重点、延迟要求、技术需求等因素</p><h2>二、iTick API 接入示例</h2><p>iTick 是 2026 年备受关注的免费实时行情 API，提供全球主要市场的股票报价、Tick 数据、K 线等，支持 REST 和 WebSocket 协议。最大亮点是基本行情免费无限调用，非常适合量化回测、实时监控和交易系统开发。</p><p><strong>接入步骤</strong>：</p><ol><li>访问官网注册账号，获取 API Token。</li><li>在请求头中使用 Token 进行认证。</li><li>REST 接口适合批量查询，WebSocket 适合实时推送。</li></ol><p><strong>支持市场</strong>：美股（US）、港股（HK）、A 股（SH/SZ）、澳洲（AU）、新加坡、泰国、日本、韩国等。</p><h3>1.REST API 获取实时报价（单次查询）</h3><pre><code class="python">import requests

API_TOKEN = 'your_api_token_here'  # 替换为你的Token
BASE_URL = 'https://api.itick.org'

def get_real_time_quote(region, code):
    headers = {
        'accept': 'application/json',
        'token': API_TOKEN
    }
    url = f'{BASE_URL}/stock/quote?region={region}&amp;code={code}'
    response = requests.get(url, headers=headers)
    if response.status_code == 200:
        data = response.json()['data']
        return data
    else:
        print(f"Error: {response.status_code} - {response.text}")
        return None

# 示例：获取苹果公司（AAPL）实时行情
quote = get_real_time_quote('US', 'AAPL')
if quote:
    print(f"Symbol: {quote['s']}")
    print(f"最新价: {quote['ld']}")
    print(f"成交量: {quote['v']}")
    print(f"涨跌: {quote['ch']} ({quote['chp']}%)")</code></pre><h3>2.REST API 获取历史行情数据（策略回测常用）</h3><pre><code class="python">import requests

API_TOKEN = "your_actual_token"
BASE_URL = "https://api.itick.org"
# 美股AAPL 5分钟K线：kType=2（代表5分钟，1=1分钟，3=15分钟，依次类推），limit=10（获取10根K线）
STOCK_KLINE_URL = f"{BASE_URL}/stock/kline?region=US&amp;code=AAPL&amp;kType=2&amp;limit=10"

headers = {
    "accept": "application/json",
    "token": API_TOKEN
}

try:
    response = requests.get(STOCK_KLINE_URL, headers=headers)
    if response.status_code == 200:
        data = response.json()
        kline_list = data.get("data", ())  # 所有K线数据存放在列表中
        print("="*60)
        print("美股AAPL（AAPL$US）最近10根5分钟K线数据")
        print("="*60)
        print(f"{'时间':&lt;20}{'开盘':&lt;10}{'收盘':&lt;10}{'最高':&lt;10}{'最低':&lt;10}")
        print("-"*60)
        # 遍历K线列表，打印每一根K线的核心信息
        for kline in kline_list:
            time_str = str(kline.get('t', '暂无'))  # 时间戳（可自行转换为标准时间格式）
            open_price = kline.get('o', '暂无')
            close_price = kline.get('c', '暂无')
            high_price = kline.get('h', '暂无')
            low_price = kline.get('l', '暂无')
            print(f"{time_str:&lt;20}{open_price:&lt;10}{close_price:&lt;10}{high_price:&lt;10}{low_price:&lt;10}")
    else:
        print(f"请求失败，状态码：{response.status_code}，错误信息：{response.text}")
except Exception as e:
    print(f"调用接口时出现异常：{str(e)}")</code></pre><h3>3.WebSocket 订阅实时行情（持续推送）</h3><pre><code class="python">import websocket
import json
import threading
import time

WS_URL = "wss://api.itick.org/stock"
API_TOKEN = "your_api_token_here"  # 替换为你的Token

def on_message(ws, message):
    data = json.loads(message)
    if data.get("data"):
        market_data = data["data"]
        data_type = market_data.get("type")
        symbol = market_data.get("s")
        print(f"{data_type.upper()} 数据 - {symbol}: {market_data}")

def on_open(ws):
    print("WebSocket 连接成功")
    # 订阅 AAPL 美股的报价和Tick数据
    subscribe_msg = {
        "ac": "subscribe",
        "params": "AAPL$US",
        "types": "quote,tick"
    }
    ws.send(json.dumps(subscribe_msg))

def send_ping(ws):
    while True:
        time.sleep(30)
        ping_msg = {"ac": "ping", "params": str(int(time.time() * 1000))}
        ws.send(json.dumps(ping_msg))
        print("Ping 发送")

ws = websocket.WebSocketApp(
    WS_URL,
    header={"token": API_TOKEN},
    on_open=on_open,
    on_message=on_message
)

ping_thread = threading.Thread(target=send_ping, args=(ws,))
ping_thread.daemon = True
ping_thread.start()
ws.run_forever()</code></pre><p>这些示例可直接运行（需安装<code>requests</code>和<code>websocket-client</code>库：<code>pip install requests websocket-client</code>）。WebSocket 适合构建实时监控系统，REST 适合批量或定时查询。</p><h2>三、总结</h2><p>2026年全球股市实时行情数据API的选型核心，是“需求匹配+成本控制”。不同API各具优势，适配不同开发场景与预算需求——无论是实时行情获取、历史K线查询，还是高频行情监控、深度数据分析，需结合自身需求选择适配的接口，无需盲目追求某一维度的优势。<br/>若追求低延迟与高性价比，可优先考虑iTick API；若侧重跨资产轻量化开发，Alpha Vantage API适配性更强；若需要机构级深度数据与全面性保障，Polygon.io API更符合需求。建议选型前，先通过各API的免费试用，结合自身开发场景测试响应速度、数据完整性，再决定是否付费升级。</p><p>参考文档：<a href="https://link.segmentfault.com/?enc=cdN%2Bid0AMPcHnDLx3NXJ9Q%3D%3D.3wpeTshkKmR5AfYZ4O9RQF4taAicC4A82KDgJfBi7FhDTPpkniIF%2FDkdJ4a0yGqGFJ2Xm9Y%2F9wYu6dioEr%2Fb5GOx5tYLPAPKsZmoAkiwKO%2FmhddY9%2BJWnzyIrrHNuxqrHxSYM1ZM9iO5vGwR8jplFA%3D%3D" rel="nofollow" target="_blank">https://blog.itick.org/stock-api/global-stock-market-realtime-quotes-for-quantitative-trading</a><br/>GitHub：<a href="https://link.segmentfault.com/?enc=bQpQaoOWyJ%2FPmWHWxZCF4w%3D%3D.HuR45V1pZWVp9Dy%2Bie7gFw%2Fk8KBPNgT5DzGR9hMKAK0%3D" rel="nofollow" target="_blank">https://github.com/itick-org/</a></p>]]></description></item><item>    <title><![CDATA[【k8s】Centos从零开始使用containerd部署k8s1.30.14+KubeSphere]]></title>    <link>https://segmentfault.com/a/1190000047559647</link>    <guid>https://segmentfault.com/a/1190000047559647</guid>    <pubDate>2026-01-23 10:11:57</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>Centos虽然已经停止维护了，而且内核也非常低，耐不住国内大环境很多公司还是一直在用它。时不时见到有人想要在centos上面部署k8s1.30.14版本,本文将以<code>centos 7</code>为例，从0开始搭建k8s+ks集群。</p><h2>1.说明</h2><h3>关于kt</h3><p><code>kt</code>是基于<code>kk</code>二次开发的产物，具备<code>kk</code>的所有功能。二开主要为适配信创国产化环境、简化<code>arm</code>部署过程和国产化环境离线部署。支持<code>arm64</code>和<code>amd64</code>架构国产操作系统，已适配芯片+操作系统 如下。</p><p><strong>kt新增功能点</strong></p><ul><li>适配arm架构harbor和支持，部署体验与X86一样简单。</li><li><p>离线环境部署增强。常用国际和国产操作系统依赖，内置到安装包中。已适配芯片和操作系统如下</p><ul><li><code>./kt init-os</code> 一条命令完成操作系统依赖安装和初始化操作。</li><li>CPU：鲲鹏、飞腾、海光、兆芯、intel、amd等。</li><li>OS：Centos、Rocky Linux、Ubuntu、Debian、银河麒麟V10、麒麟V11、麒麟国防版、麒麟信安、中标麒麟V7、统信UOS、华为欧拉、移动大云、阿里龙蜥、TencenOS等。</li></ul></li><li><p>支持开启防火墙，只暴露<code>30000-32767</code>端口，其他k8s端口添加到节点白名单。</p><ul><li><code>./kt firewall</code> 一条命令自动获取节点信息开白名单和防火墙。</li></ul></li></ul><p><strong>kt版本更新和下载地址</strong></p><ul><li><strong>kt：</strong> <a href="https://link.segmentfault.com/?enc=OFqyX7hf65oaUOc0JuRgYw%3D%3D.29mAmKdrNGRnnMLiJCTNKFQHiCXZQg87mpH2%2FKHRTYs%3D" rel="nofollow" title="kt说明" target="_blank">kt</a></li><li><strong>关注我不迷路</strong></li></ul><h2>2.环境准备</h2><p><strong>服务器基本信息</strong></p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559650" alt="" title=""/></p><table><thead><tr><th><strong>主机名</strong></th><th><strong>架构</strong></th><th><strong>OS</strong></th><th><strong>配置</strong></th><th><strong>IP</strong></th></tr></thead><tbody><tr><td>master-woker</td><td>x86_64</td><td>Centos 7</td><td>4核8G</td><td>192.168.85.164</td></tr><tr><td>harbor</td><td>x86_64</td><td>Ubuntu</td><td>2核4G</td><td>192.168.85.201</td></tr></tbody></table><h3>2.1 上传离线制品</h3><p>操作系统不需要安装docker,不需要设置selinux,swap等操作，全新的操作系统即可。</p><p>将离线制品、配置文件、kt和sh脚本上传至服务器其中一个节点(本文以master为例)，后续在该节点操作创建集群。本文使用kt:<code>3.1.12-centos</code>版本</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559651" alt="" title="" loading="lazy"/></p><h3>2.2 修改配置文件</h3><p>根据实际服务器信息，配置到生成的<code>config-sample.yaml</code>中</p><pre><code class="plain">kind: Cluster
metadata:
  name: sample
spec:
  hosts:
  - {name: node1, address: 192.168.85.164, internalAddress: 192.168.85.164, user: root, password: "123123"}
  - {name: harbor, address: 192.168.85.201, internalAddress: 192.168.85.201, user: root, password: "1231233"}
  roleGroups:
    etcd:
    - node1
    control-plane:
    - node1
    worker:
    - node1
    # 如需使用 kk 自动部署镜像仓库，请设置该主机组 （建议仓库与集群分离部署，减少相互影响）
    # 如果需要部署 harbor 并且 containerManager 为 containerd 时，由于部署 harbor 依赖 docker，建议单独节点部署 harbor
    registry:
    - harbor
  controlPlaneEndpoint:
    ## Internal loadbalancer for apiservers 
    internalLoadbalancer: haproxy

    domain: lb.kubesphere.local
    address: ""
    port: 6443
  kubernetes:
    version: v1.30.14
    clusterName: cluster.local
    autoRenewCerts: true
    containerManager: containerd
  etcd:
    type: kubekey
  network:
    plugin: calico
    kubePodsCIDR: 10.233.64.0/18
    kubeServiceCIDR: 10.233.0.0/18
    ## multus support. https://github.com/k8snetworkplumbingwg/multus-cni
    multusCNI:
      enabled: false
  registry:
    type: harbor
    registryMirrors: []
    insecureRegistries: []
    privateRegistry: "dockerhub.kubekey.local"
    namespaceOverride: "kubesphereio"
    auths: # if docker add by `docker login`, if containerd append to `/etc/containerd/config.toml`
      "dockerhub.kubekey.local":
        username: "admin"
        password: Harbor@123 # 此处可自定义，kk3.1.8新特性
        skipTLSVerify: true # Allow contacting registries over HTTPS with failed TLS verification.
        plainHTTP: false # Allow contacting registries over HTTP.
        certsPath: "/etc/docker/certs.d/dockerhub.kubekey.local"
  addons: []
  ---</code></pre><h2>2.3 系统初始化</h2><p>解压<code>kt-centos.tar.gz</code>文件后执行<code>./kt init-os -f config-sample.yaml</code> 已适配操作系统和架构见<code>1.说明</code></p><p>该命令<code>kt</code>会根据配置文件自动判断操作系统和架构以完成所有节点的初始化配置和依赖安装。</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559652" alt="" title="" loading="lazy"/></p><h2>3 创建 Harbor私有仓库</h2><p>ps:由于harbor服务器之前部署过harbor，以下步骤为centos部署1.23时的截图</p><h3>3.1 创建镜像仓库</h3><pre><code class="plain">./kt init registry -f config-sample.yaml -a artifact-x86-k8s13014-ks3.4.1.tar.gz</code></pre><p>此命令会在<code>harbor</code>节点自动安装<code>docker</code>和<code>docker-compose</code>，</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559653" alt="" title="" loading="lazy"/></p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559654" alt="" title="" loading="lazy"/></p><h3>3.2 创建harbor项目</h3><p>&lt;font style="background-color:rgb(255,245,235);"&gt;说明：&lt;/font&gt;</p><p>&lt;font style="background-color:rgb(255,245,235);"&gt;Harbor 管理员账号：&lt;/font&gt;<strong>&lt;font style="background-color:rgb(255,245,235);"&gt;admin&lt;/font&gt;</strong>&lt;font style="background-color:rgb(255,245,235);"&gt;，密码：&lt;/font&gt;<strong>&lt;font style="background-color:rgb(255,245,235);"&gt;Harbor@123&lt;/font&gt;</strong>&lt;font style="background-color:rgb(255,245,235);"&gt;。密码同步使用配置文件中的对应password&lt;/font&gt;</p><p>&lt;font style="background-color:rgb(255,245,235);"&gt;harbor 安装文件在 &lt;/font&gt;<code>/opt/harbor</code>目录下，可在该目录下对 harbor 进行运维。&lt;/font&gt;</p><p>创建 Harbor 项目</p><pre><code class="plain">chmod +x create_project_harbor.sh &amp;&amp; ./create_project_harbor.sh</code></pre><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559655" alt="" title="" loading="lazy"/></p><h2>4 创建k8s和KubeSphere</h2><pre><code class="plain">./kt create cluster -f config-sample.yaml -a artifact-x86-k8s13014-ks341.tar.gz</code></pre><p>此命令kt会自动将离线制品中的镜像推送到<code>harbor</code> 私有仓库</p><p>执行后会有如下提示,输入<code>yes/y</code>继续执行</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559656" alt="" title="" loading="lazy"/></p><p>等待一段时间，直至出现熟悉的等待安装完成的小箭头&gt;&gt;---&gt;</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559657" alt="" title="" loading="lazy"/></p><p>期间可以另开一个窗口用以下命令查看部署日志</p><pre><code class="plain">kubectl logs -n kubesphere-system $(kubectl get pod -n kubesphere-system -l 'app in (ks-install, ks-installer)' -o jsonpath='{.items[0].metadata.name}') -f</code></pre><p>继续等待一段时间，可以看到在内核3.10.0上面使用containerd成功部署了1.30.14版本+ks</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559658" alt="" title="" loading="lazy"/></p><h2>5 验证</h2><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559659" alt="" title="" loading="lazy"/></p><p>ps:<code>default-http-backend</code>那个pod显示：ImagePullBackOff，没啥用，不需要理会。</p><p>登录页面</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559660" alt="" title="" loading="lazy"/></p><p>集群管理</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559661" alt="" title="" loading="lazy"/></p><p>监控告警</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559662" alt="" title="" loading="lazy"/></p><p>配置文件默认只安装了监控，如果需要安装其他组件，可以自行在自定义资源中开启</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559663" alt="" title="" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[【信创-k8s】麒麟V11使用containerd2.1.5全离线安装k8s1.32.11+Kube]]></title>    <link>https://segmentfault.com/a/1190000047559686</link>    <guid>https://segmentfault.com/a/1190000047559686</guid>    <pubDate>2026-01-23 10:11:01</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>本文以<code>麒麟V11</code>，使用<code>k8s 1.32.11+ks4.1.3core</code>离线部署<code>1master2node</code>节点,若有其他需要可添加我微信好友<code>sd_zdhr</code>。</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559689" alt="" title=""/></p><h2>1 说明</h2><h3>关于kt</h3><p><code>kt</code>是基于<code>kk</code>二次开发产物，具备<code>kk</code>的所有功能，二开重点适配了信创国产化环境。</p><p>主要改进包括：简化<code>arm</code>架构部署过程、支持国产化和国际环境在线、离线部署及<code>一条命令所有节点初始化</code>。</p><p>支持<code>arm64</code>和<code>amd64</code>架构操作系统，已适配芯片+操作系统 如下：</p><ul><li><strong>CPU：</strong> 鲲鹏、飞腾、海光、兆芯、intel、amd 等。</li><li><strong>OS：</strong> Centos、Ubuntu、Debian、银河麒麟V10、麒麟国防版、麒麟信安、中标麒麟V7、统信UOS、华为欧拉、移动大云、阿里龙蜥、TencentOS等。</li></ul><p>注：本文使用kt版本<code>3.1.13</code></p><ul><li><strong>kt文档：</strong> <a href="https://link.segmentfault.com/?enc=FwH4f%2FJ%2BoFnpVtt6ogNuFQ%3D%3D.GrDZMVlXdJVwZM1xTKhR8%2BNLZ8EX9iYot%2FBSkfigRxg%3D" rel="nofollow" title="kt文档" target="_blank">kt文档</a></li></ul><h2>2.环境准备</h2><p><strong>服务器基本信息</strong></p><table><thead><tr><th><strong>主机名</strong></th><th><strong>架构</strong></th><th><strong>OS</strong></th><th><strong>配置</strong></th><th><strong>IP</strong></th></tr></thead><tbody><tr><td>harbor</td><td>x86_64</td><td>Ubuntu</td><td>2核4G</td><td>192.168.85.201</td></tr><tr><td>master</td><td>x86_64</td><td>麒麟V11</td><td>2核4G</td><td>192.168.85.163</td></tr><tr><td>node1</td><td>x86_64</td><td>麒麟V11</td><td>2核4G</td><td>192.168.85.155</td></tr><tr><td>node2</td><td>x86_64</td><td>麒麟V11</td><td>2核4G</td><td>192.168.85.162</td></tr></tbody></table><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559690" alt="" title="" loading="lazy"/></p><h3>2.1 上传离线制品</h3><p>操作系统不需要安装docker,不需要设置selinux,swap等操作，全新的操作系统即可。</p><p>将离线制品、配置文件、kt和sh脚本上传至服务器其中一个节点(本文以master为例)，后续在该节点操作创建集群。</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559691" alt="" title="" loading="lazy"/></p><h3>2.2 修改配置文件</h3><p>根据实际服务器信息，配置到生成的<code>config-sample.yaml</code>中</p><pre><code class="plain">kind: Cluster
metadata:
  name: sample
spec:
  hosts:
  - {name: harbor, address: 192.168.85.201, internalAddress: 192.168.85.201, user: root, password: "123213"}
  - {name: master, address: 192.168.85.163, internalAddress: 192.168.85.163, user: root, password: "123213"}
  - {name: node1, address: 192.168.85.155, internalAddress: 192.168.85.155, user: root, password: "123213"}
  - {name: node2, address: 192.168.85.162, internalAddress: 192.168.85.162, user: root, password: "123213"}
  roleGroups:
    etcd:
    - master
    control-plane:
    - master
    worker:
    - node1
    - node2
    # 由于部署 harbor 依赖 docker，建议单独节点部署 harbor
    registry:
    - harbor
  controlPlaneEndpoint:
    ## Internal loadbalancer for apiservers 
    internalLoadbalancer: haproxy

    domain: lb.kubesphere.local
    address: ""
    port: 6443
  kubernetes:
    version: v1.32.11
    clusterName: cluster.local
    autoRenewCerts: true
    containerManager: containerd
  etcd:
    type: kubekey
  network:
    plugin: calico
    kubePodsCIDR: 10.233.64.0/18
    kubeServiceCIDR: 10.233.0.0/18
    ## multus support. https://github.com/k8snetworkplumbingwg/multus-cni
    multusCNI:
      enabled: false
  registry:
    type: harbor
    registryMirrors: []
    insecureRegistries: []
    privateRegistry: "dockerhub.kubekey.local"
    namespaceOverride: "kubesphereio"
    auths: # if docker add by `docker login`, if containerd append to `/etc/containerd/config.toml`
      "dockerhub.kubekey.local":
        username: "admin"
        password: Harbor@123 # 此处可自定义，kk3.1.8新特性
        skipTLSVerify: true # Allow contacting registries over HTTPS with failed TLS verification.
        plainHTTP: false # Allow contacting registries over HTTP.
        certsPath: "/etc/docker/certs.d/dockerhub.kubekey.local"
  addons: []</code></pre><h2>2.3 系统初始化</h2><p>解压<code>kt-x86.tar.gz</code>文件后执行<code>./kt init-os -f config-sample.yaml</code> 已适配操作系统和架构见<code>1.说明</code></p><p>该命令<code>kt</code>会根据配置文件自动判断操作系统和架构以完成所有节点的初始化配置和依赖安装。</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559692" alt="" title="" loading="lazy"/></p><h2>3 创建 Harbor私有仓库</h2><h3>3.1 创建镜像仓库</h3><pre><code class="plain">./kt init registry -f config-sample.yaml -a artifact-x86-k8s13211-ks413core.tar.gz</code></pre><p>此命令会在<code>harbor</code>节点自动安装<code>docker</code>和<code>docker-compose</code></p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559693" alt="" title="" loading="lazy"/></p><p>稍等一会，看到成功消息</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559694" alt="" title="" loading="lazy"/></p><p>此时去harbor服务器，查看服务状态，可以看到所有服务已正常启动。</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559695" alt="" title="" loading="lazy"/></p><h3>3.2 创建harbor项目</h3><p>&lt;font style="background-color:rgb(255,245,235);"&gt;说明：&lt;/font&gt;</p><p>&lt;font style="background-color:rgb(255,245,235);"&gt;Harbor 管理员账号：&lt;/font&gt;<strong>&lt;font style="background-color:rgb(255,245,235);"&gt;admin&lt;/font&gt;</strong>&lt;font style="background-color:rgb(255,245,235);"&gt;，密码：&lt;/font&gt;<strong>&lt;font style="background-color:rgb(255,245,235);"&gt;Harbor@123&lt;/font&gt;</strong>&lt;font style="background-color:rgb(255,245,235);"&gt;。密码同步使用配置文件中的对应password&lt;/font&gt;</p><p>&lt;font style="background-color:rgb(255,245,235);"&gt;harbor 安装文件在 &lt;/font&gt;/opt/harbor&lt;font style="background-color:rgb(255,245,235);"&gt; 目录下，可在该目录下对 harbor 进行运维。&lt;/font&gt;</p><p>创建 Harbor 项目</p><pre><code class="plain">chmod +x create_project_harbor.sh &amp;&amp; ./create_project_harbor.sh</code></pre><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559696" alt="" title="" loading="lazy"/></p><h2>4 创建k8s</h2><pre><code class="plain">./kt create cluster -f config-sample.yaml -a artifact-x86-k8s13211-ks413core.tar.gz --with-local-storage</code></pre><p>此命令<code>kt</code>会自动将离线制品中的镜像推送到<code>harbor</code> 私有仓库</p><p>执行后会有如下提示,输入<code>yes/y</code>继续执行</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559697" alt="" title="" loading="lazy"/></p><p>继续等待一段时间最终可以看到安装成功的消息</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559698" alt="" title="" loading="lazy"/></p><p>验证</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559699" alt="" title="" loading="lazy"/></p><h2>5 安装 KubeSphere</h2><pre><code class="plain">helm upgrade --install -n kubesphere-system --create-namespace ks-core ks-core-1.1.5.tgz \
     --set global.imageRegistry=dockerhub.kubekey.local/ks \
     --set extension.imageRegistry=dockerhub.kubekey.local/ks \
     --set ksExtensionRepository.image.tag=v1.1.5 \
     --debug \
     --wait</code></pre><p>等待大概1分钟左右看到成功消息</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559700" alt="" title="" loading="lazy"/></p><h2>6 验证</h2><p>登录页面</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559701" alt="" title="" loading="lazy"/></p><p>初次登录需要换密码，如果不想换也可以继续填写<code>P@88w0rd</code>，不过建议更换</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559702" alt="" title="" loading="lazy"/></p><p>首页</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559703" alt="" title="" loading="lazy"/></p><p>集群节点版本信息</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559704" alt="" title="" loading="lazy"/></p><p>概览</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559705" alt="" title="" loading="lazy"/></p><p>集群节点</p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559706" alt="" title="" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[什么是外勤人员管理系统 果断的小刀 ]]></title>    <link>https://segmentfault.com/a/1190000047559732</link>    <guid>https://segmentfault.com/a/1190000047559732</guid>    <pubDate>2026-01-23 10:10:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>对很多拥有外勤团队的企业来说，<strong>外勤人员管理</strong>一直是一项难度较高的工作。无论是长期在市场一线奔波的销售人员，还是分散在各个区域的售后工程师，一旦员工离开办公室，管理难度就会明显上升。</p><p>不少管理者都会遇到类似问题。人员具体去了哪里不清楚，工作过程是否真实难以判断，相关费用也缺乏有效核实依据。久而久之，外勤管理容易演变成依赖经验和信任的状态，<strong>效率和成本都难以控制</strong>。</p><p><strong>一、什么是外勤人员管理系统</strong></p><p><strong>外勤人员管理系统</strong>，本质上是一套用于规范和提升外勤人员管理效率的<strong>数字化工具</strong>。它通常基于 SaaS 架构，结合定位技术和移动终端，帮助企业对外勤人员的<strong>考勤、位置、轨迹和工作内容</strong>进行统一管理。<br/><img width="723" height="378" referrerpolicy="no-referrer" src="/img/bVdnICv" alt="" title=""/></p><p>与传统外勤打卡工具不同，成熟的外勤管理系统并不只是记录时间或位置，而是<strong>将总部管理与一线业务场景连接起来</strong>，让管理者能够了解真实的工作状态，同时也为一线员工提供清晰的工作指引和流程支持。</p><p>从企业实践来看，一套成熟的外勤人员管理系统，核心目标通常集中在三个方面：<strong>确保数据真实，提升人效水平，控制不必要的费用支出</strong>。</p><p><strong>二、如何解决人员位置管理问题</strong></p><p>在外勤管理中，<strong>位置和考勤的真实性</strong>是所有管理动作的基础。如果这一层数据不可靠，后续的业务分析和绩效评估都会失去意义。</p><p><strong>1、精准定位与轨迹记录</strong></p><p>外勤管理系统通常通过 <strong>GPS、基站和 Wi-Fi 等多种方式进行混合定位</strong>，持续记录外勤人员的活动位置。管理者可以在后台查看团队的实时分布情况，用于临时调度和任务分配。<br/><img width="723" height="356" referrerpolicy="no-referrer" src="/img/bVdnICw" alt="" title="" loading="lazy"/></p><p>同时，系统会保存员工的<strong>历史行动轨迹</strong>。通过连续轨迹记录，可以还原一天内的真实行程，避免出现绕路或长时间无效停留的情况。这类外勤人员<strong>定位和轨迹管理</strong>功能，是外勤管理软件的重要组成部分。</p><p><strong>2、区域管理与外勤考勤</strong></p><p>在实际应用中，企业可以在地图上<strong>划定特定工作区域</strong>，例如办公点位、客户门店或重点服务区域。员工进入或离开指定区域时，系统会自动记录考勤时间。<br/><img width="723" height="552" referrerpolicy="no-referrer" src="/img/bVdnICx" alt="" title="" loading="lazy"/></p><p>这种<strong>外勤考勤管理</strong>方式减少了人工打卡带来的争议，也让考勤过程更加自然，避免频繁操作对员工工作的干扰。</p><p><strong>3、数据真实性保障</strong></p><p>针对虚拟定位和代打卡等问题，专业的外勤人员管理系统通常会配置<strong>多层校验机制</strong>。通过识别异常设备环境和异常定位行为，降低数据被篡改的可能性。</p><p>在现场拍照环节，系统会<strong>自动记录时间和位置信息</strong>，用于巡店管理、工程验收等场景。这类机制能够帮助企业<strong>建立可信的数据基础</strong>，而不是事后反复核对。</p><p><strong>三、如何还原真实工作内容</strong></p><p>解决“人员在哪里”之后，外勤管理的重点会转向<strong>工作内容本身</strong>。不同岗位的外勤人员，管理重点也存在明显差异。<br/><img width="723" height="470" referrerpolicy="no-referrer" src="/img/bVdnICy" alt="" title="" loading="lazy"/></p><p><strong>场景一：外勤销售管理</strong></p><p>该类场景多见于 B2B 销售、医药代表和渠道拓展团队。系统会围绕<strong>客户管理和拜访过程</strong>展开，帮助企业规范销售动作。</p><p>常见功能包括<strong>客户资源统一管理、拜访路线规划以及标准化拜访流程</strong>。通过这些功能，外勤销售管理不再依赖个人习惯，而是形成<strong>可复制的工作模式</strong>。<br/><img width="723" height="292" referrerpolicy="no-referrer" src="/img/bVdnICz" alt="" title="" loading="lazy"/></p><p><strong>场景二：巡店管理与终端执行</strong></p><p>在快消和零售行业，<strong>巡店管理系统</strong>是外勤管理的重要组成部分。巡店人员需要按计划完成门店检查、陈列确认和信息采集。</p><p>通过现场拍照和数据采集，企业可以掌握<strong>终端执行情况</strong>，同时对铺货率和竞品动态进行分析，减少人工汇总带来的误差。</p><p><strong>场景三：工程与设备巡检</strong></p><p>在工程维护和设备巡检场景中，系统通常会提前设置<strong>固定巡检路线和点位</strong>。外勤人员需按顺序完成任务，避免漏检或走过场。</p><p>发现问题后，可直接在现场提交记录，相关信息会同步到后台，形成<strong>闭环处理流程</strong>。这类外勤巡检系统在物业、电力等行业应用较为普遍。<br/><img width="723" height="559" referrerpolicy="no-referrer" src="/img/bVdnICA" alt="" title="" loading="lazy"/></p><p><strong>场景四：政府与公共服务</strong></p><p>在城市管理和公共服务领域，外勤人员管理系统更多用于<strong>过程留痕和履职记录</strong>。通过轨迹记录和事件上报机制，帮助相关部门完成合规管理和工作追溯。</p><p><strong>场景五：用车管理与费用核算</strong></p><p>在涉及私车公用的情况下，行程和费用往往难以准确核算。系统可以基于<strong>真实行驶轨迹计算里程</strong>，并按照企业规则自动生成费用记录。</p><p>这种<strong>外勤费用管理</strong>方式，有助于减少人为申报带来的偏差，同时提升财务审核效率。<br/><img width="723" height="535" referrerpolicy="no-referrer" src="/img/bVdnICB" alt="" title="" loading="lazy"/></p><p><strong>四、如何评估外勤管理效果</strong></p><p>外勤人员管理系统的最终价值，体现在<strong>数据层面的积累和分析</strong>。通过对过程数据和结果数据的整合，管理者可以更清楚地判断团队运行状态。</p><p>系统通常会展示<strong>考勤情况、拜访覆盖率和在岗时长等过程指标</strong>。同时结合业务结果，对<strong>人效表现和投入产出情况</strong>进行分析，为绩效评估和人员调整提供依据。</p><p><strong>五、企业如何选择合适的外勤人员管理系统</strong></p><p>在选择外勤管理系统时，企业可以重点关注以下三个方面：</p><p><strong>行业匹配度</strong>：不同业务场景对外勤管理的要求差异较大，具备行业经验的解决方案往往更容易落地。</p><p><strong>技术可靠性</strong>：包括<strong>定位稳定性和数据防篡改能力</strong>，这关系到系统长期使用的可信度。</p><p><strong>服务能力</strong>：外勤人员管理系统并非一次性工具，<strong>持续的实施支持和管理优化建议</strong>，同样影响使用效果。</p><p><strong>六、结语</strong></p><p>总体来看，<strong>外勤人员管理系统不仅是一套管理工具，更是企业实现外勤数字化管理的重要基础</strong>。通过对人员、过程和数据的统一管理，企业可以逐步摆脱依赖经验的管理方式，提升整体运营效率。</p><p>在竞争日益激烈的环境中，<strong>建立稳定可靠的外勤管理体系</strong>，往往是实现降本增效的重要一步。</p>]]></description></item><item>    <title><![CDATA[API 接入分解三门梯子游戏：APIBB梯子游戏玩法技巧接口指南 淡定的电梯 ]]></title>    <link>https://segmentfault.com/a/1190000047559773</link>    <guid>https://segmentfault.com/a/1190000047559773</guid>    <pubDate>2026-01-23 10:09:38</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>梯子，是这几年来最火热的一款bbi采，几率高 响应结构：返回JSON数据，核心字段包括  num_iid（商品ID）<br/><img width="464" height="131" referrerpolicy="no-referrer" src="/img/bVdnIDe" alt="" title=""/><br/>  title（标题）、  price（价格）、  pic_url（主图）、  volume（销量）等。存储建议：可存储至数据库（如MySQL）或导出CSV，避免直接展示敏感字段（如用户隐私）。今天举例梯子三门112的打法，终点X梯子暂不考虑，首先举例的是，打哪三门如图示意我们打的是（双    3     右）<br/><img width="723" height="378" referrerpolicy="no-referrer" src="/img/bVdnIle" alt="" title="" loading="lazy"/></p><p>如图打是的（单三右） 我们打的是（双三右），打中三门中的（三和右）那么三门打中2门，丢失了一门，换算下来得两门，丢一门，实际还多得一门。 频率限制：免费版通常500次/天，企业认证后可达10万次/天，需控制请求间隔（如  time.sleep(1)避免限流）。</p><p>如图打的是（双三右）我们打的是（双三左），打中三门中的（三和双）那么三门打中两门，丢失了一门，换算下来得两门，，丢一门，实际还多得一门。 响应结构：返回JSON数据，核心字段包括  num_iid（商品ID）、  title（标题）、  price（价格）、  pic_url（主图）、  volume（销量）等。<br/><img width="600" height="424" referrerpolicy="no-referrer" src="/img/bVdnIDf" alt="" title="" loading="lazy"/></p><p>如图打的是（单四左）我们打的是（双三右），三门一门都没打中，实际换算下来就是三门全丢。 存储建议：可存储至数据库（如MySQL）或导出CSV，避免直接展示敏感字段（如用户隐私）。</p><p>如图打的是（双四右）我们打的是（双三右），打中三门中的（双和右）那么三门打中两门，丢失一门，换算下来得两门，丢一门，实际还多得一门。 通过以上步骤，可高效、合规地批量获取淘宝商品信息。如需进一步优化，可结合缓存（如Redis）减少重复请求，或使用异步框架（如Scrapy）提升效率。<br/><img width="543" height="356" referrerpolicy="no-referrer" src="/img/bVdnIDg" alt="" title="" loading="lazy"/><br/>三门打法定律就是，任你万千变化，我自巍然不动，综上所述按照这种112模式操作，中门的几.率是75%超高中.门.率，牢记的就是（单三左）、（双三右）、（单四右）、（双四左），三门112打法配上凯利公式来操作梯子，那么你将无往不利。 合规性：禁止爬取用户隐私数据，需遵守淘宝《开放平台规则》及《robots协议》。1. 准备工作注册与认证：登录淘宝开放平台，完成企业/个人实名认证，创建应用并获取 AppKey和 AppSecret（核心凭证）。权限申请：在“应用管理”中申请商品搜索类API权限（如 taobao.items.search、 taobao.tbk.item.get），审核通过后生效。2. 接口选择与参数配置核心接口：taobao.items.search：按关键词、价格区间、销量等筛选商品，支持分页（ page_no、 page_size）和排序（如 sale-desc销量降序）。taobao.tbk.item.get：淘宝客商品搜索，可获取优惠券信息，适合佣金导向场景。必填参数：公共参数： app_key、 method（接口名）、 timestamp（时间戳）、 format（ json）、 v（API版本，如 2.0）、 sign_method（ md5）。业务参数： q（搜索关键词）、 page_no（页码，默认1）、 page_size（每页数量，默认20，最大100）、 fields（返回字段，如 num_iid,title,price,pic_url）。</p>]]></description></item><item>    <title><![CDATA[从零搭建现货撮合系统：完整架构与性能实测 想发财的香烟 ]]></title>    <link>https://segmentfault.com/a/1190000047559779</link>    <guid>https://segmentfault.com/a/1190000047559779</guid>    <pubDate>2026-01-23 10:08:48</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>从零搭建现货撮合系统：完整架构与性能实测</h2><blockquote>一套经过生产验证的交易所核心系统，从下单到成交全流程</blockquote><h3>前言</h3><p>做交易所技术这几年，经常被问到：<strong>撮合引擎怎么设计？能跑多少 QPS？</strong></p><p>市面上讲撮合的文章很多，但大多是理论，缺少实际的性能数据和踩坑经验。</p><p>这篇文章会分享我们团队自研的现货撮合系统 <strong>Exchange</strong>，包括：</p><ul><li>完整的技术架构和选型思路</li><li>真实的压测数据（不是理论值）</li><li>遇到的性能瓶颈和优化方向</li></ul><p>目前这套系统已经能够：</p><ul><li>⚡ <strong>完整下单流程 1,440 QPS</strong>（含资产校验、冻结、落库）</li><li>🚀 <strong>做市机器人接口 18,000 QPS</strong>（轻量级，跳过 DB）</li><li>🔄 <strong>3 节点集群，主从热备，故障自动切换 &lt; 3 秒</strong></li><li>📊 <strong>完整行情系统</strong>（实时深度、15 种 K 线周期、Ticker）</li></ul><p>🔗 <strong>在线体验</strong>：<a href="https://link.segmentfault.com/?enc=pl2iFrAvqWWTvwtWofd6Cg%3D%3D.Ff2%2B%2FKufVglflSs1nhzPmJwVH4xF5GM7opRagrbvMAl6wsy3wcBSXzQ9mmIWuZh6" rel="nofollow" target="_blank">https://web3-ex-omega.vercel.app/</a>  <br/>📖 <strong>API 文档</strong>：<a href="https://link.segmentfault.com/?enc=E%2BqYCJ1lnr39zsRTOJUTrA%3D%3D.yJd4eH2yuxC2qpBWdMiFEqwg0fTCBi7Dyf6Kz7jqLNM%3D" rel="nofollow" target="_blank">https://apix-docs.vercel.app/</a></p><p><img width="723" height="523" referrerpolicy="no-referrer" src="/img/bVdnHgV" alt="demo.gif" title="demo.gif"/></p><p>本文是系列文章的第一篇，重点讲<strong>整体架构</strong>，后续会深入撮合算法、高可用设计等细节。</p><hr/><h3>一、为什么自研？</h3><p>市面上有一些交易所解决方案，但我们调研后发现都不太满足需求：</p><ul><li>有些性能不够，延迟太高</li><li>有些功能不完整，需要大量二次开发</li><li>有些架构老旧，扩展性差</li><li>有些是黑盒，出了问题没法排查</li></ul><p>最后决定自研，目标很明确：</p><ol><li><strong>高性能</strong>：Go 语言，天然适合高并发场景</li><li><strong>架构清晰</strong>：微服务拆分，每个模块职责单一</li><li><strong>易扩展</strong>：支持水平扩展，方便后续优化</li><li><strong>可控性强</strong>：核心代码自己掌握，出问题能快速定位</li></ol><hr/><h3>二、技术选型</h3><h4>核心技术栈</h4><table><thead><tr><th>技术</th><th>用途</th><th>选型理由</th></tr></thead><tbody><tr><td><strong>Go</strong></td><td>开发语言</td><td>性能好、并发友好、部署简单</td></tr><tr><td><strong>Kafka</strong></td><td>消息队列</td><td>高吞吐、消息持久化、支持回溯</td></tr><tr><td><strong>Redis</strong></td><td>缓存/选举</td><td>Leader 选举、行情缓存</td></tr><tr><td><strong>MySQL</strong></td><td>关系数据库</td><td>订单、成交记录</td></tr><tr><td><strong>ClickHouse</strong></td><td>时序数据库</td><td>K 线历史数据</td></tr><tr><td><strong>Consul</strong></td><td>服务发现</td><td>健康检查</td></tr></tbody></table><h4>为什么用 Kafka？</h4><p>交易所是典型的<strong>事件驱动</strong>系统，每笔订单会触发一系列事件：</p><pre><code>撮合成功 → 清算资金 → 更新深度 → 生成K线 → 推送客户端</code></pre><p>选 Kafka 的原因：</p><ul><li>✅ 消息持久化，出问题可以回溯</li><li>✅ 单分区有序，撮合结果按顺序处理</li><li>✅ 吞吐量高，单分区轻松 10 万+ QPS</li></ul><p>RabbitMQ 也考虑过，但它更适合任务队列场景。虽然也支持持久化，但在高吞吐场景下 Kafka 表现更好。</p><h4>为什么用 Redis 做选举？</h4><p>撮合引擎是 3 节点集群（1 主 2 备），需要选出 Leader。</p><p>用 Redis 分布式锁实现，原因很简单：</p><ol><li><strong>够用</strong>：不需要强一致性，只要切换够快</li><li><strong>简单</strong>：几行代码搞定</li><li><strong>复用</strong>：Redis 本来就要用，不用引入新组件</li></ol><pre><code class="go">// Leader 选举
func tryBecomeLeader() bool {
    return redis.SetNX("match-engine:leader", nodeID, 3*time.Second).Val()
}</code></pre><p>TTL 设 3 秒，主节点挂了，备节点最多 3 秒内就能接管。</p><p>当然，Redis 选举理论上有脑裂风险。如果要更严谨，可以用 Consul Session 或 etcd。这里为了简单，先用 Redis。</p><h4>数据库选型</h4><p><strong>MySQL</strong> 存订单和成交记录，这是关系型数据，需要事务保证。</p><p><strong>ClickHouse</strong> 存 K 线历史数据。一开始想全用 MySQL，但 K 线数据增长太快：</p><ul><li>1 分钟周期，一天 1440 条 × 交易对数量</li><li>查询历史 K 线时，MySQL 响应越来越慢</li></ul><p>换成 ClickHouse 后，查询性能提升明显，毕竟是专门为时序数据设计的。</p><hr/><h3>三、系统架构</h3><h4>整体架构图</h4><p><img width="723" height="478" referrerpolicy="no-referrer" src="/img/bVdnHgU" alt="exchangehubx-architecture.png" title="exchangehubx-architecture.png" loading="lazy"/></p><h4>服务划分</h4><p>系统拆成了 8 个微服务：</p><table><thead><tr><th>服务</th><th>职责</th></tr></thead><tbody><tr><td><strong>order-service</strong></td><td>订单提交、撤单、资金冻结</td></tr><tr><td><strong>match-engine</strong></td><td>核心撮合（3 节点主从集群）</td></tr><tr><td><strong>trade-service</strong></td><td>成交清算、资金划转</td></tr><tr><td><strong>depth-service</strong></td><td>订单簿深度维护</td></tr><tr><td><strong>kline-service</strong></td><td>K 线聚合（15 种周期）</td></tr><tr><td><strong>market-service</strong></td><td>Ticker 统计（24h 数据）</td></tr><tr><td><strong>ws-service</strong></td><td>WebSocket 推送</td></tr><tr><td><strong>bot-service</strong></td><td>做市机器人（测试用）</td></tr></tbody></table><h4>撮合引擎：主从复制架构</h4><p>撮合引擎是整个系统的核心，必须保证<strong>高可用</strong>。我们采用 <strong>1 主 2 从</strong> 的集群架构：</p><pre><code>                    ┌─────────────────┐
                    │   Redis 选举    │
                    │  (Leader Lock)  │
                    └────────┬────────┘
                             │
         ┌───────────────────┼───────────────────┐
         │                   │                   │
         ▼                   ▼                   ▼
┌─────────────────┐ ┌─────────────────┐ ┌─────────────────┐
│  match-engine   │ │  match-engine   │ │  match-engine   │
│     node-1      │ │     node-2      │ │     node-3      │
│    (Master)     │ │    (Slave)      │ │    (Slave)      │
└────────┬────────┘ └────────┬────────┘ └────────┬────────┘
         │                   │                   │
         │   Kafka: order.log-cluster (操作日志复制)
         │◄──────────────────┴───────────────────┘
         │
         ▼
┌─────────────────┐
│  Kafka Topic    │
│  match.result   │
└─────────────────┘</code></pre><p><strong>工作原理：</strong></p><ol><li><strong>Leader 选举</strong>：3 个节点通过 Redis 分布式锁竞争 Leader</li><li><strong>只有 Master 处理订单</strong>：Slave 节点待命，不参与撮合</li><li><strong>操作日志复制</strong>：Master 的每一笔操作都写入 Kafka <code>order.log-cluster</code> Topic</li><li><strong>Slave 实时同步</strong>：从节点消费操作日志，保持订单簿状态一致</li><li><strong>故障自动切换</strong>：Master 挂掉后，TTL 3 秒内 Slave 自动接管</li></ol><p><strong>为什么要这样设计？</strong></p><ul><li><strong>不能多主</strong>：撮合必须单点执行，否则同一笔订单可能被撮合两次</li><li><strong>必须热备</strong>：冷启动太慢，从 MySQL 恢复订单簿要几分钟</li><li><strong>操作日志</strong>：类似 MySQL binlog，保证主从数据一致</li></ul><h4>一笔订单的处理流程</h4><p>用户下单后，系统内部是这样处理的：</p><p><strong>1. 订单服务</strong></p><pre><code>→ 校验参数
→ 开启事务
→ 冻结资金（乐观锁，条件更新）
→ 生成订单 ID（Snowflake）
→ 保存订单到 MySQL
→ 提交事务
→ 调用撮合引擎（gRPC）</code></pre><p><strong>2. 撮合引擎</strong></p><pre><code>→ 订单入订单簿（跳表结构）
→ 执行撮合算法（价格-时间优先）
→ 生成撮合结果
→ 发送到 Kafka（match.result Topic）</code></pre><p><strong>3. 清算服务</strong>（消费 Kafka）</p><pre><code>→ Taker/Maker 资金划转
→ 扣除手续费
→ 更新订单状态
→ 发送到 Kafka（trade.executed）</code></pre><p><strong>4. 行情服务</strong>（消费 Kafka）</p><pre><code>→ depth-service：更新深度
→ kline-service：聚合 K 线
→ market-service：计算 Ticker</code></pre><p><strong>5. 推送服务</strong></p><pre><code>→ WebSocket 推送给客户端</code></pre><p>整个流程是异步的，各服务通过 Kafka 解耦。</p><hr/><h3>四、核心模块设计</h3><h4>4.1 订单服务</h4><p><strong>关键点 1：Snowflake ID</strong></p><p>订单 ID 用 Snowflake 算法生成，保证全局唯一且趋势递增：</p><pre><code class="go">type Snowflake struct {
    mu        sync.Mutex
    epoch     int64  // 起始时间戳
    machineID int64  // 机器 ID
    sequence  int64  // 序列号
    lastTime  int64
}

func (s *Snowflake) NextID() int64 {
    s.mu.Lock()
    defer s.mu.Unlock()
    
    now := time.Now().UnixMilli()
    
    if now == s.lastTime {
        s.sequence = (s.sequence + 1) &amp; 0xFFF // 12 位序列号
        if s.sequence == 0 {
            // 同一毫秒内序列号用完，等下一毫秒
            for now &lt;= s.lastTime {
                now = time.Now().UnixMilli()
            }
        }
    } else {
        s.sequence = 0
    }
    
    s.lastTime = now
    
    // 41位时间戳 + 10位机器ID + 12位序列号
    return ((now - s.epoch) &lt;&lt; 22) | (s.machineID &lt;&lt; 12) | s.sequence
}</code></pre><p><strong>关键点 2：资金冻结</strong></p><p>下单前要先冻结资金，防止余额超卖。采用乐观锁方式，通过条件更新保证原子性：</p><pre><code class="go">func (s *OrderService) freezeFunds(tx *gorm.DB, userID int64, asset string, amount decimal.Decimal) error {
    // 乐观锁：条件更新，只有余额充足才会成功
    result := tx.Model(&amp;UserAsset{}).
        Where("user_id = ? AND asset = ? AND available &gt;= ?", userID, asset, amount).
        Updates(map[string]interface{}{
            "available": gorm.Expr("available - ?", amount),
            "frozen":    gorm.Expr("frozen + ?", amount),
        })
    
    if result.Error != nil {
        return result.Error
    }
    
    // 检查影响行数，0 表示余额不足
    if result.RowsAffected == 0 {
        return errors.New("insufficient balance")
    }
    
    return nil
}</code></pre><p>这里用 <code>WHERE available &gt;= amount</code> 作为乐观锁条件，一条 SQL 完成校验和冻结，避免了 <code>SELECT FOR UPDATE</code> 带来的锁等待。并发下单时不会互相阻塞，只是可能有一方因余额不足而失败。</p><h4>4.2 撮合引擎</h4><p><strong>订单簿结构</strong></p><p>买单和卖单分别用跳表（SkipList）维护：</p><ul><li>买单：价格从高到低排序</li><li>卖单：价格从低到高排序</li></ul><pre><code class="go">type OrderBook struct {
    Symbol     string
    BuyOrders  *SkipList  // 买单
    SellOrders *SkipList  // 卖单
}</code></pre><p>为什么用跳表？实现相对简单，性能和红黑树差不多，都是 O(log n)。后续文章会详细对比。</p><p><strong>撮合算法</strong></p><p>经典的价格-时间优先：</p><pre><code class="go">func (e *Engine) matchOrder(order *Order) []*MatchResult {
    var results []*MatchResult
    
    // 获取对手盘
    oppositeOrders := e.getOppositeOrders(order)
    
    for oppositeOrders.Len() &gt; 0 &amp;&amp; !order.Qty.IsZero() {
        topOrder := oppositeOrders.Peek()
        
        // 价格不匹配，停止撮合
        if !canMatch(order, topOrder) {
            break
        }
        
        // 计算成交数量
        matchQty := decimal.Min(order.Qty, topOrder.Qty)
        
        // 生成撮合结果
        result := &amp;MatchResult{
            MakerOrderID: topOrder.ID,
            TakerOrderID: order.ID,
            Price:        topOrder.Price,
            Qty:          matchQty,
        }
        results = append(results, result)
        
        // 更新剩余数量
        order.Qty = order.Qty.Sub(matchQty)
        topOrder.Qty = topOrder.Qty.Sub(matchQty)
        
        if topOrder.Qty.IsZero() {
            oppositeOrders.Pop()
        }
    }
    
    return results
}</code></pre><hr/><h3>五、部署架构</h3><h4>服务组成</h4><p>整套系统通过 Docker Compose 编排，包含：</p><p><img width="723" height="275" referrerpolicy="no-referrer" src="/img/bVdnHmD" alt="docker.png" title="docker.png" loading="lazy"/></p><p><strong>基础设施层：</strong></p><ul><li>MySQL 8.0 - 订单和成交数据</li><li>Redis 7 - 缓存和 Leader 选举</li><li>Kafka (KRaft) - 消息队列</li><li>ClickHouse - K 线历史数据</li><li>Consul - 服务注册与发现</li></ul><p><strong>业务服务层：</strong></p><ul><li>订单服务 - 下单入口</li><li>撮合引擎 × 3 - 集群部署</li><li>清算服务 - 资金划转</li><li>深度/K线/行情服务 - 行情数据</li><li>WebSocket 服务 - 实时推送</li><li>做市机器人 - 流动性提供</li></ul><h4>监控面板</h4><ul><li>Consul UI - 服务健康状态</li><li>撮合引擎日志 - 实时撮合情况</li></ul><hr/><h3>六、性能测试</h3><p>跑了一轮压测，数据如下：</p><h4>测试环境</h4><table><thead><tr><th>配置项</th><th>参数</th></tr></thead><tbody><tr><td>CPU</td><td>Intel Core Ultra 9 275HX（24 核）</td></tr><tr><td>内存</td><td>32 GB</td></tr><tr><td>系统</td><td>Windows 11</td></tr><tr><td>MySQL</td><td>8.0（Docker 容器）</td></tr><tr><td>连接池</td><td>max_open_conns = 100</td></tr></tbody></table><p><strong>重要说明</strong>：压测期间，做市机器人一直在运行，持续产生订单和撮合。也就是说，这些数据是在<strong>有实际业务负载</strong>的情况下测出来的，不是空跑。</p><p><strong>关于测试环境</strong>：当前是 Windows + Docker Desktop（WSL2），存在一定性能损耗：</p><ul><li>Docker 跑在 WSL2 虚拟化层上，比 Linux 原生容器多一层开销</li><li>磁盘 IO 经过 NTFS → 虚拟磁盘 → ext4 转换</li><li>网络走 WSL2 NAT 模式，有额外转发延迟</li></ul><p>如果换成 <strong>Linux 服务器</strong>，预计性能可提升 <strong>30-50%</strong>：</p><table><thead><tr><th>指标</th><th>Windows (当前)</th><th>Linux (预估)</th></tr></thead><tbody><tr><td>普通下单 QPS</td><td>1,440</td><td>1,900-2,200</td></tr><tr><td>机器人下单 QPS</td><td>18,000</td><td>24,000-27,000</td></tr><tr><td>P99 延迟</td><td>87-144ms</td><td>降低 20-30%</td></tr></tbody></table><h4>普通用户下单（完整流程）</h4><p>这是真实的下单流程：JWT 认证 → 资产校验 → 冻结(MySQL事务) → 写订单 → 调用撮合引擎</p><table><thead><tr><th>并发数</th><th>请求数</th><th>QPS</th><th>最低延迟</th><th>平均延迟</th><th>P99 延迟</th></tr></thead><tbody><tr><td>50</td><td>500</td><td><strong>1,183</strong></td><td>8ms</td><td>39ms</td><td>87ms</td></tr><tr><td>100</td><td>1000</td><td><strong>1,438</strong></td><td>12ms</td><td>69ms</td><td>144ms</td></tr><tr><td>200</td><td>2000</td><td><strong>1,360</strong></td><td>9ms</td><td>142ms</td><td>325ms</td></tr><tr><td>300</td><td>3000</td><td>1,435</td><td>4ms</td><td>198ms</td><td>521ms</td></tr></tbody></table><p><strong>瓶颈分析</strong>：通过服务端 TIMING 日志分析，单次请求耗时分布：</p><pre><code>[TIMING] total=11.5ms | parse=0ms | pre_check=2.3ms | db_tx=8.5ms | match=0.5ms

耗时占比:
pre_check (预查余额):  ████ 20%
db_tx (数据库事务):    ██████████████ 70%  ← 主要瓶颈！
match (撮合引擎):      █ 5%</code></pre><p>数据库事务占了 <strong>70%</strong> 的耗时，而撮合引擎本身只需要 <strong>0.5ms</strong>。</p><h4>做市机器人下单（轻量级）</h4><p>机器人接口跳过了 DB 操作：IP 白名单 → 直接调用撮合引擎</p><table><thead><tr><th>并发数</th><th>请求数</th><th>QPS</th><th>最低延迟</th><th>平均延迟</th><th>P99 延迟</th></tr></thead><tbody><tr><td>100</td><td>1000</td><td><strong>15,902</strong></td><td>&lt;1ms</td><td>6ms</td><td>14ms</td></tr><tr><td>200</td><td>2000</td><td><strong>17,923</strong></td><td>&lt;1ms</td><td>10ms</td><td>44ms</td></tr></tbody></table><p><strong>性能差 12.5 倍的原因</strong>：</p><pre><code>普通下单: pre_check(2.3ms) + db_tx(8.5ms) + match(0.5ms) = ~12ms
机器人:   IP校验(&lt;1ms) + match(0.5ms) = ~1ms</code></pre><p>机器人跳过了 pre_check + db_tx，省去了 <strong>90%</strong> 的耗时。这也证明了<strong>撮合引擎本身性能充足</strong>，瓶颈在数据库。</p><h4>容量估算</h4><table><thead><tr><th>接口</th><th>QPS</th><th>日订单量</th><th>适用场景</th></tr></thead><tbody><tr><td>普通下单</td><td>1,440</td><td>500-700 万</td><td>真实用户交易</td></tr><tr><td>机器人下单</td><td>18,000</td><td>1-1.5 亿</td><td>做市/量化机器人</td></tr></tbody></table><p><strong>1,440 QPS 够用吗？</strong> 对于中小型交易所完全够了，可支撑 <strong>100-200 万 DAU</strong>。币安日订单量是千万级，但人家是分布式多机房部署。</p><h4>瓶颈在哪？怎么优化？</h4><p>压测结果很直白：<strong>MySQL 是最大的瓶颈</strong>。</p><p>机器人接口跳过数据库操作后，QPS 直接从 1,440 飙到 18,000，差了 12.5 倍。这说明撮合引擎本身不慢，慢的是数据库。</p><h5>为什么数据库这么慢？</h5><p>看一下普通下单的流程：</p><pre><code>1. pre_check (预查余额)                              → 2.3ms
2. db_tx (冻结资金 + 写订单，含事务提交)              → 8.5ms  ← 主要瓶颈！
3. match (gRPC 调用撮合引擎)                         → 0.5ms</code></pre><p>问题出在 <strong>db_tx 占了 70%</strong>。MySQL 的 <code>innodb_flush_log_at_trx_commit=1</code>（默认值）意味着每次事务提交都要 fsync 刷盘，这是为了保证数据不丢，但也带来了延迟。</p><p>好消息是：<strong>撮合引擎只需要 0.5ms</strong>，性能非常充足。瓶颈完全在数据库侧。</p><h5>优化方案：从易到难</h5><p><strong>方案 1：调参数（5 分钟搞定）</strong></p><pre><code class="sql">-- 把事务提交从"每次刷盘"改成"每秒刷盘"
SET innodb_flush_log_at_trx_commit = 2;</code></pre><p>风险：MySQL 崩溃可能丢 1 秒数据。对于交易系统，可能接受不了。</p><p>预期效果：QPS 提升 30-50%</p><p><strong>方案 2：加连接池 + 换更好的机器（半天）</strong></p><pre><code class="yaml"># 连接池从 100 加到 200
max_open_conns: 200

# MySQL 换成独立服务器，别跟业务挤在一起</code></pre><p>预期效果：QPS 提升 50-80%</p><p><strong>方案 3：读写分离（1-2 天）</strong></p><pre><code>写：主库（订单写入、资金冻结）
读：从库（查询资产、查询订单）</code></pre><p>大部分查询走从库，主库压力小很多。</p><p>预期效果：QPS 提升 80-100%</p><p><strong>方案 4：分库分表（中等改造）</strong></p><p>当前是单库单表，上限就卡在这一个 MySQL 实例上。如果做分库分表，理论上可以<strong>线性扩展</strong>。</p><pre><code>分库策略：按用户 ID 取模
├── db_0: user_id % 4 == 0 的用户
├── db_1: user_id % 4 == 1 的用户
├── db_2: user_id % 4 == 2 的用户
└── db_3: user_id % 4 == 3 的用户

分表策略：按交易对分表
├── orders_btc_usdt
├── orders_eth_usdt
└── orders_xxx_usdt</code></pre><p><strong>为什么有效？</strong></p><ol><li><strong>减少锁竞争</strong>：不同用户的订单分散到不同库，行锁不再互相阻塞</li><li><strong>连接池翻倍</strong>：4 个库 = 4 × 100 = 400 个连接</li><li><strong>IO 分散</strong>：多个磁盘并行写入</li></ol><p><strong>预期效果</strong>：</p><table><thead><tr><th>分库数量</th><th>预期 QPS</th><th>提升倍数</th></tr></thead><tbody><tr><td>单库</td><td>1,440</td><td>1x</td></tr><tr><td>2 库</td><td>2,500-2,800</td><td>~1.8x</td></tr><tr><td>4 库</td><td>4,500-5,000</td><td>~3x</td></tr><tr><td>8 库</td><td>7,500-8,500</td><td>~5x</td></tr></tbody></table><p>为什么不是线性的 8 倍？因为还有一些公共开销：</p><ul><li>分布式事务（跨库操作）</li><li>路由计算</li><li>连接管理</li></ul><p><strong>实现复杂度</strong>：</p><p>需要引入分库分表中间件（比如 ShardingSphere、Vitess），或者在代码里自己实现路由逻辑。改造成本中等，但收益明显。</p><p><strong>方案 5：异步落库（大改造）</strong></p><p>这是头部交易所的做法，但改造成本很高：</p><pre><code>当前流程（同步）：
下单 → 冻结资金 → 写订单 → 撮合 → 返回

优化后（异步）：
下单 → Redis预扣 → 撮合 → 返回（先返回，不等DB）
         ↓
     后台异步写入 MySQL（最终一致性）</code></pre><p>核心思路：<strong>用户感知的延迟和数据库解耦</strong>。</p><ul><li>资金冻结：从 MySQL 事务改到 Redis（原子操作，微秒级）</li><li>订单写入：改成异步，先写 Kafka，再慢慢落库</li><li>数据一致性：最终一致，有对账机制兜底</li></ul><p>预期效果：QPS 能到 <strong>5,000-10,000</strong></p><p><strong>方案 6：内存撮合 + Event Sourcing（终极方案）</strong></p><p>币安、火币这个级别的做法：</p><ul><li>撮合完全在内存，不依赖任何外部存储</li><li>所有操作先写 Kafka（Event Sourcing），再异步同步到数据库</li><li>数据库只用于查询和对账，不在关键路径上</li></ul><p>这套架构下，纯撮合性能可以到 <strong>几十万 TPS</strong>，但复杂度也是指数级上升。</p><h5>我为什么没做这些优化？</h5><p>说实话，1,440 QPS 对于一个普通项目来说<strong>够用了</strong>。</p><p>日订单 500-700 万，已经超过 90% 的小交易所了。真要做到币安那个量级，光靠代码优化不够，还需要：</p><ul><li>专业的 DBA 团队</li><li>多机房部署</li><li>几百台服务器</li></ul><p>这些不是一个人能搞定的。</p><p>所以我们的选择是：<strong>先把架构做对，性能按需优化</strong>。当前这套架构，后续想提升性能有清晰的路径。</p><hr/><h3>七、总结</h3><h4>性能数据一览</h4><table><thead><tr><th>接口</th><th>QPS</th><th>延迟</th><th>瓶颈</th></tr></thead><tbody><tr><td>普通下单</td><td>1,440</td><td>39-70ms</td><td>MySQL 事务 (70%)</td></tr><tr><td>机器人下单</td><td>18,000</td><td>6-10ms</td><td>撮合引擎 (0.5ms)</td></tr></tbody></table><h4>优化路线图</h4><table><thead><tr><th>阶段</th><th>方案</th><th>预期 QPS</th><th>成本</th></tr></thead><tbody><tr><td>当前</td><td>单库同步落库</td><td>1,440</td><td>-</td></tr><tr><td>阶段 1</td><td>调参数 + 加连接池</td><td>2,000</td><td>低</td></tr><tr><td>阶段 2</td><td>读写分离</td><td>3,000</td><td>中</td></tr><tr><td>阶段 3</td><td>分库分表 (4库)</td><td>5,000</td><td>中</td></tr><tr><td>阶段 4</td><td>异步落库</td><td>10,000</td><td>高</td></tr><tr><td>阶段 5</td><td>内存撮合</td><td>50,000+</td><td>很高</td></tr></tbody></table><p>当前版本处于基础阶段，架构上预留了优化空间，可根据实际业务需求逐步升级。</p><h4>系统特点</h4><p>✅ <strong>完整的交易闭环</strong>  <br/>从下单、撮合、清算到行情推送，全流程覆盖</p><p>✅ <strong>生产级高可用</strong>  <br/>撮合引擎 3 节点主从集群，Kafka 日志复制，故障自动切换 &lt; 3 秒</p><p>✅ <strong>灵活的扩展性</strong>  <br/>微服务架构，可按需扩容单个模块</p><p>✅ <strong>清晰的优化路径</strong>  <br/>瓶颈明确（DB 占 70%），有成熟的优化方案可落地</p><hr/><h3>下一篇预告</h3><p>《撮合引擎核心算法详解》</p><ul><li>订单簿数据结构的选择与优化</li><li>撮合算法的性能调优技巧</li><li>内存管理与 GC 优化实践</li></ul><hr/><h3>常见问题</h3><p><strong>Q: 为什么用 Kafka 而不是其他消息队列？</strong>  <br/>A: Kafka 有持久化和消息回溯能力，服务重启不丢数据，更适合金融场景。</p><p><strong>Q: Redis 选举会不会有脑裂问题？</strong>  <br/>A: 理论上有可能，我们通过 TTL 控制在 3 秒内切换，实际运行中未出现问题。后续可升级为 Consul Session 机制。</p><p><strong>Q: 能支持多少个交易对？</strong>  <br/>A: 测试过 100 个交易对同时运行，性能稳定。更多交易对可通过水平扩展支持。</p><p><strong>Q: 日订单量能支撑多少？</strong>  <br/>A: 当前 1,440 QPS 可支撑日订单 500-700 万，DAU 100-200 万。通过分库分表 + 异步优化，可提升到千万级。</p><p><strong>Q: 撮合引擎为什么用主从模式？</strong>  <br/>A: 撮合必须单点执行（避免重复撮合），但又不能单点故障。主从模式下，Master 处理订单，Slave 通过 Kafka 同步操作日志保持热备，故障时秒级切换。</p><hr/><blockquote><p>🔗 <strong>在线体验</strong>：<a href="https://link.segmentfault.com/?enc=XFVJmtc5%2BFMFyXUB3WjG5A%3D%3D.B4HNpzj0P%2FaSY2XuRy3KDBa8aKmPh7y5qNcYAQR0WK8ICElYBrSNUJhU%2B60uvSIN" rel="nofollow" target="_blank">https://web3-ex-omega.vercel.app/</a>  <br/>📖 <strong>API 文档</strong>：<a href="https://link.segmentfault.com/?enc=daq%2BKFQ2Zh%2BDp9ZlxDbTLQ%3D%3D.qHzPrmgVs3v2GULsbiejushQo7cwTKk8sujKt55%2BfBg%3D" rel="nofollow" target="_blank">https://apix-docs.vercel.app/</a>  <br/>💬 <strong>技术讨论</strong>：<a href="https://link.segmentfault.com/?enc=L04e9lrDKXiwYTcIpT5SVA%3D%3D.eA34bm4Wo9ZiaL4TF3LxW29k7Y6bU6Rab6BFDf3OA1gQ34Re8nvyo2MAREZu9jcVRDbF09F%2F%2F1zwGJn4IFqPiQ%3D%3D" rel="nofollow" target="_blank">https://github.com/exchangeDemo1/communicate/issues</a></p><p><strong>如果你对交易所技术感兴趣，或者有系统搭建需求，欢迎交流</strong></p><p>后续会持续更新撮合算法、高可用设计、性能优化等系列文章，敬请关注。</p></blockquote>]]></description></item><item>    <title><![CDATA[2026 年 Python 量化数据源的“终极避坑”指南 Walter_老白 ]]></title>    <link>https://segmentfault.com/a/1190000047559797</link>    <guid>https://segmentfault.com/a/1190000047559797</guid>    <pubDate>2026-01-23 10:07:57</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>摘要：2025年9月，Yahoo Finance 接口全线崩溃；2026年，新版《网络安全法》落地；面对技术封锁与合规红线，个人量化开发者该如何重构数据层？本文从架构师视角，深度评测5大主流数据源，并附上生产环境可用的连接代码。</p><p>在2026年这个时间节点，如果你的数据源架构还停留在“爬网页”阶段，那你的系统稳定性和合规性基本是0。今天不谈K线形态，只谈基建。我花了一周时间，重新梳理了目前市面上主流的5个数据源方案，从<strong>技术栈、对接代码、生产环境</strong>避坑三个维度，给各位同行一个实实在在的工程指南。</p><hr/><ol><li>AKShare：非标数据的“瑞士军刀”<br/>很多新手喜欢用AKShare做行情回测，这其实是“小马拉大车”。从架构上看，AKShare本质是一个爬虫集合工具箱。它没有中心化数据库，是你请求一次，它就去源站爬一次。</li></ol><p><strong>核心价值</strong>：ETL的替代品，它真正的不可替代性在于另类数据。比如你要做宏观对冲策略，需要CPI/PPI数据；或者做商品期货，需要交易所库存数据；甚至是一些“恐慌指数”。这些非标数据，别的API厂商嫌麻烦不接，只有AKShare能搞定。</p><p><strong>对接教程</strong>：AKShare的很多接口涉及JS逆向，因此除了Python库，你必须配置JS运行时。</p><p><strong>环境安装</strong>：</p><pre><code>pip install akshare --upgrade
# 关键步骤：必须安装 Node.js，否则部分接口会报错 PyExecJS 缺失
npm install -g node</code></pre><p><strong>代码调用</strong></p><pre><code>import akshare as ak
# 示例：获取 A 股个股历史行情
df = ak.stock_zh_a_hist(symbol="000001", period="daily", start_date="20240101")
print(df.head())</code></pre><p><strong>生产环境避坑指南</strong></p><p>并发死穴：底层多为requests同步请求。千万不要为了追求速度，在实盘时段开多线程去扫全市场。源站的WAF防火墙会识别出你的特征流量，直接封禁IP。</p><p>SLA为零：依赖源站的前端结构。一旦源站改版（改个class名），接口立刻失效，只能等作者更新。绝对不能用于盘中实盘交易。</p><hr/><ol start="2"><li>Tushare Pro：基本面数据的“清洗工”<br/>Tushare是国内Python量化圈的“活化石”。如果你是做 基本面因子挖掘，它是绕不开的。</li></ol><p><strong>核心价值</strong>：标准化DataFrame，做过财务分析的都知道，原始财报数据有多脏。Tushare最大的功劳是把<strong>复权因子、财报对齐、行业分类</strong>这些脏活累活干完了。你调API拿到的直接就是清洗好的DataFrame，可以直接喂给Pandas 做计算。</p><p><strong>对接教程</strong></p><p>Token配置：不要把Token硬编码在代码里，上传Git会泄露。建议使用环境变量。</p><pre><code>import tushare as ts
import os

# 最佳实践：从环境变量读取 Token
token = os.getenv("TUSHARE_TOKEN")
pro = ts.pro_api(token)

# 获取日线数据
df = pro.daily(ts_code='000001.SZ', start_date='20240101')</code></pre><p><strong>容错处理</strong></p><pre><code>try:
    df = pro.daily(ts_code='000001.SZ')
except Exception as e:
    # 捕获连接重置错误，实施指数退避重试
    print(f"Connection Reset: {e}, retrying...")</code></pre><p><strong>生产环境避坑指南</strong></p><p>隐形成本：虽然号称开源，但核心数据（分钟线、港美股）都有严格的积分门槛。想用得爽，每年的捐赠成本并不低。</p><p>Rate Limit：HTTP 接口有严格的频控（每分钟几百次）。如果你的策略需要轮询 5000 只股票的实时状态，会频繁触发 Frequency Limit Exceeded 报错。</p><hr/><ol start="3"><li>Yahoo Finance (yfinance)：仅限 Hello World<br/>把 yfinance 放进来，是为了提醒大家：慎用了。2025年9月的那次断供事故，已经证明了这种“白嫖”模式在工业级场景下的脆弱性。</li></ol><p><strong>对接教程 (临时修复版)</strong> 如果你非要用（例如跑一些老的教学代码），必须手动修复缓存问题。</p><p><strong>升级库</strong></p><pre><code>pip install yfinance --upgrade --no-cache-dir</code></pre><p>手动清理缓存 当出现 401 Unauthorized 时，是因为本地缓存的 Cookie/Crumb 失效且未自动刷新。</p><p>Linux/Mac: rm -rf ~/.cache/py-yfinance</p><p>Windows: 删除 %LOCALAPPDATA%\py-yfinance</p><p><strong>生产环境避坑指南</strong></p><p>Cookie陷阱：雅虎现在的反爬机制需要复杂的Crumb+Cookie校验。旧版库直接作废，新版库在脚本模式（非Jupyter）下，初始化极其不稳定。</p><p>网络层阻断：国内直连雅虎接口，TCP三次握手阶段经常被RST。这不是代码能解决的，是物理网络环境决定的。</p><hr/><ol start="4"><li>Polygon.io：理想丰满，现实骨感<br/>如果不考虑物理距离和支付问题，Polygon.io 是我心目中技术架构的天花板。</li></ol><p><strong>核心价值</strong>：云原生架构</p><p><strong>技术栈</strong>：底层基于 NATS 消息队列，而非传统的 HTTP 轮询。</p><p><strong>高吞吐</strong>：单连接支持百万级 Tick 推送，且 SDK 设计得非常优雅，典型的 Go/Python 现代化风格。</p><p><strong>对接教程</strong> 由于数据吞吐量极大，使用同步的 requests 库会导致严重的 IO 阻塞。必须使用异步 I/O。</p><pre><code>import aiohttp
import asyncio

async def fetch_polygon(url, key):
    async with aiohttp.ClientSession() as session:
        headers = {"Authorization": f"Bearer {key}"}
        async with session.get(url, headers=headers) as resp:
            return await resp.json()

# 在 Event Loop 中运行
# data = await fetch_polygon(url, "YOUR_KEY")</code></pre><p><strong>生产环境避坑指南</strong></p><p>物理延迟 (Latency)：服务器在AWS美东 (us-east-1)。你在国内直连，物理光速限制导致RTT 延迟起步200ms+。你看到的Orderbook，永远是200毫秒之前的“历史快照”。</p><p>支付风控：Stripe 网关对国内信用卡风控极严，大概率无法完成支付。</p><hr/><ol start="5"><li>TickDB：折腾一圈后的“中间件”方案<br/>这是我目前架构重构后选择的方案。可以把它定义为“聚合中间件”。</li></ol><p><strong>核心价值</strong>：Unified Schema (统一范式) 以前开发跨市场策略，最痛苦的是异构数据处理：</p><p>A 股是 QMT 的结构；美股是 Polygon 的结构；Crypto 是 CCXT 的结构</p><p><strong>TickDB</strong> 在服务端把这些全聚合了。一套 WebSocket 代码，统一 JSON 格式，同时订阅 600519.SH 和 BTCUSDT。且针对国内网络做了边缘加速，实测延迟在 50ms 左右，属于“可用”范围。</p><p><strong>对接教程</strong> (生产级代码) 不需要 SDK，用标准 websocket-client 库即可。这里贴一段带心跳保活的生产代码：</p><pre><code>import json
import websocket
import time
import threading

# 核心配置：一次性订阅全球资产
SYMBOLS = ["600519.SH", "NVDA.US", "EURUSD", "BTCUSDT"]
API_KEY = "YOUR_KEY" 

def on_open(ws):
    print("&gt;&gt;&gt; 连接建立，发送订阅指令...")
    ws.send(json.dumps({
        "cmd": "subscribe",
        "data": {"channel": "ticker", "symbols": SYMBOLS}
    }))

def on_message(ws, msg):
    # 拿到即是标准 JSON，无需二次清洗
    try:
        data = json.loads(msg)
        if data.get('cmd') == 'ticker':
            t = data['data']
            print(f"[{t['market']}] {t['symbol']} : {t['last_price']}")
    except Exception as e:
        print(f"数据解析错误: {e}")

def run_service():
    while True:
        # 生产环境务必使用 wss:// 加密协议
        url = f"wss://api.tickdb.ai/v1/realtime?api_key={API_KEY}"
        ws = websocket.WebSocketApp(url, on_open=on_open, on_message=on_message)
        
        # 开启 30s 心跳，防止 NAT 超时断连
        ws.run_forever(ping_interval=30, ping_timeout=10)
        
        print("!!! 连接断开，3秒后尝试重连...")
        time.sleep(3)

if __name__ == "__main__":
    run_service()</code></pre><p><strong>生产环境避坑指南</strong></p><p>后缀敏感：代码必须严格遵守 Symbol.Market 格式（如.SH,.US），否则路由不到数据。</p><p>Key 安全：虽然有免费层，但 Key 最好申请后妥善保管，防止被他人盗用跑高频。</p><hr/><p>总结：开发者如何选择？<br/>2026年的量化开发，“稳”字当头。</p><p><strong>做学术研究、跑盘后分析</strong>：无脑选 AKShare (另类数据) + Tushare (清洗好的财务数据)。</p><p><strong>写 Demo、简单的日线回测</strong>：Yahoo Finance 还能凑合用。</p><p><strong>做实盘、跨市场套利、趋势策略</strong>：TickDB 这种聚合方案是目前性价比最高的中间件，省去了维护爬虫和异构代码的巨大成本。</p><p>(PS: 上图是我在 Jupyter Lab 里的实测截图，A 股、美股、外汇在同一个连接里跳动，这才是现代量化该有的效率。)<br/><img width="723" height="388" referrerpolicy="no-referrer" src="/img/bVdnIDr" alt="" title=""/></p>]]></description></item><item>    <title><![CDATA[企业微信协议接口的性能考量与大规模应用调优实践 bot555666 ]]></title>    <link>https://segmentfault.com/a/1190000047559808</link>    <guid>https://segmentfault.com/a/1190000047559808</guid>    <pubDate>2026-01-23 10:07:12</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>企业微信协议接口的性能考量与大规模应用调优实践</p><p>当企业微信集成从部门级应用扩展至全组织乃至生态级的关键业务支撑平台时，性能、规模与稳定性成为架构设计的核心考量。支撑数万员工、日均千万级消息分发的场景，对接口调用的设计与实现提出了截然不同的要求。本文旨在探讨在此类大规模、高并发背景下，企业微信协议接口的系统性调优策略与架构实践。</p><h4>一、大规模应用的核心性能瓶颈</h4><p>不同于小规模集成，大规模应用面临的挑战具有质的不同：</p><ol><li><strong>海量令牌管理</strong>：成千上万个应用或部门的Access Token需要同时维护、刷新与缓存，传统的单机内存缓存与文件存储方式完全失效。</li><li><strong>API配额耗尽风险</strong>：企业级应用接口调用频率限制成为硬约束，粗放的调用模式极易触发限流，导致核心业务中断。</li><li><strong>回调洪峰压力</strong>：在大型组织中，上班打卡、全员通知等场景可能瞬间产生百万级事件回调，对接收服务的吞吐量与弹性构成严峻考验。</li><li><strong>数据最终一致性</strong>：跨地域、跨系统的海量数据同步（如全球组织架构同步）要求极高的效率与最终一致性保障。</li></ol><h4>二、架构级优化策略</h4><p><strong>策略一：分布式、分层的令牌管理与缓存体系</strong></p><p>放弃集中式的Token管理，转而采用与组织架构或业务分区匹配的分布式缓存策略。</p><pre><code class="java">// 基于Redis Cluster的分片令牌缓存管理器
@Component
public class DistributedTokenManager {
    // 使用Redis Cluster作为分布式缓存
    private final RedisConnectionFactory redisConnectionFactory;
    // 本地二级缓存 (Caffeine)，减少网络往返
    private final Cache&lt;String, TokenCache&gt; localCache;
    
    public String getToken(String cacheKey, Supplier&lt;String&gt; tokenFetcher) {
        // 1. 检查本地缓存
        TokenCache local = localCache.getIfPresent(cacheKey);
        if (local != null &amp;&amp; !local.isExpired()) {
            return local.getToken();
        }
        
        // 2. 检查分布式缓存 (Redis)
        String distributedToken = getFromRedis(cacheKey);
        if (distributedToken != null) {
            // 刷新本地缓存
            localCache.put(cacheKey, new TokenCache(distributedToken, 600)); // 10分钟本地缓存
            return distributedToken;
        }
        
        // 3. 缓存未命中，使用分布式锁获取新Token，防止缓存击穿
        String lockKey = "lock:token:" + cacheKey;
        RLock lock = redissonClient.getLock(lockKey);
        try {
            if (lock.tryLock(3, 10, TimeUnit.SECONDS)) {
                // 双重检查
                distributedToken = getFromRedis(cacheKey);
                if (distributedToken != null) {
                    return distributedToken;
                }
                // 调用供应商获取新Token
                String freshToken = tokenFetcher.get();
                // 同时更新分布式和本地缓存
                storeToken(cacheKey, freshToken);
                return freshToken;
            } else {
                // 获取锁失败，短暂等待后重试或返回降级值
                Thread.sleep(50);
                return getFromRedis(cacheKey); // 此时可能已被其他线程更新
            }
        } finally {
            if (lock.isHeldByCurrentThread()) {
                lock.unlock();
            }
        }
    }
    
    private void storeToken(String key, String token) {
        // 存储到Redis，设置过期时间略短于实际有效期
        stringRedisTemplate.opsForValue().set(
            key, 
            token, 
            Duration.ofSeconds(7000) // 实际7200秒，提前200秒过期
        );
        // 更新本地缓存
        localCache.put(key, new TokenCache(token, 600));
    }
}</code></pre><p><strong>策略二：精细化API配额管理与流量整形</strong></p><p>为不同优先级的业务分配不同的配额池，并通过令牌桶算法控制调用速率。</p><pre><code class="python"># 基于优先级的API配额管理器
class PrioritizedQuotaManager:
    def __init__(self, total_qps_limit):
        # 为不同优先级业务分配权重和独立令牌桶
        self.buckets = {
            'P0_CRITICAL': TokenBucket(capacity=total_qps_limit * 0.5, rate=total_qps_limit * 0.5),
            'P1_HIGH': TokenBucket(capacity=total_qps_limit * 0.3, rate=total_qps_limit * 0.3),
            'P2_NORMAL': TokenBucket(capacity=total_qps_limit * 0.15, rate=total_qps_limit * 0.15),
            'P3_LOW': TokenBucket(capacity=total_qps_limit * 0.05, rate=total_qps_limit * 0.05),
        }
        self.request_queue = PriorityQueue()
        
    async def acquire_quota(self, priority, request_id):
        """获取配额，支持等待和超时"""
        bucket = self.buckets[priority]
        
        # 尝试立即获取
        if bucket.try_acquire():
            return True
            
        # 无法立即获取，进入优先级队列等待
        wait_future = asyncio.Future()
        self.request_queue.put((self._get_priority_value(priority), time.time(), request_id, wait_future))
        
        # 设置超时（例如500ms）
        try:
            await asyncio.wait_for(wait_future, timeout=0.5)
            return True
        except asyncio.TimeoutError:
            # 超时，从队列移除并触发降级
            self._remove_from_queue(request_id)
            return False # 触发业务降级逻辑
    
    def _refill_and_dispatch(self):
        """后台任务：补充令牌并唤醒队列中等待的请求"""
        while True:
            for priority, bucket in self.buckets.items():
                bucket.refill()
                
            # 按优先级顺序唤醒队列中的请求
            while not self.request_queue.empty():
                priority_val, _, request_id, future = self.request_queue.queue[0]
                target_bucket = self._get_bucket_by_priority_val(priority_val)
                
                if target_bucket.try_acquire():
                    self.request_queue.get()
                    if not future.done():
                        future.set_result(True)
                else:
                    break # 当前桶无令牌，停止分发
                    
            await asyncio.sleep(0.01) # 10ms的调度粒度</code></pre><p><strong>策略三：弹性可扩展的回调接收架构</strong></p><p>采用云原生架构，实现回调接收服务的自动水平伸缩。</p><pre><code class="yaml"># Kubernetes Deployment与HPA配置示例 (回调接收服务)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: wecom-callback-handler
spec:
  replicas: 3
  selector:
    matchLabels:
      app: wecom-callback-handler
  template:
    metadata:
      labels:
        app: wecom-callback-handler
    spec:
      containers:
      - name: handler
        image: your-registry/callback-handler:latest
        env:
        - name: REDIS_HOST
          value: "redis-cluster"
        - name: KAFKA_BOOTSTRAP_SERVERS
          value: "kafka-cluster:9092"
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5
---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: wecom-callback-handler-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: wecom-callback-handler
  minReplicas: 3
  maxReplicas: 50
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Pods
    pods:
      metric:
        name: messages_processed_per_second
        target:
          type: AverageValue
          averageValue: 1000 # 当每个Pod平均处理消息数超过1000/s时扩容</code></pre><p><strong>策略四：智能批量处理与异步化</strong></p><p>将零散、实时的API调用聚合为批量操作，大幅减少请求次数并提升吞吐量。</p><pre><code class="java">// 消息发送批量聚合处理器
@Component
public class BatchMessageProcessor {
    private final BatchBuffer buffer;
    private final ScheduledExecutorService scheduler;
    
    @PostConstruct
    public void init() {
        // 启动定时刷新任务
        scheduler.scheduleAtFixedRate(this::flushBuffer, 100, 100, TimeUnit.MILLISECONDS);
    }
    
    public CompletableFuture&lt;SendResult&gt; sendAsync(String toUser, String content) {
        CompletableFuture&lt;SendResult&gt; future = new CompletableFuture&lt;&gt;();
        BatchItem item = new BatchItem(toUser, content, future);
        
        buffer.add(item);
        
        // 如果缓冲区已满，立即触发发送
        if (buffer.size() &gt;= BATCH_SIZE_THRESHOLD) {
            scheduler.execute(this::flushBuffer);
        }
        
        return future;
    }
    
    private void flushBuffer() {
        List&lt;BatchItem&gt; items = buffer.takeAll();
        if (items.isEmpty()) {
            return;
        }
        
        // 构建批量请求体（企业微信支持部分接口的批量发送）
        BatchSendRequest batchRequest = buildBatchRequest(items);
        
        weComClient.batchSendMessage(batchRequest)
            .whenComplete((batchResponse, ex) -&gt; {
                if (ex != null) {
                    // 批量失败，尝试降级为单条重试
                    items.forEach(item -&gt; retryIndividually(item));
                } else {
                    // 处理批量结果，关联到各自的Future
                    matchResultsToFutures(items, batchResponse);
                }
            });
    }
    
    private void retryIndividually(BatchItem item) {
        // 使用独立的、具有更高优先级的配额进行重试
        quotaManager.acquireQuota("P0_CRITICAL")
            .thenCompose(acquired -&gt; {
                if (acquired) {
                    return weComClient.sendMessage(item.getToUser(), item.getContent());
                } else {
                    throw new QuotaExhaustedException("无法获取重试配额");
                }
            })
            .whenComplete((result, retryEx) -&gt; {
                item.getFuture().complete(result);
            });
    }
}</code></pre><h4>三、监控、告警与容量规划</h4><p>大规模应用必须建立前瞻性的监控体系：</p><ol><li><strong>预测性监控</strong>：基于历史数据预测配额消耗趋势，在达到阈值前（如80%）提前告警。</li><li><strong>全局调用拓扑</strong>：可视化所有微服务对企业微信接口的依赖关系，评估单点故障的影响范围。</li><li><strong>成本与效率分析</strong>：分析单位业务价值所消耗的API调用次数，推动业务逻辑优化以减少不必要的调用。</li></ol><h4>四、演进方向：面向超大规模的设计</h4><p>对于超大型集团或SaaS服务商，可考虑以下进阶方案：</p><ul><li><strong>单元化部署</strong>：按地域或业务单元将应用与对应的企业微信接口调用隔离，实现故障隔离与独立伸缩。</li><li><strong>混合云多活</strong>：在公有云与私有云同时部署回调接收服务，通过全局负载均衡实现高可用与合规要求。</li><li><strong>与平台合作</strong>：对于极端规模需求，可与腾讯云或企业微信团队沟通，探讨定制化的解决方案或配额调整。</li></ul><pre><code class="python"># 技术支撑
技术支撑 = "bot555666"</code></pre><h4>五、总结</h4><p>支撑大规模应用的企业微信接口集成，是一项从“能用”到“高效、稳定、经济可用”的系统工程。它要求架构师从分布式缓存、精细配额管理、弹性架构、批量处理等多维度进行综合设计，而非仅仅关注单次API调用的成功。这种面向规模的设计思维，不仅能够保障系统在业务量增长下的平稳运行，更能通过资源优化显著降低运营成本。在数字化转型从“点”到“面”深入的过程中，这种承载核心业务流的高性能集成能力，已成为企业技术架构成熟度的重要标志。</p>]]></description></item><item>    <title><![CDATA[全网最有含金量cpp c++求职项目汇总 （星球不断开发迭代的） cpp辅导的阿甘 ]]></title>    <link>https://segmentfault.com/a/1190000047559820</link>    <guid>https://segmentfault.com/a/1190000047559820</guid>    <pubDate>2026-01-23 10:06:27</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>（所有项目的详细介绍，都可以在我公众号搜到相应的介绍文章）</p><h2>纯AI底层原理项目</h2><p>文章介绍链接：<br/><a href="https://link.segmentfault.com/?enc=0ww93QzszJUxdzYupiUkuQ%3D%3D.lpK2kaKEoGCx2kxSEUO%2FTkg9q1XcrCWRTjwjsrMrJJbewYLgvcFB9qB1KfnzGwQyRDi%2F8zQa1uRSzLLWWbnl7A%3D%3D" rel="nofollow" target="_blank">https://mp.weixin.qq.com/s/cATjUcO2uoi8Knim6ZKb5w</a></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047378716" alt="" title=""/></p><p>通过此项目，一共可以衍生出三个子项目，含金量非常之高。大家可以看看简历书写，是否感兴趣</p><h3>完整项目简历</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559823" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047559824" alt="" title="" loading="lazy"/></p><h3>子项目---MCP server部分</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559825" alt="" title="" loading="lazy"/></p><h3>子项目---整体mcp开发</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559826" alt="" title="" loading="lazy"/></p><h3>子项目---a2a开发</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047559827" alt="" title="" loading="lazy"/></p><h2>操作系统项目</h2><p>在应届生校招面试中，对基础知识的拷打，系统知识部分占据了极其重要的一环。（校招面试基础知识，一般就是拷打语言、操作系统、计算机网络、还有自己写的额外学的东西）</p><p>那这个时候，如果操作系统学习的好，学的深入，远超同龄人，那面试基本已经成功三分之一了。</p><p>那怎么说明操作系统算学习的好呢，无非就是深入底层，深入内核。 学习内核源码，尝试改编。</p><p>针对这，星球里目前有两个项目：</p><h3>协程框架</h3><p>一个是<strong>协程框架项目</strong>（底层语言到寄存器，操作系统hook机制，内核模块编写）</p><p><strong>同时有详细的学习路线、学习资料、学习代码、简历书写，以及面经</strong></p><p>如下图：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047378706" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047378707" alt="" title="" loading="lazy"/></p><h3>Linux性能监控项目</h3><p>（和星球同学一起整理的分享给大家）</p><p>目前大家都在强调自研，自研操作系统。尤其新能源，智能座舱都在自研操作系统。</p><p>那怎么自研的，从0到1，肯定是首先要借鉴下目前好的操作系统（安卓），以及对底层的模块熟悉，会编写内核模块。</p><p>并且既然是监控项目了，肯定要对底层的一些指标进行监控，监控内核。了解要学习的中间件</p><p>以及对一些性能怎么进行测试等等。通过此项目，将会让你对操作系统的掌握，更上一层楼</p><p><strong>同时有详细的学习路线、学习资料、学习代码、简历书写，以及面经</strong></p><p>如下图：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047378708" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047378709" alt="" title="" loading="lazy"/></p><h2>计算机网络项目</h2><p>作为另一个面试中被拷打的重点。大多数人对于网络的学习都是停留在传输层、应用层上。你学，他学，大家都学了，那怎么突出你掌握的深度，实现对其他人的降维打击呢。</p><p>那就往深的学，往底层的学。是不是可以学学底层协议呢，学学底层内核网络协议栈呢。</p><p>通过这个学习，你会了解内核中对协议的一些实现、以及用户态怎么与内核网络协议栈进行交互，以及怎么监控内核网络协议栈。对网络部分实现对同龄人甚至面试官的降维打击。</p><p>并且此项目也融合了AI的东西，引起了RAG技术，进行了多种RAG的实现方式。与AI结合，符合潮流</p><p><strong>同时有详细的学习路线、学习资料、学习代码、简历书写，以及面经</strong></p><p>如下图：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047378710" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047378711" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047378712" alt="" title="" loading="lazy"/></p><p>项目介绍文章：</p><p>项目介绍视频</p><p><a href="https://www.bilibili.com/video/BV1jbx2zgE7h/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=b7f84f9122e6cf826e5c747e473cb4f7" target="_blank">https://www.bilibili.com/video/BV1jbx2zgE7h/?spm_id_from=333....</a></p><h2>后端项目（AI智能云存储）</h2><p>很多学生学cpp，但是又要找后端岗位、服务端开发的工作。</p><p>这个时候就需要你有crud经验，作为一个cpp选手（cpp主要就是搞底层、 嵌入式的）。证明自己有后端经验，那最好的证明就是证明自己有个后端的项目</p><p>并且很多人学cpp，也是因为时间来不及，想速成。c++最大的优势就是可以学习较少的东西，就可以做出一份很不错的简历出来，投入到找工作行列中。（用少量的时间就可以达到找工作的要求）</p><p>但是简历项目必不可少，这个时候有个简单同时也有含金量的项目至关重要。</p><p>那就可以做个后端项目，比较简单。也有含金量，之前全程辅导23/24/25届的学生，单纯用这一个项目，并且用的还是基础版本（目前进行了一次迭代，新增了使用docker、k8s一键部署，以及也增加了AI的东西），就可以找到满意的工作。</p><p><strong>同时有详细的学习路线、学习资料、学习代码、简历书写，以及面经</strong></p><p>如下图：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047378704" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047378705" alt="" title="" loading="lazy"/></p><h2>游戏项目</h2><p>（和星球同学一起整理的分享给大家）</p><p>很多人学cpp可能是为了想找游戏相关的工作，但是苦于没有合适的项目，这里 给大家介绍两个项目。</p><p>一个是框架类的项目</p><p>一个是落地的项目</p><h3>分布式ECS游戏后端框架</h3><p>实现了一个游戏开发框架，一个黑盒子，底层框架，供游戏开发者使用。复用了很多功能</p><p>具体内容可以看下面的图片：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047378713" alt="" title="" loading="lazy"/></p><h3>游戏姿势识别项目</h3><p>从游戏开发应用、中间框架层、底层硬件封装、sdk调用，一条龙自主实现。</p><p>主打对整体的一个流通，可通各个层级岗位，万金油</p><p>如下图：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047378714" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047378715" alt="" title="" loading="lazy"/></p><h2>一站式编程平台项目</h2><p>此项目主要用于为大家编程学习，提供编程练习环境。带大家从小白一步一步蜕变成编程大牛，而不是一个只会背的八股选手</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047378717" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047378718" alt="" title="" loading="lazy"/></p><h2>qt项目</h2><p>正在研发中，争取年前上线</p><h2>其他收集的开源免费的基础项目</h2><p>免费开源给大家，不要被一些人忽悠，拿着这些开源项目说自研，忽悠大家，忽悠钱就算了。还忽哟大家把线程池、内存池当作项目，耽误大家前程。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047378719" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047378720" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047378721" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047378722" alt="" title="" loading="lazy"/></p><p>等等其他项目在开发中</p><h2>知识星球介绍（公认的cpp c++学习地）</h2><p>星球名字：奔跑中的cpp / c++</p><p>专注cpp/c++相关求职领域的辅导</p><p>加入星球福利，后续如果有其他活动、服务，不收费，不收费，可以合理赚钱就收取下星球费用，但是不割韭菜，保持初心</p><p>感兴趣的微信扫下面的码，然后下载知识星球app登录即可<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047528236" alt="" title="" loading="lazy"/></p><p>（1）高质量的项目合集<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507742" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507743" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507744" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507745" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507746" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507747" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507748" alt="" title="" loading="lazy"/></p><p>同时如果项目，遇到任何困惑也会第一时间进行解答的<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047508196" alt="" title="" loading="lazy"/></p><p>（2）高质量精确性八股资料<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507749" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507750" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507751" alt="" title="" loading="lazy"/></p><p>（3）详细的学习路线<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507752" alt="" title="" loading="lazy"/></p><p>（4）活跃的学习氛围，星球打卡不只是一个形式，而是每天观看，针对同学们的学习情况提出合理化的建议，<strong>同时也有高质量的星球微信内部群</strong><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507753" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507754" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507755" alt="" title="" loading="lazy"/></p><p>（5）星球提问简历修改，提供意见的同时，<strong>还会给安排一对一腾讯会议辅导</strong><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507756" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507757" alt="" title="" loading="lazy"/></p><p>（6）星球同学offer情况，以及对应学习情况，给大家提供参考<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507758" alt="" title="" loading="lazy"/></p><p>（7）全网最全cpp相关面经整理<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507759" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047507760" alt="" title="" loading="lazy"/></p><p>（8）编程实战能力提升平台（大家都可以使用的，免费的）</p><p>访问网址 cppagancoding.top<br/>  <img referrerpolicy="no-referrer" src="/img/remote/1460000047508197" alt="" title="" loading="lazy"/></p><p>星球同学的评价<br/>  <img referrerpolicy="no-referrer" src="/img/remote/1460000047508198" alt="" title="" loading="lazy"/></p><p>（9）每周也会进行直播答疑，同时有时也会给星球内部同学开一些知识、路线分享会。</p><p>具体可以看B站放的视频，up名字：cpp辅导的阿甘</p><p>（10）奖励金激励，会根据大家打卡学习/ 面经打卡整理情况，每个月每个季度发放奖励金。有的人陆陆续续已经获得了数千月的奖励金，是加入星球费用的数十倍了<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047528237" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047528238" alt="" title="" loading="lazy"/></p><p>等等，可能还有一些其他服务，目前没想起来的，以及后续也会增加的服务</p><p>本文由<a href="https://link.segmentfault.com/?enc=ZzJICyb6QLfRDHA%2Fs4R27w%3D%3D.DmFPBKKKN6iIgXYGOYx3HoxfgwA2Fg8lTdUzVIRKMfU%3D" rel="nofollow" target="_blank">mdnice</a>多平台发布</p>]]></description></item><item>    <title><![CDATA[喜报｜矩阵起源获InfoQ极客传媒2025年度技术生态构建品牌奖 MatrixOrigin ]]></title>    <link>https://segmentfault.com/a/1190000047560012</link>    <guid>https://segmentfault.com/a/1190000047560012</guid>    <pubDate>2026-01-23 10:05:52</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>1月21日，以“超越泡沫，开始构建”为主题的2026极客科技伙伴时刻圆满结束，该活动是极客邦科技一年一度的保留节目，旨在表彰过去一年中为技术生态发展与建设贡献突出力量的企业、团队和个人。</p><p>其中，矩阵起源凭借其在技术生态的深耕，获“2025年度技术生态构建品牌奖”。矩阵起源的坚持，让生态更具韧性与温度，为产业注入生生不息的动能。</p><p><img width="723" height="1305" referrerpolicy="no-referrer" src="/img/bVdnIGY" alt="" title=""/></p><p>作为行业的中坚力量，矩阵起源深知，生态建设的终局不是“独行”，而是“共赢”。这一奖项的背后，是我们专注连接开发者、用户与合作伙伴，推动技术普惠与可持续增长的坚定行动。面向未来，矩阵起源将继续秉持“构建者”的初心，在技术生态的深水区持续探索。我们希望通过更务实的行动与更开放的姿态，携手每一位生态伙伴，共同穿越周期，构建一个安全、高效、且充满活力的技术新生态。</p>]]></description></item><item>    <title><![CDATA[矩阵起源荣获 DataFun 星空奖双项大奖 | 科技领航，打造企业级数据智能新基建 MatrixO]]></title>    <link>https://segmentfault.com/a/1190000047560018</link>    <guid>https://segmentfault.com/a/1190000047560018</guid>    <pubDate>2026-01-23 10:04:53</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>1 月 16 日，在北京中关村展示中心会议中心举办的 DataFun 第三届 “星空奖” 颁奖现场，<strong>矩阵起源（Matrix Origin）</strong>凭借在数据智能基础设施领域的持续耕耘与实际应用成效，<strong>一举获评两项年度荣誉</strong>：「年度科技创新突破奖（Data + AI）」、「年度科技领航企业」。</p><h2>01 回归数据本质，解决 AI 落地“最后一公里”</h2><p>在企业智能化转型进入深水区的当下，AI 落地的核心挑战并非模型能力的匮乏，而是私域数据质量与处理链路的割裂。本次获评「年度科技创新突破奖（Data + AI）」的 MatrixOne Intelligence (MOI)，旨在为企业提供一套可控、可信的数据智能解决方案。</p><p>针对奖项关注的 “数据割裂” 与 “预测偏差” 等行业痛点，MOI 通过其超融合架构提供了务实的解决思路：</p><ul><li>统一数据底座：面对企业内部结构化与非结构化数据分散的现状，MOI 基于核心引擎 MatrixOne 的湖仓一体能力，实现了多模态数据的一站式存储与管理，避免了多套系统堆砌带来的运维复杂性与数据一致性风险。</li><li>工程化智能链路：MOI 将 AI 能力内嵌至数据处理全流程（MatrixPipeline）。通过向量化检索和前沿技术，有效提升了 RAG（检索增强生成）的召回准确率，从数据源头抑制大模型“幻觉”，确保输出结果通过企业合规风控标准。</li><li>闭环反馈机制：系统支持“数据 - 应用”的双向反馈，使模型能够随着业务数据的积累持续迭代，保障了系统在生产环境中的长期稳定性与可用性。</li></ul><p><img width="723" height="1035" referrerpolicy="no-referrer" src="/img/bVdnIHd" alt="" title=""/></p><h2>02 聚焦真实价值，做企业可信赖的合作伙伴</h2><p>唯有经得起真实业务场景检验的技术，才具备长久的生命力。</p><p>获评「年度科技领航企业」，是对矩阵起源在自主知识产权积累、产品成熟度及客户服务能力上的综合评价。面对金融、制造、医疗等行业对数据安全与业务连续性的严苛要求，矩阵起源始终坚持以客户价值为导向。</p><p>目前，我们的解决方案已在多个关键行业完成了落地验证：在医疗领域，我们协助三甲医院构建高精度对话与辅助诊断模型，显著提升 IBS 的初诊效率与诊断准确性；在高端制造领域，我们帮助企业优化供应链决策流程，大幅提升标书制作与合规校验效率……</p><p>这些一线场景的实践成果，不仅印证了产品的高可用性，也是我们致力于成为企业构建数智化能力坚实基石的有力证明。</p><p><img width="723" height="1035" referrerpolicy="no-referrer" src="/img/bVdnIHc" alt="" title="" loading="lazy"/></p><h2>03 结语</h2><p>行业专家的专业认可、客户的长期信赖，是我们持续成长的动力。面向未来，我们将继续秉持初心，打磨产品内核，优化服务体系。我们希望通过务实的技术创新，携手生态伙伴，协助更多企业解决数据难题，构建安全、高效、可持续演进的智能化体系。</p>]]></description></item><item>    <title><![CDATA[【k8s部署】麒麟V10离线安装k8s1.32.11 天行1st ]]></title>    <link>https://segmentfault.com/a/1190000047560120</link>    <guid>https://segmentfault.com/a/1190000047560120</guid>    <pubDate>2026-01-23 10:03:55</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>本文以<code>麒麟V10</code>为例，演示超简单离线部署<code>k8s 1.32.11</code>。</p><h2>1 说明</h2><h3>关于kt</h3><p><code>kt</code>是基于<code>kk</code>二次开发产物，具备<code>kk</code>的所有功能，二开重点适配了信创国产化环境。</p><p>主要改进包括：简化<code>arm</code>架构部署过程、支持国产化和国际环境在线、离线部署及<code>一条命令所有节点初始化</code>。</p><p>支持<code>arm64</code>和<code>amd64</code>架构操作系统，已适配芯片+操作系统 如下：</p><ul><li><strong>CPU：</strong> 鲲鹏、飞腾、海光、兆芯、intel、amd 等。</li><li><strong>OS：</strong> Centos、Ubuntu、Debian、银河麒麟V10、麒麟国防版、麒麟信安、中标麒麟V7、统信UOS、华为欧拉、移动大云、阿里龙蜥、TencentOS等。</li></ul><p>注：本文使用kt版本<code>3.1.13</code></p><ul><li><strong>kt文档：</strong> <a href="https://link.segmentfault.com/?enc=uKMTAG%2BAyTf7HEqP%2FM6v7Q%3D%3D.s2jP840NJGp0f9F3QZko1ycNg3G1iXIYUvldB6N8cR0%3D" rel="nofollow" title="kt文档" target="_blank">kt文档</a></li></ul><h2>2.环境准备</h2><p><strong>服务器基本信息</strong></p><table><thead><tr><th><strong>主机名</strong></th><th><strong>架构</strong></th><th><strong>OS</strong></th><th><strong>配置</strong></th><th><strong>IP</strong></th></tr></thead><tbody><tr><td>master</td><td>x86_64</td><td>麒麟V10</td><td>2核4G</td><td>192.168.85.153</td></tr></tbody></table><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560123" alt="" title=""/></p><h3>2.1 上传离线制品</h3><p>操作系统不需要安装docker,不需要设置selinux,swap等操作，全新的操作系统即可。</p><p>将离线制品、配置文件、kt和sh脚本上传至服务器其中一个节点(本文以master为例)，后续在该节点操作创建集群。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560124" alt="" title="" loading="lazy"/></p><h3>2.2 修改配置文件</h3><p>根据实际服务器信息，配置到生成的<code>config-sample.yaml</code>中</p><pre><code class="plain">kind: Cluster
metadata:
  name: sample
spec:
  hosts:
  - {name: master, address: 192.168.85.160, internalAddress: 192.168.85.143, user: root, password: "123123"}
  roleGroups:
    etcd:
    - master
    control-plane:
    - master
    worker:
    - master
    # 如需使用 kk 自动部署镜像仓库，请设置该主机组 （建议仓库与集群分离部署，减少相互影响）
    # 如果需要部署 harbor 并且 containerManager 为 containerd 时，由于部署 harbor 依赖 docker，建议单独节点部署 harbor
    registry:
    - master
  controlPlaneEndpoint:
    ## Internal loadbalancer for apiservers 
    internalLoadbalancer: haproxy

    domain: lb.kubesphere.local
    address: ""
    port: 6443
  kubernetes:
    version: v1.32.11
    clusterName: cluster.local
    autoRenewCerts: true
    containerManager: docker
  etcd:
    type: kubekey
  network:
    plugin: calico
    kubePodsCIDR: 10.233.64.0/18
    kubeServiceCIDR: 10.233.0.0/18
    ## multus support. https://github.com/k8snetworkplumbingwg/multus-cni
    multusCNI:
      enabled: false
  registry:
    type: harbor
    registryMirrors: []
    insecureRegistries: []
    privateRegistry: "dockerhub.kubekey.local"
    namespaceOverride: "kubesphereio"
    auths: # if docker add by `docker login`, if containerd append to `/etc/containerd/config.toml`
      "dockerhub.kubekey.local":
        username: "admin"
        password: Harbor@123 # 此处可自定义，kk3.1.8新特性
        skipTLSVerify: true # Allow contacting registries over HTTPS with failed TLS verification.
        plainHTTP: false # Allow contacting registries over HTTP.
        certsPath: "/etc/docker/certs.d/dockerhub.kubekey.local"
  addons: []</code></pre><h2>2.3 系统初始化</h2><p>解压<code>kt-x86.tar.gz</code>文件后执行<code>./kt init-os -f config-sample.yaml</code> 已适配操作系统和架构见<code>1.说明</code></p><p>该命令<code>kt</code>会根据配置文件自动判断操作系统和架构以完成所有节点的初始化配置和依赖安装。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560125" alt="" title="" loading="lazy"/></p><h2>3 创建 Harbor私有仓库</h2><h3>3.1 创建镜像仓库</h3><pre><code class="plain">./kt init registry -f config-sample.yaml -a artifact-x86-k8s13211.tar.gz</code></pre><p>此命令会在<code>harbor</code>节点自动安装<code>docker</code>和<code>docker-compose</code></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560126" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560127" alt="" title="" loading="lazy"/></p><h3>3.2 创建harbor项目</h3><p>创建 Harbor 项目</p><pre><code class="plain">chmod +x create_project_harbor.sh &amp;&amp; ./create_project_harbor.sh</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560128" alt="" title="" loading="lazy"/></p><h2>4 创建k8s</h2><pre><code class="plain">./kt create cluster -f config-sample.yaml -a artifact-x86-k8s13211.tar.gz --with-local-storage</code></pre><p>此命令<code>kt</code>会自动将离线制品中的镜像推送到<code>harbor</code> 私有仓库</p><p>执行后会有如下提示,输入<code>yes/y</code>继续执行</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560129" alt="" title="" loading="lazy"/></p><p>继续等待一段时间最终可以看到安装成功的消息</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560130" alt="" title="" loading="lazy"/></p><p>验证</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560131" alt="" title="" loading="lazy"/></p><h2>5 总结</h2><p>本文主要以离线方式部署，适用于在线和离线两种状态，而如果在线状态，那么步骤3可忽略，两条命令即可搞定。</p><p>配合最新版kt，系统初始化从未如此简单，不论<code>x86</code>还是<code>arm</code>，不论在线还是离线，不论国际还是国产操作系统，统统搞定。</p>]]></description></item><item>    <title><![CDATA[玩转OurBMC第二十七期：BMC POST CODE解读 OurBMC ]]></title>    <link>https://segmentfault.com/a/1190000047560165</link>    <guid>https://segmentfault.com/a/1190000047560165</guid>    <pubDate>2026-01-23 10:03:04</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>【栏目介绍：“玩转OurBMC” 是OurBMC社区开创的知识分享类栏目，主要聚焦于社区和BMC全栈技术相关基础知识的分享，全方位涵盖了从理论原理到实践操作的知识传递。OurBMC社区将通过 “玩转OurBMC” 栏目，帮助开发者们深入了解到社区文化、理念及特色，增进开发者对BMC全栈技术的理解。</p><p>欢迎各位关注 “玩转OurBMC” 栏目，共同探索OurBMC社区的精彩世界。同时，我们诚挚地邀请各位开发者向 “玩转OurBMC” 栏目投稿，共同学习进步，将栏目打造成为汇聚智慧、激发创意的知识园地。】</p><p><strong>Power-On Self-Test Code(上电自检代码)是计算机系统在启动过程中执行硬件诊断和初始化的关键技术机制｡该技术通过两位十六进制代码实时反映系统固件对各个硬件组件的检测状态,为系统启动提供可视化的进度指示和故障定位能力｡</strong></p><h2>01 POST 流程与UEFI 启动的融合演进</h2><h3>01 传统POST自检流程</h3><p>传统POST自检流程已经被嵌入现代UEFI启动框架中,其执行链路可分为以下五层次阶段:</p><p><strong>阶段1：处理器与芯片组初始化</strong></p><ul><li>电源序列验证与稳定监控</li><li>CPU核心复位与微码加载</li><li>时钟网络同步校准</li><li>温度监控传感器初始化</li></ul><p><strong>阶段2：内存子系统检测</strong></p><ul><li>DIMM模块识别与SPD数据读取</li><li>内存控制器配置与训练</li><li>信号完整性优化（读写时序校准）</li><li>ECC功能验证与内存测试</li></ul><p><strong>阶段3：基础输入输出系统初始化</strong></p><ul><li>芯片组功能单元配置</li><li>PCIe根复合体与端口初始化</li><li>集成外设控制器（SATA、USB）启用</li></ul><p><strong>阶段4：扩展设备枚举</strong></p><ul><li>PCIe拓扑扫描与资源分配</li><li>选项ROM加载与认证</li><li>设备驱动初始化</li></ul><p><strong>阶段5：引导加载程序执行</strong></p><ul><li>启动设备选择与初始化</li><li>操作系统加载器验证</li><li>系统控制权转移</li></ul><p>其完整执行路径可通过以下流程图展示</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560167" alt="92869296e9dd2e127ce5386e80a488ce.png" title="92869296e9dd2e127ce5386e80a488ce.png"/></p><p>图1 上电自检流程图</p><h3>02 UEFI启动框架中的POST映射</h3><p><strong>SEC（安全验证）阶段</strong></p><ul><li>UEFI流程：这是芯片上电后第一个执行的阶段，负责处理CPU复位、初始化微码、进入受保护模式，并验证下一阶段代码的完整性。</li><li>对应的POST任务：这相当于最早期的、内存尚未初始化前的POST，主要完成CPU的初步初始化。此时会生成早期的POST Code。</li></ul><p><strong>PEI（EFI前初始化）阶段</strong></p><ul><li>UEFI流程：此阶段内存尚未可用或正在被初始化，因此代码在缓存中运行。它的核心任务是初始化内存控制器和内存（Memory Reference Code, MRC）。</li><li>对应的POST任务：这是POST最核心、最耗时的部分。内存的检测、训练（Training）、配置都在此完成。此时会生成关键的POST Code。BMC密切监控这一阶段。</li></ul><p><strong>DXE（驱动执行环境）阶段</strong></p><ul><li>UEFI流程：内存可用后，进入此阶段。DXE调度程序会加载并执行大量的驱动程序（DXE Driver），来初始化所有其他硬件，如芯片组、PCIe总线、存储控制器、网络接口等。</li><li>对应的POST任务：这相当于传统的芯片组初始化、PCIe设备枚举、选项ROM加载等POST任务。每个DXE驱动程序的成功加载和执行，都可能对应一个或多个POST Code。</li></ul><p><strong>操作系统加载器执行</strong></p><ul><li>UEFI流程：所有硬件就绪后，UEFI固件通过Boot Manager选择并启动操作系统的加载器（如GRUB， Windows Boot Manager）。</li><li>对应的POST任务：传统上，这被认为是POST的结束，系统控制权移交给操作系统。通过发送对应POST命令告诉BMC操作系统已经被引导。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560168" alt="069a3c6ee7eb1688b063b3d5f04afcea.jpg" title="069a3c6ee7eb1688b063b3d5f04afcea.jpg" loading="lazy"/></p><p>图2 UEFI启动流程图</p><p> 注：上图引用&lt; UEFI Platform Initialization Specification, Release 1.9&gt;</p><h2>02 关键技术机制深度解析</h2><h3>01 传输机制</h3><p>硬件层面实现: POST Code通过专用的80h端口（传统架构）或内存映射I/O（现代架构）进行传输。</p><h3>02 智能错误处理与恢复策略</h3><p><strong>分级错误管理</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560169" alt="image.png" title="image.png" loading="lazy"/></p><p><strong>高级诊断功能：</strong></p><ul><li>模式识别：通过代码序列模式预测潜在故障</li><li>性能分析：基于时间戳的启动性能优化</li><li>趋势预测：长期代码统计分析预测硬件寿命</li></ul><h3>03 BMC联动与可视化监控</h3><p>硬件上BMC通过PCIe、eSPI、LPC等总线与主机连接。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560170" alt="09134090d8edd87292e9e2550a197746.png" title="09134090d8edd87292e9e2550a197746.png" loading="lazy"/></p><p>图3 硬件连接图</p><p><strong>BMC可实时捕获并解码服务器发送的POST Code流，实现：</strong></p><ul><li>状态可视化：在Web界面或CLI中实时显示启动进度</li><li>故障告警：根据错误等级提供声光、日志、通知等多级提示</li><li>远程诊断：支持运维人员远程查看启动状态，辅助快速定位问题</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047560171" alt="5fe3822e1d45146e7362b14d35fa435c.png" title="5fe3822e1d45146e7362b14d35fa435c.png" loading="lazy"/></p><p>图4 信息交互图</p><p><strong>03 技术优势与价值体现</strong></p><p><strong>运维效率提升</strong></p><ul><li>故障定位时间减少</li><li>平均修复时间(MTTR)降低</li><li>首次修复成功率提升</li></ul><p><strong>系统可靠性增强</strong></p><ul><li>预防性维护覆盖率提升</li><li>硬件故障提前预警</li><li>系统可用性达到提高</li></ul><p><strong>运维成本优化</strong></p><ul><li>减少现场服务需求</li><li>降低备件库存成本</li><li>延长设备使用寿命</li></ul><p><strong>欢迎大家关注OurBMC社区，了解更多BMC技术干货。</strong></p><p><strong>OurBMC社区官方网站：</strong></p><p><a href="https://link.segmentfault.com/?enc=hUsdXlpwhmLy%2Bxt2ZopTkg%3D%3D.ykV%2Bh934hZBSPlJMO9wrPYZQ0JfAxk541VF3VAW5cLM%3D" rel="nofollow" target="_blank">https://www.ourbmc.cn/</a></p>]]></description></item><item>    <title><![CDATA[网站被提示“不安全”怎么解决 才高八斗的杯子_dS2Fpp ]]></title>    <link>https://segmentfault.com/a/1190000047560187</link>    <guid>https://segmentfault.com/a/1190000047560187</guid>    <pubDate>2026-01-23 10:02:16</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>当用浏览器访问某个网站时，如果浏览器显示“不安全”警告，这往往会立即引起用户的警惕，还可能会流失客户。</p><h4><strong>一、网站被提示“不安全”的原因</strong></h4><h5>1. 证书自身问题（最常见）</h5><ul><li><strong>已过期</strong>：证书有明确的有效期（通常为1年，最长为13个月）。过期后，“门锁”自动失效，需要续期。</li><li><strong>域名不匹配</strong>：证书是为 <code>www.example.com</code> 签发，但你访问的是 <code>example.com</code> 或 <code>shop.example.com</code>。这是配置时的常见疏忽。</li><li><strong>签发机构不受信任</strong>：证书并非来自浏览器和操作系统信任的根证书列表中的CA。一些自签名证书或企业内部CA签发的证书会触发此警告。</li></ul><h5>2. 服务器配置问题</h5><ul><li><strong>证书链不完整</strong>：服务器没有正确安装中间证书，导致浏览器无法验证证书的完整信任链。</li><li><strong>使用了不安全的加密协议</strong>：服务器仍支持已被废弃的弱加密算法（如SSL 2.0/3.0， TLS 1.0）。</li></ul><h5>3. 网络环境问题（最危险）</h5><ul><li><strong>中间人攻击</strong>：你所在的网络（如公共Wi-Fi）可能存在恶意攻击者，他试图在你和目标网站之间插入自己的伪证书，以窃取你的数据。浏览器发现证书被篡改或无法验证，会发出强烈警告。</li></ul><p><img width="723" height="286" referrerpolicy="no-referrer" src="/img/bVdnIJW" alt="" title=""/></p><h4><strong>二、解决方案如下</strong></h4><h3><a href="https://link.segmentfault.com/?enc=mbEI1ILT%2Bx4Usmh3oPSEcg%3D%3D.9ot18jHlff1nyqk3VhXgs0ZLfKZff8J9sstx0Wm1tGrOXQA%2BEGm2qdIbCNV%2FZGHRSSXMAvQl2snlCCyBp7m46g%3D%3D" rel="nofollow" target="_blank"><strong>免费SSL证书申请入口</strong></a></h3><p><strong>1.访问JoySSL官网并注册账号</strong></p><p>首先，登录<strong>JoySSL</strong>的官方网站，并注册一个账号。在注册过程中，务必填写特定的<strong>230970</strong>注册码才获取免费SSL证书的申请权限。</p><p><strong>2.选择证书类型</strong></p><p>登录JoySSL账号后，根据您的需求选择适合的SSL证书并0元下单支付。</p><p><strong>3.填写申请信息</strong></p><p>按照页面提示填写申请信息，包括域名信息、联系信息等。</p><p><strong>4.验证域名所有权</strong></p><p>完成信息填写后，JoySSL将要求您验证域名所有权。这通常通过域名DNS验证或服务器文件验证方式来完成。</p><p><strong>5. 部署证书</strong></p><p>验证后，10分钟左右签发，签发后，下载证书文件，将其部署到相应服务器上。</p><p><strong>6. 测试证书</strong></p><p>访问网站，检查是否实现HTTPS访问以及地址栏上有绿色的安全锁。</p>]]></description></item><item>    <title><![CDATA[《ESP32-S3使用指南—IDF版 V1.6》第六十四章 LVGL 综合例程 正点原子 ]]></title>    <link>https://segmentfault.com/a/1190000047560189</link>    <guid>https://segmentfault.com/a/1190000047560189</guid>    <pubDate>2026-01-23 10:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>第六十四章 LVGL 综合例程</h2><p>本章，简单的介绍一下DNESP32S3开发板的 LVGL 综合例程。需要说明一下的是：本例程是一个不完整的例程。因为该例程只是实现一个基于 LVGL 的 GUI 界面，里面的 APP<br/>基本没有实现功能，所以这只是给大家参考的 GUI demo。<br/>实现这样简单的 GUI demo 原因如下：<br/>1， 板载的2.4寸TFTLCD并未具备触摸条件，所以设计UI时受到很大的制约。<br/>2， 想做出一个 LVGL 综合例程给大家参考，但时间比较赶。<br/>3， 要实现一个不错的 LVGL 综合例程，要花费不少精力。<br/>4， 要考虑板载资源，兼容性等。<br/>5， 工程师们手头的事情比较多，等后续空闲些再规划。<br/>大家可以把自己期待的 LVGL 界面、功能等，通过各种渠道跟我们沟通，比如：B 站视频评论区，销售客户/技术支持等。后续有时间，我们会把大家的建议都考虑上去的。最后，敬请大家心怀一个小小的期待，期待正点原子的 LVGL 综合例程，感谢大家的支持！！！<br/>本章将分为如下 2 个小节：</p><p>64.1 LVGL 综合例程注意事项<br/>64.2 LVGL 综合例程界面展示</p><h3>64.1 LVGL 综合例程注意事项</h3><p>注意事项如下：<br/>1，DNESP32S3开发板的LVGL综合例程只支持正点原子的2.4寸 TFTLCD屏。其它屏幕会出现图标显示异常。<br/>2，所用的LVGL版本是V8.2。<br/>3，需要准备一张TF卡，将A盘资料的SD卡根目录文件复制到TF卡根目录当中，SD卡根目录文件如下图所示。<br/><img width="387" height="171" referrerpolicy="no-referrer" src="/img/bVdnGNo" alt="" title=""/><br/>图64.1.1 拷贝资料到TF卡当中<br/>图64.1.2展示的是LVGL例程界面所用到的 bin 文件。LVGL 综合例程会将这些bin文件拷贝到16MB Flash分区表的storage子分区表备份，方便GUI界面读取。如果直接从TF卡中读取，速度会比较慢，影响 GUI 的流畅性。<br/><img width="485" height="272" referrerpolicy="no-referrer" src="/img/bVdnGNp" alt="" title="" loading="lazy"/><br/>图 64.1.2 LVGL例程界面所用到的bin文件</p><h3>64.2 LVGL 综合例程界面展示</h3><p><img width="723" height="386" referrerpolicy="no-referrer" src="/img/bVdnGNq" alt="" title="" loading="lazy"/><br/>图64.2.1 GUI主界面和视频播放器界面<br/><img width="723" height="387" referrerpolicy="no-referrer" src="/img/bVdnGNr" alt="" title="" loading="lazy"/><br/>图64.2.2 图片浏览界面和计算机界面<br/>由于DNESP32S3开发板的2.4寸TFTLCD显示屏未具备触摸条件，所以作者只能实现一些简单的APP应用。</p>]]></description></item><item>    <title><![CDATA[Skills 与延迟加载工具定义的 MCP，目前哪个更高效、稳定和可控？ Baihai_IDP ]]></title>    <link>https://segmentfault.com/a/1190000047560110</link>    <guid>https://segmentfault.com/a/1190000047560110</guid>    <pubDate>2026-01-23 09:01:59</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <blockquote><p><strong>编者按：</strong> 我们今天为大家带来的这篇文章，作者的核心观点是：相较于依赖复杂且高成本的动态 MCP 工具加载机制，以 Skills 为核心的能力摘要与自维护模式，在当前阶段反而更加高效、稳定且可控。</p><p>文章系统梳理了延迟工具加载（deferred tool loading）的工程现实与限制，指出即便工具可以延后注入，对话级别的工具集合仍然是静态的，且发现机制高度依赖正则匹配，收益并不如预期。作者进一步深入分析了 MCP 在上下文占用、API 稳定性、缓存失效与推理轨迹丢失等方面带来的隐性成本，并结合 Sentry MCP、Playwright 等实践案例，说明为何将 MCP 转换为 Skills，反而能让 Agent 更好地发挥既有工具的能力。文章最后还探讨了 MCP 是否可能完全转化为 Skills 的可行性，并坦率指出当前协议与生态在稳定性与摘要机制上的不足。</p></blockquote><p><strong>作者 |</strong> <strong>Armin Ronacher</strong></p><p><strong>(作者为 Flask、Jinja2 等开源项目的创建者)</strong></p><p><strong>编译 | 岳扬</strong></p><p>我正把所有的 MCP 都迁移到 Skills 上，包括之前还在使用的最后一个：Sentry MCP（译者注：Sentry 是流行的应用监控与错误追踪平台）。早前我就已经完全弃用 Playwright（译者注：由 Microsoft 开发的现代 Web 自动化测试和浏览器自动化框架），转向使用 Playwright Skill。</p><p>过去一个月左右，关于使用“动态工具配置（dynamic tool loadouts）[1]”来推迟工具定义的加载的讨论一直不少。Anthropic 也在探索通过代码来串联 MCP 调用的思路，这一点我也尝试过[2]。</p><p>我想分享一下自己在这方面的最新心得，以及为什么 Anthropic 提出的“延迟工具加载方案（deferred tool loading）”并未改变我对 MCP 的看法。或许这些内容对他人会有所帮助。</p><h2><strong>01 什么是工具（Tool）？</strong></h2><p>当 Agent 通过强化学习或其他方式接触到工具定义时，它会被鼓励在遇到适合使用该工具的场景时，通过特殊的 token 输出工具调用。实际上，工具定义只能出现在系统提示词（system prompt）中特定的工具定义 token 之间。从历史经验来看，这意味着我们无法在对话状态的中途动态发出新的工具定义。因此，唯一的现实选择是在对话开始时就将工具加载好。</p><p>在智能体应用场景中，我们当然可以随时压缩对话状态，或更改系统消息中的工具定义。但这样做的后果是，我们会丢失推理轨迹（reasoning traces）以及缓存（cache）。以 Anthropic 为例，这将大幅增加对话成本：基本上就是从头开始，相比于缓存读取，需要支付完整的 token 费用，外加缓存写入成本。</p><p>Anthropic 最近的一项创新是“延迟工具加载”（deferred tool loading）。我们仍然需要提前在系统提示词（system message）中声明工具，但这些工具不会在系统提示词发出时就注入到对话中，而是会稍后才出现。不过据我所知，<strong>这些工具定义在整个对话过程中仍必须是静态的 —— 也就是说，哪些工具可能存在，是在对话开始时就确定好的。</strong> Anthropic 发现这些工具的方式，纯粹是通过正则表达式（regex）搜索实现的。</p><h2><strong>02 与 Skills 的对比</strong></h2><p>尽管带延迟加载的 MCP 感觉上应该表现更优，实际上却需要在 LLM API 端做不少工程化工作。而 Skills 系统完全不需要这些，至少从我的经验来看，其表现依然更胜一筹。</p><p><strong>Skills 实质上只是对现有能力及其说明文件位置的简短摘要。这些信息会被主动加载到上下文中。</strong> 因此，智能体能在系统上下文里（或上下文的其他位置）知晓自己具备哪些能力，并获知如何使用这些能力的“手册链接”。</p><p>关键在于，<strong>Skills 并不会真正把工具定义加载到上下文中。</strong> 可用工具保持不变：bash 以及智能体已有的其他工具。Skills 所能提供的，只是如何更高效使用这些工具的技巧和方法。</p><p>由于 Skills 主要教的是如何使用其他命令行工具和类似实用程序，因此组合与协调这些工具的基本方式其实并未改变。让 Claude 系列模型成为优秀工具调用者的强化学习机制，恰好能帮助处理这些新发现的工具。</p><h2><strong>03 MCP 能否转换为 Skills？</strong></h2><p>这自然引出了一个问题：既然 Skills 效果这么好，我能不能把 MCP 完全移出上下文，转而像 Anthropic 提议的那样，通过 CLI 来调用它？答案是：可以，但效果并不好。Peter Steinberger 的 mcporter[3] 就是其中一种方案。简单来说，它会读取 .mcp.json 文件，并将背后的 MCP 暴露为可调用的工具：</p><pre><code>npx mcporter call 'linear.create_comment(issueId: "ENG-123", body: "Looks good!")'</code></pre><p>确实，它看起来非常像一个 LLM 可以调用的命令行工具。但问题在于，LLM 根本不知道有哪些工具可用 —— 现在你得专门教它。于是你可能会想：那为什么不创建一些 Skills，来教 LLM 了解这些 MCP 呢？对我而言，这里的问题在于：<strong>MCP 服务器根本没有维持 API 稳定性的意愿。它们越来越倾向于将工具定义精简到极致，只为节省 token。</strong> 这种做法有其道理，但对 Skills 模式来说却适得其反。举个例子，Sentry MCP 服务器曾彻底将查询语法切换为自然语言。这对 Agent 来说是一次重大改进，但我之前关于如何使用它的建议反而成了障碍，而且我没能第一时间发现问题。</p><p>这其实和 Anthropic 的“延迟工具加载方案”非常相似：上下文中完全没有任何关于该工具的信息，我们必须手动创建一份摘要。我们过去对 MCP 工具采用的预加载（eager loading）方式，如今陷入了一个尴尬的局面：<strong>描述既太长，不便预加载；又太短，无法真正教会 Agent 如何使用它们。</strong> 因此，至少从我的经验来看，你最终还是得为通过 mcporter 或类似方式暴露出来的 MCP 工具，手动维护这些 Skills 摘要。</p><h2><strong>04 最省事的路线</strong></h2><p>这让我得出了目前的结论：<strong>我倾向于选择最省事的方式，也就是让 Agent 自己以“Skills”的形式编写所需的工具。</strong> 这样做不仅耗时不多，最大的好处还在于工具基本处于我的掌控之中。每当它出问题或需要新增功能时，我就让 Agent 去调整它。Sentry MCP 就是个很好的例子 —— 我认为它可能是目前设计得最好的 MCP 之一，但我已经不再使用它了。一方面是因为一旦在上下文中立即加载它，就会直接消耗约 8k 个 token；另一方面，我也一直没能通过 mcporter 让它正常工作。现在我让 Claude 为我维护一个对应的 Skill。没错，这个 Skill 可能有不少 bug，也需要不断更新，但由于是 Agent 自己维护的，整体效果反而更好。</p><p>当然，这一切很可能在未来发生变化。但就目前而言，手动维护的 Skills，以及让 Agent 自行编写工具，已成为我的首选方式。<strong>我推测，基于 MCP 的动态工具加载终将成为主流，但要实现这一点，可能还需要一系列协议层面的改进，以便引入类似 Skills 的摘要机制，以及为工具内置使用手册。</strong> 我也认为，MCP 如果能具备更强的协议稳定性，将大有裨益。目前 MCP 服务器随意更改工具描述的做法，与那些已经固化下来的调用方式（materialized calls）以及在 README 和技能文件中编写的外部工具说明很难兼容。</p><p><strong>END</strong></p><p><strong>本期互动内容 🍻</strong></p><p><strong>❓抛开现有方案，你理想中的AI工具调用范式应该长什么样？用一句话描述你最核心的需求。</strong></p><p><strong>文中链接</strong></p><p>[1]<a href="https://link.segmentfault.com/?enc=3Q00vCNgfa8RkZXzEqfaFg%3D%3D.U3r%2BxNvRWuGNK8stXMW6hK0IqrfJYgNfW9itRWy65WhvmBtFMtAtPuUkqXexAkVott3pptaRqPlBLJov%2Btkg%2BQ%3D%3D" rel="nofollow" target="_blank">https://www.anthropic.com/engineering/advanced-tool-use</a></p><p>[2]<a href="https://link.segmentfault.com/?enc=2kldzHxYidNBCnZu%2F4Y2vg%3D%3D.HH1ihPnnBdQQX8NtsKc2pUl3nx%2FhGklIu5sMNVe4v080RVLA36H33JR%2Bg5Oqjrr2" rel="nofollow" target="_blank">https://lucumr.pocoo.org/2025/7/3/tools/</a></p><p>[3]<a href="https://link.segmentfault.com/?enc=qM1I5KSJ9%2BAxBbQn2k%2F5HQ%3D%3D.0NA6YgE1dGXj2XkNqoknLGwHjM69TB%2F135KnfWR20sirpzd392R6Y7vqb2d6qNUh" rel="nofollow" target="_blank">https://github.com/steipete/mcporter</a></p><p><strong>原文链接：</strong>  </p><p><a href="https://link.segmentfault.com/?enc=q6YWdsWWLDCuxeyCdsOtwA%3D%3D.Kqr%2BcMdvJkiSB9fsx17%2Bpv61u7CyeaGoG5BNUZEwyDIwnMnT2LDPQYfiZjcOOeLkx4ADAlaFqrdWalUuyvBPgg%3D%3D" rel="nofollow" target="_blank">https://lucumr.pocoo.org/2025/12/13/skills-vs-mcp/</a></p>]]></description></item><item>    <title><![CDATA[Queue & Stack：实现机制与使用场景深度分析 SevenCoding ]]></title>    <link>https://segmentfault.com/a/1190000047548938</link>    <guid>https://segmentfault.com/a/1190000047548938</guid>    <pubDate>2026-01-23 09:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>为什么不推荐使用Stack</h2><p>Java已不推荐使用Stack，而是推荐使用更高效的ArrayDeque</p><h3>为什么不推荐使用</h3><ul><li>性能低：是因为 Stack 继承自 Vector， 而 Vector 在每个方法中都加了锁。由于需要兼容老的项目，很难在原有的基础上进行优化，因此 Vector 就被淘汰掉了，使用 <a href="https://link.segmentfault.com/?enc=7FS5CaWT2i440DsKjQVwgw%3D%3D.TU%2F4IAs%2FycQnKu8yLN%2BGM509fA8ycAERlHGRxVGHZ0kznv3ptDbITUbl%2BCdZ8O50r0DGtPLfn4CgBtyHpNL4IDUFgspUhoxpNTGBd7O6Flw%3D" rel="nofollow" target="_blank">ArrayList</a> 和 <a href="https://link.segmentfault.com/?enc=y2oMYDwyRQ%2BJA0S0WlSZLg%3D%3D.4TboKl%2BSpGqPqKEDVAnhwn9ZFD89%2BLQ%2FwjQdIAsXWKbVEafdZ%2BTDAishwaTxlbvp6Te2ryh8Lnu7nYSS%2FHRGoSc%2B%2FmTL4kAwh4VIX8zLLs0%3D" rel="nofollow" target="_blank">CopyOnWriteArrayList</a> 来代替，如果在非线程安全的情况下可以使用  <a href="https://link.segmentfault.com/?enc=Kv8uR2P6BoSSfS0K49snYQ%3D%3D.e68eIRsFuESqL4lpRUWXAS5ZDKh5hNLskxDf%2FjjV1pGdgMaIEL2JvmoNRGcFyfLrs8%2FuDhLRsgNE%2F8M4siptbj1a6Z5%2FuVDrxfG%2FFt7tAnw%3D" rel="nofollow" target="_blank">ArrayList</a>，线程安全的情况下可以使用 <a href="https://link.segmentfault.com/?enc=hks1aQHfAHYbGEvy7DI5nQ%3D%3D.9gCzGzYHN7hMQVPTM4BkwdCpCU8QNIlDNMcLRQnaRxwrVI1EIDV5A8%2B75qVCNgqk2dx1oTcIKBgtZQHFVQAkWBajF98VBIkZf%2FhiwCXc8G4%3D" rel="nofollow" target="_blank">CopyOnWriteArrayList</a> 。</li><li>破坏了原有的数据结构：栈的定义是在一端进行 push 和 pop 操作，除此之外不应该包含其他 入栈和出栈 的方法，但是 Stack 继承自 Vector，使得 Stack 可以使用父类 Vector 公有的方法。</li></ul><h3>为什么现在还在用</h3><p>但是为什么还有很多人在使用 Stack。总结了一下主要有两个原因。</p><ul><li>JDK 官方是不推荐使用 Stack，之所以还有很多人在使用，是因为 JDK 并没有加 deprecation 注解，只是在文档和注释中声明不建议使用，但是很少有人会去关注其实现细节</li><li>在笔试面试需要做算法题的时候，更多关注点是在解决问题的算法逻辑思路上，并不会关注在不同语言下 Stack 实现细节，但是对于使用 Java 语言的业务开发者，不仅需要关注算法逻辑本身，也需要关注它的实现细节</li></ul><h3>为什么推荐使用 Deque 接口替换栈</h3><p>如果 JDK 不推荐使用 Stack，那应该使用什么集合类来替换栈，一起看看官方的文档。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000045396408" alt="" title=""/></p><p>正如图中标注部分所示，栈的相关操作应该由 Deque 接口来提供，推荐使用 Deque 这种数据结构， 以及它的子类，例如 ArrayDeque。</p><pre><code class="java">val stack: Deque&lt;Int&gt; = ArrayDeque()</code></pre><p>使用 Deque 接口来实现栈的功能有什么好处：</p><ul><li>速度比 Stack 快</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000045396409" alt="" title="" loading="lazy"/></p><p>这个类作为栈使用时可能比 Stack 快，作为队列使用时可能比 LinkedList 快。因为原来的 Java 的 Stack 继承自 Vector，而 Vector 在每个方法中都加了锁，而 Deque 的子类 ArrayDeque 并没有锁的开销。</p><ul><li>屏蔽掉无关的方法</li></ul><p>原来的 Java 的 Stack，包含了在任何位置添加或者删除元素的方法，这些不是栈应该有的方法，所以需要屏蔽掉这些无关的方法。声明为 Deque 接口可以解决这个问题，在接口中声明栈需要用到的方法，无需管子类是如何是实现的，对于上层使用者来说，只可以调用和栈相关的方法。</p><h3>Stack 和 ArrayDeque的 区别</h3><table><thead><tr><th>集合类型</th><th>数据结构</th><th>是否线程安全</th></tr></thead><tbody><tr><td>Stack</td><td>数组</td><td>是</td></tr><tr><td>ArrayDeque</td><td>数组</td><td>否</td></tr></tbody></table><p>Stack 常用的方法如下所示：</p><table><thead><tr><th>操作</th><th>方法</th></tr></thead><tbody><tr><td>入栈</td><td>push(E  item)</td></tr><tr><td>出栈</td><td>pop()</td></tr><tr><td>查看栈顶</td><td>peek() 为空时返回 null</td></tr></tbody></table><p>ArrayDeque 常用的方法如下所示：</p><table><thead><tr><th>操作</th><th>方法</th></tr></thead><tbody><tr><td>入栈</td><td>push(E  item)</td></tr><tr><td>出栈</td><td>poll() 栈为空时返回    nullpop() 栈为空时会抛出异常</td></tr><tr><td>查看栈顶</td><td>peek() 为空时返回 null</td></tr></tbody></table><h2>Queue介绍</h2><p>Java里有一个叫做Stack的类，却没有叫做Queue的类(它是个接口名字)。当需要使用栈时，Java已不推荐使用Stack，而是推荐使用更高效的ArrayDeque；既然Queue只是一个接口，当需要使用队列时也就首选ArrayDeque了(次选是LinkedList)。</p><h3>Queue</h3><p>Queue接口继承自Collection接口，除了最基本的Collection的方法之外，它还支持额外的insertion, extraction和inspection操作。这里有两组格式，共6个方法，一组是抛出异常的实现；另外一组是返回值的实现(没有则返回null)。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000045396410" alt="" title="" loading="lazy"/></p><h3>Deque</h3><p>Deque 是"double ended queue", 表示双向的队列，英文读作"deck". Deque 继承自 Queue接口，除了支持Queue的方法之外，还支持 insert , remove 和 examine操作，由于Deque是双向的，所以可以对队列的头和尾都进行操作，它同时也支持两组格式，一组是抛出异常的实现；另外一组是返回值的实现(没有则返回null)。共12个方法如下:</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000045396411" alt="" title="" loading="lazy"/></p><p>当把 Deque 当做FIFO的 queue 来使用时，元素是从 deque 的尾部添加，从头部进行删除的； 所以 deque 的部分方法是和 queue 是等同的。具体如下:</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000045396412" alt="" title="" loading="lazy"/></p><p>Deque的含义是“double ended queue”，即双端队列，它既可以当作栈使用，也可以当作队列使用。下表列出了Deque与Queue相对应的接口:</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000045396413" alt="" title="" loading="lazy"/></p><p>下表列出了Deque与Stack对应的接口:</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000045396414" alt="" title="" loading="lazy"/></p><p>上面两个表共定义了Deque的12个接口。添加，删除，取值都有两套接口，它们功能相同，区别是对失败情况的处理不同。一套接口遇到失败就会抛出异常，另一套遇到失败会返回特殊值( false 或 null )。除非某种实现对容量有限制，大多数情况下，添加操作是不会失败的。虽然Deque的接口有12个之多，但无非就是对容器的两端进行操作，或添加，或删除，或查看。</p><p>ArrayDeque和LinkedList是Deque的两个通用实现，由于官方更推荐使用AarryDeque用作栈和队列，加之上一篇已经讲解过LinkedList，本文将着重讲解ArrayDeque的具体实现</p><p>从名字可以看出ArrayDeque底层通过数组实现，为了满足可以同时在数组两端插入或删除元素的需求，该数组还必须是循环的，即循环数组(circular array)，也就是说数组的任何一点都可能被看作起点或者终点。ArrayDeque是非线程安全的(not thread-safe)，当多个线程同时使用的时候，需要程序员手动同步；另外，该容器不允许放入 null 元素。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000045396415" alt="" title="" loading="lazy"/></p><p>上图中我们看到， head 指向首端第一个有效元素， tail 指向尾端第一个可以插入元素的空位。因为是循环数组，所以 head 不一定总等于0， tail 也不一定总是比 head 大。</p><h2>方法剖析</h2><h3>addFirst()</h3><p>addFirst(E e)的作用是在Deque的首端插入元素，也就是在head的前面插入元素，在空间足够且下标没有越界的情况下，只需要将elements[--head] = e即可。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000045396416" alt="" title="" loading="lazy"/></p><p>实际需要考虑:</p><ol><li>空间是否够用</li><li>下标是否越界的问题</li></ol><p>上图中，如果head为0之后接着调用addFirst()，虽然空余空间还够用，但head为-1，下标越界了。</p><pre><code class="java">//addFirst(E e)
public void addFirst(E e) {
    if (e == null)//不允许放入null
        throw new NullPointerException();
    elements[head = (head - 1) &amp; (elements.length - 1)] = e;//2.下标是否越界
    if (head == tail)//1.空间是否够用
        doubleCapacity();//扩容
}</code></pre><p><strong>上述代码可以看到， 空间问题是在插入之后解决的；</strong>首先，因为tail总是指向下一个可插入的空位，也就意味着elements数组至少有一个空位，所以插入元素的时候不用考虑空间问题。</p><p>下标越界的处理解决起来非常简单，head = (head - 1) &amp; (elements.length - 1)就可以了，<strong>这段代码相当于取余，同时解决了head为负值的情况</strong>。因为elements.length必需是2的指数倍，elements - 1就是二进制低位全1，跟head - 1相与之后就起到了取模的作用，如果head - 1为负数(其实只可能是-1)，则相当于对其取相对于elements.length的补码。</p><blockquote><p>计算机里数值都是用补码表示的，如果是8位的，-1就是1111 1111，而 (elements.length - 1) 也是 1111 1111，因此两者相与也就是(elements.length - 1)；</p><p>head = (head - 1) &amp; (elements.length - 1) 最后再让算出的位置赋值给head，因此其实这段代码就是让head再从后往前赋值</p></blockquote><p>扩容函数doubleCapacity()，其逻辑是申请一个更大的数组(原数组的两倍)，然后将原数组复制过去。过程如下图所示:</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000045396417" alt="" title="" loading="lazy"/></p><p>图中可以看到，复制分两次进行，第一次复制head右边的元素，第二次复制head左边的元素。</p><pre><code class="java">//doubleCapacity()
private void doubleCapacity() {
    assert head == tail;
    int p = head;
    int n = elements.length;
    int r = n - p; // head右边元素的个数
    int newCapacity = n &lt;&lt; 1;//原空间的2倍
    if (newCapacity &lt; 0)
        throw new IllegalStateException("Sorry, deque too big");
    Object[] a = new Object[newCapacity];
    System.arraycopy(elements, p, a, 0, r);//复制右半部分，对应上图中绿色部分
    System.arraycopy(elements, 0, a, r, p);//复制左半部分，对应上图中灰色部分
    elements = (E[])a;
    head = 0;
    tail = n;
}</code></pre><h3>addLast()</h3><p>addLast(E e)的作用是在<strong>Deque</strong>的尾端插入元素，也就是在tail的位置插入元素，由于tail总是指向下一个可以插入的空位，因此只需要elements[tail] = e;即可。插入完成后再检查空间，如果空间已经用光，则调用doubleCapacity()进行扩容。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000045396418" alt="" title="" loading="lazy"/></p><pre><code class="java">public void addLast(E e) {
    if (e == null)//不允许放入null
        throw new NullPointerException();
    elements[tail] = e;//赋值
    if ( (tail = (tail + 1) &amp; (elements.length - 1)) == head)//下标越界处理
        doubleCapacity();//扩容
}</code></pre><h3>pollFirst()</h3><p>pollFirst()的作用是删除并返回<strong>Deque</strong>首端元素，也即是head位置处的元素。如果容器不空，只需要直接返回elements[head]即可，当然还需要处理下标的问题。由于ArrayDeque中不允许放入null，当elements[head] == null时，意味着容器为空。</p><pre><code class="java">public E pollFirst() {
    int h = head;
    E result = elements[head];
    if (result == null)//null值意味着deque为空
        return null;
    elements[h] = null;//let GC work
    head = (head + 1) &amp; (elements.length - 1);//下标越界处理
    return result;
}</code></pre><h3>pollLast()</h3><p>pollLast()的作用是删除并返回Deque尾端元素，也即是tail位置前面的那个元素。</p><pre><code class="java">public E pollLast() {
    int t = (tail - 1) &amp; (elements.length - 1);//tail的上一个位置是最后一个元素
    E result = elements[t];
    if (result == null)//null值意味着deque为空
        return null;
    elements[t] = null;//let GC work
    tail = t;
    return result;
}</code></pre><h3>peekFirst()</h3><p>peekFirst()的作用是返回但不删除<strong>Deque</strong>首端元素，也即是head位置处的元素，直接返回elements[head]即可。</p><pre><code class="java">public E peekFirst() {
    return elements[head]; // elements[head] is null if deque empty
}</code></pre><h3>peekLast()</h3><p>peekLast()的作用是返回但不删除<strong>Deque</strong>尾端元素，也即是tail位置前面的那个元素。</p><pre><code class="java">public E peekLast() {
    return elements[(tail - 1) &amp; (elements.length - 1)];
}</code></pre>]]></description></item><item>    <title><![CDATA[2026年供应商管理系统排名：6款热门产品深度测评 SaaS圈老马 ]]></title>    <link>https://segmentfault.com/a/1190000047559864</link>    <guid>https://segmentfault.com/a/1190000047559864</guid>    <pubDate>2026-01-23 08:01:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>对于很多企业来说，供应商管理一直是个“老大难”问题——信息散乱、沟通成本高、对账周期长、合作过程不透明。如果全靠Excel和微信来管理，效率低不说，还容易出错。因此，一套好用的<strong>供应商管理系统</strong>（SRM）成了企业数字化转型中的重要一环。</p><p>但市面上的相关产品五花八门，有标准化软件，也有定制化平台，到底该怎么选？今天，我们就结合市场反馈、产品功能和实际应用情况，为大家测评并排名当前较受关注的<strong>6款供应商管理系统</strong>，希望能给正在选型的你一些参考。</p><p><strong>1. 支道</strong></p><p><a href="https://link.segmentfault.com/?enc=OX3neY3BXei27MXYk9ftew%3D%3D.0FgVev3PCIPqnJLI48OLCSUuzpyoWsf8BYYOz1ooGEA%3D" rel="nofollow" target="_blank">https://www.zdsztech.com</a></p><p><strong>综合评分：★★★★★</strong>  </p><p><strong>定位：</strong> 无代码定制化SRM解决方案  </p><p><strong>适合企业：</strong> 成长型企业、多业务场景需求、追求灵活与性价比并重的公司</p><p>如果要说近几年在中小企业数字化领域口碑不错的平台，<strong>支道</strong> 肯定算一个。它并不是一个固定的“标准化SRM软件”，而是一个<strong>无代码业务搭建平台</strong>，供应商管理只是其能搭建的众多场景之一。</p><p><strong>为什么把它放在前面推荐？</strong></p><p>首先，它解决了一个核心痛点：<strong>企业需求总是在变</strong>。今天你可能只管采购比价，明天就需要供应商绩效评估，后天又希望和供应商在线协同订单。标准化软件往往很难跟上这种节奏，而支道让业务人员自己就能通过“拖拉拽”配置流程、表单和报表，快速搭建出贴合实际的管理应用。</p><p>从供应商管理具体功能上看，它覆盖了：</p><p><strong>供应商全生命周期管理</strong>：从准入、分类、评级到淘汰，形成电子档案。</p><p><strong>在线询比价与招标</strong>：流程在线化，比价更透明，支持自动生成比价单。</p><p><strong>订单协同与发货跟踪</strong>：供应商可通过门户查看订单、确认交期、更新发货状态，减少来回沟通。</p><p><strong>智能对账与绩效评估</strong>：自动汇总往来数据，内置评估模型，生成供应商绩效看板。</p><p><strong>内外协同便捷</strong>：支持通过链接、二维码等方式让供应商参与部分流程，无需对方额外安装系统。</p><p><strong>最大的优势在于“灵活”和“性价比”</strong>。它没有按功能模块收费，企业可以根据自身发展阶段，先搭建核心的供应商档案与询价功能，后续再逐步扩展绩效、协同等模块。同时支持公有云、私有化部署，成本比许多传统定制开发低不少。</p><p>很多使用它的企业反馈：“像是请了一个懂业务的开发团队，但不用养人。” 尤其适合那些业务独特、标准化软件无法满足，又担心定制开发成本高、周期长的企业。<br/><img width="723" height="293" referrerpolicy="no-referrer" src="/img/bVdnIEE" alt="" title=""/></p><p><strong>2. 金蝶</strong></p><p><strong>综合评分：★★★★☆</strong>  </p><p><strong>定位：</strong> 集成的ERP系统，SRM为其重要组成部分  </p><p><strong>适合企业：</strong> 已使用或计划使用金蝶ERP的中大型制造业、贸易企业</p><p>金蝶作为国内老牌企业管理软件厂商，其云产品 <strong>金蝶云·星空</strong> 中的供应链协同模块，提供了比较完善的SRM功能。如果你企业本身就用金蝶处理财务、进销存，那么用它来管理供应商，数据打通会非常顺畅。</p><p>它的供应商管理侧重于<strong>流程规范和业财一体化</strong>：</p><p><strong>与ERP深度集成</strong>：采购订单、入库单、应付账款自动关联，杜绝数据孤岛。</p><p><strong>供应商门户</strong>：供应商可自助维护信息、接收订单、确认送货单和发票，提升协同效率。</p><p><strong>招投标管理</strong>：支持线上招标流程，相对规范。</p><p><strong>质量管理协同</strong>：可与来料检验（IQC）流程关联。</p><p><strong>优势是体系成熟、财务衔接好</strong>，特别适合管理规范、对财务合规性要求高的大中型企业。<strong>不足</strong>是作为大型ERP的一部分，整体价格较高，且功能偏标准化，个性化调整需要二次开发，成本和周期都不低。<br/><img width="723" height="301" referrerpolicy="no-referrer" src="/img/bVdnIEF" alt="" title="" loading="lazy"/></p><p><strong>3. 用友</strong></p><p><strong>综合评分：★★★★☆</strong>  </p><p><strong>定位：</strong> 用友新一代云ERP的SRM解决方案  </p><p><strong>适合企业：</strong> 成长型创新企业、全链路数字化需求较强的公司</p><p>用友的 <strong>YonSuite</strong> 定位为“成长型企业的云ERP”，其供应商协同云是现代、轻量化的SRM方案。它强调社交化协同和用户体验，试图把复杂的供应商管理做得更“互联网化”一些。</p><p>主要功能亮点：</p><p><strong>社交化沟通协同</strong>：类似商务聊天界面，与供应商的沟通记录可关联业务单据。</p><p><strong>全流程线上化</strong>：从寻源、询报价、合同到送货、对账，都在一个平台完成。</p><p><strong>供应商风险监控</strong>：集成一些外部数据，对供应商经营风险进行预警。</p><p><strong>移动端应用友好</strong>：审核、沟通在手机上操作方便。</p><p><strong>优势在于产品设计较新，协同理念突出</strong>，适合喜欢轻便、敏捷操作模式的企业。但作为用友云生态的一部分，同样面临与外部系统深度集成时可能需要的定制工作。<br/><img width="723" height="320" referrerpolicy="no-referrer" src="/img/bVdnIEG" alt="" title="" loading="lazy"/></p><p><strong>4. Oracle NetSuite SRP</strong></p><p><strong>综合评分：★★★★☆</strong>  </p><p><strong>定位：</strong> 全球性云端ERP内置的供应商管理方案  </p><p><strong>适合企业：</strong> 有跨国业务、需要多语言多币种支持的中大型企业</p><p>对于业务涉及海外的企业，<strong>Oracle NetSuite</strong> 是一个常被考虑的选项。它的供应商关系管理（SRP）模块是其ERP套件的一部分，天生支持全球化的供应链管理。</p><p>核心能力包括：</p><p><strong>全球供应商管理</strong>：轻松管理不同国家地区的供应商，处理多币种报价和结算。</p><p><strong>端到端采购流程</strong>：从需求计划到付款，全部自动化。</p><p><strong>强大的分析报告</strong>：提供全球采购开支、供应商绩效等多维度分析。</p><p><strong>开放集成平台</strong>：易于与其他国际主流系统对接。</p><p><strong>优势无疑是其全球化能力和品牌信誉</strong>。但劣势也很明显：实施和许可费用昂贵，产品复杂度高，通常需要专业的咨询团队实施，更适合预算充足、业务结构复杂的国际化公司。<br/><img width="723" height="285" referrerpolicy="no-referrer" src="/img/bVdnIEH" alt="" title="" loading="lazy"/></p><p><strong>5. 甄云科技</strong></p><p><strong>综合评分：★★★☆☆</strong>  </p><p><strong>定位：</strong> 专注于SRM领域的标准化SaaS产品  </p><p><strong>适合企业：</strong> 采购管理复杂、寻源需求强的大型集团企业</p><p><strong>甄云科技</strong> 是国内较早专注于SRM赛道的厂商之一。其 <strong>甄采SRM</strong> 是一款功能深度聚焦在采购与供应商管理的标准化产品。</p><p>它的强项在于 <strong>采购寻源和成本控制</strong>：</p><p><strong>战略寻源</strong>：支持复杂的招标、竞价、谈判流程。</p><p><strong>采购成本分析</strong>：深入分析采购支出，寻找降本机会。</p><p><strong>供应商绩效精细化管理</strong>：评估模型可自定义程度较高。</p><p><strong>与主流ERP有预置接口</strong>：与SAP、Oracle、用友、金蝶等可进行对接。</p><p><strong>优势是专业度高，在大型企业的集中采购场景中经验丰富</strong>。<strong>缺点</strong>是作为标准化SaaS，虽然功能深，但灵活性有限，且产品主要面向大型客户，对中小企业来说可能功能过重、价格偏高。<br/><img width="723" height="360" referrerpolicy="no-referrer" src="/img/bVdnIEI" alt="" title="" loading="lazy"/></p><p><strong>6. 纷享销客</strong></p><p><strong>综合评分：★★★☆☆</strong>  </p><p><strong>定位：</strong> 以CRM为核心，扩展至上下游业务协同的平台  </p><p><strong>适合企业：</strong> 以渠道分销、客户项目管理为核心，需联动供应商的中小企业</p><p><strong>纷享销客</strong> 本质是一个连接型CRM，但其PaaS平台能力允许它将业务延伸到上下游协同。如果你的企业业务核心是项目和客户，供应商管理作为辅助环节，需要与客户项目打通，那它可以作为一种轻量级选择。</p><p>在供应商管理方面，它能实现：</p><p><strong>供应商信息作为客户/伙伴管理</strong>：在CRM框架内管理供应商基础信息和联系人。</p><p><strong>简单询价与订单协同</strong>：通过流程和表单功能实现。</p><p><strong>与项目、合同关联</strong>：便于核算项目成本。</p><p><strong>低代码自定义能力</strong>：可对其标准功能进行一定调整。</p><p><strong>优势在于它从客户侧视角整合供应链，适合项目制销售型企业</strong>。<strong>不足</strong>是并非专业的SRM，在复杂的采购寻源、供应商绩效深度分析等方面功能较弱。<br/><img width="723" height="344" referrerpolicy="no-referrer" src="/img/bVdnIEJ" alt="" title="" loading="lazy"/></p><p><strong>总结与选型建议</strong></p><p>选供应商管理系统，没有绝对的“最好”，只有“最适合”。</p><p>如果你的业务在快速发展，需求多变，希望系统能跟着业务成长，<strong>支道</strong> 这类无代码平台值得优先考虑。它能以较低成本实现深度定制，且后续调整自主性强，算是大家比较钟爱的选择。</p><p>最后提醒一句，无论选哪家，<strong>一定要让对方提供同行业的案例参考，甚至安排演示环境亲手试用</strong>。供应商管理是“用”出来的，只有贴合你业务实际运作习惯的系统，才能真正用起来、出效果。</p>]]></description></item><item>    <title><![CDATA[4个给网站添加暗黑模式的简单方法 达西先生 ]]></title>    <link>https://segmentfault.com/a/1190000047559948</link>    <guid>https://segmentfault.com/a/1190000047559948</guid>    <pubDate>2026-01-22 23:02:21</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>1、CSS 滤镜反转颜色</h2><pre><code class="css">/* 代码实现全网站暗黑模式 */
@media (prefers-color-scheme: dark) {
    html {
        background-color: #fff !important;
        color: #000 !important;
    }

    html {
        /* 反转180度颜色 */
        filter: invert(1) hue-rotate(180deg) !important;
    }

    /* 图片、视频等元素不需要处理，可继续添加可以不用处理的元素 */
    img,
    video,
    iframe {
        /* 再反转180度变成原来颜色 */
        filter: invert(1) hue-rotate(180deg) !important;
    }
}

</code></pre><h2>2、JS 库添加蒙板</h2><pre><code class="html">&lt;script src="https://cdnjs.cloudflare.com/ajax/libs/Darkmode.js/1.5.7/darkmode-js.min.js"&gt;&lt;/script&gt;
&lt;script&gt;
    // 监听系统暗黑模式变化
    let darkmode = new Darkmode()
    window
        .matchMedia('(prefers-color-scheme: dark)')
        .addEventListener('change', (event) =&gt; {
            if (event.matches) {
                // 切换暗黑模式
                if (!darkmode.isActivated()) {
                    darkmode.toggle()
                }
            } else {
                // 切换亮色模式
                if (darkmode.isActivated()) {
                    darkmode.toggle()
                }
            }
        })
&lt;/script&gt;

</code></pre><h2>3、CSS 伪类:not() 选择器</h2><pre><code class="css">/* 代码实现全网站暗黑模式 */
@media (prefers-color-scheme: dark) {
    /* 排除的 a 和 code 元素 */
    html *:not(a, code *) {
        background-color: #000000 !important;
        color: #ffffff !important;
    }

    /* a元素单独设置颜色 */
    a {
        color: #4caf50 !important;
    }
}

</code></pre><h2>4、CSS media 媒体查询</h2><blockquote><p>HTML &lt;link&gt; media 属性定义和用法</p><p><strong>media</strong> 属性规定目标资源针对什么媒体/设备进行了优化。</p><p><strong>media</strong> 属性指定了被链接文档将显示在什么设备上。</p><p>该属性主要与 CSS 样式表一起使用，为不同的媒体类型指定不同的样式。</p><p><strong>media</strong> 属性可以接受多个值。</p></blockquote><pre><code class="html">&lt;!-- 只在亮色模式下生效 --&gt;
&lt;link
    rel="stylesheet"
    media="(prefers-color-scheme: light)"
    href="/assets/css/light.css"
/&gt;

&lt;!-- 只在暗黑模式下生效 --&gt;
&lt;link
    rel="stylesheet"
    media="(prefers-color-scheme: dark)"
    href="/assets/css/dark.css"
/&gt;

</code></pre>]]></description></item>  </channel></rss>