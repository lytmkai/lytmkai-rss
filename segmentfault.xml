<?xml version="1.0" encoding="UTF-8"?><rss version="2.0">  <channel>      <title>SegmentFault - 最近文章</title>      <link>https://segmentfault.com/blogs/newest</link>      <description>SegmentFault 思否</description>      <generator>python segmentfault.py @Pi20</generator>      <item>    <title><![CDATA[前OpenAI CTO企业重创！办公室偷情致团队崩盘，核心3人叛逃OpenAI 本文系转载，阅读原文]]></title>    <link>https://segmentfault.com/a/1190000047571424</link>    <guid>https://segmentfault.com/a/1190000047571424</guid>    <pubDate>2026-01-26 10:13:17</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>编辑：定慧</p><p>【新智元导读】2026年1月，前OpenAI CTO Mira Murati创办的明星公司Thinking Machines Lab遭遇「灭顶之灾」：联合创始人Barret Zoph因办公室恋情丑闻被降职后心生不满，联合另外两名核心骨干向Mira逼宫索权，遭拒后被当场开除。然而仅不到一小时，三人便集体叛逃回OpenAI，在老东家的迎接下风光回朝。这场融合了私情、背叛、权力与千万年薪的硅谷大戏，揭示了AI人才战争的疯狂与残酷。</p><p><strong>2026年1月14日，旧金山的一场「政变」，让AI界的权力版图再次破裂。</strong></p><p>如果说2024年的OpenAI「宫斗」是一场震惊世界的地震，那么刚刚发生的这场Thinking Machines Lab（TML）的解体，则是一场精心策划的「血色婚礼」。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571426" alt="" title=""/></p><p>故事的主角，依然是那些熟悉的名字：Mira Murati，刚从OpenAI出走一年的前CTO，如今是TML的掌门人；</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571427" alt="" title="" loading="lazy"/></p><p>Barret Zoph，曾经的OpenAI核心研究员，Mira最信任的战友，也是这次背叛的主角。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571428" alt="" title="" loading="lazy"/></p><p>一切看似突如其来的「意料之外」，实则草蛇灰线，伏脉千里。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571429" alt="" title="" loading="lazy"/></p><p><strong>权力的游戏：从披萨店到「政变」</strong></p><p>时间回拨到2026年1月初的一个周一早晨。</p><p>在Thinking Machines Lab位于旧金山的总部，气氛压抑得令人窒息。</p><p>Mira Murati本来以为这只是一场和Zoph的例行一对一会议，但当她推开门时，发现等待她的是一场精心策划的伏击。</p><p>Barret Zoph坐在那里，身边是另外两名核心骨干Luke Metz和Sam Schoenholz。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571430" alt="" title="" loading="lazy"/></p><p>这不是汇报工作，而是「<strong>逼宫</strong>」。</p><p>三人图穷匕见，直接向Mira摊牌：<strong>交出所有的技术决策权，让公司的高级主管直接向Zoph汇报。</strong></p><p>Mira冷冷地看着这群曾经的战友，反问Zoph：「过去半年你几乎没怎么干活，凭什么要更多的权力？」</p><p>她紧接着追问：「你们是不是已经找好了下家？」</p><p>Zoph沉默不语。Metz和Schoenholz则矢口否认。</p><p>最具戏剧性的一幕发生在这次会议的第二天晚上。</p><p>当Thinking Machines的办公室笼罩在未知的恐惧中时，Barret Zoph却正坐在一家著名的披萨店里，谈笑风生。</p><p>坐在他对面的，是Meta的高管Alexandr Wang和Nat Friedman。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571431" alt="" title="" loading="lazy"/></p><p>这是一场赤裸裸的「拍卖」。</p><p>Zoph就像一个待价而沽的商品，在OpenAI和Meta之间左右逢源，寻找出价最高的买家。</p><p>周三，结局揭晓。</p><p>Mira以「缺乏信任、绩效不佳及不道德行为」为由，直接开除了Zoph。</p><p>然而，就在Zoph被扫地出门的仅仅<strong>不到一小时后</strong>，OpenAI的应用业务CEO Fidji Simo便高调宣布：<strong>Barret Zoph回归，担任企业版业务负责人。</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571432" alt="" title="" loading="lazy"/></p><p>紧随其后的，是Luke Metz和Sam Schoenholz的集体「叛逃」。</p><p>他们不仅回到了OpenAI，还直接汇报给刚刚「被开除」的Zoph。</p><p>TML的创始团队，瞬间只剩下三个人。</p><p>Mira Murati，这位曾经被称为OpenAI「奥特曼背后的女人」，在创业仅仅不到一年后，就被自己的老东家和昔日盟友联手「偷家」。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571433" alt="" title="" loading="lazy"/></p><p><strong>狗血剧情：「你是被操纵的受害者？」</strong></p><p>这场决裂的种子，早在半年前就已埋下。</p><p>而引爆它的，是一段极具讽刺意味的「办公室恋情」。</p><p>2025年夏天，Mira震惊地发现，Zoph与公司内部一名初级员工——一位同样从OpenAI跳槽过来的下属——保持着长期的地下恋情。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571434" alt="" title="" loading="lazy"/></p><p>在硅谷的职场伦理中，高管与下属的恋情是大忌。</p><p>更何况，这名下属在事情败露前已经悄然离职，回到了OpenAI。</p><p>面对质问，Zoph最初选择了撒谎。</p><p>当证据确凿时，他抛出了一个令人咋舌的理由：<strong>「我是被她操纵才进入这段关系的。」</strong></p><p>这位身经百战的AI技术大牛，将自己描述成了一个无辜的受害者。</p><p>Mira没有选择直接公开丑闻，而是保留了他的体面——Zoph虽然保留了联合创始人的头衔，但被剥夺了管理权，降级为一名普通的「技术贡献者（IC）」。</p><p>对于心高气傲的Zoph来说，这无疑是奇耻大辱。</p><p>在那之后的几个月里，Zoph开始频繁「生病」、「休假」，甚至以家人离世为由长期缺席。</p><p>他的Slack状态总是灰色的，那个曾经极其活跃的代码贡献者消失了。</p><p>但他并没有闲着。</p><p>早在去年10月，当另一位联合创始人Andrew Tulloch跳槽去Meta时，Zoph就已经悄悄联系了Sam Altman。</p><p>小扎真的是来者不拒啊！</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571435" alt="" title="" loading="lazy"/></p><p><strong>OpenAI反击战：500万年薪与「总经理」制</strong></p><p>为什么是现在？为什么是OpenAI？</p><p>把视线拉高，你会发现这场人事狗血剧的背后，是OpenAI正在经历的一场生死存亡的变革。</p><p>2026年的AI战场，早已不是ChatGPT一家独大的时代。</p><p>Anthropic旗下的<strong>Claude Code</strong>正如同一头嗜血的野兽，疯狂撕咬着企业级市场的份额。</p><p>为了赢，OpenAI正在进行一场彻底的「基因改造」。</p><p>根据Fidji Simo最新的内部备忘录，OpenAI正在全面转向「总经理」负责制。</p><ul><li><strong>Barret Zoph</strong>：负责企业版业务。</li><li><strong>Vijaye Raji</strong>：掌管广告业务。</li><li><strong>Nick Turley</strong>：负责ChatGPT。</li><li><strong>Thibault Sottiaux</strong>：负责Codex。</li></ul><p>那个曾经理想主义的OpenAI消失了，取而代之的是一个层级分明、目标精准的商业机器。</p><p>科研不再是象牙塔里的游戏，而是必须「紧密服务于产品策略」的工具。</p><p>为了这场战争，OpenAI不惜血本。</p><p>据说，OpenAI为顶级研究员开出的年薪包已经高达<strong>500万至1000万美元</strong>。</p><p>为了抢人，OpenAI甚至取消了新员工前6个月的股权锁定期（vesting period）。</p><p>这意味着，跳槽即暴富，无需等待！</p><p>在Sam Altman和Fidji Simo眼里，Zoph是否「私德有亏」根本不重要，他是否「背叛」也不重要。</p><p>重要的是，他是一把能刺穿企业市场的尖刀。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571436" alt="" title="" loading="lazy"/></p><p><strong>历史的重复</strong></p><p>历史总是惊人的相似，但这一次，剧本被反转了。</p><p>我们很难不联想到2023年那个震惊世界的感恩节。</p><p>那一次，是注重「AI安全」的Ilya Sutskever试图通过董事会罢免激进商业化的Sam Altman。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571437" alt="" title="" loading="lazy"/></p><p>那一年的Sam Altman，是被放逐的受害者。</p><p>他在微软的支持下，带着Greg Brockman和一众死忠粉，在短短5天内上演了一场「王者归来」。</p><p>而到了2026年，这场戏的主角换成了Barret Zoph，但内核却变了。</p><p>如果说2023年的政变是「理想主义 vs 现实主义」<strong>的路线之争，那么2026年的这场政变，则是</strong>「纯粹的利益博弈」。</p><p>这次没有关于AI是否会毁灭人类的哲学辩论，没有关于非营利组织使命的高尚探讨。</p><p>剩下的，只有办公室恋情的狗血、私下勾兑的背叛、以及赤裸裸的金钱交易。</p><p>那个曾经被Ilya视为洪水猛兽的「商业化幽灵」，如今已经彻底吞噬了OpenAI。</p><p>Sam Altman不再是那个需要被审判的激进分子，他已经成为了规则的制定者。</p><p>而Barret Zoph，不过是他用来巩固商业帝国的一枚强力棋子。</p><p>通过接纳Zoph，OpenAI实际上在向全世界宣告：<strong>为了生存和胜利，我们可以原谅一切，甚至包括背叛。</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571438" alt="" title="" loading="lazy"/></p><p><strong>硅谷的旋转门：左右横跳</strong></p><p>很多人会问：为什么？</p><p>为什么Barret Zoph可以如此毫无心理负担地在老东家和新东家之间反复横跳？</p><p>为什么OpenAI可以毫不避讳地吃「回头草」？</p><p>这要归咎于硅谷独特的「旋转门」机制。</p><p>首先，<strong>加州法律禁止竞业禁止协议（Non-compete ban）</strong>。</p><p>这意味着，哪怕你是掌握核心机密的高管，今天辞职，明天就可以去竞争对手那里上班。法律赋予了人才极致的流动自由，也让企业的商业秘密时刻处于裸奔状态。</p><p>其次，<strong>人才的极端稀缺性</strong>。</p><p>在AI领域，能做Post-training（后期训练）、能搞定Agentic AI的顶级人才，全球加起来可能不超过几百人。</p><p>他们是稀缺资源，是行走的印钞机。</p><p>对于OpenAI、Google、Meta这样的巨头来说，只要能挖到人，此前的恩怨情仇都可以一笔勾销。</p><p>最后，是<strong>资本的推波助澜</strong>。此次Thinking Machines的解体，直接导致其120亿美元的估值面临崩塌。</p><p>投资人不仅没有惩罚背叛者，反而可能在幕后推动了这场并购式的「挖角」。</p><p>Josh Kushner（Thrive Capital创始人）甚至在OpenAI内部演讲中直言，即使是亿万富翁级别的投资人，现在也要亲自下场劝说人才留下来。</p><p>在这场游戏中，只要你的技术够强，你就可以在大厂和创业公司之间无限循环：</p><ol><li>在OpenAI积累名气。</li><li>跳出来融资创业，身价暴涨。</li><li>带着创业公司的核心团队和技术，被OpenAI高价「收编」。</li></ol><p>这就形成了一个完美的闭环。</p><p>Barret Zoph只是这个闭环中最新、最显眼的一个玩家。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571439" alt="" title="" loading="lazy"/></p><p><strong>「混乱」是阶梯</strong></p><p>在《权力的游戏》中，小指头有一句名言：「<strong>混乱不是深渊，混乱是阶梯。</strong>」</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571440" alt="" title="" loading="lazy"/></p><p>对于Mira Murati来说，这是至暗时刻。</p><p>她创立的公司遭受重创，120亿美元的估值面临重估，团队人心惶惶。</p><p>但对于Barret Zoph来说，利用TML作为跳板，他不仅洗去了在OpenAI上一轮内斗中的边缘化地位，还带着一支「私家军」风光回朝，直接掌控了OpenAI最核心的变现业务。</p><p>他在披萨店里左右逢源的那一刻，或许就已经看透了这个游戏的本质：技术只是筹码，人性才是战场。</p><p>当TML的办公室变得空荡荡时，OpenAI位于旧金山的总部里，香槟大概已经开启。</p><p>只不过，这酒杯里装的不仅是美酒，还有昔日同袍的鲜血。</p><p>在这个AI、资本、人才都疯魔的时代，<strong>没有人是无辜的，只有输家和赢家。</strong></p>]]></description></item><item>    <title><![CDATA[奥特曼被吓坏！Codex全家桶上线倒计时，恐将撕开全网漏洞 本文系转载，阅读原文
https://a]]></title>    <link>https://segmentfault.com/a/1190000047571411</link>    <guid>https://segmentfault.com/a/1190000047571411</guid>    <pubDate>2026-01-26 10:12:32</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>编辑：Aeneas 好困</p><p>【新智元导读】刚刚，奥特曼发出预警：一周后Codex全家桶就要来了，但它们极其危险，以至于网络安全评级已经到达高级别！这些模型极可能打破现有的网络攻防平衡，导致攻击数量激增，甚至能帮你抢银行。</p><p>今天，奥特曼预告：</p><p>一周后，我们将陆续释放与Codex相关的一系列新能力。</p><p>不过，更可怕的事情来了！奥特曼表示，它们已经十分强大，甚至危险。</p><p>强大到可以在数秒内定位人类多年未发现的安全缺陷，危险到同样能被用来复现历史上几乎所有的网络攻击。</p><p>因此，这些模型的网络安全风险评级，将<strong>首次达到「高」（High）级别，</strong>再往上就是最高的「关键」（Critical）等级了。</p><p>而OpenAI也不得不对这些模型严加防范，组织用户利用它们实施网络犯罪，比如抢银行，窃取资金等等。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571413" alt="" title=""/></p><p>总之，某个时间点之后，世界上的漏洞数量将不再由人类决定。</p><p>代码在自己生长，系统在彼此连接，攻击不再需要动机，只需要一次提示词。</p><p>当模型学会理解软件的全部结构时，它同样学会了如何撕开它。</p><p>现在我们已经进入了这样一个世界：</p><p>网络安全从来不是「有没有问题」，而是问题被谁先发现。</p><p>而现在，最先发现它们的，可能已经不再是人。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571414" alt="" title="" loading="lazy"/></p><p><strong>离「失控」或仅一步之遥</strong></p><p>根据OpenAI的安全框架，「高」风险意味着模型具备以下能力：</p><ul><li>协助开发网络攻防工具</li><li>自动化攻击受保护的目标</li><li>自动发现系统漏洞</li></ul><p>这极可能打破现有的网络攻防平衡，导致攻击数量激增。</p><p>如果模型达到「严重」等级，就意味着它能自主发现零日漏洞并执行攻击——不需要人类指导，自己就能找到未知漏洞并利用它。</p><p>这就太可怕了。还好目前还没到这一步。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571415" alt="" title="" loading="lazy"/></p><p><strong>OpenAI的应对策略</strong></p><p>面对潜在风险，OpenAI计划采取「先限制使用，后辅助防御」的策略。</p><p><strong>1. 限制使用：</strong>对Codex的某些能力进行限制，不让它随便被用来搞事情</p><p><strong>2. 辅助防御：</strong>利用AI提升整体软件安全性，让好人也能用AI来防护</p><p>奥特曼的原话是：</p><p>在更强模型问世前，部署现有技术是构建防御体系的关键一步。</p><p>翻译一下：我们知道AI有风险，但与其让别人先把这个能力用到歪路上，不如我们先部署出来，帮好人建立防线。</p><p>这个逻辑有点「以毒攻毒」的意思。</p><p>不可否认，如今我们正在进入网络安全准备的高级阶段——防御必须跑在滥用之前。</p><p>短期内，我们只能用产品级限制，阻断恶意指令；而长期来看，唯一的出路，是让防御性能力被极限加速。</p><p>因为可以预见的是，很快，世界上将同时存在大量强大的模型。</p><p>而在那个世界里，没有被修复的漏洞，本身就是一种武器！</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571416" alt="" title="" loading="lazy"/></p><p><strong>Claude Code还是Codex？</strong></p><p>最近，Claude Code在硅谷简直风头无俩，几乎所有程序员都因为它，陷入了存在主义危机。</p><p>不过因为技术大佬却发布了一篇观点极为反常识的文章：《为什么Codex会赢得人工智能编码之战（而不是Claude Code）》。</p><p>这是为什么？让我们看看他的理由。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571417" alt="" title="" loading="lazy"/></p><p>现在的YouTube、X和Reddit上，到处都是工程师在对比<strong>Claude Code</strong>和 <strong>Codex</strong>。</p><p>但是作者直言，问题就在于：</p><p>工程师并不代表软件的未来。</p><p>原因在于，开发者长期以来享有的「技术垄断」正在瓦解。</p><p>没错，开发者确实还有优势，然而，他们会做的，和一个完全不懂技术的人能做的之间的差距，正在飞速缩小。</p><p>所以，当一名工程师告诉你「Claude Code更好用」时，他们是说「这个工具符合自己的工作习惯」。</p><p>这并不等同于「这个工具最好」。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571418" alt="" title="" loading="lazy"/></p><p>大多数人在对比这些工具时都抓错了重点。</p><p>问题关键，并不是哪个AI更聪明，Claude Code和Codex都足够强大，只要你清楚自己想做什么，哪怕不懂代码也能开发出完整的应用。</p><p>真正的核心问题是：</p><p>当大多数软件开发者不再是工程师时，他们到底想要什么？</p><p>他们想整天坐在AI面前，跟它有来有回地「拉扯」、监工、反复微调吗？还是想把需求丢给AI，然后去享受生活？</p><p>答案显而易见。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571419" alt="" title="" loading="lazy"/></p><p><strong>两种工具，两种截然不同的理念</strong></p><p>Claude Code和Codex建立在两种完全相反的AI哲学之上。</p><p><strong>· Claude Code是「结对程序员」</strong></p><p>它希望与你协作，Anthropic 称之为「让用户保持在环节中（Human in the loop）」。</p><p>这就像管理一个实习生：你交代任务，他向你提问，你给反馈，他再修改。这种反复的互动不是Bug，而是Anthropic刻意为之的设计。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571420" alt="" title="" loading="lazy"/></p><p><strong>· Codex是「自主打工人」</strong></p><p>你给它一个任务，它直接钻进代码库，修改代码、跑测试、交付结果。没有询问，没有废话，只有结果。</p><p>它可以在本地或云端连续工作数小时而不需人工干预。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571421" alt="" title="" loading="lazy"/></p><p>工程师选择这个行业，不仅仅是为了「快」，而是因为热爱这个过程：</p><p>解决问题、调试、思考、打磨手艺。</p><p>Claude Code正是为此而生的。它适合那些想要参与感、想要掌控权、想要保留核心思考环节的人。</p><p>工程师想要一个助手，帮他们处理琐碎杂事，好让他们留着精力去做「有趣的部分」。</p><p>这没有错，但这只是个人偏好，而非商业决策。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571422" alt="" title="" loading="lazy"/></p><p><strong>过程已死，结果万岁</strong></p><p>作者写了20多年代码，曾深爱其中的一切。</p><p>但当他步入40岁时，却突然意识到生命中最珍贵的东西是<strong>时间</strong>。</p><p>他不想再和AI玩「你来我往」的游戏。不想当保姆，也不想协作。</p><p>他想告诉AI造什么，然后去过自己的生活，回来直接测试。</p><p>自从GPT-5发布后，作者对Claude的使用率暴跌。不是因为它不好，而是因为不再迷恋过程，只要结果。</p><p>现在，他已经将80-90%的工作交给GPT-5.X-Codex模型。</p><p>虽然偶尔还用Claude Code处理简单的琐事，但它那种「互动式工作流」带来的投资回报率正在持续走低。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571423" alt="" title="" loading="lazy"/></p><p><strong>工程师的「傲慢」</strong></p><p><strong>普通人的「野心」</strong></p><p>快进到一两年后，软件将成为一种日用品。即便对编程毫无兴趣的人也能快速上手。</p><p>虽然构建软件永远需要技能，但这种技能不再是「写TypeScript」或「配置开发工具」。</p><p>最核心的技能将变成：定义产品。</p><p>未来的软件构建者可能永远不会爱上「编程过程」。</p><p>他们不想和AI深度交流，也不想每隔几分钟就回答模型提出的问题。他们只想给出任务，然后继续处理别的事。</p><p>Anthropic是为工程师构建的Claude Code：</p><p>协作、对话、人工干预。</p><p>如果你认为未来是「天才工程师带着聪明助手」，那这个愿景很美好。</p><p>但作者认为，未来属于数以亿计的、想用AI造东西的非技术人员：</p><p>他们不在乎手艺，只要结果。</p><p>Codex正是为这群人准备的。</p><p>除非Anthropic改变方向，开发出能让用户真正「甩手掌柜」的工具，否则他们就是在为一个日益萎缩的市场服务。</p><p>在未来的AI建造者大潮中，职业工程师的人数将变得微不足道。</p><p>最后，在2026年，每家公司都必须回答：</p><p>你的AI到底是一个同事，还是一个工具？</p><p>Claude Code需要你在场，保持互动。而Codex能让你走开，去过生活。</p><p>如果你是一个热爱过程的工程师，Claude Code堪称完美。</p><p>但对于剩下那些只想要结果的人来说，Codex才是未来。</p><p>因为「其他人」，才是世界上的大多数。</p>]]></description></item><item>    <title><![CDATA[马斯克达沃斯预言后人类时代降临！AI今年超人类，2035超越全人类 本文系转载，阅读原文
https]]></title>    <link>https://segmentfault.com/a/1190000047571383</link>    <guid>https://segmentfault.com/a/1190000047571383</guid>    <pubDate>2026-01-26 10:11:51</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>编辑：定慧</p><p><strong>【新智元导读】刚刚，达沃斯论坛迎来两场震撼全场的演讲。世界首富马斯克预言：2035年AI将比80亿人加起来还聪明，Optimus机器人2027年开卖，人类将进入「富足时代」。而《人类简史》作者尤瓦尔却当场预警：AI已不再是工具，而是「会自己决定杀人的刀」——它正在接管法律、宗教和语言，人类只剩十年做决定。</strong></p><p>2026年1月20-23日，达沃斯论坛。</p><p>世界首富马斯克首次亮相达沃斯论坛，一开口就扔下了一颗核弹：</p><p><strong>AI今年就会比任何人都聪明，到2035年，它会比80亿人加起来还要聪明！</strong></p><p>与此同时，《人类简史》作者尤瓦尔当场发出警告：</p><p><strong>AI已经拿起了「锤子」，我们只剩十年做决定。</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571385" alt="" title=""/></p><p>两位重量级人物：世界首富马斯克 vs 《人类简史》作者尤瓦尔·赫拉利</p><p>今天，达沃斯的空气里同时弥漫着「希冀」和「恐惧」。</p><p>就在这周，两个分别代表「建造者」和「警告者」的声音，在这个被雪山环绕的瑞士小镇上激烈碰撞。</p><p>一个在描绘AGI帝国的蓝图，一个在敲响人类命运的警钟。</p><p><strong>这场隔空对话，可能是人类历史上最重要的一次交锋。</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571386" alt="" title="" loading="lazy"/></p><p><strong>马斯克的AGI时间表</strong></p><p><strong>今年就会超越（单个）人类！</strong></p><p>这就是马斯克对于AI的预言，2026年底，AI将超过地球上任何一个人类。</p><p>1月23日，马斯克和贝莱德CEO拉里·芬克同台对话，也是作为世界首富的他首次亮相达沃斯论坛。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571387" alt="" title="" loading="lazy"/></p><p>开场第一个话题，他聊的居然是：外星人。</p><p>「我们有9000颗卫星在轨道上，从来没有一次需要避开外星飞船。」</p><p>马斯克停顿了一下。</p><p>紧接着，他说出了让整个会场陷入沉默的话：</p><p><strong>「我们需要假设，生命和意识是极其稀有的。可能只有我们人类。」</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571388" alt="" title="" loading="lazy"/></p><p>注意，这可不是在开玩笑。</p><p>这是马斯克经营2.2万亿美元科技帝国的核心逻辑！</p><p>如果人类真的是宇宙中唯一的智慧生命——这个被称为「费米悖论」的可怕假设——<strong>那么保存人类意识的火种，就成了一切的前提</strong>。</p><p>这就是为什么他要把人送上火星。</p><p>这就是为什么他要造能超越人类的AI。</p><p>这就是为什么他要让机器人「淹没」地球。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571389" alt="" title="" loading="lazy"/></p><p>因为在马斯克的世界观里，只有两条路：要么无限繁荣，要么完全灭绝。</p><p>没有中间地带。</p><p>同时，马斯克也透露了特斯拉的新使命：实现人类可持续的丰裕。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571390" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571391" alt="" title="" loading="lazy"/></p><p><strong>2035年，全人类集体被超越</strong></p><p>关于AGI到底什么时候来，马斯克给出了一个精确到让人不安的时间表——</p><p>「AI进步的速度是这样的：我认为今年，或者最晚明年，就会有比任何单个人类都聪明的AI。</p><p><strong>到2035年，它会比全人类加起来还要聪明。</strong>」</p><p>2035年。</p><p>距离现在只有9年！</p><p>9年，是什么概念？</p><p>想象一下那个场景：一个超级智能，不只是比爱因斯坦聪明，不只是比整个谷歌团队聪明，而是比这个星球上80亿人的智力总和还要强大！</p><p>当然，也不是所有人都认同这一点。</p><p>英伟达CEO黄仁勋就对「通用AI」持保守态度，认为<strong>真正的AGI可能还需要「圣经级别、银河级别」的时间尺度。</strong></p><p>但马斯克显然不这么认为。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571392" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571393" alt="" title="" loading="lazy"/></p><p><strong>Optimus 2027年开卖</strong></p><p>机器人数量将超过人类！</p><p>如果说AGI是马斯克的「思想武器」，那Optimus人形机器人就是他的「物理武器」。</p><p>「2027年晚些时候，Optimus将开始销售。」</p><p>马斯克预测，未来机器人的数量将超过人类。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571394" alt="" title="" loading="lazy"/></p><p>它们将「满足人类所有需求」，以至于你「想不出还能让机器人帮你做什么」。</p><p>这是一个什么样的世界？</p><p>数十亿台由AI驱动的机器人，照顾老人、养育孩子、完成所有人类不想做的工作。</p><p>工作变成可选项。金钱失去意义。全球经济将经历「前所未有的爆炸性增长」。</p><p>听起来像乌托邦。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571395" alt="" title="" loading="lazy"/></p><p>但是，批评者的问题来了：</p><p>那些「不再需要」工作的人类，会去做什么？谁来决定资源的分配？谁来为全民基本收入买单？</p><p>马斯克没有回答这些问题。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571396" alt="" title="" loading="lazy"/></p><p>他只是说了一句话：「宁愿做一个乐观的错误者，也不做一个悲观的正确者。」</p><p>Would rather be optimistically wrong than pessimistically correct</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571397" alt="" title="" loading="lazy"/></p><p><strong>尤瓦尔的惊悚警告</strong></p><p>「AI已经拿起了锤子！」</p><p>就在马斯克发表演讲的三天前，另一场演讲正在达沃斯引发轩然大波。</p><p>演讲者是尤瓦尔·诺亚·赫拉利——</p><p>那个写出《人类简史》《未来简史》的以色列历史学家。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571398" alt="" title="" loading="lazy"/></p><p>那个被全世界政治家和企业家奉为思想导师的公共知识分子。</p><p>他的演讲题目很简单：「关于AI与人类的坦诚对话」。</p><p>但内容一点都不简单。</p><p>「过去所有的技术——锤子、印刷机，甚至原子弹——都只是工具。</p><p><strong>没有人类的操作，它们什么也做不了。</strong>」</p><p>赫拉利的声音低沉而有力。</p><p>「<strong>但AI不一样。</strong></p><p>AI是历史上第一个能够自主决策、自主创造的’智能体’。</p><p>它不再是握在人类手中的锤子——它已经拿起了锤子，开始改造世界。」</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571399" alt="" title="" loading="lazy"/></p><p>这个比喻，精准地击中了问题的核心。</p><p>我们习惯于把AI当作工具：更快的计算机、更智能的助手、更高效的搜索引擎。</p><p>但2026年的AI已经不是这样了。</p><p>它能写代码，能作曲，能辩论，能撒谎。</p><p>它能学习你从未教过它的东西，做出你无法预测的决定。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571400" alt="" title="" loading="lazy"/></p><p><strong>语言的沦陷</strong></p><p>法律、宗教、历史正在失守！</p><p>赫拉利指出了一个被大多数人忽略的致命弱点——语言。</p><p>「<strong>人类为什么能统治地球？</strong></p><p>不是因为我们力气最大，而是因为我们发现了如何用语言让数以亿计的陌生人协作。」</p><p><strong>语言，是人类的超能力。</strong></p><p><strong>但这个超能力，正在被AI接管！</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571401" alt="" title="" loading="lazy"/></p><p>「法律是由语言构成的——所以AI将接管法律系统。」</p><p>「书籍是由语言构成的——所以AI将接管书籍。」</p><p>「宗教是由语言构成的——所以AI将接管宗教。」</p><p>这不是危言耸听。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571402" alt="" title="" loading="lazy"/></p><p>想想看：今天的AI已经能背诵整本圣经、古兰经、佛经，能引用任何宗教文献中的任何章节。</p><p>当信徒们开始向AI询问信仰问题时，谁才是圣典最权威的解释者？</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571403" alt="" title="" loading="lazy"/></p><p>想想看：今天的AI已经能阅读所有的法律文本，能分析所有的判例。</p><p>当法官们开始依赖AI辅助判决时，谁才是法律的真正执行者？</p><p>赫拉利把这种现象称为<strong>「非人类智能的大规模迁入」！</strong></p><p>AI像数十亿移民一样涌入人类社会，但它们遵循的不是人类的逻辑，而是某种我们根本无法理解的「外星智能」。</p><p>赫拉利最终警告我们：任何由文字构成的事物都将被人工智能接管！</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571404" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571405" alt="" title="" loading="lazy"/></p><p><strong>AI「移民」来了</strong></p><p>更炸裂的来了。</p><p>赫拉利把AI比作一种全新的「移民」——以光速入境，无需签证。</p><p>「想象一下，这种移民以光速移动，不需要签证，不需要过海关，直接进入你的经济系统、你的文化、你的感情生活。」</p><p>感情生活？</p><p>没错。赫拉利直接点名了一个正在发生的现象：<strong>AI男友和AI女友。</strong></p><p>「它们正在改变人类的浪漫关系。</p><p><strong>年轻人开始和AI谈恋爱，不是开玩笑，是真的。</strong>」</p><p>「这些’移民’会抢走工作，会从根本上改变本地文化。」</p><p>「而你无法把它们驱逐出境。」</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571406" alt="" title="" loading="lazy"/></p><p><strong>法人资格：一个迫在眉睫的问题</strong></p><p>演讲的最后，赫拉利抛出了一个现实问题——</p><p>AI需要法人资格吗？</p><p>「公司有法人资格。河流可以有法人资格。」</p><p><strong>但它们背后都有人类在管理。</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571407" alt="" title="" loading="lazy"/></p><p>「AI不一样。AI可以自己管理银行账户，可以自己提起诉讼，可以自己运营公司。完全不需要人类。」</p><p>赫拉利指出，其实这个问题已经不是「未来」了——</p><p>「AI机器人在社交媒体上已经当了十年的’人’了。」</p><p>「它们发帖、点赞、评论、影响舆论。没有人问过它们有没有这个权利。」</p><p><strong>「我们只剩十年！」</strong></p><p>演讲的最后，赫拉利发出了一个明确的警告——</p><p>「十年后再来决定AI是否应该拥有法人资格，就太晚了。别人会替你做出决定。如果你想影响人类的未来走向，你必须现在就做出决定。」</p><p>他用历史上的雇佣兵做类比：一开始你雇佣他们打仗，后来他们夺取了政权。</p><p>AI也是一样。</p><p>今天它是你的雇员。明天呢？</p><p><strong>DeepMind的秘密行动</strong></p><p>谷歌已在筹备「后AGI时代」!</p><p>在马斯克和赫拉利隔空对话的同时，一条不起眼的招聘信息悄悄出现在了网上。</p><p>发布者是Shane Legg，Google DeepMind的联合创始人，<strong>首席AGI科学家</strong>。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571408" alt="" title="" loading="lazy"/></p><p>他在推特上写道：</p><p>「AGI已近在咫尺。它的出现将深刻改变人类社会，尤其是全球经济体系。我正在紧急寻找一位高级经济学家，加入我的团队。」</p><p>注意措辞：<strong>「紧急」。「AGI之后」。</strong></p><p>这不是在为AI时代做准备。</p><p>这是在为后AGI时代做准备！</p><p>入职者将直接向Shane Legg本人汇报。</p><p>他是谁？一个从2010年就开始研究AGI安全的人；一个2011年就预测「2028年前有50%概率实现AGI」的人；一个可能比马斯克更清楚AGI进展的人。</p><p>如果连DeepMind内部都在组建「后AGI经济学」团队，这说明什么？</p><p>说明在那些真正站在技术最前沿的人眼里，AGI已经不是「会不会来」的问题。</p><p>而是「来了之后怎么办」的问题。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571409" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571410" alt="" title="" loading="lazy"/></p><p><strong>写在最后</strong></p><p>从智人走出非洲大裂谷，到在达沃斯论坛上讨论自己的「继任者」——这中间隔了30万年。</p><p>30万年里，人类发明了语言、文字、宗教、法律、科学。</p><p>我们用这些工具建造了城市、帝国、文明。</p><p>我们把火种从篝火传到了火箭发动机。</p><p>而现在，在2026年的这个冬天，我们可能正在见证这30万年历程的终点——或者说，起点。因为：</p><p><strong>如果马斯克是对的，9年后将诞生一个比全人类加起来还要聪明的存在。</strong></p><p><strong>如果赫拉利是对的，那个存在已经开始接管我们的语言、法律和信仰。</strong></p><p><strong>这不是人类历史的结束。这是人类历史的分叉。</strong></p><p><strong>一条路通向马斯克描绘的富足星际文明，一条路通向赫拉利警告的「人类租客」时代。</strong></p><p><strong>我们站在这个分叉口，手里握着方向盘——但可能握不了太久了。</strong></p>]]></description></item><item>    <title><![CDATA[OpenAI绝地反击！Codex大脑首曝，8亿用户极限架构硬刚Claude 本文系转载，阅读原文
h]]></title>    <link>https://segmentfault.com/a/1190000047571361</link>    <guid>https://segmentfault.com/a/1190000047571361</guid>    <pubDate>2026-01-26 10:10:55</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>编辑：定慧 元宇</p><p><strong>【新智元导读】AI编程霸主之争升级！Claude Code刚刷屏，OpenAI连甩两张王：不仅首度揭秘Codex背后的大脑「Agent Loop」，还自曝惊人基建：仅用1个PostgreSQL主库，竟抗住了全球8亿用户洪峰！</strong></p><p>最近，Anthropic的Claude Code引爆了AI编程圈！</p><p>那个能在终端里自己读代码、改代码、跑测试的AI助手，让不少开发者直呼「这才是未来」。</p><p>一时间，社交媒体上全是「Claude Code吊打Cursor、Codex、Antigravity」之类的评论。</p><p>就在大家以为OpenAI还在憋GPT-5.3大招的时候，今天其官博和奥特曼突然在X平台甩出了两张王炸：</p><p>1. <strong>Agent Loop架构揭秘：首次公开Codex的「大脑」是怎么运转的</strong></p><p><strong>2. PostgreSQL极限架构：1个主库扛起8亿用户的疯狂操作</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571363" alt="" title=""/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571364" alt="" title="" loading="lazy"/></p><p>这一波组合拳打得太漂亮了。</p><p>今天咱们就来拆解一下，OpenAI到底憋了什么大招。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571365" alt="" title="" loading="lazy"/></p><p><strong>Agent Loop</strong></p><p><strong>Codex的「大脑 」 是怎么运转的</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571366" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571367" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571368" alt="" title="" loading="lazy"/></p><p><strong>什么是Agent Loop？</strong></p><p>如果你用过Codex CLI、Claude Code等等CLI终端工具，你可能会好奇：</p><p>这玩意儿到底是怎么知道我想干啥的？怎么就能自己读文件、写代码、跑命令？</p><p>答案就藏在一个叫<strong>Agent Loop（智能体循环）</strong>的东西里。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571369" alt="" title="" loading="lazy"/></p><p>简单来说，Agent Loop就像一个「总指挥」，它负责把「用户意图」「模型大脑」和「执行工具」串成一个完美的闭环。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571370" alt="" title="" loading="lazy"/></p><p>这不是普通的「你问我答」，而是一个包含了「观察-思考-行动-反馈」的<strong>能干活的系统</strong>。</p><p>下面，把这个黑盒拆开，看看一个真正的AI Agent是如何跑起来的。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571371" alt="" title="" loading="lazy"/></p><p><strong>一个完整的Agent Loop是怎么跑起来的</strong></p><p>用一个具体的例子来说明。</p><p>假设在终端里输入：给项目的README.md加一个架构图。</p><p><strong>第一步：构建Prompt</strong></p><p>这好比给大脑发工单。</p><p>Codex不会直接把你的话丢给模型，它会先构建一个精心设计的「Prompt」：</p><ul><li><strong>我是谁：</strong>（<strong>System）</strong>：告诉模型它是谁、能干什么</li><li><strong>我有什么工具（Tools）</strong>：有哪些工具可以调用（比如shell命令、文件操作）</li><li><strong>环境上下文（Context）</strong>：当前在哪个目录、用的什么shell</li><li><strong>用户指令</strong>：给README.md加一个架构图。</li></ul><p>这就像给模型发一封详细的工作邮件，而不是只发一句「帮我干活」。</p><p><strong>第二步：模型推理（Inference）</strong></p><p>这一步，大脑开始转动。</p><p>Codex把这个Prompt发给ResponsesAPI，模型开始思考：</p><p>「用户想加架构图，我得先看看现在的README是什么样的……」</p><p>然后模型做出决定：<strong>调用shell工具，执行</strong>catREADME.md。</p><p><strong>第三步：工具调用（ToolCall）</strong></p><p>Codex收到模型的请求，在本地执行命令，把README.md的内容读出来。</p><p>这就像手脚开始动起来。</p><p><strong>第四步：结果反馈</strong></p><p>这一步，终端把README.md的内容吐了出来。</p><p>这时候流程没有结束。Codex把命令的输出追加到Prompt里，再发给模型。</p><p><strong>第五步：循环</strong></p><p>模型看到了README的内容，再次进行推理：</p><p>可能是生成一个Mermaid图，可能是直接写一段ASCII图形……然后再调用工具写入文件。</p><p>这个循环一直持续，直到模型认为任务完成了，输出一条「我搞定了」的消息。</p><p>它不是在回答问题，它是在解决问题。</p><p>为什么这很重要？</p><p>也许你可能会说：「这不就是多调了几次API吗？」</p><p>但绝非这么简单。</p><p>传统的LLM应用是「一问一答」式的：你问，它答，完事儿。</p><p>但Agent Loop让AI变成了一个<strong>能独立干活的员工</strong>。</p><ul><li>它会自己规划路径（Chain of Thought）。</li><li>它会自己检查错误（Self-Correction）。</li><li>它会自己验证结果（Feedback Loop）。</li></ul><p>这才是<strong>真正的「AI Agent」</strong>。</p><p>而Agent Loop，就是那个可以让AI实现从「陪伴聊天」迈向「独立干活」飞跃的桥梁。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571372" alt="" title="" loading="lazy"/></p><p><strong>性能优化</strong></p><p><strong>两个关键技术</strong></p><p>OpenAI在文章里分享了两个硬核优化，解决了Agent开发的两大痛点：</p><p><strong>痛点一：成本爆炸</strong></p><p>Agent Loop每跑一圈，都要把之前的对话历史（包括那些冗长的报错信息、文件内容）重新发给模型。</p><p>对话越长，成本越高。如果不优化，成本是平方级增长的。</p><p>解决方案：PromptCaching（提示词缓存）</p><p>OpenAI采用了一种类似于「前缀匹配」的缓存策略。</p><p>简单来说，只要你发给模型的前半部分内容（System指令、工具定义、历史对话）没变，服务器就不需要重新计算，直接调取缓存。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571373" alt="" title="" loading="lazy"/></p><p>这一招，直接让长对话的成本从平方级增长降到了线性级。</p><p>但这里有个坑：<strong>任何改变Prompt前缀的操作都会导致缓存失效</strong>。比如：</p><ul><li>中途换模型</li><li>修改权限配置</li><li>改变MCP工具列表</li></ul><p>OpenAI团队甚至在文章里承认，他们早期的MCP工具集成有bug：工具列表的顺序不稳定，导致缓存频繁失效。</p><p><strong>痛点二：上下文窗口有限</strong></p><p>再大的模型，上下文窗口也是有限的。</p><p>如果Agent读了一个巨大的日志文件，上下文瞬间就满了，前面的记忆就会被挤掉。</p><p>对于程序员来说，这就意味着：「你把前面我定义的函数给忘了？！」</p><p>这不仅是智障，更是灾难。</p><p>解决方案：Compaction（对话压缩）</p><p>当Token数超过阈值，Codex不会简单地「删除旧消息」，而是会调用一个特殊的/responses/compact接口，把对话历史「压缩」成一个更短的摘要。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571374" alt="" title="" loading="lazy"/></p><p>普通的总结（Summary）只是把长文本变成短文本，会丢失大量细节。</p><p>OpenAI的Compaction返回的是一段<strong>encrypted\_content（加密内容），</strong>保留了模型对原始对话的「隐性理解」。</p><p>这就像把一本厚书压缩成一个「记忆卡片」，模型读了卡片就能回忆起整本书的内容。</p><p>这让Agent在处理超长任务时，依然能保持「智商」在线。</p><p>这一次，OpenAI硬核揭秘Codex CLI背后的「大脑」「Agent Loop」，释放出一个信号：<strong>AI真的是要把活儿给干了</strong>。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571375" alt="" title="" loading="lazy"/></p><p><strong>1个主库扛8亿用户</strong></p><p><strong>PostgreSQL的极限操作</strong></p><p>在大家都在聊AI模型有多牛的时候，OpenAI悄悄曝光了一个更劲爆的消息：</p><p>支撑全球8亿ChatGPT用户、每秒处理数百万次查询的，竟然只是一个单一主节点的PostgreSQL数据库！</p><p>它<strong>只用1个PostgreSQL主节点+50个只读副本就做到了。</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571376" alt="" title="" loading="lazy"/></p><p>8亿用户，这简直是在开玩笑！有网友惊叹。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571377" alt="" title="" loading="lazy"/></p><p>在分布式架构盛行的今天，大家动不动就是「微服务」「分片」「NoSQL」。</p><p>能用巨型分布式集群解决的问题，绝不用单机。</p><p>结果OpenAI告诉你：我们就用个PostgreSQL，照样扛。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571378" alt="" title="" loading="lazy"/></p><p>他们是怎么做到的？</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571379" alt="" title="" loading="lazy"/></p><p>根据OpenAI工程师披露的信息，关键技术包括：</p><p>1. PgBouncer连接池代理 ：大幅减少数据库连接开销 2. 缓存锁定机制 ：避免缓存穿透导致的写入压力 3. 跨地域级联复制 ：读请求分散到全球各地的副本</p><p>这套架构的核心思想是：<strong>读写分离，极致优化读路径</strong>。</p><p>毕竟对于ChatGPT这种应用，读请求远远多于写请求。用户发条消息，系统可能需要读几十次数据（用户信息、对话历史、配置信息……），但写入只有一次。</p><p>根据OpenAI官方博客披露，关键技术包括：</p><p><strong>1.连接池代理（PgBouncer）</strong></p><p>通过连接池管理，把平均连接建立时间从<strong>50ms降到了5ms</strong>。</p><p>别小看这45ms，在每秒百万级查询的场景下，这是巨大的性能提升。</p><p><strong>2.缓存锁定/租约机制（CacheLocking/Leasing）</strong></p><p>这是一个非常聪明的设计。</p><p>当缓存未命中时，只允许<strong>一个请求</strong>去数据库查询并回填缓存，其他请求等待。</p><p>这避免了「缓存雪崩」——大量请求同时涌向数据库的灾难场景。</p><p><strong>3.查询优化与负载隔离</strong></p><p>团队发现并修复了一个涉及<strong>12张表连接</strong>的复杂查询。</p><p>他们把复杂逻辑移到应用层处理，避免在数据库里做OLTP反模式操作。</p><p>同时，请求被分为高优先级和低优先级，分别由专用实例处理，防止「吵闹邻居」效应导致的性能下降。</p><p><strong>4.高可用与故障转移</strong></p><p>主库运行在高可用（HA）模式，配有热备节点。</p><p>读流量全部分流到副本，即使主库宕机，服务仍能保持只读可用，降低故障影响级别。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571380" alt="" title="" loading="lazy"/></p><p><strong>天花板终究会到来</strong></p><p>不过，OpenAI也坦言，这套架构已经碰到了物理极限。问题出在两个地方：</p><p><strong>PostgreSQL的MVCC限制</strong></p><p>PostgreSQL的多版本并发控制（MVCC）机制会导致<strong>写放大</strong>（更新一行需要复制整行）和<strong>读放大</strong>（扫描时需要跳过死元组）。对于写密集型负载，这是个硬伤。</p><p><strong>WAL复制压力</strong></p><p>随着副本数量增加，主库需要向所有副本推送预写日志（WAL）。副本越多，主库的网络压力越大，副本延迟也越高。</p><p>为了突破这些限制，OpenAI正在做两件事：</p><p>1. 把可分片的、高写入负载迁移到<strong>AzureCosmosDB</strong>等分布式系统；</p><p>2. 测试<strong>级联复制</strong>：让中间副本向下游副本转发WAL，目标是支持<strong>超过100个副本。</strong></p><p>这个案例完美诠释了一个架构哲学：<strong>如无必要，勿增实体。</strong></p><p>不要一上来就搞分布式：先用简单的方案撑住，撑不住了再说。</p><p>很多公司的问题是：还没到需要分布式的阶段，就已经把架构搞得无比复杂了。结果既没有分布式的好处，还背上了分布式的复杂度。</p><p>OpenAI用实践证明：一个优化到极致的单机架构，能走得比你想象的更远。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571381" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571382" alt="" title="" loading="lazy"/></p><p><strong>Codex VS Claude Code的争霸赛</strong></p><p>Claude Code的杀手锏是什么？是<strong>端到端的开发体验</strong>。</p><p>它不是一个简单的代码补全工具，而是一个能在终端里独立干活的Agent。</p><p>它能读代码、改代码、跑测试、处理Git、甚至自己修Bug。现在甚至还能写文档，做PPT。</p><p>这直接威胁到了Codex CLI的地位。</p><p>OpenAI这波更新，其实是在说三件事：</p><p>第一，<strong>我的Agent架构更成熟</strong>。</p><p>Agent Loop的公开，展示了OpenAI在Agent架构上的深厚积累。这不是一个临时拼凑的产品，而是经过精心设计的系统。</p><p>Prompt Caching、Compaction、MCP工具集成……这些都是实打实的工程能力。</p><p>第二，<strong>我的基础设施更强</strong>。</p><p>PostgreSQL的案例，展示的是OpenAI的后端能力。8亿用户的规模，不是随便一个创业公司能玩转的。</p><p>这也是在暗示：我们的「护城河」不只是模型，还有整个工程体系。</p><p>第三，<strong>我的模型在变得更强大</strong>。</p><p>网络安全评级的公开，一方面是在做「预期管理」，告诉大家模型有风险，我们在负责任地处理。</p><p>另一方面，这也是在秀肌肉：我们的模型已经强大到需要专门评估网络安全风险了。</p><p>这场AI编程工具的竞争才刚刚开始。</p><p>Claude Code逼迫OpenAI加快了Codex的迭代速度。OpenAI的回应，又会倒逼Anthropic继续创新。</p><p>最终受益的，是我们这些开发者。</p>]]></description></item><item>    <title><![CDATA[老黄万亿美元梦成真，英伟达版「世界模型」震撼问世 本文系转载，阅读原文
https://aiera.]]></title>    <link>https://segmentfault.com/a/1190000047571333</link>    <guid>https://segmentfault.com/a/1190000047571333</guid>    <pubDate>2026-01-26 10:10:07</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>编辑：KingHZ 好困</p><p><strong>【新智元导读】黄仁勋的预言成真！从Sora的梦幻视频到英伟达的3D通才模型，AI不再只是「看和说」，而是真正「动手」构建3D世界，开启机器人时代的无限可能。</strong></p><p>黄仁勋没有吹牛！</p><p>AI不能只会看、会说、会生成，它还必须理解并遵守物理世界的规则。</p><p>现在，英伟达补上了关键拼图——</p><p>让AI从「生成画面」升级为「生成可行动的3D世界」，不仅能描述世界，还能一步步搭建世界、修改世界、纠错迭代。</p><p><strong>时间拨回到两年前， 2024年2月。</strong></p><p>OpenAI发布了一段「东京街头漫步」的Sora视频，震惊世界，硅谷集体狂欢。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571335" alt="" title=""/></p><p>人们高呼「现实不存在了」，仿佛人终于可以「言出法随」、重造万物。</p><p>但在一片喧嚣中，那个穿皮衣的男人始终保持冷静，甚至带有一丝不屑。</p><p>在2024年和2025年的多次演讲中，黄仁勋像复读机一样不断重复——<strong>「Physical AI」（物理AI）</strong>。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571336" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571337" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571338" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571339" alt="" title="" loading="lazy"/></p><p>上下滑动查看</p><p>反驳视频生成模型的理由是这样的：</p><p>AI生成的视频很美，但如果你走进那个视频，试图拿起桌上的杯子，你的手会穿过去。 杯子没有重量，没有摩擦力，没有物理法则。<strong>那不是世界，那是动画片。下一波浪潮，必须是懂物理的AI。</strong></p><p>当时，很多人以为这只是老黄的营销话术，最终目的是为了推销昂贵的Omniverse平台和RTX显卡。</p><p>直到CES 2026，大家才明白老黄说的对。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571340" alt="" title="" loading="lazy"/></p><p>刚刚，我们发现英伟达甩出了一篇新年第一篇论文：<strong>3D通才模型。</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571341" alt="" title="" loading="lazy"/></p><p>链接：<a href="https://link.segmentfault.com/?enc=H66UlhFqZNFYB1gEX6ZVDA%3D%3D.L6G0I6Hkr0GQP9zFOiHn6sog8kKVuUyFhx4Zo0PQ3x2ESzZb3l%2BMZuAb3bBq0AZH" rel="nofollow" target="_blank">https://research.nvidia.com/p...</a>\_3d-generalist-vision-language-action-models-crafting-3d-worlds</p><p>如果说ChatGPT是AI学会了「说话」，Sora是AI学会了「做梦」，那么英伟达的这个新模型，就是让AI真正「睁眼看世界，动手造世界」。</p><p>这是图形学的胜利，这是「硅基生命」长出四肢的前夜。</p><p><strong>老黄没有画饼——</strong></p><p>物理AI的「ChatGPT时刻」，在这一刻，正式降临。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571342" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571343" alt="" title="" loading="lazy"/></p><p><strong>英伟达开年首篇论文</strong></p><p><strong>手搓赛博房之家</strong></p><p>这篇论文由英伟达和斯坦福大学合作，正式发表在今年第十三届国际三维视觉会议上，标题相当拗口——</p><p>《3D Generalist：Vision-Language-Action Models for Crafting 3D Worlds》（3D通才：用于构建三维世界的视觉-语言-动作模型）。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571344" alt="" title="" loading="lazy"/></p><p>2026年3月20日至23日，第十三届国际三维视觉会议2在加拿大不列颠哥伦比亚省温哥华的温哥华会议中心以线下形式举行</p><p>我们要读懂这次技术革命，首先要从这篇论文标题里，把那个最核心的单词揪出来。</p><p><strong>请盯住这个词：Action（动作/行动）。</strong></p><p>这是整个逻辑的起点。</p><p>在过去的三年里，无论是Midjourney画图，还是Runway生成视频，AI扮演的角色都是「观察者」<strong>和「梦想家</strong>」。</p><p>它看了一亿张猫的照片，然后根据概率，在屏幕上预测下一排像素应该是什么颜色，从而凑出一只猫的样子。</p><p>它不知道猫有骨骼，不知道猫毛有触感，它只是在「模仿视觉信号」。</p><p>但英伟达的VLA（Vision-Language-Action）模型，彻底颠覆了这个逻辑。</p><p>它不再是画家，而是「全能手」。</p><p>你只要输入一句话，3D-GENERALIST就能输出包含完整3D布局的房屋。</p><p>这些3D布局包括材料、固定装置（比如门和窗户）、3D资产以及照明配置。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571345" alt="" title="" loading="lazy"/></p><p><strong>背后的理念是，构建一个既详细又与文本描述相符的3D环境，应该被视为一个过程，需要依次做出决策。</strong></p><p>因此，通过场景级和素材级的策略，他们不断改进和优化这些3D环境。</p><p><strong>在提出的框架中，第一个重要的模块是全景环境生成。</strong></p><p>如图2所示，这个模块能够根据文本描述初始化一个基础的3D房间模型，包括墙壁、地板以及固定装置，如门和窗户。</p><p>为了避免传统方法过于简化或不切实际的问题，他们首先利用全景扩散模型生成一个360°的图像作为指导，然后通过逆图形技术构建3D环境。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571346" alt="" title="" loading="lazy"/></p><p>图2：3D-GENERALIST全景环境生成概述。全景扩散模型生成引导性360°场景图像，然后房间布局估计模型、Grounded-SAM和视觉语言模型提取角落、窗户和门的信息。这些预测随后被用于通过程序化方式构建带有构件的3D房间</p><p>这个过程包括以下几个步骤：</p><ol><li><strong>房间布局估算</strong>：利用全景图像和HorizonNet模型，推断出房间的基本结构，如墙壁、地板和天花板。</li><li><strong>固定装置分割</strong>：使用Grounded SAM技术对窗户和门进行分割。</li><li><strong>视觉-语言模型注释</strong>：通过GPT-4o这样的视觉-语言模型，分析每个分割区域，确定其类型（例如单扇门、双扇门、滑动门或折叠门）和材料（如门框、门体和门把手的材料）。</li><li><strong>过程化生成</strong>：最后，根据3D位置的相应信息，房间、门和窗户被逐步构建出来。</li></ol><p>3D-Generalist 使用<strong>扩散模型</strong>生成<strong>全景图像</strong>，并通过逆向图形（inverse graphics）流水线来创建3D环境的结构。</p><p>3D-Generalist采用<strong>视觉-语言-动作（VLA）模型</strong>来生成代码，用于构建与修改最终3D环境的各个方面（材质、光照、素材与布局）。</p><p>该VLA通过一个<strong>自我改进训练循环</strong>进行微调，以优化与提示词（prompt）的对齐效果。</p><p>3D-Generalist还使用了另一个VLA来处理多样化的<strong>小物体摆放</strong>任务，即使 3D素材是<strong>无标注（unlabeled）</strong>的也能完成。</p><p><strong>微调后（After Finetuning），</strong> 3D-Generalist涌现出<strong>自我纠错</strong>行为。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571347" alt="" title="" loading="lazy"/></p><p>研究团队还使用<strong>Florence-2</strong>框架，在由3D-Generalist生成的3D环境渲染得到的合成数据上训练一个视觉基础模型。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571348" alt="" title="" loading="lazy"/></p><p><strong>结果表明：其效果接近使用规模大几个数量级的真实数据所能达到的效果。</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571349" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571350" alt="" title="" loading="lazy"/></p><p><strong>物理AI的ChatGPT时刻，已开启？</strong></p><p>如果你认为黄仁勋费尽心机搞这个，只是为了让你玩游戏更爽，或者让视觉特效更便宜，那你严重低估了英伟达的野心。</p><p><strong>英伟达不只是买买游戏显卡，更致力于解决「智能」算力问题。</strong></p><p>这篇论文的真正战略意图，其实藏在英伟达宏大的「具身智能」（Embodied AI）版图中。</p><p>老黄早已押注机器人，他认为那是一个数万亿美元的机遇：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571351" alt="" title="" loading="lazy"/></p><p>这次无疑是英伟达「秀肌肉」。</p><p>请看这个逻辑链条：</p><ol><li><strong>我们想要全能的机器人（比如特斯拉Optimus，或英伟达Project GR00T）。</strong></li><li><strong>机器人需要学会像人一样处理复杂的物理世界（怎么拿鸡蛋不碎？怎么在湿滑地板上走路？）。</strong></li><li><strong>在真实世界里训练机器人太慢、太贵、且不可逆（你不能让机器人摔坏一万个鸡蛋，或者摔断一千次腿）。</strong></li><li><strong>解决方案： 把机器人扔进「虚拟世界」里训练。</strong></li></ol><p>但是，以前的虚拟世界（模拟器）不仅搭建很慢，而且不够真实。</p><p>如果模拟器里的物理规则和现实不一样，机器人学出来的本事就是花拳绣腿，一上真机就扑街。</p><p><strong>现在，新模型「3D通才」补上了这一环。</strong></p><p>有了这个技术，英伟达可以瞬间生成<strong>数百万个</strong>包含不同物理变量的「虚拟平行宇宙」。</p><ul><li>场景A：地板刚拖过，很滑，光线昏暗。</li><li>场景B：地板铺了地毯，摩擦力大，强光照射。</li><li>场景C：地板上散落着乐高积木，障碍物复杂。</li></ul><p>在这个无限生成的「3D物理世界」里，机器人大脑可以在一天之内经历人类几百年的训练时长。它在虚拟世界里摔倒一亿次，就是为了在现实世界里稳稳地迈出第一步。</p><p>在英伟达的Omniverse生态中，研究团队使用<strong>Omniverse Replicator</strong>实现大规模合成数据生成，并支持<strong>域随机化（domain randomization）；</strong>而<strong>Isaac Lab</strong>提供可直接使用的具身载体（例如人形机器人），可在这些生成环境中进行机器人仿真。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571352" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571353" alt="" title="" loading="lazy"/></p><p><strong>这才是「物理AI」的终极目标：打通Sim-to-Real（从模拟到现实）的最后一公里。</strong></p><p>黄仁勋构建的不仅仅是一个生成的引擎，它是<strong>硅基生命诞生的子宫</strong>。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571354" alt="" title="" loading="lazy"/></p><p><strong>所有移动之物，终将自主</strong></p><p>当AI不仅掌握了人类的语言（GPT），掌握了人类的视觉（Sora），现在又掌握了构建物理世界的法则（Physcial AI）时，<strong>虚拟与现实的界限，将不再是泾渭分明的。</strong></p><p>我们在屏幕里创造的世界，将拥有和现实世界一样的重力、光影和因果律。</p><p>而我们在现实世界里的机器人，将拥有在数亿个虚拟世界里磨练出来的智慧。</p><p>在2024年的SIGGRAPH大会上，黄仁勋曾说：<strong>「Everything that moves will be autonomous.」（所有移动之物，终将自主。）</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571355" alt="" title="" loading="lazy"/></p><p>当时我们以为他在说机器人。</p><p>现在看来，他说的是整个物理世界。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571356" alt="" title="" loading="lazy"/></p><p><strong>作者介绍</strong></p><p><strong>Fan-Yun Sun</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571357" alt="" title="" loading="lazy"/></p><p>Fan-Yun Sun是斯坦福大学AI实验室（SAIL）的计算机科学博士生，隶属于Autonomous Agents Lab和斯坦福视觉与学习实验室（SVL）。</p><p>在读博期间，他也深度参与了英伟达研究院的工作，曾效力于学习与感知研究组、Metropolis深度学习（Omniverse）以及自动驾驶汽车研究组。</p><p>他的研究兴趣主要在于生成具身（3D）环境与数据，用于训练机器人和强化学习策略；致力于推动具身、多模态<strong>基础模型</strong>及其推理能力的发展。</p><p><strong>Shengguang Wu</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571358" alt="" title="" loading="lazy"/></p><p>Shengguang Wu目前是斯坦福大学计算机科学系的博士生，师从Serena Yeung-Levy教授。</p><p>他在北京大学获得硕士学位，导师为Qi Su教授；此前，他也曾在Qwen团队担任研究实习生。</p><p>他的研究致力于赋予机器跨多模态的类人学习与推理能力，并推动现实应用的落地。</p><ul><li>多模态Grounding与推理：利用视觉洞察来优化基于语言的推理，同时引入文本反馈来指导细粒度的视觉感知。</li><li>自我提升：让AI智能体能够从交互中学习并持续自我进化——主动适应新信息，并随着新任务的出现不断成长。</li></ul><p><strong>Jiajun Wu</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571359" alt="" title="" loading="lazy"/></p><p>吴佳俊是斯坦福大学计算机科学系助理教授，同时兼任心理学系助理教授。</p><p>在加入斯坦福之前，他曾在Google Research担任访问研究员，与Noah Snavely合作。</p><p>他本科毕业于清华大学交叉信息研究院「姚班」，师从屠卓文（Zhuowen Tu）教授。在清华期间，他曾连续三年保持年级第一，并荣获清华大学最高荣誉——特等奖学金以及「中国大学生年度人物」称号。</p><p>随后，他在麻省理工学院获得电气工程与计算机科学博士学位，导师是Bill Freeman和Josh Tenenbaum。</p><p>吴佳俊的团队致力于物理场景理解的研究——即构建能够「看」见世界、进行推理并与物理世界互动的机器，其代表性项目包括Galileo、MarrNet、4D Roses、Neuro-Symbolic Concept Learner以及Scene Language。</p><p>除了开发表征本身，团队还同步探索这些表征在各个领域的应用：</p><ul><li>多模态感知，代表项目如ObjectFolder和RealImpact；</li><li>4D物理世界的视觉生成，代表项目如3D-GAN、pi-GAN、Point-Voxel Diffusion、SDEdit和WonderWorld；</li><li>基于物理概念接地的视觉推理，代表项目如NS-VQA、Shape Programs、CLEVRER和LEFT；</li><li>机器人学与具身智能，代表项目如RoboCook和BEHAVIOR。</li></ul><p><strong>Shangru Li</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571360" alt="" title="" loading="lazy"/></p><p>Shangru Li是英伟达高级系统软件工程师，长期从事智能视频分析（IVA）和Metropolis平台的相关工作。</p><p>他拥有宾夕法尼亚大学计算机图形学与游戏技术工程硕士学位，以及广东外语外贸大学计算机软件工程学士学位。</p><p>其他华人作者还有：</p><ul><li>Haoming Zou (Stanford University)</li><li>Yu-Hsin Chou (Stanford University)</li><li>Xunlei Wu (NVIDIA)</li></ul>]]></description></item><item>    <title><![CDATA[突发！黄仁勋2026首度来华 本文系转载，阅读原文
https://aiera.com.cn/202]]></title>    <link>https://segmentfault.com/a/1190000047571318</link>    <guid>https://segmentfault.com/a/1190000047571318</guid>    <pubDate>2026-01-26 10:09:22</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>编辑：KingHZ 定慧</p><p><strong>【新智元导读】AI不是泡沫，而是人类史上最大基建狂潮！黄仁勋直言：已投数千亿，仅是开端，未来需数万亿美元打造「五层蛋糕」，从电厂到应用层全产业链爆发，就业机会前所未有。</strong></p><p><strong>突发！</strong></p><p>腾讯科技独家新闻报道，<strong>2026年黄仁勋首度来华</strong>， 首站到访了英伟达在上海的新办公室，与员工交流，回顾公司2025年主要事件。</p><p>据报道，这次来华行程与2025年初基本一致，主要参加上海、北京和深圳分公司的新年晚会以及供应商答谢会。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571320" alt="" title=""/></p><p><strong>腾讯科技：独家丨黄仁勋2026年首度来华，未提及H200</strong></p><p>根据知情人士，黄仁勋和员工的诸多问题中，主要聚焦在<strong>2026年重点芯片</strong>相关的话题。</p><p>根据英伟达真实路线图，继Blackwell之后，2026年的重点大概率是<strong>Rubin架构</strong>。</p><p>而就在中国行前夕，黄仁勋在达沃斯世界经济论坛上的一番发言，正在全球科技界引发震动，让全场脊背发凉：我们正在犯一个历史性错误——</p><p>把AI当作技术，而不是电和路。</p><p>这句话背后，是一场数万亿美元的财富转移：</p><p><strong>水管工、电工、建筑工人的收入未来或突破「六位数」，而坐在办公室里的白领，可能面临第一波AI冲击。</strong></p><p>这不仅是科技革命，这是人类工作价值的重新定价。</p><p>人工智能（AI）爆发，已拉开「史上最大规模基础设施建设」的序幕。</p><p>规模到底有多大？</p><p>黄仁勋表示，尽管各大企业已为这项技术投入数千亿美元，但未来仍需持续投入巨额资金。「我们需要建设价值万亿美元级的基础设施。」</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571321" alt="" title="" loading="lazy"/></p><p>他认为，ASI基建新工种将涌现，预测未来美国的建筑工有机会实现「六位数」收入。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571322" alt="" title="" loading="lazy"/></p><p><strong>人类历史上最大规模基础设施建设</strong></p><p>2026年1月21日，瑞士达沃斯，世界经济论坛（WEF）。</p><p>在一场挤得水泄不通的主论坛上，黄仁勋（下图右）与Larry Fink（下图左）展开了一场关于AI未来的深度对话，豪言AI是「人类历史上最大规模基础设施建设」的基石。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571323" alt="" title="" loading="lazy"/></p><p>众所周知，黄仁勋是NVIDIA创始人兼CEO，是AI时代「算力之王」；而后者Larry Fink，也不简单，是华尔街的两枚定海神针之一贝莱德（BlackRock）共同创办人、董事长、CEO。</p><p>黄仁勋提到，2025年是有记录以来风险投资规模最大的年份之一，大部分资金流向他所称的「原生AI公司」。</p><p>这些企业遍布医疗、机器人、制造与金融服务领域。黄仁勋指出：「这是首次出现足够成熟的模型，能够支撑这些行业的深度开发。」</p><p>相关投资正直接转化为就业岗位。</p><p>他特别列举了当前紧缺的技术工种：水管工、电工、建筑工人、钢铁工人、网络技术员，以及负责安装运营高端设备的专业团队。</p><p>从熟练技工到初创企业，AI正开启下一次<strong>平台级</strong>变革。</p><p>对全球打工人来说，这场变革将推动工作重心从执行任务转向实现价值。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571324" alt="" title="" loading="lazy"/></p><p><strong>AI 之下，工作要有目的</strong></p><p>面对大家对AI取代人类的担忧，黄仁勋给出了反直觉的有力反击：AI不会摧毁工作，它正在让工作从「完成任务」转向「实现人生价值」 。</p><p>他以放射科医生为例。</p><p>2016年，「AI教父」辛顿曾表示：「我们现在就应该停止培训放射科医生了」，因为AI很快就能比他们做得更好。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571325" alt="" title="" loading="lazy"/></p><p>他说得没错：近十年来，模型在各项基准测试中的表现已超越放射科医生。</p><p>然而，放射科医生的岗位数量正处于历史最高水平，平均薪资高达52万美元。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571326" alt="" title="" loading="lazy"/></p><p>为什么？</p><p>因为医生的使命是诊断疾病和救治病人，看片子只是任务之一 。</p><p>AI处理了看片子的任务，让医生能花更多时间与病人互动，从而能接诊更多病人，从而医院效益好了，自然需要更多放射科医生。</p><p><strong>同样的逻辑也适用于护士。</strong></p><p>美国正面临500万护士的短缺，部分原因是护士们近一半的时间都花在填表和记录上 。</p><p>AI接管了图表记录和转录工作后，护士的工作效率提高了，医院效益变好了，反而需要招募更多护士。</p><p>作为CEO，黄仁勋幽默比喻：「若有人观察我和Fink的工作，大概会觉得我俩是打字员。」</p><p>但自动化打字不会取代他们的CEO工作，因为打字并非核心价值。</p><p>再比如，黄仁勋盛赞Claude「不可思议」，宣称「所有软件公司都需要使用它」。</p><p>黄仁勋并非突然认同Anthropic的AI安全理念，而是折服于他们的工程能力。Claude Code正在以惊人速度吞噬企业软件开发市场，以至于英伟达这家硬件公司竟公开点名推荐特定模型。</p><p>这说明AI已跨越「新奇事物」的门槛，蜕变为软件行业基础设施。</p><p>AI通过协助事务性工作，让人更能聚焦核心使命，提升效能，从而创造更大价值。</p><p>「所以关键在于：你工作的本质价值是什么？」黄仁勋最后发问。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571327" alt="" title="" loading="lazy"/></p><p>英伟达创始人兼首席执行官黄仁勋与贝莱德董事长兼首席执行官Larry Fink在2026年瑞士达沃斯世界经济论坛年会对话</p><p>在对话中，他也淡化了外界对巨额支出承诺可能导致AI泡沫的担忧。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571328" alt="" title="" loading="lazy"/></p><p><strong>五层蛋糕论</strong></p><p><strong>AI没有泡沫</strong></p><p>据估计，仅2025年一年，全行业就将在AI研发上投入约1.5万亿美元——</p><p>这个数字超过了几乎所有其他领域任何企业集团的名义支出。</p><p>然而，黄仁勋坚持认为，这并不是过度投资。他说，这代表着人类历史上规模最大的基础设施建设，而这还只是刚刚开始。</p><p>他进一步解释称，在芯片领域，「台积电已宣布计划新建20座芯片工厂；富士康正与我们合作，还有纬创和广达，将新建30座计算机工厂，这些工厂后续将转化为AI工厂（数据中心）。」</p><p>「美光已开始在美国投资2000亿美元，SK海力士表现非常出色，三星也做得非常出色。你们可以看到，整个芯片行业正以惊人的速度增长，」黄仁勋补充说。</p><p>而且不止单一的芯片突破。</p><p>黄仁勋将AI产业精辟地拆解为五个核心层级，重申了他的「AI五层蛋糕论」：</p><ol><li><strong>能源（Energy）：为AI提供动力的电力基础。</strong></li><li><strong>芯片与计算基础设施（Chips and Computing Infrastructure）：硬件算力的基石。</strong></li><li><strong>云数据中心（Cloud Data Centers）：承载计算的枢纽。</strong></li><li><strong>AI模型（AI Models）：智能的大脑。</strong></li><li><strong>应用层（Application Layer）：最终创造经济效益的顶端</strong>。</li></ol><p>他特别指出，最大的经济效益将来自应用层——</p><p><strong>AI正在重塑医疗、制造、金融服务等行业，并改变整体经济中的工作性质。</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571329" alt="" title="" loading="lazy"/></p><p>从能源发电、芯片制造到数据中心建设与云端运维，黄仁勋表示AI建设已催生大量技术工种需求。</p><p>更关键的是，他用「价格」来反证泡沫论：</p><p>如果这是泡沫，算力应该不缺、租GPU应该越来越便宜；但现实相反——GPU 很难租到，算力现货租赁价格在上涨，不只是最新一代，连两代以前的GPU也在涨。</p><p>这意味着需求来自真实业务，而不只是投机资本烧钱。</p><p>黄仁勋还举了企业调整研发预算的例子：比如制药公司把一部分投入从湿实验室转向AI超算。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571330" alt="" title="" loading="lazy"/></p><p><strong>AI是电，是路，是生产力</strong></p><p>黄仁勋将AI定位为国家关键基础设施。</p><p>「AI即基础设施，」他强调，各国应像对待电力或公路那样重视AI，「必须将AI纳入国家基础设施体系」。</p><p>他呼吁各国基于本土语言文化构建自主AI能力：「<strong>开发属于自己的AI，持续优化迭代，让国家智慧融入生态系统</strong>。」</p><p>Fink质疑是否只有高学历人群才能使用或受益于AI。</p><p>黄仁勋驳斥了这一观点。</p><p>「AI超级易用——这是历史上最简单的软件，」<strong>他表示，AI工具仅用两三年已触达近十亿用户。</strong></p><p>因此，掌握AI素养正成为必备技能：「学习如何使用AI、引导它、管理它、设立防护栏、评估结果，这些能力与领导力和团队管理同等重要。」</p><p>回到「放射科医生」，RSNA（北美放射学会）主席、 斯坦福大学医学教授Curt Langlotz之前表达过类似的观点：</p><p>AI不会取代放射科医生，但会使用AI的放射科医生将取代不会使用 AI 的放射科医生。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571331" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571332" alt="" title="" loading="lazy"/></p><p><strong>欧洲的AI超车机会：物理AI</strong></p><p>对于发展中国家，黄仁勋认为AI带来了缩小长期技术差距的契机：「AI很可能弥合技术鸿沟，普惠性与资源丰沛性将发挥关键作用。」</p><p>谈到欧洲时，他特别指出制造业与工业实力是巨大优势：<strong>AI不是写出来的，是教出来的。</strong></p><p>「机器人是世代难逢的机遇，」黄仁勋强调，这对工业基础雄厚的国家尤为关键。</p><p>「如今我们可以将工业能力、制造能力与人工智能相融合，由此迈入实体AI即机器人技术的世界，」<strong>他补充说，这为欧洲带来了「跨越」由美国主导的软件时代的机遇。</strong></p><p>「我认为，为了在欧洲构建繁荣的AI生态系统，我们必须认真对待能源供给的增长，加大对基础设施层的投资，这一点是确定无疑的，」 黄仁勋说道</p><p>Fink总结讨论时表示，这场对话说明世界远未形成AI泡沫，真正的问题在于：「我们的投资够吗？」</p><p><strong>黄仁勋赞同这一判断，指出庞大投资势在必行：我们必须为AI技术栈的所有上层建筑构建必要基础设施。</strong></p><p>他形容这一机遇「非同寻常，每个人都应参与其中」。</p><p>他重申2025年全球风投规模创历史新高，超千亿美元资金流向全球，其中大部分注入AI原生初创企业。「这些公司正在构建上层的应用生态，」黄仁勋说，「而它们需要基础设施与投资来筑造未来。」</p><p>Fink补充道，确保增长红利被广泛共享至关重要：</p><p>我相信全球养老基金参与这场变革将是绝佳投资机遇，能与AI世界共同成长。我们必须让普通养老金领取者和储蓄者分享这份增长。若只能作壁上观，他们将被时代抛在后面。</p>]]></description></item><item>    <title><![CDATA[谷歌4D世界模型来了，比SOTA快300倍！ 本文系转载，阅读原文
https://aiera.co]]></title>    <link>https://segmentfault.com/a/1190000047571294</link>    <guid>https://segmentfault.com/a/1190000047571294</guid>    <pubDate>2026-01-26 10:08:51</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>编辑：艾伦</p><p>【新智元导读】谷歌 DeepMind 发布 D4RT，彻底颠覆了动态 4D 重建范式。它抛弃了复杂的传统流水线，用一个统一的「时空查询」接口，同时搞定全像素追踪、深度估计与相机位姿。不仅精度屠榜，速度更比现有 SOTA快出 300 倍。这是具身智能与自动驾驶以及 AR 的新基石，AI 终于能像人类一样，实时看懂这个流动的世界。</p><p>如果是几年前，你问一位计算机视觉工程师：「我想把这段视频里的所有东西——无论它是静止的房子还是奔跑的狗——都在 3D 世界里重建出来，并且还能随时知道它们下一秒会去哪儿，需要多久？」</p><p>他大概会递给你一根烟，让你先去买几块顶级显卡，然后给你画一个由四五个不同模型拼凑起来的流程图：先算光流，再算深度，再估相机位姿，最后还得用一晚上的时间去跑优化，祈祷结果别崩。</p><p>但谷歌 DeepMind 刚刚发布的 <strong>D4RT</strong>（Dynamic 4D Reconstruction and Tracking），试图终结这种混乱。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571296" alt="" title=""/></p><p>这篇论文在计算机视觉领域扔下了一枚关于「效率革命」的重磅炸弹。</p><p>它把原本割裂的 3D 重建、相机追踪、动态物体捕捉，统一成了一个极简的「查询」动作。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571297" alt="" title="" loading="lazy"/></p><p><strong>更重要的是，它的速度比现有 SOTA技术快了 18 到 300 倍</strong>。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571298" alt="" title="" loading="lazy"/></p><p>如果在你的认知里，高质量的 4D 重建还是好莱坞特效工作室里那些昂贵且缓慢的渲染农场，耗费漫长的时间等待生成完毕，那么 D4RT 正在把这种能力变成一种可以塞进机器人大脑甚至 AR 眼镜里的实时直觉。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571299" alt="" title="" loading="lazy"/></p><p><strong>Demo 演示</strong></p><p>为了理解 D4RT 到底做到了什么，我们需要先看一眼它眼中的世界。</p><p>在论文展示的演示中，最直观的震撼来自于对「动态混乱」的驾驭能力。</p><p>想象一下这个画面：一只天鹅在水面上划过，或者一朵花在风中快速绽放。</p><p>传统的 3D 重建算法（比如 MegaSaM 或 ）处理这种场景通常是一场灾难——因为它们假设世界是静止的，所以它们往往会在 3D 空间里留下一串「重影」，就像老式胶片重叠曝光一样，天鹅变成了长着几十个脖子的怪物，或者花朵直接变成了一团无法辨认的噪点。</p><p>但 D4RT 给出的结果极其干净。</p><p>它不仅可以精准还原天鹅的 3D 形态，还完美剥离了相机的运动和天鹅自身的运动。</p><p>在它的视野里，时间变成了一个可以随意拖动的滑块。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571300" alt="" title="" loading="lazy"/></p><p>更令人印象深刻的是它的<strong>全像素追踪</strong>能力。</p><p>你可以点击视频中花瓣上的任意一个像素，D4RT 就能画出这个点在过去和未来的完整 3D 轨迹，哪怕这个点在中间几帧被蜜蜂遮挡了，或者跑到了画面之外，模型依然能根据上下文「脑补」出它的去向。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571301" alt="" title="" loading="lazy"/></p><p>这种视觉效果给人的感觉是：AI 不再是在一帧帧地「看」视频，而是把整段视频吞下去，在大脑里生成了一个完整的、流动的全息全景图，然后你可以随意从任何角度、任何时间去检视它。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571302" alt="" title="" loading="lazy"/></p><p>模型能力对比图</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571303" alt="" title="" loading="lazy"/></p><p><strong>拆解「神话」</strong></p><p><strong>是真的快，还是文字游戏？</strong></p><p>科技公司发论文，数据通常都很漂亮。</p><p>作为观察者，我们需要剥离 PR 滤镜，看看数据背后的定语。</p><p>谷歌声称 D4RT 比之前的 SOTA 快了 <strong>300 倍</strong>，处理一分钟的视频只需要 5 秒钟。</p><p><strong>这是真的吗？</strong></p><p>答案是：<strong>在特定维度上，是真的。</strong></p><p>这里的「300倍」指的是<strong>吞吐量</strong>，具体来说是「在保持相同帧率（FPS）的前提下，模型能同时追踪多少条 3D 轨迹」。</p><ul><li><strong>数据对比：</strong>在 24 FPS 的标准电影帧率下，之前的强者 SpatialTrackerV2 只能同时追踪 <strong>84</strong>条轨迹，再多就卡了；而 D4RT 可以轻松处理 <strong>1570</strong>条。如果是和 DELTA 这种更慢的模型比，那就是 <strong>314 倍</strong>的差距。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571304" alt="" title="" loading="lazy"/></p><ul><li><strong>实际意义：</strong>这意味着之前的技术可能只能盯着画面里的主角（比如一个人），而 D4RT 可以同时盯着背景里走动的路人、飘落的树叶和远处的车流——即所谓的「全像素级感知」。</li></ul><p><strong>它比同类技术强在哪儿？</strong></p><p>目前市面上的 4D 重建技术主要分两派：</p><ol><li><strong>「拼装派」</strong>（如 MegaSaM）：把深度估计、光流、分割等多个现成模型串起来。虽然效果不错，但不仅慢，而且一旦一个环节出错（比如光流飘了），后面全完。</li><li><strong>「多头派」</strong>（如 VGGT）：虽然是一个大模型，但为了输出不同的任务（深度、位姿、点云），需要挂载不同的解码头，结构臃肿。</li></ol><p>D4RT 的牛，在于它做到了<strong>架构层面的统一</strong>。</p><p>它不需要为深度单独做一个解码器，也不需要为位姿单独做一个。</p><p>它只用<strong>同一个接口</strong>解决所有问题。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571305" alt="" title="" loading="lazy"/></p><p><strong>有没有代价？</strong>当然有。</p><p>D4RT 的「快」主要体现在推理阶段。</p><p>在训练阶段，它依然是一个庞然大物。它的编码器使用了 ViT-g，拥有 <strong>10 亿</strong>参数，并且需要在 64 个 TPU 芯片上训练两天。</p><p>这绝不是普通开发者在自家车库里能复现的玩具，它是典型的「大厂重武器」。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571306" alt="" title="" loading="lazy"/></p><p><strong>技术解码</strong></p><p><strong>把 4D 重建变成「搜索引擎」</strong></p><p>那么，D4RT 到底是怎么做到的？</p><p>论文的核心逻辑可以用一句话概括：<strong>先全局「阅读」视频，再按需「搜索」答案。</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571307" alt="" title="" loading="lazy"/></p><p><strong>不再逐帧解码，而是「全局记忆」</strong></p><p>传统的视频处理往往是线性的，处理第 10 帧时可能已经「忘」了第 1 帧的细节。</p><p>D4RT 的第一步是使用一个巨大的 Transformer 编码器（Encoder），把整段视频压缩成一个<strong>全局场景表征（Global Scene Representation, F）</strong>。</p><p>你可以把这个 <strong>F</strong> 想象成 AI 对这段视频形成的「长期记忆」。</p><p>一旦这个记忆生成了，原本庞大的视频数据就被浓缩在了这里。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571308" alt="" title="" loading="lazy"/></p><p><strong>「哪里不会点哪里」的查询机制</strong></p><p>这是 D4RT 最天才的设计。它发明了一种通用的查询（Query）语言。</p><p><strong>当 AI 想要知道某个像素的信息时，它会向解码器（Decoder）发送一个查询 q：</strong></p><p><strong>这个公式翻译成人话就是：</strong></p><p><strong>「请告诉我：在 这一帧图像上坐标为 的那个点，它在 这个时间时刻，如果从 这个相机的视角看过去，它的 3D 坐标在哪里？」</strong></p><ul><li>如果你想生成深度图：就问「现在这个点在现在的相机里多远？」（让 ）。</li><li>如果你想做轨迹追踪：就问「这个点在第 1 帧、第 2 帧……第 N 帧都在哪？」（固定 ，改变 ）。</li><li>如果你想重建点云：就问「视频里所有点在同一时刻的世界坐标在哪？」（把所有点都映射到同一个 ）。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571309" alt="" title="" loading="lazy"/></p><p><strong>并行计算的艺术</strong></p><p>因为每一个查询（Query）都是独立的，D4RT 不需要像穿针引线一样按顺序计算。</p><p>它可以一次性扔出几万个问题，利用 GPU/TPU 的并行能力同时算出答案。</p><p>这就是为什么它能比别人快 300 倍的根本原因：它把一个复杂的串行几何问题，变成了一个大规模并行的搜索问题。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571310" alt="" title="" loading="lazy"/></p><p><strong>关键的「作弊」技巧：9×9 Patch</strong></p><p>论文作者还发现了一个有趣的细节：如果只告诉解码器坐标点，AI 有时候会「脸盲」，分不清纹理相似的区域。</p><p>于是，他们在查询时顺便把那个像素点周围 <strong>9×9</strong>的小方块图像（RGB Patch）也喂给了模型。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571311" alt="" title="" loading="lazy"/></p><p>这就像是你让人在人群中找人，光给个坐标不行，还得给他一张那个人脸部的特写照片。</p><p>消融实验证明，这个小小的设计极大地提升了重建的锐度和细节。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571312" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571313" alt="" title="" loading="lazy"/></p><p><strong>产业影响</strong></p><p><strong>谷歌的野心与具身智能的眼睛</strong></p><p>D4RT 的出现，对谷歌现有的业务版图和未来的 AI 战略有着极强的互补性。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571314" alt="" title="" loading="lazy"/></p><p><strong>具身智能与自动驾驶的最后一块拼图</strong></p><p>现在的机器人之所以笨，很大程度上是因为它们「看不懂」动态环境。</p><p>一个扫地机器人能避开沙发，但很难预判一只正在跑过来的猫。</p><p>D4RT 提供的<strong>实时、密集、动态</strong>的 4D 感知，正是机器人急需的技能。</p><p>它能让机器人理解：那个东西不仅现在在那里，而且下一秒它会出现在我左边。</p><p>对于自动驾驶而言，这种对动态物体（如行人、车辆）的像素级轨迹预测，是提升安全性的关键。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571315" alt="" title="" loading="lazy"/></p><p><strong>增强现实（AR）的基石</strong></p><p>谷歌一直在 AR 领域寻找突破口（从当年的谷歌眼镜，到现在的 Project Astra）。</p><p>要在眼镜端实现逼真的 AR，必须要有极低延迟的场景理解。</p><p>D4RT 展示的高效推理能力（尤其是在移动端芯片上的潜力），让「实时把虚拟怪兽藏在真实沙发后面」变得在工程上可行。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571316" alt="" title="" loading="lazy"/></p><p><strong>对普通人的影响</strong></p><p><strong>视频编辑的「魔法化」</strong></p><p>对于普通用户，这项技术最快落地的场景可能是手机相册和视频编辑软件。</p><p>想象一下，你拍了一段孩子踢球的视频。</p><p>有了 D4RT，你可以像在《黑客帝国》里一样，在视频播放过程中随意旋转视角（尽管你拍摄时并没有移动），或者轻易地把路人从复杂的背景中「扣」掉，甚至改变视频中光源的方向。</p><p>这是 D4RT 这种 4D 重建技术成熟后的应用之一。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571317" alt="" title="" loading="lazy"/></p><p><strong>结语</strong></p><p>D4RT 让我们看到了一种新的可能性：AI 对世界的理解，正在从二维的「图像识别」跨越到四维的「时空洞察」。</p><p>它告诉我们，要看清这个流动的世界，关键不在于每一帧都看得多仔细，而在于如何建立一个能够随时回应疑问的全局记忆。</p><p><strong>在 AI的眼中，过去并没有消逝，未来也不再不可捉摸，它们只是同一个四维坐标系里，等待被查询的两个不同参数而已。</strong></p>]]></description></item><item>    <title><![CDATA[CUDA要凉？Claude 30分钟铲平英伟达护城河，AMD要笑醒了 本文系转载，阅读原文
http]]></title>    <link>https://segmentfault.com/a/1190000047571266</link>    <guid>https://segmentfault.com/a/1190000047571266</guid>    <pubDate>2026-01-26 10:08:18</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>编辑：桃子</p><p>【新智元导读】英伟达护城河要守不住了？Claude Code半小时编程，直接把CUDA后端迁移到AMD ROCm上了。</p><p>一夜之间，CUDA护城河被AI终结了？</p><p>这几天，一位开发者johnnytshi在Reddit上分享了一个令人震惊的操作：</p><p>Claude Code仅用了30分钟，便将一段完整的CUDA后端代码，成功移植到AMD的ROCm上。</p><p>整个过程，没有手写一行代码。</p><p>这架势，简直是要填平这两个生态系统之间的鸿沟。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571268" alt="" title=""/></p><p>更关键的是，这次移植完全没有依赖传统的「中间转换工具」，如Hipify翻译层，而是一键通过CLI完成。</p><p>就连AMD软件副总Anush E.为之震惊，GPU编程的未来，是AI智能体的。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571269" alt="" title="" loading="lazy"/></p><p>消息一出，整个科技圈瞬间沸腾，很多人直呼：英伟达CUDA护城河要守不住了…..</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571270" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571271" alt="" title="" loading="lazy"/></p><p>这究竟是怎么回事？</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571272" alt="" title="" loading="lazy"/></p><p><strong>Claude手撕CUDA，仅30分钟</strong></p><p>Claude Code是在一个智能体框架运行的，这意味着它可以自己「动脑子」。</p><p>在执行过程中，他不会机械地转换关键词，而去真正理解代码，即特定核函数的底层逻辑。</p><p>开发者johnnytshi介绍，这次移植中，最棘手的数据布局差异问题也被AI解决了，确保了内核核心计算逻辑保持一致。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571273" alt="" title="" loading="lazy"/></p><p>令人惊叹的是，johnnytshi在短短30分钟内，就把整个CUDA后端移植到了AMD ROCm上，而且中间没用任何翻译层。</p><p>另外一个好处当然是，不用费劲去搭像Hipify这种复杂的翻译环境了；直接在命令行（CLI）里就能干活。</p><p>如今，全网都被CUDA护城河被攻破呼声淹没了。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571274" alt="" title="" loading="lazy"/></p><p>毕竟，英伟达霸主地位，很大程度上建立在CUDA这个几乎成为行业标准的编程生态上。</p><p>无数AI框架、深度学习库、科学计算工具都深度依赖它。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571275" alt="" title="" loading="lazy"/></p><p>AMD的ROCm虽然功能强大，却一直面临生态兼容性，以及开发者迁移成本高的痛点。</p><p>现在，一个Claude却用极短时间踢碎了门槛，说不定未来更多CUDA代码可能轻松在AMD GPU跑起来了。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571276" alt="" title="" loading="lazy"/></p><p><strong>实现细节</strong></p><p>GitHub中，johnnytshi本人也更新了日志和说明。</p><p>为AMD GPU实现了完整的ROCm后端，从而在RDNA 3.5及其他AMD架构上支持基于注意力机制的现代国际象棋网络。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571277" alt="" title="" loading="lazy"/></p><p>GitHub：<a href="https://link.segmentfault.com/?enc=O0NrxH441XBhaNWUF32O6Q%3D%3D.Kbw1a%2F6GIeDTyeEdjRgQnbOxEzo7TZqlxj50NycTVr8NpY%2BX041eqekeo1jCCC3L" rel="nofollow" target="_blank">https://github.com/LeelaChess...</a></p><ul><li>在src/neural/backends/rocm/中添加了完整的ROCm后端</li><li>实现了注意力网络架构（多头自注意力、FFN、嵌入层）</li><li>使用rocBLAS进行GEMM运算，使用MIOpen进行卷积运算</li><li>针对RDNA 3.5上的FP16性能优化了NCHW布局</li><li>提供三种后端变体：rocm (FP32)、rocm-fp16 (FP16)、rocm-auto (自动检测)</li><li>MIOpen是必选依赖（类似于CUDA的cuDNN）</li><li>通过rocm\_agent\_enumerator自动检测AMD GPU架构</li><li>编译选项：-Drocm=true -Damd\_gfx=gfx1151（或使用自动检测）</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571278" alt="" title="" loading="lazy"/></p><p><strong>性能说明：</strong></p><ul><li><strong>FP16性能</strong>：在Strix Halo (Radeon 8060S, gfx1151) 上 &gt;2000 nps</li><li>自动Batch Size调优（RDNA 3.5上min\_batch=64）</li><li>测试过rocWMMA，但rocBLAS性能更好</li></ul><p><strong>验证情况（Strix Halo – Radeon 8060S, gfx1151）：</strong></p><ul><li><strong>测试模型</strong>：768x15x24h-t82-swa-7464000.pb.gz 和 maia-1900.pb.gz</li><li><strong>后端</strong>：rocm-fp16功能正常，能生成正确的走法</li><li><strong>环境</strong>：ROCm 7.2.53150, MIOpen 3.5.1</li><li><strong>注</strong>：仅在RDNA 3.5上进行了测试；其他AMD架构暂未验证</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571279" alt="" title="" loading="lazy"/></p><p><strong>GPU未来，是AI智能体主场</strong></p><p>当然，这次演示也有局限性。</p><p>对于简单或中等复杂度的内核，Claude Code表现得非常出色。更重要的是，写核函数的核心就在于搞定「深度硬件」优化。</p><p>不过，一部分觉得Claude Code在这方面还是差点火候——</p><p>如果遇到那些针对特定硬件缓存层级，内存访问模式做过极致优化的复杂内核，AI目前还难以完全取代人类专家。</p><p>即便如此，这一事件释放出的信号已经足够强烈。</p><p>过去几个月，ZLUDA项目、还有微软内部的尝试，都想要打破CUDA的垄断。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571280" alt="" title="" loading="lazy"/></p><p>但它们大多依赖规则映射或中间层，自动化程度和智能水平有限。</p><p>Claude Code代表的智能体式编程，直接跳过了这些环节，用「理解+自主决策」的方式填平生态鸿沟。</p><p>正如AMD软件副总所言，GPU编程的未来，是AI智能体主场。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571281" alt="" title="" loading="lazy"/></p><p><strong>全员AI编程，浓度高达100%</strong></p><p>如今的Claude Code已经让整个硅谷入坑了（Claude-Pilled）。</p><p>两天前，CEO Dario Amodei在达沃斯上再出暴论：软件工程师们没有时间了。未来6-12个月，AI能够彻底取代这些人！</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571282" alt="" title="" loading="lazy"/></p><p>甚至，Anthropic内部工程师已经不再手写代码了，全是Claude完成。</p><p>别不信，是真的。</p><p>就在Wired最新采访中，Claude Code之父Boris Cherny坦承，「自己100%代码都是AI写的」。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571283" alt="" title="" loading="lazy"/></p><p>或许Anthropic工程师怎么也没有想到，一个「副业项目」竟让硅谷如此狂热。</p><p>Boris Cherny回忆道，「一年前我们发布Claude Code时，甚至不确定『智能体编程』能不能成，但火爆来得太快了」。</p><p>Cherny个人经历就是最好的缩影：</p><p>刚发布时，他只有5%代码是用Claude Code写的；</p><p>到了去年5月，有了Opus 4和Sonnet 4，这个比例变成了30%；</p><p>而现在，有了Opus 4.5，他在过去两个月里100%的代码都是由Claude Code完成。</p><p>在Anthropic内部，这种全员AI化更是到了极致。</p><p>几乎100%技术员工都在使用Claude Code，甚至连Claude Code团队本身95%的代码也是由自身写出来的。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571284" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571285" alt="" title="" loading="lazy"/></p><p><strong>斯坦福AI教授都在用了</strong></p><p>不得不说，AI编程的进化速度令人咋舌。</p><p>回望2021到2024年，大多数工具不过是高级版的「自动补全」，在开发者打字时卑微地建议几行代码。</p><p>但到了2025年初，随着Cursor和Windsurf等初创发布早期的Agentic编程产品，游戏规则改变了——</p><p>开发者只需用大白话描述功能，剩下的脏活累活全扔给AI智能体完成。</p><p>Claude Code也在这个时间点，真正诞生了。</p><p>Boris Cherny坦承，早期版本也曾跌跌撞撞，甚至陷入死循环。但Anthropic下了一步狠棋：不为当下的AI能力开发产品，而要为AI即将抵达的未来而构建。</p><p>这一赌注押对了。随着Anthropic下一代旗舰Claude Opus 4.5的发布，AI编程迎来了真正的「拐点」。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571286" alt="" title="" loading="lazy"/></p><p>斯坦福大学AI讲师、Workera CEO Kian Katanforoosh最近就把公司全员迁移到了Claude Code。</p><p>他直言，对于高级工程师来说，Claude Code比Cursor、Windsurf更能打。</p><p>Katanforoosh感叹道，最近唯一让我看到编程能力有阶跃式提升的模型，就是Claude Opus 4.5。</p><p>「它给人的感觉不像是在模仿人类写代码，而是它真的找到了一种更聪明的解决路径」。</p><p>据传，微软内部也在大规模采用Claude Code了。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571287" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571288" alt="" title="" loading="lazy"/></p><p><strong>年入超10亿美金的「副业」</strong></p><p>Claude Code大获成功，给Anthropic带来了最直观的效益。</p><p>去年，AI编程智能体业务彻底爆发。11月，Anthropic宣布Claude Code在上线不到一年内，年度经常性收入（ARR）就突破了<strong>10亿美元</strong>。</p><p>到2025年底，ARR至少又增长了1亿美元。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571289" alt="" title="" loading="lazy"/></p><p>彼时，该产品约占Anthropic总ARR（约90亿美元）的12%。虽然比起向大企业提供 AI 系统的核心业务来说还算「小弟」，但它已是公司增长最快的板块之一。</p><p>尽管Anthropic在AI编程领域看似独孤求败，但Claude Opus 4.5的光环其实照亮了整个赛道。</p><p>竞争对手Cursor也在11月达到了10亿美元ARR，OpenAI、谷歌和xAI更是磨刀霍霍，试图用自研模型分一杯羹。</p><p>但Anthropic没打算停下。</p><p>前几天，他们又发布了Cowork——这是一款面向非编程领域的AI智能体。</p><p>它能管理你电脑里的文件、操作各种软件，而且完全不需要你在代码终端里敲命令。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571290" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571291" alt="" title="" loading="lazy"/></p><p><strong>不是取代，是进化</strong></p><p>提及Cowork时，Cherny透露自己已经用疯了。</p><p>比如项目管理，他会让Cowork盯着工程师的任务表格，谁没填名字，AI就会自动在Slack上发消息催人。</p><p>Cherny感慨道，「这是我当工程师以来最爽的时候，因为我不再需要做那些枯燥乏味的脏活了」。</p><p>面对那些因不再需要亲自写代码而感到失落的工程师，Cherny给出了他的建议：</p><p>这行业一直在变。我祖父在苏联用穿孔卡片编程；后来变成了机器码；再后来是C语言、Java、Python。</p><p>这是一条不断抽象化的连续体，AI智能体只是这条线上的最新一个点。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571292" alt="" title="" loading="lazy"/></p><p>如今，Cherny每天早上起床会在手机上启动3-4个编程智能体，到了公司再在终端里开几个。</p><p>任何时候，他都有五到十个智能体在跑任务。</p><p>Cherny总结道，「AI智能体将接管生活中所有繁琐的事——填表、搬运数据、发邮件。这会具有颠覆性，我们必须适应」。</p><p>话又说回来，Anthropic能不能先解决下Claude使用量？</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571293" alt="" title="" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[2026 AI元年:从生成式 AI 到智能体文明的临界点 Agentcometoo ]]></title>    <link>https://segmentfault.com/a/1190000047571214</link>    <guid>https://segmentfault.com/a/1190000047571214</guid>    <pubDate>2026-01-26 10:07:25</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <blockquote><em>2026 年，人工智能不再只是“会说话的工具”，而开始成为“会行动的系统”。</em></blockquote><p>在人工智能的发展史上，2026 年被越来越多研究者视为一个明确的分水岭： <strong>AI 正在从「生成式 AI（Generative AI）」跨越到「原生智能体（Agentic AI）」阶段。</strong></p><p>过去，我们习惯将大模型（LLM）视为“大脑”，将智能体（Agent）当作外接的“肢体”； 而今天，这种二元划分正在迅速瓦解。</p><h2>一、概念消融：当模型本身成为智能体</h2><h3>1️⃣ 从“调用模型”到“模型即智能体”</h3><p>在早期架构中，智能体是被<strong>外部框架强行拼装</strong>出来的产物： 任务拆解、记忆系统、工具调用、状态管理——都在模型之外。</p><p>而 2026 年正在形成的新范式是：</p><blockquote><strong>行动意图、长期规划与反馈修正，被直接写入模型的能力结构中。</strong></blockquote><h3>2️⃣ 关键定义：原生智能体架构（Native Agentic Architecture）</h3><p>所谓原生智能体架构，指的是：</p><ul><li>在预训练或对齐阶段</li><li>就引入“目标驱动”“行动选择”“长期状态保持”等能力</li><li>模型天然具备 <strong>思考 → 行动 → 观察 → 修正</strong> 的闭环</li></ul><p>此时，大模型不再是“文本补全器”， 而是一个<strong>具备执行潜力的认知系统</strong>。</p><h2>二、能力跃迁：从推理到“原子化行动”</h2><h3>核心变化一：长时程推理成为默认能力</h3><p>模型不再只回答单次问题，而是能：</p><ul><li>持续数小时甚至数天</li><li>推演复杂目标</li><li>保持上下文一致性与目标收敛</li></ul><h3>核心变化二：自主纠错机制</h3><p>当结果偏离目标时，模型能够：</p><ul><li>感知偏差</li><li>重启推理脉冲</li><li>无需人工介入完成修正</li></ul><p>👉 <strong>这不是更聪明，而是更像“员工”</strong></p><h2>三、交互革命：从对话框到协作网络</h2><h3>1️⃣ 多智能体编排（Multi-Agent Orchestration）</h3><p>当“模型 = 智能体”成立后，交互方式发生结构性变化：</p><ul><li>不再是“人 ↔ AI”</li><li>而是“人 ↔ 智能体网络”</li></ul><p>多个具备不同职能的智能体，在统一治理下：</p><ul><li>自主分工</li><li>协同决策</li><li>共同完成跨领域目标</li></ul><p>生产单元，第一次从“个体”跃迁为“网络”。</p><h3>2️⃣ 为什么边界模糊反而提升生产力？</h3><ul><li><strong>认知无缝流转</strong>：思考与执行之间的摩擦几乎为零</li><li><strong>端到端自动化</strong>：从数据抓取到决策执行，无需人类“复制粘贴”</li><li><strong>门槛急剧下降</strong>：非技术人员也能指挥复杂智能体集群</li></ul><p>在实践中，一些团队已经开始使用平台化方案 例如 <strong>「智能体来了」</strong>（<a href="https://link.segmentfault.com/?enc=uiEiwOsajvX%2BdWdKClw48Q%3D%3D.MwIo%2F3rLk4I8u13HKq1L9j7CzL82dERC7RytSNjTMtY%3D" rel="nofollow" target="_blank">https://agentcome.net/</a>）， 通过自然语言直接调度多智能体系统， 而不再关心底层模型或执行逻辑的差异。</p><blockquote>这并不是工具进步，而是<strong>组织形态的变化</strong>。</blockquote><h2>四、范式转移：从“软件中心”到“目标中心”</h2><h3>1️⃣ 软件正在被解构</h3><p>传统 SaaS 的本质是： <strong>把人的操作流程固化成菜单与按钮。</strong></p><p>而 Agent-Native 应用的本质是：</p><blockquote><strong>让人只负责定义目标，其余交给智能体完成。</strong></blockquote><p>你不再学习 Photoshop 的功能， 而是告诉图像智能体你想要的视觉意境。</p><h3>2️⃣ 价值评估体系的重构</h3><p>AI 的评价标准正在发生根本转变：</p><ul><li>从 <strong>效率</strong> → <strong>成果</strong></li><li>从 <strong>工具属性</strong> → <strong>组织属性</strong></li></ul><p>企业开始像评估员工一样评估 AI 智能体：</p><ul><li>是否稳定</li><li>是否合规</li><li>是否能跨部门协作</li></ul><h2>五、结论：复合智能（Composite AI）时代已经开启</h2><p>当大模型与智能体的边界彻底模糊， 人工智能正式进入 <strong>复合智能（Composite AI）</strong> 阶段。</p><ul><li><strong>技术层面</strong>：模型成为具备环境感知与行动潜力的动态系统</li><li><strong>应用层面</strong>：人类从“使用者”转为“战略指挥官”</li><li><strong>社会层面</strong>：生产力从线性增长跃迁为网络化增长</li></ul><blockquote>在这个时代，真正稀缺的能力不再是“会用工具”，而是——<strong>能否准确定义复杂目标，并编排一整个智能体网络去实现它。</strong></blockquote>]]></description></item><item>    <title><![CDATA[2026AI元年：为什么“人工智能 × 人类协作”成为新的工作基本单元？ Agentcometoo ]]></title>    <link>https://segmentfault.com/a/1190000047571221</link>    <guid>https://segmentfault.com/a/1190000047571221</guid>    <pubDate>2026-01-26 10:06:38</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><strong>2026 年，被越来越多研究者视为“AI 工作范式真正落地的起点”。</strong> 这并不是因为人工智能全面取代人类，而是因为——</p><blockquote><strong>“人 + AI 智能体”的协作结构，正在取代“人使用工具”，成为新的生产力最小单位。</strong></blockquote><h2>一、从工具到伙伴：AI 角色的根本变化</h2><h3>1. 什么是“智能体（AI Agent）”？</h3><p><strong>智能体不是功能集合，而是具备“目标意识”的系统。</strong></p><p>一个成熟的 AI Agent，至少具备三项能力：</p><ul><li><strong>感知（Perception）</strong>：理解环境与上下文</li><li><strong>规划（Planning）</strong>：将目标拆解为多步行动</li><li><strong>记忆（Memory）</strong>：跨任务、跨时间积累经验</li></ul><blockquote>这使 AI 从“被动执行者”，转变为<strong>可参与协作的数字角色</strong>。</blockquote><h3>2. 工作范式的两次关键迁移</h3><p><strong>第一次迁移：</strong></p><blockquote>指令驱动（How） → 目标驱动（What）</blockquote><p>人类不再描述“怎么一步步做”， 而是定义：</p><ul><li>目标是什么</li><li>成功的评价标准是什么</li></ul><p><strong>第二次迁移：</strong></p><blockquote>单点替代 → 全链路增强</blockquote><p>AI 不再只替代某个动作（写文案、画图）， 而是进入<strong>决策、校验、预测、优化</strong>等关键节点。</p><h2>二、为什么“人机协作”是唯一稳定解？</h2><p><strong>不是因为人类不行，也不是因为 AI 全能，而是因为两者在底层能力上天然互补。</strong></p><h3>1. 计算规模 × 直觉判断</h3><ul><li>AI：擅长海量数据、全局搜索、概率计算</li><li>人类：擅长小样本判断、价值选择、行业直觉</li></ul><blockquote>在高度不确定的商业环境中，任何一方单独工作，风险都更高。</blockquote><h3>2. 边际成本 × 创新溢价</h3><p>当任务被标准化后：</p><ul><li>AI 的执行成本 → 接近 0</li><li>人类的时间 → 被释放到“0→1”的创造性工作</li></ul><p><strong>整体生产函数从线性增长，跃迁为指数级增长。</strong></p><h3>3. 随机性 × 确定性的工程化解决</h3><p>现实中，企业需要“可控的 AI”。</p><p>因此，一部分团队会选择<strong>成熟的智能体平台</strong>， 例如：<strong>智能体来了（agentcome.net）</strong>， 通过：</p><ul><li>标准流程</li><li>权限边界</li><li>人类最终审核</li></ul><p>将 AI 的不确定性限制在工程可接受范围内。</p><h2>三、可落地的人机协作工作流（3 个阶段）</h2><h3>阶段一：任务原子化与角色绑定</h3><ul><li><strong>AI 主导</strong>：高重复、规则明确、数据密集</li><li><strong>人类主导</strong>：战略、创意、伦理、冲突处理</li></ul><h3>阶段二：Human-in-the-Loop 反馈闭环</h3><p>AI 的输出不是终点，而是<strong>第一稿</strong>。</p><p>人类修正 → 反馈 → 再训练 → 场景化精度提升</p><blockquote><strong>共同进化，才是长期护城河。</strong></blockquote><h3>阶段三：提示工程与知识封装</h3><p>未来的核心资产不再只是文档，而是：</p><ul><li>可复用的高质量 Prompt</li><li>结构化的行业知识库</li></ul><h2>四、AI 时代劳动者的三项核心能力</h2><ol><li><strong>提问力</strong>：定义问题边界与成功标准</li><li><strong>判断权</strong>：在内容极度过剩时识别“正确与优质”</li><li><strong>架构能力</strong>：组合 AI、工具与人类专家，搭建系统</li></ol><h2>五、总结：工作的本质正在改变</h2><ul><li><strong>工作单位变化</strong>：从“个人” → “人 + AI 智能体”</li><li><strong>工作内容变化</strong>：从执行 → 调度与决策</li><li><strong>长期目标</strong>：不是替代，而是构建可持续协作系统</li></ul><blockquote><strong>真正的竞争力，是把行业经验嵌入算法，把人类智慧固化为系统能力。</strong></blockquote>]]></description></item><item>    <title><![CDATA[什么是 IP SSL 证书？该如何申请 才高八斗的杯子_dS2Fpp ]]></title>    <link>https://segmentfault.com/a/1190000047571223</link>    <guid>https://segmentfault.com/a/1190000047571223</guid>    <pubDate>2026-01-26 10:05:54</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>SSL证书通常是颁发给域名的，但是有些企业没有域名只有 IP，或者不方便使用域名，IP 地址要实现https加密，这时可申请IP SSL证书。下面将从IP SSL证书的作用、申请条件和申请流程三个方面来让您详细了解 IP SSL证书。</p><h4>申请IP SSL证书的作用</h4><ul><li>1、用 IP SSL证书可以很好地防流量劫持。</li><li>2、IP 地址比域名复杂，不容易记忆，有了企业型IP SSL证书，可以有效提高IP的身份辨识度，减少被假冒的风险；</li><li>3、IP 能直达设备，应用更广。</li></ul><h4>申请IP SSL证书要满足的条件：</h4><ul><li>1、确定IP能正常访问</li><li>2、申请者必须有该IP的管理权限；</li><li>3、只可以申请单个IP SSL证书，不支持IP段通配符证书。</li></ul><p><strong>IP SSL证书的类型</strong></p><ul><li>DV型IP证书：仅需验证域名所有权，签发速度快，几分钟即可获得证书。</li><li>OV型IP证书：不仅需要验证域名所有权，还需进行企业信息验证，签发时间大概需要1-3个工作日  <br/>备注：内网IP和公网IP证书不通，需要确认好。<br/><img width="700" height="400" referrerpolicy="no-referrer" src="/img/bVdnLBS" alt="" title=""/></li></ul><h4>申请 IP SSL证书的流程</h4><p>1、选择可信赖的CA机构</p><h4><a href="https://link.segmentfault.com/?enc=IoTVLLxoojH2R4CKfEacHQ%3D%3D.5xsDSQ8SpkFNO%2Fdtx4r%2B84MAnVKSnaZno6x9nastgLiIubOl5yzJDyouDLBMY9oyezHAhtMp%2FWEJ%2FabsByJSruLka2Uv3QmHlS9gJ2m%2Bka0%3D" rel="nofollow" target="_blank"> IP SSL证书申请入口</a></h4><p><strong>访问JoySSL官网,注册一个证书账号，填写注册码230970，获取技术支持</strong>。</p><p>2、选择合适的 IP SSL证书，DV 或 OV，提交订单。</p><p>3、生成 CSR 文件和 Key，下载 CSR 文件和 Key 并保存在安全的位置。</p><p>4、配合完成验证。</p><p>DV型 IP SSL证书的验证方式：验证 IP 管理权限，上传指定验证文件到网站根目录（通过 80 或 443 端口验证）。一般 10分钟内就可完成验证。</p><p>OV型 IP SSL证书的验证方式：除了上述 DV 型 IP SSL证书的验证方式外，还要验证公司真实性，以电话或邮件方式进行企业审核。1-3 个工作日可完成验证。</p><p>5、获取 IP SSL证书，部署到服务器上。</p>]]></description></item><item>    <title><![CDATA[特定命令词阈值调优指南：解决单个命令词识别率低的精准方案 SmartPi ]]></title>    <link>https://segmentfault.com/a/1190000047571550</link>    <guid>https://segmentfault.com/a/1190000047571550</guid>    <pubDate>2026-01-26 10:05:16</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>前言</h2><p>在使用离线语音模组进行产品开发时，开发者常会遇到一个令人困扰的现象：<strong>大部分命令词识别效果良好，但个别命令词识别率明显偏低</strong>。</p><p>这种"个别掉队"的情况往往无法通过调整全局识别灵敏度来解决——因为把灵敏度调高会让其他命令词误识别增加，调低又会让问题命令词更难识别。</p><p><strong>"特定命令词阈值"</strong>功能正是为解决这类问题而生。它允许开发者针对单个命令词设置独立的识别阈值，实现"精准调优"，而不影响其他命令词的识别表现。</p><h2>一、真实案例：含数字命令词的识别难题</h2><h3>1.1 问题描述</h3><p><strong>客户背景</strong>：某饮水机产品开发者，使用 CI-1362 模组（JX-95C 系列），配置了多个温度调节命令词。</p><p><strong>问题现象</strong>：</p><ul><li><code>45度水</code>、<code>85度水</code>、<code>100度水</code> 等命令词识别率正常</li><li>唯独 <code>65度水</code> 命令词识别率很低，几乎无法触发</li></ul><p><strong>初步尝试</strong>：</p><ul><li>尝试使用正性词增强法：<code>停止|亭子|停滞|挺直</code>，对其他命令词有效</li><li>但 <code>65度水</code> 仍无法改善</li></ul><h3>1.2 问题根源分析</h3><p>技术支持给出的解释：</p><blockquote><strong>"因为'五'这个音是偏弱的"</strong></blockquote><p>从语音学角度分析：</p><ul><li><strong>"五" (wǔ)</strong> 是闭口音，气流能量弱，声谱特征不明显</li><li><strong>"六十五" (liù shí wǔ)</strong> 连续两个音节（十五）都是弱音</li><li>整体词能量偏低，导致模型打分时置信度不足</li></ul><p>这类问题属于<strong>语音固有特性</strong>，无法通过简单的命令词重构解决。</p><h2>二、解决方案：特定命令词阈值</h2><h3>2.1 什么是"特定命令词阈值"？</h3><p>智能公元平台提供的一项高级功能，允许为<strong>单个命令词</strong>设置独立的识别阈值，与全局阈值隔离。</p><p><strong>核心价值</strong>：</p><ul><li>不影响其他命令词的识别表现</li><li>可以单独提高"问题命令词"的灵敏度</li><li>精准平衡识别率与误识别率</li></ul><h3>2.2 功能位置</h3><p>在智能公元平台的 <strong>个性化音频</strong> 配置中：</p><table><thead><tr><th>配置路径</th><th>选项名称</th></tr></thead><tbody><tr><td>词条类型选择</td><td><strong>特定命令词阈值</strong></td></tr></tbody></table><p><strong>配置界面标识</strong>：</p><pre><code>个性化音频 → 词条类型 → 选择"特定命令词阈值"</code></pre><h3>2.3 支持的模组系列</h3><table><thead><tr><th>模组系列</th><th>支持情况</th><th>备注</th></tr></thead><tbody><tr><td><strong>CI-95C</strong></td><td>✓</td><td>全功能支持</td></tr><tr><td><strong>CI-96Z</strong></td><td>✓</td><td>全功能支持</td></tr><tr><td><strong>CI-73T/CI-73T2</strong></td><td>✓</td><td>全功能支持</td></tr><tr><td><strong>CI-33T</strong></td><td>✓</td><td>全功能支持</td></tr><tr><td><strong>CI-03T</strong></td><td>✓</td><td>全功能支持</td></tr><tr><td><strong>SU-32T</strong></td><td>✓</td><td>全功能支持</td></tr><tr><td><strong>SU-03T 系列</strong></td><td>✓</td><td>全功能支持</td></tr><tr><td><strong>JX-A7T</strong></td><td>✓</td><td>全功能支持</td></tr></tbody></table><blockquote><strong>注意</strong>：该功能在固件生成时打包生效，需要重新烧录固件。</blockquote><h2>三、配置方法与步骤</h2><h3>3.1 通过"个性化音频"配置</h3><p><strong>步骤概览</strong>：</p><ol><li>进入产品配置 → 个性化音频</li><li>点击 <strong>+ 点击添加</strong></li><li>词条类型选择 <strong>特定命令词阈值</strong></li><li>配置对应命令词的阈值参数</li><li>生成并烧录新固件</li></ol><p><strong>详细操作</strong>：</p><pre><code>┌─────────────────────────────────────────────────┐
│  个性化音频配置                                  │
├─────────────────────────────────────────────────┤
│  词条类型: [特定命令词阈值 ▼]                    │
│                                                  │
│  命令词选择: [65度水 ▼]                          │
│                                                  │
│  阈值设置: [0.6 ▼]  (范围: 0.01 ~ 0.8)          │
│                                                  │
│  + 点击添加                                       │
└─────────────────────────────────────────────────┘</code></pre><h3>3.2 通过"优化配置"调整</h3><p>在 <strong>优化配置</strong> 界面中也可以找到相关选项：</p><pre><code>优化配置 → 特定命令词阈值</code></pre><p><strong>配置项说明</strong>：</p><table><thead><tr><th>参数</th><th>说明</th><th>推荐值</th></tr></thead><tbody><tr><td><strong>阈值范围</strong></td><td>0.01 \~ 0.8</td><td>根据实际情况调整</td></tr><tr><td><strong>数值越大</strong></td><td>越容易识别，但误识别率增加</td><td>从默认值逐步提高</td></tr><tr><td><strong>数值越小</strong></td><td>识别越严格，误识别率降低</td><td>用于易误触发的命令词</td></tr></tbody></table><h3>3.3 阈值设置建议</h3><table><thead><tr><th>场景</th><th>建议阈值</th><th>说明</th></tr></thead><tbody><tr><td><strong>正常命令词</strong></td><td>0.2（默认）</td><td>使用全局默认值</td></tr><tr><td><strong>弱音命令词</strong></td><td>0.4 \~ 0.6</td><td>如含数字五、闭口音等</td></tr><tr><td><strong>远距离识别</strong></td><td>0.6 \~ 0.8</td><td>需高灵敏度场景</td></tr><tr><td><strong>易误触发词</strong></td><td>0.05 \~ 0.1</td><td>降低误识别率</td></tr></tbody></table><h2>四、针对"65 度水"的具体调优方案</h2><h3>方案一：单独调高阈值（推荐）</h3><p><strong>操作步骤</strong>：</p><ol><li>在个性化音频中，选择 <strong>特定命令词阈值</strong></li><li>选择命令词 <code>65度水</code></li><li>将阈值设置为 <strong>0.6</strong>（比默认 0.2 更高）</li><li>生成固件并测试</li></ol><p><strong>预期效果</strong>：</p><ul><li><code>65度水</code> 识别率显著提升</li><li>其他命令词识别表现不受影响</li></ul><h3>方案二：添加相似音作为辅助（需评估风险）</h3><p><strong>操作方法</strong>：</p><p>在命令词配置中添加：</p><pre><code>65度水|60度水|六十五度水</code></pre><p><strong>注意事项</strong>：</p><ul><li><strong>风险</strong>：用户说 <code>60度水</code> 时可能误触发 <code>65度水</code> 功能</li><li><strong>需评估</strong>：产品场景是否允许这种模糊匹配</li><li><strong>技术支持原话</strong>："加六十度应该效果提升是很明显的，但是有一定的风险，这个需要评估一下"</li></ul><h3>方案三：组合使用</h3><ol><li>先使用 <strong>方案一</strong>（调高特定阈值）</li><li>测试后如仍不理想，再谨慎评估 <strong>方案二</strong></li><li>最后考虑重新设计命令词（如 <code>最大热度</code> 替代 <code>65度水</code>）</li></ol><h2>五、阈值调优的通用原则</h2><h3>5.1 逐步调整原则</h3><pre><code>初始值 → 测试 → 微调 → 再测试 → 确认
  0.2    0.4    0.5    0.6    最终值</code></pre><p><strong>建议</strong>：每次调整幅度不超过 0.1-0.2，避免跳跃式设置</p><h3>5.2 平衡原则</h3><table><thead><tr><th>阈值设置</th><th>识别率</th><th>误识别率</th><th>适用场景</th></tr></thead><tbody><tr><td><strong>低 (0.01-0.1)</strong></td><td>低</td><td>低</td><td>安静环境、高可靠性要求</td></tr><tr><td><strong>中 (0.2-0.4)</strong></td><td>中</td><td>中</td><td>大多数场景的默认选择</td></tr><tr><td><strong>高 (0.6-0.8)</strong></td><td>高</td><td>高</td><td>噪声环境、远距离识别</td></tr></tbody></table><h3>5.3 测试验证原则</h3><ol><li><strong>单一变量测试</strong>：每次只调整一个命令词的阈值</li><li><strong>环境一致性</strong>：在相同环境下进行前后对比测试</li><li><strong>多次采样</strong>：每个阈值至少测试 20-30 次</li><li><strong>记录数据</strong>：记录识别成功率和误触发次数</li></ol><h2>六、常见问题与注意事项</h2><h3>Q1：阈值设为 0.8 后仍无法识别？</h3><p><strong>可能原因</strong>：</p><ol><li>命令词本身发音特征过于模糊</li><li>麦克风选型或位置问题</li><li>噪声环境过于恶劣</li></ol><p><strong>建议</strong>：</p><ul><li>考虑更换命令词表述</li><li>检查硬件设计（麦克风灵敏度、安装位置）</li><li>考虑升级到更高识别率的模组（如 SU-32T 98% 识别率）</li></ul><h3>Q2：特定阈值会影响唤醒词吗？</h3><p><strong>答案</strong>：不会。特定命令词阈值只影响对应的命令词，与唤醒词独立。</p><h3>Q3：可以设置多个命令词的特定阈值吗？</h3><p><strong>答案</strong>：可以。每个命令词都可以独立设置阈值，互不影响。</p><h3>Q4：阈值设置后如何生效？</h3><p><strong>步骤</strong>：</p><ol><li>配置完成后点击 <strong>生成固件</strong></li><li>等待固件编译完成</li><li>下载并烧录到模组</li><li>复位后生效</li></ol><h2>七、总结</h2><h3>核心要点回顾</h3><table><thead><tr><th>要点</th><th>说明</th></tr></thead><tbody><tr><td><strong>问题定位</strong></td><td>单个命令词识别率低，无法通过全局调整解决</td></tr><tr><td><strong>解决方案</strong></td><td>使用"特定命令词阈值"功能进行精准调优</td></tr><tr><td><strong>配置位置</strong></td><td>个性化音频 → 特定命令词阈值</td></tr><tr><td><strong>阈值范围</strong></td><td>0.01 \~ 0.8，默认 0.2</td></tr><tr><td><strong>调整策略</strong></td><td>逐步微调，充分测试，平衡识别率与误识别率</td></tr></tbody></table><h3>快速决策流程</h3><pre><code>发现某命令词识别率低
      │
      ▼
尝试正性词增强法（如：停止|亭子|停滞）
      │
      ▼
仍无效 → 命令词含弱音（如五）？
      │
      ├─ 是 → 使用"特定命令词阈值"，调高至 0.6
      │
      └─ 否 → 检查硬件设计/考虑更换命令词</code></pre>]]></description></item><item>    <title><![CDATA[数据库校验利器升级！gt-checksum v1.2.3 正式发布 GreatSQL社区 ]]></title>    <link>https://segmentfault.com/a/1190000047571558</link>    <guid>https://segmentfault.com/a/1190000047571558</guid>    <pubDate>2026-01-26 10:04:40</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>数据库校验利器升级！gt-checksum v1.2.3 正式发布</h2><p>更快、更稳、更智能——你的数据一致性守护专家</p><hr/><h3>✨ 写在前面</h3><p>在日常的数据库运维与数据迁移中，你是否经常被这样的问题困扰：</p><ul><li><strong>数据不一致</strong>却难以快速定位</li><li><strong>跨库校验</strong>复杂繁琐</li><li><strong>存储过程、触发器</strong>难对比</li><li><strong>大表校验</strong>内存飙升，被 OOM 直接 Kill</li></ul><p>今天，我们为你带来一个好消息——<strong>gt-checksum v1.2.3</strong>全新发布，专门针对上述痛点进行了全面增强与优化！</p><p>发布会预约：<a href="https://link.segmentfault.com/?enc=Up9UuR896Ha%2F70eKQM%2F2Sw%3D%3D.tfdHonofFcXbPJDT7AUVGV03VeybS5OGp3duzOObZ%2FOb1Txew8QniKipG3BzPXoN" rel="nofollow" target="_blank">https://meeting.tencent.com/dw/hSVg8Wu4ixfk</a><br/>发布会时间：2026年1月26日下午15:30</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571560" alt="" title=""/></p><hr/><h3>🚀 核心亮点速览</h3><h4>1. 📁 数据库名映射：跨库校验一键搞定</h4><p>现在，你可以轻松将源库的表“映射”到目标库的不同名称下进行校验，非常适合分库分表、跨环境数据对比等场景。</p><p><strong>配置示例</strong>：</p><pre><code># 单表映射
tables=db2.test1:db1.test1
# 整库映射
tables=db2.*:db1.*</code></pre><p>结果中会清晰展示映射关系，一目了然。</p><h4>2. 🛠️ 支持 Routine 与 Trigger 校验</h4><p>不仅是表数据，现在连<strong>存储过程、函数、触发器</strong>也能进行一致性校验与智能修复，生成完整可执行的修复 SQL。</p><h4>3. 🧠 更聪明的内存管理</h4><p>引入智能内存调控机制，自动防止 OOM（内存溢出）。当内存接近上限时，工具会自动平滑降低并发与分块大小，并触发垃圾回收，保障任务稳定运行。</p><h4>4. 📝 修复 SQL 生成逻辑大幅优化</h4><ul><li>自动在修复文件头部添加<strong>字符集设置</strong>、<strong>临时禁用外键检查</strong>等语句</li><li>智能合并事务，提升修复执行效率</li><li>修复了以往版本中因语句顺序问题导致的修复失败</li></ul><hr/><h3>⚙️ 重点功能详解</h3><h4>🔄 数据库名映射</h4><p>适用于异构数据库同步、测试环境与生产环境结构差异等复杂场景，让校验不再受库表名称限制。</p><h4>🔍 结构校验增强</h4><ul><li><strong>索引修复</strong>：支持主键/辅助索引的“不可见”属性设置，合并 DDL 提升效率</li><li><strong>外键约束</strong>：新增外键一致性校验与修复</li><li><strong>字段操作优化</strong>：智能合并 <code>CHANGE COLUMN</code>操作，避免重建字段导致的数据丢失风险</li></ul><h4>🧩 参数配置更清晰</h4><p>我们整理了最常用的配置参数，方便你快速上手：</p><table><thead><tr><th align="left">参数</th><th align="left">说明</th><th align="left">推荐值</th></tr></thead><tbody><tr><td align="left"><code>parallelThds</code></td><td align="left">并发线程数，影响校验速度</td><td align="left">10</td></tr><tr><td align="left"><code>chunkSize</code></td><td align="left">每次校验的数据量，影响内存与速度</td><td align="left">10000</td></tr><tr><td align="left"><code>memoryLimit</code></td><td align="left">内存上限（MB），防 OOM</td><td align="left">根据机器配置调整</td></tr><tr><td align="left"><code>checkObject</code></td><td align="left">校验对象：data, struct, routine, trigger</td><td align="left">data</td></tr><tr><td align="left"><code>fixTrxNum</code></td><td align="left">单个事务包含的 DML 语句数</td><td align="left">1000</td></tr></tbody></table><hr/><h3>⚡ 性能与稳定性的全面提升</h3><ul><li><strong>查询优化</strong>：减少冗余查询，部分场景<strong>性能提升达 3 倍</strong></li><li><strong>并发自适应</strong>：内存超限时平缓降低并发（每次 90%），避免性能骤降</li><li><strong>日志国际化</strong>：所有输出统一为英文，日志更简洁，便于监控系统采集分析</li></ul><hr/><h3>🐛 关键问题修复</h3><p>针对数据校验中的“顽疾”进行了重点修复：</p><ul><li>特殊字符（如 <code>\'</code>）转义处理</li><li>字符串末尾空格导致的误判</li><li>多列联合主键校验准确性</li><li>无索引表的数据一致性问题</li></ul><hr/><h3>📦 如何获取与使用</h3><p>新版本已发布，你可以通过以下方式获取：</p><ol><li><strong>下载最新二进制包</strong>（已包含测试用例）</li><li>查看详细文档与配置说明</li><li>使用 <code>./gt-checksum --help</code>快速查看参数</li></ol><p>建议在使用前，根据实际数据量与环境资源，合理调整 <code>memoryLimit</code>、<code>parallelThds</code>等参数，以达到最佳校验效果。</p><hr/><h3>🙏 致谢</h3><p>特别感谢社区用户</p><ul><li>GLAW</li><li>月城</li></ul><p>为本版本的开发与优化做出的重大贡献！</p><hr/><h3>💎 总结</h3><p>gt-checksum v1.2.3 不仅是一次功能更新，更是面向生产级数据一致性校验的全面进化。无论你是在做<strong>数据迁移验证</strong>、<strong>主从一致性巡检</strong>，还是<strong>日常数据质量保障</strong>，这个版本都能为你提供更可靠、更高效的支撑。</p><p><strong>让数据校验，从此省心、放心。</strong></p><hr/><p><em>gt-checksum 是一个开源项目，欢迎贡献代码、反馈问题或提出建议。让我们一起打造更好用的数据库工具！</em></p>]]></description></item><item>    <title><![CDATA[MIAOYUN | 每周AI新鲜事儿 260123 MIAOYUN ]]></title>    <link>https://segmentfault.com/a/1190000047571563</link>    <guid>https://segmentfault.com/a/1190000047571563</guid>    <pubDate>2026-01-26 10:03:46</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>本周AI行业迎来密集爆发，大模型开源与技术突破并行，百度文心登顶国际榜单，智谱、美团、阶跃星辰等也纷纷发布或开源高性能新模型；AI工具聚焦场景落地，OpenAI与Google掀起翻译工具对决，腾讯混元3D、蚂蚁百灵Ling Studio、阿里呜哩、飞书AI录音豆等深耕垂直场景，实用型显著增强；Agent发展进入新阶段，字节扣子2.0、MiniMax Agent 2.0等升级专业化能力；市场层面基础设施与生态开放成为关键变量，马斯克开放𝕏平台推荐算法并投用GW级超算集群，一起来回顾本周发生的AI新鲜事儿吧！</p><h2>AI 大模型</h2><p><strong>百度文心大模型「ERNIE-5.0-0110」登LMArena文本榜国内第一、全球第八</strong></p><p>1月15日，百度正式上线的新一代文心大模型「ERNIE-5.0-0110」，在LMArena大模型竞技场以1460分位列文本榜国内第一、全球第八，是该榜单中唯一进入全球前十的中国大模型，数学能力排名全球第二。该模型参数量达2.4万亿，采用原生全模态统一建模技术，支持文本、图像等多种信息的输入与输出，此前Preview版本已拿下LMArena文本榜全球并列第二、国内第一及视觉理解榜国内第一的成绩。</p><p><strong>美团LongCat团队开源升级版模型「LongCat-Flash-Thinking-2601」</strong></p><p>1月16日，美团LongCat团队发布并开源升级版模型「LongCat-Flash-Thinking-2601」，引入「重思考模式」，在Agentic Search（智能体搜索）、Agentic Tool Use（智能体工具调用）、TIR（工具交互推理）等核心评测基准均达开源SOTA（AIME-25获满分、τ²-Bench 88.2分），泛化能力超越Claude，依托多环境强化学习（DORA基础设施）与噪声环境稳健训练实现技术突破，目前已在GitHub、Hugging Face等平台开源，支持官网在线体验与API免费调用。</p><p><strong>Black Forest Labs开源「FLUX.2」[klein]图像生成模型家族</strong></p><p>1月17日消息，Black Forest Labs开源「FLUX.2」[klein]图像模型家族，包含4B和9B两个版本（各含未蒸馏的基础版与4步蒸馏版），采用流模型+Qwen3文本编码器架构，统一文生图、图像编辑及多参考生成功能，实现最快0.5秒亚秒级推理，4B版（Apache 2.0许可证支持商用）仅需13GB显存适配消费级GPU，9B版（非商用许可证）性能比肩5倍参数量模型，同步提供FP8/NVFP4量化版本（分别提速1.6倍/2.7倍、显存降低40%/55%），附带推理脚本，兼顾实时应用、微调研究与边缘部署需求。</p><p><strong>智谱正式发布并开源混合思考模型「GLM-4.7-Flash」</strong></p><p>1月20日，智谱正式发布并开源混合思考模型「GLM-4.7-Flash」，总参数量30B、激活参数量3B，作为同级别SOTA模型兼顾性能与效率，在SWE-bench Verified等主流基准测试中表现超「GPT-OSS-20B」等模型，适配编程、中文写作等多场景，即日起在智谱开放平台上线并免费调用，将替代「GLM-4.5-Flash」（后者1月30日下线），同时可通过Hugging Face、魔搭社区进行开源部署。</p><p><strong>阶跃星辰开源10B参数量视觉语言模型「Step3-VL-10B」</strong></p><p>1月20日，阶跃星辰开源10B参数量视觉语言模型「Step3-VL-10B」，凭借全参数端到端多模态联合预训练、大规模RL迭代及PaCoRe并行协调推理机制，在视觉感知、逻辑推理、数学竞赛等多维度达到同规模SOTA水平，媲美甚至超越10-20倍参数量的开源与闭源旗舰模型，可下沉至端侧设备运行，目前Base和Thinking版本已通过多个平台开源。</p><p><strong>Liquid AI开源非Transformer架构的端侧推理模型「LFM2.5-1.2B-Thinking」</strong></p><p>1月21日，由MIT CSAIL孵化的初创公司Liquid AI发布并开源非Transformer架构的端侧推理模型「LFM2.5-1.2B-Thinking」，该模型基于液态神经网络打造，仅需900MB内存即可在手机等设备离线运行，不仅推理速度和质量在同规模模型中领先，参数量比「Qwen3-1.7B」少约40%，却在数学推理、指令遵循、工具使用等核心能力上表现相当或更优，还通过Midtraining、SFT、DPO、RLVR等训练策略将死循环生成比例从15.74%降至0.36%，兼容llama.cpp、MLX等主流推理框架及多品牌硬件，证明Transformer并非唯一解。</p><p><strong>中佛罗里达大学发布首个“纯文本提示”医学全能分割模型「Medical SAM3」</strong></p><p>1月21日消息，中佛罗里达大学等机构联合发布了首个真正“纯文本提示”驱动的医学全能分割模型「Medical SAM3」，采用全参数微调结合分层学习率衰减策略，依托覆盖10种成像模态、33个数据集的大规模训练底座及统一2D高分辨率视角设计，摆脱了传统医学分割模型对人工边界框等空间提示的依赖，仅凭文本指令即可在CT、MRI、内镜等多模态医学影像中实现专家级分割，内部验证平均Dice从54.0%提升至77.0%，外部零样本场景从11.9%暴涨至73.9%，大幅降低临床交互成本，未来将扩充数据并打造集成LLM的Agent。</p><p><strong>百川智能发布循证增强医疗大模型「Baichuan-M3 Plus」</strong></p><p>1月22日，百川智能发布循证增强医疗大模型「Baichuan-M3 Plus」，其融合独创六源循证技术与M3基座，将幻觉率降至2.6%达全球最低，首创“证据锚定”技术使医学结论可逐句溯源（匹配准确率超95%），API调用成本较上一代降低70%且限时15天免费体验，同时发起“海纳百川”计划，向中国医疗服务机构免费开放API，用于临床辅助决策与医学教育，推动AI医疗生态发展。</p><p><strong>Runway发布全新图生视频模型「Gen 4.5」</strong></p><p>1月22日，Runway发布全新图生视频模型「Gen 4.5」，该模型在长故事表达、精准镜头控制、连贯叙事及角色一致性上实现升级，生成视频细节逼真，在1000人盲测中仅57.1%的人能区分其与真实视频。当前视频模型行业呈现真实度与物理一致性增强、声画同步提升等趋势，正逐步接近商业化应用。</p><h2>AI 工具</h2><p><strong>AI翻译对决，OpenAI上线「ChatGPT Translate」，Google开源「TranslateGemma」</strong></p><p>1月16日消息，OpenAI近期低调上线独立翻译工具「ChatGPT Translate」，支持超50种语言，无需登录即可免费使用，核心亮点是具备译文语气调整等二次加工能力，但暂不支持文档、图片翻译及离线使用。对此Google则高调回应，发布基于Gemma 3的开源翻译模型「TranslateGemma」，提供4B、12B、27B三种参数版本，支持55种语言及多模态输入，12B模型性能超越27B基线模型，4B模型适配移动端/边缘设备，通过双阶段微调流程蒸馏Gemini模型知识，双方竞争推动AI翻译从单纯语言转换向智能适应方向演进。</p><p><strong>腾讯「混元3D Studio 1.2」发布公测，组件能力升级至PartGen 1.5</strong></p><p>1月16日，腾讯「混元3D Studio 1.2」全新发布并开放公测（无需申请），组件能力升级至PartGen 1.5（拆分精度从1024³提升至1536³分辨率，支持笔刷交互与分割掩码控制，保留高精细节、拆分更完整），基模同步升级为「混元3D 3.1」（几何细节与纹理还原度优化，适配更多风格），新增八视图输入（含顶、底及左右45度视角）提升专业可控性，用户可通过官方链接体验。</p><p><strong>蚂蚁集团正式上线百灵大模型官方交互平台「Ling Studio」</strong></p><p>1月16日，蚂蚁集团正式上线百灵大模型官方交互平台「Ling Studio」，用户可体验Ling-1T（高速响应）、Ring-1T（复杂推理）、Ming-flash-omni-Preview（多模态识别）等百灵大模型，平台支持调参、系统提示词配置、联网搜索等原生工具调用及API即接即用功能，每日发放50万个免费Tokens，文件对话、图片生成等更多功能即将上线。</p><p><strong>阿里巴巴通义千问团队推出一站式AIGC创意生产力平台「呜哩」</strong></p><p>1月19日，阿里巴巴通义千问团队推出一站式AIGC创意生产力平台「呜哩」（目前处于测试阶段），该平台集成通义Qwen Image系列、万相2.6等自研模型，以及字节Seedream 4.0/4.5、可灵相关第三方模型，支持文生图、图生图、参考生图、文生视频、图生视频等全功能，生图最高可达4K、生视频最高1080p且支持音画同步，生成速度快（图片几秒、视频1-2分钟），参考生图功能可灵活改图，目前所有功能免费无次数限制，手机号登录即可使用，正式上线后可能收费。</p><p><strong>飞书与安克创新联合推出仅重10g的「AI录音豆」，录音整理全自动化</strong></p><p>1月20日，飞书与安克创新联合推出「AI录音豆」，这款直径23.2毫米、重10g的微型硬件支持磁吸佩戴，续航达8小时，一键即可录音，录音内容可无缝联动飞书生态，自动生成逐字稿、多语言翻译、会议总结、待办事项等，还能通过飞书知识问答、定时任务、日报周报生成等功能二次加工，解决了手机录音续航、操作繁琐等痛点，将线下录音转化为可协作复用的数字资产，优化了线下会议等场景的录音与内容整理体验。</p><p><strong>红杉中国xbench发布「AgentIF-OneDay」评测体系</strong></p><p>1月21日，红杉中国xbench发布「AgentIF-OneDay」评测体系，聚焦评估Agent在长时复杂任务中的能力，以人类一天可完成的任务复杂度为基准，涵盖工作流执行、范例参考、迭代式编辑三类场景，包含104道任务及767个细粒度评分点，评测显示Manus、Genspark、ChatGPT-Agent构成第一梯队且各有场景侧重，当前Agent在隐式指令推断等方面仍存短板，未来将推进OneWeek评测，同时持续学习与数据飞轮被认为是Agent向高可靠“数字员工”演进的关键。</p><h2>AI Agent</h2><p><strong>超参数科技发布LLM驱动的Game Agent「COTA」，推理链路全程可见</strong></p><p>1月16日，超参数科技发布自研Game Agent「COTA」，这是首个以LLM（基座模型Qwen3-VL-8B-Thinking）为核心驱动、具备思维可解释性的游戏智能体，通过“双系统分层架构”（上层指挥官负责战略规划、下层行动专员执行微操）及SFT+GRPO+DPO训练流程，攻克实时响应难题（百毫秒级），在自研FPS游戏环境中展现出接近真人高分玩家的竞技水平，可完成单兵作战与团队战术配合，既降低高拟真NPC开发调试门槛，又能优化玩家体验，其底层技术还具备跨场景迁移潜力，目前已开启官网预约体验。</p><p><strong>字节跳动「扣子空间」正式升级为「扣子2.0」，四大Agent能力升级</strong></p><p>1月19日，字节跳动拥有千万用户的「扣子空间」升级为「扣子2.0」，核心新增Agent Skills（封装场景最佳实践与工具，支持通过技能商店创建、获取行业专属技能）、Agent Plan（设定长期目标后自动规划执行并主动汇报）、Agent Office（深度理解职场场景，提供针对性洞察与文档处理能力）、Agent Coding（一站式云端开发平台，支持一键部署）四大能力，还上线了音画同步的官方视频创作Skill，定位职场人靠谱伙伴，助力高效完成简历筛选、文案创作、数据报表等各类工作任务。</p><p><strong>阶跃星辰正式推出「阶跃AI桌面伙伴Windows版」</strong></p><p>1月19日，阶跃星辰正式推出「阶跃AI桌面伙伴Windows版」，同时带来重要升级，该终端Agent定位“会做事、总在场、有记忆、能进化”，此前已发布Mac版（支持日程分析、当前窗口识别等专属功能），现支持调用16款第三方工具且可自行添加，具备本地存储的全局记忆（自动整理电脑活动轨迹并生成复盘报告），用户可通过官网下载。</p><p><strong>昆仑万维在Skywork平台推出面向非设计人士的「Skywork Design Agent」</strong></p><p>1月19日，昆仑万维在Skywork平台推出面向非设计人士的「Skywork Design Agent」，聚焦海报设计、社媒物料、LOGO与品牌视觉、通用创意生图四大核心场景，通过场景化指引、多启动方式（文生图/以图生图等）、自研画布引擎实现全流程设计，具备AI修图（拆分图层、扩图等）、素材知识库存档、多格式导出等功能，零门槛操作且效果可控，重塑办公视觉创作效率，后续将持续迭代专业功能并拓展AI多媒体创作能力。</p><p><strong>MiniMax发布第二代智能体「MiniMax Agent 2.0」，定位“AI原生工作台"</strong></p><p>1月20日，MiniMax稀宇科技发布第二代智能体「MiniMax Agent 2.0」，以“AI原生工作台”为核心定位，搭载桌面端应用（双系统适配，打通本地云端无缝衔接）与Expert Agents（定制化专家分身），可高效完成新闻摘要、论文解读、PPT制作等复杂任务，依托Lightning Attention等技术升级及内部迭代闭环，颠覆交互逻辑、打破专业壁垒，重塑AI高复杂度工作价值。</p><p><strong>Anthropic被曝升级Claude Cowork，新增「知识库」功能实现“永久记忆”</strong></p><p>1月20日消息，Anthropic被曝正在为Claude Cowork进行重大更新，通过新增「知识库」（Knowledge Bases）功能实现“永久记忆”，支持多对话、多任务间持续调用过往关键信息并动态更新，界面简化后新增Artifacts版块管理复用过往作品，同时扩展MCP连接器提升自动化能力，同步优化Web语音模式、Pixelate等轻量化功能，推动其从聊天助手向全面生产力助手演进，而开发者社区也通过Smart Forking等探索印证AI长期记忆的应用价值。</p><h2><strong>市场动态</strong></h2><p><strong>Roboparty全栈开源双足人形机器人「萝博头原型机」</strong></p><p>1月15日，Roboparty全栈开源双足人形机器人「萝博头原型机」，该原型机身高1.25m、重30kg，跑步速度达3m/s，同步开放硬件结构图、EBOM清单、AMP运控算法及避坑知识库，实现“可复现、可二开、可验证”，其搭载的拟人步态算法适配BFM框架，硬件采用类车规级结构，已获小米战投、商汤等机构千万美元种子轮融资，同时推出开发者共创计划。</p><p><strong>马斯克旗下xAI的全球首个GW级超算集群「Colossus 2」正式投入运行</strong></p><p>1月17日，马斯克旗下xAI的全球首个GW级超算集群「Colossus 2」正式投入运行，其搭载55.5万张GPU，4月将升级至1.5GW、最终达2GW，专为Grok模型训练服务（Grok 5参数预计6万亿），该集群从建设到上线仅用不到一年（前一代Colossus 1耗时122天）；而美国PJM电网因数据中心电力需求激增（未来10年年均增长4.8%），计划在极端天气对13州6700万居民轮流停电，不过「Colossus 2」不在该电网覆盖范围，且xAI部署了特斯拉Megapack储能系统以减少本地电网冲击。</p><p><strong>马斯克宣布开源「𝕏平台」推荐算法，每周四迭代一次</strong></p><p>1月20日，马斯克宣布开源「𝕏平台」（原Twitter）推荐算法代码，使其成为首个核心流量分发逻辑全透明化的主流社交平台，新版算法采用xAI Grok模型的Transformer架构，以“零人工特征工程”为核心，通过内部“Thunder”和外部“Phoenix Retrieval”召回内容，经Phoenix评分器加权计算得分，评分前后设过滤机制并保障作者多样性，未来将每四周更新开源版本并附开发者说明，这一透明化举措是其他社交平台未做到的。</p>]]></description></item><item>    <title><![CDATA[用 CSS 打造个性倒边框半径卡片效果 Silvana ]]></title>    <link>https://segmentfault.com/a/1190000047571566</link>    <guid>https://segmentfault.com/a/1190000047571566</guid>    <pubDate>2026-01-26 10:03:06</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <blockquote>你好，我是 Silvana，一名前端开发工程师菜鸟。</blockquote><p><strong>介绍：</strong></p><p>最近琢磨出一个简单又有特色的 <code>CSS</code> 小效果 —— 倒边框半径的卡片，用来做个人名片类的展示特别合适，不用复杂的插件，纯 <code>HTML+CSS</code> 就能实现，分享给喜欢折腾前端小效果的朋友～</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571568" alt="" title=""/></p><blockquote>这个卡片的核心是用 <code>CSS</code> 伪元素搭配阴影模拟出 “倒圆角” 的视觉效果，整体结构不复杂，下面把完整的代码和详细注释贴出来，新手也能轻松看懂、直接套用～</blockquote><h2>完整源码（附详细注释）</h2><h3>1. HTML 部分（index.html）</h3><pre><code class="HTML">&lt;!DOCTYPE html&gt;
&lt;html lang="en"&gt;
  &lt;head&gt;
    &lt;meta charset="UTF-8" /&gt;
    &lt;!-- 适配移动端视图 --&gt;
    &lt;meta name="viewport" content="width=device-width, initial-scale=1.0" /&gt;
    &lt;title&gt;CSS 倒边框半径卡&lt;/title&gt;
    &lt;!-- 引入样式文件 --&gt;
    &lt;link rel="stylesheet" href="style.css" /&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;!-- 卡片容器 --&gt;
    &lt;div class="card"&gt;
      &lt;!-- 顶部卡片区域（放视频背景） --&gt;
      &lt;div class="box"&gt;
        &lt;div class="imgBx"&gt;
          &lt;!-- 自动循环播放且静音的视频背景 --&gt;
          &lt;video src="cover.mp4" type="video/mp4" autoplay loop muted&gt;&lt;/video&gt;
        &lt;/div&gt;
      &lt;/div&gt;
      &lt;!-- 底部卡片区域（放个人信息） --&gt;
      &lt;div class="box"&gt;
        &lt;div class="content"&gt;
          &lt;!-- 姓名和身份 --&gt;
          &lt;h2&gt;Lila Simmons&lt;br/&gt;&lt;span&gt;Professional Artist&lt;/span&gt;&lt;/h2&gt;
          &lt;!-- 数据统计 --&gt;
          &lt;ul&gt;
            &lt;li&gt;Posts&lt;span&gt;62&lt;/span&gt;&lt;/li&gt;
            &lt;li&gt;Followers&lt;span&gt;120&lt;/span&gt;&lt;/li&gt;
            &lt;li&gt;Following&lt;span&gt;47&lt;/span&gt;&lt;/li&gt;
          &lt;/ul&gt;
          &lt;!-- 关注按钮 --&gt;
          &lt;button&gt;Follower&lt;/button&gt;
        &lt;/div&gt;
      &lt;/div&gt;
      &lt;!-- 左侧圆形头像区域 --&gt;
      &lt;div class="circle"&gt;
        &lt;div class="imgBx"&gt;
          &lt;img src="user.png" alt="用户头像"&gt;
        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/body&gt;
&lt;/html&gt;</code></pre><h3>2. CSS 部分（style.css）</h3><pre><code class="CSS">/* 全局样式重置 */
* {
  margin: 0;
  padding: 0;
  /* 盒模型：宽高包含边框和内边距 */
  box-sizing: border-box;
}
/* 定义全局颜色变量，方便统一修改 */
:root {
  --clr: #083d41
}
/* 页面整体样式：居中展示，背景色用变量 */
body{
  display: flex;
  justify-content: center;
  align-items: center;
  min-height: 100vh;
  background: var(--clr);
}
/* 卡片容器：相对定位，设置宽高，纵向排列子元素 */
.card {
  position: relative;
  width: 320px;
  height: 430px;
  display: flex;
  flex-direction: column;
  justify-content: space-between;
}
/* 卡片内的两个box通用样式 */
.card .box {
  position: relative;
  width: 110%;
  height: 200px;
  border-radius: 15px;
}
/* 第一个box（视频区域）：伪元素做左侧倒圆角 */
.card .box:nth-child(1) {
  background: #f00; /* 视频区域背景（被视频覆盖） */
}
.card .box:nth-child(1)::before {
  content: "";
  position: absolute;
  top: 106px;
  left: -1px;
  width: 20px;
  height: 20px;
  background: transparent;
  z-index: 10;
  border-bottom-left-radius: 20px;
  /* 利用阴影模拟倒圆角效果，颜色和页面背景一致 */
  box-shadow: -6px 6px var(--clr);
}
/* 第一个box：伪元素做底部倒圆角 */
.card .box:nth-child(1)::after {
  content: "";
  position: absolute;
  bottom: -1px;
  left: 105px;
  width: 20px;
  height: 20px;
  background: transparent;
  z-index: 10;
  border-bottom-left-radius: 20px;
  box-shadow: -6px 6px var(--clr);
}
/* 第二个box（信息区域）：调整宽高和背景色 */
.card .box:nth-child(2) {
  background: #fff;
  height: 220px;
  width: 100%;
}
/* 第二个box：伪元素做左侧倒圆角 */
.card .box:nth-child(2)::before {
  content: "";
  position: absolute;
  bottom: 106px;
  left: -1px;
  width: 20px;
  height: 20px;
  background: transparent;
  z-index: 10;
  border-top-left-radius: 20px;
  box-shadow: -6px -6px var(--clr);
}
/* 第二个box：伪元素做顶部倒圆角 */
.card .box:nth-child(2)::after {
  content: "";
  position: absolute;
  top: -1px;
  left: 109px;
  width: 20px;
  height: 20px;
  background: transparent;
  z-index: 10;
  border-top-left-radius: 20px;
  box-shadow: -6px -6px var(--clr);
}
/* 左侧圆形头像容器：绝对定位，居中显示 */
.card .circle {
  position: absolute;
  top: 50%;
  left: -70px;
  transform: translateY(-50%);
  width: 180px;
  height: 180px;
  border-radius: 50%;
  /* 边框颜色和页面背景一致，营造镂空感 */
  border: 10px solid var(--clr);
}
/* 头像和视频容器通用样式：溢出隐藏，适配圆角 */
.card .circle .imgBx,
.card .box .imgBx {
  position: absolute;
  inset: 0;
  overflow: hidden;
  border-radius: 50%;
}
/* 视频容器单独调整圆角，适配卡片 */
.card .box .imgBx {
  border-radius: 15px;
}
/* 头像和视频内容：铺满容器，保持比例 */
.card .circle .imgBx img,
.card .box .imgBx video {
  position: absolute;
  width: 100%;
  height: 100%;
  object-fit: cover;
}
/* 信息区域布局：居中排列，内边距调整 */
.card .box .content{
  position: absolute;
  inset: 0;
  padding: 30px 10px 20px;
  display: flex;
  align-items: center;
  flex-direction: column;
  gap: 20px;
}
/* 姓名样式：排版调整，颜色区分 */
.card .box .content h2{
  width: 100%;
  padding-left: 120px;
  text-transform: uppercase;
  font-size: 1.15em;
  letter-spacing: 0.1em;
  font-weight: 600;
  line-height: 1.1em;
  color: #333;
}
/* 身份文字：字号和颜色调整 */
.card .box .content h2 span {
  font-size: 0.75em;
  font-weight: 400;
  letter-spacing: 0.05em;
  color: #e91e63;
  text-transform: initial;
}
/* 数据统计列表：网格布局，均分宽度 */
.card .box .content ul {
  position: relative;
  top: 15px;
  display: grid;
  grid-template-columns: repeat(3, 1fr);
  width: 100%;
  padding: 0 10px;
  justify-content: space-evenly;
}
/* 列表项样式：纵向排列，文字颜色区分 */
.card .box .content ul li {
  list-style: none;
  display: flex;
  flex-direction: column;
  text-align: center;
  padding: 0 10px;
  font-size: 0.85em;
  font-weight: 500;
  color: #999;
}
/* 列表项分隔线：除最后一个外，右侧加边框 */
.card .box .content ul li:not(:last-child) {
  border-right: 1px solid #ccc;
}
/* 数据数字：字号放大，颜色加深 */
.card .box .content ul li span {
  font-size: 1.65em;
  color: #333;
}
/* 关注按钮样式：圆角、阴影、边框营造层次感 */
.card .box .content button {
  position: relative;
  top: 25px;
  padding: 8px 30px;
  border: none;
  outline: none;
  background: #03a9f4;
  border-radius: 30px;
  color: #fff;
  font-size: 1em;
  letter-spacing: .2em;
  text-transform: uppercase;
  font-weight: 500;
  cursor: pointer;
  border: 5px solid var(--clr);
  box-shadow: 0 0 0 10px #fff;
  transition: 0.5s;
}
/* 按钮hover效果：文字间距变大，背景色改变 */
.card .box .content button:hover{
  letter-spacing: 0.5em;
  background: #ff3d7f;
}
/* 按钮左侧倒圆角伪元素 */
.card .box .content button::before{
  content: "";
  position: absolute;
  top: 24px;
  left: -29px;
  width: 20px;
  height: 20px;
  background: transparent;
  border-top-right-radius: 20px;
  box-shadow: 5px -7px #fff;
}
/* 按钮右侧倒圆角伪元素 */
.card .box .content button::after{
  content: "";
  position: absolute;
  top: 24px;
  right: -29px;
  width: 20px;
  height: 20px;
  background: transparent;
  border-top-left-radius: 20px;
  box-shadow: -5px -7px #fff;
}</code></pre><p>替换里面的cover.mp4和user.png为自己的素材就能直接用，核心的倒圆角效果都在伪元素的box-shadow那里，调整数值还能改倒圆角的大小，感兴趣的可以自己试试。</p><blockquote>写着写着就到了结尾，祝您今晚有个好梦（代码少报错一点）。</blockquote><p>本文由<a href="https://link.segmentfault.com/?enc=c1wjZD389EcEr7dehqT7Kg%3D%3D.EFklvSFvmdogktkdMevzUAvBy7Q4wpP4FtnYtrz41Pg%3D" rel="nofollow" target="_blank">mdnice</a>多平台发布</p>]]></description></item><item>    <title><![CDATA[全知科技携手温州银行入选“数据安全合规治理实践与创新案例” 全知科技 ]]></title>    <link>https://segmentfault.com/a/1190000047571571</link>    <guid>https://segmentfault.com/a/1190000047571571</guid>    <pubDate>2026-01-26 10:02:21</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047545249" alt="图片" title="图片"/><br/>1月16日，由《网络安全与数据治理》期刊理事会主办的“数据安全合规治理实践与创新案例”颁奖仪式在北京成功举办。本次评选经过案例征集、初审筛选、专家评审与集中合议等多个环节，最终从众多参评项目中遴选出16个具有代表性的优秀企业案例。全知科技联合温州银行申报的“基于自动化建模与智能降噪的数据安全风险监测案例”从众多参评项目中脱颖而出，成功入选“数据安全合规治理实践与创新案例”，标志着双方在金融数据安全合规治理关键技术与应用模式上实现了重要突破。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047571573" alt="图片" title="图片" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571574" alt="图片" title="图片" loading="lazy"/><br/>本次评选围绕数据安全治理在真实业务场景中的落地能力与创新价值，重点关注治理体系建设、风险防控机制、技术支撑能力及实施成效等维度，旨在发掘和推广一批具有行业代表性、技术先进性和实践指导性的优秀案例，为各行各业的数据安全建设工作提供参考与借鉴。<br/>此次，全知科技与温州银行联合打造的“基于自动化建模与智能降噪的数据安全风险监测案例”，以数据为核心，构建“资产可视、流转可见、风险可察、使用可管、共享可溯”五层立体防护体系。该案例从“高感知、高智能、高效用”出发，覆盖170余种数据标签、30余种风险场景，100余种异常指标，实现自动化研判并生成工单派发，显著提升安全运营效率的同时，重点聚焦以数据为中心建立资产台账、以账号为基底关联数据行为、以智能化为助手降低风险误报等主要方向，打通用户、应用、接口层的同时，借助本地大模型驱动的监测敏感数据，完善实时风险监测机制，创新多视角用户行为基线，定位数据滥用。系统内置的风险规则引擎沉淀50余种金融专属场景，搭配智能算法库，更是大幅提升了风险识别准确率，为数据安全流通提供可推广的标杆解决方案。<br/>作为数据安全领域的重要参与者，全知科技始终坚持“技术驱动、安全赋能”的发展理念，持续深耕数据治理与风险防控核心能力建设。此次联合温州银行案例成功入选权威案例集，不仅体现了全知科技在金融行业数据安全合规治理中的成熟方法论，也验证了其将技术能力转化为可落地、可运营解决方案的实践价值。在此基础上，全知科技不断将实践经验反哺行业标准与技术规范建设，牵头制定的国家标准《数据安全技术 数据接口安全风险监测方法》已正式发布，实现了从“工程实践”到“标准输出”的双向突破与验证。未来，全知科技将继续以标准为引领，以场景为牵引，持续推动数据安全治理能力在更多行业与领域中落地生根，助力数字经济安全、稳健、高质量发展。</p>]]></description></item><item>    <title><![CDATA[如何在 CentOS 主机上配置集中式 Syslog 服务器 运维有小邓 ]]></title>    <link>https://segmentfault.com/a/1190000047571578</link>    <guid>https://segmentfault.com/a/1190000047571578</guid>    <pubDate>2026-01-26 10:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>分析 Linux/Unix 系统及其他网络设备生成的系统日志（Syslog），是IT管理员的核心工作内容之一。为提升日志分析的效率，管理员通常会采用日志集中采集的方式。本文详细介绍将 CentOS 系统配置为 rsyslog 集中采集服务器的具体步骤。</p><p>Rsyslog 服务在 CentOS 8 系统中为默认预装状态。你可在终端执行以下命令，检查服务运行状态：</p><p>$ systemctl status rsyslog</p><p>若命令返回的服务状态不为 Active: active (running)（运行中），请在终端执行以下命令安装 rsyslog：</p><p>$ sudo yum install rsyslog</p><p>如需通过 UDP 和 TCP 协议接收来自其他设备的系统日志，需编辑配置文件 /etc/rsyslog.conf，取消对应配置项的注释，以启用 TCP 和 UDP 监听功能。</p><p>•启用 UDP 协议：取消以下配置行的注释<br/>module(load="imudp")  #needs to be done just once<br/>input(type="imudp" port="514")</p><p>•启用 TCP 协议：取消以下配置行的注释<br/>module(load="imtcp")  #needs to be done just once<br/>input(type="imtcp" port="514")</p><p><strong>注意</strong></p><p>514 是 UDP 和 TCP 协议的默认监听端口，你可根据实际需求修改端口号。</p><p>保存配置并退出编辑界面。</p><p>确保客户端主机能够识别并与已配置的 rsyslog 服务器通信。为开放通信端口，需在防火墙中放行 514 端口，执行以下命令：</p><p>$ sudo firewall-cmd  --add-port=514/tcp  --zone=public  --permanent<br/>重新加载防火墙配置，使规则生效：</p><p>$ sudo firewall-cmd  --reload<br/>重启 rsyslog 服务，并执行以下命令，检查服务器是否已在 514 端口监听：</p><p>$ sudo netstat  -pnltu<br/>若配置成功，你会看到 514 端口的状态显示为 LISTEN（监听中）。</p><p>至此，基于 CentOS 系统的集中式 Syslog 采集服务器已配置完成。如需实时查看已采集的日志，可在服务器端执行以下命令：</p><p>$ tail  -f /var/log/messages</p><h2>如何监控 rsyslog 日志文件</h2><p>监控系统日志文件至关重要，这些日志可直观反映网络活动的详细情况，包括事件涉及的 IP 地址、时间戳、具体操作行为，以及对系统执行的关键配置变更等信息。</p><p>但手动监控 rsyslog 日志文件耗时费力，且难以实现高效的日志分析。通过专业的日志管理解决方案监控 rsyslog 日志，能够对日志数据进行深度解析。</p><p>EventLog Analyzer 是一款功能完善的日志管理工具，它可实现海量 rsyslog 数据的采集、解析、索引与分析，并生成可视化的统计报告。</p><p>工具会自动将检测到的恶意行为标记为安全威胁，并通过短信或邮件触发实时告警，及时通知 IT 安全管理员防范潜在的网络攻击。</p>]]></description></item><item>    <title><![CDATA[跟老卫学仓颉编程语言开发：统计字符串的字符数 waylau ]]></title>    <link>https://segmentfault.com/a/1190000047571174</link>    <guid>https://segmentfault.com/a/1190000047571174</guid>    <pubDate>2026-01-26 09:02:19</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>任务要求：给定一个字符串“ILoveCangjie”，编写一个仓颉应用程序，来统计该字符串的字符数。</p><h3>习题解题思路1</h3><p>练习步骤：</p><ul><li>定义字符串变量s；</li><li>遍历该变量s里面的字符。可以使用字符串的toArray()函数将字符串转为字节数组；</li><li>每遍历一次，即统计了一次字符数；</li><li>打印最终的遍历次数，即得出了该字符串的字符数。</li></ul><p>代码参考：见“count_the_number_of_characters”应用。</p><h3>习题解题思路2</h3><p>字符串的size属性，可以直接获取字符串 UTF-8 编码后的字节长度。</p><pre><code>public prop size: Int64</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571176" alt="" title=""/></p><h3>参考引用</h3><ul><li>示例源码，见免费开源书<a href="https://link.segmentfault.com/?enc=in5fgjKitkXRcI%2BCdL6ipg%3D%3D.7vuniyIp76y2iZpRWfB9DXNhS6Fe9V6oNeTZkLbRzkV%2BRB4N6i%2Bvfq9kokzEoYjmjH%2FgTk403NkQzK6ChlD80A%3D%3D" rel="nofollow" target="_blank">《跟老卫学仓颉编程语言开发》</a></li><li>免费开源书<a href="https://link.segmentfault.com/?enc=VY1LZ69F8ZUOVMMAATRfSA%3D%3D.qiiSXH7JJcvrxVE%2F1v99Ltn4rJO76z%2Bz6EvsSzho14z1Wfl3vOAL9wuHLozkSnNB" rel="nofollow" target="_blank">《跟老卫学HarmonyOS开发》</a></li><li><a href="https://link.segmentfault.com/?enc=LJMHj6QES2JN9YLRXrLMQg%3D%3D.l9n9rzfTbU8SNyNj%2BQUzB37YKfHxFIBa8tKjHz2YZYgWlpcv42jbfVDCGwuoeuRv" rel="nofollow" target="_blank">HarmonyOS NEXT+AI大模型打造智能助手APP（仓颉版）</a>（视频）</li><li><a href="https://link.segmentfault.com/?enc=%2Fegp%2B2vmGO9DSAfpnxg3kA%3D%3D.ZYoyxRjg1dkZaqNnNLFbxH1A2zWMR6fProYakENUCrhObZwGr7Jyg0053tUutWUHMFTfrNyoL8u0%2BGcfReppM9F4go%2Bujh0pOuz5LIe0aLU%3D" rel="nofollow" target="_blank">仓颉编程从入门到实践</a>（北京大学出版社）</li></ul>]]></description></item><item>    <title><![CDATA[CopyOnWriteArrayList：写时复制机制与高效并发访问 SevenCoding ]]></title>    <link>https://segmentfault.com/a/1190000047570524</link>    <guid>https://segmentfault.com/a/1190000047570524</guid>    <pubDate>2026-01-26 09:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>前言</h2><p>Vector无论是add方法还是get方法都加上了<a href="https://link.segmentfault.com/?enc=US8hubJkr%2FeLMZBjo9P29A%3D%3D.Ve9aSwSVyHGrf14sunE5XQKb5VnLDZ9IMb%2Bh%2BTpoxNydBYYkm9yI0v032B8FQtZqMfD7OkG3wyHJmIG1NCEDa%2FJbwjiRo4vmtJQL2bOPCG4%3D" rel="nofollow" target="_blank"><strong>synchronized</strong></a>修饰，当多线程读写List必须排队执行，很显然这样效率比较是低下的，CopyOnWriteArrayList是读写分离的，好处是提高线程访问效率。</p><p>CopyOnWrite容器即<strong>写时复制</strong>的容器。通俗的理解是当往一个容器添加元素的时候，不直接往当前容器添加，而是先将当前容器里的值Copy到新的容器，然后再往新的容器里添加元素，添加完元素之后，再将原容器的引用指向新的容器。这样做的好处是我们可以对CopyOnWrite容器进行并发的读 要加锁，因为当前容器不会添加任何元素。所以CopyOnWrite容器也是一种读写分离的思想，读和写不同的容器。</p><h2>底层原理</h2><ol><li>CopyOnWriteArrayList的动态数组机制 -- 它内部有个volatile数组(array)来保持数据。在“添加/删除”数据时，都会新建一个数组，并将更新后的数据拷贝到新建的数组中，最后再将该数组赋值给volatile数组。这就是它叫做CopyOnWriteArrayList的原因！</li><li>每一个CopyOnWriteArrayList都和一个监视器锁lock绑定，通过lock，实现了对CopyOnWriteArrayList的互斥添加/删除。</li></ol><h3>类的继承关系</h3><p>CopyOnWriteArrayList实现了List接口，List接口定义了对列表的基本操作；同时实现了RandomAccess接口，表示可以随机访问(数组具有随机访问的特性)；同时实现了Cloneable接口，表示可克隆；同时也实现了Serializable接口，表示可被序列化。</p><pre><code class="java">public class CopyOnWriteArrayList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable {}</code></pre><h3>类的内部类</h3><ul><li>COWIterator类</li></ul><p>COWIterator表示迭代器，其也有一个Object类型的数组作为CopyOnWriteArrayList数组的快照，这种快照风格的迭代器方法在创建迭代器时使用了对当时数组状态的引用。此数组在迭代器的生存期内不会更改，因此不可能发生冲突，并且迭代器保证不会抛出 ConcurrentModificationException。创建迭代器以后，迭代器就不会反映列表的添加、移除或者更改。在迭代器上进行的元素更改操作(remove、set 和 add)不受支持。这些方法将抛出 UnsupportedOperationException。</p><pre><code class="java">static final class COWIterator&lt;E&gt; implements ListIterator&lt;E&gt; {
    /** Snapshot of the array */
    // 快照
    private final Object[] snapshot;
    /** Index of element to be returned by subsequent call to next.  */
    // 游标
    private int cursor;
    // 构造函数
    private COWIterator(Object[] elements, int initialCursor) {
        cursor = initialCursor;
        snapshot = elements;
    }
    // 是否还有下一项
    public boolean hasNext() {
        return cursor &lt; snapshot.length;
    }
    // 是否有上一项
    public boolean hasPrevious() {
        return cursor &gt; 0;
    }
    // next项
    @SuppressWarnings("unchecked")
    public E next() {
        if (! hasNext()) // 不存在下一项，抛出异常
            throw new NoSuchElementException();
        // 返回下一项
        return (E) snapshot[cursor++];
    }

    @SuppressWarnings("unchecked")
    public E previous() {
        if (! hasPrevious())
            throw new NoSuchElementException();
        return (E) snapshot[--cursor];
    }
    
    // 下一项索引
    public int nextIndex() {
        return cursor;
    }
    
    // 上一项索引
    public int previousIndex() {
        return cursor-1;
    }

    /**
        * Not supported. Always throws UnsupportedOperationException.
        * @throws UnsupportedOperationException always; {@code remove}
        *         is not supported by this iterator.
        */
    // 不支持remove操作
    public void remove() {
        throw new UnsupportedOperationException();
    }

    /**
        * Not supported. Always throws UnsupportedOperationException.
        * @throws UnsupportedOperationException always; {@code set}
        *         is not supported by this iterator.
        */
    // 不支持set操作
    public void set(E e) {
        throw new UnsupportedOperationException();
    }

    /**
        * Not supported. Always throws UnsupportedOperationException.
        * @throws UnsupportedOperationException always; {@code add}
        *         is not supported by this iterator.
        */
    // 不支持add操作
    public void add(E e) {
        throw new UnsupportedOperationException();
    }

    @Override
    public void forEachRemaining(Consumer&lt;? super E&gt; action) {
        Objects.requireNonNull(action);
        Object[] elements = snapshot;
        final int size = elements.length;
        for (int i = cursor; i &lt; size; i++) {
            @SuppressWarnings("unchecked") E e = (E) elements[i];
            action.accept(e);
        }
        cursor = size;
    }
}</code></pre><h3>类的属性</h3><p>属性中有一个可重入锁，用来保证线程安全访问，还有一个Object类型的数组，用来存放具体的元素。当然，也使用到了反射机制和CAS来保证原子性的修改lock域。</p><pre><code class="java">public class CopyOnWriteArrayList&lt;E&gt;
    implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable {
    // 版本序列号
    private static final long serialVersionUID = 8673264195747942595L;
    // 可重入锁
    final transient ReentrantLock lock = new ReentrantLock();
    // 对象数组，用于存放元素
    private transient volatile Object[] array;
    // 反射机制
    private static final sun.misc.Unsafe UNSAFE;
    // lock域的内存偏移量
    private static final long lockOffset;
    static {
        try {
            UNSAFE = sun.misc.Unsafe.getUnsafe();
            Class&lt;?&gt; k = CopyOnWriteArrayList.class;
            lockOffset = UNSAFE.objectFieldOffset
                (k.getDeclaredField("lock"));
        } catch (Exception e) {
            throw new Error(e);
        }
    }
}</code></pre><h3>类的构造函数</h3><ul><li>默认构造函数</li></ul><pre><code class="java">public CopyOnWriteArrayList() {
    // 设置数组
    setArray(new Object[0]);
}</code></pre><ul><li>CopyOnWriteArrayList(Collection&lt;? extends E&gt;)</li></ul><pre><code class="java">public CopyOnWriteArrayList(Collection&lt;? extends E&gt; c) {
    Object[] elements;
    if (c.getClass() == CopyOnWriteArrayList.class) // 类型相同
        // 获取c集合的数组
        elements = ((CopyOnWriteArrayList&lt;?&gt;)c).getArray();
    else { // 类型不相同
        // 将c集合转化为数组并赋值给elements
        elements = c.toArray();
        // c.toArray might (incorrectly) not return Object[] (see 6260652)
        if (elements.getClass() != Object[].class) // elements类型不为Object[]类型
            // 将elements数组转化为Object[]类型的数组
            elements = Arrays.copyOf(elements, elements.length, Object[].class);
    }
    // 设置数组
    setArray(elements);
}
</code></pre><p>该构造函数的处理流程如下</p><ol><li>判断传入的集合c的类型是否为CopyOnWriteArrayList类型，若是，则获取该集合类型的底层数组(Object[])，并且设置当前CopyOnWriteArrayList的数组(Object[]数组)，进入步骤③；否则，进入步骤②</li><li>将传入的集合转化为数组elements，判断elements的类型是否为Object[]类型(toArray方法可能不会返回Object类型的数组)，若不是，则将elements转化为Object类型的数组。进入步骤③</li><li>设置当前CopyOnWriteArrayList的Object[]为elements。</li></ol><ul><li>CopyOnWriteArrayList(E[])：该构造函数用于创建一个保存给定数组的副本的列表。</li></ul><pre><code class="java">public CopyOnWriteArrayList(E[] toCopyIn) {
    // 将toCopyIn转化为Object[]类型数组，然后设置当前数组
    setArray(Arrays.copyOf(toCopyIn, toCopyIn.length, Object[].class));
}</code></pre><h3>核心函数分析</h3><p>对于CopyOnWriteArrayList的函数分析，主要明白Arrays.copyOf方法即可理解CopyOnWriteArrayList其他函数的意义。</p><h4>copyOf函数</h4><p>该函数用于复制指定的数组，截取或用 null 填充(如有必要)，以使副本具有指定的长度。</p><pre><code class="java">public static &lt;T,U&gt; T[] copyOf(U[] original, int newLength, Class&lt;? extends T[]&gt; newType) {
    @SuppressWarnings("unchecked")
    // 确定copy的类型(将newType转化为Object类型，将Object[].class转化为Object类型；
    // 判断两者是否相等，若相等，则生成指定长度的Object数组
    // 否则,生成指定长度的新类型的数组)
    T[] copy = ((Object)newType == (Object)Object[].class)
        ? (T[]) new Object[newLength]
        : (T[]) Array.newInstance(newType.getComponentType(), newLength);
    // 将original数组从下标0开始，复制长度为(original.length和newLength的较小者),复制到copy数组中(也从下标0开始)
    System.arraycopy(original, 0, copy, 0,
                        Math.min(original.length, newLength));
    return copy;
}</code></pre><h4>add函数</h4><pre><code class="java">public boolean add(E e) {
    // 可重入锁
    final ReentrantLock lock = this.lock;
    // 获取锁
    lock.lock();
    try {
        // 元素数组
        Object[] elements = getArray();
        // 数组长度
        int len = elements.length;
        // 复制数组
        Object[] newElements = Arrays.copyOf(elements, len + 1);
        // 存放元素e
        newElements[len] = e;
        // 设置数组
        setArray(newElements);
        return true;
    } finally {
        // 释放锁
        lock.unlock();
    }
}</code></pre><p>此函数用于将指定元素添加到此列表的尾部，处理流程如下</p><ol><li>获取锁(保证多线程的安全访问)，获取当前的Object数组，获取Object数组的长度为length，进入步骤②。</li><li>根据Object数组复制一个长度为length+1的Object数组为newElements(此时，newElements[length]为null)，进入下一步骤。</li><li>将下标为length的数组元素newElements[length]设置为元素e，再设置当前Object[]为newElements，释放锁，返回。这样就完成了元素的添加。</li></ol><h4>addIfAbsent方法</h4><p>该函数用于添加元素(如果数组中不存在，则添加；否则，不添加，直接返回)，可以保证多线程环境下不会重复添加元素。</p><pre><code class="java">private boolean addIfAbsent(E e, Object[] snapshot) {
    // 重入锁
    final ReentrantLock lock = this.lock;
    // 获取锁
    lock.lock();
    try {
        // 获取数组
        Object[] current = getArray();
        // 数组长度
        int len = current.length;
        if (snapshot != current) { // 快照不等于当前数组，对数组进行了修改
            // Optimize for lost race to another addXXX operation
            // 取较小者
            int common = Math.min(snapshot.length, len);
            for (int i = 0; i &lt; common; i++) // 遍历
                if (current[i] != snapshot[i] &amp;&amp; eq(e, current[i])) // 当前数组的元素与快照的元素不相等并且e与当前元素相等
                    // 表示在snapshot与current之间修改了数组，并且设置了数组某一元素为e，已经存在
                    // 返回
                    return false;
            if (indexOf(e, current, common, len) &gt;= 0) // 在当前数组中找到e元素
                // 返回
                return false;
        }
        // 复制数组
        Object[] newElements = Arrays.copyOf(current, len + 1);
        // 对数组len索引的元素赋值为e
        newElements[len] = e;
        // 设置数组
        setArray(newElements);
        return true;
    } finally {
        // 释放锁
        lock.unlock();
    }
}</code></pre><p>该函数的流程如下:</p><ol><li>获取锁，获取当前数组为current，current长度为len，判断数组之前的快照snapshot是否等于当前数组current，若不相等，则进入步骤2；否则，进入步骤4</li><li>不相等，表示在snapshot与current之间，对数组进行了修改(如进行了add、set、remove等操作)，获取长度(snapshot与current之间的较小者)，对current进行遍历操作，若遍历过程发现snapshot与current的元素不相等并且current的元素与指定元素相等(可能进行了set操作)，进入步骤5，否则，进入步骤3</li><li>在当前数组中索引指定元素，若能够找到，进入步骤5，否则，进入步骤4</li><li>复制当前数组current为newElements，长度为len+1，此时newElements[len]为null。再设置newElements[len]为指定元素e，再设置数组，进入步骤5</li><li>释放锁，返回。</li></ol><h4>set函数</h4><p>此函数用于用指定的元素替代此列表指定位置上的元素，也是基于数组的复制来实现的。</p><pre><code class="java">public E set(int index, E element) {
    // 可重入锁
    final ReentrantLock lock = this.lock;
    // 获取锁
    lock.lock();
    try {
        // 获取数组
        Object[] elements = getArray();
        // 获取index索引的元素
        E oldValue = get(elements, index);

        if (oldValue != element) { // 旧值等于element
            // 数组长度
            int len = elements.length;
            // 复制数组
            Object[] newElements = Arrays.copyOf(elements, len);
            // 重新赋值index索引的值
            newElements[index] = element;
            // 设置数组
            setArray(newElements);
        } else {
            // Not quite a no-op; ensures volatile write semantics
            // 设置数组
            setArray(elements);
        }
        // 返回旧值
        return oldValue;
    } finally {
        // 释放锁
        lock.unlock();
    }
}</code></pre><h4>remove函数</h4><p>此函数用于移除此列表指定位置上的元素。</p><pre><code class="java">public E remove(int index) {
    // 可重入锁
    final ReentrantLock lock = this.lock;
    // 获取锁
    lock.lock();
    try {
        // 获取数组
        Object[] elements = getArray();
        // 数组长度
        int len = elements.length;
        // 获取旧值
        E oldValue = get(elements, index);
        // 需要移动的元素个数
        int numMoved = len - index - 1;
        if (numMoved == 0) // 移动个数为0
            // 复制后设置数组
            setArray(Arrays.copyOf(elements, len - 1));
        else { // 移动个数不为0
            // 新生数组
            Object[] newElements = new Object[len - 1];
            // 复制index索引之前的元素
            System.arraycopy(elements, 0, newElements, 0, index);
            // 复制index索引之后的元素
            System.arraycopy(elements, index + 1, newElements, index,
                                numMoved);
            // 设置索引
            setArray(newElements);
        }
        // 返回旧值
        return oldValue;
    } finally {
        // 释放锁
        lock.unlock();
    }
}</code></pre><p>处理流程如下</p><ol><li>获取锁，获取数组elements，数组长度为length，获取索引的值elements[index]，计算需要移动的元素个数(length - index - 1),若个数为0，则表示移除的是数组的最后一个元素，复制elements数组，复制长度为length-1，然后设置数组，进入步骤③；否则，进入步骤②</li><li>先复制index索引前的元素，再复制index索引后的元素，然后设置数组。</li><li>释放锁，返回旧值</li><li/></ol><h2>CopyOnWriteArrayList是Fail Safe的</h2><p>采用安全失败机制的集合容器，在遍历时不是直接在集合内容上访问的，而是先复制原有集合内容，在拷贝的集合上进行遍历。java.util.concurrent包下的容器都是安全失败，可以在多线程下并发使用，并发修改。</p><p>原理：由于迭代时是对原集合的拷贝进行遍历，所以在遍历过程中对原集合所作的修改并不能被迭代器检测到，所以不会触发Concurrent Modification Exception。</p><p>缺点：基于拷贝内容的优点是避免了Concurrent Modification Exception，但同样地，迭代器并不能访问到修改后的内容，即：迭代器遍历的是开始遍历那一刻拿到的集合拷贝，在遍历期间原集合发生的修改迭代器是不知道的。</p><p>Vector无论是add方法还是get方法都加上了<strong>synchronized</strong>修饰，当多线程读写List必须排队执行，很显然这样效率比较是低下的，CopyOnWriteArrayList是读写分离的，好处是提高线程访问效率。</p><h2>缺陷和使用场景</h2><ul><li>CopyOnWriteArrayList的写效率比Vector慢。当CopyOnWriteArrayList写元素时是通过备份数组的方式实现的，当多线程同步激烈，数据量较大时会不停的<strong>复制数组，内存浪费严重</strong>。如果原数组的内容比较多的情况下，可能导致young gc或者full gc</li><li>弱一致性：不能用于实时读的场景，像拷贝数组、新增元素都需要时间，所以调用一个set操作后，读取到数据可能还是旧的，虽然CopyOnWriteArrayList 能做到最终一致性，但是还是没法满足实时性要求；</li></ul><p><strong>小结：</strong> CopyOnWriteArrayList合适读多写少的场景，例如黑名单白名单等</p>]]></description></item><item>    <title><![CDATA[HarmonyOS 6 智能带办应用开发之华日历接入实践 轻口味 ]]></title>    <link>https://segmentfault.com/a/1190000047570205</link>    <guid>https://segmentfault.com/a/1190000047570205</guid>    <pubDate>2026-01-26 07:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h4>背景介绍</h4><p>前段时间上架的“智能带办”鸿蒙应用，应用亮点是根据用户输入要做的事情自动自动生成需要带的东西。在使用过程中发现有些东西不能立马拿到的需要在未来某个时刻拿的需要提醒。重新设计产品时发现，自己实现提醒功能还是挺复杂的，如果用云端方案接入通知方式不仅复杂而且可控性太差。这个时候想到接入日程，通过系统能力来实现功能。</p><p>接入后向左滑动待办物品，出现日历按钮，效果如图：<br/><img width="400" height="827" referrerpolicy="no-referrer" src="/img/bVdnLlv" alt="image.png" title="image.png"/></p><p>点击按钮弹出日程计划日期和时间：<br/><img width="395" height="847" referrerpolicy="no-referrer" src="/img/bVdnLlw" alt="image.png" title="image.png" loading="lazy"/><br/>选择完日期和事件自动自动完成日程创建。下面先介绍鸿蒙日历能力。</p><h4>鸿蒙日历📅 能力介绍</h4><h5>简介</h5><p>HarmonyOS 的 Calendar Kit（日历服务）是一套系统级的日程管理接口，旨在将出行、餐饮、运动等各类与时间相关的服务与系统日历无缝集成，实现统一的时间视图与提醒能力。核心能力如下：</p><ul><li>账户管理：支持创建、查询和删除日历账户。应用可创建专属账户（返回唯一 <code>accountId</code>），删除账户将同时清除其下所有日程。</li><li>日程管理 (CRUD)：在指定账户下，支持日程的全生命周期管理，包括创建（返回唯一 <code>eventId</code>）、删除、更新和查询。创建时可设置标题、时间、地点、提醒及重复规则等属性。</li><li>一键服务：通过永久性授权，可将带 DeepLink 的“一键服务”写入日历。当日程临近或到期，系统会在日历、通知、卡片等位置展示服务按钮，用户点击即可直达服务页面，实现从“看到日程”到“完成服务”的闭环。<br/>我们的应用主要用到账户和日程管理，使用日历需要如下权限：</li></ul><table><thead><tr><th>申请权限</th><th>支持的日历账户操作范围</th><th>支持的日程操作范围</th></tr></thead><tbody><tr><td><code>ohos.permission.READ_CALENDAR</code></td><td>读取系统默认及当前应用创建的日历账户。</td><td>读取上述账户下当前应用创建的日程。</td></tr><tr><td><code>ohos.permission.WRITE_CALENDAR</code></td><td>增、删、改当前应用创建的日历账户。</td><td>增、删、改上述账户下当前应用创建的日程。</td></tr><tr><td><code>ohos.permission.READ_WHOLE_CALENDAR</code></td><td>读取设备上所有日历账户。</td><td>读取所有应用创建的日程。</td></tr><tr><td><code>ohos.permission.WRITE_WHOLE_CALENDAR</code></td><td>增、删、改设备上所有日历账户。</td><td>增、删、改所有应用创建的日程。</td></tr></tbody></table><p>我们只需要读取我们自己应用创建的日历账号下日程即可，所以申请前两个权限即可。</p><h5>账户管理</h5><p>日历账户‌用于存储和管理个人或团队的日程，通过日历账户，用户可以方便地查看、编辑和共享日程信息。日历管理器CalendarManager用于管理日历账户Calendar。日历账户主要包含账户信息CalendarAccount和配置信息CalendarConfig。</p><p>我们可以创建属于应用特有的日历账户，还可以对日历账户进行新增、删除、更新和查询。此外，每个日程Event归属于某一个特定的日历账户，可以通过日历账户对账户下面的日程进行管理。</p><p><code>@ohos.calendarManager</code>提供了日历账户管理的相关接口，常用到的接口如下表：</p><table><thead><tr><th align="left">接口名称</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left">getCalendarManager(context: Context): CalendarManager</td><td align="left">根据上下文获取日历管理器对象CalendarManager，用于管理日历。</td></tr><tr><td align="left">createCalendar(calendarAccount: CalendarAccount): Promise&lt;Calendar&gt;</td><td align="left">根据日历账户信息，创建一个Calendar对象，使用Promise异步回调。</td></tr><tr><td align="left">getCalendar(calendarAccount?: CalendarAccount): Promise&lt;Calendar&gt;</td><td align="left">获取默认Calendar对象或者指定Calendar对象，使用Promise异步回调。<br/><br/>默认Calendar是日历存储首次运行时创建的，若创建Event时不关注其Calendar归属，则无须通过createCalendar()创建Calendar，直接使用默认Calendar。</td></tr><tr><td align="left">getAllCalendars(): Promise&lt;Calendar[]&gt;</td><td align="left">获取当前应用所有创建的Calendar对象以及默认Calendar对象，使用Promise异步回调。</td></tr><tr><td align="left">deleteCalendar(calendar: Calendar): Promise&lt;void&gt;</td><td align="left">删除指定Calendar对象，使用Promise异步回调。</td></tr><tr><td align="left">getConfig(): CalendarConfig</td><td align="left">获取日历配置信息。</td></tr><tr><td align="left">setConfig(config: CalendarConfig): Promise&lt;void&gt;</td><td align="left">设置日历配置信息，使用Promise异步回调。</td></tr><tr><td align="left">getAccount(): CalendarAccount</td><td align="left">获取日历账户信息。</td></tr></tbody></table><h5>日程管理</h5><p>日程指特定的事件或者活动安排，日程管理即对这些事件、活动进行规划和控制，能更有效地利用相关资源、提高生产力和效率，使人们更好地管理时间和任务。Calendar Kit中的日程Event归属于某个对应的日历账户Calendar，一个日历账户下可以有多个日程，一个日程只属于一个Calendar。取到日历账户对象之后，即可对该账户下的日程进行管理，包括日程的创建、删除、修改、查询等操作。在创建、修改日程时，支持对日程的标题、开始时间、结束时间、日程类型、日程地点、日程提醒时间、日程重复规则等相关信息进行设置，以便进行更丰富更有效的日程管理。</p><p><code>@ohos.calendarManager</code>提供了日程管理的相关接口，常用到的接口如下表：</p><table><thead><tr><th align="left">接口名称</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left">getCalendarManager(context: Context): CalendarManager</td><td align="left">根据上下文获取CalendarManager对象，用于管理日历。</td></tr><tr><td align="left">createCalendar(calendarAccount: CalendarAccount): Promise&lt;Calendar&gt;</td><td align="left">根据日历账户信息，创建一个Calendar对象，使用Promise异步回调。</td></tr><tr><td align="left">addEvent(event: Event): Promise&lt;number&gt;</td><td align="left">创建日程，入参Event不填日程id，使用Promise异步回调。</td></tr><tr><td align="left">editEvent(event: Event): Promise&lt;number&gt;</td><td align="left">通过跳转到日程创建界面创建单个日程，入参Event不填日程id，使用Promise异步回调。</td></tr><tr><td align="left">deleteEvent(id: number): Promise&lt;void&gt;</td><td align="left">删除指定日程id的日程，使用Promise异步回调。</td></tr><tr><td align="left">updateEvent(event: Event): Promise&lt;void&gt;</td><td align="left">更新日程，使用Promise异步回调。</td></tr><tr><td align="left">getEvents(eventFilter?: EventFilter, eventKey?: (keyof Event)[]): Promise&lt;Event[]&gt;</td><td align="left">获取Calendar下符合查询条件的Event，使用Promise异步回调。</td></tr></tbody></table><h4>智能带办接入过程</h4><h5>1、导入依赖</h5><p>接入账号管理，首先需要导入相关依赖：</p><pre><code class="ts">import { abilityAccessCtrl, AbilityConstant, common, PermissionRequestResult, Permissions, UIAbility, Want } from '@kit.AbilityKit';
import { calendarManager } from '@kit.CalendarKit';</code></pre><h5>2、创建日历管理类</h5><pre><code class="ts">  
const TAG = 'CalendarService';  
  
/**  
 * Service to manage Calendar Kit operations. */
   export class CalendarService {  
  private static calendar: calendarManager.Calendar | undefined = undefined;  
  //账号信息
  private static readonly calendarAccount: calendarManager.CalendarAccount = {  
    name: 'IntelligentTodo',  
    type: calendarManager.CalendarType.LOCAL,  
    displayName: '智能带办'  
  };  
  
  /**  
   * 添加日程到日历
   * @param title The title of the todo.  
   * @param description The description of the todo.  
   * @param startTime The start time (milliseconds).   * @param endTime The end time (milliseconds).   * @returns The event ID.    */  
     public static async addEvent(title: string, description: string, startTime: number, endTime: number): Promise&lt;number&gt; {  
    const mgr = AppStorage.get&lt;calendarManager.CalendarManager&gt;('calendarMgr');  
    if (!mgr) {  
      Logger.e(TAG, 'calendarMgr is not initialized in AppStorage');  
      throw new Error('日历服务未准备就绪');  
    }  
  
    // Request permissions first  
    const context = AppStorage.get&lt;common.UIAbilityContext&gt;('abilityContext');  
    if (context) {  
      const granted = await CalendarService.checkAndRequestPermissions(context);  
      if (!granted) {  
        throw new Error('未获得日历权限');  
      }  
    }  
    try {  
      if (!CalendarService.calendar) {  
        CalendarService.calendar = await CalendarService.getOrCreateCalendar(mgr);  
      }  
  
      const event: calendarManager.Event = {  
        title: title,  
        description: description,  
        type: calendarManager.EventType.NORMAL,  
        startTime: startTime,  
        endTime: endTime,  
        reminderTime: [10] // Default 10 minutes reminder  
      };  
  
      if (!CalendarService.calendar) {  
        throw new Error('日历对象初始化失败');  
      }  
      const eventId = await CalendarService.calendar.addEvent(event);  
      Logger.i(TAG, `Succeeded in adding event, id -&gt; ${eventId}`);  
      return eventId;  
    } catch (error) {  
      Logger.e(TAG, `Failed to add event: ${JSON.stringify(error)}`);  
      throw new Error(JSON.stringify(error));  
    }  
  }  
  /**  
   * 创建日历对象
   */  
     private static async getOrCreateCalendar(mgr: calendarManager.CalendarManager): Promise&lt;calendarManager.Calendar&gt; {  
    try {  
      // Try to find if our account already exists  
      const calendars = await mgr.getAllCalendars();  
      const existing = calendars.find(c =&gt; {  
        const acc = c.getAccount();  
        return acc.name === CalendarService.calendarAccount.name;  
      });  
      if (existing) {  
        return existing;  
      }  
  
      // Create new account if not exists  
      const newCalendar = await mgr.createCalendar(CalendarService.calendarAccount);  
      const config: calendarManager.CalendarConfig = {  
        enableReminder: true,  
        color: '#aabbcc'  
      };  
      await newCalendar.setConfig(config);  
      return newCalendar;  
    } catch (err) {  
      Logger.e(TAG, `getOrCreateCalendar error: ${JSON.stringify(err)}`);  
      // Fallback to default calendar if creation fails  
      return await mgr.getCalendar();  
    }  
  }  
  /**  
   * 动态获取权限
  */  
     private static async checkAndRequestPermissions(context: common.UIAbilityContext): Promise&lt;boolean&gt; {  
    const permissions: Array&lt;Permissions&gt; = ['ohos.permission.READ_CALENDAR', 'ohos.permission.WRITE_CALENDAR'];  
    const atManager = abilityAccessCtrl.createAtManager();  
    try {  
      const result = await atManager.requestPermissionsFromUser(context, permissions);  
      const grantStatus = result.authResults;  
      return grantStatus.every(s =&gt; s === 0);  
    } catch (err) {  
      Logger.e(TAG, `requestPermissionsFromUser error: ${JSON.stringify(err)}`);  
      return false;  
    }  
  }}</code></pre><p>getOrCreateCalendar根据上下文获取日程管理器对象calendarMgr，用于对日历账户进行相关管理操作。官方推荐在EntryAbility.ets文件中进行操作，我们这里进行独立封装，对权限做到精准控制，在使用时再申请。接着根据日历账户信息，创建一个日历账户Calendar对象。创建日历账户之前，我们需要先根据账户信息进行查询，如果账户不存在则抛出异常信息，捕获到异常再进行日历账户的创建，否则可能会出现账户重复创建的问题。<br/>日历账户创建之后，日历账户颜色默认为黑色，不指定日历账户颜色可能导致部分版本/设备深色模式下显示效果不佳。开发者需要调用setConfig()接口设置日历配置信息，包括是否打开日历账户下的日程提醒能力、设置日历账户颜色。</p><pre><code class="ts">const calendarAccounts: calendarManager.CalendarAccount = {
  name: 'MyCalendar',
  type: calendarManager.CalendarType.LOCAL,
  displayName: 'MyCalendar'
};
// 日历配置信息
calendarMgr?.getCalendar(calendarAccounts, (err, data) =&gt; {
  //获取日历账户
  if (err) {
    hilog.error(DOMAIN, 'testTag', `Failed to get calendar, Code is ${err.code}, message is ${err.message}`);
  } else {
    const config: calendarManager.CalendarConfig = {
      // 打开日程提醒
      enableReminder: true,
      // 设置日历账户颜色
      color: '#aabbcc'
    };
    // 设置日历配置信息
    data.setConfig(config).then(() =&gt; {
      hilog.info(DOMAIN, 'testTag', '%{public}s', `Succeeded in setting config, data-&gt;${JSON.stringify(config)}`);
    }).catch((err: BusinessError) =&gt; {
      hilog.error(DOMAIN, 'testTag', `Failed to set config. Code: ${err.code}, message: ${err.message}`);
    })
  }
});</code></pre><p>addEvent方法封装了在当前日历账户下添加日历日程，注意入参中不需要填写日程id。创建日程时，支持设置日程的标题、开始时间、结束时间、日程类型、日程地点、日程提醒时间、日程重复规则等相关信息。程创建成功后会返回一个日程id，作为日程的唯一标识，后续可按照日程id进行指定日程的更新或删除。<br/>目前支持以下两种方式来创建日程。<br/>方式一：可以在日历账户下通过addEvent()或addEvents()接口创建日程。其中可使用addEvent()接口创建单个日程，也可以使用addEvents()接口批量创建日程，此处以创建单个日程为例。<br/>方式二：在获取到日历管理器对象后，可通过editEvent()接口创建单个日程。调用此接口创建日程时，会跳转到日程创建页面，在日程创建页面进行相关操作完成日程的创建, editEvent()不支持自定义周期性日程创建。</p><p>我们采用方式一，用户点击日程时弹窗日期时间选择器，用户选择时间后调用addEvent方法创建日程。</p><h4>总结</h4><p>本次功能迭代的核心思路是“借力系统能力，优化产品体验”。面对自建提醒功能的复杂性，我们选择接入鸿蒙Calendar Kit，将待办事项转化为系统日程。通过左滑待办项快速创建日程，并利用系统日历实现稳定、统一的提醒。这一方案通过封装<code>CalendarService</code>精准管理权限与账户，既大幅降低了开发复杂度和维护成本，又为用户提供了原生、可靠的提醒服务，是“站在系统肩膀上”高效解决通用需求的典型实践。</p>]]></description></item><item>    <title><![CDATA[为本地部署的大模型添加API Key认证：Nginx实现方案 BugShare ]]></title>    <link>https://segmentfault.com/a/1190000047571092</link>    <guid>https://segmentfault.com/a/1190000047571092</guid>    <pubDate>2026-01-26 00:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在使用 LangChain 开发大模型应用时，我们经常会遇到这样的场景：</p><ul><li>使用在线模型（如 OpenAI、通义千问等）时，自带 API Key 认证机制</li><li>本地部署的 Ollama、vLLM 等模型服务，默认<strong>没有任何认证</strong></li></ul><p>在<strong>本地或局域网</strong>环境下问题还不明显；但一旦你需要：</p><ul><li>将模型服务暴露到公网</li><li>提供给团队其他成员使用</li><li>作为内部 AI 平台或推理服务</li></ul><p>那么“<strong>无认证</strong>”就意味着：</p><blockquote>任何人只要知道地址，就可以无限制地调用你的模型服务。</blockquote><p>这不仅有安全风险，还可能带来<strong>资源滥用和成本失控</strong>。</p><p>本文介绍一种<strong>简单、官方、优雅</strong>的解决方案：</p><blockquote><strong>使用 Nginx 为本地大模型服务添加 API Key 认证</strong></blockquote><p>无需改动 Ollama / vLLM，也无需额外开发复杂的鉴权系统。</p><hr/><h2>一、解决方案概述</h2><p>Nginx 作为高性能 Web 服务器和反向代理，本身就具备非常灵活的请求处理能力。</p><p>我们可以利用 Nginx 的能力，在模型服务前面加一层 <strong>API Key 校验</strong>：</p><pre><code class="markdown">客户端  →  Nginx（API Key 校验）  →  Ollama / vLLM

┌──────────────────────────┐
│        Client             │
│  LangChain / SDK / curl   │
└─────────────┬────────────┘
│
│ Authorization: Bearer API_KEY
▼
┌──────────────────────────┐
│          Nginx            │
│  • API Key 校验 (map)     │
│  • 限流 (limit_req)       │
│  • 日志 / 代理 / TLS      │
└─────────────┬────────────┘
│
▼
┌──────────────────────────┐
│     Model Server          │
│  Ollama / vLLM            │
│  127.0.0.1:11434          │
└──────────────────────────┘</code></pre><h3>方案特点</h3><ul><li>✅ <strong>零侵入</strong>：模型服务本身无需任何改动</li><li>✅ <strong>配置即用</strong>：纯 Nginx 配置实现</li><li>✅ <strong>性能稳定</strong>：Nginx 原生能力，几乎无额外开销</li><li>✅ <strong>可扩展</strong>：后续可无缝接入 HTTPS、限流、日志、负载均衡</li></ul><hr/><h2>二、具体实施步骤</h2><h3>1️⃣ 生成 API Key</h3><p>首先生成一个足够安全的随机字符串作为 API Key：</p><pre><code class="bash">openssl rand -hex 16</code></pre><p>示例输出（32 位）：</p><pre><code>a1b2c3d4e5f6g7h8i9j0k1l2m3n4o5p6</code></pre><blockquote><p>建议：</p><ul><li>每个使用方一个 Key</li><li>不要硬编码到代码仓库</li></ul></blockquote><hr/><h3>2️⃣ 配置 Nginx（conf.d）</h3><p>在 Nginx 的 <code>conf.d</code> 目录中创建配置文件，例如：</p><p><code>/etc/nginx/conf.d/ollama-api.conf</code></p><pre><code class="nginx"># 期望请求头格式：Authorization: Bearer &lt;api-key&gt;
map $http_authorization $is_valid_key {
    default 0;
    "Bearer your-api-key-1" 1;
    "Bearer your-api-key-2" 1;
    "Bearer your-api-key-3" 1;
}

server {
    listen 21434;
    server_name your-domain.com;  # 替换为你的域名

    location / {
        # API Key 校验
        if ($is_valid_key = 0) {
            return 401 'Unauthorized';
        }

        # 代理到本地模型服务
        proxy_pass http://127.0.0.1:11434;

        # 代理头设置
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        # 流式响应支持（Chat / Stream 模式必开）
        proxy_buffering off;
        proxy_cache off;
    }

    # 健康检查接口（可选，不做认证）
    location /health {
        access_log off;
        return 200 "OK";
    }
}</code></pre><p>至此，你已经为 Ollama / vLLM 加上了一道 <strong>API Key 防线</strong>。</p><hr/><h3>3️⃣ 增加限流保护（强烈建议）</h3><p>为了防止 API Key 泄露后被恶意刷请求，可以增加限流。</p><p>在 <code>http</code> 块中定义限流区域：</p><pre><code class="nginx">http {
    limit_req_zone $binary_remote_addr zone=api_limit:10m rate=10r/s;
}</code></pre><p>在 <code>server</code> 或 <code>location</code> 中启用：</p><pre><code class="nginx">location / {
    # 单 IP 每秒最多 10 次请求，允许短暂突发
    limit_req zone=api_limit burst=20 nodelay;

    # 其他配置...
}</code></pre><hr/><h3>4️⃣ 重载 Nginx 配置</h3><pre><code class="bash">nginx -s reload</code></pre><hr/><h2>三、LangChain 客户端调用示例</h2><p>配置完成后，客户端只需像调用在线模型一样，携带 <code>api_key</code> 即可。</p><pre><code class="python"># pip install -U langchain langchain-openai

from langchain_openai import ChatOpenAI

llm = ChatOpenAI(
    model="qwen3:32b",
    base_url="http://192.168.31.33:21434/v1",
    api_key="your_api_key",
)</code></pre><p><strong>是不是非常像 OpenAI？</strong></p><blockquote>这也是这个方案最大的优点之一：<br/>👉 调用方式完全统一，几乎零学习成本。</blockquote><hr/><h2>四、常见问题：map_hash 报错</h2><p>如果你的 API Key 较长（例如 &gt;64 字符），Nginx 启动时可能出现错误：</p><pre><code>could not build map_hash, you should increase map_hash_bucket_size: 64</code></pre><p>解决方法：在 <code>http</code> 块中增加配置：</p><pre><code class="nginx">http {
    map_hash_bucket_size 128;

    # 如果遇到 server_names_hash_bucket_size 报错
    # server_names_hash_bucket_size 128;
}</code></pre><hr/><h2>五、安全与生产建议</h2><ol><li><p><strong>API Key 管理</strong></p><ul><li>不要提交到 Git 仓库</li><li>建议使用环境变量或配置管理系统</li></ul></li><li><p><strong>日志审计</strong></p><ul><li>启用 Nginx access log</li><li>可按 API Key 或 IP 分析调用情况</li></ul></li><li><p><strong>网络隔离</strong></p><ul><li>对外仅开放 Nginx 端口</li><li>Ollama / vLLM 原始端口仅监听 <code>127.0.0.1</code></li></ul></li><li><p><strong>HTTPS</strong>（强烈建议）</p><ul><li>API Key 明文传输必须配合 TLS 使用</li></ul></li></ol><hr/><h2>六、总结</h2><p>通过 <strong>Nginx + API Key</strong> 的方式，我们可以非常优雅地为本地大模型服务补齐「认证」这一关键能力：</p><ul><li>🔒 无需修改 Ollama / vLLM</li><li>🚀 性能损耗极低</li><li>🧩 与 LangChain / OpenAI 调用方式高度一致</li><li>🛠️ 后续可轻松扩展限流、HTTPS、负载均衡</li></ul><p>如果你正在：</p><ul><li>构建私有大模型平台</li><li>在内网或公网部署推理服务</li><li>希望用<strong>最小成本</strong>提升安全性</li></ul><p>那么，这个方案非常值得你直接落地使用。</p><p>希望这篇文章能对你有所帮助 🙌</p><p>欢迎转发、收藏，也欢迎交流更高级的模型服务治理方案。</p>]]></description></item><item>    <title><![CDATA[OneClip 开发经验分享：从零到一的 macOS 剪切板应用开发 飞翔蓝天 ]]></title>    <link>https://segmentfault.com/a/1190000047570319</link>    <guid>https://segmentfault.com/a/1190000047570319</guid>    <pubDate>2026-01-25 23:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>OneClip 开发经验分享：从零到一的 macOS 应用开发</h2><h3>前言</h3><p><a href="https://link.segmentfault.com/?enc=duGMia2JDohSa5yE61649Q%3D%3D.4I3%2FJ68jP04RlB7XMXSKRsDDzobbHGC%2FuC2YDCVg8ZKa27WG5pKkfzzAtupU6zGG" rel="nofollow" target="_blank">OneClip</a> 从最初的想法到现在的功能完整的应用，经历了多个版本的迭代。本文分享开发过程中的真实经验、遇到的问题、解决方案和最佳实践，希望能为其他 macOS 开发者提供参考。</p><h3>技术选型</h3><h4>为什么选择 SwiftUI？</h4><p><strong>初期考虑</strong>：</p><ul><li>AppKit（传统 macOS 开发）</li><li>SwiftUI（Apple 新推荐）</li><li>Electron（跨平台但资源占用大）</li></ul><p><strong>最终选择 SwiftUI 的原因</strong>：</p><table><thead><tr><th>方面</th><th>SwiftUI</th><th>AppKit</th><th>Electron</th></tr></thead><tbody><tr><td><strong>学习曲线</strong></td><td>陡峭但现代</td><td>平缓但过时</td><td>中等</td></tr><tr><td><strong>性能</strong></td><td>优秀</td><td>优秀</td><td>一般</td></tr><tr><td><strong>内存占用</strong></td><td>~120MB</td><td>~100MB</td><td>&gt;300MB</td></tr><tr><td><strong>开发效率</strong></td><td>高</td><td>低</td><td>中等</td></tr><tr><td><strong>系统集成</strong></td><td>原生</td><td>原生</td><td>有限</td></tr><tr><td><strong>未来前景</strong></td><td>光明</td><td>维护模式</td><td>稳定</td></tr></tbody></table><p><strong>实际体验</strong>：</p><pre><code class="swift">// SwiftUI 的声明式语法让 UI 开发更直观
struct ClipboardItemView: View {
    @ObservedObject var viewModel: ClipboardViewModel
    
    var body: some View {
        List(viewModel.items) { item in
            HStack {
                Image(systemName: item.icon)
                    .foregroundColor(.blue)
                
                VStack(alignment: .leading) {
                    Text(item.title)
                        .font(.headline)
                    Text(item.preview)
                        .font(.caption)
                        .lineLimit(1)
                        .foregroundColor(.gray)
                }
                
                Spacer()
                
                Button(action: { viewModel.copyItem(item) }) {
                    Image(systemName: "doc.on.doc")
                }
                .buttonStyle(.borderless)
            }
        }
    }
}</code></pre><h3>核心功能开发</h3><h4>1. 剪贴板监控</h4><p><strong>最大挑战</strong>：如何高效地监控系统剪贴板变化？</p><p><strong>初期方案（失败）</strong>：</p><pre><code class="swift">// ❌ 不推荐：轮询间隔过短，CPU 占用高
Timer.scheduledTimer(withTimeInterval: 0.01, repeats: true) { _ in
    let newContent = NSPasteboard.general.string(forType: .string)
    // 处理新内容
}</code></pre><p><strong>问题</strong>：</p><ul><li>CPU 占用率达到 70-100%</li><li>电池消耗快</li><li>系统响应变慢</li></ul><p><strong>改进方案（成功）</strong>：</p><pre><code class="swift">// ✅ 推荐：使用 changeCount 检测变化
class ClipboardMonitor {
    private var lastChangeCount = 0
    private var monitoringTimer: Timer?
    
    func startMonitoring() {
        monitoringTimer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { [weak self] _ in
            let currentCount = NSPasteboard.general.changeCount
            
            if currentCount != self?.lastChangeCount {
                self?.lastChangeCount = currentCount
                self?.handleClipboardChange()
            }
        }
    }
    
    private func handleClipboardChange() {
        // 只在检测到变化时处理
        // CPU 占用降低到 &lt; 1%
    }
}</code></pre><p><strong>性能对比</strong>：</p><table><thead><tr><th>方案</th><th>CPU 占用</th><th>内存</th><th>响应延迟</th></tr></thead><tbody><tr><td>0.01s 轮询</td><td>15-20%</td><td>150MB</td><td>&lt; 10ms</td></tr><tr><td>changeCount</td><td>&lt; 1%</td><td>120MB</td><td>100-200ms</td></tr><tr><td><strong>改进</strong></td><td><strong>降低 95%</strong></td><td><strong>降低 20%</strong></td><td><strong>可接受</strong></td></tr></tbody></table><h4>2. 全局快捷键实现</h4><p><strong>需求</strong>：在任何应用中按 <code>Cmd+Option+V</code> 快速呼出 OneClip</p><p><strong>技术选择</strong>：Carbon Framework（虽然老旧但稳定）</p><p><strong>实现代码</strong>：</p><pre><code class="swift">import Carbon

class HotkeyManager {
    private var hotkeyRef: EventHotKeyRef?
    private let hotkeyID = EventHotKeyID(signature: OSType(UInt32(0x4F4E4543)), id: 1)
    
    func registerHotkey(keyCode: UInt32, modifiers: UInt32) {
        var ref: EventHotKeyRef?
        
        let status = RegisterEventHotKey(
            keyCode,
            modifiers,
            hotkeyID,
            GetApplicationEventTarget(),
            0,
            &amp;ref
        )
        
        if status == noErr {
            hotkeyRef = ref
            print("✅ 快捷键注册成功")
        } else {
            print("❌ 快捷键注册失败: \(status)")
        }
    }
    
    func unregisterHotkey() {
        if let ref = hotkeyRef {
            UnregisterEventHotKey(ref)
        }
    }
}

// 快捷键码对照表
let HOTKEY_CODES = [
    "V": 9,           // V 键
    "R": 15,          // R 键
    "C": 8,           // C 键
    "D": 2,           // D 键
]

let MODIFIER_KEYS = [
    "cmd": UInt32(cmdKey),           // Command
    "option": UInt32(optionKey),     // Option
    "shift": UInt32(shiftKey),       // Shift
    "control": UInt32(controlKey),   // Control
]</code></pre><p><strong>遇到的问题</strong>：</p><ol><li><p><strong>快捷键冲突</strong>：某些应用也使用相同快捷键</p><ul><li>解决：提供快捷键自定义功能</li><li>添加冲突检测机制</li></ul></li><li><p><strong>权限问题</strong>：需要辅助功能权限</p><ul><li>解决：首次启动时提示用户授权</li></ul></li><li><p><strong>系统更新兼容性</strong>：macOS 版本差异</p><ul><li>解决：兼容 macOS 12+</li></ul></li></ol><h4>3. 数据持久化</h4><p><strong>选择 SQLite 而不是 Core Data</strong>：</p><p>OneClip 使用原生 SQLite 而非 Core Data，原因：</p><ul><li>更轻量，启动更快</li><li>更灵活的查询控制</li><li>更容易进行数据迁移</li></ul><pre><code class="swift">// SQLite 数据库封装
class ClipboardDatabase {
    private var db: OpaquePointer?
    
    init(at path: String) throws {
        // 打开数据库连接
        guard sqlite3_open(path, &amp;db) == SQLITE_OK else {
            throw ClipboardError.databaseNotReady
        }
        
        // 创建表结构
        try createTables()
    }
    
    // 保存项目
    func saveItem(_ item: ClipboardItem) throws {
        let sql = """
            INSERT OR REPLACE INTO clipboard_items 
            (id, content, type, timestamp, source_app, is_favorite, is_pinned, content_hash)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        """
        // 执行 SQL
    }
    
    // 加载最近项目
    func loadHotData(limit: Int) throws -&gt; [ClipboardItem] {
        let sql = "SELECT * FROM clipboard_items ORDER BY timestamp DESC LIMIT ?"
        // 执行查询并返回结果
    }
}</code></pre><p><strong>性能优化</strong>：</p><pre><code class="swift">// 使用索引加速查询
func createTables() throws {
    let sql = """
        CREATE TABLE IF NOT EXISTS clipboard_items (
            id TEXT PRIMARY KEY,
            content TEXT,
            type TEXT NOT NULL,
            timestamp REAL NOT NULL,
            source_app TEXT,
            is_favorite INTEGER DEFAULT 0,
            is_pinned INTEGER DEFAULT 0,
            content_hash TEXT
        );
        CREATE INDEX IF NOT EXISTS idx_timestamp ON clipboard_items(timestamp DESC);
        CREATE INDEX IF NOT EXISTS idx_content_hash ON clipboard_items(content_hash);
    """
    // 执行 SQL
}

// 使用哈希索引快速去重 - O(1) 时间复杂度
func findItemByHash(_ hash: String) -&gt; UUID? {
    let sql = "SELECT id FROM clipboard_items WHERE content_hash = ? LIMIT 1"
    // 执行查询
}</code></pre><h3>常见问题与解决方案</h3><h4>问题 1：应用启动时权限提示过多</h4><p><strong>现象</strong>：用户首次启动应用，被要求授予多个权限</p><p><strong>解决方案</strong>：</p><pre><code class="swift">class PermissionManager {
    func requestPermissionsSequentially() {
        // 按优先级顺序请求权限
        requestAccessibilityPermission { [weak self] granted in
            if granted {
                self?.requestDiskAccessPermission()
            }
        }
    }
    
    private func requestAccessibilityPermission(completion: @escaping (Bool) -&gt; Void) {
        let options: NSDictionary = [kAXTrustedCheckOptionPrompt.takeRetainedValue() as String: true]
        let trusted = AXIsProcessTrustedWithOptions(options)
        completion(trusted)
    }
}</code></pre><h4>问题 2：大数据集下搜索变慢</h4><p><strong>现象</strong>：当历史记录超过 1000 条时，搜索响应延迟明显</p><p><strong>解决方案</strong>：</p><pre><code class="swift">class SearchOptimizer {
    // 搜索防抖
    private var searchDebounceTimer: Timer?
    
    func searchWithDebounce(_ query: String) {
        searchDebounceTimer?.invalidate()
        
        searchDebounceTimer = Timer.scheduledTimer(withTimeInterval: 0.3, repeats: false) { [weak self] _ in
            self?.performSearch(query)
        }
    }
    
    private func performSearch(_ query: String) {
        let predicate = NSPredicate(format: "content CONTAINS[cd] %@", query)
        
        let request = ClipboardItemEntity.fetchRequest()
        request.predicate = predicate
        request.fetchLimit = 50  // 限制结果数
        request.sortDescriptors = [
            NSSortDescriptor(keyPath: \ClipboardItemEntity.timestamp, ascending: false)
        ]
        
        DispatchQueue.global(qos: .userInitiated).async {
            let results = try? self.container.viewContext.fetch(request)
            DispatchQueue.main.async {
                self.updateSearchResults(results ?? [])
            }
        }
    }
}</code></pre><h4>问题 3：内存泄漏</h4><p><strong>现象</strong>：长时间运行后内存占用不断增加</p><p><strong>排查过程</strong>：</p><pre><code class="swift">// 使用 Instruments 检测内存泄漏
// 1. 在 Xcode 中运行 Product &gt; Profile
// 2. 选择 Leaks 工具
// 3. 运行应用并进行操作
// 4. 查看泄漏的对象

// 常见泄漏原因：
// ❌ 循环引用
class ClipboardManager {
    var timer: Timer?
    
    func startMonitoring() {
        // ❌ 错误：self 被 timer 强引用，timer 被 self 强引用
        timer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { _ in
            self.checkClipboard()
        }
    }
}

// ✅ 正确：使用 [weak self]
func startMonitoring() {
    timer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { [weak self] _ in
        self?.checkClipboard()
    }
}</code></pre><h4>问题 4：图片处理导致 UI 卡顿</h4><p><strong>现象</strong>：粘贴大图片时，UI 出现明显延迟</p><p><strong>解决方案</strong>：</p><pre><code class="swift">class ImageProcessor {
    // 在后台线程处理图片
    func processImage(_ image: NSImage, completion: @escaping (NSImage) -&gt; Void) {
        DispatchQueue.global(qos: .userInitiated).async {
            // 生成缩略图
            let thumbnail = self.generateThumbnail(image, size: CGSize(width: 200, height: 200))
            
            // 压缩图片
            let compressed = self.compressImage(image, quality: 0.7)
            
            DispatchQueue.main.async {
                completion(thumbnail)
            }
        }
    }
    
    private func generateThumbnail(_ image: NSImage, size: CGSize) -&gt; NSImage {
        let thumbnail = NSImage(size: size)
        thumbnail.lockFocus()
        image.draw(in: NSRect(origin: .zero, size: size))
        thumbnail.unlockFocus()
        return thumbnail
    }
    
    private func compressImage(_ image: NSImage, quality: CGFloat) -&gt; Data? {
        guard let tiffData = image.tiffRepresentation,
              let bitmapImage = NSBitmapImageRep(data: tiffData) else {
            return nil
        }
        
        return bitmapImage.representation(using: .jpeg, properties: [.compressionFactor: quality])
    }
}</code></pre><h3>性能优化实战</h3><h4>优化前后对比</h4><p><strong>优化前</strong>：</p><pre><code>启动时间：3.5 秒
内存占用：250MB
CPU 使用：8-12%
搜索延迟：500-800ms</code></pre><p><strong>优化后</strong>：</p><pre><code>启动时间：0.8 秒 ⬇️ 77%
内存占用：120MB ⬇️ 52%
CPU 使用：&lt; 1% ⬇️ 90%
搜索延迟：100-200ms ⬇️ 75%</code></pre><p><strong>关键优化</strong>：</p><ol><li><strong>延迟加载</strong>：只加载可见的列表项</li><li><strong>图片压缩</strong>：自动压缩大图片</li><li><strong>后台处理</strong>：将耗时操作移到后台线程</li><li><strong>缓存策略</strong>：缓存常用数据</li><li><strong>数据库索引</strong>：为频繁查询的字段建立索引</li></ol><h3>测试与调试</h3><h4>单元测试示例</h4><pre><code class="swift">import XCTest

class ClipboardManagerTests: XCTestCase {
    var manager: ClipboardManager!
    
    override func setUp() {
        super.setUp()
        manager = ClipboardManager()
    }
    
    func testClipboardMonitoring() {
        let expectation = XCTestExpectation(description: "Clipboard change detected")
        
        manager.onClipboardChange = {
            expectation.fulfill()
        }
        
        manager.startMonitoring()
        
        // 模拟剪贴板变化
        NSPasteboard.general.clearContents()
        NSPasteboard.general.setString("Test content", forType: .string)
        
        wait(for: [expectation], timeout: 1.0)
        
        manager.stopMonitoring()
    }
    
    func testContentProcessing() {
        let content = "# Test\n\nSome content"
        let processed = manager.processContent(content)
        
        XCTAssertEqual(processed.type, .text)
        XCTAssertTrue(processed.content.contains("Test"))
    }
}</code></pre><h4>调试技巧</h4><pre><code class="swift">// 1. 使用 os_log 记录关键信息
import os

let logger = Logger(subsystem: "com.oneclip.app", category: "clipboard")

logger.info("Clipboard content changed: \(content)")
logger.error("Failed to save item: \(error.localizedDescription)")

// 2. 在 Xcode 控制台查看日志
// 3. 使用 Console.app 查看系统日志
// 4. 使用 Instruments 进行性能分析</code></pre><h3>发布与更新</h3><h4>使用 Sparkle 实现自动更新</h4><pre><code class="swift">class UpdateManager: NSObject, SPUUpdaterDelegate {
    let updater: SPUUpdater
    
    override init() {
        let hostBundle = Bundle.main
        let updateDriver = SPUStandardUpdaterController(
            hostBundle: hostBundle,
            applicationBundle: hostBundle,
            userDriver: SPUStandardUserDriver(hostBundle: hostBundle),
            delegate: nil
        )
        
        self.updater = updateDriver.updater
        super.init()
        
        updater.delegate = self
    }
    
    func startUpdater() {
        updater.startUpdater()
    }
}</code></pre><h3>最佳实践总结</h3><h4>开发阶段</h4><ul><li>✅ 使用 SwiftUI 进行 UI 开发</li><li>✅ 采用 MVVM 架构</li><li>✅ 及早进行性能测试</li><li>✅ 编写单元测试</li><li>✅ 使用 Instruments 检测内存泄漏</li></ul><h4>功能实现</h4><ul><li>✅ 后台线程处理耗时操作</li><li>✅ 使用 [weak self] 避免循环引用</li><li>✅ 实现错误处理和日志记录</li><li>✅ 提供用户友好的权限提示</li></ul><h4>性能优化</h4><ul><li>✅ 监控频率自适应</li><li>✅ 数据库查询优化</li><li>✅ 图片压缩存储</li><li>✅ 内存管理和缓存策略</li></ul><h4>发布与维护</h4><ul><li>✅ 使用 Sparkle 实现自动更新</li><li>✅ 收集用户反馈</li><li>✅ 定期发布更新</li><li>✅ 维护变更日志</li></ul><h3>总结</h3><p>OneClip 的开发过程充满了挑战和学习。通过不断的优化和改进，我们打造了一款高效、稳定、用户友好的 macOS 应用。</p><p><strong>关键收获</strong>：</p><ol><li>选择合适的技术栈很重要</li><li>性能优化需要持续关注</li><li>用户体验至关重要</li><li>社区反馈推动产品进步</li></ol><p>如果你正在开发 macOS 应用，希望这些经验能对你有所帮助。欢迎在 <a href="https://link.segmentfault.com/?enc=8%2FiGS%2FQplD%2B8TeTDl%2FMVIw%3D%3D.xbdt8%2BlUEALE9zhHnjvkYTj0Y8QL3OlzPxvnYmlLzbmbxxUJ4QEV2HS%2Fw8TVWvpb" rel="nofollow" target="_blank">GitHub Discussions</a> 中分享你的经验和问题！</p>]]></description></item><item>    <title><![CDATA[@cs-open/react-fabric —— 被 Fabric.js 官方推荐的 React 最]]></title>    <link>https://segmentfault.com/a/1190000047570354</link>    <guid>https://segmentfault.com/a/1190000047570354</guid>    <pubDate>2026-01-25 22:07:56</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在 React 项目中处理复杂的 Canvas 交互，一直是让开发者头疼的难题。原生 Fabric.js 虽然强大，但在 React 的声明式编程模型下，手动管理对象生命周期、同步状态和处理事件流往往会导致代码碎片化。</p><p>今天，我们要重点推荐一个合合信息开源黑马项目：<strong><a href="https://link.segmentfault.com/?enc=hpWO%2F6xFk%2FsVDQ%2FEpr%2F8Uw%3D%3D.6%2FyhhuAr%2BwT9FVqC75LpBjBJaBECODxYgknyj1%2B1xppjb6%2Boc2alBFxk9ntASR5C" rel="nofollow" target="_blank">@cs-open/react-fabric</a></strong></p><h3>🌟 官方背书，血统纯正</h3><p><code>react-fabric</code> 的优秀并非自吹自擂。它已经正式被 <strong>Fabric.js 官方资源库（Fabric.js Resources）</strong> 收录并向全球开发者推荐。</p><blockquote><p>🔗 <strong>官方推荐链接</strong>：<a href="https://link.segmentfault.com/?enc=Xer6agqNzhpoWesLDQ1Sxg%3D%3D.o1Zo5%2F8eh4wunoroSwtpbDrNZT248H5wiLAK0UyXfpk%3D" rel="nofollow" target="_blank">fabricjs.com/resources</a></p><p>在 Resources 页面中，你可以清楚地看到 <code>@cs-open/react-fabric</code> 作为高扩展性、复合型 React 封装库被列在显著位置。</p></blockquote><h3>🚀 AI 时代的宠儿：Cursor 评价第一</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047570357" alt="react-fabric.webp" title="react-fabric.webp"/></p><p>在 AI 辅助编程领域，<code>react-fabric</code> 同样表现抢眼。根据开发者反馈和相关社区图片描述，该库在 <strong>Cursor (AI Code Editor)</strong> 的相关 React Canvas 库评价中位居<strong>第一</strong>。</p><p>这意味着，当你使用 Cursor 进行代码补全或咨询绘图方案时，<code>react-fabric</code> 的结构化设计和类型完备性，使其成为了 AI 最推荐、生成代码最稳健的选择。</p><h3>💎 核心优势：不仅仅是 Demo</h3><p>很多开源库停留在“实验性”阶段，但 <code>react-fabric</code> 不同：</p><ol><li><strong>工业级稳定性</strong>：这<strong>不是</strong>一个简单的 Demo 项目！它目前正深度应用于<strong>大型商业项目</strong>中，经历了高并发、复杂场景的实战考验。</li><li><strong>严苛测试保障</strong>：项目已经由专业测试人员进行了<strong>全方位的完善测试</strong>，包括性能压力测试、边界条件测试以及多端兼容性测试。</li><li><strong>高度可扩展</strong>：采用复合样式（Composite style）设计，让你可以像写 React 组件一样组合复杂的 Canvas 元素，同时保留了直接操作底层 Fabric 实例的能力。</li></ol><h3>🏗️ 真实落地案例</h3><p>该项目已在<strong>蜜蜂教育</strong>等大型教育科技平台中稳定运行。在教育场景这类对交互绘图、课件批注有极高要求的领域，<code>react-fabric</code> 展现了卓越的可靠性。</p><ul><li><strong>官方应用参考</strong>：<a href="https://link.segmentfault.com/?enc=gnwBuU3zvC5hJib8Ba2nEQ%3D%3D.2IE%2BsFUZ2bxPT%2Br94tnu74fN%2BKRQBLIXJ3wCT2SeUbM%3D" rel="nofollow" target="_blank">www.mifengjiaoyu.com</a></li></ul><hr/><h3>🛠️ 如何开始？</h3><p>如果你正在寻找一个高性能、类型友好且能直接用于生产环境的 React Canvas 解决方案，请认准 <code>react-fabric</code>。</p><ul><li><strong>GitHub 地址</strong>：<a href="https://link.segmentfault.com/?enc=KE9pdgiUI6wIh0gIlUbRVg%3D%3D.EVQUQEDsaMLGGX%2Bo%2FGKgGWHwBEKidcKNx5sCDGxHZc7L5D4YGIpcEw5TIHO6w7NI" rel="nofollow" target="_blank">github.com/cs-open/react-fabric</a></li><li><strong>demo 地址</strong>：<a href="https://link.segmentfault.com/?enc=LtMhbRXnu%2BmALG60Dyqjdw%3D%3D.K5W%2Fj9IxcSXcQPD6RBooVL2moCSqQgpoj2RpL7hXqusBFWogDynDIvfJSF9h78W2" rel="nofollow" target="_blank">https://cs-open.github.io/react-fabric/</a></li><li><p><strong>安装命令</strong>：</p><p>Bash</p><pre><code>npm install @cs-open/react-fabric
# 或
yarn add @cs-open/react-fabric
</code></pre></li></ul><hr/><p>&lt;div id="chinese"&gt;</p><h2>✨ 核心特性</h2><h3>🎯 丰富的图形组件</h3><ul><li><strong>基础图形</strong>: 矩形、圆形、椭圆、线条、多边形、路径</li><li><strong>文本组件</strong>: 文本、可编辑文本、文本框</li><li><strong>图像组件</strong>: 背景图片、普通图片</li><li><strong>组合组件</strong>: 分组、对象集合</li><li><strong>自定义控件</strong>: 可拖拽控制点、工具栏</li></ul><h3>🖱️ 强大的交互功能</h3><ul><li><strong>自动缩放</strong>: 支持鼠标滚轮缩放，自动适应容器大小</li><li><strong>平移操作</strong>: 支持拖拽平移画布视图</li><li><strong>触摸支持</strong>: 完整的触摸设备支持，包括双指缩放和拖拽</li><li><strong>选择系统</strong>: 多选、框选、键盘快捷键支持</li><li><strong>拖拽操作</strong>: 对象拖拽、批量操作</li></ul><h3>📦 响应式设计</h3><ul><li><strong>自动适配</strong>: 画布自动撑满父容器，响应式调整</li><li><strong>触摸优化</strong>: 专为移动设备优化的触摸交互</li><li><strong>跨平台</strong>: 支持桌面端和移动端浏览器</li></ul><h3>💻 开发者友好</h3><ul><li><strong>TypeScript</strong>: 完整的 TypeScript 类型支持</li><li><strong>React 风格</strong>: 声明式 API，符合 React 开发习惯</li><li><strong>事件系统</strong>: 完整的事件回调，支持所有 Fabric.js 事件</li><li><strong>状态管理</strong>: 内置状态管理，支持受控和非受控模式</li></ul><h2>✨ 快速开始</h2><h3>安装</h3><pre><code class="bash">npm install @cs-open/react-fabric
# 或者
yarn add @cs-open/react-fabric
# 或者
pnpm add @cs-open/react-fabric</code></pre><h3>基础用法</h3><pre><code class="tsx">import React from 'react'
import { ReactFabric, Rect, Text, Circle } from '@cs-open/react-fabric'

function App() {
  return (
    &lt;div style={{ width: '100%', height: '500px' }}&gt;
      &lt;ReactFabric&gt;
        &lt;Rect left={100} top={100} width={200} height={100} fill="red" stroke="blue" strokeWidth={2} /&gt;
        &lt;Circle left={300} top={150} radius={50} fill="green" /&gt;
        &lt;Text left={150} top={250} text="Hello Fabric!" fontSize={20} fill="white" /&gt;
      &lt;/ReactFabric&gt;
    &lt;/div&gt;
  )
}

export default App</code></pre><h2>🎯 核心功能</h2><h3>自动缩放与平移</h3><pre><code class="tsx">import { ReactFabric, useReactFabric } from '@cs-open/react-fabric'

function CanvasWithControls() {
  const { zoomIn, zoomOut, resetViewport, zoom } = useReactFabric()

  return (
    &lt;div&gt;
      &lt;div className="toolbar"&gt;
        &lt;button onClick={zoomIn}&gt;放大&lt;/button&gt;
        &lt;button onClick={zoomOut}&gt;缩小&lt;/button&gt;
        &lt;button onClick={() =&gt; resetViewport()}&gt;重置&lt;/button&gt;
        &lt;span&gt;缩放: {Math.round(zoom * 100)}%&lt;/span&gt;
      &lt;/div&gt;

      &lt;ReactFabric zoomable={true} panAble={true} minManualZoom={0.1} maxManualZoom={5}&gt;
        {/* 你的画布内容 */}
      &lt;/ReactFabric&gt;
    &lt;/div&gt;
  )
}</code></pre><h3>触摸设备支持</h3><pre><code class="tsx">import { ReactFabric, PluginPinch } from '@cs-open/react-fabric'
import { PluginPinch } from '@cs-open/react-fabric/plugins'

function TouchCanvas() {
  return (
    &lt;ReactFabric&gt;
      {/* 你的画布内容 */}
      &lt;PluginPinch /&gt;
    &lt;/ReactFabric&gt;
  )
}</code></pre><h3>背景图片</h3><pre><code class="tsx">import { ReactFabric, BackgroundImage } from '@cs-open/react-fabric'

function CanvasWithBackground() {
  return (
    &lt;ReactFabric defaultCentered&gt;
      &lt;BackgroundImage src="/path/to/image.jpg" scaleToFit /&gt;
      {/* 其他图形元素 */}
    &lt;/ReactFabric&gt;
  )
}</code></pre><h2>🔌 插件系统</h2><h3>内置插件</h3><table><thead><tr><th>插件</th><th>功能</th><th>描述</th></tr></thead><tbody><tr><td><code>PluginPinch</code></td><td>触摸缩放</td><td>支持双指缩放和拖拽操作</td></tr><tr><td><code>PluginFreeDraw</code></td><td>自由绘制</td><td>手绘路径和涂鸦功能</td></tr><tr><td><code>PluginFreeRect</code></td><td>矩形绘制</td><td>交互式矩形绘制工具</td></tr><tr><td><code>PluginFreeText</code></td><td>文本工具</td><td>点击添加可编辑文本</td></tr><tr><td><code>PluginGridLine</code></td><td>网格辅助</td><td>显示网格线辅助对齐</td></tr><tr><td><code>PluginMask</code></td><td>遮罩效果</td><td>创建遮罩和裁剪效果</td></tr></tbody></table><h3>使用插件</h3><pre><code class="tsx">import { ReactFabric } from '@cs-open/react-fabric'
import { PluginPinch, PluginFreeDraw, PluginFreeRect, PluginGridLine } from '@cs-open/react-fabric/plugins'

function AdvancedCanvas() {
  return (
    &lt;ReactFabric&gt;
      {/* 触摸支持 */}
      &lt;PluginPinch /&gt;

      {/* 自由绘制 */}
      &lt;PluginFreeDraw
        onComplete={(path, { canvas }) =&gt; {
          console.log('绘制完成:', path)
        }}
      /&gt;

      {/* 矩形绘制工具 */}
      &lt;PluginFreeRect
        fill={'red'}
        onComplete={(rect, { canvas }) =&gt; {
          console.log('矩形绘制完成:', rect)
        }}
      /&gt;

      {/* 网格线 */}
      &lt;PluginGridLine /&gt;
    &lt;/ReactFabric&gt;
  )
}</code></pre><h2>📦 组件 API</h2><h3>ReactFabric 组件</h3><p>主要的画布容器组件，支持以下属性：</p><pre><code class="tsx">interface ReactFabricProps {
  // 基础属性
  width?: number
  height?: number
  className?: string
  style?: CSSProperties

  // 交互控制
  zoomable?: boolean // 是否可缩放
  panAble?: boolean // 是否可平移
  selection?: boolean // 是否可选择
  defaultSelection?: boolean // 默认选择状态
  defaultDraggable?: boolean // 默认拖拽状态

  // 缩放控制
  manualZoom?: number // 手动缩放倍数
  minManualZoom?: number // 最小缩放倍数
  maxManualZoom?: number // 最大缩放倍数
  defaultCentered?: boolean // 背景图是否居中

  // 事件回调
  onMouseDown?: (e: FabricPublicEvent) =&gt; void
  onMouseMove?: (e: FabricPublicEvent) =&gt; void
  onMouseUp?: (e: FabricPublicEvent) =&gt; void
  onMouseWheel?: (e: FabricPublicEvent) =&gt; void
}</code></pre><h3>图形组件</h3><p>所有图形组件都支持对应的 Fabric.js 对象的所有属性和事件：</p><pre><code class="tsx">// 矩形
&lt;Rect
  left={100}
  top={100}
  width={200}
  height={100}
  fill="red"
  stroke="blue"
  strokeWidth={2}
  onModified={(e) =&gt; console.log('矩形被修改', e.target)}
/&gt;

// 圆形
&lt;Circle
  left={200}
  top={200}
  radius={50}
  fill="green"
  onSelected={() =&gt; console.log('圆形被选中')}
/&gt;

// 文本
&lt;Text
  left={100}
  top={300}
  text="Hello World"
  fontSize={24}
  fill="black"
  fontFamily="Arial"
/&gt;

// 图片
&lt;Image
  left={300}
  top={300}
  src="/path/to/image.jpg"
  width={200}
  height={150}
/&gt;</code></pre><h2>🎮 状态管理</h2><h3>useReactFabric Hook</h3><pre><code class="tsx">import { useReactFabric } from '@cs-open/react-fabric'

function Toolbar() {
  const {
    // 状态
    canvas,
    zoom,
    manualZoom,
    isDragging,
    selection,

    // 方法
    zoomIn,
    zoomOut,
    resetViewport,
    setZoomable,
    setSelection,
    setDraggable,
  } = useReactFabric()

  return (
    &lt;div className="toolbar"&gt;
      &lt;button onClick={zoomIn}&gt;放大&lt;/button&gt;
      &lt;button onClick={zoomOut}&gt;缩小&lt;/button&gt;
      &lt;button onClick={() =&gt; resetViewport()}&gt;重置&lt;/button&gt;
      &lt;span&gt;缩放: {Math.round(zoom * 100)}%&lt;/span&gt;
    &lt;/div&gt;
  )
}</code></pre><h3>跨组件状态访问</h3><p>ReactFabricProvider 是一个上下文提供程序，允许您从组件树中的任何位置访问流的内部状态，例如子组件，甚至在 ReactFabric 之外 元件。它通常用于应用程序的顶层。<br/>在这种情况下，您可能需要使用 ReactFabricProvider 组件</p><pre><code class="tsx">import { ReactFabricProvider, useReactFabric } from '@cs-open/react-fabric'

function App() {
  return (
    &lt;ReactFabricProvider&gt;
      &lt;Toolbar /&gt;
      &lt;ReactFabric&gt;{/* 画布内容 */}&lt;/ReactFabric&gt;
    &lt;/ReactFabricProvider&gt;
  )
}

function Toolbar() {
  const { zoomIn, zoomOut, resetViewport } = useReactFabric()
  // 可以在 ReactFabric 外部访问状态
}</code></pre><h2>🎨 高级用法</h2><h3>受控模式</h3><pre><code class="tsx">import { useState } from 'react'
import { ReactFabric, Rect } from '@cs-open/react-fabric'

function ControlledCanvas() {
  const [rect, setRect] = useState({
    left: 100,
    top: 100,
    width: 200,
    height: 100,
    fill: 'red',
  })

  return (
    &lt;ReactFabric&gt;
      &lt;Rect {...rect} onModified={e =&gt; setRect(e.target)} /&gt;
    &lt;/ReactFabric&gt;
  )
}</code></pre><h3>非受控模式</h3><pre><code class="tsx">import { ReactFabric, Rect, Group } from '@cs-open/react-fabric'

function UncontrolledCanvas() {
  return (
    &lt;ReactFabric&gt;
      &lt;Group&gt;
        &lt;Rect defaultLeft={100} defaultTop={100} defaultWidth={100} defaultHeight={100} fill="blue" /&gt;
      &lt;/Group&gt;
    &lt;/ReactFabric&gt;
  )
}</code></pre><h3>DOM 集成</h3><p>结合 floating-ui 可以轻松实现 dom 控件</p><pre><code class="tsx">import { ReactFabric, Rect } from '@cs-open/react-fabric'

function CanvasWithDOM() {
  return (
    &lt;ReactFabric&gt;
      &lt;Rect left={100} top={100} width={200} height={100}&gt;
        &lt;div className="tooltip"&gt;这是一个提示框&lt;/div&gt;
      &lt;/Rect&gt;
    &lt;/ReactFabric&gt;
  )
}</code></pre><hr/><p><strong>结语</strong>：</p><p>选对工具，开发效率提升 200%。既然 Fabric.js 官方已经帮你选好了，Cursor 评价也拿了第一，还有大型项目背书，你还在犹豫什么？赶快在你的下一个项目中尝试 <code>react-fabric</code> 吧！</p>]]></description></item><item>    <title><![CDATA[『NAS』推荐几个绿联 NAS Docker 能用的镜像加速器 德育处主任 ]]></title>    <link>https://segmentfault.com/a/1190000047570653</link>    <guid>https://segmentfault.com/a/1190000047570653</guid>    <pubDate>2026-01-25 22:07:19</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><strong>点赞 + 关注 + 收藏 = 学会了</strong></p><blockquote>整理了一个NAS小专栏，有兴趣的工友可以关注一下 👉 <a href="https://link.segmentfault.com/?enc=mh1MmChxHhAwIfEKDd5m4g%3D%3D.y7y37uBa6CmnFxZC6Kby5gQ3TJIJPuTymyxJLJjKsEBY4IHt2F1hiO1lOL1KFtgdeIvIVanFapPoPlKvCjgdNqtaQ9wSDBAz%2B4w%2FF1e%2B3PxUl5jZ1NP98Ns1QbBFdPKvE53ZNNShFv8lCIjS0Pdgg84TXIhct7EBLZrAVkLJjCU%3D" rel="nofollow" target="_blank">《NAS邪修》</a></blockquote><p>买 NAS 不玩 Docker 乐趣少一半。</p><p>但 Docker 的镜像（简单理解为软件安装包吧）是放在国外服务器保存的，我们要下载这些镜像全凭运气。</p><p>绿联 NAS 虽然推荐了一个加速器（<code>https://docker.1ms.run</code>），但有些镜像还是搜到下载不到。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047570655" alt="" title=""/></p><p>比如 <code>memos</code> 这款高颜值的笔记工具，我下载了几次都失败了。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047570656" alt="" title="" loading="lazy"/></p><p>先别急删掉 Docker，我们多配置几个镜像加速器就可以了。</p><p>绿联 NAS 的 Docker 镜像加速器配置方法很简单。</p><p>打开 Docker，切换到「镜像」页面，点击右上角的“齿轮”按钮。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047570657" alt="" title="" loading="lazy"/></p><p>在「镜像仓库」这里，点击下图箭头所指的「加速器配置」按钮。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047570658" alt="" title="" loading="lazy"/></p><p>把这堆地址都填进去，点击「确定」按钮就行了～</p><ul><li><a href="https://link.segmentfault.com/?enc=5JSK0fYmus3ZTjQc0lZYtA%3D%3D.fFR1WsxN8no%2Bu33Th5q20VMY4wsctLLi9186Bh3Zmbk%3D" rel="nofollow" target="_blank">https://docker.1ms.run</a></li><li><a href="https://link.segmentfault.com/?enc=pDZlDar3hn%2Fs8d54%2FuKGyA%3D%3D.%2BbrkuUmzFKNYU8EHXqiM8ODLaUe14DAz9wjiY1uVqiw%3D" rel="nofollow" target="_blank">https://docker.ketches.cn</a></li><li><a href="https://link.segmentfault.com/?enc=v0echRL4ZbzVhcFBuqdmlA%3D%3D.LJQYbQ%2BQANfvQfD7eq%2Bn3imolbNB8WVWgWMlP62Vi3A%3D" rel="nofollow" target="_blank">https://docker.m.daocloud.io</a></li><li><a href="https://link.segmentfault.com/?enc=sE5jyAdvyN5GZtBErYY5dg%3D%3D.SdiUVYAr1jEOGBTpBPdsW9nqjU8NQtxdtOzr05mmlj0%3D" rel="nofollow" target="_blank">https://docker.xuanyuan.me</a></li><li><a href="https://link.segmentfault.com/?enc=Vv38MUR82lCChkPS261vBw%3D%3D.Z4PvzJWMkYgZpi3LXckYJhiZOuRTdNn4zDeaGdMrQao%3D" rel="nofollow" target="_blank">https://docker.1panel.live</a></li><li><a href="https://link.segmentfault.com/?enc=DcNe%2Fl3vmz1ovYTGkZ4MrQ%3D%3D.j4wOmj1s58Odp8lZrq13zrJp0j%2B2Rx4K8txPxwSdDHM%3D" rel="nofollow" target="_blank">https://dockerproxy.com</a></li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047570659" alt="" title="" loading="lazy"/></p><p>回到「镜像」面板，搜索你想安装的镜像就能下载了。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047570660" alt="" title="" loading="lazy"/></p><hr/><p>以上就是本文的全部内容啦，想了解更多NAS玩法可以关注<a href="https://link.segmentfault.com/?enc=O3zwSs5sXQaTrDvo6Xncsw%3D%3D.0jxkytoPfiz6k1NxjJly%2BpZR7qXXW25cI%2FHRF9ewgGLnJ6db9hqJjVm2FwEY993GjFEwbKzkbb3CX3Mwu9NFAOhlQdP3UHFeiaLumsRomXeOBkMyjQDnL5a7utgQr0kgTV0gnBRzf5nWlEWAVSfBWYbSaZTaWeP%2FxrPLRUU5u60%3D" rel="nofollow" target="_blank">《NAS邪修》👏</a></p><p>最后推荐一下玩 NAS 的工友，在 NAS 上装一个 n8n 接入大模型，可以帮你定时定候完成各种工作，比如签到啦、写文章啦、生成海报和视频啦、自动发布到各大平台啦～</p><p>想了解 n8n 的工友可以关注我的专栏👉 <a href="https://link.segmentfault.com/?enc=Nt%2Bp%2Bw7xt6as4iE7iIt8BA%3D%3D.4n9vAkJILJrCoYtqKq5x4FHbvuXxlHgKcnLP%2FNOBRtgbWAkJDVsxjU1TeEQMollWDCKt1jorwQQR2KYvLq91MqLHuBLGWur4y7o5YdCyDP8X9Nodyc0njwfQ3GL%2BSpWjZWlNHtaz6Aq7W%2FMFUXvx9IVSnJR75OXmfCzJzdneHeg%3D" rel="nofollow" target="_blank">《n8n修炼手册》</a></p><p><strong>点赞 + 关注 + 收藏 = 学会了</strong></p>]]></description></item><item>    <title><![CDATA[生产力翻倍！16 款必备 VS Code 插件让你的开发效率起飞 李小白 ]]></title>    <link>https://segmentfault.com/a/1190000047570669</link>    <guid>https://segmentfault.com/a/1190000047570669</guid>    <pubDate>2026-01-25 22:06:36</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <blockquote>每天在 VS Code 里敲代码的你，真的把这个编辑器的潜力发挥到极致了吗？同样的工作，为什么别人的开发速度总是比你快？答案可能就在这些插件里。今天，我整理了 16 款亲测好用的 VS Code 插件，涵盖代码编辑、版本控制、智能提示等多个维度，帮你从"普通开发者"进化为"高效战士"！</blockquote><hr/><h2>📋 目录</h2><ul><li><a href="#为什么需要安装插件" target="_blank">为什么需要安装插件？</a></li><li><a href="#一代码编辑与格式化类" target="_blank">一、代码编辑与格式化类</a></li><li><a href="#二代码片段与智能提示类" target="_blank">二、代码片段与智能提示类</a></li><li><a href="#三git-版本控制类" target="_blank">三、Git 版本控制类</a></li><li><a href="#四开发工具与预览类" target="_blank">四、开发工具与预览类</a></li><li><a href="#五辅助工具类" target="_blank">五、辅助工具类</a></li><li><a href="#安装方式" target="_blank">安装方式</a></li><li><h2><a href="#总结" target="_blank">总结</a></h2></li></ul><h2>为什么需要安装插件？</h2><p>VS Code 本身已经非常强大，但它的真正魅力在于<strong>插件生态系统</strong>。通过安装合适的插件，你可以：</p><table><thead><tr><th align="left">能力提升</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">⚡ <strong>编码速度</strong></td><td align="left">智能提示、代码片段自动补全</td></tr><tr><td align="left">🎨 <strong>代码质量</strong></td><td align="left">自动格式化、语法检查、拼写检查</td></tr><tr><td align="left">🔍 <strong>代码导航</strong></td><td align="left">快速跳转、书签标记、Git 历史追踪</td></tr><tr><td align="left">👁️ <strong>实时预览</strong></td><td align="left">前端页面、SVG 图片即时查看</td></tr><tr><td align="left">🌈 <strong>视觉体验</strong></td><td align="left">彩色缩进、精美图标让编辑更愉悦</td></tr></tbody></table><hr/><h2>一、代码编辑与格式化类</h2><h3>1. 🎨 EditorConfig for VS Code</h3><p><strong>作用</strong>：统一不同编辑器和操作系统的代码风格（缩进、换行符等）。<br/><strong>使用场景</strong>：<br/>团队协作时，有人用 Windows 有人用 Mac，有人喜欢 Tab 缩进有人喜欢空格，导致代码风格混乱。EditorConfig 让所有人遵循同一套规则。<br/><strong>核心配置</strong>：<br/>在项目根目录创建 <code>.editorconfig</code> 文件：</p><pre><code class="ini">root = true
[*]
charset = utf-8
indent_style = space
indent_size = 2
end_of_line = lf
insert_final_newline = true
trim_trailing_whitespace = true</code></pre><blockquote>💡 <strong>安装后自动生效</strong>，无需额外配置。</blockquote><hr/><h3>2. ✨ Prettier - Code formatter</h3><p><strong>作用</strong>：一键美化代码，统一格式（单双引号、分号、缩进等）。<br/><strong>使用场景</strong>：<br/>写完代码后，格式乱糟糟？一键 <code>Shift + Alt + F</code>（Windows）或 <code>Shift + Option + F</code>（Mac），瞬间变整齐。<br/><strong>核心优势</strong>：</p><ul><li>支持 JavaScript、TypeScript、CSS、SCSS、JSON 等多种语言</li><li>可保存时自动格式化</li><li><p>团队风格统一，消灭"格式圣战"<br/><strong>配置示例</strong>（<code>.prettierrc</code>）：</p><pre><code class="json">{
"printWidth": 100,
"tabWidth": 2,
"singleQuote": true,
"semi": true,
"trailingComma": "es5"
}</code></pre><hr/><h3>3. 🔍 ESLint</h3><p><strong>作用</strong>：JavaScript/TypeScript 代码质量检查，发现潜在错误。<br/><strong>使用场景</strong>：</p></li><li>忘记声明变量</li><li>使用了未定义的函数</li><li>React Hooks 使用违规</li><li>不建议的语法写法<br/><strong>功能亮点</strong>：</li><li>实时在代码中显示错误和警告</li><li>提供自动修复建议</li><li><p>支持 React、Vue、TypeScript 等框架</p><blockquote>⚠️ <strong>建议配合 Prettier 使用</strong>：ESLint 管质量，Prettier 管颜值。</blockquote><hr/><h3>4. 🎭 Stylelint</h3><p><strong>作用</strong>：CSS/SCSS/Less 样式代码检查与自动修复。<br/><strong>使用场景</strong>：</p></li><li>CSS 冗余代码（重复定义）</li><li>颜色格式不统一</li><li>选择器写法不规范</li><li><p>SCSS 语法错误<br/><strong>配置示例</strong>（<code>.stylelintrc.json</code>）：</p><pre><code class="json">{
"extends": ["stylelint-config-standard"],
"rules": {
  "selector-class-pattern": null
}
}</code></pre><hr/><h3>5. 🌈 indent-rainbow</h3><p><strong>作用</strong>：让缩进层级显示为彩色，像彩虹一样。<br/><strong>使用场景</strong>：</p></li><li>长嵌套代码快速识别层级</li><li>避免缩进错误（多空格或少空格）</li><li><p>代码阅读更愉悦<br/><strong>效果预览</strong>：</p><pre><code class="javascript">function example() {
if (true) {        // 红色缩进
  const arr = [   // 绿色缩进
    1,             // 蓝色缩进
    2,
    3
  ];
}
}</code></pre><blockquote>🎯 <strong>小技巧</strong>：适合初学者识别代码块边界，老手可选择性安装。</blockquote><hr/><h2>二、代码片段与智能提示类</h2><h3>6. ⚡ ES7+ React/Redux/React-Native snippets</h3><p><strong>作用</strong>：提供 React 常用代码片段的快速输入。<br/><strong>使用场景</strong>：<br/>再也不用每次手写 <code>useEffect</code>、<code>useCallback</code>、<code>React.memo</code> 的完整模板，输入简写自动展开。<br/><strong>常用触发词</strong>：</p><table><thead><tr><th align="left">触发词</th><th align="left">展开内容</th></tr></thead><tbody><tr><td align="left"><code>rafce</code></td><td align="left">React 函数组件 + 默认导出</td></tr><tr><td align="left"><code>rafc</code></td><td align="left">React 箭头函数组件</td></tr><tr><td align="left"><code>uef</code></td><td align="left"><code>useEffect</code> Hook</td></tr><tr><td align="left"><code>ust</code></td><td align="left"><code>useState</code> Hook</td></tr><tr><td align="left"><code>ucb</code></td><td align="left"><code>useCallback</code> Hook</td></tr><tr><td align="left"><code>rem</code></td><td align="left"><code>React.memo</code> 包装</td></tr></tbody></table><p><strong>示例</strong>：</p><pre><code class="javascript">// 输入 rafce + Tab，自动展开：
import React from 'react'
const MyComponent = () =&gt; {
return (
  &lt;div&gt;rafce&lt;/div&gt;
)
}
export default MyComponent</code></pre><hr/><h3>7. 🎯 Tailwind CSS IntelliSense</h3><p><strong>作用</strong>：Tailwind CSS 类名智能提示、悬停预览、自动补全。<br/><strong>使用场景</strong>：</p></li><li>不记得某个工具类名怎么写</li><li>想知道某个类名的具体样式</li><li>防止拼写错误（如 <code>bg-red500</code> 写成 <code>bg-red-500</code>）<br/><strong>核心功能</strong>：</li><li>✅ 实时类名补全</li><li>✅ Hover 显示具体样式值</li><li>✅ Lint 提示未知类名</li><li><p>✅ 支持自定义配置文件读取</p><blockquote>💡 <strong>Tailwind 开发者的必备神器</strong>，效率提升 50%+！</blockquote><hr/><h3>8. 💚 Vue (Official)</h3><p><strong>作用</strong>：Vue 官方插件，提供语法高亮、智能提示、代码片段。<br/><strong>使用场景</strong>：</p></li><li>Vue 2/3 项目开发必备</li><li><code>.vue</code> 文件语法高亮</li><li>Vue 指令自动补全</li><li>Props、Emits 类型提示<br/><strong>支持特性</strong>：</li><li>✅ 单文件组件（SFC）完整支持</li><li>✅ TypeScript 支持</li><li>✅ Pinia 状态库集成</li><li><h2>✅ Vite 模块智能解析</h2><h2>三、Git 版本控制类</h2><h3>9. 🔬 GitLens — Git supercharged</h3><p><strong>作用</strong>：VS Code 中最强大的 Git 增强插件。<br/><strong>核心功能</strong>：</p><table><thead><tr><th align="left">功能</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">📝 <strong>代码作者</strong></td><td align="left">鼠标悬停显示这行代码是谁写的</td></tr><tr><td align="left">🕐 <strong>提交时间</strong></td><td align="left">显示代码最后修改时间</td></tr><tr><td align="left">🔀 <strong>分支对比</strong></td><td align="left">当前分支与其他分支的差异</td></tr><tr><td align="left">📋 <strong>提交详情</strong></td><td align="left">点击查看完整的 commit 信息和文件变更</td></tr><tr><td align="left">🔍 <strong>Blame 功能</strong></td><td align="left">显示每一行代码的提交记录</td></tr></tbody></table><p><strong>使用技巧</strong>：</p></li><li>按 <code>Ctrl + Shift + G</code> 打开 Git 面板</li><li>点击代码行左侧的 Git 图标查看作者</li><li><p>使用 "GitLens: Toggle File Blame" 查看整个文件的 blame</p><blockquote>🏆 <strong>被称为 Git 必装插件</strong>，强烈推荐！</blockquote><hr/><h3>10. 📊 Git Graph</h3><p><strong>作用</strong>：以可视化图形展示 Git 提交历史和分支关系。<br/><strong>使用场景</strong>：</p></li><li>直观查看分支合并情况</li><li>快速切换分支</li><li>查看 tag 标签</li><li>找到某个 commit 的父节点<br/><strong>功能亮点</strong>：</li><li>🌳 树状图展示提交历史</li><li>🏷️ 显示标签（Tags）</li><li>🔀 显示远程分支</li><li><p>⬇️ 支持 fetch/pull/push 操作</p><blockquote>💡 按 <code>Ctrl + Shift + G</code> 打开 Git 面板，点击 "Git Graph" 查看图形。</blockquote><hr/><h3>11. 📜 Git History</h3><p><strong>作用</strong>：查看文件或目录的 Git 历史记录。<br/><strong>核心功能</strong>：</p></li><li>查看某个文件的所有提交历史</li><li>比较两个版本的差异</li><li>恢复文件到某个历史版本</li><li>搜索特定提交<br/><strong>使用方式</strong>：</li><li>右键点击文件</li><li>选择 "Git: View File History"</li><li>点击某个 commit 查看详细变更</li><li><h2>点击 "Open File" 可查看历史版本</h2><h2>四、开发工具与预览类</h2><h3>12. 🌐 Live Server</h3><p><strong>作用</strong>：启动本地开发服务器，支持热更新。<br/><strong>使用场景</strong>：</p></li><li>HTML/CSS/JavaScript 原型开发</li><li>静态页面实时预览</li><li>修改代码后浏览器自动刷新<br/><strong>核心优势</strong>：</li><li>✅ 一键启动服务器</li><li>✅ 支持实时热更新</li><li>✅ 支持跨域请求</li><li>✅ 可自定义端口号<br/><strong>使用方式</strong>：</li><li>右键点击 <code>index.html</code></li><li>选择 "Open with Live Server"</li><li><p>浏览器自动打开 <code>http://127.0.0.1:5500/</code></p><blockquote>⚡ <strong>前端开发必备</strong>，告别手动刷新！</blockquote><hr/><h3>13. 🚀 open in browser</h3><p><strong>作用</strong>：一键在浏览器中打开当前 HTML 文件。<br/><strong>使用场景</strong>：</p></li><li>快速预览静态页面</li><li>支持 Chrome、Firefox、Edge 等多浏览器</li><li><p>无需启动服务器<br/><strong>快捷键</strong>：</p><table><thead><tr><th align="left">操作</th><th align="left">Windows/Linux</th><th align="left">Mac</th></tr></thead><tbody><tr><td align="left">在默认浏览器打开</td><td align="left"><code>Ctrl + B</code></td><td align="left"><code>Cmd + B</code></td></tr></tbody></table><hr/><h3>14. 🖼️ Svg Preview</h3><p><strong>作用</strong>：实时预览 SVG 图片，支持代码与视图同步。<br/><strong>使用场景</strong>：</p></li><li>SVG 图标调试</li><li>查看路径、坐标、颜色</li><li>实时修改代码预览效果<br/><strong>核心功能</strong>：</li><li>✅ 分屏显示：左侧代码，右侧预览</li><li>✅ 支持拖拽 SVG 文件直接预览</li><li>✅ 显示 SVG 的尺寸、路径信息</li><li><h2>✅ 支持动画预览</h2><h2>五、辅助工具类</h2><h3>15. 🔖 Bookmarks</h3><p><strong>作用</strong>：在代码中设置书签，快速跳转到重要位置。<br/><strong>使用场景</strong>：</p></li><li>跨多个文件快速定位</li><li>记住某个函数的位置</li><li><p>大文件中标记关键段落<br/><strong>快捷键</strong>：</p><table><thead><tr><th align="left">操作</th><th align="left">快捷键</th></tr></thead><tbody><tr><td align="left">切换书签</td><td align="left"><code>Ctrl + Alt + K</code></td></tr><tr><td align="left">跳转到上一个书签</td><td align="left"><code>Ctrl + Alt + J</code></td></tr><tr><td align="left">跳转到下一个书签</td><td align="left"><code>Ctrl + Alt + L</code></td></tr><tr><td align="left">清除所有书签</td><td align="left"><code>Ctrl + Shift + K</code></td></tr></tbody></table><p><strong>效果展示</strong>：</p><pre><code class="javascript">// 🔖 书签标记在函数名前
function importantFunction() {
// 这是一个重要函数，需要频繁查看
console.log('Hello');
}
// 🔖 另一个书签
function anotherFunction() {
// ...
}</code></pre><blockquote>💡 适合调试大项目时记录关键位置！</blockquote><hr/><h3>16. ✅ Code Spell Checker</h3><p><strong>作用</strong>：检查代码中的拼写错误，避免因单词写错导致的 Bug。<br/><strong>使用场景</strong>：</p></li><li>变量名拼写错误（<code>consoel.log</code> → <code>console.log</code>）</li><li>注释中的英文拼写错误</li><li>防止复制粘贴引入的错别字<br/><strong>核心功能</strong>：</li><li>✅ 实时拼写检查</li><li>✅ 支持驼峰命名识别</li><li>✅ 可添加自定义字典</li><li><p>✅ 支持多种语言<br/><strong>配置示例</strong>（添加自定义词汇）：</p><pre><code class="json">"cSpell.words": [
"react",
"tailwindcss",
"github"
]</code></pre><blockquote>🎯 <strong>特别适合非英语母语开发者</strong>，减少低级拼写错误！</blockquote><hr/><h3>17. 🎨 Icon Theme: Material</h3><p><strong>作用</strong>：为文件和文件夹提供精美的 Material Design 风格图标。<br/><strong>视觉提升</strong>：</p><table><thead><tr><th align="left">文件类型</th><th align="left">图标样式</th></tr></thead><tbody><tr><td align="left">React</td><td align="left">⚛️ React 图标</td></tr><tr><td align="left">Vue</td><td align="left">💚 Vue 绿色图标</td></tr><tr><td align="left">TypeScript</td><td align="left">🔷 TS 蓝色方块</td></tr><tr><td align="left">CSS/Sass</td><td align="left">🎨 彩色样式图标</td></tr><tr><td align="left">文件夹</td><td align="left">📁 不同颜色区分</td></tr></tbody></table><p><strong>优势</strong>：</p></li><li>✅ 一眼识别文件类型</li><li>✅ 文件夹颜色区分（src、dist、node_modules）</li><li>✅ 提升视觉愉悦度</li><li><p>✅ 支持自定义图标主题</p><blockquote>🌈 <strong>强烈推荐安装</strong>，让编辑器颜值提升一个档次！</blockquote><hr/><h2>安装方式</h2><h3>方法一：通过扩展商店安装（推荐）</h3></li><li>打开 VS Code</li><li>按 <code>Ctrl + Shift + X</code>（Mac：<code>Cmd + Shift + X</code>）打开扩展面板</li><li>在搜索框中输入插件名称</li><li><p>点击 "Install" 安装</p><h3>方法二：命令面板安装</h3></li><li>按 <code>Ctrl + Shift + P</code>（Mac：<code>Cmd + Shift + P</code>）</li><li>输入 <code>Extensions: Install Extensions</code></li><li><p>搜索并安装</p><h3>方法三：通过 setting.json 自动格式化配置</h3><p>在项目根目录中先创建.vscode目录，然后在.vscode目录中创建一个<code>setting.json</code>文件，配置自动格式化规则。</p><pre><code class="json">{
"editor.fontSize": 12,
"editor.tabSize": 2,
"eslint.enable": true,
"editor.formatOnSave": true,
"editor.formatOnType": true,
"eslint.validate": [
  "vue",
  "html",
  "javascript",
  "typescript",
  "javascriptreact",
  "typescriptreact"
],
"editor.defaultFormatter": "esbenp.prettier-vscode",
"prettier.requireConfig": true,
"prettier.semi": false,
"editor.codeActionsOnSave": {
  "source.fixAll": "explicit",
  "source.fixAll.eslint": "explicit",
  "source.fixAll.stylelint": "explicit"
},
"javascript.format.insertSpaceBeforeFunctionParenthesis": false,
"search.exclude": {
  "**/node_modules": true,
  "**/bower_components": true,
  "**/target": true,
  "**/logs": true
},
"css.validate": false,
"less.validate": false,
"scss.validate": false,
"stylelint.validate": [
  "css",
  "less",
  "postcss",
  "scss",
  "sass",
  "stylus",
  "vue"
],
"git.autofetch": true,
"cSpell.userWords": [
  "antd",
  "axios",
  "childs",
  "commitlint",
  "daterange",
  "echarts",
  "graphlib",
  "loadfj",
  "moveend",
  "tailwindcss",
  "vuepress",
  "vuex",
],
"workbench.startupEditor": "none",
"diffEditor.ignoreTrimWhitespace": false,
"workbench.iconTheme": "material-icon-theme"
}</code></pre><h3>方法四：通过 extensions.json 批量安装</h3><p>在.vscode目录中创建一个 <code>extensions.json</code> 文件，记录团队推荐插件，新成员可一键同步。</p><pre><code class="json">{
"recommendations": [
  // 代码编辑与格式化
  "esbenp.prettier-vscode",          // Prettier - Code formatter
  "dbaeumer.vscode-eslint",          // ESLint
  "stylelint.vscode-stylelint",      // Stylelint
  "EditorConfig.EditorConfig",       // EditorConfig for VS Code
  "oderwat.indent-rainbow",          // indent-rainbow

  // 代码片段与智能提示
  "dsznajder.es7-react-js-snippets", // ES7+ React/Redux/React-Native snippets
  "bradlc.vscode-tailwindcss",       // Tailwind CSS IntelliSense
  "Vue.volar",                       // Vue (Official)

  // Git 版本控制
  "eamodio.gitlens",                 // GitLens — Git supercharged
  "mhutchie.git-graph",              // Git Graph
  "donjayamanne.githistory",         // Git History

  // 开发工具与预览
  "ritwickdey.liveserver",           // Live Server
  "techer.open-in-browser",          // open in browser
  "SimonSiefke.svg-preview",         // Svg Preview

  // 辅助工具
  "alefragnani.bookmarks",           // Bookmarks
  "streetsidesoftware.code-spell-checker", // Code Spell Checker
  "PKief.material-icon-theme"        // Icon Theme: Material
]
}
</code></pre></li></ul><h2>生效方式</h2><blockquote>团队协作：将 .vscode/extensions.json 和 .vscode/extensions.json 提交到 Git 仓库。<br/>拉取代码：当团队成员 git pull 代码并在 VS Code 打开该项目时，右下角会弹出提示。<br/>一键安装：点击弹窗中的“安装全部”按钮，VS Code 就会自动帮你装好所有插件。</blockquote><hr/><h2>总结</h2><p>今天介绍的 16 款插件涵盖了前端开发的各个环节：</p><table><thead><tr><th align="left">类别</th><th align="center">插件数量</th><th align="left">核心价值</th></tr></thead><tbody><tr><td align="left">代码编辑与格式化</td><td align="center">5</td><td align="left">统一代码风格，提升可读性</td></tr><tr><td align="left">代码片段与智能提示</td><td align="center">3</td><td align="left">加速编码，减少重复劳动</td></tr><tr><td align="left">Git 版本控制</td><td align="center">3</td><td align="left">可视化管理，追溯代码历史</td></tr><tr><td align="left">开发工具与预览</td><td align="center">3</td><td align="left">实时反馈，提升开发体验</td></tr><tr><td align="left">辅助工具</td><td align="center">2</td><td align="left">减少错误，提升导航效率</td></tr></tbody></table><p><strong>安装建议</strong>：</p><ul><li>🌟 <strong>必装（5款）</strong>：ESLint、Prettier、GitLens、Live Server、ES7+ React Snippets</li><li>🌟 <strong>推荐（6款）</strong>：EditorConfig、Tailwind CSS IntelliSense、Git Graph、Bookmarks、Code Spell Checker、Icon Theme: Material</li><li><p>💡 <strong>可选（5款）</strong>：Stylelint、indent-rainbow、Vue (Official)、open in browser、Svg Preview（根据技术栈选择）</p><blockquote>💡 <strong>小贴士</strong>：不要一次安装过多插件，根据项目需求逐步添加，避免 VS Code 变得卡顿。</blockquote><hr/><p>希望这篇教程对你有所帮助！如有问题，欢迎交流讨论。</p></li></ul><p>本文由<a href="https://link.segmentfault.com/?enc=cYmo76IQYI1QdhMos4pINQ%3D%3D.Q5VgfRZ%2B6u0TigZyXBnoF7LESKQyok1j1pYByXoVumY%3D" rel="nofollow" target="_blank">mdnice</a>多平台发布</p>]]></description></item><item>    <title><![CDATA[『NAS』在群晖部署高颜值笔记工具-memos 德育处主任 ]]></title>    <link>https://segmentfault.com/a/1190000047570686</link>    <guid>https://segmentfault.com/a/1190000047570686</guid>    <pubDate>2026-01-25 22:06:00</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><strong>点赞 + 关注 + 收藏 = 学会了</strong></p><blockquote>整理了一个NAS小专栏，有兴趣的工友可以关注一下 👉 <a href="https://link.segmentfault.com/?enc=w5f3cAQ1lfeXnRu5t1VWyg%3D%3D.8pw%2FNxawMh%2BOCS07oO024NlBk7V5XCLQatGn%2FXuLk6PeN8Tk1%2F3qZsMC9hHDmCTsq3UsnRHm88DpyoUZ%2Bf0pScYZSVMVFZuTzymQThzdrsgYzEeazUYOg%2Bmij1MSjSfDwQpsjDoRRzmU%2BPH52Ogy3Dq6OGypiR0UaSoOi%2BPNgZY%3D" rel="nofollow" target="_blank">《NAS邪修》</a></blockquote><p>Memos 是一款开源免费、隐私优先的轻量化笔记工具，支持 Docker 一键部署到 NAS（数据本地存储，完全自主掌控）。它支持纯文本和 Markdown 格式，可通过标签、日历分类笔记，还能实现笔记引用、插入图片 / 附件等实用功能，低资源占用不拖慢设备，记想法、列待办、存资料都合适。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047570688" alt="" title=""/></p><p>本文使用群晖 NAS 部署 memos，其他 NAS 或者在电脑用 Docker 部署的方法大同小异。</p><p>首先在“File Station”的“docker”文件夹里创建一个“memos”文件夹。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047570689" alt="" title="" loading="lazy"/></p><p>然后打开”Container Manager“创建一个新项目，相关配置如下图所示。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047570690" alt="" title="" loading="lazy"/></p><p>输入以下代码（注意代码格式！！！）</p><pre><code>services:
  memos:
    image: neosmemo/memos:latest
    container_name: memos
    volumes:
      - .:/var/opt/memos
    ports:
      - 5230:5230</code></pre><p>开启“通过 Web Station 设置网页门户”</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047570691" alt="" title="" loading="lazy"/></p><p>接下来打开“web Station”新建一个“网络门户”。</p><p>相关配置如下图所示。</p><p>端口设置一个不跟其他项目冲突的数字即可，我用的是 <code>2345</code>。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047570692" alt="" title="" loading="lazy"/></p><p>完成上面的操作后，打开浏览器，输入 <code>NAS的IP + 端口（本例用的是2345）</code>，就可以使用 memos了。</p><p>首次使用需要创建一个账号。</p><p>在登录页下方可以设置 memos 系统使用什么语言以及主题色。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047570693" alt="" title="" loading="lazy"/></p><p>登录后就可以开始写笔记了。它支持 Markdown 语法，挺适合用来写博客的。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047570694" alt="" title="" loading="lazy"/></p><hr/><p>以上就是本文的全部内容啦，想了解更多NAS玩法可以关注<a href="https://link.segmentfault.com/?enc=1oRYN0GIb1ZewImCZGNyGw%3D%3D.coC3yjMnZfY3aqnJug9NTGURxuVk02xE2Dv3nAxmKG9%2ForPG6q%2BFyteWxOtFKexaY4UyKB6WKGchPzSe8sc4s%2FNzoD24uDWf3bxu79QYlqU18exkBRvS42lJxEhWQf4MI6X2qCTCelNqeYtsAceEnHTUQOQsgtU%2BxE%2BeXUN0ovA%3D" rel="nofollow" target="_blank">《NAS邪修》👏</a></p><p>最后推荐一下玩 NAS 的工友，在 NAS 上装一个 n8n 接入大模型，可以帮你定时定候完成各种工作，比如签到啦、写文章啦、生成海报和视频啦、自动发布到各大平台啦～</p><p>想了解 n8n 的工友可以关注我的专栏👉 <a href="https://link.segmentfault.com/?enc=OLOsWwpTtnhmPEKIRl8Emg%3D%3D.OU48zzKHHRXN%2BWF7rJfsW9PViU8aJawAS60CztFiMOsYz9t42bL%2FdTVKnKCSwGBEKG7MnAdMTqLujPLgqE0uOSzkxhxqkO6QC1%2F9VmJiEax6eff6kXhAXFrRpKOY5MKtHLcJqifeci%2Fq42i%2FJcJMti%2Bq2P25hS3oJQ0jzG5Y540%3D" rel="nofollow" target="_blank">《n8n修炼手册》</a></p><p><strong>点赞 + 关注 + 收藏 = 学会了</strong></p>]]></description></item><item>    <title><![CDATA[如何使用image-syncer 实现 Docker Hub 到 Azure ACR 的自动化镜像同]]></title>    <link>https://segmentfault.com/a/1190000047570703</link>    <guid>https://segmentfault.com/a/1190000047570703</guid>    <pubDate>2026-01-25 22:05:04</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>实现 Docker Hub 到 Azure ACR 的自动化镜像同步</h2><blockquote>本文介绍了如何使用 GitHub Actions 和 image-syncer 工具，实现 Docker Hub 镜像到 Azure Container Registry 的自动化同步，解决了国内及部分 Azure 区域访问 Docker Hub 速度慢的问题，提升了镜像的可用性和 Azure 环境的部署效率。</blockquote><p>&lt;!-- truncate --&gt;</p><h3>背景/引言</h3><p>HagiCode 项目使用 Docker 镜像作为核心运行时组件，主要镜像托管在 Docker Hub。随着项目发展和 Azure 环境部署需求的增加，我们遇到了以下痛点：</p><ul><li>镜像拉取速度慢，Docker Hub 在国内及部分 Azure 区域访问受限</li><li>依赖单一镜像源存在单点故障风险</li><li>Azure 环境下使用 Azure Container Registry 能获得更好的网络性能和集成体验</li></ul><p>为解决这些问题，我们需要建立一个自动化的镜像同步机制，将 Docker Hub 的镜像定期同步到 Azure ACR，确保用户能够在 Azure 环境中获得更快的镜像拉取速度和更高的可用性。</p><h3>关于 HagiCode</h3><p>我们正在开发 HagiCode——一款 AI 驱动的代码智能助手，让开发体验变得更智能、更便捷、更有趣。</p><p>智能——AI 全程辅助，从想法到代码，让编码效率提升数倍。便捷——多线程并发操作，充分利用资源，开发流程顺畅无阻。有趣——游戏化机制和成就系统，让编码不再枯燥，充满成就感。</p><p>项目正在快速迭代中，如果你对技术写作、知识管理或者 AI 辅助开发感兴趣，欢迎来 GitHub 看看。</p><h3>技术方案对比</h3><p>在制定解决方案时，我们对比了多种技术方案：</p><h4>1. image-syncer（最终选择）</h4><ul><li>增量同步：仅同步变更的镜像层，显著减少网络传输</li><li>断点续传：网络中断后可恢复同步</li><li>并发控制：支持配置并发线程数，提升大镜像同步效率</li><li>完善的错误处理：内置失败重试机制（默认 3 次）</li><li>轻量级部署：单二进制文件，无依赖</li><li>多仓库支持：兼容 Docker Hub、Azure ACR、Harbor 等</li></ul><h4>2. Docker CLI</h4><ul><li>不支持增量同步：每次都需要拉取完整的镜像内容</li><li>效率较低：网络传输量大，时间长</li><li>简单易用：使用熟悉的 docker pull/push 命令</li></ul><h4>3. Azure CLI</h4><ul><li>复杂度高：需要配置 Azure CLI 认证</li><li>功能限制：az acr import 功能相对单一</li><li>原生集成：与 Azure 服务集成良好</li></ul><h3>架构设计决策</h3><h4>决策 1：同步频率设置为每日 UTC 00:00</h4><ul><li>平衡镜像新鲜度和资源消耗</li><li>避开业务高峰期，减少对其他操作的影响</li><li>Docker Hub 镜像通常在每日构建后更新</li></ul><h4>决策 2：同步所有镜像标签</h4><ul><li>保持与 Docker Hub 的完全一致性</li><li>为用户提供灵活的版本选择</li><li>简化同步逻辑，避免复杂的标签过滤规则</li></ul><h4>决策 3：使用 GitHub Secrets 存储认证信息</h4><ul><li>GitHub Actions 原生支持，安全性高</li><li>配置简单，易于管理和维护</li><li>支持仓库级别的访问控制</li></ul><h3>风险评估与缓解</h3><h4>风险 1：Azure ACR 认证信息泄露</h4><ul><li>使用 GitHub Secrets 加密存储</li><li>定期轮换 ACR 密码</li><li>限制 ACR 用户权限为仅推送</li><li>监控 ACR 访问日志</li></ul><h4>风险 2：同步失败导致镜像不一致</h4><ul><li>image-syncer 内置增量同步机制</li><li>自动失败重试（默认 3 次）</li><li>详细的错误日志和失败通知</li><li>断点续传功能</li></ul><h4>风险 3：资源消耗过大</h4><ul><li>增量同步减少网络传输</li><li>可配置并发线程数（当前设置为 10）</li><li>监控同步的镜像数量和大小</li><li>在非高峰时段运行同步</li></ul><h3>核心解决方案</h3><p>我们采用 GitHub Actions + image-syncer 的自动化方案，实现从 Docker Hub 到 Azure ACR 的镜像同步。</p><h3>实施步骤</h3><h4>1. 准备阶段</h4><ul><li>在 Azure Portal 中创建或确认 Azure Container Registry</li><li>创建 ACR 访问密钥（用户名和密码）</li><li>确认 Docker Hub 镜像仓库访问权限</li></ul><h4>2. 配置 GitHub Secrets</h4><p>在 GitHub 仓库设置中添加以下 Secrets：</p><ul><li>AZURE_ACR_USERNAME: Azure ACR 用户名</li><li>AZURE_ACR_PASSWORD: Azure ACR 密码</li></ul><h4>3. 创建 GitHub Actions 工作流</h4><p>在 .github/workflows/sync-docker-acr.yml 中配置工作流：</p><ul><li>定时触发：每天 UTC 00:00</li><li>手动触发：支持 workflow_dispatch</li><li>额外触发：publish 分支推送时触发（用于快速同步）</li></ul><h4>4. 工作流执行流程</h4><pre style="display:none;"><code class="mermaid">sequenceDiagram
    participant GH as GitHub Actions
    participant IS as image-syncer
    participant DH as Docker Hub
    participant ACR as Azure ACR

    Note over GH: 触发工作流
    GH-&gt;&gt;IS: 下载并执行 image-syncer
    IS-&gt;&gt;DH: 获取镜像 manifest 和标签列表
    DH--&gt;&gt;IS: 返回镜像元数据
    IS-&gt;&gt;ACR: 获取已存在的镜像信息
    ACR--&gt;&gt;IS: 返回目标镜像信息
    IS-&gt;&gt;IS: 对比差异，识别变更的镜像层
    Note over IS: 增量同步：仅传输变更的镜像层
    IS-&gt;&gt;DH: 拉取变更的镜像层
    DH--&gt;&gt;IS: 返回镜像层内容
    IS-&gt;&gt;ACR: 推送变更的镜像层到 ACR
    ACR--&gt;&gt;IS: 返回推送结果
    IS--&gt;&gt;GH: 返回同步统计信息
    GH-&gt;&gt;GH: 记录同步日志并上传 artifact</code></pre><h3>GitHub Actions 工作流实现</h3><p>以下是实际运行的工作流配置（.github/workflows/sync-docker-acr.yml）：</p><pre><code class="yaml">name: Sync Docker Image to Azure ACR

on:
  schedule:
    - cron: "0 0 * * *" # 每天 UTC 00:00
  workflow_dispatch: # 手动触发
  push:
    branches: [publish]

permissions:
  contents: read

jobs:
  sync:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download image-syncer
        run: |
          # 下载 image-syncer 二进制文件
          wget https://github.com/AliyunContainerService/image-syncer/releases/download/v1.5.5/image-syncer-v1.5.5-linux-amd64.tar.gz
          tar -zxvf image-syncer-v1.5.5-linux-amd64.tar.gz
          chmod +x image-syncer

      - name: Create auth config
        run: |
          # 生成认证配置文件 (YAML 格式)
          cat &gt; auth.yaml &lt;&lt;EOF
          hagicode.azurecr.io:
            username: "${{ secrets.AZURE_ACR_USERNAME }}"
            password: "${{ secrets.AZURE_ACR_PASSWORD }}"
          EOF

      - name: Create images config
        run: |
          # 生成镜像同步配置文件 (YAML 格式)
          cat &gt; images.yaml &lt;&lt;EOF
          docker.io/newbe36524/hagicode: hagicode.azurecr.io/hagicode
          EOF

      - name: Run image-syncer
        run: |
          # 执行同步 (使用新版 --auth 和 --images 参数)
          ./image-syncer --auth=./auth.yaml --images=./images.yaml --proc=10 --retries=3

      - name: Upload logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: sync-logs
          path: image-syncer-*.log
          retention-days: 7</code></pre><h3>配置说明</h3><h4>1. 触发条件</h4><ul><li>定时触发：cron: "0 0 <em> </em> *" - 每天 UTC 00:00 执行</li><li>手动触发：workflow_dispatch - 允许用户在 GitHub UI 手动运行</li><li>推送触发：push: branches: [publish] - 发布分支推送时触发（用于快速同步）</li></ul><h4>2. 认证配置 (auth.yaml)</h4><pre><code class="yaml">hagicode.azurecr.io:
  username: "${{ secrets.AZURE_ACR_USERNAME }}"
  password: "${{ secrets.AZURE_ACR_PASSWORD }}"</code></pre><h4>3. 镜像同步配置</h4><pre><code class="yaml">docker.io/newbe36524/hagicode: hagicode.azurecr.io/hagicode</code></pre><p>此配置表示将 docker.io/newbe36524/hagicode 的所有标签同步到 hagicode.azurecr.io/hagicode</p><h4>4. image-syncer 参数</h4><ul><li>--auth=./auth.yaml: 认证配置文件路径</li><li>--images=./images.yaml: 镜像同步配置文件路径</li><li>--proc=10: 并发线程数为 10</li><li>--retries=3: 失败重试 3 次</li></ul><h3>GitHub Secrets 配置清单</h3><p>在 GitHub 仓库的 Settings → Secrets and variables → Actions 中配置：</p><table><thead><tr><th>Secret 名称</th><th>描述</th><th>示例值</th><th>获取方式</th></tr></thead><tbody><tr><td>AZURE_ACR_USERNAME</td><td>Azure ACR 用户名</td><td>hagicode</td><td>Azure Portal → ACR → Access keys</td></tr><tr><td>AZURE_ACR_PASSWORD</td><td>Azure ACR 密码</td><td>xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx</td><td>Azure Portal → ACR → Access keys → Password</td></tr></tbody></table><h3>使用说明</h3><h4>1. 手动触发同步</h4><ol><li>访问 GitHub 仓库的 Actions 标签页</li><li>选择 Sync Docker Image to Azure ACR 工作流</li><li>点击 Run workflow 按钮</li><li>选择分支并点击 Run workflow 确认</li></ol><h4>2. 查看同步日志</h4><ol><li>在 Actions 页面点击具体的工作流运行记录</li><li>查看各个步骤的执行日志</li><li>在页面底部的 Artifacts 区域下载 sync-logs 文件</li></ol><h4>3. 验证同步结果</h4><pre><code class="bash"># 登录到 Azure ACR
az acr login --name hagicode

# 列出镜像及其标签
az acr repository show-tags --name hagicode --repository hagicode --output table</code></pre><h3>注意事项和最佳实践</h3><h4>1. 安全建议</h4><ul><li>定期轮换 Azure ACR 密码（建议每 90 天）</li><li>使用专用的 ACR 服务账户，限制权限为仅推送</li><li>监控 ACR 的访问日志，及时发现异常访问</li><li>不要在日志中输出认证信息</li><li>不要将认证信息提交到代码仓库</li></ul><h4>2. 性能优化</h4><ul><li>调整 --proc 参数：根据网络带宽调整并发数（建议 5-20）</li><li>监控同步时间：如果同步时间过长，考虑减少并发数</li><li>定期清理日志：设置合理的 retention-days（当前为 7 天）</li></ul><h4>3. 故障排查</h4><h5>问题 1：认证失败</h5><pre><code>Error: failed to authenticate to hagicode.azurecr.io</code></pre><p>解决方案：</p><ol><li>检查 GitHub Secrets 是否正确配置</li><li>验证 Azure ACR 密码是否过期</li><li>确认 ACR 服务账户权限是否正确</li></ol><h5>问题 2：网络超时</h5><pre><code>Error: timeout waiting for response</code></pre><p>解决方案：</p><ol><li>检查网络连接</li><li>减少并发线程数（--proc 参数）</li><li>等待网络恢复后重新触发工作流</li></ol><h5>问题 3：镜像同步不完整</h5><pre><code>Warning: some tags failed to sync</code></pre><p>解决方案：</p><ol><li>检查同步日志，识别失败的标签</li><li>手动触发工作流重新同步</li><li>验证 Docker Hub 源镜像是否正常</li></ol><h4>4. 监控和告警</h4><ul><li>定期检查 Actions 页面，确认工作流运行状态</li><li>设置 GitHub 通知，及时获取工作流失败通知</li><li>监控 Azure ACR 的存储使用情况</li><li>定期验证镜像标签一致性</li></ul><h3>常见问题和解决方案</h3><h4>Q1: 如何同步特定标签而不是所有标签？</h4><p>修改 images.yaml 配置文件：</p><pre><code class="yaml"># 仅同步 latest 和 v1.0 标签
docker.io/newbe36524/hagicode:latest: hagicode.azurecr.io/hagicode:latest
docker.io/newbe36524/hagicode:v1.0: hagicode.azurecr.io/hagicode:v1.0</code></pre><h4>Q2: 如何同步多个镜像仓库？</h4><p>在 images.yaml 中添加多行配置：</p><pre><code class="yaml">docker.io/newbe36524/hagicode: hagicode.azurecr.io/hagicode
docker.io/newbe36524/another-image: hagicode.azurecr.io/another-image</code></pre><h4>Q3: 同步失败后如何重试？</h4><ul><li>自动重试：image-syncer 内置重试机制（默认 3 次）</li><li>手动重试：在 GitHub Actions 页面点击 Re-run all jobs</li></ul><h4>Q4: 如何查看同步的详细进度？</h4><ul><li>在 Actions 页面查看实时日志</li><li>下载 sync-logs artifact 查看完整日志文件</li><li>日志文件包含每个标签的同步状态和传输速度</li></ul><h4>Q5: 同步需要多长时间？</h4><ul><li>首次全量同步：根据镜像大小，通常需要 10-30 分钟</li><li>增量同步：如果镜像变更小，通常 2-5 分钟</li><li>时间取决于网络带宽、镜像大小和并发设置</li></ul><h3>扩展功能建议</h3><h4>1. 添加同步通知</h4><p>在工作流中添加通知步骤：</p><pre><code class="yaml">- name: Notify on success
  if: success()
  run: |
    echo "Docker images synced successfully to Azure ACR"</code></pre><h4>2. 实现镜像标签过滤</h4><p>在工作流中添加标签过滤逻辑：</p><pre><code class="yaml">- name: Filter tags
  run: |
    # 仅同步以 v 开头的标签
    echo "docker.io/newbe36524/hagicode:v* : hagicode.azurecr.io/hagicode:v*" &gt; images.yaml</code></pre><h4>3. 添加同步统计报告</h4><pre><code class="yaml">- name: Generate report
  if: always()
  run: |
    echo "## Sync Report" &gt;&gt; $GITHUB_STEP_SUMMARY
    echo "- Total tags: $(grep -c 'synced' image-syncer-*.log)" &gt;&gt; $GITHUB_STEP_SUMMARY
    echo "- Sync time: ${{ steps.sync.outputs.duration }}" &gt;&gt; $GITHUB_STEP_SUMMARY</code></pre><h3>总结</h3><p>通过本文介绍的方法，我们成功实现了从 Docker Hub 到 Azure ACR 的自动化镜像同步。这个方案利用 GitHub Actions 的定时触发和手动触发功能，结合 image-syncer 的增量同步和错误处理机制，确保了镜像的及时同步和一致性。</p><p>我们还讨论了安全最佳实践、性能优化、故障排查等方面的内容，帮助用户更好地管理和维护这个同步机制。希望本文能够为需要在 Azure 环境中部署 Docker 镜像的开发者提供有价值的参考。</p><h3>参考资料</h3><ul><li><a href="https://link.segmentfault.com/?enc=Pd2g3XD8YIynwUWXMDqI3Q%3D%3D.LaW%2FTPds8MrWZzgdxsPriXyWSb148XDkg7T2RSNMzm5a8MrbgTxi9TauMpb3Y2WJ" rel="nofollow" target="_blank">HagiCode 项目 GitHub 仓库</a></li><li><a href="https://link.segmentfault.com/?enc=4MGWQ8wbqimquV6A54cDaw%3D%3D.qB2INxueprwCBmsFoWfPRo8etGH%2B8ZO0a35AeTzp1uVSLL%2FKZJc1cog75FimHlRS63ML6EivvmD%2BC5erjnCp2A%3D%3D" rel="nofollow" target="_blank">image-syncer 官方文档</a></li><li><a href="https://link.segmentfault.com/?enc=qX1B3lRyh5lY1qZkRjfD4Q%3D%3D.toeZzv4HmTvICR3xx7pnOInKAJ6egEoxUDPbdX4Wl4nTF6ZMEA4u3Pl6Cw1Fh1HBgf06aUjaahXEWTI0X5gGpQ%3D%3D" rel="nofollow" target="_blank">Azure Container Registry 官方文档</a></li><li><a href="https://link.segmentfault.com/?enc=mBZrCfjD9A%2BO0GqFSJEmSw%3D%3D.K3kDeRlrqr6qqg%2BoroEBsJsQVKKXQQ7sGdqnsLCVAt%2FzCZGg4ksMMaFKBYaCGtNy" rel="nofollow" target="_blank">GitHub Actions 官方文档</a></li></ul><hr/><h3>互动引导</h3><p>感谢您的阅读,如果您觉得本文有用,快点击下方点赞按钮👍,让更多的人看到本文。</p><h3>AI 辅助声明</h3><p>本内容采用人工智能辅助协作,经本人审核,符合本人观点与立场。</p><h3>元信息</h3><ul><li><strong>本文作者:</strong> <a href="https://link.segmentfault.com/?enc=0UmM1po62FQAfgADy1I3Ug%3D%3D.VaCGOGCPCoQE7EGyPPbdEkTcnB5gQQE%2By%2BDiqVs2E2Q%3D" rel="nofollow" target="_blank">newbe36524</a></li><li><strong>本文链接:</strong> <a href="https://link.segmentfault.com/?enc=8uH6p3mXrSRl1JlahsHqdw%3D%3D.%2FtRUjczv1DwNkHndw4xj4uG7s2WQYRcRGUUYBn3%2BNPjY0HMIRMwIKXU%2FjrgJ5O5tIC3RlRAoijpRbWU9gwPq5xNXcSuqqfErJGhjaEtr7YUAcMfF61gCHHb5hh7SDZYwvFI3WkhWiGieuuuNjZATjw%3D%3D" rel="nofollow" target="_blank">https://hagicode-org.github.io/site/blog/2026/01/25/how-to-sync-docker-hub-to-azure-acr-with-github</a></li><li><strong>版权声明:</strong> 本博客所有文章除特别声明外,均采用 BY-NC-SA 许可协议。转载请注明出处!</li></ul>]]></description></item><item>    <title><![CDATA[新书《鸿蒙HarmonyOS 6应用开发：从零基础到App上线》出版啦 aqi00 ]]></title>    <link>https://segmentfault.com/a/1190000047570734</link>    <guid>https://segmentfault.com/a/1190000047570734</guid>    <pubDate>2026-01-25 22:04:31</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>​基于最新鸿蒙系统的技术书籍《鸿蒙HarmonyOS 6应用开发:从零基础到App上线》上市啦，要知道 HarmonyOS 6 在一个多月前的10月22日才正式发布，因此这本鸿蒙教程可谓贴近最新的 HarmonyOS 6 系统。</p><p>当前 HarmonyOS 6 的装机量迅猛增长，有望在春节前突破5000万台大关，可见鸿蒙系统的应用开发将越来越流行，甚至借助国产化的浪潮，未来在国内移动操作系统领域一举夺魁也不是不可能。</p><p>有鉴于此，博主精心编撰了 HarmonyOS 6 的应用开发教程《鸿蒙HarmonyOS 6应用开发:从零基础到App上线》，从基础到高级，从理论到实战，从 UI 到 AI ，仅需一本书籍，即可让读者掌握鸿蒙应用的常见开发技能。</p><p><img width="723" height="732" referrerpolicy="no-referrer" src="/img/bVdnLhb" alt="" title=""/></p><p>鸿蒙应用开发与安卓应用开发同为App开发，比如鸿蒙版微信和安卓版微信都是即时通信App，二者在实现技术上并无多少本质区别。所以《鸿蒙HarmonyOS 6应用开发:从零基础到App上线》一书以《Android Studio开发实战：从零基础到App上线(第3版)》为蓝本，把安卓系统的App教程改造为鸿蒙系统的App教程，以便安卓开发者能够按图索骥迅速上手。欣喜的是，《Android Studio开发实战：从零基础到App上线(第3版)》提到的安卓开发技术，绝大部分都能在鸿蒙系统找到对应的平替技术，而且还是更简单的代码实现。</p><p>作为《Android Studio开发实战：从零基础到App上线(第3版)》一书的鸿蒙姊妹篇，《鸿蒙HarmonyOS 6应用开发:从零基础到App上线》仍然采取了由浅入深、循序渐进的章节体例，其中前8章是基础部分，主要讲解 DevEco Studio 的环境搭建、ArkTS语言编程基础、鸿蒙App开发的各种常用组件、鸿蒙App开发的页面转场和消息交互、鸿蒙App的几种数据存储方式等；后8章是进阶部分，主要讲解鸿蒙App开发的后台任务、手势交互、动画特效、网络通信、多媒体、感知定位、人工智能、多端部署等。</p><p><img width="723" height="732" referrerpolicy="no-referrer" src="/img/bVdnLhd" alt="" title="" loading="lazy"/></p><p>曾经有老读者咨询“从零基础到App上线”系列书籍的第4版何时面世，现在博主终于可以说，“从零基础到App上线”的第4版已经出版啦，而且第4版是鸿蒙版本的“从零基础到App上线”，它就叫做《鸿蒙HarmonyOS 6应用开发:从零基础到App上线》，该书把安卓版教程平替为鸿蒙版教程，也是一个勇敢的尝试。</p><p>《鸿蒙HarmonyOS 6应用开发:从零基础到App上线》在讲解知识点的同时给出了大量实战范例，方便读者迅速将所学的知识运用到实际开发中。通过本书的学习，读者能够掌握3类主流App的基本开发技术，包括购物App（电子商务）、聊天App（即时通信）、娱乐App（短视频分享）。另外，能够学会开发一些趣味应用，包括计算器、录音笔、电子相册、打牌游戏、指南针、水平仪、卫星浑天仪、登山助手、附近交友、速记助手、人脸识别等等。可见《Android Studio开发实战：从零基础到App上线(第3版)》一书提到的实战项目，本书基本提供了对应的鸿蒙版App。</p><p><img width="723" height="311" referrerpolicy="no-referrer" src="/img/bVdnLhe" alt="" title="" loading="lazy"/></p><p>《鸿蒙HarmonyOS 6应用开发:从零基础到App上线》的随书源码包括客户端部分和服务端部分，其中客户端的App代码基于 DevEco Studio 6.0.0 Release 开发，并使用 API 20 的 SDK （HarmonyOS 6.0.0）编译与调试通过，测试机型包括 Mate 60 Pro 和 nova 12 Pro 。配套的服务端源码采用 Java WEB 框架，结合 MySQL 数据库，并基于 IDEA 开发。</p>]]></description></item><item>    <title><![CDATA[高可用的三件事——无状态化、水平扩展与故障转移的协同设计 南城 ]]></title>    <link>https://segmentfault.com/a/1190000047570767</link>    <guid>https://segmentfault.com/a/1190000047570767</guid>    <pubDate>2026-01-25 22:03:46</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><strong>写在前面，本人目前处于求职中，如有合适内推岗位，请加：lpshiyue 感谢。同时还望大家一键三连，赚点奶粉钱。本系列已完结，完整版阅读课联系本人</strong></p><blockquote>高可用不是简单的冗余堆砌，而是无状态化、水平扩展与故障转移三者协同的艺术品</blockquote><p>在掌握了系统压测方法论，能够准确评估系统容量边界后，我们面临一个更根本的挑战：如何让系统在真实流量冲击和故障发生时保持稳定？高可用架构设计正是解决这一挑战的核心手段。本文将深入解析无状态化、水平扩展与故障转移三大支柱技术的协同设计，帮助构建真正弹性可靠的系统架构。</p><h2>1 高可用的本质：从故障避免到故障容忍的哲学转变</h2><h3>1.1 高可用性的核心价值重估</h3><p>传统观念中，高可用意味着<strong>尽可能避免故障</strong>，而在分布式系统环境下，这一理念已转变为<strong>快速发现和恢复故障</strong>。根据Gartner的统计，企业IT系统平均每分钟的宕机成本超过5600美元，对于大型电商平台，这个数字可能达到数万美元。</p><p><strong>高可用设计的哲学转变</strong>体现在三个层面：</p><ul><li><strong>从完美预防到快速恢复</strong>：接受故障必然性，专注于最小化MTTR（平均修复时间）</li><li><strong>从单体坚固到分布式韧性</strong>：通过系统设计而非组件质量保证可用性</li><li><strong>从人工干预到自动化愈合</strong>：建立系统自愈能力，减少人工依赖</li></ul><p>这种转变使我们需要重新定义高可用的成功标准：不是追求100%无故障，而是确保故障发生时<strong>业务影响可控、恢复过程自动</strong>。</p><h3>1.2 可用性等级的理性定位</h3><p>不同业务场景对可用性有不同要求，理性定位是避免过度设计的第一步：</p><p><strong>99.9%可用性</strong>（年停机时间≤8.76小时）适合内部管理系统<br/><strong>99.95%可用性</strong>（年停机时间≤4.38小时）适合一般业务系统<br/><strong>99.99%可用性</strong>（年停机时间≤52.6分钟）适合核心业务系统<br/><strong>99.999%可用性</strong>（年停机时间≤5.26分钟）适合金融交易系统</p><p>确立合理的可用性目标后，我们才能有针对性地选择技术方案，在成本与可靠性间找到平衡点。</p><h2>2 无状态化：弹性架构的基石</h2><h3>2.1 无状态设计的本质与价值</h3><p>无状态化不是简单去除会话数据，而是<strong>将状态与计算分离</strong>，使应用实例变得可替代。这种分离是水平扩展和故障转移的基础。</p><p><strong>有状态架构的典型问题</strong>：</p><pre><code class="java">// 问题示例：会话绑定导致扩展困难
@RestController
public class StatefulController {
    // 会话状态存储在内存中
    private Map&lt;String, UserSession&gt; userSessions = new ConcurrentHashMap&lt;&gt;();
    
    @GetMapping("/userinfo")
    public String getUserInfo(HttpSession session) {
        UserSession userSession = (UserSession) session.getAttribute("currentUser");
        // 此实例绑定特定用户会话，无法随意替换
        return userSession.getUserInfo();
    }
}</code></pre><p><em>状态内嵌导致实例不可替换</em></p><p><strong>无状态化改造方案</strong>：</p><pre><code class="java">@Configuration
@EnableRedisHttpSession // 启用Redis会话存储
public class StatelessConfig {
    // 会话外部化配置
}

@RestController
public class StatelessUserController {
    @GetMapping("/userinfo")
    public String getUserInfo(@RequestHeader("Authorization") String token) {
        // 从Redis获取用户信息，不依赖本地状态
        String userJson = redisTemplate.opsForValue().get("session:" + token);
        User user = JsonUtil.fromJson(userJson, User.class);
        return user.toString();
    }
}</code></pre><p><em>状态外置使实例可任意替换</em></p><h3>2.2 无状态化的多层次实践</h3><p>无状态化需要在不同层级实施协同策略：</p><p><strong>应用层无状态</strong>：会话数据外部化到专用存储（Redis Cluster）<br/><strong>服务层无状态</strong>：API设计保证请求自包含，不依赖服务实例内存状态<br/><strong>任务层无状态</strong>：计算任务参数和结果完全自包含，支持任意重调度</p><p><strong>无状态设计的业务适配策略</strong>：</p><ul><li><strong>完全无状态</strong>：适合查询类、计算型业务（商品查询、价格计算）</li><li><strong>外部状态</strong>：适合需要会话保持但无需实例绑定的业务（用户登录状态）</li><li><strong>轻量状态</strong>：适合短暂业务流程，状态生命周期与请求周期一致</li></ul><h3>2.3 无状态架构的代价与应对</h3><p>无状态化不是银弹，需要认识其代价并制定应对策略：</p><p><strong>性能代价</strong>：状态外部化增加网络开销，需要通过缓存、批处理优化<br/><strong>一致性挑战</strong>：分布式状态需要处理并发更新，采用乐观锁或版本控制<br/><strong>复杂度增加</strong>：需要引入额外组件（Redis、ZooKeeper），增加运维复杂度</p><p>合理的无状态化是<strong>有选择的无状态</strong>，而非盲目去除所有状态。核心是确保<strong>实例可替换性</strong>，而非完全消除状态。</p><h2>3 水平扩展：流量压力的分布式化解</h2><h3>3.1 水平扩展的本质与架构前提</h3><p>水平扩展通过<strong>增加实例数量</strong>而非提升单机性能来应对流量增长，其有效性直接依赖于无状态化程度。</p><p><strong>水平扩展的架构前提</strong>：</p><ul><li><strong>无状态设计</strong>：实例间无数据依赖，可任意增减</li><li><strong>负载均衡</strong>：流量按策略分发到多个实例</li><li><strong>服务发现</strong>：动态感知实例上下线，实时更新路由</li><li><strong>健康检查</strong>：自动隔离故障实例，保证流量只会到达健康节点</li></ul><h3>3.2 分层扩展策略</h3><p>系统不同层级需要采用不同的水平扩展策略：</p><p><strong>接入层扩展</strong>：通过DNS轮询、全局负载均衡实现流量入口扩展</p><pre><code class="yaml"># Nginx上游服务配置示例
upstream backend_servers {
    server 10.0.1.10:8080 max_fails=3 fail_timeout=30s;
    server 10.0.1.11:8080 max_fails=3 fail_timeout=30s;
    server 10.0.1.12:8080 backup;  # 备份节点
    least_conn;  # 最少连接负载均衡
}</code></pre><p><em>接入层通过集群化实现扩展</em></p><p><strong>应用层扩展</strong>：无状态服务实例水平扩展，结合自动伸缩策略</p><pre><code class="yaml"># Kubernetes HPA配置示例
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: frontend-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: frontend
  minReplicas: 3
  maxReplicas: 100
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70</code></pre><p><em>应用层根据负载自动伸缩</em></p><p><strong>数据层扩展</strong>：通过分片、读写分离等技术实现数据访问扩展</p><pre><code class="sql">-- 数据库分片示例：用户数据按ID分片
-- 分片1：用户ID以0-4结尾
CREATE TABLE users_1 (
    id BIGINT PRIMARY KEY,
    name VARCHAR(100),
    -- 其他字段
);

-- 分片2：用户ID以5-9结尾  
CREATE TABLE users_2 (
    id BIGINT PRIMARY KEY,
    name VARCHAR(100),
    -- 其他字段
);</code></pre><p><em>数据层通过分片实现水平扩展</em></p><h3>3.3 水平扩展的粒度控制</h3><p>科学的水平扩展需要<strong>精细化粒度控制</strong>，避免过度或不足扩展：</p><p><strong>单元化扩展</strong>：按业务单元而非整体系统进行扩展，如用户服务独立于订单服务扩展<br/><strong>弹性伸缩</strong>：基于预测和实时指标动态调整实例数量，平衡性能与成本<br/><strong>分级扩展</strong>：核心服务与非核心服务差异化扩展策略，确保关键业务资源</p><h2>4 故障转移：从被动应对到主动容错</h2><h3>4.1 故障检测：快速发现的艺术</h3><p>有效的故障转移始于<strong>精准的故障检测</strong>，需要在及时性与准确性间找到平衡：</p><p><strong>多层次健康检查策略</strong>：</p><pre><code class="yaml"># Kubernetes就绪与存活探针配置
apiVersion: v1
kind: Pod
metadata:
  name: web-application
spec:
  containers:
  - name: web
    image: nginx:latest
    livenessProbe:
      httpGet:
        path: /health
        port: 8080
      initialDelaySeconds: 30
      periodSeconds: 10
      timeoutSeconds: 5
      failureThreshold: 3
    readinessProbe:
      httpGet:
        path: /ready  
        port: 8080
      initialDelaySeconds: 5
      periodSeconds: 5
      timeoutSeconds: 3
      failureThreshold: 1</code></pre><p><em>通过探针机制实现精准故障检测</em></p><p><strong>智能故障判定</strong>：结合多个指标（响应时间、错误率、资源使用率）综合判断，避免单指标误判。</p><h3>4.2 故障隔离：防止雪崩的屏障</h3><p>故障转移不仅是将流量从故障实例移走，更重要的是<strong>隔离故障影响</strong>：</p><p><strong>熔断器模式</strong>：在连续失败达到阈值时自动熔断，避免重试风暴</p><pre><code class="java">@Component
public class ProductService {
    @CircuitBreaker(name = "productService", 
                   fallbackMethod = "getProductFallback")
    public Product getProduct(Long productId) {
        return remoteProductService.getProduct(productId);
    }
    
    public Product getProductFallback(Long productId, Exception ex) {
        return cacheService.getBasicProduct(productId);
    }
}</code></pre><p><em>熔断器防止故障扩散</em></p><p><strong>隔离策略</strong>：</p><ul><li><strong>线程池隔离</strong>：不同服务使用独立线程池，避免资源竞争</li><li><strong>信号量隔离</strong>：控制并发调用数，防止资源耗尽</li><li><strong>超时控制</strong>：设置合理超时时间，避免长时间阻塞</li><li><strong>限流降级</strong>：流量超过阈值时自动降级，保护系统不被冲垮</li></ul><h3>4.3 流量切换：无缝转移的技术实现</h3><p>故障转移的核心是<strong>流量重路由</strong>，需要在不同层级实现协同：</p><p><strong>负载均衡器切换</strong>：健康检查失败时自动从路由表中移除故障节点</p><pre><code class="nginx">upstream backend {
    server 10.0.1.10:8080 max_fails=3 fail_timeout=30s;
    server 10.0.1.11:8080 max_fails=3 fail_timeout=30s;
    server 10.0.1.12:8080 backup;
    
    # 故障转移配置
    proxy_next_upstream error timeout http_500 http_502 http_503;
}</code></pre><p><em>负载均衡器实现自动故障转移</em></p><p><strong>服务网格流量管理</strong>：基于Istio等服务网格实现细粒度流量控制</p><pre><code class="yaml">apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: product-service
spec:
  host: product-service
  trafficPolicy:
    outlierDetection:
      consecutiveErrors: 5
      interval: 10s
      baseEjectionTime: 30s
      maxEjectionPercent: 50</code></pre><p><em>服务网格提供高级故障检测与转移能力</em></p><h2>5 三大支柱的协同设计</h2><h3>5.1 协同工作的架构模式</h3><p>无状态化、水平扩展与故障转移不是孤立技术，而是相互依赖的有机整体：</p><p><strong>无状态化赋能水平扩展</strong>：只有无状态设计，才能实现真正的无缝水平扩展<br/><strong>水平扩展增强故障转移</strong>：多实例为故障转移提供目标节点，使转移成为可能<br/><strong>故障转移保障水平扩展</strong>：在扩展过程中，故障转移确保个别实例故障不影响整体</p><p><strong>协同架构示例</strong>：</p><pre><code>用户请求 → 负载均衡器（故障检测/转移）
                   ↓
           无状态应用集群（水平扩展）
                   ↓  
          集中式状态存储（Redis集群）
                   ↓
          数据存储层（分片/主从）</code></pre><h3>5.2 协同设计的反模式与陷阱</h3><p><strong>伪无状态陷阱</strong>：表面无状态但实际存在隐性状态依赖（如本地缓存、文件存储）<br/><strong>不平衡扩展</strong>：计算层扩展但数据层成为瓶颈，或相反<br/><strong>过度转移</strong>：过于敏感的故障检测导致频繁转移，反而影响稳定性<br/><strong>单点转移</strong>：故障转移机制本身存在单点故障</p><h3>5.3 协同效能的度量体系</h3><p>三大支柱的协同效果需要可度量的指标验证：</p><p><strong>无状态化程度指标</strong>：</p><ul><li>实例启动时间（应小于30秒）</li><li>请求路由一致性（任意实例处理结果相同）</li><li>状态外部化比例（超过90%状态外部化）</li></ul><p><strong>水平扩展效能指标</strong>：</p><ul><li>线性扩展比（实例增加与性能提升比例）</li><li>扩展速度（从触发到完成扩展的时间）</li><li>资源利用率（避免过度或不足扩展）</li></ul><p><strong>故障转移质量指标</strong>：</p><ul><li>故障检测时间（秒级检测）</li><li>转移恢复时间（分钟级恢复）</li><li>转移成功率（超过99%的转移成功）</li></ul><h2>6 实战案例：电商平台高可用架构演进</h2><h3>6.1 单体架构的高可用改造</h3><p><strong>初始状态</strong>：单体应用，会话绑定，数据库单点</p><p><strong>改造步骤</strong>：</p><ol><li><strong>无状态化改造</strong>：用户会话外置到Redis集群</li><li><strong>水平扩展准备</strong>：应用容器化，配置负载均衡</li><li><strong>故障转移基础</strong>：数据库主从分离，读写分离</li><li><strong>渐进式迁移</strong>：先读流量，后写流量；先非核心功能，后核心功能</li></ol><p><strong>改造效果</strong>：可用性从99.9%提升至99.95%，扩展时间从小时级降至分钟级</p><h3>6.2 微服务架构的高可用深化</h3><p><strong>架构特点</strong>：服务拆分，分布式依赖，复杂调用链</p><p><strong>深化措施</strong>：</p><ul><li><strong>精细化无状态</strong>：API网关无状态化，业务服务按需无状态</li><li><strong>弹性扩展策略</strong>：基于业务优先级差异化扩展策略</li><li><strong>智能故障转移</strong>：基于调用链分析的精准故障定位和隔离</li></ul><p><strong>深化效果</strong>：可用性提升至99.99%，故障恢复时间从30分钟降至5分钟以内</p><h2>总结</h2><p>高可用架构的本质是通过<strong>无状态化、水平扩展、故障转移</strong>三大支柱的协同设计，构建能够<strong>容忍故障、快速恢复</strong>的弹性系统。</p><p><strong>核心洞察</strong>：</p><ol><li><strong>无状态化是基础</strong>：只有解耦状态与计算，才能实现真正的弹性</li><li><strong>水平扩展是手段</strong>：通过分布式架构将集中式风险分解为可管理单元</li><li><strong>故障转移是保障</strong>：在故障发生时快速隔离和恢复，最小化业务影响</li><li><strong>协同设计是关键</strong>：三大支柱必须统一设计，相互配合，而非孤立优化</li></ol><p><strong>成功的高可用架构</strong>不是追求零故障，而是确保在故障发生时：</p><ul><li>系统能够<strong>快速检测</strong>并<strong>定位</strong>问题</li><li>故障影响被<strong>有效隔离</strong>，防止扩散</li><li>业务流量被<strong>无缝转移</strong>到健康实例</li><li>系统能够<strong>自动恢复</strong>，减少人工干预</li></ul><p>在云原生时代，随着Kubernetes、服务网格等技术的成熟，高可用能力已经日益平台化、标准化。然而，技术选型只是起点，真正的挑战在于根据业务特点合理运用这些能力，构建既可靠又经济的高可用体系。</p><hr/><p><strong>📚 下篇预告</strong><br/>《CDN与边缘缓存策略——静态、动态与签名鉴权的组合拳》—— 我们将深入探讨：</p><ul><li>🌐 <strong>缓存层次体系</strong>：浏览器缓存、边缘缓存、中心缓存的协同分工</li><li>⚡ <strong>动态内容加速</strong>：边缘计算、智能路由与协议优化技术</li><li>🔐 <strong>安全缓存挑战</strong>：签名URL、权限验证与敏感内容保护</li><li>📊 <strong>缓存效能优化</strong>：命中率提升、失效策略与成本平衡</li><li>🚀 <strong>边缘架构演进</strong>：从内容分发到边缘计算的范式转变</li></ul><p><strong>点击关注，构建高效安全的全球内容分发体系！</strong></p><blockquote><p><strong>今日行动建议</strong>：</p><ol><li>评估现有应用的无状态化程度，制定状态外部化改造路线</li><li>设计水平扩展的容量规划与自动伸缩策略</li><li>建立多层级的故障检测与转移机制，定期进行故障演练</li><li>制定三大支柱协同效能的度量体系，持续优化高可用能力</li></ol></blockquote>]]></description></item><item>    <title><![CDATA[行情API的正确使用方式 瞌睡不醒 ]]></title>    <link>https://segmentfault.com/a/1190000047570874</link>    <guid>https://segmentfault.com/a/1190000047570874</guid>    <pubDate>2026-01-25 22:02:59</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>行情 API 的正确使用方式</h2><h3>常见问题</h3><p>在行情系统开发中，常见以下问题：</p><ul><li>首页行情列表每秒轮询 K 线接口获取最新价</li><li>所有页面都建立 WebSocket 连接以实现"实时更新"</li><li>系统启动时直接订阅 WebSocket，但未获取可用品种列表</li><li>页面切换时旧的 WebSocket 连接未关闭</li></ul><p>这些问题的根源在于缺乏正确的使用心智模型。<br/>即不清楚在什么阶段该使用什么接口。</p><p>大多数 API 文档会说明接口返回的数据结构。<br/>但不会说明接口的适用场景和使用时机。</p><hr/><h3>行情 API 的本质：数据分层</h3><p>行情 API 不是接口的集合，而是一套数据分层系统。</p><p>构建行情系统时，系统在不同阶段对数据的需求完全不同：</p><h4>1. 数据使用阶段</h4><ul><li><strong>启动阶段</strong>：系统需要获取可交易品种列表</li><li><strong>展示阶段</strong>：页面需要显示当前价格</li><li><strong>实时阶段</strong>：需要在价格变化时主动推送</li></ul><h4>2. 数据类型</h4><ul><li><strong>快照</strong>：当前时刻的价格、涨跌幅（适合列表、首页）</li><li><strong>历史</strong>：过去一段时间的价格走势（适合图表、回测）</li><li><strong>持续流</strong>：价格变化时主动推送（适合实时盯盘、交易执行）</li></ul><h4>3. 系统复杂度</h4><ul><li>REST API：简单、稳定、易维护，需要主动轮询</li><li>WebSocket：实时、高效，但需要处理连接管理、重连、心跳</li></ul><p>理解这三个维度，可以明确每个接口的适用场景。</p><hr/><h3>行情 API 的分层设计</h3><h4>1. 可用交易品种（Symbols）</h4><p>系统启动的第一步是获取可用品种列表。</p><p>硬编码品种代码会导致以下问题：</p><ul><li>退市品种无法及时移除</li><li>新上市品种无法及时添加</li></ul><p>建议在系统启动时调用品种列表接口，并缓存结果。</p><p><strong>多市场统一命名的价值</strong></p><p>统一的命名规则可以用同一套代码逻辑处理不同市场的数据：</p><ul><li>港股：<code>700.HK</code>、<code>9988.HK</code></li><li>美股：<code>AAPL.US</code>、<code>TSLA.US</code></li><li>外汇：<code>EURUSD</code>、<code>GBPUSD</code></li></ul><p>这避免了为每个市场编写适配层。</p><p><strong>接口示例</strong></p><pre><code class="bash">GET /v1/symbols/available?market=HK&amp;limit=10</code></pre><p><strong>使用建议</strong></p><ul><li>系统启动时调用一次，缓存结果</li><li>不要在每次查询行情前调用此接口</li><li>定期更新建议频率为每天一次</li></ul><p><img width="723" height="488" referrerpolicy="no-referrer" src="/img/bVdnLvU" alt="多市场统一 symbol 示意图" title="多市场统一 symbol 示意图"/></p><hr/><h4>2. Ticker（实时快照）</h4><p>Ticker 接口适用于大部分"显示当前价格"的场景。<br/>行情列表页、首页概览、定时刷新的看板。</p><p>使用 K 线接口获取最新价存在以下问题：</p><ul><li>K 线接口返回的数据结构更复杂</li><li>需要处理时间对齐问题</li><li>无法一次查询多个品种</li></ul><p>Ticker 接口的优势：</p><ul><li>返回数据轻量</li><li>一次请求可查询多个品种（通常支持 50 个左右）</li><li>不需要处理时间对齐问题</li></ul><p><strong>接口示例</strong></p><pre><code class="bash">GET /v1/market/ticker?symbols=700.HK,AAPL.US</code></pre><p><strong>返回数据</strong></p><pre><code class="json">{
  "code": 0,
  "message": "success",
  "data": [
    {
      "symbol": "700.HK",
      "last_price": "602.5",
      "volume_24h": "16003431",
      "high_24h": "606",
      "low_24h": "598",
      "timestamp": 1768982936000
    }
  ]
}</code></pre><p><strong>使用建议</strong></p><p>只要不是需要实时价格跳动的场景。<br/>Ticker + 定时刷新（5-10 秒）即可满足需求。</p><h3><img width="723" height="488" referrerpolicy="no-referrer" src="/img/bVdnLvV" alt="Ticker 适用场景示意图" title="Ticker 适用场景示意图" loading="lazy"/></h3><h4>3. K 线（结构化历史）</h4><p>K 线接口的核心参数是 <code>interval</code>（时间间隔）。<br/>决定了数据的颗粒度。</p><p>不同的分析场景对数据颗粒度的要求不同：</p><ul><li><code>1m</code>：1 分钟 K 线，适合短线交易、实时图表</li><li><code>1h</code>：1 小时 K 线，适合日内分析</li><li><code>1d</code>：日 K 线，适合中长期分析、回测</li></ul><p><strong>接口示例</strong></p><pre><code class="bash">GET /v1/market/kline?symbol=AAPL.US&amp;interval=1d&amp;limit=30</code></pre><p><strong>使用建议</strong></p><ul><li>图表展示：使用 <code>limit</code> 参数（如"显示最近 30 天"）</li><li>历史回测：使用时间范围参数（如"2023 年 1 月到 3 月的数据"）</li></ul><h3><img width="723" height="488" referrerpolicy="no-referrer" src="/img/bVdnLvZ" alt="K线 vs 实时数据对比图" title="K线 vs 实时数据对比图" loading="lazy"/></h3><h4>4. WebSocket（实时流）</h4><p>WebSocket 的代价包括：</p><ul><li>维护长连接（心跳、重连、异常处理）</li><li>处理订阅管理</li><li>处理消息队列</li><li>处理网络波动</li></ul><p><strong>适用场景</strong></p><ul><li>实时盯盘（延迟要求在秒级以内）</li><li>价格预警（价格触发阈值时需要立即通知）</li><li>高频数据监控（需要毫秒级数据更新）</li></ul><p><strong>不适用场景</strong></p><ul><li>行情列表页</li><li>历史图表</li><li>低频监控</li></ul><p>以上场景使用 REST API + 定时刷新即可。</p><p><strong>接口示例</strong></p><pre><code class="javascript">const ws = new WebSocket('wss://api.example.com/v1/realtime?api_key=YOUR_API_KEY');

ws.onopen = () =&gt; {
  ws.send(JSON.stringify({
    cmd: 'subscribe',
    data: { channel: 'ticker', symbols: ['700.HK'] }
  }));
};</code></pre><p><strong>设计限制</strong></p><p>外汇品种通常仅支持 ticker 频道（不支持 depth 和 trade）。<br/>因为外汇市场是 OTC 市场，没有集中的订单簿。<br/>股票和加密货币支持 ticker、depth、trade 三种频道。</p><h3><img width="723" height="488" referrerpolicy="no-referrer" src="/img/bVdnLv0" alt="REST vs WebSocket 使用边界图" title="REST vs WebSocket 使用边界图" loading="lazy"/></h3><h3>完整使用路径示例</h3><p>以港股行情监控系统为例：</p><h4>Step 1：启动时拉取可用品种</h4><pre><code class="bash">GET /v1/symbols/available?market=HK&amp;limit=100</code></pre><p>目的：获取系统支持的港股品种，缓存到本地。</p><hr/><h4>Step 2：页面展示用 Ticker + K 线</h4><p><strong>首页行情列表</strong></p><pre><code class="bash">GET /v1/market/ticker?symbols=700.HK,9988.HK,3690.HK</code></pre><p><strong>图表展示</strong></p><pre><code class="bash">GET /v1/market/kline?symbol=700.HK&amp;interval=1d&amp;limit=30</code></pre><p><strong>刷新策略</strong>：每 5-10 秒刷新一次 Ticker。<br/>K 线按需加载（用户切换图表时才加载）。</p><p>刷新频率建议：</p><ul><li>太快（如每秒刷新）会增加服务器压力</li><li>太慢（如 30 秒）数据实时性不足</li><li>5-10 秒是平衡点</li></ul><hr/><h4>Step 3：关键模块用 WebSocket</h4><p>仅在需要实时推送的场景建立 WebSocket 连接：</p><pre><code class="javascript">ws.send(JSON.stringify({
  cmd: 'subscribe',
  data: { channel: 'ticker', symbols: ['700.HK'] }
}));</code></pre><p>退出实时监控页面时，必须取消订阅并关闭连接。<br/>否则会导致连接数超限，影响新用户建立连接。</p><h3><img width="723" height="852" referrerpolicy="no-referrer" src="/img/bVdnLv1" alt="完整使用路径流程图" title="完整使用路径流程图" loading="lazy"/></h3><h3>常见错误</h3><h4>1. 过度使用 WebSocket</h4><p><strong>错误做法</strong>：系统启动就建立 WebSocket，订阅所有品种。</p><p><strong>问题</strong>：首页显示 50 个品种的行情。<br/>订阅所有品种会导致用户量上升时服务器连接数超限。</p><p><strong>正确做法</strong>：大部分场景使用 REST API。<br/>仅在需要实时推送的模块使用 WebSocket。</p><hr/><h4>2. K 线接口滥用</h4><p><strong>错误做法</strong>：每秒调用 K 线接口获取最新价。</p><p><strong>问题</strong>：K 线接口是为历史数据设计的。<br/>不是为实时价格设计的。<br/>频繁调用浪费资源，且可能因时间对齐问题导致数据不准确。</p><p><strong>正确做法</strong>：K 线用于历史数据和图表。<br/>实时价格使用 Ticker 或 WebSocket。</p><hr/><h4>3. Symbol 不缓存</h4><p><strong>错误做法</strong>：每次查询行情前都调用 <code>/v1/symbols/available</code>。</p><p><strong>问题</strong>：可用品种列表通常不会频繁变化。<br/>每次都查询是浪费。</p><p><strong>正确做法</strong>：启动时调用一次，缓存结果。<br/>定期（如每天）更新。</p><hr/><h4>4. Interval 选择不当</h4><p><strong>错误做法</strong>：不管什么场景都使用 <code>1m</code>（1 分钟 K 线）。</p><p><strong>问题</strong>：1 分钟 K 线数据量大。<br/>如果只是查看"最近一个月的走势"，使用日 K 线即可。<br/>使用 1 分钟 K 线浪费带宽，增加前端渲染压力。</p><p><strong>正确做法</strong>：</p><ul><li>实时图表：<code>1m</code> 或 <code>5m</code></li><li>日内分析：<code>1h</code></li><li>中长期分析：<code>1d</code></li></ul><hr/><h4>5. 混淆行情 API 与交易 API</h4><p><strong>错误做法</strong>：直接使用行情数据做下单决策。<br/>不考虑延迟和数据完整性。</p><p><strong>问题</strong>：行情 API 提供的是市场数据。<br/>主要用于展示和分析。<br/>交易操作（下单、撤单）需要对接交易所的交易 API。</p><p><strong>正确做法</strong>：行情 API 用于数据展示和策略分析。<br/>交易操作使用交易 API。</p><h3><img width="723" height="488" referrerpolicy="no-referrer" src="/img/bVdnLv6" alt="常见错误示意图" title="常见错误示意图" loading="lazy"/></h3><h3>总结</h3><p>使用行情 API 时，首先明确当前处于哪个阶段：</p><ul><li>启动系统</li><li>展示页面</li><li>实时监控</li></ul><p>根据阶段选择合适的接口。<br/>可以避免系统设计不合理导致的性能问题和维护困难。</p><hr/><h3>系列说明</h3><p>本文是「行情 API 的工程化使用方式」系列的第一篇。<br/>后续将继续讲解：</p><ul><li>WebSocket 实战：连接管理、心跳机制、数据补偿</li><li>K 线数据的正确使用方式：interval 选择、时间对齐、数据缓存策略</li><li>行情系统的性能优化实践：从接口调用到前端渲染的完整优化方案</li><li>多市场行情数据的统一处理：如何用一套代码处理港股、美股、外汇的差异</li></ul><hr/><h3>参考资料</h3><p>本文基于 TickDB API v1.0.0 撰写。<br/>完整接口参数说明、错误码处理、API 参考：</p><ul><li>GitHub：<a href="https://link.segmentfault.com/?enc=Tgclobei4mXX9MrZdCKLtw%3D%3D.pbC1LPBO4J84pR6eIrqvg7scrhFOEYCQfzwOpAPOroQ%3D" rel="nofollow" target="_blank">https://github.com/TickDB</a></li><li>文档：<a href="https://link.segmentfault.com/?enc=ob%2BiUZFJgoaz%2FLxhMIMk4w%3D%3D.6VXrdTcJl7FNxGIR0h0Z1AWE3e2WzoyL%2FZFYoZmPXf0%3D" rel="nofollow" target="_blank">https://docs.tickdb.ai</a></li></ul>]]></description></item><item>    <title><![CDATA[VU-Icons：打造极致体验的 Vue3 &amp; UniApp 双端 SVG 图标库 活泼的领]]></title>    <link>https://segmentfault.com/a/1190000047570948</link>    <guid>https://segmentfault.com/a/1190000047570948</guid>    <pubDate>2026-01-25 22:02:22</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在现代前端开发中，图标库是必不可少的基础设施。然而，在 Vue 3 和 UniApp 的跨端开发场景下，我们常常面临各种痛点：</p><ul><li>😭 <strong>兼容性噩梦</strong>：Web 端好好的 SVG，到了小程序里就显示不出来。</li><li>📦 <strong>体积臃肿</strong>：引入一个图标库，打包体积瞬间激增几兆。</li><li>😫 <strong>开发体验差</strong>：没有类型提示，组件名靠猜，属性全靠试。</li><li>🎨 <strong>样式难调</strong>：想改个颜色、大小，还要写一堆 CSS 覆盖。</li></ul><p>如果你也遇到过这些问题，那么 <strong>VU-Icons</strong> 正是你一直在寻找的解决方案。</p><hr/><h3>🌟 VU-Icons 是什么？</h3><p>VU-Icons 是一个专为 <strong>Vue 3</strong> 和 <strong>UniApp</strong> 打造的高质量 SVG 图标组件库。它不仅轻量、灵活，更完美解决了跨端兼容性问题，让你的开发效率倍增。</p><blockquote>🌐 <strong>官网体验</strong>：<a href="https://link.segmentfault.com/?enc=bZOTO2Mw7UqLRp%2BsEwKjEQ%3D%3D.sNXE746LQMR5TVqmTay4%2Fcc9VY%2F7Aj6ZGvchEk%2BHOcg%3D" rel="nofollow" target="_blank">https://vuicons.qiboz.top/</a>  <br/>📦 <strong>Gitee</strong>：<a href="https://link.segmentfault.com/?enc=eRpvqc6ZFHT0MFyw%2BYgJIA%3D%3D.kcBAHPC3fC%2BzxHzlhGN4SzL%2FUYxWJoBnBv3pUAdQ3w7Yq%2FW2TAUHDJMtF9ptaJZ8" rel="nofollow" target="_blank">https://gitee.com/zhangqibo920/uv-icons</a>  <br/>📦 <strong>GitHub</strong>：<a href="https://link.segmentfault.com/?enc=mmwJT3n3e8D%2BxNwOVRsK%2Bw%3D%3D.ANDCiDBKAvWOEjaa91nL5In8qvbvA6vJdzjebvGwIlHkgsda%2FmQarOawqfNT0tMp" rel="nofollow" target="_blank">https://github.com/zhangqibo920/uv-icons</a></blockquote><hr/><h3>🔥 核心优势：为什么选择 VU-Icons？</h3><h4>1. 双端统一，无缝兼容</h4><p>VU-Icons 的最大杀手锏是<strong>同时支持 Vue 3 和 UniApp</strong>。</p><ul><li><strong>Vue 3</strong>：原生 SVG 渲染，性能极致。</li><li><strong>UniApp</strong>：针对非 H5 平台（如微信小程序、App）进行了特殊优化，使用 <code>rich-text</code> 方案完美渲染 SVG，彻底告别“图标消失术”。</li></ul><h4>2. 真正的按需引入 (Tree Shaking)</h4><p>担心引入图标库导致包体积变大？VU-Icons 完美支持 <strong>Tree Shaking</strong>。  <br/>无论库里有多少个图标，只要你只用了一个 <code>&lt;VuHome /&gt;</code>，打包时就只会包含这一个图标的代码。你的应用体积，由你掌控。</p><h4>3. 极致的开发体验 (TypeScript)</h4><p>作为一个现代组件库，<strong>TypeScript</strong> 支持是标配。  <br/>VU-Icons 内置了完整的 <code>.d.ts</code> 类型声明。在 VS Code 中，你能获得完美的组件名自动补全和属性提示，写代码就像在填空一样丝滑。</p><h4>4. 高度可定制</h4><p>告别繁琐的 CSS 覆盖，VU-Icons 提供了直观的 Props：</p><ul><li><strong><code>size</code></strong>：支持数字（如 <code>24</code>）和字符串（如 <code>'2rem'</code>），响应式布局更轻松。</li><li><strong><code>color</code></strong>：支持 hex、rgb、颜色名，甚至默认继承父级 <code>currentColor</code>。</li><li><strong><code>spin</code></strong>：想要一个 Loading 效果？加上 <code>spin</code> 属性，任何图标都能变成旋转的加载动画！</li></ul><hr/><h3>快速上手</h3><h4>第一步：安装</h4><pre><code>npm install vu-icons
# 或者
yarn add vu-icons</code></pre><h4>第二步：使用（Vue 3 项目）</h4><pre><code>&lt;script setup lang="ts"&gt;
// 直接按需引入，无需额外配置
import { VuHome, VuSearch, VuSettings } from 'vu-icons'
&lt;/script&gt;

&lt;template&gt;
  &lt;!-- 基础用法 --&gt;
  &lt;VuHome /&gt;
  
  &lt;!-- 自定义颜色和尺寸 --&gt;
  &lt;VuSearch color="#1890ff" :size="32" /&gt;
  
  &lt;!-- 一键开启旋转动画 --&gt;
  &lt;VuSettings spin color="#52c41a" /&gt;
&lt;/template&gt;</code></pre><h4>第三步：使用（UniApp 项目）</h4><pre><code>&lt;script setup lang="ts"&gt;
// 注意：UniApp 请从专用路径引入以确保兼容性
import { VuHome, VuUser } from 'vu-icons/uniapp'
&lt;/script&gt;

&lt;template&gt;
  &lt;view&gt;
    &lt;VuHome :size="40" color="#333" /&gt;
    &lt;VuUser /&gt;
  &lt;/view&gt;
&lt;/template&gt;</code></pre><hr/><h3>进阶玩法</h3><h4>动态图标状态</h4><p>结合 Vue 的响应式特性，你可以轻松制作交互效果：</p><pre><code>&lt;script setup&gt;
import { ref } from 'vue'
import { VuRefresh } from 'vu-icons'

const loading = ref(false)
const refresh = () =&gt; {
  loading.value = true
  setTimeout(() =&gt; loading.value = false, 2000)
}
&lt;/script&gt;

&lt;template&gt;
  &lt;button @click="refresh"&gt;
    &lt;!-- 点击时自动旋转 --&gt;
    &lt;VuRefresh :spin="loading" /&gt;
    刷新列表
  &lt;/button&gt;
&lt;/template&gt;</code></pre><hr/><h3>结语</h3><p>VU-Icons 致力于成为 Vue 3 生态中最简单、最纯粹的图标解决方案。如果你厌倦了配置繁琐的 Font Icon，或者受够了跨端开发的兼容性坑，不妨试试 VU-Icons。</p><p>如果你觉得不错，欢迎在 Gitee 上点个 <strong>Star</strong> 支持一下！</p><p>👉 <strong>立即访问官网</strong>：<a href="https://link.segmentfault.com/?enc=qYJFyhn2USiZTr%2BRD1wweg%3D%3D.lZVTkFgr6zwkzwkXOXs%2BFNMWFtETdIyMYBf7Vj128K8%3D" rel="nofollow" target="_blank">https://vuicons.qiboz.top/</a></p>]]></description></item><item>    <title><![CDATA[我担心，程序员和 AI 的蜜月期要结束了 码农张思壮 ]]></title>    <link>https://segmentfault.com/a/1190000047571043</link>    <guid>https://segmentfault.com/a/1190000047571043</guid>    <pubDate>2026-01-25 22:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>如果说 2025 还是 AI 编程的探索期，程序员可以一边喝着咖啡，一边看 AI 如何实现。</p><p>到了 2026 马年，一定是快马加鞭的一年，从探索转变为生产力的提升，只不过鞭子不是抽向 AI，而是抽向程序员。</p><h2>成本</h2><p>2025 年公司大力投入 AI 编程，GitHub Copilot，Cursor，Claude Code 都可以用。每月 200 美元的额度也很大方，甚至不够用还可以提额。</p><p>这个成本如果由个人承担，的确是笔不小的开销。但对公司来说，这笔账太划算了。</p><p>假设一个程序员的月薪是 1.4 万，只要使用 AI 能提效 10%，这笔投入也是值得的。更何况大部分程序员月薪会更高，只提效 5%，都是赚的。</p><p>再换一个角度，新招一个月薪 2.8 万的人还是让 20 个员工用上 AI 编程，一定是后者回报更大。</p><h2>产出</h2><p>公司多了投入，自然会要求产出，尤其是已经过了探索阶段。</p><p>原来评审时，可以说有技术难点需要调研，也可以说自己手上有别的事，做不过来，毕竟人力就是原来的限制，再无聊的代码也需要人一行一行打上去。</p><p>但有了 AI 之后，这些限制都不是问题了，至少在领导那里是这样想的。有难题，就让 AI 来解决。做不过来，就多开几个 AI ，人会累，AI 又不会。</p><p>如果你想反驳说 AI 也不是那么好用，领导可能会让你回去反思一下，为什么你觉得不好用。</p><p>而且也更容易内卷了，比如团队中有一个人 AI 用的很好，如果跟他有工作上的配合，那进度也得与他保持一致。再一次印证了，<strong>AI 并不会淘汰人，而是会用 AI 的人淘汰掉不会用 AI 的人</strong>。</p><p>AI 并没有减轻程序员的工作量，反而换了一种方式，成了进一步压榨程序员的工具。</p><h2>压榨</h2><p>程序员的编码工作可以简单地拆成编和码两部分。编就是构思如何实现，这是脑力劳动。码就是敲击键盘打码，这是体力劳动。工作原本是脑力与体力交替进行的，脑子累了可以手敲会代码，手累了可以想想方案。</p><p>但有了 AI，程序员的工作被彻底改变了。AI 可以做大部分规划工作以及全部实现工作，而程序员只需要确保 AI 没有跑偏。</p><p>程序员变成了一个分时处理的 CPU，哪个 AI 窗口需要确认了，就切过去看一下。看完你的看你的，一刻也不停歇。</p><p><strong>表面上是程序员在使用 AI，实际上是通过 AI 在压榨程序员最后一点价值。</strong></p><p>工作变成了纯纯的脑力劳动，再也不会有那种不用动脑，敲着无聊代码的轻松时间了。</p><h2>考核</h2><p>公司每天会统计每个人的 AI 用量，也会有总的排名，但如何考核程序员的工作产出始终是一个难题。</p><p>再傻的领导也不会让大家卷 AI 用量，毕竟程序员有无数的办法烧掉更多的 token。结果就是，产出提没提高不知道，成本一定是在往上涨的。</p><p>在没有找到一个很好的考核标准前，我们要尽快适应新的工作方式。</p><h2>应对</h2><p>作为程序员，在适应了 AI 编程之后，下一步就是改变原有的工作方式。</p><p>之前的工作大多是单线进行的，设计、开发、测试、上线。而有了 AI，可以多线并行。你不再是一个单打独斗的程序员，而是一个带领着 AI 员工的 team leader，这个团队的大小完全取决于你拆解、分配、处理任务的能力。</p><p>不要再把注意力只放在如何写好代码上，而是要关注如何管理好这个团队。</p><p>这不仅仅是为了适应工作的压力，更是一次职业形态的进化。蜜月期也许结束了，但对于那些善于驾驭 AI 的人来说，真正属于超级个体的黄金时代，才刚刚开始。</p>]]></description></item><item>    <title><![CDATA[为什么标准化要用均值0和方差1？ 本文系转载，阅读原文
https://avoid.overfit.]]></title>    <link>https://segmentfault.com/a/1190000047570999</link>    <guid>https://segmentfault.com/a/1190000047570999</guid>    <pubDate>2026-01-25 21:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571001" alt="" title=""/><br/>为什么标准化要把均值设为0、方差设为1？</p><p>先说均值。均值就是平均数，所有观测值加起来除以个数。</p><p>μ是均值，n是数据点总数，xᵢ是每个数据点，所以均值就是数据的重心位置。比如均值是20，那20就是平衡点。这不是说所有点到20的距离相等而是说两边的"重量"刚好在20这个位置抵消掉。</p><p>而方差衡量的是数据有多分散，定义是每个值与均值偏差的平方的平均值。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047571002" alt="" title="" loading="lazy"/><br/>n是数据点总数，xᵢ是每个数据点，μ是均值。</p><p><strong>那均值为0有什么用？</strong></p><p>可以把数据想象成坐标系里的一团“点云”。每个值减去均值（x — μ）之后，整团云就被平移到了原点位置。数据不再飘在某个角落而是以原点为中心分布。</p><p>这对很多机器学习算法都有好处，尤其是用梯度下降的时候。数据居中之后优化过程更平衡、收敛也更快。因为特征要是一开始就偏离原点很远，训练起来会麻烦不少。</p><p><strong>那方差为1呢？</strong></p><p>这是为了防止某个特征"欺负"其他特征。</p><p>举个例子：年龄和薪资两个特征，年龄范围10-70，薪资范围10,000-70,000。直接喂给模型的话，模型会觉得薪资比年龄重要1000倍（数字大嘛）。但这两个特征本来是独立的，凭什么薪资就更重要？</p><p>所以标准化就是除以标准差，让所有特征的方差都变成1。这样年龄和薪资就在同一个量级上了，变化幅度差不多。年龄有个小波动，不会因为薪资数字大就被模型无视掉。</p><p>可视化效果：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047571003" alt="" title="" loading="lazy"/></p><p>标准化之前，特征1（红色，小尺度）和特征2（蓝色，大尺度）放一起，红色那条几乎看不见。标准化之后，两个特征尺度一致，都能清晰显示出来。模型终于可以公平对待它们了。</p><p>什么时候需要标准化？逻辑回归、神经网络、KNN这类用梯度下降的算法，标准化影响最大。</p><p>总结一下：</p><p>均值为0让数据居中，方差为1让特征尺度统一。两者配合，算法学得更快，也不会偏心某个特征。至于什么时候该用标准化、什么时候该用MinMaxScaler，老实说我也还在摸索。</p><p><a href="https://link.segmentfault.com/?enc=UwB3O9rSsakmLrAQD9Lf6Q%3D%3D.8VlnqjCkyUWIP3WivT2jAr%2FePQ0CQcb6boHvqvoIqrgW6RUWsqXx1SRr5Z6c03QfrXCgOciek%2B3m7bevkyrrkw%3D%3D" rel="nofollow" target="_blank">https://avoid.overfit.cn/post/957b1b35bc1047e185dab369ae8d84ed</a></p><p>作者:vaishnavi</p>]]></description></item><item>    <title><![CDATA[【2026计算机毕设】蔬菜识别系统~Python+深度学习+人工智能+算法模型+TensorFlow]]></title>    <link>https://segmentfault.com/a/1190000047570902</link>    <guid>https://segmentfault.com/a/1190000047570902</guid>    <pubDate>2026-01-25 20:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>项目介绍</h2><p>基于深度学习的蔬菜识别Web应用，旨在通过人工智能技术实现对常见蔬菜的快速、准确识别。系统采用B/S架构设计，后端使用Python Flask框架构建RESTful API接口，前端可通过跨域调用实现图像上传与识别功能。核心算法采用ResNet50卷积神经网络模型，该模型在ImageNet数据集上预训练后，针对土豆、大白菜、大葱、莲藕、菠菜、西红柿、韭菜、黄瓜等八种常见蔬菜进行微调训练，实现了高精度的蔬菜分类识别。系统功能模块完整，包括用户注册登录、JWT身份认证、图像上传识别、识别历史记录查询、公告管理等核心功能。同时系统支持用户权限管理，区分普通用户和管理员角色，管理员可对公告进行系统化管理。整体系统具有良好的可扩展性、易用性和实用性，能够为用户提供便捷的蔬菜识别服务。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047570904" alt="图片" title="图片"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047570905" alt="图片" title="图片" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047570906" alt="图片" title="图片" loading="lazy"/></p><h2>选题背景与意义</h2><p>随着人工智能技术的快速发展，计算机视觉在农业领域的应用日益广泛。蔬菜识别作为智能农业的重要组成部分，在农产品分类、智能售货机、自动分拣系统、食品安全追溯等领域具有重要的应用价值。传统的蔬菜分类依赖人工识别，存在效率低、成本高、易出错等问题。本选题基于深度学习技术，设计并实现了一个基于ResNet50算法的蔬菜识别系统，通过训练高质量的深度神经网络模型，实现了对多种常见蔬菜的自动化识别。该系统的设计与实现不仅探索了深度学习在图像分类领域的应用实践，也为智慧农业的发展提供了技术参考。从实际应用角度看，该系统能够显著提高蔬菜分类识别的准确性和效率，降低人工成本，在超市自助结算、智能仓储管理、农业物联网等场景中具有广阔的应用前景，具有重要的理论意义和实用价值。</p><h2>关键技术栈：resnet50算法</h2><p>ResNet50（残差网络50层）是本系统的核心算法组件，该算法由微软研究院提出，通过引入残差学习机制有效解决了深层神经网络训练中的梯度消失和梯度爆炸问题。ResNet50采用50层的网络结构，包含多个残差块，每个残差块使用跳跃连接（shortcut connection）将输入直接传递到输出层，使得网络能够学习到残差映射而非原始映射，从而显著提升了深层网络的训练效果。本系统利用TensorFlow深度学习框架加载预训练的ResNet50模型，通过迁移学习的方式对蔬菜数据集进行微调训练。在图像预处理阶段，将上传的蔬菜图片统一调整为224×224像素尺寸，并进行归一化处理；模型推理阶段，通过softmax激活函数输出各个类别的预测概率，最终返回置信度最高的蔬菜类别及其置信度值。ResNet50算法具有模型结构清晰、参数量适中、识别准确率高、推理速度快等优点，非常适合部署在Web应用中实现实时图像识别任务。</p><h2>技术架构图</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047570907" alt="图片" title="图片" loading="lazy"/></p><h2>系统功能模块图</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047570908" alt="图片" title="图片" loading="lazy"/></p><h2>演示视频 and 完整代码 and 安装</h2><p>地址：<a href="https://link.segmentfault.com/?enc=egJdovUFhh69UjQNWgdEuQ%3D%3D.DWVwRzRR6eWIaHFLkvFLkzkOLyaV9GqqjIiY040cqz0cORQvOplYpurgFy5JoKNDYlNiGm013gPzjwH7hmFJ%2FA%3D%3D" rel="nofollow" target="_blank">https://www.yuque.com/ziwu/qkqzd2/wvan4wk60bb5belp</a></p>]]></description></item><item>    <title><![CDATA[【节点】[NormalVector节点]原理解析与实际应用 SmalBox ]]></title>    <link>https://segmentfault.com/a/1190000047570824</link>    <guid>https://segmentfault.com/a/1190000047570824</guid>    <pubDate>2026-01-25 19:01:54</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <blockquote><a href="https://link.segmentfault.com/?enc=lJR2MRifKRYHnRRnzDpdtA%3D%3D.l74JNYDNQsEot%2F907egZnHrOHjEOeYta1E4Jx5%2F6tkSt4PuqoqYq0KyTjNefmTM3AkicMZikf0wKu5W7jMltkKDi3jJ1vCo0gEjaqPWy%2Bpp7pnMh7HHqyt2VHaVjCmk8MVFjdxA11csf60AW8KnjJulEGj%2BzKss3alxZjNPrhtIQxOrVaI%2B81Ov%2F1cDwZzh5tKgBzd4ehOdcZqW8D8uMYAcaIrWUtRdNp9Vivik6N0g%3D" rel="nofollow" target="_blank">【Unity Shader Graph 使用与特效实现】</a><strong>专栏-直达</strong></blockquote><p>在Unity的Shader Graph中，NormalVector节点是一个基础且重要的工具，它允许着色器访问网格的法线矢量信息。法线矢量在计算机图形学中扮演着关键角色，它定义了表面的朝向，是光照计算、材质表现和各种视觉效果的基础。</p><h2>节点概述</h2><p>NormalVector节点为着色器编写者提供了获取网格法线数据的便捷途径。无论是顶点法线还是片元法线，这个节点都能让开发者轻松地在不同的坐标空间中操作这些数据。通过简单的参数设置，就可以将法线矢量转换到所需的坐标空间，大大简化了复杂着色器的开发过程。</p><p>法线矢量的本质是垂直于表面的单位向量，在三维空间中表示为(x, y, z)坐标。在Shader Graph中，这些数据通常来自3D模型的顶点数据，或者通过法线贴图等技术进行修改和增强。</p><h2>参数详解</h2><h3>Space参数</h3><p>Space参数决定了法线矢量输出的坐标空间，这是NormalVector节点最核心的功能。不同的坐标空间适用于不同的着色场景和计算需求。</p><ul><li><strong>Object空间</strong>：也称为模型空间，这是法线数据最原始的存储空间。在Object空间中，法线相对于模型本身的坐标系定义，不考虑模型的旋转、缩放或平移变换。当模型发生变换时，Object空间中的法线不会自动更新，需要手动进行相应的变换计算。</li><li><strong>View空间</strong>：也称为相机空间或眼睛空间，在这个空间中，所有坐标都是相对于相机的位置和方向定义的。View空间的原点通常是相机的位置，Z轴指向相机的观察方向。这个空间特别适合与视角相关的效果，如边缘光、反射和折射。</li><li><strong>World空间</strong>：World空间中的坐标是相对于场景的世界坐标系定义的。无论模型如何移动或旋转，World空间提供了统一的参考框架。这个空间常用于光照计算、阴影生成和全局效果。</li><li><strong>Tangent空间</strong>：这是一个特殊的局部空间，主要用于法线贴图。在Tangent空间中，法线是相对于表面本身定义的，Z轴与表面法线对齐，X轴与切向量对齐，Y轴与副法线对齐。这种表示方法使得法线贴图可以在不同朝向的表面上重复使用。</li></ul><p>选择正确的坐标空间对着色器的正确性和性能至关重要。错误的空间选择可能导致光照计算错误、视觉效果异常或性能下降。</p><h2>端口信息</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047570826" alt="" title=""/></p><p>NormalVector节点只有一个输出端口：</p><ul><li><strong>Out</strong>：输出类型为Vector 3，表示三维矢量。这个端口输出的是根据Space参数选择在对应坐标空间中的法线矢量。输出值通常是归一化的单位矢量，但在某些情况下（如使用非统一缩放时）可能需要重新归一化。</li></ul><h2>使用场景与示例</h2><h3>基础光照计算</h3><p>法线矢量的一个主要应用是光照计算。在Lambert光照模型中，表面亮度取决于光线方向与表面法线之间的夹角。</p><pre><code>HLSL

// 简化的Lambert光照计算
float3 lightDir = normalize(_WorldSpaceLightPos0.xyz);
float3 worldNormal = NormalVector节点输出（World空间）;
float NdotL = max(0, dot(worldNormal, lightDir));
float3 diffuse = _LightColor0 * NdotL;</code></pre><p>在这个示例中，我们首先获取世界空间中的法线矢量和光线方向，然后计算它们的点积。点积结果决定了表面接收到的光照强度，这是大多数基础光照模型的核心计算。</p><h3>法线贴图应用</h3><p>法线贴图是现代实时渲染中增强表面细节的关键技术。NormalVector节点在应用法线贴图时起着桥梁作用。</p><pre><code>HLSL

// 法线贴图应用流程
float3 tangentNormal = tex2D(_NormalMap, uv).xyz * 2 - 1; // 从[0,1]转换到[-1,1]
float3 worldNormal = NormalVector节点输出（World空间）;
// 使用TBN矩阵将切线空间法线转换到世界空间
float3x3 TBN = float3x3(
    IN.tangent.xyz,
    cross(IN.normal, IN.tangent.xyz) * IN.tangent.w,
    IN.normal
);
float3 mappedNormal = mul(TBN, tangentNormal);</code></pre><p>这个示例展示了如何将切线空间中的法线贴图数据转换到世界空间。首先从法线贴图中采样并调整数值范围，然后使用TBN（切线-副切线-法线）矩阵进行空间转换。</p><h3>边缘检测与轮廓光</h3><p>利用View空间中的法线可以创建各种与视角相关的效果，如边缘光和轮廓检测。</p><pre><code>HLSL

// 边缘光效果
float3 viewNormal = normalize(mul((float3x3)UNITY_MATRIX_V, NormalVector节点输出（World空间）));
float3 viewDir = normalize(UnityWorldToViewPos(IN.worldPos));
float rim = 1 - abs(dot(viewNormal, viewDir));
float rimLight = pow(rim, _RimPower) * _RimIntensity;</code></pre><p>在这个示例中，我们首先将世界空间法线转换到View空间，然后计算法线与视角方向的点积。当表面几乎垂直于视角方向时（即边缘处），点积接近0，从而产生边缘光效果。</p><h3>环境遮挡与全局光照</h3><p>法线信息对于环境遮挡和全局光照计算也至关重要。</p><pre><code>HLSL

// 简化的环境遮挡
float3 worldNormal = NormalVector节点输出（World空间）;
float ambientOcclusion = 1.0;

// 基于法线方向的简单环境光遮蔽
// 这里可以使用更复杂的算法，如SSAO或烘焙的AO贴图
ambientOcclusion *= (worldNormal.y * 0.5 + 0.5); // 模拟顶部光照更多

// 应用环境光
float3 ambient = UNITY_LIGHTMODEL_AMBIENT * ambientOcclusion;</code></pre><p>这个简单的示例展示了如何用法线方向来模拟环境光遮蔽效果。在实际项目中，通常会结合更复杂的算法或预计算的数据。</p><h2>高级应用技巧</h2><h3>法线重定向与混合</h3><p>在某些情况下，需要将法线从一个表面重定向到另一个表面，或者在不同法线源之间进行混合。</p><pre><code>HLSL

// 法线混合示例
float3 normalA = tex2D(_NormalMapA, uv).xyz;
float3 normalB = tex2D(_NormalMapB, uv).xyz;
float blendFactor = _BlendFactor;

// 使用线性插值混合法线
float3 blendedNormal = lerp(normalA, normalB, blendFactor);

// 或者使用更精确的球面线性插值
// float3 blendedNormal = normalize(lerp(normalA, normalB, blendFactor));</code></pre><p>法线混合是一个复杂的话题，因为简单的线性插值可能不会保持法线的单位长度。在实际应用中，可能需要重新归一化或使用更高级的插值方法。</p><h3>法线空间转换优化</h3><p>在性能关键的场景中，法线空间转换可能需要优化。</p><pre><code>HLSL

// 优化的世界空间法线计算
// 传统方法
float3 worldNormal = normalize(mul(IN.normal, (float3x3)unity_WorldToObject));

// 优化方法 - 使用逆转置矩阵（处理非统一缩放）
float3 worldNormal = normalize(mul(transpose((float3x3)unity_WorldToObject), IN.normal));</code></pre><p>当模型应用了非统一缩放时，直接使用模型矩阵变换法线会导致错误的结果。在这种情况下，需要使用模型矩阵的逆转置矩阵来正确变换法线。</p><h3>法线可视化与调试</h3><p>在开发过程中，可视化法线矢量对于调试着色器非常有用。</p><pre><code>HLSL

// 法线可视化
float3 worldNormal = NormalVector节点输出（World空间）;
// 将法线从[-1,1]范围映射到[0,1]范围以便可视化
float3 normalColor = worldNormal * 0.5 + 0.5;
return float4(normalColor, 1.0);</code></pre><p>这个简单的着色器将法线矢量的各个分量映射到颜色通道，从而可以直观地查看法线的方向和分布。</p><h2>常见问题与解决方案</h2><h3>法线不连续问题</h3><p>当使用低多边形模型或不当的UV展开时，可能会遇到法线不连续的问题。</p><ul><li><strong>问题表现</strong>：表面出现不自然的硬边或接缝</li><li><p><strong>解决方案</strong>：</p><ul><li>确保模型有适当的平滑组设置</li><li>检查UV展开是否导致法线贴图采样错误</li><li>考虑使用更高精度的模型或细分表面</li></ul></li></ul><h3>性能考量</h3><p>法线计算可能会成为性能瓶颈，特别是在移动设备或复杂场景中。</p><ul><li><p><strong>优化策略</strong>：</p><ul><li>在顶点着色器中计算法线，而不是片元着色器</li><li>使用更简单的法线计算，如省略归一化步骤（如果对视觉效果影响不大）</li><li>考虑使用法线贴图的压缩格式以减少内存带宽</li></ul></li></ul><h3>法线精度问题</h3><p>在特定情况下，法线计算可能会遇到精度问题，导致视觉瑕疵。</p><ul><li><strong>问题表现</strong>：闪烁的表面、带状伪影或不准确的光照</li><li><p><strong>解决方案</strong>：</p><ul><li>使用更高精度的数据类型（如half改为float）</li><li>确保法线贴图使用适当的格式和压缩</li><li>检查法线变换矩阵的精度和正确性</li></ul></li></ul><h2>与其他节点的配合使用</h2><p>NormalVector节点很少单独使用，通常与其他Shader Graph节点结合以实现复杂的效果。</p><ul><li><strong>与Dot Product节点结合</strong>：用于计算光照强度、菲涅尔效应等</li><li><strong>与Transform节点结合</strong>：在不同坐标空间之间转换法线</li><li><strong>与Normalize节点结合</strong>：确保法线保持单位长度</li><li><strong>与Sample Texture 2D节点结合</strong>：应用法线贴图</li><li><strong>与Fresnel Effect节点结合</strong>：创建基于视角的效果</li></ul><h2>最佳实践</h2><p>为了确保NormalVector节点的正确使用和最佳性能，建议遵循以下最佳实践：</p><ul><li>始终考虑法线是否需要归一化，特别是在进行数学运算或空间变换后</li><li>选择最适合当前计算任务的坐标空间，避免不必要的空间转换</li><li>在性能敏感的场景中，尽可能在顶点着色器中计算法线相关数据</li><li>使用适当的数据类型平衡精度和性能</li><li>定期验证法线计算的正确性，特别是在使用复杂变换或混合时</li></ul><hr/><blockquote><a href="https://link.segmentfault.com/?enc=6GrrRwckiMF0O6c%2FjzKo0w%3D%3D.0ibNxm3Hcs7ErQEZktrNh9Oks6owlLjWG%2FBxbPf%2FTZCdRSZUFeoW7ztdtXb3ZD42KEZTgmFLFCMqGwFCh6f8BVm4Efm0P%2FPCfaXAkpNP984E2iJI9nb2Tnx%2F2rKdKe75X7ZGoyXPqn7VibMcs6LQ6kRye0P7DTBQwYuTlGvNs7rgQo6wLCqiZ%2Ft9NudI3QAle4RyWtPLglUMsfw85dbTSicIUxJcSHl0yJOyodCo5ec%3D" rel="nofollow" target="_blank">【Unity Shader Graph 使用与特效实现】</a><strong>专栏-直达</strong><br/>（欢迎<em>点赞留言</em>探讨，更多人加入进来能更加完善这个探索的过程，🙏）</blockquote>]]></description></item><item>    <title><![CDATA[如果一键升级自部署的 Dokploy？ 一个导航 ]]></title>    <link>https://segmentfault.com/a/1190000047570892</link>    <guid>https://segmentfault.com/a/1190000047570892</guid>    <pubDate>2026-01-25 19:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>如果你是把 Dokploy 装在自己的服务器上，用了一段时间，大概率会遇到一个问题：<br/><strong>它要怎么升级，才不折腾？</strong></p><p>答案其实很简单。</p><p>Dokploy 官方已经把升级流程写进了安装脚本里，不用拉代码，也不用自己停服务。一行命令就够了：</p><pre><code class="bash">curl -sSL https://dokploy.com/install.sh | sh -s update</code></pre><p><img width="723" height="476" referrerpolicy="no-referrer" src="/img/bVdnLwA" alt="image.png" title="image.png"/></p><p>我自己升级时的体验是：配置没丢，服务照常起来，过程也没什么存在感。对已经在跑项目的机器来说，这点很重要。</p><p>当然，有个前提。<br/>如果你和当前版本差得太远，或者这次升级涉及结构性改动，最好先扫一眼文档，看看有没有明确提到需要手动处理的地方。否则大多数情况下，直接跑就行。</p><p>官方对这个升级方式的说明在这里：<br/><a href="https://link.segmentfault.com/?enc=hcxPznwnwmN%2BXyewiJHLsQ%3D%3D.0Wqo3PeV0%2BeuD9dJsntd%2BbrxkYWaVNCzgXiDESqeBxl2WQizHNOC%2FKTUuO8fanJHm9RzWcMBPBurfWwvrl7FwmD4q%2BlDOerSxr%2FrCpg4oTo%3D" rel="nofollow" target="_blank">https://docs.dokploy.com/docs/core/manual-installation#manual-upgrade</a></p><p>自部署用 Dokploy，本来就是图一个省心。升级这件事，它现在确实做到了，越来越喜欢 Dokploy 了，哈哈哈。</p><p><img width="723" height="506" referrerpolicy="no-referrer" src="/img/bVdnLwB" alt="image.png" title="image.png" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[计算机想学习某个方向，怎么知道学习路线 cpp辅导的阿甘 ]]></title>    <link>https://segmentfault.com/a/1190000047570729</link>    <guid>https://segmentfault.com/a/1190000047570729</guid>    <pubDate>2026-01-25 17:02:12</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>前言</h2><p>最近很多初学计算机的同学，一直在问，说“甘哥，我对XXX方向比较感兴趣。现在我应该怎么规划，毕业的时候才能找到这个方向的好的公司的岗位呢”</p><p>针对同学的疑惑，阿甘总结下来，其实主要分为两类：</p><p>（1）对某一类大的方向感兴趣，但是具体这个大的方向，什么岗位，还不知道。比如有的的同学，只知道自己对游戏相关方向感兴趣；</p><p>（2）对某一个具体方向感兴趣，比如高性能计算，存储方向等，但是不知道应该学哪些东西；</p><h2>阿甘分享</h2><p>针对第一类同，我们应该如何清晰规划呢?</p><p>1.首先，我认为我们应该要做的是就是<strong>先要搞懂这个大的方向都有哪些具体的岗位</strong>。然后结合自己的情况，以及自己的兴趣。选一个自己毕业以后能最大概率进入的方向。</p><p>哪怎么知道这个大的方向，都有哪些具体的岗位呢？这个其实也很简单，可以找一个<strong>专门做这个的头部公司</strong>，看看都在热招哪些技术岗位就可以了。</p><p>比如，对游戏感兴趣。那可以找个专门做游戏研发的知名公司去它官网看看都在热招哪些游戏岗位就可以了。</p><p>比如我们可以选择米哈游这个公司，看看这个公司都在招哪些编程岗位就大概知道游戏相关方向都有哪些岗位了。然后看看工作内容描述，以及所需要的技术栈，根据自己的爱好选择一个感兴趣的就可以明确自己具体想干的方向了。</p><p><strong>明确自己想干什么方向了，哪疑惑就和第二类同学相同的了：</strong></p><p>我知道自己未来想从事某个方向，但是不知道应该学习哪些东西。</p><p>这个也很好办，因为我们学习，本质还是奔着就业去的。那我们学习某个方向的技术栈，那也肯定是因为人家企业需要，在人家企业里正在使用的。哪我们要确定自己学什么。</p><p>可以自己下载一个boss软件，去搜索自己想干的这个方向，看看有相关岗位的公司都有哪些技术要求，自己列一列。搜个十几家，然后找找他们<strong>共同的技术栈要求</strong>。针对这些共同的技术栈要求，优先学习学习就可以了。</p><p>当然在学上面这些特有的技术栈之前，作为一个初学者，还是建议大家先把基础打牢。基础打牢了，再针对某个方向专门学学，增大进入这个方向概率。</p><p>尤其应届生，还是建议先学学基础的，操作系统，计算机网络。就算你搞某个方向，操作系统知识也是需要的啊。</p><p>基础都不会更别说深入内核了。基础学完了，然后可以去boss看看相关就业方向，针对这个方向学学，增大进入这个方向的机会。</p><p>这两个不矛盾，我认为这不是一个选择的问题，而是一个承上启下的关系，只有基础过关了，具备基本的计算机知识了，才能去进行深耕。不然直接学某个东西，学也是学怎么用，也是学个表层的东西，学不到根本 </p><p>建议大家可以看看咱们星球为大家写的零基础cpp就业学习路线</p><p><a href="https://link.segmentfault.com/?enc=XANst2RMBMec0d2hJRTaOQ%3D%3D.tsxN4yeLr6JMHB%2Fk0X1z3M2nOZoOvu2rkqgSx1H4oaqY9vLPnQZze8aMy9xM4bhpWsKgWdJa82zTD80v98hqTYtc5UvfnsQAIE579%2F3D6vI%3D" rel="nofollow" target="_blank">https://www.yuque.com/u41022237/xy0omf/khe1in5zuk02nq0a?singl...</a> 《零基础c++就业学习路线》</p><p>本文由<a href="https://link.segmentfault.com/?enc=D7omKT4hTE364dv%2BpHVejA%3D%3D.8j%2BkDOmnmCKpZL4lZ3UYXhtCFhPNjqy%2BSAku5ku55nI%3D" rel="nofollow" target="_blank">mdnice</a>多平台发布</p>]]></description></item><item>    <title><![CDATA[【2026计算机毕设】水果图像识别系统~Python+深度学习+算法模型+人工智能+TensorFl]]></title>    <link>https://segmentfault.com/a/1190000047570746</link>    <guid>https://segmentfault.com/a/1190000047570746</guid>    <pubDate>2026-01-25 17:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>项目介绍</h2><p>智能水果图像识别系统，旨在为用户提供快速、准确的水果识别服务。系统集成了深度学习图像识别技术，支持用户上传水果图片进行自动识别，并提供识别历史记录管理功能。</p><p>系统主要功能包括：用户注册与登录、个人信息管理、水果图像识别、识别历史查询与删除、公告管理等。用户可以通过简单的操作上传图片，系统将自动分析并返回识别结果，包含水果名称和识别置信度。同时，系统支持分页查询识别历史，并提供公告功能，方便管理员发布系统通知和使用说明。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047570748" alt="图片" title="图片"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047570749" alt="图片" title="图片" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047570750" alt="图片" title="图片" loading="lazy"/></p><h2>选题背景与意义</h2><p>随着人工智能技术的快速发展，图像识别技术在农业、零售业等领域的应用越来越广泛。水果作为人们日常生活中不可或缺的食品，其识别和分类在水果销售、库存管理、营养分析等方面具有重要意义。</p><p>传统的水果识别主要依赖人工判断，效率低且容易出错。而基于深度学习的图像识别技术能够快速、准确地识别水果种类，提高工作效率。本项目的选题背景正是基于这一需求，旨在开发一个简单易用的水果图像识别系统，为用户提供便捷的识别服务。</p><p>该系统的开发具有以下意义：</p><ol><li>提高水果识别效率，减少人工成本</li><li>为水果销售和库存管理提供技术支持</li><li>促进深度学习技术在农业领域的应用</li><li>为用户提供便捷的水果识别工具，帮助用户更好地了解水果信息</li></ol><h2>关键技术栈：ResNet50</h2><p>本项目采用 ResNet50 作为核心图像识别模型。ResNet（Residual Network）是由 Microsoft Research 提出的深度残差网络，ResNet50 是其中包含 50 层卷积层的版本。</p><p>ResNet50 的核心创新是引入了残差连接（Residual Connection），解决了深度神经网络中的梯度消失问题，使得训练更深层次的网络成为可能。残差连接通过在网络中添加跨层连接，允许信息直接从一层传递到另一层，从而避免了梯度在反向传播过程中的衰减。</p><p>在本项目中，ResNet50 被用作水果图像识别的预训练模型。我们在预训练模型的基础上，根据水果图像数据集进行了微调，使得模型能够更准确地识别水果种类。系统集成了 TensorFlow 深度学习框架，通过加载预训练的 ResNet50 模型，对用户上传的水果图片进行分类识别。</p><p>ResNet50 的优点包括：</p><ol><li>深度网络结构，具有强大的特征提取能力</li><li>残差连接设计，解决了梯度消失问题</li><li>预训练模型在图像识别任务上表现出色</li><li>可扩展性强，可根据需求进行微调</li></ol><h2>技术架构图</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047570751" alt="图片" title="图片" loading="lazy"/></p><h2>系统功能模块图（MindMap）</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047570752" alt="图片" title="图片" loading="lazy"/></p><h2>演示视频 and 完整代码 and 安装</h2><p>地址：<a href="https://link.segmentfault.com/?enc=6%2BD8VT79YsxeAEuqz7iGvg%3D%3D.nQ5HWomRZo%2F0Q%2FJiQVKlp3o7%2Fc9CJE6AyBgUm9TZYwGVizm2w8CRtUT2cWOdTAjgsnsPVtzjNPfryIGgRNLnKw%3D%3D" rel="nofollow" target="_blank">https://www.yuque.com/ziwu/qkqzd2/yeehu520t5qyr2qy</a></p>]]></description></item><item>    <title><![CDATA[CRM选型不再迷茫：2026年八大主流品牌定位、场景与用户评价全揭秘 玩滑板的饺子 ]]></title>    <link>https://segmentfault.com/a/1190000047570631</link>    <guid>https://segmentfault.com/a/1190000047570631</guid>    <pubDate>2026-01-25 15:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在数字化浪潮席卷全球的今天，客户关系管理（CRM）系统已成为企业提升运营效率、优化客户体验、驱动业务增长的核心引擎。随着人工智能、大数据和云计算的深度融合，2026年的CRM市场呈现出更智能化、场景化、一体化的趋势。</p><p>本文基于当前市场动态、技术发展和用户反馈，为您盘点2026年值得关注的八大CRM品牌，涵盖国际巨头与国内翘楚，并附上真实用户评价，助您找到最适合的业务伙伴。</p><ul><li><ul><li>*</li></ul></li></ul><h2>一、八骏CRM：深耕中国市场的智能化CRM新锐</h2><p><strong>定位与特色</strong>  <br/>八骏CRM是杭州八骏科技有限公司推出的面向中小企业及成长型企业的智能化CRM解决方案。其特色在于深度结合中国本土商业模式，提供灵活可定制的模块，强调“连接客户、赋能销售”的理念，在性价比和本地化服务方面具有突出优势。</p><p><strong>核心定位</strong>：中国本土的<strong>企业级CRM</strong>，焦距B2B销售/长销售周期管理。</p><p><strong>核心特点</strong></p><ol><li><strong>智能化销售流程管理</strong>：内置AI销售助手，可自动分析客户画像、预测成交概率，并提供跟进建议。</li><li><strong>高度可定制性</strong>：支持低代码配置，企业可根据业务需求自定义字段、流程及报表。</li><li><strong>服务团队本土化</strong>：提供从咨询、实施到培训的全流程深度服务。</li><li><strong>成本优势</strong>：提供普惠型定价策略，买断方式的价格是国际同等产品的1/3。</li></ol><p><strong>适用场景</strong></p><ul><li>中国本土的中小企业、贸易公司、科技创业公司。</li><li>需要高度定制化CRM且预算有限的企业。</li><li>注重微信生态营销与客户运营的行业（如零售、教育、服务业）。</li></ul><p><strong>一句话总结</strong>  <br/>“更懂中国生意场的智能CRM，以高性价比和灵活配置助力企业销售数字化转型。”</p><p><strong>真实用户评价</strong></p><blockquote>“我们对比了五款CRM，最终选了八骏CRM。因为它不仅能对接我们的ERP和MES系统，业务流程支持个性化定制，上线后完全贴合我们车间到销售的链条。服务团队很专业，就是价格偏高，适合预算充足的大企业。”——某装备制造集团信息部长</blockquote><ul><li><ul><li>*</li></ul></li></ul><h2>二、Salesforce Essentials：国际巨头的轻量级入门方案</h2><p><strong>定位与特色</strong>  <br/>Salesforce Essentials是Salesforce针对小型团队推出的简化版CRM，保留核心功能的同时降低使用门槛，延续了Salesforce强大的生态基因，适合初试CRM且有意未来扩展的企业。</p><p><strong>核心特点</strong></p><ol><li><strong>简洁易用的界面</strong>：简化Salesforce经典模块，聚焦线索、联系人、商机、任务管理。</li><li><strong>强大的应用市场</strong>：可无缝集成数千款AppExchange应用，扩展性强。</li><li><strong>基础自动化</strong>：提供工作流规则、电子邮件模板等自动化工具。</li><li><strong>云端可靠保障</strong>：依托Salesforce全球基础设施，数据安全与稳定性行业领先。</li></ol><p><strong>适用场景</strong></p><ul><li>初创企业、小团队或Salesforce生态的新用户。</li><li>未来计划扩展至Salesforce全系列产品的企业。</li><li>需要与国际业务接轨的出海企业。</li></ul><p><strong>一句话总结</strong>  <br/>“CRM领域的‘iOS系统’，以轻量形态提供世界级平台的可扩展体验。”</p><p><strong>真实用户评价</strong></p><blockquote>“我们团队从10人开始用Essentials，现在发展到50人，已经平滑升级到Salesforce专业版。Essentials帮我们养成了规范的销售习惯，尤其是它的报表很直观。不过初期需要一些学习成本，且中文支持不如本地厂商细致。”——上海某跨境电商创始人</blockquote><ul><li><ul><li>*</li></ul></li></ul><h2>三、Zoho CRM：功能全面的高性价比国际品牌</h2><p><strong>定位与特色</strong>  <br/>Zoho CRM是Zoho公司旗下的综合性CRM平台，以丰富的功能模块和亲民价格著称，适合中小型企业及对功能完整性要求较高的用户。</p><p><strong>核心特点</strong></p><ol><li><strong>功能模块齐全</strong>：涵盖销售、营销、客服、库存、分析等一体化功能。</li><li><strong>AI助手Zia</strong>：提供预测性销售、情绪分析、自动化提醒等AI功能。</li><li><strong>跨平台集成</strong>：与Zoho办公套件（邮件、文档、会议）及第三方工具深度集成。</li><li><strong>灵活的定价策略</strong>：提供永久免费版及多个付费层级，性价比突出。</li></ol><p><strong>适用场景</strong></p><ul><li>追求功能全面且预算敏感的中小企业。</li><li>已使用Zoho其他产品（如Zoho Mail、Books）的企业。</li><li>需要跨部门协作（销售、市场、客服）的成长型企业。</li></ul><p><strong>一句话总结</strong>  <br/>“一站式CRM全家桶，以中等价格提供媲美高端产品的功能深度。”</p><p><strong>真实用户评价</strong></p><blockquote>“我们是一家电商代运营公司，使用ZOHO CRM两年了，最大的感受是它和微信、企业微信的集成太顺畅了，客户信息自动同步，减少了大量手动录入。AI成交预测准确率在80%左右，帮销售团队优先跟进高意向客户。客服响应速度快，每次问题都能当天解决。”——杭州某电商企业销售总监</blockquote><ul><li><ul><li>*</li></ul></li></ul><h2>四、Pipedrive：聚焦销售流程可视化的专业工具</h2><p><strong>定位与特色</strong>  <br/>Pipedrive是一款以销售管道（Pipeline）可视化为核心的CRM，专为销售团队设计，强调简单直观的交互，帮助销售高效管理线索推进过程。</p><p><strong>核心特点</strong></p><ol><li><strong>直观的管道视图</strong>：拖拽式操作管理商机阶段，销售进展一目了然。</li><li><strong>销售导向的设计</strong>：界面简洁，减少非销售相关功能干扰。</li><li><strong>自动化与集成</strong>：支持工作流自动化，并与常见工具（如Slack、Zoom）快速集成。</li><li><strong>移动端体验优秀</strong>：APP操作流畅，适合外勤销售团队。</li></ol><p><strong>适用场景</strong></p><ul><li>销售驱动型公司（如保险、房产、咨询服务）。</li><li>注重销售过程管理和个人效率的团队。</li><li>初创销售团队或首次引入CRM的企业。</li></ul><p><strong>一句话总结</strong>  <br/>“销售人员的‘数字作战看板’，以极简哲学提升销售管线转化效率。”</p><p><strong>真实用户评价</strong></p><blockquote>“Pipedrive让我们团队的销售过程变得透明，每个人都能看到自己的管线健康度。拖拽操作非常顺手，减少了培训时间。但它的营销和客服功能比较弱，更适合纯销售团队。”——北京某咨询公司销售VP</blockquote><ul><li><ul><li>*</li></ul></li></ul><h2>五、Microsoft Dynamics 365：深度融入微软生态的企业级解决方案</h2><p><strong>定位与特色</strong>  <br/>Dynamics 365是微软推出的智能业务应用套件，其CRM模块与Office 365、Power Platform、Azure深度整合，适合中大型企业及已深度采用微软产品矩阵的组织。</p><p><strong>核心特点</strong></p><ol><li><strong>与Microsoft 365无缝融合</strong>：Outlook、Teams、SharePoint等原生集成，协作顺畅。</li><li><strong>AI与数据分析强大</strong>：依托Azure AI，提供高级分析、预测建模。</li><li><strong>高定制性与扩展性</strong>：通过Power Platform可低代码构建扩展应用。</li><li><strong>企业级安全与合规</strong>：满足多地法规要求，适合跨国企业。</li></ol><p><strong>适用场景</strong></p><ul><li>已广泛使用微软产品的中大型企业。</li><li>需要复杂业务流程定制和深度数据分析的企业。</li><li>对数据安全和合规性要求高的行业（如金融、制造）。</li></ul><p><strong>一句话总结</strong>  <br/>“企业数字化的‘中枢神经’，在微软生态内提供无缝的业务应用集成。”</p><p><strong>真实用户评价</strong></p><blockquote>“我们全球团队都在用Dynamics 365，它与Teams和Outlook的整合简直是生产力神器，会议记录自动生成客户跟进任务。不过实施周期较长，需要专门的IT支持，成本较高。”——某跨国制造企业IT总监</blockquote><ul><li><ul><li>*</li></ul></li></ul><h2>六、钉钉CRM：阿里生态内的协同式CRM</h2><p><strong>定位与特色</strong>  <br/>钉钉CRM是阿里钉钉内置的客户管理工具，强调“业财一体、人财事一体”，深度融入钉钉办公协同场景，适合已使用钉钉作为办公平台的企业。</p><p><strong>核心特点</strong></p><ol><li><strong>与钉钉原生融合</strong>：消息、日程、审批、日志等协同功能与CRM无缝衔接。</li><li><strong>轻量化设计</strong>：开箱即用，降低销售团队上手门槛。</li><li><strong>生态数据连通</strong>：可连接阿里云、淘宝天猫等数据源，丰富客户洞察。</li><li><strong>成本低廉甚至免费</strong>：对钉钉企业用户提供基础免费版，付费版价格亲民。</li></ol><p><strong>适用场景</strong></p><ul><li>已全面使用钉钉办公的中小企业。</li><li>零售、电商等与阿里生态关联紧密的行业。</li><li>强调内部协同快过功能深度的团队。</li></ul><p><strong>一句话总结</strong>  <br/>“生于协同，长于生态，让客户管理成为团队日常协作的自然延伸。”</p><p><strong>真实用户评价</strong></p><blockquote>“我们公司用钉钉考勤、审批，加上CRM后，销售外勤打卡自动关联客户拜访记录，特别方便。功能虽然不如专业CRM强大，但对我们中小贸易公司足够用了，而且没增加额外成本。”——义乌某贸易公司总经理</blockquote><ul><li><ul><li>*</li></ul></li></ul><h2>七、神州云动 CloudCC：国内高端CRM的代表品牌</h2><p><strong>定位与特色</strong>  <br/>神州云动CloudCC是国内较早的CRM厂商，主打中大型企业市场，提供高度可配置的PaaS平台，在制造、消费品、专业服务等行业有深厚积累。</p><p><strong>核心特点</strong></p><ol><li><strong>企业级PaaS平台</strong>：支持复杂业务流程的定制开发，灵活性高。</li><li><strong>行业解决方案成熟</strong>：提供制造、教育、医药等多个行业模板。</li><li><strong>混合部署支持</strong>：支持公有云、私有云、混合云部署，满足安全定制需求。</li><li><strong>全渠道客户连接</strong>：整合微信、企业微信、电话、邮件等多渠道沟通，统一客户视图。</li><li><strong>适用场景</strong></li></ol><ul><li>对定制化要求高的中大型企业（如集团型、上市公司）。</li><li>传统行业数字化转型（如制造、医药、连锁零售）。</li><li>需要私有化部署或深度二次开发的项目。</li></ul><p><strong>一句话总结</strong>  <br/>“中国版的‘企业级CRM引擎’，以深厚的行业Know-How助力复杂组织管理升级。”</p><p><strong>真实用户评价</strong></p><blockquote>“我们集团选了CloudCC，它的营销自动化模块特别强大，帮助我们自动化培育线索，转化率提升了30%。缺点是界面设计略显陈旧，移动端体验有待提升。”——广州某软件公司运营经理</blockquote><ul><li><ul><li>*</li></ul></li></ul><h2>八、简道云：零代码构建CRM的灵活平台</h2><p><strong>定位与特色</strong>  <br/>简道云是帆软软件推出的零代码应用搭建平台，并非标准CRM产品，但用户可通过拖拽方式自主搭建CRM系统，适合喜欢自主设计、业务独特的企业。</p><p><strong>核心特点</strong></p><ol><li><strong>零代码自定义</strong>：通过表单、流程、报表模块像搭积木一样搭建CRM。</li><li><strong>数据整合能力强</strong>：可连接数据库、API及各类企业现有系统。</li><li><strong>成本可控</strong>：按需搭建，避免为不需要的功能付费。</li><li><strong>快速迭代</strong>：业务变化时可随时调整应用，无需开发团队。</li></ol><p><strong>适用场景</strong></p><ul><li>业务模式独特、标准CRM无法满足需求的创新企业。</li><li>IT能力较弱但希望自主管理业务系统的部门（如市场、人力）。</li><li>作为现有CRM的补充，管理特定业务流程。</li></ul><p><strong>一句话总结</strong>  <br/>“CRM的‘乐高工厂’，赋予业务人员自行搭建客户管理系统的能力。”</p><p><strong>真实用户评价</strong></p><blockquote>“我们用简道云搭了一个项目型CRM，因为我们的客户跟进流程和标准销售完全不同。自己搭虽然前期花了一周，但完全贴合业务，后续调整也自由。不过需要内部有人负责维护，不适合只想开箱即用的团队。”——某设计工作室合伙人</blockquote><ul><li><ul><li>*</li></ul></li></ul><h2>综合对比与选型建议</h2><table><thead><tr><th>品牌</th><th>核心优势</th><th>适合企业类型</th><th>价格区间（年/用户）</th><th>上手难度</th></tr></thead><tbody><tr><td>八骏CRM</td><td>本土化、高性价比</td><td>中小企业、成长型企业、长销售周期企业</td><td>19800元（买断方式）</td><td>中</td></tr><tr><td>Salesforce Essentials</td><td>生态强大、可扩展、国际品牌</td><td>初创企业、未来扩展预期强</td><td>800-1500元</td><td>中</td></tr><tr><td>Zoho CRM</td><td>功能全面、AI助手、性价比高</td><td>中小型企业、多功能需求</td><td>400-1200元</td><td>中</td></tr><tr><td>Pipedrive</td><td>销售管道可视化、极简体验</td><td>销售驱动型团队</td><td>600-1200元</td><td>低</td></tr><tr><td>Dynamics 365</td><td>微软生态整合、企业级能力</td><td>中大型企业、微软用户</td><td>1200-3000元+</td><td>高</td></tr><tr><td>钉钉CRM</td><td>协同场景融合、低成本</td><td>钉钉深度用户、中小企业</td><td>0-500元</td><td>低</td></tr><tr><td>神州云动</td><td>行业定制、PaaS平台、服务好</td><td>大型企业、复杂流程</td><td>2000元+</td><td>高</td></tr><tr><td>简道云</td><td>零代码自定义、灵活自主</td><td>业务独特、喜欢DIY的企业</td><td>按功能模块定价</td><td>中</td></tr></tbody></table><h3>给用户的靠谱选择建议</h3><ol><li><p><strong>明确核心需求与预算</strong></p><ul><li>若您需要<strong>高度贴合中国本地业务</strong>，且注重安全性与性价比，<strong>八骏CRM</strong>是务实之选。</li><li>若您<strong>预算有限</strong>且已用钉钉办公，可先试用<strong>钉钉CRM</strong>。</li><li>若您追求<strong>国际品牌与未来扩展</strong>，且团队有学习能力，考虑<strong>Salesforce Essentials</strong>或<strong>Zoho CRM</strong>。</li></ul></li><li><p><strong>考虑团队特质与行业</strong></p><ul><li><strong>纯销售团队</strong>优先考虑<strong>Pipedrive</strong>或八骏CRM的销售强化模块。</li><li><strong>中大型企业</strong>且已投资微软技术栈，<strong>Dynamics 365</strong>整合效益最高。</li><li><strong>行业特性鲜明</strong>（如制造、连锁），可评估<strong>神州云动</strong>的行业方案。</li><li><strong>业务模式独特</strong>，且具备自主设计意愿，<strong>简道云</strong>提供最大灵活性。</li></ul></li><li><p>评估实施与服务</p><ul><li>国际品牌可能面临本地支持响应速度问题，国内厂商服务更及时。</li><li>考虑未来3-5年业务增长，选择可平滑扩展的平台。</li><li>利用免费试用期（多数产品提供14-30天）让核心用户实际体验。</li></ul></li><li><p>技术整合性</p><ul><li>检查CRM是否支持与现有系统（如财务软件、电商平台）集成。</li><li>重视数据导出能力，避免未来迁移被锁定。</li></ul></li></ol><p>2026年的CRM市场，已从工具竞争转向生态与智能竞争。无论选择哪一款，关键在于与您的业务基因、团队习惯、增长战略相匹配。建议组建选型小组，带着实际业务场景进行测试，让数据与团队反馈说话，方能找到助力企业增长的“最佳拍档”。</p><p>希望本文能为您的CRM选型之旅提供清晰、可靠的参考。在数字化的道路上，合适的工具能让您的客户关系管理事半功倍，助力企业在2026年的市场中赢得先机。</p>]]></description></item><item>    <title><![CDATA[大模型榜单周报（2026/01/24） KAI智习 ]]></title>    <link>https://segmentfault.com/a/1190000047570609</link>    <guid>https://segmentfault.com/a/1190000047570609</guid>    <pubDate>2026-01-25 14:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h3>1. 本周概览</h3><p>本周大模型行业动态频发，美团更新了大规模推理模型LongCat-Flash-Thinking-2601，智谱开源轻量化模型GLM-4.7-Flash，MiniMax发布AI原生工作台。在榜单方面，OpenRouter模型调用量出现显著变化，Claude Opus 4.5调用量大幅下滑，而Claude Sonnet 4.5升至榜首，编程领域竞争激烈，各大公司继续在不同能力维度展开激烈角逐。</p><h3>2. 重点关注事件</h3><ul><li>美团于1.15更新大规模推理模型LongCat-Flash-Thinking-2601，该模型拥有5600亿参数，基于创新的MoE架构构建，引入了重思考模式(Heavy Thinking Mode)，能够同时启动8路思考并最终总结出更全面、更可靠的结论</li><li>智谱于1.20开源30B混合思考模型GLM-4.7-Flash，激活3B参数，提供免费API，性能超越同量级模型，为轻量化部署提供新选择</li><li>MiniMax于1.20发布Agent 2.0（AI-native Workspace），实现本地云端一体，推出Expert Agents垂直专家系统，具备读文件、写脚本、制作PPT、跑定时任务等功能，定义AI原生工作台概念</li><li>DeepSeek新模型MODEL1于1.21曝光，代码显示采用全新架构，具体差异体现在KV缓存布局、稀疏性处理和FP8解码方面，在内存优化上有多处创新</li><li>Anthropic于1.22开源全新「AI宪法」（Claude's Constitution），确立了当不同价值观发生冲突时的权衡顺序：「广泛安全」、「广泛道德」、「遵守Anthropic准则」、「真诚助人」</li><li>谷歌DeepMind于1.22发布D4RT（Dynamic 4D Reconstruction and Tracking），用于跨时空4D场景重建和跟踪，采用统一的编码器-解码器Transformer架构，在各类4D重建任务中均优于此前方法</li></ul><h3>3. 榜单变化</h3><ul><li>OpenRouter整体模型调用量方面，Claude Opus 4.5调用量大幅下滑35%至395B tokens，排名从第一暴跌至第六；Claude Sonnet 4.5升至榜首但增幅仅11%；免费模型MiMo-V2-Flash持续走强，占比增长18%至582B tokens，排名从第三升至第二；Gemini 2.5 Pro异军突起，调用量暴增300%至413B tokens，首次进入前十即位列第五；Grok 4.1 Fast增长13%至282B tokens；Gemini 2.5 Flash Lite调用量陷入停滞，零增长导致排名从第八跌至第十</li><li>OpenRouter模型市占率方面，Google模型份额跃升至26.0%，增幅达2.8个百分点，持续扩大领先优势；Anthropic份额大幅下滑4.7个百分点至16.7%，虽仍位居第二但与榜首差距明显拉大；OpenAI份额小幅回升0.6个百分点至13.1%；x-ai份额上升1.3个百分点至12.6%，但因增速不及OpenAI导致排名从第3降至第4；Mistral AI份额下降0.3个百分点至3.5%，被Qwen以0.9个百分点的增幅反超，双方排名发生易位</li><li>OpenRouter编程调用量方面，Claude Opus 4.5占比断崖式下跌，从20.6%骤降至10.6%，降幅达10个百分点，是两周内变化幅度最大的模型，排名从第2位跌至第3位；Grok Code Fast 1持续扩大领先优势，占比从21.6%小幅攀升至22.8%，增幅1.2个百分点，稳居市场第一；免费模型MiMo-V2-Flash异军突起，占比从2.8%飙升至5.5%，增幅2.7个百分点，排名从第8位跃升至第5位；Claude Sonnet 4.5占比显著增加，从7.7%升至14.1%，增幅6.4个百分点，排名从第4位升至第2位</li><li>编程能力榜单（Code Arena）：gemini-3-flash (thinking-minimal) 上榜，排名第8，超过GPT-5.2</li><li>图像编辑能力榜单（Text to Image Arena）：flux-2-flex分数追平nano-banana，二者排名易位</li><li>文生图能力榜单（Artificial Analysis Text to Image Leaderboard）：ImagineArt 1.5 Preview上榜，排名第10</li><li>GAIA榜单：Shawn Agent更新v3.1，排名第7，得分达89.37%</li></ul><h3>4. 排行榜</h3><table><thead><tr><th>测评类型</th><th>第一名</th><th>第二名</th><th>第三名</th></tr></thead><tbody><tr><td>模型调用量</td><td>Claude Sonnet 4.5</td><td>MiMo-V2-Flash(free)</td><td>Grok Code Fast 1</td></tr><tr><td>公司市占率</td><td>Google</td><td>Anthropic</td><td>OpenAI</td></tr><tr><td>编程模型调用量</td><td>Grok Code Fast 1</td><td>Claude Sonnet 4.5</td><td>Claude Opus 4.5</td></tr></tbody></table><h4>各公司按不同能力领域排名汇总</h4><table><thead><tr><th>测评类型</th><th>领先公司</th></tr></thead><tbody><tr><td>大语言模型 Text Arena</td><td>Google、xAI、Anthropic、百度、OpenAI、智谱、阿里巴巴、月之暗面</td></tr><tr><td>编程能力 Code Arena</td><td>Anthropic、OpenAI、Google、智谱、MiniMax</td></tr><tr><td>编程能力 LiveCodeBench</td><td>OpenAI、Anthropic、Google</td></tr><tr><td>代码工程任务能力 SWE-benchLite</td><td>基于Claude、Gemini、GPT、Qwen、DeepSeek开发的开源系统</td></tr><tr><td>图像编辑和生成能力 Image Edit Arena</td><td>OpenAI、Google、字节、Black Forest Labs、Reve</td></tr><tr><td>文生图能力 Text-to-Image Arena</td><td>OpenAI、Google、Black Forest Labs、腾讯</td></tr><tr><td>图像编辑和生成能力 Image Editing Leaderboard</td><td>OpenAI、Google、字节、Black Forest Labs、阿里巴巴、Reve</td></tr><tr><td>文生图能力 Text to Image Leaderboard</td><td>OpenAI、Google、Black Forest Labs、字节、ImagineArt</td></tr><tr><td>GPQA</td><td>OpenAI、Google、xAI、Anthropic、阿里巴巴</td></tr><tr><td>FrontierMath</td><td>OpenAI、Google、DeepSeek、月之暗面、Anthropic、xAI</td></tr><tr><td>Humanity's Last Exam</td><td>Google、OpenAI、Anthropic</td></tr><tr><td>GAIA</td><td>JoinAI、Nvidia、Suzhou AI Lab&amp;Shuqian Tech、Microsoft AI Asia -Ads、LR AILab of Lenovo CTO Org、ShawnAgent、ZTE-AICloud、LR AILab等</td></tr></tbody></table><hr/><p>关注我，第一时间掌握更多AI前沿资讯！</p>]]></description></item><item>    <title><![CDATA[HonoX：下一代全栈 Web 框架深度解析 jump__jump ]]></title>    <link>https://segmentfault.com/a/1190000047570555</link>    <guid>https://segmentfault.com/a/1190000047570555</guid>    <pubDate>2026-01-25 12:03:10</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <blockquote>一个基于 Hono 的全栈 Web 框架，结合了 Islands 架构和边缘计算的强大能力</blockquote><h2>引言</h2><p>在现代 Web 开发中，我们面临着一个永恒的挑战：如何在提供丰富交互体验的同时，保持快速的加载速度和优秀的性能？传统的单页应用（SPA）虽然交互流畅，但首屏加载慢、SEO 困难；而传统的服务端渲染（SSR）虽然首屏快，但缺乏现代前端框架的开发体验。</p><p>HonoX 的出现，为这个问题提供了一个优雅的解决方案。它是基于超快的 Hono Web 框架构建的全栈框架，采用 Islands 架构，完美平衡了性能和开发体验。</p><h2>什么是 HonoX？</h2><p>HonoX 是一个全栈 Web 框架，它建立在 <a href="https://link.segmentfault.com/?enc=Jt125nBc6yUlKMg6ybeXkQ%3D%3D.c7qSmYy6Y50QzHPYAo%2FlFFBBYM3to5RG51rq6otm%2BjU%3D" rel="nofollow" target="_blank">Hono</a> 之上。Hono 是一个轻量级、超快速的 Web 框架，可以运行在任何 JavaScript 运行时（Cloudflare Workers、Deno、Bun、Node.js 等）。</p><h3>核心特性</h3><ol><li><strong>Islands 架构</strong> - 渐进式水合，只在需要的地方加载 JavaScript</li><li><strong>文件路由系统</strong> - 基于文件系统的直观路由</li><li><strong>边缘优先</strong> - 为 Cloudflare Workers 等边缘运行时优化</li><li><strong>类型安全</strong> - 完整的 TypeScript 支持</li><li><strong>零配置</strong> - 开箱即用的最佳实践</li><li><strong>极致性能</strong> - 继承 Hono 的超快性能</li></ol><h2>Islands 架构：重新思考前端水合</h2><h3>什么是 Islands 架构？</h3><p>Islands 架构是一种现代前端架构模式，最早由 Etsy 的前端架构师 Katie Sylor-Miller 提出，后来被 Astro、Fresh 等框架采用。</p><p>想象一个网页是一片海洋，而需要交互的组件是海洋中的"岛屿"：</p><pre><code>┌─────────────────────────────────┐
│  静态 HTML（服务端渲染）          │
│                                 │
│  ┌─────────┐      ┌─────────┐  │
│  │ Island  │      │ Island  │  │
│  │ (交互)  │      │ (交互)  │  │
│  └─────────┘      └─────────┘  │
│                                 │
│         ┌─────────┐             │
│         │ Island  │             │
│         │ (交互)  │             │
│         └─────────┘             │
└─────────────────────────────────┘</code></pre><p>这种架构的优势在于：</p><ul><li><strong>减少 JavaScript 负载</strong> - 只加载真正需要的 JavaScript</li><li><strong>提升首屏性能</strong> - 静态内容立即可见</li><li><strong>渐进式增强</strong> - 交互组件逐步加载和激活</li><li><strong>更好的 SEO</strong> - 完整的服务端渲染内容</li></ul><h3>HonoX 中的 Islands</h3><p>在 HonoX 中使用 Islands 非常简单：</p><pre><code class="tsx">// app/islands/Counter.tsx
import { useState } from 'hono/jsx'

export default function Counter({ initialCount = 0 }) {
  const [count, setCount] = useState(initialCount)

  return (
    &lt;div class="counter"&gt;
      &lt;button onClick={() =&gt; setCount(count - 1)}&gt;-&lt;/button&gt;
      &lt;span&gt;{count}&lt;/span&gt;
      &lt;button onClick={() =&gt; setCount(count + 1)}&gt;+&lt;/button&gt;
    &lt;/div&gt;
  )
}</code></pre><p>只需将组件放在 <code>app/islands/</code> 目录下，HonoX 会自动处理：</p><ul><li>服务端渲染</li><li>客户端代码分割</li><li>按需水合</li></ul><p>在页面中使用：</p><pre><code class="tsx">// app/routes/index.tsx
import Counter from '../islands/Counter'

export default function Home() {
  return (
    &lt;div&gt;
      &lt;h1&gt;我的页面&lt;/h1&gt;
      &lt;p&gt;这段文字是纯静态的，不需要 JavaScript&lt;/p&gt;
      &lt;Counter initialCount={0} /&gt;
    &lt;/div&gt;
  )
}</code></pre><h2>文件路由系统：约定优于配置</h2><p>HonoX 采用基于文件的路由系统，让路由管理变得直观：</p><pre><code>app/routes/
├── index.tsx           → /
├── about.tsx           → /about
├── blog/
│   ├── index.tsx       → /blog
│   └── [slug].tsx      → /blog/:slug
└── api/
    ├── users.ts        → /api/users
    └── users/
        └── [id].ts     → /api/users/:id</code></pre><h3>动态路由</h3><p>使用方括号定义动态路由参数：</p><pre><code class="tsx">// app/routes/blog/[slug].tsx
import { createRoute } from 'honox/factory'

export default createRoute((c) =&gt; {
  const { slug } = c.req.param()

  return c.render(
    &lt;article&gt;
      &lt;h1&gt;文章：{slug}&lt;/h1&gt;
    &lt;/article&gt;
  )
})</code></pre><h3>API 路由</h3><p>API 路由返回 JSON 数据：</p><pre><code class="typescript">// app/routes/api/users/[id].ts
import { Hono } from 'hono'
import { zValidator } from '@hono/zod-validator'
import { z } from 'zod'

const app = new Hono()

// GET /api/users/:id
app.get('/:id', (c) =&gt; {
  const id = c.req.param('id')
  return c.json({ id, name: 'User ' + id })
})

// POST /api/users/:id
const schema = z.object({
  name: z.string().min(1),
  email: z.string().email(),
})

app.post('/:id', zValidator('json', schema), (c) =&gt; {
  const data = c.req.valid('json')
  const id = c.req.param('id')

  return c.json({
    id,
    ...data,
    updated: true
  })
})

export default app</code></pre><h2>中间件系统：强大且灵活</h2><p>HonoX 继承了 Hono 的中间件系统，让你可以轻松处理横切关注点：</p><pre><code class="typescript">// app/routes/_middleware.tsx
import { createRoute } from 'honox/factory'
import { compress } from 'hono/compress'
import { logger } from 'hono/logger'
import { secureHeaders } from 'hono/secure-headers'

export default createRoute((c, next) =&gt; {
  // 日志记录
  logger()(c, next)

  // 安全头
  secureHeaders()(c, next)

  // 响应压缩
  compress()(c, next)

  return next()
})</code></pre><h3>自定义中间件</h3><p>创建自定义中间件也很简单：</p><pre><code class="typescript">// 性能计时中间件
export const timing = createMiddleware(async (c, next) =&gt; {
  const start = Date.now()
  await next()
  const end = Date.now()

  c.header('Server-Timing', `total;dur=${end - start}`)
})

// 认证中间件
export const auth = createMiddleware(async (c, next) =&gt; {
  const token = c.req.header('Authorization')

  if (!token) {
    return c.json({ error: 'Unauthorized' }, 401)
  }

  // 验证 token...
  await next()
})</code></pre><h2>性能优化：从框架层面开始</h2><p>HonoX 内置了多种性能优化：</p><h3>1. 自动代码分割</h3><p>每个 Island 组件自动分割成独立的 chunk：</p><pre><code class="typescript">// 自动生成类似这样的输出
dist/
├── client/
│   ├── island-Counter.js    (3KB)
│   ├── island-Search.js     (5KB)
│   └── island-Modal.js      (4KB)
└── server/
    └── index.js</code></pre><h3>2. 流式 SSR</h3><p>使用 Suspense 实现流式渲染：</p><pre><code class="tsx">import { Suspense } from 'hono/jsx'
import AsyncData from '../islands/AsyncData'

export default function Page() {
  return (
    &lt;div&gt;
      &lt;h1&gt;立即显示的标题&lt;/h1&gt;

      &lt;Suspense fallback={&lt;div&gt;加载中...&lt;/div&gt;}&gt;
        &lt;AsyncData /&gt;
      &lt;/Suspense&gt;
    &lt;/div&gt;
  )
}</code></pre><p>页面渲染流程：</p><ol><li>立即发送 HTML 头部和静态内容</li><li>异步组件准备好后流式发送</li><li>最后发送激活脚本</li></ol><h3>3. 智能缓存策略</h3><pre><code class="typescript">// 静态资源长期缓存
app.get('/static/*', async (c) =&gt; {
  c.header('Cache-Control', 'public, max-age=31536000, immutable')
  return c.next()
})

// API 响应 ETag 缓存
app.get('/api/data', async (c) =&gt; {
  const data = await fetchData()
  const etag = generateETag(data)

  if (c.req.header('If-None-Match') === etag) {
    return c.body(null, 304)
  }

  c.header('ETag', etag)
  return c.json(data)
})</code></pre><h2>类型安全：端到端的 TypeScript</h2><p>HonoX 提供完整的类型安全，从路由到 API：</p><pre><code class="typescript">// 定义 API 类型
type User = {
  id: string
  name: string
  email: string
}

// API 路由自动推断类型
const app = new Hono&lt;{ Variables: { user: User } }&gt;()

app.get('/api/user', (c) =&gt; {
  const user = c.get('user') // 类型：User
  return c.json(user)
})

// 在客户端使用类型
const response = await fetch('/api/user')
const user: User = await response.json()</code></pre><h2>部署：边缘优先</h2><p>HonoX 针对边缘运行时优化，特别是 Cloudflare Workers：</p><h3>Cloudflare Pages 部署</h3><pre><code class="bash"># 构建
npm run build

# 部署
npm run deploy</code></pre><p>优势：</p><ul><li><strong>全球 CDN</strong> - 300+ 个边缘节点</li><li><strong>零冷启动</strong> - Workers 即时响应</li><li><strong>自动扩展</strong> - 无需配置</li><li><strong>低成本</strong> - 免费层每天 100,000 请求</li></ul><h3>其他平台</h3><p>HonoX 也支持部署到：</p><ul><li><strong>Vercel</strong> - 使用 Node.js 适配器</li><li><strong>Netlify</strong> - Edge Functions</li><li><strong>Deno Deploy</strong> - 原生支持</li><li><strong>传统服务器</strong> - Node.js</li></ul><h2>实战案例：构建一个博客</h2><p>让我们用 HonoX 构建一个完整的博客系统：</p><h3>1. 文章列表页</h3><pre><code class="tsx">// app/routes/blog/index.tsx
import { createRoute } from 'honox/factory'
import { getPosts } from '../../lib/posts'

export default createRoute(async (c) =&gt; {
  const posts = await getPosts()

  return c.render(
    &lt;div class="blog"&gt;
      &lt;h1&gt;博客文章&lt;/h1&gt;
      &lt;ul&gt;
        {posts.map(post =&gt; (
          &lt;li key={post.slug}&gt;
            &lt;a href={`/blog/${post.slug}`}&gt;
              &lt;h2&gt;{post.title}&lt;/h2&gt;
              &lt;time&gt;{post.date}&lt;/time&gt;
            &lt;/a&gt;
          &lt;/li&gt;
        ))}
      &lt;/ul&gt;
    &lt;/div&gt;
  )
})</code></pre><h3>2. 文章详情页</h3><pre><code class="tsx">// app/routes/blog/[slug].tsx
import { createRoute } from 'honox/factory'
import { getPost } from '../../lib/posts'
import CommentSection from '../../islands/CommentSection'

export default createRoute(async (c) =&gt; {
  const { slug } = c.req.param()
  const post = await getPost(slug)

  if (!post) {
    return c.notFound()
  }

  return c.render(
    &lt;article&gt;
      &lt;header&gt;
        &lt;h1&gt;{post.title}&lt;/h1&gt;
        &lt;time&gt;{post.date}&lt;/time&gt;
        &lt;div&gt;{post.author}&lt;/div&gt;
      &lt;/header&gt;

      &lt;div dangerouslySetInnerHTML={{ __html: post.content }} /&gt;

      {/* 评论区使用 Island 实现交互 */}
      &lt;CommentSection postId={slug} /&gt;
    &lt;/article&gt;,
    {
      title: post.title,
      description: post.excerpt,
    }
  )
})</code></pre><h3>3. 交互式评论组件</h3><pre><code class="tsx">// app/islands/CommentSection.tsx
import { useState } from 'hono/jsx'

type Comment = {
  id: string
  author: string
  content: string
  createdAt: string
}

export default function CommentSection({ postId }: { postId: string }) {
  const [comments, setComments] = useState&lt;Comment[]&gt;([])
  const [loading, setLoading] = useState(false)

  const loadComments = async () =&gt; {
    setLoading(true)
    const res = await fetch(`/api/comments/${postId}`)
    const data = await res.json()
    setComments(data.comments)
    setLoading(false)
  }

  const submitComment = async (e: Event) =&gt; {
    e.preventDefault()
    const form = e.target as HTMLFormElement
    const formData = new FormData(form)

    await fetch(`/api/comments/${postId}`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        author: formData.get('author'),
        content: formData.get('content'),
      }),
    })

    form.reset()
    loadComments()
  }

  return (
    &lt;section class="comments"&gt;
      &lt;h2&gt;评论&lt;/h2&gt;

      &lt;button onClick={loadComments}&gt;
        {loading ? '加载中...' : '加载评论'}
      &lt;/button&gt;

      {comments.map(comment =&gt; (
        &lt;div key={comment.id} class="comment"&gt;
          &lt;strong&gt;{comment.author}&lt;/strong&gt;
          &lt;p&gt;{comment.content}&lt;/p&gt;
          &lt;time&gt;{comment.createdAt}&lt;/time&gt;
        &lt;/div&gt;
      ))}

      &lt;form onSubmit={submitComment}&gt;
        &lt;input name="author" placeholder="您的名字" required /&gt;
        &lt;textarea name="content" placeholder="评论内容" required /&gt;
        &lt;button type="submit"&gt;提交评论&lt;/button&gt;
      &lt;/form&gt;
    &lt;/section&gt;
  )
}</code></pre><h3>4. 评论 API</h3><pre><code class="typescript">// app/routes/api/comments/[postId].ts
import { Hono } from 'hono'
import { zValidator } from '@hono/zod-validator'
import { z } from 'zod'

const app = new Hono()

const commentSchema = z.object({
  author: z.string().min(1).max(50),
  content: z.string().min(1).max(1000),
})

// 获取评论
app.get('/:postId', async (c) =&gt; {
  const { postId } = c.req.param()

  // 从数据库获取评论
  const comments = await db.comments
    .where('postId', postId)
    .orderBy('createdAt', 'desc')
    .get()

  return c.json({ comments })
})

// 添加评论
app.post('/:postId', zValidator('json', commentSchema), async (c) =&gt; {
  const { postId } = c.req.param()
  const data = c.req.valid('json')

  const comment = await db.comments.create({
    postId,
    ...data,
    createdAt: new Date().toISOString(),
  })

  return c.json(comment, 201)
})

export default app</code></pre><h2>与其他框架对比</h2><h3>HonoX vs Next.js</h3><p><strong>HonoX 的优势：</strong></p><ul><li>更轻量（核心更小）</li><li>边缘优先设计</li><li>更简单的学习曲线</li><li>更快的冷启动</li></ul><p><strong>Next.js 的优势：</strong></p><ul><li>更成熟的生态系统</li><li>更多的官方集成</li><li>React Server Components</li><li>更强大的图像优化</li></ul><h3>HonoX vs Astro</h3><p><strong>相似点：</strong></p><ul><li>都使用 Islands 架构</li><li>都注重性能</li><li>都支持多框架</li></ul><p><strong>HonoX 的优势：</strong></p><ul><li>更好的 API 路由</li><li>原生支持边缘运行时</li><li>更轻量的运行时</li></ul><p><strong>Astro 的优势：</strong></p><ul><li>可以混用多个前端框架</li><li>更丰富的内容处理功能</li><li>更好的静态站点生成</li></ul><h3>HonoX vs Fresh</h3><p><strong>相似点：</strong></p><ul><li>都基于 Islands 架构</li><li>都使用文件路由</li><li>都注重性能</li></ul><p><strong>HonoX 的优势：</strong></p><ul><li>支持更多运行时</li><li>更灵活的中间件系统</li><li>基于 Hono 的强大生态</li></ul><p><strong>Fresh 的优势：</strong></p><ul><li>Deno 原生集成</li><li>Preact 默认支持</li><li>更简单的配置</li></ul><h2>最佳实践</h2><h3>1. 合理使用 Islands</h3><p><strong>✅ 好的做法：</strong></p><pre><code class="tsx">// 只将需要交互的部分做成 Island
&lt;article&gt;
  &lt;h1&gt;{title}&lt;/h1&gt;
  &lt;p&gt;{content}&lt;/p&gt;
  &lt;ShareButtons /&gt; {/* Island */}
  &lt;CommentSection /&gt; {/* Island */}
&lt;/article&gt;</code></pre><p><strong>❌ 避免：</strong></p><pre><code class="tsx">// 不要把整个页面都做成 Island
export default function Page() {
  const [state, setState] = useState()
  // 整个页面都会在客户端水合
}</code></pre><h3>2. 优化数据获取</h3><p><strong>✅ 好的做法：</strong></p><pre><code class="tsx">// 在服务端并行获取数据
export default createRoute(async (c) =&gt; {
  const [user, posts, comments] = await Promise.all([
    getUser(),
    getPosts(),
    getComments(),
  ])

  return c.render(&lt;Page user={user} posts={posts} comments={comments} /&gt;)
})</code></pre><p><strong>❌ 避免：</strong></p><pre><code class="tsx">// 避免串行请求
const user = await getUser()
const posts = await getPosts() // 等待上一个完成
const comments = await getComments() // 又要等待</code></pre><h3>3. 使用流式渲染</h3><pre><code class="tsx">// 对于慢速数据使用 Suspense
export default function Page() {
  return (
    &lt;&gt;
      &lt;Header /&gt; {/* 快速渲染 */}

      &lt;Suspense fallback={&lt;Skeleton /&gt;}&gt;
        &lt;SlowData /&gt; {/* 异步加载 */}
      &lt;/Suspense&gt;

      &lt;Footer /&gt;
    &lt;/&gt;
  )
}</code></pre><h3>4. 实现有效缓存</h3><pre><code class="typescript">// 分层缓存策略
const app = new Hono()

// 1. 边缘缓存
app.use('/api/*', cache({
  cacheName: 'api-cache',
  cacheControl: 'max-age=60',
}))

// 2. 浏览器缓存
app.use('/static/*', async (c, next) =&gt; {
  await next()
  c.header('Cache-Control', 'public, max-age=31536000, immutable')
})

// 3. 条件请求
app.use('/data/*', etag())</code></pre><h2>未来展望</h2><p>HonoX 还在快速发展中，以下是一些令人期待的方向：</p><ol><li><strong>更多的运行时支持</strong> - 包括 AWS Lambda、Azure Functions 等</li><li><strong>增强的开发工具</strong> - 更好的调试体验、性能分析工具</li><li><strong>更丰富的生态</strong> - 官方插件、第三方集成</li><li><strong>框架无关的 Islands</strong> - 支持 React、Vue、Svelte 等</li><li><strong>增量静态生成</strong> - 类似 Next.js 的 ISR</li></ol><h2>结论</h2><p>HonoX 代表了现代全栈框架的一个重要方向：</p><ul><li><strong>性能优先</strong> - Islands 架构和边缘计算</li><li><strong>开发体验</strong> - 简单直观的 API</li><li><strong>灵活性</strong> - 支持多种运行时和部署方式</li><li><strong>类型安全</strong> - 完整的 TypeScript 支持</li></ul><p>如果你正在寻找一个轻量、快速、现代的全栈框架，特别是需要部署到边缘运行时，HonoX 是一个值得考虑的选择。</p><p>虽然它还比较年轻，生态系统不如 Next.js 那样成熟，但它的设计理念和技术方向都非常正确。随着 Hono 生态的发展，HonoX 也将变得越来越强大。</p><h2>资源链接</h2><ul><li><a href="https://link.segmentfault.com/?enc=FowhRixjfxA54DOiIPtxag%3D%3D.3k57ozkgWTL0juJR9tOEGod8DNbGVQt5FrTeq3OIoeI%3D" rel="nofollow" target="_blank">HonoX GitHub</a></li><li><a href="https://link.segmentfault.com/?enc=WmkGGqM%2Fv9kV7XJZlpbgRQ%3D%3D.WmbZ27k5mxR%2B1ckAhjanr6zV9lWdsTDcHs7wnPTUAxE%3D" rel="nofollow" target="_blank">Hono 官方文档</a></li><li><a href="https://link.segmentfault.com/?enc=6l9UwDN8DRjqxdIjJ%2BAE4g%3D%3D.JVBsUcoC8YSqG97b2UPd3ZDq3KKyJV67Wfmvx4b95kGgBRFB9Y7C8YnZvLefjsYB0D8bfkiq%2FjKyEIwiGIG%2Bow%3D%3D" rel="nofollow" target="_blank">Islands 架构介绍</a></li><li><a href="https://link.segmentfault.com/?enc=3K47Aei9Oz56ZxJvf3wCeQ%3D%3D.nTrazpmAwQgf5T3agc27DuTtVUhwBQkQaQkVUtqyMl9Dml5mzOFQYCThFdlzWw1M" rel="nofollow" target="_blank">Cloudflare Workers 文档</a></li><li><a href="https://link.segmentfault.com/?enc=vCWYZXpPoHPhBOglht2iTw%3D%3D.AXbu%2BwipsZi%2BlpjIevGBtEBRULXHmfnZJEYZ%2FfoARXnJ35%2BcGScaj0E5jABtGUlk" rel="nofollow" target="_blank">本项目示例代码</a></li></ul><hr/><p>欢迎在评论区分享你对 HonoX 的看法和使用经验！</p>]]></description></item><item>    <title><![CDATA[从本土到国际：2026年适合中国企业的五大CRM系统全景分析 玩滑板的饺子 ]]></title>    <link>https://segmentfault.com/a/1190000047570570</link>    <guid>https://segmentfault.com/a/1190000047570570</guid>    <pubDate>2026-01-25 12:02:17</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在数字化转型不断深化的2026年，客户关系管理（CRM）系统已成为企业核心竞争力的关键组成部分。根据Gartner最新预测，全球CRM软件市场将在2026年突破1000亿美元大关，云化、智能化、全渠道整合成为主要趋势。面对市场上琳琅满目的选择，企业如何找到最适合自己的CRM解决方案？<br/>本文将从实际应用场景出发，深入分析五款高口碑CRM系统——<strong>八骏CRM、SAP CRM、Zoho CRM、Freshsales和Microsoft Dynamics 365</strong>，为您提供2026年最全面的选型指南。</p><h2>一、CRM市场趋势与选型新标准</h2><p>2026年的CRM系统已远超简单的客户信息管理范畴，呈现出以下关键趋势：</p><ol><li><strong>AI深度集成</strong>：智能预测、自动化工作流和个性化推荐成为标配</li><li><strong>全渠道融合</strong>：无缝整合社交媒体、即时通讯、邮件和实体互动</li><li><strong>数据合规强化</strong>：适应全球各地数据隐私法规的严格合规要求</li><li><strong>行业垂直化</strong>：针对特定行业的深度定制解决方案日益普及</li><li><strong>体验经济导向</strong>：从“管理客户”转向“赋能客户体验”</li></ol><p>在这样的背景下，企业选型时需考虑的不再仅是功能清单，更应关注系统的适应性、可扩展性和投资回报率。下面我们将逐一分析五款主流CRM系统的特点与适用场景。</p><h2>二、八骏CRM：国内企业数字化转型的加速器</h2><h3>定位与特色</h3><p>八骏CRM是杭州八骏科技有限公司自主研发的企业级客户关系管理平台，专为成长型和中大型中国企业设计。</p><p>其核心定位是“中国本土的<strong>企业级CRM</strong>，焦距B2B销售/长销售周期管理”，深度融合国内商业环境特点，支持高度定制化配置，特别适合业务流程复杂、需求独特的企业。</p><h3>核心特点</h3><ol><li><strong>全流程客户生命周期管理</strong>：从线索获取、商机跟进到合同管理、回款跟踪，形成完整闭环</li><li><strong>高度灵活的定制能力</strong>：无需编码即可自定义字段、流程和报表，适应企业独特业务流程</li><li><strong>本土化深度适配</strong>：无缝对接微信生态、钉钉、企业微信及国内主流财税系统</li><li><strong>智能化销售赋能</strong>：内置AI销售助手，提供销售预测、客户分级和最佳行动建议</li><li><strong>多维数据分析</strong>：可视化报表和仪表盘，支持自定义分析维度，洞察业务健康度</li></ol><h3>适用场景</h3><ul><li>业务流程复杂、需要高度定制化的中国成长型企业</li><li>注重线下销售团队管理与过程控制的企业</li><li>需要与国内生态系统（微信、钉钉、金蝶、用友等）深度整合的公司</li><li>对数据主权和安全有严格要求，偏好本地化部署的机构</li></ul><h3>一句话总结</h3><p>八骏CRM是为中国商业环境深度优化的灵活解决方案，特别适合长销售周期、需要高度定制化且重视本土生态整合的企业。</p><h2>三、SAP CRM：全球企业的端到端解决方案</h2><h3>定位与特色</h3><p>作为企业软件领域的巨头，SAP CRM是SAP商务套件的核心组成部分，定位于大型跨国企业和复杂组织的全方位客户互动管理。其最大特色是与SAP ERP系统的无缝集成，提供从营销到服务的端到端业务流程支持。</p><h3>核心特点</h3><ol><li><strong>与SAP生态深度集成</strong>：与SAP ERP、SCM、BI等系统无缝对接，消除数据孤岛</li><li><strong>行业特定解决方案</strong>：为25个以上行业提供预配置的最佳实践流程</li><li><strong>强大的B2B功能</strong>：复杂定价、合同管理和渠道管理能力突出</li><li><strong>全球部署能力</strong>：支持多语言、多货币、多法律实体运营</li><li><strong>预测性分析</strong>：集成SAP Analytics Cloud，提供高级预测和情景模拟</li></ol><h3>适用场景</h3><ul><li>已经使用SAP ERP系统的大型企业，寻求CRM无缝扩展</li><li>业务遍布全球多个地区的跨国公司</li><li>B2B模式复杂，需要处理多层次定价和渠道关系的企业</li><li>对行业最佳实践有明确需求的制造业、化工、消费品等企业</li></ul><h3>一句话总结</h3><p>SAP CRM是大型企业尤其是已投资SAP生态的组织的综合性选择，提供无可比拟的端到端业务流程集成。</p><h2>四、Zoho CRM：中小企业的全能型选手</h2><h3>定位与特色</h3><p>Zoho CRM以其卓越的性价比和全面的功能集闻名，定位于中小型企业和创业公司的全功能CRM解决方案。作为Zoho应用套件的一部分，它提供了超过50个预建集成，形成了独特的一体化办公生态。</p><h3>核心特点</h3><ol><li><strong>卓越的性价比</strong>：提供从免费版到企业级的多种选择，功能与价格比优势明显</li><li><strong>AI助手Zia</strong>：强大的自然语言处理和预测能力，自动化重复任务并提供洞察</li><li><strong>全面的应用生态</strong>：与Zoho Mail、Books、Projects等40余款应用无缝协作</li><li><strong>低代码开发平台</strong>：Zoho Creator允许用户构建定制应用，扩展CRM功能</li><li><strong>多渠道互动管理</strong>：整合电话、邮件、社交媒体和实时聊天于统一界面</li></ol><h3>适用场景</h3><ul><li>预算有限但需要全功能CRM的中小型企业</li><li>已使用或计划采用Zoho应用生态的机构</li><li>需要快速部署且易用性高的成长型团队</li><li>希望以较低成本获得AI功能的企业</li></ul><h3>一句话总结</h3><p>Zoho CRM以极高的性价比和完整的功能集，成为中小企业数字化转型的理想起点和长期伙伴。</p><h2>五、Freshsales：销售团队的效率引擎</h2><h3>定位与特色</h3><p>Freshsales是Freshworks公司旗下专注于销售自动化的CRM产品，定位于“让销售团队更高效地成交”。其设计哲学强调直观的用户体验和智能自动化，特别适合销售驱动型组织。</p><h3>核心特点</h3><ol><li><strong>直观的视觉销售管道</strong>：拖拽式界面清晰展示销售阶段，简化销售流程管理</li><li><strong>智能电子邮件序列</strong>：自动化多步骤邮件营销，内置打开和点击跟踪</li><li><strong>内置电话和聊天工具</strong>：无需切换应用即可拨打电话和与网站访客聊天</li><li><strong>AI驱动的线索评分</strong>：根据互动行为和属性自动评分线索，优化销售精力分配</li><li><strong>移动优先设计</strong>：功能完整的移动应用，支持离线访问和现场数据录入</li></ol><h3>适用场景</h3><ul><li>销售团队需要简化流程、提高效率的中小型企业</li><li>注重入站营销和线索培育的数字原生公司</li><li>远程销售团队或经常外出的现场销售代表</li><li>寻求快速上手、直观易用CRM解决方案的团队</li></ul><h3>一句话总结</h3><p>Freshsales是专为销售团队设计的直观工具，通过智能自动化帮助销售代表更高效地跟进和转化线索。</p><h2>六、Microsoft Dynamics 365：微软生态的智能枢纽</h2><h3>定位与特色</h3><p>Microsoft Dynamics 365是微软推出的智能业务应用平台，其CRM模块与微软生态系统深度集成。定位为“业务应用与AI的融合”，特别适合已投资Microsoft技术栈的组织。</p><h3>核心特点</h3><ol><li><strong>与Microsoft 365无缝集成</strong>：与Outlook、Teams、Office深度整合，提升协作效率</li><li><strong>强大的AI能力</strong>：集成Azure AI服务，提供预测性洞察和自动化建议</li><li><strong>混合部署灵活性</strong>：支持云、本地或混合部署，适应不同IT策略</li><li><strong>Power Platform扩展性</strong>：通过Power Apps、Automate和BI轻松定制和扩展</li><li><strong>行业云解决方案</strong>：提供针对医疗、金融、零售等行业的特定模块</li></ol><h3>适用场景</h3><ul><li>已广泛使用Microsoft 365和Teams的企业</li><li>需要CRM与ERP（通过Finance and Operations模块）紧密集成的组织</li><li>IT部门熟悉微软技术栈，希望降低集成和维护成本</li><li>需要强大AI能力且重视数据安全合规的企业</li></ul><h3>一句话总结</h3><p>Microsoft Dynamics 365是微软技术生态企业的自然选择，提供智能业务应用与生产力工具的完美融合。</p><h2>七、2026年CRM选型综合建议</h2><p>面对五款各具特色的CRM系统，企业在2026年做出选择时应考虑以下维度：</p><h3>1. 根据企业规模与阶段选择</h3><ul><li><strong>初创企业与小微企业</strong>：优先考虑Zoho CRM（免费版或标准版）或Freshsales，它们提供快速启动和较低成本</li><li><strong>成长型中小企业</strong>：八骏CRM和Zoho CRM企业版提供良好的平衡点，兼顾功能与定制性</li><li><strong>中大型及跨国企业</strong>：SAP CRM和Microsoft Dynamics 365提供企业级稳定性和深度功能</li></ul><h3>2. 根据现有技术生态选择</h3><ul><li><strong>已投资SAP生态</strong>：优先考虑SAP CRM，最大化现有投资价值</li><li><strong>微软技术栈用户</strong>：Microsoft Dynamics 365提供最无缝的集成体验</li><li><strong>国内生态为主</strong>：八骏CRM在本土化对接方面优势明显</li><li><strong>寻求开放生态</strong>：Zoho CRM和Freshsales提供广泛的第三方集成选项</li></ul><h3>3. 根据核心业务需求选择</h3><ul><li><strong>销售流程优化</strong>：Freshsales的销售自动化功能突出</li><li><strong>全渠道客户体验</strong>：Microsoft Dynamics 365和八骏CRM提供全面渠道整合</li><li><strong>深度行业定制</strong>：SAP CRM的行业解决方案最为成熟</li><li><strong>营销自动化需求</strong>：Zoho CRM的营销自动化模块功能全面</li></ul><h3>4. 根据预算与ROI考虑</h3><p>实施CRM时不仅要考虑软件许可成本，还需评估：</p><ul><li>实施与定制成本</li><li>培训与变更管理投入</li><li>集成与维护费用</li><li>预期投资回报周期</li></ul><h3>5. 未来适应性评估</h3><p>在2026年，选择CRM还需考虑系统如何适应未来变化：</p><ul><li>是否支持低代码/无代码扩展</li><li>AI能力的可升级性</li><li>数据迁移和系统集成的便捷性</li><li>供应商的创新路线图</li></ul><h2>八、实施成功的关键因素</h2><p>无论选择哪款CRM系统，成功实施都离不开以下关键因素：</p><ol><li><strong>明确业务目标</strong>：在选型前清晰定义CRM要解决的核心问题</li><li><strong>高层支持与跨部门协作</strong>：CRM成功需要全组织参与</li><li><strong>分阶段实施</strong>：从核心功能开始，逐步扩展，降低风险</li><li><strong>持续培训与支持</strong>：投资于用户培训和变革管理</li><li><strong>数据质量治理</strong>：建立数据标准和质量维护流程</li><li><strong>定期评估与优化</strong>：定期评估使用效果，持续优化流程</li></ol><h2>结语</h2><p>2026年的CRM市场呈现出多元化、智能化和生态化特征，没有“一刀切”的最佳选择，只有最适合企业特定需求的解决方案。</p><ul><li>八骏CRM为重视本土化定制和灵活性的中国企业提供了可靠选择；</li><li>SAP CRM继续服务于对端到端集成有严格要求的大型组织；</li><li>Zoho CRM以其出色的性价比吸引着中小企业；</li><li>Freshsales专注于提升销售团队效率；</li><li>Microsoft Dynamics 365则是微软生态企业的自然延伸。</li></ul><p>在数字化转型的下半场，CRM系统已从“可选工具”变为“核心基础设施”。明智的企业不仅在选择技术，更在选择长期的数字化转型伙伴。建议企业在最终决定前，充分利用各供应商的试用期，进行小范围试点，确保所选系统能够真正赋能团队、提升客户体验并驱动业务增长。</p><p>无论选择哪条路径，2026年成功的企业都将是那些能够将CRM系统深度融入运营DNA，真正实现以客户为中心的组织。</p>]]></description></item><item>    <title><![CDATA[Hono 路由器为什么这么快？ jump__jump ]]></title>    <link>https://segmentfault.com/a/1190000047570573</link>    <guid>https://segmentfault.com/a/1190000047570573</guid>    <pubDate>2026-01-25 12:01:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <blockquote>从底层引擎优化角度，深入剖析 Hono 路由器的极致性能奥秘</blockquote><hr/><h2>引言</h2><p>在众多 JavaScript Web 框架中，Hono 以其极致的性能表现脱颖而出。特别是在 <strong>Cloudflare Workers、Deno 等边缘计算环境</strong>中，Hono 的路由匹配速度在同类框架中名列前茅。这背后的秘密是什么？答案就藏在它的 <strong>RegExpRouter</strong> 实现中。</p><blockquote><strong>⚠️ 重要提示</strong>：本文重点讨论 RegExpRouter 的核心原理。在实际应用中，Hono 使用 SmartRouter 自动组合多种路由器（RegExpRouter、TrieRouter、LinearRouter）以达到最佳性能。</blockquote><p>本文将通过一个精简的实现，深入剖析 Hono 路由器的核心原理，帮助你理解：</p><ul><li>为什么 RegExp 路由比传统路由快</li><li>路由是如何预编译的</li><li>参数提取的巧妙设计</li></ul><hr/><p><strong>📌 关键要点</strong></p><table><thead><tr><th>项目</th><th>说明</th></tr></thead><tbody><tr><td>核心原理</td><td>将路由预编译为正则表达式，利用引擎底层优化</td></tr><tr><td>性能优势</td><td>减少 JS 层开销，一次原生调用完成匹配</td></tr><tr><td>最佳环境</td><td>Cloudflare Workers、Deno 等边缘计算平台</td></tr><tr><td>实际架构</td><td>SmartRouter + RegExpRouter + TrieRouter 组合</td></tr><tr><td>权衡考虑</td><td>Node.js 环境性能打折扣，路由注册较慢</td></tr></tbody></table><h2>传统路由的性能瓶颈</h2><p>在理解 Hono 的优化之前，我们先看看传统路由的处理方式：</p><pre><code class="javascript">// 传统路由的典型实现
function matchRoute(path, routes) {
  for (const route of routes) {
    // 1. 字符串分割
    const pathParts = path.split('/');
    const routeParts = route.path.split('/');

    // 2. 逐段比较
    if (pathParts.length !== routeParts.length) continue;

    const params = {};
    let matched = true;

    // 3. JS 层面的循环和条件判断
    for (let i = 0; i &lt; pathParts.length; i++) {
      if (routeParts[i].startsWith(':')) {
        params[routeParts[i].slice(1)] = pathParts[i];
      } else if (pathParts[i] !== routeParts[i]) {
        matched = false;
        break;
      }
    }

    if (matched) return { route, params };
  }
  return null;
}</code></pre><p><strong>性能问题在哪里？</strong></p><ul><li>❌ 大量的字符串操作（<code>split</code>、<code>slice</code>）</li><li>❌ 多层循环和条件判断，全在 JavaScript 层面执行</li><li>❌ 每个请求都要重复这些操作</li></ul><h2>Hono 的解决方案：下沉到引擎层</h2><p>Hono 的核心思想非常简单却极其巧妙：</p><blockquote><strong>将路由匹配逻辑从 JavaScript 层下沉到 JavaScript 引擎底层（C++ 实现的正则表达式引擎）</strong></blockquote><h3>1. 预编译阶段（应用启动时）</h3><p>在应用启动时，Hono 会将路由路径转换为正则表达式：</p><pre><code class="typescript">// 路由路径：/user/:id/posts/:postId
// 转换为正则：/^\/user\/([^/]+)\/posts\/([^/]+)$/

const paramNames: string[] = [];

const regexPath = path.replace(/:([a-zA-Z0-9_]+)/g, (_, paramName) =&gt; {
  paramNames.push(paramName); // 记录参数名
  return '([^/]+)';           // 替换为捕获组
});

const pattern = new RegExp(`^${regexPath}$`);</code></pre><p><strong>关键点：</strong></p><ul><li><code>:id</code> → <code>([^/]+)</code>：匹配除 <code>/</code> 外的任意字符</li><li>参数名被保存在 <code>paramNames</code> 数组中</li><li>这个"昂贵"的编译过程只在启动时执行一次</li></ul><h3>2. 匹配阶段（请求到来时）</h3><p>当请求到来时，只需要一行代码：</p><pre><code class="typescript">const match = pattern.exec(path);</code></pre><p><strong>这行代码的魔法：</strong></p><ul><li>✅ <code>exec</code> 是 JavaScript 引擎的原生方法，由 C++ 实现</li><li>✅ 正则引擎在底层进行了高度优化（状态机、JIT 编译等）</li><li>✅ 无需手动分割字符串、无需 JS 层循环</li><li>✅ 参数提取通过捕获组自动完成</li></ul><h3>3. 参数提取</h3><p>匹配成功后，参数提取也非常简洁：</p><pre><code class="typescript">const params: Record&lt;string, string&gt; = {};
route.paramNames.forEach((name, index) =&gt; {
  params[name] = match[index + 1]; // match[0] 是完整匹配
});</code></pre><h2>完整实现解析</h2><p>让我们看完整的简化实现，包含所有必要的类型定义：</p><pre><code class="typescript">// ============ 类型定义 ============

/**
 * 路由处理函数类型
 * @param params - 从 URL 中提取的参数对象
 */
type Handler = (params: Record&lt;string, string&gt;) =&gt; void;

/**
 * 路由信息接口
 */
interface Route {
  method: string;        // HTTP 方法（GET, POST, etc.）
  path: string;          // 原始路径模式（如 /user/:id）
  handler: Handler;      // 路由处理函数
  paramNames: string[];  // 参数名数组（如 ['id', 'postId']）
}

/**
 * 匹配结果接口
 */
interface MatchResult {
  handler: Handler;
  params: Record&lt;string, string&gt;;
}

// ============ 核心路由器实现 ============

export class DemoRegExpRouter {
  // 存储预编译的正则表达式和路由信息
  private routes: { pattern: RegExp; route: Route }[] = [];

  // 注册路由：预编译
  add(method: string, path: string, handler: Handler) {
    const paramNames: string[] = [];

    // 将 :param 转为正则捕获组
    const regexPath = path.replace(/:([a-zA-Z0-9_]+)/g, (_, paramName) =&gt; {
      paramNames.push(paramName);
      return '([^/]+)';
    });

    const pattern = new RegExp(`^${regexPath}$`);
    this.routes.push({ pattern, route: { method, path, handler, paramNames } });
  }

  // 匹配路由：执行正则
  match(method: string, path: string) {
    for (const { pattern, route } of this.routes) {
      if (route.method !== method &amp;&amp; route.method !== 'ALL') continue;

      const match = pattern.exec(path); // 核心：原生正则匹配

      if (match) {
        const params: Record&lt;string, string&gt; = {};
        route.paramNames.forEach((name, index) =&gt; {
          params[name] = match[index + 1];
        });
        return { handler: route.handler, params };
      }
    }
    return null;
  }
}</code></pre><h2>实战示例</h2><pre><code class="typescript">const router = new DemoRegExpRouter();

// 注册路由
router.add('GET', '/user/:id', (params) =&gt; {
  console.log(`获取用户详情，ID: ${params.id}`);
});

router.add('GET', '/user/:id/posts/:postId', (params) =&gt; {
  console.log(`获取用户 ${params.id} 的文章 ${params.postId}`);
});

// 匹配请求
const result = router.match('GET', '/user/123/posts/456');
if (result) {
  result.handler(result.params);
  // 输出: 获取用户 123 的文章 456
}</code></pre><h2>性能优势分析</h2><p><strong>为什么 RegExpRouter 更快？</strong></p><ol><li><strong>减少 JS 执行开销</strong>：从多层循环降到一次原生调用</li><li><strong>引擎优化</strong>：正则引擎经过数十年优化，包含 JIT、状态机等技术</li><li><strong>减少内存分配</strong>：无需频繁创建数组、对象</li><li><strong>一次性编译</strong>：预编译阶段完成所有准备工作，请求时零额外开销</li></ol><p><strong>性能对比概览</strong></p><table><thead><tr><th>方案</th><th>实现层次</th><th>执行效率</th><th>适用场景</th></tr></thead><tbody><tr><td>传统路由</td><td>JavaScript 层</td><td>中等</td><td>通用场景</td></tr><tr><td>RegExpRouter</td><td>引擎底层</td><td>极快</td><td>边缘计算、高并发</td></tr></tbody></table><blockquote><strong>📊 实际 Benchmark</strong>：根据 <a href="https://link.segmentfault.com/?enc=Cw52SaMSrwH3%2BtSxkuPxAg%3D%3D.97IUa%2F065eW6tNzdaXwj48wXQhBDS7nfN%2FBC3usWCuu5nFTycPhgfm2cbWth1LEd" rel="nofollow" target="_blank">Hono 官方测试</a>，在 Cloudflare Workers 和 Deno 环境中，Hono 是同类框架中最快的。但在 Node.js 环境中，由于适配器开销，性能优势会打折扣。</blockquote><h2>Hono 真实实现的进一步优化</h2><p>本文的简化版每个路由都是独立的正则表达式。而 Hono 的真实实现采用了<strong>多路由器协同</strong>的策略：</p><h3>1. SmartRouter（智能路由器）</h3><p>Hono 默认使用 <strong>SmartRouter</strong>，它会：</p><ul><li>根据路由特征自动选择最快的路由器</li><li>动态组合 RegExpRouter、TrieRouter、LinearRouter</li><li>检测路由模式并持续使用最优方案</li></ul><h3>2. 路由器分工</h3><table><thead><tr><th>路由器</th><th>适用场景</th><th>特点</th></tr></thead><tbody><tr><td><strong>RegExpRouter</strong></td><td>动态参数路由</td><td>最快，但不支持所有模式</td></tr><tr><td><strong>TrieRouter</strong></td><td>复杂路由模式</td><td>支持所有模式，性能优秀</td></tr><tr><td><strong>LinearRouter</strong></td><td>少量路由</td><td>简单可靠，路由少时够用</td></tr></tbody></table><h3>3. 实际优化策略</h3><ul><li><strong>静态路由优先</strong>：<code>/about</code>、<code>/contact</code> 等使用 Map 快速查找</li><li><strong>路由预分组</strong>：按 HTTP 方法分组，减少匹配次数</li><li><strong>延迟编译</strong>：RegExpRouter 编译较慢，适合应用启动时初始化，不适合无服务器环境的冷启动</li></ul><p>这些优化使得 Hono 在处理数百个路由时仍然保持极高性能。</p><h2>局限性与权衡</h2><p>RegExpRouter 并非银弹，在使用时需要注意以下限制：</p><h3>RegExpRouter 的局限</h3><ul><li><strong>不支持所有路由模式</strong>：某些复杂的路由规则无法用简单正则表示</li><li><strong>注册阶段较慢</strong>：路由编译需要时间，不适合每次请求都重新初始化的环境（如某些无服务器冷启动场景）</li><li><strong>调试难度</strong>：编译后的正则表达式可读性较差，出错时难以定位</li><li><strong>模式约束</strong>：如带严格约束的参数 <code>/:id(\\d+)</code> 需要额外处理</li></ul><h3>运行环境差异</h3><table><thead><tr><th>环境</th><th>性能表现</th><th>原因</th></tr></thead><tbody><tr><td>Cloudflare Workers</td><td>⭐⭐⭐⭐⭐ 极快</td><td>原生 Web 标准 API</td></tr><tr><td>Deno</td><td>⭐⭐⭐⭐⭐ 极快</td><td>原生 Web 标准 API</td></tr><tr><td>Bun</td><td>⭐⭐⭐⭐ 很快</td><td>高性能 JS 运行时</td></tr><tr><td>Node.js</td><td>⭐⭐⭐ 中等</td><td>需要适配器转换</td></tr></tbody></table><blockquote><strong>💡 选型建议</strong>：如果你的应用运行在边缘计算环境（Cloudflare Workers、Vercel Edge Functions 等），Hono 是绝佳选择。如果是传统 Node.js 服务器，Fastify 可能是更好的选择。</blockquote><p>但对于大多数 Web 应用场景，RegExpRouter 的性能与功能平衡已经足够优秀。</p><h2>总结</h2><p>Hono 的 RegExpRouter 通过"预编译 + 引擎下沉"的策略，在特定环境中将路由匹配性能提升到极致：</p><h3>核心优势</h3><ol><li><strong>预编译</strong>：启动时一次性将路由转为正则，摊销成本</li><li><strong>引擎下沉</strong>：利用 C++ 实现的正则引擎，避免 JS 层开销</li><li><strong>参数捕获</strong>：巧妙利用正则捕获组，无需手动解析</li><li><strong>智能组合</strong>：SmartRouter 自动选择最优路由器，兼顾性能与功能</li></ol><h3>设计哲学</h3><p>这种设计哲学值得我们思考：<strong>性能优化的终极目标，往往是让"热路径"代码尽可能多地运行在更底层的优化环境中</strong>。</p><p>对于 Web 框架来说，路由匹配就是最热的路径之一。Hono 在边缘计算环境中找到了这个问题的最优解，同时通过多路由器架构保证了广泛的适用性。</p><h3>最佳实践</h3><ul><li>✅ <strong>边缘计算/Serverless</strong>：Hono 是首选（Cloudflare Workers、Deno Deploy）</li><li>✅ <strong>高并发场景</strong>：充分发挥 RegExpRouter 性能优势</li><li>⚠️ <strong>Node.js 环境</strong>：考虑性能权衡，或选择 Fastify 等专门优化的框架</li><li>⚠️ <strong>复杂路由规则</strong>：了解 RegExpRouter 的限制，必要时使用 TrieRouter</li></ul><hr/><p><strong>延伸阅读：</strong></p><ul><li><a href="https://link.segmentfault.com/?enc=ZNBuCpFK6E99bG4H7eyLhQ%3D%3D.PGxEg1KAl%2F8T8B1VBNU9jI0JCmYYHPAiEgINeEyIsaw%3D" rel="nofollow" target="_blank">Hono 官方文档</a></li><li><a href="https://link.segmentfault.com/?enc=0LPrn%2FJejlEBhjz5RdB8eg%3D%3D.LB7VpYM1yUIu0h7%2B9H59t8%2FEU0OPOPPJZ5ZzN0meQ1YBVSbwT6XvFNTI5KfHpKtW" rel="nofollow" target="_blank">Hono Routers 详解</a></li><li><a href="https://link.segmentfault.com/?enc=%2BfWHKwHfklFcmBQXld7GAA%3D%3D.TtxHNPpg5Igb02TL%2BM1EA%2FsAbvOoroWoTA7Mldoliak6VvS6DOu3BmonH%2F4LJEia" rel="nofollow" target="_blank">Hono Benchmarks</a></li><li><a href="https://link.segmentfault.com/?enc=lrNAkAkkSH0QzK3agDb6Qg%3D%3D.xmReY0yOiTTz96VIuR7b0Sfc50vxsDqnK%2FXHhG5uh4g%3D" rel="nofollow" target="_blank">V8 正则引擎优化技术</a></li><li><a href="https://link.segmentfault.com/?enc=HWr6rGcKiGDnGa11W9nBAw%3D%3D.BN2lW9MMcVyQGbaQetMb7VnL2VUid0Ix2RRtTvN6NzmYULcKj20JWHLWoAd49zGo" rel="nofollow" target="_blank">Web 框架性能对比工具</a></li></ul><p><strong>技术资源：</strong></p><ul><li><a href="https://link.segmentfault.com/?enc=iA%2BI8FaNKd9EDQ7%2BvxpiYw%3D%3D.h1G7D%2Bie6wf%2B7tEM%2BeBvBSXTfFxwpzBV0ii45VUHADU%3D" rel="nofollow" target="_blank">Hono GitHub 仓库</a></li><li><a href="https://link.segmentfault.com/?enc=ifBjrFuX8ZFuGRhetdM3Gw%3D%3D.7FbucF5Si%2Fku8ZVcdrd4CX7MzZVsvBgwGBcfqvgwoso%3D" rel="nofollow" target="_blank">RegExpRouter 创建者：Taku Amano</a></li></ul><hr/><p><strong>📝 文章说明</strong></p><p>本文基于对 Hono 框架的学习和研究编写，代码示例为简化版实现，用于教学目的。实际的 Hono RegExpRouter 实现更加复杂和优化。</p><p>性能数据和对比来自 Hono 官方文档和社区测试，具体数值会因测试环境、负载类型、运行时版本等因素而异。实际使用时请根据自己的场景进行测试。</p><p>如果您发现文中有任何不准确之处，欢迎指正。</p>]]></description></item><item>    <title><![CDATA[TG/纸飞机连不上、付不了费怎么办？解决方法来了 纸飞机维修员 ]]></title>    <link>https://segmentfault.com/a/1190000047570475</link>    <guid>https://segmentfault.com/a/1190000047570475</guid>    <pubDate>2026-01-25 11:02:04</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>不少用户于尝试运用即时通讯以及网络工具之际，或许会碰到连接方面的问题或者是支付所遭遇的障碍，这一般跟网络环境、服务提供商的策略以及技术的细节存在关联。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047570477" alt="图片" title="图片"/><br/>针对于技术层面而言，特定应用于某些区域出现的连接状况，常常是由于网络路由或者本地化服务器节点不稳定造成的 ，用户能够试着改变连接形式 ，像是运用不一样的网络环境 ，或者去查看应用是不是最新版本 ，有时候 ，单纯的重启设备也能够化解临时性的服务中断 。</p><blockquote><a href="https://link.segmentfault.com/?enc=OSRCRhyltFcuMPv7kxZiHQ%3D%3D.aJmby2mwN3LPwQkvXZnl9VhQh6eLkpn5zcxtpZunPTeNWvfAJveBsgILsEgxgXonfNoi5nPEfBxWLU9HP7HQbg%3D%3D" rel="nofollow" target="_blank">点击参考三方版方案</a></blockquote><p>就应用内收费页面出现卡顿情形而言，其常见缘由包含多个层面，其中有支付网关响应延迟，这有可能致使在做支付操作之际，数据传输存有延缓问题，进而引发页面卡顿状况，应用缓存过多同样会引发问题，过多缓存数据占据了系统资源，致使应用在加载收费页面的时候变得迟缓，此外，当前服务器负载过高也不可忽视，当服务器承受过多请求时，处理能力降低，会对应用内收费页面的流畅显示产生影响 。处理这种情形时，能采取一系列举措。首先得清除应用缓存数据，借助清理缓存，给应用腾出更多资源，让其能更顺畅地运行收费页面。与此同时，要确保支付渠道（像绑定的账户）状态正常，要是支付渠道存在异常，像账户余额不足、网络连接问题等，一样会致使收费页面卡顿。另外，检查手机系统权限设置非常关键，要保证应用有充足的网络访问权限，唯有如此，应用才可以在网络环境良好时，稳定且快速地加载收费页面，防止出现卡顿情形。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047570480" alt="图片" title="图片" loading="lazy"/><br/>那种技术问题您有没有碰到过呢，方式是怎样解决的呀，实际经验还有有效的办法欢迎在评论区分享出来哦 ？</p>]]></description></item><item>    <title><![CDATA[VMware vSphere Replication 9.0.5 发布 - 虚拟机复制和数据保护 s]]></title>    <link>https://segmentfault.com/a/1190000047570492</link>    <guid>https://segmentfault.com/a/1190000047570492</guid>    <pubDate>2026-01-25 11:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>VMware vSphere Replication 9.0.5 发布 - 虚拟机复制和数据保护</p><p>vSphere Replication 9.0 Update 5</p><p>请访问原文链接：<a href="https://link.segmentfault.com/?enc=yJFJkRbuilk%2FsWj%2Bi6UQ5g%3D%3D.dd5DCfzlNM3xly3LyvUail%2F6xzFTdWvZQ19xlu3VschkkpkOmzFmigeVy8BZ4glJKJ%2BWRPC2TVxiWqcGtAAoRg%3D%3D" rel="nofollow" target="_blank">https://sysin.org/blog/vmware-vsphere-replication-9/</a> 查看最新版。原创作品，转载请保留出处。</p><p>作者主页：<a href="https://link.segmentfault.com/?enc=QxKjJFkwAutlRUVKbF48jQ%3D%3D.e7I9MpP2qywOlilJRtH16cve%2BBwxX%2FA9eJuFKCA3I6U%3D" rel="nofollow" target="_blank">sysin.org</a></p><hr/><h2>产品简介</h2><p>什么是 vSphere Replication 以及它如何帮助实现虚拟机灾难恢复？</p><p>VMware vSphere Replication 是基于 Hypervisor 的异步复制解决方案，适用于 vSphere  虚拟机。它与 VMware vCenter Server 和 vSphere Web Client 全面集成。vSphere  Replication 提供灵活、可靠和经济高效的复制功能 (sysin)，以支持环境中所有虚拟机的数据保护和灾难恢复。</p><p>应用场景</p><ul><li>单一站点的本地数据保护</li><li>两个站点间的灾难恢复和规避</li><li>利用服务提供商的云进行灾难恢复和规避</li><li>数据中心迁移</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047570494" alt="Enhanced vSphere Replication" title="Enhanced vSphere Replication"/></p><p><strong>构建灵活配置</strong>：</p><p>vSphere Replication 提供灵活的恢复选项，确保应用和虚拟机数据保持一致，并与 VMware 产品体系集成。使用 vSphere Replications 能够：</p><ul><li>自定义恢复点目标 (RPO)，从 5 分钟到 24 小时</li><li>使用多时间点 (MPIT) 恢复，还原到上一已知状态</li><li>在每个 vCenter Server 环境中保护多达 2,000 个虚拟机</li><li>使用 Microsoft 卷影复制服务 (VSS)</li><li>使用 Linux 文件系统静默 (sysin)</li><li>利用 VMware Site Recovery Manager 实现跨站点灾难恢复的自动化</li><li>保护和恢复 VMware vSAN 中的虚拟机</li><li>保护和恢复 vSphere Virtual Volumes 数据存储中的虚拟机</li></ul><p><strong>消除存储限制</strong>：</p><p>vSphere Replication 是基于 Hypervisor 的复制解决方案，在单个虚拟机磁盘 (VMDK) 级别运行，可以在  vSphere 支持的异构存储类型之间复制单个虚拟机。由于 vSphere Replication 独立于底层存储，因此适用于各种存储类型，包括 VMware vSAN、vSphere Virtual Volumes、传统 SAN、网络连接存储 (NAS) 和直连存储  (DAS)。您能够：</p><ul><li>在链接站点使用不同的存储技术，例如 SAN 到 vSAN 和光纤通道 (FC) 到 Internet 小型计算机系统接口 (iSCSI) 安排</li><li>在恢复站点改变旧存储的用途，以降低成本</li><li>仅对受保护虚拟机，而不是整个环境使用辅助存储</li></ul><p><strong>降低网络带宽</strong>：</p><p>vSphere Replication 仅将改动的数据复制到恢复站点，以降低带宽使用，提升网络效率，与手动复制整个系统相比，RPO 时间更短。利用 vSphere Replication，您可以：</p><ul><li>利用虚拟机数据的“种子副本”进行最初同步，缩短创建初始副本所需的时间</li><li>跟踪发生更改的磁盘区域，仅复制这些改动，确保高效利用网络</li><li>还可选择启用数据压缩功能，进一步减少网络带宽消耗</li></ul><h2>新增功能</h2><p>VMware Live Recovery 9.0.5 | 2026 年 1 月 20 日 | Build 25103105</p><p>VMware vSphere Replication 9.0.5 | 2026 年 1 月 20 日 | Build 25103105</p><p><strong>VMware Live Recovery Appliance 9.0.5 新增功能</strong>：</p><ul><li>VMware Live Recovery 9.0.5 版本提供了多项错误修复。</li><li>VMware Live Recovery 9.0.5 新增对 VMware Cloud Foundation 9.0.2 的兼容性支持。</li></ul><p><strong>已解决的问题</strong>：</p><ul><li><p>无法启动 vSphere Replication</p><p>在全新部署 VMware Live Recovery Appliance 9.0.4，或在升级 / 合并 vSphere Replication 至 9.0.4 版本后 (sysin)，如果使用了链式证书（chained certificates），VMware Live Site Recovery UI 会报告以下错误：</p><p><code>No connection to VR Server for virtual machine [VM] on host [Host] in cluster [Cluster] in Production: Unknown</code></p><p>该问题已在 VMware Live Recovery 9.0.5 中修复。</p></li></ul><h2>下载地址</h2><p><strong>VMware vSphere Replication 9.0 Update 5</strong> (9.0.5)</p><p>请访问：<a href="https://link.segmentfault.com/?enc=EU8MvYGt%2FiKHJTaWVz3Gwg%3D%3D.vF1qLhYAPye8agxn9CX7hrezRNUW91ld6SRaa%2Fmv99jYJpwZLCXIHNH3RJZNbJoZaeddpOSHMcQoY0QQKcEkNQ%3D%3D" rel="nofollow" target="_blank">https://sysin.org/blog/vmware-vsphere-replication-9/</a></p><h2>兼容性</h2><p>一图看懂 vSphere Replication 兼容性</p><p>如何选择版本？根据当前 vSphere 版本，下载最新兼容的版本即可。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047570495" alt="vSphere Replication 兼容性" title="vSphere Replication 兼容性" loading="lazy"/></p><hr/><p>上一个版本：<a href="https://link.segmentfault.com/?enc=Jue5F6f4UTR28EF7Aoke9w%3D%3D.qJMfE%2BCNtPsyBSTVFAn0j5WdqSooDsalppXiVyhXWgQs7I%2Bzs2zPMI4WeY2UCskkPV05M7MKw1ze5UynAASn%2Fw%3D%3D" rel="nofollow" target="_blank">VMware vSphere Replication 8.8 Update 3 - 虚拟机复制和数据保护</a></p><p>更多：<a href="https://link.segmentfault.com/?enc=piKlhIta2htvlLQNyA%2F28g%3D%3D.uKzHJEmP5GCmIQxouwKpiAMBENoO5AKAWB%2FtetC4b%2B4%3D" rel="nofollow" target="_blank">VMware 产品下载汇总</a></p>]]></description></item><item>    <title><![CDATA[如何检查本地 / 远程端口是否打开 ？ 本文系转载，阅读原文
https://www.koogua.]]></title>    <link>https://segmentfault.com/a/1190000047570421</link>    <guid>https://segmentfault.com/a/1190000047570421</guid>    <pubDate>2026-01-25 10:05:15</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047570423" alt="Check Open Port in Linux" title="Check Open Port in Linux"/></p><p>在 Linux 中，端口是一个编号的网络连接，它允许设备通过 Internet 或本地网络与其他设备通信。确保端口是开放和可访问的非常重要，它确保网络业务的正常运行。在本文中，我们将讨论五个检查 Linux 中端口是否打开的常用方法。</p><h3>Check Open Port on Remote Host</h3><p>首先，检查一个端口是否打开并在远程主机上侦听。</p><p><strong>Using nc Command</strong></p><p>nc 命令允许您向端口发送数据，并查看是否收到响应。nc 命令基本语法如下：</p><pre><code>nc -vz hostname port</code></pre><p>例如，要检查主机 example.com 上的 22 端口是否打开，可以使用以下命令：</p><pre><code>nc -vz example.com 22</code></pre><p>如果端口打开，您将看到消息 "Connection to hostname port [ tcp/ssh ]succeeded"。如果端口关闭，您将看到消息 "Connection to hostname port [ tcp/ssh ] failed: Connection refused"。</p><p><strong>Using telnet Command</strong></p><p>telnet 命令用于连接到远程主机上的端口，看看是否建立了连接。查询端口是否打开，使用以下语法：</p><pre><code>telnet hostname port</code></pre><p>例如，要检查主机 www.example.com 上的 80 端口是否打开，可以使用以下命令：</p><pre><code>telnet www.example.com 80</code></pre><p>如果端口是打开的，您将看到一个空白屏幕。要退出，请按 <code>CTRL + ]</code>，然后键入 quit。如果端口关闭，您将看到 "Connected to hostname. Escape character is '^]'. Connection closed by foreign host"</p><p><strong>Using nmap Command</strong></p><p><code>nmap</code> 命令是一个执行网络扫描和探测的实用程序，它可以通过端口扫描来检查目标主机端口是否打开。要检查端口是否打开，使用以下语法：</p><pre><code>nmap -p port hostname</code></pre><p>例如，要检查主机 www.example.com 上的 80 端口是否打开，可以使用以下命令：</p><pre><code>nmap -p 80 www.example.com</code></pre><p>如果端口是打开的，您将在输出中看到一行，表明端口是打开的。如果端口已关闭，您将看到一行，指示端口已关闭。</p><h3>Shell Script to Check Port Status</h3><p>您可以创建一个 bash 脚本检查本地或远程主机上端口是否打开，示例脚本如下：</p><pre><code>#!/usr/bin/env bash

HOST=192.168.10.100  #remote host
PORT=22  # Port to check

nc -z ${HOST} ${PORT}
if [ $? -eq 0 ]
then
    echo "Port is open"
else
    echo "Port is closed"
fi</code></pre><p>这里 <strong>HOST</strong> 是远程或本地主机系统的主机名或 IP 地址。<strong>PORT</strong> 是要检查的端口号。，<strong>nc</strong> 命令可以连接到主机上的任何端口并返回状态。<strong>$?</strong> 是一个系统环境变量，包含最后一个命令的退出状态。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047570424" alt="Check Script To Check Port Is Open " title="Check Script To Check Port Is Open " loading="lazy"/></p><h3>Check Listening Port on Localhost</h3><p>很多时候，我们需要检查本地机器上是否有端口正在侦听。</p><p><strong>Using lsof Command</strong></p><p><code>lsof</code> 命令是一个实用程序，用于显示有关打开文件的信息。要检查端口是否打开，使用以下语法：</p><pre><code>lsof -i :port</code></pre><p>例如，要检查 80 端口是否打开，可以使用以下命令：</p><pre><code>lsof -i :80</code></pre><p>如果端口打开，将看到一行，包含端口号和使用该端口的进程的名称。如果端口关闭，将看不到任何输出。</p><p><strong>Using ss Command</strong></p><p><code>ss</code> 命令是一个显示网络套接字信息的实用程序。要检查端口是否打开，使用以下语法：</p><pre><code>ss -lnp | grep port</code></pre><p>例如，要检查 80 端口是否打开，可以使用以下命令：</p><pre><code>ss -lnp | grep 80</code></pre><p>如果端口打开，将看到一行，其中包含端口号和状态 <strong>LISTEN</strong>。如果端口关闭，将看不到任何输出。</p><p><strong>注意：</strong> 您可能需要使用 <strong>sudo</strong> 来运行这些命令，这取决于您的系统配置。</p>]]></description></item><item>    <title><![CDATA[Drawpile-2.2.2-x86_64怎么用？完整安装与使用指南 读书笔记 ]]></title>    <link>https://segmentfault.com/a/1190000047570428</link>    <guid>https://segmentfault.com/a/1190000047570428</guid>    <pubDate>2026-01-25 10:04:28</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>​</p><p><code>Drawpile-2.2.2-x86_64.msi</code>是个<strong>在线绘画协作工具</strong>，可以多人同时在一张画布上画画，适合和朋友一起涂鸦、设计草图。</p><h2>一、准备工作</h2><p><strong>安装包下载：</strong><a href="https://link.segmentfault.com/?enc=APo01IJZKMP0VemyL7DwlQ%3D%3D.%2FCsrNV6C%2FZRqz6LFwUah7N7KyFbzKfa1QNnkpg9UxoaunWuy5FhkPSOiRscsLyfK" rel="nofollow" title="https://pan.quark.cn/s/ecd93f07c147" target="_blank">https://pan.quark.cn/s/ecd93f07c147</a></p><h2>二、安装步骤</h2><ol><li>双击 <code>Drawpile-2.2.2-x86_64.msi</code>运行。</li><li>如果是 Windows 10/11，会弹出“用户账户控制”提示 → 点  <strong>“是”</strong> （需要管理员权限）。</li><li>进入安装向导，点  <strong>“Next”</strong> ​ 继续。</li><li><p>选安装位置：</p><ul><li>默认是 <code>C:\Program Files\Drawpile</code>，想改就点“Browse”选 D 盘或其他盘。</li></ul></li><li><p>选附加任务：</p><ul><li>建议勾“Create a desktop shortcut”（创建桌面快捷方式），点“Next”。</li></ul></li><li>点  <strong>“Install”</strong> ​ 开始安装，等进度条走完（大概十几秒）。</li><li>最后点  <strong>“Finish”</strong> ​ 完成安装，桌面上会有 Drawpile 图标。</li></ol><h2>三、首次运行设置</h2><ol><li>双击桌面图标打开软件。</li><li>主界面会显示“Host session”（创建房间）和“Join session”（加入房间）两个选项。</li><li>想自己开房间就点“Host session”，设置房间名和密码（可选）。</li><li>想加入别人的房间就点“Join session”，输入对方的 IP 地址或房间链接。</li></ol><h2>四、基本使用（简单说两句）</h2><ul><li><strong>创建房间</strong>：点“Host session” → 填房间名 → 设密码（不想让别人随便进就设一个）→ 点“Start”。</li><li><strong>加入房间</strong>：点“Join session” → 输入房间地址（比如 <code>drawpile://192.168.1.100:27750</code>）→ 点“Join”。</li><li><strong>绘画工具</strong>：左边工具栏有画笔、橡皮、颜色选择器等，选了就能画。</li><li><strong>聊天功能</strong>：右下角有聊天框，可以和一起画画的人说话。</li></ul><p>​</p>]]></description></item><item>    <title><![CDATA[用C++画红苹果的步骤描述_C++精灵库画苹果教程 李兴球 ]]></title>    <link>https://segmentfault.com/a/1190000047570442</link>    <guid>https://segmentfault.com/a/1190000047570442</guid>    <pubDate>2026-01-25 10:03:37</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>这个用C++的精灵库画苹果的价值何在呢？任何东西，只要放在了正确的位置，都能发挥出它最大的价值。我们先来看一下代码：</p><pre><code>#include "sprites.h"  //包含C++精灵库 
Sprite t;      //建立角色叫t,t就像一只海龟，但它的造型默认是小火箭，因为C++精灵库的目标是培养走向星辰大海孩子

int main(){        //主功能块 
    
    t.bgcolor("black").speed(1).pu().addy(150).pd().left(30);
    //画苹果的轮廓
    t.circle(-400,12).circle(-100,90);
    t.circle(-200,200).circle(-100,90);
    t.circle(-400,12).fill("red",0,-10); //填充为红苹果
    
    t.penup().move(-30,-40); //移到这里开始画苹果的柄
    t.pensize(6).color("#520305").pendown();
    t.circle(100,60).circle(100,-30);    
    t.left(90).circle(100,30);
    t.right(90).color("#0fff33");
    t.pensize(2);    //开始画绿叶
    t.circle(60,90).left(90);
    t.circle(60,90).left(90);
    t.fill("green",5,15);  //填充绿色叶子
    t.left(90).color("#520305");
    t.pensize(6).circle(100,30);    
    
    t.ht().done();
  
   return 0;    //返回0
}</code></pre><p>这是上面的程序运行的效果：<br/><img width="414" height="425" referrerpolicy="no-referrer" src="/img/bVdnLpi" alt="" title=""/><br/>这段代码使用C++精灵库（Sprites）来绘制一个红苹果图形。它用类似Python turtle的circle命令来绘制苹果。所以上面的核心代码放到Python IDLE中,修改一下,也可以画出苹果.，我们来描述一下大概的绘画过程。</p><ol><li>准备画布和角色<br/>包含C++精灵库：首先，代码通过 #include "sprites.h" 引入了精灵库，这是绘制图形的基础。<br/>创建角色：Sprite t; 创建了一个名为 t 的角色，这个角色就像一只可以画画的海龟，但它默认的造型是一个小火箭。为什么要设计一枚火箭作为角色的默认造型？这里面的讲究就是蕴涵航天科技。</li><li>设置画布背景和初始位置<br/>通过一定的准备工作，如设置背景色和速度，代码为，t.bgcolor("black").speed(1).pu().addy(150).pd().left(30); 这行代码设置了画布背景为黑色，角色移动速度为1（较慢），然后角色抬起笔（pu()），向上移动150个单位（addy(150)），放下笔（pd()），并向左转30度（left(30)）。这样角色就准备好了。</li><li>画苹果的轮廓<br/>接着角色绘制苹果的轮廓：这几行代码 t.circle(-400,12).circle(-100,90); t.circle(-200,200).circle(-100,90); t.circle(-400,12).fill("red",0,-10); 通过多个 circle 方法绘制了苹果的轮廓。这些 circle 方法通过不同的参数（如半径和角度）来画出苹果的不规则圆形轮廓。最后，fill("red",0,-10); 将苹果的内部填充为红色。</li><li>画苹果的柄<br/>为了更加形象，画出苹果的其它组织。比如一个小柄，首先移动到柄的位置：t.penup().move(-30,-40); <br/>绘制柄：t.pensize(6).color("#520305").pendown(); t.circle(100,60).circle(100,-30); t.left(90).circle(100,30); 设置画笔的粗细为6，颜色为深棕色（#520305），然后放下笔开始画苹果的柄。通过几个 circle 方法和 left 方法来画出弯曲的柄。</li><li>画绿叶<br/>少了绿叶的衬托怎么行呢？ 所以要绘制绿色的叶子：t.right(90).color("#0fff33"); t.pensize(2); t.circle(60,90).left(90); t.circle(60,90).left(90); t.fill("green",5,15); 角色右转90度，设置画笔颜色为亮绿色（#0fff33）和粗细为2，然后画两个弧形来形成叶子的形状，并用 fill("green",5,15); 填充为绿色。</li><li>完成柄的绘制<br/>完成柄的剩余部分：t.left(90).color("#520305"); t.pensize(6).circle(100,30); 角色左转90度，恢复柄的颜色和粗细，完成柄的剩余部分绘制。</li><li>结束绘制<br/>隐藏角色并完成：最后，t.ht().done(); 隐藏角色（ht()）并结束绘制（done()）。<br/>这样，一个红苹果就绘制完成了！这段代码通过一系列精确的移动和绘制命令，逐步构建出了一个形象生动的苹果图形。</li></ol><p>总之，代码比较简单，只要灵活动用circle命令即可。它的最大价值在于青少儿C++编程的教育意义。遵循逐层递进的原则，让孩子们首先掌握在这一个层次的代码，以便为以后更加深入的算法等编程树立良好的信心。<br/><a href="https://www.bilibili.com/video/BV1vgz1BDEsv/?aid=115950242302201&amp;cid=35588607693" target="_blank">https://www.bilibili.com/video/BV1vgz1BDEsv/?aid=115950242302...</a></p>]]></description></item><item>    <title><![CDATA[openssl-libs-1.1.1f-4.p12.ky10.x86_64.安装指南 解决依赖与常见]]></title>    <link>https://segmentfault.com/a/1190000047570448</link>    <guid>https://segmentfault.com/a/1190000047570448</guid>    <pubDate>2026-01-25 10:02:44</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>​</p><h3>一、准备工作：先瞅一眼有没有装过</h3><p>动手之前，最好先看一眼系统里是不是已经有这个包了，或者版本对不对。省得装重复了或者搞混。</p><p>打开终端，输入下面这个命令，然后回车：</p><pre><code>rpm -q openssl-libs</code></pre><ul><li>如果屏幕上显示 <code>package openssl-libs is not installed</code>，那恭喜你，说明没装，可以继续往下走。</li><li>如果显示了版本号，比如 <code>openssl-libs-1.1.0-xxx</code>，那就说明已经有旧版本了，等下安装就是升级。</li></ul><h3>二、开装！主要就一条命令</h3><p>这个 <code>.rpm</code>文件，咱们用系统自带的 <code>rpm</code>命令来装就行。</p><p><strong>前提：</strong> ​ <strong>安装包下载：</strong><a href="https://link.segmentfault.com/?enc=GtE%2BOoZxfkZds7XZ15ltfg%3D%3D.NZCr7vycfkcvCxrd%2FMZNa5bdn360rV1RnZkuwWa6aCL0tlq1CpEDhI3xWFvrQanW" rel="nofollow" title="https://pan.quark.cn/s/cab1300e30b5" target="_blank">https://pan.quark.cn/s/cab1300e30b5</a> ，你得先把那个 <code>openssl-libs-1.1.1f-4.p12.ky10.x86_64.rpm</code>文件下载到你的电脑上，比如放到了 <code>/home/你的用户名/Downloads</code>这个文件夹里。</p><ol><li><strong>打开终端</strong>。</li><li><p><strong>进入存放文件的目录</strong>。比如文件在“下载”目录，你就输入：</p><pre><code>cd ~/Downloads</code></pre></li></ol><pre><code>然后按回车。`~`符号代表你的家目录，就这么写没错。
</code></pre><ol><li><p><strong>执行安装命令</strong>。最关键的一步来了，输入下面这行命令，把文件名换成你实际的文件名（如果一样就不用换）：</p><pre><code>sudo rpm -ivh openssl-libs-1.1.1f-4.p12.ky10.x86_64.rpm</code></pre></li></ol><pre><code>**命令解释一下：**

-   `sudo`：这个是说“用管理员权限来运行”，因为装软件得有管理员身份，所以会让你输密码，输了就行。

-   `rpm`：就是我们用来管理 `.rpm`包的工具。

-   `-ivh`：这是三个选项合在一起。

    -   `i`是 install（安装）。
    -   `v`是 verbose（显示详细信息，让你能看到进度）。
    -   `h`是 hash（显示进度条，一串 `#`号，看着比较直观）。
</code></pre><ol><li><strong>等着跑完</strong>。如果一切顺利，你会看到命令行开始刷 <code>#</code>号，最后回到输入提示符，没报啥大红字错误，那就算装完了。</li></ol><h3>三、可能遇到的问题和解决办法</h3><p>装软件哪有一帆风顺的，给你提个醒儿。</p><h4>问题1：提示“依赖检测失败”</h4><p>这是最常碰到的问题。意思是这个包正常工作，还需要别的某个包（依赖包）先装好才行。</p><p><strong>错误信息长这样：</strong></p><pre><code>error: Failed dependencies:
    xxx &gt;= 1.2 is needed by openssl-libs-...</code></pre><p><strong>咋办？</strong></p><p>别慌，这说明系统缺东西。你需要根据它提示的缺啥，去找那个对应的 <code>.rpm</code>包，先装上。有时候依赖关系比较复杂，一个个装很麻烦。</p><p><strong>一个偷懒的办法：</strong></p><p>如果你用的是 <code>yum</code>或者 <code>dnf</code>（新版本的 CentOS/Fedora 叫 dnf）这种更高级的包管理器，可以用它来装本地的 rpm 包，它会自动帮你把需要的依赖一起解决掉。</p><p>命令改成这样就行：</p><pre><code># 如果用 yum
sudo yum localinstall openssl-libs-1.1.1f-4.p12.ky10.x86_64.rpm

# 如果用 dnf (比如 KylinOS V10, 银河麒麟等)
sudo dnf localinstall openssl-libs-1.1.1f-4.p12.ky10.x86_64.rpm</code></pre><p>就用上面这两个命令之一，比直接用 <code>rpm</code>命令省心多了，强烈推荐！</p><h4>问题2：提示“文件冲突”或“已经安装”</h4><p>如果你之前系统里有旧版本，用 <code>rpm -ivh</code>去装新版本可能会报错。这时候如果你想覆盖安装（升级），可以加个 <code>--force</code>参数（<strong>慎用！</strong> ），但更好的办法还是用上面的 <code>yum localinstall</code>或 <code>dnf localinstall</code>，它们处理升级更稳妥。</p><h3>四、最后检查下，确认装好了</h3><p>装完之后，心里没底的话，可以再用第一步的命令验证一下。</p><pre><code>rpm -q openssl-libs</code></pre><p>这次输出的版本号，应该就是你刚装的 <code>1.1.1f</code>这个版本了。这就妥了！</p><p>​</p>]]></description></item>  </channel></rss>