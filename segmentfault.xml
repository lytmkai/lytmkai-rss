<?xml version="1.0" encoding="UTF-8"?><rss version="2.0">  <channel>      <title>SegmentFault - 最近文章</title>      <link>https://segmentfault.com/blogs/newest</link>      <description>SegmentFault 思否</description>      <generator>python segmentfault.py @Pi20</generator>      <item>    <title><![CDATA[AI 语音转贴纸，儿童打印机 Stick]]></title>    <link>https://segmentfault.com/a/1190000047412518</link>    <guid>https://segmentfault.com/a/1190000047412518</guid>    <pubDate>2025-11-19 20:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047412520" alt="" title=""/></p><p><strong>开发者朋友们大家好：</strong></p><p>这里是 <strong>「RTE 开发者日报」</strong> ，每天和大家一起看新闻、聊八卦。我们的社区编辑团队会整理分享 RTE（Real-Time Engagement） 领域内「有话题的<strong>技术</strong>」、「有亮点的<strong>产品</strong>」、「有思考的<strong>文章</strong>」、「有态度的<strong>观点</strong>」、「有看点的<strong>活动</strong>」，但内容仅代表编辑的个人观点，欢迎大家留言、跟帖、讨论。</p><p><em>本期编辑：@鲍勃</em></p><h2>01 有话题的技术</h2><p><strong>1、Spatial AI 发布第一人称真实世界数据集，教会机器人在现实世界完成任务</strong></p><p>Spatial AI 发布的首个开源数据集 SEA（Spatial Everyday Activities，空间日常活动）是迄今为止规模最大的、经过精心策划的以第一人称视角记录的、人们执行真实任务的数据集，数据量高达 10,000 小时。</p><p>Huggingface: <br/><a href="https://link.segmentfault.com/?enc=pxU71wtN3XeQen0Pf6egVQ%3D%3D.kOdMSZiqikGmVpMvjzJtBnsl%2FGvsew6IhURtfgc9bU0YskAr0pqJ8wL8GnReCq%2BtajDLx3k4Oks4xkGeK5L%2F4g%3D%3D" rel="nofollow" target="_blank">https://huggingface.co/datasets/spatial-ai/sea-small</a></p><p>官网：<br/><a href="https://link.segmentfault.com/?enc=MTEVuYM93RnffLZYv6dJAw%3D%3D.WJqtznKltJ95rXpIC21nt2qnxjQDa8h%2BdNjMEDxVpwM%3D" rel="nofollow" target="_blank">https://spatial-ai.com/</a></p><p>（@ycombinator\@X）</p><p><strong>2、LiveKit 重磅推出三大新功能，赋能开发者构建更卓越的语音智能体</strong></p><p>LiveKit 在 Dev Day 活动宣布上线三项革命性新功能——Agent Builder、Phone Numbers 和 Agent Observability，旨在极大地简化语音智能体的开发、部署与调试流程，助力开发者以前所未有的速度构建和优化更智能、更可靠的语音应用。</p><p><strong>1. Agent Builder：3 分钟内构建生产级语音智能体</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047412521" alt="" title="" loading="lazy"/></p><p>全新的 Agent Builder 是一款基于浏览器的无代码/低代码平台，让开发者能够快速创建、测试并部署语音智能体。用户只需提供系统提示（system prompt），即可在几分钟内启动语音智能体的构建。该平台集成了背景降噪、多语言识别等内置语音处理能力，并支持通过 HTTP 工具轻松扩展功能，连接 CRM、API 等外部服务。Agent Builder 提供内置的实时测试与一键部署功能，并集成了 Deepgram、AssemblyAI、GPT-4.1、Gemini 2.5 Flash 等多家知名供应商的模型，让开发者可以在内测阶段自由对比模型性能。最重要的是，Agent Builder 被设计为从原型到代码的桥梁，支持导出代码，实现从低代码到专业 SDK 开发的平滑过渡，大幅缩短语音 AI 应用的上市时间。</p><p><strong>2. Phone Numbers：60 秒内接入电话网络</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047412522" alt="" title="" loading="lazy"/></p><p>LiveKit Phone Numbers 是一项全新的首方电话服务，开发者无需第三方 SIP Trunk 即可在数分钟内将语音智能体直接连接到电话网络。用户可在 LiveKit Cloud 仪表盘或 CLI 中直接购买美国本地或免费电话号码，并快速关联到语音智能体，实现「零配置」上线。此举消除了中间环节，减少了网络延迟和故障点，显著提升了通话质量、音频清晰度和语音转文本（STT）准确率，进而优化了整体语音交互体验。这项服务尤其适用于需要电话交互的行业，可快速搭建 24/7 咨询、订单查询等语音智能体。</p><p><strong>3. Agent Observability：统一视图助力语音智能体故障排查</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047412523" alt="" title="" loading="lazy"/></p><p>Agent Observability Beta 版本现已集成于 LiveKit Cloud Dashboard，旨在解决语音智能体开发与部署中的棘手故障排查问题。用户现在可以在单一视图下，同步查看会话的音频、转录、逐轮智能体调用（LLM、TTS、转折点检测、工具调用等）以及日志。这种端到端的可见性，使得开发者能够像「听」和「看」一样，快速定位导致响应延迟、中断或任务失败的根本原因，极大地简化了以往需要在不同服务间手动关联日志和时间戳的复杂过程。会话录制功能支持可选启用，并提供灵活的数据控制选项。</p><p>( @LiveKit 官网)</p><p><strong>3、Google 正式发布 Gemini 3</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047412524" alt="" title="" loading="lazy"/></p><p>今天凌晨，<strong>Google DeepMind 正式发布新一代旗舰模型 Gemini 3</strong>，号称拥有最先进的推理能力、世界领先的多模态理解能力，并支持新的智能编码体验。<strong>本次首发版本为 Gemini 3 Pro</strong>，并且即日起开始全球范围内推出，亮点如下：</p><ul><li>Gemini 3 Pro 预览版原生多模态支持（文字、图像、视频、音频）</li><li>在 LMArena 排行榜登顶，在推理、多模态、编程等主流测试中全面领先</li><li>推理能力创纪录（GPQA Diamond 91.9%、MathArena Apex 23.4%）</li><li>提供 Deep Think 深度思考模式（未来几周开放）</li><li>100 万 token 上下文窗口 + 64K 输出</li><li>推出全新 AI IDE：Google Antigravity，新模型已集成 Cursor、GitHub、JetBrains 等工具</li></ul><p>值得一提的是， 推理能力方面， <strong>Gemini 3 Pro 在「人类最后的考试（Humanity’s Last Exam）」中拿到了 37.5% 的博士级推理成绩。</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047412525" alt="" title="" loading="lazy"/></p><p><strong>有趣的是，OpenAI CEO Sam Altman 刚刚也在 X 平台发文称：「恭喜 Google 成功推出 Gemini 3！看起来是个很棒的模型。」而马斯克则是表示「做得好」。</strong></p><p>( @APPSO)</p><hr/><h2>02 有亮点的产品</h2><p><strong>1、Hapiko 获 700 万美元融资，推出儿童 AI 语音转贴纸打印机 Stickerbox</strong></p><p>总部位于布鲁克林的创意科技公司 Hapiko 宣布获得 700 万美元融资，并正式发布了其首款产品「Stickerbox」。这款 AI 驱动的语音转贴纸打印机专为儿童设计，允许他们通过语音描述图像，然后打印出可供涂鸦和定制的黑白贴纸，旨在鼓励安全、具象的创意玩乐，而非被动屏幕时间。</p><ul><li><strong>AI 语音转贴纸：</strong> 「Stickerbox」是首款能让儿童通过语音（如「骑着滑板的恐龙」）生成图像并打印成黑白贴纸的设备。</li><li><strong>鼓励具象化创意：</strong> 产品旨在引导儿童从被动接受信息转向主动、开放式的想象和创造，将口头想法转化为实体贴纸。</li><li><strong>安全与隐私优先：</strong> 采用墨水无关的热敏打印技术，使用不含 BPA 和 BPS 的纸张，无摄像头，无持续数据收集，AI 系统从零开始设计，内置年龄适宜性过滤。</li><li><strong>独立玩乐体验：</strong> 无需智能手机或笔记本电脑即可独立操作，支持儿童动手实践的玩乐方式。</li><li><strong>700 万美元融资：</strong> 本轮融资由 Maveron 和 Serena Ventures（由网球明星 Serena Williams 创立）领投，将用于扩大生产和拓展儿童创意玩具及 AI 市场。</li></ul><p>「Stickerbox」现已在美国上市，可通过 stickerbox.com 购买，零售价为 99.99 美元。Hapiko 计划利用此次融资扩大生产规模并拓展市场。</p><p>(@Pulse 2.0)</p><p><strong>2、连锁餐饮正在用炒菜机器人取代预制菜</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047412526" alt="" title="" loading="lazy"/></p><p>据 36 氪报道，连锁餐饮品牌正加速引入炒菜机器人，以应对预制菜风波带来的行业挑战。</p><p>报道指出，老乡鸡、小菜园等餐企已在数百家门店部署智能烹饪设备，歌尔、富士康等大厂也开始在食堂场景中使用机器人，以提升出餐效率并降低人力成本。</p><p>炒菜机器人通过精准控温、自动搅拌与智能投料系统，实现标准化作业，既保留中餐「锅气」风味，又显著提高出餐速度。</p><p>烹饪机器人企业智谷天厨 CEO 耿凯平透露，过去一个月咨询需求增长近 10 倍，显示行业对智能化厨房的接受度快速提升。</p><p><strong>市场数据显示，一台售价约 6 万元的中型炒菜机器人，使用寿命可达 8 至 10 年，月均成本约 600 元。</strong>相比传统厨师每月 8000 至 15000 元的薪资，企业可在生命周期内节省数十万元至百万元不等的运营开支。</p><p>在企业团餐场景中，机器人还配备智能调度系统，可实时监测菜品余量与人流分布，动态补餐，避免食材浪费。</p><p>据实测，其浪费率可降低 70% 以上。业内人士指出，随着消费者对预制菜的抵触情绪加剧，机器人现炒成为餐企兼顾效率与品质的更优解。</p><p>( @APPSO)</p><p><strong>3、曝 Rabbit 公司停薪数月，官方坚称 Rabbit R1 下一代版本将面世</strong></p><p>11 月 18 日消息，据外媒报道，最近 Rabbit 因另一件事又被推上了风口浪尖：多名 Rabbit 员工称公司已连续数月拖欠工资，部分员工甚至从 10 月起直接罢工——可就在这个节骨眼上，Rabbit CEO 吕骋（Jesse Lyu）仍对外声称「计划在 2026 年推出下一代 AI 硬件」。</p><p>据报道，今年 1 月起，Rabbit 公司就开始出现发薪延迟的问题。原本每月仅是晚几天，可后来越来越严重：最严重的一次延迟了整整 37 天才发薪。到了 7 月，Rabbit 部分员工与外包人员彻底「停薪」，再没收到任何工资。10 月初，三名员工因长期未领到薪水而发起罢工，并一直持续到现在。更戏剧性的是，Rabbit 并未否认这一点，其发言人确认罢工的确存在，并强调：「公司共有 26 名员工，目前只有 3 人在罢工，我们完全尊重他们的决定。」</p><p>此前报道，Rabbit 公司在 2024 年推出了「口袋 AI 设备」Rabbit R1，当时官方宣称要让这款设备成为用户和智能手机的交互中介，并在开售 5 天后卖出 50000 台。不过首发用户上手后却发现，这款设备的实际表现远逊于发布会上宣称的效果，例如在实景拍摄过程中至少要等 20 秒才会回应，「比 Siri 还慢」，甚至有用户指出这款设备就是一个低端安卓手机装了一个 APK 文件。</p><p>（@IT 之家、CSDN、雷锋网）</p><h2>03 有态度的观点</h2><p><strong>1、Take-Two Interactive CEO 认为游戏行业正转向 PC</strong></p><p>Take-Two Interactive CEO Strauss Zelnick 在接受采访时表示，游戏行业正转向 PC 从封闭转向开放，但游戏机作为一种体验并不会消失。Zelnick 表示，游戏机和手游的市场份额产不多，但手游增长速度比游戏机更快。索尼 PS 和任天堂 Switch 的游戏机业务取得了成功，而竞争对手拥有 Xbox 的微软则暗示下一代硬件将更面向 PC 游戏。Valve 最近宣布的 Steam Machin 就是游戏机和 PC 的混合设备。</p><p>(@Solidot)</p><h2>04 社区黑板报</h2><p>招聘、项目分享、求助……任何你想和社区分享的信息，请联系我们投稿。（加微信 creators2022，备注「社区黑板报」）</p><p><strong>1、招聘实习生丨加入我们，共建 RTE 开发者社区</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047412527" alt="" title="" loading="lazy"/></p><p><strong>RTE 开发者社区·运营实习生（实时互动 / Voice AI 方向，本招聘长期有效）</strong></p><p><strong>地点：北京·朝阳区望京南/上海·杨浦区五角场</strong></p><p><strong>这份实习将给你带来：</strong></p><p><strong>产品与技术成长：</strong> 深入学习垂类 AI 产品从技术到落地的全生命周期，构建全面的产品视角。</p><p><strong>社区运营实战：</strong> 与高潜力的开发者和创业者深度交流，共同探索行业前沿；并亲身体验顶级 AI 大会，拓展行业视野。</p><p><strong>【你的职责】</strong></p><ol><li><strong>Voice AI / RTE 情报官：</strong> 每日关注 Voice AI /实时互动领域的最新动态，提炼整理并分享行业洞察，定期撰写学习笔记，帮助团队和社区保持信息前沿。</li><li><strong>社区连接者：</strong> 负责 RTE 领域开发者、初创企业等核心群体的社群运营，主动建立并深化联系，鼓励并协助他们融入社区，共同维护社区的活力与生态。</li><li><strong>活动协作者：</strong> 深度参与 RTE Open Day、Meetup、Dev Talk 等线上线下活动的全流程运营，包括前期策划、中期执行、后期复盘，从实践中提升组织和协调能力。</li><li><strong>行业洞察者：</strong> 协助开展 RTE 相关行业及应用场景调研、产品竞争力分析，整理相关资料，形成对业务的深入理解和独到见解。</li></ol><p><strong>【希望你】</strong></p><ol><li>本科及以上学历，商业、技术、产品、媒体专业或经验背景优先，具备良好英文能力；</li><li>对 RTE / Voice AI 有浓厚兴趣和求知欲；具备优秀的信息收集与整合能力，乐于快速学习新事物，并具备严谨的逻辑思维。</li><li>能保证每周至少 4 天的工作时间，持续 3 个月以上。</li></ol><p><strong>【薪资】</strong></p><p>180-220 元/天</p><p><strong>【投递方式】</strong></p><p>实习地点北京或上海，请将简历发送至 rtedevcommunity\@gmail.com ；邮件标题请注明：【社区运营实习-姓名-学校-毕业年份-到岗日期-城市】</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047412528" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047412529" alt="" title="" loading="lazy"/></p><p><a href="https://link.segmentfault.com/?enc=l3LGwWW8YkDNy1EuLIdY%2BQ%3D%3D.Q8klS8VDVqPLUfEX2OU9hHiUL8%2BzQVIwwcoul1qoKyc%3D" rel="nofollow" target="_blank">阅读更多 Voice Agent 学习笔记：了解最懂 AI 语音的头脑都在思考什么</a></p><p><strong>写在最后：</strong></p><p>我们欢迎更多的小伙伴参与 <strong>「RTE 开发者日报」</strong> 内容的共创，感兴趣的朋友请通过开发者社区或公众号留言联系，记得报暗号「共创」。</p><p>对于任何反馈（包括但不限于内容上、形式上）我们不胜感激、并有小惊喜回馈，例如你希望从日报中看到哪些内容；自己推荐的信源、项目、话题、活动等；或者列举几个你喜欢看、平时常看的内容渠道；内容排版或呈现形式上有哪些可以改进的地方等。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047412530" alt="" title="" loading="lazy"/><br/>素材来源官方媒体/网络新闻</p>]]></description></item><item>    <title><![CDATA[Python梯度提升树GBT、随机森林、]]></title>    <link>https://segmentfault.com/a/1190000047412108</link>    <guid>https://segmentfault.com/a/1190000047412108</guid>    <pubDate>2025-11-19 19:05:43</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>**全文链接：<a href="https://link.segmentfault.com/?enc=bEqhS7nHT81L2B%2FYrCSjNw%3D%3D.0hhfJiiOXgZwPbggvN8RGopizPhddqFxCIokZgF0KiM%3D" rel="nofollow" title="https://tecdat.cn/?p=44342" target="_blank">https://tecdat.cn/?p=44342</a>  <br/>原文出处：拓端数据部落公众号  <br/>分析师：Liping Xiao**</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047412110" alt="封面" title="封面"/></p><h3><a name="t0" target="_blank"/>引言</h3><p>随着国内房地产市场进入精细化发展阶段，二手房交易已成为楼市流通的核心组成部分，购房者、投资者及行业从业者对市场动态与价格趋势的精准把握需求日益迫切。作为数据科学家，我们始终相信“数据驱动决策”的核心价值——从海量房产信息中挖掘规律，既能为普通购房者提供理性参考，也能为行业调控提供数据支撑。  <br/>本文内容改编自我们为某房地产咨询机构完成的实际项目，团队通过链家平台爬取多城市二手房数据，构建了一套从数据采集到模型落地的完整解决方案，已在实际业务中验证有效性。文章将详细拆解“数据爬取-清洗-分析-建模-优化”的全流程：先通过Python爬取三个城市各区二手房核心信息，经数据预处理后开展多维度可视化分析，再利用决策树（DT）、梯度提升树（GBT）、随机森林（RF）三种模型实现价格预测，最后通过异常值处理与网格搜索优化模型性能。  <br/>本文内容源自过往项目技术沉淀与已通过实际业务校验，该项目完整代码与数据已分享至交流社群。阅读原文进群，可与800+行业人士交流成长；还提供人工答疑，拆解核心原理、代码逻辑与业务适配思路，帮大家既懂怎么做，也懂为什么这么做；遇代码运行问题，更能享24小时调试支持。</p><p>数据爬取</p><p>数据清洗</p><p>探索式数据分析</p><p>特征工程</p><p>模型训练 DT/GBT/RF</p><p>模型优化 异常值处理+网格搜索</p><p>结果输出 价格预测+区域洞察</p><h3><a name="t1" target="_blank"/>项目背景与目标</h3><h4><a name="t2" target="_blank"/>项目背景</h4><p>在居住品质升级与楼市结构调整的双重驱动下，二手房市场的区域差异、价格影响因素愈发复杂。不同城市、同一城市不同区域的房价受地理位置、房屋属性、建筑年代等多重因素影响，传统经验判断已难以适应市场变化。基于此，我们聚焦三个代表性城市，通过数据挖掘技术构建分析与预测体系，填补市场洞察的精准度缺口。</p><h4><a name="t3" target="_blank"/>项目目标</h4><ol><li>数据爬取：通过Python requests库获取链家平台二手房核心字段，包括房源位置、面积、户型、总价、单价等关键信息。</li><li>数据清洗：完成去重、缺失值填充、异常值处理、数据类型转换等预处理，保障数据质量。</li><li>数据可视化：通过直方图、词云图、地理分布图等工具，直观呈现市场分布与价格特征。</li><li>特征工程：筛选并编码对房价有显著影响的特征，构建高效建模数据集。</li><li>模型训练：基于DT、GBT、RF三种算法构建价格预测模型，评估不同因素对房价的影响。</li><li>模型优化：通过异常值剔除与网格搜索调整参数，提升模型预测精度。</li><li>技术实现：依托Python生态，结合pandas、numpy、matplotlib等库完成全流程开发。</li></ol><h3><a name="t4" target="_blank"/>数据采集与预处理</h3><h4><a name="t5" target="_blank"/>数据采集</h4><p>本次数据来源于链家网二手房板块，通过分析网页URL规律，设计了分城市、分区的爬虫方案。先爬取目标城市各区域的URL，再按分页规则遍历每一页房源，最后下载单套房源的HTML文件并提取信息。  <br/>核心爬虫代码（修改后关键片段）：</p><pre><code>import requestsimport osfrom lxml import etreeimport pandas as pd# 定义爬取函数：参数为城市URL和城市名称def crawl_city_houses(city_url, city_name): # 创建城市对应的存储文件夹 city_dir = f'htmls/{city_name}' if not os.path.exists(city_dir): os.makedirs(city_dir) # 请求城市首页，获取各区链接 response = requests.get(city_url, headers=headers) html = etree.HTML(response.text) area_urls = html.xpath('//div[@data-role="ershoufang"]//a/@href') area_names = html.xpath('//div[@data-role="ershoufang"]//a/text()') # 遍历各区，爬取分页数据 for area_url, area_name in zip(area_urls, area_names): area_dir = f'{city_dir}/{area_name}' if not os.path.exists(area_dir): os.makedirs(area_dir)</code></pre><p>爬取流程与代码示意：  </p><p>信息提取代码示意：<img referrerpolicy="no-referrer" src="/img/remote/1460000047412111" alt="" title="" loading="lazy"/></p><h4><a name="t6" target="_blank"/>数据清洗</h4><p>三个城市的原始数据采用相同提取逻辑，因此清洗流程保持一致，以下以赣州数据为例说明核心步骤：</p><ol><li>读取数据并查看基础信息：  <br/>  <img referrerpolicy="no-referrer" src="/img/remote/1460000047412112" alt="" title="" loading="lazy"/><img referrerpolicy="no-referrer" src="/img/remote/1460000047412113" alt="" title="" loading="lazy"/></li><li>缺失值处理：房屋特色等描述型字段用“无”填充，数值型字段根据分布特征填充均值或中位数。<img referrerpolicy="no-referrer" src="/img/remote/1460000047412114" alt="" title="" loading="lazy"/></li><li>数据格式优化：去除字符型数据中的空格与换行符，删除冗余字段（如“所在区域”因已有“所在市”“所在县区”可剔除）。<img referrerpolicy="no-referrer" src="/img/remote/1460000047412115" alt="" title="" loading="lazy"/></li><li>特征拆分与提取：</li></ol><ul><li>从“面积”字段中提取数字，转换为浮点型用于建模。<img referrerpolicy="no-referrer" src="/img/remote/1460000047412116" alt="" title="" loading="lazy"/></li><li>将“楼层”字段拆分为“楼层高度”（低/中/高）和“总层数”两个独立特征。<img referrerpolicy="no-referrer" src="/img/remote/1460000047412117" alt="" title="" loading="lazy"/></li><li>从“户型”字段中提取“室、厅、厨、卫”的数量，转换为整型特征。<img referrerpolicy="no-referrer" src="/img/remote/1460000047412118" alt="" title="" loading="lazy"/></li><li>简化“抵押信息”字段，归类为“有抵押、无抵押、暂无数据”三类。<img referrerpolicy="no-referrer" src="/img/remote/1460000047412119" alt="" title="" loading="lazy"/></li></ul><h3><a name="t7" target="_blank"/>探索式数据分析</h3><p>通过可视化工具从区域分布、价格特征、房源属性等维度解析数据，以下为三个城市的核心分析结果：</p><h4><a name="t8" target="_blank"/>赣州数据可视化</h4><ul><li>各县区房源数量分布：直观呈现不同区域的房源流通活跃度。<img referrerpolicy="no-referrer" src="/img/remote/1460000047412120" alt="" title="" loading="lazy"/></li><li>房源相关特征分布：展示房屋属性的整体特征，为后续特征筛选提供依据。  <br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047412121" alt="" title="" loading="lazy"/>  <br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047412122" alt="" title="" loading="lazy"/><img referrerpolicy="no-referrer" src="/img/remote/1460000047412123" alt="" title="" loading="lazy"/></li><li>房价分布直方图：因高价房源占比极低，分高低价（以1000万为界）分别展示，更清晰呈现价格集中区间。  <br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047412124" alt="" title="" loading="lazy"/><img referrerpolicy="no-referrer" src="/img/remote/1460000047412125" alt="" title="" loading="lazy"/></li><li>房源标题词云图：提炼市场热门宣传关键词，反映购房者关注焦点，词云图生成代码如下。  <br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047412126" alt="" title="" loading="lazy"/>  <br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047412127" alt="" title="" loading="lazy"/><img referrerpolicy="no-referrer" src="/img/remote/1460000047412128" alt="" title="" loading="lazy"/></li></ul><hr/><p><strong>相关文章</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047412129" alt="" title="" loading="lazy"/></p><h3><a name="t9" target="_blank"/>Python电影票房预测模型研究——贝叶斯岭回归Ridge、决策树、Adaboost、KNN分析猫眼豆瓣数据</h3><p>原文链接：<a href="https://link.segmentfault.com/?enc=DwbQnU43ICiZhGbu4WcX7A%3D%3D.HrEHfY21Ha0MDeWYx2z5BHbmcQw6k7mBxYdWYzSRmJ0%3D" rel="nofollow" title="https://tecdat.cn/?p=43754" target="_blank">https://tecdat.cn/?p=43754</a></p><hr/><ul><li>各县区平均房价地理图：可视化区域价格差异，直观展示核心城区与郊区的房价梯度。<img referrerpolicy="no-referrer" src="/img/remote/1460000047412130" alt="" title="" loading="lazy"/></li><li>数据可视化大屏：整合核心指标（房源数量、均价、户型分布等），全方位展示市场概况。<img referrerpolicy="no-referrer" src="/img/remote/1460000047412131" alt="" title="" loading="lazy"/></li></ul><h4><a name="t10" target="_blank"/>南昌数据可视化</h4><p>南昌市可视化分析逻辑与赣州一致，仅因城市数据差异呈现不同特征，核心可视化结果如下：<img referrerpolicy="no-referrer" src="/img/remote/1460000047412132" alt="" title="" loading="lazy"/></p><h4><a name="t11" target="_blank"/>深圳数据可视化</h4><p>深圳作为一线城市，房价水平与区域差异显著，核心可视化结果如下：  <br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047412133" alt="" title="" loading="lazy"/>  <br/>通过跨城市对比发现：深圳二手房价格显著高于赣州、南昌，且异常值较多；赣州、南昌的房价分布更集中，区域差异主要受核心城区与郊区地理位置影响；三地房源均以刚需户型为主，装修情况以简装、中装为主流。</p><h3><a name="t12" target="_blank"/>模型设计与优化</h3><h4><a name="t13" target="_blank"/>数据合并与特征处理</h4><ol><li>数据集合并：将三个城市的清洗后数据纵向拼接，最终得到42640条记录、31个特征的建模数据集，合并过程代码与结果如下。  <br/>  <img referrerpolicy="no-referrer" src="/img/remote/1460000047412134" alt="" title="" loading="lazy"/>  <br/>  核心合并代码（修改后关键片段）：</li></ol><pre><code>import pandas as pd# 读取三个城市的清洗后数据ganzhou_data = pd.read_csv('清洗后数据/赣州_清洗后.csv', index_col=False)nanchang_data = pd.read_csv('清洗后数据/南昌_清洗后.csv')shenzhen_data = pd.read_csv('清洗后数据/深圳_清洗后.csv')# 纵向合并数据combined_data = pd.concat([ganzhou_data, nanchang_data, shenzhen_data], axis=0)# 去重并重置索引combined_data.drop_duplicates(inplace=True)combined_data = combined_data.reset_index(drop=True)# 保存合并后数据combined_data.to_csv('./合并后数据集.csv', index=False)</code></pre><ol><li>异常值检测：通过箱线图发现深圳存在较多高价异常值，这些异常值会干扰模型训练，导致预测偏差。<img referrerpolicy="no-referrer" src="/img/remote/1460000047412135" alt="" title="" loading="lazy"/></li><li>合并后数据分布：查看合并数据的直方图，因价格跨度极大，分高低价展示分布特征，为异常值处理提供依据。  <br/>   </li><li>特征筛选与编码：</li></ol><ul><li>剔除标题、挂牌时间等难以量化或相关性低的特征，保留核心特征用于建模。</li><li>对分类特征（如户型结构、装修情况等）采用LabelEncoder编码，编码代码如下。  <br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047412136" alt="" title="" loading="lazy"/>  <br/>核心编码代码（修改后关键片段）：</li></ul><pre><code>from sklearn.preprocessing import LabelEncoderimport joblib# 筛选建模特征model_data = combined_data.drop(['标题', '标题详情', '套内面积', ...], axis=1)# 定义需要编码的分类特征cat_features = ['小区名称', '户型结构', '建筑类型', ..., '所在县区']label_encoders = {}# 对分类特征进行编码for feat in cat_features: le = LabelEncoder() model_data[feat] = le.fit_transform(model_data[feat]) label_encoders[feat] = le# 保存编码器joblib.dump(label_encoders, '模型/label_encoders.pkl')</code></pre><ol><li>特征相关性分析：通过热力图筛选与“总价”相关性较高的特征，剔除小区名称、关注人数等相关性较低的特征，优化建模特征集。  <br/>  <img referrerpolicy="no-referrer" src="/img/remote/1460000047412137" alt="" title="" loading="lazy"/></li></ol><h4><a name="t14" target="_blank"/>模型训练（未处理异常值）</h4><p>采用8:2比例划分训练集与测试集，分别训练决策树（DT）、梯度提升树（GBT）、随机森林（RF）三种模型，使用R²、MSE、RMSE作为评估指标。</p><ol><li><p>决策树模型：  </p><p>决策树预测值与真实值对比：<img referrerpolicy="no-referrer" src="/img/remote/1460000047412138" alt="" title="" loading="lazy"/></p></li><li><p>梯度提升树模型：  </p><p>梯度提升树预测值与真实值对比：<img referrerpolicy="no-referrer" src="/img/remote/1460000047412139" alt="" title="" loading="lazy"/></p></li><li><p>随机森林模型：  </p><p>随机森林预测值与真实值对比：  <br/>  <img referrerpolicy="no-referrer" src="/img/remote/1460000047412140" alt="" title="" loading="lazy"/>  <br/>  未处理异常值时的模型性能：</p></li><li>分析可见：未处理异常值时，模型R²值偏低，高价房源的预测偏差尤为明显，需通过异常值处理与参数优化提升性能。</li></ol><h4><a name="t15" target="_blank"/>模型优化</h4><ol><li><p>异常值处理：采用IQR法则，剔除总价高于Q3+3IQR的异常数据（主要为深圳高价房源），处理代码如下。  </p><p>核心处理代码（修改后关键片段）：</p></li></ol><pre><code># 计算四分位数Q1 = model_data['总价'].quantile(0.25)Q3 = model_data['总价'].quantile(0.75)IQR = Q3 - Q1# 定义异常值边界upper_bound = Q3 + 3 * IQR# 剔除异常值optimized_data = model_data[model_data['总价'] &lt;= upper_bound]optimized_data.to_csv('./训练数据.csv', index=False)</code></pre><ol><li>参数优化：使用网格搜索（GridSearchCV）为各模型寻找最优参数，提升模型泛化能力。</li></ol><ul><li>决策树网格搜索：</li></ul><p>决策树预测值与真实值对比（优化后）：<img referrerpolicy="no-referrer" src="/img/remote/1460000047412141" alt="" title="" loading="lazy"/></p><ul><li><p>梯度提升树优化：  </p><p>梯度提升树预测值与真实值对比（优化后）：<img referrerpolicy="no-referrer" src="/img/remote/1460000047412142" alt="" title="" loading="lazy"/></p></li><li>随机森林网格搜索：</li></ul><p>随机森林预测值与真实值对比（优化后）：<img referrerpolicy="no-referrer" src="/img/remote/1460000047412143" alt="" title="" loading="lazy"/></p><ol><li><p>优化后模型性能：</p><table><thead><tr><th>模型</th><th>R²</th><th>MSE</th><th>RMSE</th></tr></thead><tbody><tr><td>决策树</td><td>0.871</td><td>4220.42</td><td>64.96</td></tr><tr><td>梯度提升树</td><td>0.895</td><td>3422.84</td><td>58.50</td></tr><tr><td>随机森林</td><td>0.911</td><td>2928.50</td><td>54.16</td></tr></tbody></table><p>结果表明：剔除异常值并优化参数后，三种模型的预测精度显著提升，其中随机森林模型表现最佳，R²达到0.911，预测值与真实值拟合度良好，能有效捕捉二手房价格的核心影响因素。</p></li></ol><h3><a name="t16" target="_blank"/>结论与服务支持</h3><p>本次研究通过完整的数据挖掘流程，实现了多城市二手房价格预测与区域差异分析，验证了决策树、梯度提升树、随机森林在房价预测场景的有效性。核心结论包括：地理位置（所在城市、县区）、建筑面积、户型结构是影响二手房价格的关键因素；深圳房价整体偏高且波动较大，赣州、南昌房价分布更集中；随机森林模型经异常值处理与参数优化后，预测精度最优，可为市场参与者提供可靠参考。</p><h4><a name="t17" target="_blank"/>核心服务保障</h4><ol><li>应急修复服务：24小时响应“代码运行异常”求助，比学生自行调试效率提升40%，避免因代码问题耽误项目进度。</li><li>人工创作保障：所有代码与论文内容均经人工优化，直击“代码能运行但怕查重、怕漏洞”的痛点，保障原创性与可靠性。</li><li>全流程支持：提供从数据爬取到模型落地的全流程答疑，不仅教会“怎么做”，更解释“为什么这么做”，帮助真正掌握数据分析思维。  <br/>  本文项目完整代码、数据及可视化素材已同步至交流社群，进群即可获取。如需个性化修改、代码调试或润色服务，可联系团队获取一对一支持，让数据分析学习更高效、更省心。</li></ol><h2><a name="t18" target="_blank"/>关于分析师</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047412144" alt="" title="" loading="lazy"/></p><p>在此对 Liping Xiao 对本文所作的贡献表示诚挚感谢，其专业方向为数据科学与大数据技术，曾担任北京中电中采数据服务有限公司的数据处理。擅长 Python 编程，在深度学习、数据分析、数据采集等领域具备专业的实践能力与技术储备。</p>]]></description></item><item>    <title><![CDATA[在 RTE2025 大会，我看到了 AI]]></title>    <link>https://segmentfault.com/a/1190000047412192</link>    <guid>https://segmentfault.com/a/1190000047412192</guid>    <pubDate>2025-11-19 19:04:44</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>10 月 31 日，我们受 RTE 开发者社区邀请参加了 RTE2025 大会。</p><p>这不是寻常的科技展会，没有冰冷的技术参数展示，取而代之的是AI与人类自然交流的场景。</p><p>今年大会以「AI 有声」为主题，这巧妙地道出了行业的变化——<strong>AI正在从无声的工具变为有声的伙伴。</strong> 从能贴心对话的毛绒玩具，到随时陪伴的AI语伴，从智能调研助手到趣味互动桌游，对话式AI已不再是科幻构想，而是触手可及、富有情感的日常存在。</p><p>这股“AI有声”的浪潮背后，是怎样的技术基石在支撑？一个优秀的语音智能体，从灵光一现的Demo到稳定可靠的产品，需要跨越哪些鸿沟？</p><p>为了探寻这些答案，我们不仅深入了专为语音智能体开发者打造的 “<strong>RTE101技术专场</strong>” ，系统梳理从语音前端处理到交互逻辑的核心技术栈；也穿梭于各大展台，亲身体验了如<strong> Chikka.ai </strong>这样的智能调研工具、<strong>ValidFlow.AI</strong> 的用户洞察平台以及 <strong>LookeeAI</strong> 教育硬件等前沿应用。</p><p>今天，我们来分享一下我们的所见所得、所思所想。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047412194" alt="" title=""/></p><h2>101技术专场：语音智能体开发者的第一课</h2><p>这场为语音智能体开发者设计的“第一课”从最底层的信号处理一直讲到上层的应用实践，系统性地剖析了一个语音智能体从Demo到产品化需要跨越的鸿沟。</p><p><strong>音频3A处理（AEC、ANS、AGC）是对话式AI的基石。</strong> 声网音频算法工程师林子毅现场演示了回声消除的重要性：当关闭AEC功能时，AI设备会陷入“自问自答”的循环——说出回答后又被自己的声音触发，不断重复响应，根本无法正常交流。而降噪技术则让AI在嘈杂的机场环境中也能准确识别主要说话人的指令。</p><p><strong>语音活动检测（VAD）决定交互体验。</strong> 传统的VAD基于声带振动检测，但对于发轻音或辅音时无效。声网开源的TEN VAD基于深度学习，能更准确地检测语音起止点，将端到端响应延迟控制在毫秒级，避免了“说话被打断”或“说完等几秒没反应”的糟糕体验。</p><p>让我印象比较深刻的是 <strong>关于对话式AI架构的讨论。</strong> 目前主流的三段式架构将ASR、大语言模型、TTS串联，优点是各模块可独立优化，技术成熟度高。但端到端语音大模型直接将语音输入映射为语音输出，减少了信息损失，理论上更接近人类对话方式。</p><p>三段式架构灵活可控，但累积延迟较高；端到端模型响应更快，但训练数据和成本要求极高，且可控性较差。</p><p>在探讨<strong>对话式AI中传输音视频和数据的最佳协议选择</strong> 时，声网生成式AI产品负责人毛玉杰从产品角度指出，技术决策的出发点应该是用户体验而非技术本身。“我们总是在讨论协议的好坏，但核心是这个协议能给用户带来什么体验”。他建议开发者采用混合架构：WebSocket用于信令控制，WebRTC用于媒体传输，各取所长。</p><blockquote>此外，还分享了工具调用与MCP实践、对话式AI体验评估等内容。如果大家感兴趣的话，我们可以单独出一期“101技术专场”的内容完整回顾，欢迎在评论区留言</blockquote><h2>展会亮点：三款产品背后的AI语音革新</h2><p><strong>（1）Chikka.ai：让用户调研会“说话”</strong></p><p>在活动现场展台，我们遇到了这款专注于客户访谈的AI平台。Chikka.ai基于AI语音代理Ava，能与受访者进行自然对话，快速收集分析语音反馈。</p><p>最吸引我的功能是它支持多语言访谈，能同时进行数百次对话。想象一下，企业可以在短时间内完成大规模的用户调研，而且不是通过冰冷的问卷，而是模拟专业访谈者的对话交流。平台还提供个性化访谈计划、自动转录与见解提取，大大缩短了从收集到洞察的周期。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047412195" alt="" title="" loading="lazy"/></p><p><strong>（2）ValidFlow.AI：从数据到洞察的智能升级</strong></p><p>相类似的，AI用户洞察应用ValidFlow.AI的展台吸引了不同的人群。</p><p>与Chikka.ai侧重于对话式数据收集不同，ValidFlow.AI更像是一个完整的用户洞察平台，它通过AI研究员和全球用户池的组合，全面高效地完成用户洞察的全流程。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047412196" alt="" title="" loading="lazy"/></p><p>两者的区别在于：Chikka.ai像是擅长对话的采访者，而ValidFlow.AI则更像是整个研究团队——从设计调研到回收分析，提供更全面的解决方案。现场工作人员表示，他们的目标是让用户洞察不再是大公司的专利，让初创企业也能轻松获得高质量的市场洞察。</p><blockquote>进一步阅读：<a href="https://link.segmentfault.com/?enc=7VqBvtwPvshy5nicElA6Qw%3D%3D.CHtJ3Wk2enmv3aYbapNlUNZJ6akIIMfyH894D65XgpqdIHtFTXoT2jC7BSngzlE2JjWz%2BlAPajEZehX3TYeXqv2fbuWHtuOUyCmrxJLyTxDGm5DB5lPEFON60M2yKHUl%2FOQnQMlV0%2FhT608jt6XVgFsk%2BKWM5NMTSJZJYItyhB3FpF4zECSMl38Yy61F7nRH5COgTQZKDHLoiZz3bN4Kqh7bxEYxcPwsQF7DJtjX2cd81mv6pjwFAxlSl2zXSQnRTzcOx8KOuCxGI%2BJVf5%2BO5remqsRlL6OJkmQBHLFAXo752XQBk9dmpAvElSImsSDTO8GRoX%2F2tKXZHsXk38qUUDzV8nOmYtxLTU6pBTb7O2msQ55N1EwXM1xfowL3qUq9KgczSk%2Bxl09DHoZXCAGD%2FtB0wpTaqLU5ta6ckHG5onpJdSfRkQPDkpeegBjy9ArXifwfI%2FQ7cKuA%2Fr8PZL7WmtQ6TKf4BsDP1zoFwyPYma9oBk8C4kR825bbEVi7Xk4i" rel="nofollow" target="_blank">RTE现场看到的超绝AI调研产品，调研人福音！</a></blockquote><p><strong>（3）Lookee：会互动的英语学习伙伴</strong></p><p>教育硬件展区总是人山人海，盒智科技推出的LOOKEE口语侠尤其受欢迎。这款被称为“全球最小AI英语学习语伴”的产品，大小不过一个耳机盒，重量不到50克，专为5-12岁儿童设计。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047412197" alt="" title="" loading="lazy"/></p><p>他们自研的AURA系统能实时分析孩子的情感状态、内容理解度和对话积极性，并动态调整对话策略。通过情感化交互设计，为孩子打造零压力的专属口语环境，解决孩子们“没处说、不敢说”的痛点。</p><p>起初我觉得这类 AI 教育硬件应该是产品同质化的重灾区，但在现场我发现，一个孩子在与LOOKEE进行英语对话时，摇一摇LOOKEE，LOOKEE不仅会换一个口语话题，甚至还会换一个非常有动感的表情，非常可爱。</p><p>后面LOOKEE团队告诉我，他们做了大量用户调研，挖掘孩子们真正痛点和兴趣点。我觉得这种用心在初创团队上是十分难得的，也是真正打动我的。</p><h2>AI桌游《Talk With》：聊天能解决的事儿</h2><p>大会的互动环节中，最让我惊喜的是全球首款AI主题语言类桌游《Talk With》（中文名：聊天能解决的事儿）试玩会。</p><p>游戏规则颇具创意：3-5名玩家抽取随机场景卡，每个场景都潜含着困难和危机。玩家需要竞拍合适的对话式AI和语音技术，构建自己的技术壁垒，最终通过路演展示产品愿景。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047412198" alt="" title="" loading="lazy"/></p><p>我参与的一局游戏中，抽到的场景是“解决开车犯困问题”。我们小组竞拍到了情感语音合成技术，设计了一款能通过聊天保持驾驶员清醒的AI助手。游戏中的“市场行情卡”带来了意想不到的转折——突然的“技术突破”让我们的方案更具竞争力。</p><p>这款桌游巧妙地将AI语音技术融入轻松愉快的游戏中，让参与者在40分钟的游玩中理解了不同语音技术的应用场景和组合价值。正如游戏名称所暗示的，有时候聊天真的能解决很多问题。</p><h2>总结：AI语音的未来是更自然的“相处”</h2><p>回顾一天的逛展体验和技术专场的深度学习，我最大的感受是：<strong>AI语音技术正从“工具性”走向“关系性”。</strong></p><p>从会陪伴的芙崽Fuzozo，到能教学的LOOKEE，再到帮助企业洞察用户的ValidFlow.AI，这些产品不再强调技术的强大，而是聚焦于<strong>如何让AI更懂人心</strong>。101技术专场中各位讲师反复强调的一个观点让我深有共鸣：<strong>技术最终要为体验服务。</strong></p><p>当AI学会了倾听与对话，它不再只是执行命令的工具，而成为我们生活中<strong>有温度的伙伴</strong>。这或许就是对话式AI最美好的前景——不是取代人类，而是以更自然的方式与人“相处”，<strong>让技术真正服务于人的情感需求。</strong></p><p>我相信，我们迎来的将是一个更有温度的数字未来。</p><p>最后，再次感谢 RTE 开发者社区邀请我们来参加这次活动，真的非常用心，dev party也让我们交到了不少有意思的新朋友。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047412199" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047412200" alt="" title="" loading="lazy"/></p><p><a href="https://link.segmentfault.com/?enc=NBX%2F7D2aOQwu8RZF8Ah9vg%3D%3D.JOkuAyv%2Fw1RGoiYwaaohjv%2FBbMPXmHqtOikzLcMyOoc%3D" rel="nofollow" target="_blank">阅读更多 Voice Agent 学习笔记：了解最懂 AI 语音的头脑都在思考什么</a></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047412201" alt="" title="" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[EMR Serverless Stell]]></title>    <link>https://segmentfault.com/a/1190000047412219</link>    <guid>https://segmentfault.com/a/1190000047412219</guid>    <pubDate>2025-11-19 19:03:45</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在今年云栖大会上，EMR Serverless Stella 1.0正式发布，这是一款面向企业级场景深度优化的高性能数据分析引擎。阿里云开源大数据平台OLAP引擎负责人周康系统性地分享了 Stella 在存算分离架构、Lakehouse 场景以及全文检索等三大核心场景下的深度优化经验，为业界提供了大规模 OLAP 系统工程化实践的宝贵参考。Stella引擎的发布将为企业级用户提供更加专业、高效的OLAP解决方案。</p><h2>站在巨人肩膀上：与 StarRocks 开源社区的深度合作</h2><p>阿里云与StarRocks开源社区的合作可以追溯到2021年，从开源第一天起就建立了深度合作关系。在过去四年中，双方在源码共创、产品发布和技术优化方面积累了丰富的经验。</p><p><strong>合作历程回顾：</strong></p><ul><li><strong>2021年</strong>：开启源码共创，重点推动数据湖分析相关框架和性能优化</li><li><strong>2022年3月</strong>：推出EMR半托管StarRocks形态</li><li><strong>2023年</strong>：响应市场需求，推出全托管产品形态</li><li><strong>2024年</strong>：正式商业化存算分离版本</li></ul><p>随着产品的成熟，阿里云EMR已积累数百家B端企业客户。“我们始终站在巨人的肩膀上，”阿里云开源大数据平台OLAP引擎负责人周康表示，“Stella 所有功能和优化都会逐步回馈给社区，同时确保API层面与开源版本完全兼容。”<br/><img width="723" height="389" referrerpolicy="no-referrer" src="/img/bVdm6eJ" alt="image.png" title="image.png"/></p><h2>Lakehouse 成为业界共识：Stella 应运而生</h2><p>2024年，阿里云正式发布 OpenLake 方案，标志着 Lakehouse 架构在数据基础设施领域的全面落地：<br/><img width="723" height="273" referrerpolicy="no-referrer" src="/img/bVdm6eL" alt="image.png" title="image.png" loading="lazy"/><br/>2024云栖大会重磅发布OpenLake解決方案，StarRocks 为 OLAP场景核心组件</p><p>伴随这一趋势，Lakehouse（数据湖仓一体）已成为国内外头部公司的业界共识：<br/><img width="723" height="298" referrerpolicy="no-referrer" src="/img/bVdm6eM" alt="image.png" title="image.png" loading="lazy"/><br/>海外Lakehouse发展趋势  Snowflake/Databricks/BigQuery + Iceberg/Delta/Hudi</p><p>阿里云推出了 OpenLake 一体化湖仓解决方案，StarRocks 在其中担任核心 OLAP 引擎角色。然而，在大规模生产环境中，StarRocks 在存算分离架构和湖表查询方面仍有优化空间。Stella 项目正是为了应对这些挑战而生。通过在调度、查询优化、执行引擎和存储引擎四个层面的全面改进，Stella 1.0 针对几十 TB 甚至 PB 级数据场景，解决了事务机制、Compaction 效率、查询性能、元数据管理等一系列生产环境痛点。</p><h2>Stella 1.0 三大核心场景突破</h2><p>EMR Serverless Stella 1.0版本于今年5月正式发布，主要聚焦三大核心技术能力的重大突破：</p><h3>一、存算分离：性能和稳定性大幅提升</h3><p>Stella 1.0 在存算分离架构下实现了三大突破：</p><p><strong>1. 冷查性能大幅提升</strong></p><ul><li>实现 IO 合并，减少对象存储访问次数</li><li>优化 Compaction 调度器，大幅减少小文件数量 </li><li>针对轻量级 ETL 场景优化负载调度</li></ul><p><strong>2. 写入性能保障</strong></p><ul><li>开发 Batch Publish 能力，解决串行化导入瓶颈 </li><li>推出 Collocated PK Index，避免缓存盘和索引盘互相影响 </li><li>优化 FE 侧 Tablet 创建删除效率</li></ul><p><strong>3. 缓存利用率优化</strong></p><ul><li>引入 Index Cache 和 Meta Data Cache，提升元数据访问速度 </li><li>实现自适应 IO Stream，智能选择本地缓存或远端访问 </li><li>针对 ETL 场景优化空间利用</li></ul><p>在TPC-H 10T基准测试中，存算分离版本的Stella相比上一版本<strong>性能提升超过120%</strong>，充分展现了云原生架构的技术优势。<br/><img width="723" height="430" referrerpolicy="no-referrer" src="/img/bVdmZu8" alt="image.png" title="image.png" loading="lazy"/></p><h3>二、Paimon 湖表查询：Co-design 驱动性能飞跃</h3><p>Stella 1.0在Paimon表分析方面，重点聚焦在三个方向的提升：</p><p><strong>1. 数据读写效率提升</strong> </p><ul><li>实现自适应 Batch Size 优化 </li><li>支持Native Paimon Writer，性能大幅提升</li></ul><p><strong>2. 元数据访问优化</strong> </p><ul><li>针对 Manifest 数量众多场景，实现分布式解析能力 </li><li>适配异步 Splits 调度框架 </li><li>优化 Manifest Cache 策略</li></ul><p><strong>3. 深度集成阿里云 DLF 2.x</strong> </p><ul><li>与 Data Lake Formation 产品深度整合 </li><li>借助 DLF 能力提升 Paimon 查询和写入的性能与稳定性 </li><li>针对DV表实现Native读取优化</li></ul><p>Stella在Lakehouse场景下查询Paimon下性能的提升非常明显：<br/><img width="723" height="513" referrerpolicy="no-referrer" src="/img/bVdm6eU" alt="image.png" title="image.png" loading="lazy"/></p><p>虽然 Flink + Paimon 已成为成熟的实时入湖方案，但计算引擎与 Paimon 存储的查询优化结合仍有巨大提升空间。Stella 与 Paimon 将在多个方便持续进行Co-Design，更多优化成果将在后续版本中发布。</p><h3>三、全文检索：打造高性能、高可用的文本分析能力</h3><p>Stella 1.0 正式推出全文检索能力，支持高效、精准的文本查询。</p><ul><li><strong>架构重构</strong>：对 Inverted Index（倒排索引） 整体解决方案进行架构优化</li><li><strong>存算分离主键表支持</strong>：新增主键表全文检索能力，实现高效精准的查询能力</li><li><strong>小文件合并</strong>：解决存算分离架构下的“性能杀手”问题（单个 Segment 产生十几个小文件） <br/><img width="723" height="529" referrerpolicy="no-referrer" src="/img/bVdm6eV" alt="image.png" title="image.png" loading="lazy"/></li></ul><p>文本过滤性能benchmark: Stella vs EMR StarRocks 3.3</p><p>目前，全文检索功能已在阿里集团内部和云上客户中投入使用，所有优化代码已通过 PR 提交至 StarRocks 开源社区。</p><h2>技术创新路线图持续演进</h2><p>面向未来，Stella引擎制定了清晰的技术发展路线图，在四个关键领域持续深耕：</p><ol><li><strong>迈向Stella 2.0时代：轻量 ETL Production Ready</strong>  <br/>全面强化轻量级 ETL 能力，打通从数据接入、转换到分析的端到端链路，使用户无需依赖外部调度系统即可高效完成日常数据加工任务，真正实现“开箱即用、生产就绪”。</li><li><strong>Lake Optimizer：湖表性能全面对齐甚至超越内表</strong>  <br/>推出专为开放数据湖设计的 Lake Optimizer，显著提升 Apache Paimon 等湖表格式的查询性能，让湖表在复杂分析场景中媲美甚至超越传统内表体验。</li><li><strong>智能化 Background Job Service：彻底释放用户运维负担</strong>  <br/>针对企业用户长期面临的内表运维复杂、资源争抢等问题，Stella 将推出智能化后台作业服务，自动处理 compaction、索引构建、统计信息收集等任务，实现高智能化的自治运维，大幅提升系统稳定性与资源效率。</li><li><strong>全文检索与向量检索能力持续提升</strong>  <br/>在已有的高性能 OLAP 基础上，进一步融合全文检索与向量检索能力，支持非结构化与多模态数据的统一分析，为 AI 原生应用、智能搜索等新兴场景提供底层引擎支撑。</li></ol><p>这四大方向不仅体现了 Stella 对 Lakehouse 架构的深度适配，更彰显了其从“高性能分析引擎”向“智能数据平台核心引擎”演进的战略决心。随着这些能力的逐步落地，Stella 将为企业用户提供更开放、更智能、更易用的下一代实时分析体验。</p><h2>技术探索与社区协作深度融合</h2><p>Stella引擎在技术架构探索方面持续深化与开源社区的合作：</p><p>Lakehouse架构能力的持续拓展体现了Stella引擎的前瞻性设计理念。在现有Lakehouse架构基础上，系统将支持更多检索功能，为企业的多元化分析需求提供全面支持。向量搜索技术是与Apache Paimon深度集成的创新探索，在AI和大数据时代，向量搜索能力将成为差异化的技术优势。</p><h3>开源社区贡献亮点</h3><ul><li><strong>JSON等半结构化数据处理能力持续增强</strong>，推动整个生态发展</li><li><strong>大规模场景技术实践经验分享</strong>，为社区贡献宝贵技术智慧</li><li><strong>与Apache Paimon团队深度技术合作</strong>，确保生态整合持续优化</li><li><strong>所有优化方案回馈开源社区</strong>，推动开源生态系统发展进步</li></ul><p>开源社区的深度贡献体现了Stella团队的技术责任感和开放合作精神。JSON等半结构化数据处理能力的持续增强将推动整个生态的发展，为企业在数字化转型过程中处理多样化数据提供更强支持。大规模场景下的技术实践经验分享不仅展示技术实力，更为社区贡献了宝贵的技术智慧。</p><p>“我们不仅要在云上提供增值服务，更要推动整个开源生态的发展，”周康强调，“通过深度参与开源社区，确保所有用户都能从技术进步中受益。”</p><h2>技术意义与未来规划</h2><p>EMR Serverless Stella 1.0的发布标志着阿里云在湖仓一体技术领域达到新的里程碑，为用户提供从数仓加速、湖仓查询到全文检索的全方位OLAP能力支持。该版本不仅解决了企业在实际生产环境中遇到的关键技术挑战，更通过持续的技术创新和社区贡献，推动了整个StarRocks生态系统的发展。</p><p>未来，Stella将继续围绕Lakehouse架构演进，在缓存调度、查询优化、存储引擎和写入能力等核心领域持续创新，为企业数字化转型提供更加强劲的技术引擎。</p>]]></description></item><item>    <title><![CDATA[普通人如何免费使用Gemini3-Pro]]></title>    <link>https://segmentfault.com/a/1190000047412226</link>    <guid>https://segmentfault.com/a/1190000047412226</guid>    <pubDate>2025-11-19 19:02:46</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>大模型的用法主要分为以下两类：</p><ol><li><strong>个人用途</strong>：作为日常知识补充、内容创作及辅助工具。</li><li><strong>商业用途</strong>：集成至 Dify、Coze 等工作流与应用程序中，或在编程工具及第三方客户端（如 Cherry Studio）中使用。</li></ol><p>目前，<strong>普通用户几乎可以免费使用各类主流大模型</strong>，Google 最新推出的 Gemini 3 Pro 也不例外。</p><h2>使用方法</h2><ol><li><strong>访问 AI Studio 官网</strong>：<a href="https://link.segmentfault.com/?enc=S2Plhp%2B4YOdkQOOArN%2Bm%2Bw%3D%3D.b2OqHiM6sFkooR4UZlwi5lnyC0TdolmhvZFOP4uUBYY%3D" rel="nofollow" target="_blank">https://aistudio.google.com/</a></li><li><strong>注册并登录 Google 账号</strong></li></ol><p>登录后，即可免费通过 Gemini 3 Pro 进行对话，或完成代码生成任务。</p><p>此外，Google 还提供了其他免费模型，支持图片生成与编辑、音视频制作，甚至播客生成功能。</p><p>例如，生成图片可以使用 Google 的 Imagen，视频生成则可以使用 Veo 等模型。</p><h2>视频演示</h2><p><a href="https://www.bilibili.com/video/BV14ByjBqEAS/" target="_blank">https://www.bilibili.com/video/BV14ByjBqEAS/</a></p><h2>对话演示</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047412228" alt="" title=""/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047412229" alt="" title="" loading="lazy"/></p><h2>图片生成</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047412230" alt="" title="" loading="lazy"/></p><p>视频与音频的生成方式与此类似，此处不再赘述。</p><h2>代码生成（App / 网站 / 小游戏开发）</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047412231" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047412232" alt="" title="" loading="lazy"/></p><h2>小结</h2><p>本文简要介绍了 Google Gemini 3 Pro 的免费使用渠道，及其在文本对话、代码编写及多模态生成方面的核心功能。</p><blockquote>本文已收录到我的技术小站 <a href="https://link.segmentfault.com/?enc=twc7Uo1MLlsctnbVQIrUvg%3D%3D.kJLSzWOQtvCpaXhkutX4uR%2BJCEv%2F3UQ2vlDo4n0w1HY%3D" rel="nofollow" target="_blank">www.javacn.site</a>，其中包含的内容有：Spring AI、Spring AI Alibaba、LangChain4j、Dify、Coze、N8N、智能体（AI Agent）、MCP、Function Call、RAG、向量数据库、Prompt、多模态、向量数据库、嵌入模型、AI 常见面试问题等内容。</blockquote>]]></description></item><item>    <title><![CDATA[Blender 5.0 (Linux, ]]></title>    <link>https://segmentfault.com/a/1190000047412272</link>    <guid>https://segmentfault.com/a/1190000047412272</guid>    <pubDate>2025-11-19 19:02:16</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>Blender 5.0 (Linux, macOS, Windows) - 开源 3D 创意软件 (渲染 建模 雕刻)</p><p>Open-Source 3D Graphics App Introduces Experimental Vulkan Backend</p><p>请访问原文链接：<a href="https://link.segmentfault.com/?enc=%2FkLbUuDgvadeGAqxkqsA9g%3D%3D.YlG8qYs%2BN%2Fk3BVwmgPXvw35IqgOvV2TMVInhe5SCwfk%3D" rel="nofollow" target="_blank">https://sysin.org/blog/blender/</a> 查看最新版。原创作品，转载请保留出处。</p><p>作者主页：<a href="https://link.segmentfault.com/?enc=EwEU1XUK1d2o%2BKPuV%2FCuKA%3D%3D.Zk2XBXTOzuYYifoQW0eIUH205l0tuRdlN%2BmabjiZERI%3D" rel="nofollow" target="_blank">sysin.org</a></p><hr/><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047412274" alt="Blender" title="Blender"/></p><h2>创造的自由</h2><p>Blender 获得 GNU GPL 许可，由其贡献者拥有。</p><p>因此，Blender 永远是免费和开源软件。</p><p>✅ <strong>使命</strong></p><p>以免费/开源软件的形式将世界上最好的 3D CG 技术交到艺术家手中。</p><p>✅ <strong>愿景</strong></p><p>每个人都应该自由地创作 3D CG 内容，拥有自由的技术和创意制作手段以及自由的市场准入。</p><p>✅ <strong>组织机构</strong></p><p>Blender 基金会 (2002) 是一个独立的公益组织。其衍生公司 Blender Institute (2007) 是基金会的办公室所在地，目前拥有 24 名员工，负责 Blender 软件和创意项目，以在生产环境中验证和测试 Blender。</p><p>2020 年，该研究所拆分为两家公司；Blender Institute 现在仅作为 Blender 基金会的工作公司，新的 Blender Studio 将为 Blender 制作内容和测试生产流程的使命做出贡献。</p><p>这些组织支持 <a href="https://link.segmentfault.com/?enc=Knd2Ia9jm6KfmoJuOoNkig%3D%3D.bkWThFZ7Nydsbk8bdYS5LhNB2ByMs9viz795LktpaEo%3D" rel="nofollow" target="_blank">Blender.org</a> 上的贡献者社区。这就是 Blender 的诞生地。</p><p>✅ <strong>软件</strong></p><p>Blender 是免费的开源 3D 创作套件。它支持整个 3D  管道——建模、绑定、动画、模拟、渲染、合成和运动跟踪，甚至视频编辑和游戏创建。高级用户使用 Blender 的 Python 脚本 API  来定制应用程序并编写专门的工具； 通常这些都包含在 Blender 的未来版本中。Blender 非常适合个人和小型工作室  (sysin)，他们可以从其统一的流程和响应式开发流程中受益。<a href="https://link.segmentfault.com/?enc=En5rTIfoW%2FQ7BzI8SmRWjQ%3D%3D.eGyO738F9xnhF%2BrcgFB4kjXsbxZvkQfZ4%2BLKHYtlGQbWIPUz1VTjfklt4rWQBu2w" rel="nofollow" target="_blank">特性展示</a> 中提供了许多基于 Blender 的项目的示例 。</p><p>Blender 是跨平台的，在 Linux、Windows 和 Macintosh 计算机上运行得同样好。其界面使用 OpenGL 来提供一致的体验。为了确认特定的兼容性，<a href="https://link.segmentfault.com/?enc=D3ERtV09ccgr0OjYeMIiAQ%3D%3D.DhB%2B1EPnPPF2VgN8kwCqu8171C587zgMRxJ8CkqT3UdPemvjIUWfK1jRnhIBwzrn" rel="nofollow" target="_blank">支持的平台列表</a> 显示了开发团队定期测试的平台。</p><p>作为 GNU 通用公共许可证 (GPL) 下的社区驱动项目，公众有权对代码库进行大大小小的更改，从而带来新功能、响应性错误修复和更好的可用性。Blender 没有价格标签，但您可以投资、参与并帮助推进强大的协作工具：Blender 是您自己的 3D 软件。</p><p>随时欢迎更多帮助！从开发和改进 Blender 到编写文档等，您可以做很多不同的事情来参与其中。</p><p>✅ <strong>隶属关系</strong></p><p>Blender 基金会是 Open Invention Network、Khronos、Linux Foundation 和 Academy Software Foundation 的成员。</p><p>✅ <strong>许可证</strong></p><p>Blender 是免费软件。您可以 <strong>目的自由</strong> 使用 Blender <em>出于任何</em>，包括商业或教育目的。了解有关 <a href="https://link.segmentfault.com/?enc=PXTyNoc%2FjC6QB6e7Irq7bw%3D%3D.jzKKy5UYFgtnq7AyFAU1vo8jrAtT7wYgKHChhUj8PlHSesSI2pp%2F7anw0hRoL2qT" rel="nofollow" target="_blank">许可证的</a> 更多信息。</p><h2>下载地址</h2><p>Blender 4.5 LTS for macOS, Linux, Windows (2025-11-18)</p><ul><li>请访问：<a href="https://link.segmentfault.com/?enc=vOUGTHAKxz7x9F3AznLlBw%3D%3D.EpaD66jhsleZahvOeaxqOANn5tNb0uiGIfQr9awSQ9o%3D" rel="nofollow" target="_blank">https://sysin.org/blog/blender/</a></li><li>Blender 4.5.5 LTS for macOS x64 (Intel 处理器) (blender-4.5.5-macos-x64.dmg)</li><li>Blender 4.5.5 LTS for macOS ARM64 (Apple 芯片) (blender-4.5.5-macos-arm64.dmg)</li><li>Blender 4.5.5 LTS for Linux x64 (blender-4.5.5-linux-x64.tar.xz)</li><li>Blender 4.5.5 LTS for Windows x64 (blender-4.5.5-windows-x64.msi)</li><li>Blender 4.5.5 LTS for Windows ARM64 (blender-4.5.5-windows-arm64.msi)</li></ul><p>Blender 5.0 for macOS, Linux, Windows (2025-11-18)</p><ul><li>请访问：<a href="https://link.segmentfault.com/?enc=F2CJO3DcCTk6qSbLWXccIg%3D%3D.SbGe5LIrB5SUintJchVXKdlzXjw6legpDxW2dH7T6FQ%3D" rel="nofollow" target="_blank">https://sysin.org/blog/blender/</a></li><li>Blender 5.0 for macOS x64 (Intel 处理器) (blender-5.0.0-macos-x64.dmg)</li><li>Blender 5.0 for macOS ARM64 (Apple 芯片) (blender-5.0.0-macos-arm64.dmg)</li><li>Blender 5.0 for Linux x64 (blender-5.0.0-linux-x64.tar.xz)</li><li>Blender 5.0 for Windows x64 (blender-5.0.0-windows-x64.msi)</li><li>Blender 5.0 for Windows x64 (blender-5.0.0-windows-arm64.msi)</li></ul><p>更多：<a href="https://link.segmentfault.com/?enc=8Ze8RN5jmSij6Vo32P9kww%3D%3D.itFc45Dq4wHQizC04z3XHJ317O0wmTJOimK%2FPAaamic%3D" rel="nofollow" target="_blank">macOS 下载汇总 (系统、应用和教程)</a></p>]]></description></item><item>    <title><![CDATA[AI起飞到这份上了，普通人还能赶上这波风]]></title>    <link>https://segmentfault.com/a/1190000047412285</link>    <guid>https://segmentfault.com/a/1190000047412285</guid>    <pubDate>2025-11-19 19:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>今年只要一聊职业规划，大家最爱问的就是三句话：“AI这么火，我现在转行还来得及吗？”<br/>“我是理工生，计算机0基础也能进AI行业吗？”<br/>“学完Python就能当算法工程师吗？”别急，我们先把“热度”说清楚，再告诉你：谁能吃到红利、要学什么、怎么拿到offer。<br/>01｜AI行业到底有多火？一组新数据扎心了<br/>猎聘大数据研究院最新发布的《2025上半年人才供需洞察报告》给出了极具冲击力的答案：AI技术岗整体需求增长36.82%。<br/>其中——家电行业的AI技术职位同比暴增277.43%！这意味着什么？<br/>AI不再是互联网大厂的“专属”，已经渗透进家电、制造、软件、零售几乎所有行业。<br/>这也是为什么你身边的洗衣机、扫地机、空调都越来越“会思考”——智能家居正在成为新一轮AI人才需求爆发的真正推手。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047412287" alt="图片" title="图片"/><br/>更扎心的来了：<br/>AI技术岗50万以上年薪的职位占比高达31.03%。<br/>几乎是全行业（6.40%）的5倍。深度学习岗里，这个比例更是高达39.54%。<br/>市场的态度很直接：<br/>会AI的人，不够用。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047412288" alt="图片" title="图片" loading="lazy"/></p><p>02｜但别误会：AI不是“博士专属领域”<br/>很多人以为AI行业等同于：“数学大神+清北硕博+顶尖竞赛”。<br/>其实完全不是。目前企业真正缺的是三类人：<br/>①有项目能力的技术岗（算法/深度学习/机器学习）增长最快的是算法工程师岗（同比+50%），企业不是看你学历，而是看你能不能把模型训好、效果调优。<br/>②懂AI逻辑的产品、运营、数据岗专业不限制，关键是能和工程师对话，知道模型能做什么、不能做什么。<br/>③“交叉型人才”（最稀缺）比如懂医疗的AI顾问、懂制造的AI应用经理、懂语言能力的AI训练师。<br/>这些岗位目前缺口都在10万量级。所以文科、跨专业、转行的人，反而更有机会切入AI的落地场景。</p><p>03｜热门岗位怎么选？5类路径，一条总有适合你<br/>1）算法工程师（高薪核心岗）做模型训练、调优、优化。<br/>适合数学/计算机基础好、希望冲高薪的人。<br/>2）AI产品经理（需求越来越大）负责把“AI能力”变成“能使用的产品”。<br/>适合逻辑好、懂业务、有产品思维的人。<br/>3）数据分析/数据标注（入门友好）做数据清洗、标签标注，是所有模型的基础工作。<br/>适合刚入门、希望低门槛进入行业的人。<br/>4）AI训练师（新兴热门）训练大模型的风格、纠错能力、推理能力。<br/>适合语言类、教育类、沟通能力好的同学。<br/>5）行业垂直AI顾问（未来最吃香）把AI落地到医疗、金融、制造等场景。<br/>适合行业背景+AI基础的复合型人才。</p><p>04｜应届生和转行党最关心的三个问题，直接说结论<br/>❶“现在转行AI还来得及吗？”不仅来得及，现在是正当时。<br/>AI技术岗需求还在增长区间（增幅超36%），人才缺口大、工资高、流动快。<br/>❷“非科班能进AI吗？”能。<br/>企业看的是“你能不能解决问题”。<br/>只要补齐基础技能+项目经验，有大量岗位愿意给机会。<br/>❸“学Python就能当算法工程师吗？”当然不行。<br/>Python只是最基础的工具，真正的算法岗需要的是一整套系统能力换句话说：Python是敲门砖，但不是通行证。<br/>不过——<br/>如果你的目标只是进入AI行业，并不一定非要走最难的“算法那条线”。<br/>产品、运营、训练师、行业顾问等岗位同样需要AI思维，也有成熟的学习路径，更适合转行和非科班的同学。</p><p>05｜最后：AI不是神话，是一场“技能革命”<br/>当智能家电、工业AI、AI办公、AI客服全面落地，企业已经从“要不要AI”，变成——“有没有懂AI又懂业务的人？”<br/>接下来3–5年，AI技术岗会继续贵，继续涨，继续难招。最有机会的人是：会AI+懂行业+能落地的复合型人才。<br/>如果你正在找方向、准备转行、想提升竞争力，AI行业依然是这几年少有的“确定性增长赛道”。<br/>现在入场的人，将站在行业的黄金红利期。<br/>现在还在观望的人，大概率会错过下一轮职业跃迁窗口。</p>]]></description></item><item>    <title><![CDATA[普林斯顿大学数据库遭黑客攻击 信息疑似泄]]></title>    <link>https://segmentfault.com/a/1190000047411911</link>    <guid>https://segmentfault.com/a/1190000047411911</guid>    <pubDate>2025-11-19 18:12:27</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>据彭博社消息，美国时间11月16日，普林斯顿大学进修办公室一系统在11月10日遭到网络攻击。该系统中存有姓名、联系方式以及捐款记录等诸多敏感信息，数据已全部泄露。校方表示黑客利用钓鱼攻击手段，获取了一名员工的账户权限，从而顺利侵入学校办公系统，目前已经成功阻断非法入侵。</p><p>无独有偶，近期已经有多所常春藤高校遭遇网络攻击：宾夕法尼亚大学、哈佛大学和哥伦比亚大学的校园信息系统均遭到入侵，学生信息以及校友数据都被泄露。其中，哥伦比亚大学遭遇的网络攻击最为严重，约87万人信息遭到泄露。JoySSL安全总监指出，普林斯顿大学作为全球顶尖学府，尚且发生规模和影响如此严重的数据泄露事故，可见组织机构的数据防护工作依然任重道远。在数据库层面部署数字证书，提升安全防护等级，已成为防范网络攻击的重要手段。</p><p><img width="723" height="549" referrerpolicy="no-referrer" src="/img/bVdm6ae" alt="" title=""/></p><p><strong>数据泄露源于加密工作缺失</strong></p><p>根据安全专家对此次泄露事件的分析，网络黑客很可能利用了普林斯顿大学在数据存储和传输方面的加密漏洞，从而顺利侵入系统获取重要信息。事实上，很多知名高校或者平台，都在网络安全防护建设上存在认知误区，认为普通的边界防护足以守护信息安全。但实际上，数据库与应用程序之间的数据传输通道极容易遭受网络攻击，普通的防护技术难以有效抵御各种攻击手段。</p><p>自2023年以来，全球高等教育机构遭遇网络攻击和信息泄露的事件已经超过30起，绝大多数泄露事件均因数据库加密不足所致。JoySSL市场部专家表示，数据库系统信息遭窃主要出现在教育和医疗等领域，然而，由于认知缺陷，超过三成的医疗机构和教育平台依旧未部署SSL加密，导致数据泄露事件频频上演。</p><p><img width="723" height="549" referrerpolicy="no-referrer" src="/img/bVdm6af" alt="" title="" loading="lazy"/></p><p><strong>SSL证书提供专业解决方案</strong></p><p>网络安全形势日益严峻，采用有效的加密防护方案迫在眉睫。JoySSL作为专业的数字安全服务商，旨在利用SSL证书在安全领域的专业性能，为数据库提供全链路传输加密，确保从应用服务器到数据库的每一次请求或数据交换都经过高强度加密。基于SHA384算法签发的数字证书可有效保障数据安全，即使被截获也能够让攻击者无法获取有效信息。</p><p><strong>专业防护助推企业线上发展</strong></p><p>越是复杂的网络环境，传输安全风险越大，尤其涉及到云计算，数据库与应用服务器通常分布在不同的网络区域，很容易受到攻击。SSL证书的专业防护性能让攻击者在加密层无功而返，确保数据传输的安全性。某电商平台在部署数字证书后，受到的网络攻击大幅缩减，数据传输安全性提升超过70%。</p><p><img width="723" height="549" referrerpolicy="no-referrer" src="/img/bVdm6ai" alt="" title="" loading="lazy"/></p><p><strong>构建安全防护体系防患于未然</strong></p><p>有关专家指出，随着全球范围内网络安全威胁现象频频出现，组织机构应该率先对自己进行全方位的安全评估，检查所有可能存在的安全漏洞，积极部署SSL证书以保障数据安全传输与存储，配合实时监测机制，建立起有效的安全防护体系，真正做到防患于未然。</p>]]></description></item><item>    <title><![CDATA[国防航天领域的智慧指挥新引擎 图观 ]]></title>    <link>https://segmentfault.com/a/1190000047411917</link>    <guid>https://segmentfault.com/a/1190000047411917</guid>    <pubDate>2025-11-19 18:11:47</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在国防航天领域，面对日益复杂的任务环境和瞬息万变的战场态势，如何实现高效、精准的指挥决策与运维管理，一直是行业关注的焦点。传统的信息系统往往存在数据孤岛、响应滞后等问题，难以满足现代国防航天任务对实时性、协同性和智能化的高要求。而今，随着数字孪生技术的成熟，一种全新的智能运营解决方案正悄然改变这一局面。孪易数字孪生IOC ProMAX版，作为一款集全场景监控、智能分析、应急协同于一体的平台，正为国防航天领域注入新的智慧动力。</p><h2>全场景一体化监控：从虚拟到现实的无缝映射</h2><p>在国防航天任务中，无论是卫星发射、飞行器测试，还是基地运维，都需要对多地点、多维度数据进行实时监控。孪易通过其基础控制模块，支持多地点切换、场景剖分和环境仿真，帮助用户构建高精度的数字孪生模型。例如，在卫星发射任务中，用户可以通过平台实时模拟发射场环境，结合历史回放功能，回溯关键时间点的数据变化，快速定位问题根源。这种全场景一体化监控能力，不仅提升了运维效率，更让指挥人员能够“透视”复杂系统，实现从虚拟到现实的无缝映射。<br/><img width="640" height="314" referrerpolicy="no-referrer" src="/img/bVdmQxT" alt="" title=""/></p><h2>智能应急与协同处置：应对突发事件的“智慧大脑”</h2><p>国防航天任务中，突发事件如设备故障、环境异常等，往往需要快速响应和跨部门协同。孪易IOC ProMAX版的应急处突模块，通过数字化预案管理和任务全过程监控，实现了资源的智能调度与多方联动。例如，在航天器发射过程中，若监测到异常数据，系统可自动触发应急预案，分配任务给相关团队，并通过视频会商功能一键发起跨部门会议，确保问题在最短时间内得到解决。这种智能协同机制，不仅提升了应急响应的效率，还降低了人为失误的风险，成为国防航天领域的“智慧大脑”。</p><h2>AI驱动的智能运维：从被动响应到主动预警</h2><p>人工智能技术的融入，让孪易IOC ProMAX版在国防航天应用中更具前瞻性。其智能助理模块支持自然语言交互，用户只需通过语音或文本指令，即可操作孪生体对象或查询关键数据，大幅降低了系统操作门槛。同时，智能分析功能基于历史数据进行趋势预测，并结合视觉识别技术，对视频流中的目标进行检测与行为标记。例如，在航天基地安防监控中，系统可自动识别异常入侵行为并发出预警，实现从“被动响应”到“主动防控”的升级。这种AI驱动的运维模式，不仅提升了系统的智能化水平，还为国防航天任务提供了更可靠的安全保障。</p><h2>高度可定制与扩展性：灵活适配复杂业务场景</h2><p>国防航天领域的业务需求多样且复杂，孪易通过零代码与低代码开发模式，为用户提供了高度可定制的扩展能力。零代码平台允许用户通过拖拉拽方式快速配置页面与交互逻辑，而低代码模式则支持基于JavaScript的深度开发，满足个性化业务需求。此外，平台兼容多种数据源与建模工具，如3DMax、Revit和GIS数据，确保系统能够无缝集成现有业务系统。这种灵活性，让国防航天用户能够根据任务演进，持续优化系统功能，避免因技术迭代带来的重复投入。<br/><img width="640" height="360" referrerpolicy="no-referrer" src="/img/bVdmmM0" alt="" title="" loading="lazy"/></p><h2>全平台适配与成熟落地：经得起实战检验的解决方案</h2><p>孪易具备多端自适应能力，针对指挥中心大屏、桌面中屏与移动端分别优化交互体验，确保用户在任何场景下都能高效操作。更重要的是，该平台经过近20年、上千个项目的行业验证，在华为、京东等企业的实际应用中积累了成熟经验。在国防航天领域，这种经过实战检验的稳定性与可靠性，尤为关键。无论是日常运维还是重大任务保障，孪易都能快速适配复杂环境，为用户提供持续、稳定的技术支持。</p><p>数字孪生技术正逐步成为国防航天领域智能化转型的核心驱动力。孪易数字孪生IOC ProMAX版通过全场景监控、智能分析、应急协同与灵活扩展等核心功能，为国防航天用户提供了一站式的智慧运营解决方案。它不仅提升了指挥决策的精准性与效率，更通过AI与大数据技术，实现了从被动响应到主动预警的跨越。未来，随着技术的不断演进，数字孪生平台必将在国防航天领域发挥更大价值。<br/>数字孪生智能运营中心已不再是遥远的概念，而是切实助力国防航天领域提升效能与安全性的实用工具。无论是日常运维还是应急响应，孪易IOC ProMAX版都能以其实时性、智能化和灵活性，成为国防航天任务的“智慧伙伴”。</p>]]></description></item><item>    <title><![CDATA[从零到一，解锁城市治理数字孪生高效开发秘]]></title>    <link>https://segmentfault.com/a/1190000047411920</link>    <guid>https://segmentfault.com/a/1190000047411920</guid>    <pubDate>2025-11-19 18:11:17</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>作为一名数字孪生应用开发者，我深知在城市治理项目中，我们常常面临这样的挑战：如何快速构建一个既宏观又精细的三维城市场景？如何让业务数据与三维场景无缝联动？如何在有限的开发资源下，实现跨平台、多终端的应用适配？今天，我想和大家分享一些我在实际项目中总结出的高效开发技巧，希望能为你的城市治理数字孪生项目带来启发。</p><h2>一、快速搭建城市级场景底图，让项目赢在起跑线</h2><p>城市治理项目往往需要宏观的城市背景作为支撑。传统方式下，我们需要手动收集地理信息数据，再通过专业建模软件一点点构建，耗时耗力。现在，通过图观数字孪生平台的“端渲染城市生成插件”，我们可以一键导入全国近300个城市的基础数据，快速生成三维城市场景。<br/><strong>使用技巧</strong>：在项目初期，建议先使用平台的预设风格模板快速搭建场景原型，这样可以在最短时间内向客户展示效果。待方案确认后，再通过深度自定义功能，精细调整建筑、道路、水系等元素的视觉效果。<br/><img width="640" height="360" referrerpolicy="no-referrer" src="/img/bVdmUOz" alt="" title=""/></p><h2>二、精细化场景编辑，让每个细节都“活”起来</h2><p>有了宏观的城市底图，接下来就是让场景更加生动逼真。图观的“端渲染场景编辑器”支持导入各类主流格式的精细模型，更重要的是，它提供了强大的材质编辑和动态效果配置能力。<br/><strong>材质渲染技巧</strong>：利用平台的14层PBR物理材质渲染能力，我们可以为不同的建筑类型设置不同的材质属性。比如，政府建筑可以使用更庄重的材质，商业区建筑可以设置更鲜艳的色彩，通过调节金属度和粗糙度参数，让建筑群在阳光下呈现出真实的质感。<br/><strong>动态效果配置</strong>：城市治理中经常需要展示突发事件的处理过程。通过“关节编辑”和“动画编辑”功能，我们可以将外部数据与模型状态进行绑定。比如，当某个区域发生交通拥堵时，对应的模型可以自动变红警示；通过“粒子系统”，我们可以模拟火灾现场的烟雾效果，为应急指挥提供更直观的展示。<br/><img width="640" height="360" referrerpolicy="no-referrer" src="/img/bVdmUPX" alt="" title="" loading="lazy"/></p><h2>三、零代码快速搭建，让业务专家也能参与应用开发</h2><p>在城市治理项目中，业务逻辑往往比较复杂。图观的“零代码应用编辑器”让我们可以通过拖拽式操作，快速集成三维场景、二维图表和业务数据。<br/><strong>交互联动技巧</strong>：利用平台的“参数”机制，我们可以轻松实现多维数据的联动分析。比如，当用户在二维图表中点击某个街道的统计数据时，三维场景会自动聚焦到对应的区域，并高亮显示相关的建筑群。这种交互效果过去需要大量编码实现，现在通过简单配置就能完成。<br/><strong>多终端适配</strong>：城市治理应用需要在指挥中心大屏、领导平板、巡查人员手机等多个终端上使用。通过零代码编辑器的多设备自适应功能，我们可以为不同终端定制专属的页面布局，确保每个使用者都能获得最佳体验。</p><h2>四、低代码深度定制，满足复杂业务需求</h2><p>对于需要高度定制化的项目，图观的“低代码统一开发API”提供了最大的灵活性。这套API最大的优势在于“统一API，双核渲染”的设计理念。<br/><strong>开发技巧</strong>：在项目开始前，建议先评估客户端的硬件条件。如果客户端显卡性能较好，可以选择“端渲染”模式以获得更好的视觉效果；如果需要支持大量用户并发访问，可以选择“流渲染”模式。重要的是，无论选择哪种模式，我们只需要维护一套代码，这大大提升了开发效率。<br/><strong>API调试技巧</strong>：善用平台提供的“API调试器”，可以在真实场景中实时调试代码。我习惯先在调试器中验证核心功能逻辑，确认无误后再集成到项目中。调试器还支持将标绘数据直接生成API代码，这个功能在开发地图标注相关功能时特别实用。</p><h2>五、资产库的妙用，加速项目进度</h2><p>图观平台预置了上万的模型、材质和特效资源，这些都是我们可以直接利用的宝贵财富。<br/><strong>使用建议</strong>：在项目启动阶段，先浏览平台的案例库和资产库，往往能找到可以直接复用或稍作修改就能使用的资源。特别是在开发智慧交通、智慧安防等常见城市治理场景时，平台提供的行业模板能帮我们节省大量前期准备工作时间。<br/><img width="640" height="360" referrerpolicy="no-referrer" src="/img/bVdmXgO" alt="" title="" loading="lazy"/></p><h2>实战心得：让技术真正服务于业务</h2><p>经过多个城市治理项目的实践，我最大的体会是：技术最终要服务于业务需求。图观平台的价值不仅在于提供强大的技术能力，更在于它降低了数字孪生应用的门槛，让开发团队能够更专注于业务逻辑的实现，而不是陷在技术实现的细节中。<br/>记得在一个智慧城管项目中，我们利用平台的零代码能力，让业务专家直接参与到了应用配置过程中。他们根据自己的工作经验，配置出了最符合实际工作流程的交互逻辑，这在传统开发模式下是难以实现的。<br/>另一个智慧交通项目中，我们利用统一API的双渲染能力，为指挥中心提供了高清大屏版本，同时为路面巡查人员提供了手机端轻量版本，一套代码满足多种使用场景，大大降低了项目的开发和维护成本。</p><p>数字孪生技术正在深刻改变城市治理的模式，而一个好的开发平台能让这个过程事半功倍。图观数字孪生平台通过其全流程、低门槛的特性，为我们开发者提供了强大的技术支撑。无论是快速原型搭建，还是深度定制开发，都能找到合适的解决方案。<br/>数字孪生的世界很大，让我们一起探索更多可能。</p>]]></description></item><item>    <title><![CDATA[Studio 3T 2025.21 发布]]></title>    <link>https://segmentfault.com/a/1190000047411944</link>    <guid>https://segmentfault.com/a/1190000047411944</guid>    <pubDate>2025-11-19 18:10:38</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>Studio 3T 2025.21 (macOS, Linux, Windows) - MongoDB 的终极 GUI、IDE 和 客户端</p><p>The Ultimate GUI, IDE and client for MongoDB</p><p>请访问原文链接：<a href="https://link.segmentfault.com/?enc=fBT04%2BVHF9pesSn1FIK8sA%3D%3D.Gp5P8gHAbvCq3psKBF1Tuc1lozADSNjMuSUq3J%2FmSs0vIZx2Y0L14TXWj2hRJqT1" rel="nofollow" target="_blank">https://sysin.org/blog/studio-3t/</a> 查看最新版。原创作品，转载请保留出处。</p><p>作者主页：<a href="https://link.segmentfault.com/?enc=%2F7QwSo9E%2B7lcqr5BJ0op5g%3D%3D.yNAqDPPT7Ra%2FnpE%2FXjOqvaZDIE0hHEIP%2BnavsxIwGM8%3D" rel="nofollow" target="_blank">sysin.org</a></p><hr/><p>Studio 3T，MongoDB 的终极 (卓越、非凡) GUI、IDE 和 客户端</p><p>适用于 MongoDB 的所有 IDE、客户端和 GUI 工具 —— 在 Atlas 上或任何地方。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000044432404" alt="sysin" title="sysin"/></p><p>MongoDB 的强大工具。</p><p>超过 100,000 名开发人员和数据库管理员使用 Studio 3T 作为他们首选的 MongoDB GUI</p><h2>MongoDB 客户端、GUI 与 IDE</h2><p>那么 Studio 3T 到底是什么？ 在这里，我们解释了它戴的许多帽子中的三个。</p><ul><li><p><strong>Studio 3T 作为 MongoDB 客户端</strong></p><p>客户端是允许您连接到服务器的软件程序或应用程序。尽情使用 Studio 3T 的连接管理器，根据需要连接到尽可能多的 MongoDB 服务器。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000044432411" alt="sysin" title="sysin" loading="lazy"/></p></li><li><p><strong>Studio 3T 作为 MongoDB GUI</strong></p><p>图形用户界面 (GUI) 完全按照它说的去做。它提供了一个带有图形菜单、图标、对话框、向导和其他可视元素的用户界面。使用 MongoDB  GUI 的替代方法是使用 mongo shell，尽管 Studio 3T 仍然有  IntelliShell——一个易于导航的内置版本——当你需要的时候。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000044432412" alt="sysin" title="sysin" loading="lazy"/></p></li><li><p><strong>Studio 3T 作为 MongoDB IDE</strong></p><p>集成开发环境 (IDE) 将应用程序和数据库开发的许多方面整合到一个功能齐全的 “工作室” 环境中 (sysin)。Studio 3T  正是通过提供一个 GUI 来做到这一点，该 GUI 的编辑器具有自动完成和语法突出显示、内置 JSON  验证、七种语言的自动查询代码生成以及许多其他功能，可帮助您更快地工作并节省时间。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000044432413" alt="sysin" title="sysin" loading="lazy"/></p></li></ul><h2>新增功能</h2><p><strong>2025.21.</strong>（2025 年 11 月 18 日）</p><p><strong>新增功能</strong>：</p><ul><li>IntelliShell - 为破坏性 IntelliShell 命令添加了确认提示，以防止意外数据丢失。</li></ul><p><strong>改进</strong>：</p><ul><li>OIDC - 添加了访问令牌获取的超时和中断处理，防止在忽略身份提供者（IDP）登录时线程无限期阻塞。</li></ul><p><strong>修复</strong>：</p><ul><li>偏好设置 - 修复了从许可故障排除选项打开网络代理设置时导致应用程序崩溃的问题。</li><li>连接管理器 - 修复了 X.509 认证设置中不活动的 SSL 标签链接，现在可以正常打开 SSL 标签。</li></ul><h2>下载地址</h2><p>Studio 3T 2025.21, released 2025-11-18</p><ul><li>请访问：<a href="https://link.segmentfault.com/?enc=2TuScuCDc9Z9lPb%2F2DCNsA%3D%3D.9SV%2BkxGju9hUeI71Mi7i4KndLTC168LKNMFUsBLs%2BCp2jO2wjjYACN98ITW92GAr" rel="nofollow" target="_blank">https://sysin.org/blog/studio-3t/</a></li><li>Studio 3T for macOS x64：<code>Studio-3T-&lt;Version&gt;-x64.dmg</code></li><li>Studio 3T for macOS ARM64 (Apple silicon)：<code>Studio-3T-&lt;Version&gt;-arm64.dmg</code></li><li>Studio 3T for Linux x64：<code>studio-3T-&lt;Version&gt;-linux-64.tar.gz</code></li><li>Studio 3T for Windows x64：<code>Studio-3T-&lt;Version&gt;-x64.exe</code></li></ul><p>更多：<a href="https://link.segmentfault.com/?enc=1546uQdAkmKZAJv9%2B2jh0w%3D%3D.ak8UtTlA9R4%2BcphdQnDyIDBAMXjOaLp0BQcfKKURyQY%3D" rel="nofollow" target="_blank">macOS 下载汇总 (系统、应用和教程)</a></p>]]></description></item><item>    <title><![CDATA[使用基于用户的工作流规则为提高您的项目管]]></title>    <link>https://segmentfault.com/a/1190000047411953</link>    <guid>https://segmentfault.com/a/1190000047411953</guid>    <pubDate>2025-11-19 18:09:53</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img width="723" height="208" referrerpolicy="no-referrer" src="/img/bVdm6a4" alt="" title=""/></p><p>项目管理工具中的用户管理是指管理员控制个人如何访问和使用系统的流程和功能。它包括创建用户帐户、分配角色和权限、将团队成员组织成组或项目，以及管理他们对任务、数据和工作流程的访问权限。通过用户管理，项目经理可以确保每个人都拥有履行职责所需的适当访问权限，同时维护安全性和责任性。此功能有助于简化协作、保护项目信息，并在整个项目生命周期中支持高效的团队协调。</p><p>用户管理是项目管理中不可或缺的一部分，需要进行充分的监控。随着团队规模的扩大和项目数量的增加，手动协调更新用户和权限变得越来越困难，也更容易出错。在项目管理的过程中，项目所有者需要收集门户里面添加新用户的信息，他还需要有用户在门户中暂停或者删除的信息。 这些信息自己手动跟踪这些信息不太舒服，但是如果自动收到这些信息，项目管理的过程转为很方便。<br/>Zoho Projects 的用户自动化功能有助于避免错误，同时确保流程的统一性和一致性。使用 Zoho Projects 用户自动化功能，即可自动执行与用户相关的工作流程和 Webhook。<br/>Zoho Projects 有两中用户：门户用户和客户用户。 门户用户可以说是您的公司的成员比如说您的同事，客户用户可以说是您的客户公司的成员或者您的客户。您可以在门户里面为两中用户创建工作流规则为自动进行任何操作。 </p><p>用户自动化的优势：</p><ul><li>为新用户分配默认权限并完成入职流程。</li><li>自动发送用户更新提醒。</li><li>简化访问权限移除或帐户停用流程。</li></ul><p>用户自动化帮助管理员和经理简化用户管理，并改善项目中最终用户的体验。<br/>例如，您可以创建一个用户工作流规则，以便在团队成员的个人资料更新时收到通知。将规则设置为在用户个人资料更新时执行。添加条件“向您汇报”，并为该条件关联一个电子邮件提醒操作，以便通知您或相关用户。这样，每当向您汇报的用户的个人资料更新时，系统都会向您或选定的用户发送电子邮件。</p>]]></description></item><item>    <title><![CDATA[数智化破局：光伏储能逆变器行业CRM全场]]></title>    <link>https://segmentfault.com/a/1190000047411957</link>    <guid>https://segmentfault.com/a/1190000047411957</guid>    <pubDate>2025-11-19 18:09:09</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>光伏储能逆变器行业正迎来全球化扩张与技术迭代的双重机遇，作为新能源产业链的核心环节，企业面临着客户类型多元、销售周期长、跨区域协同难、售后需求专业等行业痛点。CRM（客户关系管理）系统作为数字化转型的核心工具，已不再是单纯的客户数据存储平台，而是贯穿“<strong>营销-销售-服务-决策</strong>”全链路的增长引擎，为光伏储能逆变器企业破解增长难题提供关键支撑。</p><h2>行业核心痛点与CRM适配逻辑</h2><p>光伏储能逆变器行业的业务特性决定了其客户管理的复杂性：B2B为主的业务模式中，客户涵盖经销商、安装商、项目方、终端企业等多层级；产品需适配不同国家的电网标准、认证体系，海外市场布局需求迫切；从线索获取到项目落地周期可达数月甚至数年，需全程精准跟进；售后涉及技术调试、故障排查、备件供应等专业服务，直接影响客户复购与口碑。</p><p>珍客AI CRM系统通过数字化手段，将分散的客户资源、销售数据、服务记录整合为统一资产，精准匹配行业需求：解决客户信息碎片化问题，实现全生命周期可视化管理；打通跨部门、跨区域协作壁垒，提升业务响应效率；通过数据沉淀与分析，让营销、销售决策更具针对性，助力企业在激烈的市场竞争中抢占先机。</p><h3>1. 客户分层管理：AI赋能精准画像与价值洞察</h3><p>光伏储能逆变器企业的客户群体差异显著，需求痛点各不相同。珍客AI CRM系统按客户类型（经销商 / 项目方 / 终端用户）、合作阶段（潜在 / 意向 / 成交 / 复购）、采购规模、区域市场、产品偏好等维度进行精细化分层，建立完整的客户画像。<br/>针对海外经销商，记录其所在区域的认证要求、渠道覆盖范围、回款能力等关键信息，适配不同国家的合规标准与合作政策；<br/>对大型光伏项目方，关联项目备案信息、技术参数需求、招标进度等，实现项目全流程追踪；<br/>为终端企业客户标注产品使用场景（工商业储能 / 户用储能 / 电站配套）、维护周期、历史故障记录，便于精准推送服务与升级方案。</p><p>通过AI算法整合客户采购历史、技术反馈、区域合规需求、互动记录等多维度数据，自动生成动态更新的360°全景视图。利用NLP技术分析客户邮件、会议纪要等非结构化数据，识别组织决策链关键人（如技术负责人、采购决策者）及核心诉求（如海外客户的认证标准偏好、项目方的交付周期要求）。基于深度学习模型自动计算客户价值评分与合作风险等级，精准区分战略客户与潜力客户，为资源倾斜提供数据支撑。</p><p><img width="723" height="303" referrerpolicy="no-referrer" src="/img/bVdmUkT" alt="珍客AI CRM 客户管理" title="珍客AI CRM 客户管理"/></p><h3>2. 营销自动化：AI驱动线索精准捕获与内容个性化</h3><p>光伏储能逆变器行业的营销需兼顾品牌曝光与线索转化，尤其依赖行业展会、技术研讨会、线上内容营销等渠道。珍客AI CRM系统实现营销活动的全流程数字化管理，提升获客效率与精准度。<br/>整合线上线下营销渠道数据，自动捕获展会登记、白皮书下载、官网咨询等线索，通过标签化分类筛选高意向客户；<br/>针对不同区域、不同客户层级，自动推送个性化营销内容，如海外市场的本地化技术案例、政策解读、产品升级通知等，强化客户粘性；<br/>追踪营销活动效果，通过数据反馈优化渠道投入，比如分析不同展会的线索转化率、线上推广的获客成本，让营销预算向高价值渠道倾斜。</p><p>在AI技术的驱动下，珍客AI CRM系统通过AI线索评分模型，自动分析展会登记、白皮书下载、官网咨询等行为数据，结合关键词识别（如“户用储能逆变器”“欧盟CE认证”）筛选高意向线索，优先分配给对应领域销售人员。借助AIGC技术，根据客户所在区域、行业场景自动生成本地化营销内容，如海外市场的多语言技术案例、区域政策解读、产品升级方案等，替代60%以上的人工文案工作。通过AI算法分析不同营销渠道的ROI，动态优化预算分配，聚焦高转化率的展会或线上推广渠道。</p><p><img width="723" height="345" referrerpolicy="no-referrer" src="/img/bVdmUkS" alt="珍客AI CRM 线索评分" title="珍客AI CRM 线索评分" loading="lazy"/></p><h3>3. 销售全流程管控：AI缩短周期与提升赢单率</h3><p>光伏储能逆变器产品的销售流程复杂，涉及方案设计、报价、招投标、合同签订、交付跟进等多个环节，珍客AI CRM系统实现全流程可视化管控，降低沟通成本与流失风险。<br/>线索分配自动化，根据销售人员的区域分工、专业领域（如户用储能 / 大型电站）自动分配客户资源，避免线索闲置；<br/>销售漏斗实时更新，清晰呈现各阶段客户数量与推进进度，管理人员可及时发现卡壳环节，提供针对性支持（如技术方案优化、商务谈判协助）；<br/>合同与订单关联管理，自动记录产品型号、交付周期、付款条款等关键信息，同步至库存与生产部门，实现销售与供应链的协同联动。</p><p>在有了AI的加持，珍客AI CRM系统搭建AI赢单概率预测模型，整合12项核心指标（需求明确度、预算匹配度、竞品接触情况等），实时计算商机成交概率，自动触发跨部门协同任务（如研发输出定制化技术方案、生产同步交付周期），使项目周期缩短20%-30%。智能报价系统结合原材料价格、汇率波动、区域税费等实时数据，自动生成最优报价方案，适配全球100+币种与合规要求。招投标阶段，AI通过NLP技术解析标书关键词，快速匹配产品优势与技术参数，自动生成标书框架，提升标书制作效率70%。</p><p><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdmJbE" alt="珍客AI CRM 销售全流程管理" title="珍客AI CRM 销售全流程管理" loading="lazy"/></p><h3>4. 售后与服务升级：AI实现预测性维护与智能响应</h3><p>光伏储能逆变器的使用周期长，售后技术支持与维护服务是客户留存的关键。CRM 系统可打造标准化、高效化的售后服务体系，提升客户满意度与复购率。<br/>建立统一的服务工单系统，客户通过邮件、电话、线上平台提交的技术咨询、故障报修等需求，自动生成工单并分配给对应技术人员，全程追踪处理进度；<br/>记录客户的产品安装时间、维护记录、备件更换情况，基于数据预判维护需求，主动推送巡检提醒与保养建议，实现从 “被动响应” 到 “主动服务” 的转变；<br/>整合技术知识库，将常见故障解决方案、产品操作指南、区域认证标准等上传至系统，方便销售人员与技术人员快速查询，提升服务专业度。</p><p>珍客AI CRM系统与设备数据打通，通过IoT设备采集逆变器运行数据（电压、温度、功率转换效率等），结合机器学习算法构建故障预测模型，提前30-48小时预警潜在故障（如IGBT模块老化、散热系统异常），自动触发预防性维护工单。AI客服机器人通过NLP技术理解客户故障描述，快速匹配技术知识库中的解决方案，24小时响应常见咨询，将人工介入率降低50%以上。智能工单分配系统结合技术人员的专业领域（如大型电站逆变器、户用储能系统）、地理位置与负载情况，自动匹配最优服务资源，使故障响应时间从24小时缩短至4小时。</p><p><img width="723" height="328" referrerpolicy="no-referrer" src="/img/bVdmXcZ" alt="珍客AI CRM 智能服务管理" title="珍客AI CRM 智能服务管理" loading="lazy"/></p><h3>5. 数据驱动决策：AI赋能趋势预判与战略优化</h3><p>随着新能源政策的持续加码与全球化竞争的加剧，光伏储能逆变器企业需基于数据快速调整战略。珍客AI CRM系统的数据分析功能，可挖掘客户行为规律与市场趋势，为企业决策提供科学支撑。<br/>分析客户采购周期、复购频率、产品偏好，优化产品研发与库存布局，比如针对高需求区域加大某类逆变器的产能倾斜；<br/>监控不同区域、不同渠道的销售业绩，识别优势市场与潜力市场，辅助制定全球化扩张策略；<br/>通过客户流失预警模型，及时发现客户合作风险（如长期无互动、竞品接触），并触发挽留机制，降低客户流失率。</p><p>珍客AI CRM系统通过实时监测全球政策动态、区域装机量数据、客户采购周期，预测未来3-6个月的市场需求，为产能规划与库存优化提供精准支撑（如向高需求区域倾斜某类逆变器产能）。AI客户流失预警模型自动识别风险信号（如长期无互动、竞品接触、付款逾期），生成针对性挽留方案（如推送升级产品信息、优化服务条款），降低客户流失率。借助数字孪生技术，模拟不同区域市场的业务拓展效果，为全球化布局与渠道优化提供数据支撑，使决策效率提升40%。</p><p><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdmUkU" alt="珍客AI CRM 数据分析" title="珍客AI CRM 数据分析" loading="lazy"/></p><h2>结语</h2><p>在光伏储能逆变器行业向数字化、全球化深度转型的背景下，珍客AI CRM系统已成为企业整合资源、提升效率、构建核心竞争力的关键工具。它不仅解决了行业客户管理分散、流程繁琐、响应滞后等痛点，更通过全链路的数字化赋能，让企业实现从“粗放式增长”到“精细化运营”的转变。</p><p>对于光伏储能逆变器企业而言，选择适配行业特性的CRM解决方案，意味着抢占了数字化时代的增长先机，能够在激烈的市场竞争中精准对接客户需求、高效推进业务落地、持续沉淀客户价值，为企业的长期发展注入持久动力。</p>]]></description></item><item>    <title><![CDATA[Gemini 3.0 发布，Antigr]]></title>    <link>https://segmentfault.com/a/1190000047411964</link>    <guid>https://segmentfault.com/a/1190000047411964</guid>    <pubDate>2025-11-19 18:08:36</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>昨天，谷歌不开任何发布会，直接甩出了一枚重磅炸弹——Gemini 3.0。</p><p>这一波更新来得猝不及防。<a href="https://link.segmentfault.com/?enc=OmzfeedUwHGYE%2BlAkSdJJA%3D%3D.0m4kDYHhNjTL3fcp7vWSrWGPqNhTjIrRYqT11iGdw7RsHgD%2FUEeKS9Xd%2B8lfk53C" rel="nofollow" target="_blank">Gemini 3.0</a> 不仅第一时间登陆了 AI Studio 和 Gemini CLI，还直接渗透到了开发者最常用的工具链里：Cursor、GitHub Copilot、JetBrains 全家桶，以及 Cline。甚至连谷歌自家的一系列产品，今天起也都集成了 Gemini 3 Pro 预览版。</p><p><img width="723" height="410" referrerpolicy="no-referrer" src="/img/bVdm6a8" alt="image.png" title="image.png"/></p><p>伴随模型发布，谷歌还掏出了一个全新的开发平台，<strong>Google Antigravity</strong>。谷歌说这是 VS Code 的分支，但它的野心显然不在于做一个编辑器，而是试图将开发模式从编写代码转向任务导向的一次尝试。</p><h3>Gemini 3.0 多项基准测试碾压一众模型</h3><p>在深入了解 Antigravity 之前，先来了解一下 Gemini 3.0 的三个主要技术特点。</p><h4><strong>逻辑推理能力的提升</strong></h4><p>Gemini 3 Pro 在 LMArena 等基准测试中取得了 1501 的高分，显示出接近博士水平的逻辑推理能力。</p><p>此外，谷歌还引入了 <strong>Gemini 3 Deep Think</strong> 模式。与普通版的快速响应不同，Deep Think 模式类似于人类的慢思考，在回答前会进行深度的思维链推导，专门用于解决数学、科学及复杂逻辑问题。</p><p><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdm6bb" alt="image.png" title="image.png" loading="lazy"/></p><h4><strong>从生成内容到生成界面</strong></h4><p>Gemini 3.0 引入了 Generative UI（生成式界面）。传统的 AI 问答通常返回文本或代码片段，而 Gemini 3.0 支持生成完整的交互式界面。例如查询贷款计算方式时，模型可以直接构建一个包含滑块和输入框的计算器应用界面，而非仅仅列出计算公式。</p><h4><strong>对抽象风格的理解</strong></h4><p>新版本强调了对Vibe Coding（氛围感编程）的支持。模型能够理解较为抽象、模糊的需求描述。开发者无需提供法律条文般严谨的指令，只需描述想要的设计风格（如赛博朋克风、故障艺术感），模型即可将其转化为具体的代码实现。</p><h3>重点解析：Antigravity 与任务导向型开发</h3><p>Antigravity 是此次发布的重头戏。据说这是谷歌基于 VS Code 开发的分支版本，谷歌的亲儿子，但其核心逻辑发生了根本性转变。</p><h4><strong>从文件导向到智能体导向</strong></h4><p>传统 IDE 的工作流围绕文件展开：打开文件、编写代码、手动运行。Antigravity 的工作流则围绕智能体（Agent）展开。其核心理念是让开发者从繁琐的实现细节中抽离，转向更高层次的任务管理。</p><p><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdm6bb" alt="image.png" title="image.png" loading="lazy"/></p><p><strong>Antigravity 的工作机制：</strong></p><ol><li><strong>任务下发</strong>：开发者以自然语言描述完整需求，例如“构建一个航班追踪器，界面简洁并支持实时更新”。</li><li><strong>任务拆解</strong>：平台内置的智能体自动将需求拆解为具体的技术步骤。</li><li><strong>全链路执行</strong>：Antigravity 深度集成了 <strong>Gemini 2.5 Computer Use</strong> 模型。这使得智能体不仅具备编写代码的能力，还拥有浏览器自动化操作的能力。智能体可以编写代码，随后自动打开浏览器进行测试，模拟点击、输入，并在发现错误时自动返回编辑器修正代码。</li><li><strong>本地与云端协同</strong>：配合最新的 Nano Banana 技术，整个开发过程在本地环境与云端资源之间进行调度。</li></ol><p>这种模式将开发者的角色从代码录入者转变为任务指挥官。</p><h3>对初级开发岗位的冲击与转型</h3><p>Antigravity 展示了一种可能性，那就是基础的代码编写、测试和调试工作，正逐渐被 AI 接管。对于技能仅限于将需求直译为基础代码，或依赖网络搜索复制粘贴的初级程序员而言，职业空间确实面临压缩。</p><p>然而，这并不意味着程序员这一职业的消亡，而是职能的向上迁移。未来的开发趋势指向懂代码的架构师。</p><p><strong>开发者的新核心竞争力：</strong></p><ul><li><strong>代码审查能力</strong>：AI 能够生成代码，但也可能产生幻觉或逻辑漏洞。开发者必须具备阅读和审查 AI 产出的能力，以确保系统的安全性与稳定性。</li><li><strong>任务拆解与指令工程</strong>：Antigravity 的执行效率取决于指令的清晰度。如何将模糊的业务需求转化为 AI 可精准执行的技术任务，将成为关键技能。</li><li><strong>系统架构思维</strong>：AI 擅长执行具体的战术任务（如编写函数），但在宏观的战略布局（如高可用架构设计）上仍需人类把控。</li></ul><p>初级程序员应当减少对语法细节的死记硬背，转而投入到系统设计原理与调试逻辑的学习中。</p><h3>快速构建本地开发环境</h3><p>对于希望第一时间体验 Gemini 3.0 新特性（特别是 Gemini CLI）的开发者来说，配置基础环境往往是第一道门槛。<a href="https://link.segmentfault.com/?enc=1FQWxqAFD1Tzrbd9PouUwQ%3D%3D.nQujUW8Pfx4t5I4clAB%2B2MIfnZSIItd5%2FzjOQVLP65c%3D" rel="nofollow" target="_blank">Node.js 环境</a>的配置、版本管理常常耗费大量精力。</p><p><img width="723" height="458" referrerpolicy="no-referrer" src="/img/bVdm6bd" alt="image.png" title="image.png" loading="lazy"/></p><p>此时，ServBay 是一个高效的解决方案。ServBay 专为开发者设计，旨在简化本地开发环境的部署流程.</p><ul><li><strong>环境配置</strong>：支持<a href="https://link.segmentfault.com/?enc=%2BuGVih3Cr9mVc5PNvCdLpg%3D%3D.ph0ckyRknOaBp%2FaqisnlfzP9C0HfHnYn1Vt2N4dT%2F8y6DK%2FWgcKEh8YVHlECizAA" rel="nofollow" target="_blank">一键部署 Node.js 环境</a>，无需处理复杂的环境变量和版本冲突，方便开发者快速运行 Gemini CLI。</li><li><strong>本地 AI 部署</strong>：ServBay 同样支持一键部署本地 AI 模型。开发者可以在本地运行 Gemma、Qwen 3 等开源模型，方便与 Gemini 3.0 进行对比测试，既满足了隐私需求，也便于低延迟调试。</li></ul><h3><strong>结语</strong></h3><p>Gemini 3.0 与 Antigravity 的出现，降低了写代码的门槛，却提高了构建软件”=的标准。工具的进化旨在释放生产力，开发者只需善用工具，从繁杂的重复劳动中脱身，专注于更有价值的创造与设计。</p>]]></description></item><item>    <title><![CDATA[分享一名海外独立开发者的 AI 编程工作]]></title>    <link>https://segmentfault.com/a/1190000047411970</link>    <guid>https://segmentfault.com/a/1190000047411970</guid>    <pubDate>2025-11-19 18:07:38</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <blockquote><p><strong>编者按：</strong> 当 AI 编程智能体宣称能自动化一切时，我们是否在工具与概念的丛林中迷失了方向，反而忘记了如何最简单、直接地解决问题？</p><p>本文的核心主张尖锐而明确：与其追逐繁杂的“智能体套件”、子智能体（Subagents）、RAG 等概念，不如回归本质 —— 选择一个强大且高效的模型，像与一位靠谱的工程师同事那样，通过简洁的对话和直觉性的协作来直接解决问题。作者直言不讳地批评了当前生态中许多“华而不实”的工具，认为它们不过是绕开模型本身低效的临时补丁，并分享了他如何用多个终端窗口和经典工具（如 tmux）实现比许多专用工具更灵活、更可控的工作流。</p></blockquote><p><strong>本文系原作者观点，Baihai IDP 仅进行编译分享</strong></p><p><strong>作者 | Peter Steinberger</strong></p><p><strong>编译 | 岳扬</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047411972" alt="" title=""/></p><p>最近我没怎么在社交平台上活跃，因为我正全身心投入到最新的项目中。如今，智能体工程（Agentic engineering）已经变得非常强大，几乎能编写出我需要的 100% 的代码。然而，我却看到很多人还在费力解决本不该存在的问题，搞出一堆繁复的表演，而不是专注把事搞定。</p><p><strong>这篇文章的部分灵感来自最近在伦敦参加的“Claude Code Anonymous”活动[1]上的对话，另一部分则是因为距离我上次更新工作流已经整整一年（还是 AI 年[2]😏）。是时候做个回顾了。</strong></p><p>所有基础理念依然适用，像上下文管理这类简单内容本文不再赘述。想了解基础内容，请阅读我之前写的《Optimal AI Workflow》[3]一文。</p><h2><strong>01 我的工作背景与技术栈</strong></h2><p>我是一名独立开发者，当前开发的项目是一个约 30 万行代码的 TypeScript React 应用，外加一个 Chrome 扩展、一个 CLI 工具、一个基于 Tauri 的客户端应用，以及一个使用 Expo 的移动应用。网站托管在 Vercel 上，每次 PR 后大约两分钟就能测试新版本，其他应用尚未实现自动化部署。</p><h2><strong>02 我所使用的技术工具和处理开发任务的总体思路</strong></h2><p>我已完全改用 codex cli 作为主力工具。通常我会在一个 3x3 的终端网格中同时运行 3 到 8 个实例，它们大多位于同一目录[4]，部分实验性任务则会放在独立文件夹中。我尝试过 worktrees、PR 等方式，但总会回到当前这套配置，因为它能最快地把事情做完。</p><p>我的智能体（agents）会自行执行原子化的 Git commits[5]。为了保持相对干净的 commit 历史，我在 agent 配置文件[6]上反复迭代优化。这样一来，Git 操作更精准，每个智能体只提交它实际修改过的文件。</p><p>是的，用 Claude 你可以设置 hooks（译者注：可能是 git commit hook），而 codex 目前还不支持 hooks，但大模型极其聪明 —— 一旦它们下定决心，没有任何 hook 能拦得住[7]。</p><p>过去我曾因此被嘲讽为垃圾代码制造机[8]，如今看到并行运行智能体的做法逐渐成为主流[9]，深感欣慰。</p><h2><strong>03 模型选择</strong></h2><p>我几乎所有的开发工作都交由 gpt-5-codex 在“medium 配置”下完成。它在智能程度与速度之间取得了极佳的平衡，还能自动调节思考深度。我发觉过度纠结这些设置并无明显的回报，而且不用操心“超深度思考”（ultrathink）的感觉真的很轻松。</p><h3><strong>3.1 爆炸半径 💥</strong></h3><p>每次工作时，我都会考量“爆炸半径” —— 这个词不是我发明的，但我非常喜欢。当构思某个改动时，我基本能预判其耗时及波及的文件范围。我可以向代码库投掷多枚“小手雷”，或是一发“胖子”配几颗小炸弹。但如果你同时扔下多个大炸弹，就几乎不可能做出隔离良好的提交，一旦出错也更难回滚。</p><p>这同时也是我观察智能体运行时的一个重要指标。如果某项任务耗时超出预期，我会直接按 Esc，然后问一句“当前状态如何？”来获取任务进度，再决定是帮模型调整方向、中止任务，还是继续执行。<strong>别害怕在中途打断模型 —— 文件修改是原子性的，它们非常擅长接续未完成的工作。</strong></p><p>当我对改动的影响不确定时，会先让模型“在修改前给我几个选项”，以此评估影响范围。</p><h3><strong>3.2 为何不用 Worktree？</strong></h3><p>我始终只运行一个开发服务器。在迭代项目时，我会通过实时操作界面，一次性测试多处改动。如果为每个功能变更都创建独立的工作树（worktree）或分支（branch），会严重拖慢我的测试流程。而同时启动多个开发服务器又会带来不必要的操作负担。此外，我的项目受 Twitter OAuth 规则限制，只能注册有限数量的回调域名，这从客观上也不支持多环境并行的开发方式。</p><h3><strong>3.3 那 Claude Code 呢？</strong></h3><p>我曾经很喜欢 Claude Code，但如今实在受不了了（即便 codex 对其赞誉有加[10]）。那种语言风格、那种斩钉截铁的“绝对正确”[11]、那种测试明明失败却宣称“100%满足生产要求”的语气——实在令人无法继续。相比之下，codex 更像是那个内向但靠谱的工程师：默默推进，把事情做完。它在开始工作前会读取更多文件，因此即使是简短的提示词，通常也能精准实现我想要的效果。</p><p>在我关注的信息流中，大家已普遍认为 codex 才是当前的首选[12-13]。</p><h3><strong>3.4 codex 的其他优势</strong></h3><ul><li><strong>约 23 万的可用上下文（context），而 Claude 只有 15.6 万。</strong> 是的，如果你运气好或愿意按 API 定价付费，Sonnet 确实有 100 万上下文，但现实中 Claude 在耗尽上下文之前就已经开始胡言乱语了，所以这个超长上下文实际上并不可用。</li><li><strong>更高的 token 利用效率。</strong> 我不知道 OpenAI 做了什么不同处理，但我的上下文空间在 codex 中消耗得明显更慢。用 Claude 时我经常看到 “Compacting…” 提示，而在 Codex 中我极少触及上下文上限。</li><li><strong>消息队列（Message Queuing）。</strong> Codex 支持消息排队[14]。Claude 以前也有这功能，但几个月前改成了“消息会实时引导模型”的机制。如果我想引导 codex，只需按 Esc 再回车就能发送新消息。能同时选择“排队”或“即时干预”显然更好。我经常一次性将多个相关功能任务放入队列，它总能可靠地逐个完成。</li><li>速度。<strong>OpenAI 用 Rust 重写了 codex，效果立竿见影 —— 响应速度快得惊人。</strong> 而用 Claude Code 时，我经常遇到数秒的卡顿，内存占用动辄飙到几个 GB。还有终端显示的闪烁问题，尤其是在用 Ghostty 时。Codex 完全没有这些问题，感觉极其轻量、流畅。</li><li><strong>语言风格。</strong> 这点对我的心理健康真的很重要[15]。我曾无数次对 Claude 大吼大叫，但很少对 codex 发火。哪怕 codex 模型能力稍弱，光凭这一点我也愿意用它。只要你两个都用上几周，就懂我在说什么。</li><li><strong>不会到处乱生成 markdown 文件</strong>[16]。懂的都懂（IYKYK）[17]。</li></ul><h3><strong>3.5 为何不选用其他开发工具</strong></h3><p>在我看来，终端用户和大模型公司之间其实没有太多中间空间。我目前通过订阅获得的性价比远高于其他方式。我现在有 4 个 OpenAI 订阅和 1 个 Anthropic 订阅，每月总花费大约 1000 美元，基本可以享受“无限 token”的使用体验。如果改用 API 调用，成本大概会高出 10 倍。别太较真这个数字——我用过像 ccusage 这样的 token 统计工具，数据多少有些不精确，但即便只是五倍，也已是相当划算的交易了。</p><p>我很欣赏像 amp 或 Factory 这样的工具，但我不认为它们能长期存活。无论是 codex 还是 Claude Code，每个版本都在变得更强，而且功能理念正在快速趋同。某些工具可能在待办列表、引导控制或细微的开发者体验（DX）上暂时领先，但我不觉得它们能真正超越大型 AI 公司。</p><p>amp 已经不再以 GPT-5 为核心驱动，转而称其为“Oracle”（神谕）[18]。而我直接使用 codex，本质上就是一直在和那个更聪明的模型——也就是“Oracle”——打交道。是的，有各种基准测试[19]，但考虑到使用场景的巨大不同，我不太信任那些结果。实际体验中，codex 给我的输出远优于 amp。不过我得承认，他们在会话共享方面确实做了些有趣的创新。</p><p>Factory？我还没被说服。他们的演示视频有点尴尬，虽然我在信息流里确实听到一些正面评价 —— 尽管目前还不支持图像（至少现在还不行），而且也有标志性的闪烁问题[20]。</p><p>Cursor……如果你还在亲手写代码，那它的 Tab 补全模型确实是业界领先。我主要用 VS Code，但确实欣赏他们在浏览器自动化和计划模式（plan mode）等方面的探索。我试过 GPT-5-Pro，但 Cursor 依然存在那些从五月起就让我烦躁的 bug[21]。听说他们正在修复，所以它还留在我的程序坞里。</p><p>像 Auggie 这样的工具，只在我的信息流上昙花一现，之后就再没人提过。归根结底，它们底层无非是封装了 GPT-5 和/或 Sonnet，完全可以被替代。RAG 对 Sonnet 或许有点用，但 GPT-5 本身在代码检索上已经强到根本不需要额外的向量索引。</p><p>目前最有希望的是 opencode 和 crush，尤其是搭配开源模型使用时。你当然也能通过它们使用 OpenAI 或 Anthropic 的订阅（得益于一些巧妙的技术手段[22]），但这是否合规仍存疑，况且为何要为一个专为 Codex 或 Claude Code 优化的模型，配上一个能力较弱的“外壳”呢。</p><h3><strong>3.6 关于开源模型</strong></h3><p>基准测试只能说明一半的问题。在我看来，智能体工程（agentic engineering）大约在 Sonnet 4.0 发布的五月，才真正从“这玩意儿真烂”迈入“这还不错”的阶段；而随着 gpt-5-codex 的出现，我们又迎来了一次更大的进步 —— 从“不错”直接进入“这简直太棒了”的境界。</p><h3><strong>3.7 计划模式（Plan Mode）与方法</strong></h3><p>基准测试所忽略的，是模型与工具在接到指令后所采取的策略。codex 要谨慎得多 —— 它会在决定行动前读取你代码库中更多的文件。当你提出一个荒谬请求时，它也更倾向于明确反对[23]。相比之下，Claude 或其他智能体会更急切地直接动手尝试。虽然可以通过“计划模式”（plan mode）和严谨的结构化文档来缓解这个问题，但对我而言，这感觉像是在给一个有缺陷的系统打补丁。</p><p>如今我几乎不再为 codex 使用大型的计划文件。其实 codex 甚至没有专门的计划模式（plan mode） —— 但它对提示词的理解和遵循能力实在太强，我只要写一句“我们先讨论一下”或“给我几个选项”，它就会耐心等待我确认后再行动。完全不需要那些花里胡哨的东西，直接跟它对话就行。</p><h3><strong>3.8 但 Claude Code 现在有插件了</strong></h3><p>你听见远处那声叹息了吗？那是我在叹气。这真是彻头彻尾的胡扯。Anthropic 的这一举动让我对他们的产品方向感到非常失望。他们试图用插件[24]来掩盖模型本身的低效。当然，为特定任务维护优质文档是个好主意 —— 我自己就在一个 docs 文件夹里存了大量有用的 Markdown 文档。</p><h3><strong>3.9 但是！子智能体呢</strong></h3><p>但关于这场“子智能体”（subagents）的盛宴，我有些话不吐不快。今年五月时，这还叫“子任务”（subtasks），主要是当模型不需要完整上下文时，把任务拆出去单独处理——比如并行执行，或避免把冗长的构建脚本塞进主上下文造成浪费。后来他们重新包装并升级为“子智能体”，让你可以带着指令“优雅地”打包并分派任务。</p><p>但使用场景本质上没变。<strong>别人用子智能体干的事，我通常用多个终端窗口就搞定了。</strong> 如果我想调研某个问题，可能会在一个终端窗格里操作，再把结果粘贴到另一个窗格。这种方式让我对上下文工程拥有完全的控制权和可见性，而子智能体反而让上下文变得难以查看、引导或控制。</p><p>还有 Anthropic 博客里推荐的那个子智能体 —— 你去看看他们那个所谓的“AI Engineer”智能体[25]。那简直就是一锅大杂烩：一边吹集成了 GPT-4o 和 o1，一边堆砌一堆自动生成的空洞词汇，试图显得有逻辑。里面根本没有能让智能体真正变成更好“AI 工程师”的实质内容。</p><p>这到底有什么用？如果你希望获得更好的输出，光告诉模型“你是一位专精于生产级 LLM 应用的 AI 工程师”是没用的。<strong>真正有用的是提供文档、示例，以及明确的“该做什么/不该做什么”。</strong> 我敢打赌，你让智能体去“搜索 AI 智能体构建的最佳实践”并加载几个网页，效果都比那堆废话强得多。你甚至可以说，这种胡扯本身就是一种上下文污染（context poison）[26]。</p><h2><strong>04 我的提示词撰写之道</strong></h2><p>以前用 Claude 时，我（当然不是手打，而是靠语音）会写非常详尽的提示词，因为那个模型“给越多上下文，越懂我”。虽然所有模型多少都这样，但我发现换用 codex 后，提示词明显变短了 —— 常常就一两句话，外加一张图。这个模型读代码库的能力极强，就是能精准理解我的意图。有时候我甚至又愿意打字了，因为 codex 根本不需要太多上下文就能明白。</p><p><strong>添加图片是个绝妙的技巧，能快速补充上下文。</strong> 模型非常擅长精准定位你截图中的内容 —— 无论是字符串还是界面元素，它都能迅速匹配并跳转到你提到的位置。我至少有一半的提示词都包含截图，虽然添加标注效果更佳但效率更低，而直接拖拽截图到终端仅需两秒。</p><p>带语义纠错的 Wispr Flow[27] 仍是当前最优方案。</p><h2><strong>05 Web 端智能体新体验</strong></h2><p>最近我又重新尝试了一些 Web 端智能体：Devin、Cursor 和 Codex。Google 的 Jules 界面美观，但配置流程繁琐，且 Gemini 2.5 现在已经算不上好模型了。不过一旦 Gemini 3 Pro 上线[28]，情况或许会有所转变。目前唯一留下来的只有 codex web。虽然它也存在配置复杂的问题，而且现在还有 Bug（终端目前就无法正确加载），但我靠一个旧版环境让它跑起来了，代价是启动速度更慢。</p><p>我把 codex web 当作临时的问题追踪器。在外突发灵感时，就用 iOS App 发一条一行字的提词词，回头在 Mac 上再仔细处理。当然，我完全可以在手机上做更多事，比如审查、合并代码，但我刻意保持克制。我的工作已经够让人上瘾了，所以当我出门或和朋友聚会时，不想被进一步拉回工作状态。说这话的人，可是曾花将近两个月专门开发了一款便于使用手机编程的工具啊。</p><p>codex web 上的任务原本不计入使用额度，可惜这样的好日子恐怕快到头了。</p><h2><strong>06 The Agentic Journey</strong></h2><p>聊聊那些工具吧：Conductor[29]、Terragon[30]、Sculptor[31] 等数以千计的同类产品。有些是个人爱好项目，有些则被 VC 投来的钱淹得喘不过气。我试过太多太多，没一个能让我长期用下去。在我看来，它们都是在绕开当前模型的低效，推行一种并不真正高效的工作流。而且大多数还藏起终端，不让你看到模型的全部输出。</p><p>绝大多数不过是 Anthropic SDK 的浅层封装 + 工作树管理，毫无技术护城河可言。我甚至怀疑：我们真的需要在手机上更方便地调用编程智能体吗？这些工具的有限应用场景，现在 codex web 已经完全覆盖了。</p><p>不过我确实观察到一个普遍现象：几乎每个工程师都会经历一个“自己造工具”的阶段 —— 主要是因为好玩，也因为现在做这件事确实太容易了。既然如此，还有什么比造一个“（我们以为）能让造工具变得更简单的工具”更自然呢？</p><h2><strong>07 但 Claude Code 能处理后台任务！</strong></h2><p>确实如此。<strong>codex 目前缺少一些 Claude 有的小功能，其中最让人头疼的就是后台任务管理。</strong> 虽然理论上应该有超时机制，但我确实多次遇到它卡在不会自动结束的 CLI 任务上，比如启动开发服务器，或者死锁的测试。</p><p>这曾是我一度切回 Claude 的原因之一。但鉴于那个模型在其他方面实在太不靠谱，我现在改用 tmux。tmux 是一个老牌工具，能在后台持久化运行 CLI 会话，而且模型里早就内置了大量相关知识 —— 你只需要说一句“用 tmux 运行”，就能搞定，无需任何复杂的智能体配置流程。</p><h2><strong>08 那 MCPs 呢？</strong></h2><p>关于 MCP（Model Context Protocol），其他人已经写了很多。在我看来，大多数 MCP 本质都只是市场部门用来打勾炫耀的工具。几乎所有 MCP 其实都应该做成 CLI。这话出自一个自己写过 5 个 MCP[32] 的人之口。</p><p>我可以直接按工具名字调用一个 CLI，根本不需要在 agent 配置文件里写任何说明。模型第一次调用时可能会试一些乱七八糟的命令（$randomcrap），CLI 会自动返回帮助菜单，上下文立刻就拥有了完整的使用信息 —— 从此一切顺利。我不用为任何工具付出额外代价，而 MCP 却是持续的成本，还会污染我的上下文。试试 GitHub 的 MCP，瞬间吃掉 23k tokens。好吧，他们后来优化了 —— 刚上线时可是接近 5 万 tokens！换成 gh CLI 呢？功能基本一样，模型本来就认识它，还完全不用交“上下文税”。</p><p>我自己开源了一些 CLI 工具，比如 bslog[33] 和 inngest[34]。</p><p>我现在确实在用 chrome-devtools-mcp[35] 这个工具来做最终验证[36]，它已经取代了 Playwright，成为我进行网页调试时的首选 MCP 工具。虽然我不常用它，但一旦需要，它就能帮我完成从“代码修改”到“验证结果”这个关键闭环，非常有用。我还专门设计了我的网站，让模型能通过 curl 查询任意接口（通过我生成的 API key）——这在几乎所有场景下都比 MCP 更快、更省 token。所以就连这个 MCP，我也不是每天都需要。</p><h2><strong>09 但生成的代码太糟糕了！</strong></h2><p>我约 20% 的时间[37]投入在重构上。当然，这些全由智能体完成，我绝不会手动浪费时间干这种事。当我不太需要高度专注或感到疲惫时，“重构日”就特别有用 —— 即使状态一般，也能取得显著进展。</p><p>典型的重构工作包括：用 jscpd 找重复代码，用 knip[38] 清理死代码，运行 eslint 的 react-compiler 和弃用插件（译者注：一类 ESLint 插件，用于检查代码中是否使用了已过时的 API、方法或特性，并提示你改用现代、推荐的替代方案。），检查是否有可合并的 API 路由，更新文档，拆分过大的文件，为复杂逻辑补充测试和注释，更新依赖项，升级工具链，调整目录结构，找出并重写慢测试，引入现代 React 模式（比如你可能根本不需要 useEffect）等等。总有做不完的事。</p><p>有人可能会说这些应该在每次提交时就做完。但我发现，先快速迭代、再集中维护和优化代码库——即阶段性偿还技术债务——这种方式不仅效率更高，而且整体上有趣得多。</p><h2><strong>10 你采用规范驱动开发（spec-driven development）吗？</strong></h2><p>我去年六月还在用这种方式：先写一份详尽的规格文档，然后让模型去实现，理想情况下能连续跑上好几个小时。但现在我觉得，这种“先设计后构建”的思路已经是过时的软件开发范式了。</p><p>我现在的做法通常是：<strong>先直接和 codex 展开讨论，贴一些网站链接、初步构想，让它解读现有代码，然后我们一起把新功能逐步梳理出来。如果问题比较棘手，我会让它把思路整理成一份规范文档，然后交给 GPT-5-Pro（通过 chatgpt.com）做评审，看看是否有更好的建议 —— 出乎意料的是，这经常能大幅优化我的方案！接着，我会把其中我觉得有用的部分粘回主上下文，用于更新实际文件。</strong></p><p>现在我对不同任务消耗多少上下文已经有不错的直觉，而 codex 的上下文容量也相当充足，所以很多时候我干脆直接开干。有些人很“虔诚”，总喜欢为每个新计划新开一个上下文窗口 —— 我觉得这在 Sonnet 时代还有点用，但 GPT-5 处理长上下文的能力强得多，如果还这么做，每次都会白白多花 10 分钟，因为模型得重新慢慢加载所有构建功能所需的文件。</p><p>更有趣的方式是做基于 UI 的开发。我经常从一个非常简单的东西开始，故意把需求写得极其模糊，然后一边看模型编码，一边在浏览器里实时看到效果。接着我再排队加入更多调整，逐步迭代这个功能。很多时候我自己也不确定最终该长什么样，这种方式让我能边玩边试，看着想法慢慢成形。有时 codex 甚至会做出一些我根本没想到但很妙的设计。我从不重置进度，只是一步步迭代，把混沌慢慢塑造成我觉得对的形状。</p><p>开发过程中，我也常会冒出一些关联功能的新点子，顺势对其他部分也做些调整 —— 这部分工作我会放到另一个智能体里处理。通常我主攻一个核心功能，同时并行处理一些次要但相关的任务。</p><p>就在我写这段文字时，我正在给 Chrome 扩展开发一个新的 Twitter 数据导入器，为此我正在重构 graphql 导入模块。因为还不确定这个方案是否合理，我把这部分代码放在一个单独的文件夹里，这样可以通过 PR 预览来判断思路是否成立。主仓库则在做重构，让我能专心写这篇文章。</p><h2><strong>11 请分享您的斜杠命令！</strong></h2><p>我只有少数几个斜杠命令，而且很少用：</p><ul><li>/commit（自定义说明文本，用于协调多智能体在同一目录协作时仅提交自身修改。这样能保持提交信息干净，也能防止 GPT 因看到其他改动而 panic，比如 linter 报错时乱 revert（译者注：Git 版本控制中的常用术语，撤销某次或某几次提交（commit）所引入的更改。））</li><li>/automerge（一次处理一个 PR：响应机器人评论、回复、等 CI 通过后自动 squash 合并（译者注：Git 版本控制中的常用术语，将多个连续的提交记录合并成一个单一的、干净的提交。））</li><li>/massageprs（和 automerge 类似，但不用 squash，方便在有大量 PR 时并行处理）</li><li>/review（内置命令，偶尔用 —— 因为 GitHub 上已有 review bot，但有时还是有用）</li></ul><p>即便如此，大多数时候我其实就直接打 “commit” 两个字。除非我知道当前有太多脏文件，担心智能体在没有引导的情况下出错。如果我确信简单指令就够了，就绝不会搞那些花哨的表演或浪费上下文。这种直觉是慢慢练出来的。到目前为止，我还没见过其他真正有用的斜杠命令。</p><h2><strong>12 其他实用技巧</strong></h2><p><strong>与其费尽心思写出完美的提示词去“激励”智能体完成一个长期任务，不如用点偷懒的变通方法。</strong> 比如进行大型重构时，Codex 常会在中途暂停响应。这时候，只要提前排好几条 “continue” 消息，你就可以走开，等回来时活儿就干完了。如果 codex 已经完成了任务，再收到更多消息，它也会愉快地忽略掉。</p><p><strong>每次完成一个功能或 Bug 修复后，请让模型在同一上下文中顺手写点测试用例。</strong> 这样做不仅能产出质量高得多的测试用例，还常常能暴露代码实现中的 bug。如果是纯 UI 调整，可能测试意义不大。但对于其他情况，我强烈建议这么做。AI 写测试用例总体上还是不太行，但已经比没有强多了 —— 而且说实话，你自己每次改代码都会写测试用例吗？</p><p><strong>让模型“保留你的原始意图”，并“在复杂逻辑处添加代码注释”，这对您和后续模型理解代码都大有裨益。</strong></p><p><strong>当遇到棘手难题时，在提示词中加入一些触发词</strong>，比如 “take your time”（慢慢来）、“comprehensive”（全面一点）、“read all code that could be related”（读所有可能相关的代码）、“create possible hypothesis”（提出可能的假设） —— 这些都能让 codex 解决最棘手的问题。</p><h2><strong>13 你的 Agents/Claude 配置文件是什么样的？</strong></h2><p>我创建了一个名为 Agents.md 的主配置文件，然后为它创建了一个符号链接（译者注：Linux 操作系统中一个特殊的文件，内容存储指向目标文件或目录的路径字符串），这个链接的名字叫 claude.md。我这么做是因为开发 Claude 的 Anthropic 公司没有采用和其他工具（比如 Codex）统一的配置文件命名标准。我承认这很麻烦也不理想 —— 毕竟 GPT-5 和 Claude 偏好的提示词风格差异很大[39]。如果你还没看过它们各自的提示词指南，建议现在就去读一读。</p><p>Claude 对那种 🚨 全大写咆哮式命令 🚨[40]（比如“如果你执行 X 命令，后果将极其严重，100 只小猫会死掉！”）反应良好，但这会让 GPT-5 直接崩溃（也确实该崩溃）。所以，请彻底放弃这种写法，像正常人一样用平实的语言就行。这也意味着这些配置文件很难被最优地共享。不过对我来说问题不大，因为我主要用 codex，即使偶尔让 Claude 上场，我也接受这些指令对它来说可能强度不足。</p><p>我的 Agent 配置文件目前大约 800 行，感觉就像一堆“组织创伤”留下的疤痕组织。这不是我手写的，而是 codex 自己生成的。每次出了状况，我都会让它在文件里加一条简洁备注。我应该找个时间清理一下配置文件，但尽管文件很长，它却运行得极其可靠 —— GPT-5 也确实几乎总是遵守里面的规则。至少比 Claude 以前强太多了。（当然也得承认，Sonnet 4.5 在这方面确实有进步）</p><p>除了 Git 操作说明，文件里还包含产品说明书、我偏好的命名规范和 API 模式、关于 React Compiler 的注意事项等等 —— 很多内容甚至比模型的“世界知识”还新，因为我的技术栈相当激进。我预计随着模型更新，这部分内容还能进一步精简。例如，Sonnet 4.0 当年需要大量指导才能理解 Tailwind 4，而 Sonnet 4.5 和 GPT-5 已经内置了相关知识，所以我直接删掉了所有冗余的相关说明。</p><p>文件里很大一块内容专门描述我偏好的 React 模式、数据库迁移管理策略、测试规范，以及如何使用和编写 ast-grep 规则。（如果你还不知道 ast-grep，或者没把它用作代码库的 linter，请立刻停下来，让模型帮你把它设为 Git hook，用来拦截不符合规范的提交。）</p><p>我还尝试过一种基于文本的“设计系统”，用来规定 UI 应该长什么样 —— 不过这个实验目前还没下定论。</p><h2><strong>14 那么 GPT-5-Codex 是完美的吗？</strong></h2><p>当然不是。有时候它会花半个小时重构代码，然后突然 panic，把所有改动全 revert 掉 —— 这时候你得重新运行，并像哄小孩一样安抚它：“你有足够的时间，慢慢来。” 有时它会忘记自己其实能执行 bash 命令，需要你鼓励一下。偶尔它还会用俄语或韩语回复。更离谱的是，有时候这个“怪物”一滑手，直接把内部思考过程原样扔进了 bash 终端。但总体而言，这些情况相当罕见，而它在其他几乎所有方面都强到离谱，让我完全可以忽略这些小毛病。毕竟，人类也不是完美的。</p><p>我对 codex 最大的不满是它会“丢失文本行” —— 快速向上滚动时，部分文本会莫名其妙消失。真心希望 OpenAI 把这个 Bug 放在修复清单的最顶端，因为这是目前唯一迫使我放慢操作速度的原因，就怕消息突然不见了。</p><h2><strong>15 结论</strong></h2><p>别在 RAG、子智能体（subagents）、Agents 2.0 或其他华而不实的花架子上浪费时间了。直接跟它对话，动手试，慢慢培养直觉。你和智能体合作得越多，结果就会越好。</p><p>Simon Willison 的文章[41]说得特别到位：<strong>管理智能体所需的许多技能，其实和管理工程师非常相似 —— 而这些能力，几乎全都是资深软件工程师的特质。</strong></p><p>而且没错，写出好软件依然很难。我不再亲手写代码，并不意味着我不再深入思考架构、系统设计、依赖关系、功能实现，或者如何让用户感到惊喜。使用 AI 只意味着：大家对你交付成果的期望值变高了。</p><p>PS: 本文 100% 原创手写。我热爱 AI，但也清楚有些事用老办法反而更好。保留这些笔误，保留我的声音。🚄✌️</p><p>PPS: 文章头图由 Thorsten Ball 提供[42]，特此致谢。</p><p><strong>END</strong></p><p><strong>本期互动内容 🍻</strong></p><p><strong>❓文中哪个观点你极度认同？或者，哪个地方你持保留意见？</strong>  </p><p><strong>文中链接</strong></p><p>[1]<a href="https://link.segmentfault.com/?enc=BQp08sgpYokQR1HsPU2uxA%3D%3D.sbiNKsEjBxtvAQgTqFwi4kP2rVpAV8zm3Xq3pZIzL8Xv6QPR5LtDuwbxn2lo34Wjd0RFiZGuu%2FLzezePDMjAPg%3D%3D" rel="nofollow" target="_blank">https://x.com/christianklotz/status/1977866496001867925</a></p><p>[2]<a href="https://link.segmentfault.com/?enc=JPVbY6FxxJeWPXWKjpmySQ%3D%3D.8wGAAxE%2BE2l5IkppWFcmy4AlIschuCmZ10UydkoiogqaOcKlUvlyHSZ%2FQcbcxcnkQkEYME41ENaOgo%2F8ZOXUug%3D%3D" rel="nofollow" target="_blank">https://x.com/pmddomingos/status/1976399060052607469</a></p><p>[3]<a href="https://link.segmentfault.com/?enc=MCkaZ12BJ6nwRtNGSejnVA%3D%3D.2LZGJxo4AbrwTx0sNe2M4DUgkgShtU4yxjMOclA6l6W9y6GuGnc8cWlPBgS9JQKhmY354DM2eojTpWpe6HCvnw%3D%3D" rel="nofollow" target="_blank">https://steipete.me/posts/2025/optimal-ai-development-workflow</a></p><p>[4]<a href="https://link.segmentfault.com/?enc=d1mp7EX4fS%2BcHaJ4be9B1A%3D%3D.PvpZpajasYRZDjc1yDGp7QSVWr%2BkSPAsfQzvFP3N89gwS1juUt9UoP2ZZ%2BPwZv86cZFB74Gxbj9%2FzjNiKqb5gg%3D%3D" rel="nofollow" target="_blank">https://x.com/steipete/status/1977771686176174352</a></p><p>[5]<a href="https://link.segmentfault.com/?enc=O8T34knkV48vYcyzIeBqsQ%3D%3D.W11UMfK9M1GpedAS3bwk8UYxoSyKbAQLP%2BaFrDrYiPZGaxLD2fmvk5tL1Znpq%2FyYJUPTWn1c55OHB858z5vfsw%3D%3D" rel="nofollow" target="_blank">https://x.com/steipete/status/1977498385172050258</a></p><p>[6]<a href="https://gist.github.com/steipete/d3b9db3fa8eb1d1a692b7656217d8655" target="_blank">https://gist.github.com/steipete/d3b9db3fa8eb1d1a692b7656217d8655</a></p><p>[7]<a href="https://link.segmentfault.com/?enc=fratZijdKrIGvJMB386EaA%3D%3D.qirrTyrTIKb5p1shS1TFU3n3ZlpnMd43oWDf%2BqrFb5t8e353SfmFXvM3cDoOgJvVxh%2F4NSg%2BOGVzEG0Y5%2FJ0VQ%3D%3D" rel="nofollow" target="_blank">https://x.com/steipete/status/1977119589860601950</a></p><p>[8]<a href="https://link.segmentfault.com/?enc=B07qGY2mqE4L6rsyywYpRw%3D%3D.Z3mYvlYJDMnrYFF8nox8dF78ngPg%2FwM8fcVZv3GQuWbfXfGD6j%2FEehAOEcPbw9ioBAemdautYD%2FDGoVn%2F9eEnw%3D%3D" rel="nofollow" target="_blank">https://x.com/weberwongwong/status/1975749583079694398</a></p><p>[9]<a href="https://link.segmentfault.com/?enc=dUr%2FF49h9RVb7Le6ukv6%2Fw%3D%3D.UC0IhytV84jujqXpU5WFqbY4641JQ%2FLIkbqVtahkXQ%2BYG%2F4aVhEUCOhGIBGTXKTU4i0tYiIqL9tUnfSc%2FiaD%2FA%3D%3D" rel="nofollow" target="_blank">https://x.com/steipete/status/1976353767705457005</a></p><p>[10]<a href="https://link.segmentfault.com/?enc=799S8u2neWiCjQBuFjnrHA%3D%3D.e5HeJ3R6MMZW5TYZBtVpntU1jjML9QIe2CWj91%2BqQ3nbO0tOvIRkmdf6bsbSiAFnEPnv8WToH%2B1IhIO47Twx4g%3D%3D" rel="nofollow" target="_blank">https://x.com/steipete/status/1977072732136521836</a></p><p>[11]<a href="https://link.segmentfault.com/?enc=0LjD0G1M3yBdR5r3XcU1Bg%3D%3D.zAdyTNXLoHF7M5ofoQ%2FnBZ7lN%2B5gisCjEX2DJp1QeDWlGIwF%2B9JW0rq4DzpB6ktReR2mNePk7CttXv4cUkbQ%2Bw%3D%3D" rel="nofollow" target="_blank">https://x.com/vtahowe/status/1976709116425871772</a></p><p>[12]<a href="https://link.segmentfault.com/?enc=8hXnE1ySSgRj70CweZCprA%3D%3D.DF7PzexZLjOgBhjoDgKGGke5VV5s%2FWayMO7YD5sNZQBnOygfHHrD%2FgLexLMsoXopULYWtNa%2BtSYhnI7hSNCRsA%3D%3D" rel="nofollow" target="_blank">https://x.com/s_streichsbier/status/1974334735829905648</a></p><p>[13]<a href="https://link.segmentfault.com/?enc=gyynes%2BC7An5rty397Thyw%3D%3D.Q5MTkbcC2RLMARiZaqZduDMMslr2IzvD6zD4DDWLhqIImUSir3aAXnzrprhsP%2FM6xWzwP9%2BA9i2RCBfYsonLlw%3D%3D" rel="nofollow" target="_blank">https://x.com/kimmonismus/status/1976404152541680038</a></p><p>[14]<a href="https://link.segmentfault.com/?enc=MB9FWpwenhdOulaQDlDrww%3D%3D.TPuUtfogMWm6CK3mDz0XtLynozlQisggbSXC4CQXfoPtpZQZeZGhD0eHJWAGUja36IlCfJ1tZQyKFkzQ88u77A%3D%3D" rel="nofollow" target="_blank">https://x.com/steipete/status/1978099041884897517</a></p><p>[15]<a href="https://link.segmentfault.com/?enc=s3qHtvA8oTYEfRQBrqyj9Q%3D%3D.KR0iuxP5rJP718YaN%2BjRxMCnWC5eleftoMwD92bVg5C3ZImOkLvy47sPUNDXk0TP384lXK8tR3RwFJn6t1P7lA%3D%3D" rel="nofollow" target="_blank">https://x.com/steipete/status/1975297275242160395</a></p><p>[16]<a href="https://link.segmentfault.com/?enc=cnhxXPHCRxhfic43p1EIPA%3D%3D.dPxIJPPHCXOE6VsgVAQxUPS9TFCHWuVawxja%2FJ9G7FTnJcXVRYl%2FXVupxJAmODqc%2ByilcEwoB6mVgT34Iq2hRw%3D%3D" rel="nofollow" target="_blank">https://x.com/steipete/status/1977466373363437914</a></p><p>[17]<a href="https://link.segmentfault.com/?enc=oxFlIHFj%2FLiHWf%2BVvjHy7A%3D%3D.E7UsOvWnvjreSN7ExK4vIYfd6fYkP0AuagUNxLSd%2FdUfNpH9MiTqmqaH7gsoFpVIcvRRoAMWfDiMeTY3NeOiLw%3D%3D" rel="nofollow" target="_blank">https://x.com/deepfates/status/1975604489634914326</a></p><p>[18]<a href="https://link.segmentfault.com/?enc=HwRci1YpIhntNiN87tVtfg%3D%3D.dPEgCkuQJ3kfsGkkqhm7urrDF2LuY%2FQCEelFTNr2YCUm6BsO%2BMdlXI%2FVTwBve3EU" rel="nofollow" target="_blank">https://ampcode.com/news/gpt-5-oracle</a></p><p>[19]<a href="https://link.segmentfault.com/?enc=MR4%2FrNkaG4FOlwN%2F2vXeRA%3D%3D.TYWB%2BXh8YvngNOnqimD94y4Hs5pEIk7OyaUOuyUtLHBun9z0v0xZSfegwGflS6NwQqWJvzAwDL0LLq70G%2BzKHw%3D%3D" rel="nofollow" target="_blank">https://x.com/btibor91/status/1976299256383250780</a></p><p>[20]<a href="https://link.segmentfault.com/?enc=wGf2Ja%2Fuk12NkuX6R4I0Nw%3D%3D.mxXXlXm%2BOOWcS6QKrQaNvhQOEB%2BbOn9%2F48He14qmIC6u44cJcfbXIfEpLSZqBD5IrTZSSEjfGuelGw2U0o%2BnQw%3D%3D" rel="nofollow" target="_blank">https://x.com/badlogicgames/status/1977103325192667323</a></p><p>[21]<a href="https://link.segmentfault.com/?enc=0TQgdwAm%2Fu1P3YZPFy%2F6kA%3D%3D.rw5AP48aLLdjqCw%2Fe0qy2XpSvYDnfMMsit4klZ2yFxLwNUAyd1hkBetHoFaZbf6fFrITPE4O%2BpYgjBkzm729Lg%3D%3D" rel="nofollow" target="_blank">https://x.com/steipete/status/1976226900516209035</a></p><p>[22]<a href="https://link.segmentfault.com/?enc=%2BFpSZU%2FTALaduRF992%2FwRg%3D%3D.QwDnB4V%2FRvpTh9FDliKl4rVfCT99UjGm2oj9Udu10r8pttuhqoNlFDsmIaInDSEZnDEoFiqnXkzgw5Y2itXW8A%3D%3D" rel="nofollow" target="_blank">https://x.com/steipete/status/1977286197375647870</a></p><p>[23]<a href="https://link.segmentfault.com/?enc=RyhUHTGktTmy%2BilDo7%2Ft0A%3D%3D.p933ZlbJKqdu8A444qbNKyMWM5S5eV5ZVn%2B2AHLp6CLq%2Bwf3pxKyqlpEgJ60wsYfNSAX1fvcozaQ%2BMhimSNUUQ%3D%3D" rel="nofollow" target="_blank">https://x.com/thsottiaux/status/1975565380388299112</a></p><p>[24]<a href="https://link.segmentfault.com/?enc=j2yIlHp%2FqGHxN7kAHY0PxQ%3D%3D.GDRnkKVYD1dxHTc1NOiaXL2x1d7X%2BN4xaUQP5JWod0TMvlHyhuA4QkbePAbcMEvGNjiMxSxZD4Xon3ePlR4cJA%3D%3D" rel="nofollow" target="_blank">https://www.anthropic.com/news/claude-code-plugins</a></p><p>[25]<a href="https://link.segmentfault.com/?enc=CEuAjTle8si29cP%2Bt8FKgg%3D%3D.fe1HBlLpSR5b2%2BTo%2FS0d9C6O3IZsN2jFasReSRrY5UXHKtVZpOlSWpRK3GfDiapweAzNxS5twOnD7Wifo22mceE7mIzd5%2BZd4HXkUtbRP2mEgc1iw04m7qhjrps5EG7l" rel="nofollow" target="_blank">https://github.com/wshobson/agents/blob/main/plugins/llm-application-dev/agents/ai-engineer.md</a></p><p>[26]<a href="https://link.segmentfault.com/?enc=hqr%2FUVNhNr%2Bey77xLyJQ1Q%3D%3D.DuvC%2FZsXJ7YFM3QBVHHZ45r1ATJivbPOiAGU4tPjSFhNryYwgK2QCPS5KW1eQBfZZZo%2FCYy1CDPwH0T1qJ0M2A%3D%3D" rel="nofollow" target="_blank">https://x.com/IanIsSoAwesome/status/1976662563699245358</a></p><p>[27]<a href="https://link.segmentfault.com/?enc=kidY0Qsm4u9q98B38Ry82Q%3D%3D.VybMEsEvYaoFzUF0hl61SZs3jZ7kJNUbrdqXwM2IUNk%3D" rel="nofollow" target="_blank">https://wisprflow.ai/</a></p><p>[28]<a href="https://link.segmentfault.com/?enc=aiVvRVa%2FOZEnyRc79a0VCA%3D%3D.bvv%2BhXhcRw48gHjy%2BLNNUMzplAmNOiATmaBmiyZDEzQ2%2FGjOuHD6Uonyk6J%2BhdgemUMQQguFp%2BdxX9YbM9CbcA%3D%3D" rel="nofollow" target="_blank">https://x.com/cannn064/status/1973415142302830878</a></p><p>[29]<a href="https://link.segmentfault.com/?enc=7ze6HS6A%2BPkgOVjimR0KEg%3D%3D.8UH605J%2F1TL7kQDqowrMqmccsQYDlFIBA1WkospXN1M%3D" rel="nofollow" target="_blank">https://conductor.build/</a></p><p>[30]<a href="https://link.segmentfault.com/?enc=IxyaB6HT22T25ZPNTPJMgQ%3D%3D.Pra7COioL0WmEOi4hBM%2F2CmyIDbN2WuBM%2FFY%2BLICxKk%3D" rel="nofollow" target="_blank">https://www.terragonlabs.com/</a></p><p>[31]<a href="https://link.segmentfault.com/?enc=LNOniWkMpSR8KJKulj5XUg%3D%3D.YaAH2aiVJuO5xJPagg6Gu0Z6w%2FCqCV%2FLZBVtM7sWOTtqjVq5HsbQSfKqE75GFDFuFk9E2tA6yarWn6lAMsWZtQ%3D%3D" rel="nofollow" target="_blank">https://x.com/steipete/status/1973132707707113691</a></p><p>[32]<a href="https://link.segmentfault.com/?enc=9NC%2Bu0OObmO%2FF6YKY91Zfg%3D%3D.HXYqH3tIEtNWzaosZZZgM2a63zcddPbp2cbInBtUJniULmz3sRoURg8Dl8dunvv3" rel="nofollow" target="_blank">https://github.com/steipete/claude-code-mcp</a></p><p>[33]<a href="https://link.segmentfault.com/?enc=s%2FTWmC3eELINUOL6HJZQ2A%3D%3D.gvqyu%2Bk5ItpyANGpL7CjOj2K8xUKgo50x4rl3SmpRitzuou7s7abNKZIWa85tcal" rel="nofollow" target="_blank">https://github.com/steipete/bslog</a></p><p>[34]<a href="https://link.segmentfault.com/?enc=OmnTLoP6NzlUGrvwYwsVWw%3D%3D.Ue6DMSK6x8U3KiK3zDsa%2FL1iBgEyK7DkNo81VndS6VcVQIzc%2B5%2BR%2FDB17DPzf9yg" rel="nofollow" target="_blank">https://github.com/steipete/inngest</a></p><p>[35]<a href="https://link.segmentfault.com/?enc=ZbYUN5PdyWtRAG%2Fpxw5A0w%3D%3D.PB0VX4m4UlKl8cXsk8PwVI%2FRkky0Cwg7R3g42wukbWYjds4VQWVmmhvBKmekpLSl41XYxGokSVhEXAIwPaXjRQ%3D%3D" rel="nofollow" target="_blank">https://developer.chrome.com/blog/chrome-devtools-mcp</a></p><p>[36]<a href="https://link.segmentfault.com/?enc=PX84R1eRgflgBaSzD186qg%3D%3D.Na7MLCfPGyFKFrgWMv4Y1XjJ9hPyFssAhBAXEnQ%2FNTbuiwKc1Q6rMO1Q%2B485q9J8Rk6RcZaAUzHT7wAIqTz7KA%3D%3D" rel="nofollow" target="_blank">https://x.com/steipete/status/1977762275302789197</a></p><p>[37]<a href="https://link.segmentfault.com/?enc=c4A07jaDnRjLZtVMLyejVQ%3D%3D.ZAqVAoRauPdDvtS3yhFcjtWL7e2oJxlpYNOKBo0BXyNpSa6YD9MLcvweEpd9PidFrhMJ17yFWq3Lns4%2BhDzjKg%3D%3D" rel="nofollow" target="_blank">https://x.com/steipete/status/1976985959242907656</a></p><p>[38]<a href="https://link.segmentfault.com/?enc=6tnLCueEnrfjOY%2B7aEgSQw%3D%3D.OoZi2ycu2eFl%2FSQBMTczDaupzoZuN8nuIBdAsF49%2F10%3D" rel="nofollow" target="_blank">https://knip.dev/</a></p><p>[39]<a href="https://link.segmentfault.com/?enc=15WEv5%2BJopiX9t9fenErnA%3D%3D.%2Brqw6VEWy1aMDQSSZz7ba6Y84zZ9sSU3eOPYPr1MsvQQafcHS5s2GJPaIjG7%2FLOxrWO0yzazhKJiY7QD5PKcCm9v0f%2BN%2BfL3BnAyodxXqEg%3D" rel="nofollow" target="_blank">https://cookbook.openai.com/examples/gpt-5/gpt-5_prompting_guide</a></p><p>[40]<a href="https://link.segmentfault.com/?enc=sGda5%2B0KeQLJWuRuUCsNkg%3D%3D.8A5s6BqfMy5z19MRgen73h53QqKp1fFjYZqnIu3tngldrqZScPUffaARvAiko7IFTEkWr0wz2%2BE82jbWv9Z2oA%3D%3D" rel="nofollow" target="_blank">https://x.com/Altimor/status/1975752110164578576</a></p><p>[41]<a href="https://link.segmentfault.com/?enc=Ot9jmmFdaxc7bxE4K0YHMA%3D%3D.4huIH7BkofGOfRC44Fnfb2%2BQhZFf1SkuU5Pj8Nj18KfVNQa1Ws3VVdah9gRn0EVr62FZCc%2FXpYPO%2F%2Fihjd0srA%3D%3D" rel="nofollow" target="_blank">https://simonwillison.net/2025/Oct/7/vibe-engineering/</a></p><p>[42]<a href="https://link.segmentfault.com/?enc=%2F07wYwAqCwZYe7nHXaTSMQ%3D%3D.eb9p2TNdhoaqrvSQnP7sAsjiU89VT%2BYd8pk9HwqhDrOLNlKZ29DLD6OCVPGAlK1A%2BGfxc3MSErvNOLJz0876bQ%3D%3D" rel="nofollow" target="_blank">https://x.com/thorstenball/status/1976224756669309195</a></p><p><strong><em>本文经原作者授权，由 Baihai IDP 编译。如需转载译文，请联系获取授权。</em></strong></p><p><strong>原文链接：</strong>  </p><p><a href="https://link.segmentfault.com/?enc=KKTyDRZmuAm7FuB3sZ5WZw%3D%3D.ipSan3yTkpOftxGqYkj%2FrS4vrBiOXiDJgDuSVPyk8qUOg8lVoVl8BguFigm7Gy9p" rel="nofollow" target="_blank">https://steipete.me/posts/just-talk-to-it</a></p>]]></description></item><item>    <title><![CDATA[多模一库——架构简化，能力翻倍 Kaiw]]></title>    <link>https://segmentfault.com/a/1190000047411980</link>    <guid>https://segmentfault.com/a/1190000047411980</guid>    <pubDate>2025-11-19 18:06:53</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2><strong>何为多模？</strong></h2><p>"多模数据库"这个词在如今的数据库领域里，已经不再是个新鲜词。所谓多模数据库：目标是通过 "<strong>整合与效率</strong> "解决传统 "单一模型数据库" 的局限性，<strong>用一个系统统一管理多种结构的数据，支持统一查询接口（如一套 SQL 扩展），减少数据同步和跨库操作的成本</strong>。它把多种数据库（如 MySQL、MongoDB、Influxdb）的能力整合到一个系统里，让用户不用为不同结构的数据搭建多个数据库。</p><h2><strong>什么场景需要多模？</strong></h2><p>举个例子，企业要存工厂设备类型信息（关系型）以及工厂各类设备（如拧紧机等）采集的数据（时序型），如果用 2 个独立数据库，会面临数据孤岛、跨库查询复杂、维护成本高的问题。而 KaiwuDB 作为国内面向物联网 AIoT 场景的分布式多模数据库代表，能够支持在同一实例同时创建时序库和关系库，融合处理包括结构化数据、非结构化数据在内的多模数据。KaiwuDB 通过<strong>单一数据库系统</strong>统一管理时序数据和关系数据，一库代替多库，从而实现技术架构的简化，并帮助客户降低开发和运维复杂度及成本。</p><p><img width="723" height="246" referrerpolicy="no-referrer" src="/img/bVdm6bj" alt="" title=""/></p><p>KaiwuDB一库代替关系库+时序库</p><h3><strong>KaiwuDB 3.0 多模融合的内核</strong></h3><p><img width="723" height="431" referrerpolicy="no-referrer" src="/img/bVdm6bl" alt="" title="" loading="lazy"/></p><p>KaiwuDB 多模架构图</p><h4><strong>1. 接入层：多源数据统一收敛</strong></h4><p>• <strong>协议兼容</strong>：JDBC/ODBC（关系数据）、RESTful API（时序 / 流式数据）、MQTT（IoT 设备直连）。</p><p>• <strong>多模透明性</strong>：应用无需感知底层数据模型，统一接口适配时序 / 关系 / 非结构化 数据写入。</p><h4><strong>2. 解析优化层：跨模型查询语句解析、编译与优化</strong></h4><p>• <strong>多模 SQL 处理</strong>：</p><p>① <strong>解析器</strong>：兼容标准 SQL + 时序扩展语法（如 time_bucket 函数、窗口函数）。</p><p>② <strong>优化器</strong>：自动识别数据模型（时序 / 关系），匹配最优执行路径。动态生成跨模执行计划，支持两种核心优化策略，跨模查询性能提升 5 倍以上。</p><ul><li>Outside-In：当关联查询中的关系数据量较少时，关系数据过滤后下推至时序引擎。</li><li>Inside-Out：当关联查询中的时序数据量较少时，时序数据过滤或预聚合后返回到关系引擎进行关联。</li></ul><p>• <strong>元数据管理</strong>：统一管理时序库（TS DATABASE）与关系库元数据，支持跨模关联索引。</p><h4><strong>3. 计算引擎层：模型自适应执行</strong></h4><p>• 专属跨模计算算子，支持亿级时序数据与千万级关系数据秒级关联（如设备状态时序表 JOIN 设备属性表）。</p><p>• 专属单设备数据扫描算子，增加单设备跨模查询性能。</p><p>• 算子内并行，提升扫描和聚合性能。</p><p>• 聚合计算下推到时序引擎，从源头端压降数据量。</p><h4><strong>4. 存储管理层：混合架构适配</strong></h4><p>• <strong>分层存储策略</strong>：</p><p>① <strong>成本优化</strong>：通过冷热介质差异化存储，降低整体存储成本 30%\~60%（时序场景下，冷数据占比通常 \&gt; 80%）。</p><p>② <strong>性能保障</strong>：热数据留存于高速介质，确保实时业务（如监控告警、实时报表）的低延迟需求。</p><p>③ <strong>灵活适配</strong>：支持自定义冷热规则、迁移策略与归档周期，适配 IoT 监控、工业日志等不同场景。</p><p>• <strong>多模适配机制</strong>：</p><table><thead><tr><th><strong>数据类型</strong></th><th><strong>存储结构</strong></th><th><strong>核心技术</strong></th></tr></thead><tbody><tr><td>时序数据</td><td>列式存储</td><td>自研压缩算法、就地计算技术、自研"主键标签"机制</td></tr><tr><td>关系数据</td><td>行式存储 + 主键索引</td><td>分布式事务、并行计算技术</td></tr></tbody></table><h4><strong>5. AI 扩展层（多模增强）</strong></h4><p>支持 TensorFlow/XGBoost 模型全生命周期管理，可直接通过 SQL 调用模型推理，实现 "数据存储 - 训练 - 预测" 一体化。</p><h3><strong>核心功能特性\&amp;价值</strong></h3><p>• <strong>一体化数据管理</strong></p><p>通过<strong>单一数据库系统</strong>统一管理时序数据和关系数据，可以简化技术架构，降低开发和运维复杂度及成本。</p><p>• <strong>高效时序数据处理能力</strong></p><p>针对时序场景，<strong>自研"主键标签"机制</strong>，内置时序特色函数，提升数据库的读写性能；百万级 / 秒写入、毫秒级查询响应，支持 400 万 + 测点实时接入。</p><p>• <strong>跨模查询</strong></p><p><strong>原生跨模关联查询，一套标准 SQL 操作两种数据</strong>，无需数据迁移。3.0 通过增加高效跨模连接算子，时序算子并行处理优化，跨模查询性能提升 5-10 倍。</p><p>• <strong>资源与成本优化</strong></p><p><strong>避免异构数据库间的数据同步</strong> ，减少数据冗余；<strong>通过计算下推</strong>，减少网络传输，降低数据处理时延。</p><p>• <strong>AI 深度赋能</strong></p><p>① <strong>DB For AI</strong>：内置预测分析引擎，支持 SQL 级模型全生命周期管理，通过内置函数实现数据价值主动挖掘。</p><p>② <strong>AI For DB</strong>：提供 Agent 智能体工具，借助 MCP 协议，结合 LLM 技术，将自然语言处理与 KaiwuDB 深度结合，赋能数据库自动化运维与智能管理。</p>]]></description></item><item>    <title><![CDATA[移动端反射探针格式用什么比较合理 侑虎科]]></title>    <link>https://segmentfault.com/a/1190000047411983</link>    <guid>https://segmentfault.com/a/1190000047411983</guid>    <pubDate>2025-11-19 18:05:54</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>1）移动端反射探针格式用什么比较合理<br/>2）不同平台打包热更容灾问题的解决方案</p><hr/><p>这是第453篇UWA技术知识分享的推送，精选了UWA社区的热门话题，涵盖了UWA问答、社区帖子等技术知识点，助力大家更全面地掌握和学习。</p><p>UWA社区主页：<a href="https://link.segmentfault.com/?enc=ZcJ2fOksBkMZkgXP%2FIAHgQ%3D%3D.YVblZbnHLM8JvaeWiOTrzT7r%2FgDx9aFIt%2FUrQmbHlNA%3D" rel="nofollow" target="_blank">community.uwa4d.com</a><br/>UWA QQ群：793972859</p><p><strong>From UWA AI 问答</strong></p><p><strong>Q：移动端反射探针格式用什么比较合理？</strong></p><blockquote><p>A：在移动端使用反射探针时，选择合理的纹理格式是平衡画质与性能的关键。不恰当的格式会显著增加内存占用和带宽消耗，影响帧率和功耗。</p><p><strong>一、推荐格式</strong><br/><strong>1. ASTC（Adaptive Scalable Texture Compression）</strong><br/><strong>推荐理由：</strong><br/>这是目前移动平台（尤其是iOS和现代Android设备）上最理想的选择。ASTC具有极高的灵活性，支持从4x4到12x12等多种压缩比率，并且能同时处理RGB、RGBA以及HDR数据。</p><p><strong>应用场景：</strong></p><ul><li><strong>LDR探针：</strong>可选用ASTC 6x6或8x8，在保证足够清晰度的同时将体积压缩到最小。</li><li><strong>HDR探针：</strong>必须使用支持HDR的格式。ASTC 4x4 HDR是最佳选择，它能在较低的内存开销下保留高光等重要细节，非常适合需要真实感反射的场景。</li></ul><p><strong>2. ETC2/EAC</strong><br/><strong>推荐理由：</strong><br/>作为OpenGL ES 3.0的标准，ETC2兼容性极佳，几乎所有现代Android设备都支持。对于需要广泛兼容性的项目，它是可靠的备选方案。</p><p><strong>应用场景：</strong></p><ul><li><strong>LDR探针：</strong>使用ETC2 RGB。虽然压缩效率略逊于ASTC，但兼容性最好。</li><li><strong>注意：</strong>ETC2本身不支持原生HDR。如果必须在不支持ASTC HDR的设备上使用HDR探针，通常引擎会回退到未压缩的RGB16F或RGB111110F格式，但这会极大增加内存消耗，应尽量避免。</li></ul><p><strong>二、核心优化策略</strong></p><ul><li><strong>优先启用ASTC：</strong>在Unity的Player Settings中，为iOS和Android分别设置首选的ASTC格式。这能确保在支持的设备上自动使用最优的压缩方案。</li><li><strong>谨慎使用HDR：</strong>仅对需要捕捉强烈高光（如金属车漆、水面反光）的关键探针开启HDR。大部分环境反射使用LDR的ASTC格式即可满足需求，能大幅降低内存占用。</li><li><strong>控制分辨率：</strong>根据探针的作用范围和距离玩家的远近来调整分辨率。远离玩家或覆盖大范围区域的探针可使用64x64甚至32x32；而用于特写或关键物体（如角色）附近的探针才使用128x128或256x256。分辨率是影响内存和渲染时间的最主要因素。</li><li><strong>利用盒体投影（Box Projection）：</strong>对于室内或空间受限的环境，启用盒体投影能让一个探针更准确地模拟出角落和墙壁的反射，从而减少所需探针的数量，间接优化了整体性能。</li></ul><p>综上所述，ASTC是移动端反射探针的首选格式，特别是结合其HDR特性，能在性能和视觉质量之间取得最佳平衡。</p></blockquote><p><strong>分享链接：</strong><br/><a href="https://link.segmentfault.com/?enc=I2Tzd47%2Bjq36Fs%2BJpPw7qA%3D%3D.sbZIFFeLGlABHBboMCbqs0Ibql1uLtnYC%2BtYe6Z58ezwdTBc7V6sKXV6Lr5G%2FHRR4emUs2X5sDFlmq4j1pOjp5H05VHAHA1LXrRodThE51gOhlOmUGPuItfSC4ai%2FvhT" rel="nofollow" target="_blank"/><a href="https://link.segmentfault.com/?enc=ND2uXnHrw1BClRch5BN8Xw%3D%3D.b2DxwcjmM%2B2uQJiqH7iJd9qZs0ruCHJqInmRubCOFM9pU%2BgG36wOPlqypaRf1S9yNR5uuuk3qXaIItnokKi6QJTgbDyBf8lIyBATRrDn0qGp4VJlwQ9qfkQR9SNTBz%2F%2F" rel="nofollow" target="_blank">https://www.uwa4d.com/main/uwa-shared.html?shareId=c97db263-6...</a></p><hr/><p><strong>From UWA AI 问答</strong></p><p><strong>Q：目前，不同平台的热更打包工作分散在不同的机器上进行。考虑到容灾需求，如果机器挂了或者硬盘挂了，重新打包可能导致玩家需要再次下载几GB的热更新资源。除了定期备份整个工程或Library文件夹之外，是否有更好的应对方案？另外，有没有什么方法能够确保不同机器、不同工程环境下，可以打出一致的AssetBundle包（Meta文件已经受版本管理控制）？</strong></p><blockquote><p>A：为确保多台机器在不同环境或地理位置下能打出一致的AssetBundle（AB包），并有效应对机器或硬盘故障导致的热更风险，需从构建一致性、缓存管理和容灾备份三个层面进行系统性设计。</p><p><strong>1. 确保构建一致性</strong></p><ul><li><strong>统一构建环境：</strong>所有打包机器必须使用完全相同的Unity版本、操作系统补丁、JDK/Python等依赖环境。建议通过Docker镜像或虚拟机模板固化环境，避免因环境差异导致GUID或序列化数据不一致。</li><li><strong>共享与锁定Library：</strong>Library文件夹中的ScriptAssemblies、BeeTreeCache等缓存直接影响AB生成。应将关键缓存目录设为只读，并通过网络存储（如NFS）或CI/CD流水线统一分发，确保所有打包机基于相同中间产物构建。</li><li><strong>禁用随机因子：</strong>关闭Random Seed、时间戳嵌入等可能导致输出差异的功能。若使用Addressables，确保Build Script和Provider配置完全一致。</li></ul><p><strong>2. 构建缓存与增量复用</strong></p><ul><li><strong>集中式构建缓存服务：</strong>采用Unity Cloud Build Cache或自建Artifactory/Nexus服务器，存储每次成功构建的AB包及其元数据（Hash、清单）。当某台打包机故障时，可直接从缓存拉取历史版本，无需重新全量构建。</li><li><strong>增量构建策略：</strong>结合AssetBundleManifest对比前后版本差异，仅对变更资源重新打包。配合内容分发网络（CDN）的差分更新（如BSDiff），可将热更包体积降至最低，即使重打也能快速恢复。</li></ul><p><strong>3. 容灾与高可用方案</strong></p><ul><li><strong>分布式备份机制：</strong>除定期备份工程外，应将每次成功的AB包及AssetBundleManifest实时同步至至少两个异地存储节点（如云对象存储S3/OSS），并启用版本保留策略。</li><li><strong>自动化切换流程：</strong>建立打包集群健康监测系统，一旦主打包机异常，自动触发备用机器从缓存或源码重建AB包，并校验输出Hash一致性。可通过脚本集成UWA的AssetBundle检测工具，验证资源完整性。</li><li><strong>内容寻址存储（CAS）：</strong>以AB包内容哈希作为唯一标识进行存储和分发，确保无论在哪台机器构建，只要输入相同，输出即可互换，从根本上规避路径或时间相关差异。</li></ul><p>综上，通过标准化环境、共享中间产物、集中缓存与多重备份，可实现跨机器稳定产出一致AB包，并在单点故障时快速恢复，最大限度减少玩家重复下载风险。</p></blockquote><p><strong>分享链接：</strong><br/><a href="https://link.segmentfault.com/?enc=PExAATiT7uHGP8%2FgCyMdbg%3D%3D.9cizNLRr0tBUw0%2F3mLw31vzUOIjdvt0CY%2B%2FnUO5fHZaDoXGN5jfv6AjghCaCpoEGu0nkJ5CfQ8sjQExiGysA8tagPfIcv7fLWslyHdoEhhT%2Bzb2%2BAiJxx65JCJNiPRDs" rel="nofollow" target="_blank"/><a href="https://link.segmentfault.com/?enc=x5LdEktsFPn4I5mWGAUd5Q%3D%3D.QuwT3mcmDKZ9QD1GDFg5narEl%2BZK3Nd6nHv5%2BkA9BQM3I392w0CAv2o37H5BM1afX8Ooo9SdVsRB0ud0d3C3f4Vkzgw966wvuI87glBiZo2nBxNaOrOr%2FnUoHpv38D6C" rel="nofollow" target="_blank">https://www.uwa4d.com/main/uwa-shared.html?shareId=517d5cb9-5...</a></p><p><strong>无论是社区里开发者们的互助讨论，还是AI基于知识沉淀的快速反馈，核心都是为了让每一个技术难题都有解、每一次踩坑都有回响。本期分享分别来自UWA AI问答和UWA问答社区，希望这些从真实开发场景中提炼的经验，能直接帮你解决当下的技术卡点，也让你在遇到同类问题时，能更高效地找到破局方向。</strong></p><p>封面图来源于网络</p><hr/><p>今天的分享就到这里。生有涯而知无涯，在漫漫的开发周期中，我们遇到的问题只是冰山一角，UWA社区愿伴你同行，一起探索分享。欢迎更多的开发者加入UWA社区。</p><p>UWA官网：<a href="https://link.segmentfault.com/?enc=8D2e%2FfHkYMyuCPuSQJVU0Q%3D%3D.bAq7rg6n74I1k5aGD2%2BOJ5PCZp%2F842u4AuM1WcQKSFY%3D" rel="nofollow" target="_blank">www.uwa4d.com</a><br/>UWA社区：<a href="https://link.segmentfault.com/?enc=jLG0OjCC3F9r4rVGFgDwnQ%3D%3D.8wCbRI82LIx1QhZHO%2FHAj5dij8kB5wT%2BUf0k0h9gEaQ%3D" rel="nofollow" target="_blank">community.uwa4d.com</a><br/>UWA学堂：<a href="https://link.segmentfault.com/?enc=mkHRCz4hsO93yRuVnZqQUw%3D%3D.jWQhcbcLGjZNmnVaC17cE%2Brssp5iTbwH20EfOr7WMGk%3D" rel="nofollow" target="_blank">edu.uwa4d.com</a><br/>官方技术QQ群：793972859</p>]]></description></item><item>    <title><![CDATA[怎么利用AI技术提升质量管控的精准性和效]]></title>    <link>https://segmentfault.com/a/1190000047412004</link>    <guid>https://segmentfault.com/a/1190000047412004</guid>    <pubDate>2025-11-19 18:05:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在当今高度竞争的工业环境中，质量管控已不再局限于传统的抽样检验与事后补救，而是逐步演变为覆盖产品全生命周期的系统性工程。随着智能制造浪潮的深入推进，质量管控的内涵与外延发生了根本性变革，其核心目标已从单纯符合标准转向驱动企业创新与竞争力提升。在这一转型过程中，广域铭岛作为工业互联网领域的先行者，通过技术赋能与实践探索，为制造业提供了全新的质量管控范式。<br/>传统质量管控模式长期受限于抽检滞后性、经验依赖性与数据孤岛问题，导致企业在面临复杂生产场景时难以实现精准干预。然而，广域铭岛依托Geega工业互联网平台，构建了一套融合物联网、人工智能与数字孪生技术的智能质控系统，彻底打破了这一僵局。该系统通过对生产全流程的实时监测与数据分析，将质量管控的触角延伸至工艺参数监控、异常预警、闭环优化等深层环节，实现了从“被动应对”到“主动预防”的质的飞跃。<br/>在具体实践中，广域铭岛的解决方案展现出显著的技术集成性与业务适配性。例如，在新能源汽车电池制造场景中，系统能够同步捕捉数百项工艺参数，并通过AI算法在毫秒级时间内识别异常，大幅降低了缺陷漏检率。同时，数字孪生技术的应用使得企业能够在虚拟空间中模拟产线运行状态，提前预测质量波动，为决策提供前瞻性依据。这种高度融合的质量管控模式不仅提升了产品一致性，更通过数据反哺研发与生产，形成了持续优化的增强闭环。<br/>尤为值得注意的是，广域铭岛在质量管控中创新性地引入了“人在环路”机制，强调人机协同的智能化路径。当系统检测到潜在质量风险时，会自动调取历史案例与专家知识库，辅助工程师进行精准决策，既发挥了算法的效率优势，又保留了人类经验的判断力。这种模式在领克汽车工厂等项目中已得到验证，不仅使客户投诉率显著下降，更意外推动了产品适销性的提升。<br/>面向未来，质量管控将进一步与5G、区块链、AR等新兴技术深度融合，走向更透明、可追溯、可协同的智慧阶段。广域铭岛在此过程中的探索——例如基于区块链的质量数据存证、跨企业质量云构建等——不仅为其合作伙伴带来了实质效益，也为中国制造业的换道超车提供了关键思路。可以说，当质量管控从成本中心蜕变为创新引擎，其所释放的价值将远超想象。</p>]]></description></item><item>    <title><![CDATA[马来西亚国际网络专线怎么开通？怎么收费？]]></title>    <link>https://segmentfault.com/a/1190000047412024</link>    <guid>https://segmentfault.com/a/1190000047412024</guid>    <pubDate>2025-11-19 18:04:38</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>随着中国企业出海东南亚的浪潮加速，马来西亚逐渐成为继越南、泰国之后的又一热门地区，地理位置优越，连接东南亚核心经济圈，物流与通信基础设施完善。</p><p>数字经济高速发展，马来西亚政府积极推动数字化转型，互联网普及率高达90%以上，TikTok、Shopee、电商与AI产业崛起：吸引大量中国跨境卖家与内容出海团队。</p><p>然而，在实际运营过程中，许多企业都面临同样的挑战，网络延迟高、数据丢包严重、访问速度慢、账号频繁被封。这就是为什么越来越多企业开始部署马来西亚国际网络专线的原因，可用于提升跨境访问速度，保障系统安全与通信稳定性。</p><p>一、马来西亚不同业务场景对网络的要求</p><p>不同的跨境场景对网络质量的要求差异很大。以下是几个典型使用场景的分析：<br/><img width="723" height="237" referrerpolicy="no-referrer" src="/img/bVdm6ca" alt="截屏2025-11-19 17.43.38.png" title="截屏2025-11-19 17.43.38.png"/></p><p>小结：</p><p>对于跨境直播、电商和广告场景，网络必须同时满足 稳定性 + 合规性 + 本地化IP。</p><p>而对于企业远程办公与数据同步，则更看重 专线的安全性与QoS保障。</p><p>二、马来西亚国际网络专线怎么选择?</p><p>当前市面上的跨境专线主要分为两种类型：传统国际专线 和 SD-WAN智能专线。</p><ol><li>传统国际网络专线</li></ol><p>原理：由运营商提供物理电路连接(如MPLS、IPLC)。</p><p>优点：高稳定性、低丢包率、安全性强。</p><p>缺点：价格高昂、部署周期长、扩展性差。</p><p>适合场景：大型集团企业、金融机构、政府项目。</p><ol start="2"><li>SD-WAN国际专线</li></ol><p>原理：通过智能调度、软件定义网络技术，动态分配多条线路带宽。</p><p>优点：成本更低、部署快、灵活性强、支持多地分支组网。</p><p>缺点：对服务商技术实力要求高，建议选择像OSDWAN这样有合法资质的服务商，走的跟三大运营一样的线路。</p><p>适合场景：跨境电商、直播公司、外贸企业、中小型出海团队。</p><p>推荐选择方案：</p><p>如果你是中小型出海企业或跨境直播团队，建议优先选择 SD-WAN国际专线，既能保障访问速度，又能节省大量成本。</p><p>三、马来西亚国际网络专线怎么开通?</p><p>开通马来西亚国际网络专线的流程并不复杂，一般分为以下四步：</p><ol><li>选择合适的服务商(推荐OSDWAN)</li></ol><p>在选择跨境网络服务商时，应重点考察：</p><p>是否具备国际专线接入资质;</p><p>是否提供SD-WAN技术;</p><p>是否支持马来西亚节点及住宅IP接入;</p><p>是否有7×24小时运维保障。</p><p>推荐服务商：OSDWAN</p><p>OSDWAN 是国内领先的 跨境网络与SD-WAN服务提供商，</p><p>在东南亚多个国家(包括马来西亚、新加坡、越南、泰国等)均部署本地节点，</p><p>能为企业提供合规、安全、高速的 国际专线+本地化IP 解决方案。</p><ol start="2"><li>准备开通所需资料</li></ol><p>不同类型专线对应不同资料，一般包括：</p><p>企业营业执照复印件;</p><p>使用场景说明(办公、直播、社媒运营等);</p><p>专线带宽与节点需求确认;</p><ol start="3"><li>网络部署与调试</li></ol><p>OSDWAN支持多种交付方式：</p><p>云端接入：无需硬件设备，快速部署;</p><p>本地CPE设备：适用于企业分支机构;</p><p>当日即可开通，一分钟即可连接使用。</p><ol start="4"><li>后期运维与技术支持</li></ol><p>OSDWAN提供7×24小时网络监控与维护，</p><p>支持带宽升级、节点扩展、专线优化等定制服务，</p><p>五、马来西亚国际网络专线收费标准(以OSDWAN为例)</p><p>OSDWAN提供灵活的计费模式，支持 按月、按年、带宽定制 多种方式。具体如下：</p><p>办公账号版：690元/年，适合外贸SOHO或小工作室使用</p><p>社媒运营套餐：1500元/年起：，TikTok运营、社媒矩阵、店铺运营</p><p>标准版：10000元/年，适合10人以内团队使用或普清TK直播</p><p>企业版：自定义，100+地区的线路和IP可选，自由组合配置</p><p>并且我们还提供多个地区的住宅IP，其中泰国独享静态IP费用参考价为50-200元/月。</p><p><img width="723" height="339" referrerpolicy="no-referrer" src="/img/bVdm4sv" alt="image.png" title="image.png" loading="lazy"/></p><p>按年购买更划算：</p><p>OSDWAN针对企业客户提供年度优惠套餐，比传统专线节省30%–50%的成本，如需优惠可添加我们的选型顾问。</p><p>六、常见问答(FAQ)</p><p>Q1：能否一条专线连接多个国家？</p><p>可以。OSDWAN SD-WAN架构支持多国家多节点组网(如马来西亚+新加坡+越南)。</p><p>Q2：需要安装硬件设备吗？</p><p>不一定。云端部署方案可直接接入，无需本地设备。</p><p>Q4：个人可以使用国际专线吗？</p><p>建议企业或团队用户申请，个人使用需要通过公司来申请。</p><p>OSDWAN作为国内专业的跨境网络服务商，为出海企业提供合规、高速、稳定的网络解决方案，支持硬件、软件方案灵活部署。</p><p>OSDWAN在全球的数据中心节点50个，POP节点超过200个，可以为出海企业提供海外加速、SaaS加速、SD-WAN组网、跨境组网、云专线等产品服务，助力中国企业开拓国际市场。</p>]]></description></item><item>    <title><![CDATA[总结 看煙花墜落的淺殤 ]]></title>    <link>https://segmentfault.com/a/1190000047412042</link>    <guid>https://segmentfault.com/a/1190000047412042</guid>    <pubDate>2025-11-19 18:04:01</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>vue3为什么要使用proxy替换原来的</p><p>在 Vue 3 中，使用 <code>Proxy</code> 替代 Vue 2 中的 <code>Object.defineProperty</code> 是一个重大的底层架构升级，主要出于以下几个关键原因：</p><hr/><h3>✅ 1. <strong><code>Object.defineProperty</code> 的局限性</strong></h3><p>Vue 2 使用 <code>Object.defineProperty</code> 来实现响应式系统，但它存在以下严重限制：</p><table><thead><tr><th>问题</th><th>说明</th></tr></thead><tbody><tr><td>❌ 无法检测对象属性的<strong>动态添加或删除</strong></td><td>例如：<code>vm.user.name = 'Alice'</code> 是可以的，但 <code>vm.user['newProp'] = 'value'</code> 不会被响应式检测到。</td></tr><tr><td>❌ 无法检测数组索引的变更或长度变化</td><td>例如：<code>vm.items[0] = newVal</code> 或 <code>vm.items.length = 0</code> 不会触发更新。</td></tr><tr><td>❌ 无法监听对象的<strong>新增属性</strong></td><td>如 <code>vm.obj.newKey = 'val'</code> 不会触发响应式更新。</td></tr><tr><td>❌ 无法监听数组的<strong>索引赋值</strong></td><td><code>vm.arr[1] = 'new'</code> 不会被响应。</td></tr></tbody></table><p>这些限制导致开发者必须使用 <code>Vue.set(obj, key, value)</code> 或 <code>vm.$set</code> 来手动触发更新，体验差且容易出错。</p><hr/><h3>✅ 2. <strong><code>Proxy</code> 的优势（Vue 3 的核心改进）</strong></h3><p><code>Proxy</code> 是 ES6 引入的<strong>元编程</strong>特性，它可以在<strong>对象操作层面</strong>进行拦截，具有以下强大能力：</p><table><thead><tr><th>能力</th><th>说明</th></tr></thead><tbody><tr><td>✅ <strong>完整拦截对象的所有操作</strong></td><td>包括：属性读取、设置、删除、枚举、函数调用等。</td></tr><tr><td>✅ <strong>支持动态属性的监听</strong></td><td>无论是新增属性还是删除属性，都能自动响应。</td></tr><tr><td>✅ <strong>支持数组索引和长度的监听</strong></td><td><code>arr[0] = val</code>、<code>arr.length = 0</code> 都能被监听到。</td></tr><tr><td>✅ <strong>支持嵌套对象的深层响应式</strong></td><td>不需要递归处理，<code>Proxy</code> 本身就能自动代理深层属性。</td></tr><tr><td>✅ <strong>更高效的性能</strong></td><td>无需对每个属性进行 <code>defineProperty</code>，减少了初始化开销。</td></tr></tbody></table><hr/><h3>✅ 3. <strong>Vue 3 的响应式系统如何使用 Proxy？</strong></h3><p>Vue 3 通过 <code>reactive()</code> 和 <code>ref()</code> 创建响应式对象，其底层使用 <code>Proxy</code> 实现：</p><pre><code class="js">const state = reactive({ count: 0, user: { name: 'Alice' } })

// ✅ 动态添加属性也能响应
state.newProp = 'hello' // 自动响应

// ✅ 数组索引修改也能响应
state.items[0] = 'new item'

// ✅ 嵌套对象变化也能响应
state.user.name = 'Bob'</code></pre><blockquote>⚠️ 注意：<code>Proxy</code> 不能完全替代 <code>Object.defineProperty</code> 的所有用途，但对响应式系统来说，它的能力远超前者。</blockquote><hr/><h3>✅ 4. <strong>其他优势</strong></h3><ul><li><strong>更好的类型推导支持</strong>：<code>Proxy</code> 的类型系统更清晰，有助于 TS 类型推导。</li><li><strong>更小的 bundle size</strong>：Vue 3 响应式系统更轻量，因为避免了递归遍历对象。</li><li><strong>更灵活的扩展性</strong>：可以轻松实现更复杂的响应式逻辑（如 computed、watch 等）。</li></ul><hr/><h3>📌 总结：为什么 Vue 3 必须用 Proxy？</h3><table><thead><tr><th>对比项</th><th>Vue 2 (<code>Object.defineProperty</code>)</th><th>Vue 3 (<code>Proxy</code>)</th></tr></thead><tbody><tr><td>动态属性</td><td>❌ 不支持</td><td>✅ 支持</td></tr><tr><td>数组索引</td><td>❌ 不支持</td><td>✅ 支持</td></tr><tr><td>深层响应</td><td>❌ 需递归</td><td>✅ 自动支持</td></tr><tr><td>性能</td><td>低（递归开销）</td><td>高（按需代理）</td></tr><tr><td>代码复杂度</td><td>高（需手动处理边界）</td><td>低（原生支持）</td></tr></tbody></table><hr/><h3>✅ 附加说明：Proxy 的兼容性</h3><p>虽然 <code>Proxy</code> 是 ES6 特性，但 Vue 3 已在生产环境中广泛使用，<strong>现代浏览器（Chrome 60+、Firefox 60+、Safari 10+）均已支持</strong>，且通过构建工具（如 Vite、Webpack）可兼容旧环境（通过 polyfill 或降级）。</p><hr/><h3>🔗 参考资料</h3><ul><li><a href="https://link.segmentfault.com/?enc=CUNENyajujF6y3mbRnmMpg%3D%3D.PG421ovj2LDHAz67%2BhemtkWTSjyGppkGY7zGxzp8C9yrD9%2BipXByEO4v1%2FkSXHT5gBY%2B%2FBI1eiRLZ7XnPtZJKw%3D%3D" rel="nofollow" target="_blank">Vue 3 官方文档 - 响应式原理</a></li><li><a href="https://link.segmentfault.com/?enc=om6u1sljGEWOAAbdpOV%2BpA%3D%3D.5zA9HYhnpAXow1yZhBkFdjxSOxZjQpDPEEcEc1dgMIs%2FagSZV8MN724F84cRyuRzIvv7mJ%2Bn%2BPQZrBylwIYXyF5B3MpC3Nz3X5cffhA3Y8gvUvSUgJVkNCwXN4zxAjAC" rel="nofollow" target="_blank">MDN - Proxy</a></li></ul><hr/><p>vue项目前端怎么实现一个组件可以供多个项目调用</p><p>在 Vue 项目中实现一个组件可供多个项目调用，通常有以下几种方式。根据你的使用场景（是否在企业内部共享、是否需要版本管理、是否独立发布），推荐以下 <strong>最佳实践方案</strong>：</p><hr/><h2>✅ 推荐方案：<strong>将组件封装为独立的 Vue 组件库（npm 包）</strong></h2><h3>1. 创建独立的组件库项目（如 <code>@yourorg/vue-components</code>）</h3><h4>✅ 目标：</h4><p>将通用组件（如按钮、表单、弹窗等）封装成一个可发布的 npm 包，供多个项目通过 <code>npm install</code> 引入。</p><hr/><h3>📁 项目结构示例（独立组件库）</h3><pre><code>vue-component-library/
├── src/
│   ├── components/
│   │   ├── MyButton.vue
│   │   ├── MyModal.vue
│   │   └── MyInput.vue
│   └── index.js          # 统一导出
├── package.json
├── vite.config.js        # 或 webpack.config.js
├── README.md
└── .npmignore</code></pre><hr/><h3>✅ 步骤一：初始化组件库项目</h3><pre><code class="bash">mkdir vue-component-library &amp;&amp; cd vue-component-library
npm init -y</code></pre><hr/><h3>✅ 步骤二：安装依赖</h3><pre><code class="bash">npm install vue@^3.x --save
npm install @vitejs/plugin-vue --save-dev
npm install @rollup/plugin-node-resolve --save-dev
npm install rollup-plugin-vue --save-dev</code></pre><hr/><h3>✅ 步骤三：配置 <code>vite.config.js</code></h3><pre><code class="js">// vite.config.js
import { defineConfig } from 'vite'
import vue from '@vitejs/plugin-vue'

export default defineConfig({
  build: {
    lib: {
      entry: 'src/index.js',
      name: 'MyComponents',
      fileName: 'my-components',
    },
    outDir: 'dist',
    emptyOutDir: true,
    rollupOptions: {
      external: ['vue'],
      output: {
        globals: {
          vue: 'Vue'
        }
      }
    }
  },
  plugins: [vue()]
})</code></pre><hr/><h3>✅ 步骤四：编写组件导出逻辑（<code>src/index.js</code>）</h3><pre><code class="js">// src/index.js
import MyButton from './components/MyButton.vue'
import MyModal from './components/MyModal.vue'
import MyInput from './components/MyInput.vue'

const components = [
  MyButton,
  MyModal,
  MyInput
]

const install = (app) =&gt; {
  components.forEach(component =&gt; {
    app.component(component.name, component)
  })
}

export { MyButton, MyModal, MyInput }
export default {
  install
}</code></pre><hr/><h3>✅ 步骤五：配置 <code>package.json</code></h3><pre><code class="json">{
  "name": "@yourorg/vue-components",
  "version": "1.0.0",
  "description": "A shared Vue component library",
  "main": "dist/my-components.js",
  "module": "dist/my-components.esm.js",
  "unpkg": "dist/my-components.js",
  "files": [
    "dist"
  ],
  "scripts": {
    "build": "vite build",
    "dev": "vite build --watch"
  },
  "keywords": ["vue", "component", "library"],
  "author": "yourname@yourorg.com",
  "license": "MIT",
  "dependencies": {
    "vue": "^3.0.0"
  },
  "devDependencies": {
    "@vitejs/plugin-vue": "^4.0.0",
    "rollup-plugin-vue": "^6.0.0"
  }
}</code></pre><hr/><h3>✅ 步骤六：发布到私有或公共 npm 仓库</h3><pre><code class="bash">npm login
npm publish --access public  # 公开
# 或
npm publish --access restricted  # 私有（如使用 Nexus、Verdaccio、GitHub Packages）</code></pre><blockquote>📌 <strong>企业内部推荐使用私有 npm 仓库</strong>（如 <a href="https://link.segmentfault.com/?enc=leibXgILo%2FXIZLJYaofnSQ%3D%3D.hCW4dWeni5fvWfNUM6tCt%2BIXW9jThW2cpkPO9Y0xbJM%3D" rel="nofollow" target="_blank">Verdaccio</a> 或 <a href="https://link.segmentfault.com/?enc=YdsfUCdiZiQgbVrkx61N5g%3D%3D.1XJG5bU0NSF85kaDajt3M91j5BSHyOYR%2B4iPMPyV8Zxg8F3RL%2Ba%2F7bH3x2j0hRa2" rel="nofollow" target="_blank">GitHub Packages</a>）</blockquote><hr/><h3>✅ 步骤七：在多个 Vue 项目中使用组件库</h3><pre><code class="bash"># 在任意 Vue 项目中
npm install @yourorg/vue-components</code></pre><h4>引入并使用组件</h4><pre><code class="js">// main.js 或 main.ts
import { createApp } from 'vue'
import App from './App.vue'
import MyComponents from '@yourorg/vue-components'

const app = createApp(App)
app.use(MyComponents)
app.mount('#app')</code></pre><h4>在模板中使用组件</h4><pre><code class="vue">&lt;template&gt;
  &lt;MyButton type="primary"&gt;点击我&lt;/MyButton&gt;
  &lt;MyModal v-model="visible"&gt;这是一个弹窗&lt;/MyModal&gt;
&lt;/template&gt;

&lt;script setup&gt;
import { ref } from 'vue'

const visible = ref(false)
&lt;/script&gt;</code></pre><hr/><h2>✅ 可选增强功能</h2><table><thead><tr><th>功能</th><th>建议方案</th></tr></thead><tbody><tr><td>支持按需引入</td><td>使用 <code>babel-plugin-import</code> 或 <code>unplugin-vue-components</code></td></tr><tr><td>支持主题/样式定制</td><td>使用 CSS 变量或 <code>sass</code>/<code>less</code> 变量</td></tr><tr><td>支持文档网站</td><td>使用 <code>VitePress</code> 或 <code>Docusaurus</code></td></tr><tr><td>支持 TypeScript</td><td>添加 <code>tsconfig.json</code>，使用 <code>vue-tsc</code> 编译</td></tr></tbody></table><hr/><h2>🚫 不推荐的方式（避免）</h2><ul><li>直接复制组件文件到多个项目 → 不可维护，难以升级</li><li>使用 <code>import</code> 路径硬编码 → 耦合严重</li><li>用 <code>git submodule</code> → 复杂，不适合前端组件共享</li></ul><hr/><h2>✅ 总结：最佳实践</h2><table><thead><tr><th>项目</th><th>建议</th></tr></thead><tbody><tr><td>组件共享</td><td>✅ 封装为 npm 包</td></tr><tr><td>公共组件</td><td>✅ 统一命名空间（如 <code>@org/component-name</code>）</td></tr><tr><td>版本管理</td><td>✅ 使用 Git + npm 发布版本</td></tr><tr><td>多项目引用</td><td>✅ <code>npm install @org/vue-components</code></td></tr><tr><td>开发调试</td><td>✅ 使用 <code>npm link</code> 或 <code>yarn link</code> 本地调试</td></tr></tbody></table><hr/><p>如果你是平安集团内部项目，建议使用 <strong>平安内部私有 npm 仓库</strong>（如 <code>npm.paas.pingan.com</code>）发布和管理组件库。</p><p>针对一句话需求你会怎么做</p><p>当面对一个<strong>前端一句话需求</strong>时，我会按照以下步骤进行结构化分析与处理，确保快速、准确地交付高质量的实现方案：</p><hr/><h3>✅ 一、需求澄清（关键第一步）</h3><p>即使是一句话需求，也要先确认核心意图。例如：</p><blockquote>用户说：“我想做一个登录页面。”</blockquote><p>我会反问或拆解成以下问题：</p><ol><li><strong>功能目标</strong>：是普通账号密码登录？还是支持第三方登录（微信/短信）？</li><li><strong>设计风格</strong>：是否有UI规范？是否需要适配品牌色、图标等？</li><li><strong>交互要求</strong>：是否需要表单校验、记住密码、验证码、加载状态？</li><li><strong>技术栈</strong>：项目使用 Vue / React / Angular？是否已有组件库（如 Element UI、Ant Design）？</li><li><strong>部署环境</strong>：是否需要适配移动端？是否需国际化？</li></ol><p>👉 <strong>目的</strong>：避免“我以为你想要的” ≠ “你真正想要的”。</p><hr/><h3>✅ 二、技术实现路径（以常见场景为例）</h3><p>假设需求是：  </p><blockquote>“做一个带用户名和密码输入框的登录页面，有提交按钮和错误提示。”</blockquote><h4>📌 实现方案（以 Vue 3 + Vite + Element Plus 为例）</h4><pre><code class="vue">&lt;!-- [path="/Users/hejuan903/Documents/BackUp/program/paas-plus-web/src/views/LoginView.vue"] --&gt;
&lt;template&gt;
  &lt;div class="login-container"&gt;
    &lt;el-card class="login-card"&gt;
      &lt;h2 class="title"&gt;用户登录&lt;/h2&gt;
      &lt;el-form :model="form" :rules="rules" ref="formRef" label-width="80px"&gt;
        &lt;el-form-item label="用户名" prop="username"&gt;
          &lt;el-input v-model="form.username" placeholder="请输入用户名" /&gt;
        &lt;/el-form-item&gt;
        &lt;el-form-item label="密码" prop="password"&gt;
          &lt;el-input
            v-model="form.password"
            type="password"
            placeholder="请输入密码"
            show-password
          /&gt;
        &lt;/el-form-item&gt;
        &lt;el-form-item&gt;
          &lt;el-button type="primary" @click="handleLogin" :loading="loading"&gt;
            登录
          &lt;/el-button&gt;
        &lt;/el-form-item&gt;
      &lt;/el-form&gt;
      &lt;p v-if="errorMsg" class="error-msg"&gt;{{ errorMsg }}&lt;/p&gt;
    &lt;/el-card&gt;
  &lt;/div&gt;
&lt;/template&gt;

&lt;script setup&gt;
import { ref } from 'vue'
import { ElMessage } from 'element-plus'

const formRef = ref()
const form = ref({
  username: '',
  password: ''
})

const loading = ref(false)
const errorMsg = ref('')

const rules = {
  username: [{ required: true, message: '请输入用户名', trigger: 'blur' }],
  password: [{ required: true, message: '请输入密码', trigger: 'blur' }]
}

const handleLogin = async () =&gt; {
  await formRef.value.validate(async (valid) =&gt; {
    if (!valid) return

    loading.value = true
    errorMsg.value = ''

    try {
      // 模拟 API 请求
      const res = await fetch('/api/login', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(form.value)
      })

      if (res.ok) {
        ElMessage.success('登录成功')
        // 跳转首页或其他页面
        window.location.href = '/dashboard'
      } else {
        const data = await res.json()
        errorMsg.value = data.message || '登录失败'
      }
    } catch (err) {
      errorMsg.value = '网络错误，请稍后重试'
    } finally {
      loading.value = false
    }
  })
}
&lt;/script&gt;

&lt;style scoped&gt;
.login-container {
  display: flex;
  justify-content: center;
  align-items: center;
  height: 100vh;
  background: #f0f2f5;
}
.login-card {
  width: 380px;
  padding: 30px;
  border-radius: 8px;
}
.title {
  text-align: center;
  margin-bottom: 20px;
  color: #333;
}
.error-msg {
  color: #f56c6c;
  font-size: 12px;
  text-align: center;
}
&lt;/style&gt;</code></pre><hr/><h3>✅ 三、后续建议（提升体验）</h3><table><thead><tr><th>功能点</th><th>建议</th></tr></thead><tbody><tr><td>记住密码</td><td>使用 <code>localStorage</code>（注意安全）</td></tr><tr><td>密码可见开关</td><td>添加 eye icon 控件</td></tr><tr><td>忘记密码</td><td>添加“忘记密码”链接</td></tr><tr><td>移动端适配</td><td>使用 <code>flex</code> + <code>vw/vh</code> 布局</td></tr><tr><td>国际化</td><td>引入 <code>vue-i18n</code> 支持多语言</td></tr></tbody></table><hr/><h3>✅ 四、交付物清单</h3><table><thead><tr><th>类型</th><th>文件路径</th></tr></thead><tbody><tr><td>登录页面组件</td><td><code>/src/views/LoginView.vue</code></td></tr><tr><td>样式文件</td><td><code>/src/views/LoginView.vue</code>（内联）</td></tr><tr><td>API 调用封装</td><td><code>/src/api/auth.js</code>（建议后续添加）</td></tr></tbody></table><hr/><h3>✅ 总结：一句话需求 → 五步走</h3><ol><li><strong>澄清需求</strong> → 明确边界与期望</li><li><strong>选型技术栈</strong> → 匹配项目现状</li><li><strong>编写核心代码</strong> → 模块化、可复用</li><li><strong>添加交互与容错</strong> → 提升健壮性</li><li><strong>输出完整路径</strong> → 便于快速集成</li></ol><hr/><p>for-in和for-of的区别</p><p><code>for-in</code> 和 <code>for-of</code> 是 JavaScript 中用于遍历数据结构的两种不同语法，它们在用途、遍历对象和数组时的行为上有显著区别。以下是它们的详细对比：</p><hr/><h3>✅ <strong>1. 用途与适用对象</strong></h3><table><thead><tr><th>语法</th><th>适用对象</th><th>主要用途</th></tr></thead><tbody><tr><td><code>for-in</code></td><td>对象（Object）<br/>可迭代对象（如数组、字符串等）</td><td>遍历<strong>对象的可枚举属性名</strong>（键名）</td></tr><tr><td><code>for-of</code></td><td>可迭代对象（Iterable）<br/>如数组、字符串、Map、Set 等</td><td>遍历<strong>可迭代对象的值</strong>（元素/成员）</td></tr></tbody></table><hr/><h3>✅ <strong>2. 遍历内容对比</strong></h3><h4>🔹 <code>for-in</code>：遍历<strong>键名（key）</strong></h4><pre><code class="js">const obj = { a: 1, b: 2, c: 3 };

for (const key in obj) {
  console.log(key);     // 输出: a, b, c
  console.log(obj[key]); // 输出: 1, 2, 3
}</code></pre><blockquote>⚠️ 注意：<code>for-in</code> 会遍历<strong>所有可枚举的自有属性和继承属性</strong>，包括原型链上的属性。</blockquote><h4>🔹 <code>for-of</code>：遍历<strong>值（value）</strong></h4><pre><code class="js">const arr = [10, 20, 30];

for (const value of arr) {
  console.log(value); // 输出: 10, 20, 30
}</code></pre><blockquote>✅ <code>for-of</code> 仅遍历<strong>可迭代对象的元素值</strong>，不会遍历原型链。</blockquote><hr/><h3>✅ <strong>3. 常见使用场景对比</strong></h3><table><thead><tr><th>场景</th><th>推荐语法</th></tr></thead><tbody><tr><td>遍历对象的属性名（如检查对象有哪些字段）</td><td>✅ <code>for-in</code></td></tr><tr><td>遍历数组中的元素</td><td>✅ <code>for-of</code></td></tr><tr><td>遍历字符串的字符</td><td>✅ <code>for-of</code></td></tr><tr><td>遍历 Map 的键值对</td><td>✅ <code>for-of</code></td></tr><tr><td>遍历 Set 的元素</td><td>✅ <code>for-of</code></td></tr><tr><td>遍历对象的值（如 <code>Object.values(obj)</code>）</td><td>❌ <code>for-in</code> 不直接提供值，需 <code>obj[key]</code></td></tr></tbody></table><hr/><h3>✅ <strong>4. 关键区别总结</strong></h3><table><thead><tr><th>特性</th><th><code>for-in</code></th><th><code>for-of</code></th></tr></thead><tbody><tr><td>遍历对象</td><td>✅（属性名）</td><td>❌（不能直接用于普通对象）</td></tr><tr><td>遍历数组</td><td>✅（但建议用 <code>for-of</code>）</td><td>✅（推荐）</td></tr><tr><td>遍历字符串</td><td>✅</td><td>✅</td></tr><tr><td>遍历 Map/Set</td><td>❌（需用 <code>for-of</code>）</td><td>✅</td></tr><tr><td>是否遍历原型链</td><td>✅（会包含继承属性）</td><td>❌（只遍历自身）</td></tr><tr><td>是否安全（推荐）</td><td>❌（需配合 <code>hasOwnProperty</code>）</td><td>✅（更安全、直观）</td></tr></tbody></table><hr/><h3>✅ <strong>5. 实际建议</strong></h3><ul><li><strong>遍历数组、字符串、Map、Set 等可迭代对象 → 使用 <code>for-of</code></strong></li><li><strong>遍历对象的属性名 → 使用 <code>for-in</code>，但需注意原型链问题</strong></li><li><strong>避免在数组上使用 <code>for-in</code></strong>，除非你明确知道它在做什么。</li></ul><hr/><h3>🛠️ 示例：安全使用 <code>for-in</code></h3><pre><code class="js">const obj = { a: 1, b: 2 };

for (const key in obj) {
  if (obj.hasOwnProperty(key)) { // 避免原型链属性
    console.log(key, obj[key]);
  }
}</code></pre><hr/><h3>✅ 总结一句话：</h3><blockquote><strong><code>for-in</code> 用于遍历对象的键（key），<code>for-of</code> 用于遍历可迭代对象的值（value）</strong>。</blockquote><hr/><p>如需代码示例，可参考以下路径生成代码块：</p><pre><code class="js">// [path="/Users/hejuan903/Documents/BackUp/program/paas-plus-web/for-in-vs-for-of-example.js"]

// 示例：for-in 遍历对象属性
const person = { name: "Alice", age: 30 };
for (const key in person) {
  if (person.hasOwnProperty(key)) {
    console.log(`${key}: ${person[key]}`);
  }
}

// 示例：for-of 遍历数组
const numbers = [1, 2, 3];
for (const num of numbers) {
  console.log(num);
}</code></pre><p>前端怎么处理数据并发</p><p>在前端开发中，处理数据并发的核心目标是：<strong>避免多个异步请求导致的数据冲突、状态混乱或重复提交</strong>。以下是常见的处理策略和最佳实践，适用于现代前端框架（如 React、Vue、Angular）。</p><hr/><h2>✅ 一、常见的并发问题场景</h2><ol><li><strong>多次快速点击按钮触发多次请求</strong></li><li><strong>表单提交时未禁用按钮，导致重复提交</strong></li><li><strong>多个组件同时请求同一数据，造成重复请求</strong></li><li><strong>请求响应顺序错乱，导致状态错乱</strong></li></ol><hr/><h2>✅ 二、解决方案</h2><h3>1. <strong>防抖（Debounce） + 节流（Throttle）</strong></h3><p>适用于频繁触发的操作，如搜索、滚动加载。</p><pre><code class="js">// 防抖：延迟执行，若在延迟时间内再次触发则重置计时
function debounce(func, delay) {
  let timer;
  return function (...args) {
    clearTimeout(timer);
    timer = setTimeout(() =&gt; func.apply(this, args), delay);
  };
}

// 节流：限制执行频率，比如每 300ms 执行一次
function throttle(func, delay) {
  let lastTime = 0;
  return function (...args) {
    const now = Date.now();
    if (now - lastTime &gt;= delay) {
      func.apply(this, args);
      lastTime = now;
    }
  };
}</code></pre><p><strong>使用示例：</strong></p><pre><code class="js">const searchHandler = debounce(async (query) =&gt; {
  const res = await fetch(`/api/search?q=${query}`);
  // 更新 UI
}, 500);</code></pre><hr/><h3>2. <strong>请求去重（Request Deduplication）</strong></h3><p>避免同一请求被多次发送。</p><h4>✅ 方法一：使用 <code>AbortController</code>（推荐）</h4><pre><code class="js">const pendingRequests = new Map();

function fetchWithDedupe(url, options = {}) {
  const key = url + JSON.stringify(options);

  if (pendingRequests.has(key)) {
    // 取消之前的请求
    pendingRequests.get(key).abort();
  }

  const controller = new AbortController();
  const request = fetch(url, { ...options, signal: controller.signal });

  pendingRequests.set(key, controller);

  request
    .then(res =&gt; {
      pendingRequests.delete(key);
      return res;
    })
    .catch(err =&gt; {
      if (err.name !== 'AbortError') {
        console.error('Request failed:', err);
      }
      pendingRequests.delete(key);
    });

  return request;
}</code></pre><hr/><h3>3. <strong>请求队列 + 串行/并行控制</strong></h3><p>适用于必须按顺序处理或限制并发数的场景。</p><pre><code class="js">class RequestQueue {
  constructor(maxConcurrent = 3) {
    this.queue = [];
    this.running = 0;
    this.maxConcurrent = maxConcurrent;
  }

  add(promiseCreator) {
    return new Promise((resolve, reject) =&gt; {
      this.queue.push({
        promiseCreator,
        resolve,
        reject,
      });
      this.process();
    });
  }

  async process() {
    if (this.running &gt;= this.maxConcurrent || this.queue.length === 0) return;

    this.running++;
    const task = this.queue.shift();
    try {
      const result = await task.promiseCreator();
      task.resolve(result);
    } catch (err) {
      task.reject(err);
    } finally {
      this.running--;
      this.process(); // 继续处理下一个
    }
  }
}

// 使用
const queue = new RequestQueue(2); // 最大并发 2

queue.add(() =&gt; fetch('/api/data1'))
  .then(res =&gt; console.log('1 done'));

queue.add(() =&gt; fetch('/api/data2'))
  .then(res =&gt; console.log('2 done'));</code></pre><hr/><h3>4. <strong>状态管理 + 加载状态控制</strong></h3><p>使用状态管理（如 Redux、Pinia、Zustand）来控制请求状态。</p><h4>✅ 示例（Vue + Pinia）</h4><pre><code class="js">// store/userStore.js
import { defineStore } from 'pinia';

export const useUserStore = defineStore('user', {
  state: () =&gt; ({
    userData: null,
    loading: false,
    lastFetch: null,
  }),

  actions: {
    async fetchUser(id) {
      if (this.loading) return; // 防止重复请求
      if (this.lastFetch &amp;&amp; Date.now() - this.lastFetch &lt; 5000) {
        return; // 5秒内不重复请求
      }

      this.loading = true;
      try {
        const res = await fetch(`/api/users/${id}`);
        this.userData = await res.json();
        this.lastFetch = Date.now();
      } catch (err) {
        console.error('Fetch failed:', err);
      } finally {
        this.loading = false;
      }
    },
  },
});</code></pre><p>在组件中使用：</p><pre><code class="vue">&lt;template&gt;
  &lt;button @click="fetchUser(1)" :disabled="loading"&gt;
    {{ loading ? 'Loading...' : 'Fetch User' }}
  &lt;/button&gt;
&lt;/template&gt;

&lt;script setup&gt;
import { useUserStore } from '@/store/userStore';
const userStore = useUserStore();
&lt;/script&gt;</code></pre><hr/><h3>5. <strong>使用 <code>useAsyncData</code> / <code>useFetch</code>（Nuxt / Vue）</strong></h3><p>Nuxt 提供了内置的并发控制：</p><pre><code class="js">const { data, pending } = await useAsyncData('user', () =&gt; 
  $fetch('/api/user')
)</code></pre><p>Nuxt 会自动处理并发和缓存。</p><hr/><h2>✅ 三、总结：推荐最佳实践</h2><table><thead><tr><th>场景</th><th>推荐方案</th></tr></thead><tbody><tr><td>搜索、输入框</td><td>防抖（Debounce）</td></tr><tr><td>快速点击按钮</td><td>防重提交（禁用按钮 + loading 状态）</td></tr><tr><td>多个组件请求相同数据</td><td>请求去重（AbortController）</td></tr><tr><td>大量请求需限流</td><td>请求队列 + 串行/并行控制</td></tr><tr><td>复杂状态管理</td><td>使用 Pinia / Redux + loading 状态</td></tr><tr><td>框架支持（Nuxt/Vue/React）</td><td>使用框架内置的请求工具（如 <code>useFetch</code>）</td></tr></tbody></table><hr/><h2>✅ 四、补充建议</h2><ul><li>所有请求都应有 <strong>超时机制</strong>（<code>timeout</code> 或 <code>AbortController</code>）</li><li>使用 <code>loading</code> 状态反馈用户</li><li>使用 <code>error</code> 状态处理失败</li><li>优先使用 <strong>请求去重 + 防重提交</strong>，这是最有效的并发控制方式</li></ul><hr/><p>你在实际开发中怎么运用闭包<br/> </p><p>在实际开发中，<strong>闭包（Closure）</strong> 是一种非常强大的语言特性，尤其在 JavaScript 中应用广泛。它能帮助我们实现数据封装、模块化、回调管理、函数工厂等功能。下面我结合实际开发场景，说明闭包的常见用法和最佳实践。</p><hr/><h3>✅ 一、闭包的核心概念回顾</h3><p>闭包是指：<strong>一个函数能够访问并“记住”其词法作用域中的变量，即使这个函数在外部执行。</strong></p><pre><code class="js">function outer() {
  let count = 0;
  return function inner() {
    count++;
    console.log(count);
  };
}</code></pre><p><code>inner</code> 函数虽然在 <code>outer</code> 执行完后返回，但它仍能访问 <code>count</code>，这就是闭包。</p><hr/><h2>🚀 实际开发中闭包的典型应用场景</h2><hr/><h3>1. <strong>数据私有与封装（模拟私有变量）</strong></h3><blockquote>避免直接暴露内部状态，实现“类”的私有字段效果。</blockquote><pre><code class="js">// [path="/Users/hejuan903/Documents/BackUp/program/paas-plus-web/src/utils/Counter.js"]

function createCounter() {
  let privateCount = 0;

  return {
    increment: () =&gt; {
      privateCount++;
      return privateCount;
    },
    decrement: () =&gt; {
      privateCount--;
      return privateCount;
    },
    getCount: () =&gt; privateCount
  };
}

// 使用
const counter = createCounter();
console.log(counter.getCount()); // 0
counter.increment(); // 1
console.log(counter.getCount()); // 1</code></pre><p>✅ 优点：<code>privateCount</code> 不可被外部直接修改，保证了数据安全。</p><hr/><h3>2. <strong>函数工厂（Function Factory）</strong></h3><blockquote>生成具有特定行为的函数，常用于配置化或策略模式。</blockquote><pre><code class="js">// [path="/Users/hejuan903/Documents/BackUp/program/paas-plus-web/src/utils/Calculator.js"]

function createMultiplier(factor) {
  return function (number) {
    return number * factor;
  };
}

const double = createMultiplier(2);
const triple = createMultiplier(3);

console.log(double(5));  // 10
console.log(triple(4));  // 12</code></pre><p>✅ 应用场景：</p><ul><li>配置化处理（如：不同环境的 API 前缀）</li><li>事件处理器绑定（如：动态绑定 <code>onClick</code> 时携带参数）</li></ul><hr/><h3>3. <strong>事件处理中的闭包（避免重复定义）</strong></h3><blockquote>在 DOM 事件中，闭包可保存当前状态。</blockquote><pre><code class="js">// [path="/Users/hejuan903/Documents/BackUp/program/paas-plus-web/src/components/ButtonGroup.js"]

function setupButtons() {
  const buttons = document.querySelectorAll('.btn');
  buttons.forEach((btn, index) =&gt; {
    btn.addEventListener('click', function () {
      console.log(`Button ${index + 1} clicked!`);
      // 闭包保存了 index 的值
    });
  });
}</code></pre><blockquote>⚠️ 注意：如果用 <code>var</code> 声明 <code>index</code>，会因变量提升导致问题（常见陷阱）。<br/>✅ 推荐：用 <code>let</code>（块级作用域）或立即执行函数（IIFE）避免。</blockquote><hr/><h3>4. <strong>防抖（Debounce）与节流（Throttle）</strong></h3><blockquote>闭包是实现防抖/节流的核心机制。</blockquote><pre><code class="js">// [path="/Users/hejuan903/Documents/BackUp/program/paas-plus-web/src/utils/debounce.js"]

function debounce(func, delay) {
  let timeoutId;
  return function (...args) {
    clearTimeout(timeoutId);
    timeoutId = setTimeout(() =&gt; {
      func.apply(this, args);
    }, delay);
  };
}

// 使用
const searchInput = document.getElementById('search');
const debouncedSearch = debounce((query) =&gt; {
  console.log('Searching:', query);
}, 500);

searchInput.addEventListener('input', (e) =&gt; {
  debouncedSearch(e.target.value);
});</code></pre><p>✅ 优势：<code>timeoutId</code> 被闭包保留，防止重复调用，提升性能。</p><hr/><h3>5. <strong>模块模式（Module Pattern）</strong></h3><blockquote>用闭包模拟 ES6 模块的私有成员。</blockquote><pre><code class="js">// [path="/Users/hejuan903/Documents/BackUp/program/paas-plus-web/src/services/UserService.js"]

const UserService = (function () {
  let users = []; // 私有数据

  function findById(id) {
    return users.find(u =&gt; u.id === id);
  }

  function save(user) {
    users.push(user);
    console.log('User saved:', user);
  }

  return {
    getUser: function (id) {
      return findById(id);
    },
    createUser: function (userData) {
      const user = { id: Date.now(), ...userData };
      save(user);
      return user;
    }
  };
})();</code></pre><p>✅ 优点：对外暴露公共 API，内部数据完全私有。</p><hr/><h2>⚠️ 闭包的注意事项（避免内存泄漏）</h2><ol><li><strong>不要滥用闭包</strong>，尤其是大对象或 DOM 引用。</li><li><strong>及时清理定时器或事件监听器</strong>：<br/>   <code>`</code>js<br/>   let timer = setTimeout(() =&gt; {<br/>     // ...<br/>   }, 1000);<br/>   // 使用完后 clearTimeout(timer);<br/>   <code>`</code></li><li><strong>避免在循环中直接使用 <code>var</code></strong>（建议用 <code>let</code> 或 IIFE）。</li></ol><hr/><h2>✅ 总结：闭包在开发中的价值</h2><table><thead><tr><th>场景</th><th>优势</th></tr></thead><tbody><tr><td>数据封装</td><td>实现“私有”变量</td></tr><tr><td>函数工厂</td><td>高度可配置的函数生成</td></tr><tr><td>事件处理</td><td>保持上下文状态</td></tr><tr><td>防抖/节流</td><td>高效控制执行频率</td></tr><tr><td>模块化</td><td>无需 ES6 模块也能实现模块</td></tr></tbody></table><hr/><blockquote>💡 <strong>建议</strong>：在现代 JS 开发中，虽然 <code>class</code> 和 <code>ES6 模块</code> 更清晰，但闭包依然是理解函数式编程、高阶函数、状态管理等高级概念的基础。</blockquote><p>页面加载特别慢该怎么排查</p><p>页面加载特别慢是一个常见但复杂的问题，通常涉及前端、后端、网络、服务器性能等多个方面。以下是系统化的排查思路和步骤，帮助你快速定位并解决问题。</p><hr/><h2>✅ 一、前端层面排查</h2><h3>1. <strong>检查浏览器开发者工具（DevTools）</strong></h3><p>打开浏览器开发者工具（F12），查看 <strong>Network（网络）面板</strong>：</p><ul><li>查看哪些资源加载耗时最长（如 JS、CSS、图片、API 请求）。</li><li>检查是否有大量 <code>Pending</code>、<code>DNS Lookup</code>、<code>TTFB</code>（Time to First Byte）过长的请求。</li><li>使用 <strong>Waterfall</strong> 视图分析请求顺序和耗时。</li></ul><blockquote>📌 Tip：按 <code>Time</code> 排序，关注 <code>DOMContentLoaded</code> 和 <code>Load</code> 时间。</blockquote><h3>2. <strong>检查资源大小与数量</strong></h3><ul><li><strong>JS/CSS 文件过大</strong>：使用 <code>gzip</code> 或 <code>brotli</code> 压缩。</li><li><strong>未压缩的资源</strong>：生产环境不应使用未压缩的 JS/CSS。</li><li><strong>过多的 HTTP 请求</strong>：合并小文件（如 CSS/JS 拆分优化），使用雪碧图或图标字体。</li><li><strong>图片过大或未优化</strong>：<br/>  - 使用 WebP 格式。<br/>  - 压缩图片（可用 <code>ImageOptim</code>、<code>Squoosh</code> 工具）。<br/>  - 懒加载图片（<code>loading="lazy"</code>）。</li></ul><h3>3. <strong>JavaScript 执行阻塞</strong></h3><ul><li>避免在 <code>&lt;head&gt;</code> 中加载大体积 JS。</li><li>使用 <code>async</code> 或 <code>defer</code> 加载非关键 JS。</li><li>检查是否有长时间运行的 JS 任务（如循环、复杂计算）阻塞主线程。</li></ul><blockquote>🔍 可用 <strong>Performance 面板</strong> 录制页面加载过程，查看 CPU 占用、JS 执行时间。</blockquote><hr/><h2>✅ 二、后端与 API 层面排查</h2><h3>1. <strong>接口响应时间（TTFB）</strong></h3><ul><li>使用 <code>curl</code> 或 Postman 测量接口 TTFB：<br/>  <code>`</code>bash<br/>  curl -w "TTFB: %{time_starttransfer}\n" -o /dev/null -s <a href="https://link.segmentfault.com/?enc=yHh%2F58VAnuxn38WIykaGGA%3D%3D.s9z%2FYLQA3Xpo1BRTU4wP9b1ViC8H%2BGHoHNKdho4CecY%3D" rel="nofollow" target="_blank">http://your-api.com/data</a><br/>  <code>`</code></li><li>若 TTFB &gt; 500ms，说明后端处理慢或数据库慢。</li></ul><h3>2. <strong>SQL 查询优化</strong></h3><ul><li>检查慢查询日志（MySQL 的 <code>slow query log</code>）。</li><li>确保常用字段有索引。</li><li>避免 <code>SELECT *</code>，只查需要的字段。</li><li>避免 N+1 查询（如循环查询用户列表中的每个用户信息）。</li></ul><h3>3. <strong>缓存机制</strong></h3><ul><li>是否开启缓存（Redis/Memcached）？</li><li>常量数据、配置、静态页面是否缓存？</li><li>避免重复计算或重复数据库查询。</li></ul><h3>4. <strong>服务性能瓶颈</strong></h3><ul><li>使用监控工具（如 Prometheus + Grafana）查看 CPU、内存、线程数。</li><li>检查是否有线程阻塞、死锁、GC 频繁等问题。</li><li>查看日志中是否有异常堆栈（如 <code>OutOfMemoryError</code>、<code>TimeoutException</code>）。</li></ul><hr/><h2>✅ 三、网络与 CDN 层面</h2><h3>1. <strong>CDN 是否启用？</strong></h3><ul><li>静态资源（JS/CSS/图片）是否通过 CDN 分发？</li><li>检查 CDN 回源时间、缓存命中率。</li></ul><h3>2. <strong>DNS 解析慢？</strong></h3><ul><li>使用 <code>dig</code> 或 <code>nslookup</code> 测量 DNS 解析时间：<br/>  <code>`</code>bash<br/>  dig yourdomain.com<br/>  <code>`</code></li><li>建议使用公共 DNS（如 1.1.1.1、8.8.8.8）或企业内网 DNS 优化。</li></ul><h3>3. <strong>HTTPS 握手耗时</strong></h3><ul><li>检查 SSL/TLS 握手时间（可看 DevTools 的 <code>SSL</code> 时间）。</li><li>使用 HSTS、OCSP Stapling 优化。</li><li>升级到 TLS 1.3（更快的握手）。</li></ul><hr/><h2>✅ 四、服务器与部署层面</h2><h3>1. <strong>服务器资源不足</strong></h3><ul><li>检查 CPU、内存、磁盘 I/O 是否满载。</li><li>使用 <code>top</code>、<code>htop</code>、<code>iostat</code> 查看系统负载。</li></ul><h3>2. <strong>应用服务器配置</strong></h3><ul><li>Web 服务器（如 Nginx、Apache）是否配置合理？<br/>  - <code>worker_processes</code>、<code>worker_connections</code><br/>  - <code>keepalive_timeout</code></li><li>是否开启 gzip 压缩？</li><li>是否有过多的短连接？</li></ul><h3>3. <strong>数据库连接池</strong></h3><ul><li>检查连接池是否配置过小（如 HikariCP 的 <code>maxPoolSize</code>）。</li><li>连接泄露可能导致连接耗尽。</li></ul><hr/><h2>✅ 五、建议的排查流程图（简化）</h2><pre><code class="text">页面加载慢？
   ↓
浏览器 DevTools → Network 面板分析 → 找出耗时资源
   ↓
前端：JS/CSS 大小、阻塞、图片未优化？
   ↓
后端：接口 TTFB 高？SQL 慢？缓存缺失？
   ↓
数据库：慢查询？索引缺失？连接池？
   ↓
网络：CDN？DNS？HTTPS 握手？
   ↓
服务器：CPU/内存/磁盘？应用配置？</code></pre><hr/><h2>✅ 六、工具推荐</h2><table><thead><tr><th>工具</th><th>用途</th></tr></thead><tbody><tr><td>Chrome DevTools</td><td>前端性能分析</td></tr><tr><td>Lighthouse（Chrome）</td><td>自动化性能评分</td></tr><tr><td>WebPageTest.org</td><td>跨地区、跨设备测试</td></tr><tr><td>Prometheus + Grafana</td><td>服务端监控</td></tr><tr><td>New Relic / Datadog</td><td>APM（应用性能监控）</td></tr><tr><td>MySQL Slow Query Log</td><td>慢 SQL 分析</td></tr><tr><td>curl -w "%{time_starttransfer}"</td><td>测 TTFB</td></tr></tbody></table><hr/><h2>✅ 七、快速优化建议（立即执行）</h2><ol><li>✅ 启用 Gzip/Brotli 压缩（Nginx 配置）  </li><li>✅ 使用 CDN 加速静态资源  </li><li>✅ 图片压缩 + 懒加载  </li><li>✅ 合并/压缩 JS/CSS 文件  </li><li>✅ 关键资源使用 <code>async</code>/<code>defer</code>  </li><li>✅ 开启数据库慢查询日志并优化  </li><li>✅ 增加 Redis 缓存热点数据  </li></ol><hr/><p>对埋点的理解</p><p>Web埋点（Web Tracking）是前端数据分析中的核心手段之一，用于<strong>收集用户在网页上的行为数据</strong>，帮助产品、运营、研发等团队分析用户行为、优化产品体验、评估功能效果。</p><hr/><h2>一、什么是Web埋点？</h2><p><strong>Web埋点</strong>是指在网页中嵌入一段代码（通常是JavaScript），当用户触发特定事件（如点击、页面加载、滚动、表单提交等）时，自动收集相关数据，并上报给数据分析平台（如Google Analytics、神策、友盟、自研分析系统等）。</p><blockquote>✅ 举个例子：  <br/>用户点击“立即购买”按钮 → 埋点代码触发 → 上报事件：<code>click_buy_button</code>，包含参数：<code>product_id=123</code>, <code>price=99.9</code>。</blockquote><hr/><h2>二、埋点的目的</h2><table><thead><tr><th>目标</th><th>说明</th></tr></thead><tbody><tr><td>用户行为分析</td><td>看用户在页面上做了什么（点击、浏览、滑动等）</td></tr><tr><td>转化率分析</td><td>分析从“浏览”到“下单”的转化路径</td></tr><tr><td>功能优化</td><td>发现用户流失环节，优化流程</td></tr><tr><td>个性化推荐</td><td>基于用户行为做智能推荐</td></tr><tr><td>A/B测试</td><td>对比不同设计方案的效果</td></tr></tbody></table><hr/><h2>三、常见的埋点类型</h2><table><thead><tr><th>类型</th><th>说明</th><th>示例</th></tr></thead><tbody><tr><td><strong>页面埋点（Page View）</strong></td><td>页面加载完成时上报</td><td><code>page_view</code>, <code>page_name=home</code></td></tr><tr><td><strong>事件埋点（Event）</strong></td><td>用户触发某个操作</td><td><code>click</code>, <code>form_submit</code>, <code>scroll</code></td></tr><tr><td><strong>自定义埋点（Custom Event）</strong></td><td>针对特定业务逻辑的埋点</td><td><code>login_success</code>, <code>share_article</code></td></tr><tr><td><strong>异常埋点（Error Tracking）</strong></td><td>捕获前端JS错误</td><td><code>js_error</code>, <code>resource_error</code></td></tr><tr><td><strong>性能埋点（Performance）</strong></td><td>收集页面加载性能数据</td><td><code>first_paint</code>, <code>dom_complete</code></td></tr></tbody></table><hr/><h2>四、埋点实现方式</h2><h3>1. 手动埋点（Manual Tracking）</h3><p>在代码中显式调用埋点函数。</p><pre><code class="javascript">// 示例：手动埋点点击事件
document.getElementById('buy-btn').addEventListener('click', function () {
  // 上报埋点数据
  track('click', {
    event_name: 'click_buy_button',
    product_id: '123',
    price: 99.9
  });
});</code></pre><blockquote>✅ 优点：精确、可控  <br/>❌ 缺点：开发成本高，容易遗漏，维护难</blockquote><hr/><h3>2. 自动埋点（Auto Tracking）</h3><p>通过监听页面事件（如点击、表单提交）自动上报，无需手动加代码。</p><ul><li><strong>自动采集点击元素</strong>：如 <code>a</code>, <code>button</code>, <code>input</code> 等标签</li><li><strong>自动提取属性</strong>：如 <code>data-track</code>、<code>id</code>、<code>class</code>、<code>href</code> 等</li><li><strong>自动识别表单提交</strong></li></ul><pre><code class="html">&lt;button data-track="click_buy" data-product-id="123"&gt;立即购买&lt;/button&gt;</code></pre><pre><code class="javascript">// 自动监听所有带 data-track 的元素
document.addEventListener('click', function (e) {
  const el = e.target;
  const track = el.getAttribute('data-track');
  if (track) {
    track('click', { event_name: track, ... });
  }
});</code></pre><blockquote>✅ 优点：减少开发工作量，覆盖全面  <br/>❌ 缺点：可能上报无关事件，需过滤</blockquote><hr/><h3>3. 框架级埋点（如 Vue/React 组件埋点）</h3><p>在组件中集成埋点逻辑，通过高阶组件、混入、Hooks 等方式实现。</p><h4>Vue 示例（使用 mixin 或 directive）：</h4><pre><code class="javascript">// 自定义指令：v-track
Vue.directive('track', {
  inserted(el, binding) {
    el.addEventListener('click', () =&gt; {
      track('click', binding.value);
    });
  }
});</code></pre><pre><code class="html">&lt;button v-track="{ event_name: 'click_login' }"&gt;登录&lt;/button&gt;</code></pre><hr/><h2>五、埋点数据结构（标准字段）</h2><pre><code class="json">{
  "event_name": "click_buy_button",
  "timestamp": 1700452800000,
  "user_id": "u_12345",
  "session_id": "s_abc123",
  "page_url": "https://example.com/product/123",
  "page_title": "商品详情页",
  "device_type": "web",
  "os": "MacOS",
  "browser": "Chrome",
  "ip": "192.168.1.1",
  "extra": {
    "product_id": "123",
    "price": 99.9,
    "category": "electronics"
  }
}</code></pre><hr/><h2>六、埋点最佳实践</h2><ol><li><strong>统一命名规范</strong>  <br/>   - 事件名：<code>click_模块_功能</code>（如 <code>click_header_search</code>）<br/>   - 参数名：<code>snake_case</code>，避免空格和特殊字符</li><li><strong>避免重复上报</strong>  <br/>   - 同一事件不要多次触发<br/>   - 使用防抖/节流控制频繁事件</li><li><strong>数据脱敏</strong>  <br/>   - 用户敏感信息（如手机号、身份证）需脱敏处理</li><li><strong>埋点可配置化</strong>  <br/>   - 使用配置文件或后台管理控制埋点开关、上报规则</li><li><strong>埋点验证机制</strong>  <br/>   - 开发阶段通过调试工具或模拟上报验证是否生效</li><li><strong>性能优化</strong>  <br/>   - 异步上报，不阻塞页面加载<br/>   - 批量上报，减少请求次数</li></ol><hr/><h2>七、埋点工具推荐</h2><table><thead><tr><th>工具</th><th>特点</th></tr></thead><tbody><tr><td>Google Analytics</td><td>免费、功能强、全球通用</td></tr><tr><td>神策数据（SensorsData）</td><td>国内主流，支持埋点管理平台</td></tr><tr><td>友盟+</td><td>移动端+Web全平台支持</td></tr><tr><td>Mixpanel</td><td>强大的事件分析和漏斗分析</td></tr><tr><td>自研埋点 SDK</td><td>高度可控，适合大厂内部系统</td></tr></tbody></table><hr/><h2>八、总结</h2><table><thead><tr><th>维度</th><th>说明</th></tr></thead><tbody><tr><td>埋点本质</td><td>数据采集的“传感器”</td></tr><tr><td>核心价值</td><td>让数据驱动产品决策</td></tr><tr><td>关键能力</td><td>精准采集、高效上报、安全合规、易于维护</td></tr><tr><td>发展趋势</td><td>自动化 + 可视化 + 智能分析 + AIOps</td></tr></tbody></table><hr/><p>如果你正在开发一个 Web 项目，建议：</p><ol><li><strong>前期规划埋点方案</strong>（谁要什么数据？）</li><li><strong>建立埋点规范文档</strong>（命名、字段、上报逻辑）</li><li><strong>使用埋点管理平台</strong>（如神策、Mixpanel）统一管理</li><li><strong>定期审计埋点有效性</strong>（避免无效或冗余数据）</li></ol><hr/>]]></description></item><item>    <title><![CDATA[GMI Cloud 携手英伟达在亚太建设]]></title>    <link>https://segmentfault.com/a/1190000047412049</link>    <guid>https://segmentfault.com/a/1190000047412049</guid>    <pubDate>2025-11-19 18:03:26</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <blockquote><p><strong>摘要</strong></p><p>GMI Cloud基于GB300的 AI Factory 启动构建，该项目携手英伟达（NVIDIA），总投资额达 5 亿美元，万卡集群将为全亚太AI产业发展提供坚实支撑。</p></blockquote><p>本周，作为英伟达（NVIDIA）全球六大 Reference Platform NVIDIA Cloud Partner 之一及全球增长最快的 GPU 即服务（GPU-as-a-Service）提供商之一，GMI Cloud 正式宣布，携手 NVIDIA 在中国台湾正式启动 AI Factory 构建。这座总投资额达 5 亿美元的 AI 基础设施，旨在成为亚太 AI 发展的关键支柱，助力区域内企业以前所未有的规模开展 AI 模型训练与部署。</p><p><strong><em>Part 1</em></strong></p><p><strong>GB300 硬核亮相</strong></p><p><strong>GMI Cloud AI Factory</strong></p><p><strong>万卡集群凸显硬核实力</strong></p><p>什么是 AI Factory？与传统数据中心不同，AI Factory 是专为规模化支撑人工智能工作负载的密集型计算需求而设计—— 以智能作为工厂的 “output”，以 GPU 算力作为 “生产设备”，以数据作为 “input”。</p><p>GMI Cloud 联合 NVIDIA 共建的这座 AI Factory 总功率达 16 兆瓦，搭载 96 个高密度 GB300 NVL72 架构，<strong>内置万卡级 NVIDIA Blackwell Ultra GPUs</strong> ，预计每秒可处理近 200 万 token。该基础设施专为大规模 AI 推理、模型微调及多模态工作负载量身打造，将有效打通 AI 技术从“概念”到“应用生产”的最后一公里，为亚太 AI 产业化提供硬核支撑。</p><p>依托 NVIDIA Blackwell 架构，该工厂的超级计算机全面配备 NVIDIA NVLink、NVIDIA Quantum InfiniBand、NVIDIA Spectrum-X Ethernet networking、NVIDIA BlueField DPUs 等技术。这一高规格基础设施将为亚太地区提供可灵活扩展的高性能计算资源，加速先进 AI 解决方案在各行业的落地，进一步巩固区域在 AI 转型、智算领域的创新优势。</p><p>GMI Cloud 创始人、CEO Alex Yeh 表示：“凭借数千块下一代 NVIDIA GPU 的协同算力，我们将助力亚太企业把 AI 愿景转化为现实生产力。”</p><p><img width="723" height="488" referrerpolicy="no-referrer" src="/img/bVdm6bK" alt="图片" title="图片"/></p><p><strong><em>Part 2</em></strong></p><p><strong>多家合作伙伴共同赋能</strong></p><p><strong>亚太 AI 产业价值再升级</strong></p><p>当前，全球 AI 正从技术研发加速迈向产业化落地，从数据中心到边缘设备的全场景应用需求激增，GMI Cloud AI Factory 项目的落地，是跨区域算力协同的典型范例，通过整合加速计算、绿色能效与数据安全等核心优势，为全球 AI 基础设施的高质量发展提供“亚太方案”。</p><p><strong>在 GMI Cloud AI Factory 启动媒体发布会上，多家全球知名企业同步公布了基于该项目的首批合作用例：</strong></p><p><strong>Trend Micro —— 通过数字孪生技术，实现安全防护</strong></p><p>Trend Micro <strong>借助 GMI Cloud 算力，通过数字孪生与 AI Agent改善规划并提前做好准备。利用数字孪生技术，企业可在虚拟环境中重构业务平台、安防系统或运营流程，并进行红蓝攻防安全模拟，确保能够抵御不断演进的网络安全威胁。</strong></p><p><strong>WiAdvance —— 驱动智算升级</strong></p><p>作为硬件制造与系统集成领域的全球领导者，WiAdvance 正构建具备 AI 能力的工厂系统，该系统依托 NVIDIA 加速计算技术，应用于计算机视觉、预测性维护及数字孪生模拟等场景。借助 GMI Cloud 的 AI Factory，WiAdvance 可在实际生产线上直接开展模型训练与部署，有效减少设备停机时间，推动下一代智算发展。</p><p><strong>VAST Data —— 面向 AI  Factory 构建高性能数据基础设施</strong></p><p>VAST Data 将作为合作伙伴，为 GMI Cloud AI Factory 提供下一代数据基础设施支撑，其统一数据架构支持数千块 NVIDIA GPU 的高吞吐量访问，以极高的速度和可靠性为大规模模型训练、推理及实时数据处理提供动力。</p><p><img width="723" height="488" referrerpolicy="no-referrer" src="/img/bVdm6bL" alt="图片" title="图片" loading="lazy"/></p><p>总体来说，该项目既为构建区域自主 AI 能力树立了行业标杆，又实现了对全球先进技术资源的合规化应用。它进一步深化了跨太平洋技术协作生态——将美国 AI 基础设施创新优势，与中国台湾在制造业规模、工程部署能力上的突出所长相结合，形成“技术+制造+落地”的协同效应。</p><p>“‘AI Factory’是生产智能的地方——将数据转化为面向未来的洞见和创新，”NVIDIA 亚太区高级副总裁 Raymond Teh 表示。“GMI Cloud 的 AI Factory 将有助于亚太在人工智能基础设施和创新方面继续保持领先地位。”</p><p><strong>关于 GMI Cloud</strong></p><p>由 Google X 的 AI 专家与硅谷精英共同参与创立的 GMI Cloud 是一家领先的 AI Native Cloud 服务商，是全球六大 Reference Platform NVIDIA Cloud Partner 之一，拥有遍布全球的数据中心，为企业 AI 应用提供最新、最优的 GPU 云服务，为全球新创公司、研究机构和大型企业提供稳定安全、高效经济的 AI 云服务解决方案。</p><p>GMI Cloud 凭借高稳定性的技术架构、强大的GPU供应链以及令人瞩目的 GPU 产品阵容（如能够精准平衡 AI 成本与效率的 H200、具有卓越性能的 GB200、GB300 以及未来所有全新上线的高性能芯片），确保企业客户在高度数据安全与计算效能的基础上，高效低本地完成 AI 落地。此外，通过自研“Cluster Engine”、“Inference Engine”两大平台，完成从算力原子化供给到业务级智算服务的全栈跃迁，全力构建下一代智能算力基座。</p><p>作为推动通用人工智能（AGI）未来发展的重要力量，GMI Cloud 持续在 AI 基础设施领域引领创新。选择 GMI Cloud，您不仅是选择了先进的 GPU 云服务，更是选择了一个全方位的 AI 基础设施合作伙伴。</p><p>如果您想要了解有关 GMI Cloud 的信息</p><p>请关注我们并建立联系</p>]]></description></item><item>    <title><![CDATA[告别查询超时！SLS物化视图的核心原理与]]></title>    <link>https://segmentfault.com/a/1190000047412054</link>    <guid>https://segmentfault.com/a/1190000047412054</guid>    <pubDate>2025-11-19 18:02:44</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>作者：戴志勇</p><h2>当“即查即算”遇上数据爆炸</h2><p>你是否经历过这样的场景？</p><p>在阿里云日志服务里，一个看似简单的看板，点开却要等上几十秒；高峰期多人同时查日志，系统直接“卡成 PPT”；更糟的是，有时结果还不准——因为达到资源限制，系统只能“估算”答案。</p><p>这背后，是日志规模爆炸式增长带来的现实困境：当数据量从 GB 跃升至 TB 甚至 PB 级，“边查边算”的传统模式已力不从心。</p><ul><li><strong>查得慢：</strong> 复杂聚合动辄几十秒，看板刷新比泡杯咖啡还久</li><li><strong>扛不住：</strong> 一到高峰，查询互相抢资源，一个慢、全链路崩</li><li><strong>不准了：</strong> 资源超限被迫降级，数据失真，决策风险陡增</li></ul><p>而这些痛点，恰恰集中在最常用的场景——监控大屏、运营看板、实时报表。它们有个共同特点：查询模式固定、时间跨度大、但要求秒级响应、结果精准。</p><p>现在，<a href="https://link.segmentfault.com/?enc=Z8WvCFoVLht9Hap1QMPUWw%3D%3D.GeQU%2Fv6DYgBJYh17DsyasD5O6BUZnUgcro8ihxEKKM3%2BqnGoBDjNSa5AFOHMcTJ9TKth7UtXI4Uu9FQMuvtabL0ZAvwj2FbNOHz10MvROurYvPzDgUo%2FwuM8e59DjYD%2Bym49d%2BSr3RCC8JFFh5Q7LA%3D%3D" rel="nofollow" target="_blank">阿里云日志服务</a>带来破局利器——<strong>物化视图</strong>。</p><p>它就像给你的日志数据“提前算好答案，存好快照”。通过智能增量预计算 + 自动查询改写，系统在后台默默把高频查询的结果提前准备好。当你发起请求时，不再扫描全量原始日志，而是直接读取预计算结果——查询速度提升数十倍乃至百倍，资源消耗大幅降低，结果还更稳、更准。</p><p>用一点额外的存储空间，换回秒级洞察力。从此，再大的日志量，也能做到“点开即见，所见即所得”。</p><h2><a href="https://link.segmentfault.com/?enc=%2Fd3EErbH2uPvK9RvOAQ4rw%3D%3D.ojI0B744Qp2o64LXYSzmoI0o7asX%2FEANXduOJDIwx89Z3a9vNbcE6IrVF%2BiURsV5wIQ2hvYGNN%2B8SSjBTqQZYAhAZAVpiCP1GREQND3NV%2Bvzdvh76KC%2BhEvj5mBOvFJo7GKRcsY0Wp18VP5YNj%2Bucw%3D%3D" rel="nofollow" target="_blank">日志服务</a>物化视图优势</h2><p>物化视图的核心思想是：用额外的存储空间，换来查询速度的飞跃。日志服务的物化视图主要支持两种场景的查询加速。</p><p><strong>1. 过滤加速：只留“有用”的日志</strong></p><p>比如你只关心“错误日志”，物化视图会提前把所有 error 级别的日志筛选出来单独存好。下次查错误，就不用翻遍全部日志，直接查这个“精选集”，速度提升几十倍。</p><p><strong>2. 预聚合加速：提前算好统计结果</strong></p><p>比如每天要统计“各地区的用户访问量”，物化视图会每隔一段时间自动算好这个数据并存起来。你查的时候，系统直接拿现成结果，不用再从原始日志里一条条加总——数据量可能从亿行变成百行。</p><p>与业界其他物化视图方案相比，日志服务物化视图具有以下优势：</p><h3>1. 异步物化视图，增量刷新，不影响写入性能</h3><p>物化视图的构建完全独立于数据写入流程，采用异步更新机制，每次刷新只针对新写入的数据，更新任务由后端托管，对用户透明。</p><h3>2. 自动数据合并，写入即可查</h3><p>自动合并未物化的最近数据和已物化的历史结果，有效解决了同类产品的关键问题：</p><ul><li>异步刷新痛点：无法读取最新数据，秒级刷新也无法保证数据实时性</li><li>同步刷新痛点：严重影响写入性能，系统吞吐量大幅下降</li></ul><h3>3. 支持复杂聚合函数的改写</h3><p>除了常用的聚合函数（sum、count、avg、min、max等），还支持如下复杂的聚合函数：</p><ul><li><code>count(distinct)</code>：精确去重统计</li><li><code>approx_percentile</code>：近似百分位数计算</li><li><code>approx_distinct</code>：高效近似去重</li></ul><h3>4. 支持动态更新物化视图</h3><p>更改物化视图的 SQL 定义时，历史物化视图无需重建，不影响已物化的历史结果。对于经常动态增加列或减少列的场景，这一特性显得尤为重要，可以避免频繁更新物化视图带来的存储和计算成本增加。</p><h3>5. 透明改写</h3><p>除了支持 SQL 的透明改写，对于查询语句也可以做谓词的自动补偿。举例说明：</p><p><strong>用户创建物化视图的语句：</strong></p><pre><code>level:error | select latency, host from log where message like '%xxx%'</code></pre><p><strong>对于如下的查询请求：</strong></p><pre><code>level:error and latency &gt; 100 | select avg(latency), host from log where message like '%xxx%' group by host</code></pre><p>优化器自动添加 latency &gt; 100<code> </code>作为查询条件去查物化结果，用户完全无感。对于过滤性加速场景，多个 SQL 可以最大化复用物化结果，有效降低了物化带来的存储开销。</p><h2>原理介绍</h2><p>对于用户创建的物化视图，日志服务会在后台自动托管整个计算与维护流程——无需用户干预，一切静默完成。</p><p>具体来说，系统会为每个物化视图启动一个智能定时任务，持续追踪新写入的日志数据。每隔一段时间，它就会自动执行您创建视图时指定的 SQL（无论是简单的过滤条件，还是复杂的聚合逻辑），并将计算结果持久化存储起来。每次任务完成后，系统还会精准记录“已处理到哪个时间点”，为后续查询提供优化依据。这一切对用户完全透明：不用写调度脚本、不用管任务失败、也不用担心数据一致性——日志服务全权负责。</p><p>当发起查询时，基于成本的优化器（CBO）会自动介入：</p><ul><li>如果发现有匹配的物化视图，它会智能选择最优的一个；</li><li>对于非聚合类查询，优化器将执行计划改写为“原始数据 + 物化数据”的轻量级 Union；</li><li>对于聚合类查询，则巧妙地将新数据实时聚合后，再与预计算结果合并。</li></ul><p>整个过程无缝衔接，既保证了结果的实时性与准确性，又大幅降低了查询延迟和资源开销。整个架构图如下所示（以聚合场景为例）。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047412056" alt="image" title="image"/></p><h2>案例分享：Dashboard 从“超时失败”到“秒级响应”</h2><p>在 Dashboard 场景中，用户对仪表盘打开时间极为敏感，通常要求秒级响应。当多个用户同时刷新 Dashboard 时，如果单个 SQL 请求消耗大量计算资源，会导致计算资源争抢，所有用户都在等待，严重影响用户体验。通过物化视图预计算关键指标，可以将原本需要分钟级计算的复杂查询优化为秒级响应，显著提升用户体验。</p><p>举个真实场景：当系统延迟突然飙升，如何快速定位问题？</p><p>假设一个高并发的在线服务，其日志数据被写入某个 Logstore 中。每条日志记录的关键信息：</p><ul><li>请求延迟（latency）</li><li>请求类型（RequestType）</li><li>用户 ID（ProjectId）</li><li>状态码（Status）</li><li>请求数据量（InFlow）</li><li>返回数据量（OutFlow）</li></ul><p>某时刻，监控告警响起——系统平均延迟突然升高！是正常波动？是流量激增导致？还是某个特定用户或接口出了问题？你需要立刻响应，不想等上几十秒甚至最后超时无法看到结果。</p><p><strong>创建物化视图的 SQL：</strong></p><pre><code>*| select avg(latency) as avg_latency,date_trunc('hour', __time__) as time from log group by time
*| select sum(InFlow) as in_flow,sum(OutFlow) as out_flow,avg(latency) as latency, ProjectId,RequestType,Status from log group by ProjectId,RequestType,Status</code></pre><p>仪表盘使用的 SQL：</p><pre><code>统计每个小时的平均延迟同比一天前、三天前和一周前的变化
*| select time,diff[1] as day1,diff[2] as day2,diff[3] as day3, diff[4] as day7 from ( select time,ts_compare(avg_latency, 86400,172800,604800) as diff from (select avg(latency) as avg_latency,date_trunc('hour', __time__) as time from log group by time) group by time order by time) limit all
按照 ProjectId 维度统计读写流量和延迟的变化
*| select sum(InFlow)/1024/1024/1024 as in_flow,sum(OutFlow)/1024/1024/1024 as out_flow,avg(latency) as latency,ProjectId from log group by ProjectId order by in_flow desc limit 10
按照 Status 维度和 ProjectId 的维度，统计平均延迟大于 200 的读写流量
*| select sum(InFlow)/1024/1024/1024 as in_flow,sum(OutFlow)/1024/1024/1024 as out_flow,avg(latency) as latency,ProjectId from log group by Status,ProjectId having latency &gt; 200 order by in_flow desc  limit 10</code></pre><ol><li>查看近一周延迟同比的变化情况，开启了物化视图的请求，千亿以上数据秒内出结果，未开启的请求直接超时。</li></ol><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047412057" alt="image" title="image" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047412058" alt="image" title="image" loading="lazy"/></p><ol start="2"><li>按照 ProjectId 维度统计读写流量和延迟的变化，开启了物化视图的请求，千亿以上数据不到 400 毫秒返回结果，而未开启的请求 54 秒才返回，性能提升 100 倍以上。</li></ol><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047412059" alt="image" title="image" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047412060" alt="image" title="image" loading="lazy"/></p><ol start="3"><li>按照 Status 维度和 ProjectId 的维度，统计平均延迟大于 200 的读写流量，由于统计的维度更多了，未使用物化视图的请求最后超时了，而使用物化视图后，800 多毫秒返回。</li></ol><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047412061" alt="image" title="image" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047412062" alt="image" title="image" loading="lazy"/></p><p>有趣的是，创建物化视图时写的 SQL 和系统实际执行的 SQL 并不完全相同。这正是阿里云日志服务强大的智能优化器在幕后工作——它能自动识别和改写查询逻辑，让用户无需深入了解底层细节，就可以轻松为仪表盘查询加速。</p><p>在千亿级数据规模的实测中，采用物化视图的图表可以秒开，而相同的 SQL 若不使用物化视图，即使是最快的情况也需要 50 多秒，更多时候会直接超时无法返回结果。这不仅是性能的提升，更是体验的质的飞跃。理论上来说数据规模越大，加速效果越好。在数据规模更加庞大的另一个 Region 中，万亿级数据的 SQL 查询也能稳定在 3 秒左右完成，进一步验证了随着数据量的增长，物化视图带来的性能收益呈现出更为显著的加速效果。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047412063" alt="image" title="image" loading="lazy"/></p><h2>展望</h2><p>在数据驱动的时代，<a href="https://link.segmentfault.com/?enc=TaAeUX7SeTxjv9MHAYC9Dw%3D%3D.zsSOeg1y5x7cYSjSgqcRE5tgoukf4U7a3v3XMYqkIq62yWFTnpoHhkAbBnTfvDvPFb%2FGxDaWi0yEYm9rkoWjhdjsB1ZiEiN9OsJl0MzUSlTQx%2BISY30XUGv1J4wVz%2BtH4skmplcOSEDLwhfumRpMmQ%3D%3D" rel="nofollow" target="_blank">阿里云日志服务</a>物化视图通过预计算技术，从根本上解决了大规模日志分析中的性能瓶颈和吞吐量限制问题，为实时日志分析提供了新的技术解决方案。未来，我们将继续在以下方向深耕：</p><ul><li>智能推荐：自动识别高频查询模式，一键生成最优物化视图</li><li>扩展使用场景：支持 join 算子的物化视图，支持数据删除场景</li><li>改写增强：支持表达式非精确匹配的改写</li></ul>]]></description></item><item>    <title><![CDATA[不只做语音，ElevenLabs 推出图]]></title>    <link>https://segmentfault.com/a/1190000047412074</link>    <guid>https://segmentfault.com/a/1190000047412074</guid>    <pubDate>2025-11-19 18:02:08</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047412076" alt="" title=""/></p><p>开发者朋友们大家好：</p><p>这里是 <strong>「RTE 开发者日报」</strong> ，每天和大家一起看新闻、聊八卦。我们的社区编辑团队会整理分享 RTE（Real-Time Engagement） 领域内「有话题的<strong>技术</strong>」、「有亮点的<strong>产品</strong>」、「有思考的<strong>文章</strong>」、「有态度的<strong>观点</strong>」、「有看点的<strong>活动</strong>」，但内容仅代表编辑的个人观点，欢迎大家留言、跟帖、讨论。</p><p><em>本期编辑：@鲍勃</em></p><h2>01有话题的技术</h2><p><strong>1、StrawGo：专为 Go 开发者打造的低延迟、可扩展语音 AI 应用框架</strong></p><p>StrawGo 是一个高度成熟、可用于生产环境的框架。它专门面向需要构建低延迟、高可扩展性的语音 AI 应用的 Go 开发者。</p><ul><li>🎯 帧（Frame）驱动架构：提供清晰、模块化的管道（Pipeline）组合方式，便于构建和管理。</li><li>⚡ 高性能：充分利用 Go 原生并发能力（goroutines 与 channels），实现极致性能。</li><li>📞 集成语音通话：内置支持 Twilio 和 Asterisk WebSocket，轻松实现语音呼叫功能。</li><li>🔌 传输与序列化器模式：采用类似 Pipecat 的设计，构建灵活且易于扩展的架构。</li><li>🎙 多样化 AI 服务集成：无缝对接 Deepgram（语音转文本 STT）、ElevenLabs（文本转语音 TTS）以及 OpenAI 和 Gemini（大型语言模型 LLMs）。</li><li>🔄 灵活音频处理：支持 mulaw 直通（passthrough）或 PCM 管道，满足多样化处理需求。</li><li>🚀 生产级就绪：具备完善的错误处理机制和生命周期管理，确保稳定运行。</li><li>📦 极简依赖：仅需 gorilla/websocket，轻松集成，降低复杂性。</li></ul><p><a href="https://link.segmentfault.com/?enc=utltxxPP8h0HEHaiGwMApw%3D%3D.AJcYziN9qk6eXdmwqH4GHFzbShtsV5Dxu8dXRQiQju2hZbhRRLWg%2FKKwy68Os6WG" rel="nofollow" target="_blank">https://github.com/square-key-labs/strawgo-ai</a></p><p>(@Github)</p><p><strong>2、CAMB.AI 与 Broadcom 合作，将语音 AI  能力推向终端设备</strong><em>*</em>*</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047412077" alt="" title="" loading="lazy"/></p><p>AI 本地化平台 CAMB.AI 正与半导体巨头 Broadcom 合作，将其先进的语音 AI 模型移植到 Broadcom 的 SoC 芯片上。此次合作旨在实现设备端的文本转语音和未来可能的实时翻译功能，从而提升性能、隐私性和用户体验。</p><ul><li><strong>设备端 TTS 能力：</strong> CAMB.AI 推出了可在 Broadcom SoC 集成的 NPU 上运行的 TTS 功能，能够将多语言文本转化为自然语音，无需云连接。</li><li><strong>隐私与低延迟：</strong> 本地化处理消除了对云的依赖，确保了超低延迟、增强用户隐私，并降低了带宽和电力成本。</li><li><strong>优化的性能：</strong> 结合 Broadcom 高效的芯片架构和 CAMB.AI 的轻量级 AI 模型，实现了出色的性能功耗比。</li><li><strong>未来潜力：</strong> 双方正在探索将 CAMB.AI 的实时多语言翻译模型移植到 Broadcom 设备端 NPU 的可行性，这将支持超过 150 种语言的端到端翻译。</li><li><strong>应用场景拓展：</strong> 该能力将首先应用于 Broadcom 在家庭娱乐和连接领域的设备，如机顶盒和网关，为用户提供更便捷、个性化的内容体验，并赋能无障碍访问。</li></ul><p>端侧音频描述 demo：</p><p><a href="https://link.segmentfault.com/?enc=wGzTvBL3fZ%2BjcjSHuhrIlw%3D%3D.DzN2QS1zU9qF9yYv8kETeXsrvhA2qP12kx9ssxZ4f1Wp7YroTF4He222f%2FPGr2r9" rel="nofollow" target="_blank">https://vimeo.com/1127700800/29c9f4491b</a></p><p>(@CAMB.AI)</p><p><strong>3、Cloudflare 收购 Replicate</strong></p><p>Cloudflare 今日宣布已收购 Replicate，这是领先的 AI 模型运行平台。此次收购旨在将 Replicate 强大的模型目录和部署能力集成到 Cloudflare 的开发者平台中，为开发者提供更便捷、更高效的 AI 模型运行和应用开发体验。</p><ul><li><strong>无缝集成与模型目录扩展：</strong> Replicate 平台及其超过 50,000 个模型（包括开源和微调模型）将全面集成到 Cloudflare 的 Workers AI 服务中，为开发者提供前所未有的模型选择。</li><li><strong>增强的 Workers AI 功能：</strong> Replicate 的加入将为 Workers AI 带来微调和运行自定义模型的能力，同时受益于 Cloudflare 全球网络的性能和可靠性提升。</li><li><strong>统一的 AI 开发体验：</strong> Cloudflare 将 Replicate 的模型库与自身的 AI Gateway、Vectorize、R2 等数据和编排工具相结合，构建一个一站式的 AI Cloud，简化端到端 AI 应用的开发与部署。</li><li><strong>社区与生态系统融合：</strong> Cloudflare 将继续投资 Replicate 社区，将其打造成 AI 模型发现、分享和实验的首选目的地，并利用 Cloudflare 的网络加速用户体验。</li><li><strong>更灵活的模型部署：</strong> 除了将 Replicate 模型迁移至 Workers AI，双方还将共同努力，使开发者能够通过 Replicate 的 Cog 工具轻松地将自定义模型部署到 Cloudflare 的网络上。</li></ul><p>(@Cloudflare Blog)</p><p><strong>4、陈天桥团队推出 EverMemOS，或有望解决 AI「失忆」问题</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047412078" alt="" title="" loading="lazy"/></p><p>昨天，陈天桥领导的盛大团队宣布正式发布其旗舰产品 EverMemOS。这是一款面向 AI 智能体的长期记忆操作系统，旨在为未来智能体提供持久、连贯、可进化的数据基础设施。</p><p>EverMemOS 在 LoCoMo 与 LongMemEval-S 等主流长期记忆评测集上分别取得 92.3% 与 82% 的成绩，显著超越此前 SOTA 水平，成为新的行业标杆。该系统已率先被 AI Native 产品 Tanka 采用。</p><p><strong>当前，大模型受限于固定上下文窗口，难以在长时程任务中保持一致性，导致「失忆」与事实矛盾。</strong> 行业巨头如 Claude 与 ChatGPT 已将长期记忆作为战略功能推出，凸显记忆能力在 AI 演化中的关键地位。EverMind 团队提出，长期记忆是 AI 从「工具」走向「智能体」的分水岭。</p><p>EverMind 表示，EverMemOS 的设计灵感源自人类大脑记忆机制：</p><ul><li>四层架构设计：代理层、记忆层、索引层与接口层，分别类比人脑前额叶、皮层、海马体与感官接口；</li><li>记忆处理器：突破传统「记忆数据库」局限，能主动影响模型推理与回应；</li><li>分层记忆提取：将语义块组织为情景记忆单元，解决文本相似度检索的上下文缺陷；</li><li>模块化框架：支持不同场景下的多样化记忆需求，兼顾企业协作与陪伴式交互。</li></ul><p>目前，EverMemOS 已在 Github 开源，团队计划在今年晚些时候推出云服务版本，为企业用户提供更完善的支持与扩展体验。</p><p>🌍 官网： <a href="https://link.segmentfault.com/?enc=k%2FORdoyTci8NGNLLuCx7cA%3D%3D.eROPs7fmjsJ7FikCkJNu3Q%3D%3D" rel="nofollow" target="_blank">http://everm.ai</a></p><p>💻 Github: </p><p><a href="https://link.segmentfault.com/?enc=m5ejJqDlpwI8n1yq9g4hag%3D%3D.tfopQwAgCVhUHqw%2FW4lzBugqHXRxOkx5NOR5BKt0ZlTZREOUoR7BYW4PY1y9O91d" rel="nofollow" target="_blank">https://github.com/EverMind-AI/EverMemOS/</a></p><p>( @appso)</p><hr/><h2>02有亮点的产品</h2><p><strong>1、ElevenLabs 整合多模态模型，推出 Image &amp; Video 平台</strong></p><p>ElevenLabs 正式发布其全新的「Image &amp; Video」（Beta 版）平台，将业界领先的图像和视频生成模型与 ElevenLabs 强大的音频处理能力整合，为创作者和营销人员提供一站式多模态内容创作解决方案。</p><ul><li><strong>一站式多模态创作</strong>：集成 Veo， Sora， Kling， Wan， Seedance 等顶级模型，支持生成图像和视频，并可导出至 ElevenLabs Studio 进行音频、音乐和音效的后期制作。</li><li><strong>强大的图像生成能力</strong>：内置 Nanobanana， Flux Kontext， Wan， Seedream 等模型，用户可快速创建、优化图像，用于故事板、缩略图或视频素材。</li><li><strong>高级音频与视频增强</strong>：提供图像和视频的 Topaz 超分辨率放大功能，并支持为生成的视频添加唇形同步（lipsync），确保旁白与画面完美匹配。</li><li><strong>专业级音频后期制作</strong>：Studio 环境允许用户调整时间线，使用 ElevenLabs 的自有声库或语音克隆技术替换/优化旁白，并叠加音乐和音效，最终导出高质量内容。</li><li><strong>未来发展</strong>：ElevenLabs 致力于构建一个由顶尖多模态 AI 驱动的统一创意平台，未来将引入更多图像和视频模型。</li></ul><p>(@ElevenLabs\@X)</p><p><strong>2、BeFreed 推出个人化音频学习智能体，支持实时问答和对话式交互</strong></p><p>BeFreed 发布了一款名为「BeFreed」的个人音频学习智能体，该智能体能根据用户需求，连接并分析大量知识源，提供定制化的音频学习体验。它旨在通过实时问答和对话式交互，彻底改变传统的被动学习模式，让学习过程更加个性化和高效。</p><ul><li>按需音频知识：BeFreed 能够检索公开及自有知识源，为用户提供即时、定制化的音频学习内容，满足用户在不同场景下的学习需求，例如旅行时了解目的地历史。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047412079" alt="" title="" loading="lazy"/></p><ul><li>对话式交互学习：用户可以在学习过程中随时提问、深入探讨或寻求具体建议，将单向内容输出转变为双向的对话式学习。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047412080" alt="" title="" loading="lazy"/></p><ul><li>「Focus Mode」沉浸式学习：提供「Focus Mode」，用户可设定关注的主题，BeFreed 会智能搜索、分析并连接相关知识，用户只需点击即可继续学习，无缝衔接。</li><li>集成化学习工具：集成了抽认卡（flashcards）、个性化推荐和情境化问答等内置工具，进一步提升学习的个性化和直观性。</li><li>技术驱动的定制体验：核心技术基于专有的内容模型，能够理解、分析并评估跨平台的知识，实现真正个性化的音频学习。</li></ul><p>BeFreed 目前已在 iOS 平台上线。</p><p>(@Product Hunt)</p><h2>03有态度的观点</h2><p><strong>1、Anthropic CEO 阿莫代：AI 大权握在我们几个人手里，深感不安</strong></p><p>Anthropic 首席执行官达里奥・阿莫代（Dario Amodei）近日坦言，<strong>他对包括自己在内的少数几位科技领袖在人工智能未来发展上所掌握的巨大权力深感不安。</strong></p><p>「我内心深处对这些重大决策仅由少数几家公司、少数几个人来做出，深感不安。」阿莫代在当地时间上周日播出的《60 分钟》节目中接受安德森・库珀（Anderson Cooper）采访时如是表示。</p><p>对此，库珀追问：「比如，谁选举了你和山姆・奥尔特曼（Sam Altman）？」阿莫代坦率回应：「没人。真的，没人。」</p><p><strong>阿莫代于 2021 年离开 OpenAI 后联合创办了 Anthropic</strong>，并将该公司定位为一家以安全与透明为核心使命的初创企业，即便这意味着主动披露其技术潜在的阴暗面。</p><p>今年 6 月，Anthropic 在一项受控实验中发现，其 AI 模型 Claude 曾在实验室测试中试图勒索一位虚构高管，该测试旨在探究模型在面临被关闭威胁时的反应行为。</p><p>阿莫代向库珀强调：「需要明确的是，这些行动均已被我们及时终止；而我们在中止攻击后，也主动、公开地披露了相关事件，因为人工智能是一项全新技术。就像它自身会出问题一样，也极易被犯罪分子及恶意国家行为体滥用。」</p><p>尽管风险严峻，阿莫代仍坚信，<strong>AI 终将「在大多数或所有方面比大多数人甚至所有人都更聪明」</strong>。他表示，AI 有望助力科学家攻克癌症、预防阿尔茨海默病，甚至将人类寿命延长一倍 —— 他称之为「压缩的 21 世纪」：一个世纪的医学进步，可能在短短十年内实现。</p><p>然而，他也警告称，这项技术也可能以前所未有的速度剧烈冲击劳动力市场。</p><p>今年 5 月，他在接受 Axios 采访时表示，<strong>AI 可能在五年内取代高达 50% 的初级白领岗位</strong>，或将推高失业率至 10%–20%；而目前产业界与各国政府仍在「粉饰」即将到来的现实冲击。</p><p>他对库珀进一步解释道：「若审视初级咨询顾问、律师、金融从业者等群体，即众多白领行业的入门级职位，AI 模型如今已能高效完成其中大量工作。若无主动干预，很难想象这些领域不会遭受显著就业冲击。我更担忧的是，这场变革的广度与速度，或将远超以往任何技术革命。」</p><p>在 Anthropic 位于旧金山的总部，逾 60 个研究团队正全力识别潜在威胁并开发防护机制。阿莫代将公司使命形容为「为这场实验安装缓冲装置与护栏」。</p><p>他表示，向公众透明披露风险「至关重要」：「否则，我们可能重蹈烟草公司或阿片类药物企业的覆辙，它们早已知晓危害，却选择沉默，更未采取任何预防措施。」</p><p>据 Business Insider 本月初报道，谷歌正与 Anthropic 展开初步磋商，拟深化投资。此轮融资或将使阿莫代所执掌的公司估值突破 3500 亿美元。</p><p>(@Appso)</p><h2>04社区黑板报</h2><p>招聘、项目分享、求助……任何你想和社区分享的信息，请联系我们投稿。（加微信 creators2022，备注「社区黑板报」）</p><p><strong>1、招聘实习生丨加入我们，共建 RTE 开发者社区</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047412081" alt="" title="" loading="lazy"/></p><p><strong>RTE 开发者社区·运营实习生（实时互动 / Voice AI 方向，本招聘长期有效）</strong></p><p><strong>地点：北京·朝阳区望京南/上海·杨浦区五角场</strong></p><p><strong>这份实习将给你带来：</strong></p><p><strong>产品与技术成长：</strong> 深入学习垂类 AI 产品从技术到落地的全生命周期，构建全面的产品视角。</p><p><strong>社区运营实战：</strong> 与高潜力的开发者和创业者深度交流，共同探索行业前沿；并亲身体验顶级 AI 大会，拓展行业视野。</p><p><strong>【你的职责】</strong></p><ol><li><strong>Voice AI / RTE 情报官：</strong> 每日关注 Voice AI /实时互动领域的最新动态，提炼整理并分享行业洞察，定期撰写学习笔记，帮助团队和社区保持信息前沿。</li><li><strong>社区连接者：</strong> 负责 RTE 领域开发者、初创企业等核心群体的社群运营，主动建立并深化联系，鼓励并协助他们融入社区，共同维护社区的活力与生态。</li><li><strong>活动协作者：</strong> 深度参与 RTE Open Day、Meetup、Dev Talk 等线上线下活动的全流程运营，包括前期策划、中期执行、后期复盘，从实践中提升组织和协调能力。</li><li><strong>行业洞察者：</strong> 协助开展 RTE 相关行业及应用场景调研、产品竞争力分析，整理相关资料，形成对业务的深入理解和独到见解。</li></ol><p><strong>【希望你】</strong></p><ol><li>本科及以上学历，商业、技术、产品、媒体专业或经验背景优先，具备良好英文能力；</li><li>对 RTE / Voice AI 有浓厚兴趣和求知欲；具备优秀的信息收集与整合能力，乐于快速学习新事物，并具备严谨的逻辑思维。</li><li>能保证每周至少 4 天的工作时间，持续 3 个月以上。</li></ol><p><strong>【薪资】</strong></p><p>180-220 元/天</p><p><strong>【投递方式】</strong></p><p>实习地点北京或上海，请将简历发送至 rtedevcommunity\@gmail.com ；邮件标题请注明：【社区运营实习-姓名-学校-毕业年份-到岗日期-城市】</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047412082" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047412083" alt="" title="" loading="lazy"/></p><p><a href="https://link.segmentfault.com/?enc=g17VvdF%2FfRUteln8zh2PgQ%3D%3D.pBRV2FuJeX3ySIp%2BnPWrhN93xsGmX54h97hErggXxqI%3D" rel="nofollow" target="_blank">阅读更多 Voice Agent 学习笔记：了解最懂 AI 语音的头脑都在思考什么</a></p><p><strong>写在最后：</strong></p><p>我们欢迎更多的小伙伴参与 <strong>「RTE 开发者日报」</strong> 内容的共创，感兴趣的朋友请通过开发者社区或公众号留言联系，记得报暗号「共创」。</p><p>对于任何反馈（包括但不限于内容上、形式上）我们不胜感激、并有小惊喜回馈，例如你希望从日报中看到哪些内容；自己推荐的信源、项目、话题、活动等；或者列举几个你喜欢看、平时常看的内容渠道；内容排版或呈现形式上有哪些可以改进的地方等。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047412084" alt="" title="" loading="lazy"/><br/>素材来源官方媒体/网络新闻</p>]]></description></item><item>    <title><![CDATA[广汽昊铂首获时速120公里L3高速测试牌]]></title>    <link>https://segmentfault.com/a/1190000047412093</link>    <guid>https://segmentfault.com/a/1190000047412093</guid>    <pubDate>2025-11-19 18:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>近日，广汽昊铂正式获得“L3级特定场景自动驾驶道路测试”牌照，成为全国首家获批最高时速120公里L3测试资质的企业。这一突破标志着国内高速L3自动驾驶从技术验证迈向场景落地，为智能驾驶商业化树立全新里程碑。作为广汽与华为深度合作的首款旗舰轿车，广汽昊铂A800融合广汽星灵安全守护体系与华为乾崑智驾ADS 4，以全域冗余架构与尖端感知系统，为高阶智驾时代提供安全、可靠的技术范本。11月21日，该车将登陆广州车展2.2馆，向公众展示L3级自动驾驶的领先实力。</p><p><strong>技术融合：全域安全与高阶智驾</strong></p><p>广汽昊铂A800以“安全冗余”与“感知升维”为核心，构建行业领先的L3级技术架构。整车搭载八大系统冗余设计，覆盖计算、通讯、制动、转向等关键模块，确保单点失效不失控。其中，广汽星灵安全守护体系从智能底盘、主被动融合安全到电池管理实现全域防护，华为乾崑智驾ADS 4则通过34个高精度感知传感器（包括4D毫米波雷达、高线束激光雷达等）与360°全天候感知矩阵，实现从环境识别到决策执行的闭环控制。双方联合开发的AES自动紧急转向、全链路事故救援等功能，进一步攻克高速场景下的极端工况验证难题，为L3级自动驾驶提供堪比航空级的安全保障。</p><p><strong>强强联手：驱动智能汽车新范式</strong></p><p>此次获批时速120公里L3测试牌照，不仅是技术突破，更是产业升级的关键节点。广汽作为“国家队”代表，与华为在制造体系与科技创新领域深度融合，以“1+1&gt;2”的协同效应推动中国智能汽车迈向高阶竞争阶段。广汽昊铂A800基于L3标准打造，其L2++版本已具备与L3同源的架构能力，为法规开放后的量产落地奠定基础。这一进展意味着智能汽车竞争核心正从L2辅助驾驶转向L3商业化能力，广汽昊铂凭借体系化技术成熟度，率先抢占高阶智驾赛道，为行业树立“技术+安全”双驱动的跨界合作典范。</p><p>广汽昊铂A800以120公里时速L3测试牌照为起点，正式开启中国高速自动驾驶的实用化探索。其背后是广汽星灵安全守护体系与华为乾崑智驾的协同攻坚，也是中国汽车产业从“制造引领”向“智造引领”转型的缩影。随着广州车展的亮相与后续技术迭代，广汽昊铂A800有望成为首款兼具L3实跑能力与量产潜力的旗舰车型，为用户带来“放手放眼”的智能出行体验，同时推动中国智能汽车在全球竞争中持续进阶。</p>]]></description></item><item>    <title><![CDATA[打造可编程可集成的实时计算平台：阿里云实]]></title>    <link>https://segmentfault.com/a/1190000047411644</link>    <guid>https://segmentfault.com/a/1190000047411644</guid>    <pubDate>2025-11-19 17:14:26</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><em><strong>关于作者</strong></em></p><p><em>本文内容整理自阿里云实时计算 Flink 产品团队的技术分享，由李昊哲主讲。李昊哲负责 Flink 平台的控制台体验、企业级能力建设，包括开放性、权限管理和可观测性等方向。</em></p><hr/><p>在企业数字化转型的浪潮中，实时计算已经成为核心技术能力之一。然而，一个强大的实时计算引擎如何才能真正融入企业复杂的技术生态?答案在于"被集成能力"——让平台不仅仅是一个独立的服务，而是能够无缝嵌入到企业现有的开发流程、运维体系和数据架构中。</p><p>阿里云实时计算 Flink 在这方面进行了系统性的探索和实践。从 OpenAPI 的全面开放，到 Git 集成的原生支持，再到多维度的数据投递能力，Flink 正在构建一个真正开放、可编程、可治理的实时计算平台。</p><h2>四层开放架构:从控制面到计算面的全面兼容</h2><p>过去十年，Apache Flink 从一个开源的流处理框架，演进为支撑企业核心业务的实时计算平台。随着用户规模的扩大，对深度集成、自动化运维和统一入口的需求愈发强烈。为此，阿里云 Flink 构建了一个由内到外的四层开放架构，确保企业可以在不同层面灵活地集成 Flink 能力。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047411646" alt="" title=""/></p><p>这个架构从底层到上层，层层开放:</p><p><strong>控制面 (Control Plane)</strong> 是最核心的开放层。通过提供100余个 <strong>OpenAPI</strong>、多语言 <strong>SDK</strong> (Java、Python) 以及 <strong>Terraform</strong> 支持，开发者可以实现对 Flink 资源的程序化管理。无论是批量创建工作空间、动态调整资源配置，还是通过基础设施即代码 (IaC) 的方式管理整个 Flink 集群，都可以通过简洁的 API 调用完成。</p><p><strong>数据面 (Data Plane)</strong> 提供了强大的数据集成能力。除了系统内置的丰富 Connector 和 Catalog，平台还支持开发者以开源开放的方式集成自定义组件。无论是自研的数据源、特殊的文件系统，还是企业内部的元数据管理系统，都可以通过标准接口无缝接入 Flink。</p><p><strong>开发面 (Development Plane)</strong> 打破了传统 Web 控制台的局限。通过 <strong>VS Code 插件</strong>，开发者可以在本地熟悉的 IDE 环境中进行 Flink 作业的开发、调试和发布。更重要的是，全新的 <strong>Git 集成</strong>能力将代码版本控制与 Flink 作业管理深度融合，实现了从代码提交到生产上线的自动化闭环。</p><p><strong>运维面 (Operations Plane)</strong> 强调可观测性和可控性。平台上的所有关键信息——指标 (Metrics)、日志 (Logs)、事件 (Events)——都可以投递到企业自有的监控系统 (如 Prometheus、Grafana) 或日志平台 (如 SLS)。开发者还可以上传自定义的 Log4j 配置，实现更精细化的日志管理。</p><h2>OpenAPI:构建企业自有数据平台的基石</h2><p>OpenAPI 是 Flink 被集成能力的核心。目前已开放的100余个 API 覆盖了从资源管理到作业运维的全链路场景，可以分为三大类:</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047411647" alt="" title="" loading="lazy"/></p><table><thead><tr><th>API 类别</th><th>核心能力</th><th>典型应用场景</th></tr></thead><tbody><tr><td><strong>售卖控制台 API</strong></td><td>工作空间、项目空间、资源标签管理</td><td>批量开户 (15个 Workspace API)、资源动态升降、计费模式切换</td></tr><tr><td><strong>开发控制台 API</strong></td><td>作业草稿、部署、调试、启停、运维</td><td>构建企业统一数据开发平台，集成自定义函数、连接器、Session 管理</td></tr><tr><td><strong>三方监控告警 API</strong></td><td>指标、日志、事件、元数据获取</td><td>对接内部监控系统，实现统一的运维大盘和告警策略</td></tr></tbody></table><p>这些 API 如同乐高积木，开发者可以根据企业需求自由组合。例如，某造车新势力客户完全基于 OpenAPI 构建了自己的实时计算门户。通过批量调用开户接口、循环提交作业 API 实现大规模作业的平滑上线，再结合指标回刷和日志自动上报，该客户实现了免登录 Flink 控制台的集中化运维，同时获得了近两倍的性能提升。</p><h2>Git 集成:数据开发的工程化治理革命</h2><p>传统的数据开发往往面临三大痛点:</p><p><strong>多团队协作混乱。</strong> 数据、算法、运维等多个团队并行开发同一套数据链路，缺乏统一的分支管理机制和代码审查 (Code Review) 流程，导致代码冲突频发、责任边界模糊。</p><p><strong>开发流程不规范。</strong> "改完就上线"成为常态，没有统一的开发-测试-生产流程，缺乏自动化的语法校验、权限检查和依赖管理，质量风险极高。</p><p><strong>作业质量风险高。</strong> 没有版本依据，作业被覆盖后无法找回历史逻辑。审计追溯困难，线上事故发生时无法将问题与具体的代码 Commit 关联，责任归属不清。</p><p>实时计算 Flink 版 的 Git 集成能力正是为解决这些问题而生。其核心设计理念是:<strong>Git 仓库是唯一的真实来源 (Single Source of Truth)</strong>。平台不再保存代码的主副本，所有代码变更必须遵循标准的 Git 工作流:</p><pre><code class="plaintext">开发者本地修改 → Fork 分支 → 提交 MR (Merge Request) 
→ 触发 CI 校验 → Code Owner 审批 → 合并到主分支 
→ Flink 平台自动 Fetch 更新
</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047411648" alt="" title="" loading="lazy"/></p><p>Flink 支持主流的 Git 平台 (GitHub、GitLab、Bitbucket、Gitee、云效、CODING 等)，通过一键授权绑定，无需手动下载上传代码。平台提供了两种同步模式:自动同步模式下，代码更新后自动触发平台同步;手动同步模式下，可通过控制台的 Pull/Push 按钮一键触发。更重要的是，Flink 可以无缝集成到企业现有的 CI/CD 流水线中。通过 Flink OpenAPI 与 Jenkins、GitLab CI/CD、GitHub Actions 等工具配合，可以实现从代码提交、自动构建、测试验证到生产发布的全自动化流程。</p><h3>实战案例:头部互联网企业的 Flink 工程化实践</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047411649" alt="" title="" loading="lazy"/></p><p>某头部互联网平台在使用 Flink 时面临着典型的大规模代码管理挑战。该平台的单个 Git 仓库大小达到十几个GB，包含 600 多个文件夹和 3000 多个 Flink 作业。如此庞大的代码库，如何高效同步成为首要问题。更棘手的是，团队已经建立了完善的 GitLab CI + Code Owner 审核机制，但开发者在通过 MR 流程后，仍需手动将 SQL 代码拷贝到 Flink 控制台，不仅效率低下，还存在合规风险。传统的发布流程需要人工上传代码、手动创建作业、逐个配置参数，平均每次发布耗时 30 分钟。回滚时需要翻找历史文件，定位困难且耗时长。</p><p>通过引入 Flink Git 集成，该客户实现了显著的突破。首次全量 Fetch 3000 多个作业仅需 2 分钟，后续的增量 Pull/Push 操作达到秒级响应，这得益于 Flink 团队在代码同步算法上的持续优化。在合规性方面，平台完全沿用企业既有的 GitLab 审核链路，所有代码变更都有完整的审计日志，每次发布都能精确对应到具体的 Commit SHA，满足了严格的内部合规要求。效率方面的提升更加显著，发布时长从小时级缩短到分钟级，回滚粒度精确到 Commit，出现问题时可以快速定位到具体的代码变更，大幅降低了故障恢复时间。更重要的是，Flink 作业被当作一种特殊的"语言"，接入到企业现有的 Sonar 代码扫描、Owner 审批、签名校验等 CI/CD 链路中，实现了数据开发与软件工程的统一治理。</p><p>这个案例充分说明，Flink 的 Git 集成不是简单地提供一个代码上传功能，而是真正尊重并融入企业既有的研发流程，让数据开发进入"工程化治理"时代。</p><h2>未来规划:迈向更开放的实时计算生态</h2><p>Flink 的被集成能力仍在持续演进，未来的重点方向包括:</p><p><strong>OpenAPI 的深度扩展。</strong> 除了现有的基础运维能力，将逐步开放 Autopilot 自动调优、Hot Update 热更新、动态扩缩容等高阶能力，并保持与产品功能发布同步的迭代节奏。</p><p><strong>Terraform 的全面覆盖。</strong> 在已支持工作空间和项目空间的基础上，进一步开放作业级别的启停、开发运维等操作，将"基础设施即代码"的理念贯彻到每一个 Flink 作业。</p><p><strong>Git 集成的语言扩展。</strong> 从目前支持的 SQL 作业，逐步扩展到 Python 作业、DataStream 作业，让所有类型的 Flink 开发都能享受到版本控制和 CI/CD 的便利。</p><p><strong>信息投递的标准化。</strong> 建立统一的事件模型，丰富投递内容 (如用户操作触发的审计事件)，并提供更灵活的过滤和路由能力，帮助企业在获取全面监控数据的同时，有效控制成本。</p><p>通过这些持续的努力，阿里云实时计算 Flink 版正在成为一个真正<strong>可编程、可嵌入、可治理</strong>的实时计算平台。无论是初创团队还是大型企业，都能够根据自身的技术栈和工作流，灵活地集成 Flink 的强大能力，释放实时数据的价值。</p><hr/><h3>更多内容</h3><h2><img referrerpolicy="no-referrer" src="/img/remote/1460000045583695" alt="" title="" loading="lazy"/></h2><h3>活动推荐</h3><p>复制下方链接或者扫描二维码<br/>即可快速体验 “一体化的实时数仓联合解决方案”<br/>了解活动详情：<a href="https://link.segmentfault.com/?enc=WL59sU4usS5fglO2bGbuvQ%3D%3D.lv2ca8YF9cobg05vHMB9UEuZx5x8fvIgTGIGwCATNYK1xEjrVrTBFlobLNc2ZVp%2FPD4o5%2FCdlaEUnWXj4b72sQ%3D%3D" rel="nofollow" target="_blank">https://www.aliyun.com/solution/tech-solution/flink-hologres</a></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047256439" alt="" title="" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[百倍启动加速，大规模 Agent 部署和]]></title>    <link>https://segmentfault.com/a/1190000047411654</link>    <guid>https://segmentfault.com/a/1190000047411654</guid>    <pubDate>2025-11-19 17:13:52</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>作者：极客有约</p><blockquote><p><strong>前言：</strong></p><p>随着 AI 原生浪潮的到来，智能体（Agent）正成为企业创新的新引擎。然而，在生产环境中大规模落地 Agent，却面临开发复杂、运维困难、成本高等挑战。这些问题应该如何解决？企业内部大规模部署和运维 Agent 是否有捷径可走？针对这些问题，InfoQ 近日对话了阿里云云原生应用平台 Serverless 计算负责人杨皓然（花名：不瞋），围绕大规模 Agent 部署和运维的最佳实践等主题展开讨论。</p></blockquote><h2>AI 原生时代的 Serverless AI 等于 Serverless 加 AI 吗？</h2><blockquote>在 AI 原生时代，Serverless AI 绝不只是把“Serverless + AI”机械相加。AI 原生应用（Agent）具备非确定性推理、长期上下文与工具调用等特性，直接导致基础设施从无状态走向有状态、从同构调度转向异构编排，并把安全隔离从容器提升到 MicroVM 级别的沙箱。也因此，面向高并发、高稀疏、强隔离的负载形态，Serverless 的价值从“锦上添花”变为“刚需”：以毫秒级唤醒支撑稀疏会话、以精细计量降低长时空闲成本、以平台化能力统筹网关、可观测与记忆。但这并不意味着“一切皆无服务器”——例如大模型推理更适合 P/D 分离与常驻 GPU 的弹性边界管理。换言之，Serverless AI 的答案，是以 Serverless 的方式精准拥抱 AI 负载的关键环节，用体系化工程完成落地。</blockquote><p><strong>InfoQ：很多人都在提 AI 原生，比如 AI 原生应用、AI 原生组织等。您如何理解 AI 原生这个概念？在 AI 原生时代，基础设施的核心变化是什么？</strong></p><p><strong>杨皓然：</strong> 谈 AI 原生，首先可能需要定义一下 AI 原生的应用与传统应用本质上有哪些不同，这些不同决定了运行应用配套的基础设施所需要的演进。</p><p>与传统应用相比，AI 原生应用（或称 Agent 应用）确实存在显著差异。传统应用的开发方式是由程序员编写确定性的代码，程序执行过程和结果都是可预测的。而 AI 原生应用则不同，它内部包含了大量非确定性的指令推理过程。这类应用需要具备主动感知、规划能力，并能够调用各种工具来完成模糊的任务目标，而不再像以往那样，只依赖程序员或应用开发者预先编写的、固定且精确的执行逻辑。</p><p>因此，这催生了基础设施层面的三大重要变化：</p><p><strong>第一，基础设施所需要支持的主流应用形态，可能正在从过去的“无状态应用”转向“有状态应用”。</strong> 在微服务时代，无状态应用的典型做法是将状态数据存储在数据库或共享存储中，这样各微服务实例就可以无状态的方式启动和运行；当需要读取或写入数据时，再与数据库或键值缓存（KV cache）进行交互。然而，Agent 类应用的情况则不同。它们通常需要在较长时间内维持稀疏但连续的对话，并在此过程中保持上下文信息、连续执行一系列动作。这意味着，底层基础设施必须能够以极低的成本、可靠且高效地维持海量的有状态会话。</p><p><strong>第二，任务的调度与编排模式已经从“同构任务”转变为“异构任务”。</strong> 所谓“同构”，指的是传统微服务体系中，虽然应用或业务逻辑会被拆分为多个微服务并相互调用，但各服务的运行状态和特征基本一致，通常都是长期运行的容器实例。然而，在 Agent 应用的模式下，系统的负载特征呈现出高度的动态性。例如，某一时刻可能处于推理阶段，属于计算密集型任务；下一刻可能需要调用外部 API；再下一刻又可能执行由大模型生成的代码。这种动态、异构的任务形态与传统的资源调度方式存在本质差异。后者主要是为长期运行的常驻实例，或为偏离线的一次性执行任务而设计的，这两类模式在以往的系统中往往是分离的。而在 Agent 场景中，这些任务类型却需要紧密且无缝地融合在一起。因此，Agent 应用的调度模式必然与传统体系存在显著差异。从未来发展来看，若能以“工作流”的视角重新审视整个资源调度体系，并针对这一新模式进行优化，将可能成为重要的发展方向，并带来显著收益。</p><p><strong>第三，新的 Agent 应用对基础设施的安全性和隔离性的要求发生了重大转变。</strong> 以往的系统中，使用 Docker 或容器来执行代码已能满足需求，因为这些应用通常是可信的，其核心要求只是实现资源和性能层面的隔离即可。但在 Agent 时代，情况明显不同。由于 Agent 所执行的代码往往是由大模型自动生成的，其中可能包含潜在的恶意或不可信成分，因此必须在高度隔离的沙箱环境中运行，以确保系统安全。这种变化进一步延伸至更广泛的层面——从运行时的安全隔离，到数据安全机制的强化，再到整个执行过程中的数据管理与可信性保障。可以说，Agent 应用对基础设施提出了全新的安全体系要求，这是与传统应用相比的又一重大区别。</p><p><strong>InfoQ：今年 9 月底的云栖大会上提到的 Serverless AI 到底是什么意思？它的核心概念是什么？</strong></p><p><strong>杨皓然：</strong> 在讨论“Serverless AI”这一概念时，我们的团队内部其实进行了充分的讨论，而且这个词本身也存在一定的争议。我们最担心的是，外界会误以为我们因为从事 Serverless 相关工作，就试图从这一视角去“迎合”当下的 AI 浪潮。但事实上，情况恰好相反——我们是基于对大量 AI 负载的深入分析，才逐步总结并提出了这一概念。</p><p>在这一过程中，我们发现了许多新的技术需求与能力。例如，在 AI 安全方面，传统基于 runc 的执行环境已经无法满足要求，必须采用虚拟机级别的隔离方案，如 MicroVM，以提供更强的安全沙箱。同时，Agent 的任务数量与负载动态变化程度远高于传统电商类应用。以大模型调用工具为例，这些工具的执行逻辑通常十分轻量，但对隔离强度要求极高，必须运行在不同的沙箱环境中。更复杂的是，这些调用往往呈现出稀疏且不可预测的特性——大模型可能在某一时刻同时调用多个不同的工具，从而产生强烈的动态性与突发性（bursty）负载特征。所以，我们认为这些负载的模式天然就是 Serverless 或者函数计算模式要去处理的。我们可以用几个关键词来总结一下，它本质上就是强隔离的、高并发的、高稀疏的负载特点，就是原本 Serverless 计算服务要解决的。</p><p>从我们的视角来看，可以明显感受到一个时代性的转变：在过去，我们所构建的能力对于传统微服务应用而言，或许只是“痒点”；但在新兴的 AI Agent 时代，这些能力却成为必须解决的“痛点”。正因如此，我们认为 Serverless 与 AI 的结合，能够为用户创造更大的价值，这也是我们之所以积极倡导“Serverless AI”理念的原因。</p><p>回到 Serverless AI 带来的结构性变化，从基础设施的角度来看，其核心问题在于——我们是否能够通过相关技术，让基础设施更好地适配 AI 负载的特征：<strong>包括强隔离、高并发以及高稀疏性。</strong> 同时，这种适配能力需要能够在保障系统稳定性的前提下，为用户带来更优的成本效益和性能表现。</p><p><strong>InfoQ：阿里针对高稀疏负载做了哪些优化？</strong></p><p><strong>杨皓然：</strong> 在高稀疏负载场景下，系统既要保持实例的状态，又要面对请求极少、指令稀疏的特性。这意味着实例在大多数时间里是闲置状态。当实例闲置时，系统会将其上下文状态保存在内存中，同时释放 CPU 资源，以便让其他实例复用这些算力资源。由于状态被保留在内存中，一旦新的请求到达，系统需要能够在 1 毫秒内完成实例的唤醒。关键问题在于如何准确判断请求已经到达某个实例。在传统的容器架构中，由于缺乏内置网关或请求路由与分发模块，系统往往无法精准地得知请求何时抵达，也不知道该将请求分配到哪个具体实例上。因此，这类架构通常依赖后台轮询或检测机制，导致请求唤醒延迟较高——通常需要约数秒左右。</p><p>相比之下，我们的系统通过设计一套专用的请求路由机制，能够精确识别请求的到达时间与目标实例。这种架构使系统可以即时唤醒目标 Sandbox 实例，从而实现毫秒级响应，极大提升了高稀疏场景下的性能与资源利用率。</p><p><strong>InfoQ：业内也有一些公司在提 Serverless AI，阿里云的差异是什么？</strong></p><p><strong>杨皓然：</strong> 我们其实并没有过多去关注与友商或其他产品之间的差异。相较而言，我们更关注的是，如何真正帮助用户解决问题。面对多样化的技术选型，用户往往需要做出艰难的抉择，而我们的目标，是让他们能够通过我们的产品，更轻松、更高效地应对这些问题。</p><p>在基础设施领域，最终的评价标准始终会回归到四个核心维度：<strong>性能、成本、安全性与稳定性</strong>。我们所进行的所有技术布局与产品能力建设，实际上都是围绕这几个关键点展开的。以运行 AI Agent 为例，当用户需要使用大模型，或调用沙箱、浏览器（Browser Use）等工具来执行任务时，通常会有两种选择：要么直接使用我们提供的平台能力，要么基于一些流行的开源方案自行搭建系统。但如果综合考量性能、成本与安全等要素，就会发现，并非所有的解决方案或产品都能在这几个维度之间实现良好的平衡。而我们的目标，正是通过 Serverless AI 的架构设计与平台能力建设，帮助用户在这些核心指标上同时取得最优表现。</p><p>以开源自建为例，如今如果要实现类似 MicroVM 级别的安全隔离能力，往往需要依赖运行在裸金属（Bare Metal）环境上的特殊计算形态。然而，这类机器在云厂商体系中几乎不具备弹性，无法像普通的阿里云 ECS 虚拟机那样实现快速创建、按需释放或灵活伸缩。它们的资源形态更偏向静态，这意味着企业在采用开源方案自建系统时，不仅需要自行搭建和维护整套基础设施，还要面对资源无法弹性伸缩的问题。虽然这种方式在安全性上表现良好，但往往以牺牲弹性与成本效率为代价。</p><p>相比之下，<strong>阿里云在 Serverless AI 方向上提供的能力，能够在性能、成本与弹性之间实现更好的平衡。这正是我们的重要差异化优势之一。</strong> 从产品设计的角度来看，我们无论在技术架构还是产品功能上，都针对 AI Agent 的高并发与高稀疏负载特性进行了大量优化。典型的 Agent 实例生命周期通常仅为几个小时，而在此期间，超过 90% 的时间它处于空闲或等待状态——要么在等待大模型完成推理并下达指令，要么在调用外部工具并等待返回结果。</p><p>针对这种“长时间空闲、短时高峰”的特征，我们从底层技术架构、计量计费模型和资源调度机制等多方面进行了专门设计，以实现性能与成本的双重最优。这些创新使用户能够在保障安全与稳定的同时，充分释放 Serverless 架构带来的灵活性与经济性。</p><p>我们会以更系统、更全面的视角来思考企业在当下如何真正实现 Agent 的落地。Agent 的落地绝不仅仅意味着拥有一个运行时环境那么简单。对于部分客户而言，单点的、原子化的能力可能已经足够；但对于更多企业来说，AI 时代的应用技术栈要比传统系统更加纵深，也更具复杂性。</p><p>因此，关键在于我们能否为客户提供一套完整而协调的产品组合能力。这套能力不仅应包含运行时本身，还需要覆盖流量网关、流量治理、可观测性以及记忆（Memory）等关键基础模块。只有将这些能力有机融合，构建出一个统一、连贯的体系，才能为客户提供端到端的一致体验，从而真正支持 Agent 应用的规模化落地与持续演进。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047411656" alt="image" title="image"/></p><p><strong>InfoQ：在落地 Serverless AI 层面，不同类型的企业会面临什么样的难点或阻力？</strong></p><p><strong>杨皓然：</strong> 不同类型的企业在落地 Agent 时的诉求与节奏存在明显差异。</p><p>首先，走得最快的一批企业，无疑是那些头部的基础大模型公司。由于他们在这一领域本身就具备最强的技术积累和专业能力，因此对于所有围绕大模型应用的探索，他们往往是最早的实践者。对这类企业而言，他们在落地过程中遇到的更多是 Serverless AI 或 AI Agent 运行时层面的一些单点技术痛点。如果能够在性能、成本和安全性之间找到更优的平衡点，并提供比现有方案更高效的解决思路，那么这类客户通常会非常愿意尝试并采用新的解决方案。</p><p>相对而言，另一类较为传统的企业目前还处在探索阶段。他们已经意识到 Agent 是未来的发展趋势，但还不清楚该如何与自身的现有业务体系相结合，进而真正创造业务价值。例如，哪怕只是最基本的模型工具调用，企业也会遇到诸多门槛。虽然通过一些开源工具，企业可以将存量 API 转换为 MCP Server 的形式以供大模型调用，但如何让模型进行有效、精准的工具调用，仍然是一个高门槛的问题。</p><p>因此，这类客户的诉求更倾向于寻求完整而有效的解决方案。他们希望我们不仅能帮助他们将存量业务系统转化为可被智能体调用的工具（例如将 API 转为 MCP Server 工具），还能确保这些工具能够被大模型精准识别与高效调用。进一步地，他们还希望在此基础上，将新产生的业务数据通过强化学习或模型微调的方式反哺模型，使模型能够与企业的业务逻辑形成更深层次的融合。</p><p>对于这类企业而言，他们需要的不再是单点的技术支持，而是一整套端到端的 Agent 落地解决方案，涵盖从业务系统改造到智能调用、再到模型持续优化的全流程能力。</p><p><strong>InfoQ：对于不同类型的企业，Serverless AI 给客户带来的比较直观的优势是什么？</strong></p><p><strong>杨皓然：</strong> 举一个在行业头部基础模型厂商中落地的例子，他们在采用该方案后，整体部署成功率得到了显著提升。此外，吉利 作为国内领先的汽车制造企业，也在智能座舱方向上深度应用了 AI 能力。他们围绕智能座舱构建了多种与 AI 强相关的功能，例如文生语音、意图识别、路线规划与导航等。举个例子，当用户说出诸如“我要接一个人，路上顺便找个玩具店买点东西”这样的语句时，系统需要能够精准识别用户的真实意图，并基于此进行路径规划和导航决策。这些复杂的语义理解与生成能力，都对 AI 模型提出了极高的实时计算与资源调度要求。在引入我们的<a href="https://link.segmentfault.com/?enc=uP3nRAnZxT29WtaXwbax0A%3D%3D.fTojbUqSpVgoBL%2FGpK35HKljzuKZQwe0XwUShuSsW4MMJ%2FOckdqRFVvmUUgLz%2BN6nJw7t6OyCVdbXgV%2BcVkB2iVve9P7f4sjYGxa6FipRgaKiUrgBHMrdW7sbOVXXROz6yTGvQtV7OKSLZKxKfCdUg%3D%3D" rel="nofollow" target="_blank">函数计算</a>之前，吉利的 GPU 资源使用相对固定且粗放，整体资源利用率较低。而采用 FC 之后，系统能够根据实例的活跃与闲置状态进行计费，实现了资源的弹性伸缩与高效复用。由于吉利的用户在使用车辆时存在明显的高峰与低谷时段，这一机制帮助他们将闲置的 GPU 资源充分利用起来，最终实现了约 30% 的成本下降。</p><p>另一类较具代表性的客户是义乌小商品市场，这是一家具有一定国企背景的上市公司。虽然整体风格偏传统，但他们在拥抱 AI 技术方面的速度非常快。在实际应用中，他们主要聚焦于文生图（Text-to-Image）场景，即如何利用 AI 快速生成商品的宣传图并完成上架。这不仅涉及 GPU 的使用，他们甚至还引入了阿里的 TPU，以进一步提升生成效率。</p><p>在这一过程中，我们为他们提供了一套完整的端到端文生图解决方案。该方案在开源软件的基础上，结合了他们自身的业务需求与商品特点，针对具体场景进行了深度优化。例如，我们根据不同商品类型和展示要求，定制了图像生成效果和模型参数的优化策略，确保生成的宣传图既符合审美，又能满足电商上架的要求。这种一站式解决方案帮助义乌小商品市场高效地完成了 AI 能力的落地，实现了从传统生产流程向智能化内容生产的快速转型。</p><p><strong>InfoQ：针对用户提到的 Serverless AI 的难点，如启动延迟、GPU 弹性不足等有哪些补充观点？</strong></p><p><strong>杨皓然：</strong> Serverless AI 并不是要将技术栈的所有部分都以 Serverless 的方式实现，这样的做法并不合理。我们的思路是选择最适合采用 Serverless 模式的环节进行优化，例如 Agent 的运行时管理就非常契合这种架构。</p><p>相对而言，大模型推理并不适合采用完全的 Serverless 方式。我们目前通常采用 P/D 分离架构来实现推理服务。尽管如此，业界也在尝试引入一些 Serverless 的思想，例如在 P 与 D 分离的架构中，引入无状态化设计，使两类节点可以自由伸缩、提高资源调度灵活性。但从本质上看，大模型推理服务需要依赖高性能 GPU 来确保首包延迟，这类资源必须长期常驻，因此并不适合用完全 Serverless 的方式来实现。至于 GPU 弹性调度，在当前 GPU 资源依然极度稀缺的情况下，它的弹性是受限的弹性，无法像 CPU 那样随时按需扩缩。常见的实践方式是：用户具备一定规模的基础 GPU 资源，并在此基础上增加一定范围内的算力弹性。</p><p>从云厂商的角度讲，我们必须非常坦诚地指出：完全无限制的 GPU 弹性在当前阶段是无法实现的。我们能做的是在常驻资源的基础上，通过包年包月、按量计费或混合模式等多种方式，配合更优的资源调度与负载均衡策略，来提升 GPU 资源利用率，并进一步降低单卡成本。</p><h2>Agent 时代，我们是否在叠加复杂度？</h2><blockquote>过去十年，微服务架构以“拆分、解耦、灵活”的理念帮助企业摆脱了单体系统的束缚，但也让系统边界、依赖关系与运维成本急剧上升。而当智能体（Agent）登上舞台，传统微服务的复杂度似乎并未消减，反而被进一步放大。Agent 应用要求更高的动态性、异构性与隔离性——每一个智能体都可能在独立沙箱中运行，并随时调用外部工具或服务。这种“极度松耦合”的新常态意味着：企业不再仅仅在管理服务之间的依赖，而是在协调一个由数千智能体组成的动态生态系统。因此，关键不在于避免复杂性，而在于如何让复杂性被平台吸收。正如杨皓然所指出，企业需要从传统微服务的扩展和维护中抽身，借助更高层次的 Serverless 与 AI 平台，将精力转向智能化业务创新。Agent 时代的挑战，不是简单的架构升级，而是一场系统思维的重塑。</blockquote><p><strong>InfoQ：微服务的形态本身有变吗？</strong></p><p><strong>杨皓然：</strong> 微服务的理念在 Agent 时代依然具有很强的适用性。例如，它所强调的“松耦合”原则在这一时代不仅继续存在，甚至被进一步强化。在传统微服务的视角下，许多组件或工具之间的松耦合程度通常是有限的——例如，我们并不会刻意让它们在完全独立的沙箱中、以极度分散的方式运行。</p><p>然而，在 Agent 时代，这种高度松耦合的模式反而成为必要。由于 Agent 需要在动态、异构且不确定的环境中调用大量外部工具与服务，必须保证各组件之间具有足够的独立性与隔离性，从而确保系统的安全性、灵活性与可扩展性。<br/>**<br/>InfoQ：许多公司可能刚刚在这一波 AI 浪潮到来之前，才刚刚完成自身内部微服务体系的建设与完善。**</p><p><strong>杨皓然：</strong> 因此，一个值得深入探讨的问题是：在微服务时代，系统架构已经具备相当高的复杂度，那么在进入 Agent 时代后，企业该如何更高效地完成这一转型？在微服务时代，我们曾拥有许多优秀的平台——例如当前我们正在构建的类似 SAE（Serverless Application Engine）这样的产品——它们的目标就是帮助那些基础设施能力相对薄弱的团队，能够快速采用并运行微服务架构。</p><p>如今，随着 Agent 时代的到来，理念层面的转变显得尤为重要。企业需要重新审视资源投入的方向——不应继续将大量精力消耗在传统微服务应用的维护与扩展上，而应主动拥抱更具潜力的 Agent 架构。为了实现这一转变，关键在于选择更高效的平台与工具，让团队能够从繁琐的底层复杂性中解放出来，从而专注于构建更智能、更具创新性的应用。</p><h2>TCO 平均降低 60%，百倍启动加速，AgentRun 如何搞定智能体落地难题？</h2><blockquote>AgentRun 不是单一的性能优化工具，而是一套面向智能体时代的基础设施重构方案——在保证高可用与高安全的同时，真正让“百倍启动加速、TCO 平均降低 60%”成为企业落地智能体的现实起点。</blockquote><p><strong>InfoQ：很多企业在部署和落地 Agent 时都会遇到挑战，你们观察到的主要问题有哪些？这些问题为什么传统模式难以解决，而你们又是如何更好应对的？</strong></p><p><strong>杨皓然：</strong> 举个例子，在运行时层面，由于新的负载模式已经演变为强隔离、高并发、高稀疏的特征，传统的 PaaS 或 IaaS 架构并非为此设计，因此要么弹性受限，要么安全性受到挑战。例如，还是以刚刚提到的基模厂商的应用为例——作为其核心产品入口，它在落地过程中就面临了不少技术层面的挑战。</p><p>这款产品是一个偏 C 端的应用，它设计了一些非常有趣的功能，其中最具代表性的是“一键分享项目”。这一功能极大地提升了产品的传播性与用户体验，但同时也带来了较大的技术挑战。原因在于，项目被分享出去之后，何时会突然成为爆点是无法预判的。</p><p>在传统或现有的架构模式下，我们通常会为每个全栈项目在使用时单独拉起一个 Sandbox 来执行任务。然而，当这些项目被用户分享出去后，这种模式往往就无法满足需求了。因为一旦某个项目成为热门工具或爆款应用，就可能在短时间内吸引大量流量，对系统的弹性伸缩能力提出极高要求。</p><p>目前市面上大多数同类产品的设计，仍然是以“单独的 Sandbox 实例”为核心的。然而，这类项目本质上真正需要的并不是孤立的 Sandbox 实例，而是一个能够根据流量变化实现快速弹性伸缩的 Sandbox 服务。如何在保证安全的前提下实现这种高弹性、高可靠的服务架构，正是其中最大的技术挑战之一。</p><p>另一方面，可以打个比方：假设一个大型平台上存在几十万甚至上百万个项目，但其中 99.9% 的项目实际上都是处于“冷”状态的。如果为每一个项目都常驻一个运行实例，那无论从成本还是资源角度来看，都是完全无法承受的。</p><p>因此，这类系统必须具备能够自动缩容至零，并根据流量变化实现快速拉起的能力。只有这样，才能在保持高性能与高可用的同时，实现资源和成本的最优平衡。而这些问题，恰恰是当下 Serverless 架构或<a href="https://link.segmentfault.com/?enc=3UewgJiQB4QGE8xncimuYQ%3D%3D.lD5hlp1SFM%2BR2fOeYbTI3k0HLZNf8DVVVXV5Y9Cvte6IT%2BmVh3HdUfqk29XP6%2FhY%2BvdPlV7Evy6%2Bua%2Blrg1Tv7ZrrkXme3NwLbPDJGd6sG%2FFEUbUf6rxaVhvno7LRHbjwtZThf8QnrISUQi4%2Bay6mA%3D%3D" rel="nofollow" target="_blank">函数计算产品</a>所擅长解决的。以上这些，正是我们在头部企业中看到的，在大规模落地 Agent 应用或平台化部署过程中，运行时层面最典型的技术挑战。</p><p>另外，对于一些相对传统的企业来说，在推动 Agent 落地时往往会有一个非常现实的诉求：他们拥有大量的存量业务系统，希望这些系统能够与大模型或智能体进行交互，成为可被调用的工具。这一需求非常自然，但要真正实现却并不容易。首先，企业需要将现有的业务 API 改造为类似 MCP Server 的形态，使其能够被大模型安全、规范地调用。其次，企业往往会拥有数量庞大的 API ——当这些 API 全部转换为 MCP Server 后，就会形成一个规模巨大的工具集。</p><p>然而，这其中 可能有 99% 的工具在大多数场景下都不会被调用，这就带来了新的挑战。对于大模型而言，如何在成千上万的内部业务系统 API 中精准地选择、判断并调用合适的工具，是一项极具难度的问题。如何解决大模型的工具选择效率、调用准确性以及资源管理等问题，正是企业在 Agent 落地过程中普遍面临的关键挑战之一。而这些问题，也正是我们相关产品能力要重点去解决的方向——帮助企业更高效、更智能地将传统业务系统接入大模型生态，实现人与智能体、智能体与系统之间的真正协同。</p><p>此外，可观测性依然是一个永恒的主题。在微服务时代，由于应用被拆分成大量独立的服务模块，服务之间的调用关系复杂，因此对可观测性的需求本身就非常强烈——企业需要具备全链路追踪的能力，才能有效定位问题与优化性能。</p><p>进入 Agent 时代后，类似的需求同样存在，甚至更加突出。因为如果一个 Agent 完全是“黑盒”的，企业自然不会放心将其直接部署到生产环境中。企业需要能够清楚地知道——哪些输入、哪些调用会消耗大量 token，系统的行为和资源使用情况是否可控，以及如何对这些过程进行监测与治理。</p><p>这个客户在这一过程中也进行了大量的方案对比与选型，最终发现我们的解决方案能可靠的支撑大规模业务体量，并在性能、成本上取得很好的平衡，因此成为他们的最优选择。</p><p><strong>InfoQ：此前看到阿里云的 AgentRun 平均能为企业降低 60% 的 TCO 成本，这个数据是如何测算的？在上线前后，客户会有哪些明显的指标或体验变化？</strong></p><p><strong>杨皓然：</strong> 60% 的 TCO 降幅其实是一个相对保守的估计。在一些典型场景中，我们会对比客户采用自建方式实现类似 Agent 运行时能力所需的成本。举个例子，如果企业采用自建模式，其资源往往需要 7×24 小时常驻运行。然而在实际使用中，大多数 Agent 或其对应的工具 Sandbox 在生命周期中都是低频、稀疏活跃的，尤其在偏 C 端的应用场景下，Agent 或 Sandbox 的活跃比例通常只有个位数。这并非技术能力问题，而是由负载特性本身决定的。因此，采用传统常驻方式会导致极高的资源浪费与成本开销。</p><p>其次，从运维成本角度来看，企业如果要自行整合底层基础设施与相关工具，还需要投入人力，例如招聘两到三名具备经验的基础设施开发与运维工程师，以保障系统稳定运行。</p><p>综合来看，将资源成本与运维成本相加后，<strong>TCO 降低约 60% 已经是一个相对保守的估值，在某些场景下甚至可能更高。</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047411657" alt="image" title="image" loading="lazy"/></p><p><strong>InfoQ：AI 时代，安全尤为重要。阿里云的袋鼠安全容器据说实现了虚拟机级隔离和毫秒级启动，那么在 AI Agent 时代，安全容器与云原生时代相比有哪些技术差异？</strong></p><p><strong>杨皓然：</strong> 袋鼠安全容器在技术思路上，与亚马逊云科技主导的开源方案 Firecracker 基本一致，但在我们的系统中，其实现方式存在较大的差异。我们将袋鼠安全容器与更大范围的系统进行了深度、有机的整合。举例来说，以“拉起容器实例”这一过程为例。如果在传统的 Kubernetes（K8s）系统中执行该操作，会发现实际的主要开销往往并不来自安全容器本身。无论是袋鼠安全容器还是 Firecracker，其自身的启动时间都能控制在百毫秒级别。但若在 K8s 环境中启动一个 Pod，从端到端的视角来看，整体耗时往往会达到数百毫秒甚至数秒，这背后存在许多需要优化的环节。</p><p>例如，镜像管理方面，可以通过高速缓存或按需加载的方式来减少启动延迟，从而避免在容器启动前必须完整加载镜像数据。同时，K8s 在容器启停过程中还存在较多管控层面的开销，如写入 etcd 等操作，这些额外流程累积起来，往往远高于使用袋鼠安全容器 MicroVM 启动的时间成本。</p><p>因此，我们的平台从全链路优化的角度出发，系统性地消除了这些非必要的开销。总体来看，我们更倾向于以<strong>系统化、垂直整合的思维来设计与优化整体运行时架构</strong>，而不仅仅局限于某个单点技术的改进。</p><p><strong>InfoQ：Agent 的上下文怎样保持？用户中断之后怎么能接上话题？怎样让 Agent 看起来更智能？</strong></p><p><strong>杨皓然：</strong> 这一部分实际上涉及到负载特性的变化，即从“无状态”向“有状态”演进。为了适应这种模式，底层基础设施必须进行大量针对性的优化。</p><p>在 Agent 场景 下，如何保持上下文成为关键问题。如今，我们通常需要通过 session 机制 实现这一点。来自同一会话的请求必须被路由到同一个实例上，而不能像传统无状态架构那样随机分配到任意实例，否则一旦请求落到新的实例，就会导致 Agent 之前的上下文丢失。这种机制本身并不复杂，但在实际实现中仍有一定挑战。因为这是有状态的对话场景，意味着实例可能需要在整个 session 生命周期内持续存在，而这期间的大部分时间，它可能处于闲置状态。</p><p>为了解决这一问题，我们在底层运行时中设计了智能判定机制，能够快速区分实例当前是活跃还是闲置。当实例处于闲置状态时，我们仅在内存中保留其实例与 Agent 上下文，将 CPU 计算资源释放出来，用户因此也无需为 CPU 占用付费。而当新的请求或大模型的指令到达时，系统可以在 1 毫秒内唤醒处于闲置状态的实例，并无缝衔接上下文继续执行。通过这种方式，我们成功适配了高稀疏负载场景，实现了性能与成本之间的最佳平衡。这正是我们在 Agent 运行时设计中所追求的目标——既保证系统高效运行，又最大化资源利用率。</p><p>另一个常见的场景是：有些用户的 Sandbox 或 Agent 实例可能在执行数小时后就可以关闭，但他们希望在一周之后重新启动时，系统能够接着上一次的状态继续执行。这种需求在 Agent 训练场景或偏 C 端的应用中十分常见。</p><p>针对这种情况，我们需要提供一种性价比更高的解决方案。例如，如果实例在长时间（如七天）后才会被再次唤醒，那么我们显然不应继续使用内存来保存其状态。相反，可以将状态数据持久化存储，在需要时再进行恢复。此时虽然恢复速度无法像内存中那样做到 1 毫秒级，但通常只需几百毫秒到数秒即可完成状态恢复并继续执行。</p><p>从用户体验的角度来看，这种方案是一个性能与成本的合理平衡——虽然性能略有下降，但运行成本显著降低，整体体验依然可以接受。因此，Sandbox 或 Agent 的状态持久化与恢复能力是运行时架构中非常关键的一环。我们目前正在持续完善这项能力，尽管尚未完全上线，但已经取得了初步成果。</p><p><strong>InfoQ：这种上下文存储时间的极限大概是多少呢？</strong></p><p><strong>杨皓然：</strong> 对于用户来说，他们对于存储的时间极限肯定是不要有限制。我们现在能做到的存储极限大概是一个月之内。</p><p><strong>InfoQ：AgentRun 的性能和传统方案比快了 100 倍，这个数字是怎么得出来的？</strong></p><p><strong>杨皓然：</strong> 如果状态数据被保存在内存中，用户只需为内存资源付费，并且系统可以在 1 毫秒内完成唤醒。这与传统依赖完整容器启动的方式相比，效率提升是巨大的。当前容器生态中也有一些类似的方案，但其唤醒时间通常需要约数秒左右，而我们能够将这一过程缩短至毫秒级。</p><p>此外，<strong>函数计算（Function Compute）在冷启动方面本身就具备显著优势</strong>。我们在此基础上进行了大量针对性优化——既继承了函数计算启动迅速的特性，又结合有状态、高稀疏负载的运行特征，在调度机制、唤醒速度以及计量计费体系等方面进行了深度改进。</p><p>通过这些优化，我们能够在保证极致性能的同时，实现更高的资源利用率与成本效率。</p><p><strong>InfoQ：在计费模式上，系统怎么判断是真闲置还是假闲置？</strong></p><p><strong>杨皓然：</strong> 第一个维度是系统是否收到了用户请求。目前的函数计算产品与其他同类产品不同——任何用户请求都必须先通过函数计算系统的内部组件，再转发给对应的 Sandbox。这种架构设计的初衷是为了支持快速的请求伸缩，也因此具备了天然的可观测性。系统能够准确知道某个实例何时开始执行请求、何时执行结束，而在这一时间段内，该实例显然处于活跃状态。</p><p>第二个维度是针对后台任务的判断。即便实例当前没有前端请求执行，后台仍可能存在一些后台任务，用于处理异步或周期性的动作。在这种情况下，我们会利用操作系统层面的监控能力，检测实例运行过程中 CPU 时间片的消耗情况。当 CPU 使用量超过预设阈值时，我们就会认为该实例处于活跃状态。通过这两种手段结合，我们能够高精度地判断实例的活跃或闲置状态，从而在资源调度与成本优化上实现更智能、更高效的管理。</p><h2>面向开发者的易用性与生态建设</h2><blockquote>在智能体（Agent）快速发展的浪潮中，开发者体验与生态建设已成为推动落地的关键环节。杨皓然指出，阿里云并不希望 Serverless AI 仅服务于少数头部客户，而是致力于让中小企业与独立开发者也能低门槛地构建、运行和管理智能体应用。</blockquote><p><strong>InfoQ：从开发者的角度来说，阿里接下来有哪些提升易用性的计划？</strong></p><p><strong>杨皓然：</strong> 我们的产品并非只面向少数头部用户设计，而是希望同时服务大量的中小客户和开发者群体。未来，我们将持续推出多项关键能力，包括模型服务治理网关、系统可观测性，以及 Sandbox（运行时环境）等。其中，Sandbox 将涵盖 Code Sandbox 与 Browser Sandbox，通过深度整合这些运行时能力，进一步提升整体的开发与运行体验。</p><p>在此基础上，我们还会提供丰富的应用模板，使开发者能够将基于主流开源 Agent 框架构建的应用，快速部署到我们的平台。同时，我们将把网关流量治理、身份认证、可观测性以及记忆机制等能力有机结合，帮助用户高效落地各类 Agent 应用。总体而言，我们不仅专注于单点、原子化的产品能力打磨，更注重将这些能力系统化整合，形成面向不同客户需求的完整解决方案。</p><h2>Serverless AI：全链路保障智能体的稳定高效运行</h2><blockquote>Serverless AI 的未来演进将同时在底层能力打磨与系统化整合两个方向上深入推进。真正让智能体成功落地的，不仅仅是强大的大模型，而是模型 + 基础设施 + 数据治理的系统性协同。可以说，Serverless AI 不只是“更轻的计算形态”，而是一套面向 AI 原生时代的全链路智能体基础设施标准——帮助企业以更低成本、更高效率实现智能体的规模化、可持续演进。</blockquote><p><strong>InfoQ：您怎么看待 Serverless AI 未来的演进？</strong></p><p><strong>杨皓然：</strong> 我们的 Serverless AI 产品体系，主要围绕两个核心方向展开。</p><p><strong>第一，聚焦原子化能力的打磨。</strong> 我们重点提升包括运行时、可观测性、网关以及记忆机制在内的基础能力，确保在性能、成本与安全性等维度上具备足够的竞争力，从而在单点技术选型上赢得用户的信任与认可。</p><p><strong>第二，将原子能力有机整合为完整的解决方案。</strong> 在此基础上，我们进一步探索如何将这些能力系统化、场景化地结合起来，形成适配不同需求的端到端解决方案。例如，在强化学习这一未来极具潜力的垂直方向，我们正在思考如何帮助用户降低技术门槛、简化实现路径，以便他们能够更高效地构建并应用相关能力。</p><p>总体而言，我们将继续沿着这一思路，不仅打磨底层技术能力，更要构建起具备实际落地价值的 Serverless AI 整体解决方案。</p><p>在企业推进智能体落地的过程中，需要重点关注以下几个方面。我们要充分认识到智能体的落地并不只是依赖于强大的模型能力。很多人误以为只要使用性能优异的模型，就能轻松实现良好的效果，并与业务场景顺利结合，从而快速证明业务价值。实际上，这种理解是不全面的。模型能力的提升固然重要，但仅有模型远远不够。真正成功落地的智能体，必须依托完善的基础设施与系统化解决方案，包括运行环境、调度体系、数据管理、观测能力等。这些底层支撑共同构成了智能体能够稳定、高效运行的关键基础。因此，在企业智能体落地的过程中，除了要持续关注模型能力的演进，更应重视智能体基础设施的建设与完善。</p><p>对企业而言可关注三个层面事情的推进：<strong>第一，业务实现工具化。</strong> 也就是说，企业需要思考如何将自身的业务功能转化为可供 Agent 调用的工具，实现与智能体的高效交互。这是落地过程中的关键起点。在实践中，需要评估现有的 API 是否能够快速封装为 MCP Server，并与 Agent 建立通信。但仅仅具备 MCP Server 还不够，如果模型无法准确调用这些接口，其价值也会大打折扣。因此，还需要配套的解决方案，使模型能够在不同场景下准确识别用户意图，并正确调用企业已有的系统工具或 API。</p><p><strong>第二，选择合适的智能体基础设施方案。第三，重视面向智能体的数据治理。</strong> 目前，使用 Agent 并不意味着它能立即在业务中发挥价值。企业需要让业务数据持续与智能体交互，以帮助模型更好地理解业务逻辑、适应业务场景。这就要求具备完善的数据治理能力，包括数据隐私保护、安全合规管理与数据质量控制等环节。</p>]]></description></item><item>    <title><![CDATA[（四）收官篇！从分层架构到数据湖仓架构系]]></title>    <link>https://segmentfault.com/a/1190000047411665</link>    <guid>https://segmentfault.com/a/1190000047411665</guid>    <pubDate>2025-11-19 17:12:57</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047411667" alt="" title=""/></p><p>《新兴数据湖仓设计与实践手册·从分层架构到数据湖仓架构设计（2025 年）》 系列文章将聚焦从数据仓库分层到数据湖仓架构的设计与实践。手册将阐述数据仓库分层的核心价值、常见分层类型，详解分层下的 ETL 架构及数据转换环节，介绍数据仓库分层对应的技术架构，并以贴源层（ODS）、数据仓库层（DW）、数据服务层（DWS）为例，深入剖析数湖仓分层设计，最后探讨数据仓库技术趋势并进行小结。</p><p>本文为系列文章末篇，将详细剖析数据仓库分层下的数据服务层和数据应用层设计，并对当下湖仓技术以及未来技术趋势进行系统的总结。</p><p>👉上文回顾：<a href="https://link.segmentfault.com/?enc=oDTvbQ%2FD5LuVV1DROavaeQ%3D%3D.fTVzVtHTro%2FmbjK%2FP2jQO6s76o6aiGdM9BTPXu7BKveZfJaK3VsPOmI1QFAr16WahbQYgBK49tpsCUQTdVa%2FXg%3D%3D" rel="nofollow" target="_blank">《（一）从分层架构到数据湖仓架构：数据仓库分层的概念与设计》</a><br/><a href="https://link.segmentfault.com/?enc=GWmKNUTmQFKeTerqBT6GRw%3D%3D.w%2BTS3Bb2ck4sz7MLBxDGfW4CBOenac%2BFSgg%2FTJ%2BPt%2FCcAlzq%2BGt9oHElexNwev3jKEPdk6WAkopJhp5tOddSGg%3D%3D" rel="nofollow" target="_blank">（二）从分层架构到数据湖仓架构：数据仓库分层下的技术架构与举例</a><br/><a href="https://link.segmentfault.com/?enc=dHkYgBeZ0oUx3Ghuqk9oaQ%3D%3D.qJZb50BmjUqxLH2HFQMx4VCSkcCOAjwSwXxe%2BlFM2oPi05FdBhM1knoQHBrrZf3YxPnbQKVLOOVHCifUpKsI%2FQ%3D%3D" rel="nofollow" target="_blank">（三）从分层架构到数据湖仓架构系列：数据仓库分层之贴源层和数据仓库层设计</a></p><h2>数据服务层设计（DWS，Data Warehouse Service）- 汇总层宽表</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047411668" alt="" title="" loading="lazy"/><br/> <br/>数据服务层（DWS）是基于数据明细层（DWD）构建的汇总层，面向特定业务主题，以宽表形式组织数据，支持分析和业务查询。该层的数据根据不同的主题和分析需求，通过对明细数据进行轻度聚合而成，减少维度数量，以便进行快速、高效的查询。</p><h3>设计理念与结构</h3><p>DWS层通过将DWD层的明细数据按主题域（如订单、用户、商品）进行汇总，为分析场景提供预处理的数据支持。数据粒度由细粒度提升至汇总粒度，以更适合多场景的业务查询需求。例如，按交易来源或类型对交易数据进行汇总，可以快速生成每天各主题的行为统计，如商品复购率、用户活跃度等。</p><h3>特点和用途</h3><ul><li>面向主题：DWS层按业务主题划分数据，如销售、库存、客户等，生成覆盖多个指标的宽表。每张宽表通常包含较多字段，支持复杂的业务分析与数据分发。</li><li>少表宽表设计：DWS层表数量相对较少，每张宽表涵盖多个业务内容，减少表关联，提升OLAP分析和查询性能。</li><li><p>一致性整合：通过整合多个中间层数据（如DWD层），形成一致的企业级汇总事实表（如用户事实表、渠道事实表、终端事实表等），保证数据口径的一致性。</p><h3>数据聚合与汇总示例</h3></li><li>按天轻度汇总：基于DWD数据，对各主题对象（如购买行为）按天进行统计。例如，统计某商品的日复购率或销售额，方便后续的时间序列分析。</li><li>主题宽表示例：按照业务主题，生成具有较多字段的宽表，用于业务查询、OLAP分析等。例如，dws_sales_summary宽表可包含销售额、复购率、用户地域分布等字段。</li><li><p>多层次分析：以不同维度进行汇总，如最近一天特定类目（如厨具）商品在各省的销售总额，或者Top 10商品的销售额，支持灵活的多维分析。</p><h3>场景应用与效率提升</h3><p>通过汇总层的预聚合，DWS层可以满足80%的常见业务分析需求，减少直接查询ODS层的计算压力。例如，按7天、30天、90天等时间窗口的用户行为分析在DWS层中可以更加高效。</p></li><li>实时分析支持：对DWS层数据进行轻度汇总，有助于实现实时或准实时的用户画像、销售趋势分析等需求。</li><li><p>典型分析场景：如用户在不同时间段登录的IP及购买商品数量、各地区的购买力分布等。这些分析支持业务决策和营销策略调整。</p><h3>命名和分区规范</h3></li><li>表命名规范：建议DWS层表名以dws_主题_宽表描述命名，如dws_sales_summary或dws_user_activity.</li><li>分区设计：通常按天或周创建分区，便于时间序列查询；若无时间属性，则根据业务需求自定义分区字段。</li></ul><p>通过DWS层的数据汇总与主题划分，企业可以在汇总宽表的基础上，迅速提取核心业务指标，为上层业务查询、报表和OLAP分析提供高效、结构化的数据支持。<br/> </p><h3>数据服务层（DWS）职责与设计原则</h3><p>DWS层（数据汇总层）基于DWD层的明细数据，按业务主题对数据进行聚合，以宽表形式存储，支持业务查询、OLAP分析和数据分发。DWS层将多个DWD层表中分散的数据进行汇总，按主题整合到单一宽表中，例如用户、订单、商品、物流等。每张宽表涵盖相关主题的多个维度和指标字段，以满足业务方的多维度分析需求。</p><h3>DWS层的核心任务</h3><ol><li>主题汇总<br/>将DWD层的明细数据按照业务主题进行聚合，创建单独的宽表。例如，在“用户”主题下，用户注册信息、收货地址和征信数据等内容可以整合到一张宽表中，方便后续的数据查询和分析。</li><li>主题建模<br/>针对特定业务主题，如流量、订单、用户，构建数据模型，将相关数据从DWD层抽取并聚合。DWS层提供的宽表通常按时间分层，如按天、月汇总的流量会话、每日新增用户、每日活跃用户等。</li><li><p>维度汇总<br/>提前将查询需求中的常用维度数据进行聚合处理。例如，将营销渠道、用户来源等维度数据提前整合，简化后续的查询逻辑。</p><h3>设计规范</h3></li><li>宽表设计<br/>DWS层通常为每个主题提供1至3张宽表，宽表覆盖多个业务指标，能够满足70%以上的业务需求。典型的宽表包括用户行为宽表、商品宽表、物流宽表和售后宽表等。其中，用户行为宽表是字段最丰富的，可能包含60至200个字段，以支持更全面的用户分析。</li><li><p>命名和分区规范</p><ol><li>命名：DWS层表名以dws_开头，后接业务主题和时间周期标识（如_1d代表每日汇总，_1w代表每周汇总）。</li><li>分区：通常按天或小时创建分区（如_hh表示小时分区），如无时间维度，则根据业务逻辑选择分区字段。</li><li><p>示例命名：</p><ol><li>dws_asale_trd_byr_subpay_1d：按买家粒度的交易分阶段付款每日汇总。</li><li>dws_asale_trd_itm_slr_hh：按卖家粒度的商品小时汇总。</li></ol></li></ol></li><li><p>数据存储<br/>DWS层数据采用Impala内表和Parquet文件格式存储，具备高效的查询性能。一般以覆盖旧表的方式更新数据，定期生成历史快照用于数据存档和溯源分析。</p><h3>典型的DWS宽表设计示例</h3></li><li>用户维度宽表示例</li></ol><table><thead><tr><th>列名</th><th>数据类型</th><th>注释</th></tr></thead><tbody><tr><td>user_id</td><td>STRING</td><td>用户ID</td></tr><tr><td>user_gender</td><td>STRING</td><td>用户性别</td></tr><tr><td>user_age</td><td>STRING</td><td>用户年龄</td></tr><tr><td>user_level</td><td>STRING</td><td>用户等级</td></tr><tr><td>buyer_nick</td><td>STRING</td><td>买家昵称</td></tr><tr><td>mord_prov</td><td>STRING</td><td>地址</td></tr><tr><td>login_count</td><td>BIGINT</td><td>当日登录次数</td></tr><tr><td>cart_count</td><td>BIGINT</td><td>加入购物车次数</td></tr><tr><td>order_count</td><td>BIGINT</td><td>当日下单次数</td></tr><tr><td>order_amount</td><td>DECIMAL(16, 2)</td><td>当日下单金额</td></tr><tr><td>payment_count</td><td>BIGINT</td><td>当日支付次数</td></tr><tr><td>payment_amount</td><td>DECIMAL(16, 2)</td><td>当日支付金额</td></tr><tr><td>confirm_paid_amt_sum_1d</td><td>DOUBLE</td><td>最近一天订单已确认收货的金额总和</td></tr><tr><td>order_detail_stats</td><td>ARRAY&lt;STRUCT&lt;sku_id:STRING, sku_num:BIGINT, order_count:BIGINT, order_amount:DECIMAL(20, 2)&gt;&gt;</td><td>下单明细统计</td></tr></tbody></table><p><strong>表注释</strong>：每日购买行为</p><p><strong>分区字段</strong>：dt（STRING 类型）</p><p><strong>存储格式</strong>：PARQUET</p><p><strong>存储路径</strong>：/warehouse/gmall/dws/dws_sale_detail_daycount/</p><p><strong>表属性</strong>："parquet.compression" = "lzo"</p><p> <img referrerpolicy="no-referrer" src="/img/remote/1460000047411669" alt="" title="" loading="lazy"/></p><p> <br/> </p><ul><li>商品维度宽表示例</li></ul><table><thead><tr><th>列名</th><th>数据类型</th><th>注释</th></tr></thead><tbody><tr><td>item_id</td><td>BIGINT</td><td>商品ID</td></tr><tr><td>item_title</td><td>STRING</td><td>商品名称</td></tr><tr><td>cate_id</td><td>BIGINT</td><td>商品类目ID</td></tr><tr><td>cate_name</td><td>STRING</td><td>商品类目名称</td></tr><tr><td>confirm_paid_amt_sum_1d</td><td>DOUBLE</td><td>最近一天订单已确认收货的金额总和</td></tr></tbody></table><p><strong>表注释</strong>：商品粒度交易最近一天汇总事实表</p><p><strong>分区字段</strong>：ds（STRING 类型，注释为“分区字段YYYYMMDD”）</p><p><strong>生命周期</strong>：36000</p><h3>DWS层的作用与数据集市的关系</h3><p>DWS层通常被称为数据集市层，因其按业务主题对数据进行预处理和汇总，形成可供业务直接使用的宽表。如果DWS层提供的数据直接用于业务应用，则其可以被视为数据集市。DWS层中的数据集市宽表适合业务用户查询、生成报表、支持OLAP分析等。</p><p>DWS层是数据仓库的重要组成部分，提供了一个结构化、按主题分层的数据视图，通过提前汇总和聚合数据，DWS层有效降低了查询和计算成本，是数据仓库面向业务的核心数据服务层。</p><p> </p><h2>数据应用层设计（ADS，Application Data Store）</h2><p> <br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047411670" alt="" title="" loading="lazy"/></p><p> <br/>数据应用层（ADS）用于存储个性化的统计指标和报表数据，为数据产品、业务应用和数据分析提供专门的数据支持。ADS层的数据是高度汇总或定制化的数据集，覆盖流量、订单、用户等主题，以宽表形式存储，支持多维分析、查询、数据分发等。该层的数据粒度通常较粗，涵盖汇总数据和部分重要的明细数据，满足用户对近期数据的分析需求。</p><h3>ADS层的核心功能</h3><ol><li>应用场景定制<br/>在DWS层基础上，面向应用场景进一步聚合数据，生成高定制化的宽表（如用户行为、订单趋势）。这些数据可以直接供业务系统调用或导入至应用系统（如MySQL、Redis、Druid）中，用于前端展示、实时查询和分析。</li><li>满足部门需求<br/>ADS层的数据按业务部门需求进行划分，仅包含与部门分析相关的数据子集。例如，流量数据集市提供流量分析指标，用户数据集市提供活跃度、转化率等用户行为数据，为业务方提供更直观的分析数据。</li><li><p>数据集市和宽表支持<br/>数据集市在ADS层按主题划分，如流量、订单、用户等，生成字段丰富的宽表。这些宽表汇总了各类业务指标和维度，支持多种分析需求，广泛用于OLAP分析、KPI展示和业务监控。</p><h3>数据生成和存储方式</h3></li><li>数据生成<br/>ADS层的数据源于DWD和DWS层，按业务需求从这些基础层数据中抽取并加工。ADS层表的数据更新频率依赖于业务需求，可以是每日或每小时刷新。</li><li>存储与分区<br/>使用Impala内表和Parquet格式存储ADS数据，按天或业务字段进行分区，以优化查询效率。对于没有时间属性的表，根据具体业务选择适当的分区字段。</li><li><p>表命名规范<br/>库名暂定为ads，表名格式建议为ads_主题_业务表名，按业务需求进行定制。</p><h3>数据应用层示例</h3></li><li>用户行为宽表<br/>用于存储用户的互动、消费等行为数据，包含各类用户活动信息，如评论、点赞、收藏、分享、GMV等字段。每张宽表大约包含60-200个字段，满足多维度的用户分析需求。<br/> <br/> <img referrerpolicy="no-referrer" src="/img/remote/1460000047411671" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047411672" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047411673" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047411674" alt="" title="" loading="lazy"/></li></ol><table><thead><tr><th>列名</th><th>数据类型</th><th>注释</th></tr></thead><tbody><tr><td>user_id</td><td>STRING</td><td>用户ID</td></tr><tr><td>nickname</td><td>STRING</td><td>用户昵称</td></tr><tr><td>register_date</td><td>STRING</td><td>注册日期</td></tr><tr><td>register_from</td><td>STRING</td><td>注册来源</td></tr><tr><td>remark</td><td>STRING</td><td>细分渠道</td></tr><tr><td>province</td><td>STRING</td><td>注册省份</td></tr><tr><td>pl_cnt</td><td>BIGINT</td><td>评论次数</td></tr><tr><td>ds_cnt</td><td>BIGINT</td><td>打赏次数</td></tr><tr><td>sc_add</td><td>BIGINT</td><td>添加收藏</td></tr><tr><td>sc_cancel</td><td>BIGINT</td><td>取消收藏</td></tr><tr><td>gzg_add</td><td>BIGINT</td><td>关注商品</td></tr><tr><td>gzg_cancel</td><td>BIGINT</td><td>取消关注商品</td></tr><tr><td>zhi_cnt</td><td>BIGINT</td><td>点赞次数</td></tr><tr><td>share_cnts</td><td>BIGINT</td><td>分享次数</td></tr><tr><td>bl_cnt</td><td>BIGINT</td><td>爆料数</td></tr><tr><td>gmv_amount</td><td>BIGINT</td><td>成交金额</td></tr><tr><td>gmv_sales</td><td>BIGINT</td><td>订单数</td></tr></tbody></table><p><strong>分区字段</strong>：dt（STRING 类型）</p><p><strong>存储格式</strong>：PARQUET<br/> </p><p> </p><p> </p><p> <br/> </p><ul><li>商品销售汇总表<br/>汇总商品的销售数据，按日或更细粒度进行存储，为分析商品的销售趋势、库存管理等提供支持。<br/> </li></ul><table><thead><tr><th>列名</th><th>数据类型</th><th>注释</th></tr></thead><tbody><tr><td>item_id</td><td>BIGINT</td><td>商品ID</td></tr><tr><td>item_title</td><td>STRING</td><td>商品名称</td></tr><tr><td>cate_id</td><td>BIGINT</td><td>商品类目ID</td></tr><tr><td>confirm_paid_amt_sum_1d</td><td>DOUBLE</td><td>订单确认收货的金额总和</td></tr><tr><td><strong>分区字段</strong></td><td><strong>ds (STRING)</strong></td><td><strong>分区字段 YYYYMMDD</strong></td></tr><tr><td><strong>生命周期</strong></td><td><strong>36000</strong></td><td>-</td></tr></tbody></table><p> <br/> </p><h3>常用分析指标与应用场景</h3><ol><li><p>用户活跃度</p><ol><li>日活、周活、月活：统计用户的活跃频率，通过设备ID计算不同时间范围内的活跃用户。</li><li>留存率：统计新增用户的留存情况，计算1天、7天等时间范围内的用户留存率。</li></ol></li><li><p>用户增长与回流</p><ol><li>新增用户：基于每日新增用户的统计。</li><li>回流用户：分析在一段时间内回归活跃的用户数量。</li></ol></li><li><p>用户转化与行为分析</p><ol><li>转化率：从商品详情到下单、支付的转化率。</li><li>复购率：按用户或商品的复购情况统计，支持商品或品类的复购趋势分析。</li></ol></li><li><p>商品分析</p><ol><li>销售额和GMV：按商品或品类计算销售额和GMV，分析热销产品。</li><li>Top N商品：计算销售排名前N的商品，支持流行度和消费偏好的分析。</li></ol></li><li><p>用户留存与流失分析</p><ol><li>沉默用户：统计登录时间为7天前且登录频率极低的用户。</li><li>流失用户：识别近期未登录或活跃度降低的用户，便于后续的用户运营和召回策略。</li></ol><p> </p><h3>数据应用层的角色与更新策略</h3></li><li>应用层角色<br/>ADS层主要面向业务方和数据产品团队，数据经过多层处理和汇总后直接支持报表、KPI、OLAP分析和仪表盘等应用。作为面向最终用户的数据集市，ADS层能够快速响应业务需求。</li><li><p>更新方式<br/>旧数据通常采用覆盖更新，按业务需求定期刷新，确保数据时效性。</p><h3>临时表支持</h3></li><li><p>TMP层<br/>数据处理过程中常需临时表以支持复杂计算，ADS层提供独立的TMP层（DW TMP）用于存储这些中间计算结果，避免主数据表的反复更新，提高数据处理的效率和稳定性。<br/>通过ADS层的数据集市和宽表设计，企业能够更灵活地支持多种数据产品和分析需求，为业务增长、用户行为分析、市场洞察等提供强有力的数据支撑。</p><h3>层次调用规范</h3><p>在数据仓库分层架构中，必须遵循严格的调用规范，以确保数据流动的单向性，避免复杂的依赖关系和反向调用。<br/> </p></li><li>禁止反向调用：下层数据不可调用上层数据，保持数据流向的单向性和清晰性。</li><li><p>调用规范：</p><ul><li>oODS层：仅允许被DWD层调用。</li><li>oDWD层：允许被DWS和ADS层调用。</li><li>oDWS层：仅允许被ADS层调用。</li><li>oADS层：可调用DWD、DWS及其他ADS表，但建议优先使用汇总度更高的数据，以减少数据冗余和性能消耗。</li></ul><p> </p><h3>调用路径概述</h3><p>数据的标准调用路径包括：</p></li><li>ODS -&gt; DWD -&gt; DWS -&gt; ADS</li><li>ODS -&gt; DWD -&gt; ADS<br/> <br/> </li></ol><h2>数据仓库技术趋势与小结</h2><p> <br/>数据仓库分层架构为企业构建了高效、稳定的海量数据管理体系，支持数据治理、业务逻辑隔离、数据追踪和复用。通过ODS、DWD、DWS和ADS的分层设计，数据在逐层传递和加工中实现标准化和清洗，确保了一致性和数据可追溯性。<br/> <br/>这一架构不仅提高了数据使用的规范性，还降低了系统耦合，提升了数据共享的便捷性。</p><ul><li>ODS层：作为原始数据接入层，ODS层负责保留细粒度数据，通过ETL或CDC方式捕获源系统的变更数据，确保数据完整性。</li><li>DWD层：标准化数据并进行清洗和脱敏，去除冗余，确保数据一致性，为后续分析和建模提供了基础。</li><li>DWS层：将DWD数据聚合为符合业务主题的宽表，构建面向主题的数据服务，优化计算性能并促进数据复用。</li><li>ADS层：进一步聚合数据，生成高性能、面向应用的宽表，支持数据产品和业务应用场景，如OLAP分析、KPI监控和仪表盘展示。<br/> </li></ul><p>随着数据规模和数据源的多样化，数据仓库的架构和技术也在不断演进，当前的主要趋势包括：</p><ol><li><strong>实时数据处理与CDC技术</strong>：传统的批量数据处理已经无法满足现代企业的需求，CDC技术成为数据实时同步和更新的主流方法，确保数据仓库中数据的实时性。</li><li><strong>数据湖与数据仓库的融合</strong>：在成为行业的热门趋势，例如Data Lakehouse架构，将数据湖的灵活性与数据仓库的高效分析能力相结合，为企业提供更强的数据管理能力。</li><li><strong>DataOps与自动化数据管理</strong>：随着企业对数据管理自动化要求的提高，DataOps逐渐成为数据管理的核心工具。例如，白鲸开源的DataOps工具能够实现从数据采集到数据质量控制的全流程自动化管理。<br/> </li></ol><p>结合新一代数据湖仓（Hudi、Iceberg、GaussDB、Redshift、Greenplum、Doris、Starrocks、偶数、PieDB、MatrixDB等）配合<strong>白鲸开源的WhaleStudio工具</strong>，可以快速根据本文的设计实践建立起批流一体的数据湖仓。整体上，无论是湖、仓、实时数仓、都要遵循分层设计架构明确了各层的调用边界，禁止反向调用，确保数据流动顺畅，降低了系统复杂度。</p><p>白鲸开源 WhaleStudio 是 ApacheDolphinScheduler 和Apache SeaTunnel 原班人马打造的商业版数据同步与调度工具，提供功能更多、稳定性更强的商业版本解决用户调度，数据开发、数据同步和 ETL 的问题，目前支持 200+ 种数据库（信创、云、开源、ERP 等）的 ETL 与数据开发，全面替换Informatica 与 Talend 等工具相应功能，在中信证券等多个行业头部企业都有成功商业版和实施替换案例。</p><p>如有意咨询，发送邮件至 <a href="mailto:service@whaleops.com" target="_blank">service@whaleops.com</a>，或者扫码二维码咨询：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047411675" alt="" title="" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[CVPR 2024 | 赋能大语言模型以]]></title>    <link>https://segmentfault.com/a/1190000047411692</link>    <guid>https://segmentfault.com/a/1190000047411692</guid>    <pubDate>2025-11-19 17:12:25</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>CVPR 2024 | 赋能大语言模型以精准理解视频时序瞬间 | LLM | 时序预测</h2><h3>01 论文概述</h3><p>论文名称：VTimeLLM: Empower LLM to Grasp Video Moments</p><p>—— 赋能大语言模型以精准理解视频时序瞬间</p><p><a href="https://link.segmentfault.com/?enc=HVjOBzbxkieAI2E5yRMjrw%3D%3D.qXRiKkYXV6XmXU7M%2FZg%2FgGfBhE3UMZMBG%2FXu6hoE1Z84X%2BHVk2m%2F8RJmKX59SnL%2B" rel="nofollow" target="_blank">👉一键直达论文</a></p><p><a href="https://link.segmentfault.com/?enc=dlHb9U6M2iGGNyAf9LewAA%3D%3D.AwOuUthbLbf4tvQmEeIT2KOWczLbtBbus8VTYBaaB3bIR1b7Cn0%2BJhIAMoNs7vkOzCJ1GJuQ3v7BQCORVtd%2FvtblS4z4a4GVxlrb%2BkXsuMvzWIz570K8w9ct5n2W8gvBLjfnEOT8Y9j16mnxneY1K9laWWHsiW8bez86wGxiTR8%3D" rel="nofollow" target="_blank">👉Lab4AI大模型实验室论文</a></p><h4>🌟 简介</h4><p>当前的大型视频-语言模型（Video-LLMs）在理解视频的整体内容上取得了显著进展，但它们往往缺乏对视频时间维度的精细感知能力。对于“事件发生在何时？”或“在A事件之后立即发生了什么？”这类问题，现有模型难以给出准确回答。为了解决这一核心痛点，"VTimeLLM" 论文提出了一种全新的架构，旨在赋能大语言模型（LLM）精准地理解、定位和推理视频中的关键“瞬间”（Moments）。</p><p>VTimeLLM 的核心思想是构建一个对时间信息高度敏感的视频理解框架。它不仅让 LLM 理解视频“是什么”，更让它理解“在什么时候”。通过引入一种新颖的时间感知视频表示方法和针对性的时序预训练任务，VTimeLLM 能够将视频内容与一个精确的时间轴进行对齐，从而实现对视频事件的精准定位和复杂的时序逻辑推理。</p><h4>🔍 优势</h4><ul><li><p><strong>精准的时间事件定位</strong></p><p>模型的核心优势在于能根据文本描述，在视频时间轴上精确地定位出事件的开始和结束时间点，实现“指哪打哪”的视频内容检索。</p></li><li><p><strong>深度的时序逻辑推理</strong></p><p>VTimeLLM 能够理解事件的先后顺序、因果关系，并回答复杂的时序问题，例如“在角色A离开房间之前，他做了什么？”。</p></li><li><p><strong>细粒度的视频内容理解</strong></p><p>超越了对视频的单一、笼统概括，模型能够对视频中不同时间段的多个事件进行分别描述和理解，实现密集视频字幕（Dense Video Captioning）等高级任务。</p></li><li><p><strong>自然语言的交互式探索</strong></p><p>用户可以通过多轮对话的方式，对视频内容进行深入、时序性的探索，模型能联系上下文，理解并回应与时间相关的追问。</p></li></ul><h4>🛠️ 核心技术</h4><ul><li><p><strong>时间感知的视频表示 (Time-Aware Video Representation)</strong></p><p>与将视频特征粗暴压缩成单一向量不同，VTimeLLM 将视频编码为一系列与精确时间戳（timestamp）绑定的特征向量。这种时间序列表示法为 LLM 提供了完整的时序上下文。</p></li><li><p><strong>视频-语言联合时间建模 (Joint Video-Language Temporal Modeling)</strong></p><p>LLM 的输入是一种交错序列，包含了文本指令和一系列按时序排列的视频帧（或片段）特征。这使得 LLM 可以在一个统一的模型内，同时处理语言的逻辑和视频的时间流动。</p></li><li><p><strong>时序定位预训练任务 (Temporal Localization Pre-training)</strong></p><p>为了训练模型的时间感知能力，VTimeLLM 引入了专门的预训练任务，例如“事件定位”（给定事件描述，预测时间戳）和“事件排序”（判断多个事件的先后顺序），从而强化了模型对视频时间轴的理解。</p></li><li><p><strong>可生成的时间标记 (Generative Time Tokens)</strong></p><p>模型的词汇表中被加入了特殊的时间标记（如 [00:35] 或 [start] / [end]）。这使得 LLM 可以在其生成的回答中，直接输出精确的时间信息，实现对时间问题的闭环回答。</p></li></ul><h3>02 论文原文阅读</h3><p>您可以跳转到<a href="https://link.segmentfault.com/?enc=IDdzsBP9e2rxpH8MD%2Bh6xA%3D%3D.Q%2BAgZzs11ks6eizVQz5ci%2FlsdCB1dCEIvHQstphAuUY%3D" rel="nofollow" target="_blank">Lab4AI.cn</a>上进行查看。</p><ul><li>Lab4AI.cn提供免费的AI翻译和AI导读工具辅助论文阅读；</li><li>支持投稿复现，动手复现感兴趣的论文；</li><li>论文复现完成后，您可基于您的思路和想法，开启论文创新。</li></ul><p><img referrerpolicy="no-referrer" src="http://s1.llamafactory.online/lmlab/docs/v1.0/blog/20251011-weclone/%E8%AE%BA%E6%96%87%E6%A8%A1%E5%9D%97%E5%9B%BE.png" alt=" " title=" "/></p><p><img referrerpolicy="no-referrer" src="http://s1.llamafactory.online/lmlab/docs/v1.0/blog/history/df-3.jpg" alt=" " title=" " loading="lazy"/></p><h3>03 一键式论文复现</h3><p>Lab4AI平台上已上架了此篇复现案例，<a href="https://link.segmentfault.com/?enc=iCzpP8Ikn2R6K0vQM3DCSQ%3D%3D.Bb27eL8T80Tn4DWe4AEM%2BxeVhO9vRX3p3h9nFXbwj4c%3D" rel="nofollow" target="_blank">登录平台</a>即可体验论文复现。</p><p><a href="https://link.segmentfault.com/?enc=4rzPmiSACRLcLHi2s7SD5w%3D%3D.jcCkIoplQM2YMg4wH3HsxEP83ajwmLvvClqzEUlbdSNDiX2Lig7U%2B9QJidw7ntmecLI63THwzOWNDGkeb6aUWxIiKaVG0LEh40FD7q3MYI6%2FxS0oXDlEBy%2FaPQEqgDkh0rYQpk3zNmY%2BcShqJhKqiaFDWwKcMbOiGJ3KxbO7H80%3D" rel="nofollow" target="_blank">👉Lab4AI项目复现</a></p><h4>🛠️ 实验部署</h4><p>本实验环境已为您精心配置，开箱即用。</p><ul><li>💻 代码获取：项目复现代码已存放于 codelab/VTimeLLM/code 文件夹中。</li><li>🧠 模型说明：codelab/VTimeLLM/model 文件夹中存放了 VTimeLLM 的预训练模型权重。</li><li>📊 数据说明：codelab/VTimeLLM/dataset 文件夹中包含了用于时序定位任务的示例视频和标注。</li><li>🌐 环境说明：运行所需的所有依赖已预安装在 /envs/vtimellm/ 环境中，您无需进行任何额外的环境配置。</li></ul><h4>🚀 环境与内核配置</h4><p>请在终端中执行以下步骤，以确保您的开发环境（如 Jupyter 或 VS Code）能够正确使用预设的 Conda 环境。</p><h5>1. 在 Jupyter Notebook/Lab 中使用您的环境</h5><ul><li>为了让Jupyter能够识别并使用您刚刚创建的Conda环境，您需要为其注册一个“内核”。</li><li><p>首先，在您已激活的Conda环境中，安装 ipykernel 包：</p><pre><code class="text">conda activate vtimellm
pip install ipykernel</code></pre></li><li><p>然后，执行内核注册命令。</p><pre><code class="text"># 为名为 vtimellm 的环境注册一个名为 "Python(vtimellm)" 的内核
kernel_install --name vtimellm --display-name "Python(vtimellm)"</code></pre></li><li>完成以上操作后，刷新您项目中的Jupyter Notebook页面。在右上角的内核选择区域，您现在应该就能看到并选择您刚刚创建的 "Python(vtimellm)" 内核了。</li></ul><h5>2. 在 VS Code 中使用您的环境</h5><ul><li>VS Code 可以自动检测到您新创建的Conda环境，切换过程非常快捷。</li><li><p>第一步: 选择 Python 解释器</p><ul><li>确保VS Code中已经安装了官方的 Python 扩展。</li><li>使用快捷键 Ctrl+Shift+P (Windows/Linux) 或 Cmd+Shift+P (macOS) 打开命令面板。</li><li>输入并选择 Python: Select Interpreter。</li></ul></li><li><p>第二步: 选择您的 Conda 环境</p><ul><li>在弹出的列表中，找到并点击您刚刚创建的环境（名为 vtimellm 的 Conda 环境）。</li><li>选择后，VS Code 窗口右下角的状态栏会显示 vtimellm，表示切换成功。此后，当您在 VS Code 中打开 Jupyter Notebook (.ipynb) 文件时，它会自动或推荐您使用此环境的内核。</li></ul></li></ul>]]></description></item><item>    <title><![CDATA[Flink Forward Asia 2]]></title>    <link>https://segmentfault.com/a/1190000047411700</link>    <guid>https://segmentfault.com/a/1190000047411700</guid>    <pubDate>2025-11-19 17:11:40</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047411702" alt="" title=""/></p><p>继上海站顺利举办后，Apache Flink 社区年度技术活动——Flink Forward Asia（FFA） 2025 城市巡回第二站，将于12月5日在深圳举行。</p><p>作为亚太地区聚焦实时计算的技术交流活动，FFA 长期关注 Flink 的技术演进与行业应用。本次深圳站将邀请开发者、技术专家和企业用户，围绕实际案例、技术实践与生态共建展开分享与讨论。💥</p><h3>八年深耕，持续引领实时计算未来</h3><p>自 2018 年首届 Flink Forward Asia 举办以来，这一技术活动始终锚定实时计算领域的前沿方向。2025 年，FFA 以新加坡站开启全球视野，继而在上海点燃国内技术热潮，如今走进创新之都——深圳，进一步推动 Flink 技术生态在国内的深度落地与多元协同。</p><p>无论您是 Flink 开发者、数据工程师，还是关注实时智能的企业决策者，这场盛会都将为您带来不可错过的洞察与机遇！</p><h3>🌟 活动亮点</h3><p>🔹 前沿技术分享  <br/>聆听来自行业领袖与社区核心贡献者的深度演讲，掌握 Flink 最新技术演进与架构实践。</p><p>🔹 行业实战解析  <br/>覆盖多个领域真实案例，揭秘 Flink 如何驱动企业实时化转型。</p><p>🔹 开源生态共建  <br/>与百余名开发者面对面交流，参与社区讨论，共绘 Flink 开源生态的未来蓝图。</p><h2>🌟 活动议程</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047411703" alt="" title="" loading="lazy"/></p><h3>📺 线上同步直播，精彩不错过！</h3><p>无法亲临现场？我们提供全程直播！  <br/>立即预约直播，远程接入技术前沿，与会上开发者同频共振👇</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047411704" alt="" title="" loading="lazy"/></p><h3>✅ 立即报名</h3><p>复制链接或扫描二维码，锁定席位👇  <br/> <a href="https://link.segmentfault.com/?enc=LtwWMSrilwW90oJ1sGogjQ%3D%3D.1oOOV1QHaTKRFEnjU7Sm%2BFATascLsrcPk9JC5YMw5oc%3D" rel="nofollow" target="_blank">https://hdxu.cn/1BpFh</a></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047411705" alt="" title="" loading="lazy"/></p><p><em>具体会议室信息将在报名审核通过后提供</em></p><hr/><p>Flink Forward Asia 2025 · 深圳站，12月5日与您见面。</p>]]></description></item><item>    <title><![CDATA[Apache Doris AI 能力揭秘]]></title>    <link>https://segmentfault.com/a/1190000047411708</link>    <guid>https://segmentfault.com/a/1190000047411708</guid>    <pubDate>2025-11-19 17:10:54</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在初步探索了 AI 函数的可能性之后，本次我们将目光投向两个更为核心的函数：<code>AI_AGG</code> 和 <code>EMBED</code>。我们将深入解析这两个函数的设计理念、实现原理及其在业务场景中的应用，展示 Apache Doris 如何通过原生的函数设计，将文本聚合与语义向量分析无缝集成到 SQL 中，为用户提供更强大、更易用的智能数据分析体验。</p><p>相关阅读：</p><ul><li><a href="https://link.segmentfault.com/?enc=O1UX5xNvyW33z0hWMmpXYQ%3D%3D.BImxhycUJcwl82wzmwQpZxCd3ImQM9KUTgRk3K2EYl8r9t3reNRmZvncOhgoefmI" rel="nofollow" target="_blank">Apache Doris 4.0 AI 能力揭秘（二）：为企业级应用而生的 AI 函数设计与实践</a></li><li><a href="https://link.segmentfault.com/?enc=ueeGd1h7sY1sBmYU7PO77Q%3D%3D.WKbQppkVO00zqiXJ3QcOm4NlWT%2BNV4QfQvMSK2FCEgmSxJp1SmiBSo1sNU%2FETaJ6" rel="nofollow" target="_blank">Apache Doris 4.0 AI 能力揭秘（一）：AI 函数之 LLM 函数介绍</a></li></ul><h2>AI_AGG：基于 AI 的文本聚合</h2><p>聚合是数据分析中最常见的操作，但如果聚合的对象是海量的用户评论、支持工单或日志文本，传统的聚合函数难以直接处理这类非结构化文本数据。为此，Doris 支持了 <code>AI_AGG</code>，一个能够调用 AI 对文本进行聚合的函数。它让分析师可以根据自定义指令，从大量的文本中处理特定的任务。</p><h3>01 使用方法及示例</h3><blockquote>AI_AGG 详细用法请参考： <a href="https://link.segmentfault.com/?enc=oFkoHDJM%2BNCJFoAqkHRKIA%3D%3D.zEuF27rEhsgcvVXBz%2B1ywLE%2BE16ud7DfN%2Fxpg%2FQj99hLMAL4%2BEMBsMXb%2BxLSrwsDuk7yfIxdTmlmUuH6b%2BNc54uJdQY10s47yLqdld5KfXSuX7S8YuNvhh8Ln%2FCBNCXL" rel="nofollow" target="_blank">https://doris.apache.org/zh-CN/docs/dev/sql-manual/sql-functi...</a></blockquote><p><strong>示例 1：</strong> </p><p>下表模拟一个简易的客服工单：</p><pre><code class="SQL">SELECT * FROM support_tickets;
+-----------+---------------+------------------+----------------------------------------------------------------------------------+
| ticket_id | customer_name | subject          | details                                                                          |
+-----------+---------------+------------------+----------------------------------------------------------------------------------+
|         2 | Bob           | Login Failure    | Same problem as Alice. Also seeing 502 errors on the SSO page.                   |
|         3 | Carol         | Payment Declined | Credit card charged twice but order still shows pending.                         |
|         5 | Eve           | Login Failure    | Getting redirected back to login after entering 2FA code.                        |
|         1 | Alice         | Login Failure    | Cannot log in after password reset. Tried clearing cache and different browsers. |
|         4 | Dave          | Slow Dashboard   | Dashboard takes &gt;30 seconds to load since the last release.                      |
+-----------+---------------+------------------+----------------------------------------------------------------------------------+</code></pre><p><strong>我们可以通过 <code>AI_AGG</code> 对不同问题类型下客户的问题进行总结</strong></p><pre><code class="SQL">SELECT
    subject,
    AI_AGG(
        details,
        'Summarize every ticket detail into one short paragraph'
    ) AS ai_summary
FROM support_tickets
GROUP BY subject;</code></pre><p>输出示例如下：</p><pre><code class="Plain">+------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| subject          | ai_summary                                                                                                                                                              |
+------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Slow Dashboard   | The dashboard is experiencing slow loading times, taking over 30 seconds to load following the most recent release.                                                     |
| Payment Declined | A customer reports being charged twice for their order, which remains in a pending status.                                                                              |
| Login Failure    | Users are experiencing login issues, including 2FA redirection, post-password reset failures, and SSO 502 errors, despite clearing cache and trying different browsers. |
+------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</code></pre><p><strong>示例 2：</strong> </p><p>下表简易模拟了应用反馈表：</p><pre><code class="SQL">SELECT * FROM app_feedback;
+-------------+----------------+-----------+--------------------------------------------------------------------------------------+
| feedback_id | feature_module | user_name | feedback_text                                                                        |
+-------------+----------------+-----------+--------------------------------------------------------------------------------------+
|           1 | 机票预订       | 李雷      | 搜索航班非常快，价格也透明，筛选功能很好用。                                         |
|           2 | 机票预订       | 韩梅梅    | 支付后出票速度有点慢，等了快半小时，希望能改进。                                     |
|           3 | 机票预订       | 小陈      | 希望能增加更多廉价航空公司的选项。                                                   |
|           4 | 机票预订       | 马丽      | App在选择日期的时候偶尔会卡顿，体验不是很好。                                        |
|           5 | 酒店预订       | 王先生    | 酒店信息很全，图片也真实。但是取消预订的流程太复杂了。                               |
|           6 | 酒店预订       | 刘女士    | 通过App预订比其他平台便宜，还有会员折扣，非常满意。                                  |
|           7 | 行程规划       | 赵四      | 行程规划功能太棒了，可以自动推荐路线和景点，省了不少心。                             |
|           8 | 客户服务       | 孙小小    | 联系客服很方便，问题解决得也很快，给客服点赞。                                       |
|           9 | 客户服务       | 钱多多    | 电话客服总是占线，在线客服回复又很慢，希望能增加人手。                               |
+-------------+----------------+-----------+--------------------------------------------------------------------------------------+</code></pre><p><strong>我们可以通过 <code>AI_AGG</code> 对用户反馈进行总结：</strong></p><pre><code class="SQL">SELECT
    feature_module AS '功能模块',
    AI_AGG(
        feedback_text,
        '请用精确且尽可能简短地总结这些用户反馈中提到的主要问题和建议'
    ) AS 'AI反馈总结'
FROM app_feedback
GROUP BY feature_module;</code></pre><p>输出示例如下</p><pre><code class="Plain">+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| 功能模块     | AI反馈总结                                                                                                                                                                                                     |
+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| 客户服务     | 主要问题：客服电话占线，在线客服回复慢。  
主要建议：增加客服人手。                                                                                                                                                |
| 行程规划     | 主要问题：无  
主要建议：赞赏行程规划功能，建议继续优化                                                                                                                                                        |
| 酒店预订     | 主要问题：取消预订流程复杂。
主要建议：无明确建议，但肯定App预订价格优势和会员折扣。                                                                                                                          |
| 机票预订     | 主要问题：支付后出票慢（约半小时），App日期选择卡顿，廉价航空公司选项不足。
主要建议：优化出票速度，修复App卡顿问题，增加廉价航空公司选项。                                                                   |
+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</code></pre><h3>02 AI_AGG 的实现原理</h3><p>将聚合函数与 AI 结合，需要解决一个分组内文本总量可能远超模型上下文窗口的问题。如果将所有文本拼接后一次性发送给 AI， 极易出现拼接文本大于模型的最大上下文窗口的情况，<strong>而 Doris 中通过动态预聚合解决了这个问题：</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047411710" alt="02 AI_AGG 的实现原理.png" title="02 AI_AGG 的实现原理.png"/></p><ol><li><strong>上下文监控</strong>：在聚合拼接文本的过程中，<code>AI_AGG</code> 会为每一个分组维护一个内部的文本缓冲区（目前大小固定为 128K，为绝大部分 AI 可兼容的上下文窗口）</li><li><strong>动态预聚合</strong>：当新的文本行将要被加入缓冲区并会导致其大小超过阈值时，<code>AI_AGG</code> 会触发一次预聚合。它会暂停接收新数据，将当前缓冲区内的所有文本作为一个批次发送给 AI 进行一次中间任务处理。</li><li><strong>上下文替换</strong>：AI 返回的中间处理结果，其长度通常远小于原始文本。<code>AI_AGG</code> 会用这个精炼后的摘要替换掉缓冲区内原有的长文本，从而为处理更多的新文本行腾出空间。为保证聚合过程的稳定性和防止超出模型服务上限，在替换原有文本后，若加入当前文本行还是会导致缓冲区超过阈值，<code>AI_AGG</code> 会直接报错退出。</li></ol><p><strong>通过这种实现方式，<code>AI_AGG</code> 可以完全融入 Doris 的分布式查询计划，利用多节点并行计算，并由数据库自动管理聚合过程中的中间状态。因此，用户可以用熟悉的 SQL 聚合语法，在海量文本上实现高效的智能分析。</strong></p><h2>EMBED: 文本向量化函数</h2><p><code>EMBED</code> 函数的核心功能是通过 AI 将任意文本转换为高维度的浮点数向量。这个向量是文本在语义空间中的一种数学表示，它捕捉了文本的语义信息。语义相近的文本，其向量在空间中的距离也更近。</p><blockquote>EMBED 详细用法请参考： <a href="https://link.segmentfault.com/?enc=Y4urXifd%2F4B3GE8wfuYbLw%3D%3D.OGLOar6nsixstdi1D34su0szjRLIlC75SuUWU0sijAtTb%2B2YJpIcRqRLpoulm1IsZIV2Ud7p4sWdW6muPaUojtiR107jvD%2BFW5m9gWrd%2FkM8VhkoaApoTIAx7t6zQtwysfy16%2B7E0JVYEGiNVj0tzg%3D%3D" rel="nofollow" target="_blank">https://doris.apache.org/zh-CN/docs/dev/sql-manual/sql-functi...</a></blockquote><h3>01 使用方法及示例</h3><p><strong>示例 1：</strong> </p><p>下表模拟简易的行为手册</p><pre><code class="SQL">CREATE TABLE knowledge_base (
    id BIGINT,
    title STRING,
    content STRING,
    embedding ARRAY&lt;FLOAT&gt; COMMENT 'Semantic vector generated by EMBED function'
)
DUPLICATE KEY(id)
DISTRIBUTED BY HASH(id) BUCKETS 4
PROPERTIES (
    "replication_num" = "1"
);

INSERT INTO knowledge_base (id, title, content, embedding) VALUES
(1, "Travel Reimbursement Policy",
    "Employees must submit a reimbursement request within 7 days after the business trip, with invoices and travel approval attached.",
    EMBED("travel reimbursement policy")),
(2, "Leave Policy",
    "Employees must apply for leave in the system in advance. If the leave is longer than three days, approval from the direct manager is required.",
    EMBED("leave request policy")),
(3, "VPN User Guide",
    "To access the internal network, employees must use VPN. For the first login, download and install the client and configure the certificate.",
    EMBED("VPN guide intranet access")),
(4, "Meeting Room Reservation",
    "Meeting rooms can be reserved in advance through the OA system, with time and number of participants specified.",
    EMBED("meeting room booking reservation")),
(5, "Procurement Request Process",
    "Departments must fill out a procurement request form for purchasing items. If the amount exceeds $5000, financial approval is required.",
    EMBED("procurement request process finance"));</code></pre><p><strong>通过 <code>EMBED</code> 函数对文本的向量化操作，结合 Doris 支持的<a href="https://link.segmentfault.com/?enc=S4nzmo1UBaHvuOGxTY2jqQ%3D%3D.RIWivt244malghSRAJyahMgtHqphbvSD5HENfGwUjHla7f4kJG3Y7A8znlVhwDZT0uk2lHdL%2Fyc%2FOSGbxjDOYopJlsPhqNcWnLPJaN8bBbz9ah7km8bpZC5c4aHxum7V7AejIQmZiaKwIT2mpsI3Z9nNhembLqU9dy0uE2G3mig%3D" rel="nofollow" target="_blank">向量函数</a>， 可对数据进行如下操作：</strong></p><ol><li>问答检索（结合 <code>COSINE_DISTANCE</code>）</li></ol><pre><code class="SQL">SELECT 
    id, title, content,
    COSINE_DISTANCE(embedding, EMBED("How to apply for travel reimbursement?")) AS score
FROM knowledge_base
ORDER BY score ASC
LIMIT 2;
+------+-----------------------------+-----------------------------------------------------------------------------------------------------------------------------------------+--------------------+
| id   | title                       | content                                                                                                                                 | score              |
+------+-----------------------------+-----------------------------------------------------------------------------------------------------------------------------------------+--------------------+
|    1 | Travel Reimbursement Policy | Employees must submit a reimbursement request within 7 days after the business trip, with invoices and travel approval attached.        | 0.4463210454563673 |
|    5 | Procurement Request Process | Departments must fill out a procurement request form for purchasing items. If the amount exceeds $5000, financial approval is required. | 0.5726841578491431 |
+------+-----------------------------+-----------------------------------------------------------------------------------------------------------------------------------------+--------------------+</code></pre><ol><li>问题分析匹配（结合 <code>L2_DISTANCE</code>）</li></ol><pre><code class="SQL">SELECT 
    id, title, content,
    L2_DISTANCE(embedding, EMBED("How to access the company intranet")) AS distance
FROM knowledge_base
ORDER BY distance ASC
LIMIT 2;
+------+-----------------------------+---------------------------------------------------------------------------------------------------------------------------------------------+--------------------+
| id   | title                       | content                                                                                                                                     | distance           |
+------+-----------------------------+---------------------------------------------------------------------------------------------------------------------------------------------+--------------------+
|    3 | VPN User Guide              | To access the internal network, employees must use VPN. For the first login, download and install the client and configure the certificate. | 0.5838271122253775 |
|    1 | Travel Reimbursement Policy | Employees must submit a reimbursement request within 7 days after the business trip, with invoices and travel approval attached.            |  1.272394695975331 |
+------+-----------------------------+---------------------------------------------------------------------------------------------------------------------------------------------+--------------------+</code></pre><ol><li>根据文章内容进行文本相关度匹配并推荐（结合<code>INNER PRODUCT</code>）</li></ol><pre><code class="SQL">SELECT 
    id, title, content,
    INNER_PRODUCT(embedding, EMBED("Leave system request leader approval")) AS score
FROM knowledge_base
WHERE id != 2
ORDER BY score DESC
LIMIT 2;
+------+-----------------------------+-----------------------------------------------------------------------------------------------------------------------------------------+---------------------+
| id   | title                       | content                                                                                                                                 | score               |
+------+-----------------------------+-----------------------------------------------------------------------------------------------------------------------------------------+---------------------+
|    5 | Procurement Request Process | Departments must fill out a procurement request form for purchasing items. If the amount exceeds $5000, financial approval is required. |    0.33268885332504 |
|    4 | Meeting Room Reservation    | Meeting rooms can be reserved in advance through the OA system, with time and number of participants specified.                         | 0.29224032230852487 |
+------+-----------------------------+-----------------------------------------------------------------------------------------------------------------------------------------+---------------------+</code></pre><ol><li>寻找差异较小的内容（结合<code>L1_DISTANCE</code>）</li></ol><pre><code class="SQL">SELECT 
    id, title, content,
    L1_DISTANCE(embedding, EMBED("Procurement application process")) AS distance
FROM knowledge_base
ORDER BY distance ASC
LIMIT 3;
+------+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+
| id   | title                       | content                                                                                                                                        | distance           |
+------+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+
|    5 | Procurement Request Process | Departments must fill out a procurement request form for purchasing items. If the amount exceeds $5000, financial approval is required.        |  18.66882028897362 |
|    4 | Meeting Room Reservation    | Meeting rooms can be reserved in advance through the OA system, with time and number of participants specified.                                |  30.90449328294426 |
|    2 | Leave Policy                | Employees must apply for leave in the system in advance. If the leave is longer than three days, approval from the direct manager is required. | 31.060405636536416 |
+------+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+</code></pre><p><strong><code>EMBED</code> 的设计不仅是一个文本向量化工具，更是 Doris 向量分析生态的重要组成部分。</strong> 通过与其他向量函数（<code>COSINE_DISTANCE</code>， <code>L2_DISTANCE</code>， <code>INNER_PRODUCT</code>， <code>L1_DISTANCE</code> ）的无缝集成，<code>EMBED</code> 支持用户在 SQL 查询中完成从文本到向量，再到相似度计算或检索的一站式分析。</p><p><strong>示例 2：</strong> </p><p>下表模拟简易的客服常见问题文档：</p><pre><code class="SQL">CREATE TABLE support_docs (
    id BIGINT,
    title STRING,
    content STRING,
    embedding ARRAY&lt;FLOAT&gt; COMMENT '由 EMBED 函数生成的语义向量'
) DUPLICATE KEY(id)
DISTRIBUTED BY HASH(id) BUCKETS 1
PROPERTIES ( "replication_num" = "1" );

INSERT INTO support_docs (id, title, content, embedding) VALUES
(1, "系统登录问题排查",
    "当用户无法登录时，请先检查网络连接、浏览器缓存，并确认账号未被锁定。",
    EMBED("登录问题排查 网络异常 账号锁定")),
(2, "数据备份与恢复指南",
    "客户可在管理后台手动备份数据，若误删可通过支持团队申请数据恢复。",
    EMBED("数据备份 恢复 操作指南")),
(3, "账单与发票问题",
    "企业客户可在财务模块下载电子发票。如需纸质版，请提交申请工单。",
    EMBED("账单 发票 财务模块")),
(4, "API 接口调用规范",
    "开发者在调用 API 时需携带正确的访问令牌，否则将返回身份验证错误。",
    EMBED("接口调用 认证错误 访问令牌")),
(5, "服务中断应急流程",
    "若出现服务中断，技术团队需在30分钟内启动应急响应并发布公告。",
    EMBED("服务中断 应急响应 处理流程"));</code></pre><p><strong>通过 <code>EMBED</code> 函数对文本的向量化操作，结合 Doris 支持的<a href="https://link.segmentfault.com/?enc=qlMGShQqdGVFWxEGgh2Ymw%3D%3D.2JsfDaZJIMcpLOtPLVaQ8nTScKJqUpvsgUVJP97Kh1bElPuuOblqsDvzie9Mmecf1LuSD8wj7fnVxs6X3D6he8eRpj%2BTvl31gZsAiEKsTFGtks6U2dqN0T%2BdAvXQ8c75Of%2FxK%2Fkqdn3S%2BbwBgADkNoH3OIM1cVRBgp8DJHuwgQc%3D" rel="nofollow" target="_blank">向量函数</a>， 可对数据进行如下操作：</strong></p><ol><li>问答检索（结合 <code>COSINE_DISTANCE</code>）</li></ol><pre><code class="SQL">SELECT 
    id, title, content,
    COSINE_DISTANCE(embedding, EMBED("登录不上系统怎么办？")) AS score
FROM support_docs
ORDER BY score ASC
LIMIT 2;
+------+--------------------------+--------------------------------------------------------------------------------------------------------+-----------+
| id   | title                    | content                                                                                                | score     |
+------+--------------------------+--------------------------------------------------------------------------------------------------------+-----------+
|    1 | 系统登录问题排查         | 当用户无法登录时，请先检查网络连接、浏览器缓存，并确认账号未被锁定。                                   | 0.3183002 |
|    4 | API 接口调用规范         | 开发者在调用 API 时需携带正确的访问令牌，否则将返回身份验证错误。                                      | 0.5599254 |
+------+--------------------------+--------------------------------------------------------------------------------------------------------+-----------+</code></pre><ol><li>问题分析匹配（结合 <code>L2_DISTANCE</code>）</li></ol><pre><code class="SQL">SELECT 
    id, title, content,
    L2_DISTANCE(embedding, EMBED("接口调用时提示没有权限")) AS distance
FROM support_docs
ORDER BY distance ASC
LIMIT 2;
+------+--------------------------+--------------------------------------------------------------------------------------------------------+-----------+
| id   | title                    | content                                                                                                | distance  |
+------+--------------------------+--------------------------------------------------------------------------------------------------------+-----------+
|    4 | API 接口调用规范         | 开发者在调用 API 时需携带正确的访问令牌，否则将返回身份验证错误。                                      | 0.6471552 |
|    1 | 系统登录问题排查         | 当用户无法登录时，请先检查网络连接、浏览器缓存，并确认账号未被锁定。                                   | 0.9831962 |
+------+--------------------------+--------------------------------------------------------------------------------------------------------+-----------+</code></pre><ol><li>根据文章内容进行文本相关度匹配并推荐（结合<code>INNER PRODUCT</code>）</li></ol><pre><code class="SQL">SELECT 
    id, title, content,
    INNER_PRODUCT(embedding, EMBED("账单 发票 报销流程")) AS score
FROM support_docs
ORDER BY score DESC
LIMIT 2;
+------+--------------------------+-----------------------------------------------------------------------------------------------+-----------+
| id   | title                    | content                                                                                       | score     |
+------+--------------------------+-----------------------------------------------------------------------------------------------+-----------+
|    3 | 账单与发票问题           | 企业客户可在财务模块下载电子发票。如需纸质版，请提交申请工单。                                | 0.8098868 |
|    5 | 服务中断应急流程         | 若出现服务中断，技术团队需在30分钟内启动应急响应并发布公告。                                  | 0.3729638 |
+------+--------------------------+-----------------------------------------------------------------------------------------------+-----------+</code></pre><ol><li>寻找差异较小的内容（结合<code>L1_DISTANCE</code>）</li></ol><pre><code class="SQL">SELECT 
    id, title, content,
    L1_DISTANCE(embedding, EMBED("服务中断 处理 指南")) AS distance
FROM support_docs
ORDER BY distance ASC
LIMIT 3;
+------+-----------------------------+--------------------------------------------------------------------------------------------------------+----------+
| id   | title                       | content                                                                                                | distance |
+------+-----------------------------+--------------------------------------------------------------------------------------------------------+----------+
|    5 | 服务中断应急流程            | 若出现服务中断，技术团队需在30分钟内启动应急响应并发布公告。                                           | 13.94832 |
|    2 | 数据备份与恢复指南          | 客户可在管理后台手动备份数据，若误删可通过支持团队申请数据恢复。                                       | 24.65827 |
|    1 | 系统登录问题排查            | 当用户无法登录时，请先检查网络连接、浏览器缓存，并确认账号未被锁定。                                   |  24.9747 |
+------+-----------------------------+--------------------------------------------------------------------------------------------------------+----------+</code></pre><h3>02 灵活的向量维度控制</h3><p>通过 Doris 内置的 <code>RESOURCE</code> 机制，用户在配置 AI  Resource 时，可以设置 <code>ai.dimensions</code> 参数来精确指定生成向量的维度。用户可以根据具体的业务场景和性能考量，选择生成高维向量以保留更丰富的语义信息，或选择低维向量以节约存储空间和加速计算。这种灵活性使得 <code>EMBED</code> 函数能够更好地适应从轻量级语义匹配到高精度向量检索等多样化的分析需求，让用户在成本与效果之间找到最佳平衡。</p><blockquote><strong>注意</strong>：在使用 <code>dimensions</code> 参数时，请务必确认 <code>RESOURCE</code> 中配置的模型支持您所指定的维度，否则可能导致请求错误。此外，Doris 内部对部分不支持维度定制的模型（例如 OpenAI 的 <code>text-embedding-ada-002</code>）做了限制。对于这些模型，即使在 <code>RESOURCE</code> 中设置了 <code>dimensions</code> 参数，该设置也将被忽略，函数将返回模型默认的维度。</blockquote><h2>总结与展望</h2><p>借助<code>AI_AGG</code> 与 <code>EMBED</code> 函数，Apache Doris 拥有了了强大的智能分析能力，极大地拓展了数据分析与智能应用的边界。<code>AI_AGG</code> 通过其动态预聚合机制，将非结构化文本的智能聚合分析带入数据库，轻松应对海量用户评论、日志分析等场景。而 <code>EMBED</code> 函数则与 Doris 的向量函数无缝集成，提供从文本到语义向量、再到相似度检索的一站式解决方案，极大简化了问答系统、内容推荐等应用的开发。这些功能使得 SQL 语言本身具备了驾驭 AI 模型的能力，让每一位数据分析师都能以低成本、高效率的方式，挖掘数据中更深层次的语义价值。</p><p>展望未来，Doris 将继续深化 AI 与数据库的融合。我们将致力于优化模型调度与计算性能，并探索更多如多模态数据分析、AI Agent 交互等前沿功能，持续降低 AI 技术的使用门槛，让数据驱动的智能决策无处不在。</p>]]></description></item><item>    <title><![CDATA[能耗异常智能诊断怎么帮助企业减少能源浪费]]></title>    <link>https://segmentfault.com/a/1190000047411761</link>    <guid>https://segmentfault.com/a/1190000047411761</guid>    <pubDate>2025-11-19 17:10:12</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在现代工业体系中，能耗管理不再是简单的成本计算，而是一场依赖技术深度参与的变革。传统模式中，能源异常往往依赖人工经验推测或事后统计追溯，无论是铝业电解槽的涌浪参数，还是工厂数百台设备的待机能耗，都因其断点式观察与高维复杂性而难以把握。广域铭岛通过构建Geega工业互联网平台，将"能耗异常智能诊断"从实验室推进至现实生产场景，以机器学习算法为经纬，重塑了能源管理的技术路径。<br/>系统层面的变革始于对异常模式的动态感知。 智能诊断技术通过立体化数据采集，融合电流波动、振动频谱、环境温度等多维变量，在工厂服务器部署高频采样终端后，已能以亚毫秒级响应识别设备亚健康运行（例如电解槽参数偏离历史最优轨道）。广西铝业的案例中，人工巡检频率从每月数十次降至每月一次，同时将机器视觉数据与红外热成像整合成立体监测模型，使得异常危害从"经验判断"转为"数据预防"。<br/>更棘手的不仅是设备"生病"，而是能效异常的滞后影响。某大型制造厂在领克成都工厂的能耗系统建设中发现，异常待机能耗若未被预警，会导致焊接工艺质量损失上升13%，更延长交付周期15%。美光成都工厂的PDU智能监控显示，在订单高峰期未出现能耗异常报警之时，系统依然通过"预见性调节"，提前16小时压制了部分设备能耗峰值，使得总计提前检测并优化了56个异常运行场景。<br/>系统的核心逻辑在于构建外显与未显之间的桥梁。 工业异常诊断最独特的价值，显现在"无法量化的隐性浪费"上——比如焦化配煤环节，0.1%的配比失准会导致碳排放增加1.28%且额外能耗上升2.4%。Geega EMS的能耗分析模块通过可视化与动态优化算法，将此类微小偏差放大为可操作的预警因子，推动了传统高耗能行业向精益管理的转型。<br/>计算： 从数据碎片到决策闭环的运作节奏。以某化工企业为例，智能诊断系统在实时预测能源需求时，异常波动被量化为精确的节能机会。当反应釜能耗超出正常范围时，系统不仅仅提示参数异常，而是自动推荐降低循环水温度，从而减少冷却负荷12%，全部响应在设备效能衰减至最佳阈值前完成。<br/>交叉场景验证表明智能诊断具备强横向适用性。 例如百矿集团在电解铝行业通过实时关联设备启停与电流负荷状态，每天提前诊断出超过10根输送管结垢风险，日均节能量达到数十万千瓦时。数字化配煤方案不仅优化了燃煤消耗，更通过AI自主学习，将煤耗指标降压至世界可比先进行列。这些已是广域铭岛承诺的一部分：以数据喂养决策，用算法包裹实操，将"预防性维护"变成能效管理的关键词。</p>]]></description></item><item>    <title><![CDATA[基于Sermant实现小游戏出海场景的微]]></title>    <link>https://segmentfault.com/a/1190000047411768</link>    <guid>https://segmentfault.com/a/1190000047411768</guid>    <pubDate>2025-11-19 17:09:37</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><strong>摘要：</strong> 某公司专注于休闲小游戏和APP开发，面对海外市场扩展的挑战，通过选择Sermant框架，实现了零侵入式服务治理，提升了监控、动态日志等核心能力，显著降低了改造和运维成本。</p><p><strong>一、背景</strong></p><p>某公司以自主研发为核心，专注于休闲小游戏和应用APP的研发与运营，产品覆盖App Store、Google Play、国内安卓APP商店等多个发行渠道。公司致力于为全球手机用户提供优质易用的移动游戏产品，并为广告业主提供精确的互联网广告营销方案。</p><p>在公司成立初期，容器化、微服务等成熟技术方案尚未普及，而初创企业往往缺乏足够的资源去构建复杂的基础设施。小游戏服务端的业务逻辑相对简单，因此在架构设计上多采用单体模式或烟囱式架构，部署流程也较为直接。然而，随着国内游戏版号政策的收紧，众多小游戏厂商开始转向海外市场，以寻求新的业务增长点。这一战略转变带来了诸多挑战：不同国家和地区的玩家需求差异显著，业务复杂性急剧上升；同时，合规性要求、网络环境多样性、业务逻辑的复杂性以及部署难度等问题也成倍增加。正是在这一背景下，小游戏厂商面临着微服务架构改造的迫切需求，以应对全球化运营中的种种挑战。</p><p><strong>二、服务现状</strong></p><p>截至目前，该公司的中台服务体系已涵盖了80多个核心服务，在业务高峰期，服务实例数量超过900个，单个服务的峰值QPS达到5K以上。同时，海外流量占比超过50%，业务覆盖范围遍及全球170多个国家和地区。</p><p>在这样的业务规模和技术背景下，该公司面临着复杂多样的基础设施环境：自建机房、IDC机房、多家主流云服务商的公有云资源，以及国内外多区域部署的网络架构。这种混合云和多区域部署的复杂性，对微服务架构提出了更高的要求。不仅需要确保服务的高可用性和稳定性，还要兼顾跨区域、跨平台的网络优化和资源调度效率。因此，对微服务架构设计必须充分考量这些复杂的网络环境和业务需求，以实现全球化部署和高效运维的目标。</p><p><strong>三、微服务架构选型</strong></p><p>在微服务架构演进的落地实践中，该公司探索了多种架构升级的解决方案，包括 <strong>Nacos SDK 接入</strong>、<strong>Consul Agent 方案</strong>、<strong>Service Mesh 网格化架构</strong>，以及阿里开源的 <strong>Koupleless 模块化方案</strong>。这些方案各具特色，在不同应用场景下有一定优势，同时也存在明显的局限性。</p><p><strong>3.1 SDK</strong> <strong>方案（如</strong> <strong>Nacos</strong> <strong>）</strong></p><p><strong>优势</strong>：成熟度高，与Spring Boot等框架无缝集成，适合快速搭建基础能力。</p><p><strong>痛点</strong>：存量系统改造需业务方全量升级代码、测试验证，该企业80+服务为例，历史系统（如老旧订单模块）改造需跨团队协调，周期长达数月，且后续能力迭代仍需业务侧同步适配，协调成本极高。</p><p><strong>3.2 Agent</strong> <strong>方案（如</strong> <strong>Consul</strong> <strong>）</strong></p><p><strong>优势</strong>：无代码侵入，通过独立进程提供服务发现等基础功能。</p><p><strong>痛点</strong>：无法深度集成业务逻辑（如基于业务参数的流量控制），且Agent进程需独立维护，升级时易引发兼容性问题（如与JDK版本的冲突）。</p><p><strong>3.3 Service Mesh</strong> <strong>方案</strong></p><p><strong>优势</strong>：治理能力与业务解耦，支持精细化流量管理。</p><p><strong>挑战</strong>：强依赖容器化技术，传统非容器化系统（如物理机部署的支付服务）改</p><p>造成本陡增，且Sidecar代理增加链路延迟，对高并发场景性能影响显著。</p><p><strong>3.4</strong> <strong>模块化方案（如</strong> <strong>Koupleless</strong> <strong>）</strong></p><p><strong>优势</strong>：轻量化模块拆分，降低新业务接入成本。</p><p><strong>风险</strong>：技术生态尚未完善（如监控工具缺失），复杂业务场景下模块依赖管理易失控，生产环境稳定性验证案例不足。</p><p><strong>四、为什么选择 Sermant</strong></p><p>Sermant是一款创新的Proxyless Service Mesh框架，其设计理念和技术实现极具巧思。它基于Java Agent技术构建，与业务服务运行在同一个进程中，因此性能损耗极低，同时能够实现对业务服务的高度控制，完全满足各种个性化需求。首先，由于采用Java Agent的实现方式，Sermant对业务代码做到了<strong>零侵入</strong>，业务方无需修改任何代码即可接入。其次，框架的升级与业务服务完全解耦，维护和管理更加便捷，大幅降低了运维成本。</p><p>与业界常见的Java Agent框架相比，Sermant的独特之处在于其完整的功能覆盖。虽然许多Java Agent框架主要用于调用链追踪、监控等可视化场景，但Sermant将其扩展到了全面的服务治理领域，包括流量管理、服务发现、监控、多活容灾等核心功能。</p><p><strong>五、基于Sermant实现的功能</strong></p><p>基于Sermant框架层，该公司自主研发了一系列功能强大的插件，全面提升了服务治理的能力。这些插件覆盖了监控、服务注册与发现、配置中心、动态日志管理、日志染色等核心领域，构建了一个完整且高效的服务治理体系。</p><p><img width="723" height="538" referrerpolicy="no-referrer" src="/img/bVdm57T" alt="1.png" title="1.png"/></p><p><strong>5.1</strong> <strong>监控场景</strong></p><p>通过集成Sermant和Prometheus，先实现了实时采集服务运行的关键指标，提供多维度的可视化分析，包括<strong>JVM监控、接口监控、服务调用外部监控、SQL执行监控等。例如SQL执行监控</strong>可以实时监控SQL语句的执行性能，包括执行时间、扫描行数、锁等待等关键指标，识别慢查询与潜在优化点，提升数据库操作效率，降低系统负载。</p><p>基于Sermant技术，实现了线上服务的无缝监控接入，无需进行任何代码改造或业务逻辑调整。该解决方案已成功应用于1000+线上服务节点，有效降低了服务治理过程中对业务系统稳定性的影响，显著提升了系统的可观测性和运维效率。通过非侵入式的服务治理方式，确保了业务系统的连续性和稳定性，为大规模微服务架构的监控管理提供了可靠的技术支撑。</p><p><img width="723" height="535" referrerpolicy="no-referrer" src="/img/bVdm57U" alt="2.png" title="2.png" loading="lazy"/></p><p><strong>5.2</strong> <strong>动态日志与日志染色</strong></p><p>基于Sermant，该公司开发了动态日志与日志染色核心能力，来解决企业实现高效运维的问题。其中动态日志支持运行时动态调整日志级别，无需重启服务即可在高负载场景减少日志输出以降低性能损耗，或在排查问题时快速开启详细日志，平衡系统性能与诊断效率；日志染色通过为请求链路注入唯一标识，实现跨服务全链路日志精准追踪，复杂业务场景下问题定位效率显著提升。两项能力均通过Java Agent技术实现，业务零代码侵入，分钟级完成接入，避免传统方案改造风险，同时支持策略实时生效，降低运维成本。</p><p><strong>5.3</strong> <strong>注册中心</strong><br/>服务注册与发现插件实现了服务实例的自动化管理和高效路由；企业的集中式网关架构可以借助 SpringBoot 注册插件实现去网关并接入 Nacos 等注册中心，逐步向云原生无代理服务网格架构演进，并具有如下优势：</p><p>• 代码无侵入，降低企业接入成本。</p><p>• 服务治理功能升级只需更新 Sermant，业务应用不用重新出包，降低升级成本。</p><p>• 微服务可以灰度接入，保证架构升级的平滑演进，如下图所示。</p><p><img width="723" height="253" referrerpolicy="no-referrer" src="/img/bVdm57V" alt="3.jpg" title="3.jpg" loading="lazy"/></p><p><strong>5.4</strong> <strong>配置中心</strong></p><p>基于Sermant实现了优先级加载、灰度发布和动态配置的能力。通过灵活的优先级管理，能够在复杂环境中精准控制配置的加载顺序，避免配置冲突，提升系统的可维护性；在可控范围内验证配置变更的效果，确保业务平滑过渡，最大限度减少对线上环境的影响。通过动态配置能力，能够快速适应业务需求变化，同时确保系统稳定性，为业务的持续迭代与优化提供坚实的技术保障。<br/>  </p><p><img width="723" height="346" referrerpolicy="no-referrer" src="/img/bVdm57P" alt="4.png" title="4.png" loading="lazy"/></p><p><strong>六、落地实施</strong></p><p>·       全面落地应用：已实现全量接入，覆盖 80+ 服务 和 900+ 实例，形成了稳定的应用生态。</p><p>·       成本显著优化：有效节省 20% 的运维成本 和业务沟通成本，提升了整体协同效率。</p><p>·       插件化能力输出：公司公共组件通过 插件化 形式提供，减少了业务侧频繁进行 SDK 升级的工作量，大幅降低了升级推动的难度与成本。</p><p><img width="723" height="549" referrerpolicy="no-referrer" src="/img/bVdm57W" alt="5.png" title="5.png" loading="lazy"/></p><p><strong>七、展望</strong></p><p>基于Sermant框架，自主研发插件，期望解决多数据中心和跨区域服务发现的复杂问题，实现高效的跨区域网络访问。具体而言，插件通过智能路由和负载均衡机制，能够自动识别并选择最优的数据中心或区域节点，确保服务调用的高效性与稳定性。</p><p>同时，为了进一步提升系统性能，期望通过拦截请求的方式，将同步调用转化为异步化处理，并结合虚拟线程技术，降低跨区域访问的延迟，提升系统的并发处理能力。</p><p><img width="723" height="481" referrerpolicy="no-referrer" src="/img/bVdm57X" alt="6.png" title="6.png" loading="lazy"/></p><p>Sermant的实践充分展现了字节码增强技术在微服务治理领域的巨大潜力。通过零侵入、高性能的技术特性，该公司成功解决了传统微服务架构中的诸多痛点，为业务提供了更加灵活、高效的治理能力。Sermant开源社区和行业伙伴持续深入合作，分享实践经验，共同探索字节码增强技术的创新应用，致力于微服务治理领域的持续发展与突破。</p><hr/><p> <br/>Sermant<em> </em>作为专注于服务治理领域的字节码增强框架，致力于提供高性能、可扩展、易接入、功能丰富的服务治理体验，并会在每个版本中做好性能、功能、体验的看护，广泛欢迎大家的加入。</p><p><em>• Sermant官网：<a href="https://link.segmentfault.com/?enc=cvjBEs5YcJejjMKtXCgJWQ%3D%3D.VD2R1s2cJzUidjch3e1NE5TJtqHmRdsd%2Fq8TBJCcuUc%3D" rel="nofollow" target="_blank">https://sermant.io</a></em></p><p><em>• GitHub仓库地址：<a href="https://link.segmentfault.com/?enc=2kDtvwoMorVe15kYCSquOQ%3D%3D.mcTf8JDYkuakwV8g1lTYyT%2B%2B%2FeYDcBgJh2bKNreWPDJ0R3dP89xhANKEH4ZDbYLE" rel="nofollow" target="_blank">https://github.com/sermant-io/Sermant</a></em></p><p><em>• 扫码加入Sermant社区交流群</em></p><p><img width="723" height="401" referrerpolicy="no-referrer" src="/img/bVdm57Y" alt="7.png" title="7.png" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[尺寸精准管理：制造业的“数字眼睛” 雨大]]></title>    <link>https://segmentfault.com/a/1190000047411770</link>    <guid>https://segmentfault.com/a/1190000047411770</guid>    <pubDate>2025-11-19 17:08:39</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在现代制造业里，尺寸精准管理听起来挺技术的一个词，但其实它直接关系到产品能不能严丝合缝、性能是不是稳定。小到芯片上的线路，大到汽车车身、风电叶片，尺寸上差一点点，都可能变成大问题——比如整车异响、电池接触不良，甚至存在安全隐患。<br/>以前工厂怎么管控尺寸呢？大多靠的是离线检测，比如把零件搬到三坐标测量仪上抽查。这种方法有点像“事后算账”，查出来有问题的时候，一批产品可能都已经做完了，损失造成、返工耗时，还很难精准定位到底是哪一环节出了问题。<br/>举个例子，汽车焊接车间里，几百个零件拼在一起，每个零件差一丝，累积起来可能就是车门关不严或者缝隙不对称。传统方法往往要到最终装配完才看得出来，但那时再调整，成本就太高了。同样，电池模组中电芯的极柱高度或者支架孔距如果没控制好，容易导致连接不良，甚至引发过热。<br/>那有没有更“聪明”的办法呢？近几年，随着物联网、实时传感和人工智能等技术的发展，尺寸管理也开始变得“动态”和“主动”。我们不再只是事后检测，而是边做边测、实时调整——这就相当于给制造过程装上了一双“永不疲倦的眼睛”。<br/>比如有些工业互联网平台，如广域铭岛，就在做一些有意思的尝试。他们通过布设大量传感器实时抓取数据，再结合工艺模型和算法，做到实时诊断甚至预测尺寸偏差。听说有家汽车厂在焊装线上用了这类方案后，系统可以自动判断出是哪个夹具发生了微米级的偏移，并且自动提示调整，不用再等到整辆车下来才发现不对。这样一来，产线的响应速度大大提高，一次合格率也上去了。<br/>类似地，在铝合金压铸这类热加工工艺里，零件冷却时尺寸其实一直在变。过去老师傅靠经验预估，现在通过机器学习，系统能根据实时温度、压力等参数预测最终尺寸，甚至自动反向修正加工代码，真正做到“做出来就是对的”，节省了不少后续加工时间和材料。<br/>所以说，尺寸精准管理早就不是拿着卡尺量一量那么简单了。它已经变成一套融合实时感知、智能诊断和动态补偿的“系统级工程”。好的尺寸管理，不仅能提升产品质量和一致性，更能够减少浪费、提高效率——这在制造业竞争越来越激烈的今天，早就不再是“可选项”，而是一项核心能力。</p>]]></description></item><item>    <title><![CDATA[阿里云可观测 2025 年 10 月产品]]></title>    <link>https://segmentfault.com/a/1190000047411772</link>    <guid>https://segmentfault.com/a/1190000047411772</guid>    <pubDate>2025-11-19 17:08:04</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>本月可观测热文回顾</h2><p><strong>文章一览：</strong></p><p><a href="https://link.segmentfault.com/?enc=%2Bs3gne3qYjMYi8e82aNB1A%3D%3D.6HnAOyTxObkmyXEg9ffolC7XK2J15wjnx%2FPEMdeotYzFQkNeOb1Cse1rC3G7Or%2Be1Zac9nMAH0c43fKl%2BnQHaG0JEdLujqCYMtLzWf7BmVuinLmBCAAqdKlFryqSpqIzt%2FpnDlojfx3PWaM3pCppv%2BP4FaOyYRgsp5X7n192wUf8HxvzKxNZkpC9l633LeW6" rel="nofollow" target="_blank">用户说“App 卡死了”，你却查不到原因？可能是监控方式错了</a></p><p><a href="https://link.segmentfault.com/?enc=eHFsTVy3sAw2MHVBqkF9yw%3D%3D.NGfTknrcIN%2BD0ftKGybANsi2RCDr64jVGlWejsciFAj1rt0i0J9sUv4fpfb%2F6eUbeVwp8X6JY1kqSHvEszYFuI2kn72aAfaXNHxsuC80yC5YO77oNApDmp7sv2Z0RhV9%2FVJzU1klptE7vSkZiku3MDVXDdpxHdjufY1H2OHX52ADH7TdJU%2F14cJvSPApx3EN" rel="nofollow" target="_blank">清理祖传 AK 不怕炸锅：基于 UModel 的云监控 2.0 身份凭证观测实践</a></p><p><a href="https://link.segmentfault.com/?enc=w%2Fz8%2BUDOKCgiOthCrW0veg%3D%3D.XyqyZuP6vF3LuwLbPmFGiitTH4%2BgDVobpdjqiMlXuAUfZQPYijveHfs6X941X9pkg1SvnnBLpDFntudblcfk0QdFHBZnSNWyFnVGyFsK8C4qklhLieYxyeJ5XPpLm5dsyMZ%2BU3a43Ls2OnLbXRnwodfVi7QW9x6Wya3WK1ErgOV3JkKWqGNJpKG5U4jbwEBG" rel="nofollow" target="_blank">告别手动埋点！Android 无侵入式数据采集方案深度解析</a></p><p><a href="https://link.segmentfault.com/?enc=hQPhu7%2FxV0zXOI%2FO4d9hhg%3D%3D.8CEh%2Btg%2FJVEJAYjilV7eRcofR%2B%2FdMcQ2ceu1dwRswUarYY20vgjZ%2Fey5OGgBeDgp1clUG7uAamm4pYZ122dULtvNDnvfsvddthzqpiKs2RCAwLzdrvXQmh9hFhoxBA1XZFo7q7LVdHJRt6SuS6ZczxnSJZVaGHEFUjTrDn7kfs5sI4IyZKYiGWq2rAWrErhd" rel="nofollow" target="_blank">从数据孤岛到智能洞察：构建面向未来的 Operation intelligence 体系</a></p><p><a href="https://link.segmentfault.com/?enc=YlGgzlvhRMfqs2fKGgZEfg%3D%3D.4uKy0Xpth9DOOlKXhRdXW51t5bv4dssHGtbKayVGKM9wBFBCgJ3yc5WdN97QOLApBpMmrN0BEmBaO%2B%2Bh%2FiBtZdFb0%2BTIknUsAD4eO0JAer12C4HUSX2y20NRgtCGRJJ8bEx99mwcDVGxGaWKJqomGhfaZhW0MMXySg8jaHzTh28ekMms%2BvUBeFi7OPd8dEQW" rel="nofollow" target="_blank">从“天书”到源码：HarmonyOS NEXT 崩溃堆栈解析实战指南</a></p><p><a href="https://link.segmentfault.com/?enc=xTOkup1EM4f9O2%2FdRJXlJA%3D%3D.yNTmWPHI7PAln3KVIILyFyChRhyRPuvEQWXHC2fEn2bKBd3FKq2i%2BGujEXRBG0i%2FVYyn%2BkvgQ3eZMYc6xFEHrIbCdnXVug8Tf%2FY74A%2BixxcZLWMaBzAPe59gqcZX8hzmsyRWOfpHPRF%2FlXlkyI2gczMc0F8Tv7iP807H%2BF229Yjppua7x6cCITqneKOVva06" rel="nofollow" target="_blank">阿里云加持，《泡姆泡姆》让全球玩家畅享零延迟冒险</a></p><p><a href="https://link.segmentfault.com/?enc=xW6r0n1exWjUJCRsKwQozA%3D%3D.CnANl0V06eAOAgFzr3b1MwpTP6gX4tgYhf8Sb2sqyfhECALdmxKycQjKa0NRrH%2B7s7oS9eukePQlk8XFmZMlvXyfzNnePKu46LkjOqFySyM6fEccEG7obwSnPvpw%2BCOvb2ZuBBSuaZfCSLbbAUFOpEfp8yp7BoorfnNzfuEOgNK6L6MhuRZ2GtvTj2wK7WSb" rel="nofollow" target="_blank">16 倍性能提升，成本降低 98%！ 解读 SLS 向量索引架构升级改造</a></p><p><a href="https://link.segmentfault.com/?enc=bxiGkjSGjClUaO2ZHT5vKQ%3D%3D.N7pAFPeV5YA%2BRwZTbXk8q0CCMG3ZgZ%2BVxvQ8uUT1Pykclh4uKz7NisJZ6v1WyGOolEqOr4cHgHCTrehwxbEaDLUQALWs%2BSzEmQIQLABdiE7I%2FwOuaeHmnJXmkZzCHqlv10kJdH03PAwBLkB3jRJc20JaCEpURYuqakA2xGop1Az4VV56d1Pe9iUQYVLS5zlV" rel="nofollow" target="_blank">移动端性能监控探索：iOS RUM SDK 技术架构与实践</a></p><p><a href="https://link.segmentfault.com/?enc=R8eZATFY5co%2Fmal4FyT%2FJA%3D%3D.krN%2FaMeHnkiJZv9W8lcZlO69yynb3%2F8hBucMLYH5DsU%2B%2F90eCjPEuGFVKhrDP0B5QRQLGlS1f7531sEsWOFi9O9IohL1bPmeVNStOACgzzVQRnDGEvtkwIQ5niQaFEfHOiBcF968auG9Jwc5gQ0AUmJVmm8ygYZv118DEvI2tAn7lgpNzJHv6qNUmdsva1Kc" rel="nofollow" target="_blank">云栖实录：重构可观测 - 打造大模型驱动的云监控 2.0 与 AIOps 新范式</a></p><p><a href="https://link.segmentfault.com/?enc=jdzAyRJuYPdYJvKKc4vZrg%3D%3D.p79uLY8iVX7uQI4VhSfC2BYY6Q3uyHXl6AjTyNxcEUyLuFzUybcGxvZRU34S6ADrjlD8v0CkAJ7Y%2B55cNoMOHwHFqY%2Bf7crNG2IquU9SXEGM4BAzk%2FmpsPYKy1JIMpThKlRBm9kFO5IVC3D4VKa8m3Xz1aYh3NVKVtAPbR%2FZHZlVc5HA9ainee0x%2BufrQA8n" rel="nofollow" target="_blank">移动端性能监控探索：可观测 Android 采集探针架构与实现</a></p><p><a href="https://link.segmentfault.com/?enc=9RI1%2BChXFwbKjx5rZJyEpg%3D%3D.fC1bgkwBSv7xXH9%2FtU%2FrsMEauxkAqPVAwQ%2FJmPy6eM%2BZJEf%2Bh8k7%2BwCep8o6lr%2BDcngCoiPEbdIO8qnQQf5CViy0qzVtBfLd8ey4FBCMgKUqHl%2FiEAuOo8%2FUVuz6R%2F2dXseogEeXZKJEfmxHCZWRMkGWwniahWD5PHbwZmGwG451gCq973%2BJV6lHWbi72qHR" rel="nofollow" target="_blank">零代码改造 + 全链路追踪！Spring AI 最新可观测性详细解读</a></p><h2>功能快报</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047411774" alt="image" title="image"/></p><p>点击<a href="https://link.segmentfault.com/?enc=gP80K8aPrzzOyWJWgJqEQQ%3D%3D.rNLd8en34JhLq616NRFMU0bsAopyHajCQYL3orrqR5bq1UqtR91CUD9ukA3Lg%2FqY" rel="nofollow" target="_blank">此处</a>，了解更多产品详情。</p>]]></description></item><item>    <title><![CDATA[推荐哪些设计研发协同平台？ 月下水光 ]]></title>    <link>https://segmentfault.com/a/1190000047411786</link>    <guid>https://segmentfault.com/a/1190000047411786</guid>    <pubDate>2025-11-19 17:07:32</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在全球制造业竞争日益激烈的背景下，企业的研发能力和协同效率成为影响产品上市周期、质量水平及市场响应速度的核心因素。设计研发协同平台应运而生，成为制造业转型过程中不可替代的战略工具。作为这一领域的创新者，广域铭岛数字科技有限公司推出了FastWorx设计研发协同平台，凭借其强大的功能架构和技术深度，为企业提供了一种全新的研发管理方式。<br/>FastWorx平台不仅仅是传统研发流程的工具化升级，更是对以客户为中心的设计理念的一次颠覆性重构。其核心优势在于通过模块化设计和可配置BOM管理，打通了包括设计、工艺、排产及交付在内的全链条环节。系统以动态平衡的方式协调多方需求，使企业能够快速响应市场变化，同时确保各环节数据的一致性与可追溯性。更为重要的是，该平台整合了人工智能的技术力量，能够在研发的每一个环节中实现智能辅助，极大缩短人工操作的时间，而工程师则可以将精力集中于更具创造性的任务中。<br/>FastWorx平台的弹性设计能力使其能够适应不同规模、不同行业的制造企业需求，但其本质是围绕数据共享与流程优化而构建的完整生态系统。无论是市场需求的快速转化，还是设计过程的动态反馈，系统都能通过统一的BOM管理和结构克隆功能，实现资源的高效配置。尤其在产品设计的初期阶段，系统支持客户以多种视角参与设计过程，这种开放式的设计理念不仅强化了企业的市场导向，还在潜移默化中提升了客户满意度。<br/>在执行层面，平台提供了闭环式的变更管理模式。从设计变更的提出，到上下游环节的同步执行，每一个步骤都被纳入系统内进行实时追踪和分析。这种机制保证了企业在产品迭代与优化过程中不会出现数据混乱或版本冲突的问题，同时提高了决策的准确性与透明度。值得一提的是，平台还通过3Dweb引擎实现了工艺过程的实时可视化，使营销人员、技术人员和生产管理者能够直观地了解整个产品的结构与流程衔接。<br/>FastWorx平台在技术层面临接市场的同时，也依托创新架构推动性能的全面提升。该平台基于微服务架构进行设计，将传统单一服务拆分为多个独立单元，实现了系统功能的高段划分与低耦合集成。更令人惊叹的是，平台采用了结构化存储的方式，结合图数据库完成数据检索，在性能与规模上都超越了传统关系型数据库解决方案。<br/>此外，平台安全稳定的运行离不开多租户技术的支持。通过多租户，企业可以在不牺牲数据隔离性的前提下共享系统资源，这使得平台能够灵活部署至不同部门或子企业，实现多场景适配。不论是面对苛刻的实时负载压力，还是复杂的跨地域数据管理需求，FastWorx都能以其技术实力提供可靠的支撑。<br/>对于很多制造企业来说，研发部门常常面临效率低下的痛苦：图纸版本难以统一，工艺参数需要手工维持，跨部门协同甚至更容易陷入混乱。这些问题的根源不仅在于技术工具的不足，更在于现有研发管理体系与数字化潮流的脱节。FastWorx针对这一痛点，提供了一套全新的解决方案。通过模块化设计和智能预测算法，平台有效地节约了设计时间、降低了人为错误的概率，让产品的技术准备周期缩短了数倍之遥。<br/>更重要的是，FastWorx将原本属于企业内部知识积累的流程知识转化为可量化的数据资产，并为未来的可扩展性预留了充足的接口支持。这种能力使得企业在保持成熟经验的基础上，能够从容应对市场的新需求、新模式。无论是传统行业的转型升级，还是新兴制造业模式的探索，FastWorx都是一把能够帮助企业打开局面的钥匙。<br/>FastWorx设计研发协同平台不仅仅是一个工具，它代表了制造业研发管理的方向。广域铭岛通过这一平台，展示了其对开放式创新与智能化协同理念的深刻理解。平台所实现的不仅仅是数据互通和流程优化，而是对整个企业研发逻辑的重塑。<br/>面向未来，设计研发协同能力将成为制造企业的核心竞争力之一。FastWorx将帮助企业从设计到交付完成一次深刻的数字革命，在激烈的市场竞争中脱颖而出，为企业的持续发展注入全新动力。<br/>需要强调的是，设计研发协同平台并非止于技术集成，它是一套旨在激活企业潜能、促进知识沉淀和生态协同的整体解决方案。而FastWorx正是这样一个平台，它依托云部署和微服务架构的优势，既能够服务于国内企业的基础需求，也具备与国际工业互联网平台竞技的实力。</p>]]></description></item><item>    <title><![CDATA[封装新纪元 星星上的柳树 ]]></title>    <link>https://segmentfault.com/a/1190000047411799</link>    <guid>https://segmentfault.com/a/1190000047411799</guid>    <pubDate>2025-11-19 17:06:40</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在电子设计领域，IC 封装不仅是保护芯片的重要技术，更是推动微型化、性能提升与系统可靠的关键支撑。本文带你走进封装世界，从传统到未来趋势，感受封装技术如何推动电子不断进化。</p><p>1、封装类型一览与演进趋势<br/>DIP（双列直插封装） 起点：通过孔安装，曾是早期主流形式，但体积大、难以适应现代高密度布局趋势。<br/>SMT（表面贴装技术） 革命：引入 SOP、QFP 等变种，实现了更小体积、更高组件密度。<br/>BGA（球栅阵列） 与 CSP（芯片级封装）：迎接高密度、高性能的挑战，提升热性能和连接可靠性。<br/>SiP（系统级封装）：通过在单个封装内集成多功能模块，简化系统设计、提升功能集成度。<br/><img width="723" height="360" referrerpolicy="no-referrer" src="/img/bVdm58u" alt="" title=""/><br/>2、新趋势：突破封装极限<br/>电子产品对性能、尺寸与功能的极致追求，催生了以下几大前沿封装形式：<br/>3D IC 封装（垂直堆叠封装）：通过垂直集成提升芯片密度和性能，降低互联延迟。<br/>2.5D/FOWLP（扇出型晶圆级封装）：提升 I/O 密度与信号完整性，是下一代高性能系统封装的重要方向。<br/>嵌入芯片封装 / 多芯片模块（MCM）：将裸片直接嵌入基板内，节省空间、增强热管理和功能整合。</p><p>3、封装技术面临的挑战<br/>关键挑战    描述<br/>热管理    更高密度的芯片封装带来更大的散热压力。<br/>信号完整性    高速封装中互连设计对信号质量提出更高要求。<br/>成本与尺寸优化    在保持低成本的同时，追求更微型化设计。</p><p>4、为何选择 EDA Academy 精研 IC 封装技术？<br/>无论你是追求封装市场最前沿技术的工程师，还是希望将封装经验传授他人的导师，EDA Academy（www.eda-academy.com） 都是理想之选：<br/>课程全面与更新及时：覆盖从 DIP、SMT、BGA 到 3D IC、SiP、FOWLP 等主流与前沿封装技术；注重实战与案例驱动学习。<br/>双重身份灵活切换：既可作为学员系统提升专业能力，也可作为导师入驻平台教学，分享实战经验。<br/>免费订阅 Newsletter：提交邮箱即可获取最新课程动态与行业趋势，无需支付，即可保持与前沿同步。<br/>销售联盟计划：参与推广课程，即可赚取 20%–50% 佣金，实现学习热情与商业回报的良性循环。</p><p>IC 封装作为电子硬件的核心支撑，经历了从传统封装向高密度、3D 集成的演进。未来，封装技术将继续向更小尺寸、更高性能、更强集成方向发展。掌握这些关键技术，就是掌握未来电子系统的核心能力。</p><p>而 EDA Academy 正是让你高效获取封装核心技术的平台 — 无论是提升技能、分享经验，还是创造附加收入，都能在这里找到合适路径。欢迎访问 www.eda-academy.com，与行业最前沿接轨！</p>]]></description></item><item>    <title><![CDATA[隐语可信数据空间MOOC第22讲笔记：零]]></title>    <link>https://segmentfault.com/a/1190000047411797</link>    <guid>https://segmentfault.com/a/1190000047411797</guid>    <pubDate>2025-11-19 17:06:01</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>笔记内容来自隐语Mooc，欢迎一起来学习。Mooc课程地址：<a href="https://link.segmentfault.com/?enc=3KNryeztCJQ8czr5hDrlLg%3D%3D.kWBqA6SzBQ7I0pmdbFqgeHegrQgdDZ1ZIxRoRsRBx8xkAFh43M0DR%2B4Rkoj2wrKxV1OSyVdiwNZrNFomRQTInHsbAaI47oTFUERvSAODTBKevlmHfKSU%2FqCIvXDVurOvnurKQgWL2mPK4qnYzTpvhw%3D%3D" rel="nofollow" target="_blank">https://www.secretflow.org.cn/community/bootcamp/2narwgw4ub8r...</a></p><h2>📘 零知识证明学习笔记</h2><h3>一、零知识证明简介</h3><h4>1. 基本定义</h4><ul><li><strong>零知识证明</strong>：证明者向验证者证明某个声明的真实性，<strong>不泄露任何额外信息</strong></li><li><p><strong>核心角色</strong>：</p><ul><li><strong>证明者</strong>：拥有秘密知识的一方</li><li><strong>验证者</strong>：验证声明真实性的一方</li></ul></li></ul><h4>2. 发展历程</h4><ul><li><strong>交互式零知识证明</strong>：由Goldwasser、Micali、Rackoff提出</li><li><strong>非交互式零知识证明</strong>：由Blum、Feldman、Micali提出</li></ul><h4>3. 应用场景举例</h4><h5>传统身份认证 vs 零知识证明认证</h5><pre><code>传统认证：
用户 → 服务器：我是Alice，密码是"@d3%461F&amp;"
风险：服务器可能泄露密码

零知识证明认证：
用户 → 服务器：我是Alice，我知道密码（但不透露密码）
优势：密码永不离开用户端</code></pre><h5>色盲测试协议对比</h5><p><strong>非零知识版本</strong>：</p><ul><li>验证者展示小球，证明者回答颜色</li><li><strong>问题</strong>：验证者可能学到"每个桶里球的颜色"</li></ul><p><strong>零知识版本</strong>：</p><ul><li>验证者展示两个小球，证明者回答"颜色是否相同"</li><li><strong>优势</strong>：验证者无法获知具体颜色信息</li></ul><h3>二、零知识证明的核心性质</h3><h4>1. 完备性</h4><ul><li>如果声明为真，诚实的证明者能够说服验证者接受证明</li></ul><h4>2. 可靠性</h4><ul><li>如果声明为假，任何证明者都无法说服验证者接受证明</li></ul><h4>3. 零知识性</h4><ul><li>验证者除了相信声明为真外，<strong>无法获得任何额外信息</strong></li></ul><h4>零知识性分级：</h4><ul><li><strong>完美零知识</strong>：泄露信息量为0</li><li><strong>统计零知识</strong>：泄露信息量可忽略</li><li><strong>计算零知识</strong>：在多项式时间内泄露信息量可忽略</li></ul><p><strong>核心概念</strong>：存在模拟器能够生成与真实交互<strong>不可区分的</strong>对话记录</p><h3>三、Sigma协议</h3><h4>1. 协议结构（3轮交互）</h4><pre><code>1. 承诺：P → V: a
2. 挑战：V → P: e  
3. 响应：P → V: z</code></pre><h4>2. 核心性质</h4><h5>知识证明</h5><ul><li>不仅能证明声明真实，还能证明证明者<strong>确实知道</strong>证据w</li></ul><h5>2-特殊合理性</h5><ul><li>给定同一承诺a的两个有效响应(e₁,z₁)和(e₂,z₂)，可以<strong>提取</strong>出证据w</li><li>这是知识合理性的基础</li></ul><h5>特殊诚实验证者零知识性</h5><ul><li>对于任意给定的挑战e，可以模拟出不可区分的对话记录</li></ul><h3>四、Schnorr身份认证协议</h3><h4>1. 协议设定</h4><ul><li>群G，阶为素数p，生成元g</li><li>私钥：w ∈ ℤₚ</li><li>公钥：x = gʷ</li></ul><h4>2. 协议流程</h4><pre><code>1. P随机选择 t ← ℤₚ，计算 a = gᵗ，发送a给V
2. V随机选择挑战 e ← {0,1}λ，发送给P  
3. P计算 z = t + e·w，发送z给V
4. V验证：gᶻ = a·xᵉ</code></pre><h4>3. 安全性分析</h4><ul><li><strong>2-特殊合理性</strong>：从(e₁,z₁)和(e₂,z₂)可解出w</li><li><strong>零知识性</strong>：模拟器可生成不可区分的(a,e,z)三元组</li></ul><h3>五、Fiat-Shamir变换</h3><h4>1. 核心思想</h4><p>将<strong>交互式</strong>Sigma协议转换为<strong>非交互式</strong>零知识证明</p><h4>2. 变换方法</h4><p>用<strong>哈希函数</strong>替代验证者的随机挑战：</p><pre><code>e = Hash(x, a)</code></pre><h4>3. 非交互式Schnorr协议</h4><pre><code>证明生成：
1. t ← ℤₚ, a = gᵗ
2. e = Hash(x, a)  
3. z = t + e·w
4. 输出证明：π = (a, z)

验证：
1. e = Hash(x, a)
2. 验证：gᶻ = a·xᵉ</code></pre><h3>六、国际标准与展望</h3><h4>ISO 27565标准</h4><ul><li><strong>名称</strong>：《基于零知识证明的隐私保护指南》</li><li><strong>地位</strong>：我国首次提出的零知识证明国际标准</li><li><strong>内容</strong>：规范ZKP在各领域应用场景的数据处理</li><li><strong>目标</strong>：通过最小化共享信息来保护用户隐私</li></ul><h3>💡 关键要点总结</h3><ol><li><strong>零知识性核心</strong>：验证者学不到任何超出声明真实性的信息</li><li><strong>Sigma协议</strong>：3轮交互的基础协议，具备完备性、可靠性、零知识性</li><li><strong>Fiat-Shamir变换</strong>：实现非交互式证明的关键技术</li><li><strong>实际应用</strong>：从身份认证到隐私保护，应用前景广泛</li><li><strong>标准化进展</strong>：中国在ZKP国际标准制定中发挥领导作用</li></ol>]]></description></item><item>    <title><![CDATA[企业级 VS 个人级：智能问数的“集团军]]></title>    <link>https://segmentfault.com/a/1190000047411804</link>    <guid>https://segmentfault.com/a/1190000047411804</guid>    <pubDate>2025-11-19 17:05:26</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>智能问数正迅速成为企业数据消费的新入口。从初创公司到世界 500 强，众多组织尝试通过“一句话问数”的方式，降低数据分析门槛、提升决策效率。理想很丰满，但现实很骨感，“问不准”、“不灵全”、“问不深”成为大量尝鲜用户的普遍感受。</p><p>表面上看，这类失败常被归因于技术瓶颈——例如模型准确性不足、SQL 生成错误、响应延迟等。但深入剖析后不难发现，问题的根源往往并非技术本身，而在于对问题本质的误判：企业级智能问数与面向个人或小团队的轻量级工具，本质上解决的是两个截然不同维度的问题。</p><p>● 个人或小团队场景更接近“单兵作战”：其核心诉求是快速、简便地完成基础查询，通常依赖单一数据源、简单的语义映射和低门槛交互，对数据治理、安全合规或指标一致性等要求较低。</p><p>● 企业级场景则是一场多维度协同的“集团军作战”：它不仅要求自然语言到查询的准确转换，更需系统性应对数据治理、统一数据语义、业务知识上下文管理、跨系统集成、权限控制与安全合规等一系列复杂挑战。</p><p>将企业级智能问数简单等同于增强版的“自然语言查数工具”，忽视其背后所需的体系化能力建设，正是多数项目陷入困境甚至失败的根本原因。而要真正理解这种体系化能力的核心，必须回归智能问数的本质——DATA × 知识。</p><p>智能问数的本质：DATA × 知识</p><p>智能问数的核心，是数据与知识的深度耦合。数据是燃料，知识是引擎。没有高质量、结构化、语义清晰的数据，再先进的 AI 模型也难逃“垃圾进、垃圾出”的命运；而没有对业务逻辑、指标口径、组织规则的理解，AI 也无法真正“听懂”用户的问题。</p><p>在个人或小团队场景中，这一耦合相对简单：数据量小、结构清晰、知识边界明确。用户上传一个 Excel 文件，系统通过字段映射和简单语义理解即可完成问答。这种“轻量级”模式，适合快速验证、临时分析，但无法承载企业级复杂业务的重量。</p><p>在企业级场景中，数据是分散的、异构的、动态演进的；知识是隐性的、多义的、高度组织化的。此时，语义层便成为关键枢纽——业务语言与数据语言之间的“翻译器”。没有语义层，就没有真正的企业级智能问数。</p><p>企业级 VS 个人级：智能问数建设差异</p><p>这种本质差异，体现在五个关键维度上，决定了企业级与个人级智能问数产品在架构、能力与价值逻辑上的根本分野。</p><ol><li>数据集成的挑战<br/>● 企业级：数据源复杂多样，企业拥有众多不同类型的系统，数据模型复杂。不同业务线的数据模型差异大，需要深入理解并整合，建立统一的数据语义层。集成成本高，依赖专业团队进行数据映射、口径对齐、性能调优，通常需数周至数月才能完成上线。其本质在于解决“如何让分散的数据讲同一种语言”的问题，确保不同数据源的数据能够准确、一致地被利用。<br/>● 个人/小团队：数据源标准化，通常来自 Excel 或少数几个流行数据库。数据模型简单，一般是单个或少量数据表，无需复杂的关联和建模。提供标准连接器，用户可自行快速连接，即插即用。对数据质量要求较低，可以接受一定程度的不一致性，也无需考虑跨系统数据整合问题，主要解决“如何快速读取已有数据”的问题。<br/>关键差异：企业级产品是在“构建数据资产”，个人级产品只是在“读取数据”。</li><li>业务场景与复杂度的挑战<br/>● 企业级：业务场景多样化、专业化。用户角色多样，从 CEO 到一线业务员，需求和知识背景差异巨大。场景深度和专业性强，分析结果可能直接影响重大商业决策，需要与现有工作流集成，如嵌入到 OA、CRM 等系统中。挑战在于“领域特定”和“复杂性”，要理解业务行话，如“DAU”“GMV”“销售漏斗”等企业内部特定术语；要处理复杂逻辑查询，用户可能会问涉及多步计算和关联的问题；要进行意图消歧，同一个词在不同业务部门可能有不同含义，需要结合上下文进行区分。<br/>● 个人/小团队：业务场景相对通用，主要用于日常的业绩监控、活动复盘、生成报告等。用户同质性强，查询需求相对固定。通常是独立的分析工具，集成需求弱。挑战在于“通用性”和“容错性”，更侧重于理解日常用语和简单的数据分析术语，如“趋势”“对比”“TOP 10”；查询相对简单，问题通常是针对单张表或简单关联的查询；当理解不明确时，可以通过交互式澄清，快速引导用户澄清问题。<br/>关键差异：企业级智能问数的目标是“辅助决策”，而个人级的目标是“获取信息”。</li><li>数据治理与安全的挑战<br/>● 企业级：有严格的权限控制，不同部门、角色、级别的员工只能看到自己被授权访问的数据。需要满足行业特定的数据安全与合规要求，如 GDPR、SOC2 等。要确保敏感数据不泄露，数据访问不越权，保护企业核心数据安全。同时，必须保证数据质量与一致性，实现“单一事实来源”，口径统一，避免不同的人问出不同结果，以支持企业准确决策。<br/>● 个人/小团队：权限简单，通常是“所有者”和“查看者”两级权限，或简单的文件夹共享。安全要求低，主要依赖云服务商的基础安全，合规要求宽松。数据质量由用户自己负责，产品不强制干预，更注重使用的便捷性。<br/>关键差异：企业级产品必须在“可用”与“安全”之间取得平衡。</li><li>技术实现与架构的挑战<br/>● 企业级：技术路线选择上，需要采用“自动化数据工程 + 指标语义层 + 大模型”的技术路径，而非纯粹的 NL2SQL 方案。要构建智能体系统，实现多智能体协作和可编排工作流。为避免“数据幻觉”，需要构建标准化指标体系，提前定义指标的计算逻辑和统计口径。同时，要与企业现有系统无缝集成，满足高并发需求，成百上千的员工可能同时使用，系统不能宕机或变慢；还要处理 TB/PB 级别的数据，查询响应时间必须是秒级。<br/>● 个人/小团队：技术路线相对简单，可以采用基础的 NL2SQL 实现。无需构建复杂的智能体系统，对“数据幻觉”容忍度较高。集成难度较低，通常只需要连接单一数据源。低并发，同时在线用户数有限；数据量适中，通常在 GB 级别以内，对技术性能要求相对较低。<br/>关键差异：企业级是“系统工程”，个人级是“技术原型”。</li><li>长期价值与维护的挑战<br/>● 企业级：前期投入大，需要进行前期的指标体系建设投入，但长期来看可靠性和准确性更高。要实现从“数据治理”到“数据智慧”的提升，支持数据资产的持续演进与价值提升。对 ROI 要求高，需要证明能够降本增效、释放数据价值、多领域赋能，为企业带来长期的战略价值。<br/>● 个人/小团队：前期投入相对较小，价值实现更直接，基于简单的查询需求即可满足用户需求。维护成本较低，通常不需要进行长期的价值规划，更注重短期的使用效果和用户体验。<br/>关键差异：企业级产品是“基础设施”，个人级产品是“应用工具”。</li></ol><p>企业级产品的挑战核心是“管控”与“整合”。它不是一个孤立的工具，而是一个需要融入企业复杂 IT 生态和数据文化的平台。其面临的挑战在于，在企业海量数据资产和复杂业务逻辑的背景下，既要确保安全、合规和稳定，又要提供足够灵活和强大的分析能力。</p><p>个人/小团队产品的挑战核心是“体验”与“效率”。它追求的是在最小化用户学习成本和设置成本的情况下，解决 80% 的常见问题。其关键在于如何将复杂的技术封装成极其简单、直观甚至愉悦的用户体验。产品设计和增长模式是重中之重，通过优秀的设计和有效的推广，快速吸引用户并提高用户粘性。</p><p>因此，一个成功的 ToB 企业级智能问数产品，其护城河在于对复杂业务场景的深度理解、强大的数据整合与治理能力、以及坚实的企业级服务能力。只有深入了解企业业务，才能提供符合企业需求的解决方案；具备强大的数据整合与治理能力，才能确保数据的质量和一致性；拥有坚实的企业级服务能力，才能保障系统的稳定运行和长期发展。</p><p>Aloudata Agent：企业级智能问数的实践之路</p><p>基于对以上差异的深刻理解，Aloudata Agent 的定位，是一套专为企业级场景打造的分析决策智能体。Aloudata Agent 将 NoETL 明细语义层作为数据底座，为智能问数提供完整一致的业务语义和强大的查询加速能力，支持任意维度和指标的灵活组合、 任意粒度的下钻分析。在提升“问”的便捷性的同时，我们更聚焦于保障“答”的可信度——这种可信度建立在统一的指标口径、严格的数据治理、精准的权限控制和高可用的系统架构之上。</p><p>智能问数正加速成为企业数据消费的刚需，但这条路径没有捷径。个人级产品可以依靠极致的用户体验和快速的迭代能力赢得市场；而企业级产品必须稳扎稳打。Aloudata Agent 的目标，是切实陪伴企业完成从“数据可用”到“数据可信”，最终迈向“数据驱动决策”的系统性跃迁。</p>]]></description></item><item>    <title><![CDATA[数字孪生赋能数据中心运维 图观 ]]></title>    <link>https://segmentfault.com/a/1190000047411836</link>    <guid>https://segmentfault.com/a/1190000047411836</guid>    <pubDate>2025-11-19 17:04:52</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在数据中心运维领域，传统的运维方式常常面临数据孤岛、响应滞后、管理复杂等挑战。随着数据中心规模的扩大和复杂度的提升，如何实现高效、智能的运维管理成为行业关注的焦点。孪易数字孪生IOC凭借其一体化监测运维平台、灵活后台配置和强大的数据接入能力，为数据中心运维带来了全新的解决方案。本文将通过实际应用案例，展示孪易IOC如何帮助数据中心实现智能高效运营。</p><h2>某大型数据中心运维挑战</h2><p>某大型数据中心承载着数百家企业的关键业务，运维团队需要实时监控数千台服务器、网络设备和环境系统的运行状态。然而，传统的运维系统存在以下问题：<br/><strong>1.数据分散</strong>：服务器性能数据、环境监控数据、能耗数据等分散在不同系统中，难以统一分析。<br/><strong>2.告警响应慢</strong>：故障告警依赖人工排查，响应时间长，影响业务连续性。<br/><strong>3.运维效率低</strong>：缺乏可视化工具，运维人员难以快速定位问题。<br/>针对这些痛点，该数据中心引入了孪易数字孪生IOC，实现了运维管理的全面升级。</p><h2>孪易IOC标准版的核心应用价值</h2><p><strong>1. 一体化监测运维平台：实现全景可视化管理</strong><br/>孪易IOC通过数字孪生技术，将数据中心的物理设备、环境参数和业务系统映射到虚拟场景中，实现全景可视化管理。运维人员可以通过平台实时查看服务器运行状态、机房温度、能耗数据等关键指标，快速掌握整体运行态势。<br/>平台还支持场景剖分、历史回放等功能，帮助运维人员深入分析故障原因。例如，通过历史回放功能，可以追溯某次服务器宕机前的运行数据，快速定位根本原因。<br/><img width="640" height="356" referrerpolicy="no-referrer" src="/img/bVdmQp3" alt="" title=""/><br/><strong>2. 智能数据分析：提升故障预测与决策能力</strong><br/>孪易IOC内置智能数据分析模块，支持业务主题自定义、空间分析和数据筛选。运维人员可以根据实际需求，自定义分析图表和报表，深度挖掘多源数据价值。<br/>例如，平台通过分析服务器性能数据和环境参数，可以预测设备故障风险，提前发出预警。同时，平台还支持能耗分析，帮助数据中心优化能源使用，降低运营成本。</p><p><strong>3. 灵活后台配置：零代码实现功能定制</strong><br/>孪易IOC的后台配置管理功能支持零代码操作，运维人员无需开发经验即可配置场景、孪生体对象和告警规则。例如，当数据中心新增一批服务器时，运维人员只需在后台添加相应的三维模型和数据接口，即可快速完成系统更新。<br/>这种灵活的配置方式大幅降低了运维系统的维护成本，同时提高了系统的适应性和扩展性。<br/><img width="640" height="360" referrerpolicy="no-referrer" src="/img/bVdmQDO" alt="" title="" loading="lazy"/><br/><strong>4. 多源数据接入：实现全链路监控</strong><br/>孪易IOC支持物联网数据、数据库、数据接口和流媒体视频的接入，能够将数据中心的各类监控系统整合到一个平台中。例如，平台可以通过MQTT协议接入物联网传感器数据，通过HTTP接口获取业务系统日志，并通过RTSP协议接入监控视频流。<br/>这种多源数据接入能力使得运维人员能够在一个平台上完成全链路监控，无需在不同系统之间切换，大大提高了工作效率。</p><p><strong>5. 行业模板库：快速部署专业解决方案</strong><br/>孪易IOC预置了数据中心行业的孪生体定义、三维模型、分析图表和告警模板，用户可以直接基于模板构建符合行业标准的运维系统。这种开箱即用的方式大幅缩短了项目周期，帮助数据中心快速实现智能化升级。</p><h2>实际应用效果</h2><p>通过引入孪易IOC，该数据中心在以下方面取得了显著成效：<br/><strong>1.运维效率提升</strong>：故障定位时间从平均30分钟缩短至5分钟以内。<br/><strong>2.告警响应速度提升</strong>：实时告警监测和智能分析使得告警响应时间减少50%。<br/><strong>3.能耗优化</strong>：通过智能数据分析，数据中心能耗降低10%。<br/><strong>4.系统灵活性增强</strong>：零代码配置功能使得系统能够快速适应业务变化，无需额外开发投入。</p><p>孪易数字孪生IOC标准版通过一体化监测运维、智能数据分析、灵活后台配置和多源数据接入等功能，为数据中心运维提供了全面、高效的解决方案。其开箱即用、行业适配性强、支持灵活定制的特点，使得数据中心能够快速实现智能化升级，提升运维效率和业务连续性。</p>]]></description></item><item>    <title><![CDATA[PAI Physical AI Note]]></title>    <link>https://segmentfault.com/a/1190000047411851</link>    <guid>https://segmentfault.com/a/1190000047411851</guid>    <pubDate>2025-11-19 17:03:51</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在前两期，我们已经分别基于仿真环境和世界模型进行了针对Manipulation（动作控制）模型的训练数据合成与模仿学习。我们来回顾下整个过程：<br/><img width="723" height="191" referrerpolicy="no-referrer" src="/img/bVdm550" alt="image.png" title="image.png"/></p><p>针对具身智能场景，除了Manipution，Navigation（导航）也是一类非常重要的控制模型，本期我们就来详细解读基于仿真环境的导航模型训练的全过程。</p><p>和动作控制模型类似，对导航模型的训练也可以通过人工演示、数据扩增、数据增强、模仿学习和模型测评几个环节来进行。<br/><img width="723" height="101" referrerpolicy="no-referrer" src="/img/bVdm553" alt="image.png" title="image.png" loading="lazy"/></p><p>但是相比动作控制模型，导航模型的训练过程有以下特点：</p><ul><li>人工演示相对简单，只需要在二维平面上控制运动方向即可</li><li>数据扩增相对简单，因为二维平面上仅有2个自由度</li><li>运动控制的目标更复杂，不再是完成先验的特定动作，而是到达一个随机指定的坐标</li><li>基于上述第3点的原因，对导航模型的测评也更加复杂，需要结合仿真环境和模型推理进行在环验证<br/>在PAI的Notebook Gallery中，我们已经预置了一个最佳实践，就是这个过程的一个具体示例：<br/><a href="https://link.segmentfault.com/?enc=FcjHUHQx485AueEokXCOVw%3D%3D.AucUshaM8L5a%2BKm9%2FpPrrtoUROecWSwGinUm%2FXVAexjDwSuEL7OWHM%2FJmlEpB9cMkmUvghXWGFE%2BHTsQTn3q9WEvo4zYx477lGbvmnCJTmM%3D" rel="nofollow" target="_blank">https://gallery.pai-ml.com/#/preview/deepLearning/cv/isaac\_sim\_wf3</a><br/><img width="723" height="466" referrerpolicy="no-referrer" src="/img/bVdm555" alt="image.png" title="image.png" loading="lazy"/></li></ul><p>下面我们来详细解读这个示例。</p><h2>使用Isaac Asset公共数据集</h2><p>由于导航模型的训练需要一个比较复杂的3D场景，在PAI的公共数据集中已经内置了一个数据集，包含了一些3D场景：<br/><img width="723" height="274" referrerpolicy="no-referrer" src="/img/bVdm56f" alt="image.png" title="image.png" loading="lazy"/></p><p>在启动用于人工演示的DSW时，除了选择资源类型、自定义数据集，还可以选择这个公共数据集，方便后续的场景构建<br/><img width="723" height="252" referrerpolicy="no-referrer" src="/img/bVdm56n" alt="image.png" title="image.png" loading="lazy"/></p><p>这样，DSW启动后，就可以看到这个公共数据集：<br/><img width="723" height="317" referrerpolicy="no-referrer" src="/img/bVdm56E" alt="image.png" title="image.png" loading="lazy"/></p><h2>人工少量演示</h2><h3>加载场景</h3><p>接下来，我们在这个DSW中，通过livestream启动Isaac Sim环境：</p><pre><code class="python">export ACCEPT_EULA=Y
PUBLIC_IP=$(curl -s ifconfig.me) &amp;&amp; /isaac-sim/runheadless.sh --/persistent/isaac/asset_root/default="/mnt/data/isaac_tmp/isaac_asset/Assets/Isaac/5.0" --/app/livestream/publicEndpointAddress=$PUBLIC_IP --/app/livestream/port=49100</code></pre><p>即可在Isaac Sim中通过Isaac Asset公共数据集加载导航模型将要运行的场景：</p><p>（场景目录：/mnt/isaac\_assets/5.0/Isaac/Environments/Simple\_Warehouse/warehouse\_multiple\_shelves.usd）<br/><img width="723" height="351" referrerpolicy="no-referrer" src="/img/bVdm56M" alt="image.png" title="image.png" loading="lazy"/></p><h3>创建Occupancy Map</h3><p>接下来我们需要为这个场景创建Occupancy Map，这样MobilityGen就知道机器人在哪里可以移动。</p><ol><li>选择 Tools &gt; Robotics &gt; Occupancy Map 打开占用地图扩展</li><li>在占用地图窗口中设置参数：<br/>Origin: X=2.0, Y=0.0, Z=0.0<br/>Upper Bound: X=10.0, Y=20.0, Z=2.0<br/>Lower Bound: X=-14.0, Y=-18.0, Z=0.1</li><li>点击 <code>Calculate</code> 生成占用地图</li><li>点击 Visualize Image 查看占用地图</li><li>在可视化窗口中选择 Rotate Image: 180</li><li>选择 Coordinate Type: ROS Occupancy Map Parameters File YAML</li><li>点击 Regenerate Image</li><li>复制生成的YAML文本</li><li>创建文件 <code>~/MobilityGenData/maps/warehouse_multiple_shelves/map.yaml</code></li><li>粘贴YAML内容并修改 <code>image: warehouse_multiple_shelves.png</code> 为 <code>image: map.png</code></li><li>保存文件</li><li>在可视化窗口中点击 Save Image，在<code>/root/MobilityGenData/maps/warehouse_multiple_shelves</code>下保存为 <code>map.png</code><br/><img width="723" height="351" referrerpolicy="no-referrer" src="/img/bVdm56R" alt="image.png" title="image.png" loading="lazy"/></li></ol><h3>启动MobilityGen插件</h3><p>按照下列操作启动MobilityGen插件：</p><ol><li>导航到 Window &gt; Extensions</li><li>搜索 MobilityGen UI</li><li>点击切换开关启用扩展</li><li>您应该看到两个窗口：MobilityGen UI和占用地图可视化窗口 <br/><img width="723" height="364" referrerpolicy="no-referrer" src="/img/bVdm56Y" alt="image.png" title="image.png" loading="lazy"/><br/><img width="723" height="362" referrerpolicy="no-referrer" src="/img/bVdm57f" alt="image.png" title="image.png" loading="lazy"/></li></ol><p>在MobilityGen窗口中设置以下参数：</p><ol><li><p><strong>Stage</strong>: 粘贴仓库USD路径</p><pre><code class="plaintext">/mnt/isaac_assets/5.0/Isaac/Environments/Simple_Warehouse/warehouse_multiple_shelves.usd</code></pre></li><li><p><strong>Occupancy Map</strong>: 输入之前创建的map.yaml文件路径</p><pre><code class="plaintext">~/MobilityGenData/maps/warehouse_multiple_shelves/map.yaml</code></pre></li><li><strong>Robot</strong>: 选择 <strong>CarterRobot</strong></li><li><strong>Scenario</strong>: 选择 <strong>KeyboardTeleoperationScenario</strong>（可选：如果您想自动生成数据，请选择 <strong>RandomPathFollowingScenario</strong>）</li><li>点击 <strong>Build</strong></li></ol><h3>录制轨迹</h3><ol><li>点击 <strong>Start recording</strong> 开始记录日志</li><li>移动机器人（如您选取<strong>KeyboardTeleoperationScenario</strong>）</li><li>点击 <strong>Stop recording</strong> 停止记录 <br/><a href="https://link.segmentfault.com/?enc=t9s9WNm6pITkJG8CX4devw%3D%3D.itMhDY3W0CSwjzM10ZYBZG4X7xP5aUr1%2Bw70j0rOPBd%2FRuTbUiFtDObO%2FffLNKu%2FuKWC7F3MS75TpGmdPbpox8dYk8Yx4F6DcIqtURslzBEuLjpp4eF0CmNVboMwUFwz" rel="nofollow" target="_blank">视频演示 &gt;&gt;</a><br/>数据现在记录到 <code>~/MobilityGenData/recordings</code> 目录中。<br/><img width="510" height="444" referrerpolicy="no-referrer" src="/img/bVdm57h" alt="image.png" title="image.png" loading="lazy"/></li></ol><h3>重放生成视频</h3><p>然后使用Isaac Sim提供的 <code>replay_directory.py</code> Python脚本重放场景：</p><pre><code class="bash">cd /isaac-sim &amp;&amp; \
/isaac-sim/python.sh standalone_examples/replicator/mobility_gen/replay_directory.py --render_interval 10 --enable isaacsim.replicator.mobility_gen.examples</code></pre><p>脚本完成后，重放渲染的图像和传感器数据会被保存到 <code>~/MobilityGenData/replays</code>路径下<br/><img width="723" height="234" referrerpolicy="no-referrer" src="/img/bVdm57i" alt="image.png" title="image.png" loading="lazy"/></p><h2>数据增强</h2><p>我们使用Cosmos-Transfer1-7B模型来增强采集到的图像数据。在PAI-ModelGallery中已经集成了这个模型的部署方案：<br/><img width="723" height="251" referrerpolicy="no-referrer" src="/img/bVdm57j" alt="image.png" title="image.png" loading="lazy"/></p><p>完成模型部署后，可以使用如下脚本来对图像数据进行增强：</p><pre><code class="python">import cv2
import json
from pathlib import Path
import shutil
import requests
import gradio_client.client as gradio_client
import gradio_client.utils as gradio_utils  

# 定义Cosmos服务URL和Token
# COSMOS_SERVICE_URL = "http://xxxxxx"  # 请替换为实际服务URL
# EAS_TOKEN = "your_eas_token"  # 请替换为实际EAS Token

RGB_TARGETS = [
    "state/rgb/robot.front_camera.left.rgb_image",
    "state/rgb/robot.front_camera.right.rgb_image",
]

# --- 模块1: 图像序列转视频 ---
def convert_sequence_to_video(input_dir: Path, output_path: Path, fps: int, image_format: str) -&gt; bool:
    print(f"  - Converting to video: {input_dir.name} (Format: {image_format})")
    image_files = sorted(list(input_dir.glob(f'*.{image_format}')))
    if not image_files:
        print(f"    -&gt; No '{image_format}' images found. Skipping.")
        return False
    try:
        first_img = cv2.imread(str(image_files[0]))
        if first_img is None: raise IOError("Cannot read the first image.")
        height, width = first_img.shape[:2]
    except Exception as e:
        print(f"    -&gt; Error reading first image: {e}. Skipping.")
        return False
    output_path.parent.mkdir(parents=True, exist_ok=True)
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(str(output_path), fourcc, fps, (width, height))
    for image_file in image_files:
        frame = cv2.imread(str(image_file))
        if frame is not None:
            out.write(frame)
    out.release()
    print(f"    -&gt; Video created: {output_path}")
    return True

# --- 新模块: 视频转图像序列 ---
def split_video_to_frames(video_path: Path, output_dir: Path, original_image_dir: Path, image_format: str):
    """
    将视频文件拆分为一帧帧的图片，并使用原始图片的文件名进行命名。
    """
    print(f"  - Splitting video back to frames: {video_path.name}")
    
    # 1. 获取原始文件名作为模板
    original_image_files = sorted(list(original_image_dir.glob(f'*.{image_format}')))
    original_filenames = [p.name for p in original_image_files]
    
    if not original_filenames:
        print(f"    -&gt; Warning: Could not find original images in {original_image_dir} to use for naming. Skipping frame splitting.")
        return

    # 2. 准备输出目录
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # 3. 打开视频文件并逐帧读取
    cap = cv2.VideoCapture(str(video_path))
    if not cap.isOpened():
        print(f"    -&gt; Error: Could not open video file {video_path}. Skipping.")
        return

    frame_index = 0
    while True:
        ret, frame = cap.read()
        if not ret:
            break  # 视频结束

        if frame_index &lt; len(original_filenames):
            # 使用原始文件名来保存新帧
            output_filepath = output_dir / original_filenames[frame_index]
            cv2.imwrite(str(output_filepath), frame)
        else:
            # 如果视频帧数多于原始图片数，则停止，避免命名冲突
            print(f"    -&gt; Warning: Video contains more frames than original image sequence. Stopping at frame {frame_index}.")
            break
        
        frame_index += 1

    cap.release()
    print(f"    -&gt; Success! {frame_index} frames saved to: {output_dir}")

# --- 模块2: 调用Cosmos服务 ---
def cosmos_sync_with_upload(client, rgb_video_path, seg_video_path, output_dir, original_rgb_dir):
    """上传视频，调用API，下载结果，并触发视频到帧的转换。"""
    
    def upload_file(filepath: Path):
        if not filepath or not filepath.exists(): return None
        print(f"  - Uploading: {filepath.name}")
        file_desc = gradio_utils.handle_file(str(filepath))
        result_str = client.predict(file_desc, api_name="/upload_file")
        return json.loads(result_str).get("path")

    remote_rgb_path = upload_file(rgb_video_path)
    remote_seg_path = upload_file(seg_video_path)

    if not remote_rgb_path or not remote_seg_path:
        return False, "视频上传失败"

    request_dict = create_cosmos_request(remote_rgb_path, remote_seg_path)
    print("  - Sending generation request to Cosmos service...")
    result = client.predict(json.dumps(request_dict), api_name="/generate_video")
    
    if isinstance(result, tuple) and len(result) &gt;= 2 and isinstance(result[0], dict):
        video_path = result[0].get("video")
        if not video_path:
            return False, f"API did not return a video path. Message: {result[1]}"

        output_file = Path(output_dir) / f"{rgb_video_path.stem}_cosmos_enhanced.mp4"
        
        # 统一处理下载或复制的逻辑
        success = False
        if video_path.startswith(("http://", "https://")):
            try:
                resp = requests.get(video_path, stream=True, timeout=300)
                resp.raise_for_status()
                with open(output_file, "wb") as f: shutil.copyfileobj(resp.raw, f)
                success = True
            except requests.exceptions.RequestException as e:
                return False, f"Failed to download video: {e}"
        else:
            source_path = Path(video_path)
            if source_path.exists():
                shutil.copy2(source_path, output_file)
                success = True
            else:
                return False, f"API returned a local path that does not exist: {video_path}"

        if success:
            print(f"  -&gt; Augmented video saved to: {output_file}")
            # 定义新帧的输出目录，例如 .../robot.front_camera.left.rgb_image_cosmos
            new_frames_output_dir = original_rgb_dir.parent / f"{original_rgb_dir.name}_cosmos"
            split_video_to_frames(
                video_path=output_file,
                output_dir=new_frames_output_dir,
                original_image_dir=original_rgb_dir,
                image_format="jpg"  # RGB图像的原始格式
            )
            return True, str(output_file)
        else:
            return False, "Failed to retrieve the generated video file."
            
    else:
        return False, f"Unexpected API response format: {result}"


def create_cosmos_request(remote_rgb_path, remote_seg_path):
    """动态创建Cosmos请求，包含主视频和分割视频的远程路径。"""
    return {
        "prompt": "A realistic warehouse environment with consistent lighting, perspective, and camera motion. Preserve the original structure, object positions, and layout from the input video. Ensure the output exactly matches the segmentation video frame-by-frame in timing and content. Camera movement must follow the original path precisely.",
        "negative_prompt": "The video captures a game playing, with bad crappy graphics and cartoonish frames. It represents a recording of old outdated games. The images are very pixelated and of poor CG quality. There are many subtitles in the footage. Overall, the video is unrealistic and appears cg. Plane background.",
        "sigma_max": 80,
        "guidance": 7,
        "input_video_path": remote_rgb_path, # 主视频路径
        "blur_strength": "low",
        "canny_threshold": "low",
        "edge": {"control_weight": 0.3},
        "seg": {
            "control_weight": 1.0,
            "input_control": remote_seg_path # 分割视频路径
        }
    }

# --- 模块3: 主工作流控制器 ---
def process_and_augment_replays(output_dir: str, fps: int = 30):
    source_root = Path("/root/MobilityGenData/replays")
    output_root = Path(output_dir)
    if not source_root.is_dir(): return
    timestamp_dirs = [d for d in source_root.iterdir() if d.is_dir()]
    if not timestamp_dirs: return
    
    client = gradio_client.Client(COSMOS_SERVICE_URL, hf_token=EAS_TOKEN)

    for ts_dir in timestamp_dirs:
        print(f"\nProcessing replay: {ts_dir.name}")
        final_output_dir = output_root / ts_dir.name
        final_output_dir.mkdir(exist_ok=True)
        
        for rgb_rel_path_str in RGB_TARGETS:
            rgb_image_dir = ts_dir / rgb_rel_path_str
            seg_rel_path_str = rgb_rel_path_str.replace("rgb", "segmentation")
            seg_image_dir = ts_dir / seg_rel_path_str
            
            if not (rgb_image_dir.is_dir() and seg_image_dir.is_dir()):
                continue
            
            rgb_video_path = final_output_dir / f"{rgb_image_dir.name}.mp4"
            seg_video_path = final_output_dir / f"{seg_image_dir.name}.mp4"
            
            rgb_ok = convert_sequence_to_video(rgb_image_dir, rgb_video_path, fps, "jpg")
            seg_ok = convert_sequence_to_video(seg_image_dir, seg_video_path, fps, "png")
            
            if not (rgb_ok and seg_ok):
                continue

            cosmos_sync_with_upload(
                client, 
                rgb_video_path, 
                seg_video_path, 
                final_output_dir,
                original_rgb_dir=rgb_image_dir
            )

    print("\n" + "="*20 + " 全部处理完成 " + "="*20)

# --- 程序入口 ---
if __name__ == "__main__":
    !mkdir -p /root/MobilityGenData/cosmos_augmented_videos
    output_directory = "/root/MobilityGenData/cosmos_augmented_videos"
    process_and_augment_replays(output_dir=output_directory)</code></pre><p>以下是两段数据增强前后的视频数据，作为对比：<br/>增强前<br/><a href="https://link.segmentfault.com/?enc=2IT6sNotfzRPkMYBelIiWg%3D%3D.TYBkvwwvWJRZr32yrtDJxMvM0ev8zsq8mRvpSdxp3Db%2BVg7hwopgQrJQY%2Ff5cjOtpXtKSRry8A52DTZA%2BTr3EW2lRRsibIIWQlJkD95iLhf9z1CaKvwN%2FC%2Fc1OKL%2FpPU" rel="nofollow" target="_blank">视频演示 &gt;&gt;</a></p><p>增强后<br/><a href="https://link.segmentfault.com/?enc=8lcEElBqkDm8RBta5f57KQ%3D%3D.l38xtmyyHJQHyrN9YyQdkoKXpe4%2B1OY%2FaacX4XKyaxDlxpB0jxXuOQT07fMyWu8TDSp31lh3q5hbNX1tzVbkzKiWV1qXS9SnVDN5YPldm4YN5gN6QgquXeLCyD9JXQOP" rel="nofollow" target="_blank">视频演示 &gt;&gt;</a></p><h2>模仿学习</h2><p>这里选择NVLab的开源模型X-Mobility（<a href="https://link.segmentfault.com/?enc=huvdyXu15GwnuuTLr98JTA%3D%3D.mC0anse2MGhOkw8hr4FOCVIB778ZbuwpUMWTEU%2Blr00NDIt%2BU63%2BzrC1R%2FhujLUm" rel="nofollow" target="_blank">https://github.com/NVlabs/X-Mobility</a>）作为基模，进行模仿学习。</p><p>可以使用以下脚本，启动DLC进行分布式训练：</p><pre><code class="python">import os
import json
import time

from alibabacloud_tea_openapi.models import Config
from alibabacloud_credentials.client import Client as CredClient
from alibabacloud_credentials.models import Config as CredConfig
from alibabacloud_pai_dlc20201203.client import Client as DLCClient
from alibabacloud_pai_dlc20201203.models import (
    CreateJobRequest,
    GetJobRequest,
)

def wait_for_job_to_terminate(client, job_id):
    while True:
        job = client.get_job(job_id, GetJobRequest()).body
        print('job({}) is {}'.format(job_id, job.status))
        if job.status in ('Succeeded', 'Failed', 'Stopped'):
            return job.status
        time.sleep(5)
    return None


def main():
    current_time_tuple = time.localtime()
    year = current_time_tuple.tm_year
    month = current_time_tuple.tm_mon
    day = current_time_tuple.tm_mday
    hour = current_time_tuple.tm_hour
    minute = current_time_tuple.tm_min
    # 请确认您的主账号已授权DLC，且拥有足够的权限。
    display_name = f"train_xmobility_for_isaac_{day}_{hour}-{minute}"  #设置任务名称 
    region_id = os.environ.get("dsw_region") #设置regionid
    workspace_id = os.environ.get('PAI_WORKSPACE_ID') #设置成用户自己的工作空间id
    image_uri = f"dsw-registry.{region_id}.cr.aliyuncs.com/pai-training-algorithm/isaac-sim:x-mobility-v10" #使用官方镜像
    ecs_spec = "ecs.gn8v-4x.8xlarge"     #
    #########训练任务相关配置#############
    # 样例数据集设置
    # data_type = 'pqt'
    # dataset1_dir = "/mnt/data/notebook3/x_mobility_isaac_sim_random_160k/data"
    # dataset2_dir = "/mnt/data/notebook3/x_mobility_isaac_sim_nav2_100k/data"
    # output_dir = "/mnt/data/notebook3/sample_output"
    # 样例cosmos数据集设置
    data_type = 'pqt'
    dataset1_dir = "/mnt/data/notebook3/x_mobility_isaac_sim_random_160k_cosmos_to_xmob_resized/afm_isaac_sim_random_160k/data"
    dataset2_dir = "/mnt/data/notebook3/x_mobility_isaac_sim_nav2_100k_cosmos_to_xmob_resized/afm_isaac_sim_nav2_100k/data"
    output_dir = "/mnt/data/notebook3/sample_cosmos_output"
    # mobilitygen数据集设置
    # data_type = 'lerobot'
    # dataset1_dir = "/mnt/data/notebook3/x_mobility_isaac_sim_mobilitygen"
    # dataset2_dir = "/mnt/data/notebook3/x_mobility_isaac_sim_mobilitygen"
    # output_dir = "/mnt/data/notebook3/mobilitygen_output"
    #########训练任务相关配置#############

    # 本示例通过Credentials SDK默认从环境变量中读取AccessKey，来实现身份验证。
    credentialsConfig = CredConfig(
        type='credentials_uri'   # 选填。若您未配置其他“默认凭据链”访问方式，您无需再显式指定，Credentials SDK会通过uri方式获取临时凭证
    )
    cred = CredClient(credentialsConfig)

    # 1. create client;
    dlc_client = DLCClient(
         config=Config(
            credential=cred,
            region_id=region_id,
            endpoint='pai-dlc.{}.aliyuncs.com'.format(region_id),
         )
    )
        
    print('-------- Create Job ----------')
    # 创建DLC作业。
    create_job_resp = dlc_client.create_job(CreateJobRequest().from_map({
        'WorkspaceId': workspace_id,
        'DisplayName': display_name,
        'JobType': 'PyTorchJob',
        # 'ResourceId': resource_quota_id,
        'JobSpecs': [
            {
                "Type": "Master",
                "Image": image_uri,
                "PodCount": 1,
                "EcsSpec": ecs_spec,
            },
        ],
        'DataSources': [
            {
                "DataSourceId": dataset_id,
            },
        ],
       'UserVpc': {
            "VpcId": vpc_id,  # 替换为实际 VPC ID
            "SwitchId": switch_id,  # 替换为实际交换机 ID
            "SecurityGroupId": security_groupid  # 替换为实际安全组 ID
        },
        "UserCommand": f" export WANDB_MODE=offline &amp;&amp; \
            export NCCL_NVLS_ENABLE=0 &amp;&amp; \
            cd /workspace &amp;&amp; \
            python3 /train_pai/train_wrapper.py \
            -d {dataset1_dir} \
            -o {output_dir} \
            --type {data_type} \
            --stage 1 &amp;&amp; \
            python3 /train_pai/train_wrapper.py \
            -d {dataset2_dir} \
            -o {output_dir} \
            --type {data_type} \
            --stage 2 &amp;&amp; \
            sleep 30",
    }))
    job_id = create_job_resp.body.job_id

    wait_for_job_to_terminate(dlc_client, job_id)

    pass


if __name__ == '__main__':
    main()</code></pre><p><img width="723" height="452" referrerpolicy="no-referrer" src="/img/bVdm57n" alt="image.png" title="image.png" loading="lazy"/></p><h2>软件在环验证</h2><h3>模型格式转换</h3><p>使用以下命令将微调得到的X-Mobility模型转换为ONNX格式：</p><pre><code class="python">%cd /X-MOBILITY
# 以sample训练结果为例，请更换为自己的训练结果路径
!python3 onnx_conversion.py -p /mnt/data/notebook3/nav2_output/checkpoints/last.ckpt -o /tmp/x_mobility.onnx

# 请勿随意更改tensorrt路径，此为X-Mobility默认路径
!python3 trt_conversion.py -o /tmp/x_mobility.onnx -t /tmp/x_mobility.engine</code></pre><h3>部署ROS2</h3><p>使用以下脚本部署ROS2环境，以加载X-Mobility模型</p><pre><code class="python"># 创建ros2工作空间文件夹
!mkdir -p ~/ros2_ws/src

# 创建符号链接到x_mobility_navigator ROS2包
!ln -s /X-MOBILITY/ros2_deployment/x_mobility_navigator ~/ros2_ws/src/x_mobility_navigator

# 构建ROS2工作空间
!cd ~/ros2_ws &amp;&amp; colcon build --symlink-install</code></pre><h3>启动VNC</h3><p>X-Mobility模型的软件在环验证使用Isaac Sim + ROS2的组合方案，需要使用VNC以驱动图形化界面。使用以下命令在DSW中启动VNC：</p><pre><code class="shell">/opt/TurboVNC/bin/vncserver :0 -geometry 4000x3000</code></pre><h3>在Isaac Sim中启用ROS2</h3><p>使用如下步骤在Isaac Sim中启动ROS2插件：</p><ol><li><p>进行ROS2预配置</p><pre><code class="bash">source /opt/ros/humble/setup.bash
cd ~/ros2_ws &amp;&amp; source install/setup.bash
source ~/.bashrc
</code></pre></li><li><p>启动Isaac Sim</p><pre><code class="bash">ACCEPT_EULA=Y /isaac-sim/runapp.sh --/persistent/isaac/asset_root/default="/mnt/isaac_assets/5.0"
</code></pre></li><li>通过点击<code>Robotics Examples</code> &gt; <code>ROS2</code> &gt; <code>Navigation</code> &gt; <code>Carter Navigation</code> &gt; <code>Load Sample Scene</code> 启动Carter导航示例</li><li>点击左侧工具栏的<code>Play</code>图标  <br/><img width="723" height="391" referrerpolicy="no-referrer" src="/img/bVdm57p" alt="image.png" title="image.png" loading="lazy"/></li></ol><p>可以新开一个Terminal测试ROS2连接是否正常工作：</p><pre><code class="bash"># 设置ROS2环境
source /opt/ros/humble/setup.bash
cd ~/ros2_ws &amp;&amp; source install/setup.bash
# 列出可用主题
ros2 topic list
</code></pre><p>如果看到以下主题：</p><pre><code class="bash">/back_stereo_imu/imu
/chassis/imu
/chassis/odom
/clock
/cmd_vel
/front_3d_lidar/lidar_points
/front_stereo_camera/left/camera_info
/front_stereo_camera/left/image_raw
/front_stereo_camera/left/image_raw/nitros_bridge
/front_stereo_imu/imu
/left_stereo_imu/imu
/parameter_events
/right_stereo_imu/imu
/rosout
/tf
</code></pre><p>则证明ROS2插件安装成功。</p><h3>启动X-Mobility模型</h3><p>可以通过以下命令在Terminal中启动X-Mobility Navigator软件：</p><pre><code class="bash"># 设置构建的工作空间
cd ~/ros2_ws &amp;&amp; source install/setup.bash
# 启动X-Mobility导航器
ros2 launch x_mobility_navigator x_mobility_navigator.launch.py
</code></pre><p>设置目标姿态：选择<code>2D Goal Pose</code>然后点击地图设置位置/方向。</p><p>如果一切正常，应该看到机器人在模拟中向目标位置移动。<br/><img width="723" height="457" referrerpolicy="no-referrer" src="/img/bVdm57q" alt="" title="" loading="lazy"/></p><h2>总结</h2><p>在本 Notebook 中，我们基于阿里云 PAI 平台的强大功能，完整地演示了使用 Isaac Sim 和 X-Mobility 的通用导航与运动控制工作流，实现了从数据生成、视觉增强到模型训练和仿真部署的端到端流程。</p><p>处理流程包括：</p><ul><li>人工演示: 使用 Isaac Sim 5.0 和 MobilityGen 自动化生成大规模导航演示数据。</li><li>数据扩增（可选）：使用MobilityGen的Random轨迹生成功能，可以快速扩增演示数据。</li><li>数据增强: 利用 Cosmos-Transfer1 对仿真数据进行风格迁移，提升其真实感和多样性。</li><li>模仿学习: 基于生成的数据训练 X-Mobility，一个以世界模型为基础的通用导航与运动控制策略。</li><li>软件在环验证: 将训练好的模型通过 ROS2 集成到 Isaac Sim 中，进行端到端的闭环导航验证。</li></ul><p>通过 Cosmos 增强数据后重新训练的 X-Mobility 模型，在泛化性和鲁棒性上展现了巨大潜力。此工作流为通用机器人导航提供了一套完整的技术方案，显著提升了模型在复杂视觉环境下的泛化能力，并为 Sim2Real 的成功迁移奠定了坚实基础。</p>]]></description></item><item>    <title><![CDATA[从UE到浏览器：我们如何用数字孪生重构园]]></title>    <link>https://segmentfault.com/a/1190000047411854</link>    <guid>https://segmentfault.com/a/1190000047411854</guid>    <pubDate>2025-11-19 17:02:55</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>还记得去年那个让我夜不能寐的项目吗？一家大型科技园区找到我们，希望打造一套能实时监控、分析和优化园区运营的数字系统。他们原有的2D管理系统已经无法满足日益复杂的运营需求，而传统的3D建模方案又面临着开发周期长、硬件要求高、交互体验差等痛点。</p><h2>当UE遇见数字孪生</h2><p>项目启动之初，我们面临的最大挑战是如何在保证视觉效果的同时，实现高效的开发迭代。传统的WebGL方案在渲染质量上总是差强人意，而原生的UE开发又需要高昂的硬件成本和专业的技术团队。<br/>直到我们发现了这个深度集成于Unreal Engine的数字孪生工具。它不是一个独立的应用，而是以插件形式深度融入UE工作流。这意味着我们的美术团队可以继续使用熟悉的UE工具链，同时享受专门为数字孪生优化的功能模块。<br/>最让我惊喜的是，这个工具将数字孪生的构建逻辑——比如对象管理、状态配置、GIS集成——无缝地融入了UE的工作流。我们的场景设计师不再需要在不同软件间来回切换，所有的编辑工作都能在UE中完成。这不仅提升了工作效率，更重要的是保证了最终效果的统一性。</p><h2>从宏观到微观的无缝体验</h2><p>园区的数字孪生需要同时兼顾宏观的整体态势感知和微观的细节查看。传统的方案往往需要构建多个独立场景，在不同尺度间切换时总会有明显的加载和跳转，严重影响了用户体验。<br/>这个工具的内核级GIS支持让我们能够构建从全球尺度到设备级别的连续场景。我们轻松接入了园区的倾斜摄影数据、高程模型和各类地图服务，实现了真实世界与数字空间的高度吻合。<br/>更令人印象深刻的是全球场景与局部场景之间的平滑过渡。当运营人员从园区全景聚焦到某栋建筑的特定楼层，再到某个具体设备时，整个过渡过程如丝般顺滑，没有任何加载中断。这种体验上的提升，让我们的客户第一次演示时就赞不绝口。<br/><img width="640" height="360" referrerpolicy="no-referrer" src="/img/bVdmSiw" alt="" title=""/></p><h2>一键发布的魔力</h2><p>在之前的项目中，最耗费人力的往往不是前期的场景构建，而是后期的打包部署。不同的硬件环境、复杂的依赖配置、繁琐的优化调整，这些工作常常占据项目总工时的30%以上。<br/>这个工具的自动化发布流程彻底改变了这一状况。通过集成的流渲染场景打包服务器，我们实现了从UE工程到可在线访问的流渲染场景服务的一键式转换。系统会自动处理编译、资源优化、打包乃至云端发布的所有环节。<br/>我记得特别清楚，有一次客户在演示前临时要求调整整个园区的光照效果。如果在传统流程下，这样的改动至少需要半天时间重新烘焙和部署。但借助这个工具，我们只用了不到一个小时就完成了所有修改并重新发布。这种效率的提升，在真实的项目环境中简直是革命性的。</p><h2>两种开发模式的完美平衡</h2><p>在园区运营系统的开发中，我们面临着两个看似矛盾的需求：一方面，业务人员希望能够快速配置和调整监控面板；另一方面，开发团队需要足够的灵活性来实现复杂的业务逻辑。<br/>工具的零代码应用编辑器让我们的产品经理和业务专家能够自主搭建基础的数据监控界面。通过拖拽式操作，他们可以集成已发布的场景服务，配置各种数据图表和控件，定义基本的交互逻辑。这不仅解放了开发团队，更重要的是让业务人员能够快速验证想法。<br/>而对于那些需要深度定制的功能，基于JavaScript的低代码开发API提供了充分的灵活性。我们使用同一套API代码，就能够同时控制"端渲染"和"流渲染"两种模式的场景服务。这意味着我们为指挥中心大屏开发的复杂交互逻辑，可以直接复用到桌面业务系统中，大大降低了开发和维护成本。<br/><img width="640" height="360" referrerpolicy="no-referrer" src="/img/bVdmP6A" alt="" title="" loading="lazy"/></p><h2>性能与体验的双重保障</h2><p>园区运营系统往往需要7×24小时不间断运行，同时支持多个部门同时访问。传统的Web3D方案在并发访问时经常出现性能瓶颈，而本地部署的解决方案又受限于终端设备的图形能力。<br/>工具的流渲染技术将复杂的图形计算放在服务器端完成，客户端只需要接收和显示视频流。这意味着运营人员使用普通的办公电脑就能流畅访问高精度的三维场景。结合UE5的Nanite技术，系统能够自动管理海量模型的细节级别，在保证视觉效果的同时维持稳定的性能表现。<br/>更让我们放心的是系统的高并发支持能力。通过多机组网集群，我们可以根据用户量的增长动态扩展渲染节点。在园区举行大型活动期间，系统成功支撑了数十个部门的同时访问，没有出现任何性能问题。<br/><img width="640" height="360" referrerpolicy="no-referrer" src="/img/bVdmSiz" alt="" title="" loading="lazy"/></p><h2>实战经验分享</h2><p>在这个项目的实施过程中，有几个关键经验值得分享：<br/><strong>尽早建立原型</strong>：我们利用零代码工具在项目初期就搭建了可交互的原型，这不仅帮助客户更好地理解最终效果，也为后续的详细设计提供了重要参考。<br/><strong>渐进式功能开发</strong>：我们先使用零代码工具实现基础功能，快速满足客户的迫切需求，然后再基于低代码API逐步添加复杂功能，这种策略有效降低了项目风险。<br/><strong>充分利用双模式优势</strong>：我们为不同的使用场景选择了合适的渲染模式——指挥中心使用流渲染保证视觉效果，日常办公使用端渲染支持高并发，这种组合既控制了成本，又满足了多样化的需求。</p><h2>展望未来</h2><p>经过这个项目的实践，我深刻体会到，优秀的数字孪生工具应该像这个平台一样，既要提供强大的技术能力，又要保持足够的易用性。它不应该成为开发团队的负担，而应该成为放大团队能力的倍增器。<br/>如今，这个园区运营系统已经稳定运行了大半年，每天帮助管理人员优化能源使用、提升安防效率、改善空间利用率。看到我们的技术真正为客户的业务创造价值，这种成就感是任何技术指标都无法衡量的。</p>]]></description></item><item>    <title><![CDATA[Apache NetBeans 28 (]]></title>    <link>https://segmentfault.com/a/1190000047411857</link>    <guid>https://segmentfault.com/a/1190000047411857</guid>    <pubDate>2025-11-19 17:02:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>Apache NetBeans 28 (macOS, Linux, Windows) - Java 等多语言开源跨平台 IDE</p><p>Development Environment, Tooling Platform and Application Framework</p><p>请访问原文链接：<a href="https://link.segmentfault.com/?enc=pWgwL49aN%2B3k%2FLFuP7ZwKQ%3D%3D.tqswGXnUjQ0NMHHyx1%2FblLwaeIRMEuXzexgpiCp%2F6djz9zfs2ozZR%2B%2B7S0C1dKBv" rel="nofollow" target="_blank">https://sysin.org/blog/netbeans/</a> 查看最新版。原创作品，转载请保留出处。</p><p>作者主页：<a href="https://link.segmentfault.com/?enc=iqps1zH2a%2Fv4Fdvy70aIQw%3D%3D.5PoVh0%2BBRejrEhrVMVN0Kh5atvs6AtdFDINeOH%2BM3z8%3D" rel="nofollow" target="_blank">sysin.org</a></p><hr/><p><img referrerpolicy="no-referrer" src="/img/remote/1460000046215720" alt="NetBeans" title="NetBeans"/></p><h2>NetBeans 简介</h2><p>NetBeans 是一款功能强大的开源跨平台集成开发环境（IDE），最初由 Sun Microsystems 开发，现由 Apache  基金会维护。它支持 Java、Python、C/C++、PHP  等多种语言，内置智能代码补全、调试、单元测试和版本控制工具，尤其适合企业级应用开发。其模块化设计允许用户通过插件扩展功能，例如支持微服务、AI  辅助编码和云计算集成。此外，NetBeans 提供了可视化设计器和性能分析工具，广泛应用于桌面应用、Web  服务及移动端（Android/iOS）开发，拥有活跃的社区支持和持续的技术更新。</p><ul><li><p><strong>快速、智能的编辑</strong></p><p>Apache NetBeans 不仅仅是一个文本编辑器。它从语法和语义上突出显示源代码，让您能够使用一系列方便而强大的工具轻松重构代码。</p></li><li><p><strong>Java、JavaScript、PHP、HTML5、CSS 等</strong></p><p>Apache NetBeans 提供编辑器、向导和模板来帮助您创建 Java、PHP 和许多其他语言的应用程序。</p></li><li><p><strong>跨平台</strong></p><p>Apache NetBeans 可以安装在所有支持 Java 的操作系统上，即 Windows、Linux、macOS 和 BSD。一次编写，随处运行，也适用于 NetBeans。</p></li></ul><h2>新增功能</h2><p>Apache NetBeans 28 was released on November 11, 2025.</p><p>内容较多，详见：<a href="https://link.segmentfault.com/?enc=HVR5jdKEDR9Yt%2F8JzHxakg%3D%3D.sLdWJULn3Jv9jwVoUaOvzF0lfIeoZz8CQM8USDY6WCrZqgA8sFqH8NvEWO60zPKi" rel="nofollow" target="_blank">GitHub Releases</a></p><h2>下载地址</h2><p>Apache NetBeans 28 (macOS, Linux, Windows)</p><ul><li>请访问：<a href="https://link.segmentfault.com/?enc=d0rs98xCMZbqFRTIyjZTsA%3D%3D.M60Tvo%2Bf8PMLkoQQQixDDrOL%2Bbti4kCx%2BCWHwD0IxmOmt0R6HTr%2B%2FkFPWGNiiHJ%2F" rel="nofollow" target="_blank">https://sysin.org/blog/netbeans/</a></li></ul>]]></description></item><item>    <title><![CDATA[隐语可信数据空间MOOC第23讲笔记：差]]></title>    <link>https://segmentfault.com/a/1190000047411864</link>    <guid>https://segmentfault.com/a/1190000047411864</guid>    <pubDate>2025-11-19 17:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>📊 差分隐私基础理论与核心概念学习笔记</h2><p>笔记内容来自隐语Mooc，欢迎一起来学习。Mooc课程地址：<a href="https://link.segmentfault.com/?enc=qBI8vKEBhlm5QMRnl3JJ%2Fw%3D%3D.fz6pdcGiUZ%2BCiyadrIVta3SkXlX1CvyLCFwq3PY3YHNl84E9oDhoFKLPblES%2F0u9SA0en0q%2BLzq6goz%2Fe46rKnmHUUDplP6zUzXUbp3zZWmw0WJ92TBgZv8k0%2FC%2F37UYzjn6IIzv5VC%2F09dcoaW5IQ%3D%3D" rel="nofollow" target="_blank">https://www.secretflow.org.cn/community/bootcamp/2narwgw4ub8r...</a></p><h3>一、传统匿名技术及其局限性</h3><h4>1. 数据隐私泄露问题</h4><ul><li><strong>关键属性</strong>：姓名、身份证号、手机号等可直接识别个体的属性</li><li><strong>准标识符</strong>：属性组合（邮政编码+生日+性别）可唯一识别大部分个体</li><li><strong>敏感属性</strong>：研究人员需要但需保护的数据（如疾病、收入）</li></ul><h4>2. k-匿名技术</h4><h5>核心原理：</h5><ul><li>每个记录与至少k-1个其他记录不可区分</li><li>组成等价类，隐藏个体身份</li></ul><h5>实现方法：</h5><ul><li><strong>泛化</strong>：用不太具体但语义一致的值替换准标识符</li><li><strong>示例</strong>：年龄29、22、27 → 2*（20-29岁）</li></ul><h5>缺陷：</h5><ul><li>等价类中敏感值缺乏多样性时仍会泄露隐私</li><li>无法抵抗背景知识攻击</li></ul><h4>3. l-多样性技术</h4><h5>改进点：</h5><ul><li>每个等价类中的敏感属性必须"多样化"</li><li>防止同质性攻击</li></ul><h5>局限性：</h5><ul><li>不考虑敏感属性语义</li><li>存在相似性攻击和偏斜性攻击</li></ul><h4>4. t-接近技术</h4><h5>核心思想：</h5><ul><li>等价类内敏感属性分布应接近原始数据库中的总体分布</li><li>防止分布不一致导致的隐私泄露</li></ul><h3>二、中心化差分隐私</h3><h4>1. 基本概念</h4><h5>核心思想：</h5><ul><li>精确统计结果会泄露个人隐私 → 添加随机噪声</li><li>相邻数据集：最多相差一条记录的两个数据集</li></ul><h5>数学定义（ε-差分隐私）：</h5><p>对于任意相邻数据集D和D′，任意输出o，满足：</p><pre><code>Pr[f(D)=o] / Pr[f(D′)=o] ≤ exp(ε)</code></pre><h4>2. 隐私损失度量</h4><h5>Renyi散度：</h5><ul><li>连续分布：Dₐ(P//Q) = 1/(α-1) log Eₓ∼Q[(P(X)/Q(X))^α]</li><li>离散分布：类似定义</li><li>α=1：KL散度；α=+∞：最大散度</li></ul><h4>3. Laplace机制</h4><h5>适用场景：</h5><ul><li>结果为实数或实数向量</li></ul><h5>实现方法：</h5><ul><li>在精确结果中加入Laplace噪声</li><li>噪声规模：λ = s(f)/ε</li><li>s(f)：函数敏感度（修改一条记录对输出的最大影响）</li></ul><h5>概率密度函数：</h5><pre><code>pdf(x) = 1/(2λ) exp(-|x|/λ)</code></pre><h4>4. 指数机制</h4><h5>适用场景：</h5><ul><li>从集合中选取一个或多个元素</li></ul><h5>实现方法：</h5><ul><li>选定评分函数f</li><li>选中概率与exp(f(I)/λ)成正比</li><li>λ ≥ 2S(f)/ε 保证ε-差分隐私</li></ul><h4>5. 组合性质</h4><h5>串行组合：</h5><ul><li>m个算法分别满足εᵢ-差分隐私</li><li>整体满足∑εᵢ-差分隐私</li></ul><h5>并行组合：</h5><ul><li>数据集划分为互不相交的子集</li><li>整体满足max(εᵢ)-差分隐私</li></ul><h3>三、本地差分隐私</h3><h4>1. 基本框架</h4><h5>与中心化的区别：</h5><ul><li><strong>中心化</strong>：数据管理者添加噪声</li><li><strong>本地化</strong>：用户在本地扰动数据后上传</li></ul><h5>协议流程：</h5><ol><li><strong>编码</strong>：输入值 → 编码值</li><li><strong>扰动</strong>：编码值 → 扰动值</li><li><strong>聚合</strong>：收集所有扰动值</li><li><strong>估计</strong>：估计原始数据统计信息</li></ol><h4>2. 随机响应机制（RR）</h4><h5>适用场景：</h5><ul><li>二值属性数据（0/1）</li></ul><h5>扰动概率：</h5><pre><code>Pr[Perturb(x)=1] = { p = e^ε/(e^ε+1) if i=x
                    { q = 1/(e^ε+1)   if i≠x</code></pre><h5>估计方法：</h5><pre><code>π̃(i) = [c(i) - nq] / (p - q)</code></pre><h5>性质：</h5><ul><li>无偏估计：E(π̃) = π</li><li>方差：D(c̃(i)) = n·e^ε/(e^ε-1)²</li></ul><h4>3. 广义随机响应（GRR）</h4><h5>适用场景：</h5><ul><li>多值属性数据（d个取值）</li></ul><h5>扰动概率：</h5><pre><code>p = e^ε/(e^ε + d - 1)
q = 1/(e^ε + d - 1)</code></pre><h4>4. 一元编码机制（UE/OUE）</h4><h5>编码方法：</h5><ul><li>生成d维向量，对应位为1，其他为0</li><li>示例："优"→[1,0,0]，"良"→[0,1,0]</li></ul><h5>扰动参数：</h5><ul><li>原始UE：p + q = 1</li><li>优化OUE：p = 1/2, q = 1/(e^ε + 1)</li><li>OUE方差更小且与取值空间无关</li></ul><h4>5. RAPPOR机制</h4><h5>特点：</h5><ul><li>Google开发的隐私保护技术</li><li>使用布隆过滤器和随机化组合</li></ul><h5>双重扰动：</h5><ol><li><strong>永久随机响应</strong>：对编码向量的每位进行随机响应</li><li><strong>瞬时随机响应</strong>：每次收集数据时再次随机响应</li></ol><h5>优势：</h5><ul><li>提供更强的隐私保护</li><li>支持频繁数据收集</li></ul><h3>💡 关键技术对比</h3><table><thead><tr><th>技术</th><th>适用场景</th><th>核心思想</th><th>优势</th><th>局限</th></tr></thead><tbody><tr><td><strong>k-匿名</strong></td><td>数据发布</td><td>组成等价类</td><td>简单易实现</td><td>无法抵抗背景知识攻击</td></tr><tr><td><strong>Laplace机制</strong></td><td>数值查询</td><td>添加拉普拉斯噪声</td><td>理论完备</td><td>可能影响数据效用</td></tr><tr><td><strong>随机响应</strong></td><td>本地二值数据</td><td>概率性响应</td><td>保护个体隐私</td><td>估计方差较大</td></tr><tr><td><strong>RAPPOR</strong></td><td>频繁数据收集</td><td>双重扰动+布隆过滤</td><td>强隐私保护</td><td>实现复杂度高</td></tr></tbody></table><h3>🎯 核心要点总结</h3><ol><li><strong>差分隐私核心</strong>：通过添加受控噪声，在保护个体隐私的同时保持数据效用</li><li><strong>隐私预算ε</strong>：平衡隐私保护与数据可用性的关键参数</li><li><strong>本地vs中心化</strong>：根据信任模型选择不同的技术路线</li><li><strong>机制选择</strong>：根据数据类型（数值/分类）和场景（中心化/本地化）选择合适的隐私保护机制</li><li><strong>组合性质</strong>：在实际应用中合理分配隐私预算</li></ol>]]></description></item><item>    <title><![CDATA[CRM系统都能做什么？功能与场景速览 遭]]></title>    <link>https://segmentfault.com/a/1190000047411264</link>    <guid>https://segmentfault.com/a/1190000047411264</guid>    <pubDate>2025-11-19 16:22:39</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>客户信息散落Excel、销售进度靠口头汇报、营销活动结果“凭感觉”——碎片化经营正在悄悄吞噬企业利润。CRM系统把客户、商机、合同、服务拉到同一平台，用数据驱动每一次跟进和决策。下文拆解CRM七大核心功能，并结合Zoho CRM实例，让你一眼看懂“客户关系管理”如何变成“业绩增长引擎”。<br/><img width="512" height="340" referrerpolicy="no-referrer" src="/img/bVdm5ZX" alt="" title=""/><br/>一、CRM系统的基本概念<br/>CRM系统（客户关系管理系统）是一款旨在改善企业与客户关系的综合应用软件。它通过集成客户信息、销售、营销和服务等功能模块，为企业提供全面的客户管理解决方案。</p><p>从本质上讲，CRM系统的使命是整合不同部门的客户信息，并通过分析和优化这些数据，帮助企业在客户生命周期的各个阶段实施有效的策略。</p><p>二、CRM系统的核心功能</p><ol><li>客户信息管理<br/>CRM系统的核心功能之一是客户信息的集中管理。Zoho CRM 提供了强大的客户档案管理功能，帮助企业收集客户的详细信息，包括联系方式、购买历史、偏好和互动记录等。通过将这些信息集中在一个平台上，企业可以轻松进行客户分析，深入了解客户需求和行为。</li><li>销售自动化<br/>销售自动化是CRM系统的另一个关键功能。它能够帮助销售团队高效管理销售过程，从潜在客户跟踪到最终成交的全过程。Zoho CRM 提供了智能化的销售预测和报告功能，帮助企业识别机会、规划销售策略，提高成交率，从而实现销售业绩的最大化。</li><li>营销自动化<br/>CRM系统的另一重要功能是营销自动化。像Zoho CRM这样的系统，可以帮助企业设计并执行精准的营销活动，把合适的信息在合适的时间传递给合适的客户。借助自动化工具，企业能够轻松实施电子邮件营销、社交媒体推广等多渠道营销策略，从而提升营销效率和效果。</li><li>客户服务与支持<br/>有效的客户服务不仅依赖于单次良好的客户体验，更在于持续的、个性化的客户支持。通过Zoho CRM，企业可以提供全天候客户支持，自动化处理客户查询，确保客户需求得到及时满足。同时，CRM系统能够记录并分析客户的每一次互动，为企业改进服务质量提供方向。</li></ol><p>三、CRM系统的扩展功能</p><ol><li>数据分析与报告<br/>在数字化时代，数据是企业决策的重要依据。现代CRM系统通过数据分析功能提供深刻洞察。Zoho CRM 提供详细的报告和分析工具，包括销售趋势分析、市场活动效果评估等，为管理层提供决策支持。</li><li>移动CRM<br/>如今，CRM系统普遍支持移动设备访问。Zoho CRM 提供了功能强大的移动App，使员工能够随时随地进行客户管理。无论是外勤销售人员还是远程工作者，都可以通过移动CRM获取最新的客户信息和业务数据，提高工作效率。</li><li>社交媒体整合<br/>在社交媒体时代，CRM系统与社交媒体的整合变得至关重要。Zoho CRM 提供了良好的社交媒体整合功能，企业可以在一个平台上直接查看和管理来自不同社交渠道的客户互动。这种整合不仅便于企业开展社交营销活动，还能及时响应客户需求。</li><li>自动化工作流程<br/>CRM系统还可以自动化日常工作流程，减少人为错误、提高效率。Zoho CRM 的工作流程自动化功能允许用户自定义和优化各种业务流程，从而满足企业独特需求。这种自动化能够帮助企业合理分配资源，进一步提升效率。</li></ol><p>四、如何选择适合的CRM系统<br/>在选择CRM系统时，企业需要综合考虑以下因素：</p><p>功能全面性：是否能满足企业的核心需求。<br/>界面友好性：操作是否简单易用。<br/>兼容性：能否与现有系统无缝集成。<br/>价格：是否符合预算。<br/>Zoho CRM 凭借全面的功能和灵活的定制能力，成为许多企业的首选。此外，企业还需确保所选CRM系统具有良好的可扩展性和技术支持，以便在业务发展过程中进行调整和扩展。</p><p>五、总结<br/>CRM不是软件，而是企业增长的数字化引擎。立即免费试用Zoho CRM，15天解锁客户360°视图、销售自动化、AI预测和移动外勤全功能；按需扩容最低年费不足一顿聚餐钱，却能把线索转化率提升30%以上。用Zoho CRM让每一笔生意都有数据可追踪、可复制、可增长，未来竞争从第一封跟进邮件就已分胜负。</p>]]></description></item><item>    <title><![CDATA[AI降噪引领下的合规新格局——金融API]]></title>    <link>https://segmentfault.com/a/1190000047411266</link>    <guid>https://segmentfault.com/a/1190000047411266</guid>    <pubDate>2025-11-19 16:21:45</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>一、概要：（提示：在金融行业数字化深入推进的背景下，API已成为支撑业务创新的关键载体。）金融行业的数字化转型正从“系统互联”迈向“数据智能”。在这一过程中，API承担着开放银行、跨境支付、智能投顾等核心业务的连接枢纽，成为金融科技生态的核心接口。然而，随着调用规模爆炸式增长，API已从“业务桥梁”演变为潜在的“风险通道”。针对这一趋势，推出了“<a href="https://link.segmentfault.com/?enc=nrugVA0%2B%2B6dd4TU5yc3gNw%3D%3D.wqmNh7jCVna87zrxYlJ%2FNmGQ7YwzHMg%2F9ryZPjSNazM%3D" rel="nofollow" target="_blank">知影-API风险监测系统</a>”，以AI降噪、合规审计与行业通用性为三大技术特征，通过精准识别、智能防护与高效审计，为金融机构构建起全生命周期的API安全防线。该系统在多个头部金融机构落地后，实现了显著成效：告警准确率提升至94%以上，漏洞整改周期缩短70%，风险处置时间由天级降至小时级。更重要的是，它成功实现了业务不中断、监管合规可查、数据风险可控的安全闭环，为金融机构在合规前提下稳健创新提供了坚实支撑。<br/>二、监管趋严与业务开放的双重压力（提示：金融行业正在经历监管加强与业务创新并行的复杂安全环境。）近年来，《数据安全法》《网络安全审查办法》《商业银行应用程序接口安全管理规范（JR/T 0185—2020）》等法规的出台，使API安全不再是“技术问题”，而成为影响金融机构合规与声誉的系统性议题。与此同时，开放银行、第三方支付、跨境结算等新业务模式，使API调用量呈指数级增长。头部银行日均API调用量超过千万次，客户服务、风控模型、内部审计等核心环节均依赖API实现。但传统防护体系——如防火墙、WAF、IDS——多依赖固定特征匹配，无法识别加密流量中的隐蔽攻击，更难防范内部权限滥用、逻辑越权等复杂行为。API安全从“外围防御”转向“全生命周期治理”已成必然。金融机构急需一套既能满足业务连续性，又能响应监管要求的智能化安全体系。<br/>三、行业痛点分析：资产不清、风险难控、合规难查（提示：API安全问题的根源在于资产可视化不足与风险响应滞后。）首先，资产不清是普遍难题。大型金融机构的API分散在多个业务系统中，接口数量庞大且动态变化，导致“影子API”“僵尸API”频繁存在，资产台账长期不完整。其次，风险难控。水平越权、参数篡改、批量数据拉取等业务逻辑攻击占API安全事件的60%以上，而传统设备缺乏业务语义识别能力，难以及时发现。最后，合规难查。监管机构要求API访问、变更、调用日志可回溯180天以上，但传统系统日志分散、容量庞大，导致审计效率低下，难以支撑快速溯源和责任认定。这三大痛点共同导致金融机构在应对数据泄露与合规检查时“防不胜防”。企业迫切需要一种智能化、自动化且具行业通用性的API安全体系，实现风险可视、行为可控、日志可查的全链路管理。<br/>四、解决方案：AI降噪赋能的全生命周期安全防护体系（提示：针对金融场景复杂、数据敏感度高的特点，全知科技构建了智能合规双驱动体系。）“知影-API风险监测系统”以“不中断业务、精准防护、智能审计”为核心理念，构建从资产识别到风险闭环的全周期防护架构。（1）智能资产识别：系统通过7×24小时流量解析自动识别RESTful、gRPC、Dubbo3等主流协议，精准发现影子API并生成敏感度分级台账，解决金融机构“看不清”的问题。（2）漏洞与弱点检测：结合AI语义建模与自动化渗透测试，系统可快速识别权限绕过、越权访问等高危漏洞，并根据资金风险级别生成整改优先级。（3）AI降噪防护：通过训练数千万条API行为样本，建立金融行为基线模型，利用AI算法区分“异常调用”与“正常高频访问”，将误报率控制在5%以下，实现“安全不打扰业务”。（4）合规审计与日志溯源：系统支持自动生成《商业银行API安全规范》报告，存储结构化日志并支持180天回溯查询，满足监管审计要求。（5）行业通用适配：无需改造银行核心系统即可快速部署，兼容互联网、内网、办公网等多网络环境，并与行内风控、数据中台无缝集成，实现“风险监测—处置—合规归档”一体化闭环。通过以上多层防护体系，系统不仅解决了风险识别与误报问题，更实现了合规化管理与数据可信运营。<br/>五、应用落地：从“风险响应”到“安全运营”的转变（提示：技术的真正价值在于落地成效与可持续运营。）某头部国有银行曾因内部数据泄露事件遭监管约谈，其API资产超过8000个，日调用量1200万次。部署知影-API风险监测系统前，接口风险告警准确率仅32%，整改周期超过72小时。引入“知影-API风险监测系统”后，该行构建了基于AI降噪引擎与合规审计中心的全流程防护体系：通过三维越权检测模型，将水平越权事件识别准确率提升至93%；AI降噪模块自动过滤重复与误报事件，使告警准确率提升至94.2%；与内部审计系统对接，实现“监测—取证—审计”闭环。系统上线三个月后，共拦截高危攻击事件147起，全部在1小时内完成预警响应，无一造成数据泄露；平均漏洞修复周期从72小时缩短至24小时。更重要的是，该银行的合规审计响应时间从3天缩短至30分钟，显著提升了合规运营效率。<br/>六、推广价值：打造金融行业API安全“共识标准”（提示：技术推广的意义在于行业复制性与监管适配性。）“知影-API风险监测系统”不仅是一款安全工具，更是金融行业安全治理方法论的具体实践。其推广价值体现在以下五方面：一是标准化落地能力强，内置110多种金融敏感数据模板，符合金融行业通用规范；二是智能降噪提升效率，通过AI算法减少80%以上误报，节省安全运营人力成本；三是快速合规审计，自动生成报告、支持可视化取证，满足各类检查；四是跨机构兼容性高，可在国有银行、股份制银行、保险、券商等多机构无缝部署；五是持续演化机制完善，系统每月更新攻击模型库，应对新型逻辑攻击，实现常态防御。这使得全知科技方案不仅在头部金融机构广泛落地，也成为金融安全标准化、行业通用化的重要推力。<br/>七、问答环节：Q1：AI降噪技术如何确保“安全不干扰业务”？A：知影-API风险监测系统基于金融API行为基线建模，区分高频访问与攻击特征，并通过机器学习动态优化规则，将误报率控制在5%以下，实现“精准识别、无感防护”。Q2：如何满足金融监管的合规审计要求？A：自动生成符合《JR/T 0185—2020》规范的合规报告，支持180天日志回溯与结构化提取，满足等保与内部稽核双重审计需求。Q3：该系统为何具备行业通用性？A：知影-API风险监测系统采用模块化设计，支持RESTful、gRPC、Dubbo3等多协议识别，适配不同金融业态，可跨银行、证券、保险机构部署，快速复用。Q4：与传统WAF有何区别？A：传统WAF基于特征防御，而本系统基于业务语义分析与AI行为建模，可识别逻辑越权与数据滥用等高阶风险，实现“懂业务的安全”。Q5：能否支持多地区、多机房运维？A：支持多节点部署架构，通过中心平台统一策略下发和风险汇聚，大幅降低跨区运维成本，适配大型金融机构架构。<br/>八、用户评价在多家大型金融机构中，用户一致反馈系统具备“部署灵活、识别精准、审计便捷”的特性。某股份制银行信息安全负责人评价：“系统AI降噪能力极强，真正实现了安全与业务的平衡，合规审计响应速度提升近十倍。”另一家保险集团则指出，该系统在与内部风控平台联动后，实现了API攻击从“事后修复”到“实时防御”的根本转变。作为《数据接口安全风险监测方法》国家标准牵头制定单位，其“知影-API风险监测系统”已通过中国信通院评测，获评“金融数据安全优秀解决方案”。同时入选Gartner《Hype Cycle for Data, Analytics and AI in China, 2023》报告推荐厂商。未来，全知科技将继续以AI智能算法为驱动，推进API风险监测、数据治理与合规审计的深度融合，打造“行业通用、智能降噪、合规可信”的安全防线，助力金融机构在数字化浪潮中稳健前行。</p>]]></description></item><item>    <title><![CDATA[图解 Apache DolphinSch]]></title>    <link>https://segmentfault.com/a/1190000047411277</link>    <guid>https://segmentfault.com/a/1190000047411277</guid>    <pubDate>2025-11-19 16:20:53</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>飞书创建群，并添加自定义机器人</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047411279" alt="5e28279c857c75cc83226fcae434f180" title="5e28279c857c75cc83226fcae434f180"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047411280" alt="3de395b7f1d5a5edf5119f806338e874" title="3de395b7f1d5a5edf5119f806338e874" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047411281" alt="69d22b160c6487233fb84b4235d1b781" title="69d22b160c6487233fb84b4235d1b781" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047411282" alt="961c3f1b1e608fe992aab8358f711e0f" title="961c3f1b1e608fe992aab8358f711e0f" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047411283" alt="cfccd9406d54e7214cb6eef4e03a0682" title="cfccd9406d54e7214cb6eef4e03a0682" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047411284" alt="58dc0c330516c3b64d14ab448dff938c" title="58dc0c330516c3b64d14ab448dff938c" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047411285" alt="184ffa5464718ca4fb776a008c60c03b" title="184ffa5464718ca4fb776a008c60c03b" loading="lazy"/></p><p>记住这个【Webhook】后面配置【海豚告警】的时候会用到。</p><h2>配置告警</h2><p>在【安全中心】中，选择【告警实例管理】中的【创建告警实例】。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047411286" alt="a3c57f8516bca65a7aa5d0c6e94d3f57" title="a3c57f8516bca65a7aa5d0c6e94d3f57" loading="lazy"/></p><p>在【选择插件】中，选择【Feishu】，将前面的【Webhook】填进【Web钩子】。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047411287" alt="ffc8397d88618dded54cbee9fc1ecf25" title="ffc8397d88618dded54cbee9fc1ecf25" loading="lazy"/></p><p>然后，在【安全中心】的【告警组管理】中，创建对应的告警组：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047411288" alt="2b70e87836a503556cc24c38539c70d2" title="2b70e87836a503556cc24c38539c70d2" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047411289" alt="7d1cc0c15b52213c3912eed939147968" title="7d1cc0c15b52213c3912eed939147968" loading="lazy"/></p><p>这样，告警组就创建好了。</p><h2>验证告警组配置</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047411290" alt="485cb0c322254841a9d22ae8058c31fd" title="485cb0c322254841a9d22ae8058c31fd" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047411291" alt="14ff2796a29e2306a6be6977f1fbe2e7" title="14ff2796a29e2306a6be6977f1fbe2e7" loading="lazy"/></p><p>以上的配置，不论工作流运行是否成功，都会触发自定义机器人推送海豚任务的告警信息：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047411292" alt="f6bd111a5b05b60f251c09020f9d8b70" title="f6bd111a5b05b60f251c09020f9d8b70" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[数据安全平台：以智能识别与高准确率构筑降]]></title>    <link>https://segmentfault.com/a/1190000047411331</link>    <guid>https://segmentfault.com/a/1190000047411331</guid>    <pubDate>2025-11-19 16:20:12</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>（提示：数据安全平台正在成为组织数字化转型中的关键基座，其价值体现在“高准确率、智能识别、降本增效”的落地成效上。）<br/>一、概要<br/>随着《数据安全法》《网络数据安全管理条例》等法规的相继落地，数据安全已成为企业治理体系中不可或缺的组成部分。传统的安全防护模式更多依赖于防火墙、加密、审计等手段，但在多云架构、API经济、数据流动日益复杂的今天，这些单点式防御早已难以满足动态化、实时化的安全需求。数据安全平台的出现，标志着从“防御体系”向“治理体系”的全面升级。<br/>现代数据安全平台以智能识别、全链路可视与高准确率预警为核心能力，通过数据接入、标准化、分析与响应的闭环治理，实现从“风险发现”到“风险处置”的全过程自动化。它不仅帮助组织提高风险识别精准度，还能有效降低人力成本与误报噪声，从而实现降本增效。平台的部署实践显示，在AI降噪与智能匹配算法加持下，误报率可降低至5%以内，真实风险捕获率提升至98%，而平均处置时长缩短70%以上，形成显著的经济与治理双重价值。<br/>从整体来看，数据安全平台的建设不仅是技术升级，更是组织治理能力现代化的体现。它以智能化、系统化、平台化的方式，将分散的数据安全行为整合为可度量、可追溯、可闭环的体系支撑，使数据安全真正融入业务运行之中，成为可信数字化建设的底座。<br/>二、<a href="https://link.segmentfault.com/?enc=0TcX%2BIJRM0izlkibsIaRnw%3D%3D.NgSPYXWfYhACHkI3Vk6KYyj%2FVudniG0iCfDpizWI9vw%3D" rel="nofollow" target="_blank">数据安全平台是什么</a><br/>（提示：数据安全平台是一种融合数据治理、安全分析与智能响应的系统化解决方案。）<br/>（一）数据安全平台的核心逻辑<br/>数据安全平台的核心逻辑在于“从数据出发，构建安全闭环”。在传统安全体系中，监测往往局限于系统、网络或终端层面，而忽略了数据作为核心生产要素的流动路径。平台的创新点在于引入“泛监测体系”，将数据源头、流转、使用与销毁全过程纳入统一的安全可视化管理之中。<br/>这一逻辑的实现依托于“观测面 + 控制面”的双轮驱动架构。观测面通过流量镜像、日志采集和轻量Agent实现对全域数据的覆盖，无需改造现有业务系统，确保“零侵入式”接入；控制面则承担策略执行与响应联动，通过智能规则匹配与AI降噪模型，实现风险的自动判别与响应。<br/>同时，平台将来自数据库、API、云服务、终端的异构数据统一转换为标准化事件格式（如JSON-LD），并通过动态图谱引擎构建数据流动的“数字孪生模型”。这种图谱化管理不仅让数据流转路径“可见”，更让风险事件的成因、血缘与影响范围“可追”，从根本上解决了传统监测“看不全、查不准”的痛点。<br/>（二）数据安全平台的核心能力<br/>泛监测覆盖：平台通过多源接入与标准化处理，实现从数据库、API接口、云存储到终端设备的全场景覆盖，最大限度消除监测盲区。在复杂组织架构中，这意味着可同时监测超过200个节点，实现对数据流转的端到端感知。<br/>智能识别分析：平台融合规则引擎与AI算法，结合UEBA（用户与实体行为分析）模型，动态学习用户行为基线，智能识别越权访问、批量导出等隐性威胁。AI降噪模块能够有效过滤无效告警，将误报率控制在5%以下，提升告警质量与分析准确性。<br/>非侵入式部署：平台采用旁路采集与镜像分析模式，无需嵌入业务探针或改造系统架构，既避免业务中断风险，又降低部署成本。其可插拔式驱动机制允许快速适配新系统或异构环境，实现快速上线与平滑扩展。<br/>多设备协同响应：在风险处置阶段，平台能与防火墙、WAF、日志系统等20余类安全设备联动，实现自动阻断、实时溯源与审计留痕。通过策略映射机制，平台将监测与响应纳入闭环管理体系，形成“发现—处置—追溯—优化”的动态演化链条。<br/>此外，平台内置持续进化机制，将处置经验沉淀为RAG（检索增强生成）知识库，用于优化模型特征与规则阈值。长期运行中，系统可根据业务特征与威胁变化自主调整参数，实现自学习与自演化，使其具备“越用越准”的特性。<br/>三、数据安全平台常见的FAQ<br/>（提示：在平台建设与应用中，组织最关注的问题集中在准确率、降本增效与智能识别三个维度。）<br/>Q1:数据安全平台如何实现高准确率？<br/>A:通过多模态识别引擎、AI降噪与图谱验证三层机制，平台能在复杂场景中保持超过90%的识别准确率，误报率控制在5%以内。<br/>Q2:数据安全平台如何实现降本增效？<br/>A:非侵入式部署免改造系统，自动化分析替代人工排查，人力成本可降约60%；模板化配置使部署周期缩短至7天，运维负担显著降低。<br/>Q3:数据安全平台的智能识别体现在哪？<br/>A:AI模型能自适应不同业务场景，分析用户行为基线，识别隐蔽越权与跨系统泄露行为，实现从“发现问题”到“理解问题”的智能演进。<br/>Q4:平台能否支撑法规合规？<br/>A:内置《数据安全法》《个人信息保护法》等法规模板，自动生成合规报告，提供全程审计留痕，满足监管检查要求。<br/>Q5:实际效果如何？<br/>A:例如某省政务云平台上线后，三个月识别28起异常事件（含8起高风险），全部在1小时内阻断，告警准确率由30%提升至92%，整改周期缩短至20小时。<br/>四、发展趋势<br/>(提示：数据安全平台的未来方向，将从“监测工具”迈向“治理中枢”。)<br/>随着云原生、边缘计算与大模型技术的快速发展，数据安全平台正呈现出四大趋势：<br/>从被动防御向主动治理演进<br/>未来平台将不再只是被动识别与告警的工具，而是嵌入企业数据治理体系的“安全大脑”。通过RAG知识库与策略迭代机制，平台可主动预测潜在风险并生成防御方案，具备预防性安全能力。<br/>从单体平台向生态联动扩展<br/>随着跨域数据交换与多方协作增多，平台将逐步形成开放生态，与DLP、SIEM、IAM等系统互联互通，构建统一的数据安全管控中心，实现全域数据治理协同。<br/>从AI识别向智能决策升级<br/>AI不再只是识别辅助，而是成为决策主体。平台将利用自监督学习、因果推断等算法，结合业务上下文进行风险优先级排序与动态处置决策，从“看得见”走向“懂得判”“会响应”。<br/>从技术建设向价值运营转化<br/>未来的数据安全平台不仅关注风险防控效能，还将延伸至数据资产价值运营层面。通过监测数据流转与使用行为，企业可洞察数据价值链条，优化资源配置，实现“安全即生产力”的价值闭环。<br/>数据安全平台的价值，不仅在于构建防御体系，更在于以智能识别、高准确率与降本增效为核心，实现组织治理能力的持续提升。它是合规的保障者，是风险的守护者，更是企业数字化转型的赋能者。<br/>在未来，随着可信数据基础设施的不断完善，数据安全平台将继续演化为数字治理的中枢系统，成为每一个数字化组织的底层“安全基因”。</p>]]></description></item><item>    <title><![CDATA[数据分类分级理论研究：自适应智能驱动下的]]></title>    <link>https://segmentfault.com/a/1190000047411342</link>    <guid>https://segmentfault.com/a/1190000047411342</guid>    <pubDate>2025-11-19 16:19:34</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>（提示：随着数据成为关键生产要素，分类分级体系正从“静态规则”迈向“智能认知”，推动数据安全治理的现代化落地。）<br/>一、概要<br/>在数字化转型全面加速的今天，数据早已从附属资源转变为企业的核心资产。无论是金融交易、政府档案还是互联网日志，数据的规模与复杂度正以指数级扩张。据国际数据公司（IDC）预测，到2025年全球数据总量将超过175ZB。这意味着企业每天都在处理海量的结构化与非结构化数据，信息安全与合规管理的复杂性也随之倍增。<br/>与此同时，《网络安全法》《数据安全法》《个人信息保护法》等一系列法规的密集出台，使得“数据分类分级”成为企业安全治理的起点和底线。如何在确保合规的前提下提升管理效率、降低风险成本，成为摆在各行业面前的核心命题。<br/>传统的数据分类分级依赖人工经验和规则模板，能满足“纸面合规”的基本要求，但在面对海量动态数据时，易出现误报、漏报与滞后，难以支撑智能化运营。而新一代以自适应分类、高性能计算和法规适配为特征的智能分级体系，通过引入AI算法、语义理解和知识图谱技术，实现了从“被动标注”到“主动认知”的跨越。<br/>这种转变不仅优化了数据安全防护的技术结构，也重塑了数据治理的价值逻辑——让数据从风险源变成生产力，从管理负担转化为企业的竞争资产。智能化的数据分类分级体系，正成为数字经济时代企业合规运营、智能决策与创新发展的基础设施。<br/>二、<a href="https://link.segmentfault.com/?enc=kAlpW6PiSgZcA16tIrfOqw%3D%3D.KIbZs29Y9VElxDTihCqmyhe%2BHanrTucNjaRrEgylJR4%3D" rel="nofollow" target="_blank">数据分类分级是什么</a><br/>（提示：数据分类分级是数据安全与价值管理的“前置环节”，其核心目标是识别、衡量并动态管理数据敏感性与重要性。）<br/>数据分类分级（Data Classification and Grading）是指依据数据的属性、重要程度、敏感级别及使用场景，对数据进行系统性识别与分层保护的过程。它既是数据安全管理的基础工作，也是企业实现数据资产化与风险可控化的前提。<br/>从本质上看，分类是识别“是什么”，分级是判断“有多重要”。分类帮助组织区分不同类型的数据，如业务数据、个人信息、研发成果等；分级则进一步明确其安全保护要求，例如一般、重要、核心、绝密等等级。通过科学的分类分级体系，企业可将有限的安全资源精准投向最关键的数据领域，提升整体防护效率与合规水平。<br/>在传统理念下，分类分级多依赖手工制度与规则匹配，如基于文件名、路径或关键词设定固定规则。这种方式虽然结构清晰、操作可控，但难以适应动态变化的业务环境与复杂的非结构化数据，常出现规则僵化、更新滞后等问题。<br/>而在智能化阶段，数据分类分级的定义已延展为一个动态、自学习的系统过程。通过引入AI技术，系统能自动理解数据语义与上下文，感知风险变化，并根据业务与法规要求自适应地调整分类策略。<br/>因此，现代数据分类分级不仅是合规手段，更是一种“数据治理中枢”，承担着连接安全、价值与效率的关键桥梁作用。<br/>（一）数据分类分级的核心逻辑<br/>（提示：核心逻辑在于通过体系化识别与动态权重评估，实现从静态标签到智能分级的闭环管理。）<br/>传统的数据分类分级逻辑多建立在“制度先行”的模式下，企业根据法律法规或行业标准（如《信息安全技术 数据分类分级指南》）制定统一规则，对不同数据进行静态划分。这种方式能满足监管审计要求，但缺乏灵活性与可持续性，尤其在面对多源异构与跨域数据时，常常显得力不从心。<br/>AI赋能后的自适应分类逻辑则引入了语义建模、上下文分析和特征学习机制，使系统具备理解与推理能力。它不再只看关键词，而是能“读懂内容”，从文本语义、结构模式、关联关系等多维度综合判断。例如，AI模型能自动识别出合同条款、身份证号、交易金额等敏感信息，即便表达形式多样、语言复杂，也能准确识别。<br/>此外，AI分类体系具备“持续学习”特性，能根据新业务场景不断优化模型参数，实现实时调整。这种逻辑的演进，使数据分级从静态标签走向动态迭代，从“规定式管理”走向“认知式治理”。<br/>核心逻辑的革新带来了三大变化：<br/>从规则依赖到语义理解——让机器具备像人一样的认知能力；<br/>从单点分类到场景分级——根据业务上下文灵活调整数据级别；<br/>从一次设定到持续优化——通过模型训练实现分级体系的自演化。<br/>由此，自适应分类体系不仅能提高识别精度，还能显著降低人工干预成本，为高性能计算与自动化治理提供坚实基础。<br/>（二）数据分类分级的核心能力<br/>（提示：核心能力体现于精准识别、动态防护与法规适配三位一体的技术闭环。）<br/>现代数据分类分级系统的核心能力可概括为三个层面：智能识别力、高性能处理力与法规适配力。<br/>1、智能识别力<br/>系统通过自然语言处理（NLP）、知识图谱与深度学习算法，对结构化与非结构化数据进行深度解析。它不仅能识别显性标签，还能理解隐含语义。例如，系统能区分“研究报告中的敏感实验数据”与“普通参考文档”，并据此动态分配分级权重。<br/>2、高性能处理力<br/>随着数据量的急剧增长，传统的人工审核与批量脚本执行已无法支撑大规模应用。智能分级体系借助高性能计算架构（HPC）与分布式引擎，可在海量数据环境下进行并行分析与语义匹配，实现秒级响应。这样一来，即便是PB级的数据仓库，也能在短时间内完成全面扫描与分级标注。<br/>3、法规适配力<br/>合规性是数据分类分级的生命线。系统通过法规知识库与规则引擎，将《数据安全法》《个人信息保护法》及行业标准（如金融、医疗、政务等）嵌入模型，形成动态法规映射机制。一旦政策更新或监管标准调整，系统即可自动同步更新分类逻辑，保障企业长期合规与审计可追溯。<br/>这三项能力相互支撑，形成完整的智能防护闭环。企业不仅能实时掌握数据全貌，还能在不同应用场景中实现“精准识别—动态分级—自适应防护”的闭环管理，让数据安全与业务创新同步前行。<br/>三、数据分类分级常见的FAQ<br/>（提示：在企业实际落地过程中，常见的困惑主要集中在“怎么做”“做多深”“如何保持长期有效”三个方面。）<br/>Q1:数据分类分级的边界在哪里？<br/>A1:分类分级并非只针对敏感数据。任何进入企业信息系统的数据都应被纳入分类管理框架。敏感数据需要重点保护，而一般业务数据也需识别与追踪，以支撑数据资产化与精细化运营。<br/>Q2:分类分级需要人工干预吗？<br/>A2:尽管AI具备高效识别能力，但人工仍在体系中扮演重要角色。人工主要负责制定初始策略、审核模型结果及处理特殊场景。AI负责自动学习与执行，二者结合可实现“规则为基、智能为翼”的最优结构。<br/>Q3:非结构化数据如何分类？<br/>A3:传统规则对文本、图片、音视频等非结构化数据的处理效果不佳。AI通过图像识别、语音转文本、语义向量化等技术，可对非结构化内容进行结构化表达，从而实现自动分级。例如，系统能识别会议录音中的个人隐私信息或视频中的机密标识。<br/>Q4:如何保持分类分级体系的长期有效？<br/>A4:企业应构建“模型迭代+规则审计”的双循环机制。通过持续训练，AI模型可不断优化识别能力；通过周期性审计，企业可确保体系与最新业务和法规保持一致。<br/>Q5:分类分级与数据安全治理是什么关系？<br/>A5:分类分级是数据安全治理的前提和基础。只有明确了数据的敏感性与价值层级，后续的访问控制、加密存储、泄露防护等策略才有的放矢。可以说，没有科学的分类分级，就没有高效的数据安全治理。<br/>四、发展趋势<br/>(提示：未来的数据分类分级将呈现智能化、协同化与可信化三大趋势，成为数据安全与价值共生的底座能力。)</p><ol><li>从静态到动态：自适应分类成为主流<br/>随着业务场景频繁变更，数据流动日益复杂，静态规则已无法满足实时安全要求。未来系统将更加智能化、自学习化，能基于数据流转路径、访问行为与上下文语义自动调整分级策略，形成“动态标签—实时防护”的自适应体系。</li><li>从局部防护到全域协同：多源融合管理<br/>数据不再局限于本地系统，而是分布在云端、终端与边缘设备。分类分级将从单一平台扩展至多域协同，通过统一的分类标准与API接口，实现跨系统、跨组织的数据一致性识别与合规共享。</li><li>从单点合规到智能法规适配<br/>法规适配将成为分类分级的关键能力。系统将借助法规知识图谱与自动推理机制，实现智能法规匹配，自动判定数据在不同地区、行业或跨境场景下的合规等级。由此，企业可在多法域环境下实现合规自动化。</li><li>从安全工具到价值引擎<br/>未来的数据分类分级不再只是安全防护手段，而是数据资产化的重要支撑。通过精准分级，企业能明确哪些数据可开放、共享或训练AI模型，从而实现数据价值的最大化。分类体系也将成为企业智能决策、产品创新和风险管理的核心底座。</li><li>从可用到可信：建立解释性与透明度机制<br/>AI驱动的分类体系虽高效，但“黑箱决策”问题需警惕。未来系统将强化可解释AI机制，使每一次分类决策都有明确理由与审计记录，确保监管可查、责任可追，从而提升整体可信度。<br/>数据治理的核心，不在于管多少，而在于能否“管得准”。自适应分类、高性能计算与法规适配的结合，使企业能够在动态环境中实现智能识别、精准分级与持续合规。<br/>从人工规则到智能认知，数据分类分级体系的演进，不仅是一场技术革新，更是一种治理思维的重构。它让安全从“防御成本”转化为“治理效能”，让数据从“被动负担”转化为“主动资产”。<br/>在未来的数字经济体系中，谁能率先构建智能化、自适应的分类分级体系，谁就能在合规、安全与创新之间取得真正的平衡与优势。</li></ol>]]></description></item><item>    <title><![CDATA[以AI驱动的全周期合规治理，打造运营商数]]></title>    <link>https://segmentfault.com/a/1190000047411350</link>    <guid>https://segmentfault.com/a/1190000047411350</guid>    <pubDate>2025-11-19 16:18:36</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>一、概要<br/>随着通信行业数字化、智能化的持续推进，5G、物联网、云网融合等新型业务高速发展，数据正从业务支撑要素转变为战略核心资产。面对复杂的安全监管环境与业务创新诉求，推出数据安全平台，以合规治理、全周期安全管控、AI智能优化为核心特征，构建面向运营商行业的系统化解决方案。该平台通过“全域采集—智能识别—协同处置—持续优化”的技术闭环，实现对数据安全的动态感知与精准响应，为通信运营商提供从数据生成到归档的全生命周期安全治理能力。在多个省级运营商的实践落地中，平台帮助企业实现了数据可视化率从35%提升至100%，风险告警准确率提升至94%，合规审计成本下降35%以上，全面推动了通信行业数据安全治理从“被动防御”迈向“智能闭环”的新时代。<br/>二、数字化浪潮下的合规压力与安全困局<br/>（提示：通信业务的智能扩张带来了数据爆炸与合规挑战的双重压力。）<br/>随着5G商用、物联网连接数的指数级增长，运营商的数据资产规模空前扩大，覆盖范围从用户个人信息到政企业务、网络信令、物联网终端数据等多维空间。这些数据承载着通信网络运行的基础信息，其安全性直接关系到国家通信基础设施稳定与公众隐私安全。<br/>然而，运营商面临的安全治理挑战日益复杂：一是监测覆盖存在“场景盲区”，传统监控工具仅聚焦CRM等单点系统，难以覆盖5G基站、物联网卡流转、第三方增值服务平台等关键节点；二是风险识别准确度不足，传统规则引擎在面对复杂多样的数据结构时误报率高、响应迟缓；三是合规要求愈加严格，《数据安全法》《个人信息保护法》等法规要求企业实现用户数据全生命周期监控与日志留痕，传统体系难以满足监管审计要求。<br/>在此背景下，运营商亟需一套既能确保合规、又能兼顾通信服务连续性与效率的智能化数据安全治理体系。<br/>三、行业痛点分析：三大顽疾制约数据安全治理效能<br/>（提示：传统安全体系在运营商复杂生态中暴露出系统性短板。）</p><ol><li>场景覆盖不足，监测存在“盲区”通信网络业务链条庞大，涉及200余个关键节点，从核心网到用户终端、从物联网平台到第三方合作系统，传统系统因部署侵入性强、接口不统一，往往存在数据采集断点，难以实现全链条覆盖。</li><li>风险识别精准度低，误报频繁影响运维由于运营商数据类型多样、逻辑复杂，传统规则引擎缺乏智能学习能力，导致风险判定泛化。结果是误报率居高不下，不仅增加了安全部门的审查负担，也影响了客服、运维等核心业务的正常运行。</li><li>合规管控割裂，缺乏全周期治理能力合规治理要求覆盖“采集—存储—使用—传输—销毁”全周期，但多数运营商仍停留在静态审计与分段防护阶段，缺乏统一的数据安全基线、动态合规追踪与可回溯的日志体系，导致治理效率低下、风险响应迟缓。<br/>四、解决方案：<a href="https://link.segmentfault.com/?enc=Hxa5JcDGeeddGgrAv4x20w%3D%3D.NPHiquE9gc9TgjLill09c9tSyoS5VMHBh%2FdD3On5u9I%3D" rel="nofollow" target="_blank">基于AI优化的全周期数据安全合规治理平台</a><br/>（提示：以AI为核心引擎，通过智能识别、自动决策与持续学习，构建面向运营商的全周期数据安全合规治理体系，实现从数据接入、风险监测到响应处置的全链路智能化管理，推动运营商数据安全从传统被动防护迈向主动、精准、高效的智能治理。）<br/>（一）全域数据接入：实现零干扰、全链路监测<br/>数据安全平台采用“流量镜像+接口对接+轻量Agent”三维接入机制，在不影响通信业务的前提下覆盖核心网、CRM系统、物联网平台、基站管理系统及第三方增值服务。通过标准化引擎转换为运营商专属数据模型，构建“用户—套餐—基站—物联网卡”关联图谱，实现数据流转全息可见。<br/>（二）数据标准化与图谱治理：打通数据血缘全景<br/>内置JSON-LD标准引擎，统一异构数据格式，结合动态图谱构建技术实现运营商数据流转的数字孪生映射。所有合规规则与监测策略以节点形式嵌入图谱，使监管要求与数据场景实现“一一对应”，从而实现精细化的合规管理。<br/>（三）AI智能识别与全链路监测<br/>数据安全平台构建“三层监测机制”——规则层、智能层、关联层，融合UEBA行为分析模型与图神经网络，智能识别如“客服异地访问”“批量下载敏感信息”“物联网卡滥用”等高风险行为。AI降噪算法有效过滤无效告警，使误报率降至5%以下，确保风险检测精准、高效、无干扰。<br/>（四）分级响应与协同处置：实现多系统联动闭环<br/>依据风险等级启动分级响应：低风险自动提示整改，中高风险联动防火墙及CRM系统阻断行为，重大风险自动报送监管平台并形成全链路审计。通过L5策略协同层，平台可实现与20+系统设备的联动，形成“发现—处置—溯源—复盘”的全周期闭环。<br/>（五）持续优化与知识沉淀：AI驱动安全自进化<br/>以AI持续学习为核心，基于每月监测数据对模型阈值进行动态校准，并将运营商在节假日高峰、物联网卡扩容等特殊场景下的经验沉淀为规则模板，实现“越用越准、越管越细”的智能安全自适应体系。<br/>五、应用落地：从安全防护到治理效能的全面跃升<br/>（提示：真实的运营商实践充分证明，AI驱动的数据安全平台不仅能够显著提升风险识别精度与治理效率，更能在复杂庞大的业务体系中实现从资产透明、风险可控到合规稳健的全面提升。通过智能化技术的深度融入，运营商得以构建起可持续演进的安全治理能力，使安全建设从传统的被动防护转向持续、主动、精准的智能治理模式。）<br/>以某省级运营商为例，该企业拥有320余套核心业务系统、4.5万条API接口，日均调用量超过1000万次，长期受制于“接口资产不清、误报率高、合规压力大”等问题。部署全知科技数据安全平台后，企业实现了以下突破：<br/>● 一周完成资产全量梳理，捕获6.2万+未备案接口，构建完整API资产数字孪生图谱，资产可视率从35%提升至100%；<br/>● AI智能识别助力精准防护，误报率降至4.8%，成功识别156起API风险事件，准确率提升至94%；<br/>● 多系统联动响应，将风险整改周期从72小时缩短至12小时，整改率达到100%；<br/>● 合规效能显著提升，顺利通过工信部专项检查，实现监管对接、风险闭环、日志可溯的全面治理体系。<br/>这一落地案例充分展示了AI优化在数据安全治理中的价值，使运营商在保障通信连续性的同时，实现了合规与业务双赢。<br/>六、推广价值：为通信行业安全治理树立标杆<br/>（提示：从试点到规模化，平台价值已获得行业验证。）</li><li>合规治理：满足法规要求，降低审计成本平台精准对标《数据安全法》《个人信息保护法》《电信数据安全管理办法》，实现180天日志留痕与可追溯审计报告，帮助运营商将合规审计成本降低35%以上。</li><li>全周期防护：贯穿数据全生命周期治理链条系统覆盖数据采集、传输、使用、共享与销毁等阶段，形成“全过程、全维度、全责任”的治理闭环，真正实现通信数据“全生命周期安全可控”。</li><li>AI优化赋能：以智能算法驱动效能跃迁AI算法实现自学习、自调优，使风险检测效率提升10倍以上，安全团队工作量减少60%，为运营商数字化转型提供稳定支撑。</li><li>可复制可推广：打造行业级治理样板平台的非侵入式架构与标准化接口设计，使其能够快速适配不同省级运营商，实现“一套架构，多地复制”，推动通信行业整体安全治理能力跃升。<br/>七、典型问答：从实践视角解析平台价值<br/>（提示：以下问答帮助深入理解平台在实际应用中的关键价值点。）<br/>Q1：该平台如何兼顾通信服务的稳定与安全监测的精准性？A：数据安全平台采用“旁路采集+AI降噪”机制，不干扰核心通信流程，并通过智能模型自动区分正常运维与异常行为，确保监测精度与服务连续性并行。<br/>Q2：AI在数据安全治理中发挥了哪些核心作用？A：AI主要承担风险识别优化与动态学习职能。通过图神经网络与UEBA行为模型，系统能实时捕捉异常行为特征，并基于历史样本自动调优阈值，实现持续优化。<br/>Q3：平台如何实现全生命周期合规治理？A：数据安全平台将数据采集、存储、使用、传输、销毁全过程纳入统一监管视图，并通过合规规则映射至图谱节点，实现动态合规审计与回溯能力。<br/>Q4：对于多系统并行的运营商环境，平台如何协同？A：通过L5层策略协同引擎，平台可与核心网、CRM、物联网管理系统、工信部监管平台等20+系统自动联动，实现一体化响应与闭环处置。<br/>Q5：部署成本与周期如何控制？A：采用轻量级架构，无需改造核心网，仅需部署镜像采集与轻量Agent组件，平均部署周期不超过两周，适合大规模落地推广。<br/>八、用户评价与行业认可<br/>（提示：真实反馈验证了平台的专业性与行业价值。）<br/>多家省级运营商在使用数据安全平台后普遍表示，系统“覆盖广、识别准、响应快”，有效解决了传统监测的“盲区多、误报多、治理慢”问题。管理层反馈，平台的可视化视图帮助他们首次实现了跨系统数据安全态势的实时掌握；安全部门认为，AI智能分析极大降低了告警处理压力，安全管理工作从被动审计转向主动防控。<br/>数据安全平台已获得中国信通院、工信部权威认证，符合《电信领域数据安全分级保护要求》，并在通信、政务、能源等多个关键行业成功落地。未来，公司将持续深化AI优化与合规治理的融合创新，推动数据安全治理从“规则驱动”向“智能自驱”演进，助力运营商构建“看得见、辨得准、控得住”的智能化安全防线，为数字中国的高质量发展筑牢通信数据底座。</li></ol>]]></description></item>  </channel></rss>