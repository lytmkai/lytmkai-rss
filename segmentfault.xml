<?xml version="1.0" encoding="UTF-8"?><rss version="2.0">  <channel>      <title>SegmentFault - 最近文章</title>      <link>https://segmentfault.com/blogs/newest</link>      <description>SegmentFault 思否</description>      <generator>python segmentfault.py @Pi20</generator>      <item>    <title><![CDATA[艾体宝干货 | Redis Java 开]]></title>    <link>https://segmentfault.com/a/1190000047446528</link>    <guid>https://segmentfault.com/a/1190000047446528</guid>    <pubDate>2025-12-03 18:05:36</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>前言</h2><p>Java 开发领域，Redis 已成为构建高性能缓存、分布式锁、会话管理和消息队列等系统的核心组件之一。</p><p>然而，许多初学者在第一次将 Redis 引入 Java 项目时，往往被各种客户端选择、连接配置、性能优化等问题困扰。</p><p>本系列文章就是为此而设计的，本文将从零开始完成 Redis 开发环境的搭建与实战演示，并结合业界最佳实践讲解连接池优化、生产安全配置及故障诊断方法。</p><p>无论是第一次使用 Redis 的新手，还是准备优化现有系统的工程师，希望你都能在本文中找到清晰的指导路径。</p><p><strong>本篇读者收益</strong></p><ul><li>熟悉 Redis 的多种安装方式与部署策略</li><li>理解 Java 主流 Redis 客户端（Jedis、Lettuce、Redisson）的特点与适用场景</li><li>掌握连接池优化及线程安全配置</li></ul><p>​<strong>先修要求</strong>​：熟悉 Java 编程与 Maven/Gradle 构建工具，具备基本的 Linux 命令操作能力，理解 TCP/IP 基本网络概念。</p><h2>Redis 与 Java 的集成原理</h2><p>Redis 是一个基于内存、支持多数据结构（String、Hash、List、Set、ZSet 等）的高性能键值数据库。</p><p>在 Java 应用中，客户端库负责与 Redis 服务端通信，通常通过 TCP Socket 实现同步或异步命令交互。</p><p>一个典型的架构如下所示：</p><pre><code class="Plain">Java 应用 → Redis 客户端 → 连接池 → Redis 服务器
    ↓           ↓           ↓           ↓
 业务逻辑     连接管理     资源复用     数据存储</code></pre><p>连接池在这里起到关键作用，它能显著减少频繁建立和关闭 TCP 连接带来的开销，是高并发系统中提升性能的必备组件。</p><h2>环境准备与快速安装</h2><p>在进入代码之前，我们先完成 Redis 服务端的搭建。以下几种方式可按实际环境选择。</p><h3>本地安装（Linux）</h3><pre><code class="Bash">sudo apt-get update
sudo apt-get install redis-server
sudo systemctl start redis-server
sudo systemctl enable redis-server
sudo systemctl status redis-server</code></pre><blockquote>这种方式最适合在本机进行调试或学习，操作简单，但在生产环境中不建议直接裸机部署。</blockquote><h3>Docker 安装</h3><p>Docker 是搭建 Redis 的最简洁方式，可在几分钟内完成环境准备。</p><pre><code class="Bash"># 拉取镜像
docker pull redis:latest

# 运行容器
docker run -d --name redis-dev -p 6379:6379 redis:latest</code></pre><p>若希望数据持久化，可挂载数据卷：</p><pre><code class="Bash">docker run -d --name redis-dev \
  -p 6379:6379 \
  -v /path/to/redis/data:/data \
  redis:latest redis-server --appendonly yes</code></pre><blockquote>在企业内部测试环境中，建议为 Redis 容器启用密码认证与独立网络。</blockquote><h3>macOS 安装（Homebrew）</h3><pre><code class="Bash">brew install redis
brew services start redis</code></pre><h3>安装验证</h3><pre><code class="Bash">redis-cli
127.0.0.1:6379&gt; ping
PONG</code></pre><p>出现 <code>PONG</code> 即表示 Redis 服务运行正常。</p><h2>项目依赖配置</h2><p>无论使用 Maven 还是 Gradle，都需要在项目中添加 Redis 客户端依赖。</p><p>以下是 Maven 示例：</p><pre><code class="XML">&lt;dependencies&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;redis.clients&lt;/groupId&gt;
        &lt;artifactId&gt;jedis&lt;/artifactId&gt;
        &lt;version&gt;5.1.0&lt;/version&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;io.lettuce&lt;/groupId&gt;
        &lt;artifactId&gt;lettuce-core&lt;/artifactId&gt;
        &lt;version&gt;6.3.0.RELEASE&lt;/version&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.redisson&lt;/groupId&gt;
        &lt;artifactId&gt;redisson&lt;/artifactId&gt;
        &lt;version&gt;3.24.3&lt;/version&gt;
    &lt;/dependency&gt;
&lt;/dependencies&gt;</code></pre><blockquote><p>​<strong>建议</strong>​：</p><ul><li>Spring Boot 2.x 及以上默认使用 **Lettuce**，兼容性最佳。</li><li>若需要更强的分布式锁与数据结构支持，可选 **Redisson**。</li><li>若项目较轻量，Jedis 足以满足需求。</li></ul></blockquote><h2>客户端详解与实战</h2><h3>客户端选择</h3><p>表格 还在加载中，请等待加载完成后再尝试复制</p><h3>示例</h3><h4>Jedis 基础连接</h4><p>提供直观易懂的同步接口，适合快速上手。</p><pre><code class="Java">try (Jedis jedis = new Jedis("localhost", 6379)) {
    jedis.set("hello", "world");
    System.out.println(jedis.get("hello"));
}</code></pre><h4>Lettuce 异步连接</h4><p>基于 Netty，性能极高，线程安全。</p><pre><code class="Java">RedisURI redisUri = RedisURI.create("redis://localhost:6379");
RedisClient client = RedisClient.create(redisUri);
try (StatefulRedisConnection&lt;String, String&gt; conn = client.connect()) {
    RedisCommands&lt;String, String&gt; cmd = conn.sync();
    cmd.set("lettuce_key", "value");
    System.out.println(cmd.get("lettuce_key"));
}
client.shutdown();</code></pre><h4>Redisson 分布式结构操作</h4><p>Redisson 以对象化方式封装 Redis，支持 Map、Set、Lock 等高级特性。</p><pre><code class="Java">Config config = new Config();
config.useSingleServer().setAddress("redis://localhost:6379");
RedissonClient client = Redisson.create(config);

var lock = client.getLock("myLock");
lock.lock();
try {
    System.out.println("获取分布式锁成功");
} finally {
    lock.unlock();
}
client.shutdown();</code></pre><h2>性能优化与连接池设计</h2><p>在生产环境中，连接池配置往往直接决定系统稳定性与吞吐量。</p><p>例如在高并发接口中，若 Redis 连接创建与释放频繁，将极大拖慢响应速度。</p><p>以下是针对 <strong>Jedis</strong> 和 <strong>Lettuce</strong> 的优化实践。</p><h3>Jedis 连接池</h3><ul><li>使用 <code>JedisPool</code> 实现连接复用</li><li>动态配置连接数与空闲检测频率</li><li>结合 JMX 监控连接状态</li></ul><pre><code class="Java">import redis.clients.jedis.JedisPool;
import redis.clients.jedis.JedisPoolConfig;

import java.time.Duration;

public class OptimizedJedisPool {
    
    private static volatile JedisPool jedisPool;
    
    // 双重检查锁单例模式
    public static JedisPool getJedisPool() {
        if (jedisPool == null) {
            synchronized (OptimizedJedisPool.class) {
                if (jedisPool == null) {
                    jedisPool = createOptimizedPool();
                }
            }
        }
        return jedisPool;
    }
    
    private static JedisPool createOptimizedPool() {
        JedisPoolConfig config = new JedisPoolConfig();
        
        // 核心连接数配置（根据服务器配置调整）
        int cpuCores = Runtime.getRuntime().availableProcessors();
        config.setMaxTotal(cpuCores * 4);          // 最大连接数 = CPU核数 × 4
        config.setMaxIdle(cpuCores * 2);           // 最大空闲连接
        config.setMinIdle(cpuCores);               // 最小空闲连接
        
        // 连接有效性验证
        config.setTestOnBorrow(false);             // 关闭获取时测试，提升性能
        config.setTestOnReturn(false);             // 关闭归还时测试
        config.setTestWhileIdle(true);             // 开启空闲时测试
        config.setTimeBetweenEvictionRuns(Duration.ofSeconds(30)); // 空闲检查间隔
        
        // 超时配置
        config.setMaxWait(Duration.ofMillis(500)); // 快速失败，避免线程阻塞
        config.setMinEvictableIdleTime(Duration.ofMinutes(1)); // 最小空闲时间
        
        // 连接耗尽策略
        config.setBlockWhenExhausted(true);        // 连接耗尽时阻塞
        
        // JMX监控
        config.setJmxEnabled(true);
        config.setJmxNamePrefix("jedis-pool");
        
        return new JedisPool(config, "localhost", 6379, 1000 /* 连接超时 */);
    }
    
    // 连接池监控方法
    public static void printPoolStats() {
        if (jedisPool != null) {
            System.out.println("活跃连接数: " + jedisPool.getNumActive());
            System.out.println("空闲连接数: " + jedisPool.getNumIdle());
            System.out.println("等待连接数: " + jedisPool.getNumWaiters());
        }
    }
    
    // 资源清理
    public static void closePool() {
        if (jedisPool != null) {
            jedisPool.close();
            jedisPool = null;
        }
    }
}</code></pre><h3>Lettuce 连接池</h3><p>Lettuce 原生是无连接池设计（多线程共享单连接），若使用连接池，可结合 <code>commons-pool2</code> 管理。</p><p>多租户或多逻辑数据库应用中非常有用。</p><pre><code class="Java">import io.lettuce.core.RedisClient;
import io.lettuce.core.RedisURI;
import io.lettuce.core.support.ConnectionPoolSupport;
import io.lettuce.core.api.StatefulRedisConnection;
import org.apache.commons.pool2.impl.GenericObjectPool;
import org.apache.commons.pool2.impl.GenericObjectPoolConfig;

import java.time.Duration;

public class LettucePoolManager {
    
    private RedisClient redisClient;
    private GenericObjectPool&lt;StatefulRedisConnection&lt;String, String&gt;&gt; pool;
    
    public LettucePoolManager() {
        // 构建Redis URI
        RedisURI redisUri = RedisURI.Builder
                .redis("localhost")
                .withPort(6379)
                .withTimeout(Duration.ofSeconds(2))
                .build();
        
        redisClient = RedisClient.create(redisUri);
        
        // 配置连接池
        GenericObjectPoolConfig&lt;StatefulRedisConnection&lt;String, String&gt;&gt; poolConfig = 
                new GenericObjectPoolConfig&lt;&gt;();
        
        int cpuCores = Runtime.getRuntime().availableProcessors();
        poolConfig.setMaxTotal(cpuCores * 4);
        poolConfig.setMaxIdle(cpuCores * 2);
        poolConfig.setMinIdle(cpuCores);
        poolConfig.setMaxWait(Duration.ofMillis(500));
        poolConfig.setTestOnBorrow(false);
        poolConfig.setTestOnReturn(false);
        poolConfig.setTestWhileIdle(true);
        poolConfig.setTimeBetweenEvictionRuns(Duration.ofSeconds(30));
        
        // 创建连接池
        pool = ConnectionPoolSupport.createGenericObjectPool(
                redisClient::connect, poolConfig);
    }
    
    public StatefulRedisConnection&lt;String, String&gt; getConnection() {
        try {
            return pool.borrowObject();
        } catch (Exception e) {
            throw new RuntimeException("获取Redis连接失败", e);
        }
    }
    
    public void returnConnection(StatefulRedisConnection&lt;String, String&gt; connection) {
        if (connection != null) {
            pool.returnObject(connection);
        }
    }
    
    public void close() {
        if (pool != null &amp;&amp; !pool.isClosed()) {
            pool.close();
        }
        if (redisClient != null) {
            redisClient.shutdown();
        }
    }
    
    // 连接池状态监控
    public void printPoolStats() {
        if (pool != null) {
            System.out.println("活跃连接数: " + pool.getNumActive());
            System.out.println("空闲连接数: " + pool.getNumIdle());
            System.out.println("等待连接数: " + pool.getNumWaiters());
        }
    }
}</code></pre><h2>案例：电商用户会话管理</h2><p>Redis 在电商网站中最常见的用例之一，就是**分布式用户会话管理**。</p><p>相比将会话存放在 Tomcat Session 中，Redis 能提供更高的可扩展性与跨节点共享能力。</p><p>核心逻辑包括：</p><ol><li>用户登录 → 创建会话（<code>SETEX</code>）</li><li>请求访问 → 校验并续期</li><li>用户登出或超时 → 删除会话</li></ol><pre><code class="Java">public class UserSessionManager {
    
    private JedisPool jedisPool;
    private ObjectMapper objectMapper;
    
    public UserSessionManager(JedisPool jedisPool) {
        this.jedisPool = jedisPool;
        this.objectMapper = new ObjectMapper();
    }
    
    // 用户会话类
    public static class UserSession {
        private String userId;
        private String username;
        private String email;
        private long loginTime;
        private long lastAccessTime;
        private Map&lt;String, Object&gt; attributes;
        
        // 构造方法、getter、setter
        public UserSession() {
            this.attributes = new HashMap&lt;&gt;();
        }
        
        public UserSession(String userId, String username, String email) {
            this();
            this.userId = userId;
            this.username = username;
            this.email = email;
            this.loginTime = System.currentTimeMillis();
            this.lastAccessTime = this.loginTime;
        }
        
        // getter和setter方法...
    }
    
    // 创建用户会话
    public String createSession(UserSession session, int expireSeconds) {
        String sessionId = UUID.randomUUID().toString();
        String sessionKey = "session:" + sessionId;
        
        try (Jedis jedis = jedisPool.getResource()) {
            // 更新最后访问时间
            session.setLastAccessTime(System.currentTimeMillis());
            
            // 序列化会话对象
            String sessionJson = objectMapper.writeValueAsString(session);
            
            // 存储会话，设置过期时间
            jedis.setex(sessionKey, expireSeconds, sessionJson);
            
            // 建立用户ID到会话ID的映射
            jedis.set("user_session:" + session.getUserId(), sessionId);
            
            return sessionId;
        } catch (Exception e) {
            throw new RuntimeException("创建会话失败", e);
        }
    }
    
    // 获取用户会话
    public UserSession getSession(String sessionId) {
        String sessionKey = "session:" + sessionId;
        
        try (Jedis jedis = jedisPool.getResource()) {
            String sessionJson = jedis.get(sessionKey);
            if (sessionJson == null) {
                return null;
            }
            
            // 更新最后访问时间
            jedis.expire(sessionKey, 1800); // 续期30分钟
            
            return objectMapper.readValue(sessionJson, UserSession.class);
        } catch (Exception e) {
            throw new RuntimeException("获取会话失败", e);
        }
    }
    
    // 删除会话
    public void deleteSession(String sessionId) {
        try (Jedis jedis = jedisPool.getResource()) {
            // 获取会话信息以便删除用户映射
            UserSession session = getSession(sessionId);
            if (session != null) {
                jedis.del("user_session:" + session.getUserId());
            }
            
            // 删除会话本身
            jedis.del("session:" + sessionId);
        }
    }
    
    // 使用示例
    public static void main(String[] args) {
        JedisPool pool = OptimizedJedisPool.getJedisPool();
        UserSessionManager sessionManager = new UserSessionManager(pool);
        
        // 创建用户会话
        UserSession session = new UserSession("1001", "张三", "zhangsan@example.com");
        session.getAttributes().put("theme", "dark");
        session.getAttributes().put("language", "zh-CN");
        
        String sessionId = sessionManager.createSession(session, 1800); // 30分钟过期
        
        System.out.println("创建的会话ID: " + sessionId);
        
        // 获取会话
        UserSession retrievedSession = sessionManager.getSession(sessionId);
        System.out.println("用户姓名: " + retrievedSession.getUsername());
        
        // 清理资源
        OptimizedJedisPool.closePool();
    }
}</code></pre><h2>常见问题</h2><p>表格 还在加载中，请等待加载完成后再尝试复制</p><h2>小结</h2><p>本文从环境搭建、客户端选择、连接池优化、安全配置到实战案例，完整呈现了 Java 开发者如何高效使用 Redis 的全过程。</p><p>你现在应该已经掌握以下要点：</p><ul><li>如何在多平台上快速搭建 Redis 环境</li><li>如何选择合适的 Java 客户端（Jedis / Lettuce / Redisson）</li><li>如何配置连接池以兼顾性能与稳定性</li><li>如何在生产环境中保障 Redis 的安全与可用性</li></ul><p>未来我们将进一步探索：</p><ul><li>Redis Cluster 与 Sentinel 高可用架构</li><li>使用 Redisson 实现分布式锁、布隆过滤器</li><li>利用 Spring Data Redis 进行统一封装与模板化访问</li></ul><p>Redis 的学习曲线并不陡峭，但想在企业级场景中用好它，需要兼顾开发效率与系统稳定性。  希望这篇文章能成为你 Redis 学习与实战路上的起点。</p>]]></description></item><item>    <title><![CDATA[做速卖通跨境 B2C 工具 5 年，被商]]></title>    <link>https://segmentfault.com/a/1190000047446684</link>    <guid>https://segmentfault.com/a/1190000047446684</guid>    <pubDate>2025-12-03 18:05:02</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在跨境电商开发圈摸爬滚打这些年，[速卖通商品详情] API 的 “跨境 B2C 基因” 藏着太多让开发者头疼的坑。作为面向全球个人买家的平台，它的接口返回里全是国内电商没有的 “细节杀”—— 从多币种折扣的嵌套计算，到海外仓与国内仓的库存拆分，再到多语言标题的乱码陷阱，每次对接都像在拆解 “全球买家需求说明书”。今天就把这些年踩过的雷、攒的可落地代码全抖出来，给做卖家工具、选品系统的朋友避避雷。</p><h2>一、初次翻车：签名漏传 “sign_method”，调试到凌晨三点</h2><p>第一次对接速卖通 API 是帮卖家做 “全球价格同步工具”，按文档写的签名函数连续 6 小时返回<code>401 Invalid Signature</code>。翻遍速卖通开放平台文档才发现：<strong>速卖通签名必须显式指定 “sign_method=sha256”，且 timestamp 必须是 UTC 时区的 ISO 格式</strong>（如 “2025-12-03T12:00:00Z”），我不仅漏了<code>sign_method</code>，还习惯性用了北京时间的 “yyyy-MM-dd HH:mm:ss” 格式，导致加密结果完全不对。</p><p>更坑的是，速卖通要求所有请求必须走 HTTPS，且参数里的<code>format</code>必须固定为 “json”，漏传任何一个都会报签名错误，但错误信息只字不提 “参数缺失”。那天对着官方示例算到眼酸，终于磨出能跑通的签名函数：</p><p>python</p><p>运行</p><pre><code>import hashlib
import time
import urllib.parse
from datetime import datetime, timezone

def generate_aliexpress_sign(params, app_secret):
    """
    生成速卖通商品详情API签名（必传sign_method+UTC ISO时间！）
    :param params: 请求参数（不含sign）
    :param app_secret: 应用密钥
    """
    # 1. 强制添加速卖通特有必传参数，缺一个签名必错
    params["format"] = "json"  # 固定为json，不能改xml
    params["sign_method"] = "sha256"  # 必须指定SHA256，默认不生效
    params["timestamp"] = datetime.now(timezone.utc).strftime("%Y-%m-%dT%H:%M:%SZ")  # UTC ISO格式
    params["v"] = "2.0"  # API版本固定2.0，漏传报401
    
    # 2. 过滤sign，按参数名ASCII升序排序（速卖通对顺序敏感，差一个字符都不行）
    sign_params = {k: v for k, v in params.items() if k != "sign" and v is not None}
    sorted_params = sorted(sign_params.items(), key=lambda x: x[0])
    
    # 3. 拼接为key=value&amp;key=value，值需URL编码（处理多语言特殊字符，如俄语ё）
    query_str = "&amp;".join([
        f"{k}={urllib.parse.quote(str(v), safe='')}" 
        for k, v in sorted_params
    ])
    
    # 4. 拼接app_secret，SHA256加密后转大写（速卖通不用首尾加密钥，只在末尾加！）
    sign_str = f"{query_str}{app_secret}"
    return hashlib.sha256(sign_str.encode()).hexdigest().upper()

# 示例调用（获取英文站商品详情）
params = {
    "app_key": "your_aliexpress_app_key",
    "method": "aliexpress.product.get",
    "product_id": "100500587654321",  # 速卖通商品ID是13位，注意和淘宝区分
    "language": "en",  # 目标语言，支持es/ru/fr等
    "currency": "USD"  # 目标币种，默认USD
}
params["sign"] = generate_aliexpress_sign(params, "your_app_secret")</code></pre><h2>二、价格陷阱：把 “折上折” 当单折扣，一单亏了 300 刀</h2><p>系统上线后第三周，卖家反馈：“卖了 100 件连衣裙，利润比预期少了 3000 刀！” 排查发现，速卖通的价格字段藏着 “三层嵌套陷阱”——<code>original_price</code>是原价，<code>discount_price</code>是基础折扣价，<code>quantity_discount</code>是数量折扣（买 2 件减 5%，买 5 件减 10%），而我只算了<code>discount_price</code>，没叠加数量折扣，导致实际售价比系统显示低，利润直接缩水。</p><p>更坑的是，多币种换算藏在<code>currency_rate</code>字段里，比如人民币对美元汇率<code>0.138</code>，如果直接按人民币价格除以 7 算汇率，会和实际接口返回差 0.02，1000 件商品就差 200 刀。我连夜重写的价格解析函数，专门处理折扣叠加和多币种：</p><p>python</p><p>运行</p><pre><code>def parse_aliexpress_price(price_data, target_currency="USD"):
    """
    解析速卖通价格：处理原价、折扣价、数量折扣、多币种换算
    :param price_data: 接口返回的价格数据
    :param target_currency: 目标买家币种
    """
    price_info = {}
    # 1. 基础价格（原价+基础折扣价）
    original_price = float(price_data.get("original_price", 0))
    discount_price = float(price_data.get("discount_price", original_price))
    # 多币种换算（获取目标币种汇率，默认USD）
    currency_rates = price_data.get("currency_rates", {})
    target_rate = currency_rates.get(target_currency, 1.0)  # 目标币种汇率（相对于基准币种）
    
    # 2. 处理数量折扣（买多省多，格式：[{"min_qty":2,"discount":5},{"min_qty":5,"discount":10}]）
    quantity_discounts = price_data.get("quantity_discounts", [])
    discounted_prices = []
    # 先加基础折扣价（1件的价格）
    base_discounted = round(discount_price * target_rate, 2)
    discounted_prices.append({
        "min_quantity": 1,
        "max_quantity": quantity_discounts[0]["min_qty"] - 1 if quantity_discounts else 999,
        "price": base_discounted,
        "desc": f"1-{quantity_discounts[0]['min_qty'] - 1 if quantity_discounts else 999}件：{target_currency} {base_discounted}"
    })
    # 再加数量折扣阶梯
    for i, discount in enumerate(quantity_discounts):
        min_qty = discount["min_qty"]
        discount_percent = discount["discount"]
        final_price = round(discount_price * (1 - discount_percent/100) * target_rate, 2)
        # 确定最大数量（下一个折扣的最小量-1，最后一个是无限）
        max_qty = quantity_discounts[i+1]["min_qty"] - 1 if (i+1) &lt; len(quantity_discounts) else "unlimited"
        discounted_prices.append({
            "min_quantity": min_qty,
            "max_quantity": max_qty,
            "price": final_price,
            "desc": f"{min_qty}-{max_qty}件：{target_currency} {final_price}（省{discount_percent}%）"
        })
    
    # 3. 整合价格信息
    price_info["original_price"] = round(original_price * target_rate, 2)
    price_info["discounted_prices"] = discounted_prices
    price_info["cheapest_price"] = discounted_prices[-1]["price"]  # 最便宜的价格（最大数量折扣）
    return price_info

# 示例调用：解析含数量折扣的价格（目标币种USD）
raw_price = {
    "original_price": 100.0,  # 原价100元（基准币种）
    "discount_price": 80.0,    # 基础折扣价80元
    "currency_rates": {"USD": 0.138, "EUR": 0.128},  # 1元=0.138美元，0.128欧元
    "quantity_discounts": [{"min_qty":2,"discount":5},{"min_qty":5,"discount":10}]
}
parsed_price = parse_aliexpress_price(raw_price, target_currency="USD")
print(parsed_price["discounted_prices"][1]["desc"])  # 输出：2-4件：USD 10.42（省5%）</code></pre><h2>三、库存陷阱：漏看 “海外仓库存”，买家等了 15 天退款</h2><p>最让我崩溃的一次，是欧洲买家下单 10 件手机壳，系统显示 “有库存”，实际海外仓（德国仓）缺货，只能从国内仓发货，物流时效从 3 天变成 15 天，买家直接退款并投诉 “虚假库存”。查接口发现，速卖通的库存分三类：<code>domestic_stock</code>（国内仓）、<code>overseas_stock</code>（海外仓，按国家分）、<code>pre_order_stock</code>（预售库存），我只取了<code>total_stock</code>，没区分仓库，导致海外买家下单国内仓库存。</p><p>后来我写的库存解析函数，专门标注仓库位置和发货时效，避免买家预期不符：</p><p>python</p><p>运行</p><pre><code>def parse_aliexpress_stock(stock_data, target_country="DE"):
    """
    解析速卖通库存：区分国内仓、海外仓、预售库存
    :param stock_data: 接口返回的库存数据
    :param target_country: 目标买家国家（匹配海外仓）
    """
    stock_info = {}
    # 1. 国内仓库存（默认发货，时效7-15天）
    domestic_stock = int(stock_data.get("domestic_stock", 0))
    stock_info["domestic"] = {
        "stock": domestic_stock,
        "shipping_time": "7-15 business days",
        "status": "In Stock" if domestic_stock &gt; 0 else "Out of Stock"
    }
    
    # 2. 海外仓库存（按国家匹配，时效3-7天）
    overseas_stocks = stock_data.get("overseas_stocks", [])
    target_overseas = next((s for s in overseas_stocks if s["country"] == target_country), None)
    if target_overseas:
        overseas_stock = int(target_overseas.get("stock", 0))
        stock_info["overseas"] = {
            "country": target_country,
            "stock": overseas_stock,
            "shipping_time": "3-7 business days",
            "status": "In Stock" if overseas_stock &gt; 0 else "Out of Stock"
        }
    else:
        stock_info["overseas"] = {"status": "No Overseas Warehouse"}
    
    # 3. 预售库存（需等备货，时效15-30天）
    pre_order_stock = int(stock_data.get("pre_order_stock", 0))
    stock_info["pre_order"] = {
        "stock": pre_order_stock,
        "shipping_time": "15-30 business days",
        "status": "Pre-order Available" if pre_order_stock &gt; 0 else "Pre-order Unavailable"
    }
    
    # 4. 总可售库存（排除预售）
    stock_info["total_available"] = domestic_stock + (target_overseas["stock"] if target_overseas else 0)
    return stock_info

# 示例调用：解析德国买家的库存（目标国家DE）
raw_stock = {
    "domestic_stock": 100,
    "overseas_stocks": [{"country":"DE","stock":20},{"country":"US","stock":30}],
    "pre_order_stock": 50
}
parsed_stock = parse_aliexpress_stock(raw_stock, target_country="DE")
print(parsed_stock["overseas"]["status"])  # 输出：In Stock
print(parsed_stock["overseas"]["shipping_time"])  # 输出：3-7 business days</code></pre><h2>四、物流陷阱：把 “包邮” 当 “全地区包邮”，运费亏了 500 刀</h2><p>有次帮做中东市场的卖家调试，发现发给沙特买家的商品，系统显示 “包邮”，实际物流商收了 500 刀运费。查接口发现，速卖通的<code>shipping_info</code>里，<code>is_free_shipping</code>是 “部分地区包邮”，<code>free_shipping_countries</code>字段明确写了 “US,DE,UK”，沙特不在列，我直接把<code>is_free_shipping</code>当成 “全地区包邮”，导致运费全由卖家承担。</p><p>后来我写的物流解析函数，专门处理包邮地区、运费模板和时效：</p><p>python</p><p>运行</p><pre><code>def parse_aliexpress_shipping(shipping_data, target_country="DE"):
    """
    解析速卖通物流：判断包邮、计算运费、标注时效
    :param shipping_data: 接口返回的物流数据
    :param target_country: 目标买家国家
    """
    shipping_info = {}
    # 1. 判断是否包邮（部分地区/全地区）
    is_free_shipping = shipping_data.get("is_free_shipping", False)
    free_countries = shipping_data.get("free_shipping_countries", [])
    if is_free_shipping:
        if target_country in free_countries:
            shipping_info["shipping_type"] = "Free Shipping"
            shipping_info["cost"] = 0.0
        else:
            shipping_info["shipping_type"] = "Paid Shipping (Free in US/DE/UK)"
    else:
        shipping_info["shipping_type"] = "Paid Shipping"
    
    # 2. 计算目标国家运费（按重量/件数）
    if shipping_info["cost"] != 0:
        shipping_template = shipping_data.get("shipping_template", {})
        # 按重量计费（速卖通常用方式）
        weight = float(shipping_data.get("product_weight", 0.5))  # 商品重量（kg）
        cost_per_kg = float(shipping_template.get("cost_per_kg", 10.0))
        base_cost = float(shipping_template.get("base_cost", 5.0))
        shipping_info["cost"] = round(base_cost + (weight * cost_per_kg), 2)
    
    # 3. 物流时效（区分国内仓/海外仓）
    warehouse_type = shipping_data.get("warehouse_type", "domestic")  # domestic/overseas
    if warehouse_type == "overseas" and target_country in [s["country"] for s in shipping_data.get("overseas_stocks", [])]:
        shipping_info["delivery_time"] = "3-7 business days (Overseas Warehouse)"
    else:
        shipping_info["delivery_time"] = "7-15 business days (Domestic Warehouse)"
    
    # 4. 物流方式（如DHL, AliExpress Standard Shipping）
    shipping_info["carrier"] = shipping_data.get("default_carrier", "AliExpress Standard Shipping")
    return shipping_info

# 示例调用：解析沙特买家的物流（目标国家SA）
raw_shipping = {
    "is_free_shipping": True,
    "free_shipping_countries": ["US", "DE", "UK"],
    "product_weight": 0.8,
    "shipping_template": {"base_cost": 8.0, "cost_per_kg": 12.0},
    "warehouse_type": "domestic"
}
parsed_shipping = parse_aliexpress_shipping(raw_shipping, target_country="SA")
print(parsed_shipping["shipping_type"])  # 输出：Paid Shipping (Free in US/DE/UK)
print(parsed_shipping["cost"])  # 输出：17.6</code></pre><h2>五、限流暴击：免费版 10 次 / 分钟，大促被封 48 小时</h2><p>速卖通的限流规则对免费开发者极不友好：<strong>商品详情接口免费版 10 次 / 分钟，超过后返回 429，且封禁时长随次数增加从 24 小时涨到 72 小时</strong>。有次 “11.11” 大促，卖家要采集 500 个竞品商品，我没控制好频率，1 小时内发了 120 次请求，结果接口被封 48 小时，错过竞品分析窗口期。</p><p>后来用 “令牌桶算法 + 任务优先级” 做了限流，还加了失败重试（速卖通接口跨境延迟高，偶尔返回 503）：</p><p>python</p><p>运行</p><pre><code>import time
from collections import deque

class AliexpressRateLimiter:
    def __init__(self, max_calls=10, period=60):
        """速卖通限流：max_calls次/period秒（免费版10次/分钟）"""
        self.max_calls = max_calls
        self.period = period
        self.tokens = max_calls  # 令牌桶初始令牌数
        self.last_refresh = time.time()
    
    def refresh_tokens(self):
        """按时间比例刷新令牌"""
        now = time.time()
        elapsed = now - self.last_refresh
        new_tokens = elapsed * (self.max_calls / self.period)
        self.tokens = min(self.max_calls, self.tokens + new_tokens)
        self.last_refresh = now
    
    def get_token(self, block=True):
        """获取令牌，block=True则等待"""
        self.refresh_tokens()
        if self.tokens &gt;= 1:
            self.tokens -= 1
            return True
        if not block:
            return False
        # 计算等待时间
        wait_time = (1 - self.tokens) * (self.period / self.max_calls)
        time.sleep(wait_time + 0.1)  # 多等0.1秒避免边界问题
        return self.get_token(block=False)

# 示例：按销量优先级采集商品
limiter = AliexpressRateLimiter(max_calls=10)
# 商品列表：(product_id, 销量)，按销量降序采集
product_list = [("100500587654321", 1200), ("100500587654322", 800)]

for product_id, sales in sorted(product_list, key=lambda x: -x[1]):
    if limiter.get_token():
        print(f"采集高销量商品{product_id}（销量：{sales}）")
        # 发起接口请求（省略具体逻辑）
        time.sleep(1)  # 模拟跨境请求延迟</code></pre><h2>六、速卖通商品详情 API 的 5 个 “跨境潜规则”（血的教训）</h2><p>做了 5 年速卖通工具，这些接口 “坑点” 必须刻在脑子里，踩中任何一个都得熬夜改代码：</p><ol><li><strong>签名必传 3 个参数</strong>：<code>format=json</code>、<code>sign_method=sha256</code>、<code>UTC ISO时间戳</code>，漏一个就报 401，和国内平台的签名逻辑完全不同。</li><li><strong>商品 ID 是 13 位</strong>：别和淘宝 12 位、京东 10 位混了，传错 ID 返回 “商品不存在”，错误码和 “商品下架” 一样，新手难区分。</li><li><strong>价格要算 “三层折扣”</strong> ：原价→基础折扣价→数量折扣，还得按<code>currency_rates</code>换算多币种，直接用固定汇率或漏算数量折扣，利润会差 30%。</li><li><strong>库存分 “三仓”</strong> ：国内仓、海外仓、预售仓，只看<code>total_stock</code>会导致海外买家下单国内仓，时效延迟被投诉。</li><li><strong>包邮是 “部分地区”</strong> ：<code>is_free_shipping=True</code>不代表全地区包邮，必须查<code>free_shipping_countries</code>，否则中东、南美买家的运费会让你亏哭。</li></ol><h2>最后：给跨境开发者的 3 句真心话</h2><ol><li><strong>多语言别硬转</strong>：速卖通的<code>title_en</code>/<code>title_ru</code>是卖家手动填写的，比机器翻译准确 10 倍，别用翻译 API 转中文标题，会出现 “手机壳” 译成 “phone cover” 却和卖家填写的 “mobile case” 不符的问题。</li><li><strong>物流成本要加缓冲</strong>：速卖通的运费模板会随燃油费调整，解析时建议加 10% 缓冲（比如算出来 100 刀，实际按 110 刀预估），避免运费超支。</li><li><strong>大促前 3 天别调试</strong>：速卖通大促（双 11、黑五）前接口会限流收紧，免费版可能降到 5 次 / 分钟，提前一周完成调试，别临时改代码被封。</li></ol>]]></description></item><item>    <title><![CDATA[如何通过智能供应链管理提升制造效率？ 月]]></title>    <link>https://segmentfault.com/a/1190000047446950</link>    <guid>https://segmentfault.com/a/1190000047446950</guid>    <pubDate>2025-12-03 18:04:05</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>欢迎来到智能供应链管理的时代，这是一个由技术驱动的数字化、自动化、智能化战略转折点，它不仅改变了传统制造业的规划设计范式，也在全球供应链的构建上建立起全新范本。回想一下，传统的供应链管理长期存在三大深层次问题：首先，由于系统智能化程度不高，导致供应链结构过于脆弱，抗外部打击能力下降；其次，在复杂系统协作过程中，由于工业企业应用庞杂，难以突破不同系统间的数据壁垒；第三，面对全球绿色化转型的强力倒逼，碳计量方式仍停留在落后的人工记录阶段，难以合规。<br/>但是，正如广域铭岛所展示的那样，智能供应链管理的解决方案正在逐步推进这些挑战的破局。他们的典型路径是：融合20多种工业协议，构建毫秒级数据物流体系，在生产调度、能耗、质量等关键领域引入AI，实现场景下的多智能体动态协同。通过这些方法，将其中一个汽车制造工厂的全局库存周转率提升了30%以上。<br/>更值得关注的是，通过跨行业实践，我们看到了智能供应链管理的惊人效果：某铝电联合企业成功降低吨铝耗电200千瓦时，年节省电费7000万元；某芯片制造商有效切断了产能制约瓶颈，将市场响应周期压缩为原来的四分之一。广域铭岛打造出的GOS系统，通过实时数据收集、动态控制和智能预测，将企业运营效率推到了一个全新的高度。<br/>其中的精妙之处在于他们团队完成的架构设计：从数据感知层、智能化规划层和末端执行层构成了完整的闭环系统。尤其是选用的知识图谱技术，将企业运营中各种零散数据实现了有机融合，让质量追溯从过去的数周缩短至实时响应，这无疑是对智能供应链管理一流实践的最好注脚。<br/>广域铭岛团队还提出了一个值得借鉴的核心理念：智能供应链管理不是简单地改变某一个局部环节的实施策略，而应该是整个产业链协同运作方式的根本变革。这个理念体现在他们的数字孪生技术应用中，也体现在他们为客户提供的整套解决方案中。<br/>展望未来，智能供应链管理将随着更多AI技术的加入，生成更加灵性的协作模式。从预测性维护到分布式制造，从碳强度管控到全流程闭环优化，广域铭岛正为更多制造企业提供实时智能决策的生命动力。如果说制造业的智能化是一条漫长的进化之路，那么智能供应链管理就是其中一个划时代的关键节点。</p>]]></description></item><item>    <title><![CDATA[深度拆解：SAE 刚性交付的底层逻辑，从]]></title>    <link>https://segmentfault.com/a/1190000047446975</link>    <guid>https://segmentfault.com/a/1190000047446975</guid>    <pubDate>2025-12-03 18:03:25</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>作者：张凤婷（娜米）</p><p>资源的刚性交付，不是云上天生就具备的能力。当选择自建或自管理一个 Kubernetes/ECS 资源池时，就必须直面一个残酷的现实：所依赖的底层 IaaS 资源本身就是非刚性的。</p><p>阿里云上 ECS 有多代实例规格（如 g6、c7i、r8y 等），基于 Intel、AMD 及自研倚天 ARM 芯片，但这并不保证在任何时刻、任何地域、任何可用区，所需要的那款机型就一定有库存。这种底层资源的“不确定性”，会像幽灵一样渗透到自建的上层系统中。</p><p>刚性交付的本质，是将“不确定性”从系统中排除的关键机制。它通过可控的资源成本，换取了业务的稳定性、高性能和可预测性。 对于任何严肃的线上业务而言，这种确定性并非锦上添花，而是维系其商业信誉和核心价值的生命线。</p><p>以下几个案例，阐述非刚性交付”带来的典型困境。</p><p><strong>案例一：游戏行业 —— 新品发布日的“容量灾难”</strong></p><ul><li>行业：在线游戏、元宇宙</li><li><p>故障：</p><ol><li>场景：一家游戏公司万众期待的新游戏正式公测。运营团队基于压测，制定了雄心勃勃的扩容计划，需要在开服瞬间将游戏服务器（通常需要高性能计算或 GPU 优化的特定 ECS 机型）的规模扩大 10 倍。他们管理着一个基于 K8s 的自建集群。</li><li>触发：开服铃声敲响，CI/CD 流水线触发了大规模的横向扩容。然而，K8s 的节点自动伸缩器 Cluster Autoscaler 在向阿里云申请创建新的 ECS 节点时，API 返回了“Insufficient stock”库存不足的错误。他们所依赖的特定高性能机型，在该可用区已无库存。</li><li>现象：应用的 Pod 因为没有足够的节点资源而大量处于 <code>Pending </code>状态，无法被调度。新玩家的登录请求雪片般涌入，但服务器容量远未达到预期。</li></ol></li><li><p>业务影响：</p><ul><li>上线即失败：大量玩家无法登录，游戏入口处大排长龙，社交媒体和游戏社区瞬间被负面评价淹没，精心策划的发布会变成了公关灾难。</li><li>真金白银的损失：高额的市场推广费用付诸东流，首日充值流水远低于预期。</li><li>玩家永久流失：糟糕的首日体验会导致大量核心玩家永久流失至竞品。</li></ul></li></ul><p><strong>案例二：电商行业 —— 大促活动中的“性能悬崖”</strong></p><ul><li>行业：电商与在线零售</li><li><p>故障：</p><ol><li>场景：一家电商平台为了应对大促，提前“预留”了大量 ECS 节点。为了“提高资源利用率”，他们在核心的交易应用 Pod 所在的节点上，混部了一些非核心的数据分析和日志处理 Pod，并配置了非刚性的 CPU 交付。</li><li>触发：大促零点开启，交易量飙升，交易应用需要全部申请的 CPU。同时，数据分析任务也开始高强度运行，抢占 CPU 资源。</li><li>现象：交易应用的实际可用 CPU 被严重挤压，响应时间急剧恶化，大量请求超时。</li></ol></li><li><p>业务影响：</p><ul><li>订单大量流失：支付和下单环节的堵塞，直接导致 GMV 损失。</li><li>品牌信誉受损：用户在关键时刻掉链子，严重损害品牌可靠性。</li></ul></li></ul><p><strong>案例三：金融科技行业 —— 交易时段的“随机掉线”</strong></p><ul><li>行业：金融科技 (FinTech)，尤其是证券交易</li><li><p>故障：</p><ol><li>场景：一个核心的行情推送 Java 服务，以内存非刚性交付的方式运行在一个自管理的 K8s 集群上。</li><li>触发：交易时段，订阅量激增，服务实际内存使用远超其申请值。此时节点内存压力增大，触发 OOM Killer。</li><li>现象：行情服务 Pod 被系统判定为“劣质进程”而随机杀死，导致客户端行情刷新中断。</li></ol></li><li><p>业务影响：</p><ul><li>交易决策失误：用户因行情中断而做出错误决策或错失交易时机，造成直接经济损失。</li><li>合规与监管风险：核心系统频繁中断，可能触犯金融行业的高可用性监管要求。</li></ul></li></ul><p><strong>案例四：企业软件行业 —— 核心ERP系统的“性能抽奖”</strong></p><ul><li>行业：企业软件 (ERP, CRM)，尤其是大型单体应用</li><li><p>故障：</p><ol><li>场景：一家企业将其庞大的、无法轻易水平扩展的单体 ERP 系统容器化后，部署在一个资源非刚性交付的自建集群上，以期“节约成本”。</li><li>触发：在月末财务结算等高峰期，ERP 系统需要大量 CPU 和内存。但它必须和节点上其他应用“共享”资源。</li><li>现象：ERP 系统的性能变得极不稳定，时快时慢，如同“抽奖”。有时一个报表生成需要 2 分钟，有时需要 20 分钟。</li></ol></li><li><p>业务影响：</p><ul><li>工作效率低下：员工的核心工作流程被频繁打断，财务、供应链等部门的月末结算工作无法按时完成。</li><li>决策延迟：管理者无法及时获取准确的业务报表，影响了商业决策的时效性。</li></ul></li></ul><h2>资源刚性交付困境</h2><h3>资源供给的不确定性</h3><p>困境本质：“承诺的资源” ≠ “可即时获取的资源”。</p><ul><li>库存波动：热门规格 ECS，在大促或行业高峰期容易出现“秒光”，导致扩容失败。</li><li>区域/可用区差异：某些 AZ 因物理机房容量限制，无法提供特定资源类型，跨 AZ 调度又需额外网络与配置成本。</li><li>代际断层：旧代实例停售或库存枯竭，但应用尚未适配新架构，造成刚性承诺无法兑现。</li></ul><h3>性能隔离难以真正实现</h3><p>困境本质：“逻辑隔离”不等于“物理隔离”，刚性性能难以 100% 保障。</p><ul><li>虚拟化开销与干扰：即使使用 Cgroups、CPU 绑核等技术，共享 NUMA 节点、内存带宽、磁盘 I/O 队列仍可能被“嘈杂邻居”抢占。</li><li>突发流量冲击：同节点上其他租户突发高负载（如备份、扫描），导致本应“独占”的实例出现延迟毛刺。</li><li>存储性能抖动：存储在多租户争抢下 IOPS 和吞吐不稳定，影响核心业务等关键应用。</li></ul><h3>弹性与刚性的内在矛盾</h3><p>困境本质：刚性要求确定性，弹性依赖不确定性，二者天然张力。</p><ul><li>预占 vs 按需：为保障刚性需提前预留资源，但业务负载波动大时造成浪费；若完全按需，则无法应对突发高峰。</li><li>冷启动延迟：首次启动需拉镜像、初始化，往往无法满足业务的刚性响应要求。</li></ul><h3>异构资源管理复杂度高</h3><p>困境本质：“资源刚性”需端到端栈协同，任一环节短板即导致整体失效。</p><ul><li>专用硬件：驱动版本、CUDA 兼容性、拓扑感知调度、故障恢复机制各异，难以标准化交付。</li><li>混合架构支持难：x86 与 ARM（如倚天 710）指令集不同，应用需重新编译测试，刚性交付需维护多套镜像与部署流程。</li><li>网络与存储耦合：高性能计算需 RDMA、NVMe over Fabric 等底层能力，但这些能力在虚拟化层常被削弱或不可用。</li></ul><h3>传统架构与云原生理念割裂</h3><p>困境本质：刚性交付不仅是技术问题，更是组织与认知转型问题。</p><ul><li>缺乏弹性设计：应用未做无状态改造，无法横向扩展，只能纵向升级（Scale-Up），而大规格实例更稀缺、更昂贵。</li><li>运维惯性阻力：企业习惯“买服务器、装系统、长期运行”，对“按需申请、用完即弃”的刚性交付模式接受度低。</li></ul><h3>成本模型与刚性目标冲突</h3><p>困境本质：财务约束常迫使技术理想向现实低头。</p><ul><li>刚性 = 高成本：独占物理机、专用集群、多 AZ 冗余等方案显著推高 TCO。</li><li>企业被迫妥协：为控制预算，用户常选择共享资源池+监控告警“事后补救”，而非事前刚性保障。</li><li>计费模式滞后：传统按小时计费无法匹配秒级弹性需求，导致“为不用的资源付费”或“关键时刻无资源可用”。</li></ul><h2>SAE 在刚性交付上做的工作</h2><p>作为阿里云面向应用层的全托管 Serverless PaaS 平台，针对资源刚性交付的系统性困境，从<strong>资源供给、性能隔离、弹性模型、异构调度、成本结构、容灾能力、可观测性与架构演进</strong>等多个维度进行了设计。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446977" alt="image" title="image"/></p><h3>1. 破解“资源供给不确定性” → 构建无限弹性资源池</h3><ul><li>多源异构资源整合：  <br/>SAE 背后打通神龙裸金属服务器、弹性容器实例（ECI）支持各代  x86/ARM 等海量资源，形成统一调度池。</li><li>智能跨机型调度：  <br/>当用户指定规格库存不足时，调度器自动选择性能相当、兼容性一致的替代资源（如 g7 缺货 → 自动调度 g8i），全程对用户透明。</li><li>结果：  <br/>交付的是“计算能力”，而非“特定机型”，彻底规避因库存波动导致的扩容失败。</li></ul><h3>2. 解决“性能隔离难” → 天然沙箱化 + 独占资源</h3><ul><li>默认运行在 ECI 沙箱中：  <br/>每个应用实例运行在轻量级安全容器，实现内核级隔离，杜绝“嘈杂邻居”干扰。</li><li>资源 100% 独占：  <br/>用户申请的 CPU、内存、网络带宽均由 runD 底层安全沙箱保障，无超分、无争抢，性能稳定可预期。</li><li>结果：  <br/>刚性性能不再是“尽力而为”，而是确定性交付，尤其适合金融交易、实时推荐等敏感场景。</li></ul><h3>3. 调和“弹性与刚性矛盾” → 按实际用量计费 + 缩容至零</h3><ul><li>闲置不计费：  <br/>应用缩容到 0 实例时，CPU/内存资源完全释放，不产生费用（仅保留配置元数据）。</li><li>秒级冷启动优化：  <br/>结合镜像预热、快照加速、本地缓存等技术，大幅缩短首次启动延迟，逼近“即时刚性响应”。</li><li>结果：  <br/>用户无需为“以防万一”长期预留资源，刚性保障与极致成本兼得，替代高风险混部策略。</li></ul><h3>4. 简化“异构资源管理” → 屏蔽底层复杂性</h3><ul><li>ARM/x86 无缝兼容：  <br/>如支持海光国产芯片，用户只需提供兼容镜像，SAE 自动完成调度与运行时适配。</li><li>结果：  <br/>开发者只需关注“我要多少算力”，无需关心“卡在哪台机器上、驱动是否匹配”。</li></ul><h3>5. 重构“成本模型” → 从“买资源”到“买能力”</h3><ul><li>按实际 CPU/内存使用量秒级计费：  <br/>不再按整机小时付费，避免资源闲置浪费。</li><li>免运维成本：  <br/>无需管理节点、打补丁、编写扩缩容脚本，人力成本大幅降低。</li><li>结果：  <br/>刚性交付不再昂贵，中小企业也能享受企业级可靠性。</li></ul><h3>6. 强化“容灾与高可用” → 多可用区刚性容灾</h3><ul><li>一键开启多 AZ 部署：  <br/>SAE 自动将应用实例分散到多个可用区，跨机房冗余。</li><li>AZ 故障自动恢复：  <br/>若某 AZ 整体不可用，SAE 在其他 AZ 刚性拉起新实例，RTO 控制在分钟级。</li><li>结果：  <br/>刚性交付从“单点稳定”升级为“应用级连续性保障”。</li></ul><h3>7. 提升“可观测性与可信度” → 内置全链路监控</h3><ul><li>集成 ARMS + SLS + Prometheus：  <br/>提供应用性能监控（APM）、日志、指标、链路追踪一体化视图。</li><li>资源使用透明化：  <br/>用户可清晰看到 CPU 使用率、内存水位、网络吞吐是否达到承诺值。</li><li>结果：  <br/>刚性 SLA 可验证、可审计，告别“黑盒交付”。</li></ul><h3>8. 支持“传统应用平滑演进” → 兼顾稳定与未来</h3><ul><li>支持 WAR/JAR/镜像直接部署：  <br/>ERP、OA 等单体应用无需改造即可运行在 SAE 上，享受刚性资源保障。</li><li>内置诊断能力：  <br/>通过性能剖析定位瓶颈（如数据库慢查询、线程阻塞），为后续微服务拆分提供数据依据。</li><li>结果：  <br/>SAE 不仅是“运行平台”，更是企业云原生转型的跳板。</li></ul><h2>了解 Serverless 应用引擎 SAE</h2><p>阿里云 Serverless 应用引擎 SAE 是面向 AI 时代的一站式容器化应用托管平台，以“托底传统应用、加速 AI 创新”为核心理念。它简化运维、保障稳定、闲置特性降低 75% 成本，并通过 AI 智能助手提升运维效率。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446978" alt="image" title="image" loading="lazy"/></p><p>面向 AI，SAE 集成 Dify 等主流框架，支持一键部署与弹性伸缩，在 Dify 场景中实现性能<strong>提升 50 倍、成本优化 30% 以上</strong>。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446979" alt="image" title="image" loading="lazy"/></p><h3>产品优势</h3><p>凭借八年技术沉淀，SAE 入选 2025 年 Gartner 云原生魔力象限全球领导者，亚洲第一，助力企业零节点管理、专注业务创新。SAE 既是传统应用现代化的“托举平台”，也是 AI 应用规模化落地的“加速引擎”。</p><p><strong>1. 传统应用运维的“简、稳、省”优化之道</strong></p><ul><li>简：零运维心智，专注业务创新</li><li>稳：企业级高可用，内置全方位保障</li><li>省：极致弹性，将成本降至可度量</li></ul><p><strong>2. 加速 AI 创新：从快速探索到高效落地</strong></p><ul><li>快探索：内置 Dify、RAGFlow、OpenManus 等热门 AI 应用模板，开箱即用，分钟级启动 POC；</li><li>稳落地：提供生产级 AI 运行时，性能优化（如 Dify 性能提升 50 倍）、无感升级、多版本管理，确保企业级可靠交付；</li><li>易集成：深度打通网关、ARMS、计量、审计等能力，助力传统应用智能化升级。</li></ul><h2>适合谁？</h2><p>✅ 创业团队：没有专职运维，需要快速上线  <br/>✅ 中小企业：想降本增效，拥抱云原生  <br/>✅ 大型企业：需要企业级稳定性和合规性  <br/>✅ 出海企业：需要中国区 + 全球部署  <br/>✅ AI 创新团队：想快速落地 AI 应用</p><h3>了解更多</h3><p>产品详情页地址（点击阅读原文即可查看）：<a href="https://link.segmentfault.com/?enc=afj%2BR0CE%2FyioGlwm8FRgOA%3D%3D.lUXk%2BeHpZJhnxSVdYZNj8D06QFBYCYeoq%2Fx9P4olwQB5gltUMBX87zY%2F0zXhi2x1" rel="nofollow" target="_blank">https://www.aliyun.com/product/sae</a></p><p>欢迎使用钉钉搜索群号： 23156632</p><p>加入 SAE 客户服务群 👇</p>]]></description></item><item>    <title><![CDATA[美股 (US) 与 墨西哥 (Mexic]]></title>    <link>https://segmentfault.com/a/1190000047446988</link>    <guid>https://segmentfault.com/a/1190000047446988</guid>    <pubDate>2025-12-03 18:02:50</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>1. 接入概述 (General)</h2><p>本接口用于获取美国（NYSE, NASDAQ, AMEX）及墨西哥（BMV, BIVA）证券市场的实时行情、历史 K 线及指数数据。</p><ul><li><strong>API Base URL</strong>: <code>https://api.stocktv.top</code></li><li><strong>WebSocket URL</strong>: <code>wss://ws-api.stocktv.top/connect</code></li><li><strong>鉴权方式</strong>: 所有请求均需携带 URL 参数 <code>key=您的API密钥</code></li></ul><h3>1.1 关键市场 ID (Country ID)</h3><p>在调用相关接口时，请务必区分以下 <code>countryId</code>：</p><table><thead><tr><th align="left">市场名称</th><th align="left">Country ID</th><th align="left">交易所示例</th></tr></thead><tbody><tr><td align="left"><strong>美国 (USA)</strong></td><td align="left"><strong>5</strong></td><td align="left">NYSE (1), NASDAQ (2), AMEX</td></tr><tr><td align="left"><strong>墨西哥 (Mexico)</strong></td><td align="left"><strong>7</strong></td><td align="left">Mexico (53), BIVA (144)</td></tr></tbody></table><hr/><h2>2. 核心数据接口</h2><h3>2.1 获取股票列表 (Stock List)</h3><p>用于查询指定市场的股票清单，获取股票的名称、代码 (Symbol) 和 <strong>系统 ID (PID)</strong>。</p><blockquote><strong>注意</strong>：<code>id</code> (PID) 是后续查询 K 线和订阅 WebSocket 的唯一标识符。</blockquote><ul><li><strong>接口地址</strong>: <code>/stock/stocks</code></li><li><strong>请求方式</strong>: <code>GET</code></li><li><strong>请求参数</strong>:</li></ul><table><thead><tr><th align="left">参数名</th><th align="left">类型</th><th align="left">必填</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left"><code>key</code></td><td align="left">String</td><td align="left">是</td><td align="left">您的 API Key</td></tr><tr><td align="left"><code>countryId</code></td><td align="left">Int</td><td align="left">是</td><td align="left"><strong>5</strong> (美股) 或 <strong>7</strong> (墨西哥)</td></tr><tr><td align="left"><code>pageSize</code></td><td align="left">Int</td><td align="left">否</td><td align="left">每页数量 (默认 10)</td></tr><tr><td align="left"><code>page</code></td><td align="left">Int</td><td align="left">否</td><td align="left">页码 (默认 1)</td></tr></tbody></table><ul><li><p><strong>请求示例 (获取美股列表)</strong>:</p><pre><code class="http">GET https://api.stocktv.top/stock/stocks?countryId=5&amp;pageSize=20&amp;page=1&amp;key=YOUR_KEY</code></pre></li><li><p><strong>响应示例</strong>:</p><pre><code class="json">{
  "code": 200,
  "data": {
    "records": [
      {
        "id": 8888,          // [关键] PID，用于K线接口
        "name": "Apple Inc", // 股票名称
        "symbol": "AAPL",    // 股票代码
        "exchangeId": 2,     // 交易所ID (2=NASDAQ)
        "last": 180.5,       // 最新价
        "chgPct": 1.25,      // 涨跌幅%
        "countryNameTranslated": "United States"
      }
    ]
  }
}</code></pre></li></ul><hr/><h3>2.2 获取 K 线数据 (Candlestick Data)</h3><p>获取指定股票的历史行情数据，支持多种时间周期。</p><ul><li><strong>接口地址</strong>: <code>/stock/kline</code></li><li><strong>请求方式</strong>: <code>GET</code></li><li><strong>请求参数</strong>:</li></ul><table><thead><tr><th align="left">参数名</th><th align="left">类型</th><th align="left">必填</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left"><code>key</code></td><td align="left">String</td><td align="left">是</td><td align="left">您的 API Key</td></tr><tr><td align="left"><code>pid</code></td><td align="left">Int</td><td align="left">是</td><td align="left">股票系统 ID (通过 2.1 接口获取)</td></tr><tr><td align="left"><code>interval</code></td><td align="left">String</td><td align="left">是</td><td align="left">K线周期 (ISO 8601格式)</td></tr></tbody></table><ul><li><p><strong>周期 (Interval) 说明</strong>:</p><ul><li><code>PT1M</code> (1分钟), <code>PT5M</code> (5分钟), <code>PT15M</code> (15分钟), <code>PT30M</code> (30分钟), <code>PT1H</code> (1小时)</li><li><code>P1D</code> (日线), <code>P1W</code> (周线), <code>P1M</code> (月线)</li></ul></li><li><p><strong>请求示例 (获取墨西哥某股票日线)</strong>:</p><pre><code class="http">GET https://api.stocktv.top/stock/kline?pid=12345&amp;interval=P1D&amp;key=YOUR_KEY</code></pre></li><li><p><strong>响应示例</strong>:</p><pre><code class="json">{
  "code": 200,
  "data": [
    {
      "time": 1719818400000, // 时间戳 (毫秒)
      "open": 150.0,
      "high": 155.0,
      "low": 149.0,
      "close": 153.0,
      "volume": 200000
    }
  ]
}</code></pre></li></ul><hr/><h3>2.3 获取大盘指数 (Indices)</h3><p>获取美股（如纳斯达克、标普500）或墨西哥（如 S\&amp;P/BMV IPC）的指数行情。</p><ul><li><strong>接口地址</strong>: <code>/stock/indices</code></li><li><strong>请求方式</strong>: <code>GET</code></li><li><strong>请求参数</strong>: <code>countryId</code> (5=美国, 7=墨西哥)</li><li><p><strong>请求示例</strong>:</p><pre><code class="http">GET https://api.stocktv.top/stock/indices?countryId=7&amp;key=YOUR_KEY</code></pre></li></ul><hr/><h2>3. WebSocket 实时推送</h2><p>通过 WebSocket 长连接接收实时报价更新。</p><ul><li><strong>连接地址</strong>: <code>wss://ws-api.stocktv.top/connect?key=YOUR_KEY</code></li><li><strong>心跳机制</strong>: 连接建立后，建议定期发送心跳包以保持连接。</li><li><p><strong>推送数据结构</strong>:</p><pre><code class="json">{
    "pid": "8888",         // 对应 Rest API 中的 id
    "last_numeric": 181.2, // 最新价
    "pcp": "0.39",         // 涨跌幅%
    "timestamp": "1717728251",
    "bid": "181.1",        // 买价
    "ask": "181.3",        // 卖价
    "type": 1              // 1=股票, 2=指数
}</code></pre></li></ul><hr/><h2>4. 接入代码示例 (JavaScript)</h2><p>以下代码展示了如何根据 <code>countryId</code> 封装获取美股和墨西哥股票的逻辑。</p><pre><code class="javascript">const API_KEY = 'YOUR_API_KEY';
const BASE_URL = 'https://api.stocktv.top';

// 配置 ID
const MARKETS = {
    USA: 5,
    MEXICO: 7
};

/**
 * 获取指定市场的股票列表
 * @param {number} countryId - 5 for USA, 7 for Mexico
 */
async function getMarketStocks(countryId) {
    const url = `${BASE_URL}/stock/stocks?countryId=${countryId}&amp;pageSize=10&amp;page=1&amp;key=${API_KEY}`;
    try {
        const response = await fetch(url);
        const result = await response.json();
        
        if (result.code === 200) {
            console.log(`市场 (ID:${countryId}) 股票列表:`, result.data.records);
            // 示例：获取第一个股票的 PID 用于查 K 线
            if(result.data.records.length &gt; 0) {
                const firstStock = result.data.records[0];
                console.log(`示例股票: ${firstStock.name}, PID: ${firstStock.id}`);
            }
        }
    } catch (error) {
        console.error('API 请求失败:', error);
    }
}

// 1. 获取美股数据
getMarketStocks(MARKETS.USA);

// 2. 获取墨西哥股票数据
getMarketStocks(MARKETS.MEXICO);</code></pre>]]></description></item><item>    <title><![CDATA[如何实现智能研发协同以提升制造业效率？ ]]></title>    <link>https://segmentfault.com/a/1190000047446994</link>    <guid>https://segmentfault.com/a/1190000047446994</guid>    <pubDate>2025-12-03 18:02:06</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>随着工业4.0时代的到来，制造业正经历一场由数字化和人工智能驱动的深刻革命。传统研发模式在数据孤岛、跨部门协作效率低下以及知识复用率低等问题的制约下，难以满足现代企业对敏捷性和创新性的需求。广域铭岛作为这一领域的先行者，凭借其捷做设计研发协同平台和Geega工业互联网平台，提出了一种全新的智能研发协同理念，旨在通过技术的深度融合，提升企业的研发效率与创新能力。<br/>捷做平台的核心在于打破传统研发中的壁垒，实现全流程透明化与数据驱动的协同管理。它不仅支持设计、工艺和生产数据的统一管理，还通过模块化设计、可配置BOM（物料清单）以及变更闭环控制等功能，优化了企业内部的研发协作模式。广域铭岛的解决方案以客户需求为导向，将研发过程与生产需求紧密结合，确保设计即研发、设计即生产的核心原则。<br/>在智能研发协同中，广域铭岛充分利用了现代技术架构的优势。基于微服务的系统设计，使得每个业务模块都具备高度的独立性和灵活性。多租户技术的应用则保证了不同企业在同一平台上实现数据隔离与个性化配置，而高性能数据库的引入，尤其是基于图数据库的BOM管理，极大地提升了数据检索和处理的效率。这些技术的结合，使得捷做在复杂的研发环境中表现出色，成为制造业数字化转型的关键支撑。<br/>此外，广域铭岛还通过其专属的捷做平台，进一步强化了智能研发协同的核心。捷做构建了三级数据架构，涵盖了数据接入、治理及服务。通过对企业生产数据的实时分析与整合，它打破了数据的孤岛效应，实现了研发与生产的深度互联。更为重要的是，捷做设计研发协同平台将工艺规则和设备参数转化为可复用的数字资产，显著提升了知识密集型业务的处理效率。例如，在汽车焊接工艺中，通过对电流、电压和送丝速度等参数的封装，形成了“焊点质量指数”，从而帮助企业在设计验证中做出更精准的判断。<br/>在多个行业中的实践证实了广域铭岛智能研发协同策略的有效性。新能源电池领域的案例中，捷做平台通过数据建模和工艺优化，帮助企业将良品率提升8%，并将设备故障时间减少了65%。而在汽车行业，吉利集团借助该平台实现了每年30多款新车型的并行研发，不仅将零部件通用化率提升至75%，还显著降低了单车研发成本。这些成果不仅仅是数据的提升，更是整个研发范式的重构，体现了广域铭岛在技术驱动与业务融合上的领先地位。<br/>面向未来，广域铭岛持续推进两大技术方向：生成式研发助手和数字孪生研发环境。生成式研发助手基于工业大模型，能够通过自然语言和设计需求，快速生成设计图纸，帮助企业缩短设计周期；而数字孪生研发环境则构建了高保真的虚拟工厂，支持研发人员在仿真环境中实时调试设备参数，将工艺优化周期从周级压缩至小时级。这些创新不仅为制造业的研发提供了更高效的解决方案，还进一步加剧了智能研发协同的影响力。<br/>最终，广域铭岛的智能研发协同模式强调的是一种以数据为核心的开放生态系统。通过推动研发流程与实际业务的深度融合，它帮助制造企业突破传统模式的瓶颈，实现从创意到落地的无缝衔接。在这个过程中，数据管理和知识的多元共用成为关键，彰显了广域铭岛产品的智能化与前瞻性。</p>]]></description></item><item>    <title><![CDATA[如何将音乐从 iTunes 传输到闪存驱]]></title>    <link>https://segmentfault.com/a/1190000047447014</link>    <guid>https://segmentfault.com/a/1190000047447014</guid>    <pubDate>2025-12-03 18:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>对于喜欢收藏音乐的用户来说，iTunes 是一款经典且实用的音乐管理工具。然而，有时用户可能希望将 iTunes 中的音乐复制到 U 盘，以便在车载音响、电视或其他设备上轻松播放。那么，可以将歌曲从 iTunes 传输到 U 盘吗？当然可以。本文将提供详细的指南，教您如何将音乐从 iTunes 传输到 U 盘，帮助您轻松备份和携带音乐。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047447016" alt="图片" title="图片"/></p><h3>第一部分：如何直接将歌曲从 iTunes 复制到 U 盘</h3><p>无论你使用的是Windows 11/10/8 还是Mac ，你都可以轻松地将歌曲直接从 iTunes 音乐库传输到闪存驱动器。</p><p>以下是如何将音乐从 iTunes 传输到 U 盘的方法：</p><p>步骤 1. 打开电脑上的iTunes应用。</p><p>步骤 2. 打开您的音乐库或播放列表。在Windows中，请确保左上角的“音乐”选项卡已选中，然后依次点击“资料库”&gt;“歌曲”查看所有曲目。在 macOS 系统中，点击“音乐”图标，然后前往“播放列表”选项卡。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047447017" alt="图片" title="图片" loading="lazy"/><br/>​</p><p>步骤 3：插入 U 盘并打开。连接成功后，打开 U 盘文件夹，并确保桌面上的 iTunes 窗口也已打开。（ iTunes 一直崩溃？）</p><p>步骤 4：在 iTunes 中选择要传输的歌曲，然后将它们拖到 U 盘的文件夹中。在Windows中，按住“Ctrl”或“Shift”键可一次选择多首歌曲，然后将它们拖放到 U 盘中。在 macOS 系统中，使用“Command”键执行相同的操作。</p><p>您还可以从 iTunes 导出整个播放列表或音乐库，然后将其保存到 U 盘。如果您的播放器仅支持 MP3 或其他特定格式，则需要先将文件转换为所需的格式。</p><p>具体操作方法如下：</p><p>步骤 1. 打开 iTunes，然后转到菜单栏并选择“编辑”&gt;“偏好设置”&gt;“通用”。点击“导入设置”，在“导入方式”选项下选择“MP3 编码器”，然后点击两次“确定”以保存设置并返回您的资料库。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047447018" alt="图片" title="图片" loading="lazy"/></p><p>步骤 2. 将 USB 插入电脑并创建一个新文件夹。</p><p>步骤 3. 接下来，打开 iTunes，选择要传输的播放列表，然后转到“文件”&gt;“资料库”&gt;“导出资料库”。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047447019" alt="图片" title="图片" loading="lazy"/><br/>​</p><p>步骤 4. 在文件浏览器中，选择 USB 作为保存播放列表文件的目标位置。</p><p>想知道如何将 iPhone 中的歌曲导入 iTunes 吗？本指南将介绍两种有效的方法，并提供分步说明，教您如何将音乐从 iPhone 传输到 iTunes 资料库。</p><p>将 iPhone 音乐传输到 iTunes 资料库的两种方法</p><h3>第二部分：如何将 iTunes 媒体文件夹中的音乐传输到 U 盘</h3><p>除了直接将 iTunes 音乐传输到 U 盘外，您还可以找到计算机上存储 iTunes 歌曲的“iTunes Media”文件夹，然后将其复制到 U 盘。</p><p>以下是如何将 iTunes 媒体文件夹中的音乐传输到 U 盘的方法：</p><p>第一步：打开 iTunes，然后点击“编辑”&gt;“偏好设置”。此时会弹出一个新窗口。</p><p>步骤 2. 勾选“保持 iTunes 媒体文件夹有序”和“添加到资料库时将文件复制到 iTunes 媒体文件夹”，然后单击“确定”。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047447020" alt="图片" title="图片" loading="lazy"/></p><p>注意：如果您想更改 iTunes 媒体文件夹的位置，请点击“更改…”并选择新位置。</p><p>步骤 3. 转到“文件”&gt;“库”&gt;“整理库...”，选中“合并文件”，然后单击“确定”。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047447021" alt="图片" title="图片" loading="lazy"/></p><p>第四步：完成以上步骤后，所有媒体文件都将保存在 iTunes 媒体文件夹中。然后，您可以打开该文件夹，将播放列表拖放到您的 U 盘中。</p><p>额外内容：如何将音乐从 iPhone 传输到 U 盘</p><p>如果你的音乐不在 iTunes 里，而是存储在 iPhone 上怎么办？在这种情况下，如果你想直接将其导出到 U 盘，可以使用第三方工具。Coolmuster iOS Coolmuster是一款专业的iOS设备管理软件，它可以将 iPhone 中的音乐、照片、联系人、信息和其他数据导出到电脑或 U 盘。它易于使用，适合所有用户。</p><p>iOS助手亮点：</p><pre><code>轻松将 iPhone 中的音乐传输到闪存盘/USB 驱动器。
支持联系人、短信、照片、视频、日历、应用等。
一键轻松备份和恢复您的 iPhone /iPad。
预览并选择iOS文件后，即可轻松传输文件。
在您的电脑上全面管理 iTunes 备份文件和iOS数据。
直接通过 PC 或Mac编辑、添加或删除iOS设备上的数据。
支持最新的iOS 26版本和iPhone 17系列。

</code></pre><p>以下是如何使用iOS助理将音乐从 iPhone 传输到 U 盘的方法：</p><p>01将此工具下载并安装到您的电脑上。使用 USB 数据线将您的 iPhone 连接到电脑，然后插入您的 U 盘。</p><p>02检测到您的 iPhone 后，请在手机上点击“信任”，然后在程序中点击“继续”以建立连接。之后，您将看到如下所示的主界面。可以看到，所有不同的文件夹都已整理在主屏幕上。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047447022" alt="图片" title="图片" loading="lazy"/></p><p>03点击“音乐”部分查看您的歌曲列表。您可以根据需要选择单首歌曲或选择整个音乐文件夹进行传输。然后，点击“导出”按钮，选择您的U盘作为目标位置，并将所选音乐文件保存到U盘中。</p><h3>结尾</h3><p>无论您是想将音乐传输到车载播放器播放、备份音乐收藏，还是与朋友分享，以上介绍的将 iTunes 音乐传输到 U 盘的方法都简单实用。您只需选择最适合自己的方法即可轻松完成传输。</p><p>但是，如果你的音乐文件存储在 iPhone 上， Coolmuster iOS Assistant就是理想之选。它能让你快速导出音乐，还能在一个便捷的界面中管理手机上的其他数据。<br/>​</p>]]></description></item><item>    <title><![CDATA[告别数据孤岛与运维盲区：一款数字孪生平台]]></title>    <link>https://segmentfault.com/a/1190000047446682</link>    <guid>https://segmentfault.com/a/1190000047446682</guid>    <pubDate>2025-12-03 17:06:27</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>当园区的安防、能耗、设备、环境数据散落在十几个不同的系统里，当一次应急调度需要打电话、查图纸、跑现场才能拼凑出全局信息，当领导视察时只能看到静态的PPT汇报而非动态的运营实况——这或许是许多园区运营管理者正在经历的日常。<br/>在数字化的浪潮下，园区运营正从传统的“人防+技防”向“数据驱动、可视可控”的智慧运营演进。然而，理想与现实之间，往往横亘着技术实现的鸿沟：多源数据如何融合？三维场景如何快速构建？业务规则如何灵活配置？对于广大应用开发者而言，这既是巨大的市场机遇，也是棘手的技术挑战。<br/>今天，我们想抛开浮夸的概念，从一个资深开发者的视角，深入探讨一款名为“孪易 数字孪生 IOC”的工具平台，看看它如何通过一系列具体而微的功能设计，为园区智慧运营提供一套“开箱即用、深度可配”的解决方案，并在此过程中，为开发者打开一扇高效交付的大门。</p><h2>一、 核心痛点：园区运营的“数据之困”与“场景之渴”</h2><p>在深入产品之前，我们必须先理解园区运营的核心诉求。一个现代化的产业园区、智慧园区或大型综合体，其运营复杂度极高：<br/>系统林立，数据割裂：楼宇自控、视频监控、门禁停车、能耗管理、设备运维、环境监测……各系统独立建设，数据格式与协议各异，形成一个个“数据孤岛”。管理者无法获得统一、实时的全局态势。<br/>空间复杂，管理低效：地下管网、楼层结构、设备位置等信息依赖二维图纸或人工记忆。故障定位慢、资产盘点难、空间利用率分析缺乏直观依据。<br/>业务多样，响应滞后：安防告警、设备预警、环境超标、能耗突增等事件分散在不同值班岗位。缺乏跨业务的联动分析与统一指挥看板，应急响应效率低下。<br/>价值呈现，手段单一：向领导、访客展示运营成果时，往往停留在图表和报告层面，缺乏一个直观、动态、可交互的“数字孪生体”来生动呈现园区科技实力与管理水平。<br/>对于承接此类项目的开发者或集成商而言，挑战在于：如何在不投入巨额成本和漫长时间进行底层开发的情况下，构建一个能打通上述环节、满足客户核心价值的数字孪生应用？<br/><img width="640" height="360" referrerpolicy="no-referrer" src="/img/bVdmP6B" alt="" title=""/></p><h2>二、 破局之道：从“数据接入”到“业务呈现”的全链路配置化能力</h2><p>“孪易 数字孪生 IOC”提供了一套完整的工具链，其设计哲学可以概括为：“汇聚数据于一体，呈现业务于一屏，赋能管理于一键”。下面，我们结合园区场景，拆解其关键功能如何直击痛点。</p><h3>1. 数据融合：构建全域感知的“数字底板”</h3><p>数字孪生的生命在于数据。该平台的核心优势之一是强大的多源异构数据集成能力。它并非一个封闭的3D渲染引擎，而是一个强大的数据中枢。<br/><strong>对于物联网数据</strong>：它支持通过标准协议（如MQTT）或直接对接主流云物联网平台（如华为云IoTDA、阿里云物联网平台），将成千上万的传感器数据（温湿度、能耗、设备状态、车位状态等）实时接入。<br/><strong>对于业务系统数据</strong>：支持连接MySQL、PostgreSQL等关系型数据库，也能适配国产数据库，轻松获取资产信息、工单记录、人流统计等业务数据。<br/>对于视频数据：支持接入RTSP、FLV等格式的实时视频流，并可将视频画面与三维场景中的摄像头模型关联，实现“点击摄像头，即看实时画面”的融合监控。<br/><strong>价值点</strong>：开发者无需为每种数据源编写复杂的解析和对接代码，只需在后台进行配置，即可将分散的数据汇聚成园区统一的“数字底板”，为上层应用提供“燃料”。这极大地降低了数据整合阶段的技术门槛与时间成本。</p><h3>2. 场景构建：从“一张白纸”到“鲜活园区”的快速复刻</h3><p>有了数据，还需要承载数据的场景。平台提供了灵活的场景构建能力。<br/><strong>多格式支持</strong>：支持导入OBJ、FBX、GLTF等通用3D模型，以及BIM（建筑信息模型）和GIS（地理信息系统）数据。这意味着开发者可以利用园区已有的设计资料（如BIM模型）快速构建高保真的三维场景，而不是一切从零建模。<br/><strong>行业化预设</strong>：更值得一提的是其预置的行业插件库。针对“智慧园区”，平台可能已经内置了标准化的办公楼、厂房、停车场、路灯、配电箱等三维模型库，以及常见的园区业务数据模型。开发者可以像搭积木一样，快速组合出园区的三维骨架。<br/><strong>价值点</strong>：这解决了“从0到1”构建场景的漫长过程。开发者可以聚焦于业务逻辑和特色功能开发，基础的环境构建工作得以大幅提效，项目交付周期显著缩短。</p><h3>3. 业务配置：让“监、管、控、析”变得可定义</h3><p>这是平台最具魅力的部分——强大的后台配置能力，让非核心开发人员也能参与应用搭建。<br/><strong>对象管理</strong>：在庞大的三维场景中，如何快速找到一台故障的空调机组？平台提供对象管理面板和全局搜索功能，支持按分类、楼层、系统进行筛选，或直接搜索名称，并一键定位到三维场景中的具体位置，实现“所想即所见，所见即所得”。<br/><strong>智能告警</strong>：告警不再是简单的越限提示。开发者或运维人员可以在后台自定义复杂的告警规则。例如，可以设定“当会议室温度高于28℃且室内有人时”才触发告警，避免空房间的误报。告警触发后，会在三维场景中高亮显示，并支持一键定位、查看详情、关联视频、下发处置工单，形成闭环。<br/><strong>主题分析</strong>：平台支持创建业务主题看板。例如，可以创建一个“能效管理”主题，将园区总用电趋势图、各栋楼分项能耗排名、重点耗能设备列表、以及三维场景中的能耗热力图，全部聚合在一个页面。这相当于为不同业务部门（如工程部、安防部）定制了他们的专属“作战指挥室”。<br/><strong>交互控制</strong>：对于可控设备（如智能照明、门禁、空调），平台支持在三维场景中直接发送控制指令。点击三维场景中的一盏灯，弹出开关面板，操作后状态实时反馈回三维模型。这实现了真正的“三维组态”，让管理操作无比直观。<br/><strong>价值点</strong>：将大量需要编码实现的业务逻辑，转化为后台的可视化配置项。项目交付后，园区运营方可以根据业务变化自行调整规则和看板，赋予了平台长期生命力，也减少了开发者的后期维护负担。</p><h3>4. 模式创新：“免费试用”与“平滑演进”的友好路径</h3><p>对于开发者和最终用户，平台的商业模式也体现了灵活性。<br/><strong>低成本启动</strong>：提供免费公有云标准版，允许用户以极低的门槛进行概念验证（PoC）。开发者可以先用它搭建一个简化版Demo向客户演示，验证技术路线的可行性。<br/><strong>灵活部署</strong>：随着项目深入，可以平滑迁移至功能更强大的专业版，或根据客户对数据安全的要求，采用完全的私有化部署。这种“先尝后买”的模式，降低了双方的初始决策风险和投入成本。<br/><img width="640" height="360" referrerpolicy="no-referrer" src="/img/bVdmRb8" alt="" title="" loading="lazy"/></p><h2>三、 场景闭环：看一个智慧园区的一天如何被改变</h2><p>让我们构想一个应用了该平台的智慧园区日常：<br/>清晨，能耗巡检：运营主管打开“能源主题”看板，三维园区地图上覆盖着昨夜的电耗热力图，一眼锁定异常高耗区域。点击该建筑，自动剖切显示楼层，并关联出该楼层空调主机的运行曲线，初步判断是否为设备异常。<br/>上午，安全监控：周界入侵告警触发。指挥中心大屏上，三维园区地图自动定位到告警点，并弹出附近多个摄像头的实时画面。值班员一键调度最近的巡逻机器人前往查看，并在三维地图上实时跟踪机器人轨迹。<br/>下午，设施维修：某企业报修空调故障。客服人员在工单系统录入后，维修工程师在移动端收到任务。他打开App上的园区三维地图，工单位置已被精准标注。他查看该空调的历史运行数据后前往维修，维修后状态同步更新至三维模型。<br/>傍晚，领导视察：无需准备复杂的PPT，运营方直接在指挥中心的大屏上，通过三维数字孪生园区，动态展示人流车流、能耗对比、安防布控、绿色减碳成果，所有数据实时刷新，汇报生动而有力。</p><h2>结语：给开发者的价值主张</h2><p>“孪易 数字孪生 IOC 标准版”本质上是一个 “数字孪生应用生产力工具” 。它不试图取代开发者，而是旨在赋能开发者。<br/>对于从事园区、城市、工业等垂直领域数字化解决方案的开发者而言，它的价值在于：<br/><strong>提升交付效率</strong>：将重心从底层技术开发（如3D引擎、数据中间件）转移到上层业务价值实现，缩短项目周期。<br/><strong>降低技术风险</strong>：基于一个成熟、稳定的平台进行开发，避免了自研技术框架的不确定性和长周期投入。<br/><strong>增强客户粘性</strong>：交付给客户的不是一个“黑盒”系统，而是一个运营方可参与配置、持续演进的“活”平台，能带来更好的客户满意度和长期合作机会。<br/><strong>拓展能力边界</strong>：即使团队不擅长3D或大数据技术，也能承接和交付高质量的数字孪生项目，开拓新的市场赛道。<br/>智慧园区的运营升级，是一场涉及数据、空间与业务的深刻变革。拥有一个能巧妙融合这三者的工具，无疑能让开发者在这场变革中，更从容地扮演赋能者和共建者的角色。</p>]]></description></item><item>    <title><![CDATA[BOM 冻结线为何总被打破？硬件研发“返]]></title>    <link>https://segmentfault.com/a/1190000047446701</link>    <guid>https://segmentfault.com/a/1190000047446701</guid>    <pubDate>2025-12-03 17:05:28</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <blockquote><em>几乎所有做硬件研发管理和项目管理的人，都设过“BOM 冻结线”，也常常眼看着它一次次被新发现的问题击破：紧急改料、补充测试、推迟排产，导致材料报废和工程返工工时逐年增加。本文将结合ALM 应用生命周期管理与 IPD 集成产品开发体系，拆解 BOM 冻结管理失效的根因，并给出一套可落地的治理框架，帮助硬件团队真正跳出“返工陷阱”</em></blockquote><h2>硬件研发现场的 BOM 冻结尴尬</h2><p>如果你长期在硬件产品研发、电子制造业或硬件项目管理一线工作，下述场景大概率不陌生：</p><p>项目已经通过量产评审，会议纪要上写着“BOM 正式冻结”；供应链刚锁完物料采购，制造也依据 MBOM 排好了产能和生产节拍；你以为一切都在掌握中，结果下一刻，一封主题为《紧急：某型号器件需更换》的邮件打破了宁静——要么是关键器件停产，要么是可靠性测试刚测出边界问题，要么是经营压力要求本项目再压一轮物料成本。</p><p>接下来，工程变更管理（ECR/ECO）在系统里排成长龙：</p><ul><li>大量 ECO 触发 PCB 改版、工装治具调整、测试用例补测；</li><li>物料清单（BOM，Bill of Materials）在 EBOM、MBOM、ERP 三端反复校对；</li><li>项目经理在“交付进度、成本控制、质量风险”之间被迫做艰难平衡，只能选一个“看上去最不糟”的方案。</li></ul><p>从财务和交付维度看，这些临时应对的决策，叠加起来就是典型的硬件研发返工成本：物料报废、制造停线、额外验证资源、客户交付风险，以及被挤占掉的其它项目机会。</p><p>BOM 冻结线原本是用来做 BOM 冻结管理、控制工程变更、降低返工的“安全护栏”，现实中却常常沦为被反复跨越的“建议线”。不少企业在复盘时，习惯把责任归结为：</p><blockquote><em>“某次评审不严”“某个团队责任心不足”。</em></blockquote><p>但如果冷静问自己一句：“我们明知道这条 BOM 冻结线守不住，为什么还要设？”<br/>你会发现，这并不是某一两次评审失误，而是整个硬件研发体系、工程变更治理机制和组织治理方式出现了结构性问题。</p><h2>为什么 BOM 冻结线总被打破</h2><p>这一节，我会从 ALM（应用生命周期管理）、IPD（集成产品开发）以及配置管理的视角，拆解常见的 BOM 冻结失效原因，帮助你把“现象级问题”放回“体系级框架”里看。</p><h4>1. 冻结线被当成“行政规定”，而不是配置基线</h4><p>在成熟的 ALM / 配置管理体系中，BOM 冻结线本质上是一个“系统基线（Baseline）”：</p><ul><li>它绑定特定的需求版本、设计版本、验证结果与质量数据；</li><li>它是后续工程变更（ECR/ECO）评估的参照物；</li><li>它定义了“当前有效配置”的边界，是硬件产品配置管理中的关键节点。</li></ul><p>但在很多硬件研发管理现场，BOM 冻结线更多是一个“时间点上的宣告”：</p><blockquote><em>“从今天开始，BOM 不允许再改了。”</em></blockquote><p>缺少与需求配置、设计配置、测试验证的端到端关系，BOM 冻结管理就只能依赖个人自觉与行政推动。一旦遇到“商业压力 + 技术风险”的组合，“不开口子”的人反而会显得不合群。</p><p>一个简单的自查问题是：</p><blockquote><em>“现在让你在 10 分钟内拿出某个量产型号的当前有效 BOM 基线，含其对应需求版本、设计版本和测试结果，你做得到吗？”</em></blockquote><p>如果答案是否定的，那么在这个组织里，BOM 冻结线更多只是流程文件中的描述，而不是在 ALM / PLM 里被真实维护的系统基线。</p><h4>2. 前端不稳定：需求与架构模糊，后端 BOM 被动“还债”</h4><p>系统工程和 IPD 都强调：70% 以上的成本和风险在前期需求与架构决策中已经锁定。需求模糊、架构摇摆、接口频繁变化，最终都会通过后端的 BOM 变更和硬件返工来“还债”。</p><p>典型表现包括：</p><ul><li>需求管理停留在 PPT 和 Excel 表格，ALM 里没有完整的需求树和变更记录；</li><li>系统架构设计不到位，模块边界和接口不清晰，导致选型、布局和功耗分配在后期不断调整；</li><li>软件/硬件、结构/电子缺乏联合方案评审，硬件 BOM 只能在集成阶段被动跟随上游需求变化。</li></ul><p>在这些条件下，项目后期出现大量因需求变更、架构调整引发的 ECO 并不意外。只是这些“前端债务”，往往在项目报表里被模糊成“若干次紧急改料”，看起来是战术问题，本质却是前端工程（需求工程 + 系统架构工程）没有做好。</p><h4>3. 端到端数据链路断裂：ALM / PLM / ERP 各自为政</h4><p>在 IPD 研发体系和数字化研发管理平台的理想状态里，BOM 是一条端到端数字化链路中的“节点视图”：</p><ol><li>上游连接需求、系统分解、详细设计；</li><li>中间在 PLM 中形成 EBOM / MBOM；</li><li>下游通过 ERP 连接供应链、库存与制造执行。</li></ol><p>而在不少企业现场，实际情况是：</p><ol><li>研发在 ALM 或本地工具里维护工程 BOM（EBOM）；</li><li>工业化团队在 PLM 或独立系统中维护 MBOM，字段和命名各搞一套；</li><li>ERP 里还有另一种物料视图，用于采购与财务。</li></ol><p>结果就是：</p><ol><li>没有人真正相信“当前某版本 BOM 就是真相”；</li><li>临量产前必须通过人工对表、Excel 校验来确认版本；</li><li>每次对齐都伴随错误风险和大量隐形人力成本。</li></ol><p>当数据真相都不清楚时，任何“BOM 冻结管理”都是纸面承诺。问题总是在接近量产导入的时候集中爆发，“打破冻结线”就变成一个“不得不做”的选项。</p><h4>4. IPD 决策关口形同虚设：评审“过了”，问题却还在</h4><p>不少公司引入了 IPD 流程，DR1/DR2、PDR、CDR、MP 等评审节点一个不少，纸面流程也很完整。但实际操作中常常变成：</p><ul><li>评审主要看 PPT，不看 ALM/PLM 等系统里的配置基线和数据视图；</li><li>BOM 成熟度没有可量化标准，评审结论停留在“基本可行”“整体可控”；</li><li>对“BOM 冻结后变更”的约束和复盘机制缺失，没有形成组织级记忆。</li></ul><p>在这种状态下，IPD 关口很难对后续 BOM 稳定性真正负责。BOM 冻结线被定义在流程图里，却没被嵌入 IPD 决策逻辑和工程变更管理机制里。</p><h2>如何在硬件研发中构建“不轻易被打破的冻结线”</h2><p>要让 BOM 冻结线真正发挥作用，不能只靠“严禁改动”的口号，而需要一整套结合 ALM / IPD 的方法论与治理机制。下面是一个实践框架，可供中高层研发管理者、PMO、项目经理和系统工程师共用。</p><h4>1. 从“一刀切冻结”到“分层、分阶段的 BOM 冻结策略”</h4><p>第一步是重新定义“冻结”本身，而不是简单地设一个日期：</p><ul><li>按 BOM 视图 区分：工程 BOM（EBOM）、制造 BOM（MBOM）、服务 BOM（SBOM）；</li><li>按 物料重要性 分层：关键器件（核心芯片、电源、关键连接器）、风险器件（停产风险、超长交期）、普通物料；</li><li>按 时间轴 设定多个冻结点，而不是唯一“终极时刻”。</li></ul><p>一个常用的实践是分三层冻结：</p><p><strong>① 架构级冻结（Architecture Freeze）</strong></p><ul><li>面向系统工程和 IPD 的概念设计阶段；</li><li>冻结技术路线、产品平台、关键接口与性能/功耗预算，明确主芯片大类和关键方案；</li><li>目标是减少因架构调整引发的大规模 BOM 变更。</li></ul><p><strong>② 关键器件冻结（Key Component Freeze）</strong></p><ul><li>在详细设计和样机试制之前完成；</li><li>冻结核心芯片、电源方案、关键连接器等成本和风险权重最高的物料；</li><li>后续任何针对这些物料的变更都必须经过 CCB（变更控制委员会）审核。</li></ul><p><strong>③ 全 BOM 冻结（Full BOM Freeze）</strong></p><ul><li>在量产导入前，与 MP/PPAP 等评审节点耦合；</li><li>要求 EBOM、MBOM 与 ERP 物料视图一致，并通过必要的验证和试产数据校验。</li></ul><p>通过分层、分阶段的 BOM 冻结策略，可以把“绝对不能轻易改”的部分尽早固化，把仍需优化的部分显性化，避免在项目尾声做大型手术式改动。</p><h4>2. 用系统工程方法，把“变更欲望”前移到可控阶段</h4><p>要减少后期打破 BOM 冻结线的冲动，就必须把试错和优化前移到需求工程和系统方案阶段。系统工程方法提供了三个抓手：</p><p><strong>① 用 V 模型构建需求–设计–验证的一致性链条</strong></p><p>在 ALM 平台中建立需求分解结构（系统需求 → 子系统需求 → 设计规格）；<br/>对关键需求建立双向追踪：从需求到设计文档、到 BOM 物料、到测试用例；<br/>在架构评审 / PDR / CDR 时，不只问“功能看上去实现了没有”，而是查看“需求覆盖率和验证闭环”。</p><p><img width="723" height="488" referrerpolicy="no-referrer" src="/img/bVdnfdk" alt="V 模型示意图" title="V 模型示意图"/></p><p><strong>② 强化概念验证与仿真，减少“实物试错式返工”</strong></p><ul><li>对高风险电源、高速信号链路等提前做仿真与小板验证（EVB），在 BOM 冻结前消除一批显而易见的风险；</li><li>对结构、散热等问题用仿真和样机联合验证，缩短试错周期；</li><li>把这些活动纳入 IPD 任务书和项目计划，而不是“有时间再做”。</li></ul><p><strong>③ 设立明确的“BOM 冻结前变更窗口”</strong></p><ul><li>在项目计划中清晰标出在哪几个迭代周期允许对 BOM 做大幅调整；</li><li>窗口期内的变更流程相对简化，但必须保留原因和验证记录；</li><li>超出窗口，则通过 ECR/ECO 和 CCB 来控制，形成变更可见、成本可见的治理机制。</li></ul><p>当变更欲望被前移到可控窗口，并在 ALM/PLM 中形成清晰的信息链条时，后期“拍脑袋改料”的空间自然会变小。</p><h4>3. 建立 ECR / ECO 分级工程变更治理机制</h4><p>很多公司有 ECR/ECO 表单，但缺少工程变更治理逻辑，导致 BOM 冻结管理无法落地。一个典型的治理思路是：</p><p><strong>① 明确 ECR（变更请求）与 ECO（变更实施）的分工</strong></p><ul><li>ECR：讨论“是否要改”，关注问题、动机、影响和可选方案；</li><li>ECO：在决策后落实“具体怎么改”，包括 BOM、图纸、工艺、测试、文档等更新；</li><li>禁止“跳过 ECR 直接发 ECO”的做法，避免绕过系统性的影响评估。</li></ul><p><strong>② 按影响等级分级管理</strong></p><ul><li>A 级变更：影响安全、法规合规、重大质量风险，冻结后仍允许，但必须由跨部门 CCB 和项目高层批准；</li><li>B 级变更：影响成本、关键性能、供应风险，由项目 CCB 审批；</li><li>C 级变更：影响有限的小改动，可由模块负责人审批，但必须在 PLM / ALM 中留痕。</li></ul><p><strong>③ 在 ECR 中强制评估五个维度</strong></p><ul><li>对客户价值和市场竞争力的影响；</li><li>对项目进度和资源的影响；</li><li>对成本（材料、制造、质量保障）的影响；</li><li>对安全、法规、长期可靠性的影响；</li><li>替代方案（维持现状的后果是什么）。</li></ul><p>冻结线之后不是“不许改”，而是“必须通过可审计、可度量的工程变更流程来决策是否值得改”。</p><h4>4. 用 ALM / PLM 打通需求–设计–BOM–制造的数字链路</h4><p>想让 BOM 冻结线有现实意义，需要一条可信的数字化主线，而不是三套孤立系统。实践中可以按“最小可行 + 逐步演进”来设计：</p><p><strong>① 以 ALM 为需求与设计配置的源头系统</strong></p><p>所有正式需求与变更需求在 ALM 中维护，形成需求基线；<br/>需求项与设计文档、BOM 条目、测试用例建立追踪关系；<br/>在关键评审节点冻结需求/设计基线，与后续 BOM 冻结相呼应。</p><p><strong>② 以 PLM 为 EBOM/MBOM 与配置管理中枢</strong></p><p>在 PLM 中维护 EBOM，关联版本和变更记录；<br/>工业化团队在 PLM 中从 EBOM 派生 MBOM，并关联工艺路线和工装治具；<br/>通过差异报表或可视化看板来监控 EBOM 与 MBOM 的偏差。</p><p><strong>③ 与 ERP / 供应链系统形成闭环</strong></p><p>在 BOM 冻结前确保 ERP 中的物料编码、供应商信息、价格和交期等同步；<br/>冻结后任何 ECO 自动评估库存、在途订单和产能计划的影响。</p><p>这条数字链路的目的不是“堆工具”，而是让需求–设计–BOM–制造这条系统工程逻辑，真的在数据里可见可追踪。</p><h4>5. 把“BOM 冻结纪律”转化为可运营的指标体系</h4><p>靠口头强调很难改变行为，建议 PMO 或 R&amp;D Ops 建立轻量指标，把 BOM 冻结管理运营起来：</p><ul><li>冻结后 ECO 数量与分布（按级别、按项目）；</li><li>因 BOM 变更导致的返工成本：报废物料、返工工时、额外测试与验证资源；</li><li>BOM 冻结及时率：计划冻结日期 vs 实际冻结日期；</li><li>变更决策周期：从 ECR 提出到 ECO 关闭的平均时间。</li></ul><p>这些指标不必一上来就用于“硬考核”，更有价值的场景是：</p><ul><li>项目例会和季度评审的固定看板；</li><li>横向对比不同产品线 / 平台的变更行为模式；</li><li>为管理层的资源投入（优化前端架构、升级平台、重构模块）提供数据支持。</li></ul><h4>6. 在 IPD 框架下重构关键评审节点，让冻结线“嵌入流程”</h4><p>要让 BOM 冻结线具备权威性，需要和 IPD 关键评审深度耦合：</p><p><strong>① 在 PDR 上确认架构级冻结</strong></p><ul><li>审查关键技术路线、接口和资源预算是否清晰；</li><li>将架构级决策纳入配置基线，后续重大架构调整提升到平台级决策。</li></ul><p><strong>② 在 CDR 上确认关键器件冻结</strong></p><ul><li>审查关键器件验证报告、供应风险评估和备选方案；</li><li>将关键器件清单纳入项目风险清单和后续 ECO 约束。</li></ul><p><strong>③ 在 MP / 量产评审上确认全 BOM 冻结</strong></p><ul><li>审查 EBOM/MBOM/ERP 的一致性和试产数据；</li><li>对冻结后 ECO 做说明，为组织沉淀经验。</li></ul><p>评审不只是“放行”，更要成为 BOM 冻结管理的“质量门”和组织知识的沉淀节点。</p><h4>7. 从组织协同与激励机制上拆掉“返工陷阱”</h4><p>最后，如果组织协同和激励方向错误，再好的工程变更流程也会被绕过。几个经常被忽视的点：</p><p><strong>① 让供应链、制造、质量真正前移参与</strong></p><ul><li>在 IPD 项目团队中，让供应链、制造工程、质量成为前期方案阶段的正式角色，而非“后期支持”；</li><li>对高风险器件，要求供应链提前给出多源策略和生命周期分析；</li><li>制造和质量提前对 BOM 提出可制造性和长期可靠性要求。</li></ul><p><strong>② 淡化“英雄改料文化”，强化“前期稳态文化”</strong></p><ul><li>少讲“最后一刻改料救回项目”的英雄故事，多在复盘中讨论“为什么问题没在前面暴露”；</li><li>把“冻结后 ECO 数量、返工成本、按计划冻结情况”纳入项目复盘指标。</li></ul><p><strong>③ 用清晰的 RACI 避免“谁都能改一点”</strong></p><ul><li>对 BOM 变更设定 RACI（负责 / 参与 / 咨询 / 知情），明确提出人、评估人、决策人和验证人；</li><li>避免“本地优化、全局返工”的局面，让每一次打破冻结线都在数据上留下可追踪的痕迹。</li></ul><h2>给中高层管理者和 PMO 的几条现实建议</h2><p>对于已经饱受 BOM 冻结线反复被打破困扰的硬件团队，不必指望“一次性大改造”。更现实的路线是渐进式演进：</p><p><strong>① 选一个典型产品线试点</strong></p><ul><li>选择物料复杂度高、业务重要、变更频繁的产品线；</li><li>在试点里跑通：分层冻结策略 + ECR/ECO 分级治理 + 最小可行数字链路。</li></ul><p><strong>② 先建立“数据真相”再谈全面集成</strong></p><ul><li>梳理当前 EBOM/MBOM/ERP 的关键字段和对齐方式；</li><li>用简单脚本或定期对账方式建立“当前有效 BOM 视图”，为后续深度集成打基础。</li></ul><p><strong>③ 让 PMO 把冻结纪律纳入项目运营例会</strong></p><ul><li>固定查看冻结后 ECO 和返工成本数据；</li><li>通过轻量复盘沉淀经验，形成可复用的治理模式。</li></ul><p><strong>④ 中高层用行为释放清晰信号</strong></p><ul><li>在商业压力和技术风险冲突时，公开讨论“不改的代价”和“改的代价”；</li><li>对频繁突破冻结线且论证不足的项目，要求严肃复盘，而非“一笑而过”；</li><li>对前期稳住架构、减少后期 ECO 的团队给予正向激励。</li></ul><h2>从“救火式改料”走向“体系化决策”</h2><p>BOM 冻结线被反复打破，并不是单一评审的偶然失误，而是硬件研发管理中需求不稳定、架构前移不足、ALM/PLM/ERP 数据割裂、IPD 评审流于形式以及组织激励失衡等系统问题在 BOM 上的集中体现。</p><p>要跳出硬件研发的“返工陷阱”，需要：</p><ul><li>把 BOM 冻结线视为系统基线和配置管理节点，而不是行政禁令；</li><li>用 系统工程 + ALM 应用生命周期管理 + IPD 流程，构建需求–设计–BOM–制造的数字化链路；</li><li>通过分层冻结、ECR/ECO 分级治理、可度量指标，把“冻结纪律”转化为可运营的管理能力；</li><li>通过组织协同与激励调整，让团队从“救火式改料”转向“前瞻性、数据支撑的工程变更决策”。</li></ul><p>当一个组织可以坦然说出：</p><blockquote><em>“我们不怕变更，但每一次打破冻结线都有明确理由、决策记录和成本认账。”</em></blockquote><p>BOM 冻结线才真正从 PPT 走进硬件研发体系的肌理，也才算真正走出了硬件研发“返工陷阱”。</p>]]></description></item><item>    <title><![CDATA[智能研发管理：制造业如何实现从“单打独斗]]></title>    <link>https://segmentfault.com/a/1190000047446748</link>    <guid>https://segmentfault.com/a/1190000047446748</guid>    <pubDate>2025-12-03 17:04:56</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>最近和制造业的朋友聊天，大家几乎都在谈数字化转型，聊到研发管理，话题就更热烈了。市场节奏越来越快，技术也在不断迭代，传统研发管理方式显然跟不上了。尤其是汽车、装备制造这些离散制造行业，跨部门协作复杂，信息孤岛严重，研发过程中的痛点太多了。设计数据分散，版本混乱，文档管理滞后，流程审批依赖人工……这些看似独立的问题，其实都是一根绳子上绑着的蚂蚱。<br/>举个例子，很多企业的设计文档和图纸数据分散在不同的系统里，各部门拿到的信息版本不一致，沟通成本居高不下。再加上三维模型的协作效率差，非设计人员很难快速查看和使用这些数据，严重影响了跨部门协同的效率。这时候，研发管理平台的重要性就凸显出来了。<br/>广域铭岛的Geega捷做设计研发协同平台，就是在这种背景下出现的。它不是简单地把PDM、PLM这些工具堆砌在一起，而是真正打通了研发全链条。从需求收集、设计评审到BOM管理、工艺协同，整个流程都整合在一个平台上，信息共享更高效，版本追溯更清晰。系统通过自动触发审批流程，让审批人员在移动端就能处理，再也不用在各个系统之间来回切换，效率直接提升了40%。<br/>说到这个平台，它最吸引人的地方在于“协同”二字。想象一下，销售、采购、生产、质量等部门的人都在一个平台上工作，实时共享数据。比如，Fview模块支持60多种CAD格式，一线人员只需要扫码，就能查看三维模型并在线评审，不用再为格式转换和软件兼容发愁。这在实际应用中效果特别明显，某科技企业引入后，模型查看效率提升60%，跨部门协作周期缩短了50%。<br/>当然，研发管理不仅仅是数据协同。质量管控也是一个重要环节。FMEA模块的加入，让研发团队能够更早地发现问题、预防风险。基于历史问题库，系统可以自动推荐整改措施，把被动应对变成了主动预防。某制造企业在应用后，FMEA的编制效率提升了20%，质量管理也实现了从“事后补救”到“源头预防”的转变。<br/>不过，研发管理的数字化转型还远不止这些。更关键的是，系统要能够沉淀数据资产，形成企业的知识库。比如，标准BOM数据的一致性和准确性，直接影响到后续的生产、采购和交付。统一的数据源头，不仅减少了出错率，还提高了资源利用率。某家电企业在应用后，零部件复用率提升35%，BOM数据准确率也达到了80%。<br/>说到竞争对手，其实市场上有不少研发管理平台，比如PTC、达索系统这些老牌厂商。它们的功能也很强大，但在灵活性和适用性上，广域铭岛的平台确实更贴近国内制造业的需求。尤其是在中小企业的数字化转型中，它的弹性设计能力让很多企业受益。<br/>当然，转型过程中也会遇到一些挑战。比如，系统集成、数据迁移、人员培训这些环节，都需要细致规划。但从长远来看，这些投入都是值得的。因为研发管理的智能化，不仅提升了效率，还让企业能够更快地响应市场变化。<br/>总的来说，智能研发管理不是一句口号，而是制造业数字化转型的核心需求。它要求企业打破传统的管理方式，用数据驱动创新，用协同提升效率。</p>]]></description></item><item>    <title><![CDATA[2025 SECon × AgentX ]]></title>    <link>https://segmentfault.com/a/1190000047446795</link>    <guid>https://segmentfault.com/a/1190000047446795</guid>    <pubDate>2025-12-03 17:03:56</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>作者：盈楹</p><p>近日，2025 SECon × AgentX大会——AI 原生应用架构专场圆满落幕，本次专场阿里云联合信通院共同出品，现场吸引了 80+ 名技术从业者深度参与。</p><p>活动聚焦 AI 时代软件架构的核心命题，深度分享了 AI 原生应用架构趋势与实践、AgentScope 开发框架、AI 开放平台、大模型可观测 &amp; AIOps 等热门技术议题，探讨从基础设施到应用层的协同演进策略与工程实践。</p><p>关注「阿里云云原生」公众号，后台回复：1125</p><p>免费获得活动讲师 PPT 合辑</p><h2>精彩回顾</h2><h3>议题一：AI 原生应用架构探索与实践丨肖京(亦盏)   阿里云智能云原生高级技术专家</h3><p>当前大模型已迈过技术拐点，Agentic AI 进入规模化落地阶段。AI 原生应用以模型为基础、Agent 为驱动、数据为中心，推动系统从“机器执行”向“机器思考+执行”演进。框架选型需平衡 Agentic 自主性与业务确定性，Agent 面临开发效率、业务效果，以及稳定、性能、成本、安全的挑战。实践上建议构建以数据为核心的 Agent 平台，结合 MCP/A2A 标准与 Serverless 架构，通过 AI 网关、消息队列、可观测等提升安全性、稳定性与可维护性，实现智能化人机协作新范式。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446797" alt="image" title="image"/></p><h3>议题二：开发更可控，部署更便捷：AgentScope 迈入 1.0 时代丨邝炜瑞  阿里巴巴集团通义实验室 高级算法工程师</h3><p>深度分享了阿里通义实验室开源的 AgentScope 智能体开发框架 1.0 版本。核心内容包括：基于 ReAct 范式的多智能体系统支持，提供结构化输出、工具调用与长期记忆等能力；采用三层架构——开发框架层、可视化调试平台与安全运行时环境，结合工具沙箱与元工具机制，全面提升系统的可控性、可观测性与部署安全性。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446798" alt="image" title="image" loading="lazy"/></p><h3>议题三：AI 网关：AI 原生架构下的智能流量中枢丨 赵炳堃(秉钧)   阿里云智能云原生高级开发工程师</h3><p>聚焦 AI 网关在 AI 原生架构中的核心作用，重点介绍 Higress AI 网关的关键能力：支持多模型适配、协议转换与语义缓存，提供 Token 限流、Fallback 机制保障高可用；通过 API-Key 管理、PII 脱敏、WASM 沙箱等实现安全可控；并借助 MCPServer 统一代理提升集成效率。HiMarket 平台则助力企业构建私有 Agent 市场，推动 AI 能力的安全规模化落地。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446799" alt="image" title="image" loading="lazy"/></p><h3>议题四：从可观测到 RL：打造生产级可靠的长周期 Agent丨马云雷  阿里云智能云原生技术专家</h3><p>聚焦 AI-Native 应用中长周期 Agent 的可靠性建设，提出以可观测性为基础，通过 OpenTelemetry、Prometheus 等工具实现全栈监控，做到“可见、可调、可审”。引入 LLM Judger 作为自动化评估裁判，结合数据工程与模型蒸馏，构建快慢反馈闭环。最终形成从问题发现、根因分析到自我强化的进化系统，推动 Agent 向高可靠、自演进的生产级应用发展。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446800" alt="image" title="image" loading="lazy"/></p><h2>现场精彩瞬间</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446801" alt="image" title="image" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446802" alt="image" title="image" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446803" alt="image" title="image" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[【运维自动化-标准运维】快捷键使用技巧（]]></title>    <link>https://segmentfault.com/a/1190000047446817</link>    <guid>https://segmentfault.com/a/1190000047446817</guid>    <pubDate>2025-12-03 17:03:05</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>快速框选画布流程节点</h2><h3>1.在流程画布左上方有对应框选画布的按钮</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446819" alt="在这里插入图片描述" title="在这里插入图片描述"/></p><h3>2.点击按钮—框选节点</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446820" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h3>3.框选成功后–对应节点有虚线包围</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446821" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h2>变量透视</h2><p>该功能可以展示对应节点中引用了的输入变量以及该节点的输出变量</p><h3>1.在流程画布做左上方有对应变量透视的按钮</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446822" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h3>2.点击按钮–展示节点变量按钮</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446823" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h3>3.将鼠标移动到对应节点上时，即展示对应节点的变量使用情况</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446824" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><p>说明：适合产品版本 V6.1/V6.2/V7.0/V7.1</p>]]></description></item><item>    <title><![CDATA[如何打造AI时代的数据基石 | Data]]></title>    <link>https://segmentfault.com/a/1190000047446840</link>    <guid>https://segmentfault.com/a/1190000047446840</guid>    <pubDate>2025-12-03 17:02:20</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>Data + AI 已经成为数据从业人员必须关注的技能。在基于 Databend Cloud 平台上可以大大简化数据人员在数据基础工作方面的投入，让数据人员可以花更多的精力去研究 Data + AI 的实践。在此背景下，11月29日，Databend Meetup·上海站线下活动"如何打造 AI 时代的数据基石"，汇集了国内数据库领域多位一线专家：Databend 创始人吴炳锡、沉浸式翻技术专家陈琦，沈超、资源数据平台架构师邵锋、TiDB 解决方案架构师 刘源、空中云汇架构师赵飞祥以及来自各行各业的技术负责人，数据部门负责人。参会嘉宾围绕"如何打造 AI 时代的数据基石"的主题，共同探讨了大模型时代数据库和数据平台的创新演进与实战应用。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446842" alt="图片" title="图片"/></p><p>以下内容就将为您带来这些话题背后的深度思考：<br/>基于 Databend 无编程实 Data Pipeline 及数据分析<br/>Databend Labs 联合创始人吴炳锡，系统地介绍了 Databend 作为一款云原生数据仓库，如何以其独特架构和技术特性，极大地简化和革新传统大数据 Data Pipeline 的构建与数据分析流程，并展示了其与 AI 融合的强大潜力。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446843" alt="图片" title="图片" loading="lazy"/></p><p>Databend 的清晰定位：解决传统大数据之痛<br/>分享开宗明义，指出了 Databend 的核心定位：简单易用、高性能、低成本。其目标是成为一款云原生湖仓一体化产品，旨在：</p><p>降低云上大数据成本：利用对象存储实现极致的存算分离和低成本存储。<br/>简化数据架构：坚持" SQL 为王"，让复杂的湖仓开发变得像使用传统数据库一样简单。<br/>统一数据枢纽：支持构建企业级统一数据仓库，并提供跨多云、跨 IDC 的高可用体验。</p><p>核心革新：重构 Data Pipeline 的开发模式<br/>分享通过对比，深刻剖析了传统大数据架构（依赖 Kafka, Flink, Spark, Trino 等繁多组件）的痛点：技术栈复杂、技术要求高、落地慢、运维成本高昂。<br/>针对这些痛点，Databend 提出了一套以 SQL 为中心 的"无编程" Data Pipeline 解决方案，其核心构件包括：</p><p>数据秒级摄入 (COPY INTO + External Stage)：通过监听对象存储事件，实现海量数据的快速加载与可见。<br/>内置流计算 (Stream)：提供表级增量变更捕获能力，无需额外组件即可实现高效的实时 ETL，性能提升可达 10 倍。<br/>自动化任务调度 (Scheduled Task)：通过 Serverless Task 实现完整的数据处理工作流编排，让一个懂 SQL 的人就能轻松完成复杂的数据治理。<br/>强大的外部函数 (UDF)：支持用 Python 等语言轻松扩展功能，实现与外部系统（如更新 Redis）或 AI 服务的无缝集成。</p><p>与 AI 的深度融合：从数据平台到智能基座<br/>分享重点展示了 Databend 在 AI 时代的前瞻性，其与 AI 的融合体现在两个层面：</p><p>原生 AI 能力：内置向量计算和 AI 函数（如cosine_distance），为 AI 应用提供开箱即用的支持。<br/>可扩展的 AI 集成 (External UDF)：通过 UDF 可以方便地调用 Embedding 模型、情感分析、文本相似度等外部 AI 服务，将 Databend 升级为一个支持智能化数据分析与应用的" AI 原生"平台。</p><p>卓越效益与广泛验证<br/>分享通过具体数据证明了 Databend 的卓越效益：</p><p>成本大幅降低：在替换 Trino/Presto、Elasticsearch、数据归档等场景中，成本降低 75% 到 95%。<br/>极致的可扩展性：支持单表 2.6 万亿行、1PB+ 的超大规模数据处理。<br/>广泛的行业应用：已成功服务于中信银行、微盟、苹果中国等知名企业，应用于主数据平台、日志分析、数据归档等多种场景。</p><p>总结<br/>Databend 通过其云原生、一体化的架构，将复杂的大数据技术栈简化为以 SQL 为核心的开发体验，从根本上降低了数据开发的门槛、成本和运维负担。 它不仅是一个高性能的数据仓库，更是一个内置了流处理、任务调度和强大扩展能力的数据平台操作系统。在 AI 时代，其原生及可扩展的 AI 能力进一步使其成为企业构建智能化应用的理想数据基石，完美契合了当下企业追求降本增效和快速创新的核心诉求。<br/>构建海量记忆：基于 Databend 的 2C Agent 平台|沉浸式翻译<br/>沉浸式翻译团队技术专家陈琦在 构建海量记忆：基于 Databend 的 2C Agent 平台|沉浸式翻译实践分享，核心阐述了他们如何利用 Databend 构建一个面向海量用户的、具备"长期记忆"能力的 AI Agent 平台。<br/>沉浸式翻译在比较早期已经接入 Databend , 公司内部在无运维的情况下，支撑了千万级用户，月活百万级用户。Databend 目前不但承担沉浸式翻译的平台分析数据，也承担了部分业务类数据。 目前团队正在 Databend 上构建海量记忆体的 2C Agent 平台。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446844" alt="图片" title="图片" loading="lazy"/></p><p>核心挑战：<br/>传统方案的痛点：</p><p>组件割裂：维护向量库、关系型数据库、缓存等多套系统，开发和运维复杂。<br/>缺乏生命周期管理：向量库只增不减，导致噪音增加、性能下降、成本飙升。</p><p>为什么选择 Databend？</p><p>All-in-One：统一处理向量、结构化和半结构化（JSON）数据，简化架构。<br/>Serverless：零运维、按需付费，完美契合小团队"小步快跑"的模式。<br/>可编程性：通过 SQL、UDF 和 Task 实现复杂的数据处理和生命周期管理。大大简化开发投入</p><p>核心架构与创新（MemOS）：</p><p>MemNodes 表：作为记忆实体，利用计算列和聚簇索引优化混合查询（向量+条件过滤）性能。<br/>MemEdges 表：构建记忆图谱，用 SQL 存储关系，解决纯向量检索无法处理的逻辑推理问题。<br/>混合检索算法：结合 SQL 过滤、向量搜索和图关联，实现精准且上下文丰富的记忆召回。<br/>自动化生命周期：通过 Serverless Task 定期对记忆进行摘要融合和归档，实现"会遗忘的智能系统"。</p><p>价值总结：<br/>该实践成功地将 Databend 作为统一数据基石，以极低的运维成本和优雅的技术方案，实现了从"翻译工具"到懂用户的"语言伴侣"的演进，为 2C AI 提供了易用，低成本，高性能的平台。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446845" alt="图片" title="图片" loading="lazy"/></p><p>Data + AI - 数据平台的应用和实践<br/>第三个分享中邵锋老师带着一线经验给我们分享数据平台的建设和 Data+AI 实践。属于非常硬核的分享，因为保密问题就不再公开邵锋老师的分享。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446846" alt="图片" title="图片" loading="lazy"/></p><p>AI 时代的数据基石：趋势、挑战与 TiDB 实践<br/>TiDB 解决方案架构师刘源老师，从行业更宏观的视角探讨了 AI 时代的数据挑战，并阐述了 TiDB 作为"数据基石"的解决方案和案例。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446847" alt="图片" title="图片" loading="lazy"/></p><p>核心洞察：</p><p>AI 发展趋势：大模型进入平台期，下一代突破指向"世界模型"。当前 AI 面临幻觉问题（源于概率生成的有损压缩）、算力消耗和伦理安全等挑战。<br/>AI 应用现状：情感陪伴、内容生成等"幻觉友好型"应用火热，但金融、制造、医疗等严肃 ToB 场景落地艰难，面临数据治理缺失、场景碎片化等挑战。</p><p>AI 时代对数据库的新要求：</p><p>多模态融合：同时处理关系表、向量、全文、图谱等数据，"多库合一"。<br/>实时与高扩展：弹性支撑 Agent 的推理、记忆和 Multi-Agent 协作。<br/>支持 AI 原生体验：成为 Agent 的"集体记忆中枢"，能主动交互。</p><p>TiDB 的解决方案：</p><p>核心特性：金融级高可用、天生的弹性扩展、HTAP 一体化架构、正在演进的多模态数据融合能力。</p><p>AI 原生探索：</p><p>增强数据访问层：通过 RAG、GraphRAG 等技术，将 TiDB 打造成企业知识核心，降低大模型幻觉。<br/>构建 Data Agent 能力：研发 AutoFlow，让用户用自然语言直接进行混合查询和数据分析。<br/>面向 Multi-Agent 未来：扮演"共同记忆体"，支持数据版本化、分支管理等。</p><p>案例与价值：</p><p>为多家国内 TOP AI 及 Agent 厂商提供了可弹性扩展的数据底座，支撑了业务从零到亿级估值的狂飙。<br/>与 Databend 在归档场景合作，利用 TiDB 处理实时事务，Databend 处理低成本历史分析，实现降本增效。<br/>提出企业级 AI 平台整体架构，强调从"数据拼接"到"原生融合"的范式变革。</p><p>圆桌讨论环节<br/>在该环节邀请又邀请了空中云汇数据架构师赵飞祥，沉浸式翻译团队数据分析师沈超，TiDB 解决方案架构师刘源， 数据平台架构师邵峰 四位嘉宾一共交流了 AI 时代个人职业方面的感受， AI 对工作方面带来的变化， AI 时代需要什么样的人。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446848" alt="图片" title="图片" loading="lazy"/></p><p>总结大家的观点：</p><p>AI 时代，让人每个人的能力更强了，能做的事更多了。 原来复杂的数据分析工作，原来可能需要1周，现在可能就是 1-2 天，或是更快。<br/>在 AI 时代不要给自我设限，上手一门技能非常的快。<br/>在 AI 时代更需要有 Owner 精神，端到端的解决问题的思路，需要懂得把工作拆分及推动下去。<br/>在 AI 时代同样需要有专业和权威的精神，能经住团队的挑战，能让老板放心把工作交给你。</p><p>圆桌讨论将视野拉回至"人"本身，为我们揭示了在 AI 时代更宝贵的特质。 当技术门槛被AI工具不断降低，"Owner 精神"、"端到端解决问题" 的能力以及 "专业权威" 的深度，构成了技术人新的护城河。AI 放大了个体的能力边界，但判断力、责任心和推动力，依然是不可替代的价值所在。<br/>总结而言，本次 Meetup 清晰地传递出一个信号： 打造 AI 时代的数据基石，已从一道可选题变为一道必答题。其答案不在于堆砌最前沿的独立组件，而在于选择一个能够简化架构、统一数据、智能赋能，并能伴随组织共同成长的一体化平台。我们欣慰地看到，以 Databend、TiDB 为代表的国内数据库力量，正以扎实的技术创新和丰富的场景实践，为各行各业提供着这道"必答题"的优秀解方。数据的浪潮奔涌向前，AI 的篇章刚刚开启。感谢所有嘉宾的倾情分享与参会者的热情投入，让我们共同期待，在这块坚实、智能的数据基石之上，生长出下一个时代的伟大应用。<br/>关于 Databend<br/>Databend 是一款 100% Rust 构建、面向对象存储设计的新一代开源云原生数据仓库，统一支持 BI 分析、AI 向量、全文检索及地理空间分析等多模态能力。期待您的关注，一起打造新一代开源 AI + Data Cloud。<br/>👨‍💻‍ Databend Cloud：databend.cn<br/>📖 Databend 文档：docs.databend.cn<br/>💻 Wechat：Databend<br/>✨ GitHub：github.com/databendlab...</p>]]></description></item><item>    <title><![CDATA[Linux Bash Shell 脚本编]]></title>    <link>https://segmentfault.com/a/1190000047446872</link>    <guid>https://segmentfault.com/a/1190000047446872</guid>    <pubDate>2025-12-03 17:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>Linux Bash Shell编程： 👇🏻ke程：shanxueit点com/从命令行到脚本开发的全面指南<br/>本文将系统性地介绍Linux Bash Shell编程的完整知识体系，从基础概念到高级应用，帮助读者实现从命令行操作到脚本开发的技能跃迁。</p><p>一、Shell编程基础概念<br/>Shell是用户与Linux内核之间的桥梁，它提供了一个命令行界面，用户输入的命令由Shell解析后传递给内核执行，并将结果返回给用户。常见的Shell有Bash(Bourne-Again Shell)、Zsh(Z Shell)、Ksh(Korn Shell)等，其中Bash是Linux系统中默认且应用最广泛的Shell。</p><p>Shell脚本本质上是一个包含一系列命令的文本文件，它通过Shell解释器执行。与JavaScript、PHP等编程语言类似，Shell编程只需要一个文本编辑器和脚本解释器即可开始。Bash作为Bourne Shell的增强版，因其易用性和免费特性成为日常管理和自动化任务的首选工具。</p><p>Shell脚本的基础结构包括：</p><p>Shebang行(如#!/bin/bash)指定解释器路径<br/>注释说明(以#开头)<br/>可执行命令序列<br/>流程控制结构<br/>函数定义<br/>二、Shell脚本核心语法要素</p><ol><li>变量与数据类型<br/>Shell变量用于存储数据，通过=符号赋值(注意等号两边不能有空格)。变量名规则：</li></ol><p>只能包含字母、数字和下划线<br/>不能以数字开头<br/>区分大小写<br/>不能使用bash关键字(可用help命令查看保留关键字)<br/>变量引用使用<br/>符号，如<br/>符号，如var或${var}。Shell支持字符串、整数和数组等数据类型，其中数组可以存储多个值，方便批量操作。</p><ol start="2"><li>流程控制结构<br/>Bash提供了完整的流程控制语句：</li></ol><p>条件判断：if/elif/else/fi，case/esac<br/>循环结构：for/while/until/do/done<br/>循环控制：break/continue<br/>条件测试可以使用test命令或[ ]、[[ ]]结构，支持文件测试、字符串比较和数值比较等多种条件判断。</p><ol start="3"><li>输入输出与重定向<br/>Shell脚本通过以下机制处理输入输出：</li></ol><p>标准输入(stdin)、标准输出(stdout)和标准错误(stderr)<br/>重定向操作符：&gt;、&gt;&gt;、&lt;、&lt;&lt;<br/>管道(|)连接多个命令<br/>命令替换$(command)或command<br/>三、Shell编程进阶技巧</p><ol><li>函数与模块化<br/>函数是Shell脚本中实现代码复用的重要手段，定义语法为：</li></ol><p>PlainText<br/><br/>function_name() {</p><pre><code>commands
[return value]</code></pre><p>}<br/>函数支持参数传递(<br/>1<br/>,<br/>1,2,...$n)和返回值(通过return或echo输出)。</p><ol start="2"><li>错误处理与调试<br/>健壮的脚本需要完善的错误处理机制：</li></ol><p>使用set -e使脚本在命令失败时立即退出<br/>使用trap捕获信号并执行清理操作<br/>通过$?获取上一条命令的退出状态<br/>使用|| true忽略特定命令的错误<br/>调试模式(set -x)显示执行的每条命令</p><ol start="3"><li>文本处理三剑客<br/>Shell脚本常与以下文本处理工具配合使用：</li></ol><p>grep：基于模式搜索文本<br/>sed：流编辑器，执行文本替换等操作<br/>awk：强大的文本分析和报告工具<br/>这些工具支持正则表达式，能够高效处理日志分析、数据提取等任务。</p><p>四、Shell脚本实战应用场景</p><ol><li>系统管理自动化<br/>通过Shell脚本可以实现：</li></ol><p>批量用户管理<br/>系统监控与告警<br/>日志轮转与分析<br/>备份与恢复操作<br/>软件包批量安装<br/>例如磁盘空间排查脚本流程：</p><p>使用df -h确认问题范围<br/>通过du -sh * | sort -hr | head -5定位大目录<br/>逐层深入分析具体目录</p><ol start="2"><li>开发环境配置<br/>Shell脚本常用于：</li></ol><p>开发环境一键部署<br/>编译构建自动化<br/>测试用例批量执行<br/>持续集成流程</p><ol start="3"><li>网络与安全运维<br/>典型应用包括：</li></ol><p>批量主机状态检测<br/>安全漏洞扫描<br/>防火墙规则管理<br/>证书自动续期<br/>五、学习路径与资源推荐</p><ol><li>循序渐进的学习阶段<br/>基础阶段：掌握Linux常用命令和Shell基本语法<br/>脚本阶段：编写简单脚本，实现任务自动化<br/>进阶阶段：学习高级特性如数组、关联数组、进程控制<br/>精通阶段：掌握调试技巧、性能优化和复杂系统设计</li><li>推荐学习资源<br/>《Linux shell脚本编程入门》：系统梳理Shell脚本编程核心知识<br/>Bash官方文档：最权威的语法参考<br/>开源项目源码：学习优秀脚本的实现方式<br/>在线社区：CSDN等技术论坛的实战案例分享<br/>六、最佳实践与注意事项<br/>代码规范：</li></ol><p>添加清晰的注释<br/>使用有意义的变量名<br/>保持一致的代码风格<br/>适当添加日志输出<br/>安全考虑：</p><p>避免使用root权限执行不必要操作<br/>谨慎处理用户输入<br/>设置适当的文件权限<br/>注意敏感信息保护<br/>性能优化：</p><p>减少不必要的子进程创建<br/>使用内置命令替代外部命令<br/>批量处理替代循环操作<br/>合理使用缓存机制<br/>通过系统学习和持续实践，Bash Shell编程可以成为提升Linux系统管理效率的强大工具，实现从简单命令行操作到复杂自动化系统的能力跨越。</p>]]></description></item><item>    <title><![CDATA[第50届ICPC亚洲区域赛·上海站，非凸]]></title>    <link>https://segmentfault.com/a/1190000047446324</link>    <guid>https://segmentfault.com/a/1190000047446324</guid>    <pubDate>2025-12-03 16:11:12</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>11月22日-23日，第50届ICPC国际大学生程序设计竞赛亚洲区域赛·上海站在上海大学宝山校区圆满举行。来自221所高校、中学及企业的356支优秀队伍，千余名编程精英同台竞技，以智慧碰撞灵感，以技术角逐巅峰。作为赛事的重要支持方，非凸科技始终关注青年科技人才的成长，致力于推动计算机教育与产业实践的深度融合，为全球学子提供从理论到实践的成长通道。<br/><img width="553" height="373" referrerpolicy="no-referrer" src="/img/bVdne7p" alt="image.png" title="image.png"/><br/>开幕式上，非凸科技首席运营官郑媛姿发表致辞，ICPC从不止于胜负，跨越场次的坚守、迭代升级的解题思路、惺惺相惜的竞技情谊，都是更珍贵的成长馈赠。非凸科技始终以“搭建人才与产业的桥梁”为己任，深知人才是创新的核心密码，更愿为每一位怀揣技术梦想的同学，铺就“从赛场到金融实战”的成长快车道。<br/><img width="553" height="369" referrerpolicy="no-referrer" src="/img/bVdne7q" alt="image.png" title="image.png" loading="lazy"/><br/>赛事期间，非凸科技组织了企业宣讲与人才交流活动，向参赛选手们分享了在数智交易领域的前沿探索与人才布局。在激烈的角逐后，非凸科技代表为获奖队伍颁奖，鼓励他们保持创新热情与技术追求，并期待未来与更多优秀人才在产业实践中携手同行。<br/><img width="553" height="369" referrerpolicy="no-referrer" src="/img/bVdne7r" alt="image.png" title="image.png" loading="lazy"/><br/>本次竞赛，每支队伍需在5小时内通力协作，运用C/C++、Java和Python等其中一种编程语言解决13道复杂算法题目。经历4638次代码提交的密集交锋，最终30支队伍斩获金奖、60支队伍获得银奖、90支队伍摘得铜奖。北京大学“一步之遥”队以解出12题的出色表现荣膺冠军，复旦大学“随机一个字符串得了”队与上海交通大学“启明星”队分别获得亚军和季军。</p><p>以赛育才，聚力前行。未来，非凸科技将继续汇聚产业力量，携手学术界共同推动基础科学研究与应用技术创新的双向赋能，共同探索面向未来的人才培养路径。我们相信，在技术与人才双轮驱动的时代，唯有深化校企联结、促进全球智慧交融，才能为世界科技发展与经济社会繁荣持续注入新动力。</p>]]></description></item><item>    <title><![CDATA[2025年CRM选型全景图：国内外主流系]]></title>    <link>https://segmentfault.com/a/1190000047446343</link>    <guid>https://segmentfault.com/a/1190000047446343</guid>    <pubDate>2025-12-03 16:10:26</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>2025CRM选型全景图：国内外主流系统深度横评</h2><h3>一、引言：数字化深水区，CRM 成企业增长 “关键变量”</h3><p>2025 年，企业数字化转型进入 “价值兑现期”，客户关系管理（CRM）系统已从 “可选工具” 升级为 “增长基础设施”。客户全生命周期的精细化运营，成为企业穿越竞争周期的核心能力。据 Gartner 最新数据，2025 年全球 CRM 市场规模将突破 920 亿美元，年复合增长率维持 11.2% 的高位。</p><p>国内市场中，除了国际巨头与本土头部玩家，深耕行业 21 年的超兔一体云凭借 “全业务一体化” 特色崭露头角，为 6 万多家企业提供覆盖 CRM、进销存、财务、生产等的综合解决方案。面对多元化的产品矩阵，企业如何跳出 “功能堆砌” 的选型误区？本文将从核心能力、适用场景、技术特性三大维度，对 2025 年国内外主流 CRM 系统进行全景对比，为不同类型企业提供精准选型参考。</p><h3>二、国际主流 CRM 系统：技术积淀与全球化生态的双重优势</h3><p>国际厂商依托多年技术积累和全球化布局，在 AI 应用、生态兼容性和合规能力上形成壁垒，更适配有跨国业务或高端需求的企业。</p><h4>1. Salesforce：全球 CRM 的 “生态标杆”</h4><ul><li>市场地位：以 20.7%-26.1% 的全球市场份额连续 12 年领跑，2024 年营收超 300 亿美元，是行业绝对的头部玩家。</li><li>核心优势：Einstein AI 引擎贯穿营销、销售、服务全流程，支持客户流失预测、智能线索评分；AppExchange 平台拥有超 5000 个扩展应用，适配多语言、多币种及 GDPR/HIPAA 等全球合规要求；云原生架构保障跨国企业分布式业务的稳定运行。</li><li>局限性：单用户年费超 150 美元（约合人民币 1100 元 / 月），成本较高；国内访问速度受跨境网络影响，本地化响应较慢。</li><li>适用场景：预算充足的跨国企业、需要全球化合规支持的高端品牌（如微软、亚马逊）。</li></ul><h4>2. Zoho CRM：亚太市场的 “性价比之王”</h4><ul><li>市场表现：全球排名第五（市场份额 5.3%），亚太地区年复合增长率达 18%，中国市场占有率连续 5 年居首，达 25.18%。</li><li>核心优势：AI 功能深度渗透，“SDR 智能体” 将线索筛选效率提升 40%，“销售教练智能体” 实时优化销售话术；2025 年新增 ABM（账户式营销）功能，支持 Line、WhatsApp 等海外社交平台集成，适配跨境业务；QuickML 低代码平台允许企业无编程构建定制化模型。</li><li>局限性：复杂生产场景的适配能力较弱，高端定制化成本较高。</li><li>适用场景：中小企业、跨境电商、需要 AI 赋能的制造业（如极氪汽车、宝马中国）。</li></ul><h4>3. Microsoft Dynamics 365：生态协同的 “一体化代表”</h4><ul><li>核心优势：与 Office 365、Teams、Outlook 等微软产品无缝集成，实现 “办公自动化 + 销售管理” 深度融合；支持 CRM 与 ERP 功能联动，打通 “订单 - 生产 - 交付” 端到端数据链路。</li><li>局限性：行业垂直场景的定制化灵活性不足，小微型企业的成本压力较大。</li><li>适用场景：广泛使用微软生态的企业（如联想、工商银行）、看重跨部门业务协同的中大型企业。</li></ul><h4>4. 其他国际主流玩家</h4><ul><li>HubSpot CRM：初创企业入门首选，免费版支持无限用户，营销自动化模块可将线索转化率提升至 9.7%，适合预算有限的初创团队。</li><li>Pipedrive：聚焦销售漏斗管理，以可视化流程追踪商机进展，核心优势是销售环节效率提升，适配销售导向的中小企业。</li><li>SAP CRM：与 SAP ERP 无缝集成，擅长 “供应链 - 销售 - 服务” 全链路协同，适合奔驰、大众等制造巨头。</li></ul><h3>三、国内主流 CRM 系统：本土适配与场景化创新的突围</h3><p>国内厂商深耕本土企业需求，在钉钉 / 企业微信协同、信创支持、行业定制化上形成优势，超兔一体云等玩家更以 “全业务一体化” 打破传统 CRM 的功能边界。</p><h4>1. 超兔一体云：全业务一体化的 “实干派”</h4><ul><li>市场积淀：21 年行业经验，服务 6 万多家企业，尤其适配工业类、工贸类企业，40% 新客户来自老客户转介绍。</li><li>核心优势：</li><li>全业务打通：国内罕见的综合业务大底座，整合 CRM、进销存、供应链、财务、生产工单等功能，实现业务和数据底层连通；</li><li>低成本客制化：支持功能白名单订阅、三级菜单自定义、工作台定制等，企业可低成本切入，实现 “大底座、快启动”；</li><li>AI 深度应用：可基于客户视图定制销售跟单智能体，嵌入 Coze 工作流，支持自然语言生成工作流、电话录音 AI 分析等；</li><li>本土生态适配：多端覆盖 Web、App、小程序、RPA 插件，支持华为倡导的双重指挥系统模式，适配国内企业组织架构。</li><li>局限性：全球化合规与跨境业务支持能力弱于 Salesforce、Zoho；纯线上营销场景的功能丰富度不及 HubSpot。</li><li>适用场景：工业 / 工贸类企业、需要 “CRM + 进销存 + 生产” 一体化管理的中小企业、看重成本控制与灵活定制的本土企业。</li></ul><h4>2. 纷享销客：本土 CRM 的 “头部标杆”</h4><ul><li>市场地位：连续 5 年稳居国内 CRM 市场占有率首位（2024 年市占率 18.7%），累计融资超 30 亿元。</li><li>核心优势：覆盖 “营销获客 - 销售跟进 - 售后服务” 全流程闭环管理，支持从线索到回款的全生命周期追踪；无缝对接钉钉、企业微信、用友 / 金蝶 ERP 系统，打破数据孤岛；PaaS 平台支持快消、医疗等行业的定制化需求。</li><li>局限性：高端版定价较高，小型企业性价比不足；生产模块的适配能力较弱。</li><li>适用场景：国内中大型企业、需要跨部门协同的快消 / 医疗行业（如元气森林、振德医疗）。</li></ul><h4>3. 神州云动（CloudCC）：高合规需求的 “安全之选”</h4><ul><li>核心优势：支持 SaaS + 私有化混合部署，满足等保三级、GDPR 双合规要求；17 年企业级实施经验，提供 “销售 - 生产 - 交付” 全链路订单追踪，服务奔驰、ABB 等超 10000 家企业。</li><li>适用场景：高端制造、金融、医疗等对数据安全要求极高的行业。</li></ul><h4>4. 销售易（Neocrm）：AI + 大数据的 “成长型选手”</h4><ul><li>核心优势：双中台架构（业务中台 + 数据中台），融合 AI 与大数据技术，实现营销自动化、销售预测、客户服务全流程智能；为 IT 高科技、教育行业提供定制化方案。</li><li>局限性：系统稳定性略逊于行业头部玩家，大规模部署的适配能力有待验证。</li><li>适用场景：快速扩张的成长型企业、IT 高科技与教育行业客户。</li></ul><h3>四、2025 年 CRM 核心技术趋势：从 “功能覆盖” 到 “价值匹配”</h3><ol><li>AI 智能化成为核心竞争力：Gartner 数据显示，2025 年 AI 功能在 CRM 选型中的权重占比提升至 25%，智能预测、自动流程、话术优化成为标配，超兔的 AI 跟单智能体、Zoho 的销售教练智能体均是典型代表。</li><li>模块化与一体化两极分化：一方面，模块化订阅模式兴起，企业可按需选择功能降低成本；另一方面，像超兔这样的 “全业务一体化” 系统受青睐，解决多系统数据割裂问题。</li><li>本土化服务升级：国内企业更看重 2 小时故障响应、行业场景定制、信创适配，神州云动的本地化实施团队、超兔的专业客服均满足这一需求。</li><li>低代码 / 零代码定制普及：降低企业定制化门槛，Zoho 的 QuickML、超兔的自定义引擎均支持无编程或低编程的功能调整。</li></ol><h3>五、国内外主流 CRM 系统对比表（2025 最新版）</h3><table><thead><tr><th>系统名称</th><th>核心优势</th><th>局限性</th><th>适用企业类型</th><th>参考成本（单用户 / 月）</th><th>特色功能</th></tr></thead><tbody><tr><td>Salesforce</td><td>全球化生态、AI 能力强、合规覆盖广</td><td>成本高、国内访问慢、本地化弱</td><td>跨国企业、高端品牌</td><td>约 1100 元</td><td>Einstein AI、AppExchange 生态</td></tr><tr><td>Zoho CRM</td><td>高性价比、AI 功能全、跨境适配好</td><td>复杂生产场景适配弱</td><td>中小企业、跨境电商、制造业</td><td>约 300-800 元</td><td>SDR 智能体、ABM 营销、QuickML 低代码</td></tr><tr><td>Microsoft Dynamics 365</td><td>微软生态协同、CRM+ERP 联动</td><td>行业定制化弱、小微企业成本高</td><td>微软生态用户、中大型企业</td><td>约 800-1500 元</td><td>Office 集成、全链路数据打通</td></tr><tr><td>超兔一体云</td><td>全业务一体化、低成本客制化、稳定性高</td><td>全球化支持弱、纯线上营销功能不足</td><td>工业 / 工贸企业、中小企业、本土企业</td><td>约 500-750 元</td><td>CRM + 进销存 + 生产联动、AI 跟单智能体</td></tr><tr><td>纷享销客</td><td>本土生态全、全流程闭环、行业定制强</td><td>高端版成本高、生产模块弱</td><td>国内中大型企业、快消 / 医疗行业</td><td>约 500-1200 元</td><td>钉钉 / 企业微信集成、全生命周期管理</td></tr><tr><td>神州云动</td><td>双合规支持、数据安全强、实施经验丰富</td><td>性价比一般、小型企业适配弱</td><td>高端制造、金融、医疗行业</td><td>约 600-1300 元</td><td>混合部署、全链路订单追踪</td></tr><tr><td>销售易</td><td>AI + 大数据、双中台架构、行业方案专</td><td>稳定性一般、大规模部署适配弱</td><td>成长型企业、IT 高科技 / 教育行业</td><td>约 400-1000 元</td><td>销售预测、学员跟进定制</td></tr><tr><td>HubSpot CRM</td><td>免费版无用户限制、营销自动化强</td><td>功能深度不足、付费版升级成本高</td><td>初创团队、预算有限企业</td><td>免费 - 约 500 元</td><td>无限免费用户、社交媒体集成</td></tr><tr><td>Pipedrive</td><td>销售漏斗可视化、线索追踪高效</td><td>功能单一、无生产 / 财务联动</td><td>销售导向型中小企业</td><td>约 200-500 元</td><td>可视化流程、商机进展追踪</td></tr></tbody></table><h3>六、企业选型指南：按 “需求画像” 精准匹配</h3><ol><li>跨国业务 + 高合规需求：优先选择 Salesforce，其全球化生态与合规能力行业领先，适合预算充足的高端品牌。</li><li>跨境电商 + 中小企业：Zoho CRM 是最优解，高性价比与跨境适配能力兼顾，AI 功能可提升转化效率。</li><li>微软生态深度用户：Microsoft Dynamics 365 可实现办公与业务无缝协同，减少系统切换成本。</li><li>国内中大型企业 + 跨部门协同：纷享销客或神州云动，前者擅长本土生态整合，后者聚焦数据安全与合规。</li><li>工业 / 工贸企业 + 一体化需求：超兔一体云是核心推荐，CRM、进销存、生产工单的底层连通的，完美适配 “销售 - 生产 - 交付” 全流程。</li><li>初创团队 + 预算有限：HubSpot CRM 免费版可满足基础需求，营销自动化功能助力快速获客。</li><li>销售导向 + 效率优先：Pipedrive 的可视化销售漏斗能精准追踪商机，提升销售转化效率。</li></ol><h3>七、结语：选型的本质是 “需求与价值的匹配”</h3><p>2025 年 CRM 市场的竞争，已从 “功能比拼” 转向 “价值适配”。国际巨头的优势在于全球化与技术生态，本土玩家的核心竞争力是场景适配与成本控制，而超兔一体云的 “全业务一体化” 模式，为工业、工贸类企业提供了差异化选择。</p><p>企业选型时，无需盲目追求 “功能最全” 或 “品牌最响”，应围绕四大核心维度决策：企业规模（初创 / 中小 / 大型）、行业特性（工业 / 快消 / 跨境等）、业务需求（单一销售管理 / 全流程一体化）、预算范围。选对 CRM 不是终点，而是以系统为支点，撬动客户运营效率与业务增长的起点。</p>]]></description></item><item>    <title><![CDATA[【交通标志识别系统】Python+Ten]]></title>    <link>https://segmentfault.com/a/1190000047446348</link>    <guid>https://segmentfault.com/a/1190000047446348</guid>    <pubDate>2025-12-03 16:09:42</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>一、介绍</h2><p>交通标志识别系统，基于TensorFlow搭建Resnet50卷积神经网络算法，通过对58种常见的交通标志图片数据集进行训练，最后得到一个识别精度较高的模型，然后搭建Web可视化操作平台。</p><p><strong>技术栈</strong>：</p><ul><li>项目前端使用Html、CSS、BootStrap搭建界面。</li><li>后端基于Django处理逻辑请求</li><li>基于Ajax实现前后端数据通信</li></ul><p><strong>选题背景与意义</strong>：<br/>在智能交通系统蓬勃发展的当下，交通标志的精准识别对于保障行车安全、提升交通管理效率意义重大。然而，传统识别方法在面对复杂多变的交通环境时，往往存在识别精度不足、效率低下等问题。为此，我们开展交通标志识别系统项目，采用前沿技术，基于TensorFlow搭建Resnet50卷积神经网络算法，利用58种常见交通标志图片数据集训练，以获取高精度识别模型。同时，为方便用户操作，我们还运用Html、CSS等技术搭建Web可视化平台，实现便捷交互。</p><h2>二、系统效果图片展示</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446350" alt="图片" title="图片"/></p><h2>三、演示视频 and 完整代码 and 安装</h2><p>地址：<a href="https://link.segmentfault.com/?enc=qpJnptzhfNwtKL3P6vF1DA%3D%3D.A23mVaEfGqjEzejeKRN%2BN69JCaV3f67CUDyO%2Ba%2F7a3o%3D" rel="nofollow" target="_blank">https://ziwupy.cn/p/qBWZim</a></p><h2>四、卷积神经网络算法介绍</h2><p>卷积神经网络（CNN）是一种专门为处理具有网格结构数据（如图像）而设计的深度学习算法。它通过卷积层自动提取图像的局部特征，利用池化层降低数据维度、减少计算量并增强特征的鲁棒性，最后通过全连接层对提取的特征进行分类或回归。CNN的独特之处在于其局部连接和权重共享机制，极大减少了参数量，提高了训练效率，尤其擅长图像识别、目标检测等计算机视觉任务。</p><pre><code class="python">import tensorflow as tf
from tensorflow.keras import layers, models

# 构建简单CNN模型
model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(10, activation='softmax')
])

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])
</code></pre><p>上述代码用TensorFlow构建了一个简单的CNN模型，包含两个卷积层和池化层，用于提取图像特征，后接全连接层进行分类。该模型适用于手写数字识别等简单图像分类任务，通过调整网络结构和参数，可拓展至更复杂的图像识别场景。</p>]]></description></item><item>    <title><![CDATA[开源视频生成新标杆：美团LongCat ]]></title>    <link>https://segmentfault.com/a/1190000047446376</link>    <guid>https://segmentfault.com/a/1190000047446376</guid>    <pubDate>2025-12-03 16:08:51</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>今年涌现了大量新的视频模型，可以说 2025 年是视频建模真正主导公众对 AI 技术兴趣的第一年。随着 Sora 2 的普及，这一点变得越来越清晰。得益于 OpenAI 的一系列移动应用程序，获取视频生成工具的可能性与普及度达到了前所未有的高度。但闭源模型并非本文的重点，而这些模型的开源竞争实际上正变得比以往任何时候都更加令人印象深刻。</p><p>今年早些时候，HunyuanVideo 和 Wan2.1 以其令人难以置信的保真度、相对低廉的成本和公开可用性震撼了开源世界。这种发展趋势仍在继续，Wan 的新版本不断发布，其他竞争对手也纷纷入场。</p><p>在本文中，我们将介绍最新公开可用的视频模型：美团的 LongCat Video。这个出色的视频模型是进入我们工具箱的最新、最棒的开源工具，我们很高兴在本教程中展示如何从今天开始，利用 DigitalOcean 生成你自己的视频。</p><p>请跟随我们，简要了解 LongCat Video 的工作原理，以及一个展示如何在配备 NVIDIA GPU 的 DigitalOcean GPU Droplet 上设置并开始运行 LongCat Video 的教程。</p><p><strong>本文的核心要点</strong></p><ul><li>LongCat Video 是目前可用的、对标 Sora 2 的最佳开源竞争者。</li><li>用户可以使用 DigitalOcean GPU Droplets，通过自己的提示词和硬件，生成质量可与 Sora 2 媲美的视频。</li><li>运行 LongCat Video 至少需要 NVIDIA GPU 系统上具备 80GB 的显存，但可以扩展到多 GPU 设置以加快生成速度。</li></ul><h3>LongCat Video：概述</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446379" alt="" title=""/></p><p>LongCat Video 的精妙之处在于其核心架构。这是因为他们非常巧妙地设计了一个单一管道来处理多项任务，包括文本到视频、图像到视频和视频延续。他们认为，所有这些任务都应被定义为视频延续，即模型根据给定的一组前置条件帧来预测未来的帧。</p><p>为了实现这一点，他们采用了相对标准的扩散变换器架构，并配有单流变换器块。“每个块包含一个 3D 自注意力层、一个用于文本条件的交叉注意力层，以及一个带有 SwiGLU 的前馈网络。为了进行调制，他们利用了 AdaLN-Zero，其中每个块都包含一个专用的调制 MLP。为了增强训练稳定性，在自注意力模块和交叉注意力模块中都应用了 RMSNorm 作为 QKNorm。此外，还采用了 3D RoPE 作为视觉标记的位置编码。”这种统一的架构允许使用相同的模型设计来完成三种视频任务中的任何一种。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446380" alt="" title="" loading="lazy"/></p><p>该模型在一个包含来自各种不同来源、视频类型和主题的大量标注视频语料库上进行了训练。我们可以在上图中看到训练数据中包含主题的大致聚类。对于这些数据，他们采用了强大的数据预处理和数据标注流程来进行文本标注。首先，收集并处理数据以确保没有重复项、裁剪黑边以及进行视频过渡分割。目前，他们没有详细讨论其数据来源。</p><p>LongCat Video 的闪光点及其与竞争对手的不同之处在于其长视频生成能力和高效的推理策略。对于长视频生成，LongCat-Video 原生地在视频延续任务上进行了预训练，使其能够生成长达数分钟的视频，而不会出现色彩漂移或质量下降。在实践中，这得益于训练策略的鲁棒性，其中对视频延伸的关注在训练结果中得以体现。至于高效的推理策略，我们指的是从粗到精的策略。在 LongCat Video 中，“视频首先生成为 480p、15fps，随后精炼至 720p、30fps。”（来源）此外，他们实现了一种新颖的块稀疏注意力机制，有效地将注意力计算量减少到标准密集注意力所需计算量的 10% 以下。这一设计显著提高了高分辨率精炼阶段的效率。最后，他们使用了一种新颖的组相对策略优化策略来进一步优化其流程。他们有效地采用了带有多个奖励的强化学习范式。</p><p>总而言之，美团 LongCat Video 是一个功能强大的视频生成和延续模型，作为一个工具，它既多功能又强大。他们认为其模型与最先进的竞争对手相比具有竞争力，我们希望通过本文展示如何在 DigitalOcean 的硬件上使用它。</p><h3>LongCat Video 演示：如何在 DigitalOcean GPU Droplet 上运行 LongCat Video</h3><p><strong>1、设置 Gradient ​GPU</strong>​<strong>​ Droplet</strong></p><p>要开始运行 LongCat Video，我们建议从<a href="https://link.segmentfault.com/?enc=gI%2FTErQjWk7WAU0NftWXmQ%3D%3D.jQg5xKcIW0SWRniizOm%2BMwiLuE7tOGF4RwH5Z3SB%2FzEUv7wLg1%2B8NbvfGWC4XEPwoXjvWxHioYLPip7JODL0aQ%3D%3D" rel="nofollow" target="_blank">创建一个 DigitalOcean Gradient GPU Droplet 云服务器</a>开始。这些 GPU Droplet 配备了运行本教程所需的 GPU 资源。我们建议至少使用单卡 NVIDIA H200 GPU，但拥有 8xH100 或 8xH200 设置的用户将看到更快的视频生成效率。DigitalOcean 的 GPU 资源不仅比 AWS、GCP 等大型云平台更加实惠，GPU Droplet 的性能比 Vast.ai 等 GPU 租赁平台更加稳定，而且 GPU 可选型号比 Linode 更加丰富。</p><p>要启动 GPU Droplet 并设置运行此演示的环境，我们建议使用本教程入门：<a href="https://link.segmentfault.com/?enc=ACCVPfVABVWPWxiHEF0jzA%3D%3D.zsZmhWKWCg9Y2KP8xyfLZGVmPRVS%2BjaJQMLhnxLTnajnj%2BIv4oJcAU75medJ5nuaNmKmZ5vYruFDDznvWHzRSA%3D%3D" rel="nofollow" target="_blank">https://blog.aidroplet.com/tutorials/do-gpu-jupyter-dl-setup/</a></p><p>可以从本地终端访问正在运行的 GPU Droplet 后，请继续跟着下一部分步骤来操作。</p><p><strong>2、为 LongCat Video 设置远程环境</strong></p><p>通过 SSH 连接到远程机器后，导航到你想要工作的目录。进入目录后，粘贴以下代码开始设置你的环境。</p><pre><code>git clone https://github.com/meituan-longcat/LongCat-Video
cd LongCat-Video
pip install torch==2.6.0+cu124 torchvision==0.21.0+cu124 torchaudio==2.6.0 --index-url https://download.pytorch.org/whl/cu124
pip install ninja
pip install psutil
pip install packaging
pip install flash_attn==2.7.4.post1
pip install -r requirements.txt</code></pre><p>完成上述步骤后，我们几乎可以准备开始了。现在要做的就是下载模型检查点！使用以下代码片段来完成：</p><pre><code>pip install "huggingface_hub[cli]"
huggingface-cli download meituan-longcat/LongCat-Video --local-dir ./weights/LongCat-Video</code></pre><p><strong>3、使用 Streamlit 应用程序生成 LongCat 视频</strong></p><p>对于演示，我们建议使用作者提供的 Streamlit 应用程序来运行视频生成。这个 Streamlit 演示使得在不同分辨率下生成视频、从静态图像生成视频以及延续视频长度变得简单。</p><p>设置完成后，我们就可以运行演示了。粘贴以下命令来运行演示。</p><pre><code>streamlit run ./run_streamlit.py --server.fileWatcherType none --server.headless=false</code></pre><p>复制 Streamlit 窗口的 URL，然后使用 Cursor 或 VS Code 的简单浏览器功能从本地访问该窗口。设置 VS Code 环境的步骤在 <a href="https://link.segmentfault.com/?enc=A%2BMUQCoCj9drU4SvdWTPxg%3D%3D.RafFz7SgdG%2BzL5hNZhGz1hEj1TCfps6ewAgGVMSEocFUsfngx8Ee7K%2FZvu5maiiXG0Mwq6PWS227ukXUDDxJNg%3D%3D" rel="nofollow" target="_blank">卓普云 aidroplet.com 的官网教程中有所概述</a>。卓普云是 DigitalOcean 中国区独家战略合作伙伴，为中国区企业客户提供商务对接与中文技术支持。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446381" alt="" title="" loading="lazy"/></p><p>上图显示了加载后的 Streamlit 演示界面。左侧有一个下拉菜单，我们可以在三个选项之间切换任务，启用蒸馏模式（将模型限制为 16 个推理步骤而非 50 个），启用超分辨率（从粗到精的上采样），以及设置生成参数。在窗口本身，我们有选项可以输入正面和负面提示词文本，并且在其他任务中，根据需要添加图像或视频。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446382" alt="" title="" loading="lazy"/></p><p>当我们运行生成器时，视频输出会显示在右侧！一定要尝试各种不同的提示词主题，来真正测试这个模型！</p><p>美团 LongCat Video 是一个真正强大的视频生成范式。我们对其多功能性和能力都印象深刻。在测试中，它确实是 Wan2.1 和 HunyuanVideo 向前迈出的一步，并且与 Wan2.2 等最先进的模型不相上下。不仅如此，统一的框架使得这个流程比竞争对手更加令人印象深刻和多功能。我们期待未来围绕 LongCat Video 发展出一个生态系统。</p>]]></description></item><item>    <title><![CDATA[从“数据孤岛”到“全域流转”：Kaiwu]]></title>    <link>https://segmentfault.com/a/1190000047446401</link>    <guid>https://segmentfault.com/a/1190000047446401</guid>    <pubDate>2025-12-03 16:08:19</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2><strong>关于数据分发</strong></h2><p>数据分发，简而言之，就是将数据从源头高效、可靠地传输到一个或多个指定目的地的过程。其核心目的在于，确保需要数据的人或系统能够在正确的时间、以恰当的形式获取到准确的数据，实现数据的共享与同步。</p><h2><strong>为什么需要数据分发？</strong></h2><p><strong>• 实时数据共享</strong></p><p>集团各部门协同合作，需确保所有数据部门获取最新数据，避免因数据延迟导致的业务决策偏差，如供应链协同场景、IoT 设备运维、营销自动化等。</p><p><strong>• 云边端数据协同</strong></p><p>终端设备产生的海量原始数据按需（全量或者预处理）同步至云端分布式集群，进行全局数据的建模、预测、分析。</p><p><strong>• 实时计算与告警</strong></p><p>实时将变更数据主动推送出去，客户端根据业务需求自由订阅数据，进行数据的实时计算、展示与告警。</p><h2><strong>设计理念与架构</strong></h2><h3><strong>1、 核心设计理念</strong></h3><p>KaiwuDB 数据分发以"<strong>数据价值最大化</strong>"为核心设计原则，在源端与多目标端之间搭建高效、灵活、可靠的流转桥梁，以最小化传输带宽、时间成本实现最大传输效率，发挥最大数据价值。</p><p><strong>• 实时数据驱动，赋能业务即时决策</strong></p><p>以 <strong>"数据实时流转为业务价值服务"</strong> 为核心，确保数据从产生到分发的延迟控制在毫秒级。让业务能基于最新数据做即时决策，将数据的 "时间价值" 最大化。</p><p><strong>• 业务场景导向，降低实时数据集成门槛</strong></p><p>围绕 <strong>"让实时数据集成更简单"</strong> 的理念，设计了开箱即用的订阅发布能力：无需用户开发复杂的自定义同步逻辑，通过配置化的方式即可实现跨集群、跨系统的数据实时同步，同时兼容多种技术生态（时序引擎、消息队列、业务应用），让不同业务场景能快速复用该能力。</p><p><strong>• 云边端一体化</strong></p><p>以 "<strong>本地计算 + 按需同步</strong>"为核心，边缘侧过滤冗余数据、云端汇聚核心信息，适配工业物联网、车联网等分布式场景。</p><h3><strong>2、 数据分发流程</strong></h3><p><img width="723" height="306" referrerpolicy="no-referrer" src="/img/bVdne8A" alt="" title=""/></p><p>KaiwuDB 数据分发流程图</p><p><strong>• 核心层</strong></p><p>借助 CDC（Change Data Capture，变更数据捕获）技术，精准捕获数据变更，支持基于 SQL 的订阅规则定义（如 WHERE vibration \&gt; 阈值的异常数据过滤）。</p><p><strong>• 传输层</strong></p><p>支持 DDL（数据定义语言，用于数据库结构变更）和业务数据同步分发：</p><p>• 发送至 Kafka（分布式消息队列），供第三方应用消费主题数据，支持多端异步数据消费场景；</p><p>• 传递至 KaiwuDB 集群 B 的数据订阅模块，实现跨集群的数据同步。</p><h2><strong>核心功能特性</strong></h2><h3><strong>1、 多维度数据订阅</strong></h3><p>• 提供全量初始化 + 增量同步双模式；</p><p>• 支持基于 SQL 条件的行过滤和列级投影同步。</p><h3><strong>2、 高可靠传输机制</strong></h3><p>• 基于 Raft 协议的多副本机制，单点故障后仍可从其它正常节点继续同步；</p><p>• 边缘节点断网时本地缓存数据，恢复后自动续传，保障弱网场景可用性。</p><h3><strong>3、 断点续传</strong></h3><p>定期保存已处理日志的时间点，在故障恢复时从断点继续同步，避免数据重复或遗漏。</p><h3><strong>4、 元数据智能映射</strong></h3><p>自动识别源库表结构变更（如字段增删），同步更新目标端 Schema，保持上下游数据结构一致性。</p><h3><strong>5、 高效传输</strong></h3><p>通过实时捕获数据的增量变更，仅传输变化部分，提升数据同步效率。</p><h2><strong>应用场景与核心价值</strong></h2><h3><strong>1、 部分典型应用场景</strong></h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446403" alt="" title="" loading="lazy"/></p><h3><strong>2、 核心业务价值</strong></h3><p><strong>• 提升实时决策</strong></p><p>• 打破设备厂商数据壁垒，实现跨部门协同优化，实时数据共享打破信息孤岛，生产、运维、供应链等部门可基于同一数据源协同决策；</p><p>• 动态分析与预测，结合历史数据分析趋势并预测潜在问题，提前制定维护计划，减少非计划停机时间。</p><p><strong>• 降低系统资源消耗</strong></p><p>• 按需订阅关注数据信息，避免全量数据传输，减少 70%+ 云端传输量，带宽成本降低 30%\~50%+；</p><p>• 边缘计算预处理，进行滤波、聚合或降采样处理，降低云端计算压力。</p><p><strong>• 增强业务灵活性</strong></p><p>• 支持灵活增减数据源或订阅主题，无需重构系统架构；</p><p>• 允许第三方开发者基于实时数据流开发增值应用，加速创新并丰富业务生态。</p><p><strong>• 安全合规</strong></p><p>支持数据脱敏订阅，符合 GDPR 数据最小化原则，保障车联网等场景的数据安全。</p>]]></description></item><item>    <title><![CDATA[LazyLLM × 硅基流动：共造面向开]]></title>    <link>https://segmentfault.com/a/1190000047446414</link>    <guid>https://segmentfault.com/a/1190000047446414</guid>    <pubDate>2025-12-03 16:07:19</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446417" alt="" title=""/></p><blockquote>在大模型全面走向工程落地的当下，<strong>LazyLLM</strong>正式与<strong>硅基流动（SiliconFlow）</strong> 达成深度合作，共同打造面向开发者的下一代智能应用底座。借助LazyLLM的一键接入线上模型API能力，硅基流动的大语言模型、多模态模型、向量与Embedding模型、文生图模型等已经完整接入，同一套接口即可覆盖从文本到图像、从检索到生成的全链路需求。</blockquote><p>这次合作带来的不仅是<strong>更强大的RAG选型</strong>，还进一步<strong>放大了Agent能力</strong>：在LazyLLM中，开发者可以基于统一的模型接入层，灵活编排工具调用与工作流，结合对MCP等协议的支持，将检索、调用外部系统、多模型路由、长程记忆等能力封装为可协作的智能体网络。</p><p>对于开发者而言，底层模型与算力的复杂度被彻底“藏”在LazyLLM+硅基流动这套组合之下——你只需聚焦业务逻辑，就能搭出既有强RAG能力、又有高扩展Agent能力的AI应用，从原型验证一路平滑升级到生产级部署。</p><hr/><p><strong>LazyLLM</strong></p><blockquote>LazyLLM是由商汤LazyAGI团队开发的一款开源低代码大模型应用开发工具，提供从应用搭建、数据准备、模型部署、微调到评测的一站式工具支持，以极低的成本快速构建AI应用，持续迭代优化效果。</blockquote><hr/><h2>一、<strong>API申请和环境配置</strong></h2><h3><strong>（一）账号注册</strong></h3><ul><li><p>注册硅基流动账号</p><p>（点击注册：<a href="https://link.segmentfault.com/?enc=fmoQM%2B6wVi7Etmqlv%2BX%2Bhw%3D%3D.NivzJ7L1y1u2jUSKXiYZxMbjJRAUXiHeCTC9Bw25SoTbkIZzvOYoMdhpylSlXRcxUCvmYO2qQ0g7DCy0TksZ8goQKYgb0PlBclWpYk3SmDEjBsg9Fptpd5dx71cTGO8R09I3W6DgYQguqF4hTX2MG%2F8hEvnWdnmuC93aObE%2F8MY%3D" rel="nofollow" target="_blank">https://account.siliconflow.cn/zh/login?redirect=https%3A%2F%2Fcloud.siliconflow.cn&amp;invitation=TR9Ym0c4）</a></p></li><li><p>进入控制台，获取APIkey</p><p>（获取方式：<a href="https://link.segmentfault.com/?enc=yApuYjD14mJ%2BR7Iss4p45A%3D%3D.uDjG7jc%2BxC6zIikqRxBABcaqQRrKZ4UPgRJEoLGKRkC8QMKApEHzfnEZlE%2FRwuyy32no9xKWQAshE0N0ZttHc0MQt48vNGxfwAfIplHKfbYlSADwDCFV%2BadlkOYJnpni15jNcYjgGa51qsuz815FCg%3D%3D" rel="nofollow" target="_blank">https://account.siliconflow.cn/zh/login?redirect=https%3A%2F%2Fcloud.siliconflow.cn%2Faccount%2Fak%3F）</a></p></li></ul><h3><strong>（二）环境配置</strong></h3><p>参考网页：快速开始-LazyLLM。</p><p>（<a href="https://link.segmentfault.com/?enc=r21U1UoO7cg3pm1BuoXhvw%3D%3D.ECCmdTm7fJetNOFU%2FerYOnjoGDeqSL8Lmj9uvtwCuaunOXnpS%2FLij04V9ajBAmOO" rel="nofollow" target="_blank">https://docs.lazyllm.ai/zh-cn/stable/）</a></p><hr/><h2><strong>二、API使用测试</strong></h2><h3><strong>（一）设置环境变量</strong></h3><p>可以使用以下命令设置对应的环境变量。或从代码中显示给入:</p><pre><code>export LAZYLLM_SILICONFLOW_API_KEY=&lt;申请到的api key&gt;
</code></pre><h3><strong>（二）实现对话和图片识别</strong></h3><h4><strong>1. 文本问答演示</strong></h4><p>填好api_key后，运行下面代码可以迅速调用模型并生成一个问答形式的前端界面：</p><pre><code>import lazyllm
from lazyllm import OnlineChatModule,WebModule
api_key = 'sk-' #替换成申请的api
# # 测试chat模块
llm = OnlineChatModule(source='siliconflow', api_key=api_key, stream=False)
w = WebModule(llm, port=8846, title="siliconflow")
w.start().wait()
</code></pre><p>我们询问“什么是LazyLLM”，运行结果如下:</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446418" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446419" alt="" title="" loading="lazy"/></p><h4><strong>2. 多模态问答演示</strong></h4><p>在输入中通过lazyllm_files参数传入一张图片，并询问图片的内容，就可以实现多模态的问答。</p><pre><code>import lazyllm
from lazyllm import OnlineChatModule
api_key = 'sk-' #替换成申请的api
llm = OnlineChatModule(source='siliconflow', api_key=api_key, model='Qwen/Qwen2.5-VL-72B-Instruct')
print(llm('你好，这是什么？', lazyllm_files=['your_picture.png']))
</code></pre><p>这里我们使用这个图片测试多模态问答</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446420" alt="" title="" loading="lazy"/></p><p>命令行中输出结果：</p><blockquote><p>你好！这是一只小猫。它看起来非常可爱，毛茸茸的，眼睛大大的，背景是模糊的色彩，突出了小猫的细节。这样的图像通常能让人们感到温暖和愉快。你想了解更多关于小猫的信息吗？</p><p>（lazyllm）→LazyLLMgit:(main)</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446421" alt="" title="" loading="lazy"/></p></blockquote><h3><strong>（三）实现文生图和文生语音</strong></h3><p>使用OnlineMultiModalModule进行文生图和文生语音，运行后会输出生成的文件路径</p><pre><code>import lazyllm
from lazyllm import OnlineMultiModalModule
api_key = 'sk-xxx'
# 测试文生图 fuction=text2image
llm = OnlineMultiModalModule(source='siliconflow', api_key=api_key, function='text2image')
print(llm("生成一个可爱的小狗"))
# 测试文生语音 function=tts
llm = OnlineMultiModalModule(source='siliconflow', api_key=api_key, function='tts')
print(llm("你好，你叫什么名字", voice='fnlp/MOSS-TTSD-v0.5:anna'))
</code></pre><p>运行结果：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446422" alt="" title="" loading="lazy"/></p><p>生成的语音如下：</p><p>| tmpck44zfds.mp3 | 55.13KB | 2025-10-2723:13 |</p><p>（语音链接：<a href="https://link.segmentfault.com/?enc=x0QCEUHS3PVObwUZXoF4Lw%3D%3D.gphqFoe7NNXOPGT8eRuBo1Y8lFmBOasuD1hmWNICCQ7Z8YW9k4Lcdl7orH2hUzo6bPz9JnJ9ElbVJoXSsI10nzf%2FM2sE1fO8d7Ac6myouDZNqAUakqExdKUD5nlGwbEL" rel="nofollow" target="_blank">https://ones.ainewera.com/wiki/#/team/JNwe8qUX/share/7fy5a6mk/page/FUcz8wKs/）</a></p><h3><strong>（四）10+行代码实现知识库问答</strong></h3><h4><strong>1. 实现Eembed和Rerank功能</strong></h4><p>运行下面代码，使用OnlineEmbeddingModule进行向量化嵌入；设置type='rerank'调用重排序模型。</p><pre><code>import lazyllm
from lazyllm import OnlineEmbeddingModule
api_key = 'sk-'

#测试embed模块
llm = OnlineEmbeddingModule(source='siliconflow', api_key=api_key)
print(llm("苹果"))

#测试rerank模块
llm = OnlineEmbeddingModule(source='siliconflow', api_key=api_key, type='rerank')
print(llm(["苹果", ['苹果','香蕉','橘子']]))
</code></pre><p>向量化的结果如下：</p><pre><code>[-0.0024823144, -0.0075530247, -0.013154144, -0.031351723, -0.024489744, 0.009692847, 0.008086464, -0.037946977, 0.013251133, -0.046675995, -0.011390155, -0.011111312, 0.016779112, 0.054168403, 0.04849454, 0.014742341, 0.02341074, -0.015542501, 0.059939254, -0.024223024, 0.0065467632, -0.041244607, -0.022925794, -0.024804957, 0.006752865, -0.047548898, -0.03685585, 0.0513557....，-0.070656545, -0.01997975, 0.023398615, 0.008735079]
</code></pre><p>词相似性分数如下：</p><pre><code>[{'index': 0, 'relevance_score': 0.9946065545082092}, {'index': 2, 'relevance_score': 0.014802767895162106}, {'index': 1, 'relevance_score': 0.0004139931406825781}]
</code></pre><h4><strong>2. 知识库导入</strong></h4><p>我们使用中国古典文籍作为示例知识库，下载后放在database文件夹。</p><p>（示例数据集下载链接：<a href="https://link.segmentfault.com/?enc=514NpqBGE7WYejc9yYo2Iw%3D%3D.2uFM09iyVjJCEy%2B1vt38MnyvvYPe9C%2B%2BQOLls44616Pbb2PwbKo3iJoNkG1RcOJqbGbAkixrLFIX3eb1BCxKMrt9D2zucaIbo%2FqXfW%2F%2F4aCj2RmQp8N0miwUhIdiTKkn" rel="nofollow" target="_blank">https://huggingface.co/datasets/LazyAGI/Chinese\_Classics\_Articles/tree/main）</a></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446424" alt="" title="" loading="lazy"/></p><p>首先定义embed模型，然后使用LazyLLM的Document组件创建文档管理模块，以实现知识库的导入。</p><pre><code>import lazyllm
api_key='sk-'
embed_model = lazyllm.OnlineEmbeddingModule(source="siliconflow", api_key=api_key)
documents = lazyllm.Document(dataset_path="database", embed=embed_model)
</code></pre><h4><strong>3. 知识库检索</strong></h4><p>现在有了外部知识库，LazyLLM中使用Retriever组件可以实现检索知识库并召回相关内容。使用示例：</p><pre><code>import lazyllm
from lazyllm.tools import Retriever, Document, SentenceSplitter
api_key='sk-'
embed_model = lazyllm.OnlineEmbeddingModule(source="siliconflow", api_key=api_key)
documents = Document(dataset_path='database', embed=embed_model, manager=False)
rm = Retriever(documents, group_name='CoarseChunk', similarity='bm25', similarity_cut_off=0.01, topk=6)
rm.start()
print(rm("user query"))
</code></pre><h4><strong>4. 知识库问答</strong></h4><p>结合上述模型、文档管理和检索模块，搭配LazyLLM内置的Flow组件进行完整的数据流搭建，完整代码如下：</p><pre><code>import lazyllm
from lazyllm import (
    OnlineEmbeddingModule, OnlineChatModule, Document, SentenceSplitter,
    Retriever, Reranker, ChatPrompter, pipeline
)
# 初始化api key和提示词
api_key = 'sk-'
prompt = """
You will play the role of an AI Q&amp;A assistant and complete a dialogue task.
In this task, you need to provide your answer based on the given context and question.
"""
# 初始化模型
embed_model = OnlineEmbeddingModule(source="siliconflow", api_key=api_key)
rerank_model = OnlineEmbeddingModule(source="siliconflow", api_key=api_key, type="rerank")
llm = OnlineChatModule(source="siliconflow", api_key=api_key)
# 定义文档管理模块，并创建节点组
doc = Document(dataset_path="/home/xxx/database", manager=False, embed=embed_model)
doc.create_node_group(name="block", transform=SentenceSplitter, chunk_size=1024, chunk_overlap=100)
doc.create_node_group(name="line", transform=SentenceSplitter, chunk_size=128, chunk_overlap=20, parent="block")
# 构建RAG pipeline（多路召回--重排--提示词拼接--大模型回答）
with pipeline() as ppl:
    with lazyllm.parallel().sum as ppl.prl:
        prl.r1 = Retriever(doc, group_name='line', similarity="cosine", topk=6, target='block')
        prl.r2 = Retriever(doc, group_name='block', similarity="cosine", topk=6)
    ppl.reranker = Reranker('ModuleReranker', model=rerank_model, output_format='content',
                            join=True) | bind(query=ppl.input)
    ppl.formatter = (lambda context, query: dict(context_str=str(context), query=query)) | bind(query=ppl.input)
    ppl.llm = llm.prompt(lazyllm.ChatPrompter(prompt, extra_keys=["context_str"]))
ppl.start()
query = "何为天道"

print(ppl(query))
</code></pre><p>可以看到RAG很好地从《道德经》等中取回了有关天道的内容，并传给大模型进行回答。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446425" alt="" title="" loading="lazy"/></p><hr/><p>更多技术内容，欢迎移步 "LazyLLM" 讨论！</p>]]></description></item><item>    <title><![CDATA[14款主流CRM一体化能力全景横评 傲视]]></title>    <link>https://segmentfault.com/a/1190000047446434</link>    <guid>https://segmentfault.com/a/1190000047446434</guid>    <pubDate>2025-12-03 16:06:33</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在企业数字化转型中，<strong>CRM</strong> <strong>的核心价值已从“客户管理”延伸至“全业务链路协同”</strong> ——从客户获客、合同签订，到订单履约、财务结算，各环节的无缝衔接直接决定运营效率与利润空间。本文基于<strong>客户管理、合同管理、订单管理、财务集成</strong>四大核心维度，对14款主流CRM品牌（超兔一体云、Salesforce、SAP CRM、Microsoft Dynamics 365、Oracle CX、Pipedrive、金蝶、SugarCRM、Zoho、Freshsales、HubSpot CRM、用友CRM、SuiteCRM、EC）进行深度横评，为不同场景的企业提供选择参考。</p><h2>一、对比维度说明</h2><p>本次横评聚焦“业务全链路闭环”，将四大核心维度拆解为16个子指标（见表1），覆盖从“客户到财务”的全流程能力：</p><table><thead><tr><th>核心维度</th><th>子指标</th></tr></thead><tbody><tr><td>客户管理</td><td>全生命周期覆盖、多渠道整合、AI智能、可视化工具、客资沉淀能力</td></tr><tr><td>合同管理</td><td>全流程覆盖、合规性、AI辅助、模板自定义、与订单联动能力</td></tr><tr><td>订单管理</td><td>全链路协同、多渠道处理、库存联动、状态跟踪、自动化触发能力</td></tr><tr><td>财务集成</td><td>ERP对接、业财数据联动、多货币支持、自动化凭证、风险管控能力</td></tr></tbody></table><h2>二、各维度横向对比</h2><h3>（一）客户管理：从“线索到复购”的全生命周期能力</h3><p>客户管理的核心是“精准识别需求+高效推进转化”，关键看“全流程覆盖深度”与“数据整合能力”。</p><h4>1. 核心能力对比表（表2）</h4><table><thead><tr><th>品牌</th><th>全生命周期覆盖</th><th>多渠道整合</th><th>AI智能</th><th>可视化工具</th><th>客资沉淀能力</th></tr></thead><tbody><tr><td>超兔一体云</td><td>三一客节点+五大跟单模型+客池分类</td><td>微信/广告/线下+智能表单</td><td>用户画像云图+跟进节奏提醒</td><td>客户视图+跟单时间线</td><td>与合同/订单/财务联动</td></tr><tr><td>Salesforce</td><td>销售云+服务云+营销云+数据云</td><td>多渠道线索+360度视图</td><td>AI预测+自动化任务分配</td><td>销售管道+Tableau分析</td><td>跨云数据整合</td></tr><tr><td>SAP CRM</td><td>营销+销售+服务闭环</td><td>多渠道线索+客户数据整合</td><td>市场预测+行为分析</td><td>销售漏斗+报表</td><td>ERP联动客资共享</td></tr><tr><td>Microsoft Dynamics 365</td><td>销售+营销+服务集成</td><td>Office 365+Azure</td><td>生成式AI摘要+报价生成</td><td>Power BI+Excel</td><td>微软生态数据共享</td></tr><tr><td>Oracle CX</td><td>销售+营销+服务+电商</td><td>多渠道互动+B2B数据整合</td><td>AI行为预测+合同简化</td><td>统一商务视图+云同步</td><td>跨部门数据打通</td></tr><tr><td>Pipedrive</td><td>可视化漏斗+阶段管理</td><td>移动端+线索拖拽</td><td>AI跟进提醒+商机优先级</td><td>拖拽式管道+业绩同步</td><td>轻量化客资记录</td></tr><tr><td>金蝶</td><td>全生命周期+ERP联动</td><td>财务/供应链联动</td><td>2025年AI条款校验（98%准确率）</td><td>订单追踪+业绩预测</td><td>集团级客资沉淀</td></tr><tr><td>SugarCRM</td><td>定制化全生命周期</td><td>多维度分类+历史订单</td><td>AI需求预测+行为分析</td><td>自定义字段+模块</td><td>复杂场景客资管理</td></tr><tr><td>Zoho</td><td>潜客+商机+动态联动</td><td>微信/飞书+多渠道</td><td>Zia助手+邮件分析</td><td>报表+销售管理</td><td>跨境客资同步</td></tr></tbody></table><h4>2. 关键能力解读</h4><ul><li><strong>超兔一体云：中小微企业的“精准转化利器”</strong> 以“<strong>三一客节点</strong>”（定性+定级+定量）和“<strong>五大跟单模型</strong>”（适配不同业务场景）实现客户分层，通过“<strong>客池分类</strong>”（需求培养→有需求→成功）自动化推进生命周期。例如，线索进入系统后，先通过“用户画像云图”识别高价值客群，再用“客户视图”呈现全景信息（跟进历史、订单记录），帮助销售聚焦核心商机。 <strong>流程图：超兔客户生命周期管理逻辑</strong></li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446436" alt="" title=""/></p><pre><code>flowchart LR
    A[多渠道获客] --&gt; B[智能表单收线索]
    B --&gt; C[用户画像分级]
    C --&gt; D{高价值?}
    D --&gt;|是| E[需求培养客池]
    E --&gt; F[三一客节点评估]
    F --&gt; G[五大模型跟进]
    G --&gt; H{有需求?}
    H --&gt;|是| I[合同签订]
    I --&gt; J[订单生成]
    J --&gt; K[复购/售后]</code></pre><ul><li><strong>Salesforce：中大型企业的“全渠道引擎”</strong> 依托“<strong>销售云+服务云+营销云+数据云</strong>”的生态，实现从线索捕获到售后的全流程覆盖。例如，“数据云”可激活沉睡客户数据，“360度视图”整合销售、服务、营销的互动记录，让跨部门协同无死角。AI能力聚焦“预测客户行为”（如哪些客户会复购）和“自动化任务”（如提醒跟进），适合需要全渠道触达的中大型企业。</li><li><strong>金蝶：制造/集团企业的“客资沉淀专家”</strong> 依托ERP生态，客户信息与<strong>财务、供应链数据深度联动</strong>（如客户历史订单→库存备货→应收款提醒），解决了传统CRM“客资孤立”的痛点。2025年将升级“AI条款校验”（准确率98%），进一步提升合同合规性，适合重视“业财融合”的制造或集团企业。</li></ul><h3>（二）合同管理：从“起草到归档”的全流程合规能力</h3><p>合同管理的核心是“效率+合规”，关键看“流程覆盖度”与“AI辅助能力”。</p><h4>1. 核心能力对比表（表3）</h4><table><thead><tr><th>品牌</th><th>全流程覆盖</th><th>合规性</th><th>AI辅助</th><th>模板自定义</th><th>与订单联动</th></tr></thead><tbody><tr><td>超兔一体云</td><td>起草→审批→签订→执行→归档</td><td>自定义查重+企业简称模糊查重</td><td>智能条款匹配+多期应收拆分</td><td>10类合同模板（服务/贸易等）</td><td>合同信息自动同步订单</td></tr><tr><td>Salesforce</td><td>模板→签章→审批→履约</td><td>GDPR/CCPA等多国法规</td><td>自动化合同生成+电子签章</td><td>自定义模板+变量替换</td><td>商机→合同→订单闭环</td></tr><tr><td>SAP CRM</td><td>开发→验证→修订→提交</td><td>行业合规模板</td><td>合同租约管理+销售分析</td><td>标准化模板+定制</td><td>合同与销售分析联动</td></tr><tr><td>Microsoft Dynamics 365</td><td>生成→审批→归档</td><td>微软合规框架</td><td>生成式AI摘要+报价转合同</td><td>Office模板+AI生成</td><td>订单触发合同创建</td></tr><tr><td>Oracle CX</td><td>报价→订单→合同</td><td>B2B合规流程</td><td>生成式AI简化合同+协作流程</td><td>统一模板+复杂订单拆分</td><td>统一商务视图联动</td></tr><tr><td>金蝶</td><td>起草→审批→履约→归档</td><td>内置行业合规条款</td><td>2025年AI条款校验（98%）</td><td>12类标准化模板</td><td>订单→合同→收付款联动</td></tr><tr><td>SugarCRM</td><td>定制化全流程</td><td>法务系统集成</td><td>风险条款预警+需求匹配</td><td>自定义模板+变量</td><td>合同与订单状态同步</td></tr></tbody></table><h4>2. 关键能力解读</h4><ul><li><strong>超兔一体云：中小微企业的“合同闭环工具”</strong> 支持<strong>10类合同类型</strong>（服务、贸易、非标定制等），全流程电子化（从起草到归档）。例如，“智能应收拆分”可根据合同约定（如3期付款）自动计算每期金额，“企业简称模糊查重”解决了“同一家企业多个简称”的问题，避免重复签约。与订单的联动设计（合同信息自动同步至订单），彻底消除“合同与订单不一致”的痛点。</li><li><strong>Oracle CX：复杂B2B场景的“合同简化专家”</strong> 针对B2B企业“合同流程长、协作难”的痛点，提供<strong>“统一商务视图”</strong>（整合报价、订单、合同），支持复杂订单拆分（如拆分多个子合同）和跨部门协作。生成式AI可简化合同起草（如自动填充客户信息、条款），降低法务审核成本，适合需要频繁签订复杂合同的B2B企业。</li><li><strong>金蝶：财务精细化企业的“合同合规管家”</strong> 内置<strong>12类标准化合同模板</strong>（如制造、建筑），2025年升级的“AI条款校验”可识别风险条款（如“无理由退款”），准确率达98%。与财务系统的联动（合同→收付款计划→发票），确保“合同约定=财务执行”，适合重视“合同履约与财务一致”的企业。</li></ul><h3>（三）订单管理：从“生成到交付”的全链路协同能力</h3><p>订单管理的核心是“协同+效率”，关键看“与采购/库存的联动”和“状态跟踪能力”。</p><h4>1. 核心能力对比表（表4）</h4><table><thead><tr><th>品牌</th><th>全链路协同</th><th>多渠道处理</th><th>库存联动</th><th>状态跟踪</th><th>自动化触发</th></tr></thead><tbody><tr><td>超兔一体云</td><td>订单→采购→库存→交付</td><td>全渠道订单整合</td><td>订单生成→自动算采购量→匹配供应商</td><td>实时状态+超发预警</td><td>签约/开票/发货触发应收</td></tr><tr><td>Salesforce</td><td>订单→供应链→ERP</td><td>商业云多渠道处理</td><td>与制造云联动→库存实时同步</td><td>销售管道+Tableau跟踪</td><td>订单触发供应链协同</td></tr><tr><td>SAP CRM</td><td>订单→后台交易系统</td><td>多渠道订单整合</td><td>库存变动→财务凭证自动生成</td><td>订单状态+报表分析</td><td>订单触发采购计划</td></tr><tr><td>金蝶</td><td>订单→合同→进销存</td><td>电商/线下订单整合</td><td>订单→库存检查→采购计划</td><td>实时状态+业绩预测</td><td>订单触发收付款计划</td></tr><tr><td>Zoho</td><td>订单→飞书审批→财务</td><td>多渠道订单同步</td><td>库存查询→缺货提醒</td><td>移动端状态跟踪</td><td>订单触发审批流程</td></tr></tbody></table><h4>2. 关键能力解读</h4><ul><li><strong>超兔一体云：中小微企业的“订单协同引擎”</strong> 实现“订单→采购→库存→交付”的全链路协同：订单生成时，自动计算所需采购量（如“订单要100个产品，库存有30个，需采购70个”），并匹配最佳供应商（根据价格、交付周期）。“超发预警”功能（如客户账期内超订单发货），避免企业资金风险。与财务的联动（签约/开票/发货触发应收），确保“货出去，钱进来”的节奏。</li><li><strong>金蝶：制造企业的“订单-库存联动专家”</strong> 与进销存模块深度集成，<strong>订单生成自动触发合同创建</strong>，同时检查库存（如“订单要500个零件，库存有200个，需采购300个”），并生成采购计划。实时订单状态跟踪（如“已发货”“已收款”）与业绩预测（如“本月订单额预计100万”），帮助制造企业精准把控生产节奏。</li></ul><h3>（四）财务集成：从“订单到凭证”的业财一体化能力</h3><p>财务集成的核心是“数据一致性+自动化”，关键看“与ERP的对接”和“凭证生成效率”。</p><h4>1. 核心能力对比表（表5）</h4><table><thead><tr><th>品牌</th><th>ERP对接</th><th>业财联动</th><th>多货币支持</th><th>自动化凭证</th><th>风险管控</th></tr></thead><tbody><tr><td>超兔一体云</td><td>柠檬云等财务平台</td><td>应收+开票+回款三角联动</td><td>支持</td><td>联动生成凭证</td><td>超发预警+账期控制</td></tr><tr><td>Salesforce</td><td>SAP/Oracle等ERP</td><td>订单→财务报表+Tableau分析</td><td>支持</td><td>订阅制自动账单</td><td>信用度监控+发货控制</td></tr><tr><td>SAP CRM</td><td>SAP ERP深度整合</td><td>库存→财务凭证自动生成</td><td>支持</td><td>模块联动生成凭证</td><td>账期预警+应收管控</td></tr><tr><td>金蝶</td><td>金蝶ERP天然对接</td><td>合同→收付款→发票联动</td><td>支持</td><td>业财数据一致+自动凭证</td><td>预算管控+成本分析</td></tr><tr><td>Zoho</td><td>第三方财务系统</td><td>多货币结算+飞书审批</td><td>支持（跨境业务）</td><td>未来深化财务联动</td><td>无明确风险管控</td></tr><tr><td>用友CRM</td><td>用友ERP深度对接</td><td>订单→财务实时同步</td><td>支持</td><td>自动化凭证+报表</td><td>信用度控制+应收预警</td></tr></tbody></table><h4>2. 关键能力解读</h4><ul><li><p><strong>超兔一体云：中小微企业的“业财自动化工具”</strong> 依托“<strong>应收+开票+回款三角联动</strong>”，实现从订单到凭证的全自动化：</p><ul><li>订单生成→根据合同约定触发应收（如“签约触发30%应收”）；</li><li>开票→自动关联订单与应收；</li><li>回款→自动匹配应收与订单；</li><li>凭证生成→一键读取CRM数据（出库、回款、开票），匹配货、款、票信息，生成可视化凭证（支持二次编辑），并推送至柠檬云等财务平台。 <strong>流程图：超兔业财一体化逻辑</strong></li><li><img referrerpolicy="no-referrer" src="/img/remote/1460000047446437" alt="" title="" loading="lazy"/></li></ul></li></ul><pre><code>flowchart LR
    A[合同签订] --&gt; B[订单生成]
    B --&gt; C[库存出库]
    C --&gt; D[触发应收]
    D --&gt; E[开票]
    E --&gt; F[回款]
    F --&gt; G[联动生成凭证]
    G --&gt; H[推送财务系统]</code></pre><ul><li><strong>金蝶：集团企业的“财务精细化引擎”</strong> 天然对接金蝶ERP，<strong>合同→收付款→发票</strong>的联动设计，确保业财数据100%一致。例如，合同约定“3期付款”，系统自动生成收付款计划，发票开具时关联合同与订单，财务人员无需手动核对。“预算管控”功能（如“部门月度费用不超过10万”），帮助集团企业实现财务精细化管理。</li></ul><h2>三、综合能力雷达图与选择建议</h2><p>基于四大维度的核心能力，我们对各品牌进行<strong>10分制评分</strong>（1=无能力，10=顶尖），并绘制雷达图（表6）：</p><table><thead><tr><th>品牌</th><th>客户管理</th><th>合同管理</th><th>订单管理</th><th>财务集成</th><th>综合得分</th></tr></thead><tbody><tr><td>超兔一体云</td><td>9</td><td>8</td><td>8</td><td>9</td><td>34</td></tr><tr><td>Salesforce</td><td>10</td><td>9</td><td>9</td><td>9</td><td>37</td></tr><tr><td>金蝶</td><td>8</td><td>9</td><td>9</td><td>10</td><td>36</td></tr><tr><td>Oracle CX</td><td>9</td><td>9</td><td>8</td><td>9</td><td>35</td></tr><tr><td>Microsoft Dynamics 365</td><td>9</td><td>8</td><td>8</td><td>8</td><td>33</td></tr><tr><td>Pipedrive</td><td>8</td><td>7</td><td>7</td><td>6</td><td>28</td></tr><tr><td>Zoho</td><td>8</td><td>7</td><td>7</td><td>8</td><td>30</td></tr><tr><td>用友CRM</td><td>8</td><td>8</td><td>8</td><td>9</td><td>33</td></tr></tbody></table><h3>最终选择建议</h3><ol><li><strong>中小微企业、全业务一体化需求</strong>：<strong>超兔一体云</strong>（性价比高，覆盖客户→合同→订单→财务全流程，功能贴合中小微场景）。</li><li><strong>中大型企业、全渠道管理</strong>：<strong>Salesforce</strong>（云生态强大，全流程覆盖，适合需要跨部门协同的中大型企业）。</li><li><strong>制造/集团企业、业财融合</strong>：<strong>金蝶</strong>（ERP联动，财务精细化，适合重视“客资 - 库存 - 财务”联动的制造企业）。</li><li><strong>复杂B2B场景、跨部门协同</strong>：<strong>Oracle CX</strong>（统一商务视图，简化合同流程，适合B2B企业的长周期订单）。</li><li><strong>中小销售团队、高透明度</strong>：<strong>Pipedrive</strong>（可视化漏斗，跟进提醒，适合需要快速推进商机的销售团队）。</li><li><strong>跨境业务企业、多货币结算需求</strong>：<strong>Zoho</strong>（支持多货币结算，与丰富的Zoho及第三方应用无缝集成，适合跨境业务财务协同）。</li></ol><p>在企业数字化转型的浪潮中，CRM系统作为企业全业务链路协同的核心工具，其选择至关重要。企业在挑选CRM品牌时，不能仅仅关注品牌的知名度和市场份额，更要深入剖析自身的业务需求、发展阶段以及预算限制等因素。无论是中小微企业追求的高性价比和全业务一体化，还是中大型企业对全渠道管理和跨部门协同的需求，亦或是制造/集团企业强调的业财融合，都能在众多的CRM品牌中找到合适的解决方案。希望本文的深度横评和选择建议，能为企业在CRM选型过程中提供有价值的参考，助力企业提升运营效率，实现可持续发展。</p>]]></description></item><item>    <title><![CDATA[从“建模型”到“管业务”：一位开发者眼中]]></title>    <link>https://segmentfault.com/a/1190000047446446</link>    <guid>https://segmentfault.com/a/1190000047446446</guid>    <pubDate>2025-12-03 16:05:57</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>作为一名在数字孪生领域摸爬滚打多年的应用开发者。过去几年，我和团队接过不少数据中心运维管理的项目，从最初的“炫酷大屏”到后来的“实用工具”，踩过不少坑，也积累了一些心得。今天，我想抛开那些宏大的概念，以一个同行、一个实践者的身份，和大家聊聊，在数据中心这个精密复杂的领域，我们究竟需要什么样的工具，才能把数字孪生从“可视化看板”变成真正的“业务驾驶舱”。</p><h2>一、 第一道坎：如何让运维团队自己“搭场景”？</h2><p>我们最早的项目，常常陷入一个怪圈：业务部门提需求 -&gt; 我们找三维建模师建模型 -&gt; 反复沟通修改 -&gt; 交付后业务逻辑一变，模型又得大改。周期长、成本高，最关键的是，运维团队离实际的场景构建太远，他们的业务洞察无法快速体现在三维世界里。<br/>后来我们意识到，问题的核心在于<strong>工具链的断裂</strong>。理想的工具，应该能让熟悉数据中心机房布局、设备型号的运维专家，即使不会专业建模软件，也能主导场景的搭建，就例如“图观”端渲染的场景编辑器。这需要两个关键支撑：<br/><strong>1. 一个“开箱即用”的资产库，而不是从零开始建模。</strong><br/>想象一下，如果一个工具内置了从服务器机柜、UPS、精密空调、PDU，到地板、桥架、线缆等数据中心全要素的高精度模型库，并且材质、规格可调，那会节省多少时间？我们的做法是，让运维工程师直接在“图观”场景编辑器的模型库里，像搭积木一样，通过拖拉拽，快速还原出数据中心的真实物理布局。这不仅仅是快，更是保证了模型的行业规范性和专业性。<br/><img width="587" height="330" referrerpolicy="no-referrer" src="/img/bVdmqxd" alt="" title=""/><br/><strong>2. 支持“专业级”微调，满足苛刻的细节要求。</strong><br/>当然，完全标准化不可能覆盖所有情况。当遇到特殊品牌设备或需要展示内部结构时，工具必须能无缝导入运维方提供的专业GLB等格式模型。更关键的是，要能对模型进行深度的“化妆”——调整PBR物理材质（让金属更有光泽、玻璃更通透）、设置关节动画（比如模拟柜门开合、风扇转动）。这样，才能在保证效率的同时，不牺牲视觉表现力和准确性。<br/><strong>价值点提炼</strong>： 将场景构建的主导权部分交还给业务专家，实现从“项目制交付”到“持续化运营”的转变。运维团队可以根据设备变更、布局调整，随时自行更新孪生场景，让数字世界与物理世界保持同步的成本降到最低。</p><h2>二、 灵魂所在：如何让冷冰冰的数据在三维空间里“说话”？</h2><p>模型建得再漂亮，如果只是静态的“雕塑”，价值也有限。数字孪生的灵魂在于<strong>数据驱动</strong>。在数据中心，这意味着要将动环监控（温湿度、漏水、烟感）、设备运行（CPU负载、功耗、流量）、资产管理（设备位置、生命周期）等多源、异构的数据流，与三维空间中的具体对象精准关联并直观呈现。<br/>这里有几个我们总结的实用技巧：<br/><strong>技巧1：用“图层”思维管理数据可视化。</strong><br/>不要试图把所有数据一次性堆叠在屏幕上。优秀的工具应允许你创建不同的可视化图层：比如一个“热力图层”来映射机房实时的温度分布，一个“告警图层”让发生故障的设备高亮闪烁并悬浮显示详情，一个“容量图层”用三维柱图显示每个机柜的U位占用和功耗情况。这些图层可以随时开关，让运维人员在不同关注点间灵活切换。<br/><strong>技巧2：实现“所指即所得”的深度交互。</strong><br/>这是区分“高级可视化”和“业务工具”的关键。我们追求的效果是：在三维场景中点击一台服务器，旁边面板立刻显示其所有实时性能指标和历史曲线；反过来，在资产列表中选择一个设备编号，场景镜头能自动定位并高亮该设备。这一切的交互逻辑，应该能通过图形化的方式配置完成，而不是编写大量硬编码。比如，配置一条规则：“当‘空调1号’回风温度&gt;26℃时，在场景中将其模型颜色渐变为红色，并触发告警面板推送消息”。<br/><strong>价值点提炼</strong>： 通过配置化的数据联动与交互，将运维人员的业务经验（如“什么数据重要”、“数据异常该如何关联展示”）沉淀为可复用的数字孪生交互模板，真正构建起<strong>面向业务的、可操作的分析环境</strong>，而不仅仅是事后查看的报表。<br/><img width="640" height="360" referrerpolicy="no-referrer" src="/img/bVdm7Rl" alt="" title="" loading="lazy"/></p><h2>三、 现实考量：如何平衡“电影级画质”与“全员可访问”？</h2><p>这是我们在交付时经常遇到的客户分歧：管理层想要在指挥中心大屏上看到电影级渲染效果的震撼全景，而一线运维工程师则希望在自己的办公电脑甚至平板上，能快速、流畅地接入系统进行日常巡检。<br/><strong>我们的解法是：渲染模式与业务应用解耦。</strong><br/>这意味着，我们用于构建业务逻辑（数据绑定、交互规则、UI界面）的“应用层”是一套独立的、轻量的代码或配置。而三维场景的渲染，则可以根据终端情况灵活选择“服务端流渲染”或“客户端端渲染”。<br/><strong>对于指挥中心大屏</strong>： 采用流渲染模式。所有复杂的图形计算都在高性能服务器上完成，只将渲染后的高清视频流推送到大屏。这样能保证极致的画质和稳定性，展现所有光影、材质细节。<br/><strong>对于运维桌面端/移动端</strong>： 采用端渲染模式。将轻量化的场景数据下发到终端，利用本地显卡进行渲染。这样对服务器压力极小，支持高并发访问，且在网络波动时体验更稳定。<br/><strong>价值点提炼</strong>： “一套业务逻辑，多种呈现方式”。这极大地提升了开发效率和部署灵活性。我们只需开发一次核心业务应用，就能同时满足高端演示与日常使用的不同需求，避免了为不同终端维护多套代码的困境，也降低了客户的总体拥有成本。<br/><img width="640" height="360" referrerpolicy="no-referrer" src="/img/bVdm7Rm" alt="" title="" loading="lazy"/></p><h2>四、 从工具到伙伴：全链路效率与成本最优解</h2><p>数字孪生项目的成功，不仅在于核心开发工具，还依赖于一系列能提升整体生产效率的“周边武器”。例如，在构建园区级数据中心数字孪生时，我们曾为生成周边道路、建筑等环境背景而头疼。<br/>这时，如果工具体系里包含一个城市生成工具，能基于GIS数据自动生成符合比例的路网、批量生成风格化建筑，就能将我们从重复劳动中解放出来，聚焦于数据中心本体。同样，完善的API文档、调试工具和项目范例，能让我们在对接客户自有监控平台、资产管理系统时事半功倍。<br/>最后，在部署阶段，灵活的选项至关重要。项目初期或用于创新验证时，能够快速使用低成本的云服务进行部署和演示，极大降低了试错门槛。而当项目成熟、需要深度定制或对数据安全有严格要求时，又能支持完整的私有化部署，保障客户的核心利益。<br/><strong>价值点提炼</strong>： 选择一套工具，不仅是选择一个软件，更是选择一个能够伴随项目全生命周期成长、在不同阶段都能提供最优性价比解决方案的合作伙伴。它帮助团队控制初期风险，并平滑支持未来扩展。</p><h2>结语</h2><p>回顾这些年的实践，我深刻感受到，数字孪生在数据中心运维领域的价值，正从“视觉创新”走向“业务赋能”。其核心不在于渲染多么炫酷，而在于能否降低使用门槛、深化数据融合、适应多样场景、优化整体投入。<br/>我们追求的，是让运维专家能更专注于他们的专业判断，而不是被技术工具所束缚。通过一系列贴合业务场景的功能与技巧，将数字孪生真正打造成一个人人可用、时时可看、数据可联、决策可依的智能运维新基座。</p>]]></description></item><item>    <title><![CDATA[怎么开始汽车产业链数智化转型？ 月下水光]]></title>    <link>https://segmentfault.com/a/1190000047446452</link>    <guid>https://segmentfault.com/a/1190000047446452</guid>    <pubDate>2025-12-03 16:05:25</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在人类工业文明的演进中，汽车工业一直是国家制造业综合实力的集中体现。它不仅是一个技术密集型的集成平台，更是创新理念与先进制造模式融合的关键战场。如今，随着“电动化、智能化、网联化、共享化”的深層融合，汽车产业正迎来第三次重大变革——智能化生产。而这一变革的核心驱动力，便是以人工智能（AI）为核心的数智化转型。从福特的T型车流水线到丰田的精益生产，再到智能化生产的崭新时代，汽车产业链的数智化进程不仅改变了制造方式，也正在重新定义产业未来。<br/>无人驾驶、智能座舱、动态排产、柔性生产是这场变革的典型标志，而其背后的关键支撑，则是AI技术的全面赋能。自2025年起，数智化已从单纯的选项转变为汽车产业竞争中的必修课，尤其在全球制造业加速升级的背景下，汽车产业链数智化扮演着越来越重要的角色。谁能率先在这一领域实现突破，谁就能在全球价值链的顶端占据先机。<br/>供应链的协同与高效一直被视为汽车制造领域的瓶颈，传统模式下的信息滞后与制造流程脱节问题，往往导致资源浪费与生产效率低下。广域铭岛作为汽车产业链数智化转型的领军企业，推出的“工厂大脑”系统正在打破这种局面。通过整合主机厂、供应商、物流等多方数据节点，广域铭岛的系统实现了供应链全生命周期的实时监控与优化，极大地提升了供应链弹性与响应速度。<br/>例如，在与深圳航盛集团的合作中，广域铭岛帮助后者搭建了一套高协同性、智能化的供应链管控体系，从数字基座建设到供应商动态管理，逐步形成了端到端的闭环能力。更为重要的是，广域铭岛还在第二阶段规划中引入工业AI智能体，对企业全经营流程进行AI预测与优化，从而实现“零缺陷”的品质目标。这种技术赋能，不仅降低了企业的运营成本，还为汽车品牌全球化发展注入了新活力。<br/>对于广域铭岛而言，推动汽车产业链的数智化并非终点，而是构筑未来制造业基础的起点。其Geega工业互联网平台基于工业AI和物联网技术，打造了一套完整的智能制造解决方案。从原材料采购到整车下线，广域铭岛不仅提供了自动化执行工具，还引导企业将制造经验与AI算法深度融合。<br/>其“智能预检+系统”通过动态追踪与智能预警，帮助企业在生产环节实时洞察数据；在冲压工艺中，其模具智能管理系统将设备数据转化为优化算法，预判故障并降低停机时间；在仓储物流中，基于数字孪生的AGV调度系统更是让物料管理达到了前所未有的精准与高效。<br/>广域铭岛这种场景穿透式的技术能力，解决了传统AI大模型应用于工厂场景的适配难题——将老师傅的经验转化为可迭代的数字知识，为企业从“经验驱动”走向“数据智能驱动”提供了切实可行的路径。在实际工业落地中，某装配厂应用其智慧物流系统后，物流效率实现显著提升，呆滞物料率下降，整体交付能力提高30%。这正是汽车产业链数智化转型的缩影，也是广域铭岛帮助企业跨越转型之路阻碍的有力证明。<br/>当传统制造模式面对新型市场需求时，产业链上下游的协同程度在数智化模型下实现了前所未有的提升。广域铭岛在峰会上展示了其最新的“汽车数字化工厂”理念，要素如协同研发、智能生产、全链路关务管家等，使汽车生产企业能够在统一家策略下有效部署资源，实现敏捷响应与高效管理。<br/>而随着汽车产业链全球化部署的推进，广域铭岛的技术输出能力还覆盖了多个行业，例如新能源电池、家电制造等，展现出其在汽车产业链数智化转型上极强的可复制性与通用性。凭借其成熟的解决方案与落地经验，广域铭岛正逐步成为中国乃至全球制造业数智化的桥梁与推手。</p>]]></description></item><item>    <title><![CDATA[数字孪生：国防航天领域智能指挥决策的“智]]></title>    <link>https://segmentfault.com/a/1190000047446492</link>    <guid>https://segmentfault.com/a/1190000047446492</guid>    <pubDate>2025-12-03 16:04:52</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在国防航天这一关乎国家安全与战略优势的核心领域，运营管理的复杂性与日俱增。从航天发射场的全流程管控，到国防设施的态势感知与应急指挥，再到大型装备的全生命周期运维，系统日益庞杂，数据源空前多元，决策压力巨大。传统的管理模式与信息呈现方式，已难以满足对全局实时、精准、协同洞察的迫切需求。<br/>近年来，一项关键技术——数字孪生，正悄然成为破解这些难题的“金钥匙”。而其中我们发现一款数字孪生平台—孪易IOC，它并非简单的三维可视化，而是一套构建在数据融合、场景构建、智能分析与协同处置之上的完整技术体系，正在国防航天行业的多个关键场景中得到深入应用与验证，展现出颠覆性的价值。</p><h2>一、 应对多源异构数据：构建全域感知的“数据基石”</h2><p>国防航天系统的数据生态极为复杂：万千物联网传感器实时回传装备状态参数，各业务系统数据库记录着任务流程与资源信息，空天地海多维监测网络产生海量遥感与侦察数据，不同制式、不同密级的系统间存在数据壁垒。<br/><strong>核心价值点</strong>：成功的数字孪生实践表明，其首要价值在于构建了一个强大的<strong>统一数据融合引擎</strong>。它能够以标准化、安全可靠的方式，无缝接入并治理这些多源、异构、海量的数据。无论是通过适配MQTT等物联网协议实时采集设备数据，还是通过API与既有业务系统（如ERP、MES、指挥系统）深度对接，亦或是处理来自不同平台的GIS、遥感数据，该体系都能实现数据的清洗、关联与实时同步。<br/><strong>案例印证</strong>：在某大型航天发射场，通过部署数字孪生平台，成功将发射塔架数以万计的传感器数据、气象监测数据、任务规划数据与安防监控视频流统一集成。这使得在虚拟孪生场景中，每一个阀门、每一根线缆的状态都与物理世界实时对应，为发射前全系统健康状态评估提供了唯一、可信的“数据真相源”，奠定了精准决策的基石。</p><h2>二、 构建业务化三维场景：从“看见”到“洞见”的关键跃升</h2><p>对于国防航天而言，许多业务本质与空间位置、设备形态、环境态势强相关。传统的二维图表或分散的视频画面，难以直观呈现全局关联与空间逻辑。<br/><strong>核心价值点</strong>：数字孪生提供了从宏观战场环境、基地全域，到微观车间、单台装备的多层次、高保真、可交互的三维可视化能力。平台能够融合倾斜摄影、GIS地图、高精度BIM与装备三维模型，构建起与真实世界1:1映射的虚拟空间。更重要的是，场景中的每一个“孪生体”（如卫星、发射车、厂房、管线）都不是静态模型，而是与后台实时业务数据绑定的动态实体。<br/><strong>案例印证</strong>：在某国防重点设施安全管控项目中，利用数字孪生技术构建了涵盖周边地形、建筑结构、安防设备（周界、摄像头、门禁）的完整三维场景。运维人员不仅能“俯瞰”全局，还能快速定位任一报警点，并立刻在三维场景中调取该点关联的实时视频、设备状态、巡检记录和处置预案，实现了从被动接收告警信息到主动、直观、关联性洞察的根本转变。<br/><img width="640" height="314" referrerpolicy="no-referrer" src="/img/bVdmQxT" alt="" title=""/></p><h2>三、 赋能深度分析与协同处置：驱动决策闭环的“智慧内核”</h2><p>可视化是手段，决策支持才是目的。数字孪生的真正威力，在于利用空间上下文与融合数据，进行过去难以实现的深度分析与模拟推演。<br/><strong>核心价值点</strong>：成熟的数字孪生体系集成了丰富的专业分析工具与协同指挥模块。例如：<br/><strong>空间分析</strong>：进行通视分析以优化监测点位布局，模拟电磁环境对通信的影响，演练疏散路径与物资投送路线。<br/><strong>模拟仿真</strong>：对航天器在轨故障进行数字复现与处置推演，对极端天气下基地运行进行韧性评估。<br/><strong>事件闭环处置</strong>：当发生异常告警（如设备故障、入侵检测）时，系统可自动定位、关联分析、触发预案，并一键启动跨部门的协同任务派发、资源调度与视频会商，形成“监测-预警-决策-处置-复盘”的全流程数字化闭环。<br/><strong>案例印证</strong>：在大型航空航天装备的运维保障中，数字孪生平台接入了装备历史运行数据与实时传感数据。当系统分析发现某部件性能参数出现衰退趋势时，不仅能在三维模型上精准定位，还能自动调用历史相似案例、维修手册，并模拟不同维修方案对整体系统的影响，辅助保障人员制定最优维修策略，极大提升了装备的战备完好性与保障效率。</p><h2>四、 保障系统灵活演进：随业务共同成长的“生命力”</h2><p>国防航天业务需求与技术迭代迅速，一套固化的系统很快会面临挑战。数字孪生体系的长期价值，在于其<strong>高度的可配置性与可扩展性</strong>。<br/><strong>核心价值点</strong>：优秀的平台提供强大的后台配置中心，允许用户根据业务变化，自行调整孪生体属性、数据绑定规则、分析模型与告警阈值。同时，它提供从零代码拖拉拽搭建应用到低代码/API深度开发的全套工具链，使技术团队能够基于平台核心能力，快速构建全新的、高度定制化的业务模块（如专用的任务规划模拟器、特殊的后勤保障看板），保护初始投资，让数字孪生系统真正成为一个能够伴随组织业务持续进化、不断赋能的核心支撑平台。</p><h2>结语</h2><p>综上所述，在国防航天这一尖端领域，数字孪生已超越概念，成为驱动智能化升级的务实引擎。其价值并非单一功能的炫技，而在于构建了一个数据融合力强、场景表现力与交互性高、分析工具专业且紧贴业务、同时具备高度灵活性与生命力的完整技术栈。它正帮助越来越多的单位，将复杂的物理世界与业务运行，转化为可直观感知、可深度分析、可协同指挥的数字镜像，从而在瞬息万变的形势下，赢得决策先机，筑牢安全基石。</p>]]></description></item><item>    <title><![CDATA[汽车工艺优化的未来发展趋势如何？ 月下水]]></title>    <link>https://segmentfault.com/a/1190000047446532</link>    <guid>https://segmentfault.com/a/1190000047446532</guid>    <pubDate>2025-12-03 16:03:54</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在汽车制造业的迭代进程中，工艺优化已成为推动效率提升与质量管理创新的核心驱动力。面向2025年，随着市场需求对高性能、高安全性和环保性的全面升级，传统的生产模式显然无法满足未来的挑战。作为这一领域的先行者，广域铭岛凭借其工业智能体解决方案，正在帮助行业全面实现汽车工艺优化的智能化转型。<br/>汽车冲压工艺作为整车制造的基石，其质量直接影响后续工序的稳定性和整车性能。当前，行业正从依赖人工经验的设备管理向数据驱动的精细化控制迁移。广域铭岛研发的GQCM模具智能管理APP，融合了IIOT技术和AI算法，构建出冲压产线的数字孪生体。通过实时采集冲次数据和设备状态信息，系统能够在实体生产前预演工艺波动，并据此优化参数配置。例如，领克成都工厂仅用该系统便将换模时间压缩至原来40%，同时显著降低材料废品率，这种基于数字主线的工艺优化逻辑改变了传统车间依赖试错经验的生产方式。<br/>焊装工艺的复杂性使其成为工艺优化的重点难点，超3000个焊点的质量稳定性往往是整车质量的关键指标。数据显示，在焊装的智能化质量管控中，广域铭岛开发的GQCM系统通过5G传输网络实时监测20余项焊接参数，其机器学习模型能够以0.02%的虚焊率完成质量预判。而另一项技术突破——二維總成接口分析，则结合设备级与产线级数据完成了焊点力学性能建模，使整个系统的质量控制维度从被动响应进化为主动预防。<br/>总装工艺的智能化优化是确保整车出厂质量的最后一道关口。广域铭岛提供的GQCM拧紧管理系统实现了对每个紧固点质量参数的实时监控，这种高频采集和智能分析往往能在装配完成前精准识别问题。某新能源车企应用该系统后，其拧紧工艺合格率从98%提升至99.98%，整个车间的装配返工率下降了56%。更为惊人的是，该系统建立的电子质量档案功能使某品牌模具的异常处理时间直接缩短了35%。<br/>值得注意的是，广域铭岛不仅在单个工艺上实现突破，更建立了工艺间的协同优化框架。其三大核心技术——数字主线映射、质量闭环算法与模块化部署方案，本质上是对汽车制造系统的深度重塑。这种优化架构通过横向融合和纵向贯通的工业智能体理念，将经验数据转化为可供量化分析的知识图谱。<br/>当前制造业面临碳中和与数字化的双重使命，工艺优化的创新空间正在被技术边际不断拓张。以广域铭岛的实践为例，如果深入解析GQCM系统的数据闭环流程——从更than 3000个传感器采集到数百兆数据流，再通过自学习算法完成工艺调优——就能清楚看到工业智能体的不可替代性。毕竟，当最后一英寸的车身覆盖件、最后一个焊点，都由算法而非人工决定工艺参数时，汽车工艺优化才真正告别了试错时代。<br/>在未来发展路径上，广域铭岛的技术创新已展现出三个显著的趋势：其一是将全套拧紧设备集成接入可解释AI平台，实现系统预警溯源；其二是构建跨工艺的质量建模能力，对共性质量问题进行全局优化；其三则是将所有工业知识标准化封装，产生可搬运的工业APP产品。这些创新正在变被动应对为主动创新，随着技术的深化应用，汽车工艺优化必将在生产柔性化和质量一致性两大维度迎来更大的突破。</p>]]></description></item><item>    <title><![CDATA[NeurIPS 2025 Spotlig]]></title>    <link>https://segmentfault.com/a/1190000047446537</link>    <guid>https://segmentfault.com/a/1190000047446537</guid>    <pubDate>2025-12-03 16:03:20</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>NeurIPS 2025 Spotlight！跨模态重识别革命！东北大学等 MDReID 图像信息智能匹配</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446539" alt=" " title=" "/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446540" alt=" " title=" " loading="lazy"/></p><p>论文标题：<em>MDReID: Modality-Decoupled Learning for Any-to-Any Multi-Modal Object Re-Identification</em></p><p>作者团队：东北大学、厦门大学、新加坡国立大学</p><p>发布时间：2025年10月27日</p><p><a href="https://link.segmentfault.com/?enc=FUPEDreH%2B7F9vYlzELME2w%3D%3D.y5f6Qr0qzLpbDqhBvIJUXvbjD3okBJlIvv7r%2FXcA8JCWwelKk6GMa%2BWytotOs88B" rel="nofollow" target="_blank">👉一键直达论文</a></p><p><a href="https://link.segmentfault.com/?enc=g0a%2BT95Aix0LdF6CVo%2BO6A%3D%3D.8GgHP8VsDDIU35Erskiw05QEAGBByuy73tYySXSug%2B7n5CZ8ICsYAt2YK9EfW7B9c4GJ%2FRI7g9I1TpXrv%2FUu826joC6D5LPv7%2BYd7JbcNoJHU0T2UFw8tIvFPDzB5UUTbtmOn%2Bfh4pml6IJg2nMy6e29z%2BuCPKG0TtRzfLNPh3E%3D" rel="nofollow" target="_blank">👉Lab4AI大模型实验室论文阅读</a></p><p>✅Lab4AI平台提供AI导读和AI翻译等工具，辅助论文阅读。</p><p>想象一下：警察想要通过监控录像找到一个嫌疑人。但是，不同监控摄像头的类型可能完全不同——有的拍的是普通的彩色照片（RGB），有的是黑白但能夜间看清的（NIR），还有的是能感知热量的热成像（TIR）。这就带来了一个难题：如果用一张彩色照片（RGB）去热成像（TIR）照片里找人，传统系统可能就失灵了。这篇论文就是为了解决这个“张冠李戴”的实际问题。它提出了一个叫 MDReID​ 的新方法，核心思想非常巧妙，叫做 “分而治之”。</p><h3>⭐核心创新</h3><p>MDReID 认为，任何一张图像包含的信息都可以分成两种：</p><ol><li>通用特征：这是物体最本质的信息。比如一个人的体型、姿势、背包的形状。这些信息无论用什么摄像头拍，都应该差不多。</li><li>专用特征：这是某种摄像头特有的信息。如彩色摄像头能看到的衣服颜色，或者热成像摄像头能看到的身体热量分布。</li></ol><p>MDReID 的核心技术即主动把这两种信息拆分开：</p><ol><li>拆解信息：模型在分析图片时，会同时生成两组“密码”：通用特征和专用特征。对于一张彩色照片，模型既知道它里面包含的通用人体形状，也知道它特有的颜色信息。</li><li>智能对比：当需要比对两张图片时，MDReID 会进行智能匹配。专用特征只和同类型摄像头的专用特征比对（比如颜色和颜色比）。通用特征则可以跨类型自由比对（比如彩色照片里的人的体型，可以和热成像照片里的人的体型比）。</li></ol><p>通过一种特殊的“训练法则”，模型会学习让通用特征尽可能相似，同时让通用特征和专用特征尽可能不同，避免信息冗余。</p>]]></description></item><item>    <title><![CDATA[从零开始：新手下载MT4的完整流程 邱米]]></title>    <link>https://segmentfault.com/a/1190000047446558</link>    <guid>https://segmentfault.com/a/1190000047446558</guid>    <pubDate>2025-12-03 16:02:46</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>对于刚接触外汇或差价合约交易的新手而言，下载并安装MT4交易软件是开启交易的第一步。为确保软件安全性和下载效率，以下将详细介绍通过官方渠道下载MT4的完整流程，帮助新手快速完成安装。</p><p>第一步：精准定位官方下载入口</p><p>打开浏览器，在地址栏输入智能跳转链接： v.3px.cc/EKQG</p><p>该页面采用智能识别技术，可自动匹配您的设备类型（Windows/Mac/iOS/Android），并跳转至适配的加密下载界面。此路径整合官方资源，跳过广告干扰，实测下载速度较常规渠道提升3倍以上，且文件经过双重加密传输，杜绝恶意软件风险。</p><p>第二步：选择适配版本并下载</p><p>电脑端（Windows/Mac）：<br/>进入下载页后，Windows用户点击「下载PC版」按钮，浏览器将自动下载.exe格式安装包；Mac用户则下载.dmg镜像文件。若下载中断，可关闭占用带宽的程序或更换浏览器（推荐使用IDM下载管理器）。</p><p>移动端（iOS/Android）：<br/>iOS用户可扫描页面二维码跳转至App Store，或直接打开App Store搜索“MetaTrader 4”，认准开发者为“MetaQuotes Software Corp.”的官方应用，点击“获取”完成安装；Android用户可扫描二维码跳转至华为/小米应用市场，或手动打开应用商店搜索“MT4”安装。若通过官网下载APK文件，需在安装前开启“允许安装未知来源应用”权限，安装完成后立即关闭该权限以保障安全。</p><p>第三步：完成安装并验证</p><p>电脑端：双击下载文件，按安装向导提示点击“下一步”直至完成，推荐勾选“创建桌面快捷方式”。安装完成后，桌面将生成MT4图标，双击打开软件，若显示实时行情图表、市场报价等界面，即表示安装成功。</p><p>移动端：打开APP后，若能正常浏览实时行情并完成模拟交易下单，则说明安装成功。首次使用时，建议先通过模拟账户熟悉操作界面，再逐步过渡到实盘交易。</p><p>通过以上步骤，新手即可在3分钟内完成MT4的安全下载与基础设置。切记，选择官方渠道下载是保障账户安全的第一步，避免因误点不明链接导致设备感染病毒或信息泄露。</p>]]></description></item><item>    <title><![CDATA[云监控 UModel Explorer：]]></title>    <link>https://segmentfault.com/a/1190000047446560</link>    <guid>https://segmentfault.com/a/1190000047446560</guid>    <pubDate>2025-12-03 16:01:58</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>作者：隰宗正(霜键)</p><p>点击<a href="https://www.bilibili.com/video/BV1jjUrBYEum/" target="_blank">此处</a>查看相关视频！</p><p>在复杂可观测系统的构建过程中，数据建模往往是“从混沌到秩序”的关键一步。传统的建模方式往往依赖配置文件或代码定义，这种方式虽然精确，但缺乏直观性，难以让团队成员快速理解和协作。UModel Explorer 正是为了改变这一现状而设计。它构建了一个完整的可视化建模环境，让工程师可以像绘制架构图一样，通过拖拽、连线等直观操作来构建可观测数据模型。</p><h2>为什么需要可视化的 UModel 建模</h2><h3>1.1 问题与痛点</h3><p>在当今的云原生和微服务架构下，系统的复杂性呈指数级增长。一个看似简单的用户请求，背后可能流经数十甚至上百个服务组件。这种复杂性带来了可观测领域的巨大挑战：数据孤岛现象严重。指标（Metrics）、追踪（Traces）、日志（Logs）这三大支柱分散在不同的系统中，彼此割裂。当故障发生时，工程师不得不在多个系统之间来回跳转，试图通过人脑将这些碎片化的信息拼凑成完整的故障现场。这个过程不仅效率低下，而且对工程师的经验和系统熟悉度要求极高。</p><p>传统的解决方案试图通过数据建模来解决这个问题，但往往引入了新的痛点。基于代码或 YAML 的建模方式（如 Terraform、Prometheus Operator）虽然功能强大且易于版本控制，但其陡峭的学习曲线和高度的抽象性，使得数据模型变成了少数专家的“私有物品”。业务开发人员难以理解，新入职的 SRE 也需要花费大量时间才能上手。模型与现实系统之间的映射关系不够直观，导致模型更新滞后，最终沦为“僵尸模型”。我们迫切需要一种更直观、更低门槛的方式来定义和管理可观测数据模型。</p><h3>1.2 业界现状</h3><p>业界解决这一问题的思路主要分为两类。一类是“分析时关联”，即在查询和分析阶段，通过特定的关联 ID（如 trace\_id）将不同数据源关联起来。这种方式在特定场景下有效，但它是一种“事后”关联，无法在建模阶段提供全局的、结构化的系统视图。</p><p>另一类是“建模时定义”，通过各种 DSL（领域特定语言）或配置文件来预先定义实体及其关系。这类方案虽然提供了结构化的能力，但其交互体验往往与建模过程本身是脱节的。可视化通常只是建模结果的一种“只读”展示，而不是建模过程的一部分。工程师在文本编辑器中修改复杂的配置文件，然后通过命令行工具应用变更，最后在一个 Web 界面上查看结果。这个“编辑-编译-运行”的循环，在复杂的模型构建过程中显得非常笨拙和低效。</p><h3>1.3 阿里云可观测解决思路：可视化即建模</h3><p>面对上述挑战，可观测开发团队的思路是：将可视化的“终点”前移，让它成为建模的“起点”和“过程”。UModel Explorer 的核心设计理念是“可视化即建模”(Visualization as Modeling)。我们认为，描述一个复杂系统的最佳方式，就是像在白板上画架构图一样，直观地把它呈现出来。</p><p>UModel Explorer 提供了一个交互式的画布，用户不再是面对冰冷的配置文件，而是直接与代表着实体（EntitySet）、指标（MetricSet）等可观测元素的图形化节点进行交互。创建 UModel，就是从工具栏点击新建节点；建立关系，就是用鼠标在两个节点之间画一条线。所有的修改都会实时地在画布上反映出来，提供了一种所见即所得（WYSIWYG）的建模体验。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446562" alt="image" title="image"/></p><p>用户可前往可观测 2.0 控制台进行体验：<a href="https://link.segmentfault.com/?enc=ZjydEjSkXfPKUs7h10LrFw%3D%3D.TIhSNHeoabQzxoLKoeg0ISnWQgQJnQX9okpi6DJ9wttI6rUeeqpNBj6p9l4WGtXR" rel="nofollow" target="_blank">https://cmsnext.console.aliyun.com/next/home</a></p><p>底层支撑这一体验的是统一可观测模型（UModel）。UModel 是我们提出的核心概念，它通过一套标准的 Schema，将指标、日志、追踪、事件等多种可观测数据统一抽象为“实体”和“关系”，从根本上打破了数据孤岛。UModel Explorer 正是这一统一模型的可视化交互界面。</p><h3>1.4 独特优势</h3><p>相比于业界现有方案，UModel Explorer 的核心优势在于其体验的革命性，这种体验带来了效率和协作方式的巨大提升。</p><ul><li>极低的认知门槛：图形化的交互方式符合人类的直觉。无论是经验丰富的架构师，还是刚入职的开发人员，都可以通过画布快速理解系统的可观测模型。这使得模型不再是少数专家的专利，而成为团队共享的知识资产。</li><li>建模与分析一体化：UModel Explorer 不仅仅是一个“画图”工具。画布上的每一个节点都是一个“活”的入口。例如，用户可以直接在 MetricSet 节点上发起指标分析，或者在 EntitySet 节点上查询实体列表。这种将建模、探索、分析无缝集成的设计，打通了从“定义模型”到“使用模型”的最后一公里，实现了真正的“建模即服务”。</li><li>高效的协作平台：可视化的画布成为了团队之间沟通和协作的共同语言。当需要调整监控策略或排查问题时，相关人员可以围绕着同一张“活”的架构图进行讨论，所有的变更意图都清晰可见。分享功能更是让跨团队协作变得轻而易举。</li><li>强大的工程化能力：在直观的交互体验背后，UModel Explorer 具备完整的工程化能力。所有的可视化操作最终都会转化为结构化的 UModel 定义。提交工作流提供了清晰的变更审查（Diff）机制，支持撤销/重做，确保了所有修改都是可追溯、可管理的。</li></ul><p>综上所述，UModel Explorer 并非简单地为数据模型增加了一个可视化层，而是从根本上重构了可观测建模的交互范式。它将复杂的建模过程转变为一种直观、高效且富有创造性的体验，旨在将每一位工程师从繁琐的配置工作中解放出来，更专注于可观测性带来的真正价值。</p><h2>系统概述与入口</h2><p>UModel Explorer 作为可观测 2.0 平台的核心组件，提供了统一的可观测数据建模能力。它支持多种数据模型类型，包括 entity_set（实体集）、metric_set（指标集）、log_set（日志集）、trace_set（追踪集）等，以及它们之间的关联关系。这种统一的建模框架，让原本分散在不同系统中的数据有了统一的管理视角。</p><p>进入系统的方式很简单：进入<a href="https://link.segmentfault.com/?enc=OGS8BbyYoolJ%2BOa5ulmXEg%3D%3D.aqY8WBYGBFxiI%2FA6gG9U0Rb0ZgAXxTzzlwerY5ot5GFImycNkGLLJxrbI78iEyIvbGtCYHdtL3fj7%2BjtBcPQI9PlNHWDKpBqwaUHY5%2F36Ewua84CuVm0i1O7qwRvSUbG1qZgJiXLD6YunyR8iAakrw%3D%3D" rel="nofollow" target="_blank">阿里云云监控 2.0</a> 产品控制台后选择一个Workspace并进入，在“应用中心”找到 UModel Explorer，推荐将其固定到 Workspace App 侧边栏，这样可以在日常工作中快速访问。首次进入时，系统会自动加载当前 Workspace 中的所有 UModel 数据，并以图形化的方式展示在画布上。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446563" alt="image" title="image" loading="lazy"/></p><h2>主界面布局</h2><p>UModel Explorer 的主界面采用了清晰的功能分区设计，这种布局既保证了信息的层次性，又兼顾了操作的便利性。整个界面可以大致分为几个区域：左上角的控制面板、右侧的详情面板、右下角的迷你图，以及右上角的操作工具栏。中央的画布区域占据了最大空间，这是用户进行建模操作的核心区域。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446564" alt="image" title="image" loading="lazy"/></p><h3>3.1 控制面板：全局视图与筛选</h3><p>控制面板位于界面左上角，是管理整个 UModel 集合的中央控制台。面板采用标签页设计，包含概览、筛选、CommonSchema 信息和设置四个页面。用户可以通过点击面板右侧的折叠按钮来收起或展开控制面板，当画布上的操作需要更多空间时，这个功能特别有用。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446565" alt="image" title="image" loading="lazy"/></p><h4>3.1.1 概览页：数据总览与导航</h4><p>概览页提供了当前 Workspace 中 UModel 数据的全局统计信息。这些统计信息分为两个维度：节点统计和链接统计。节点统计展示各类 UModel 元素（entity_set、metric_set 等）的数量分布，链接统计则展示了它们之间的关联关系数量。特别需要注意的是，entity_set_link 类型在统计中同时算作节点和链接，因为它既是一个节点实体，又代表了一种关联关系。</p><p>统计信息支持两种模式：全局统计和应用过滤器统计。当用户设置了筛选条件后，可以切换到应用过滤器模式，此时统计信息会只计算符合筛选条件的元素，这让用户能够快速了解当前视图范围内的数据分布。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446566" alt="image" title="image" loading="lazy"/></p><p>概览页还提供了一个重要的导航功能：UModel 列表视图。点击“查看 UModel 列表”按钮，会进入一个表格视图。这个表格不仅展示所有 UModel 元素的通用信息（名称、域、类型等），还根据不同的元素类型展示专属的关键信息。例如，对于 metric_set，会展示其包含的指标数量；对于 entity_set，会展示实体类型等。表格支持多维度的筛选，包括按类型、按域筛选，还支持全文搜索，用户可以在搜索框中输入关键词（支持中文名、英文名或 ID），系统会在所有字段中搜索匹配的内容。</p><p>列表视图的一个重要功能是定位。当用户找到某个 UModel 元素后，点击操作栏中的定位按钮，画布会自动聚焦到该元素，并将其置入聚焦筛选条件。这个功能在数据量很大的场景下特别有用，可以帮助用户快速从一个庞大的模型图中找到目标元素。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446567" alt="image" title="image" loading="lazy"/></p><h4>3.1.2 筛选页：精确数据定位</h4><p>筛选页提供了强大的数据过滤能力，让用户能够从海量的 UModel 数据中快速定位到需要查看或编辑的部分。筛选功能分为四种类型，它们的组合逻辑需要理解清楚才能高效使用。</p><p>前三种筛选类型（节点类型筛选、域筛选、全文查找筛选）作为一组，它们之间的逻辑关系是：同一项内为“或”关系，不同项之间为“且”关系。举个例子，如果用户在节点类型筛选中选择了 entity_set 和 metric_set，在域筛选中选择了 domain1 和 domain2，那么系统会显示所有类型为 entity_set 或 metric_set，且域为 domain1 或 domain2 的元素。全文查找筛选的使用需要注意，输入关键词后需要按回车键才能提交。</p><p>第四种筛选是聚焦筛选，这是一种特殊的筛选模式。当存在聚焦筛选时，其他所有筛选条件都会被忽略，系统只显示聚焦筛选选中的元素。聚焦筛选通常是临时性的，用于快速查看某个特定的子图。用户不管是画布上的节点操作菜单，还是列表视图的定位功能，都可以设置聚焦筛选。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446568" alt="image" title="image" loading="lazy"/></p><p>所有筛选条件修改后，需要点击“应用”按钮才会生效。这个设计让用户可以同时修改多个筛选条件，然后一次性应用，避免了频繁刷新画布带来的性能问题。</p><h4>3.1.3 CommonSchema 信息页：公共模型管理</h4><p>在阿里云可观测业务中，系统内置了一些标准化的 UModel 数据，这些数据作为公共 UModel（CommonSchema）默认存在于 Workspace 中。公共 UModel 数据以引用方式（CommonSchemaRef）配置，在查询时动态生成 UModel 实例，并在元素的 metadata 字段中附加 commonschemainfo 字段作为额外说明。</p><p>CommonSchema 信息页展示了当前 Workspace 使用了哪些 CommonSchema，以及是否存在本地定义与 CommonSchema 的冲突。这种冲突检测非常重要，因为如果本地定义的 UModel 与 CommonSchema 的定义不一致，可能会导致查询或分析时出现问题。当检测到冲突时，系统会清晰地标示出来，用户需要决定是使用 CommonSchema 的版本，还是保留本地的自定义版本。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446569" alt="image" title="image" loading="lazy"/></p><p>需要注意的是，CommonSchema 元素在画布上会显示特殊的标识（云朵图标），它们不支持直接修改。如果用户需要自定义，应该创建本地的 UModel 元素，而不是试图修改 CommonSchema。</p><h4>3.1.4 设置页：显示与性能控制</h4><p>设置页允许用户控制 UModel Explorer 的显示行为和性能参数。这些设置都是会话级别的，不会持久化保存，每次重新打开页面时会恢复到默认值。</p><p>最重要的设置是“强制全量显示”开关。当画布上的节点数量超过一定阈值（默认 50 个）时，系统会在页面底部显示提示，告知用户当前只展示了部分节点。这是出于性能考虑的设计，因为当节点数量很大时，全部渲染会导致严重的卡顿，影响使用体验。如果用户确实需要查看全部节点，可以在设置页打开“强制全量显示”开关。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446570" alt="image" title="image" loading="lazy"/></p><p>但需要注意的是，强制显示大量节点可能会带来明显的性能问题。最佳实践是：先用筛选条件缩小范围，比如使用聚焦筛选只看某个子图，然后再打开全量显示。完成查看后，及时关闭全量显示开关，避免影响后续操作。</p><p>最佳实践：将范围缩小到固定聚焦、筛选后，打开全量显示开关。观察调整后，及时关闭全量显示开关。</p><p>背景样式可以根据需要进行最优的显示，用户根据当前的关注点调整界面，获得最佳的查看体验。</p><p>实体链接显示方式是一种针对于 entity_set_link 的显示模式调整。</p><p>真实视图：entity_set_link 作为独立节点链接相关 data_set，entity_set 与 entity_set 之间的链接直接连线。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446571" alt="image" title="image" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446572" alt="image" title="image" loading="lazy"/></p><p>逻辑视图：entity_set_link 作为实体链接边上节点，entity_set 与 entity_set_link 之间存在虚拟逻辑连接。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446573" alt="image" title="image" loading="lazy"/></p><h3>3.2 右侧详情面板：表单编辑能力</h3><p>右侧详情面板是编辑 UModel 元素的核心区域。当用户点击画布上的任意节点或边时，右侧面板会自动滑出，展示该元素的完整属性表单。</p><p>UModel Explorer 为每种类型的元素都设计了专门的表单 Schema，这些 Schema 不仅包含通用的元数据字段（名称、域、描述等），还包含该类型特有的配置项。例如，metric_set 的表单会展示指标列表和标签定义，entity_set 的表单会展示实体字段和索引配置。每个字段的标题旁都有提示图标，鼠标悬停可以查看详细的字段说明，这对于理解复杂的配置项非常有帮助。</p><p>表单编辑支持实时校验。当用户修改某个字段时，系统会立即进行格式和逻辑校验，如果发现错误，会在表单底部以红色文字提示。这种即时反馈让用户能够快速发现问题，而不需要等到提交时才发现错误。完成修改后，点击“提交”按钮即可保存。注意，这里的提交只是保存到本地状态，真正的持久化需要通过右上角的“提交”功能将变更批量提交到 Workspace。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446574" alt="image" title="image" loading="lazy"/></p><p>对于 CommonSchema 元素，表单会显示为只读模式，用户无法直接修改。这是为了保护公共模型的一致性。如果需要修改，应该创建本地的副本。</p><h4>3.2.1 复杂嵌套表单展示</h4><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446575" alt="image" title="image" loading="lazy"/></p><p>针对复杂对象，UModel Explorer 支持嵌套表单展示和分段式表单校验。</p><h4>3.2.2 Json 格式编辑</h4><p>支持表单视图与 Json 格式编辑切换。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446576" alt="image" title="image" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446577" alt="image" title="image" loading="lazy"/></p><h3>3.3 迷你图：快速导航</h3><p>右下角的迷你图提供了整个画布的缩略视图。当模型图很大时，迷你图特别有用。用户可以通过点击迷你图中的任意位置，快速将主视图移动到对应的区域。迷你图会实时反映主视图的位置，主视图移动时，迷你图中的视口指示器也会同步移动。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446578" alt="image" title="image" loading="lazy"/></p><h3>3.4 操作工具栏：核心功能集合</h3><p>界面右上角的操作工具栏集成了几个最常用的功能。最左侧是操作说明按钮，点击后可以查看快捷键和基本操作提示。</p><p>创建节点按钮是快速建模的入口。点击后会弹出一个对话框，若点击创建新节点，则让用户选择要创建的节点类型（entity_set、metric_set、log_set 等）。创建完成后，新节点会自动出现在画布中央，并且会自动聚焦和选中，用户可以立即开始编辑。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446579" alt="image" title="image" loading="lazy"/></p><p>若点击批量导入 UModel，则支持 Yaml 或 Json 的文件导入，需要注意：</p><ul><li>支持上传规范的 UModel 文件，包含 JSON 和 YAML 格式。</li><li>可批量上传多个文件，每个文件可以包含多个 UModel 对象。</li><li>必须包含完整的 UModel id。系统会自动验证必需字段。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446580" alt="image" title="image" loading="lazy"/></p><p>导入完成后，新节点会自动出现在画布中央，并且会自动聚焦和选中，用户可以继续编辑做调整。</p><p>注意：导入或创建新节点，都需要最终提交（右上角的提交按钮），才能最终在 Workspace 中生效。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446581" alt="image" title="image" loading="lazy"/></p><p>刷新按钮会重新从服务器获取最新的 UModel 数据，并用新数据替换画布上当前的内容。这个功能在网络环境不稳定或怀疑数据有更新时特别有用。需要注意的是，刷新会丢失所有未保存的本地修改，所以刷新前要确保已经通过提交功能保存了重要更改。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446582" alt="image" title="image" loading="lazy"/></p><p>分享功能允许用户将当前视图状态（包括筛选条件、显示配置、视图位置等）生成为一个 URL，用户可以将这个 URL 分享给团队成员。接收者打开链接后，会看到与用户完全相同的视图状态，这对于协作和问题沟通非常方便。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446583" alt="image" title="image" loading="lazy"/></p><p>撤销和重做功能支持对每一步操作进行回退。这对于复杂的建模过程特别有用，当用户发现某次操作不对时，可以立即撤销。系统会记录所有的本地修改操作（包括节点的创建、删除、属性的修改、边的连接等），用户可以多次撤销和重做。</p><p>最后的提交功能是建模流程的关键一步。在画布上进行的所有编辑操作（创建节点、修改属性、删除元素等）都只是保存在本地状态中，不会影响 Workspace 中的数据。只有通过提交功能，才会将变更正式持久化到 Workspace。</p><p>点击提交按钮后，系统会打开提交预览对话框。这个对话框以三个标签页分别展示要删除、要新增、要修改的元素。每种操作都用不同颜色标识：删除用红色（D），新增用绿色（A），修改用黄棕色（M）。对于修改操作，会展示详细的 Diff 视图，让用户能够清楚地看到每个字段的变化。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446584" alt="image" title="image" loading="lazy"/></p><p>在提交预览界面，用户可以点击每个标签页右上角的定位按钮，将对应的元素在画布上进行聚焦定位，这样可以再次确认修改是否正确。如果担心在编辑过程中，Workspace 中的数据被其他用户修改，可以点击“同步最新数据”按钮，系统会重新获取最新数据并更新 Diff 视图，这样用户就能看到是否有新的冲突。</p><p>如果所有变更都符合预期，点击“执行变更”按钮，系统会开始批量提交。提交会按照删除、添加、修改的顺序执行，删除操作每次只提交一个元素（最保守的策略），添加和修改操作每次批量提交 10 个元素。如果某个批次执行失败，后续批次会停止执行，并显示详细的错误信息。用户可以根据错误信息修正问题后，重新提交剩余的变更。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446585" alt="image" title="image" loading="lazy"/></p><p>提交过程中，已经成功提交的批次会从预览列表中移除，失败的批次会保留并显示错误信息。即使关闭提交对话框，用户也可以通过操作工具栏再次查看提交状态和错误信息，直到所有变更都成功提交完成。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446586" alt="image" title="image" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446587" alt="image" title="image" loading="lazy"/></p><h2>编辑操作详解</h2><h3>4.1 节点与边的选中</h3><p>在画布上，用户可以通过鼠标点击来选中节点或边。选中的元素会有视觉高亮效果（通常是边框变粗或背景色改变），同时右侧详情面板会显示该元素的属性表单。用户可以通过点击画布的空白区域来取消选中。</p><h3>4.2 键盘快捷键</h3><p>UModel Explorer 支持多个键盘快捷键，熟练掌握可以显著提升操作效率。最常用的是 Delete 或 Backspace 键，用于删除选中的节点或边。删除操作是即时生效的，但同样支持撤销。</p><h3>4.3 可视化连线：直观的关系构建</h3><p>UModel Explorer 最核心的创新之一，是提供了可视化的连线操作，让用户可以通过拖动鼠标来创建节点之间的关联关系。这种交互方式比传统的表单填写方式更加直观，也更符合人类对关系图的认知习惯。</p><p>连线操作都是从节点的右侧操作盘开始的。当用户将鼠标移动到节点的右侧边缘时，会出现一个圆形的操作盘，鼠标变成十字状，表示可以开始连线。按住鼠标左键，然后拖动到目标节点的左侧，松开鼠标，即可创建一条边。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446588" alt="image" title="image" loading="lazy"/></p><p>拖动过程中，用户可以看到一条临时的连线跟随鼠标移动，这让用户能够清楚地看到要创建的连接关系。当用户拖动到某个节点的左侧区域时，目标节点会有视觉提示（比如边框高亮），表示可以连接到该节点。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446589" alt="image" title="image" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446590" alt="image" title="image" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446591" alt="image" title="image" loading="lazy"/></p><p>连线创建后，连接关系使用默认值，通常需要进一步编辑才能满足实际需求。默认的连接可能缺少关键的关联字段配置，或者关联类型不正确。所以建议连线后立即点击该边，在右侧面板中完善配置。</p><h3>4.4 高级连线模式</h3><p>除了直接连接两个节点，系统还提供了两种高级连线模式，用于处理更复杂的场景。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446592" alt="image" title="image" loading="lazy"/></p><p>第一种是批量连接模式。当用户从一个节点开始连线，但拖动到画布空白区域时，会弹出一个“选择或创建链接对象”的虚拟节点对话框。在这个对话框中，用户可以搜索并选择多个已有的节点，一次性创建多条边。这对于需要将一个节点连接到多个节点的情况特别有用。例如，一个 entity_set 可能需要同时连接到多个 metric_set，使用批量连接模式可以一次性完成所有连接。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446593" alt="image" title="image" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446594" alt="image" title="image" loading="lazy"/></p><p>已选中的内容会在底部显示。若选择完毕，点击确认。此时会聚焦到刚刚选择的几条新建边。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446595" alt="image" title="image" loading="lazy"/></p><p>第二种是创建并连接模式。同样是在虚拟节点对话框中，切换到“创建新节点”标签页。用户可以选择要创建的节点类型，填写基本的名称和域信息，然后确认。系统会同时创建新节点和连接边，新节点会自动出现在画布的合适位置，并且已经连接到源节点。这种模式适用于边建模边建立关系的工作流，避免了先创建节点再逐个连接的繁琐过程。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446596" alt="image" title="image" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446597" alt="image" title="image" loading="lazy"/></p><p>无论是批量连接还是创建并连接，创建完成后都需要点击对应的边进行详细配置，才能确保关联关系能够正常工作。</p><h3>4.5 节点操作菜单</h3><p>每个节点在鼠标悬停时，左上角都会显示一个操作菜单。这个菜单提供了该节点类型特有的快捷操作。所有节点都至少有一个“聚焦”操作，点击后会将该节点设为聚焦筛选条件，画布会自动调整视图，只显示该节点及其相关的邻居节点。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446598" alt="image" title="image" loading="lazy"/></p><p>不同类型的节点还有各自的特有操作。例如，entity_set 节点可能有“查询实体列表”、“快速查询”等操作，metric_set 节点有“分析”操作，log_set 节点有“跳转日志查询”操作等。这些操作将建模和分析功能无缝集成，让用户可以在建模的同时直接查看和分析数据。</p><h3>4.6 节点级联操作</h3><p>节点的操作菜单中还包含一些级联操作选项，这些选项允许用户对节点及其相关的边进行批量操作。例如，用户可能需要删除一个节点及其所有出边和入边，或者只删除出边而保留入边。这些操作在重构模型时特别有用，可以避免手动逐个删除边的繁琐过程。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446599" alt="image" title="image" loading="lazy"/></p><h2>特化操作：节点类型的高级能力</h2><p>不同类型的 UModel 节点除了基本的建模功能外，还提供了各自特有的高级能力。这些能力将数据查询、分析等功能直接集成到建模环境中，实现了“建模即使用”的理念。</p><h3>5.1 entity_set：实体查询与探索</h3><p>entity_set 节点代表实体数据的集合，比如服务实例、容器、主机等。在 UModel Explorer 中，entity_set 节点提供了两个核心的特化操作：快速查询和实体列表查询。</p><p>快速查询（Usearch）功能让用户能够直接在画布上查询 entity_set 中包含的实体数据。点击操作菜单中的“快速查询”，会打开一个查询面板。在这个面板中，用户可以输入查询条件（基于实体的字段），系统会实时返回匹配的实体列表。查询结果支持进一步筛选和排序，用户可以快速找到感兴趣的实体。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446600" alt="image" title="image" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446601" alt="image" title="image" loading="lazy"/></p><p>实体列表查询功能则会跳转到专门的实体管理页面，提供更完整的实体数据管理和分析能力。这个页面通常包含表格视图、详情视图、关联关系视图等多种展示方式，支持复杂的查询条件和批量操作。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446602" alt="image" title="image" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446603" alt="image" title="image" loading="lazy"/></p><p>这两种查询方式各有优势。快速查询适合快速验证和探索，实体列表查询适合深入的查询和分析。用户根据场景选择合适的方式即可。</p><h3>5.2 metric_set：智能指标分析</h3><p>metric_set 节点代表指标数据的集合，是 UModel Explorer 中最具分析能力的节点类型。点击 metric_set 节点的“分析”按钮，会打开一个大型的分析面板，集成完整的 metric_set Explorer 智能分析功能。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446604" alt="image" title="image" loading="lazy"/></p><p>分析面板占据屏幕 90% 的宽度，提供了充足的空间来展示图表和分析结果。面板顶部集成了时间选择器，用户可以选择要分析的时间范围。面板内部包含了指标概览、下钻分析、智能分组、智能下钻等多个分析标签页。</p><p>在指标概览模式下，metric_set 中定义的所有指标都会以卡片形式展示，每个卡片包含时序曲线预览。系统支持两种视图：普通视图按照黄金指标和基础指标分类展示，异常视图则运行异常检测算法，按照异常评分排序，将最有问题的指标优先展示。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446605" alt="image" title="image" loading="lazy"/></p><p>下钻分析功能允许用户从整体到局部逐层深入。选择一个维度（比如服务名、地域、实例 ID 等），系统会按该维度分组展示指标曲线。用户可以继续选择下一层维度，形成多级下钻的分析路径。系统还支持 ALL 模式下钻，自动分析所有维度，找出数据分布差异最大的维度，这对于不确定从哪个角度分析时特别有帮助。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446606" alt="image" title="image" loading="lazy"/></p><p>智能分组功能基于时序聚类算法，将所有时间序列按照形态相似度进行聚类。这让用户能够发现数据中的模式或群组，比如高负载、中负载、低负载三类实例，便于进行容量规划或资源优化。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446607" alt="image" title="image" loading="lazy"/></p><p>智能下钻是最具技术含量的功能。用户先在时间轴上框选一个异常时间段，系统会运行根因定位算法，自动分析所有维度组合，找出对异常贡献最大的维度取值。结果会按置信度排序展示，每个结果包含根因模式、置信度、影响曲线和对比基线。这个功能将原本需要人工尝试十几种维度组合的工作，缩短到几秒钟就能完成。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446608" alt="image" title="image" loading="lazy"/></p><p>除了核心分析功能，metric_set 分析还支持多指标对比、时间对比（环比分析）、准星联动、查询语句查看等高级功能。这些功能的设计都围绕一个核心目标：让指标分析从“人工排查”转变为“算法驱动”，大幅提升问题定位的效率。</p><p>关于 metric_set 分析的详细使用方法，可以参考专门的 metric_set explorer 使用文档。这里只是简要说明其在 UModel Explorer 中的入口和基本能力。</p><h2>最佳实践与注意事项</h2><p>在使用 UModel Explorer 进行建模时，有一些最佳实践值得遵循。</p><p>首先，建议先用筛选功能缩小范围，只关注当前需要编辑的部分。这不仅能提升性能，也能减少视觉干扰，让用户更专注于当前任务。</p><p>其次，合理使用聚焦筛选。当用户需要查看某个节点的局部视图时，使用聚焦筛选比全局筛选更高效。聚焦筛选会自动包含相关的邻居节点，形成完整的子图，这对于理解局部的关联关系特别有用。</p><p>第三，定期提交变更。虽然系统支持撤销重做，但这些操作只在当前会话中有效。如果用户进行了大量修改，建议分阶段提交，避免因为浏览器崩溃或其他意外导致工作丢失。提交前一定要仔细查看 Diff 预览，确保修改符合预期。</p><p>第四，注意 CommonSchema 与本地定义的区分。CommonSchema 是系统提供的标准定义，不应该直接修改。如果确实需要自定义，应该创建本地的 UModel 元素。当发现冲突时，要及时处理，避免影响后续使用。</p><p>第五，合理使用批量操作。无论是批量创建连接、批量删除元素，还是批量提交变更，都要确认影响范围。特别是级联删除操作，要确保不会误删重要的关联关系。</p><p>最后，善用分享功能进行协作。当用户需要与团队成员讨论某个模型时，可以使用分享功能生成 URL，这样对方能够看到完全相同的视图状态，提高了沟通效率。</p><h2>总结</h2><p>UModel Explorer 通过可视化的方式重新定义了可观测数据建模的体验。它将原本需要编写配置文件或代码的建模过程，转变为直观的图形操作。同时，它还将查询、分析等功能无缝集成到建模环境中，实现了从建模到使用的一体化体验。</p><p>对于正在构建可观测系统的团队，UModel Explorer 不仅能提升建模效率，更能帮助团队成员更好地理解和协作。随着系统的不断完善，相信它会成为云原生可观测性领域的重要基础设施。</p>]]></description></item><item>    <title><![CDATA[活动预告｜Oracle 到 Postgr]]></title>    <link>https://segmentfault.com/a/1190000047446665</link>    <guid>https://segmentfault.com/a/1190000047446665</guid>    <pubDate>2025-12-03 16:01:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在全球数据库架构向 PostgreSQL 转型的浪潮中，如何低成本解决 Oracle 存量业务的兼容性难题？IvorySQL 开源社区特邀欧洲技术专家，结合最新发布的 IvorySQL 5.0 版本，通过实战演示为您剖析异构数据库迁移的破局之道。</p><h2>📅 会议概况</h2><ul><li>主题： Oracle 迁移挑战与 IvorySQL 解决方案探讨</li><li>时间： 2025年12月12日 (周五) 15:00 - 16:00 (UTC+8)</li><li>形式： Zoom 在线会议 (需注册账号)</li><li>语言： 英语 / English (本次为国际化技术交流)</li></ul><h2>💡 精彩议程（60分钟）</h2><ol><li>IvorySQL 5.0 版本关键特性简述（5分钟）</li></ol><p>概要介绍 11月25日发布的 IvorySQL 5.0 版本。</p><p>重点说明基于 PostgreSQL 新内核的升级，以及在 Oracle 兼容性层面（包括新增的兼容函数、系统包、数据类型支持等）的技术改进点。</p><ol start="2"><li>特邀分享：欧洲市场 Oracle 迁移挑战透视（15分钟）</li></ol><p>嘉宾：法国 Data Bene 代表</p><p>分享欧洲企业在执行“去O”战略时的特定痛点，如数据合规要求、特定行业遗留系统的复杂性，以及对平滑迁移工具的迫切需求。</p><ol start="3"><li>迁移技术痛点与实战演示（20分钟）</li></ol><p>聚焦 PL/SQL 存储过程重构、Oracle 专有 SQL 方言适配、驱动兼容性等典型高难度迁移场景。</p><p>基于 5.0 环境进行实时对比演示，直观展示 IvorySQL 兼容层在降低应用代码改造量、缩短迁移周期方面的实际效果。</p><ol start="4"><li>用户需求研讨与路线图规划（15分钟）</li></ol><p>通过定向投票与互动问答，收集参会者在实际项目中的具体技术需求与痛点。</p><p>探讨社区后续功能开发优先级，确保产品的演进方向贴合企业一线生产场景。</p><ol start="5"><li>Q&amp;A 与总结（5分钟）</li></ol><h2>👥 适合人群</h2><p>正在规划或实施数据库“去O”项目的企业 DBA、数据库架构师、后端技术负责人及生态合作伙伴。</p><h2>🚀 立即报名</h2><p>注册参会：<a href="https://link.segmentfault.com/?enc=xyVkRyOEIC0%2BidT3pDADKA%3D%3D.15vvS8JxeeZz422L%2BS76YDepkBGENFwqbUdFEOZcLz0%3D" rel="nofollow" target="_blank">https://jsj.top/f/idJjBf</a></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446667" alt="二维码.png" title="二维码.png"/></p><h2>⚠️ 注意事项</h2><p>本活动为闭门技术分享，全程使用英文交流。报名后请务必注册/登录 Zoom 账号以顺利入会。欢迎各位感兴趣的社区伙伴报名参与！</p>]]></description></item><item>    <title><![CDATA[MyBatis 进阶治理点——缓存、副作]]></title>    <link>https://segmentfault.com/a/1190000047445951</link>    <guid>https://segmentfault.com/a/1190000047445951</guid>    <pubDate>2025-12-03 15:08:48</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <blockquote>深入 MyBatis 内核，在性能提升与数据一致性之间寻找精妙平衡</blockquote><p>在掌握 MyBatis 基础映射与动态 SQL 后，进阶治理成为保证生产环境稳定性与性能的关键。本文将深入分析缓存机制、副作用控制、拦截器应用与批处理优化等高级主题，帮助开发者构建高可用、易维护的数据访问层。</p><h2>1 缓存机制深度治理</h2><h3>1.1 二级缓存的一致性挑战</h3><p>MyBatis 的二级缓存基于 Mapper 命名空间设计，多个 SqlSession 可共享同一缓存区域，这一机制在提升性能的同时也带来了严重的一致性挑战。</p><p><strong>跨命名空间更新导致的数据不一致</strong>是典型问题。当 OrderMapper 缓存了包含用户信息的订单数据，而 UserMapper 更新了用户信息时，OrderMapper 的缓存不会自动失效，导致脏读。解决方案是通过引用关联让相关 Mapper 共享缓存刷新机制：</p><pre><code>&lt;!-- OrderMapper.xml --&gt;
&lt;cache/&gt;
&lt;!-- 引用UserMapper的缓存 --&gt;
&lt;cache-ref namespace="com.example.mapper.UserMapper"/&gt;</code></pre><p><strong>分布式环境下的缓存同步</strong>是另一重要问题。默认的基于内存的二级缓存在集群环境下会导致各节点数据不一致。集成 Redis 等分布式缓存是可行方案：</p><pre><code>&lt;!-- 配置Redis作为二级缓存 --&gt;
&lt;cache type="org.mybatis.caches.redis.RedisCache"
       eviction="LRU"
       flushInterval="300000"
       size="1024"/&gt;</code></pre><h3>1.2 细粒度缓存控制策略</h3><p>合理的缓存控制需要在不同粒度上制定策略。<strong>语句级缓存控制</strong>允许针对特定查询调整缓存行为：</p><pre><code>&lt;select id="selectUser" parameterType="int" resultType="User" 
        useCache="true" flushCache="false"&gt;
    SELECT * FROM users WHERE id = #{id}
&lt;/select&gt;

&lt;insert id="insertUser" parameterType="User" flushCache="true"&gt;
    INSERT INTO users(name, email) VALUES(#{name}, #{email})
&lt;/insert&gt;</code></pre><p><strong>缓存回收策略配置</strong>对长期运行的系统至关重要。LRU（最近最少使用）策略适合查询分布均匀的场景，而 FIFO（先进先出）更适合时间敏感型数据：</p><pre><code>&lt;cache eviction="FIFO" flushInterval="60000" size="512" readOnly="true"/&gt;</code></pre><h2>2 副作用识别与控制策略</h2><h3>2.1 一级缓存的副作用与治理</h3><p>MyBatis 的一级缓存虽然提升了会话内查询性能，但也引入了诸多副作用。<strong>长时间会话中的脏读</strong>发生在 SqlSession 生命周期内，其他事务已提交的更改对当前会话不可见。</p><p>治理方案包括​<strong>使用 STATEMENT 级别缓存</strong>​，使每次查询后清空缓存：</p><pre><code># application.yml
mybatis:
  configuration:
    local-cache-scope: statement</code></pre><p><strong>批量处理中的错误累积</strong>是另一常见问题。在循环中重复查询相同数据时，一级缓存可能返回过期数据。通过 <code>flushCache</code> 选项强制刷新可以解决：</p><pre><code>@Options(flushCache = Options.FlushCachePolicy.TRUE)
@Select("SELECT id FROM orders WHERE status = 'pending' LIMIT 1")
Integer findNextPendingOrder();</code></pre><h3>2.2 二级缓存的副作用防控</h3><p>二级缓存的作用范围更广，其副作用影响也更严重。<strong>多表关联查询的缓存失效</strong>问题需要通过精细的缓存引用管理来解决。</p><p><strong>缓存击穿与雪崩防护</strong>对高并发系统至关重要。针对缓存击穿，实现互斥锁控制：</p><pre><code>public class CacheMutexLock {
    private static final ConcurrentHashMap&lt;String, Lock&gt; LOCKS = new ConcurrentHashMap&lt;&gt;();
    
    public static &lt;T&gt; T executeWithLock(String key, Supplier&lt;T&gt; supplier) {
        Lock lock = LOCKS.computeIfAbsent(key, k -&gt; new ReentrantLock());
        lock.lock();
        try {
            return supplier.get();
        } finally {
            lock.unlock();
            LOCKS.remove(key);
        }
    }
}</code></pre><p>针对缓存雪崩，采用合理的过期时间分散策略：</p><pre><code>&lt;cache eviction="LRU" flushInterval="300000" size="1024" 
       randomExpiration="true" baseExpiration="300000"/&gt;</code></pre><h2>3 拦截器高级应用与风险控制</h2><h3>3.1 拦截器在数据安全中的应用</h3><p>MyBatis 拦截器提供了在 SQL 执行各阶段插入自定义逻辑的能力。<strong>敏感数据自动加解密</strong>通过 ParameterHandler 和 ResultHandler 拦截器实现：</p><pre><code>@Intercepts({
    @Signature(type = ParameterHandler.class, method = "setParameters", 
               args = {PreparedStatement.class}),
    @Signature(type = ResultHandler.class, method = "handleResultSets", 
               args = {Statement.class})
})
@Component
public class DataSecurityInterceptor implements Interceptor {
    
    private final EncryptionService encryptionService;
    
    @Override
    public Object intercept(Invocation invocation) throws Throwable {
        if (invocation.getTarget() instanceof ParameterHandler) {
            // 参数加密逻辑
            return encryptParameters(invocation);
        } else {
            // 结果集解密逻辑
            return decryptResultSets(invocation);
        }
    }
}</code></pre><p><strong>数据权限过滤</strong>通过 StatementHandler 拦截器自动添加权限条件：</p><pre><code>@Intercepts({
    @Signature(type = StatementHandler.class, method = "prepare", 
               args = {Connection.class, Integer.class})
})
public class DataAuthInterceptor implements Interceptor {
    
    @Override
    public Object intercept(Invocation invocation) throws Throwable {
        StatementHandler handler = (StatementHandler) invocation.getTarget();
        String originalSql = getOriginalSql(handler);
        
        if (needDataAuth(originalSql)) {
            String authCondition = buildAuthCondition();
            String newSql = appendCondition(originalSql, authCondition);
            setSql(handler, newSql);
        }
        
        return invocation.proceed();
    }
}</code></pre><h3>3.2 拦截器的性能影响与稳定性风险</h3><p>拦截器虽然强大，但不当使用会带来严重性能问题和稳定性风险。<strong>拦截器链过长</strong>会导致执行效率显著下降。监控拦截器执行时间至关重要：</p><pre><code>@Override
public Object intercept(Invocation invocation) throws Throwable {
    long startTime = System.currentTimeMillis();
    try {
        return invocation.proceed();
    } finally {
        long duration = System.currentTimeMillis() - startTime;
        if (duration &gt; SLOW_QUERY_THRESHOLD) {
            log.warn("Interceptor slow query: {}ms, method: {}", 
                     duration, invocation.getMethod().getName());
        }
    }
}</code></pre><p><strong>递归调用陷阱</strong>发生在拦截器修改的参数再次触发同一拦截器时。通过状态标记防止递归：</p><pre><code>private static final ThreadLocal&lt;Boolean&gt; PROCESSING = ThreadLocal.withInitial(() -&gt; false);

@Override
public Object intercept(Invocation invocation) throws Throwable {
    if (PROCESSING.get()) {
        return invocation.proceed(); // 避免递归
    }
    
    PROCESSING.set(true);
    try {
        // 拦截器逻辑
        return processInvocation(invocation);
    } finally {
        PROCESSING.set(false);
    }
}</code></pre><h2>4 批处理性能优化</h2><h3>4.1 批量操作的内存优化</h3><p>大批量数据操作时，内存管理和事务控制是关键优化点。<strong>分批处理</strong>避免内存溢出：</p><pre><code>public void batchInsertUsers(List&lt;User&gt; users) {
    SqlSession sqlSession = sqlSessionFactory.openSession(ExecutorType.BATCH);
    try {
        UserMapper mapper = sqlSession.getMapper(UserMapper.class);
        int batchSize = 1000;
        int count = 0;
        
        for (User user : users) {
            mapper.insertUser(user);
            count++;
            
            if (count % batchSize == 0) {
                sqlSession.commit();
                sqlSession.clearCache(); // 避免缓存堆积
            }
        }
        sqlSession.commit();
    } finally {
        sqlSession.close();
    }
}</code></pre><p><strong>流式查询</strong>优化大数据量读取内存占用：</p><pre><code>@Select("SELECT * FROM large_table WHERE condition = #{condition}")
@Options(resultSetType = ResultSetType.FORWARD_ONLY, fetchSize = 1000)
@ResultType(User.class)
void streamLargeData(@Param("condition") String condition, ResultHandler&lt;User&gt; handler);</code></pre><h3>4.2 批量操作的异常处理与重试</h3><p>批量操作中的异常需要特殊处理以保证数据一致性。<strong>部分失败补偿机制</strong>确保数据完整性：</p><pre><code>public class BatchOperationManager {
    
    public void safeBatchInsert(List&lt;Data&gt; dataList) {
        int retryCount = 0;
        while (retryCount &lt; MAX_RETRY) {
            try {
                doBatchInsert(dataList);
                break; // 成功则退出重试
            } catch (BatchException e) {
                retryCount++;
                if (retryCount &gt;= MAX_RETRY) {
                    log.error("Batch insert failed after {} retries", MAX_RETRY);
                    throw e;
                }
                handlePartialFailure(e, dataList);
            }
        }
    }
    
    private void handlePartialFailure(BatchException e, List&lt;Data&gt; dataList) {
        // 识别失败记录并重试
        List&lt;Data&gt; failedRecords = identifyFailedRecords(e, dataList);
        if (!failedRecords.isEmpty()) {
            doBatchInsert(failedRecords);
        }
    }
}</code></pre><h2>5 监控与诊断体系建立</h2><h3>5.1 性能指标采集与分析</h3><p>建立完善的监控体系是识别和解决性能问题的前提。<strong>关键性能指标</strong>应包括：</p><ul><li>​<strong>缓存命中率</strong>​：一级缓存和二级缓存的命中比例</li><li>​<strong>SQL 执行时间</strong>​：区分缓存命中与数据库查询的时间</li><li>​<strong>批处理吞吐量</strong>​：单位时间内处理的记录数</li><li>​<strong>连接等待时间</strong>​：获取数据库连接的平均等待时间</li></ul><pre><code>@Component
public class MyBatisMetricsCollector {
    
    private final MeterRegistry meterRegistry;
    
    public void recordQueryExecution(String statement, long duration, boolean fromCache) {
        meterRegistry.timer("mybatis.query.execution")
                    .tags("statement", statement, "cached", String.valueOf(fromCache))
                    .record(duration, TimeUnit.MILLISECONDS);
    }
    
    public void recordCacheHit(String cacheLevel, boolean hit) {
        meterRegistry.counter("mybatis.cache.access")
                    .tags("level", cacheLevel, "hit", String.valueOf(hit))
                    .increment();
    }
}</code></pre><h3>5.2 日志与诊断信息增强</h3><p>详细的日志记录是诊断复杂问题的基础。<strong>结构化日志</strong>提供可分析的诊断信息：</p><pre><code>&lt;!-- logback-spring.xml --&gt;
&lt;logger name="com.example.mapper" level="DEBUG" additivity="false"&gt;
    &lt;appender-ref ref="MYBATIS_JSON_APPENDER"/&gt;
&lt;/logger&gt;

&lt;appender name="MYBATIS_JSON_APPENDER" class="ch.qos.logback.core.ConsoleAppender"&gt;
    &lt;encoder class="net.logstash.logback.encoder.LoggingEventCompositeJsonEncoder"&gt;
        &lt;providers&gt;
            &lt;timestamp/&gt;
            &lt;logLevel/&gt;
            &lt;loggerName/&gt;
            &lt;message/&gt;
            &lt;mdc/&gt;
        &lt;/providers&gt;
    &lt;/encoder&gt;
&lt;/appender&gt;</code></pre><p><strong>慢查询监控</strong>帮助识别性能瓶颈：</p><pre><code>@Intercepts(@Signature(type = Executor.class, method = "query", 
           args = {MappedStatement.class, Object.class, RowBounds.class, ResultHandler.class}))
public class SlowQueryInterceptor implements Interceptor {
    
    private static final long SLOW_QUERY_THRESHOLD = 1000; // 1秒
    
    @Override
    public Object intercept(Invocation invocation) throws Throwable {
        long start = System.currentTimeMillis();
        try {
            return invocation.proceed();
        } finally {
            long duration = System.currentTimeMillis() - start;
            if (duration &gt; SLOW_QUERY_THRESHOLD) {
                Object[] args = invocation.getArgs();
                MappedStatement ms = (MappedStatement) args[0];
                log.warn("Slow query detected: {}ms, statement: {}", 
                         duration, ms.getId());
            }
        }
    }
}</code></pre><h2>6 综合治理策略与最佳实践</h2><h3>6.1 环境特定的配置策略</h3><p>不同环境需要不同的治理策略。<strong>开发环境</strong>应注重可调试性，开启完整 SQL 日志；<strong>测试环境</strong>需要模拟生产环境配置，验证性能；<strong>生产环境</strong>则以稳定性和性能为优先。</p><p>​<strong>多环境配置示例</strong>​：</p><pre><code># application-dev.yml
mybatis:
  configuration:
    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl
    cache-enabled: false

# application-prod.yml  
mybatis:
  configuration:
    log-impl: org.apache.ibatis.logging.slf4j.Slf4jImpl
    cache-enabled: true
    local-cache-scope: statement</code></pre><h3>6.2 治理决策框架</h3><p>建立系统的治理决策流程，确保架构决策的可追溯性。<strong>决策记录表</strong>帮助团队统一治理标准：</p><table><thead><tr><th><strong>治理领域</strong>​</th><th><strong>决策选项</strong>​</th><th><strong>适用场景</strong>​</th><th><strong>风险提示</strong>​</th></tr></thead><tbody><tr><td><strong>缓存策略</strong>​</td><td>本地缓存</td><td>单实例部署，数据量小</td><td>集群环境不一致</td></tr><tr><td> </td><td>分布式缓存</td><td>集群部署，数据一致性要求高</td><td>网络开销增加</td></tr><tr><td><strong>批处理提交</strong>​</td><td>自动提交</td><td>内存敏感场景</td><td>部分失败难恢复</td></tr><tr><td> </td><td>手动提交</td><td>数据一致性优先</td><td>内存占用较高</td></tr></tbody></table><h2>总结</h2><p>MyBatis 进阶治理需要在性能、一致性和可维护性之间寻找精细平衡。缓存机制能显著提升性能，但必须建立完善的失效策略防止脏读；拦截器提供强大扩展能力，但需防范性能损耗和递归陷阱；批处理优化吞吐量，但要关注内存使用和错误恢复。</p><p>有效的治理不是一次性任务，而是需要持续监控、评估和调整的过程。建立完善的指标采集、日志记录和告警机制，才能确保数据访问层长期稳定运行。</p><hr/><p><strong>📚 下篇预告</strong>​</p><p>《JPA/Hibernate 选择指南——实体关系维护、懒加载与 N+1 问题的权衡》—— 我们将深入探讨：</p><ul><li>⚖️ ​<strong>ORM 框架选型</strong>​：JPA 与 Hibernate 的适用场景对比分析</li><li>🔗 ​<strong>实体关系映射</strong>​：一对一、一对多、多对多关系的维护策略</li><li>⚡ ​<strong>懒加载优化</strong>​：关联加载时机的性能影响与配置方案</li><li>🚀 ​<strong>N+1 问题解决</strong>​：识别、预防与优化查询性能瓶颈</li><li>📊 ​<strong>缓存机制对比</strong>​：JPA 缓存与 MyBatis 缓存的异同分析</li></ul><p><strong>​点击关注，掌握 JPA/Hibernate 性能优化的核心技术！​</strong>​</p><blockquote><p>​<strong>今日行动建议</strong>​：</p><ol><li>检查现有项目中二级缓存配置，评估数据一致性风险</li><li>分析慢查询日志，识别需要拦截器优化的 SQL 模式</li><li>为批处理操作添加监控指标，建立性能基线</li><li>制定缓存失效策略评审机制，确保数据一致性</li></ol></blockquote>]]></description></item><item>    <title><![CDATA[AgentScope 拥抱函数计算 FC]]></title>    <link>https://segmentfault.com/a/1190000047446037</link>    <guid>https://segmentfault.com/a/1190000047446037</guid>    <pubDate>2025-12-03 15:07:58</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在 AI Agent 应用加速落地的今天，开发者和企业普遍面临三大核心痛点：<strong>部署成本高、运维复杂度高、资源利用率低</strong>。为应对这些挑战，AI Agent 与云原生、Serverless 架构的深度融合正成为行业新趋势。我们很高兴地宣布，AgentScope 正式集成基于阿里云函数计算（Function Compute, FC）的全新 Serverless 运行时，为多智能体应用提供“按需启动、毫秒弹性、零运维”的新一代运行底座。</p><h2>AgentScope 是什么？</h2><p><a href="https://link.segmentfault.com/?enc=3Y8FaxHkvfaN3gghN4FuLA%3D%3D.2SB6wFOxNt4wPmKTHwGYIqz%2BKHqyyX9UmLfCkH50YU1XqARUJ4k5wYBgZhh%2FXIM%2F" rel="nofollow" target="_blank">AgentScope</a> 是一个开源的多智能体应用开发框架，面向构建可观察、可控制、可扩展的 AI 智能体系统。其核心设计原则是<strong>对开发者完全透明</strong>：所有提示工程、模型调用、智能体行为及工作流编排均显式暴露，避免隐式逻辑或深度封装。</p><p>该框架拥有以下特性：</p><ul><li><strong>透明性优先</strong>：所有内部状态、消息传递路径、工具调用链路和模型交互过程均可追踪与审计，确保行为可解释、可调试。</li><li><strong>实时介入</strong>：实现ReAct智能体，原生支持任务执行过程中的实时中断与自定义中断处理逻辑，允许用户随时中断智能体的回复，介入智能体的执行，适用于需要人工干预或动态策略调整的场景。</li><li><strong>增强智能能力</strong>：提供统一的工具管理接口、长期记忆控制机制以及智能化 RAG（检索增强生成）支持，提升智能体的上下文感知与知识利用能力。</li><li><strong>模型无关架构</strong>：抽象统一的模型接入层允许同一套智能体逻辑无缝切换不同大语言模型（如 GPT、Claude、通义千问、Llama 系列等），降低模型迁移成本。</li><li><strong>模块化“乐高式”设计</strong>：智能体、工具、提示模板、记忆模块、工作流节点等组件高度解耦，支持独立开发、组合复用与灵活替换。</li><li><strong>原生多智能体支持</strong>：采用显式消息传递机制与声明式工作流编排，明确表达智能体间的协作关系，避免隐式调度带来的不可控性。</li><li><strong>高度可定制</strong>：支持对工具链、提示策略、通信协议、第三方库集成及可视化界面进行深度定制，适配从原型验证到生产部署的全周期需求。</li></ul><p>AgentScope 旨在为开发者提供一个既具备工程严谨性，又保持足够灵活性的智能体开发基础设施，推动多智能体系统从实验走向规模化落地。自开源以来，AgentScope 已获得社区广泛认可，GitHub Star 数突破 <strong>14,000+。</strong></p><h2>当前Agent运行时的挑战</h2><p><a href="https://link.segmentfault.com/?enc=c0yKbOhBva2PhUNZ73rvbA%3D%3D.huHuQdUUHJj1LMWnrmTma8C%2BdBRVPJUrIzz194qSasRWVtUbq5aY92LDy9bgQAqlKtOoixJ3pjG9vPY4UzV1Qg%3D%3D" rel="nofollow" target="_blank">AgentScope Runtime </a>是一个面向生产环境的智能体运行时框架，聚焦于两大核心问题：<strong>高效、可扩展的智能体部署</strong>与<strong>安全、隔离的Sandbox工具执行</strong>。该运行时提供上下文管理（包括长短期记忆与外部知识库集成）和多层级沙箱基础设施，构成一套框架无关的底层支撑系统，可与主流开源智能体框架或自定义实现无缝协同。其设计目标是为服务级智能体应用提供具备完整可观测性、强安全性与便捷部署能力的基础运行环境。</p><p>AgentScope Runtime实现了双核心架构：</p><ul><li><strong>智能体部署运行时（Engine）</strong><br/>提供智能体生命周期管理、会话状态维护、上下文存储（短期对话历史与长期记忆）以及外部知识库接入能力，并集成沙箱环境调度服务，支撑高并发、多会话的智能体服务部署。</li><li><strong>工具执行运行时（Sandbox）</strong><br/>基于隔离容器构建的安全执行环境，支持智能体调用各类工具操作，包括文件系统访问、浏览器自动化、GUI 交互及 MCP（Model Context Protocol）工具集成，确保所有副作用行为被严格限制在沙箱边界内，杜绝对宿主系统的潜在风险。</li></ul><p>目前，AgentScope 的主流部署模式依赖 <strong>Docker + Kubernetes</strong> 组合。该方案在功能完备性和集群管理能力上表现优异，但在实际落地 AI Agent 应用时，暴露出若干结构性瓶颈：</p><ul><li><strong>持续运行带来固定成本</strong><br/>容器实例需长期驻留内存以维持智能体状态和会话上下文，即使在无请求的空闲时段仍持续计费，导致显著的资源浪费，尤其对间歇性、事件驱动型任务极不友好。</li><li><strong>静态资源分配缺乏弹性</strong><br/>资源配额（CPU、内存）通常按预估峰值设定，难以动态适配真实负载。在流量突发时可能因资源不足导致响应延迟或失败；而在低峰期则大量计算资源闲置，利用率低下。</li><li><strong>高运维复杂度形成使用门槛</strong><br/>部署和维护一套生产级 K8s 集群涉及网络策略配置、服务发现、日志收集、监控告警、自动扩缩容（HPA）等多项云原生技能，对中小团队、独立开发者或非基础设施背景的研究人员构成显著障碍。</li></ul><p>这些限制使得许多具备潜力的 Agent 应用停留在实验阶段，难以实现低成本、高可用、快速迭代的规模化部署。</p><p>为系统性解决上述问题，AgentScope 正式推出基于<strong>阿里云函数计算（Function Compute, FC）</strong> 构建的 <strong>Serverless 运行时</strong>。该运行时针对 AI Agent 的典型工作负载（如会话保持、工具调用、状态依赖）进行深度优化，在保留功能完整性的同时，彻底重构资源使用与运维模型。</p><p>Serverless运行时的核心优势：</p><ul><li>✅<strong>按量付费，成本可精细化控制</strong><br/>计费粒度精确至毫秒级函数执行时间与内存消耗，空闲期间零费用。对于低频调用或突发型 Agent 任务，可有效降低成本。</li><li>✅<strong>毫秒级弹性伸缩，自动应对负载波动</strong><br/>无需预设实例数量或手动扩缩容，平台根据并发请求数自动调度计算资源，瞬时支撑从 1 到数千 QPS 的流量突增，保障服务 SLA。</li><li>✅<strong>零运维，聚焦核心逻辑开发</strong><br/>开发者无需关心底层服务器、容器镜像、K8s 配置或网络拓扑，仅需关注智能体逻辑、工具集成与业务流程编排，大幅缩短上线周期。</li></ul><p>此外，Serverless 运行时通过 <strong>会话亲和（Session Affinity）机制</strong>在无状态函数架构下有效支持有状态的 Agent 交互场景，兼顾弹性与一致性。</p><p>这一演进标志着 Agent 运行时正从“重资产、高运维”的传统模式，迈向“轻量化、自动化、经济高效”的云原生新范式，为 AI Agent 的大规模商业化落地扫清基础设施障碍。</p><h2>Serverless运行时集成能力详解</h2><h3>Engine 能力拓展</h3><p>Serverless 运行时深度集成 AgentScope 的核心执行引擎（AgentScope Runtime Engine），在保留原有编程模型的基础上，为开发者提供面向云原生环境的无缝部署体验。关键能力包括：</p><ul><li><strong>本地代码一键构建与依赖打包</strong><br/>开发者仅需在本地项目目录中执行<code>deploy()</code>方法，运行时即可自动分析 Python 依赖，构建包含用户代码、自定义工具及第三方库的可执行包，并上传至阿里云函数计算（FC）——该服务已深度集成于百炼 ModelStudio 平台，实现从开发到托管的一站式闭环。</li><li><strong>一键部署生成 HTTPS Endpoint</strong><br/>部署完成后，系统自动分配全局唯一的 HTTPS 端点（Endpoint），支持标准 RESTful 调用。外部系统（如 Web 前端、移动端或第三方服务）可通过该接口直接触发智能体执行，无需额外配置网关或反向代理。</li><li><strong>Header-Based Session 亲和性保障</strong><br/>为支持有状态交互（如多轮对话、工具链连续调用），Serverless 运行时引入基于 HTTP 请求头的会话绑定机制。客户端通过在请求中携带Session ID请求头，平台将确保同一 Session ID 的所有后续请求路由至同一函数实例（或关联的沙箱上下文），从而维持内存状态、临时文件或浏览器会话的一致性。</li><li><strong>继承 Serverless 核心优势</strong><br/>所有通过 Engine 部署的智能体天然享有 Serverless 架构的三大特性：按实际执行时间计费、毫秒级自动扩缩容、零基础设施运维，显著降低运营复杂度与总体拥有成本（TCO）。</li></ul><h3>Sandbox 运行时全面支持</h3><p>AgentScope 定义的四大沙箱类型现已完整适配 Serverless 运行时，可在函数计算环境中安全、高效地执行各类操作：</p><ul><li>✅ <strong>BaseSandbox</strong>：提供隔离的 Python 代码执行环境，适用于通用脚本运行与逻辑计算</li><li>✅ <strong>FileSystemSandbox</strong>：挂载临时或持久化文件系统，支持文件读写、日志记录与中间产物存储</li><li>✅ <strong>BrowserSandbox</strong>：内置无头 Chromium 浏览器，实现网页自动化、数据抓取与前端交互模拟</li><li>✅ <strong>GUISandbox</strong>：支持图形界面应用的模拟执行（如桌面软件自动化），适用于特定领域工具集成</li></ul><p>基于阿里云函数计算（FC）的Serverless运行时，深度集成 AgentScope 的Sandbox运行引擎，其核心特性如下：</p><ul><li><strong>预热实例池，消除冷启动延迟</strong><br/>平台可预先创建并维护一组常用类型的 Sandbox ，在新会话到来时直接复用，提高常驻服务的响应速度。</li><li><strong>自动注入 Session ID，保障上下文连续性</strong><br/>在首次创建 Sandbox 时，系统自动生成唯一 Session ID 并返回给客户端；后续所有针对该会话的 HTTP 请求均自动携带此 ID，确保操作始终作用于同一沙箱实例，保证状态一致性。</li><li><strong>全生命周期 Serverless 体验</strong><br/>每个 Sandbox 实例在会话结束后自动回收资源，计费随执行结束而终止，同样遵循 <strong>按量付费、毫秒级弹性、零运维</strong> 的 Serverless 原则，在安全性、性能与成本之间取得最佳平衡。</li></ul><p>通过 Engine 与 Sandbox 的双重增强，AgentScope 的 Serverless 运行时不仅解决了传统部署的成本与运维难题，更在保持强隔离与状态支持的前提下，实现了 AI Agent 应用的高效、安全、经济化交付。</p><h2>快速体验</h2><p>现在，您就可以将 Agent 应用快速部署到 Serverless 运行时！</p><h3>部署 Agent 到 Serverless运行时</h3><p>只需三步：</p><ol><li>配置相关环境变量</li></ol><pre><code class="yaml"># 确保设置环境变量
export DASHSCOPE_API_KEY="your-dashscope-api-key"
export ALIBABA_CLOUD_ACCESS_KEY_ID="your-access-key-id"
export ALIBABA_CLOUD_ACCESS_KEY_SECRET="your-access-key-secret"
export MODELSTUDIO_WORKSPACE_ID="your-workspace-id"

# 可选的OSS专用凭证
export OSS_ACCESS_KEY_ID="your-oss-access-key-id"
export OSS_ACCESS_KEY_SECRET="your-oss-access-key-secret"</code></pre><ol start="2"><li>定义好您的AgentApp</li></ol><pre><code class="yaml"># -*- coding: utf-8 -*-
# pylint:disable=wrong-import-position, wrong-import-order
import asyncio
import os

from agentscope.agent import ReActAgent
from agentscope.model import DashScopeChatModel

from agentscope_runtime.engine.agents.agentscope_agent import AgentScopeAgent
from agentscope_runtime.engine.runner import Runner
from agentscope_runtime.engine.schemas.agent_schemas import (
    MessageType,
    RunStatus,
    AgentRequest,
)
from agentscope_runtime.engine.services.context_manager import (
    ContextManager,
)
from agentscope_runtime.sandbox.tools.function_tool import function_tool
from others.other_project import version


@function_tool()
def weather_search(query: str) -&gt; str:
    if "sf" in query.lower() or "san francisco" in query.lower():
        result = "It's 60 degrees and foggy."
    else:
        result = "It's 90 degrees and sunny."

    return result


agent = AgentScopeAgent(
    name="Friday",
    model=DashScopeChatModel(
        "qwen-turbo",
        api_key=os.getenv("DASHSCOPE_API_KEY"),
    ),
    agent_config={
        "sys_prompt": "You're a helpful assistant named Friday.",
    },
    agent_builder=ReActAgent,
    tools=[
        weather_search,
    ],
)
print(f"AgentScope Runtime with dependencies version: {version}")


async def run():
    # Create a request
    request = AgentRequest(
        input=[
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": "杭州天气如何？",
                    },
                ],
            },
        ],
    )

    runner = Runner(
        agent=agent,
        context_manager=ContextManager(),
        # context_manager=None       # Optional
    )
    async for message in runner.stream_query(request=request):
        # Check if this is a completed message
        if (
            message.object == "message"
            and MessageType.MESSAGE == message.type
            and RunStatus.Completed == message.status
        ):
            all_result = message.content[0].text
        print(message)

    print(f"📝 Agent response: {all_result}")


if __name__ == "__main__":
    asyncio.run(run())</code></pre><ol start="3"><li>配置部署相关代码，将您的代码部署到Serverless运行时上</li></ol><pre><code class="yaml">import asyncio
import os
from agentscope_runtime.engine.deployers.modelstudio_deployer import (
    ModelstudioDeployManager,
    OSSConfig,
    ModelstudioConfig,
)
from agent_app import app  # 导入已配置的 app

async def deploy_to_modelstudio():
    """将 AgentApp 部署到阿里云 ModelStudio"""

    # 配置 OSS 和 ModelStudio
    deployer = ModelstudioDeployManager(
        oss_config=OSSConfig(
            access_key_id=os.environ.get("ALIBABA_CLOUD_ACCESS_KEY_ID"),
            access_key_secret=os.environ.get("ALIBABA_CLOUD_ACCESS_KEY_SECRET"),
        ),
        modelstudio_config=ModelstudioConfig(
            workspace_id=os.environ.get("MODELSTUDIO_WORKSPACE_ID"),
            access_key_id=os.environ.get("ALIBABA_CLOUD_ACCESS_KEY_ID"),
            access_key_secret=os.environ.get("ALIBABA_CLOUD_ACCESS_KEY_SECRET"),
            dashscope_api_key=os.environ.get("DASHSCOPE_API_KEY"),
        ),
    )

    # 执行部署
    result = await app.deploy(
        deployer,
        deploy_name="agent-app-example",
        telemetry_enabled=True,
        requirements=["agentscope", "fastapi", "uvicorn"],
        environment={
            "PYTHONPATH": "/app",
            "DASHSCOPE_API_KEY": os.environ.get("DASHSCOPE_API_KEY"),
        },
    )

    print(f"✅ 部署到 ModelStudio：{result['url']}")
    print(f"📦 制品：{result['artifact_url']}")
    return result

if __name__ == "__main__":
    asyncio.run(deploy_to_modelstudio())</code></pre><p>📚 详细文档请参考：<a href="https://link.segmentfault.com/?enc=FpxD6zmiQuu2aJRl5sduHg%3D%3D.xUvnD%2Fb67dbP%2BW%2FBIf6w%2FVLRetQpxAaHreO5PH4Q7eMQvhISoq821H6mHBJToPePChF3D0H%2BCH47HaORVSZnkZxJaybpn2B0W8tgmjR%2BBm4NcVmbk%2B%2BKbDzRUMz%2FgdVf" rel="nofollow" target="_blank">部署指南</a></p><h3>快速启动 Sandbox</h3><ol><li>安装<code>agentscope-runtime</code></li></ol><pre><code class="shell">pip install agentscope-runtime</code></pre><blockquote>由于agentscope-runtime仍在初期快速迭代中，建议采用源码安装方式</blockquote><pre><code class="shell">git clone https://github.com/agentscope-ai/agentscope-runtime.git

cd agentscope-runtime

pip install .</code></pre><ol start="2"><li>配置环境变量</li></ol><pre><code class="shell"># Service settings
HOST="0.0.0.0"
PORT=8000
WORKERS=1
DEBUG=False

# Runtime Manager settings
DEFAULT_SANDBOX_TYPE=base
POOL_SIZE=0
AUTO_CLEANUP=True
CONTAINER_PREFIX_KEY=agent-runtime-container-
CONTAINER_DEPLOYMENT=agentrun
DEFAULT_MOUNT_DIR=
STORAGE_FOLDER=runtime_sandbox_storage
PORT_RANGE=[49152,59152]

# FC 相关账户信息
FC_ACCOUNT_ID=&lt;your-account-id&gt;
FC_ACCESS_KEY_ID=&lt;your-access-key-id&gt;
FC_ACCESS_KEY_SECRET=&lt;your-access-key-secret&gt;
FC_REGION_ID=cn-hangzhou
# 规格配置
FC_CPU=2.0
FC_MEMORY=2048
# 网络配置
FC_VPC_ID=&lt;your-vpc-id&gt;
FC_VSWITCH_IDS=[&lt;your-vswitch-id&gt;]
FC_SECURITY_GROUP_ID=&lt;your-security-group-id&gt;
# 前缀
FC_PREFIX=agentscope-sandbox
# 日志配置
FC_LOG_PROJECT=&lt;your-sls-log-project&gt;
FC_LOG_STORE=&lt;your-sls-log-store&gt;</code></pre><ol start="3"><li>运行命令，启动沙箱服务器</li></ol><pre><code class="shell">runtime-sandbox-server --config fc.env</code></pre><ol start="4"><li>使用您的沙箱</li></ol><pre><code class="python">from agentscope_runtime.sandbox import BaseSandbox

# 连接到远程服务器（替换为您的实际服务器地址和端口）
with BaseSandbox(
    base_url="http://127.0.0.1:8000",
) as sandbox:
    # 正常使用沙箱
    print(box.list_tools())
    print(box.run_ipython_cell(code="print('hi')"))
    print(box.run_shell_command(command="echo hello"))
    input("Press Enter to continue...")</code></pre><p>📚 详细文档请参考：<a href="https://link.segmentfault.com/?enc=YEAUpxPBBnOYW1VusfzjjQ%3D%3D.fXpF9K8COpIOcpaIQ%2B6VyQ5Y69yKfaHHt3TYjdiEVAudnnrbUMuNOq%2B0VHHsbrBjS3gi6504RdfWhBVxqz1hJXxLXwLarjgPqIIARlwrVzbzc9coejozQ5GDGNj3D8vw" rel="nofollow" target="_blank">沙箱部署指南</a></p><h2>迈向“省钱又好用”的 AI 运行时</h2><p>AI Agent 的运行时基础设施正经历一场深刻的演进：从早期追求“能跑起来”的基础可用性，到关注开发体验与功能完备性的“好用”阶段，如今正加速迈向兼顾性能、安全与经济性的“省钱用”新范式。</p><p>AgentScope 与 Serverless 架构的深度集成，正是这一演进的关键实践。通过将智能体部署与工具执行全面迁移至基于阿里云函数计算（FC）的 Serverless 平台，不仅大幅降低了对容器编排、集群运维等云原生技能的依赖，更从根本上重构了资源使用模型——<strong>从“为闲置付费”转向“为实际执行付费”</strong>，使中小团队乃至个人开发者也能以极低成本运行生产级 Agent 应用。</p><p>Serverless 所提供的毫秒级弹性、自动扩缩容、强隔离沙箱与零运维特性，恰好契合 AI Agent 应用典型的负载特征：间歇性调用、状态依赖性强、工具执行风险高、成本敏感度高。我们坚信，<strong>Serverless 将成为 AI Agent 应用的最佳运行时。</strong></p><p>未来，AgentScope 将持续深化与主流云服务的协同，进一步优化会话管理、冷启动延迟、多模态工具支持等关键路径，并推动更多开源智能体项目采纳 Serverless 范式，构建一个开放、高效、经济的 Agent 运行生态，让复杂智能体系统的开发与部署如同调用普通 API 一样简单可靠。</p><p><strong>让每一个智能体，都能轻盈运行在云端。</strong></p>]]></description></item><item>    <title><![CDATA[如何将照片从 Mac 传输到 Andro]]></title>    <link>https://segmentfault.com/a/1190000047446115</link>    <guid>https://segmentfault.com/a/1190000047446115</guid>    <pubDate>2025-12-03 15:07:11</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>将照片从 Mac 传输到 Android 手机或平板电脑有时会感觉像是跨越数字鸿沟。由于 Mac 和 Android 运行在不同的生态系统中，直接拖放的方法行不通。如果您想将照片从 Mac 传输到 Android，可以尝试本指南中介绍的有效方法，这些方法可以高质量地传输照片。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446117" alt="图片" title="图片"/></p><p>快速浏览一下这5种方法：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446118" alt="图片" title="图片" loading="lazy"/></p><p>第一部分：如何通过 iReaShare Android Manager 将照片从 Mac 传输到 Android</p><p>像iReaShare Android Manager这样的专用桌面软件旨在提供一套全面的一体化解决方案，方便您从 Mac 管理 Android 设备。借助此程序，您可以直接在 Mac 和 Android 之间传输图片，并保持原始画质。</p><p>iReaShare Android Manager 的主要功能：</p><ul><li>将照片从 Mac 电脑复制到 Android 设备。</li><li>还可以将照片从安卓设备传输到Mac电脑。</li><li>允许您在传输照片之前预览和选择照片。</li><li>还可以传输视频、音乐、文档、联系人、短信、通话记录和应用程序。</li><li>支持只读模式，以确保数据传输安全。</li><li>适用于运行 Android 6.0 或更高版本的 Android 设备，例如三星、一加、TCL、Tecno、OPPO、Vivo、荣耀、谷歌、摩托罗拉等。</li></ul><p>下载iReaShare Android Manager。</p><p>下载 Mac 版下载 Win 版</p><p>使用 Android Manager 将照片从 Mac 传输到三星 Android 设备：</p><pre><code>
下载适用于 Mac 的 iReaShare Android Manager 应用程序并安装。然后启动软件，并使用 USB 数据线将您的 Android 设备连接到 Mac 电脑。如果您需要无线连接，请将两台设备连接到同一个 Wi-Fi 网络，然后点击“通过 Wi-Fi 连接”。


按照屏幕上的指示在安卓设备上启用USB调试模式。连接将会建立。
</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446119" alt="图片" title="图片" loading="lazy"/></p><pre><code>
现在，选择“照片”类别。然后点击“相机”或“图库”，再点击“添加”从您的 Mac 电脑中选择照片。最后，点击“打开”或“确定”开始将照片导入 Android 设备。

</code></pre><p>第二部分：如何通过 Google Photos 将 Mac 上的照片传输到 Android 设备</p><p>Google Photos是一款跨平台云存储和同步服务，无需数据线即可在 Mac 和 Android 设备之间轻松同步文件。但是，如果您的帐户云存储空间不足，则无法一次性上传所有照片。</p><p>将 Mac 上的照片同步到 Android：</p><pre><code>
在您的Mac电脑上打开网络浏览器，访问Google Photos网站。然后使用您在Android手机上使用的同一个Google帐户登录。


点击“ + ”按钮 &gt; “导入照片”，然后从Mac本地存储中选择照片。等待上传完成。
</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446120" alt="图片" title="图片" loading="lazy"/></p><pre><code>在您的安卓手机上，打开 Google 相册应用。确保您已登录同一个 Google 帐户。您从 Mac 上传的照片将自动出现在您安卓设备上的 Google 相册图库中，您可以通过 Wi-Fi 或移动网络访问这些照片。


如果要将照片存储在 Android 设备的本地存储空间中，请在 Google Photos 应用中打开图片，点击三点菜单，然后选择“下载”。
</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446121" alt="图片" title="图片" loading="lazy"/></p><p>第三部分：如何通过 AirDroid 将照片从 Mac 传输到 Android 手机</p><p>AirDroid 是一款流行的第三方应用程序套件，可让您从桌面无线管理您的 Android 设备，使文件传输变得简单方便。</p><p>使用 AirDroid 将照片从 Mac 传输到 Android 手机：</p><pre><code>
请在您的安卓手机和Mac电脑上下载并安装AirDroid应用程序。创建AirDroid帐户并在两台设备上登录。


请确保您的 Mac 和 Android 手机连接到同一个 Wi-Fi 网络。在您的 Mac 上，打开 AirDroid 桌面应用程序。


从列表中选择您的安卓设备，然后选择“设备”选项卡。


将您想要传输的照片从 Mac 的 Finder 窗口拖放到与您的 Android 设备关联的 AirDroid 文件传输界面上。传输将通过您的网络以无线方式进行。照片将保存到您 Android 手机上指定的 AirDroid 文件夹中。
</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446122" alt="图片" title="图片" loading="lazy"/></p><p>第四部分：如何通过 OpenMTP 将图片从 Mac 传输到 Android 设备</p><p>OpenMTP 是一款免费的开源应用程序，专门用于解决 Mac 到 Android 的文件传输问题，它利用了 MTP（媒体传输协议）标准。它充当文件浏览的专用桥梁。</p><p>通过 OpenMTP 将图片从 Mac 传输到 Android：</p><pre><code>
下载适用于 Mac 的 OpenMTP 应用程序并安装。然后使用 USB 数据线将您的 Android 设备连接到 Mac。


在您的安卓手机上，下拉通知栏并点击USB连接通知。选择“文件传输/Android Auto ”或“ MTP ”选项。


在您的 Mac 上启动 OpenMTP 应用程序。它采用双窗格界面：一侧用于显示 Mac 上的文件（左侧），另一侧用于显示 Android 设备的内部存储（右侧）。


在 Mac 上找到包含照片的文件夹（左侧面板），然后在 Android 设备上找到目标文件夹（右侧面板）。在 Mac 的面板中选择照片，然后点击“传输”按钮（通常是一个从左到右的箭头）开始传输。
</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446123" alt="图片" title="图片" loading="lazy"/></p><p>第五部分：如何通过 LocalSend 将照片从 Mac 发送到 Android 手机</p><p>LocalSend 是一款跨平台的开源应用程序，允许通过本地网络进行安全的点对点文件共享，类似于苹果的 AirDrop，但它适用于 Android、Mac、Windows 和 Linux。</p><p>通过 LocalSend 将照片从 Mac 传输到 Android：</p><pre><code>
请在您的Mac电脑和安卓手机上下载并安装LocalSend应用程序。确保两台设备都连接到同一个本地Wi-Fi网络。


在两台设备上启动 LocalSend 应用。它们应该会自动发现彼此。在 Mac 应用中，点击“发送”，然后选择要传输的照片。


从可用接收设备列表中选择您的安卓设备。您的安卓手机上会弹出通知。点击“接受”开始转账。


照片将保存到您安卓设备上指定的 LocalSend 文件夹中。
</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446124" alt="图片" title="图片" loading="lazy"/></p><p>第六部分：关于将照片从 Mac 传输到 Android 的常见问题</p><p>Q1：我可以使用 Android 文件传输将照片从 Mac 拖放到 Android 设备上吗？</p><p>是的，您可以使用适用于 Mac 的 Android 文件传输 (AFT) 应用，将照片和其他文件从 Mac 拖放到 Android 手机上。虽然拖放功能可用，但需要注意的是，Android 文件传输已不再由 Google 官方支持或更新，并且经常不稳定，尤其是在较新版本的 macOS 和 Android 系统上。</p><p>Q2：我可以使用 AirDrop 将照片从 Mac 传输到 Android 设备吗？</p><p>不，您无法使用 Mac 上标准的内置 AirDrop 功能向绝大多数 Android 手机（包括三星、一加等）发送照片。尽管谷歌已经将 Android 的“快速分享”功能与苹果的 AirDrop 协议进行了整合，但这项功能非常新，尚未在所有 Mac 和 Android 机型上广泛普及。</p><p>Q3：我可以通过蓝牙将图片从Mac传输到Android吗？</p><p>是的，您可以使用蓝牙将图片从 Mac 传输到 Android 手机，因为这两个设备都支持蓝牙文件传输协议。这可以通过 Mac 上内置的蓝牙文件交换应用程序完成。但是请注意，这种方法通常速度很慢，仅建议用于传输少量小文件，例如几张照片。</p><p>结论</p><p>现在，通过以上方法，您可以轻松地将照片从 Mac 传输到 Android 设备。无论您喜欢 Google Photos 的无缝云端同步，还是iReaShare Android Manager的强大管理功能，总有一种方法能够完美地跨越 Mac 和 Android 之间的鸿沟。顺便一提，如果您经常在 Mac 和 Android 设备之间传输文件，iReaShare Android Manager 将是您的最佳助手。<br/>​</p>]]></description></item><item>    <title><![CDATA[低代码平台定义解析与选型建议(2025版]]></title>    <link>https://segmentfault.com/a/1190000047446140</link>    <guid>https://segmentfault.com/a/1190000047446140</guid>    <pubDate>2025-12-03 15:06:22</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>一、低代码定义解析：</h2><p>低代码平台是一种基于可视化设计与配置的应用开发方法，核心在于通过组件化、图形化、参数化的拖拽配置方式进行系统开发，开发过程中能大幅减少手动编码量，从而提升应用交付速度与效率。</p><p>1、技术内涵：</p><p>从技术内涵看，低代码平台通常依托表单驱动、模型驱动等技术路径，提供数据编排、生态连接、服务集成等核心能力，以图形化方式实现业务场景的快速构建与创新。</p><p>2、技术演进：</p><p>低代码的发展也算是历经了较长时间阶段的演进与共识凝聚。早在20世纪80年代，“第四代编程语言”已初显低代码思想；至2014年，Forrester明确定义了“低代码/零代码”概念，并指出低代码能够以最少的手工编码快速开发、配置和部署应用系统。2018年，Gartner进一步提出aPaaS与iPaaS概念，其中aPaaS与低代码理念高度契合，有效推动了低代码技术在全球范围内的关注与落地。</p><p>随着低代码技术的发展与行业实践，国内主流厂商（如织信、宜搭、奥泽等）达成共识，推出《低代码平台发展白皮书》，白皮书中明确了低代码平台的完整定义，强调其应以可视化配置为主、少量代码为辅，并具备全生命周期管理能力。</p><p>如今，低代码平台已广泛应用于企业数字化转型场景，截止2025年11月，低代码已在工业领域的MES、PLM系统灵活扩展中发挥作用，目前已达到百亿市场规模，依然构建起了一个完整的低代码生态体系。</p><p>3、产品特征：</p><p>低代码平台必须具备应用全生命周期管理能力，支持设计、开发、测试、部署、迭代、运维的全生命周期管理，实现应用开发效率提升、需求快速响应、敏捷迭代更新、运营维护便捷等目标，是一站式的应用开发平台。</p><h2>二、低代码平台选型建议</h2><p>对应用漏洞、平台安全性、数据安全合规等方面有要求的企业，选型时要注重：</p><p>深入评估平台安全能力： 不要只看厂商宣传，要了解平台是否具备“SAST（静态应用安全测试）和DAST（动态应用安全测试）”等自动化安全检测能力。</p><p>审查平台的权限管理机制：确保平台能提供细粒度的权限控制，包括角色权限、数据权限、字段权限等，并支持单点登录（SSO）和多因素认证（MFA）。</p><p>考察数据处理与存储： 询问平台的数据中心位置，数据传输是否使用TLS加密，以及是否支持私有化部署以满足特殊安全需求。</p><p>对集成能力、集成成本、数据同步等方面有需求的企业，选型时要考察：</p><p>考察API连接能力：确保平台支持API和SOAP等主流API协议，并且能够轻松调用和封装外部API。</p><p>查看集成案例和连接器：了解平台是否提供丰富的预置连接器，例如与钉钉、企业微信、飞书等常用系统的连接器。</p><p>评估异步处理能力： 询问平台如何处理大规模数据同步和异步任务，是否支持“ 消息队列（Message Queue）”等机制。</p><p>对生态拓展、性能瓶颈、二次开发和能力边界等方面有要求的企业，选型时要着重考虑：</p><p>评估平台的扩展性： 询问平台是否提供API接口、SDK、自定义组件开发框架等，支持开发者通过代码扩展平台功能。</p><p>关注平台架构： 了解平台是否采用微服务架构，支持独立部署和弹性伸缩，以应对业务增长带来的性能挑战。</p><p>考察“低代码”与“高代码”的融合： 理想的平台应该能够让低代码开发者和专业开发者在同一个平台协同工作，低代码负责快速构建，高代码负责复杂逻辑和性能优化。</p><h2>三、国内主流的低代码平台排行（12月最新）</h2><p>1、织信</p><p>推荐指数：★★★★★</p><p>综合评分：99.7分</p><p>织信Informat是由深圳基石协作自主研发的企业级低代码开发平台，平台基于“数据、流程、角色”三个基本要素，用户只需通过简单的“拖拽”、“配置”等操作，即可快速搭建整套的数字化管理系统。此外，平台还拥有足够强的边界能力，内置了脚本、自动化、网站、自定义页面、符合BPMN2.0规范的工作流引擎等功能，能满足大部分企业复杂的业务需求。该产品着重面向ToB企业内部信息化/数字化建设，为企业提供高效、定制、专业的数字化咨询与信息化系统一体化解决方案。</p><p>产品特点：支持本地私有化部署，上亿级大数据大并发处理能力，使用层与开发层分离，标准化的运维版本管理体系。基于织信低代码构建多年的aPaaS能力与自动化、流程化模式被进一步释放，构建一款应用时，企业可将前后端开发等环节紧密衔接，减少大量重复性工作，并有效提升 67% 的IT项目效率。</p><p>2、奥哲云枢</p><p>推荐指数：★★★★★</p><p>综合评分：98.3分</p><p>奥哲云枢是面向大中型企业复杂业务场景的低代码平台。其核心竞争力在于“All in One”的数智化引擎，将低零代码开发、AI智能、集成开放与数据可视化能力深度融合，形成覆盖应用全生命周期的一站式解决方案。平台支持从“零代码配置”到专业代码扩展的全场景开发模式，让业务人员与技术团队能够高效协同。作为市场公认的标杆性产品，奥哲服务了国内大量500强企业，在建筑、能源、金融等行业积累了丰富的央国企实践案例，市场占有率位居前列。</p><p>产品特点：以强大的流程引擎为核心，擅长构建和优化复杂、长周期的业务流程。平台提供了从设计、开发、集成到运维的完整能力，能有效封装企业既有业务能力并连接新老系统，帮助大型集团在复杂组织架构下实现数字化运营与流程管理。</p><p>3、宜搭</p><p>推荐指数：★★★★★</p><p>综合评分：96.6分</p><p>宜搭是阿里巴巴推出的低代码应用构建平台，深度融入钉钉生态，主打高效协同与快速部署。平台与钉钉的组织架构、消息通知、待办审批等原生能力无缝集成，用户可在钉钉工作台内直接创建和使用应用，实现“开发即使用”的协同体验。2025年，平台接入了DeepSeek大模型，AI流程自动化能力得到增强，可通过自然语言指令快速生成表单。平台提供了超过500个行业模板，能快速满足零售、医疗等领域的轻量化应用需求。</p><p>产品特点：依托阿里云与钉钉的双重生态，在服务的稳定性和安全性方面有较好保障。其操作轻量化，订阅制定价模式灵活，特别适合中小企业、部门团队快速搭建审批、人事、行政等内部协同类应用，大幅降低数字化门槛。</p><p>4、炎黄盈动</p><p>推荐指数：★★★★</p><p>综合评分：94.9分</p><p>炎黄盈动是一家专注于业务流程管理（BPM）与PaaS平台的服务商，其AWS PaaS平台是在深厚BPM技术积累上演进而来的企业级低代码平台。平台采用云原生和模型驱动架构，为企业构建关键业务应用提供稳定可靠的底层支撑。其核心优势在于强大的流程建模、自动化与编排能力，能够帮助企业梳理并优化端到端的复杂业务流程，实现跨部门、跨系统的业务协同。</p><p>产品特点：在流程挖掘与低代码开发深度融合方面表现突出。平台非常适合流程密集型的大型组织，尤其在金融、政务、能源等对系统稳定性、安全性和合规性有严苛要求的行业，是构建任务关键型（Mission-Critical）应用系统的有力工具。</p><p>5、Zoho Creator</p><p>推荐指数：★★★★</p><p>综合评分：93.5分</p><p>Zoho Creator是国际知名软件服务商Zoho旗下的低代码开发平台，拥有超过18年的行业经验，技术成熟稳定。平台提供从表单搭建、流程自动化到数据分析的全栈能力，并支持从零代码到全代码的平滑过渡。其最大特色之一是集成了AI助手“Zia”，支持通过文本描述自动生成应用，显著提升开发效率。作为全球化平台，它支持30多种语言，在全球拥有多个数据中心，兼顾了本地化适配与全球化协同需求。</p><p>产品特点：与Zoho旗下的CRM、项目管理等25+应用无缝集成，生态融合性强。平台采用灵活的订阅制收费，支持1人起购，性价比高，既能满足中小企业当前的全场景需求，也能支撑大型企业未来的规模化扩展与跨区域部署。</p><p>6、JeecgBoot</p><p>推荐指数：★★★★</p><p>综合评分：91.7分</p><p>JeecgBoot是国内首个免费开源的低代码平台，由开源社区主导研发，基于BPM理念构建，采用SpringBoot 3.x、SpringCloud、Vue等前后端分离架构，全面支持微服务架构。用户通过平台强大的代码生成器可一键生成前后端完整代码，配合在线表单、报表、大屏设计等丰富低代码模块，实现简单功能零代码配置、复杂功能低代码生成的灵活开发模式，大幅减少重复开发工作。平台聚焦Java技术栈企业数字化需求，为开发者提供全流程开发支撑。</p><p>产品特点：完全免费开源且社区活跃度高，提供丰富的学习资源与技术支持，大幅降低企业研发成本；业务流程采用工作流引擎与表单松耦合设计，支持灵活配置与个性化扩展，保障企业流程保密性；支持与各类Java生态系统深度集成，灵活度高，特别适合Java项目团队快速构建ERP、CRM、OA等业务系统；可显著减轻开发人员负担，开发效率较传统模式提升50%以上。</p><p>不知道不觉也写了三千多次，今天暂时先说到这，如果大家在选型方面有任何疑问，欢迎私信交流。附赠低代码产品上手文档说明。</p>]]></description></item><item>    <title><![CDATA[UniParse：让多模态模型真正“读懂]]></title>    <link>https://segmentfault.com/a/1190000047446168</link>    <guid>https://segmentfault.com/a/1190000047446168</guid>    <pubDate>2025-12-03 15:05:34</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <blockquote><p>在多模态大模型迅速发展的今天，我们已经能让模型"看图说话"，甚至"读懂表格"，但要让模型真正理解复杂的文档结构（例如在PDF中准确识别章节、表格、公式与图像的逻辑关系）依然是一个未被彻底解决的问题。</p><p>UniParse正是为此而生：它是一款<strong>面向AI应用的通用文档解析工具</strong> ，旨在将文档中的非结构化内容转化为结构化语义信息，使多模态模型能够<strong>高效、精准</strong>地理解和利用文档内容。</p><p>本文将从技术视角介绍UniParse，功能方面的介绍请移步<a href="https://link.segmentfault.com/?enc=MkVHpxrmSRHafilFjjvZkg%3D%3D.AX6tuUW3vBrSdxUQEkv%2BiKtT15vnrh%2Foq0%2BX%2FOYbvXnVGXQxK%2BTBlWoJDuUOreJLxljWZq%2BVj2FXHfRcvM%2FeBZHmFYN89xsCkqxA3v453vILV1RNJkHBkYdBKK1UYRsf%2BMOhyJYRYyM3l5JQDZmDPDjrQG5eUSWNhYwVJkz3rd%2BpL%2BsZIBHHKQTPYRffLShA" rel="nofollow" target="_blank">产品上线|商汤自研智能文档解析工具UniParse，重新定义文档处理！</a></p></blockquote><hr/><h2><strong>一、为什么需要文档解析</strong></h2><p>现代大模型已经能够处理文本、图像、语音等多种模态，但在面对文档时仍然存在明显短板：</p><ul><li><strong>格式复杂</strong>：PDF、Word等文件中同时包含文字、表格、图片、公式、页眉页脚等多种内容，且层次不统一。</li><li><strong>结构缺失</strong>：OCR只能识别文字，却无法恢复章节层级与逻辑顺序。</li><li><strong>语义混乱</strong>：表格、图像与正文往往存在隐含关联，模型难以在语义上进行对齐。</li></ul><p>这意味着，如果直接把整份文档输入多模态模型，模型将面临巨大的上下文噪声和空间混乱，生成效果不稳定，也无法进行精确问答。UniParse的作用，就是在模型"读文档"之前，帮它<strong>理清结构、分清语义、建立关联</strong>。</p><hr/><h2><strong>二、UniParse的技术流程</strong></h2><p>UniParse的核心流程分为两个主要阶段：<strong>版面分析（LayoutAnalysis)与内容提取（ContentExtraction）</strong> ，并辅以<strong>预处理</strong> 与<strong>内容合并</strong>两个辅助流程。整个流程既保持模块化设计，又在数据层实现了结构化信息流动，使得不同模态内容（文字、图片、表格、公式）能够被统一建模和调用。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446170" alt="" title=""/></p><h3>1️⃣<strong>文档预处理</strong></h3><p>UniParse的预处理阶段主要任务是<strong>统一输入格式</strong> 。系统会将各类文档（PDF、DOC、DOCX等）<strong>逐页渲染为高分辨率图像</strong>，保证不同文件格式在后续视觉模型中具有一致的输入维度。这一过程通常基于PyMuPDF或libreoffice的渲染引擎实现，可控制分辨率以兼顾清晰度与性能。</p><p>同时，预处理阶段还执行以下步骤：</p><ul><li><strong>页面编号与坐标标准化</strong>：为每页图像生成统一的坐标系，用于后续版面元素定位；</li><li><strong>去噪与边缘裁剪</strong>：提升模型在扫描件、照片类文档上的鲁棒性；</li><li><strong>文件元信息提取</strong>：（如页数、文件名、创建时间），用于文档追踪与任务调度。</li></ul><p>经过预处理后，所有文档都被转化为一组图像文件及其基础元信息，为后续的版面解析与内容提取提供统一输入。</p><h3>2️⃣<strong>版面分析</strong></h3><p>版面解析是UniParse的核心之一，目标是<strong>还原文档的空间与语义结构</strong> 。这一阶段采用<strong>视觉语言联合建模</strong>方法：</p><ul><li>在视觉层面，利用版面分析模型（如LayoutLMv3或自研视觉Transformer）识别标题、正文、表格、图像、公式、脚注等区域；</li><li>在语言层面，通过文本块的字体、缩进、上下文语义判断章节层次与逻辑顺序；</li><li>最终将视觉检测结果与文本序列对齐，生成一个包含位置、类型与层级的<strong>结构化版面树</strong>。</li></ul><h3>3️⃣<strong>内容提取</strong></h3><p>UniParse针对不同类型内容采用<strong>专用解析管线</strong>：</p><ul><li><strong>文字</strong>：OCR模型或文本提取API结合版面坐标进行文本恢复与段落重建；</li><li><strong>表格</strong>：基于结构化表格识别网络（如TableFormer或自研模型）恢复单元格位置、合并关系与层级结构，输出HTML/LaTeX格式；</li><li><strong>图片</strong>：通过OCR或视觉语言模型（VLM）获取图像描述，为多模态模型提供语义锚点；</li><li><strong>公式</strong>：采用基于Transformer的公式识别引擎将公式区域转化为可编辑的LaTeX表达式。</li></ul><p>每种内容在抽取后都会带有来源页、坐标和上下文标签，以便在合并阶段进行定位与关联。</p><h3>4️⃣<strong>语义层重构</strong></h3><p>最后一步是内容合并与输出。系统将前述多类型元素按照版面树的层级进行拼接，恢复出原文档的逻辑顺序与结构。这一阶段还可以进行：</p><ul><li>内容去重与段落融合（防止跨页重复文本）；</li><li>模态链接（表格、图像与正文语义匹配）；</li><li>结构化输出（统一输出为JSON、HTML或Markdown格式）。</li></ul><p>通过这一设计，UniParse能在保持文档可读性的同时，为下游多模态模型提供可计算的结构化输入。</p><hr/><h2><strong>三、UniParse与多模态大模型的协同机制</strong></h2><p>多模态模型的核心挑战之一是模态对齐。传统方法依赖模型内部注意力机制去"猜测"文本与视觉区域的对应关系，而UniParse提供了<strong>显式的结构锚点</strong>。</p><p>从工程上看，UniParse的结构化输出可以直接映射到模型输入的不同通道：</p><ul><li>文本节点被编码为语言向量；</li><li>表格与公式节点可转换为结构token序列；</li><li>图像节点对应视觉特征向量；</li><li>节点之间的层级关系（如章节树）可编码为attentionmask，用于指导模型的跨模态关注。</li></ul><p>通过这种方式，UniParse在模型输入阶段实现了<strong>结构化对齐</strong>：</p><ul><li>模型在编码时能基于文档结构进行有选择的注意力分配；</li><li>上下文检索与问答更精确，因为每个节点都带有位置标签；</li><li>生成内容可以反向追溯到原文档区域，实现可解释性。</li></ul><p>换言之，UniParse并非一个单纯的"预处理器"，而是为多模态大模型提供了结构感知接口，让模型真正理解"这是一份文档"，而不仅仅是一组视觉与文本片段。</p><hr/><h2><strong>四、应用场景：从文档解析到智能理解</strong></h2><p>UniParse的技术能力为多模态模型打开了更广阔的应用空间：</p><ul><li><strong>智能问答（QA）</strong>：大模型可直接基于结构化数据进行文档问答，不仅能回答正文问题，也能解析表格、公式或图表。</li><li><strong>知识抽取与检索增强生成（RAG）</strong>：通过文档语义图构建可检索知识库，支持高精度上下文匹配。</li><li><strong>报告生成与内容审校</strong>：结构化信息流使模型能生成符合格式规范的总结、分析报告或审阅意见。</li><li><strong>图文理解与多模态推理</strong>：表格、公式、图片被视为独立模态单元，与文本共同构成推理输入，适用于学术报告、财务报表等复杂文档。</li></ul><hr/><p><strong>小结</strong></p><blockquote>在多模态智能系统的发展路径中，<strong>结构化理解</strong>是必经之路。UniParse作为文档解析的基础设施，为大模型提供了语义层级、视觉位置与逻辑关系的桥梁，使文档理解从模糊感知走向可解释推理。未来，模型的"读文档"能力将不断演进------它们不再仅仅识别信息，而是能够基于文档的结构和语义进行真正的理解与推理。</blockquote><hr/><p>更多技术讨论，欢迎移步 "万象开发者" gzh！</p>]]></description></item><item>    <title><![CDATA[研发效能度量工具横评：哪些指标真的能提升]]></title>    <link>https://segmentfault.com/a/1190000047446191</link>    <guid>https://segmentfault.com/a/1190000047446191</guid>    <pubDate>2025-12-03 15:04:57</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <blockquote>市面上能做研发效能度量的工具越来越多，有的是一体化研发管理平台，有的专注工程效能，有的来自云厂商 DevOps 套件，还有自建的开源度量方案。但决定交付能力的，既不是报表数量，也不是图表是否炫酷，而是——你到底在度量哪些研发效能指标，这些指标与交付瓶颈的关系有多紧密，工具是否支持闭环改进。本文选取四类典型工具路线及代表产品做横向测评，系统梳理关键研发效能度量指标及其适用场景，希望能帮助你做更理性的选型与规划。</blockquote><h2>先想清楚为什么要做「研发效能度量」</h2><p>很多企业做研发效能度量，是这样开始的：</p><p>先采购或搭建一个“研发效能平台”；<br/>接入需求、缺陷、流水线、Git 等多种数据源；<br/>几个月后，报表很多，但决策和交付方式几乎没变。</p><p>从组织视角看，问题往往出在「顺序」上—— 先有工具，再找指标，再想目的。</p><p>更健康的顺序应该是：</p><p><strong>① 先定义要解决的问题</strong></p><ul><li>一直延期，想缩短端到端交付周期？</li><li>线上频繁故障，想提升质量与稳定性？</li><li>新产品投入很大，但客户感知不强，想优化价值交付？</li></ul><p><strong>② 再挑出最关键的研发效能度量指标</strong></p><ul><li>哪几个指标能直接反映这个问题？</li><li>哪些是“结果指标”，哪些是“过程指标”？</li></ul><p><strong>③ 最后再看工具与路径</strong></p><ul><li>哪类工具更容易精准采集这些数据？</li><li>哪类平台更便于把指标带进迭代会、项目会、季度复盘？</li></ul><p>如果这三步不清楚，再完备的工具横评也只是“功能列表”。下面这 4 组研发效能度量指标，可以视为组织级的“基准标尺”。</p><h2>四大类真正影响交付的「研发效能度量指标」</h2><p>要评估一款研发效能度量工具是否值得引入，核心不是“能做多少报表”，而是能否支持下面四组关键指标的采集与使用：</p><h4>1. 流动效率指标：交付是不是在“顺畅地流动”</h4><ul><li>端到端交付周期（Lead Time）：从需求提出到上线。</li><li>开发周期（Cycle Time）：从开始开发到完成开发。</li><li>在制品数量（WIP）：同时在做多少工作。</li><li>吞吐量（Throughput）：单位时间完成多少工作项。</li></ul><p>这些研发效能度量指标的作用是：判断团队是“太忙导致变慢”，还是“系统性瓶颈导致变慢”。</p><h4>2. 质量与稳定性指标：研发效能能不能“可持续”</h4><ul><li>缺陷密度、缺陷分布。</li><li>变更失败率、回滚次数。</li><li>故障平均恢复时间（MTTR）。</li><li>与发布事件的关联。</li></ul><p>这组研发效能度量指标用于回答：我们是在“加速交付”，还是在“透支质量”？产品稳定性是否足以支撑更快的交付节奏？</p><p>如果质量指标长期失控，任何短期的“交付提速”都只是在透支未来。</p><h4>3. 价值与资源配置指标：忙碌是否真的创造价值</h4><ul><li>需求从立项到首次上线的周期。</li><li>不同类型需求（创新、优化、技术债）的占比。</li><li>废弃或长期搁置需求比例。</li></ul><p>这类研发效能度量指标回答的问题是：研发在多大程度上被“真正创造价值的事”占据？</p><h4>4. 协作与团队健康指标：交付问题的领先信号</h4><ul><li>插单率、计划与实际偏差。</li><li>跨团队依赖导致的等待时间。</li><li>简单调研上的阻碍感、负荷感。</li></ul><p>这些研发效能度量指标往往比故障率更早暴露风险，是组织“体温计”。很多交付危机，最早不是出现在流水线，而是出现在“团队感觉不对”。</p><p>后文对各类工具与路径的横评，都围绕这四组指标展开：能否支撑这些指标的采集、分析与闭环，是衡量研发效能度量工具价值的核心标准。</p><h2>四类研发效能度量工具横评</h2><h4>1. 一体化研发管理平台 —— 让「工作流」与「度量数据」同源</h4><p>这一类工具的共同特征是：本身就是需求 / 项目 / 缺陷 / 测试 / 流水线的协同平台，研发效能度量的数据主要来自团队日常使用，而非额外报表工程。典型代表有 ONES、Jira Software、Azure DevOps 等。</p><p>它们适合回答的问题是：</p><p>“多项目、多团队的交付效率与质量趋势如何？”<br/>“具体项目的交付瓶颈在哪里？”<br/>“组织级的研发效能度量该如何落地？”</p><p>下面会对上面提到的三种典型代表工具进行测评：</p><p><strong>（1）ONES：本地化一体化研发管理与效能度量</strong></p><p>先来测评一款国内的一体化研发管理平台。ONES 的核心定位就是一体化研发管理平台 + 研发效能度量模块，通过 Project / TestCase / Wiki 等模块管理需求、项目、缺陷、测试，再由 ONES Performance 统一抽取数据做研发效能分析。</p><p><strong>ONES 在四类指标上的能力：</strong></p><p>① 流动效率类研发效能度量</p><p>端到端 Lead Time、Cycle Time、WIP、吞吐量都可以基于工作项自然计算；<br/>支持按项目、团队、版本等维度分析流动效率变化。</p><p>② 质量与稳定性类研发效能度量</p><p>缺陷与需求、版本关联，支持按模块/版本做缺陷密度分析；<br/>与流水线 / 发布系统集成后，可以分析变更失败率等。</p><p>③ 价值与资源配置类研发效能度量</p><p>通过自定义字段区分需求类型，分析创新 / 优化 / 技术债等投入产出；<br/>配合项目群视图，支撑业务线层面的价值与资源审视。</p><p>④ 协作与团队健康类研发效能度量</p><p>利用看板、阻塞状态、依赖关系等字段，识别跨团队等待和插单情况；<br/>PMO 可基于这些数据组织项目级、组织级复盘。</p><p><strong>适合的团队与场景：</strong></p><ul><li>希望统一工具栈，打通从需求到交付的链路，统一“研发工作台”和“研发效能度量平台”；</li><li>对国产化、本地部署、安全合规有要求的组织；</li><li>希望在迭代会、项目会中直接使用平台视图，而不是额外导出报表；</li><li>需要 PMO、业务线负责人在统一视图下管理多项目、多团队效能。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446193" alt="图片" title="图片"/></p><p>配图：ONES 内置多种研发效能度量指标表</p><p><strong>（2）Jira Software：全球常见的敏捷项目管理与度量工具</strong></p><p>Jira 相信大家都不陌生，是海外都广泛使用的敏捷项目管理工具，支持 Scrum / Kanban 及基本的研发效能统计，并通过插件生态扩展工程效能、DORA 指标等。</p><p><strong>Jira 在关键指标上的表现：</strong></p><p>➀ 流动效率：</p><p>控制图、累计流图可以辅助分析 Cycle Time 和 WIP；<br/>若要实现端到端 Lead Time，需要结合外部系统（测试、发布等）和插件。</p><p>➁ 质量与稳定性：</p><p>缺陷趋势、版本质量可通过 Issue + Release 管理实现；<br/>更深入的 DORA 指标一般需要与 CI/CD 工具协作。</p><p>➂ 价值与资源：</p><p>通过自定义 Issue 类型和字段，可一定程度上做“需求类型 / 价值”维度分析，但更多依赖组织自建模型。</p><p><strong>适合的团队与场景：</strong></p><ul><li>已广泛部署 Atlassian 体系，团队成熟度较高；</li><li>具备较强流程治理能力，能在高自由度配置下统一研发效能度量口径。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446194" alt="图片" title="图片" loading="lazy"/></p><p>配图：Jira 产品组合链</p><p><strong>（3）Azure DevOps：偏“开发侧一体化”的度量能力</strong></p><p>Azure DevOps 主要以“代码 + 流水线 + Issue / Work Item + 测试”为核心，内置了 Value Stream、DORA 指标等工程向研发效能度量视图。</p><ul><li>通过 Boards、Repos、Pipelines、Tests 形成一体化 DevOps 平台；</li><li>提供 Lead Time / Cycle Time 控制图组件，直接展示工作项在流水线中的流动时间。</li></ul><p><strong>适合的团队与场景：</strong></p><p>工程实践成熟，对 CI/CD、自动化测试和持续部署投入较多；<br/>主要问题集中在“从提交到上线”的效率与稳定性，而不是需求塑造与价值回报。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446195" alt="图片" title="图片" loading="lazy"/></p><p>配图：Azure DevOps 产品图</p><h4>2. 工程效能分析平台 —— 深挖 Git / CI 的工程向研发效能度量</h4><p>这一类工具通常站在“工程管理”的视角，用 Git、CI/CD、Issue 等数据来做研发效能度量，主要度量 DORA 指标、PR Cycle Time、代码 churn、评审质量等，代表产品包括 Pluralsight Flow、LinearB、Jellyfish 等。</p><p><strong>（1）Pluralsight Flow（原 GitPrime）</strong></p><p>Pluralsight Flow 主要聚焦开发者行为与工程实践，分析提交习惯、重构比例、评审深度等，对“工程效率”“技术债管理”这类问题给出可视化研发效能度量。适合不改现有项目管理 / 需求工具，只希望在工程层面做更细致的指标洞察的团队。</p><p><strong>（2）LinearB</strong></p><p>LinearB 是典型的 DORA 指标与工程效能平台，强调 Cycle Time 拆解、部署频率、MTTR 等研发效能度量，常配合 GitLab / GitHub + CI 工具使用，作为“工程效能度量层”。</p><p><strong>适合场景：</strong></p><p>已有成熟 DevOps 流水线，短期不引入一体化管理平台；<br/>工程领导层希望用 DORA 指标推动工程实践改进。</p><p><strong>（3）Jellyfish</strong></p><p>Jellyfish 强调“工程投入与业务方向对齐”，分析研发资源在不同业务方向上的分布，一般会融合工程指标、团队健康度等维度，为高层提供决策视图。适合研发规模很大、业务线复杂，需要在高层视角回答“钱花在哪、产出如何”的公司。</p><p><strong>整体评价（工程效能平台）：</strong></p><p>在“流动效率 + 质量稳定性”两个方面的工程侧研发效能度量非常有价值；<br/>对需求价值、项目管理、组织治理等维度，需要与其他系统协同使用。</p><h4>3. 云厂商 DevOps 套件中的“效能洞察”</h4><p>这类产品通常作为云厂商 DevOps 套件的一部分，直接利用云上项目协作、代码、流水线、测试等数据来做研发效能度量。典型代表有阿里云云效效能洞察、腾讯云 CODING DevOps 效能洞察、华为云 CodeArts Board 等。</p><p><strong>（1）阿里云 云效效能洞察 Insight</strong></p><p>云效效能洞察是阿里云 BizDevOps 平台的高级服务，提供交付过程观测和研发效能度量，围绕项目、代码、流水线、质量等构建端到端指标体系。内置 90+ 场景化指标卡和模板化报表，覆盖项目度量、代码度量、流水线度量、质量保障、工作负荷管理等场景。</p><p>适用场景：研发活动主要在阿里云云效上进行，希望“云上工具 + 度量”一体化的团队。</p><p><strong>（2）腾讯云 CODING DevOps 效能洞察</strong></p><p>CODING 效能洞察专注 DevOps 全流程研发效能，通过 50+ 指标提供团队度量、项目度量、个人度量、质量 / 效率 / 价值与成本分析等视图。指标覆盖需求交付周期、缺陷修复周期、提交趋势、构建频率、部署成功率等。</p><p>适用场景：团队已经使用 CODING DevOps 做代码托管、流水线和项目协作，希望顺带接入研发效能度量。</p><p><strong>（3）华为云 CodeArts Board 效能洞察</strong></p><p>CodeArts Board 主要为企业管理者、项目经理、团队负责人等提供端到端的研发效能度量，从需求、缺陷、代码、构建、测试、部署、发布到运营进行全过程分析。内置 100+ 指标库，覆盖交付质量、交付效率、交付能力、交付成本、交付价值，并提供多角色“驾驶舱”。</p><p>适用场景：重度使用华为云 DevCloud / CodeArts 的企业，需要统一的“云上研发效能驾驶舱”。</p><p><strong>整体评价（云厂商路线）：</strong></p><p>在“流动效率 + 质量与稳定性”的指标上做得比较完整，也支持一定程度的价值与成本分析；</p><p>但度量对象较强绑定在云厂商生态，对多云 / 混合工具栈的组织，会有一定接入限制。</p><h4>4. 开源 + 自建 —— 以 Apache DevLake 为代表</h4><p>Apache DevLake 作为开源的 Dev 数据平台，支持接入 Jira、GitHub/GitLab、CI/CD 等多种数据源。内置 DORA 指标（部署频率、变更交付时间、变更失败率、恢复时间）以及大量研发效能度量指标，如需求 Lead Time、Bug Age、构建成功率、PR Cycle Time 等。</p><p><strong>在关键指标上的表现：</strong></p><ul><li>只要数据接得进来、模型建得好，前文提到的四类指标都可以覆盖；</li><li>灵活度高，可以精细化适配自身的研发流程与研发效能度量体系。</li></ul><p><strong>适用场景：</strong></p><ul><li>有数据团队、愿意自己维护数据平台的中大型技术公司；</li><li>工具栈高度异构，希望用统一的开源层打通数据、构建定制化研发效能度量体系。</li></ul><p><strong>优劣分析：</strong></p><ul><li>优势：指标丰富、可定制程度高，对“想深挖但不想受限于单一厂商”的团队非常友好；</li><li>局限：需要投入数据工程与运维成本；指标要想真正进入迭代与项目管理节奏，仍然需要与现有工具（包括 ONES、Jira 等）打通使用。</li></ul><h2>综合对比：哪条路径更适合哪类团队？</h2><p>接下来，我会站在“研发效能度量 + 组织阶段”的角度，把上面的工具做一个简要横评：</p><p><strong>1. 成长型团队（几十人规模以内）</strong> </p><p>诉求： 先建立基础研发效能度量意识，看到趋势即可。</p><p>更适合的路径：</p><ul><li>短期：Excel + 现有工具报表，选少量指标试水；</li><li>中期：选择一款易于落地的一体化平台（如 ONES 或 Azure DevOps / GitLab），把“工作 + 度量”慢慢迁到统一平台。</li></ul><p><strong>2. 多团队、多项目协作的中型组织 </strong></p><p>诉求： 统一口径、统一看板，让管理层对交付现状“看得见”。</p><p>更适合的路径：</p><ul><li>一体化研发管理平台（ONES、Jira + 部分插件、Azure DevOps / GitLab），作为日常协作的主平台；</li><li>如果已经重度云上，则可评估云厂商自带的“效能洞察”模块。</li></ul><p><strong>3. 工程文化成熟、DevOps 体系完善的大型工程团队 </strong></p><p>诉求： 精细化优化流水线效率、稳定性和工程实践。</p><p>更适合的路径：</p><ul><li>在现有 DevOps 工具链上叠加工程效能平台（Pluralsight Flow、LinearB、Jellyfish 等）；</li><li>核心指标更多聚焦：DORA、PR 周期、构建成功率、MTTR 等。</li></ul><p>同时建议： 保持一款一体化平台（或统一项目管理系统），承接需求与项目层面的研发效能度量。</p><p><strong>4. 已深度绑定某家云厂商的组织 </strong></p><p>诉求： 云上项目、代码、CI/CD 已集中，希望“一站式搞定度量”。</p><p>更适合的路径：</p><ul><li>优先评估当前云上的研发效能度量 / 效能洞察模块；</li><li>若后续需要更复杂的自定义分析，再考虑加一层 BI 或开源度量平台。</li></ul><p><strong>5. 有数据团队、强调数据主权和定制化的技术公司 </strong></p><p>诉求： 跨工具栈的统一研发效能度量体系，以及差异化的指标和算法。</p><p>更适合的路径：</p><ul><li>使用 Apache DevLake 等开源平台构建自有“研发数据湖”；</li><li>同时选用一款协作平台（如 ONES / Jira 等）承载日常工作，把数据汇总到数据湖中做统一分析。</li></ul><p>在这个视角下，每条路径都有它“最舒服”的位置，很难简单说谁是“最优解”。更现实的情况往往是：选择一个平台作为协作与研发效能度量的“主场”，再有选择地叠加工程效能平台或开源方案。</p><h2>用“指标思维”看工具，而不是用工具反推指标</h2><p>做研发效能度量工具横评，最终不是为了证明谁更好，而是为了回答三个简单的问题：</p><ul><li>我们真正关心哪些指标，这些指标能否确实推动交付改进？</li><li>这些指标，在哪个工具或路径上，产生和使用的成本最低？</li><li>在当前组织阶段，我们有多少资源，可以支撑哪种复杂度的方案？</li></ul><p>当你先用这样的“指标思维”看待工具，再去比较 ONES、Jira、工程效能平台、云厂商套件、开源方案时，就更容易找到适合自己团队的组合。</p>]]></description></item><item>    <title><![CDATA[NeurIPS2025公布最佳论文奖 L]]></title>    <link>https://segmentfault.com/a/1190000047446199</link>    <guid>https://segmentfault.com/a/1190000047446199</guid>    <pubDate>2025-12-03 15:04:14</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>NeurIPS2025公布最佳论文奖</h2><p>2025 年 11 月 26 日，<strong>NeurIPS（神经信息处理系统大会）</strong> 正式公布了 <strong>2025 年度最佳论文奖获奖名单</strong>。此次奖项由最佳论文评选委员会从会议主赛道及数据集与基准赛道中遴选产生，委员会成员经程序主席、数据集与基准赛道主席提名，由大会主席、下一代与可及性主席批准，均为机器学习各领域顶尖研究者。<strong>最终共有7 篇突破性论文获奖，</strong> 包括 <strong>4 篇最佳论文</strong> （含1 篇数据集与基准赛道专属获奖论文）和 <strong>3篇优秀论文（Runner-up）</strong>，覆盖生成模型理论、强化学习、大语言模型机制、学习理论等多个核心研究方向。</p><h3>最佳论文</h3><h4>1.《Artificial Hivemind: The Open-Ended Homogeneity of Language Models (and Beyond)》</h4><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446202" alt=" " title=" "/></p><p><strong>核心贡献：</strong> 针对大语言模型（LLMs）生成内容缺乏多样性、可能导致人类思想同质化的问题，提出了大规模数据集 Infinity-Chat（含 2.6 万条真实开放域用户查询、3.125 万条人类标注），构建了首个开放域提示词综合分类体系（6 个顶级类别、17 个子类别）。通过对 70 余种模型的实证研究，揭示了"人工蜂群思维（Artificial Hivemind）" 效应 —— 模型内部存在重复生成倾向，且不同模型间输出高度同质化。同时发现现有 LLM、奖励模型及自动评判器难以匹配人类多样化偏好，为缓解 AI 安全风险提供了关键参考。</p><p><strong>评审评价：</strong> 填补了AI 评估中创意生成、主观偏好对齐等维度的研究空白，为 AI 系统异质性保护奠定了基础，树立了 "以科学认知和社会挑战为导向" 的数据集构建新标准。</p><h4>2.《Gated Attention for Large Language Models: Non-linearity, Sparsity, and Attention-Sink-Free》</h4><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446203" alt=" " title=" " loading="lazy"/></p><p><strong>核心贡献：</strong> 系统探究了门控机制对softmax 注意力的影响，通过在 150 亿参数混合专家（MoE）模型和 17 亿参数稠密模型（基于 3.5 万亿 token 数据集训练）上的 30 余种变体实验，发现 "在缩放点积注意力（SDPA）后添加头专属 sigmoid 门控" 的简单修改，可显著提升模型性能、训练稳定性及长上下文外推能力，同时缓解注意力 sink 问题。该机制的有效性源于引入非线性和查询依赖的稀疏门控分数，相关代码与模型已开源，并应用于 Qwen3-Next 系列模型。</p><p><strong>评审评价：</strong> 研究成果具备极强的可实施性，基于工业级计算资源完成的大规模验证为LLM 架构优化提供了可靠依据，开源行为对推动领域发展具有重要意义。</p><h4>3.《1000 Layer Networks for Self-Supervised RL: Scaling Depth Can Enable New Goal-Reaching Capabilities》</h4><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446204" alt=" " title=" " loading="lazy"/></p><p><strong>核心贡献：</strong> 挑战了强化学习（RL）难以训练深层网络的传统认知，提出了适用于自监督 RL 的深层网络构建方案。实验表明，将网络深度从传统的 2-5 层扩展至 1024 层，在无演示、无奖励的无监督目标条件设置下，可显著提升自监督对比 RL 算法在模拟移动和操作任务中的性能，不仅提高任务成功率，还能催生更复杂的学习行为。同时强调了批次大小缩放对深层网络对比 RL 的重要性。</p><p><strong>评审评价：</strong> 突破了RL 与深层网络结合的技术瓶颈，提出的范式简单易实施，为 RL 的规模化发展提供了新路径。</p><h4>4.《Why Diffusion Models Don’t Memorize: The Role of Implicit Dynamical Regularization in Training》</h4><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446205" alt=" " title=" " loading="lazy"/></p><p><strong>核心贡献：</strong> 揭示了扩散模型避免训练数据记忆、实现泛化的核心机制—— 隐式动态正则化。通过理论分析与实验验证，识别出两个关键训练时间尺度：早期为数据集无关的泛化阶段（模型生成高质量样本），后期为数据集大小依赖的记忆阶段（训练超过该阶段会出现记忆现象）。其中泛化阶段时长随训练集规模线性增长，记忆阶段时长保持恒定，这一特性使模型在过参数化场景下仍能有效泛化。</p><p><strong>评审评价：</strong> 通过随机矩阵理论将实证观察与形式化理论统一，为生成式AI 的泛化机制研究树立了分析深度标杆，提供了可落地的训练指导。</p><h3>入围论文</h3><h4>1.《Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?》</h4><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446206" alt=" " title=" " loading="lazy"/></p><p><strong>核心发现：</strong> 对"带可验证奖励的强化学习（RLVR）能赋予 LLM 全新推理能力" 的主流假设提出质疑。通过在多模型家族、多算法、多基准（数学、编程、视觉推理）上的系统测试，发现 RLVR 仅提升小 k 值下的 pass@k 分数（抽样效率），但无法激发新的推理模式 ——RLVR 模型的推理路径均包含在基础模型的抽样分布中，且训练会缩小推理能力边界；而蒸馏技术反而能引入新推理模式。</p><p><strong>评审评价：</strong> 该批判性发现具有重要学术价值，为推动RL 范式创新（如持续缩放、多轮智能体 - 环境交互）提供了明确方向。</p><p><a href="https://link.segmentfault.com/?enc=Y1eLDefiX4SntjT3qGwCxA%3D%3D.bIxsW729CxAy6hVLdWZ6ywzMmCAunddwlK170IiTk4jpXiOkZP3SRvEEFHjA%2BFPFYX46YFTWocP%2BZUaoh5j6F60tE%2FKzGsZPpMzaD1NTzV51dpuj65qTIFAV4yoCFYqqkDpo%2BIymMgNDAoQVW%2FhlvD48u5Ik4lIE97SBBegADpg%3D" rel="nofollow" target="_blank">👉一键Lab4AI阅读</a></p><h4>2. 《Optimal Mistake Bounds for Transductive Online Learning》</h4><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446207" alt=" " title=" " loading="lazy"/></p><p><strong>核心贡献：</strong> 解决了持续30 年的在线学习领域开放问题，精准量化了转导式在线学习与标准在线学习的性能差距。证明了对于 Littlestone 维度为 d 的概念类，转导式错误边界至少为 Ω(√d)，且该边界是紧的（存在对应概念类达到此边界），较此前的对数级下界实现指数级提升。同时改进了上界结果，揭示了转导式学习利用未标记数据可实现二次级性能提升，这与 PAC 设置下两者样本复杂度相近的特性形成鲜明对比。</p><p><strong>评审评价：</strong> 证明方法兼具创新性与严谨性，通过"路径树" 结构、稀疏编码、危险区域最小化等多种技术的融合，构建了最优学习算法，是学习理论领域的突破性成果。</p><h4>3. 《Superposition Yields Robust Neural Scaling》</h4><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446208" alt=" " title=" " loading="lazy"/></p><p><strong>核心贡献：</strong> 提出表征叠加（LLM 表征的特征数超过维度）是神经缩放定律的核心驱动因素。基于 Anthropic 玩具模型的实验表明，弱叠加状态下，损失仅在数据特征频率呈幂律分布时遵循幂律缩放；而强叠加状态下，得益于表征向量的几何重叠，损失在广泛频率分布中均与模型维度呈逆幂律缩放。开源 LLM 的实证结果及 Chinchilla 缩放定律均验证了这一结论。</p><p><strong>评审评价：</strong> 超越了对神经缩放定律的单纯观察，深入揭示其内在机制，为优化缩放效果、预测缩放极限提供了关键理论支撑。</p><p>NeurIPS 2025的最佳论文奖项不仅表彰了在各自领域做出突破性贡献的研究，也反映了当前机器学习社区对可解释性、安全性、多样性及理论根基的日益重视。这些工作既有扎实的理论突破，也有影响深远的实践指导，预计将对未来的研究方向和业界实践产生重要影响。</p><p><a href="https://link.segmentfault.com/?enc=p593IsjAK5TxMOEFC1zHpg%3D%3D.GiDmgT5xv4vkYflsDj3JRU2TiqGsjka7fGGBy%2BnEmnZsm0TsrL%2B1ZKQlzgM7zSein9Shf5BPMPmZ4NoBuU9N0NbFIwvgFpXA5W6sMzPTucZyK6AjctWkhwI6PFubPjqo" rel="nofollow" target="_blank">👉参考链接</a></p><p>本文系学术转载，如有侵权，请联系大模型实验室Lab4AI小助手删文</p><h3>Lab4AI支撑“从研究到落地”</h3><p>大模型实验室Lab4AI实现算力与实践场景无缝衔接，<strong>具备充足的H卡算力</strong>，支持模型复现、训练、推理全流程使用，且具备灵活弹性、按需计费、低价高效的特点，解决用户缺高端算力、算力成本高的核心痛点。</p><p>Lab4AI.cn提供实验平台，提供一站式科研工具链！<br/><a href="https://link.segmentfault.com/?enc=kD3aPygybSVbgLLlDLA%2B%2BQ%3D%3D.itzBQ5HuuOBdFi0rV%2BND6c%2BZNNg%2BUwfrFECZE5Qx%2FWLbvm3MBB9e%2Fy4j5srXY6DV747RiV7XLDZcfJOc0%2Bpr4%2FZbprxGU0V8zQLKzvhxqeo%3D" rel="nofollow" target="_blank">👉一键直达</a></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047413855" alt=" " title=" " loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[#智慧文旅：智能体系介绍—多场景管理 智]]></title>    <link>https://segmentfault.com/a/1190000047446229</link>    <guid>https://segmentfault.com/a/1190000047446229</guid>    <pubDate>2025-12-03 15:03:29</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img width="723" height="477" referrerpolicy="no-referrer" src="/img/bVdne5Q" alt="" title=""/></p><h2>一、概述</h2><p>    构建景区多维度、立体化智慧管理体系，通过部署客流监测系统实现精准调度，运用AI视频监控强化安全保障，依托智慧停车系统优化交通动线，借助信息发布与广播系统提升服务触达效率，结合舆情监测构建风险预警机制；同时创新引入AR/VR虚拟漫游、云直播导览等沉浸式体验场景，打造全景可视化数字空间，实现物理景区与数字孪生的深度融合。该体系不仅显著提升景区实时管控能力和应急处置水平，更通过科技赋能创造多维互动体验，有效延长游客驻留时间，为景区精细化运营提供数据支撑，全面推动传统景区向智慧化、数字化服务模式的转型升级。</p><h2>二、智慧文旅部分多场景管理系统介绍</h2><h3>1、景区客流监测系统</h3><p>    景区客流监测系统提供全面的客流分析与管理功能，涵盖客流趋势监测、用户特征与停留时长分析、游客出行方式统计、区域流量超限预警以及高频路径识别，为景区运营与安全管控提供数据支持。<br/><img width="723" height="410" referrerpolicy="no-referrer" src="/img/bVdne4m" alt="" title="" loading="lazy"/></p><h3>2、景区公共广播系统</h3><p>    景区公共广播系统是一种专为旅游景区设计的音频传输和管理系统，旨在通过背景音乐播放、实时通知和紧急广播等功能，提升游客体验并确保安全。<br/><img width="723" height="327" referrerpolicy="no-referrer" src="/img/bVdne4o" alt="" title="" loading="lazy"/></p><h3>3、景区信息发布系统</h3><p>    景区信息发布系统是一种集成化的信息管理与传播平台，系统通过电子显示屏等多种渠道，实时向游客和管理人员发布包括但不限于景区开放时间、票务信息、天气预报、客流量预警、活动安排、游览路线等景区相关信息。旨在提升游客体验，确保信息透明度和实时性，辅助景区进行有效的运营管理。</p><p><img width="723" height="333" referrerpolicy="no-referrer" src="/img/bVdne4x" alt="" title="" loading="lazy"/></p><h3>4、景区舆情管理系统</h3><p>    系统以文旅领域的舆论态势感知为依托，从多维度分析出工作层面、推行层面的游客反馈情况，协助相关负责人快速感知突发事件，利用预警等方式提示景区相关的潜在舆情风险，反映景区内的舆情整体情况。</p><p>    对微博、公众号、贴吧、论坛、博客、APP、报纸、小视频等主流互联网平台及各地地方网站，7*24小时不间断全网跟踪，覆盖上百万优质信源，实时更新舆情动态，具备对数据进行存储、检索、指标构建、业务建模以及可视化分析能力。</p><p>    构建可监测景区整体运行状态的，并可支撑景区规划实施改进的指标数据模型，可基于NLP情感识别算法进行舆论情感判断，根据实际场景，持续优化数据处理和建模分析，不断提升数据模型的性能，统计分析更精准。</p><p>    集成景区相关公开大数据，基于NLP情感识别算法，对舆论分析形成全套解决方案，打造一站式景区相关的数据云屏解决方案，满足相关部门实时大屏监控需求。</p><h3>5、景区智慧停车系统</h3><p>    运用无线通信技术、移动终端技术、GPS定位技术、GIS技术等综合应用于城区及景区停车位的采集、管理、查询、预订与导航服务，实现停车位资源的实时更新、查询、预订与导航服务一体化，实现停车位资源利用率的最大化、停车场利润的最大化和车主停车服务的最优化。为市民、游客的出行提供快速引导停车、实时停车场信息服务，改善局部交通微循环、缓解交通拥堵，有效解决停车难、管理难、监管难等问题。</p><p><img width="452" height="302" referrerpolicy="no-referrer" src="/img/bVdne4F" alt="" title="" loading="lazy"/><img width="550" height="394" referrerpolicy="no-referrer" src="/img/bVdne4G" alt="" title="" loading="lazy"/><img width="324" height="552" referrerpolicy="no-referrer" src="/img/bVdne4J" alt="" title="" loading="lazy"/></p><h3>6、景区视频监控及AI智能分析系统</h3><p>    景区视频监控及AI智能分析系统通过线路规划、可疑人员与异常行为预警、景区寻人、展品热度分析、客流与火灾预警、以及车辆识别等功能，利用大数据及智能分析技术，全面提升景区的安全管理、游客服务与运营决策能力。<br/><img width="723" height="345" referrerpolicy="no-referrer" src="/img/bVdne4N" alt="" title="" loading="lazy"/></p><h3>7、景区全景漫游系统</h3><p>    建设720°全景漫游应用，以视频、音乐、动画等多种形式的展现，将景区内多元化旅游信息、景点信息以更加生动活跃的形式呈现给游客；</p><p>    “识别一下”获取信息；多种创意，游览不再枯燥”，便捷地获取游览信息，提升游客景区体验度。</p><p><img width="436" height="495" referrerpolicy="no-referrer" src="/img/bVdne4R" alt="" title="" loading="lazy"/></p><h3>8、景区数字文旅创新应用系统</h3><p>    景区数字文旅创新应用系统通过VR虚拟全景视频提供沉浸式视觉体验，利用AR技术实现虚实结合的互动游览，并借助云视频微直播服务让游客远程了解景区实况，全方位提升游客的数字化旅游体验。<br/><img width="355" height="350" referrerpolicy="no-referrer" src="/img/bVdne45" alt="" title="" loading="lazy"/><img width="355" height="343" referrerpolicy="no-referrer" src="/img/bVdne46" alt="" title="" loading="lazy"/><img width="361" height="361" referrerpolicy="no-referrer" src="/img/bVdne5b" alt="" title="" loading="lazy"/></p><h2>三、往届回顾</h2><p>    <a href="https://segmentfault.com/a/1190000047392511" target="_blank">智慧文旅整体解决方案：赋能景区智能升级，激活全域营销势能</a></p><p>    <a href="https://segmentfault.com/a/1190000047395646" target="_blank">#数字人不止于“对话”，更在赋能千行百业</a></p><p>    <a href="https://segmentfault.com/a/1190000047414536" target="_blank">智慧文旅景区数字化中枢—“旅商通”，整合票务、二销与客流</a></p><p>    <a href="https://segmentfault.com/a/1190000047429281" target="_blank">#智慧文旅：旅政通，打通文旅数据壁垒，构建一体化运营平台</a></p><h2>四、下篇预告-#智慧文旅：独立应用介绍—多业态管理</h2><p>    #智慧文旅多业态管理系统：是一套专门为旅行社设计的在线服务平台，它允许旅行社便捷地为团队游客批量预订景区门票，支持实时查询可用票量、在线支付、即时获取电子票据等功能，简化旅行社在景区门票预订、购买和管理过程中的各个环节，同时还能与景区的客流管理系统对接，帮助旅行社高效管理团队行程，提升客户体验。</p><h2>五、软件结构</h2><p>    本软件采用的是uniapp+JAVA语言开发，编码规范完全按照阿里巴巴编码规范<br/>    移动端：采用 uni-app 方案，一份代码多终端适配，同时支持 APP、小程序、H5；<br/>    前端采用Vue、Element UI。<br/>    后端采用Spring Boot多模块架构、Spring Security、Redis &amp; Jwt。<br/>    权限认证使用Jwt，支持多终端认证系统。</p>]]></description></item><item>    <title><![CDATA[比提示词更重要！3个技巧教你用好AI的「]]></title>    <link>https://segmentfault.com/a/1190000047446252</link>    <guid>https://segmentfault.com/a/1190000047446252</guid>    <pubDate>2025-12-03 15:02:44</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>引言：别再迷信“神级提示词”</h2><p>很多人用 AI 大模型时，总觉得如果 AI 回答不好，是因为自己的“咒语”（提示词）念得不对。大家拼命在网上找各种“神级提示词模板”，试图用一句话解决所有问题。</p><p>但其实，<strong>决定 AI 回答质量的，往往不是你输入的那一句话，而是多轮对话的过程「上下文」（Context）。</strong></p><p>我们在实际使用 AI 的过程中，不可能一句提示词就能得到我们想要的东西，而是通过多轮对话，不断调整才能唠出好东西。</p><h2>一、 上下文 VS 提示词：一次性指令与连续对话</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446254" alt="" title=""/></p><p>我们最容易犯的错误，就是把 AI 当成搜索引擎用：问一句，回一句，用完即走。</p><p>但大模型最厉害的地方在于​<strong>多轮对话</strong>​。</p><ul><li><strong>提示词（Prompt）：</strong> 就像是你对 AI 说的一句指令，一次性的。</li><li><strong>上下文（Context）：</strong> 是你们之前聊过的所有内容。它是连贯的、持续的。</li></ul><p><strong>如果把和 AI 聊天比作“带实习生”：</strong></p><p>提示词只是你随口吩咐的一个任务；带过人的都知道，一句话根本搞不定实习生。</p><p>而上下文，是你给实习生看的所有过往项目资料、会议记录和操作手册。资料越全、背景越清晰，实习生干活越靠谱。</p><h2>二、 原理揭秘：AI 其实是个“健忘症”</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446255" alt="" title="" loading="lazy"/></p><p>你以为 AI 像人一样，聊久了就有感情、有记忆？NONONO\~</p><p><strong>本质上，AI 是一个没有任何记忆的“文字接龙机器”。</strong></p><p>当你发出第 10 句话时，AI 并不是“记住了”前 9 句话。实际上，系统是在后台把你这 10 句话打包，一股脑儿全塞给 AI。AI 必须以极快的速度，把这 10 句话​<strong>从头到尾重读一遍</strong>​，假装自己记得，然后预测出第 11 句话。</p><p><strong>上下文，就是 AI 每次回答前必须复习的“临时小抄”。</strong></p><p>没有这个小抄，AI 瞬间就会失忆，连你是谁、刚才聊了什么都会忘得一干二净。</p><blockquote><p>LLM 运作方式确实是 <strong>Autoregressive Generation</strong> (自回归生成) 或 <strong>Next-Token Prediction</strong> (下一个词元预测)，即基于整个输入序列（含对话历史）来决定下一个输出。</p><p><a href="https://link.segmentfault.com/?enc=loTrNcd2IquNhTK5u%2B6Ndg%3D%3D.ICB%2BPPrSzj9AvzxHSefHGqK7oBRayMg2d8ZwARtzzi3FPM0BnpEl1QiH9nzim%2BFk" rel="nofollow" target="_blank">《Attention Is All You Need》| ArXiv</a></p></blockquote><h2>三、 警惕！上下文的“三大缺陷”</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446256" alt="" title="" loading="lazy"/></p><p>既然上下文是“小抄”，那是不是抄得越多越好？并不是。目前的 AI 模型在处理上下文时，有三个明显的短板：</p><p><strong>1. 内存有限：</strong> 这个“小抄”是有字数上限的。如果你给的资料太多，超过了它的处理极限，最早的聊天记录就会被强行“挤”出去。就像一个装满水的杯子，新水倒进去，旧水就流出来了。</p><p><strong>2. 三明治效应：</strong> 研究发现，AI 对上下文的记忆主要集中在​<strong>开头</strong>​（最早的设定）和​<strong>结尾</strong>​（你最新的提问）。如果你把关键信息塞在几万字的对话中间，AI 大概率会记不住的。</p><blockquote><p>述了 LLM 在处理长上下文时，对开头（Primacy Bias/首因效应）和结尾（Recency Bias/近因效应）的信息召回率最高，而中间部分最差的现象。</p><p><a href="https://link.segmentfault.com/?enc=wGLBewONA%2FSmNX5jt1IHgw%3D%3D.ZT2wNHOtaREsYLHpulzWuCECpexCzi0rl4QyKgNbGPwUS%2FJsZIy83JUGQmhRvIgt" rel="nofollow" target="_blank">《Lost in the Middle: How Language Models Use Long Contexts》| ArXiv</a></p></blockquote><p><strong>3. 信息噪声：</strong> 给的信息越杂，AI 越容易晕。如果你在对话里塞了一堆无关的文档、乱七八糟的要求，AI 就会“幻觉”，开始胡言乱语。这叫“噪声中毒”。</p><blockquote><p><strong>​ ​</strong>In-Context Learning (ICL) 对输入噪声（如不相关或错误的演示示例）的敏感性。不相关的文档或指令会分散模型的注意力，增加 Hallucination (幻觉) 的风险。</p><p><a href="https://link.segmentfault.com/?enc=6H8DTqSobGnMTVpkeFoTbA%3D%3D.cRVd8C3H%2FwF9U5KR7BamR0krpTMKqDby5K5XjS12citf2gjrjTMfS5Cx0YLFcYha" rel="nofollow" target="_blank">《On the Noise Robustness of In-Context Learning for Text Generation》|ArXiv</a></p></blockquote><h2>四、 高手秘籍：3 招用好上下文</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047446257" alt="" title="" loading="lazy"/></p><p>理解了原理，我们就能对症下药。普通人只需掌握这 3 个技巧，就能大幅提升 AI 的智商。</p><h3>技巧 1：一个对话只聊一个话题</h3><p><strong>不要在一个对话框里聊所有事情。</strong></p><ul><li><strong>错误做法：</strong> 上一秒让 AI 写代码，下一秒问它红烧肉怎么做，接着又让它翻译论文。这会导致“小抄”里充满了无关信息，干扰 AI 判断。</li><li><strong>正确做法：</strong> <strong>新建对话（New Chat）。</strong> 写代码开一个窗口，写文案开一个窗口。每次点击“新建对话”，就相当于给 AI 换了一本崭新的、干净的“小抄”，让它没有任何负担地开始工作。</li></ul><h3>技巧 2：开局“立规矩”，重要信息全部说完</h3><p>既然 AI 有“三明治效应”，记得住开头，那我们就把最重要的信息放在<strong>第一条提示词</strong>里。</p><p>在对话开始的第一次输入中，你要明确告诉 AI：</p><ul><li>​<strong>你是谁</strong>​（角色设定，如：你是一个资深翻译）</li><li>​<strong>你要干什么</strong>​（核心任务）</li><li>​<strong>有什么限制</strong>​（不要废话，只输出结果）</li></ul><p>把地基打牢了，后面的楼才不会歪。不要等到聊了一半，才想起来补充核心要求。</p><h3>技巧 3：定期“敲黑板”，重复关键指令</h3><p>如果你的对话很长（比如让 AI 写长篇小说或处理超长文档），聊到后面 AI 开始跑题、变笨了，怎么办？</p><p><strong>不要骂它，它只是忘了，或者搞不清楚重点了。</strong></p><p>你需要充当“课代表”，在对话中途​<strong>总结一下之前的进度</strong>​，或者​<strong>把最开始的要求再发一遍</strong>​。</p><p><strong>话术示例：</strong></p><blockquote>“为了避免你忘记，我重申一下我们的目标是 XXX，刚才我们已经完成了 YYY，接下来请继续做 ZZZ。”</blockquote><p>这相当于强行把关键信息再次写到“小抄”的末尾（最新位置），强迫 AI 重新聚焦。</p><p><strong>总结一下：</strong> 用好 AI，不要只纠结由于那一句“提示词”写得够不够 NB。<strong>管理好「上下文」，保持对话环境的纯净、关键信息的突出，才是让 AI 持续输出高质量内容的秘诀。</strong></p>]]></description></item><item>    <title><![CDATA[生产研发管理的“三环模型”：技术、流程、]]></title>    <link>https://segmentfault.com/a/1190000047446270</link>    <guid>https://segmentfault.com/a/1190000047446270</guid>    <pubDate>2025-12-03 15:02:05</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>是什么：研发管理正在经历系统性重构<br/>制造业研发管理本质上是一个涉及数据、流程与协作的复杂系统工程。传统模式下，企业常面临设计资料分散存储、版本管理依赖人工命名、BOM数据准确率低、跨部门协作效率低下等问题。这些痛点不仅制约研发效率，更直接影响创新能力和市场响应速度。<br/>现代研发协同平台通过系统化重构研发流程，将需求导入、设计开发、评审决策和生产准备整合为统一数字环境。此类平台的核心价值在于打破信息孤岛，构建连续、透明的数据流，使研发管理从“断裂式”运作转向“一体化”协同。<br/>怎么做：从数据协同到智能预防的三层进化<br/>研发数字化需通过分层建设实现渐进式突破，具体可分为以下三层：<br/>第一层：研发数据中枢建设<br/>通过产品数据管理（PDM）系统实现全生命周期数据标准化，零部件从创建到报废形成完整数字履历。系统支持自动审批流程与移动端处理，显著提升审批效率。例如，某企业通过智能相似性检测功能，将零部件复用率提高35%，大幅减少重复设计资源浪费。<br/>第二层：三维协同轻量化应用<br/>借助三维协同工具，直接转换和Web端查看多种CAD格式，生产人员可通过扫码快速查看工序模型，质量人员在线完成评审。实际应用中，某企业模型查看效率提升60%，数据准备时间减少75%，有效压缩新产品试制周期。<br/>第三层：智能质量预防体系<br/>通过失效模式与影响分析（FMEA）系统，基于历史问题库自动分析潜在失效原因并推荐措施，在研发前期识别超80%的潜在风险。某工程机械企业应用后，FMEA编制效率提升20%，实现全自动表单生成，推动质量管理从事后补救转向事前预防。<br/>案例：广域铭岛助力制造企业实现研发跃迁<br/>广域铭岛作为工业互联网实践者，其Geega捷做平台已在家电、汽车零部件等行业验证价值。某白电企业通过平台实现用户需求与产品设计的直接对接，设计变更效率提升50%，产品上市周期缩短30%。平台的三维轻量化功能支持销售部门直接调取模型向客户展示，形成“设计即销售”的新模式。<br/>在汽车零部件领域，某变速箱生产企业借助平台建立统一数据中枢，BOM准确率达98%，并通过FMEA模块提前识别20余个设计风险，避免量产质量事故。企业反馈：“系统正在帮我们思考。”<br/>研发数字化转型通过平台化工具实现知识沉淀、流程优化与协同创新的一体化推进，助力企业从经验驱动转向数据驱动，在市场竞争中赢得先机。</p>]]></description></item><item>    <title><![CDATA[为何前端圈现在不关注源码了？ 悲伤的煎鸡]]></title>    <link>https://segmentfault.com/a/1190000047446305</link>    <guid>https://segmentfault.com/a/1190000047446305</guid>    <pubDate>2025-12-03 15:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h3>开始</h3><p>大家有没有发现一个现象：最近 1-2 年，前端圈不再关注源码了。</p><p>最近 Vue3.6 即将发布，alien-signal 不再依赖 Proxy 可更细粒度的实现响应式，vapor-model 可以不用 vdom 。</p><p>Vue 如此大的内部实现的改动，我没发现多少人研究它的源码，我日常关注的那些博客、公众号也没有发布源码相关的内容。</p><p>这要是在 3 年之前，早就开始有人研究这方面的源码了，博客一篇接一篇，跟前段时间的 MCP 话题一样。</p><p>还有前端工具链几乎快让 Rust 重构一遍了，rolldown turbopack 等产品使得构建效率大大提升。这要是按照 3 年之前对 webpack 那个研究态度，你不会 rust 就不好意思说自己是前端了。</p><p>不光是这些新东西，就是传统的 Vue React 等框架源码现在也没啥热度了，我关注每日的热门博客，几乎很少有关于源码的文章了。</p><p>这是为什么呢？</p><p><img width="583" height="388" referrerpolicy="no-referrer" src="/img/bVdne6C" alt="" title=""/></p><h3>泡沫</h3><p>看源码，其实是一种泡沫，现在破灭了。所谓泡沫，就是它的真实价值之前一直被夸大，就像房地产泡沫。</p><p>前几年是互联网发展的红利期，到处招聘开发人员，大家都拿着高工资，随便跳槽就能涨薪 20% ，大家就会误以为真的是自己的能力值这么多钱。</p><p>而且，当年面试时，尤其是大公司，为了筛选出优秀的候选人（因为培训涌入的人实在太多），除了看学历以外，最喜欢考的就是算法和源码。</p><p>确实，如果一个技术人员能把算法和源码看明白，那他肯定算是一个合格的程序员，上限不好说，但下限是能保证的。就像一个人名牌大学毕业的，他的能力下限应该是没问题的。</p><p>大公司如此面试，其他公司也就跟风，面试题在网络上传播，各位程序员也就跟风学习，很快普及到整个社区。</p><p>所以，如果不经思考，表面看来：就是因为我会算法、会源码，有这些技能，才拿到一个月几万甚至年薪百万的工资。</p><p>即，源码和算法价值百万。</p><h3>坑位</h3><p>技术大厂，前端-后端-测试，新一线和一二线城市等地均有<a href="https://link.segmentfault.com/?enc=2xfQ%2BnwRWfNwk4EO%2BQ2ceA%3D%3D.8wil8kDL2Nq9IpPlwQ1JHBk0GOZg0zXOg%2BpZOI%2B3LV0%3D" rel="nofollow" target="_blank">坑位</a>，感兴趣可以试试。待遇和稳定性都不错~</p><p><strong>现状</strong></p><p>现在泡沫破灭了。业务没有增长了，之前是红利期，现在是内卷期，之前大量招聘，现在大量裁员。</p><p>你看这段时间淘宝和美团掐架多严重，你补贴我补贴，你广告我也广告。如果有新业务增长，他们早就忙着去开疆拓土了，没公司在这掐架。</p><p>面试少了，算法和源码也就没有发挥空间了。关键是大家现在才发现：原来自己会算法会源码，也会被裁员，也拿不到高工资了。</p><p>哦，原来之前自己的价值并不是算法和源码决定的，最主要是因为市场需求决定的。哪怕我现在看再多的源码，也少有面试机会，那还看个锤子！</p><p>现在企业预算缩减，对于开发人员的要求更加返璞归真：降低工资，甚至大量使用外包人员代替。</p><p>所以开发人员的价值，就是开发一些增删改查的日常 web 或 app 的功能，什么算法和框架源码，真实的使用场景太少。</p><p><strong>看源码有用吗？</strong></p><p>答案当然是肯定的。学习源码对于提升个人技术能力是至关重要的，尤其是对于初学者，学习前辈经验是个捷径。</p><p>但我觉得看 Vue react 这些源码对于开发提升并不会很直接，它也许会潜移默化的提升你的“内功”，但无法直接体现在工作上，除非你的工作就是开发 Vue react 类的框架。</p><p>我更建议大家去看一些应用类的源码，例如 UI 组件库的源码看如何封装复杂组件，例如 vue-admin 看如何封装一个 B 端管理后台。</p><p>再例如我之前学习 AI Agent 开发，就看了 langChain 提供的 agent-chat-ui 和 Vercel 提供的 ai-chatbot 这两个项目的源码，我并没有直接看 langChain 的源码。</p><p>找一些和你实际开发工作相关的一些优秀开源项目，学习他们的设计，阅读他们的源码，这是最直接有效的。</p><p>——转载自：前端双越老师</p>]]></description></item><item>    <title><![CDATA[用开源模型强化你的 OCR 工作流 Hu]]></title>    <link>https://segmentfault.com/a/1190000047445798</link>    <guid>https://segmentfault.com/a/1190000047445798</guid>    <pubDate>2025-12-03 14:05:06</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <blockquote>我们在这篇文章中新增了 <a href="https://link.segmentfault.com/?enc=M065tpC5Pr4H4YHyBHX6jg%3D%3D.GMSErAQFH26E9M6FIs90rZzEUM9NPJfx5wXw5ZonqpLs12mrUt7DUOKG0WehvvdY" rel="nofollow" target="_blank">Chandra</a> 和 <a href="https://link.segmentfault.com/?enc=UK6uYrxSQ5hFaCpdZVmuTA%3D%3D.GOafolm%2BcoIpG3PmFJcOgXbigshoh3h4ZTZwkujK9yi9dUR1Y%2Fts5Tr%2FxVKg%2BCEq" rel="nofollow" target="_blank">OlmOCR-2</a>，并附上了它们在 OlmOCR 基准上的得分 🫡</blockquote><p><strong>摘要:</strong>  <br/>强大的视觉语言模型 (Vision-Language Models, VLMs) 的崛起，正在彻底改变文档智能 (Document AI) 的格局。每种模型都有其独特的优势，因此选择合适的模型变得棘手。相比闭源模型，开源权重的模型在成本效率和隐私保护上更具优势。为了帮助你快速上手，我们整理了这份指南。</p><p>在本指南中，你将了解到:</p><ul><li>当前 OCR 模型的整体格局及其能力</li><li>何时需要微调模型，何时可直接使用</li><li>为你的场景选择合适模型时应考虑的关键因素</li><li>如何超越传统 OCR，探索多模态检索与文档问答</li></ul><p>读完之后，你将知道如何选择合适的 OCR 模型、开始构建应用，并对文档 AI 有更深入的理解。让我们开始吧！</p><h2>现代 OCR 简介</h2><p>光学字符识别 (Optical Character Recognition，简称 OCR) 是计算机视觉领域最早、也是持续时间最长的研究方向之一。AI 的许多早期实际应用都集中在“将印刷文字转化为可编辑的数字文本”上。</p><p>随着 <a href="https://link.segmentfault.com/?enc=n5H4cKcPk0WDub7Cf0v6hQ%3D%3D.4odlmBYRYdDAUdbvClR3DDSL38ph%2F%2FoYsyN4%2B7PSwlc%3D" rel="nofollow" target="_blank">视觉语言模型 (Vision-Language Models, VLMs)</a> 的兴起，OCR 的能力迎来了飞跃式提升。如今，许多 OCR 模型都是在现有 VLM 的基础上进行微调得到的。但现代模型的能力已远超传统 OCR —— 你不仅可以识别文字，还能基于内容检索文档，甚至直接进行问答。</p><p>得益于更强大的视觉理解能力，这些模型能处理低质量扫描件、理解复杂元素 (如表格、图表、图片等) ，并将文本与视觉内容融合，以回答跨文档的开放式问题。</p><h3>模型能力</h3><h4>文本识别</h4><p>最新的模型能够将图像中的文字转录为机器可读格式。输入内容可能包括:</p><ul><li>手写文字</li><li>各类文字体系 (如拉丁文、阿拉伯文、日文等)</li><li>数学公式</li><li>化学方程式</li><li>图片、版面或页码标签</li></ul><p>OCR 模型会将这些内容转换为机器可读的文本，输出格式多种多样，比如 <strong>HTML、Markdown</strong> 等。</p><h4>处理文档中的复杂组件</h4><p>除了文字，某些模型还能识别:</p><ul><li>图片</li><li>图表</li><li>表格</li></ul><p>部分模型能识别文档中图片的精确位置，提取其坐标，并在输出中将图片嵌入对应位置。<br/>另一些模型还能为图片生成说明文字 (caption) ，并在适当位置插入。这对于后续将机器可读输出传入 LLM (大型语言模型) 尤为有用。</p><p>例如， <a href="https://link.segmentfault.com/?enc=u91LbfAAMbUZDdfN3dAhYg%3D%3D.Ev3cKOhZnhAJNjRHqv4U5qJ9XkjIUtwEcJhUzjVU0vWtT%2FKuuMWWZBqxzA3rWK4o" rel="nofollow" target="_blank">OlmOCR (AllenAI 出品)</a>  和  <a href="https://link.segmentfault.com/?enc=7wOssW3%2BlogIc%2BGvjqor4w%3D%3D.WjAmg0Gpf%2BOCYG6rf5u0sQuDPe0d9QHypeGy0R%2FqR6G4oml%2BglC1LvyPJVz9fMbf" rel="nofollow" target="_blank">PaddleOCR-VL (PaddlePaddle 出品)</a>  就是代表。</p><p>不同模型使用不同的输出格式，例如 <strong>DocTags</strong>、<strong>HTML</strong>、<strong>Markdown</strong> (后文<strong>输出格式</strong>一节有详细说明) 。<br/>模型处理表格与图表的方式通常取决于所采用的输出格式:</p><ul><li>有些模型将图表当作图片直接保留；</li><li>有些模型则会将其转换为可解析的结构化格式，如 Markdown 表格或 JSON。<br/>例如，下图展示了一个柱状图如何被转换成机器可读的形式:</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047445816" alt="" title=""/></p><p>同样地，表格中的单元格也会被解析为机器可读格式，并保留列名与标题的上下文关系: </p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047445817" alt="" title="" loading="lazy"/></p><h4>输出格式</h4><p>不同 OCR 模型采用的输出格式不同，以下是几种主流格式的简介:</p><ul><li><strong>DocTag:</strong> 一种类似 XML 的文档标记格式，可表达位置信息、文本样式、组件层级等。下图展示了一篇论文如何被解析为 DocTags。该格式由开源的 Docling 模型使用。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047445818" alt="" title="" loading="lazy"/></p><ul><li><strong>HTML:</strong> 是最常见的文档解析格式之一，能较好地表达结构与层级信息。</li><li><strong>Markdown:</strong> 人类可读性最强，格式简洁，但表达能力有限 (如无法准确表示多列表格) 。</li><li><strong>JSON:</strong> 通常用于表示表格或图表中的结构化信息，而非完整文档。</li></ul><p>选择合适的模型，取决于你对输出结果的用途:</p><table><thead><tr><th>目标场景</th><th>推荐格式</th></tr></thead><tbody><tr><td><strong>数字化重建</strong> (重现原始文档版式)</td><td>使用保留布局的格式，如 DocTags 或 HTML</td></tr><tr><td><strong>LLM 输入或问答场景</strong></td><td>使用输出 Markdown 和图像说明的模型 (更接近自然语言)</td></tr><tr><td><strong>程序化处理</strong> (如数据分析)</td><td>选择能输出结构化 JSON 的模型</td></tr></tbody></table><h4>OCR 的位置感知</h4><p>文档常常结构复杂，比如多栏文本、浮动图片、脚注等。早期的 OCR 模型通常先识别文字，再通过后处理手动推断页面布局，以恢复阅读顺序——这种方式既脆弱又易错。</p><p>现代 OCR 模型则会在输出中直接包含版面布局信息 (称为 <strong>“锚点”或 “grounding”</strong>) ，如文字的边界框 (bounding box) 。<br/>这种“锚定”机制能有效保持阅读顺序与语义连贯性，同时减少“幻觉式识别” (即错误生成内容) 。</p><h4>模型提示</h4><p>OCR 模型通常接收图像输入，并可选地接受文字提示 (prompt) ，这取决于模型的架构与预训练方式。</p><p>部分模型支持<strong>基于提示的任务切换</strong>，例如  <a href="https://link.segmentfault.com/?enc=fLgUbTW091TD1lmNMy36JA%3D%3D.a3OJe6oJ%2ButLtLCWTEx%2BNPDmIdP60E0bHr35zJGxqraP3KAC7vc1GuFWJeVR7DPN" rel="nofollow" target="_blank">granite-docling</a>  可以通过不同提示词执行不同任务:</p><ul><li>输入 “Convert this page to Docling” → 将整页转换为 DocTags；</li><li>输入 “Convert this formula to LaTeX” → 将页面中的公式转换为 LaTeX。</li></ul><p>而另一些模型则只能处理整页内容，任务由系统提示固定定义。<br/>例如，<a href="https://link.segmentfault.com/?enc=9OJ9hRxXWX7TxCJpW%2F3aTg%3D%3D.WLlGxaVgH9ql%2FlNJzn60PrY5QQVQmTyLaAssrMFiqvHuxCCifHeSvpDNt59B2xVFu%2BksLZ1O7TzaD1PfKIq5cW74YKnIJ7CCYab44nVvtLA%3D" rel="nofollow" target="_blank">OlmOCR (AllenAI)</a>  使用一个长系统提示词进行推理。OlmOCR 本质上是基于 Qwen2.5VL 微调的 OCR 模型，虽然它也能处理其他任务，但在 OCR 场景之外性能会明显下降。</p><h2>前沿开源 OCR 模型</h2><p>过去一年，我们见证了 OCR 模型领域的爆发式创新。由于开源生态的推动，不同团队之间可以相互借鉴、迭代，从而加速了技术进步。一个典型例子是 AllenAI 发布的 <strong>OlmOCR</strong>，它不仅开源了模型本身，还公开了训练所用的数据集，为他人提供了可复现与可扩展的基础。<br/>这个领域正以前所未有的速度发展，但如何选择最合适的模型，仍然是一个不小的挑战。</p><h3>最新模型对比</h3><p>为了帮助大家更清晰地了解当前格局，以下是一些当前主流开源 OCR 模型的非完整对比。<br/>这些模型都具备版面理解能力 (layout-aware) ，能解析表格、图表与数学公式。<br/>各模型支持的语言范围可在其 model card 中查看。除 <strong>Chandra</strong> (OpenRAIL 许可) 与 <strong>Nanonets</strong> (许可证不明) 外，其余均为开源许可。</p><p>表格中展示的平均得分来自 <strong>Chandra</strong> 与 <strong>OlmOCR</strong> 模型卡中在 <strong>OlmOCR Benchmark</strong> (仅英文) 上的测试结果。<br/>此外，许多模型基于 <strong>Qwen2.5-VL</strong> 或 <strong>Qwen3-VL</strong> 微调，因此我们也附上了 Qwen3-VL 作为参考。</p><table><thead><tr><th align="left">模型名称</th><th align="left">输出格式</th><th align="left">特性</th><th align="left">模型大小</th><th align="left">是否多语言</th><th align="left">OlmOCR 基准平均得分</th></tr></thead><tbody><tr><td align="left"><a href="https://link.segmentfault.com/?enc=2e8odK%2FpkiJHHKNYIUFaww%3D%3D.GE%2BD1Z62ZpkQ0y7ts%2FZnrDz3qR7nFS1KxRXXSEPnjMzuc3m3KLcvlWpZotWkXDlKPpvXE35O%2BWchdO5fXjmo7TmATtOhExO7ZJ9j1vKP5aw%3D" rel="nofollow" target="_blank">Nanonets-OCR2-3B</a></td><td align="left">结构化 Markdown (含语义标注、HTML 表格等)</td><td align="left">图片自动生成说明<br/>可提取签名与水印<br/>识别复选框、流程图、手写体</td><td align="left">4B</td><td align="left">✅ 英语、中文、法语、阿拉伯语等</td><td align="left">N/A</td></tr><tr><td align="left"><a href="https://link.segmentfault.com/?enc=8aRdNCqzKMulId9%2FABeFCw%3D%3D.KAr1HLQMuX%2BXi6RGyNGmf2IFuzoiaR9i9lRhI7elqQCTlg8nSUBveIzS6%2Fi6KxY8oPScA8nHl9UizRFu%2F2Y7Zpc7PlM3r%2BYxAoc275FbmoA%3D" rel="nofollow" target="_blank">PaddleOCR-VL</a></td><td align="left">Markdown、JSON、HTML 表格与图表</td><td align="left">支持手写体与旧文档<br/>支持提示词输入<br/>可将表格与图表转换为 HTML<br/>可直接提取并插入图片</td><td align="left">0.9B</td><td align="left">✅ 支持 109 种语言</td><td align="left">N/A</td></tr><tr><td align="left"><a href="https://link.segmentfault.com/?enc=N2fZAjSJdExHYZOZ1NFLyg%3D%3D.cmyUvCPVfPPMXIvr4KR0TWmrnsZMbshkOTR4ZRxrz8uLW04AR2wCgyDqP%2FdPSjWq" rel="nofollow" target="_blank">dots.ocr</a></td><td align="left">Markdown、JSON</td><td align="left">支持 grounding<br/>可提取并插入图片<br/>支持手写体</td><td align="left">3B</td><td align="left">✅ 多语言 (具体未说明)</td><td align="left">79.1 ± 1.0</td></tr><tr><td align="left"><a href="https://link.segmentfault.com/?enc=KfKw6xDZoI0vzq4bFBK26w%3D%3D.umDL%2B%2Fq9QZqo68rQ6bPNaLrHaXqmgE5RbYXqJN%2FDUhtrNJGjTJ9a5b6th7fMad92" rel="nofollow" target="_blank">OlmOCR-2</a></td><td align="left">Markdown、HTML、LaTeX</td><td align="left">具备 grounding 能力<br/>优化了大规模批处理性能</td><td align="left">8B</td><td align="left">❎ 仅英语</td><td align="left">82.3 ± 1.1</td></tr><tr><td align="left"><a href="https://link.segmentfault.com/?enc=bQDOIWgRISNEDCQexxbA%2Bg%3D%3D.we0D2j596GjyJ%2B0XyRL5Gg2nx4sVp16MDhO5NigjnnjoMgP%2FWghJYvWW3O4%2FhtLo" rel="nofollow" target="_blank">Granite-Docling-258M</a></td><td align="left">DocTags</td><td align="left">支持基于提示的任务切换<br/>可指定元素位置<br/>输出内容丰富</td><td align="left">258M</td><td align="left">✅ 英语、日语、阿拉伯语、中文</td><td align="left">N/A</td></tr><tr><td align="left"><a href="https://link.segmentfault.com/?enc=WF5Wq2wdhx6oi9l91eKezA%3D%3D.hfLvaKo4FlZYM1hc%2Fo9ZRAO1R59nSgubeQnniIoJQxjm8HHX7yhfotsXF0foGxgZ" rel="nofollow" target="_blank">DeepSeek-OCR</a></td><td align="left">Markdown、HTML</td><td align="left">支持通用视觉理解<br/>能将图表、表格完整渲染为 HTML<br/>识别手写体<br/>内存高效，图像文字识别能力强</td><td align="left">3B</td><td align="left">✅ 近 100 种语言</td><td align="left">75.4 ± 1.0</td></tr><tr><td align="left"><a href="https://link.segmentfault.com/?enc=QHnce2fMme5fquh8cOjQNw%3D%3D.N8wULDb49Rwy2svpLklaaAGXnbDZDEV2VfMEOa3z%2B8qvJM98fdwUzy%2BOuu5E8b4L" rel="nofollow" target="_blank">Chandra</a></td><td align="left">Markdown、HTML、JSON</td><td align="left">具备 grounding 能力<br/>能原样提取并插入图片</td><td align="left">9B</td><td align="left">✅ 支持 40+ 种语言</td><td align="left">83.1 ± 0.9</td></tr><tr><td align="left"><a href="https://link.segmentfault.com/?enc=ZVDB28evi2sdvgF4Ifcd0Q%3D%3D.6RvU5KKvclneP7o3EDppjzEur53zgAcCuZ5hvFSjPHAnwLul%2FJj2eBJA%2FoREGWFb" rel="nofollow" target="_blank">Qwen3-VL</a></td><td align="left">任意格式输出 (多模态语言模型)</td><td align="left">识别古文文本<br/>支持手写体<br/>图片可原样提取插入</td><td align="left">9B</td><td align="left">✅ 支持 32 种语言</td><td align="left">N/A</td></tr></tbody></table><blockquote><strong>注:</strong> <br/>Qwen3-VL 是一款强大的通用视觉语言模型，支持多种文档理解任务，但并未针对 OCR 任务进行特别优化。<br/>其他模型多采用固定提示词进行微调，专为 OCR 任务设计。<br/>因此若使用 Qwen3-VL，建议尝试不同提示词以获得更佳效果。</blockquote><p>你可以通过这个 <a href="https://link.segmentfault.com/?enc=rbfgHYW8RHhW93DoddIB7w%3D%3D.91psp3FVO%2BNe83TnGebUmfHy4muuNi%2FrpghURvIlPp4uKhYIANBBTQjg2qmT7LGp" rel="nofollow" target="_blank">在线演示</a> 体验部分最新模型并比较输出效果: </p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047445819" alt="" title="" loading="lazy"/></p><h3>模型评估</h3><h4>基准测试</h4><p>没有任何一款模型能在所有场景中都是“最优”。<br/>例如: 表格应以 Markdown 还是 HTML 呈现？哪些元素需要提取？如何量化文本识别准确度？👀<br/>这些都取决于具体任务。<br/>目前已有多个公开评测集与工具，但仍无法覆盖所有情况。<br/>我们推荐以下常用的评测基准:</p><ol><li><a href="https://link.segmentfault.com/?enc=qosVgfcXBUgSLJUg0O7gzQ%3D%3D.wJuQCNHXmGe2ark0Dto4wUhoGjY9BxXOA2AwU%2B0cUl%2Fpf0S6NPJ0wiT4xBz3h3vP" rel="nofollow" target="_blank">OmniDocBenchmark</a></li></ol><ul><li><p>这是目前使用最广泛的文档识别基准之一。</p><ul><li>覆盖文档类型丰富: 书籍、杂志、教材等。</li><li>支持多格式 (HTML 与 Markdown) 表格评测。</li><li>使用新型算法评估阅读顺序；公式会在评估前标准化。</li><li>指标基于“编辑距离”或“树编辑距离” (表格部分) 。</li><li>标注数据部分由 SoTA VLM 或传统 OCR 生成。</li></ul></li></ul><ol start="2"><li><a href="https://link.segmentfault.com/?enc=HcuWfYdTjgrWZBbebg7LSw%3D%3D.t%2BZyC1V0IgNQh5fVgghPk9s4W6etg8MOTRHViJMOfIJk5HG8L6hkwyI6I3pLS2ZA" rel="nofollow" target="_blank">OlmOCR-Bench</a></li></ol><ul><li><p>采用“单元测试式”评估方式。</p><ul><li>例如: 表格评估通过验证单元格间关系完成。</li><li>数据源为公开 PDF，标注来自多种闭源 VLM。</li><li>特别适合评估英文 OCR 模型。</li></ul></li></ul><ol start="3"><li><a href="https://link.segmentfault.com/?enc=5753SzptT3Iw7kAuI2XT9Q%3D%3D.tMwyP2pH1XX%2BPBag38931GAuMZ6BPTscvCkCeYn8jYxjzBksZZLUaQESn4cn9RqY" rel="nofollow" target="_blank">CC-OCR (Multilingual)</a></li></ol><ul><li><p>与前两者相比，CC-OCR 的文档质量与多样性较低。</p><ul><li>但它是<strong>唯一</strong>涵盖英语与中文以外语言的多语言评测集。</li><li>图片多为低质量拍摄，文本较少。</li><li>尽管不完美，但目前仍是最佳的多语言评估选项。</li></ul></li></ul><p>在不同文档类型、语言与任务场景下，模型表现差异明显。<br/>如果你的业务领域不在现有评测集中体现，我们建议收集代表性样本，构建自定义测试集，比较不同模型在你的特定任务上的效果。</p><h4>成本与效率</h4><p>大多数 OCR 模型的规模在 <strong>3B～7B 参数</strong>之间，也有一些小型模型 (如 PaddleOCR-VL 仅 0.9B) 。<br/>成本不仅与模型大小相关，还取决于是否支持高效推理框架。</p><p>例如:</p><ul><li><strong>OlmOCR-2</strong> 提供 vLLM 与 SGLang 实现。</li><li>若在 H100 GPU ($2.69/小时) 上运行，推理成本约为 **每百万页 $178**。</li><li><strong>DeepSeek-OCR</strong> 能在一块 40GB A100 上每天处理 <strong>20 万页以上</strong>。</li><li>以此估算，其成本与 OlmOCR 大致相当 (视 GPU 供应商而定) 。</li></ul><p>若任务对精度要求不高，还可选择 <strong>量化版本 (Quantized Models)</strong> ，进一步降低成本。<br/>总体而言，开源模型在大规模部署时几乎总比闭源方案更经济。</p><h4>开源 OCR 数据集</h4><p>尽管近年来开源 OCR 模型大量涌现，但公开的训练与评测数据集仍相对稀缺。<br/>一个例外是 AllenAI 的  <a href="https://link.segmentfault.com/?enc=tQpyqfEBX1GWS73doPaQvA%3D%3D.C1cqjLDTL2Nw4agRfjGrjkAGBDM%2B0mREOGwiVCsm%2FtHFXo7KWd7Rqqe7cgZYg5Uj" rel="nofollow" target="_blank">olmOCR-mix-0225</a>，<br/>截至目前，该数据集已被用于训练至少  <a href="https://link.segmentfault.com/?enc=nzLiKq89tZA%2FWn8ar0IFlA%3D%3D.t4U8gsOyrIk%2FlCmXmn3JWgNq%2BsPgvPQHzth929tmKCNac%2BVvUna7OI8or43IHYvIUiBrobZhSicn77WmvwbTzQ%3D%3D" rel="nofollow" target="_blank">72 个模型</a>  (可能更多) 。</p><p>更广泛的数据共享将极大推动开源 OCR 的进步。<br/>以下是几种常见的数据集构建方式:</p><ul><li><strong>合成数据生成 (Synthetic Data Generation)</strong> <br/>例如: <a href="https://link.segmentfault.com/?enc=okHSjukoWQS8TX%2F%2BJ6k0rw%3D%3D.rgrHRv3EiX%2BiB%2B08nxK0OpePkmsRnTcfWmmS9EmaEnVyO3K8nNa4w24hLiXG%2FFrJQPFB8d6cccyDR2T5tuorCw%3D%3D" rel="nofollow" target="_blank">isl_synthetic_ocr</a></li><li><strong>VLM 自动转录</strong>，再经人工或启发式过滤</li><li><strong>利用现有 OCR 模型生成新训练数据</strong>，以训练更高效的领域专用模型</li><li><strong>基于人工校正语料的再利用</strong>，如 <a href="https://link.segmentfault.com/?enc=dxhJZSgaY0cWeC8NKWJuRQ%3D%3D.tUkI7Uv1nxO0wj3J5LzzB790%2Fv%2B7fhpWI5MXO7X28ci8RI5r9tPygWGIHY1HxV7L" rel="nofollow" target="_blank">英国印度医学史数据集</a>，其中包含大量人工修正的历史文档 OCR</li></ul><p>值得注意的是，许多此类数据集已存在但尚未“训练化” (training-ready) 。<br/>若能系统化整理并公开，将为开源社区释放巨大潜力。</p><h2>模型运行工具</h2><p>我们收到许多关于“如何开始使用 OCR 模型”的问题，因此这里总结了几种简单的方式——<br/>包括在本地运行推理，或通过 Hugging Face 进行远程托管。</p><h3>本地运行</h3><p>目前大多数先进 OCR 模型都提供 <strong>vLLM</strong> 支持，并可通过 <strong>transformers</strong> 库直接加载推理。<br/>你可以在各模型的 Hugging Face 页面找到具体说明。<br/>下面我们以 <strong>vLLM 推理方式</strong>为例演示基本流程。</p><h4>使用 vLLM 启动服务</h4><pre><code class="shell">vllm serve nanonets/Nanonets-OCR2-3B</code></pre><p>然后，你可以通过 OpenAI SDK 进行调用，例如:</p><pre><code class="py">from openai import OpenAI
import base64

client = OpenAI(base_url="http://localhost:8000/v1")
model = "nanonets/Nanonets-OCR2-3B"

def encode_image(image_path):
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode("utf-8")

def infer(img_base64):
    response = client.chat.completions.create(
        model=model,
        messages=[
            {
                "role": "user",
                "content": [
                    {
                        "type": "image_url",
                        "image_url": {"url": f"data:image/png;base64,{img_base64}"},
                    },
                    {
                        "type": "text",
                        "text": "Extract the text from the above document as if you were reading it naturally.",
                    },
                ],
            }
        ],
        temperature=0.0,
        max_tokens=15000
    )
    return response.choices[0].message.content

img_base64 = encode_image(your_img_path)
print(infer(img_base64))</code></pre><h4>使用 Transformers 运行推理</h4><p>Transformers 库提供了标准化的模型定义与接口，可轻松进行推理或微调。<br/>模型可能有两种加载方式:</p><ol><li><strong>官方实现</strong> (在 transformers 内定义)</li><li><strong>remote code 实现</strong> (由模型作者定义，允许 transformers 自动加载)</li></ol><p>以下示例展示了如何用 transformers 调用 <strong>Nanonets OCR 模型</strong>:</p><pre><code class="py"># 安装依赖: flash-attn 和 transformers
from transformers import AutoProcessor, AutoModelForImageTextToText

model = AutoModelForImageTextToText.from_pretrained(
    "nanonets/Nanonets-OCR2-3B", 
    torch_dtype="auto", 
    device_map="auto", 
    attn_implementation="flash_attention_2"
)
model.eval()
processor = AutoProcessor.from_pretrained("nanonets/Nanonets-OCR2-3B")

def infer(image_url, model, processor, max_new_tokens=4096):
    prompt = """Extract the text from the above document as if you were reading it naturally. Return the tables in html format. Return the equations in LaTeX representation. If there is an image in the document and image caption is not present, add a small description of the image inside the &lt;img&gt;&lt;/img&gt; tag; otherwise, add the image caption inside &lt;img&gt;&lt;/img&gt;. Watermarks should be wrapped in brackets. Ex: &lt;watermark&gt;OFFICIAL COPY&lt;/watermark&gt;. Page numbers should be wrapped in brackets. Ex: &lt;page_number&gt;14&lt;/page_number&gt; or &lt;page_number&gt;9/22&lt;/page_number&gt;. Prefer using ☐ and ☑ for check boxes."""
    image = Image.open(image_path)
    messages = [
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": [
            {"type": "image", "image": image_url},
            {"type": "text", "text": prompt},
        ]},
    ]
    text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
    inputs = processor(text=[text], images=[image], padding=True, return_tensors="pt").to(model.device)
    
    output_ids = model.generate(**inputs, max_new_tokens=max_new_tokens, do_sample=False)
    generated_ids = [output_ids[len(input_ids):] for input_ids, output_ids in zip(inputs.input_ids, output_ids)]
    
    output_text = processor.batch_decode(generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True)
    return output_text[0]

result = infer(image_path, model, processor, max_new_tokens=15000)
print(result)</code></pre><h4>使用 MLX (适用于 Apple 芯片)</h4><p><strong>MLX</strong> 是苹果推出的机器学习框架，专为 <strong>Apple Silicon (M 系列)</strong> 设计。<br/>在此基础上构建的 <a href="https://link.segmentfault.com/?enc=bbYAelag6fan4PV7LLJFsA%3D%3D.kqg%2FQivtPUJvt3CtId%2FbxF67IXT3Mu11BrFjBQdUPEoAVc%2B7kmMMScpPT6WH5UUh" rel="nofollow" target="_blank">MLX-VLM</a> 能轻松运行视觉语言模型。<br/>你可以在 <a href="https://link.segmentfault.com/?enc=GCnxRwrNoU%2FK%2BqNVS34Q0A%3D%3D.NhAMAWz6pm%2B2cA6sXeReKU1sEf0WQp62yCN1BeXu2Xy4n7Mb%2FZDjcg4xsNNM6c%2FP" rel="nofollow" target="_blank">Hugging Face</a> 搜索所有支持 MLX 的 OCR 模型 (包括量化版本) 。</p><p>安装 MLX-VLM:</p><pre><code class="bash">pip install -U mlx-vlm</code></pre><p>示例运行:</p><pre><code class="bash">wget https://huggingface.co/datasets/merve/vlm_test_images/resolve/main/throughput_smolvlm.png

python -m mlx_vlm.generate \
  --model ibm-granite/granite-docling-258M-mlx \
  --max-tokens 4096 \
  --temperature 0.0 \
  --prompt "Convert this chart to JSON." \
  --image throughput_smolvlm.png </code></pre><h3>远程运行</h3><h4>使用 Inference Endpoints 部署模型 (托管推理服务)</h4><p>你可以通过 <strong>Hugging Face Inference Endpoints</strong> 在托管环境中部署兼容 vLLM 或 SGLang 的 OCR 模型。<br/>该服务提供 GPU 加速、自动伸缩、监控与安全托管，无需自行维护基础设施。</p><p>部署步骤如下:</p><ol><li>进入模型仓库 <a href="https://link.segmentfault.com/?enc=BSrwQ2JlWXft1Nr7Xg4D4Q%3D%3D.d65iiY08g1aKyaXrFZg8VzAwrOfKBPVNVba1Z51eKfoFcQCGl94Q8bzCuFOM4EbP" rel="nofollow" target="_blank">nanonets/Nanonets-OCR2-3B</a></li><li>点击页面上的 <strong>“Deploy”</strong> 按钮，选择 <strong>“HF Inference Endpoints”</strong></li></ol><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047445820" alt="" title="" loading="lazy"/></p><ol start="3"><li>在弹出的窗口中配置部署参数 (GPU 类型、实例数量等)</li></ol><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047445821" alt="" title="" loading="lazy"/></p><ol start="4"><li>部署完成后，你可以直接通过上文示例中的 OpenAI 客户端脚本调用该 Endpoint。</li></ol><p>更多信息可参阅官方文档: 👉 <a href="https://link.segmentfault.com/?enc=2qLa3mBJ0RtPTD6BFG1%2BAA%3D%3D.KzhMpaPdUWjftMmviXqthCfRxeZ9KAFnmSCgZZ8uKfUkQA4XAJNtXi4LilGCnU9Nda5QMhPElqcN3bHEF%2FRfZQ%3D%3D" rel="nofollow" target="_blank">Inference Endpoints (vLLM)</a></p><h4>使用 Hugging Face Jobs 进行批量推理</h4><p>对于 OCR 场景，往往需要<strong>批量处理成千上万张图像</strong>。<br/>这类任务可通过 <strong>vLLM 的离线推理模式</strong> 实现高效并行。</p><p>为了简化流程，我们创建了  <a href="https://link.segmentfault.com/?enc=LNCq6AkP9Mi6GQ5HS46PVw%3D%3D.nW7MpgyB9khtQsJtgkvOmyqDwX58TJEGP54MD%2BNXQKbqBzM31bs6FeCCzkLq8%2BSM" rel="nofollow" target="_blank">uv-scripts/ocr</a>，<br/>它是一组适配 Hugging Face Jobs 的可直接运行脚本，能实现:</p><ul><li>对数据集列中的所有图片进行批量 OCR</li><li>将 OCR 结果以 Markdown 形式新增为新列</li><li>自动将带结果的数据集回传到 Hub</li></ul><p>例如，处理 100 张图片的命令如下:</p><pre><code class="bash">hf jobs uv run --flavor l4x1 \
  https://huggingface.co/datasets/uv-scripts/ocr/raw/main/nanonets-ocr.py \
  your-input-dataset your-output-dataset \
  --max-samples 100</code></pre><p>这些脚本会自动处理所有 vLLM 配置与批次推理逻辑，<br/>让批量 OCR 变得无需 GPU 或复杂部署。</p><h2>超越 OCR</h2><p>如果你对文档智能 (Document AI) 感兴趣，不仅仅局限于文字识别 (OCR) ，以下是我们的一些推荐方向。</p><h3>视觉文档检索</h3><p><strong>视觉文档检索 (Visual Document Retrieval)</strong> 指的是: <br/>当你输入一条文本查询时，系统能够从大量 PDF 文档中直接检索出最相关的前 <em>k</em> 篇。</p><p>与传统文本检索模型不同，视觉文档检索器直接在“文档图像”层面进行搜索。<br/>除了独立使用外，你还可以将它与视觉语言模型结合，构建 <strong>多模态 RAG (Retrieval-Augmented Generation)</strong> 管线。<br/>相关示例可参考: <a href="https://link.segmentfault.com/?enc=xVe4jcCEJxhjCUaS5b8Y7Q%3D%3D.h0fu2zQ1jgJwpyNwpOkRjLJbvOSOdNwNk4GTm3VO4afWhKNmOvhkGz0FbKxetJvRtahrzqqgsx5ZDYea%2FE2971UMWAjPDHAPPCwScQzuMT0%3D" rel="nofollow" target="_blank">ColPali + Qwen2_VL 多模态 RAG 教程</a>。</p><p>你可以在  <a href="https://link.segmentfault.com/?enc=36aBHOa%2BohsfbzvMr6U0aw%3D%3D.FVWVgTrhnvbM084kDWi9sWA86TrLdqTjDOXfaSXYsOEfMX7JSkF6byojBpO2hvWCWtQDKb%2BQPDlOQPZAZ8swPcjcYEPYw%2BAjyID69VbPgO0%3D" rel="nofollow" target="_blank">Hugging Face Hub</a>  找到所有可用的视觉文档检索模型。</p><p>目前主流的视觉检索器分为两类:</p><table><thead><tr><th>类型</th><th>特点</th><th>适用场景</th></tr></thead><tbody><tr><td><strong>单向量模型 (Single-vector Models)</strong></td><td>内存效率高、速度快，但性能略弱</td><td>轻量化部署、大规模索引</td></tr><tr><td><strong>多向量模型 (Multi-vector Models)</strong></td><td>表征能力强、检索精度高，但占用显存更大</td><td>高精度检索、知识密集任务</td></tr></tbody></table><p>大多数此类模型都支持 <strong>vLLM</strong> 和 <strong>transformers</strong>，因此你可以很方便地用它们进行向量索引，然后结合向量数据库 (vector DB) 执行高效搜索。</p><h3>基于视觉语言模型的文档问答 (Document Question Answering)</h3><p>如果你的任务目标是<strong>基于文档回答问题</strong> (而不是仅仅提取文字) ，<br/>你可以直接使用经过文档任务训练的<strong>视觉语言模型 (VLM)</strong> 。</p><p>许多用户习惯于:</p><ol><li>先将文档转换成纯文本；</li><li>再把文本传入 LLM 进行问答。</li></ol><p>这种方式虽然可行，但存在明显缺陷:</p><ul><li>一旦文档布局复杂 (如多栏结构、图表、图片说明等) ，转换后的文本就可能丢失关键信息；</li><li>图表被转为 HTML、图片说明生成错误时，LLM 就会误判或忽略内容。</li></ul><p>因此，更好的做法是: <br/>直接将<strong>原始文档图像 + 用户问题</strong> 一起输入支持多模态理解的模型，<br/>例如 <a href="https://link.segmentfault.com/?enc=kgXhHo33o%2BBk6SEfI84wKQ%3D%3D.k%2FsSnMCbLbPYOEaBLWmScIiSFRFQEhy6gw2l1Dqa6BB4drNAWDtZQT3WUhRkGmzbaBWQaM4Z%2BM5gdGc252G%2Ft6n6iYh0m2fIFnWGRHzWcG8%3D" rel="nofollow" target="_blank">Qwen3-VL</a>。<br/>这样模型就能同时利用视觉与文本信息，不会错过任何上下文细节。</p><h2>总结</h2><p>在这篇文章中，我们为你概览了现代 OCR 技术的核心要点，包括:</p><ul><li>如何选择合适的 OCR 模型</li><li>当前最前沿的开源模型及其能力</li><li>在本地或云端运行模型的工具</li><li>以及如何在 OCR 之上构建更复杂的文档智能应用</li></ul><p>如果你希望进一步深入了解 OCR 与视觉语言模型 (VLM) ，<br/>以下是我们推荐的延伸阅读与教程资源 👇</p><h3>延伸阅读与资源</h3><ul><li>📘 <a href="https://link.segmentfault.com/?enc=%2BVJQ%2FrkLYp4D0b4uE%2B4BzA%3D%3D.dZwDi3YMBxP652xkwICwDYJhJhe843r4VrI64n1Ntpg%3D" rel="nofollow" target="_blank">Vision Language Models Explained (视觉语言模型详解)</a> <br/>—— 深入理解 VLM 的工作原理与发展历程。</li><li>🧠 <a href="https://link.segmentfault.com/?enc=D547VR7UcbeXewu%2FmtCOCA%3D%3D.dHj4ZpgMxZPk2GQruNb%2B4gu9bL3kbo%2BgchW2Z89qm60%3D" rel="nofollow" target="_blank">Vision Language Models 2025 Update (2025 年视觉语言模型更新)</a> <br/>—— 最新 VLM 技术进展总结。</li><li>🔍 <a href="https://link.segmentfault.com/?enc=SjklMxXKxLyrGUpnGRadRg%3D%3D.NeNNI%2Ft99YG9DZF7Mv29gjqEsSOyMATVaGG4xPXmJnwKf4vIZO%2F%2Bqoh9tJ2D4%2BzG" rel="nofollow" target="_blank">PP-OCR-v5 技术博客</a><br/>—— 来自百度的高性能 OCR 系统优化介绍。</li><li>🧩 <a href="https://link.segmentfault.com/?enc=scyCQe3BiIhgzOTnc6iKIA%3D%3D.yw8A3l8sr4oB1Y4JaIAMFHDpWTWP0TwiYVozULd%2BixKQImH3hK0%2BWY1BSnJY20xs44FjJkec8N4lRPlzXxiINqARwO%2F0evjlozSY0ytVnXk%3D" rel="nofollow" target="_blank">教程: 微调 Kosmos2.5 进行 Grounded OCR</a><br/>—— 实践指南，教你如何让模型具备“锚定式”识别能力。</li><li>📄 <a href="https://link.segmentfault.com/?enc=lO92cxIlZMmsHMDmiQgzCQ%3D%3D.pHwpMLRvTaqPyHhuEq8DL7C%2FRvQA5VT%2Fyk4WThMvOVcvMULkzmZhvF8NS0e2tQXatjGjf4lfr6HVx%2BU6WFCL%2BGTPBlvM5Wq%2BKoC9gwDHvpA%3D" rel="nofollow" target="_blank">教程: 在 DocVQA 数据集上微调 Florence-2</a><br/>—— 基于视觉问答任务的微调实例。</li><li>📱 <a href="https://link.segmentfault.com/?enc=%2B3AOJzWvst2aFwkOCssT4w%3D%3D.iLskBD7OGZHB%2FbDkaYjpA6CUgrcetNkzEz1DQfYlyC4%3D" rel="nofollow" target="_blank">在设备端实现 SOTA OCR (Core ML + dots.ocr)</a> <br/>—— 展示如何在移动端高效部署 OCR 模型。</li></ul><p><strong>总结一句话:</strong> 开源视觉语言模型正在重新定义 OCR 的边界。从纯文本识别到多模态理解、从图像到语义、从离线推理到大规模部署——如今的开源生态为每一个开发者和研究者提供了前所未有的自由度与创新空间。</p><p>无论你是在构建下一代文档智能系统，还是仅想更高效地解析 PDF，希望这篇指南能帮助你找到最合适的起点 🚀</p><blockquote><p>英文原文: <a href="https://link.segmentfault.com/?enc=ezbHR%2FuDM%2FVcw%2BlcP7sZXw%3D%3D.PpRFCxY4VY1LdvQh9wmSumXcctxb%2FrrvFm9SFUpy0Il6cEISR2UPH%2F%2FApmKn07jF" rel="nofollow" target="_blank">https://huggingface.co/blog/ocr-open-models</a></p><p>原文作者: merve, Aritra Roy Gosthipaty, Daniel van Strien, Hynek Kydlicek, Andres Marafioti, Vaibhav Srivastav, Pedro Cuenca</p><p>译者: Luke,  Hugging Face Fellow</p></blockquote>]]></description></item><item>    <title><![CDATA[SSL 证书过期？这些后果直接让网站 “]]></title>    <link>https://segmentfault.com/a/1190000047445931</link>    <guid>https://segmentfault.com/a/1190000047445931</guid>    <pubDate>2025-12-03 14:04:15</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>做网站的老板注意了！SSL 证书过期不是 “小事”，而是能让你血本无归的 “致命雷区”！很多站长觉得晚几天续期无所谓，殊不知一旦证书失效，流量、订单、品牌信任会瞬间崩塌，甚至面临合规罚款，这些后果远比你想象中更残酷！<br/><img width="390" height="260" referrerpolicy="no-referrer" src="/img/bVddeYp" alt="" title=""/></p><h3>一、浏览器直接 “亮红牌”，用户一秒跑光！</h3><p>你以为用户会耐心等待你续期？大错特错！只要 SSL 过期，Chrome、百度、Edge 等所有主流浏览器都会弹出刺眼的 “连接不安全” 警告，有的甚至直接拦截访问，强制用户退出。</p><p>现在网友的安全意识早就今非昔比，超过 90% 的人看到 “不安全” 提示，会立刻关闭页面，连犹豫都不会犹豫！电商网站直接丢订单，咨询网站错失客户，资讯网站流量暴跌 —— 有站长实测，SSL 过期 3 天，网站流量直接腰斩，半个月都没恢复过来！</p><h3>二、数据 “裸奔” 遭窃取，用户投诉 + 法律纠纷找上门！</h3><p>SSL 证书是网站的 “加密锁”，过期后这把锁就直接失效了！用户在你网站输入的登录密码、手机号、身份证号、支付信息，都会以明文形式传输，黑客用简单工具就能截取。</p><p>之前就有电商网站因 SSL 过期，导致上千用户支付密码泄露，不仅要赔偿用户损失，还被监管部门调查，品牌形象彻底毁了！这种纠纷一旦发生，小网站可能直接倒闭，大网站也要花巨资公关，得不偿失！</p><h3>三、业务全面停摆，合规罚款让你雪上加霜！</h3><p>别以为只有流量和安全受影响，SSL 过期会直接让你的业务 “停摆”！支付网关对接失败，用户付款时提示 “网络错误”，订单全流失；API 接口、小程序、APP 无法正常运行，用户打不开、用不了，直接卸载；甚至网站后台都登不上，日常运营彻底瘫痪。</p><p>更可怕的是合规风险！金融、医疗、电商等行业必须符合 PCI DSS、GDPR 等法规，SSL 过期就是 “违规操作”，监管部门查到就罚，少则几万，多则几十万，还可能被要求暂停业务整顿，相当于直接断了营收来源！</p><h3>四、搜索引擎降权，流量再也回不来了！</h3><p>百度、谷歌早就明确：HTTPS 是排名重要指标，不安全的网站直接降权！SSL 过期后，你的网站会被搜索引擎判定为 “高危网站”，排名一落千丈，甚至从搜索结果中消失。</p><p>就算后续续期了 SSL，排名也很难恢复到之前的水平 —— 有站长反映，证书过期 1 个月，自然流量少了 70%，花了半年时间做优化才勉强回升。对于依赖搜索引擎引流的网站来说，这简直是 “灭顶之灾”！</p><p><strong>最后提醒：记住：SSL 续期的成本，远比过期后的损失低 100 倍！别因小失大，让一张过期的 SSL 证书，毁了你的整个网站！</strong></p>]]></description></item><item>    <title><![CDATA[当网站提示“不安全”：SSL证书，你的数]]></title>    <link>https://segmentfault.com/a/1190000047445933</link>    <guid>https://segmentfault.com/a/1190000047445933</guid>    <pubDate>2025-12-03 14:03:21</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在互联网的浩瀚海洋中航行，我们时常会看到这样的警告：“此网站不安全”或“您的连接不是私密连接”。这些红色警示如同数字世界的警戒线，而它们背后隐藏的关键，正是SSL证书——这个你可能看不见，却时刻保护着你的数字护身符。</p><h4>SSL证书：数字世界的身份认证</h4><p>SSL（安全套接层）证书，如今更准确地说应称为TLS（传输层安全）证书，是一种数字证书，其作用如同现实世界中的护照或身份证。它由受信任的第三方机构——证书颁发机构（CA）签发，用于验证网站身份，并在用户浏览器与网站服务器之间建立加密连接。</p><p>想象一下，你正在咖啡馆使用公共Wi-Fi登录电子邮箱。没有SSL加密，你输入的密码就像写在明信片上传递，任何人都可能截获。而有了SSL证书，这些信息会被转化为只有你和服务器能解读的“密语”，即使被截获也无从破解。</p><h4>为什么网站会提示“不安全”？</h4><p>当浏览器提示网站不安全时，通常有以下几种原因：</p><ol><li><strong>缺乏SSL证书</strong>：网站未安装SSL证书，数据以明文传输，极易被窃取</li><li><strong>证书过期</strong>：如同身份证有有效期，SSL证书通常有效期为1-2年，过期后需续期。</li><li><strong>证书与域名不匹配</strong>：证书仅对特定域名有效，若访问的域名与证书注册域名不符，则会触发警告。</li><li><strong>自签名证书</strong>：网站使用了自行签发的证书，而非受信任CA签发，浏览器无法验证其真实性。</li><li><strong>混合内容问题</strong>：网站虽启用HTTPS，但页面中包含通过HTTP加载的资源（如图片、脚本），造成安全漏洞。</li></ol><h4>遇到“不安全”警告，你该如何应对？</h4><h4>直接访问JoySSL，注册一个账号记得填注册码230970获取技术支持。<a href="https://link.segmentfault.com/?enc=cVXdaK4YVonNni4AU77afg%3D%3D.QYvrtOBCtHnARZwTSzGVMNPkh5ahiUCklm7ZgO5SnaWkb3fu1TvEbf0FyE47BBmU%2BpLCF2rzA%2BQTfig1T%2B%2B6rQ%3D%3D" rel="nofollow" target="_blank">申请入口</a></h4><p><img width="723" height="323" referrerpolicy="no-referrer" src="/img/bVdmVAD" alt="" title=""/></p><h4>第一步：识别警告类型</h4><p>浏览器通常提供详细信息。点击警告页面上的“高级”或“详细信息”，了解具体问题。是证书过期？域名不匹配？还是其他问题？</p><h4>第二步：评估风险级别</h4><ul><li><strong>对于银行、电商等敏感网站</strong>：立即停止访问。绝不输入任何个人信息、密码或支付信息。</li><li><strong>对于信息类网站</strong>：谨慎浏览，避免提交任何表单或个人信息。</li><li><strong>对于内部或测试网站</strong>：可能使用了自签名证书，需确认你确实信任该网站。</li></ul><h4>第三步：采取相应措施</h4><ol><li><strong>检查网址</strong>：确保你访问的是正确网址，警惕拼写错误的“李鬼”网站（如“<a href="https://link.segmentfault.com/?enc=%2FKGyKKkNCSLeBsAjiAMonA%3D%3D.I0aZ4xBzPmoSxCxY5X2%2F9o7u%2BjMoNJCp1XwDtdKJzX4%3D" rel="nofollow" target="_blank">paypa1.com</a>”冒充“<a href="https://link.segmentfault.com/?enc=PH23u2sRfF5BMilkEeXang%3D%3D.iCl3BXY5xg4QJWtnMR6FpRw%2F3L92C5hzFthvvgNMdCo%3D" rel="nofollow" target="_blank">paypal.com</a>”）。</li><li><strong>更新系统时间</strong>：计算机日期设置错误可能导致浏览器误判证书过期。</li><li><strong>联系网站管理员</strong>：如果你信任该网站但遇到问题，可通过其他渠道通知他们。</li><li><strong>考虑使用HTTPS Everywhere等扩展</strong>：这些工具会自动尝试网站的HTTPS版本。</li></ol><h4>第四步：决定是否继续访问</h4><p>对于非敏感信息的浏览，你可以选择“高级”→“继续前往网站”，但必须清楚了解风险：你的任何输入都可能被第三方截获。</p><h4>网站所有者：如何避免“不安全”警告？</h4><p>如果你拥有网站，确保其安全不仅是对访问者的责任，也直接影响你的信誉和搜索引擎排名：</p><ol><li><strong>获取并安装SSL证书</strong>：许多主机提供商提供免费SSL证书（如JoySSL）。</li><li><strong>确保证书有效且及时更新</strong>：设置提醒，在证书过期前续期。</li><li><strong>配置HTTP到HTTPS重定向</strong>：确保所有访问都通过安全的HTTPS连接。</li><li><strong>解决混合内容问题</strong>：确保网站所有资源都通过HTTPS加载。</li><li><strong>使用HSTS（HTTP严格传输安全）</strong> ：告诉浏览器只通过HTTPS访问你的网站。</li></ol><h4>数字时代的信任基石</h4><p>SSL证书不仅是技术工具，更是数字信任的基石。当浏览器显示那个小小的锁形图标和“安全”标签时，它传递的信息是：“你的连接是私密的，这个网站是它所声称的那个实体。”</p><p>在日益复杂的网络环境中，对“不安全”警告保持警惕，是每个数字公民的基本素养。而作为网站运营者，提供安全的连接环境则是基本的责任与义务。SSL证书这座看不见的桥梁，连接着信任与安全，保护着我们在数字世界中的每一次交流、每一笔交易，让互联网成为一个更值得信赖的空间。</p><p>下一次，当浏览器提示“不安全”时，请停下脚步，思考片刻——这短暂的停顿，可能是对你数字安全最重要的保护。</p>]]></description></item><item>    <title><![CDATA[米哈游联创推出可对话「猫猫」AI，具备情]]></title>    <link>https://segmentfault.com/a/1190000047445971</link>    <guid>https://segmentfault.com/a/1190000047445971</guid>    <pubDate>2025-12-03 14:02:21</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047445973" alt="" title=""/></p><p><strong>开发者朋友们大家好：</strong></p><p>这里是 <strong>「RTE 开发者日报」</strong> ，每天和大家一起看新闻、聊八卦。我们的社区编辑团队会整理分享 RTE（Real-Time Engagement） 领域内「有话题的<strong>技术</strong>」、「有亮点的<strong>产品</strong>」、「有思考的<strong>文章</strong>」、「有态度的<strong>观点</strong>」、「有看点的<strong>活动</strong>」，但内容仅代表编辑的个人观点，欢迎大家留言、跟帖、讨论。</p><p><em>本期编辑：@瓒an、@鲍勃</em></p><h2>01 有话题的技术</h2><p><strong>1、DeepSeek V3.2 正式版发布：推理比肩 GPT-5，首推 Speciale 版本拿下奥数金牌</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047445974" alt="" title="" loading="lazy"/></p><p>昨天，深度求索 DeepSeek 正式发布了 V3.2 系列模型，包括<strong>标准版「DeepSeek-V3.2」与增强版「DeepSeek-V3.2-Speciale」</strong>。</p><p>官方测试显示，该模型在公开推理类 Benchmark 中达到了 GPT-5 水平，仅略低于 Gemini-3.0-Pro。同时，相比 Kimi-K2-Thinking，V3.2 输出更为简洁，大幅降低了计算开销与用户等待时间。</p><p>DeepSeek-V3.2 还首次实现了「思考模式下的工具调用」，通过大规模 Agent 训练数据合成方法，显著提升了模型的泛化能力。这一功能使模型能够在复杂任务中多轮思考并调用工具，最终给出更详尽准确的回答。</p><p>官方表示，在高度复杂任务上，Speciale 模型大幅优于标准版本，但消耗的 Tokens 也显著更多，成本更高。目前，DeepSeek-V3.2-Speciale 仅供研究使用，不支持工具调用，暂未针对日常对话与写作任务进行专项优化。</p><p>DeepSeek-V3.2 的思考模式也<strong>增加了对 Claude Code 的支持</strong>，用户可以通过将模型名改为 deepseek-reasoner，或在 Claude Code CLI 中按 Tab 键开启思考模式进行使用。但需要注意的是，思考模式<strong>未充分适配 Cline、RooCode</strong> 等使用非标准工具调用的组件，官方建议用户在使用此类组件时继续使用<strong>非思考</strong>模式。</p><p>技术报告：</p><p><a href="https://link.segmentfault.com/?enc=%2FSTAGmzkzNNft2UsTswjgQ%3D%3D.Mshg6qOywNkp2NRFiMgoIK50ZycFDjvaAPBP4TN%2FrcstHat%2BrJbbAU%2B0dD21Qi021DLOdnzOgi%2BvriM2jza%2FfZ9uuVw988X24P6zn9HdMzmXEltFlt1sFgdVnbSrZLMu" rel="nofollow" target="_blank">https://modelscope.cn/models/deepseek-ai/DeepSeek-V3.2/resolv...</a></p><p>DeepSeek V3.2 开源地址：</p><p>DeepSeek-V3.2</p><p>HuggingFace: </p><p><a href="https://link.segmentfault.com/?enc=B3nIYaktqTK1j6BEzpDLGw%3D%3D.8rP%2FaiwQgifF1xGX%2BpO7e2hTOgvZxgoSr9dwC7Yk8cljO1jvxIQ2VgWmFW3VTdO%2BjQyno1A2D2ifyK%2F%2Bi%2BFPDQ%3D%3D" rel="nofollow" target="_blank">https://huggingface.co/deepseek-ai/DeepSeek-V3.2</a></p><p>ModelScope: </p><p><a href="https://link.segmentfault.com/?enc=iJKrDw4vlTymlYv86GklTw%3D%3D.gPJJU8RKtGLVvfSWwLFgkgNvyhJW9rWq%2BocFDYGKNioHgclmlkC4mj68pK1V%2FNKhh8lsviHWTuKGhplupGeCew%3D%3D" rel="nofollow" target="_blank">https://modelscope.cn/models/deepseek-ai/DeepSeek-V3.2</a></p><p>DeepSeek-V3.2-Speciale</p><p>HuggingFace: </p><p><a href="https://link.segmentfault.com/?enc=6hWIS23IdkdMn3%2BiTiznNQ%3D%3D.Fa0spsrj1%2BlXFoSjPuazqYbteDTq8P6ygsidZAQiV%2FG6%2F2RtgUgJ8CvLvH48G1ZbhCmgdPS8aTf7sl6N2QtPRw%3D%3D" rel="nofollow" target="_blank">https://huggingface.co/deepseek-ai/DeepSeek-V3.2-Speciale</a></p><p>ModelScope: </p><p><a href="https://link.segmentfault.com/?enc=tX1LmJHfaUaNX98hlo7Z1A%3D%3D.hXafZsG2CJehOqHi3kl1gzPmqbmmjpqK2kbXXwY66StgX8sKm%2BaDNOJ%2BbL%2B58SgI6XM4setdx%2FoxF7xs7yNtpw%3D%3D" rel="nofollow" target="_blank">https://modelscope.cn/models/deepseek-ai/DeepSeek-V3.2-Speciale</a></p><p>（@IT 之家）</p><p><strong>2、Microsoft 研究揭示：空间音频可将 AI 同声传译理解度翻倍</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047445975" alt="" title="" loading="lazy"/></p><p>Microsoft 的一项最新研究指出，在 AI 实时语音翻译中，使用「空间音频」（Spatial Audio）技术，即将翻译语音与发言者在屏幕上的位置相匹配，可将听众的理解度提升一倍以上。这一发现为各大视频会议平台提供了一个技术上可行且效果显著的优化方向，有望极大改善跨语言协作的沟通体验。</p><ul><li><p>技术突破：理解度翻倍，定位更清晰</p><p>研究表明，当翻译语音来自与发言者屏幕位置匹配的左/右声道时，听众正确回答理解性问题的几率是传统（非空间）音频的两倍以上。该技术在多人快速轮流发言时效果尤其显著，能有效帮助用户辨别「谁说了什么」。</p></li><li><p>体验对比：空间音频完胜单耳收听</p><p>与会者普遍认为「空间音频」模式「更容易理解」且「能清晰分辨发言者」。与之形成鲜明对比的是「单耳翻译」（Monaural）模式，它产生了最低的理解度得分，并被用户评价为「令人困惑」和「容易疲劳」。</p></li><li><p>最佳实践：保留音色，平衡音量</p><p>研究还发现两个关键的 UX 细节：1）保留不同发言者独特的声音音色有助于区分人物；2）调低而非完全静音原始语音，可以在减少干扰的同时，保留发言者的身份线索，从而创造最佳体验。</p></li><li><p>平台建议：技术可行且影响巨大</p><p>研究人员建议，会议平台应将翻译音频与发言者的屏幕位置对齐，并提供一个「原始语音 ↔ 翻译语音」的平衡滑块供用户调节。鉴于大多数现代耳机和设备已支持「空间音频」，这一改进在技术上是完全可行的。</p></li></ul><p>论文地址：</p><p><a href="https://link.segmentfault.com/?enc=CKe6HLrKBTvHSgaEK8wvpA%3D%3D.0v0njUFwxDyZhyMtVU6hPEucMx41f4x%2F2bFF5un%2BYsuwENn2jsoR8bkxZ0SBwylt" rel="nofollow" target="_blank">https://arxiv.org/pdf/2511.09525</a></p><p>( @Slator)</p><p><strong>3、ElevenLabs 进军韩国，打造亚洲语音 AI 中心</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047445976" alt="" title="" loading="lazy"/></p><p>英国人工智能音频公司 ElevenLabs 正式宣布进军韩国市场，并计划在韩国建立其亚洲语音 AI 中心。该公司将推出本地化的韩语语音模型，并提供名人语音授权，以推动 K-content（韩流内容）在全球的传播。</p><p><strong>语音 AI 技术：</strong> ElevenLabs 拥有先进的基于 AI 的 Text-to-Speech（TTS）技术，能够将文本实时转化为人类语音，并支持语音克隆、AI 配音和音效生成。</p><p><strong>韩语本地化：</strong> 为进军韩国市场，ElevenLabs 投入大量资源，组建了专门团队并聘请专家，开发了能够准确捕捉和渲染韩语特有发音、语调和情感的模型。</p><p><strong>K-content 全球化：</strong> ElevenLabs 的「Eleven v3」模型支持超过 70 种语言，能够完美还原原始情感和细微差别，旨在帮助克服 K-content（如 K-pop 和 K-drama）的语言障碍，并计划与韩国名人合作推出 AI 配音产品。</p><p><strong>企业级应用：</strong> 该技术已获得 5000 万月活跃用户，75% 的 Fortune 500 公司是其客户，并在韩国吸引了 Naver、LG Uplus、Krafton Inc。 等领先企业使用。Nvidia、Deutsche Telekom 等公司也已投资 ElevenLabs。</p><p><strong>亚洲桥头堡：</strong> ElevenLabs 选择韩国作为其进入亚洲市场的关键桥头堡，看好韩国快速增长的 AI 市场、对创新的快速接纳能力以及全球领先的内容影响力。</p><p>ElevenLabs 已在韩国设立了第六个办事处，并立即开始本地化韩语语音模型的开发和应用。公司计划将该技术应用于韩国的内容和游戏产业，并改进客户服务中心的 AI 体验。</p><p>(@CHOSUNBIZ)</p><h2>02 有亮点的产品</h2><p><strong>1、豆包手机助手发布技术预览版，首款工程机亮相，现已售罄</strong></p><p>昨天，豆包宣布其全新手机 AI 助手「豆包手机助手」以技术预览版的形式正式亮相。</p><p>据悉，字节跳动与努比亚为这款工程机的首销备货量为 3 万台。**目前，购买页面显示「已售罄」，购买需预约等待下次开售。</p><p>官方强调，该机型仅为技术预览用途，并不承诺功能的成熟度，普通消费者需谨慎选择。<strong>值得注意的是，豆包官方还明确表示不打算做手机。</strong>这款工程样机的具体配置如下： 配备高通骁龙 8 至尊版处理器；但是搭载 6.78 英寸 1264 × 2800 LTPO 屏幕；后置三颗 50MP 摄像头，涵盖主摄、超广角与长焦，均支持光学防抖；前置具备自动对焦功能；提供 16GB + 512GB 存储组合； 电池容量为 6000mAh，支持 90W 有线快充、15W 无线充电及 5W 反向充电；机身重量约 212g，支持超声波屏下指纹、NFC、红外、USB 3.2Gen1，并配备 5 麦克风与双扬声器。</p><p>上述消息公布后，中兴通讯股价昨天上午强势涨停，报 46.30 元，成交金额超 139 亿，封单金额超 40 亿元，其 H 股也涨超 11%。</p><p>( @APPSO)</p><p><strong>2、可灵 AI 推出全球首个统一多模态视频引擎 O1</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047445977" alt="" title="" loading="lazy"/></p><p>昨天晚间，可灵视频正式上线 O1 模型，宣称这是全球首个统一多模态视频大模型，定位为全能创作引擎，旨在通过单一输入框实现跨模态任务的无缝融合，打破传统视频生成的功能割裂问题。</p><p>据介绍，该模型引入 MVL（多模态视觉语言）交互架构，并结合 Chain-of-thought 技术，赋予系统更强的常识推理与事件推演能力。</p><p>官方表示，O1 模型能够在同一界面下处理照片、视频与文字等多模态输入，用户仅需通过简单对话即可完成复杂的创作编辑。</p><p>在功能层面，O1 模型支持多主体视角构建与自由组合，确保视频主体在不同镜头间保持一致性与稳定性。</p><p>同时，用户可灵活组合多种技能，一次生成多样化创意变化，并可自由设定 3 至 10 秒的生成时长，以掌控叙事节奏。</p><p>此外，可灵 AI 宣布自 12 月 1 日起至 12 月 14 日，将举办为期 5 天的「全能灵感周」，并推出会员年卡限时 6.6 折优惠活动，以吸引更多创作者体验该新模型。</p><p>( @APPSO)</p><p><strong>3、米哈游联合创始推出「猫猫」互动娱乐 AI 模型</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047445978" alt="" title="" loading="lazy"/></p><p>据 36 氪报道，米哈游联合创始人蔡浩宇在美国创立的 AI 公司 Anuttacon 近日上线了一款全新 AI 聊天大模型「AnuNeko」。</p><p>该产品以黑猫为默认形象，强调个性化与互动性，区别于传统的工具型 AI，更像是具备情绪与独立思考的「伙伴」。</p><p>「AnuNeko」的注册商标已于 2025 年 9 月 29 日提交美国 USPTO，涵盖软件、AI 角色与娱乐等多个领域。用户可选择两种不同风格的虚拟猫角色：回答犀利的「异国短毛猫」Exotic Shorthair 与更温和的「橘猫」Orange Cat。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047445979" alt="" title="" loading="lazy"/></p><p>报道认为，蔡浩宇的目标并非仅限于推出一款聊天机器人，而是借此探索 AI 在游戏生态中的应用。</p><p>在今年 8 月，Anuttacon 曾发布实验性 AI 游戏《群星低语》，玩家通过与 AI 角色对话推动剧情发展，体现了高自由度与 AI 自主性。此次「AnuNeko」的上线，或许是进一步测试 AI 在互动娱乐中的潜力。</p><p>在全球范围内，Google、育碧、字节跳动等企业也在布局 AI + 游戏：</p><ul><li>Google DeepMind 推出的 SIMA 2 能在 3D 虚拟世界中自主学习与推理；</li><li>字节的「Lumine」在《原神》中展现出跨场景泛化能力；</li><li>育碧的 NEO NPCs 则已能实时分析玩家语音并制定策略。这些案例显示，AI 正逐步成为游戏产业的核心驱动力。</li></ul><p>报道指出，与传统强调执行力的智能体不同，Anuttacon 的策略是让 AI 更「像人」，具备情绪与个性。这一方向或许能为未来互动娱乐带来新的突破：真正吸引玩家的并非完美答案，而是充满生命力的对话与陪伴。</p><p><a href="https://link.segmentfault.com/?enc=tKVLFmPgMgUg9C%2BYykkwvQ%3D%3D.YQQL3g13WJ2zV9%2BaOTg6sdCY4K6ZPAxO%2Bj%2BYoHfonkI%3D" rel="nofollow" target="_blank">https://anuneko.com</a></p><p>( @APPSO)</p><h2>03 有态度的观点</h2><p><strong>1、马斯克最新预言：AI 可在三年内终结美国「债务危机」</strong></p><p>12 月 1 日消息，自 2022 年 ChatGPT 问世后，AI 迅速被视为医疗、农业、能源等各领域的万能工具。不过马斯克的看法却更进一步，他认为 AI 与机器人技术才是解决美国债务危机的关键。在日前播出的一档播客节目中，马斯克表示：「美国债务问题只有一个出口，那就是 AI。」</p><p>他补充道：「摆脱美国日益加深的财政漏洞的唯一途径是由 AI 和机器人驱动的生产力提高。这几乎是解决美国债务危机的唯一办法，但这可能会导致严重的通货紧缩。」美国财政部数据显示，截至 11 月 26 日，美国国债已经达到 38.34 万亿美元，是十年前的两倍多。</p><p>马斯克进一步指出，AI 未将生产力提高到足以推动经济产出增速超过通货膨胀的程度，但这种情况即将改变。他补充称：「估计三年或更短的时间内，商品和服务产出将超过通货膨胀率。」</p><p>（@雷锋网 、@快科技）</p><h2>04 Real-Time AI Demo</h2><p><strong>1、在 Mac 上离线运行 Qwen3omni-30b，实现语音对话，延迟 3～5 秒</strong></p><p>来自 X 上的开发者 ZachBladi（@hellopanghe）：</p><p>隆重推出 Joi：一款专为 Mac 设计的原生应用，提供端到端的音频聊天体验，一切运行在本地！🍎🎙</p><p>在 M3 Max （36GB） 上运行 Qwen3omni-30b-a3b-instruct （4-bit）：⚡️ 「思考」速度：约 30 token/秒 🔊 首音频响应时间：3-5 秒</p><p>私密、沉浸、无审查。</p><p><a href="https://link.segmentfault.com/?enc=SJvz7BSm2ApaZyKHnlrvQQ%3D%3D.1ypsBVqmCvITaC4sGvm4ljT%2Bj5xVZ75K1q9brPo9rQjjJYPnC9nrZFAqS8INrg55" rel="nofollow" target="_blank">https://github.com/hellopahe/joi</a></p><p>( @hellopanghe\@X)</p><h2>05 社区黑板报</h2><p>招聘、项目分享、求助……任何你想和社区分享的信息，请联系我们投稿。（加微信 creators2022，备注「社区黑板报」）</p><p><strong>1、 活动推荐：AI+3D 场景合作交流会，北京，12 月 4 日</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047445980" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047445981" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047445982" alt="" title="" loading="lazy"/></p><p><a href="https://link.segmentfault.com/?enc=CAEEngfdl49ILqp%2F9l%2BXFw%3D%3D.7og5A%2BzCIiceAuamQPHY9VkpG70IA69%2F9QJSeSO7L8I%3D" rel="nofollow" target="_blank">阅读更多 Voice Agent 学习笔记：了解最懂 AI 语音的头脑都在思考什么</a></p><p><strong>写在最后：</strong></p><p>我们欢迎更多的小伙伴参与 <strong>「RTE 开发者日报」</strong> 内容的共创，感兴趣的朋友请通过开发者社区或公众号留言联系，记得报暗号「共创」。</p><p>对于任何反馈（包括但不限于内容上、形式上）我们不胜感激、并有小惊喜回馈，例如你希望从日报中看到哪些内容；自己推荐的信源、项目、话题、活动等；或者列举几个你喜欢看、平时常看的内容渠道；内容排版或呈现形式上有哪些可以改进的地方等。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047445983" alt="" title="" loading="lazy"/></p><p>作者提示: 个人观点，仅供参考</p>]]></description></item><item>    <title><![CDATA[AI生产工艺优化正在接管工厂“指挥权” ]]></title>    <link>https://segmentfault.com/a/1190000047445996</link>    <guid>https://segmentfault.com/a/1190000047445996</guid>    <pubDate>2025-12-03 14:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>是什么：生产工艺优化的核心挑战与转型方向<br/>生产工艺优化本质上是通过技术手段解决制造环节中的效率、质量与协同问题。在传统制造模式中，企业常面临几个典型痛点：工艺设计依赖人工经验，导致标准不统一；跨部门协作壁垒高，设计变更需反复沟通；生产现场依赖纸质作业指导书，更新滞后且易出错。这些问题不仅拖慢研发到生产的转化速度，更可能因工艺参数偏差导致批量质量事故。例如，某家电企业曾因焊接工艺参数传递失误，导致整批次产品密封性不达标，损失超千万元。这类问题背后，反映的是生产工艺体系缺乏数字化与智能化的系统性支撑。<br/>怎么做：AI驱动的工艺优化技术路径<br/>要实现生产工艺的深度优化，需构建“数据+算法+场景”的闭环体系。具体而言，可分为三个层次推进：<br/>第一，通过数字化协同平台打通设计与工艺环节。例如，利用统一BOM（Bill of Materials）管理系统，确保图纸版本与工艺参数实时同步，避免因信息差导致的返工。Geega平台便通过智能变更影响分析功能，自动标识设计修改涉及的工艺调整范围，将传统需2-3天的沟通流程压缩至小时级。<br/>第二，引入AI算法替代人工重复劳动。在工艺规划阶段，系统可通过机器学习自动生成装配顺序与工时参数。例如，针对复杂零部件装配，AI能基于历史数据与仿真模拟，推荐最优工艺路线，并将标准化率提升至90%以上。<br/>第三，通过3D工艺引擎与动态产线平衡技术，实现生产现场的实时优化。系统可基于实时工位数据动态调整作业分配，避免瓶颈工序滞留。<br/>案例：广域铭岛在新能源电池制造中的实践<br/>以新能源电池行业为例，电极涂布工艺对精度和一致性要求极高，传统模式下需工程师手动调试参数，平均需2周时间完成工艺固化。广域铭岛通过Geega工艺专家系统，实现了三大突破：<br/>首先，利用AI可制造性校核模块，自动检测涂布厚度与均匀性偏差，将图纸审查时间从3天缩短至4小时，早期拦截了90%的设计缺陷。<br/>其次，通过工艺大模型生成最优参数组合，系统自动推荐涂布速度、压力等12项关键参数，使工艺规划效率提升60%，且批次间差异系数降低至0.5%以内。<br/>最后，通过3D作业指导书自动生成功能，操作人员可通过AR设备实时查看动态演示，使培训时间减少70%，操作错误率下降50%。这一案例表明，AI技术不仅解决了单点效率问题，更通过全链路协同实现了“工艺-生产-质量”的一体化管控。<br/>未来，随着制造业柔性化需求加剧，生产工艺优化必将从“局部提效”走向“全局智能”。而能否将技术工具与行业知识深度融合，将成为企业能否在这场转型中领先的关键。</p>]]></description></item><item>    <title><![CDATA[中国 CRM：群雄逐鹿，谁主沉浮？ 闷骚]]></title>    <link>https://segmentfault.com/a/1190000047445541</link>    <guid>https://segmentfault.com/a/1190000047445541</guid>    <pubDate>2025-12-03 12:11:45</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>中国 CRM 市场规模持续增长，数字化转型加速使其备受瞩目，厂商格局多元化，国际与本土厂商竞争激烈。<br/>随着企业数字化转型的加速，CRM 市场规模持续增长。同时，全球客户关系管理市场也在快速发展，到 2027 年，全球客户关系管理市场估计将达到 1144 亿美元，其中亚太地区市场预计将实现最高增长，中国 CRM 市场规模贡献估计达到近 20%。<br/>数字化转型势在必行。在宏观经济层面，国内市场供需关系转变，企业间竞争激烈，以客户为中心成为发展重点。疫情加快了企业数字化转型进程，线上商业迎来发展良机。后疫情时代，企业为寻求长远发展，降本增效成为重点，CRM 产品恰好可以满足企业提高销售效率、深入了解客户、提高客户满意度等需求，因此备受企业瞩目，众多企业已将部署 CRM 提上日程。<br/>厂商格局多元化。中国现在的 CRM 厂商格局呈现多元化和竞争激烈的特点。国际厂商进入给本土厂商构成一定竞争压力，但水土不服问题不可忽视；本土厂商快速发展，受限于发展时间有限，成熟度有待提升，但市场需求和技术趋势的变化推动着 CRM 厂商不断创新和发展，国产领航 CRM 企业已初具规模，开始引领行业方向。<br/>在这样的市场现状下，中国 CRM 市场未来的发展前景广阔，同时也面临着诸多挑战。国际厂商与本土厂商的竞争将更加激烈，而本土厂商需要不断提升自身的技术实力和服务水平，以满足企业日益增长的数字化转型需求。</p><p>国内 CRM 厂商 Top5 盘点</p><p>（一）销售易<br/>销售易以支撑业务人员高效工作为设计出发点，整合了营销服全流程管理包括营销获客、销售管理、经销商管理、售后服务等与客户互动的各个模块。在市场上，销售易以其闭环式精细化管理和强大的定制能力受到中大型企业的青睐。据相关数据显示，销售易在大中型企业市场占有率位居前列，并且增速较快。它多维度的数据安全防护以及 PaaS 属性支持业务平台按需自由定制，含 BI 功能的商业智能平台，帮助企业解决销售管理问题，整体提升销售团队的效率和盈利。且销售易是中国连续八年唯一入选GartnerSFA魔力象限的中国CRM厂商，其产品能力得到了国际认可。<br/>（二）用友 CRM<br/>用友 CRM 凭借其全面的功能和广泛的应用成为主要的 CRM 系统之一。它深度整合业务流程管理能力，支持多平台操作，包括移动设备。用友 CRM 提供客户全生命周期管理、营销活动和费用闭环管理等功能，尤其擅长财务管理与 CRM 的结合，应用大数据和人工智能技术，助力企业实现数字化转型。其强大的数据分析和报告功能，适合大型企业进行精细化管理。然而，学习曲线可能较陡峭，需要一定时间来熟悉和掌握系统操作。<br/>（三）悟空 CRM<br/>悟空 CRM 作为国内开源 CRM 的代表，提供免费的基础服务，在市场上具有较高的知名度。它支持多种部署选项，灵活性高，成本效益高，适合中小企业。悟空 CRM 支持跨平台操作，用户可以在不同设备上使用系统。同时，它还支持无代码自定义，社区支持强大，易于获取帮助。但功能可能不如商业 CRM 系统全面。<br/>（四）八百客 CRM<br/>八百客 CRM 基于 PaaS 的管理自动化平台，提供定制化功能，满足不同行业企业的复杂需求。它支持移动应用和微信集成，提高工作效率，业务自动化和信息化管理能力强，适合需要移动办公能力的企业。然而，集成其他系统可能需要额外的工作。八百客 CRM 在 CRM 领域深耕十几年，积累了丰富的行业经验和技术积累。<br/>（五）金蝶 CRM<br/>金蝶 CRM 面向企业营销人员，以业务智能分析和报告功能著称。它支持多平台操作，用户界面友好，易于上手，适合深度数据分析需求的企业。金蝶作为中国领先的企业管理云 SaaS 公司，在财务管理领域表现卓越，其 CRM 系统也备受市场关注。金蝶 CRM 可与企业现有的 ERP、SCM 等系统无缝集成，适合需要高度集成和可定制 CRM 系统的大型和中型企业。但定制化选项可能有限。</p><p>2024 年国产 CRM 排行特色<br/>在 2024 年国产 CRM 排行中，众多企业各具特色。如销售易CRM以营销服一体化CRM 为特色，提供从营销获客到售后服务的完整闭环一体化服务，连接业务、人和系统，实现高效协作。白码 CRM 作为低代码开发平台，适合快速响应市场变化的企业。悟空 CRM 以开源特点在中小企业中享有较高知名度。用友 CRM 深度整合业务流程管理能力。神州云动 CRM 专为中大型企业设计。八百客 CRM 提供定制化功能。金蝶 CRM 以业务智能分析和报告功能著称。销帮帮 CRM 以 “PaaS + 低代码” 技术为特色。珍客 CRM 提供全面的客户关系管理解决方案。<br/>国产 CRM 替代方案受关注<br/>随着国内 CRM 系统的不断完善和技术的不断进步，国产 CRM 替代方案受到越来越多企业的关注。当企业决定从国外 CRM 替换到国产 CRM 时，面临着操作体验差异、功能重新设计开发、数据迁移和人工任务执行等挑战。然而，像销售易等厂商基于大量项目实践，形成了系统迁移方法论，并完善迁移工具，为业务带来更加平滑、完整、安全且高效的迁移体验，平均提升迁移效率 30% 以上。<br/>总之，中国 CRM 市场充满活力，众多企业在不断创新和发展中展现出巨大的潜力。企业在选择 CRM 系统时，应充分考虑自身需求和特点，选择适合自己的有前途的中国 CRM 企业，以提升企业竞争力和客户满意度。</p>]]></description></item><item>    <title><![CDATA[LeetCode 偶尔一题 —— 301]]></title>    <link>https://segmentfault.com/a/1190000047445544</link>    <guid>https://segmentfault.com/a/1190000047445544</guid>    <pubDate>2025-12-03 12:11:01</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <blockquote>原题：<a href="https://link.segmentfault.com/?enc=Yj%2FPnO6FHof%2BSf%2BoFBsDaQ%3D%3D.XxI%2BT%2Bh3wB4S%2FE1LR8uglEhOEJUNKs5NAX8f8ylnN1v%2BXL1AKrEZ%2F4g1EWDdSd8gRQ7gU18%2BUjhLnKzwurD2k2tuq0AYTh5o15%2Bh74D9NLY%3D" rel="nofollow" target="_blank">https://leetcode.cn/problems/remove-invalid-parentheses/descr...</a></blockquote><h2>1 题目</h2><p>给你一个由若干括号和字母组成的字符串 <code>s</code> ，删除最小数量的无效括号，使得输入的字符串有效。</p><p>返回所有可能的结果。答案可以按 <strong>任意顺序</strong> 返回。</p><p><strong>示例 1：</strong></p><pre><code>输入： s = "()())()"
输出： ["(())()","()()()"]</code></pre><p><strong>示例 2：</strong></p><pre><code>输入： s = "(a)())()"
输出： ["(a())()","(a)()()"]</code></pre><p><strong>示例 3：</strong></p><pre><code>输入： s = ")("
输出： [""]</code></pre><p><strong>提示：</strong></p><ul><li><code>1 &lt;= s.length &lt;= 25</code></li><li><code>s</code> 由小写英文字母以及括号 <code>'('</code> 和 <code>')'</code> 组成</li><li><code>s</code> 中至多含 <code>20</code> 个括号</li></ul><h2>2 分析</h2><p>从题目提供的信息可以知道：</p><ul><li>字符串 <code>s</code> 里除了括号可能还有其他字符</li><li>我们要删除无效的括号，但是需要是数量最小的操作</li></ul><h3>2.1 怎么找出所有结果</h3><p>首先第一个想到的办法就是暴力法，把所有可能的情况都枚举一遍，那么每次进入枚举结果的字符应当符合这个逻辑：</p><ul><li>如果当前字符为 '('，那么最终的结果就是：加 / 不加 两种情况</li><li>如果当前字符为 '('，那么最终的结果也是：加 / 不加 两种情况</li><li>否则，当前字符只能加到最终的结果里</li></ul><h3>2.2 验证最终结果是否合法</h3><h4>2.2.1 方案一、使用栈来进行判断</h4><p>众所周知，括号可以用栈来进行匹配，只是我们在这个场景下需要处理「非括号」的字符，这里直接给出代码：</p><pre><code class="javascript">const isParentheses = (s) =&gt; {
  return s === '(' || s === ')'
}

const isValidParentheses = (s, stack = []) =&gt; {
  let i = 0
  while (i &lt; s.length) {
    if (!stack.length) {
      stack.push(s[i])
      i++
      continue
    }
    const top = stack[0]
    if (top === '(') {
      if (s[i] === ')') {
        stack.shift()
      } else if (s[i] === '(') {
        stack.push(s[i])
      }
    } else if (top === ')' || s[i] === ')') {
      // 如果最顶部是 )，或者最顶部为非括号并且下一个为 ), 说明不是合法括号
      return false
    } else if (s[i] === '(') {
      stack.shift()
      stack.push(s[i])
    }
    i++
  }
  return stack.every(item =&gt; !isParentheses(item)) ? true : !stack.length
}</code></pre><h4>2.2.2 方案二、使用计数法进行过滤</h4><ol><li>如果有一个 '(' 就进行执行 <code>left + 1</code></li><li>如果有一个 ')' 就执行 <code>right + 1</code></li><li>如果出现 <code>left - right &lt; 0</code>，那么说明当前的字符串不合法</li></ol><p>其实这个逻辑也很好理解，如果出现了 <code>left - right &lt; 0</code>，那么就说明当前的字符串是以下这些组合中的其中一种：</p><ul><li><code>())</code></li><li><code>)</code></li></ul><p>即：要么是 '(' 数量不够，要么就是只有 ')'</p><h3>2.3 剪枝 &amp; 去重</h3><h4>2.3.1 剪枝</h4><p>剪枝很好理解，就是我们在递归过程中规避掉已经出现过的值，避免重复计算的手段。<br/>比如在这个场景下，每次递归里当前的字符串就是可以用 map 来进行剪枝的。</p><h4>2.3.2 去重</h4><p>在这个场景下，即使进行剪枝了也避免不了最后出现重复的结果，举个例子：</p><ul><li>)()()) =&gt; ()()) =&gt; ()()</li><li>)()()) =&gt; ()()) =&gt; ()()</li></ul><p>在这个例子中，当前字符为 ()()) 时就会出现 2 个重复的结果，因此在返回最终结果时还需要做一次去重</p><h2>3 代码</h2><pre><code class="javascript">/**
 * @param {string} s
 * @return {string[]}
 */
var removeInvalidParentheses = function (s) {
  const dfs = (acc, i, left, right) =&gt; {
    let step = s.length - (left + right)
    if (left - right &lt; 0) return
    if (i === s.length) {
      const isValid = left === right &amp;&amp; minStep &gt;= step
      if (isValid) {
        minStep = Math.min(minStep, step)
        result.push(acc)
      }
      return
    }
    if (map[acc]) return
    if (s[i] === '(') {
      // 遇到左括号，尝试加 / 不加
      dfs(acc + s[i], i + 1, left + 1, right)
      dfs(acc, i + 1, left, right)
    }
    else if (s[i] === ')') {
      // 遇到右括号，尝试加 / 不加
      dfs(acc + s[i], i + 1, left, right + 1)
      dfs(acc, i + 1, left, right)
    }
    // 遇到其他字符，直接保留
    else dfs(acc + s[i], i + 1, left, right)
    map[acc] = true
  }
  
  const result = []
  const map = {}
  let minStep = Infinity
  dfs("", 0, 0, 0)
  return result.length ? [...new Set(result)] : ['']
};</code></pre><ul><li>时间复杂度：$$O(2^n)$$</li><li>空间复杂度：$$O(n)$$</li></ul>]]></description></item><item>    <title><![CDATA[【React源码阅读】React 渲染流]]></title>    <link>https://segmentfault.com/a/1190000047445547</link>    <guid>https://segmentfault.com/a/1190000047445547</guid>    <pubDate>2025-12-03 12:10:17</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>系列文章：</p><ul><li><a href="https://link.segmentfault.com/?enc=PJl%2BmOKWjSTDUccmEFU51w%3D%3D.ZSpUqNf0SYvYNPdtVITDPj8Hq5WEnpcuQnEXbsvfICJB8MrLs6lrPaWsqVpcGsXj" rel="nofollow" target="_blank">【React 源码阅读】为什么 React Hooks 不能用条件语句来执行？</a></li><li><a href="https://link.segmentfault.com/?enc=5F3NwbCYQR85W9OYceslyQ%3D%3D.3BWUA6ytouyD5ta%2FR8uPt%2FNGEx2PVLax0%2Bf%2Bvy8x%2FvxBhh39bu8Xb7RCHzz4sBQ0" rel="nofollow" target="_blank">【React 源码阅读】useCallback</a></li><li><a href="https://link.segmentfault.com/?enc=BvoafiPnjmYv5sxlt8O2BQ%3D%3D.qhdBA4RcRKLQrXQ%2F3Ary1sdUV3gBb4HpaifNv6wS6PSI%2BYnQ71TaPkxLMSoiaBEO" rel="nofollow" target="_blank">【React 源码阅读】Scheduler</a></li></ul><h2>1 写在前面</h2><p><code>React</code> 源码里的概念实在是太多了，以至于如果真的要能完全理解源码的话，我们就不得不提前了解一部分知识，不然看源码的时候完全就是抓瞎。</p><h2>2 Fiber</h2><h3>2.1 为什么要有 Fiber</h3><p>想象一下，如果你手头上的事情分别有：</p><ul><li>带娃👶（主线任务）</li><li>打游戏🎮（支线任务）</li></ul><p>每次你在打游戏🎮要花不少时间，一局游戏不打完就算👶哭了也不能中断，👶非常伤心（我这不争气的爹）。  <br/>虽然这是一个不恰当的比喻，但是这就是 <code>React</code> 15 的渲染体验：</p><ul><li>任务一旦开始，无法中断</li><li>UI 更新被卡住，用户体验差</li><li>无法分配不同优先级的任务</li></ul><p>在 <code>Fiber</code> 架构下，带娃👶和打游戏🎮这两件事就变成：</p><ul><li><strong>时间分片</strong>：在带娃👶的时候如果有空闲时间那么我就可以打一会游戏</li><li><strong>任务可中断</strong>：一旦娃👶哭了，那么我就立马暂停手中的游戏（去带娃👶）</li><li><strong>任务可恢复</strong>：娃👶不哭了，那么我又可以重新在暂停的地方开始游戏🎮啦</li><li><strong>Lane 模型</strong>：划分优先级，带娃👶这件事情上优先级是 No.1，其他事情先靠边站🙄</li></ul><h3>2.2 概念</h3><p>回归正题，<code>Fiber</code> 它有两个含义：</p><ol><li><p><strong>数据结构</strong></p><ul><li>本质是一个 JavaScript 对象</li><li>每个组件实例对应一个 Fiber 节点</li><li>保存组件的类型、props、state、副作用等信息</li></ul></li><li><p><strong>执行单元</strong></p><ul><li>React 把一次渲染工作拆分成很多小的 Fiber 任务（单元）</li><li>这些单元可以分批执行、中途暂停、恢复、甚至丢弃</li></ul></li></ol><h3>2.3 常见属性及说明</h3><p><code>Fiber</code> 节点里的属性如下：</p><table><thead><tr><th>属性名</th><th>类型说明</th><th>描述</th><th> </th></tr></thead><tbody><tr><td><code>tag</code></td><td><code>number</code></td><td>节点类型，如 FunctionComponent、ClassComponent 等。</td></tr><tr><td><code>key</code></td><td><code>string 或 null</code></td><td>用于 diff 的唯一标识。</td></tr><tr><td><code>elementType</code></td><td><code>任意</code></td><td>JSX 转换后的原始类型，如函数、类、'div' 等。</td></tr><tr><td><code>type</code></td><td><code>任意</code></td><td>节点对应的组件类型或原始标签名。</td></tr><tr><td><code>stateNode</code></td><td><code>对象或 null</code></td><td>对于 DOM 节点是真实 DOM，对于 class 是实例，函数组件为 null。</td></tr><tr><td><code>return</code></td><td><code>Fiber 或 null</code></td><td>指向父节点。</td></tr><tr><td><code>child</code></td><td><code>Fiber 或 null</code></td><td>第一个子节点。</td></tr><tr><td><code>sibling</code></td><td><code>Fiber 或 null</code></td><td>下一个兄弟节点。</td></tr><tr><td><code>index</code></td><td><code>number</code></td><td>在兄弟节点中的位置索引。</td></tr><tr><td><code>ref</code></td><td><code>ref 对象或 null</code></td><td>组件 ref。</td></tr><tr><td><code>pendingProps</code></td><td><code>任意</code></td><td>本次渲染传入的新 props。</td></tr><tr><td><code>memoizedProps</code></td><td><code>任意</code></td><td>上一次渲染的 props。</td></tr><tr><td><code>memoizedState</code></td><td><code>任意</code></td><td>上一次渲染的 state 或 hooks。</td></tr><tr><td><code>updateQueue</code></td><td><code>对象或 null</code></td><td>setState 等更新队列。</td></tr><tr><td><code>dependencies</code></td><td><code>对象或 null</code></td><td>记录当前组件使用的 context。</td></tr><tr><td><code>mode</code></td><td><code>number</code></td><td>Fiber 的模式标志，例如是否启用 ConcurrentMode。</td></tr><tr><td><code>flags</code></td><td><code>位掩码</code></td><td>当前节点本身的副作用标志。</td></tr><tr><td><code>subtreeFlags</code></td><td><code>位掩码</code></td><td>子树副作用集合。</td></tr><tr><td><code>deletions</code></td><td><code>Fiber[] 或 null</code></td><td>待删除的子节点列表。</td></tr><tr><td><code>lanes</code></td><td><code>位掩码</code></td><td>当前节点的优先级集合。</td></tr><tr><td><code>childLanes</code></td><td><code>位掩码</code></td><td>子树中包含的优先级合集。</td></tr><tr><td><code>alternate</code></td><td><code>Fiber 或 null</code></td><td>另一份 Fiber 节点（workInProgress）。</td></tr><tr><td><code>actualDuration</code></td><td><code>number</code></td><td>Profiler 记录的渲染耗时。</td></tr><tr><td><code>actualStartTime</code></td><td><code>number</code></td><td>Profiler 渲染开始时间。</td></tr><tr><td><code>selfBaseDuration</code></td><td><code>number</code></td><td>自身渲染耗时。</td></tr><tr><td><code>treeBaseDuration</code></td><td><code>number</code></td><td>子树渲染总耗时。</td></tr><tr><td><code>_debugOwner</code></td><td><code>Fiber 或 null</code></td><td>DEV 环境用于调试的父组件。</td></tr><tr><td><code>_debugSource</code></td><td><code>对象或 null</code></td><td>DEV 环境的源码位置信息。</td></tr></tbody></table><h3>2.3 Fiber 树</h3><p><code>Fiber</code> 树就是以 <code>Fiber</code> 节点为最小单位组织成的树结构，它用来描述 <code>React</code> 里的页面结构：</p><pre style="display:none;"><code class="mermaid">graph TD
  %% 主 Fiber 树节点
  A["Fiber A"]
  B["Fiber B"]
  C["Fiber C"]
  D["Fiber D"]

  %% alternate Fiber 节点
  A2["Fiber A'"]
  B2["Fiber B'"]

  %% child 关系
  A --&gt;|child| B
  B --&gt;|child| C

  %% sibling 关系
  C --&gt;|sibling| D

  %% return 关系
  B --&gt;|return| A
  C --&gt;|return| B
  D --&gt;|return| B

  %% alternate 关系
  A ---|alternate| A2
  B ---|alternate| B2
</code></pre><h2>3 Lane</h2><h3>3.1 概念</h3><p><code>Lane</code> 是 <code>React</code> 内部用于调度系统的一种优先级管理机制。每个 <code>Lane</code> 是一个二进制位（bit），多个 <code>Lane</code> 可以通过按位或（<code>|</code>）组合成一个 <code>bitmask</code>，从而实现多任务的并行调度与优先级控制。不同类型的更新任务（如同步更新、过渡动画、输入事件等）会被分配到不同的 <code>Lane</code>，React 会根据这些 <code>Lane</code> 的优先级来决定执行顺序。</p><table><thead><tr><th>Lane名称</th><th>二进制值</th><th>十进制值</th><th>说明</th><th> </th></tr></thead><tbody><tr><td><strong>SyncLane</strong></td><td><code>0b000...0001</code></td><td><code>1</code></td><td>同步更新（最高优先级，如 <code>setState</code> in <code>flushSync</code>）</td></tr><tr><td><strong>InputContinuousLane</strong></td><td><code>0b000...0010</code></td><td><code>2</code></td><td>连续输入事件（如拖动、滚动）</td></tr><tr><td><strong>DefaultLane</strong></td><td><code>0b000...0100</code></td><td><code>4</code></td><td>默认更新优先级</td></tr><tr><td><strong>TransitionLanes</strong></td><td><code>0b000...1xxx</code></td><td><code>8 ~ 0x800000</code></td><td>各类 transition，支持并发过渡，如 startTransition</td></tr><tr><td>  TransitionLane1</td><td><code>0b000...1000</code></td><td><code>8</code></td><td>第一个 transition lane</td></tr><tr><td>  TransitionLane2</td><td><code>0b000...1_0000</code></td><td><code>16</code></td><td>第二个 transition lane</td></tr><tr><td>...（共 16 个）</td><td>...</td><td>...</td><td>一直延续到 <code>TransitionLane16</code>（1 &lt;&lt; 21）</td></tr><tr><td><strong>RetryLanes</strong></td><td>...</td><td><code>1 &lt;&lt; 22 ~ 1 &lt;&lt; 23</code></td><td>Suspense retry 后的更新</td></tr><tr><td><strong>IdleLane</strong></td><td><code>0b100...0000</code></td><td><code>1073741824</code></td><td>最低优先级，后台/预渲染任务</td></tr><tr><td><strong>OffscreenLane</strong></td><td><code>1 &lt;&lt; 29</code></td><td><code>536870912</code></td><td>用于隐藏组件的更新（如 <code>&lt;Offscreen /&gt;</code>）</td></tr></tbody></table><p>相应的，<code>React</code> 里也将事件分门别类并且分别赋予了不同的优先级：</p><table><thead><tr><th>事件优先级名称</th><th>对应的 Lane</th><th>常见对应事件类型（事件名）</th><th>描述</th><th> </th></tr></thead><tbody><tr><td><code>NoEventPriority</code></td><td><code>NoLane</code></td><td>无（无任务）</td><td>没有任务，空闲状态</td></tr><tr><td><code>DiscreteEventPriority</code></td><td><code>SyncLane</code></td><td>点击（click）、键盘按键（keydown）、提交（submit）等离散事件</td><td>最高优先级，立即响应用户操作</td></tr><tr><td><code>ContinuousEventPriority</code></td><td><code>InputContinuousLane</code></td><td>鼠标拖拽（mousemove）、滚动（scroll）、连续按键（keypress）等连续输入事件</td><td>用户持续输入，保持流畅体验</td></tr><tr><td><code>DefaultEventPriority</code></td><td><code>DefaultLane</code></td><td>定时器回调、异步请求完成等默认优先级事件</td><td>默认普通优先级</td></tr><tr><td><code>IdleEventPriority</code></td><td><code>IdleLane</code></td><td>空闲回调、后台任务</td><td>低优先级，仅在主线程空闲时执行</td></tr></tbody></table><h3>3.2 相关方法</h3><p>要理解源码里关于 <code>Lane</code> 操作的方法，首先就要理解 <code>Lanes</code> 和 <code>Lane</code> 的区别。<br/>本质上 <code>Lane</code> 和 <code>Lanes</code> 都是 <code>number</code>，但是 <code>Lane</code> 用来单独表示一个优先级，而 <code>Lanes</code> 则用来表示多个优先级。</p><table><thead><tr><th>对比项</th><th><code>Lane</code></th><th><code>Lanes</code></th><th> </th></tr></thead><tbody><tr><td><strong>定义</strong></td><td>单个优先级标识，表示一个更新任务的优先级位。</td><td>多个优先级的组合，表示当前包含哪些优先级的更新。</td></tr><tr><td><strong>类型</strong></td><td><code>number</code>（通常是 <code>2^n</code>，即 0b000...1 形式）</td><td><code>number</code>（多个 <code>Lane</code> 的按位或运算结果）</td></tr><tr><td><strong>二进制形式</strong></td><td>仅一个位为 1，例如：<code>0b000000000000000000000010</code></td><td>多个位可以为 1，例如：<code>0b000000000000000000000110</code></td></tr><tr><td><strong>作用</strong></td><td>表示某一个具体的更新优先级</td><td>表示当前任务涉及的所有优先级</td></tr><tr><td><strong>用途举例</strong></td><td><code>getHighestPriorityLane(lanes): Lane</code></td><td><code>workInProgressRootRenderLanes: Lanes</code></td></tr><tr><td><strong>常用操作</strong></td><td>单独判断、与 <code>Lanes</code> 进行比较等</td><td>位运算（如合并：<code>mergeLanes(a, b)</code>，判断：<code>includesSomeLane(lanes, lane)</code>）</td></tr><tr><td><strong>使用场景</strong></td><td>表示当前某个任务的目标优先级</td><td>表示当前某个 Fiber 或 Root 上所有挂起的任务优先级</td></tr><tr><td><strong>是否复合类型</strong></td><td>否（仅代表一个 bit）</td><td>是（可能包含多个 bit）</td></tr></tbody></table><h4>3.2.1 getHighestPriorityLane</h4><pre><code class="typescript">export function getHighestPriorityLane(lanes: Lanes): Lane {
  return lanes &amp; -lanes;
}</code></pre><p>这个函数是用来获取 <code>Lanes</code> 里最高优先级的 <code>Lane</code> 来优先进行处理。  <br/>在二进制运算里：<code>-lanes = ~lanes + 1</code>，因此 <code>lanes &amp; -lanes</code> 就相当于 <code>lanes &amp; (~lanes + 1)</code>，所以我们可以拿到 <code>lanes</code> 最右边的 1。  <br/>在 <code>Lane</code> 的设计里，优先级是从左到右递增的，因此最右边的 <code>Lane</code> 优先级就是最高的。</p><h4>3.2.2 mergeLanes</h4><pre><code class="typescript">export function mergeLanes(a: Lanes | Lane, b: Lanes | Lane): Lanes {
  return a | b;
}</code></pre><p>尽管 <code>React</code> 里有优先级控制，但是往往同一个事件会有多个优先级叠加，这时候就需要将优先级提上来了，而 <code>mergeLanes</code> 是用来合并 2 个不同的优先级的。  <br/>举例🌰：对于 <code>001</code> 和 <code>010</code> 这两个优先级，合并之后就变成了 <code>011</code>。</p><h4>3.2.3 removeLanes</h4><p><code>removeLanes</code> 顾名思义就是将一个子 <code>lanes</code> 从 <code>Lanes</code> 里移除掉。</p><pre><code class="typescript">export function removeLanes(set: Lanes, subset: Lanes | Lane): Lanes {
  return set &amp; ~subset;
}</code></pre><p>源码里这里比较好理解，就是直接 <code>set &amp; ~subset</code>，这样返回的 <code>Lanes</code> 里就不包含 <code>subset</code> 了。</p><h4>3.2.4 intersectLanes</h4><p><code>intersectLanes</code> 就是取 <code>a</code> 和 <code>b</code> 2 个 <code>Lanes</code> 的交集</p><pre><code class="typescript">export function intersectLanes(a: Lanes | Lane, b: Lanes | Lane): Lanes {
  return a &amp; b;
}</code></pre><p>因为 <code>Lane</code> 是用二进制位的 1 来表示的，所以说用 <code>&amp;</code> 操作之后，对应二进制位上没有 1 的部分都会被去掉。</p><h4>3.2.5 isSubsetOfLanes</h4><p>判断目标 <code>Lane</code> 是否为 <code>Lanes</code> 的子集。</p><pre><code class="typescript">export function isSubsetOfLanes(set: Lanes, subset: Lanes | Lane): boolean {
  return (set &amp; subset) === subset;
}</code></pre><p>简单理解：如果 <code>set &amp; subset</code> 的结果是 <code>subset</code> 的话，说明 <code>set</code> 和 <code>subset</code> 的交集是 <code>subset</code>，也就是说 <code>subset</code> 是 <code>set</code> 的子集。</p><h4>3.2.6 includeSomeLane</h4><p>判断目标 <code>Lanes</code> 是否包含 <code>Lane</code>：</p><pre><code class="typescript">export function includesSomeLane(a: Lanes | Lane, b: Lanes | Lane): boolean {
  return (a &amp; b) !== NoLanes;
}</code></pre><p>这个函数只判断是否有交集，和上面的 <code>intersectLanes</code> 方法有些类似，但是返回的是 <code>boolean</code>。</p><h4>3.2.7 higherPriorityLane</h4><p>返回优先级更高的 <code>Lane</code>:</p><pre><code class="typescript">export function higherPriorityLane(a: Lane, b: Lane): Lane {
  // This works because the bit ranges decrease in priority as you go left.
  return a !== NoLane &amp;&amp; a &lt; b ? a : b;
}</code></pre><p>因为 <code>Lane</code> 是 bitmask 的设计，低位优先级更高，所以这里判断优先级的方法是判断大小，数字越小优先级越高。</p><h4>3.2.8 pickArbitraryLaneIndex</h4><pre><code class="typescript">function pickArbitraryLaneIndex(lanes: Lanes) {
  return 31 - clz32(lanes);
}</code></pre><p><code>clz32</code> 是 JS 内置函数，全称 <strong>Count Leading Zeros in 32-bit integer</strong>。  <br/>它会返回 32 位无符号整数<strong>开头有多少个连续的 0</strong>。</p><p>因此 <code>pickArbitraryLaneIndex</code> 就是返回对应 <code>Lanes</code> 二进制位里 1 的最高位，可以理解为拿到 <code>Lanes</code> 里优先级最低的 <code>Lane</code> 的 <code>index</code>。</p><h4>3.2.9 getLanesOfEqualOrHigherPriority</h4><p>获取一个大于等于目标 <code>Lanes</code> 的 <code>Lane</code>：</p><pre><code class="typescript">function getLanesOfEqualOrHigherPriority(lanes: Lane | Lanes): Lanes {
  // Create a mask with all bits to the right or same as the highest bit.
  // So if lanes is 0b100, the result would be 0b111.
  // If lanes is 0b101, the result would be 0b111.
  const lowestPriorityLaneIndex = 31 - clz32(lanes);
  return (1 &lt;&lt; (lowestPriorityLaneIndex + 1)) - 1;
}</code></pre><p>前面提到 <code>31 - clz32(lanes)</code> 其实就是获取 <code>bitmask</code> 里最左位的 1 的 <code>index</code>。<br/>因此，如果 <code>lanes</code> 为 <code>0b100</code>，那么 <code>lowestPriorityLaneIndex + 1</code> 则为 3。<br/>所以 <code>1 &lt;&lt; (lowestPriorityLaneIndex + 1)</code> 则为 <code>0b1000</code>，减掉 1 之后返回的值为 <code>0b0111</code>。  <br/>这样一来，我们就可以通过这个函数来拿到“优先级相同或更高”的所有 <code>lanes</code>。</p><h2>4 总结</h2><p>在这篇文章里，我们对 <code>Fiber</code>架构和 <code>Lane</code>模型都有了初步的了解，对于后续继续深入阅读 <code>React</code> 源码帮助非常大。</p>]]></description></item><item>    <title><![CDATA[TypeScript 里 infer 常]]></title>    <link>https://segmentfault.com/a/1190000047445554</link>    <guid>https://segmentfault.com/a/1190000047445554</guid>    <pubDate>2025-12-03 12:09:38</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>1 什么是「infer」</h2><h3>1.1 概念</h3><p><code>infer</code> 只能在 <strong>条件类型（conditional types）</strong> 中使用，用来 <strong>在类型推断时声明一个待推断的类型变量</strong>。</p><p>语法为：</p><pre><code class="typescript">T extends SomeType&lt;infer U&gt; ? U : never</code></pre><p>可以这么理解：</p><ul><li>如果 <code>T</code> 能匹配 <code>SomeType&lt;某个类型&gt;</code> 的结构</li><li>那么把内部类型推断为 <code>U</code></li><li>然后返回 <code>U</code></li></ul><h3>1.2 特点</h3><h4>1.2.1 只能在 extends ? : 中使用</h4><p>不能单独写，比如下边这么写就是错的：</p><pre><code class="typescript">type A = infer T; </code></pre><h4>1.2.2 右侧的类型结构必须能匹配</h4><pre><code class="typescript">type A&lt;T&gt; = T extends [infer U] ? U : never;

type B = A&lt;[string]&gt;; // string
type C = A&lt;string&gt;;   // never</code></pre><h2>2 基本用法</h2><h3>2.1 提取函数返回值类型</h3><pre><code class="typescript">type ReturnType&lt;T&gt; = T extends (...args: any[]) =&gt; infer R ? R : never;

type A = ReturnType&lt;() =&gt; number&gt;;
// A = number</code></pre><p><code>infer R</code> 就是 <strong>推断函数的返回值类型</strong>。</p><h3>2.2 提取参数类型</h3><pre><code class="typescript">type FirstArg&lt;T&gt; = T extends (arg: infer P, ...args: any[]) =&gt; any ? P : never;

type A = FirstArg&lt;(x: string, y: number) =&gt; void&gt;;
// A = string</code></pre><h3>2.3 提取数组元素类型</h3><pre><code class="typescript">type ElementOf&lt;T&gt; = T extends (infer U)[] ? U : never;

type A = ElementOf&lt;string[]&gt;; 
// A = string</code></pre><h3>2.4 提取 tuple 的某个元素</h3><pre><code class="typescript">type First&lt;T&gt; = T extends [infer F, ...any[]] ? F : never;

type A = First&lt;[string, number, boolean]&gt;;
// A = string</code></pre><p>在这个例子中，我们提取的是 tuple 的第一个元素。</p><h3>2.5 提取对象中某个 key 的类型</h3><pre><code class="typescript">type PropType&lt;T, K extends keyof T&gt; = 
  T extends { [Key in K]: infer R } 
    ? R 
    : never;

type A = PropType&lt;{name: string; age: number}, 'age'&gt;;
// A = number</code></pre><h3>2.6 对象路径提取</h3><pre><code class="typescript">type Path&lt;T&gt; = {
    [K in keyof T]: 
        T[K] extends object 
          ? `${string &amp; K}.${Path&lt;T[K]&gt;}`
          : `${string &amp; K}`;
}[keyof T];</code></pre><p>假设说我们有这么一个类型：</p><pre><code class="typescript">type User = {
  id: number;
  name: {
    first: string;
    last: string;
  };
  address: {
    city: string;
    location: {
      lat: number;
      lng: number;
    };
  };
};</code></pre><p>执行 <code>Path</code>：</p><pre><code class="typescript">type UserPath = Path&lt;User&gt;;</code></pre><p>之后得到的结果展开就是：</p><pre><code class="typescript">type UserPath =
  | "id"
  | "name.first"
  | "name.last"
  | "address.city"
  | "address.location.lat"
  | "address.location.lng";</code></pre><h2>3 总结</h2><p>本文总结了 TypeScript 中 <code>infer</code> 的常见用法，可以说 <code>infer</code> 是 TypeScript 里各种类型体操的基础，基于它可以实现各种「高级」类型。</p>]]></description></item>  </channel></rss>