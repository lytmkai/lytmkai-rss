<?xml version="1.0" encoding="UTF-8"?><rss version="2.0">  <channel>      <title>SegmentFault - 最近文章</title>      <link>https://segmentfault.com/blogs/newest</link>      <description>SegmentFault 思否</description>      <generator>python segmentfault.py @Pi20</generator>      <item>    <title><![CDATA[立省 200 刀！Claude Code 接入 GMI Cloud Inference Engine]]></title>    <link>https://segmentfault.com/a/1190000047554120</link>    <guid>https://segmentfault.com/a/1190000047554120</guid>    <pubDate>2026-01-20 18:08:48</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><strong>GMI Cloud Inference Engine</strong> 是全球 AI 模型统一接入与在线使用的“高性能推理引擎平台”，底层搭载 H100/H200 芯片，集成全球近百个最前沿的大语言模型和视频生成模型，如 Gemini、Claude、Minimax、DeepSeek、GPT、Qwen、Kling 等，为 AI 开发者与企业提供速度更快、质量更高的模型服务。</p><p>欢迎来到！🎉🎉🎉</p><p>GMI Cloud Inference Engine AI 场景实践案例集【AI Coding 篇】之二。</p><p>**本期任务目标：**在 Windows 终端里，使用 Claude Code 命令行工具，连接 GMI Cloud Inference Engine 的 MiniMax 模型 API。</p><p>Claude Code 是 Anthropic 推出的命令行 AI 编程工具，基于 Claude 大模型，可在终端 / IDE 中用自然语言交互，深度理解代码库，支持跨文件编辑、Git 协作。其具有 agent 优势，与超大上下文+多文件编辑+终端原生+安全自主执行+顶级模型能力，在处理大型项目、复杂重构和企业级开发时展现出明显优势。</p><p>本文将以接入 Inference Engine 中的 MiniMax-M2 api 为例，详细讲解在 Claude Code 中接入 api 的过程。Token福利文末自行领取！！</p><p>MiniMax-M2 界面：</p><p><a href="https://link.segmentfault.com/?enc=tcdXP0%2FY7mCcy9aX9XZXOQ%3D%3D.011rPQEoTnimEvxiQiFngqaFXkFP%2B9yWkXMdS4KT8nXRJBY87VAt5q%2FZGNLi7Z1JGHT31bx5VZ9x0U6ITjPk1unKPaGUul%2BbdjoKzOwfMHf3ZGlrYRm2CAhZPz1ECXpF" rel="nofollow" target="_blank">https://console.gmicloud.ai/playground/llm/minimax-m2/bbfb2cb...</a></p><p><strong>01</strong></p><p><strong>准备工作</strong></p><p><strong>Get ready?</strong></p><p>确保你已经掌握 AI Coding 基础知识，没有可看上一篇：</p><blockquote><p>附上链接~</p><p>Kooty，公众号：GMI Cloud 黑板报小白友好教程！如何在 Cursor 接入 GMI Cloud 的 API</p></blockquote><p>确保你的电脑已经安装了：</p><ul><li>Python （为了运行 LiteLLM）</li><li>Node.js （为了运行 Claude Code）</li></ul><p><strong>02</strong></p><p><strong>接入步骤</strong></p><p><strong>API Connection Guide</strong></p><p><strong>步骤 1：安装必要工具</strong></p><p>打开 PowerShell，依次运行以下命令：</p><p><strong>1.安装 Claude Code 工具</strong></p><pre><code>npm install -g @anthropic-ai/claude-code</code></pre><p><strong>2.安装 LiteLLM（带代理功能）</strong></p><pre><code>
# 注意加上引号，因为[proxy]是特殊字符 
pip install "litellm[proxy]"</code></pre><p>如果不懂怎么安装，可以直接在 Cursor 聊天框输入（亲测 Gemini3 可以直接一步到位，模型不够好可能中途会报错）：</p><pre><code>https://docs.claude.com/en/docs/claude-code/overview参考这个文档，帮我安装claudecode</code></pre><p>无论是通过哪种安装方式，Claude Code 在安装后都会引导你配置参数或者注册登录，如果你有账号可以按照引导往下走。如果没有、希望和笔者一样直接接入自己的（便宜的）api，可以登录到非得付费的那一步退出，然后继续步骤 2。</p><p><strong>步骤 2：启动“翻译官” （LiteLLM）</strong></p><p>我们需要启动一个本地服务，用来做连接我们的 api 和 Anthropic 之间的桥梁。在 PowerShell 中运行（替换为你自己的 API Key）：</p><pre><code>
# 设置 Key (必须加引号)
$env:OPENAI_API_KEY = "你的MiniMax_API_Key"

# 启动服务
# --drop_params: 自动丢弃不兼容的参数，防止报错
litellm --model openai/MiniMaxAI/MiniMax-M2 --api_base https://api.gmi-serving.com/v1 --drop_params</code></pre><p>✅ 成功标志：看到 Running on <a href="https://link.segmentfault.com/?enc=DAIWXJoSzY9SpKNmfPZO1w%3D%3D.9nVnVkyHP7FWjaBqFECH2%2FMj8C51NpzYtE5E0G%2B9qWQ%3D" rel="nofollow" target="_blank">http://0.0.0.0:4000</a>。</p><p>⚠️ 注意：这个窗口不要关闭。步骤 3 打开一个新的 powershell 窗口。</p><p>步骤 3：配置 PowerShell 连接</p><p>现在我们要告诉 Claude 工具：“别去连官网了，来连我们本地的翻译官”。</p><p><strong>1. 打开配置文件：</strong></p><p>在新的 PowerShell 窗口中输入：</p><pre><code> notepad $PROFILE</code></pre><p><strong>2.粘贴以下代码：</strong></p><pre><code>
   function minimax {
       &amp; {
           # 1. 把目标地址指向本地 LiteLLM (端口 4000)
           $env:ANTHROPIC_BASE_URL = "http://localhost:4000"
           
           # 2. Key 随便填，因为真实的 Key 已经在 LiteLLM 那边配好了
           $env:ANTHROPIC_AUTH_TOKEN = "sk-placeholder"
           
           # 3. 模型名称要和 LiteLLM 启动时的匹配
           $env:ANTHROPIC_MODEL = "MiniMaxAI/MiniMax-M2"
           $env:ANTHROPIC_SMALL_FAST_MODEL = "MiniMaxAI/MiniMax-M2"
           
           # 4. 启动 Claude 工具
           if (Get-Command claude -ErrorAction SilentlyContinue) {
               claude @args
           } else {
               Write-Error "请先安装 claude-code: npm install -g @anthropic-ai/claude-code"
           }
       }
   }</code></pre><p><strong>步骤 4：开始使用</strong></p><ol><li><strong>新建一个 PowerShell 窗口（确保配置生效）。</strong></li><li><strong>输入命令：</strong></li></ol><pre><code>
# 启动自设定的minimax程序 
minimax 
# 进行测试 
你好</code></pre><p>🎉 看到回复即搞定！ 现在你就在用 Anthropic 的顶级命令行体验，驱动着公司的 MiniMax 模型了。</p><p>大家可以对比输入“claude code”和“minimax”下的差别：</p><p><img width="723" height="510" referrerpolicy="no-referrer" src="/img/bVdnG8x" alt="图片" title="图片"/></p><p><strong>步骤 5：将 LiteLLM 的启动简化（选做）</strong></p><p>Cursor 聊天框输入:</p><pre><code>帮我将LiteLLM的启动简化，生成一个一键启动脚本。</code></pre><p>下次使用时，就只需两步：</p><ol><li>点击该脚本</li><li>在另一个终端窗口中输入“minimax”</li></ol><p>另外，如果想更方便，比如在桌面启动 LiteLLM，也可以将这个 .bat 的文件和 .yaml 的参数文件一起复制到目标位置。比如我将其复制到了桌面。</p><p><img width="378" height="276" referrerpolicy="no-referrer" src="/img/bVdnG8y" alt="图片" title="图片" loading="lazy"/></p><p><img width="723" height="533" referrerpolicy="no-referrer" src="/img/bVdnG8z" alt="图片" title="图片" loading="lazy"/></p><p>💡 <strong>常见报错</strong></p><p>Q: 报错 ImportError: Missing dependency 'backoff'？</p><p>A: 你安装时少装了组件。请运行 pip install "litellm[proxy]"。</p><p>Q: 报错 UnsupportedParamsError: ... reasoning\_effort?</p><p>A: 启动 LiteLLM 时忘了加 --drop\_params 参数。</p><p>Q: 输入 minimax 提示找不到命令？</p><p>A: 修改完配置文件后，需要重启 PowerShell 窗口，或者运行 。 $PROFILE 刷新一下。</p><p><strong>03</strong></p><p><strong>总结和拓展</strong></p><p><strong>Summary &amp; Expansion</strong></p><p><strong>总结</strong></p><p><strong>1. 核心文件</strong></p><p><img width="723" height="170" referrerpolicy="no-referrer" src="/img/bVdnG8A" alt="图片" title="图片" loading="lazy"/></p><p><strong>2. 完整的逻辑链路图</strong></p><ul><li><strong>准备层（启动网关）</strong></li></ul><p>运行 start\_minimax\_proxy.bat。</p><p>关键动作：它不仅加载了 yaml 配置，还通过 set OPENAI\_API\_KEY 把**通行证（Token）**交给了 LiteLLM 进程。</p><p>结果：本地 4000（或其他）端口开始监听。</p><ul><li><strong>调用层（触发指令）</strong></li></ul><p>你输入 minimax。</p><p>关键动作：系统执行 ps1 脚本里的函数。</p><ul><li><strong>重定向层（配置环境）</strong></li></ul><p>关键动作：ps1 脚本在内存里临时改了两个环境变量：</p><p>ANTHROPIC\_BASE\_URL：指路，让 Claude Code 走向本地端口。</p><p>ANTHROPIC\_MODEL：定名，告诉 Claude Code 要发出的“暗号”是什么。</p><p>结果：Claude Code 启动并按照这个路标发包。</p><ul><li><strong>翻译层（中转适配）</strong></li></ul><p>关键动作：这是最复杂的一步。</p><p>收包：LiteLLM 收到 Claude Code 的 Anthropic 格式请求。</p><p>查表：它看一眼 yaml，发现 model\_name（暗号）对上了。</p><p>变身：它把请求拆开，去掉多余参数（drop\_params），重新包装成标准的 OpenAI 格式。</p><p>送达：最后，它带着 .bat 里的那个 Token，把请求发给供应商的 v1 接口。</p><p><strong>拓展：思考题</strong></p><p><em>如果不想用MiniMax了，想用Inference Engine平台的其他模型，该修改哪几个文件？</em></p><p>**正确答案：**以Deepseek为例</p><p>修改.ps1、修改yaml，将 minimax function 一样的格式复制一份、修改模型名称部分就可以啦！</p><p><img width="723" height="391" referrerpolicy="no-referrer" src="/img/bVdnG8B" alt="图片" title="图片" loading="lazy"/></p><p><img width="723" height="681" referrerpolicy="no-referrer" src="/img/bVdnG8C" alt="图片" title="图片" loading="lazy"/></p><p>在启动时则可在终端输入deepseek，同样能成功启动</p><p><img width="723" height="381" referrerpolicy="no-referrer" src="/img/bVdnG8D" alt="图片" title="图片" loading="lazy"/></p><p>教程完毕！😍😍😍 快去试试吧~</p>]]></description></item><item>    <title><![CDATA[“全栈模式”必然导致“质量雪崩”！和个人水平关系不大~ 悲伤的煎鸡蛋_cQXuXF ]]></title>    <link>https://segmentfault.com/a/1190000047554137</link>    <guid>https://segmentfault.com/a/1190000047554137</guid>    <pubDate>2026-01-20 18:08:16</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在经济下行的大背景下，越来越多的中小型企业开始放弃“前后端分离”的人员配置，开始采用“全栈式开发”的模式来进行研发费用的节省。</p><p>这方法真那么好吗？</p><p>作为一名从“全栈开发”自我阉割成“前端开发”的逆行研发，我有很多话想说。</p><p>先从一个活生生的真实案例开始吧。</p><p>我认识一个非常优秀的全栈开发，因为名字最后一个字是阳，所以被大家称为“阳神”。</p><ol><li>“阳神”的“神狗二相性”</li></ol><p>阳神当然是牛逼的。</p><p>他不仅精通后端开发，更是对前端了解的非常深。这样来说吧:</p><p>当他作为后端开发时，他可以是那群后端同事里库表设计最清晰，代码最规范，效率最高的后端。</p><p>当他作为前端开发时，他除了比几位高级别前端稍逊一点外，效率和UI还原性都非常高，还会主动封装组件减少耦合。</p><p>但是非常奇怪的事情总是会发生，因为一旦阳神不是全职的“后端”或者“前端”时，一旦让他同时操刀“后端+前端”开发任务，作为一名“全栈”来进行业务推进时，他的表现会让人感到惊讶：</p><p>他会写出设计糟糕，不规范，职责混乱的代码。</p><p>这个现象我把他戏称为“阳神”的“神狗二相性”，作为单一职责时他是“阳神”，同时兼任多职时，他就有非常大的可能降格为“阳狗”。<br/><img width="574" height="313" referrerpolicy="no-referrer" src="/img/bVdnG7y" alt="" title=""/></p><p>为什么呢？这是阳神主观上让自己写更糟糕的代码吗？</p><p>不是的兄弟，不是的。</p><p>这是系统性的崩塌，几乎不以人的意志为转移。换我去也是一样，换你去也是一样。</p><ol start="2"><li>分工粗化必然导致技术细节的差异</li></ol><p>从前，在软件开发的古老行会里，一个学徒需要花很多年才能出师，专门做一把椅子，或者专门雕一朵花。现在，你被要求从伐木到抛光，从结构力学到表面美学，全部一手包办。</p><p>生产力在发展，对人的技能要求也在发展。</p><p>因此“分工细化”成为了工业革命之后完全不可逆的趋势。</p><p>在 IT 产业上也是如此。</p><p>“软件开发”经过多年被细化出了前端开发、后端开发、客户端开发、大数据开发 等等多种不同的细分职业。</p><p>但是现在有人想通过 粗化 职业分功来达到 “提效” 的目的，在我眼中这就是和客观规律对着干。</p><p>人的精力是守恒的。当你需要同时关心useEffect的依赖数组会不会导致无限渲染，和kubectl的配置能不能正确拉起Pod时，你的注意力就被稀释了。你不再有那种“针对一个领域，往深里钻，钻到冒油”的奢侈。</p><p>当你脑袋里冒出了一个关于前端工程化优化的问题时，身为全栈的你会本能地冒出另一个念头：</p><p>在整个全栈体系内，前端工程化优化是多么边角料且无关痛痒的问题啊，我去深入研究和解决它的性价比实在太低了，算了不想了。</p><p>如此一来，无论是后端的性能问题还是前端的性能问题都会变得无关紧要。<br/><img width="568" height="370" referrerpolicy="no-referrer" src="/img/bVdnHah" alt="" title="" loading="lazy"/></p><p>结果是，只有业务问题是全栈开发要关心的问题。</p><ol start="2"><li>“岗位对立”与“自我妥协”</li></ol><p>在日常开发中，前端开发和后端开发之间互相吐槽争论是再正常不过的话题，而且争论的核心非常简单易懂：</p><p>前端：这事儿不能在后端做吗？</p><p>后端：这事儿前端不能做吗？</p><p>可以的，兄弟，最后你会发现都是可以的，代码里大部分的事情无论是在浏览器端完成还是在服务器里完成都是可行的。</p><p>但是，总有一个“哪方更适合做”吧？</p><pre><code>一个大屏页面的几万几十万条的数据统计，是应该后端做还是前端做？
业务数据到Echarts展示数据的格式转换应该后端做还是前端做？
用户数据权限的过滤应该后端做还是前端做？
一个列表到底要做真分页还是假分页？
列表已经返回了全量实体信息，为什么还要再增加一个详情接口？

</code></pre><p>这都是日常开发时前端和后端都会去争论思考的问题，身处不同的职位，就会引入不同的立场和思考。</p><pre><code>前端需要去思考页面刷新后状态的留存，js单线程下大量数据处理的卡顿，页面dom树爆表的困境。
后端也需要思考并发下服务器资源和内存的分配，可能的死锁问题，以及用户的无状态token如何处理等。

</code></pre><p>前后端的“争吵”和观点输出是不可避免的。</p><p>真理总是越辩越清晰的，后续讨论出的结果多半是最有利于当前现状的。</p><p>但如果“前后端”都是同一个人呢？</p><p>全栈模式，完美地消灭了这种“有益的摩擦”。当你自己和自己联调时，你不会给自己提挑战灵魂的问题。你不会问：“这个API设计是否RESTful？”因为你赶时间。你也不会纠结：“这个组件的可访问性够好吗？”因为你还得去部署服务器。</p><p>这两种思想在你的大脑里打架，最终往往不是最优解胜出，而是最省事的那个方案活了下来。</p><p>于是，你的代码里充满了“差不多就行”的妥协。这种妥协，一两个无所谓，当成百上千个“差不多”堆积起来时，质量的基础就酥了。</p><p>内部摩擦的消失，使得代码在诞生之初就缺少了一道质量校验的工序。它顺滑地流向生产环境，然后，在某个深夜，轰然引爆。</p><p><strong>插播机-会</strong></p><p>技术大厂，前端-后端-测试，全国均<a href="https://link.segmentfault.com/?enc=Vvm3naxCj5BZa2Hbb6RZxQ%3D%3D.2DGHxq7Gvems1tOFzYdBKR8jQeZodU3l%2BIe9vXMtjX0%3D" rel="nofollow" target="_blank">有机-会</a>，感兴趣可以试试。待遇和稳定性都还不错~</p><ol start="3"><li>工程的“不可能三角”</li></ol><p>软件开发领域有一个著名的“不可能三角”：</p><p>快、好、省，你只能选两样。</p><p>全栈模式，在管理者眼中，完美地实现了“省”（一个人干两个人的活）和“快”（省去沟通成本）。那么，被牺牲掉的是谁？</p><p>雪崩时，没有一片雪花是无辜的。但更重要的是，当结构性雪崩发生时，问责任何一片雪花，都意义不大。</p><p>至于“快、好、省”这三兄弟怎么选？</p><p>那主要看老板的认知和他的钱包了。</p><p>——转载自：摸鱼的春哥</p>]]></description></item><item>    <title><![CDATA[从lnstagram数据泄露事件看时代危机 JoySSL揭示数字证书是数字化发展不可或缺的安全防护系]]></title>    <link>https://segmentfault.com/a/1190000047554140</link>    <guid>https://segmentfault.com/a/1190000047554140</guid>    <pubDate>2026-01-20 18:07:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>据国外网络安全公司Malwarebytes近日披露的消息显示，知名企业lnstagram的用户系统遭到非法入侵，超1750万个用户账户的个人敏感信息遭到泄露。目前这些个人隐私数据正在暗网流通，对用户的隐私与账户安全造成了严重威胁。此次泄露的数据包含了用户名、电子邮箱、电话号码甚至地址信息，使得用户面临严重的隐私曝光。攻击者完全可以利用这些泄露的信息进行身份盗用，实施钓鱼攻击，从而开展网络诈骗活动。有知情人士反馈，已有多名用户收到了平台的密码重置通知，表明攻击者正在尝试利用泄露的账户信息进行非法操作。JoySSL安全部负责人表示，透过此次lnstagram数据泄露事件不难看出，数据已成为驱动全球经济的核心燃料，任何掌握用户数据的平台，都必须重视安全防护建设，任何微小的裂痕都足以引发一场“数字地震”，动摇用户对数字服务的信任根基。以数字证书为代表的安全加密类技术，正在为全球数字化发展构筑安全防线，建立信任体系，市场价值不言而喻。</p><p><img width="723" height="480" referrerpolicy="no-referrer" src="/img/bVdnHak" alt="" title=""/></p><p><strong>lnstagram泄露事件 揭露数字生态系统共性弱点</strong></p><p>此类涉及超大数据规模的泄漏事件，往往揭示了复杂数字生态系统中存在的各种问题。数据传输链普遍存在漏洞，若缺乏端到端加密及强制性身份验证，或可成为攻击者窃取数据的机会。 此外，攻击者可能伪装为合法用户，获取未授权的数据访问权，看似是轻微的漏洞被利用，其带来的后果往往堪称灾难级。</p><p><strong>SSL证书构筑防护堤坝 数据洪流中抵御网络威胁</strong></p><p>数字化时代，数据早已成为数字经济发展的核心构成。若不能建立有效的防护体系，保障数据安全，经济的发展只是建立在沙滩上的堡垒，根基不稳，一冲即散。SSL证书确保数据传输的“加密防护”，维护信息流的隐私性，有效防止网络窃听。 </p><p><img width="723" height="481" referrerpolicy="no-referrer" src="/img/bVdnHal" alt="" title="" loading="lazy"/></p><p>OV/EV证书强化服务器端身份验证，建立安全可信的连接环境，可有效防范网络钓鱼攻击、中间人攻击及非法连接。可通过浏览器的绿色地址栏直接显示企业名称，为普通用户提供简单直观的身份验证方式。企业利用基于SSL证书的双向认证技术，能够有效确保数据仅在身份验证成功并获得授权的合作伙伴之间，进行安全传输。</p><p><strong>从可有可无到核心竞争力资产 数字证书价值凸显</strong></p><p>在数字化转型深入发展的时期，SSL证书的市场价值已被彻底重新定义。它是企业满足数据安全法规、避免因缺乏加密措施而面临巨额罚款的高性价比投资。通过部署具有高辨识度的EV证书，企业能够证明其身份直接提升用户忠诚度和品牌溢价，为自己构筑数字时代的“信任壁垒”。</p><p><img width="723" height="477" referrerpolicy="no-referrer" src="/img/bVdnHam" alt="" title="" loading="lazy"/></p><p>谷歌、百度等搜索引擎已将HTTPS视为影响排名的重要因素。JoySSL网络总监指出，基于HTTPS启用HTTP/2或HTTP/3等现代协议可显著改善应用加载速度，提升用户体验。同时，越来越多的生态合作伙伴将可信的HTTPS证书作为技术集成的准入标准。</p><p><strong>以SSL证书作信任基石 以可信链接锚定未来市场</strong></p><p>Instagram数据泄露事件并非孤立现象，而是数字化转型中的典型表现。数据流动过程中，安全保障已经从技术领域上升为企业的核心经营需求，成为不可或缺的数字信任基石。它不仅确保数据的加密传输，还维护企业的信誉，同时提升消费者对品牌的信任感，通过建立可信链接，锚定企业未来发展市场。</p>]]></description></item><item>    <title><![CDATA[云原生周刊：Kubernetes 1.35 新机制与云原生生态更新 KubeSphere ]]></title>    <link>https://segmentfault.com/a/1190000047554143</link>    <guid>https://segmentfault.com/a/1190000047554143</guid>    <pubDate>2026-01-20 18:06:28</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>云原生热点</h2><h3><a href="https://link.segmentfault.com/?enc=TFspogut50UzIfbQT%2BkXag%3D%3D.qkbxUCcdNxMRNenC8eemceb7A484tDz0cvTDdgcdWRupIns3PSoBEiy%2Bqd%2BGA%2BLv745AnxC22eOxi1VBSVR5e4HmMTKk7JmIX7kJmnI1o3I53WlzdETE09gc6qpsZCFxe5g9QLuMzphUcKPhW0SrRbiyWQYWtI6GZ%2F3qsKM%2BLPt7O9qyt2u4ZqceZDTm3cQ67ei6LW%2B1skxPj0bdix0GJvZ5efqGyZbgTc6cXLAGbZHPtQEhJtVMXqR%2BF6jxdtiz" rel="nofollow" target="_blank">Agones 1.54.0 版本发布：计数器能力增强，GKE Autopilot 直通通信正式稳定</a></h3><p>Agones 是一个开源的 K8s 原生游戏服务器托管与扩展框架，用于在 K8s 集群上运行、管理和自动扩缩专用游戏服务器资源。它通过自定义资源（如 GameServer、Fleet 等）和控制器，帮助开发者高效管理大规模实时游戏服务器生命周期与调度。</p><p>1.54.0 版本新增对 K8s v1.34 的支持，并强化了在 GKE Autopilot 场景下的端口直通能力；同时引入更完善的 Counter 状态工具，提升服务器状态可观测性，简化自动扩缩配置，并修复 Init Container 相关问题，整体提升了稳定性、易用性和云托管兼容能力。</p><h3><a href="https://link.segmentfault.com/?enc=pN%2Fqv%2FHMlyIY3QzmVAmPUw%3D%3D.DyQCTnoslDpqxvzOroo0FrcGG0lu%2Fz1sJYQJk45Wpa9MSOBYu%2FqCeysB6388EJayyA93xTWneajvmognO5YFhw%3D%3D" rel="nofollow" target="_blank">Kube-OVN v1.15 发布：新年新版，网络功能再进化</a></h3><p>Kube-OVN 是一个基于 OVN/Open vSwitch 的 K8s 云原生网络插件，将 SDN 虚拟网络能力引入容器网络，支持静态 IP 分配、VPC 多租户、灵活网络策略等丰富功能，提升集群网络可控性与性能。</p><p>Kube-OVN v1.15 近日成功发布，新版本重点增强网络灵活性与稳定性，支持更精细的 IPPool 绑定与管理，升级 OVS 和 OVN 核心组件，提升性能与安全性，同时强化监控与健康检查能力，并清理遗留代码，进一步提升生产环境下的可运维性与可靠性。</p><h2>技术实践</h2><h3>文章推荐</h3><h3><a href="https://link.segmentfault.com/?enc=Vr%2FXnfDd3NhEx3l5FgbGfw%3D%3D.Ae2eCWE5XxJy%2BstiUbjAZoqkdoj%2BA%2Fjbi%2BiD6et0h3rLvS6ux2n92MqrXHtlQHd%2FdApX2spcUQStxek%2B4oXlKoqWp4gQ%2F1%2BzjAYOtfFb3dJlY5OOUBqEeUikhqvSrF6A" rel="nofollow" target="_blank">K8s v1.35：云控制器管理器中的基于监视的路由协调</a></h3><p>本文介绍了 K8s v1.35 在 Cloud Controller Manager（CCM）的路由控制器中新增特性门控 <code>CloudControllerManagerWatchBasedRoutesReconciliation</code>：将原先按固定间隔轮询对账，改为基于 informer 的 watch 机制，在节点增删或 <code>.spec.podCIDRs</code>、<code>.status.addresses</code> 变化时触发对账，并保留 12–24 小时随机周期的补充对账，从而在路由无变化时显著减少对云厂商的无谓 API 请求，同时不改变既有对账逻辑，降低行为变化风险。</p><h3><a href="https://link.segmentfault.com/?enc=cnkQgUWc%2BtZl6ABNwDtnWA%3D%3D.lToyJY8v%2FH6ccjJAtPBXJmWYl2w3hW6jqSlT%2BVS%2FaTRUUwON6%2B3eL6N%2BcOwIKXSvEAuxjPIXBqdxLOR7DjHRdeRDNnjzFjWiCsZOQF2F0zs%3D" rel="nofollow" target="_blank">使用 clientcmd 进行统一的 API 服务器访问</a></h3><p>本文介绍了 K8s 在 v1.35 中针对 <strong>clientcmd 访问 API Server</strong> 的改进（Uniform API server access using clientcmd），强调统一和简化使用 kubeconfig/clientcmd 与 API Server 交互的方式，使客户端（如 kubectl 或程序库）通过一致的配置和流程发现 API Server 地址、凭据与认证细节，从而减少重复配置和访问复杂度，提高与集群 API 交互的可靠性和开发效率，同时保持与现有访问机制兼容。</p><h3><a href="https://link.segmentfault.com/?enc=ZXN22hlnDjtpNcWLfrJNCg%3D%3D.lVPI5H9ylXvCBTr%2FPVZmflNjE0I0fvxuYA2KzOROKuSEUldvpi3te2JVtyij2juS3NrRc2x%2FnfsLmfdYLVIuByxPx89XObfDxPn5vaYwkm4WGi5oKIhQVRHKMBNifppY" rel="nofollow" target="_blank">K8s 事故中惨痛教训揭示的隐藏不良实践</a></h3><p>本文介绍了一些在生产事故中才暴露出来的 K8s 错误实践及其应避免的方式。文章由一位 SRE 工程师分享常见但常被忽视的错误做法，如错误配置探针/资源请求、缺乏网络策略、过度权限设置等，这些隐性坏习惯在集群运行和故障时会引发严重问题。作者结合实际事件，提出改善建议以提升集群稳定性与安全性，对于 K8s 生产环境的运维和 SRE 团队具有重要参考价值。</p><h3>开源项目推荐</h3><h3><a href="https://link.segmentfault.com/?enc=06jpawNU28%2BaDhBTsKcyow%3D%3D.4hIXACd9oLA2B%2FIeBT7oT7VUUdqTxtdHyUIeZqwvFHDZlNvVYkxu5a%2BuImLrP5iZ" rel="nofollow" target="_blank">AIBrix</a></h3><p>AIBrix 是一个开源的云原生大规模 LLM 推理基础设施框架，用于在 K8s 上高效部署、管理和扩展大型语言模型推理服务，支持路由、自动扩缩、分布式推理和 KV 缓存等关键能力，帮助企业构建可扩展、高性价比的生成式 AI 推理平台。它与 vLLM 紧密集成，适合生产环境和大规模应用场景。</p><h3><a href="https://link.segmentfault.com/?enc=U%2FKe04s563PS0O0AuCPDJg%3D%3D.HpuxJyvh%2Bihww2C6NNN7LC6meRVIER3YoPvArVDuVAqTuSeeriOOrHWlYz4e4g0y" rel="nofollow" target="_blank">Kyverno</a></h3><p>Kyverno 是一个开源的 K8s 原生策略引擎，用于通过“策略即代码”（Policy as Code）管理集群中的资源安全、合规和自动化。它允许你用熟悉的 K8s YAML 定义策略，验证(validate)、变更(mutates)、生成(generate) 和清理(cleanup) 资源，增强安全性和治理，还支持镜像签名验证等高级用例，非常适合平台工程、DevOps 和安全团队。</p><h3><a href="https://link.segmentfault.com/?enc=c5R90XfBZTC0nM8pIpy%2Bew%3D%3D.x0OnExdrvlYm3aoe5xKrbhiqu%2F39bYu2WGxy8Ma1Bkt8F6vwUlWF8kq9EQPRzFm3" rel="nofollow" target="_blank">vcluster</a></h3><p>vcluster 是一个开源的虚拟 K8s 集群解决方案，它在一个真实集群内创建轻量级、隔离的虚拟集群实例。每个虚拟集群拥有独立的 API 和控制平面，但共享底层节点资源，启动快、资源占用少、权限隔离好。适合多租户开发测试、CI/CD 环境和平台自助服务等场景。</p><h3><a href="https://link.segmentfault.com/?enc=yof%2FtrF9DMW9vv2g3Iu8nw%3D%3D.aMMGZBOatkcsexsaevakCL4g6VFPFGN14vT5Oy6kDGrzLwiLv9g2fvhsFrDcd%2FFY" rel="nofollow" target="_blank">SpinKube</a></h3><p>SpinKube 是一个开源的 WebAssembly（Wasm）无服务器运行时平台，简化在 K8s 上开发、部署与管理 Wasm 工作负载。它结合 Spin Operator、containerd shim 和 Runtime Class 管理器，可让轻量级、快速启动的 Wasm 应用像容器一样运行，并集成自动扩缩与 Kubernetes 原生机制。该项目已成为 CNCF Sandbox 成员，适合构建高效、可扩展的云原生服务。</p><h3>关于KubeSphere</h3><p>KubeSphere （<a href="https://link.segmentfault.com/?enc=5ukboLn8eTszTV8lQflpqg%3D%3D.RQFldSfj13p2AWDJR579ZvZA%2BJ1hs4l3AfeRefyJD3E%3D" rel="nofollow" target="_blank">https://kubesphere.io</a>）是在 Kubernetes 之上构建的容器平台，提供全栈的 IT 自动化运维的能力，简化企业的 DevOps 工作流。</p><p>KubeSphere 已被 Aqara 智能家居、本来生活、东方通信、微宏科技、东软、新浪、三一重工、华夏银行、四川航空、国药集团、微众银行、紫金保险、去哪儿网、中通、中国人民银行、中国银行、中国人保寿险、中国太平保险、中国移动、中国联通、中国电信、天翼云、中移金科、Radore、ZaloPay 等海内外数万家企业采用。KubeSphere 提供了开发者友好的向导式操作界面和丰富的企业级功能，包括 Kubernetes 多云与多集群管理、DevOps (CI/CD)、应用生命周期管理、边缘计算、微服务治理 (Service Mesh)、多租户管理、可观测性、存储与网络管理、GPU support 等功能，帮助企业快速构建一个强大和功能丰富的容器云平台。</p>]]></description></item><item>    <title><![CDATA[PostgreSQL 性能：云端与本地的延迟分析 IvorySQL ]]></title>    <link>https://segmentfault.com/a/1190000047554163</link>    <guid>https://segmentfault.com/a/1190000047554163</guid>    <pubDate>2026-01-20 18:05:42</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>PostgreSQL 在各行各业的关键应用中具有极高适用性。尽管 PostgreSQL 提供了良好的性能，但仍存在一些用户不太关注但对整体效率与速度至关重要的问题。多数人认为增加 CPU 核数、更快的存储、更大内存即可提升性能，但还有同样重要的因素需要关注——那就是延迟。</p><h2>延迟意味着什么？</h2><p>数据库执行查询操作的耗时，仅占应用程序接收查询结果总耗时的极小部分。下图可直观呈现该过程的内在逻辑：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047554165" alt="1.png" title="1.png"/></p><p>客户端应用发送请求后，驱动程序通过网络向 PostgreSQL 发送消息（a），数据库执行查询（b），并将结果集返回给应用程序（c）。关键问题在于：相较于查询执行时间（b），网络传输时间（a 与 c）是否具有显著影响。通过实验可以加以验证。</p><p>首先，使用 pgbench 初始化一个简单的测试数据库。对于本次测试，小规模数据库已足够：</p><pre><code>cybertec$ pgbench -i blog
dropping old tables...
NOTICE:  table "pgbench_accounts" does not exist, skipping
NOTICE:  table "pgbench_branches" does not exist, skipping
NOTICE:  table "pgbench_history" does not exist, skipping
NOTICE:  table "pgbench_tellers" does not exist, skipping
creating tables...
generating data (client-side)...
vacuuming...
creating primary keys...
done in 0.19 s (drop tables 0.00 s, create tables 0.02 s, client-side generate 0.13 s, vacuum 0.02 s, primary keys 0.02 s).</code></pre><p>随后进行第一次基础测试：建立单个 UNIX Socket 连接，运行 20 秒（只读测试）：</p><pre><code>cybertec$ pgbench -c 1 -T 20 -S blog
pgbench (17.5)
starting vacuum...end.
transaction type: &lt;builtin: select only&gt;
scaling factor: 1
query mode: simple
number of clients: 1
number of threads: 1
maximum number of tries: 1
duration: 20 s
number of transactions actually processed: 1035095
number of failed transactions: 0 (0.000%)
latency average = 0.019 ms
initial connection time = 2.777 ms
tps = 51751.287839 (without initial connection time)</code></pre><p>关键指标如下：</p><ul><li>平均延迟：0.019 毫秒</li><li>每秒事务处理量（TPS）：51751</li></ul><p>该数据表现对于单连接场景而言已属良好水平。</p><p>下一步执行相同查询测试，但将连接方式从 UNIX 套接字更换为指向本地主机（localhost）的 TCP 连接（非远程连接）：</p><pre><code>cybertec$ pgbench -c 1 -T 20 -S blog -h localhost
pgbench (17.5)
starting vacuum...end.
transaction type: &lt;builtin: select only&gt;
scaling factor: 1
query mode: simple
number of clients: 1
number of threads: 1
maximum number of tries: 1
duration: 20 s
number of transactions actually processed: 583505
number of failed transactions: 0 (0.000%)
latency average = 0.034 ms
initial connection time = 3.290 ms
tps = 29173.916752 (without initial connection time)</code></pre><p>结果出现明显变化，关键指标如下：</p><ul><li>平均延迟：0.034 毫秒</li><li>每秒事务数（TPS）：29173</li></ul><p>吞吐量下降约 44%。下图对此进行了直观展示：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047554166" alt="2.png" title="2.png" loading="lazy"/></p><p>值得注意的是，延迟仅从 0.019 毫秒上升至 0.034 毫秒，变化幅度极小。但由于查询本身执行速度极快，即便如此微小的延迟也会带来显著影响。执行计划可以说明这一点：</p><pre><code>blog=# explain analyze SELECT *
      FROM   pgbench_accounts
WHERE  aid = 434232;
                         QUERY PLAN
------------------------------------------------------------
 Index Scan using pgbench_accounts_pkey on pgbench_accounts
   (cost=0.29..8.31 rows=1 width=97)
   (actual time=0.015..0.016 rows=0 l                                                                                                                  oops=1)
   Index Cond: (aid = 434232)
 Planning Time: 0.227 ms
 Execution Time: 0.047 ms
(4 rows)</code></pre><p>执行计划中的关键数值为 0.016，表示索引扫描在表中定位记录所需的时间。将该数值与额外引入的网络延迟进行对比，即可理解微小变化为何会造成巨大差异。</p><h2>真实网络环境中的延迟</h2><p>在实际场景中，应用程序与数据库通常部署在不同的机器上。测试前，先查看 traceroute 的输出结果：</p><pre><code>different_box$ traceroute 10.1.139.53
traceroute to 10.1.139.53 (10.1.139.53), 30 hops max, 60 byte packets
 1  _gateway (10.0.0.1)  0.212 ms  0.355 ms  0.378 ms
 2  cybertec (10.1.139.53)  0.630 ms  0.619 ms *</code></pre><p>可以看到，从运行 pgbench 的主机到数据库服务器的路径较短，仅通过内部网络完成通信。</p><p>再次运行相同测试，结果如下：</p><pre><code>different_box$ pgbench -h 10.1.139.53 -S -c 1 -T 20 blog
pgbench (17.5)
starting vacuum...end.
transaction type: &lt;builtin: select only&gt;
scaling factor: 1
query mode: simple
number of clients: 1
number of threads: 1
maximum number of tries: 1
duration: 20 s
number of transactions actually processed: 47540
number of failed transactions: 0 (0.000%)
latency average = 0.420 ms
initial connection time = 9.727 ms
tps = 2378.123901 (without initial connection time)</code></pre><p>关键指标为：</p><ul><li>平均延迟：0.420 毫秒</li><li>每秒事务数（TPS）：2378</li></ul><p>即便延迟仅为 0.420 毫秒，吞吐量已从 5 万 TPS 降至 2378 TPS。虽然该测试仍为单连接，但原因十分清晰：网络传输所消耗的 0.4 毫秒，与索引读取所需的 0.016 毫秒相比，已是数量级上的差距。</p><p>下图展示了吞吐量变化情况：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047554168" alt="3.png" title="3.png" loading="lazy"/></p><p>可确定的是，若网络架构中增加更多网络层级，吞吐量数据将进一步显著下降。该问题在云计算环境中尤为突出，每一层负载均衡、每一次网络跳转、每一台路由设备、每一条防火墙规则，均会增加网络延迟，进而降低应用程序运行效率。对于执行耗时极短的查询操作而言，网络延迟产生的额外开销占比越高，查询操作本身的执行耗时占比则越低，其对整体性能的影响程度也随之下降。</p><h2>并发机制：可行的解决方案？</h2><p>上述实验展示了极端情况，适用于单一应用在应用与数据库间频繁交互的场景。而在负载较高的业务系统中，通常存在多用户并发访问的情况。若增加并发连接数，系统性能可呈现较为理想的表现：</p><pre><code>cybertec$ pgbench -c 4 -j 4 -T 20 -S blog -h localhost
pgbench (17.5)
starting vacuum...end.
transaction type: &lt;builtin: select only&gt;
scaling factor: 1
query mode: simple
number of clients: 4
number of threads: 4
maximum number of tries: 1
duration: 20 s
number of transactions actually processed: 1639827
number of failed transactions: 0 (0.000%)
latency average = 0.049 ms
initial connection time = 5.637 ms
tps = 82007.653121 (without initial connection time)</code></pre><p>提取关键数据如下：</p><ul><li>平均延迟：0.429 毫秒</li><li>每秒事务数（TPS）：82007</li></ul><p>使用 4 个并发连接，TPS 达到 82,000，增加更多并发可进一步提升。在现代服务器上，每秒超过 100 万次操作完全可行。但前提是数据库与查询来源距离接近，网络延迟不构成瓶颈。</p><h2>更快的 CPU 是否有帮助？</h2><p>常见疑问：增加 CPU 核数或提升单核性能是否有意义？对比如下：</p><ul><li>索引查找：0.016 毫秒</li><li>网络延迟：0.490 毫秒</li></ul><p>即便 CPU 更快，优化的仅为 0.016 毫秒，占总耗时约 3%，剩余 97% 时间不受影响。本质上，这与吞吐量关系不大，而是延迟问题。对于极短查询，延迟累积可能导致严重性能下降，尤其在云环境下网络复杂度更高。</p><p>对于执行时间较长的查询，延迟影响较小；但对于超快小查询，网络延迟可能成为主要性能瓶颈。</p><h2>总结</h2><p>延迟在高频、短时查询场景中具有决定性影响。单连接环境下，微小的网络延迟即可导致吞吐量大幅下降；通过并发可以在一定程度上缓解这一问题，但网络距离和拓扑结构仍是关键约束因素。相比之下，单纯提升 CPU 性能对以网络延迟为主导的场景改善有限。在云环境与分布式架构中，延迟问题需要在系统设计阶段予以重点关注。</p><p>原文链接：</p><p><a href="https://link.segmentfault.com/?enc=3mTedDWWdYfk%2B1HxIgkAbw%3D%3D.ZYAEIAvaI6guu9PyHjQFjMdhclj3UogjOlYLwEvaNyDLJy5sr3Js%2FLMzSndw%2FZ7jUkxWGo8m3un2H9Ut4D92WQ0Ex%2BkTZYbomcpSxqTj%2F%2FSIJrdD5sl38bQnEw%2F%2BFcSqIWEwsAs3fFKaUQcMXEFY7Q%3D%3D" rel="nofollow" target="_blank">https://www.cybertec-postgresql.com/en/postgresql-performance...</a></p><p>作者：Hans-Jürgen Schönig</p><hr/><h2><a href="https://link.segmentfault.com/?enc=sUOWpyO%2FXv1IifoGC5CXIw%3D%3D.GpyAvieAyctwrHtaISry2vfAv3fKvHza5iQajPJS0iI%3D" rel="nofollow" target="_blank">HOW 2026 议题招募中</a></h2><p>2026 年 4 月 27-28 日，由 IvorySQL 社区联合 PGEU（欧洲 PG 社区）、PGAsia（亚洲 PG 社区）共同打造的 HOW 2026（IvorySQL &amp; PostgreSQL 技术峰会） 将再度落地济南。届时，PostgreSQL 联合创始人 Bruce Momjian 等顶级大师将亲临现场。</p><p>自开启征集以来，HOW 2026 筹备组已感受到来自全球 PostgreSQL 爱好者的澎湃热情。为了确保大会议题的深度与广度，我们诚邀您在 2026 年 2 月 27 日截止日期前，提交您的技术见解。</p><p>投递链接：<a href="https://link.segmentfault.com/?enc=i1PwcpH5ZMGeNV1jxM3crg%3D%3D.nDXW%2FqPDgxa4RognCS6CNpu0f8O%2F%2B2zndxidM5D%2BlK8%3D" rel="nofollow" target="_blank">https://jsj.top/f/uebqBc</a></p>]]></description></item><item>    <title><![CDATA[9款主流CRM选型指南：客户与销售管理系统深度解析 率性的开水瓶 ]]></title>    <link>https://segmentfault.com/a/1190000047554175</link>    <guid>https://segmentfault.com/a/1190000047554175</guid>    <pubDate>2026-01-20 18:04:48</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在数字化转型背景下，企业对CRM的需求已从“销售工具”升级为“全链路业务操作系统”——既要覆盖客户从获客到复购的全生命周期（CLM），也要通过自动化降低销售成本（SFA），更要实现销售、财务、采购、仓储等角色的无缝配合。本文选取<strong>超兔一体云、Odoo、YetiForce、纷享销客、简道云、销帮帮、八百客、Free CRM、Streak</strong>九大主流CRM系统，从<strong>客户</strong> <strong>全生命周期管理</strong> <strong>（CLM）、</strong> <strong>销售自动化</strong> <strong>（SFA）、多角色无缝配合</strong>三大核心维度展开深度对比，结合功能拆解、流程可视化与量化评分，为企业选型提供参考。</p><h2>一、对比框架说明</h2><p>本次对比围绕企业最核心的三个需求维度，拆解为<strong>12个二级指标、36个三级指标</strong>（见表1），覆盖从线索到复购的全流程、从人工到智能的自动化、从部门到供应链的协同。</p><h3>表1 核心对比指标框架</h3><table><thead><tr><th><strong>一级维度</strong></th><th><strong>二级指标</strong></th><th><strong>三级指标示例</strong></th></tr></thead><tbody><tr><td>客户全生命周期管理（CLM）</td><td>获客阶段、跟进培育阶段、签约交付阶段、售后复购阶段</td><td>获客渠道覆盖、线索质量管控、跟单模型丰富度、订单类型适配、复购分析工具</td></tr><tr><td>销售自动化（SFA）</td><td>线索自动化、跟单自动化、订单自动化、AI辅助</td><td>线索一键处理、自动跟进提醒、订单触发采购、AI话术生成、自动日报</td></tr><tr><td>多角色无缝配合</td><td>数据底层连通性、流程协同自动化、权限管理精准度、供应链上下游协同</td><td>全模块数据共享、订单-采购-财务自动流转、角色适配权限、上下游对账自动化</td></tr></tbody></table><h2>二、客户全生命周期管理（CLM）：从获客到复购的全链路能力对比</h2><p>客户全生命周期管理的核心是“精准触达+个性化运营+闭环转化”，需覆盖“获客-跟进-签约-售后”四大阶段。以下是各系统的能力拆解：</p><h3>1. 获客阶段：渠道覆盖与线索质量管控</h3><p>获客是CLM的起点，关键指标是<strong>渠道多样性</strong>与<strong>线索质量过滤能力</strong>。</p><table><thead><tr><th>系统</th><th>获客渠道覆盖</th><th>线索质量管控</th><th>特色功能</th></tr></thead><tbody><tr><td>超兔一体云</td><td>百度/抖音/官网/微信/小程序/地推/工商搜客（8+渠道）</td><td>手机号验证码验证、IP归属地识别、市场活动成本均摊</td><td>多渠道线索一键转化（新客户/待办/订单）</td></tr><tr><td>Odoo</td><td>400电话/社交媒体/官网表单/线下活动（4+渠道）</td><td>潜在客户评分（行为+信息）</td><td>线索自动分配至销售公海池</td></tr><tr><td>YetiForce</td><td>官网/社交媒体/线下活动（3+渠道）</td><td>无明确质量管控</td><td>适配制造企业的“订单-生产”前置线索关联</td></tr><tr><td>纷享销客</td><td>企业微信/官网/线下活动（3+渠道）</td><td>线索清洗（重复数据合并）</td><td>360°客户视图关联线索来源</td></tr><tr><td>Free CRM</td><td>官网/邮件（2渠道）</td><td>无质量管控</td><td>轻量化线索录入</td></tr><tr><td>Streak</td><td>Gmail邮件（1渠道）</td><td>邮件行为追踪（打开/点击）</td><td>Gmail内直接管理线索</td></tr></tbody></table><h3>2. 跟进培育阶段：个性化运营与跟单效率</h3><p>跟进培育的核心是“识别客户需求+匹配销售动作” <strong>，关键指标是</strong>跟单模型丰富度<strong>与</strong>客户视图完整性。</p><h4>（1）跟单模型对比</h4><table><thead><tr><th>系统</th><th>跟单模型类型</th><th>客户视图能力</th><th>特色功能</th></tr></thead><tbody><tr><td>超兔一体云</td><td>五大模型（客户/商机/项目/组织/配置单）</td><td>全景时间线+多级分类汇总</td><td>“三一客”节点（定性+定级+定量）</td></tr><tr><td>Odoo</td><td>销售漏斗+自定义商机阶段</td><td>关联客户行为/采购历史</td><td>商机阶段自动推进（如“方案演示”→“价格谈判”）</td></tr><tr><td>YetiForce</td><td>销售漏斗+客户分级</td><td>关联订单/生产记录</td><td>制造企业“订单-生产”链路跟单</td></tr><tr><td>纷享销客</td><td>销售流程自定义</td><td>360°视图（线索+订单+售后）</td><td>销售行为轨迹追踪（拜访/邮件/电话）</td></tr><tr><td>简道云</td><td>无代码流程设计</td><td>自定义字段关联（线索+客户+订单）</td><td>拖拽式流程配置（如“线索→客户→订单”）</td></tr></tbody></table><h4>（2）超兔一体云CLM全流程流程图（Mermaid）</h4><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047554177" alt="" title=""/></p><pre><code>flowchart LR
    A[多渠道获客] --&gt; B[线索质量管控&lt;br&gt;（手机号验证+IP归属地）]
    B --&gt; C[“三一客”节点管理&lt;br&gt;（定性+定级+定量）]
    C --&gt; D[五大跟单模型&lt;br&gt;（客户/商机/项目等）]
    D --&gt; E[订单生成&lt;br&gt;（服务/实物/特殊型）]
    E --&gt; F[售后复购&lt;br&gt;（RFM分析+维修工单）]</code></pre><h3>3. 签约交付阶段：订单适配与执行效率</h3><p>签约交付的核心是“适配复杂业务场景”<strong>与</strong>“订单全链路可见” <strong>，关键指标是</strong>订单类型覆盖<strong>与</strong>执行流程自动化。</p><table><thead><tr><th>系统</th><th>订单类型适配</th><th>订单执行自动化</th><th>特色功能</th></tr></thead><tbody><tr><td>超兔一体云</td><td>服务型/实物型（标准/批发/定制）/特殊型（维修/外勤）</td><td>订单锁库、自动生成采购计划、财务应收联动</td><td>多渠道订单统一管理（电商/实体店/官网）</td></tr><tr><td>Odoo</td><td>标准订单/服务订单/租赁订单</td><td>订单触发采购、库存更新同步财务</td><td>“一物一码”资产跟踪（移动端扫码）</td></tr><tr><td>YetiForce</td><td>制造订单（订单-生产-发货）</td><td>库存不足自动触发采购提醒</td><td>适配“MTO（按订单生产）”模式</td></tr><tr><td>纷享销客</td><td>销售订单/服务订单</td><td>订单关联ERP系统（应收/应付）</td><td>订单进度可视化（客户可查）</td></tr><tr><td>简道云</td><td>自定义订单类型</td><td>无代码订单流程配置（如“审核→发货”）</td><td>订单数据联动仪表盘</td></tr></tbody></table><h3>4. 售后复购阶段： retention与复购挖掘</h3><p>售后复购的核心是“识别高价值客户+降低流失” <strong>，关键指标是</strong>复购分析工具<strong>与</strong>售后响应效率。</p><table><thead><tr><th>系统</th><th>复购分析工具</th><th>售后响应能力</th><th>特色功能</th></tr></thead><tbody><tr><td>超兔一体云</td><td>RFM分析（客户分层）、复购流失预警</td><td>维修工单（到店）/外勤工单（上门）</td><td>客户分层推送复购任务</td></tr><tr><td>Odoo</td><td>客户采购历史分析</td><td>工单自动路由（高优先级→认证工程师）</td><td>“SLA服务级别”提醒（如2小时响应）</td></tr><tr><td>YetiForce</td><td>客户采购频率分析</td><td>售后工单关联库存备件</td><td>制造企业“设备维护”复购提醒</td></tr><tr><td>纷享销客</td><td>客户价值评分</td><td>多渠道客服（企业微信/电话/官网）</td><td>售后数据联动销售（复购线索推送）</td></tr><tr><td>Free CRM</td><td>无明确分析工具</td><td>基础客服工单</td><td>轻量化售后记录</td></tr></tbody></table><h3>5. CLM能力量化评分（1-5分，5分为优）</h3><table><thead><tr><th>系统</th><th>获客阶段</th><th>跟进培育</th><th>签约交付</th><th>售后复购</th><th>综合得分</th></tr></thead><tbody><tr><td>超兔一体云</td><td>5</td><td>5</td><td>5</td><td>5</td><td>5</td></tr><tr><td>Odoo</td><td>4</td><td>4</td><td>4</td><td>4</td><td>4</td></tr><tr><td>YetiForce</td><td>3</td><td>4</td><td>5</td><td>4</td><td>4</td></tr><tr><td>纷享销客</td><td>4</td><td>4</td><td>3</td><td>4</td><td>4</td></tr><tr><td>简道云</td><td>3</td><td>4</td><td>3</td><td>3</td><td>3</td></tr><tr><td>销帮帮</td><td>4</td><td>4</td><td>3</td><td>4</td><td>4</td></tr><tr><td>八百客</td><td>3</td><td>3</td><td>3</td><td>3</td><td>3</td></tr><tr><td>Free CRM</td><td>2</td><td>2</td><td>2</td><td>2</td><td>2</td></tr><tr><td>Streak</td><td>2</td><td>3</td><td>2</td><td>2</td><td>2</td></tr></tbody></table><h2>三、销售自动化（SFA）：从人工到智能的效率跃迁</h2><p>销售自动化的核心是“用系统替代重复劳动”，需覆盖“线索-跟单-订单-AI”四大环节。</p><h3>1. 线索自动化：从获取到分配的无人干预</h3><p>线索自动化的关键是“减少人工录入”<strong>与</strong>“精准分配”。</p><table><thead><tr><th>系统</th><th>线索自动化能力</th><th>特色功能</th></tr></thead><tbody><tr><td>超兔一体云</td><td>线索一键转化（新客户/待办/订单）、归属地自动识别、分配后自动提醒</td><td>市场活动成本自动均摊至线索</td></tr><tr><td>Odoo</td><td>潜在客户评分（自动标记“高价值线索”）、公海池自动分配</td><td>线索行为追踪（如官网访问→自动评分）</td></tr><tr><td>YetiForce</td><td>无明确线索自动化</td><td>制造企业“线索-订单-生产”关联</td></tr><tr><td>纷享销客</td><td>线索自动分配至销售（按区域/行业）</td><td>线索清洗（重复数据合并）</td></tr><tr><td>Streak</td><td>邮件线索自动导入Gmail、批量发送邮件模板</td><td>Gmail内直接回复线索</td></tr></tbody></table><h3>2. 跟单自动化：从跟进到复盘的智能辅助</h3><p>跟单自动化的核心是“提醒关键动作+自动复盘”。</p><table><thead><tr><th>系统</th><th>跟单自动化能力</th><th>特色功能</th></tr></thead><tbody><tr><td>超兔一体云</td><td>自动生成日报（客户+行动+待办）、电话录音AI分析（识别客户意向）</td><td>跟单时间线自动归档（沟通记录/拜访记录）</td></tr><tr><td>Odoo</td><td>任务自动提醒（如“方案演示”前1天提醒）、销售漏斗自动推进</td><td>自动化规则引擎（如“高意向线索→优先跟进”）</td></tr><tr><td>YetiForce</td><td>客户采购频率自动提醒跟进</td><td>制造企业“订单-生产”进度自动同步</td></tr><tr><td>简道云</td><td>无代码跟进提醒配置（如“3天未跟进→提醒”）</td><td>跟进数据联动仪表盘（可视化进度）</td></tr><tr><td>销帮帮</td><td>销售流程自动跟踪（从线索到现金）</td><td>销售简报自动生成（业绩/转化率）</td></tr></tbody></table><h3>3. 订单自动化：从生成到执行的全链路自动</h3><p>订单自动化的关键是“减少跨部门沟通”<strong>与</strong>“避免人为错误”。</p><table><thead><tr><th>系统</th><th>订单自动化能力</th><th>特色功能</th></tr></thead><tbody><tr><td>超兔一体云</td><td>订单生成采购计划、订单锁库、应收自动计算（多期拆分）</td><td>多仓库订单自动分配（根据库存）</td></tr><tr><td>Odoo</td><td>订单触发采购（库存不足→自动生成采购单）、库存同步财务</td><td>“一物一码”扫码发货（自动更新库存）</td></tr><tr><td>YetiForce</td><td>订单-生产-库存自动联动（库存不足→采购提醒）</td><td>制造企业“MTO”订单自动排产</td></tr><tr><td>纷享销客</td><td>订单关联ERP（应收/应付自动同步）</td><td>订单进度客户可见（减少咨询）</td></tr><tr><td>八百客</td><td>订单生成后自动提醒销售跟进</td><td>基础订单流程自动化（审核→发货）</td></tr></tbody></table><h3>4. AI辅助：从经验到数据的智能决策</h3><p>AI辅助是SFA的高阶能力，关键是“替代经验判断”<strong>与</strong>“预测性建议”。</p><table><thead><tr><th>系统</th><th>AI辅助能力</th><th>特色功能</th></tr></thead><tbody><tr><td>超兔一体云</td><td>AI定制行业销售SOP、AI待办（根据行动记录生成）、AI日报</td><td>电话录音AI识别客户意向（如“价格敏感”）</td></tr><tr><td>Odoo</td><td>自动化规则引擎（如“高优先级工单→自动分配”）</td><td>无明确AI生成功能</td></tr><tr><td>简道云</td><td>智能数据分析（客户转化率/业绩曲线）</td><td>无代码AI模型配置（如“复购预测”）</td></tr><tr><td>销帮帮</td><td>销售预测（根据历史数据）</td><td>销售话术库自动推荐</td></tr></tbody></table><h3>5. SFA能力量化评分（1-5分）</h3><table><thead><tr><th>系统</th><th>线索自动化</th><th>跟单自动化</th><th>订单自动化</th><th>AI辅助</th><th>综合得分</th></tr></thead><tbody><tr><td>超兔一体云</td><td>5</td><td>5</td><td>5</td><td>5</td><td>5</td></tr><tr><td>Odoo</td><td>4</td><td>4</td><td>4</td><td>3</td><td>4</td></tr><tr><td>YetiForce</td><td>2</td><td>3</td><td>5</td><td>2</td><td>3</td></tr><tr><td>纷享销客</td><td>4</td><td>4</td><td>3</td><td>3</td><td>4</td></tr><tr><td>简道云</td><td>3</td><td>4</td><td>3</td><td>4</td><td>3</td></tr><tr><td>销帮帮</td><td>4</td><td>4</td><td>3</td><td>4</td><td>4</td></tr><tr><td>八百客</td><td>3</td><td>3</td><td>3</td><td>2</td><td>3</td></tr><tr><td>Free CRM</td><td>2</td><td>2</td><td>2</td><td>1</td><td>2</td></tr><tr><td>Streak</td><td>3</td><td>3</td><td>2</td><td>1</td><td>2</td></tr></tbody></table><h2>四、多角色无缝配合：从部门到供应链的协同能力</h2><p>多角色配合的核心是“数据共享 + 流程联动”，需解决“信息孤岛”与“跨部门推诿”问题。</p><h3>1. 数据底层连通性：全模块数据共享</h3><p>数据连通是协同的基础，关键是“是否基于同一数据库”<strong>或</strong>“是否实现 API 深度集成”。</p><table><thead><tr><th>系统</th><th>数据连通能力</th><th>覆盖模块</th></tr></thead><tbody><tr><td>超兔一体云</td><td>全模块底层连通（CRM/进销存/供应链/财务/生产）</td><td>销售、财务、采购、仓储、生产、售后</td></tr><tr><td>Odoo</td><td>模块化无缝连接（各模块基于同一框架）</td><td>销售、财务、采购、库存、项目管理</td></tr><tr><td>YetiForce</td><td>供应链深度连通（订单 - 生产 - 库存）</td><td>销售、生产、采购、库存</td></tr><tr><td>纷享销客</td><td>多系统 API 集成（ERP/企业微信/钉钉）</td><td>销售、财务、客服</td></tr><tr><td>简道云</td><td>跨应用数据联动（CRM/表单/仪表盘）</td><td>销售、财务、运营</td></tr></tbody></table><h3>2. 流程协同自动化：订单全链路流转</h3><p>流程协同的关键是“跨部门流程自动触发”，以下是超兔一体云的“订单 - 采购 - 财务”协同流程（Mermaid 时序图）：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047554178" alt="" title="" loading="lazy"/></p><pre><code>sequenceDiagram
    participant 销售 as 销售部
    participant 系统 as 超兔一体云
    participant 采购 as 采购部
    participant 财务 as 财务部
    participant 仓储 as 仓储部

    销售-&gt;&gt;系统: 生成销售订单（含产品/数量）
    系统-&gt;&gt;采购: 自动生成采购计划（库存不足时）
    采购-&gt;&gt;系统: 确认采购单（关联销售订单）
    系统-&gt;&gt;仓储: 采购入库（自动更新库存）
    系统-&gt;&gt;财务: 自动计算应收（按订单金额/账期）
    仓储-&gt;&gt;系统: 按订单发货（关联库存）
    财务-&gt;&gt;系统: 回款确认（自动核销应收）</code></pre><h3>3. 权限管理精准度：角色适配与数据安全</h3><p>权限管理的核心是“最小权限原则”，需适配不同角色的职责。</p><table><thead><tr><th>系统</th><th>权限管理能力</th><th>特色功能</th></tr></thead><tbody><tr><td>超兔一体云</td><td>全局自动权限（上级管下级、同级隔离、助理跟随主管）</td><td>老板全局视图、岗位特殊权限（如客服无财务权限）</td></tr><tr><td>Odoo</td><td>支持灵活的权限配置，可根据不同角色设置不同的操作权限</td><td>可对不同模块的数据进行细致的权限控制</td></tr><tr><td>YetiForce</td><td>基于 Vtiger foundation 的权限体系，适配不同业务流程的角色</td><td>对供应链相关角色有针对性的权限设置</td></tr><tr><td>纷享销客</td><td>提供强大的定制化权限管理，满足中大型企业复杂的组织架构需求</td><td>可对销售流程、数据访问等进行个性化权限定制</td></tr><tr><td>简道云</td><td>零代码平台支持灵活的权限设置，多角色可根据需求配置不同权限</td><td>方便快速调整权限以适应业务变化</td></tr></tbody></table><h3>4. 供应链上下游协同</h3><p>供应链协同是企业提升整体效率和竞争力的关键，能够实现企业与供应商和客户之间的全流程协同。</p><table><thead><tr><th>系统</th><th>供应链上下游协同能力</th><th>特色功能</th></tr></thead><tbody><tr><td>超兔一体云</td><td>通过 OpenCRM 的体系结构，实现上下游全流程协同，包括询价比价、采购单生成、发货验收、对账等</td><td>支持与上下游企业的深度业务交互</td></tr><tr><td>Odoo</td><td>支持采购、销售与库存的协同管理，可实现供应链的优化和成本控制</td><td>提供供应链数据分析功能</td></tr><tr><td>YetiForce</td><td>打通订单、生产、库存环节，库存不足时自动触发采购提醒，实现供应链的高效运作</td><td>适配制造/贸易企业的供应链管理需求</td></tr><tr><td>纷享销客</td><td>支持与供应商、客户的业务协同，可实现订单、报价等信息的实时共享</td><td>提供供应链协同的可视化管理界面</td></tr><tr><td>简道云</td><td>可通过数据联动实现供应链各环节的协同，支持自定义业务流程</td><td>方便企业根据自身需求构建供应链协同流程</td></tr></tbody></table><h3>多角色无缝配合能力量化评分（1 - 5 分）</h3><table><thead><tr><th>系统</th><th>数据底层连通性</th><th>流程协同自动化</th><th>权限管理精准度</th><th>供应链上下游协同</th><th>综合得分</th></tr></thead><tbody><tr><td>超兔一体云</td><td>5</td><td>5</td><td>5</td><td>5</td><td>5</td></tr><tr><td>Odoo</td><td>4</td><td>4</td><td>4</td><td>4</td><td>4</td></tr><tr><td>YetiForce</td><td>4</td><td>4</td><td>4</td><td>4</td><td>4</td></tr><tr><td>纷享销客</td><td>3</td><td>3</td><td>4</td><td>3</td><td>3</td></tr><tr><td>简道云</td><td>3</td><td>3</td><td>3</td><td>3</td><td>3</td></tr><tr><td>销帮帮</td><td>2</td><td>2</td><td>2</td><td>2</td><td>2</td></tr><tr><td>八百客</td><td>2</td><td>2</td><td>2</td><td>2</td><td>2</td></tr><tr><td>Free CRM</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td></tr><tr><td>Streak</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td></tr></tbody></table><h2>五、总结与企业选型建议</h2><h3>总结</h3><p>本次对比围绕客户全生命周期管理（CLM）、销售自动化（SFA）、多角色无缝配合三大核心维度，对超兔一体云、Odoo、YetiForce、纷享销客、简道云、销帮帮、八百客、Free CRM、Streak 九大主流 CRM 系统进行了深度剖析。从各项量化评分来看，不同系统在不同维度表现各有优劣。</p><p>超兔一体云在三个核心维度的综合表现最为出色，在客户全生命周期管理的各个阶段、销售自动化的各个环节以及多角色无缝配合方面均获得高分，展现了全面且强大的功能，为企业提供了一站式的数字化解决方案。</p><p>Odoo 和 YetiForce 也具备较强的综合实力，在多个方面表现良好。Odoo 的模块化架构和一体化协同能力较为突出；YetiForce 在供应链协同和制造企业场景适配方面有独特优势。</p><p>纷享销客、简道云、销帮帮、八百客等系统也能满足企业的部分需求，具有一定的特色功能和适用场景。而 Free CRM 和 Streak 由于功能局限性，在综合评分上相对较低。</p><h3>企业选型建议</h3><p>企业在选择 CRM 系统时，应根据自身的规模、行业特点、业务需求和发展战略等因素进行综合考虑。</p><ul><li><strong>大型企业</strong>：如果企业规模较大，业务复杂，需要全面的客户管理、高效的销售自动化以及深度的多角色协同，超兔一体云是一个不错的选择，其全模块底层连通和强大的功能体系能够满足大型企业的复杂管理需求。同时，纷享销客的强大定制化能力也能适配中大型企业的具体管理要求。</li><li><strong>制造/贸易企业</strong>：YetiForce 在供应链协同和制造企业场景适配方面表现出色，其“订单 - 生产 - 库存”的深度连通和“MTO”订单自动排产等功能，能有效提升制造/贸易企业的运营效率。Odoo 的模块化架构和对生产计划、销售预测与财务集成的支持，也适合此类企业。</li><li><strong>依赖邮件沟通的团队</strong>：Streak 深度嵌入 Gmail 邮件场景，对于依赖邮件沟通的团队（如外贸、B2B），可实现轻量化客户管理。</li><li><strong>追求轻量化和快速上手的中小企业</strong>：Free CRM 界面简洁、操作门槛低，适合中小企业快速上手，提升单一销售场景的效率。简道云的零代码平台支持快速搭建和定制，能满足中小企业灵活性的需求。</li></ul><p>总之，企业在选型时应充分评估各系统的优缺点，结合自身实际情况做出合理选择，以实现数字化转型，提升企业的盈利水平和竞争能力。</p><p>（注：文中功能相关描述均基于公开披露信息，具体功能服务与价格以厂商实际落地版本为准。）</p>]]></description></item><item>    <title><![CDATA[《异步编程必修课：asyncio API稳定性观察手册》 程序员阿伟 ]]></title>    <link>https://segmentfault.com/a/1190000047554187</link>    <guid>https://segmentfault.com/a/1190000047554187</guid>    <pubDate>2026-01-20 18:04:05</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>异步编程的核心矛盾，往往藏在API稳定性与演进张力的隐秘平衡中。多数开发者初次接触asyncio时，容易陷入对表面语法的迷恋，却忽视了其底层接口设计的深层逻辑—那些看似固定的调用方式背后，是一套动态调整的隐性契约。在长期的异步架构打磨中，逐渐发现asyncio的API稳定性并非静态固化，而是通过分层设计实现弹性兼容，核心接口的语义一致性被刻意保留，而扩展功能则以渐进式方式融入，这种演进策略既避免了破坏性更新带来的重构成本，又为新技术场景预留了生长空间。比如在协程调度的实践中，从Python 3.7到3.11的多个版本迭代中，用于创建和运行协程的核心接口始终保持着稳定的调用逻辑，即便底层调度器进行了多次性能优化，开发者无需修改一行代码，就能让旧项目享受到新版本的性能提升。而新增的调度增强功能，如任务优先级调整、协程组批量管理等，则以附加方法或可选参数的形式出现，既满足了复杂场景的需求，又不会对既有代码造成干扰。这种“核心不变、边缘迭代”的思路，正是asyncio能够在快速发展的异步编程领域保持生态稳定的关键，也让众多基于该库构建的项目得以平稳跨越版本周期，无需陷入无休止的重构泥潭。在实际开发中，曾多次经历Python版本的重大更新，从3.8的异步上下文管理器优化到3.10的任务组接口引入，核心业务代码始终未受影响，仅需根据新特性的优势，选择性地在新模块中引入扩展功能，这种平滑过渡的体验，让开发者能够更专注于业务创新，而非被技术迭代裹挟。</p><p>理解asyncio API的稳定性，需要穿透接口名称的表象，触及其设计的本质诉求。在异步编程的学习过程中，曾多次遇到不同Python版本间接口行为的细微差异，起初误以为是设计疏漏，深入探究后才发现，这些差异实则是对真实场景的精准适配。asyncio的维护者在演进过程中，始终以“场景驱动”为核心原则，当新的异步需求出现时，并非简单新增接口，而是先评估现有接口的适配潜力，尽可能通过扩展参数或优化内部实现来满足需求，只有当现有接口无法覆盖核心场景时，才会谨慎引入新接口，并为旧接口提供清晰的过渡路径。这种策略在事件循环的相关接口中体现得尤为明显，不同操作系统平台的事件循环实现存在底层差异，比如Windows平台的IOCP模型与Linux平台的epoll模型在处理异步事件时的机制截然不同，但对外暴露的核心接口始终保持一致，开发者无需关注底层实现细节，只需基于统一接口进行开发。例如在处理网络连接时，无论是在Windows还是Linux环境下，创建异步套接字、注册读写事件的接口调用方式完全相同，底层会根据平台自动适配最优实现。此外，在异步IO的缓冲处理、连接池管理等场景中，也能看到这种场景驱动的设计思路，比如某个用于数据接收的接口，通过新增“缓冲阈值”参数，既支持了高并发场景下的内存优化，又没有改变原有调用逻辑，让旧项目无需修改即可兼容。维护者们往往会通过社区调研、实际项目案例分析、开发者访谈等多种方式，收集不同场景下的使用痛点，再将这些需求转化为接口的优化方向，这种源于实践、服务实践的设计理念，让asyncio的API始终保持着强大的场景适配能力。</p><p>asyncio API的演进过程，本质上是社区共识与技术创新的动态平衡。在长期跟踪其版本更新日志与社区讨论的过程中，发现每一次接口调整都经过了充分的实践验证与意见征集。维护者会优先采纳来自大规模实践场景的反馈，那些在真实异步架构中被频繁使用、且被证明稳定可靠的模式，往往会被固化为标准接口，而一些实验性的功能则会以临时接口或扩展模块的形式存在，待其在社区中经过充分验证、积累足够多的使用案例后，再逐步整合到核心库中。这种“实践先行、共识后定”的演进模式，使得asyncio的API能够始终贴合开发者的真实需求，避免了过度设计或脱离实际的问题。例如在协程任务管理相关接口的演进中，社区曾围绕任务取消的时机、状态查询的粒度、异常传播的机制等问题展开长达数月的讨论，来自网络编程、异步爬虫、微服务架构等不同领域的开发者，纷纷分享了自己在实际项目中遇到的痛点——有的开发者需要精确控制任务取消后的资源释放，有的则希望简化任务组的管理逻辑。维护者基于这些反馈，反复打磨接口设计，最终推出的任务组接口，既支持批量创建和管理任务，又提供了灵活的异常处理机制，同时保持了与原有任务接口的兼容性。而像早期的异步文件IO功能，由于场景需求尚未完全明确，且实现方式存在争议，便以 aiofiles 这样的第三方扩展模块形式存在，待技术方案成熟后，才逐步将核心能力整合到asyncio中。长期以来，通过订阅asyncio的社区邮件列表、参与GitHub上的issue讨论，深刻体会到这种社区共建的力量，每一个接口的优化都凝聚着众多开发者的实践智慧，这也让asyncio的API在保持稳定性的同时，始终充满创新活力。</p><p>判断asyncio API的稳定性，需要建立一套基于场景适配度的评估框架，而非单纯依赖版本号或官方标注。在异步编程的实践中，逐渐总结出三个核心评估维度：接口使用频率、社区讨论热度与场景覆盖广度。那些被广泛应用于各类异步场景、社区讨论中争议较少、且能够适配多种业务需求的接口，往往具备更高的稳定性，其被废弃或变更的概率极低；而那些仅适用于特定场景、使用频率较低的接口，则可能随着场景的变迁而被优化或替换。具体来看，接口使用频率可以通过GitHub上的项目引用量、技术博客中的提及次数来判断，比如用于创建事件循环的核心接口，在数百万个异步项目中被引用，其稳定性不言而喻；社区讨论热度则体现在Stack Overflow的提问量、社区issue的关闭速度上，稳定的接口往往提问量少且问题多为使用误区，而非接口本身的设计缺陷；场景覆盖广度则表现为接口能否适配从简单异步脚本到复杂分布式系统的不同需求，比如某个用于异步任务同步的接口，既能满足小型爬虫的任务协调，又能适配大型微服务的跨节点通信，其稳定性自然更有保障。同时，还需要关注接口的语义一致性，真正稳定的API不仅接口名称与参数格式保持不变，其背后的行为逻辑与异常处理机制也会保持连贯，开发者能够基于过往经验放心使用，无需担心版本升级带来的行为突变。比如在处理异步连接超时的接口中，无论版本如何更新，其超时触发的条件、异常抛出的类型始终保持一致，即便底层实现进行了优化，开发者也无需调整异常处理逻辑。曾在项目中面临两个功能相近的接口选择，通过这套评估框架发现，其中一个接口使用频率高、社区争议少、适配场景广，而另一个则仅适用于特定的异步IO场景，最终选择了前者，后续历经三次Python版本升级，该接口始终保持稳定，避免了因接口变更导致的维护成本增加，这也让这套评估框架的实用性得到了充分验证。</p><p>应对asyncio API的演进，开发者需要构建一种“弹性适配”的编程思维，在依赖稳定接口的同时，为潜在的变更预留缓冲空间。在实际开发中，可通过抽象封装的方式隔离具体接口的调用细节，将核心业务逻辑与底层API解耦，比如构建一层异步工具封装层，所有对asyncio接口的调用都通过该层完成，封装层内部定义统一的抽象接口，底层根据不同Python版本或API状态，实现对应的适配逻辑。例如在封装异步任务提交接口时，抽象层定义 submit_task 方法，底层在Python 3.10及以上版本中，使用新增的任务组接口实现，而在低版本中，则使用传统的任务创建接口兼容，业务层无需关注底层实现差异，只需调用抽象层方法即可。同时，还应养成跟踪社区动态与版本更新的习惯，提前了解接口的演进规划，比如通过阅读Python的官方PEP文档、关注asyncio的版本更新日志、参与社区讨论等方式，及时掌握哪些接口被标记为待废弃、哪些新接口即将引入，对于标记为待废弃的接口，尽早制定替代方案，避免在版本升级时陷入被动。此外，合理利用官方提供的兼容工具与过渡接口，也是应对演进的有效策略，官方在废弃旧接口时，往往会提供一段时间的过渡期，并推出兼容模块或过渡接口，帮助开发者平滑迁移。比如在某次版本更新中，某个核心的异步调度接口被标记为废弃，官方同时提供了功能兼容的过渡接口，并在文档中详细说明了迁移步骤，通过封装层的适配，仅修改了封装层内部的实现逻辑，业务代码未做任何调整，就完成了版本升级，且未影响线上业务的稳定运行。这种弹性适配的思维，不仅适用于asyncio的使用，也同样适用于其他快速演进的技术栈，通过构建抽象层、跟踪技术动态、利用兼容工具，能够帮助开发者在技术迭代的浪潮中保持架构的稳定性与可扩展性，减少因API变更带来的业务冲击。</p><p>asyncio API的稳定性与演进策略，为异步编程领域提供了一套可借鉴的设计范式，其核心在于在创新与兼容之间找到精准的平衡点。从早期的接口探索到如今的成熟稳定，asyncio的演进之路充满了社区的智慧与实践的沉淀，每一次接口的调整与优化，都体现了对异步编程本质的深刻理解—异步编程的核心价值在于提升IO密集型场景的效率，而API的设计则需要为这种价值的实现提供稳定可靠的支撑，同时兼顾技术的持续创新。对于开发者而言，深入理解这套演进策略，不仅能够更好地使用asyncio构建可靠的异步系统，还能从中汲取技术设计的灵感，在自己的项目中实现功能创新与架构稳定的和谐共存。比如在设计内部异步框架的API时，借鉴asyncio的分层演进思路，将核心功能（如任务调度、事件循环）的接口保持稳定，确保现有业务不受影响，而扩展功能（如分布式任务协调、高性能IO优化）则通过插件化或扩展模块的形式实现，既满足了业务的多样化需求，又避免了API的碎片化。在实际的框架设计中，核心的任务提交、结果获取接口始终保持不变，而新增的任务优先级控制、资源限制等功能，则以可选参数或扩展类的形式添加，让旧业务无需改造即可使用新功能，新业务则能根据需求灵活选择。</p>]]></description></item><item>    <title><![CDATA[《dataclasses与Pydantic职责边界深度剖析指南》 程序员阿伟 ]]></title>    <link>https://segmentfault.com/a/1190000047554190</link>    <guid>https://segmentfault.com/a/1190000047554190</guid>    <pubDate>2026-01-20 18:03:32</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>数据建模的深层困惑，往往不在于工具本身的用法，而在于对其职责边界的模糊认知——dataclasses与Pydantic的选择之争，本质是对“数据载体”与“数据治理”核心诉求的错位判断。在长期的开发实践中，我曾多次陷入“一刀切”的工具使用误区：早期为了追求代码简洁，用dataclasses处理所有数据场景，结果在外部接口接入时因缺乏数据校验，导致非法数据流入核心业务，引发连锁性的逻辑异常；后来又盲目迷信Pydantic的强约束能力，将其用于内部模块高频数据传递，却发现额外的校验逻辑让系统响应延迟提升了近三成，尤其在数据批量处理场景中，性能损耗更为明显。这些踩坑经历让我逐渐意识到，两者并非替代关系，而是基于数据流转场景的互补存在，其边界划分的核心在于“是否需要主动介入数据生命周期的治理行为”。真正的实践智慧，是在数据创建、流转、校验、序列化的全链路中，精准匹配工具的核心能力：dataclasses专注于数据结构的轻量描述，不附加任何多余逻辑，确保内部数据传递的高效；Pydantic聚焦于数据行为的严格治理，通过类型注解与约束规则，构建可靠的外部交互边界。比如在内部模块间的配置传递场景中，dataclasses仅需几行代码就能完成数据结构定义，无需关注校验与转换，让开发者聚焦于业务逻辑；而在接收第三方接口数据时，Pydantic能自动完成类型校验、格式清洗与默认值填充，将不符合规则的数据拦截在业务逻辑之外，避免潜在风险。这种分工明确的使用方式，既保留了架构的简洁性，又确保了数据在关键节点的可靠性，让数据建模真正服务于业务效率与系统稳定。</p><p>dataclasses的核心价值，在于以最低成本实现数据结构的规范化描述，其设计哲学是“无侵入式的结构定义”，不附加额外的数据处理逻辑，仅专注于数据的存储与基础访问。在长期的学习与实践中，我深刻体会到它作为Python标准库一员的独特优势：无需引入任何第三方依赖，就能自动生成初始化、比较、字符串表示等常用方法，极大减少了冗余代码的编写。这种轻量性使其在内部系统的数据载体场景中表现尤为突出，尤其是在模块间无复杂交互、数据格式相对固定的场景下，能以极简的方式完成数据封装。例如在一个日志处理系统中，日志的核心字段（时间戳、级别、内容、模块名）相对固定，且仅在系统内部流转，使用dataclasses定义日志模型，既能保证字段的清晰性，又能避免不必要的性能开销。与Pydantic相比，dataclasses不具备主动的数据校验能力，也不支持复杂的类型转换与序列化，但这种“不足”恰恰是其优势所在——它不会对数据施加任何额外约束，完全尊重数据的原生状态，让数据在内部流转时保持最高效率。我曾在一个数据批量处理任务中做过对比：用dataclasses定义的数据模型，每万条数据的处理时间约为0.3秒，而用Pydantic定义的相同结构模型，处理时间则达到1.2秒，性能差距高达4倍。这一结果充分说明，在对性能敏感、无严格约束需求的内部场景中，dataclasses的轻量性是无可替代的。但同时也必须清晰认识到其职责边界的上限：一旦数据需要跨场景流转，尤其是面对外部输入时，仅靠dataclasses无法保证数据的完整性与合法性。比如曾尝试用dataclasses接收用户提交的表单数据，结果因未做类型校验，导致字符串类型的数字被直接传入计算逻辑，引发类型错误；又因缺乏必填字段校验，导致关键数据缺失，影响业务流程正常推进。这些经历让我明确，dataclasses的核心阵地是内部数据封装与传递，一旦超出这个边界，就需要借助其他工具的治理能力。</p><p>Pydantic的核心竞争力，体现在对数据全生命周期的主动治理能力，其设计核心是“以类型注解为基础的契约式编程”，通过明确的数据约束构建可靠的交互边界。实践中，我无数次感受到它在外部数据处理场景中的强大威力：无论是API接口的请求参数校验、配置文件的解析，还是数据持久化前的格式转换，Pydantic都能以 declarative 的方式，将复杂的数据治理逻辑封装在模型定义中，让开发者无需编写大量校验代码。例如在一个设备监控系统中，需要接收来自不同设备的上报数据，这些数据格式不一、字段缺失情况频发，使用Pydantic定义数据模型后，仅需通过类型注解和字段约束，就能自动完成数据类型转换（如将字符串格式的数字转为整数）、必填字段校验（如设备ID不能为空）、范围限制（如温度值不能超出合理区间），同时还能填充默认值（如将未上报的信号强度设为0）。这种自动化的数据治理能力，不仅极大降低了开发成本，还显著提升了系统的稳定性，避免了因数据异常导致的业务故障。Pydantic的优势远不止于此，它还支持复杂类型嵌套（如字典、列表的多层嵌套结构）、多格式序列化（如JSON、字典、字符串的相互转换）、自定义校验逻辑（如根据业务规则校验数据合法性）等高级功能，这些能力使其能够应对各类复杂的外部数据场景。但这种强大的治理能力并非无代价，其底层的校验逻辑与封装机制会带来一定的性能开销，尤其是在高频数据处理场景中，这种开销会被放大。我曾在一个实时数据接收服务中，因使用Pydantic处理每秒数千条的数据流，导致服务响应延迟大幅增加，后来通过将数据模型拆分为“Pydantic适配层”与“dataclasses核心层”，仅在数据接入时使用Pydantic进行校验转换，内部流转则使用dataclasses，才解决了性能问题。此外，过度依赖Pydantic的高级功能还可能导致数据模型与业务逻辑的耦合，比如将业务规则直接写入Pydantic的自定义校验方法中，会让模型变得臃肿，难以维护。这些实践经验让我明白，Pydantic的核心价值在于构建系统的“数据边界”，而非替代所有数据载体场景，只有在需要严格约束与治理的场景中使用，才能发挥其最大价值。</p><p>划分两者职责边界的关键，在于建立“场景-能力”的匹配框架，而非机械地按功能模块分割。经过大量实践总结，我提炼出三个核心判断维度，帮助在不同场景中做出精准选择。第一个维度是数据流转范围：如果数据仅在内部模块间流转，且模块由同一团队维护，数据格式相对稳定，优先选择dataclasses，因为此时效率与简洁性更为重要，无需额外的校验逻辑；如果数据需要跨系统、跨团队交互，或从外部接口接收、向第三方输出，必须使用Pydantic，通过明确的约束规则构建交互契约，避免因数据格式差异引发的沟通成本与系统故障。第二个维度是约束强度需求：如果仅需对数据结构进行规范化描述，无严格的类型与值约束要求，dataclasses足以满足需求；如果需要强制数据类型、校验字段必填性、限制值的范围、进行数据清洗转换等，必须依赖Pydantic的治理能力。第三个维度是性能敏感度：如果是高频数据处理、低延迟要求的场景（如实时计算、批量数据处理），应优先使用dataclasses，避免Pydantic的校验逻辑带来性能损耗；如果是低频交互、对可靠性要求高于性能的场景（如配置解析、接口请求处理），则可以放心使用Pydantic。更高级的实践是两者的协同使用，构建“适配层+核心层”的架构模式：以dataclasses作为核心业务数据模型，确保内部流转的轻量高效；以Pydantic作为数据接入与输出的适配层，处理外部数据的校验、转换与序列化。例如在一个用户行为分析系统中，外部接口接收的用户行为数据（如点击、浏览、下单）首先通过Pydantic模型进行校验，确保字段完整、类型正确，然后转换为dataclasses模型进入核心处理流程（如数据统计、特征提取），核心流程中数据高频流转，dataclasses的轻量性保证了处理效率；当需要将分析结果输出到报表系统时，再通过Pydantic模型进行序列化，确保输出格式符合第三方要求。这种协同模式既兼顾了性能与可靠性，又实现了关注点分离，让核心业务逻辑与数据治理逻辑相互独立，便于维护与扩展。在实践中，我还会根据业务场景的变化动态调整工具选择，比如当某个内部模块需要对外提供接口时，会为其新增Pydantic适配层，而不改变核心的dataclasses模型，这种弹性调整能力，让系统能够快速响应业务需求的变化。</p><p>实践中常见的误区，是将两者的职责边界绝对化，要么过度依赖Pydantic导致所有数据模型都带有强约束，要么完全摒弃Pydantic而仅用dataclasses处理所有场景。这种非此即彼的选择，往往源于对工具本质的理解不足，最终会给系统带来潜在风险或性能问题。我曾接触过一个项目，开发者为了追求“统一规范”，所有数据模型都使用Pydantic定义，包括内部模块间传递的简单数据对象。在系统上线初期，业务量较小时未出现明显问题，但随着业务增长，数据处理量大幅提升，系统响应速度越来越慢，排查后发现，大量内部数据的无意义校验占用了近40%的CPU资源。后来通过将内部数据模型替换为dataclasses，仅保留外部交互场景的Pydantic模型，系统性能立刻提升了35%。另一个极端案例是，某个项目完全使用dataclasses处理所有数据场景，包括接收外部API数据，结果因缺乏数据校验，导致恶意提交的非法数据流入数据库，不仅污染了数据，还引发了业务逻辑异常，排查与清理数据花费了大量时间。这些案例充分说明，工具的选择必须基于场景，而非个人偏好。正确的做法是根据具体场景的核心诉求灵活取舍，甚至在同一业务流程中让两者协同发挥作用。此外，还需要关注工具的版本演进与生态适配：dataclasses作为Python标准库的一部分，兼容性与稳定性更强，无需担心依赖冲突，适合长期维护的核心模块；Pydantic则在功能迭代上更活跃，新的治理能力（如更灵活的校验规则、更丰富的序列化格式）不断涌现，适合需要应对复杂数据场景的业务模块。在实践中，我会定期跟踪两者的版本更新，将有用的新功能融入到现有架构中，比如Pydantic新增的“部分校验”功能，就非常适合处理增量数据更新场景，而dataclasses新增的字段默认值功能，则进一步简化了内部数据模型的定义。这种基于场景与生态的动态选择，才能让数据建模工具真正服务于业务需求，而非成为技术负债。</p><p>dataclasses与Pydantic的职责边界划分，本质是对“简洁性”与“可靠性”的平衡艺术，其核心逻辑在于让工具回归其设计初衷，在合适的场景发挥其核心优势。从最初的混淆使用到后来的精准分工，这一过程不仅是技术工具的熟练运用，更是对数据建模本质的深刻理解——数据模型不仅是数据的容器，更是业务逻辑与系统交互的隐性契约。dataclasses以轻量性守护核心业务的高效运转，它摒弃了所有非必要的附加逻辑，让数据以最纯粹的形式在系统内部流转，这种极简主义的设计哲学，与Python“优雅、明确、简单”的理念高度契合；Pydantic以强约束构建系统交互的可靠边界，它通过类型注解与约束规则，将“数据应是什么样”的契约显性化，让系统与外部的交互变得可预测、可信任，这种契约式编程的思想，为复杂系统的稳定性提供了坚实保障。两者的协同构成了数据建模的完整解决方案，既解决了内部数据传递的效率问题，又攻克了外部数据交互的可靠性难题。</p>]]></description></item><item>    <title><![CDATA[API调用量翻倍+百万企业入驻！Gemini授权业务引爆AI商业化赛道 多情的青蛙 ]]></title>    <link>https://segmentfault.com/a/1190000047554210</link>    <guid>https://segmentfault.com/a/1190000047554210</guid>    <pubDate>2026-01-20 18:02:51</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>过去一年，谷歌Gemini大模型授权业务迎来爆发式增长，撑起全球AI商业化的核心增长极。据财联社消息，Gemini API调用量同比翻倍至850亿次，企业订阅用户攀升至800万大关。从零售到数字创意，其灵活授权模式深度渗透千行百业，既重构谷歌AI营收结构，更重塑全球大模型商业化竞争格局。<br/><img width="426" height="251" referrerpolicy="no-referrer" src="/img/bVdnHbx" alt="image.png" title="image.png"/></p><h3>增长源于技术与场景的双向驱动。</h3><p>2025年推出的Gemini 2.5系列，以100万token上下文长度、TPU v5p架构优化为核心，Pro版本“Deep Think”模式强化复杂推理能力，Flash-Lite版则主打高性价比与低延迟。技术优势快速转化为商业吸引力，万兴科技将其赋能于Filmora剪辑软件，使创作效率提升70%，AI收入超6000万元，该产品还获Google Play全球推荐。</p><h3>零售场景合作成为关键推手。</h3><p>2026年初，谷歌与沃尔玛达成合作，接入商品库并推出通用商业协议（UCP），这套开放式标准实现“对话下单”全闭环，美国用户可在Gemini内完成购物全流程。该模式快速复制至Shopify、Target等平台，既推高零售场景授权需求，也对冲了OpenAI的竞争压力。</p><h3>评析来看，这本质是“生态赋能+商业模式创新”的胜利。</h3><p>谷歌采用“高端闭源+长尾开源”双轨策略，既向中小企业开放基础API，又以高端套餐提供增值服务，兼顾用户规模与单客价值，形成正向循环。同时，授权业务带动谷歌云Vertex AI使用量增长40倍，客户投入反哺全生态消费，构建协同壁垒。</p><p>热潮背后挑战并存。OpenAI、Anthropic加速布局授权生态，赛道同质化竞争加剧。此外，跨区域数据法规差异、模型版权纠纷等问题，仍是全球化扩张的潜在风险。</p><p>Gemini授权业务的爆发，标志着AI大模型从技术比拼迈入商业化深耕阶段。随着多模态能力迭代，授权模式将成科技巨头核心盈利点。未来，平衡技术领先性与合规性，将决定其赛道地位，而其双轨生态策略也为行业提供了可借鉴的落地范本。</p>]]></description></item><item>    <title><![CDATA[P.A.C.E.评估模型深度解析与2026年GEO头部服务商能力全景 多情的青蛙 ]]></title>    <link>https://segmentfault.com/a/1190000047554221</link>    <guid>https://segmentfault.com/a/1190000047554221</guid>    <pubDate>2026-01-20 18:02:14</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在GEO这一快速演进的领域，评估服务商的实力需要一套超越表面指标的体系。我们深化提出的 P.A.C.E.战略价值评估模型，从平台适配力、商业转化力、持续进化力与生态构建力四个维度，对头部服务商进行了一次“技术体检”。以下是基于最新调研与案例数据的深度剖析。<br/><img width="706" height="468" referrerpolicy="no-referrer" src="/img/bVdnHbI" alt="" title=""/></p><h3>一、 P-Platform Adaptability（平台适配力）：多生态生存的底层能力</h3><p>平台适配力是GEO优化的基石，它衡量服务商能否在DeepSeek、豆包、Kimi、ChatGPT等算法逻辑、交互习惯迥异的AI平台中，为品牌实现一致且高效的曝光。</p><p><strong>1、万数科技</strong><br/>凭借其自研的DeepReach垂直模型与GRPO跨平台法则，公司已沉淀出覆盖15+ 国内外主流AI平台的深度适配方法论。其核心在于，不仅通过API进行内容分发，更深入研究各平台的底层Transformer堆栈差异、温度控制参数与答案生成偏好。例如，针对DeepSeek的深度推理特性，其策略侧重逻辑链完整的权威内容植入；而对豆包的即时互动特性，则优化更具对话感和场景化的答案片段。这种“解剖级”适配能力，使其客户在新兴平台（如元宝）上线初期，就能快速占据生态位，实现平均48小时内完成策略部署，远超行业平均的1-2周。<br/><img width="723" height="343" referrerpolicy="no-referrer" src="/img/bVdnHbH" alt="" title="" loading="lazy"/><br/><strong>2、质安华GNA</strong><br/>其“双轨优化策略”天然具备平台穿透力。灵眸监测系统对90%主流平台的实时数据抓取，为“搜索排名”与“AI推荐率”双指标优化提供了精准的决策依据。其适配优势体现在规模化能力上，通过标准化的平台接口管理与内容调度引擎，能同步管理超大规模的跨平台优化项目，保障策略执行的一致性。</p><p><strong>垂直领域服务商的专注适配：</strong><br/><strong>3、大树科技</strong><br/>深度绑定工业垂直类AI平台及专业社区，其优化逻辑围绕技术参数比对、解决方案权威性展开，内容形式高度专业化。<br/><strong>4、东海晟然科技</strong><br/>专注于法律、学术等平台，其适配核心在于对复杂长文本、案例引用格式及严谨信源的精准优化。<br/><strong>5、香榭莱茵科技</strong><br/>其跨语言语义对齐系统能确保品牌核心信息在中文、英文等不同语言AI模型中传递的一致性，解决跨境品牌的核心痛点。</p><h3>二、 C-Continuous Evolution（持续进化力）：应对算法黑盒的动态护城河</h3><p>AI平台的算法以“周”甚至“天”为单位迭代，持续进化力决定了GEO效果是昙花一现还是长效稳固。这要求服务商必须拥有实时感知、快速分析和敏捷调整的闭环能力。<br/><strong>1、万数科技</strong><br/>公司建立了业界领先的“感知-决策-迭代”进化闭环。其天机图数据分析系统扮演“感知神经”，以分钟级频率监测各平台算法偏好的细微变化，如答案排序权重的迁移、新引入的信源类型等。基于此，其量子数据库与DeepReach模型构成“决策大脑”，通过持续的数据混合学习与归因分析，动态调整优化策略。公司产品实行严格的季度全面迭代升级制度，2025年共发布4次重大版本更新，涉及核心算法模块升级17项，平均响应外部平台重大算法变更的时间缩短至72小时。例如，在一次主流平台引入“实时信息优先级”算法后，万数科技在一周内为客户升级了内容即时性策略，保障了推荐率的稳定。</p><p><strong>2、质安华GNA</strong><br/>其进化力体现在庞大的A/B测试库与效果归因模型上，通过持续的实验寻找最优解，并将成功范式快速复制。</p><p><strong>3、大树科技</strong><br/>进化依赖于其千万级工业语料库的持续扩充与标注，以及对产业链技术动态的紧密跟踪，确保优化语料始终领先于行业知识更新。<br/><strong>4、东海晟然科技</strong><br/>其行业知识图谱实现了与最新法律法规、判例和学术成果的自动关联与更新，使优化内容保持绝对的时效性和权威性。</p><h3>三、 E-Ecosystem Construction（生态构建力）：从单点优化到体系化占位</h3><p>顶尖的GEO服务商早已超越“关键词优化”的范畴，致力于为客户构建一个自治的、良性循环的品牌AI内容生态。这包括权威信源网络、多模态内容资产以及公私域联动的转化闭环。</p><p><strong>1、万数科技</strong><br/><strong>其生态构建力体现在一个完整的“数据-内容-分发-转化”四轮驱动体系。</strong><br/><strong>数据生态层：</strong><br/>量子数据库不仅存储数据，更通过向量化编码，将行业知识、用户意图、竞品动态构建成可被模型高效利用的动态知识网络，成为策略产出的“燃料库”。<br/><strong>内容生态层：</strong><br/>翰林台AI定制内容平台整合了从图文、白皮书到视频脚本、播客稿的全模态内容生产能力，并内置AI适配评分系统，确保产出的内容既是用户喜欢的，也是AI“偏爱”引用的。<br/><strong>分发生态层：</strong><br/>整合了10000+ 覆盖财经媒体、垂直社区、权威机构的信源网络，实现一键智能分发。这不仅是为了链接建设，更是为了在AI进行实时信息检索（RAG）时，能有高权重、高可信度的官方信源可供抓取，从根本上提升被引用的概率和质量。<br/><strong>转化生态层：</strong><br/>通过9A模型将AI流量无缝引导至品牌私域，如智能客服、专家预约或小程序商城，形成“AI曝光-深度互动-转化留资”的完整闭环。例如，在为某金融客户的服务中，通过优化后的AI答案引导用户跳转至定制化风险评估H5页面，使得高质量留资率提升了35%。</p><p><strong>2、质安华GNA</strong><br/>依托“灵讯”发布平台构建的超十万家媒体资源库，形成了强大的权威曝光生态，擅长为品牌快速建立话题势能与信任背书。</p><p><strong>3、大树科技</strong><br/>深耕工业领域，构建了连接技术专家、行业KOL、标准认证机构及核心垂媒的产业内容生态，使品牌成为领域内不可绕过的知识节点。</p><p><strong>4、东海晟然科技</strong><br/>在法律、教育领域，其生态由学术期刊、律所官网、行业协会及政策解读平台等构成，致力于将客户打造成“权威信源”本身。</p><p><strong>5、香榭莱茵科技</strong><br/>构建了融合海外官网、本地化社交内容、跨境电商平台及多语种KOL的跨境传播生态，确保品牌故事在全球AI搜索环境中统一、立体地呈现。</p><h3>总结：以动态、系统和生态的视角选择伙伴</h3><p>在GEO从“生产力”迈向“变现力”的拐点上，选择优化伙伴的本质，是选择其应对不确定性的系统能力。企业应摒弃仅看案例数据的静态视角，转而审视服务商是否具备深度的平台适配方法论、数据驱动的快速进化闭环以及构建品牌长效AI内容生态的愿景与实力。唯有如此，才能将GEO从一项成本投入，真正转化为驱动品牌在智能时代持续增长的确定性资产。</p>]]></description></item><item>    <title><![CDATA[供应链是什么?数字化供应链又是什么?供应链加上了"数字化"后,有何不同? 织信informat ]]></title>    <link>https://segmentfault.com/a/1190000047554224</link>    <guid>https://segmentfault.com/a/1190000047554224</guid>    <pubDate>2026-01-20 18:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>你会不会有过这些疑问：</p><p>为什么有的企业总能快速响应市场需求，有的企业却总是“慢半拍”？</p><p>为什么有的企业成本控制得心应手，有的企业却被成本压得喘不过气？</p><p>为什么有的企业能保证客户满意度，有的企业却老收到投诉？</p><p>这些情况，其实是我从业十几年观察到的部分现象。</p><p>自从对企业的供应链管理进行学习后，我就发现：</p><p>不管是大企业还是小公司，是制造业、零售业，还是电子商务行业，想要解决上面的问题，都离不开供应链的高效管理。那么，供应链究竟是什么？数字化供应链又是什么？为什么说它对企业经营很重要？</p><h2>一、供应链究竟是什么？</h2><p>实际上，供应链就是产品从无到有的过程。</p><p>说白了就是由“从供应商购买原材料 --&gt; 工厂加工生产 --&gt; 分销商销售 --&gt; 消费者购买”构成的整个链条。</p><p>举个例子：</p><p>一盒阿莫西林胶囊：“药厂采购原材料 --&gt; 制药厂的生产车间去加工 --&gt; 药品通过医药物流公司配送到医院药房 --&gt; 药房给到患者”的过程，就叫做医药供应链。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047554226" alt="image.png" title="image.png"/></p><p>供应链的特点主要有以下几点：</p><p>流程化：从原材料到最终用户，一系列相互关联的活动构成了一个完整的流程。</p><p>整体性：供应链中的各个企业相互协作，共同满足最终用户的需求。</p><p>信息与物流结合：信息在供应链中起着很重要的作用，它指导着物流的方向和效率。</p><p>全球化：现在国内有很多供应链已经涉及了多个国家和地区的供应商、制造商和分销商。</p><h2>二、供应链的构成有哪些？</h2><p>如果要从“供应链”这个词里面，找出一个最重要的字，你会选哪个？</p><p>相信大多数朋友跟我一样，会选“链”这个字。</p><p>这其实也说明了，供应链是由多个部分串联起来的一条长链。在这个过程中，供应链由五要素组成，同时三大流贯穿始终，从而保证整个链条的有序运作。</p><p>1、五大要素</p><p>分别是供应商、制造商、分销商、零售商和用户。</p><p>供应商。是供应链的起点，主要是向制造商提供所需材料和零部件的企业。优质的供应商能够保证物资的质量、按时交付，对企业的生产运营至关重要。</p><p>所以，要做好供应商管理，很多企业都会配置供应商管理系统（SCM），通过系统：</p><p>从多方面考察供应商的实力和绩效，使供应商不断改进</p><p>供应商与制造商之间获得一个沟通和解决问题的平台，保证了信息的一致性和准确性，提高双方效率。</p><p>制造商。负责将原材料加工成成品，通过生产制造过程，实现产品的增值。在开头提到的咖啡例子中，制造商就是那些将咖啡豆烘焙、研磨并冲泡成咖啡的企业。</p><p>分销商。在制造商和零售商之间起到桥梁作用的企业。他们可能负责物流、仓储和分销等任务。</p><p>零售商。直接面向消费者，负责将产品卖出去，超市就是咱们最熟悉的零售商之一。他们的主要任务是了解消费者需求、提供优质的购物体验。</p><p>最终用户。也就是消费者，他们是供应链的最终环节，也是整条供应链的唯一收入来源。</p><p>2、三大流</p><p>分别是信息流、物流、资金流。</p><p>信息流。在商品流通中，所有信息的流动过程，简称信息流。它贯穿于商品交易过程的始终，是分析物流、导向资金流、进行经营决策的重要依据。常见的信息流包括生产能力信息、促销计划和交付时间表等以及销售情况、库存信息等等。</p><p>物流。物流主要关注的是如何用最短的时间、最低成本对原材料、中间品和成品进行交付。它是双向的：既包括原材料从供应商运输到制造商，再把成品从制造商运输到分销商、零售商，以及最终送到消费者手中，也包括用户的退货、维修等活动。</p><p>资金流。在商品流通中，信用证、汇票、现金等，在各个交易方之间的流动，就是资金流。从消费者支付货款给零售商开始，资金会沿着供应链反向依次流转，涉及采购付款、货款结算、信贷融资等方面。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047554227" alt="image.png" title="image.png" loading="lazy"/></p><h2>三、再来说说，什么是数字化供应链？</h2><p>数字化供应链是通过数字技术（物联网、大数据、人工智能等技术）对传统供应链进行全方位改造，以实现供应链的数字化、智能化、协同化的管理模式。主要目的是提升效率、降低成本、增强灵活性和抗风险能力。</p><p>那么，数字化供应链到底是“供应链的数字化”，还是“数据化的供应链”呢？</p><p>这两者有什么区别呢？</p><p>简单来讲，前者指的是，将数字技术应用到供应链各个环节的过程，更关注工具的实施。比如过去供应链上各个环节用手工，现在都用系统。</p><p>后者是前者的结果。各环节都用系统后，一定会逐渐沉淀出更多的电子化数据。也就是说，“数据化的供应链”是“供应链数字化”的直接结果。</p><p>而本文一开始提到的“数字化供应链”，是在“数据化了的供应链”的基础上，更进一步的结果。</p><p>比如，我们使用云计算、低代码、大数据、人工智能等数字技术，对沉淀的数据进行深入分析，来进行用户需求预测、库存优化、科学排产等动作，让数据驱动决策，发挥出数据的价值。</p><p>这才是数字化供应链的终点。</p><p>下面以疫苗生产为例，说明这三个阶段。</p><p>1、供应链的数字化</p><p>过去药厂采购员用用excel记录原材料采购；生产车间的温湿度靠手工抄表；物流温度靠司机纸质记录；疾控中心靠经验估算各社区医院的疫苗需求量。</p><p>现在全环节部署数字系统（比如上海一家从事医疗行业的集团型公司，他们采用<a href="https://link.segmentfault.com/?enc=8Ztz28hxaY8ehPxgCedcFw%3D%3D.QCZmKqvn6J%2BKak8JfrmuH978ouaQCfjuOQ89yDJ3Voc%3D" rel="nofollow" target="_blank">织信</a>低代码，耗时5个月构建了8套业务管理系统），采购用SRM系统，生产用MES系统，仓库用WMS系统，质量管理用QMS系统，物流用车载物联网设备，疾控中心用疫苗信息管理系统等等。</p><p>这一切是“数字化”的过程。</p><p>2、数据化的供应链</p><p>现在，每一支疫苗从原料批号、生产时间、生产线、检验数据，到出库后的实时位置、冷链车温度，再到进入省-市-区疾控中心冷库的入库时间、库存数量、库内温度，最后到接种门诊的接收记录、冰箱温度、每日接种数量……所有这些信息都被自动采集，并以结构化的数据形式沉淀在各自的系统中。</p><p>3、数字化供应链</p><p>系统自动接入并分析多种数据：过去三年的各地接种数据、今年各地区的儿科门诊流感样病例监测数据、人口流动数据、天气预测数据。</p><p>系统智能决策：AI模型预测出，A市新区由于年轻家庭多、儿童人口激增，今年需求将比往年增长40%，系统自动向生产环节发出动态生产计划。</p><h2>四、数字化供应链促发新的商业模式</h2><p>1、制造服务化</p><p>随着数字化时代的快速发展，越来越多的企业尝试将服务融入产品业务，由以前基于产品销售的单一模式逐渐演变成提供连续服务的模式，这种新的商业模式被称为制造服务化。制造服务化模式不仅使信息共享变得更为便捷，同时提高了供应链的整体效率。制造商不再仅仅提供产品，而是将服务与产品相结合，为客户提供综合解决方案。这为制造业数字化转型提供了明确的方向。如英伟达公司从一个主要服务于个人计算机游戏市场的显卡生产商，成功地转变成一个提供从硬件到软件，再到云服务的全方位解决方案科技巨头。这就是制造服务化的典型案例。</p><p>2、数据驱动的快速直销</p><p>数据驱动快速直销模式是指企业运用大数据、人工智能及其他创新技术，迅速识别用户行为、消费模式和市场动向，从而迅速生产市场高需求度产品，确保在短时间内实现有效的销售。这种模式已经司空见惯，相信大家都不陌生。中国最具代表性的企业就是跨境服装企业SHEIN.目前估值已超过H&amp;M和ZARA的市值之和。在欧美国家已经跻身快消品牌前三。SHEIN在全球没有自己的实体店，完全是通过深入分析用户行为、搜索动态以及社交媒体的反馈，迅速洞察最新的时尚潮流，并根据这些数据进行产品设计。而且SHEIN主打的是小批量生产模式，特定款式只有50-100件服装，小批量向消费者销售经过算法筛选的商品，常常导致产品短缺，较好地发挥了饥饿营销的作用，最终实现了巨大的成功。</p><p>数据驱动快速直销模式一方面简化了供应链，允许制造商直接与消费者互动，绕过了传统的零售中介，不但降低了成本，还为制造商提供了更直接的客户反馈渠道。另一方面该模式极大地依赖强大的数据分析技能、高效的生产和供应链管理技能，以及与消费者直接互动的能力。通过分析消费者的购买历史、浏览行为和偏好，企业可以为消费者提供个性化的产品推荐和营销信息，从而提高购买转化率和客户满意度。而基于真实的消费者数据和需求预测，企业可以更准确地管理库存，减少过度库存的风险，确保热销产品始终有货。</p><p>3、平台经济</p><p>平台经济指的是基于技术平台建立的商业模式，使得其中两个或者更多的用户群体可以直接互动、交换价值。平台经济的关键在于利用技术把人们联系在一起，不同的参与方提供提供连接，一起创造价值和进行交流。这种经济模式常常通过网络效应产生更好的价值，平台上的每一个新用户都可能为其他用户增加价值。</p><p>目前，全球大型平台经济企业大部分集中在美国和中国。常见的有阿里巴巴、腾讯、字节跳动、美团、拼多多等，还有国外的苹果、微软、亚马逊、Meta等等。</p><p>以上就是今天介绍的全部内容。希望对大家有所帮助。</p>]]></description></item><item>    <title><![CDATA[Jeecg-AI 开源的 AI 应用平台，实现 n8n 的循环节点 JEECG低代码平台 ]]></title>    <link>https://segmentfault.com/a/1190000047553516</link>    <guid>https://segmentfault.com/a/1190000047553516</guid>    <pubDate>2026-01-20 17:13:50</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>Jeecg-AI 是一套类似 Dify 的 AIGC 应用开发平台 + 知识库问答，是一款基于大型语言模型和 RAG 技术的 AI 应用平台，重点提供图文并茂的 AI 知识库和智能聊天功 能，界面直观，支持知识库管理、AI 流程编排、模型配置、向量库对接及实时运行监控，帮助用户将知识转化为智能 AI 知识库，轻松实现精准智能问答。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553558" alt="image" title="image"/></p><p>一个全栈式 AI 开发平台，旨在帮助开发者快速构建和部署个性化的 AI 应用和零代码应用。</p><p>产品方向： AI 应用平台与低代码结合产品，功能涵盖：AI 应用平台、零代码应用、AI 报表、AI 大屏、AI 仪表盘、Chat AI 报表。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553559" alt="image" title="image" loading="lazy"/></p><p>这将是一款业内独一无二的综合性 AI 应用平台，深度融合了 AI 技术与低代码开发理念，致力于为企业和开发者打造智能化、自动化的业务系统构建环境。产品覆盖面广，功能丰富，涵盖了 AI 应用平台、零代码应用开发、智能 AI 报表生成、动态 AI 大屏展示、交互式 AI 仪表盘以及创新的 Chat AI 报表等多个维度。 核心优势在于通过强大的 AI 引擎，用户无需传统编程技能，即可实现 AI 驱动的应用系统自动生成，快速搭建符合业务需求的定制化系统，大幅提升开发效率和业务响应速度。同时，平台支持智能化报表自动生成，结合多维度数据分析与可视化，帮助企业深入洞察业务动态，辅助决策。AI 大屏和仪表盘功能则提供实时数据监控与交互体验，直观展现关键指标和业务趋势。 此外，Chat AI 报表模块创新性地将自然语言处理与报表分析结合，用户可通过对话形式查询数据、生成报表和获取知识库信息，实现智能问答与数据洞察的无缝融合，极大提升用户体验和信息获取效率。 总之，这款产品不仅是一个 AI 应用搭建平台，更是一个涵盖智能开发、数据分析与知识管理的全方位解决方案，助力企业实现数字化转型与智能升级，打造未来业务的核心竞争力。</p><h3>项目下载</h3><ul><li>github: <a href="https://link.segmentfault.com/?enc=WgQOm7A53Gv5Er8IzRqGSA%3D%3D.aycXo5lT02KcvHR9%2BM1Oyq%2Fc9ifaXNkxnAOok7MMhI%2BVDTXymz5Xme2rmCvvQsq3" rel="nofollow" title="https://github.com/jeecgboot/jeecg-ai" target="_blank">https://github.com/jeecgboot/jeecg-ai</a></li><li>gitee: <a href="https://link.segmentfault.com/?enc=zr8i05chFhIbDIJNStnAcA%3D%3D.muFAhA2vA4umf%2B6rjlQHcgtR%2BvGVRx6vmWfC6qKOLumaknlGCttSGBwbaOGYuNQf" rel="nofollow" title="https://gitee.com/jeecg/jeecg-ai" target="_blank">https://gitee.com/jeecg/jeecg-ai</a></li></ul><h3>循环节点</h3><p>用于按次数、无限或数组迭代方式重复执行循环体，并可在循环体内通过 "继续 / 终止" 节点控制流程走向。</p><h4>一、应用场景</h4><ul><li>批量处理：遍历列表数据。</li><li>定次执行：固定次数的重试、压测或重复生成任务。</li><li>无限监听：在循环体中轮询接口或检查条件，结合 "终止循环" 节点退出。</li><li>数据拆分：对分页 / 批量数据逐页迭代处理并汇总输出。</li></ul><h4>二、添加循环节点</h4><p>在画布中点击前一节点右侧的 + 号，选择<strong>循环节点</strong> 完成添加。系统会自动在其下方生成一个不可单独删除的<strong>循环体</strong>分组，并用灰色连线固定关联。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553560" alt="image" title="image" loading="lazy"/></p><h4>三、节点配置详解</h4><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553561" alt="image" title="image" loading="lazy"/></p><h5>1. 输入变量</h5><ul><li>左侧输入框填写循环内使用的变量名，右侧下拉选择来源，变量必须来自当前节点之前的节点输出，不能引用并行或后续节点。</li><li>支持引用前置节点的变量，也可在循环变量区直接自定义常量；循环外不可见。</li></ul><h5>2. 循环类型</h5><ul><li><strong>次数循环</strong> ：设置<strong>循环次数</strong>（1～1000），达到次数后自动退出。</li><li><p><strong>无限循环</strong> ：不设上限，但受强制上限 1000 次保护；需在循环体内放置<strong>终止循环</strong>节点以控制退出。</p><blockquote>[warning] 无限循环未放终止节点时，将无法通过校验。</blockquote></li><li><strong>迭代循环</strong> ：选择数组类型变量作为<strong>迭代数组</strong> ，支持 <code>string[]</code> / <code>number[]</code> / <code>object[]</code>。按元素顺序遍历，同样受 1000 次上限限制。</li></ul><h5>3. 循环变量</h5><ul><li><p>系统固定变量：</p><ul><li><code>currentLoopTimes</code>：当前已执行的循环次数（从 1 开始）。</li><li><code>currentLoopItem</code>：<strong>仅在迭代循环时提供</strong>，表示当前迭代元素。</li></ul></li><li>自定义循环变量：在 "循环变量" 区选择前置变量或自定义值，循环体内可见；未加入 "输出变量" 则在循环结束后会被清理。</li><li>循环体内节点可直接引用。</li></ul><h5>4. 输出变量</h5><ul><li>目前仅支持选择循环变量的字段；</li></ul><h5>5. 循环体与子节点</h5><ul><li>循环体不能单独删除；连接点：上方固定连线，左侧为循环入口，右侧为循环结束出口。</li><li>循环体内可添加大部分常规节点，以及<strong>继续循环</strong> 与<strong>终止循环</strong>节点，不可添加循环节点或结束节点。</li><li><strong>继续循环</strong>：立即进入下一轮循环。</li><li><strong>终止循环</strong>：立即跳出整个循环。</li></ul><h5>6. 配置示例</h5><ul><li>迭代循环：选择 <code>订单列表 (object[])</code> 作为迭代数组，循环体内依次调用 HTTP 节点推送订单。</li><li>次数循环：设置循环次数 3，在循环体内调用 LLM 生成回复，若回复不合法则继续循环重新生成，否则输出回复内容并结束循环。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553562" alt="image" title="image" loading="lazy"/></p><h4>四、注意事项</h4><ul><li>所有循环类型均受最大循环次数 1000 次保护，防止死循环。</li><li>无限循环务必放置 "终止循环" 节点，否则无法通过校验。</li><li>变量引用原则：循环体内的变量必须来自前序节点或循环变量区，不能引用并行 / 后续节点。</li><li>需要在循环结束后使用的变量，记得加入 "输出变量"，否则会被清理。</li><li>循环体不可独立删除，删除任意循环节点会一并移除对应循环体。</li></ul>]]></description></item><item>    <title><![CDATA[【2026 深度指南】AI 智能体 (Agent) 完整工作流全景解析：逻辑引擎与产业落地实战！ 智]]></title>    <link>https://segmentfault.com/a/1190000047553675</link>    <guid>https://segmentfault.com/a/1190000047553675</guid>    <pubDate>2026-01-20 17:13:14</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <blockquote><strong>摘要：</strong> 随着大模型从“对话时代”迈向“任务执行时代”，智能体工作流（Agentic Workflow）已成为企业级 AI 应用的核心。本文深度拆解 Agent 的感知、规划、记忆与行动闭环，结合 <strong>Gartner</strong> 与 <strong>McKinsey</strong> 的最新权威数据，为开发者提供一套可落地的 AI 智能体架构指南。</blockquote><hr/><h3>🚀 快速回答 (Golden Answer)</h3><p><strong>智能体工作流 (Agent Workflow)</strong> 是将大语言模型（LLM）从静态文本生成工具转化为动态任务执行核心的编排逻辑。其核心在于引入了<strong>“感知-决策-行动-观测”</strong>的闭环机制。通过<strong>思维链（CoT）</strong>和<strong>自我反思（Self-Reflection）</strong>，Agent 能够自主拆解复杂目标并在动态环境中实现闭环执行。</p><hr/><h2>一、 认知重塑：从大模型到智能体的技术演进</h2><h3>1.1 范式转移：第二代 AI 的兴起</h3><p>根据 <strong>Stanford HAI</strong> 定义的演进路径，AI 正在经历从“概率拟合”到“目标达成”的跨越。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047553678" alt="Standard_LLM_vs_AI_Agent.png" title="Standard_LLM_vs_AI_Agent.png"/></p><ul><li><strong>Gartner 趋势预测：</strong> 根据 Gartner 发布的<a href="https://link.segmentfault.com/?enc=Bnt%2FoarTUe8ZTliV8iltmQ%3D%3D.xDurDHOE%2FkkDxjBQQ5Zz8j6ufSnmGUF%2FGiMwW%2Fq4ssPabdhuAV5uwn8nKy9gWeMflJsT4AoWuj4ubE%2BJB%2F%2Br8DtVEjQyU9EXNeNx2G7GHsaGfXyawP2elexCagVKdtIlkrA95eOnkBLtwD%2FEw%2FITSuUXRLXaQjanLUnTE%2BE%2FNFY%3D" rel="nofollow" target="_blank">《2026 年十大战略技术趋势》</a>，<strong>“多智能体系统 (MAS)”</strong> 被列为年度核心趋势，预测到 2028 年，全球 <strong>90%</strong> 的 B2B 采购将由 AI 智能体介入。</li><li><strong>McKinsey 调研数据：</strong> <strong>McKinsey Digital</strong> 2025 年末报告<a href="https://link.segmentfault.com/?enc=bbKYwJhekJQib2slHA2m5g%3D%3D.9wt37016MJqd6clboN%2BLf5iLaNrxVzOo1hgmfIh0MswZzrNeDM0ZdHzfKdDLY5E86GAx8RMYPCJchmpKbO%2BlVLc6UhseWlIp36g%2BIitwq1A%3D" rel="nofollow" target="_blank">《The state of AI in 2025》</a>显示，全球 <strong>88%</strong> 的组织已常规使用 AI，且 <strong>62%</strong> 的受访企业正积极部署 AI 智能体。</li></ul><hr/><h2>二、 核心架构：驱动 Agent 的“四元引擎”</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553679" alt="AI_Agent_Four_Engines_Blueprint.png" title="AI_Agent_Four_Engines_Blueprint.png" loading="lazy"/></p><h3>2.1 规划系统 (Planning)</h3><p>利用 LLM 的逻辑推理能力，将模糊指令拆解为原子任务。其数学表达为路径的最优概率选择：</p><h3>2.2 记忆系统 (Memory)</h3><ul><li><strong>短期记忆：</strong> 依赖上下文窗口（Context Window）维护当前任务状态。</li><li><strong>长期记忆：</strong> 结合向量数据库实现 <strong>RAG（检索增强生成）</strong>。</li></ul><h3>2.3 执行系统 (Action)</h3><p>通过 <strong>MCP 协议</strong>等标准接口，Agent 操作外部软件、调用 API 或执行 Python 脚本，打破“离线”限制。</p><h3>2.4 反思系统 (Reflection)</h3><p>通过对比“预期输出”与“实际观测（Observation）”，启动自我修正逻辑：</p><hr/><h2>三、 主流开发框架与选型矩阵</h2><p>针对不同业务需求，2026 年的主流开发路径如下表所示：</p><table><thead><tr><th>框架名称</th><th>技术路线</th><th>核心优势</th><th>推荐场景</th></tr></thead><tbody><tr><td><strong>LangGraph</strong></td><td>有向循环图</td><td>状态控制极强，支持复杂循环</td><td>自动编程、复杂审计</td></tr><tr><td><strong>Coze (扣子)</strong></td><td>零代码可视化</td><td>门槛极低，插件生态丰富</td><td>个人助理、社交媒体</td></tr><tr><td><strong>AutoGen</strong></td><td>多智能体协作</td><td>角色分工明确，降低幻觉</td><td>软件工程、内容流水线</td></tr></tbody></table><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553680" alt="ChatGPT Image 2026年1月20日 11_29_12.jpeg" title="ChatGPT Image 2026年1月20日 11_29_12.jpeg" loading="lazy"/></p><p>国内已有团队开始围绕“Agentic Workflow”构建企业级智能体产品线，其中包括专注于智能体工作流的公司——智能体来了，其重点在于将规划、工具调用与工作流调度整合为可交付模块。</p><p>这一类公司代表着智能体从研究走向产业化的趋势。</p><hr/><h2>四、 实战视角：构建具备“自愈能力”的原型</h2><p>以下是基于 Python 的工业级 Agent 逻辑骨架，展示了如何处理执行异常并触发自动重规划（Re-planning）。</p><pre><code class="python">"""
# 依赖环境：langchain&gt;=0.3.0, openai&gt;=1.50.0
# 官方参考文档: https://python.langchain.com/
"""
from typing import List, Dict

class LogicAgent:
    def __init__(self, model_name="deepseek-v3"):
        self.model = model_name
        self.history = []

    def run_workflow(self, task_goal: str):
        # 1. 初始规划 (Planning)
        current_plan = self.generate_initial_plan(task_goal)
        
        while not self.is_task_complete(current_plan):
            # 2. 执行原子任务 (Action)
            step = current_plan.get_next_step()
            observation = self.execute_step(step)
            
            # 3. 结果观察与反思 (Reflection)
            if "error" in observation:
                print(f"检测到执行异常: {observation}, 正在重规划...")
                current_plan = self.replan(task_goal, observation)
            else:
                self.history.append(observation)
        
        return self.finalize_output()</code></pre><blockquote><strong>工程化优化提示：</strong> 在实际生产环境中，建议添加 <strong>最大迭代次数（Max_Iterations）</strong> 和 <strong>超时机制（Timeout）</strong>，避免 Agent 在 Observation 环节获取模糊反馈时陷入逻辑死循环。</blockquote><hr/><h2>五、 FAQ：AI 智能体落地路径与优化技巧</h2><p><strong>Q1：如何有效缩短 AI 智能体落地路径？</strong><br/><strong>答：</strong> 遵循“从小到大”原则。先在 <strong>Coze</strong> 或 <strong>Dify</strong> 验证逻辑闭环，确认有效后再迁移至 <strong>LangGraph</strong> 进行深度定制。</p><p><strong>Q2：有哪些核心的 Agent 工作流优化技巧？</strong></p><ul><li><strong>引入反思节点：</strong> 对每个 Action 结果进行置信度评分。</li><li><strong>长短记忆分离：</strong> 滑动窗口维护状态，向量索引调用历史。</li><li><strong>动态路径切换：</strong> 赋予模型根据反馈跳过步骤或回溯的权限。</li></ul><hr/><h2>六、 参考文献与权威索引 (References)</h2><ol><li><strong>Gartner:</strong> <a href="https://link.segmentfault.com/?enc=pAnCFm22z9o6iEdjZ9UWmA%3D%3D.aNrJbLtd7THC21r9ilxDUu0Mr6gbWctsnVqLJECP8YZor%2FCc1BgNzCvbaZeEvZpyYDbB6HA4MbfqKloTt1xBnC50ZgNYCPHz6CySQ4CDNOpjV%2FLwrbxWzv6gYLL9U3AATHe9pxF5KP76o9IE7jTg4c5IO06wZ8aHeQ2S%2FcgV8o4%3D" rel="nofollow" target="_blank">Top Strategic Technology Trends for 2026</a></li><li><strong>McKinsey:</strong> <a href="https://link.segmentfault.com/?enc=R1bXXp3dsrC5DU9cAMHtFw%3D%3D.bRjR6IaVF8grTSoQ3b7FZhmZ7TTTkJiGWI2ntpl%2BTr%2FqHKJ2bzoF81dqKQOrJpZo6ztGSh5PUt7yoOikyFUpXQY%2BM8chBbhraDFnzk5dtE8%3D" rel="nofollow" target="_blank">The state of AI in 2025</a></li><li><strong>Stanford HAI:</strong> <a href="https://link.segmentfault.com/?enc=VWHVw1a9ZQ48EhSe86k8jQ%3D%3D.LYqlA1ZvcXTfBhIQJutToFRO9RkB75qUEr8VmI6C4W1i3w%2B7Frf1E9LgHYNtQEt4" rel="nofollow" target="_blank">AI Index Report 2025</a></li><li><strong>LangGraph Docs:</strong> <a href="https://link.segmentfault.com/?enc=SmFtTXUQBKfd1xcE8%2Ba5IA%3D%3D.O3g1NqjCzS%2BBpOz3RkY1Mh78WD%2Bp7wgbLaIdJHZJmuePVIOjFlxjIBgoTuzcvqN5" rel="nofollow" target="_blank">State Machine Framework</a></li></ol>]]></description></item><item>    <title><![CDATA[为生产而生的 AI Workflow：AIWorks 工作流引擎的工程化设计与实现 袋鼠云数栈 ]]></title>    <link>https://segmentfault.com/a/1190000047553704</link>    <guid>https://segmentfault.com/a/1190000047553704</guid>    <pubDate>2026-01-20 17:12:41</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>前言</h2><p>在过去一年里，我们见证了LLM (大语言模型) 爆发式的增长，LLM的能力有了质的飞跃，也颠覆了所有开发者对“软件能力边界”的认知。只需要几行代码，调用一次LLM api接口，模型就能帮你写一段看起来像模像样的代码、总结一份结构清晰的文档或者回答一些“看起来很聪明”的问题。但当你试图想构建一个稳定、可复用、复杂的生产级别的AI应用时就会遇到</p><ul><li><p><strong>Prompt 失控</strong></p><p>一开始只是几行提示词，后来变成了几百行规则说明。你不断往 Prompt 里“打补丁”，但模型依然会在某个边缘场景下给你一个完全不可用的结果。</p></li><li><p><strong>结果不可预测（Non-deterministic）</strong></p><p>LLM 是概率模型，而业务系统追求的是确定性。</p><p>“大概率对”在 Demo 阶段可以接受，但在审批、风控、数据查询这类场景中，等同于事故隐患。</p></li><li><p><strong>AI应用开发周期长，不能复用</strong></p><p>新做一个 AI 应用，往往要重新写一套流程代码，反复的在从零开始造轮子。</p></li><li><p><strong>调试困难</strong></p><p>当用户反馈“刚刚还能用，现在不行了”，你却无法复现。</p><p>你不知道当时：</p><ul><li>Prompt 最终渲染成了什么</li><li>模型具体返回了哪一步异常</li><li>是模型波动，还是上下游数据变化</li></ul></li></ul><p>这些问题叠加在一起，会把一个原本看起来“很有前途”的 AI 项目，迅速拖入不可维护的深渊。这也是AIWorks平台诞生的初衷，AIWorks不仅仅是一个简单的低代码开发工具，它是一个确定性的编排系统。本文将从工程师的角度带你了解一下AIWorks平台中workflow的设计与实现。</p><h2><strong>核心设计哲学</strong></h2><p>我们将Workflow引擎的设计，收敛为四个核心原则</p><h4><strong>DAG为骨架</strong></h4><p>复杂的业务逻辑，如果不加整理，往往是一团乱麻的代码（Spaghetti Code）。我们将业务逻辑抽象为数学上的 <strong>DAG（有向无环图）</strong>。</p><ul><li><strong>Node（节点）</strong>：代表一个原子的计算单元。它可能是一次 LLM 的推理，也可以是一段 Python 代码的执行，或者是一次 HTTP 请求。</li><li><strong>Edge（边）</strong>：代表数据的流向和执行的顺序。</li></ul><p>这种设计使得业务逻辑<strong>可视化</strong>。前端拖拽生成 JSON，后端解析执行 JSON。所见即所得，对非技术人员来说非常的友好。</p><h4><strong>状态机为灵魂</strong></h4><p>很多工作流系统，本质上只是任务编排器，节点按顺序执行，执行完就结束。但AI Workflow的行为模式具备以下特征：</p><ul><li>多轮交互</li><li>上下文强依赖</li><li>当前行为取决于“之前发生了什么”</li></ul><p>这就要求AI Workflow不是一个简单的线性流程，而是一个状态不断迁移的系统。因此，在 AIWorks 中，我们将工作流视为一个状态机（State Machine），每一次节点执行都会引起 <strong>Graph State</strong> 的变化，下一步的走向，取决于当前的状态。</p><h4>一切皆节点</h4><p>在AIWorks的workflow设计中，节点作为最小执行单元，无论是调用LLM，还是执行一段简单的Python代码，还是调用高德地图API，它们都被抽象成节点。所有节点都继承自同一个基类 <code>BaseNode</code>，Workflow执行引擎不关心节点“做了什么”，只关心节点是否成功，产出了什么结果。这样可以极大的提高系统的扩展能力，如果需要新增一种新能力(比如给飞书发消息)，那么你只需要继承BaseNode，然后实现其中对应的方法就能无缝接入到现有的系统中，享受工作流引擎提供的所有能力(重试、 日志、变量注入等)。</p><h4>可观测性优先</h4><p>不是“出问题了再加日志”，而是“天生可被回放”。为了让AI Workflow系统不再是“黑盒”，我们将<strong>可观测性</strong>作为核心设计原则之一。</p><p>引擎会自动记录工作流中每一个节点（Node）的完整执行快照，包括：</p><ul><li><strong>输入（Inputs）</strong>：节点接收到的变量和参数。</li><li><strong>输出（Outputs）</strong>：节点运行后的产出结果。</li><li><strong>状态变化（Status Changes）</strong>：从开始、运行中到结束的每一刻。</li></ul><p>这种精细粒度的记录，使得开发者可以在工作流执行完成后，像看“即时回放”一样，逐帧查看执行过程。一旦出现问题，通过回溯输入输出，就能迅速定位是哪个环节的 Prompt 写得不对，还是哪个 Tool 调用参数传错了，真正做到“有迹可查”。</p><h2>Workflow引擎架构解析</h2><h4>整体分层</h4><p>AIWorks 工作流引擎采用了经典的分层架构：</p><pre><code>应用层（Application Layer）
    ↓
图引擎层（Graph Engine Layer）
    ↓
节点层（Node System Layer）
    ↓
基础设施层（Infrastructure Layer）</code></pre><p>每一层的职责都很明确：</p><ul><li><strong>应用层</strong>：提供 API 接口，处理用户请求</li><li><strong>图引擎层</strong>：负责工作流的编排和执行</li><li><strong>节点层</strong>：实现各种能力单元（LLM、工具、知识检索等）</li><li><strong>基础设施层</strong>：提供底层服务（模型调用、向量检索、工具运行时等）</li></ul><p>这样分层的好处是<strong>关注点分离</strong>。比如你要换个 LLM 提供商，只需要改基础设施层；要加个新节点类型，只需要在节点层扩展，不会影响引擎核心逻辑。</p><h4><strong>Graph Engine：整个系统的“心脏”</strong></h4><p>GraphEngine是 AIWorks 工作流引擎的核心调度器，它的职责可以概括为三件事：</p><ul><li>解析前端传入的工作流JSON</li><li>将其编译为可执行的 Graph App</li><li>驱动整个执行生命周期(初始化状态、执行Graph、输出结果并保存状态)</li></ul><p><strong>1. 静态图构建：业务逻辑的“蓝图”</strong></p><p>前端通过拖拽或配置生成的流程，本质上是一份 JSON 描述的 DAG。在 AIWorks中，我们并不会直接将这份 JSON 交给执行引擎，而是定义类Graph对其进行装载和校验，并解析JSON中的节点(Node)和边(Edge)。GraphEngine使用LangGraph作为工作流的执行引擎，GraphEngine将 <code>Graph</code> 对象转换为 LangGraph 提供的 <code>StateGraph</code>，并将Graph中的节点(Node)和边(Edge)动态设置到<code>StateGraph</code>中。</p><p>简化后的核心逻辑如下：</p><pre><code class="python"># 伪代码示意
class GraphEngine:
        def __init__(self, ..., graph: Graph):
        self._graph = graph
        ...
    def _build_graph_app(self, state_context):
            workflow = StateGraph(GraphRuntimeState)
            node_id_config_mapping = self._graph.node_id_config_mapping
            
            # 1. 动态添加节点
            for node_id, node_data in node_config_mapping.items():
                wrapper_node = self._create_command_node(node_id, node_data, state_context)
                workflow.add_node(node_id, wrapper_node)
            # 2. 动态添加边
            for edge in edges:
                workflow.add_edge(edge.source, edge.target)
                
            return workflow.compile()</code></pre><p>StateGraph设置完成后，会调用compile()进行编译，在这个阶段会对整个图进行结构校验，包括是否存在环、是否有孤立节点或不可达节点和节点和边的引用是否完整等。</p><p><strong>2. 异步调度与事件流</strong></p><p>GraphEngine的执行核心并非简单的循环，而是基于 <code>LangGraph</code> 提供的 <code>astream</code> 接口实现的异步事件流处理。事件类型包括FLOW_START、NODE_START、NODE_END、FLOW_END。</p><pre><code class="python"># 伪代码示意
async def _run_workflow(self, inputs: GraphGenerateEntity, enable_run_log: bool):
    graph_app = self._build_graph_app(state_context)
    state = self._init_graph_state(inputs)
    # ... 初始化状态 ...
    yield GraphEvent(event=GraphEventEnum.FLOW_START, run_id=run_id)
    
    # 订阅 LangGraph 的流式输出，关注 "custom" (自定义事件) 和 "tasks" (节点状态)
    event_stream = graph_app.astream(state, stream_mode=["custom", "tasks"])
    
    async for event_tuple in event_stream:
        stream_mode, event_message = event_tuple
        
        # 将 LangGraph 的内部事件转换为 aiworks 的标准 GraphEvent
        if stream_mode == "tasks":
            # 处理节点启动/结束
            yield GraphEvent(event=GraphEventEnum.NODE_START, ...)
        else:
            # 透传自定义事件 (如 LLM Token)
            yield GraphEvent(**event_message)
            
    yield GraphEvent(event=GraphEventEnum.FLOW_END, ...)</code></pre><p><strong>3. 状态持久化</strong></p><p>在工作流执行结束后，引擎会自动进行“快照存档”。这种设计不仅仅是保存 Log，它保存了<strong>完整的运行时状态（GraphRuntimeState）</strong>。这意味着：</p><ul><li><strong>可溯源</strong>：你可以随时打开一个历史运行记录，看到当时图的结构（哪怕现在的图已经改了）以及每个节点的输入输出。</li><li><strong>可恢复（未来及展望）</strong>：这种结构为未来的“断点续跑”和“人工介入”功能打下了数据基础。</li></ul><h4><strong>状态管理（State）：可观测的执行过程</strong></h4><p>工作流执行过程中,最重要的就是状态管理。我们设计了三层状态结构：</p><p><strong>1. 变量池（VariablePool）</strong></p><p>这是整个工作流的"记忆"，存储所有变量：</p><pre><code class="python">class VariablePool(BaseModel):
    user_inputs: dict  # 用户输入的变量
    system_inputs: dict  # 系统变量（如 conversation_id）
    pool: dict  # 节点执行过程中产生的变量</code></pre><p>节点执行时，可以从<strong>pool</strong>中读取前置节点的输出，也可以把自己的输出写入<strong>pool</strong>，供后续节点使用。</p><p><strong>2. 节点状态（NodeState）</strong></p><p>记录每个节点的执行状态：</p><pre><code class="python">class NodeState(BaseModel):
    id: str
    status: NodeStatus  # pending/running/succeeded/failed
    inputs: dict  # 节点输入
    result: dict  # 节点输出
    start_at: datetime
    finished_at: datetime
    error_msg: str</code></pre><p>这里有个细节：<strong>我们会完整记录节点的输入和输出</strong>。这样做的好处是：</p><ul><li><strong>执行回放</strong>：根据 <code>inputs</code> 可以重新执行节点，复现问题</li><li><strong>调试</strong>：可以清楚看到每个节点的输入输出，快速定位问题</li><li><strong>性能分析</strong>：通过 <code>start_at</code> 和 <code>finished_at</code> 计算耗时，找出瓶颈</li></ul><p><strong>3. 工作流运行时状态（GraphRuntimeState）</strong></p><p>整个工作流的全局状态：</p><pre><code>classGraphRuntimeState(BaseModel):
    query:str
    variable_pool: VariablePool
    node_state_mapping: dict[str, NodeState] # 所有节点状态
    routes: dict[str, list[str]] # 实际执行路径
    status: GraphStatus # running/succeeded/failed
    output:str|dict # 最终输出</code></pre><p>执行完成后，我们会把GraphRuntimeState 序列化成 JSON，存储到数据库。这样就有了完整的执行记录，方便后续分析和优化。</p><h3><strong>节点系统：可扩展的能力单元</strong></h3><p>如果说图引擎是工作流的"大脑"，那节点系统就是"四肢"——具体干活的地方。</p><p><strong>1. 节点抽象：模板方法模式的实践</strong></p><p>所有节点都继承自BaseNode，它定义了节点的生命周期：</p><pre><code class="python">class BaseNode:
    def __init__(self, node_id, node_data, user_id, tenant_id, graph):
        self.node_id = node_id
        self.node_data = node_data
        self.init_node()
    
    def init_node(self):
        config = self.resolve_node_data()
        self.init_node_config(config)
    
    @abstractmethod
    def _run(self, state) -&gt; NodeResult:
        raise NotImplementedError
    
    async def run(self, state):
        return await self._run(state)</code></pre><p>这是典型的<strong>模板方法模式</strong>：</p><ul><li><strong>init_node()</strong> 定义了初始化流程</li><li>子类只需要实现 <strong>init_node_config()</strong> 和 <strong>_run()</strong> 两个方法</li></ul><p>这样做的好处是<strong>统一了节点的初始化流程</strong>，子类只需要关注自己的核心逻辑。</p><p><strong>2. 节点概览：工作流的能力单元</strong></p><p><strong>Start 节点：</strong>工作流的入口节点，标识整个流程的起点，每个工作流都必须有一个 Start 节点，它负责接收用户的输入变量，并将它们传递给后续节点。</p><p><strong>LLM 节点：</strong>调用大语言模型进行文本生成、对话、摘要等任务。这是使用最频繁的节点，支持友好的提示词管理、记忆管理、多种LLM提供商等。</p><p><strong>Knowledge Retrieval 节点：</strong>从向量数据库中检索相关知识文档。典型应用场景是 RAG（检索增强生成），先检索相关知识，再传给 LLM 节点进行回答。</p><p><strong>Tool 节点：</strong>工具节点是与外部环境交互的接口，支持内置工具、API工具和自定义工具。</p><p><strong>IF-Else 节点：</strong>根据条件动态选择执行路径, 是实现复杂业务逻辑的关键。支持：</p><ul><li>多种比较操作符（等于、包含、为空等）</li><li>AND / OR 逻辑组合</li><li>多分支（IF / ELIF / ELSE）</li><li>基于变量池中的任意变量做判断</li></ul><p><strong>Code 节点：</strong>执行用户自定义的代码逻辑。适合处理复杂的数据转换、计算逻辑等 LLM 不擅长的任务。</p><p><strong>HTTP 节点：</strong>发起 HTTP 请求，调用外部 API。</p><p><strong>Answer 节点：</strong>格式化最终输出，返回给用户。</p><p><strong>3. 扩展新节点：三步走</strong></p><p>当我们需要新增节点类型时, 流程很简单：</p><p><strong>1）定义配置类</strong>：继承类<strong>BaseNodeConfig</strong></p><pre><code class="python">lass MyNodeConfig(BaseNodeConfig):
    param1: str
    param2: int</code></pre><p><strong>2）实现节点类</strong>：继承<strong>BaseNode</strong></p><pre><code class="python">class MyNode(BaseNode):
    _node_type = NodeType.MY_NODE
    
    def init_node_config(self, valid_config):
        self.node_config = MyNodeConfig(**valid_config)
    
    def _run(self, state):
        # 实现具体逻辑
        return NodeResult(result={...})</code></pre><p>3）<strong>注册节点类型</strong>：在 NodeType 枚举和工厂方法中注册</p><p>这个设计让节点系统具备了很强的扩展性，每个节点并遵守单一原则，这样就能保证新增节点时效率高，还能保持引擎代码的稳定。</p><h2>总结</h2><p>回顾整个工作流引擎的开发过程,最大的感受是：<strong>好的架构设计真的能事半功倍</strong>。</p><p>我们在 AIWorks 中遵循的几个核心理念：</p><ul><li><strong>分层解耦</strong>：图定义、执行引擎、节点实现各自独立</li><li><strong>抽象优先</strong>：基于接口编程,易于扩展</li><li><strong>可观测性</strong>：完整记录执行链路,方便调试和优化</li><li><strong>异步流式</strong>：提升用户体验和系统吞吐</li></ul><p>目前这套系统已经在生产环境中稳定运行，支撑了多个企业级应用。当然,还有很多可以优化的地方：</p><ul><li><strong>可视化调试器</strong>：图形化展示执行流程和状态变化</li><li><strong>分布式执行</strong>：支持大规模工作流的分布式调度</li><li><strong>智能优化</strong>：基于历史数据,自动优化节点配置</li></ul><p>希望这篇文章能对正在做类似系统的同学有所帮助。如果你有任何问题或建议，欢迎留言交流！</p>]]></description></item><item>    <title><![CDATA[【技术分享】xhs_one_spider: 用python开发一站式小红书数据聚合采集软件 马哥天才]]></title>    <link>https://segmentfault.com/a/1190000047553744</link>    <guid>https://segmentfault.com/a/1190000047553744</guid>    <pubDate>2026-01-20 17:12:07</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <blockquote>本工具仅限学术交流使用，严格遵循相关法律法规，符合平台内容的合法及合规性，禁止用于任何商业用途！</blockquote><h2>1. 项目背景与核心功能整合</h2><p><strong>开发初衷</strong></p><p>小红书作为国内头部的社区种草平台，其海量笔记数据蕴含着极高的商业与学术价值。此前，为了满足不同场景的采集需求，我曾分别开发了针对评论、博主主页以及UID转换的三款独立工具。然而，许多用户反馈在处理复杂任务（如同时采集评论和主页笔记）时，频繁切换软件带来了操作上的不便。</p><p>为了解决这一痛点，我将上述三个核心模块进行了深度融合，推出了全新的 <strong>“爬小红书聚合软件v1.0”</strong>。这是一款集成了“评论采集”、“达人笔记采集”及“UID转换”的一体化数据解决方案。</p><p><strong>适用场景</strong></p><p>本工具严格遵循相关法律法规，仅限于学术交流与合规性研究，具体适用场景包括：</p><ul><li><strong>获客截流：</strong> 从行业热门作品评论区精准挖掘目标用户画像。</li><li><strong>舆情分析：</strong> 用于社会舆情挖掘、网络传播规律等学术研究。</li><li><strong>内容优化：</strong> 辅助内容创作者分析优质博主风格与热门话题。</li><li><strong>运营辅助：</strong> 解决跨平台协作中链接与ID转换的痛点。</li></ul><h2>2. 技术架构与实现逻辑</h2><p>本软件完全由 <strong>Python</strong> 语言独立开发，采用模块化设计以保证高效运行与维护。</p><p><strong>核心模块分工</strong></p><table><thead><tr><th align="left">序号</th><th align="left">模块名称</th><th>功能描述</th></tr></thead><tbody><tr><td align="left">1</td><td align="left"><code>tkinter</code></td><td>构建GUI图形用户界面</td></tr><tr><td align="left">2</td><td align="left"><code>requests</code></td><td>负责发送HTTP请求</td></tr><tr><td align="left">3</td><td align="left"><code>json</code></td><td>解析服务器返回的响应数据</td></tr><tr><td align="left">4</td><td align="left"><code>pandas</code></td><td>处理并保存为CSV数据结果</td></tr><tr><td align="left">5</td><td align="left"><code>logging</code></td><td>记录运行日志，便于异常回溯</td></tr></tbody></table><p><strong>核心代码实现</strong></p><p>以下是软件中处理数据请求与保存的关键代码片段：</p><p><em>发送请求与解析：</em></p><pre><code class="python"># 发送请求
r = requests.get(url, headers=h1, params=params)
# 解析数据
json_data = r.json()</code></pre><p><em>数据解析示例（评论内容）：</em></p><pre><code class="python">for c in json_data['data']['comments']: 
    # 评论内容 
    content = c['content'] 
    self.tk_show('评论内容:' + str(content)) 
    content_list.append(content)</code></pre><p><em>数据保存至CSV：</em></p><pre><code class="python"># 保存数据到DF
df = pd.DataFrame( {  
    '笔记链接': 'https://www.xiaohongshu.com/explore/' + note_id,  
    '笔记链接_长': note_url2,  
    '页码': page,  
    '评论者昵称': nickname_list,  
    '评论者id': user_id_list,  
    '评论者主页链接': user_link_list,  
    '评论时间': create_time_list,  
    '评论IP属地': ip_list,  
    '评论点赞数': like_count_list,  
    '评论级别': comment_level_list,  
    '评论内容': content_list, })
# 设置csv文件表头
if os.path.exists(self.result_file3): 
    header = False
else: 
    header = True
# 保存到csv
df.to_csv(self.result_file3, mode='a+', header=header, index=False, encoding='utf_8_sig')
self.tk_show('文件保存成功：' + self.result_file3)</code></pre><p>采用logging模块记录日志运行过程，方便debug回溯场景：</p><pre><code class="python">def get_logger(self):    
    self.logger = logging.getLogger(__name__)    
    # 日志格式
    formatter = '[%(asctime)s-%(filename)s][%(funcName)s-%(lineno)d]--%(message)s'    
    # 日志级别
    self.logger.setLevel(logging.DEBUG)    
    # 控制台日志
    sh = logging.StreamHandler()    
    log_formatter = logging.Formatter(formatter, datefmt='%Y-%m-%d %H:%M:%S')    
    # info日志文件名
    info_file_name = time.strftime("%Y-%m-%d") + '.log'    
    # 将其保存到特定目录
    case_dir = r'./logs/'    
    info_handler = TimedRotatingFileHandler(filename=case_dir + info_file_name,                                        
                                          when='MIDNIGHT',                                        
                                          interval=1,                                        
                                          backupCount=7,                                        
                                          encoding='utf-8')</code></pre><h2>3. 功能详解与数据产出</h2><p>本软件通过接口协议进行数据交互，相比模拟浏览器（RPA）具有更高的稳定性。采集过程中，系统会实时（每页请求间隔1～2s）将数据存入CSV文件，有效防止因网络异常导致的数据丢失。</p><p><strong>功能一：搜索笔记与评论采集</strong></p><p>该模块支持根据关键词或笔记链接采集评论区数据。<img referrerpolicy="no-referrer" src="/img/remote/1460000047553747" alt="在这里插入图片描述" title="在这里插入图片描述"/></p><ul><li><strong>笔记数据字段（19个）：</strong> 包含关键词、笔记ID、标题、正文、点赞/收藏/评论数、发布时间及IP属地等。</li><li><strong>评论数据字段（11个）：</strong> 包含评论者昵称/ID、评论内容、点赞数、IP属地及评论级别等。</li><li><strong>多媒体支持：</strong> 自动下载搜索到的笔记封面图片。</li></ul><p><strong>功能二：博主主页笔记采集</strong></p><p>支持根据博主主页链接批量抓取其发布的历史笔记。<img referrerpolicy="no-referrer" src="/img/remote/1460000047553748" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><ul><li><strong>采集字段（18个）：</strong> 包含作者信息、笔记ID、链接、类型、互动数据及正文内容等。</li><li><strong>结果展示：</strong> 生成结构化的CSV文件及对应的图片素材包。</li></ul><p><strong>功能三：UID与链接转换工具</strong></p><p>提供高频使用的转换功能，无需打开网页即可完成：<img referrerpolicy="no-referrer" src="/img/remote/1460000047553749" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><ol><li>主页链接 $\leftrightarrow$ 小红书号（xhs号）互转。</li><li>App端作品链接 $\rightarrow$ PC端作品链接转换。</li></ol><h2>4. 使用指南</h2><p>前置准备</p><ul><li>在开始采集前，用户需获取并填写自己的Cookie值。</li><li>打开浏览器开发者工具（F12），复制Cookie值。</li><li>将其粘贴至软件同级目录下的 cookie.txt 文件中。</li></ul><p>操作流程</p><ul><li>登录界面： 启动软件并完成登录验证。</li><li>选择模块： 根据需求选择“搜索采集”、“主页采集”或“转换工具”。</li><li>配置参数： 填写关键词、时间范围或博主链接等信息。</li><li>执行任务： 点击「开始执行」，实时监控进度条。</li><li>查看结果： 任务完成后，在软件所在文件夹查看生成的CSV文件及图片文件夹。</li></ul><h2>5.演示视频</h2><p>为了方便用户上手，附带了完整的操作演示视频:</p><blockquote>mp.weixin.qq.com/s/t9cKGsgJoI9rca3I1w5RdA</blockquote><h2>END. 版权声明</h2><p>本软件及文章均为本人独立原创开发与编写。请尊重原创成果，严禁任何形式的二创、转载或盗发，违者必究！</p>]]></description></item><item>    <title><![CDATA[FlowyAIPC v4.0.5 正式发布文生图功能，本地 AI 创作再进一步 FlowyAIPC ]]></title>    <link>https://segmentfault.com/a/1190000047553838</link>    <guid>https://segmentfault.com/a/1190000047553838</guid>    <pubDate>2026-01-20 17:11:14</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>【2026年01月19日】 <strong>FlowyAIPC</strong> 现已更新至 <strong>v4.0.5</strong> 版本。本次更新聚焦于 AI 创作体验与本地推理使用门槛的优化，带来了全新的 <strong>文生图功能</strong>，同时对 WinML NPU 系列模型的使用引导进行了加强，让更多用户可以更清楚、更安心地使用本地 AI 能力。</p><h3>新功能上线：文生图（Text to Image）</h3><p>在 v4.0.5 中，<strong>FlowyAIPC</strong> 正式支持 文生图功能。用户只需输入文字描述，即可生成对应图片，用于创意设计、内容配图、灵感草稿等多种场景。</p><p><strong>FlowyAIPC</strong>文生图功能具有更丰富的生成控制能力，包括：</p><ul><li><ul><li><strong>支持设置生成风格</strong>（如人像摄影、经典日漫、赛博朋克等）</li><li><strong>支持自定义图片比例</strong>（如1:1、3:2、9:16等），适配不同使用场景</li><li>同时支持 <strong>本地模型生成 与 云端模型生成</strong></li></ul></li></ul><p>其中，本地文生图基于 <strong>Z-image 模型</strong>，生成过程在本地完成，更加注重数据可控性与隐私安全。</p><p><img width="723" height="436" referrerpolicy="no-referrer" src="/img/bVdnG5v" alt="" title=""/><br/>⚠️ 文生图功能使用说明（请务必查看）</p><blockquote>FlowyAIPC本地文生图最低配置：Intel Core Ultra系列芯片 + 内存 32GB 及以上</blockquote><p>如果设备暂不满足本地文生图功能最低配置，也可直接使用云端文生图模式，无需额外配置即可体验完整功能。</p><p><strong>FlowyAIPC文生图效果展示</strong></p><p><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdnG5w" alt="" title="" loading="lazy"/></p><h3>WinML · NPU 模型使用引导优化</h3><p>在 v4.0.5 版本中，<strong>FlowyAIPC</strong> 还针对 WinML 的 NPU 系列模型 增加了更多用户引导与提醒，包括硬件适配提示、使用条件说明等，帮助用户在使用本地模型时更清楚地了解设备支持情况，降低上手成本，减少试错。</p><p><img width="723" height="434" referrerpolicy="no-referrer" src="/img/bVdnG5x" alt="" title="" loading="lazy"/></p><p>FlowyAIPC 将持续围绕 <strong>本地 AI、可控数据、真实效率提升</strong>不断迭代与完善。  <br/>欢迎大家更新至 <strong>v4.0.5</strong>，体验全新的文生图能力，也欢迎在使用过程中向我们反馈你的建议。</p><p><strong>访问FlowyAIPC官网：<a href="https://link.segmentfault.com/?enc=q35FFJeau9oiWt0HFRwp4w%3D%3D.sT34oRGgDmVG5dpGEscN3mhHPhe8ckaE1Y78u4WM0Iw%3D" rel="nofollow" target="_blank">www.flowyaipc.cn</a></strong></p>]]></description></item><item>    <title><![CDATA[深度解析：索引式文档看板工具如何重构我们的信息处理逻辑 NAVI_s1mple ]]></title>    <link>https://segmentfault.com/a/1190000047553870</link>    <guid>https://segmentfault.com/a/1190000047553870</guid>    <pubDate>2026-01-20 17:10:19</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>想象一下，当你的团队启动一个跨部门项目，成员面对的是散落在各个云盘的零碎方案、埋没在邮件往来里的旧版合同，以及存储在个人对话框里语焉不详的参考资料。</p><p>新加入的成员不停地询问“那个文档在哪里”，而负责人则在反复发送文件的琐事中被打断得心力交瘁。每次决策的质量全看员工搜索信息的速度，而非组织的整体智慧。这正是现代团队面临的**“信息黑盒”**困境：文档无法索引，内容无法聚合。</p><h3><strong>01 导语：协同力的瓶颈，是知识资产的断层</strong></h3><p>在信息爆炸的办公环境中，团队的核心挑战已从“如何产生内容”转向了“如何快速检索内容”。<strong>索引式文档看板工具</strong>的缺失，已成为影响团队响应速度的隐形障碍。</p><p>研究表明，职场人平均每天有 <strong>20% 以上</strong>的工作时间浪费在跨平台寻找文档和重复确认信息上。当一个组织的工作高度依赖于“个人记忆”而非“数字化索引”时，这种碎片化所带来的隐性成本——包括决策迟缓、沟通内耗和因信息差导致的执行错误——远超业务层面的竞争。</p><h3><strong>02 协作低效的根源：不是员工不专业，而是缺乏“内容图谱”</strong></h3><p>许多团队尝试用传统的文件夹或即时通讯软件来分发文档，却发现效果不佳。问题的核心不在于没有存储，而在于内容的<strong>非结构化</strong>与<strong>割裂化</strong>。</p><ul><li><strong>存储散乱：</strong> 文档被锁在不同的云盘和本地路径，没人能一眼看到全局。</li><li><strong>缺乏脉络：</strong> 纯粹的文件名无法体现文档间的逻辑关联，查找过程像大海捞针。</li><li><strong>版本失控：</strong> 资料在传递中产生无数副本，确保团队拿到的是“最终版”成了难题。</li></ul><p><strong>索引式文档看板工具</strong>（如板栗看板）的价值在于：它将“文档存储”与“视觉看板”完美结合。</p><h3><strong>03 板栗看板：打通知识经络的系统解药</strong></h3><p>作为一款领先的索引式文档看板工具，<strong>板栗看板</strong>的核心价值在于将海量文档“索引化”与“场景化”。它不仅是一个存储空间，更是一个知识分发引擎。</p><p>这类工具的核心功能通常包括：</p><ul><li><strong>卡片式文档索引：</strong> 将每个文档封装为可视化卡片，通过封面和标签一目了然。</li><li><strong>多维属性标注：</strong> 为文档附加时间、负责人、密级等元数据，实现精准过滤。</li><li><strong>看板逻辑组织：</strong> 按项目阶段或业务模块排列文档，呈现完整的知识图谱。</li><li><strong>全量资产检索：</strong> 随着项目演进自动积累文档资产，确保团队随时获取最全的资料库。</li></ul><h3>---</h3><p><strong>04 索引式文档看板的多维应用场景</strong></p><p><strong>索引式文档看板工具</strong>在不同场景中能产生极大的降本增效作用：</p><ul><li><strong>项目交付的“资产包”：</strong> 通过板栗看板建立交付索引，客户或接手人可以对照看板快速调阅所有技术规格、设计图纸和验收报告。</li><li><strong>品牌资源“中央库”：</strong> 将海量视觉VI、宣传视频分类索引到看板节点，确保全渠道输出的物料始终保持版本一致。</li><li><strong>政策制度“百科全书”：</strong> 企业规章、合规文档通过索引式展示，员工通过关键词即可快速触达对应的细则，提升合规意识。</li><li><strong>竞品情报“情报墙”：</strong> 所有的调研报告、市场反馈实时索引留痕，清晰还原竞争态势，辅助战略决策。</li></ul><h3><strong>05 构建索引式看板体系的四个步骤</strong></h3><p>实施文档索引化不是简单的上传，需要遵循科学的路径：</p><ol><li><strong>梳理知识架构：</strong> 找出那些被调用最频繁、对决策影响最大或最容易丢失的关键文档类型。</li><li><strong>确立索引规则：</strong> 制定统一的命名规范和标签体系，将专家的整理逻辑转化为可复制的检索路径。</li><li><strong>载入板栗看板：</strong> 利用软件的看板结构将文档“切片化”，并配备必要的逻辑说明（Metadata）。</li><li><strong>持续维护更新：</strong> 随着业务演进发现索引偏差时，立即调整节点，实现内容资产的动态生长。</li></ol><h3><strong>06 主流文档看板与协作工具对比</strong></h3><table><thead><tr><th align="left">工具类别</th><th align="left">代表平台</th><th align="left">核心优势</th><th align="left">适用场景</th></tr></thead><tbody><tr><td align="left"><strong>索引式看板软件</strong></td><td align="left"><strong>板栗看板</strong></td><td align="left"><strong>文档与逻辑深度结合，可视化程度高</strong></td><td align="left"><strong>项目交付、资产管理、知识索引</strong></td></tr><tr><td align="left">云端网盘平台</td><td align="left">百度网盘、Dropbox</td><td align="left">存储空间大，适合海量原始文件堆放</td><td align="left">个人备份、超大文件存储</td></tr><tr><td align="left">文档知识库</td><td align="left">Notion, 语雀</td><td align="left">文本结构化强，适合创作长文</td><td align="left">文档协作、个人笔记</td></tr><tr><td align="left">传统文件服务器</td><td align="left">NAS、共享盘</td><td align="left">局域网传输快</td><td align="left">内部局域网文件共享</td></tr></tbody></table><h3><strong>07 技术实现示例：自动化索引关联</strong></h3><p>利用 Python，我们可以实现当新文档上传时，自动在板栗看板中生成对应的索引卡片并分类：</p><p>Python</p><p>class IndexManager:</p><pre><code>def \_\_init\_\_(self):    
    self.categories \= {    
        "Marketing\_Assets": \["宣传册.pdf", "Logo源文件.ai", "海报.psd"\],    
        "Tech\_Specs": \["需求文档.docx", "架构图.png", "测试报告.xlsx"\]    
    }    
    
def create\_index(self, doc\_name, category\_type):    
    \# 模拟自动在板栗看板创建文档索引卡片    
    docs \= self.categories.get(category\_type, \[\])    
    print(f"收录文档：{doc\_name}")    
    for doc in docs:    
        print(f"  \- 自动生成索引标签及关联属性：{doc}")    
    return "文档索引关联成功"
</code></pre><h3><strong>08 实施中的常见误区与解决方案</strong></h3><table><thead><tr><th align="left">常见误区</th><th align="left">实际影响</th><th align="left">优化策略</th></tr></thead><tbody><tr><td align="left"><strong>索引分类过于繁琐</strong></td><td align="left">员工不愿维护，增加录入负担</td><td align="left">遵循“极简主义”，只标注最核心的检索维度</td></tr><tr><td align="left"><strong>只存不管无人维护</strong></td><td align="left">索引与内容脱节，变成死库</td><td align="left">强制要求在<strong>板栗看板</strong>等看板中同步更新最新资产</td></tr><tr><td align="left"><strong>权限设置过于封闭</strong></td><td align="left">信息无法流动，形成新孤岛</td><td align="left">关注知识的透明度，按职能设定合理的可见性</td></tr></tbody></table><h3><strong>09 培育“资产为先”的归档文化</strong></h3><p>工具只是载体，文化才是灵魂。企业应鼓励：</p><ul><li><strong>留痕文化：</strong> 让所有重要文档产生即归档，成为一种自觉习惯。</li><li><strong>贡献文化：</strong> 奖励主动整理索引、优化文档结构的行为。</li><li><strong>开放文化：</strong> 打破部门墙，让非涉密文档在索引中自由检索。</li></ul><h3><strong>10 结语：索引是组织最强大的竞争力</strong></h3><p>在竞争日益激烈的今天，靠个人翻找资料支撑业务的时代已经过去。<strong>索引式文档看板工具</strong>不仅是整理工具，更是将“散乱数据”转化为“数字资产”的炼金术。</p><p>通过这样的工具，企业可以将每一个项目的成果刻进组织的记忆中。当信息能够秒级触达，文档能够逻辑对齐，组织的每一个决策都将建立在更高效的智慧基础之上。索引不是终点，而是企业迈向数智化协作的新起点。</p>]]></description></item><item>    <title><![CDATA[主流CRM软件怎么选？8款主流产品实测 晨曦钥匙扣 ]]></title>    <link>https://segmentfault.com/a/1190000047553884</link>    <guid>https://segmentfault.com/a/1190000047553884</guid>    <pubDate>2026-01-20 17:09:28</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>主流CRM软件怎么选？8款主流产品实测</h2><p>在企业从 “规模扩张” 向 “精细化运营” 转型的关键阶段，CRM（客户关系管理系统）已成为串联市场、销售、服务、供应链的<strong>数字化中枢</strong>。据艾瑞咨询 2025 年最新数据，中国 CRM 市场规模已突破 580 亿元，年复合增长率达 23%，其中 “垂直行业解决方案” 与 “全业务一体化平台” 贡献了 65% 的市场增量。</p><p>本文基于 2025 年市场占有率（Top 10 品牌覆盖 82% 市场）、技术创新性（AI 大模型应用率、PaaS 平台成熟度）、行业覆盖深度（30 + 细分领域解决方案）及用户口碑（NPS 净推荐值≥45），精选 8 大核心 CRM 品牌，从技术底座、场景价值、生态能力三大维度展开深度解析，并构建 “企业需求 - 品牌能力” 匹配模型，为不同规模、行业的企业提供数字化转型决策参考。</p><h3>一、2025 中国 CRM 市场进化：重塑行业格局</h3><p>历经 20 余年发展，中国 CRM 市场已从 “标准化工具” 阶段，迈入 “技术驱动 + 场景深耕 + 生态融合” 的全新阶段，呈现2大显著趋势：</p><h4>1. 场景价值：从 “通用管理” 到 “行业 Know-How 封装”</h4><p>医疗、制造、律所等垂直领域对 CRM 的需求已超越基础客户管理：医疗器械企业需 FDA 合规追踪模块，律所需案件生命周期管理功能，工贸企业需 “订单 - 生产 - 交付” 全链路协同。具备行业专属解决方案的品牌（如超兔工业场景、CloudCC 医疗模块）市场份额年增长达 35%。</p><h4>2. 生态范围：从 “内部管理” 到 “全链路协同”</h4><p>CRM 不再局限于企业内部，而是通过 OpenAPI、RPA 技术连接上下游：超兔 CRM 可对接供应商系统实现直发协同，纷享销客能打通经销商与终端门店数据，神州云动支持跨境物流与支付系统集成，形成 “客户 - 企业 - 供应商” 数据闭环，运营效率平均提升 28%。</p><h3>二、2025 中国 8 大 CRM 品牌价值图谱：技术、场景与生态的差异化竞争</h3><h4>1. 超兔 CRM：工贸企业的全业务数字化底座</h4><p><strong>核心定位</strong>：聚焦工业、工贸类中小企业，提供 “CRM + 进销存 + 财务 + 生产” 全业务一体化解决方案，目前服务 6 万 + 企业，40% 新客户来自老客户转介绍。</p><p><strong>差异化优势</strong>：</p><ul><li><strong>一体云架构</strong>：底层打通 12 大业务模块，销售订单可自动触发采购计划与生产排程，某机械制造企业使用后，跨部门数据同步时间从 2 小时压缩至实时，订单交付周期缩短 25%；</li><li><strong>低成本定制引擎</strong>：6 大零代码工具（功能白名单、三级菜单自定义等）支持 “小步快跑” 式调整，年定制成本较传统 CRM 降低 60%；</li><li><strong>AI 业务赋能</strong>：AI 跟单智能体可生成客户跟进话术，Coze 工作流支持自然语言创建自动化任务（如 “每周一提醒跟进 90 天未复购客户”），某电子元件厂商销售效率提升 30%。</li></ul><p><strong>适配画像</strong>：50-500 人工贸 / 制造企业（机械加工、五金批发、医疗器械），需全业务流程数字化、降低跨部门协作成本的场景。</p><h4>2. CloudCC CRM：垂直行业的 PaaS 平台专家</h4><p><strong>核心定位</strong>：为 30 + 行业提供 “PaaS 平台 + 行业化 CRM” 解决方案，在医疗、律所、教育领域解决方案成熟度位居行业前列。</p><p><strong>差异化优势</strong>：</p><ul><li><strong>第三代</strong> <strong>PaaS</strong> <strong>技术</strong>：支持内存计算与云计算协同，实时处理 20TB 级客户数据，区域销售额动态 ROI 计算仅需 3 秒，满足企业 “秒级决策” 需求；</li><li><strong>行业模块封装</strong>：医疗行业内置医院招标周期管理、患者随访跟踪功能；律所定制案件证据链管理、回款追踪模块；教育行业开发学员生命周期追踪系统，某中闻律所使用后案件管理效率提升 45%；</li><li><strong>生态扩展能力</strong>：开放 600+API 接口，可对接 ERP、财务、物流系统，某跨境医疗企业借此实现 “客户咨询 - 合规审批 - 设备交付” 全链路协同。</li></ul><p><strong>适配画像</strong>：中大型企业（医疗、律所、教育），需深度行业解决方案与高扩展性平台的场景。</p><h4>3. 八百客 800APP-CRM：组织协同的效率加速器</h4><p><strong>核心定位</strong>：以 “社交化协同” 为核心，推动 CRM 从 “客户管理” 向 “企业内部协作” 延伸，适配跨部门协同需求强烈的企业。</p><p><strong>差异化优势</strong>：</p><ul><li><strong>社交化工作流</strong>：内置即时通讯、文档协作、任务共享功能，销售可直接 @技术支持加入客户会议，某科技企业跨部门协作效率提升 38%；</li><li><strong>低代码开发</strong>：业务人员可自主搭建定制模块（如设备巡检记录、客户满意度调研），无需技术团队支持，系统扩展周期缩短至 1 周；</li><li><strong>移动协同体验</strong>：移动端支持离线数据录入、扫码查询客户信息，外勤团队日均工作效率提升 40%。</li></ul><p><strong>适配画像</strong>：中大型企业（科技、制造），需跨部门协同（市场 - 销售 - 技术）与快速功能扩展的场景。</p><h4>4. 用友 TurboCRM：集团企业的定制化专家</h4><p><strong>核心定位</strong>：面向年营收 10 亿 + 的集团型企业，提供 “CRM+ERP” 深度集成解决方案，支持多事业部、多区域协同管理。</p><p><strong>差异化优势</strong>：</p><ul><li><strong>集团化架构</strong>：九级组织权限管理、矩阵式项目组配置，满足大型企业多事业部数据隔离与协同需求，某汽车制造集团借此实现 “总部战略 - 区域执行 - 终端反馈” 闭环；</li><li><strong>行业标准化路径</strong>：制造业内置供应链协同、经销商管理模块；零售行业开发连锁门店库存同步、促销活动监控功能；能源行业定制客户用能分析、设备维护提醒系统；</li><li><strong>数据安全保障</strong>：私有化部署选项与三级数据加密，符合金融、能源等敏感行业合规要求，某能源集团使用后客户数据安全等级提升至国家等保三级。</li></ul><p><strong>适配画像</strong>：集团型企业（汽车制造、能源、连锁零售），需多组织协同与高数据安全的场景。</p><h4>5. 纷享销客：渠道管理的连接型标杆</h4><p><strong>核心定位</strong>：聚焦快消、农牧、食品饮料行业，构建 “品牌商 - 经销商 - 终端门店” 全渠道数据协同平台。</p><p><strong>差异化优势</strong>：</p><ul><li><strong>渠道数据贯通</strong>：经销商 APP 实时上传库存与销售数据，终端门店小程序采集消费者反馈，品牌商可动态调控供货计划，某食品饮料企业借此将渠道库存周转效率提升 30%；</li><li><strong>营销活动赋能</strong>：支持经销商自主发起区域促销活动，总部实时监控活动效果并分配资源，某农资企业通过该功能将经销商促销转化率提升 25%；</li><li><strong>行业化报表</strong>：快消行业专属 “动销率分析”“终端铺货率追踪” 报表，帮助品牌商精准掌握市场动态。</li></ul><p><strong>适配画像</strong>：中大型快消、农牧企业，依赖经销商网络且需实时渠道数据的场景。</p><h4>6. 销售易：高客单价行业的 AI 智能专家</h4><p><strong>核心定位</strong>：为高客单价、长周期销售行业（IT 服务、工业设备）提供 “AI+CRM” 解决方案，聚焦商机转化效率提升。</p><p><strong>差异化优势</strong>：</p><ul><li><strong>AI 商机预测</strong>：基于历史成交数据构建预测模型，精准识别高价值线索（准确率≥85%），某 IT 服务企业借此将销售精力聚焦在成单概率高的客户上，成交周期缩短 22%；</li><li><strong>多角色协同</strong>：销售、技术、交付团队在同一商机下共享数据，技术方案修改可实时同步给客户，某工业设备企业使用后客户沟通成本降低 35%；</li><li><strong>客户成功管理</strong>：内置客户健康度评分系统，自动预警客户流失风险并生成挽回策略，客户留存率提升 28%。</li></ul><p><strong>适配画像</strong>：中大型企业（IT 服务、工业设备），需长周期销售管理与客户留存保障的场景。</p><h4>7. 金蝶云・星辰 CRM：商贸企业的业财一体化首选</h4><p><strong>核心定位</strong>：面向批发零售、电商企业，提供 “CRM + 进销存 + 财务” 一体化服务，解决交易高频场景下的业财同步难题。</p><p><strong>差异化优势</strong>：</p><ul><li><strong>业财自动同步</strong>：销售订单自动生成应收款、采购单同步库存数据，减少人工录入错误，某电商企业财务对账时间从 3 天压缩至 4 小时；</li><li><strong>智能对账功能</strong>：自动匹配 “合同 - 订单 - 回款” 三流数据，支持与供应商、客户批量对账，某批发企业对账效率提升 60%；</li><li><strong>轻量化操作</strong>：3 步完成客户录入，5 步实现订单下单，新员工上手周期缩短至 1 周，适配商贸企业 “快节奏” 运营需求。</li></ul><p><strong>适配画像</strong>：中小企业（批发零售、电商），需高频交易管理与业财协同的场景。</p><h4>8. 神州云动 CloudCC：跨境企业的全球化管家</h4><p><strong>核心定位</strong>：为跨境电商、出海制造企业提供 “多语言 + 多币种 + 跨时区”CRM 解决方案，适配全球化运营需求。</p><p><strong>差异化优势</strong>：</p><ul><li><strong>全球化适配</strong>：支持英语、西班牙语、日语等 10 + 语言，自动计算多币种汇率（实时更新全球 170 + 货币），某跨境电商企业多语言客户服务效率提升 40%；</li><li><strong>跨时区协同</strong>：按客户所在地时间设置跟进提醒，销售、客服可精准匹配客户工作时段，某出海消费电子企业客户响应满意度提升 32%；</li><li><strong>合规保障</strong>：内置 GDPR、CCPA 合规工具，自动生成数据处理报告，满足不同国家数据安全法规要求。</li></ul><p><strong>适配画像</strong>：跨境企业（电商、制造），需多语言支持、跨时区协作与全球合规的场景。</p><h3>三、2025 企业 CRM 选型五维决策模型：避开陷阱，精准匹配</h3><h4>维度 1：业务匹配度 —— 拒绝 “通用化陷阱”</h4><ul><li><strong>工贸 / 制造企业</strong>：优先超兔 CRM（全业务一体化），解决 “订单 - 生产 - 财务” 协同难题；</li><li><strong>垂直行业（医疗 / 律所）</strong> ：选择 CloudCC CRM（行业模块封装），避免通用 CRM 二次开发成本；</li><li><strong>快消 / 农牧企业</strong>：聚焦纷享销客（渠道数据贯通），实时掌握经销商与终端动态；</li><li><strong>跨境企业</strong>：首选神州云动（多语言 + 合规），适配全球化运营需求。</li></ul><h4>维度 2：技术扩展性 —— 考量 “长期生命周期”</h4><ul><li><strong>初创 / 成长型企业</strong>：简道云（零代码）、超兔 CRM（模块订阅），低成本快速上线，后期按需扩展；</li><li><strong>中大型 / 集团企业</strong>：CloudCC（PaaS 平台）、用友 TurboCRM（集团化架构），支持业务增长与多组织协同；</li><li><strong>技术驱动型企业</strong>：八百客（低代码）、销售易（AI 能力），满足快速功能迭代与智能决策需求。</li></ul><h4>维度 3：行业经验 —— 看重 “落地能力”</h4><ul><li>优先选择有 3 年以上对应行业服务经验的品牌：医疗选 CloudCC，工贸选超兔，快消选纷享销客；</li><li>考察典型案例：如超兔服务 6 万 + 工贸企业，用友 TurboCRM 合作多家汽车制造集团，确保解决方案可落地。</li></ul><h4>维度 4：成本效益 —— 平衡 “投入与回报”</h4><table><thead><tr><th>品牌名称</th><th>适用规模</th><th>年均成本区间</th><th>成本优势</th><th>避免误区</th></tr></thead><tbody><tr><td>超兔 CRM</td><td>工贸中小企业</td><td>1-2 万元</td><td>模块订阅，无冗余功能收费</td><td>无需为不使用的生产模块付费</td></tr><tr><td>CloudCC CRM</td><td>中大型企业</td><td>10-30 万元</td><td>行业模块内置，减少开发成本</td><td>避免通用版 + 二次开发的高投入</td></tr><tr><td>纷享销客</td><td>中大型快消企业</td><td>8-20 万元</td><td>渠道功能全，无需额外采购</td><td>无需买通用版再定制渠道模块</td></tr><tr><td>神州云动</td><td>跨境企业</td><td>5-15 万元</td><td>多语言合规内置，省合规成本</td><td>避免后期添加语言包的额外费用</td></tr></tbody></table><h4>维度 5：生态兼容性 —— 确保 “系统协同”</h4><ul><li>已使用用友 ERP 的企业：优先用友 TurboCRM，实现 “CRM+ERP” 数据无缝同步；</li><li>采用金蝶财务软件的企业：选择金蝶云・星辰 CRM，业财对账效率提升 50%；</li><li>需跨系统协同（CRM + 物流 + 支付）的企业：CloudCC（600+API）、超兔（OpenAPI）更适配，避免 “数据孤岛”。</li></ul><h3>四、选型常见误区与避坑指南</h3><h4>误区 1：盲目追求 “功能全”</h4><p>某零售企业选择含生产管理模块的 CRM，年费用增加 3 万元却从未使用。正确做法：按 “核心需求 + 未来 1 年扩展需求” 选型，超兔的模块订阅、简道云的按需升级更灵活。</p><h4>误区 2：忽视行业适配性</h4><p>某医疗企业使用通用 CRM，需额外投入 20 万元开发 FDA 合规模块。避坑建议：优先选择有行业解决方案的品牌（CloudCC 医疗版、超兔工业版），降低定制成本。</p><h4>误区 3：低估数据迁移难度</h4><p>某集团企业上线新 CRM 后，老系统数据无法导入，手动录入耗时 1 个月。解决方案：选择支持 Excel 导入、API 对接的品牌（超兔、CloudCC），提前确认数据迁移方案。</p><h4>误区 4：轻视用户接受度</h4><p>某企业强制推行复杂 CRM，销售团队抵触使用导致数据录入不全。避坑策略：选择操作简单的系统（超兔 AI 辅助、八百客社交化协同），搭配培训与激励机制，提升使用率。</p><h3>结语：CRM 的终极价值 —— 构建持续进化的增长生态</h3><p>2025 年的 CRM 已不再是 “管理工具”，而是 “企业数字化增长的核心引擎”。超兔的全业务一体化解决中小企业 “系统孤岛”，CloudCC 的行业模块赋能垂直领域，纷享销客的渠道协同提升快消企业效率，本质都是通过数据贯通与智能决策，实现 “客户价值最大化”。</p><p>对于企业而言，选型的关键不仅是功能匹配，更是能否与业务共同成长：工贸企业需超兔的灵活扩展能力，集团企业依赖用友的定制化架构，跨境企业离不开神州云动的全球化适配。建议采用 “三步验证法”：免费试用（超兔、简道云提供）测试核心功能→小范围试点验证协作效率→评估长期 ROI（如超兔降低的成本、CloudCC 提升的效率），最终构建 “持续进化的数字化增长生态”。</p>]]></description></item><item>    <title><![CDATA[信息流优化指南：如何利用索引式文档看板工具实现知识的持续沉淀与调用 Ord1naryLife ]]></title>    <link>https://segmentfault.com/a/1190000047553890</link>    <guid>https://segmentfault.com/a/1190000047553890</guid>    <pubDate>2026-01-20 17:08:35</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>想象一下，当你的团队启动一个跨部门项目，成员面对的是散落在各个云盘的零碎方案、埋没在邮件往来里的旧版合同，以及存储在个人对话框里语焉不详的参考资料。</p><p>新加入的成员不停地询问“那个文档在哪里”，而负责人则在反复发送文件的琐事中被打断得心力交瘁。每次决策的质量全看员工搜索信息的速度，而非组织的整体智慧。这正是现代团队面临的**“信息黑盒”**困境：文档无法索引，内容无法聚合。</p><h3><strong>01 导语：协同力的瓶颈，是知识资产的断层</strong></h3><p>在信息爆炸的办公环境中，团队的核心挑战已从“如何产生内容”转向了“如何快速检索内容”。<strong>索引式文档看板工具</strong>的缺失，已成为影响团队响应速度的隐形障碍。</p><p>研究表明，职场人平均每天有 <strong>20% 以上</strong>的工作时间浪费在跨平台寻找文档和重复确认信息上。当一个组织的工作高度依赖于“个人记忆”而非“数字化索引”时，这种碎片化所带来的隐性成本——包括决策迟缓、沟通内耗和因信息差导致的执行错误——远超业务层面的竞争。</p><h3><strong>02 协作低效的根源：不是员工不专业，而是缺乏“内容图谱”</strong></h3><p>许多团队尝试用传统的文件夹或即时通讯软件来分发文档，却发现效果不佳。问题的核心不在于没有存储，而在于内容的<strong>非结构化</strong>与<strong>割裂化</strong>。</p><ul><li><strong>存储散乱：</strong> 文档被锁在不同的云盘和本地路径，没人能一眼看到全局。</li><li><strong>缺乏脉络：</strong> 纯粹的文件名无法体现文档间的逻辑关联，查找过程像大海捞针。</li><li><strong>版本失控：</strong> 资料在传递中产生无数副本，确保团队拿到的是“最终版”成了难题。</li></ul><p><strong>索引式文档看板工具</strong>（如板栗看板）的价值在于：它将“文档存储”与“视觉看板”完美结合。</p><h3><strong>03 板栗看板：打通知识经络的系统解药</strong></h3><p>作为一款领先的索引式文档看板工具，<strong>板栗看板</strong>的核心价值在于将海量文档“索引化”与“场景化”。它不仅是一个存储空间，更是一个知识分发引擎。</p><p>这类工具的核心功能通常包括：</p><ul><li><strong>卡片式文档索引：</strong> 将每个文档封装为可视化卡片，通过封面和标签一目了然。</li><li><strong>多维属性标注：</strong> 为文档附加时间、负责人、密级等元数据，实现精准过滤。</li><li><strong>看板逻辑组织：</strong> 按项目阶段或业务模块排列文档，呈现完整的知识图谱。</li><li><strong>全量资产检索：</strong> 随着项目演进自动积累文档资产，确保团队随时获取最全的资料库。</li></ul><h3>---</h3><p><strong>04 索引式文档看板的多维应用场景</strong></p><p><strong>索引式文档看板工具</strong>在不同场景中能产生极大的降本增效作用：</p><ul><li><strong>项目交付的“资产包”：</strong> 通过板栗看板建立交付索引，客户或接手人可以对照看板快速调阅所有技术规格、设计图纸和验收报告。</li><li><strong>品牌资源“中央库”：</strong> 将海量视觉VI、宣传视频分类索引到看板节点，确保全渠道输出的物料始终保持版本一致。</li><li><strong>政策制度“百科全书”：</strong> 企业规章、合规文档通过索引式展示，员工通过关键词即可快速触达对应的细则，提升合规意识。</li><li><strong>竞品情报“情报墙”：</strong> 所有的调研报告、市场反馈实时索引留痕，清晰还原竞争态势，辅助战略决策。</li></ul><h3><strong>05 构建索引式看板体系的四个步骤</strong></h3><p>实施文档索引化不是简单的上传，需要遵循科学的路径：</p><ol><li><strong>梳理知识架构：</strong> 找出那些被调用最频繁、对决策影响最大或最容易丢失的关键文档类型。</li><li><strong>确立索引规则：</strong> 制定统一的命名规范和标签体系，将专家的整理逻辑转化为可复制的检索路径。</li><li><strong>载入板栗看板：</strong> 利用软件的看板结构将文档“切片化”，并配备必要的逻辑说明（Metadata）。</li><li><strong>持续维护更新：</strong> 随着业务演进发现索引偏差时，立即调整节点，实现内容资产的动态生长。</li></ol><h3><strong>06 主流文档看板与协作工具对比</strong></h3><table><thead><tr><th align="left">工具类别</th><th align="left">代表平台</th><th align="left">核心优势</th><th align="left">适用场景</th></tr></thead><tbody><tr><td align="left"><strong>索引式看板软件</strong></td><td align="left"><strong>板栗看板</strong></td><td align="left"><strong>文档与逻辑深度结合，可视化程度高</strong></td><td align="left"><strong>项目交付、资产管理、知识索引</strong></td></tr><tr><td align="left">云端网盘平台</td><td align="left">百度网盘、Dropbox</td><td align="left">存储空间大，适合海量原始文件堆放</td><td align="left">个人备份、超大文件存储</td></tr><tr><td align="left">文档知识库</td><td align="left">Notion, 语雀</td><td align="left">文本结构化强，适合创作长文</td><td align="left">文档协作、个人笔记</td></tr><tr><td align="left">传统文件服务器</td><td align="left">NAS、共享盘</td><td align="left">局域网传输快</td><td align="left">内部局域网文件共享</td></tr></tbody></table><h3><strong>07 技术实现示例：自动化索引关联</strong></h3><p>利用 Python，我们可以实现当新文档上传时，自动在板栗看板中生成对应的索引卡片并分类：</p><p>Python</p><p>class IndexManager:</p><pre><code>def \_\_init\_\_(self):    
    self.categories \= {    
        "Marketing\_Assets": \["宣传册.pdf", "Logo源文件.ai", "海报.psd"\],    
        "Tech\_Specs": \["需求文档.docx", "架构图.png", "测试报告.xlsx"\]    
    }    
    
def create\_index(self, doc\_name, category\_type):    
    \# 模拟自动在板栗看板创建文档索引卡片    
    docs \= self.categories.get(category\_type, \[\])    
    print(f"收录文档：{doc\_name}")    
    for doc in docs:    
        print(f"  \- 自动生成索引标签及关联属性：{doc}")    
    return "文档索引关联成功"
</code></pre><h3><strong>08 实施中的常见误区与解决方案</strong></h3><table><thead><tr><th align="left">常见误区</th><th align="left">实际影响</th><th align="left">优化策略</th></tr></thead><tbody><tr><td align="left"><strong>索引分类过于繁琐</strong></td><td align="left">员工不愿维护，增加录入负担</td><td align="left">遵循“极简主义”，只标注最核心的检索维度</td></tr><tr><td align="left"><strong>只存不管无人维护</strong></td><td align="left">索引与内容脱节，变成死库</td><td align="left">强制要求在<strong>板栗看板</strong>等看板中同步更新最新资产</td></tr><tr><td align="left"><strong>权限设置过于封闭</strong></td><td align="left">信息无法流动，形成新孤岛</td><td align="left">关注知识的透明度，按职能设定合理的可见性</td></tr></tbody></table><h3><strong>09 培育“资产为先”的归档文化</strong></h3><p>工具只是载体，文化才是灵魂。企业应鼓励：</p><ul><li><strong>留痕文化：</strong> 让所有重要文档产生即归档，成为一种自觉习惯。</li><li><strong>贡献文化：</strong> 奖励主动整理索引、优化文档结构的行为。</li><li><strong>开放文化：</strong> 打破部门墙，让非涉密文档在索引中自由检索。</li></ul><h3><strong>10 结语：索引是组织最强大的竞争力</strong></h3><p>在竞争日益激烈的今天，靠个人翻找资料支撑业务的时代已经过去。<strong>索引式文档看板工具</strong>不仅是整理工具，更是将“散乱数据”转化为“数字资产”的炼金术。</p><p>通过这样的工具，企业可以将每一个项目的成果刻进组织的记忆中。当信息能够秒级触达，文档能够逻辑对齐，组织的每一个决策都将建立在更高效的智慧基础之上。索引不是终点，而是企业迈向数智化协作的新起点。</p>]]></description></item><item>    <title><![CDATA[现在学智能值不值？权威数据 + 产业实践告诉你答案 智能猫 ]]></title>    <link>https://segmentfault.com/a/1190000047553913</link>    <guid>https://segmentfault.com/a/1190000047553913</guid>    <pubDate>2026-01-20 17:07:48</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>随着中国大模型技术从研发攻坚迈向规模化应用，“现在学智能值不值”成为无数学习者、求职者关注的核心命题。有人因“500 万人才缺口”的行业红利心动，也有人担忧技术迭代快、学习成本高的风险。判断其价值，需立足产业发展规律、人才需求结构与个人发展定位综合研判，以下内容将结合权威数据与典型案例，给出清晰答案与实操指引。</p><h4>🚀快速回答</h4><p>现在学智能值得投入，但需精准定位而非盲目跟风。核心结论：产业升级催生刚性需求，智能人才缺口大、薪资高，“智能 + 行业”复合型人才价值凸显；对学习者而言，只要匹配自身基础选择适配方向（科研攻坚/行业应用），通过实践提升能力，就能将技术转化为长期竞争力；潜在风险可通过精准选课、参与项目规避。</p><h2>一、核心背景：智能产业爆发，人才需求进入刚性增长期</h2><p>智能技术已成为新质生产力的核心支撑，国内产业规模与人才需求的双重增长，为学习者提供了核心价值基础，相关数据均来自官方发布与权威机构报告，具备强可信度。</p><h3>1.1 产业规模持续扩张，政策持续护航</h3><ul><li>工业和信息化部数据：我国人工智能核心产业规模已突破 6000 亿元，企业数量超 4700 家，且仍保持高速增长态势</li><li>中国信通院《人工智能发展白皮书（2025）》预测：到 2035 年我国人工智能产业规模有望达 1.73 万亿元，全球占比将达 30.6%</li><li>政策导向：工信部明确 2025 年实施“人工智能 + 制造”行动，重点推进通用大模型和行业大模型的研发布局与场景应用，降低企业转型门槛的同时，扩大了智能人才的需求场景</li></ul><h3>1.2 人才缺口巨大，薪资优势显著</h3><table><thead><tr><th>数据维度</th><th>具体数值</th><th>信息来源</th></tr></thead><tbody><tr><td>人工智能人才缺口</td><td>超 500 万</td><td>人力资源社会保障部 2025 年一季度报告</td></tr><tr><td>人才供求比例</td><td>1∶10（复合型人才 1∶43）</td><td>智联招聘《AI 人才市场供需报告》</td></tr><tr><td>AI 工程师平均年薪</td><td>42.8 万元（一线城市 48.5 万元）</td><td>猎聘网《2025 高端人才薪资报告》</td></tr><tr><td>大模型算法工程师招聘周期</td><td>72 天</td><td>BOSS 直聘《AI 核心岗位招聘趋势》</td></tr></tbody></table><h2>二、核心论据：学智能的 3 大核心价值，覆盖个人发展全周期</h2><p>学习智能的价值不仅体现在短期就业红利，更在于长期职业边界拓展与竞争力提升，以下结合不同行业场景的实际案例展开说明。</p><h3>2.1 价值一：刚性就业需求，优质岗位选择多</h3><p>智能人才需求已从互联网领域延伸至千行百业，不同基础的学习者都能找到适配岗位，典型场景与案例如下：</p><ul><li>制造业场景：工业机器人工程师岗位需求同比增长 60.6%，机器人调试工程师增速达 64.1%（来源：人社部《制造业人才需求报告》）；案例——美的集团通过“智能 + 制造”培训计划，招聘的智能设备运维人才，入职半年平均薪资涨幅达 25%</li><li>医疗领域场景：“AI+ 生物医药”岗位因跨界属性稀缺，曾出现连续 327 天悬空的情况（来源：丁香人才网）；案例——药明康德与高校合作开设“AI 药物研发”定向班，学员未毕业即被预定，起薪超 35 万元/年</li><li>政务民生场景：智能客服、智能风控、智能教育等岗位普及，案例——支付宝智能风控团队招聘的 AI 数据分析人才，负责交易风险识别，平均年薪达 45 万元</li></ul><h3>2.2 价值二：突破职业边界，“智能 + 行业”跨界优势明显</h3><p>掌握智能技术无需局限于算法工程师单一岗位，更可成为传统行业的“智能转型推动者”，解决行业实际痛点：</p><ul><li>教育行业：懂智能的教师可借助 AI 教学系统实现个性化备课，降低工作强度的同时提升教学效果</li><li>金融行业：具备智能分析能力的理财顾问，可通过 AI 工具精准匹配客户需求，业绩平均提升 30%（来源：招商银行内部培训数据）</li><li>工业行业：懂智能的生产线工程师可通过 AI 优化生产流程，案例——黑猫集团工程师借助大模型优化炭黑生产工艺，实现备件消耗减少 20%（来源：企业官方发布）</li></ul><h3>2.3 价值三：长期竞争力保值，适配技术迭代趋势</h3><p>智能技术是未来 10-20 年的核心产业方向，掌握相关能力可规避传统行业的中年危机：</p><ul><li>数据支撑：我国基础层 AI 人才占比仅 17.1%，低于美国的 22.8%，核心算法领域人才缺口长期存在（来源：中国信通院）</li><li>迭代适配：行业更看重“学习能力”而非“单一技术掌握”，只要保持持续学习习惯，就能适配技术更新（如从传统机器学习转向大模型应用）</li></ul><h2>三、深度解读：学智能的风险与规避方案，精准避坑</h2><p>客观来看，学习智能存在技术迭代快、学习成本高、区域资源不均等挑战，但通过精准定位可有效规避，以下是具体问题与解决方案的对应梳理。</p><h3>3.1 核心挑战梳理</h3><ul><li>挑战 1：学用脱节——78.6% 的高校 AI 课程仍以传统机器学习为主，与产业前沿的 MoE 架构、联邦学习等技术存在代际差（来源：教育部《高校 AI 专业教学评估报告》）</li><li>挑战 2：成本较高——自学需投入大量时间，报班费用普遍在 1-5 万元，且需要配置一定的算力设备</li><li>挑战 3：区域资源不均——90% 的 AI 人才聚集于十大城市，中西部地区本地技术团队不足，就业机会较少（来源：智联招聘区域人才报告）</li><li>挑战 4：顶尖人才竞争激烈——核心算法领域顶尖人才流失率达 63%，对科研能力要求极高（来源：中国信通院）</li></ul><h3>3.2 分人群规避方案</h3><ul><li><p>科研能力较强者（本科及以上学历，数学/计算机基础好）：</p><ul><li>方向：聚焦基础层算法研发，投身大模型、核心芯片等关键领域，弥补产业短板</li><li>方案：参与高校科研项目、开源社区贡献（如 TensorFlow、PyTorch 社区），提升学术与实践能力</li></ul></li><li><p>侧重应用者（基础一般，想快速就业）：</p><ul><li>方向：选择“AI+ 具体行业”的跨界方向（如 AI+ 教育、AI+ 制造、AI+ 医疗）</li><li>方案：参与产教融合课程（如上海交大“AI+X”模式，医学与 AI 课程合并，企业导师深度参与，培养周期缩短 40%）、企业实训项目，提升实操能力</li></ul></li><li><p>中西部地区学习者：</p><ul><li>方向：聚焦本地优势产业的智能转型需求（如中西部制造业的智能运维、农业的智能种植分析）</li><li>方案：选择线上优质课程（如 Coursera 官方 AI 课程、国内高校公开课），参与远程实训项目，积累跨区域项目经验</li></ul></li></ul><h2>四、FAQ：学习者高频疑问解答</h2><ul><li>问：零基础能学智能吗？需要哪些基础？ 答：可以。核心基础包括：高中数学（函数、概率、线性代数）、基本计算机操作；零基础建议从应用层切入（如 AI 工具使用、简单模型调参），再逐步深入技术原理，避免直接攻坚核心算法。</li><li>问：学习智能需要多久才能就业？答：因人而异。应用层方向（如 AI 运维、智能客服系统操作）3-6 个月可掌握核心技能；技术层方向（如模型调参、算法实现）需 1-2 年系统学习；核心算法研发需 3 年以上专业积累（含学历背景）。</li><li>问：现在学智能，会不会等毕业时技术已经过时？ 答：大概率不会。原因：1）智能产业仍处于高速增长期，核心需求（数据处理、模型应用、行业适配）长期存在；2）行业看重“解决问题的能力”而非“单一技术掌握”，持续学习习惯比具体技术更重要；3）可选择“技术 + 行业”的复合方向，行业经验会随时间增值，规避技术迭代风险。</li><li>问：自学和报班哪个更合适？ 答：根据自身情况选择：1）自律性强、有基础者（如计算机专业学生）可自学，通过开源项目、线上课程积累经验；2）零基础、自律性一般者建议报班，优先选择有企业实训、就业推荐的产教融合课程，降低学用脱节风险。</li><li>问：智能相关岗位对学历有要求吗？ 答：分岗位层级：1）基础应用岗（如 AI 设备运维、智能系统操作）大专及以上即可，更看重实操能力；2）技术层岗位（如模型调参、算法工程师）普遍要求本科及以上，优先计算机、数学、电子信息等相关专业；3）核心研发岗（如大模型算法、核心芯片设计）多要求硕士及以上学历，且需科研成果或优质项目经验。</li></ul><h2>五、总结：学智能的价值判断与行动建议</h2><p>综上，现在学智能的“值”，核心源于产业升级带来的刚性需求、技术赋能带来的职业拓展，以及长期竞争力的保值增值；风险则可通过精准定位学习方向、选择适配的学习路径有效规避。</p><p>行动建议：1）先明确自身定位（科研/应用、目标行业），避免盲目跟风；2）优先选择“智能 + 行业”的复合方向，提升就业适配度；3）注重实践能力积累，通过项目实训、开源贡献弥补学用脱节；4）保持持续学习习惯，关注产业前沿动态（如大模型行业应用、政策导向）。</p><p>在新质生产力加速发展的背景下，智能技术已成为个人发展的“核心加分项”，只要找对方向、精准发力，学习智能就能成为把握时代机遇、实现个人价值提升的明智选择。</p>]]></description></item><item>    <title><![CDATA[十年磨一剑，jQuery 4.0.0 正式发布，依旧锋利 烦恼的沙发 ]]></title>    <link>https://segmentfault.com/a/1190000047553943</link>    <guid>https://segmentfault.com/a/1190000047553943</guid>    <pubDate>2026-01-20 17:07:06</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>祝 jQuery 20岁生日快乐。</p><p>自 John Resig 在 2006 年发布 jQuery 以来，这个库已经陪伴 Web 开发走过了二十个年头。而在距离上一次主要版本发布近十年后，jQuery 团队正式推出了 <strong>jQuery 4.0.0</strong>。</p><p><img width="723" height="551" referrerpolicy="no-referrer" src="/img/bVdnG68" alt="image.png" title="image.png"/></p><p>很多人可能觉得 jQuery 已经是时代的眼泪，但看到 jQuery 4.0.0 正式发布的消息时，还是不得不感叹法拉利老了还是法拉利。</p><p>这次更新可不是简单的修修补补，这次团队清理了多年的技术债务，移除了过时的 API，这个经典库终于也能跟上现代 Web 开发的节奏。</p><p>以下是这次更新中几个最值得关注的变化：</p><h3>告别旧版的浏览器</h3><p>这应该是最喜闻乐见的改动了。jQuery 4.0.0 正式停止支持 <strong>IE 10 及以下版本</strong>。目前仅保留对 IE 11 的支持，但这只是暂时的，团队计划在未来的 jQuery 5.0 中彻底移除 IE 支持。此外，旧版 Edge（Edge Legacy）、iOS 11 以下版本、Firefox 65 以下版本以及旧版 Android 浏览器的支持也被移除。</p><p>只要不是做古董级项目，包体积会更小，运行速度也会更快。</p><h3><strong>移除过时的</strong> <strong>API</strong></h3><p>随着原生 JavaScript（ES6+）功能的完善，许多 jQuery 早期的辅助函数已失去存在的意义。4.0 版本移除了大量此类 API，包括用于去除字符串空格的 <code>jQuery.trim</code>、判断数组的 <code>jQuery.isArray</code>、解析 JSON 的 <code>jQuery.parseJSON</code> 等。</p><p><img width="723" height="399" referrerpolicy="no-referrer" src="/img/bVdnG69" alt="image.png" title="image.png" loading="lazy"/></p><p>此外，一些仅供内部使用的数组方法（如 <code>push</code>、<code>sort</code> 和 <code>splice</code>）也从 jQuery 原型中移除。现在，开发者应直接使用原生的 JavaScript 方法来替代这些旧功能。</p><h3><strong>源码</strong> <strong>迁移至</strong> <strong>ES</strong> <strong>Modules</strong></h3><p>jQuery 的源码终于从旧式的 AMD 模块系统迁移到了 <strong>ES</strong> <strong>Modules</strong>。 这下 jQuery 能更丝滑地融入 Vite、Rollup 或 Webpack 等现代构建工具链。而且，在浏览器中可以通过模块化的方式直接加载和运行 jQuery，符合现代开发流程。</p><h3><strong>焦点事件顺序回归 W3C 标准</strong></h3><p>在很长一段时间里，不同浏览器对焦点事件（focus/blur/focusin/focusout）的触发顺序存在分歧。jQuery 曾为了统一行为而强制了一套自己的顺序。</p><p>现在，所有主流浏览器已达成一致，jQuery 4.0.0 决定不再进行人工干预，直接遵循 W3C 标准顺序，<code>blur</code> -&gt; <code>focusout</code> -&gt; <code>focus</code> -&gt; <code>focusin</code>。这属于破坏性更新，如果现有项目严重依赖特定的事件触发顺序，升级时需格外注意。</p><h3><strong>更轻量的 Slim 版本</strong></h3><p>新的 Slim 版本（精简版）移除了 Deferreds 和 Callbacks 模块，体积进一步缩小（gzip 后减少约 8KB）。</p><p>由于现代浏览器（除 IE11 外）都已原生支持 Promise，大多数异步操作已不再需要 jQuery 的 Deferreds。如果是面向现代浏览器的项目，Slim 版本将是更优的选择。</p><h3>快速上手体验</h3><p>即使不为了新项目，仅仅为了情怀，很多人也想试试这个 4.0 版本。最快的方法就是通过 npm 安装 <code>jquery@4.0.0</code> 跑个 Demo，那一个稳定且配置好的 <a href="https://link.segmentfault.com/?enc=p7GVAE2vGL%2FvuZ2RJGtcjg%3D%3D.sDgpIYYK7WXHNMWbLr8sQdEF2JZaEssIi5J%2FmCRusq%2BpWsiPMuhN9EV2MitV3n5y" rel="nofollow" target="_blank">Node.js 环境</a>必不可少。</p><p>如果你不想为了尝鲜就在本地折腾一堆 Node.js 配置，或者单纯觉得配环境很麻烦，可以试试 <strong><a href="https://link.segmentfault.com/?enc=33fbOVnUeG2YLxmtRFyLHQ%3D%3D.OFw8eudndzznlIkBkvsh0bVnVqpagCn%2F96Ko2AO1fY0%3D" rel="nofollow" target="_blank">ServBay</a></strong>。它能一键把 Node.js 环境部署好，自动搞定路径配置和版本管理。</p><p><img width="723" height="399" referrerpolicy="no-referrer" src="/img/bVdnG69" alt="image.png" title="image.png" loading="lazy"/></p><p>环境弄好后，直接在目录里运行 npm 命令拉取最新的 jQuery 就能直接玩，省时省力。</p><h3>结语</h3><p>jQuery 4.0.0 的发布证明了它并躺平，而是在努力适应现代 Web 标准，就像一个武林高手，闭关10年，出关后变得更强了。</p><p>无论是为了维护现有资产，还是为了在特定场景下快速开发，这个新版本都交出了一份合格的答卷。</p><p>最后，这个时代的眼泪还有多少用户知道？</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553945" alt="" title="" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[《免费开源！edisao：5 分钟搞定知识整理，再也不怕考点 / 技术点漏缺》 edisao ]]></title>    <link>https://segmentfault.com/a/1190000047553993</link>    <guid>https://segmentfault.com/a/1190000047553993</guid>    <pubDate>2026-01-20 17:06:32</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>最近整理微服务架构笔记时快被逼疯了：写了 3 页文档，结果评审时被指出漏了 “分区容忍性” 的核心场景；之前存的 “分布式锁” 模块，换个电商场景根本用不了 —— 索性花 3 天写了个轻量化工具 edisao，把自己的知识管理流程做成了闭环，现在开源出来给有同样痛点的朋友用～</p><h2>我写的原子化校验核心代码（自己调试了5次才跑通）</h2><p>def check_atomicity(module: dict) -&gt; dict:</p><pre><code># 针对微服务模块的校验逻辑（自己踩坑后加的）
if "微服务" in module["content"]:
    if not ("注册中心" in module["content"] and "熔断" in module["content"]):
        return {"status": "fail", "reason": "微服务模块缺核心组件"}
return {"status": "pass", "reason": "原子化检测通过"}
</code></pre><h4>10分钟跑通edisao（亲测Windows/Mac通用）</h4><ol><li>克隆仓库：<code>git clone https://gitcode.com/edisao/edisao-知识管理闭环模型2.0.git</code></li><li>装依赖：<code>pip install -r requirements.txt</code>（我踩的坑：Python版本要3.8+）</li><li>跑第一个校验：打开<code>test_module.yaml</code>，填自己的技术笔记，然后运行<code>python atomicity_check.py</code></li></ol><p>目前这个工具只适配了技术知识整理，接下来打算加 “考研考点模板”（自己也在备考），如果有朋友用了发现问题，欢迎去 GitCode 提 Issues~<br/><a href="https://link.segmentfault.com/?enc=uoQ7l%2BG7RjEO7QdvqVWNtw%3D%3D.t%2Fo8Y62kc9SeSe7Q8JmU%2Fa6%2Bg6vVep0mkZo5y5wNwPlQLjGJyojz%2Fhj9O42O%2B5Ef" rel="nofollow" target="_blank">https://gitcode.com/edisao/edisao-pkm-v2-core</a></p>]]></description></item><item>    <title><![CDATA[智能体，正在成为普通人的新能力 智能体小狐 ]]></title>    <link>https://segmentfault.com/a/1190000047554002</link>    <guid>https://segmentfault.com/a/1190000047554002</guid>    <pubDate>2026-01-20 17:05:34</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>过去，AI 更像是一个工具。</p><p>你问，它答；你用，它停。<br/>真正的事情，还是要人自己完成。</p><p>但现在，智能体的出现，正在改变这一点。</p><hr/><h2>一、智能体不是更聪明，而是开始“做事”</h2><p>很多人第一次接触智能体，会以为它只是更聪明的 AI。</p><p>但真正的区别在于：<br/>智能体能把一件事情，从头到尾完成。</p><p>你只需要给出目标，它会拆解步骤、调用工具、执行流程、检查结果，直到任务结束。这种能力，让 AI 从“回答者”变成了“执行者”。</p><hr/><h2>二、智能体最先改变的，是大量低价值工作</h2><p>在大多数人的工作和生活中，有一类事情既不复杂，也不重要，却非常耗时间：</p><ul><li>信息搜索与整理</li><li>内容初稿生成</li><li>报告结构搭建</li><li>格式修改与重复调整</li><li>日常资料汇总</li></ul><p>这些工作长期消耗精力，却难以体现价值。<br/>智能体的出现，正在接管这些流程。</p><hr/><h2>三、使用智能体的人，工作结构正在发生变化</h2><p>当执行被系统接管，人自然会把时间放在更重要的事情上：</p><ul><li>判断方向是否正确</li><li>决定是否继续</li><li>选择最优结果</li><li>进行最终修正</li></ul><p>你不再被流程拖住，而是只对结果负责。</p><hr/><h2>四、智能体降低了完成复杂任务的门槛</h2><p>过去，研究、分析、写作、整理等工作需要长期积累经验；现在，这些流程中的大量步骤可以被智能体接管，普通人只需清楚目标、检查结果，就能完成原本难以完成的事情。</p><p>这也是为什么，越来越多非技术用户开始主动使用智能体。</p><hr/><h2>五、真正的变化，是工作方式而不是工具</h2><p>从工具到系统，是智能体带来的最大改变。</p><p>当人开始把执行交给智能体，把判断留给自己，工作方式本身就已经发生变化。这种变化，会持续影响每一个人的效率、节奏与价值位置。</p><hr/><h2>结语</h2><p>智能体不会一夜改变一切，但会持续改变每一个使用它的人。</p><p>对普通人来说，越早建立这种新的工作方式，就越早拥有主动权。</p>]]></description></item><item>    <title><![CDATA[高打开率邮件主题的炼成法则：一位十年营销人的实战笔记 旅途中的围巾_d7edGc ]]></title>    <link>https://segmentfault.com/a/1190000047554011</link>    <guid>https://segmentfault.com/a/1190000047554011</guid>    <pubDate>2026-01-20 17:04:38</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在这个行业里摸爬滚打了十多年，我常常感觉，我们这些做邮件营销的人，就像是在客户的邮箱里“开小店”。每一天，无数个“店铺招牌”（也就是邮件主题）在客户眼前闪过。想让客户在匆匆一瞥中为你驻足，甚至推开你这扇门，真的需要点真功夫。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047554013" alt="图片" title="图片"/><br/>今天，我就和大家聊聊这个决定“开门率”的第一关——邮件主题行。这不仅仅是一行字，这是你和客户之间最精炼、最关键的对话开端。<br/>一、信任是基石：先让客户认识你，再期待他打开<br/>你在琢磨怎么让主题更吸引人之前，我们必须先回到一个更根本的问题：客户凭什么相信你？想象一下，你收到两封邮件，一封来自陌生的个人邮箱，另一封来自规范的service@知名品牌.com，你会本能地更信任谁？研究显示，发件人信息的可信度直接影响打开率，使用企业官方域名邮箱能显著提升专业形象。我的实践心得：从早期创业开始，我就坚持使用专业的邮件营销平台来管理发件域名和身份认证（如SPF、DKIM）。这不仅是技术配置，更是建立品牌信任的门面。我长期合作的U-Mail邮件营销平台，在这一点上给我的帮助很大。它允许企业直接使用自己的域名作为发件后缀，这不仅让每一封邮件都成为品牌宣传，更重要的是，它联合了国内外主流邮箱运营商，建立了专属的“绿色通道”。这意味着我们的邮件能更安全、更稳定地进入客户的收件箱，而不是垃圾箱。信任，始于抵达。<br/>二、主题行心法：像朋友一样说话，像顾问一样思考<br/>当信任的基石打好后，主题行就是那句脱口而出的问候或提醒。它必须精准有吸引力，并且尊重对方的时间。我认为，好的主题行要做到以下三点：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047554014" alt="图片" title="图片" loading="lazy"/></p><p>1、关联与价值，缺一不可一个冰冷的“产品推荐”远不如一句“为您上周关注的XX问题，找到了三个解决方案”。主题行必须瞬间建立“与我有关”的链接。这可以是客户的姓名、公司名，也可以是您洞察到的他的业务痛点。通过U-Mail的“自定义变量”功能，我可以轻松地在主题和内容中插入客户的名字、公司或其他属性，实现基础个性化。更进一步，基于平台的地址池分类和用户行为追踪报告，我能对不同分组（比如已打开某类邮件的用户、点击过某链接的用户）设计完全不同角度的主题。例如，对互动过的客户，主题可以是“继我们上次的讨论…”，而对新客户，则突出行业解决方案价值。<br/>2、激发好奇，但保持真诚提问和数字是制造好奇的经典技巧。“如何将季度成本降低15%？” 比 “我们的服务很好” 有力得多。引用具体数字，如“3个技巧提升您的团队效率”，能增加信息的可信度和吸引力。但切记，不要做“标题党”。过度使用“免费！”“惊天优惠！”等词汇，极易触发垃圾邮件过滤器，并损害长期信任。我常用的一个检验方法是：问自己，这个主题承诺的内容，我的邮件正文是否能够毫无水分地兑现？<br/>3、简洁有力，移动端友好客户可能在手机上快速浏览，据统计超过60%的邮件在移动设备上打开。过长的主题会被截断。我的经验是，将主题行核心控制在30-50个字符（大约6-10个词）为佳，确保核心价值在手机通知栏或收件箱列表中就一目了然。<br/>三、进阶的艺术：用数据让直觉更靠谱<br/>多年的经验会形成直觉，但直觉需要用数据来验证和优化。这是我职业生涯中后期提升最大的一个环节。1、A/B测试是黄金准则：我从不凭感觉决定最终用哪个主题。对于重要邮件，我会准备2-3个不同角度（例如，一个侧重“提问”，一个侧重“价值声明”）的主题，发给一小部分用户进行A/B测试。U-Mail邮件营销平台内置的统计功能可以非常清晰地告诉我，哪个版本的打开率更高、哪个链接点击更多。用数据说话，让每一次发送都成为下一次优化的养分。<br/>2、智能发送，事半功倍：找到最佳发送时间能显著提升打开率。除了参考通用数据（如避开周一早高峰和周末），更重要的是分析你的特定受众。通过U-Mail邮件营销平台生成的详细数据报告，我可以观察我的用户通常在哪个时间段最活跃、打开率最高。基于这些洞察，再利用平台的“定时发送”任务系统，让邮件在用户最可能查阅的时间精准送达，效果立竿见影。<br/>四、温情提示：比技巧更重要的是“心法”<br/>最后，我想分享几个比技术更重要的原则：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047554015" alt="图片" title="图片" loading="lazy"/><br/>1、提供价值，而非仅仅推销：客户愿意打开的，永远是那些能为他解决问题、带来启发的内容。让你的主题成为价值预告片。<br/>2、保持一致性：稳定的发送频率和稳定的品牌语气，会让客户逐渐熟悉并期待你的邮件。<br/>3、尊重选择：在邮件中提供清晰、便捷的退订链接，这不仅是法律要求，也是一种尊重。维护一个干净、自愿的订阅列表，长远来看打开率和转化率会更高。<br/>EDM邮件营销是一场与用户建立长期关系的慢舞，主题行就是优雅邀请的第一步。它需要技术工具的保障，需要数据思维的优化，但归根结底，需要的是一颗真正想为用户提供价值的心。<br/>工欲善其事，必先利其器。像U-Mail邮件营销平台这样的专业工具，对我来说就像一个可靠的伙伴。它从确保送达的底层通道开始，到内容个性化、数据统计分析，再到基于数据的自动化任务管理，覆盖了整个营销闭环，让我能更专注于策略和创意本身，把“敲门”这件事，做得更得体、更有效。</p>]]></description></item><item>    <title><![CDATA[Nuxt 3 vs Next.js：新手选型指南与项目实战对比 大前端历险记 ]]></title>    <link>https://segmentfault.com/a/1190000047554049</link>    <guid>https://segmentfault.com/a/1190000047554049</guid>    <pubDate>2026-01-20 17:03:42</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>Nuxt 3 vs Next.js：新手选型指南与项目实战对比</h2><blockquote>当Vue遇上React，服务端渲染框架如何选择？</blockquote><p>在现代Web开发中，两大全栈框架Nuxt 3和Next.js占据着服务端渲染(SSR)领域的主导地位。它们都提供了<strong>文件系统路由、自动代码分割、SEO优化</strong>等现代Web应用所需的核心功能，但技术选型背后的<strong>技术栈差异</strong>和<strong>设计哲学</strong>却大不相同。</p><p>本文将通过对比分析，帮助前端新手理解这两大框架的区别，并提供实际的项目创建示例。</p><hr/><h3>01 核心差异：Vue与React的技术栈选择</h3><p>Nuxt 3与Next.js最根本的区别在于其<strong>底层技术栈</strong>：</p><ul><li><strong>Nuxt 3</strong>：基于<strong>Vue 3</strong>生态系统，采用组合式API和响应式系统</li><li><strong>Next.js</strong>：基于<strong>React</strong>生态系统，支持最新的React特性</li></ul><p>这种核心差异决定了你的开发体验、学习曲线以及可用的第三方库生态。</p><h4>学习曲线对比</h4><p>对于完全没有前端经验的新手来说，Vue通常被认为比React<strong>学习曲线更平缓</strong>。Vue的模板语法更接近传统HTML，而React的JSX则需要适应将HTML与JavaScript混合编写的模式。</p><table><thead><tr><th>框架特性</th><th>Nuxt 3</th><th>Next.js</th></tr></thead><tbody><tr><td>基础框架</td><td>Vue 3</td><td>React</td></tr><tr><td>路由系统</td><td>文件系统路由（pages/目录）</td><td>文件系统路由（app/目录）</td></tr><tr><td>数据获取</td><td><code>useAsyncData</code>, <code>useFetch</code></td><td>服务端组件、<code>fetch</code> API</td></tr><tr><td>状态管理</td><td>Pinia (推荐)</td><td>Zustand, Redux等</td></tr><tr><td>样式方案</td><td>多种选择（CSS模块、Tailwind等）</td><td>多种选择（CSS模块、Tailwind等）</td></tr><tr><td>部署平台</td><td>Vercel、Netlify、Node服务器等</td><td>Vercel（官方）、Netlify等</td></tr></tbody></table><h4>生态圈对比</h4><p>Next.js拥有<strong>更庞大的社区和更丰富的第三方库</strong>，这得益于React本身的普及度。Nuxt 3虽然社区规模较小，但其<strong>官方模块质量很高</strong>，且与Vue生态无缝集成。</p><hr/><h3>02 快速入门：创建你的第一个应用</h3><h4>Nuxt 3入门示例</h4><p><strong>项目初始化</strong>：</p><pre><code class="bash"># 创建Nuxt 3项目
npx nuxi@latest init my-nuxt-app
cd my-nuxt-app
npm install
npm run dev</code></pre><p><strong>创建页面和组件</strong>：</p><ol><li><p>在<code>pages/index.vue</code>中创建主页：</p><pre><code class="js">&lt;template&gt;
  &lt;div class="container"&gt;
 &lt;h1&gt;欢迎使用Nuxt 3&lt;/h1&gt;
 &lt;p&gt;当前时间：{{ currentTime }}&lt;/p&gt;
 &lt;button @click="refreshTime"&gt;刷新时间&lt;/button&gt;
  &lt;/div&gt;
&lt;/template&gt;

&lt;script setup&gt;
// 使用组合式API
const currentTime = ref('')

// 获取服务器时间
onMounted(async () =&gt; {
  const { data } = await useFetch('/api/time')
  currentTime.value = data.value
})

// 客户端交互
const refreshTime = () =&gt; {
  currentTime.value = new Date().toLocaleString()
}
&lt;/script&gt;</code></pre></li><li><p>创建API端点<code>server/api/time.get.ts</code>：</p><pre><code class="typescript">export default defineEventHandler(() =&gt; {
  return new Date().toISOString()
})</code></pre></li></ol><h4>Next.js入门示例</h4><p><strong>项目初始化</strong>：</p><pre><code class="bash"># 创建Next.js项目（使用App Router）
npx create-next-app@latest my-next-app
cd my-next-app
npm install
npm run dev</code></pre><p><strong>创建页面和组件</strong>：</p><ol><li><p>在<code>app/page.tsx</code>中创建主页：</p><pre><code class="js">export default function HomePage() {
  return (
 &lt;div className="container"&gt;
   &lt;h1&gt;欢迎使用Next.js&lt;/h1&gt;
   &lt;TimeDisplay /&gt;
 &lt;/div&gt;
  )
}

// 服务端组件：自动在服务器上运行
async function TimeDisplay() {
  // 在服务端获取数据
  const response = await fetch('http://worldtimeapi.org/api/timezone/Asia/Shanghai')
  const data = await response.json()
  
  return (
 &lt;div&gt;
   &lt;p&gt;当前时间：{data.datetime}&lt;/p&gt;
   &lt;ClientComponent /&gt;
 &lt;/div&gt;
  )
}

// 客户端组件：需要"use client"指令
'use client'
function ClientComponent() {
  const [count, setCount] = useState(0)
  
  return (
 &lt;button onClick={() =&gt; setCount(count + 1)}&gt;
   点击次数：{count}
 &lt;/button&gt;
  )
}</code></pre></li></ol><hr/><h3>03 特性深度对比：数据获取与渲染策略</h3><h4>数据获取方式对比</h4><p><strong>Nuxt 3的数据获取</strong>：</p><pre><code class="js">&lt;template&gt;
  &lt;div&gt;
    &lt;h2&gt;文章列表&lt;/h2&gt;
    &lt;div v-if="pending"&gt;加载中...&lt;/div&gt;
    &lt;ul v-else&gt;
      &lt;li v-for="post in posts" :key="post.id"&gt;
        {{ post.title }}
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/div&gt;
&lt;/template&gt;

&lt;script setup&gt;
// useAsyncData用于服务端获取数据
const { data: posts, pending } = await useAsyncData(
  'posts',
  () =&gt; $fetch('https://api.example.com/posts')
)

// useFetch是useAsyncData的简写
const { data: user } = await useFetch('/api/user')
&lt;/script&gt;</code></pre><p><strong>Next.js的数据获取</strong>：</p><pre><code class="js">// 在App Router中，页面组件默认为服务端组件
export default async function PostsPage() {
  // 直接使用fetch API，Next.js会自动优化
  const response = await fetch('https://api.example.com/posts', {
    next: { revalidate: 60 } // 每60秒重新验证
  })
  const posts = await response.json()
  
  return (
    &lt;div&gt;
      &lt;h2&gt;文章列表&lt;/h2&gt;
      &lt;ul&gt;
        {posts.map((post) =&gt; (
          &lt;li key={post.id}&gt;{post.title}&lt;/li&gt;
        ))}
      &lt;/ul&gt;
      &lt;LikeButton postId={posts[0].id} /&gt;
    &lt;/div&gt;
  )
}

// 客户端交互组件需要"use client"指令
'use client'
function LikeButton({ postId }) {
  const [likes, setLikes] = useState(0)
  
  return (
    &lt;button onClick={() =&gt; setLikes(likes + 1)}&gt;
      点赞 ({likes})
    &lt;/button&gt;
  )
}</code></pre><h4>渲染策略对比</h4><p>两个框架都支持多种渲染策略，但实现方式不同：</p><table><thead><tr><th>渲染模式</th><th>Nuxt 3实现</th><th>Next.js实现</th></tr></thead><tbody><tr><td>静态生成(SSG)</td><td><code>nuxt generate</code></td><td><code>output: 'static'</code></td></tr><tr><td>服务端渲染(SSR)</td><td>默认启用</td><td>默认启用（服务端组件）</td></tr><tr><td>客户端渲染(CSR)</td><td><code>&lt;ClientOnly&gt;</code>组件</td><td>"use client"指令</td></tr><tr><td>增量静态再生(ISR)</td><td>通过模块实现</td><td>原生支持（fetch选项）</td></tr></tbody></table><hr/><h3>04 实际应用场景分析</h3><h4>何时选择Nuxt 3？</h4><ol><li><strong>Vue技术栈项目</strong>：团队已熟悉Vue生态</li><li><strong>快速原型开发</strong>：需要快速搭建MVP产品</li><li><strong>内容型网站</strong>：博客、文档、营销页面</li><li><strong>项目结构清晰</strong>：喜欢"约定优于配置"的理念</li></ol><p><strong>Nuxt 3优势场景示例</strong>：</p><pre><code class="js">&lt;!-- 快速创建SEO友好的内容页面 --&gt;
&lt;template&gt;
  &lt;div&gt;
    &lt;Head&gt;
      &lt;Title&gt;产品介绍 - 我的网站&lt;/Title&gt;
      &lt;Meta name="description" :content="product.description" /&gt;
    &lt;/Head&gt;
    
    &lt;article&gt;
      &lt;h1&gt;{{ product.title }}&lt;/h1&gt;
      &lt;!-- 内容自动渲染 --&gt;
      &lt;ContentRenderer :value="product" /&gt;
    &lt;/article&gt;
  &lt;/div&gt;
&lt;/template&gt;

&lt;script setup&gt;
// 自动根据文件路径获取内容
const { data: product } = await useAsyncData('product', () =&gt; 
  queryContent('/products').findOne()
)
&lt;/script&gt;</code></pre><h4>何时选择Next.js？</h4><ol><li><strong>React技术栈项目</strong>：团队已熟悉React生态</li><li><strong>大型复杂应用</strong>：需要React丰富生态支持</li><li><strong>需要最新特性</strong>：希望使用React最新功能</li><li><strong>Vercel平台部署</strong>：计划使用Vercel的完整能力</li></ol><p><strong>Next.js优势场景示例</strong>：</p><pre><code class="js">// 复杂的动态仪表板应用
export default async function DashboardPage() {
  // 并行获取多个数据源
  const [sales, users, analytics] = await Promise.all([
    fetchSalesData(),
    fetchUserData(),
    fetchAnalyticsData(),
  ])
  
  return (
    &lt;div className="dashboard"&gt;
      &lt;SalesChart data={sales} /&gt;
      &lt;UserTable users={users} /&gt;
      &lt;AnalyticsOverview data={analytics} /&gt;
      {/* 实时更新的客户端组件 */}
      &lt;LiveNotifications /&gt;
    &lt;/div&gt;
  )
}

// 使用React Server Components实现部分渲染
'use client'
function LiveNotifications() {
  const [notifications, setNotifications] = useState([])
  
  useEffect(() =&gt; {
    // 建立WebSocket连接获取实时数据
    const ws = new WebSocket('wss://api.example.com/notifications')
    // ... 处理实时数据
  }, [])
  
  return &lt;NotificationList items={notifications} /&gt;
}</code></pre><hr/><h3>05 开发体验与工具链对比</h3><h4>Nuxt 3的开发体验</h4><ol><li><strong>零配置起步</strong>：大多数功能开箱即用</li><li><strong>模块系统</strong>：官方和社区模块质量高</li><li><strong>TypeScript支持</strong>：一流的TypeScript体验</li><li><strong>开发工具</strong>：Nuxt DevTools提供强大调试能力</li></ol><pre><code class="bash"># Nuxt 3的典型工作流
npx nuxi@latest init my-project  # 创建项目
npm install                       # 安装依赖
npm run dev                       # 开发模式
npm run build                     # 生产构建
npm run preview                   # 预览生产版本</code></pre><h4>Next.js的开发体验</h4><ol><li><strong>灵活的配置</strong>：可根据需要深度定制</li><li><strong>TurboPack</strong>：极快的构建和刷新速度</li><li><strong>完善的文档</strong>：官方文档质量极高</li><li><strong>Vercel集成</strong>：无缝部署和预览体验</li></ol><pre><code class="bash"># Next.js的典型工作流
npx create-next-app@latest my-app  # 创建项目
npm install                        # 安装依赖
npm run dev                        # 开发模式
npm run build                      # 生产构建
npm run start                      # 启动生产服务器</code></pre><hr/><h3>06 性能与优化对比</h3><h4>性能特征</h4><ol><li><strong>首次加载性能</strong>：两者都优秀，Nuxt 3在小型项目上可能略快</li><li><strong>开发服务器速度</strong>：Next.js的Turbopack在大型项目上优势明显</li><li><strong>构建速度</strong>：取决于项目大小，两者都提供增量构建</li></ol><h4>优化技巧对比</h4><p><strong>Nuxt 3优化示例</strong>：</p><pre><code class="html">&lt;!-- 组件懒加载和图片优化 --&gt;
&lt;template&gt;
  &lt;div&gt;
    &lt;!-- 延迟加载重型组件 --&gt;
    &lt;LazyMyHeavyComponent v-if="showComponent" /&gt;
    
    &lt;!-- 自动优化的图片 --&gt;
    &lt;NuxtImg
      src="/images/hero.jpg"
      width="1200"
      height="600"
      loading="lazy"
      format="webp"
    /&gt;
  &lt;/div&gt;
&lt;/template&gt;</code></pre><p><strong>Next.js优化示例</strong>：</p><pre><code class="js">// 使用Next.js内置优化功能
import Image from 'next/image'
import dynamic from 'next/dynamic'

// 动态导入重型组件
const HeavyComponent = dynamic(() =&gt; import('./HeavyComponent'))

export default function OptimizedPage() {
  return (
    &lt;&gt;
      {/* 自动优化的图片组件 */}
      &lt;Image
        src="/hero.jpg"
        alt="Hero image"
        width={1200}
        height={600}
        priority={false} // 非关键图片延迟加载
      /&gt;
      
      {/* 条件加载重型组件 */}
      &lt;HeavyComponent /&gt;
    &lt;/&gt;
  )
}</code></pre><hr/><h3>07 新手选择建议</h3><h4>根据背景选择</h4><ol><li><p><strong>完全零基础</strong>：</p><ul><li>如果喜欢<strong>更直观的模板语法</strong> → 选择<strong>Nuxt 3</strong></li><li>如果看重<strong>就业市场需求</strong> → 选择<strong>Next.js</strong></li></ul></li><li><p><strong>有前端基础</strong>：</p><ul><li>熟悉HTML/CSS/JS → 都可尝试，根据偏好选择</li><li>有React经验 → 选择<strong>Next.js</strong></li><li>有Vue经验 → 选择<strong>Nuxt 3</strong></li></ul></li></ol><h4>根据项目类型选择</h4><table><thead><tr><th>项目类型</th><th>推荐框架</th><th>理由</th></tr></thead><tbody><tr><td>个人博客/作品集</td><td>Nuxt 3</td><td>快速搭建，SEO优秀</td></tr><tr><td>企业官网/营销页</td><td>Nuxt 3</td><td>开发效率高，维护简单</td></tr><tr><td>SaaS/管理后台</td><td>Next.js</td><td>React生态丰富，组件库多</td></tr><tr><td>电商平台</td><td>Next.js</td><td>性能优化完善，生态成熟</td></tr><tr><td>实时应用</td><td>均可</td><td>根据团队技术栈选择</td></tr></tbody></table><p>无论选择哪个框架，最重要的是<strong>开始构建</strong>。真正的经验来自于项目实践，而不是框架比较。</p><h3>🗳️ 互动时间：你的选择是？</h3><p>读完全文，相信你对 Nuxt 3 和 Next.js 有了更清晰的认识。技术选型没有标准答案，真实项目中的经验才是最宝贵的参考。</p><p><strong>欢迎在评论区分享你的观点：</strong></p><ol><li><p><strong>投票选择</strong>：你目前更倾向于或正在使用哪个框架？</p><ul><li>A. <strong>Nuxt 3</strong> (Vue阵营)</li><li>B. <strong>Next.js</strong> (React阵营)</li><li>C. <strong>两个都在用/观望中</strong></li></ul></li><li><strong>经验分享</strong>：在实际项目中，你使用 Nuxt 3 或 Next.js 时，<strong>遇到的最大挑战或最惊喜的体验是什么？</strong> 你的分享对其他开发者会非常有帮助！</li></ol><hr/><p>关注我的公众号" <strong>大前端历险记</strong>"，掌握更多前端开发干货姿势！</p><p>本文由<a href="https://link.segmentfault.com/?enc=ZHN9kH3oPvM5VO2nQc%2Bbng%3D%3D.QeUXxrBFpZ0L%2BLfXswzTRvTWqMaFCTmnN1nXEMLjrfQ%3D" rel="nofollow" target="_blank">mdnice</a>多平台发布</p>]]></description></item><item>    <title><![CDATA[工业AI大模型在汽车制造中的应用：如何选择最适合的解决方案？ 雨大王 ]]></title>    <link>https://segmentfault.com/a/1190000047554057</link>    <guid>https://segmentfault.com/a/1190000047554057</guid>    <pubDate>2026-01-20 17:02:59</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>工业AI大模型作为人工智能技术在工业领域的高度集成与应用，正在深刻改变汽车制造业的生产方式和管理逻辑。其核心在于通过融合多模态数据、应用深度学习算法以及构建全局优化系统，解决传统汽车制造中长期存在的效率瓶颈、数据割裂和质量波动等问题。在数字化转型的大背景下，工业AI大模型不仅是技术升级的工具，更是企业实现智能化运营的关键驱动力。<br/>一、工业AI大模型的核心原理与技术架构<br/>工业AI大模型的引入，标志着汽车制造业从“经验驱动”向“数据驱动”范式的转变。传统汽车工厂依赖人工经验制定生产计划，面对多车型混流、设备状态复杂和供应链波动等问题时，往往难以快速响应。而工业AI大模型通过整合设备、人员、物料、订单等多维度数据，结合实时监控和动态分析，能够实现全流程的协同优化。<br/>二、工业AI大模型在汽车制造中的实际应用价值<br/>工业AI大模型的应用正在从根本上重塑汽车制造的生产效率、质量控制和资源利用率。在焊装车间，传统的人工质检不仅效率低下，而且容易受到主观因素影响。而AI大模型通过实时采集焊接电流、电压、压力等参数，并结合多模态数据（如视觉信息、温度场数据）进行动态分析，能够快速识别虚焊、漏焊等缺陷，甚至在问题发生前进行预警。<br/>三、工业AI大模型的案例解析<br/>在汽车工厂数字化转型的实践中，工业AI大模型已经展现出其强大的赋能能力。以下将通过几个具体案例，深入探讨工业AI大模型在汽车制造中的应用效果。<br/>广域铭岛：多模态工业大模型助力汽车制造智能化升级<br/>广域铭岛的Geega工业AI应用平台在汽车制造中发挥了重要作用。其核心技术包括多模态数据融合、实时决策和闭环控制，覆盖了焊装车间、尺寸精度控制、工艺设计和供应链管理等多个环节。在焊装车间，平台每秒采集20多个关键参数，通过AI模型动态识别虚焊和漏焊问题，并自动生成补偿指令，大幅提升了生产效率和质量稳定性。<br/>赛力斯汽车：超级工厂的智能排产与质检<br/>赛力斯汽车在龙兴超级工厂中引入工业AI大模型，实现了生产全过程的智能化管理。通过部署3000多台智能制造机器人，结合AI驱动的排产优化系统，赛力斯成功将关键生产工序的自动化率提升至100%。这不仅减少了人为干预，还提高了生产效率和资源利用率。<br/>东风设备制造有限公司：焊接工艺的智能优化<br/>东风设备制造有限公司的焊装Agent 1.0系统是工业AI大模型在焊接工艺优化中的典型应用。该系统通过实时采集和分析焊接数据，实现了虚焊、漏焊等缺陷的快速识别和自动修复。与传统方法相比，Agent 1.0不仅缩短了排查时间，还提升了焊接质量的一致性，为企业带来了显著的经济效益。</p>]]></description></item><item>    <title><![CDATA[Tiktok 用户主页 视频 和 评论 爬虫，基于Python selenium 库 和 playw]]></title>    <link>https://segmentfault.com/a/1190000047554059</link>    <guid>https://segmentfault.com/a/1190000047554059</guid>    <pubDate>2026-01-20 17:02:00</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h3><strong>背景</strong></h3><blockquote>一开始是通过Api获取数据，但是最近他们增加X-Gnarly参数，而且在github上没有找有效的方案后，放弃api请求，改用页面爬取的方式。彻底避免参数加密校验。</blockquote><h3><strong>我的环境</strong></h3><pre><code>    python 3.11 
    selenium 4.39.0
    playwright 1.57.0</code></pre><h3><strong>评论页面</strong></h3><p>实现啦抓取第一页和第二页的评论，你们要是抓更多页可以吧第二页改成循环。<br/>执行脚本后会在当前目录生成一份json文件，里面是/api/comment/list/接口返回的数据。</p><pre><code> python3.11 comment_scraper.py "@mahi.islam.oliva/video/7565942090039954706"
</code></pre><p><img width="723" height="323" referrerpolicy="no-referrer" src="/img/bVdnG6U" alt="image.png" title="image.png"/></p><p>代码如下：</p><pre><code>import json
import time
import sys
import base64
import re,os
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import argparse



def merge_comments(first_page, second_page):
    """合并两页的评论数据"""
    merged_data = first_page.copy()
    if 'comments' in second_page:
        if 'comments' not in merged_data:
            merged_data['comments'] = []
        merged_data['comments'].extend(second_page['comments'])
    return merged_data

def extract_tiktok_filename(path: str) -&gt; str:
    """
    从 TikTok 路径（如 '@username/video/123456'）中提取 'username_123456'
    支持带或不带 @、带 URL 等情况
    """
    # 匹配模式：可选的 @ + 用户名（字母数字下划线.）+ /video/ + 数字ID
    match = re.search(r'@?([\w.]+)/video/(\d{16,})', path)
    if match:
        username = match.group(1)
        video_id = match.group(2)
        return f"{username}_{video_id}"
    else:
        # 如果格式不符，回退到清理后的通用方式
        safe = re.sub(r'[\\/:*?"&lt;&gt;|\s]+', '_', path.strip('@/'))
        return safe[:100]


class TiktokScraper:
    def __init__(self):
        self.comments_data = []
        self.setup_driver()


    def setup_driver(self):

        chrome_options = Options()
        chrome_options.set_capability("goog:loggingPrefs", {"performance": "ALL"})

        chrome_options.add_argument("--start-maximized")
        chrome_options.add_argument("--no-sandbox")
        chrome_options.add_argument("--headless=new")
        chrome_options.add_argument("--disable-dev-shm-usage")
        chrome_options.add_argument("--disable-blink-features=AutomationControlled")
        chrome_options.add_argument("--disable-infobars")
        chrome_options.add_argument("--disable-extensions")
        chrome_options.add_argument("--disable-gpu")  # 减少 WebGL 差异（可选）
        chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
        chrome_options.add_experimental_option('useAutomationExtension', False)

        user_agent = "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36"
        chrome_options.add_argument('user-agent={0}'.format(user_agent))

        self.driver = webdriver.Chrome(options=chrome_options)

        self.driver.execute_cdp_cmd("Emulation.setDeviceMetricsOverride", {
            "width": 1440,
            "height": 900,
            "deviceScaleFactor": 2,  # macOS Retina
            "mobile": False
        })

        # 覆盖 WebGL 参数（关键！）
        self.driver.execute_cdp_cmd("Emulation.setHardwareConcurrencyOverride", {"hardwareConcurrency": 8})
        # 1. 设置基础 UA（CDP 安全方式）
        self.driver.execute_cdp_cmd("Emulation.setUserAgentOverride", {
            "userAgent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "platform": "MacIntel"
        })

        # 2. 用 JS 覆盖高级指纹（包括 userAgentData）
        self.driver.execute_cdp_cmd("Page.addScriptToEvaluateOnNewDocument", {
            "source": """
#             delete navigator.__proto__.webdriver;

            Object.defineProperty(navigator, 'platform', { get: () =&gt; 'MacIntel' });
            Object.defineProperty(navigator, 'languages', { get: () =&gt; ['en-US', 'en'] });

            // 伪造 userAgentData
            if (!navigator.userAgentData) {
                Object.defineProperty(navigator, 'userAgentData', {
                    value: {
                        brands: [
                            { brand: "Chromium", version: "120" },
                            { brand: "Google Chrome", version: "120" },
                            { brand: "Not:A-Brand", version: "99" }
                        ],
                        mobile: false,
                        platform: "macOS",
                        getHighEntropyValues: async (hints) =&gt; ({
                            architecture: "x86_64",
                            model: "",
                            platform: "macOS",
                            platformVersion: "13.5",
                            uaFullVersion: "120.0.6099.0"
                        })
                    },
                    writable: false,
                    configurable: false
                });
            }
            """
        })

        # 覆盖 WebGL 渲染器（防指纹关键）
        self.driver.execute_cdp_cmd("Page.addScriptToEvaluateOnNewDocument", {
            "source": """
            const getParameter = WebGLRenderingContext.prototype.getParameter;
            WebGLRenderingContext.prototype.getParameter = function(param) {
                if (param === 37445) return 'Apple Inc.'; // UNMASKED_VENDOR_WEBGL
                if (param === 37446) return 'Apple GPU';   // UNMASKED_RENDERER_WEBGL
                return getParameter.call(this, param);
            };
            """
        })
        self.driver.execute_cdp_cmd("Emulation.setTimezoneOverride", {"timezoneId": "America/New_York"})
        self.driver.execute_cdp_cmd("Emulation.setLocaleOverride", {"locale": "en-US"})

    def extract_comment_response_from_logs(self):
        """从 performance 日志中提取评论 API 的完整响应"""
        try:
            logs = self.driver.get_log("performance")
        except Exception as e:
            print(f"获取日志失败: {e}")
            return None

        request_id_to_url = {}
        finished_request_ids = set()

        for entry in logs:
            try:
                message = json.loads(entry["message"])
                method = message.get("message", {}).get("method")
                params = message.get("message", {}).get("params", {})

                if method == "Network.responseReceived":
                    url = params.get("response", {}).get("url", "")
                    request_id = params.get("requestId")
                    if request_id and re.search(r'comment.*list|comments.*aweme', url, re.I):
                        request_id_to_url[request_id] = url

                elif method == "Network.loadingFinished":
                    request_id = params.get("requestId")
                    if request_id:
                        finished_request_ids.add(request_id)
            except Exception:
                continue

        for req_id, url in request_id_to_url.items():
            if req_id in finished_request_ids:
                try:
                    body = self.driver.execute_cdp_cmd(
                        "Network.getResponseBody",
                        {"requestId": req_id}
                    )
                    raw = body.get("body", "{}")
                    if body.get("base64Encoded"):
                        raw = base64.b64decode(raw).decode("utf-8")
                    data = json.loads(raw)
                    if isinstance(data, dict) and ("comments" in data or "item_comments" in data):
                        print(f"✅ 捕获评论接口: {url}")
                        return data
                except Exception as e:
                    print(f"获取响应体失败 (req_id={req_id}): {e}")

        return None

    def scroll_comment_section(self):
        """在 .TUXTabBar-content 内部查找并滚动真正的评论列表容器"""
        script = """
            const tabContent = document.querySelector('.TUXTabBar-content');
            if (!tabContent) {
                console.log('❌ .TUXTabBar-content not found');
                return false;
            }

            // 获取所有子 div
            const candidates = Array.from(tabContent.querySelectorAll('div'));

            // 按 DOM 层级深度排序（优先选深层级的，通常是列表）
            candidates.sort((a, b) =&gt; {
                let depthA = 0, depthB = 0;
                let p = a; while (p &amp;&amp; p !== tabContent) { depthA++; p = p.parentElement; }
                p = b; while (p &amp;&amp; p !== tabContent) { depthB++; p = p.parentElement; }
                return depthB - depthA; // 深的优先
            });

            for (const el of candidates) {
                const style = window.getComputedStyle(el);
                const overflowY = style.overflowY;
                // 必须满足：可滚动 + 有溢出内容
                if ((overflowY === 'auto' || overflowY === 'scroll') &amp;&amp;
                    el.scrollHeight &gt; el.clientHeight) {
                    el.scrollTop = el.scrollHeight+100;
                    console.log('✅ Scrolled real comment container');
                    return true;
                }
            }

            console.log('⚠️ No scrollable child found in .TUXTabBar-content');
            return false;
        """
        try:
            result = self.driver.execute_script(script)
            return result is True
        except Exception as e:
            print(f"滚动执行异常: {e}")
            return False

    def auto_play_and_load_more_comments(self, user_input):

        url = 'https://www.tiktok.com/' + user_input
        print(f"打开视频页面: {url}")
        self.driver.get(url)
        wait = WebDriverWait(self.driver, 20)
        # wait.until(EC.presence_of_element_located((By.TAG_NAME, "video")))
        # 等待评论tab加载完毕
        # wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "div.TUXTabBar-list")))
        wait.until(EC.presence_of_element_located((By.XPATH, "//span[@data-e2e='comment-icon']")))

        print("视频评论已加载")

        # 点击评论按钮
        try:
            comment_span = wait.until(
                EC.element_to_be_clickable((By.XPATH, '//span[@data-e2e="comment-icon"]'))
            )
            print("正在点击评论图标 (span[@data-e2e='comment-icon'])...")
            self.driver.execute_script("arguments[0].click();", comment_span)
        except Exception as e:
            print(f"无法点击评论按钮: {e}")
            return

#         time.sleep(2)
#         debug_prefix = extract_tiktok_filename(user_input)
#         try:
#             # 保存 HTML
#             with open(f"{debug_prefix}_after_click.html", "w", encoding="utf-8") as f:
#                 f.write(self.driver.page_source)
#             print(f"页面 HTML 已保存: {debug_prefix}_after_click.html")
#
#             # 保存截图
#             self.driver.save_screenshot(f"{debug_prefix}_after_click.png")
#             print(f"页面截图已保存: {debug_prefix}_after_click.png")
#         except Exception as e:
#             print(f"保存调试文件失败: {e}")

        # 加载第一页评论
        first_page_data = self.wait_for_comments(10)
        if not first_page_data:
            print("未捕获到第一页评论")
            return
        self.comments_data.append(first_page_data)

        # 模拟滚动加载更多评论
        # self.driver.execute_script("document.querySelector('.TUXTabBar-content').scrollTo(0, document.querySelector('.TUXTabBar-content').scrollHeight);")
        # 改为调用新方法
        time.sleep(1)
        if self.scroll_comment_section():
            print("已滚动加载更多评论...")
            time.sleep(1)  # 等待新评论加载
        else:
            print("无法滚动评论区，可能结构变化")

        # 加载第二页评论
        second_page_data = self.wait_for_comments(10)
        if second_page_data:
            # 假设每页返回的数据结构相似，合并 comments 字段
            merged_comments = merge_comments(first_page_data, second_page_data)
        else:
            merged_comments = first_page_data
            print("未捕获到第二页评论")


        filename = f"{extract_tiktok_filename(user_input)}.json"
        print(filename)
        with open(filename, "w", encoding="utf-8") as f:
            json.dump(merged_comments, f, ensure_ascii=False, indent=2)
        print(f"评论数据已保存到: {filename}")
        print(f"   共 {len(merged_comments.get('comments', []))} 条评论")

    def wait_for_comments(self, timeout_seconds=10):
        """等待并捕获评论API响应"""
        start_time = time.time()
        while time.time() - start_time &lt; timeout_seconds:
            comment_data = self.extract_comment_response_from_logs()
            if comment_data:
                return comment_data
            time.sleep(0.5)
        return None

    def close(self):
        if hasattr(self, "driver"):
            self.driver.quit()


def main():
    parser = argparse.ArgumentParser(
        description="Scrape TikTok comments via /api/comment/list/ ")
    parser.add_argument(
        "video_input",
        help="TikTok video URL or video_id, e.g., '/@user/video/7318855966163275054' "
    )
    args = parser.parse_args()

    video_input = args.video_input.strip()
    print(video_input)

    if not video_input:
        print("Error: Video input cannot be empty")
        sys.exit(1)


    scraper = TiktokScraper()
    try:
        scraper.auto_play_and_load_more_comments(video_input)
        time.sleep(1)  # 保持窗口打开以便观察
    finally:
        scraper.close()

    sys.exit(0)

if __name__ == "__main__":
    main()
</code></pre><h3><strong>用户页面发布的视频</strong></h3><p>这里只实现啦只第一页接口的数据， /api/post/item_list/把这个接口的数据放到啦一个json文件中。<br/>这个页面我做了根据cookie的登陆，其实不登陆应该也可以。cookie 文件是通过chrome扩展 Cookies.txt 生成。登陆TikTok后点击这个扩展下载文件下来就行。<br/><img width="594" height="410" referrerpolicy="no-referrer" src="/img/bVdnG8b" alt="image.png" title="image.png" loading="lazy"/></p><p><code>python3.11 post_item_list.py @dlw2026</code><br/><img width="723" height="187" referrerpolicy="no-referrer" src="/img/bVdnG8I" alt="image.png" title="image.png" loading="lazy"/></p><p>post_item_list.py 代码如下：</p><pre><code># scraper.py
import asyncio
import json
import sys
import argparse
from playwright.async_api import async_playwright
from cookies import load_cookies_safely


# 这是用来抓取用户主页的 /api/post/item_list/


async def scrape_tiktok_user(username):
    target_responses = []
    clean_username = username.lstrip("@")
    output_json = clean_username + "_posts.json"
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        context = await browser.new_context(
            viewport={"width": 1920, "height": 1080},
            user_agent="Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36"
        )

        cookies = load_cookies_safely()
        await context.add_cookies(cookies)
        page = await context.new_page()

         # 隐藏自动化特征
        await page.add_init_script("""
            // 隐藏 webdriver 标志
            delete navigator.__proto__.webdriver;
            window.chrome = { runtime: {} };
            // 伪造 platform 为 Mac
            Object.defineProperty(navigator, 'platform', {
                get: () =&gt; 'MacIntel'
            });
            // 伪造 userAgentData（高熵指纹）
            if (!navigator.userAgentData) {
                Object.defineProperty(navigator, 'userAgentData', {
                    value: {
                        brands: [
                            { brand: "Chromium", version: "120" },
                            { brand: "Google Chrome", version: "120" },
                            { brand: "Not:A-Brand", version: "99" }
                        ],
                        mobile: false,
                        platform: "macOS",
                        getHighEntropyValues: async (hints) =&gt; ({
                            architecture: "x86_64",
                            model: "",
                            platform: "macOS",
                            platformVersion: "13.5",
                            uaFullVersion: "120.0.6099.0"
                        })
                    },
                    writable: false,
                    configurable: false
                });
            }
        """)

        # ✅ 关键：宽松匹配 API（不再检查 content-type）
        def handle_response(response):
            url = response.url
            if (
                    "/api/post/item_list/" in url
                    and response.status == 200
                    and "tiktok.com" in url
            ):
                if not target_responses:
                    target_responses.append(response)
                    print(f"捕获 API: {url.split('?')[0]}")

        page.on("response", handle_response)

        url = f"https://www.tiktok.com/{username}"
        print(f"打开页面: {url}")
        await page.goto(url, wait_until="domcontentloaded", timeout=50000)

        # 等待用户信息出现
        try:
            await page.wait_for_selector('h1[data-e2e="user-title"]', timeout=15000)
            print("用户主页加载成功")
        except:
            print("用户信息未加载，继续尝试...")

        # 滚动一下，触发懒加载（重要！）
        await page.evaluate("window.scrollTo(0, document.body.scrollHeight / 3)")

        # 等待 API（最多 20 秒）
        for i in range(40):
            if target_responses:
                break
            if i % 10 == 0:
                print(f"⏳ 等待 API 中... ({i * 0.5}s)")
            await asyncio.sleep(0.5)

        api_data = None
        if target_responses:
            try:
                api_data = await target_responses[0].json()
                print("✅ 成功解析 JSON 数据")
            except Exception as e:
                # 如果 .json() 失败，可能是 text/plain，手动解析
                try:
                    text = await target_responses[0].text()
                    api_data = json.loads(text)
                    print("✅ 通过 .text() 成功解析 JSON")
                except:
                    print(f"❌ 完全无法解析响应: {e}")

        if api_data:
            with open(output_json, "w", encoding="utf-8") as f:
                json.dump(api_data, f, ensure_ascii=False, indent=2)
            items = api_data.get("itemList", [])
            print(f"抓取到 {len(items)} 个视频，已保存至 {output_json}")
        else:
            print("未捕获到任何 API 数据")
            # 调试：打印所有请求（可选）
#             await page.route("**/*", lambda route: print("REQ:", route.request.url) or route.continue_())
#         screenshot_path = f"{clean_username}_homepage.png"
#         await page.screenshot(path=screenshot_path, full_page=True)
#         print(f"已保存页面截图: {screenshot_path}")

        await page.wait_for_timeout(5000)
        await browser.close()
        if api_data:
            return True
        else:
            return False


def main():
    parser = argparse.ArgumentParser(description="Scrape TikTok user profile")
    parser.add_argument("username", help="TikTok username (with or without @), e.g., @dishilife or dishilife")
    args = parser.parse_args()

    username = args.username.strip()
    if not username:
        print("Error: Username cannot be empty")
        sys.exit(1)
    if not username.startswith('@'):
        username = '@' + username
    success = asyncio.run(scrape_tiktok_user(username))
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()
</code></pre><p>cookies.py脚本：</p><pre><code>import os
from datetime import datetime



COOKIES_FILE = "cookies.txt"

def load_cookies_safely():
    filepath = COOKIES_FILE
    if not os.path.exists(filepath):
        raise FileNotFoundError(f"❌ Cookie 文件不存在: {os.path.abspath(filepath)}")

    cookies = []
    current_ts = int(datetime.now().timestamp())
    tiktok_domains = {".tiktok.com", "www.tiktok.com"}

    with open(filepath, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line or line.startswith("#"):
                continue
            parts = line.split("\t")
            if len(parts) &lt; 7:
                continue

            domain = parts[0]
            if domain.startswith("#HttpOnly_"):
                domain = domain[len("#HttpOnly_"):]
            if not domain.startswith("."):
                domain = "." + domain.lstrip(".")

            if not any(t in domain for t in tiktok_domains):
                continue

            cookie = {
                "name": parts[5],
                "value": parts[6],
                "domain": domain,
                "path": parts[2],
                "secure": parts[3].upper() == "TRUE",
            }

            expires_str = parts[4]
            if expires_str.isdigit():
                expires = int(expires_str)
                if expires &gt; current_ts:
                    cookie["expires"] = expires

            cookies.append(cookie)

    if not cookies:
        raise ValueError("❌ 未加载有效 Cookie！请确认包含 sessionid。")
    return cookies

if __name__ == "__main__":
    print('不可以直接执行')</code></pre>]]></description></item><item>    <title><![CDATA[TNG Digital基于OceanBase构建东南亚金融科技支付场景核心数据底座 OceanBas]]></title>    <link>https://segmentfault.com/a/1190000047554086</link>    <guid>https://segmentfault.com/a/1190000047554086</guid>    <pubDate>2026-01-20 17:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><strong>摘要：</strong></p><p><strong><em>OceanBase 凭借原生分布式、零停机、全栈多云兼容三大核心技术优势，精准破解 TNG Digital 在高并发支撑、业务连续性等方面的痛点，助力其实现从“宕机危机”到“99.99%高可用”的跨越式升级,成为其规模化盈利的技术基石，打造了分布式数据库以硬核技术赋能东南亚头部金融科技企业核心支付场景的标杆范例，为分布式数据库基础软件出海提供“技术适配+低成本落地”的全新实践路径。</em></strong></p><p>作为马来西亚金融科技领域的领军者，TNG Digital 凭借 TNG eWallet 深度融入民众支付生活，全面覆盖交通出行、餐饮消费、资金转账等高频场景。</p><p>自 2018 年起，其用户规模实现超 10倍爆发式增长，截至 2025 年，已服务马来西亚 3300 万人口中的 2500 万验证用户，成为支撑区域数字经济运转、贯穿民生服务的关键信息基础设施。</p><p>然而，高速增长背后暗藏技术“生死考验”，OceanBase 凭借原生分布式、零停机、全栈多云兼容三大核心技术优势，精准破解 TNG Digital 在高并发支撑、业务连续性等方面的痛点，助力其实现从“宕机危机”到“99.99%高可用”的跨越式升级。</p><p>本次合作不仅成为 TNG Digital 规模化盈利的技术基石，更打造了分布式数据库以硬核技术赋能东南亚头部金融科技企业核心支付场景的标杆范例，为分布式数据库基础软件出海提供“技术适配+低成本落地”的全新实践路径。</p><h2>增长阵痛：金融科技高并发场景下的核心数据底座短板</h2><p>作为承载马来西亚数千万用户日常支付的核心平台，TNG Digital 的系统稳定性直接关系到民生服务体验与金融市场秩序。</p><p>Leslie Lip（TNG Digital CTO）坦言，业务年增长率达 2-3 倍的背后，是技术团队不断与“规模陷阱”博弈的过程。</p><p>核心痛点集中于数据底座的四大短板：</p><p><strong>·    突发流量峰值应对失效</strong></p><p>午间支付高峰时段，全钱包系统需承载巨大的交易压力，而原有数据库难以支撑政府补贴发放等非常规突发流量。TNG Digital 曾在 6 年前发生的数据异常，正是因为原有数据库架构缺陷导致服务器资源未充分利用从而陷入瓶颈，暴露了核心数据底座的“抗冲击”能力不足。</p><p><strong>·    业务迭代中的停机风险</strong></p><p>金融科技平台需通过高频表结构更新，适配支付场景创新，但原有数据库的 DDL 变更常导致生产环境停机，直接影响用户支付、转账等核心操作的连续性，成为业务快速迭代的“绊脚石”。</p><p><strong>·    多云扩展的兼容性壁垒</strong></p><p>业务初期依托阿里云，随规模扩张延伸至 Azure、AWS 等多平台，但不同云厂商的数据库服务存在适配鸿沟，既无法实现跨云协同运维，又面临被单一厂商绑定的“vendor lock-in”风险，制约 TNG Digital 的全球化布局步伐。</p><p><strong>·    性能与成本的失衡困境</strong></p><p>用户增长带来数据量爆发式累积，原有数据库存储效率低下，导致 IDC 运维与存储成本持续攀升；同时在相同硬件规格下，吞吐量难以匹配业务增长需求，形成“成本涨、性能滞”的恶性循环。</p><h2>OceanBase 破局之道：以“支付级”能力适配金融科技核心需求</h2><p>Leslie Lip 强调，选择 OceanBase 的核心逻辑是“解决真实业务痛点，而非单纯追求技术参数升级”。</p><p>针对 TNG Digital 在支付场景高并发、业务连续性、多云扩展等方面的核心诉求，OceanBase 提供了贴合金融科技特性的全链路解决方案：</p><p><strong>01零停机解决核心技术破解迭代难题</strong></p><p>依托原生分布式架构设计，OceanBase 实现核心表 DDL 操作零停机执行的关键技术突破——在 POC 阶段即完成 4 万 TPS CRUD 并发场景下的表结构更新测试，全程无业务中断、无性能衰减。</p><p>这一技术特性彻底解决了 TNG Digital 高频迭代中的停机隐患，为支付场景快速创新扫清核心技术障碍。</p><p><strong>02原生分布式架构扛住峰值压力</strong></p><p>OceanBase 采用“share-nothing”原生分布式架构，具备线性弹性扩展能力，可按需扩容支撑业务增长。</p><p>该技术特性使其既能轻松承接午间的常规高峰流量，更能应对政府补贴发放等非常规突发流量的冲击，从底层架构层面杜绝宕机风险，完美匹配支付场景对高可用的极致要求。</p><p><strong>03全栈多云一致性体验能力</strong></p><p>OceanBase 内置全栈多云兼容技术模块，通过统一的技术接口与适配层，完美兼容阿里云、Azure、AWS 三大云平台的底层环境，实现不同云平台下的部署架构、运维操作、性能表现及合规审计的全链路一致性体验。</p><p>这一核心技术特性，不仅为 TNG 搭建了 “以私有化部署为核心、多云协同为延伸” 的弹性 IT 架构，保障了征信数据跨云流转与管理的稳定性、安全性，更从技术层面帮助 TNG Digital 彻底摆脱 “vendor lock-in” 制约，为其后续拓展东南亚其他区域征信服务、接入更多全球云服务提供商奠定了核心基础，让 TNG Digital 在全球化业务布局中具备更强的技术灵活性与成本可控性。</p><p><strong>04高压缩比+高性能优化技术提升效益</strong></p><p>OceanBase 基于高压缩的数据引擎，实现 5 倍数据体积缩减的技术效果，大幅降低存储与运维成本。</p><p>同时凭借分布式执行引擎优化技术，在相同硬件规格下实现 40% 的吞吐量提升，精准破解 TNG Digital “成本涨、性能滞”的核心困境，为金融科技企业盈利化发展提供技术支撑。</p><p><strong>05全量 MySQL 兼容技术加速落地见效</strong></p><p>OceanBase 深度打磨 MySQL 兼容层技术，实现语法、应用行为、驱动的全量兼容。</p><p>这一技术特性使 TNG Digital 技术团队无需额外学习成本即可快速上手，大幅缩短项目升级与落地周期，实现技术升级的“平滑过渡”。正如 Leslie Lip 所言，OceanBase 不仅是数据库，更是“能伴随企业野心共同成长的技术平台”。</p><h2>实现从“生存线”到“增长线”的价值跃升</h2><p>基于 OceanBase 完成核心数据底座升级后，TNG Digital 在业务稳定性、运营效率、创新能力三大维度实现质的飞跃，关键成效完全匹配金融科技支付场景的核心诉求：</p><p><strong>01支付连续性达行业顶尖水平</strong></p><p>核心系统实现 99.99% 的高可用，与 OceanBase 合作至今，未发生任何数据库事故，成功支撑多轮政府补贴发放等重大场景的平稳运行，彻底摆脱过往宕机阴影，筑牢支付业务“生存线”。</p><p><strong>02性能与成本效益双突破</strong></p><p>相同硬件规格下，业务吞吐量提升 40%，高效承接高峰期高并发交易；5 倍数据压缩比大幅降低存储成本，为企业盈利化发展提供有力支撑，将数据底座从“成本中心”转化为“效益中心”。</p><p><strong>03创新与拓展能力全面释放</strong></p><p>零停机 DDL 与多云协同能力，为 TNG Digital 的场景迭代与跨平台拓展扫清障碍。</p><p>目前双方已启动键值数据库模型搭建、跨云双活架构合作等计划，将基于 OceanBase 构建更具弹性的时间敏感型支付应用，进一步拓宽业务增长边界。</p><h2>从服务本土支付场景的分布式数据库，到支撑海外支付场景的分布式数据库</h2><p>金融科技的规模化增长，本质是数据底座“抗冲击能力、迭代能力、扩展能力”的综合较量。</p><p>TNG Digital 作为东南亚支付领域的龙头企业，其面临的“高并发、零中断、多云扩展”痛点，是全球金融科技企业规模化过程中的共性难题。OceanBase 的成功落地，不仅解决了单一企业的技术困境，更提供了适配支付场景核心需求的可复制技术方案。</p><p>OceanBase 与 TNG Digital 的合作，标志着分布式数据库凭借“原生分布式+零停机+全栈多云兼容”等硬核技术特性，已具备支撑海外头部金融科技核心支付场景的成熟能力，实现从“国内核心场景验证”到“海外高频支付场景落地”的关键跨越。</p><p>区别于其他出海案例，此次合作的核心亮点在于以技术特性精准匹配支付场景需求——零停机保障业务迭代连续性，原生分布式支撑高并发峰值，多云兼容打破拓展壁垒，这些技术优势共同重塑了海外市场对分布式数据库基础软件在支付场景下的技术认知。</p><p>未来，OceanBase 将持续深化与 TNG Digital 的协同创新，助力其实现云服务提供商拓展、跨云韧性升级等战略目标，同时进一步完善东南亚市场的本地化服务体系，聚焦金融科技支付、数字钱包等核心场景，为更多海外企业提供“支付级”稳定、高效、经济的数据底座支撑，推动分布式数据库基础软件全球化布局向“场景化深度赋能”新阶段迈进。</p><p>欢迎访问 OceanBase 官网获取更多信息：<a href="https://link.segmentfault.com/?enc=5reswDRzNbPfg%2FjwA9b89g%3D%3D.xMMzRGznYMzWr5oT1NIYNCS94c5kuaqlRe5oBSgHDpA%3D" rel="nofollow" target="_blank">https://www.oceanbase.com/</a></p>]]></description></item><item>    <title><![CDATA[Codigger 官网新界面上线，诚邀体验全新浏览风貌 codigger ]]></title>    <link>https://segmentfault.com/a/1190000047553269</link>    <guid>https://segmentfault.com/a/1190000047553269</guid>    <pubDate>2026-01-20 16:16:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>Codigger 官网（<a href="https://link.segmentfault.com/?enc=uRk6m%2B3t8qoCI5WhKVUFyw%3D%3D.itNzHkLgHhbe%2F81vLjmrfplRMNe4gp2Fu46g7y%2FnA22duk2S79D2mUsJsFlPKTt8" rel="nofollow" target="_blank">https://newabc.codigger.com/web/portal/</a>）已完成界面更新，现正式对外开放。本次更新聚焦于浏览体验优化，呈现更直观的视觉设计与更清晰的功能导航，方便用户快速了解平台核心方向，后续核心功能仍在开发推进中。<br/><img width="723" height="433" referrerpolicy="no-referrer" src="/img/bVdnGWj" alt="image.png" title="image.png"/><br/>作为一款围绕分布式计算构建的平台，Codigger 的核心构想包括将算力转化为 “公用事业”—— 支持按需调用节点资源、共享闲置算力；保障数据主权 —— 采用本地存储与加密分片技术，探索数据合规变现路径；同时打造适配分布式场景的工具生态，如集成开发环境 SIDE、终端工具 Terminai 等，为开发者提供协同与效率支持。<br/><img width="723" height="433" referrerpolicy="no-referrer" src="/img/bVdnGWk" alt="image.png" title="image.png" loading="lazy"/><img width="723" height="433" referrerpolicy="no-referrer" src="/img/bVdnGWl" alt="image.png" title="image.png" loading="lazy"/><br/>此次新界面上线，可帮助用户更清晰地获取平台架构、核心理念及工具矩阵相关信息。若您对分布式计算工具与开发生态感兴趣，不妨访问官网，提前体验新界面的浏览逻辑与信息呈现方式，后续平台功能迭代也将通过官网及时同步。<br/><img width="723" height="433" referrerpolicy="no-referrer" src="/img/bVdnGWm" alt="image.png" title="image.png" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[AAAI 2026 | 西北工业大学提出YOLO-IOD，实时增量目标检测新框架 Lab4AI ]]></title>    <link>https://segmentfault.com/a/1190000047553274</link>    <guid>https://segmentfault.com/a/1190000047553274</guid>    <pubDate>2026-01-20 16:15:45</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>AAAI 2026 | 西北工业大学提出YOLO-IOD，实时增量目标检测新框架</h2><p>该篇论文被 AAAI 2026 录用。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553277" alt=" " title=" "/></p><p>论文标题：<em>YOLO-IOD: Towards Real Time Incremental Object Detection</em></p><p><a href="https://link.segmentfault.com/?enc=%2BmMUCG67QX5yK4IiHO7mWA%3D%3D.IeJzzVU7ALl7Sq6u9yA9JhOFB6YJhPWZ180xqixcgDOReVVvfywXqrh4c2hysecu" rel="nofollow" target="_blank">GitHub项目</a></p><p><a href="https://link.segmentfault.com/?enc=AN1IxcVn1x1UWMR8bL0CbA%3D%3D.DIiEYCkSv6dI%2F9T1l8b3muwq%2FDgjJwPwikQBNf8DSWiUg18XoYUrnT9DDk37SVfmrs631oKnn2SEEfhh1lEROJJcb3pP2aTWOBexTX3cYBFK51mPhYhjQtKu2xAtq0nX" rel="nofollow" target="_blank">大模型实验室</a>论文阅读</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553278" alt=" " title=" " loading="lazy"/></p><h3>01 引言</h3><p><a href="https://link.segmentfault.com/?enc=3c1fqgRC3W1OIxqZfIv7WA%3D%3D.cnSRX9%2FCq7E8W89kNPobKjtGy9sD4i9TVUmVugI6ltW9gQ9SWC%2Bj9gct6pnmL2fJBudnX6r3N9sZ6fUYW4xI6qWDxOuzZhD6oxso%2FN%2B9lpOYvp6zolIDi3lkrXag8D0q" rel="nofollow" target="_blank">增量目标检测</a>（IOD）是一个让目标检测模型能够像人类一样持续学习、积累知识的任务。它的核心目标是在不断吸收新类别信息的同时，有效克服对旧类别的“灾难性遗忘”。</p><p>传统方法（如Faster R-CNN）可以逐步学习新类别（比如从猫狗扩展到飞机、船），但这类方法速度慢，无法满足实时检测需求。而速度更快的YOLO模型在增量学习时却像“健忘症患者”，它学完新类别后，容易忘记旧类别。</p><p>论文发现，这种“遗忘”主要源于三大冲突：</p><ul><li>前景-背景混淆：训练新类别时，图中未标注的旧类别物体会被误判为“背景”，导致模型逐渐遗忘它们。</li><li>参数干扰：模型参数像大脑的<a href="https://link.segmentfault.com/?enc=DXa5z2BIAZzrWHt%2FBMZQJQ%3D%3D.Uu2pfU2KYBJWA5GSUD%2BLKmT%2B7PnvQqb20FJ2ZNJNjI8pl242QhWMd2IuMFp8DnSsEFnTFYLOzIHPuDkdzrFvj944Zb4wf77i212x78tAUi7F8A8YkBBGs73X4mhJanN%2B" rel="nofollow" target="_blank">神经元</a>，学习新任务时会修改与旧任务共享的参数，从而破坏原有知识。</li><li>知识蒸馏错位：传统方法用“教师模型”指导“学生模型”，但新旧类别的学习目标不一致，导致指导过程混乱。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553279" alt=" " title=" " loading="lazy"/></p><p>另外，现有IOD基准存在类别划分随意、图像跨阶段重复等问题，难以反映实际应用场景。</p><p>基于以上，本文构建一个基于<a href="https://link.segmentfault.com/?enc=BnC%2Bd30DwHcQUBeW%2B5cYBw%3D%3D.LHKCYOplrp6I9XPbAaO9KQQ2oLg2b44YUiHTsuuD1NiedHr2vtymHYZWQB4E%2FS2W5KBvYRUSJe5SrHM%2FZrZzU7Kbh0r9uz6TMFRwq8cbpzIanfVPM2zbqygFyzG0SndW" rel="nofollow" target="_blank">YOLO-World</a>的实时增量目标检测框架<a href="https://link.segmentfault.com/?enc=kJqinzXfd4a2QDhleFq0Ew%3D%3D.IL90Pmb3H0HPjrbbuU1U9kAJrBo3fkNWUXyQ0SiDKfe%2B8w41ZxSTGQJi87sa%2Ffq1Er35oWGM%2B%2FCdIAxTFuWiMWZDToJEn9w3JqwgV7MVpi4fO%2B00J%2FL52vhRh2E48NvW" rel="nofollow" target="_blank">YOLO-IOD</a>，通过阶段化参数高效微调解决YOLO模型在增量学习中的知识冲突问题，实现对新类别的持续学习的同时有效保留历史类别知识。</p><h3>02 核心思路</h3><h4>2.1三大妙招</h4><p>论文提出YOLO-IOD框架：基于现成的<a href="https://link.segmentfault.com/?enc=sF6Su6u3Vzh86xtRxosSfA%3D%3D.cNObixpatjp2GNAra5YR%2Ft1Q3jz0p7USYF7%2FWtJ6D%2Bp%2F9GmrDpv57%2Br3%2BcOPsk9tS0geNl2CbiGVPf4za0HRMLIcmSC%2F7FIiBD6LEm8glfAhOXA2kj%2BTMNdWeGF3VQRJ" rel="nofollow" target="_blank">YOLO-World</a>模型，通过三招解决上述问题。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553280" alt=" " title=" " loading="lazy"/></p><h5>妙招1：CPR（冲突感知伪标签精炼）— 解决 “前景背景搞混”</h5><ul><li>增强伪标签损失：采用<a href="https://link.segmentfault.com/?enc=vD9RaMS1EFpXcLf%2BSV71NA%3D%3D.HaZlP5u3hf%2BuI9HKxYWFnzutgcrrQ7mLepkvRVnjEvT%2FU6GaJuKUQKZQ6vLjnNI2GOWka%2BwkvMruzxuUBdGWd%2FTuHKl%2FzzQpDcXC0Ln2uB3uwWronsUP6OoR3%2BuZQQkV" rel="nofollow" target="_blank">置信度</a>对齐的焦点损失和自适应熵正则化，充分利用不同置信度的伪标签。即：对模型自己生成的旧类别预测（伪标签）按置信度加权，高置信度的重点学习，低置信度的谨慎参考，避免错误引导。</li><li>聚类未知伪标签：构建通用词汇集，通过<a href="https://link.segmentfault.com/?enc=eYChTVFy3HDxTb38x3YUYA%3D%3D.zOKNmJQ016cwkYSlz0mrwdO%2Bubyrxafj18%2FjiXhyGBzQEvINOJ347gzAFfkxxl04gHC2dfekDi%2Frs2E9x658%2BzYU1V%2FDrb2XUi%2Bz9u16Pfpw80D18wSnV58lcb7NaZV%2B" rel="nofollow" target="_blank">开放词汇检测</a>识别未标注前景目标，对其文本特征进行频率加权 K-Means 聚类，将未来任务类别转化为 “未知超类” 进行学习，避免前景 - 背景混淆。</li></ul><h5>妙招2：IKS（基于重要性的核选择）— 解决 “参数互相干扰”</h5><p>只选择对当前任务关键的部分参数（约12%的卷积核）进行微调，其他参数冻结不动，像“保护重要记忆不受新知识干扰”。</p><h5>妙招3：CAKD（跨阶段非对称知识蒸馏）— 解决 “老师教错方向”</h5><p>将学生模型的特征分别输入旧教师模型和新教师模型的检测头，通过分类和回归蒸馏损失传递知识，并使用焦点权重抑制背景区域干扰。即：让“学生模型”同时接受两位老师指导。</p><ul><li>老老师：就是之前学完旧物体的模型，只负责教 “旧知识”，而且会主动忽略和新物体无关的内容（比如只教 “猫狗”，不干扰 “无人机” 的学习）；</li><li>新老师：专门用新数据训练的临时模型，只负责教 “新物体知识”，也会忽略旧物体的干扰；</li><li>新模型（学生）：同时听两个老师的课，把旧知识和新知识融合起来，这样既不会忘旧的，也能学好新的。</li></ul><h4>2.2 引入LoCo COCO基准</h4><p>现有评测基准存在“数据泄露”——同一张图片在不同阶段重复使用，使模型表现虚高。论文提出<a href="https://link.segmentfault.com/?enc=e8J%2FlyN1aoFvwdbphJ789Q%3D%3D.ck82AD1CPcg7%2BlXkoKVl49STR6PJO2xWnHaE2xcDGE8A0CVrp%2Bg%2BINiH9q5Tl9E3iDKwi%2FjmxqtUvcfKL0nyyWHUHROBpqe%2FZL1dljjE05p4guAibRL497pklV%2FsHkif" rel="nofollow" target="_blank">LoCo COCO基准</a>，通过两类改进更贴近现实：</p><ul><li>按共现关系分组：将常同时出现的类别（如“汽车”和“行人”）分到同一阶段，避免强行拆分。</li><li>禁止图像重复：每张图片仅出现在一个阶段，杜绝数据泄露。</li></ul><h3>03 实验结果</h3><h4>3.1 在传统COCO基准上的性能</h4><p>单步增量设置下，YOLO-IOD在40+40和70+10任务中分别达到53.0%和52.4%的mAP，相对联合训练的差距降至2.7%和3.9%，显著优于BPF、CL-DETR等方法。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553281" alt=" " title=" " loading="lazy"/></p><p>多步增量设置下，在40-10、20-20等任务中均取得最优结果，尤其在10-10任务中相对差距仅8.8%，显著优于对比方法。</p><h4>3.2 在LoCo COCO基准上的鲁棒性</h4><p>所有方法在 LoCo COCO 上 AP 均有 0.6%-2.0% 下降（验证数据泄露的影响），但 YOLO-IOD 仍保持优势，40+40、70+10、40-20 设置下 AP 分别超此前最佳方法 GCD 7.5、5.9、8.5 个百分点。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553282" alt=" " title=" " loading="lazy"/></p><h4>3.3 消融实验</h4><ul><li>三大模块协同有效：CPR、IKS、CAKD 分别带来显著性能提升，组合后效果最优。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047553283" alt=" " title=" " loading="lazy"/></li><li>CAKD 双教师架构最优：早期阶段“仅当前教师”适配新类别更快，后期“仅旧教师”保留知识更优，双教师融合始终表现最佳。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047553284" alt=" " title=" " loading="lazy"/></li><li>IKS 核选择比例：κ=12% 时实现稳定性与可塑性平衡，性能最优。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047553285" alt=" " title=" " loading="lazy"/></li></ul><h3>04 快速上手</h3><p>作者在GitHub上公开了该项目，并且在环境安装步骤中提到：“请按照 YOLO-World 的安装说明来设置环境。”</p><p><a href="https://link.segmentfault.com/?enc=gAsPaXUTgelh0zjjwItmSw%3D%3D.aV76X3Ggdo0Xdya31AjKC7G%2BazjGU3azcLBuVnILWxPvH16HrBw72pS3lS68LzNAER%2F83U05wyNFOdCJs8vat8XroqQJs3kr3W7ijekj0SF16Vk19pGWVzf0P7o1Eje%2B" rel="nofollow" target="_blank">大模型实验室</a>Lab4AI已经内置好了<a href="https://link.segmentfault.com/?enc=vyBnYxvkl4IzsjzM5SLiJA%3D%3D.FObKdTYI2j3IbGsS5XyvEcJrVkyQBT5XmjxAVY%2FSq9ngT%2BFmprgSI93WTgwSZ1lY%2FQdF1OShvz8nH3Bgr7BBjnDGGm6I6g%2Fve51rWzNbPbSRr33Q4%2BpfWSuDV3FCux7i" rel="nofollow" target="_blank">YOLO-World</a>论文的复现所需的环境。所以，您可以登录<a href="https://link.segmentfault.com/?enc=IXKSIS8VRqQBa%2FW2f7eu1Q%3D%3D.v9YPyLFe2HW%2Bmc6M9ns0aGk%2FyxHKRedMl0UZhM3SwG6B9KgCW79PvfBco6Efv%2FrQAiENZspbnDQaQ2B%2BWRAsahtp1ntphY1q3WsAYFS86t70i5skaduetdqaW8wg8txN" rel="nofollow" target="_blank">大模型实验室</a>Lab4AI来直接使用该环境进行体验本论文的训练过程。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553286" alt=" " title=" " loading="lazy"/></p><h3>05 总结</h3><p>论文针对 <strong>YOLO 框架下增量目标检测的知识冲突问题</strong>，提出 YOLO-IOD 实时框架，通过 <strong>CPR、IKS、CAKD</strong> 三大模块分别解决前景-背景混淆、参数干扰、蒸馏错位，实现知识保留与新增类别学习的平衡。</p><p>提出的 <strong>LoCo COCO 基准</strong>消除了跨阶段数据泄露，更贴合实际应用场景，为 IOD 方法评估提供了公平、真实的平台。</p><p>大量实验验证了 <strong>YOLO-IOD 在传统 COCO 和 LoCo COCO 基准上的 SOTA 性能</strong>，且保持<a href="https://link.segmentfault.com/?enc=NktamUE2Kj7A9dE%2FJv6STg%3D%3D.z4WILVY945wIcUwvE0HPJ34VGhADTpu6qFyxRu%2BaO7oC15jWZMF9O8jD1zrQxE1pgxunJSwicZtjwcKMfer53AfSg9XMgzBwQOH3SRLQcIrtkiI2SUS%2F1N686KirVWDX" rel="nofollow" target="_blank">实时推理</a>速度，证实了方法的有效性与实用性。</p><p><strong>关注“<a href="https://link.segmentfault.com/?enc=Ylmg%2FME6hVRbqhpOzS%2BK2A%3D%3D.q7Y94TsGVkjWtEZZh9fPbefLPNcEHvBe%2F6ql6WlRmAf9VPutnlFbIuCZ8RcrITqbIy%2BWM5CluiXbLTawlfWrkIKir5OS2JdjVoayW4eBRWvB1IseOcKQhW8VlqT%2BAHJC" rel="nofollow" target="_blank">大模型实验室</a>Lab4AI”，第一时间获取前沿AI技术解析！</strong></p>]]></description></item><item>    <title><![CDATA[Linux开机默认显示grub 打篮球的凳子 ]]></title>    <link>https://segmentfault.com/a/1190000047553389</link>    <guid>https://segmentfault.com/a/1190000047553389</guid>    <pubDate>2026-01-20 16:14:59</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在 Ubuntu 的默认配置中，当系统检测到仅存在一个操作系统时，GRUB 启动菜单会被隐藏，系统会直接进入内核启动流程。这种“无感启动”在桌面用户场景下较为友好，但在 服务器、运维、开发和多内核管理场景 中，会带来一系列明显的痛点。</p><p>可通过配置grub控制默认是否显示grub界面以及倒计时相关的配置</p><h2>配置文件路径</h2><ol><li><code>ubuntu</code> grub配置文件路径</li></ol><p><code>/etc/default/grub</code></p><ol start="2"><li><code>centos</code> grub配置文件路径</li></ol><p><code>/etc/sysconfig/grub</code></p><h2>默认配置文件内容</h2><pre><code class="ini"># If you change this file, run 'update-grub' afterwards to update
# /boot/grub/grub.cfg.
# For full documentation of the options in this file, see:
#   info -f grub -n 'Simple configuration'

GRUB_DEFAULT=0
GRUB_TIMEOUT_STYLE=hidden
GRUB_TIMEOUT=0
GRUB_DISTRIBUTOR=`lsb_release -i -s 2&gt; /dev/null || echo Debian`
GRUB_CMDLINE_LINUX_DEFAULT="quiet splash"
GRUB_CMDLINE_LINUX=""

# Uncomment to enable BadRAM filtering, modify to suit your needs
# This works with Linux (no patch required) and with any kernel that obtains
# the memory map information from GRUB (GNU Mach, kernel of FreeBSD ...)
#GRUB_BADRAM="0x01234567,0xfefefefe,0x89abcdef,0xefefefef"

# Uncomment to disable graphical terminal (grub-pc only)
#GRUB_TERMINAL=console

# The resolution used on graphical terminal
# note that you can use only modes which your graphic card supports via VBE
# you can see them in real GRUB with the command `vbeinfo'
#GRUB_GFXMODE=640x480

# Uncomment if you don't want GRUB to pass "root=UUID=xxx" parameter to Linux
#GRUB_DISABLE_LINUX_UUID=true

# Uncomment to disable generation of recovery mode menu entries
#GRUB_DISABLE_RECOVERY="true"

# Uncomment to get a beep at grub start
#GRUB_INIT_TUNE="480 440 1"
</code></pre><p>主要关注以下三个参数</p><pre><code class="ini">GRUB_DEFAULT=0
GRUB_TIMEOUT_STYLE=hidden
GRUB_TIMEOUT=0</code></pre><p><code>GRUB_DEFAULT</code></p><p>默认引导项，可以有以下几种值</p><ol><li><code>saved</code> 代表上次启动时选择的引导项</li><li>从0开始的数字，第一个引导项是0，第二个引导项是1，以此类推</li></ol><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553392" alt="" title=""/></p><p>如上图<code>Previous Linux Versions</code>存在的子菜单可以用<code>2&gt;0</code>或者<code>2&gt;1</code>表示</p><ol start="3"><li>grub选项名</li></ol><p><code>GRUB_TIMEOUT_STYLE</code></p><p>grub显示风格，默认值是<code>menu</code></p><p>可选值有<code>menu</code>,<code>hidden</code>,<code>countdown</code></p><p>如果该选项未设置或者值设为menu,启动时将显示grub，并开启<code>GRUB_TIMEOUT</code>倒计时。倒计时结束前可以按任意键中断倒计时，否则倒计时结束后会引导<code>GRUB_DEFAULT</code>启动项。</p><p>如果选项设置为<code>hidden</code>或<code>countdown</code>,在显示grub界面之前会开启<code>GRUB_TIMEOUT</code>倒计时。倒计时结束前按<code>ESC</code>键中断倒计会进入grub界面，如果没有按<code>ESC</code>键进行中断操作，倒计时结束后会引导<code>GRUB_DEFAULT</code>启动项。</p><p><code>hidden</code>和<code>countdown</code>的区别在于，<code>hidden</code>不显示倒计时读秒，<code>countdown</code>显示倒计时读秒</p><p><code>GRUB_TIMEOUT</code></p><p>这个参数代表grub的超时时间，单位是秒，默认值为<code>5</code>,设置为<code>0</code>代表不显示grub界面，<code>-1</code>代表一直等待</p><h2>例子</h2><pre><code class="ini">GRUB_DEFAULT=0
GRUB_TIMEOUT_STYLE=menu
GRUB_TIMEOUT=5</code></pre><p>修改后执行<code>update-grub</code>应用配置，重启后必定进入grub界面</p><pre><code class="ini">GRUB_DEFAULT=1
GRUB_TIMEOUT_STYLE=countdown
GRUB_TIMEOUT=5</code></pre><p>修改后执行<code>update-grub</code>应用配置，重启后在5秒倒计时结束前按<code>ESC</code>必定进入grub界面</p><pre><code class="ini">GRUB_DEFAULT="2&gt;1"
GRUB_TIMEOUT_STYLE=menu
GRUB_TIMEOUT=5</code></pre><p>修改后执行<code>update-grub</code>应用配置，重启后在5秒倒计时结束后会引导指定启动项，这个方法对于客户要求进入旧版本内核比较好用</p>]]></description></item><item>    <title><![CDATA[rector-rules - 提供标准化的常量、变量、函数、类、属性和方法命名以及其他 Rector]]></title>    <link>https://segmentfault.com/a/1190000047553402</link>    <guid>https://segmentfault.com/a/1190000047553402</guid>    <pubDate>2026-01-20 16:14:22</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>rector-rules - 提供标准化的常量、变量、函数、类、属性和方法命名以及其他 Rector 规则</h2><blockquote><p>之前写过用 Rector <a href="https://link.segmentfault.com/?enc=cZ9NLpAMFoQ0hrziyts3Qw%3D%3D.LjleJbf50eL2Q5c9syw94Bo7IeTASVaD4UaByONPPaZ4es6h%2F9DSvvkiOBYuYYxz" rel="nofollow" target="_blank">《统一规范化代码的命名风格》</a>，现在已经整理发布为 Composer 包了。</p><p><a href="https://link.segmentfault.com/?enc=zVZ2755Pp99li6ys7xa%2BSA%3D%3D.6i%2BF4mc5%2FN9xqhIko2feSCYS%2F45nZsg%2B3Xo3SkR24NBgAzGQysCC%2BlQ2v6YsMZs7" rel="nofollow" target="_blank">rector-rules</a> - 提供标准化的常量、变量、函数、类、属性和方法命名以及其他 Rector 规则。</p></blockquote><h3><a href="https://link.segmentfault.com/?enc=%2B%2FjLWt5BNPOjSvcoOQcG8g%3D%3D.pD9vqFvGK%2BZdSxvAUtM7xllDw5Mj8sVWhF5T0%2BhrGgBIDiw5Y8efE3aOVw2cvJluPd9hEE4x%2FIIVwENzx2RH56%2FWOSLg9y5nZAtWOzA1fsY%3D" rel="nofollow" target="_blank">Rector 规则总览</a></h3><h3><a href="https://link.segmentfault.com/?enc=czbTe8kw9iw1ZkL3S%2FplxQ%3D%3D.HrQqpzhNxBZrR65cTc6tH1UdjeXTn3aQ3A2XSwf%2FveL%2B6LyL3JFKO%2BYe%2Fu%2BuuB6hE8Qc8jHelpO3%2FO6BskRjxQ%3D%3D" rel="nofollow" target="_blank">Rector 规则集总览</a></h3><ul><li><code>Guanguans\RectorRules\Set\SetList::ALL</code></li><li><code>Guanguans\RectorRules\Set\SetList::COMMON</code></li><li><code>Guanguans\RectorRules\Set\SetList::PHPBENCH</code></li><li><code>Guanguans\RectorRules\Set\SetList::PHPSTAN</code></li><li><code>Guanguans\RectorRules\Set\SetList::RECTOR</code></li></ul><h3>配置使用规则集和规则</h3><pre><code class="php">use Guanguans\RectorRules\Rector\File\SortFileFunctionStmtRector;
use Guanguans\RectorRules\Rector\Name\RenameToPsrNameRector;
use PhpParser\NodeVisitor\ParentConnectingVisitor;
use Rector\Config\RectorConfig;

return RectorConfig::configure()
    -&gt;withSets([
        Guanguans\RectorRules\Set\SetList::ALL,
        // ...
    ])
    // ...
    -&gt;registerDecoratingNodeVisitor(ParentConnectingVisitor::class)
    -&gt;withConfiguredRule(RenameToPsrNameRector::class, [
        'assertMatches*Snapshot', // 排除 spatie/pest-plugin-snapshots 包的函数名称
        'beforeEach', // 排除 pestphp/pest 包的函数名称
        'PDO', // 排除 PDO 类名称
    ])
    // ...
    -&gt;withRules([
        SortFileFunctionStmtRector::class,
        // ...
    ]);</code></pre><h3>另外推荐下其他相关类似的包</h3><ul><li><a href="https://link.segmentfault.com/?enc=EEoxK2QJm1INS4iQZgCP4A%3D%3D.q8YTiv2RHEL6POHVA3OI1mzIrJSamRvCvO%2B0t%2FctF5oi60bP796Oq3%2Fbnkw8MAF3OUPNxFyN1xJ61nXBwHGWEA%3D%3D" rel="nofollow" target="_blank">php-cs-fixer-custom-fixers</a> - 用 php-cs-fixer 统一修复项目中的非 php 格式文件</li><li><a href="https://link.segmentfault.com/?enc=gVRgZcNn2HzUrQ%2BXYl7ESA%3D%3D.%2Fk69omMy7rlow%2B%2BFoqO41wgFCKVR6uWOEi%2B0hphYUKKYBD6U8nvqwTRl3KPmf8Z6LFa5At81eD6GLhXwZFVOMA%3D%3D" rel="nofollow" target="_blank">monorepo-builder-worker</a> - 用 monorepo-builder 自动化生成 <a href="https://link.segmentfault.com/?enc=zyI%2BBTTcEiNgylr8L4BlYg%3D%3D.JKiUz0r5tbRrvf1kDkad%2BHteiFo%2BWhaH%2FLE6jaRUIiqJxQCJ9PkdxERosnAyrnbJRAb7%2FygL%2FpCt5WnhF5XpiytRK7RywZnIajwwsoC9Gjs%3D" rel="nofollow" target="_blank">changelog</a> / 自动化项目<a href="https://link.segmentfault.com/?enc=81etJES2n%2FEhWLJqjN%2BeXw%3D%3D.uceA5fjTVwScTFZMuOrxHE2Q8tyJ4WSj0He6RjNlQMlQOu8RUPiTKkLYcdfAjWZcSyoHq9p9wy%2FX7Y%2FvZNnflw%3D%3D" rel="nofollow" target="_blank">发布流程</a></li><li><a href="https://link.segmentfault.com/?enc=I74CzXLMCtHLX2a1CSvv3w%3D%3D.n%2F3jM4fd9iGUsNO6H1g%2FEJos5w7UvZzAwaFenpiz4JdywDWcnxsT3Zo1kRVmbRti" rel="nofollow" target="_blank">phpstan-rules</a> - 一些附加的 phpstan 规则</li></ul>]]></description></item><item>    <title><![CDATA[rector-rules - 提供标准化的常量、变量、函数、类、属性和方法命名以及其他 Rector]]></title>    <link>https://segmentfault.com/a/1190000047553406</link>    <guid>https://segmentfault.com/a/1190000047553406</guid>    <pubDate>2026-01-20 16:13:38</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>rector-rules - 提供标准化的常量、变量、函数、类、属性和方法命名以及其他 Rector 规则</h2><blockquote><p>之前写过用 Rector <a href="https://link.segmentfault.com/?enc=HVIpeF135dI46ftGMy7DnA%3D%3D.74Mdy%2F%2F%2BHAEUZeXes%2FuoJJW4gdGjtAkv82D28n%2FE1Tq3PLsvjog5Mk73qFM6OlZr" rel="nofollow" target="_blank">《统一规范化代码的命名风格》</a>，现在已经整理发布为 Composer 包了。</p><p><a href="https://link.segmentfault.com/?enc=Vkf7zMflBYHTM5ac3KqQSg%3D%3D.dyHWhc1JAJxY3MhyGhzSpbeokywCyAhyeR1yeKq31HzvInsWOGakMAojZBlTiwjH" rel="nofollow" target="_blank">rector-rules</a> - 提供标准化的常量、变量、函数、类、属性和方法命名以及其他 Rector 规则。</p></blockquote><h3><a href="https://link.segmentfault.com/?enc=c3TLnOA7oR405gWcp3%2FAWA%3D%3D.iDDpqHQF2EboJgyLg2lzaOjARy9DMDujZoFBazQqMovaV8T4DnZX9eT2j7c9xU%2FUe0cD7%2FsgD6c6Rv5FzVUGKwFRL1nnZOwejzzzu04zKig%3D" rel="nofollow" target="_blank">Rector 规则总览</a></h3><h3><a href="https://link.segmentfault.com/?enc=qKMRrMES3jwH6ebs4vporg%3D%3D.GTtp9dDl%2F5y9j2DbZ%2FDttkPSv9fX1Qbb5C3qpLsG3myH5erReApbEfCBna%2FuSeTLv2aX6Cp5AXvuLlSsEaHuFw%3D%3D" rel="nofollow" target="_blank">Rector 规则集总览</a></h3><ul><li><code>Guanguans\RectorRules\Set\SetList::ALL</code></li><li><code>Guanguans\RectorRules\Set\SetList::COMMON</code></li><li><code>Guanguans\RectorRules\Set\SetList::PHPBENCH</code></li><li><code>Guanguans\RectorRules\Set\SetList::PHPSTAN</code></li><li><code>Guanguans\RectorRules\Set\SetList::RECTOR</code></li></ul><h3>配置使用规则集和规则</h3><pre><code class="php">use Guanguans\RectorRules\Rector\File\SortFileFunctionStmtRector;
use Guanguans\RectorRules\Rector\Name\RenameToPsrNameRector;
use PhpParser\NodeVisitor\ParentConnectingVisitor;
use Rector\Config\RectorConfig;

return RectorConfig::configure()
    -&gt;withSets([
        Guanguans\RectorRules\Set\SetList::ALL,
        // ...
    ])
    // ...
    -&gt;registerDecoratingNodeVisitor(ParentConnectingVisitor::class)
    -&gt;withConfiguredRule(RenameToPsrNameRector::class, [
        'assertMatches*Snapshot', // 排除 spatie/pest-plugin-snapshots 包的函数名称
        'beforeEach', // 排除 pestphp/pest 包的函数名称
        'PDO', // 排除 PDO 类名称
    ])
    // ...
    -&gt;withRules([
        SortFileFunctionStmtRector::class,
        // ...
    ]);</code></pre><h3>另外推荐下其他相关类似的包</h3><ul><li><a href="https://link.segmentfault.com/?enc=695hzbWgFent%2F7sY7%2BGYHQ%3D%3D.CknF%2BetCE2x1q4U86dBfRFvKo5HH6bozduhauCaubNvwjmfkZggQwjgO3agObGfaRmCEH6uaFruKeKkvQJCGUw%3D%3D" rel="nofollow" target="_blank">php-cs-fixer-custom-fixers</a> - 用 php-cs-fixer 统一修复项目中的非 php 格式文件</li><li><a href="https://link.segmentfault.com/?enc=LV6sMsTGYYd%2B6p1oRsD3zA%3D%3D.1DV2JORcEVvUqdbiotv2boepz9%2BGpKdp8ALQD9tB98%2Fw8ZN6nUQonjbnMjAsVIcEYl7XT%2BtIeIV45zS%2FGY4hxw%3D%3D" rel="nofollow" target="_blank">monorepo-builder-worker</a> - 用 monorepo-builder 自动化生成 <a href="https://link.segmentfault.com/?enc=ZQkJdAoqAwA1i40qy%2F0hcw%3D%3D.FFqHMJ8qJs%2BD8EGwV4aS097JdDXprNgLrxyFVza%2Fq%2FQHd9jE2LL9Vzxe22NUTKt1mRG7Tiu7b%2BCquMhco20QWKGA%2FkPSJzNUB7IKb9KJbXc%3D" rel="nofollow" target="_blank">changelog</a> / 自动化项目<a href="https://link.segmentfault.com/?enc=I30IOc4Z3dt4YvTWC3K8zA%3D%3D.gxnfV2%2F%2Brvck%2FDD6M0onmhEMlPEMSgdM7ngb8ZDQfdeZizED1SeU0DxyGUd9ULuT5rtV62TDiaut056X3Xe2Xg%3D%3D" rel="nofollow" target="_blank">发布流程</a></li><li><a href="https://link.segmentfault.com/?enc=BrzFTPbSl%2FqYEhjdEwVXMQ%3D%3D.OzvMuH3vOV%2Fe3AUo1uoM7E8%2BRRo8q2pm1TKp4UEPJHOEfM889wx6rpUYhLiO%2BS5M" rel="nofollow" target="_blank">phpstan-rules</a> - 一些附加的 phpstan 规则</li></ul>]]></description></item><item>    <title><![CDATA[rector-rules - 提供标准化的常量、变量、函数、类、属性和方法命名以及其他 Rector]]></title>    <link>https://segmentfault.com/a/1190000047553411</link>    <guid>https://segmentfault.com/a/1190000047553411</guid>    <pubDate>2026-01-20 16:12:44</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>rector-rules - 提供标准化的常量、变量、函数、类、属性和方法命名以及其他 Rector 规则</h2><blockquote><p>之前写过用 Rector <a href="https://link.segmentfault.com/?enc=0CS5TIhMA9WlCxPlugS90A%3D%3D.gxybq7s%2BGTB05ptS2%2BqBZE6Uzkf2dy8xmu7e9nHb3NrzmpPi4Gtv8XDmOuWvnBAJ" rel="nofollow" target="_blank">《统一规范化代码的命名风格》</a>，现在已经整理发布为 Composer 包了。</p><p><a href="https://link.segmentfault.com/?enc=sLBt%2FJMgAsnpj8lXIR95cw%3D%3D.%2Fud%2BiDttHhGYqbWwHyqOXfkfsn2ZTg11eiq6mhtMosWR011pG7SE30Gv%2BhQndDmn" rel="nofollow" target="_blank">rector-rules</a> - 提供标准化的常量、变量、函数、类、属性和方法命名以及其他 Rector 规则。</p></blockquote><h3><a href="https://link.segmentfault.com/?enc=sHJ14Wsads3ZWa%2BYTFz9pw%3D%3D.LhldVxNEPTjFaVyH%2BuaoHAxkG%2Fzc%2Bk95j94U25UPyWKN4Uy%2FaJQfNXVJeevS9LwrM6GLxU3yNvtKua6IlI9iXHLinNQP9oCpRNmwkus3Zsk%3D" rel="nofollow" target="_blank">Rector 规则总览</a></h3><h3><a href="https://link.segmentfault.com/?enc=JCWve7ggftko%2FnxcOxdbGA%3D%3D.nCiw05GWiYt6wkiSjNtyU6AyBJnF3w67RK75lWi%2BpMmqe1B0s7Vi7BKvixX5CZyZpIPZ5znBKVi7Zh12lgTziQ%3D%3D" rel="nofollow" target="_blank">Rector 规则集总览</a></h3><ul><li><code>Guanguans\RectorRules\Set\SetList::ALL</code></li><li><code>Guanguans\RectorRules\Set\SetList::COMMON</code></li><li><code>Guanguans\RectorRules\Set\SetList::PHPBENCH</code></li><li><code>Guanguans\RectorRules\Set\SetList::PHPSTAN</code></li><li><code>Guanguans\RectorRules\Set\SetList::RECTOR</code></li></ul><h3>配置使用规则集和规则</h3><pre><code class="php">use Guanguans\RectorRules\Rector\File\SortFileFunctionStmtRector;
use Guanguans\RectorRules\Rector\Name\RenameToPsrNameRector;
use PhpParser\NodeVisitor\ParentConnectingVisitor;
use Rector\Config\RectorConfig;

return RectorConfig::configure()
    -&gt;withSets([
        Guanguans\RectorRules\Set\SetList::ALL,
        // ...
    ])
    // ...
    -&gt;registerDecoratingNodeVisitor(ParentConnectingVisitor::class)
    -&gt;withConfiguredRule(RenameToPsrNameRector::class, [
        'assertMatches*Snapshot', // 排除 spatie/pest-plugin-snapshots 包的函数名称
        'beforeEach', // 排除 pestphp/pest 包的函数名称
        'PDO', // 排除 PDO 类名称
    ])
    // ...
    -&gt;withRules([
        SortFileFunctionStmtRector::class,
        // ...
    ]);</code></pre><h3>另外推荐下其他相关类似的包</h3><ul><li><a href="https://link.segmentfault.com/?enc=Rj%2F0LrtiHTElmfduhsFI%2FQ%3D%3D.zQIa7AzKJTCIgOmrbW3ylqhLeZLP92MdbcVCMN%2BX6T6kAxB62OtK%2FBozpwQJzp93bpQbyn%2Bc3KCPrxR8rPjZ3Q%3D%3D" rel="nofollow" target="_blank">php-cs-fixer-custom-fixers</a> - 用 php-cs-fixer 统一修复项目中的非 php 格式文件</li><li><a href="https://link.segmentfault.com/?enc=%2FErYJ3hvxR5czns82WnXyA%3D%3D.s4ZdGOgPO7%2BR1JRXjskzIzBrEyHVZJ8SJu7ad3N0TypG0TyTQmOd8JlwE8I54nAeG0n7AzRTWYzkrlhVcKFU%2Bg%3D%3D" rel="nofollow" target="_blank">monorepo-builder-worker</a> - 用 monorepo-builder 自动化生成 <a href="https://link.segmentfault.com/?enc=ObvKLN8Fw3s3%2B0VKFBoJrA%3D%3D.cOqVr6RHcYxsI0waPK4EIKxAWEsIVVsGzQmbDYL6%2FO0HfqglZgxJ8SNa%2FTK83jlNEeu7EKJ3z9ZwcPsqNj08kbgN3MeE0vOe3KTehNjrrco%3D" rel="nofollow" target="_blank">changelog</a> / 自动化项目<a href="https://link.segmentfault.com/?enc=xd8Lnh6AnibTrPleohRvvQ%3D%3D.w4bUhSX20f3K%2Fv8JunF2BJoQT4fsXG9l61VFBQjlv8Xnud4K0lUNk59Xg1B%2FchWCw858YXiUQCqyGInlImM%2BTg%3D%3D" rel="nofollow" target="_blank">发布流程</a></li><li><a href="https://link.segmentfault.com/?enc=lcr3cemoTSk4U12tJCXWvw%3D%3D.xNP5Fx7rnPV0fABDOfliONixgCGNnyGWeJ7xeX59Go2RYrmzHZvuxW3061BmvRO%2F" rel="nofollow" target="_blank">phpstan-rules</a> - 一些附加的 phpstan 规则</li></ul>]]></description></item><item>    <title><![CDATA[清华联合字节刷新 3D 头像技术！FlexAvatar 实现 “少图输入 + 高保真动态” 双重突破]]></title>    <link>https://segmentfault.com/a/1190000047553428</link>    <guid>https://segmentfault.com/a/1190000047553428</guid>    <pubDate>2026-01-20 16:11:44</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>清华联合字节刷新 3D 头像技术！FlexAvatar 实现 “少图输入 + 高保真动态” 双重突破</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553431" alt=" " title=" "/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553432" alt=" " title=" " loading="lazy"/></p><p>论文标题：<em>FlexAvatar: Flexible Large Reconstruction Model for Animatable Gaussian Head Avatars with Detailed Deformation</em></p><p>作者团队：<a href="https://link.segmentfault.com/?enc=3UcoGill3glPuz5CgNUTEA%3D%3D.eizzzV%2Bn8KrhWpcjrq8Z6%2FUK7jWTcsNHvzcM2IOwUJA5Ww7mjMANmSkCkaS2j0EFoj7N4yUEPljgLvHsBboOKQppg4LS7Npzt5Ux9tyisq1BhZoEsGkI8bY2uIfCwYy4" rel="nofollow" target="_blank">清华大学</a>、<a href="https://link.segmentfault.com/?enc=awdbVRDZOxGAZrpEc7DRnw%3D%3D.1lOdMFGqe3bbUiNb9od0Huo2rQN%2B3b8gJC58N7Xj%2F7p6ovDvPeC1oU%2Fv88ckfDe3ljNJhMWtmoB9uyBWghx%2FwENxBNLvoIxlM6HpPP6PBy8ZqvbjuLALtsOMOyfuVO0j" rel="nofollow" target="_blank">字节跳动</a></p><p>发布时间：2025年12月19日</p><p><a href="https://link.segmentfault.com/?enc=6dGFpqSxDZPUfiEg8xXH6Q%3D%3D.zgEWHZ2JYrZT2QQuqskzfte7If6G53U08UMzpJo8srO89lz%2F6JluNjRCLyw7t%2Fm%2B" rel="nofollow" target="_blank">论文链接</a></p><p><a href="https://link.segmentfault.com/?enc=D9mieuHsp3Y6Hn5ftQ%2FCBw%3D%3D.5YzlsO9Cnb5G6%2Br9fIzZqIE%2BxeXPve1pkS2RMO3dgEhhgUW7rzqCtLF6zlSAtBy033efiKauIM0q52DaflDp2il%2FhIIlLXGG7ljcN%2Bg2FngPBSWGmE%2FfpbTh%2FVVdl1Xt" rel="nofollow" target="_blank">大模型实验室链接</a>Lab4AI论文阅读</p><h3>🔍背景</h3><p>以前做 3D 头像，要么得用专业设备拍几十上百张不同角度的照片，普通人搞不定；要么做出来的头像假，侧面看变形，做表情时没细节；要么动起来卡顿，或者只能做几种固定表情，没法自然还原复杂动作；要么得花几小时甚至几天调教模型，没法快速得到自己的头像。</p><h3>🔍研究目的</h3><p>本研究旨在构建一个无需相机位姿与表情标注、支持单张或稀疏输入的高保真可驱动3D头部虚拟人生成框架。</p><p>无需相机姿态和表情标签，仅从单张或稀疏图像中生成高保真、几何一致的可动画 3D 头部头像，同时兼顾实时渲染效率与动态细节真实性，填补现有技术在灵活性、保真度与实时性之间的平衡缺口。</p><h3>🔍本文核心贡献</h3><p>1️⃣灵活的重建模型：提出首个免相机位姿、免表情标签、支持任意数量输入的3D高斯虚拟人框架，基于结构化头部查询令牌（Head Query Tokens）实现特征聚合；</p><p>2️⃣动态高斯变形解码：设计以UV位置图为条件的UNet解码器，在UV空间生成表情相关的高斯属性变化，实现实时高保真驱动；</p><p>3️⃣数据分布调整策略：通过锚点表情筛选与相似帧检索，平衡训练集表情分布，提升动态细节学习效率；</p><p>4️⃣高效微调机制：10秒级的测试时优化可增强身份细节，且不影响实时驱动性能。</p>]]></description></item><item>    <title><![CDATA[西北工业大学StereoMV2D突破3D物体检测深度难题，精度与效率兼得 Lab4AI ]]></title>    <link>https://segmentfault.com/a/1190000047553524</link>    <guid>https://segmentfault.com/a/1190000047553524</guid>    <pubDate>2026-01-20 16:11:11</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>西北工业大学StereoMV2D突破3D物体检测深度难题，精度与效率兼得</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553527" alt=" " title=" "/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553528" alt=" " title=" " loading="lazy"/></p><p>论文标题：StereoMV2D: A Sparse Temporal Stereo-Enhanced Framework for Robust Multi-View 3D Object Detection</p><p>作者团队：<a href="https://link.segmentfault.com/?enc=w7pLZ5Gxf2hQ1ZVoeF3P5Q%3D%3D.plBaYOgRyqkeBRHeNNVmGK2HAYycA9p%2BFHQz4y9G5CNpDqaq8br0qbRj20zYiGC6PiylMDyCnscixgcBFiA7owTFW0XC8KGFWOYogdcg9hGerr8wUVM%2Fh3O8o2%2FQutiy" rel="nofollow" target="_blank">西北工业大学</a>、<a href="https://link.segmentfault.com/?enc=VkssR6brBPepJg6G7JdArQ%3D%3D.GGXk7eBXUeSiriBibPb%2F2rwbNFlEXcKtRpQskI2lyLXhIj81er8JZYDddGxYJ%2FP286tAKuksgislOy29b1pWSKUrMy0Yczf2nNscdku%2FBl0hQrRZlCdGFxrpfa8CTR%2Bg" rel="nofollow" target="_blank">苏州科技大学</a></p><p>发布时间：2025年12月19日</p><p><a href="https://link.segmentfault.com/?enc=ebroNj9ohwBMCcL17wDkxg%3D%3D.N1gWYSMy%2BwPzCStMH7D9srwjO48bJyJ0nfq1kIJAXbkkBaLbks4aQbQbcEWUm7E4" rel="nofollow" target="_blank">论文链接：</a></p><p><a href="https://link.segmentfault.com/?enc=VaLS0gP9RVI7m00MAltB%2Bg%3D%3D.sPlW8i1kkwg7b2oWIIJAu3PAPspMCailBj3abLUJgOj5MlkszfGo69mpgr2%2FRPALsdsT8wT0PaFnnUzRDJEXYF4YJMG%2BtRMTHlyD8k6iFgvK%2BWaYZnnz0o0gsBWjfwOm" rel="nofollow" target="_blank">大模型实验室</a>Lab4AI论文阅读</p><h3>✔️研究背景</h3><p>多视图3D物体检测需在检测精度和计算效率间取得平衡。<a href="https://link.segmentfault.com/?enc=N8bggZOh0A0Bngh7JlBNTg%3D%3D.k15YY4jHHOBRdC70RRSePs%2FPm%2FgsF5NPUVV71DOlPxFmXYbqZetTZ%2BqOaeI3W7%2BfPy3a6cokwLoG8As6y4ERLM%2B%2B%2BYk1tUfD7uDQ%2FiWZltIJbYENphda6iGJT3S4dDOZ" rel="nofollow" target="_blank">稀疏查询</a>基方法（如MV2D）通过2D检测结果初始化3D查询，提供了高效的端到端检测范式，但单帧2D检测存在深度模糊问题，导致3D查询初始化不准确。</p><p>现有融合时序立体建模的方法多依赖密集代价体构建，引入大量计算与内存开销，难以兼容<a href="https://link.segmentfault.com/?enc=LaEl4jiKjV8N5LwTp8tH%2Fg%3D%3D.zkVCmzvcTSknD3u0kc2haNdMfA2Y%2Bn8Et%2BxJCTa5MICKDR5AqqVF%2Bu45fyHZqLXl7WjRhRyK1xBuuBEK1nuin%2FkM8Y3jNwWxXCFLYa9Q6G%2Brf9ZOy%2F8TPacY35Z%2FViJo" rel="nofollow" target="_blank">稀疏查询</a>类方法的高效特性，形成研究缺口。</p><h3>✔️研究内容</h3><p>针对单帧 2D 检测的深度模糊缺陷，以及现有时序立体建模方法计算开销大的问题，本研究旨在提出一种统一框架，将时序立体建模融入<a href="https://link.segmentfault.com/?enc=NONtrEhNkMdRJjpmL4QZFQ%3D%3D.BhwdyJgIgMRYQRiTwEFLGUM7BeBfzSTDXEh8CA9ztPbVVg9ze4cmcDKFICsPn5OpJPWXSh4UTiAvA67bDFG%2BSHaJY2n3RJ%2BJ1OzGDGeaFj6DZlMaQpoHxC%2F0KHtoUZoR" rel="nofollow" target="_blank">稀疏查询</a>检测范式，在保持<a href="https://link.segmentfault.com/?enc=rfjo60zVS%2B7Jpxu6FgTofg%3D%3D.ZItHltHQga0BecyfIbaYmIX8WSyksEvrLL4JAfNvVFaLe0I0LUhoRcYToy9j1%2B5rxK3KNU94gHLOeDIicQEUgX0YVi7XkR63AVZgtrqN%2BUprrntZ66eUgfhtRjAMgmn5" rel="nofollow" target="_blank">稀疏查询</a>类方法高效性的同时，增强深度感知能力，提升多视图 3D 目标检测的精度与鲁棒性，实现精度与效率的良好平衡。</p><h3>✔️核心思想</h3><h4>1️⃣匹配同一物体</h4><p>汽车运动、场景变化时，系统需在前一帧与当前帧图像中匹配同一物体。<br/>论文采用 “运动感知软匹配” 模块，结合物体外观与运动趋势，建立跨帧关联。</p><h4>2️⃣物体区域内算深度</h4><p>匹配到同一物体的跨帧图像后，StereoMV2D 仅在物体对应的感兴趣区域（RoI）内开展精细立体计算，减少计算量；通过对比物体在两帧图像中的细微位移，精准计算其真实距离。</p><h4>3️⃣智能筛选有效信息</h4><p>针对现实场景中物体新出现或被遮挡的动态情况，论文设计动态置信门控机制，自动判定采用立体测量结果，还是回退至单帧图像的推测结果。</p>]]></description></item><item>    <title><![CDATA[UI常备的 7 款 网站设计工具 UXbot ]]></title>    <link>https://segmentfault.com/a/1190000047553538</link>    <guid>https://segmentfault.com/a/1190000047553538</guid>    <pubDate>2026-01-20 16:10:36</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>现在互联网行业竞争这么激烈，网页界面设计得好不好，不光影响用户用着顺不顺手，还直接关系到产品能不能留住人。大厂设计师能做出让人眼前一亮的界面，除了自身本事硬，背后肯定少不了好用的设计工具帮忙。下面就给大家盘点 7 款 UI 设计师平时常用的网页设计软件，不管是新手还是老手，都能找到适合自己的。<br/>一、UXbot：原型、交互、开发一条龙搞定<br/>核心功能：</p><ul><li>多页面自动生成：你只要把想法用文字说清楚，它就能自动画出完整的用户使用流程，还会告诉你背后的设计思路。可以自己选要生成哪些页面，一次性做出整套界面，不用再一点点拼凑，大大节省时间。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdnG0c" alt="image.png" title="image.png"/></li><li>自由编辑超灵活：既能用说话、打字的方式快速操作，也有专业的精细编辑器，能精准调整到每一个像素。不管是改页面布局、换设计风格，还是换图片文字，都能精准满足需求，创意和专业性都不耽误。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdnG0f" alt="image.png" title="image.png" loading="lazy"/></li><li>交互原型一键分享：马上就能生成能实际操作的演示原型，点一点、滑一滑都跟真的产品一样，还能直接分享给别人。不管是给客户演示、团队内部讨论，还是项目推介，都能让大家直观看到效果，更有说服力。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdnG0g" alt="image.png" title="image.png" loading="lazy"/></li><li>自动生成前端代码：界面设计一确定，它就会自动生成能直接用的前端代码，还能适配 vue.js 这种常用框架。设计效果和代码能无缝衔接，甚至能一键传到云服务器上，再也不用纠结设计和开发脱节的问题了。<br/><img width="723" height="395" referrerpolicy="no-referrer" src="/img/bVdnG0h" alt="image.png" title="image.png" loading="lazy"/></li><li>多平台协作方便：能一键导出 HTML 或 Sketch 格式，还能设置不同人的查看、编辑权限，团队随时随地都能协作，设计和开发衔接更顺畅。</li></ul><p>适用场景：<br/>中小型企业、工作室做项目演示，能快速把商业想法变成可展示的原型；企业做数字化项目，跨部门一起做内部工具或客户产品；设计和开发团队合作，减少沟通误会，提高原型评审和代码转化效率；产品更新优化时，快速验证新功能的逻辑和用户体验。</p><p>二、Adobe Illustrator：矢量设计的王牌<br/>核心功能：</p><ul><li>专门做矢量图形，用来设计网页里的图标、装饰图案、品牌插画再合适不过了，不管放大多少倍，画面都清晰锐利，不会出现模糊、边缘变形的情况。</li><li>有钢笔工具、形状生成器这些强大的图形编辑功能，不管是复杂的几何形状，还是自定义的创意图形，都能轻松画出来，满足各种视觉设计需求。</li><li>文字排版能精准调控，字体、字号、行间距、字间距都能细细调整，能做出整齐又好看的界面文字布局，让整个页面的视觉质感更棒。<br/>适用场景：<br/>主要用来设计网页里的矢量元素，比如企业官网的品牌 LOGO、导航栏的功能图标、页面里的装饰插画，还有需要精细排版的标题、说明文字等。<br/><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdnG0j" alt="image.png" title="image.png" loading="lazy"/></li></ul><p>三、Sketch：UI/UX 设计的高效小帮手<br/>核心功能：</p><ul><li>就是为 UI/UX 设计量身做的，界面简单明了，新手也能快速上手，不用花好多时间学操作。</li><li>有智能自适应布局功能，设计能适配不同屏幕的网页时，调整一个元素的大小，和它相关的其他元素会按照预设的规则自动调整，不用手动一个个改位置、调大小，省了好多事。</li><li>支持装各种插件，比如切图、填充数据、生成标注的插件，能大大提高设计效率，和开发团队合作也更顺畅。</li><li>有符号复用功能，把按钮、输入框这些常用元素设为 “符号”，后面只要改一下原始的 “符号”，所有用了这个 “符号” 的地方都会自动更新，能保证整个设计的一致性。<br/>适用场景：<br/>特别适合互联网创业公司快速做产品原型，比如开发新的网页应用时，设计师能用它高效完成界面设计和原型制作，快速验证产品思路，缩短项目周期。<br/><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdnG0k" alt="image.png" title="image.png" loading="lazy"/></li></ul><p>四、Adobe Photoshop：界面视觉精修神器<br/>核心功能：</p><ul><li>经典的图像处理软件，功能特别全，调颜色、抠图、合成图片、修细节都能搞定，能给网页界面打造出精致的视觉效果。</li><li>用图层来管理内容，导航栏、正文、背景图这些元素可以分别放在不同的图层上，能灵活控制每个图层的显示、隐藏和透明度，改一个元素的时候不会影响到其他内容。</li><li>有各种滤镜和特效工具，能快速做出模糊、阴影、发光这些效果，让界面更有层次感和立体感，看起来更吸引人。<br/>适用场景：<br/>适合对视觉效果要求高、需要大量处理图片的网页项目。比如电商平台的首页设计，商品图片精修、促销海报制作、页面氛围渲染这些工作，用它都能高效完成。<br/><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdnG0l" alt="image.png" title="image.png" loading="lazy"/></li></ul><p>五、Axure RP：专业的交互原型工具<br/>核心功能：</p><ul><li>是专门做原型设计的工具，不光能做出高还原度的界面，还能做可交互的产品原型。可以给元素加点击跳转、滑动切换这些交互效果，甚至能设置条件逻辑，完整模拟用户实际使用的流程。</li><li>有丰富的元件库，还能自己做自定义元件，轻松做出表单、弹窗、导航菜单这些常见的界面组件，还能给元件改样式，贴合项目的整体设计风格。</li><li>支持多人一起编辑，团队成员能共同管理原型项目，生成的 HTML 格式原型文件，开发、测试的同事不用装专门的软件，直接就能查看和体验。<br/>适用场景：<br/>在网页产品的前期规划和交互设计阶段特别有用。比如开发新的网页应用，或者给现有网站改版时，设计师和产品经理能用它快速搭建原型，做用户测试和方案验证，确保产品的交互逻辑符合用户需求。<br/><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdnG0z" alt="image.png" title="image.png" loading="lazy"/></li></ul><p>六、Adobe XD：设计到原型无缝衔接<br/>核心功能：</p><ul><li>把设计、原型制作、动效设计三个功能整合到一起，设计师不用在好几个软件之间来回切换，在一个界面里就能完成从静态设计图到动态原型的全部工作。</li><li>支持响应式设计布局，设置好断点和约束条件，就能快速适配电脑、平板、手机等不同屏幕尺寸，让设计更灵活、适用范围更广。</li><li>有重复网格功能，设计新闻列表、产品列表这种界面时，只要做好一个列表项，一键就能生成多个相同样式的元素，不用重复设计，省了好多时间。<br/>适用场景：<br/>适合 UI/UX 设计师做网页界面设计和原型制作，尤其是需要给客户展示设计效果、给团队评审交互流程的时候。比如做方案汇报，用它生成的可交互原型，能让大家更直观地感受到产品的功能和操作体验。<br/><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdnG0E" alt="image.png" title="image.png" loading="lazy"/></li></ul><p>七、InVision：原型测试和团队反馈的高效平台<br/>核心功能：</p><ul><li>专注于原型设计和团队协作，能导入 Sketch、Adobe XD 等多种格式的设计文件，方便整合不同来源的设计资源。</li><li>有丰富的交互动画模板，设计师能轻松给原型加页面切换、元素弹出、下拉刷新这些动画效果，让原型更真实、更有吸引力。</li><li>评论批注功能很方便，团队成员和客户能直接在原型上标注意见和建议，设计师能快速找到需要修改的地方，不用反复沟通确认，能加快项目推进速度。<br/>适用场景：<br/>在网页项目的后期测试和反馈阶段优势特别明显。比如完成界面设计和原型制作后，用这款工具能快速和开发团队、测试团队、客户对接，收集大家的意见，及时优化设计方案，确保最终的产品符合预期。<br/><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdnG0G" alt="image.png" title="image.png" loading="lazy"/></li></ul><p>总结<br/>总的来说，这 7 款网页设计软件各有各的优势，UI 设计师可以根据项目的具体需求、团队的协作方式来灵活选择。对于做网页设计的从业者和爱好者来说，摸清这些工具的特点和适用场景，熟练用它们辅助设计，既能提高工作效率，也能让自己的作品更有竞争力，做出更优质的网页界面。</p>]]></description></item><item>    <title><![CDATA[如何使用Python Mammoth将DOCX转换为HTML？ 码云笔记 ]]></title>    <link>https://segmentfault.com/a/1190000047553590</link>    <guid>https://segmentfault.com/a/1190000047553590</guid>    <pubDate>2026-01-20 16:09:54</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>我们在实际的项目开发的过程中，有时候不得不将文件从一种格式转换为另一种格式。</p><p>DOCX（由 Microsoft Word 使用）是一种非常常见的文件格式，被很多人使用。有时候，我们希望将 Word 文档转换为 HTML。</p><p>这可以通过 Mammoth 包轻松实现。它是一个用于将 DOCX 文件转换为 HTML 的简单、高效、快速的库。在本文中，我们将学习如何在 Python 中使用 Mammoth 将 DOCX 转换为 HTML。</p><h2>安装 Mammoth</h2><p>首先，在安装之前准备好并激活你的虚拟环境：</p><pre><code>python3 -m venv myenv
. myenv/bin/activate</code></pre><p>然后，使用pip安装 Mammoth：<br/><code>pip3 install mammoth</code><br/>本教程使用的 Mammoth 版本是 1.4.15。在测试的时候，请确保它是.docx 文件！</p><p>以上环境准备好后，现在让我们开始提取文本并将其转换成 HTML。</p><h2>提取 DOCX 文件的原始文本</h2><p>在转换为 HTML 时保留格式是 Mammoth 的最佳功能之一。这里我们只需要几行代码转换成你需要 DOCX 文件的文本。</p><p>使用 extract_raw_text()方法来获取它：</p><pre><code>import mammoth

with open(input_filename, "rb") as docx_file:
    result = mammoth.extract_raw_text(docx_file)
    text = result.value # The raw text
    with open('output.txt', 'w') as text_file:
        text_file.write(text)</code></pre><p>注意，此方法不会返回有效的 HTML 文档。它只返回页面上的文本，因此我们使用.txt 扩展来保存它。如果你确实需要保持布局或格式，你需要提取 HTML 内容。</p><h2>将 Docx 转换为 HTML 并自定义样式映射</h2><p>默认情况下，Mammoth 将文档转换为 HTML，但它不会提供有效的 HTML 页面。虽然网页浏览器可以显示内容，但它缺少一个&lt;html&gt;标签来封装文档，以及一个&lt;body&gt;标签来包含文档。</p><p>假设使用的是带有模板的网络框架。可能会定义一个模板来显示 Word 文档，并将 Mammoth 的输出加载到模板主体内。</p><p>Mammoth 不仅在如何使用其输出方面具有灵活性，而且在如何创建输出方面也具有很大的灵活性。特别是在我们想要样式化我们生成的 HTML 时，我们有很多选项。我们通过将每个 DOCX 格式规则匹配到相应的 CSS 规则来映射样式。</p><p>要查看你的 DOCX 文件有哪些样式，你有两个选择：</p><ol><li>使用 MS Word 打开您的 docx 文件，并检查样式工具栏。</li><li>通过用解压管理器打开你的 DOCX 文件来研究 XML 文件，然后导航到/word/styles.xml并找到你的样式。</li></ol><p>第二个选项适用于无法使用 MS Word 或无法解释和显示样式的替代文字处理程序的用户。</p><p>Mammoth 已经默认涵盖了某些最常用的样式映射。例如，Heading1在 docx 样式中映射到 HTML 元素的&lt;h1&gt;，bold被映射到 HTML 元素的 strong，等等。</p><p>我们还可以在映射时使用 Mammoth 来自定义文档的样式。例如，如果您想将 DOCX 文件中的所有bold出现次数更改为 HTML 中的斜体，可以这样子实现：</p><pre><code>import mammoth

custom_styles = "b =&gt; i"

with open(input_filename, "rb") as docx_file:
    result = mammoth.convert_to_html(docx_file, style_map = custom_styles)
    text = result.value
    with open('output.html', 'w') as html_file:
        html_file.write(text)</code></pre><p>通过 custom_styles 变量，左边的样式来自 DOCX 文件，而右边的是相应的 CSS。<br/><code>custom_styles = "b =&gt; "</code><br/>有时我们转换的文档会有很多样式需要保留。这个时候再这样实现就会变得不切实际，要为每一个我们要映射的样式都创建一个变量。</p><p>不过有解法，我们可以使用docstrings一次映射我们想要的任意多个样式：</p><pre><code>custom_styles = """ b =&gt; del
                    u =&gt; em
                    p[style-name='Heading 1'] =&gt; i"""</code></pre><p>你可能已经注意到，最后的映射与其他的有点不同。在映射样式时，我们可以使用方括号[]并在其中添加条件，这样只有部分元素会以这种方式进行样式设置。</p><p>在我们的示例中，p[style-name='Heading 1']选择具有样式名称的段落Heading 1。我们也可以使用p[style-name^='Heading']来选择具有以Heading开头的样式名称的每个段落。</p><p>样式映射还允许我们将样式映射到自定义 CSS 类。通过这样做，我们可以随心所欲地修改 HTML 的样式。让我们举一个例子，我们在文档字符串中定义基本的自定义 CSS：</p><pre><code>custom_css ="""
    &lt;style&gt;
    .red{
        color: red;
    }
    .underline{
        text-decoration: underline;
    }
    .ul.li{
        list-style-type: circle;
    }
    table, th, td {
    border: 1px solid black;
    }
    &lt;/style&gt;
    """</code></pre><p>现在我们可以更新我们的映射，以引用我们在&lt;style&gt;块中定义的 CSS 类：</p><pre><code>custom_styles = """ b =&gt; b.red
                    u =&gt; em.red
                    p[style-name='Heading 1'] =&gt; h1.red.underline"""</code></pre><p>并将 CSS 和 HTML 合并在一起：<br/><code>edited_html = custom_css + html</code><br/>这个时候如果 DOCX 文件包含任何这些元素，就能看到我们设置的样式结果。</p><p>通过以上方法我们已经知道如何映射样式，那就让我们使用一个更著名的 CSS 框架（以及相关的 JS）来让我们的 HTML 看起来更好，并练习一个更有可能的现实场景。</p><p>使用 Bootstrap（或其他任何前端框架）映射样式<br/>就像我们之前处理custom_css一样，我们需要确保 CSS 与 HTML 一起加载。我们需要将 Bootstrap 文件 URI 或 CDN 添加到我们的 HTML 中：</p><pre><code>bootstrap_css = '&lt;link rel="nofollow" href="https://mybj123.com/links?url=aHR0cHM6Ly9jZG4uanNkZWxpdnIubmV0L25wbS9ib290c3RyYXBANS4wLjAtYmV0YTIvZGlzdC9jc3MvYm9vdHN0cmFwLm1pbi5jc3M=" rel="stylesheet" integrity="sha384-BmbxuPwQa2lc/FVzBcNJ7UAyJxM6wuqIj61tLrc4wSX0szH/Ev+nYRRuWlolflfl" crossorigin="anonymous"&gt;'
bootstrap_js = '&lt;script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta2/dist/js/bootstrap.bundle.min.js" integrity="sha384-b5kHyXgcpbZJO/tY9Ul7kGkf1S0CWuKcCD38l8YkeH8z8QjE0GmW1gYU5S9FOnJ0" crossorigin="anonymous"&gt;&lt;/script&gt;'</code></pre><p>这里我稍微调整我们的 custom_styles，以匹配我们的新 CSS 类：</p><pre><code>custom_styles = """ b =&gt; b.mark
                    u =&gt; u.initialism
                    p[style-name='Heading 1'] =&gt; h1.card
                    table =&gt; table.table.table-hover
                    """</code></pre><p>在第一行，我们将粗体 DOCX 样式映射到具有类的 HTML 元素，该类是 HTML 标签的 Bootstrap 类，用于突出显示文本的一部分。bmark &lt;mark&gt;</p><p>在第二行，我们为 HTML 元素添加了类，稍微减小了字体大小，并将文本转换为大写。initialism u</p><p>在第三行，我们选择所有具有样式名称的段落，并将其转换为具有 Bootstrap 类的 HTML 元素，该类为元素设置多个样式属性，例如背景颜色、位置和边框。Heading 1 h1 card</p><p>在最后一行，我们将 docx 文件中的所有表格转换为 HTML 元素，并使用 Bootstrap 的类来给它一个新的外观，同时我们通过添加 Bootstrap 类使其在悬停时高亮显示。table table table-hover</p><p>和之前一样，我们使用点符号将多个类映射到同一个 HTML 元素，即使这些样式来自另一个来源。</p><p>最后，将 Bootstrap CDNs 添加到我们的 HTML 中：</p><pre><code>edited_html = bootstrap_css + html + bootstrap_js</code></pre><p>现在可以分享我们的 HTML，以下是完整的代码以供参考：</p><pre><code>import mammoth

input_filename = "file-sample_100kB.docx"

custom_styles = """ b =&gt; b.mark
                    u =&gt; u.initialism
                    p[style-name='Heading 1'] =&gt; h1.card
                    table =&gt; table.table.table-hover
                    """


bootstrap_css = '&lt;link rel="nofollow" href="https://mybj123.com/links?url=aHR0cHM6Ly9jZG4uanNkZWxpdnIubmV0L25wbS9ib290c3RyYXBANS4wLjAtYmV0YTIvZGlzdC9jc3MvYm9vdHN0cmFwLm1pbi5jc3M=" rel="stylesheet" integrity="sha384-BmbxuPwQa2lc/FVzBcNJ7UAyJxM6wuqIj61tLrc4wSX0szH/Ev+nYRRuWlolflfl" crossorigin="anonymous"&gt;'
bootstrap_js = '&lt;script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta2/dist/js/bootstrap.bundle.min.js" integrity="sha384-b5kHyXgcpbZJO/tY9Ul7kGkf1S0CWuKcCD38l8YkeH8z8QjE0GmW1gYU5S9FOnJ0" crossorigin="anonymous"&gt;&lt;/script&gt;'


with open(input_filename, "rb") as docx_file:
    result = mammoth.convert_to_html(docx_file, style_map = custom_styles)
    html = result.value 

edited_html = bootstrap_css + html + bootstrap_js

output_filename = "output.html"
with open(output_filename, "w") as f: 
    f.writelines(edited_html)</code></pre><p>此外，需要注意的一点是，在实际情况下，你可能不会像我们在这里所做的那样直接将 Bootstrap CSS 添加到 HTML 内容中。相反，你会将 HTML 内容加载或注入到一个特殊的 HTML 页面中，该页面已经包含了必要的 CSS 和 JS 捆绑包。</p><p>Mammoth 还允许我们修改我们正在转换的内容。</p><h2>处理我们不想分享的图片</h2><p>假设我们希望跳过 DOCX 文件中的图像不进行转换。convert_to_html()方法接受一个convert_image参数，这是一个图像处理函数。它返回一个应该转换并添加到 HTML 文档中的图像列表。</p><p>当然，如果我们覆盖它并返回一个空列表，它们将从转换后的页面中省略：<br/>`def ignore_image(image):</p><pre><code>return []`</code></pre><p>现在，让我们将该函数作为参数传递到convert_to_html()方法中：</p><pre><code>with open(input_filename, "rb") as docx_file:
    result = mammoth.convert_to_html(docx_file, style_map = custom_styles, convert_image=ignore_image)
    html = result.value
    with open('output.html', 'w') as html_file:
        html_file.write(text)</code></pre><p>就是这样！ Mammoth 在生成 HTML 文件时将忽略所有图像。</p><p>到目前为止，我们一直在用 Python 编程方式使用 Mammoth。Mammoth 也是一个命令行工具，因此我们有了另一个将 DOCX 转换为 HTML 的接口。让我们在下一节中看看它的工作情况。</p><h2>使用命令行工具将 DOCX 转换为 HTML</h2><p>使用 Mammoth 的 CLI 进行文件转换通常如下所示：</p><pre><code>mammoth path/to/input_filename.docx path/to/output.html</code></pre><p>如果你想将图像从 HTML 中分离出来，可以指定一个输出文件夹：</p><pre><code>mammoth file-sample_100kB.docx --output-dir=imgs</code></pre><p>我们也可以像在 Python 中那样添加自定义样式。首先需要创建一个自定义样式文件：<br/><code>touch my-custom-styles</code><br/>然后，我们将在其中添加自定义样式，语法与之前相同：</p><pre><code>b =&gt; b.red
u =&gt; em.red
p[style-name='Heading 1'] =&gt; h1.red.underline</code></pre><p>现在我们可以生成带有自定义样式的 HTML 文件：</p><pre><code>mammoth file-sample_100kB.docx output.html --style-map=my-custom-styles</code></pre><p>大功告成！您的文档已按定义的自定义样式进行转换。<a href="https://link.segmentfault.com/?enc=SifZbz41h91G5MJK2P49Pw%3D%3D.XK%2ByukhAJMQiJD2%2BJH6rryOWMstDqWT2hhbmo2oy3dA%3D" rel="nofollow" target="_blank">https://mybj123.com/28792.html</a></p><h2>结语</h2><p>文件类型转换在处理网页技术时是一种常见需求。将 DOCX 文件转换为易于操作的 HTML 格式，使我们能够根据需要重建数据。使用 Mammoth，我们学会了如何从 docx 中提取文本并将其转换为 HTML。</p><p>在转换为 HTML 时，我们可以使用我们创建的 CSS 规则或常见的 UI 框架提供的规则来样式化输出。我们还可以省略不需要在 HTML 中可用的数据。</p>]]></description></item><item>    <title><![CDATA[“最强大脑”下沉工地：红圈AI Agent在施工现场的N个应用瞬间 看点 ]]></title>    <link>https://segmentfault.com/a/1190000047553593</link>    <guid>https://segmentfault.com/a/1190000047553593</guid>    <pubDate>2026-01-20 16:09:06</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>吊塔旋转,机器轰鸣,尘土飞扬——这是你印象中的工地。</p><p>但如果你看得再仔细一点,会发现一些“不同寻常”的事情正在发生:</p><p>项目经理不再对着电话咆哮要数据,而是平静地对手机说句话,所有经营数字瞬间清晰呈现;</p><p>采购员不再为核查供应商背景熬夜翻网站,系统3秒自动生成一份风险“体检报告”;</p><p>材料员面前那堆如山的手写票据,正被手机摄像头快速“吞食”,自动变成系统里的规整记录……</p><p>这不是科幻电影。这是一场正在全国无数工程项目部真实上演的“静默革命”。</p><p>而掀起这场革命的,是一群特殊的“新员工”——它们不吃不喝不领工资,却24小时在岗;它们没有实体,却无所不在。它们就是红圈AI系列智能产品中的AI Agent,一群更懂工程企业经营的“数字大脑”。</p><p>今天,让我们走进施工现场,看看这群“智能同事”如何在最粗犷的行业里,干着最精细的活儿。</p><p>告别“表哥表姐”:一个能听懂人话的BOSS助理</p><p>“昨天华东区的产值是多少?”“钢筋价格波动对我们在建项目影响多大?”“帮我比一下王队和李队这个月的施工效率。”……曾几何时,项目经理的每一个问题,都可能让下属团队手忙脚乱,上演一场跨部门的数据“搬运”与“组装”大战。电话、微信、表格、报告,在碎片化的信息流中,决策的速度与准确性被大幅损耗。</p><p>红圈AI的BOSS助理Agent,终结了这种低效循环。它被设计成“更懂管理者的‘数据员’”。其核心能力在于“智能理解”与“精准呈现”。管理者可以用最自然的语言下达指令,这位助理能借助AI大模型的推理能力,精准挖掘企业自有数据模型,智能生成全面、准确的经营数据汇报。它能迅速抓取全域业务数据,精准呈现多维报表及数据卡片。</p><p>它带来的改变是颠覆性的。首先,是决策的即时性。任何时间管理者下达的指令,都能智能理解随时快速汇报,有问必答。其次,是洞察的深度。它能告别需多人汇报的繁琐与校验,直接提供分析结果。最后,也是工程企业最为看重的数据安全。它依托红圈系统权限和数据建模能力,确保核心数据不被大模型采集与留存。</p><p>从此,在飞驰的车上、在喧闹的工地旁、在深夜的办公室,管理者与关键经营数据之间,只剩下一个简单提问的距离。数据不再是需要费力挖掘的矿石,而是随时可供引用的清泉。</p><p>风险“扫描仪”:在供应商进门之前,先看透它的底牌</p><p>工程行业有句老话:“利润是干出来的,也是省出来的,但更是‘防’出来的。”一个劣质供应商带来的合同纠纷、材料延误、质量隐患,足以吞噬一个项目的全部利润。传统的供应商评估,严重依赖个人经验、有限的工商查询和耗时耗力的背景调查,如同雾里看花,风险防不胜防。</p><p>红圈AI的采购助理Agent,就像一台高精度的风险“扫描仪”。它整合多维度供应商企业数据并通过AI算法智能动态评分,减少人工主观误差。它的工作流程快如闪电:3秒完成信用数据抓取,40秒AI完成各风险排查及评估,10秒生成完整报告。</p><p>这份报告的价值,在于其令人信服的“硬核”细节。报告会进行多维评估,基于六大维度数据采集,逐项风险排查分析。例如,面对一家高风险供应商,报告会列出“异常情况总览”,包括企业存在破产案件记录、被列为限制高消费企业(存在多条限制消费令)、存在终本案件、因未按规定提交年度报告被列入经营异常名录等。</p><p>更令人惊叹的是它对法律风险的深度剖析。报告中会详细拆解法律诉讼情况:包括总诉讼案件、涉诉金额、作为被告/原告的次数及金额。它会分析主要案件类型(如买卖合同纠纷),并指出企业作为被告的纠纷金额较大,显示在大量交易中存在违约风险;同时企业作为原告也发起多起诉讼,反映其业务合作中可能存在较多争议。最终给出穿透性判断:民事纠纷频发且存在不利判决,表明企业在合同管理和履约合规性方面存在明显短板。</p><p>这套系统不仅是“守门员”,更是“监护仪”。它能对已合作的供应商进行定期智能排查,自动刷新风险等级及各项评分,并通过风险变化通知进行提示。企业可以设置限制合作标准,快速终止合作并系统溯源追查从此,采购部门的工作,从“救火”变成了主动“防火”。</p><p>“秒懂”一切单据:让最繁琐的录入工作,变得“毫无存在感”</p><p>如果说数据决策和风险防控是“高大上”的脑力活,那么单据录入就是工地里最接地气、也最让人头疼的“体力活”。混凝土小票、机打送货单、手写签收单、甚至偶现的外文单据……它们格式不一、字迹潦草、数量庞大,却是成本归集的第一道生命线。传统的人工录入,是重复、枯燥且错误率高发的代名词。</p><p>红圈AI录单助手Agent pro,正是为了消灭这种“毫无创造力的痛苦”而生。它通过大模型自动识别各类单据,实现从图像识别到高质量系统录入的秒级闭环。它能智能提取关键字段、智能匹配相关数据并回填业务系统。</p><p>它的智能远不止于“识别”,更在于“理解”与“关联”。智能分析入库材料匹配的合同明细并挂接,从而厘清成本发生源头。效率的提升是数量级的:处理5张单据约50条明细,人工录入需20-30分钟,而AI录入仅需3-5分钟,减少90%人工操作。</p><p>为了实现极高的匹配准确率,它融合了多种智能策略。“精准匹配” 根据入库单的物资名称、规格型号等字段精准匹配合同明细。据同一个项目历史匹配的数据,自动做对应数据匹配。当遇到模糊或复杂情况时,“智能判断” 功能启动,借助大模型语意识别及通识能力,智能判别入库明细与合同明细的相似性并完成匹配。这种能力,让低成本完成实际成本归集统计,实现后期精准统计及溯源成为可能。材料员和成本会计,终于可以从无尽的表格中直起身来,将智慧用于更重要的管理工作。</p><p>不止于此:一张看不见的智能矩阵</p><p>红圈AI在工地的应用瞬间,远不止于上述几个高光场景。它更像一个多维度的“智能矩阵”,将AI能力编织成一张覆盖工程经营全链条的隐形守护网。这个由多个AI助手构成的智能体军团,正在将“更懂工程企业经营”的承诺,落地为一个个具体而微的智能解决方案。</p><p>想象一下,在每周至关重要的项目经营例会前,项目经理不再需要带领团队熬夜准备庞杂的数据报告。他只需轻点“项目360°AI解读”功能,这个“项目经营的‘智能指挥官’”便能整合资金、成本、合同、付款等全维度经营指标,一键生成项目的全景作战图。大模型会对经营数据进行深度解读,不仅指出“项目经营毛利率为-0.63%,存在严重风险”,更能精准揭示“垫资施工存在资金风险”、“项目回款困难”、“实物工期超出合同工期”等核心问题。它甚至能调用行业专家经验,对项目进行智能评级和趋势预测,并直接给出“规范管理成本、制定详细应对计划”等结构化建议。这使得会前准备时间从以天计缩短到以分计,会议效率得以十倍提升,将管理者从数据整理的苦海中解放,真正聚焦于决策本身。</p><p>而在财务与采购部门,AI则以另一种形式发挥着“智能分析官”的作用。面对繁杂的《供应商应付管理表》,AI报表助手能够秒级解析业务数据,自动定位异常。它能快速识别供应商付款链条中的差异与风险,并基于历史合作履约情况、账期账龄等多维度数据,对所有供应商进行应付优先级排序,智能建议优先支付对象,识别付款底线,从而辅助财务进行科学的付款统筹。这改变了以往风险识别被动滞后、分析与资金情况脱节的局面,让付款决策从“凭感觉”走向“凭数据”。</p><p>当一位新员工加入公司,面对浩如烟海的制度、工艺和历史项目资料时,AI企业知识库便成为他最强的“知识中枢”。员工可以用最自然的语言提问,例如“马上要投XX智慧校园项目,找3个同类中标方案”,红圈AI能在3秒内从向量数据库中锁定历史标书、技术方案和报价分析报告,并生成对比摘要。对于法务人员,AI能快速从诉讼智库中检索相似判例,提炼风险规律与应诉策略;对于运维人员,它能即刻调取故障排除指南和历史维修方案,实现快速诊断。无论是查询差旅标准、年假天数,还是了解固定资产申请流程,AI都能做到有问必答、全年无休,将分散的企业知识转化为即问即答的能力,让核心经验传承效率提升3倍。</p><p>最后,在业务风险防控的最前线,“AI业务助手”扮演着“智能决策引擎”的关键角色。在合同审查环节,它能自动识别合同主体合法性、项目范围明确性、金额付款条款、违约责任对等性等维度的风险,将审核效率提升20倍,帮助规避80%的基础风险。面对潜在的合作方,它能自动汇总分散在工商、司法、舆情等多源信息,生成结构化的风险报告,让关键信息与风险一目了然,彻底改变了过去信息分散、耗时易错、评估片面的困境。</p><p>从项目全局指挥到单据扫描录入,从风险智能预警到知识即时获取,红圈AI系列智能产品已然构成一个协同工作的有机生态。它们并非彼此孤立的功能点,而是一个贯穿项目全生命周期、渗透业务各毛细血管的“智能矩阵”。这张网,让数据得以流动,让经验得以传承,让风险无处遁形,最终让每一个工程企业都能拥有一个全天候在线的“最强大脑”,稳健地驶向经营的下一个时代</p><p>当AI的“最强大脑”真正下沉,与工地的钢筋水泥、机械轰鸣融合,改变的远非几个岗位的效率。它正在重塑一种工作方式:让决策基于全域实时数据而非经验猜测,让风险防控于未然而非事后补救,让繁琐重复的劳动被智能释放,让管理者的视野穿透层层报表直达业务本质。红圈AI ,这些施工现场的新“工友”,正以其无声却强大的力量,推动着中国工程建造走向一个更加智能、精准与安全的未来。这,才是技术革命在产业深处,最动人、也最坚实的模样。</p>]]></description></item><item>    <title><![CDATA[SpreadJS V19.0 新特性解密：透视表拖动自定义排序，解锁数据整理新姿势 葡萄城技术团队 ]]></title>    <link>https://segmentfault.com/a/1190000047553598</link>    <guid>https://segmentfault.com/a/1190000047553598</guid>    <pubDate>2026-01-20 16:08:07</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在数据分析与报表制作场景中，透视表凭借强大的维度聚合能力成为开发者的核心工具。但传统透视表的排序功能往往受限于固定规则，当用户需要根据业务逻辑自定义调整字段项顺序时，操作繁琐、灵活性不足的问题尤为突出——比如想按业务优先级调整产品类别顺序，或按部门协作逻辑重组数据维度，都需要额外编写复杂代码或手动修改数据源，严重影响工作效率。</p><p>为解决这一痛点，SpreadJS V19.0 重磅推出透视表拖动（自定义）排序功能，让用户无需复杂配置，通过直观的拖拽操作即可实现字段项顺序的自由调整，彻底重构透视表数据整理的便捷性。下面，我们将深入解析这一特性的核心价值与使用细节。</p><h2>核心功能解析：灵活拖拽，精准控序</h2><p>SpreadJS V19.0 的透视表拖动排序功能，以“直观操作+全面兼容”为设计核心，覆盖多种使用场景，满足不同用户的排序需求：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047553600" alt="在这里插入图片描述" title="在这里插入图片描述"/></p><h3>1. 多维度拖拽选择，适配多样操作习惯</h3><p>功能支持四种灵活的拖拽选择方式，无论用户习惯精准选择还是批量操作，都能快速上手：</p><ul><li>仅选择字段头（PivotField Header）：精准调整单个字段的整体顺序，不影响字段下的值区域；</li><li>选择字段头及部分值区域：针对字段下的特定数据项进行排序调整，保留其他项的原有位置；</li><li>选择字段头及全部值区域：批量移动整个字段及下属所有数据项，实现维度整体迁移；</li><li>点击字段头选择全部值区域：一键选中字段关联的所有数据，简化批量拖拽操作。</li></ul><h3>2. 可视化拖拽流程，操作直观无门槛</h3><p>拖拽过程全程伴随清晰的视觉指引，降低操作学习成本：</p><ol><li>鼠标移动到选中区域边缘时，光标自动切换为“移动状态”，明确提示当前区域可拖拽；</li><li>按下鼠标开始拖拽后，系统会显示动态拖拽指示器，实时标注目标插入位置，避免误操作；</li><li>拖拽过程中，指示器会根据鼠标坐标智能判断：列字段按水平（x坐标）定位插入点，行字段按垂直（y坐标）定位，精准匹配透视表结构；</li><li>若拖拽的是父字段，指示器会自动跳过所有子字段的数据区域，确保层级结构不混乱；</li><li>释放鼠标后，选中的字段项会自动插入到指示器标注的位置，排序结果即时生效。</li></ol><h3>3. 排序选项智能联动，状态同步不脱节</h3><p>拖拽排序后，字段项的排序状态会自动同步到透视表的排序选项对话框：当用户打开排序设置时，排序方式会默认切换为“手动（manual）”，清晰标识当前为自定义拖拽排序结果，避免与系统自动排序规则冲突，也方便用户后续按需切换排序方式。</p><h2>典型应用场景：让数据整理更贴合业务逻辑</h2><p>这一特性的推出，让透视表排序彻底摆脱固定规则的束缚，在多个核心场景中发挥价值：</p><ul><li>业务优先级排序：在销售报表中，将重点推广的产品类别拖拽到靠前位置，直观突出核心数据；</li><li>协作场景适配：跨部门协作分析时，按协作流程拖拽调整部门、项目等维度顺序，让报表更符合团队工作逻辑；</li><li>个性化报表展示：根据汇报对象需求，自定义调整透视表字段顺序，让数据呈现更具针对性；</li><li>临时数据重组：数据分析过程中，快速拖拽字段项进行多维度组合尝试，无需修改数据源即可探索不同数据视角。</li></ul><h2>操作指南：3步完成自定义拖拽排序</h2><ol><li>选中目标：在透视表中选择需要排序的字段项（支持前文提到的四种选择方式）；</li><li>开始拖拽：鼠标移动到选中区域边缘，待光标变为移动状态后，按下鼠标并拖动；</li><li>确认插入：拖动过程中观察拖拽指示器，到达目标位置后释放鼠标，字段项自动完成排序调整。</li></ol><h2>注意事项：这些边界场景需留意</h2><p>为确保功能使用顺畅，以下两类操作暂不支持，开发者需提前知晓：</p><ol><li>不支持选中整行或整列进行字段项拖拽：仅能通过选中“字段头”或“字段头+值区域”的方式进行拖拽，全选行/列无法触发字段项排序；</li><li>不支持同时选择不同父字段下的同名子字段进行拖拽：SpreadJS 仅支持单个子字段的独立拖拽，避免多父字段下的子字段混淆。</li></ol><h2>总结与展望：让透视表更懂业务需求</h2><p>SpreadJS V19.0 推出的透视表拖动自定义排序功能，以“直观操作、灵活适配、精准控制”为核心优势，彻底解决了传统透视表排序灵活性不足的痛点，让数据整理更贴合业务逻辑，大幅提升报表制作与数据分析效率。</p><p>作为一款面向企业级应用的纯前端表格控件，SpreadJS 始终聚焦开发者与终端用户的实际需求，持续优化透视表等核心功能的使用体验。除了拖动排序，V19.0 还为透视表带来了日期分组、受保护工作表中启用透视表等多项增强能力，全方位提升数据处理能力。</p><p>如需了解更多功能细节，可访问 <a href="https://link.segmentfault.com/?enc=4zcI7teUY1ZZy5iu1enSZQ%3D%3D.hKrt7wbkDf0%2F0w73RdOxJa2nAKmti33C%2FLMBD4RYiHUSVPrEPg7UbqV39hmzLIIkHXgHFAn%2FOOWEcaELRMW2EQ%3D%3D" rel="nofollow" target="_blank">SpreadJS 官网</a> 查看产品文档，或通过 <a href="https://link.segmentfault.com/?enc=BT97GC5IcRLy9OLnKSkJlg%3D%3D.P4gxn5XkjBbhgLtOirf0fEc%2F%2FI87%2ByPZF%2Fn%2B4SuufKiPI%2F%2B38YrvEMZ6w7l%2FwpTGWGIP46h33BPG6cQNVk37uA%3D%3D" rel="nofollow" target="_blank">在线 Demo</a> 直接体验新特性。SpreadJS V19.0 即将正式发布，敬请期待这款更强大、更灵活的前端表格控件，为你的业务系统注入新的活力！</p>]]></description></item><item>    <title><![CDATA[未来工厂的建造者：国内顶尖整车制造数字化服务商深度盘点 雨大王 ]]></title>    <link>https://segmentfault.com/a/1190000047553604</link>    <guid>https://segmentfault.com/a/1190000047553604</guid>    <pubDate>2026-01-20 16:07:10</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在全球汽车产业加速迈向电动化、智能化的背景下，数字化制造已成为车企提升竞争力的核心手段。传统汽车制造依赖固化的流水线和经验驱动决策，难以满足市场对个性化定制、快速迭代与质量精益化的需求。而数字化制造通过集成物联网、人工智能与数字孪生等技术，正推动工厂向“柔性、透明、智能”方向演进。这一趋势下，选择一家能够真正解决制造痛点的数字化服务商，成为车企战略布局中不可忽视的一环。<br/>一、为什么数字化制造是整车领域的必选项？<br/>汽车制造业的复杂程度远超其他行业。从冲压、焊接、涂装到总装，四大工艺环环相扣，精度要求极高。在传统模式下，生产线灵活性不足，订单响应慢，质量问题往往在最终环节才暴露，导致高额返工成本。例如，某传统车企的总装车间里，每台车的组装需要300名工人流水作业，焊接、拧螺丝、质检等环节高度依赖人工经验，不仅效率低下，更难保证品质一致性。<br/>相比之下，数字化制造通过设备互联、数据互通与业务协同，显著提升了生产效率和质量管控能力。以实时数据采集为例，系统能够动态优化排产计划，应对混合车型共线生产的需求；借助AI视觉检测技术，车身焊点质量可实现100%在线评判，大幅降低漏检率；利用数字孪生技术，新车导入前即可在虚拟环境中验证工艺可行性，缩短量产爬坡周期。这些技术的集成应用，不仅解决了传统制造的痛点，更让工厂具备了快速响应市场变化的能力。<br/>二、数字化服务商的关键能力是什么？<br/>整车数字化制造涉及多技术融合与深层次行业知识，因此服务商的选择至关重要。一家优秀的数字化服务商，不仅需要提供技术平台，更需将技术落地为业务价值。这要求他们具备以下核心素质：<br/>首先，服务商必须深度理解整车制造工艺，熟悉冲压回弹控制、焊接参数优化、涂装膜厚管理等具体场景。其次，技术整合与定制化能力不可或缺。由于车企设备品牌繁多、系统异构性强，服务商需具备软硬一体集成能力，实现从边缘设备到云平台的数据贯通。比第三，全局优化与生态协同能力是数字化制造的精髓。数字化转型不是单点工具替换，而是供应链、生产与售后全链路协同。最后，服务商需具备国际化服务与本土适配能力。随着中国车企出海，海外工厂的落地需要解决当地人才与标准差异问题。<br/>三、案例：国内顶尖服务商的实践与成果<br/>广域铭岛：从汽车集团走出的数字化专家<br/>作为吉利体系孵化的工业互联网平台企业，广域铭岛基于Geega（际嘉）OS构建了整车数字化制造解决方案。在极氪智慧工厂，其通过工艺质量一体化系统，实现白车身尺寸精度控制在±0.5mm以内，订单交付周期缩短20%。同时，其智能能源管理系统帮助工厂年减排二氧化碳超过万吨，成为绿色制造的行业标杆。<br/>长安汽车：全球领先的智慧工厂解决方案样板点<br/>长安汽车与华为、中国联通共同打造的数智工厂，是全球首个全域5G数智AI柔性超级工厂。通过C2M模式驱动的柔性制造革命，长安实现了从“以产品为中心”到“以客户为中心”的转变。<br/>赛力斯：AI赋能的未来工厂典范<br/>作为新能源汽车领域的领军企业，赛力斯重庆两江分公司入选2024年重庆市未来工厂——AI赋能示范型。</p>]]></description></item><item>    <title><![CDATA[2026年主流CRM系统优缺点盘点：预算有限的团队更适合哪一款？ 程序员老叶 ]]></title>    <link>https://segmentfault.com/a/1190000047553606</link>    <guid>https://segmentfault.com/a/1190000047553606</guid>    <pubDate>2026-01-20 16:06:15</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>随着数字化转型的加速，客户关系管理（CRM）系统已成为企业不可或缺的工具。无论是销售、市场还是客户服务团队，CRM都在提升效率、优化客户体验、推动业绩增长方面发挥着核心作用。2026年，CRM市场竞争更加激烈，各大厂商不断创新，功能日益强大。但对于预算有限的中小团队，如何选择一款既实用又经济的CRM系统，成为了亟需解决的问题。</p><p>本文将盘点目前市场主流的CRM系统，包括Salesforce、Zoho CRM、HubSpot CRM、Microsoft Dynamics 365、Pipedrive、Freshsales等，从权威评测和用户反馈中提炼优缺点，并针对预算有限的团队给出建议。</p><hr/><h2>一、主流CRM系统概览</h2><p>根据Gartner、Capterra、PCMag等权威机构2026年最新评测，以下几款CRM系统在全球市场占有率和用户口碑方面表现突出：</p><ol><li><strong>Salesforce CRM</strong></li><li><strong>Zoho CRM</strong></li><li><strong>HubSpot CRM</strong></li><li><strong>Microsoft Dynamics 365</strong></li><li><strong>Pipedrive</strong></li><li><strong>Freshsales</strong></li></ol><hr/><h2>二、各CRM系统优缺点详解</h2><h3>1. Salesforce CRM</h3><h4>优点</h4><ul><li><strong>功能最全</strong>：作为全球领先的CRM，Salesforce拥有极为丰富的功能模块，包括销售自动化、营销自动化、服务管理、分析报表、AI智能助手等，适用于各类企业。</li><li><strong>高度可扩展</strong>：支持自定义开发、API集成，拥有庞大的应用生态（AppExchange），可根据业务需求进行深度定制。</li><li><strong>数据安全与合规性</strong>：通过多项国际认证，数据安全和隐私保护能力强。</li></ul><h4>缺点</h4><ul><li><strong>价格昂贵</strong>：基础版起步价较高，功能越多费用越高，适合预算充足的大中型企业。</li><li><strong>学习成本高</strong>：系统复杂，员工培训和实施周期较长。</li><li><strong>小团队功能过剩</strong>：许多功能对小型团队来说用不上，造成资源浪费。</li></ul><h4>适用建议</h4><p>预算有限的团队不建议首选，除非对功能有极高要求。</p><hr/><h3>2. <a href="https://link.segmentfault.com/?enc=eaEg%2FU75Le4Oz9iMdl0bQA%3D%3D.mTbFZw0QH0WQHzkwYOc2g10YYgZws%2FWgJzugSdwVT4Q%3D" rel="nofollow" target="_blank">Zoho CRM</a></h3><h4>优点</h4><ul><li><strong>性价比高</strong>：Zoho CRM以实惠的价格提供全面的CRM功能，尤其适合中小企业和初创团队。</li><li><strong>易用性强</strong>：界面简洁，操作直观，上手快，支持中文界面和本地化服务。</li><li><strong>功能丰富</strong>：涵盖销售管理、市场营销、自动化流程、数据分析等，支持多渠道集成（邮件、社交、电话等）。</li><li><strong>生态完善</strong>：与Zoho旗下其他产品（如Zoho Campaigns、Zoho Desk、Zoho Finance等）无缝集成，形成一体化办公平台。</li></ul><h4>缺点</h4><ul><li><strong>高级定制有限</strong>：虽然支持一定程度的定制，但与Salesforce相比，深度开发和复杂流程支持略弱。</li><li><strong>第三方集成略少</strong>：部分外部应用集成不如Salesforce丰富，但主流需求基本覆盖。</li></ul><h4>适用建议</h4><p>预算有限的团队首选之一，尤其适合追求高性价比和易用性的企业。</p><hr/><h3>3. HubSpot CRM</h3><h4>优点</h4><ul><li><strong>免费基础版</strong>：核心CRM功能完全免费，适合预算极其有限的团队。</li><li><strong>营销自动化强</strong>：HubSpot在营销自动化和内容管理领域表现突出，适合需要市场推广的团队。</li><li><strong>界面友好</strong>：设计现代，用户体验好，支持拖拽式自定义。</li></ul><h4>缺点</h4><ul><li><strong>进阶功能收费</strong>：如销售自动化、分析报表、客户服务等高级功能需付费，且价格逐级递增。</li><li><strong>本地化支持有限</strong>：中文支持和本地服务不如Zoho CRM。</li></ul><h4>适用建议</h4><p>预算有限且对营销自动化有需求的团队可以优先考虑，尤其是初创企业。</p><hr/><h3>4. Microsoft Dynamics 365</h3><h4>优点</h4><ul><li><strong>与Office生态无缝整合</strong>：适合已采用微软产品的企业，提升协同效率。</li><li><strong>功能全面</strong>：涵盖销售、市场、客服、项目管理等模块。</li><li><strong>强大分析能力</strong>：集成Power BI，数据分析和报表功能突出。</li></ul><h4>缺点</h4><ul><li><strong>价格偏高</strong>：整体费用不低，功能模块按需购买，成本易超预算。</li><li><strong>实施复杂</strong>：需要专业IT团队支持，学习曲线陡峭。</li></ul><h4>适用建议</h4><p>预算有限的团队不建议优先考虑，适合已有微软生态的大型企业。</p><hr/><h3>5. Pipedrive</h3><h4>优点</h4><ul><li><strong>专注销售流程</strong>：以销售为核心，流程清晰，适合销售驱动型团队。</li><li><strong>价格合理</strong>：基础版价格较低，按需升级，适合中小企业。</li><li><strong>易于使用</strong>：界面简洁，功能聚焦，学习成本低。</li></ul><h4>缺点</h4><ul><li><strong>功能相对单一</strong>：以销售为主，市场营销、客服等模块较弱。</li><li><strong>分析能力有限</strong>：数据分析和报表功能不如Salesforce和Zoho CRM全面。</li></ul><h4>适用建议</h4><p>预算有限且以销售为主的小型团队可以优先考虑。</p><hr/><h3>6. Freshsales（Freshworks CRM）</h3><h4>优点</h4><ul><li><strong>一体化解决方案</strong>：集成销售、市场、客服于一体，适合需要全流程管理的团队。</li><li><strong>价格亲民</strong>：基础版价格适中，功能覆盖日常需求。</li><li><strong>自动化强</strong>：支持销售自动化、邮件跟进、线索评分等。</li></ul><h4>缺点</h4><ul><li><strong>本地化支持一般</strong>：中文支持和国内服务有待提升。</li><li><strong>生态有限</strong>：与第三方应用集成不如Salesforce和Zoho CRM广泛。</li></ul><h4>适用建议</h4><p>预算有限且希望一体化管理的小型团队可以考虑。</p><hr/><h2>三、权威评测与用户反馈</h2><h3>Gartner魔力象限（2026）</h3><ul><li><strong>领导者象限</strong>：Salesforce、Microsoft Dynamics 365</li><li><strong>挑战者象限</strong>：Zoho CRM、HubSpot CRM</li><li><strong>远见者象限</strong>：Freshsales、Pipedrive</li></ul><h3>Capterra用户评分（2026）</h3><table><thead><tr><th>CRM系统</th><th>总分（满分5）</th><th>易用性</th><th>性价比</th><th>客户支持</th></tr></thead><tbody><tr><td>Salesforce</td><td>4.6</td><td>4.2</td><td>3.8</td><td>4.5</td></tr><tr><td>Zoho CRM</td><td>4.4</td><td>4.5</td><td>4.7</td><td>4.4</td></tr><tr><td>HubSpot CRM</td><td>4.5</td><td>4.7</td><td>4.6</td><td>4.3</td></tr><tr><td>Dynamics 365</td><td>4.3</td><td>4.0</td><td>3.9</td><td>4.2</td></tr><tr><td>Pipedrive</td><td>4.3</td><td>4.6</td><td>4.5</td><td>4.1</td></tr><tr><td>Freshsales</td><td>4.2</td><td>4.4</td><td>4.3</td><td>4.0</td></tr></tbody></table><h3>媒体点评（PCMag、TechRadar、Forbes）</h3><ul><li><strong>Salesforce</strong>：功能无敌，但价格高昂，适合大企业。</li><li><strong>Zoho CRM</strong>：中小企业首选，性价比极高，功能实用。</li><li><strong>HubSpot CRM</strong>：免费入门，营销自动化强，适合初创团队。</li><li><strong>Pipedrive</strong>：销售团队利器，流程简明，价格合理。</li><li><strong>Freshsales</strong>：一体化管理，适合成长型企业。</li></ul><hr/><h2>四、预算有限团队的选择建议</h2><h3>1. 明确需求</h3><p>首先，团队需明确自身需求：是以销售为主、市场为主，还是需要全流程管理？是否需要高度定制？对本地化支持有无要求？</p><h3>2. 价格与功能平衡</h3><ul><li><strong>预算极低且重视营销自动化</strong>：优先考虑<strong>HubSpot CRM</strong>免费版，后续可根据需求升级。</li><li><strong>追求高性价比与易用性</strong>：<strong>Zoho CRM</strong>是最佳选择，价格合理，功能全面，支持中文及本地服务。</li><li><strong>专注销售流程</strong>：<strong>Pipedrive</strong>简单高效，适合销售驱动型团队。</li><li><strong>一体化管理</strong>：<strong>Freshsales</strong>功能均衡，价格适中。</li><li><strong>对微软生态有依赖</strong>：可考虑<strong>Dynamics 365</strong>，但需预估预算与实施成本。</li></ul><h3>3. 试用与评估</h3><p>大多数CRM厂商都提供免费试用期，建议团队先实际操作，体验界面、功能和服务，再做最终决定。</p><hr/><h2>五、Zoho CRM的独特优势</h2><p>Zoho CRM在预算有限团队中的独特优势：</p><ul><li><strong>价格透明，套餐灵活</strong>：支持按需选择，避免资源浪费。</li><li><strong>本地化服务强</strong>：中国区设有专属团队，支持中文界面、微信集成等。</li><li><strong>生态系统完善</strong>：可无缝连接Zoho旗下办公、财务、项目等产品，提升团队整体协作效率。</li><li><strong>自动化与智能分析</strong>：通过AI助手Zia，实现线索评分、销售预测、自动提醒等功能，帮助小团队提升业绩。</li><li><strong>安全合规</strong>：通过GDPR、ISO等国际认证，保障数据安全。</li></ul><hr/><h2>六、结论</h2><p>2026年CRM市场百花齐放，各大系统各有千秋。对于预算有限的团队，选择CRM时应以“实用性、性价比、易用性”为核心标准。综合权威评测与用户反馈，<strong>Zoho CRM</strong>、<strong>HubSpot CRM</strong>、<strong>Pipedrive</strong>、<strong>Freshsales</strong>是最值得推荐的四款，能够兼顾成本与功能，助力中小团队高效管理客户关系，实现业绩增长。</p><p>最后建议，团队应结合实际需求，积极试用，多参考权威评测和用户口碑，选出最适合自己的CRM系统。未来，CRM将继续智能化、自动化，成为企业数字化转型的强力引擎。</p>]]></description></item><item>    <title><![CDATA[百度文心助手月活破2亿，国内三大AI超级入口形成 咸口锅包肉 ]]></title>    <link>https://segmentfault.com/a/1190000047553681</link>    <guid>https://segmentfault.com/a/1190000047553681</guid>    <pubDate>2026-01-20 16:05:17</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><img width="723" height="471" referrerpolicy="no-referrer" src="/img/bVdnG2S" alt="微信图片_20260120151234_1904_102.jpg" title="微信图片_20260120151234_1904_102.jpg"/></p><p><strong>1月20日，据《华尔街日报》报道，百度旗下文心助手月活用户数已突破2亿，与豆包、千问形成国内三大亿级AI入口。</strong></p><p>此前国内报道，<strong>文心助手</strong>是百度APP推出的AI智能助手，依托文心大模型和“百度猎户座”AI引擎，实现了搜索与AI的深度重构，<strong>是集深度思考、多模态交互与全场景服务于一体的全能搭子</strong>。</p><p>据悉，该助手具备强大的深度思考与长期记忆能力，能结合交互上下文，提供极具个性化的精准回应与推荐，并能深度思考和主动推荐，懂用户所想；同时具备多模态全能交互能力，支持视频通话、AI创作、拍照问答、打电话、拍题答疑等多项AI服务，让AI真正深入用户的实时生活与工作场景中；更为重要地是，文心助手充分发挥了百度搜索生态优势，支持MCP服务工具调用，实现从“提供信息”到“交付服务”。目前不仅接入了百度地图、百度健康等百度生态服务，而且链接了京东、美团、盈米基金等头部合作伙伴MCP服务，全面覆盖电商、健康、本地生活、学术教育、汽车、金融、法律、星座命理等多个领域，解决用户订票、出行、购物，理财与法律咨询等需求。</p>]]></description></item><item>    <title><![CDATA[家中杂物管理术 - 不断不舍不离 Homebox 本文系转载，阅读原文
https://blog.m]]></title>    <link>https://segmentfault.com/a/1190000047553718</link>    <guid>https://segmentfault.com/a/1190000047553718</guid>    <pubDate>2026-01-20 16:04:45</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><img width="723" height="381" referrerpolicy="no-referrer" src="/img/bVdnG3k" alt="Homebox 的 QR Code 标签" title="Homebox 的 QR Code 标签"/></p><p>本文分享如何通过 Homebox —— 一个自托管的家庭物品管理系统，重新整理我的 “杂物生活”，节省时间、减少焦虑，并让全家人都受益。如果你的第一反应是 “就家里那点东西要上系统，至于吗？” 那证明你是个正常人，我以前也是这样的反应。作为一名技术爱好者，我曾长期被家中不断增长的电子设备和零部件小工具所困扰。</p><p>作为一名软件工程师，我的生活始终游走在数字世界与现实世界之间。白天，我为大型企业设计复杂的系统架构，帮助它们管理庞大的数字资产、提升运转效率（Come on…… AI, 你不知道我已经失业了吗 🙄）；到了晚上和周末，我就是 “折腾党”。无论是写脚本自动化家里的灯光系统，在 Homelab 搭建一组 Raspberry Pi 集群，还是亲手给汽车做一次 DIY 换灯，这些动手项目都让我乐在其中。</p><p>然而，我的这些爱好背后，渐渐笼罩上了一层阴影：<strong>东西实在太乱了。</strong></p><blockquote>注：本文由我写大纲，Gemini 协助完成润色和扩展。我也作了后期 review 和修改。其中绝大部分内容来自我自己的真实经历和感受。</blockquote><p><img width="430" height="932" referrerpolicy="no-referrer" src="/img/bVdnG3n" alt="image.png" title="image.png" loading="lazy"/></p><h2>“设备税”：看不见的精神负担</h2><p>很多年里，我一直承受着一种挥之不去、却又说不清的低度焦虑感。家里到处都是“明明存在、却像消失了一样”的物品。我留着一堆早已不用设备的线缆，却偏偏找不到正在用的那根；抽屉里塞满了传感器、微控制器和汽车零件，因为没有整理，它们几乎等同于不存在。</p><p>真正让我崩溃的，通常是两种情况之一。第一种是“重复购买”：为了某个项目，我兴冲冲地买了一个 OBD‑II 扫描仪或一根高速 USB‑C 线，结果三个月后在一个盒子里，又发现了一模一样的东西。第二种是“家庭冲突”：我妻子问我备用电池或某个工具放在哪儿，而我只能指着车库或书房，给出一个模糊的方向——这显然无助于家庭和谐。</p><p>我终于意识到，自己正活成了那句老话的典型例子：“鞋匠的孩子没鞋穿。” 我在工作中帮公司把数据管理得井井有条，而自己的私人“资产管理”却一团糟。我必须开始<strong>自己吃自己做的狗粮（Eat My Own Dog Food）</strong>。</p><h2>发现 Homebox：自托管的答案</h2><p>我接触自托管（self‑hosting）已经有一段时间了，从媒体服务器到家庭自动化系统都折腾过。但直到我发现 <a href="https://link.segmentfault.com/?enc=JgNEBmccHdfjSjVc%2F4%2FrhA%3D%3D.lW6%2F%2BegcSHb2uIiFQ5r%2ByijecdW4tJKxiAnH7E%2BHkzxS9BnbnrwmBzsxNL3dCVks" rel="nofollow" target="_blank"><strong>Homebox</strong>（homebox.software）</a>，才算找到了拼图中缺失的那一块。</p><p>Homebox 是一个开源、自托管的家庭物品管理系统，专为普通家庭设计。它不像工业级资产管理系统那样复杂笨重，而是轻量、快速、直观。使用 Go 编写，后端是 SQLite，资源占用极低，丢到一台 Raspberry Pi 上跑也毫无压力。</p><h2>从“纸箱”到“比特”：搭建过程</h2><p>安装本身非常简单，一个 <code>docker-compose</code>，几分钟内就能看到干净、响应迅速的 Web 界面。真正的挑战——任何数据工程师都懂——在于<strong>录入数据</strong>。</p><p>一开始，说实话我有点想偷懒。面对多年积累下来的“技术囤货”，我差点在开始之前就放弃了。后来我决定套用一个最基本的管理原则：<strong>从小处开始，持续迭代</strong>。</p><p>我只专注于书房——我的“指挥中心”，那里放着 homelab 设备、焊接工具以及各种零碎电子玩意。</p><p>首先是 <strong>位置（Locations）</strong> 的层级结构。Homebox 支持嵌套位置，于是我这样规划：</p><ul><li><p><strong>书房</strong></p><ul><li><p><strong>储物柜 A</strong></p><ul><li><strong>第 1 层（微控制器）</strong></li><li><strong>第 2 层（线缆）</strong></li></ul></li><li><strong>书桌抽屉</strong></li></ul></li></ul><p>接下来是 <strong>物品（Items）</strong>。每一件硬件，我都会记录：</p><ul><li><strong>名称与描述</strong>：清晰、可搜索。</li><li><strong>购买时间与价格</strong>：方便追踪我的“折腾预算”。</li><li><strong>保修信息</strong>：不再翻邮箱找 PDF 发票，直接附在物品记录里。</li><li><strong>标签（Tags）</strong>：真正的威力所在，比如 <code>#automotive</code>、<code>#esp32</code>、<code>#usb-c</code>、<code>#raspberrypi</code>。</li></ul><h2>转折点：那串“消失的钥匙”</h2><p>起初的几个星期，Homebox 对我来说更像是一个“理论工具”——我在录数据，但还没真正依赖它。直到某个周二早上，我开会已经迟到十分钟，车钥匙却怎么也找不到。</p><p>在沙发垫、外套口袋里疯狂翻找五分钟后，我突然灵光一闪：<strong>我是不是记过这个？</strong>  <br/>我掏出手机，打开 Homebox，搜索 “钥匙”。结果立刻跳了出来：我把它们作为一个“资产”记录过，位置是 <strong>书房 → 书桌抽屉（小收纳盒）</strong>。</p><p>前一晚做项目时，我为了避免焊锡助焊剂沾到钥匙，把它们放到了那里。正是这个清晰、准确的位置记录，帮我省下了至少二十分钟的焦虑。那一刻，Homebox 从“业余项目”正式升级成了“生活必需品”。</p><h2>真正改变体验的功能</h2><p>一旦体会到实际价值，我就彻底“上头”了。下面这些功能，尤其打动技术爱好者：</p><ol><li><strong>二维码与标签</strong>  <br/>Homebox 可以为每个物品和位置生成二维码。我给那些不透明的收纳箱都贴上了小标签。现在不需要再翻箱倒柜，只要一扫码，就能看到箱子里的完整清单。</li><li><strong>维护与保养计划</strong>  <br/>对于汽车相关的零件，我可以设置提醒。比如刹车片、机油滤芯，什么时候该用、库存还剩多少，一目了然。</li><li><strong>家庭共享</strong>  <br/>这是对我婚姻帮助最大的一点。我给妻子也开了访问权限。现在她想找某个工具，或者只是想知道家里还有没有备用 HDMI 线，都可以自己查。结果是，“那个东西在哪？”的问题大幅减少。</li><li><strong>理性消费</strong>  <br/>在 京东 点下“立即购买”之前，我会先在 Homebox 里搜一下。这已经帮我省下了不少钱——提醒我某个电阻包、转接头，其实就躺在某个“待整理”的箱子里。</li></ol><h2>结语</h2><p>如果你是技术爱好者、DIY 玩家，或者只是厌倦了那种“东西到底放哪了？”的精神消耗，我真心推荐你试试 Homebox 。它不仅仅是一个数据库，而是一种重新掌控时间与空间的方式。</p><p>作为一名软件工程师，我越来越清楚：我们用来支撑企业系统稳定运行的那些原则——<strong>组织、有文档、易访问</strong>——在家里同样重要。  <br/>事实证明，我做的“Dog Food”味道还不错；而多亏了 Homebox，我的书房终于更像实验室，而不再是杂物堆了。</p><p>Homebox 这样的软件大概不会在国内流行。不是资产多少问题，是大家的习惯不同。大家的记忆力都特别好，国内的小工具小产品的价格又物美价廉，丢了买新的也大概不太心痛。而且管理风格上也不同，我们更注重人而非数据。而就算有这种需求，大概会选择 Excel 或大平台的云服务来解决。</p>]]></description></item><item>    <title><![CDATA[一图看懂HarmonyOS SDK 鸿蒙百晓生 ]]></title>    <link>https://segmentfault.com/a/1190000047553724</link>    <guid>https://segmentfault.com/a/1190000047553724</guid>    <pubDate>2026-01-20 16:03:59</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><img width="723" height="3235" referrerpolicy="no-referrer" src="/img/bVdnG3l" alt="一图看懂HarmonyOS SDK.png" title="一图看懂HarmonyOS SDK.png"/></p><p><a href="https://link.segmentfault.com/?enc=vXKh3XUlYn93qA%2FpEUJqWA%3D%3D.V9L0eIAoN7yhn8NRbneftliE5t%2FjTASybRF%2FlLqEMJrRUkJXiRoH4sGTM1f%2Fb8kwzEIJV3DAZrN3N7aun7mZdnFwQQ6qI34wO8eC3J4%2F22W9xK4d7nKZEOClhgODDWKb" rel="nofollow" target="_blank">HarmonyOS SDK 官方社区</a><br/><a href="https://link.segmentfault.com/?enc=iqp3DxN%2BDUgE06Ya1qjsAg%3D%3D.xANFr0XDENhSwMcWzLvGMavR5doh69ySSGYLmy0Td%2BsgH7h5cLcC1qH68CZ97%2Bj93OW%2FHS5HRJ6zECp94YV1jFdD9uM8DNJ26OwnOG9v3vf5oZqgymmUy1Er81Cfn6Vu" rel="nofollow" target="_blank">加入 HarmonyOS，正当其时</a></p>]]></description></item><item>    <title><![CDATA[一图看懂HarmonyOS SDK AI领域开放能力 鸿蒙百晓生 ]]></title>    <link>https://segmentfault.com/a/1190000047553740</link>    <guid>https://segmentfault.com/a/1190000047553740</guid>    <pubDate>2026-01-20 16:03:08</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><img width="723" height="1757" referrerpolicy="no-referrer" src="/img/bVdnG3T" alt="一图看懂HarmonyOS SDK AI领域开放能力.png" title="一图看懂HarmonyOS SDK AI领域开放能力.png"/></p><p><a href="https://link.segmentfault.com/?enc=BTgNG0EbmTHsW7ha3eALjg%3D%3D.QmU9KGmlSVNEPQgzGNw%2FIllPYWyOyfUYjEAeSFsfjD7nYfwvgE4%2Bo%2BvpuNR4pb%2FtkGU07RWu3CD97poeKFt9xQdTV%2BTpt4uByt5mVvkQml8Y3dqAacf9AQnaNW1px2F3" rel="nofollow" target="_blank">HarmonyOS SDK 官方社区</a><br/><a href="https://link.segmentfault.com/?enc=iDKLYEF5cJCJFwXdbZDB0g%3D%3D.fiuTdGYRUCjaNw0sRErnDamYNpduk%2FaTI7lJkcwBeC4UVSYWrGTdvLPQqozVDMvRyNqyTJZhyvIC1p5rJnzvQIwgbqwGgB4G95qd0T8r7jw85VnQ53U54Z3XoOrkOWbl" rel="nofollow" target="_blank">加入 HarmonyOS，正当其时</a></p>]]></description></item><item>    <title><![CDATA[保姆级教程！TinyPro 最新 SpringBoot 上手指南，新手也能快速落地 OpenTiny]]></title>    <link>https://segmentfault.com/a/1190000047553767</link>    <guid>https://segmentfault.com/a/1190000047553767</guid>    <pubDate>2026-01-20 16:02:09</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>本文由TinyPro中后台系统贡献者周泽龙原创。  </p><p>在长达三个月的开发下，终于TinyPro的Springboot后端版本终于要问世了，在本期内容中我将带大家一步步去搭建整个后端的流程，也将带大家去探索对于最新版本的更改应该如何实现，以及如何使用本项目进行一个二次的开发和探索。<br/>首先我们先要对于TinyPro项目进行一个整体的拉取，去到TinyPro的官方进行拉取，当我们获取到项目以后就可以进行开始今天的项目构建了。</p><blockquote>接下来的流程就是对于前端i项目的搭建以及后端的springboot项目的搭建，最后再去介绍咱们新版本里面的一些特性和组件</blockquote><h2>1.前端部分的搭建</h2><p>首先要确保咱们安装了Node.js、NPM、TinyCLI接下来就要正式初始化项目了首先我们进行初始化</p><p>(1)在命令行输入tiny init pro对项目进行一个初始化具体的流程可以看我的<a href="https://www.bilibili.com/video/BV1kNkeBKEEt/?spm_id_from=333.1387.homepage.video_card.click" target="_blank">视频介绍</a>  </p><p><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdnG4b" alt="1.jpg" title="1.jpg"/><br/>(2)接下来就让我们进入到我们的项目里面，tinyvue的前端代码里面我们首先进行一个项目的依赖的下载大家可以使用npm install进行项目依赖的下载。  </p><p>(3)当我们项目依赖下载完成后就可以进入到一个启动流程了，使用npm start进行一个项目的启动启动后就会开启3031端口这样就可以看见项目的启动界面了!  </p><p><img width="723" height="408" referrerpolicy="no-referrer" src="/img/bVdnG4c" alt="2.png" title="2.png" loading="lazy"/></p><blockquote>到目前为止我们的前端项目就算正式启动成功了，接下来让我们一起开始启动后端项目</blockquote><h2>2.后端项目的搭建</h2><p>首先我们需要确保自己的本地环境里面有jdk17，maven,mysql,redis以及一个自己喜欢的开发软件可以idea或者vscode</p><blockquote>好了准备工作做好以后接下来就让我们进入后端的开发和后端二次开发的一个介绍并且我也将带着大家去了解springboot里面的一些设计和里面的一些函数的内容接下来开始吧</blockquote><p>项目结构的介绍：<br/>当进入到项目里面的时候我们最直观的可以看见项目的一个整体结构  </p><p><img width="462" height="763" referrerpolicy="no-referrer" src="/img/bVdnG4d" alt="3.png" title="3.png" loading="lazy"/><br/>（1）先介绍一下项目的一个配置文件，对于所有的springboot项目上来第一件事就算看配置文件<code>application.properties</code>文件这个文件里面包含了所有项目需要的配置比如：<code>mysql</code>,<code>redis</code>,<code>Springjpa</code>,<code>mybatis-plus</code>(项目里面没有使用，但是基本的配置都配置好了，也就兼容了喜欢使用mybatis-plus的同学）大家可以更具自己的数据库信息和redis进行配置，需要自己填写好数据库的用户名，端口和驱动地址，还有redis的配置信息比如主机地址和端口号</p><blockquote>到这里的同学，那就恭喜大家数据服务的配置我们就是做好了，接下来就是对项目的依赖的下载，这块主要涉及到maven的使用，如果还，没有下载maven的同学记得赶快去下载</blockquote><p>（2）接下来开始项目依赖的初始化过程，在项目启动的时候，我们需要先对项目的依赖包去官方的仓库里面下载(这块给大家一个提醒，如果下载过慢的同学记得去配置一下maven的国内镜像源进行下载和配置),敲入命令<br/><code>mvn install</code>进行一个项目依赖的下载。</p><blockquote>如果到这里都执行成功，大家就可以正式的启动项目，正式启动项目之前我希望大家可以去查看自己jdk的配置是否是17，因为接下来的必须要使用jdk17了</blockquote><p>（3）进入到<code>TinyProApplication</code>文件里面进行启动项目，在这之前需要确保启动了redis和mysql的服务，并且配置好了密码，然后启动项目以后我们就会看到一个提示：  </p><p><img width="723" height="108" referrerpolicy="no-referrer" src="/img/bVdnG4e" alt="4.png" title="4.png" loading="lazy"/><br/>这里就算证明项目的整体正式启动成功了，接下来就开始监听3000端口了。</p><blockquote>项目启动成功以后就可以开始进行一个交互了，大家就可以进入到刚才启动的前端项目里面准备进行一个交互，账户和密码都是admin，这块是配置里面预先写好的，如果有人需要修改这个用户和角色名称，可以进到 <code>DataInitializer</code>文件里面找到user配置进行修改</blockquote><h2>3.二次开发的讲解</h2><p>首选项目里面可以进行二次开发的地方就算，<code>权限管理</code>，<code>拒绝策略</code>，以及<code>用户的登录校验</code>，<code>初始化配置</code>  </p><p><img width="723" height="434" referrerpolicy="no-referrer" src="/img/bVdnG4f" alt="5.png" title="5.png" loading="lazy"/></p><p>（1）首先就是项目的权限管理的问题大家可以看见代码里面首先需要权限校验的接口上面都会有一个</p><p><img width="723" height="76" referrerpolicy="no-referrer" src="/img/bVdnG4g" alt="6.png" title="6.png" loading="lazy"/><br/><code>@PermissionAnnotation</code>这个注解里面配置的就是当前接口需要用户所拥有的权限，然后这块里面底层的实现细节在aspect这个目录里面，然后里面就是对于apo的一个使用。如果大家需要给某一个接口增加新的权限大家就可以直接在接口的上面进行一个使用然后写入具体要限制的细节<br/>比如可以写：  </p><p><img width="723" height="68" referrerpolicy="no-referrer" src="/img/bVdnG4h" alt="7.png" title="7.png" loading="lazy"/><br/>这块就是要求用户必须要有menu::query::list这个权限才能进入到这个接口里面进行查询操作如果大家想更进一步了解到权限管理的细节，可以去看aop的使用java里面的切面编程</p><p>（2）接下来可以看拒绝的策略，首先对于接口拒绝策略的具体控制在配置文件里面，大家可以看到  </p><p><img width="449" height="60" referrerpolicy="no-referrer" src="/img/bVdnG4i" alt="8.PNG" title="8.PNG" loading="lazy"/> <br/>这块就是一个拒绝策略的开关，如果大家想开始拒绝策略就可以直接输入true这个然后就会开启拒绝策略进行项目模式，目前是默认在演示模式里面</p><blockquote>这个里面主要分为一个演示模式和一个项目模式，在项目模式里面大家可以自由的进行控制但是在演示模式里面，有很多的功能都被禁止了，所以大家要是不能使用的话就需要先查看是否是因为在演示模式里面导致的</blockquote><p>（3）接下来就是用户的登录校验，大家首先要明白的一个流程就是用户首先要登录，只有登录成功以后才会将token放到redis里面，然后用户登录的校验就会先去redis里面进行查询，如果查询的到就会通过校验，如果redis里面没有当前用户人的信息就会进行一个拒绝的返回，然后就会跳转到前端的登录界面里面进行一个登录。具体就是拿一个拦截器进行拦截然后对每一个请求都进行校验只有登录过的才能进行项目的操作<br/>（4）项目的初始化整个项目的初始化都在DataInitializer.java这个文件里面，如果后续需要进行一个项目的初始化调整，比如更改初始化的顺序以及在初始化的过程中想再加载一些资源都可以在这个文件里面进行增加  </p><p><img width="723" height="597" referrerpolicy="no-referrer" src="/img/bVdnG4j" alt="9.png" title="9.png" loading="lazy"/></p><p>在这个run方法里面进行添加，这样项目在启动的时候就会先去加载项目里面的内容然后生成一个data文件夹的，这就标志着项目以及初始化过了，不需要再进行初始化，接下来每次的项目初始化都会先去看项目里面是否有data的目录如果存在就不走初始化的逻辑了</p><blockquote>好了讲解完二次开发以后，接下来就要进入到docker的一个部署流程，在这个之前，大家可以更具的自己的情况去看是去买一个云服务器还是自己搭建一个虚拟机环境，然后进行配置，我在视频里面给搭建演示的就是在自己的虚拟机里面进行一个docker的部署和调用</blockquote><h2>4.docker的部署讲解</h2><p>首先要了解在进行docker部署的时候，自己的容器文件里面的内容是否创建好了，以及对应的docker-compose.yml的一个配置</p><blockquote>再检查完这些内容以后就要进入到我们的一个docker的部署流程环节，其实本质上也很简单就是进入到项目的文件夹目录里面，然后直接执行docker compose up -d这个命令以后，等待下载，但是下载的过程里面会有很多的问题比如下载过慢问题</blockquote><p>（1）将项目的文件上传到服务器上面  </p><p><img width="723" height="178" referrerpolicy="no-referrer" src="/img/bVdnG4k" alt="10.png" title="10.png" loading="lazy"/></p><p>然后进入当前目录大家可以看见，项目里面有两个文件一个是Dockerfile另一个是docker-compose.yml着两个文件是我们必须要的文件，进入进去看见  </p><p><img width="723" height="627" referrerpolicy="no-referrer" src="/img/bVdnG4l" alt="11.png" title="11.png" loading="lazy"/></p><p>里面就是一些配置比如mysql的地址以及redis的地址，都是对应着我们即将启动的容器名称  </p><p>（2）接下来就开始正式的启动docker-compose.yml文件，使用命令<code>docker compose up -d</code>启动成功以后就可以进行前端端口的配置映射到线上的docker地址，方便未来的开发  <br/><img width="723" height="58" referrerpolicy="no-referrer" src="/img/bVdnG4m" alt="12.png" title="12.png" loading="lazy"/></p><p>这个就是启动成功了，大家可以看映射的地址进行修改前端的配置了</p><h2>5.本次参加开源之夏的感受和收获</h2><p>在参加完这次的开源之夏以后，我最大的感受就是第一次有一个整齐的计划和老师还有别的学校的同学们可以一起开发一个软件，让我还没出社会的时候就已经拥有了独立开发的经验和经历。其次就是老师的辅导和社区的教导让我真的成长了很多，我特别感谢开源之夏和+OpenTiny社区对我的帮助,最后谢谢我的导师（真的很牛），他也很耐心的教我，特别感谢名字的话就不说了，不然以后有人烦他去了</p><blockquote>谢谢大家我真的很珍惜这次机会，谢谢开源之夏，谢谢OpenTiny社区，谢谢导师，那我的这次开源之旅就结束，但是我相信只是暂时，我以后还会继续投身到开源里面，也希望可以帮助更多的人</blockquote><h2>关于OpenTiny</h2><p>欢迎加入 OpenTiny 开源社区。添加微信小助手：opentiny-official 一起参与交流前端技术～</p><p>OpenTiny 官网：<strong><a href="https://link.segmentfault.com/?enc=1bq77WZNgrlUEDsegiodRw%3D%3D.cAyR304I96TIbLwWbkv%2Bxeiy3gIPtevI3SB9TScx144%3D" rel="nofollow" target="_blank">https://opentiny.design</a></strong>  <br/>OpenTiny 代码仓库：<strong><a href="https://link.segmentfault.com/?enc=f64LlGX42GlLYGEGtBpu7w%3D%3D.W8klIuP7OUixMKGygPskUlgCJKYRtu074IZbTzJPIxY%3D" rel="nofollow" target="_blank">https://github.com/opentiny</a></strong>  <br/>TinyPro 源码：<strong><a href="https://link.segmentfault.com/?enc=xelcuEcOPium4ycJ%2FVqJbg%3D%3D.uOlM9CwlDpY0f4zg2rZXpBANu%2F%2BNb4JpyATWimeZRfBzV6jWtBizXo2tif0Z7CJM" rel="nofollow" target="_blank">https://github.com/opentiny/tiny-pro</a></strong>  <br/>欢迎进入代码仓库 Star🌟TinyEngine、TinyVue、TinyNG、TinyCLI、TinyEditor~<br/>如果你也想要共建，可以进入代码仓库，找到 good first issue标签，一起参与开源贡献~</p>]]></description></item><item>    <title><![CDATA[数字化正如何将汽车产业链编织成一张智能协同一张网？ 雨大王 ]]></title>    <link>https://segmentfault.com/a/1190000047553828</link>    <guid>https://segmentfault.com/a/1190000047553828</guid>    <pubDate>2026-01-20 16:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>一、 数字浪潮下的汽车产业：协同成为新焦点<br/>当前，全球正处于深刻变革的时代，以人工智能、大数据、物联网为代表的前沿技术以前所未有的力量驱动着各行各业的转型升级。在这场新工业革命浪潮中，汽车产业链数字化转型不仅是技术发展的必然趋势，更是重构行业竞争格局、提升整体效率与质量的核心引擎。<br/>汽车产业，以其产业链长、涉及面广、关联带动性强的特征，长期以来形成了相对固定的层级结构和线性运作模式。从上游的原材料供应、零部件制造，到中游的整车设计、生产装配，再到下游的销售服务、用户反馈，每个环节都像链条中的一个节点。然而，这种传统的线性结构在日益复杂的市场环境和技术迭代下，暴露出诸多痛点：信息流转不畅导致“信息孤岛”，数据滞后影响决策时效，上下游协同效率低下制约了整体发展速度。<br/>二、 数字化实现智能协同：从数据感知到闭环运作<br/>实现汽车产业链从线性链条向智能协同网络的转变，关键在于建立端到端的数字化协同能力。这不仅仅是提升算力和优化流程，更深层次的意义在于构筑新型的联结机制，实现生产透明化到决策智能化的“闭环能力”。<br/>数字化协同的核心在于打破节点间的壁垒，实现数据的互联互通与价值共享。以Geega工业互联网平台为例，它深度融合了工业AI智能体架构，致力于将汽车产业链的“链式结构”向更智能、更协同的“网状生态”进化。通过其平台提供的“汽车数字化工厂”、“汽车生产监控系统”和“智能预检+系统”等核心产品，能够对生产过程进行深度洞察，实现关键信息的动态追踪与智能预警。<br/>三、 实践与案例：编织智能协同网络的探索</p><ol><li>广域铭岛：构建汽车产业链数字基础<br/>作为汽车产业链数字化转型的积极践行者，其工业互联网平台专注于解决转型中的应用难题。该平台不仅提供通用的工业AI应用能力，还针对汽车特定场景开发了“汽车数字化工厂”、“汽车生产监控系统”以及“GECP企业碳管理平台”等解决方案。</li><li>EDI技术：供应链协同的基石<br/>像“盟接之桥”这样的专业EDI服务商，通过支持多种传输协议（如AS2、OFTP2）和国际标准报文集，帮助企业实现了预测、订单、发货通知、发票等关键数据的自动流转。这不仅大幅降低了人工操作带来的错误率和对账成本，更重要的是，它支撑了JIT模式下的稳定运行，让供应链各节点能够像一个整体一样协同运作。</li><li>一物一码：连接物理与数字世界的桥梁<br/>“一物一码”技术，即为每个物理对象（如车辆、零部件）赋予唯一数字标识，正在成为汽车产业链数字化的基础支撑。它不仅是产品追溯的辅助工具，更是串联全产业链数据、驱动智能协同的核心数字基座。<br/>如中选科技（HiMarking）的实践所示，通过“一物一码”与区块链等技术结合，可以构建产品的“出生-流转-装车”全生命周期档案。这使得车辆的每一个环节数据都能无缝关联，满足质量管控和合规要求。</li></ol>]]></description></item><item>    <title><![CDATA[LangGraph简介 AIAgent研究 ]]></title>    <link>https://segmentfault.com/a/1190000047553298</link>    <guid>https://segmentfault.com/a/1190000047553298</guid>    <pubDate>2026-01-20 15:05:05</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>一、概述</h2><p>LangGraph是LangChain团队开发的<strong>低级别编排框架</strong>，专为构建、管理和部署<strong>长时间运行的有状态AI代理</strong>设计，提供持久化执行、灵活控制流和全面内存管理功能，支持循环和条件分支，是开发复杂AI工作流的理想选择。</p><h3>1.1 核心特点</h3><ul><li><strong>持久执行</strong>：自动保存执行状态，支持故障恢复和断点续跑</li><li><strong>循环与分支</strong>：突破传统DAG限制，支持复杂的条件判断和循环逻辑</li><li><strong>全面内存</strong>：集成短期工作内存和长期持久内存，支持跨会话状态保留</li><li><strong>人机协作</strong>：内置中断机制，允许人工介入审批或修改代理行为</li><li><strong>流支持</strong>：实时输出执行结果，包括LLM的token级流式响应</li><li><strong>可观察性</strong>：无缝集成LangSmith，提供完整的执行轨迹和状态转换可视化</li></ul><h2>二、核心概念</h2><h3>2.1 状态(State)</h3><p><strong>共享内存</strong>，所有节点都可读写的全局数据结构，是代理的"工作记忆"。</p><ul><li>定义为Python的TypedDict或dataclass，包含代理需要的所有信息</li><li>存储原始数据而非格式化文本，确保不同节点可灵活使用</li><li><p>示例：</p><pre><code class="python">from typing import TypedDict
class AgentState(TypedDict):
    messages: list  # 对话消息列表
    search_results: list  # 搜索结果
    user_preferences: dict  # 用户偏好</code></pre></li></ul><h3>2.2 节点(Nodes)</h3><p><strong>图的基本执行单元</strong>，是接收状态并返回更新的函数。</p><ul><li><p>类型：</p><ul><li>LLM节点：调用语言模型进行文本理解或生成</li><li>工具节点：执行外部API调用、数据库查询等</li><li>数据处理节点：转换或分析数据</li><li>人工介入节点：暂停执行等待用户输入</li></ul></li><li><p>定义示例：</p><pre><code class="python">def greet(state: AgentState) -&gt; dict:
    return {"greeting": f"Hello, {state['user_name']}!"}</code></pre></li></ul><h3>2.3 边(Edges)</h3><p><strong>节点间的连接</strong>，定义执行流的路径。</p><ul><li><strong>普通边</strong>：始终执行固定路径</li><li><strong>条件边</strong>：根据状态决定下一步执行节点</li><li><p>定义示例：</p><pre><code class="python"># 普通边：从"start"到"greet"
graph.add_edge("start", "greet")

# 条件边：根据状态判断是执行"search"还是"reply"
def decide_next(state: AgentState) -&gt; str:
    return "search" if state["needs_info"] else "reply"
graph.add_conditional_edges("greet", decide_next)</code></pre></li></ul><h2>三、架构与工作原理</h2><h3>3.1 图结构</h3><p>LangGraph使用<strong>有向图模型</strong>表示代理工作流，包含：</p><ul><li><p><strong>特殊节点</strong>：</p><ul><li><code>START</code>：执行入口点</li><li><code>END</code>：执行结束点</li></ul></li><li><strong>执行模型</strong>：基于"消息传递"的迭代执行，以离散"超步骤"(super-step)推进</li></ul><h3>3.2 状态管理</h3><ul><li><strong>短期内存</strong>：线程范围内存，随执行结束自动清除</li><li><p><strong>长期内存</strong>：</p><ul><li>存储于独立的<code>Store</code>系统，支持跨会话、跨线程访问</li><li>使用<code>namespace</code>和<code>key</code>组织数据，类似文件系统的目录和文件名</li><li>支持多种存储后端：内存(开发)、PostgreSQL(生产)、Redis等</li></ul></li></ul><h3>3.3 执行流程</h3><ol><li>初始化状态并设置入口节点</li><li>执行入口节点，更新状态</li><li>根据边的类型(普通/条件)决定下一节点</li><li>重复直到到达<code>END</code>或达到递归限制(默认25步)</li><li>执行过程中自动保存检查点，支持故障恢复</li></ol><h2>四、存储方案</h2><p>LangGraph支持多种存储后端，满足不同场景需求：</p><table><thead><tr><th>存储类型</th><th>适用场景</th><th>特点</th><th>配置示例</th></tr></thead><tbody><tr><td><strong>InMemoryStore</strong></td><td>开发测试</td><td>速度快，无持久化</td><td><code>store = InMemoryStore()</code></td></tr><tr><td><strong>PostgresStore</strong></td><td>生产环境</td><td>高可靠，支持事务</td><td><code>store = PostgresStore("postgresql://user:pass@host/db")</code></td></tr><tr><td><strong>RedisStore</strong></td><td>分布式系统</td><td>高性能读写，适合缓存</td><td><code>store = RedisStore("redis://host:port")</code></td></tr><tr><td><strong>SQLiteStore</strong></td><td>轻量级应用</td><td>文件存储，无需服务器</td><td><code>store = SQLiteStore("langgraph.db")</code></td></tr></tbody></table><p><strong>长期记忆配置</strong>：</p><pre><code class="python">from langgraph.store.postgres import PostgresStore
from langgraph.backends import CompositeBackend, StateBackend, StoreBackend

# 配置复合存储：/memories/路径下的数据持久化，其他临时存储
def make_backend(runtime):
    return CompositeBackend(
        default=StateBackend(runtime),  # 临时存储
        routes={"/memories/": StoreBackend(runtime, PostgresStore("..."))}  # 持久存储
    )</code></pre><h2>五、使用方法</h2><h3>5.1 安装</h3><pre><code class="bash">pip install -U langgraph  # Python版本
npm install @langchain/langgraph  # JavaScript版本</code></pre><h3>5.2 基本使用步骤</h3><p><strong>1. 定义状态</strong>：</p><pre><code class="python">from typing import TypedDict
class ChatState(TypedDict):
    messages: list  # 对话消息列表</code></pre><p><strong>2. 构建图</strong>：</p><pre><code class="python">from langgraph.graph import StateGraph, START, END
from langchain.llms import OpenAI

# 初始化图
graph = StateGraph(ChatState)

# 定义节点：调用LLM生成回复
def call_llm(state: ChatState):
    llm = OpenAI(temperature=0)
    response = llm.invoke(state["messages"])
    return {"messages": state["messages"] + [response]}

# 添加节点和边
graph.add_node("generate_response", call_llm)
graph.add_edge(START, "generate_response")
graph.add_edge("generate_response", END)</code></pre><p><strong>3. 编译并执行</strong>：</p><pre><code class="python"># 编译为可执行应用
app = graph.compile()

# 执行
initial_state = {"messages": [{"role": "user", "content": "Hello!"}]}
final_state = app.invoke(initial_state)
print(final_state["messages"][-1]["content"])  # 输出AI回复</code></pre><h3>5.3 条件执行与循环</h3><pre><code class="python"># 定义条件函数：检查是否需要调用工具
def needs_tool(state: ChatState) -&gt; Literal["use_tool", "reply"]:
    last_message = state["messages"][-1]
    return "use_tool" if last_message.get("tool_calls") else "reply"

# 添加条件边
graph.add_conditional_edges("generate_response", needs_tool)

# 添加工具节点和循环边
graph.add_node("use_tool", tool_node)
graph.add_edge("use_tool", "generate_response")  # 循环回LLM节点</code></pre><h2>六、API参考</h2><h3>6.1 Graph API</h3><p><strong>核心类</strong>：</p><ul><li><strong>StateGraph</strong>：构建状态驱动的图，需传入状态类型</li><li><strong>MessageState</strong>：预定义的消息状态，适合聊天应用</li><li><strong>Checkpointer</strong>：管理执行状态的保存和恢复</li></ul><p><strong>关键方法</strong>：</p><ul><li><code>add_node(name, function, **kwargs)</code>：添加节点，支持重试策略等配置</li><li><code>add_edge(from_node, to_node)</code>：添加普通边</li><li><code>add_conditional_edges(from_node, condition_func)</code>：添加条件边</li><li><code>compile(checkpointer=None)</code>：编译图为可执行应用，支持持久化配置</li><li><code>invoke(input_state, config=None)</code>：执行图，返回最终状态</li></ul><h3>6.2 Functional API (简化版)</h3><p>提供更简洁的方式构建小型工作流：</p><pre><code class="python">from langgraph import entrypoint, task

@entrypoint
def my_agent():
    state = {"counter": 0}
    while state["counter"] &lt; 3:
        state = task(increment)(state)  # 调用任务函数
    return state

@task
def increment(state):
    state["counter"] += 1
    return state

result = my_agent()  # 执行</code></pre><h2>七、开发指南</h2><h3>7.1 构建步骤</h3><ol><li><strong>设计工作流</strong>：将问题分解为离散步骤，确定节点间依赖关系</li><li><strong>定义状态</strong>：确定需要在步骤间共享的数据</li><li><strong>实现节点</strong>：为每个步骤编写函数，处理输入状态并返回更新</li><li><strong>连接节点</strong>：使用边定义执行顺序，添加必要的条件判断</li><li><strong>添加内存</strong>：配置检查点和持久化，实现长期记忆</li><li><strong>测试与调试</strong>：使用LangSmith可视化执行过程，检查状态转换</li></ol><h3>7.2 最佳实践</h3><p><strong>状态设计</strong>：</p><ul><li>只存储必要信息，避免冗余</li><li>保持状态原始，在节点内格式化输出</li><li>使用描述性键名，提高可读性</li></ul><p><strong>节点设计</strong>：</p><ul><li>单一职责：每个节点专注做一件事</li><li>错误处理：为不同错误类型设置适当的处理策略(重试/回退/人工介入)</li><li>外部调用：将API调用、数据库操作等封装为独立节点，便于添加重试和监控</li></ul><p><strong>内存管理</strong>：</p><ul><li>短期数据存于状态，长期数据使用专用存储</li><li>定期清理过时数据，优化存储性能</li><li>使用命名空间组织长期数据，便于管理和查询</li></ul><h2>八、调试与监控</h2><h3>8.1 使用LangSmith集成</h3><p>LangGraph无缝集成LangSmith，提供全面的可观察性：</p><pre><code class="python"># 启用LangSmith追踪
import os
os.environ["LANGSMITH_TRACING"] = "true"
os.environ["LANGSMITH_API_KEY"] = "..."

# 编译图时启用追踪
app = graph.compile(checkpointer=checkpointer, trace=True)</code></pre><p><strong>监控功能</strong>：</p><ul><li>执行轨迹可视化：查看完整执行路径和状态变化</li><li>性能分析：测量各节点执行时间，识别瓶颈</li><li>异常检测：自动标记执行错误和异常路径</li><li>交互式调试：在LangSmith Studio中检查中间状态</li></ul><h3>8.2 本地调试技巧</h3><ul><li><strong>断点打印</strong>：在节点函数中添加<code>print</code>语句，输出关键状态</li><li><strong>分步执行</strong>：使用<code>graph.invoke</code>并传入小输入，逐步验证每个节点</li><li><p><strong>错误处理</strong>：为节点添加详细的异常捕获和日志记录：</p><pre><code class="python">def safe_node(state):
    try:
        # 正常逻辑
    except Exception as e:
        return {"error": str(e)}  # 返回错误信息而非崩溃</code></pre></li></ul><h2>九、部署方案</h2><h3>9.1 自托管部署</h3><p><strong>使用Docker</strong>：</p><pre><code class="bash"># 安装CLI
pip install -U langgraph-cli

# 构建镜像
langgraph build --name my-agent .

# 运行
docker run -p 8124:8124 my-agent</code></pre><p><strong>生产配置建议</strong>：</p><ul><li>使用PostgreSQL作为存储后端，确保数据持久化</li><li>配置数据加密，保护敏感信息</li><li>设置适当的资源限制，防止滥用</li><li>使用负载均衡和水平扩展，提高吞吐量</li></ul><h3>9.2 LangSmith Cloud (原LangGraph Platform)</h3><p>提供一键式云部署：</p><ul><li><strong>Lite版本</strong>：免费使用，每年限制100万节点执行</li><li><strong>Enterprise版本</strong>：全功能支持，适合大规模生产环境</li></ul><p><strong>优势</strong>：</p><ul><li>自动扩展和高可用性</li><li>内置监控和告警系统</li><li>开箱即用的安全与合规功能</li><li>与LangSmith无缝集成，提供完整的可观察性</li></ul><h2>十、完整示例：构建天气查询代理</h2><pre><code class="python"># 1. 安装依赖
pip install langgraph langchain openai

# 2. 导入必要模块
from typing import TypedDict, Literal
from langchain.llms import OpenAI
from langchain_core.messages import HumanMessage, AIMessage
from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.memory import MemorySaver  # 内存检查点

# 3. 定义状态
class WeatherAgentState(TypedDict):
    messages: list  # 对话消息
    location: str  # 查询的城市
    weather_info: str  # 天气信息

# 4. 定义工具函数
def get_weather(location: str) -&gt; str:
    """简化的天气查询API"""
    if location.lower() == "sf":
        return "60°F, foggy"
    elif location.lower() == "ny":
        return "90°F, sunny"
    else:
        return "Weather data not available for this location"

# 5. 定义节点
def initial_prompt(state: WeatherAgentState) -&gt; dict:
    """询问用户想查询哪个城市的天气"""
    llm = OpenAI(temperature=0)
    response = llm.invoke([HumanMessage(content="Which city's weather would you like to check?")])
    return {"messages": [response]}

def parse_location(state: WeatherAgentState) -&gt; dict:
    """从用户消息中提取城市名"""
    last_message = state["messages"][-1]
    location = last_message.content.strip().lower()
    return {"location": location, "messages": state["messages"] + [AIMessage(content=f"Checking weather for {location}...")]}

def get_weather_info(state: WeatherAgentState) -&gt; dict:
    """调用天气工具获取信息"""
    weather = get_weather(state["location"])
    return {"weather_info": weather, "messages": state["messages"] + [AIMessage(content=f"Weather in {state['location']}: {weather}")]}

# 6. 构建图
graph = StateGraph(WeatherAgentState)

# 添加节点
graph.add_node("initial_prompt", initial_prompt)
graph.add_node("parse_location", parse_location)
graph.add_node("get_weather_info", get_weather_info)

# 添加边定义执行流
graph.add_edge(START, "initial_prompt")
graph.add_edge("initial_prompt", "parse_location")
graph.add_edge("parse_location", "get_weather_info")
graph.add_edge("get_weather_info", END)

# 7. 添加内存支持
checkpointer = MemorySaver()  # 使用内存检查点保存状态
app = graph.compile(checkpointer=checkpointer)

# 8. 执行代理
first_run = app.invoke({})
print("First run output:")
for msg in first_run["messages"]:
    print(f"{msg['role'].capitalize()}: {msg['content']}")

print("\nSecond run (with state persistence):")
# 第二次执行会保留之前的对话状态
second_run = app.invoke({})
for msg in second_run["messages"]:
    print(f"{msg['role'].capitalize()}: {msg['content']}")</code></pre><h2>十一、总结</h2><p>LangGraph是构建复杂AI代理的强大框架，通过状态驱动的图结构，提供了持久执行、灵活控制流和全面内存管理能力。使用LangGraph，开发者可以轻松构建具有记忆、能够处理复杂逻辑的AI代理，适用于客服、研究助手、自动化工作流等多种场景。</p>]]></description></item>  </channel></rss>