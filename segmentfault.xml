<?xml version="1.0" encoding="UTF-8"?><rss version="2.0">  <channel>      <title>SegmentFault - 最近文章</title>      <link>https://segmentfault.com/blogs/newest</link>      <description>SegmentFault 思否</description>      <generator>python segmentfault.py @Pi20</generator>      <item>    <title><![CDATA[大模型语音呼叫智能体「云蝠智能」完成 A]]></title>    <link>https://segmentfault.com/a/1190000047406583</link>    <guid>https://segmentfault.com/a/1190000047406583</guid>    <pubDate>2025-11-18 09:04:12</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>云蝠智能现已完成了由金沙江创业投资领投的 A+ 轮融资，鞍羽资本担任独家财务顾问。</p><p>作为国内第一批直接采用大模型从事智能语音客服的企业，云蝠智能其全栈自研的「神鹤大模型」支撑着语音智能体在 3-5 分钟内快速构建上下文对话能力。</p><p>云蝠智能不仅是「超音速计划 2025·Voice Agent Camp」的优秀学员，更在刚结束的 RTE 2025 年度 Demo Day 中脱颖而出，位列三强。</p><p>RTE 开发者社区作为云蝠智能在创业征途中的重要陪跑者和成长伙伴，一路见证了其技术产品的迭代升级与融资里程碑。</p><p>RTE 开发者社区将一如既往地关注 Voice Agent 及语音驱动的下一代人机交互界面，并期待更多优秀项目加入社区，携手共建，加速成长。</p><hr/><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406585" alt="" title=""/></p><p>作为国内第一批直接采用大模型从事智能语音客服的企业，云蝠智能其全栈自研的“神鹤大模型”支撑着语音智能体在3-5分钟内快速构建上下文对话能力。云蝠智能现已完成了由 <strong>金沙江创业投资</strong> 领投的 A+ 轮融资，<strong>鞍羽资本</strong> 担任独家财务顾问。</p><p><strong>本轮融资主要用于以下的产品迭代：</strong></p><ol><li>加强语音智能体在结果及服务的业务场景落地，加速呼入、不良资产处置等产品的市场化及规模化落地。</li><li>加速 VoiceAgent 的产品优化，构建自动化 FDE 前线部署工程师，实现自动化交付。</li><li>优化智能体工程，将对话延迟稳定压缩到 1s，实现类人级无感情绪理解和互动。</li></ol><h2>VoiceAgent 在呼叫领域的探索者</h2><p>云蝠智能成立于 2018 年，是 VoiceAgent 领域不多的从 AI1.0 周期全面转型模型呼叫的技术企业。成立之初的命名就以声音为唯一互动的动物“蝙蝠”作为品牌，构建对话智能服务。历经关键词、正则表达式、NLP、大模型理解、大模型生成等诸多技术周期，到现在全力冲刺语音能力在呼叫领域的全面智能化。</p><p>云蝠智能的创始人魏佳星毕业于江南大学，常年从事语音智能体、对话的构建开发和产品设计。作为国内不多长期关注、垂直在语音智能领域的创始人，他表示：</p><p>“在 2018 年创办云蝠智能的时候，我就相信这是一个常识：即终将出现一个达到人类能力的对话智能体，而我为这件事情做好了等待十年的准备。LLM 能力极大的提高了我实现个人理想的可能性。声音，终将无处不在。”</p><h2>关于云蝠智能</h2><p>“云蝠智能”是一款 AI 原生的大模型语音智能体，我们为企业提供AICC大模型呼叫中心，在ChatBOT和CRM基础上提供包括语音智能体，产品能力包括了大模型语音外呼、智能呼入、网页实时语音交互 sdk 及 api我们由来自阿里巴巴等公司优秀的开发者组成，曾经获得华为云开发者大赛、讯飞开发者大赛冠军。</p><p>这款产品可以在呼入工单建立、投诉处理及需求跟进等场景完全取代人工客服，在会员回访、客户召回场景取代大多数客服。</p><p>当前我们的月均AI 人机通话量为 4500 万通电话，服务于 3 万家终端企业。在呼入场景中，模型可以实现对人的80% 的取代，平均对话时长 171 秒。</p><p><strong>云蝠的技术特点如下：</strong></p><p><strong>超低延迟</strong></p><p>基于自研的暴风引擎、及多模型语音加速方案，和对模型的零信任构建的模型主备机制，云蝠智能可以在基于公有云 token 调用的情况下，将对话延迟稳定压缩在 1～1.2s 之间。</p><p><strong>更拟人</strong></p><p>基于对呼叫声优的 SFT 微调，并结合大模型技术，实现 50 国语音，超多方言的小样本克隆音合成，并对语音中数值、符号等情绪进行优化。请可能模拟人类在电话中的情感状态。</p><p><strong>幻觉控制</strong></p><p>自创时空注意力机制，结合 tool 的调用，构建模型、注意力、tool 的三层组合，实现速度和对话体验互斥的调和架构。</p><p><strong>高并发处理</strong></p><p>基于 7 年FreeSwitch 的开发，实现全面的通信模块自主化，可以实现超高并发能力的稳定控制和确保通话稳定。</p><h2><strong>云蝠智能伙伴招募</strong></h2><p>作为国内见证了呼叫智能体从 1.0 到 2.0延边的创新者，云蝠智能期待和更多合作伙伴共创，找到模型能力在呼叫、语音中可以实现结果交付的业务场景。</p><p>我们期待来自文本客服、模型厂家、电信运营商、PBX 公司、SCRM 及 CRM 数据拥有者等等更多垂直地区、垂直行业的合作伙伴一起合作，基于 OEM+iframe 的形式，快速为您的系统部署语音智能体，让无法说话的系统开口，主动和被动的联络用户！</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406586" alt="" title="" loading="lazy"/></p><p>云蝠智能VoiceAgent发布会现场</p><p><strong>投资人寄语：</strong></p><p>种子轮投资人<strong>奇绩创坛</strong>合伙人<strong>曹勖文</strong></p><blockquote>“我们非常看好语音Agent在垂直场景的规模化落地。云蝠智能在语音与AI长期深耕，技术栈扎实，产品贴近一线；团队战斗力强、执行快、能在复杂场景中快速打穿并复制。伴随VoiceAgent赛道进入商业化加速期，我们相信云蝠将把成本、效率与体验的提升转化为持续增长与行业影响力。”</blockquote><p>作为早期投资人，<strong>御势资本</strong>非常看好云蝠智能与魏总在 AI赋能产业升级中帮助中国数千万企业抓住 AI 带来的机遇，让企业运营更高效</p><p>A 轮投资人御势资本主管合伙人 <strong>邓明生</strong> 表示：</p><blockquote><p>“云蝠智能作为 Voice Agent 领域的领先者，在短短几年搭建了完善的客户服务体系，目前已经服务了数万家企业客户，沉淀了大量的用户商业对话行为数据。创始人魏佳星魏总具有非常敏锐的技术洞察，在企业管理中精益求精，搭建强大的技术与运营团队，注重客户服务体验，真正为客户带来了销售额的显著增长。</p><p>大模型技术带来的 Voice Agent 在 AI 销售和 AI 客服，让企业不仅可以快速扩展销售和服务网络，更是让每一位客户都能获得金牌销售与金牌客服的优质体验，从而实现从“人力密集型”的线性增长向“Ai 驱动型”的指数增长，这是万亿级人力资本市场的颠覆性变革。"</p></blockquote><p>A+轮投资人<strong>金沙江创业投资</strong>基金主管合伙人<strong>朱啸虎</strong></p><blockquote>我们认为语音 Agent 将成为企业级 AI 最快进入规模化应用的方向之一。云蝠在智能呼叫领域深耕多年，建立了扎实的场景理解和数据基础，并率先推出可商用的模型呼叫产品。凭借领先的产品力和迭代速度，云蝠在呼入、销售、客服、不良资产处置等关键场景展现出快速渗透和复制能力。我们相信云蝠将成为新一代 Voice Agent 企业的领跑者。”</blockquote><p>本轮融资财务顾问 <strong>鞍羽资本合伙人 沈海丰</strong></p><blockquote>“云蝠团队有着行业内最深的产品及技术认知和积累，团队从第一天取名“云蝠”起就一直在VoiceAgent赛道上狂奔，致力于成为语音交互方向最好的公司、打造真人实时语音交互体验。几年来经历了数次的产品及技术迭代，公司持续获得各行各业数千家客户的正向反馈，业务连续多年高质量增长，取得了优异的业绩表现。鞍羽资本见证了云蝠在佳星的带领下，从技术攻坚到生态落地的完整蜕变，也将一如既往支持云蝠公司的长期发展。”</blockquote><p>本轮融资后，云蝠智能同步发布 VoiceAgent2.0 版本，您也可以直接访问：</p><p>https\://www.telrobot.top/</p><p>注册体验云蝠智能 VoiceAgent2.0 最新特性！</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406587" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047406588" alt="" title="" loading="lazy"/></p><p><a href="https://link.segmentfault.com/?enc=lk%2Fxmy3T3bpUQ%2BewggB8HA%3D%3D.shJ28YFu1l%2F%2BCaeVtKCkTK512%2F%2Fwy6efnc3diuIsccc%3D" rel="nofollow" target="_blank">阅读更多 Voice Agent 学习笔记：了解最懂 AI 语音的头脑都在思考什么</a></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406589" alt="" title="" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[RustRover 2025.2.4 1]]></title>    <link>https://segmentfault.com/a/1190000047406607</link>    <guid>https://segmentfault.com/a/1190000047406607</guid>    <pubDate>2025-11-18 09:03:20</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <ul><li>2025-11-18亲测</li><li>支持最新版本2025.2.4</li><li>支持Windows、MAC、Linux<br/><img width="647" height="454" referrerpolicy="no-referrer" src="/img/bVdm4MP" alt="rust.png" title="rust.png"/></li></ul><h2>一 安装</h2><p>官网下载：<a href="https://link.segmentfault.com/?enc=imMrdhEwxLVoB4m3fyvBDA%3D%3D.Ox8%2BWU87x%2FV6Ktt0cbms8BoHBYdFo4e%2FSXV%2FFrPgaO30504sY%2F3YHYJfOBkvHjBJ" rel="nofollow" target="_blank">https://www.jetbrains.com/zh-cn/rust/</a><br/>根据提示安装</p><h2>二 授权说明</h2><p><img width="723" height="265" referrerpolicy="no-referrer" src="https://segmentfault.com/img/bVdmZkU" alt="图片" title="图片" loading="lazy"/><br/>回复 《rust》获取<br/>新版本安装后不提示授权，需要手动处理</p><h2>三 使用</h2><p>打开自己的项目，配置环境，开始开发<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdm4MQ" alt="image.png" title="image.png" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[PandaCoder：我的个人开发者工具]]></title>    <link>https://segmentfault.com/a/1190000047406613</link>    <guid>https://segmentfault.com/a/1190000047406613</guid>    <pubDate>2025-11-18 09:02:50</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>引言：从个人项目到开发者工具的转变</h2><p>在技术领域，我常常思考一个问题：什么样的工具才能真正帮助开发者？我意识到真正的价值不在于功能的数量，而在于这些功能是否真正解决了用户的痛点。作为PandaCoder的独立开发者，我的核心理念正是建立在这一认知之上——<strong>与其堆砌功能，不如倾听用户的声音</strong>。</p><h3>工具的本质</h3><p>正如纳瓦尔所言："工具应该为你工作，而不是你为工具工作。"我设计PandaCoder的初衷是创建一个能够真正理解开发者需求的智能助手，而不是又一个需要复杂配置的负担。</p><h2>用户反馈：产品进化的核心驱动力</h2><h3>为什么建议比打赏更重要？</h3><p>在PandaCoder的设计中，我刻意将"✍️ 插件的建议"功能置于"☕️ 请作者喝杯"之前。这不是偶然，而是基于一个深刻的洞察：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406615" alt="" title=""/></p><p><strong>用户的建议是产品进化的燃料，而打赏只是这个过程的副产品。</strong></p><p>当开发者愿意花时间提供反馈时，实际上是在投资这个工具的未来。这种投资远比金钱更有价值，因为它包含了真实的用户体验和需求洞察。</p><h3>反馈系统的设计哲学</h3><p>我设计的反馈系统采用了精心设计的交互体验：</p><ul><li><strong>智能限流机制</strong>：每日6次反馈限制，确保每一条建议都是经过深思熟虑的</li><li><strong>分类反馈</strong>：功能建议、Bug反馈、使用体验、其他，让反馈更有针对性</li><li><strong>即时确认</strong>：用户提交后立即收到确认，建立反馈闭环</li></ul><p>这种设计体现了史蒂文·巴特利特强调的"用户体验即品牌"理念。</p><h2>功能演进：从用户需求出发</h2><h3>中文编程助手的诞生</h3><p>最初的PandaCoder只是一个简单的翻译工具。但通过用户反馈，我发现中国开发者真正需要的是<strong>从中文思维到英文代码的顺畅转换</strong>，而不仅仅是文字翻译。</p><p>用户建议促使我开发了：</p><ul><li>智能命名转换（小驼峰、大驼峰、大写带下划线）</li><li>中文类名自动生成</li><li>多级翻译引擎（国内大模型 &gt; Google翻译 &gt; 百度翻译）</li></ul><h3>Jenkins Pipeline支持的进化</h3><p>最初只是语法高亮，但用户反馈揭示了更深层次的需求：开发者在编写Pipeline时需要<strong>智能补全、环境变量管理、文档支持</strong>。</p><p>这些功能不是凭空想象的，而是来自真实用户的痛点反馈。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406616" alt="" title="" loading="lazy"/></p><h3>SpringBoot配置的可视化</h3><p>通过用户建议，我实现了技术栈的智能识别和可视化显示。现在开发者打开配置文件时，能够直观看到使用的技术组件，大大提升了开发效率。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406617" alt="" title="" loading="lazy"/></p><h2>数据驱动的产品迭代</h2><h3>Git统计分析功能</h3><p>用户反馈显示，团队需要更好的代码协作洞察。我开发了：</p><ul><li>多维度代码统计</li><li>可视化图表展示</li><li>自动邮件报告系统</li></ul><p>这些功能帮助团队管理者了解开发进度，识别瓶颈，优化协作流程。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406618" alt="" title="" loading="lazy"/></p><h3>实时监控体系的建立</h3><p>基于用户对调试效率的需求，我构建了完整的监控体系：</p><ul><li>Elasticsearch DSL监控</li><li>SQL执行监控</li><li>API调用链追踪</li></ul><p>这些功能让开发者能够实时了解应用运行状态，快速定位问题。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406619" alt="" title="" loading="lazy"/></p><h2>社区驱动的技术决策</h2><h3>翻译引擎的选择</h3><p>最初我只支持百度翻译，但用户反馈显示：</p><ul><li>国内大模型在某些场景下翻译质量更高</li><li>Google翻译在国际化项目中有独特优势</li><li>需要多引擎备用确保服务稳定性</li></ul><p>这些反馈促使我建立了三级翻译引擎系统。</p><h3>AI助手功能的扩展</h3><p>用户建议让我意识到：开发者需要的不只是翻译，还有<strong>代码审查、技术咨询、学习辅导</strong>等AI能力。</p><p>这促使我集成了多种AI模型，包括OpenAI、Ollama本地部署、国内大模型等。</p><h2>技术实现背后的思考</h2><h3>性能与用户体验的平衡</h3><p>在实现功能时，我始终遵循纳瓦尔的建议："在技术决策中，简单性往往比复杂性更有价值。"</p><p>例如：</p><ul><li>使用ConcurrentHashMap确保线程安全</li><li>实现延迟加载优化性能</li><li>合理的缓存策略提升响应速度</li></ul><h3>可扩展性设计</h3><p>我采用模块化设计，确保新功能能够无缝集成。这种设计理念来源于用户对未来扩展性的需求预期。</p><h2>用户参与的价值创造</h2><h3>从使用者到共建者</h3><p>PandaCoder的成功案例证明：<strong>当用户参与产品设计时，他们从被动的使用者转变为积极的共建者。</strong></p><p>这种转变带来的价值是双向的：</p><ul><li>用户获得更符合需求的工具</li><li>我获得真实的用户洞察</li><li>整个生态实现良性循环</li></ul><h3>反馈的乘数效应</h3><p>一个用户的建议可能影响数千名其他用户的使用体验。这种乘数效应是开源社区最强大的力量之一。</p><h2>未来展望：基于用户需求的持续进化</h2><h3>短期规划</h3><p>基于当前用户反馈，我计划：</p><ul><li>增强AI助手功能（代码生成、重构建议）</li><li>优化Git统计图表样式</li><li>改进邮件模板自定义功能</li></ul><h3>中长期愿景</h3><p>用户建议指引我向更智能化的方向发展：</p><ul><li>代码智能分析与建议系统</li><li>项目健康度评估报告</li><li>团队协作效率分析工具</li></ul><h2>结语：共建更好的开发者工具</h2><p>PandaCoder的成长历程印证了一个重要观点：<strong>最好的产品功能来源于真实用户的需求。</strong></p><p>我相信，技术工具的价值不在于它拥有多少功能，而在于它是否真正解决了开发者的问题。而了解这些问题的唯一途径，就是倾听用户的声音。</p><p>正如史蒂文·巴特利特所说："成功的企业不是那些拥有最好产品的企业，而是那些最了解客户需求的企业。"</p><p>我邀请每一位开发者参与PandaCoder的进化之旅。您的每一个建议都可能成为下一个重要功能的灵感来源。</p><hr/><p><strong>参与方式：</strong></p><ul><li>在IDE中点击"✍️ 插件的建议"提交反馈</li><li>通过GitHub Issues参与讨论</li><li>关注公众号"舒一笑的架构笔记"获取最新动态</li></ul><p><strong>技术博客信息：</strong></p><ul><li>主站：www.poeticcoder.com</li><li>备用站：www.shuyixiao.top</li><li>详细功能介绍：<a href="https://link.segmentfault.com/?enc=6uQabN7%2BIqYoXK9rLRPHmw%3D%3D.XLjNt9rZ0q92aHkIAN6Cd3t6T61pgIywowlcYdggdiWoLyoiYmvA3UyR%2B%2BYZ5HdxU%2Fla2iFFX7P%2FMyfOmPBsfw%3D%3D" rel="nofollow" target="_blank">PandaCoder完整功能介绍</a></li></ul><hr/><p><em>舒一笑不秃头，生成式AI应用工程师(高级)认证，阿里云博客专家，专注于企业级Java开发和AI应用开发。</em></p>]]></description></item><item>    <title><![CDATA[为什么内网IP也需要SSL证书 冷冷的炒]]></title>    <link>https://segmentfault.com/a/1190000047406632</link>    <guid>https://segmentfault.com/a/1190000047406632</guid>    <pubDate>2025-11-18 09:01:58</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>为什么内网IP也需要SSL证书？在很多人看来，SSL证书主要是用于互联网上的网站，比如电商平台、银行网站等，需要保护用户的敏感数据。但你可能不知道，内网IP（如192.168.1.1、10.0.0.1等）同样需要SSL证书。</p><p><strong>1. 防止内网数据被窃听</strong></p><p>即使你的服务只在局域网内运行，数据仍然可能被监听。例如：如果公司Wi-Fi被入侵，黑客可以嗅探内部HTTP流量，获取账号密码、数据库信息等。内部员工可能利用抓包工具（如Wireshark）查看未加密的通信内容。</p><p><strong>SSL证书的作用</strong>：通过HTTPS加密，确保数据在传输过程中无法被窃取或篡改。</p><h4>内网IP地址SSL证书<a href="https://link.segmentfault.com/?enc=DhBGHkDhj4eBtDv5rbsrhA%3D%3D.M%2FcrUq7JUiTjmtzV7jyPC6DHyVqBjj3IqheILTUFvUmOdaPr2FIIxQLYXQ7t8%2BaRgZMvBgwln9rONLjFWM6C4%2BAHQkTZf1LI4NBiDg4TNsM%3D" rel="nofollow" target="_blank">申请入口</a>直接访问JoySSL注册一个账号，记得填写注册码230973获取免费安装服务</h4><p><img width="688" height="353" referrerpolicy="no-referrer" src="/img/bVdm1Ae" alt="" title=""/><br/><strong>2. 避免浏览器“不安全”警告</strong></p><p>现代浏览器（如Chrome、Edge）会对所有HTTP网站标记为“不安全”，即使是内网IP也不例外。这会导致：员工访问内部系统时频繁看到警告，影响使用体验。某些浏览器可能阻止访问HTTP网站，导致内部工具无法正常使用。<br/><strong>SSL证书的解决方案</strong>：部署证书后，内网服务将以HTTPS运行，浏览器不再提示“不安全”。</p><p><strong>3. 满足安全合规要求</strong></p><p>许多行业（如金融、医疗、政府）对数据安全有严格要求，例如：GDPR（欧盟通用数据保护条例） ：要求企业保护用户和员工的隐私数据。等保2.0（中国网络安全等级保护） ：明确要求内部系统采用加密通信。SSL证书的合规价值：帮助企业在审计时证明内部通信符合安全标准。</p><p><strong>4. 防止中间人攻击（MITM）</strong></p><p>在内网环境中，攻击者可能伪装成网关或服务器，进行中间人攻击（MITM），例如：伪造一个假的登录页面，诱导员工输入账号密码。</p><p>篡改内部API请求，导致数据泄露或系统故障。SSL证书的防护机制：HTTPS通过数字证书验证服务器身份，确保通信双方不被冒充。</p><p>如何为内网IP申请SSL证书？虽然公共通常不直接为内网IP签发证书，但仍有几种解决方案：私有CA（企业级方案） ：在企业内部搭建CA，统一签发和管理证书。特殊CA支持：部分CA（如JoySSL）提供内网IP证书，需付费申请。</p><p><strong>总结：内网IP使用SSL证书并非多此一举，而是提升安全性、改善用户体验、满足合规要求的重要措施。无论是企业OA系统、内部数据库还是开发测试环境，HTTPS加密都能有效降低风险。</strong></p>]]></description></item><item>    <title><![CDATA[剑指offer-38、⼆叉树的深度 程序]]></title>    <link>https://segmentfault.com/a/1190000047402152</link>    <guid>https://segmentfault.com/a/1190000047402152</guid>    <pubDate>2025-11-18 09:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>题⽬描述</h2><p>输⼊⼀棵⼆叉树，求该树的深度。从根结点到叶结点依次经过的结点（含根、叶结点）形成树的⼀条路径，最⻓路径的⻓度为树的深度。</p><p>示例1<br/>输⼊：{1,2,3,4,5,#,6,#,#,7}<br/>返回值：4</p><h2>思路及解答</h2><p>声明：这⾥的输⼊是⼀个数的根节点，也就是从根节点，我们就可以获取到树的所有节点，⽽类似数组的表达⽅式 {1,2,3,4,5,#,6,#,#,7} ，则是按照层次来放的。(⽐如这个树就是4层)</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047402154" alt="" title=""/></p><h3>递归</h3><p>第⼀种⽅法⽐较容易想到，对于任意⼀个节点 node ⽽⾔，我要想知道当前 node 节点（包括当前节点）的深度，肯定得求当前节点的左边节点（设为 left ）的深度 leftDeepth ，以及获取右节点（设为 right ）的深度 rightDeepth ，然后求两者最⼤+1（ Max{leftDeepth,rightDeepth}+1 ），就是当前节点的深度。</p><p>思路：二叉树的深度 = max(左子树深度, 右子树深度) + 1</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047402155" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047402156" alt="" title="" loading="lazy"/></p><p>⽽递归中⽐较重要的⼀点，是结束条件。在这道题中，如果⼀个节点为 null ，就结束，并且当前节点的深度是 0 。代码超级⽆敌短：</p><pre><code class="java">public class Solution {
     public int TreeDepth(TreeNode root) {
         if(root==null) return 0;
         return Math.max(TreeDepth(root.left),TreeDepth(root.right))+1;
     }
}</code></pre><p>以上解法要是看不明白，可以看详细点的：</p><pre><code class="java">public class Solution {
    public int TreeDepth(TreeNode root) {
        // 递归终止条件：空节点深度为0
        if (root == null) {
            return 0;
        }
        
        // 递归计算左子树深度
        int leftDepth = maxDepth(root.left);
        // 递归计算右子树深度
        int rightDepth = maxDepth(root.right);
        
        // 当前树深度 = 左右子树最大深度 + 1（当前节点）
        return Math.max(leftDepth, rightDepth) + 1;
    }
}</code></pre><ul><li><strong>时间复杂度</strong>：O(n)，需要访问每个节点一次</li><li><strong>空间复杂度</strong>：O(h)，递归栈深度等于树高，最坏情况（链表）为O(n)</li></ul><h3>迭代遍历</h3><p>思路是如果树的根节点不为空，则将根节点放进队列中。也就是，每遍历一层，深度加1，直到遍历完所有层</p><p>设置深度 deep 为0。使⽤ while 循环，只要队列不为空，则执⾏下⾯操作：</p><ol><li>获取队列的⼤⼩ size 。</li><li>依次取出队列的前 size 个元素，如果该元素的左边节点不为空，则将左边节点放进队列，如果该元素的右边节点不为空，则将该元素的右边节点放进队列。</li><li>层次 deep+1</li></ol><pre><code class="java">public class Solution {
    public int TreeDepth(TreeNode root) {
        if (root == null) return 0;
        
        Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;();
        queue.offer(root);
        int depth = 0;
        
        while (!queue.isEmpty()) {
            // 当前层的节点个数
            int levelSize = queue.size();
            
            // 遍历当前层的所有节点
            for (int i = 0; i &lt; levelSize; i++) {
                TreeNode currentNode = queue.poll();
                
                // 将下一层节点加入队列
                if (currentNode.left != null) {
                    queue.offer(currentNode.left);
                }
                if (currentNode.right != null) {
                    queue.offer(currentNode.right);
                }
            }
            
            // 完成一层遍历，深度加1
            depth++;
        }
        
        return depth;
    }
}</code></pre><ul><li>时间复杂度为：O(n)，所有的节点需要进⼊队列，再出队列</li><li>空间复杂度：O(n),借助了额外的队列空间。</li></ul>]]></description></item><item>    <title><![CDATA[从「跨模态思维链」到「物理 AI 数据闭]]></title>    <link>https://segmentfault.com/a/1190000047406538</link>    <guid>https://segmentfault.com/a/1190000047406538</guid>    <pubDate>2025-11-18 08:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406540" alt="" title=""/></p><p>在本届 RTE2025 大会上，来自产业界和学术界的多位专家深入探讨了从 AI 视频生成到可实时交互的世界模型，从被动响应到主动感知与交互，再到下一代多模态大模型的设计与构建——由<strong>商汤科技</strong> 和 <strong>RTE 开发者社区</strong> 联合出品的 <strong>「多模态技术专场」</strong> 将展望一个由实时多模态 AI 驱动的未来。</p><p>商汤科技执行商务总监<strong>李星冶</strong>、RTE 开发者社区联合主理人和 OpenQ 联合创始人<strong>林旅强</strong>、商汤科技多模态交互产品负责人<strong>路少卿</strong>、加拿大滑铁卢大学访问学者<strong>冯睿蠡</strong>、阶跃星辰语音和 AIGC 算法负责人<strong>俞刚</strong>、和众科技 HooRii Technology Co-Founder\&amp;CTO <strong>刘一聪</strong>、灵宇宙创始人<strong>顾嘉唯</strong>、Agora 的 Principal Product Manager <strong>Monica Chen</strong>、拽米科技（DraMa.i）创始人<strong>何竞飞</strong>以及 Memories.ai 算法负责人 <strong>Jerrick</strong> 分享了他们在各自领域的实践经验和独到见解。</p><hr/><p>商汤科技执行商务总监李星冶和 RTE 开发者社区的联合主理人，OpenQ 联合创始人林旅强分别主持了活动主题分享和圆桌讨论环节。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406541" alt="" title="" loading="lazy"/></p><h2>路少卿：从文本推理到多模态交互：为什么是必经之路？</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406542" alt="" title="" loading="lazy"/></p><p>商汤科技多模态交互产品负责人路少卿发现，即使是市面上最新的模型，在处理涉及视觉理解、空间认知和复杂图文推理的任务时，也表现出明显的缺失。并提出了商汤未来必须攻克的方向——从文本推理到原生融合的统一多模态大模型。<strong>目前的多模态模型依然停留在 VLP（视觉语言预训练）+ LLM的 Merge 阶段（即 VQA 任务），缺乏真正原生融合后产生的跨模态思维链推理能力。</strong></p><p>商汤的核心路径是追求统一深度的多模态大模型，目标是实现理解与生成融合统一，并激活类人的多模态思维链能力。针对图文交错的推理难题，商汤构建了<strong>专门的数据生产管线和强化学习后训练机制</strong>，用于提升模型在需要多次图像局部信息确认和推理的任务上的能力。同时，商汤重构了 DiT 网络，<strong>实现了单人人像视频的生成和语音驱动</strong>。通过引入音频驱动的 Attention 模块，成功整合了人像生成、实时驱动和多模态实时交互的完整能力。商汤还<strong>在文本对话中掺杂了图片域训练</strong>，使端到端融合模型能够实现文本域推理，并结合对话历史中的图片域推理和交互，大幅提升了上下文记忆能力。</p><p>路少卿也提到了业界的最新突破，如 OpenAI GPT-4o 实现了复杂的 Prompt 与图像生成的完全对齐，以及 Google Nano-banana 在跨多角色 ID 保持上的突破，都是「理解与生成融合统一」的最新信号。<strong>模型正从传统的被动接受指令转向具备环境感知、主动推理和主动规划的能力</strong> 。他以一个案例演示：模型感知到用户「有点渴」，能识别到环境中的饮品和食物，主动发起交互反馈。他认为，技术发展很快，但远未到收敛状态，未来将聚焦于图文交错推理数据、视频理解和 Agentic RL（强化学习）等六个方向，最终实现统一的多模态表征的理解和生成的统一。</p><p>「未来，AI 将从单纯的问答机器转向自主规划、主动服务的方向发展。」</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406543" alt="" title="" loading="lazy"/></p><p><strong>路少卿</strong> </p><p>商汤科技多模态交互产品负责人</p><h2>冯睿蠡：Neural Interactive Simulation as World Foundation Models</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406544" alt="" title="" loading="lazy"/></p><p>加拿大滑铁卢大学访问学者冯睿蠡认为，<strong>通往更强智能的关键在于一个「Playground」，一个低成本、实时交互的世界模型（World Foundation Model）</strong>。他以「黑客帝国」为代号，展示了如何让 AI 能在虚拟世界中不断「玩耍」和学习。当 GPT 看到一张脏桌子并制定了「把书拿走」的 Plan 后，它并不知道书底下可能还藏着油污和划痕。他指出，<strong>目前 AI 缺失的正是「在环境中检验 Policy 的能力」</strong>。</p><p>人类智能是一个迭代过程，我们需要和世界交互，环境给出反馈，我们再基于反馈做 Reason 和 Plan——这是「实践检验真理」的过程。此外，他观察到当前 AI 模型调用存在「倒挂现象」：视觉交互对人类至关重要（90% 信息是视觉信号），但 <strong>AI 模型的调用量却是文本模态远高于视觉模态</strong>。为了填补这个空白，必须给模型搭建一个「Playground」。</p><p>冯睿蠡从生物学中找到了灵感：动物为什么需要 Play（玩耍）？ 乌鸦在雪地里打滚、蜜蜂搬运圆形物体，这些看似与生存无直接利益的行为，实际上提供了一种「Simulation」（模拟），让生物<strong>在安全、廉价、可重复的环境下练习技能</strong>。基于此，他提出了理想交互模拟器的四个标准：实时反馈、足够廉价和快速、支持测试不同选择、能够覆盖对应场景。</p><p>他的「The Matrix」项目实现了四个主要目标：<strong>实时交互、立即的视觉反馈、极长的存在时间</strong>（最长测试了 10 小时交互性能不衰减），以及<strong>强大的泛化能力</strong>。模型现在能生成 15 分钟以上的长视频，且画面质量无显著衰减。它能响应用户对 Prompt 的切换（如将驾驶场景从沙漠切换到水面），并保持对键盘输入（前后左右运动）的准确响应。模型通过采用混合数据策略（游戏引擎数据与真实世界运动数据混合），模型获得了强大的泛化能力。即使训练数据中只包含白色的车，它也能生成其他颜色的车；<strong>即使训练数据中不存在，它也能让车在办公室或深水里运动</strong>。</p><p>这些成果意味着，AI 已经拥有了一个安全、廉价、高性能的神经交互模拟器来不断磨炼自己的认知和决策能力，最终可以被用于 Vtuber、电商直播或机器人控制等场景。</p><p>「只有成本降到每个人都能承受的程度，交互式世界模型才能被大规模用于推理场景，成为通往更强智能的基石。」</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406545" alt="" title="" loading="lazy"/></p><p><strong>冯睿蠡</strong></p><p>加拿大滑铁卢大学访问学者</p><h2>俞刚：大模型时代下的多模态生成和理解</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406546" alt="" title="" loading="lazy"/></p><p>阶跃星辰语音和 AIGC 算法负责人俞刚提到，过去两年大模型的参数量从 T 级狂飙到万亿级，训练数据量也像坐上了火箭，连开源和闭源模型的差距都在肉眼可见地缩小。这让他意识到，<strong>文本智能这座高山已经快被征服了</strong>。下一个战场自然是声音。语音和文本是天生的好搭档。他们的目标很明确：<strong>做一款能把所有信息都吃进去的「大胃王」</strong>。</p><p>他们推出了 Step-Audio2，一款百亿级的模型，特点是采用了连续信号输入（能保留语音中的情感和声学信号）和离散 tokenizer 输出（兼顾训练效率）。为了让这个模型「智力」和「听力」双高，他们设计了一个多达四个阶段的预训练流程，再用 SFT（指令微调）和 PPO+GRPO 的强化学习技术进行「对齐训练」。他们也同步开源了小尺寸的 7B 模型，让创业者和开发者能以更低的门槛把语音 AI 搬上自家业务。</p><p>俞刚直言，目前的 AI 世界出现了两个「流派」：</p><p>1.理解派： 侧重「思考」，如阿里的千问 Omni 系列，它<strong>能接收各种模态的输入，但通常只能输出文本或音频</strong>；</p><p>2.生成派： 侧重「创造」，比如 Veo3 或 Sora2，它们能生成炫酷的视觉内容，但 <strong>「脑子」相对简单</strong>，缺乏复杂的理解和推理能力。</p><p>为什么不能把这两种能力「深度融合」在一个模型里，做一个真正的 Any2Any 全能模型？俞刚坦诚，<strong>最大的绊脚石是 Tokenizer</strong>。目前的大模型主要依赖离散的 Tokenizer，但面对图像和视频这些二维、三维的复杂信号时，信息损失非常严重。而生成派的 Diffusion 模型则采用连续信号，信息量更大，更擅长处理全局视觉信息。</p><p>为了解决这个「硬伤」，他们通过将 AI 模型作为「思考者」和信息提取器，再把生成工作交给 Diffusion 模型。这个组合<strong>最大的价值在于让 AI 有了「反思」和「自我纠正」的能力</strong>。比如，在图片编辑时，如果第一次生成结果遗漏了猫的影子或人物的残肢，理解模型能立刻发现并进行下一轮修正，从而让成品更加完美。</p><p>俞刚总结，<strong>未来 AI 的上限仍有赖于 World Model、交互和记忆的突破，甚至需要探索自主学习的新范式</strong>，才能实现真正的飞跃。</p><p>「当模型已经充分利用现有数据，如何进一步提升模型性能？自主学习是潜在的突破方向之一。」</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406547" alt="" title="" loading="lazy"/></p><p><strong>俞刚</strong></p><p>阶跃星辰语音和 AIGC 算法负责人</p><h2>刘一聪：个人化的 HomeAI——为归属而生</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406548" alt="" title="" loading="lazy"/></p><p>和众科技 HooRii Technology Co-Founder &amp; CTO 刘一聪看来，<strong>HomeAI 的终极形态绝不应该是一个冰冷的工具，而是一位有温度的家人</strong>。</p><p>他提出的「信息论困境」点明：<strong>AI 的进化迫切需要来自物理世界的第一手原始数据，来构建「世界模型」</strong>。然而，用户对家里的 AI 兴趣寥寥，不愿高频交互，因为他们得到的是一个工具，而不是一个灵魂伴侣。这种「工具范式」导致了<strong>三个致命缺陷：空间断连、情境失忆、关系缺失</strong>。AI 记不住你何时何地做了什么，更无法主动关心你。</p><p>起因就是这个「工具循环」：体验不够好 → 没有高频交互 → 无法获取一手数据 → AI 无法进化。为了打破这一循环，HooRii 的解决方案是实现范式转移，从「工具」转向「关系」。他们推出的核心平台 HooRii Stage，被定位为连接数字智能与物理世界的关键基础设施。</p><p>那么，HooRii 是如何通过精妙的智能架构来实现「赛博家人」的养成的呢？</p><p><strong>1.连接层：</strong> 解决「空间断连」。通过 HooRii OS、ShadowLink（跨协议通信技术）和 HooRii Console，平台为 AI 提供了连接物理世界的 API。这就像给 AI 接上了「神经系统」，让它可以管理跨品牌的智能设备，真正「住进家里」；</p><p><strong>2.感知层：</strong> 解决「情境失忆」。其中的 Perceiver Agent 和 Context Agent 就像 AI 的记忆中枢，将摄像头、麦克风等上报的原始数据转化为结构化的情景知识，这个自进化记忆引擎能让 AI 越用越懂你；</p><p><strong>3.协作层：</strong> Planning Agent 负责制定执行计划。它分析当前情境，将用户的需求转化为一系列行动路径，并分配给不同的智能体。</p><p><strong>4.执行层：</strong> 负责将计划转化为具体操作。包括控制 HomeAI 智能体，直接驱动物理设备的响应和交互，实现个性化、有情感的陪伴。</p><p>他们产品的核心优势在于实现了自我迭代的闭环：当 AI 执行动作后，物理世界状态的变化会被实时捕获并反馈给感知层，更新记忆。这种持续的实时反馈，使得 HomeAI 能够自我纠正、自我学习。刘一聪强调，HomeAI 必须是个人化的，这才是 AIGC 的灵魂。无论是对 AI 角色进行「灵魂雕刻」，还是根据家庭环境进行「情景重组」，<strong>这种高度定制化才能真正构建出「归属感」</strong>。</p><p>「自进化的记忆引擎是我们 HomeAI 成为家人的关键，因为一个家人会记得你的习惯、你的喜好、你的忧伤。」</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406549" alt="" title="" loading="lazy"/></p><p><strong>刘一聪</strong></p><p>和众科技<br/> HooRii Technology Co-Founder &amp; CTO</p><h2>顾嘉唯：World as Prompt, World as Interface</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406550" alt="" title="" loading="lazy"/></p><p>灵宇宙创始人顾嘉唯作为曾在微软、百度从事 AR 和自动驾驶研究的资深创作者，他将自己 12 年前的作品——百度 Eye（一个语音对话摄像头）和今天的「小方机」进行对比，感叹大模型将当年的「不可能」变成了「可能」。他认为，这是时代赋予的机会，<strong>要为下一代孩子定义一个「不只是机，而是伴」的新型学习伙伴</strong>。</p><p>如果<strong>将空间尺度拉小、用户价值放大</strong>，通过一个第一视角设备高频使用，是否就能获取到自动驾驶最渴求的物理世界结构化数据集？这个想法的本质，是找到了物理世界 AI 最大的痛点：<strong>缺乏数据</strong>。</p><p>1.Luka 时代（读万卷书）： 这是顾嘉唯上一代创业的产品，一只可爱的大眼睛猫头鹰机器人。它解决了家庭场景的垂直痛点（如读绘本），通过摄像头识别、OCR 转 TTS 等技术，实现了「翻到哪里读到哪里」的交互。</p><p>2.小方机时代（行万里路）： 小方机利用多模态大模型的能力，让孩子的世界变得 AR 化和可交互。它是一个随身、可穿戴的 AI 伙伴，并将 Luka 积累的桌面数据扩展到了孩子一整天的世界交互行为。</p><p>顾嘉唯强调，这不是简单的功能叠加，而是要构建一个 FSD（全自动驾驶）一样的数据闭环。通过第一视角数据集，他希望能够<strong>捕捉下一代年轻人如何在物理世界中交互的完整过程，为未来具身机器人等最需要数据的领域提供最核心的资产</strong>。</p><p>顾嘉唯将自己的工作视为在践行物理世界的 AI，并尝试构建 LingOS，一套基于数据闭环的操作系统。</p><p>他坦诚这需要极强的韧性，去等待和感悟时机。他认为自己正在做的事情，就是将十年前的百度 Eye 梦想，通过今天的技术和产品落地，来构建世界模型上「非常重要的数据源」。</p><p>「具身不只是人形，本质是怎么把物理世界和虚拟世界融合。未来可能会诞生各种各样的新物种，但不变的是人类对于物理世界的感知和解决问题的能力。」</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406551" alt="" title="" loading="lazy"/></p><p><strong>顾嘉唯</strong></p><p>灵宇宙创始人</p><h2>圆桌讨论：从帮点一杯咖啡到 AGI——多模态的未来</h2><p>本次主题为「从帮点一杯咖啡到 AGI——多模态的未来」的圆桌讨论由 RTE 开发者社区的联合主理人，OpenQ 联合创始人<strong>林旅强</strong>主持，参与讨论的嘉宾还有 Agora 的 Principal Product Manager <strong>Monica Chen</strong>、拽米科技（DraMa.i）创始人<strong>何竞飞</strong>以及 Memories.ai 算法负责人<strong> Jerrick</strong>。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406552" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406553" alt="" title="" loading="lazy"/></p><p>本次圆桌首先聚焦于 AI 时代的<strong>实时互动基建</strong>。主持人抛出了第一个问题：<strong>在 AI 时代，视频作为 3D 维度的信息载体，其处理和传输的挑战是什么？机器生成内容是否更易于机器理解？</strong></p><p>Agora 的 Monica Chen 关于这个问题从底层技术进行了剖析。她指出，视频的信息量是文字和声音的几百倍，这赋予了它在图表理解等场景中不可替代的优势，但同时也使实时互动和传输成为一个共同的、难以解决的挑战。她特别提到了<strong>实时互动中的低延时、清晰度、真实度之间的平衡</strong>，认为这三者的权衡，以及上行与下行带宽、多设备适配性等问题，都<strong>是决定未来几年技术竞争的关键</strong>。</p><p>针对机器生成视频（如数字人）是否更易于机器理解的问题，Monica Chen 解释说，计算机生成的内容虽然省略了模拟到数字的转换，但它可能色彩更丰富、边缘更清晰，这些特点实际上不利于传输。但从正面看，这类内容又具有更高的对称性，更可以被拆解和分析。</p><p>她总结，<strong>Agora 的产品提供超低延时、高保真、高适配性的解决方案</strong>，确保无论是真实信息还是 AI 生成信息，信息流的顺畅都是基石。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406554" alt="" title="" loading="lazy"/></p><p>如果说底层技术保证了信息流的顺畅，那么如何在这些信息之上构建有吸引力的 AI 应用和世界？主持人将视角转向了多 Agent 驱动的娱乐体验，向拽米科技创始人何竞飞提出了第二个问题：<strong>多 Agent 世界如何从学术研究走向 C 端商业化？AI 角色「活灵活现」的核心机制是什么？</strong></p><p>何竞飞指出，其项目虽然灵感来源于「斯坦福小镇」论文中对多智能体模拟人类行为的探索，但<strong>作为一个商业 C 端产品，最核心的部分在于「模拟剧情」，而非简单的行为模拟</strong>。</p><p>他坦言，<strong>仅靠多模态系统自主运行，故事线会因为冲突点不够密集而过于平淡</strong>。为此，他分享了其创新的 Direct Agent + Multimodal System 机制。其中，Direct Agent 扮演了中心化的「导演」角色，负责主导所有剧情控制，直接向 NPC 下达精准的指令，以确保产生具有戏剧张力的核心冲突场景。而 Multimodal System 则负责填充核心章节之间的日常片段，提供 24 小时运行的陪伴感。他强调，这种模式结合俯瞰像素体和动画漫画片段，复刻了用户在现实中 <strong>「聊天-看社交媒体-再交流」的社交逻辑，是当前阶段通往世界模型的最佳商业化路径</strong>。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406555" alt="" title="" loading="lazy"/></p><p>随着 AI 应用在实时互动和虚拟世界中的成熟，AI 的长时记忆和认知能力自然成为下一个核心议题。主持人将问题转向 Memories.ai 的 Jerrick：<strong>如何构建 AI 的视频记忆，并利用 Visual RAG 改变搜索范式？我们距离 AGI 的关键缺口在哪里？</strong></p><p>Jerrick 认为，<strong>构建 AI 记忆必须同时解决「存储」和「搜索」的问题</strong>。</p><p>在存储上，他们将视频、音频、文字、OCR 视为全模态信息源，通过高效的压缩算法和基于 AI 的信息整合，构建可供自由问答的全网视频库。更关键的是搜索范式的革命：<strong>未来的搜索将不再是简单的检索，而是一个由 Agent 规划的「全模态搜索链条」</strong>。这个 Agent 将理解用户的意图，进行「分析 + 整合」，提供个性化的精准答案，使 AI 成为用户的「个人助理」。</p><p>关于 AGI 的关键缺口，Jerrick 认为，除了 AI 记忆，最关键的探索方向是<strong>空间智能或具身领域</strong>。Memories.ai 正通过 AI 硬件探索收集人类生活化场景的第一视角视频，用这些数据来训练 World Model，目标是让 AI 能够在记住信息的同时，真正地理解物理世界。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406556" alt="" title="" loading="lazy"/></p><p>在最后的总结环节，圆桌讨论走向了<strong>对 AI 价值的深度反思与对未来的有力展望</strong>，三位嘉宾以精炼的观点对圆桌内容进行了收束。</p><p>Monica Chen 再次强调了实时互动和传输的基建支撑，指出无论是真实信息还是 AI 生成信息， Agora 的产品都是<strong>实现端到端触达的坚实平台</strong>，希望借此为创业者和企业家提供更好的发展基础。</p><p>何竞飞则从产品实践中提炼出深刻的教训：在 AI 互动娱乐中，切忌过度追求 AI 性能的「本体论」，因为这往往会忽略用户的体验和感受；他强调，<strong>用户体验应该是第一位的</strong>，只有当 AI Native 能够带来更新或更好的体验时，其价值才能被有效实现。</p><p>Jerrick 则用一句简明的话概括了他们的终极目标：<strong>希望能够让 AI 「看见并且记住」，真正理解人类世界</strong>，并通过构建 Agent 系统，帮助人类更好地生活、规划，完成各种任务。</p><p>最终，主持人林旅强将个人的参与热情升华为对整个行业的呼吁。他不仅强调了 RTE 开发者社区作为技术交流平台 365 天不打烊的活力，更指出 <strong>RTE 开发者社区的愿景是成为中国能牵头的中坚力量，去改变这个世界的技术</strong>。他鼓励所有开发者和创作者，借助社区力量，将技术提炼、场景验证，并在商业上有所提升，共同将 RTE 领域推向全球技术的前沿。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406557" alt="" title="" loading="lazy"/></p><hr/><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406558" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406559" alt="" title="" loading="lazy"/></p><p><a href="https://link.segmentfault.com/?enc=l2UJG9stjSk98F7k3qfVzg%3D%3D.Db5JI%2BHQPInQ0DhuS2DR4U3l2ANx9PTIJVo7NsipPZA%3D" rel="nofollow" target="_blank">阅读更多 Voice Agent 学习笔记：了解最懂 AI 语音的头脑都在思考什么</a></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406560" alt="" title="" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[字节跳动AI大将再离职，大模型团队暗流涌]]></title>    <link>https://segmentfault.com/a/1190000047406332</link>    <guid>https://segmentfault.com/a/1190000047406332</guid>    <pubDate>2025-11-18 00:02:02</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h3>字节跳动再失核心：离职风波</h3><p>近日，据爆料，字节跳动豆包大模型视觉多模态生成方向的负责人杨建朝，正准备离开公司。这一消息如若属实，将是继2023年马维英、李磊等AI骨干相继离职后，字节大模型团队遭遇的又一次核心人才流失。<br/>截至目前，字节跳动方面尚未对此作出任何回应，但外界已开始猜测这背后可能预示的团队重组与战略调整。<br/>杨建朝的离职绝非普通人事变动。他目前主要负责豆包大模型的视觉多模态生成技术，包括文生图、视频生成等关键方向，这些都是当前AIGC领域最前沿、最具商业价值的技术领域。</p><h3>天才的轨迹：从郭沫若奖学金到视觉多模态领军</h3><p>杨建朝的学术背景堪称完美。2006年，他获得中国科学技术大学的郭沫若奖学金——这是中科大学生最高荣誉。随后，他远赴伊利诺伊大学香槟分校，师从“计算机视觉之父”Thomas Huang（黄煦涛），并于2011年获得博士学位。在读期间，他多次获得智能识别世界大赛的冠军，展现出非凡的研究实力。<br/>他的职业经历同样令人瞩目。博士毕业后，他先后在Adobe和Snapchat担任算法研究岗位，2018年加入字节跳动后，历任美国AI Lab研发总监、智能创作团队负责人，最终成为豆包大模型视觉多模态生成技术的掌舵人。<br/>这样一位顶尖人才的离去，无疑会给字节的大模型研发带来不小的影响。</p><h3>组织架构调整：权力重组下的团队未来</h3><p>就在不久前，字节跳动的大模型团队刚刚经历了一次重大的组织架构调整。2月份，原谷歌DeepMind副总裁吴永辉空降担任Seed基础研究负责人，杨建朝等5名核心骨干也从向朱文佳汇报，转为向吴永辉汇报。<br/>这一变动本身就引发了外界对字节大模型团队未来走向的诸多猜测。而爆料显示，杨建朝离开后，团队可能会由周畅接管。如果这一消息属实，那么字节跳动的大模型团队又将迎来一次新的权力重组。<br/>核心人才的频繁变动与组织架构的不断调整，反映出字节跳动在大模型领域的焦虑与不安。在AI军备竞赛日益激烈的今天，任何一家公司都难以承受如此频繁的核心人才流失。</p><h3>AI时代的人才战争：你准备好了吗？</h3><p>杨建朝的离职不是孤立事件。从马维英、李磊到如今的杨建朝，字节跳动AI骨干的相继离去，映射出整个AI行业面临的人才困境。<br/>一方面，顶尖AI人才供不应求，各大公司纷纷开出天价薪酬争夺有限的人才资源；另一方面，技术的快速迭代让从业者必须不断学习更新知识体系，否则就会面临被淘汰的风险。<br/>当下，AIGC和多模态大模型正处于爆发前夜，文生图、视频生成等技术正在重塑内容创作、娱乐、教育等众多行业。随着技术的成熟，市场对相关人才的需求呈指数级增长。<br/>据统计，AIGC相关岗位的薪资在过去一年中上涨了40%以上，但合格的人才仍然稀缺。企业不仅需要人才掌握理论知识，更要求具备实战能力和项目经验。<br/>抢占先机：AIGC大模型系列助你乘风破浪<br/>面对如此广阔的职业前景和人才缺口，如何才能快速切入这一赛道，成为企业争抢的对象？<br/>近屿智能针对这一痛点特别推出👇<br/><img width="723" height="4020" referrerpolicy="no-referrer" src="/img/bVdm4In" alt="1dc54fa27762e6598a45ad1400e91577.jpg" title="1dc54fa27762e6598a45ad1400e91577.jpg"/></p><ol><li>名师引路，量身定制<br/>名校硕博+一线大咖：清华、墨尔本大学等背景师资，懂技术更懂行业<br/>3.5个月进阶路：3大热门方向任选，零基础也能跟上的系统课程<br/>硬核技术手把手：从CUDA优化到模型微调，实操落地不脱节</li><li>实战为王，项目锤炼真本事<br/>100个智能体项目库：覆盖多行业，对接真实工作场景<br/>趣味+实用实战：AI操控机器狗、机械臂编程、AI玩具开发，边玩边学<br/>PBL模式+实习证明：学习效果可视化，求职简历添亮点</li><li>证书加持，竞争力翻倍<br/>权威证书冲刺：微软AIGC工程师、人工智能训练师双证辅导<br/>免费备考礼包：专属题库+视频教程+流程指导，考证无忧<br/>结业认证：近屿智能专属证书，行业认可度高</li><li>就业无忧，直通高薪岗位<br/>多重就业机会：5+AIGC岗位面试邀请，名企内推优先<br/>求职全流程帮扶：从简历到面试，专业指导一站式搞定</li><li>灵活学习，全程有人陪<br/>直播+录播：错过直播也能补，碎片时间高效用<br/>线上线下联动：腾讯会议授课+上海自习室督学，疑问及时解<br/>专属学管+7x24小时答疑：学习路上不孤单</li><li>超值福利，资源全解锁<br/>算力&amp;API免费送：英伟达A800算力卡+千次ChatGPT4调用额度<br/>附加学习权益：Python强化班、Stable Diffusion权限<br/>长期资源：OJAC会员+AI技术社群，持续交流成长<br/>AI世界的竞争从未如此激烈，但也从未如此充满机遇。当行业巨头为争夺顶尖人才而苦恼时，提前布局、掌握核心技能的普通人，同样可以在这场人才盛宴中分得一杯羹。<br/>在这个技术颠覆一切的时代，唯一不变的就是变化本身。与其被动观望，不如主动学习，抓住AIGC带来的历史性机遇。</li></ol>]]></description></item><item>    <title><![CDATA[从SRS项目看现代C++最佳实践：高性能]]></title>    <link>https://segmentfault.com/a/1190000047406369</link>    <guid>https://segmentfault.com/a/1190000047406369</guid>    <pubDate>2025-11-18 00:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>从SRS项目看现代C++最佳实践：高性能实时流媒体服务器的设计智慧</h2><p><img width="723" height="393" referrerpolicy="no-referrer" src="/img/bVdm4IX" alt="68747470733a2f2f6f737372732e6e65742f77696b692f696d616765732f5352532d53696e676c654e6f64652d342e302d73642e706e673f763d313134.png" title="68747470733a2f2f6f737372732e6e65742f77696b692f696d616765732f5352532d53696e676c654e6f64652d342e302d73642e706e673f763d313134.png"/></p><h3>前言</h3><p>SRS (Simple Realtime Server) 是一个高性能的实时视频服务器，支持RTMP、WebRTC、HLS、HTTP-FLV、SRT等多种协议。作为一个拥有200万行代码、在生产环境广泛应用的开源项目，SRS展现了许多值得学习的现代C++设计思路和最佳实践。本文将深入解析SRS项目的C++代码架构，探索其在高性能、高并发场景下的设计智慧。</p><h3>项目背景：为什么SRS值得研究？</h3><h4>技术规模与影响力</h4><ul><li><strong>代码规模</strong>: 超过200万行C++代码，6000+源文件</li><li><strong>协议支持</strong>: RTMP/WebRTC/HLS/HTTP-FLV/SRT/MPEG-DASH/GB28181</li><li><strong>平台兼容</strong>: Linux/macOS/Windows，支持X86_64/ARMv7/AARCH64/M1/RISCV等架构</li><li><strong>编解码</strong>: H.264/H.265/AV1/VP9/AAC/Opus/G.711</li><li><strong>生产应用</strong>: 被众多公司用于构建直播和实时通信平台</li></ul><h4>技术挑战</h4><p>流媒体服务器面临的核心技术挑战包括：</p><ul><li><strong>低延迟要求</strong>: 毫秒级别的延迟控制</li><li><strong>高并发处理</strong>: 同时处理数万路流</li><li><strong>内存管理</strong>: 大量音视频数据的高效处理</li><li><strong>协议复杂性</strong>: 多种协议的状态机管理</li><li><strong>稳定性要求</strong>: 7x24小时稳定运行</li></ul><p>这些挑战促使SRS采用了许多精巧的C++设计模式和实践。</p><h3>现代C++特性的保守与务实使用</h3><h4>C++11标准的选择</h4><p>SRS项目选择C++11作为基础标准，这在看似保守的选择背后体现了工程项目的务实考量：</p><pre><code class="cpp">// trunk/auto/utest.sh:24
SRS_CPP_VERSION="-std=c++11"</code></pre><p><strong>为什么选择C++11而非更新标准？</strong></p><ol><li><strong>兼容性考虑</strong>: 确保在各种老旧系统上的编译兼容性</li><li><strong>稳定性优先</strong>: C++11已经足够成熟，避免新标准的潜在bug</li><li><strong>性能敏感</strong>: 避免新特性带来的性能开销</li><li><strong>团队协作</strong>: 降低团队成员的学习成本</li></ol><h4>智能指针的自定义实现</h4><p>SRS没有直接使用<code>std::unique_ptr</code>，而是实现了自己的智能指针系统，这展现了高性能项目的典型做法：</p><pre><code class="cpp">// trunk/src/core/srs_core_autofree.hpp:32-89
template &lt;class T&gt;
class SrsUniquePtr
{
private:
    T *ptr_;
    void (*deleter_)(T *);

public:
    SrsUniquePtr(T *ptr = NULL, void (*deleter)(T *) = NULL)
    {
        ptr_ = ptr;
        deleter_ = deleter;
    }

    virtual ~SrsUniquePtr()
    {
        if (!deleter_) {
            delete ptr_;
        } else {
            deleter_(ptr_);
        }
    }

    // C++11 move semantics support
#if __cplusplus &gt;= 201103L
    SrsUniquePtr(SrsUniquePtr&lt;T&gt; &amp;&amp;other);
    SrsUniquePtr&lt;T&gt; &amp;operator=(SrsUniquePtr&lt;T&gt; &amp;&amp;other);
#endif
};</code></pre><p><strong>自定义智能指针的优势：</strong></p><ol><li><strong>自定义删除器</strong>: 支持malloc/free、特殊释放函数</li><li><strong>性能优化</strong>: 避免标准库的额外开销</li><li><strong>调试友好</strong>: 可添加自定义调试信息</li><li><strong>向后兼容</strong>: 支持C++11之前的编译器</li></ol><h4>模板的精确使用</h4><p>SRS在模板使用上非常克制，主要用于工具类和类型安全：</p><pre><code class="cpp">// trunk/src/kernel/srs_kernel_mp4.hpp:3027-3047
template &lt;typename T&gt;
std::stringstream &amp;srs_dumps_array(std::vector&lt;T&gt; &amp;arr, std::stringstream &amp;ss,
                                   SrsMp4DumpContext dc,
                                   void (*pfn)(T &amp;, std::stringstream &amp;, SrsMp4DumpContext),
                                   void (*delimiter)(std::stringstream &amp;, SrsMp4DumpContext))
{
    for (int i = 0; i &lt; (int)arr.size(); i++) {
        if (i &gt; 0 &amp;&amp; delimiter) {
            delimiter(ss, dc);
        }
        if (pfn) {
            pfn(arr[i], ss, dc);
        }
    }
    return ss;
}</code></pre><p><strong>模板使用原则：</strong></p><ul><li>仅在必要时使用模板，避免过度抽象</li><li>优先考虑代码可读性和编译速度</li><li>模板主要用于类型安全和代码复用</li></ul><h3>内存管理的艺术</h3><h4>RAII模式的彻底贯彻</h4><p>SRS通过RAII模式确保资源的安全释放：</p><pre><code class="cpp">// trunk/src/core/srs_core.hpp:57-65
#define srs_freep(p) \
    delete p;        \
    p = NULL;        \
    (void)0

#define srs_freepa(pa) \
    delete[] pa;       \
    pa = NULL;         \
    (void)0</code></pre><h4>资源管理器模式</h4><pre><code class="cpp">// trunk/src/kernel/srs_kernel_resource.hpp:215-249
template &lt;typename T&gt;
class SrsSharedResource : public ISrsResource
{
private:
    SrsSharedPtr&lt;T&gt; ptr_;
public:
    SrsSharedResource(T *ptr = NULL) : ptr_(ptr) {}
    virtual ~SrsSharedResource() {}

    T *operator-&gt;() { return ptr_.operator-&gt;(); }
    T *get() { return ptr_.get(); }
};</code></pre><p><strong>内存管理最佳实践：</strong></p><ol><li><strong>统一的资源管理</strong>: 所有资源都通过RAII管理</li><li><strong>自定义智能指针</strong>: 满足特定需求的智能指针实现</li><li><strong>明确的所有权语义</strong>: 通过类型系统表达资源所有权</li></ol><h3>错误处理的工程化实践</h3><h4>分层错误系统</h4><p>SRS实现了一个强大的分层错误处理系统：</p><pre><code class="cpp">// trunk/src/kernel/srs_kernel_error.hpp:437-481
class SrsCplxError
{
private:
    int code_;
    SrsCplxError *wrapped_;
    std::string msg_;
    std::string func_;
    std::string file_;
    int line_;
    SrsContextId cid_;
    int rerrno_;

public:
    // 错误链构建
    SrsCplxError *wrap(const std::string &amp;msg);
    SrsCplxError *transform(int code);

    // 错误信息提取
    std::string description() const;
    int error_code() const { return code_; }
};</code></pre><h4>错误分类体系</h4><p>SRS按功能模块对错误进行分类：</p><pre><code class="cpp">// 系统错误 (1000-1099)
#define ERROR_SOCKET_CREATE 1000
#define ERROR_SOCKET_BIND   1002
#define ERROR_SOCKET_LISTEN 1003

// RTMP协议错误 (2000-2999)
#define ERROR_RTMP_HANDSHAKE 2000
#define ERROR_RTMP_PACKET_SIZE 2001

// 应用错误 (3000-3999)
#define ERROR_HLS_DECODE_ERROR 3000
#define ERROR_DVR_CANNOT_OPEN 3001</code></pre><p><strong>错误处理最佳实践：</strong></p><ol><li><strong>分层错误链</strong>: 错误可以被包装和传递，保持调用栈信息</li><li><strong>上下文信息</strong>: 每个错误包含完整的调试信息</li><li><strong>分类管理</strong>: 按模块和严重级别分类错误代码</li><li><strong>性能考虑</strong>: 错误对象的创建和销毁要高效</li></ol><h3>并发编程的创新方案</h3><h4>State Threads协程库</h4><p>SRS没有使用标准的pthread或C++11线程，而是选择了State Threads库：</p><pre><code class="cpp">// trunk/src/protocol/srs_protocol_st.hpp:22-26
typedef void *srs_netfd_t;
typedef void *srs_thread_t;
typedef void *srs_cond_t;
typedef void *srs_mutex_t;</code></pre><h4>协程化的网络IO</h4><pre><code class="cpp">// 协程式的网络读写
srs_error_t SrsStSocket::read(void *buf, size_t size, ssize_t *nread)
{
    *nread = st_read(stfd_, buf, size, ST_UTIME_NO_TIMEOUT);
    if (*nread &lt;= 0) {
        return srs_error_new(ERROR_SOCKET_READ, "st_read failed");
    }
    return srs_success;
}</code></pre><h4>线程安全的锁机制</h4><pre><code class="cpp">// trunk/src/protocol/srs_protocol_st.hpp:152-174
#define SrsLocker(instance) \
    impl__SrsLocker _SRS_free_instance(instance)

class impl__SrsLocker
{
private:
    srs_mutex_t *lock_;
public:
    impl__SrsLocker(srs_mutex_t *l) {
        lock_ = l;
        srs_mutex_lock(*lock_);
    }
    virtual ~impl__SrsLocker() {
        srs_mutex_unlock(*lock_);
    }
};</code></pre><p><strong>并发编程最佳实践：</strong></p><ol><li><strong>协程优于线程</strong>: 在IO密集型场景下，协程提供更好的性能</li><li><strong>RAII锁管理</strong>: 通过RAII确保锁的正确释放</li><li><strong>事件驱动架构</strong>: 基于事件循环的高效并发模型</li></ol><h3>类型安全与接口设计</h3><h4>前向声明的大量使用</h4><pre><code class="cpp">// trunk/src/app/srs_app_server.hpp:27-73
class SrsAsyncCallWorker;
class SrsUdpMuxListener;
class SrsRtcConnection;
class ISrsAsyncCallTask;
class SrsSignalManager;
// ... 更多前向声明</code></pre><p><strong>前向声明的价值：</strong></p><ol><li><strong>编译速度</strong>: 减少头文件依赖，提升编译速度</li><li><strong>解耦合</strong>: 降低模块间的耦合度</li><li><strong>循环依赖</strong>: 解决头文件的循环依赖问题</li></ol><h4>接口抽象的使用</h4><p>SRS大量使用抽象接口来实现多态和解耦：</p><pre><code class="cpp">class ISrsSignalHandler
{
public:
    virtual ~ISrsSignalHandler() {}
    virtual srs_error_t on_signal(int signo) = 0;
};

class ISrsResourceManager
{
public:
    virtual ~ISrsResourceManager() {}
    virtual void subscribe(ISrsResource* c) = 0;
    virtual void unsubscribe(ISrsResource* c) = 0;
};</code></pre><h3>条件编译与平台适配</h3><h4>测试友好的设计</h4><pre><code class="cpp">// trunk/src/core/srs_core.hpp:16-25
#ifdef SRS_FORCE_PUBLIC4UTEST
#define SRS_DECLARE_PRIVATE public
#define SRS_DECLARE_PROTECTED public
#else
#define SRS_DECLARE_PRIVATE private
#define SRS_DECLARE_PROTECTED protected
#endif</code></pre><p>这个设计让所有私有成员在测试模式下变为public，极大地便利了单元测试。</p><h4>平台兼容性检查</h4><pre><code class="cpp">// trunk/src/core/srs_core.hpp:67-70
#if !defined(__amd64__) &amp;&amp; !defined(__x86_64__) &amp;&amp; !defined(__i386__) &amp;&amp; \
    !defined(__arm__) &amp;&amp; !defined(__aarch64__) &amp;&amp; !defined(__mips__) &amp;&amp; \
    !defined(__mips64) &amp;&amp; !defined(__loongarch64) &amp;&amp; !defined(__riscv)
#error "Only support i386/amd64/x86_64/arm/aarch64/mips/mips64/loongarch64/riscv cpu"
#endif</code></pre><h3>性能优化的细节考量</h3><h4>内存池和对象复用</h4><p>SRS在关键路径上大量使用对象池和内存池技术：</p><pre><code class="cpp">// 包对象的复用管理
class SrsPacketManager
{
private:
    std::vector&lt;SrsRtpPacket*&gt; free_packets_;

public:
    SrsRtpPacket* acquire_packet() {
        if (!free_packets_.empty()) {
            SrsRtpPacket* pkt = free_packets_.back();
            free_packets_.pop_back();
            return pkt;
        }
        return new SrsRtpPacket();
    }

    void release_packet(SrsRtpPacket* pkt) {
        pkt-&gt;reset();
        free_packets_.push_back(pkt);
    }
};</code></pre><h4>零拷贝技术</h4><p>在媒体数据处理中，SRS尽可能避免不必要的内存拷贝：</p><pre><code class="cpp">class SrsBuffer
{
private:
    char* data_;
    int size_;
    int pos_;

public:
    // 返回当前位置的指针，避免拷贝
    char* current() { return data_ + pos_; }

    // 直接在缓冲区上操作
    void skip(int size) { pos_ += size; }
};</code></pre><h3>现代C++特性的取舍思考</h3><h4>为什么不用更新的C++标准？</h4><ol><li><strong>兼容性至上</strong>: 流媒体服务器需要在各种环境中部署</li><li><strong>性能第一</strong>: 避免新特性可能带来的性能开销</li><li><strong>稳定性考虑</strong>: 生产环境优先选择成熟稳定的技术</li><li><strong>团队效率</strong>: 降低学习成本，提高开发效率</li></ol><h4>哪些现代特性值得采用？</h4><p><strong>建议采用的特性：</strong></p><ul><li><code>auto</code>关键字：提高代码可读性</li><li>Lambda表达式：简化回调和算法</li><li>智能指针：改善内存管理</li><li>右值引用：优化性能关键路径</li><li><code>constexpr</code>：编译时计算</li></ul><p><strong>需要谨慎的特性：</strong></p><ul><li>复杂模板：可能影响编译速度和调试</li><li>异常：在高性能场景下开销较大</li><li>标准库算法：不一定比手写代码更高效</li><li>新的并发库：可能不如专门的高性能库</li></ul><h3>总结：工程实践的智慧</h3><p>SRS项目展现了现代C++在大型工程项目中的最佳实践：</p><h4>设计原则</h4><ol><li><strong>性能优先</strong>: 所有设计决策都以性能为首要考量</li><li><strong>稳定可靠</strong>: 优先选择成熟稳定的技术方案</li><li><strong>可维护性</strong>: 代码结构清晰，便于长期维护</li><li><strong>可测试性</strong>: 设计时考虑测试的便利性</li></ol><h4>技术选择</h4><ol><li><strong>保守的标准选择</strong>: C++11提供了足够的现代特性</li><li><strong>自定义核心组件</strong>: 针对性能需求定制关键组件</li><li><strong>接口驱动设计</strong>: 通过抽象接口实现模块解耦</li><li><strong>RAII贯彻始终</strong>: 确保资源管理的安全性</li></ol><h4>工程化思维</h4><ol><li><strong>分层架构</strong>: 清晰的模块分层和职责划分</li><li><strong>错误处理</strong>: 完善的错误分类和处理机制</li><li><strong>平台兼容</strong>: 考虑多平台部署的兼容性</li><li><strong>性能调优</strong>: 在关键路径上进行精细优化</li></ol><p>SRS项目证明了现代C++不一定要追求最新的语言特性，而是要根据项目特点选择合适的技术栈。在高性能、高可靠性要求的系统中，工程化的设计思维比语言特性的新颖性更为重要。</p><p>对于其他C++项目，SRS的经验告诉我们：</p><ul><li><strong>根据需求选择技术</strong>：不是越新越好，而是越合适越好</li><li><strong>性能与可维护性平衡</strong>：在性能要求和代码可维护性之间找到平衡</li><li><strong>工程化思维</strong>：把代码当作工程来设计，考虑长期维护和团队协作</li><li><strong>渐进式演进</strong>：在稳定的基础上渐进式地引入新技术</li></ul><p>这些实践经验对于开发高质量的C++项目具有重要的指导意义。</p><p>本文基于SRS 6.0版本代码分析，SRS是一个持续演进的开源项目，代码地址：<a href="https://link.segmentfault.com/?enc=IGOAHkr3W1H5RIoSqq6Dmg%3D%3D.hW04jUdH2RHPksLMW89HzMqbWt5cUBhM3fDi7ULMOKo%3D" rel="nofollow" target="_blank">https://github.com/ossrs/srs</a></p>]]></description></item><item>    <title><![CDATA[cpp c++面经分享 cpp辅导的阿甘]]></title>    <link>https://segmentfault.com/a/1190000047406271</link>    <guid>https://segmentfault.com/a/1190000047406271</guid>    <pubDate>2025-11-17 23:04:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>前言</h2><p>大家好，我是阿甘，“奔跑中cpp / c++”，知识星球的创始人</p><p>今天给大家分享分享，我们星球同学一起整理的，同时也在不断更新的，cpp / c++相关岗位面经。</p><p>全网最全收集</p><h2>面经分享</h2><p>因面经过多，今天只分享部分，后续有时间继续分享（让大家学习/ 面试形成一个参考）<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047406273" alt="" title=""/></p><h3>字节客户端一面</h3><ol><li>C++智能指针有哪些，都是为了解决什么问题？</li><li>虚函数是什么，如何实现虚函数？</li><li>如何用栈实现一个队列？</li><li>TCP的流量控制，拥塞控制</li><li>主从reactor是什么，数据是怎么传输的？</li><li>(以下都是网络检测项目)项目的背景是什么，为什么要做这样一个项目？有没有应用到实际中？</li><li>ai的具体作用是什么，会不会负载很大？</li><li>传入ai的是什么？有多大？会不会在运行上有一个后置性，为什么不在前置设置一个阈值，超出阈值的输出给ai？</li><li>如何进行网络好坏的判断？这些指标是在现如今工作中的统一标准还是什么？</li><li>算法手撕</li></ol><h3>oppo多媒体开发</h3><p>一面:</p><p>1.无手撕，直接拷打项目，挑一个最熟悉的项目介绍</p><p>2.线程池和内存池用来干什么，怎么实现的</p><p>3.性能调优具体怎么做的</p><p>4.有没遇到过内存泄露，具体场景</p><p>5.tcp和udp区别，具体实现</p><p>6.数据结构相关，map,set,unordered_map底层实现，vector和list区别</p><p>7.(开始进入智能云存储项目)ai检索具体怎么做的，用api的话工作量在哪</p><p>8.遇到的困难，怎么解决的/遇到过那些比较棘手的debug情况/介绍下怎么快速上手项目的</p><p>二面:</p><p>1.同样是先介绍项目，无手撕</p><p>2.进程间通信和线程同步</p><p>3.追着本人的项目一直问到具体遇到过哪些debug场景以及最后如何解决的，但没涉及到具体的八股</p><p>4.分布式架构如何实现的</p><p>5.采用gpu处理信号的时候考虑过gpu到cpu通信的耗时吗？为什么最终还是选择gpu(本人的实验室项目)</p><p>6.性能怎么测的？以及再次问了线程池和内存池</p><p>7.lamda以及移动语义用没用过等</p><p>8.对oppo有哪些了解</p><p>三面(hr面):<br/>大概问了下优点缺点，意向地怎么考虑的，对oppo的认识，对于未来工作环境的想法等等，纯聊天局。</p><p>总结:全程无手撕，建议笔试好好做(本人笔试水过去被问真不知道笔试成绩比较低)，问项目感觉更多是在看有没有真实的做过一些东西，以及对项目的整体把控。timeline基本是一周一推进。</p><h3>米哈游一面</h3><p>1、自我介绍</p><p>2、为什么投递这个客户端工具岗位</p><p>3、指针和引用的区别（概念、使用场景）</p><p>4、是否存在指针数组和引用数组</p><p>5、野指针</p><p>6、内存泄漏</p><p>7、new和malloc的区别</p><p>8、new和malloc怎么判断分配内存失败了？</p><p>9、智能指针</p><p>10、引用计数保存在内存哪个部分</p><p>11、介绍下C++内存分布</p><p>12、静态区、堆和栈什么时候确定大小？</p><p>13、堆和栈的区别</p><p>14、为什么栈的分配效率更高？</p><p>15、堆和栈的安全性</p><p>16、static关键字</p><p>17、静态全局变量和全局变量</p><p>18、静态局部变量和局部变量</p><p>19、静态成员变量和静态成员函数</p><p>20、手撕：用数组实现一个可以扩容的栈，不能用vector</p><p>21、map的底层</p><p>22、二叉搜索树、二叉平衡树、红黑树</p><p>23、熟悉的设计模式</p><p>24、单例模式</p><p>25、简单工厂、工厂方法、抽象工厂</p><h3>海康</h3><p>1、云存储项目：</p><p>介绍文件秒传逻辑</p><p>介绍大文件分片上传逻辑</p><p>分片文件上传到后端在合并前存储在哪里</p><p>有没有考虑以分片形式存储到fastdfs中</p><p>fastdfs的原理展开说下</p><p>ai搜索展开讲下</p><p>2、弱网项目：</p><p>介绍下ICMP协议实现方式</p><p>介绍eBPF怎么用的</p><p>项目的难点是什么</p><p>3、拷贝构造函数在那些场景下调用</p><p>4、静态成员函数与普通成员函数的差别是什么</p><p>5、追问为什么this不能调用静态成员函数，底层原理是什么</p><p>6、了解什么设计模式</p><p>7、讲下你在项目中怎么实现一个具体单例模式的</p><p>8、项目有没有用过线程池？怎么设置的</p><p>9、条件变量怎么使用的？为什么要配合锁使用？</p><p>10、写没写过网络库</p><p>11、Reactor要怎么实现</p><h2>知识星球介绍（公认的cpp c++学习地）</h2><p>星球名字：奔跑中的cpp / c++</p><p>里面服务也不会变，四个坚守目前:</p><p>1.每天都会看大家打卡内容，给出合理性建议。</p><p>2.大家如果需要简历指导，心里迷茫需要疏导都可以进行预约周六一对一辅导。</p><p>3.每周五晚上九点答疑聊天不会变。</p><p>4.进去星球了，后续如果有什么其他活动，服务，不收费不收费(可以合理赚钱就收取下星球费用，但是不割韭菜，保持初心)</p><p>（还有经历时间考验的独家私密资料）</p><p>加入星球的同学都可以提问预约，一对一帮做简历，一对一  职业规划辅导    ，解惑。同时有高质量的项目以及学习资料</p><p>本文由<a href="https://link.segmentfault.com/?enc=3%2FuOxIgWRHM6kLPpo5ASkw%3D%3D.tvpVe3U2zzUMArqNH5UD9R3zk8oQZdM5V2Tsv1Ewmio%3D" rel="nofollow" target="_blank">mdnice</a>多平台发布</p>]]></description></item><item>    <title><![CDATA[《Unity渲染实战宝典：突破平台限制的]]></title>    <link>https://segmentfault.com/a/1190000047406281</link>    <guid>https://segmentfault.com/a/1190000047406281</guid>    <pubDate>2025-11-17 23:03:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>许多开发者初期极易陷入“参数拉满即优质”的认知误区，盲目调高光照强度、堆叠后处理效果、复用高面数模型，却忽略了不同平台（移动端、PC端、主机端）的硬件架构本质差异—移动端GPU的ALU数量通常仅为PC端的1/5至1/3，显存带宽也存在数倍差距，而主机端则具备专属的光线追踪加速单元。这种硬件差异直接导致相同渲染配置在不同设备上表现天差地别，最终出现真机测试时帧率断崖式下跌、设备异常发热、画面元素穿帮（如阴影断裂、材质闪烁）等问题。真正成熟的渲染优化，是对渲染管线每一个环节的深度解构与灵活重组，是在有限资源边界内实现视觉体验最大化的艺术。以复杂场景光照处理为例，既不能为了追求照片级真实感而无限制增加实时光源—移动端设备通常难以承载超过4个实时光源的同时计算，过多光源会直接导致GPU算力过载，甚至触发设备的 thermal throttling（热节流）机制；也不能为了单纯节省性能而过度简化光照层次，否则会让画面显得扁平乏味，失去沉浸感。此时需要结合场景类型与动态物体占比精准决策：动态物体占比高的动作游戏，可采用“少量实时光源（主角2个+关键交互道具1个）+光照探针”的组合，保证角色与核心道具的光影实时反馈，同时通过环境光反射贴图模拟周围环境的光影影响；静态场景为主的解谜游戏，则可通过光照烘焙生成Lightmap，将烘焙分辨率设置为每米512像素以保证细节，再搭配2次间接光反弹模拟自然光影过渡，甚至通过材质的反光系数调整（如墙面反光系数0.1、金属道具0.8）与环境光探针的合理布局，让玩家在视觉上感知到超出硬件实际支持的光影层次。这种“感知优化”远比单纯的参数堆砌更具性价比，也是资深开发者与新手的核心差距所在。</p><p>材质系统作为渲染的基础载体，其优化细节直接决定游戏的运行效率与画面一致性，却最容易被开发者忽视。很多人习惯直接使用Unity默认Shader或网络下载的复杂Shader模板，却未意识到每一个冗余的Shader变体都会成为性能负担—Shader变体过多会导致游戏加载阶段的Shader编译时间大幅延长，移动端设备可能出现3-5秒的启动卡顿，而在部分低端机型上，甚至会出现Shader编译失败导致的画面粉红错误。更严重的是，冗余变体还会占用额外内存，一款中型游戏的Shader变体若未做裁剪，可能占用数十MB内存，这对于仅配备2GB显存的移动端设备来说，无疑是雪上加霜。在实际开发中，Shader的精准裁剪是核心优化动作：需借助Unity的Shader Variant Collection工具，分析游戏运行过程中实际调用的变体，剔除所有无用功能模块，比如2D游戏无需保留3D Shader中的法线贴图计算、视差映射模块，远景物体可移除Shader中的高光反射、细节纹理采样、自发光等逻辑，仅保留基础颜色渲染功能，将Shader指令数控制在100条以内。材质的复用与共享同样关键，对于外观相似仅颜色或纹理不同的物体（如批量生成的敌人、重复的场景装饰、道具库中的同类物品），应通过材质实例化（Material Instantiate）功能修改主纹理或颜色参数，而非创建多个独立材质，这样能有效减少DrawCall的无效增长—DrawCall的增加会直接加重CPU的调度负担，当DrawCall超过2000时，多数移动端设备的CPU会成为性能瓶颈，帧率可能从60帧骤降至30帧以下。此外，渲染队列的设置直接影响画面渲染顺序与OverDraw（过度绘制）压力，错误的队列配置可能引发严重问题：将透明物体设置在不透明队列（Opaque）会导致遮挡关系错乱，出现“透明物体被不透明物体穿透”的视觉bug；而将半透明物体放在透明队列（Transparent）前端，则会导致后续物体重复渲染，OverDraw占比可能飙升至300%以上，造成GPU像素填充率过载。正确的做法是根据物体的透明属性与场景层级分级配置：不透明物体放在“Opaque”队列（优先级2000），半透明物体放在“Transparent”队列（优先级3000），粒子特效、UI等需要叠加的元素放在“Overlay”队列（优先级4000），同时通过调整队列偏移值，确保关键视觉元素（如主角、任务道具）优先渲染，避免被次要物体遮挡。借助Unity的Frame Debugger工具，可实时查看OverDraw热点区域，针对占比超过200%的区域优化渲染队列，往往能快速提升帧率。</p><p>光照与阴影是塑造画面质感的核心，也是渲染优化中最具挑战性的环节，其优化的关键在于“分层适配”与“视觉欺骗”的深度结合。很多开发者盲目追求高阴影分辨率，认为分辨率越高画面越真实，却忽视了阴影计算对GPU的巨大消耗—阴影本质是通过深度纹理采样实现的，分辨率每提升一倍，GPU的计算量会增加四倍。在动态物体较多的开放世界场景中，若将阴影分辨率设置为2048以上，会导致GPU的像素填充率瞬间饱和，帧率可能从60帧骤降至30帧以下，尤其在移动端设备上，还会伴随严重的发热问题。真正高效的阴影策略，是根据物体的视觉权重与玩家距离进行分层处理：主角、关键道具等近距离交互元素，可将阴影分辨率设置为1024，阴影距离调整至50米，同时开启软阴影（Soft Shadows）增强立体感；中距离的NPC、场景互动物体，阴影分辨率降至512，阴影距离缩短至30米；远景的建筑、植被等非核心元素，可将阴影分辨率降至256或直接关闭实时光影，通过Lightmap烘焙预留阴影痕迹，或使用“软阴影贴图”（Fake Shadow）模拟阴影效果，既节省性能又不破坏画面整体性。间接光照的调整同样需要精准把控，过多的间接光反弹（超过3次）会导致画面过亮、色彩失真，且烘焙时间可能从半小时延长至数小时，占用大量开发时间；而反弹次数过少（少于1次）则会让场景显得灰暗、缺乏层次感，物体之间的光影过渡生硬，影响沉浸感。在实际调试中，需结合场景封闭程度与材质反光属性灵活调整：室内场景空间狭小、材质（如瓷砖、金属）反光较强，间接光反弹2次即可避免过曝，同时将间接光强度衰减系数设置为0.8，让光线过渡更自然；室外开阔场景光线充足，材质（如泥土、布料）反光较弱，可将反弹次数提升至3次，间接光强度衰减系数设置为0.6，模拟阳光照射下的环境反光。光照探针的布局则需遵循“疏密有致”原则，在光照变化剧烈的区域（如门窗边缘、转角、树荫下），将探针间距设置为2-3米，确保动态物体进入该区域时能精准接收光影变化；而在光照均匀的开阔区域（如草原、广场），探针间距可扩大至5-8米，避免探针过多导致的内存浪费与烘焙效率下降。对于大型开放世界场景，还可使用Probe Volume替代传统光照探针，通过体积化的探针分布，实现更细腻的光影过渡，同时支持动态加载与卸载，减少内存占用。此外，阴影的“距离缩放”功能也值得运用，根据玩家视角距离自动调整阴影范围，当玩家远距离移动时，逐步缩小阴影距离，近距离时则扩大，在不影响视觉体验的前提下进一步节省性能。</p><p>后处理效果是画面的“点睛之笔”，但过度使用会成为性能的“枷锁”，尤其在移动端等硬件资源有限的平台，后处理的不合理配置往往是帧率下跌的主要诱因。很多开发者在开发初期会一股脑开启抗锯齿、景深、体积雾、颜色校正、光晕、镜头畸变等所有后处理效果，却未意识到这些效果叠加后对GPU的负载—以移动端为例，同时开启4种以上后处理效果，GPU的渲染耗时可能从10ms增加至25ms，帧率直接跌破30帧，而部分老旧设备甚至会因GPU算力不足出现画面卡顿、掉帧。高效的后处理策略核心是“取舍与分级”，需结合游戏类型、美术风格与目标平台性能精准配置：动作类游戏需优先保证画面流畅度与清晰度，可保留抗锯齿（推荐FXAA或TAA，避免使用MSAA，后者对移动端GPU压力过大）与颜色校正（调整Gamma值、对比度），关闭景深、体积雾等非核心效果，避免画面模糊影响操作精准度；叙事类或解谜类游戏更注重氛围营造，可保留景深（降低采样率至24，影响范围限制在10-30米）与体积雾（减少密度至0.1，影响范围50米），关闭镜头畸变、光晕等冗余效果，既保证焦点突出，又控制性能消耗。不同抗锯齿方案的性能差异也需重点关注：FXAA算法简单，性能消耗最低，但边缘模糊度较高；TAA抗锯齿效果更细腻，适合3D游戏，但需要额外的帧缓冲存储，内存占用略高；MSAA抗锯齿效果最佳，但仅支持前向渲染，且对移动端GPU压力极大，仅建议在PC或主机平台使用。后处理的执行顺序同样影响渲染效率，合理的顺序应遵循“先基础优化，后效果叠加”原则：首先进行抗锯齿处理，解决画面锯齿问题；其次进行阴影修复（如Contact Shadows），弥补实时光影的细节缺失，让物体与地面的接触阴影更自然；再进行颜色校正、对比度调整，统一画面色调，增强视觉冲击力；最后叠加景深、体积雾等氛围效果，避免重复计算导致的性能浪费。此外，后处理的“分级加载”机制能进一步提升适配性，通过检测设备的GPU型号与内存大小，自动调整后处理等级：高端设备开启全量效果，中端设备关闭部分高消耗效果，低端设备仅保留抗锯齿与颜色校正。后处理的分辨率缩放功能也值得重点运用，在低配置设备上，可将后处理渲染分辨率设置为屏幕分辨率的0.7-0.8倍，以微小的画质损失换取15%-20%的帧率提升；在高端设备上则可全开分辨率，甚至开启超采样（1.2倍）提升画面细腻度。同时，后处理的“距离剔除”设置能减少无效计算，比如体积雾仅在50米范围内生效，景深仅对10-30米区间的物体起作用，避免对远处无关物体进行不必要的效果处理。</p><p>纹理资源的优化是渲染性能提升的“隐形抓手”，其核心逻辑是“适配需求、精简冗余”，在保证视觉效果的前提下，最大限度降低内存占用与GPU带宽消耗。很多开发者在制作纹理时存在“分辨率越高越好”的误区，比如将UI图标分辨率设置为1024x1024，将地面纹理设置为4096x4096，却未意识到纹理分辨率每提升一倍，内存占用会增加四倍—一张4096x4096的RGBA32格式纹理，内存占用高达64MB，而移动端游戏的纹理总内存通常建议控制在512MB以内，过多高分辨率纹理会直接引发内存溢出（OOM）或加载卡顿，尤其在切换场景时，可能出现黑屏等待。纹理分辨率的选择需严格适配显示需求：UI图标、按钮等近距离查看的元素，分辨率设置为256x256或512x512即可满足清晰需求，无需超过屏幕分辨率的两倍（如手机屏幕分辨率为1080x1920，UI纹理最大设置为1024x1024即可）；场景中的地面、墙面等大面积纹理，可根据实际显示尺寸设置为1024x1024或2048x2048，通过纹理平铺（Tiling）与Mipmap技术保证远处显示的清晰度，比如地面纹理平铺值设置为4x4，可覆盖更大面积且不损失细节；远景的山体、天空盒等元素，分辨率甚至可降低至512x512，肉眼几乎无法察觉画质损失，却能节省大量内存。纹理压缩格式的选择则需结合目标平台与纹理类型：Android平台优先使用ETC2格式，该格式支持透明通道，且在Android 4.4以上版本全面兼容，能将纹理内存占用减少75%，对于无透明通道的纹理，可使用ETC1格式进一步提升压缩效率；iOS平台适合使用PVRTC格式，压缩效率更高，且对苹果设备的GPU兼容性更佳，支持1bit和4bit压缩模式；PC与主机平台可使用BC格式（如BC3支持透明、BC5适用于法线贴图），在保证画质的同时降低带宽消耗。透明纹理的压缩需格外注意，避免因压缩格式选择不当导致边缘模糊或颜色失真，比如移动端透明UI纹理建议使用ETC2 Alpha格式，而非RGBA32格式。Mipmap的设置需灵活调整：UI纹理、小图标等无需远距离显示的资源，可关闭Mipmap以节省内存（关闭后可减少约33%的内存占用）；场景纹理、模型纹理等需要远距离显示的资源，应开启Mipmap，并将Mipmap层级设置为3-4级，避免远处纹理出现锯齿或模糊，同时Mipmap还能减少GPU在采样远处纹理时的带宽消耗。此外，纹理图集的打包是减少DrawCall的有效手段，将同一场景、同一材质的纹理（如角色的服装、武器纹理，场景中的道具、装饰纹理）打包成一个图集，可避免频繁切换纹理导致的GPU开销，提升渲染效率。打包时需注意：图集尺寸不宜超过2048x2048像素（部分低端设备不支持超过4096x4096的纹理），否则会增加加载时间与内存占用；保证图集中纹理的格式统一（如均为ETC2），避免混合格式导致的压缩失效；使用Sprite Packer工具的“tight packing”模式，减少纹理之间的空白区域，提升图集利用率。同时，纹理的导入设置也需优化，关闭不必要的导入选项（如“Generate Lightmap UVs”“Read/Write Enabled”），仅在需要时开启，避免额外的内存占用与导入时间。</p><p>渲染管线的适配与定制是Unity渲染优化的高阶核心，不同渲染管线（URP、HDRP、内置管线）的性能特性、功能支持与适用场景差异显著，盲目选择只会导致性能与画质的双重失衡，甚至增加开发成本与周期。内置管线虽然兼容性强，能适配老旧设备（如Android 4.0以上、iOS 9以上），但功能相对单一，缺乏先进的光照模型（如PBR）、后处理框架与自定义渲染通道支持，难以满足高品质画面需求，仅适合开发轻量化2D游戏或对画质要求较低的3D游戏；HDRP（高清渲染管线）能提供电影级的渲染效果，支持实时全局光照（RTGI）、体积雾、屏幕空间反射（SSR）、光线追踪等高级特性，但其对硬件要求极高，需要显卡支持DirectX 12或Vulkan，且显存至少4GB以上，仅适用于PC、主机等高端平台，移动端设备几乎无法流畅运行，开发成本也相对较高；而URP（通用渲染管线）则兼顾了性能与灵活性，通过模块化设计可按需启用功能（如是否开启PBR、后处理、阴影），支持多平台适配，是移动端、中端PC等平台的最优选择，也是当前Unity开发的主流管线。</p>]]></description></item><item>    <title><![CDATA[《Unity多语言开发：从文本到体验的深]]></title>    <link>https://segmentfault.com/a/1190000047406284</link>    <guid>https://segmentfault.com/a/1190000047406284</guid>    <pubDate>2025-11-17 23:02:50</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>游戏多语言本地化的深层逻辑，从来不是简单的文本替换，而是语言特性与技术架构的深度耦合，每一种语系的语法规则、表达习惯，都会像无形的脉络，牵动UI布局、资源存储、交互逻辑乃至玩家体验的底层设计。以语系差异为例，黏着语体系中词汇的组合方式往往让句子长度产生极大波动，同样一句技能描述，日语可能比中文多出三成字符，英语的缩略表达又可能缩短近半，泰语的声调变化虽不直接影响字符数量，却会因发音节奏差异需要调整文本分行逻辑，这种差异绝非自动换行就能化解。它要求技术层面在文本渲染之初就建立动态适配模型—既要预留足够的显示空间避免文本溢出，又要通过算法优化避免空间浪费导致的UI失衡，更要兼顾不同语言的阅读节奏，比如长句文本需要拆分显示以减轻视觉疲劳，短句则需紧凑排版保持界面简洁。在实际开发中，这种适配还需要考虑不同语言的字符间距、行高差异，中文方块字的排版密度与西文的字母组合逻辑截然不同，强行套用同一套排版规则只会导致界面杂乱，因此需要为不同语系定制专属的排版参数，比如中文行高设置为字体大小的1.5倍，西文则调整为1.2倍，同时结合用户研究数据优化文本间距，确保阅读流畅度。更重要的是，动态适配模型还需关联玩家行为数据，比如通过分析不同语言版本用户的停留时长、文本阅读速度，持续微调排版策略，让文本显示既符合语言特性，又贴合目标用户的阅读习惯，这种对语言本质的技术响应，才是多语言版本跳出“翻译表层”、触及体验核心的关键，而非仅仅停留在字面意义的转换上。</p><p>文本提取作为多语言开发的基础环节，真正的难点不在于捕捉显式标注的文本，而在于挖掘那些隐藏在功能逻辑、音效、视觉元素中的隐性表达，这些容易被忽视的内容，恰恰是影响本地化完整性的关键。比如技能释放时的音效字幕，不仅要精准匹配音效时长，还要考虑不同语言的发音节奏，避免字幕显示与音效不同步导致的体验割裂；道具描述中的文化隐喻不能直接直译，需要技术层面支持翻译文本的扩展字段，让翻译人员补充语境说明，确保玩家准确理解核心含义；加载界面的进度提示、成就解锁的弹窗文案、甚至错误报告中的提示信息，这些分散在各个功能模块的隐性文本，若不建立统一的提取标准，很容易出现遗漏或重复翻译的问题。文本ID的命名逻辑同样需要深思熟虑，单纯以功能命名极易出现歧义，比如“open”既可能指打开宝箱，也可能指开启菜单，若不结合场景维度进行区分，后续维护和翻译对接都会陷入混乱，因此建立“场景+功能+优先级”的三维命名体系至关重要，例如“mainUI_chest_open_01”明确指向主界面宝箱打开的一级提示文本，既方便技术人员快速定位文本位置，也让翻译人员明确文本的使用语境。此外，字符编码的兼容性问题常被忽略，北欧小语种的特殊字符、东南亚语系的音调符号，都需要提前适配UTF-8-BOM或其他兼容编码格式，避免在不同设备上出现乱码现象；同时要对提取后的文本进行去重处理，通过文本相似度算法识别重复或高度相似的内容，减少冗余翻译工作量。Unity中文本资源的存储格式选择也需谨慎权衡，XML格式结构清晰但加载效率稍低，JSON格式轻便灵活却在复杂文本管理上存在局限，实际开发中可根据项目规模选择混合存储方案，核心文本采用JSON保证加载速度，扩展文本与语境说明采用XML便于维护，同时搭建可视化的文本管理工具，让翻译人员在不改动代码的情况下直接更新文本内容，大幅提升协作效率，避免因格式限制导致后续本地化迭代困难。</p><p>UI适配是多语言版本中最直观的技术挑战，其核心远不止于文本的自动换行，而是要应对不同语言的阅读习惯和文本特性带来的连锁反应，每一处细节的处理都直接影响玩家的视觉体验和操作流畅度。从阅读方向来看，阿拉伯语、希伯来语等属于从右到左的语系，这要求UI布局不仅要翻转文本显示顺序，还要调整控件的排列逻辑—比如导航栏的图标顺序需从右至左排列，下拉菜单的展开方向改为向左弹出，输入框的光标默认位置设置在右侧，甚至弹窗的关闭按钮也需移动到界面左侧，这种调整不能简单地镜像翻转，还要考虑用户的操作习惯，比如从右到左阅读的用户更习惯在界面右侧进行核心操作，因此需要将攻击、跳跃等关键按钮的位置保留在右侧，仅调整辅助控件的顺序。文本膨胀率的预估则需要建立数据模型，不同语言的膨胀系数存在显著差异，德语的名词复合结构常常导致句子长度比中文多出50%，韩语的音节组合方式会让文本占用30%以上的额外空间，泰语的声调符号虽不增加字符数量却会影响行高，这就要求在UI设计之初就根据目标语言的膨胀规律预留足够的显示区域，同时采用动态布局组件，通过设置灵活的锚点和自适应容器，让控件能够根据文本长度自动调整大小和位置，避免出现文本溢出或空间浪费的情况。此外，不同分辨率设备下的文本缩放问题也需重点考虑，小屏手机上，长句文本若单纯缩小字体会导致可读性下降，因此需要结合文本拆分与字体自适应算法，将过长文本按语义拆分为多行，同时根据屏幕尺寸动态调整字体大小，在保证可读性的前提下实现界面的整体协调；大屏设备如平板、PC端，则要避免文本过大导致的界面空洞，通过调整字符间距、行间距以及补充装饰性元素，保持UI的视觉完整性。字体的兼容性同样不容忽视，部分小语种字体在iOS和Android平台上的渲染效果存在差异，比如冰岛语的特殊字母在Android原生字体中可能显示模糊，需要提前嵌入自定义字体包，同时进行跨平台测试，确保文本显示清晰、美观，避免因字体问题影响玩家对游戏内容的理解。</p><p>文化适配与翻译协同的技术实现，是多语言版本跳出“字面翻译”误区的核心，它要求技术架构能够支撑翻译的灵活性和文化适配的深度，让游戏在不同地区都能传递一致的核心体验，同时贴合当地的文化习惯。敬语体系的分级适配是典型场景，日语、韩语等语言中，根据角色身份、玩家等级或交互场景的不同，需要使用不同等级的敬语，比如玩家与NPC对话时，若NPC为皇室角色需使用最高级敬语，与普通村民对话则使用普通敬语，系统通知需采用中性敬语，这就需要技术层面建立敬语分级配置表，将敬语等级与场景ID、角色属性、玩家等级进行关联，让系统能够根据实际情况动态调用对应的翻译文本，而非采用统一的翻译版本。文化禁忌词汇的过滤机制则需要结合技术与数据，通过建立多语言的禁忌词库，涵盖宗教敏感词、地域歧视词、粗俗用语等，在文本加载时进行实时检测，同时支持对接地区政策数据库，根据不同国家和地区的法规动态更新词库，比如部分中东地区禁止提及特定宗教符号，欧洲部分国家对种族相关词汇有严格限制，这些都需要通过技术手段提前规避，避免因文化差异引发的用户反感。翻译文本的校验机制同样重要，技术上可以通过设置多维度检测指标，比如文本长度阈值确保适配UI显示，关键词匹配度检测避免核心玩法信息缺失，语法规则校验减少翻译错误，文化适配度检测通过算法分析文本是否符合目标地区的表达习惯，比如中文的“吉祥如意”在英语中若直译为“lucky and as you wish”会显得生硬，需通过校验机制提示翻译人员调整为更自然的“good luck and all the best”。此外，翻译人员与开发团队的协同效率也需要技术工具支撑，搭建实时同步的文本管理平台，支持多人在线编辑、权限分级管理，翻译人员的修改能够实时同步到开发环境，无需通过文件传输等繁琐方式；同时加入翻译批注功能，让翻译人员可以标注文化背景、语义说明，帮助开发人员理解文本使用场景，避免因理解偏差导致的技术实现错误。版本回溯功能也不可或缺，便于在出现翻译争议或适配问题时快速恢复到之前的稳定版本，减少沟通成本和迭代周期，确保文化适配与翻译工作高效推进。</p><p>动态资源的多语言协同是容易被忽略却至关重要的环节，游戏中的音效、语音、动画、图标等非文本资源，同样需要进行本地化适配，才能让多语言版本的体验更加完整、沉浸。语音资源的适配不仅是简单的翻译录制，还需要考虑不同语言的发音时长与动画口型的匹配度，比如中文语音的节奏相对平缓，英文语音的重音突出且时长可能更短，若直接替换语音而不调整动画帧，会出现口型与语音不同步的违和感。技术上可采用两种解决方案：一是基于语音时长的帧同步调整，通过算法分析语音文件的时长，自动拉伸或压缩对应的动画帧，确保口型与发音精准匹配；二是采用骨骼动画的自适应口型设计，在制作角色动画时预留多组基础口型，根据语音的发音特征动态组合，适配不同语言的发音节奏，减少因语音替换导致的二次开发成本。图标和视觉元素的本地化则需要结合文化符号的差异，比如中国文化中的龙图腾在西方语境中可能带有负面含义，部分中东地区对猪的形象较为敏感，技术上需要支持不同地区的资源包动态切换，在游戏启动时根据用户选择的语言或设备定位，自动加载对应的视觉资源，同时要优化资源加载策略，避免因资源包过大导致的加载延迟。采用“基础资源+语言专属资源”的分包加载模式，基础资源包含通用的模型、场景素材，语言专属资源仅包含该版本对应的图标、语音、音效等，仅在切换语言时下载对应地区的专属资源，既节省存储空间，又提升加载效率。音效的本地化也不容忽视，不同地区的玩家对音效的接受度存在差异，比如东亚玩家更习惯清脆的技能音效，欧美玩家则偏好厚重的打击音效，技术上可以通过音效参数的动态调整，让音效与对应语言的表达习惯相契合，同时支持玩家自定义音效音量、音色，满足不同用户的个性化需求。此外，动画中的文字元素也需要进行本地化处理，比如剧情动画中的匾额、海报文字，需要提前预留文本替换接口，确保切换语言后动画中的文字能够同步更新，避免出现“中文动画配英文文本”的违和场景。</p><p>本地化测试的技术闭环是确保多语言版本质量的最后一道防线，其核心在于构建全面、高效的测试体系，覆盖语言准确性、功能兼容性、体验一致性等多个维度，避免因本地化问题影响游戏的市场表现。自动化测试工具的应用能够大幅提升测试效率，开发基于UI识别的自动化测试脚本，通过图像识别技术检测不同语言版本中文本显示是否正常、控件位置是否偏移、按钮点击是否有效，同时支持多设备、多分辨率的并行测试，比如同时在iOS、Android的不同机型，以及PC、主机等平台上运行测试用例，快速定位跨平台、跨语言的适配问题。脚本中可加入智能断言机制，比如预设文本显示区域的阈值，当文本超出该区域时自动标记为异常，预设控件位置的偏差范围，当控件偏移超过允许值时触发报警，减少人工测试的重复工作量。人工测试则需要聚焦于文化适配和体验细节，组织不同母语背景的测试人员进行沉浸式体验，测试人员需具备目标地区的文化认知，重点关注翻译的自然度、文化符号的适配性、操作逻辑的合理性等，比如检测日语版本中敬语使用是否准确，阿拉伯语版本中UI布局是否符合从右到左的阅读习惯。技术上可以搭建测试反馈平台，让测试人员能够快速提交问题，并关联对应的文本ID、UI控件名称或资源文件路径，同时支持上传截图、录屏，方便开发人员精准定位并修复问题。此外，灰度发布与用户反馈收集也是测试闭环的重要组成部分，通过向小范围目标用户推送多语言版本，比如按地区筛选数千名用户参与测试，收集真实场景下的使用反馈。技术上集成用户行为分析工具，追踪不同语言版本中用户的操作路径、停留时长、报错频率、核心功能使用率等数据，通过数据分析发现潜在的本地化问题，比如某一语言版本中用户在任务界面的停留时长明显过长，可能是由于文本表达晦涩导致玩家无法理解任务要求；某一版本的退出率异常偏高，可能是UI适配不佳影响操作流畅度，进而针对性地进行优化迭代。同时，要建立本地化版本的快速迭代机制，利用热更新技术确保测试中发现的问题能够及时修复，无需用户重新下载完整安装包，修复后通过二次测试验证效果，形成“测试-反馈-优化-再测试”的技术闭环。</p>]]></description></item><item>    <title><![CDATA[有远见的长期主义者 留胡子的饼干_dli]]></title>    <link>https://segmentfault.com/a/1190000047406295</link>    <guid>https://segmentfault.com/a/1190000047406295</guid>    <pubDate>2025-11-17 23:02:14</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>从生成式 AI 的惊艳亮相引起全球科技巨头军备竞赛般的投入开始，整个 AI 行业仿佛被注入了无限的想象力。似乎在宣告着即将出现一个生产力即将被彻底解放、商业模式即将被完全颠覆的光明未来。<br/>微软、谷歌、亚马逊等云巨头纷纷将资本支出的绝大部分押注于 AI 基础设施建设，而无数逐利而来的 AI 初创公司，更是如雨后春笋般涌现试图分一杯羹，全球 AI 领域的投资额也达到了史无前例的高度。<br/>然而，正如任何过热的淘金热最终都会迎来冷静期当技术以超乎预期的速度普及时，潜在的负面效应也以同样的速度被放大，正在悄然侵蚀着行业参与者。<br/>从 " 可选项 " 到 " 必选项 " 的巨额支出<br/>根据奇安信集团对外发布《2024 人工智能安全报告》来看，在 2023 年基于 AI 的深度伪造欺诈便已暴增了 3000%，基于 AI 的钓鱼邮件也增长了 1000%；而内容生成环节更是实现规模化生产。<br/>基于 Stable Diffusion 和 GPT-4 的定制模型，可每小时生成 2000 条伪原创研报、800 段逼真视频。暗网平台 "DarkGPT" 更是提供包月服务，1 万美元即可获得每日 5000 条金融虚假内容的产能。<br/>而且 "AI 滥用 " 的后遗症并不仅仅在社会新闻版块，可以说它已经穿透了科技公司的防火墙直接作用于其财务报表。而金融行业正是这场风暴的中心，当 AI 以假乱真的能力被精准地应用于金融诈骗时，其破坏力可以说是指数级的增长。<br/>据行业估算，2024 年由深度伪造技术引发的各类欺诈造成的全球经济损失已高达 120 亿美元。尤其在监管相对滞后、交易更为匿名的加密货币领域，AI 滥用更是如鱼得水。根据相关的报告也显示 2024 年仅 AI 深度伪造技术全年造成的损失便高达 46 亿美元。<br/>随着 AI 滥用事件的频发，过去模糊的 " 伦理指南 " 正在迅速转变为具有强制约束力的法律条文，而且这种转变直接导致了企业合规成本的急剧攀升。<br/>而且一旦出现违规需要付出的代价更是惨痛的，罚款最高可达全球年营业额的数个百分点或数千万欧元，而且合规也不再是法务部门的单一工作，而是渗透到研发、产品、市场的每一个环节。<br/>这些 " 反噬 " 也并非凭空产生，在 AI 商业化过程中对速度和规模的追求，长期以来压倒了对安全和伦理的考量所以形成了这种 " 原罪 "。因此未来合规成本的升高是不可避免的，而欧盟的《AI 法案》可以说是这一趋势的先行者。<br/>该法案于 2024 年 8 月 1 日正式生效并分阶段实施，着重对高风险的 AI 系统施加了严格的合规要求。而且这不仅仅是一项区域性法规，更可能产生 " 布鲁塞尔效应 " 从而影响全球的 AI 监管格局。<br/>监管的落地也将会直接转化为企业的合规成本。据公开信息推算，仅欧盟 AI 法案便可能导致欧洲企业的 AI 采纳成本增加约 310 亿欧元，并使 AI 投资减少近 20%。而美国联邦贸易委员会也已对 OpenAI 展开调查，谷歌等公司也不得不调整其营销话术，避免被处以巨额罚款。<br/>可以说 " 监管的铁幕 " 正在迫使整个行业从过去 " 快速行动，打破陈规 " 的互联网思维转向一种更为审慎、合规驱动的开发模式。可以说这种转变无疑会减缓创新速度并增加运营成本，对于那些资源有限的中小企业和初创公司构成尤为严峻的挑战。<br/>对 " 信任 " 的侵蚀或许是 AI 滥用最难修复的一种<br/>这源于在激烈的竞争压力下，企业急于抢占市场将产品快速推向用户，所以将风险控制和安全测试置于次要位置。但是这种 " 快速行动并打破规则 " 的心态在 AI 时代尤为危险，因为 AI 技术的潜在破坏力远超以往的软件应用。<br/>并且市场对于 AI 技术的可靠性极度敏感，甚至一次小小的失误都可能引发巨大的信任危机和财务损失。谷歌的 Bard 模型之前便在一次演示中出现事实性错误，竟然导致其母公司 Alphabet 的股价在单日内暴跌 7%，市值蒸发超过 1000 亿美元。<br/>并且随着 AI 投资的巨额支出持续攀升，投资者开始担忧其回报前景，这种悲观情绪导致 Meta、Microsoft、Alphabet 和 Nvidia 等 AI 领域的领军企业股价普遍承压下跌，市场也开始讨论 "AI 泡沫 " 的风险，并开始质疑哪些不计成本的 " 军备竞赛 " 式投资。<br/>更何况大量公司缺乏对 AI 伦理的明确责任归属，高管层面也并未对其有所调整。所以 AI 系统的决策过程像一个 " 黑箱 "，在责任主体模糊的情况下滥用和误用的风险便难以控制。企业内部也未建立有效的问责机制。<br/>但是更深层次的原因在于当前主流生成式 AI 商业模式本身所内含的风险。这些模型依赖于海量数据的投喂，其训练过程难以完全避免偏见和有害信息的吸收。而其强大的生成能力却为恶意利用提供了温床。<br/>因此当商业模式的核心是追求更强大的模型、更广泛的应用时，如果缺乏与之匹配的强大 " 安全刹车 " 系统，滥用就成了可预见的副产品。这种商业逻辑与伦理要求之间的结构性失衡才是导致 " 反噬 " 的根本内因。<br/>所以当企业享受了技术红利带来的增长，如今便也不得不为其模式所伴生的风险 " 买单 "。哪怕科技公司以 " 让世界更美好 " 的叙事推广 AI，公众在实际体验中，也会频繁受到隐私泄露、算法偏见、就业替代、虚假信息等负面影响。<br/>这种落差也导致了广泛的 "AI 焦虑 " 和不信任感。公众普遍认为现有的监管法规不足以应对 AI 带来的社会风险期望政府采取更加果断的行动。这种强大的民意压力也是推动监管机构加速行动的根本动力。<br/>面对公众的呼声和潜在的社会风险，监管机构的介入是必然的。但由于技术发展的速度远超立法速度监管往往表现出一定的滞后性，欧盟 AI 法案便被部分人士认为可能增加企业负担、抑制创新。<br/>全球主要经济体在 AI 领域的竞争，也使得监管变得更加复杂。各国都希望在鼓励创新和防范风险之间找到平衡点但这种平衡点的位置各不相同，因此形成了复杂的国际监管格局给跨国企业的合规带来了巨大挑战。<br/>而且这种外部滥用对整个 AI 行业的声誉造成了 " 连坐 " 效应。即使一家公司本身恪守伦理，也无法完全独善其身，因为公众对 AI 的信任是整体性的。恶意滥用行为如同向池塘中投下的毒药，在污染了整个水域后迫使所有 " 池中生物 " 共同承担后果。<br/>这场危机成为 AI 自我革新的契机<br/>这场 " 反噬 " 带来的阵痛，是 AI 产业从野蛮生长走向规范发展的必经阶段。它正在淘汰那些只想赚快钱、缺乏责任感的 " 玩家 "，筛选出真正有实力、有远见的长期主义者。从长远来看，这也是为 AI 产业的健康、可持续发展所必须付出的代价。<br/>其中最大的机遇在于将 " 信任 " 从一种道德呼吁，转变为一种可量化、可变现的商业资产和竞争壁垒。数据显示近 85% 的客户也更愿意与重视 AI 伦理实践的公司合作，而那些优先考虑伦理和透明度的公司收入增长也更快。<br/>可以说在 AI 产品同质化日益严重的未来，谁能赢得用户的信任谁就能赢得市场。" 负责任的 AI" 将不再仅仅是公关部门的口号，而是必须贯穿于产品设计、开发、部署全流程的核心战略。<br/>谷歌和微软等公司已经开始调整其策略，谷歌选择利用 AI 技术提升广告安全审核的效率，打击欺诈内容；微软则发布了负责任 AI 透明度报告，并推出了 AzureAIContentSafety 等服务，帮助客户构建更安全的 AI 应用。这些举措既是应对风险的防御，也是在构建新的竞争优势。<br/>正是 " 反噬 " 催生了全新的 " 安全即服务 " 市场。随着 AI 滥用风险的加剧企业对 AI 安全审计、风险评估、内容过滤、合规咨询等服务的需求将急剧增长。这为专门从事 AI 安全和伦理治理的科技公司、咨询机构创造了巨大的市场空间。<br/>而科技巨头自身也可以将其内部成熟的安全工具和能力平台化、服务化，开拓新的收入来源。例如，谷歌和微软在内容审核、风险识别方面的技术积累，完全可以转化为对外输出的商业服务。<br/>虽然监管的收紧虽然带来了成本，但也为行业设定了 " 准入标准 "，能够率先满足高标准合规要求的企业将获得更强的市场公信力和竞争优势，从而在未来的市场整合中占据有利地位。这实际上是一种由监管驱动的市场出清和格局优化。weibo.com/ttarticle/p/show?id=2309405233995679137906<br/>weibo.com/ttarticle/p/show?id=2309405233995817549851<br/>weibo.com/ttarticle/p/show?id=2309405233995951767682<br/>weibo.com/ttarticle/p/show?id=2309405233996090179688<br/>weibo.com/ttarticle/p/show?id=2309405233996807405670<br/>weibo.com/ttarticle/p/show?id=2309405233996946079868<br/>weibo.com/ttarticle/p/show?id=2309405233997084229682<br/>weibo.com/ttarticle/p/show?id=2309405233997218447497<br/>weibo.com/ttarticle/p/show?id=2309405233998128873660<br/>从滥用事件的激增，到资本市场的审慎，再到全球监管的收紧，这股 " 反噬 " 之力正在重塑 AI 产业的发展轨迹。它迫使整个行业从过去对技术力量的无限崇拜，转向对技术责任和社会价值的深刻反思。<br/>麦肯锡预测，到 2030 年 AI 将为全球经济创造 13 万亿美元价值。但价值分配取决于我们如何驾驭这头猛兽。未来的竞争，将不仅仅是模型参数和算力大小的竞争，更是治理能力、责任担当和用户信任的竞争。</p>]]></description></item><item>    <title><![CDATA[灵宇宙获 2 亿新融资，要做 AI 世界]]></title>    <link>https://segmentfault.com/a/1190000047406302</link>    <guid>https://segmentfault.com/a/1190000047406302</guid>    <pubDate>2025-11-17 23:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406304" alt="" title=""/></p><p>开发者朋友们大家好：</p><p>这里是 <strong>「RTE 开发者日报」</strong> ，每天和大家一起看新闻、聊八卦。我们的社区编辑团队会整理分享 RTE（Real-Time Engagement） 领域内「有话题的 <strong>技术</strong> 」、「有亮点的 <strong>产品</strong> 」、「有思考的 <strong>文章</strong> 」、「有态度的 <strong>观点</strong> 」、「有看点的 <strong>活动</strong> 」，但内容仅代表编辑的个人观点，欢迎大家留言、跟帖、讨论。</p><p>本期编辑：<a href="https://link.segmentfault.com/?enc=QeQ2YuFoRoQz%2FBz%2F2ewZZg%3D%3D.kpc04s7lDJ3MB3oQw3ZoVPEVCldJ6MqIPKZv9dgppR4%3D" rel="nofollow" target="_blank">@鲍勃</a></p><h2>01 有话题的技术</h2><p><strong>1、 Vogent 推出 AI 语音智能体向导：描述即生成，分钟级部署语音智能体</strong></p><p>Vogent 发布了 Voice Agent Wizard，旨在通过简化语音 AI 应用的开发流程，大幅缩短开发周期并降低技术门槛。用户只需提供描述和相关文件，即可在短短几分钟内生成一套完整、可部署的语音智能体。</p><ul><li><strong>描述驱动生成：</strong> 借助自然语言描述语音智能体的功能和目标，并上传少量参考文件（如对话记录），AI 便能自动完成构建。</li><li><strong>海量数据训练：</strong> 该向导基于对数千个真实语音智能体设计过程的学习，深刻理解语音 AI 在实际生产环境中的运作原理。</li><li><strong>全流程自动化：</strong> AI 不仅能自动选择合适的架构、优化参数、生成系统提示，还能预测和处理潜在的边缘情况，实现全流程自动化。</li><li><strong>开发周期显著缩短：</strong> 过去需要数周甚至数月的试错和配置工作，现在仅需几分钟即可完成，从而显著加速产品上市时间。</li><li><strong>赋能快速迭代：</strong> 用户可以即时测试新的应用场景，并根据用户反馈进行实时迭代，将精力集中于产品本身，而非底层基础设施。</li></ul><p>Vogent 的 AI 语音智能体向导现已上线，用户可通过 app.vogent.ai 访问并开始使用。</p><p>(<a href="https://link.segmentfault.com/?enc=Ur9MJYX3MO%2BBgTimujuDig%3D%3D.LWu4c%2BM7zWISCHyrTal6w2KbCIHgcVYZVMBGfEtabKQ%3D" rel="nofollow" target="_blank">@Y</a> Combinator)</p><p><strong>2、Talo 被 Palabra.ai 收购，整合打造全场景 AI 实时语音翻译平台</strong></p><p>Talo 在被 Palabra.ai 收购后，正式整合并发布了其全方位的 AI 实时语音翻译平台。此次整合旨在打破语言障碍，提供从视频通话到直播、线下活动及 API 集成的无缝跨语言沟通解决方案。</p><ul><li><strong>全场景覆盖：</strong> Talo 现已支持视频通话、网络研讨会、线下活动、直播广播以及通过 API 集成，满足多样化的翻译需求。</li><li><strong>核心技术升级：</strong> 实时视频通话翻译能力大幅提升，用户体验更为自然流畅。</li><li><p><strong>新增功能：</strong></p><ul><li>Palabra Events 支持网络研讨会和线下活动的实时翻译。</li><li>Palabra Broadcaster 提供直播广播的即时语音翻译。</li></ul></li><li><strong>开发者平台：</strong> 推出 API 平台，赋能开发者构建自定义的翻译应用。</li></ul><p>(@ Producthunt)</p><h2>02 有亮点的产品</h2><p><strong>1、Proxis：AI 邮件智能体，以你的语调风格撰写邮件</strong></p><p>Proxis 推出一款 AI 邮件智能体，能够连接用户的知识库和收件箱，模仿其邮件风格和语调，自动草拟并发送邮件。该工具旨在解决日益增长的邮件数量和信息处理难题，尤其适用于需要高强度邮件沟通的销售、运营及创始人等用户。</p><ul><li><strong>个性化邮件草拟：</strong> Proxis 能够学习用户的语调和风格，生成听起来「像你本人」的邮件回复。</li><li><strong>语境优先：</strong> 可连接 CRM、Notion、Drive、Slack、帮助文档以及历史邮件，确保回复内容准确且符合品牌调性。</li><li><strong>智能发送机制：</strong> 仅在 AI 拥有高置信度时自动发送邮件，其他回复则保留在草稿箱供用户审核。</li><li><strong>持续学习：</strong> 用户的每一次发送和反馈都会帮助 AI 更好地学习和适应其沟通方式。</li><li><strong>规则配置：</strong> 用户可配置特定的规则来指导 AI 的行为。</li></ul><p>(<a href="https://link.segmentfault.com/?enc=jksukqSSAX64q43T9WN7cA%3D%3D.uZBQ8pO16zuSSEPxq1UaViNpL3feXCihOUEHAbrfGx4%3D" rel="nofollow" target="_blank">@Y</a> Combinator)</p><p><strong>2、Willow 发布 iOS 智能语音键盘，实现「边说边改」的无缝输入体验</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406305" alt="" title="" loading="lazy"/></p><p>Y Combinator 孵化的初创公司 Willow 发布了一款 iOS 智能语音键盘应用，支持在所有 App 中进行高效的语音输入。与传统语音转录工具不同，Willow 将完整的键盘与语音输入集成，解决了语音输入后「编辑困难」的核心痛点，旨在提供一种更高效、更自然的移动端输入方式。</p><ul><li><strong>全功能键盘集成：</strong> Willow 的最大优势在于它是一个完整的键盘，而非单纯的语音输入面板。用户可以在语音转录后，无需切换键盘，直接进行光标移动、文字修改和输入，极大地提升了编辑效率。这一点是其与竞品 Wispr Flow 的核心差异。</li><li><strong>基于 LLM 的个性化引擎：</strong> 该应用支持超过 100种语言，并允许用户自定义专业词汇和写作风格（例如，区分工作、邮件、即时消息等场景）。其技术栈基于一系列模型，并重点调优了基于 Meta Llama 模型的文本到文本（text-to-text）管线，以实现精准的格式化与个性化。</li><li><strong>强劲的商业势头：</strong> 自发布以来，Willow 的用户量实现了每月 50% 的增长，并已获得包括 Uber、Heidi Health 等在内的企业客户。公司已获得由 Box Group、Y Combinator 以及 Reddit 联合创始人 Alexis Ohanian 等知名投资方提供的 450 万美元融资。</li><li><strong>超越听写的长期愿景：</strong> 在桌面端，Willow 还提供名为「Hey Willow」的语音助手，可以执行更复杂的指令，如用用户的语气风格撰写邮件回复。其长期目标是构建一个能通过语音控制计算机的下一代人机交互界面。</li></ul><p>(@TechCrunch)</p><p><strong>3、灵宇宙获 2 亿新融资，要做 AI 世界操作系统</strong></p><p>「暗涌 Waves」获悉，灵宇宙近日完成 2 亿元 PreA 轮融资，由上海国际集团旗下国方创新、国泰海通、广发信德、滴滴出行、拉卡拉旗下考拉基金、润建股份等金融机构和上市公司参投，老股东超额追投。</p><p>「如果 AI 要进入生活，它一定得从家庭和随身场景开始理解人，而全球化是这类产品的自然方向。」顾嘉唯告诉「暗涌 Waves」，Luka 时代资本火热，大家都在冲机器人。但那时的底层模型没准备好、硬件也太贵，做终端就是在「逆风走钢丝」。现在完全不一样了，模型成熟了、基础成本降下来、交互方式变了，「AI 开始真正进入物理世界。」</p><p>基于这样的判断，大模型到来后顾嘉唯创立灵宇宙，这并非简单的二次创业，而是将其坚守十余年「万物有灵」的核心理念置于大模型时代的新基座上重新出发。不再只是单一爆款产品，目的打造一个面向下一代 AI 终端的操作系统生态，让机器真正具备感知、共情与主动交互的 「灵性」。</p><p>但 AI 硬件并不是顾嘉唯的终极目标。他想把验证有效的模型推向规模化，不再只是做陪伴机器，而是构建一个能在全球不同家庭中运行的人机交互系统------从 AI 伴读的单点突破，到面向全球家庭的具身智能系统化实验。</p><p>灵宇宙的关键引擎在于其自主研发的 LingOS 交互操作系统，而 LingOS 的核心价值在于其可迁移性------它不是一个被绑定在特定硬件上的固件，而是一个能够注入不同形态终端（从随身设备到家用消费机器人）的「AI 灵性」及「机器人灵魂」，通过持续收集的真实世界交互数据不断进化。在他的理想中，LingOS 不会局限于单一场景的智能响应，而是要成为跨越地域、文化与年龄的 「通用 AI 灵性接口」。</p><p>在顾嘉唯看来，「硬件只是接口，系统才是核心。」而从发展路径上看，系统的价值需要在更大市场------尤其是海外市场被验证和放大。</p><p>（<a href="https://link.segmentfault.com/?enc=i3fSBRny18YUGC6QOhInAw%3D%3D.13ozBx6CwHnTYJfNLOHucGCshUR3KtBVzcaO8dBmJcMTakkUvPCKdsVssXHI%2FsjF" rel="nofollow" target="_blank">@暗涌</a> Waves）</p><p><strong>4、前云鲸产品副总裁李阳创业，聚焦陪伴具身赛道</strong></p><p>雷峰网·鲸犀独家获悉，前云鲸智能产品副总裁李阳（Roger）离职后创业，成立公司「Ouropia」，主攻家庭陪伴具身领域，该项目将聚焦内容情绪消费与物理实体陪伴，通过深度情感交互实现 Physical AI 的家庭场景进入问题。</p><p>目前，李阳的创业项目已完成种子轮融资，获数千万美元融资。据了解，Ouropia 的首款产品将通过具身方式实现深度情绪交互和内容消费，产品将面向北美市场，预计客单价将处于较高区间。</p><p>另据雷峰网了解，Ouropia 创始团队包括来自大疆、影石、字节、清华的机器人和认知领域专家，以及知名产品设计团队，是一支磨合多年的成熟产品工程团队。李阳早年曾在大疆担任动力系统专家，后相继负责 Mavic 系列产品、教育机器人产品及自动驾驶相关业务，于 2021 年离开大疆加入云鲸。在云鲸期间担任产品副总裁，负责产品设计、研发工程管理、质量等工作，在团队中具有重要影响力。</p><p>（@雷峰网）</p><h2>03 有态度的观点</h2><p><strong>1、 李彦宏回应百度总是「起大早赶晚集」：不能指望所有创新都成功，创新的特点就是大多数会失败</strong></p><p>11 月 16 日消息，在 2025 百度世界大会后，百度创始人李彦宏接受媒体采访。在采访中，李彦宏谈到了一个外界非常关注的话题：「当然，别人说我们『起大早赶晚集』，这不冒犯，一些也是事实。甚至我在内部也让大家研讨说，我们为什么会『起大早赶晚集』。」</p><p>李彦宏表示：「我们不能够指望所有的创新尝试都是成功的，创新的特点就是，大多数创新会失败，我们要接受这样一个现实。所以百度内部可能起过十个不同的创新项目，如果九个都失败了，我认为是很正常的，它就应该失败，从概率上讲就应该失败，如果有一个成功了，那就非常好。」</p><p>李彦宏还说：「另外一方面，百度这些年有做成的、有做失败的。如果有什么规律性的话，当这件事的成败几乎完全取决于它技术的先进性的时候，我们的成功概率就会大不少，尤其是这个技术需要很多很多年的投入和迭代，那我们成功的概率就会更大一些。」</p><p>（@潇湘晨报）</p><h2>04 社区黑板报</h2><p>招聘、项目分享、求助......任何你想和社区分享的信息，请联系我们投稿。（加微信 creators2022，备注「社区黑板报」）</p><p><strong>1、招聘实习生丨加入我们，共建 RTE 开发者社区</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406306" alt="" title="" loading="lazy"/></p><p><strong>RTE 开发者社区·运营实习生（实时互动 / Voice AI 方向，本招聘长期有效）</strong></p><p><strong>地点：北京·朝阳区望京南/上海·杨浦区五角场</strong></p><p><strong>这份实习将给你带来：</strong></p><p>**产品与技术成长：**深入学习垂类 AI 产品从技术到落地的全生命周期，构建全面的产品视角。</p><p>**社区运营实战：**与高潜力的开发者和创业者深度交流，共同探索行业前沿；并亲身体验顶级 AI 大会，拓展行业视野。</p><p><strong>【你的职责】</strong></p><p><strong>Voice AI / RTE 情报官：</strong> 每日关注 Voice AI /实时互动领域的最新动态，提炼整理并分享行业洞察，定期撰写学习笔记，帮助团队和社区保持信息前沿。</p><p><strong>社区连接者：</strong> 负责 RTE 领域开发者、初创企业等核心群体的社群运营，主动建立并深化联系，鼓励并协助他们融入社区，共同维护社区的活力与生态。</p><p><strong>活动协作者：</strong> 深度参与 RTE Open Day、Meetup、Dev Talk 等线上线下活动的全流程运营，包括前期策划、中期执行、后期复盘，从实践中提升组织和协调能力。</p><p><strong>行业洞察者：</strong> 协助开展 RTE 相关行业及应用场景调研、产品竞争力分析，整理相关资料，形成对业务的深入理解和独到见解。</p><p><strong>【希望你】</strong></p><p>1.本科及以上学历，商业、技术、产品、媒体专业或经验背景优先，具备良好英文能力；</p><p>2.对 RTE / Voice AI 有浓厚兴趣和求知欲；具备优秀的信息收集与整合能力，乐于快速学习新事物，并具备严谨的逻辑思维。</p><p>3.能保证每周至少 4 天的工作时间，持续 3 个月以上。</p><p><strong>【薪资】</strong></p><p>180-220 元/天</p><p><strong>【投递方式】</strong></p><p>实习地点北京或上海，请将简历发送至 <a href="mailto:rtedevcommunity@gmail.com" target="_blank">rtedevcommunity@gmail.com</a> ；邮件标题请注明：【社区运营实习-姓名-学校-毕业年份-到岗日期-城市】</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406307" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047406308" alt="" title="" loading="lazy"/></p><p><a href="https://link.segmentfault.com/?enc=cF9Ps%2BYnpt%2F5CARsTqINWQ%3D%3D.yyvD26vluuLvojYJmuEf6AxbShf3ilE2KDTf0n9IHos%3D" rel="nofollow" target="_blank">阅读更多 Voice Agent 学习笔记：了解最懂 AI 语音的头脑都在思考什么</a></p><p><strong>写在最后：</strong></p><p>我们欢迎更多的小伙伴参与**「RTE 开发者日报」**内容的共创，感兴趣的朋友请通过开发者社区或公众号留言联系，记得报暗号「共创」。</p><p>对于任何反馈（包括但不限于内容上、形式上）我们不胜感激、并有小惊喜回馈，例如你希望从日报中看到哪些内容；自己推荐的信源、项目、话题、活动等；或者列举几个你喜欢看、平时常看的内容渠道；内容排版或呈现形式上有哪些可以改进的地方等。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406309" alt="" title="" loading="lazy"/></p><p>素材来源官方媒体/网络新闻</p>]]></description></item><item>    <title><![CDATA[TOON：专为 LLM 设计的轻量级数据]]></title>    <link>https://segmentfault.com/a/1190000047406174</link>    <guid>https://segmentfault.com/a/1190000047406174</guid>    <pubDate>2025-11-17 22:02:19</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>这几天好像这个叫 TOON 的东西比较火，我们这篇文章来看看他到底是什么，又有什么作用。TOON 全称 Token-Oriented Object Notation，它主要解决的问题就是当你把JSON 输入给LLM 的时候，token 消耗太高了。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047406176" alt="" title=""/><br/>一个长 JSON 数组扔进模型token 计数直接起飞。因为引号、大括号、重复的键名，到处都是这些没什么实际意义的字符，而TOON 就是从这个痛点出发，它不是要干掉 JSON，而是说：既然主要是语言模型，那些装饰性的字符完全可以省掉。</p><h2>Token数对比</h2><p>常规 JSON 长这样：</p><pre><code> [  
   { "id": 1, "name": "Deep", "role": "admin" },  
   { "id": 2, "name": "Hub", "role": "user" }  
 ]</code></pre><p>TOON 版本：</p><pre><code> users[2]{id,name,role}:  
   1,Deep,admin  
   2,Hub,user</code></pre><p>第一眼看上去像半成品草稿。但逻辑其实很清晰——字段名只写一次，声明有多少行，然后直接按表格形式写数据，我们直接可以说这个算是CSV的一个进化版。</p><p>有一个不严谨的测试JSON 格式的 token 数基本是 TOON 的两倍。差距就这么大。</p><h2>TOON</h2><p>JSON 的问题是结构不变的情况下还在重复。而TOON的想法是既然结构本来就很明显了，没必要每条记录都写一遍。</p><p>另外就是该有得支功能还是都有，比如说嵌套，使用类似 YAML 的缩进结构来处理嵌套对象：</p><pre><code> user:
   id: 123
   email: ada111@666.com
   metadata:
     active: true
     score: 4.5</code></pre><p>简单得嵌套跟YAML 基本一样，如果把嵌套和列表放在一起就是这样：</p><p>比如说这个json</p><pre><code> {
  items: [
    {
      users: [
        { id: 1, name: 'Deep' },
        { id: 2, name: 'Hub' }
      ],
      status: 'active'
    }
  ]
 }</code></pre><p>转换完以后是这样的</p><pre><code> items[1]:
   - users[2]{id,name}:
     1,Deep
     2,Hub
     status: active</code></pre><p>这完全就是YAML 和CSV的缝合怪，不过倒是把JSON冗余的标点去掉了。</p><p>不过根据官网的评测token的确是减少了很多<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047406177" alt="" title="" loading="lazy"/></p><h2>局限性</h2><p>对于YAML来说深层嵌套的数据结构一直是个问题，而TOON也一样，如果层次太多会比较乱。而且同一个列表里如果对象结构不一致，也不太好处理。但是如果只是为了优化 LLM prompt，TOON还真的确实挺实用。</p><h2>总结</h2><p>适合用 TOON 的情况：</p><ul><li>往模型里塞大量重复结构的数据</li><li>token 成本是主要考虑因素</li><li>数据结构相对规整</li></ul><p>继续用 JSON 的情况：</p><ul><li>写 API 接口</li><li>需要长期存储</li><li>数据结构复杂或者不规则</li></ul><p>所以TOON并不是什么颠覆性的东西。更像是有人把 JSON 里那些多余的部分清理掉，然后说：跟模型交互的时候，可以试试这个。</p><p>github地址：</p><p><a href="https://link.segmentfault.com/?enc=5toVUX%2BwxAJfSlU30fTAng%3D%3D.4GTYXlrrTVkxbaoXEjPdX5dm%2BaaTidyxrXC%2Bmm7C3nAv6Zkks%2F6x397obn18vq3pb9NpOjZu42FcBnyaBjlo9Q%3D%3D" rel="nofollow" target="_blank">https://avoid.overfit.cn/post/95264c51c6544c139b198c31fe4127ab</a></p>]]></description></item><item>    <title><![CDATA[AI 面试智能体：降本增效的招聘新利器 ]]></title>    <link>https://segmentfault.com/a/1190000047406181</link>    <guid>https://segmentfault.com/a/1190000047406181</guid>    <pubDate>2025-11-17 22:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>AI 面试智能体：降本增效的招聘新利器<br/>当预算遭遇腰斩：AI面试如何成为HR降本增效的“破局利器”？<br/>培训预算削减的背后，是时候重新审视招聘的真正成本。<br/>年底复盘，不少HR对着培训报表愁眉不展：预算花了近百万，员工满意度刚过及格线，业务部门还抱怨“培训没用”。降本增效的要求之下，培训预算首当其冲被压缩。问题真的出在培训本身吗？或许，根源在于招聘环节——选错人，才是企业最大的成本浪费。</p><p>01 培训无效的背后：选错人是最昂贵的成本<br/>当业务部门抱怨“培训没用”时，他们真正抱怨的是什么？是培训内容不够好，还是培训对象选错了？<br/>一位资深HR总监坦言：“我们花大价钱培训员工，却发现有些人根本不适合岗位。这种错配的成本，远超培训预算本身。”传统招聘依赖HR和专业面试官的主观判断，难免出现偏差。而AI面试智能体正将招聘从“凭感觉”推向“凭数据”的科学决策时代。<br/>02 精准度革命：从“参考意见”到“决策依据”<br/>招聘的核心是“选对人”，AI面试智能体将“精准度”做到了行业领先水平。<br/>其打分结果不仅通过效标效度与重测稳定信度的双重心理学指标考验，更经得起一对一的“背靠背”人机对比实验验证。这意味着，AI面试智能体的评估结果不再仅是参考意见，而是可直接作为招聘决策的依据。相关AI面试智能体的迭代版本发布，标志着其在该领域已达到国际领先水平，这是经得起验证的技术实力体现。<br/>03 面试环节的精准进化：四大技术突破<br/>AI面试智能体的“精准”体现在每一个招聘环节的技术突破上：<br/>•一问多能：一道题目即可同步评估多项胜任力，无缝衔接HR初筛与技术复试，评估效率提升50%以上。<br/>•自由追问：能根据候选人的回答即时生成针对性问题，如同资深面试官般抓住关键信息，避免遗漏核心能力。<br/>•简历深度挖掘：自动抓取简历中的关键信息与模糊点，生成递进式提问，既杜绝信息造假，也避免因HR主观疏忽错过优质候选人。<br/>•全维度考察：既能评估沟通、协作等通用胜任力，也能针对编程、算法、工程、财务等专业领域精准出题，在解放HR面试官的基础上进一步解放专业面试官。<br/>04 候选人体验升级：招聘即品牌传播<br/>传统AI面试常因“机械、生硬”让候选人体验不佳，进而损害雇主品牌。AI面试智能体则把“拟人化交互”做到了极致，让面试成为雇主品牌的加分项。<br/>•懂情绪的智能交互：精准捕捉候选人的语速、情绪与潜台词，像真人HR一样引导候选人充分展现实力，避免因紧张发挥失常。<br/>•无断点流畅体验：无需手动点击“开始/结束答题”，系统自动识别回答状态并衔接下一问题，全程如面对面交流般自然。<br/>•沉浸式视觉体验：通过语音与口型匹配精度的大幅提升，嘴型开合与语速节奏精准同步，彻底告别“纸片人”式的疏离感。<br/>•多轮对话答疑：允许候选人随时提问，AI能准确解答职位信息、公司福利等问题，让候选人更深入了解企业，提升入职意愿。<br/>05 全流程自动化：从识人到沟通的一体化执行<br/>AI人才寻访智能体是一款具备简历解读、精准匹配、有效沟通能力的AI招聘工具。<br/>它并非单一功能的自动消息助手，而是一套完整的招聘自动化系统，可在无需人工干预的情况下，独立完成从简历筛选、初步沟通、简历回收到系统同步的完整流程。从30-60秒完成初始化，到自动筛选简历、动态沟通、全覆盖回复，再到系统同步，AI人才寻访智能体实现了招聘初筛阶段的全面自动化，提升招聘效率10到100倍。<br/>培训预算削减不一定是危机，也可能是转型的契机。当传统的培训投入回报率持续走低，聪明的HR已经开始将资源前置到招聘环节——从源头上确保“选对人”。与其在培训无效后追悔莫及，不如在招聘环节精准筛选。毕竟，选择比努力更重要，选对比选择更关键。</p>]]></description></item><item>    <title><![CDATA[SQL Server 2022 企业版I]]></title>    <link>https://segmentfault.com/a/1190000047406047</link>    <guid>https://segmentfault.com/a/1190000047406047</guid>    <pubDate>2025-11-17 21:01:57</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>​</p><p>一、准备工作</p><ol><li><p><strong>确认系统要求</strong></p><ul><li>你电脑得是 <strong>Windows 10/11 专业版/企业版，或者 Windows Server 系统</strong>，而且必须是 <strong>64位</strong>的。</li><li>最好有 <strong>管理员权限</strong>（就是能安装软件那种账号）。</li></ul></li><li><p><strong>挂载 ISO 文件</strong>（就是打开这个光盘镜像文件）</p><p>方法：</p></li><li><ul><li><p>安装包下载：<a href="https://link.segmentfault.com/?enc=BVcmb2k72%2BXxnwhgPMQEfQ%3D%3D.yC5ptv7wf7YtQkAqtN9zcrcC1PxL1DCLAIfnRJFNSHKl%2Bls6427XcZuqHj2UBujw" rel="nofollow" title="https://pan.quark.cn/s/d83b749b87e5" target="_blank">https://pan.quark.cn/s/d83b749b87e5</a></p><p><strong>双击这个 ISO 文件</strong>，Windows 一般会自动挂载，就像插了个虚拟光盘。</p></li><li>或者右键点击 ISO 文件 → 选择  <strong>“装载”</strong> 。</li><li>挂载后，你会在  <strong>“此电脑”</strong> 里看到一个 <strong>虚拟光驱</strong>，点进去就能看到里面的安装文件。</li></ul><blockquote>如果你电脑不支持直接双击挂载，可以用压缩软件（比如 WinRAR、Bandizip）打开，或者下载个 <strong>虚拟光驱工具</strong>（比如 Daemon Tools）来挂载。</blockquote></li></ol><ul><li><ul><li>*</li></ul></li></ul><h3>二、开始安装</h3><ol><li><p><strong>进入安装界面</strong></p><ul><li>打开挂载后的虚拟光驱，找到并双击运行 <strong>setup.exe</strong>（一般就在根目录，或者 setup 文件夹里）。</li></ul></li><li><p><strong>选择安装类型</strong></p><ul><li><p>第一次打开后，一般会看到几个选项，比如：</p><ul><li><strong>全新 SQL Server 独立安装</strong></li><li><strong>添加功能到现有安装</strong></li></ul></li><li>你是新安装，就选  <strong>“全新 SQL Server 独立安装”</strong> 或者类似选项（比如 “安装” → “全新 SQL Server 独立安装”）。</li></ul></li><li><p><strong>安装程序支持规则检查</strong></p><ul><li>它会先检查你的电脑是否符合安装条件（比如有没有缺 .NET、权限够不够等）。</li><li>如果有 <strong>报错或警告</strong>，按照提示解决一下，比如安装缺的组件，再重新运行 setup。</li></ul></li><li><p><strong>输入产品密钥（如果有）</strong></p><ul><li>如果你有正版的 <strong>产品密钥（25位字符）</strong> ，就输入；如果没有，可能可以选择  <strong>“评估版”</strong> 或  <strong>“开发版”</strong> （免费试用一段时间）。</li><li>企业版通常需要密钥，如果你没有，看看你拿到的这个 ISO 是否包含授权，或者联系提供者。</li></ul></li><li><p><strong>接受许可条款</strong></p><ul><li>勾选  <strong>“我接受许可条款”</strong> ，然后下一步。</li></ul></li><li><p><strong>选择安装功能</strong></p><ul><li><p>这里会让你选要安装哪些功能，比如：</p><ul><li>数据库引擎服务（必须装，这是核心）</li><li>Analysis Services、Reporting Services（看你需要不需要）</li><li>客户端工具等</li></ul></li><li>一般新手或普通用途，<strong>数据库引擎服务</strong>是必选的，其他按需勾选。</li><li>选好后，点下一步。</li></ul></li><li><p><strong>设置实例名称</strong></p><ul><li>你可以选 <strong>默认实例</strong>（就是用电脑名作为实例名），或者自己起个 <strong>实例名</strong>（比如叫 MSSQLSERVER2022）。</li><li>大多数情况选 <strong>默认实例</strong>就行，下一步。</li></ul></li><li><p><strong>服务器配置</strong></p><ul><li>设置 <strong>SQL Server 服务用的账号</strong>，比如数据库引擎服务要用哪个用户启动。</li><li>一般选  <strong>“内置账户”</strong> ，比如 <strong>NT AUTHORITY\NETWORK SERVICE</strong>或 <strong>Local System</strong>就可以（适合个人或测试环境）。</li><li>如果是公司正式环境，可能要专门设置域账号，那得找管理员。</li><li>然后点下一步。</li></ul></li><li><p><strong>数据库引擎配置</strong></p><ul><li><p>选择 <strong>身份验证模式</strong>：</p><ul><li><strong>Windows 身份验证模式</strong>：只允许 Windows 用户登录。</li><li><p><strong>混合模式（推荐）</strong> ：可以用 Windows 用户，也可以用 SQL Server 自己的用户名和密码登录。</p><ul><li><p>如果你选混合模式，<strong>一定要设置一个 SA 密码（SQL 管理员账号密码）！</strong></p><ul><li>密码要设得 <strong>复杂一点</strong>（比如字母+数字+符号，别太简单）。</li></ul></li></ul></li></ul></li><li>把你的 <strong>Windows 用户添加为 SQL 管理员</strong>（一般会自动加当前用户，也可以手动加）。</li><li>然后点下一步。</li></ul></li><li><p><strong>继续后续配置页面</strong></p><ul><li>接下来可能还有 <strong>Analysis Services、Reporting Services</strong>的配置（如果你选了安装这些功能），按提示设置就行，一般保持默认也可以。</li><li>如果没有安装这些额外功能，可能直接跳到下一步。</li></ul></li><li><p><strong>准备安装</strong></p><ul><li>它会列出你要安装的所有功能和配置，<strong>检查一遍，没问题的话点“安装”</strong> 。</li></ul></li><li><p><strong>等待安装完成</strong></p><ul><li>这一步会真正开始安装，时间可能有点长，耐心等等。</li><li>安装过程中别关电脑或关窗口。</li></ul></li><li><p><strong>安装完成</strong></p><ul><li>安装成功后，会提示  <strong>“安装已完成”</strong> 。</li><li>你可以点  <strong>“关闭”</strong> ，然后重启电脑（建议，但不是必须）。</li></ul></li></ol><ul><li><ul><li>*</li></ul></li></ul><h3>三、安装后检查</h3><ol><li><p><strong>打开 SQL Server Management Studio（SSMS）</strong></p><ul><li>这是一个管理 SQL Server 的工具，通常需要<strong>单独下载</strong>（微软官网有免费版本）。</li><li>下载地址（可以去微软官网搜：<strong>SQL Server Management Studio 19 或 18</strong>）。</li><li><p>安装后，打开 SSMS，用以下方式连接：</p><ul><li>服务器名称：写你的电脑名 或 （如果是默认实例，就写 <code>.` 或 电脑名；如果是命名实例，写</code>电脑名\实例名`）</li><li><p>身份验证：</p><ul><li>如果你选了 <strong>Windows 身份验证</strong>，就直接用你的 Windows 账号登录；</li><li>如果你选了 <strong>混合模式</strong>，就选 <strong>SQL Server 身份验证</strong>，输入 <strong>SA 用户名 和 你设置的密码</strong>。</li></ul></li></ul></li></ul></li><li><p><strong>测试连接</strong></p><ul><li>能连上，说明 SQL Server 已经装好了，并且正常运行！</li></ul></li></ol><p>​</p>]]></description></item><item>    <title><![CDATA[申威SW64系统安装docker-ce-]]></title>    <link>https://segmentfault.com/a/1190000047406095</link>    <guid>https://segmentfault.com/a/1190000047406095</guid>    <pubDate>2025-11-17 21:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>​一、准备工作</p><ol><li><p><strong>确认系统架构是申威（SW64）</strong></p><ul><li>一般这个包就是专门为申威64位系统准备的，比如基于 <strong>银河麒麟操作系统 KY10</strong>的申威版。</li><li><p>你可以通过命令查看系统信息：</p><pre><code>uname -m</code></pre></li></ul></li></ol><pre><code>  

    如果显示是 `sw_64`或类似申威相关的，那就没问题。
</code></pre><ol><li><p><strong>下载 Docker RPM 包</strong></p><ul><li><strong>docker-ce-19.03.14.ce-3.ky10.sw_64.rpm安装包下载：</strong><a href="https://link.segmentfault.com/?enc=VQrE4uxYUeNkrytUYhvPNg%3D%3D.LvvXHobiS9K%2BExuTvugXkRvngYRMLTapQXNQQ%2BN%2FUC32MyNLgY3NcRR7mSTsQLbH" rel="nofollow" title="https://pan.quark.cn/s/d83b749b87e5" target="_blank">https://pan.quark.cn/s/d83b749b87e5</a></li><li>如果还没有，得从官方或可信渠道下载这个 <strong>针对申威架构的 RPM 包</strong>，一般后缀是 <code>.sw_64.rpm</code>，说明是为申威编译的。</li></ul></li></ol><h3>二、安装 Docker</h3><ol><li><p><strong>使用 rpm 命令直接安装</strong></p><ul><li><p>打开终端，切换到存放这个 rpm 包的目录，比如你放在了 <code>/home/yourname/</code>下，可以运行：</p><pre><code>cd /home/yourname/</code></pre></li></ul></li></ol><pre><code>-   然后执行安装命令：

    ```
    rpm -ivh docker-ce-19.03.14.ce-3.ky10.sw_64.rpm
    ```

    ![](&lt;&gt; "点击并拖拽以移动")

    -   `-i`是安装
    -   `-v`是显示详细信息
    -   `-h`是显示进度条
</code></pre><ol><li><p><strong>如果提示依赖问题</strong></p><ul><li>某些依赖包可能没装，比如 <code>container-selinux</code>、<code>docker-ce-cli</code>等。</li><li>如果你遇到类似 “依赖缺失” 的报错，可以尝试手动下载这些依赖的 <strong>申威版 RPM 包</strong>，然后一起安装。</li><li><p>或者用这个命令自动解决依赖（如果你的系统支持 yum/dnf）：</p><pre><code>rpm -ivh --nodeps docker-ce-19.03.14.ce-3.ky10.sw_64.rpm</code></pre></li></ul></li></ol><pre><code>    ⚠️ 注意：`--nodeps`是忽略依赖检查，**可能会导致功能不正常，尽量先解决依赖**。

&gt; 如果你系统里有 `yum`或者 `dnf`，并且有对应的申威源，那用 `yum localinstall docker-ce-xxxx.rpm`会更好，它会自动处理依赖关系。


</code></pre><h3>三、启动 Docker</h3><p>安装成功后，启动 Docker 服务：</p><pre><code>systemctl start docker</code></pre><p>设置开机自启（可选）：</p><pre><code>systemctl enable docker</code></pre><h3>四、检查是否安装成功</h3><p>运行以下命令，看 Docker 是否正常工作：</p><pre><code>docker --version</code></pre><p>你应该能看到类似这样的输出，表明版本信息：</p><pre><code>Docker version 19.03.14, build xxxx</code></pre><p>再运行一个测试命令，看看 Docker 服务是否真的在跑：</p><pre><code>docker run hello-world</code></pre><p>这会下载一个小的测试镜像并运行，如果看到 “Hello from Docker!” 之类的提示，那就说明 <strong>Docker 安装成功并能正常使用</strong>。</p><p>​</p>]]></description></item><item>    <title><![CDATA[动态IP如何帮助爬虫采集？IP代理有哪些]]></title>    <link>https://segmentfault.com/a/1190000047405653</link>    <guid>https://segmentfault.com/a/1190000047405653</guid>    <pubDate>2025-11-17 19:06:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在互联网数据爆炸的时代，爬虫技术成为了获取信息的重要手段。而动态 IP 在其中扮演着至关重要的角色，它能帮助爬虫高效、稳定地采集数据。同时，IP 代理也有其独特的特点，下面我们就来详细探讨。</p><p><img width="723" height="546" referrerpolicy="no-referrer" src="/img/bVdm4xs" alt="" title=""/></p><p>动态 IP 助力爬虫采集的方式</p><p>突破反爬虫机制</p><p>许多网站为了防止恶意爬虫大量抓取数据，会设置反爬虫机制。当检测到同一 IP 地址在短时间内进行频繁的访问请求时，就会将该 IP 列入黑名单，限制其访问。而动态 IP 可以在每次请求时更换不同的 IP 地址，让网站难以识别这是同一个爬虫在进行访问。例如，一个爬虫程序在采集电商网站的商品信息时，如果一直使用同一个 IP，可能在采集几百条数据后就会被封禁。但使用动态 IP 后，每次请求都像是来自不同的用户，大大增加了采集数据的数量和效率。</p><p>提高采集速度</p><p>使用动态 IP 可以让爬虫同时从多个 IP 地址发送请求，实现并行采集。就好比多个人同时去完成一项任务，速度自然会加快。比如在采集新闻网站的文章时，通过动态 IP 可以同时从不同的 IP 地址向服务器发送请求，同时获取多篇文章的内容，而不是依次等待每一个请求的响应，从而显</p><p>有些网站的内容会根据用户的 IP 地址进行地域限制。例如，某些国外的视频网站只允许特定国家或地区的 IP 访问。使用动态 IP 可以模拟不同地区的 IP 地址，让爬虫能够访问这些地域受限的内容。这样，爬虫就可以采集到更广泛的数据，为数据分析和研究提供更全面的素材。</p><p>IP 代理的特点</p><p>隐藏真实 IP 地址</p><p>IP 代理的一个重要特点就是能够隐藏用户的真实 IP 地址。当爬虫通过 IP 代理发送请求时，服务器只能看到代理 IP 的信息，而无法获取爬虫所在设备的真实 IP。这不仅可以保护用户的隐私和安全，还可以避免爬虫被追踪和封禁。例如，在进行一些敏感数据的采集时，隐藏真实 IP 可以防止被恶意攻击或法律追究。</p><p>提高网络访问的稳定性</p><p>一些网络环境可能存在不稳定的情况，例如网络拥塞、带宽不足等。使用 IP 代理可以选择网络质量较好的代理服务器，从而提高网络访问的稳定性。代理服务器通常拥有更高速的网络连接和更充足的带宽资源，能够保证爬虫请求的快速响应。此外，当一个代理服务器出现故障或被封禁时，可以及时切换到其他代理服务器，确保爬虫的正常运行。</p><p>提供匿名性</p><p>IP 代理可以为爬虫提供匿名性，让爬虫的行为更加隐蔽。在一些需要采集敏感信息或进行竞争情报收集的场景中，匿名性尤为重要。例如，在采集竞争对手的产品价格和营销策略时，使用 IP 代理可以避免被对方察觉，保护采集行为的安全性和有效性。</p><p>支持多种协议</p><p>IP 代理通常支持多种网络协议，如 HTTP、HTTPS、SOCKS 等。这使得爬虫可以根据不同的采集需求选择合适的协议进行通信。不同的网站可能使用不同的协议进行数据传输，支持多种协议的 IP 代理可以确保爬虫能够与各种类型的网站进行兼容，顺利完成数据采集任务。</p><p>综上所述，动态 IP 为爬虫采集提供了突破限制、提高效率的有效途径，而 IP 代理的诸多特点也为爬虫的正常运行和数据采集提供了有力保障。在使用爬虫进行数据采集时，合理运用动态 IP 和 IP 代理可以让我们更加高效、安全地获取所需的数据。</p><p>你对这篇文章的内容还满意吗？如果有任何修改意见，比如增减内容、调整结构等，都可以随时告诉我。</p>]]></description></item><item>    <title><![CDATA[LoRaWAN FUOTA 空中固件升级]]></title>    <link>https://segmentfault.com/a/1190000047405675</link>    <guid>https://segmentfault.com/a/1190000047405675</guid>    <pubDate>2025-11-17 19:05:41</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在大规模物联网（IoT）项目中，终端设备部署往往分布在偏远、难以接触的场景，依赖人工更新固件几乎不可能实现。为确保设备长期稳定运行，“空中固件升级”（Firmware Update Over The Air，FUOTA）成为关键技术，尤其是在使用 LoRaWAN 的项目中更显重要。由于 LoRaWAN 带宽低、每包数据受限，实现稳定高效的 FUOTA 极具挑战。本文系统解析 FUOTA 的原理、LoRaWAN 中的技术难点，并介绍门思科技（Manthink）在多年项目经验中形成的工程化升级方案。</p><hr/><h2><strong>一、什么是 FUOTA？</strong></h2><p>FUOTA（Firmware Update Over The Air）指通过无线网络远程更新设备固件，使设备在无人工干预的情况下完成功能更新、漏洞修复和性能优化。</p><p>在物联网项目中，终端设备数量动辄成千上万，分布地点可能包括：</p><ul><li>城市地下管网</li><li>农田或山区的农业监测点</li><li>工业园区、油田、仓储中心等现场</li><li>城市设施（路灯杆、井盖、消防栓等）</li></ul><p>一旦部署，这些设备往往多年不维护，因此 FUOTA 直接决定项目生命周期管理能力。</p><hr/><h2><strong>二、LoRaWAN 中 FUOTA 的两大核心挑战</strong></h2><p>LoRaWAN 的优势在于低功耗、远距离，但其限制也格外突出，使 FUOTA 成为一项高难度工程。</p><h3><strong>1. 固件体积极大，传输速度受限</strong></h3><ul><li>LoRaWAN 的最大有效载荷约 <strong>255 字节</strong></li><li>典型固件大小从 <strong>数十 KB 到数百 KB</strong></li></ul><p>在低速链路上上传大文件极易出现：</p><ul><li>丢包</li><li>信道干扰</li><li>升级中断</li><li>升级失败后需重新传输</li></ul><p>尤其是地下管网、弱信号覆盖区，失败率更高。</p><h3><strong>2. 数据分片、校验与重组机制复杂</strong></h3><p>LoRaWAN 升级必须通过数据分片方式完成：</p><ul><li>分片数量可能数百到上千</li><li>需要顺序或乱序重组</li><li>丢包重传策略需精细控制</li><li>大规模设备同时升级需要同步与拥塞控制</li></ul><p>因此，仅依赖标准 FUOTA 规范难以满足真实项目需求。</p><hr/><h2><strong>三、门思科技（Manthink）如何解决 LoRaWAN FUOTA 的工程化问题？</strong></h2><p>门思科技自 ​<strong>2017 年即在实际项目中大规模应用 FUOTA</strong>​，形成了涵盖操作系统、通信机制、算法与工具链在内的完整升级体系。</p><p>以下三项核心技术，使其 FUOTA 在大量部署中稳定可靠。</p><hr/><h2><strong>1. 自研 MPOS 操作系统：为升级预留底层 Hook</strong></h2><p>MPOS（Manthink Portable OS）是门思科技为 IoT 嵌入式设备开发的轻量级操作系统。</p><p>其核心优势在于 ​<strong>为远程升级预置扩展能力（Hook）</strong>​，包括：</p><ul><li>支持单函数级别的动态替换</li><li>支持向系统中新增任务或事件处理</li><li>支持差分升级，只传输变化部分</li></ul><p>相比整包固件升级，差分升级可以：</p><ul><li><strong>减少 70%\~95% 的传输数据量</strong></li><li>显著提升成功率</li><li>降低升级时间</li><li>降低对 LoRaWAN 链路质量的依赖</li></ul><hr/><h2><strong>2. EB（Edge-Bus）计算框架：压缩业务逻辑的“核心武器”</strong></h2><p>EB 框架是一种高度抽象的业务逻辑描述模型，具有：</p><ul><li>极高可压缩性</li><li>模块化</li><li>仅需少量字节即可描述复杂逻辑</li></ul><p>在实际项目中，EB 可以：</p><ul><li>将原本 <strong>几 KB 或几十 KB 的逻辑压缩为数百甚至数十字节</strong></li><li>将升级所需数据量降低一个数量级</li><li>极大提升 LoRaWAN FUOTA 的可行性</li></ul><p>这意味着：<br/><strong>设备无需再升级大固件，只需更新业务逻辑指令即可实现功能扩展。</strong></p><hr/><h2><strong>3. 多 bin 技术：可靠的数据切片与重组机制</strong></h2><p>多 bin 升级机制是门思科技为 LoRaWAN 环境优化的稳定传输方案。</p><p>其特点包括：</p><ul><li>根据设备当前信号质量自适应选择分片大小</li><li>针对弱信号环境优化的纠错和重传策略</li><li>智能组合与完整性校验</li><li>支持断点续传</li></ul><p>即使在高丢包率（5%\~20%）的场景中，也能确保：</p><ul><li>数据分片完整</li><li>升级可持续推进</li><li>最终固件校验通过后自动切换</li></ul><p>真正实现 ​<strong>工程级的远程升级可靠性</strong>​。</p><hr/><h2><strong>四、FUOTA 的价值：让 LoRaWAN 设备“活”起来</strong></h2><p>一个不能升级的物联网设备，只能“被动工作”；<br/>一个支持 FUOTA 的设备，才具备“生命周期管理”的能力。</p><p>FUOTA 带来的价值包括：</p><ul><li><strong>延长设备寿命</strong></li><li><strong>修复长期暴露在现场的安全漏洞</strong></li><li><strong>无需派人维护，大幅降低运维成本</strong></li><li><strong>设备可持续加入新功能</strong></li><li><strong>可适应项目场景变化</strong></li></ul><p>门思科技基于 MPOS、EB 和多 bin 的 FUOTA 技术，为 LoRaWAN 项目提供了工程级、可规模化、长期可靠的远程升级体系。</p><hr/><h2><strong>五、进一步了解 ThinkLink LoRaWAN 网络服务器（NS）</strong></h2><p>如果你正在寻找稳定、开放、全球标准兼容的 LoRaWAN 网络服务器平台，ThinkLink 是一个成熟选择：</p><ul><li><p><strong>ThinkLink Cloud 版</strong></p><ul><li>永久免费</li><li>支持 1000 个设备接入</li><li>支持 BACnet、Home Assistant、ThingsBoard 等系统对接<br/>👉 <a href="https://link.segmentfault.com/?enc=KiEqzgkOSneSIqBl3Ia%2B8Q%3D%3D.TPFs5GprYtQs3bnxXrZbhyua4vQ74xKSB%2FSHKi6m948%3D" rel="nofollow" target="_blank">https://thinklink.manthink.cn</a></li></ul></li><li><p><strong>ThinkLink Edge 版</strong></p><ul><li>可本地部署</li><li>支持 1000 个设备</li><li>内置 Home Assistant 开源版、ThingsBoard CE 版<br/>👉 <a href="https://link.segmentfault.com/?enc=GgChsfT1hNfw4Hi%2FLHrFGw%3D%3D.vf%2FeeRN2SLzN77klomDevzq5HFxwwWixhlFoN9XYcrVipCWUC0Tg%2BpBRK4QadUOw" rel="nofollow" target="_blank">https://www.manthink.cn/zh/thinklink-2/</a></li></ul></li></ul><p>了解更多 LoRaWAN 产品与解决方案：<br/>👉 <a href="https://link.segmentfault.com/?enc=7%2BBGfEL4r6mwDljviZw1KA%3D%3D.GkFTXFSuKN2SZseoB%2F1f3px6kgeXh7gHUhm3GbBFFVk%3D" rel="nofollow" target="_blank">https://www.manthink.cn</a></p>]]></description></item><item>    <title><![CDATA[在项目管理中如何跟踪工作量和工作时间？ ]]></title>    <link>https://segmentfault.com/a/1190000047405679</link>    <guid>https://segmentfault.com/a/1190000047405679</guid>    <pubDate>2025-11-17 19:04:50</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>项目管理工具中的工作量报告非常有用，因为它能清晰地展现任务和职责在团队成员之间的分配情况。通过显示哪些成员工作负荷过重、哪些成员资源利用不足或哪些成员空闲，报告可以帮助管理者更有效地平衡工作，防止员工倦怠或项目延误。此外，报告还能突出显示潜在的资源缺口，帮助团队在问题出现之前调整任务分配或时间安排，从而更好地进行规划。通过提高对团队能力和进度的可见性，团队可以做出更明智的决策，加强协调，并确保项目按计划进行。</p><p>Zoho Projects 支持项目工作量报表和全局工作量报表帮助您了解各个项目里面用户的工作量和您参加的所有的项目里面用户的工作量。 工作量报表为经理非常有帮助。 经理可以了解每个用户的工作量。 如果一个用户的工作量过多和另一个用户的工作量不足，只需要工作量过多的用户的一个任务拖放到工作量不足的用户。</p><p>项目管理工具中的“计划与实际对比”报告会将项目的计划内容（例如时间、成本、范围和资源）与实际执行情况进行比较。这种对比有助于项目经理评估绩效、识别偏差并做出纠正决策。它突出显示了计划时间表、预算或工作量与实际结果之间的差异。这使得项目进度是超前、按计划进行还是落后于计划变得清晰明了。</p><p>Zoho Projects 支持项目计划VS实际报表也支持全局计划VS实际报表。这个报表可以帮助用户查看一个任务中设置的工作时间和用户在任务中花费的时间。 它按照任务中设置的工作时间和用户在门户中添加的工时日志计算的。</p><p>当您需要评估项目进度或了解所有项目的任务信息时，“全局报告”功能将为您提供极大的帮助。“全局计划与实际”报告就是其中之一，您可以通过它了解各项任务所花费的时间。要查看此报告，请导航至 Zoho Projects 主页中的“全局报告”小部件。</p><p>“全局计划与实际”报告通过区分任务的计划工时和实际工时，提供每个用户的任务工时详情。报告还会显示每项任务的预期工时与实际工时之间的差异。</p><p>例如，门户管理员 李俊 使用“全局计划与实际”报告来了解哪些项目耗时较长。通过该报告，李俊 可以找到用户在所有项目中完成所有任务的总计划工时和实际工时。此外，通过比较每个项目的计划工时和实际工时，他还可以找出耗时较长的项目。</p><p>另外，李俊的老板要求他提供一份关于特定用户在特定项目和时间段内的工作报告。他对报告应用筛选器，并将报告导出为 XLS 文件。借助“全局计划与实际对比”报告，约翰找到了一个快速解决方案，可以生成所有项目的报告，而无需为每个项目单独生成报告。</p>]]></description></item><item>    <title><![CDATA[印度股票数据 PHP 对接文档 覆盖 B]]></title>    <link>https://segmentfault.com/a/1190000047405693</link>    <guid>https://segmentfault.com/a/1190000047405693</guid>    <pubDate>2025-11-17 19:04:18</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>本文档详细介绍如何使用 PHP 语言对接 StockTV 印度股票数据源，覆盖 BSE（孟买证券交易所）和 NSE（印度国家证券交易所）的实时数据。</p><h2>🚀 快速开始</h2><h3>环境要求</h3><ul><li>PHP 7.4+</li><li>cURL 扩展</li><li>JSON 扩展</li><li>网络连接（可访问 <code>api.stocktv.top</code>）</li></ul><h2>🏗️ 核心架构</h2><h3>项目结构</h3><pre><code>src/
├── config/
│   └── StockTVConfig.php
├── models/
│   ├── Stock.php
│   ├── Index.php
│   ├── KLine.php
│   └── ApiResponse.php
├── clients/
│   ├── StockTVHttpClient.php
│   └── StockTVWebSocketClient.php
├── services/
│   └── IndiaStockService.php
└── examples/
    └── IndiaStockDemo.php</code></pre><h2>📦 核心代码实现</h2><h3>1. 配置类</h3><pre><code class="php">&lt;?php
// src/config/StockTVConfig.php

namespace StockTV\Config;

/**
 * StockTV API 配置类
 */
class StockTVConfig
{
    // API 基础配置
    const BASE_URL = 'https://api.stocktv.top';
    const WS_URL = 'wss://ws-api.stocktv.top/connect';
    
    // 印度市场配置
    const INDIA_COUNTRY_ID = 14;
    const NSE_EXCHANGE_ID = 46;
    const BSE_EXCHANGE_ID = 74;
    
    // API 接口路径
    const STOCK_LIST = '/stock/stocks';
    const QUERY_STOCKS = '/stock/queryStocks';
    const STOCKS_BY_PIDS = '/stock/stocksByPids';
    const INDICES = '/stock/indices';
    const INDICES_BY_ID = '/stock/indicesById';
    const KLINE = '/stock/kline';
    const UPDOWN_LIST = '/stock/updownList';
    const GET_IPO = '/stock/getIpo';
    const COMPANIES = '/stock/companies';
    const COMPANY_URL = '/stock/companyUrl';
    const NEWS = '/stock/news';
    
    private $apiKey;
    private $timeout = 30;
    
    public function __construct(string $apiKey)
    {
        $this-&gt;apiKey = $apiKey;
    }
    
    public function getApiKey(): string
    {
        return $this-&gt;apiKey;
    }
    
    public function getTimeout(): int
    {
        return $this-&gt;timeout;
    }
    
    public function setTimeout(int $timeout): self
    {
        $this-&gt;timeout = $timeout;
        return $this;
    }
}</code></pre><h3>2. 数据模型类</h3><h4>股票数据模型</h4><pre><code class="php">&lt;?php
// src/models/Stock.php

namespace StockTV\Models;

/**
 * 印度股票数据模型
 */
class Stock
{
    public $id;
    public $symbol;
    public $name;
    public $last;
    public $chg;
    public $chgPct;
    public $high;
    public $low;
    public $volume;
    public $open;
    public $exchangeId;
    public $countryId;
    public $countryNameTranslated;
    public $flag;
    public $fundamentalMarketCap;
    public $fundamentalRevenue;
    public $technicalDay;
    public $technicalHour;
    public $technicalWeek;
    public $technicalMonth;
    public $performanceDay;
    public $performanceWeek;
    public $performanceMonth;
    public $performanceYtd;
    public $time;
    public $url;
    
    public function __construct(array $data = [])
    {
        foreach ($data as $key =&gt; $value) {
            if (property_exists($this, $key)) {
                $this-&gt;$key = $value;
            }
        }
    }
    
    public function getExchangeName(): string
    {
        if ($this-&gt;exchangeId == \StockTV\Config\StockTVConfig::NSE_EXCHANGE_ID) {
            return 'NSE';
        } elseif ($this-&gt;exchangeId == \StockTV\Config\StockTVConfig::BSE_EXCHANGE_ID) {
            return 'BSE';
        }
        return 'Unknown';
    }
    
    public function isGaining(): bool
    {
        return $this-&gt;chgPct &gt; 0;
    }
    
    public function getFormattedChange(): string
    {
        $sign = $this-&gt;chgPct &gt; 0 ? '+' : '';
        return $sign . number_format($this-&gt;chgPct, 2) . '%';
    }
    
    public function getFormattedPrice(): string
    {
        return '₹' . number_format($this-&gt;last, 2);
    }
}</code></pre><h4>指数数据模型</h4><pre><code class="php">&lt;?php
// src/models/Index.php

namespace StockTV\Models;

/**
 * 指数数据模型
 */
class Index
{
    public $id;
    public $name;
    public $symbol;
    public $last;
    public $chg;
    public $chgPct;
    public $high;
    public $low;
    public $isOpen;
    public $flag;
    public $url;
    public $time;
    
    public function __construct(array $data = [])
    {
        foreach ($data as $key =&gt; $value) {
            if (property_exists($this, $key)) {
                $this-&gt;$key = $value;
            }
        }
    }
    
    public function isGaining(): bool
    {
        return $this-&gt;chgPct &gt; 0;
    }
    
    public function getFormattedChange(): string
    {
        $sign = $this-&gt;chgPct &gt; 0 ? '+' : '';
        return $sign . number_format($this-&gt;chgPct, 2) . '%';
    }
}</code></pre><h4>K线数据模型</h4><pre><code class="php">&lt;?php
// src/models/KLine.php

namespace StockTV\Models;

/**
 * K线数据模型
 */
class KLine
{
    public $time;
    public $open;
    public $high;
    public $low;
    public $close;
    public $volume;
    public $vo;
    
    public function __construct(array $data = [])
    {
        foreach ($data as $key =&gt; $value) {
            if (property_exists($this, $key)) {
                $this-&gt;$key = $value;
            }
        }
    }
    
    public function getAmplitude(): float
    {
        if ($this-&gt;open == 0) {
            return 0;
        }
        return (($this-&gt;high - $this-&gt;low) / $this-&gt;open) * 100;
    }
    
    public function getChangePercent(): float
    {
        if ($this-&gt;open == 0) {
            return 0;
        }
        return (($this-&gt;close - $this-&gt;open) / $this-&gt;open) * 100;
    }
}</code></pre><h4>API响应包装类</h4><pre><code class="php">&lt;?php
// src/models/ApiResponse.php

namespace StockTV\Models;

/**
 * API通用响应包装类
 */
class ApiResponse
{
    public $code;
    public $message;
    public $data;
    
    public function __construct(array $data = [])
    {
        foreach ($data as $key =&gt; $value) {
            if (property_exists($this, $key)) {
                $this-&gt;$key = $value;
            }
        }
    }
    
    public function isSuccess(): bool
    {
        return $this-&gt;code === 200;
    }
}

/**
 * 股票列表响应包装类
 */
class StockListResponse
{
    public $records;
    public $total;
    public $size;
    public $current;
    public $pages;
    
    public function __construct(array $data = [])
    {
        foreach ($data as $key =&gt; $value) {
            if (property_exists($this, $key)) {
                $this-&gt;$key = $value;
            }
        }
        
        // 转换records为Stock对象数组
        if (isset($data['records']) &amp;&amp; is_array($data['records'])) {
            $this-&gt;records = array_map(function($item) {
                return new Stock($item);
            }, $data['records']);
        }
    }
}</code></pre><h3>3. HTTP客户端实现</h3><pre><code class="php">&lt;?php
// src/clients/StockTVHttpClient.php

namespace StockTV\Clients;

use StockTV\Config\StockTVConfig;
use StockTV\Models\ApiResponse;
use StockTV\Models\Stock;
use StockTV\Models\Index;
use StockTV\Models\KLine;
use StockTV\Models\StockListResponse;

/**
 * StockTV HTTP API客户端
 */
class StockTVHttpClient
{
    private $config;
    private $lastResponse;
    
    public function __construct(StockTVConfig $config)
    {
        $this-&gt;config = $config;
    }
    
    /**
     * 获取印度股票列表
     */
    public function getIndiaStocks(int $pageSize = 50, int $page = 1): array
    {
        $params = [
            'countryId' =&gt; StockTVConfig::INDIA_COUNTRY_ID,
            'pageSize' =&gt; $pageSize,
            'page' =&gt; $page,
            'key' =&gt; $this-&gt;config-&gt;getApiKey()
        ];
        
        $response = $this-&gt;makeRequest(StockTVConfig::STOCK_LIST, $params);
        
        if ($response-&gt;isSuccess()) {
            $stockListResponse = new StockListResponse($response-&gt;data);
            return $stockListResponse-&gt;records;
        }
        
        throw new \Exception("获取印度股票列表失败: " . $response-&gt;message);
    }
    
    /**
     * 查询单个股票
     */
    public function queryStock(?int $id = null, ?string $symbol = null, ?string $name = null): array
    {
        $params = ['key' =&gt; $this-&gt;config-&gt;getApiKey()];
        
        if ($id !== null) {
            $params['id'] = $id;
        }
        if ($symbol !== null) {
            $params['symbol'] = $symbol;
        }
        if ($name !== null) {
            $params['name'] = $name;
        }
        
        $response = $this-&gt;makeRequest(StockTVConfig::QUERY_STOCKS, $params);
        
        if ($response-&gt;isSuccess()) {
            return array_map(function($item) {
                return new Stock($item);
            }, $response-&gt;data);
        }
        
        throw new \Exception("查询股票失败: " . $response-&gt;message);
    }
    
    /**
     * 批量查询多个股票
     */
    public function getStocksByPids(array $pids): array
    {
        if (empty($pids)) {
            throw new \InvalidArgumentException("股票PID列表不能为空");
        }
        
        $params = [
            'key' =&gt; $this-&gt;config-&gt;getApiKey(),
            'pids' =&gt; implode(',', $pids)
        ];
        
        $response = $this-&gt;makeRequest(StockTVConfig::STOCKS_BY_PIDS, $params);
        
        if ($response-&gt;isSuccess()) {
            return array_map(function($item) {
                return new Stock($item);
            }, $response-&gt;data);
        }
        
        throw new \Exception("批量查询股票失败: " . $response-&gt;message);
    }
    
    /**
     * 获取印度主要指数
     */
    public function getIndiaIndices(): array
    {
        $params = [
            'countryId' =&gt; StockTVConfig::INDIA_COUNTRY_ID,
            'key' =&gt; $this-&gt;config-&gt;getApiKey()
        ];
        
        $response = $this-&gt;makeRequest(StockTVConfig::INDICES, $params);
        
        if ($response-&gt;isSuccess()) {
            return array_map(function($item) {
                return new Index($item);
            }, $response-&gt;data);
        }
        
        throw new \Exception("获取印度指数失败: " . $response-&gt;message);
    }
    
    /**
     * 通过ID查询特定指数
     */
    public function getIndexById(int $id): array
    {
        $params = [
            'id' =&gt; $id,
            'key' =&gt; $this-&gt;config-&gt;getApiKey()
        ];
        
        $response = $this-&gt;makeRequest(StockTVConfig::INDICES_BY_ID, $params);
        
        if ($response-&gt;isSuccess()) {
            return array_map(function($item) {
                return new Index($item);
            }, $response-&gt;data);
        }
        
        throw new \Exception("获取指数失败: " . $response-&gt;message);
    }
    
    /**
     * 获取K线数据
     */
    public function getKLineData(int $pid, string $interval): array
    {
        $params = [
            'pid' =&gt; $pid,
            'interval' =&gt; $interval,
            'key' =&gt; $this-&gt;config-&gt;getApiKey()
        ];
        
        $response = $this-&gt;makeRequest(StockTVConfig::KLINE, $params);
        
        if ($response-&gt;isSuccess()) {
            return array_map(function($item) {
                return new KLine($item);
            }, $response-&gt;data);
        }
        
        throw new \Exception("获取K线数据失败: " . $response-&gt;message);
    }
    
    /**
     * 获取涨跌排行榜
     */
    public function getUpDownList(int $type): array
    {
        $params = [
            'countryId' =&gt; StockTVConfig::INDIA_COUNTRY_ID,
            'type' =&gt; $type,
            'key' =&gt; $this-&gt;config-&gt;getApiKey()
        ];
        
        $response = $this-&gt;makeRequest(StockTVConfig::UPDOWN_LIST, $params);
        
        if ($response-&gt;isSuccess()) {
            return array_map(function($item) {
                return new Stock($item);
            }, $response-&gt;data);
        }
        
        throw new \Exception("获取排行榜失败: " . $response-&gt;message);
    }
    
    /**
     * 获取IPO数据
     */
    public function getIpoList(?int $type = null): array
    {
        $params = [
            'countryId' =&gt; StockTVConfig::INDIA_COUNTRY_ID,
            'key' =&gt; $this-&gt;config-&gt;getApiKey()
        ];
        
        if ($type !== null) {
            $params['type'] = $type;
        }
        
        $response = $this-&gt;makeRequest(StockTVConfig::GET_IPO, $params);
        
        if ($response-&gt;isSuccess()) {
            return $response-&gt;data;
        }
        
        throw new \Exception("获取IPO数据失败: " . $response-&gt;message);
    }
    
    /**
     * 通用HTTP请求方法
     */
    private function makeRequest(string $endpoint, array $params = []): ApiResponse
    {
        $url = StockTVConfig::BASE_URL . $endpoint . '?' . http_build_query($params);
        
        $ch = curl_init();
        curl_setopt_array($ch, [
            CURLOPT_URL =&gt; $url,
            CURLOPT_RETURNTRANSFER =&gt; true,
            CURLOPT_TIMEOUT =&gt; $this-&gt;config-&gt;getTimeout(),
            CURLOPT_HTTPHEADER =&gt; [
                'Content-Type: application/json',
                'User-Agent: StockTV-PHP-Client/1.0'
            ]
        ]);
        
        $response = curl_exec($ch);
        $httpCode = curl_getinfo($ch, CURLINFO_HTTP_CODE);
        $error = curl_error($ch);
        curl_close($ch);
        
        if ($error) {
            throw new \Exception("HTTP请求失败: " . $error);
        }
        
        if ($httpCode !== 200) {
            throw new \Exception("HTTP请求失败，状态码: " . $httpCode);
        }
        
        $data = json_decode($response, true);
        if (json_last_error() !== JSON_ERROR_NONE) {
            throw new \Exception("JSON解析失败: " . json_last_error_msg());
        }
        
        $this-&gt;lastResponse = $data;
        return new ApiResponse($data);
    }
    
    /**
     * 获取最后一次响应数据
     */
    public function getLastResponse(): ?array
    {
        return $this-&gt;lastResponse;
    }
}</code></pre><h3>4. WebSocket客户端实现</h3><pre><code class="php">&lt;?php
// src/clients/StockTVWebSocketClient.php

namespace StockTV\Clients;

use StockTV\Config\StockTVConfig;
use Ratchet\Client\WebSocket;
use Ratchet\Client\Connector;
use React\EventLoop\Factory;
use React\Socket\Connector as ReactConnector;

/**
 * StockTV WebSocket实时数据客户端
 */
class StockTVWebSocketClient
{
    private $config;
    private $loop;
    private $connector;
    private $webSocket;
    private $callbacks;
    
    public function __construct(StockTVConfig $config)
    {
        $this-&gt;config = $config;
        $this-&gt;loop = Factory::create();
        $this-&gt;connector = new Connector($this-&gt;loop);
        $this-&gt;callbacks = [
            'message' =&gt; [],
            'error' =&gt; [],
            'close' =&gt; []
        ];
    }
    
    /**
     * 连接WebSocket服务器
     */
    public function connect(): void
    {
        $wsUrl = StockTVConfig::WS_URL . '?key=' . $this-&gt;config-&gt;getApiKey();
        
        $this-&gt;connector-&gt;__invoke($wsUrl)
            -&gt;then(function(WebSocket $conn) {
                $this-&gt;webSocket = $conn;
                $this-&gt;onOpen($conn);
                
                $conn-&gt;on('message', function($msg) use ($conn) {
                    $this-&gt;onMessage($conn, $msg);
                });
                
                $conn-&gt;on('close', function($code = null, $reason = null) use ($conn) {
                    $this-&gt;onClose($conn, $code, $reason);
                });
                
            }, function(\Exception $e) {
                $this-&gt;onError($e);
            });
    }
    
    /**
     * 启动事件循环
     */
    public function run(): void
    {
        $this-&gt;loop-&gt;run();
    }
    
    /**
     * 停止事件循环
     */
    public function stop(): void
    {
        if ($this-&gt;loop) {
            $this-&gt;loop-&gt;stop();
        }
    }
    
    /**
     * 连接建立回调
     */
    private function onOpen(WebSocket $conn): void
    {
        echo "WebSocket连接已建立\n";
    }
    
    /**
     * 消息接收回调
     */
    private function onMessage(WebSocket $conn, $msg): void
    {
        $data = json_decode($msg, true);
        if (json_last_error() !== JSON_ERROR_NONE) {
            echo "JSON解析失败: " . json_last_error_msg() . "\n";
            return;
        }
        
        $this-&gt;handleRealTimeData($data);
        
        // 执行用户定义的回调
        foreach ($this-&gt;callbacks['message'] as $callback) {
            call_user_func($callback, $data);
        }
    }
    
    /**
     * 连接关闭回调
     */
    private function onClose(WebSocket $conn, $code, $reason): void
    {
        echo "WebSocket连接已关闭: code={$code}, reason={$reason}\n";
        
        foreach ($this-&gt;callbacks['close'] as $callback) {
            call_user_func($callback, $code, $reason);
        }
    }
    
    /**
     * 错误回调
     */
    private function onError(\Exception $e): void
    {
        echo "WebSocket连接错误: " . $e-&gt;getMessage() . "\n";
        
        foreach ($this-&gt;callbacks['error'] as $callback) {
            call_user_func($callback, $e);
        }
    }
    
    /**
     * 处理实时数据
     */
    private function handleRealTimeData(array $data): void
    {
        if (isset($data['pid'])) {
            $symbol = $data['symbol'] ?? $data['pid'];
            $price = $data['last_numeric'] ?? 'N/A';
            $changePercent = $data['pcp'] ?? '0';
            
            echo "实时行情: {$symbol} - 价格: {$price}, 涨跌幅: {$changePercent}%\n";
            
            // 价格预警逻辑
            $changePercentNum = floatval($changePercent);
            if (abs($changePercentNum) &gt; 2.0) {
                echo "🚨 价格波动预警: {$symbol} 波动 {$changePercentNum}%\n";
            }
        }
    }
    
    /**
     * 添加消息回调
     */
    public function onMessageCallback(callable $callback): self
    {
        $this-&gt;callbacks['message'][] = $callback;
        return $this;
    }
    
    /**
     * 添加错误回调
     */
    public function onErrorCallback(callable $callback): self
    {
        $this-&gt;callbacks['error'][] = $callback;
        return $this;
    }
    
    /**
     * 添加关闭回调
     */
    public function onCloseCallback(callable $callback): self
    {
        $this-&gt;callbacks['close'][] = $callback;
        return $this;
    }
    
    /**
     * 发送消息
     */
    public function send(string $message): void
    {
        if ($this-&gt;webSocket) {
            $this-&gt;webSocket-&gt;send($message);
        }
    }
    
    /**
     * 关闭连接
     */
    public function close(): void
    {
        if ($this-&gt;webSocket) {
            $this-&gt;webSocket-&gt;close();
        }
        $this-&gt;stop();
    }
}</code></pre><h3>5. 服务层封装</h3><pre><code class="php">&lt;?php
// src/services/IndiaStockService.php

namespace StockTV\Services;

use StockTV\Config\StockTVConfig;
use StockTV\Clients\StockTVHttpClient;
use StockTV\Clients\StockTVWebSocketClient;
use StockTV\Models\Stock;
use StockTV\Models\Index;
use StockTV\Models\KLine;

/**
 * 印度股票数据服务
 */
class IndiaStockService
{
    private $httpClient;
    private $wsClient;
    
    public function __construct(string $apiKey)
    {
        $config = new StockTVConfig($apiKey);
        $this-&gt;httpClient = new StockTVHttpClient($config);
        $this-&gt;wsClient = new StockTVWebSocketClient($config);
    }
    
    /**
     * 获取Nifty 50成分股
     */
    public function getNifty50Stocks(): array
    {
        try {
            $stocks = $this-&gt;httpClient-&gt;getIndiaStocks(50, 1);
            echo "成功获取 " . count($stocks) . " 只印度股票\n";
            return $stocks;
        } catch (\Exception $e) {
            echo "获取Nifty 50成分股失败: " . $e-&gt;getMessage() . "\n";
            throw $e;
        }
    }
    
    /**
     * 获取印度主要指数
     */
    public function getMajorIndices(): array
    {
        try {
            $indices = $this-&gt;httpClient-&gt;getIndiaIndices();
            echo "成功获取 " . count($indices) . " 个印度指数\n";
            return $indices;
        } catch (\Exception $e) {
            echo "获取印度指数失败: " . $e-&gt;getMessage() . "\n";
            throw $e;
        }
    }
    
    /**
     * 查询特定股票
     */
    public function getStockBySymbol(string $symbol): ?Stock
    {
        try {
            $stocks = $this-&gt;httpClient-&gt;queryStock(null, $symbol, null);
            if (empty($stocks)) {
                echo "未找到股票: {$symbol}\n";
                return null;
            }
            echo "查询股票 {$symbol} 成功\n";
            return $stocks[0];
        } catch (\Exception $e) {
            echo "查询股票失败: {$symbol} - " . $e-&gt;getMessage() . "\n";
            throw $e;
        }
    }
    
    /**
     * 批量查询股票
     */
    public function getStocksBySymbols(array $symbols): array
    {
        $results = [];
        foreach ($symbols as $symbol) {
            try {
                $stock = $this-&gt;getStockBySymbol($symbol);
                if ($stock) {
                    $results[] = $stock;
                }
            } catch (\Exception $e) {
                // 单个股票查询失败，继续处理其他股票
                continue;
            }
        }
        echo "批量查询成功，获取 " . count($results) . " 只股票\n";
        return $results;
    }
    
    /**
     * 获取股票K线数据
     */
    public function getStockKLine(int $pid, string $interval): array
    {
        try {
            $klines = $this-&gt;httpClient-&gt;getKLineData($pid, $interval);
            echo "成功获取股票 {$pid} 的K线数据，共 " . count($klines) . " 条\n";
            return $klines;
        } catch (\Exception $e) {
            echo "获取K线数据失败: pid={$pid} - " . $e-&gt;getMessage() . "\n";
            throw $e;
        }
    }
    
    /**
     * 获取涨幅榜
     */
    public function getGainers(): array
    {
        try {
            $gainers = $this-&gt;httpClient-&gt;getUpDownList(1);
            echo "成功获取涨幅榜，共 " . count($gainers) . " 只股票\n";
            return $gainers;
        } catch (\Exception $e) {
            echo "获取涨幅榜失败: " . $e-&gt;getMessage() . "\n";
            throw $e;
        }
    }
    
    /**
     * 获取跌幅榜
     */
    public function getLosers(): array
    {
        try {
            $losers = $this-&gt;httpClient-&gt;getUpDownList(2);
            echo "成功获取跌幅榜，共 " . count($losers) . " 只股票\n";
            return $losers;
        } catch (\Exception $e) {
            echo "获取跌幅榜失败: " . $e-&gt;getMessage() . "\n";
            throw $e;
        }
    }
    
    /**
     * 获取IPO数据
     */
    public function getUpcomingIPOs(): array
    {
        try {
            $ipos = $this-&gt;httpClient-&gt;getIpoList(1); // 1表示未上市
            echo "成功获取IPO数据，共 " . count($ipos) . " 个\n";
            return $ipos;
        } catch (\Exception $e) {
            echo "获取IPO数据失败: " . $e-&gt;getMessage() . "\n";
            throw $e;
        }
    }
    
    /**
     * 启动实时数据监控
     */
    public function startRealTimeMonitoring(): void
    {
        try {
            // 添加消息处理回调
            $this-&gt;wsClient-&gt;onMessageCallback(function($data) {
                $this-&gt;handleRealTimeData($data);
            });
            
            $this-&gt;wsClient-&gt;connect();
            echo "实时数据监控已启动\n";
            
            // 启动事件循环
            $this-&gt;wsClient-&gt;run();
            
        } catch (\Exception $e) {
            echo "启动实时数据监控失败: " . $e-&gt;getMessage() . "\n";
            throw $e;
        }
    }
    
    /**
     * 处理实时数据
     */
    private function handleRealTimeData(array $data): void
    {
        if (isset($data['pid'])) {
            $symbol = $data['symbol'] ?? $data['pid'];
            $price = $data['last_numeric'] ?? 'N/A';
            $changePercent = $data['pcp'] ?? '0';
            
            $trend = floatval($changePercent) &gt;= 0 ? '📈' : '📉';
            echo "{$trend} 实时行情: {$symbol} - 价格: ₹{$price}, 涨跌幅: {$changePercent}%\n";
            
            // 价格预警逻辑
            $changePercentNum = floatval($changePercent);
            if (abs($changePercentNum) &gt; 5.0) {
                echo "🚨 大幅波动预警: {$symbol} 波动 {$changePercentNum}%\n";
            }
        }
    }
    
    /**
     * 停止实时数据监控
     */
    public function stopRealTimeMonitoring(): void
    {
        $this-&gt;wsClient-&gt;close();
        echo "实时数据监控已停止\n";
    }
}</code></pre><h3>6. 使用示例</h3><pre><code class="php">&lt;?php
// examples/IndiaStockDemo.php

require_once __DIR__ . '/../vendor/autoload.php';

use StockTV\Services\IndiaStockService;
use StockTV\Models\Stock;
use StockTV\Models\Index;

/**
 * 印度股票数据使用示例
 */
class IndiaStockDemo
{
    private $stockService;
    
    public function __construct(string $apiKey)
    {
        $this-&gt;stockService = new IndiaStockService($apiKey);
    }
    
    public function runDemo(): void
    {
        echo "=== StockTV 印度股票数据演示程序开始 ===\n\n";
        
        try {
            // 1. 获取印度主要指数
            $this-&gt;demonstrateIndices();
            
            // 2. 查询特定股票
            $this-&gt;demonstrateStockQuery();
            
            // 3. 获取Nifty 50成分股示例
            $this-&gt;demonstrateNifty50();
            
            // 4. 获取K线数据
            $this-&gt;demonstrateKLineData();
            
            // 5. 获取排行榜
            $this-&gt;demonstrateRankings();
            
            echo "\n=== 演示程序执行完成 ===\n";
            
        } catch (Exception $e) {
            echo "演示程序执行失败: " . $e-&gt;getMessage() . "\n";
        }
    }
    
    /**
     * 演示指数数据获取
     */
    private function demonstrateIndices(): void
    {
        echo "1. 印度主要指数\n";
        echo str_repeat("-", 50) . "\n";
        
        $indices = $this-&gt;stockService-&gt;getMajorIndices();
        
        foreach ($indices as $index) {
            $trend = $index-&gt;isGaining() ? '📈' : '📉';
            $changeSign = $index-&gt;isGaining() ? '+' : '';
            
            echo "{$trend} {$index-&gt;name}: {$index-&gt;last} ";
            echo "({$changeSign}{$index-&gt;chgPct}%)\n";
        }
        echo "\n";
    }
    
    /**
     * 演示股票查询
     */
    private function demonstrateStockQuery(): void
    {
        echo "2. 查询特定股票\n";
        echo str_repeat("-", 50) . "\n";
        
        // 查询Reliance Industries
        $reliance = $this-&gt;stockService-&gt;getStockBySymbol('RELIANCE');
        $this-&gt;printStockInfo($reliance, 'Reliance Industries');
        
        // 查询TCS
        $tcs = $this-&gt;stockService-&gt;getStockBySymbol('TCS');
        $this-&gt;printStockInfo($tcs, 'Tata Consultancy Services');
        
        echo "\n";
    }
    
    /**
     * 演示Nifty 50成分股
     */
    private function demonstrateNifty50(): void
    {
        echo "3. Nifty 50成分股（示例）\n";
        echo str_repeat("-", 50) . "\n";
        
        $niftyStocks = $this-&gt;stockService-&gt;getNifty50Stocks();
        
        // 显示前10只股票
        $count = 0;
        foreach ($niftyStocks as $stock) {
            if ($count &gt;= 10) break;
            
            $trend = $stock-&gt;isGaining() ? '🟢' : '🔴';
            $changeSign = $stock-&gt;isGaining() ? '+' : '';
            
            echo "{$trend} {$stock-&gt;symbol}: ₹{$stock-&gt;last} ";
            echo "({$changeSign}{$stock-&gt;chgPct}%) - {$stock-&gt;name}\n";
            
            $count++;
        }
        echo "\n";
    }
    
    /**
     * 演示K线数据获取
     */
    private function demonstrateKLineData(): void
    {
        echo "4. K线数据示例\n";
        echo str_repeat("-", 50) . "\n";
        
        $reliance = $this-&gt;stockService-&gt;getStockBySymbol('RELIANCE');
        if ($reliance) {
            $klines = $this-&gt;stockService-&gt;getStockKLine($reliance-&gt;id, 'P1D');
            
            echo "Reliance Industries 近期日K线数据:\n";
            $count = 0;
            foreach ($klines as $kline) {
                if ($count &gt;= 5) break;
                
                $date = date('Y-m-d H:i:s', $kline-&gt;time / 1000);
                $amplitude = number_format($kline-&gt;getAmplitude(), 2);
                
                echo "时间: {$date}, 开: ₹{$kline-&gt;open}, ";
                echo "高: ₹{$kline-&gt;high}, 低: ₹{$kline-&gt;low}, ";
                echo "收: ₹{$kline-&gt;close}, 振幅: {$amplitude}%\n";
                
                $count++;
            }
        }
        echo "\n";
    }
    
    /**
     * 演示排行榜功能
     */
    private function demonstrateRankings(): void
    {
        echo "5. 市场排行榜\n";
        echo str_repeat("-", 50) . "\n";
        
        // 获取涨幅榜
        $gainers = $this-&gt;stockService-&gt;getGainers();
        echo "📈 今日涨幅榜（前5）:\n";
        $count = 0;
        foreach ($gainers as $stock) {
            if ($count &gt;= 5) break;
            
            $changeSign = $stock-&gt;isGaining() ? '+' : '';
            echo "   {$stock-&gt;symbol}: ₹{$stock-&gt;last} ";
            echo "({$changeSign}{$stock-&gt;chgPct}%) - {$stock-&gt;name}\n";
            
            $count++;
        }
        
        echo "\n";
        
        // 获取跌幅榜
        $losers = $this-&gt;stockService-&gt;getLosers();
        echo "📉 今日跌幅榜（前5）:\n";
        $count = 0;
        foreach ($losers as $stock) {
            if ($count &gt;= 5) break;
            
            echo "   {$stock-&gt;symbol}: ₹{$stock-&gt;last} ";
            echo "({$stock-&gt;chgPct}%) - {$stock-&gt;name}\n";
            
            $count++;
        }
        echo "\n";
    }
    
    /**
     * 打印股票信息
     */
    private function printStockInfo(?Stock $stock, string $description): void
    {
        if ($stock) {
            $status = $stock-&gt;open ? '🟢 交易中' : '🔴 已收盘';
            $trend = $stock-&gt;isGaining() ? '📈' : '📉';
            
            echo "{$trend} {$description} - {$status}\n";
            echo "   代码: {$stock-&gt;symbol} | 价格: ₹{$stock-&gt;last}\n";
            echo "   涨跌: ₹{$stock-&gt;chg} ({$stock-&gt;getFormattedChange()})\n";
            echo "   最高: ₹{$stock-&gt;high} | 最低: ₹{$stock-&gt;low} | 成交量: {$stock-&gt;volume}\n";
            
            if ($stock-&gt;technicalDay) {
                $techName = $this-&gt;getTechnicalIndicatorName($stock-&gt;technicalDay);
                echo "   技术指标: {$techName}\n";
            }
        }
        echo "\n";
    }
    
    /**
     * 获取技术指标中文名称
     */
    private function getTechnicalIndicatorName(string $indicator): string
    {
        $map = [
            'strong_buy' =&gt; '强烈买入',
            'buy' =&gt; '买入',
            'neutral' =&gt; '中性',
            'sell' =&gt; '卖出',
            'strong_sell' =&gt; '强烈卖出'
        ];
        
        return $map[$indicator] ?? $indicator;
    }
}

// 运行演示程序
$apiKey = '您的API_KEY'; // 替换为实际的API Key

$demo = new IndiaStockDemo($apiKey);
$demo-&gt;runDemo();</code></pre><h2>🎯 高级功能</h2><h3>实时价格监控器</h3><pre><code class="php">&lt;?php
// examples/PriceMonitor.php
</code></pre>]]></description></item><item>    <title><![CDATA[【赵渝强老师】达梦数据库的事务隔离级别 ]]></title>    <link>https://segmentfault.com/a/1190000047405731</link>    <guid>https://segmentfault.com/a/1190000047405731</guid>    <pubDate>2025-11-17 19:03:22</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>达梦数据库允许多个客户端同时访问。当这些客户端并发访问数据库中同一部分的数据时，如果没有采取必要的隔离措施就容易造成并发一致性问题，从而破坏数据的完整性。考虑下图中的场景：<br/><img width="723" height="276" referrerpolicy="no-referrer" src="/img/bVdm3K4" alt="image.png" title="image.png"/></p><p>在时间点1上，var的数值是100。客户端A在时间点2的时候更新了它的值为200，但没有提交事务。在时间点3的时候，客户端B读取到了客户端A还未提交的数值200。但在时间点4，客户端A执行了回滚操作。那么，对于客户端B来说，如果在时间点5再次读取数据，得到就应该是100。那么客户端B就有了数据不一致的问题。而造成问题的根本原因在，客户端B读取到了客户端A还没有提交的事务中的数据。</p><p>为了解决数据在并发访问时，数据的一致性问题。在SQL标准中定义了四种事务的隔离级别，它们分别是：读未提交（READ-UNCOMMITTED）、读已提交（READ-COMMITTED）、可重复读（REPEATABLE-READ）和可序列化读（SERIALIZABLE）。<br/>达梦数据库支持三种事务隔离级别：读未提交（READ-UNCOMMITTED）、读提交（READ-COMMITTED）和串行化（SERIALIZABLE）。其中，读提交是DM 数据库默认使用的事务隔离级别，可重复读升级为更严格的串行化隔离级。</p><p>视频讲解如下：<br/><a href="https://www.bilibili.com/video/BV1EACiBuEq6/?aid=115563779069332&amp;cid=34063516477" target="_blank">https://www.bilibili.com/video/BV1EACiBuEq6/?aid=115563779069...</a></p><p>在达梦数据库中要查看默认的事务隔离级别，可以通过下面的方式来获取。<br/>（1）使用管理员登录数据库。</p><pre><code class="sql">SQL&gt; conn sysdba/Welcome_1</code></pre><p>（2）执行下面的语句获取事务的隔离级别。</p><pre><code class="sql">SQL&gt; select para_name,para_value,
    case para_value
        when 1 then 'Read Commited'
        when 3 then 'Serializable'
        else 'None'
    end as "隔离级别"
    from v$dm_ini where para_name='ISOLATION_LEVEL';

# 输出的信息如下：
行号     PARA_NAME       PARA_VALUE     隔离级别 
------ --------------- ---------- -------------
1       ISOLATION_LEVEL     1              Read Commited

# 从输出的信息可以看出，DM数据库默认的事务隔离级别是读已提交（READ-COMMITTED）。</code></pre><p>数据库在不同的事务隔离级别下会有不同的行为，从而在并发访问数据的时候会带来不同的问题。下表列举了在不同的SQL标准事务隔离级别下，数据库可能存在的不同问题。<br/><img width="723" height="146" referrerpolicy="no-referrer" src="/img/bVdm3Lj" alt="image.png" title="image.png" loading="lazy"/></p><p>由于达梦数据库默认的事务隔离级别是读已提交（READ-COMMITTED），因此在达梦数据库中默认是不存在脏读问题的。</p>]]></description></item><item>    <title><![CDATA[Data Agent 精选推荐：Alou]]></title>    <link>https://segmentfault.com/a/1190000047405735</link>    <guid>https://segmentfault.com/a/1190000047405735</guid>    <pubDate>2025-11-17 19:02:30</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>摘要</h2><p>在数据量爆炸式增长与业务决策实时性要求提升的双重驱动下，Data Agent（数据智能体）正从辅助工具向企业核心数据分析中枢演进。其通过融合大模型能力与数据管理和分析技术，为企业提供“对话即分析”、“自动找根因”、“一键生成报告”等智能化数据分析服务，推动“人人都是分析师”的愿景落地。</p><p>本文聚焦 Data Agent 的发展趋势与市场需求，重点推荐面向企业的 Aloudata Agent 分析决策智能体——它以“智能问数、智能归因、报告生成”三大核心能力，为企业构建可信智能 Data Agent，助力企业实现 AI 驱动的数据洞察与敏捷决策，是企业数智化转型的优选方案。</p><h2>前言：当数据分析遇上 AI，Data Agent 为何成为新焦点？</h2><p>随着企业数智化转型的深入，数据已成为核心生产要素，但传统数据分析模式却面临严峻挑战：业务人员依赖 IT 部门取数，平均响应周期长达数天；海量数据中隐藏的业务关联难以快速挖掘；管理层需要决策支持时，往往因报告滞后错失商机。</p><p>与此同时，大语言模型（LLM）的突破为数据分析带来了革命性变化——通过自然语言对话直接获取洞察，让非技术人员也能“对话数据”。在此背景下，Data Agent（数据智能体）应运而生。作为连接用户需求与数据系统的“智能中介”，它不仅能理解自然语言指令，更能自动完成数据查询、关联分析、根因定位、可视化呈现等复杂任务，成为企业数据分析的“AI 专家”。</p><p>据 IDC 预测，到 2026 年，将有 50% 的中国 500 强数据团队使用 AI Agent来实现数据准备和分析。而在这场变革中，Aloudata Agent 分析决策智能体凭借对企业级场景的深度适配，正成为市场中的标杆产品。</p><h3>推荐理由一：智能问数——让“开口即得”取代“提需求排队”</h3><p>传统数据分析流程中，业务人员需先梳理需求→提交 IT 或数据团队→等待 SQL 编写与数据提取→再解读结果，链路长且效率低。Aloudata Agent 的核心突破在于深度优化了“企业级语义理解”。其通过采用了“NoETL 明细语义层 + 多 Agent 协同”架构，创新 NL2MQL2SQL 技术路径，提供了全面、丰富的指标语义知识库，确保基于用户问数意图对齐指标语义，实现精准的指标与维度召回，保障数据完整性和口径一致性，避免了“问 A 得 B”的常见错误。</p><p>当用户输入问题，其能够准确识别用户查询目标，精准理解业务意图，生成指标语义查询 MQL，再通过指标语义引擎将 MQL 自动转化为可执行的 SQL 语句，实现 100% 准确的 SQL 查询和物化加速，最后由大模型将数据结果转化为易于理解的洞察语言和图表报告。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405737" alt="图片" title="图片"/></p><p>例如，用户只需通过日常语言提问，如“Q3 华东区销售额同比下滑的原因是什么？”“哪些客户的复购率提升了但客单价下降了？”，Aloudata Agent 即可自动解析意图、生成指标语义查询 MQL、转化为 SQL 查询，并以图表或简报形式返回答案。</p><h3>推荐理由二：智能归因——从“数据堆砌”到“根因定位”的质变</h3><p>数据分析的价值不仅在于呈现“发生了什么”，更在于回答“为什么发生”以及“如何应对”。然而，面对海量关联数据，人工定位根因往往依赖经验猜测，效率低且易遗漏关键因素。</p><p>Aloudata Agent 的“智能归因”功能，包括“维度归因”和“因子归因”两大路径：</p><p>1、维度归因：用于识别影响目标指标的关键业务维度，通过维度下钻与贡献度计算，量化各维度对整体变化或差异的贡献权重，帮助用户锁定问题焦点。例如，分析“门店 A 与门店 B 的业绩差距”时，可自动归因于客群结构、促销策略等维度；</p><p>2、因子归因：聚焦驱动指标变动的关联因子，通过指标间的计算逻辑与影响路径，识别哪些前置因子的变化是导致最终结果差异的根本动因，从而提供更具操作性的改进方向。例如，识别“GMV 增长”的主要驱动因素是产品类目、会员等级还是渠道类型。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405738" alt="图片" title="图片" loading="lazy"/></p><p>这种“从现象到本质”的智能归因分析，不仅能够帮助业务团队快速聚焦关键问题，更将归因分析的效率提升数倍。例如，原本需要多人在数周内完成的根因分析工作，现在通过 Aloudata Agent 可在 1 天内输出完整报告，且结论的可信度更高。</p><h3>推荐理由三：报告生成——从“人工撰写”到“一键智能输出”的效率革命</h3><p>定期生成经营分析报告（如日报、周报、月报）是企业数据团队的常规工作，但这类任务往往重复性强、格式固定，占用大量人力。Aloudata Agent 的“报告生成”功能，支持用户通过自然语言指定报告目标，例如，“生成 Q3 销售业绩分析报告，重点突出区域差异与渠道贡献”，Aloudata Agent 即可自动整合多维数据、按逻辑框架组织内容，并生成图文并茂报告文档。</p><p>更关键的是，报告内容并非简单的数据堆砌，而是基于 AI 的“业务视角解读”，整合趋势、对比、归因结论，包含数据结果查询、异常发现、归因、对比与改善措施建议的结构化内容，将数据洞察转化为可执行的业务动作。</p><p>这对于分析师而言，以前写报告要花数个小时，现在基于 Aloudata Agent 显著提升撰写效率，并能够直接标出了“需关注事项”和“优化建议”等关键信息，极大简化了工作任务，实现敏捷决策。</p><h2>总结：Aloudata Agent——企业级 AI 数据分析的“专家级伙伴”</h2><p>在 Data Agent 加速渗透企业级市场的趋势下，核心需求已从“能查数据”升级为“能懂业务、能解决问题、能驱动决策”。Aloudata Agent 分析决策智能体正是这一需求的典型代表：它以“智能问数”降低数据分析门槛，让全员参与洞察；以“智能归因”挖掘数据背后的因果逻辑，提升决策精准度；以“报告生成”自动化重复工作，释放专业团队价值。</p><p>随着企业对“全员数据素养”的要求越来越高，像 Aloudata Agent 这样的智能体将成为数据驱动决策的关键工具。它不仅是技术的创新，更是企业数据分析范式的革新，让“人人都是分析师”不再是一句口号，而是触手可及的现实。访问 Aloudata Agent 产品官网，一起贴近更智能的数据未来。</p><h2>适用对象：</h2><p>希望实现自然语言问数、AI 数据分析，推进数据民主化，提升数据交付敏捷性，让一线业务能够减少对数据开发的依赖，自主开展全面、灵活、智能、安全问数，覆盖金融（银行、证券）、制造、消费、零售、交通、能源、医疗、航空航天、互联网、ICT、政企等行业领域。</p><h2>权威认可：</h2><ul><li>IDC：2025 IDC 中国面向生成式 AI 的数据基础设核心厂商、数据流管理（Data Flow Agent）代表厂商；2024 IDC「GenAI+Data」中国市场代表厂商</li><li>Gartner：2024 中国代表性数据基础设施供应商、中国数据编织代表厂商和数据资产管理代表厂商</li><li>信通院：2024《数据智能产业图谱》-数据智能基础设施企业、数据治理企业、数据智能开发企业代表</li><li>爱分析：2025 AI Agent 对话式智能分析核心厂商</li><li>数据猿：2025 中国数智化转型升级创新服务企业</li></ul>]]></description></item><item>    <title><![CDATA[阿尔特携手 Amazon AgentCo]]></title>    <link>https://segmentfault.com/a/1190000047405755</link>    <guid>https://segmentfault.com/a/1190000047405755</guid>    <pubDate>2025-11-17 19:01:59</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img width="723" height="160" referrerpolicy="no-referrer" src="/img/bVdkFLr" alt="image.png" title="image.png"/></p><h2>关于Monus AI</h2><p>Monus AI是由南京阿尔特科技推出的一款专注于消费决策的AI搜索应用，在搜索垂类工具中表现领先。该产品核心功能包括规格级比价、虚假软广识别、商品对比和智能对话，致力于在购物前为用户提供高效、可信的决策支持。通过6大智能体体系和返利体系，Monus AI不仅帮助用户省钱，还能让用户在消费过程中“赚钱”。无论是搜索“程序员AI开发电脑”还是查询“Pampers湿纸巾最低价”，它都始终围绕“信任+效率”重塑消费搜索体验。</p><p><img width="723" height="251" referrerpolicy="no-referrer" src="/img/bVdm2TV" alt="image.png" title="image.png" loading="lazy"/></p><h3>什么是 Amazon Bedrock AgentCore？</h3><p>Amazon Bedrock AgentCore 提供专为Agent工作负载构建的基础设施、可增强Agent功能的强大工具，以及适用于现实部署场景的基础组件。AgentCore 服务可以组合使用，也可以单独使用。该服务兼容多种Agent框架（包括 CrewAI、LangGraph、LlamaIndex 和 Strands Agents 等），并支持 Amazon Bedrock提供的多种模型，为 Agent 带来极大的灵活性。AgentCore 消除了构建专用Agent基础设施时千篇一律的繁重工作，可以加快 Agent 从研发进入生产的过程。</p><h3>场景挑战</h3><p>在电商AI搜索领域，用户和系统面临多重核心挑战，特别是需求表达与匹配的断层。具体挑战包括：</p><p>（1）用户不同购买决策时期的识别</p><p>用户在购物过程中，处于不同的购买决策期，需求和关注点差异显著。多模态输入（文字、语音、图片）的准确理解及决策时期判别至关重要。需求萌芽期的用户更需要全面的指导和信息，帮助形成购买意向；而决策后期的用户则更加关注优惠促销和售后保障。对这些时期的精准识别能够实现针对性服务和优化用户体验。</p><p>（2）多平台商品规格同义不同名问题</p><p>跨平台商品信息孤立，用户需在不同电商平台间切换对比价格和评价，且常遭遇虚假软广和冗余信息扰乱，筛选有效信息耗时且低效。更复杂的是，不同平台采用各自独特的商品规格命名规则，导致“同义不同名”现象普遍存在，严重阻碍了规格级颗粒度的实时比价和精准匹配，给系统带来了极大挑战。</p><p>（3）用户画像与商品推理匹配度不足</p><p>传统推荐系统主要依赖用户的行为数据进行相似商品推荐，泛化能力和关联推理能力有限，难以有效捕获用户日常生活中的跨品类兴趣和潜在需求。这导致推荐结果同质化严重，无法做到用户需求的深度理解和精准满足，影响用户满意度和转化率。</p><p>针对上述挑战，电商AI搜索系统需具备精准的决策期识别能力，高效处理跨平台异构商品数据，并强化用户画像与商品间的智能推理匹配能力，才能提供真正个性化、连贯且高效的消费决策支持。</p><h3>解决方案</h3><p>Monus AI采用自研的多模态融合输入技术，可同时高效处理文字、语音、图片三种类型的用户输入，打破传统搜索的输入局限。更具创新性的是，系统引入 “消费决策时期判断” 机制，通过深度学习模型分析用户输入的语义特征与情感倾向，能准确识别用户当前处于需求萌芽、信息收集还是购买决策阶段，该判断的匹配度高达 94%，为后续精准服务奠定基础。</p><p><img width="723" height="797" referrerpolicy="no-referrer" src="/img/bVdm2Va" alt="image.png" title="image.png" loading="lazy"/></p><ul><li>第一级：决策洞察智能体体系– 深度结合 AgentCore Memory 基于 UserPreferenceMemory 策略存储的用户偏好数据，实时分析用户搜索请求的复杂度，同时判断用户决策的紧迫性，为后续处理流程设定优先级。</li><li>第二级：智能匹配智能体体系– 基于用户历史购物偏好、浏览记录等数据，动态调整商品与搜索内容的匹配权重，确保优先呈现与用户需求高度契合的信息。</li><li>第三级：语义压缩智能体体系 – 采用先进的语义编码算法，在保留 98% 核心商品信息完整性的前提下，将数据处理速度提升 3 倍，同时使整体处理成本降低 80%，实现效率与成本的双重优化。</li><li>第四级：数据融合智能体体系 – 运用自研的多源数据清洗算法，对来自不同电商平台的商品数据进行处理，噪音过滤率达到 87%，有效解决了跨平台商品信息孤岛问题，为用户提供统一、准确的信息视图。</li><li>第五级：个性推荐智能体体系– 深度融合 AgentCore Memory 的用户数据，摒弃传统机械的推荐方式，采用拟人化导购的交互形式，进行情感化推荐排序，让推荐结果更贴合用户个性化需求与购物习惯。</li></ul><p>多级智能体体系通过用户偏好分析、精准匹配、效率优化等维度构建了核心能力，在这一体系运行框架下，通过以下关键技术点，实现效率与质量的双重提升：</p><p><img width="723" height="346" referrerpolicy="no-referrer" src="/img/bVdm2Vb" alt="image.png" title="image.png" loading="lazy"/></p><ol><li>智能分解 – AI 自动将用户提出的复杂需求（如 “推荐一款适合大学生用、预算 5000 元以内、能运行设计软件的笔记本”）拆解为多个可并行处理的子任务，如 “大学生使用场景分析”“预算筛选”“软件运行需求匹配” 等。</li><li>并行路由 – 多个 Agent 同时针对不同维度的子任务进行处理，避免串行处理的等待时间，使系统响应时间缩短 60%，大幅提升用户体验。</li><li>记忆融合 – 基于 Strands Agents 调用 AgentCore Memory 中的用户历史数据，对各 Agent 处理后的结果进行个性化答案整合，确保最终呈现给用户的搜索结果完全符合其独特偏好与需求。</li></ol><p><img width="723" height="1440" referrerpolicy="no-referrer" src="/img/bVdm3et" alt="" title="" loading="lazy"/></p><p>通过上述技术架构与流程设计，Monus AI 实现了从 “单一搜索工具” 到 “专属购物伙伴” 的根本性转变。如今，用户无需在重复搜索中反复描述需求，AI 能够精准理解需求的上下文演进过程，为用户提供具备连续性的个性化服务体验。这一技术架构不仅彻底解决了传统 AI 搜索存在的记忆缺失、推荐同质化等问题，更开创了电商 AI 领域的全新服务范式，为行业树立了技术与体验双重领先的标杆。</p><h2>效果评估</h2><p>基于AgentCore Memory和Strands Agent协同架构，Monus AI实现了跨越式提升，AI 搜索优化 具体表现如下：</p><p><img width="723" height="334" referrerpolicy="no-referrer" src="/img/bVdm2Vd" alt="image.png" title="image.png" loading="lazy"/></p><p>依托 AgentCore Memory 长期记忆的技术优势，不仅显著加快 Agent 开发进程，更在实际应用中实现多重价值：基于用户画像的智能搜索 Token 用量大幅减少，同时搜索结果准确率有效提升，为 Monus AI 在技术竞争力与成本效益层面提供了跨越式突破。</p><h2>总结</h2><p>阿尔特科技与亚马逊云科技的技术合作，不仅是 “任务编排框架 + 记忆服务” 与电商场景的深度融合，更给出了 “AI 如何真正懂用户、服务用户” 的清晰答案。其以 Strands Agents能力为 “骨架”，以 AgentCore Memory 的记忆功能为 “大脑”，搭配大小模型协同、语义共识引擎等技术，找到了当前电商 AI 搜索的最优实现路径，体现对 AI 技术本质的深刻理解与实践智慧。正如阿尔特科技团队所言：“创业不是一份工作，是热爱、坚持与智慧成长的过程。” 此次通过技术创新，不仅验证了 AI 在电商领域的巨大商业潜力，更为行业提供了 “框架 + 记忆” 双核心驱动的可复制、可扩展实践范式，为电商 AI 搜索的发展注入新动能。</p><p>*前述特定亚马逊云科技生成式人工智能相关的服务目前在亚马逊云科技海外区域可用。亚马逊云科技中国区域相关云服务由西云数据和光环新网运营，具体信息以中国区域官网为准。</p><p><strong>本篇作者</strong><br/><img width="723" height="457" referrerpolicy="no-referrer" src="/img/bVdm2Vm" alt="image.png" title="image.png" loading="lazy"/></p><blockquote>本期最新实验为《<a href="https://link.segmentfault.com/?enc=Ou62xqLasnlYNDonsuVytg%3D%3D.db6K1KmzbWSBw9RyMbxEo5kUKkTSAmRFDBeb7bFSF8Q2UZc7PBVeyiX3M%2FpclWCcrr4RhQp9qqlBOf%2FxtVRA1Hz7M1gJwXDtRvO1tzZ32hnhoAobkIASVOgHBijA25fiHTdUqCe0NBA2zKY6uSXfs767iDU17oaq%2BW2dzY12miqnyQqI3LDm8UhvAuzIPvJ9wtTLuwy1XQVKdn48RSwb5w%3D%3D" rel="nofollow" target="_blank">大模型选型实战 —— 基于Amazon Bedrock测评对比和挑选最合适业务的大模型</a>》<br/>✨ 立即解锁当下最火爆的AI大模型，带你零基础玩转 DeepSeek、Nova 等顶尖大预言模型。<br/>📱 即刻在云上探索实验室，开启构建开发者探索之旅吧！<br/>⏩<a href="https://link.segmentfault.com/?enc=KHeFFiPFu%2FVzMwEvyL1%2Ftg%3D%3D.oxPaMDECBigAh3ulm2kQn9YqPwozGTwV1NVSNjcN6buyQr3nyJQd4vcQiX3yo8%2F2uEI%2B6cBJfrKnI%2Fd%2BDHDQR9MaLFAZIvZdK4tEOSrY%2Fx0dmAm%2FhSRJWl63l%2Fd7csBSXKa49NhPqDbkGiLgx6GmfLn7DWVha4pspOMPztT0KxsYZSNgczlVIgu%2Fs30fcbB7Qpsn5Awe%2F8ur563XBZaaoA%3D%3D" rel="nofollow" target="_blank">[点击进入实验</a>] 构建无限, 探索启程！🚀</blockquote>]]></description></item><item>    <title><![CDATA[Rust 与 Go，后端开发的下一个五年]]></title>    <link>https://segmentfault.com/a/1190000047405757</link>    <guid>https://segmentfault.com/a/1190000047405757</guid>    <pubDate>2025-11-17 19:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>开发没有那么容易，每个后端有它的脾气，它不关心业务的快速变化，只关心自身的稳定和高效。</p><p>那么在未来几年，在高并发、低延迟的新兴后端领域，Rust 和 Go，谁会成为更主流的选择？我个人认为，这不在于哪个语言更时髦，而在于谁的架构性成本更低。</p><p><img width="723" height="351" referrerpolicy="no-referrer" src="/img/bVdm4y4" alt="image.png" title="image.png"/></p><h3>核心差异：编译时的严谨 vs. 运行时的灵活性</h3><p>Rust 和 Go 的设计哲学，从一开始就走向了两个不同的方向。</p><ul><li><strong>Rust</strong> 选择的是一条“先难后易”的路。它的编译器非常严格，尤其是所有权和借用检查机制，会在编译阶段就把潜在的内存安全问题全部暴露出来。这个过程对新手来说确实有不小的学习曲线，但一旦编译通过，程序在运行时的稳定性和性能表现会非常可靠。它没有垃圾回收（GC），这意味着不会有因GC扫描而导致的不可预测的延迟暂停。</li><li><strong>Go</strong> 则走了另一条路：“快速上手，快速产出”。它的语法简洁，工具链完善，特别是<code>goroutine</code>让并发编程变得前所未有的简单。开发者可以很快地将业务逻辑转化为可运行的服务。这种高效率的背后，是Go语言运行时自带的垃圾回收机制。在大多数情况下，Go的GC表现得相当不错，但在面对流量洪峰或大量瞬时内存分配的场景时，GC的“Stop-the-world”暂停仍然可能引发P99延迟的抖动。</li></ul><p>这本质上是两种不同权衡：一种是用前期的开发投入换取运行时的极致性能和可预测性；另一种是用运行时的些许不确定性，换取极高的开发效率和更低的入门门槛。</p><h3>性能场景对比</h3><p>比如一个很常见的后端任务：接收一个JSON格式的POST请求，进行一些数据处理，然后返回一个新的JSON响应。</p><p>在这个场景下，两种语言的表现通常会呈现一种规律：</p><ul><li><strong>Go (1.22)</strong> ：我用Go写这个功能可能只需要很短的时间。服务在常规负载下运行良好，响应迅速。但当并发请求量急剧上升时，通过监控工具，就会观察到延迟曲线出现一些细小的毛刺，内存占用也会随请求量线性增长。</li><li><strong>Rust</strong> <strong>(基于tokio)</strong> ：用Rust实现同样的功能，可能需要花更多时间去处理数据的生命周期和所有权问题，确保代码能通过编译器的检查。但服务部署后，它的延迟曲线会很平滑，即使在高压下，性能表现也始终如一，内存占用非常稳定。</li></ul><p>Rust 是把优化工作前置到了编码和编译阶段，而Go则让开发者先快速实现功能，再根据运行时的性能表现进行针对性优化。</p><h3>从代码的细节来看</h3><p>我们来看一下实现相同功能的两段代码。</p><h4><strong>Go：清晰直观，关注业务</strong></h4><pre><code class="go">package main

import (
        "encoding/json"
        "fmt"
        "log"
        "net/http"
        "time"
)

type RequestPayload struct {
        Name  string `json:"name"`
        Value int    `json:"value"`
}

type ResponsePayload struct {
        ID      int64  `json:"id"`
        Message string `json:"message"`
}

func handleRequest(w http.ResponseWriter, r *http.Request) {
        if r.Method != http.MethodPost {
                http.Error(w, "Only POST method is allowed", http.StatusMethodNotAllowed)
                return
        }

        var reqPayload RequestPayload
        if err := json.NewDecoder(r.Body).Decode(&amp;reqPayload); err != nil {
                http.Error(w, "Bad JSON format", http.StatusBadRequest)
                return
        }

        respPayload := ResponsePayload{
                ID:      time.Now().UnixNano(),
                Message: fmt.Sprintf("hello %s", reqPayload.Name),
        }

        w.Header().Set("Content-Type", "application/json")
        if err := json.NewEncoder(w).Encode(respPayload); err != nil {
                log.Printf("Failed to encode response: %v", err)
        }
}

func main() {
        http.HandleFunc("/api/process", handleRequest)
        fmt.Println("Go server listening on :8080")
        if err := http.ListenAndServe(":8080", nil); err != nil {
                log.Fatalf("Server failed to start: %v", err)
        }
}</code></pre><p>这段Go代码的逻辑非常直接，核心就是解码、处理、编码。开发者可以把注意力完全放在业务流程上。但在这个过程中，<code>json.Decode</code>和<code>json.Encode</code>等操作会隐式地进行内存分配，这些都是未来GC需要处理的对象。</p><h4><strong>Rust：严谨精密，掌控资源</strong></h4><p>首先，<code>Cargo.toml</code> 依赖配置:</p><pre><code class="rust">[dependencies]
axum = "0.7"
tokio = { version = "1", features = ["full"] }
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
chrono = { version = "0.4", features = ["serde"] }</code></pre><p>然后是实现代码:</p><pre><code class="rust">use axum::{routing::post, Json, Router};
use serde::{Deserialize, Serialize};
use std::net::SocketAddr;
use tokio;

#[derive(Deserialize)]
struct RequestPayload {
    name: String,
    value: i32,
}

#[derive(Serialize)]
struct ResponsePayload {
    id: i64,
    message: String,
}

async fn handle_request(Json(payload): Json&lt;RequestPayload&gt;) -&gt; Json&lt;ResponsePayload&gt; {
    let message = format!("hello {}", payload.name);

    let response = ResponsePayload {
        id: chrono::Utc::now().timestamp_nanos_opt().unwrap_or(0),
        message,
    };
    
    Json(response)
}

#[tokio::main]
async fn main() {
    let app = Router::new().route("/api/process", post(handle_request));

    let addr = SocketAddr::from(([127, 0, 0, 1], 3000));
    println!("Rust server listening on {}", addr);
    
    let listener = tokio::net::TcpListener::bind(addr).await.unwrap();
    axum::serve(listener, app).await.unwrap();
}</code></pre><p>Rust的代码在结构上需要更多的思考，比如异步运行时和框架的选择。但它带来的好处是，所有的数据传递和内存使用都在编译器的严格监督之下，开发者对资源的掌控力更强，从而避免了运行时的意外。</p><h4>Go VS Rust，Pick 谁？</h4><p><strong>什么时候会更倾向于Go？</strong></p><ul><li>在构建内部系统、运维工具、以及大部分业务逻辑复杂的CRUD应用时，Go的开发效率是巨大的优势。它的生态成熟，招聘相对容易，能让团队快速响应业务需求。</li></ul><p><strong>什么时候会选择Rust？</strong></p><ul><li>对于那些直接面向用户、对性能和资源消耗有严苛要求的核心服务，我会选择Rust。例如，API网关、底层中间件、实时计算引擎等。在这些领域，可预测的低延迟和内存效率至关重要。</li></ul><h3>对未来五年的看法</h3><p>我认为，Go和Rust并不会是谁取代谁的关系，而是会在各自擅长的领域里变得更加重要。</p><ul><li><strong>Go</strong> 将继续作为云原生时代的核心语言之一，在微服务和业务后端领域保持其强大影响力。</li><li><strong>Rust</strong> 则会在高性能计算、系统编程和基础设施领域占据越来越重要的位置，成为追求极致性能和安全性的团队的首选。</li></ul><h3>动手实践是最好的检验方式</h3><p>伟人曾经说过，实验是检验真理的唯一标准，所以最好的方式还是亲手实践一下，感受两种语言在开发体验和运行表现上的真实差异。</p><p>但环境配置往往让人抓耳挠腮。安装Go，再安装Rust，管理不同版本和依赖，尤其是在一个团队里，有的人用macOS，有的人用Windows，环境不统一很容易在协作中产生不必要的问题。</p><p>那 <strong>ServBay</strong> 这样的工具就非常有用了。</p><p><strong>ServBay</strong> 是一个集成的<a href="https://link.segmentfault.com/?enc=Cfsv4XF8ifPDwWDtpSpjwA%3D%3D.Nch1P1a%2Frh6jL1EvS0GqhaT1AONSFwMPKaTa%2B2EIaN4%3D" rel="nofollow" target="_blank">本地开发环境工具</a>，支持macOS和Windows。它能一键安装和管理Go、Rust以及Python、PHP、Node.js等多种开发环境，并且各个环境之间是隔离的，不会互相干扰。</p><p><img width="723" height="458" referrerpolicy="no-referrer" src="/img/bVdm4y5" alt="image.png" title="image.png" loading="lazy"/></p><p>这样一来，无论是想快速验证一个Go的Web服务想法，还是想深入学习Rust的所有权模型，都不再被繁琐的环境配置所困扰。它提供了一个统一、干净的实验平台，让我们可以把精力真正集中在代码和架构的探索上。</p><p><img width="723" height="458" referrerpolicy="no-referrer" src="/img/bVdm4y6" alt="image.png" title="image.png" loading="lazy"/></p><p>最终选择哪门语言，其实是选择在项目的哪个阶段投入更多精力：是前期的严谨设计与实现，还是后期的性能调优与维护。通过ServBay这样的工具亲手尝试，或许能帮我们更快地找到适合自己项目和团队的答案。</p>]]></description></item><item>    <title><![CDATA[FMEA与数字化工具结合的应用案例与未来]]></title>    <link>https://segmentfault.com/a/1190000047405394</link>    <guid>https://segmentfault.com/a/1190000047405394</guid>    <pubDate>2025-11-17 18:14:07</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>FMEA是什么？——系统性、前瞻性的产品与过程失效模式分析工具<br/>失效模式与影响分析（FMEA），即Failure Mode and Effects Analysis，是一种广泛应用且经过时间考验的风险管理方法论。它本质上是一种系统性的、前瞻性的分析活动，旨在识别和评估潜在的产品或过程失效模式及其后果。FMEA的核心在于其“预防性”思维，通过在问题实际发生前对其进行结构化的剖析，帮助企业锁定风险点，从而采取针对性的预防或探测措施，提升产品设计的可靠性、制造过程的稳定性和最终的客户满意度。<br/>从应用范围来看，FMEA主要分为两大类型。设计FMEA（Design FMEA，简称DFMEA）聚焦于产品设计阶段，旨在识别设计缺陷可能引发的失效模式，如结构强度不足、功能异常、材料选择不当等，并通过设计改进来规避这些风险，确保产品在设计层面就具备高质量和高可靠性。例如，在汽车零部件设计中，通过DFMEA分析可能存在的腐蚀、断裂等问题，从而优化选材和设计结构，提升部件的使用寿命和安全性。<br/>过程FMEA（Process FMEA，简称PFMEA）则应用于生产制造阶段，关注生产流程、设备、人员、物料、方法等各环节可能出现的失效情况，如参数漂移、装配错误、焊接不良等，并制定相应的控制策略，以保障生产过程的稳定运行和产品质量的一致性。一个典型的电子制造业案例是，某企业通过PFMEA深入分析了SMT贴片工艺中焊膏回流可能出现的虚焊、锡珠、桥接等失效模式，识别出温度曲线设置不当、焊膏保存条件不满足等因素，并据此优化了工艺参数和环境控制，显著降低了生产缺陷率。</p><p>FMEA为什么要做？——其核心价值在于事前预防与持续改进<br/>其次，FMEA有助于强化产品和过程的质量控制。通过在设计和过程层面主动寻找薄弱环节，FMEA促使企业从源头入手，优化设计方案，改进工艺流程，使得最终交付的产品或服务具有更高的可靠性和一致性。例如，某汽车制造商在新车型开发中严格执行DFMEA，有效预防了早期设计中未考虑到的零部件接口问题，确保了整车装配的顺畅和功能的完善，显著提升了用户在使用过程中的体验。<br/>再者，FMEA能够提升企业的整体运营效率。提前识别和解决潜在失效模式，意味着减少了生产过程中的故障停机时间、减少了因质量问题导致的物料浪费和返修成本，提高了资源的利用率和生产效率。同时，FMEA作为一种持续改进的机制，鼓励团队不断反思和学习，积累组织知识，提升整体的风险意识和应对能力。<br/>典型案例如，广域铭岛FASTWORX FMEA平台建立了在线协同编制和在线评审体系，加强FMEA管理，让相关人员都了解到失效原因和失效影响。便于企业成立多功能小组，有利于调动员工积极性<br/>最后，FMEA是建立客户信任的重要途径。当企业能够通过FMEA展示其对产品质量的严谨态度和有效控制时，无疑会增强客户对其产品和服务的信心。这对于企业拓展市场、提升品牌形象具有长远的战略意义。</p><p>FMEA怎么做？——系统化实施流程与实践要点<br/>在实际操作中，为了提升FMEA的效率和效果，一些领先企业开始结合数字化工具进行实施。例如，利用FMEA软件平台（如FASTWORX FMEA）来辅助分析，实现数据的统一管理、多人协同编辑、版本控制以及RPN自动计算等功能。同时，通过与产品生命周期管理（PLM）、制造执行系统（MES）等系统的集成，使FMEA分析能够实时反映最新的设计和工艺信息，提高准确性。此外，经验教训的积累和共享也是FMEA成功实施的关键，将其录入FMEA数据库，有助于避免重复犯错，并为后续的分析提供参考。<br/>某汽车研究院通过广域铭岛FASTWORX FMEA系统使得通过FMEA在线协同编辑，实现全公司研发相关人员的社交化协作，消除部门间隔阂，提高30-50%开发工作效率，缩减开发时间约50%。<br/>总之，FMEA作为一种强大的风险管理工具，其实施需要系统的方法、跨部门的协作以及持续的投入和改进。当正确应用于产品开发和生产制造过程时，FMEA能够为企业带来显著的质量提升和成本节约效益，是实现高质量、高可靠产品交付的重要保障。</p>]]></description></item><item>    <title><![CDATA[工艺工程怎么优化生产流程以降低成本？ 月]]></title>    <link>https://segmentfault.com/a/1190000047405402</link>    <guid>https://segmentfault.com/a/1190000047405402</guid>    <pubDate>2025-11-17 18:13:08</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在当今制造业迅猛演进的洪流中，工艺工程俨然成为企业竞争力的基石，它不仅定义了生产流程的精髓，更在数字化转型的浪潮中扮演着不可或缺的角色。工艺工程，这一涵盖从设计到执行的全面体系，通过科学的方法论和技术创新，持续推动着生产效率的提升与产品质量的优化。广域铭岛，作为工业互联网领域的先锋，以其先进的平台技术，为工艺工程的智能化注入了鲜活动力，使传统制造焕发新生。<br/>工艺工程的核心在于其多维度的内涵：它起始于精密的工艺设计与规划，工程师需深入分析产品特性与市场动态，构建高效且稳定的生产流程；继而延伸至设备选型与布局，通过智能配置最大化资源利用率；更重要的是，工艺参数的设置与优化，如同交响乐中的指挥棒，细微调整便能协调整个生产节奏，确保输出的一致性；而工艺流程的改进与创新，则体现了工艺工程的动态本质，不断吸纳新技术以应对市场变幻。广域铭岛通过其工业互联网解决方案，例如GQCM模具智能管理APP，将这些元素无缝集成，实现了冲压工序的数字化孪生，大幅削减非计划停机，彰显了工艺工程在实践中的强大效能。<br/>谈及工艺工程的作用，它远不止于提升效率；更是企业降本增效、保障质量的战略支点。通过优化生产流程，工艺工程能够显著减少材料浪费与能源消耗，例如在焊接工艺中，广域铭岛的点焊质量管理APP通过实时数据采集与算法模型，将焊点一次合格率推升至99.5%，这不仅降低了返工成本，还缩短了培训周期，凸显了工艺工程在质量管控中的卓越贡献。此外，工艺工程还驱动着技术创新与可持续发展，它融入绿色制造理念，减少排放，并借助人工智能和大数据实现从经验驱动到数据驱动的跃迁。广域铭岛的平台在此发挥了催化作用，通过预测性维护和效能分析，帮助企业构建智能化的生产生态，使工艺工程成为智能制造的中流砥柱。<br/>展望未来，工艺工程将继续深化其数字化转型，拥抱工业4.0的机遇。随着人工智能和物联网技术的普及，工艺工程将更加智能化、自适应化，为企业提供前所未有的灵活性与竞争力。广域铭岛等企业的持续创新，无疑将加速这一进程，推动工艺工程向更高维度进化，最终赋能制造业实现全面升级与可持续发展。</p>]]></description></item><item>    <title><![CDATA[不止合规 JoySSL国密数字证书安全高]]></title>    <link>https://segmentfault.com/a/1190000047405411</link>    <guid>https://segmentfault.com/a/1190000047405411</guid>    <pubDate>2025-11-17 18:12:22</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>随着互联网技术的快速升级，数字经济也迎来蓬勃发展，数据信息在网络世界中不断传输交互，构筑起现如今庞大的互联网体系。由于互联网发展具有双面性，且信息安全是国家发展的重要基石。因此，数据信息的安全传输，成为了公众最为关注的问题之一。国密数字证书通过建立加密通信通道，验证服务端身份等方式，成为网络安全防护领域的重要工具。作为国内专业的数字安全服务商，JoySSL率先完成国密证书技术体系搭建，并全网普及，为企业数字化转型与网络安全系统建设提供一站式解决方案。</p><p><img width="723" height="549" referrerpolicy="no-referrer" src="/img/bVdm4tu" alt="" title=""/></p><p><strong>技术升级 国密证书的核心优势</strong></p><p>作为我国自主研发的加密算法体系，国密算法包含SM2（非对称算法）、SM3（杂凑算法）和SM4（对称算法），与国际算法相比，自主研发的国密算法无论是安全表现还是功能表现上，皆更具优势。传统数字证书通常都采用国际加密标准，如RSA或ECC。而国密证书以自研密码算法为基础，实现强大的加密功能，确保数据安全传输。JoySSL技术总监指出，国密算法在相同安全强度的前提下，密钥长度相比RSA更短，运行效率更高，且算法经过国家密码管理局严格认证，可有效防范各种密码攻击手段。</p><p><strong>应用普遍 数字证书的不断普及</strong></p><p>截至目前，国密数字证书已成为电子政务系统的标配，在政务领域应用范围甚广。凭借有效的防护手段和加密算法，国密证书在金融、医疗等对数据安全要求高的行业，有着极高的需求度。</p><p><img width="723" height="549" referrerpolicy="no-referrer" src="/img/bVdm4tv" alt="" title="" loading="lazy"/></p><p>JoySSL作为数字安全领域的专业服务商，与多家银行达成合作，部署国密SSL证书，利用加密算法完成网银系统升级，有效降低潜在的安全风险，增强隐私数据防护能力。不仅提升了交易的安全性，同时也获得了用户与市场的信任。</p><p><strong>生态搭建 国密证书的全面服务</strong></p><p>随着国内《数据安全法》《网络安全法》等一系列法规的相继出台，社会各界普遍对网络安全防护的认识不断加深，应用范围和领域也逐渐扩大。国密证书的推广与普及，让整个数字证书产业生态正在经历重塑，不仅获得了主流浏览器和操作系统的支持与认可，同时还具备极高的兼容性，让国密证书的普及范围进一步扩大。JoySSL市场部专家分析指出，国密数字证书的影响力与日俱增，市场认可度逐年提升，不仅推动了国内信息安全技术的发展，同时也推动了国内企业进一步朝着规范化、国际化的方向迈进。</p><p><img width="723" height="549" referrerpolicy="no-referrer" src="/img/bVdm4tw" alt="" title="" loading="lazy"/></p><p><strong>创新突破 国密证书的未来展望</strong></p><p>作为互联网技术的具体表现形式，国密证书的成长上限远不止于此。在网络技术升级迭代、市场需求变化和全球数字化发展的大趋势下，国密证书还有更大的上升空间。以JoySSL为代表的数字安全厂商，早已投入到国密证书最新技术的研发当中，利用更先进的技术理念和创新思维，打造出新一代国密证书，提升安全防护能力与市场渗透率，推动全球网络空间安全稳定发展。</p>]]></description></item><item>    <title><![CDATA[怎么利用设备全面诊断进行预测性维护？ 月]]></title>    <link>https://segmentfault.com/a/1190000047405418</link>    <guid>https://segmentfault.com/a/1190000047405418</guid>    <pubDate>2025-11-17 18:11:34</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在现代工业体系中，设备的高效运行与安全性保障已成为企业提升生产效率和竞争力的核心要素。设备全面诊断技术，作为一套通过实时监测、动态分析与预测性维护相结合的综合性解决方案，正在成为推动制造业智能化升级的关键引擎。该技术不仅涵盖了传统设备管理方法，还融合了物联网、大数据与人工智能等前沿科技，通过多维度的数据采集与多层次的分析手段，实现了从被动应对到主动预防的管理转型。<br/>设备全面诊断的本质在于对设备运行状态的全面感知与智能评估。借助各类传感器，系统可以实时采集设备的振动、温度、电流等关键参数，并通过边缘计算与云端分析平台进行深度处理。例如，振动分析不仅能识别轴承磨损与转子失衡等机械故障，还能结合其他数据源，提供更为准确的故障预警信号。与此同时，在诸如多源感知网络与仿真技术的支持下，设备全面诊断系统能够模拟极端条件下的设备运行情况，从而提前发现潜在隐患，避免重大事故发生。<br/>广域铭岛作为工业互联网领域的技术先锋，凭借其Geega平台为设备全面诊断的实现提供了理想的工具。该平台不仅整合了设备技术资料、运行数据与维修经验，还通过先进的AI算法实现了故障的自动诊断与维修方案的智能推送。在多个行业应用场景中，广域铭岛的系统成功帮助企业降低了非计划停机时间，并显著提升了生产效率与设备利用率。这种集成化的智能诊断方式，使得设备维护从经验驱动转向数据驱动，全面革新了传统管理模式。<br/>从实际应用效果来看，设备全面诊断带来的价值不仅局限于简单的故障修复。在制造业生产车间，通过优化工艺参数与实时监控设备健康状态，企业能够在节能环保的前提下，进一步提高生产线的产出稳定性。特别是在一些大型制造基地，设备全面诊断系统的应用直接带来了成本削减与生产效率提升的双重效应。这使得全面诊断不仅是一种技术革新，更是企业实现降本增效的重要战略手段。<br/>此外，设备全面诊断的应用范围正在扩展至更广泛的领域，包括能源、医疗、交通等。在核电设备与大型医疗机械中，实时的状态监测与预测性维护同样发挥着不可忽视的作用。并且随着技术的不断演进，设备全面诊断正在与AR远程指导、自动化运维机器人等创新技术相结合，推动工业生态向协同化与智能化方向发展。<br/>展望未来，设备全面诊断将在工业4.0与绿色制造的时代浪潮中扮演更加重要的角色。作为一种融合多学科技术的解决方案，它不仅能够帮助企业减少停机时间与维护成本，还能加速资源的循环利用与生产流程的优化。随着新一代技术整合的深入，设备全面诊断的准确度与覆盖范围将进一步提升，成为企业持续发展的强大支撑。</p>]]></description></item><item>    <title><![CDATA[SCALE | 2025 年 10 月《]]></title>    <link>https://segmentfault.com/a/1190000047405440</link>    <guid>https://segmentfault.com/a/1190000047405440</guid>    <pubDate>2025-11-17 18:11:00</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405442" alt="" title=""/></p><h2>一、本月导览与核心看点</h2><p>2025 年 10 月，<a href="https://link.segmentfault.com/?enc=cW4fsNRkH2Aqg2xSOTu76g%3D%3D.nexlr2UCqR0EBgVYnuMYSxzdG1n1F5d04YSJxF%2BG1SBhIklu%2FmyX1x6Hf41auxIc" rel="nofollow" title="SCALE 202510" target="_blank">SCALE</a> 评测基准持续追踪 AI 在专业 SQL 领域的最新进展。本月，榜单迎来了蚂蚁百灵大模型团队发布的两大 万亿级 参数的模型：<a href="https://link.segmentfault.com/?enc=yoWf3dkPoGLIWJGAWaD07Q%3D%3D.7izThiew3nVzZPjxm5BM0Z8Wtqr1ASbU1qFSuqAnBKrxItnLNXTW1zr7A9xFNPAL" rel="nofollow" target="_blank">Ling-1T</a> 和 <a href="https://link.segmentfault.com/?enc=vWC60RQzawASIvdW8u4FpQ%3D%3D.6wk9FO6vI6J318pw6EJNnZDi3RovnaPZ5%2F%2ByYuzXEy%2BWLyzegwm%2BIGCb4KAV%2BJPw" rel="nofollow" target="_blank">Ring-1T</a>。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405443" alt="" title="" loading="lazy"/></p><ul><li><strong>Ling-1T</strong> ：蚂蚁百灵大模型 <strong>Ling 2.0</strong> 系列的第一款旗舰模型。</li><li><strong>Ring-1T</strong> ：一款基于 <strong>Ling 2.0</strong> 架构的思考模型，也是全球首个开源万亿参数思考模型。</li></ul><p>本期核心看点：</p><ul><li><p><strong>新增模型评测</strong> ：首次引入蚂蚁 <em>Ling-1T</em> 与 <em>Ring-1T</em> 模型。评测数据显示，两款模型呈现出清晰的能力分化：</p><ul><li>Ling-1T 在「<strong>国产数据库</strong>」转换场景中表现突出，获得满分！</li><li>Ring-1T 在「<strong>SQL 优化</strong> 」和「<strong>SQL 理解</strong> 」维度展现了 <strong>更为均衡和稳健的综合能力</strong>，总分均进入榜单上游。</li></ul></li></ul><h2>二、评测基准说明</h2><p>为保证评测结果的长期可比性和权威性，本月我们的核心评测基准与算法保持不变，继续沿用 <strong>SCALE</strong> 自创立之初便确立的三维评测体系，确保所有模型与工具在统一、标准的测试环境下进行评估，以提供公正、可复现的评测结果。</p><ul><li><strong>SQL 优化</strong>：考察模型提升查询效率与性能的意识和能力。</li><li><strong>方言转换</strong>：考察模型在主流数据库之间进行语法迁移的准确性。</li><li><strong>SQL 理解</strong>：考察模型是否能精准解析复杂的查询逻辑与用户意图的能力。</li></ul><p>本月所有新增模型均在此标准体系下进行评估。</p><h2>三、焦点分析</h2><h3>专题一：Ling-1T 首次评测</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405444" alt="发布日期：2025-10-09" title="发布日期：2025-10-09" loading="lazy"/></p><p><em>Ling-1T</em> 作为 <strong>Ling 2.0</strong> 系列的首款旗舰非思考模型，在本月首次参评。其各维度总分分别为：</p><ul><li><strong>SQL 优化</strong>：62.5</li><li><strong>方言转换</strong>：59.2</li><li><strong>SQL 理解</strong>：59.4</li></ul><p>评测结果显示，该模型能力特点鲜明，在特定场景表现优异，但在复杂任务处理上仍存在明显短板。</p><h4>SQL 优化能力：62.5</h4><p><em>Ling-1T</em> 在 <strong>SQL 优化</strong> 维度获得 62.5 分。根据细分指标数据显示，该模型在「<strong>逻辑等价</strong>」方面表现出色，以 84.2 分位列该项第 5 名。</p><p>然而，其在「<strong>优化深度</strong> 」上表现不足，得分仅为 51.1 分（排名第 17），同时「<strong>语法错误检测</strong> 」得分也偏低（84.2分）（排名第 18），分析测评报告可见，模型将符合 MySQL 宽松模式的 <code>GROUP BY</code> 查询误判为有语法错误；对 <code>UNION</code> 查询中 <code>ORDER BY/LIMIT</code> 的语法规则理解不准确。</p><p><strong>核心缺陷</strong> ：模型缺乏对数据库特定模式（如 MySQL 的 <code>ONLY_FULL_GROUP_BY</code>）和 <strong>SQL 标准/方言差异</strong> 的上下文感知能力，过度依赖教条式语法规则，无法根据数据库配置灵活判断语法正确性，导致在边界情况下的误判。这一系列分数表明，模型具备保障逻辑一致性的能力，但在应用深度优化策略和保障语法规范性方面仍有较大提升空间。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405445" alt="Ling-1T：SQL 优化维度评分" title="Ling-1T：SQL 优化维度评分" loading="lazy"/></p><h4>方言转换能力：59.2</h4><p>此维度得分呈现出显著的能力分化（总分 59.2，排名第 17）。<strong>其最大亮点在于对国内数据库生态的适配性</strong> ，其「<strong>国产数据库</strong> 」转换子项获得 100 分满分（与 <a href="https://link.segmentfault.com/?enc=fe3gmIsw%2BL2GLKEs1JsNjw%3D%3D.xJRTIb4M4tdMJKBeYxT%2FodOG4tU8tY70Cj2jCrYvkhM%3D" rel="nofollow" target="_blank">SQLShift</a> 并列），展现了其在该特定场景下的卓越能力。</p><p>然而，模型在处理复杂迁移任务时表现挣扎。「<strong>大 SQL 转换</strong> 」得分仅为 12.9分（排名第 20）。测评报告显示，在复杂 SQL 方言转换中，模型误用不兼容语法（如保留 <code>SET NOCOUNT ON</code>、混用 <code>DBMS_OUTPUT</code> 等），且对控制流、游标、异常处理等结构的语义理解不足，导致转换后语法不兼容或逻辑不等价，这体现出模型对复杂结构化代码的全局理解能力，以及对多方言语义差异的精确把握能力还有待提升。同时，其「<strong>逻辑等价</strong> 」（61.3分）和「<strong>语法错误检测</strong>」（69.0分）得分中等，表明其在处理非国产数据库的复杂转换时，难以保证代码的规范性。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405446" alt="Ling-1T：方言转换维度评分" title="Ling-1T：方言转换维度评分" loading="lazy"/></p><h4>SQL 理解能力：59.4</h4><p>该分数表明 <em>Ling-1T</em> 具备基础的 SQL 解析能力。数据细分显示，其在「<strong>语法错误检测</strong> 」上表现突出，以 87.1 分的成绩与 <em>Claude 3.5 Sonnet</em> 并列该指标测评的第 1 名。</p><p>然而，其在「<strong>执行准确性</strong> 」方面表现不佳，得分仅为 52.9 分（排名第 19），分析测评报告可见，模型在日期条件测评中易出错，如 <code>due_date &lt; '2025-06-07'</code> 的查询中返回了 <code>due_date='2025-06-10'</code> 的记录，明显违反了条件。这类错误反映了模型在执行 SQL 查询时，对日期比较的语义理解与严谨性不足。这是其主要短板之一。</p><p>此外，其「<strong>执行计划检测</strong> 」得分为 57.1 分，模型在执行计划预测时，对 DDL 中未定义索引的字段错误预测了 <code>key</code> 和 <code>possible_keys</code>。例如查询 <code>WHERE fruit_name = 'Banana'</code> 时，模型预测 <code>key: "fruit_name"</code> 和 <code>possible_keys: "fruit_name"</code>，但 DDL 中 <code>fruit_name</code> 字段没有索引，反映出模型过于基于查询模式推测出现误判，在约束验证能力和结构化解析与推理上仍有较大提升空间。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405447" alt="Ling-1T：SQL 理解维度评分" title="Ling-1T：SQL 理解维度评分" loading="lazy"/></p><h3>专题二：Ring-1T 首次评测</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405448" alt="发布日期：2025-10-14" title="发布日期：2025-10-14" loading="lazy"/></p><p><em>Ring-1T</em> 作为基于 <strong>Ling 2.0</strong> 架构的万亿级参数思考模型，展现了比 <em>Ling-1T</em> 更强的综合实力。其各维度总分分别为：</p><ul><li><strong>SQL 优化</strong>：70.5</li><li><strong>方言转换</strong>：69.5</li><li><strong>SQL 理解</strong>：78.1</li></ul><p>能力表现更为均衡。</p><h4>SQL 优化能力：70.5</h4><p>该分数体现了模型在 SQL 优化方面的均衡能力。其「<strong>语法错误检测</strong> 」获得 100 分满分（与 <a href="https://link.segmentfault.com/?enc=iQZhC9UDrY6mCuwN%2BSnOSQ%3D%3D.8WljEnHlA%2B%2BecJWPu%2F7xR%2BlrGzKDgPPpXE2KMtMKM28%3D" rel="nofollow" target="_blank">SQLFlash</a> 并列），保证了优化后代码的规范性与可用性。「<strong>逻辑等价</strong> 」得分为 84.2 分（排名第 6），表现优异。「<strong>优化深度</strong>」得分为 60.0 分（排名第 4），表明模型能够应用常规的优化策略，但在处理复杂的查询、进行深度重构以追求极致性能方面，仍有进步空间。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405449" alt="Ring-1T：SQL 优化维度评分" title="Ring-1T：SQL 优化维度评分" loading="lazy"/></p><h4>方言转换能力：69.5</h4><p><em>Ring-1T</em> 在方言转换维度获得 69.5 分（排名第 11）。细分数据显示，其在「<strong>国产数据库</strong> 」转换（94.7分）、「<strong>语法错误检测</strong> 」（73.8 分，排名第 9）和「<strong>逻辑等价</strong>」（71.0 分）上均表现稳健。</p><p>其短板在于「<strong>大 SQL 转换</strong> 」，得分仅为 41.9 分（排名第 12），模型在处理跨数据库访问（如 SQL Server 的 <code>[server].database.schema.table</code>）、控制流（如 GOTO 标签跳转）、错误处理机制（如 <code>@@ERROR</code> 检查、<code>BEGIN TRY/CATCH</code>）、动态 SQL 执行（如 <code>sp_executesql</code> 参数绑定）等复杂结构时，存在语法混用、语义不等价、结构转换不完整等问题。</p><p><strong>核心缺陷</strong> ：缺乏对复杂结构化代码的全局理解能力，以及对多方言语义差异的精确映射能力，导致转换后的 SQL 在语法正确性或逻辑等价性上存在缺陷。相较于 <em>Ling-1T</em> 的 12.9 分，该分数有了显著提升，表明其在处理「<strong>大 SQL 转换</strong>」和保证代码规范性方面具备更强的能力，使其成为一个更可靠的数据库迁移工具。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405450" alt="Ring-1T：方言转换维度评分" title="Ring-1T：方言转换维度评分" loading="lazy"/></p><h4>SQL 理解能力：78.1</h4><p>得分 78.1 分，这是一个稳健的分数。其在「<strong>执行准确性</strong> 」上表现稳定（84.3分）。但其「<strong>执行计划检测</strong> 」（60.7分）和「<strong>语法错误检测</strong>」（67.1分）得分偏低。</p><p>模型混淆了标准 SQL 语法与数据库特定规则，将正确的标准语法误判为错误（如 GROUP BY 中使用别名 <code>category_prefix</code>、<code>INSERT</code> 子查询 <code>INSERT INTO table (SELECT ...)</code>、<code>CREATE VIEW</code> 中使用 <code>HAVING</code> 等），同时对复杂结构理解不准确，导致误判和漏判并存，反映了模型对标准 SQL 规范的准确理解不足，以及对语法规则判断的机械性。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405451" alt="Ring-1T：SQL 理解维度评分" title="Ring-1T：SQL 理解维度评分" loading="lazy"/></p><h2>四、专家点评</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405452" alt="" title="" loading="lazy"/></p><blockquote><strong>林春</strong>，中国太平洋保险数智研究院首席数据库专家，OceanBase 客户专家委员会（OBCE）专家委员，获得 OBCE 认证。获得 Oracle OCM、PostgreSQL PCM、MySQL OCP 认证。墨天轮 MVP，中国数据库技术大会（DTCC）演讲嘉宾。</blockquote><p>SCALE 2025 年 10 月《大模型 SQL 能力排行榜》的发布，堪称 AI 与数据库协同领域的关键行业参照。其依托"<strong>SQL优化+方言兼容+SQL理解</strong> "的三维测评框架，将大模型在数据库场景的落地能力进行了体系化量化，尤其在 Ling-1T、Ring-1T 等模型的分项表现中，清晰呈现了自然语言与数据库操作的适配差异，<strong>为企业级 AI+ 数据库的技术选型提供了精准的能力标尺</strong>。</p><p>这个榜单通过月度迭代的动态测评范式，既强化了对大模型数据库能力演进的追踪性，又以"细分场景得分+综合能力排名"的形式，缓解了企业对大模型"泛能力强、垂直场景弱"的选型焦虑，这与当前数据库向智能化、场景化演进的趋势高度契合。<strong>它不仅为中小企业提供了低成本评估 AI 数据库工具的参照标准，更倒逼大模型行业加速垂直能力优化 ------ 在 SQL 复杂查询适配、多数据库方言兼容等领域形成技术迭代</strong>。</p><p>SCALE 榜单的价值在于以标准化测评姿态打通了大模型能力与数据库需求的匹配链路，推动"<strong>模型能力评估-场景技术选型-落地效果验证</strong>"全流程的理性化重构，为下一代智能数据系统的技术适配提供了极具实践意义的行业范本。</p><p>我们可以看到，Ring-1T 模型在数据库场景中的核心优势场景包括：</p><ul><li><strong>复杂 SQL 查询生成</strong>：在多表关联、嵌套子查询等复杂 SQL 构建任务中表现突出（SQL 优化能力得分 70.5），可高效将自然语言需求转化为高性能 SQL 语句。</li><li><strong>多数据库方言兼容</strong>：适配 MySQL、Oracle 等主流数据库的语法差异（方言兼容能力得分 69.5），能自动生成符合不同数据库语法规范的操作语句。</li><li><strong>SQL 语义理解与纠错</strong>：对模糊需求、表述不规范的查询指令，具备较强的语义解析与纠错能力（SQL 理解能力得分 78.1），降低自然语言交互的精准度门槛。</li><li><strong>批量数据操作适配</strong>：在批量插入、更新等数据操作场景中，可生成高效且符合数据库性能要求的 SQL 脚本，适配企业级数据批量处理需求。</li></ul><h2>五、总结与展望</h2><p>随着蚂蚁百灵 <em>Ling-1T</em> 和 <em>Ring-1T</em> 两款新模型的加入，<strong>SCALE</strong> 评测榜单已累计收录超过 20 款业界主流 AI 模型及专业工具。本月评测清晰地展示了 <strong>Ling 2.0</strong> 系列两款模型的特点：</p><ul><li><strong>Ling-1T</strong> 在国产数据库适配上表现出众，但在复杂任务处理上存在短板</li><li><strong>Ring-1T</strong> 则展现了更均衡、更强大的综合 SQL 处理能力，特别是在 SQL 理解和优化方面表现稳健</li></ul><p>展望未来，SCALE 将继续秉持客观、严谨的原则：</p><ul><li>持续追踪：我们将继续追踪并迅速引入业界前沿的大模型和 SQL 工具。</li><li>深化场景：我们计划引入更多维度的企业级真实应用场景，使评测结果更贴近实际生产环境。</li></ul><blockquote><p>一个开放、透明的评测生态需要社区的共同建设。我们诚挚地邀请国内外更多的模型开发者、数据库工具提供商提交您的产品参与 SCALE 评测。通过在同一基准下与全球顶尖模型竞技，不仅可以精准定位产品优势与不足，更能提升品牌在开发者社区中的影响力。</p><p>即刻访问 <a href="https://link.segmentfault.com/?enc=SzLc73R6%2B%2BplY%2FrKKvIoYA%3D%3D.H1To2bOix61zfOuf7TOKfEXsp8zYGc3NeDLiJNjnOnRzcqXqq0v3v9MgVnvTA1Ug" rel="nofollow" target="_blank">https://sql-llm-leaderboard.com/ranking/2025-09</a></p><p>查看完整榜单并联系我们提交您的产品。</p></blockquote><p><strong>SCALE ------ 为专业 SQL 任务，选专业 AI 模型。</strong></p>]]></description></item><item>    <title><![CDATA[如何用 5 种方法删除三星手机上的消息/]]></title>    <link>https://segmentfault.com/a/1190000047405476</link>    <guid>https://segmentfault.com/a/1190000047405476</guid>    <pubDate>2025-11-17 18:10:26</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>三星一直向全球众多消费者销售其移动设备。三星智能手机，尤其是三星Galaxy S系列和Note系列，深受许多人的喜爱，特别是白领和大学生。</p><p>您可能对手机的新功能非常感兴趣，但您也应该注意在管理联系人和短信时需要哪些操作。您是否曾经想知道如何在三星手机上删除短信？我们将向您展示一些在三星手机上删除垃圾短信/联系人的方法。</p><h3>第一部分：如何在三星S25/24/23上手动删除短信</h3><p>如何在三星手机上删除短信？最常见的方法是在应用内手动删除。以下是如何在三星 Galaxy S25/S24/S23 上手动删除单条短信的方法。</p><p>步骤 1. 打开三星手机上的短信应用。</p><p>步骤 2. 长按要删除的消息，直到出现菜单。</p><p>步骤 3：从菜单选项中选择“删除”。然后，在出现提示时确认删除。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405478" alt="图片" title="图片"/></p><h3>第二部分：如何通过联系人应用从三星手机中删除联系人</h3><p>就像删除短信一样，在三星手机上删除联系人也很简单。最简单的方法仍然是直接从联系人应用中删除。请按照以下步骤从三星手机中删除联系人：</p><p>步骤 1. 打开三星设备上的“联系人”应用。</p><p>步骤 2. 滚动浏览列表或使用搜索栏找到要删除的联系人。</p><p>步骤 3. 点击联系人以打开其详细信息。</p><p>步骤 4. 点击“编辑”按钮（铅笔图标）或“更多选项”菜单（三个垂直点），然后选择“删除”或“移除”。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405479" alt="图片" title="图片" loading="lazy"/><br/>​</p><h3>第三部分：如何使用Coolmuster Android Eraser 删除三星手机上的信息</h3><p>无法删除三星手机上的短信？之前的方法无法永久删除三星手机上的短信和联系人。如果您想永久删除它们，可以尝试使用Coolmuster Android Eraser软件。</p><p>Coolmuster Android Eraser 是一款专业的数据擦除软件。它可以删除三星手机上的所有内容，包括但不限于短信和联系人。它提供低、中、高三种数据擦除级别，您可以根据需要进行选择。除了三星手机，它还支持大多数Android手机型号，例如 OnePlus、摩托罗拉、小米、Tecno、TCL、谷歌、vivo 等。</p><p>Coolmuster Android Eraser 的主要功能</p><pre><code>彻底清除所有三星数据，包括联系人、短信和其他数据。
确保彻底永久删除个人数据，防止任何恢复尝试。
您可以从三个递增级别的数据清除级别中进行选择：低级别、中级别和高级别。
高级权限可以覆盖数据 3 次，因此无法恢复任何数据。
适用于大多数Android手机，例如三星、荣耀、小米、一加、摩托罗拉等。
支持Android 6.0或更高版本。

</code></pre><p>如何使用Coolmuster Android Eraser 在三星 S25/24 上删除单个短信/联系人？以下是分步指南。</p><p>01安装、下载并打开Coolmuster Android Eraser。之后，使用 USB 数据线或 Wi-Fi 将您的三星手机连接到电脑。</p><p>02连接成功后，按下“擦除”按钮开始擦除过程。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405480" alt="图片" title="图片" loading="lazy"/></p><p>03现在，您可以从低、中或高三个级别中选择您偏好的安全级别。选择后，点击“确定”继续。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405481" alt="图片" title="图片" loading="lazy"/></p><p>04确认后，软件将迅速扫描您的Android手机中的文件并开始数据擦除程序。</p><h3>第四部分：如何使用Coolmuster Android Assistant从三星手机中删除短信</h3><p>除了Coolmaster Android Eraser之外，Coolmaster Android Assistant也能删除三星手机上的短信和联系人。除了删除短信和联系人之外，这款软件还能在电脑和手机之间传输数据，直接在电脑上编辑、添加、发送或恢复短信，以及在电脑上编辑联系人。除了短信和联系人之外，它还支持视频、图片、音乐等多种类型的数据。</p><p>Coolmuster Android Assistant的主要功能</p><pre><code>允许您选择性地删除三星手机短信和联系人。
在电脑上收发短信。
在电脑上轻松编辑现有联系人并创建新联系人。
一键备份和恢复Android手机短信、联系人和其他文件。
兼容最新的Android 16系统。

</code></pre><p>以下是如何使用Coolmuster Android Assistant在三星手机上删除短信的教程：</p><p>01在您的计算机上下载、安装并运行Coolmuster Android Assistant 。</p><p>02选择 USB 或 Wi-Fi 将三星手机连接到电脑。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405482" alt="图片" title="图片" loading="lazy"/></p><p>03连接成功后，从左侧面板选择“短信”。手机上的所有短信都会显示在这里。选中要删除的短信，然后点击页面顶部的“删除”。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405483" alt="图片" title="图片" loading="lazy"/></p><p>如果您想通过此软件从三星手机中删除联系人，步骤与删除短信相同。连接成功后，选择“联系人”类别，勾选要删除的联系人，然后点击“删除”按钮完成操作。</p><h3>第五部分：如何通过恢复出厂设置删除三星 S25/24/23 上的多条短信</h3><p>如果您不想使用第三方软件，但又想彻底删除三星手机上的短信和联系人，可以尝试恢复出厂设置。请注意，此方法会删除手机上的所有数据，因此请谨慎操作。最好在操作前备份您的三星手机。具体步骤如下：</p><p>第一步：进入三星手机的设置界面。找到并点击“常规管理”选项。</p><p>步骤 2. 您会看到“重置”选项。点击它，然后点击“恢复出厂设置”。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405484" alt="图片" title="图片" loading="lazy"/></p><p>步骤 3：向下滚动并点击“重置”。然后输入您的 PIN 码，点击“继续”&gt;“全部删除”，输入您的三星帐户密码，然后点击“确定”。您的三星手机将开始重置，并删除所有短信和其他数据。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405485" alt="图片" title="图片" loading="lazy"/></p><h3>结论</h3><p>以上提到的 5 种方法可以帮助您删除三星手机上的信息/联系人，但只有Coolmuster Android Eraser可以永久删除它们，且无法恢复，包括现有信息和已删除信息。</p><p>如果您想在三星手机上管理短信或联系人，我们推荐使用Coolmuster Android Assistant，这是一款专业的数据管理软件。如果您对此有任何疑问，请在评论区留言。我们会尽快回复您。<br/>​</p>]]></description></item><item>    <title><![CDATA[云栖实录 | 洋钱罐基于 EMR Ser]]></title>    <link>https://segmentfault.com/a/1190000047405499</link>    <guid>https://segmentfault.com/a/1190000047405499</guid>    <pubDate>2025-11-17 18:09:30</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>演讲人：宋晓峰 洋钱罐大数据运维总监</p><h2>十年破壁：从数据筑基到智能生态的全链路实践</h2><h3>一、数据筑基——自建大数据集群的攻坚与突破</h3><h4>背景介绍</h4><p>瓴岳科技（Fintopia）是以大数据和人工智能为基础的数字科技集团，为全球用户提供卓越的金融体验。2015年成立至今，瓴岳科技始终聚焦消费金融，业务遍布中国大陆、东南亚、拉丁美洲和非洲等；集团旗下拥有洋钱罐、Easycash等知名品牌，截至2025年，服务全球金融机构超过114家，全球注册用户超过1.81亿，全球累计交易额超过5400亿元。在公司发展的过程中，我们大数据部门为智能风控、精准营销、产品创新三大核心业务提供数据支撑，整合多源数据，利用机器学习算法实时识别欺诈风险，构建全流程风控体系，基于用户行为、偏好等数据，定制个性化金融服务推荐，通过分析市场趋势与用户需求数据，为产品开发提供精准方向，助力瓴岳科技全球化业务布局。</p><h4>大数据技术栈迭代与升级路径</h4><p>过去十年，洋钱罐的大数据技术栈经历了多次迭代。</p><p>2018年，面对数据孤岛问题及传统MySQL数据库无法有效支持复杂分析任务的挑战，我们自建了首个基于十多个节点的Hadoop大数据集群。当时用户规模约2000万，每日新增数据量约300GB。</p><p>随着业务需求的增长，特别是在2018年至2021年间，原有的MapReduce 框架因处理延迟较高而难以满足日益增长的数据处理时效性要求。因此，在2021年，我们将离线数据处理引擎由MapReduce迁移至Apache spark 2.x，并同步升级了Hive版本至3.x以提升数据仓库性能。彼时，系统每天运行约3,000个批处理作业。</p><p>为进一步提高数据处理效率并响应业务对数据实时性的更高期待，2022年我们引入了数据湖技术Apache Hudi，从而将原本的日全量数据抽取转变为增量更新模式，显著提升了数据的新鲜度至小时级别。</p><p>此外，为了更好地支持交互式查询场景，在2023年我们采用StarRocks作为新的Ad-hoc查询引擎，取代了之前依赖于Spark Thrift Server实现的方法。截至目前，Ad-hoc 日均SQL查询请求量超过8,000，P95响应时间控制在60秒以内。鉴于全球化布局带来的弹性资源、业务稳定性和成本优化要求，我们在2024年对整个集群架构进行了重大升级，将自建集群迁移至阿里云EMR Serverless平台，Yarn 节点规模超过一千台，在此过程中，我们也将spark 2.x升级到了spark 3.x。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdm4tg" alt="image.png" title="image.png"/></p><p>当前，我们集群的整体存储能力已经达到单副本10PB的规模，每日新增数据量约为30TB。核心业务报表数量超过3000份，而调度工作流数量已突破15000个。在StarRocks集群方面，我们同时采用了存算一体化架构与存算分离架构，并根据不同的业务线进行了划分，因此目前拥有超过30个独立的StarRocks集群实例。左侧展示的是我们的调度能力和 Ad-hoc 查询能力，YARN日执行job量超过4万。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdm4tk" alt="image.png" title="image.png" loading="lazy"/></p><h4>从稳定性到效率：自建集群的困境解析</h4><p>在自建大数据集群的过程中，我们遇到了诸多挑战，主要集中在稳定性、弹性资源管理和运维效率三个方面。</p><p>首先，在稳定性方面，我们面临的主要问题是业务SLA破线。这种情况往往源于底层 NodeManager 因网络带宽限制或shuffle 量大而导致任务失败率上升。此外，在使用开源组件过程中，也存在一些 bug 或者性能问题，比如我们在使用 Hive3.x 开源版本时，在高并发的场景下会出现进程卡死等问题，从而影响业务稳定性，无法满足生产环境的要求。</p><p>其次，在弹性资源管理上，自建集群缺乏快速扩展的能力以应对突发流量需求。例如，在凌晨遇到紧急情况时，希望迅速增加计算资源来解决问题变得不可行。同时，即使进行了物理服务器的扩容，在YARN的容量调度策略下，也难以有效平衡不同队列之间的负载分布，导致部分队列利用率过高而其他队列则相对空闲，整体上降低了集群资源利用效率。</p><p>最后，关于运维效率的问题，大数据集群的维护工作相当复杂且耗时。从硬件采购到最终完成配置并投入使用，整个过程通常需要两至三天时间。此外，开发人员还需投入大量精力进行性能调优、故障排除及日常巡检等任务，这不仅增加了人力成本，也影响了团队的工作效率。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdm4ts" alt="image.png" title="image.png" loading="lazy"/></p><h4>Spark 引擎核心痛点解析</h4><p>在使用Apache Spark引擎的过程中，我们遇到了几个核心痛点，这些问题主要集中在资源管理、性能与稳定性、版本升级以及成本控制等方面。</p><p>首先，在资源管理方面，我们面临的主要问题之一是峰值资源的优化。例如，在凌晨执行大规模任务时，该任务可能会占用队列中90%以上的资源，而其他较小的任务虽然只占用了剩余10%左右的资源，但其完成时间却可能更长。这表明了当前资源分配机制存在不合理之处，需要更加精细地调整以提高整体效率。另一个问题是谷值期间资源利用率低下。特别是在非高峰时段（如午夜过后），集群的整体资源利用率往往只能达到30%左右，导致大量计算能力被闲置。</p><p>其次，在性能与稳定性方面也存在问题。当我们使用自建的大数据集群部署Spark时，采用的是开源版的Shuffle Service作为NodeManager组件。然而，在高负载情况下，这种服务的表现并不理想，容易成为瓶颈，并且当单个NodeManager出现问题时，会严重影响到整个集群上运行任务的稳定性和性能。</p><p>第三点关于引擎版本固化的问题也非常突出。比如将 spark 2.x迁移到spark 3.x，不仅耗时较长，还需要充分考虑新旧版本之间的兼容性问题、系统稳定性测试以及对现有业务流程的影响评估等多方面因素。</p><p>最后，在成本控制方面同样存在着挑战。由于不同业务线之间可能存在交叉需求，比如风控场景下的离线数据仓库处理与Adhoc查询同时进行，这就使得很难按照单一业务维度来精确划分和管理相关费用。因此，如何有效地衡量并优化跨部门使用的Spark资源成本，成为了我们需要解决的重要课题之一。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdm4tx" alt="image.png" title="image.png" loading="lazy"/></p><h4>StarRocks 问题解析</h4><p>在使用 StarRocks 的过程中，我们也遇到了一些挑战，主要集中在数据导入、资源隔离及系统稳定性三个方面。</p><p>首先，在数据导入方面，StreamLoad 导入速度慢，支持的数据量有限，当提高数据导入频率时，可能会触发 FE 内存问题，会出现MVC相关报错。Broker Load 虽然导入速度快，但是软性资源隔离策略会影响读性能，最后我们还是要依赖Spark集群的Spark Load解决大数据量导入问题</p><p>其次，关于资源隔离的问题，虽然开源版StarRocks提供了基本的资源隔离功能，但它是软隔离，而非硬性隔离，数据导入与查询操作之间存在竞争关系，尤其是大规模查询请求可能会影响其他小型查询请求的响应时间。</p><p>最后，在系统运维与稳定性保障方面，开源版本没有自带的管控页面，运维人员不得不自行开发一系列脚本来完成扩缩容等请求，增加了运维难度。此外，在面对版本升级时，升级耗时长，还需额外进行业务回归测试以验证新版本兼容性和系统稳定性。</p><p>以上因素共同构成了 StarRocks 在实际应用中面临的主要技术挑战。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdm4tC" alt="image.png" title="image.png" loading="lazy"/></p><h3>二、云帆起航——迁移阿里云 EMR 的全链路实践</h3><p>面对上述挑战，我们对大数据架构进行了全面升级，全面切换至阿里云生态组件。此次升级的核心在于构建了一个符合数据湖理念的全新平台架构，该架构不仅满足了当前业务需求，还为公司未来向数据湖方向的发展奠定了坚实基础。此次升级主要对两个计算引擎进行了重大改造。</p><p>首先，我们将Hive SQL完全迁移至Spark SQL。因为相较于Hive SQL，Spark SQL展现出更优的执行效率，这也是业界共识。整体迁移过程非常丝滑，在性能与兼容性方面，EMR Serverless Spark 表现亮眼，还支持丰富的开源生态，如Kyuubi、Livy等。</p><p>其次，我们将 StarRocks 存算一体版本切换为了存算分离版本，这也顺应了Serverless 架构的发展趋势。</p><p>基于计算引擎升级，我们在上层构建了自己的数据应用产品，如一站式开发平台、标签系统、实时开发平台、数据质量监控系统、Ad-hoc查询等。</p><p>我们还将底层存储从传统HDFS切换为阿里云OSS-HDFS，消除了原生Hadoop文件系统中存在的单点故障问题。相比自建集群成本，新架构成本仅为其十分之一左右。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdm4tF" alt="image.png" title="image.png" loading="lazy"/></p><h4>EMR Serverless Spark：一站式数据平台服务</h4><p>EMR Serverless Spark 提供了一站式的数据平台服务，包括任务开发、调试、调度和运维等，极大地简化了数据处理和模型训练的全流程。内置 SQLEditor、Notebook 开发环境，提供版本管理，工作流调度，以及运维诊断能力。 版本管理功能使得用户能轻松切换Spark版本，只需确保SQL语句能正常运行，数据能正常处理即可，无需考虑底层基础设施的复杂性。</p><p>针对Spark和Python环境，用户可以根据具体业务需求进行配置，如调整spark-defaults.conf文件中的参数值，来优化特定应用场景下的性能表现。通过简单的spark-submit命令配合相关参数，即可快速切换到所需的运行时环境，极大提高了工作效率。</p><p>监控与诊断方面，EMR Serverless Spark 还提供完善的监控与诊断功能。提供工作空间、队列以及任务等各种维度的资源指标统计，方便用户更清晰地掌握作业运行情况。在Spark任务完成之后，收集和分析该任务的各种资源消耗指标，并根据这些指标给出合理的优化建议。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdm4tI" alt="image.png" title="image.png" loading="lazy"/></p><p>EMR Serverless Spark 还提供极致资源弹性与性能。首先，在弹性伸缩方面，支持 Driver/Executor级别进程弹性，最低支持一核力度，容器拉起时间在20秒以内。资源供给方面，底层是 Iaas + 神龙资源池，提供海量供给，自迁移至 EMR Serverless Spark 以来，我们尚未遇到任何资源短缺问题。</p><p>此外，EMR Serverless Spark 采用类似于YARN的资源管理模式。Workspace/队列两层Quota管理支持用户根据业务特性选择合适的提交路径。平台提供了基于Workspace/队列/作业的多维度、精确到天/时/分的多周期资源观测能力。</p><p>性能方面，EMR Serverless Spark 自研 Fusion 引擎，内置高性能向量化计算和 RSS 能力，相比开源版本性能大幅提升。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdm4tJ" alt="image.png" title="image.png" loading="lazy"/></p><h4>EMR Serverless StarRocks：功能丰富、性能卓越</h4><p>EMR Serverless StarRocks在管控能力方面显著优于自建方案，提供实例管理功能，包括创建，扩容缩容，升降配，网络管理，白名单管理，操作任务管理，网关管理等。</p><p>此外，其管控平台提供实例健康报告与慢SQL诊断分析、可视化缓存管理、支持大/小版本主动触发滚动升级、支持全链路实例操作审计等功能。</p><p>值得一提的是，EMR Serverless StarRocks 实现了真正的存算分离架构，提供物理隔离能力，不同计算组作业负载相互独立，支持多计算组独立配置。在我们的实际应用场景下，存算分离内表查询较开源性能提升约100%，数据湖查询较开源性能提升约50%。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdm4tS" alt="image.png" title="image.png" loading="lazy"/></p><p>下图展示了基于EMR Serverless StarRocks 的湖仓新范式，StarRocks 作为统一 Lakehouse，基于湖表进行自助分析查询。数据写入 StarRocks 提供极速分析；数据写入开放数据湖，使用 StarRocks 直接分析数据湖；在DWD、DWS以及ADS层，通过构建物化视图并实施分层建模策略，不仅能够有效支撑各类报表需求，同时也为OLAP提供了强有力的支持。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdm4tX" alt="image.png" title="image.png" loading="lazy"/></p><h4>架构升级带来的关键价值</h4><p>上述重大架构升级，带来了哪些关键价值呢？</p><p>首先，在成本优化方面，通过引入弹性资源，显著提高了资源利用率。</p><p>其次，从业务稳定性角度来看，EMR Serverless Spark 自带的高性能 Shuffle 服务，极大地增强了系统的稳定性和可靠性。此外，StarRocks 的性能优化也进一步提升了整体业务处理能力与响应速度。</p><p>关于业务敏捷性，新架构支持快速部署新业务场景所需的计算资源，从而大幅缩短了业务上线周期。</p><p>运维效率方面，得益于 EMR Serverless Spark与 EMR Serverless StarRocks 丰富的管控能力，开发团队所需投入的日常维护工作量显著减少。同时，平台提供了全天候的技术支持服务，确保即使面对突发问题也能迅速获得解决方案，进一步保障了系统的连续可用性。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdm4t1" alt="image.png" title="image.png" loading="lazy"/></p><p>具体而言，在保持业务规模不变的前提下，与传统的自建方案相比，基于 EMR Serverless 构建的解决方案能够实现约25.4%的成本节约。基于 EMR Serverless StarRocks 进行查询（如标签系统和用户圈选场景），SQL 查询执行时长缩短了30%。此外，在相同成本情况下，EMR Serverless Spark 作业的执行时间也缩短了30%以上。最值得注意的是运维效率方面的改进，实现了近40%的大幅提升。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdm4ur" alt="image.png" title="image.png" loading="lazy"/></p><h3>三、智创未来——未来基于阿里云的智能生态布局</h3><p>在完成架构升级后，整体稳定性得到显著提升。展望未来，我们的目标是构建一个更加智能化的金融生态环境。为此，我们设想了四个主要发展方向：</p><p>首先，在数据处理方面，我们计划基于阿里云EMR及机器学习平台PAI来实现高效的数据协同架构。</p><p>其次，在业务流程优化上，通过整合阿里云的大规模模型能力，旨在创建一个既简化又高效的运营环境，涵盖预测式风控、自动化运营，大智能化监控等领域。</p><p>再者，在应用层面，致力于形成以数据为驱动并支持智能决策的完整业务闭环。</p><p>最后，在算法创新方面，我们将依托于阿里云机器学习平台PAI，专注于开发适用于特定行业的专属AI模型库。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdm4ut" alt="image.png" title="image.png" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[这两个开源项目在世界互联网大会乌镇峰会获]]></title>    <link>https://segmentfault.com/a/1190000047405501</link>    <guid>https://segmentfault.com/a/1190000047405501</guid>    <pubDate>2025-11-17 18:08:36</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>2025 <strong>“直通乌镇”全球互联网大赛</strong>是世界互联网大会乌镇峰会重要活动之一，自 2019 年以来已连续举办 7 届。本届大赛以“发现未来新势力 共筑数字新生态”为主题，设置人工智能、智联出行、数智医疗、智能制造、智能终端、开源项目（分为开源模型应用赛和开源竞技挑战赛）六大赛道。</p><p>自 6 月启动报名以来，共吸引来自全球 29 个国家的 1082 个项目报名参赛，其中国内项目 864 个、海外项目 218 个。经过激烈角逐，共有 71 个项目入围决赛，包含海外项目 11 个。在最终的决赛中：</p><p><strong>Spring AI Alibaba</strong> 和 <strong>Higress</strong> 分别获得了开源先锋社区、开源优秀社区的称号，两位社区贡献者<strong>张圣航</strong>（GitHubID: shenghang）、<strong>刑国富</strong>（GitHubID: erasernoob）获得最具价值贡献者奖。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405503" alt="image" title="image"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405504" alt="image" title="image" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405505" alt="image" title="image" loading="lazy"/></p><p>感谢所有社区贡献者和开发者用户们的信任。</p><h3>关于 Spring AI Alibaba</h3><p>Spring AI Alibaba 开源项目基于 Spring AI 构建，是阿里云通义系列模型及服务在 Java AI 应用开发领域的最佳实践，提供高层次的 AI API 抽象与云原生基础设施集成方案，帮助开发者快速构建 AI 应用。目前，Spring AI Alibaba 底层正升级到 AgentScope，未来作为 AgentScope 生态的一环，定位是做好 Spring 和 AgentScope 的连接。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405506" alt="image" title="image" loading="lazy"/></p><h3>关于 Higress</h3><p>Higress 是一款开源的 API 网关，内核基于 Istio 和 Envoy，可以用 Go/Rust/JS 等编写 Wasm 插件，提供对 K8s 集群的 Ingress 入口网关, 并且兼容了大量 K8s Nginx Ingress 的注解，可以从 K8s Nginx Ingress 快速平滑迁移到 Higress。此外，作为一款 AI 网关，提供 LLM API 和 MCP API 的统一管理。已服务于通义千问、阿里云百炼、携程、蚂蚁数科、钉钉、优酷、快手、Paypal、汤臣倍健、UU跑腿、Sealos、国泰产险等互联网、金融、IT 服务等多行业的企业客户。</p><p>率先在国内开源 AI 网关的通用能力，包括</p><ul><li>面向大模型：统一代理各主流大模型和自建大模型服务，提供 OpenAI 兼容的访问方式，并提供二次 API KEY 签发、限流、安全防护、观测等治理能力 。</li><li>面向 Agent：用户可便捷、安全地将各类智能体能力无缝集成至业务系统，实现智能对话、流程自动化等创新功能，助力企业高效构建智能化应用生态。</li><li>面向 MCP：支持 API-to-MCP 快速转化，并提供 MCP Server 代理、安全认证，以及统一观测、限流等治理能力。</li></ul>]]></description></item><item>    <title><![CDATA[如何删除 iPhone 短信记录中显示的]]></title>    <link>https://segmentfault.com/a/1190000047405513</link>    <guid>https://segmentfault.com/a/1190000047405513</guid>    <pubDate>2025-11-17 18:07:43</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>​在 iPhone 的“信息”应用中，发送或接收短信后，对方的电话号码或联系人姓名会被系统自动记录，并显示在搜索栏或最近联系人建议中。虽然这是为了方便用户快速访问，但许多用户为了保护隐私或避免误发信息，会选择清理这些最近联系人。那么，如何在 iPhone 的短信记录中删除最近联系人呢？本文将提供三种解决方案供您参考。</p><h3>第一部分：如何在 iPhone 上通过删除整个对话来删除“信息”应用中的最近联系人</h3><p>从短信记录中删除最近联系人的最简单方法是删除与该联系人关联的整个短信对话。要执行此操作，请按照以下步骤操作：</p><p>步骤 1. 打开 iPhone 上的“信息”应用。</p><p>步骤 2. 点击顶部的“编辑”，然后选择要删除的对话。</p><p>步骤 3. 点击“垃圾桶”图标。</p><h3>第二部分：如何通过“信息”应用删除 iPhone 上最近删除的联系人</h3><p>你也可以直接从 iPhone 的“信息”应用中删除最近联系人。但问题是，你必须在“信息”应用中逐个删除它们。</p><p>如何在短信中删除最近联系的联系人？以下是步骤：</p><p>步骤 1. 解锁你的 iPhone，然后打开通讯录应用，确认你已从通讯录中删除不需要的电话号码或联系人。</p><p>步骤 2. 然后切换到“信息”应用，新建一条信息，然后开始输入要删除的联系人的姓名或电话号码。</p><p>步骤 3. 当不需要的联系人出现在短信记录中时，点击联系人右侧的带圆圈的“i”图标，打开新的联系人信息窗口。</p><p>第四步，请找到并点击“从最近联系人中移除”选项。确认是否是您要移除的联系人。如果是，请点击删除不需要的电话号码。</p><p>步骤 5. 删除不需要的联系人信息后，您将返回到“新建消息”窗口，您会注意到不需要的联系人已消失，并且仅显示“通讯录”应用中的正确联系人信息。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405515" alt="图片" title="图片"/><br/>​</p><h3>第三部分：如何永久删除 iPhone 短信历史记录中显示的最近联系人</h3><p>逐个从 iPhone 信息应用中删除最近联系人可能很麻烦，而且如果您想确保已从 iPhone 或 iPad 中彻底删除所有不需要的最近联系人，那更是难上加难。因此，我们向您推荐一款专业的iOS数据擦除工具Coolmuster iOS Eraser 。</p><p>有了它，您可以在一个程序中系统地管理 iPhone/iPad/iPod 上的所有联系人，包括现有联系人和已删除联系人。除了已删除的联系人之外，您还可以从 iDevice 中彻底清除已删除的信息、日历、提醒事项、语音备忘录、照片、备忘录、通话记录、Safari 书签等，且无法恢复。</p><p>iOS橡皮擦的主要功能：</p><pre><code>安全永久地清除iOS设备上的所有数据，包括个人信息、系统设置、已删除的文件等。
您可以选择三种擦除级别（低、中、高）来满足您的特定需求。
确保现有数据和已删除数据均被永久清除，无法恢复。
永久删除各种数据类型，例如联系人、短信、通话记录、音乐、视频、照片、应用程序和应用程序数据、提醒事项、日历、书签、浏览历史记录、语音备忘录、笔记和设置（包括 iCloud 和 iTunes 帐户信息）。
以 100% 只读模式运行，确保在数据擦除过程中不会对您的设备造成任何损害。
完全兼容所有 iPhone、iPad 和 iPod touch 机型，包括最新的 iPhone 17 和iOS 26。

</code></pre><p>以下是该程序的Mac和Windows版本免费试用版。请将其下载到您的电脑上，即可轻松删除iPhone短信记录中显示的最近联系人。</p><p>以下是如何使用iOS Eraser 在 iPhone 信息中删除最近联系人：</p><p>01使用 USB 数据线将您的 iPhone/iPad/iPod 连接到电脑。软件将自动检测您的设备，并显示主界面，即可开始抹掉数据。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405516" alt="图片" title="图片" loading="lazy"/></p><p>02点击“擦除”按钮，选择所需的安全级别（低、中或高），然后点击“确定”进行确认。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405517" alt="图片" title="图片" loading="lazy"/></p><p>03出现提示时，输入“删除”进行确认，然后再次点击“擦除”。将出现最终确认信息；点击“确定”以永久删除数据。</p><p>04流程完成后，设备上的所有数据将被永久删除且无法恢复。之后，您可以将您的 iDevice 设置为新设备。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405518" alt="图片" title="图片" loading="lazy"/></p><h3>结论</h3><p>如果您遇到最近删除的联系人仍然出现在 iPhone 短信记录中的问题，可以使用上述方法解决。如果您想要彻底、不可逆地完全清除所有残留记录，那么Coolmuster iOS Eraser无疑是最佳选择。它可以从系统深处删除所有隐私痕迹，确保联系人不再出现在短信记录或建议中，非常适合对隐私要求较高的用户。<br/>​</p>]]></description></item><item>    <title><![CDATA[Invicti v25.11 发布，新增]]></title>    <link>https://segmentfault.com/a/1190000047405540</link>    <guid>https://segmentfault.com/a/1190000047405540</guid>    <pubDate>2025-11-17 18:07:03</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>Invicti v25.11 发布，新增功能简介</p><p>Invicti v25.11.0 for Windows - Web 应用程序安全测试</p><p>Invicti (formerly Netsparker) | Web Application and API Security for Enterprise</p><p>请访问原文链接：<a href="https://link.segmentfault.com/?enc=1rKWWP%2B%2FDLfuZz1JyWg39Q%3D%3D.E5ro8elUnXsMuluk5uBAr522ecCVGBEbrlmCD0jxvMM%3D" rel="nofollow" target="_blank">https://sysin.org/blog/invicti/</a> 查看最新版。原创作品，转载请保留出处。</p><p>作者主页：<a href="https://link.segmentfault.com/?enc=GhT8Zvdy5r7g751c2sZd7A%3D%3D.ZaidUYZiqSGinCEqvd1cElrfCED7fRwxqR3qmv9Uo0c%3D" rel="nofollow" target="_blank">sysin.org</a></p><hr/><p>Invicti 是一种自动化但完全可配置的 Web 应用程序安全扫描程序，使您能够扫描网站、Web 应用程序和 Web 服务，并识别安全漏洞。Invicti 可以扫描所有类型的 Web 应用程序，无论其构建平台或语言。</p><ul><li>Invicti 是唯一一款能够以只读且安全的方式自动利用已识别漏洞以确认已识别问题的在线 Web 应用程序安全扫描程序。</li><li>它还提供了漏洞证明，因此您无需浪费时间手动验证它。例如，在检测到 SQL 注入漏洞的情况下，它将显示数据库名称作为利用证明。</li></ul><p>Invicti 的扫描技术旨在帮助您轻松保护 Web 应用程序而无需忧虑枝节小事，因此您可以专注于修复报告的漏洞。如果 Invicti  无法自动确认漏洞，它会通过在它前面加上 ‘[Possible]’ 并分配一个确定性值来通知您该漏洞，因此您知道应该立即修复什么。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000045076921" alt="Invicti-Logo" title="Invicti-Logo"/></p><p>Invicti (formerly Netsparker) 应用安全测试</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000045076922" alt="invicti-homepage-dashboard" title="invicti-homepage-dashboard" loading="lazy"/></p><p>Invicti - The Largest Dynamic Application Security Solutions Provider In The World</p><h2>新增功能</h2><p>Invicti Standard v25.11.0 - 2025 年 11 月 11 日</p><p><strong>改进</strong>：</p><ul><li>改进了 “SameSite Cookie 未实现” 安全检查</li><li>改进了 “JWT 签名未验证” 安全检查</li></ul><p><strong>已解决的问题</strong>：</p><ul><li>修复了由于加载认证配置文件问题导致的登录失败</li><li>修复了 Linux/云代理无法解析请求前查询参数中的密钥的问题</li><li>改进了应用程序的启动时间</li></ul><h2>下载地址</h2><p>想要开始学习和研究？</p><ul><li>请访问：<a href="https://link.segmentfault.com/?enc=9tKYnCBBt9j%2FKej84FL7lA%3D%3D.K7l40Vjl3y%2BzIgrLjoy6xnT6%2BtQ%2BVPTnvFmO%2Be3X9%2B4%3D" rel="nofollow" target="_blank">https://sysin.org/blog/invicti/</a></li></ul><hr/><p>更多：<a href="https://link.segmentfault.com/?enc=ntySBNIj2%2FeNkxmzPGKY9w%3D%3D.bUTDi6%2FbRuipU6MhhbozWHpDPbW51E2%2Bu88qS8SVQ5E%3D" rel="nofollow" target="_blank">HTTP 协议与安全</a></p>]]></description></item><item>    <title><![CDATA[如何将 OnePlus 手机中的联系人传]]></title>    <link>https://segmentfault.com/a/1190000047405544</link>    <guid>https://segmentfault.com/a/1190000047405544</guid>    <pubDate>2025-11-17 18:06:31</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>如果您正 从 OnePlus 手机换到 iPhone，并且想知道如何将联系人从 OnePlus 手机转移到 iPhone，您并不孤单。许多用户在升级设备时都会遇到这个问题。幸运的是，有几种方法可以快速高效地转移联系人。在本指南中，我们将为您介绍五种将联系人从 OnePlus 手机转移到新 iPhone 的有效方法。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405546" alt="图片" title="图片"/><br/>​</p><h3>第一部分：如何一键将 OnePlus 手机联系人传输到 iPhone</h3><p>将 OnePlus 手机联系人传输到 iPhone 最简单快捷的方法之一是使用Coolmuster Mobile Transfer 。这款工具提供一键式解决方案，可在Android和 iPhone 之间传输数据，包括联系人。对于追求便捷体验的用户来说，这是一个绝佳的选择。它的优势在于操作简单、速度快，而且无需网络连接。无论您是新手还是经验丰富的用户，都能轻松上手。</p><p>Coolmuster Mobile Transfer的亮点：</p><pre><code>只需单击一下，即可轻松将联系人从Android （OnePlus）传输到 iPhone 。
将电子书（PDF 和 ePub）和联系人从Android传输到 iPhone。
您可以选择四种灵活的传输方式： iOS到iOS 、 Android到iOS 、 iOS到Android和Android到Android 。
完全兼容最新的iOS 26和Android 16系统。
体验快速、无缝、安全的数据传输，无需担心数据丢失。

</code></pre><p>如何将 OnePlus 手机上的联系人传输到 iPhone？请按照以下步骤操作：</p><p>01首先，请在电脑上下载并安装Coolmuster Mobile Transfer 。使用 USB 数据线将您的 OnePlus 手机和 iPhone 连接到电脑。请确保您的 OnePlus 手机已启用 USB 调试模式。</p><p>02在电脑上打开该工具。连接成功后，选择 OnePlus 作为源设备，iPhone 作为目标设备。如果未选择，请点击“翻转”按钮进行切换。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405547" alt="图片" title="图片" loading="lazy"/></p><p>03勾选“通讯录”选项，确保只传输通讯录，然后点击“开始复制”按钮，开始将通讯录从 OnePlus 手机传输到 iPhone。传输完成后，您的通讯录就会出现在新的 iPhone 上。</p><h3>第二部分：如何通过“移动到iOS将联系人从 OnePlus 手机转移到 iPhone</h3><p>将联系人从 OnePlus 手机传输到 iPhone 的另一种有效方法是使用“转移到iOS应用。“转移到iOS是苹果官方推出的迁移工具，专为Android用户设计。它可以帮助您将联系人、短信、照片等数据从Android手机传输到 iPhone 。数据传输通过 Wi-Fi 进行，因此对于初次使用 iPhone 的用户来说，这是一个完美的解决方案。</p><p>以下是如何通过“转移到iOS将 OnePlus 手机中的联系人复制到 iPhone 的方法：</p><p>步骤 1. 从 Google Play 商店在您的 OnePlus 设备上安装“迁移到iOS应用程序。</p><p>步骤 2. 在新 iPhone 上，开始设置过程，并在“应用与数据”部分出现提示时选择“从Android转移数据”。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405548" alt="图片" title="图片" loading="lazy"/><br/>​</p><p>步骤 3. 在您的 OnePlus 手机上打开“转移到iOS应用程序，并按照屏幕上的说明进行操作。</p><p>第四步：iPhone 上会显示一个六位数的代码。请在 OnePlus 设备上输入此代码以建立连接。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405549" alt="图片" title="图片" loading="lazy"/><br/>​</p><p>步骤 5. 选择“联系人”和您想要传输的任何其他数据，然后点击“下一步”。</p><p>第六步：等待传输过程完成。完成后，您的联系人即可在您的 iPhone 上使用。</p><h3>第三部分：如何使用 Google 帐户将 OnePlus 手机中的联系人同步到 iPhone</h3><p>如果您之前在 OnePlus 手机上启用了 Google 帐户同步，则可以通过 Google 帐户直接将联系人导入 iPhone。只需将您的 Google 帐户添加到 iPhone，联系人就会自动导入。</p><p>以下是如何使用 Google 帐户将 OnePlus 手机上的联系人传输到 iPhone 的方法：</p><p>第一步：确保您的联系人已与您的 Google 帐户同步。为此，请转到“设置”&gt;“帐户”&gt;“Google”，并确保“联系人”同步已启用。</p><p>步骤 2. 在您的 iPhone 上，前往“设置”&gt;“邮件”&gt;“帐户”&gt;“添加帐户”，然后选择“Google”。</p><p>步骤 3. 使用您的 Google 帐户用户名和密码登录。</p><p>步骤 4. 登录后，确保“联系人”开关已打开。</p><p>第五步：您的 Google 联系人将自动与 iPhone 上的“通讯录”应用同步。您可以立即查看它们。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405550" alt="图片" title="图片" loading="lazy"/></p><h3>第四部分：如何通过 VCF 文件将 OnePlus 手机中的联系人导入 iPhone</h3><p>如果您只需要传输一部分联系人，使用 VCard 文件（.vcf 文件）是一种简单的方法。</p><p>以下是如何通过 VCF 文件将 OnePlus 手机中的联系人导入 iPhone 的方法：</p><p>步骤 1. 打开 OnePlus 手机上的“联系人”应用，进入“设置”，然后选择“导出”。选择将联系人保存为 VCF 文件。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405551" alt="图片" title="图片" loading="lazy"/></p><p>步骤 2. 将 VCF 文件通过电子邮件发送给自己，或者使用云存储服务（如 Google Drive）保存该文件。</p><p>步骤 3. 打开 iPhone 上的电子邮件或云存储，下载 VCF 文件。</p><p>第四步：点击 VCF 文件将其打开。你的 iPhone 会询问你是否要将联系人添加到“通讯录”应用；点击“添加所有联系人”。</p><p>步骤 5. 导入完成后，您的所有联系人将出现在您的 iPhone 上。</p><h3>第五部分：如何使用 SIM 卡将 OnePlus 手机中的联系人传输到 iPhone</h3><p>如果您只需要传输联系人而无需传输其他数据，使用 SIM 卡是一种简单常用的方法。您可以将 OnePlus 手机中的联系人保存到 SIM 卡中，然后再将其导入到 iPhone 中。</p><p>以下是如何使用 SIM 卡将 OnePlus 手机中的联系人发送到 iPhone 的方法：</p><p>步骤 1. 打开 OnePlus 手机上的“联系人”应用，进入“设置”，然后选择“导入/导出”。选择将联系人导出到 SIM 卡。</p><p>步骤 2. 从 OnePlus 手机中取出 SIM 卡，然后将其插入 iPhone。</p><p>步骤 3. 在您的 iPhone 上，前往“设置”&gt;“通讯录”&gt;“导入 SIM 卡通讯录”。</p><p>步骤 4. 等待联系人导入，它们将出现在 iPhone 的“通讯录”应用中。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405552" alt="图片" title="图片" loading="lazy"/><br/>​</p><h3>总结</h3><p>将 OnePlus 手机上的联系人传输到 iPhone 时，您可以根据自身需求和设备情况选择多种方法。对于大多数用户而言，使用“转移到iOS应用或通过 Google 帐户同步是最便捷的选择。如果您只需要传输部分联系人，手动使用 VCard 文件也是一个不错的选择。为了更高效地迁移数据， Coolmuster Mobile Transfer是另一个值得尝试的工具。</p><p>无论你选择哪种方法，迁移之前务必备份你的联系人，以免数据丢失。<br/>​</p>]]></description></item><item>    <title><![CDATA[智能计划助手怎么优化资源调度和排产流程？]]></title>    <link>https://segmentfault.com/a/1190000047405567</link>    <guid>https://segmentfault.com/a/1190000047405567</guid>    <pubDate>2025-11-17 18:05:42</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在当今瞬息万变的制造业环境中，企业正面临着前所未有的运营挑战：订单波动剧烈、资源调度复杂、交货周期难以准确预测。传统依赖人工经验的生产计划模式已显疲态，无法满足现代制造业对柔性、高效与智能化的迫切需求。正是在这一背景下，智能计划助手应运而生，以其算法驱动的智慧，为制造业注入全新的活力与效率。广域铭岛作为这一领域的先驱，通过其深度集成的智能体系统，展现了智能计划助手如何成为企业数字化转型的关键引擎。<br/>智能计划助手的核心在于其能够动态分析海量数据，实现精准的资源配置与调度。传统排产方式效率低下，计划员需手动调整数十种约束参数，耗时长达数小时，且结果往往不尽人意。而智能计划助手则凭借机器学习与自然语言处理技术，在短短分钟内生成多套高满足率的方案，并通过实时模拟验证效果。这种转变不仅是技术上的飞跃，更是思维模式的革新——从“经验主义”的试错，迈向“算法驱动”的精准决策。广域铭岛的实践案例表明，智能计划助手绝非空中楼阁；例如在某大型整车工厂，单次排产时间从6小时压缩至0.5-1小时，释放了大量人力资源，让工程师专注于战略规划，而非繁琐的操作。<br/>进一步地，智能计划助手通过智能调度引擎，快速响应市场变化与异常情况。订单频繁调整或临时插单曾是企业运营的噩梦，但智能计划助手能在10秒内完成全局生产计划的重新计算，支持多目标优化，如交期优先或成本优先。广域铭岛为电子制造企业部署的系统，使订单准时交付率从75%提升至94%，异常响应速度从滞后数小时缩短为实时预警。这种敏捷性不仅提升了生产效率，更增强了企业的市场竞争力，使智能计划助手成为应对不确定性的强大盾牌。<br/>全流程可视化监控是智能计划助手的另一大优势，它实现了从原材料到成品的无缝追踪与风险预警。通过实时生产看板，企业可以洞察每一个环节的运作状态，异常情况自动报警，从而减少客户投诉与运营成本。广域铭岛在合作的一家机械制造企业中，利用智能计划助手将交货周期预测准确率提高至96%，极大提升了管理透明度与决策敏捷性。移动端功能的集成，更使得决策者可以随时随地掌控生产动态，凸显了智能计划助手在现代化管理中的不可或缺性。<br/>然而，智能计划助手的崛起并非没有挑战。算法稳定性、数据基础与团队接受度仍是需要权衡的因素。广域铭岛通过云边协同架构和持续优化模型，部分解决了这些难题，但其成功仍依赖于企业的整体数字化成熟度。未来，随着5G和物联网技术的普及，智能计划助手或将进一步进化，实现全链路智能化，甚至自主决策生产流程，为制造业带来更深刻的变革。<br/>总之，智能计划助手代表了制造业排产的未来方向——它不仅是工具，更是战略资产。广域铭岛的创新实践为我们描绘了一幅蓝图：如何通过算法赋能，将繁琐的人工操作转化为高效、精准的自动化流程。在这个充满变数的时代，拥抱智能计划助手，或许正是企业决胜千里的关键一步。</p>]]></description></item><item>    <title><![CDATA[Dify 上线 GMl Cloud 插件]]></title>    <link>https://segmentfault.com/a/1190000047405580</link>    <guid>https://segmentfault.com/a/1190000047405580</guid>    <pubDate>2025-11-17 18:04:44</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><strong>摘要</strong></p><p>GMI Cloud 插件正式无缝集成到 Dify！提供高性能的多系列模型，如<strong>Minimax</strong>、<strong><em><em>DeepSeek</em></em></strong>、<strong><em><em>GPT OSS</em></em></strong>、<strong><em><em>Qwen</em></em></strong>、<strong><em><em>Keling</em></em></strong>等，支持市场研究、模型评估、文献综述等任务处理。大家只需获取 GMI Cloud API 密钥，在 Dify 安装配置插件，即可借助模板构建深度研究工作流程。本文为步骤的详细教程。**</p><p><strong><em>01</em></strong></p><p><strong><em>概述</em></strong></p><p>GMI Cloud 是一个强大的云原生 GPU 基础设施平台，专为高性能 AI 推理服务设计。适配 Dify 的 GMI Cloud 插件可让你将 GMI Cloud 的功能无缝集成到 Dify 工作流程中。以下是插件的主要功能：</p><ul><li>OpenAI 兼容的 API：支持通过标准 OpenAI 客户端库和工具实现无缝集成。</li><li>多个模型系列：获取丰富的模型资源，包括 DeepSeek、Llama、Qwen、OpenAI OSS 和 GLM 模型。</li><li>高性能：针对快速推理和低延迟优化，非常适合需大量计算能力的研究任务。</li><li>流媒体支持：支持实时流式传输，实现流畅聊天交互。</li><li>工具调用：支持函数调用，可将外部工具集成到工作流程中。</li><li>自定义模型支持：轻松部署和使用你自己的微调模型。</li><li>灵活的端点：可为企业级部署配置自定义 API 端点。</li></ul><p><img width="723" height="217" referrerpolicy="no-referrer" src="/img/bVdm4vm" alt="图片" title="图片"/></p><p>配置插件后，你可以访问和使用插件附带的一系列预设模型。目前包含以下类别：</p><ul><li>DeepSeek：</li><li>deepseek-ai/DeepSeek-V3-0324</li><li>deepseek-ai/DeepSeek-V3.1</li><li>OpenAI OSS：</li><li>openai/gpt-oss-120b</li><li>Meta-Llama：</li><li>meta-llama/Llama-4-Scout-17B-16E-Instruct</li><li>Qwen：</li><li>Qwen/Qwen3-32B-FP8</li><li>Qwen/Qwen3-Next-80B-A3B-Instruct</li><li>Qwen/Qwen3-235B-A22B-Thinking-2507-FP8</li><li>Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8</li><li>智谱（ZAI）：</li><li>zai-org/GLM-4.6</li></ul><p>这些模型具备多种功能，可用于执行自然语言处理、文本生成、代码生成等任务。</p><p>通过以下链接可以获取该插件的最新文档（复制到浏览器中打开）：</p><p><a href="https://link.segmentfault.com/?enc=d0ubndw9xi3jCAlIwtPc9w%3D%3D.cbSKTP2S1bjI4%2FqoMTQtvSOe%2BMGA5rTJpu8zyuJivGCdohgGu92Yhf413hwimhsDA5AdWgudhcfmDDT0uR0a%2BQ%3D%3D" rel="nofollow" target="_blank">https://marketplace.dify.ai/plugins/langgenius/gmicloud</a></p><p><strong><em>02</em></strong></p><p><strong><em>分步指南</em></strong></p><p><strong>第 1 步：从 GMI Cloud 获取 API 密钥</strong></p><p>若你尚未准备好 API 密钥，请先前往 GMI Cloud 控制台创建：</p><ol><li>登录 GMI Cloud 控制台，进入 API 密钥管理页面。</li><li>点击「创建 API 密钥」，为其设置易记名称，然后选择 “范围” 为 “推理”。</li><li>请妥善保存你的 API 密钥，关闭弹出窗口后将无法再次查看。</li></ol><p><img width="723" height="473" referrerpolicy="no-referrer" src="/img/bVdm4vn" alt="图片" title="图片" loading="lazy"/></p><p><strong>第 2 步：在 Dify 中安装插件</strong></p><p>接下来操作 Dify：前往 Dify 插件市场（路径：Plugins - Dify <a href="https://link.segmentfault.com/?enc=DtkHXTB0gdS%2BP1susVabpQ%3D%3D.HuNUNm9FeLDDfScjQCkBFjX8mDiaigHi3sZIi3a0hDHrlgsZmBW5U4Asvn0bQ%2FjD" rel="nofollow" target="_blank">https://cloud.dify.ai/plugins?category=discover</a>），搜索并安装 GMI Cloud 插件。</p><p><img width="723" height="742" referrerpolicy="no-referrer" src="/img/bVdm4vo" alt="图片" title="图片" loading="lazy"/></p><p><strong>第 3 步：在 Dify 中配置插件</strong></p><p>现在为 Dify 中的插件完成配置：</p><ol><li>打开 Dify，进入设置→模型提供程序。</li><li>在可用提供商列表中找到 GMI Cloud，点击「设置」。</li><li>在 API 密钥字段中输入你的密钥，这是唯一必填项。</li><li>（可选）若你的组织使用自定义端点，可输入 API 端点 URL；否则插件默认值为：<a href="https://link.segmentfault.com/?enc=liApYWv4EOVOjcgn7Relrg%3D%3D.%2B8TMKtr1bse1B35EYLNbbPZSPJy5%2Fvf1xcJui%2Bqcb3k%3D" rel="nofollow" target="_blank">https://api.gmi-serving.com/v1</a>。</li><li>点击「保存」激活插件。</li></ol><p>Dify 将通过调用 /v1/models 端点验证你的凭据，确保所有设置无误。</p><p><img width="723" height="351" referrerpolicy="no-referrer" src="/img/bVdm4vp" alt="图片" title="图片" loading="lazy"/></p><p>若配置成功，你将看到绿灯提示。此时即可开始构建工作流程！</p><p><img width="723" height="308" referrerpolicy="no-referrer" src="/img/bVdm4vq" alt="图片" title="图片" loading="lazy"/></p><p><strong>第 4 步：在 Dify 中构建深度研究工作流程</strong></p><p>进入首页，点击「从模板创建」：</p><p><img width="723" height="416" referrerpolicy="no-referrer" src="/img/bVdm4vr" alt="图片" title="图片" loading="lazy"/></p><p>本次将使用 Dify 官方提供的 DeepResearch 模板。</p><p><img width="723" height="371" referrerpolicy="no-referrer" src="/img/bVdm4vs" alt="图片" title="图片" loading="lazy"/></p><p>在插件安装页面，请务必勾选两个工具：Tavily 和 JSON Process。无需启用另外两个模型提供程序插件，我们将使用 GMI Cloud 的模型端点。</p><p><img width="723" height="371" referrerpolicy="no-referrer" src="/img/bVdm4vt" alt="图片" title="图片" loading="lazy"/></p><p>复杂的图表看似很多，但无需困扰，我们只需关注两个节点：LLM 节点和推理模型节点——用 GMI Cloud 的模型端点替换它们。</p><p><img width="723" height="371" referrerpolicy="no-referrer" src="/img/bVdm4vu" alt="图片" title="图片" loading="lazy"/></p><p>对于 LLM 节点：将 gpt-4o 替换为 GLM-4.6（这是一款性能出色的通用 LLM 模型，擅长各类通用任务。了解更多信息可访问 zai-org/GLM-4.6 · Hugging Face  <a href="https://link.segmentfault.com/?enc=Se6E%2BM8mAwcTkeVo7Kgepg%3D%3D.zbDXAQD1ecIyODaBbji9Ec3MYTmoTUk7DpvvG2sf%2FKA8IotGsY4ek1Ms9V8LYnYz" rel="nofollow" target="_blank">https://huggingface.co/zai-org/GLM-4.6</a>）。</p><p><img width="723" height="859" referrerpolicy="no-referrer" src="/img/bVdm4vv" alt="图片" title="图片" loading="lazy"/></p><p>对于推理模型节点：将其替换为 Qwen/Qwen3-235B-A22B-Thinking-2507-FP8（该模型在多项推理基准测试中表现优异。了解更多信息可访问 Qwen/Qwen3-235B-A22B-Thinking-2507-FP8 · Hugging Face</p><p><a href="https://link.segmentfault.com/?enc=JTTHDZUBG0PLmYjNcdKXUA%3D%3D.NvSyjKFYUFbZs%2FEW%2Fz6BTzoDCkrgSLNYKXf4AI7Xl2faVZGaNJHBzbXbuljKGPqcOgA7%2BZu1yfjEfaCIV741TA%3D%3D" rel="nofollow" target="_blank">https://huggingface.co/Qwen/Qwen3-235B-A22B-Thinking-2507-FP8</a>）。</p><p><img width="723" height="371" referrerpolicy="no-referrer" src="/img/bVdm4vw" alt="图片" title="图片" loading="lazy"/></p><p>完成以上设置后，点击右上角的「发布」按钮，工作流即可运行！</p><p><strong>第 5 步：开始试用！</strong></p><p>现在让我们进入工作流应用程序。设置一个可选的<strong>深度</strong>参数——这就是这个工作流被称为<strong>深度</strong>研究的原因，能够根据指定的深度，会进行多轮迭代搜索。例如，我们把它设为<strong>2</strong>。</p><p>以下是示例提示词：</p><pre><code>Which industries are showing the strongest early signals of disruption from generative AI?</code></pre><p><img width="723" height="740" referrerpolicy="no-referrer" src="/img/bVdm4vx" alt="图片" title="图片" loading="lazy"/></p><p>需要注意的是，由于深度研究可能需要多轮推理，完整答案可能需要一两分钟才能生成。总之，你最终将获得一份撰写规范、来源明确的分析报告。</p><p><img width="723" height="481" referrerpolicy="no-referrer" src="/img/bVdm4vy" alt="图片" title="图片" loading="lazy"/></p><p><strong><em>03</em></strong></p><p><strong><em>结论</em></strong></p><p>在 Dify 中通过 GMI 插件构建深度研究工作流程，能够充分利用 GMI Cloud Inference Engine中的 AI 模型和尖端云基础设施。无论你是进行市场研究、模型评估还是文献综述的撰写，它都将是你最可靠的伙伴，全力助力你的生产流程。</p><p>现在就去安装 GMI Cloud 插件，完成 API Key 配置，就可以立刻开始构建你的深度研究工作流程啦！如有任何问题，可随时通过邮箱联系我们： <a href="mailto:support@gmicloud.ai" target="_blank">support@gmicloud.ai</a></p><p><strong>关于 GMI Cloud</strong></p><p>由 Google X 的 AI 专家与硅谷精英共同参与创立的 GMI Cloud 是一家领先的 AI Native Cloud 服务商，是全球六大 Reference Platform NVIDIA Cloud Partner 之一，拥有遍布全球的数据中心，为企业 AI 应用提供最新、最优的 GPU 云服务，为全球新创公司、研究机构和大型企业提供稳定安全、高效经济的 AI 云服务解决方案。</p><p>GMI Cloud 凭借高稳定性的技术架构、强大的GPU供应链以及令人瞩目的 GPU 产品阵容（如能够精准平衡 AI 成本与效率的 H200、具有卓越性能的 B200 以及未来所有全新上线的高性能芯片），确保企业客户在高度数据安全与计算效能的基础上，高效低本地完成 AI 落地。此外，通过自研“Cluster Engine”、“Inference Engine”两大平台，完成从算力原子化供给到业务级智算服务的全栈跃迁，全力构建下一代智能算力基座。</p><p>作为推动通用人工智能（AGI）未来发展的重要力量，GMI Cloud 持续在 AI 基础设施领域引领创新。选择 GMI Cloud，您不仅是选择了先进的 GPU 云服务，更是选择了一个全方位的 AI 基础设施合作伙伴。</p><p>如果您想要了解有关 GMI Cloud 的信息</p><p>请关注我们并建立联系</p>]]></description></item><item>    <title><![CDATA[如何将音乐从一部itel手机传输到另一部]]></title>    <link>https://segmentfault.com/a/1190000047405582</link>    <guid>https://segmentfault.com/a/1190000047405582</guid>    <pubDate>2025-11-17 18:03:56</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>​如果您正在寻找一种轻松将音乐从一部itel手机传输到另一部itel手机的方法，那么您来对地方了。无论您是更换新的itel手机，还是仅仅想与其他设备分享您喜爱的歌曲，都有几种可靠的方法可供选择。从专业的手机传输工具到蓝牙和云存储等无线共享选项，本指南将通过清晰的步骤和详细的解释，引导您了解最有效的解决方案。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405584" alt="图片" title="图片"/></p><h3>第一部分：如何使用Coolmuster Mobile Transfer将音乐从 itel 手机传输到另一台 itel 手机</h3><p>如果您想要快速、稳定、高效地传输大量音乐文件，专业的传输工具始终是最便捷的选择。Coolmuster Mobile Transfer正是为此而生。它无需您进行复杂的手动操作，即可自动完成整个传输过程，即使是新手也能轻松上手。</p><p>Coolmuster Mobile Transfer的主要功能</p><pre><code>传输音乐、照片、视频、联系人、短信、通话记录、应用程序等。
支持Android到Android 、 iOS到iOS 、 iOS到Android和Android到iOS之间的数据传输。
一键传输，界面简洁直观。
数据无丢失；所有文件均保持原状。
几乎适用于所有Android和iOS机型，包括itel、TECNO、华为和iPhone 17。
确保安全稳定的传输过程。

</code></pre><p>如何使用Coolmuster Mobile Transfer在 itel 设备之间传输音乐？</p><p>01在您的计算机上下载、安装并打开Coolmuster Mobile Transfer 。</p><p>02使用 USB 数据线连接两部 itel 手机，并在每部手机上启用 USB 调试模式。</p><p>03将旧 itel 设置为源，新 itel 设置为目标。如果未设置，请单击“翻转”按钮更改它们的位置。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405585" alt="图片" title="图片" loading="lazy"/></p><p>04从数据列表中勾选“音乐”选项，然后单击“开始复制”，等待传输完成。</p><h3>第二部分：如何通过蓝牙将音乐从itel手机传输到itel手机</h3><p>蓝牙是一种传统且广泛使用的在两部itel手机之间共享文件的方式。虽然它比不上专业的传输工具，但无需电脑或互联网即可方便地传输少量音乐文件。</p><p>蓝牙传输有什么用？</p><pre><code>小型音乐收藏。
喜欢完全无线方式的用户。
无需安装任何应用或工具即可快速分享。

</code></pre><p>如何通过蓝牙传输音乐？</p><p>步骤 1. 在两台 itel 设备上打开蓝牙：“设置”&gt;“蓝牙”。</p><p>步骤 2. 使两部手机均可被发现并配对。</p><p>步骤 3. 在发送设备上，打开“文件管理器”，找到您的音乐文件。</p><p>步骤 4. 长按选择歌曲，点击“分享”，然后选择“蓝牙”。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405586" alt="图片" title="图片" loading="lazy"/><br/>​</p><p>第五步：在接收设备上，接受收到的传输请求。等待传输完成，然后检查音乐文件夹。</p><p>缺点：</p><pre><code>传输速度慢。
不太适合大型音乐库。

</code></pre><h3>第三部分：如何使用云存储将 itel 手机中的音乐同步到另一部 itel 手机</h3><p>如果您想将音乐备份到云端，同时还要将其传输到另一部itel手机上，那么使用云存储是理想之选。Google Drive、Dropbox和OneDrive是最常见的选择。</p><p>最佳使用场景：</p><pre><code>当两部itel手机不在同一地点时。
除了传输之外，你还需要备份。
您的Wi-Fi连接稳定。

</code></pre><p>如何通过云存储同步音乐？</p><p>步骤 1. 在旧款 itel 手机上，将您的音乐文件上传到 Google Drive、Dropbox 等。</p><p>步骤 2. 打开云应用，点击“上传”，然后选择您的音乐文件。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405587" alt="图片" title="图片" loading="lazy"/><br/>​</p><p>步骤 3. 在新 itel 上，登录同一个云账户。</p><p>步骤 4. 将上传的音乐文件下载到新手机的存储空间。</p><p>缺点：</p><pre><code>需要连接互联网（建议使用 Wi-Fi）。
处理超大文件速度较慢。

</code></pre><h3>第四部分：如何使用手机克隆功能将音乐从itel手机传输到itel手机</h3><p>手机克隆功能专为希望快速将包括音乐在内的多种类型数据从一部手机迁移到另一部手机的用户而设计。该应用程序支持包括itel在内的多个品牌。</p><p>为什么选择手机克隆？</p><pre><code>传输内容包括音乐、照片、视频、联系人、应用程序等。
可通过热点或 Wi-Fi Direct 进行无线连接。
通过二维码连接，设置简便。

</code></pre><p>使用手机克隆功能将音乐从一部itel手机传输到另一部itel手机的步骤：</p><p>步骤 1. 在两台 itel 设备上安装Phone Clone 。</p><p>步骤 2. 打开应用程序，在旧款 itel 手机上，选择“发送方”；在新款 itel 手机上，点击“接收方”。</p><p>步骤 3. 扫描新 itel 上显示的二维码，建立安全连接。</p><p>步骤 4. 选择“音乐”类别以及您想要复制的任何其他文件。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405588" alt="图片" title="图片" loading="lazy"/><br/>​</p><p>步骤 5. 点击“传输”，等待所有文件移动到新设备。</p><p>缺点：</p><pre><code>需要两部手机保持靠近。
速度取决于 Wi-Fi Direct 的性能。

</code></pre><h3>总结一下</h3><p>将音乐从一部itel手机传输到另一部itel手机有多种方法，最佳选择取决于您的具体情况。如果您需要快速、稳定且功能齐全的解决方案， Coolmuster Mobile Transfer是最便捷的选择，尤其适用于大型音乐库或跨平台传输。蓝牙适合小规模传输，云存储是备份和同步的理想之选，而手机克隆则适合想要一次性传输多种数据类型的用户。</p><p>选择适合您需求的方式，即可在您的新itel手机上轻松享受音乐。<br/>​</p>]]></description></item><item>    <title><![CDATA[京东云张晨 受邀参加KCD 杭州站 x ]]></title>    <link>https://segmentfault.com/a/1190000047405593</link>    <guid>https://segmentfault.com/a/1190000047405593</guid>    <pubDate>2025-11-17 18:03:01</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>AI正在重塑一切，驱动云原生基础设施经历其诞生以来最深刻的变革。这一变革对底层设施提出了前所未有的新要求：更极致的弹性伸缩、更高效的算力利用、更复杂的跨域调度和更全面的安全防护。面对如此系统性的挑战，单一技术栈或社区已难以给出完美答案。</p><p>KCD（Kubernetes Community Days，Kubernetes 社区日）是由社区组织的活动，汇聚开源和云原生领域的采用者和技术人员，旨在促进教育、协作和交流。KCD 活动由云原生计算基金会（CNCF）提供支持。</p><p>OpenInfra Days 每年由开源社区生态系统中的本地用户组和公司组织和主办，包含主题演讲、分组会议甚至研讨会。这是一个绝佳的机会，在活动上可以直接聆听杰出的开源基础设施领导者的演讲，学习用户案例，建立人脉，并融入当地社区。</p><p>今年由两个社区组织联合发起的开创性融合盛会，标志着云计算领域两大核心基础设施技术的深度协作与创新。它充分展现了开源社区的开放精神和跨社区协作的强大力量，我们将共同推动 AI 与云计算技术 的进步与发展。</p><p>本次会议由 京东，亚马逊, Nvidia, 阿里，蚂蚁，字节，百度，华为，中科院, Linux foundation等国内外顶级专家学者分享CNCF/openinfra相关技术议题。本次会议JDOS 的Chen因Kata container等开源社区贡献受邀参加此次会议并做出技术分享。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047405595" alt="在这里插入图片描述" title="在这里插入图片描述"/><br/>作为对共同挑战的回应，KCD杭州站与OpenInfra Days China将于11月15日在杭州首度联合举办，共同呈现一场开创性的技术盛会。这标志着围Kubernetes敏捷应用编排与OpenInfra稳定基础设施构建的两大生态，正主动打破壁垒，迈向融合协同的新阶段。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405596" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><p>京东云高级工程师张晨受邀将在本次大会中进行分享，他的主题是《大型集群中的数据处理：如何兼顾效率、可拓展性与可持续性》。<br/>Chen Zhang</p><p>Chen Zhang is a staff software engineer at JD cloud and a maintainer of the </p><p>QEMU project. He works in the virtualization field for many years.  As an accomplished speaker, Chen has presented at several international conferences, including KVM Forum 2022, Xen Summit 2019, LinuxCon China 2017, Open Source Summit Japan 2017, and CLK 2022, among others.<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047405597" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><p>在AI驱动的数据洪流时代，大规模集群的数据处理能力是衡量云基础设施核心竞争力的关键。张晨将基于京东云在超大规模复杂场景下的深厚实践，分享如何构建既高效、又可平滑扩展，同时保证长期运营可持续性的数据处理架构与策略。他的分享将为业界同行应对相似挑战提供宝贵的思路与实战经验。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047405598" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><p>运营大型 Kubernetes 集群的企业面临一个关键难题：如何在不牺牲容器性能与密度的前提下实现强隔离。通过采用 Kata 容器，京东云成功实现了安全与性能隔离，并支持在线应用与离线任务在数十万个节点上的共处而彼此互不干扰，大幅提高物理 CPU 的利用率以节省巨额成本。这一方式在“618 购物节”期间显著降低能耗。本次演讲将深入解析京东在部署 Kata 容器中的历程，涵盖架构设计、动机出发点及关键性能指标。另外分享京东自研的Kata Disk I/O 性能加速技术，对比默认配置可最高提升40%的通用磁盘性能。我将分享一套经实际部署的方案经验，如何在严苛的真实场景中基于虚拟机的隔离提升安全性与效率，并剖析其实际应用价值与注意事项。</p><p>京东云高级工程师-张晨 《大型集群中的数据处理：如何兼顾效率、可拓展性与可持续性》现场分享内容<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047405599" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[vue3 百度地图组件 freeman_]]></title>    <link>https://segmentfault.com/a/1190000047405610</link>    <guid>https://segmentfault.com/a/1190000047405610</guid>    <pubDate>2025-11-17 18:02:13</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <pre><code>&lt;template&gt;
  &lt;div class="map-container"&gt;
    &lt;!-- 搜索地址部分 --&gt;
    &lt;div class="search-box"&gt;
      &lt;a-input-group compact style="margin-bottom: 16px"&gt;
        &lt;!-- 将a-select改为a-input --&gt;
        &lt;a-input
          id="suggestId"
          v-model:value="searchAddress"
          placeholder="请输入详细地址进行搜索"
          style="width: 300px"
          @input="handleSearchInput($event.target.value)"
          @change="handleAddressChange($event.target.value)"
          @blur="handleBlur"
          @press-enter="throttledSearch"
          allow-clear
        /&gt;
        &lt;a-button type="primary" @click="searchBtn"&gt;
          &lt;template #icon&gt;&lt;SearchOutlined /&gt;&lt;/template&gt;
          搜索
        &lt;/a-button&gt;
        &lt;!-- &lt;a-button @click="getCurrentLocation" style="margin-left: 8px"&gt;
          &lt;template #icon&gt;&lt;AimOutlined /&gt;&lt;/template&gt;
          定位
        &lt;/a-button&gt; --&gt;
      &lt;/a-input-group&gt;
    &lt;/div&gt;

    &lt;!-- 地图容器 --&gt;
    &lt;div ref="mapRef" class="map-box"&gt;
      &lt;Loading
        :loading="loading"
        :absolute="false"
        theme="dark"
        background="rgba(111,111,111,.7)"
        tip="地图加载中..."
      /&gt;
    &lt;/div&gt;

    &lt;!-- 地址信息展示 --&gt;
    &lt;a-card v-if="selectedAddress" size="small" style="margin-bottom: 16px"&gt;
      &lt;a-space direction="vertical" style="width: 100%"&gt;
        &lt;a-text&gt;选中地址：{{ selectedAddress }}&lt;/a-text&gt;
        &lt;a-space&gt;
          &lt;a-text&gt;经度：{{ selectedPoint.lng }}&lt;/a-text&gt;
          &lt;a-text&gt;纬度：{{ selectedPoint.lat }}&lt;/a-text&gt;
        &lt;/a-space&gt;
        &lt;a-space v-if="addressComponents.province"&gt;
          &lt;a-text&gt;省份：{{ addressComponents.province }}&lt;/a-text&gt;
          &lt;a-text&gt;城市：{{ addressComponents.city }}&lt;/a-text&gt;
          &lt;a-text&gt;区域：{{ addressComponents.district }}&lt;/a-text&gt;
          &lt;a-text&gt;行政编码：{{ addressComponents.adcode }}&lt;/a-text&gt;
        &lt;/a-space&gt;
      &lt;/a-space&gt;
    &lt;/a-card&gt;
  &lt;/div&gt;
&lt;/template&gt;

&lt;script lang="ts"&gt;
  import { defineComponent, ref, onMounted, nextTick, unref, computed, onUnmounted } from 'vue';
  import { SearchOutlined } from '@ant-design/icons-vue';
  import { useMessage } from '/@/hooks/web/useMessage';
  import coordtransform from 'coordtransform';
  import type { TrackArray } from './typing';
  import { Loading } from '/@/components/Loading';
  import { useUserStore } from '@/store/modules/user';
  import { useScript } from '/@/hooks/web/useScript';
  import { Space as ASpace } from 'ant-design-vue';
  import { throttle } from 'lodash-es';

  const { createMessage } = useMessage();
  const userStore = useUserStore();
  const { mapKey = '' } = userStore.userInfo;
  const BAI_DU_MAP_URL = `https://api.map.baidu.com/getscript?v=1.0&amp;type=webgl&amp;ak=${mapKey}`;

  // 定义地址组件接口
  interface AddressComponents {
    province: string;
    city: string;
    district: string;
    adcode: string;
    street: string;
    streetNumber: string;
  }

  // 定义地址选择事件返回的数据结构
  interface AddressSelectResult {
    address: string;
    point: {
      lng: number;
      lat: number;
    };
    lng: string;
    lat: string;
    province: string;
    city: string;
    district: string;
    adcode: string;
    fullAddress: string;
  }

  export default defineComponent({
    name: 'BaiduMapWithSearch',
    components: { SearchOutlined, Loading, ASpace },

    props: {
      trackArray: Array as PropType&lt;TrackArray&gt;,
      mapPointSelect: {
        type: Boolean,
        default: false,
      },
      enableAddressSelect: {
        type: Boolean,
        default: false,
      },
    },

    emits: ['address-select', 'finish'],

    setup(props, { emit }) {
      let BMapGL: any = null;
      let mapObj: any = null;
      let geoc: any = null;
      let currentMarker: any = null;
      let autocomplete: any = null;

      const mapRef = ref&lt;HTMLElement | null&gt;(null);
      const { toPromise } = useScript({ src: BAI_DU_MAP_URL });
      const loading = ref(false);

      // 搜索相关数据
      const searchAddress = ref('');
      const selectedAddress = ref('');
      const selectedPoint: any = ref({ lng: 0, lat: 0 });
      const searchHistory = ref&lt;string[]&gt;([]);
      const mapSuggestions = ref&lt;string[]&gt;([]);
      const showSuggestions = ref(false);
      const isSearching = ref(false);
      let debounceTimer: any = null;
      // 新增：地址组件信息
      const addressComponents = ref&lt;AddressComponents&gt;({
        province: '',
        city: '',
        district: '',
        adcode: '',
        street: '',
        streetNumber: '',
      });

      // 计算属性：获取过滤后的建议
      const filteredSuggestions = computed(() =&gt; {
        const allSuggestions = [...new Set([...mapSuggestions.value, ...searchHistory.value])];
        // console.log('allSuggestions:', allSuggestions);
        return allSuggestions
          .filter((suggestion) =&gt;
            suggestion.toLowerCase().includes(searchAddress.value.toLowerCase()),
          )
          .slice(0, 10);
      });

      // 初始化地图
      async function initMap() {
        searchAddress.value = '';
        selectedAddress.value = '';
        try {
          loading.value = true;
          await toPromise();
          await nextTick();

          const wrapEl = unref(mapRef);
          if (!wrapEl) return;

          BMapGL = (window as any).BMapGL;
          mapObj = new BMapGL.Map(wrapEl);
          geoc = new BMapGL.Geocoder();

          const point = new BMapGL.Point(116.404, 39.915);
          mapObj.centerAndZoom(point, 12);
          mapObj.enableScrollWheelZoom(true);

          // 添加地图控件
          mapObj.addControl(new BMapGL.NavigationControl());
          mapObj.addControl(new BMapGL.ScaleControl());
          // todo: 添加地图事件
          if (props.mapPointSelect) {
            initMapEvents();
          }

          // 初始化自动完成
          initAutocomplete();

          window.addEventListener('resize', resizeMap);
          emit('finish');

          // 加载搜索历史
          loadSearchHistory();
        } catch (error) {
          createMessage.error('地图初始化失败');
          console.error('地图初始化错误:', error);
        } finally {
          loading.value = false;
        }
      }

      // 初始化地图事件
      function initMapEvents() {
        mapObj.addEventListener('click', (e: any) =&gt; {
          if (!props.enableAddressSelect) return;

          const point = new BMapGL.Point(e.latlng.lng, e.latlng.lat);
          addMarker(point);
          reverseGeocode(point);
        });
      }

      // 初始化自动完成功能
      function initAutocomplete() {
        if (!BMapGL) return;

        // 创建Autocomplete实例
        autocomplete = new BMapGL.Autocomplete({
          input: 'suggestId', // 绑定输入框
          location: mapObj,
        });

        // 监听选择事件
        autocomplete.addEventListener('onconfirm', function (e: any) {
          console.log('onconfirm:', e);
          const item = e.item.value;
          // 拼接完整地址
          // const fullAddress =
          //   item.province + item.city + item.district + item.street + item.business;
          const fullAddress =
            item.address || item.province + item.city + item.district + item.street + item.business;

          // searchAddress.value = fullAddress;
          selectedAddress.value = fullAddress;
          showSuggestions.value = false;
          // 执行搜索
          handleSearch(fullAddress);

          // const point = new BMapGL.Point(item.location.lng, item.location.lat);
          // addMarker(point);
          // reverseGeocode(point);

          // 添加到搜索历史
          addToSearchHistory(fullAddress);
        });
        // 监听下拉列表高亮事件（实时获取建议）
        // autocomplete.addEventListener('onhighlight', function (e) {
        //   console.log('=== onhighlight事件被触发 ===');

        //   if (e.toitem &amp;&amp; e.toitem.index &gt; -1) {
        //     const item = e.toitem.value;
        //     const suggestion =
        //       item.province + item.city + item.district + item.street + item.business;
        //     console.log('高亮建议:', suggestion);

        //     // 这里可以实时更新您的自定义建议列表
        //     updateCustomSuggestions([suggestion]);
        //   }
        // });
      }

      // 搜索输入处理（带防抖）
      const handleSearchInput = (value: string) =&gt; {
        console.log('handleSearchInput:', value);
        searchAddress.value = value;
        isSearching.value = true;
        // showSuggestions.value = value.length &gt; 0;

        clearTimeout(debounceTimer);
        debounceTimer = setTimeout(() =&gt; {
          if (value.trim()) {
            getAddressSuggestions(value);
          } else {
            showSuggestions.value = false;
          }
          isSearching.value = false;
        }, 300);
      };

      // 地址选择变化处理
      const handleAddressChange = (value: string) =&gt; {
        if (value) {
          searchAddress.value = value;
          // 添加到搜索历史
          addToSearchHistory(value);
          // 执行搜索
          // handleSearch(value);

          // getAddressSuggestions(value);
        }
      };

      // 输入框失去焦点处理
      const handleBlur = () =&gt; {
        setTimeout(() =&gt; {
          showSuggestions.value = false;
          const currentValue = searchAddress.value;
          if (currentValue &amp;&amp; !searchHistory.value.includes(currentValue)) {
            addToSearchHistory(currentValue);
          }
        }, 200);
      };
      const searchBtn = () =&gt; {
        if (!searchAddress.value) {
          createMessage.warning('请输入搜索地址');
          return;
        }
        console.log('搜索地址：', searchAddress.value);
        isSearching.value = true;
        showSuggestions.value = searchAddress.value.length &gt; 0;

        clearTimeout(debounceTimer);
        debounceTimer = setTimeout(() =&gt; {
          if (searchAddress.value.trim()) {
            getAddressSuggestions(searchAddress.value);
          } else {
            showSuggestions.value = false;
          }
          isSearching.value = false;
        }, 300);
      };
      // 执行搜索
      const handleSearch = (value?: string) =&gt; {
        const searchValue = value || searchAddress.value;
        // 添加类型检查
        if (!searchValue || typeof searchValue !== 'string' || !searchValue.trim()) {
          createMessage.warning('请输入搜索地址');
          return;
        }

        if (!searchValue.trim()) {
          // createMessage.warning('请输入搜索地址');
          return;
        }

        geocodeAddress(searchValue);
        showSuggestions.value = false;
      };
      // 节流搜索处理
      const throttledSearch = throttle(handleSearch, 500);

      // 获取地址建议
      const getAddressSuggestions = async (keyword: string) =&gt; {
        if (!BMapGL || !keyword.trim()) {
          return;
        }
        try {
          // 使用Autocomplete获取建议
          autocomplete.search(keyword, (results: any) =&gt; {
            if (results &amp;&amp; results.poi_list.length &gt; 0) {
              const suggestions = results.poi_list.map(
                (item: any) =&gt;
                  item.province + item.city + item.district + item.street + item.business,
              );
              mapSuggestions.value = suggestions;
            } else {
              mapSuggestions.value = [];
            }
          });
        } catch (error) {
          console.error('获取地址建议失败:', error);
          mapSuggestions.value = [];
        }
      };

      // 地理编码（地址转坐标）
      const geocodeAddress = (address: string) =&gt; {
        if (!geoc) return;

        geoc.getPoint(
          address,
          (point: any) =&gt; {
            if (point) {
              mapObj.centerAndZoom(point, 16);
              addMarker(point);
              selectedPoint.value = { lng: point.lng, lat: point.lat };

              // 触发地址选择事件
              // emitAddressSelect();
              const ainpoint = new BMapGL.Point(point.lng, point.lat);
              reverseGeocode(ainpoint);
            } else {
              // createMessage.warning('无法解析该地址，请尝试更详细的地址信息');
            }
          },
          '全国',
        );
      };

      // 逆地理编码（坐标转地址）
      const reverseGeocode = (point: any) =&gt; {
        if (!geoc) return;

        geoc.getLocation(point, (result: any) =&gt; {
          if (result) {
            const addressComponentsResult = result.content.address_detail;
            console.log('逆地理编码结果:', result);

            // 设置地址组件信息[5](@ref) town_code
            addressComponents.value = {
              province: addressComponentsResult.province || '',
              city: addressComponentsResult.city || '',
              district: addressComponentsResult.district || '',
              adcode: addressComponentsResult.adcode || '',
              street: addressComponentsResult.street || '',
              streetNumber: addressComponentsResult.streetNumber || '',
            };

            // selectedAddress.value =
            //   addressComponentsResult.province +
            //   addressComponentsResult.city +
            //   addressComponentsResult.district +
            //   addressComponentsResult.street +
            //   addressComponentsResult.streetNumber;
            showSuggestions.value = false;
            emitAddressSelect();
          }
        });
      };

      // 添加标记点
      const addMarker = (point: any) =&gt; {
        if (currentMarker) {
          mapObj.removeOverlay(currentMarker);
        }

        currentMarker = new BMapGL.Marker(point);
        mapObj.addOverlay(currentMarker);
      };

      // 添加到搜索历史
      const addToSearchHistory = (address: string) =&gt; {
        // console.log('添加到搜索历史：', address);
        if (!address.trim() || address.length &lt; 2) return;

        const isSimilar = searchHistory.value.some(
          (item) =&gt; item.includes(address) || address.includes(item),
        );

        if (!isSimilar) {
          const filteredHistory = searchHistory.value.filter((item) =&gt; item !== address);
          searchHistory.value = [address, ...filteredHistory].slice(0, 15);
          saveSearchHistory();
        }
      };

      // 保存搜索历史到本地存储
      const saveSearchHistory = () =&gt; {
        if (typeof localStorage !== 'undefined') {
          localStorage.setItem('baidu-map-search-history', JSON.stringify(searchHistory.value));
        }
      };

      // 从本地存储加载搜索历史
      const loadSearchHistoryFromStorage = (): string[] =&gt; {
        if (typeof localStorage !== 'undefined') {
          const history = localStorage.getItem('baidu-map-search-history');
          return history ? JSON.parse(history) : [];
        }
        return [];
      };

      // 加载搜索历史
      const loadSearchHistory = () =&gt; {
        searchHistory.value = loadSearchHistoryFromStorage();
      };

      const convertToGPS = (lng: number, lat: number) =&gt; {
        const gcj02 = coordtransform.bd09togcj02(lng, lat);
        return coordtransform.gcj02towgs84(gcj02[0], gcj02[1]);
      };

      // 触发地址选择事件
      const emitAddressSelect = () =&gt; {
        if (props.enableAddressSelect) {
          console.log('已选择地址：' + selectedAddress.value);
          console.log('已选择坐标：' + selectedPoint.value.lng + ',' + selectedPoint.value.lat);
          console.log('省市区信息：', addressComponents.value);

          // 转换为WGS84坐标
          const [wgs84Lng, wgs84Lat] = convertToGPS(
            selectedPoint.value.lng,
            selectedPoint.value.lat,
          );

          // 构建完整的地址选择结果[5](@ref)
          const addressSelectResult: AddressSelectResult = {
            address: selectedAddress.value,
            point: selectedPoint.value,
            lng: wgs84Lng.toFixed(6),
            lat: wgs84Lat.toFixed(6),
            province: addressComponents.value.province,
            city: addressComponents.value.city,
            district: addressComponents.value.district,
            adcode: addressComponents.value.adcode,
            fullAddress: `${addressComponents.value.province}${addressComponents.value.city}${addressComponents.value.district}${addressComponents.value.street}${addressComponents.value.streetNumber}`,
          };

          // 触发地址选择事件，返回完整信息
          emit('address-select', addressSelectResult);
        }
      };

      // 调整地图大小
      const resizeMap = () =&gt; {
        if (mapObj) {
          setTimeout(() =&gt; {
            mapObj.resize();
            mapObj.setCenter(mapObj.getCenter());
          }, 100);
        }
      };

      // 重置地图
      const resetMap = () =&gt; {
        if (mapObj) {
          mapObj.clearOverlays();
          const point = new BMapGL.Point(116.404, 39.915);
          mapObj.centerAndZoom(point, 12);
        }
        searchAddress.value = '';
        selectedAddress.value = '';
        selectedPoint.value = { lng: 0, lat: 0 };
        addressComponents.value = {
          province: '',
          city: '',
          district: '',
          adcode: '',
          street: '',
          streetNumber: '',
        };
      };

      onMounted(() =&gt; {
        initMap();
      });

      // 组件卸载时清理
      onUnmounted(() =&gt; {
        // 清理资源
        if (mapObj) {
          mapObj.destroy();
          mapObj = null;
        }
        if (throttledSearch) {
          throttledSearch.cancel();
        }
        window.removeEventListener('resize', resizeMap);
      });

      return {
        mapRef,
        loading,
        searchAddress,
        selectedAddress,
        selectedPoint,
        searchHistory,
        filteredSuggestions,
        addressComponents,
        showSuggestions,
        handleSearchInput,
        handleAddressChange,
        handleBlur,
        handleSearch,
        throttledSearch,
        resetMap,
        initMap,
        searchBtn,
      };
    },
  });
&lt;/script&gt;

&lt;style lang="less" scoped&gt;
  .map-container {
    position: relative;
    width: 100%;
    height: 100%;

    :deep(.tangram-suggestion) {
      z-index: 1001 !important;
    }

    .search-box {
      position: absolute;
      z-index: 999;
      top: 16px;
      left: 16px;
      min-width: 400px;
      padding: 16px;
      border-radius: 6px;
      background: rgb(255 255 255 / 95%);
      box-shadow: 0 2px 8px rgb(0 0 0 / 15%);
    }

    .map-box {
      width: 100%;
      height: 100%;
      min-height: 500px;
    }

    // 搜索建议下拉框样式
    .suggestions-dropdown {
      position: absolute;
      z-index: 1000;
      top: 100%;
      right: 16px;
      left: 16px;
      max-height: 200px;
      overflow-y: auto;
      border: 1px solid #d9d9d9;
      border-radius: 6px;
      background: white;
      box-shadow: 0 2px 8px rgb(0 0 0 / 15%);

      .suggestion-item {
        padding: 8px 12px;
        transition: background-color 0.3s;
        border-bottom: 1px solid #f0f0f0;
        cursor: pointer;

        &amp;:last-child {
          border-bottom: none;
        }

        &amp;:hover {
          background-color: #f5f5f5;
        }
      }
    }
  }
  // 优化选择器下拉框样式
  :deep(.ant-select-dropdown) {
    z-index: 1000;

    .ant-select-item {
      padding: 8px 12px;
    }
  }

  :global(.tangram-suggestion) {
    z-index: 9999 !important;
  }

  // 优化输入框样式
  // :deep(.ant-input) {
  //   height: 32px;
  // }
&lt;/style&gt;
</code></pre>]]></description></item><item>    <title><![CDATA[动力电池怎么选？关键参数解析与行业案例分]]></title>    <link>https://segmentfault.com/a/1190000047405622</link>    <guid>https://segmentfault.com/a/1190000047405622</guid>    <pubDate>2025-11-17 18:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>动力电池的基本概念与重要性<br/>动力电池，即为电动汽车、电动工具、便携式设备等提供动力的可充电电池，是新能源汽车的核心部件，其性能直接决定了整车的续航能力、安全性和使用寿命。随着全球能源转型和“双碳”目标的推进，动力电池产业已成为绿色经济的重要支柱之一。目前，动力电池主要分为三元锂电池、磷酸铁锂电池和固态电池等类型，其中三元锂电池和磷酸铁锂电池占据了主流市场，而固态电池因其高能量密度和安全性被视为下一代技术方向。例如，特斯拉通过采用三元锂电池技术，大幅提升了其电动汽车的续航里程；比亚迪则凭借磷酸铁锂电池的高安全性和低成本，在商用车领域取得了显著优势。<br/>动力电池技术发展现状<br/>近年来，动力电池技术取得了显著进步，主要体现在能量密度提升、充电速度加快和循环寿命延长等方面。以三元锂电池为例，其单体能量密度可达300Wh/kg以上，系统能量密度也在260Wh/kg左右；磷酸铁锂电池则以安全性著称，循环寿命可达2000次以上。然而，成本问题仍是制约其大规模应用的关键因素。例如，2024年全球动力电池装机量预计突破1.2TWh，中国市场份额持续保持60%以上，但电池原材料价格波动较大，导致生产成本居高不下。<br/>动力电池制造的挑战与应对<br/>在动力电池生产过程中，质量控制和能耗管理是两大核心挑战。以电芯制程异常为例，该问题受到多种因素影响，包括设备参数漂移、材料批次差异和环境温度波动等。传统制造模式依赖人工经验调整设备参数，效率低且难以避免缺陷。然而，随着工业4.0技术的引入，广域铭岛通过其Geega工业AI应用平台，为新能源电池企业打造了“工业超级智能体”，实现了工艺优化和能耗管理的全面升级。例如，在富江能源的12GWh电池项目中，广域铭岛帮助工厂降低综合能耗15%以上；在衢州极电工厂的数字化改造中，其QAL质量分析平台将工艺波动降低30%，显著提升了生产效率和良品率。<br/>动力电池未来发展趋势<br/>未来，动力电池技术将向高能量密度、长寿命和绿色化方向发展。固态电池作为最具潜力的技术路线之一，其安全性高，能量密度可进一步提升至400Wh/kg以上。例如，丰田在硫化物固态电池领域的研发已取得突破，实验原型能量密度达到400Wh/kg，并计划在2020年实现产业化。此外，数字化和AI技术也将成为推动动力电池行业升级的重要力量。广域铭岛正在通过构建“数字孪生工厂”，实现生产全流程的可视化和智能化管理，助力企业应对产能扩张和市场需求变化的挑战。<br/>动力电池回收与可持续发展<br/>随着动力电池使用年限的增加，回收利用问题日益突出。据统计，2025年全球动力电池累计装机量将超过1000GWh，届时退役电池数量将达到数千万台。广域铭岛在电池回收领域也有所布局，通过建立完善的回收体系，实现退役电池的梯级利用和材料再生。例如，其回收项目资源回收率超过95%，为行业树立了环保标杆。这种闭环管理模式不仅降低了环境影响，还提高了资源利用效率，符合可持续发展的理念。<br/>总之，动力电池作为新能源汽车和储能系统的核心部件，其技术发展和制造升级对推动绿色能源转型具有重要意义。广域铭岛通过其工业超级智能体和数字化解决方案，为行业提供了创新性的技术支持，助力企业在高能量密度电池研发、生产效率提升和成本控制等方面取得突破。未来，随着固态电池等新技术的不断成熟，以及数字化技术的广泛应用，动力电池产业将迎来更加广阔的发展空间。</p>]]></description></item><item>    <title><![CDATA[工业AI大模型：智能制造的核心引擎与落地]]></title>    <link>https://segmentfault.com/a/1190000047405166</link>    <guid>https://segmentfault.com/a/1190000047405166</guid>    <pubDate>2025-11-17 17:09:47</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>近年来，人工智能技术的快速发展推动了工业领域的智能化转型，而工业AI大模型作为这一趋势的核心驱动力，正在重塑制造业的生产流程、管理方式和商业模式。工业AI大模型不仅具备通用大模型的泛化能力，还融合了工业场景的专业知识，能够解决复杂、非标准化的生产任务。然而，从技术到落地，工业AI大模型仍面临诸多挑战，包括数据孤岛、模型泛化能力不足、安全风险以及商业模式不成熟等问题。<br/>在制造业中，工业AI大模型的应用已逐步从外围环节向核心生产环节渗透。例如，在汽车制造领域，工业大模型被用于优化车身涂装工艺，通过实时分析喷涂参数（如压力、温度、湿度），预测涂层缺陷并自动调整设备运行状态。某吉利集团子公司在引入工业AI大模型后，涂装合格率提升至99.8%，年节省成本超200万元。<br/>数据壁垒与安全问题：工业AI落地的两大瓶颈<br/>工业AI大模型的训练和优化高度依赖高质量数据，但当前工业企业的数据往往分散在不同系统中，形成“数据孤岛”。例如，在钢铁行业，某龙头企业通过构建“决策-管控-操控”三层数据架构，成功整合了生产、能耗、设备等多源数据，开发了49个垂直大模型应用场景。然而，数据采集和清洗仍是许多中小企业的痛点。<br/>此外，AI生成代码的安全性问题也不容忽视。根据行业调查，45%的工业AI生成代码存在安全漏洞，可能导致设备损坏或生产中断。为此，企业需要建立“云边端三级部署”架构，将模型部署在边缘设备时进行轻量化处理，提升实时性和安全性。<br/>广域铭岛的实践：边缘计算助力工业AI落地<br/>作为工业智能化的先行者，广域铭岛在边缘计算领域积累了丰富经验，其工业AI解决方案覆盖了设备层、产线层和企业层的多层次需求。例如，通过边缘计算平台，广域铭岛帮助某制造企业实现了设备数据的实时采集与分析，显著提升了生产调度效率。<br/>广域铭岛还通过数据合成技术弥补了工业数据缺失的问题，尤其是在涉及核心技术的CAD数据领域。该企业通过构建虚拟数据集，完成了设计图的自动生成与优化，缩短了研发周期。<br/>场景化落地：从“技术找场景”到“问题驱动”<br/>工业AI大模型的成功落地并非单纯依赖技术先进性，而是需要精准匹配企业实际需求。例如，在炼钢厂的钢包热修场景中，某团队通过深入一线调研，发现该环节存在高温作业风险，而工业AI技术恰好可以缓解这一问题。通过部署智能工作站，单台设备的售价虽高（超1000万元），但其带来的安全性和效率提升为企业创造了显著价值。<br/>结语<br/>工业AI大模型不仅是技术的革新，更是制造业转型升级的关键工具。通过解决数据、安全、场景适配等问题，工业大模型有望在更多领域实现规模化落地，为传统工业注入新的活力。广域铭岛等企业的实践表明，边缘计算与模型协同是实现这一目标的重要路径，而“问题驱动”的实施策略则是确保ROI的关键。</p>]]></description></item><item>    <title><![CDATA[三款热门供应链系统实测，这样选不踩坑 遭]]></title>    <link>https://segmentfault.com/a/1190000047405176</link>    <guid>https://segmentfault.com/a/1190000047405176</guid>    <pubDate>2025-11-17 17:09:14</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>供应链掉一次链子，整单利润就“打水漂”。传统ERP太贵、Excel又管不住多环节？Zoho Creator低代码平台用“拖—拉—拽”15天搭出采购-库存-物流-销售一体化系统，开发成本仅为传统定制的1/5，让中小企业也能用得起、改得快、管得住全球供应链。<br/><img width="500" height="328" referrerpolicy="no-referrer" src="/img/bVdm4pL" alt="" title=""/><br/>一、供应链管理是什么？<br/>供应链管理是对从原材料采购到产品交付最终用户的整个流程进行规划、协调、控制和优化的系统性方法。它涵盖了物流、信息流、单证流、商流和资金流的全面自动化与优化，旨在实现整体供应链的可视化、管理信息化和利益最大化。</p><p>在现代商业环境中，一套高效的供应链管理系统能帮助企业应对多重挑战：</p><p>解决因供应商、物流商、仓库和销售团队之间信息不透明导致的协同效率低下问题；<br/>避免全球多地仓库库存数据更新不及时造成的库存管理失衡；<br/>缓解国际物流环节多周期长带来的跟踪困难；<br/>有效控制传统供应链系统开发成本高、维护费用贵的财务压力。<br/>二、什么是低代码？低代码开发供应链管理有什么优势？<br/>低代码是一种可视化应用开发方法，通过图形化界面和拖放组件，让开发者以最少的编码快速构建应用程序。在供应链管理领域，低代码平台正成为企业快速构建应用的重要工具，它们通过可视化界面和模块化组件，让非技术人员也能参与应用开发，大幅降低开发门槛和成本。</p><p>低代码开发供应链管理系统具有以下显著优势：</p><p>1、时间和成本节约<br/>低代码平台采用可视化的编程方式，大多数操作基于拖放方式进行，极大地缩短了开发周期，同时降低了开发成本。对于中小企业而言，传统供应链管理系统动辄数十万的开发成本和冗长的实施周期是难以承受的负担，而低代码平台能将开发成本降至传统定制开发的1/5 - 1/3，实施周期从传统的3 - 6个月缩短至1 - 4周。</p><p>2、灵活定制与快速迭代<br/>全球供应链需求多变，企业可能突然需要新增海外仓库或调整供应商合作模式。低代码平台支持“快速迭代应用”——业务人员可直接在现有应用基础上添加模块、修改流程，无需重新开发，适配成本极低。这种灵活性使企业能够快速响应市场变化，保持竞争优势。</p><p>3、打破信息孤岛，实现全链路协同<br/>Zoho低代码平台可搭建“供应商-物流-仓库-销售”全链路协同应用，实现数据实时同步。通过多角色权限管控，针对供应商、物流商、仓库管理员、销售团队等不同角色设置差异化权限，确保数据安全的同时，实现“数据在正确的人手中流转”。</p><p>三、如何选择合适的低代码开发平台？选型的注意事项<br/>在选择低代码开发平台时，企业需从多个维度评估平台的适用性，以确保选择最适合自身需求的解决方案。</p><p>1、平台能力与扩展性评估<br/>一个合格的平台应提供模型驱动、可视化开发、表达式语言等核心能力，并支持测试debug和版本控制等软件工程实践。平台是否支持多语言、多时区也是出海企业的关键需求。Zoho低代码平台支持一次开发、多端部署，可同时生成Web应用、移动应用和桌面应用，确保用户在不同设备上获得一致体验。</p><p>2、行业经验与案例积累<br/>有经验的平台能提供更佳实践参考，减少企业试错成本。Zoho低代码已有19年技术积累，服务过多行业客户，能提供更有价值的解决方案。</p><p>3、总体拥有成本综合评估<br/>除初始开发费用外，企业还需考虑维护成本、升级费用等。Zoho低代码平台采用订阅制，价格透明，且提供免费试用，企业可先验证效果再决策。其价格方案灵活，有免费版，标准版672元/用户/年，专业版1680元/用户/年（不限应用），企业版2100元/用户/年（不限应用），满足不同规模企业需求。</p><p>4、选择可靠、安全的技术厂商<br/>Zoho低代码的优势：</p><p>丰富的集成：与国际物流平台、电商平台集成更顺畅，贴合国际贸易场景。<br/>可靠的技术支持：Zoho低代码提供国内专业的中文技术支持，遇到问题时，可获1对1服务，快速响应解决。<br/>长期稳定：Zoho在全球自建16个服务器，数据传输稳定可靠。<br/>数据安全：企业级数据加密、隐私保护合规等，满足国际贸易中的数据安全要求。<br/>四、如何用Zoho低代码平台开发供应链管理系统？<br/>使用Zoho低代码，您可以像搭积木一样，轻松构建涵盖采购、库存、生产、销售、物流全链路的管理系统。</p><p>1、蓝图规划<br/>与各部门协作，梳理出核心业务流程与数据模型（如供应商、SKU、仓库、订单等）。</p><p>2、拖拽式构建<br/>使用直观的可视化构建器，创建数据表、表单和报表界面。无需编码，即可定义字段关系和页面逻辑。</p><p>3、配置自动化工作流<br/>设置“如果-那么”规则。例如：“如果库存量低于安全水位，那么自动发送采购预警邮件并生成采购申请单”。</p><p>4、深度集成<br/>利用内置连接器或API，将您的供应链应用与Zoho Books（进销存系统）、Shopify（电商）、FedEx（物流）等系统打通，消除信息孤岛。</p><p>5、发布移动APP<br/>一键将应用发布为原生移动APP，赋能一线员工进行扫码盘点、订单处理和物流跟踪。</p><p>6、持续迭代优化<br/>根据业务反馈和市场变化，随时使用平台添加新功能或调整现有流程，让系统永远与业务同步成长。</p><p>五、成功案例：元品贸易的数字化转型<br/>元品贸易是一家专注于美国和非洲商超市场的小型服装外贸企业。通过Zoho低代码平台，元品贸易在仅15天内就搭建了符合企业需求的供应链管理系统，系统总费用仅为传统开发的十分之一，年账号续费仅两千多元（3用户）。</p><p>该系统支持多实体选择切换，对于不同的客户，可以选择不同的代理商实体和出口商实体，对应到每个订单的财务开票。不同订单和实体统一到一个数据看板，应收账款、应付账款和销账数据一目了然。实施Zoho低代码后，元品贸易的工作效率提升了50%，订单管理和跟进时间大大缩短，错误率归零。</p><p>别让漫长的实施周期和高昂费用挡住出海脚步。立即免费试用Zoho Creator，15天全功能体验：从采购预警、多币种发票到物流节点实时追踪一键配齐，按需订阅84元/用户/月起，随增随减无绑定。把供应链搬进Zoho Creator，让全球订单、库存、资金在同一屏幕安全可控，快速响应市场变化，稳步拓展海外版图。</p>]]></description></item><item>    <title><![CDATA[Apache Cloudberry 集成]]></title>    <link>https://segmentfault.com/a/1190000047405242</link>    <guid>https://segmentfault.com/a/1190000047405242</guid>    <pubDate>2025-11-17 17:08:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>Apache Cloudberry™ (Incubating) 是 Apache 软件基金会孵化项目，由 Greenplum 和 PostgreSQL 衍生而来，作为领先的开源 MPP 数据库，可用于建设企业级数据仓库，并适用于大规模分析和 AI/ML 工作负载。<br/>GitHub: <a href="https://link.segmentfault.com/?enc=GIS%2BCv4PFqejvOFikOaENQ%3D%3D.%2FTWCxWt6Tm%2F04jOuHcWSDxb%2BK3XXPjWWMMdIoDjqYH1e75jSL4gN88LbZOTWazf3" rel="nofollow" target="_blank">https://github.com/apache/cloudberry</a>文章作者：陈亮，酷克数据售后工程师；整理：酷克数据ZomboDB 是 PostgreSQL 的扩展组件，通过与 Elasticsearch 的集成，为数据库系统引入了高性能的全文检索与文本分析功能。我们对 ZomboDB 进行了兼容性改造与优化，使其能够支持 Apache Cloudberry，从而让 Cloudberry 拥有 Elasticsearch 丰富的全文检索与文本分析能力。通过简单的 SQL 语法，用户即可在已有的 Cloudberry 表上创建 ZomboDB 索引，实现高性能、可事务化的全文搜索。ZomboDB 实际上是基于 Elasticsearch 外部索引的实现，它可以管理 Elasticsearch 集群上的索引，并确保在事务层面上保持数据与索引的一致性。此外，ZomboDB 支持大多数 Cloudberry 的 SQL 操作，包括：CREATE INDEX、COPY、INSERT、UPDATE、DELETE、SELECT、ALTER、DROP、REINDEX、(auto)VACUUM 等。工作原理ZomboDB 通过连接 Cloudberry 集群与 Elasticsearch 集群，实现两者的数据同步与检索协作。无论两个集群是否位于同一主机，只需保证网络通信畅通即可正常运行。Cloudberry 中的每一个 ZomboDB 索引实际上对应 Elasticsearch 中的一个 Index。当数据量较大时，为避免每个 Segment 扫描全量索引数据，ZomboDB 会将不同 Segment 的数据映射到 Elasticsearch 索引下的不同分片（Shard），从而提升并行扫描与查询性能。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405244" alt="图片" title="图片"/></p><p>创建索引和加载数据流程下图展示了数据表创建 ZomboDB 索引，并加载数据的大致流程。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405245" alt="图片" title="图片" loading="lazy"/></p><p>整个过程都是在和 Cloudberry集群中的 Coordinator 节点进行通信和交互。在 Cloudberry集群中创建数据表，并且加载相应的数据。使用 CREATE INDEX 语法创建 ZomboDB 的索引。此时需要保证 Elasticsearch 的集群处于可用状态，并且网络和 Cloudberry集群互通。创建的过程中，ZomboDB 会自动将表中已有的数据插入到 Elasticsearch 中对应的 index 里面，如果发生了错误，或者手动回滚事务，那么也会自动清理 ES 中的数据。在索引创建完成后，后续有新的数据插入到表中，都会自动将数据插入到对应 Elasticsearch 的 index 里。查询数据流程下图展示了存在 ZomboDB 索引的情况下，对数据进行查询的大致流程。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405246" alt="图片" title="图片" loading="lazy"/></p><p>用户侧使用 ZomboDB 的查询语法，基于 ZomboDB 的索引进行查询。ZomboDB 的查询和普通的 select 基本上没有区别，只是需要使用 ZomboDB 特定的标识符 ==&gt;。Cloudberry集群中的 Coordinator 节点将查询分发给各个 Segment。每个 Segment 各自执行查询，只需要查询对应的 Elasticsearch 的 index 中某个 Shard 的数据。每个 Segment 将查询的结果返回给 Coordinator 节点。Coordinator 节点收到 Segment 的结果，进行聚合或者其他操作，并返回给用户。安装 ZomboDB 插件注意：当前 ZomboDB 插件尚未开源，此安装方式适用于 HashData Lightning（基于 Apache Cloudberry）版本。// 通过 psql postgres 进入数据库，创建 zombodb 扩展<br/>postgres=# create extension zombodb;<br/>// 出现如下结果表示安装成功<br/>CREATE EXTENSION安装 Elasticsearch下载对应平台 elasticserch 安装包wget <a href="https://link.segmentfault.com/?enc=Stf15JeMmkMd3ze2alB7hQ%3D%3D.psh4purpwLqysGetJfP4EiVqkoR7c0aS2f9l%2F4ci%2FbNapxuO83QVrVZ83aeHwmGE%2Bs5oIQGuscAbI%2BBOKC6Utd%2FgQVQlNJkdelXh%2B8I2z10%2B8%2FYJ9fleupECgW3nxNil" rel="nofollow" target="_blank">https://artifacts.elastic.co/downloads/elasticsearch/elastics...</a>安装 elasticsearchyum -y install ./elasticsearch-8.6.1-x86_64.rpm修改/etc/elasticsearch/elasticsearch.yml，设置 xpack.security.enabled 为 falsexpack.security.enabled: false启动 elasticsearchsystemctl start elasticsearch安装 elasticsearch-analysis-ik 中文分词插件注意插件的版本必须与 elasticsearch 版本一致。上面的 elasticsearch 版本是 8.6.1，所以这里插件也要使用同样的版本。有 2 种安装方式：自动安装：cd /usr/share/elasticsearch/bin<br/>./bin/elasticsearch-plugin install <a href="https://link.segmentfault.com/?enc=TaaCgzfoq3WWWXC81JiOvg%3D%3D.IopI6M3mzUH8TgsiwKLkQgowKuTGNIi23EuhhpX98bHKLOZQ%2F6zRBriersKsbykZByKcg6%2FNJLJ5LYiC8Ezf%2FF7w%2F0aRsnFaDTjOH016qW5bq1EldCwiAxHwQ1RxTCNRkZB8bl4X%2By%2FTmbVIjSuslg%3D%3D" rel="nofollow" target="_blank">https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v8.6.1/elasticsearch-analysis-ik-8.6.1.zip</a>手动安装：从这个链接下载对应版本的安装包：<a href="https://link.segmentfault.com/?enc=xyr5PWvdgOmpPmPJUXnCZg%3D%3D.nmoJPqDAMq5WNYALsWRZsHF%2BZfdwwVed2flJ2EmLQWETjFJh6YJ5928JXv6zeFBNjlo4heJ0%2ByAptg3kO1ImaQ%3D%3D" rel="nofollow" target="_blank">https://github.com/medcl/elasticsearch-analysis-ik/releases</a>安装mkdir /usr/share/elasticsearch/plugins/ik<br/>unzip -d /usr/share/elasticsearch/plugins/ik ./elasticsearch-analysis-ik-8.6.1.zip重启 elasticsearchsystemctl restart elasticsearchCloudberry 实现中文检索创建一个名称是'myik'的 analyzer。SELECT zdb.define_analyzer('myik', '{"tokenizer": "ik_max_word"}');创建 domainCREATE DOMAIN myik AS text;创建测试表，注意这里列 c1 的数据类型要对应上面创建的 domain 名称。create table zombodb_t1 (c1 myik);创建索引create index idx_zombodb_t1 on zombodb_t1 using zombodb((zombodb_t1.*)) with (url='<a href="https://link.segmentfault.com/?enc=YQxYwtBCCGe57oUWQYR6UQ%3D%3D.0zOCL6jffCKEqGfpwfJR6%2B3Mb0WyjiMUJyiRqGyznh0%3D" rel="nofollow" target="_blank">http://localhost:9200/</a>');测试效果gpadmin=# insert into zombodb_t1 values ('中文测试');<br/>INSERT 0 1<br/>gpadmin=# insert into zombodb_t1 values ('中 文测试');<br/>INSERT 0 1<br/>gpadmin=# select * from zombodb_t1 where zombodb_t1 ==&gt; '中文';</p><pre><code>c1</code></pre><hr/><p>中文测试<br/>(1 row)</p><p>gpadmin=# select * from zombodb_t1 where zombodb_t1 ==&gt; '中 文';</p><pre><code>c1</code></pre><hr/><p>中 文测试<br/>(1 row)</p><p>gpadmin=# select * from zombodb_t1 where zombodb_t1 ==&gt; '测试';</p><pre><code>c1</code></pre><hr/><p>中文测试<br/> 中 文测试<br/>(2 rows)创建 index 报错在创建 index（例如 create index <br/>idx_fulltext_client_extended_info）时，出现了以下错误信息：ERROR: code=Some(429),<br/>"error": {<br/>  "root_cause": [</p><pre><code>{
  "type": "es_rejected_execution_exception",
  "reason": "rejected execution of coordinating operation [coordinating_and_primary_bytes=...]"
}</code></pre><p>],<br/>  "type": "es_rejected_execution_exception",<br/>  "reason": "rejected execution of coordinating operation [coordinating_and_primary_bytes=...]",<br/>  "status": 429<br/>}从错误信息可以看出，Elasticsearch 在协调节点执行操作时因为内存压力过大而拒绝了请求（<br/>es_rejected_execution_exception），导致索引创建失败。解决方法：修改/etc/elasticsearch/elasticsearch.yml， 添加如下参数。如果不指定，这个参数的默认值是 10%的 ES heap 内存大小。indexing_pressure.memory.limit: 8g重启 elasticsearchsystemctl restart elasticsearch结语通过将 ZomboDB 与 Apache Cloudberry 深度集成，用户能够在 MPP 架构下直接使用 Elasticsearch 的全文检索与中文分词能力，实现高性能的结构化与非结构化数据混合查询。这种融合方案不仅扩展了 Cloudberry 的应用边界，也为日志分析、智能检索、文本挖掘等场景提供了开源可行的新路径。未来，随着社区的发展与多语言分词支持的增强，Cloudberry + ZomboDB + Elasticsearch 的组合将成为构建智能数据仓库与搜索分析平台的重要技术基石。</p>]]></description></item><item>    <title><![CDATA[Magnet Axiom 9.8 发布 ]]></title>    <link>https://segmentfault.com/a/1190000047405275</link>    <guid>https://segmentfault.com/a/1190000047405275</guid>    <pubDate>2025-11-17 17:07:46</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>Magnet Axiom 9.8 Windows x64 Multilingual - 数字取证与分析</p><p>Digital Forensic Software</p><p>请访问原文链接：<a href="https://link.segmentfault.com/?enc=VaOzW2ALus7Pi9khJ51Q9Q%3D%3D.3Ybb%2F6RlKUhbFnjtliK8%2FtoZjKSutKJMLcPpdMt%2FWLs47GIFmSvQ88tHlh6Mz%2BBD" rel="nofollow" target="_blank">https://sysin.org/blog/magnet-axiom/</a> 查看最新版。原创作品，转载请保留出处。</p><p>作者主页：<a href="https://link.segmentfault.com/?enc=48pOuBsfBItXzJSVUhd0kA%3D%3D.oyuc6yq24FpSqaYEVYxkN4IS2pTwxpAY9mnSVEiVt9Q%3D" rel="nofollow" target="_blank">sysin.org</a></p><hr/><p>Magnet Axiom</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047322344" alt="形象标识" title="形象标识"/></p><p><strong>在一个案件中恢复并分析所有的证据</strong>。</p><p>在一个案件文件中，同时检查来自移动设备、云端、计算机和车辆来源的数字证据，以及第三方提取数据。使用强大且直观的分析工具，自动快速呈现与案件相关的证据。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047322345" alt="产品图像" title="产品图像" loading="lazy"/></p><p><strong>新工具如何消除干扰寻找证据</strong>？</p><p>涉及调查的数字设备数量正在增长，平均每人约有六台设备*，这使得取证、处理和分析在后勤上变得复杂、耗时且成本高昂。像 Axiom 这样的工具让调查人员能够简化工作流程 (sysin)，从大量数字干扰中快速定位、恢复和收集证据。</p><blockquote>*2022 年 IDC MarketScape</blockquote><h2>Axiom 功能</h2><p>使用 Magnet Axiom，在一个案件文件中恢复、分析并报告来自移动设备、计算机、云端和车辆的数据信息。</p><ul><li>强大的数据提取能力</li><li>移动端工作流</li><li>高级分析工具</li><li>Magnet One 增强支持</li></ul><h3>强大的数据提取能力</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047322346" alt="数据提取界面" title="数据提取界面" loading="lazy"/></p><p>轻松恢复已删除的数据，并以“数据工件优先”的方式在一个案件文件中分析来自移动设备、计算机、云端和车辆的数字证据。发现文件或工件的完整历史，以构建案件并证明意图。Magnet Axiom 为最新设备和数据来源提供最及时的数据工件支持。</p><p><strong>关键要点</strong>：</p><ol><li>在同一案件中获取并分析来自移动设备、云端和计算机的证据。</li><li>处理来自 Google、Facebook 和 Instagram 等提供商的授权数据返回。</li><li>检查来自云端来源（如 Google、WhatsApp 等）的开源和用户账户数据。</li><li>从提取、数据恢复到案件文件构建，一步完成图像处理。</li></ol><h3>移动端工作流</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047322347" alt="移动端工作流" title="移动端工作流" loading="lazy"/></p><p>无论你使用哪种提取工具，Magnet Axiom 都能获取最多的数据，并为 iOS 和 Android 设备提供最佳的分析效果。随着 Magnet Graykey 直接集成到 Axiom 中，加载移动端证据进行深度分析变得更加轻松。</p><p><strong>关键要点</strong>：</p><ol><li>接收并处理移动设备提取内容，直接集成 Magnet Graykey，并支持 Cellebrite、Oxygen、Berla 等第三方工具。</li><li>Axiom 直观的 <code>Mobile View</code> 视图帮助你和相关人员在 Axiom 与 Portable Case 中轻松浏览和交互移动证据。</li><li>利用 Axiom 内强大的数据雕刻功能，发现图片、聊天记录和浏览历史。</li><li>通过 KnowledgeC、Android Motion Photos、iOS Wallet、Samsung myFiles、地理位置数据等工件，揭示详细的主体信息。</li><li>利用移动设备的令牌和钥匙串进行自动解密。</li></ol><h3>高级分析工具</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047322348" alt="Magnet AXIOM 产品界面" title="Magnet AXIOM 产品界面" loading="lazy"/></p><p>通过 Magnet Axiom 的分析工具自动发现更多证据，让你专注于案件相关信息。借助 <code>Magnet Copilot</code>、<code>Media Explorer</code>、<code>Cloud Insights Dashboard</code>、<code>Magnet.AI</code>、<code>Connections</code>、<code>Timeline</code>、<code>Email Explorer</code> 等功能 (sysin)，快速找到所需证据。</p><p><strong>关键要点</strong>：</p><ol><li>使用 <code>Magnet.AI</code> 和 <code>Thorn</code> 等机器学习工具自动检测潜在的非法图片，如儿童虐待、毒品和武器内容。</li><li>使用 <code>Connections</code> 快速了解工件、人物或设备之间的关联。</li><li>借助 <code>Media Explorer</code> 从图像和视频中快速提取智能洞察。</li><li>使用 <code>Timeline</code> 可视化所有证据来源中的事件。</li><li>按日期、时间范围、特定工件或关键词筛选数据，快速找到相关证据。</li><li>通过早期访问 <code>Magnet Copilot</code> 等新 AI 工具，快速识别深度伪造媒体并提取相关证据。</li></ol><h3>借助 Magnet One 提升效率与协作</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047322349" alt="Magnet One" title="Magnet One" loading="lazy"/></p><p>将 Axiom 与其他数字取证解决方案整合，贯穿整个工作流程，实现更快速、更高效的调查。Magnet One 可轻松简化工作流程 (sysin)，并支持取证人员、调查员、检察官、指挥人员和机构领导之间的无缝协作。</p><p><strong>关键要点</strong>：</p><ol><li>轻松提交数字取证实验室请求并创建案件，节省时间与精力。</li><li>通过互联的工作流程减少手动步骤，提高工作效率。</li><li>在每个阶段监控 Axiom 处理任务进度，处理完成后自动通知调查人员。</li><li>与调查团队实时协作，确保所有人都能保持同步。</li></ol><h2>新增功能</h2><p>Magnet AXIOM 版本 9.8.0.46347</p><p>发布日期：2025 年 11 月 12 日</p><p>✅ <strong>新增特色 Artifacts</strong></p><ul><li>Microsoft Teams</li><li>Zangi</li><li>Signal</li><li>Snapchat</li><li>Chrome</li></ul><p>✓ <strong>OpenAI 采集</strong></p><p>AXIOM Process 现在能够从 OpenAI 帐户采集数据，包括 ChatGPT 消息，作为云证据来源。</p><p>✓ <strong>发布后启动 Magnet Griffeye</strong></p><p>在完成发布到 Magnet Griffeye 后，现在可以<strong>直接启动</strong> Magnet Griffeye 案件。</p><p>✅ <strong>新增 Artifacts</strong></p><ul><li>Chrome Cookies、Logins、Credit Cards | 多平台：新增对 v20 Chromium 加密字段的解密能力。</li><li>基于 Chromium 的浏览器 “Top Sites” | 计算机：新增支持基于 Chromium 浏览器的 “Top Sites” 。</li><li>解密数据库文件 | “Refined Results”：新增用于查看解密数据库文件的信息。</li><li>Microsoft Teams 帐户 | iOS：新增支持 Microsoft Teams 帐户。</li><li>Microsoft Teams 日历 | iOS：新增支持 Microsoft Teams 日历。</li><li>Microsoft Teams 消息 | iOS：新增支持 Microsoft Teams 消息。</li><li>Wi-Fi 已发现设备 | iOS：新增支持 Wi-Fi 已发现设备 (sysin)。</li><li>Zangi 通话 | iOS：新增支持 Zangi 通话。</li><li>Zangi 联系人 | iOS：新增支持 Zangi 联系人。</li></ul><p>✅ <strong>更新 Artifacts</strong></p><ul><li>Android Signal | Android：更新以支持 “Decrypted Database Retention（解密数据库保留）”。</li><li>Cloud Google Chrome Browser History | 云端：更新解析以支持新的架构变更。</li><li>Grindr 消息 | Android：更新以支持 Grindr 版本 25.15.0。</li><li>Instagram Direct Messages | iOS：更新支持 Instagram 版本 393.0.0。</li><li>iOS Wi-Fi 配置文件 | iOS：更新以支持已知网络的新时间戳片段 (sysin)。</li><li>图片 | 计算机：更新以将 Thumbcache Pictures 合并进入 Pictures Artifact。</li><li>Samsung Customization Service | Android：更新以支持解密数据库保留。</li><li>Samsung Customization Service、iOS Private Photo Vault、iOS Signal、Android Session、iOS Session、Android Threema、Samsung Positioning | Android, iOS：更新以支持解密数据库保留。</li><li>Signal | iOS：更新支持最新版本的 Signal（v7.82）。</li><li>Snapchat 聊天消息 | Android：更新支持 Snapchat 版本 13。</li><li>Telegram Android 消息 | Android：更新支持最新版本的 Telegram Android 消息。</li><li>WhatsApp | Android：更新本地媒体的解析。</li></ul><p>✅ <strong>云端（Cloud）</strong></p><ul><li>AXIOM Process 现在能够从 OpenAI 帐户采集数据，作为云证据来源。</li><li>在通过代理执行云采集时，如果之前未提供有效凭据，AXIOM Process 现在会提示输入凭据。</li><li>在获取 Instagram Private Direct Messages 时，现在可以选择特定对话。</li></ul><p>✅ <strong>处理（Processing）</strong></p><ul><li>在向 Magnet Griffeye 或创建新的 Magnet One 案例时，AXIOM Process 现在<strong>可选</strong>将 Magnet One 案例号作为可选的案例编号。</li><li>高级 Premier Cyber：在将案件发布至 Magnet Griffeye 完成后，现在可选择启动 Magnet Griffeye。</li></ul><p>✅ <strong>检查（Examining）</strong></p><ul><li>在 AXIOM Examine 中，Magnet Review 的登录信息现在被保留，从而减少了检查机上的登录次数。</li></ul><p>✅ <strong>修复 Bug</strong></p><ul><li>之前，AXIOM Examine 可能无法从案件中移除证据来源。 — EXM-5444</li><li>之前，导出数据中的列名称对非 ANSI 字符可能显示不正确 (sysin)。 — EXM-5250</li><li>之前，从 VICS 导出报告中的 “在 Artifacts Explorer 中显示项” 链接可能无效。 — EXM-5269</li><li>地图视图 World Map View 现在支持带 Geolocation 的自定义 Artifacts。这也解决了自定义 Artifacts 的内容类型过滤器不工作的 问题。 — EXM-5465</li><li>改进了电子邮件附件的处理，以减少记录异常 “An item with the same key has already been added”。 — CARS-1638</li><li>之前，含附件 “.msg” 文件类型的 Microsoft Outlook 电子邮件可能无法恢复。 — CARS-731</li><li>之前，如果 FileInfoList.txt 包含无效字符，AXIOM Process 可能无法处理 Apple Warrant Return。 — CA-3372</li><li>之前，AXIOM Process 只在管理员用户的当前域中搜索 Google Workspace 用户。 — CA-3464</li><li>之前，AXIOM Process 会为未启用 Gmail 范围的帐户显示可获取 Google Workspace Gmail 帐户的选项，导致 “Mail service not enabled” 错误。 — CA-1186</li><li>之前，如果在采集过程中遇到编码文件名，iCloud Photos 可能未被保存。 — CA-3311</li></ul><h2>下载地址</h2><p>想要开始学习和研究？</p><p><strong>Magnet Axiom</strong> 9.8.0.46347 for Windows x64 Multilingual</p><ul><li>请访问：<a href="https://link.segmentfault.com/?enc=QuoerTp8oJa8O6Oamndb4w%3D%3D.FmFxUk92CgS8TdgOEnAC1oKMJk8vsZJzh8zjlFL36rBZ%2BUbW6a1rHfDRuvjrUrz%2F" rel="nofollow" target="_blank">https://sysin.org/blog/magnet-axiom/</a></li></ul><p>更多：<a href="https://link.segmentfault.com/?enc=dopn2NRwwjFjFvhioTWqVw%3D%3D.2Qv5BqHYJ8mYMneFxhzIpy1KEnW9oEO%2BNfCpadteXrk%3D" rel="nofollow" target="_blank">HTTP 协议与安全</a></p>]]></description></item><item>    <title><![CDATA[【2025年11月更新】国内 ChatG]]></title>    <link>https://segmentfault.com/a/1190000047405277</link>    <guid>https://segmentfault.com/a/1190000047405277</guid>    <pubDate>2025-11-17 17:07:04</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>一、ChatGPT镜像网站</h2><p>① <a href="https://link.segmentfault.com/?enc=GOhoN39oUljJmdkjtF87uA%3D%3D.Uf310o%2BONZ6Shbkx1jVtZFkK81qWR8Gu%2BfPwPBAaf6s%3D" rel="nofollow" target="_blank">ChatGPT 中文版</a> 支持 GPT-5、GPT-5.1、4.1 以及 Claude 4.5 sonnet、Gemini 2.5 Pro、Grok 4，支持 4o 绘画、nano banana<br/>② <a href="https://link.segmentfault.com/?enc=uKFLyjH0rvR8W6odpXvcwA%3D%3D.Bynt13YGOLGkLl44LCfcv6RcevRDUjUSmu2zOLq9Vjw%3D" rel="nofollow" target="_blank">ChatGPT 镜像网站</a> 支持通用全模型，支持文件读取、插件、绘画、AI PPT<br/>③ <a href="https://link.segmentfault.com/?enc=%2FhF%2Fz3hyqCfJfynDriSaNQ%3D%3D.kH3l2CzJwnu35Ve%2BsGV%2FDOy5Bezi%2F28G1QUAWjsqjbQ%3D" rel="nofollow" target="_blank">ChatGPT 工具站</a> 收集各种可以用的ChatGPT镜像网站，免费的收费的。</p><h3>1. 什么是ChatGPT镜像网站</h3><p><strong>ChatGPT镜像网站</strong>（ChatGPT Mirror Site）是指通过复制原始网站内容和结构，创建的备用网站。其主要目的是在原始网站无法访问时，提供相同或类似的服务和信息。</p><h3>2. ChatGPT 镜像站的用途</h3><ul><li><strong>绕过访问限制</strong> ：在某些地区，访问 OpenAI 官方网站可能受到限制或阻塞，镜像站可以帮助用户绕过这些限制，继续使用 ChatGPT 服务。</li><li><strong>负载均衡</strong> ：在高流量时期，镜像站可以分担部分用户请求，减轻官方服务器的负担，确保服务的稳定性。</li><li><strong>备份与冗余</strong> ：如果官方服务遇到故障或维护，镜像站可以作为备用，保证用户依然能够访问聊天机器人。</li></ul><h4>镜像网站的优势</h4><ul><li><strong>稳定访问</strong> ：在网络限制或高峰期，提供更可靠的访问体验。</li><li><strong>快速响应</strong> ：减少访问延迟，提升用户互动流畅度。</li><li><strong>本地化服务</strong> ：优化中文支持，满足国内用户的语言需求。</li></ul><h2>二、模型知识</h2><h3>1、模型基础信息</h3><p><strong>GPT-3.5 Turbo</strong>：官方已经计划下线，现在已经全面被gpt-4o-mini替代。</p><p><strong>o1/o1-mini</strong>：最新的版本模型， o1 不是 GPT 的下一代模型！o1 和 GPT-4o在不同领域各有所长。o1 擅长 STEM领域和需要大量思考的问题，并不擅长需要常识知识的知识。OpenAI 计划在之后分别研发 GPT 和 o1 系列模型。</p><p><strong>GPT-4o/4o-mini</strong>：性价比最高模型，支持视觉等多模态，OpenAI 文档中已经更新了 GPT-4o 的介绍：128k 上下文，训练截止 2023 年 10 月（作为对比，GPT-4-Turbo 截止 2023 年 12 月）。</p><p><strong>GPT-4 Turbo</strong>：支持视觉等多模态，128k 上下文，训练截止 2023 年 12 月。</p><h3>2、功能对比（对比热门的4o和o1）</h3><p><strong>最大区别</strong>：ChatGPT 4o支持多模态，OpenAI o1目前只支持文本内容。</p><p><strong>能力上</strong>：OpenAI o1在推理能力上全面领先ChatGPT 4o。</p><p><strong>使用限制</strong>：目前ChatGPT 4o官方Plus用户没有使用限制了，o1-mini 的限额从每周 50 条增加到每天 50 条，而 o1-preview 的限额从每周 30 条提高到每周 50 条。</p><p>就我自身的使用体验来说，我更喜欢使用4o。4o整体使用更流畅，o1响应太慢。</p><p><img width="723" height="826" referrerpolicy="no-referrer" src="/img/bVdgMXJ" alt="" title=""/></p><h3>3、模型选择</h3><p>目前来说，最聪明的版本肯定是o1，但是最好用的的版本我觉得是GPT-4o。GPT-4o在综合能力方面表现更为出色，支持多模态，响应速度和价格都更有优势。</p><h4>GPT-4o 的优势</h4><pre><code>响应速度快：GPT-4o在处理任务时的响应速度更快，能够更高效地完成复杂任务。
高性价比：比GPT-4 Turbo便宜一半。
多模态支持：GPT-4o支持视觉等多模态输入，这使得它在处理图像、文本等混合任务时表现尤为出色。
128k上下文：相比其他模型，GPT-4o拥有更大的上下文窗口，可以处理更长的文本和更复杂的任务。
</code></pre><h4>OpenAI o1 的优势</h4><pre><code>超强的逻辑能力：o1 模型采用了全新的“思维链”（CoT，Chain-of-Thought）推理机制，类似于人类在回答问题前需要深入思考的过程。该模型会在作出最终回答之前，构建一条详细的内部推理链，通过强化学习不断优化其思考过程。模型能够自我纠正错误，尝试不同的策略，并将复杂的步骤分解为更简单的部分，从而大幅提高其推理能力。
</code></pre><h2>三、国内大模型能替代？</h2><p>现在好用的大模型，不仅仅ChatGPT（GPT-5、GPT-4o、4o mini）、Claude 模型</p><p>还有百度、智谱、阿里等的大模型。</p><p>尤其DeepSeek能力已经接近OpenAI等主流大模型。目前DeepSeek最新模型评分已经可以追上GPT-4。</p><p>而且还巨便宜，大家感兴趣的真的可以抄底~~</p>]]></description></item><item>    <title><![CDATA[aPaaS更新速览：业务事件操作更精准，]]></title>    <link>https://segmentfault.com/a/1190000047405281</link>    <guid>https://segmentfault.com/a/1190000047405281</guid>    <pubDate>2025-11-17 17:06:15</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>大家好，新一期得帆云aPaaS更新如期而至！本次aPaaS在业务事件等方面有不少提升，一起看看吧！<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047405283" alt="图片" title="图片"/></p><p>业务事件提示优先级优化&amp;允许关闭提示</p><p>本次更新后，业务事件「事件终止」的节点异常支持自定义展示相关提示和提示的内容。其中查询节点、弹窗节点、调用节点可自定义新增异常提示内容。查询节点、循环节点、引用节点、弹窗节点、调用节点、校验节点、外部节点可自定义新增是否展示异常提示。<br/>以下以查询节点为例，介绍功能使用：查询节点查询结果为空时选择「事件终止」，则下方出现关闭默认终止提醒、查询结果为空时提醒的功能设置。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047405284" alt="图片" title="图片" loading="lazy"/><br/>将关闭默认终止提醒右侧的开关开启，则应用前台后续业务事件执行时，查询节点查询结果为空时事件终止，且不会弹出“业务事件已终止”的默认提示；<br/>将查询结果为空时提醒右侧的开关开启，则下放出现自定义提醒内容的区域，在此区域内可输入个性化的提醒内容。<br/>输入完成后，后续应用前台业务事件执行时，查询节点结果为空时仅会弹出自定义的提醒内容；<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047405285" alt="图片" title="图片" loading="lazy"/></p><p>审批按钮支持触发操作成功后的业务事件<br/>本次更新后，列表操作栏的审批按钮将支持触发操作成功后类型的业务事件，涉及的审批按钮包括同意、拒绝、撤回、转交、驳回。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047386680" alt="图片" title="图片" loading="lazy"/><br/>人员、角色、部门、表单、流程API接口补齐本次更新新增了以下功能的API接口：<br/>人员人员信息查询：查询具体人员的基础信息；人员上/下级查询：查询指定人员的级联上级领导和直属下级员工；人员的所有上级部门：查询指定人员的部门及级联上级部门；部门部门信息查询：查询具体部门的基础信息；部门上/下级查询：查询指定部门的级联上级部门和直属下级部门；部门及其下级部门人员：查询指定部门的直属员工和包括下级部门员工的全部；角色查询用户的角色列表：查询指定用户所属的全部角色；查询指定角色的指定参数的用户：可根据角色编码和参数条件查询符合条件的人员；数据字典批量新增字典批量添加字典项查询字典信息查询字典项信息表单附件下载流程管理员操作跳转批量转交批量终止重试已处理删除未生效的流程授权修改流程授权数据删除未生效的流程转办修改流程转办数据审批人/知会对象操作征询回复前加签批量同意批量拒绝知会分发发起人终止流程信息查询流程图根据条件查询租户流程实：查询条件新增流程标题、流程实例ID、创建时间、业务字段、审批节点、备注</p><p>平台与租户中账号管理增加状态筛选<br/>本次更新，平台管理和后台管理的「账号管理」和「人员管理」页面，可以按照员工类型、状态和在职状态对员工数据进行筛选，筛选方式更加灵活。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047405286" alt="图片" title="图片" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405287" alt="图片" title="图片" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[Apache Cloudberry 内核]]></title>    <link>https://segmentfault.com/a/1190000047405302</link>    <guid>https://segmentfault.com/a/1190000047405302</guid>    <pubDate>2025-11-17 17:05:39</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>Apache Cloudberry™ (Incubating) 是 Apache 软件基金会孵化项目，由 Greenplum 和 PostgreSQL 衍生而来，作为领先的开源 MPP 数据库，可用于建设企业级数据仓库，并适用于大规模分析和 AI/ML 工作负载。</p><p>GitHub: <a href="https://link.segmentfault.com/?enc=H41186ZIJTvHasPMtRa95Q%3D%3D.8EW5WkTatCzoKSh4T%2F%2FgAQ%2BVcRdlDfEOTrC6dzUIFZhgNvpwpWSmB5VZNXLUqRhL" rel="nofollow" target="_blank">https://github.com/apache/cloudberry</a><br/>文章作者：张玥，酷克数据研发工程师；整理：酷克数据</p><p>在优化分布式数据库查询性能时，有一个长期被开发者忽视却真实存在的成本：在 Join 前没有及时过滤无效数据，导致 CPU、内存和网络被浪费在处理这些永远不可能匹配的行上。</p><p>在 Apache Cloudberry 的用户社区中，我们经常遇到这样的提问：“同样的数据量，为什么这个 Join 查询在我们的集群上跑得并不快？” 当我们排查执行计划时，往往会发现问题的根源在于 Join 的 probe 端（大表侧）始终在无差别扫描所有行，即使这些行根本不可能匹配到小表上的 Join Key。</p><p>这是很多数据库系统都曾经历的 “成长烦恼”，也是为什么我们在 Cloudberry 中坚定地实现并落地 Runtime Filter（动态过滤器）。</p><p>为什么传统 Hash Join 在大表上会成为性能瓶颈？</p><p>传统 Hash Join 的执行流程非常简单直接：先在小表上构建哈希表，然后扫描大表，对每一行都做一次哈希匹配。对用户来说，这种实现是 “透明” 的，因为它在任何场景下都能正确返回结果，但问题在于，当大表体量非常大时，这种 “扫描一切再判断” 的策略就成了资源黑洞。</p><p>具体来说：</p><p>CPU 被无效使用。 大表扫描过程中，每一行都要经过哈希探测，即便它们不可能匹配，也在消耗 CPU。<br/>内存负载高。 无效行被加载、缓存、参与后续算子处理，挤占了真正有效数据的内存空间。<br/>网络带宽浪费。 在分布式执行时，大表中这些无效行可能被传输到其他节点参与分布式 Join，白白浪费带宽。<br/>如果 Join 能在真正开始之前就知道哪些行必然不会命中，那么这些 CPU、内存和网络资源完全可以节省下来，用于处理真正有价值的数据。</p><p>这就是 Runtime Filter 存在的意义。</p><p>所谓 Runtime Filter，本质上是 在查询执行时根据小表 Join Key 动态生成的过滤器，将其 “提前” 下推到大表扫描节点，对大表行做快速预过滤，让那些不可能匹配的行直接在扫描时就被丢弃。</p><p>它并不复杂：</p><p>在小表构建哈希表时，同时根据 Join Key 创建 Bloom Filter（或 Range Filter）。<br/>将这个过滤器下推到大表扫描（SeqScan）阶段。<br/>在大表扫描时，Join Key 会先经过过滤器检查，如果不可能命中，直接丢弃。<br/>结果是，大表参与 Join 的行数锐减，执行时间随之下降，用户感觉就是：“查询快了不少。”</p><p>值得一提的是，Runtime Filter 并不是 Cloudberry 独有的优化，Spark SQL、Trino（Presto）、Apache Doris 等主流系统都早已在生产环境使用这一技术。</p><p>在 TPC-H、TPC-DS 等标准测试中，Runtime Filter 可以帮助部分 Join-heavy 的查询实现 2-10 倍的加速，且这些加速并不依赖于复杂调优参数，而是来源于最朴素的道理：“能不处理的行就不要处理。”</p><p>Cloudberry 是如何实现 Runtime Filter 的？</p><p>在实现 Runtime Filter 的过程中，我们遵循了 Cloudberry 的整体理念：简洁、高效、易扩展。</p><p>首先，我们使用 Bloom Filter 作为主要过滤器类型。原因很简单：Bloom Filter 是一种概率型过滤器，占用空间极小（通常几个 MB），通过多个哈希函数判断某个值是否可能存在，即便存在假阳性（放行无效行），也不会出现假阴性（误过滤正确行），这保证了最终结果的一致性。</p><p>其次，对于数值型 Join Key（如时间戳、整型 ID 等），我们也支持 Range Filter。它只记录 Join Key 的最小值和最大值，用于直接排除范围外的数据，更加简单高效。</p><p>我们在实现层面选择了 LOCAL 模式（进程内下推）：</p><p>Bloom Filter 和 Range Filter 的构建与下推都在同一进程内完成，无需跨进程或跨节点通信。<br/>下推到大表 SeqScan 节点后，过滤器直接作用于扫描过程，几乎没有额外延迟。<br/>这种模式实现简单，效果立竿见影，避免了引入不必要的分布式复杂性，同时带来显著的执行性能提升。</p><p>实际效果怎么样？</p><p>在 Cloudberry 的性能基准测试中，我们使用了 TPC-DS 10GB 和 100GB 数据集进行了对比：</p><p>在 10GB 测试集上，开启 Runtime Filter 后，查询总耗时从 939 秒降低到 779 秒，缩短了约 17%。<br/>在 100GB 测试集上，从 5270 秒降低到 4365 秒，提升同样在 17% 左右。<br/>需要注意的是，这种性能提升并非源于魔法，而是因为 Runtime Filter 在 Join 前就过滤掉了大量无用数据，使得 Join 的输入更 “干净”，从而减少了计算、内存和网络负担。</p><p>在实际用户环境中，这种加速效果往往更明显，特别是在 Join Key 基数较小、过滤效果明显的场景中，Runtime Filter 能让长时间跑不完的分析报表大幅缩短执行时间。</p><p>Runtime Filter 实现</p><p>在执行 Hash Join 构建哈希表时，Cloudberry 会在内部同步生成 Bloom Filter 或 Range Filter：</p><p>Bloom Filter 通过哈希函数将小表的 Join Key 值映射到位数组，实现快速的概率过滤。内存消耗极小（通常仅需几 MB），但可能存在假阳性。<br/>Range Filter 则记录 Join Key 的最小值和最大值，对于数值范围连续的数据（如时间戳、整型 ID）过滤效果更好。<br/>这些过滤器在小表扫描时被无感知地构建，完全不需要额外扫描，也不需要二次计算，真正做到 “顺手” 完成。</p><p>下推至大表扫描节点</p><p>过滤器构建完成后，最关键的步骤是将它下推到大表的 SeqScan 节点，让过滤器在扫描时生效。</p><p>在 Cloudberry 中，Join 构建和大表扫描通常位于同一执行进程内，因此过滤器可以以内存指针的方式直接传递给大表扫描节点，避免了序列化和网络通信的额外成本。</p><p>在大表执行扫描时，每当拉取下一行数据时，系统会先将该行数据的 Join Key 列送入过滤器检查：</p><p>如果不在 Range Filter 范围内，直接丢弃。<br/>如果 Bloom Filter 判断 “不存在”，直接丢弃。<br/>只有通过过滤的行，才会继续进入 Hash Join 参与探测。<br/>这种在扫描时 “预过滤” 的模式，与 Cloudberry 的执行流水线完美适配，不会破坏流水线调度，也不会引入额外锁和同步延迟。</p><p>LOCAL 模式下推</p><p>业界的一些引擎会选择在跨节点环境中通过 GLOBAL 模式下推过滤器，将过滤器同步到所有数据节点，实现更大范围的预过滤。</p><p>在 Cloudberry 的第一阶段，我们刻意选择了 LOCAL 模式（进程内下推）：</p><p>因为大部分 Broadcast Join 的场景，过滤器在进程内就足够高效；<br/>避免了跨节点网络传输和序列化带来的延迟；<br/>让过滤器的构建和应用零延迟生效，让收益最大化且稳定。<br/>这种实现方式使 Runtime Filter 成为了 Cloudberry 查询链路中 “真正无感知但持续生效” 的能力。</p><p>在执行计划中可观测，让加速 “看得见”</p><p>Runtime Filter 不仅仅是默默执行的幕后加速器，它在执行计划中是可被用户清晰感知的。当用户执行 EXPLAIN ANALYZE 时，可以看到类似如下输出：</p><p>Rows Removed by Pushdown Runtime Filter: 4,328,191<br/>意味着有 430 万行在扫描时就被 Runtime Filter 丢弃了，不再进入 Hash Join 的计算管道。</p><p>这种 “可见可观测” 的设计对 DBA、性能调优工程师非常友好：</p><p>便于判断 Runtime Filter 是否生效；<br/>能验证过滤效果是否达到预期；<br/>为后续优化 SQL 提供直观依据。<br/>代码中的 “真实细节”</p><p>在 Cloudberry 的执行器中，Runtime Filter 并非独立流程，而是通过核心结构 AttrFilter 与 Hash Join 和 SeqScan 深度集成。</p><p>AttrFilter 在执行时记录：</p><p>Join 键范围（min/max）用于 Range Filter；<br/>Bloom Filter 实例用于概率过滤；<br/>Join 键位置映射（rattno/lattno）确保列正确匹配；<br/>关联到目标 SeqScan 节点的 PlanState 指针，用于精确下推。<br/>构建过程完全与 Hash Join 的 MultiExecPrivateHash 流程同步：</p><p>在小表哈希表构建时调用 AddTupleValuesIntoRF 将值写入 Bloom Filter 或更新范围；<br/>构建完成后调用 PushdownRuntimeFilter 下推过滤器到目标扫描节点；<br/>在查询结束时自动调用 FreeRuntimeFilter 回收内存，保证系统稳定性和内存安全。<br/>这种嵌入式实现方式，使 Runtime Filter 成为了 Cloudberry 查询执行过程中 “天然存在” 的优化能力。</p><p>结语</p><p>在 Cloudberry，我们希望大部分优化能力都能做到 “对用户无感，对系统有益”，Runtime Filter 正是这样一种能力。</p><p>它不需要用户额外学习参数，不需要写复杂 SQL Hint，也不需要在执行前进行特别配置，但只要你的查询包含 Join，它就会自动工作，为你节省时间与资源。</p><p>Runtime Filter 的使命非常纯粹： 在 Join 前，让不可能命中的行在最便宜的阶段被提前过滤掉，让资源只用于真正有价值的计算。</p><p>未来，我们将继续扩展 Runtime Filter：</p><p>在合适的场景中引入 GLOBAL 模式支持，跨节点做全局预过滤；<br/>支持 IndexScan / BitmapScan 下推；<br/>提供更加智能的过滤器精度控制；<br/>实现与自适应并行度、管道执行更深度融合。<br/>但无论演化到何种程度，这项能力的本质始终不变： 用最简单的方法，让 Cloudberry 更快、更稳、更省。</p><p>如果你想了解更多 Cloudberry 在执行链路中的底层优化实践，欢迎继续关注，我们会持续发布更多底层设计与优化实战分享。</p>]]></description></item>  </channel></rss>