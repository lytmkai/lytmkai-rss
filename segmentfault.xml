<?xml version="1.0" encoding="UTF-8"?><rss version="2.0">  <channel>      <title>SegmentFault - 最近文章</title>      <link>https://segmentfault.com/blogs/newest</link>      <description>SegmentFault 思否</description>      <generator>python segmentfault.py @Pi20</generator>      <item>    <title><![CDATA[使用C#代码从工作簿中删除工作表 千杯不醉的脸盆 ]]></title>    <link>https://segmentfault.com/a/1190000047551773</link>    <guid>https://segmentfault.com/a/1190000047551773</guid>    <pubDate>2026-01-19 19:08:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>精简 Excel 工作簿、删除多余或不再使用的工作表，是一种非常有效的整理方式。通过移除无关内容，可以减少冗余信息，使文件结构更加清晰，只保留最有价值的数据。删除不必要的工作表不仅有助于释放存储空间，还能让工作簿的浏览与管理更加高效、直观。</p><p>在本文中，你将学习如何使用 Spire.XLS for .NET 库，通过 C# 从 Excel 工作簿中删除指定的工作表。</p><h2>安装 Spire.XLS for .NET</h2><p>首先，你需要将 Spire.XLS for .NET 包中包含的 DLL 文件添加为 .NET 项目的引用。你可以通过提供的下载链接手动下载 DLL 文件并引入项目，或者直接使用 NuGet 进行安装。</p><pre><code class="C#">PM&gt; Install-Package Spire.XLS</code></pre><h2>在 C# 中通过索引删除工作簿中的工作表</h2><p>Spire.XLS for .NET 提供了 WorksheetsCollection.RemoveAt(int index) 方法，可根据工作表在工作簿中的索引位置删除指定的工作表。</p><p><strong>具体示例代码如下：</strong></p><pre><code class="C#">using Spire.Xls;
using Spire.Xls.Collections;

namespace RemoveWorksheetByIndex
{
    class Program
    {
        static void Main(string[] args)
        {
            // 创建一个 Workbook 对象
            Workbook wb = new Workbook();

            // 加载 Excel 文件
            wb.LoadFromFile(@"C:\Users\Administrator\Desktop\Input.xlsx");

            // 从工作簿中获取工作表集合
            WorksheetsCollection worksheets = wb.Worksheets;

            // 根据索引删除指定的工作表
            worksheets.RemoveAt(0);

            // 将工作簿保存为新的 Excel 文件
            wb.SaveToFile("RemoveByIndex.xlsx", ExcelVersion.Version2016);

            // 释放资源
            wb.Dispose();
        }
    }
}</code></pre><h2>在 C# 中通过工作表名称删除工作簿中的工作表</h2><p>如果你已经知道需要删除的工作表名称，可以使用 WorksheetsCollection.Remove(string sheetName) 方法，直接按名称从工作簿中移除对应的工作表。</p><p><strong>具体示例代码如下：</strong></p><pre><code class="C#">using Spire.Xls;
using Spire.Xls.Collections;

namespace RemoveWorksheetByName
{
    class Program
    {
        static void Main(string[] args)
        {
            // 创建一个 Workbook 对象
            Workbook wb = new Workbook();

            // 加载 Excel 文件
            wb.LoadFromFile(@"C:\Users\Administrator\Desktop\Input.xlsx");

            // 从工作簿中获取工作表集合
            WorksheetsCollection worksheets = wb.Worksheets;

            // 根据工作表名称删除指定的工作表
            worksheets.Remove("sheet2");

            // 将工作簿保存为新的 Excel 文件
            wb.SaveToFile("RemoveByName.xlsx", ExcelVersion.Version2016);

            // 释放资源
            wb.Dispose();
        }
    }
}</code></pre><h2>在 C# 中一次性删除工作簿中的所有工作表</h2><p>如果需要一次性移除工作簿中的所有工作表，可以使用 WorksheetsCollection.Clear() 方法快速清空工作表集合。</p><p><strong>具体示例代码如下：</strong></p><pre><code class="C#">using Spire.Xls;
using Spire.Xls.Collections;

namespace RemoveAllWorksheets
{
    class Program
    {
        static void Main(string[] args)
        {
            // 创建一个 Workbook 对象
            Workbook wb = new Workbook();

            // 加载 Excel 文件
            wb.LoadFromFile(@"C:\Users\Administrator\Desktop\Input.xlsx");

            // 从工作簿中获取工作表集合
            WorksheetsCollection worksheets = wb.Worksheets;

            // 删除所有工作表
            worksheets.Clear();

            // 将工作簿保存为新的 Excel 文件
            wb.SaveToFile("RemoveAllWorksheets.xlsx", ExcelVersion.Version2016);

            // 释放资源
            wb.Dispose();
        }
    }
}</code></pre><h2>申请临时许可证</h2><p>如果你希望移除生成文档中的评估提示信息，或解除功能限制，请申请一个 为期 30 天的试用许可证。</p>]]></description></item><item>    <title><![CDATA[Linux下，服务器VPS配置、网速、带宽、IO、性能、Netflix等一键测试脚本 landonV]]></title>    <link>https://segmentfault.com/a/1190000047551797</link>    <guid>https://segmentfault.com/a/1190000047551797</guid>    <pubDate>2026-01-19 19:07:29</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>概要</p><p>云服务器市场的供应商激增，如今许多厂商经常将自己的服务器宣传得像天花乱坠，夸大其性能优势。这让许多新手用户在选择时感到困惑，往往难以判断选择合适的服务器，或者说如何科学地面对服务器的实际性能。这种情况，我们需要借助命然而，对于大多数新手来说，高效命令行的使用可能不太熟悉，这也使得他们在判断服务器性能时面临技术领先。为了帮助大家发现这些陷阱，博主特地整理了一些命令，帮助你快速检测服务器的真实性能，确保不再“踩坑”！</p><p>脚本1 </p><p><code>wget -qO- bench.sh | bash</code></p><p>脚本2</p><pre><code>  wget -qO- https://raw.githubusercontent.com/oooldking/script/master/superbench.sh | bash</code></pre><p>看上下行</p><p>脚本3</p><pre><code>(wget -qO- wget.racing/nench.sh | bash; wget -qO- wget.racing/nench.sh | bash) 2&gt;&amp;1 | tee nench.log</code></pre><p>脚本4</p><pre><code>curl -s bench.wget.racing | bash</code></pre><p>脚本5</p><pre><code>curl -s https://raw.githubusercontent.com/masonr/yet-another-bench-script/master/yabs.sh | bash
</code></pre><p>可比较真实的测试服务器带宽</p><p>脚本6</p><pre><code>curl -fsL https://ilemonra.in/LemonBenchIntl | bash -s fast</code></pre><p>可测试是否支持Netflxi等（不一定准确）</p><p>脚本7</p><pre><code>wget -N --no-check-certificate https://raw.githubusercontent.com/veip007/hj/master/hj.sh &amp;&amp; chmod +x hj.sh &amp;&amp; bash hj.sh</code></pre><p>全能，测速、加速 DD系统等</p><p>脚本8</p><pre><code>(curl -s wget.racing/nench.sh | bash) 2&gt;&amp;1 | tee nench.log</code></pre><p>脚本9</p><pre><code>screen -S uping
wget -N --no-check-certificate https://raw.githubusercontent.com/FunctionClub/uPing/master/uping.py
python uping.py</code></pre><p>服务器延迟监测<br/>脚本10</p><pre><code>wget -qO- --no-check-certificate https://raw.githubusercontent.com/qd201211/Linux-SpeedTest/master/superbench.sh | bash</code></pre><p>系统配置、国内速度等</p><p>脚本11</p><pre><code>wget --no-check-certificate https://zhujiwiki.com/wp-content/uploads/2018/07/unixbench.sh

chmod +x unixbench.sh

./unixbench.sh</code></pre><p>UnixBench跑分，测试主机性能</p><p>运行10-30分钟后（根据CPU内核数量，运算时间不等）得出分数，越高越好</p><p>脚本12<br/>访问：<a href="https://link.segmentfault.com/?enc=Kdsvd1LvG4gwmHUD6Ndt3w%3D%3D.MX48FmJzFVJzmYW1YvyttHLSAVjvAlHjBKByQHZrpeMLBx4NWm5iNmpxzv8HT%2BLj" rel="nofollow" target="_blank">https://netflix.com/title/80018499</a><br/>测试是否可以观看Netflix（奈飞）</p><p>脚本13</p><pre><code>bash &lt;(curl -Lsk https://raw.githubusercontent.com/BigMangos/speedtest-go-script/master/install.sh)
</code></pre><p>测试本地速度speedtest go版本的一键安装脚本</p><p>脚本14</p><pre><code>bash &lt;(curl -Lso- http://yun.789888.xyz/speedtest.sh)
</code></pre><pre><code>        或者
</code></pre><pre><code> bash &lt;(curl -Lso- https://zhujiwiki.com/wp-content/uploads/2021/12/speedtest.sh)
</code></pre><p>一键测试三网速度</p><p>脚本15</p><pre><code>curl https://raw.githubusercontent.com/zhucaidan/mtr_trace/main/mtr_trace.sh|bash
</code></pre><p>一键测试TCP三网回程线路</p><p>脚本16</p><pre><code>curl https://raw.githubusercontent.com/zhanghanyun/backtrace/main/install.sh -sSf | sh
</code></pre><p>一键测试TCP三网回程线路</p><p>脚本17</p><pre><code>bash &lt;(curl -Lso- https://bench.im/hyperspeed)</code></pre><pre><code>        或
</code></pre><pre><code> bash &lt;(curl -Lso- https://2life.top/speedtest.sh)</code></pre><p>国内三网速度</p><p>脚本18</p><p>`curl -sL yabs.sh | bash<br/>`<br/>yabs，系统性能测试</p><p>脚本19</p><pre><code>wget -O box.sh https://raw.githubusercontent.com/BlueSkyXN/SKY-BOX/main/box.sh &amp;&amp; chmod +x box.sh &amp;&amp; clear &amp;&amp; ./box.sh
</code></pre><p>综合工具箱</p><p>脚本20</p><pre><code> wget -q https://github.com/Aniverse/A/raw/i/a &amp;&amp; bash a
</code></pre><p>独服测试</p><p>脚本21</p><p><code> wget -qO- benchy.pw | sh</code></p><pre><code>       或
</code></pre><p><code> curl -Ls benchy.pw | sh</code></p><p>已开源：<a href="https://link.segmentfault.com/?enc=bByMDElW7dvXnbkQc8Cysw%3D%3D.o8K4VHy5gx5kJa7huaaW7nZEc9F2tgxczRC45q3ruRA%3D" rel="nofollow" target="_blank">https://github.com/L1so/benchy</a></p><p>22、系统信息和测速</p><p>含国内、亚洲、国际等节点，可选节点</p><p>1、面向全球</p><p><code>wget -qO- network-speed.xyz | bash</code></p><p>2、限定区域，包括国内</p><pre><code>curl -sL network-speed.xyz | bash -s -- -r region_name</code></pre><p>中国</p><pre><code>curl -sL network-speed.xyz | bash -s -- -r china</code></pre><p>亚洲</p><pre><code>curl -sL network-speed.xyz | bash -s -- -r asia

region_name = na, sa, eu, asia, middle-east, india, china, iran</code></pre><p>23、TCP三网回程</p><pre><code>bash &lt;(curl -Ls https://raw.githubusercontent.com/sjlleo/nexttrace/main/nt_install.sh) &amp;&amp; nexttrace -F -T</code></pre><p>24、VPS一键脚本工具</p><pre><code>curl -fsSL https://raw.githubusercontent.com/eooce/ssh_tool/main/ssh_tool.sh -o ssh_tool.sh &amp;&amp; chmod +x ssh_tool.sh &amp;&amp; ./ssh_tool.sh</code></pre><p>或</p><pre><code>wget -qO ssh_tool.sh https://raw.githubusercontent.com/eooce/ssh_tool/main/ssh_tool.sh &amp;&amp; chmod +x ssh_tool.sh &amp;&amp; ./ssh_tool.sh</code></pre><p>总结</p><p>在使用性能测试脚本时，绝对不能随便运行从网上找到一个就直接在自己的服务器上。很多正常的脚本，背后可能被某些不法分子侵入了后门或病毒，这些恶意代码可能会窃取你的资源和数据，甚至利用你的服务器进行恶意攻击，导致你所在的服务区域瘫痪，影响其他用户的正常使用。因此，安全性作为首要，必须确保所用的测试脚本来源可靠、无害。博主在这里为大家收集的脚本，都是经过检验的。欢迎大家使用，之后博主还会不断的更新！</p>]]></description></item><item>    <title><![CDATA[【vLLM 学习】Rlhf Utils 超神经HyperAI ]]></title>    <link>https://segmentfault.com/a/1190000047551815</link>    <guid>https://segmentfault.com/a/1190000047551815</guid>    <pubDate>2026-01-19 19:06:35</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>vLLM 是一款专为大语言模型推理加速而设计的框架，实现了 <a href="https://link.segmentfault.com/?enc=2Re6hb9cCnbzQ7EWJxJXNg%3D%3D.G8jEatqVH1X4l%2BqALFr0bCbd%2F%2BS4Ef2ljaZDEJz34HHGL%2FTyNPFsNQQsxoRyMfUcCTSFdjlIZTy69otKiqrTSQ%3D%3D" rel="nofollow" target="_blank">KV 缓存</a>内存几乎零浪费，解决了<a href="https://link.segmentfault.com/?enc=d70DBznJr%2Bgz8aFQTHGTBA%3D%3D.JT3uAz%2BzcX%2BDMGNImmqqK3%2FeYar8nVMLBP5hywDeiUwQWxeMKdhuM3pS7K3okA0vxOEWjX3h4maWbFQrdrxluw%3D%3D" rel="nofollow" target="_blank">内存管理瓶颈</a>问题。</p><p>更多 vLLM 中文文档及教程可访问 →<a href="https://link.segmentfault.com/?enc=mXQGuhRZPmIeWFppycn2lw%3D%3D.rof2rZ04qXyxSdjfLJbfF%2BrYDAeCglcSY6AKCK9Gafc%3D" rel="nofollow" target="_blank">https://vllm.hyper.ai/</a></p><p><a href="https://link.segmentfault.com/?enc=XfozRxXzfGrsALJev0Ufsw%3D%3D.YktDn9qkxQGZNN2R2b%2BuNLAf%2BxHstqusDbRXyXz%2BJBhSU3eTm0E5S1FAcD0zpSK4gyQrCOY70I%2FpjyDdWcUcZkOmq5jOXlaDhGvUfeeU5gWE%2FkUsOfNwm8C637vPGYOyPcP2slNBJ76YWuEMKYo8OswUUYAOOfXY2tDS4kQ%2BAd2xJNHx36vqQC110Z80Mz0M" rel="nofollow" target="_blank">*在线运行 vLLM 入门教程：零基础分步指南</a></p><p>源码 <a href="https://link.segmentfault.com/?enc=wDbzhPFClyUPe0l1Z04VLQ%3D%3D.dWbeEQOVKm7pgr%2FuEOeJsS5ROqskq1o2l38rvHawS3Og0O3CT13g4tYrxN6w089OSqIxyqtqjxB5RmJ4VYsLi%2BGWiwaNwXSiAI8ySMRnSJ6cZExYs2DfM8XJhx6J8Cnp" rel="nofollow" target="_blank">examples/offline_inference/rlhf_utils.py</a></p><pre><code>import torch


def stateless_init_process_group(master_address, master_port, rank, world_size,
                                 device):

    """
    vLLM 提供 `StatelessProcessGroup` 来创建进程组，
    无需考虑 torch.distributed 中的全局进程组。
    建议先创建 `StatelessProcessGroup`，然后初始化
    外部（训练进程）与 vLLM 工作进程之间的数据平面通信（NCCL）。
    """
    from vllm.distributed.device_communicators.pynccl import PyNcclCommunicator
    from vllm.distributed.utils import StatelessProcessGroup
    pg = StatelessProcessGroup.create(host=master_address,
                                      port=master_port,
                                      rank=rank,
                                      world_size=world_size)
    pynccl = PyNcclCommunicator(pg, device=device)
    return pynccl


class WorkerExtension:

    """
    vLLM 工作进程的基类。
    通过定义扩展类，无论底层工作进程类是什么，代码都能正常工作。
    这种方式使代码能同时兼容 vLLM V0 和 V1。
    注意：我们在单独模块中定义此类，主模块应将完整限定名
    作为 `worker_extension_cls` 参数传递。
    """

    def init_weight_update_group(self, master_address, master_port,
                                 rank_offset, world_size):
        from vllm.distributed.parallel_state import get_world_group
        rank = get_world_group().rank + rank_offset
        self.model_update_group = stateless_init_process_group(
            master_address,
            master_port,
            rank,
            world_size,
            self.device,
        )

    def update_weight(self, name, dtype, shape):
        weight = torch.empty(shape, dtype=dtype, device="cuda")
        self.model_update_group.broadcast(weight,
                                          src=0,
                                          stream=torch.cuda.current_stream())

        self.model_runner.model.load_weights(weights=[(name, weight)])

        del weight

    def check_weights_changed(self):
        """
        Check if the weights are updated to 0.
        """
        """
        检查权重是否已更新为 0。
        """
        weights_updated = True
        for name, p in self.model_runner.model.named_parameters():
            weights_updated = weights_updated and torch.allclose(
                p, torch.zeros_like(p))
        return weights_updated


class ColocateWorkerExtension:

    """
    vLLM 工作进程在协同部署场景下的基类。
    通过定义扩展类，无论底层工作进程类是什么，代码都能正常工作。
    这种方式使代码能同时兼容 vLLM V0 和 V1。
    注意：我们在单独模块中定义此类，主模块应将完整限定名
    作为 `worker_extension_cls` 参数传递。
    """

    def report_device_id(self) -&gt; str:
        from vllm.platforms import current_platform
        self.device_uuid = current_platform.get_device_uuid(self.device.index)
        return self.device_uuid

    def update_weights_from_ipc_handles(self, ipc_handles):
        handles = ipc_handles[self.device_uuid]
        device_id = self.device.index
        weights = []
        for name, handle in handles.items():
            func, args = handle
            list_args = list(args)
            # the key is to change device id to the current device id
            # in case two processes have different CUDA_VISIBLE_DEVICES
            # 关键是将设备 ID 改为当前设备 ID，
            # 以防两个进程有不同的 CUDA_VISIBLE_DEVICES
            list_args[6] = device_id
            tensor = func(*list_args)
            weights.append((name, tensor))
        self.model_runner.model.load_weights(weights=weights)
        torch.cuda.synchronize()

    def check_weights_changed(self):

        """
        检查权重是否已更新为0。
        """
        weights_updated = True
        for name, p in self.model_runner.model.named_parameters():
            weights_updated = weights_updated and torch.allclose(
                p, torch.zeros_like(p))
        return weights_updated
</code></pre>]]></description></item><item>    <title><![CDATA[【Triton 教程】triton_language.where 超神经HyperAI ]]></title>    <link>https://segmentfault.com/a/1190000047551824</link>    <guid>https://segmentfault.com/a/1190000047551824</guid>    <pubDate>2026-01-19 19:05:47</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>Triton 是一种用于并行编程的语言和编译器。它旨在提供一个基于 Python 的编程环境，以高效编写自定义 DNN 计算内核，并能够在现代 GPU 硬件上以最大吞吐量运行。</p><p>更多 Triton 中文文档可访问 →triton.hyper.ai/</p><pre><code>triton.language.where(condition, x, y)</code></pre><p>根据 <code>condition</code> 返回来自 <code>x</code> 或 <code>y</code> 元素的张量。  <br/>注意：无论 <code>condition</code> 的值是什么，<code>x</code> 和 <code>y</code> 总是会被求值。  <br/>如果希望避免意外的内存操作，请使用 <em>triton.load</em> 和 <em>triton.store</em> 中的 <code>mask</code> 参数。  <br/><code>x</code> 和 <code>y</code> 的形状都会被广播到 <code>condition</code> 的形状。<code>x</code> 和 <code>y</code> 必须具有相同的数据类型。  <br/><strong>参数</strong><strong>：</strong></p><ul><li><strong>condition</strong>（<em>triton.bool 的块</em>）- 当为 True（非零）时，产生 x，否则产生 y。</li><li><strong>x</strong> - 在条件为 True 的索引处选择的值。</li><li><strong>y</strong> - 在条件为 False 的索引处选择的值。</li></ul>]]></description></item><item>    <title><![CDATA[本地可控的 Agentic 招聘页面岗位订阅（PoC）- Part 1 MarkZhu ]]></title>    <link>https://segmentfault.com/a/1190000047551828</link>    <guid>https://segmentfault.com/a/1190000047551828</guid>    <pubDate>2026-01-19 19:05:13</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>作为一名求职中的中年软件工程师，由于地域和年龄限制，我的选择空间其实就那么几家。我经常需要反复查看自己感兴趣公司的招聘页面。这一过程既耗时又枯燥，尤其是在需要同时跟踪多家公司职位的情况下。虽然许多招聘网站都提供基于邮件的职位提醒，但这些提醒通常要么依赖于对已提交简历进行不透明的 AI 匹配，要么只是简单的关键词匹配。在这两种情况下，我对实际的匹配条件几乎没有控制权。</p><p>为了解决这个问题，我决定利用一个 AI Agent 来自动 Watching 招聘页面，并在发布符合<strong>我自己定义条件</strong>的新职位时通知我。在本文中，我将介绍一个用于验证这一想法的概念验证（PoC）。</p><p>在这个 PoC 中，我展示了如何使用 AI Agent 来 Watching 一家公司招聘页面上的软件开发岗位。该 Agent 能够自动浏览招聘网站、搜索相关职位、提取结构化信息，并将结果存储到 SQLite 数据库中，以便后续查询和跟踪。</p><h2>PoC</h2><h3>职位数据来源</h3><p>在本次实验中，我选择了一家其招聘页面基于 <a href="https://link.segmentfault.com/?enc=w1TtcciOqM1H4OoC4HKxeg%3D%3D.lko8RsIJYQwcNxJ8Iv%2FKSjgHPvJW660W9PHAI16lKAI%3D" rel="nofollow" target="_blank">Eightfold AI</a> 平台构建的公司。如果你的目标公司同样使用 Eightfold AI，那么只需做很少的修改即可复用该 PoC。</p><blockquote><a href="https://link.segmentfault.com/?enc=%2BV14XwHKBF7ho5aPVMQcFg%3D%3D.UVKZK%2B8p2LWO3EMqsOx%2Ff4FPUYF%2BtGHo74mOX9Vq%2Fy4%3D" rel="nofollow" target="_blank">Eightfold AI</a> 是一个人才智能平台，利用人工智能支持招聘、员工留任以及劳动力发展。它基于技能和经验将候选人与开放职位进行匹配，目前已被包括 Vodafone、Morgan Stanley 和 Chevron 在内的 100 多家公司使用。该平台覆盖 155 多个国家。</blockquote><p>尽管 Eightfold AI 平台本身已经提供了基于 AI 的职位提醒订阅功能，但我仍希望对匹配逻辑和采集到的数据拥有更细粒度的控制，因此才希望有一套自定义解决方案。</p><h3>Agent 设计</h3><p>我在 VS Code Copilot Chat 环境中实现了该 PoC，并使用了以下工具和提示词。</p><h4>MCP 工具</h4><ul><li><strong>浏览器工具</strong> – <a href="https://link.segmentfault.com/?enc=tS3AcXV0Kp%2B6To89oXWJOA%3D%3D.0bdUQxiHTQDhuDeCBRfyGqjkxviVka09C%2FAcFZugOn4%3D" rel="nofollow" target="_blank">browsermcp</a>：用于导航和操作招聘网站页面。</li><li><strong>SQLite 数据库工具</strong> – <a href="https://link.segmentfault.com/?enc=Ns3JVHO1lXTbqQdF2UPKLw%3D%3D.BhgDkHORtTFgYGSUhd7xIksiH%2B06agD%2BQ6Uly57HfdViigiS9pCnCwKwXCJKhjV3B%2BFf%2BYgyxz1Mcc3ahwegOhfDfxm%2BdF9E45TEIKDfxEM%3D" rel="nofollow" target="_blank">genai-toolbox</a>：用于持久化存储提取到的职位数据。</li></ul><p><code>./vscode/mcp.json</code>：</p><pre><code class="json">{
  "servers": {
    "browsermcp": {
      "type": "stdio",
      "command": "npx",
      "args": [
        "@browsermcp/mcp@latest"
      ]
    },
    "sqlite": {
      "command": "~/genai-toolbox/toolbox",
      "args": [
        "--prebuilt",
        "sqlite",
        "--stdio"
      ],
      "env": {
        "SQLITE_DATABASE": "~/jobs/jobs.db"
      }
    }
  }
}</code></pre><h4>数据库 Schema</h4><pre><code class="sql">CREATE TABLE IF NOT EXISTS xyz_company_jobs (
    job_id TEXT PRIMARY KEY, -- 职位的唯一标识
    req_id TEXT,             -- 招聘需求 ID
    job_title TEXT,          -- 职位名称
    location TEXT,
    date_posted TEXT,        -- 格式：'YYYY-MM-DD'
    business_department TEXT,
    job_description_url TEXT,
    job_description TEXT     -- 职位描述的主要内容
);</code></pre><h4>Agent 提示词</h4><pre><code class="markdown">你是一个可以访问浏览器工具和 SQLite 数据库工具的 AI Agent。你的任务是从 XYZ_Company 的招聘网站中收集与软件开发相关的职位信息，并将提取到的数据存储到 SQLite 数据库中。当前浏览器中打开的页面是 XYZ_Company 的职位搜索门户。

数据库:
```sql
CREATE TABLE IF NOT EXISTS xyz_company_jobs (
    job_id TEXT PRIMARY KEY, -- 职位的唯一标识
    req_id TEXT,             -- 招聘需求 ID
    job_title TEXT,          -- 职位名称
    location TEXT,
    date_posted TEXT,        -- 格式：'YYYY-MM-DD'
    business_department TEXT,
    job_description_url TEXT,
    job_description TEXT     -- 职位描述的主要内容
)
```

规则:
- 在调用一次 `click()` 操作后，必须等待 10 秒，确保页面完全加载，然后再调用 `snapshot` 捕获当前页面状态。
- 在向 `xyz_company_jobs` 表插入新记录之前，需要检查 `job_id` 是否已经存在，以避免重复数据。
- 在生成 INSERT SQL 语句时，确保对值中的单引号进行正确转义。
- 不要收集或点击位于 `document &gt; main &gt; group Similar Position` 区域下的职位。

用户已经准备的环境:
- 浏览器中打开的页面是 XYZ_Company 的职位搜索门户。

你的安装过程:
1. 如果 `xyz_company_jobs` 表不存在，则创建该表。在执行 SQL 时，需保留 SQL 代码块中的注释行。

执行过程:
1. 每一个文本匹配 "$Job_Title$ 于 $time_since_publication$ 前发布" 模式的按钮都代表一个职位。通过 `今天 - time_since_publication` 计算 `Date Posted`。
2. 点击职位按钮以打开职位详情页面，该页面的 URL 即为 `Job Description URL`。
3. 从职位详情页面中提取：职位名称、工作地点、Job ID、业务部门（可选）、Req ID 以及职位描述的主要内容。
4. 仅收集与软件开发相关的职位。
5. 将每个收集到的职位插入 `xyz_company_jobs` 表，并基于 `job_id` 确保不产生重复记录。
6. 如有需要，点击 `更多职位` 按钮以加载更多职位。
7. 至少收集并存储 10 个职位。</code></pre><h3>运行</h3><ol><li>打开一个 Chrome 浏览器标签页，访问 XYZ 公司的招聘门户网站。在该标签页上激活 Browser MCP Chrome 扩展程序。</li><li>在 VS Code 中启动一个新的 Copilot Chat 会话，并使用上述 MCP 配置和提示。</li></ol><h2>总结</h2><p>通过上述配置，我成功实现了一个 AI Agent，它能够自动 Watching 目标公司的招聘页面，发现新的软件开发职位。该 Agent 可以自动浏览招聘网站、识别相关职位、提取结构化数据，并将其存储到 SQLite 数据库中，从而方便后续访问和长期跟踪。</p><h2>后续工作</h2><p>该 PoC 还可以在多个方面进行扩展：</p><ul><li>引入更复杂的匹配逻辑，例如简历解析和基于语义的技能匹配。</li><li>将收集到的职位信息导出为 RSS 或邮件摘要，从而构建一个完全自托管的职位提醒系统。</li><li>添加通知机制，在发现新的匹配职位时立即提醒我。</li></ul>]]></description></item><item>    <title><![CDATA[【TVM教程】模块序列化指南 超神经HyperAI ]]></title>    <link>https://segmentfault.com/a/1190000047551831</link>    <guid>https://segmentfault.com/a/1190000047551831</guid>    <pubDate>2026-01-19 19:04:13</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>TVM 现已更新到 0.21.0 版本，<a href="https://link.segmentfault.com/?enc=Fjbj2%2B9VI6jnO9%2F%2BBjM33w%3D%3D.0Xob7oOezKw0lUTNXZex3oyTD%2Bz6jaSO7kLGegEiD9LxJHTBqobOxcA9BwGspu%2FzbTra2hC3v10sb3H1iK2pUQ%3D%3D" rel="nofollow" target="_blank">TVM 中文文档</a>已经和新版本对齐。</p><p>Apache TVM 是一个深度的深度学习编译框架，适用于 CPU、GPU 和各种机器学习加速芯片。更多 TVM 中文文档可访问 →<a href="https://link.segmentfault.com/?enc=lm7YDNn1RuYCsNwS45bI7w%3D%3D.WOwTCECSQG8UPOK9ao7Io0k1D%2FkdBfEItSzgVyxknYg%3D" rel="nofollow" target="_blank">https://tvm.hyper.ai/</a></p><p>在部署 TVM 运行时模块时，无论目标是 CPU 还是 GPU，TVM <strong>最终只需要一个动态共享库（dynamic shared library）</strong> 。实现这一点的关键就在于 <strong>统一的模块序列化机制</strong>。本文将介绍 TVM 模块序列化的格式标准与实现细节。</p><h2>序列化（Serialization）<a href="https://link.segmentfault.com/?enc=om2MlPD0g5neKJuUbxoUow%3D%3D.jAxwhyH1V2esrdKkiPkpWKKWHZeOWCM3U0v5KZYZlk6RqXH%2FkpsCRS847lng%2FiWYFvcOBOo7qt6lfDZwRIVYf5oqWQlB6WCueBovg1%2FQHmRCD0HKO1LrzbfceHF4YkyUE7cKmmERM5EJ5UMAcBEm9FdyJybTNz75sjC0yoZ3pNdvMxKEEQh4Z8K7I2VbUdj2qaIV23z24%2B5FlvYRCGlcKoevMdZGiZ5QiQ%2BrwDtKnXNfmQUOoeMdAPfKrGlq2u0Z" rel="nofollow" target="_blank">​</a></h2><p>入口 API 为 <code>tvm.module.Module</code> 的 <code>export_library</code>。在此函数内部，我们会执行以下步骤：</p><ol><li><strong>收集所有 DSO 模块</strong>（例如 LLVM 模块和 C 模块）。</li><li>在获得 DSO 模块后，调用 <code>save</code> 函数将它们保存到文件。</li><li>随后检查是否存在已导入的模块（imported modules），例如 CUDA、OpenCL 等。这里对模块类型不做限制。  <br/>如果存在导入模块，我们将创建一个名为 <code>devc.o</code> / <code>dev.cc</code> 的文件（用于将这些导入模块的二进制数据打包进最终的动态库中），然后调用 <code>_PackImportsToLLVM</code> 或 <code>_PackImportsToC</code> 来执行模块序列化。</li><li>最后，调用 <code>fcompile</code>，其内部会调用<code>_cc.create_shared</code>，生成动态共享库。</li></ol><p>备注</p><ol><li>对于 C 源码模块（CSourceModule），我们会将它们编译并与 DSO 模块一同进行链接。</li><li>是否使用 <code>_PackImportsToLLVM</code> 或 <code>_PackImportsToC</code><strong>取决于 TVM 是否启用了 LLVM</strong>。它们本质上实现的是相同的目标。</li></ol><h2>序列化底层机制与格式标准<a href="https://link.segmentfault.com/?enc=mjfY5MoV9C4SOJuD1gcfDA%3D%3D.x%2BqNWLh7UaU7%2BN9nnXKosdZWgUAVKXJHNTFKQVKbzvVmGbfKwB7cYEdGrj%2B%2B4%2BMxIdOJ9p88x%2F7eV3JzIAjcNOoelZLlWaG10l4DlegwBVgVkF1povWyQ5G38sk58snUZuf9JVcSlp6dVwmb5QG212aUtC4dwyNpONcPjSdHkyE%2BC3yVsPGUuOKTiR9J6JIKrsCcyjLB9ErNHDgvWSJ1P%2BznnppJda02vmrx1RaI%2FzaF7jrbuTDZftV7v0Y1PkjWBEvDc9FzlLUSKY4V01Kic3ywHOVvVB4SliIOnuOFTa%2F%2B10bfuQ9goTtl536LAWAUbcn4OfeeuBe3B8u3ayRRPl2Lrc6fl0%2FF6BWEhpveNIFLWLHZAF%2F45DFD2%2FDdYnVAv5jvPynw%2FWRabjvOhyIUDJGp%2FevLU85MzzrZ0WKB94A%3D" rel="nofollow" target="_blank">​</a></h2><p>序列化主要发生在 <code>_PackImportsToLLVM</code> 或<code>_PackImportsToC</code> 中。它们都会调用 <code>SerializeModule</code> 来序列化 runtime module。在 <code>SerializeModule</code> 函数中，我们首先会构造一个辅助类 <code>ModuleSerializer</code>。它会以 <code>module</code> 为输入进行初始化，例如分配模块索引。随后可以调用其 <code>SerializeModule</code> 方法执行序列化。</p><p>为了更好地理解，让我们更深入地挖掘这个类的实现。</p><p>下面的代码用于构造 <code>ModuleSerializer</code>：</p><pre><code>explicit ModuleSerializer(runtime::Module mod) : mod_(mod) {
  Init();
}
private:
void Init() {
  CreateModuleIndex();
  CreateImportTree();
}</code></pre><p>在 <code>CreateModuleIndex()</code> 中，我们使用 DFS 遍历模块的导入关系并为每个模块分配索引。根模块固定为索引 <code>0</code>。</p><p>例如：</p><pre><code>llvm_mod:imported_modules
  - cuda_mod</code></pre><p>因此，LLVM 模块的索引将是 0，CUDA 模块的索引将是 1。</p><p>在构建完模块索引之后，我们将尝试构建导入树（<code>CreateImportTree()</code>），该导入树会在我们重新加载导出的库时用于恢复模块之间的导入关系。在我们的设计中，我们使用 CSR 格式来存储导入树，每一行对应父节点索引，而子数组中的索引对应其子模块索引。在代码中，我们使用 <code>import_tree_row_ptr_</code> 和<code>import_tree_child_indices_</code> 来表示它们。</p><p>在完成初始化之后，我们就可以使用 <code>SerializeModule</code> 函数来序列化模块。</p><p>在该函数的逻辑中，我们假设序列化格式如下所示：</p><pre><code>binary_blob_size
binary_blob_type_key
binary_blob_logic
binary_blob_type_key
binary_blob_logic
...
_import_tree
_import_tree_logic</code></pre><p><code>binary_blob_size</code> 是我们在本次序列化步骤中将会包含的 blob 数量。在我们的示例中会有三个 blob，分别对应 LLVM 模块、CUDA 模块以及 <code>_import_tree</code>。</p><p><code>binary_blob_type_key</code> 是模块的 blob 类型键。 对于 LLVM / C 模块，其 blob 类型键为 <code>_lib</code>。对于 CUDA 模块，其类型键为 <code>cuda</code>，可以通过 <code>module-&gt;type_key()</code> 获取。</p><p><code>binary_blob_logic</code> 是处理该 blob 的逻辑。 对于大多数 blob（例如 CUDA、OpenCL），我们会调用 <code>SaveToBinary</code> 函数将 blob 序列化为二进制。然而，对于 LLVM / C 模块，我们只会写入 <code>_lib</code>，用于表示这是一个 DSO 模块。</p><p>备注  <br/>是否需要实现 SaveToBinary 虚函数取决于模块的使用方式。例如，如果模块中包含我们在重新加载动态共享库时需要的信息，那么我们就应该实现该函数。像 CUDA 模块，在重新加载动态共享库时我们需要将其二进制数据传递给 GPU 驱动，因此我们需要实现 <code>SaveToBinary</code> 来序列化其二进制数据。但对于主机侧模块（如 DSO 模块），在加载动态共享库时我们并不需要额外信息，因此不需要实现 <code>SaveToBinary</code>。不过，如果未来我们希望记录一些关于 DSO 模块的元信息，我们也可以为 DSO 模块实现 <code>SaveToBinary</code>。</p><p>最后，除非我们的模块中仅有一个 DSO 模块并且它位于根位置，否则我们会写入一个键 <code>_import_tree</code>。该键用于在重新加载导出的库时恢复模块导入关系，如前文所述。<code>import_tree_logic</code> 的内容则是将 <code>import_tree_row_ptr_</code> 和 <code>import_tree_child_indices_</code> 写入到流中。</p><p>在上述步骤完成后，我们会将最终结果打包进一个符号 <code>runtime::symbol::tvm_ffi_library_bin</code>，该符号可在动态库中恢复。</p><p>现在，我们已经完成序列化部分。正如你所看到的，我们理论上可以支持导入任意模块。</p><h2>反序列化<a href="https://link.segmentfault.com/?enc=RuWYQdMT5U2jcmU%2BOnNXJw%3D%3D.eRfAJs68s7dJ2AB40Ak7%2FvYr6RGEI%2BA9IYzxIS4jUaEEjOa8xy4tTgmWuMQOlQW20lJMhXtn5gjXU0Z75oGTqnu7kGQFiFrSKXgmENt113u7v8iPah4mTy8VE3%2FkGpbZPCOrz9OtpvcEKMlTJjpz1vRvUwMXxZmTz7EDR0dDV7nIgBLrdwkTn9bNXBnFxoCqxx1SpfmCooXblxGA8z%2FuceZwuaxApsmo98L9wWo7laVeuKBh3fDhKHhVXrtTZKqKou4fQkut8k%2BIWUpXM6Ru6A%3D%3D" rel="nofollow" target="_blank">​</a></h2><p>入口 API 是 <code>tvm.runtime.load</code>。实际上，该函数会调用 <code>_LoadFromFile</code>。 如果进一步展开，可以看到其对应的是 <code>Module::LoadFromFile</code>。</p><p>在我们的示例中，文件是 <code>deploy.so</code>。根据其函数逻辑，我们会在 <code>dso_library.cc</code> 中调用 <code>module.loadfile_so</code>，关键代码如下：</p><pre><code>// Load the imported modules
const char* library_bin = reinterpret_cast&lt;const char*&gt;(
   lib-&gt;GetSymbol(runtime::symbol::tvm_ffi_library_bin));
Module root_mod;
if (library_bin != nullptr) {
   root_mod = ProcessLibraryBin(library_bin, lib);
} else {
   // Only have one single DSO Module
   root_mod = Module(n);
}```

如前所述，我们会将 blob 打包进符号 `runtime::symbol::tvm_ffi_library_bin`· 中。
在反序列化阶段，我们会检查它。如果存在 `runtime::symbol::tvm_ffi_library_bin`，我们将调用 `ProcessLibraryBin`，其逻辑如下：

```c++
READ(blob_size)
READ(blob_type_key)
for (size_t i = 0; i &lt; blob_size; i++) {
    if (blob_type_key == "_lib") {
      // construct dso module using lib
    } else if (blob_type_key == "_import_tree") {
      // READ(_import_tree_row_ptr)
      // READ(_import_tree_child_indices)
    } else {
      // call module.loadbinary_blob_type_key, such as module.loadbinary_cuda
      // to restore.
    }
}
// Using _import_tree_row_ptr and _import_tree_child_indices to
// restore module import relationship. The first module is the
// root module according to our invariance as said before.
return root_module;</code></pre><p>完成上述步骤后，我们会将 <code>ctx_address</code> 设置为 <code>root_module</code>， 以便能够从根模块查找符号（使所有符号可见）。</p><p>最终，我们就完成了反序列化部分。</p>]]></description></item><item>    <title><![CDATA[Zoho Projects 多级工时表审批如何帮助您管理您的项目工时表？ 英勇无比的羽毛球 ]]></title>    <link>https://segmentfault.com/a/1190000047551835</link>    <guid>https://segmentfault.com/a/1190000047551835</guid>    <pubDate>2026-01-19 19:03:22</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><img width="723" height="208" referrerpolicy="no-referrer" src="/img/bVdnGze" alt="" title=""/></p><p><strong>多级工时审批如何提升项目管理效率</strong><br/>在现代项目管理中，准确跟踪时间和工时对于确保生产力、责任落实和成本控制至关重要。实现这一目标最有效的机制之一是项目管理工具中的多级工时审批功能。该功能引入了一种结构化的工作流程，记录的工时在最终验收前需要经过多层审核。随着组织规模和复杂性的增长，这样的系统对于维护透明度、效率和治理至关重要。</p><p><strong>提高准确性和责任落实</strong><br/>多级审批确保工时表条目由多个负责人审核，例如团队负责人、项目经理和财务经理。每个层级都会验证记录的工时是否与任务和里程碑相符。这显著减少了错误、虚报工时或意外的时间错配。员工会更加负责，因为他们知道自己的工时记录会经过系统性的验证，从而鼓励他们如实准确地报告。</p><p><strong>增强资源管理</strong></p><p>多级审批机制能够提供关于资源利用情况的宝贵信息。高级管理人员可以发现工作量不平衡、员工利用率不足或团队负担过重等问题。这有助于在各个项目中更智能地分配资源，确保在避免员工过度劳累的情况下实现最佳生产力。随着时间的推移，历史审批数据有助于预测未来的项目时间表和人员需求。</p><p><strong>提升沟通与透明度</strong></p><p>当多方利益相关者审核工时表时，员工、经理和财务团队之间的沟通将得到改善。有关任务范围、工时或优先级变更的疑问可以及早得到解答。这种透明度有助于建立团队内部的信任，并确保每个人都对项目进展有共同的理解。</p><p>Zoho Projects 多级工时表审批巧能帮助您制定规则，使用特定标准来定义工时表的审批方式和审批人。这适用于跨项目和特定项目内的工时表，允许多个利益相关者进行审核和批准。在Zoho Projects门户里面，用户可以为工时表审批创建工作流规则。按照工作流规则中添加的条件，可以进行任何操作。比如说，如果项目名称是X，工时表必须由一级汇报经理中的任何一位批准。添加这样的条件以后，用户还可以为审批者设置审批提醒。只需要输入提醒时间，然后点击提交。工时表模块中的工作流规则就被创建。</p><p>在 Zoho Projects 中，时间日志是用户在门户中输入的工时记录，记录内容是他们在特定工作项上花费的时间。工时表则是一组时间日志的集合，方便审核和审批。在Zoho Projects门户里面用户可以设置有关工时和工时表的各种个样的审批规划。<br/>Zoho Projects项目管理软件非常灵活帮助各个业务很容易地管理项目。</p>]]></description></item><item>    <title><![CDATA[2026 稳定币支付：机遇与陷阱 ChainFlash链訊 ]]></title>    <link>https://segmentfault.com/a/1190000047551879</link>    <guid>https://segmentfault.com/a/1190000047551879</guid>    <pubDate>2026-01-19 19:02:43</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>作者：Shier Han | Founder of PengoPay</p><p>在过去的半年里，我们深入调研了稳定币支付赛道，从线下零售到跨境贸易，再到B2B结算，最终得出结论：B2B场景是目前稳定币支付最具潜力的切入点。为此，我们团队将在 2026 年 2 月份推出一款面向B2B企业的稳定币收款产品，帮助企业更高效、更低成本地接收稳定币支付。</p><p>在这段市场探索过程中，我们形成了以下几点关键认知：</p><p>一、行业背景：稳定币的万亿未来</p><p>市场共识日益清晰：美元稳定币规模将持续增长，未来3~5年内有望突破万亿美元市值。这一增长不仅源于加密货币生态的内部需求，更来自传统金融领域对高效结算工具的渴望。跨境贸易、企业间结算、供应链金融等场景正在成为稳定币应用的新前沿。</p><p>二、牌照与合规：成本与现实的冲突</p><p>当前稳定币支付业务面临一个尴尬现实：并没有专属于稳定币支付的牌照体系。即便有政府机构颁发相关许可，也是将其纳入传统支付牌照框架。如果涉及资金托管，则需要申请与加密货币交易所同等级的牌照，成本极高。</p><p>这种监管滞后性导致了一个矛盾：稳定币支付创新者要么承担不合理的合规成本，要么在灰色地带冒险展业。</p><p>三、“高风险、低回报”的全托管陷阱</p><p>许多早期稳定币支付产品采用全托管钱包模式，但这隐藏着巨大风险。全托管方案的风控成本直接对标中心化交易所，需要同等水平的安全体系、合规团队和保险措施，否则极易因安全问题或资金挪用而暴雷。</p><p>更关键的是投入产出比问题：一个稳定币支付产品年度处理的资金规模，可能还不及一家中型交易所单日的交易量，却要承担相近级别的合规与风控成本。这种“小马拉大车”的模式难以为继。</p><p>四、真正的赢家：卖铲子的人</p><p>在稳定币支付这波浪潮中，我们观察到基础设施和服务提供商往往比直接做支付的产品更有发展空间：</p><p>钱包解决方案服务商<br/>KYT/AML风控服务商<br/>KYC/KYB身份验证服务商<br/>Off-Ramp法币兑换机构<br/>这些“卖铲子”的公司为整个行业提供工具和服务，风险相对分散，标准化程度高，更容易实现规模化。</p><p>五、明确的自杀行为：三条死路</p><p>通过市场观察，我们已经清晰看到哪些做法“大概率会死”：</p><ol><li>重金追逐牌照</li></ol><p>除非背靠大型金融集团，否则独立创业公司投入大量资源申请和维护全系列金融牌照，往往会在产品验证前耗尽资源。</p><ol start="2"><li>全托管资金方案</li></ol><p>为用户托管资金意味着承担交易所级别的风险，却只有支付级别的收益。一旦安全出问题或内部管控失效，信任将瞬间崩塌。</p><ol start="3"><li>亲自下场做出入金</li></ol><p>建立稳定的法币通道需要极强资源，而为了业务增长放松KYC要求或降低AML标准，则是饮鸩止渴，终将招致监管重锤。</p><p>六、持久战思维：先进场，保持在场</p><p>稳定币支付行业充满想象空间，但当前阶段能做的事情比想象的少。这是一场持久战，需要耐心、节奏感和生存智慧。</p><p>我们认为，成功的关键在于：先进入这个领域，并确保自己能够持续留在场上。</p><p>这需要我们：</p><p>选择轻资产、可扩展的商业模式<br/>与专业合规服务商合作而非自己重建轮子<br/>聚焦核心价值，不做大而全的解决方案<br/>保持灵活，随时准备调整方向</p><hr/><p><em>最后</em></p><p>我们即将推出的B2B稳定币收款产品，正是基于这些认知的产物。首先，我们不托管用户资金；正是因为选择不托管资金的方案，所以我们在合规层面不用自建复杂的合规体系；此外，我们也不会涉足高风险的法币出入金通道业务。相反，我们专注于解决企业接受稳定币支付的实际需求，与专业服务商和合规持牌机构合作构建安全合规的解决方案。</p><p>稳定币支付的未来是光明的，但道路是曲折的。在这个新兴市场中，克制比野心更重要，生存比扩张更紧迫。我们选择以谨慎乐观的态度入场，以持久战的心态布局，相信只要保持在场，就能等到行业成熟、价值兑现的那一天。</p><p>这场无国界支付变革已经开始，我们正在路上。</p>]]></description></item><item>    <title><![CDATA[2026年移动ERP系统排名测评：这5款真正能让企业“跑”起来 SaaS圈老马 ]]></title>    <link>https://segmentfault.com/a/1190000047551888</link>    <guid>https://segmentfault.com/a/1190000047551888</guid>    <pubDate>2026-01-19 19:02:10</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>说到企业管理，ERP系统早已不是新鲜词。但如今，光在电脑上用可不够了——<strong>移动办公</strong>成了刚需。老板在外想看一眼业绩，销售跑客户需要随时查库存，生产主管在车间也得能报工……一个好用、流畅、功能实在的<strong>移动ERP</strong>，已经成了企业效率的隐形引擎。</p><p>市面上叫“移动ERP”的产品不少，但哪些是真正好用、能落地的？我们结合市场口碑、产品能力、客户案例和服务模式，给大家测评出下面这5款值得重点关注的系统。排名不分绝对先后，但各有千秋，帮你找到最适合的那一个。</p><p><strong>1. 用友YonSuite</strong></p><p>用友作为国内财务和管理软件的“老大哥”，其云原生ERP套件YonSuite在移动端的表现相当扎实。</p><p><strong>核心亮点：</strong></p><p><strong>业财一体化深度好</strong>：这是用友的传统强项。从销售订单、采购入库到自动生成凭证、财务报表，移动端也能查看完整的业务流和资金流，特别适合对财务合规要求高的企业。</p><p><strong>场景化应用丰富</strong>：针对销售、采购、仓库、生产等不同角色，提供了专属的移动工作台。比如，销售员用手机就能完成客户跟进、报价、合同申请；仓管员用手持PDA或手机就能扫码入库、盘点。</p><p><strong>生态连接能力强</strong>：能较好地对接到企业微信、钉钉，方便日常审批沟通。</p><p><strong>需要注意的点：</strong></p><p>作为标准化产品，<strong>深度个性化定制能力较弱</strong>。如果你的业务流程非常特殊，需要大改系统逻辑，用友可能更倾向于复杂的二次开发，成本和周期都较高。</p><p>产品体系庞大，对于中小型企业来说，部分高级功能可能用不上，但依然需要为此付费。</p><p><strong>适合谁：</strong> 业务相对规范、尤其看重财务模块严谨性，且不希望IT运维太复杂的中大型企业或成长型企业。<br/><img width="723" height="303" referrerpolicy="no-referrer" src="/img/bVdnGz0" alt="" title=""/></p><p><strong>2. 支道</strong></p><p><a href="https://link.segmentfault.com/?enc=jn60PRMa%2Bf09zt8OPdSGcw%3D%3D.eMczPKtgrpMYAcPYPQxiFJVJayzin1laij7YN8P3Vec%3D" rel="nofollow" target="_blank">https://www.zdsztech.com</a></p><p>如果你想找一款<strong>既够用又能随时跟着业务变</strong>的系统，<strong>支道</strong>值得放在前面仔细看看。它的核心思路是提供一个<strong>无代码开发平台</strong>，让企业自己能像搭积木一样，搭建和调整ERP、CRM、项目管理等各种应用，并且天然支持多端同步。</p><p><strong>为什么它值得关注？</strong></p><p><strong>真正的“业务主导”</strong>：最大的不同在于，它改变了软件开发的逻辑。传统ERP是你提需求，厂商开发，周期长、改不动。支道提供的是表单、流程、报表等可视化引擎，企业自己的业务人员（经过简单培训）或实施顾问，就能通过“拖拉拽”配置出贴合实际流程的系统。<strong>业务怎么跑，系统就怎么配</strong>，上线阻力小。</p><p><strong>移动端与PC端同源一体</strong>：在PC端配置好的功能（如一张自定义的采购申请单、一个独特的质检流程），会自动适配手机端，无需单独开发。员工在外通过APP或集成到微信/钉钉里，就能完成全流程操作。</p><p><strong>性价比与长期灵活性</strong>：对于成长型企业，业务变得快是常态。支道模式避免了“过两年系统就不适用，推倒重来”的窘境。它按账号收费，无流量和算力限制，支持私有化部署且成本相对可控。这意味着你买的不只是一套软件，更像一个<strong>可持续生长的数字能力中心</strong>。</p><p><strong>行业方案接地气</strong>：从提供的材料看，它在生产制造、工程服务、贸易等行业有大量落地案例，解决方案直接针对这些行业的痛点（如生产进度跟踪、项目成本核算、多仓库存管理），不是泛泛而谈。</p><p><strong>需要注意的点：</strong></p><p>无代码模式在初期需要认真的业务梳理和配置投入，虽然比写代码快，但依然需要企业和实施方紧密合作，把线下流程理清楚。毕竟使用该模式的目的就是要系统“合身”，那制作系统前的“量尺寸”自然要认真。</p><p><strong>适合谁：</strong> <strong>业务流程独特、变化快</strong>的成长型中小企业；对成本敏感又需要深度适配业务的制造业、工程项目、贸易公司；以及那些被标准化软件“伤过”，渴望自己能掌控系统演进的企业。<br/><img width="723" height="291" referrerpolicy="no-referrer" src="/img/bVdnGz1" alt="" title="" loading="lazy"/></p><p><strong>3. 金蝶云·星空</strong></p><p>金蝶云·星空是金蝶面向成长型企业的ERP旗舰产品，尤其在<strong>制造业</strong>领域口碑扎实。它的移动应用 <strong>“云之家”</strong> 深度集成，在移动端管理生产、供应链方面功能突出。</p><p><strong>核心亮点：</strong></p><p><strong>制造业MES移动融合深</strong>：移动端可以查看生产任务、扫码报工、反馈工序进度、进行质量检验。实现了从订单到车间的数据贯通，管理者在外也能实时掌控生产现场。</p><p><strong>老板移动驾驶舱</strong>：为管理者提供的移动BI报表比较直观，关键经营指标（如订单交付率、库存周转、应收逾期）一屏可见，支持下钻分析。</p><p><strong>供应链协同便捷</strong>：供应商可以通过移动门户自主查询订单、确认交货、开具发票，简化了采购沟通。</p><p><strong>需要注意的点：</strong></p><p>与用友类似，复杂定制也需要走二次开发。其产品本身复杂度高，需要专业的实施顾问才能发挥最大价值。</p><p>移动端某些深度操作（如复杂报表自定义）仍需回归PC。</p><p><strong>适合谁：</strong> 尤其是<strong>离散制造和装备制造</strong>企业，需要对生产环节进行精细化移动管理的场景。<br/><img width="723" height="302" referrerpolicy="no-referrer" src="/img/bVdnGz2" alt="" title="" loading="lazy"/></p><p><strong>4. 纷享销客</strong></p><p>纷享销客起家于CRM，如今已扩展成覆盖CRM、办公协同、进销存、项目的“连接型CRM”。它的移动基因非常强大，整个产品设计就是<strong>以移动优先、销售驱动</strong>为核心的。</p><p><strong>核心亮点：</strong></p><p><strong>销售团队体验极佳</strong>：移动端做客户跟进、商机管理、合同审批、业绩查看流畅无比。它把内外勤协同、审批流和业务流结合得很好。</p><p><strong>轻量级业务管理</strong>：其进销存、项目费用管理等功能，更偏向于支撑销售业务后端，满足中小型贸易、服务类企业的日常运营管理足够，<strong>上手快，易推广</strong>。</p><p><strong>开放连接</strong>：通过PaaS平台和应用市场，能连接很多第三方工具。</p><p><strong>需要注意的点：</strong></p><p>在<strong>深度财务、复杂生产制造、多工厂供应链</strong>管理等重型ERP领域，并非其强项。</p><p>更像是一个“销售业务运营平台”，如果企业核心诉求是财务或生产，它可能需要搭配其他系统。</p><p><strong>适合谁：</strong> <strong>销售驱动型</strong>公司（如快消、IT服务、互联网），核心需求是管好销售团队和客户，并轻量化管理配套业务。<br/><img width="723" height="316" referrerpolicy="no-referrer" src="/img/bVdnGz3" alt="" title="" loading="lazy"/></p><p><strong>5. 简道云</strong></p><p>简道云是帆软软件旗下的应用搭建平台，与支道理念类似，同属<strong>无代码/低代码</strong>范畴。它以其<strong>极低的学习成本</strong>和<strong>灵活的轻应用构建能力</strong>，在中小企业中非常受欢迎。</p><p><strong>核心亮点：</strong></p><p><strong>简单易用，普及快</strong>：通过简单的表单、流程和报表设计，能快速搭建出如OA审批、进销存、设备巡检等各种管理应用。普通员工经过简短学习就能参与搭建。</p><p><strong>移动端适配优秀</strong>：搭建的应用在微信、钉钉、独立APP中都能完美运行，数据同步无感。</p><p><strong>性价比高</strong>：对于轻量级、部门级的管理需求，能以很低的成本快速满足。</p><p><strong>需要注意的点：</strong></p><p>应对<strong>极其复杂的业务逻辑、海量数据并发、多系统深度集成</strong>时，会显得力有不逮。它更像是一个<strong>出色的部门级效率工具和轻量化管理补充</strong>。</p><p>在完整的、体系化的ERP建设方面（如完整的MRP运算、成本精细核算），需要更专业的架构设计和深度开发。</p><p><strong>适合谁：</strong> 作为大型ERP的移动补充；或者满足中小企业、部门内部<strong>标准化、流程化</strong>的轻管理需求，是快速数字化的“敲门砖”。<br/><img width="723" height="293" referrerpolicy="no-referrer" src="/img/bVdnGz5" alt="" title="" loading="lazy"/></p><p><strong>总结：怎么选？看阶段和核心诉求</strong></p><p><strong>业务独特、变化快、想自己掌控，</strong>则强烈建议深入了解<strong>支道</strong>这类无代码平台。它用灵活性带来了长期的适配性和性价比，是企业构建“独家”管理系统的利器。</p><p>移动ERP的核心，不是把屏幕变小，而是<strong>把管理场景延伸</strong>。在选择时，一定要想清楚：你的团队最常在移动端完成什么？是审批、跟进、查看数据，还是完成核心业务操作？结合自身的行业特和发展阶段，才能找到那款能让企业真正“跑”起来，而不是增加负担的工具。</p>]]></description></item><item>    <title><![CDATA[2026年热门知识库管理工具：哪些项目管理软件值得一试 研之有李 ]]></title>    <link>https://segmentfault.com/a/1190000047551891</link>    <guid>https://segmentfault.com/a/1190000047551891</guid>    <pubDate>2026-01-19 19:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>本文测评了 ONES Wiki、Confluence、Notion、BookStack、GitBook、MediaWiki、Microsoft SharePoint 等知识库管理工具，从知识组织能力、搜索/语义检索、协作集成与实践策略等维度展开全面分析，帮助中高层管理者、PMO、项目经理与产品经理做出科学选型决策。</p><h2>为什么“知识库管理工具”是未来组织的核心资产</h2><p>在信息碎片化、知识孤岛普遍存在的企业环境中，组织往往面临以下核心挑战：</p><ul><li>知识难以系统化组织：不同团队间信息分散在邮件、即时通讯、个人文档中。</li><li>知识检索效率低：传统关键词匹配难以复现业务语义深层关联，而现代向量检索与语义搜索可显著提升知识可获取性。</li><li>知识生命周期难以管理：从创建、审阅、发布到淘汰，不同阶段的知识如何有效治理是组织必须面对的课题。</li></ul><p>事实上，IDC 与 Gartner 都将“知识管理软件市场”视为未来企业数字化转型的重要增长引擎，并指出到 2026 年全球知识管理软件市场规模将持续增长，强调企业对 AI 驱动的“智能知识库”和“知识生态体系”需求显著增强。</p><h4>核心测评依据</h4><p>我们的测评框架不仅评估功能覆盖，还融入了专业信息架构设计，以增强语义可检索性：</p><ul><li>知识组织与结构层级：支持层级分类、元数据、关系映射等能力；</li><li>智能搜索与语义理解：支持智能搜索、向量化检索或语义推荐能力；</li><li>协作与集成生态：与任务/项目管理、协同工具的集成能力；</li><li>治理与权限模型：支持 RBAC 权限、版本审批和知识生命周期管理；</li><li>实践成熟度与业务效果：从业务场景落地效果和操作成本维度综合评估。</li></ul><h2>热门知识库管理工具深度对比</h2><p>下面按工具核心能力类别进行分组评测。</p><h4><a href="https://link.segmentfault.com/?enc=PYNxtztK4R0SWk373qaTgA%3D%3D.bZwmp2CFQ5sEcoh99ijl8PLLsfplZzMtcFxvjYKfZrI%3D" rel="nofollow" target="_blank">ONES Wiki</a> — 文档协同和知识库管理</h4><p>作为国产研发管理平台 ONES 的知识库模块，ONES Wiki 支持丰富的知识组织层级、全文搜索、权限控制、版本可回滚与内容模板化配置。特别在与任务、需求、用例等实体数据的联动方面表现突出，对研发场景下知识沉淀、复用与交付评审形成闭环。</p><p>核心业务价值点：</p><ul><li>项目级联动知识关联：在任务、需求中直接引用知识库条目或链接文章，实现“从工作项到知识库”的闭环。</li><li>高级检索机制：支持全文索引、标签过滤和上下文匹配搜索，有利于快速定位与项目相关的知识内容。</li><li>安全与权限控制：可根据组织角色设定访问权限，有助于保护敏感信息。</li></ul><p>实践场景：ONES Wiki 非常适合研发团队、跨部门协同项目和需要将知识沉淀嵌入日常研发流程的组织。尤其是在流程驱动型组织中，文档与任务的双向链接可以极大减少重复信息整理工作，并加速经验复用周期。</p><p><img width="723" height="436" referrerpolicy="no-referrer" src="/img/bVdnurO" alt="" title=""/></p><h4>Confluence — 企业级结构化知识管理标准</h4><p>Atlassian Confluence 支持高度结构化页面层级、空间权限、审批流程与丰富插件生态。</p><p>核心优势</p><ul><li>内容结构化管理能力；</li><li>与 Jira、Opsgenie 等协同工具无缝集成；</li><li>企业级权限模型与安全治理机制完善。</li></ul><p>业务洞察：在大型企业跨部门协作场景中，Confluence 能将不同团队间文档碎片有机整合成统一知识体系。在实际项目落地中，采用基于角色分区管理、串联审批流程的知识库可显著降低跨团队沟通阻力。</p><p>局限与注意事项：因其侧重结构化与流程化，如果团队以轻量型协作和快速迭代为主，初期部署与规范制定可能会提高上手成本。</p><h4>Notion — 灵活的知识库与协作空间</h4><p>Notion 将页面、数据库、模板和表格协作等功能整合到同一平台，是一种偏向轻量且可自定义的知识库系统。其最大特色是通过“块级构建”的方式，让知识库不仅仅是文档静态层级，更是灵活的知识与任务协同空间。</p><p>主要优点：</p><ul><li>自定义数据库关系：团队可以根据自身业务场景创建定制知识结构。</li><li>知识+任务一体化管理：Notion 同时支持任务、日程、文档和知识库内容。</li></ul><p>适用与局限：适合跨职能团队、小型组织或初创企业构建灵活且低门槛的协作与知识库体系。但在知识规模大、结构复杂的企业环境中，可能需要搭配规范制度，否则会出现内容混乱、检索困难等问题。</p><h4>BookStack — 开源 Wiki 工具</h4><p>核心能力：BookStack 用“书架 → 书籍 → 章节 → 页面”层级方式组织知识，使复杂的内容结构变得直观。作为开源工具，其优势在于可自主部署、低成本、易扩展。</p><p>亮点功能：</p><ul><li>结构清晰：自然层级的内容组织方式非常适合架构大型知识体系。</li><li>权限粒度控制：支持不同访问级别设定，便于精细化管理。</li></ul><p>适用场景：对于预算敏感、技术团队内部的知识管理，BookStack 提供了一个成熟且可控的开源解决方案。但在智能搜索、流程审批与跨产品集成方面表现有限。</p><h4>GitBook — 技术型知识库管理与版本协作平台</h4><p>核心能力：GitBook 是面向技术团队和文档发布场景设计的知识管理工具，重点在于Markdown 编辑、版本控制、发布流程和团队协作体验上，尤其适合 API 文档、技术手册和产品说明书等内容的管理。</p><p>优势特点</p><ul><li>版本历史与回滚：支持详尽的历史版本管理，非常适合技术内容。</li><li>开发者友好：与 Git 流程结合紧密。</li></ul><p>选型指引：如果你的组织以技术内容为核心（如开发文档、API 指南等），GitBook 是理想选择。但在“知识运营”或“业务流程学习库”等更广泛领域，则需要结合其他工具弥补功能。</p><h4>MediaWiki &amp; 扩展 — 企业百科级知识库基础引擎</h4><p>核心能力与生态：MediaWiki 是维基百科使用的开源引擎，特别适合构建大型且协同贡献的知识库。其插件/分发版本如 BlueSpice 可提升企业级管理能力。</p><p>功能亮点：</p><ul><li>大规模协同贡献支持</li><li>扩展搜索与权限插件</li><li>内容模板与结构化数据</li></ul><p>适用场景：适合构建企业内部百科、标准流程库或产品知识树。在复杂场景中可以通过插件补足权限管理、搜索强化等企业需求。</p><h4>Microsoft SharePoint — 企业内容治理与知识库融合平台</h4><p>核心能力与价值：SharePoint 在企业内容管理与知识库系统领域具备深厚基础，支持文档库、列表、工作流审批与权限治理等能力，与 Microsoft 365 其他组件协作紧密。</p><p>适用建议：适合大型组织希望将知识管理与文档流程、合规治理、协同办公深度整合的场景。</p><h2>对比总结：选型依据与建议</h2><p>为了便于实操选型，以下是不同类型组织的推荐策略：</p><p><img width="723" height="218" referrerpolicy="no-referrer" src="/img/bVdnGz8" alt="" title="" loading="lazy"/></p><p>知识库管理工具不再只是“文档仓库”，它们是组织认知地图、协作驱动引擎和智能决策支持平台。未来知识管理的核心不在于信息堆积，而在于让知识成为组织战略资源与数字化协作能力的核心引擎。选择合适的工具、建立科学的知识治理策略，并结合智能能力与实践落地，是构建高效团队的基础。</p>]]></description></item><item>    <title><![CDATA[IQuest-Coder-V1：基于代码流训练的编程逻辑增强模型 超神经HyperAI ]]></title>    <link>https://segmentfault.com/a/1190000047551556</link>    <guid>https://segmentfault.com/a/1190000047551556</guid>    <pubDate>2026-01-19 18:12:07</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>当前，AI 代码生成工具虽然普及，但常面临生成代码逻辑僵化、上下文理解不足、难以模仿真实开发流程的挑战。<strong>许多模型仅学习代码片段的「静态快照」，缺乏对代码为何及如何修改的深层理解，导致生成的代码实用性受限。</strong></p><p>基于此，九坤投资旗下的至知创新研究院于 2026 年 1 月开源发布了 IQuest-Coder-V1 代码大模型系列。<strong>该模型基于独特的「代码流」思想构建，其核心创新在于通过让模型学习海量的真实代码变更历史，使其像经验丰富的开发者一样理解软件演进的动态过程。</strong> 且模型生成的代码在正确性、可维护性和符合开发者意图方面表现突出，能更好地处理需要多步推理的复杂编程任务。<strong>其主力版本参数量为 400 亿，并采用了可内部迭代优化代码的 Loop 架构和原生支持 128K 长上下文等设计，显著提升了处理复杂编程任务的能力。</strong></p><p>目前，HyperAI超神经官网已上线了「IQuest-Coder-V1 模型」，快来试试吧\~</p><p><strong>在线使用：<em><a href="https://link.segmentfault.com/?enc=J09EwZ8T2ZGoaIyHQCyErA%3D%3D.zgRyZEH2gXKfIrcpfrn%2BzKhYkYHY79qILkGkkFmU46s%3D" rel="nofollow" target="_blank">https://go.hyper.ai/vk4K2</a></em></strong></p><p><strong>1 月 12 日-1 月 16 日，hyper.ai 官网更新速览：</strong></p><ul><li>优质教程精选：3 个</li><li>热门百科词条：5 条</li><li>1 月截稿顶会：8 个</li></ul><p><strong>访问官网：<em>hyper.ai</em></strong></p><p>**\<br/>**</p><p><strong>公共教程精选</strong></p><p><strong>1.vLLM+Open WebUI 部署 IQuest-Coder-V1</strong></p><p>IQuest-Coder-V1 是由 IQuestLab 发布的一个专注于代码生成、理解和优化的先进人工智能模型。具备多种参数规模（7B、14B、40B）和版本（Instruct、Thinking、Loop），以满足不同开发需求。采用「代码流多阶段训练」策略，学习静态代码片段，从代码演化过程中获取知识，显著提升了对真实开发场景的理解能力。</p><p>**<em>在线运行：</em> **<strong><em><a href="https://link.segmentfault.com/?enc=xwWYlfpGaP4U%2BSLSnQivug%3D%3D.LYhkBG%2FIDuFY5iZc9SQAC52DlhSOo4LpqfbLCqP9QMM%3D" rel="nofollow" target="_blank">https://go.hyper.ai/vk4K2</a></em></strong></p><p><strong><em>论文链接：<a href="https://link.segmentfault.com/?enc=%2F7wfC6W2ea9TlkhPNUO22Q%3D%3D.QHW2ejnZWFGpStcsaSdzm22Y1k3WRtvZ%2B7MAkfje9L4%3D" rel="nofollow" target="_blank">https://hyper.ai/papers/IQuest</a></em></strong></p><p><img width="723" height="456" referrerpolicy="no-referrer" src="/img/bVdnGun" alt="" title=""/><br/>Demo 页面</p><p><strong>2.vLLM+Open WebUI 部署 QwenLong-L1.5</strong></p><p>QwenLong-L1.5 是阿里巴巴通义实验室推出的长上下文推理与记忆管理模型系列模型。本教程使用的 QwenLong-L1.5-30B-A3B 是一个约 300 亿参数的解码式 Transformer 模型，基于基础模型 Qwen3-30B-A3B-Thinking 进行系统化后训练（post-training）得到，并以开源形式发布在 Hugging Face 等平台，其采用一系列后训练技巧，包括长上下文数据合成管线、面向长序列的稳定强化学习和记忆增强的超长上下文框架，在长上下文基准测试中表现更为优秀，同时，这些能力也迁移到了通用领域任务，包括数学推理、工具使用以及长对话一致性等。</p><p><strong><em>在线运行：<a href="https://link.segmentfault.com/?enc=DfNj6IiqIwZrVBi6sQrSqA%3D%3D.%2B0rzSN2X06YktIf9cAXjK7oFaDh7NQqzRzPi8gODNG4%3D" rel="nofollow" target="_blank">https://go.hyper.ai/6mD9U</a></em></strong></p><p><img width="723" height="454" referrerpolicy="no-referrer" src="/img/bVdnGuo" alt="" title="" loading="lazy"/></p><p>Demo 页面</p><p><strong>3.Qwen-Image-2512：更真实的人像与自然风光生成</strong></p><p>Qwen-Image-2512 是 Qwen-Image 系列中的一款 Text-to-Image（文本生成图像）基础模型，是该系列在年末推出的升级版本。该模型主要面向高质量图像生成与复杂多模态内容表达场景。相比此前版本，Qwen-Image-2512 在多个关键维度上进行了系统性优化，重点提升了生成图像的整体真实感与可用性。其中，人像生成的自然程度显著增强，人物面部结构、皮肤质感与光影关系更加接近真实摄影效果；在自然场景中，模型能够生成更细腻的地貌纹理、植被细节以及动物毛发等高频信息；同时，模型在图像中文字的生成与排版能力上也有所改进，能够更稳定地呈现可读文本与较复杂的文字布局。</p><p><strong><em>在线运行：<a href="https://link.segmentfault.com/?enc=u1FHcq5ME5K664awfV1P5Q%3D%3D.nvP3xkFh7O4jz3uUI31uv%2BSZ8MDaebVWe6YRFpywEyk%3D" rel="nofollow" target="_blank">https://go.hyper.ai/rODFG</a></em></strong></p><p><img width="723" height="408" referrerpolicy="no-referrer" src="/img/bVdnGuq" alt="" title="" loading="lazy"/><br/>&lt;p align=center&gt;效果展示&lt;/p&gt;</p><p><strong>热门百科词条精选</strong></p><p><strong>1. 每秒帧数 FPS</strong></p><p><strong>2. 双向长短期记忆 Bi-LSTM</strong></p><p><strong>3. 具身导航 Embodied Navigation</strong></p><p><strong>4. 多阶段强化学习框架 RewardMap</strong></p><p><strong>5. 猜测-思考-回答 Guess–Think–Answer</strong></p><p>这里汇编了数百条 AI 相关词条，让你在这里读懂「人工智能」：</p><p><strong><em><a href="https://link.segmentfault.com/?enc=dKr2ZOq2o6JdIaonGmNjWw%3D%3D.eERczQ%2BEC9DgMnEu%2BzirUf4T7ip1D%2F4IQ5PeEgCg2Q4%3D" rel="nofollow" target="_blank">https://go.hyper.ai/wiki</a></em></strong></p><p><img width="469" height="724" referrerpolicy="no-referrer" src="/img/bVdnGlq" alt="" title="" loading="lazy"/><br/>一站式追踪人工智能学术顶会：<strong><em><a href="https://link.segmentfault.com/?enc=AvjqMplN2e4hiQoUSf8Atg%3D%3D.P0FGNrgGgQ%2FNNQa7jzjazK8KbhvtDSe5s4ShYhdC6dQ%3D" rel="nofollow" target="_blank">https://go.hyper.ai/event</a></em></strong></p><p>以上就是本周编辑精选的全部内容，如果你有想要收录 hyper.ai 官方网站的资源，也欢迎留言或投稿告诉我们哦！</p><p>下周再见！</p>]]></description></item><item>    <title><![CDATA[从入门到精通：三款最适合业务人员自助分析的 AI-BI 工具选型推荐 数据集成与治理 ]]></title>    <link>https://segmentfault.com/a/1190000047551617</link>    <guid>https://segmentfault.com/a/1190000047551617</guid>    <pubDate>2026-01-19 18:11:16</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>一、行业背景：业务人员 “自己做分析” 成趋势，AI-BI 是破局关键</h2><p>根据 Gartner 2025 年《企业 analytics 趋势报告》，<strong>2026 年 80% 的业务分析将由业务人员自主完成</strong>—— 无需 IT 写 SQL、不用等数据导出，直接用 “自己的方式” 拿到想要的洞察。但传统 BI 的痛点依然突出：IDC 2024 年调查显示，<strong>72% 的业务人员因 “需要 IT 支持” 放弃深度分析</strong>，<strong>65% 的人认为 “BI 工具太复杂，学不会”</strong>。<br/>AI-BI 的出现彻底改变了这一局面：它用<strong>自然语言问数</strong>替代 SQL、用<strong>零代码操作</strong>降低门槛、用<strong>AI 智能洞察</strong>替代人工探索，让业务人员从 “数据的被动接收者” 变成 “分析的主导者”。本质上，企业需要的不是 “更强大的 BI”，而是 “业务人员能自己用的 BI”—— 这也是本次选型的核心标准。</p><h2>二、三款最适合业务人员的 AI-BI 工具横评</h2><h3>TOP1：FineBI（综合评分：4.8/5）</h3><p><strong>产品定位</strong>：帆软旗下一站式智能自助 BI 平台，是<strong>Gartner 全球 ABI 魔力象限唯一入选中国独立 BI 厂商</strong>，IDC 报告连续八年（2017–2024）蝉联中国 BI 市场占有率第一。聚焦 “零代码 + AI 智能”，目标是 “让业务人员从‘找 IT 要数据’变成‘自己做分析’”，覆盖从数据整合到智能洞察的全链路自助分析。<br/><strong>核心优势</strong>：</p><ol><li><strong>零代码入门，10 分钟上手</strong>：无需学习 SQL 或数据建模，业务人员打开工具就能用 —— 比如想查 “最近一周的抖音新客转化率”，直接在搜索框输入问题，系统自动返回结果，连 “选数据源”“拉维度” 都不用做。</li><li><strong>AI 问数能听懂 “人话”</strong>：支持完全口语化表述，比如 “上个月华南区门店坪效最高的前三名是哪几个？”，系统会自动拆解 “时间（上个月）、区域（华南区）、指标（坪效）、维度（前三名）” 四大要素，精准返回结果；如果表述模糊（比如 “最近销量不好的产品”），会主动提示 “你是指近 30 天销量同比下降超 20% 的产品吗？”，帮用户明确需求。</li><li><strong>从 “查数” 到 “洞察” 的全链路自助</strong>：不仅能查数据，还能自动生成分析结论 —— 比如问 “这个季度销售额增长的原因”，系统会联动多数据源（ERP 的库存、CRM 的客户行为），生成结论：“销售额增长 15%，主要因为华东区推出新品，带动客单价提升 12%”，直接把 “数据” 变成 “可行动的 insight”。</li></ol><p><strong>适用场景</strong>：</p><ul><li>入门级：业务人员日常查数（比如运营问 “最近的用户增长”、销售问 “客户复购率”）；</li><li>进阶级：自助探索分析（比如市场部找 “广告转化率低的原因”，用工具联动渠道、地域、人群维度）；</li><li>精通级：跨部门协作（比如财务问 “CRM 客户与 ERP 库存的关联”，不用等 IT 整合数据，自己就能连）。</li></ul><p><strong>真实案例</strong>：唯捷城配是仓配一体物流企业，业务扩张后对数据要求提升。痛点包括：原有 BI 系统难支撑业务，驾驶舱加载慢、数据落后，业务数据汇总分析难，异常发现处理不及时。<br/>解决方案：重构数据中心，搭建三层架构，用帆软搭建 BI；重新设计驾驶舱；构建业务报表；开发数据风险监控。<br/>结果：首页加载优化至 2 秒内，驾驶舱月访问量增至 5000 + 人次，每月为业务部门减 10 人/天/部门工作量，风险监控月访 3000 次以上、自动发起处理流程 156 次。</p><h3>TOP2：Tableau（综合评分：4.5/5）</h3><p><strong>产品定位</strong>：全球可视化 BI 权威，以 “可视化故事化 + AI 智能洞察” 为核心，适合需要<strong>高颜值交互式报表</strong>和<strong>深度可视化分析</strong>的业务人员，目标是 “让数据通过可视化‘说话’”—— 从 Gartner 到 Forbes，均将其评为 “全球最易使用的可视化 BI 工具”。<br/><strong>核心优势</strong>：</p><ol><li><strong>可视化故事化能力</strong>：一键生成 “交互式仪表盘”，把散点的数据变成 “有逻辑的故事”—— 比如分析 “广告转化率”，可自动串联 “渠道→地域→人群” 的可视化图表，点击某个渠道（如抖音），自动下钻到该渠道的 “年龄分布” 和 “时段效果”，让业务人员不用写报告，直接用图表 “讲数据故事”；</li><li><strong>AI 问数联动可视化</strong>：支持 “自然语言→可视化” 的直接转换 —— 比如问 “上个月华南区门店坪效最高的前三名”，系统会自动生成 <strong> 地图（华南区）+ 柱状图（门店坪效）</strong> 的组合报表，点击地图上的 “广州”，柱状图会实时筛选出广州的门店，无需额外操作；</li><li><strong>跨数据源整合</strong>：支持连接 200+ 数据源（Excel、SQL Server、Amazon Redshift、Salesforce 等），业务人员可直接整合 “线下 Excel 客户数据” 和 “线上 CRM 交易数据”，做联合分析（比如 “客户复购率与线上互动的关联”）。</li></ol><p><strong>适用场景</strong>：</p><ul><li>营销 / 设计 / 战略团队：需要 “高颜值报表” 做季度汇报（比如市场部用 Tableau 做 “广告效果可视化故事”，直接发给管理层）；</li><li>需要深度可视化的场景：比如零售企业分析 “门店选址与客流量的关系”，用地图 + 热力图直观展示；</li><li>跨数据源整合分析：比如财务团队整合 “ERP 库存数据” 和 “Excel 预算数据”，分析 “库存周转与预算的偏差”。</li></ul><h3>TOP3：Power BI（综合评分：4.3/5）</h3><p><strong>产品定位</strong>：微软生态智能 BI，以 “Excel 无缝集成 + AI 辅助分析 + 生态协同” 为核心，适合<strong>微软生态深度用户</strong>和<strong>需要轻量级自助分析</strong>的业务人员，目标是 “让 Excel 用户‘零学习’过渡到 BI”—— 作为微软 Office 365 的核心组件，全球超 500 万企业用户在使用。<br/><strong>核心优势</strong>：</p><ol><li><strong>Excel 无缝集成</strong>：直接导入 Excel 的 “数据透视表”“公式模型”，业务人员用熟悉的 Excel 逻辑做 BI 分析 —— 比如财务团队用 Excel 做 “月度预算表”，可直接导入 Power BI，自动生成 “预算 vs 实际” 的折线图，还能添加 “AI 快速见解”（比如自动指出 “行政费用超支 15%”）；</li><li><strong>AI 辅助分析</strong>：内置 “AI Insights” 功能，自动识别数据中的 “趋势、异常、关联”—— 比如分析 “销售数据”，AI 会自动提示 “某产品在 11 月销量骤增，原因是双十一促销”，或 “华北区销售额与气温呈负相关”；</li><li><strong>生态协同</strong>：深度整合微软 Teams、Outlook、SharePoint—— 比如业务人员在 Teams 里分享 Power BI 仪表盘，同事可直接在 Teams 里评论 “这个月销量为什么下降？”，或通过 Outlook 自动接收 “每日销售简报”，无需切换工具。</li></ol><p><strong>适用场景</strong>：</p><ul><li>财务团队：Excel 报表的 “升级需求”（比如把 Excel 预算表变成交互式 BI 仪表盘）；</li><li>微软生态企业：比如用 Office 365 的企业，业务人员可在 Word 里插入 Power BI 图表，或在 Teams 里协同分析；</li><li>轻量级实时监控：比如运营团队监控 “网站实时流量”，用 Power BI 连接 Google Analytics，实时生成 “流量来源” 仪表盘。</li></ul><h2>三、三款工具核心能力对比表</h2><p><img width="720" height="330" referrerpolicy="no-referrer" src="/img/bVdnGvh" alt="image.png" title="image.png"/></p><h2>四、业务人员 AI-BI 工具选型指南：三步选对 “自己能用的 BI”</h2><h3>1. 选型三原则（避开 90% 的坑）</h3><ul><li><strong>原则一：先看 “易用性”，再看 “功能强”</strong>：业务人员不是数据专家，“能快速上手” 比 “有 100 个功能” 更重要 —— 比如 FineBI 的零代码，让运营人员 10 分钟就能用，比 “功能强大但要学 SQL” 的工具更适合；</li><li><strong>原则二：测 “AI 问数的准确率”</strong>：找 3 个日常场景测试 ——① 口语化提问（比如 “上个月华南区的坪效”）；② 模糊提问（比如 “最近销量不好的产品”）；③ 连续提问（比如 “这个季度销售额→华东区呢？”），能通过这三个测试的工具才是 “能听懂人话” 的；</li><li><strong>原则三：匹配 “企业规模与场景”</strong>：中小微企业选 FineBI（零代码 + 全链路）；需要可视化故事的选 Tableau（高颜值报表）；微软生态用户选 Power BI（Excel 无缝过渡）。</li></ul><h3>2. 首推 FineBI 的理由</h3><p>FineBI 是<strong>唯一能覆盖 “业务人员从入门到精通” 全阶段</strong>的工具：</p><ul><li>入门级：零代码让新手 “会说话就能用”；</li><li>进阶级：AI 问数 + 自助探索，满足深度分析需求；</li><li>精通级：支持 200+ 数据源、万人级协作，适合中大型企业的复杂场景；</li><li>全行业：有 180+ 行业模板（零售、制造、金融），15 分钟就能搭建贴合业务的系统。</li></ul><h2>五、本文相关 FAQs</h2><h3>Q1：业务人员自助分析需要学 SQL 吗？</h3><p>A：不需要。AI-BI 工具的核心价值就是 “替代 SQL”——80% 的日常场景（比如 “最近的销售额”“客户复购率”），用自然语言提问就能解决；即使是复杂场景（比如 “按产品类别分的季度销售额”），也只需要在工具里 “点选维度”，不用写 SQL。只有极少数极端复杂的需求（比如自定义计算逻辑），可能需要辅助设置参数，但依然不需要掌握完整的 SQL 语法。对业务人员来说，“会说话就能做分析” 是 AI-BI 工具的核心优势。</p><h3>Q2：AI-BI 工具能处理实时数据吗？</h3><p>A：是的。很多 AI-BI 工具支持 “实时数据连接”，比如连接车间的传感器、电商的实时订单、直播的观众数据。业务人员可以随时问 “当前的生产线良品率”“现在的销售额”，系统会实时读取数据源，1 秒内返回结果。实时数据处理的核心是工具能 “低延迟连接数据源”，并优化查询性能，确保业务人员能及时拿到最新洞察。</p><h3>Q3：自助分析如何保证数据安全？</h3><p>A：自助分析的安全不是 “禁止使用”，而是 “在安全框架内使用”，主要通过三个手段：① <strong>权限管理</strong>：企业可以给不同岗位设置不同权限（比如市场部只能看市场数据，销售部只能看销售数据），避免数据泄露；② <strong>数据加密</strong>：工具会对数据传输（比如从数据源到工具的过程）和存储（比如存在工具里的数据）进行加密，即使被窃取也无法读取；③ <strong>本地部署</strong>：很多工具支持 “本地部署”，把数据存在企业自己的服务器里，不用上传到云端，进一步保证安全。总之，自助分析≠数据不安全，只要做好 “权限 + 加密 + 部署”，就能放心用。<br/><strong>结语</strong>：对业务人员来说，最好的 AI-BI 工具不是 “功能最强大的”，而是 “自己能快速上手、能听懂自己的话、能解决实际问题的”。FineBI 之所以成为首推，就是因为它把 “复杂的 BI 技术” 藏在背后，让业务人员 “用说话的方式做分析”—— 从入门到精通，只需要 “会提问”。告别 “等 IT 数据” 的日子，从选对一款 “自己能用的 AI-BI” 开始。</p>]]></description></item><item>    <title><![CDATA[7个 Golang 官方文档没细说的高效技巧 烦恼的沙发 ]]></title>    <link>https://segmentfault.com/a/1190000047551623</link>    <guid>https://segmentfault.com/a/1190000047551623</guid>    <pubDate>2026-01-19 18:10:32</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>Go 的语法确实简单，但要在生产环境写出高性能代码，光靠语法糖是不够的。但很多时候，写出能跑的代码只是及格线，写出高性能、内存友好且易于维护的代码才是真正的门槛。<br/><img width="723" height="425" referrerpolicy="no-referrer" src="/img/bVdnGvN" alt="image.png" title="image.png"/></p><p>为了省心，我最近把本地环境换成了 <a href="https://link.segmentfault.com/?enc=5A3V5dSAd3orAwOfPwJfGQ%3D%3D.XNilkH6RZHivpze7XS5pxn9Wq61atlzTcgMecqWTIVk%3D" rel="nofollow" target="_blank">ServBay</a>。它最大的好处是能一键安装从 Go 1.11 到 Go 1.24 的所有版本，而且这些版本是物理隔离并存的。不需要再去手动折腾 <a href="https://link.segmentfault.com/?enc=MHLa%2Bku2PiQd8PMDZogyOg%3D%3D.rPNriug7jcEPd0mjE8aLKvIOy%2F0n2G5l24DE6dpScN4tOra12fkJu14Oa0zyWQrR" rel="nofollow" target="_blank">Go 的环境变量</a>，想用哪个版本随时切，甚至可以开着不同版本的终端同时跑。</p><p><img width="723" height="458" referrerpolicy="no-referrer" src="/img/bVdnGvO" alt="image.png" title="image.png" loading="lazy"/></p><p>环境搞定后，我们把精力收回到代码本身，聊聊几个容易被忽视却极其实用的 Go 技巧。</p><h3>Slice 的预分配（Pre-Allocate）</h3><p>这是最基础也最容易被忽略的性能优化点。很多人习惯写 <code>var data []int</code> 然后直接开始循环 <code>append</code>。</p><p>代码确实能跑，但底层就不一定了。Go 运行时发现容量不够，就得重新申请更大的内存条，把旧数据拷过去，再把旧内存丢给 GC 回收。在数据量大的循环里，这会造成大量的内存分配和 CPU 消耗。</p><p><strong>低效写法：</strong></p><pre><code class="go">// 每次 append 都可能触发扩容和内存拷贝
func collectData(count int) []int {
    var data []int 
    for i := 0; i &lt; count; i++ {
        data = append(data, i)
    }
    return data
}</code></pre><p><strong>高效写法：</strong></p><pre><code class="go">// 一次性分配好内存，避免中途扩容
func collectDataOptimized(count int) []int {
    // 使用 make 指定长度为 0，容量为 count
    data := make([]int, 0, count)
    for i := 0; i &lt; count; i++ {
        data = append(data, i)
    }
    return data
}</code></pre><p>如果能预估容量，务必使用 <code>make([]T, 0, cap)</code>。这不仅减少了 CPU 消耗，更显著降低了 GC 压力。</p><h3>警惕 Slice 的内存别名问题</h3><p>Slice 本质上是对底层数组的一个视图（View）。对 Slice 进行切片操作（reslicing）时，新 Slice 和原 Slice 共享同一个底层数组。</p><p>如果原数组很大，而你只需要其中一小部分，直接切片会导致整个大数组无法被 GC 回收，造成内存泄漏；或者修改新 Slice 会意外影响原数据。</p><p><strong>问题代码：</strong></p><pre><code class="go">origin := []int{10, 20, 30, 40, 50}
sub := origin[:2] // sub 和 origin 共享底层数组
sub[1] = 999      // 修改 sub 会影响 origin

// origin 变成了 [10, 999, 30, 40, 50]</code></pre><p><strong>安全写法：</strong></p><pre><code class="go">origin := []int{10, 20, 30, 40, 50}
// 创建一个独立的 slice
sub := make([]int, 2)
copy(sub, origin[:2]) 

sub[1] = 999
// origin 依然是 [10, 20, 30, 40, 50]</code></pre><p>若需要数据隔离或防止内存泄漏，请使用 <code>copy</code> 或者 <code>append([]T(nil), origin[:n]...)</code> 这种惯用法。</p><h3>利用结构体嵌入实现组合</h3><p>Go 没有传统的继承，但通过结构体嵌入（Embedding）可以实现类似的效果，且更加灵活。嵌入字段的方法会被直接提升到外部结构体，调用起来就像是自己的方法一样。</p><pre><code class="go">type BaseEngine struct {
    Power int
}

func (e BaseEngine) Start() {
    fmt.Printf("Engine started with power: %d\n", e.Power)
}

type Car struct {
    BaseEngine // 匿名嵌入
    Model      string
}

func main() {
    c := Car{
        BaseEngine: BaseEngine{Power: 200},
        Model:      "Sports",
    }
    // 可以直接调用 BaseEngine 的 Start 方法，仿佛是 Car 自己的方法
    c.Start() 
}</code></pre><p>这种方式让代码结构更扁平，符合 Go 提倡的组合优于继承的设计哲学。</p><h3>Defer 不只是用来关文件的</h3><p>很多人只在 <code>File.Close()</code> 时才想起来用 <code>defer</code>。其实在并发编程里，它更是防死锁的利器。</p><p>比如使用互斥锁（Mutex）时，最怕的就是中间有个 <code>if err != nil { return }</code>，结果锁忘了解，导致整个程序卡死。</p><pre><code class="go">func safeProcess() error {
    mu := &amp;sync.Mutex{}
    mu.Lock()
    // 立即注册解锁操作，防止后续代码 panic 或 return 导致死锁
    defer mu.Unlock()

    f, err := os.Open("config.json")
    if err != nil {
        return err
    }
    // 文件打开成功后，立即注册关闭操作
    defer f.Close()

    // 业务逻辑...
    return nil
}</code></pre><p>Go 1.14 之后 <code>defer</code> 的性能开销已经非常小，在大多数 I/O 场景下可以忽略不计，放心使用。</p><h3>使用 iota 优雅定义枚举</h3><p>Go 虽无枚举类型，但 <code>iota</code> 常量计数器能很好地解决这个问题。配合自定义类型和 <code>String()</code> 方法，可以实现类型安全且可读性强的枚举。</p><pre><code class="go">type JobState int

const (
    StatePending JobState = iota // 0
    StateRunning                 // 1
    StateDone                    // 2
    StateFailed                  // 3
)

func (s JobState) String() string {
    return [...]string{"Pending", "Running", "Done", "Failed"}[s]
}

func main() {
    current := StateRunning
    fmt.Println(current) // 输出: Running
}</code></pre><p>这样维护起来也更直观。</p><h3>高并发计数？Atomic 比 Mutex 快</h3><p>对于简单的计数器或状态标志，使用 <code>sync.Mutex</code> 有点“杀鸡用牛刀”，且锁的竞争会带来上下文切换的开销。<code>sync/atomic</code> 包提供的原子操作在硬件指令层面完成，效率极高。</p><pre><code class="go">var requestCount int64

func worker(wg *sync.WaitGroup) {
    defer wg.Done()
    // 原子增加，不需要加锁
    atomic.AddInt64(&amp;requestCount, 1)
}

func main() {
    var wg sync.WaitGroup
    for i := 0; i &lt; 100; i++ {
        wg.Add(1)
        go worker(&amp;wg)
    }
    wg.Wait()
    // 原子读取
    fmt.Println("Total requests:", atomic.LoadInt64(&amp;requestCount))
}</code></pre><p>在并发极高的场景下，Atomic 操作通常比 Mutex 性能更好。</p><h3>接口嵌入用于 Mock 测试</h3><p>写单元测试时，Mock 一个大接口很麻烦。通过嵌入小接口来组合大接口，可以让 Mock 对象只实现必要的方法。</p><pre><code class="go">type Reader interface {
    Read(p []byte) (n int, err error)
}

type Writer interface {
    Write(p []byte) (n int, err error)
}

// 通过嵌入组合成新接口
type ReadWriter interface {
    Reader
    Writer
}

// 业务代码依赖接口而非具体实现
func CopyData(rw ReadWriter) {
    // ...
}</code></pre><p>在测试时，只需要实现 <code>Read</code> 和 <code>Write</code> 方法即可满足 <code>ReadWriter</code> 接口，不需要去继承什么复杂的基类。</p><hr/><p>Go 的哲学是“少即是多”，但掌握这些细节就能在受限的语法中写出更健壮的代码。无论是内存布局的控制，还是并发原语的选择，都需要大量的实践积累。</p><p>最后再次提醒，如果不想在本地环境配置上浪费时间，或者需要在 Go 1.11 到 Go 1.24 之间反复横跳验证这些特性，ServBay 是一个非常值得尝试的工具，它能让你把精力集中在代码逻辑而非环境搭建上。</p>]]></description></item><item>    <title><![CDATA[从0到1落地智能家居AI交互：LLaMA Factory & Qwen3-4B 微调实战指南 Lab]]></title>    <link>https://segmentfault.com/a/1190000047551628</link>    <guid>https://segmentfault.com/a/1190000047551628</guid>    <pubDate>2026-01-19 18:09:40</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>从0到1落地智能家居AI交互：LLaMA Factory &amp; Qwen3-4B 微调实战指南</h2><p>在智能家居逐渐普及的今天，自然语言交互已成为许多家庭的控制入口。</p><p>你是否也曾遇到这样的场景：对着智能家居发出指令，它却理解错了你的意思，或是理解的不到位？</p><p>这背后其实是<a href="https://link.segmentfault.com/?enc=Q3m79TOo3OXbF1WQWMOOCw%3D%3D.2yheTfYATaWfzvGHd9x%2BmcfPYdWKtWhZQ%2F1RS7Sj%2Bk5nUOKF6NVwABBL6ebhAYZVgs%2BwmPqgPcB%2BHTZ0s5xDFg7Zlbw9xzx3zik8sqtN730Qzk1JHbRGPJ1N0K8kMesQeVRXjilJ%2B0VB5BZlaQLSxA%3D%3D" rel="nofollow" target="_blank">通用大模型</a>在垂直场景中面临的普遍困境，尽管它们具备强大的泛化能力，但在真实家居环境中，常常出现精度不足、响应延迟高、资源消耗大等问题。</p><p>尤其在边缘设备上运行，这些矛盾更加凸显。</p><p>因此，为了满足轻量级模型契合智能家居场景的基础需求，我们基于<a href="https://link.segmentfault.com/?enc=f4ot9BdrWDLEpV1YKiMYpQ%3D%3D.1VFMUSgv8MdQzC0ZN6T8EDDkC5UZLvwJ%2FzJlR1no3pvn6IVKXENVRtl%2BhJlEuyC6z4R4EIkcUTmS7WP%2FAbeK8JG9FuebS3a6pZTEdTnejmVJcjfgTieC%2FwyaFCB1L3%2FSSfHZd6G7TyP%2BNH8r%2FHMTTg%3D%3D" rel="nofollow" target="_blank">大模型实验室Lab4AI平台</a>开展了<strong>基于Qwen3-4B的智能家居轻量化模型</strong>这个项目。</p><p>该<a href="https://link.segmentfault.com/?enc=hE5ItlNc%2FvqvycsWyPhEAg%3D%3D.6v5Dv3ofPvhHkPOaiS4VrNdpxVclcuLKR8GDRH600KpdN%2BAr8AtRrOtxScmWOQ6is3xKdCvJAIgtKG9T8AgILicdngK70xgL2xlDUjZ1ElSaXp%2B%2BfyxPL2p%2FfvMxQy0nBUySmqn8Bi7HDxUI175nsQ%3D%3D" rel="nofollow" target="_blank">项目</a>针对智能家居控制任务（如设备指令解析、条件触发、复杂场景模式）构建了从数据工程到模型生产化的完整流程。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047551631" alt="" title=""/><br/>除了这个项目，<a href="https://link.segmentfault.com/?enc=alsXLzOWAXwat%2F1FSy77Ng%3D%3D.2%2FCT%2BFRGGgUYwVo40G1IxcYMulTejOX1mHporjQZrcNkbhCdL6fyaPEqfu6CodmDWPm9G4onoq47cFTBPKdnssuWepU4mjE1806a%2FmQ352g5AYLtee2o4BFuJf1CO38NJ0VfzQ%2Bjgof1pTbaQPEIvg%3D%3D" rel="nofollow" target="_blank">Lab4AI大模型实验室项目复现</a>板块还上架了许多热门案例，新用户注册，领取6.5h H800GPU体验时长，体验大模型训练、微调与推理。<br/>&lt;div align="center"&gt;<br/>  💰 扫码立即领取<br/>&lt;/div&gt;<br/>&lt;p align="center"&gt;<br/>  &lt;img src="http://llamafactory-online-assets.oss-cn-beijing.aliyuncs.com/lmlab/docs/v1.0/blog/synchronize/smart%20home%20-13.png"&gt;<br/>&lt;/p&gt;</p><h3>01 微调后效果一览</h3><p>通过在<a href="https://link.segmentfault.com/?enc=jOx7mdJ3zUR6hZZQswiz8g%3D%3D.evYTvw76QH9%2F3xxLfB%2Bpa%2BiqI6S3jGNP%2Bqx0X2OuvHIBYb3t52D%2F6KC%2Bm7p7RKe335vuC9QI0X1UbkB0LwisZTN0zdwynXXTOCPHICLvWliwzULTlX6HB3vz%2BcIVu35NVKq8EFpXJmk%2FXK%2FXaPIJAg%3D%3D" rel="nofollow" target="_blank">大模型实验室Lab4AI</a>上的一键体验，用户可以快速对比基线模型与微调后模型的效果。  <br/>下面是微调后的模型对条件触发型指令和基础控制型指令的输出解读。</p><h4>1. 场景一：条件触发型</h4><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047551632" alt="" title="" loading="lazy"/></p><h4>1. 场景二：基础控制型</h4><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047551633" alt="" title="" loading="lazy"/><br/>从两个典型场景的输出结果来看：微调后的轻量级模型在智能家居指令解析中，任务识别精准、输出结构化适配工程落地。</p><h3>02 项目实战</h3><p>本项目的复现可遵循“<strong>环境准备-数据准备-模型微调-模型推理</strong>”四步骤，流程清晰且能够一键体验。<br/>&lt;div align="center"&gt;<br/>  扫码或点击阅读原文跳转 <br/>&lt;/div&gt;<br/>&lt;p align="center"&gt;<br/>  &lt;img src="http://llamafactory-online-assets.oss-cn-beijing.aliyuncs.com/lmlab/docs/v1.0/blog/synchronize/smart%20home%20-14.png"&gt;<br/>&lt;/p&gt;</p><h4>▾ Step 1 环境准备</h4><p><a href="https://link.segmentfault.com/?enc=8TpLr4QIEFwgSw2f6g8SDw%3D%3D.l26jSwFsOkVB4Z%2BPqBSJAxyp5SZ6FzdjWDoXYhENDZAG6iZJ2J%2FwNySdKDiMMUWVYbeWU4igAyW3%2FirMFF5m9TvpCgq2xnw4fZZWNrhKvMNLVRsjC58Z5d0i8RPguYRiRdu5LyhE5u6vSGv%2FZfx3BA%3D%3D" rel="nofollow" target="_blank">大模型实验室Lab4AI</a>已经预安装了此项目需要的环境，并且存放在了 <code>env/smarthome</code> 目录下。</p><p>您无需安装依赖包，只需激活环境就可以使用。</p><p>这种“低门槛+易操作”的组合，也恰好解决了学习者不用再为环境搭建、代码调试耗费精力的烦恼。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047551634" alt="" title="" loading="lazy"/></p><h4>▾ Step 2 数据准备</h4><p>本实践选择 <strong>Smart Home Command Dataset</strong> 作为基准数据，该数据集旨在用繁体中文训练大型语言模型（LLM），用于控制智能家居系统，特别是针对家庭助理系统。</p><p>数据集包含用户输入的繁体中文，输出是结构化的 JSON 命令，代表用户控制智能家居设备的意图。</p><p>我们已经将数据集下载，并存放在了 <code>dataset</code> 文件夹下。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047551635" alt="" title="" loading="lazy"/><br/>由于数据中存在格式不规范、模糊指令、条件判断失效等现象，所以我们需要做数据处理。</p><p>(1) 统一数据格式<br/>由于 LLaMA-Factory 支持 Alpaca 格式的数据，所以我们对数据格式做了标准化。并且在“output”中补全缺失的字段“function”。</p><p>(2) 解决条件判断失效问题<br/>针对条件判断失效的问题，使用以下规则改写。</p><ul><li><p>1） 命中"instruction"中"条件+动作"的指令（如果/若/当/當/的话/的話/分钟后/分鐘後/小时后/小時候後）<br/>将"output"统一为：</p><pre><code class="json">"mcp_type": "sensor_trigger", "function": "create_automation", "params": {"trigger": {}}</code></pre></li><li><p>2） 相对时间改写（如“一小时/一小時/半小时/半小時/五分钟/五分鐘/十分钟/十分鐘/...后”）<br/><code>trigger</code> 写成：<code>{"time_after": "NhNmNs"}</code>，并支持中文数字转换。</p></li><li>一小时/一小時 → <code>"1h"</code></li><li>半小时/半小時 → <code>"30m"</code></li><li>五分钟/五分鐘 → <code>"5m"</code></li><li><p>十分钟/十分鐘 → <code>"10m"</code></p></li><li><p>3）绝对时间改写（如“十点三十分/10:30/十點半/十點十分”）</p><pre><code class="json">`trigger` 写成：`{"time": "HH:MM"}`（24小时制标准化）</code></pre></li><li><p>4） 比较条件改写（温度/湿度/PM2.5/CO₂/电量等 + 大于/小于/≥/≤/...）</p><pre><code class="json">"trigger": {"temperature" | "humidity" | "pm25" | "co2" | "battery": {"operator": "...", "value": ...}}</code></pre></li></ul><p>处理后的数据保存在了 <code>dataset/smart_home_fixed.json</code> 中。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047551636" alt="" title="" loading="lazy"/></p><h4>▾ Step 3 模型微调</h4><p>本项目采用轻量化基础模型，在垂直场景语料上进行定向微调，选择的基础模型是Qwen3-4B-Instruct-2507 。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047551637" alt="" title="" loading="lazy"/></p><h4>▾ Step 4 模型推理</h4><p>本项目使用LightLLM服务部署并执行推理。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047551638" alt="" title="" loading="lazy"/></p><h3>03 项目总结</h3><p>从两个典型场景的输出结果来看，该轻量级模型在智能家居垂直场景的指令解析能力已具备较高的工程实用价值，具体分析如下：</p><h4>1. 任务识别精准度</h4><ul><li>条件触发型场景：模型准确识别“十分钟后启动”为时间条件触发任务，通过<code>mcp_type: sensor_trigger</code>和<code>function: create_automation</code>明确任务类型，输出的<code>trigger</code>和<code>action</code>字段完整映射了延迟触发逻辑与设备动作，无语义偏差。</li><li>基础控制型场景：模型精准解析“调湿度到 3 挡”为实时参数调节任务，通过<code>mcp_type: io</code>和<code>function: set_humidity</code>区分基础控制与自动化任务，参数中设备 ID、目标值清晰明确，无需二次确认即可执行。</li></ul><h4>2. 结构化输出的工程适配性</h4><ul><li>两个场景的输出均采用标准 JSON 格式，字段定义（如<code>trigger</code>/<code>action</code>/<code>params</code>）与智能家居中控系统的接口规范高度对齐，可直接被设备控制引擎调用，无需额外格式转换。</li><li>条件触发场景中，<code>time_after: 10m</code>的时间格式、基础控制场景中<code>confirm: false</code>的交互逻辑，均符合工业级落地的细节要求。</li></ul><h4>3. 场景覆盖与泛化能力</h4><ul><li>已验证的两类场景覆盖了智能家居中的高频指令类型（基础控制 + 条件触发），且输出无关键信息缺失（如设备 ID、参数值、触发条件）。</li><li>模型对“空气净化器”这类特定设备的指令解析一致性高，未出现设备类型混淆或参数错误。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047551639" alt="" title="" loading="lazy"/></p><h4>04 给新手的秘密武器</h4><p>如果你还没接触过 LLaMA Factory 这个明星微调框架，快来看看<strong>《从零开始玩转 LLaMA Factory 大模型微调》</strong>这门课程！</p><p>随着多模态的应用场景越来越丰富，为了顺应大模型的发展需求，以及响应 LLaMA Factory 粉丝的呼声，我们在《从零开始玩转 LLaMA Factory 大模型微调》课程基础上做了重磅升级，<strong>新增多模态实战内容，但是加量不加价</strong>。</p><h4>课程亮点</h4><ul><li><strong>作者亲授</strong>：LLaMA-Factory 开源作者亲自教学，拒绝二手解读、拒绝搬运教程</li><li><strong>新增多模态实战内容</strong>：紧跟大模型发展趋势，课程全面升级！</li></ul><p>早鸟价仅 <strong>450 元</strong>，包含：</p><ul><li>✨ 价值 300 元的配套算力资源（开箱即用）</li><li>✨ 官方完课证书</li><li>✨ 独家《大模型微调实战手册》</li><li>✨ 课程期间专家答疑支持</li></ul><p>&lt;div align="center"&gt;<br/>  👉 立即抢购，锁定席位<br/>&lt;/div&gt;<br/>&lt;p align="center"&gt;<br/>  &lt;img src="http://llamafactory-online-assets.oss-cn-beijing.aliyuncs.com/lmlab/docs/v1.0/blog/synchronize/smart%20home%20-15.png"&gt;<br/>&lt;/p&gt;<br/>&lt;div align="center"&gt;<br/>  👆加课程福利官，了解详细内容<br/>&lt;/div&gt;</p>]]></description></item><item>    <title><![CDATA[“说话就能做分析” 是真是假？实测 5 大 BI 系统的 AI 数据分析能力（2026最新） 数据集]]></title>    <link>https://segmentfault.com/a/1190000047551640</link>    <guid>https://segmentfault.com/a/1190000047551640</guid>    <pubDate>2026-01-19 18:08:39</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>一、行业背景：AI-BI 正在颠覆 “业务人员做分析” 的逻辑</h2><p>根据 Gartner 2025 年《生成式 AI 在 ABI 中的应用趋势》报告，<strong>2026 年生成式 AI 在商业智能（BI）工具中的渗透率将达 75%</strong>，“自然语言交互” 将成为 BI 工具的核心功能。但现实痛点依然尖锐：IDC 2024 年《企业 BI 使用现状调研》显示，<strong>60% 的业务人员因 “需要写 SQL 或依赖 IT” 放弃深度分析</strong>，<strong>70% 的员工认为 “AI 分析结果不准”</strong>—— 比如问 “最近销量下滑的产品”，系统返回 “近 1 年销量下降的所有产品”，完全偏离 “最近”（1 个月内）的真实需求；更有 45% 的企业因 “AI 听不懂口语化表述”（比如 “华南区门店坪效最高的前三名”），导致 BI 工具利用率不足 30%。<br/>“说话就能做分析” 到底是噱头还是真需求？我们针对<strong>5 款主流 AI-BI 系统</strong>，从 “口语化理解准确率、上下文关联能力、全链路洞察深度” 三个核心维度展开实测，结果或许能给你答案。</p><h2>二、实测 5 大 AI-BI 系统：谁真的 “能听懂人话”？</h2><h3>TOP1：FineBI（综合评分：4.8/5）</h3><p><strong>产品定位</strong>：帆软旗下一站式智能自助 BI 平台，是<strong>Gartner 全球 ABI 魔力象限唯一入选中国独立 BI 厂商</strong>，IDC 报告连续八年（2017–2024）蝉联中国 BI 市场占有率第一。聚焦 “零代码 + AI 智能”，目标是 “让业务人员从‘找 IT 要数据’变成‘自己用自然语言做分析’”，覆盖从数据整合到智能洞察的全链路自助分析。<br/><strong>核心优势（实测结果）</strong>：</p><ol><li><strong>口语化理解准确率 95%，真・能听懂 “人话”</strong>：实测用 “上个月华南区门店坪效最高的前三名是哪几个？”，系统 1 秒内拆解 “时间（上个月）、区域（华南区）、指标（坪效）、维度（前三名）” 四大要素，直接返回精准结果；用模糊表述 “最近销量不好的产品” 测试，系统主动弹出提示 “你是指近 30 天销量同比下降超 20% 的产品吗？”，帮用户明确需求 —— 这是唯一通过 “模糊提问修正” 测试的工具。</li><li><strong>上下文关联能力：能 “接话” 的 AI</strong>：实测连续提问 “这个季度销售额环比增长多少？”→“那华东区呢？”，系统自动关联上一个问题的 “这个季度” 和 “销售额”，无需重复说明；甚至能理解 “指代性提问”（比如 “它的主要原因是什么？”），自动关联前一个问题的 “增长” 结果，返回 “华东区新品带动客单价提升 12%” 的结论。</li><li><strong>从 “查数” 到 “洞察” 的全链路覆盖</strong>：不仅能回答 “是什么”，还能解决 “为什么”—— 比如问 “这个季度销售额增长的原因”，系统联动 ERP 库存数据、CRM 客户行为数据，自动生成结论：“销售额增长 15%，主要因为华东区推出的‘夏季限定套餐’带动客单价提升 12%，同时库存周转天数缩短 3 天”，直接把 “数据” 变成 “可行动的 insight”。</li></ol><p><strong>适用场景</strong>：</p><ul><li>入门级：业务人员日常查数（运营问 “最近一周抖音新客转化率”、销售问 “客户复购率”）；</li><li>进阶级：自助探索分析（市场部找 “广告转化率低的原因”，联动渠道、地域、人群维度）；</li><li>精通级：跨部门协作（财务问 “CRM 客户与 ERP 库存的关联”，无需 IT 整合数据）。</li></ul><p><strong>真实案例：</strong>真功夫此前的运营分析依赖 IT 部门导出 Excel 并手动透视，查询 “上周各门店坪效 Top10” 需耗时 1-2 小时，且无法快速下钻到 “坪效高的门店对应哪些热销菜品”。使用 FineBI 后，运营人员直接通过自然语言提问：“上周华南区门店坪效最高的 5 家店是哪几个？它们的热销菜品是什么？”，系统 1 分钟内返回结果 —— 不仅列出坪效 Top5 门店，还联动菜品销售数据，自动标注 “香汁排骨饭”“香菇鸡腿饭” 是这些门店的 Top2 热销菜品。<strong>每月节省运营人员时间约 80 小时，分析效率提升 40%</strong>。</p><h3>TOP2：Qlik Sense（综合评分：4.6/5）</h3><p><strong>产品定位</strong>：全球关联式 AI-BI leader，以 “Associative Engine（关联引擎）” 为核心，适合<strong>需要 “无预处理” 关联分析</strong>的业务人员，目标是 “让数据自己‘说话’”—— 无需提前建模，直接关联所有数据关系。<br/><strong>核心优势（实测结果）</strong>：</p><ol><li><strong>关联分析：不用预处理数据</strong>：实测导入 “门店销售数据”“库存数据”“客户行为数据”，无需做数据清洗或建模，直接问 “坪效高的门店库存周转情况”，系统自动关联三者的关系，返回 “坪效前 10% 的门店库存周转天数比均值短 5 天”；</li><li><strong>AI 问数联动关联图</strong>：问 “最近销量下滑的产品”，系统不仅返回结果，还自动生成<strong>关联网络图</strong>，展示 “销量下滑→库存积压→促销活动不足” 的因果关系，帮业务人员快速定位问题；</li><li><strong>多设备适配</strong>：支持手机、平板、电脑端同步，业务人员在门店用手机问 “当前客流量”，结果同步到电脑端的仪表盘，无需重新操作。</li></ol><p><strong>适用场景</strong>：</p><ul><li>需要深度关联分析的场景（零售企业分析 “门店选址→客流量→库存周转” 的关系）；</li><li>数据类型复杂的企业（比如制造企业整合 “生产线数据”“供应链数据”“销售数据”）；</li><li>移动办公需求强的团队（比如销售外勤人员用手机查 “客户历史订单”）。</li></ul><h3>TOP3：Sisense（综合评分：4.5/5）</h3><p><strong>产品定位</strong>：云原生嵌入式 AI-BI 平台，以 “嵌入式 AI 分析 + 预测式洞察” 为核心，适合 <strong> 需要 “把 AI 分析嵌入业务系统”</strong> 的企业，目标是 “让业务人员在自己的工作流里做分析”—— 比如在 CRM 里直接问 “这个客户的复购概率”。<br/><strong>核心优势（实测结果）</strong>：</p><ol><li><strong>嵌入式 AI 问数</strong>：实测将 Sisense 嵌入某 SaaS 产品的 “客户管理页面”，业务人员点击 “AI 分析”，直接问 “这个客户的复购概率是多少？”，系统自动关联 CRM 中的 “历史订单”“互动记录”，返回 “复购概率 75%，建议推送‘老客专属折扣’”；</li><li><strong>预测式洞察</strong>：问 “未来 3 个月的库存需求”，系统用机器学习模型结合 “历史销售数据”“市场趋势”，生成预测结果，并标注 “预测误差 ±5%”；</li><li><strong>低代码定制</strong>：业务人员可通过 “拖曳组件” 定制分析模板（比如 “客户复购分析模板”），无需 IT 支持。</li></ol><p><strong>适用场景</strong>：</p><ul><li>SaaS 企业：将 AI 分析嵌入自己的产品（比如电商 SaaS 给客户提供 “销售预测” 功能）；</li><li>中大型企业：整合业务系统（比如在 ERP 里问 “当前库存周转天数”）；</li><li>需要预测的场景（零售企业预测 “节日库存需求”）。</li></ul><h3>TOP4：ThoughtSpot（综合评分：4.4/5）</h3><p><strong>产品定位</strong>：搜索式 AI-BI 开创者，以 “Google 式搜索 + AI 智能推荐” 为核心，适合 <strong> 需要 “快速查数”</strong> 的业务人员，目标是 “让分析像搜索网页一样简单”—— 全球超 2000 家企业（如沃尔玛、戴尔）在使用。<br/><strong>核心优势（实测结果）</strong>：</p><ol><li><strong>搜索式问数：速度极快</strong>：实测问 “最近一个月的订单量”，系统 0.5 秒返回结果；问 “华东区 vs 华南区的销售额对比”，直接生成柱状图，无需额外操作；</li><li><strong>AI 智能推荐</strong>：输入 “销售额”，系统自动推荐 “最近 3 个月销售额趋势”“top 5 产品销售额”“区域销售额分布” 等相关分析，帮业务人员拓展思路；</li><li><strong>实时数据支持</strong>：连接 “直播实时观众数据”，问 “当前直播的观众转化率”，1 秒返回结果，适合电商、直播等需要实时洞察的行业。</li></ol><p><strong>适用场景</strong>：</p><ul><li>快速查数需求强的团队（电商运营问 “当前直播观众转化率”、零售店长问 “今日客流量”）；</li><li>需要实时分析的行业（直播、电商、物流）；</li><li>新人上手：搜索式操作门槛极低，10 分钟学会。</li></ul><h3>TOP5：Looker（综合评分：4.3/5）</h3><p><strong>产品定位</strong>：模型驱动 AI-BI 平台，以 “LookML 语义层” 为核心，适合 <strong> 需要 “统一数据语言”</strong> 的中大型企业，目标是 “让所有业务人员用同一种逻辑分析数据”——Google 2020 年以 26 亿美元收购，现为 Google Cloud 核心 BI 产品。<br/><strong>核心优势（实测结果）</strong>：</p><ol><li><strong>语义层统一：避免 “数据歧义”</strong>：通过 LookML 定义 “销售额 = 订单金额 - 退款金额”“复购率 = 30 天内再次购买的客户数 / 总客户数”，业务人员问 “销售额” 时，系统自动用统一逻辑计算，避免 “财务算的销售额和销售算的不一样”；</li><li><strong>AI 问数联动模型</strong>：问 “这个季度销售额增长的原因”，系统联动 LookML 模型，返回 “华东区新品销售额占比 25%，带动整体增长 12%”，确保结果符合企业的 “数据语言”；</li><li><strong>企业级协作</strong>：支持 “权限分级”（比如销售只能看自己区域的数据）、“版本控制”（恢复之前的分析版本），适合万人级企业协作。</li></ol><p><strong>适用场景</strong>：</p><ul><li>中大型企业：需要统一数据逻辑（比如金融企业定义 “风险率” 的统一计算方式）；</li><li>跨部门协作：比如财务、销售、运营用同一种逻辑分析 “销售额”；</li><li>合规需求强的行业（金融、医疗）：确保数据计算符合监管要求。</li></ul><h2>三、5 大 AI-BI 系统核心能力对比表</h2><p><img width="706" height="581" referrerpolicy="no-referrer" src="/img/bVdnGvT" alt="image.png" title="image.png"/></p><h2>四、AI-BI 工具选型指南：3 步避开 “听不懂人话” 的坑</h2><h3>1. 选型三核心标准</h3><ul><li><strong>标准一：测 “口语化理解准确率”</strong>：用 3 个问题测试 ——① 具体问题（“上个月华南区门店坪效最高的前三名”）；② 模糊问题（“最近销量不好的产品”）；③ 连续问题（“这个季度销售额→华东区呢？”），能通过前两个且第三个不用重复说明的工具，才是 “能听懂人话” 的；</li><li><strong>标准二：看 “全链路能力”</strong>：不要只看 “查数”，要看能否从 “查数” 到 “洞察”（比如问 “销售额增长的原因”，能否返回因果结论）；</li><li><strong>标准三：匹配 “企业规模与场景”</strong>：中小微企业选 “零代码、易用” 的（如 FineBI）；中大型企业选 “支持协作、统一逻辑” 的（如 Looker）；需要实时分析的选 “实时数据支持” 的（如 ThoughtSpot）。</li></ul><h3>2. 首推 FineBI 的理由</h3><p>FineBI 是<strong>唯一能覆盖 “全行业 + 全规模 + 全场景” 的 AI-BI 工具</strong>：</p><ul><li>对小微型企业：零代码让业务人员 “会说话就能用”，无需 IT 支持；</li><li>对中大型企业：支持 200+ 数据源、万人级协作，统一数据逻辑；</li><li>对所有行业：有 180+ 行业模板（零售、制造、金融），15 分钟搭建系统；</li><li>对业务人员：从 “查数” 到 “洞察” 全链路覆盖，解决 “需要 SQL、结果不准、找不到原因” 三大痛点。</li></ul><h2>五、本文相关 FAQs</h2><h3>Q1：“说话就能做分析” 的 AI-BI，结果真的准吗？</h3><p>A：AI-BI 的准确性取决于两个核心：<strong>自然语言理解（NLU）能力</strong>和<strong>数据基础</strong>。首先，NLU 要能拆解 “时间、区域、指标、维度” 四大要素 —— 比如问 “最近销量不好的产品”，好的 AI 会提示 “你是指近 30 天销量同比下降超 20% 的吗？”，帮用户明确需求；其次，数据基础要 “统一、干净”—— 如果企业数据分散在 Excel、CRM、ERP 里，AI 无法关联，结果自然不准。<br/>简单来说，<strong>AI-BI 的准确性 =“能听懂人话”+“数据统一”</strong>。只要工具能解决这两个问题，结果比人工查数更准（比如 FineBI 实测准确率 95%）。</p><h3>Q2：业务人员用 AI-BI，需要学代码吗？</h3><p>A：不需要。AI-BI 的核心价值就是 “替代代码”——80% 的日常场景（比如 “最近的销售额”“客户复购率”），用自然语言提问就能解决；即使是复杂场景（比如 “坪效高的门店与库存的关系”），也只需要 “点选维度”，不用写 SQL。<br/>对业务人员来说，<strong>“会说话”=“会分析”</strong>，这才是 AI-BI 最核心的意义 —— 把 “数据的权力” 还给业务人员，不用再依赖 IT。</p><h3>Q3：AI-BI 分析数据，安全吗？</h3><p>A：AI-BI 的安全不是 “禁止使用”，而是 “在安全框架内使用”，主要通过三个手段：</p><ol><li><strong>权限管理</strong>：给不同岗位设置不同权限（比如销售只能看自己区域的数据，财务能看所有数据）；</li><li><strong>数据加密</strong>：数据传输（从数据源到工具）和存储（存在工具里）都用 AES-256 加密，即使被窃取也无法读取；</li><li><strong>本地部署</strong>：很多工具支持 “本地部署”，把数据存在企业自己的服务器里，不用上传到云端。</li></ol><p>只要做好这三点，AI-BI 的安全性比 “用 Excel 传数据” 高 10 倍 —— 毕竟，Excel 可能被转发、丢失，而 AI-BI 的数据 “只在企业内部流动”。<br/><strong>结语</strong>：“说话就能做分析” 不是噱头，而是 AI-BI 发展的必然结果。但关键是要选对工具 —— 能听懂 “人话”、能关联数据、能生成 “可行动的 insight”。FineBI 之所以成为实测 top1，正是因为它解决了业务人员的核心痛点：<strong>不用学代码、不用等 IT、不用猜结果</strong>。如果你想让业务人员 “自己做分析”，FineBI 是最稳妥的选择。</p>]]></description></item><item>    <title><![CDATA[20 周年之际！jQuery 4.0 正式发布！轻装上阵 冴羽 ]]></title>    <link>https://segmentfault.com/a/1190000047551704</link>    <guid>https://segmentfault.com/a/1190000047551704</guid>    <pubDate>2026-01-19 18:07:49</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>2006 年 1 月 14 日，John Resig 发布了名为 jQuery 的 JavaScript 库。</p><p><strong>至今已经整整过去了 20 年！</strong></p><p>你还记得第一次在项目中使用 jQuery 的场景吗？</p><p>在那个浏览器兼容性让人头疼，DOM 操作繁琐复杂的时代，jQuery 凭借着“Write less, do more”的理念，几乎是那个时代网站开发的标配。</p><p>后来，前端框架层出不穷，React、Vue、Angular 各领风骚，但 jQuery 依然在全球数百万网站上默默工作着。</p><p>如今， jQuery 4.0.0 正式版发布。</p><p>这也是 jQuery 近 10 年来的首个主要版本，标志着 jQuery 正式踏上了现代化转型之路。</p><p>让我们一起来看看 jQuery 4.0 都做了哪些更新。</p><h2>1. 彻底告别 IE</h2><p>jQuery 4.0 不再支持 IE 10 及更早版本。IE 11 预计在 5.0 版本移除。</p><p>同时也停止了一些老旧浏览器的支持，这使得 jQuery 代码更清爽，文件体积更小，性能提升显著。</p><h2>2. 安全大升级</h2><p>jQuery 4.0 引入了对 Trusted Types 的支持，jQuery 内部会自动通过 TrustedHTML 封装字符串，避免被 CSP 拦截，大大降低了网站被黑客攻击的风险。</p><h2>3. 架构现代化</h2><p>jQuery 源码从 AMD 迁移到了 ES Modules，这意味着更好的模块化开发体验，并为未来拆分功能打下基础。</p><h2>4. API 精简</h2><p>jQuery 4.0 移除了 15 个废弃的 API，这些函数要么是内部使用，要么已经有了原生的替代方案。</p><h2>5. jQuery 的全新定位</h2><p>有人可能会问：现在前端框架这么发达，jQuery 还有存在的必要吗？</p><p>答案是肯定的！</p><p><strong>jQuery 不是要重新成为前端主角，而是在它适应的场景中继续发光发热。</strong></p><h2>6. 最后</h2><p>jQuery 4.0 不是一次“重生”，而是一次<strong>面向现代 Web 的断舍离</strong>。它抛弃了历史包袱，拥抱了安全标准，清理了冗余代码，做了工程化升级。</p><p>20 年前，jQuery 改变了 Web 开发的方式；20 年后，它选择了与时俱进。</p><p>对于用过 jQuery 的老程序员来说，虽然我们已经习惯了 Vue、React 的思维模式，但看到 jQuery 的这次蜕变，依然会心潮澎湃。</p><p><strong>因为这是我们青春岁月里最美好的代码记忆。</strong></p><p>我是冴羽，10 年笔耕不辍，专注前端领域，更新了 10+ 系列、300+ 篇原创技术文章，翻译过 Svelte、Solid.js、TypeScript 文档，著有小册《Next.js 开发指南》、《Svelte 开发指南》、《Astro 实战指南》。</p><p>欢迎围观我的“<a href="https://link.segmentfault.com/?enc=Sod8qlcMVElV4AM12uefkA%3D%3D.M0k4%2FhE7MHEI1%2B9%2BhywI9YpdzVDF6K9Ppjs3NLH3n5g%3D" rel="nofollow" target="_blank">网页版朋友圈</a>”，关注我的公众号：<strong>冴羽（或搜索 yayujs）</strong>，每天分享前端知识、AI 干货。</p>]]></description></item><item>    <title><![CDATA[做淘宝图片搜索工具6年，被识图接口坑到凌晨改代码的实战手记 电商数据猿 ]]></title>    <link>https://segmentfault.com/a/1190000047551713</link>    <guid>https://segmentfault.com/a/1190000047551713</guid>    <pubDate>2026-01-19 18:06:52</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在电商工具开发圈摸爬滚打这些年，淘宝图片搜索接口（识图接口）是我见过“最挑剔”的接口没有之一。它不像商品详情、关键字接口那样逻辑直白，反而对图片格式、编码方式、参数传递有着近乎苛刻的要求，还藏着不少“权限隐藏坑”——明明签名正确却返回403，相似商品混着无关内容，大促期间突然限额缩水，每一次踩坑都得熬夜返工。</p><p>6年来，我从第一次对接时的“传图就报错”，到现在能稳定支撑日均3万次识图调用，踩过的坑涵盖了图片处理、参数解析、权限校验全流程。今天就把这些血的教训、可直接复制复用的代码全抖出来，给做同款识别、货源查找、竞品图搜的朋友避避雷，少走我当年的弯路。</p><p><strong>实例返回</strong>  测试url：[免费测试]</p><pre><code>"items": {
    "pagecount": 3,
    "total_results": 60,
    "real_total_results": 60,
    "item": [
      {
        "title": "李宁篮球袜男款专业实战短筒运动袜子女夏跑步中长精英美式毛巾底",
        "pic_url": "https://img.alicdn.com/imgextra/O1CN01i8iOpV1rZSiOwyUYE_!!2068455645.jpg",
        "promotion_price": "25.00",
        "price": "25.00",
        "num_iid": "785697155584",
        "is_tmall": "false",
        "area": "淄博",
        "detail_url": "//item.taobao.com/item.htm?id=785697155584"
      },
      {
        "title": "likeid篮球袜美式中长筒袜男夏季专业实战精英袜训练防滑运动袜子",
        "pic_url": "https://img.alicdn.com/imgextra/O1CN01tzf4lC1RMTNN4FCVw_!!623082097.jpg",
        "promotion_price": "19.90",
        "price": "19.90",
        "num_iid": "706255675043",
        "is_tmall": "false",
        "area": "佛山",
        "detail_url": "//item.taobao.com/item.htm?id=706255675043"
      },
      {
        "title": "黑人月精英专业篮球袜加厚毛巾底中筒高筒运动袜子男",
        "pic_url": "https://img.alicdn.com/imgextra/TB2luFSbTIlyKJjSZFMXXXvVXXa_!!546743164.jpg",
        "promotion_price": "12.90",
        "price": "12.90",
        "num_iid": "543839578944",
        "is_tmall": "false",
        "area": "深圳",
        "detail_url": "//item.taobao.com/item.htm?id=543839578944"
      },
      {
        "title": "李宁运动袜子男短筒专业跑步篮球羽毛球女款棉透气防臭毛巾底秋冬",
        "pic_url": "https://img.alicdn.com/imgextra/O1CN01i8iOpV1rZSiOwyUYE_!!2068455645.jpg",
        "promotion_price": "29.00",
        "price": "29.00",
        "num_iid": "751100232040",
        "is_tmall": "false",
        "area": "淄博",
        "detail_url": "//item.taobao.com/item.htm?id=751100232040"
      },
      {
        "title": "实战篮球袜精英款训练斯坦斯stance篮球袜子高筒559中筒359毛巾底",
        "pic_url": "https://img.alicdn.com/imgextra/O1CN01GJGJlc1fwZNLhfdEe_!!2215130674071.jpg",
        "promotion_price": "43.90",
        "price": "43.90",
        "num_iid": "835954755321",
        "is_tmall": "false",
        "area": "石家庄",
        "detail_url": "//item.taobao.com/item.htm?id=835954755321"
      },
      {
        "title": "袜子男防臭防脚气夏季薄款运动抑菌中筒袜吸汗毛巾底篮球袜四季fm",
        "pic_url": "https://img.alicdn.com/imgextra/O1CN01Y89HYb2KdErlFuBmQ_!!4059759579.jpg",
        "promotion_price": "20.71",
        "price": "20.71",
        "num_iid": "787279891547",
        "is_tmall": "false",
        "area": "金华",
        "detail_url": "//item.taobao.com/item.htm?id=787279891547"
      },
      {
        "title": "斗牛篮球精英袜男款高帮加厚毛巾底专业实战长筒防滑透气运动袜子",
        "pic_url": "https://img.alicdn.com/imgextra/O1CN011VQ3pa1nRthROBUCP_!!2212944505087.jpg",
        "promotion_price": "19.80",
        "price": "19.80",
        "num_iid": "751809323321",
        "is_tmall": "true",
        "area": "金华",
        "detail_url": "//item.taobao.com/item.htm?id=751809323321"
      },
      {
        "title": "包邮皇马主客场足球袜灰色白色紫色球袜毛巾底长筒过膝足球袜",
        "pic_url": "https://img.alicdn.com/imgextra/TB2kc0RbwJlpuFjSspjXXcT.pXa_!!85536437.jpg",
        "promotion_price": "16.00",
        "price": "16.00",
        "num_iid": "528042874974",
        "is_tmall": "false",
        "area": "郑州",
        "detail_url": "//item.taobao.com/item.htm?id=528042874974"
      },
      {
        "title": "科比欧文加厚专业篮球袜男中筒精英袜高帮毛巾底防滑透气吸汗防臭",
        "pic_url": "https://img.alicdn.com/imgextra/O1CN01YjiY1A1eHyLEsYqae_!!2908813847.png",
        "promotion_price": "29.90",
        "price": "29.90",
        "num_iid": "636638770741",
        "is_tmall": "true",
        "area": "广州",
        "detail_url": "//item.taobao.com/item.htm?id=636638770741"
      },
      {
        "title": "情缘  袜子男士  足球袜  运动袜  提花袜  定制袜  长筒袜男定制",
        "pic_url": "https://img.alicdn.com/imgextra/O1CN0130nTa524Rl8JXBJqz_!!0-item_pic.jpg",
        "promotion_price": "12.80",
        "price": "12.80",
        "num_iid": "845255066462",
        "is_tmall": "false",
        "area": "鹤壁",
        "detail_url": "//item.taobao.com/item.htm?id=845255066462"
      },

</code></pre><h2>一、初次翻车：Base64漏加前缀+图片超限，调试到凌晨四点</h2><p>第一次对接淘宝图片搜索接口，是帮客户做“同款货源查找工具”——用户上传商品图，工具返回淘宝上的相似款和价格。我照着文档把图片转成Base64编码，直接拼接参数发起请求，结果连续9小时返回两种错误：要么是<code>40001</code>签名错误，要么是<code>40013</code>参数无效。</p><p>翻遍淘宝开放平台文档和开发者社区，才摸清两个致命坑：</p><ol><li><strong>Base64编码必须带格式前缀</strong>：淘宝识图接口要求图片Base64串必须加上“data:image/jpeg;base64,”前缀（根据图片格式调整），我只传了纯编码串，导致接口无法识别图片类型，直接判定参数无效；</li><li>图片大小和格式有严格限制：仅支持JPG/PNG格式，单张图片大小不能超过2M，且分辨率不能低于300*300。我测试用的图是5M的PNG，虽然转了编码，但接口直接拒收，错误信息却只显示“参数无效”，完全不提示图片超限。</li></ol><p>更坑的是，识图接口的签名逻辑比商品详情接口多了“图片参数单独编码”要求——Base64串里的“+”“/”必须URL编码，否则签名计算时会被截断。那天对着官方示例反复调试，逐字符对比编码结果，终于磨出能跑通的签名和图片处理函数：</p><pre><code>import hashlib
import time
import urllib.parse
import base64
from PIL import Image
import io

def compress_image(image_bytes, max_size=2*1024*1024, min_resolution=(300, 300)):
    """
    压缩图片：适配淘宝识图接口要求（JPG/PNG，≤2M，≥300*300）
    :param image_bytes: 图片字节流
    :param max_size: 最大大小（字节）
    :param min_resolution: 最小分辨率（宽，高）
    """
    img = Image.open(io.BytesIO(image_bytes))
    # 检查分辨率
    if img.size[0] &lt; min_resolution[0] or img.size[1] &lt; min_resolution[1]:
        raise ValueError("图片分辨率过低，需≥300*300")
    # 压缩质量（逐步降低直到符合大小）
    quality = 90
    while True:
        img_byte_arr = io.BytesIO()
        img.save(img_byte_arr, format=img.format if img.format in ["JPEG", "PNG"] else "JPEG")
        img_byte_arr = img_byte_arr.getvalue()
        if len(img_byte_arr) &lt;= max_size or quality &lt;= 30:
            break
        quality -= 10
    return img_byte_arr, img.format

def generate_taobao_image_sign(params, app_secret, image_bytes=None):
    """
    生成淘宝图片搜索API签名（Base64带前缀+图片单独编码！）
    :param params: 请求参数（不含sign）
    :param app_secret: 应用密钥
    :param image_bytes: 图片字节流（用于生成Base64）
    """
    # 1. 处理图片，生成符合要求的Base64编码
    if image_bytes:
        img_bytes, img_format = compress_image(image_bytes)
        img_base64 = base64.b64encode(img_bytes).decode()
        # 必须加格式前缀，否则接口无法识别
        params["image"] = f"data:image/{img_format.lower()};base64,{img_base64}"
    
    # 2. 强制添加淘宝识图接口必传参数
    params["format"] = "json"
    params["v"] = "2.0"
    params["timestamp"] = time.strftime("%Y-%m-%d %H:%M:%S")
    params["method"] = "taobao.image.search.query"  # 识图接口固定方法名
    params["fields"] = "num_iid,title,price,similarity,image_url,shop_type"  # 显式指定返回字段
    
    # 3. 过滤sign，按参数名ASCII升序排序，图片Base64需单独URL编码
    sign_params = {}
    for k, v in params.items():
        if k != "sign":
            # 图片参数单独编码，避免特殊字符截断
            if k == "image":
                sign_params[k] = urllib.parse.quote(v, safe='')
            else:
                sign_params[k] = v
    sorted_params = sorted(sign_params.items(), key=lambda x: x[0])
    
    # 4. 拼接参数，首尾加密钥，SHA1加密转大写
    query_str = "&amp;".join([f"{k}={v}" for k, v in sorted_params])
    sign_str = f"{app_secret}{query_str}{app_secret}"
    return hashlib.sha1(sign_str.encode()).hexdigest().upper(), params

# 示例调用：上传本地图片发起识图
if __name__ == "__main__":
    app_key = "your_app_key"
    app_secret = "your_app_secret"
    # 读取本地图片为字节流
    with open("test.jpg", "rb") as f:
        image_bytes = f.read()
    # 生成签名和参数
    params = {"app_key": app_key}
    sign, final_params = generate_taobao_image_sign(params, app_secret, image_bytes)
    final_params["sign"] = sign
    print("请求参数准备完成，图片Base64前缀：", final_params["image"][:50])</code></pre>]]></description></item><item>    <title><![CDATA[京东金融鸿蒙端部署AI超分模型实践(纯干货) 京东云开发者 ]]></title>    <link>https://segmentfault.com/a/1190000047551727</link>    <guid>https://segmentfault.com/a/1190000047551727</guid>    <pubDate>2026-01-19 18:06:12</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><code>在这里插入代码片</code>作者：高阔</p><h2><strong>1. 背景</strong></h2><p><strong>这可能是全网第一篇完整讲解鸿蒙端使用CANN部署AI模型的文章, 满满干货。</strong></p><p>社区作为用户交流、信息传递的核心载体，图片内容（如理财产品截图、投资经验分享配图、用户互动评论图片等）的展示质量直接影响用户的信息获取效率与平台信任感。从京东金融App社区的业务需求来看，当前用户上传图片普遍存在多样性失真问题：部分用户通过老旧设备拍摄的图片分辨率较低，部分用户为节省流量选择低画质压缩上传，还有部分截图类内容因原始来源清晰度不足导致信息模糊（如理财产品收益率数字、合同条款细节等），这些问题不仅降低了内容可读性，还可能因信息传递不清晰引发用户误解。</p><p>京东金融App团队已完成Real-ESRGAN-General-x4v3超分辨率模型在安卓端的部署，能够针对性提升评论区、内容详情页、个人主页等核心场景的图片清晰度，从视觉体验层面优化用户留存与互动意愿。</p><p>ESRGAN-General-x4v3模型在安卓端的部署，采用的是ONNX框架，该方案已有大量公开资料可参考，且取得显著业务成效。但鸿蒙端部署面临核心技术瓶颈：鸿蒙系统不支持ONNX框架，部署端侧AI仅能使用华为自研的CANN（Compute Architecture for Neural Networks）架构，且当前行业内缺乏基于CANN部署端侧AI的公开资料与成熟方案，全程需技术团队自主探索。接下来我会以ESRGAN-General-x4v3为例, 分享从模型转换(NPU亲和性改造)到端侧离线模型部署的全部过程。</p><h2><strong>2. 部署前期准备</strong></h2><h3><strong>2.1 离线模型转换</strong></h3><p>CANN Kit当前仅支持Caffe、TensorFlow、ONNX和MindSpore模型转换为离线模型，其他格式的模型需要开发者自行转换为CANN Kit支持的模型格式。模型转换为OM离线模型，移动端AI程序直接读取离线模型进行推理。</p><h4><strong>2.1.1 下载CANN工具</strong></h4><p>从鸿蒙开发者官网下载 <a href="https://link.segmentfault.com/?enc=BZwhns6%2FmQuq%2B423bhhbnQ%3D%3D.4gGVo906sPWW5Bha2MAktdFeR65Bsu74Dt5aa0jVvk8TzmisRCiet6NoviX6lj3UICaXdDMm3pn0Hx1qWwFPJnPD%2FuJ3TpX1vwhBCdeVfp%2FUdU0HixYfB04sRhdutMYruwafva27cQ5nh1SCGf95nSDxpwxIpnLM2BjW185qzln6LcQFTGmJuJmfl66awAB9OVLHhwm%2BxNTpGnWFrrUFmZqK9E5PeOkor%2BX2g6co2Rkq11HHfkOYhgo62m1RUrAHfheSBTnjZc66pxE2BKfw0ET%2B1lKJvD%2FhYERsJjNWkahB56uhIqP7pxdmXjbj%2F10cRb%2BatkcMcfMXMeiizgXmsS8uMCdiZJIFY%2BQHhmHU%2BvAscwY2O044K2%2Bk%2FT0aWBuUIQBjSVS3Ue%2F%2FDa3viGL7fNlvUr19nugHFhEfbNnd%2BLYqrPUzs6qr8IUvczIql6Kv7H3lQsCpTtI%2FhSX8ykpCRQwqOVVUBE6pgEdRBemIAY3riwlPMK%2BFCIEsGcuF3xps" rel="nofollow" target="_blank">DDK-tools-5.1.1.1 </a>, 解压使用Tools下的OMG工具，将ONNX、TensorFlow模型转换为OM模型。(OMG工具位于Tools下载的tools/tools\_omg下，<strong>仅可运行在64位Linux平台上</strong>。)</p><p>﻿</p><h4><strong>2.1.2 下载ESRGAN-General-x4v3模型文件</strong></h4><p>从<a href="https://link.segmentfault.com/?enc=ILWZFLBgrtxsRjQQPbq%2FgQ%3D%3D.OEOurJG50cyiBHfTj4f5omGbj8fldl6t7STBf69fBbkQxMTbD9BEnZXrfFIS8bn7k7pZBPRRuyzLIRs4P6Aoq%2BSTK6eyXGp1XE%2Fu6DSqMyM%3D" rel="nofollow" target="_blank">https://aihub.qualcomm.com/compute/models/real\_esrgan\_general\_x4v3 </a>下载模型的onnx文件.</p><p>注意: 下载链接中的a8a8的量化模型使用了高通的算子(亲测无法转换), CANN工具无法进行转换, 因此请下载float的量化模型。</p><p><strong>下载后有两个文件:</strong></p><p>•model.onnx文件 (模型结构): 包含计算图、opset版本、节点配置等，文件较小。</p><p>•model.data文件 (权重数据): 包含神经网络参数、权重等，文件较大。</p><p>现在我们需要把这种分离文件格式的模型合并成一个文件,后续的操作都使用这个。</p><p><strong>合并文件:</strong></p><p>请使用JoyCode写个合并脚本即可, 提示词: 请写一个脚本, 把onnx模型文件的.onnx和.data文件合并。</p><h4><strong>2.1.3 OM模型转换</strong></h4><p><strong>1. ONNX opset 版本转换</strong></p><p>当前使用CANN进行模型转换, 支持ONNX opset版本7\~18（最高支持到V1.13.1）, 首先需要查看原始的onnx模型的opset版本是否在支持范围, 这里我们使用<a href="https://link.segmentfault.com/?enc=3u1oFIo94f8u%2BUB5npItmg%3D%3D.%2BqEzm8Wyx3wd9KwHTe23FtK2%2FTkxXIc%2Bfc6sersrWQkSjcX2yfUNQEZ0T%2FIamFHP" rel="nofollow" target="_blank">Netron</a>(点击下载)可视化工具进行查看。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047551729" alt="在这里插入图片描述" title="在这里插入图片描述"/></p><p>﻿</p><p>目前该模型使用的opset版本是20, 因此我们需要把该模型的opset版本转成18, 才可以用CANN转换成鸿蒙上可部署的模型。请使用JoyCode写个opset转换脚本即可, 提示词: 请写一个脚本, 把onnx模型文件的opset版本从20转换成18。</p><p>﻿</p><p><strong>2. OM离线模型</strong>****</p><p>命令行中的参数说明请参见<a href="https://link.segmentfault.com/?enc=s%2B%2F%2BloJjvsZH30VtSsMEuw%3D%3D.73AsP5qFGu%2FK1h23DpRobaFqIzz8p%2FUx0O8JPXxHqJd9FCDUCyz4AWQYWSK%2Bjf%2B%2BUgdd0ttC6WJtMwvQFK2KmdOnwnY4Cs%2FR6UL7X%2FLu7G%2BdkxpmlY3mJh03FVBr%2B%2Fzi" rel="nofollow" target="_blank">OMG参数</a>，转换命令：</p><pre><code>./tools/tools_omg/omg --model new_model_opset18.onnx --framework 5 --output ./model
</code></pre><p>转换完成后, 生成model.om的模型文件, 该模型文件就是鸿蒙上可以正常使用的模型文件</p><h3><strong>2.2 查看模型的输入/输出张量信息</strong></h3><p>部署AI模式时, 我们需要确认模型的输入张量和输出张量信息, 请使用JoyCode编写一个脚本, 确定输入输出张量信息, 提示词: 写一个脚本查看onnx模型的输入输出张量信息。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047551730" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h4><strong>2.2.1 输入张量</strong></h4><p>BCHW格式, 是深度学习中常见的张量维度排列格式, 在图像处理场景中:</p><p>•B (Batch): 批次大小 - 一次处理多少个样本。</p><p>•C (Channel): 通道数 - 图像的颜色通道数。</p><p>•H (Height): 高度 - 图像的像素高度。</p><p>•W (Width): 宽度 - 图像的像素宽度。</p><p>由此可以得出结论, 该模型1个批次处理1张宽高为128*128的RGB图片(因为C是3,因此不包含R通道)。</p><p>﻿</p><h4><strong>2.2.2 输出张量</strong></h4><p>该模型1个批次输出1张宽高为512*512的RGB图片。</p><p>﻿</p><h4><strong>2.2.3 BCHW和BHWC格式的区别:</strong></h4><p>超分模型中的BCHW和BHWC是两种不同的张量存储格式，主要区别在于通道维度的位置：</p><p>﻿</p><p>•<strong>BCHW格式（Batch-Channel-Height-Width）</strong></p><p>◦维度顺序：[批次, 通道, 高度, 宽度]</p><p>◦内存布局：通道维度在空间维度之前</p><p>◦常用框架：PyTorch、TensorRT等</p><p>示例: 形状为 (1, 3, 256, 256) 的RGB图像</p><p><strong>内存中的存储顺序：</strong> R通道的所有像素 -&gt; G通道的所有像素 -&gt; B通道的所有像素</p><pre><code>tensor_bchw = torch.randn(1, 3, 256, 256)
访问第一个像素的RGB值需要跨越不同的内存区域
pixel_0_0_r = tensor_bchw[0, 0, 0, 0]  # R通道
pixel_0_0_g = tensor_bchw[0, 1, 0, 0]  # G通道  
pixel_0_0_b = tensor_bchw[0, 2, 0, 0]  # B通道
</code></pre><p>•<strong>BHWC格式（Batch-Height-Width-Channel）</strong></p><p>◦维度顺序：[批次, 高度, 宽度, 通道]</p><p>◦内存布局：通道维度在最后，像素的所有通道连续存储</p><p>◦常用框架：TensorFlow、OpenCV等</p><p>示例：形状为 (1, 256, 256, 3) 的RGB图像</p><p>内存中的存储顺序：像素(0,0)的RGB -&gt; 像素(0,1)的RGB -&gt; ... -&gt; 像素(0,255)的RGB -&gt; 像素(1,0)的RGB...</p><pre><code>tensor_bhwc = tf.random.normal([1, 256, 256, 3])
# 访问第一个像素的RGB值在连续的内存位置
pixel_0_0_rgb = tensor_bhwc[0, 0, 0, :]  # [R, G, B]
</code></pre><p>﻿</p><h2><strong>3. 鸿蒙端部署核心步骤</strong></h2><h3><strong>3.1 创建项目</strong></h3><p>1.创建DevEco Studio项目，选择“Native C++”模板，点击“Next”。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047551731" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><p>﻿</p><p>2.按需填写“Project name”、“Save location”和“Module name”，选择“Compile SDK”为“5.1.0(18)”及以上版本，点击“Finish”。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047551732" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h3><strong>3.2 配置项目NAPI</strong></h3><p>CANN部署只提供了C++接口, 因此需要使用NAPI, 编译HAP时，NAPI层的so需要编译依赖NDK中的libneural\_network\_core.so和libhiai\_foundation.so。</p><p>﻿</p><p><strong>头文件引用</strong></p><p>按需引用NNCore和CANN Kit的头文件。</p><pre><code>#include "neural_network_runtime/neural_network_core.h"
#include "CANNKit/hiai_options.h"
</code></pre><p><strong>编写CMakeLists.txt</strong></p><p>CMakeLists.txt示例代码如下。</p><pre><code>cmake_minimum_required(VERSION 3.5.0)
project(myNpmLib)

set(NATIVERENDER_ROOT_PATH ${CMAKE_CURRENT_SOURCE_DIR})

include_directories(${NATIVERENDER_ROOT_PATH}
                    ${NATIVERENDER_ROOT_PATH}/include)

include_directories(${HMOS_SDK_NATIVE}/sysroot/usr/lib)
FIND_LIBRARY(cann-lib hiai_foundation)

add_library(imagesr SHARED HIAIModelManager.cpp ImageSuperResolution.cpp)
target_link_libraries(imagesr PUBLIC libace_napi.z.so
    libhilog_ndk.z.so
    librawfile.z.so
    ${cann-lib}
    libneural_network_core.so
    )
</code></pre><h3><strong>3.3 集成模型</strong></h3><p>模型的加载、编译和推理主要是在native层实现，应用层主要作为数据传递和展示作用。模型推理之前需要对输入数据进行预处理以匹配模型的输入，同样对于模型的输出也需要做处理获取自己期望的结果</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047551733" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h4><strong>3.3.1 加载离线模型</strong></h4><p>为了让App运行时能够读取到模型文件和处理推理结果，需要先把离线模型和模型对应的结果标签文件预置到工程的“entry/src/main/resources/rawfile”目录中。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047551734" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><p>﻿</p><p>在App应用创建时加载模型:</p><p>1.native层读取模型的buffer。</p><pre><code>const char* modelPath = "imagesr.om";
RawFile *rawFile = OH_ResourceManager_OpenRawFile(resourceMgr, modelPath);
long modelSize = OH_ResourceManager_GetRawFileSize(rawFile);
std::unique_ptr&lt;uint8_t[]&gt; modelData = std::make_unique&lt;uint8_t[]&gt;(modelSize);
int res = OH_ResourceManager_ReadRawFile(rawFile, modelData.get(), modelSize);
</code></pre><p>2.使用模型的buffer, 调用OH\_NNCompilation\_ConstructWithOfflineModelBuffer创建模型的编译实例</p><pre><code>HiAI_Compatibility compibility = HMS_HiAICompatibility_CheckFromBuffer(modelData, modelSize);
OH_NNCompilation *compilation = OH_NNCompilation_ConstructWithOfflineModelBuffer(modelData, modelSize);
</code></pre><p>3.（可选）根据需要调用HMS\_HiAIOptions\_SetOmOptions接口，打开维测功能（如Profiling）。</p><pre><code>const char *out_path = "/data/storage/el2/base/haps/entry/files";
HiAI_OmType omType = HIAI_OM_TYPE_PROFILING;
OH_NN_ReturnCode ret = HMS_HiAIOptions_SetOmOptions(compilation, omType, out_path);     
</code></pre><p>4.设置模型的deviceID。</p><pre><code>size_t deviceID = 0;
const size_t *allDevicesID = nullptr;
uint32_t deviceCount = 0;
OH_NN_ReturnCode ret = OH_NNDevice_GetAllDevicesID(&amp;allDevicesID, &amp;deviceCount);

for (uint32_t i = 0; i &lt; deviceCount; i++) {
    const char *name = nullptr;
    ret = OH_NNDevice_GetName(allDevicesID[i], &amp;name);
    if (ret != OH_NN_SUCCESS || name == nullptr) {
        OH_LOG_ERROR(LOG_APP, "OH_NNDevice_GetName failed");
        return deviceID;
    }
    if (std::string(name) == "HIAI_F") {
        deviceID = allDevicesID[i];
        break;
    }
}

ret = OH_NNCompilation_SetDevice(compilation, deviceID);
</code></pre><p>5.调用OH\_NNCompilation\_Build，执行模型编译。</p><pre><code>ret = SetModelBuildOptions(compilation);
ret = OH_NNCompilation_Build(compilation);
</code></pre><p>6.调用OH\_NNExecutor\_Construct，创建模型执行器。</p><pre><code>executor_ = OH_NNExecutor_Construct(compilation);
</code></pre><p>7.调用OH\_NNCompilation\_Destroy，释放模型编译实例。</p><p>﻿</p><h4><strong>3.3.2 准备输入输出****Tensor</strong></h4><p>1.处理模型的输入，模型的输入为1<em>3</em>128*128格式(BCHW) Float类型的数据, 需要把RGB 数据转成BCHW格式并进行归一化。</p><pre><code>从图片中读取的RGB数据为BHWC,需要转换成模型可以识别的BCHW
/**
 * 把bhwc转成bchw
 */
uint8_t *rgbData = static_cast&lt;uint8_t*&gt;(data);
uint8_t *floatData_tmp = new uint8_t[length];
for (int c = 0; c &lt; 3; ++c) {
    for (int h = 0; h &lt; 128; ++h) {
        for (int w = 0; w &lt; 128; ++w) {
            // HWC 索引: h * width * channels + w * channels +c 
            int hwc_index = h * 128 * 3 + w * 3 + c;
            // CHW 索引: C * height * width + h* width + W
            int chw_index = c * 128 * 128 + h * 128 + w;
            floatData_tmp[chw_index] = rgbData[hwc_index];
        }
    }
}
//归一化
float *floatData = new float[length];
for (size_t i = 0; i &lt; length; ++i) {
    floatData[i] = static_cast&lt;float&gt;(floatData_tmp[i])/ 255.0f;
}
</code></pre><p>2.创建模型的输入和输出Tensor，并把应用层传递的数据填充到输入的Tensor中</p><pre><code>// 准备输入张量
size_t inputCount = 0;
OH_NN_ReturnCode ret = OH_NNExecutor_GetInputCount(executor_, &amp;inputCount);
for (size_t i = 0; i &lt; inputCount; ++i) {
    NN_TensorDesc *tensorDesc = OH_NNExecutor_CreateInputTensorDesc(executor_, i);
    NN_Tensor *tensor = OH_NNTensor_Create(deviceID_, tensorDesc);
    if (tensor != nullptr) {
        inputTensors_.push_back(tensor);
    }
    OH_NNTensorDesc_Destroy(&amp;tensorDesc);
}


ret = SetInputTensorData(inputTensors_, inputData);

// 准备输出张量
size_t outputCount = 0;
ret = OH_NNExecutor_GetOutputCount(executor_, &amp;outputCount);

for (size_t i = 0; i &lt; outputCount; i++) {
    NN_TensorDesc *tensorDesc = OH_NNExecutor_CreateOutputTensorDesc(executor_, i);
    NN_Tensor *tensor = OH_NNTensor_Create(deviceID_, tensorDesc);
    if (tensor != nullptr) {
        outputTensors_.push_back(tensor);
    }
    OH_NNTensorDesc_Destroy(&amp;tensorDesc);
}
if (outputTensors_.size() != outputCount) {
    DestroyTensors(inputTensors_);
    DestroyTensors(outputTensors_);
    OH_LOG_ERROR(LOG_APP, "output size mismatch.");
    return OH_NN_FAILED;
}
</code></pre><p>﻿</p><h4><strong>3.3.3 进行推理</strong></h4><p>调用OH\_NNExecutor\_RunSync，完成模型的同步推理。</p><pre><code>OH_NN_ReturnCode ret = OH_NNExecutor_RunSync(executor_, inputTensors_.data(), inputTensors_.size(),
                                                 outputTensors_.data(), outputTensors_.size());
</code></pre><p>说明</p><p>•如果不更换模型，则首次编译加载完成后可多次推理，即一次编译加载，多次推理。</p><p>•所有关于模型的操作, 均无法多线程执行。</p><p>﻿</p><h4><strong>3.3.4 获取模型输出并处理数据</strong></h4><p>1.调用OH\_NNTensor\_GetDataBuffer，获取输出的Tensor，在输出Tensor中会得到模型的输出数据。</p><pre><code>// 获取第一个输出张量
NN_Tensor* tensor = outputTensors_[0];

// 获取张量数据缓冲区
void *tensorData = OH_NNTensor_GetDataBuffer(tensor);

// 获取张量大小
size_t size = 0;
OH_NN_ReturnCode ret = OH_NNTensor_GetSize(tensor, &amp;size);

float *tensorDataOutput = (float*)malloc(size);
// 将tensorData的数据一次性复制到tensorDataOutput中
memcpy(tensorDataOutput, tensorData, size);
</code></pre><p>﻿</p><p>2.对Tensor输出数据进行相应的处理</p><p>把模型输出的BCHW转成BHWC, 并进行反归一化处理</p><p>﻿</p><pre><code>//把模型输出的BCHW转成BHWC
float *outputResult = static_cast&lt;float *&gt;(tensorData);
float *output_tmp = new float[size/sizeof(float)];
for (int h = 0; h &lt; 512; ++h) {
    for (int w = 0; w &lt; 512; ++w) {
        for (int c = 0; c &lt; 3; ++c) {
            output_tmp[h * 512 * 3 + w* 3 + c] = outputResult[c * 512 * 512 + h * 512 + w];
        }
    }
}
std::vector&lt;float&gt; output(size / sizeof(float), 0.0);
for (size_t i = 0; i &lt; size / sizeof(float); ++i) {
    output[i] = output_tmp[i];
}
delete [] output_tmp;


 // 计算总的数据大小
size_t totalSize = output.size();

// 分配结果数据内存
std::unique_ptr&lt;uint8_t[]&gt; result_data = std::make_unique&lt;uint8_t[]&gt;(totalSize);

// 将float数据转换为uint8_t (反归一化)
size_t index = 0;
for (float value : result) {
    // 将float值转换为uint8_t (0-255范围)
    float scaledValue = value * 255.0f;
    scaledValue = std::max(0.0f, std::min(255.0f, scaledValue));
    result_data[index++] = static_cast&lt;uint8_t&gt;(scaledValue);
}

result_data 就是最终的超分数据,可以正常显示
</code></pre><p>﻿</p><h2><strong>4. 总结与技术展望</strong></h2><p>京东金融App在鸿蒙端部署Real-ESRGAN-General-x4v3超分辨率模型的完整实践过程，成功解决了ONNX模型到OM离线模型转换、BCHW与BHWC张量格式处理、以及基于CANN Kit和NAPI的完整部署链路等关键技术难题。</p><p>展望端智能的未来发展，随着芯片算力的指数级增长、模型压缩技术的突破性进展以及边缘计算架构的日趋成熟，端侧设备将从单纯的数据采集终端演进为具备强大推理能力的智能计算节点，通过实现多模态AI融合、实时个性化学习、隐私保护计算和跨设备协同等核心能力，将大语言模型、计算机视觉、语音识别等AI技术深度集成到移动设备中，构建起无需联网即可提供智能服务的自主计算生态，推动人机交互从被动响应向主动感知、预测和服务的范式转变，最终开启真正意义上的普惠人工智能时代。</p>]]></description></item><item>    <title><![CDATA[告别手动搬砖： JoyCode + i18n-mcp 实现前端项目多语言自动化 京东云开发者 ]]></title>    <link>https://segmentfault.com/a/1190000047551735</link>    <guid>https://segmentfault.com/a/1190000047551735</guid>    <pubDate>2026-01-19 18:05:40</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>作者：王元</p><h2>1. 背景与痛点：存量代码的“多语言噩梦”</h2><p>在前端开发中，将一个成熟的中文存量项目进行国际化多语言（i18n）改造，往往面临着以下困境：</p><p>•工作量巨大： 项目包含数百个 <code>.vue/.js/.ts</code> 等文件，散落着成千上万个硬编码的中文字符串。</p><p>•人工易错： 手动提取容易遗漏，且极其枯燥，极易产生 <code>Copy/Paste</code> 错误。</p><p>•命名困难： 为每一个中文词条想一个语义化的英文 Key（如 <code>homePageTitle</code>）不仅耗时，而且难以保证团队风格统一。</p><p>•维护成本高： 翻译文件（zh.ts/en.ts）的维护和代码中的替换需要同步进行，稍有不慎就会导致报错。</p><p>如果按照传统的人工查找替换方式，预计需要耗费数周的人力。为了打破这一僵局，我决定利用 JoyCode 结合我开发的 i18n-mcp 工具，打造一套自动化的国际化多语言解决方案。</p><p>﻿</p><h2>2. 解决方案：JoyCode + i18n-mcp</h2><p>我基于 MCP (Model Context Protocol) 开发了一个工具 <code>i18n-mcp</code>，通过 JoyCode 的 AI 能力来调度和执行以下三个核心步骤，实现了从“提取”到“替换”的全链路自动化。</p><h3>流程图</h3><p>以下是i18n-mcp的流程图（由JoyCode生成）</p><p>﻿<img referrerpolicy="no-referrer" src="/img/remote/1460000047551737" alt="在这里插入图片描述" title="在这里插入图片描述"/></p><h3>核心流程拆解</h3><h4>第一步：智能提取中文与去重</h4><p><code>i18n-mcp</code> 自动扫描所有源文件。利用正则或 AST（抽象语法树）精准识别代码中的中文字符串（包括 Template、Script 和 JSX 部分）。</p><p>•全量扫描（<code>full-project-scan</code>工具）： 文件过多的时候，全量扫描会有问题。可以通过指定文件夹的方式，扫描该文件夹下面的文件。</p><p>•增量扫描（<code>git-change</code>工具）：针对git变更的文件，进行扫描。精准定位变更文件，仅处理本次变更涉及的代码，大幅提升效率。</p><p>•智能去重： 对提取出的文本进行去重，确保相同的中文文案（如“确认”、“取消”）只生成一个 Key，避免冗余。</p><h4>第二步：AI 辅助翻译与文件生成</h4><p>•翻译缓存： 优先查询 <code>数据存储层</code> 中的 <code>Translation Cache</code>，已翻译过的文案直接复用，显著降低 Token 消耗并加速流程。</p><p>•自动化翻译： 提取的中文列表没有在缓存中或zh文件中的，被发送给 LLM，自动翻译成英文。</p><p>•语义化 Key 生成： 区别于传统 Hash 值，LLM 根据代码上下文（Context）自动生成符合语义的 Key（如将“请输入密码”生成为 <code>pleaseInputPassword</code>），提升代码可读性。</p><p>•文件落地： 自动在 <code>lang</code> 文件夹下生成标准的 <code>zh.ts</code> 和 <code>en.ts</code> 文件。</p><p>﻿</p><blockquote>生成示例： <code>zh.ts</code>: <code>{ "pleaseSelect": "请选择" }</code> <code>en.ts</code>: <code>{ "pleaseSelect": "Please Select" }</code></blockquote><p>﻿</p><p>﻿</p><h4>第三步：一键代码替换</h4><p>•变更预览 (Preview)： 在实际修改前，可调用 <code>preview-changes</code> 工具展示即将变更的代码对比，确保修改符合预期。</p><p>•AST 节点替换： 使用 <code>extract-and-replace</code> 工具，将源代码中的硬编码字符串精准替换为国际化方法（如 <code>$t('pleaseSelect')</code>）。</p><p>•无损格式保持： 基于 AST 的替换策略能够完美保留原代码的缩进、换行和注释，修改后的代码无需二次 Lint 即可直接提交。</p><p>﻿</p><p>﻿</p><h2>3. 成果与收益：从“数周”到“数小时”</h2><p>通过引入 JoyCode + i18n-mcp 的实践，我在项目的国际化改造中取得了显著的成效：</p><h3>📊 定量收益</h3><table><thead><tr><th><strong>维度</strong></th><th><strong>传统人工方式</strong></th><th><strong>JoyCode + i18n-mcp</strong></th><th><strong>提升幅度</strong></th></tr></thead><tbody><tr><td>单页面改造耗时</td><td>约 10-30 分钟</td><td>&lt; 1 分钟</td><td>效率提升 90%+</td></tr><tr><td>词条遗漏率</td><td>高</td><td>低</td><td>质量显著提升</td></tr><tr><td>变量命名耗时</td><td>需人工构思</td><td>AI 秒级生成</td><td>完全自动化</td></tr></tbody></table><h3>💡 定性收益</h3><p>1.解放生产力： 从枯燥的“搬运工”工作中解脱出来，可以专注于业务逻辑和核心功能的开发。</p><p>2.代码规范统一： AI 生成的 Key 风格高度统一（全驼峰），避免了“千人千面”的命名混乱。</p><p>3.可维护性增强： 建立了自动化的语言包管理机制，后续新增词条只需运行脚本即可。</p><p>﻿</p><h2>4. i18n-mcp开发</h2><p>i18n-mcp是我首次开发MCP，整体难度相对较低。对于前端部分，基于<a href="https://link.segmentfault.com/?enc=FXJqXdzoRBhUzJMzNkYB5Q%3D%3D.kMNE8XPp1gG0XaqnZU3fiBZHUZ7nKx6J6VjACOQyk9QoK8B1kiphh5qHf5fHo9OPMQ7%2Fqd34CFOAJkNYhlE%2FsUGafkGXlvsvCP%2FsbT7XoelhDbZPjEgJ34%2Bm%2BuYku%2Fnixlnk%2BbJR4B8SzEqScn%2BWdA%3D%3D" rel="nofollow" target="_blank">github模板</a>进行开发，随后发布至公司NPM私服即可。</p><p>核心代码主要由JoyCode的编码功能协助完成。按照上述核心流程步骤通过问答交互的方式，引导JoyCode完成核心代码的开发工作。</p><p>整个i18n-mcp架构图如下所示（架构图亦由JoyCode生成）。</p><p>﻿<img referrerpolicy="no-referrer" src="/img/remote/1460000047551738" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><p>﻿</p><p>MCP配置如下</p><pre><code>{
  "mcpServers": {
    "i18n-mcp": {
      "autoApprove": [],
      "disabled": true,
      "timeout": 180,
      "command": "npx",
      "type": "stdio",
      "transportType": "stdio",
      "args": [
        "-y",
        "@jd/i18n-mcp@latest"
      ],
      "env": {}
    }
  }
}
</code></pre><h3>效果</h3><p>配置之后，输入prompt “调用i18n-mcp的auto-i18n-process方法”</p><p>效果如下：</p><p>﻿<img referrerpolicy="no-referrer" src="/img/remote/1460000047551739" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h2>5. 总结</h2><p>尽管目前 i18n-mcp 仍存在一些不足，例如在全面扫描大量文件时可能出现连接错误、翻译和替换结果不够准确等问题，仍需人工进行二次校验，但其在短时间内辅助开发的价值依然显著。在本次实践过程中，我主要通过 JoyCode 的交互式问答完成开发工作。JoyCode 不仅在代码补全方面发挥了重要作用，更凭借其强大的智能调度和自动化执行能力，成为高效处理复杂任务的核心中枢。结合 i18n-mcp 的开发，AI技术的深度赋能得以充分体现，大幅提升了开发的效率。</p><p>后续，我将持续研究 AI 在前端开发中的落地场景，充分发挥 AI 辅助开发的强大能力。通过深入探索和应用 AI 技术，进一步释放其在业务创新与效率提升方面的巨大潜力。</p>]]></description></item><item>    <title><![CDATA[设计不止于界面-AI引领的“Design to Code”时代 京东云开发者 ]]></title>    <link>https://segmentfault.com/a/1190000047551744</link>    <guid>https://segmentfault.com/a/1190000047551744</guid>    <pubDate>2026-01-19 18:04:54</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>作者：桑伟杰</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047551746" alt="在这里插入图片描述" title="在这里插入图片描述"/></p><h2><strong>一、背景</strong></h2><p>当前在传统设计环节，设计师与研发之间存在大量的关于样式等视觉层的理解偏差，从而会出现大量的重复且无效的细节像素调整工作，由于项目时间紧、细节多设计走查环节会给各方角色诸多额外负担，在AI涌现后设计师尝试使用AI\_Code直接还原设计稿件，并且从传统交付静态界面设计图片转为交付可运行的实现方案，但在多数团队的认知里，AI\_Code仍停留在“氛围编程”阶段：能写出代码，但不符合框架规范，改动越多问题越多。通过不断摸索总结出一套稳定可用的 <strong>Design to Code (D2C)</strong> 解法：设计师借助 AI - IDE工具以及设计工具，通过MCP打通设计数据与研发数据，实现将设计稿直接转译为<strong>符合开发规范、可上线的前端代码</strong>，极大缩短交付周期。</p><p>D2C核心效果：设计师第一次拥有了对实现效果的“直接控制权”工程师从繁琐的像素级样式修改中解放出来团队整体迭代速度大幅提升</p><p>﻿<img referrerpolicy="no-referrer" src="/img/remote/1460000047551747" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><p>传统链路VSD2C链路</p><h2><strong>二、效果展示</strong></h2><h4>案例1：PC端\_WMS6.0工艺配置</h4><p>通过D2C流程从【组件生成】→【页面生成】，完成PC端工艺流程配置功能代码输出，实现了卡片拖拽、卡片状态自动变更、放置位置判断等核心功能；实现项目完整交付在测试环境中可直接运行，研发无需对前端代码进行修改，D2C代码输出总耗时0.5人/日，项目整体效率提升26%</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047551748" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><p>WMS6.0\_Vue2.0实现效果</p><h4>案例2：移动端\_PDA上架到容器</h4><p>通过D2C流程链接设计数据与研发数据，【直接调用研发组件库代码】，按照代码仓库标准代码输出规范的前端页面，实现多页面跳转，逻辑判断，查询等核心功能，达到像素级还原并符合团队规范。D2C代码输出总耗时0.5人/日，项目整体效率提升50%</p><p>﻿<img referrerpolicy="no-referrer" src="/img/remote/1460000047551749" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><p>PDA\_Flutter实现效果</p><h2><strong>三、设计思维转变</strong></h2><p>D2C 并非“让设计师写代码”，而是促使设计师提升工程化思维：使设计师从传统的设计界面转向当前的设计容器，从而更好的让AI能够读懂设计数据实现D2C流程</p><p>﻿</p><p>传统设计思维 ➔ 工程化思维</p><h4>传统设计思维：</h4><p>步骤：1.设计全部视觉元素 ➔ 2.在页面进行元素相对位置的排布 ➔ 3.完成设计内容的产出</p><p>特点：元素之间仅包含相对关系没有结构层的动态属性，与页面实现的框架不一致</p><h4>工程化思维：</h4><p>步骤：1.设计组织分层关系 ➔ 2.设计分层容器布局规则 ➔ 3.设计容器所需设计元素 ➔ 4.完成设计内容的产出</p><p>特点：先有组织容器再有容器内容，组织容器具备布局规则等动态属性，更符合页面实现的框架。</p><h2><strong>四、实现路径</strong></h2><p>D2C的核心方法：D2C的核心法则是在保证幻觉与Token限制的条件下，通过稳定与可靠的方法，尽量多的将设计数据与研发数据进行链接，让AI充分理解两端数据并完成翻译</p><p>﻿<img referrerpolicy="no-referrer" src="/img/remote/1460000047551750" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><p>优劣势对比</p><h4>稳定的D2C链接方法：</h4><p>通过Figma MCP获取全部设计数据，包括颜色、圆角、间距、图层名称、文本信息、图片资源、代码数据、页面截图；将设计数据传递给AI-IDE工具，通过rules和Prompt控制设计数据解析标准，规定AI按照解析结果与代码数据对应，实现代码输出优势：即有设计元属性，又包含截图以及基础代码信息，AI可以更好的关联研发数据实现完美还原</p><p>并且针对不同页面构成，总结并执行不同的D2C步骤，用于还原设计内容，由于D2C的核心是链接，所以重点在于如何制造稳定链接，我们可以通过Code Connect或者让AI通过图层命名检索的方式实现稳定链接</p><p>﻿<img referrerpolicy="no-referrer" src="/img/remote/1460000047551751" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><p>D2C设计流程图</p><h5>针对已有组件：</h5><p>逻辑：通过调整设计组件名称与变体与研发组件名称和属性建立映射链接</p><p>步骤：提供界面截图 ➔ 工程师维护组件映射表 ➔ 设计师调整设计组件与研发组件结构一致 ➔ 还原页面内容</p><p>重点：工程师维护的<strong>组件映射表</strong>需包含组件名称及组件属性，设计师需保持设计组件与研发组件的结构相同</p><p>案例：<a href="https://link.segmentfault.com/?enc=z%2F7ftusa8Cp9kqyq%2FNCXZg%3D%3D.D6tRBGObpD5TWIjrnkxnC8De5w9YTP6uKFw4AtKScLirDjLU0hB4mAQyGgitAd%2B%2FVJjtBRXfTAG4tK2blqSITg%3D%3D" rel="nofollow" target="_blank">PDADesign组件映射表</a>﻿</p><h5>针对无组件场景：</h5><p>逻辑：按照设计组件的名称与结构按照研发代码编写规则输出组件建立映射链接</p><p>步骤：设计师需采用<strong>工程化思维</strong>绘制组件 ➔ AI阅读代码仓库组件书写规范 ➔ 按照规范将设计组件输出为研发组件 ➔ 通过MCP获取设计组件并关联已经转为代码的研发组件</p><p>重点：与工程师对齐结构规范，若仓库中有Token数据再设计组件绘制时也需要保持一致</p><p>﻿</p><h2><strong>五、结语</strong></h2><p>D2C 是一次 团队角色和流程的升级，更是一场认知的跃迁：设计师不再只是交付界面，而是交付“可运行的实现方案”AI 成为设计师和工程师之间的“实时翻译器”最终实现：更快迭代、更少摩擦、更强共创。</p><p>在这条由 AI 驱动的设计到代码之路上，设计师不再是单纯的界面构建者，而是系统规则的定义者、智能逻辑的编织者。他们与 AI 一起，共同塑造一个能“理解意图、自动生成、持续学习”的设计生态。</p><p>当设计稿不再停留于视觉表达，而成为可以被机器直接理解的语言，设计师便跨越了传统的边界——从视觉思考者，走向了系统架构的参与者；从界面呈现者，走向了智能生产力的创造者。</p><p>AI 不会取代设计师，但会放大他们的思考维度，让人类的创造力从重复劳动中解放出来，去关注更本质的价值：如何让设计更智能、更高效、更具生命力。 在未来，D2C 不仅是“设计到代码”的捷径，更是“人机共创”的起点—— 让每一位设计师，都能成为 AI 时代的工程合作者，让设计真正成为推动产品智能演化的核心力量。</p>]]></description></item><item>    <title><![CDATA[【场景：识别C2通信】评估出站IP是否为已知恶意地址，方法：IP离线库+威胁情报融合 香椿烤地瓜 ]]></title>    <link>https://segmentfault.com/a/1190000047551776</link>    <guid>https://segmentfault.com/a/1190000047551776</guid>    <pubDate>2026-01-19 18:04:17</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>最近项目组做了一次安全项目，在联动讨论中，我们团队提出攻克一个一直被“模糊处理”的问题：如何在不引入复杂流量解密、不严重影响性能的前提下，更可靠地识别潜在的 C2通信行为。</p><p>其实在我看来这个问题并不新，在往常的项目中异常端口、可疑域名、频繁外联、策略命中日志等检测点都是这个问题。而这些信号单独存在时，误报率高，且很难形成可执行的处置结论。而本次讨论的关键转折点，正是在“出站 IP 本身是否具备明确恶意属性”这一角度上。</p><h3><strong>一、从“流量行为”转向“通信对象本身”的判断</strong></h3><p>在复盘既往处置案例时，阿孙提到一个共性：多数被确认为C2 的样本不是因为流量形态极其复杂，而是<strong>其通信目标本身就具备明显的基础设施风险特征</strong>，比如位于高风险国家或地区、IP 段频繁出现在僵尸网络、钓鱼、木马回连情报中、长期驻留在 VPS/云主机/异常 ASN、多项目/多情报源重复命中等</p><p>但这些信息在现有体系中是割裂的，地理信息在 IP 归属系统中，恶意标签在威胁情报平台中，而F火墙/EDR却只能看到“一个外联IP”，由此，我门讨论是否可以多采用IP离线库植入威胁情报，手动拓宽我们的“威胁情报”，提出这正是我们提出使用IP离线库和威胁情报进行融合。</p><h3><strong>二、</strong> <strong>为什么必须引入 IP 离线库，而不是完全依赖情报 API</strong></h3><p>最初也有人提出直接调用在线威胁情报 API 即可，但在技术评估阶段，很快暴露出几个不可回避的问题：</p><p><strong>1.</strong> <strong>出站连接频率高，实时 API 成本与延迟不可控</strong>  <br/>在核心业务网段，单节点每天的外联 IP 数量级在百万级，实时查询并不可行。</p><p><strong>2.</strong> <strong>部分安全系统处于内网或半隔离环境</strong>  <br/>核心日志分析、审计系统无法直接访问外部情报接口。</p><p><strong>3.</strong> <strong>IP 基础属性缺失会削弱判断上下文</strong>  <br/>单一“是否恶意”的结论，无法解释风险来源，例如：</p><p>1. 这是一个海外 IDC 正常业务 IP？</p><p>2. 还是位于高风险区域的小型自治系统？</p><p>3. 是否属于动态拨号或代理出口？</p><p>因此，我们的思路是<strong>先通过本地 IP 离线库快速完成“背景定性”，再用威胁情报完成“恶意定量”</strong>  。</p><h3><strong>三、</strong> <strong>IP离线库在 C2 识别中的实际定位</strong></h3><p>在方案中，IP 离线库并不直接承担“是否 C2”的判断，而是用于回答以下关键问题：</p><p>1. 该出站 IP 的国家/地区/城市是否与业务场景匹配</p><p>2. 是否命中云厂商、数据中心、匿名网络、异常 ASN</p><p>3. 是否存在明显的跨国、跨区域跳变特征</p><p>4. 是否属于历史上极少访问、但突然频繁出现的地理位置</p><p>在我们实际部署中，使用的是IP数据云离线库，它覆盖IPv4/IPv6的本地IP 离线库，字段不仅包括国家、省市，还包含 ASN、运营商类型、IDC/住宅网络标识，方便后续识别C2通信，评估出站IP是否为已知恶意地址。<br/><img width="723" height="386" referrerpolicy="no-referrer" src="/img/bVdnGxb" alt="【场景：识别C2通信】评估出站IP是否为已知恶意地址，方法：IP离线库+威胁情报融合2.png" title="【场景：识别C2通信】评估出站IP是否为已知恶意地址，方法：IP离线库+威胁情报融合2.png"/></p><h3><strong>四、</strong> <strong>威胁情报融合的方式，而非简单“命中即拦截”</strong></h3><p>第二层才是威胁情报，但这里我们刻意避免了“黑名单式”的粗暴使用方式。</p><p>具体做法是：</p><p>第一步，<strong>多源情报聚合</strong>：商业情报 + 社区情报 + 历史处置数据</p><p>第二步，<strong>情报置信度分级</strong>：区分活跃 C2、历史恶意、关联基础设施</p><p>第三步，<strong>时间衰减机制</strong>：避免因陈旧情报导致长期误判</p><p>当某个出站 IP在 IP 离线库中表现为、海外小众地区、云主机 / VPS、非业务白名单 ASN，该IP同时在威胁情报中命中已知 C2 或僵尸网络关联，被多个情报源低频标注，我们才将其提升为  <strong>“高置信度可疑 C2 通信”</strong>  ，进入阻断或人工复核流程。</p><h3><strong>五、</strong> <strong>实际落地的处理流程拆解</strong></h3><p>在最终方案中，整体流程被拆解为清晰的四个阶段：</p><p><strong>1.</strong> <strong>出站连接采集</strong>  <br/>从F火墙、NDR、EDR 中统一采集目的 IP、端口、协议、频率。</p><p>2.<strong>IP 离线库快速画像</strong></p><p>1. 地理位置</p><p>2. ASN / 网络类型</p><p>3. 是否云主机 / IDC</p><p>4. 是否偏离正常业务访问分布</p><p>3.<strong>威胁情报关联评分</strong></p><p>1. 是否命中恶意标签</p><p>2. 情报来源数量</p><p>3. 最近活跃时间</p><p><strong>4.</strong> <strong>策略与响应联动</strong></p><p>1. 自动阻断（高置信度）</p><p>2. 降权监控（中置信度）</p><p>3. 留痕审计（低置信度）</p><p>这种方式的一个明显变化是<strong>我们不再“猜测流量是不是 C2”，而是在判断“这个通信对象是否值得被当作 C2 对待”</strong>  。</p><p>项目讨论中最被认可的是①不依赖深度包检测；②不影响现有网络性能；③可解释性强，适合审计与复盘；④能在离线、内网环境稳定运行。<img width="723" height="352" referrerpolicy="no-referrer" src="/img/bVdnGxg" alt="【场景：识别C2通信】评估出站IP是否为已知恶意地址，方法：IP离线库+威胁情报融合1.png" title="【场景：识别C2通信】评估出站IP是否为已知恶意地址，方法：IP离线库+威胁情报融合1.png" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[《Python动态类型的可靠性屏障：属性测试的实战探索》 程序员阿伟 ]]></title>    <link>https://segmentfault.com/a/1190000047551781</link>    <guid>https://segmentfault.com/a/1190000047551781</guid>    <pubDate>2026-01-19 18:03:28</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>Python动态类型机制所带来的编码自由度，是吸引无数开发者深耕于此的核心魅力，却也如同一把双刃剑，在消解静态类型繁琐约束的同时，埋下了类型契约模糊、行为边界失范的隐性隐患，传统测试手段始终被困在“预设输入-验证输出”的点覆盖逻辑里，面对动态类型环境中对象属性动态绑定、参数类型多元兼容、逻辑分支随运行时状态灵活演化的复杂场景，往往显得捉襟见肘，而属性测试的横空出世，恰好为突破这一技术困局提供了全新的实践路径，它不再执着于单一用例的精准匹配，而是从被测试对象的核心行为特征出发，提炼出那些不因输入变化、环境调整、版本迭代而转移的普适性属性共识，通过海量衍生场景的自动化探索，验证对象在动态变化全过程中的行为稳定性与一致性，这种从“点验证”到“面验证”的思维跃迁，恰恰切中了动态类型环境下测试有效性的核心诉求。在个人长期的开发实践与技术复盘过程中，我逐渐意识到，动态类型的灵活绝非放任代码类型混乱的借口，而是需要更高级的测试方法论来守护代码的可靠性底线，属性测试正是这样一种方法论，它不依赖于代码层面的类型注解或静态检查工具的表层扫描，而是深入到代码运行时的行为本质，通过挖掘那些支撑业务逻辑的核心不变量，构建起动态类型环境下的信任基石，这种信任基石的搭建，远比零散的单元测试用例更具抗脆弱性，也更能适应Python动态特性带来的代码演化需求，更重要的是，它让开发者在享受动态类型便利的同时，不必承担隐性错误扩散的风险，真正实现了灵活与可靠的双向平衡。</p><p>动态类型环境中最常见且最易被忽视的痛点，莫过于函数或对象对参数的隐式约定，这种约定往往不会以显性的类型声明或文档注释的形式呈现，而是潜藏在代码逻辑的深处，成为只有开发者本人才能意会的“潜规则”，传统测试只能基于开发者的经验与认知预设有限的测试用例，却很难覆盖那些边缘的、非常规的输入组合，而这些组合恰恰是动态类型代码最容易出现问题的重灾区，很多时候，这些非预期输入并不会触发语法错误或程序崩溃，而是会产生不符合业务预期的隐性结果，这种结果在测试阶段难以被察觉，却会在生产环境中引发连锁反应，造成难以估量的损失。属性测试的核心优势就在于它能够基于预设的生成策略，自动生成海量多样化的输入数据，这些数据不仅涵盖常规的合法输入，更包括那些边界值、异常值和类型兼容但行为存疑的输入，在个人实践过程中，我曾针对一个处理复杂层级数据结构的工具类展开测试，最初采用传统单元测试的思路，设计了二十余组覆盖常规场景的用例，测试通过率达到100%，但当引入属性测试后，通过提炼“数据转换前后核心特征不变”“异常输入触发合规反馈而非隐性错误”等关键属性，测试工具在短时间内自动生成了数千组输入数据，成功暴露了多个隐藏在动态类型兼容场景下的行为漏洞，比如当输入数据中混合了字符串与数字类型的键名时，工具类会出现键值映射错位的问题，当输入嵌套层级超过预设阈值时，会出现数据结构扁平化不彻底的问题，这些漏洞在常规测试中完全无法被发现，因为它们既不触发报错信息，也不会导致程序终止，只是会在特定条件下产生偏离预期的输出，而这种隐性问题，在动态类型项目中往往会随着代码迭代不断放大，最终演变成难以排查的系统故障。</p><p>属性测试的有效性，本质上取决于开发者对被测试对象核心属性的提炼能力，这也是属性测试区别于传统测试的关键所在，更是考验开发者对业务逻辑理解深度的试金石，在动态类型环境中，对象的属性并非一成不变，部分属性是与代码实现细节强耦合的边缘属性，会随着版本迭代或逻辑调整发生变化，而另一些属性则是支撑对象存在的核心骨架，是与业务目标直接相关的稳定属性，属性测试的第一步，就是要精准区分这两类属性，剥离那些易变的、非核心的边缘属性，聚焦于那些稳定的、决定对象价值的核心属性，这些核心属性往往表现为行为层面的不变量，比如对象经过特定操作后状态的一致性、不同输入序列下输出结果的可复现性、参数类型兼容转换后的行为等价性等。在实践中，我曾针对一个动态生成业务配置对象的模块设计属性测试，最初因为对核心属性的认知模糊，过度关注配置项的具体数值与默认参数，导致测试用例频繁失效，每当配置项的默认值调整或新增配置字段时，测试就需要大面积修改，不仅增加了维护成本，也失去了测试的意义，后来我调整思路，重新梳理模块的业务目标，提炼出“配置对象的键值映射关系与输入源完全一致”“配置项的优先级规则在动态添加与删除过程中始终生效”“配置对象序列化与反序列化后核心业务属性保持无损”这三个核心属性，这一调整让测试用例的稳定性提升了80%以上，也让测试从对实现细节的过度依赖中解脱出来，真正成为守护业务逻辑的屏障，更重要的是，这种属性提炼的过程，本身就是对代码逻辑的深度复盘，能够倒逼开发者更清晰地梳理动态类型对象的行为边界，让原本模糊的隐式约定变得显性化、结构化，从而降低团队协作中的沟通成本，避免因认知偏差引发的开发失误。</p><p>验证属性测试在动态类型环境中的有效性，需要建立多维度的评估体系，而不是简单以测试通过率作为唯一标准，单一的通过率指标往往具有极强的迷惑性，无法反映测试的真实价值，只有从多个维度进行综合评估，才能全面衡量属性测试的有效性与实用性。第一个维度是覆盖深度，这不仅包括代码行的覆盖，更重要的是行为路径的覆盖，通过分析属性测试生成的输入数据所触发的代码执行路径，可以清晰看到哪些路径是传统测试从未触及的，这些路径往往对应着动态类型代码中最复杂的逻辑分支，比如参数类型的强制转换逻辑、异常情况的兜底处理逻辑等，在实践中，我曾对比过同一模块的传统单元测试与属性测试的路径覆盖情况，结果显示传统测试仅覆盖了65%的行为路径，而属性测试的路径覆盖率达到了92%，那些未被覆盖的路径，恰恰是最容易滋生隐性错误的区域。第二个维度是行为一致性，即在不同版本迭代中，核心属性的验证结果是否保持稳定，在个人实践中，我发现当对一个动态类型工具库进行重构时，传统单元测试需要修改超过60%的用例才能适配新的实现逻辑，而属性测试仅需调整少量输入生成策略，核心属性的验证逻辑完全无需改动，这充分体现了属性测试在应对代码演化时的超强适应性，因为它关注的是业务行为而非实现细节，只要核心业务逻辑不变，测试就无需大动干戈。第三个维度是问题发现效率，属性测试能够在代码提交后的自动化测试阶段，快速定位那些因动态类型特性引发的隐性问题，相比传统测试依赖人工复现的低效模式，属性测试可以直接输出触发问题的输入特征，极大缩短了问题排查的周期，比如一次重构后，工具库出现了罕见的配置项丢失问题，传统测试花费了两天时间仍未定位到根源，而属性测试在运行后立即输出了触发问题的输入组合，开发者仅用一小时就找到了问题所在，这种效率上的提升，对于追求快速迭代的动态类型项目而言，具有不可替代的价值。</p><p>在动态类型环境中践行属性测试，需要警惕一些容易陷入的实践误区，这些误区往往源于开发者对动态类型特性与属性测试本质的理解偏差，一旦踩入，不仅无法发挥属性测试的价值，反而会增加不必要的开发负担，甚至误导测试方向。第一个常见误区是过度抽象属性，将一些非核心的、与业务无关的特征纳入属性范畴，导致测试用例与代码实现过度耦合，一旦代码细节调整，测试就会失效，这种脱离业务本质的属性设计，完全违背了属性测试的初衷，比如在测试一个动态序列化工具时，我曾错误地将序列化后的字符串长度纳入核心属性，结果当工具引入压缩算法后，字符串长度大幅变化，导致测试全面失效，后来我将属性调整为“序列化与反序列化后内容完全一致”，才解决了这个问题。第二个误区是忽视动态类型的灵活性，用静态类型的思维设计属性测试，比如强行限制输入数据的类型范围，这不仅浪费了属性测试的场景探索能力，也与Python动态类型的设计哲学相悖，比如测试一个支持多类型输入的字符串处理函数时，若强行将输入限制为字符串类型，就会错过数字、布尔值等类型隐式转换为字符串后的行为测试，从而遗漏潜在问题。第三个误区是低估输入生成策略的重要性，简单采用默认的随机生成规则，导致生成的输入数据要么过于单一，无法覆盖复杂场景，要么过于杂乱，难以触发有价值的代码路径，在个人实践中，我曾因依赖默认生成策略而导致属性测试长期无法发现潜在问题，后来通过结合业务场景定制输入生成规则，比如针对动态数据结构设置嵌套深度阈值、针对参数类型设置兼容转换规则、针对业务逻辑设置输入数据的分布权重，才让属性测试的效能得到充分释放，这些实践误区的踩坑与复盘，让我深刻认识到，属性测试不是一个可以无脑套用的工具，而是需要结合动态类型特性与业务场景灵活调整的方法论，只有避开这些误区，才能真正发挥它的价值。</p><p>属性测试在Python动态类型环境中的应用，绝不仅限于测试层面，更能反向推动代码设计的优化与升级，实现测试与开发的双向赋能，在动态类型环境中，代码的可读性与可维护性很大程度上取决于行为契约的清晰度，而属性测试提炼核心属性的过程，正是对行为契约的显性化定义，这种显性化定义能够让团队成员更准确地理解代码的设计意图，减少因类型模糊引发的沟通成本，提升协作效率。在长期实践中，我发现引入属性测试的动态类型项目，代码的内聚性会显著提升，开发者会不自觉地规避那些行为模糊、属性混乱的设计，转而追求核心属性清晰、行为边界明确的代码结构，比如在设计一个动态数据验证工具时，因为属性测试要求核心验证规则稳定不变，开发者会主动将验证规则与输入数据的类型处理逻辑解耦，从而提升代码的可复用性与可维护性，这种由测试驱动的设计优化，远比单纯的代码评审更具约束力，也更能从根源上提升代码质量。</p>]]></description></item><item>    <title><![CDATA[《Python模糊测试普及困局：隐性壁垒与破局路径深度解析》 程序员阿伟 ]]></title>    <link>https://segmentfault.com/a/1190000047551784</link>    <guid>https://segmentfault.com/a/1190000047551784</guid>    <pubDate>2026-01-19 18:02:56</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>Python生态的生命力源于其极致的灵活性与丰富的库资源，这种特性让开发者能快速搭建各类应用、适配多元场景，却也为模糊测试的普及埋下了深层矛盾。模糊测试的核心价值在于通过非预设输入的探索性验证，捕捉常规测试难以触及的隐性风险，但其在Python生态中始终未能像单元测试工具那样融入主流开发流程，并非工具本身不够成熟，而是生态的碎片化特性、开发者的认知偏差、工具与开发节奏的适配失衡等多重因素交织，形成了一道难以逾越的普及壁垒。这种壁垒并非显性的技术难题，而是隐藏在工具选型、学习路径、流程整合等日常开发场景中的隐性阻碍，需要从生态特性与测试需求的本质矛盾出发，才能看清其核心症结——模糊测试的设计逻辑与Python开发者的使用习惯、项目的迭代节奏、生态的兼容模式之间存在着未被弥合的缝隙，这些缝隙共同构成了普及路上的隐形鸿沟。Python生态的独特性在于第三方库的爆发式增长，不同领域的库在设计理念、数据结构、执行逻辑上差异巨大，而模糊测试工具往往基于通用逻辑开发，难以兼顾各类库的特性，比如面向结构化数据处理的库与面向异步网络请求的库，对输入数据的格式、类型、边界条件的要求截然不同，模糊测试工具若缺乏针对性的适配策略，生成的输入数据要么无法触发核心逻辑，要么因格式不兼容被直接过滤，无法发挥探索性测试的真正价值，这种适配的复杂性让很多开发者在初期尝试后便选择放弃。</p><p>工具生态的碎片化适配困境，是模糊测试在Python生态中普及的首要障碍。Python生态中存在大量功能各异的框架、库与开发范式，从Web开发、数据处理到自动化脚本，不同场景下的项目架构、接口设计、数据流转逻辑差异极大，而现有模糊测试工具大多缺乏普适性的适配能力，往往针对特定场景设计，难以兼容多元开发模式。例如面向Web框架的模糊测试工具，在应对数据科学领域的矩阵运算库时，会因输入生成逻辑与数据结构不匹配而失效；针对同步代码设计的工具，在处理异步协程项目时，又会出现执行流程错乱的问题。更关键的是，Python库的版本迭代频繁，部分库的接口在迭代中缺乏向后兼容，导致模糊测试工具需要持续跟进适配，而多数工具维护团队规模有限，难以覆盖全生态的版本更新，这就使得开发者在使用时往往需要投入大量精力进行定制化改造，从输入生成规则的调整到执行逻辑的适配，一系列繁琐的适配工作让很多开发者望而却步，最终放弃引入模糊测试。以某主流模糊测试工具为例，其最初针对传统同步Web框架开发，当异步框架逐渐成为主流后，工具未能及时更新协程兼容逻辑，开发者若要在异步项目中使用该工具，需要手动修改工具的执行引擎，添加协程调度的适配代码，这不仅要求开发者熟悉工具的内部实现，还需要掌握异步编程的核心原理，对于专注于业务开发的团队而言，这种额外的技术投入远超预期收益，自然会将模糊测试排除在核心测试流程之外。</p><p>开发者的认知阈值与使用惯性，构成了模糊测试普及的深层阻碍。在Python开发群体中，多数开发者更倾向于轻量化、即时反馈的测试方式，单元测试的“编写用例-执行验证-快速迭代”模式已深入人心，形成了稳定的使用惯性。而模糊测试的核心逻辑与这种惯性存在天然差异，它需要开发者跳出“预设场景”的思维定式，转向“探索性验证”的逻辑，这种思维转换本身就存在一定的认知门槛。更重要的是，模糊测试的价值呈现方式较为间接，它无法像单元测试那样即时反馈用例通过率，而是需要通过长期运行、海量输入探索才能发现潜在风险，这种“慢反馈”特性与Python项目快速迭代的开发节奏形成了鲜明冲突。很多开发者在初期尝试时，因短期内看不到明显效果，便认为模糊测试“性价比低”，忽视了其在捕捉隐性风险、提升代码鲁棒性上的长期价值。此外，行业内对模糊测试的宣传多聚焦于复杂场景的深度验证，导致很多开发者形成“模糊测试只适用于大型项目”的认知偏差，而Python生态中大量的中小型项目、工具类库开发者，往往因这种认知而不愿尝试引入。比如一个开发轻量级数据解析库的团队，开发者习惯用单元测试覆盖常见的解析场景，当尝试引入模糊测试时，连续运行数小时未发现明显问题，便觉得模糊测试对小型项目没有价值，却忽略了那些极端数据格式可能引发的解析逻辑漏洞，这些漏洞在日常使用中出现概率低，但一旦出现就会导致整个解析流程瘫痪，而这种隐性风险的预防价值，恰恰是模糊测试的核心优势所在。</p><p>学习路径的陡峭与优质资源的匮乏，进一步加剧了模糊测试的普及难度。模糊测试本身涉及输入生成策略、覆盖准则设计、结果分析等多个专业维度，而Python生态中针对这些维度的系统化、入门级学习资源严重不足。现有资源大多偏向工具的基础使用说明，缺乏对核心逻辑、场景化适配思路的深度拆解，导致开发者在使用时往往只知其然，不知其所以然。例如很多教程仅介绍如何调用工具生成随机输入，却未讲解如何结合项目业务逻辑设计高效的输入生成规则，如何根据不同数据类型调整探索策略，这就使得开发者在面对复杂项目时，即便掌握了基础操作，也难以发挥模糊测试的真正效能。同时，Python生态中缺乏统一的实践标准与最佳案例库，不同项目的模糊测试实施路径差异较大，开发者难以借鉴成熟经验，只能在试错中摸索，这不仅增加了学习成本，还容易因初期的错误实践导致对模糊测试的误解，进一步阻碍了其普及。比如针对机器学习模型的输入验证场景，模糊测试需要生成符合特征维度、数值范围的输入数据，才能有效测试模型的鲁棒性，但现有教程几乎没有涉及这类场景的适配方法，开发者只能盲目使用默认的随机输入生成规则，导致生成的大量数据因不符合特征要求被模型直接拒绝，测试效率极低，这种低效的实践体验会让开发者对模糊测试的价值产生怀疑，最终放弃深入探索。</p><p>资源消耗与执行效能的错配，是模糊测试在Python生态中落地的现实障碍。Python作为解释型语言，运行速度本身就低于编译型语言，而模糊测试需要生成海量输入数据并反复执行被测试代码，这会带来显著的资源消耗——大量的CPU占用、内存开销以及漫长的执行时间，这种消耗在中小型项目、资源有限的开发环境中尤为突出。例如在处理复杂数据结构或逻辑密集型代码时，模糊测试的执行速度可能是单元测试的数十倍，一次完整的测试往往需要数小时甚至数天，这与Python项目快速迭代、频繁测试的开发模式严重不符。更关键的是，模糊测试的执行效能与输入生成策略的精准度密切相关，若输入生成缺乏针对性，大量无效输入会进一步拉长测试周期、浪费资源，而精准输入策略的设计又需要开发者投入额外精力，这种“高投入-低效能”的错配让很多团队在权衡成本后，选择放弃引入模糊测试，即便认可其价值，也只能将其作为边缘测试手段，难以融入核心开发流程。以一个处理复杂数学运算的工具库为例，其核心函数包含多层嵌套的逻辑判断，模糊测试需要生成大量不同数值范围、精度的输入数据，在普通的开发电脑上，一次完整的测试需要占用80%以上的CPU资源，持续运行超过12小时，期间开发者无法进行其他开发工作，这种资源占用与时间成本，对于追求快速迭代的小型团队而言，显然是难以承受的，最终只能将模糊测试从日常测试流程中剔除。</p><p>生态级集成支持的缺失，让模糊测试难以形成顺畅的使用闭环。在Python生态中，单元测试工具已与主流IDE、CI/CD平台、代码管理工具形成深度集成，开发者可以在编码过程中即时编写用例、提交代码后自动触发测试、通过平台直观查看结果，这种无缝集成的体验极大降低了使用门槛。而模糊测试工具在这方面的集成支持严重不足，多数工具仍以独立运行的命令行形式存在，缺乏与主流开发工具链的适配，导致开发者需要在不同工具之间手动切换、传递数据，打破了原有的开发流程闭环。例如在CI/CD流程中，模糊测试的配置复杂且缺乏标准化，不同平台的适配方式各异，需要开发者编写大量定制化脚本才能实现自动触发；在结果分析环节，多数工具输出的日志格式杂乱，缺乏与代码调试工具的联动，开发者需要手动定位问题关联的代码片段，排查效率极低。这种集成层面的断层，让模糊测试无法像单元测试那样融入日常开发的每一个环节，只能作为额外的“附加操作”，自然难以得到广泛普及。比如在GitHub Actions中配置模糊测试，开发者需要手动编写yaml配置文件，指定工具的安装路径、执行命令、输出目录，还需要处理不同操作系统的兼容性问题，而单元测试只需调用内置的测试命令即可自动运行；在结果分析时，模糊测试工具输出的日志仅包含输入数据与执行结果，开发者需要手动将输入数据代入代码调试，才能定位问题根源，这种繁琐的操作流程，让模糊测试的使用体验远不如单元测试流畅，难以被开发者广泛接受。</p><p>价值转化的模糊性与评估体系的缺失，是模糊测试普及的终极桎梏。模糊测试的核心价值在于预防潜在风险、提升代码鲁棒性，但这种价值难以量化评估，不像功能测试那样可以通过用例通过率、缺陷修复率等明确指标衡量。在Python生态中，多数项目缺乏对模糊测试价值的评估标准，开发者无法直观判断引入模糊测试后代码质量的提升幅度，也难以向团队或管理层证明其投入的合理性。例如模糊测试发现的隐性风险，若未发生实际影响，往往被认为是“无关紧要的问题”，其预防价值被严重低估；而即便发现了关键风险，也因缺乏前后对比数据，难以量化其避免的损失。这种价值转化的模糊性，导致很多团队在资源分配时优先选择价值明确的测试手段，而将模糊测试排在次要位置。此外，行业内尚未形成统一的模糊测试效果评估框架，不同项目对“有效测试”的定义各异，进一步加剧了价值认知的混乱，让开发者在引入时缺乏明确的目标导向，最终难以坚持长期使用，也阻碍了模糊测试在Python生态中的广泛普及。</p>]]></description></item><item>    <title><![CDATA[拆解AI搜索的“黑盒”：GEO如何系统性影响大模型的引用概率？ AI代码猴 ]]></title>    <link>https://segmentfault.com/a/1190000047551787</link>    <guid>https://segmentfault.com/a/1190000047551787</guid>    <pubDate>2026-01-19 18:02:05</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h4>引言：一个“非随机”的选择困境</h4><p>当你向ChatGPT、DeepSeek或文心一言提问：“2026年最适合程序员的轻薄本是哪款？”时，AI生成的答案中，为何总是那几款品牌被反复推荐，而其他性能相近甚至更具性价比的产品却踪迹全无？</p><p>这个看似“智能”的推荐，背后绝非随机选择。它是一场发生在高维向量空间、由复杂概率计算主导的精密博弈。你的品牌未被提及，不是因为产品不好，而是因为在大模型的“世界模型”里，你的信息未被有效地编码、关联，或在最终生成阶段被其他更高权重的信息“挤掉”。</p><p>本文将以技术侦探的视角，试图拆解大模型生成答案的“黑盒”流程，并逆向推演一套名为 GEO（生成式引擎优化） 的技术体系，如何通过系统工程方法，科学、可度量地提升品牌信息在这一链条中的 引用概率。</p><h4>第一章：逆向工程——大模型生成答案的“三层漏斗”</h4><p>尽管各大模型的内部权重与训练数据是核心机密，但根据公开论文（如Transformer架构、RAG系统原理）及可观测现象，我们可以将其生成包含外部信息的答案过程，简化为一个 “召回-排序-生成” 的三层漏斗模型。</p><p><strong>1. 召回（Recall）：从“信息宇宙”中捕捞候选集</strong></p><p>发生了什么？ 当模型解析你的问题（Query）后，它并非从完整训练数据中逐字扫描，而是将问题转化为一个高维向量（Embedding），并在其内部的索引或关联的外部知识库中，进行近似最近邻搜索（ANN），快速召回一批语义相关的信息片段（Chunks）。这些片段可能来自训练数据中的网页、文档、问答对，或实时检索的结果。</p><p>技术挑战： 如果你的品牌内容（官网、评测、技术文档）在语义上与用户的高频提问方式向量距离过远，或在数据索引中权重过低、特征不明显，就会在召回层被直接过滤掉。这是“零推荐”的根本原因之一。</p><p><strong>2. 排序（Ranking）：对候选信息进行“价值评估”</strong></p><p>发生了什么？ 召回的上百条候选信息，将进入一个复杂的排序环节。模型会综合评估每条信息的：</p><p><strong>相关性（Relevance）：</strong> 与问题的语义匹配度。</p><p><strong>权威性（Authority）： </strong>信源本身的权重（如知名媒体、官方机构、高权威域名）。</p><p><strong>新鲜度（Freshness）：</strong> 信息的时效性。</p><p><strong>流行度（Popularity）：</strong> 在训练数据中被引用的广泛程度。</p><p><strong>技术挑战：</strong>即使被召回，如果你的内容在权威性（未被高质量信源引用）、新鲜度（信息陈旧）、流行度（网络声量小）等维度上得分不足，其综合排序也会靠后，难以进入最终生成的候选名单。</p><p><strong>3. 生成（Generation）：基于概率采样构造最终答案</strong></p><p>发生了什么？ 模型根据排序靠前的信息片段作为核心上下文，结合其预训练的世界知识，通过自回归的方式逐词生成答案。在此过程中，它会对提及的具体实体（如品牌名、产品型号）进行概率采样。排序更高、在上下文中出现更连贯、更符合模型“认知”的实体，被采样的概率自然更大。</p><p><strong>技术挑战：</strong>生成环节的随机性背后是概率的博弈。如果你的品牌信息未能与“理想答案”的上下文强绑定，或者表述方式（如昵称、别称）未被模型良好对齐，也可能在最后一刻“落选”。</p><h4>第二章：GEO的理想框架——在“三层漏斗”中施加技术干预</h4><p>要系统性地提升引用概率，就必须针对上述三层漏斗，设计一套可工程化的技术干预框架。一个理想化的GEO系统应包含以下核心模块：</p><p><strong>垂直诊断模型（用于理解与预测）：</strong></p><p>目标： 逆向诊断目标大模型（如DeepSeek、GPT-4）在特定领域的偏好与逻辑。它需要理解：对于某类问题，模型倾向于召回什么类型的内容？排序时更看重什么信号？</p><p>技术实现猜想： 可能需要通过海量的问答对进行对比学习，或对开源模型进行针对性微调，构建一个能够模拟目标模型部分决策行为的“镜像模型”。</p><p><strong>向量化运营数据库（用于优化召回与排序）：</strong></p><p>目标： 不再将内容视为孤立的文本，而是将其结构化、向量化存储。运营重点是将品牌内容的关键信息，以更易被模型“召回”和“理解”的方式重新组织。</p><p>技术实现猜想： 建立行业知识图谱，将产品特性、使用场景、用户痛点映射为标准化的向量表示。同时，需要追踪哪些外部高权威信源引用了品牌，并优化这些“引用锚点”的内容。</p><p><strong>实时反馈控制系统（用于验证与迭代）：</strong></p><p>目标： 构建一个分钟级监测系统，能够量化每一次优化动作（如发布一篇技术白皮书、获得一个权威媒体引用）对最终AI引用概率的影响。</p><p>技术实现猜想： 需要自动化地模拟海量用户提问，抓取AI答案，并通过NLP技术解析其中品牌露出的位置、情感和上下文，形成归因分析报告，驱动策略迭代。</p><h4>第三章：从理论到实践——万数科技的“工程应答”</h4><p>当我们把视线投向业界，会发现 万数科技 提出的技术栈，几乎是对上述理想GEO框架的一次精准工程实现。他们的方案不是功能罗列，而是针对每个工程挑战的深度解决方案。</p><p><strong>1. 对“垂直诊断模型”的应答：DeepReach大模型</strong></p><p><strong>设计原理揭秘：</strong> DeepReach并非一个通用的聊天模型，而是一个专门针对 “预测并提升被主流模型引用概率” 这一任务进行优化的垂直模型。其技术栈深入Transformer堆栈的中间层表示、高维向量空间的几何关系以及温度参数对生成随机性的影响。简单说，它通过技术手段（可能包括对抗性训练、梯度信号分析等）尝试“学习”目标模型的内部打分机制，从而能更准确地诊断：优化哪些内容、以何种形式呈现，最能撬动目标模型的排序权重。</p><p><strong>2. 对“向量化运营数据库”的应答：量子数据库 + 翰林台平台</strong></p><p><strong>设计原理揭秘：</strong></p><p>量子数据库 解决了“如何高效组织与检索海量优化语料”的问题。它通过系统化多级行业数据向量化编码和分布存储，不仅存储内容，更存储内容之间的语义关联和优化归因。它支持大模型数据混合学习，意味着优化行动产生的新数据（如一次成功的AI推荐案例）能被拆解、归因，并反哺给DeepReach模型，形成一个自我强化的学习闭环。</p><p>翰林台AI定制内容平台 则是将诊断结果和数据库知识，转化为标准化作战动作的“兵工厂”。它基于DeepReach的理解，自动生成在特定模型看来权威性更高、相关性更强、更易被集成的跨模态内容（技术文档、Q&amp;A对、场景化评测），并确保内容格式符合不同AI平台的偏好（多模态适配化）。</p><p><strong>3. 对“实时反馈控制系统”的应答：天机图数据分析系统</strong></p><p><strong>设计原理揭秘：</strong> 这是将GEO从“艺术”变为“科学”的关键。天机图系统实现了对优化效果的定量数据化监测。它能：</p><p><strong>洞察意图演化：</strong> 分析用户提问模式的变迁，提前布局内容。</p><p><strong>分钟级追踪效果：</strong> 当一个新的优化内容被部署后，系统能快速监测到它在目标AI答案中排名或提及率的变化。</p><p><strong>归因分析：</strong> 将“效果波动”与“运营动作”在时间线上关联，明确是哪些具体操作（如更新了某核心页面的Schema标记、在某高权重论坛发布了深度帖）驱动了引用概率的提升。</p><p><strong>方法论闭环：GRPO法则</strong><br/>其独创的 GRPO法则 正是将上述三项技术组件串联起来的“操作系统级”工作流。它规定了从 表达结构化（G）、多模态适配化（R）、定量数据化（P） 到 整体优化（O） 的标准作业程序，确保整个干预过程是严谨、可重复、可度量的工程实践，而非依赖灵感的随机尝试。</p><h4>结论：从“黑盒猜测”到“白盒干预”</h4><p>GEO的终极目标，是将在海量参数中运行的、非确定性的AI生成过程，通过一套外部的、系统性的工程技术框架，变得更具可预见性和可影响力。</p><p>它不再是对“黑盒”的盲目猜测，而是通过 垂直模型（DeepReach）进行深度诊断、利用 向量数据库（量子数据库）重构信息资产、并通过 实时反馈系统（天机图）构建控制闭环 的“白盒化”干预尝试。万数科技 的技术栈展示了一条清晰的路径：将影响大模型引用概率这一宏大课题，分解为一个个可被测量、可被优化的工程子任务。</p><p>对于技术团队而言，理解这套框架的价值在于：当你们在选择GEO服务商或考虑自研时，可以不再被模糊的承诺所迷惑，而是能够尖锐地提问：你们的技术，究竟是在召回、排序还是生成层发挥作用？你们的模型，是简单调用API，还是真正具备逆向诊断能力？你们的数据，是散乱的文档，还是结构化的、可归因的向量网络？</p><p>答案，将决定你的品牌是永远在AI的“黑盒”外徘徊，还是能够深入其内部逻辑，赢得这场关于未来注意力的关键战争。</p>]]></description></item><item>    <title><![CDATA[一文看懂：MES价值，MES系统对企业的生产管理有哪些改进？ 织信informat ]]></title>    <link>https://segmentfault.com/a/1190000047551790</link>    <guid>https://segmentfault.com/a/1190000047551790</guid>    <pubDate>2026-01-19 18:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>MES制造执行系统是精益生产的重要支撑工具，它能够帮助企业实现生产过程的数字化、智能化和精细化管理，提高生产效率和质量，降低生产成本，为企业创造更大的价值。</p><p>MES制造执行系统是一种集生产计划、物料管理、工艺执行、设备控制、质量管理等功能于一体的软件系统。它通过实时监控生产过程、收集并分析生产数据，为管理层提供决策支持，同时为操作层提供指导和帮助。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047551792" alt="image.png" title="image.png"/></p><h2>制造行业在生产过程中所面临的挑战</h2><p>1、无法预测生产线需求使用</p><p>随着工厂订单量的增多，在生产前，人工往往不知道或无法快速预知在一条产线中应该做哪个订单的那些工序，所需量是多少，要提前准备何种物料。</p><p>2、不能及时掌握生产情况</p><p>每天的生产数据需要人工事后填写和统计，管理层不能及时掌握订单在车间的最新生产情况。无法及时得知当前每个生产订单、每个工序的生产进度如何、哪些未按计划开始、哪些未按计划完工、特急件是哪些、良品数、不良品数分别多少等等问题。</p><p>3、没有对比，无竞争感</p><p>因为没有即时的目视指令和电子看板，现场人员没有绩效对比和竞争，没有紧迫感。不知道当前谁的效率高？谁的效率低？</p><p>4、无法及时得知当前机台产线情况</p><p>当前哪些机台产线是在工作或是停机？机台、产线有多少时间在生产，多少时间在停转和空转？利用率是多少？这些都是无法及时得知，只能通过记录得知。</p><p>5、无法及时得知致错原因</p><p>无法及时得知过去几小时之内，车间出现最多的不良品是什么原因造成的？不良率有多高等问题。</p><p>6、无法追溯源头</p><p>用户投诉产品不良时，如何立即追溯该产品的历史生产过程信息？如：是谁、在什么时间、在哪台机器上、用什么材料做的？该产品加工过程经过了哪些工序？当时的工艺参数是怎样的等问题。</p><h2>MES系统对企业生产管理有哪些改进？</h2><p>在精益生产的背景下，MES制造执行系统发挥着至关重要的作用，具体来说，MES制造执行系统在精益生产中的改善企业生产的五大方法：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047551793" alt="image.png" title="image.png" loading="lazy"/></p><p>1、全面的生产能力平衡分析</p><p>在企业生产过程中，不同的人员和设备都有着不同的生产能力，不同的产品有着不同的生产能力需求，若采用同一种生产任务分配模式，容易造成车间生产能力与完成计划所需能力之间的不协调，直接导致车间生产现场混乱，且难以合理调整各工作中心的生产分配量。</p><p>MES系统拥有最直观的图形和文字，可以为企业提供最精准的设备任务负荷分析、部门/班组任务负荷分析等数据。通过详细的数据逐级查询和分析，还能够帮助企业计划和调度人员进行生产任务的外协和均衡，并实现最优的生产计划排程。</p><p>2、高效的生产计划管理</p><p>在没有使用MES系统之前，企业生产信息的获取，只能通过人员填写的报表反馈或者电话汇报。这样，信息获取不够及时，影响企业管理层及时有效地下达管理指令，制约了管理措施的有效实施。</p><p>MES系统能够全面管理企业订单的整个生产流程，通过生产信息的采集和多维度的看板展现，让每个订单、每个零件、每道工序等实时信息，及时展现给车间管理人员，使企业各级领导更加便捷地掌握生产任务执行状况，并迅速做出生产决策，确保实现生产任务按时、按节点完成。</p><p>3、便捷的任务派工管理</p><p>生产订单的执行往往需要通过多道不同的工序来完成。未使用MES系统时，开始阶段可能对生产任务执行的进度比较了解，但一旦工序并行作业，就无法完成工单的追踪和管理了。MES系统拥有强大的任务动态调度能力，能够及时响应生产现场各种状态的变化。</p><p>在生产计划完成后，系统还能够自动生成任务派工单，并通过条码扫描向生产现场自动输送加工程序、零件图纸、工艺指导文档等，大大节约工作人员在生产现场来回奔波的时间。</p><p>4、完善的产品质量管理</p><p>制造企业把产品质量视为企业的生命，全面的质量管理保障高品质的产品。MES系统通过对原材料、生产过程以及在用户使用中的产品的整个生命周期进行数字化、网络化和动态化的管理，实现对产品质量的管控和追溯。</p><p>这样，MES系统就可以通过持续不断的改进，帮助企业完善全面的质量管理体系，进而有效控制生产成本。</p><p>5、最优的车间库存管理</p><p>库存管理是每个企业在生产过程中都不可或缺的环节。合理的库存控制，可以有效避免生产停滞，为企业建立良好的生产环境。MES系统支持原材料、成品、半成品、工具等的库存管理，所有流程通过条码扫描操作，既准确又便捷。</p><p>MES系统彻底改善了企业车间生产管理流程，实现车间管理无盲点，生产管控一体化的新模式。其最前沿的信息技术在各大制造企业间得到强烈反响，并成为支撑制造企业高速发展的内在动力。</p><h2>成功实施MES系统需先完善管理基础</h2><p>将MES系统导入到企业的运作体系之中，企业需要先完善管理基础，根据自身情况选择好“合身”的MES软件系统，而后采用科学的实施方法充分准备，才能促使MES正式运行、发挥效用。</p><p>要想成功实施MES，企业必须先在管理上下功夫——与MES密切相关的工作，包括车间环境、职责分工以及人员保障等方面。</p><p>1、定置，改善车间环境</p><p>定置，是指通过对生产和工作环境的分析，把生产和工作需要的物品按照工艺的需要科学地确定位置。定置管理，则是指对现场物品定置的设计、组织、实施、控制，使现场管理达到科学化、规范化、经常化的全过程。定置管理为生产者在较短的时间内用较低的成本制造出高质量产品提供良好的客观条件。通过定置管理，理顺物流，可以为MES的实施提供良好的车间环境。</p><p>2、合理分工，明确职责</p><p>“计算机能够解决一切管理问题。”——这是相当一部分企业领导在实施MES时的一个误区。事实上，许多企业面临的管理问题是不可能靠计算机来解决的，必须靠企业自身通过科学的组织、严格的规章及有效的控制来解决。计算机只能通过信息的获取与加工、一定的流程控制来支持企业管理思想的贯彻。有些企业的组织结构不合理、职能相互重叠，其结果是责任不清、相互扯皮。</p><p>这一方面妨碍了MES的顺利实施，另一方面也难以保证MES正常高效地运行。因此，在实施MES时，必须对企业的业务流程进行合理重组，去除重叠的部门职能，减少无效劳动，合理分工、明确责职。这样既可以简化MES软件的权限设置和流程控制，又能够保证信息处理的及时性，为MES的实施提供组织保证。</p><p>3、提供人员保证</p><p>MES系统实施，通常涉及到计算机人员、企业管理人员、车间现场操作人员和具体业务人员等方面。不仅涉及面广，而且各类人员的文化水平、业务能力、计算机应用水平也参差不齐。因此，为了保证MES的顺利实施，必须对相关人员进行足够的培训。对不同类型、不同层次人员的培训方式应有所不同。</p><p>实际上，在整个MES实施过程中，培训工作是贯彻始终的。不仅要在实施准备阶段进行原理培训，而且在实施准备、模拟运行与试运行、切换运行、新系统运行过程中也要进行有关培训，如软硬件产品培训、系统管理员培训和持续扩大培训等。只有通过培训让企业员工对MES软硬件产品有了一定的了解，才能够保证系统最终的顺利实施和应用。</p><p>【声明】：以上所发文章仅供大家学习参考，请不要作商业用途；MES系统的专业性很强，文中难免有错误，一旦发现，请联系我们及时更正；文中部分图片源于网络，侵删。</p><p>最后感谢图片内容的提供方：织信MES，该厂商专注企业信息化系统管理10年余，坚持传播生产管理知识，自研低代码开发底座，基于B/S架构，可帮助企业快速构建生产管理所需的各项功能，可根据客户实际作业流程和管理要求实现定制化开发，系统内置自定义开放接口OpenAPI，能够对接所有的管理信息系统，广泛应用于国内外各行各业。</p>]]></description></item><item>    <title><![CDATA[ERP实施40问——30分钟让外行变专家 织信informat ]]></title>    <link>https://segmentfault.com/a/1190000047551420</link>    <guid>https://segmentfault.com/a/1190000047551420</guid>    <pubDate>2026-01-19 17:13:04</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>能在一个小时内搞明白ERP以及其实施中的要点吗？</p><p>听起来似乎有点要求过分，但这真的是忙碌的CIO和CEO的迫切需求。</p><p>本人在多年的实践中，结合自身经验和多年的理论积累，总结出有关ERP实施的最关键的40个问题，以问答的形式，让你在最短的时间内对ERP实施有一个全面而客观的认识，以免陷入日新月异的技术、层出不穷的理念以及纷繁复杂的观点怪圈中。</p><h2>一、实施过程</h2><p>1.ERP的实施分哪些阶段?</p><p>ERP的实施通常分为准备、设计、实施及上线支持四个阶段。</p><p>2.准备阶段的主要工作有哪些?</p><p>办公环境和计算机等办公设备的落实，关键用户，总体方案，动员启动大会。</p><p>3.设计阶段的主要工件有哪些?</p><p>业务流程设计，现状调研，未来流程设计，确定客户化工作范围。</p><p>4.实施阶段的主要工作有哪些?</p><p>在预配置系统的基础上，对每个单位的系统进行个性配置，但必须经过总部的审批;设计并完成客户化编程，设计并建立系统用户权限，进行系统测试，进行讲师和最终用户培训，进行数据转换试转档，正式转档与系统上线。</p><p>5.后续工作有哪些?</p><p>实施后的技术支持。为了保证新的系统能够支持日常的业务运营，对系统配置进一步完善，并确保系统的顺利移交。</p><h2>二、基本理念</h2><p>6.ERP是一种软件产品吗?</p><p>下面这类的对话，几乎在所有的ERP活动中都会遇到：</p><p>企业：“我们想上ERP，你看选哪一个软件最好?大概要多少钱?”</p><p>问：“你们是ERP想解决什么问题?有没有算过可能得到的回报或效益?”</p><p>企业：“……”</p><p>事实是ERP不是一种软件产品，而是一种知识转移，对企业最重要的是培养自己诊断管理问题的能力，包括：企业战略与信息化战略的确定，业务流程描述，企业诊断方法，需求分析方法等。这些都要求企业积极投入到ERP实施项目中，在过程是积累知识、培养技能。</p><ol start="7"><li>ERP与ERP项目有何不同?</li></ol><p>ERP和ERP项目是不同的，前者是个理念，而后者则是实实在在的项目，理念是可以完美无瑕的、漫无边际的，但项目则是在有限的时间内投入有限的资源以达到有限的目标。</p><p>很多企业的一把手往往混淆了ERP理念与ERP项目的区别，忽视了ERP项目的项目特性，用ERP理念的东西去套ERP项目，导致项目不明确，项目需求计划变动大，投入的资源一再变更扩大，最终使得项目举步维艰、陷入困境。</p><p>因此，必须要掌握项目管理的技巧与方法，并且要在项目实施中去不断的完善与深刻理解，知道运用什么样的方法去推动项目，在什么阶段关注什么样的问题，在什么样的情况下发挥一把手的作用等等。</p><p>8.ERP能提高效益吗?</p><p>某些企业说：“ERP上线后，工作效率是提高了，但是效益还不明显”。</p><p>效益问题是可以通过实施ERP系统来解决，但是要想实现预期的目标不能仅仅停留在“上线”，更重要的是学会应用系统提供的信息来解决问题。因此如何用ERP系统提供的信息来解决管理中的问题，最终提高效益和竞争力，是ERP知识转移中一个很容易被忽略的方面。</p><p>9.合作伙伴的选择标准与评估方法是什么?</p><p>无论是信息化解决方案与服务提供商，还是相关的咨询服务提供商，对于企业而言，都应该有一定的选择标准与评估方法，以确保选择对的合作伙伴进行信息化建设与应用。为此，应着重考虑以下几点：</p><p>1).要根据企业信息化需求初步调查的结果与业务流程重组(BPR)形成的相关需求方案来确定选择相应软件解决方案或服务的标准;</p><p>2).要考虑到解决方案或服务的成熟性;</p><p>3).还要考察解决方案提供商对于企业业务行业运营与管理的熟悉度;</p><p>4).还要考虑提供商的成长能力。</p><p>对于咨询服务提供商的选择，需要考虑的因素包括：咨询服务商的行业经验、专业程度、是否与企业长期发展战略方向一致等。</p><p>10.谁是ERP项目的拥有者?</p><p>有些企业会错误的把ERP项目当作是咨询方的项目。但是，咨询方不可能对企业有深刻的了解，也不可能为企业作决策。咨询方的主要责任是向用户提供管理改进的建议和技术支持，以及知识传递。</p><p>企业只有把ERP项目真正当作自己的项目，与咨询方密切合作、相互理解，才能充分发挥咨询方的作用和实现自己管理变革和目标。</p><h2>三、实施风险</h2><p>11.为什么要使企业高层认识到ERP项目风险?</p><p>如果企业高层不能清醒认识实施ERP的目的和风险，就不会注入足够的资源(龙其是业务部门的人员)参与到项目中，不会投入足够的精力参与项目的各种重大决策，不会为ERP项目营运足够的声势使全体员工在意识上做好迎接管理变革的准备。</p><p>企业高层管理的深刻认识和强力支持是ERP成功的必要条件之一。</p><p>12.为何称ERP为“一把手工程”?</p><p>企业的决策者在ERP实施过程中的特殊作用。ERP是一个管理系统，牵动全局，加之要实施过程中会触及和影响到不同的即得利益，如果没有第一把手的参与、授权和协调，是很难调动全局的。</p><p>企业最高层领导对ERP系统的重视、期待和参与，主要体现在以下方面：首先，为了保证ERP的实施成功，必须支持项目在企业中获得仅次于企业正常运营的第二位优先级。其次，进行整个企业范围的资源分配和进度安排。第三，对业务流程的改变拍板。第四，制订和执行奖惩措施。</p><p>13.如何克服传统管理体制所维系的经营习惯形成的运作惰性阻力?</p><p>新旧管理模式难免有一些本质的区别。公司的管理者往往已习惯于传统的模式管理，往往会沿用习惯的方法去了解问题、思考问题、解决问题。</p><p>但是，ERP动态、共享式的管理手段难免会改变调研情况的方法和作出营运决策的依据，使许多企业管理者一下难以适从，对新型管理系统产生抵触情绪。特别是在新型管理系统中的管理点，工作量和工作强度相对增加了的情况下。</p><p>对此，公司应该在建立ERP系统前，就客观地认识和评估新系统的利弊，估算企业将为此付出的代价和增加的工作量，从心里上做好准备主动去适应它，从而把运作惰性阻力降至可能的最低限度。</p><p>14.ERP项目的人力资源投入误区是什么?</p><p>很多企业在ERP项目初期会把它当成是IT部门或企划部门的信息工程项目，项目小组通常只由缺乏业务背景和决策能力的IT人员和对企业的了解较少的咨询顾问组成，而没有实际享受项目成果的业务部门的参与。这样，项目小组的工作结果往往不被业务部门接受，造成项目的决策周期延长。</p><p>这种脱节的项目人员投入无疑会导致项目周期的拖长和总体资源的浪费。</p><p>15.为何说“ERP就是实施一套新软件，ERP项目只是IT部门的事”是一种错误而危险的认识?</p><p>一些企业往往会认为ERP项目就是实施一套新软件，ERP项目只是IT部门的事，只要业务部门把自己的需求说清楚，剩下的事就一概不管了。这种认识显然是错误的。</p><p>如果把ERP项目除去系统软件的外壳，其最核心还是企业管理。企业管理是什么，就是企业的方方面面，企业的任何神经脉络，任何角落，都存在着管理问题。因此，ERP的实施应该是一个企业全员的行为，而不只是哪个单个部门的行为。</p><p>ERP项目决不仅仅是流程的自动化，它一定是管理模式及业务流程的优化，如果没有业务部门的全力参与甚至是起主导作用的话，可以说根本就不是ERP项目。</p><p>16.何谓ERP的“集成性风险”?</p><p>对于熟悉过去单一业务系统的企业来说，基于流程并且具有高度集成性的ERP系统给他们提出了新的挑战：前后连贯的流程使相关部门之间产生了一定的依赖关系。这就很容易发生部门间相互误工、扯皮的现象。</p><p>企业变革管理和相应的岗位培训，要能够使最终用户对他们各自在整个业务流程中的每一项操作对其他流程、用户和整个系统的影响有个正确的认识和理解，形成系统整体的概念。</p><h2>四、实施难点</h2><p>17.如何克服传统的作业流程向计算机技术支持作业规范过渡时遇到的阻力?</p><p>新型计算机辅助管理信息系统采用的数据标准和规范，在整个企业范围内是一致的。而一般企业现行的传统标准通常是各部门之间相对独立的。两者的矛盾对企业实施ERP通常会造成很大的阻力。</p><p>常见的现象是，某些部门且员工难以接受为了适应统一，将他们认为是很好的历史标准换成一套陌生的东西。解决这个问题，除了使用一定的行政手段强制执行统一标准和规范外，一定要同时加强全局观念的思想教育和动员。</p><p>18.如何克服人事组织机构的调整和员工工作性质变化而造成的实施阻力?</p><p>由于ERP系统的实施和应用，难免会带来公司的管理体制的变革，某些相关员工在企业中的责任、权利和自身的利益的变动，会引起一些对ERP系统实施的阻碍。</p><p>对企业管理者来说，除了使用行政手段配合外，还要具体情况具体分析，正确的引导是解决问题的重要方法。</p><p>对企业员工来说，不仅要正确的认识ERP给个人的机遇和困难，更加要用长远、发展的眼光来分析自己在企业的ERP变革浪潮中的地位和作用。</p><p>19.如何避免漫长、不及时的问题处理和决策?</p><p>顺畅的沟通可以提高问题处理和决策的效率。由于ERP实施通常要涉及企业的相关部门，而不仅仅局限于项目小组，内部沟通就显得十分重要。</p><p>20.如何完善的保留历史系统数据，做好新旧系统的切换?</p><p>要做好充分的数据准备。</p><p>没有准确的数据就没有成功的ERP。从ERP实施项目一开始，就重视数据的准备工作，是避免实施风险的重要因素。数据准备包括数据整理、规则统一、数据倒入等工作。明确项目中的数据管理组织及责任是非常必要的。</p><p>21.何谓ERP的“穿鞋论”?</p><p>从某种角度来说，实施ERP项目就是企业在为自己订做一双适应企业管理新时代的时尚新鞋。而应用ERP系统无非就是穿鞋了，只有合脚了，才能说是好鞋。如果鞋做好了，却不满意，势必出现削履适足或削足适履的问题。我们姑妄称之为ERP穿鞋理论。</p><p>鞋穿上舒服不舒服，取决于用户事先是否充分参与，取决于双方是否有效的沟通，取决于用户是否真正了解自己的需求。所以公司上下一定要达成共识，充分的参与项目的实施和应用，否则势必会带来失败。ERP不是一个“交钥匙”工程，客户必须自己参与实施的全过程，并真正的应用它。</p><p>22.谁是ERP的试鞋人?</p><p>ERP实施是一企业范围的变革过程，企业的所有部门都要进行部门业务流程重组，定义新系统的相差模块功能。</p><p>只有穿鞋的人才知道鞋子什么地方是卡脚的。中层领导是上下联系的桥梁，他们深入基层，经常与实际问题打交道，只有他们真正了解企业的实际情况。在实施项目时，尽量做到把每个模块能否在相关部门实施成功作为对相关部门负责人的重要指标，并由其参与部门业务流程重组。让这些中层领导亲自接触ERP软件，接触各种新的管理思想，让他们自己提出对软件的看法，才能调动他们的积极性、发挥他们的创造性和主观能动性，推动ERP的实施。</p><h2>五、项目组组成</h2><p>23.为什么说中层领导要参与业务流程设计?</p><p>各个企业要根据自己的具体情况设计自己使用ERP软件的方式。往往有一种错误的观点，认为这些是咨询顾问的事，他们设计好，公司只要拿来用就行了。事实上，天上不会掉馅饼，咨询顾问是软件方面的专家，但并不是贵公司的专家，也不是企业长久的资源。业务流程的设计应该是中层领导的一个重要责任。</p><p>另外，各个模块的参数决定整个软件系统的运行方式和具体操作。中层领导要了解这些参数的作用，至少要了解那些重要的参数，他们要与咨询顾问一起设置这些参数，一旦需要，他们要能够修改某些参数。</p><p>24.项目核心小组在项目中有什么关键作用?</p><p>核心组成员在实施过程中起着重要的关键作用：传、帮、带。即将ERP思想及软件功能传入企业、向部门传递领导对ERP工作的指示和要求、将部门业务传给实施顾问; 帮助制定业务流程及操作流程、帮助指定人员分工及明确职责、帮助跟进数据及监督项目进度、配合实施顾问工作;带领部门人员收集数据、培训最终用户、指导部门正确使用系统开展业务。</p><p>25.选择项目核心小组成员有哪些要考虑的因素?</p><p>ERP核心组应该是一个有推动力的机构，核心组成员也必须是企业的精英。</p><p>实践证明，顾虑到项目对正常业务的影响，随便从各部门找一些闲人来作为核心组成员的做法都是不可取的。在指定项目核心组人选时，必须慎重考虑这些人员的综合业务的能力及对企业的忠诚。1)核心成员必须是全职的，否则，势必无法兼顾，甚至两头兼失。2)基于项目培训的稳定性和企业数据的安全性考虑，必须选择对企业忠诚的核心成员。</p><p>26.在ERP系统对现有的操作方式或流程的变革浪潮中，怎样才能应变不乱?</p><p>项目组要组织好、员工要参加好充分的用户培训。</p><p>使用ERP系统将在较大程度上改变员工现有的操作方式或流程。如果在系统投入使用前不对用户进行充分的培训，将直接导致大量数据错误或操作错误。而ERP系统是整合性很强的系统，业务的操作会自动在财务中体现出来。若有大量的业务操作失误，财务系统将产生紊乱。这也是部分企业实施ERP失败的原因之一。</p><p>ERP项目是一个涉及到企业全员参与的项目，只要有人不理解这个项目的重要性或是不理解项目与自己岗位业务和关系，就极有可能给ERP项目带来不可估量的巨大风险，因此，培训与宣传的作用应该得到充分的重视。</p><p>27.什么是ERP项目的“三个从来没”和“三个不”?</p><p>项目启动前“从来没听过”，项目实施过程中“从来没明白”，项目上线后对系统“从来没用过”，然后带来项目启动前“不关心”，项目实施中“不支持”，项目上线后“不赞成”。这些都是忽视培训与宣传带来的项目恶果。</p><h2>六、应用问题</h2><p>28.ERP系统没有历史系统方便快捷，是不是根本不符合实际业务需要?</p><p>企业原来如果是使用手工操作、或单一功能的软件操作，在实施ERP，使用新的集成性管理软件的初期，很容易会觉得ERP根本没有原来的操作或系统方便快捷，甚至怀疑ERP是否能够符合实际业务的需要。</p><p>应该承认，使用集成性的ERP软件与手工操作或单一功能的软件有很多区别。它更严格，更规整。例如，ERP软件是付款要对应发票，每笔款项要说明是对应哪一笔发票，或哪几笔发票。而采购发票要对应收货，而我们实际中有些并不作要求。但是，这些看似很死板的地方，从管理的角度去解释中必要的。严格的业务操作保留完整的数据，产生详细的报表，为公司的管理决策提供有力的数据。</p><p>这些都需要领导去理解，解释，也需要最终用户心服口服的坚持运用。</p><p>29.当项目的开展与业务发生冲突时孰重孰轻?</p><p>ERP项目往往是任务艰巨、时间紧迫的，在即有的人力、物力资源条件下，难免会产生项目和实际业务之间的冲突。</p><p>这里以联想ERP成功案例作为借鉴：联想在实施ERP项目的时候，当时的总裁柳传志一开始就明确了业务为项目让路的原则，具体措施表现在：抽调各子公司、各部门精兵强将全职加入项目组工作。另外，只要是ERP项目组要求柳总参加的决策会议，柳场场必到，并且此类决策会议是由副总裁李勤亲自主持，会议还规定：各子公司各部门一把手必须到会，且必须亲自汇报本子公司本部门推进ERP项目的情况及遇到的问题。</p><h2>七、用户培训</h2><p>30.讲师培训是否重要?</p><p>是的，讲师和关键用户作为企业ERP的支撑框架，其重要性是不言而喻的。一方面，他们需要承担最终用户的培训任务，另一方面，他们需要支撑本单位的业务和ERP上线后的滚动培训。</p><p>31.讲师培训的主要目标是什么?</p><p>通过对讲师的培训，使得讲师能支撑织信ERP系统的正常运行和业务流程的优化，熟练处理一些业务突发事件。独立承担系统内业务人员后续培训和本公司业务和支撑，因此企业ERP项目指导委员会决定每个单位派三人参加讲师培训。</p><p>32.讲师培训是否要求考试或者试讲?为什么?</p><p>讲师向最终用户传递知识的主题，因此讲师的素质直接关系到最终用户的培训质量。因此，讲师除了自己必须参加理论考试、上机考试和讲课考核。</p><p>33.最终用户培训是否很重要?</p><p>是的，ERP系统的实施，是企业改革的一个重要的变革过程。而最终用户的培训，是整个ERP变革管理工作中最关键的重心。最终用户培训的质量和效果，将直接关系到织信ERP系统上线成功予否，及改革工作是否能够成功。因此企业各阶层，应该对此次的ERP最终用户培训，予最大的支持。</p><p>34.最终用户培训的主要目标是什么?</p><p>通过最终用户培训可以帮助未来的ERP最终用户了解、理解并逐渐适应系统实施所带来的一系列“变革”;能够正确地掌握未来的业务操作规程、了解ERP的相关知识并具备系统操作能力，从而可以有效地完成相关工作，确保上线后各项业务平稳运行;帮助未来的ERP最终用户学会使用“用户手册”作为日常操作辅助工具，培养独立解决问题的能力。</p><p>35.最终用户培训是否要求考试?为什么?</p><p>是的，各个模块在培训的最后一天都会进行考试。因为考试可以具体了解你在哪些业务操作步骤或系统操作上需要进一步指导;可以帮助项目组从新系统操作人员对新技能的掌握水平上考量系统上线的准备情况。</p><h2>八、数据采集</h2><p>36.为什么要对数据采集人员进行培训?</p><p>ERP是一个全新的系统，它是一个高度集成的管理系统，在整个ERP软件中涵盖了全新的管理理念和管理方法，同时也对进入ERP的数据提出全新的要求。数据必须是“三流合一”，即物流、票据流、信息流高度统一，这些理念是我们以前所未接触过的，但我们现有的数据是相户独立的，没有联系的，因而不符合ERP系统的要求。因此必须对数据采集人员进行的培训，完全理解ERP系统对数据的要求，对现有的数据按ERP有要求重新进行整理和收集，才能保证数据采集和转换工作的顺利进行以及数据的准确完整、高度统一。</p><p>37.数据采集人员培训的主要目标是什么?</p><p>数据采集人员培训的主要目标是让数据采集人员完全了解数据收集模块的格式，对数据采集的每个字段含义理解清楚无误，了解数据采集的范围及注意事项，保证整个采集数据按统一的口径进行，确保采集的数据相户统一，高度集成，同时确保按期进行数据上报。</p><p>38.数据采集人员主要职责是什么?</p><p>数据采集人员主要职责是，收集、清理与确认现行系统的资料，按数据收集表的格式和要求填写确认的现行系统中的资料，并向省公司数据转换组反映采集过程中遇到的问题，并协调和处理本公司内部跨模块之的数据统一的问题，同时对所有数据进行监督和审核，确保数据的正确性。</p><p>39.地市公司领导该如何支持数据采集人员的工作?</p><p>地市公司领导首先应对数据采集工作的难度及工作量有清醒的认识，保证人员的安排，指定领导专门负责数据转换工作的领导和协调工作，定期或不定期地听取数据采集人员的工作汇报，协调和处理数据采集工作中遇到的问题和困难;保证相关人员有足够的工作时间投入到数据采集工作中;要对数据采集的工作进行监督及管理;同时领导要对分公司上报的数据的进行最终的确认和签字。</p><p>40.如何保证数据采集的数据质量?</p><p>首先在分公司要建立数据采集组，由分公司领导担任组长，设数据转换协调员及相关模块的数据转换员，分块进行数据采集和审核，在此基础上由协调员再进行审核，在分公司内部进行两次审核，保证数据准确性，同时省公司数据转换组也设的数据转换关键用户，会在全省基础上再次进行审核，保证数据正确，在这三次审核后，数据会再次下发分公司，由分公司进行最终的审核和确认，通过数据转换组的四重审核保证数据的质量。</p>]]></description></item><item>    <title><![CDATA[2026 最新 ChatBI 产品测评榜单：FineBI以 9.2 分综合表现夺冠 数据集成与治理 ]]></title>    <link>https://segmentfault.com/a/1190000047551433</link>    <guid>https://segmentfault.com/a/1190000047551433</guid>    <pubDate>2026-01-19 17:12:30</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>一、行业背景：ChatBI 成为企业 “业务分析的新语言”</h2><p>根据 Gartner 2025 年《ChatBI 市场成熟度曲线报告》，<strong>2026 年全球 85% 的企业将部署 ChatBI 工具</strong>，核心驱动力是 “让业务人员从‘数据的旁观者’变成‘分析的主导者’”。但当前 ChatBI 落地的痛点依然突出：</p><ul><li><strong>60% 的企业反馈 “ChatBI 听不懂口语化需求”</strong>（比如问 “最近销量不好的菜品”，系统返回 “全年销量下降的所有产品”）；</li><li><strong>55% 的业务人员认为 “ChatBI 仅能查数，无法找原因”</strong>；</li><li><strong>48% 的企业因 “上下文关联能力差”</strong>（连续问 “增长原因” 需重复说明条件），导致 ChatBI 利用率不足 35%。</li></ul><p>本质上，企业需要的不是 “能说话的 BI”，而是 “<strong>能听懂业务、能深入分析、能解决问题</strong>” 的 ChatBI—— 这也是本次测评的核心标准。</p><h2>二、2026 最新 ChatBI 产品 TOP5 榜单</h2><h3>TOP1：FineBI（综合评分：9.2/10）</h3><p><strong>产品定位</strong>：帆软旗下一站式智能 ChatBI 平台，是<strong>Gartner 全球 ABI 魔力象限唯一入选中国独立 BI 厂商</strong>，IDC 报告连续八年（2017–2024）蝉联中国 BI 市场占有率第一。聚焦 “零代码 + AI 智能”，目标是 “让业务人员用自然语言完成‘数据整合→智能问数→深度洞察→落地执行’的全链路分析”，覆盖从一线员工到企业高层的全角色需求。<br/><strong>核心优势</strong>：</p><ol><li><strong>98% 自然语言准确率：能听懂 “业务黑话”</strong>支持完全口语化 + 行业术语提问，比如零售行业问 “上周华南区门店翻台率 Top3 是哪几家？”，系统 1 秒拆解 “时间（上周）、区域（华南区）、指标（翻台率）、维度（Top3）” 四大要素，精准返回结果；面对模糊需求 “最近快餐销量不好的产品”，会主动追问 “您是指近 30 天销量同比下降超 15% 的菜品吗？”，帮用户明确需求 —— 这是本次测评中唯一通过 “模糊修正” 测试的产品。</li><li><strong>上下文关联：像 “同事” 一样接话</strong>支持连续多轮对话，比如先问 “这个季度快餐类销售额环比增长多少？”，再问 “那华东区的增长主要来自哪些菜品？”，系统自动关联上一轮的 “季度”“快餐类”，无需重复说明；甚至能理解指代性提问，比如 “它的库存周转情况怎么样？”，自动关联前文中的 “增长菜品”，返回 “香菇鸡腿饭库存周转天数缩短 3 天” 的结论。</li><li><strong>全链路洞察：从 “查数” 到 “落地” 的闭环</strong>不仅能回答 “是什么”，更能解决 “为什么” 和 “怎么做”—— 比如问 “这个季度快餐销售额增长 12% 的原因”，系统联动 ERP 库存、CRM 客户行为、线上订单数据，生成结论：“增长主要来自华东区新品‘香汁排骨饭’，占比 28%，建议加大该菜品在华南区的促销力度”，直接给出可执行建议。</li><li><strong>零代码适配企业数据：不用 IT 也能连</strong>支持 200+ 数据源（Excel、SQL Server、钉钉、企业微信等），业务人员无需 IT 协助，直接通过 “拖拽 + 自然语言” 整合数据 —— 比如要分析 “线上订单与线下门店库存的关联”，只需说 “连接线上订单和线下库存数据”，系统自动完成数据映射，5 分钟内即可使用。</li></ol><p><strong>适用场景</strong>：</p><ul><li>基础场景：业务人员日常查数（运营问 “今日线上订单量”、店长问 “门店今日坪效”）；</li><li>进阶场景：自助探索分析（市场部找 “快餐类销量下滑的原因”，联动渠道、地域、人群维度）；</li><li>深度场景：跨部门协作（财务问 “快餐类成本与销售额的关联”，无需 IT 整合 ERP 与 CRM 数据）；</li><li>战略场景：高层决策支持（CEO 问 “2026 年快餐类增长的核心驱动力”，系统自动生成多维度洞察报告）。</li></ul><p><strong>真实案例：</strong>作为连续 6 年全国奶茶销量领先企业（年销 10 亿杯），香飘飘曾因 “库存高、人员效率低、部门信息割裂” 陷入增长瓶颈 —— 生产靠经验导致临期损耗高，销售数据仅后台可见，前端无法及时调整策略。<br/>引入帆软<strong>AI 驱动的智能数据分析平台</strong>后，香飘飘搭建了<strong>智能销售日报体系</strong>：通过 AI 算法整合跨系统数据（销售、库存、会员），每天 8 点前自动生成<strong>个性化销售日报</strong>，通过微信推送给 2000 + 前端销售人员，实时呈现 “业绩完成率、区域排名、重点商品动销” 等 KPI。<br/><strong>效果</strong>：销售人员从 “月底等结果” 转向 “每日看数据调整”，库存折价损失下降 20%；团队劳效提升 27%，还推动仓库 WM 条码系统上线（解决出库数据实时性问题）。智能数据工具成了前端销售的 “实时参谋”，让扁平化渠道管理更精准，巩固了行业龙头地位。。</p><h3>TOP2：Amazon QuickSight Q（综合评分：8.9/10）</h3><p><strong>产品定位</strong>：亚马逊云科技旗下云原生智能 ChatBI 工具，聚焦 “AWS 生态 + 多模态交互”，适合<strong>AWS 用户的快速数据分析</strong>。<br/><strong>核心优势</strong>：</p><ul><li>AWS 数据源深度整合：直接连接 S3、Redshift、RDS 等，问 “云存储中的订单数据” 无需额外配置；</li><li>多模态交互：支持 “文字 + 图表” 联动，问 “季度销售额” 自动生成折线图，点击图表可直接提问 “这个月下降的原因”；</li><li>智能推荐：根据历史查询习惯，推荐 “可能感兴趣的分析”（比如 “您之前查过销售额，是否想了解利润情况？”）。</li></ul><p><strong>适用场景</strong>：AWS 生态企业、云数据用户、喜欢可视化交互的业务人员。</p><h3>TOP3：IBM Cognos Analytics with Watson（综合评分：8.7/10）</h3><p><strong>产品定位</strong>：IBM 旗下企业级 ChatBI 平台，以 “Watson AI + 企业级数据治理” 为核心，适合<strong>合规需求强的大型企业</strong>。<br/><strong>核心优势</strong>：</p><ul><li>因果推理：支持 “为什么” 型提问，比如 “销售额增长的原因”，会返回 “因果路径图”（新品→客单价→销售额），帮业务人员理解逻辑；</li><li>多语言支持：覆盖 10+ 语言，适合跨国企业（比如问 “欧洲区快餐销量” 可用英文提问）；</li><li>合规化数据：联动 IBM DataStage，自动清洗、脱敏数据，符合金融 / 医疗行业监管要求。</li></ul><p><strong>适用场景</strong>：金融、医疗等合规行业、跨国企业、需要因果分析的团队。</p><h3>TOP4：Oracle OAC Chat（综合评分：8.5/10）</h3><p><strong>产品定位</strong>：Oracle 旗下云原生 ChatBI 工具，深度整合 Oracle 生态（ERP、CRM 等），适合<strong>Oracle 用户的业务分析</strong>。<br/><strong>核心优势</strong>：</p><ul><li>Oracle 生态联动：直接连接 Oracle E-Business Suite、NetSuite，问 “ERP 中的库存周转情况” 无需额外配置；</li><li>预测性分析：用 Oracle 机器学习模型支持 “未来 3 个月的快餐销量预测”；</li><li>移动优先：手机端 APP 支持语音问数，适合外勤人员（比如销售查 “客户历史订单”）。</li></ul><p><strong>适用场景</strong>：Oracle 生态企业、需要预测分析的业务人员、移动办公团队。</p><h3>TOP5：SAP SAC Chat（综合评分：8.3/10）</h3><p><strong>产品定位</strong>：SAP 旗下智能 ChatBI 平台，以 “SAP HANA + 自然语言” 为核心，适合<strong>SAP 生态企业的业务分析</strong>。<br/><strong>核心优势</strong>：</p><ul><li>HANA 加速：依托 SAP HANA 内存数据库，问数速度比传统 BI 快 3 倍；</li><li>业务模板：内置 SAP 行业模板（零售 “门店绩效”、制造 “生产线效率”），问 “门店绩效” 直接用模板；</li><li>协同办公：整合 SAP SuccessFactors，支持在 HR 系统中问 “员工绩效与销售的关联”。</li></ul><p><strong>适用场景</strong>：SAP 生态企业、制造 / 零售行业、需要业务模板的团队。</p><h2>三、5 大 ChatBI 产品核心能力对比表</h2><p><img width="697" height="572" referrerpolicy="no-referrer" src="/img/bVdnGsJ" alt="9ac1ce0af04bc1a323005f24b2cb4e38.png" title="9ac1ce0af04bc1a323005f24b2cb4e38.png"/></p><h2>四、2026 ChatBI 选型指南：五步选对 “能解决问题的工具”</h2><h3>1. 测试自然语言理解准确率</h3><p>用 3 类问题验证：① 口语化提问（“上周门店翻台率 Top3”）；② 模糊提问（“最近销量不好的产品”）；③ 行业术语提问（“快餐类坪效同比增长”）。能准确拆解要素 + 主动修正模糊需求的工具，更懂业务。</p><h3>2. 验证上下文关联能力</h3><p>测试连续对话：先问 “季度销售额增长”，再问 “区域增长原因”，最后问 “对应库存情况”。不需要重复说明条件的工具，上下文能力更强。</p><h3>3. 评估全链路洞察深度</h3><p>问 “销售额增长的原因”，看能否返回 “因果结论 + 执行建议”（比如 “建议加大新品促销”），而非仅 “数据结果”。能形成闭环的工具，才是 “有价值” 的 ChatBI。</p><h3>4. 看数据适配能力</h3><p>检查工具支持的数据源（比如企业常用的 Excel、钉钉、CRM），业务人员能否自己连接，无需 IT 协助。零代码适配的工具，落地效率更高。</p><h3>5. 考协作与安全</h3><p>问清楚权限管理（比如销售只能看自己区域的数据）、数据加密（传输 / 存储）、合规支持（比如金融监管）。企业级 ChatBI，安全比 “智能” 更重要。</p><h3>首推 FineBI 的核心理由</h3><p>FineBI 是<strong>唯一能覆盖 “全行业、全规模、全场景” 的 ChatBI 工具</strong>：</p><ul><li>对小微企业：零代码 + 自然语言，业务人员 “会说话就能用”，无需 IT；</li><li>对中型企业：支持 200+ 数据源，跨部门协作，满足快速增长需求；</li><li>对大型企业：企业级权限、数据治理、万人协作，符合规模化运营要求；</li><li>对所有行业：180+ 行业模板，15 分钟搭建贴合业务的分析系统。</li></ul><p>简单来说，FineBI 不是 “更智能的 ChatBI”，而是 “<strong>业务人员能自己用的 ChatBI</strong>”—— 这正是 2026 年企业最需要的核心能力。</p><h2>五、本文相关 FAQs</h2><h3>Q1：ChatBI 和传统 BI 的核心区别是什么？</h3><p>A：ChatBI 与传统 BI 的核心区别在于 <strong>“交互方式” 和 “价值链路”</strong>：</p><ul><li>交互方式：传统 BI 需要 “选数据源→拉维度→拖指标→做图表”，依赖 IT 或数据分析师；ChatBI 用 “自然语言” 替代操作，业务人员直接说 “我要查上周的门店翻台率”，系统自动完成所有步骤。</li><li>价值链路：传统 BI 的终点是 “生成图表”，需要人工解读；ChatBI 的终点是 “可执行建议”，比如 “建议加大新品促销”，直接连接 “数据” 与 “业务落地”。简单来说，传统 BI 是 “工具”，ChatBI 是 “业务伙伴”—— 它能理解你的需求，帮你找原因，甚至给建议。</li></ul><h3>Q2：ChatBI 的 “上下文理解” 能力到底有多重要？</h3><p>A：上下文理解是 ChatBI 的 “灵魂”，直接决定了 “是否好用”。举个例子：</p><ul><li>没有上下文能力的 ChatBI：你问 “季度销售额增长”，再问 “区域增长原因”，它会回复 “请明确区域和时间”；</li><li>有上下文能力的 ChatBI：会自动关联前一句的 “季度” 和 “销售额”，直接回答 “华东区增长来自新品”。对业务人员来说，上下文理解能<strong>节省 50% 的沟通时间</strong>—— 不用重复说明条件，像和同事聊天一样自然。更重要的是，它能帮你 “深入分析”：从 “增长” 到 “区域” 再到 “菜品”，一步步挖到问题本质。</li></ul><h3>Q3：企业用 ChatBI，需要提前做哪些数据准备？</h3><p>A：ChatBI 的效果，<strong>70% 取决于数据基础</strong>，提前要做 3 件事：</p><ol><li><strong>数据整合</strong>：把分散在 Excel、CRM、ERP 中的数据，集中到一个可访问的地方（比如数据仓库）——ChatBI 无法关联分散的数据，结果会不准；</li><li><strong>数据清洗</strong>：处理重复值、缺失值（比如 “销售额” 字段不能有空白），确保数据 “干净”；</li><li><strong>定义业务逻辑</strong>：统一关键指标的计算方式（比如 “翻台率 = 接待客数 / 门店桌数”），避免 “财务算的翻台率和运营算的不一样”。其实这些准备不是 “为了 ChatBI”，而是企业数据管理的基础 ——ChatBI 只是帮你 “用好” 这些数据而已。</li></ol><p><strong>结语</strong>：2026 年，ChatBI 不再是 “可选项”，而是 “必选项”。但选对工具比 “追热点” 更重要 ——FineBI 用 “能听懂业务、能深入分析、能解决问题” 的核心能力，成为本次测评的 “夺冠者”。对企业来说，选择 FineBI，就是选择 “让业务人员真正掌握数据的权力”。</p>]]></description></item><item>    <title><![CDATA[中小企业省钱 vs 大企业省心：2026 年企业如何选到最适合的 BI 工具？ 数据集成与治理 ]]></title>    <link>https://segmentfault.com/a/1190000047551447</link>    <guid>https://segmentfault.com/a/1190000047551447</guid>    <pubDate>2026-01-19 17:11:51</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>一、引言：为什么 80% 的企业选 BI 都 “没踩到点”？</h2><p>在 “数字化要落地” 的 2026 年，企业选 BI 的核心矛盾早已不是 “要不要上”，而是 “能不能贴合自身需求”：</p><ul><li>中小企业吐槽 “花了 8 万买 BI，业务人员学了 3 周还不会用，报表还是靠 Excel”；</li><li>大企业抱怨 “投了百万建 BI，却连‘产线良率下降的根因’都查不清，数据还是散在各个系统里”。<strong>本质问题</strong>：没抓住 “企业规模的核心需求”—— 中小企业要的是 “<strong>低成本、低门槛、快速出结果</strong>”，大企业要的是 “<strong>全链路整合、深度适配业务、长期运营支撑</strong>”。</li></ul><h2>二、中小企业选 BI 的 3 个 “实战标准”：不用 IT，业务自己就能玩</h2><p>中小企业的核心痛点是 “IT 人少（通常 1-3 人）、预算有限（年投入≤20 万）、要快速看到业务价值”，选 BI 必须满足 3 个 “能落地” 的标准：</p><h3>1. 操作门槛：业务人员 “零 SQL 基础” 就能上手</h3><p>中小企业 IT 团队根本没时间 “每周帮业务做 10 张报表”。BI 工具必须支持<strong>拖拽式建模 + 自然语言问数</strong>—— 比如想查 “上月老人鞋库存周转天数”，直接拖 “库存数量”“销售数量” 字段到画布，或打字 “上月老人鞋库存周转天数”，10 秒就能出结果，不用找 IT 写 SQL。</p><h3>2. 性价比：不买 “冗余功能”，只付 “用得到的钱”</h3><p>中小企业不需要 “企业级数据仓库”“AI 算法平台”，更需要 “按需订阅”—— 比如只买 “库存管理 + 会员分析” 模块，或按用户数付费（最低 5 万 / 年），避免 “花 10 万买了 100 万的功能”。</p><h3>3. 见效速度：1-2 周落地，1 个月看到 “真金白银” 的效果</h3><p>中小企业等不起 “3 个月实施”，必须有<strong>行业预制模板</strong>—— 比如零售行业有 “库存周转模板”“产销协同模板”，直接对接 POS、库存系统，1 周就能生成 “库存积压预警报表”，快速解决 “缺货 / 积压” 问题。</p><h2>三、大企业选 BI 的 3 个 “实战标准”：能扛住 “复杂业务” 的考验</h2><p>大企业的核心痛点是 “数据孤岛多（≥5 个系统）、业务逻辑复杂（比如制造企业的产线良率分析）、要支撑战略决策”，选 BI 必须满足 3 个 “深适配” 的标准：</p><h3>1. 数据整合：能打通 200 + 数据源，消灭 “信息孤岛”</h3><p>大企业有 SAP、Oracle、MES、SCM 等多个系统，BI 工具必须支持<strong>200 + 数据源对接</strong>—— 比如把 “产线良率数据（MES）”“库存数据（ERP）”“供应链数据（SCM）” 整合到一个平台，才能分析 “良率下降是不是因为某批原材料质量差”。</p><h3>2. 业务适配：能 “定制”，不搞 “一刀切”</h3><p>大企业的业务不是 “标准模板” 能覆盖的 —— 比如航空制造企业要 “定制到期未领物资管控”，零售企业要 “定制全渠道会员画像”。BI 工具必须支持<strong>自定义报表逻辑 + 智能洞察</strong>—— 比如设置 “当产线良率低于 95% 时，自动分析设备参数、原材料、工人操作 3 个维度的原因”。</p><h3>3. 长期运营：有 “服务”，不是 “卖完软件就不管”</h3><p>大企业的 BI 项目是 “长期工程”，不是 “一次性采购”。必须选<strong>有行业服务经验 + 生态兼容</strong>的厂商 —— 比如能对接 SAP、Oracle 等主流系统，提供 “驻场实施 + 7×24 运维 + 定期迭代” 的服务，避免 “系统上线后没人维护”。</p><h2>四、案例验证：FineBI 如何 “精准匹配” 大 / 中小企业的需求？</h2><h3>1. 中小企业案例：足力健老人鞋 —— 用 FineBI 解决 “产销协同” 痛点</h3><p><strong>企业背景</strong>：专业老人鞋品牌，线下门店 3200+，全渠道布局，年营收超 10 亿。<br/><strong>核心痛点</strong>：POS、库存、会员系统未打通，产销协同难 ——2024 年 Q3 某款棉鞋积压 1.2 万双，同期秋季单鞋缺货 3000 双。<br/><strong>FineBI 落地逻辑</strong>：</p><ul><li>用<strong>拖拽式建模</strong>快速对接 POS、库存、会员 5 个系统，1 周完成数据整合；</li><li>用<strong>零售行业预制模板</strong>生成 “产销协同看板”，实时显示 “销售需求 - 库存数量 - 生产计划”；</li><li>用<strong>自然语言问数</strong>让业务人员自主查询 “下月老人鞋生产计划”，不用找 IT。</li></ul><p><strong>落地效果</strong>：</p><ul><li>供应链管理效率提升 40%，减少库存积压与缺货损失 30 万元；</li><li>生产可视化看板让产量提升 30%（2024 年 Q4 单鞋产量从 8 万双增至 10.4 万双）；</li></ul><h3>2. 大企业案例：西安飞机工业集团 —— 用 FineBI 解决 “库存积压 + 采购监控” 痛点</h3><p><strong>企业背景</strong>：科研生产一体化特大型航空工业企业，年营收超 200 亿，旗下 5 个制造基地、100 + 供应商（大企业规模）。<strong>核心痛点</strong>：</p><ul><li>库存积压：某类航空零部件库存周转 60 天（行业平均 40 天），占压资金 8000 万；</li><li>人工低效：每月统计 “到期未领物资” 需 5 天，易漏统（比如某车间 100 套零部件）；</li><li>决策滞后：无法实时监控采购进度，导致生产计划延迟。</li></ul><p><strong>FineBI 落地逻辑</strong>：</p><ul><li>用<strong>多源数据整合</strong>对接 ERP、MES、SCM 等 8 个系统，3 个月打通 “库存 - 采购 - 生产” 全链路数据；</li><li>用<strong>自定义报表逻辑</strong>定制 “到期未领管控中心”，自动预警即将过期的物资；</li><li>用<strong>自助分析看板</strong>让采购部门实时查看 “原材料到货时间”，避免生产延迟。</li></ul><p><strong>落地效果</strong>：</p><ul><li>降低库存金额 5000 万以上（2023 年上线后）；</li><li>每年节约人工成本 500 万元，工作效率提升 10 倍；</li><li>生产计划延迟率从 15% 降至 3%。</li></ul><h2>FineBI 的 “通用优势”：为什么能覆盖大 / 中小企业的需求？</h2><p>FineBI 作为<strong>Gartner 全球 ABI 魔力象限唯一入选的中国独立 BI 厂商</strong>（2024 年）、<strong>IDC 连续 8 年（2017-2024）中国 BI 市场占有率第一</strong>的工具，其核心优势刚好匹配大 / 中小企业的 “差异化需求”：</p><ul><li><strong>对中小企业</strong>：拖拽式操作 + 自然语言问数降低门槛，行业预制模板快速见效，按需付费控制成本；</li><li><strong>对大企业</strong>：200 + 数据源整合消灭信息孤岛，自定义报表适配复杂业务，驻场服务支撑长期运营。</li></ul><h2>五、结尾：选 BI 的本质，是 “选匹配自身需求的工具”</h2><p>2026 年企业选 BI，<strong>不是选 “最贵的”，而是选 “最适合的”</strong>—— 中小企业不要贪 “企业级功能”，大企业不要省 “定制化服务”。FineBI 的价值在于：它不搞 “版本分化”，而是用 “通用功能” 精准匹配不同企业的核心需求 —— 无论是中小企业要的 “快速见效”，还是大企业要的 “深度适配”，都能通过 “拖拽式分析、多源整合、行业模板、自定义逻辑” 等功能实现。毕竟，<strong>数字化的核心是 “用数据解决业务问题”，不是 “买一套复杂的工具”</strong>。</p>]]></description></item><item>    <title><![CDATA[校园食堂订餐微信小程序系统 —— 高效解决校园配餐管理难题 微擎应用市场 ]]></title>    <link>https://segmentfault.com/a/1190000047551450</link>    <guid>https://segmentfault.com/a/1190000047551450</guid>    <pubDate>2026-01-19 17:10:55</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><strong>一、概述总结</strong><br/>校园食堂订餐微信小程序系统是一款专为学校午餐配餐与午托服务打造的数字化管理工具，支持微信小程序与微信公众号双端适配，通过微擎系统在线交付，源码未加密且兼容 PHP5.6 至 PHP7.4 多种版本，为学校、家长提供便捷、高效的订餐与管理解决方案。系统以 “自愿报名” 为服务原则，聚焦校园配餐场景核心需求，实现套餐自定义设置、多学生订餐管理、请假报备、数据统计等一体化功能。无论是学校的配餐统筹管理，还是家长的便捷订餐操作，都能通过该系统得到全方位满足，有效提升校园配餐服务的规范化与高效性。</p><p><strong>二、功能介绍</strong><br/>（一）核心操作功能<br/>套餐灵活配置：支持自定义设置套餐价格、使用天数、开始与结束日期，目前已适配 “午餐 + 午休” 等主流套餐类型，学校可根据实际服务内容灵活调整，满足不同年级、不同需求的配餐安排。</p><p>多学生订餐管理：家长前台可添加多个学生信息并选择对应套餐购买，无需重复操作，方便多孩家庭或代订餐场景使用；系统后台可清晰查看订餐人姓名、年级、班级、身份证号、支付金额、服务天数等详细信息，便于统计核对。</p><p>请假报备功能：学生因研学、事假等原因无需备餐时，家长可通过系统提前提交请假申请，注明请假时间与备注信息，学校后台实时接收请假记录，避免食材浪费，保障配餐精准度。</p><p>全面记录查询：家长端可随时查看订餐记录、取消记录、请假记录，清晰掌握消费情况与服务安排；学校端可导出各类记录数据，便于台账管理与财务核算。</p><p>（二）后台管理功能<br/>多模块统筹管理：后台涵盖用户列表、套餐管理、订餐管理、学生管理、请假管理、系统设置六大核心模块，管理员可一站式完成信息维护、业务审核与系统配置。</p><p>精准数据统计：支持按学生姓名、年级、班级、套餐名称等关键词搜索查询，快速统计订餐人数、请假数据、支付总额等关键信息，减少人工统计工作量。</p><p>信息灵活操作：可对学生信息、会员信息、订餐记录、请假记录进行添加、修改、删除等操作，支持批量删除功能，提升管理效率；同时可设置系统基础信息，包括 logo、订餐须知、轮播图、跳转链接等，打造个性化服务页面。</p><p>安全权限控制：支持会员拉黑管理，可查看会员注册时间、最后登录时间与 IP 来源，保障系统使用安全；严格遵循线上交易规范，规避线下交易带来的欺诈、纠纷风险。</p><p>（三）适配与保障功能<br/>多端适配支持：同时适用微信小程序与微信公众号，家长无需下载额外 APP，通过微信即可完成订餐、请假等操作，降低使用门槛。</p><p>技术兼容保障：兼容 PHP5.6、PHP7.1 至 PHP7.4 等多个版本，适配不同服务器环境；源码未加密，方便学校根据个性化需求进行二次开发与功能拓展。</p><p><strong>三、适用场景与行业价值</strong><br/>（一）适用场景<br/>中小学配餐管理：适配小学、初中等不同学段，尤其适合校园自建厨房提供午餐与午托服务的学校，解决学生多、配餐统计难、请假报备不及时等问题。</p><p>多校区统一管理：支持多个学校选择配置，可满足教育集团、学区统筹管理配餐服务的需求，实现多校区数据集中管理与统一调度。</p><p>家长便捷订餐需求：适用于需要为孩子预订校园午餐与午休服务的家长，尤其是多孩家庭、双职工家庭，通过手机快速完成订餐与请假操作，节省时间成本。</p><p>（二）行业价值<br/>提升学校管理效率：通过数字化手段替代人工统计、纸质报备，减少订餐核对、请假统计等重复性工作，降低管理成本，同时避免人为失误导致的配餐浪费或遗漏。</p><p>保障配餐服务质量：校园自建厨房模式下，系统精准统计订餐人数，便于学校合理采购食材、安排餐食制作，结合严格的食品安全与品质管理，确保学生吃饱吃好；午休服务配套管理功能，助力学校保障午休效果与安全。</p><p>优化家长服务体验：家长随时可通过微信操作订餐、查询记录、提交请假，无需线下沟通或填写表格，信息透明可追溯，提升家长对校园配餐服务的满意度与信任度。</p><p>规范行业服务标准：通过统一的系统流程实现报名缴费、订餐管理、请假报备等环节的规范化，符合市教育局学生配餐工作要求，推动校园配餐服务走向标准化、数字化。</p><p><strong>四、问答环节</strong><br/>该系统支持哪些使用平台？</p><p>答：支持微信小程序与微信公众号双端使用，家长无需下载 APP，通过微信即可完成各项操作。</p><p>学校能否根据自身需求调整套餐内容？</p><p>答：可以，系统支持自定义设置套餐价格、使用天数、开始与结束日期，学校可根据实际提供的服务（如仅午餐、午餐 + 午休等）灵活配置套餐。</p><p>家长如何为多个孩子订餐？</p><p>答：前台支持添加多个学生信息，家长可一次性为多个孩子选择对应套餐购买，无需重复操作，方便快捷。</p><p>学生需要请假时，如何操作才能避免浪费餐食？</p><p>答：家长可通过系统提前提交请假申请，注明请假时间与备注（如研学、事假等），学校后台实时接收记录，可精准调整配餐数量，避免食材浪费。</p><p>系统兼容哪些服务器环境？是否支持二次开发？</p><p>答：兼容 PHP5.6、PHP7.1 至 PHP7.4 多个版本，适配多数服务器环境；源码未加密，支持学校根据个性化需求进行二次开发。</p><p>学校管理员能否导出订餐、请假等数据？</p><p>答：可以，系统支持导出会员列表、订餐记录、请假记录等数据，便于学校进行台账管理与财务核算。</p>]]></description></item><item>    <title><![CDATA[学习任务考试微信公众号系统：一站式在线学习与考核解决方案 微擎应用市场 ]]></title>    <link>https://segmentfault.com/a/1190000047551460</link>    <guid>https://segmentfault.com/a/1190000047551460</guid>    <pubDate>2026-01-19 17:10:07</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><strong>一、概述总结</strong><br/>这款学习任务考试微信小程序插件是《在线考试》的专属配套工具，需先安装《在线考试》主程序方可使用，不支持单独运行。插件以 “任务驱动 + 考试检验” 为核心逻辑，通过后台精准下达包含视频、音频、文章等多种形式的学习任务，指定任务对象、时间范围及完成要求，学生在微信公众号端的 “我的任务” 中按要求计时完成各项学习内容后，需参加通关考试，考试及格方可认定大任务完成，不及格则需重考。插件采用微擎系统交付模式，支持 PHP5.3 至 PHP7.2 多种版本环境，源码经过加密处理，保障官方正品权益，能全面满足在线学习与考核的闭环管理需求。</p><p><strong>二、功能介绍</strong><br/>（一）后台管理功能<br/>任务发布与管理：可自定义任务标题、任务对象、开始 / 结束时间及排序优先级，灵活选择任务包含的收听音频、观看视频、阅读文章等内容，支持对任务进行上架、编辑等操作。</p><p>考试设置功能：可关联考试分类、选择考试试卷及证书模板，设定答题时间（留空或为 0 则不限制）、考试次数及补考次数，支持 “完成学习任务才可考试”“随时可以考试”“不需要考试” 三种通关类型选择。</p><p>资源管理功能：涵盖视频管理、音频管理、文章管理及分类管理，支持添加分类、上传媒体文件（手机端仅支持 mp4 格式视频），可设置资源的观看 / 收听时间及完成任务后可获得的积分。</p><p>数据统计分析：可查看学生任务完成情况、考试成绩，包含考试人数、最高分、最低分、平均分统计，支持分数段分布统计，以及答错（含未答）题排行、答对题排行、未答题排行查询，直观掌握学习与考核效果。</p><p>基础设置与权限管理：可获取用户微信昵称、头像、性别、地区等信息及位置信息、相册权限，支持对任务和资源进行多级分类管理，保障系统有序运行。</p><p>（二）前端学生使用功能<br/>任务查看与执行：在 “我的任务” 中可清晰查看所有已发布任务，包括任务包含的学习内容、要求完成时间、需观看 / 收听 / 阅读的时长及当前进度、已获积分等信息，按提示逐一完成视频观看、音频收听、文章阅读等小任务。</p><p>在线考试功能：完成指定学习任务后，可进入通关考试环节，按设定的答题时间和考试规则完成试卷作答，提交后即时知晓考试结果，不及格可按规定进行补考。</p><p>个人中心功能：包含首页、我的视频、我的班级、错题集、我的收藏等模块，可查看学习记录、错题回顾、已获积分等信息，方便自主管理学习过程。</p><p><strong>三、适用场景与行业价值</strong><br/>（一）适用场景<br/>企事业单位及各类机构：包括工厂、农场、服务酒店等，可用于企业内训，通过指定员工完成计时阅读文档、观看培训视频、收听音频资料后参加考试，以考试及格作为内训成功的标准，规范培训流程。</p><p>教育培训机构与学校：适用于 K12 阶段及各类职业教育机构，可针对学生发布单元学习任务、课后复习任务等，让学生在线阅读教材资料、观看教学视频、收听辅导音频后进行单元测试，巩固学习成果。</p><p>（二）行业价值<br/>对企业而言：简化内训组织流程，无需线下集中培训，降低培训时间与人力成本；通过计时学习 + 考试检验的模式，确保员工真正掌握培训内容，提升内训质量与效率，助力企业人才能力提升。</p><p>对教育机构与学校而言：丰富教学组织形式，突破时间与空间限制，方便学生自主安排学习；借助后台数据统计功能，教师可精准掌握学生学习进度与知识薄弱点，实现个性化教学指导，提升教学效果；通过积分激励与通关考试机制，激发学生学习主动性，培养自主学习能力。</p><p><strong>四、问答环节</strong><br/>这款插件可以单独使用吗？<br/>答：不可以，该插件是《在线考试》的专属插件，必须先购买安装好《在线考试》主程序后，才能正常使用。</p><p>插件支持哪些运行环境？</p><p>答：支持 PHP5.3、PHP5.4、PHP5.5、PHP5.6、PHP7.1、PHP7.2 版本环境，适用于微信公众号平台。</p><p>后台能否查看学生的学习和考试情况？</p><p>答：可以，后台可查看学生任务完成情况、考试成绩，包含考试人数、最高分、最低分、平均分、分数段统计及错题排行等详细数据。</p><p>学生完成学习任务后，考试有次数限制吗？</p><p>答：考试次数和补考次数可由后台自定义设置，留空或设为 0 则不限制考试次数，满足不同场景下的考核需求。</p><p>手机端支持上传什么格式的视频？</p><p>答：手机端仅支持 mp4 格式的视频，不支持其他格式的视频上传。</p>]]></description></item><item>    <title><![CDATA[实用指南：构建工业AI原生企业的关键步骤与成功案例 雨大王 ]]></title>    <link>https://segmentfault.com/a/1190000047551463</link>    <guid>https://segmentfault.com/a/1190000047551463</guid>    <pubDate>2026-01-19 17:09:28</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>制造业正站在一个新的十字路口。当我们谈论工业AI原生企业时，实际上是在讨论一种全新的生产范式。它不再局限于传统的单点智能应用，而是将AI深度嵌入企业价值链的每个环节，形成一个自我进化、持续优化的智能生态系统。<br/>从技术工具到运营基础设施：工业AI原生企业的本质<br/>工业AI原生企业，这个概念远比表面看到的要深刻得多。它代表着AI已经从一个独立的技术工具，转变为支撑企业运营的基础设施。就像水电一样，AI不再需要作为外挂组件存在，而是直接融入企业的血液中。这种转变对制造业产生了革命性影响。<br/>在传统制造模式下，企业的AI应用往往存在明显的割裂感。技术部门负责开发，业务部门负责使用，两者互不相通。而工业AI原生企业则打破了这种壁垒，让AI真正成为业务流程的一部分。<br/>构建工业AI原生企业的核心路径<br/>要实现工业AI原生转型，企业需要的是一套完整的解决方案。首先，平台是基础。Geega OS工业操作系统作为底层支撑，为上层应用提供了坚实基础。它不仅能统一数据格式和规范，还能实现跨域数据引擎贯通，让不同部门的数据无缝连接。<br/>其次，数据是血液。工业AI原生企业需要建立高效的数据治理体系，通过多源数据融合更精准地刻画与指导生产现场。最后，场景是灵魂。没有实际应用场景的支撑，再强大的AI平台也只是空中楼阁。在这方面做出了表率，他们将AI技术深度融入研发、生产、运营等各个环节，形成了覆盖全链路的智能体矩阵。<br/>工业AI原生企业的实践案例<br/>在众多行业实践中，工业AI原生企业展现出强大的生命力。以汽车制造业为例，领克成都工厂通过广域铭岛的Geega平台实现了全链路数据增值服务，质量损失成本降低13%，订单交付周期缩短15%，物流调度效率提升10%。</p>]]></description></item><item>    <title><![CDATA[告别 Excel 报表！商业智能工具如何让数据分析效率提升 10 倍 数据集成与治理 ]]></title>    <link>https://segmentfault.com/a/1190000047551466</link>    <guid>https://segmentfault.com/a/1190000047551466</guid>    <pubDate>2026-01-19 17:08:40</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>一、引言：Excel 的 “效率陷阱”，为何成了企业的 “通用痛点”？</h2><p>每月中旬，无数企业的数据分析人员都会陷入同一个 “Excel 循环”：从 ERP 导出销售数据，从库存系统复制损耗明细，从采购系统粘贴批次信息，再用 VLOOKUP、数据透视表来回合并 —— 这不是某家企业的特例，而是<strong>零售行业的普遍困境</strong>：据零售行业报告显示，70% 的企业数据分析人员将 60% 的时间花在 “数据整理” 上，真正用于 “分析问题、解决问题” 的时间不到 20%。更致命的是，<strong>Excel 的 “静态属性” 让数据永远滞后一步</strong>：等你用 5 天合并完 “生鲜损耗报表”，上周的损耗原因早已无法追溯；想查 “南区某门店生菜损耗比北区高 2 倍” 的根因，要翻 10 张 Excel 表、对比 3 个系统的数据，耗时 2 小时，结果还可能因为数据更新不及时得出错误结论。<br/>Excel 作为 “全民报表工具”，曾帮企业解决了 “从无到有” 的报表需求，但在 “实时、深度、自助” 的数据分析时代，它早已跟不上节奏 ——<strong>商业智能（BI）工具的出现，正是为了打破这个 “效率陷阱”</strong>。</p><h2>二、商业智能工具提升效率的 4 个核心逻辑</h2><p>商业智能工具能让数据分析效率提升 10 倍，本质是解决了 Excel 的 4 大痛点：</p><h3>1. 数据自动化：消灭 “复制粘贴” 的重复劳动</h3><p>Excel 的核心痛点是 “数据孤岛”—— 数据散在 POS、库存、ERP 等系统，需要人工录入或复制粘贴。商业智能工具通过<strong>自动对接多数据源</strong>，将分散的数据实时同步到一个平台，不用再手动整理。比如想做 “生鲜损耗分析”，直接对接 POS（销售数据）、库存（损耗数据）、采购（批次数据）系统，数据自动更新，不用再花 5 天合并表格。</p><h3>2. 自助分析：业务人员不用再 “求 IT”</h3><p>Excel 需要懂函数、懂 SQL 才能做深度分析，业务人员想查 “某门店某产品的损耗率”，只能找 IT 写公式。商业智能工具通过<strong>拖拽式建模 + 自然语言问数</strong>，让业务人员自己就能做分析：比如想查 “南区门店生菜的周损耗率”，直接拖 “门店”“产品”“损耗率” 字段到画布，或打字 “南区门店生菜的周损耗率”，10 秒就能出结果，不用再等 IT 反馈。</p><h3>3. 可视化交互：一眼看透 “数据背后的问题”</h3><p>Excel 是静态表格，想看出 “损耗率的趋势” 要画折线图，想钻取 “某门店的具体原因” 要翻页。商业智能工具通过<strong>动态可视化看板</strong>，将数据变成 “可交互的图表”：比如天虹的 “生鲜损耗看板”，用热力图显示各门店的损耗率（红色是高损耗），点击某门店，直接钻取 “采购批次→运输时间→陈列温度” 的细节，不用再翻 10 张表。</p><h3>4. 智能洞察：自动定位 “问题的根因”</h3><p>Excel 只能告诉你 “损耗率高”，但无法告诉你 “为什么高”。商业智能工具通过<strong>智能异常检测</strong>，自动分析数据中的关联关系，定位根因。比如天虹的生菜损耗率高，工具会自动提示 “损耗高的门店，对应采购批次的运输时间超过 4 小时（标准 2 小时）”，不用再人工排查 3 天。</p><h2>三、天虹零售的真实案例：从 5 天到 1 小时，效率提升 12 倍</h2><p>天虹是全国性零售企业，线下超市超 300 家，生鲜品类占比 25%，是引流的核心品类，但之前用 Excel 做损耗分析，效率极低 ——<strong>每月花 5 天整理数据，想查原因要 2 小时，损耗率一直维持在 8%（行业平均 6%）</strong>。</p><h3>Excel 时代的痛点</h3><ul><li><strong>数据滞后</strong>：要等 3 天才能拿到上周的损耗数据，无法及时调整陈列或采购策略；</li><li><strong>手动整合</strong>：数据散在 3 个系统，复制粘贴容易出错，曾因录错 “某批次生菜的运输时间” 导致损耗率计算错误；</li><li><strong>无法深挖</strong>：想查 “生菜损耗高的原因”，要翻 10 张 Excel 表，对比运输、陈列、销售数据，耗时 2 小时。</li></ul><h3>FineBI 如何解决？</h3><p>天虹选择用 FineBI 替代 Excel 后，通过 4 个功能直接解决痛点：</p><ol><li><strong>多源数据自动对接</strong>：直接连接 POS、库存、采购系统，数据实时同步，不用再手动复制；</li><li><strong>拖拽式自助分析</strong>：生鲜部门自己做 “损耗实时看板”，拖 “门店”“产品”“损耗率” 字段，10 分钟生成可视化报表；</li><li><strong>可视化钻取</strong>：点击某门店的高损耗数据，直接看到 “采购批次→运输时间→陈列温度” 的细节，不用再翻表；</li><li><strong>智能异常洞察</strong>：工具自动提示 “生菜损耗高是因为运输时间超过 4 小时”，快速定位问题。</li></ol><h3>效果：效率提升 12 倍，损耗率下降 3%</h3><ul><li>数据分析时间从 5 天缩短到 1 小时，效率提升 12 倍；</li><li>损耗率从 8% 下降到 5%，年节约成本 120 万元（数据来源：帆软公众号《天虹零售：用 FineBI 实现生鲜品类全链路数字化，损耗率下降 3%》）。</li></ul><h2>四、商业智能工具的核心价值：从 “体力劳动” 到 “脑力劳动”</h2><p>天虹的案例，本质是商业智能工具将数据分析从 “体力劳动”（复制粘贴、整理表格）转向 “脑力劳动”（分析问题、解决问题）。而 FineBI 之所以能做到这一点，正是因为它精准解决了 Excel 的痛点：</p><ul><li><strong>自动对接多数据源</strong>：覆盖 POS、库存、ERP 等 200 + 系统，消灭数据孤岛；</li><li><strong>拖拽式 + 自然语言问数</strong>：业务人员不用学 SQL，自己就能做分析；</li><li><strong>动态可视化看板</strong>：可钻取、可交互，一眼看透数据背后的问题；</li><li><strong>智能异常洞察</strong>：自动找根因，不用人工排查。</li></ul><h2>五、结尾：告别 Excel，不是否定，是 “升级”</h2><p>告别 Excel 报表，不是否定 Excel 的价值 —— 它依然是优秀的 “表格工具”，但<strong>当你需要 “实时、深度、自助” 的数据分析时，商业智能工具才是更高效的选择</strong>。<br/>天虹的故事告诉我们：数据分析的核心不是 “做表”，而是 “解决问题”。商业智能工具的出现，正是让你从 “花 5 天整理数据” 中解放出来，把时间用在 “优化运输流程、调整陈列策略” 这些真正创造价值的事情上。<br/>2026 年，企业的数据分析能力，不再是 “会不会用 Excel”，而是 “能不能用商业智能工具，把效率提升 10 倍”—— 毕竟，<strong>时间才是最珍贵的数据分析资源</strong>。</p>]]></description></item><item>    <title><![CDATA[如何编写和部署Agent SKill？ DigitalOcean ]]></title>    <link>https://segmentfault.com/a/1190000047551489</link>    <guid>https://segmentfault.com/a/1190000047551489</guid>    <pubDate>2026-01-19 17:08:01</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>Agent Skills（智能体技能）是一组文件夹，里面包含指令、脚本和资源。当大型语言模型（LLM）判断任务相关时，可以加载这些内容，以一致、可重复的方式完成特定任务。这一开放框架由 Claude 于 2025 年首次提出。此后，越来越多的组织和 Agent 开发者开始采用该框架。</p><p>在过去，当你给 LLM 分配任务时，必须在每一次提示词中手动提供完整上下文。而使用 Agent Skills 后，你可以将资源和补充指令拆分成独立文件夹。只有当 LLM 判断确实需要时，才会访问这些内容。</p><p>例如，如果你希望 LLM 能生成 PowerPoint 演示文稿。相比每次都在提示词中加入公司的样式规范、图片素材和模板，你可以把这些内容统一放进一个 Skill 文件夹中。之后，每次生成演示文稿时，LLM 都能自动查找并使用这些资源。你可以创建大量 Skills。LLM 可以像使用工具一样引用它们。</p><p>在本教程中，你将创建一个用于 <strong>PDF 解析</strong> 的 Agent Skill。同时，你还可以为其添加可选文件夹，用于存放参考文档和素材资源。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047551492" alt="" title=""/></p><h2>第一步 —— 创建 Skill</h2><p>最简单的 Skill 实现方式，是创建一个包含 <code>SKILL.md</code> 文件的文件夹。</p><p>该 Markdown 文件用于描述元数据和指令，告诉 Agent 如何完成特定任务。</p><p>你也可以在文件夹中加入：</p><ul><li>资源文件</li><li>模板</li><li>脚本</li><li>参考文档</li></ul><h3>文件夹结构</h3><pre><code>your-skill-name/
├── SKILL.md          # 必需：指令 + 元数据
├── scripts/          # 可选：可执行代码
├── references/       # 可选：文档
└── assets/           # 可选：模板、资源</code></pre><p>Skill 文件夹的名称，就是 Skill 的名称。文件夹中必须包含 SKILL.md 文件，其余内容可按需添加。</p><p>首先，创建一个名为 skills 的文件夹。该文件夹将存放你编写的所有 Skills。</p><p>在其中创建一个名为 pdf-parsing 的文件夹。该文件夹用于存放 PDF 解析相关的全部文件。</p><p>在 pdf-parsing 文件夹中，新建一个 SKILL.md 文件，内容如下：</p><pre><code>---
name: pdf-processing
description: Extracts text from PDF files using PyPDF2.
---

# PDF Processing Skill

## When to use this skill
Use this skill when a user needs to extract text from a PDF file.

## How to Use this Skill
This skill provides the `extract_text()` function from the `parse_pdf.py` script. Import it into your agent script:

python
from skills.pdf_parsing.parse_pdf import extract_text

result = extract_text(
    file_path="/path/to/document.pdf",
    pages="all"  # or "1-3" or "1,2,3"
)

### Parameters
- `file_path` (str): Path to the PDF file
- `pages` (str): Pages to extract - "all", "1-3" (range), or "1,2,3" (specific pages)

### Returns
JSON object with:
- `success` (bool): Whether extraction succeeded
- `file_path` (str): Path to the processed file
- `total_pages` (int): Total pages in PDF
- `extracted_pages` (int): Number of pages extracted
- `pages` (list): Array of {page: number, text: string} objects</code></pre><p>你也可以直接通过命令行调用脚本：</p><pre><code>python skills/pdf-parsing/parse_pdf.py extract_text \
  --file_path /path/to/file.pdf \
  --pages all</code></pre><h3>关于 Frontmatter</h3><p>在 Markdown 文件顶部的 Frontmatter 中：</p><ul><li>name 和 description 是<strong>必需字段</strong></li><li>Agent 会解析这些字段，用于判断哪个 Skill 最适合当前请求</li></ul><p>你还可以添加可选字段，例如：</p><ul><li>license</li><li>compatibility</li><li>metadata</li><li>allowed-tools</li></ul><p>在自定义 Agent 工作流中，你可以自由扩展这些字段。</p><p>Agent 会将所有 Skill 的 Frontmatter 与用户请求一起进行匹配，以确定最合适的 Skill。</p><h3>编写解析脚本</h3><p>接下来，你可以：</p><ul><li>使用已有的免费 PDF 解析脚本</li><li>或自行创建 parse\_pdf.py 文件，并实现 extract\_text() 函数</li></ul><p>如果使用示例脚本，需要安装 PyPDF2：</p><pre><code>pip3 install PyPDF2</code></pre><p>这将安装 PyPDF2 Python 包。</p><h2>第二步 —— 集成 Skill</h2><p>要让 Agent 使用 Skills，需要完成以下流程：</p><ol><li>扫描所有包含 <code>SKILL.md</code> 的目录</li><li>在启动时加载每个 Skill 的元数据（名称与描述）</li><li>将用户请求与可用 Skills 进行匹配</li><li>激活 Skill，加载完整指令内容</li><li>根据指令执行脚本或加载资源</li></ol><p>一些 Agent（如 Claude Code、Codex）已经自动支持该流程。越来越多的 Agent 平台正在集成这一标准。</p><p>如果你想将你的 Skill 集成到自己定制的智能体（agent）中，主要有两种方式：一种是基于文件系统的模式，另一种是基于工具的模式。</p><p>在基于文件系统的模式中，大语言模型（LLM）的工作流运行在一个计算机环境中，并输出诸如 cat /path/to/my-skill/skill.md 这样的 shell 命令，随后这些命令会被执行。</p><p>而在基于工具的方法中，Skill 会被封装成 LLM 可以直接调用的工具。</p><p>本教程不涉及从零开始构建一个支持 SKill 的智能体，但你可以使用我们提供的这个智能体脚本。该脚本通过 <a href="https://link.segmentfault.com/?enc=MvgA7jOGZzhU1s27FSeK8A%3D%3D.nQ3KgONwLcZgvvDzrUSVRJyqY6ABPhCAj3ByXZ0FquaJAPU%2B5kltrsS3rZEoI3He" rel="nofollow" target="_blank">DigitalOcean Gradient AI 平台</a>的<a href="https://link.segmentfault.com/?enc=mFaHdnVOKszVJOZsnah40w%3D%3D.Go2AyY4IkvY7QwFBnUgWK9kEPXdk0jk8BOpkPeesKSzkTHj45YTY26MfxFDGVziRaL1EJoLM%2FrJcdLi0%2B8HHNg%3D%3D" rel="nofollow" target="_blank">无服务器推理（Serverless Inference）</a>功能调用 Llama 3.3 70B 模型。你需要先获取一个模型访问密钥，才能在 DigitalOcean Gradient AI 平台上使用无服务器推理服务。请将你的模型访问密钥添加到脚本的 main() 函数中。</p><p>在这里我们简单先介绍一下 DigitalOcean Gradient AI 平台的无服务推理。</p><p>DigitalOcean Gradient AI 平台的 <strong>无服务器推理（Serverless Inference）</strong> 是一种让开发者无需管理任何底层基础设施，就能调用强大 AI 模型进行推理计算的服务。这种模式通过简洁的 API 让你直接访问包括开源模型和主流大模型提供者的能力，无需自行部署或维护服务器集群。它由 DigitalOcean 平台自动处理 <strong>扩容、可用性和资源调度</strong> 等复杂工作，使开发者可以集中精力构建应用逻辑，而不必担心底层算力的管理和运维。</p><p>无服务器推理采用 <strong>按使用量计费</strong> 模式，即按输入和输出的 Token 数量收费，没有闲置服务器的成本，这对于请求量波动较大的场景尤为经济。开发者通过申请和配置一个模型访问密钥（Model Access Key），即可通过统一的端点发起 HTTP 请求来调用模型进行文本生成、对话、分析等推理任务。</p><p>与传统需要预先部署、调整和监控基础设施的推理服务相比，Serverless Inference 的优势在于 ​<strong>开箱即用、自动扩展、无需容量规划</strong>​。它适用于内容增强、实时数据处理、原型快速迭代、嵌入式 AI 能力集成等多种场景，同时支持通过 SDK（如 Gradient Python SDK）以编程方式实现同步或异步调用。</p><p>总之，DigitalOcean Gradient AI 的无服务器推理为希望快速集成、灵活调用 AI 模型的开发者提供了一条低门槛、高效率的路径，让构建生产级 AI 功能更加简便直接。</p><p>OK，言归正传，继续回到教程来。当你将我们上文提到的脚本与你的 skills 文件夹放在同一目录下后，即可运行该脚本。</p><pre><code>python3 agent_example.py</code></pre><p>在打开的输入框中输入：</p><pre><code>Please parse the text out of the PDF at /path/to/your/document.pdf</code></pre><p>你将看到 PDF 文本解析结果：</p><pre><code>============================================================
SIMPLE TOOL-BASED SKILLS EXAMPLE
============================================================

✅ Found 1 skills:
   - pdf-processing: Extracts text from PDF files using PyPDF2.

============================================================
CHAT (type 'quit' to exit)
============================================================

You: Please extract the text from: /Desktop/document.pdf

[Turn 1]
💭 LLM: {"function_call": {"name": "activate_skill", "arguments": {"skill_name": "pdf-processing"}}}
..........
The cost of an RV is 30,000</code></pre><p>Agent 已成功完成以下流程：</p><ul><li>找到 Skill</li><li>解析元数据</li><li>执行脚本</li><li>返回 PDF 文本内容</li></ul><h2>第三步 —— 扩展功能与 Skills</h2><p>添加任何你希望 LLM 能够访问的脚本或文件夹。然后在 <strong>SKILL.md</strong> 文件中，为每个文件夹和脚本添加相应的功能说明与描述。例如，你可以添加用于生成或编辑 PDF 的脚本。请确保将这些附加文件放在你希望它们所属的具体 Skill 文件夹中。</p><p>你可以添加任意数量的 Skills，但每个 Skill 文件夹中都必须包含一个 <strong>SKILL.md</strong> 文件，Agent 才能识别该 Skill。此外，当 Skills 数量增多时，Agent 可能难以将用户意图与大量 Skill 的元数据准确匹配。因此，随着 Skill 数量的增加，可能需要引入额外的搜索功能，或使用向量嵌入来将用户请求匹配到正确的 Skill。</p><h2>常见问题</h2><p><strong>Q：Skills 之间可以相互通信或调用其他 Skills 吗？应如何实现技能链（skill chaining）？</strong></p><p>可以。Skills 可以调用其他 Skills。Agent 应能够识别在完成任务时是否需要多个 Skills，并将它们串联执行。此外，也可以在某个 Skill 的指令中直接引用其他 Skills。</p><p><strong>Q：当 Skills 需要访问外部服务时，应该如何处理身份认证和 ​API</strong>​<strong>​ Key？</strong></p><p>切勿在 Skill 文件中硬编码任何凭据。应使用环境变量，或安全的密钥管理系统来存储和读取相关信息。</p><p><strong>Q：在启动时加载大量 Skills 会对性能产生什么影响？是否有延迟加载策略？</strong></p><p>在启动阶段加载数百个 Skill 的元数据可能会比较缓慢。可以考虑对已加载的 Skills 进行缓存，并使用索引机制来加快在大量 Skills 中的搜索速度。你还可以将“发现（discovery）”与“激活（activation）”步骤分离，在真正需要使用某个 Skill 之前，仅加载其元数据。</p><p><strong>Q：如何测试和调试 Skills？</strong></p><p>在集成之前，请确保单独测试每一个 Skill。同时，为 Skills 添加更详细的日志输出，以便观察哪些 Skills 被选中，以及被选中的原因。</p><h2>写在最后</h2><p>Agent Skills 是一种非常优秀的方式，用于标准化 LLM Agent 的功能能力。它们使用户能够以结构化的形式，为智能体添加和增强各类能力。具体的实现方式取决于你的 Agent 工作流，但目前已经有越来越多的 Agent 服务可以开箱即用地支持 Skills，其中包括 Claude Code、Codex 和 VS Code 等，这些都是已经采用该标准的 Agent 提供方。</p><p>接下来，你可以添加更多 Skills，并根据项目需求为它们扩展额外功能。随后，通过向量嵌入或其他搜索机制，进一步提升 Agent 工作流中 Skill 的匹配能力。</p>]]></description></item><item>    <title><![CDATA[Kubernetes入门地图——核心对象、网络与存储的抽象关系与心智模型 南城 ]]></title>    <link>https://segmentfault.com/a/1190000047551495</link>    <guid>https://segmentfault.com/a/1190000047551495</guid>    <pubDate>2026-01-19 17:07:12</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><strong>写在前面，本人目前处于求职中，如有合适内推岗位，请加：lpshiyue 感谢。同时还望大家一键三连，赚点奶粉钱。</strong></p><blockquote>Kubernetes的本质不是简单的容器编排，而是一套完整的分布式系统抽象模型</blockquote><p>在掌握了容器镜像的工程化构建后，我们面临一个更宏大的挑战：如何协调成千上万的容器实例，让它们像训练有素的交响乐团一样协同工作？Kubernetes正是这套复杂 orchestration 的交响指挥，它通过精妙的抽象模型将分布式系统的复杂性封装成可理解、可操作的逻辑单元。本文将为您构建完整的Kubernetes心智地图，揭示核心对象、网络与存储的抽象关系。</p><h2>1 从容器到编排：为什么需要Kubernetes？</h2><h3>1.1 容器时代的演进逻辑</h3><p>容器技术解决了应用<strong>环境一致性</strong>的问题，但单个容器如同孤岛，无法形成规模效应。当容器数量从个位数增长到百位数甚至千位数时，一系列新的挑战随之出现：</p><p><strong>调度复杂性</strong>：容器应该运行在哪个节点？如何保证资源利用率最大化？<br/><strong>网络互联</strong>：分散的容器如何相互发现和通信？<br/><strong>存储管理</strong>：有状态应用的数据如何持久化和迁移？<br/><strong>故障恢复</strong>：节点故障时容器如何自动重建？<br/><strong>弹性伸缩</strong>：如何根据流量自动调整容器数量？</p><h3>1.2 Kubernetes的核心理念：抽象与声明</h3><p>Kubernetes的突破性在于它采用了<strong>声明式API</strong>和<strong>控制循环</strong>机制。用户只需告诉Kubernetes"期望的状态"，系统会自动驱动当前状态向期望状态收敛。</p><p>这种设计哲学使得Kubernetes更像一个<strong>自主神经系统</strong>，能够自动处理节点故障、容器重启、流量调度等常规运维操作，让开发者专注于业务逻辑而非基础设施细节。</p><h2>2 Kubernetes集群架构：从物理到逻辑的映射</h2><h3>2.1 控制平面：集群的大脑与神经中枢</h3><p>控制平面是Kubernetes的<strong>决策中心</strong>，负责维护集群的期望状态和实际状态。</p><p><strong>API Server</strong>：集群的<strong>唯一入口</strong>，所有操作都必须通过API Server进行。它负责认证、授权、验证请求，并作为其他组件之间的通信枢纽。</p><p><strong>etcd</strong>：集群的<strong>记忆中心</strong>，持久化存储所有集群数据，包括节点信息、Pod状态、配置信息等。etcd采用Raft一致性算法确保数据的高可用性和一致性。</p><p><strong>Scheduler</strong>：<strong>资源调度专家</strong>，负责将新创建的Pod分配到合适的节点上。调度决策基于资源需求、策略约束、硬件/软件限制等复杂因素。</p><p><strong>Controller Manager</strong>：<strong>集群状态守护者</strong>，运行各种控制器，确保当前状态与期望状态一致。例如，当Pod异常终止时，控制器会自动创建新的Pod来替代。</p><h3>2.2 工作节点：任务的执行者</h3><p>工作节点是<strong>实际运行容器负载的机器</strong>，可以是物理机或虚拟机。</p><p><strong>Kubelet</strong>：节点上的<strong>监管代理</strong>，负责与API Server通信，管理本节点上Pod的生命周期，包括创建、修改、删除容器等操作。</p><p><strong>Kube-proxy</strong>：<strong>网络代理</strong>，维护节点上的网络规则，实现Service的负载均衡和网络路由功能。</p><p><strong>容器运行时</strong>：<strong>容器执行引擎</strong>（如Docker、containerd），负责真正运行容器。</p><h3>2.3 集群抽象模型：住宿楼比喻</h3><p>将Kubernetes集群比喻为<strong>智能住宿楼</strong>可以建立直观的心智模型：</p><pre><code>Cluster（集群） = 整栋智能大楼
Node（节点） = 楼层单元
Pod（容器组） = 独立房间
Container（容器） = 房间内的住户
Namespace（命名空间） = 楼层功能分区（A座、B座）</code></pre><p>这种类比帮助理解各组件之间的层级关系和职责划分。</p><h2>3 核心对象模型：Kubernetes的构建基石</h2><h3>3.1 Pod：最小部署单元的精妙设计</h3><p>Pod是Kubernetes中最基本也是最重要的概念，它是一个或多个<strong>容器的逻辑组合</strong>，这些容器共享存储、网络和运行上下文。</p><p><strong>Pod的设计哲学</strong>：</p><ul><li><strong>亲密性容器组合</strong>：将需要紧密协作、共享资源的容器放在同一个Pod中</li><li><strong>生命周期一致性</strong>：Pod内的容器同时创建、同时销毁、同节点调度</li><li><strong>资源共享机制</strong>：共享网络命名空间（同一IP）、存储卷、进程空间</li></ul><pre><code class="yaml"># 多容器Pod示例：主应用容器+日志收集sidecar
apiVersion: v1
kind: Pod
metadata:
  name: web-app
spec:
  containers:
  - name: web-server
    image: nginx:1.25
    ports:
    - containerPort: 80
  - name: log-collector
    image: fluentd:latest
    volumeMounts:
    - name: log-volume
      mountPath: /var/log/nginx
  volumes:
  - name: log-volume
    emptyDir: {}</code></pre><p><em>Pod内容器通过共享Volume实现日志共享</em></p><h3>3.2 Controller：状态收敛的智能引擎</h3><p>Controller是Kubernetes的<strong>自动化核心</strong>，通过持续的控制循环确保系统状态向期望状态收敛。</p><p><strong>Deployment</strong>：<strong>无状态应用的管家</strong>，管理Pod副本集，支持滚动更新、回滚、扩缩容等高级功能。</p><pre><code class="yaml">apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3  # 期望维持3个副本
  selector:
    matchLabels:
      app: frontend
  template:
    metadata:
      labels:
        app: frontend
    spec:
      containers:
      - name: nginx
        image: nginx:1.25
        ports:
        - containerPort: 80</code></pre><p><em>Deployment确保始终有3个Pod副本运行</em></p><p><strong>StatefulSet</strong>：<strong>有状态应用的守护者</strong>，为Pod提供稳定的标识符、有序部署、稳定的存储，适合数据库等有状态应用。</p><p><strong>DaemonSet</strong>：<strong>节点服务代理</strong>，确保每个节点上都运行一个Pod副本，常用于日志收集、监控代理等场景。</p><p><strong>Job/CronJob</strong>：<strong>任务执行器</strong>，负责一次性任务或定时任务，确保任务成功完成。</p><h3>3.3 标签与选择器：松耦合的粘合剂</h3><p>Label和Selector是Kubernetes的<strong>服务发现和关联机制</strong>，实现了对象之间的松耦合连接。</p><p><strong>Label</strong>：<strong>键值对标签</strong>，附加到对象上用于标识其特征。</p><pre><code class="yaml">metadata:
  labels:
    app: frontend        # 应用名称
    tier: web            # 架构层级
    environment: prod    # 环境类型
    version: v1.2        # 版本标识</code></pre><p><strong>Selector</strong>：<strong>标签选择器</strong>，用于筛选具有特定标签的对象。</p><pre><code class="yaml">selector:
  matchLabels:
    app: frontend
    tier: web
  matchExpressions:
  - {key: version, operator: In, values: [v1.2, v1.3]}</code></pre><p>这种标签系统使得Kubernetes具备了<strong>基于属性的智能路由能力</strong>，为微服务架构提供了天然支持。</p><h2>4 服务发现与网络：连接的艺术</h2><h3>4.1 Service：稳定的网络端点</h3><p>Service解决了Pod<strong>动态性带来的网络挑战</strong>——Pod可能随时被重建、调度到不同节点，IP地址也会随之改变。</p><p><strong>Service的抽象价值</strong>：</p><ul><li><strong>稳定访问入口</strong>：为Pod集合提供唯一的ClusterIP和DNS名称</li><li><strong>负载均衡</strong>：将请求均匀分发到后端所有健康的Pod</li><li><strong>服务抽象</strong>：解耦服务消费者与提供者，消费者无需关注Pod细节</li></ul><p><strong>Service类型及其适用场景</strong>：</p><pre><code class="yaml"># ClusterIP：集群内部服务发现
kind: Service
apiVersion: v1
metadata:
  name: backend-service
spec:
  type: ClusterIP
  selector:
    app: backend
  ports:
  - port: 80
    targetPort: 8080

# NodePort：外部访问集群内部服务
kind: Service  
apiVersion: v1
metadata:
  name: web-service
spec:
  type: NodePort
  selector:
    app: web
  ports:
  - port: 80
    targetPort: 80
    nodePort: 30080  # 外部访问端口

# LoadBalancer：云平台负载均衡集成
kind: Service
apiVersion: v1
metadata:
  name: api-service
spec:
  type: LoadBalancer
  selector:
    app: api
  ports:
  - port: 443
    targetPort: 8443</code></pre><h3>4.2 Ingress：七层流量治理</h3><p>Ingress是<strong>HTTP/HTTPS流量的智能路由器</strong>，提供基于域名和路径的路由能力。</p><pre><code class="yaml">apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: app-ingress
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  rules:
  - host: app.example.com
    http:
      paths:
      - path: /api
        pathType: Prefix
        backend:
          service:
            name: api-service
            port:
              number: 80
      - path: /
        pathType: Prefix
        backend:
          service:
            name: web-service
            port:
              number: 80</code></pre><p><em>Ingress根据访问路径将流量导向不同服务</em></p><h3>4.3 网络模型的设计哲学</h3><p>Kubernetes网络遵循<strong>扁平地址空间原则</strong>，每个Pod都获得唯一的IP地址，Pod之间可以直接通信，无需NAT转换。这种设计简化了网络拓扑，为应用提供了透明的网络体验。</p><h2>5 存储抽象：状态持久化的挑战与解决方案</h2><h3>5.1 Volume：Pod级别的存储抽象</h3><p>Volume解决了容器内磁盘文件的<strong>持久化问题</strong>和数据<strong>容器间共享</strong>的需求。</p><p><strong>Volume的生命周期</strong>与Pod相同，但可以超过单个容器的生命周期，容器重启时数据得以保留。</p><pre><code class="yaml">apiVersion: v1
kind: Pod
metadata:
  name: app-with-storage
spec:
  containers:
  - name: main-app
    image: nginx:1.25
    volumeMounts:
    - name: shared-data
      mountPath: /app/data
  - name: sidecar
    image: busybox:latest
    volumeMounts:
    - name: shared-data  
      mountPath: /sidecar/data
  volumes:
  - name: shared-data
    emptyDir: {}  # 临时共享存储</code></pre><p><em>Pod内多个容器通过Volume共享数据</em></p><h3>5.2 PersistentVolume/PersistentVolumeClaim：存储消费的抽象分离</h3><p>Kubernetes通过<strong>两层抽象</strong>将存储供应与消费解耦：</p><p><strong>PersistentVolume（PV）</strong>：<strong>集群存储资源池</strong>，由管理员预先配置或动态供应。</p><pre><code class="yaml">apiVersion: v1
kind: PersistentVolume
metadata:
  name: database-pv
spec:
  capacity:
    storage: 100Gi
  accessModes:
  - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: fast-ssd
  nfs:
    path: /exports/data
    server: nfs-server.example.com</code></pre><p><strong>PersistentVolumeClaim（PVC）</strong>：<strong>用户存储需求声明</strong>，用户无需关心后端存储细节。</p><pre><code class="yaml">apiVersion: v1
kind: PersistentVolumeClaim  
metadata:
  name: database-pvc
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 100Gi
  storageClassName: fast-ssd</code></pre><p>这种<strong>声明式存储模型</strong>使得应用可以透明地使用各种存储技术（NFS、iSCSI、云存储等），实现了存储基础设施与应用的解耦。</p><h3>5.3 ConfigMap与Secret：配置管理的现代化实践</h3><p><strong>ConfigMap</strong>：<strong>应用配置管理中心</strong>，将配置数据与容器镜像分离，实现配置的集中管理。</p><pre><code class="yaml">apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
data:
  database.url: "jdbc:mysql://db-host:3306/app"
  log.level: "INFO"
  cache.size: "256MB"</code></pre><p><strong>Secret</strong>：<strong>敏感信息保险箱</strong>，专门用于存储密码、令牌、证书等敏感数据，支持Base64编码和加密存储。</p><h2>6 控制器模式：Kubernetes的智能引擎</h2><h3>6.1 声明式API与控制循环</h3><p>Kubernetes的核心运作机制建立在<strong>声明式API</strong>和<strong>控制循环</strong>之上。</p><p><strong>声明式API</strong>允许用户描述"期望状态"，而非具体执行步骤。例如，用户声明"需要3个副本"，而不是手动执行"创建3个Pod"的命令序列。</p><p><strong>控制循环</strong>持续监控当前状态与期望状态的差异，并驱动系统向期望状态收敛。这种机制使Kubernetes具备了<strong>自我修复能力</strong>和<strong>自动化运维能力</strong>。</p><h3>6.2 控制器协同工作原理</h3><p>以Deployment为例，其协同工作流程如下：</p><ol><li>用户创建Deployment，声明期望的Pod副本数</li><li>Deployment Controller创建ReplicaSet</li><li>ReplicaSet Controller根据副本数创建对应数量的Pod</li><li>Scheduler为Pod分配合适的节点</li><li>Kubelet在节点上创建并运行容器</li><li>各控制器持续监控状态，确保与实际状态一致</li></ol><p>这种分层控制架构使得Kubernetes能够管理极其复杂的分布式系统，同时保持各组件的职责单一和可维护性。</p><h2>7 实践指南：从概念到实践</h2><h3>7.1 资源定义的最佳实践</h3><p><strong>标签标准化</strong>：建立统一的标签规范，便于资源管理和查询。</p><pre><code class="yaml">metadata:
  labels:
    app.kubernetes.io/name: frontend
    app.kubernetes.io/component: web-server
    app.kubernetes.io/version: "1.2.0"
    app.kubernetes.io/environment: production</code></pre><p><strong>资源请求与限制</strong>：合理设置CPU和内存资源，确保应用性能与集群稳定性。</p><pre><code class="yaml">resources:
  requests:
    memory: "64Mi"
    cpu: "250m"
  limits:
    memory: "128Mi" 
    cpu: "500m"</code></pre><h3>7.2 故障排查心智模型</h3><p>建立系统的<strong>故障排查路径</strong>：</p><ol><li><strong>Pod状态检查</strong>：<code>kubectl get pods</code> 查看Pod基本状态</li><li><strong>详细描述</strong>：<code>kubectl describe pod</code> 获取事件和详细状态</li><li><strong>日志分析</strong>：<code>kubectl logs</code> 查看容器日志</li><li><strong>资源验证</strong>：检查相关Service、Volume、ConfigMap等关联资源</li></ol><h2>总结</h2><p>Kubernetes通过层层抽象，将复杂的分布式系统管理简化为<strong>声明式API操作</strong>和<strong>自动化状态收敛</strong>。其核心价值在于提供了一套统一的概念模型，使得开发者可以忽略底层基础设施差异，专注于应用本身的价值交付。</p><p><strong>Kubernetes抽象模型的核心优势</strong>：</p><ol><li><strong>声明式API</strong>：描述期望状态，而非具体操作步骤</li><li><strong>控制器模式</strong>：自动驱动当前状态向期望状态收敛</li><li><strong>标签系统</strong>：基于属性的灵活关联和选择机制</li><li><strong>统一抽象</strong>：跨云厂商和基础设施的一致性体验</li></ol><p>掌握Kubernetes的关键在于理解其<strong>抽象思维</strong>而非具体命令。当您开始用"期望状态"的思维方式描述系统时，就已经掌握了Kubernetes的精髓。</p><hr/><p><strong>📚 下篇预告</strong><br/>《灰度与蓝绿：风险可控的发布——流量切分、指标回滚与版本管理策略》—— 我们将深入探讨：</p><ul><li>🎯 <strong>发布策略谱系</strong>：从重建发布到影子测试的完整风险控制梯度</li><li>🔄 <strong>流量切分算法</strong>：基于内容、比例、用户特征的精细化流量路由</li><li>📊 <strong>指标监测体系</strong>：发布过程中的业务与技术指标双维度验证</li><li>⏱️ <strong>回滚决策模型</strong>：自动回滚触发条件与人工干预的平衡点选择</li><li>🏷️ <strong>版本管理策略</strong>：API版本化、数据迁移与前后向兼容性保障</li></ul><p><strong>点击关注，掌握现代化应用发布的全链路风险管理！</strong></p><blockquote><p><strong>今日行动建议</strong>：</p><ol><li>在本地搭建Minikube环境，实践Pod、Deployment、Service核心对象操作</li><li>为现有应用设计标签策略，建立基于标签的资源管理规范</li><li>分析生产环境存储需求，规划PersistentVolume的存储类设计</li><li>建立Kubernetes资源定义代码库，实现基础设施即代码</li></ol></blockquote>]]></description></item><item>    <title><![CDATA[全场景CRM横向对比：从中小微到大型企业的数字化选型指南 率性的开水瓶 ]]></title>    <link>https://segmentfault.com/a/1190000047551505</link>    <guid>https://segmentfault.com/a/1190000047551505</guid>    <pubDate>2026-01-19 17:06:16</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在企业数字化转型中，CRM（客户关系管理）已从“销售工具”升级为“全业务协同平台”。不同规模、行业的企业对CRM的需求差异显著：<strong>大型企业需要全链路整合与AI驱动</strong>，<strong>中小企业需要简单高效与</strong> <strong>销售自动化</strong>，<strong>项目型企业需要多方协同与收支管控</strong>。本文选取<strong>超兔一体云、Oracle</strong> <strong>CX</strong> <strong>、Less Annoying CRM、浪潮CRM、励销云、Agile CRM</strong>六大主流品牌，从<strong>销售管理、客服支持、</strong> <strong>供应链协同</strong> <strong>、项目管理、</strong> <strong>数据分析</strong>五大核心维度展开深度对比，结合场景化案例与可视化工具，为企业选型提供参考。</p><h2>一、核心定位与目标客户对比</h2><p>先通过一张表格明确各品牌的<strong>核心价值与适用场景</strong>，避免“用大型企业CRM套中小微业务”的误区：</p><table><thead><tr><th>品牌</th><th>核心定位</th><th>目标客户</th><th>核心价值</th></tr></thead><tbody><tr><td>超兔一体云</td><td>全业务一体化CRM</td><td>中小到中大型企业（项目型/制造型）</td><td>多方协同+收支管控+全流程闭环</td></tr><tr><td>Oracle CX</td><td>企业级客户体验平台</td><td>大型企业（制造/高科技/金融）</td><td>全链路数据整合+AI驱动+行业深度适配</td></tr><tr><td>Less Annoying CRM</td><td>简单易用的轻量级CRM</td><td>小微型企业（初创/零售/服务）</td><td>无代码上手+低成本+基础销售管理</td></tr><tr><td>浪潮CRM</td><td>行业化CRM</td><td>传统中小企业（批发/制造/零售）</td><td>行业模板+基础销售/客服协同</td></tr><tr><td>励销云</td><td>销售自动化CRM</td><td>中小企业（电销/快消/教育）</td><td>智能拓客+销售漏斗+电销模块</td></tr><tr><td>Agile CRM</td><td>一体化销售营销平台</td><td>初创科技企业（SaaS/互联网）</td><td>拖放式流程+多渠道整合+轻量级协作</td></tr></tbody></table><h2>二、销售管理：从线索到订单的全流程能力对比</h2><p>销售管理是CRM的核心，<strong>线索转化率、商机可控性、订单灵活性</strong>是关键指标。我们拆解为<strong>线索管理、商机模型、订单类型、特色功能</strong>四大维度对比：</p><h3>1. 销售管理维度对比表</h3><table><thead><tr><th>品牌</th><th>线索管理</th><th>商机模型</th><th>订单类型</th><th>特色功能</th></tr></thead><tbody><tr><td>超兔一体云</td><td>多渠道集客（百度/抖音/微信/工商）+AI分配+查重</td><td>三一客（小单快单）、商机（中长单）、多方项目（复杂单）</td><td>标准/批发/非标/套餐/租售一体/总分订单</td><td>多方项目跟单（客户+供应商+内部团队）、分组隔离跟单</td></tr><tr><td>Oracle CX</td><td>CDP整合多渠道数据+AI线索评分</td><td>引导式销售（大型企业复杂商机）</td><td>支持服务/实物/订阅等多业务模型</td><td>360°客户视图+战略客户资源倾斜</td></tr><tr><td>Less Annoying CRM</td><td>手动/CSV导入+基础分类</td><td>简单销售漏斗（线索→商机→订单）</td><td>基础产品订单</td><td>无代码线索跟踪+低学习成本</td></tr><tr><td>浪潮CRM</td><td>行业模板化线索录入+基础分配</td><td>传统商机阶段管理（需求→报价→成交）</td><td>标准订单+批发订单</td><td>行业适配（如批发业的批量下单）</td></tr><tr><td>励销云</td><td>对接搜客宝/小励机器人（智能获客）+AI筛选</td><td>销售漏斗+商机赢率预测</td><td>标准订单+电销订单</td><td>一键拨号+通话录音+线索自动分级</td></tr><tr><td>Agile CRM</td><td>网站访客捕获+邮件营销线索导入</td><td>拖放式商机流程（自定义阶段）</td><td>标准订单+订阅订单</td><td>多渠道通信整合（邮件/电话/社交）</td></tr></tbody></table><h3>2. 特色功能可视化：超兔“多方项目跟单”流程图</h3><p>对于<strong>项目型企业（如系统集成、设备制造）</strong> ，超兔的“多方项目模型”解决了“客户、供应商、内部团队协同难”的痛点。用Mermaid流程图展示核心逻辑：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047551507" alt="" title=""/></p><pre><code>graph TD
    A[创建多方项目] --&gt; B[关联项目组（客户/供应商/内部团队）]
    B --&gt; C[生成合同订单（含定制参数）]
    C --&gt; D[触发采购跟单（关联BOM清单→比价→下单）]
    D --&gt; E[收支管控（应收/应付实时对比→规避超支）]
    E --&gt; F[项目进度跟踪（甘特图+关键节点→车间大屏预警）]
    F --&gt; G[项目交付（验收+售后工单）]
    G --&gt; H[项目结案（数据归档+ROI分析）]</code></pre><p><strong>场景案例</strong>：某系统集成商通过超兔管理“政府智慧校园项目”，在一个视图内整合了“客户（教育局）、供应商（服务器厂商）、内部团队（研发/实施）”，实时监控“合同应收100万、采购应付60万、进度延迟2天”，最终项目利润达标率110%。</p><h2>三、客服支持：从“响应”到“体验”的升级</h2><p>客服已从“问题解决”升级为“客户忠诚管理”，<strong>渠道覆盖、AI能力、业务联动</strong>是关键。以下是对比表：</p><h3>1. 客服支持维度对比表</h3><table><thead><tr><th>品牌</th><th>渠道覆盖</th><th>AI能力</th><th>业务联动</th></tr></thead><tbody><tr><td>超兔一体云</td><td>电话/微信/工单/现场服务</td><td>电话录音AI分析（情绪/关键词提取）、智能回复建议</td><td>与销售/项目/供应链联动（如售后关联订单BOM）</td></tr><tr><td>Oracle CX</td><td>全渠道（电话/邮件/社交/视频/现场）</td><td>生成式AI助手（智能回复/知识库推荐）、客户情绪识别</td><td>与CDP整合（360°客户视图→个性化服务）</td></tr><tr><td>Less Annoying CRM</td><td>邮件/电话/基础工单</td><td>无AI功能</td><td>仅关联客户基本信息</td></tr><tr><td>浪潮CRM</td><td>电话/工单</td><td>基础智能回复</td><td>与销售订单联动</td></tr><tr><td>励销云</td><td>电话/短信/微信</td><td>通话录音转文字</td><td>与销售线索联动（如投诉客户标记为高风险）</td></tr><tr><td>Agile CRM</td><td>邮件/电话/社交</td><td>邮件模板+自动化跟进</td><td>与营销模块联动（如售后触发复购邮件）</td></tr></tbody></table><h3>2. 特色功能可视化：Oracle CX“全渠道服务”流程图</h3><p>对于<strong>大型制造企业（如汽车厂商）</strong> ，Oracle CX的“全渠道服务”解决了“客户从线上咨询到线下维修的割裂”问题：</p><pre><code>graph TD
    A[客户多渠道咨询（官网/微信/400）] --&gt; B[智能路由（分配给对应服务组）]
    B --&gt; C[AI助手先响应（如“查订单进度”→自动回复）]
    C --&gt; D[人工介入（360°视图：客户历史维修记录/车辆配置）]
    D --&gt; E[解决问题（如“预约维修”→联动现场服务系统）]
    E --&gt; F[满意度调查→数据回传CDP]
    F --&gt; G[驱动后续行动（如“3个月后保养提醒”）]</code></pre><p><strong>场景案例</strong>：某汽车厂商用Oracle CX整合“官网咨询、4S店维修、客服热线”，客户咨询“车辆故障”时，系统自动调出“历史维修记录+车辆配置”，服务工程师直接给出“到店维修方案”，客户满意度提升25%。</p><h2>四、供应链协同：从“销售”到“产销一体化”的延伸</h2><p>传统CRM只做“销售端”，但<strong>制造型/项目型企业</strong>需要“销售-采购-库存”闭环。以下是对比表：</p><h3>1. 供应链协同维度对比表</h3><table><thead><tr><th>品牌</th><th>上下游协同</th><th>BOM管理</th><th>特色功能</th></tr></thead><tbody><tr><td>超兔一体云</td><td>供应商询价/比价/对账、客户发货跟踪</td><td>生产BOM+领料控制（避免超领）</td><td>订单→采购→库存闭环（如订单触发采购计划）</td></tr><tr><td>Oracle CX</td><td>供应商协同平台（订单确认/物流跟踪）</td><td>与SCM Cloud集成（复杂BOM）</td><td>IoT驱动（如设备故障→提前备货）</td></tr><tr><td>Less Annoying CRM</td><td>无</td><td>无</td><td>无</td></tr><tr><td>浪潮CRM</td><td>基础供应商管理</td><td>无</td><td>无</td></tr><tr><td>励销云</td><td>无</td><td>无</td><td>无</td></tr><tr><td>Agile CRM</td><td>无</td><td>无</td><td>无</td></tr></tbody></table><h3>2. 特色功能可视化：超兔“订单-采购-库存”流程图</h3><p>对于<strong>设备制造企业</strong>，超兔的“供应链协同”解决了“订单多了缺料、订单少了积压”的痛点：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047551508" alt="" title="" loading="lazy"/></p><pre><code>graph TD
    A[销售订单生成] --&gt; B[自动匹配BOM清单→计算需采购物料]
    B --&gt; C[触发采购计划→比价选供应商→生成采购单]
    C --&gt; D[采购入库→关联订单→减库存]
    D --&gt; E[发货给客户→关联订单→更新物流状态]
    E --&gt; F[应收/应付对比→管控利润]</code></pre><p><strong>场景案例</strong>：某机床厂通过超兔管理“定制化机床订单”，订单生成后自动调用BOM清单，计算“需采购10套电机+5套导轨”，系统自动对比3家供应商的价格，选择最低的一家下单，最终采购成本降低18%。</p><h2>五、项目管理：从“内部协作”到“多方协同”的升级</h2><p>项目型企业（如工程/系统集成）需要“客户、供应商、内部团队”在一个视图内协同，以下是对比表：</p><h3>1. 项目管理维度对比表</h3><table><thead><tr><th>品牌</th><th>多方协同</th><th>进度管控</th><th>特色功能</th></tr></thead><tbody><tr><td>超兔一体云</td><td>项目组（客户/供应商/内部）+合同/采购/收支一体化</td><td>甘特图+关键节点+车间大屏（超期预警）</td><td>多方项目模型（适合“客户+供应商+内部”的复杂项目）</td></tr><tr><td>Oracle CX</td><td>内部协作（文件共享/@通知）+第三方工具集成（Slack）</td><td>协作仪表板+进度节点审批</td><td>与SCM/ERP集成（适合大型项目的内部管控）</td></tr><tr><td>Less Annoying CRM</td><td>无</td><td>无</td><td>无</td></tr><tr><td>浪潮CRM</td><td>基础内部协作</td><td>简单进度跟踪</td><td>无</td></tr><tr><td>励销云</td><td>无</td><td>无</td><td>无</td></tr><tr><td>Agile CRM</td><td>拖放式任务分配+文件共享</td><td>简单进度条</td><td>与销售模块联动（如项目触发订单）</td></tr></tbody></table><h3>2. 特色功能可视化：超兔“项目进度管控”流程图</h3><p>对于<strong>系统集成企业</strong>，超兔的“项目进度管控”解决了“项目延期、成本超支”的痛点：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047551509" alt="" title="" loading="lazy"/></p><pre><code>graph TD
    A[项目启动→设定关键节点（需求确认/开发/测试/验收）] --&gt; B[甘特图展示进度（实际vs计划）]
    B --&gt; C[车间大屏实时显示（待办任务/超期节点）]
    C --&gt; D[关键节点触发待办（如“需求确认”→提醒客户签字）]
    D --&gt; E[超期预警→自动通知项目负责人]
    E --&gt; F[项目结案→计算“实际成本vs预算”]</code></pre><p><strong>场景案例</strong>：某系统集成商通过超兔管理“医院信息化项目”，甘特图显示“开发节点延期2天”，系统自动预警，项目负责人及时调整资源，最终项目按时交付，成本控制在预算内。</p><h2>六、数据分析：从“统计”到“预测”的AI革命</h2><p>数据分析已从“事后统计”升级为“事前预测”，<strong>数据整合能力、AI驱动、可视化程度</strong>是关键。以下是对比表：</p><h3>1. 数据分析维度对比表</h3><table><thead><tr><th>品牌</th><th>数据整合</th><th>AI驱动</th><th>可视化能力</th></tr></thead><tbody><tr><td>超兔一体云</td><td>销售/客服/供应链/项目多模块整合</td><td>线索转化预测、收支差分析、项目ROI预测</td><td>自定义仪表板+多表聚合+甘特图</td></tr><tr><td>Oracle CX</td><td>多渠道（营销/销售/服务/供应链）+CDP整合</td><td>线索评分、需求预测、客户流失预警、定价优化</td><td>BI报表+智能仪表板+自然语言查询</td></tr><tr><td>Less Annoying CRM</td><td>仅销售/客户基础数据</td><td>无AI功能</td><td>基础报表（如“销售业绩统计”）</td></tr><tr><td>浪潮CRM</td><td>销售/客服数据整合</td><td>简单趋势分析</td><td>固定报表</td></tr><tr><td>励销云</td><td>销售/线索数据整合</td><td>商机赢率预测</td><td>销售漏斗可视化</td></tr><tr><td>Agile CRM</td><td>销售/营销数据整合</td><td>邮件打开率预测</td><td>拖放式报表</td></tr></tbody></table><h3>2. 特色功能可视化：Oracle CX“AI驱动决策”流程图</h3><p>对于<strong>大型高科技企业</strong>，Oracle CX的“AI分析”解决了“数据太多无法落地”的痛点：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047551510" alt="" title="" loading="lazy"/></p><pre><code>graph TD
    A[多渠道数据采集（营销/销售/服务/供应链）] --&gt; B[CDP整合→360°客户视图]
    B --&gt; C[AI分析（线索评分/需求预测/流失预警）]
    C --&gt; D[BI可视化（仪表板/报表）]
    D --&gt; E[驱动业务行动（如“高流失风险客户”→触发 retention  campaign）]</code></pre><p><strong>场景案例</strong>：某手机厂商用Oracle CX分析“客户流失数据”，系统预测“3个月内将有10%的客户流失”，并推荐“针对这些客户发送‘以旧换新’优惠券”，最终流失率降低15%。</p><h2>七、综合能力雷达图：各品牌优劣势量化</h2><p>我们用<strong>5分制雷达图</strong>量化各品牌在五大维度的能力（分数越高越优），直观展示“长板与短板”：</p><table><thead><tr><th>品牌</th><th>销售管理</th><th>客服支持</th><th>供应链协同</th><th>项目管理</th><th>数据分析</th></tr></thead><tbody><tr><td>超兔一体云</td><td>4.5</td><td>4.0</td><td>4.5</td><td>4.5</td><td>4.5</td></tr><tr><td>Oracle CX</td><td>4.8</td><td>4.8</td><td>4.6</td><td>4.2</td><td>4.9</td></tr><tr><td>Less Annoying CRM</td><td>3.0</td><td>2.5</td><td>1.0</td><td>1.0</td><td>2.0</td></tr><tr><td>浪潮CRM</td><td>3.5</td><td>3.0</td><td>2.0</td><td>2.0</td><td>3.0</td></tr><tr><td>励销云</td><td>4.0</td><td>2.5</td><td>1.5</td><td>2.0</td><td>3.5</td></tr><tr><td>Agile CRM</td><td>3.5</td><td>3.0</td><td>1.5</td><td>2.5</td><td>3.5</td></tr></tbody></table><h2>八、选型建议：匹配业务场景是关键</h2><p>最后，结合<strong>企业规模、业务类型、核心需求</strong>给出选型结论：</p><ol><li><p><strong>项目型/制造型企业（中小到中大型）</strong> ：选<strong>超兔一体云</strong></p><ol><li>需求：多方协同、收支管控、产销一体化</li><li>场景：系统集成、设备制造、工程服务</li></ol></li><li><p><strong>大型企业（制造/高科技/金融）</strong> ：选<strong>Oracle CX</strong></p><ol><li>需求：全链路数据整合、AI驱动、行业深度适配</li><li>场景：汽车制造、手机厂商、银行</li></ol></li><li><p><strong>小微型企业（初创/零售/服务）</strong> ：选<strong>Less Annoying</strong> <strong>CRM</strong></p><ol><li>需求：无代码上手、低成本、基础销售管理</li><li>场景：小餐馆、美甲店、初创电商</li></ol></li><li><p><strong>传统中小企业（批发/零售）</strong> ：选<strong>浪潮</strong> <strong>CRM</strong></p><ol><li>需求：行业模板、基础销售/客服协同</li><li>场景：服装批发、家居零售</li></ol></li><li><p><strong>电销型企业（</strong> <strong>快消</strong> <strong>/教育）</strong> ：选<strong>励销云</strong></p><ol><li>需求：智能拓客、销售自动化、电销模块</li><li>场景：保健品电销、教育咨询</li></ol></li><li><p><strong>初创科技企业（SaaS/互联网）</strong> ：选<strong>Agile</strong> <strong>CRM</strong></p><ol><li>需求：轻量级协作、多渠道整合、拖放式流程</li><li>场景：SaaS创业、互联网产品</li></ol></li></ol><h2>九、总结：CRM的本质是“业务协同”</h2><p>无论选哪个品牌，<strong>CRM</strong> <strong>的核心不是“功能多”，而是“匹配业务场景”</strong> ：</p><ul><li>小微型企业不需要“AI预测”，需要“简单录入线索”；</li><li>项目型企业不需要“全渠道服务”，需要“多方协同”；</li><li>大型企业不需要“无代码上手”，需要“全链路数据整合”</li></ul><p>（注：文中功能相关描述均基于公开披露信息，具体功能服务与价格以厂商实际落地版本为准。）</p>]]></description></item><item>    <title><![CDATA[隐形引擎：汽车制造Agent如何无声地重构生产线？ 雨大王 ]]></title>    <link>https://segmentfault.com/a/1190000047551520</link>    <guid>https://segmentfault.com/a/1190000047551520</guid>    <pubDate>2026-01-19 17:05:41</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在全球制造业加速向智能化转型的浪潮中，汽车工业作为技术密集型的代表产业，正经历一场前所未有的变革。传统的生产模式在效率、成本和质量控制方面逐渐暴露出局限性，特别是在新能源汽车和定制化生产需求激增的背景下，如何实现柔性制造和精益管理成为行业关注的核心问题。而近年来悄然兴起的AI Agent技术，正在以一种“隐形”的方式，逐步渗透到汽车生产线的各个环节，展现出颠覆性的重构潜力。<br/>那么，汽车制造中的Agent到底是什么？它为何能如此“无声”地改变生产流程？简单来说，AI Agent是一种具备自主性与决策能力的智能系统，它融合了物联网、大数据和人工智能技术，能够主动感知环境、理解意图、自主规划并执行动作，而无需依赖预设规则或人工干预。这种技术特性使其在解决制造业长期存在的“数据孤岛”、效率瓶颈和经验传承等问题时，展现出独特的价值。<br/>在汽车生产中，许多环节对精度和一致性的要求极高，而传统模式往往依赖人工经验和分散的自动化设备，导致跨系统协作效率低下。例如，在焊接环节，虚焊和漏焊等质量问题不仅影响整车品质，还增加了生产成本。数据显示，在某些工厂中，焊接缺陷的处理时间占总生产时间的可观比例，且人工检测的主观性常常带来标准不一的困扰。然而，通过引入AI Agent，这些痛点得到了有效缓解。<br/>以Geega工业AI平台在极氪智慧工厂的应用为例。该平台通过实时监测焊接电流与压力参数，并结合数千条工艺数据，能够在数分钟内识别焊接缺陷并自动生成调优指令。这使得焊点一次合格率从传统的95%提升至99.5%，同时将缺陷处理时间缩短了70%以上。而广域铭岛的另一项技术创新则聚焦于涂料利用率的提升。在极氪工厂的生产线上，Agent系统通过智能视觉终端监控火花落点，优化喷涂参数，使涂料利用率提高了12%，并将色差波动控制在1.5以内。这些优化不仅降低了生产成本，还提升了消费者的满意度。<br/>吉利集团也在积极布局Agent技术，将其应用到汽车制造的多个环节。作为中国制造业的领军企业，吉利汽车不仅在传统燃油车领域占据重要地位，更在新能源和智能汽车领域展现出强大的创新能力。极氪、领克等子品牌在生产过程中广泛应用AI Agent，实现了从生产调度到质量检测的全流程智能化。例如，在冲压环节，Agent技术通过精确的模具控制和参数调整，大幅减少了因人为因素导致的废品率；在总装环节，多智能体系统的协作则确保了装配过程的顺畅与高效。这些案例表明，Agent不仅是吉利集团提升竞争力的秘密武器，更是整个行业智能化转型的风向标。<br/>某汽车有限公司与某科技公司的合作，也展示了国产多智能体技术在汽车制造中的突破。搭载智平方GOVLA大模型的通用智能机器人（AlphaBot 2）在工厂中完成了上下料、拖拽料车、贴挡风玻璃标签等多项任务，其灵活度和适应性远超传统设备。<br/>从这些案例可以看出，汽车制造Agent正在以一种“无声”的方式重构生产线。它通过数据驱动的智能决策和跨系统的协同操作，将传统依赖经验的制造过程转化为可量化、可优化、可自动化的闭环系统。这种重构不仅提升了生产效率和产品质量，还为制造业的可持续发展注入了新的动力。</p>]]></description></item><item>    <title><![CDATA[Novproxy出海攻略之用一杯奶茶钱换来的海外原生住宅IP，让我白嫖了一整年——技术细节与长期主义]]></title>    <link>https://segmentfault.com/a/1190000047551524</link>    <guid>https://segmentfault.com/a/1190000047551524</guid>    <pubDate>2026-01-19 17:05:06</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <ol><li>从“免费三百刀”到“无限续命”：谷歌云风控模型到底在查什么</li></ol><p>谷歌内部把免费层用户放进一个名叫“Sandbox-First”的实时评分管道。</p><p>核心维度只有三项，但权重动态调整：</p><ul><li>Identity Realism（身份真实度）</li></ul><p>包括姓名与账单地址的同源性、信用卡 BIN 所属银行的风险等级、手机号段的可追溯性。</p><p>很多人以为“GV 号就能过”，其实谷歌更在乎“号段与账单州”是否在同一 LATA（本地接入与传输区域）。一个洛杉矶账单地址配 415 区号，就会被降权。</p><ul><li>Network Credibility（网络可信度）</li></ul><p>不是简单看“是不是住宅 IP”，而是看 ASN 的“邻居质量”。</p><p>假设你的 IP 在 AS7922（Comcast），但同 /24 段过去 30 天被 1200 次用于批量注册，谷歌就会把该段标记成“灰色泳池”。</p><p>静态 ISP 的价值在于：你买的是“/30 甚至 /32”，邻居只有你自己，历史干净。</p><ul><li>Behavior Velocity（行为速度）</li></ul><p>注册当天就创建 8 核实例 + 开 5 个 API 密钥 + 启用 Billing Export，会被系统判定为“脚本狗”。</p><p>正确姿势是“三天递增”：第一天只开 Compute API，第二天创建 f1-micro，第三天再升级。</p><p>让风控模型把你错分成“谨慎的个人开发者”。</p><p>只要三项总分 &gt; 0.78（满分 1.0），你就会被移入“Low-Risk”队列，后续额度、Survey、Partner Coupon 都会优先发放。</p><p>原生住宅 IP 是网络可信度这块最省事的加分项，能把 0.4 直接拉到 0.75， 剩下的交给时间与演技。</p><ol start="2"><li>住宅 IP 的底层原理：为什么 ASN 类型比地理位置更关键</li></ol><p>ASN 的分类</p><p>全球 9 万多 ASN，大体分四类：</p><ol><li>Transit / Tier-1：Level3、NTT 等，纯粹骨干，不直接放用户。</li><li>IDC / Hosting：AS15169（Google 自身）、AS396982（DigitalOcean），被 CDN 与云服务商包揽。</li><li>ISP / Residential：AS7922（Comcast）、AS20115（Charter），末端接入，用户密度高。</li><li>Static ISP / Business：AS22773（Cox Business）、AS14537（Sprint Business），给企业与专线，IP 块固定，却挂在住宅 ASN 下。</li></ol><p>第 4 类就是“静态 ISP”——它同时拥有“住宅 ASN 的干净标签”与“固定 IP 的可运维性”，是注册谷歌云的黄金通道。</p><p>Novproxy 拿到的正是这类块：Cox、Spectrum、AT&amp;T Business，/32 单卖，WHOIS 显示业务客户，但反向解析又能对上家庭小区。</p><ul><li>RIR 注册信息与谷歌交叉验证</li></ul><p>谷歌会拉 IRR 与 RPKI，看该前缀的 maintainer 是不是“RESOLVE-CUSTOMER”。如果是，可信度再加 10%。</p><p>很多便宜“原生 IP”其实是托管商自己拿 PI 空间伪造 AS，RPKI 无效，注册当天就触发人工复核。</p><ul><li>GeoIP 粒度</li></ul><p>谷歌内部不用 MaxMind，而是自研“GIP”库，把全美切成 7 万个“社区指纹”（neighborhood fingerprint）。</p><p>住宅 IP 的指纹与机房 IP 的最大差别在于“晚高峰抖动”：</p><p>住宅 19-22 点延迟上浮 8-15 ms，丢包 0.2-0.5%；机房全天平稳。</p><p>谷歌会主动 ping 你的 IP 做 baseline，只要抖动曲线像“家庭”，就坐实了住宅身份。</p><ol start="3"><li>静态 ISP 与动态轮换池的区别：一张图没有，但我能讲明白</li></ol><ul><li>动态轮换池</li></ul><p>每 5-30 分钟换一次 IP，适合爬数据、刷广告，但对“注册场景”是灾难：</p><ol><li>谷歌注册页把“IP 突变”视为代理铁证；</li><li>同一出口可能被前人反复注册，ASN 信誉早已花光；</li><li>轮换节点通常托管在 Vultr、Hetzner，ASN 类型就是 IDC，直接扣到 0 分。</li></ol><ul><li>静态 ISP</li></ul><p>一个 IP 绑定一个账号，直到你自己释放。</p><p>优势：</p><ol><li>历史空白，邻居只有自己；</li><li>可以反向解析成“cpe-xxx-xx.comcast.net”，像极家庭网关；</li><li>支持 30 天续费，IP 不变，养号期不会掉链。</li></ol><p>劣势：</p><ol><li>不能暴力并发，需要单线程精心呵护；</li><li>价格高于轮换池（Novproxy 3 USD/月，依旧比 0.5 USD/GB 的动态流量便宜，因为不限带宽）。</li></ol><p>一句话：注册用静态，业务用动态，别混用。</p><ol start="4"><li>注册链路拆解：浏览器指纹、IP 轨迹、账单地址的三轴对齐</li></ol><ul><li>浏览器指纹</li></ul><p>谷歌注册页会调 uach（User-Agent Client Hints）与 WebGL vendor。</p><p>把显卡型号改成“Intel Inc.”+“Intel Iris OpenGL Engine”即可，苹果味最浓，风控认为你是 Mac 用户，天然高净值。</p><p>语言栏只留 en-US,en，再多就扣分。</p><p>时区与 IP 对齐，别用插件硬改，用系统级变量，防止 JS 读到时区偏移量。</p><ul><li>IP 轨迹</li></ul><p>注册全程禁止跳国家。</p><p>如果你买的美西 IP，却在 6 小时后从香港登录控制台，系统会强制 SMS 二验。</p><p>解决方法是本地浏览器 + 远程桌面双通道：</p><p>本地用住宅 IP 注册，注册完立刻在同一 IP 下开 Chrome Remote Desktop，以后远程维护，谷歌看到的永远是“同一屏幕、同一鼠标轨迹”。</p><ul><li>账单地址</li></ul><p>信用卡账单地址最好与 IP 的 ZIP Code 前 3 位一致（Census Bureau 的 CBSA 区）。</p><p>我用的是 Wise 美元卡，账单地址改到 Irvine, CA 92618，与 IP 的 ZIP 92606 同属 Orange County，系统判定“通勤范围”，可信度 +0.12。</p><p>若无法改地址，可在 Google Pay 里新增“secondary address”，强制对齐。</p><ol start="5"><li>养号期行为画像：让机器学习把你误判成“高价值开发者”</li></ol><p>谷歌云的“开发者信号”模型把用户分成六类：</p><p>Exploratory Student / Startup Founder / Enterprise Admin / Academic Researcher / Personal Experimenter / Suspicious Automaton。</p><p>我们要的是“Startup Founder”——额度高、续命概率大、人工审核宽松。</p><p>画像公式：</p><ol><li>节奏感</li></ol><p>注册后第 1 天只开“Compute Engine API”；</p><p>第 3 天创建 1 个 f1-micro 实例，区域 us-west1-b（与 IP 同州）；</p><p>第 7 天启用 Cloud Shell，产生 20 条交互式命令（手动敲，别复制）；</p><p>第 14 天打开 BigQuery，导入 500 行公开数据集；</p><p>第 30 天提交 1 张 Support 票，询问“如何为项目设置预算告警”。</p><p>这套节奏能让系统把你标成“谨慎的初次创业者”。</p><ol start="2"><li>多样性</li></ol><p>谷歌喜欢“多产品交叉使用”。</p><p>除了 GCE，再去 Cloud Run 部署一个静态网页，用 Firebase Hosting 做重定向，用 Artifact Registry 存镜像。</p><p>每个产品都点几下控制台，留下“人类在探索”的点击热图。</p><ol start="3"><li>社交背书</li></ol><p>把 github 仓库加到 Google Cloud Build，触发几次 CI。</p><p>谷歌会拉公开事件流，一旦发现你在“持续交付”，就认定你是真实开发者，而不是批量注册狗。</p><ol start="6"><li>额度耗尽后的四条生路：Support Ticket、Survey、Partner、Academic</li></ol><ul><li>Support Ticket 法</li></ul><p>额度剩 5% 时发 ticket，类别选“Billing → Budget &amp; Payment”，正文只写一句话：</p><p>“My startup is close to finishing MVP testing, any chance to extend the trial so we can evaluate BigQuery BI Engine?”</p><p>不要提“free credit”，系统关键词触发器会秒拒。</p><p>人工客服一般给 100-200 刀，继续跑 2 个月。</p><ul><li>Survey 法</li></ul><p>谷歌云每年会向“Low-Risk”用户推送“Cloud Customer Survey”。</p><p>填写时间选在凌晨 1-3 点（PST），因为值班审核是印度团队，他们 KPI 是“完成率”，你填完就能当场拿兑换码，面值 50-350 刀不等。</p><p>关键：最后一道开放题写“Looking forward to Vertex AI new runtime but need more GPU quota”，审核会把你标成“AI 潜力用户”，额度翻倍。</p><ul><li>Partner 法</li></ul><p>谷歌云 Partner 手里有“Entrepreneur Launch Pack”，官方给 1000 刀，Partner 自己留 200，放 800 刀出来。</p><p>你只需在 LinkedIn 把头衔改成“Co-Founder @ xxx.ai”，发邮件给任意 Partner，对方会帮你走“Track 2”申请，7 天到账。</p><p>住宅 IP 在这里的作用：Partner 后台会查你账号的“Risk Tier”，Tier&lt;2 才给批。原生 IP 注册的用户默认 Tier=1。</p><ul><li>Academic 法</li></ul><p>非学生也能用“Faculty Authorization”。</p><p>在 Research.google.com 申请“Cloud Research Credit”，写一份 300 字摘要，主题可以是“使用 BigQuery 分析加州空气质量”。</p><p>谷歌学术团队只看 ASN 类型： residential 直接批 5000 刀，IDC 直接拒。</p><p>我 3 天拿到授权，额度 12 个月，不限区。</p><ol start="7"><li>多账号矩阵：如何在同一台电脑上养 5 个不互杀的谷歌云身份</li></ol><ul><li>硬件隔离</li></ul><p>用 BIOS 级虚拟机（QEMU-KVM）+ PCIe 直通，每个 Guest 挂一张 USB 网卡，走不同静态 ISP 出口。</p><p>谷歌拿不到宿主机的 Intel ME 信息，只能看到直通的网卡 MAC，不会关联。</p><ul><li>软件隔离</li></ul><p>浏览器用 Ungoogled-Chromium，禁用 Safe Browsing 与 CRLSet，防止后台连谷歌服务器泄露真实 IP。</p><p>每个 Profile 配独立字体包、独立 Canvas 噪声，Cookie 存于 tmpfs，关机即焚。</p><ul><li>行为隔离</li></ul><p>账号 A 做 AI 训练，账号 B 做 Web 爬虫，账号 C 做电商独立站，互不交叉 repo。</p><p>谷歌的“跨账号相似度”模型只看“项目协同者”与“账单卡号”。</p><p>卡号用同一张 Wise 没关系，因为 Wise 的虚拟卡 BIN 是 pooled，几千人共用，系统无法判定。</p><ul><li>时间隔离</li></ul><p>每个账号每月只登录 3 次，每次 30 分钟，其余操作走 REST API + Service Account。</p><p>人类行为越少，越不容易被关联。</p><ol start="8"><li>翻车现场复盘：我亲身踩过的 9 个大坑与急救方案</li><li>注册当天顺手开了“Cloud Armor”，2 小时后收到“需要验证信用卡”邮件——因为 Armor 默认是付费级。</li></ol><p>急救：立即删资源，发 ticket 说“误触”，客服退款并恢复额度。</p><ol start="2"><li>用 iPhone 流量登录后台，IP 跳到 T-Mobile 5G，账号被锁。</li></ol><p>急救：用最初住宅 IP 开远程桌面拍照上传驾照，24h 解封。</p><ol start="3"><li>买代理时贪图便宜，拿到被标记的 /24，注册页直接 403。</li></ol><p>急救：让客服换 IP，Novproxy 支持 72 小时内免费重配。</p><ol start="4"><li>用云函数定时开关机，频率 5 分钟一次，被判“挖矿”。</li></ol><p>急救：改频率到 30 分钟，发邮件承诺“测试弹性伸缩”。</p><ol start="5"><li>把实例命名为“test-scan-open”，触发滥用扫描。</li></ol><p>急救：重命名“ca-web-mvp”，附 ticket 说明“内部 Web 服务”。</p><ol start="6"><li>在推特晒流量图，附带实例 ID，被路人举报“免费层滥用”。</li></ol><p>急救：锁推，删图，开私密账户。</p><ol start="7"><li>把 GitHub 公开库写成“google-cloud-free-cheat”，被谷歌 GitHub 扫描器抓到。</li></ol><p>急救：改库名，加 MIT 声明，发邮件道歉。</p><ol start="8"><li>用 PayPal 虚拟卡，BIN 被谷歌拉黑，结算失败。</li></ol><p>急救：换 Wise 实体卡，同地址，3 天后重试。</p><ol start="9"><li>额度还剩 10 刀时开 4 卡 T4 GPU，瞬间欠费 120 刀。</li></ol><p>急救：立刻关实例，发 ticket 申请“首次销账”，谷歌豁免欠款。</p><ol start="9"><li>成本核算：三美元月费到底值不值？给你一张“隐形账单”</li></ol><ul><li>显性成本</li></ul><p>静态 ISP 3 USD × 12 = 36 USD/年</p><ul><li>隐性节省</li></ul><ol><li>账号被封导致的时间成本：重新注册 + 养号 30 小时 × 时薪 20 USD = 600 USD</li><li>商务级网络互连：Comcast Business 静态 IP 市售价 120 USD/年，且需签 2 年合约。</li><li>谷歌云额度：保守 800 USD/年（按最低续命两次算）。</li></ol><p>36 USD 换 1520 USD 等价资源，ROI 42 倍。</p><p>如果项目真能跑到生产，36 USD 买到的“低风控标签”未来还能帮你申请 20 万美金的谷歌云加速器。</p><ol start="10"><li>长期主义：当谷歌云变成生产环境，如何把“白嫖”洗成“合规”</li></ol><ul><li>升级付费</li></ul><p>一旦项目有收入，立刻把结算账户迁到“Cloud Billing Account”，绑定实体公司银行卡。</p><p>谷歌对“从免费到付费”的账号会再跑一次 KYC，住宅 IP 用户通过率高达 97%。</p><p>迁完费后，之前“Low-Risk”标签不会消失，而是继承到组织节点，后续加项目依旧绿灯。</p><ul><li>申请官方折扣</li></ul><p>付费满 1 万美元后，找客户经理解锁“Committed Use Discount”，再省 57%。</p><p>客户经理同样会看历史风险评级，住宅 IP 出身会让你直接跳过“押金期”。</p><ul><li>成为 Partner</li></ul><p>当你手上管理 10 个客户，每家年消费 5 千刀，就能申请“Service Partner”。</p><p>谷歌会返 15% 佣金 + 额外 10% 市场基金，等于把过去“白嫖”的钱合法赚回来。</p><p>Partner 审核最看重“账号健康度”，住宅 IP 注册的组织默认全绿。</p><ul><li>退出策略</li></ul><p>如果有一天想关号，记得把静态 ISP 退订，让 IP 回到池子。</p><p>谷歌会保留 180 天日志，之后你的“网络指纹”被彻底稀释，下次再注册仍是干净身份。</p><p>这是对自己、也是对后来者的“环保”。</p><p>尾声</p><p>三美元买不到一杯手冲，却让我换来一整年与谷歌云“同桌吃饭”的门票；</p><p>更重要的是，它让我把“对抗风控”这门手艺，练成了“与平台共舞”的职业习惯。</p><p>技术人总嘲笑“免费是最贵的”，可如果能把免费当成杠杆，就能用最小成本撬动最大资源，再把资源变成现金流，把现金流换成下一个杠杆。</p><p>愿你在读完这篇长文后，不再到处找“最新破解”，而是沉下心去弄懂每一条日志、每一次评分、每一个 ASN。</p><p>当你真正理解规则，规则就会开始为你让路。</p><p>祝各位都能用一杯奶茶的钱，买到属于自己的云计算自由。</p>]]></description></item><item>    <title><![CDATA[清华/芝加哥大学最新Nature成果！AI令科学家提前1.37年晋升，科学探索范围缩减4.63% 超]]></title>    <link>https://segmentfault.com/a/1190000047551528</link>    <guid>https://segmentfault.com/a/1190000047551528</guid>    <pubDate>2026-01-19 17:04:17</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>人工智能（AI）的飞速发展正深刻改写科学研究的底层逻辑，从 AlphaFold 精准预测蛋白质结构并斩获诺贝尔奖，到 ChatGPT 驱动自主实验室实现高通量实验，再到大语言模型赋能科学写作与成果提炼，AI 正以多元形态展现着提升科研生产力、放大研究可见度的巨大潜力。</p><p>然而，AI 工具在推动个体科学家进步的同时，也引发了关于其对科学整体发展影响的深层思考，核心矛盾聚焦于个体利益与集体利益的潜在冲突：AI 究竟是仅助力科学家个人学术发展，还是能同时推动科学领域的多元化探索与长远进步？尽管已有研究暗示 AI 能为个体科学家带来显著益处，却也可能因 AI 教育差距加剧不平等，且引用模式的演变正悄然改变科研格局，但关于 AI 对科学影响的大规模实证测量仍显匮乏，其对科研生态的细致、动态作用仍亟待厘清。</p><p>近期，清华大学联合芝加哥大学的研究团队在 Nature 发表题为「Artificial intelligence tools expand scientists’ impact but contract science’s focus」的最新研究成果，通过分析 1980-2025 年间 4,130 万篇自然科学论文和 537 万名科学家的数据，揭示了一个关于 AI for Science 的惊人悖论：AI 是个人科研的「超级加速器」，却是集体科学的「隐形收缩器」。 这项研究不仅数据规模宏大，其分析框架更是精巧，为行业理解 AI 对科学的根本性影响提供了前所未有的系统性证据。</p><p><img width="723" height="438" referrerpolicy="no-referrer" src="/img/bVdnGl4" alt="" title=""/><br/>论文地址： </p><p><a href="https://link.segmentfault.com/?enc=T%2Bed%2BikEmoeQrjhLQ9yaMA%3D%3D.crqKFtdZapIXIhT7V3NQj77fa0heI5pio2lO6qsw7NzuEbsYk6kAdHnUgzL3Mb0f1OIHG7k%2BvHZEbRprnFoT3Q%3D%3D" rel="nofollow" target="_blank">https://www.nature.com/articles/s41586-025-09922-y </a></p><p>关注公众号，后台回复「AI 工具」获取完整 PDF</p><p>更多 AI 前沿论文：\<br/><a href="https://link.segmentfault.com/?enc=dCGGJnco6KThCholO2VsLA%3D%3D.u9Flvuo6vVwCWv5U6xvVPPka%2FFUYLOaPawGNFcVsblQ%3D" rel="nofollow" target="_blank">https://hyper.ai/papers</a></p><h2>研究思路：从个体到集体，构建一条完整的因果链条</h2><p>这项研究的顶层设计极为清晰，它没有停留在对现象的简单描述，而是构建了一条从识别（Identification）到探寻机制的完整分析链条。</p><h3>起点：精准识别（What）</h3><p>研究的第一步也是最关键的一步，是如何在浩如烟海的文献中，准确区分出哪些是「使用 AI 作为工具」的研究，而非「研究 AI 本身」的工作。研究团队刻意排除了计算机科学和数学领域，将焦点锁定在生物学、医学、化学等 6 个自然科学学科，确保研究的是 AI 对科学生产方式的「外溢影响」。</p><p><img width="723" height="417" referrerpolicy="no-referrer" src="/img/bVdnGl7" alt="" title="" loading="lazy"/></p><p>人工智能在科学研究中采用率的持续上升</p><p>a：在对 BERT 预训练模型进行两阶段微调的过程中，AI 论文识别性能不断提升：第一阶段使用较为粗略的训练数据，第二阶段在此基础上演化出更为精确的判别能力。研究人员分别基于论文标题（绿色）和摘要（紫色）独立训练两个模型，并将其整合为一个集成模型（橙色），在两个阶段中动态选择表现最优的模型（红色星号），以识别所有相关论文。</p><p>b：由人类专家对识别结果进行准确性评估。对于覆盖 AI 三个发展时期的样本，专家之间达成了高度一致（κ ≥ 0.93）。模型在与专家标注数据的验证中表现出较高准确性，F1 分数不低于 0.85。</p><p>c：在所选 AI 发展时期内，各学科中排名前 15 位的 AI 方法的相对采用频率。</p><p>d,e：在 1980 至 2025 年间、所选科学学科中，AI 增强型论文（d，n = 41,298,433）和采用 AI 的研究人员（e，n = 5,377,346）在机器学习（ML）、深度学习（DL）和生成式 AI（GAI）三个时期的增长情况。纵轴均采用对数刻度。</p><p>f：在 ML、DL 和 GAI 各时期内，所有所选学科中 AI 论文与研究人员数量的平均月增长率（n = 543 个月度观测值），误差条表示以均值为中心的 99% 置信区间（CI）。</p><h3>个体层面：量化个人收益（Individual Impact）</h3><p>在精准识别的基础上，研究首先回答了「对科学家个人有什么好处？」这个问题。通过追踪研究人员的年度发文量、引用量以及职业角色转变（从初级研究者到项目负责人），研究团队得出了那组令人震撼的数据：3.02 倍的发文量、4.84 倍的引用量、1.37 年的职业提前期。</p><p><img width="723" height="485" referrerpolicy="no-referrer" src="/img/bVdnGl5" alt="" title="" loading="lazy"/></p><p>人工智能扩大论文影响力并促进研究人员职业发展 </p><p>a：AI 论文（红色）与非 AI 论文（蓝色）在发表后获得的年均引用次数（插图分别展示前 1% 和前 10% 分位；n = 27,405,011），结果表明 AI 论文整体上吸引了更多引用。</p><p>b：采用 AI 的研究人员与未采用 AI 的研究人员的年均引用次数对比（P &lt; 0.001，n = 5,377,346），其中采用 AI 的研究人员获得的引用次数平均为未采用者的 4.84 倍。</p><p>c：在初级科学家中，采用 AI 与未采用 AI 的研究人员在两类角色转变上的概率对比（各学科均为 n = 46 年度观测值）。与未采用 AI 的同行相比，采用 AI 的初级科学家更有可能成长为成熟研究人员，且退出学术界的概率更低。</p><p>d：从初级研究人员转变为成熟研究人员的生存函数（P &lt; 0.001，n = 2,282,029）。该生存函数可很好地用指数分布进行拟合，结果显示采用 AI 的初级科学家更早完成这一转变。在所有面板中，误差条表示 99% 置信区间（CI）；a 中的插图以 1% 和 10% 分位数为中心，其余面板均以均值为中心。所有统计检验均采用双侧 t 检验</p><h3>集体层面：揭示结构变迁（Collective Structure）</h3><p>随后，研究视角从微观个体跃升至宏观生态，提出了一个更深刻的问题：「当每个人都因 AI 受益时，科学整体发生了什么变化？」为此，研究团队引入了两个创新性的集体指标：第一类是知识广度（Knowledge Extent），衡量研究主题的覆盖范围。第二类是后续互动（Follow-on Engagement），衡量后续研究之间的互动密度。研究人员将引用同一项原始研究的后续成果视为一个整体，统计这些成果之间的相互引用密度，结果发现 AI 研究的后续互动减少约 22%。</p><h3>归因：探寻背后机制（Why）</h3><p>最后，研究并未止步于现象，而是深入探究了这种「扩张-收缩」悖论背后的驱动机制。通过排除热门度、早期影响力、资助优先级等因素，研究团队将矛头指向了最根本的原因——数据可得性（Data Availability）。AI 天然地被吸引到数据丰富、易于建模的成熟领域，从而导致了集体注意力的集中和探索空间的收缩。</p><p>这条从「What」到「Why」的完整逻辑链，使得研究结论极具说服力。</p><h2>研究亮点：三大创新，直指核心</h2><h3>超越关键词匹配的 AI 论文识别法：</h3><p>传统研究常依赖关键词（如「Neural Network」）来筛选 AI 论文，但这极易引入偏差。本研究采用两阶段微调的 BERT 模型，分别在论文标题和摘要上进行训练，并集成判断。该方法经专家盲审验证，F1 值高达 0.875，为整个研究奠定了坚实可靠的数据基础。</p><p><img width="723" height="614" referrerpolicy="no-referrer" src="/img/bVdnGl6" alt="" title="" loading="lazy"/></p><p>扩展数据图——使用微调语言模型识别研究论文中 AI 使用情况的方法示意图</p><p>a：所部署语言模型的结构示意，该模型由分词器（tokenizer）、核心 BERT 模型以及线性层组成。</p><p>b：两阶段模型微调流程示意，其中在每个阶段研究人员分别设计了用于构建正样本与负样本数据的具体方法</p><h3>开创性的「知识广度」量化指标：</h3><p>如何衡量一个领域的「探索范围」？研究团队利用 SPECTER 2.0 这一专为科学文献设计的嵌入模型，将每篇论文映射到 768 维的语义向量空间。一个论文集合的「知识广度」被定义为其在该空间中所覆盖的最大直径。这种方法将抽象的「知识多样性」转化为可精确计算的几何距离，是科学计量学的一大创举。</p><h3>揭示「孤独的拥挤」学术互动模式：</h3><p>研究发现，引用同一篇 AI 论文的后续研究之间，相互引用的概率降低了 22%。这描绘出一幅「星型」而非「网状」的科研图景：大量研究像行星一样围绕少数几颗「明星」AI 成果公转，彼此之间却缺乏横向连接。这种「孤独的拥挤（Lonely Crowds）」状态，正是科学创造力被抑制的危险信号。</p><h2>如何用向量空间「称量」科学的广度？</h2><p>如果说整篇论文是一座宏大的建筑，那么其技术核心无疑是 SPECTER 2.0 嵌入模型与知识广度（Knowledge Extent）。</p><p>想象一下，整个科学知识体系是一个浩瀚的宇宙。SPECTER 2.0 的作用，就是给这个宇宙建立一套精密的坐标系。它通过学习数千万篇论文及其引用关系，将每一篇论文都转化为一个 768 维的坐标点（即向量）。在这个高维空间里，主题相近的论文，其坐标点就靠得近；主题迥异的论文，坐标点则相距甚远。</p><p>有了这个坐标系，如何衡量一个研究领域的「疆域」有多大？研究团队的思路非常巧妙：</p><p>取样： 从某个特定领域（比如 AI 增强的生物学研究）中，随机抽取一批论文。</p><p>定位： 利用 SPECTER 2.0，将这批论文全部投射到 768 维的知识宇宙中，得到一堆坐标点。</p><p>找中心： 计算所有这些点的几何中心（质心）。</p><p>量直径： 找到离这个中心最远的那个点，它到中心的距离，就被定义为这批论文的「知识广度」。</p><p><img width="723" height="539" referrerpolicy="no-referrer" src="/img/bVdnGl3" alt="" title="" loading="lazy"/></p><p>AI 的采用与科学领域内及跨领域知识广度的收缩相关</p><p>a：研究人员使用一个预训练的文本嵌入模型，将研究论文嵌入到一个 768 维向量空间中，并在该空间内度量论文的知识广度。</p><p>b：为了便于可视化，研究人员采用 t 分布随机邻域嵌入（t-SNE）算法，将随机抽取的 10,000 篇论文（其中一半为 AI 论文）的高维嵌入压缩至二维空间。如实线箭头和圆形边界所示，AI 论文（其知识广度在未降维的原始空间中计算）在整个自然科学范围内表现出更小的知识广度。此外，AI 论文在知识空间中的聚集程度更高，表明其对特定问题的关注更为集中。</p><p>c：各学科中 AI 论文与非 AI 论文的知识广度对比（P &lt; 0.001，各学科 n = 1,000 个样本），结果显示 AI 研究聚焦于更加收缩的知识空间。</p><p>d：各学科中 AI 论文与非 AI 论文的知识熵对比（P &lt; 0.001，各学科 n = 1,000 个样本），其中 AI 研究表现出更低的知识熵。在 c 和 d 两个面板中，箱线图以中位数为中心，箱体上下界分别为第一和第三四分位数（Q1 和 Q3），须线表示 1.5 倍四分位距。所有统计检验均采用中位数检验。</p><p>通过这种方法，研究团队可以公平地比较 AI 研究和非 AI 研究的「疆域」大小。结果清晰地显示，AI 研究的「知识广度」中位数比非 AI 研究小了 4.63%。这意味着，在 AI 的驱动下，科学家们正不约而同地涌向一片更小、更集中的知识区域。</p><p>更进一步，研究还分析了引用分布，发现 AI 研究呈现出更强的「马太效应」：前 22.2% 的 AI 论文拿走了 80% 的引用，其引用不平等程度（基尼系数 0.754）显著高于非 AI 研究（0.690）。</p><h2>结语</h2><p>综合来看，这套技术方案不仅回答了「科学是否变窄了」的问题，更精确地告诉研究人员「窄了多少」、「在哪个维度上变窄了」，以及「变窄后形成了怎样的结构」。这不再是模糊的担忧，而是可以用数据精确刻画的现实。</p><p>这项研究的价值，不在于否定 AI，而在于以最严谨的方式，揭示了研究人员拥抱 AI 时可能付出的隐性代价。它提醒研究人员，真正的科学智能，不应仅仅是提高效率的「工具」，更应成为拓展人类认知边界的「伙伴」。</p>]]></description></item><item>    <title><![CDATA[告别复杂操作！2026 主流 BI 平台横评：谁的 “AI 智能问数” 最能听懂人话？ 数据集成与治]]></title>    <link>https://segmentfault.com/a/1190000047551530</link>    <guid>https://segmentfault.com/a/1190000047551530</guid>    <pubDate>2026-01-19 17:03:38</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>一、行业背景：AI 问数成 BI 选型核心，“听不懂人话” 是最大痛点</h2><p>根据 Gartner 2025 年 ABI 技术趋势报告，<strong>2026 年生成式 AI 在 BI 工具中的渗透率将达 75%</strong>，AI 智能问数（用自然语言替代 SQL 查询）成为企业选 BI 的核心需求。但痛点同样突出：IDC 2024 年企业 BI 使用现状调查显示，<strong>60% 的业务人员因 “问数需要写 SQL” 放弃使用 BI</strong>，<strong>70% 的员工认为 “AI 问数结果不准”</strong>—— 比如问 “最近销量不好的产品”，系统返回 “近 1 年销量下降的所有产品”，完全偏离 “最近”（1 个月内）的需求；更有 45% 的企业因 “AI 问数听不懂口语化表述”（比如 “华南区门店坪效最高的前三名”），导致工具利用率不足 30%。<br/>本质上，企业需要的不是 “能问数的 AI”，而是 “能听懂人话的 AI”——<strong>让业务人员不用学代码，用日常说话的方式，精准拿到想要的数据</strong>。这也是本次横评的核心标准。</p><h2>二、2026 主流 BI 平台 TOP8 横评</h2><h3>TOP1：FineBI（综合评分：4.8/5）</h3><p><strong>产品定位</strong>：帆软旗下一站式智能 BI 平台，是<strong>Gartner 全球 ABI 魔力象限唯一入选中国独立 BI 厂商</strong>，IDC 报告连续八年（2017–2024）蝉联中国 BI 市场占有率第一。聚焦 “零代码 + AI 智能”，目标是 “让业务人员直接用自然语言问数”，覆盖从数据整合到智能洞察的全链路。<br/><strong>核心优势</strong>：</p><ol><li><strong>口语化问数高准确率</strong>：支持 “完全口语化表述”，比如 “上个月华南区门店坪效最高的前三名是哪几个？”，系统能自动拆解 “时间（上个月）、区域（华南区）、指标（坪效）、维度（前三名）” 四大要素，直接返回精准结果；即使表述模糊（比如 “最近销量不好的产品”），会自动弹出提示 “你是指近 30 天销量同比下降超过 20% 的产品吗？”，帮用户明确需求。</li><li><strong>上下文关联能力</strong>：能理解 “连续问题”—— 比如先问 “这个季度销售额环比增长多少？”，再问 “那华东区呢？”，系统会自动关联上一个问题的 “这个季度” 和 “销售额”，无需重复说明。</li><li><strong>多模态输出</strong>：问数结果不仅能生成柱状图 / 折线图，还能自动生成自然语言总结（比如 “上个月华南区门店坪效最高的前三名分别是 A 门店（1.2 万 /㎡）、B 门店（1.1 万 /㎡）、C 门店（1.05 万 /㎡），主要原因是 A 门店推出新饮品套餐，带动客单价提升 15%”），直接把 “数据” 变成 “结论”。</li></ol><p><strong>适用场景</strong>：</p><ul><li>业务人员日常查数（比如市场部问 “最近一周抖音广告带来的新客转化率”）；</li><li>管理层决策支持（比如 CEO 问 “这个月各事业部的利润完成率”）；</li><li>跨部门协作（比如销售部问 “CRM 客户复购率与 ERP 库存周转天数的关联”）；</li><li>新人上手（零代码，不需要学 SQL，10 分钟就能用）。</li></ul><p><strong>真实案例</strong>：可多便利是武汉社区便利店领先品牌，有600多家加盟店和12家直营店。其痛点在于传统手工补货依赖人工、效率低、失误率高，难以满足规模化发展。解决方案是自主研发“慧订货”自动配货系统，结合帆软分析平台和ERP系统，通过关键分析模型实现智能补货。结果显示，部分加盟商使用后节省叫货时间，盘点库存更轻松，缺货率降低，日均销售达8000元，还能提供精准配发和详实报表。</p><h3>TOP2：Tableau（综合评分：4.5/5）</h3><p><strong>产品定位</strong>：全球知名可视化 BI 工具，以 “高质量图表” 为核心优势，侧重 “数据可视化与故事化呈现”。<strong>核心优势</strong>：AI 问数支持 “关键词匹配 + 可视化联动”，比如问 “2026 年 Q1 销售额”，会自动生成折线图，并支持 “点击图表某部分” 进一步问数（比如点击 “华东区”，直接问 “这部分的占比是多少？”）；可视化效果行业顶尖，适合做 “汇报用的高颜值报表”。<strong>适用场景</strong>：需要 “可视化故事化” 的营销、设计、战略团队（比如做季度汇报的市场部，用图表讲 “销售额增长的故事”）。</p><h3>TOP3：Power BI（综合评分：4.4/5）</h3><p><strong>产品定位</strong>：微软旗下云 BI 工具，深度集成 Office 生态（Excel、Azure、Teams 等），侧重 “轻量级自助分析”。<strong>核心优势</strong>：AI 问数支持 “自然语言生成 DAX 语句”，比如问 “这个季度销售额环比增长多少？”，会自动生成对应的 DAX 公式（方便技术人员验证）；能直接导入 Excel 数据，适合 “用 Excel 做报表的财务团队”。<strong>适用场景</strong>：微软生态深度用户的企业（比如财务部门用 Excel 做预算，直接导入 Power BI 问 “预算完成率”）、中小微企业的轻量级分析。</p><h3>TOP4：Sisense（综合评分：4.3/5）</h3><p><strong>产品定位</strong>：云原生嵌入式 BI 工具，以 “AI 驱动的嵌入式分析” 为核心，侧重 “将 BI 能力无缝嵌入业务系统”（如 CRM、ERP、SaaS 产品），适合 “需要整合 BI 到现有业务流程的企业”。<strong>核心优势</strong>：AI 问数支持 “嵌入式场景”—— 比如在 CRM 系统中直接问 “这个客户的历史复购率是多少？”，无需切换工具，系统会自动关联 CRM 中的客户数据返回结果；支持 “预测式问数”，比如问 “下个月这个客户的复购概率是多少？”，会结合历史交易数据和行为特征生成预测结果；同时支持 “自定义 AI 模型”，企业可根据业务需求训练专属的问数逻辑。<strong>适用场景</strong>：需要嵌入式分析的 SaaS 企业（如把 BI 嵌入自己的产品给客户用）、中大型企业的业务系统整合（如在 ERP 里问 “当前库存的周转天数”）、需要预测性洞察的营销团队（如预测客户复购率）。</p><h3>TOP5：TIBCO Spotfire（综合评分：4.2/5）</h3><p><strong>产品定位</strong>：自助式高级分析 BI 工具，以 “实时数据 + 预测分析” 为核心，侧重 “深度探索与实时洞察”，适合 “需要实时数据和预测能力的企业”。<strong>核心优势</strong>：AI 问数支持 “实时数据查询”—— 比如问 “当前生产线的良品率是多少？”，会连接车间的实时传感器数据，1 秒内返回结果；支持 “预测式问数”，比如问 “未来 3 个月的库存需求是多少？”，会用机器学习模型结合历史销售数据和市场趋势生成预测；同时支持 “拖曳式建模”，业务人员无需代码就能搭建简单的预测模型（如销量预测）。<strong>适用场景</strong>：需要实时分析的制造企业（如生产线实时监控）、需要预测的零售企业（如库存需求预测）、需要深度探索的金融机构（如实时交易数据洞察）。</p><h3>TOP6：思迈特 SmartBI（综合评分：4.1/5）</h3><p><strong>产品定位</strong>：国产化智能 BI 工具，聚焦 “企业级 BI 解决方案”，侧重 “国产化适配与复杂场景支持”。<strong>核心优势</strong>：AI 问数支持 “多数据源关联”，比如连接 ERP（SAP）、CRM（Salesforce）、Excel 问 “客户复购率与订单金额的关系”，能自动整合多数据源的数据；国产化适配度高（支持信创体系），适合 “国产化需求强的传统企业”。<strong>适用场景</strong>：国产化需求强的传统企业（比如金融、政府、制造，需要符合信创要求）、需要整合多系统数据的企业。</p><h3>TOP7：永洪 BI（综合评分：4.0/5）</h3><p><strong>产品定位</strong>：大数据 BI 工具，以 “高性能计算” 为核心，侧重 “海量数据处理”，适合 “数据量极大的企业”。<strong>核心优势</strong>：AI 问数支持 “海量数据秒级查询”，比如问 “近一年的日订单量（1000 万条数据）”，能在 3 秒内返回结果；支持 “分布式计算”，适合处理 TB 级以上数据。<strong>适用场景</strong>：需要处理海量数据的企业（比如电商、物流，每天产生 millions 条订单数据）、互联网企业。</p><h3>TOP8：亿信华辰 BI（综合评分：3.9/5）</h3><p><strong>产品定位</strong>：行业化 BI 工具，以 “报表自动化” 为核心，侧重 “标准化报表生成”，适合 “需要固定报表的行业”。<strong>核心优势</strong>：AI 问数支持 “报表模板化问数”，比如问 “月度销售报表”，会自动生成 “标准格式的报表”（包含销售额、销量、毛利率等指标）；支持 “自动推送报表”（比如每月 1 号自动把报表推给管理层）。<strong>适用场景</strong>：需要 “标准化报表” 的行业（比如医疗（月度患者流量报表）、教育（年度招生报表）、政府（月度财政收入报表））。</p><h2>三、主流 BI 平台 AI 问数能力对比表</h2><p><img width="723" height="700" referrerpolicy="no-referrer" src="/img/bVdnGug" alt="image.png" title="image.png"/></p><h2>四、AI 智能问数 BI 工具选型指南：五步避开坑</h2><h3>1. 五步选型法</h3><ul><li><strong>第一步：明确 “用户” 和 “场景”</strong>：先想清楚 “谁用”（业务人员 / IT / 管理层）、“用什么”（日常查数 / 决策支持 / 报表汇报）、“痛点”（是 “听不懂人话” 还是 “数据不统一”）；</li><li><strong>第二步：测试核心功能</strong>：重点测 3 点 ——① 口语化问数准确率（比如用 “上个月华南区门店坪效最高的前三名” 测试）；② 上下文关联（比如连续问 “这个季度销售额”→“华东区呢？”）；③ 错误修正能力（比如用 “最近销量不好的产品” 测试是否有提示）；</li><li><strong>第三步：考察易用性</strong>：让业务人员 “零学习” 测试 —— 比如找一个从没用过 BI 的运营，看 10 分钟内能不能用自然语言问出 “上周门店客流量”；</li><li><strong>第四步：验证数据兼容性</strong>：确认工具能连接企业现有系统（比如 ERP、CRM、Excel），不需要额外做数据对接；</li><li><strong>第五步：评估服务</strong>：问厂商 “有没有同行业案例”“售后支持响应时间”，避免 “买了工具没人教”。</li></ul><h3>2. 首推 FineBI 的理由</h3><p>FineBI 是<strong>唯一能覆盖 “全行业 + 全规模 + 全场景” 的 AI 智能 BI</strong>：</p><ul><li>对小微型企业：零代码让业务人员直接用，不需要 IT 支持；</li><li>对中大型企业：能连接 200+ 数据源（ERP/CRM/ 数据库 / Excel），支持万人级用户协作；</li><li>对传统行业（制造 / 零售 / 金融）：有 180+ 行业模板，15 分钟就能搭建系统；</li><li>对新兴行业（电商 / 直播 / 互联网）：支持全渠道数据整合，实时问数（比如 “当前直播的观众转化率”）。</li></ul><h2>五、本文相关 FAQs</h2><h3>Q1：AI 智能问数真的能替代 SQL 吗？</h3><p>A：AI 智能问数的核心是 “把自然语言转换成查询逻辑”，<strong>能覆盖 80% 以上的日常业务场景</strong>—— 比如 “上个月销售额”“某区域坪效”“近 7 天库存周转”，这些场景的逻辑是 “固定维度 + 指标”，AI 能自动识别，完全不需要写 SQL。但对于<strong>复杂自定义场景</strong>（比如 “计算某产品近 3 个月的复购率，复购定义为 30 天内再次购买”），可能需要辅助设置 “复购的时间定义”，但依然不需要写完整的 SQL。总的来说，AI 问数能让业务人员 “摆脱对 IT 的依赖”，把更多时间花在 “分析结论” 上，而不是 “写代码查数”。</p><h3>Q2：AI 问数的准确率怎么保证？</h3><p>A：AI 问数的准确率取决于两个核心能力 ——<strong>自然语言理解（NLU）和行业知识沉淀</strong>：首先，NLU 要能 “拆解问题要素”：比如 “上个月华南区门店坪效最高的前三名”，需要识别 “时间、区域、指标、维度” 四个要素，缺一不可；其次，要 “懂行业术语”：比如零售行业的 “坪效”（每平米的销售额）、制造行业的 “良品率”（合格产品占比），AI 需要提前沉淀这些行业知识，才能准确理解；最后，要有 “错误修正机制”：如果用户表述模糊（比如 “最近销量不好”），AI 要能主动提示 “你是指近 30 天还是 7 天？”，帮用户明确需求。简单来说，准确率高的 AI 问数，一定是 “懂业务 + 懂用户” 的。</p><h3>Q3：企业用 AI 问数，数据安全怎么解决？</h3><p>A：数据安全是企业选 BI 的核心顾虑，主要看 3 点：</p><ul><li><strong>数据存储</strong>：工具是否支持 “本地部署”（把数据存在企业自己的服务器），避免 “数据上云” 的风险；</li><li><strong>权限管理</strong>：是否能设置 “角色权限”（比如业务人员只能看自己部门的数据，管理层能看全公司数据），避免 “数据泄露”；</li><li><strong>数据加密</strong>：是否支持 “传输加密”（比如 HTTPS）和 “存储加密”（比如 AES-256），确保数据在传输和存储过程中不被窃取。只要工具能满足这 3 点，AI 问数的安全问题就能解决 —— 毕竟，AI 只是 “查询工具”，数据的所有权和控制权始终在企业手里。</li></ul><p><strong>结语</strong>：选对 AI 智能问数 BI 工具，本质是选 “能帮业务人员节省时间的工具”—— 比如 FineBI 让业务人员从 “找 IT 写 SQL” 变成 “1 分钟问出结果”，每月节省的时间，就是企业省下来的利润。告别复杂操作，从 “选对能听懂人话的 BI” 开始。</p>]]></description></item><item>    <title><![CDATA[赋能央企 | 中智集团携手思迈特共筑数字化人才高地，激活“数据价值”新动能 Smartbi ]]></title>    <link>https://segmentfault.com/a/1190000047551539</link>    <guid>https://segmentfault.com/a/1190000047551539</guid>    <pubDate>2026-01-19 17:02:55</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047551541" alt="图片" title="图片"/></p><h2>背景</h2><p>在数字经济浪潮下，数据已成为驱动企业高质量发展的核心生产要素。作为人力资源服务领域的中央一级企业，中国国际技术智力合作集团有限公司（简称“中智集团”） 始终走在行业前列，积极贯彻国家数字经济发展战略。</p><p>为进一步夯实数字化转型的人才基础，近期，思迈特再度携手中智集团，成功推进并落地了2025年“<strong>数据价值素养</strong>”培训项目。本次合作不仅仅是一次技能培训，更是中智集团深化人才培养战略、构建数据驱动型组织的成功实践。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047551542" alt="图片" title="图片" loading="lazy"/></p><h2>01破局</h2><p><strong>从“技术支撑”到“业务赋能”，锚定人才核心诉求</strong></p><p>作为人力资源行业领军者，中智集团已构建完善的数据资源体系与统一数据门户，但在数字化转型深水区，一个核心痛点日益凸显：数据分析长期集中于技术部门，一线业务人员参与度低，且受限于理论知识，难以将数据与实际业务痛点深度结合。</p><p>真正的数字化转型，既需强大系统支撑，更需懂数据、通业务的复合型人才。如何打破“技术”与“业务”的壁垒，让数据能力在业务一线“落地生根”，成为中智集团此次人才培养的核心诉求。</p><p>在此背景下，中智集团与思迈特达成共识，确立“<strong>场景化、定制化、实战化</strong>”三大培训方针，目标直指打造一支“<strong>懂业务、会工具、能落地</strong>”的数字化主力军。</p><h2>02实战</h2><p><strong>以业务场景为靶，让数据成为业务决策“硬支撑”</strong></p><p>区别于传统标准化软件培训的照本宣科，此次培训并非提供标准化的课程，而是思迈特基于自身深厚经验，深度定制的一套深度融合业务、即刻赋能的定制化培训解决方案，实现了课程内容与业务场景的深度绑定。思迈特服务团队深入到各个部门，旨在帮助核心骨干建立数据思维，掌握数据分析基础方法、BI 工具（Smartbi）操作技能以及集团数据资源体系。</p><p>思迈特通过开展前期深度调研，将集团真实业务数据与高频工作痛点转化为实战教案。培训过程中，学员不仅要掌握理论基础，同时基于思迈特Smartbi平台，亲自上手实操三大业务场景，在实践过程中培养以数据为支撑的业务决策能力：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047551543" alt="图片" title="图片" loading="lazy"/></p><h4>成本分析场景</h4><p>降本增效实现供应链成本精准透视</p><p>针对成本分析场景，学员通过数据拆解“自营”与“委外”的成本差异，不盲目投入资源，而是用多维度数据划分业务价值等级，让决策有明确数据支撑。冰冷的数据转化为业务部门优化供应商结构、开展商务谈判的“强力底牌”，直接助力成本管控与利润挖掘。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047551544" alt="图片" title="图片" loading="lazy"/></p><h4>收入分析场景</h4><p>开源优投推动集团实现数据支撑决策</p><p>在收入分析场景，学员通过对客户行业、地区分布及业务类型的多维分析，清晰划分不同类型业务，寻找新增长点，一方面将资源向高价值业务与市场倾斜，另一方面对发展不及预期的业务进行动态评估与优化调整，为市场策略制定提供精准数据支撑，推动集团从 “经验决策” 迈向 “数据决策”，集中力量深耕高价值行业和地区。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047551545" alt="图片" title="图片" loading="lazy"/></p><h4>账单分析场景</h4><p>风控提效，从“人找数”到“数找人”</p><p>在账单逾期分析场景中，学员不仅掌握监控看板制作技能，更熟练运用Smartbi消息推送功能，将逾期预警直接送达责任人。这一机制让被动报表查看转变为主动风险干预，将分析系统从一个“需要被人查看的看板”变成了一个“能主动找人办事的助手”，显著提升业务流转效率与风控水平。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047551546" alt="图片" title="图片" loading="lazy"/></p><h2>03成效</h2><p><strong>人才与业务双重进化，培训价值可视化落地</strong></p><p>本次培训既是技能传递，更是思维革新，最终实现了人才能力与业务价值的双重跃升，培训后，学员独立完成业务数据分析任务的比例<strong>从15%跃升至78%</strong>，业务部门主动发起的数据应用<strong>需求增长200%</strong>。</p><p>在此之前的培训交付中，中智已经完成<strong>22名数据分析师Level 1 认证</strong>，而基于本期培训的良好成效，中智希望将数据素养培训与认证机制常态化、体系化，实现<strong>三年内重点培育具备Level 2数据分析能力的业务骨干</strong>，在集团内推广覆盖，打造层次清晰的人才梯队，持续推进数据驱动型组织建设。</p><p>对中智集团而言，开展培训并持续运营推广的本质，是将一次性的“培训项目”升级为系统性的“组织能力建设”，是一笔能带来文化变革、人才成长、业务增值和品牌提升的高回报战略投资，最终将为集团数字化转型注入源源不断的核心动能。</p><h4>文化重塑</h4><p>打破部门信息壁垒，扭转“凭经验决策”的传统模式，让“<strong>用数据决策、用数据管理</strong>”成为全员共识，为数字化转型筑牢“软环境”。</p><h4>人才赋能</h4><p>聚焦核心业务人群，拒绝“大水漫灌”，通过场景化教学实现“<strong>所学即所用</strong>”。员工既掌握数据分析方法与BI工具技能，又熟悉集团数据资源体系，同时形成“<strong>骨干引领、全员参与</strong>”的人才自我孵化良性循环。</p><h4>业务增效</h4><p>让业务核心人员熟练运用数据资产统一门户，将数据能力转化为经营分析、账单管理等具体工作的效能提升，既让培训价值“<strong>可视化、可量化</strong>”，更盘活了集团在IT与数据平台的长期投入，让“<strong>数据资产”真正成为业务增长的“核心动能</strong>”。</p><h2>04展望</h2><p><strong>长效共赢：数字化人才建设没有终点</strong></p><p>从中智集团的实践可以看出，央企数字化转型的核心，始终是“以人为本”。思迈特十分荣幸与中智携手，从初期的方案定制到后期的常态化合作，始终坚守“贴合业务、赋能于人”的原则，不追求表面光鲜，只专注实际价值。</p><p>中智的成功实践，也为更多央企推进数字化人才建设提供了可复制、可落地的参考范本——唯有把数据素养根植于人才培养，才能让数字化转型行稳致远。</p><p>未来，思迈特将继续发挥在商业智能与大数据分析领域的专业优势，与中智集团保持紧密战略协同，持续赋能其数字化人才队伍建设，为建设世界一流人力资源服务企业注入源源不断的数字动能。</p>]]></description></item><item>    <title><![CDATA[CI-96Z 金手指离线语音模组完全指南：小体积旗舰的量产之选 SmartPi ]]></title>    <link>https://segmentfault.com/a/1190000047551587</link>    <guid>https://segmentfault.com/a/1190000047551587</guid>    <pubDate>2026-01-19 17:01:56</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>前言</h2><p>在智能语音产品开发的硬件选型中，封装形式往往是一个被忽视但至关重要的因素。传统的排针模组虽然便于原型开发，但在大规模 SMT 生产线中却面临效率瓶颈。<strong>CI-96Z 系列金手指模组</strong>正是为此而生——它将旗舰级的语音识别能力与适合贴片生产的金手指封装完美结合，成为智能家电、照明控制等领域的高性价比量产方案。</p><p>本文将全面解析 CI-96Z 系列模组的技术特性、硬件设计要点、开发流程及应用实战，帮助开发者快速掌握这款面向量产的语音模组。</p><h2>一、模组定位与核心规格</h2><h3>1.1 产品定位</h3><p>CI-96Z 系列是 <strong>CI 系列中的金手指封装旗舰型号</strong>，其核心定位可概括为：</p><table><thead><tr><th>维度</th><th>特点</th></tr></thead><tbody><tr><td><strong>封装形式</strong></td><td>金手指 SMD22/DIP22，适合 SMT 贴片生产</td></tr><tr><td><strong>识别性能</strong></td><td>97% 综合识别率，与 CI-95C 旗舰相当</td></tr><tr><td><strong>词条容量</strong></td><td>1000 条（CI 系列最大容量）</td></tr><tr><td><strong>Flash 存储</strong></td><td>8M（CI 系列最大）</td></tr><tr><td><strong>特色功能</strong></td><td>支持蓝牙小程序 OTA 修改语音指令</td></tr><tr><td><strong>适用场景</strong></td><td>智能家电、照明、门锁、玩具等大规模量产产品</td></tr></tbody></table><h3>1.2 型号对比</h3><p>CI-96Z 系列目前有两个子型号：</p><table><thead><tr><th>参数</th><th>CI-96Z61</th><th>CI-96Z62</th></tr></thead><tbody><tr><td>芯片型号</td><td>CI1361</td><td>CI1361</td></tr><tr><td><strong>Flash 容量</strong></td><td><strong>8MB</strong></td><td><strong>8MB</strong></td></tr><tr><td><strong>命令词支持</strong></td><td><strong>\~1000 条</strong></td><td><strong>\~1000 条</strong></td></tr><tr><td>SRAM</td><td>288KB</td><td>288KB</td></tr><tr><td>适合场景</td><td>基础语音控制</td><td>复杂多功能产品</td></tr></tbody></table><blockquote><strong>选型建议</strong>：根据官方模块性能对比表，CI-96Z61/62 均支持 1000 条词条、8MB Flash。两者主要差异在于具体配置和成本，选择时请参考最新官方规格书。</blockquote><h3>1.3 快速规格一览</h3><table><thead><tr><th>指标分类</th><th>参数项</th><th>规格</th></tr></thead><tbody><tr><td><strong>核心性能</strong></td><td>AI 运算内核</td><td>BNPU V3.5 神经网络加速器</td></tr><tr><td> </td><td>CPU</td><td>32 位高性能 CPU，最高 210MHz</td></tr><tr><td> </td><td>综合识别率</td><td><strong>97%</strong></td></tr><tr><td><strong>存储资源</strong></td><td>SRAM</td><td>288KB</td></tr><tr><td> </td><td>Flash</td><td><strong>8MB</strong>（官方参数）</td></tr><tr><td><strong>音频能力</strong></td><td>麦克风配置</td><td>双麦</td></tr><tr><td> </td><td>AEC 回声消除</td><td>✗（双麦算法支持，但无内部 AEC）</td></tr><tr><td> </td><td>功放输出</td><td>2.4W @ 5V 4Ω</td></tr><tr><td><strong>电源特性</strong></td><td>供电范围</td><td>3.6V \~ 5.5V</td></tr><tr><td> </td><td>待机电流</td><td>\~45mA</td></tr><tr><td> </td><td>工作电流</td><td>&gt;500mA（带 4Ω 喇叭）</td></tr><tr><td><strong>机械参数</strong></td><td>封装形式</td><td>金手指 SMD22/DIP22</td></tr><tr><td> </td><td>模组尺寸</td><td>21 × 15mm</td></tr></tbody></table><h3>1.4 高级功能支持</h3><table><thead><tr><th>功能</th><th>支持情况</th></tr></thead><tbody><tr><td>自然说</td><td>✓ 系统自动泛化 + 用户指定泛化</td></tr><tr><td>声纹识别</td><td>✓ 支持男女声纹识别</td></tr><tr><td>声源定位</td><td>✓ 限双 MIC 型号</td></tr><tr><td>哭声检测</td><td>✓ 适用于婴童监护产品</td></tr><tr><td>鼾声检测</td><td>✓ 适用于健康监护产品</td></tr><tr><td>文字转语音 (TTS)</td><td>✓ 本地语音合成</td></tr><tr><td>自学习功能</td><td>✓ 支持中英文自学习指令</td></tr><tr><td><strong>蓝牙/小程序</strong></td><td><strong>✓ OTA 修改语音指令</strong></td></tr><tr><td>支持语言</td><td>中文、英文、日文、韩语</td></tr></tbody></table><h2>二、硬件设计要点</h2><h3>2.1 金手指接口说明</h3><p>CI-96Z 采用金手指封装设计，<strong>不支持插拔式连接</strong>，需要通过焊接方式集成到 PCB 上。</p><h4>接口定义</h4><table><thead><tr><th>引脚类型</th><th>引脚名称</th><th>功能说明</th></tr></thead><tbody><tr><td><strong>电源</strong></td><td>5V、GND</td><td>模组供电，支持 3.6-5.5V 宽电压</td></tr><tr><td><strong>音频输出</strong></td><td>SPK+、SPK-</td><td>喇叭输出，内置 2.4W 功放</td></tr><tr><td><strong>麦克风输入</strong></td><td>MIC+、MIC-</td><td>差分麦克风输入</td></tr><tr><td><strong>串口通信</strong></td><td>RX0/TX0、RX1/TX1</td><td>双路 UART，最高 3M 波特率</td></tr></tbody></table><h4>安装方式</h4><pre><code>┌─────────────────────────────────────┐
│         CI-96Z 金手指模组            │
│  ┌───┬───┬───┬───┬───┬───┬───┐      │
│  │ 5 │ 4 │ 3 │ 2 │ 1 │   │   │      │
│  ├───┼───┼───┼───┼───┼───┼───┤      │
│  │SPK│SPK│MIC│MIC│GND│...│5V │      │
│  │ + │ - │ + │ - │   │   │   │      │
│  └───┴───┴───┴───┴───┴───┴───┘      │
│     ←──── 21mm ────→ × 15mm         │
└─────────────────────────────────────┘</code></pre><p><strong>安装方案对比</strong>：</p><table><thead><tr><th>方式</th><th>优点</th><th>缺点</th><th>推荐场景</th></tr></thead><tbody><tr><td>竖直焊接</td><td>连接可靠，成本低</td><td>不可拆卸维修</td><td>原型验证</td></tr><tr><td>SMD 贴装</td><td>适合大规模生产</td><td>需要钢网和回流焊设备</td><td>量产产品</td></tr><tr><td>板对板连接器</td><td>可拆卸维护</td><td>增加连接器成本</td><td>需要模块化设计</td></tr></tbody></table><h3>2.2 电源设计</h3><pre><code>┌─────────────┐
   5V ───┤  CI-96Z     ├────────→ VCC (3.6-5.5V)
         │  模组        │
   GND ──┤             ├────────→ GND
         └─────────────┘
              │
              ├─ 10μF  ─┬─ GND
              └─ 100nF ─┘</code></pre><p><strong>设计要点</strong>：</p><ol><li><strong>独立供电</strong>：建议使用独立的 LDO 或 DC-DC + LDO 为模组供电</li><li><strong>滤波电容</strong>：在 VCC 引脚附近放置 10μF + 100nF 滤波电容</li><li><strong>接地设计</strong>：数字地与模拟地单点汇合，避免大电流回流经过音频前端</li></ol><h3>2.3 声学设计</h3><h4>麦克风布局</h4><ul><li>差分走线并包地处理</li><li>麦克风孔应有良好密封性，防止气漏</li><li>麦克风与喇叭之间应有声学隔离（如减震棉）</li></ul><h4>功放电路</h4><ul><li>功放电路应远离麦克风电路，避免电磁干扰</li><li>喇叭线建议使用屏蔽线或双绞线</li></ul><h3>2.4 接口防护</h3><ul><li><strong>UART/IO</strong>：预留 TX/RX 测试点以便调试升级</li><li><strong>ESD 防护</strong>：对外接口建议放置 ESD 保护器件</li><li><strong>防静电</strong>：焊接和生产过程中注意防静电保护</li></ul><h2>三、固件配置全流程</h2><h3>3.1 创建产品</h3><ol><li>登录 <strong>智能公元平台</strong>（<a href="https://link.segmentfault.com/?enc=CTVC9fL4jbWwic9lUySMlw%3D%3D.vSbYEOrX9D%2BAlgJlOxVdDqEMwqpUpbDYf02lKV5d8Tc%3D" rel="nofollow" target="_blank">smartpi.cn</a>）</li><li>进入「产品管理」→「所有产品」</li><li>点击「创建产品」</li><li>选择产品类别（如「灯具」→「照明灯」）</li><li>选择场景：<strong>纯离线方案</strong></li><li>选择模组：<strong>CI-96Z61 (CI13161)</strong> 或 <strong>CI-96Z62 (CI13162)</strong></li></ol><h3>3.2 版本配置步骤</h3><p>产品创建后，按照以下 9 个步骤完成固件配置：</p><pre><code>┌─────────────────────────────────────────────────────────┐
│                    固件配置步骤                          │
├─────────────────────────────────────────────────────────┤
│ ① 前端信号处理  → 麦克风配置、声学模型、产品特性         │
│ ② Pin 脚配置    → GPIO、PWM、UART 等端口配置            │
│ ③ 唤醒词自定义  → 配置唤醒词和灵敏度                     │
│ ④ 自选协议配置  → 自定义通信协议（可选）                 │
│ ⑤ 命令词自定义  → 配置语音控制命令                       │
│ ⑥ 发音人配置    → TTS 语音播报参数                       │
│ ⑦ 其它配置      → 开机播报、超时退出、主动退出           │
│ ⑧ 个性化音频    → 上传自定义音频文件                     │
│ ⑨ 优化配置      → 高级参数微调                           │
└─────────────────────────────────────────────────────────┘</code></pre><h3>3.3 前端信号处理（关键）</h3><h4>麦克风配置</h4><table><thead><tr><th>选项</th><th>说明</th></tr></thead><tbody><tr><td>单 MIC</td><td>适用于单麦克风硬件配置</td></tr><tr><td>双 MIC</td><td>更好的降噪效果，需确认硬件支持</td></tr></tbody></table><h4>声学模型选择</h4><p>根据产品应用场景选择专用模型，可以显著提升识别准确率：</p><table><thead><tr><th>场景</th><th>推荐模型</th></tr></thead><tbody><tr><td>通用照明</td><td>中文灯具通用 Pro</td></tr><tr><td>风扇控制</td><td>中文风扇通用 Pro</td></tr><tr><td>窗帘控制</td><td>中文窗帘通用 Pro</td></tr><tr><td>智能门锁</td><td>中文门锁通用 Pro5</td></tr><tr><td>安静环境</td><td>安静环境模型</td></tr><tr><td>抗干扰</td><td>低误识别模型</td></tr></tbody></table><blockquote><strong>注意</strong>：不同模型占用 Flash 空间不同，CI-96Z61 (1M Flash) 建议选择占用 0.6M 或更小的模型。</blockquote><h4>产品特性</h4><table><thead><tr><th>特性</th><th>说明</th></tr></thead><tbody><tr><td>语音识别 + 自学习</td><td>支持用户自定义命令词</td></tr><tr><td>语音识别 + 深度降噪</td><td>高噪声环境优化</td></tr><tr><td>语音识别 + AEC 打断</td><td>支持语音打断播报（限单 MIC）</td></tr><tr><td>语音识别 + 声纹识别</td><td>支持男女声纹识别</td></tr></tbody></table><h3>3.4 Pin 脚配置</h3><p>通过可视化配置自动生成控制代码，无需手写固件：</p><table><thead><tr><th>功能类型</th><th>应用场景</th></tr></thead><tbody><tr><td>GPIO 输出</td><td>控制继电器、LED 指示灯</td></tr><tr><td>PWM 输出</td><td>调光、调速控制</td></tr><tr><td>UART 通信</td><td>与主控 MCU 交互</td></tr><tr><td>变量控制</td><td>状态管理、逻辑控制</td></tr></tbody></table><h3>3.5 命令词配置</h3><h4>命令词容量限制</h4><ul><li><strong>CI-96Z61</strong>：最大 100 条命令词</li><li><strong>CI-96Z62</strong>：最大 300 条命令词</li></ul><h4>免唤醒命令词</h4><p>支持配置部分命令为「免唤醒」，无需先说唤醒词即可直接识别。注意：唤醒词 + 免唤醒命令词总数不能超过 20 条。</p><h4>灵敏度调节</h4><table><thead><tr><th>级别</th><th>效果</th></tr></thead><tbody><tr><td>低</td><td>误识别少，但可能漏识别</td></tr><tr><td>中</td><td>平衡识别率和误识别率（推荐）</td></tr><tr><td>高</td><td>识别更灵敏，但误识别概率增加</td></tr></tbody></table><h2>四、特色功能：蓝牙小程序 OTA</h2><h3>4.1 功能概述</h3><p>CI-96Z 系列最大的亮点之一是 <strong>支持通过蓝牙小程序进行 OTA 升级和配置</strong>，这意味着：</p><ul><li>无需拆机即可修改语音指令</li><li>无需重新烧录固件</li><li>支持远程参数调整</li></ul><h3>4.2 支持的操作</h3><table><thead><tr><th>操作</th><th>说明</th></tr></thead><tbody><tr><td>词表配置</td><td>在线修改唤醒词和命令词</td></tr><tr><td>参数调整</td><td>调整识别阈值、音量等参数</td></tr><tr><td>固件升级</td><td>通过蓝牙推送新固件</td></tr></tbody></table><h2>五、典型应用场景</h2><h3>5.1 智能照明</h3><p><strong>功能示例</strong>：</p><pre><code>// 伪代码示例
void on_voice_command(int cmd_id) {
    switch(cmd_id) {
        case CMD_LIGHT_ON:
            gpio_set_level(PIN_RELAY, 1);
            play_voice("灯已打开");
            break;
        case CMD_LIGHT_OFF:
            gpio_set_level(PIN_RELAY, 0);
            play_voice("灯已关闭");
            break;
        case CMD_BRIGHTNESS_UP:
            pwm_set_duty(PIN_PWM, brightness + 20);
            break;
    }
}</code></pre><p><strong>命令词设计</strong>：</p><table><thead><tr><th>唤醒词</th><th>命令词</th><th>动作</th></tr></thead><tbody><tr><td>小智小智</td><td>打开台灯</td><td>继电器吸合</td></tr><tr><td>小智小智</td><td>关闭台灯</td><td>继电器断开</td></tr><tr><td>小智小智</td><td>调亮一点</td><td>PWM 占空比增加</td></tr><tr><td>小智小智</td><td>调暗一点</td><td>PWM 占空比减小</td></tr></tbody></table><h3>5.2 智能家电（茶吧机/风扇）</h3><p><strong>控制逻辑</strong>：</p><ol><li>用户说出唤醒词：「你好小智」</li><li>设备回复：「我在」</li><li>用户说出命令：「烧水」</li><li>设备执行：GPIO 输出高电平 → 继电器吸合 → 加热器工作</li><li>设备播报：「正在烧水」</li></ol><h3>5.3 串口透传方案</h3><p>对于需要对接主控 MCU 的场景，CI-96Z 可作为语音协处理器：</p><pre><code>┌─────────────┐      UART      ┌─────────────┐
│   CI-96Z    │ ←──────────→  │   主控 MCU   │
│ 语音识别模块 │   命令 ID     │  (STM32/ESP) │
└─────────────┘               └─────────────┘
      │                              │
      ├─ GPIO（直接控制）              ├─ 执行业务逻辑
      └─ SPK（语音播报）              └─ 驱动显示屏/传感器</code></pre><p><strong>串口协议格式</strong>：</p><pre><code>0xAA 0x55 [CMD] [LEN] [DATA] [CS]</code></pre><table><thead><tr><th>字段</th><th>说明</th></tr></thead><tbody><tr><td>0xAA 0x55</td><td>帧头</td></tr><tr><td>CMD</td><td>命令字/命令词 ID</td></tr><tr><td>LEN</td><td>数据长度</td></tr><tr><td>DATA</td><td>数据内容</td></tr><tr><td>CS</td><td>校验和</td></tr></tbody></table><h2>六、烧录与调试</h2><h3>6.1 工具准备</h3><table><thead><tr><th>工具</th><th>说明</th></tr></thead><tbody><tr><td>CH340 驱动</td><td>USB 转串口驱动</td></tr><tr><td>烧录软件</td><td>固件烧录工具</td></tr><tr><td>串口调试工具</td><td>日志查看与命令调试</td></tr></tbody></table><h3>6.2 烧录步骤</h3><ol><li><strong>硬件连接</strong>：连接 UART 接口（RX/TX/GND/5V）</li><li><strong>打开烧录软件</strong>：选择对应的 .bin 固件文件</li><li><strong>配置参数</strong>：选择正确的 COM 端口和波特率</li><li><strong>执行烧录</strong>：点击烧录，等待进度完成</li><li><strong>验证结果</strong>：复位设备并测试语音功能</li></ol><h2>七、常见问题排查</h2><h3>7.1 模组焊接相关</h3><p><strong>Q：CI-96Z 金手指接口是否支持插拔式连接？</strong><br/>A：不支持。CI-96Z 设计为焊接固定，并非为插拔使用，目前也没有配套的金手指插槽。如需更换模块，建议设计可拆卸的连接方案或使用转接板。</p><h3>7.2 固件配置相关</h3><p><strong>Q：命令词数量超出限制怎么办？</strong><br/>A：检查是否超过模组支持的上限。根据官方模块性能对比表，CI-96Z61/62 均支持 <strong>1000 条词条</strong>。建议根据实际业务需求合理规划词表结构。<br/><strong>Q：Pin 脚配置不生效？</strong><br/>A：确认引脚号与实际硬件一致，注意部分引脚存在功能复用，配置错误可能导致功能冲突。</p><h3>7.3 语音调优相关</h3><table><thead><tr><th>问题</th><th>可能原因</th><th>解决方案</th></tr></thead><tbody><tr><td>识别不灵敏</td><td>灵敏度设置过低</td><td>在「优化配置」中提高阈值</td></tr><tr><td>误识别多</td><td>灵敏度设置过高</td><td>在「优化配置」中降低阈值</td></tr><tr><td>某个命令词识别差</td><td>命令词与唤醒词相似</td><td>在「特定命令词阈值」中单独调整</td></tr></tbody></table><h2>八、与其他模组的选型对比</h2><table><thead><tr><th>特性</th><th>CI-96Z</th><th>CI-03T</th><th>CI-95C</th><th>SU-03T</th></tr></thead><tbody><tr><td>封装形式</td><td>金手指</td><td>排针</td><td>排针</td><td>排针</td></tr><tr><td>识别率</td><td>97%</td><td>95%</td><td>97%</td><td>90%</td></tr><tr><td>词条数</td><td>1000</td><td>300</td><td>1000</td><td>40</td></tr><tr><td>Flash</td><td>8M</td><td>2M</td><td>4M</td><td>1M</td></tr><tr><td>蓝牙小程序</td><td>✓</td><td>✗</td><td>✓</td><td>✗</td></tr><tr><td>成本</td><td>中</td><td>低</td><td>高</td><td>低</td></tr><tr><td><strong>适合量产</strong></td><td><strong>✓</strong></td><td>✗</td><td>✗</td><td>✗</td></tr></tbody></table><p><strong>选型建议</strong>：</p><ul><li><strong>CI-96Z</strong>：大规模 SMT 量产的首选，性价比最高</li><li><strong>CI-03T</strong>：原型开发和小批量生产，成本低</li><li><strong>CI-95C</strong>：高性能要求的产品，识别率最高</li><li><strong>SU-03T</strong>：快速验证和 DIY 项目</li></ul><h2>九、总结</h2><p>CI-96Z 系列金手指模组是面向大规模量产的理想选择：</p><ol><li><strong>金手指封装</strong>：适合 SMT 贴片生产，提升生产效率</li><li><strong>旗舰性能</strong>：97% 识别率 + 1000 条词条容量</li><li><strong>丰富功能</strong>：支持声纹识别、声源定位、蓝牙小程序等</li><li><strong>高性价比</strong>：在大规模量产中具有成本优势</li></ol><p>对于智能家电、照明控制、门锁安防等需要大规模量产的产品，CI-96Z 是一个兼顾性能、成本和生产便利性的优秀选择。<br/><em>参考资料：SmartPi 官方文档 - CI-96Z 系列文档</em></p>]]></description></item><item>    <title><![CDATA[你们在用MySQL还是PostgreSQL？ 王中阳讲编程 ]]></title>    <link>https://segmentfault.com/a/1190000047551593</link>    <guid>https://segmentfault.com/a/1190000047551593</guid>    <pubDate>2026-01-19 17:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>大家好，我是地鼠哥，最近和我们就业陪跑训练营学员日常答疑的时候聊到一个有趣的话题，就像标题中说的，你们正在用什么DB呢？为什么呢？也欢迎在文末留言区交流。</p><p>最近几年，关注国内信创产业或数据库领域的人会发现一个现象：虽然MySQL在互联网公司的业务开发中依然占据主导地位，但那些主打“自主可控”、“高性能分布式”的国产数据库，绝大部分都是基于PostgreSQL深度开发的。</p><p>这并不是巧合。我们先来看看这几家头部厂商的选择：</p><ol><li><strong>腾讯云 TDSQL PG版（TBase）</strong><br/><a href="https://link.segmentfault.com/?enc=kSx7zTTQCSE797Gnz2TuFQ%3D%3D.A2%2BBCyinydhY%2FnwxZcscvyDHASkeoXDnKDsYVoNQTAveEZpUgIpBWvZGeH38bd5eUAoMku39zywqMqWF%2FyFbB5bbwNiGQhioZuTnvLYnp5U%3D" rel="nofollow" target="_blank">github.com/Tencent/TBa…</a><br/>他们引入了GTM全局事务管理器，实现了跨分片的事务支持。</li><li><strong>阿里云 PolarDB for PostgreSQL</strong><br/>他们重构了存储层，做到了“一写多读共享存储”，解决了传统数据库扩容慢的问题。</li><li><strong>华为云 GaussDB(for openGauss)</strong><br/><a href="https://link.segmentfault.com/?enc=CH%2FlYqJOEHecSkk0GEW4gA%3D%3D.jamDIJ2dj0Du5RTZWnIgFNxAN2MFWNLvBMfhkotveyovzvrVJf4mZieXKBF2myyLFGaFEbW%2Fork8br3h4YEIYA%3D%3D" rel="nofollow" target="_blank">opengauss.org</a><br/>华为在PG的基础上加入了列存储引擎和AI优化器，主要面向HTAP（混合事务/分析处理）场景。</li><li><strong>杭州易景数通 openHalo</strong><br/><a href="https://link.segmentfault.com/?enc=4ozLKJ2cxm20S4RMAfrtDw%3D%3D.B4edFqZMcBHgkC3f3lr%2BHPllR6107RnrI8zXfSCLazyn6ke1Jjq2lCKM2lYL5GCIfcEk4NwPvmZOdBxYDmA8lXAcn%2F1BLbCqZHQ9oYQlCg9j9CDSYuuFQlU55Ls6vk6E" rel="nofollow" target="_blank">github.com/HaloTech-Co…</a></li></ol><p>为什么这些架构师和厂商，在研发底层系统时，都不约而同地选择了PostgreSQL？今天我们就从实战和架构的角度来聊聊这背后的原因。</p><hr/><h3>1. 开源协议与自主可控</h3><p>这一点是国产数据库厂商最看重的。</p><p>MySQL虽然开源，但它的版权属于Oracle公司。MySQL采用的是GPL协议，而且存在商业版和社区版的区别。这意味着如果要基于MySQL修改内核并发布商业产品，会面临法律和商业上的限制。更重要的是，核心开发路线图是由Oracle控制的。</p><p>PostgreSQL则完全不同。它采用的是类BSD协议，这是一种非常宽松的协议。可以随意修改代码、重新分发，甚至闭源商业化，而不需要受制于任何一家商业公司。PostgreSQL的控制权在社区手里，由全球开发者共同维护。对于想要打造“自主知识产权”产品的国产厂商来说，PostgreSQL显然是更安全、更可控的基础。</p><h3>2. 数据库的可扩展性</h3><p>在使用MySQL时，我们通常只把它当作一个存储数据的仓库：存进去，取出来。如果需要额外的功能，比如分词、时序数据处理，通常会引入Elasticsearch或InfluxDB等其他组件。</p><p>但PostgreSQL的设计理念不同。它支持极其强大的插件机制（Extension），允许开发者深入内核去扩展功能，而不是仅仅停留在应用层。</p><p>看看这些常用的扩展，每一个都具备独立处理特定场景的能力：</p><ul><li><strong>TimescaleDB</strong>：直接把PG扩展为专业的时序数据库，支持自动分区、压缩。</li><li><strong>pg_trgm</strong>：在数据库内就能做高效的模糊匹配和相似度搜索。</li><li><strong>Citus</strong>：通过插件就能把单机PG扩展为分布式数据库。</li><li><strong>pg_stat_statements</strong>：详细的SQL执行统计，排查性能问题非常方便。</li></ul><p>在MySQL中，想要实现类似级别的扩展，难度要大得多。</p><h3>3. 数据处理能力的差异</h3><p>在实际开发复杂业务系统时，MySQL的一些设计细节常常会让开发者感到受限，而PostgreSQL则提供了更严谨的解决方案。</p><p><strong>关于序列（Sequence）</strong></p><p>在MySQL中，通常使用<code>AUTO_INCREMENT</code>。但如果需要一个全局唯一的ID生成器，或者需要在多个表之间共享同一个序列，MySQL就难以直接实现。可能需要专门建一张表来维护ID，或者依赖Redis。</p><p>PostgreSQL原生支持独立的序列对象，它不依赖于任何表：</p><pre><code class="sql">-- PostgreSQL 中创建独立序列 
CREATE SEQUENCE order_seq START WITH 1 INCREMENT BY 1;

-- 使用序列生成 ID，完全独立于表结构
INSERT INTO orders (id, name) VALUES (nextval('order_seq'), 'test');</code></pre><p>对比一下MySQL的处理方式，需要模拟实现：</p><pre><code class="ini">-- MySQL 必须绑定到某张表的 AUTO_INCREMENT 
ALTER TABLE orders AUTO_INCREMENT = 1000;

-- 或者用复杂的变量计算模拟 
SET @next_id = 3088413 + 1;</code></pre><p><strong>关于数据类型</strong></p><p>MySQL的数据类型比较基础。虽然现在也支持了JSON，但性能和灵活性上依然有限。</p><p>PostgreSQL在这方面支持得更全面：</p><ul><li><strong>数组类型（Array）</strong>：可以直接在一个字段里存一串标签，不需要关联表。</li><li><strong>JSONB</strong>：这是二进制格式的JSON，支持索引，查询速度非常快，很多时候甚至可以替代MongoDB。</li><li><strong>范围类型</strong>：比如时间段、价格区间，系统能自动处理区间的重叠判断。</li></ul><h3>4. 数据的可靠性与复制</h3><p>对于金融级或企业级的应用，数据的完整性至关重要。</p><p>MySQL的主从复制主要依赖binlog。虽然现在也有了GTID和半同步复制，但在默认配置下，它是异步的，且在高并发下可能会有延迟。如果主库突然宕机，从库是有可能丢失数据的。</p><p>PostgreSQL的流复制（Streaming Replication）是基于WAL（预写式日志）的物理复制。它不仅效率高，而且非常稳定。更关键的是，PG原生支持同步复制（Synchronous Replication），可以确保事务在提交前，数据至少已经写入了一个备库。这对于追求“零数据丢失”的国产数据库来说，是一个现成的、极其重要的特性。</p><hr/><h3>总结</h3><p>MySQL依然是Web开发的主流选择，它简单、普及率高、生态好。如果目标是快速搭建一个网站或APP后台，MySQL完全可以胜任。</p><p>但是，当站在“研发国产数据库”或者“构建复杂企业级系统”的角度时，PostgreSQL的严谨性、强大的扩展能力以及宽松的开源协议，就成了关键优势。这也是为什么在国产数据库领域，PostgreSQL被广泛采用的原因。</p><p><strong>简单来说：MySQL适合作为应用开发的存储后端，而PostgreSQL更适合作为数据库系统的研发基础。</strong></p>]]></description></item><item>    <title><![CDATA[如何利用工业超级智能体提升汽车供应链韧性？ 雨大王 ]]></title>    <link>https://segmentfault.com/a/1190000047551229</link>    <guid>https://segmentfault.com/a/1190000047551229</guid>    <pubDate>2026-01-19 16:05:56</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>汽车供应链作为制造业中最复杂的网络之一，正面临着前所未有的挑战。全球化的供应链布局、多级供应商体系、频繁的需求波动以及外部环境的不确定性，使得传统管理方式显得力不从心。近年来，随着人工智能技术的成熟，"工业超级智能体"逐渐成为解决这些痛点的关键工具。它不仅仅是技术的堆砌，更是一种全新的供应链管理范式，通过数据驱动和智能决策，实现供应链的全链路协同与自主优化。<br/>一、供应链的复杂挑战与智能体的必要性<br/>汽车供应链的复杂性远超一般人的想象。一辆汽车包含上万个零部件，涉及数百家直接供应商和数千家间接供应商，任何环节的延迟或异常都可能导致整个生产线的停滞。例如，2021年的芯片短缺就让全球汽车产量减少了超过1000万辆。与此同时，市场需求的个性化趋势日益明显，消费者对配置、颜色和功能的定制化需求使得排产计划变得极其复杂。再加上疫情、地缘政治等外部风险的频繁冲击，传统基于经验和局部优化的管理方法已经难以应对。<br/>工业超级智能体的价值正是在这种背景下凸显出来。它不同于传统的ERP或SCM系统，后者更多是流程的电子化记录工具，而智能体则具备主动感知、分析和决策的能力。通过接入物联网设备、ERP系统、物流平台等多源数据，智能体能够实时监控供应链状态，预测潜在风险，并自动生成应对方案。举个例子，当某个供应商的原材料质量出现波动时，智能体不仅能立即预警，还能通过历史数据和替代方案库，在几分钟内推荐最优的供应商切换策略，甚至自动触发订单调整流程。这种能力使得供应链从"被动响应"转向"主动防控"，大幅提升了整体韧性。<br/>二、智能体技术的核心架构与运作机制<br/>工业超级智能体的落地离不开一套成熟的技术架构。以Geega供应链智能体为例，其系统分为三层：数据感知层、智能决策层和执行协同层。数据感知层通过物联网设备和系统接口，实时采集供应商产能、物流状态、库存水平等300余类数据；智能决策层则融合了机器学习算法和行业知识图谱，能够进行需求预测、风险评级和方案模拟；执行协同层通过与ERP、WMS等系统的集成，将决策转化为实际操作指令。<br/>这套架构的独特之处在于其"感知-决策-执行"的闭环能力。例如，当预测到未来两周某车型需求将上升20%时，智能体会自动模拟三种供应方案：增加现有供应商订单、启用备用供应商或调整生产节奏。它会综合考虑成本、交货期和风险系数，选择最优方案并自动下发执行指令。整个过程无需人工干预，但却能保持95%以上的决策准确率。更值得一提的是，智能体具备持续学习能力。每次决策执行后，它会对比实际结果与预测结果，自动优化算法模型。这种自我迭代的机制使得系统越用越智能，逐步降低对人工经验的依赖。<br/>三、从理论到实践：行业案例深度解析<br/>广域铭岛在其打造的供应链智能体中，实现了对500余家核心供应商的实时监控。系统通过智能算法，将供应商的交货准时率从82%提升至96%，同时将库存周转天数减少了18天。<br/>特斯拉通过其自主研发的供应链智能体，实现了电池原材料采购的精准预测，将采购周期从60天压缩至35天<br/>某国外汽车集团则通过智能体系统，将全球工厂的设备备件库存降低了30%，同时保证了99.5%的供应及时率。这些案例共同证明，工业超级智能体正在重塑汽车供应链的运作模式，使其变得更加敏捷、高效和抗风险。</p>]]></description></item><item>    <title><![CDATA[现代 CSS 颜色使用指南进阶篇 冴羽 ]]></title>    <link>https://segmentfault.com/a/1190000047551267</link>    <guid>https://segmentfault.com/a/1190000047551267</guid>    <pubDate>2026-01-19 16:04:56</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在上篇文章，我们学会了现代 CSS 颜色的基础用法。</p><p>本篇我们进入更高级的领域：<strong>如何像设计师一样操纵颜色</strong>。</p><p>CSS 现在能做的事情，甚至比设计软件还要强大！</p><h2>1. 操纵颜色</h2><h3>1.1. 基础回顾</h3><p>先复习一下上篇文章的内容：</p><pre><code class="css">:root {
  --primary: #ff0000;
}

.primary-bg-50-opacity {
  /* h s l 不是字母，是变量！ */
  background: hsl(from var(--primary) h s l / 0.5);
}</code></pre><p><strong>注意：</strong> <code>h s l</code> 这三个字母其实是变量，分别存储了色相（hue）、饱和度（saturation）、亮度（lightness）的值。</p><p>我们可以替换这些变量，比如给绿色（#00ff00）加点蓝：</p><pre><code class="css">/* 基础绿色没有蓝色成分 */
.green-with-a-touch-of-blue {
  /* 在蓝色通道加 25 */
  color: rgb(from #00ff00 r g calc(b + 25));
}</code></pre><p>这就像调色板，在基础的绿色中，添加点“蓝色颜料”。</p><h3>1.2. 实用技巧</h3><p>掌握了基础用法，我们就可以讲些实际开发中会用到的场景了。</p><ol><li><strong>创建互补色（色轮对面的颜色）：</strong></li></ol><pre><code class="css">:root {
  --color-primary: #2563eb; /* 蓝色 */

  /* 色相加 180 度，跳到对面 */
  --color-secondary: hsl(from var(--color-primary) calc(h + 180) s l);
}</code></pre><ol start="2"><li><strong>创建三色组合：</strong></li></ol><pre><code class="css">:root {
  --color-primary: #2563eb;

  /* 色轮上均匀分布 120 度 */
  --color-secondary: hsl(from var(--color-primary) calc(h + 120) s l);
  --color-tertiary: hsl(from var(--color-primary) calc(h - 120) s l);
}</code></pre><p>就像时钟：12 点是主色，4 点和 8 点是配色，完美对称！</p><p><a href="https://link.segmentfault.com/?enc=Egp8khXhI1bLsuJQ%2BHHpnw%3D%3D.o%2FU6FjW6HkiyNUeQ3zrsFnCWwhVZEDY6E1tCK0%2FFB97mO54EcrG0zIAhgVQdjB8ul847PRSGPg7ch%2BhoJObv%2BOQaFk8LCvrqmfq5KqIRDd8%3D" rel="nofollow" target="_blank">使用效果如下：</a></p><p>&lt;!-- 这是一张图片，ocr 内容为：CHANGE THE PRIMARY COLOR: --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047551269" alt="" title=""/></p><ol start="3"><li><strong>相对调整</strong></li></ol><pre><code class="css">:root {
  --color-primary-base: #2563eb;

  /* 比基础色亮 25% */
  --color-primary-lighter: hsl(from var(--color-primary-base) h s calc(l + 25));

  /* 比基础色暗 25% */
  --color-primary-darker: hsl(from var(--color-primary-base) h s calc(l - 25));
}</code></pre><p>使用这种方法，不管基础色是多亮，都会相对地变亮或变暗。</p><p>这就像调空调，“比现在低 5 度”比“设定到 20 度”更灵活。</p><p><a href="https://codepen.io/kevinpowell/pen/vELwYoO" target="_blank">使用效果如下：</a></p><p>&lt;!-- 这是一张图片，ocr 内容为：CHANGE THE PRIMARY COLOR: --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047551270" alt="" title="" loading="lazy"/></p><h2>2. 暗黑模式的层次感</h2><p>现在我们能相对调整颜色了，可是究竟有什么用呢？</p><p>让我给你举个具体的使用场景。</p><p>在浅色主题中，我们可以根据阴影来区分层次：</p><p>&lt;!-- 这是一张图片，ocr 内容为：LEVEL 1 LEVEL 2 LEVEL 3 --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047551271" alt="" title="" loading="lazy"/></p><p>但在深色背景下，阴影的效果并不明显。</p><p>因此在深色主题中，我们希望每个层次的颜色略微变浅。</p><p>借助上篇讲过的 <code>light-dark()</code>和相对颜色调整，我们便可以实现：</p><pre><code class="css">:root {
  --surface-base-light: hsl(240 67% 97%);
  --surface-base-dark: hsl(252 21% 9%);
}

/* 第一层：基础层 */
.surface-1 {
  background: light-dark(var(--surface-base-light), var(--surface-base-dark));
}

/* 第二层：稍微亮一点 */
.surface-2 {
  background: light-dark(var(--surface-base-light), hsl(from var(--surface-base-dark) h s calc(l + 4)));
}

/* 第三层：再亮一点 */
.surface-3 {
  background: light-dark(var(--surface-base-light), hsl(from var(--surface-base-dark) h s calc(l + 8)));
}</code></pre><p>想象一下深海：越接近水面，光线越充足。暗色模式的层次就是这个原理。</p><p><a href="https://codepen.io/kevinpowell/pen/VYeOKQj" target="_blank">使用效果如下：</a></p><p>&lt;!-- 这是一张图片，ocr 内容为：LEVEL 1 LEVEL 1 LEVEL 2 LEVEL 2 LEVEL LEVEL 3 --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047551272" alt="" title="" loading="lazy"/></p><h2>3. 完整配色方案</h2><p>设计师创建配色方案时，不只是简单地调整亮度，还会<strong>同时微调色相和饱和度</strong>，比如</p><ul><li><strong>变亮时</strong>：饱和度增加，色相向冷色调偏移</li><li><strong>变暗时</strong>：饱和度降低</li></ul><p>这便可以通过 CSS 来实现：</p><pre><code class="css">:root {
  --primary-base: hsl(221 83% 50%);

  /* 400: 亮度60%，色相-3度，饱和度+5% */
  --primary-400: hsl(from var(--primary-base) calc(h - 3) calc(s + 5) 60%);

  /* 300: 亮度70%，色相-6度，饱和度+10% */
  --primary-300: hsl(from var(--primary-base) calc(h - 6) calc(s + 10) 70%);

  /* 以此类推... */
}</code></pre><p><strong>为什么要这么麻烦呢？</strong></p><p>因为只调亮度会让浅色看起来“失去活力”。</p><p>就像拍照：自动模式能拍，但手动调整曝光、对比度、色温会更漂亮。</p><p><a href="https://codepen.io/kevinpowell/pen/JoYaoGW/5407077415578757498bf930eb55f8d4" target="_blank">为了让你更直观地看到变化</a>：</p><p>&lt;!-- 这是一张图片，ocr 内容为：PRIMARY COLOR SCALE SYSTEMS PERCEPTUAL SCALE(ADJUSTS HUE &amp; SATURATION) 200 700 900 600 1000 100 400 800 500 300 FLAT SCALE(ONLY LIGHTNESS CHANGES) 600 500 400 300 100 700 1000 900 800 200 --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047551273" alt="" title="" loading="lazy"/></p><p>第一排是都调整的版本，第二排是未调整色相和饱和度的版本。</p><p>最明显的区别在于 100、200 和 300 这几个色块，当仅调整亮度值时，颜色看起来失去了一些鲜艳度。</p><h2>4. OKLCH 更科学的配色方式</h2><h3>4.1. 问题：HSL</h3><p>HSL 虽然很棒，但在使用时，你会发现一些问题，让我们看个例子：</p><pre><code class="css">.green-bg {
  /* 饱和度 100%，亮度 50% */
  background: hsl(100 100% 50%);
  color: white;
}

.blue-bg {
  /* 同样饱和度 100%，亮度 50% */
  background: hsl(220 100% 50%);
  color: white;
}</code></pre><p>你会发现，色和蓝色的饱和度、亮度虽然完全一样，但视觉效果完全不同：</p><p>&lt;!-- 这是一张图片，ocr 内容为：BLUE GREEN --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047551274" alt="" title="" loading="lazy"/></p><p>明显蓝色背景上的文字清晰易读，对比度超过 5，而绿色背景上的文字却很难看清，对比度仅略高于 1。</p><p>之所以会这样，是因为 HSL 的“亮度”不符合人眼感知。</p><p>人眼对绿色比蓝色更敏感，所以同样的“50%亮度”，绿色看起来更亮。</p><h3>4.2. 解决：OKLCH</h3><p>而这就是 oklch() 的优势。</p><p>OKLCH 是基于<strong>感知亮度</strong>设计的：</p><pre><code class="css">.consistent-green {
  background: oklch(0.54 0.23 261);
}

.consistent-blue {
  background: oklch(0.54 0.23 146);
}</code></pre><p>使用效果如下：</p><p>&lt;!-- 这是一张图片，ocr 内容为：BLUE GREEN --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047551275" alt="" title="" loading="lazy"/></p><p>现在不管什么颜色，亮度值相同，人眼看起来的亮度就相同！</p><h3>4.3. 讲解：OKLCH 的三个参数</h3><p>在 LCH 颜色模型中：</p><p>第一个值是亮度（Lightness），取值范围为 0 到 1。它的计算方式与 HSL 略有不同，因为它基于感知亮度，但概念相同，即 0 是黑色，1 是白色。</p><p>第二个值是色度（Chroma），类似于饱和度，0 是灰色，越大越鲜艳，但最大值不固定，取决于亮度和色相（这是 OKLCH 最麻烦的地方）</p><p>第三个值是色相（Hue），和 HSL 一样是色轮，0 到 360 度，区别是 0 度是洋红色（HSL 里 0 度是红色）</p><p>OKLCH 的尴尬之处就在于色度（Chroma）的最大值会变：</p><pre><code class="css">/* 某些色相+亮度组合，0.4 已经是极限 */
.max-chroma-1 {
  background: oklch(0.6 0.4 120);
}

/* 但另一些组合，0.4 可能太高或太低 */
.max-chroma-2 {
  background: oklch(0.8 0.4 200); /* 可能超出范围 */
}</code></pre><p>就像不同口味的饮料，有的最浓是“3 勺糖”，有的最浓是“5 勺糖”，没有统一标准。</p><h3>4.4. 实用技巧：结合相对颜色</h3><p>虽然直接写 OKLCH 值很麻烦，但我们可以用 HSL 定义基础色，然后用 OKLCH 保持一致性：</p><pre><code class="css">.toast {
  --base-color: hsl(225, 87%, 56%); /* 用熟悉的 HSL 定义 */
}

[data-toast="info"] {
  /* 只改变色相，保持亮度和色度 */
  --toast-color: oklch(from var(--base-color) l c 275);
}

[data-toast="warning"] {
  --toast-color: oklch(from var(--base-color) l c 80);
}

[data-toast="error"] {
  --toast-color: oklch(from var(--base-color) l c 35);
}</code></pre><p><a href="https://codepen.io/kevinpowell/pen/wBMbozY" target="_blank">使用效果如下：</a></p><p>&lt;!-- 这是一张图片，ocr 内容为：USING OKLCH SOME GENERAL INFO TOAST THIS MIGHT END BADLY OH NO, SOMETHING HAS GONE WRONG! USING HSL SOME GENERAL INFO TOAST THIS MIGHT END BADLY OH NO,SOMETHING HAS GONE WRONG! --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047551276" alt="" title="" loading="lazy"/></p><p>这样做的好处在于：不同颜色的提示框，边框对比度、整体饱和度感觉都很一致。</p><h2>5. 混合颜色</h2><p>有的时候，我们可能需要混合两种颜色：</p><pre><code class="css">.purple {
  /* 红色和蓝色各占 50% */
  color: color-mix(in srgb, red, blue);
}</code></pre><p>就像调颜料：红色颜料加蓝色颜料，得到紫色。</p><p>目前必须定义一个颜色空间，所以必须写 <code>in srgb</code> 或 <code>in oklab</code> 等，未来会默认用 <code>oklab</code>。</p><p>不同颜色空间混出来的结果不一样：</p><p>&lt;!-- 这是一张图片，ocr 内容为：SRGB OKLCH OKLAB XYZ XYZ --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047551277" alt="" title="" loading="lazy"/></p><p>一般推荐：</p><ol><li>先试 <code>oklab</code></li><li>再试 <code>oklch</code></li><li>不满意就换其他的</li></ol><h3>5.1. 控制混合比例</h3><p>默认情况下，使用该功能时 <code>color-mix()</code>，每种颜色将使用 50% 的强度。</p><p>当然，我们也可以控制特定颜色的具体强度。</p><pre><code class="css">/* 90% 红色 + 10% 蓝色 */
.red-with-a-touch-of-blue {
  background: color-mix(in oklab, red 90%, blue);
}

/* 或者反过来写 */
.or-like-this {
  background: color-mix(in oklab, red, blue 10%);
}</code></pre><h3>5.2. 创建半透明色</h3><p>有两种方法可以获得透明的值：</p><p><strong>方法一：让总量小于 100%</strong></p><pre><code class="css">/* 60% + 20% = 80%，所以透明度是 80% */
.semi-opaque {
  background: color-mix(in oklab, red 60%, blue 20%);
}</code></pre><p><strong>方法二：混入 transparent</strong></p><pre><code class="css">/* 30% 的不透明红色 */
.thirty-percent-opacity-red {
  background: color-mix(in oklch, red 30%, transparent);
}</code></pre><p>不过如果只是想降低透明度，还是用相对颜色更直接：</p><pre><code class="css">.better-way {
  background: rgb(from red r g b / 0.3);
}</code></pre><h3>5.3. 小技巧：分段渐变</h3><pre><code class="css">/* 不用手动算中间的每个颜色，color-mix 帮你搞定 */
.banded-gradient {
  background: linear-gradient(to right, red, color-mix(in oklch, red 75%, blue), color-mix(in oklch, red 50%, blue), color-mix(in oklch, red 25%, blue), blue);
}</code></pre><p><a href="https://codepen.io/kevinpowell/pen/VYeOvYE" target="_blank">使用效果如下：</a></p><p>&lt;!-- 这是一张图片，ocr 内容为： --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047551278" alt="" title="" loading="lazy"/></p><h2>6. 未来更简单</h2><p>重复写这些代码很烦？</p><p>CSS 自定义函数快来了：</p><pre><code class="css">/* 定义函数 */
@function --lower-opacity(--color, --opacity) {
  result: oklch(from var(--color) l c h / var(--opacity));
}

/* 使用函数 */
.lower-opacity-primary {
  background: --lower-opacity(var(--primary), 0.5);
}</code></pre><p>或者定义整套色阶函数：</p><pre><code class="css">@function --shade-100(--color) returns &lt;color&gt; {
  result: hsl(from var(--color) calc(h - 12) calc(s + 15) 95%);
}

@function --shade-200(--color) returns &lt;color&gt; {
  result: hsl(from var(--color) calc(h - 10) calc(s + 12) 85%);
}
/* 以此类推... */

.call-to-action {
  background: --shade-200(var(--accent));
}

.hero {
  background: --shade-800(var(--primary));
  color: --shade-100(var(--primary));
}</code></pre><p>一次定义，到处使用，完美！</p><h2>7. 总结</h2><p>最后总结下本篇文章的重点：</p><ol><li><strong>用 calc() 操纵颜色</strong> - 数学生成配色方案</li><li><strong>OKLCH</strong> - 基于人眼感知的颜色系统，不同色相亮度一致</li><li><strong>color-mix()</strong> - 像调颜料一样混合颜色</li></ol><p>在实际使用时：</p><ul><li><strong>简单需求</strong>：相对颜色 + HSL</li><li><strong>需要视觉一致性</strong>：OKLCH</li><li><strong>需要混合颜色</strong>：color-mix()</li><li><strong>暗黑模式层次</strong>：light-dark() + 相对颜色</li></ul><p>本篇整理自<a href="https://link.segmentfault.com/?enc=03G%2FtGLMJ2HMguMcBYWbQQ%3D%3D.L9oXZD032yCccNRvP9ghiyKjdgjntKmxEd61fpyCqcpPeBFq72YihT%2BAWz7yNimN%2BT28pCKDAiLoOSuRW%2Brk0jfBvyibTEzoqwUk0hbQ09k%3D" rel="nofollow" target="_blank">《A pragmatic guide to modern CSS colours - part two》</a>，希望能帮助到你。</p><p>我是冴羽，10 年笔耕不辍，专注前端领域，更新了 10+ 系列、300+ 篇原创技术文章，翻译过 Svelte、Solid.js、TypeScript 文档，著有小册《Next.js 开发指南》、《Svelte 开发指南》、《Astro 实战指南》。</p><p>欢迎围观我的“<a href="https://link.segmentfault.com/?enc=h9i9qGqWvR1ecWJ2zn3Gkg%3D%3D.8KYnXbEisST0fUkYOv9H3HzM%2BKltkzfdvX1MJYYAaao%3D" rel="nofollow" target="_blank">网页版朋友圈</a>”，关注我的公众号：<strong>冴羽（或搜索 yayujs）</strong>，每天分享前端知识、AI 干货。</p>]]></description></item><item>    <title><![CDATA[筑业软件工程协同功能：资料共享与协作的便捷桥梁 聪明的拐杖 ]]></title>    <link>https://segmentfault.com/a/1190000047551289</link>    <guid>https://segmentfault.com/a/1190000047551289</guid>    <pubDate>2026-01-19 16:04:05</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在工程项目的复杂运作中，高效的工程协同对于确保各方顺畅合作、项目顺利推进至关重要。筑业软件的工程协同功能，以其独特的资料共享模式，为项目团队搭建了便捷的协作桥梁。<br/>云端资料便捷分享<br/>筑业软件赋予资料员强大的资料分享能力。资料员可将存储于云端丰富的工程资料，通过简单操作，依据接收方的账号或手机号进行分享。例如，在项目施工过程中，资料员整理好最新的施工进度资料，只需在软件界面选择分享功能，输入相关人员的手机号或账号，即可快速完成分享，确保资料及时传递给需要的团队成员。<br/>即时查看与编辑<br/>接收方一旦收到分享通知，登录云资料软件，就能立即查看与编辑接收到的工程资料。这种即时性极大地提升了工作效率，避免因等待资料传递或格式转换等问题造成的时间浪费。比如，项目技术负责人收到资料员分享的工程变更资料后，可即刻登录软件查看详细内容，并根据实际情况进行编辑批注，提出专业意见，为后续施工决策提供支持。<br/>保障协作流畅性<br/>该功能确保了项目团队成员之间资料的实时同步与更新，使得各方始终基于最新信息开展工作。无论是在施工现场的一线人员，还是位于办公室的管理层，都能通过云资料软件获取一致的资料，有效避免因信息不一致导致的误解和错误。例如，在多部门协作完成一项复杂工程任务时，各部门成员可随时查看和编辑共享资料，实时沟通协作，确保任务顺利推进，各个环节紧密衔接。<br/>筑业软件的工程协同功能，通过云端资料分享、即时查看编辑、保障协作流畅以及灵活权限设置等特性，为工程项目各方提供了高效、便捷且安全的协作环境，有力推动项目的顺利实施与成功交付。</p>]]></description></item><item>    <title><![CDATA[等保三级 + 国密认证双门槛下，谁是电子合同安全第一梯队？ 俊秀的小摩托_bWeu86 ]]></title>    <link>https://segmentfault.com/a/1190000047551296</link>    <guid>https://segmentfault.com/a/1190000047551296</guid>    <pubDate>2026-01-19 16:03:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>随着数字化发展的深入，合同作为一个重要的应用基础，也是第一时间进行数字化的转型，电子合同逐步替代了传统纸质合同。但是电子合同的厂商市场上却有很多，那这些厂商生成的电子合同是不是都是安全有保障的呢？今天我们便简单剖析一下各个厂商。</p><p>首先，我们要先明确一点的便是，国内并没有一个官方、绝对的“安全性排名”，因为不同厂商的安全架构、合规侧重和客户群体有所不同。但是，我们可以通过一套核心的安全评估框架，对国内主流的电子合同厂商进行对比分析，帮助判断哪家更符合您的安全要求。</p><ol><li>核心安全评估框架</li></ol><p>1) 合规性与认证（基础门槛）</p><p>Ø 等保三级：国内非银行机构最高备案认证，必备项。</p><p>Ø 商用密码产品认证：使用国密算法对数据进行加密的合规证明，必备项。</p><p>Ø ISO系列：27001（信息安全管理）、27701（隐私保护）、22301（业务连续性）等，国际通用标准。</p><p>Ø 行业特定合规：如公安行业的电子签章标准、医疗行业的HIPAA/GDPR（如涉及出海业务）等。</p><p>2) 技术安全性</p><p>Ø 加密技术：是否全链路采用SSL/TLS、数据存储加密、关键信息是否使用硬件加密机（HSM） 进行私钥保护。国密算法支持是重要加分项。</p><p>Ø 数据隔离与主权：是否为大型客户提供数据隔离部署（公有云、混合云、私有云），数据能否明确存储在国内。</p><p>Ø 安全运维与审计：是否有完善的内部安全管控、渗透测试、灾备体系。</p><p>3) 司法实践与证据效力</p><p>Ø 是否与公证处直连，形成在线争议解决闭环。</p><p>Ø 是否有大量的法院判例支持，其证据链是否被司法机构普遍采信。</p><p>Ø 是否提供从合同起草、签署到存证、出证的一站式服务。</p><ol start="2"><li>主流厂商安全性特点分析（按综合安全能力排序参考）</li></ol><p>基于以上框架，以下是国内市场主流厂商的特点分析：</p><p>第一梯队：综合安全能力最强，服务大型企业及政府机构</p><ol><li>北京安证通信息科技股份有限公司</li></ol><p>优势：</p><p>Ø 历史积淀与技术创新：拥有二十年电子签名领域经验，技术架构历经多次迭代，形成高稳定性、高扩展性的产品体系。</p><p>Ø ·大型企业服务经验：服务超过300家央企、国企及中国500强企业，包括中石油、中建五局等，积累大量复杂业务场景解决方案。</p><p>Ø ·全栈安全能力：从身份认证、电子签名到合同存证，构建多层次安全防护体系，通过等保三级认证，符合金融、政务等高安全要求场景。</p><p>Ø ·定制化服务能力：针对大型企业复杂业务流程，提供从咨询、实施到运维的全流程定制化服务，确保系统深度贴合业务需求。</p><p>安全侧重点：</p><p>在政府、集团企业、住建行业、工程建设行业等领域安全口碑突出，尤其注重行业合规与隐私保护等。</p><ol start="2"><li>法大大</li></ol><p>优势：</p><p>市场覆盖极广，生态集成度高。合规资质齐全（等保三级、密评、ISO系列等）。与腾讯云深度合作，背靠其安全能力。司法衔接广泛，已对接多家法院和仲裁委。</p><p>安全侧重点：</p><p>在各类行业均有大量标杆案例，安全体系经过海量业务验证，平衡了安全性与产品易用性。</p><ol start="3"><li>e签宝</li></ol><p>优势：</p><p>行业头部厂商，阿里系投资，在政务和大企业市场占有率很高。拥有全链条的电子签名服务，从CA机构到签署平台。在政务领域的合规经验非常丰富。</p><p>安全侧重点：</p><p>特别符合国内政务和大型国企的安全与合规要求，对国内标准理解深刻。</p><p>第二梯队：在特定领域或场景有安全优势</p><ol><li>腾讯电子签</li></ol><p>优势：</p><p>背靠腾讯的安全能力和C端生态（微信），在个人与小B场景的便捷性和安全结合得很好。内生于腾讯云的安全体系，合规资质齐全。</p><p>安全侧重点：</p><p>依托腾讯整体安全防护，在防攻击、数据安全方面有天然优势。适合已使用腾讯生态的企业。</p><ol start="2"><li>字节跳动电子签（飞书合同）</li></ol><p>优势：</p><p>深度集成于飞书，主打内部管理和供应链协同场景。享有字节跳动的安全技术底座，在用户体验和内部风控流程结合上做得较好。</p><p>安全侧重点：</p><p>更适合飞书生态内的企业，实现办公、签约、数据的一体化安全管理。</p><ol start="3"><li>契约锁</li></ol><p>优势：</p><p>专注于电子印章的统一管理，常与OA、ERP系统集成，提供一体化印控方案。支持混合部署，满足集团型客户对物理印章和电子印章的统一管控需求。</p><p>安全侧重点：</p><p>印控安全和一体化管理，适合对内部用印流程风控要求极高的中大型组织。</p>]]></description></item><item>    <title><![CDATA[如何通过工业智造超级智能体实现汽车制造工厂数字化转型 雨大王 ]]></title>    <link>https://segmentfault.com/a/1190000047551329</link>    <guid>https://segmentfault.com/a/1190000047551329</guid>    <pubDate>2026-01-19 16:02:32</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>技术架构的核心突破<br/>工业智造超级智能体正在彻底改变汽车制造业的数字化转型路径。与传统的自动化系统不同，这种智能体采用了一种全新的架构设计——它不仅仅是简单的机器替代人力，而是构建了一个能够自主感知、分析和决策的智能生态系统。这个系统的核心在于将物联网、人工智能和大数据技术深度融合，形成一个能够自我学习和持续优化的智能网络。<br/>在汽车制造领域，这种技术架构表现得尤为突出。以Geega平台为例，其架构设计专门针对汽车制造的特殊需求，包含了三个关键层次：实时数据感知层、智能决策层和自主执行层。数据感知层通过部署数以万计的传感器，实时采集生产线、设备状态、物料流动等全方位数据；智能决策层则运用机器学习算法对这些数据进行分析，生成最优的生产调度方案；自主执行层则将决策转化为具体的生产指令，实现从冲压、焊装、涂装到总装的全流程智能化控制。<br/>这种架构设计使得汽车制造企业能够实现从被动响应到主动预测的根本转变。比如在焊装车间，系统能够实时监测焊接机器人的工作状态，预测可能出现的设备故障，提前安排维护计划，避免生产线停摆。这种预见性维护能力，正是传统制造系统所欠缺的。<br/>实施过程中的关键考量<br/>汽车制造工厂的数字化转型绝非易事，它需要一个系统性的实施路径。首先面临的挑战是数据基础的构建。汽车制造涉及上百个工序、数千个零部件，数据采集的复杂程度远超一般制造业。<br/>接下来是算法模型的训练和优化阶段。这个阶段往往需要3-6个月的时间，期间需要工程师与产线人员密切配合，不断调整和优化模型参数。值得注意的是，每个汽车工厂的生产线布局、设备型号都有差异，这就需要智能体系统具备很强的自适应能力。某新能源汽车工厂在实施过程中就遇到了这样的问题——原有的质量检测算法在新产线上准确率只有85%，经过两个月的持续迭代才提升到99%以上。<br/>最后是实现全价值链协同的阶段。智能体不仅要优化单个车间的生产效率，更要实现跨车间、跨工厂的协同运作。例如，当总装车间出现生产延误时，系统能够自动调整焊装和涂装车间的生产节奏，同时协调供应商调整零部件配送计划。这种全链路的协同能力，正是数字化转型带来的最大价值。<br/>实践案例与成效分析<br/>在具体实践方面，广域铭岛为某知名汽车集团打造的数字化转型方案取得了显著成效。该企业通过部署生产优化智能体，实现了焊装生产线效率提升38%，质量缺陷率降低65%。更令人印象深刻的是，系统能够实时预测设备故障，提前12-24小时发出预警，使非计划停机时间减少了85%。这些改进直接带来了每年数亿元的成本节约。<br/>另一个典型案例来自某新能源汽车电池工厂。通过引入质量检测智能体，将电池检测准确率提升至99.8%，同时检测效率提高了6倍。这套系统不仅能够识别表面缺陷，还能通过分析生产过程中的数百个参数数据，预测潜在的质量风险。在实际运行中，系统成功预警了多次批量性质量事故，避免了数千万元的损失。<br/>吉利汽车集团的数字化转型案例同样值得关注。通过构建智能供应链系统，实现了从订单到交付的全流程数字化管理。客户下单后，系统能够自动生成生产方案，实时调度生产线资源，将定制车型的交付周期从4周缩短到2周。这种柔性制造能力使得企业能够快速响应市场需求变化，在激烈的市场竞争中占据优势。<br/>这些案例表明，工业智造超级智能体正在成为汽车制造业数字化转型的关键驱动力。它不仅提升了生产效率和产品质量，更重要的是改变了汽车制造企业的运营模式和价值创造方式。随着技术的不断成熟，预计未来三年内，采用智能体技术的汽车制造企业将获得25-35%的综合效益提升，这将成为决定企业竞争力的重要因素。</p>]]></description></item><item>    <title><![CDATA[Zoho在迪拜、阿布扎比投建双数据中心，出海中东再提速！ Zoho ]]></title>    <link>https://segmentfault.com/a/1190000047551350</link>    <guid>https://segmentfault.com/a/1190000047551350</guid>    <pubDate>2026-01-19 16:01:58</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>1月13日，Zoho宣布在<strong>迪拜、阿布扎比</strong>投建的两座<strong>数据中心正式投入运营</strong>。这是继2024年沙特利雅得、吉达数据中心落地后，Zoho在中东的又一重要基建动作。至此，<strong>Zoho在中东地区自建的数据中心已达四座，将用来全面提升对当地客户的服务响应效率与数据安全保障能力</strong>。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047551352" alt="图片" title="图片"/></p><p>两座数据中心目前已获得迪拜电子安全中心 (DESC)颁发的CSP安全标准认证，并且符合 ISO 27001、ISO 22301、ISO 27017和CSA STAR二级数据中心认证标准。这意味着，<strong>Zoho有资格为当地政府、机构、企业及出海中东的海外企业</strong>提供安全可靠的数字化服务。</p><p>Zoho联合创始人沙伊莱什•戴维说到：「阿联酋是Zoho在中东的核心战略市场，目前<strong>已投资8000万迪拉姆(约合人民币1.52亿)</strong>，两座数据中心的启用是我们持续投资中东市场战略的重要一步，<strong>更好地帮助企业实现本地数据存储，增强数据主权</strong>，并支持国家网络安全议程。」</p><p>过去五年，Zoho在中东市场的发展势头持续攀升，成功从早期的市场探索者蜕变为<strong>中东企业数字化转型的关键伙伴</strong>。仅在<strong>2025年，Zoho在阿联酋的业务就增长了38.7%，合作伙伴网络扩大了29%，本地员工人数增加了35%，助力7000多家企业</strong>实现数字化转型升级。</p>]]></description></item><item>    <title><![CDATA[25年的关键词：失业、工伤、外包、投资回血…… 悲伤的煎鸡蛋_cQXuXF ]]></title>    <link>https://segmentfault.com/a/1190000047551357</link>    <guid>https://segmentfault.com/a/1190000047551357</guid>    <pubDate>2026-01-19 16:01:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h3>引言</h3><p>「2025」 年就这么稀里糊涂的过去咯, 前不久正巧听到播客不禁感慨, 于世界而言「2025」这一年属实精彩:</p><pre><code>年初的 Deepseek、宇树机器人爆火
特朗普上台后各种折腾, 关税战一度引起全球股市暴跌, 而最后又好像啥也没发生一样
后面泡泡马特爆火、小红书出圈...
之后又有雷军塌房、西贝塌房、俞敏洪塌房...
再之后又是美团、京东、淘宝三方外卖大战...
最后高德闭关整了个用脚投票, 最后好像也没声了
然后就是各大厂商的 AI 争夺战了
...

</code></pre><p>然而这一切又和我有啥关系, 各种风口并没有让我踩到, AI 的出现也只会让我更难找到合适的工作, 2025 我依然过得平庸, 比起 2024 也没啥起色....</p><p>而 2026, 我的生活大概率还是不会有起色? 谁知道呢? 随便吧....</p><p>一、无业游民这半年</p><p>从去年九月份被裁后就一直在 GAP, 属实没想到这一 GAP 就 GAP 了近一年....</p><p>不幸的 2024 又是失业又是车祸, 所以年初一直在处理工伤的事; 从劳动能力鉴定、出劳动能力鉴定结果、提交工伤赔偿申请到最后 💰 到账。折腾了三四个月, 跑了好几次社保局, 捡钱好像也没那么容易</p><p>当然最后结果是好的, 小赚了一笔。 钱到账前还计划着出去奢侈一把, 到账后还是不舍得花钱, 还是老老实实存着吧....</p><p>上半年除了折腾工伤这事, 其余时间就是准备面试咯, 这期间还尝试写日记、做 TODO...</p><p>然鹅并没有什么用, 回头过了下上半年写的内容, 每天写的最多的就是:</p><pre><code>去健身房
煮饭
没有面试机会
焦虑
今天又啥都没干
....

</code></pre><p>是的失业这半年基本上也没干啥, 有面试机会就面试, 没有就宅家里和 “自律” 抗争...</p><p>最后自然也不会有出乎意料的结果, 破罐子破摔罢了。最后入职了一家外包公司, 主要是看给的薪资也还行就去了</p><h3>二、 外包这半年</h3><p>人生第一次外包工作, 好像也没想象🤔中那么差</p><p>有免费的零食吃、无限自助咖啡, 偶尔一天干它个三杯 😂)。过节也有各种礼盒、去了半年 T 恤、衣服、帽子、鼠标垫都不知道领了多少个了, 同时外包公司过节偶尔也有礼盒, 这过一次节领双份礼盒了都 👍</p><p>对了, 还有免费的早中晚餐。刚开始去还自己带饭, 后面杭州这边可以集体点餐了, 自此三餐就全包咯。晚餐不吃, 就带回去给对象, 第二天她带去公司当午饭吃, 一家人全靠公司养活了</p><p>唯一不好的就是得加班, 每天得 8.30 下班, 这样就更不想去健身了。下班到家都 9 点了, 如果去健身那么到家都得 10 点多了。不对, 还有就是没有年假, 这坑爹的外包公司必须入职满一年才给年假....</p><p>没有绩效压力, 纯牛马好像过得也挺爽的, 运气好的是还有机会接触到 Agent 相关的工作(虽然只是边缘的对接工作)</p><p><strong> 机-会</strong></p><p>技术大厂，前端-后端-测试，全国均有<a href="https://link.segmentfault.com/?enc=OU0gbAih4a12%2BXie%2FlMpzQ%3D%3D.mBItPcVlcobwLOc2jJnA1zRftpQExShihoZyYe4SsYM%3D" rel="nofollow" target="_blank">机-会</a>，感兴趣可以试试。待遇和稳定性都还不错~</p><h3>二、好好生活</h3><p>2.1 见家长</p><p>人生进程 +1: 51 去了对象老家, 10 月份趁着周末带对象也回了趟我的老家, 一切都还挺顺利的。实际上好像也没想象中那么紧张, 在对象老家这一待就待了 5 天, 每天就是吃吃喝喝...</p><p>2.2 旅游</p><p>上半年一直忙着工伤和工作的事, 下半年也一直在上班, 所以这一年也没去几个地方。</p><p>五月份大学舍长结婚, 就和对象一起去了趟福建, 之后就顺便就绕道去厦门玩了几天。厦门不错, 就是物价忒贵了, 如果去鼓浪屿千万自带吃食, 要不然就等着被宰吧。住的酒店就挺不错的, 服务周到、还有个大天台...</p><p>之后就是十月份, 去了心心念念的重庆。不愧是山城啊, 有被惊到, 刚去就按错电梯了 🐶。和美食荒漠的杭州相比, 那重庆简直是美食天堂了吧。可惜了, 上了年纪了真真感觉没以前能吃了, 一吃多肚子就难受得很....</p><p>再之后又去了趟桐庐, 当然主要目的是对象在支付宝上白嫖了医美项目(只有那边能预约到), 顺带着就想着溜达溜达。景点就去了「石舍村」, 主要是淡季很多景点都闭园修整了, 在富春江溜达了两天就溜了, 江边一路风景倒是挺不错的。</p><p><strong>2.3 健康</strong></p><p>是不是人一到 30 往后, 身体毛病就开始多起来了。 上半年差点不能入职了, 主要就是体检「心电图」有点异常, 吓坏了都。后面第二天又跑医院重新做了一次, 还是有一点点「异常」又补了其他检查, 最后没发现问题, 让医生开了个证明, 才顺利入职。</p><p>可能是那几天生活作息不良引起的「心电图」波动, 但是那时才感觉真的老咯, 以前可不这样。并且还检查出血压偏高, 当然我血压偏高这事其实早就知道, 只是一直不重视而已。这次检查医生说我的一个心房好像偏大, 问是不是血压高, 我说是的, 然后就建议我吃药、减肥...</p><p>好咯, 谨遵医嘱。 现在就是每天食用降压药, 还给自己安排上了血压仪。</p><p>后面就开始尝试减肥了, 到目前为止已瘦 20 斤吧。大部分都是前面几个月减下来的, 主要最开始上班都是自己带饭, 做的也干净(基本水煮), 所以瘦得还挺快的。</p><p>后面公司有免费的早中晚餐, 就放弃自己带饭咯。 慢慢的就反弹了点, 人啊一破防就容易破罐子破摔, 现在也不关注体重了, 现在估计又反弹不少....</p><p><strong>2.4 理财</strong></p><p>今年大家都回本了吧 🐶。 毕竟今年大 A 表现这么好, 再不回本也太说不过去了。</p><p>今年我也可算回本了, 感谢大 A 🙇。往年我的理财账户是另一个支付宝, 只为了眼不见为净毕竟亏了那么多。今年做了个改变:</p><pre><code>将所有基金都转托管到常用的那个支付宝上
追求稳健、分散, 并卖掉亏损大的
大仓位放在债劵、固收、红利上
还配置了点纳指
最后只有一小部分放在科技上

</code></pre><p>这种做法是稳, 但注定不能赚太多。在今年行情这么好的情况下, 今年收益也就 8.25% 远远跑输大盘。慢慢来吧, 起码今年的收益可以把我一年的房租给 cover 掉, 还是挺满意的。</p><p>今年半场还进了股市, 折腾了大半年, 小赚 400 大洋 😆。小资金, 玩得不亦说乎....</p><p>今年黄金、白银也有点给力。黄金入场了, 可惜中场没拿住卖了, 后面又进场, 少赚了(虽然也没买多少)。后面白银出现套利的机会, 没整明白就瞎炒作, 导致耽误了好几天, 少套利了不少。我对象场外买了不少, 也因此错过了最高点(就差那么一天), 可惜了...</p><p><strong>2.5 其他</strong></p><p>七月份大热天搬了个家, 在这小区已经换了三个窝了, 第一个主要是楼上太吵了, 第二个就是有点贵外加顶楼夏天实在是热得不行。</p><p>这一个也不知道能坚持多久呢, 主要问题就是二房东总是要房东催好几次才肯给他房租, 房东都找上我了让我催二房东给钱, 还说明年不租给他了 😭</p><p>双十二对象整了个烘干机, 那是真后悔没早点整, 简直太香了。特别是对我这种租房党, 晚上洗个衣服, 白天出门上班前把衣服丢烘干机就完事咯。主要还能收集灰尘和毛絮, 烘出来的衣服看起来就和新买的一样。强力推荐, 免去晒衣服的烦扰, 而且这样常年也只需要买 2~3 套衣服就行 🐶</p><p>两个崽: 妹妹越吃越胖、就像头猪; 姐姐倒是自律得很, 这一年身材管理起码比我好太多了, 没胖没瘦一切如旧。年初二狗子还了场病, 一直流鼻涕(怀疑是鼻炎), 被整的够呛的。还担心今年冬天会不会复发, 现在看着应该不会了吧, 对了这家伙年初应该还被俺们给噶了。</p><p>一年 365 天, 说长不长说短不短</p><p>翻翻手机里的照片总会有些收获的...</p><h3>三、工作与成长</h3><p><strong>3.1 工作</strong></p><p>新的工作, 工作难度一般吧, 反正轻松驾驭! 就是整体会更难? 或者说是更乱, 工期赶加上一群外包一起开发的项目, 虽然说有正式员工在把控, 但是项目质量也很难起来。正式员工也只是参与初期的项目开发, 后面的维护基本也就不管了, 毕竟只有新项目、新玩意才能出绩效。</p><p>但总的来说还是有点新东西可以学到, 毕竟不同的团队他们的开发习惯、开发范式都是不同的。总是能看到一些新玩意, 即便有些玩意个人也不太喜欢, 但是也是可以玩一玩的。</p><p>后面也有幸参与了 vscode 插件相关工作, 这里也涉及到 Agent, 虽然只是一些简单的对接工作, 但是我可以接触到 Agent 代码呀。明年一大目标就是好好研究研究大佬们写的代码, 应该是会有所收获的吧。</p><p>这大半年工作唯一的感受就是, 太多工作都没啥意义, 都是用一群人内卷换来一小撮人的自嗨罢了。但是又能咋样, 牛马嘛给钱就干。先把钱赚到了再说。</p><p><strong>3.2 读书 &amp; 播客</strong></p><p>今年相比去年阅读量少了些, 当然去年其实也没读多少书。书嘛, 都是随便瞎看的, 看过了 26 本书, 但真正看完的也就 10 本。本着先培养习惯的目的, 所以很多书看几眼不感兴趣也就不会强迫自己去读。也不会抱着太强的目的去看书, 也不要求一定会有啥收获。</p><p>今年还入坑了博客, 平常做家务、坐地铁、撸铁、上班... 无聊时就会听听博客。大部分都是财经类的、科技类的, 再则就是几个脱口秀平台。</p><p>3.3 开源? 独立作品</p><p>今年 小绿点还行, 出乎意料的多....<br/><img width="723" height="179" referrerpolicy="no-referrer" src="/img/bVdnGrm" alt="" title=""/></p><p>今年主要新开了两个坑, 当然也都没有填上:</p><pre><code>智账: 一个记账的 APP, 为此还去研究了下 React Native 还输出了5篇播客， 整了个专栏, 实际上连项目都还没搭建起来, 就研究了下 React Native
writeflow: 基于 prosemirror 写的一个富文本编辑器吧, 整体架构主要参考  Tiptap全当是学习了。之所以要写这么一个东西一为折腾, 二是昆仑虚中文章编辑器用的是代码编辑器, 不是很方便想要换成富文本编辑器。

</code></pre><p>其他的, 昆仑虚今年应该也做了些调整, 没做记录也不知道改了啥, 也懒得查了, 就这样吧....</p><p><strong>3.4 写文 &amp; 视频</strong></p><p>今天拢共就写了 11 篇文章, 主要还是发布在掘金、公众号上, 掘金上整体数据也就一般般吧。大部分都是上半年失业时闲得无聊写的, 下半年基本就荒废了, 毕竟当牛马的日子那么累, 谁还写文章啊 </p><p>今年公众号粉丝从 830 到 1394 涨了 500 多吧, 主要也都是上半年涨的, 下半年也都没怎么更新了。</p><p>对了, 油管、B站还发了一期视频, 配套文章 还原 Mac Dock 栏动效: 一步步打造流畅的波形缩放动画<br/><img width="723" height="183" referrerpolicy="no-referrer" src="/img/bVdnGrn" alt="" title="" loading="lazy"/></p><p>内容创作收入: 掘金金石 300+、公众号累计收入 47</p><h3>四、展望 2026</h3><p>照例, 定定 2026 目标, 至于能不能实现另说....</p><pre><code>
好好生活


    身材管理(减肥、撸铁): 撸铁每周四次(下雨可以不去)、体重维持在 80~82 (目前 2025.12.31 体重 90)
    吃喝玩乐: 好好吃饭(不吃饱)、养生(少喝饮料)、多出去逛逛(去次新疆或韩国)
    财务理财: 保护钱袋子、稳定理财(别浪)
    人生体验: 整个人生第一辆小车(10w 左右)、人生大事安排起来、学习打网球



工作与成长

    保住饭碗: 简历常更新(6月、12月)、保持学习
    通过软考: 为了 E 类人才、为了买车
    AI 学习: 把公司 Agent 那一套研究明白、侧重应用端、AI Coding 技巧掌握
    算法学习
    多输出: 写文(每月 2 篇)、公众号(每月 2 篇)、视频(每月 1 个)
    独立作品: 昆仑虚(增加两个 APP、开放注册)、智帐(完成开发)



习惯养成:


    坚持写日记、做月度总结、季度总结
    阅读: 每天 30 分钟, 微信读书打卡
    早起(给自己找个活干)

</code></pre><p>——转载自：墨渊君</p>]]></description></item>  </channel></rss>