<?xml version="1.0" encoding="UTF-8"?><rss version="2.0">  <channel>      <title>SegmentFault - 最近文章</title>      <link>https://segmentfault.com/blogs/newest</link>      <description>SegmentFault 思否</description>      <generator>python segmentfault.py @Pi20</generator>      <item>    <title><![CDATA[借助gh-ost，对MySQL大表进行表结构的变更 好文收藏 ]]></title>    <link>https://segmentfault.com/a/1190000047557175</link>    <guid>https://segmentfault.com/a/1190000047557175</guid>    <pubDate>2026-01-21 23:02:28</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>关于 gh-ost</h2><p>gh-ost 是 GitHub 开发的一个 MySQL 在线表结构变更工具(online schema migration tool)。它的全称是 "GitHub's Online Schema Translator"。</p><p>gh-ost 现在已经是大型互联网公司进行数据库运维的重要工具。</p><h3>主要作用</h3><p>gh-ost 允许在不锁表、不影响业务的情况下,对 MySQL 数据库表进行结构变更(如添加列、修改索引等)。</p><h3>核心特点</h3><ol><li><strong>无触发器设计</strong> - 不像传统工具使用触发器来同步数据,gh-ost 通过解析 binlog 来捕获变更</li><li><strong>可暂停/恢复</strong> - 可以随时暂停迁移过程,对生产环境更友好</li><li><strong>可测试</strong> - 支持在从库上测试变更,确认无误后再应用到主库</li><li><strong>动态调整</strong> - 可以实时调整迁移速度,避免影响线上服务</li></ol><h3>工作原理</h3><ol><li>创建一个与原表结构相同的"影子表"(ghost table)</li><li>在影子表上执行 DDL 变更</li><li>通过 binlog 将原表的增量数据同步到影子表</li><li>数据同步完成后,快速切换表名完成迁移</li></ol><h3>使用方法</h3><ol><li><strong>安装</strong>：<br/><code>gh-ost</code> 可以直接从最新的 <a href="https://link.segmentfault.com/?enc=5VXGnl1U8LdIBYisXgjt0w%3D%3D.o6qphFAYMZXnetdAWZxikfb6nMBHsNq%2FUGPl8eSRod%2B9kg9u3jX2jZo83q1sRX7%2F" rel="nofollow" title="发布页面" target="_blank">发布页面</a> 下载二进制文件，支持 Linux 和 macOS。</li><li><p><strong>基本命令</strong>：</p><ul><li><p><strong>测试迁移</strong>：</p><pre><code class="bash">gh-ost --test-on-replica --database=mydb --table=mytable --alter="ADD COLUMN new_col INT" --execute</code></pre></li><li><p><strong>真实迁移</strong>：</p><pre><code class="bash">gh-ost --database=mydb --table=mytable --alter="ADD COLUMN new_col INT" --execute</code></pre></li></ul></li></ol><h3>实际例子</h3><p>假设你有一个用户表需要添加新字段:</p><pre><code class="bash">gh-ost \
  --host=localhost \
  --user=root \
  --password=password \
  --database=mydb \
  --table=users \
  --alter="ADD COLUMN age INT DEFAULT 0" \
  --execute</code></pre><p><strong>场景说明</strong>:</p><ul><li>原表 <code>users</code> 有 1000 万条数据</li><li>使用传统 <code>ALTER TABLE</code> 可能需要锁表数小时</li><li>使用 gh-ost 可以在后台逐步完成变更,期间用户可以正常读写数据</li><li>最后只需要几秒钟的短暂切换时间即可完成迁移</li></ul><h3>适用场景</h3><ul><li>大表的结构变更(百万级以上数据)</li><li>需要保证高可用性的生产环境</li><li>需要精确控制数据库负载的情况</li></ul><h3>数据库支持范围</h3><p><strong>gh-ost 目前只适用于 MySQL</strong>(包括 Percona Server 和 MariaDB)。它依赖 MySQL 的 binlog 机制,因此不支持 PostgreSQL、Oracle 等其他数据库。</p><h3>常见的坑</h3><h4>1. <strong>外键约束问题</strong></h4><p>gh-ost <strong>不支持有外键的表</strong>。如果表有外键关系,迁移会失败。</p><pre><code>解决办法: 需要先删除外键,迁移完成后再重新添加</code></pre><h4>2. <strong>binlog 格式要求</strong></h4><p>必须使用 <strong>ROW 格式</strong>的 binlog,STATEMENT 或 MIXED 格式不支持。</p><pre><code class="sql">-- 检查 binlog 格式
SHOW VARIABLES LIKE 'binlog_format';

-- 如果不是 ROW,需要修改配置
SET GLOBAL binlog_format = 'ROW';</code></pre><h4>3. <strong>主键要求</strong></h4><p>表<strong>必须有主键</strong>或唯一索引,否则 gh-ost 无法正常工作。</p><h4>4. <strong>磁盘空间</strong></h4><p>会创建影子表,需要<strong>额外的磁盘空间</strong>(大约是原表的大小)。如果磁盘空间不足,迁移会失败。</p><h4>5. <strong>复制延迟</strong></h4><p>如果主从复制本身就有延迟,gh-ost 的迁移会进一步加重延迟。需要监控 <code>--max-lag-millis</code> 参数。</p><h4>6. <strong>触发器冲突</strong></h4><p>虽然 gh-ost 本身不用触发器,但如果原表上<strong>已有触发器</strong>,可能会导致数据不一致。</p><h4>7. <strong>字符集问题</strong></h4><p>影子表的字符集需要与原表一致,否则可能出现乱码或数据截断。</p><h4>8. <strong>长时间迁移中断</strong></h4><p>如果迁移过程很长(几天),期间 MySQL 重启或 binlog 被清理,会导致迁移失败需要重新开始。</p><h3>实践建议</h3><pre><code class="bash"># 先在从库测试
gh-ost \
  --host=slave-host \
  --test-on-replica \
  --migrate-on-replica \
  --database=mydb \
  --table=users \
  --alter="ADD COLUMN age INT" \
  --execute

# 设置合理的限流参数
gh-ost \
  --max-load=Threads_running=25 \
  --critical-load=Threads_running=100 \
  --chunk-size=1000 \
  --throttle-query="SELECT HOUR(NOW()) BETWEEN 2 AND 6" \
  --execute</code></pre><h3>替代方案</h3><p>如果 gh-ost 不适用,可以考虑:</p><ul><li><strong>pt-online-schema-change</strong> (Percona Toolkit)</li><li><strong>原生 Online DDL</strong> (MySQL 5.6+ 支持部分操作)</li><li>对于其他数据库,PostgreSQL 可以用 pg_repack</li></ul>]]></description></item><item>    <title><![CDATA[鸿蒙系统 IO 性能优化实战：从应用卡顿到 OTA 升级的完整解决方案 前端视界 ]]></title>    <link>https://segmentfault.com/a/1190000047557180</link>    <guid>https://segmentfault.com/a/1190000047557180</guid>    <pubDate>2026-01-21 23:01:58</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047554512" alt="在这里插入图片描述" title="在这里插入图片描述"/></p><h2>摘要</h2><p>在鸿蒙（HarmonyOS / OpenHarmony）应用和系统开发中，IO 操作几乎无处不在，比如文件读写、配置加载、日志输出、数据库访问以及 OTA 升级等。很多性能问题表面上看是应用卡顿、启动慢、耗电高，实际上根源都指向 IO 使用不当。本文结合当前鸿蒙系统的实际开发现状，从应用层和系统层两个角度，系统梳理 IO 性能优化的常见思路，并通过可运行的 Demo 代码，讲清楚这些优化在真实项目中该怎么落地。</p><p>文章整体偏向实战，语言尽量贴近日常开发交流，适合正在做鸿蒙应用、系统服务或设备升级相关开发的同学参考。</p><h2>引言</h2><p>随着鸿蒙生态逐渐完善，应用形态从早期的简单页面，发展到现在的多端协同、分布式能力、设备级应用，IO 压力明显变大。一方面，应用启动阶段要加载更多配置和资源；另一方面，系统服务、后台任务、设备升级都会产生大量读写操作。</p><p>在实际项目中，经常能看到下面这些情况：</p><ul><li>页面一打开就卡，结果发现主线程在读文件</li><li>日志一多，设备开始明显发热</li><li>OTA 升级时间很长，写盘阶段占了一大半</li><li>分布式数据一同步，前台体验明显下降</li></ul><p>这些问题并不是鸿蒙系统本身性能不行，而是 IO 的使用方式不够合理。下面我们就从最常见、也最容易优化的地方开始讲。</p><h2>鸿蒙 IO 性能瓶颈从哪来</h2><p>在多数项目中，IO 性能问题通常集中在下面几个点：</p><ul><li>频繁进行小文件读写</li><li>同步 IO 放在主线程执行</li><li>每次用文件都重新 open 和 close</li><li>没有任何缓存策略</li><li>用文件存 KV 数据</li><li>日志输出不受控制</li></ul><p>只要命中其中一两条，性能基本都会出问题。</p><h2>应用层 IO 优化（最常用）</h2><h3>IO 一定不要放在主线程</h3><p>这是最基础，也是最容易踩坑的一点。ArkTS 中如果直接使用同步文件接口，UI 线程就会被直接卡住。</p><h4>错误示例</h4><pre><code class="ts">import fs from '@ohos.file.fs';

let text = fs.readTextSync('/data/storage/test.txt');</code></pre><p>这种写法在数据量稍微大一点时，页面就会出现明显卡顿。</p><h4>推荐写法（异步 IO Demo）</h4><pre><code class="ts">import fs from '@ohos.file.fs';

export async function readFileAsync(path: string): Promise&lt;string&gt; {
  let file = await fs.open(path, fs.OpenMode.READ_ONLY);
  let buffer = new ArrayBuffer(4096);
  let result = '';

  let readLen = await fs.read(file.fd, buffer);
  if (readLen &gt; 0) {
    result = String.fromCharCode(...new Uint8Array(buffer, 0, readLen));
  }

  await fs.close(file);
  return result;
}</code></pre><h4>代码说明</h4><ul><li>使用 async/await，把 IO 操作放到异步任务中</li><li>读取完成后再返回结果，不阻塞 UI</li><li>真实项目中可以配合 taskpool 使用</li></ul><h3>合并小 IO，减少系统调用</h3><p>很多性能问题不是数据量大，而是 IO 次数太多。</p><h4>不推荐的写法</h4><pre><code class="ts">for (let i = 0; i &lt; list.length; i++) {
  fs.writeSync(fd, list[i]);
}</code></pre><h4>推荐写法</h4><pre><code class="ts">let content = list.join('');
fs.writeSync(fd, content);</code></pre><h4>实际效果</h4><ul><li>系统调用次数明显减少</li><li>写盘效率更高</li><li>对 Flash 存储更友好</li></ul><h3>引入内存缓存，避免重复读文件</h3><p>配置文件、初始化数据非常适合放进内存缓存。</p><pre><code class="ts">let configCache: string | null = null;

export async function getConfig(path: string): Promise&lt;string&gt; {
  if (configCache !== null) {
    return configCache;
  }
  configCache = await readFileAsync(path);
  return configCache;
}</code></pre><h4>使用场景</h4><ul><li>应用启动配置</li><li>JSON 静态数据</li><li>权限或状态信息</li></ul><h3>能用 Preferences 就别用文件</h3><p>对于少量 KV 数据，文件 IO 的性价比非常低。</p><h4>Preferences Demo</h4><pre><code class="ts">import preferences from '@ohos.data.preferences';

export async function saveUserInfo(context, userId: string) {
  let pref = await preferences.getPreferences(context, 'user_config');
  await pref.put('userId', userId);
  await pref.flush();
}</code></pre><h4>优点</h4><ul><li>内部自带缓存</li><li>自动批量落盘</li><li>使用简单，性能稳定</li></ul><h2>系统层 IO 优化（Native / 服务侧）</h2><h3>使用缓冲 IO</h3><p>在系统服务或 Native 模块中，直接写裸 IO 往往效率不高。</p><pre><code class="cpp">#include &lt;stdio.h&gt;

void writeFile(const char* path, const char* data, size_t len) {
    FILE* fp = fopen(path, "w");
    if (!fp) return;

    setvbuf(fp, nullptr, _IOFBF, 8 * 1024);
    fwrite(data, 1, len, fp);
    fclose(fp);
}</code></pre><h4>说明</h4><ul><li>设置 8KB 缓冲区</li><li>减少实际写盘次数</li><li>适合大量顺序写场景</li></ul><h3>顺序 IO 优于随机 IO</h3><pre><code class="cpp">off_t offset = 0;
pread(fd, buffer, size, offset);
offset += size;</code></pre><p>尽量避免频繁 seek 和交叉读写多个文件。</p><h3>控制日志 IO</h3><p>日志在调试阶段很有用，但在正式环境中是 IO 隐形杀手。</p><pre><code class="ts">if (__DEV__) {
  console.info('debug log');
}</code></pre><p>建议：</p><ul><li>发布版本关闭 debug 和 info</li><li>避免循环内打印日志</li><li>合并日志输出</li></ul><h2>典型应用场景分析</h2><h3>场景一：应用启动阶段加载配置</h3><h4>问题</h4><p>启动慢，页面白屏时间长。</p><h4>解决方案</h4><ul><li>异步读取配置</li><li>内存缓存</li></ul><pre><code class="ts">await getConfig('/data/storage/app_config.json');</code></pre><h3>场景二：OTA 升级文件写入</h3><h4>问题</h4><p>升级包大，写盘耗时长。</p><h4>优化思路</h4><ul><li>分块下载</li><li>分块写入</li><li>写完再统一校验</li></ul><pre><code class="ts">async function writeChunk(fd: number, data: Uint8Array) {
  await fs.write(fd, data.buffer);
}</code></pre><h3>场景三：日志过多导致设备发热</h3><h4>问题</h4><p>设备运行一段时间后发热、掉帧。</p><h4>解决方案</h4><ul><li>控制日志级别</li><li>关闭非必要日志</li></ul><h2>常见问题 QA</h2><p><strong>Q：异步 IO 一定比同步快吗？</strong><br/>A：不一定，但一定不会卡 UI。</p><p><strong>Q：缓存会不会导致数据不一致？</strong><br/>A：需要设计好更新策略，配置类数据问题不大。</p><p><strong>Q：文件和 RDB 怎么选？</strong><br/>A：结构化数据选 RDB，大文件选文件。</p><h2>总结</h2><p>IO 性能优化并不复杂，关键在于使用方式是否合理。大多数性能问题，并不是因为设备性能不足，而是 IO 用得太随意。</p><p>简单总结几句话：</p><ul><li>IO 不要放主线程</li><li>少做小 IO，多做批量 IO</li><li>能缓存就缓存</li><li>能不用文件就不用文件</li><li>日志一定要克制</li></ul><p>这些原则在应用层、系统层、OTA 场景中都是通用的。如果你正在做鸿蒙系统相关开发，把 IO 优化当成基本功，会少踩很多坑。</p>]]></description></item><item>    <title><![CDATA[鸿蒙系统中地区特定内容实现实战：从资源适配到业务控制 前端视界 ]]></title>    <link>https://segmentfault.com/a/1190000047557182</link>    <guid>https://segmentfault.com/a/1190000047557182</guid>    <pubDate>2026-01-21 23:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047557184" alt="在这里插入图片描述" title="在这里插入图片描述"/></p><h2>摘要（背景与现状）</h2><p>随着鸿蒙系统在手机、平板、穿戴设备以及 IoT 场景中的逐步落地，同一套应用需要面向<strong>不同国家、不同地区、不同语言和政策环境</strong>已经成为常态。<br/>在实际项目中，我们经常会遇到这些问题：</p><ul><li>不同地区展示的文案不一样</li><li>某些功能在特定地区不能上线</li><li>活动内容、公告、支付方式存在地区差异</li></ul><p>如果地区适配逻辑处理得不好，就很容易出现<strong>代码混乱、维护成本高、后期改动困难</strong>的问题。</p><p>本文结合鸿蒙系统（HarmonyOS / OpenHarmony）的实际开发方式，从<strong>系统能力、资源机制和业务逻辑</strong>三个层面，总结一套<strong>可落地、好维护</strong>的地区特定内容实现方案。</p><h2>引言（发展情况与应用场景）</h2><p>从早期 Android / iOS 开发经验来看，地区适配往往依赖大量 <code>if-else</code> 判断，代码里到处是国家缩写，后期维护非常痛苦。<br/>鸿蒙在设计之初，就在<strong>国际化与地区适配</strong>方面做了比较完整的能力封装，比如：</p><ul><li>系统级语言和地区识别</li><li>资源文件按地区自动匹配</li><li>ArkUI 对多语言、多地区资源的天然支持</li></ul><p>在真实项目中，大多数地区定制需求并不复杂，核心思路其实只有一句话：</p><p><strong>先交给系统做资源适配，实在不行再写判断逻辑。</strong></p><p>下面我们一步一步来看具体实现方式。</p><h2>鸿蒙地区特定内容的整体实现思路</h2><p>在鸿蒙系统中，地区定制通常可以拆分为三个层次：</p><ol><li>系统层：获取当前设备的语言和地区信息</li><li>资源层：根据地区自动加载不同资源</li><li>业务层：在运行时根据地区控制功能和内容</li></ol><p>这三层并不是互斥的，而是经常组合使用。</p><h2>通过系统语言和地区识别用户环境</h2><h3>获取系统地区信息</h3><p>鸿蒙提供了 i18n 模块用于国际化相关能力，获取系统地区非常简单。</p><pre><code class="ts">import i18n from '@ohos.i18n';

const locale: string = i18n.getSystemLocale();
console.info(`当前系统地区为: ${locale}`);</code></pre><p>常见返回值包括：</p><ul><li>zh-CN：中国大陆</li><li>zh-HK：香港地区</li><li>en-US：美国</li><li>ja-JP：日本</li></ul><p>这个值通常在应用启动时获取一次即可。</p><h3>基于地区进行基础内容控制</h3><pre><code class="ts">let isChinaRegion: boolean = false;

if (locale.startsWith('zh-CN')) {
  isChinaRegion = true;
}</code></pre><p>在 ArkUI 页面中直接使用：</p><pre><code class="ts">if (isChinaRegion) {
  Text('中国地区专属内容')
    .fontSize(16)
}</code></pre><p>这种方式比较直观，适合少量差异控制，但不建议大量使用在文案层面。</p><h2>通过资源文件实现地区内容自动适配</h2><h3>资源目录结构设计</h3><p>这是鸿蒙中<strong>最推荐、维护成本最低</strong>的方式。</p><pre><code class="text">resources/
 ├─ base/
 │   └─ element/
 │       └─ string.json
 ├─ zh_CN/
 │   └─ element/
 │       └─ string.json
 ├─ en_US/
 │   └─ element/
 │       └─ string.json</code></pre><h3>不同地区资源内容示例</h3><p>base 目录作为兜底资源：</p><pre><code class="json">{
  "welcome_text": "Welcome"
}</code></pre><p>中国地区资源：</p><pre><code class="json">{
  "welcome_text": "欢迎使用（中国地区）"
}</code></pre><p>美国地区资源：</p><pre><code class="json">{
  "welcome_text": "Welcome (US Version)"
}</code></pre><h3>ArkUI 中直接使用资源</h3><pre><code class="ts">Text($r('app.string.welcome_text'))
  .fontSize(18)</code></pre><p>系统会根据当前设备地区自动匹配资源，不需要任何额外判断。</p><p>如果没有对应地区资源，就自动回退到 base。</p><h2>结合运行时逻辑实现地区功能差异</h2><p>在真实项目中，地区差异不仅体现在文案上，功能层面的限制更常见。</p><h3>地区功能开关示例</h3><pre><code class="ts">let enablePayment: boolean = true;

if (!locale.startsWith('zh-CN')) {
  enablePayment = false;
}</code></pre><p>ArkUI 中控制按钮展示：</p><pre><code class="ts">if (enablePayment) {
  Button('立即支付')
    .width(200)
}</code></pre><h3>代码逻辑说明</h3><ul><li>地区判断逻辑集中在一个地方</li><li>UI 只关心布尔状态，不直接判断地区</li><li>后期调整地区规则只改一处代码</li></ul><p>这种写法在中大型项目中特别重要。</p><h2>结合实际业务场景的应用示例</h2><h3>场景一：地区公告与活动内容展示</h3><p>不同地区活动内容变化频繁，适合服务端下发。</p><pre><code class="ts">let requestParam = {
  locale: locale
};</code></pre><p>服务器返回内容：</p><pre><code class="json">{
  "notice": "日本地区限定活动"
}</code></pre><p>客户端展示：</p><pre><code class="ts">Text(serverData.notice)</code></pre><p>这种方式运营改内容不需要重新发版。</p><h3>场景二：支付方式地区限制</h3><pre><code class="ts">function isPaymentSupported(locale: string): boolean {
  return locale.startsWith('zh-CN');
}</code></pre><pre><code class="ts">if (isPaymentSupported(locale)) {
  Button('使用本地支付')
}</code></pre><p>清晰区分业务规则和 UI。</p><h3>场景三：隐私协议与合规文案差异</h3><p>通过资源文件区分不同地区隐私条款：</p><pre><code class="ts">Text($r('app.string.privacy_policy'))</code></pre><p>不同地区加载不同内容，避免代码层面处理复杂文本。</p><h2>常见问题 QA</h2><h3>Q1：可以只用代码判断不做资源适配吗？</h3><p>可以，但不推荐。<br/>代码判断适合控制功能，不适合承载大量文案。</p><h3>Q2：地区和语言一定是一一对应的吗？</h3><p>不一定。<br/>比如香港地区可能使用中文或英文，建议优先按语言，再结合地区判断。</p><h3>Q3：地区变化时需要重启应用吗？</h3><p>一般不需要，重新加载页面即可。<br/>资源匹配通常在页面创建时生效。</p><h2>总结</h2><p>在鸿蒙系统中实现地区特定内容，其实并不复杂，关键在于<strong>合理分层</strong>：</p><ul><li>文案和静态内容优先使用资源适配</li><li>功能和业务规则使用少量逻辑判断</li><li>活动和运营内容交给服务端</li></ul><p>一句话概括就是：</p><p><strong>资源适配解决大部分问题，代码只处理真正的差异逻辑。</strong></p>]]></description></item><item>    <title><![CDATA[如何系统性打造高浏览量视频号内容 blossom ]]></title>    <link>https://segmentfault.com/a/1190000047557133</link>    <guid>https://segmentfault.com/a/1190000047557133</guid>    <pubDate>2026-01-21 22:03:00</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>从「抄作业」到 AI 自动生成视频的完整方法论</h2><p>很多创作者在做视频号时都会遇到同一个问题：<br/><strong>为什么看起来很努力，却始终没有稳定的高播放？</strong></p><p>原因往往不在执行力，而在起点就错了——<br/><strong>从“原创灵感”开始，而不是从“成功案例”开始。</strong></p><p>事实证明，当前阶段最容易跑通的方式不是凭空创作，而是：</p><blockquote><strong>先抄作业，再用 AI 把成功经验规模化复制。</strong></blockquote><p>下面是一套已经被反复验证、且非常适合短视频平台的完整方法。</p><hr/><h2>一、核心思路：不是抄内容，而是抄「爆款结构」</h2><p>这里的“抄作业”并不是搬运视频，而是<strong>反向工程爆款</strong>：</p><ul><li>不关心某条视频讲了什么</li><li>只关心它<strong>为什么能火</strong></li><li>把“感觉”拆成可复用的结构</li></ul><p>整个流程可以拆成四个关键词：</p><blockquote><strong>采样 → 归纳 → 再创作 → 自动生成</strong></blockquote><hr/><h2>二、为什么这个方法能跑通？</h2><h3>1️⃣ 爆款不是偶然，而是可重复的结构结果</h3><p>绝大多数高播放视频，并不是随机出现的，而是满足了以下条件：</p><ul><li>前几秒有强烈视觉或行为异常</li><li>中段存在明确冲突或失控</li><li>结尾有情绪释放或反转</li><li>风格高度统一，利于算法识别</li></ul><p>单个视频看不出规律，但<strong>同一 channel 的 Top 视频几乎一定有共性</strong>。</p><hr/><h3>2️⃣ 从 YouTube 入手，是最稳妥的起点</h3><p>YouTube 的优势在于：</p><ul><li>样本量大</li><li>数据透明</li><li>爆款生命周期长</li></ul><p>选择一个已经跑通的 YouTube channel，本质是在复用：</p><ul><li>已验证的受众偏好</li><li>已适配的平台算法</li><li>已成熟的内容节奏</li></ul><hr/><h3>3️⃣ NotebookLM 的价值：把隐性经验变成显性规则</h3><p>NotebookLM 的核心作用并不是“写文案”，而是：</p><blockquote><strong>从多个成功样本中，提炼共性模式。</strong></blockquote><p>例如：</p><ul><li>开头平均在第几秒出现刺激点</li><li>冲突是否围绕“规则 / 强迫 / 对抗”</li><li>情绪是逐步升级还是瞬间爆发</li><li>是否存在固定角色关系（支配 / 反抗）</li></ul><p>这一步完成后，爆款不再是“感觉”，而是<strong>结构模板</strong>。</p><hr/><h3>4️⃣ 文本转视频，是 AI 当前最成熟的短视频应用场景</h3><p>当前 AI 在短视频领域的优势集中在：</p><ul><li>夸张动作</li><li>强对比画面</li><li>明确情绪</li><li>简单故事线</li></ul><p>当“创意结构”已经由 NotebookLM 给出，<br/>AI 更适合承担的是<strong>从创意到画面的执行过程</strong>。</p><hr/><h2>三、完整可执行流程（SOP）</h2><h3>Step 1：查找 YouTube 火爆 Channel</h3><p>筛选标准：</p><ul><li>同一类型内容</li><li>至少 3–5 条百万播放</li><li>风格高度统一</li></ul><hr/><h3>Step 2：选取 Top 10 爆款视频</h3><p>重点关注：</p><ul><li>播放量</li><li>明显被算法推荐的迹象</li><li>评论区情绪密度</li></ul><hr/><h3>Step 3：将视频链接输入 NotebookLM 分析</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047557135" alt="" title=""/></p><p>分析重点放在结构层面：</p><ul><li>前 3 秒发生了什么</li><li>冲突第一次出现的时间点</li><li>情绪如何被放大</li><li>是否存在“规则被打破”的瞬间</li></ul><p>最终得到的是一个<strong>可复用的爆款结构模型</strong>。</p><hr/><h3>Step 4：让 NotebookLM 生成“类似结构”的新创意</h3><p>在结构不变的前提下，替换：</p><ul><li>场景</li><li>道具</li><li>主题设定</li></ul><p>NotebookLM 在这一阶段输出的，是<strong>已经符合爆款结构的新视频创意</strong>。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047557136" alt="" title="" loading="lazy"/></p><hr/><h2>四、演示案例：厨房灾难——机器“闹鬼”事件</h2><p><strong>根据前述步骤，选择一个由 NotebookLM 生成的视频创意，用于展示从创意到视频生成的全过程。</strong></p><h3>创意名称</h3><p><strong>厨房灾难：机器“闹鬼”事件（The Haunted Mixer Prank）</strong></p><h3>创意概念</h3><p>在制作节日甜点的过程中，人为制造厨房设备故障，形成短暂混乱，再用反转完成喜剧闭环。</p><h3>核心情节点</h3><ul><li>设备失控</li><li>人物恐慌</li><li>荒诞解释</li><li>快速反转恢复秩序</li></ul><hr/><h2>五、让 AI 根据该创意生成文本转视频 Prompt</h2><p>在演示中，并不直接人工编写提示词，而是：</p><blockquote><strong>将该创意输入给视频生成模型或多模态 AI，要求其根据创意自动生成文本转视频 Prompt。</strong></blockquote><p>并对 AI 提出明确约束：</p><ul><li>视频总时长：20 秒</li><li>镜头数量：4 个</li><li>每个镜头 1 个核心事件</li><li>强调视觉、动作和情绪变化</li></ul><h3>🎬 AI 生成的 Text-to-Video Prompt（20 秒）</h3><pre><code>A 20-second comedic kitchen prank video.

Scene 1 (0–4s):
Bright home kitchen.
A cheerful female character is happily making holiday desserts.
She overloads a stand mixer with too many ingredients.
The mixer begins shaking violently.

Scene 2 (4–9s):
The mixer malfunctions.
Smoke rises dramatically.
Ingredients splatter everywhere.
The character panics, shouting:
“Unplug it! Unplug it now!”

Scene 3 (9–14s):
The mixer stops.
Close-up of the burnt mixer head.
She stares at it and asks nervously:
“Did I summon a ghost?”

Scene 4 (14–20s):
Comedic reversal.
She pulls out a brand-new mixer.
Smiles calmly and continues cooking as if nothing happened.
Bright, cheerful ending.

Style:
Fast-paced, exaggerated comedy.
Strong facial expressions.
Short-form video style.
No subtitles, no text overlays, no watermarks.</code></pre><p>然后选一个文本转视频的模型将提示词输入。</p><hr/><h2>六、为什么这个演示案例具有代表性？</h2><ul><li>创意来源于结构分析，而非灵感碰运气</li><li>Prompt 由 AI 基于创意自动生成</li><li>冲突、节奏、反转完整可复用</li><li>非常适合短视频平台算法偏好</li></ul><p>这说明：<br/><strong>当结构正确时，AI 的执行能力已经足够支撑内容生产。</strong></p><hr/><h2>七、结语：内容创作正在进入「工程化时代」</h2><p>当内容生产开始遵循：</p><ul><li>用数据筛选方向</li><li>用模型总结结构</li><li>用 AI 生成与执行</li><li>用批量测试验证结果</li></ul><p>创作就不再是玄学，而是一套<strong>可以被复用和放大的系统</strong>。</p><p>在这个体系中，“抄作业”不是捷径，而是<strong>最低成本、最高成功率的起点</strong>。<br/>当结构被掌握，所谓的“原创”，自然会不断出现。</p><p>本文由<a href="https://link.segmentfault.com/?enc=WP7hk88PHk5X5oUEOVKYRw%3D%3D.yBTGhtIVVrIqlacOzJwfmCFCfeXvXHqLeEi4k37Ivdc%3D" rel="nofollow" target="_blank">mdnice</a>多平台发布</p>]]></description></item><item>    <title><![CDATA[Andrej Karpathy：过去一年大模型的六个关键转折 卡尔AI工坊 ]]></title>    <link>https://segmentfault.com/a/1190000047557148</link>    <guid>https://segmentfault.com/a/1190000047557148</guid>    <pubDate>2026-01-21 22:02:14</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><strong>Andrej Karpathy：过去一年大模型的六个关键转折</strong></p><p><img width="554" height="554" referrerpolicy="no-referrer" src="/img/bVdnHWN" alt="" title=""/></p><p>本文共 2836 字，阅读预计需要 4 分钟。</p><p>一边是模型光靠"多想一会儿"就能解出奥数题，另一边是刷爆排行榜的选手被用户吐槽"中看不中用"。</p><p>2025年的AI圈，弥漫着一股诡异的气息：</p><p><strong>参数规模不再是唯一的军备竞赛指标，但模型能力却在某些维度上狂飙突进。</strong></p><p>这到底发生了什么？</p><p>Andrej Karpathy——前OpenAI研究总监、曾掌舵特斯拉AI团队的技术大牛——在年终复盘中抛出了一个判断：</p><p><strong>2025年LLM的真正突破，不在于模型变大，而在于我们"驯养"它的方式、理解它的视角、以及使用它的姿势，都发生了根本性的变化。</strong></p><p>这篇文章，我会带你拆解Karpathy眼中的六个范式转变，聊聊它们对普通人意味着什么，以及有哪些坑是你现在就该绕开的。</p><p><img width="723" height="408" referrerpolicy="no-referrer" src="/img/bVdnHWO" alt="" title="" loading="lazy"/></p><p><strong>一、RLVR：训练范式的静默换代</strong></p><p>2024年之前，大模型训练三板斧：预训练、监督微调、RLHF。但RLHF的瓶颈很明显——<strong>依赖人工标注，成本高、速度慢</strong>。</p><p>2025年，RLVR（基于可验证奖励的强化学习）开始上位。核心逻辑很简单：<strong>用有标准答案的任务来训练</strong>。数学题对不对？代码能不能跑？机器自己就能验证。</p><p>打个比方：RLHF像请老师批改作文，标准不一；RLVR像做数学卷子，对就是对、错就是错。</p><p><img width="723" height="408" referrerpolicy="no-referrer" src="/img/bVdnHWP" alt="" title="" loading="lazy"/></p><p>RLVR还解锁了一个调节旋钮：<strong>让模型"多想一会儿"</strong></p><p>生成更长的推理链，就能换来更强能力。OpenAI的o1到o3，DeepSeek的R1，都是这条路线的产物。</p><p>以前比谁模型参数多，现在比谁的强化学习跑得久。</p><p><strong>二、召唤幽灵，而非驯养动物</strong></p><p>Karpathy用了一个隐喻：<strong>我们不是在"培育动物"，而是在"召唤幽灵"</strong>。</p><p>动物智能是进化塑造的，能力配合天衣无缝。</p><p>但LLM的"大脑"是为了预测下一个词、在数学题里拿分——<strong>这些目标和生存没关系</strong>。</p><p>结果就是"锯齿状智能"：<strong>某些任务碾压专家，另一些任务犯低级错误。</strong></p><p>它能写出逻辑严密的报告，但是转头就被越狱提示词骗了。</p><p><img width="723" height="408" referrerpolicy="no-referrer" src="/img/bVdnHWQ" alt="" title="" loading="lazy"/></p><p>实际后果是：<strong>别迷信基准测试。</strong> LLM团队为了刷榜，围绕测试题大量生成训练数据，榜单漂亮，实际用起来翻车。</p><p>幽灵的能力是尖刺的、不可预测的。用的时候，得时刻警惕。</p><p><strong>三、Cursor与新应用层：上下文工程的价值爆发</strong></p><p><img width="723" height="408" referrerpolicy="no-referrer" src="/img/bVdnHWR" alt="" title="" loading="lazy"/></p><p>2025年，Cursor没有自己训练模型，但估值从4亿飙到99亿美元。它做对了什么？</p><p>答案是<strong>上下文工程</strong>——在调用大模型时，精心设计给它的信息环境：提示词怎么写、代码库怎么索引、多次调用怎么编排。</p><p>Karpathy的观点是：<strong>LLM实验室培养"通才大学生"，应用层把他们培养成"垂直专家"</strong>。桥梁就是上下文工程。</p><p>直接问ChatGPT和用Cursor写代码，体验天差地别。Cursor自动索引代码仓库，理解文件依赖，提问时自动塞入相关上下文。这不是模型能力差距，是<strong>信息组织方式的差距</strong>。</p><p>启示很清晰：<strong>模型会迭代，但上下文工程能力可以沉淀，能无缝迁移到下一代模型。</strong></p><p>这也是我一直以来坚持上下文工程优先的原因。</p><p><strong>四、Claude Code：AI从"网站"变成"室友"</strong></p><p><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdnHWS" alt="" title="" loading="lazy"/></p><p>Claude Code是Anthropic推出的命令行工具，特别之处在于：<strong>直接运行在本地电脑上</strong>，访问你的文件、配置、密钥。后续Copilot等工具也相继推出了这样的开发模式。</p><p>Karpathy说：<strong>它不再是需要打开浏览器的网站，而是"寄居"在电脑里的小精灵</strong>。</p><p>本地运行的好处：AI直接读取电脑上的上下文——装了哪些软件、项目代码长什么样，不需要手动复制粘贴。</p><p>更重要的是<strong>延迟和隐私</strong>——云端来回几百毫秒，敏感数据发到第三方合规部门不同意。</p><p>当然也有隐患：一个能操作本地文件的AI，权限边界怎么划定？</p><p><strong>五、Vibe Coding：代码正在变得廉价</strong></p><p>Karpathy造了个词叫"Vibe Coding"——氛围编程。</p><p><strong>用自然语言描述需求，AI帮你写代码，你甚至不需要"懂"代码</strong>。</p><p>2025年这事跨过了临界点。之前AI写代码问题多，需要人debug。现在很多简单项目，从想法到可运行程序，一气呵成。</p><p><img width="723" height="408" referrerpolicy="no-referrer" src="/img/bVdnHWT" alt="" title="" loading="lazy"/></p><p>Karpathy自己用它写了Rust版tokenizer（不需要学Rust）、做了好几个小应用原型、甚至写过临时应用定位bug——用完就扔。</p><p>他的原话是：<strong>代码变得廉价、短暂、可塑、用完即弃。</strong></p><p>对普通人意味着什么？"我有想法但不会代码"这个门槛，正在消失。</p><p><strong>六、Nano Banana：LLM的GUI时代前奏</strong></p><p>Google的Gemini Nano Banana让Karpathy特别兴奋。</p><p>核心不是图像生成能力，而是<strong>文本、图像与世界知识在模型权重中的深度融合</strong>。</p><p>现在"跟LLM对话"像1980年代敲命令。文本是机器原生语言，但人更喜欢视觉化呈现——这正是GUI被发明的原因。</p><p><strong>LLM也需要自己的GUI</strong>——用图片、信息图、动画跟我们沟通。Nano Banana就是这个方向的早期预演。</p><p><img width="723" height="408" referrerpolicy="no-referrer" src="/img/bVdnHWU" alt="" title="" loading="lazy"/></p><p><strong>写在最后：可立即落地的三个建议</strong></p><p>拉回来说说，这六个范式转变对你意味着什么。</p><p><strong>如果你是创业者</strong>，最重要的启示是：模型能力会继续涨，但涨的方式变了。与其追着模型跑，不如在上下文工程上建立壁垒。Cursor的成功已经证明了这条路。</p><p><strong>如果你是开发者</strong>，Vibe Coding值得你认真对待。不是说它会取代你，而是说它能让你的生产力翻倍。把重复性的代码工作交给AI，把精力放在架构设计和业务逻辑上。</p><p><strong>如果你是普通用户</strong>，最重要的是调整预期。AI既不是全能的神，也不是彻底的废物——它是一个能力极度不均匀的"幽灵"。用好它的尖刺能力，同时对它的盲区保持警惕。</p><p>三个行动建议，作为结束：</p><p><strong>投资上下文工程能力</strong>。学会设计提示词、组织RAG检索、编排多步调用，这是当下性价比最高的AI技能。</p><p><strong>用Vibe Coding降低创意落地门槛</strong>。你脑子里的想法，别再等"等我学会编程再说"，现在就可以试着让AI帮你实现。</p><p><strong>理解锯齿状智能，设置人工校验</strong>。在享受AI效率提升的同时，别忘了在关键环节保留人工把关。</p><p>2025年是LLM的分水岭。规则变了，玩法也得跟着变。</p><p>2026年，又会有什么新的成果出现呢？评论区聊聊你的看法</p><p>既然看到这了，如果觉得不错，随手点个赞、收藏、转发三连吧～</p><p>我是Carl，大厂研发裸辞的AI创业者，只讲能落地的AI干货。</p><p>关注我，更多AI趋势与实战，我们下期再见！</p><p><img width="723" height="311" referrerpolicy="no-referrer" src="/img/bVdnuIt" alt="" title="" loading="lazy"/></p><p><strong>数据来源</strong></p><p>Karpathy 2025年终复盘原文 [数据|2025|<a href="https://link.segmentfault.com/?enc=c2aH28NQkYu%2BcDvNPeoQFQ%3D%3D.cBJT5Qlno%2FVvwqRdXEIhQOID4q08ShHOgztPNALCPoHkrn8nswrZ9dlnEAn1LWa7jZoWT%2BCdKTbCgua%2F0FSYNQ%3D%3D" rel="nofollow" target="_blank">https://karpathy.bearblog.dev/year-in-review-2025/</a>]</p><p>RLVR训练范式说明：基于可验证奖励的强化学习 [数据|2025|Karpathy原文]</p><p>DeepSeek R1推理能力展示 [数据|2025|DeepSeek R1论文]</p><p>Cursor估值变化：$400M(2024.8) → $9.9B(2025.6) [数据|2024-2025|<a href="https://link.segmentfault.com/?enc=j61Od%2BzxlkO%2F7NE3BKUYrQ%3D%3D.jfmxt5aRCtGTrr0gF3ZNSyU3xfgOr24PaB5LdjllOEep3wZVI8sEZ1h43MCOMsd0" rel="nofollow" target="_blank">https://techcrunch.com/tag/cursor/</a>]</p><p>OpenAI o1/o3推理模型发布 [数据|2024-2025|OpenAI官方]</p><p>Claude Code产品发布与功能说明 [数据|2025|Anthropic官方]</p><p>Vibe Coding概念由Karpathy在Twitter提出 [数据|2025|<a href="https://link.segmentfault.com/?enc=OaT%2BThX4ur9CJctXs%2BDpxQ%3D%3D.g3XlWXPEXvZHZfsSzYL%2BHq5CY2IlD2a6bD%2FDUhJOjYnvPTqjpfncWqaryT0NS1eyQDjRLEE7gh3fRnv51QK63g%3D%3D" rel="nofollow" target="_blank">https://x.com/karpathy/status/1886192184808149383</a>]</p><p>Google Gemini Nano Banana多模态融合能力 [数据|2025|Google官方]</p>]]></description></item><item>    <title><![CDATA[对抗样本：20行Python代码让95%准确率的图像分类器彻底失效 本文系转载，阅读原文
https]]></title>    <link>https://segmentfault.com/a/1190000047557152</link>    <guid>https://segmentfault.com/a/1190000047557152</guid>    <pubDate>2026-01-21 22:01:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>下图展示了一个有趣的现象：在法国斗牛犬的图像上添加一小块对抗性补丁后，VGG分类器竟然以极高的置信度将其判定为足球。Grad-CAM可视化清楚地显示，模型的注意力完全从狗身上转移到了那块补丁——一个精心构造的小扰动就足以劫持整个决策过程。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047557154" alt="" title=""/></p><h2>95%准确率的模型可能不堪一击</h2><p>ResNet、VGG、EfficientNet这些主流架构在ImageNet上动辄90%以上的准确率，看起来已经相当可靠。但这些模型隐藏着一个被多数工程师忽视的致命缺陷：它们极易被对抗样本愚弄。</p><p>改变一个像素，可能肉眼完全看不出区别，但分类器会彻底崩溃。本文会用FGSM（快速梯度符号法）演示如何制作对抗样本，并解释神经网络为何如此脆弱。</p><h2>对抗样本到底是什么</h2><p>简单说，对抗样本就是专门设计来欺骗模型的输入。和随机噪声不同，这种扰动是经过精确计算的——目标是在人眼察觉不到的前提下，最大化模型的预测误差。</p><p>这里存在一个悖论：模型可以正确识别成千上万张图片，但只要加上一点经过数学优化的噪声（像素值变化不到1%），它就会完全判断失误。</p><p>对抗攻击绝非学术界的自娱自乐。自动驾驶汽车可能把停车标志识别成限速标志；人脸识别系统可能被绕过；放射科AI可能给出错误诊断；有害内容可能躲过审核系统的检测。</p><p>问题的根源在于：分类器学到的是统计层面的捷径，而非真正的语义理解。高准确率和高安全性是两回事。</p><h2>FGSM：简单却致命的攻击方法</h2><p>Ian Goodfellow等人在2015年提出的FGSM至今仍是最经典的对抗攻击之一。它的原理出奇地简单，但恰恰暴露了深度神经网络的根本弱点。</p><h3>数学原理</h3><p>给定分类器和输入图像，FGSM计算一个扰动把图像推向错误分类的方向。具体做法是沿着损失函数梯度的方向移动每个像素，用epsilon参数控制扰动幅度，确保改动在视觉上不可察觉。</p><h3>FGSM为何有效</h3><p>深度网络虽然有非线性激活函数但在局部表现出近似线性的特性。每个像素上的微小变化会在高维空间中累积，最终在输出空间产生巨大偏移。梯度恰好指明了这个最有效的攻击方向——随机噪声做不到的事情，梯度对齐的噪声可以轻松做到。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047557155" alt="" title="" loading="lazy"/><br/>上图就是是Goodfellow等人最初展示的结果：在熊猫图像上叠加梯度符号计算得到的微小扰动，模型就会以极高置信度将其误判为长臂猿。两张图片在人眼看来毫无差别，但神经网络的判断却天差地别。</p><h2>Python实战：构建你的第一个对抗样本</h2><p>下面用PyTorch和预训练的ResNet-50从零实现一个对抗样本。</p><p>先安装依赖：</p><pre><code> pip install torch torchvision matplotlib numpy pillow</code></pre><p>导入必要的库：</p><pre><code> import torch  
 import torch.nn.functional as F  
 import torchvision.models as models  
 import torchvision.transforms as transforms  
 import matplotlib.pyplot as plt  
 import numpy as np  
 from PIL import Image</code></pre><p>第一步：加载分类器</p><p>用ResNet-50作为目标模型。这个架构在生产环境中很常见，而且支持梯度计算：</p><pre><code> model=models.resnet50(pretrained=True)  
 model.eval()</code></pre><p>第二步：准备图像</p><p>按ImageNet标准预处理输入图像：</p><pre><code> transform=transforms.Compose([  
    transforms.Resize((224, 224)),  
    transforms.ToTensor(),  
])

img=Image.open("your_image.jpg").convert("RGB")  
x=transform(img).unsqueeze(0)  
 x.requires_grad=True</code></pre><p>注意</p><pre><code>requires_grad=True</code></pre><p>这行。没有它就无法计算梯度，对抗攻击也就无从谈起。</p><p>第三步：获取原始预测</p><p>跑一次前向传播，看看模型本来会给出什么分类：</p><pre><code> logits=model(x)  
 pred=logits.argmax(dim=1)  
 print(f"Original prediction: {pred.item()}")</code></pre><p>正常情况下模型应该能正确分类。</p><p>第四步：FGSM攻击</p><p>核心代码如下：</p><pre><code> label = pred  
loss = F.cross_entropy(logits, label)  
loss.backward()

epsilon = 0.01  # perturbation budget
perturbation = epsilon * x.grad.sign()  
x_adv = x + perturbation  
 x_adv = torch.clamp(x_adv, 0, 1)</code></pre><p>这段代码做了什么？计算损失对输入像素的梯度，取符号得到方向，乘以epsilon控制幅度，加到原图上就得到对抗样本。最后用clamp保证像素值在合法范围内。</p><p>第五步：检验效果</p><p>用同一个模型测试对抗图像：</p><pre><code> logits_adv=model(x_adv)  
 pred_adv=logits_adv.argmax(dim=1)  
 print(f"Adversarial prediction: {pred_adv.item()}")</code></pre><p>大多数情况下预测结果会完全不同。图像看起来一样，分类却天壤之别。</p><p>第六步：可视化</p><p>把原图、对抗图、噪声模式放在一起对比：</p><pre><code> def show_adversarial_attack(original, adversarial, perturbation):  
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))  
      
    axes[0].imshow(original)  
    axes[0].set_title("Original Image")  
    axes[0].axis("off")  
      
    axes[1].imshow(adversarial)  
    axes[1].set_title("Adversarial Image")  
    axes[1].axis("off")  
      
    axes[2].imshow(perturbation, cmap="gray")  
    axes[2].set_title("Noise Pattern (10x Amplified)")  
    axes[2].axis("off")  
      
    plt.tight_layout()  
    plt.show()

orig_np = x.detach().squeeze().permute(1, 2, 0).numpy()  
adv_np = x_adv.detach().squeeze().permute(1, 2, 0).numpy()  
noise_np = (adv_np - orig_np) * 10
 show_adversarial_attack(orig_np, adv_np, noise_np)</code></pre><p>噪声模式放大10倍后看起来像电视雪花。人眼根本分辨不出两张图的区别，但神经网络却认为它们是完全不同的物体。</p><h2>神经网络为何如此脆弱</h2><p>理解这个问题需要从三个角度切入。</p><p>高维几何：一张224×224的RGB图像有150,528个维度。在这么高的维度里每个维度上的微小扰动累加起来就是巨大的距离。</p><p>局部线性：尽管激活函数是非线性的，深度网络在数据点附近的小邻域内表现得非常线性，这让基于梯度的攻击特别有效。</p><p>非泛化特征：研究发现模型大量依赖那些与标签相关、但与人类感知无关的统计模式。对抗样本正是在利用这些"捷径特征"。</p><p>一个令人不安的事实：深度学习模型优化的目标是训练集上的准确率，而不是对扰动的泛化性。</p><h2>一些限制需要说明</h2><p>FGSM只是单步攻击算比较弱的。迭代方法如PGD和Carlini-Wagner攻击力更强也更难防御。</p><p>本文的演示假设攻击者能拿到模型权重和梯度，属于白盒场景。现实中攻击者可能只能观察模型输出，需要用黑盒攻击技术或者利用对抗样本的迁移性。</p><p>数字扰动只是一种形式。物理世界的对抗样本——比如贴在物体上的特制贴纸——可以在不同光照和角度下持续欺骗视觉系统。</p><p>防御手段确实存在：对抗训练、输入预处理、集成方法、认证防御等等。但这些方法往往要牺牲准确率，而且没有哪个能提供完全的保护。</p><h2>防御策略</h2><p>几种主流防御思路：</p><p>对抗训练把对抗样本混入训练数据，让模型学会应对扰动。输入变换用JPEG压缩、随机缩放、降低位深等预处理来破坏对抗扰动。集成防御结合多个模型的预测或引入随机性来增加攻击难度。认证防御用随机平滑等技术在一定范围内提供数学上的泛化性保证。检测方法则训练专门的模型来识别对抗样本。</p><p>每种方法都有代价，在泛化性、准确率、计算开销之间做权衡。</p><h2>总结</h2><p>对抗样本揭示的是统计优化和人类感知之间的根本鸿沟。深度学习擅长模式匹配，但它并不理解图像的语义。</p><p>对抗样本不会消失。这不是可以修复的bug而是当前深度学习架构的内在属性。随着AI在关键基础设施中的应用越来越广，理解和缓解对抗脆弱性变得愈发重要。</p><p>泛化性应该和准确率、公平性、效率一样，成为一等公民级别的工程需求。否则，高准确率带来的只是虚假的安全感。</p><p><a href="https://link.segmentfault.com/?enc=iPNKIfJj2O4Wurp3m79zlg%3D%3D.L2R3eQYgd5RQfJakjiGiPcXB8tvZAu0IY81UK0CScl0qgQ5Wvk8mx1AFeEw3evwVPOLMbezTM1B%2FqmCLI1noJQ%3D%3D" rel="nofollow" target="_blank">https://avoid.overfit.cn/post/935d5167003748db859452026a44b056</a></p><p>作者: Sarthakvyadav</p>]]></description></item><item>    <title><![CDATA[解决 pip 遇到 Missing dependencies for SOCKS support 问]]></title>    <link>https://segmentfault.com/a/1190000047557079</link>    <guid>https://segmentfault.com/a/1190000047557079</guid>    <pubDate>2026-01-21 21:01:54</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <pre><code class="log">ERROR: Could not install packages due to an OSError: Missing dependencies for SOCKS support.</code></pre><p>最后排查了一下，发现是 vpn 的问题，我把 vpn 关了。然后把终端关了，新开一个终端再运行 pip 就行了</p>]]></description></item><item>    <title><![CDATA[基于 YOLOv8 的电网绝缘子破损与闪络缺陷智能检测系统识别项目 [目标检测完整源码] 南瓜 ]]></title>    <link>https://segmentfault.com/a/1190000047557102</link>    <guid>https://segmentfault.com/a/1190000047557102</guid>    <pubDate>2026-01-21 21:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>基于 YOLOv8 的电网绝缘子破损与闪络缺陷智能检测系统识别项目 [目标检测完整源码]</h2><h3>一、研究背景与工程问题分析</h3><p>随着电力系统规模的不断扩大，输电线路和变电设备的运行安全已成为电网运维中的核心问题之一。在众多电力设备中，<strong>绝缘子</strong>承担着电气隔离与机械支撑的双重任务，其运行状态直接影响电网的稳定性与可靠性。</p><p>在长期运行过程中，绝缘子通常会受到以下不利因素影响：</p><ul><li>长期高压电场作用导致材料老化</li><li>风沙、盐雾、工业污染物附着</li><li>高湿环境下易发生表面放电</li><li>外力冲击造成瓷裙破损或脱落</li></ul><p>由此产生的典型缺陷主要包括 <strong>绝缘子破损</strong> 与 <strong>绝缘子闪络</strong>。这类缺陷具有隐蔽性强、分布范围广、人工巡检成本高等特点，一旦未能及时发现，极易引发线路跳闸、设备损毁，甚至区域性停电事故。</p><p>传统的人工巡检方式已逐渐暴露出明显不足：</p><ul><li>巡检效率难以覆盖大规模线路</li><li>高空、野外作业存在安全风险</li><li>检测结果依赖个人经验，缺乏一致性</li></ul><p>在此背景下，结合无人机巡检、固定摄像头采集手段，引入<strong>基于深度学习的视觉检测技术</strong>，构建自动化缺陷识别系统，已成为智能电网发展的重要方向。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047557104" alt="在这里插入图片描述" title="在这里插入图片描述"/></p><h3>源码下载与效果演示</h3><p>哔哩哔哩视频下方观看：<br/><a href="https://www.bilibili.com/video/BV1Qk8uz6E9f/" target="_blank">https://www.bilibili.com/video/BV1Qk8uz6E9f/</a></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047557105" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/><br/>包含：</p><p>📦完整项目源码</p><p>📦 预训练模型权重</p><p>🗂️ 数据集地址（含标注脚本</p><h3>二、系统总体设计思路</h3><p>本项目以 <strong>YOLOv8 目标检测模型</strong> 为核心算法，面向电力巡检场景进行专项训练，并通过 <strong>PyQt5 图形界面</strong> 实现完整的工程化封装，最终形成一套可直接投入使用的 <strong>电网绝缘子缺陷智能检测系统</strong>。</p><h4>系统设计目标包括：</h4><ol><li><strong>高检测准确率</strong>：能够稳定识别破损与闪络缺陷</li><li><strong>实时推理能力</strong>：满足视频流与在线巡检需求</li><li><strong>良好可用性</strong>：非算法人员也可直接操作</li><li><strong>可扩展性强</strong>：便于后期模型升级与功能拓展</li></ol><hr/><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047557106" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h3>三、整体系统架构</h3><p>系统采用典型的分层架构设计，各模块职责清晰、相互解耦：</p><pre><code>┌───────────────┐
│ 数据采集层    │  图像 / 视频 / 摄像头 / 无人机
└───────┬───────┘
        │
┌───────▼───────┐
│ YOLOv8 推理层 │  缺陷检测与分类
└───────┬───────┘
        │
┌───────▼───────┐
│ 结果解析层    │  类别 / 置信度 / 坐标
└───────┬───────┘
        │
┌───────▼───────┐
│ PyQt5 界面层  │  可视化展示与交互
└───────────────┘</code></pre><p>该架构的优势在于：</p><ul><li>算法模块可独立替换或升级</li><li>UI 与模型完全解耦，降低维护成本</li><li>支持本地部署或后续服务化改造<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047557107" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></li></ul><hr/><h3>四、检测目标定义与业务建模</h3><h4>4.1 缺陷类别建模</h4><p>结合电力运维业务需求，本项目共定义三类检测目标：</p><table><thead><tr><th>类别</th><th>业务含义</th></tr></thead><tbody><tr><td>绝缘子</td><td>正常完整的绝缘子本体</td></tr><tr><td>破损</td><td>瓷裙缺失、裂纹、结构破坏</td></tr><tr><td>闪络</td><td>放电痕迹、污染导致的表面闪络</td></tr></tbody></table><p>这种分类方式不仅能够识别缺陷类型，还可为后续<strong>缺陷定位、统计分析与风险分级</strong>提供基础数据支持。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047557108" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><hr/><h4>4.2 数据集构建原则</h4><p>为了保证模型在实际场景中的泛化能力，数据集构建阶段重点考虑：</p><ul><li>不同拍摄高度（模拟无人机巡检）</li><li>不同光照条件（逆光、阴影、强反射）</li><li>复杂背景（山地、树林、建筑）</li><li>正常与缺陷样本的合理比例</li></ul><p>数据统一采用 YOLO 标准格式，便于训练、推理与工程复用。</p><hr/><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047557109" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h3>五、YOLOv8 模型选型与训练流程</h3><h4>5.1 YOLOv8 在工业场景中的优势</h4><p>YOLOv8 作为 Ultralytics 推出的新一代检测模型，在工程实践中具备以下优势：</p><ul><li>Anchor-Free 设计，减少人工调参</li><li>更合理的损失函数设计，提高收敛稳定性</li><li>推理接口高度封装，工程接入成本低</li><li>兼容 ONNX、TensorRT 等多种部署形式</li></ul><p>对于绝缘子这类<strong>尺度变化大、形态细长、背景复杂</strong>的目标，YOLOv8 在精度与速度之间取得了良好平衡。</p><hr/><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047557110" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h4>5.2 模型训练流程</h4><p>训练流程主要包括：</p><ol><li>数据清洗与标注校验</li><li>训练 / 验证集划分</li><li>模型初始化与参数配置</li><li>多轮迭代训练与性能评估</li></ol><p>训练过程中重点关注以下指标：</p><ul><li><code>mAP@0.5</code>：整体检测能力</li><li>混淆矩阵：破损与闪络的区分效果</li><li>Loss 曲线：模型是否稳定收敛</li></ul><p>当模型在验证集上表现稳定后，即可用于推理部署。</p><hr/><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047557111" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h3>六、推理流程与缺陷结果解析</h3><p>YOLOv8 提供了简洁高效的推理接口，推理阶段主要完成以下工作：</p><ul><li>加载训练完成的权重文件</li><li>对输入图像或视频帧进行检测</li><li>输出目标类别、置信度与边界框</li></ul><p>在视频与摄像头模式下，系统采用逐帧检测方式，并通过合理的帧率控制，确保检测效果与实时性之间的平衡。</p><hr/><h3>七、PyQt5 图形化系统设计</h3><p>为了提升系统的可用性，本项目引入 PyQt5 构建桌面级可视化应用，核心功能包括：</p><ul><li>多种检测模式切换（图片 / 视频 / 摄像头）</li><li>实时显示检测结果与缺陷标签</li><li>一键保存检测结果图片或视频</li><li>自动管理输出目录，便于后期复核</li></ul><p>该界面设计使系统能够直接服务于<strong>运维人员与巡检人员</strong>，而不仅仅局限于算法研究。</p><hr/><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047557112" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h3>八、典型应用场景与扩展方向</h3><h4>8.1 实际应用场景</h4><ul><li>输电线路无人机巡检</li><li>变电站设备日常检查</li><li>电网缺陷快速筛查与统计</li><li>智能运维示范项目</li></ul><h4>8.2 可扩展方向</h4><ul><li>缺陷严重程度自动分级</li><li>与巡检工单系统对接</li><li>缺陷时序变化分析</li><li>多模型协同检测（如分割 + 检测）</li></ul><hr/><h3>九、总结与思考</h3><p>本文围绕电网绝缘子破损与闪络缺陷检测这一典型工业视觉问题，系统性地介绍了一套 <strong>基于 YOLOv8 的智能检测系统</strong> 的完整实现过程。从问题背景、系统架构、模型训练，到可视化应用与工程部署，展示了深度学习技术在电力运维场景中的实际价值。</p><p>实践表明，<strong>只有将算法能力与工程需求深度结合，AI 技术才能真正落地并产生长期价值</strong>。本项目不仅适合作为电力巡检智能化的参考方案，也为其他工业缺陷检测场景提供了可复用的技术范式。</p>]]></description></item><item>    <title><![CDATA[移动ERP系统推荐（2026实用版）：6款按场景选不踩坑 SaaS圈老马 ]]></title>    <link>https://segmentfault.com/a/1190000047556959</link>    <guid>https://segmentfault.com/a/1190000047556959</guid>    <pubDate>2026-01-21 20:04:09</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>供应链、交付、现金流压力一上来，很多公司才发现：ERP不是“有没有”，而是“能不能在手机上把事办完”。<br/><strong>移动ERP选对了，核心是让审批、开单、库存、对账这些高频动作随时闭环。</strong></p><p><strong>一、主流移动ERP系统详细盘点</strong></p><p><strong>1、</strong><strong>支道</strong></p><p>支道是“一站式业务管理平台”，而不是那种固定菜单的传统ERP：你可以用它把采购、销售、项目、费用、审批、数据看板等流程按自己业务搭起来，然后在移动端跑起来。支道官方站点与App信息里都明确提到其以低代码/aPaaS等方式提供业务全流程数字化管理能力，背后主体为浙江支点数字科技有限公司。</p><p><strong>如果你们的痛点是“流程散、表格多、跨部门全靠催”，支道通常比换一套重ERP更快见效。</strong></p><p>推荐理由：</p><p>1、适合“业务变化快”的团队：流程、表单、权限经常要调整，不想每次都找开发改系统。</p><p>2、移动端上手快：App商店可查，适合把填报、审批、协同、数据汇总搬到手机上处理。</p><p>产品特色：</p><p>1、流程能“按你公司习惯走”：不是让你适应系统，而是系统更容易贴合你的流程。</p><p>2、数据能汇总到一处：减少“同一份数据多处填、多版本对不上”的情况。</p><p>3、适合先从一个部门/一条流程试起：跑通后再扩，不容易翻车。</p><p>适合场景/行业：</p><p>项目型/专业服务类公司、以及需要快速搭建内部流程的成长型企业。<br/><img width="723" height="298" referrerpolicy="no-referrer" src="/img/bVdnHTh" alt="" title=""/></p><p><strong>2、金蝶</strong></p><p>金蝶在小微与中小企业的移动端体验上做得比较成熟，尤其是“金蝶云星辰”这类产品，官方页面强调覆盖采购、销售、库存、资金等链路；同时其App商店信息也强调移动端经营看板、开单、审批等能力</p><p>1、推荐理由：想用手机把生意管住（开单/库存/资金），金蝶这条线比较稳。</p><p>2、产品特色：进销存与资金链路打通，移动端可做经营与待办处理。</p><p>3、适合场景：小微工贸、零售商家、轻量制造或商贸企业。</p><p>4、可能的局限：更偏“经营执行与老板看数”，复杂集团多业态要看更高阶产品与实施能力。<br/><img width="723" height="386" referrerpolicy="no-referrer" src="/img/bVdnHTi" alt="" title="" loading="lazy"/></p><p><strong>3、</strong><strong>用友</strong></p><p>用友体系里，“友空间”作为移动协同与门户入口，官方页面直接写到：一个App访问多系统、移动快捷审批、实时处理业务；App商店也强调可按组织/角色配置移动门户。</p><p>1、推荐理由：<strong>如果你们审批链条长、跨部门多，用友的“移动入口+审批</strong><strong>”更容易打通。</strong></p><p>2、产品特色：移动工作台、待办审批、业务单据一键访问。</p><p>3、适合场景：成长型企业、集团型组织的移动协同与业务处理。</p><p>4、可能的局限：体系更大，落地往往更依赖实施与规划。<br/><img width="723" height="287" referrerpolicy="no-referrer" src="/img/bVdnHTz" alt="" title="" loading="lazy"/></p><p><strong>4、</strong><strong>鼎捷</strong></p><p>鼎捷“掌上易助”页面写得很直白：提供易助小程序，用于满足ERP用户移动化需求；同时易助ERP介绍中也强调其面向中小微制造企业，覆盖财务、进销存、生产等模块。</p><p>1、推荐理由：制造企业经常是“人不在电脑前”，小程序入口更容易推广。</p><p>2、产品特色：面向中小微制造的ERP体系 + 移动端应用入口。</p><p>3、适合场景：机械、五金、汽配、电子加工等中小制造。</p><p>4、可能的局限：如果你是多工厂、多语言、多币种的全球化集团，需要评估更高阶产品线。<br/><img width="723" height="447" referrerpolicy="no-referrer" src="/img/bVdnHTO" alt="" title="" loading="lazy"/></p><p><strong>5、</strong><strong>浪潮</strong></p><p>浪潮移动ERP在App商店描述中明确写到：提供移动首页、功能中心、移动审批、协同消息等，并可接入后台业务系统。</p><p>1、推荐理由：<strong>你要的是“统一移动入口+审批协同”，浪潮这类更对路。</strong></p><p>2、产品特色：移动首页、功能中心、待办审批、协同消息等。</p><p>3、适合场景：高端集团企业移动化协同场景。</p><p>4、可能的局限：更偏“集团移动门户”，中小企业如果只要轻量进销存，可能会显得偏重。<br/><img width="723" height="287" referrerpolicy="no-referrer" src="/img/bVdnHTP" alt="" title="" loading="lazy"/></p><p><strong>6、</strong><strong>网上管家婆</strong></p><p>网上管家婆官网与App商店信息都提到：移动版为中小微打造，覆盖采购、销售、库存、财务等；并支持电脑、手机、平板、PDA多终端数据同步。</p><p>1、推荐理由：商贸批零电商最常见的诉求是“开单快、盘点快、对账清楚”。</p><p>2、产品特色：多终端同步、扫码操作、进销存+财务基础闭环。</p><p>3、适合场景：批发、零售、电商等。</p><p>4、可能的局限：更强在执行层，复杂制造/项目型的深度协同要另评估。<br/><img width="723" height="305" referrerpolicy="no-referrer" src="/img/bVdnHTQ" alt="" title="" loading="lazy"/></p><p><strong>二、6款移动ERP对比表</strong></p><p><img width="723" height="469" referrerpolicy="no-referrer" src="/img/bVdnHTR" alt="" title="" loading="lazy"/></p><p><strong>三、选型建议与关键知识</strong></p><p>移动ERP成不成功，<strong>不取决于“功能多不多”，取决于“用的人愿不愿意天天用”。</strong></p><p>1、先定“移动端三大高频动作”</p><p>（1）审批：合同/付款/报销/采购申请</p><p>（2）业务动作：开单、查库存、对账、收发货</p><p>（3）现场回填：项目进度、巡检、异常上报</p><p>2、再看“供应商/协作方是否好用”</p><p>（1）入口轻不轻，有没有App、小程序、网页</p><p>（2）操作顺不顺，能不能3步以内完成常用动作</p><p>3、再看“你现有系统怎么接”</p><p>（1）已有财务/ERP/OA？优先选接口开放、能集成的。</p><p>（2）用友/金蝶生态用户，走原生或强集成路线通常更省心。</p><p>4、最后算总成本，不只看软件费</p><p>（1）实施、培训、对接、运维、人力配合成本都要算进去。</p><p>（2）最稳的做法：先做PoC，拿你们真实单据和流程跑一遍。</p><p><strong>总结：如果你只想先把“移动闭环”跑起来，支道确实应该先看</strong></p><p>很多企业的真实情况是：流程不标准、变化快、协同靠人盯。这个时候，<strong>支道这种更偏“可搭建、可迭代”的路线，往往更容易先拿到效果</strong>，再逐步扩到更完整的管理体系。</p>]]></description></item><item>    <title><![CDATA[产品管理必备：产品指标体系搭建5步法（指标树/漏斗/看板全覆盖） PM老周 ]]></title>    <link>https://segmentfault.com/a/1190000047556962</link>    <guid>https://segmentfault.com/a/1190000047556962</guid>    <pubDate>2026-01-21 20:03:20</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>很多企业的指标越做越多，决策却越来越慢：会上报数热闹，真正的“下一步做什么”说不清。根因往往不是数据不够，而是缺少一套能对齐战略、解释因果、嵌入节奏的产品指标体系。本文用一套“5步法”把北极星、指标树、漏斗、治理与看板串成可执行路径，让指标从“汇报材料”变成“决策语言”。</p><blockquote>关键词聚合：产品指标体系｜北极星指标（North Star Metric）｜指标树（Driver Tree/KPI Tree）｜AARRR 漏斗（Pirate Metrics）｜HEART 体验指标｜OKR｜指标口径｜数据治理｜数据质量｜数据看板/仪表盘（Dashboard）</blockquote><h2>为什么你的指标越做越多，决策却越来越慢？</h2><p>我在不同规模的组织里反复见到一个现象：指标体系做得很“全”，管理却做得很“虚”。 每个部门都能拿出一组“看起来不错”的数字，但一旦追问“这些数字如何改变用户价值、如何影响长期收入”，讨论就会迅速滑向口径争执、责任推诿，最后以“下次再看”收场。</p><p>更棘手的是，一些“可展示但不可驱动”的指标会天然占据汇报舞台：曝光、下载、浏览量、粉丝数……它们往往能让人产生“我们在变好”的错觉，却很难直接导向下一步行动。组织越依赖这类指标，越容易陷入“报数化”，决策反而越来越慢。</p><p>所以问题不在于缺指标，而在于缺一套能把“指标—行动—结果—复盘”真正连起来的产品指标体系。当指标只用来展示，它会越来越像装饰；当指标用来决策，它才会成为组织能力。</p><h2>方法论：一套好的产品指标体系，至少解决三件事</h2><h4>关键定义：什么是“产品指标体系”？</h4><p>产品指标体系不是一张报表，也不是 KPI 清单，而是：</p><p><strong>一套围绕“用户价值与业务价值”建立的指标结构（指标分层+指标口径+数据治理+看板节奏），用于支持决策、资源配置与持续改进。</strong></p><p>它至少要同时解决三个问题：方向是否一致、原因是否可解释、行动是否能闭环。</p><p><strong>1）对齐：让“用户价值”和“业务价值”说同一种话</strong></p><p>中高层最怕的不是指标不好看，而是组织努力方向不一致：产品追功能，运营追热度，销售追签约，最后用户体验与续费被牺牲。我通常建议用“北极星指标（North Star Metric）”做对齐：用一个最核心的指标把方向统一，避免资源在部门之间相互抵消。</p><p><strong>2）可解释：从“指标清单”升级为“因果链条”</strong></p><p>有数字不等于有洞察。你需要的不是几十个 KPI，而是一棵能解释“为什么上升/下降”的指标树（Driver Tree / KPI Tree）：把结果指标拆解为可影响的驱动因素，帮助团队定位杠杆、做资源配置。</p><p><strong>3）可运营：把指标嵌入节奏，而不是只在月底出现</strong></p><p>指标体系发挥作用，靠的是机制：看板怎么设计、例会怎么开、异常怎么处理、动作怎么验证。否则指标会退化成“月度PPT”。这里要特别警惕一个规律：当指标被当作硬目标与奖惩绑定时，人会“优化指标”而不是“优化系统”。</p><h2>5步法：从“定方向”到“能落地”的产品指标体系搭建路径</h2><blockquote>一页速览（可直接做成内部共识页）<br/>1）定北极星（方向） → 2）搭指标树（因果） → 3）串漏斗（旅程） → 4）建治理（可信） → 5）上看板（闭环）</blockquote><h4>第一步：定北极星——先把“我们到底要变好什么”说清楚</h4><p>北极星指标怎么选？一句话答案：选“最能代表用户核心价值、且能牵引长期业务结果”的那一个。</p><p>北极星三条硬标准（评审时直接照此打分）</p><ul><li>代表用户核心价值（不是内部产出）</li><li>与商业结果强相关（能解释留存、续费、复购、成本效率等）</li><li>不能被短期手段直接拉动：如果一个指标能被刷量、活动堆资源迅速抬高，它往往不适合作为北极星（会把组织带偏）。</li></ul><p>常见误选（也是中国企业最常见的“走歪点”）</p><ul><li>误把“营收/签约额”当北极星：这是结果，但难指导产品日常动作；</li><li>误把“DAU/访问量”当北极星：易被流量手段劫持，且未必代表价值达成；</li><li>误把“上线功能数/迭代次数”当北极星：这是输出不是结果，容易把组织带向“忙而无功”。</li></ul><p><strong>产出物（务必落在纸面）</strong></p><ul><li>北极星指标（1个主选+1个备选）</li><li>3~5个输入指标（能被日常工作影响）</li><li>关键假设清单（本季度必须验证的因果假设）</li></ul><p>落地提示：北极星与关键假设最怕“只在会议上存在”。实践里我更建议把它们沉淀成可追溯、可讨论、可复用的“产品共识页”（例如 PRD/策略说明/指标定义页），并允许后续迭代版本化。像 <a href="https://link.segmentfault.com/?enc=nhDP%2FEHu5ImOOLggY5WY3Q%3D%3D.dxe5PToJes60D8v6kFQ5XNbiq%2Bcz%2F5nk2AvvGqrRxhA%3D" rel="nofollow" target="_blank">ONES Wiki</a> 这种知识库工具支持富文本/Markdown、评论讨论、版本记录与回滚，也支持把文档与项目任务关联起来，便于“战略—需求—迭代”同源追踪。</p><p><img width="723" height="436" referrerpolicy="no-referrer" src="/img/bVdnurO" alt="" title=""/></p><h4>第二步：搭指标树——把结果拆到“可被影响”的驱动指标</h4><p>指标树怎么画？一句话答案：把滞后结果拆成领先杠杆，让团队能“事前纠偏”而不是“事后复盘”。</p><p>我在项目里常用一句话提醒团队：</p><p><strong>只看结果，你永远在解释过去；有领先指标，你才可能改变未来。</strong></p><p>拆解三条纪律（避免“拆得很细但毫无行动价值”）</p><ul><li>可控性：拆到团队能影响的层级，否则只是压力传导；</li><li>可解释性：每条分支必须讲得清“为什么会影响上层指标”；</li><li>可验证性：允许被数据检验，避免拍脑袋“伪因果”。</li></ul><p>一个通用指标树骨架（可直接复用）</p><p>北极星（结果）：每周/每月“价值达成”的客户或用户规模</p><ul><li>覆盖：进入价值路径的比例（从“进入”到“达成”）</li><li>深度：价值行为频次/协作深度（从“能用”到“用好”）</li><li>稳定：关键流程成功率/性能/缺陷（从“可用”到“可靠”）</li><li>留存：次周/次月留存、续费前置信号（从“发生”到“持续”）</li></ul><p>指标卡片（Metric Card）：口径统一的最低成本做法</p><p>每个关键指标至少写清：</p><ul><li>指标定义（口径）｜计算公式｜数据来源（埋点/表/系统）</li><li>更新频率｜Owner（业务Owner）｜使用场景（用于什么决策）</li></ul><p>检查点：如果会开到最后仍在争“活跃到底怎么算”，说明你缺的不是分析能力，而是指标卡片与口径库。</p><p>落地提示：指标卡片不是“数据团队的文档”，而是产品团队的“决策字典”。我见过做得比较顺的团队，会把指标卡片放在知识库里，同时在需求/用户故事/实验任务上引用同一口径，避免“文档一套、执行一套”。ONES Wiki 支持文档关联项目任务、并能嵌入工作项列表；<a href="https://link.segmentfault.com/?enc=F7K2Q5ioEpnkk%2BChMc4%2BAw%3D%3D.2drY5XDegGHNduVTB%2B1gQ3f%2Fw4hIUwSU0imUKX6QEWXLeNAz75xxrhRjUjl%2Fpm1N" rel="nofollow" target="_blank">ONES Project</a> 则覆盖需求管理、迭代管理等场景，能把“要改什么”直接落到工作项上。</p><p><img width="723" height="446" referrerpolicy="no-referrer" src="/img/bVdnwjo" alt="" title="" loading="lazy"/></p><h4>第三步：串漏斗——把“增长与留存”讲成同一种语言</h4><p>漏斗怎么定义？一句话答案：把用户从“进入—首次价值—持续使用—付费/续费”的关键路径，用事件+时间窗固化为可运营指标。</p><p>在B2B/复杂产品里，漏斗最容易失败的两件事</p><ul><li>激活定义含糊：只写“完成注册”，没有“首次价值达成”；</li><li>没有时间窗口：不规定“7天内/14天内”，漏斗就无法比较、无法运营。</li></ul><p>推荐做法：把“激活”定义为“首次价值达成（First Value）”。B2B 常见示例：</p><ul><li>T天内完成关键配置 / 跑通关键流程一次</li><li>首次协作达成（≥2角色、≥1流程闭环）</li><li>首次产出可交付结果（报表/审批/工单闭环等）</li></ul><p>产出物</p><ul><li>关键路径（用户旅程）图</li><li>AARRR 各阶段的“决策级指标”（每段1~2个）</li><li>每个指标对应的“可运营动作库”（触达、引导、产品改造、质量改进）</li></ul><p>落地提示：漏斗不是“画出来”，而是“跑起来”。所以建议你把每个漏斗节点的改进动作拆成可执行的产品工作项：比如“激活引导改版”“关键任务模板”“首个价值路径埋点补齐”“新手引导实验A/B”等，并按优先级进入需求池。比如 ONES Project 提到其支持建立需求池、规划迭代，并可通过看板、燃尽图等跟踪进度——这类能力更适合承载产品团队“从漏斗诊断到迭代交付”的连续动作。</p><h4>第四步：建治理——口径统一、数据可信、权责闭环</h4><p>治理怎么做？一句话答案：把指标当“管理资产”来管，像管需求一样管口径、质量与变更。</p><p>很多企业的产品指标体系失败，不是方法错，而是“治理缺席”：同名不同口径、数据延迟、指标无人负责，最后只能“用感觉决策”。</p><p>治理四件套（PMO 最适合牵头）</p><ul><li>指标口径库：统一定义、统一版本、可追溯</li><li>数据质量红线：准确性、完整性、一致性、及时性（不达标必须标注风险）</li><li>Owner机制：业务Owner 对指标解释与改进负责（数据同学负责“数的正确”）</li><li>变更控制：口径/埋点/报表变更必须评审、公告、可回溯</li></ul><p>检查点：如果一个指标没有Owner，就没有人对“为什么变动、下一步怎么改”负责——它迟早变成“会议装饰”。</p><p>落地提示：很多产品团队在“指标治理”上忽略了一件事：指标体系不仅要管增长，也要管质量与体验。一个常见闭环是：需求→开发→测试→缺陷→复盘，如果链条断了，你会在“指标下降”时找不到可修复的抓手。<a href="https://link.segmentfault.com/?enc=nCKAQpOexk2pJI6jZ1Pg0A%3D%3D.PD%2BkqzydQG%2Bxfa0%2BzHjYiGi3MGy2nBgfMwsuZ5rRj0cT1OL6CIjgOFmcHLDVYrBi" rel="nofollow" target="_blank">ONES TestCase</a> 支持测试用例与需求/任务关联、测试计划与迭代关联，并可由未通过用例快速创建缺陷任务；ONES Project 也与 TestCase 数据互通、可一键提 Bug 并跟踪缺陷。对产品团队而言，这意味着“漏斗问题”可以更快落到“版本质量与缺陷修复”的可执行闭环。</p><p><img width="723" height="428" referrerpolicy="no-referrer" src="/img/bVdnHTV" alt="" title="" loading="lazy"/></p><h4>第五步：上看板——用“看板+例会+复盘”把指标变成组织习惯</h4><p>看板怎么做？一句话答案：看板不是展示页，而是“决策清单”——每次例会都要产出动作与验证方式。</p><p>三层看板（与组织层级匹配）</p><ul><li>经营层看板：北极星 + 关键结果（季度视角）</li><li>产品层看板：指标树主干 + 漏斗关键节点（双周/月度节奏）</li><li>专项看板：版本/实验/活动（短周期验证，明确假设与样本）</li></ul><p>OKR 如何衔接指标体系？</p><ul><li>OKR 的 KR 要“可衡量、可复盘、能驱动对齐”。因此我建议的硬规则是：</li><li>KR 优先来自“指标树主干 + 漏斗关键节点”；</li><li>每个KR必须对应：动作（做什么）+ 证据（怎么证明有效）；</li><li>复盘只讨论：事实—解释—动作，避免变成表态会。</li></ul><p>落地提示：</p><p>产品经理常见痛点是：单个迭代看得清，多项目/多团队协同就看不清（依赖、资源、节奏容易失控）。在这种情况下，除了迭代看板，还需要“产品线/项目集”层面的汇总视角。ONES 的项目集管理解决方案强调为管理者提供全局视角、支持跨项目制定迭代计划；同时 ONES Project 也提供看板、燃尽图与多种报表来呈现项目表现。你不需要把看板做得花，关键是把它绑定到“例会—异常—动作—验证”的固定节奏上。</p><p>如果你还想把“指标体系”落实到更稳定的度量面（交付效率、交付质量、资源效率等），<a href="https://link.segmentfault.com/?enc=ds6p0bTFgcfag0yQ%2Fl8osA%3D%3D.kytyqNdyswSaY5sRoogOoy9C5gChHG4ZhB7%2BFNbswxIfdA4sTO8GsVIg2%2BxM970b" rel="nofollow" target="_blank">ONES Performance</a> 提到其建立多维度效能度量实践体系，并提供仪表盘模板与多维分析能力，可用于跨团队的趋势复盘。</p><p><img width="723" height="443" referrerpolicy="no-referrer" src="/img/bVdnyyT" alt="" title="" loading="lazy"/></p><h2>常见误区：产品指标体系最怕“越努力越错”</h2><p><strong>误区1：指标越多越安全</strong><br/>指标多往往意味着焦点分散。建议先把“决策级指标”控制在 10~20 个，其他作为诊断指标按需展开。</p><p><strong>误区2：只盯增长，不看体验与质量</strong><br/>如果产品进入长期经营阶段，建议把体验纳入指标体系。HEART 框架提供五类 UX 指标：Happiness、Engagement、Adoption、Retention、Task Success，并强调不必每次都用全量指标，应按目标选择组合。</p><p><strong>误区3：把指标当考核“唯一答案”</strong><br/>当指标直接绑定奖惩，人会优化指标而不是优化系统，这是典型的古德哈特风险。<br/>更成熟的做法是：指标用于“方向与学习”，考核看“过程合规 + 结果趋势 + 关键里程碑”，避免单点指标绑架组织。</p><h2>常见问题 FAQ：</h2><p><strong>Q：北极星指标可以有两个吗？</strong><br/>A：强烈建议“一条业务线一个北极星”，否则对齐会被稀释；若多业务线，可采用“业务线北极星 + 集团约束指标”。</p><p><strong>Q：指标树拆到多细才算够？</strong><br/>A：拆到“团队可控、可行动、可验证”为止；再细会变成噪音。</p><p><strong>Q：产品经理最容易把哪一步做成形式？</strong><br/>A：第三步与第五步——漏斗没变成需求池动作、看板没绑定复盘节奏，最后都会退化成“好看的图”。</p><p>一套真正有效的产品指标体系，最终在提升一种组织能力：</p><ul><li>用北极星对齐方向，减少内耗；</li><li>用指标树解释因果，把结果变成可驱动的杠杆；</li><li>用漏斗运营旅程，把增长与留存放到同一条价值路径上；</li><li>用治理保证可信，让复盘基于同一套事实；</li><li>用看板与 OKR 固化节奏，把学习变成组织习惯。</li></ul><p>当指标从“月底报表”走向“日常决策”，管理不会更冷，反而更诚实：因为每一次取舍，都能被解释、被验证、被复盘。对中高层与 PMO 来说，这才是指标体系真正的价值——把组织从“讲故事”带到“做学习”。</p>]]></description></item><item>    <title><![CDATA[数据语义层 vs 宽表模式：哪种架构更适合 AI 时代的数据分析？ Aloudata大应科技 ]]></title>    <link>https://segmentfault.com/a/1190000047556965</link>    <guid>https://segmentfault.com/a/1190000047556965</guid>    <pubDate>2026-01-21 20:02:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在 AI 驱动的数据分析时代，传统宽表模式因敏捷性不足、数据冗余和难以支持即席查询而力不从心。相比之下，NoETL 数据语义层（Semantic Layer）作为位于数据存储与应用间的抽象层，通过将物理数据映射为统一业务语义，实现了逻辑与物理解耦。对于需要快速响应变化、支持 AI 交互的场景，语义层架构是更具适应性的选择，能提供零等待的指标交付和 100% 一致的业务口径。</p><h2>AI 时代下，传统宽表模式为何力不从心？</h2><p>数据分析正从“预制品加工”转向“自助式厨房”。过去支撑报表的宽表模式，在 AI 驱动、即席查询的需求下暴露三大瓶颈：</p><ol><li>敏捷性坍塌：业务变更需回溯修改 ETL、重跑宽表，响应周期长达数周。</li><li>数据一致性失控：多张口径各异的宽表导致“指标打架”，AI 模型基于此将产生不可靠洞察。</li><li>无法支持即席查询：宽表只能回答预设问题，无法响应跨域、临时的分析需求。</li></ol><p>例如，周五下午，市场部需要新指标评估促销活动。数据团队告知需新建宽表，排期至下周三。决策时机已然错过。这种“响应迟滞”在 AI 时代是致命的。</p><h2>什么是 NoETL 数据语义层（Semantic Layer）？</h2><p>NoETL 数据语义层（Semantic Layer）是数据存储与数据应用间的关键抽象层，其核心功能是将复杂的技术数据结构映射为统一的业务术语和指标，充当数据的“业务翻译官”。其颠覆性源于三大技术理念：</p><ol><li>解耦逻辑与物理：业务逻辑（如“销售额=价格×数量-折扣”）不再硬编码于 ETL，而是作为可复用定义存储于语义层。</li><li>统一业务语义：动态编织明细数据为统一的业务语义，确保全公司对“销售额”只有一个定义，实现“单一事实来源”。</li><li>实时查询下推：将“查看华东区销售额”的查询实时翻译、优化并下推至数据源执行，无需移动和预计算数据。</li></ol><h3>为什么它是 AI 时代的关键？</h3><p>AI Agent 需要无歧义的上下文来准确生成 SQL。语义层提供了这份“业务词典”，为 AI 提供了稳定、可靠的数据接口，从根本上避免了因口径混乱导致的“AI 幻觉”。</p><h2>Aloudata 如何基于语义层赋能 AI 驱动的分析？</h2><p>作为国内数据语义编织（Semantic Fabric）领导者，Aloudata 方案的核心是：用 Aloudata CAN 自动化指标平台构建语义层，用 Aloudata Agent 分析决策智能体作为交互入口。</p><p>企业可以通过 Aloudata CAN 中连接数仓明细层，在可视化界面通过配置化的方式定义业务实体、维度和指标，构建语义模型，形成 NoETL 数据语义层，实现业务语义的标准化开发和管理，保障 100% 指标口径的一致性，避免 AI 问数的“幻觉”出现。</p><p>以 NoETL 数据语义层为底座，用户可以部署 Aloudata Agent，通过自然语言交互的方式直接提问：“上周新用户首单平均客单价？”Agent 基于语义层理解意图，通过 NL2MQL2SQL 的技术路径，先输出 MQL，再通过指标语义引擎生成 100% 准确的 SQL 语句并返回结果。</p><p>在这个过程中，用户零等待指标交付，逻辑变更分钟级生效，无需 ETL；100%一致口径，所有人与 AI 通过同一语义层访问数据；无缝对接 AI，语义层为 AI 提供标准化查询 API。</p><h2>常见疑问回答（FAQ）</h2><h4>Q: 语义层架构的性能是否比宽表差？</h4><p>不会。语义层采用智能查询下推与缓存，其优势在于在保证核心性能的同时，极大扩展了可即时响应的问题范围。</p><h4>Q: 已建的宽表和数据仓库，是否要推倒重来？</h4><p>不需要。语义层是增强层。Aloudata CAN 可直接连接现有数据资产，在其之上构建统一语义，保护投资的同时解锁新能力。</p><h4>Q: 语义层如何保证数据安全与权限控制？</h4><p>企业级产品（如 Aloudata CAN）提供行列级权限管控，并将规则与语义模型绑定。任何查询都会自动注入权限过滤，确保安全合规。</p>]]></description></item><item>    <title><![CDATA[GraphicsGale安装步骤详解（附首次运行与基本使用） 读书笔记 ]]></title>    <link>https://segmentfault.com/a/1190000047556979</link>    <guid>https://segmentfault.com/a/1190000047556979</guid>    <pubDate>2026-01-21 20:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>​</p><p><code>GraphicsGale</code>是一款<strong>像素画制作软件</strong>，很多画像素图、做 GIF 动画的人都在用，体积小、功能全，还支持逐帧编辑。</p><p>它的安装包通常就是一个 <code>.exe</code>文件，双击就能装，下面一步步教你。</p><h2>一、准备工作</h2><p><strong>安装包下载：</strong><a href="https://link.segmentfault.com/?enc=S21dayf3qzyg5%2FHrDScogg%3D%3D.UDbFgYegP9SyIVfykKCbkhTTNXz7DXzwOfZuqO%2BSl7Wm2eAHlzB2BsqWq5vTuxvH" rel="nofollow" title="https://pan.quark.cn/s/007523c13df9" target="_blank">https://pan.quark.cn/s/007523c13df9</a></p><h2>二、安装步骤</h2><ol><li>双击 <code>GraphicsGale.exe</code>运行。</li><li>如果是 Windows 10/11，会弹出“用户账户控制”提示 → 点  <strong>“是”</strong> （需要管理员权限）。</li><li>进入安装界面，选语言（默认 English，想换日语或中文可以看有没有选项，有的版本没有就默认英文）。</li><li>点  <strong>“Next”</strong> ​ 继续。</li><li><p>选安装位置：</p><ul><li>默认是 <code>C:\Program Files\GraphicsGale</code>，想改就点“Browse”选 D 盘或其他盘。</li></ul></li><li><p>选附加任务：</p><ul><li>建议勾“Create a desktop shortcut”（创建桌面快捷方式），点“Next”。</li></ul></li><li>点  <strong>“Install”</strong> ​ 开始安装，等进度条走完（很快，几秒钟）。</li><li>最后点  <strong>“Finish”</strong> ​ 完成安装，桌面上会有 GraphicsGale 图标。</li></ol><h2>三、首次运行设置</h2><ol><li>双击桌面图标打开软件。</li><li>第一次打开可能会提示“是否注册” → 选“试用”或“Cancel”（免费版够用了）。</li><li>进入主界面，就能开始画像素图了。</li></ol><h2>四、基本使用（简单说两句）</h2><ul><li><strong>新建画布</strong>：点“File”→“New”，选尺寸（比如 32x32、64x64 像素）。</li><li><strong>画图工具</strong>：左边工具栏有铅笔、橡皮、油漆桶、吸色器等，选了就能画。</li><li><strong>保存文件</strong>：点“File”→“Save As”，支持 <code>.gal</code>（工程文件）、<code>.png</code>、<code>.gif</code>等格式。</li><li><strong>做 GIF 动画</strong>：新建多帧画布，每帧画不同的画面，然后导出为 GIF 就行。</li></ul><p>​</p>]]></description></item><item>    <title><![CDATA[跨平台开发地图：2025跨平台技术简单总结 | 2026年1月 程序员老刘 ]]></title>    <link>https://segmentfault.com/a/1190000047556516</link>    <guid>https://segmentfault.com/a/1190000047556516</guid>    <pubDate>2026-01-21 19:10:37</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><strong>哈喽，我是老刘</strong></p><p>2025年已成过往。随着iOS、Android、桌面端、Web与各类小程序的持续发展，原生开发的高墙已难以维系，成本与效率的矛盾达到顶峰。</p><p>跨平台不再只是备选项，而是个人和团队的必选项。但面对Flutter的全平台一致体验、React Native的新架构性能突破、uni-app x的原生编译能力、KMP的Compose全栈统一，究竟谁才是2026年的最优解？</p><p>如何在这个AI重塑代码的时代，把有限的资源发挥出最大的效率？</p><p>老刘每个月为大家画出最新的跨平台技术选型地图，帮你快速做决策。</p><p>本月，各大框架在“原生体验”与“AI提效”上都有重磅更新。</p><hr/><h2>1. 2025年跨平台技术简单总结</h2><ul><li><strong>性能仍是核心</strong></li></ul><p>2025年，各个框架都在寻找性能的突破点。</p><p>Flutter全面普及Impeller引擎，解决了最后一公里的卡顿问题。</p><p>uni-app x和KMP则选择了另外一条路，通过编译为原生代码（Native Compilation），直接从物理层面消除了性能鸿沟。</p><p>RN则全面切换到新架构来实现性能的突破。</p><p>性能上向原生看齐是2025年跨平台技术的一个重要趋势。</p><ul><li><strong>平台拼图补全</strong></li></ul><p>框架们不再满足于能跑，而是追求各个平台的完美适配。</p><p>Flutter在桌面端和Web端（Wasm）持续发力，真正实现六端同源。</p><p>KMP推出了Kotlin-to-Swift导出功能，让iOS开发者也能优雅地接入，填补了跨平台在iOS原生生态上的最后一块拼图。</p><ul><li><strong>AI与框架深度融合</strong></li></ul><p>AI不再只是外部辅助，而是开始进入框架内部。</p><p>Flutter推出的Dart MCP Server让AI能直接理解项目结构和组件树。</p><p>MAUI也在不断完善其AI功能，如Copilot Agent，试图通过AI赋能来改善开发者体验。</p><p>应该说我们离描述即应用的时代不远了。</p><h2>2. 最新技术动态</h2><h3>2.1 React Native 新架构全面启用</h3><p>React Native 0.83 发布日志: <a href="https://link.segmentfault.com/?enc=muKiWRaJjfn1WALS1tTI6A%3D%3D.z8XOHjjU3pK%2FbXLauyrgtq8P%2B64c93Sq3d%2BMaD5p36g%3D" rel="nofollow" target="_blank">https://reactnative.dev/blog</a></p><p>React Native 0.83 版本随 Expo SDK 55 正式到来。新架构（New Architecture）已成为默认标准，遗留架构代码正在被加速移除。新版本集成了 React 19.2，并在构建时间和应用体积上取得了显著优化。开发者现在可以享受到更接近原生的性能体验，以及更强大的 DevTools 支持。</p><h3>2.2 Kotlin Multiplatform 生态成熟加速</h3><p>Kotlin 2.3.20-Beta1 新特性: <a href="https://link.segmentfault.com/?enc=9pWn9qfUbr0kj3uF3Oy6xg%3D%3D.qS6BGQrPWowq%2FsJFnofulS64lFWcRfuE1pgFKsAgvm9WNbu%2By6NNFVyYlVaqTihr" rel="nofollow" target="_blank">https://kotlinlang.org/docs/whatsnew-eap.html</a></p><p>Kotlin 2.3.20-Beta1 于本月发布，标志着 KMP 生态的进一步成熟。</p><p>Compose Multiplatform for iOS 已经稳定，越来越多的团队开始从原生转向 KMP。</p><p>K2 编译器的全面普及以及 JetBrains 在 AI 辅助开发（如 Koog 和 Mellum）上的投入，使得 KMP 的开发效率达到了新高度。</p><h3>2.3 .NET MAUI 企业级发展</h3><p>.NET MAUI Roadmap: <a href="https://link.segmentfault.com/?enc=e4Lw3qC%2FKbVirIilnZwrPQ%3D%3D.Ssxafrdg4i1DJGZyg%2BJpKmhImqYWuCFvXC2kBzsGa5gmrM4juuAxnCAnUdA%2FSUdA" rel="nofollow" target="_blank">https://github.com/dotnet/maui/wiki/Roadmap</a></p><p>.NET 11的规划和早期迭代正在进行中。当前重点依然是提升产品质量和性能稳定性。微软正在深度集成 GitHub Copilot 和 Copilot Agent，试图通过 AI 赋能来改善 MAUI 的开发者体验。尽管社区仍有关于稳定性的讨论，但其在企业级市场的地位依然稳固。</p><h3>2.4 Flutter 平台更新</h3><p>Flutter 最新动态: <a href="https://link.segmentfault.com/?enc=9DXnQXyy9PTKxAqwPLoZHw%3D%3D.%2BhalBbj4POj96om0SwykXhQyYljrlY6vYWyuta6lV48qpPb4mkRXTwc1wy3nydjp" rel="nofollow" target="_blank">https://docs.flutter.dev/release/whats-new</a></p><p>虽然社区对 Flutter 4.0 充满期待，但截止 2026 年 1 月，<strong>Flutter 3.38</strong> 仍是官方维护的最新稳定版本。目前的更新重点在于 <strong>Impeller 渲染引擎</strong> 的进一步优化与稳定性提升，该引擎现已在 iOS 和 Android 上默认启用，彻底解决了 shader 编译造成的卡顿问题。此外，Flutter 团队修复了 Android 端 Activity 销毁时的内存泄漏问题，并对 Android 15 的 16KB Page Size 提供了完整支持，继续巩固其在跨平台渲染一致性上的优势。</p><h3>2.5 uni-app x 进展</h3><p>uni-app x 更新日志: <a href="https://link.segmentfault.com/?enc=YLtqSeF5ckRShueDeZHtlA%3D%3D.cggjSaVbuoS0NFKf3sDTG0iE2n6bzyzhw8za3qp%2F0lyUYpyup0ZTyDfEZxr6WBg%2B" rel="nofollow" target="_blank">https://uniapp.dcloud.net.cn/release.html</a></p><p>近期 uni-app x 迎来了一系列重要更新（v4.87）。核心亮点包括：</p><ul><li><strong>多线程能力增强</strong><br/>新增 <code>uni.createWorker</code> API，正式支持 Worker 线程，显著提升复杂计算场景下的性能表现。</li><li><strong>鸿蒙生态深度适配</strong><br/>将逻辑层 JSVM 迁移至独立子线程，彻底解决主线程阻塞问题；新增微信登录、分享及屏幕亮度调节等原生能力。</li><li><strong>新设备与系统兼容</strong><br/>修复 Android 16KB 页大小模式下的录音问题，并提前适配 iPhone 17 系列机型。</li></ul><h3>2.6 Valdi 进展</h3><p>Valdi GitHub 仓库: <a href="https://link.segmentfault.com/?enc=qeOREE2ZndXG8xboXk6YLg%3D%3D.Qme4EYasOoYeYfZTnej3aLAtgmxgAxDbb6IWO5L%2BlwD74YnvQMxfNWx7m%2FMoeXew" rel="nofollow" target="_blank">https://github.com/Snapchat/Valdi</a></p><p>本月Valdi框架没有新的进展，最新发布版本仍然是beta-0.0.1</p><p>接下来老刘按照跨平台技术框架的三种路线，分别介绍一下目前主流的跨平台技术。</p><hr/><h2>3. 自渲染类框架</h2><p>简单来说，就是框架自己携带渲染引擎，自己画界面，不用系统提供的组件。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047276640" alt=" " title=" "/></p><p>这样做有什么好处？</p><ul><li><strong>界面完全一致</strong><br/>UI渲染不依赖系统组件，多端展示效果完全统一。</li><li><strong>性能媲美原生</strong><br/>跳过系统UI层直接操作GPU绘制，架构与原生一致。</li><li><strong>无兼容性Bug</strong><br/>不调用系统原生组件，规避了因系统差异导致的兼容性问题。</li></ul><h3>3.1 Flutter</h3><p>2024年Stack Overflow调查显示，Flutter是最受欢迎的跨平台框架。</p><p>全球有超过500万开发者在使用。</p><p>连阿里巴巴、腾讯、字节跳动都在使用Flutter。</p><p><strong>为什么这么多大厂选择Flutter？</strong></p><ul><li><strong>性能强劲</strong><br/>切换Impeller引擎后，Flutter性能已与原生应用一致。</li><li><strong>开发高效</strong><br/>热重载实现秒级预览，Dart语言在功能性与复杂度间达成完美平衡。</li><li><strong>生态成熟</strong><br/>pub.dev拥有超4万插件，涵盖地图、支付等各类功能，开箱即用。</li><li><strong>测试友好</strong><br/>拥有客户端领域最佳的单元测试支持，是TDD及敏捷团队的最优选择。</li><li><p><strong>拥抱AI</strong></p><ul><li><strong>AI Toolkit</strong></li></ul><p>集成Gemini API，快速实现聊天、识别等功能。</p><ul><li><strong>本地部署</strong></li></ul><p>支持TensorFlow Lite/ONNX，保障隐私安全。</p><ul><li><strong>Dart MCP Server</strong></li></ul><p>让AI助手直接理解项目，辅助编码与调试。</p></li></ul><hr/><h2>4. 中间层类框架</h2><p>简单来说，就是在你的代码和系统原生组件之间，加了一个"翻译官"。</p><p>比如你用JavaScript写界面逻辑，框架帮你翻译成原生的Button、TextView。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047276641" alt=" " title=" " loading="lazy"/></p><p><strong>核心特点：</strong></p><ul><li><strong>成熟的开发体验</strong><br/>复用React/Vue/C#等生态成熟的开发思路，上手快，学习成本低。</li><li><strong>原生组件渲染</strong><br/>最终映射为系统原生组件，UI符合平台规范，质感原生。</li><li><strong>桥接性能损耗</strong><br/>通过中间层与原生通信存在"翻译"开销，交互密集场景性能稍弱，常规界面无感知。</li></ul><h3>4.1 React Native</h3><p>React Native是第二受欢迎的跨平台框架，是Facebook开源的项目。</p><p><strong>为什么这么多人选择React Native？</strong></p><p><strong>核心优势：</strong></p><ul><li><strong>零门槛上手</strong><br/>React开发者可直接复用JSX、组件化及状态管理经验，一周即可转型。</li><li><strong>生态庞大</strong><br/>npm拥有超15万相关包，共享Web生态，导航、支付等库应有尽有。</li><li><strong>动态热更新</strong><br/>支持不发布新版本App直接在线更新，无需发版即可修复Bug或上线新功能，迭代极快。</li><li><strong>架构升级</strong><br/>Meta持续投入，新架构引入Fabric和TurboModules，性能提升30%，旧架构已退役。</li></ul><h3>4.2 .NET MAUI</h3><p>2024年5月，微软正式停止了Xamarin的支持，.NET MAUI（Multi-platform App UI）成为微软官方的跨平台解决方案。</p><p><strong>核心优势：</strong></p><ul><li><strong>企业级保障</strong><br/>微软提供长期技术支持（LTS），确保企业应用所需的稳定性。</li><li><strong>数据处理强</strong><br/>C#擅长处理复杂业务逻辑，特别适合金融、ERP等数据密集型应用。</li><li><strong>生态深度集成</strong><br/>与Azure、SQL Server等微软全家桶无缝对接，集成体验最佳。</li></ul><hr/><h2>5. 转译类框架</h2><p>简单来说，就是把你写的高级语言代码，"翻译"成目标平台的原生代码。</p><p>比如你用Kotlin写业务逻辑，框架帮你"翻译"成iOS的Swift代码。</p><p>或者你用类TypeScript的语法写界面，框架帮你"翻译"成Android的Kotlin和iOS的Swift。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556518" alt="" title="" loading="lazy"/></p><p><strong>核心特点：</strong></p><ul><li><strong>性能接近原生</strong></li></ul><p>因为最终运行的就是原生代码，没有任何中间层损耗。</p><p>就像你直接用Swift写iOS应用，用Kotlin写Android应用一样。</p><ul><li><strong>能享受原生生态</strong></li></ul><p>转译后的代码可以直接调用平台的所有API。</p><ul><li><strong>转译效果可能不完美</strong></li></ul><p>毕竟是机器"翻译"的代码，有时候可能不如手写的原生代码优雅。</p><p>特别是复杂的业务逻辑，转译后的代码可能需要人工优化。</p><p>但这个问题随着AI技术的发展，正在快速改善。</p><h3>5.1 Kotlin Multiplatform (KMP)</h3><p>KMP的核心用法：业务逻辑用KMP共享，UI用Compose Multiplatform统一开发</p><p>这是KMP的最新发展方向，结合了Compose Multiplatform的强大能力。</p><p>一套Compose代码可以运行在Android、iOS、Desktop、Web等所有平台。</p><p><strong>KMP的特点</strong></p><ul><li><strong>真正的一套代码多平台</strong></li></ul><p>不仅业务逻辑共享，UI也可以共享，开发效率大幅提升。</p><ul><li><p><strong>保持原生性能</strong></p><p>Compose Multiplatform在各平台都编译为原生代码，性能接近原生应用。</p></li><li><strong>技术栈统一</strong></li></ul><p>全部使用Kotlin生态，学习成本更低，团队协作更高效。</p><ul><li><strong>渐进式迁移</strong></li></ul><p>你不需要重写整个应用，可以先从一个模块开始。</p><p>比如先把网络层用KMP重写，然后逐步迁移UI到Compose Multiplatform。</p><ul><li><strong>生态仍需完善</strong></li></ul><p>生态仍在加速建设，注意版本兼容与插件成熟度，第三方库相对较少，但发展很快。</p><h3>5.2 uni-app / uni-app x</h3><p><strong>传统uni-app</strong><br/>基于Vue.js + JavaScript，更适用于小程序开发</p><p><strong>uni-app x</strong><br/>全新架构，使用UTS语言，性能达到原生级别</p><p><strong>uni-app x的技术特点</strong></p><ul><li><strong>平台支持最全</strong></li></ul><p>一套代码可以发布到：iOS、Android、Web、各种小程序、快应用、鸿蒙...</p><p>总共支持14+个平台，这是其他框架做不到的。</p><ul><li><strong>小程序优先的设计理念</strong></li></ul><p>如果你的产品需要同时支持App和小程序，uni-app几乎是唯一的选择。</p><p>其他框架都是App优先。</p><ul><li><strong>国产化支持</strong></li></ul><p>对鸿蒙、信创等国产化平台支持最好。</p><p>这对国内企业来说非常重要。</p><ul><li><p><strong>uni-app的局限</strong></p><p><strong>生态相对封闭</strong><br/>主要依赖DCloud的生态<br/>  <strong>国际化程度低</strong><br/>海外开发者使用较少<br/>  <strong>技术栈绑定</strong><br/>主要适合Vue技术栈</p></li></ul><h3>5.3 Valdi</h3><p>Valdi的核心思路属于转译方案的范畴，但是并发代码级转译。</p><p>它采用了介于转译和中间层之间的混合架构，将UI组件树编译为原生组件并交由C++引擎管理生命周期，同时保留业务逻辑在TS层（Worker）运行，从而实现无JS Bridge的高性能渲染。</p><p>这样的好处是在一定程度上避免了转译类方案代码翻译不到位造成的一些问题。</p><p>但是仍然会有中间层方案在高UI交互场景下的性能问题，这部分就需要把处理逻辑放到C++/Swift/Kotlin编写的Polyglot模块解决。</p><p>站在纯粹客户端跨平台开发的角度，转译类方案老刘目前更推荐KMP。</p><p>Valdi可以作为一个有潜力的备选，等生态更加成熟后再重新考虑。</p><hr/><h2>6. 技术选型指南</h2><p>看了这么多技术栈，是不是更晕了？老刘把复杂的选型逻辑浓缩成一份<strong>实战决策指南</strong>，帮你快速拍板。</p><h3>6.1 核心推荐：Flutter (通用首选)</h3><p>对于 90% 的新启动 App 项目，<strong>Flutter 是当前版本的最优解</strong>。</p><ul><li><strong>性能强悍</strong><br/>自带 Impeller 渲染引擎，不依赖系统组件，体验无限接近原生。无论是复杂的动画还是高性能列表，都能轻松驾驭。</li><li><strong>效率极高</strong><br/>Hot Reload (热重载) 让改代码像刷新网页一样快。一套代码覆盖 Android、iOS、Web 甚至桌面端，研发成本降低 40% 以上。</li><li><strong>AI 友好</strong><br/>作为 Google 亲儿子，Cursor、Claude 等 AI 工具对 Dart/Flutter 的支持极为成熟，能自动生成高质量 UI 代码。</li></ul><p><strong>⚠️ 避坑提示</strong><br/>如果你的应用极度依赖原生比如有大量历史遗留的原生代码，或对包体积有苛刻要求 (&lt;10MB)，需谨慎评估。</p><h3>6.2 潜力观察：Kotlin Multiplatform (KMP)</h3><p>极度依赖原生的最佳选择。</p><ul><li><strong>核心定位</strong><br/><strong>逻辑共享，UI 原生</strong>。<br/>它不强求 UI 统一，而是让 Android 和 iOS 共享数据层、网络层和业务逻辑代码。</li><li><p><strong>适用场景</strong></p><ul><li>已经在原生层面积累了大量的UI组件和功能模块，可以逐步把业务逻辑切换到KMP。</li><li>应用强依赖系统底层能力 (蓝牙、NFC、深度硬件交互)，同时又希望保持跨平台的优势。</li></ul></li><li><strong>现状判断</strong><br/>技术理念先进，但第三方生态仍在爬坡期。<strong>2026 谨慎全量 All-in。</strong></li></ul><h3>6.3 谨慎评估需求：App + 小程序 ≠ 一套代码</h3><p>一个产品有App和小程序不代表他们的业务逻辑是完全一致的，小程序在产品定位上不应该是App的简化版。</p><ul><li><p><strong>最佳实践：App和小程序承担不同的产品职责</strong></p><ul><li><strong>App (Flutter/原生)</strong><br/>负责沉浸式体验、复杂交互、高粘性留存 (如阅读、创作、社交)。</li><li><strong>小程序 (原生/Uni-app)</strong><br/>负责营销裂变、即用即走、低成本获客 (如分享落地页、简单工具)。</li></ul></li><li><strong>决策依据</strong><br/>只有当功能重叠度 &gt; 80% 且交互极其简单 (如纯展示类新闻、简单电商) 时，才推荐使用 Uni-app/Taro 等方案同时生成 App 和小程序。</li></ul><h3>6.4 决策速查表</h3><table><thead><tr><th align="left">你的项目场景</th><th align="left">推荐技术栈</th><th align="left">理由</th></tr></thead><tbody><tr><td align="left"><strong>从 0 到 1 新项目</strong></td><td align="left"><strong>Flutter</strong></td><td align="left">效率与体验的最佳平衡点</td></tr><tr><td align="left"><strong>原生项目转型跨平台</strong></td><td align="left"><strong>Flutter</strong></td><td align="left">可以增量迁移，混合开发风险低</td></tr><tr><td align="left"><strong>重度依赖原生底层</strong></td><td align="left"><strong>KMP</strong></td><td align="left">风险低，渐进式重构</td></tr><tr><td align="left"><strong>App与小程序功能重叠</strong></td><td align="left"><strong>Uni-app</strong></td><td align="left">小程序支持好</td></tr><tr><td align="left"><strong>系统级工具</strong></td><td align="left"><strong>纯原生 (Swift/Kotlin)</strong></td><td align="left">无中间层损耗，完全掌控硬件</td></tr><tr><td align="left"><strong>团队 Web 背景</strong></td><td align="left"><strong>React Native</strong></td><td align="left">学习曲线平滑，社区资源丰富</td></tr></tbody></table><hr/><h2>7. 总结与建议</h2><p>写了这么多，老刘最后给你一个终极建议。</p><p><strong>2026年跨平台开发，记住这三个关键词：务实、聚焦、长期主义。</strong></p><h3>7.1 务实</h3><p>软件开发没有银弹。</p><p>Flutter性能好但包体积大，React Native动态性好但有桥接损耗，KMP接近原生但生态不成熟。</p><p><strong>选择技术的核心是：在当前约束条件下，哪个方案的收益最大。</strong></p><h3>7.2 聚焦</h3><p>没有项目需要超过2种跨平台框架同时使用。</p><p>同样也不推荐团队同时在多个不同的跨平台框架上投入时间和精力。</p><p><strong>建议：选定一个主力技术栈，最多再备一个备选方案。</strong></p><h3>7.3 长期主义</h3><p>真正决定项目生死的，是你选定技术栈之后做的那些事。</p><ul><li><strong>架构设计够不够清晰？</strong></li><li><strong>开发流程够不够规范？</strong></li><li><strong>代码规范够不够严格？</strong></li><li><strong>技术债务管理够不够及时？</strong></li></ul><p>选定技术栈不是终点，而是起点。</p><p>做好这些基础建设，才是项目能持续健康演进的根本。</p><p>否则，再好的技术栈也救不了你。</p><p>最后，希望这篇跨平台开发地图能帮你避开那些坑，找到最适合你的路。</p><blockquote><p>如果看到这里的同学对客户端开发或者Flutter开发感兴趣，欢迎联系老刘，我们互相学习。</p><p>点击免费领老刘整理的《Flutter开发手册》，覆盖90%应用开发场景。</p><p>可以作为Flutter学习的知识地图。</p><p><a href="https://link.segmentfault.com/?enc=M2Qh2Mi2%2BqBuOYII5ajAgQ%3D%3D.qs1qkYmWZLYK%2Fo0SX0MiA1Qgw3EH1eOfZpxvY9Q5jGTlt5I4r3xKIcyEgTIte9wEvpL8KdDpq5zGvio97VRYahCPBPPv3Evjx37yo2o2sYEUn7wpw2gDNGa6sJFuQjtCVwN5uboew8BRTmslrhHxueyWJQtopgnhHQaaR13jmazdQUfQ0qoGedzgYuw7lRhgWjTkJMIByyCtPTHwGT4ou5s18GTnW8irnyfFLtSJhSBK2EgIkq539xTYj82ze9drTB9g7warjxyZTi%2BiTexSpQ%3D%3D" rel="nofollow" target="_blank">覆盖90%开发场景的《Flutter开发手册》</a></p></blockquote>]]></description></item><item>    <title><![CDATA[中央音乐学院联合研究：视频自动配乐还卡点 Lab4AI ]]></title>    <link>https://segmentfault.com/a/1190000047556530</link>    <guid>https://segmentfault.com/a/1190000047556530</guid>    <pubDate>2026-01-21 19:09:45</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>中央音乐学院联合研究：视频自动配乐还卡点</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556533" alt="" title=""/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047556534" alt="" title="" loading="lazy"/></p><p>论文标题: <em>Video Echoed in Music: Semantic, Temporal, and Rhythmic Alignment for Video-to-Music Generation</em>  </p><p>作者团队: 中央音乐学院、北京大学、阿里巴巴等  </p><p>发布时间: 2025年11月12日</p><p>🔗 Github地址: <a href="https://link.segmentfault.com/?enc=lNdLuUvS29nK736M1BfNhw%3D%3D.bX3OjDBJVIM%2ByNf4kjcz6inZcazI%2BsLfeLOGNW6Jj%2BamV5kmITtoj8KvAWPqYSmv" rel="nofollow" target="_blank">https://vem-paper.github.io/VeM-page/</a>  <br/>🔗 Lab4AI链接: <a href="https://link.segmentfault.com/?enc=UCnY%2BWAORWwk79n8yts%2BEQ%3D%3D.tOHyzgB255M77o4VudcWn%2BM%2FCrJULRXHg7R1MMtdEoEJlcE0LkoNKTXCYouLb09%2FyeHnQZI%2BN0%2F%2FrRHPU3caSkPty4%2FcAOHbw3GsucprlBIj8Cr6mUdis9lsOHzOI%2Fpj8TOTBVZA6r%2FcRBE7kloS%2Bg%3D%3D" rel="nofollow" target="_blank">https://www.lab4ai.cn/paper/detail/reproductionPaper?utm_sour...</a></p><h4>✨ 研究背景:</h4><p>视频配乐要同时"贴"内容、跟段落、能卡点。但自动配乐常出现情绪不匹配、分镜节奏不同步、转场对不上鼓点，导致视听割裂。</p><h4>✨ 研究内容:</h4><p>论文提出<a href="https://link.segmentfault.com/?enc=yBAiiF0CspDMGrInnhUoRg%3D%3D.mckEu%2BIUz4rpp6LF4vVtVxLg9s%2B8OnHbw2Q00Ch152nxv9haNkTlwQiVLSnI51IscUQMqP78YodCENV0ZtA8hOuFeU%2Bso%2B0ojan%2FO%2F7joFZleFOIdnMHyR5fHe3PNhUCmgutBkY2zmk%2BLE0dVgpHKg%3D%3D" rel="nofollow" target="_blank">VeM</a>: 以<a href="https://link.segmentfault.com/?enc=I1OEyduIVHy%2FNiI00sZRKQ%3D%3D.clWmODv4dvWUtM5LravRHgmNbN7uB4QIrfgTH8gBOEv1joQx008JeXLrBhtvygWB6wjqwjc%2FHf5d5gMIk88PhTXxt%2BukJXlDtnSI3aYRisFaVZ18jNbzw%2BDn22ghYTnQ%2BVxNPibiEnpKSAKzn27eOg%3D%3D" rel="nofollow" target="_blank">潜空间音乐扩散模型</a>为主干，把视频先做"分层解析"再作为条件输入生成过程。</p><h4>✨ 具体包括:</h4><ul><li><strong>分层视频解析</strong>: 同时提取<a href="https://link.segmentfault.com/?enc=Z4FwyfTLMaGERUlUzKD2Bw%3D%3D.gfJ3Fg8UBkxHzre4B7RBCfKWCPnkA6f2VPmTyk4ePS%2FodIVzYsZBKVaVmC8ETDY9J1ZnrOm%2Ft7nlx1kHINKAb7esVeeIGZBkz9k08Mkazy6qzGMQrYt0Y3MxR4YpltVmYsQOMXIa4HjJ9MUd51eOcQ%3D%3D" rel="nofollow" target="_blank">全局语义/情绪</a>、分镜级语义与时长结构、帧级转场时间点，把视频从"一个整体特征"变成可控的结构化条件。</li><li><strong>分镜引导对齐</strong>: 在扩散网络中用分镜条件做<a href="https://link.segmentfault.com/?enc=ZRl%2FhMFh%2Fbuj0Mst6y%2FuSg%3D%3D.xK4H49siJZeiljnX%2FYo7HmmibrzpJp6EXgSWCmtRoFzbXkuOQh2tgn1oeMcBOUIGSHVWq2HzbwqwJsJhahUnxJkgTu%2FkxejbzDVnnw0%2F%2FBTiJOZqP3bwkfM8p%2FBKwNTsckEOCiRsgxwaJm1rh0nI%2FQ%3D%3D" rel="nofollow" target="_blank">交叉注意力</a>，引导音乐跟随镜头段落推进，并通过位置/时长编码保持时间同步，使音乐的主题与段落变化更贴视频。</li><li><strong>转场—节拍精细同步</strong>: 将<a href="https://link.segmentfault.com/?enc=HmQH1Y9uqAQc41TcsjxmCQ%3D%3D.l4adUm4mdJwTzK4Ef7jjhdteng8WMxICjDlUDDvk7yqke8o2fIp0A4Q4eE%2FsyLM56PCxQCByqE7OKwV%2BdTbAiqWOA5l6QySqjKLdwzgPdO9MJB6ms18tyK1NiWHrRo8OseRNtvPdUdi4AJklUKEaow%3D%3D" rel="nofollow" target="_blank">转场序列</a>与节拍信息对齐，构造节奏约束特征，再用适配器注入扩散过程，强化"转场落在节拍边界附近"的<a href="https://link.segmentfault.com/?enc=2NFTHiNRAYrK5J4%2B0R64qQ%3D%3D.dU7yBCrI8Px%2F2UMb1TSvWFQakbhRzBaQ5BUcyXEZlCqkDi31rXKguZ8WS3hQYDTPqqIKXNYrqcS%2BWJSoqy1OXG6XdIi9jnUGL23wjPd%2B9mSqwJ6U7xi4bNDa%2FTncSWk%2F9qFWPSXzK3%2FNlKGsDywkcQ%3D%3D" rel="nofollow" target="_blank">卡点效果</a>。</li></ul>]]></description></item><item>    <title><![CDATA[DeepSeek提出mHC，改造何恺明残差连接 Lab4AI ]]></title>    <link>https://segmentfault.com/a/1190000047556602</link>    <guid>https://segmentfault.com/a/1190000047556602</guid>    <pubDate>2026-01-21 19:08:44</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>DeepSeek提出mHC，改造何恺明残差连接</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556605" alt=" " title=" "/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556606" alt=" " title=" " loading="lazy"/></p><p><a href="https://link.segmentfault.com/?enc=cg3buSAcy9ZoeynYB%2BRVog%3D%3D.CUytO6p%2F5DTOQ0QJBltxl5c%2FXiq21JMP8aGLsMKo2EoSC15rMz3u4p9X1xlYrqrB7Cc1yhq1q1FMntnfZ%2BVmiGqG00jdRWmkpo5IfQJQ86qbTer5TFAWU9Lzw3ur8253NhBnEmIesczSW7PgHdPi5mzBv4H%2FuCqZfo0Hh2M2cpI%3D" rel="nofollow" target="_blank">大模型实验室</a>Lab4AI论文阅读</p><h3>✔️研究背景</h3><p>深度学习中，<a href="https://link.segmentfault.com/?enc=HDnBfRZfvwpBVwibyuvvVw%3D%3D.YShC%2Fq6e585mVVGBjZ3okoig5m%2FF01f1EBrINsGgOM4aO5fc8ezA4Rfmhq%2F9MAKHJaEcIaRkV%2B28pamrlBgY%2B%2Bpldq0PFgibld0AEoXnuUGgz9bSJWiunrqM176S1WRlnOjdQqNYM56G37ct8JALHBINUcB%2BntixEIsYKJoW2Hc%3D" rel="nofollow" target="_blank">残差连接</a> 是 <a href="https://link.segmentfault.com/?enc=lb0kK7CWpCQIGOvNbAhqvg%3D%3D.mJ%2FXO%2F1DxorFKKFd2LZrNyE2p8yaIhOJ7EfB%2F4BDFMd%2Bk%2FoQYcY2P%2BTnrB4MKwMHSGBNBTJiFn3agGD4JE0SUPSFPxRa%2B%2F0hTWHPKA6PXKKv0WWmhySlgjt1xBi73cgczCCI8UgJn%2Fs66bkNCQ%2Boaa9E426nkIy3lEwYIlDVNK0%3D" rel="nofollow" target="_blank">ResNet</a>、<a href="https://link.segmentfault.com/?enc=bGqi94bz%2FIN54DHH84ou8w%3D%3D.XtebzqzrEtKeePwv5Z7SmAtkI6WatAPgIhj6%2BR0rgTeaYNx5rTPIGltEo1Yvrl%2Fd8cm2N1EKU4HxcVMfFxUwN3MOHNb29pUpOZHBEl4%2FaRFRGbuC1G6wLWa8rBKyGzl1uO6LCGYRj3oQCRBKUj1AgIeBupsrKRkNOeP00wRxOiw%3D" rel="nofollow" target="_blank">Transformer</a> 等架构（含 LLM）的基础，其恒等映射特性保障了大规模训练的稳定性与效率。Hyper-Connections（HC）通过扩展残差流宽度、多样化连接模式提升模型性能，但因连接无约束，破坏了恒等映射特性，导致训练不稳定、扩展性受限，且存在显著内存访问与通信开销，这一问题限制了 HC 在大规模训练中的实际应用，形成研究缺口。</p><h3>✔️研究目的</h3><p>本文解决 <a href="https://link.segmentfault.com/?enc=ZPER6R9OHieXlZZmklOA0g%3D%3D.rV0C1IyXma7UTWEtPMePAoh2y2LvobfiK91eZQsut7p%2Bd1jVwGpFUtuITLUByw4Fj%2BiQq57FW8gP724JFllMdE0fJx8di%2BLKYjpI9dkgS0dOCBd7LxkQQiYK1fAjAKiP1kSs2lYq2CBfIb1D7PKlSoJqSwWtfdLeeIKQ4QmwZ%2FI%3D" rel="nofollow" target="_blank">HC 架构</a>存在的训练不稳定性、扩展性差及系统开销大的核心问题，同时保留 HC 扩展<a href="https://link.segmentfault.com/?enc=tYnAL52hvYY%2FYzh94eY48Q%3D%3D.anF45L5i7sDQytLSsshd75fnfmzUY6ry11usNSI1BKnHk415OC80Uc7pCv7OvZY5E7hA7GJwUGtenpAD%2BhN7PYuZz2QdARZWwCpjDDVaUR8SCC4eEn%2FKduz4MFx3b5sMPLWGTKVNlQo2ZlbHhZQ60ZX9kysGRqrt8F2C1b6dakA%3D" rel="nofollow" target="_blank">残差连接</a>带来的性能优势，提出一种兼顾稳定性、扩展性与效率的通用残差连接框架，支撑大规模深度学习模型（尤其是 LLM）的高效训练。</p><h3>✔️核心贡献</h3><p>提出 Manifold-Constrained Hyper-Connections（mHC）框架，通过将 HC 的残差映射投影到双随机矩阵流形（Birkhoff 多面体），恢复恒等映射特性，保障信号传播稳定性；<br/>对输入 / 输出映射施加非负约束，避免信号抵消，同时通过核融合、选择性重计算、DualPipe 通信重叠等基础设施优化，降低系统开销；<br/>实证验证 mHC 在大规模预训练中的有效性，为深度网络拓扑架构设计提供新视角，推动基础模型的演进。</p><h3>✔️研究方法</h3><ul><li>1）核心方法论：采用 Sinkhorn-Knopp 算法将<a href="https://link.segmentfault.com/?enc=L3niDdYjvie6mRjXlbh8%2Bw%3D%3D.K2HuWA5uddM5EQAo73QgsV5yKJ4wBejdWW92UPuFmXnfxiAOFddzpnmB74yIJcIhaXHLEYajIO8kQWqddU9%2B9bbujCVaBkJrBINvHomm%2Bn7L3%2F5873Q2vX7JIH2MlveqgGBELqPi86Q1VfbcnLyGVSI6IfjFkUVRcs%2ByEy2Kk7A%3D" rel="nofollow" target="_blank">残差映射</a> H_res 熵投影到双随机矩阵流形，对 H_pre 和 H_post 用 Sigmoid 函数施加非负约束；</li><li>2）基础设施优化：基于 TileLang 实现混合精度核融合，通过选择性重计算降低内存占用，扩展 DualPipe 调度实现通信与计算重叠；</li><li>3）实验设计：在3B至27B参数的语言模型上进行预训练实验，对比基线、HC和mHC的稳定性、下游任务性能及缩放特性。</li></ul><h3>✔️研究结果</h3><ul><li>1）稳定性提升：mHC在27B模型训练中消除HC的损失突增现象，梯度范数保持稳定（对比HC的3000倍信号增益峰值，mHC最大增益仅1.6倍）。</li><li>2）性能优势：在推理、阅读理解、数学问题解决等任务上全面优于基线和 HC，27B 模型在 BBH 上较 HC 提升 2.1%；</li><li>3）扩展性与效率：支持模型规模与训练数据量的高效扩展，n=4 时仅增加 6.7% 时间开销，显著降低内存访问与通信成本。</li></ul>]]></description></item><item>    <title><![CDATA[有哪些原因会让爬虫代理IP失效？ 流冠代理IP ]]></title>    <link>https://segmentfault.com/a/1190000047556612</link>    <guid>https://segmentfault.com/a/1190000047556612</guid>    <pubDate>2026-01-21 19:08:05</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>爬虫代理IP是爬虫技术中很常用的一种方法，方便于隐藏爬虫的真实IP地址，防止被目标网站识别并封锁。可是，在实际应用中，爬虫代理IP可能会因为很多原因而失效。下面是一些很常见的让爬虫IP代理失效的因素：</p><p><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdnHOg" alt="" title=""/></p><p>一、代理服务器问题</p><p>代理服务器故障：</p><p>代理服务器可能因硬件故障、软件错误或网络问题而暂时或永久失效。</p><p>代理服务器负载过高：</p><p>当代理服务器处理的请求量超过其处理能力时，可能会导致请求处理延迟增加，甚至请求被拒绝。</p><p>代理服务器被封锁：</p><p>目标网站可能已经识别并封锁了某些代理服务器的IP地址，导致通过这些代理服务器发出的请求被直接拒绝。</p><p>二、网络环境问题</p><p>网络延迟与不稳定：</p><p>网络延迟或不稳定可能导致请求无法及时到达目标服务器，或响应无法及时返回给爬虫。</p><p>网络配置错误：</p><p>爬虫或代理服务器的网络配置错误可能导致连接问题，如错误的端口号、IP地址或路由设置。</p><p>三、目标网站策略</p><p>动态IP封锁：</p><p>目标网站可能采用动态IP封锁策略，根据请求的特征（如请求频率、请求头信息等）来识别并封锁代理IP。</p><p><img width="723" height="517" referrerpolicy="no-referrer" src="/img/bVdnHOh" alt="" title="" loading="lazy"/></p><p>验证码验证：</p><p>当目标网站检测到异常请求模式时，可能会要求用户通过验证码验证来确认身份，从而阻止爬虫继续访问。</p><p>用户行为分析：</p><p>目标网站可能通过用户行为分析（如点击模式、停留时间等）来识别爬虫，并采取相应的封锁措施。</p><p>四、爬虫自身问题</p><p>请求频率过高：</p><p>如果爬虫发送的请求频率过高，可能会触发目标网站的防爬虫机制，导致代理IP被封锁。</p><p>请求头信息不当：</p><p>如果爬虫在请求头中包含了与目标网站不兼容的信息（如错误的User-Agent、Referer等），可能会导致请求被拒绝。</p><p>爬虫策略不当：</p><p>爬虫的策略（如访问顺序、访问间隔等）如果设计不当，也可能导致代理IP被封锁。</p><p>五、其他因素</p><p>代理IP质量：</p><p>低质量的代理IP（如共享IP、频繁更换的IP等）可能更容易被封锁。</p><p>第三方服务限制：</p><p>如果爬虫使用了第三方提供的代理服务，这些服务可能有限制（如请求次数、请求速度等），超过限制可能导致代理失效。</p><p>爬虫代理IP失效可能由很多原因引起，为了防止这种情况，爬虫开发者需要密切关注代理服务器的状态、网络环境的变化、目标网站的策略调整以及爬虫自身的行为模式，并采取相应的措施来优化爬虫策略和增加代理IP的有效性。</p>]]></description></item><item>    <title><![CDATA[观测云接入 Zabbix 数据最佳实践 观测云 ]]></title>    <link>https://segmentfault.com/a/1190000047556623</link>    <guid>https://segmentfault.com/a/1190000047556623</guid>    <pubDate>2026-01-21 19:07:35</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>Zabbix 介绍</h2><p>Zabbix 是一个开源的企业级监控解决方案，它可以监控各种网络参数，服务器健康状态，应用程序性能等，并提供灵活的告警机制和丰富的报表功能。</p><p><strong>1、Zabbix Server</strong></p><ul><li>核心组件，负责接收和处理所有监控数据，生成报警和报表。</li><li>需要一个数据库来存储所有配置和监控数据。</li></ul><p><strong>2、Zabbix Agent</strong></p><ul><li>部署在被监控的设备上，负责收集本地资源和应用数据，并发送给 Zabbix Server。</li><li>支持多种操作系统，包括 Linux、Windows 和 Unix。</li><li>其中 Agent 分为 Zabbix Agent 和 Zabbix Agent 2，后者是增强版 Agent，支持插件，适合大规模监控。</li></ul><p><strong>3、Zabbix Proxy</strong></p><ul><li>用于分担 Zabbix Server 的负载，尤其适用于大规模分布式监控。</li><li>可以在远程网络中收集数据并转发给 Zabbix Server。</li></ul><p><strong>4、Zabbix Web Interface</strong></p><ul><li>基于 PHP 的 Web 界面，用于配置、管理和查看监控数据。</li><li>提供用户管理、权限控制、仪表盘和报表等功能。</li></ul><p><strong>5、数据库</strong></p><ul><li>存储所有的配置、监控数据、历史记录等。</li><li>支持多种数据库，如 MySQL、PostgreSQL、Oracle、SQLite。</li></ul><h2>观测云</h2><p>观测云是一款专为 IT 工程师打造的全链路可观测产品，它集成了基础设施监控、应用程序性能监控和日志管理，为整个技术栈提供实时可观察性。这款产品能够帮助工程师全面了解端到端的用户体验追踪，了解应用内函数的每一次调用，以及全面监控云时代的基础设施。此外，观测云还具备快速发现系统安全风险的能力，为数字化时代提供安全保障。</p><h3>部署 DataKit</h3><p>DataKit 是一个开源的、跨平台的数据收集和监控工具，由观测云开发并维护。它旨在帮助用户收集、处理和分析各种数据源，如日志、指标和事件，以便进行有效的监控和故障排查。DataKit 支持多种数据输入和输出格式，可以轻松集成到现有的监控系统中。（注意，请安装完整版 DataKit，Lite 版本 DataKit 没有 Zabbix 相关采集器。）</p><p>登录<a href="https://link.segmentfault.com/?enc=9Fm%2B1HbnGKgilHXrLngUSg%3D%3D.54TzyZKje%2BzBJ%2B3M70fkvmGfyZoXoWoCsXzglenkh10%3D" rel="nofollow" target="_blank">观测云控制台</a>，在「集成」 - 「DataKit」选择对应安装方式。这里使用主机方式安装。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556625" alt="图片" title="图片"/></p><p>复制一键安装命令，登陆到目标服务器执行该命令即可实现一键安装。</p><p>执行 <code>datakit monitor</code> 命令查看 DataKit 运行状态。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556626" alt="图片" title="图片" loading="lazy"/></p><h2>指标数据采集</h2><h3>Zabbix API 方式（zabbix &gt;= 5.0)</h3><h4>DataKit 方式</h4><p>1、配置 pythond 配置文件</p><p>进入 DataKit 的配置文件目录 <code>conf.d</code>，进入 pythond 目录，复制 <code>pythond.conf.sample</code> 为 <code>pythond.conf</code>, 修改如下配置：</p><pre><code>[[inputs.pythond]]
  # Python input name
  name = 'zabbix_collect'  # required

  # System environments to run Python
  #envs = ['LD_LIBRARY_PATH=/path/to/lib:$LD_LIBRARY_PATH',]
  envs = ['ZABBIX_HOST=http://127.0.0.1/zabbix', 'ZABBIX_USER=Admin', 'ZABBIX_PASSWD=zabbix', 'ZABBIX_VERSION=7.0', 'COLLECT_TYPE=api']

  # Python path(recomment abstract Python path)
  cmd = "python3" # required. python3 is recommended.

  # Python scripts relative path
  dirs = ["zabbix"]</code></pre><p>其中 <code>ZABBIX_HOST</code>，<code>ZABBIX_USER</code>，<code>ZABBIX_PASSWD</code>，<code>ZABBIX_VERSION</code> 填写实际 Zabbix 的地址用户名密码和版本。</p><p>保存并退出。</p><p>2、复制脚本</p><p>进入 DataKit 目录，进入 <code>python.d</code> 目录，创建 zabbix 目录，点击下方链接下载脚本到 zabbix 目录下：</p><p><a href="https://link.segmentfault.com/?enc=TVaf3GjTuE3gwKB2qGo%2FWA%3D%3D.8uDQiMGBF%2B0JLr3R5ScWVTzAHi%2F08F7B%2BtVJX%2BgdgBGNyD4yqSc2Olat9Hkw39sYm9WNNjzypuHjwFvVD3QRLdR5jgYqkIUSs3VCnvuwQpk%3D" rel="nofollow" target="_blank">https://static.guance.com/integrations/zabbix/zabbix-collecto...</a></p><p>3、重启 DataKit</p><pre><code>datakit service -R</code></pre><p>4、检查采集任务，出现 zabbix_collect 任务则说明采集任务开启成功</p><pre><code>datakit monitor</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556627" alt="图片" title="图片" loading="lazy"/></p><h4>Func 方式</h4><p>1、安装采集脚本</p><p>登录 Func，点击「脚本市场」，选择预装脚本市场，点击管理按钮，进入预装脚本市场的脚本列表页。在过滤搜索框中输入 ，过滤出 zabbix 采集脚本。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556628" alt="图片" title="图片" loading="lazy"/></p><p>点击安装按钮，并在弹出的确认框点击确认按钮。点击确认后，在弹出的部署对话框中输入 zabbix 的地址，用户名，密码，以及版本号。确认信息无误后，点击部署启动脚本，即可完成脚本的部署以及采集任务的创建。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556629" alt="图片" title="图片" loading="lazy"/></p><p>2、查看采集结果</p><p>登录观测云，点击「指标」 - 「指标管理」，查找 zabbix 指标，看是否采集到。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556630" alt="图片" title="图片" loading="lazy"/></p><h3>Streaming 方式（zabbix &gt;= 6.4）</h3><p>该方式类似于 Prometheus 的 Remote Write，由 zabbix server 主动将数据打给 DataKit，有较高的时效性。</p><h4>HTTP Server</h4><h5>DataKit 方式</h5><p>1、配置 pythond 配置文件</p><p>进入 DataKit 的配置文件目录 <code>conf.d</code>，进入 <code>python.d</code> 目录，复制 <code>pythond.conf.sample</code> 为 <code>pythond.conf</code>，修改如下配置：</p><pre><code>[[inputs.pythond]]
  # Python input name
  name = 'zabbix_collect'  # required

  # System environments to run Python
  #envs = ['LD_LIBRARY_PATH=/path/to/lib:$LD_LIBRARY_PATH',]
  envs = ['ZABBIX_HOST=http://127.0.0.1/zabbix', 'ZABBIX_USER=Admin', 'ZABBIX_PASSWD=zabbix', 'ZABBIX_VERSION=7.0', 'COLLECT_TYPE=stream', 'STREAM_LISTENER_PORT=8000']

  # Python path(recomment abstract Python path)
  cmd = "python3" # required. python3 is recommended.

  # Python scripts relative path
  dirs = ["zabbix"]</code></pre><p>其中 <code>ZABBIX_HOST</code>，<code>ZABBIX_USER</code>，<code>ZABBIX_PASSWD</code>，<code>ZABBIX_VERSION</code> 填写实际 Zabbix 的地址用户名密码和版本。</p><p>注意，COLLECT_TYPE 必须为 stream， 可根据需要调整 STREAM_LISTENER_PORT 的值。</p><p>保存并退出。</p><p>2、复制脚本</p><p>进入 DataKit 目录，进入 pythond 目录，创建 zabbix 目录，点击下方链接下载脚本到 zabbix 目录下：</p><p><a href="https://link.segmentfault.com/?enc=t0wClCdPoxvw6OphlhWKHA%3D%3D.%2FBQm7OvsV8IURGszbn7Gfq%2BF7KDYc5rdRoifnabECTj5Z6lkqdNW9cWntIQBiTr5qmjBA6%2B9CNieoTPPPJfkhzZaU7a6MBaN3c1bp24nESk%3D" rel="nofollow" target="_blank">https://static.guance.com/integrations/zabbix/zabbix-collecto...</a></p><p>3、重启 DataKit</p><pre><code>datakit service -R</code></pre><p>4、检查采集任务，出现 zabbix_collect 任务则说明采集任务开启成功</p><pre><code>datakit monitor</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556631" alt="图片" title="图片" loading="lazy"/></p><p>5、创建 Zabbix 连接器</p><p>登录 Zabbix，点击管理 -&gt; 常规 -&gt; 连接器，点击创建连接器，URL处输入 DataKit 的地址以及 <code>zabbix stream</code> 的监听端口（默认8000），信息类型选择数字和浮点数，点击添加。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556632" alt="图片" title="图片" loading="lazy"/></p><p>6、修改 <code>zabbix_server.conf</code>，修改 <code>StartConnectors</code> 为10，保存并重启 <code>zabbix-server</code> 服务</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556633" alt="图片" title="图片" loading="lazy"/></p><p>7、验证指标采集结果</p><h5>Func 方式</h5><p>1、安装采集脚本</p><p>登录 Func，点击「脚本市场」，选择预装脚本市场，点击管理按钮，进入预装脚本市场的脚本列表页。在过滤搜索框中输入zabbix Stream ，过滤出zabbix Stream采集脚本。点击安装即可。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556634" alt="图片" title="图片" loading="lazy"/></p><p>2、创建URL</p><p>登录 Func，点击「管理」 - 「同步 API」（建议使用异步API）- 「新建」， 执行一栏选择刚导入脚本中的 <code>Zabbix Receiver</code> 方法，在参数指定中配置采集任务相关的配置，需要指定 <code>zabbix_host</code>，<code>zabbix_user</code>，<code>zabbix_passwd</code>，<code>zabbix_version</code> 为实际的值，<code>base64</code> 为 Zabbix 入参，此处填 <code>INPUT_BY_CALLER</code>，点击保存，并复制 url。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556635" alt="图片" title="图片" loading="lazy"/></p><p>3、创建 Zabbix 连接器</p><p>登录 Zabbix， 点击管理 -&gt; 常规 -&gt; 连接器，点击创建连接器，URL 处输入上一步创建的 url，信息类型选择数字和浮点数，点击添加。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556636" alt="图片" title="图片" loading="lazy"/></p><p>4、修改 <code>zabbix_server.conf</code>，修改 <code>StartConnectors</code> 为10，保存并重启 <code>zabbix-server</code> 服务</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556637" alt="图片" title="图片" loading="lazy"/></p><p>5、验证指标采集结果</p><h4>Kafka</h4><p>该方式原理同 HTTP 方式消费指标数据，区别在于该方法引入了 Kafka 组件，需部署一个 HTTP 服务用于接收 Zabbix 的 stream 输出并将消息发送到 Kafka 中，详见<a href="https://link.segmentfault.com/?enc=2%2BetUtexr7w%2FrSEvLkLRIQ%3D%3D.LiAjpqI7fMufCZOykP6WjTBZOnUfDCOELlZBIjlqmslgJDHpvRjjM3AE9yU1t%2FnnUBbFqQOGQnm1FLW4G8JeyQ%3D%3D" rel="nofollow" target="_blank">https://git.zabbix.com/projects/ZT/repos/kafka-connector/browse</a>，再由消费者订阅 Kafka，进行数据消费。</p><h3>指标治理</h3><h4>Zabbix 指标数据结构</h4><p>Zabbix 以主机为维度统计指标和告警。所以所有的指标必然包含主机信息。主机往往绑定一个或多个接口。</p><p>Zabbix 的指标（<code>item key</code>） 的形式为 <code>key[param1,param2,param3]</code>。其中 <code>params</code> 分为静态值和变量两种。</p><p>如 <code>vfs.fs.size[{#FSNAME},pused]</code>。其中 <code>key</code> 为 <code>vfs.fs.size</code>，<code>{#FSNAME}</code> 是动态参数，指实际文件系统名，<code>pused</code> 为静态参数，指使用量。</p><p>上述采集方式中 <code>zabbix api</code>，<code>Streaming</code>，<code>Zabbix Agent 2</code> 三种采集方式均默认使用该规则进行指标映射。</p><h4>建议的指标治理规则</h4><p>由于 Zabbix 的数据结构跟观测云存在较大差异，为方便指标的使用与管理，结合实际企业用户的部署经验，对于 API 和 Streaming 的采集方式，我们建议 Zabbix 指标数据上传到观测云时按如下规则进行转换：</p><ul><li>measurement (指标集)：<code>zabbix key</code> 第一个 '.' 前的内容。</li><li>fields (指标)：<code>zabbix key</code> + 所有静态参数。如 <code>vfs.fs.size[{#FSNAME},pused]</code>，就会变成 <code>vfs.fs.size.pused</code>，<code>system.cpu.load[all,avg1]</code>，就会变成<code>system.cpu.load.all.avg1</code>。</li><li>tags (标签)：<code>zabbix item key</code> 中的所有动态参数小写。同时会添加 <code>host</code>，<code>ip</code> 以及 <code>item</code> 的 <code>tag</code>s。如：<code>vfs.fs.size[{#FSNAME},pused]</code> 的 <code>tag</code> 为 <code>fsname</code>。</li></ul><p>Example：</p><table><thead><tr><th>Zabbix item key</th><th>measurement</th><th>Field</th><th>tags</th></tr></thead><tbody><tr><td>vfs.dev.queue_size[{#DEVNAME}]</td><td>vfs</td><td>vfs.dev.queue_size</td><td>devname</td></tr><tr><td>vfs.dev.read.await[{#DEVNAME}]</td><td>vfs</td><td>vfs.dev.read.await</td><td>devname</td></tr><tr><td>vfs.dev.read.rate[{#DEVNAME}]</td><td>vfs</td><td>vfs.dev.read.rate</td><td>devname</td></tr><tr><td>vfs.file.contents[/sys/block/{#DEVNAME}/stat]</td><td>vfs</td><td>vfs.file.contents._sys_blck__stat</td><td>devname</td></tr><tr><td>vfs.file.contents["/sys/class/net/{#IFNAME}/type"]</td><td>vfs</td><td>vfs.file.contents._sys_class_net__type</td><td>ifname</td></tr><tr><td>vfs.fs.inode[{#FSNAME},pfree]</td><td>vfs</td><td>vfs.fs.inode.pfree</td><td>fsname</td></tr><tr><td>vfs.fs.size[{#FSNAME},pused]</td><td>vfs</td><td>vfs.fs.size.pused</td><td>fsname</td></tr><tr><td>net.if.in["{#IFNAME}",dropped]</td><td>vfs</td><td>net.if.in.dropped</td><td>ifname</td></tr><tr><td>net.if.in["{#IFNAME}"]</td><td>vfs</td><td>net.if.in</td><td>ifname</td></tr></tbody></table><h4>使用 Pipeline 的 reference table 实现自定义 Tag</h4><p>场景：对于已有 CMDB 的客户，希望将主机的一些字段富足到指标 Tag 中。如应用、负责人信息等。</p><p>方式：使用 Pipeline 的 refertable 功能。</p><p>具体步骤：</p><p>1、使用 Func 创建一个脚本用于组装 reference  table 数据，并发布。数据结构类似于：</p><pre><code>{
"table_name": "zabbix-refer-table",
"column_name": ["itemid", "host", "ip", "itemkey"],
"column_type": ["string", "string", "string", "string"],
"row_data": [["1001", "host-1", "10.0.0.1", "vfs.fs.size"], 
    ["1002", "host-2", "10.0.0.2", "vfs.fs.size.pused"], 
    ["1003", "host-3", "10.0.0.3", "vfs.fs.size.pfree"]]
}</code></pre><p>更多 reference table 用法，可参考：<a href="https://link.segmentfault.com/?enc=aVIM%2Bgu%2BKB1C4NkYqXThzA%3D%3D.%2FZYY8zQjQvTSIZnMWv3%2BVZX857PsMn1QKNVbfNgpPNmVI%2Bs%2B%2FSImHnC7UhQkLEPM%2BCg6zpZD3sgh3EYlN%2B2bhQ%3D%3D" rel="nofollow" target="_blank">https://docs.guance.com/datakit/datakit-refer-table/</a></p><p>2、创建同步 API</p><p>登录 Func，点击「管理」 - 「同步 API」，点击 新建，在添加同步 API 对话框执行一栏中选择 zabbix-reference-table 获取脚本，点击确定保存脚本，并点击示例，获取请求 API。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556638" alt="图片" title="图片" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556639" alt="图片" title="图片" loading="lazy"/></p><p>3、编辑 DataKit 的配置文件</p><p>登录 DataKit 所在服务器（容器部署DataKit 参考官方文档），进入 DataKit 配置目录 <code>/user/local/datakit/conf.d</code>，编辑 <code>datakit.conf</code> 文件，修改 <code>[pipeline]</code> 选项下的 <code>refer_table_url</code> 的值为上一步复制的 Func 接口地址。DataKit 会将 refertable 数据预先加载到本地的 sqllite 中，可以根据 refer table 大小灵活选择是否使用内存模式的 sqllite。保存后重启 DataKit 生效。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556640" alt="图片" title="图片" loading="lazy"/></p><p>4、编辑 Pipeline</p><p>登录观测云，点击「管理」 - 「Pipelines」- 「新建 Pipeline」，这里给到一个参考 Pipeline，可根据实际业务情况和 refertable 数据结构灵活调整。</p><p>5、查看指标 Tag</p><h3>超大数据量采集优化策略</h3><ul><li>对于 Export Directory 方式，可以增加独立的高速 SSD 磁盘，增加单独的 zabbix server 用于数据导出（由于需要访问 zabbix API 和数据库，DataKit 采集 ExportDirectory 会比较占用 zabbix 资源）。调低 ExportFileSize 大小。</li><li>API 采集方式，可以通过分页查询，减少查询关联表，多线程查询等方式。</li><li>HTTP stream 方式，可以引入队列进行异步消费或使用异步方法。支持采样收集等方式。</li><li>指标治理应先将映射关系生成后存入缓存或内存中，方便快速匹配。为减少 redis 读写压力可以考虑分片缓存或缓存压缩等方法。</li></ul><h3>各采集方式对比</h3><table><thead><tr><th>采集方式</th><th>采集原理</th><th>优势</th><th>劣势</th></tr></thead><tbody><tr><td>Zabbix API</td><td>func/datakit使用python代码通过zabbix api获取指标数据。进行指标治理和映射后上传到观测云。</td><td>可分布式采集，采集过程高可用便于灵活调整采集所需资源。便于指标的灵活治理和映射</td><td>时效性不高，最大时延可达1minzabbix到func区间数据无法压缩，对该区间网路压力较大。通常需要在func维护采集代码，对采集代码质量要求较高，否则在进行大数据量采集时速度较慢导致时效变差或丢失数据，严重时会影响zabbix性能。</td></tr><tr><td>Streaming</td><td>与zabbix建立网络长连接（HTTP server/Kafka）消费zabbix产生的history和event数据</td><td>时效性高可分布式采集，采集过程高可用便于灵活调整采集所需资源。便于指标的灵活治理和映射</td><td>zabbix到func区间数据无法压缩，对该区间网路压力较大。</td></tr><tr><td>Zabbix 转 Prometheus</td><td>部署独立服务通过调用zabbix api将zabbix指标数据暴露成Prometheus metric接口供datakit采集</td><td>集成简单，可以使用datakit现有能力。</td><td>需要维护独立的转换服务。转换服务与zabbix间网络转发无压缩，对网络压力较大。无法灵活进行指标治理和映射。</td></tr></tbody></table><h2>总结</h2><p>监控数据的集成是一个复杂的综合性工作，本文所展示方案所适用场景需相关运维工程师根据实际情况进行调整。</p>]]></description></item><item>    <title><![CDATA[《JS与Python浏览器互操作技术全解》 程序员阿伟 ]]></title>    <link>https://segmentfault.com/a/1190000047556666</link>    <guid>https://segmentfault.com/a/1190000047556666</guid>    <pubDate>2026-01-21 19:06:51</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>当Python的科学计算与JavaScript的前端交互禀赋在浏览器环境中实现无界交融，一种颠覆传统开发逻辑的协同范式正悄然重塑Web开发的底层逻辑。这种无需后端中转、摆脱环境依赖的直接互操作，绝非简单的语法移植或功能拼接，而是基于运行时深度耦合的能力重构。在长期的探索中逐渐发现，浏览器内跨语言协作的核心价值，在于打破两种语言固有的生态壁垒，让数据流转与功能调用脱离接口协议的束缚，形成原生级的协同闭环。无论是需要前端承载复杂数据建模的可视化应用，还是依赖密集计算的交互式工具，这种互操作模式都能将Python在数据分析、机器学习领域的生态优势，与JavaScript在DOM操作、用户交互上的灵活性无缝衔接，构建出更轻量化、高效率的开发路径。这种变革背后，是对Web开发本质的重新认知——前端不再仅仅是界面呈现的载体，而是能够整合多语言能力的综合计算平台，让前端开发者无需切换开发环境即可调用全量Python工具链，同时为数据科学家提供了将模型与可视化成果直接嵌入网页的便捷途径，实现了技术能力的双向赋能与价值放大。在实际体验中，这种协同模式带来的不仅是开发效率的提升，更是思维方式的转变，让跨语言协作从“按需适配”升级为“原生共生”，为Web应用的功能边界与体验深度开辟了全新可能。</p><p>浏览器内JS与Python互操作的底层实现，其核心逻辑在于通过字节码转译技术构建共享执行空间，彻底摆脱了传统跨进程通信的性能瓶颈与复杂度。这种基于WebAssembly的沙箱化运行环境，能够让Python解释器在浏览器中原生启动，同时建立与JavaScript引擎的直接通信链路，实现两种语言的内存级交互。双向调用的实现并非依赖标准化的接口定义，而是通过构建动态适配层，完成类型系统的隐式转换与函数签名的智能映射，让不同语言的函数能够像原生函数一样被直接调用。在实践探索中发现，这种通信机制支持同步与异步两种调用模式，同步调用适用于轻量级计算场景，能够确保数据实时反馈，满足界面交互的即时性需求；异步调用则通过事件循环的协同调度，将Python的密集计算任务分流至后台，避免阻塞JavaScript的前端渲染进程，保障界面的流畅性。更具价值的是，借助Web Worker的并行处理能力，可以将Python的计算任务分配至独立的线程中，实现两种语言的并行执行，既充分发挥了Python在数据处理、模型计算上的效率优势，又保留了JavaScript对前端界面的精准控制。这种底层架构的创新，让跨语言调用的延迟降至微秒级，为复杂场景的应用提供了坚实的技术支撑。在实际测试中，即便是处理大规模数据集的转换与分析，也能实现无感知的实时响应，这种原生级的协同体验，是传统跨语言方案难以企及的。</p><p>环境适配是浏览器内JS与Python互操作落地的关键环节，其核心挑战在于解决Python生态与浏览器运行环境的兼容性鸿沟。Python的众多第三方库在设计之初并未考虑浏览器场景的限制，大量依赖系统级API与C扩展模块，直接迁移至浏览器环境必然面临功能失效的问题。实践中采用的惰性加载适配策略，并非简单的库移植，而是基于依赖分析的按需加载机制——通过静态分析工具识别Python代码的依赖链条，仅在实际功能被调用时，动态引入所需模块及其适配版本，既大幅减少了初始加载的资源体积与耗时，又有效降低了内存占用。对于包含C扩展的复杂库，通过编译层面的深度改造，将C代码转换为浏览器可识别的WebAssembly字节码，同时保留原有API的调用方式与参数规范，确保开发者无需修改代码即可直接使用。针对两种语言的数据类型差异，构建了智能转换机制，能够自动识别数值、序列、映射等不同类型的数据，在传递过程中完成格式适配与精度保留，避免手动转换带来的繁琐操作与数据丢失风险。此外，在适配过程中充分考虑了不同浏览器对WebAssembly的支持差异，通过特征检测与降级处理，确保在主流浏览器中都能获得一致的运行体验。这种环境适配的思路，既尊重了两种语言的原生特性与生态完整性，又通过灵活的适配层设计，实现了生态资源的最大化利用，为互操作模式的广泛应用奠定了基础。</p><p>能力封装的核心目标在于构建无感知的跨语言调用层，让开发者能够摆脱底层实现细节的束缚，以原生函数调用的体验实现JS与Python的相互调用。这种封装并非简单的函数包裹，而是基于接口标准化与功能模块化的设计理念，将Python的核心能力拆解为高内聚、低耦合的功能单元，同时为Python提供访问浏览器API的统一入口，实现双向能力的无缝渗透。在设计过程中，重点强化了函数调用的语法一致性，无论是从JavaScript调用Python的数据分析函数，还是从Python调用JavaScript的DOM操作方法，都采用统一的调用语法与参数传递规则，降低了跨语言开发的认知成本。针对异步场景，通过回调机制与Promise异步模式的深度融合，解决了跨语言调用中的异步协同问题，确保数据处理与界面响应的有序进行，同时提供了完善的异常捕获机制，让跨语言调用过程中的错误能够被精准定位与处理。此外，封装层还具备良好的可扩展性，支持开发者根据具体需求自定义类型转换规则与函数适配逻辑，实现个性化的协同方案。在实际使用中，这种封装策略不仅大幅降低了开发门槛，更实现了两种语言能力的有机整合，让开发者能够根据场景需求灵活组合使用两种语言的优势功能——比如用Python处理复杂的数值计算与数据建模，用JavaScript实现流畅的交互反馈与可视化呈现，构建出功能更强大、架构更简洁的应用，真正实现了“1+1&gt;2”的协同效应。</p><p>性能优化是浏览器内JS与Python互操作走向实用的关键，其核心在于突破数据传输与计算调度的双重瓶颈，实现跨语言协同的高效稳定运行。在数据传输方面，摒弃了传统的JSON序列化与反序列化方式，采用基于内存视图的直接数据访问模式，让两种语言能够共享同一块内存区域，数据在传递过程中无需进行格式转换与拷贝，大幅降低了传输延迟与性能损耗。对于大规模数据集的处理，通过分块传输与流式处理相结合的方式，将数据分解为可并行处理的单元，既减少了单次传输的资源压力，又通过并行计算提高了整体处理效率。在计算调度上，构建了动态负载均衡机制，通过实时监控浏览器的CPU、内存占用情况，智能分配JavaScript与Python的计算任务，当前端界面需要响应用户操作时，自动降低Python计算任务的资源占用，确保界面流畅；当处于后台计算场景时，则充分利用空闲资源提升Python的计算效率。针对Python在浏览器中运行的特性，对垃圾回收机制进行了优化调整，通过动态调整回收时机与回收策略，避免长时间运行导致的内存泄漏问题，同时减少垃圾回收过程对前端交互的影响。此外，还通过代码层面的优化，比如Python函数的惰性执行、重复计算的缓存机制等，进一步提升运行效率。在实际测试中，经过多维度优化后，跨语言调用的性能损耗已降低至可忽略的范围，即便是处理百万级数据的分析任务，也能保持流畅的用户体验，为复杂场景的落地提供了性能保障。</p><p>生态融合与场景落地是浏览器内JS与Python互操作的最终价值体现，这种协同模式正在重构多个前端应用场景的开发逻辑，催生全新的应用形态。在数据可视化领域，Python的数据分析库能够直接处理前端获取的原始数据，完成数据清洗、建模、统计分析等复杂操作，生成的结果无需转换即可通过JavaScript的可视化工具渲染为交互式图表，实现从数据处理到界面呈现的全流程浏览器内完成，既减少了数据传输的延迟，又提升了可视化的实时性与交互性。在在线教育场景中，借助这种互操作模式，可构建轻量化的在线编程环境，学习者能够在网页中直接编写运行Python代码，通过JavaScript实现实时的代码校验、结果反馈与错误提示，同时结合前端交互设计，打造沉浸式的编程学习体验，让编程教育突破环境限制，更具便捷性与普及性。在科研工具开发中，可将Python的专业计算模型与JavaScript的交互界面相结合，打造无需安装、跨平台的科研辅助工具，科研人员能够通过前端界面输入参数、调整模型，实时获取计算结果与可视化分析，大幅降低科研工具的使用门槛。</p>]]></description></item><item>    <title><![CDATA[《智能缓冲调度：文件I/O异步处理的底层实战指南》 程序员阿伟 ]]></title>    <link>https://segmentfault.com/a/1190000047556669</link>    <guid>https://segmentfault.com/a/1190000047556669</guid>    <pubDate>2026-01-21 19:05:59</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>文件I/O的效能瓶颈始终潜藏于数据从内存到存储介质的流转链路中，传统同步读写模式下的固定缓冲策略，早已无法匹配现代应用中多变的读写场景与海量数据处理诉求。异步缓冲优化算法的核心突破，绝非简单扩容缓冲空间或调整读写触发时机，而是构建了一套基于数据行为预判的动态资源调度体系，让缓冲策略与I/O请求特征、存储介质特性形成毫秒级实时联动。这种重构彻底打破了“缓冲即静态缓存”的固有认知，将异步机制的非阻塞优势与缓冲的预载、合并、分流能力深度绑定——在数据未被显式请求时，通过历史行为建模提前预判加载；在请求密集爆发时，智能合并同类操作减少设备交互；在系统空闲时段，通过分批落盘优化存储写入效率，实现了从“被动响应请求”到“主动适配需求”的效能跃迁。无论是大规模日志采集场景中每秒数万条记录的写入压力，高清视频流式处理时的低延迟读取需求，还是分布式数据备份中的跨节点数据传输，这种优化算法都能通过精准的行为感知，让文件I/O的延迟与吞吐量达到动态平衡。在长期的实践观察中发现，这种算法的价值不仅在于逻辑层面的革新，更在于对数据流转本质的重新解构——它不再将缓冲视为孤立的中间层，而是作为串联请求与存储的智能枢纽，为高并发、大数据量场景下的I/O处理提供了全新的解题思路，其带来的效能提升往往能突破硬件本身的物理限制，实现软件层面的效能重构。</p><p>异步缓冲优化算法的底层逻辑，核心在于构建“请求解析-缓冲调度-存储适配”的三角联动机制，而非孤立优化单个环节的性能表现。异步机制的真正价值并非单纯的非阻塞执行，而是通过对请求队列的智能排序与优先级调度，为缓冲策略争取宝贵的预判与调整时间窗口。缓冲层在此架构中不再是静态的中间存储区域，而是具备行为感知能力的动态枢纽，能够实时捕捉I/O请求的频率、数据块大小、访问连续性、重复度等多维特征，进而动态调整数据预载的范围、缓冲分区的划分规则以及数据落盘的时机与批次。在实际调试中发现，当算法检测到连续的顺序读取请求时，会自动扩大预载范围，按照存储介质的物理扇区大小，提前将后续1-3个数据块载入缓冲，这种预载策略能将磁盘寻道次数降低60%以上；而当识别到离散的小文件写入请求时，则会启动“零散数据聚合”机制，设置动态调整的聚合阈值，将短时间内来自不同进程的小写入请求暂时存储于缓冲的独立分区，待数据量达到阈值或触发超时机制后，批量写入存储介质，这种方式能有效减少存储设备的写入次数，降低机械硬盘的磁头损耗与SSD的写入放大效应。这种联动机制的实现，依赖于对I/O行为的精细化建模——通过统计学习方法捕捉请求模式的隐性规律，比如工作日高峰时段的请求密度、特定应用的读写偏好等，让缓冲策略能够自适应不同应用场景与存储设备的特性。它既避免了固定缓冲导致的资源浪费，又解决了异步调度中数据一致性与延迟控制的核心矛盾，在实际应用中，这种底层逻辑的优化能让文件I/O的整体效能提升30%-50%，实现了执行效率的根本性跃迁。</p><p>不同文件I/O场景的请求特征存在显著差异，异步缓冲优化算法的落地关键在于场景锚定与策略动态贴合，而非用一套固定方案适配所有情况。在高清视频流式处理场景中，I/O请求呈现大尺寸、连续性强、低延迟需求突出的特点，算法会针对性采用“大区块预载+增量缓冲”策略——将视频数据按帧组划分为固定大小的区块，通常以8MB或16MB为单位，在播放器解码当前区块时，提前载入后续1-2个区块的核心数据，同时根据解码进度动态补充剩余部分，既满足实时播放对低延迟的要求，又避免过量预载占用过多内存资源。实际测试中，这种策略能将视频加载的卡顿率降低70%以上，尤其在网络带宽波动或存储性能不稳定的环境中，表现更为突出。日志采集场景则以高频、小尺寸、离散写入为典型特征，算法会启用“请求聚合+延迟落盘”机制，设置基于系统负载动态调整的聚合阈值，当系统负载较低时，阈值可适当降低以保证数据实时性；当负载较高时，阈值自动提升以减少I/O交互。同时，通过缓冲分区隔离不同日志源的数据，防止多进程写入时的数据干扰，这种方式能将日志写入的吞吐量提升40%，且有效降低存储介质的写入压力。在分布式数据备份场景中，I/O请求伴随网络传输延迟与存储节点负载波动，算法会引入“缓冲水位动态调整”机制——实时监测网络带宽、节点响应速度与存储队列长度，动态调整缓冲的高低水位线。当网络拥堵时，提高水位线暂存更多数据，避免数据丢失或传输超时；当节点空闲时，降低水位线加速落盘，确保备份任务高效推进。这种场景化的适配思路，要求算法具备极强的灵活性，能够根据场景的核心痛点动态切换策略，在实际落地中，正是这种精准的场景适配让算法能够在不同领域都发挥出最优效能，避免了“一刀切”方案带来的适配短板。</p><p>缓冲的动态调整是异步优化算法的核心创新点，其关键在于摒弃传统的固定阈值模式，构建基于实时负载与请求特征的自适应调节体系。传统缓冲策略中，阈值设定往往依赖经验值，容易导致轻负载时缓冲利用率不足，重负载时缓冲溢出或数据积压，进而引发效能波动。新算法通过引入“缓冲生命周期管理”概念，将缓冲空间划分为预载区、活跃区、待落盘区三个动态分区，每个分区的大小根据实时I/O压力与系统资源状况动态伸缩，实现资源的最优分配。预载区的大小由请求连续性预测模型决定，模型通过分析近期请求的连续度、访问频率等数据，预判后续可能的访问范围，当预测到高连续性请求时自动扩容，离散请求时则收缩，确保预载的针对性；活跃区用于缓存当前高频访问的数据块，通过热度衰减机制淘汰长期未被访问的内容——设定基于访问次数与时间的双重权重，比如近5分钟内访问3次以上的数据视为热数据，超过30分钟未访问则自动标记为冷数据并释放空间，避免无效占用内存；待落盘区则根据存储介质的写入性能动态调整数据批量落盘的阈值，针对机械硬盘的高寻道延迟，适当提高阈值以减少写入次数；针对SSD的高速写入特性，降低阈值以保证数据实时性。同时，算法会实时监测系统内存占用、磁盘I/O队列长度等核心指标，当内存使用率超过80%时，优先释放非核心数据的缓冲空间；当磁盘I/O队列长度低于阈值时，主动清理待落盘区数据，确保缓冲资源在系统整体负载中处于最优分配状态。这种动态调整机制，让缓冲层具备了自我优化的能力，能够在复杂多变的运行环境中始终保持高效运转，避免了传统策略中“要么浪费资源，要么效能不足”的两难困境。</p><p>异步缓冲优化算法的性能调优，核心在于在延迟、吞吐量、资源占用三者之间寻求动态平衡，而非追求单一维度的极致提升。延迟控制的关键在于数据预载的精准度，算法通过分析历史I/O请求数据，构建请求序列预测模型——基于马尔可夫链或时序分析方法，捕捉请求的前后关联规律，提前预判后续可能被访问的数据块，将磁盘I/O操作提前至系统空闲时段完成，从而隐藏存储延迟。在实际调优中发现，预测模型的准确率每提升10%，I/O延迟可降低15%左右，因此模型的持续迭代优化成为延迟控制的核心。吞吐量优化则依赖于请求合并与并行调度的协同——将多个目标地址相同或相邻的I/O请求合并为单次操作，减少磁盘寻道与指令开销；同时，利用异步机制的并行处理能力，将不同分区的缓冲数据分配至独立的处理线程，实现数据预载、缓冲处理、磁盘写入的并行执行，这种并行调度能让吞吐量提升25%-40%，尤其在多进程并发读写场景中效果显著。资源占用的控制则通过缓冲池化管理实现，算法会根据系统整体资源状况，动态调整缓冲池的总容量，避免因缓冲过度占用内存导致系统卡顿；同时，采用“冷热数据分离”策略，将高频访问的热数据保留在高速缓冲中，低频访问的冷数据及时释放，确保缓冲资源的高效利用。在实际调优过程中，需要根据应用的核心诉求灵活调整三者的权重：实时性要求高的场景（如视频直播、实时监控数据写入）优先保障低延迟，适当牺牲部分吞吐量；数据传输密集型场景（如大数据批量处理、备份任务）则侧重提升吞吐量，在资源占用可控的前提下放宽延迟限制。这种多维度的精细化调控，让算法能够适配不同应用的性能需求，实现整体效能的最优解，而非单一指标的片面提升。</p><p>异步缓冲优化算法的落地价值不仅在于提升单一文件I/O的性能，更在于为复杂系统的底层效能重构提供了可复用的核心逻辑，其探索方向正朝着更智能、更贴合业务本质的方向延伸。在实际应用中，该算法已在多个非电商金融场景中展现出显著价值：在气象数据采集系统中，通过优化海量传感器数据的写入逻辑，将数据处理延迟降低40%以上，确保气象预测的实时性与准确性；在影视后期制作平台中，通过大文件分片缓冲与预载策略，实现了4K高清素材的流畅读写与实时编辑，让剪辑师无需等待数据加载，工作效率提升35%；在企业级备份系统中，通过请求聚合与动态落盘机制，将备份效率提升30%，同时减少了存储设备的写入损耗，延长硬件使用寿命达20%。这些落地案例充分证明，算法的价值并非停留在理论层面，而是能够切实解决实际场景中的效能痛点。未来的探索将聚焦于更深度的智能感知能力——比如结合存储设备的硬件特性（如机械硬盘的寻道时间、SSD的擦写寿命）进行自适应优化，根据不同硬件的性能曲线调整缓冲策略；基于业务逻辑的请求优先级动态排序，让核心业务的I/O请求获得更高的调度权重，确保关键操作的响应速度。</p>]]></description></item><item>    <title><![CDATA[写给前端同学的 21 条职场教训 冴羽 ]]></title>    <link>https://segmentfault.com/a/1190000047556673</link>    <guid>https://segmentfault.com/a/1190000047556673</guid>    <pubDate>2026-01-21 19:05:08</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>很多人以为在大厂工作，就是不停地写代码、解决技术难题。</p><p><strong>但事实是：真正成功的工程师并不是那些代码写得最好的人，而是那些解决了代码以外事情的人。</strong></p><p>本篇和你分享 21 条职场教训。</p><p>这些教训，有的能让你少走几个月的弯路，有的则需要数年才能完全领悟。</p><p>它们都与具体的技术无关，因为技术变化太快，根本无关紧要。</p><p>但这些教训，项目换了一个又一个，团队换了一批又一批，始终在重复上演。</p><p>希望能帮助到你：</p><h2>1. 最优秀的工程师都痴迷于解决用户问题</h2><p>很多人容易爱上一项新技术，然后到处找地方用它。</p><p>我干过，你肯定也干过。</p><p>但真正创造最大价值的工程师是反过来的：</p><p><strong>他们专注于深入理解用户问题，并让解决方案从这种理解中自然而然地涌现。</strong></p><p>以用户为中心意味着花时间处理支持工单，与用户沟通，观察用户遇到的困难，不断追问“为什么”，直到找到问题的症结所在。</p><p><strong>真正理解问题的工程师往往会发现，优雅的解决方案比任何人预想的都要简单。</strong></p><p>工程师如果一开始就想着如何解决问题，往往会为了寻找理由而人为地增加复杂性。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556675" alt="" title=""/></p><h2>2. 正确很容易，共同达成正确才是真正的挑战</h2><p>即使你在技术上胜券在握，最终也可能输掉项目。</p><p>我曾亲眼目睹一些才华横溢的工程师，自诩为房间里最聪明的人，但总是默默地积攒怨气。最终表现为“莫名其妙的执行问题”和“莫名其妙的阻力”。</p><p><strong>关键不在于证明自己正确，而在于参与讨论以达成对问题的共识。</strong></p><p>为他人创造发言空间，并对自己确信的观点保持怀疑。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556676" alt="" title="" loading="lazy"/></p><h2>3. 行动优先，先做，再做对，再做好</h2><p>追求完美会让人停滞不前。</p><p>我曾经见过工程师花几周讨论一个从没建过的东西的理想架构。</p><p>但完美的方案很少从思考中产生，它都是从与现实的碰撞中产生。</p><p>先做出来，再做对，再做得更好。</p><p>把丑陋的原型放到用户面前，写出乱糟糟的技术文档初稿，发布那个让你有点尴尬的 MVP。</p><p>从真实反馈中学到的内容，哪怕只有一周，也远比一个月的理论辩论多得多。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556677" alt="" title="" loading="lazy"/></p><h2>4. 代码清晰远比炫技重要</h2><p>我知道你想要写出酷炫的代码，那可以证明自己很牛逼。</p><p>但项目往往不止你一个人，以后还有其他同事要维护。</p><p>优化时要考虑他们的理解能力，而不是你的代码是否优美。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556678" alt="" title="" loading="lazy"/></p><h2>5. 谨慎选择新技术</h2><p>新技术就像贷款，你要用 bug、招聘困难和认知负担来还。</p><p>关键不在于“永远不要创新”，而在于“只在因创新可以带来独特报酬的领域进行创新”。其他的一切还是应该回归平庸。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556679" alt="" title="" loading="lazy"/></p><h2>6. 你的代码不会替你说话，但人会</h2><p>刚开始工作时，我相信是金子总会发光。</p><p>但我错了。</p><p>代码静静地躺在仓库里。你的领导在会议上提到你，或者没提。同事推荐你参与项目，或者推荐了别人。</p><p>在大公司，决策是在你没被邀请的会议上做出的，用的是你没写的总结，由只有五分钟时间和十二件事要处理的人做出的。</p><p>如果你不在场时没人能清楚说出你的价值，那你的价值就等于可有可无。</p><p>这不是让你鼓吹自己，而是告诉你：<strong>你需要让你的价值被所有人看到。</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556680" alt="" title="" loading="lazy"/></p><h2>7. 最好的代码是你根本不用写的代码</h2><p>工程师文化崇拜创造。</p><p>没有人会因为删除代码而获得晋升，即使删除代码往往比添加代码更能改进系统。</p><p><strong>因为你不写的每一行代码，都意味着你永远不必调试、维护或解释。</strong></p><p>在动工之前，先仔细思考一下：“如果我们不做这件事会发生什么？” 有时答案是“没什么坏处”，那就是你的解决方案。</p><p>问题不是工程师不会写代码，而是我们太会写了，以至于忘了问：该不该写？</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556681" alt="" title="" loading="lazy"/></p><h2>8. 大规模时，连你的 bug 都有用户</h2><p>用户多的时候，连你的 bug 都会有用户，这产生了一个职业级洞察：</p><p>你不能把兼容性工作当“维护”，把新功能当“真正的工作”。兼容性就是产品。</p><p>所以把你的“废弃”做成“迁移”，带上时间、工具和同理心。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556682" alt="" title="" loading="lazy"/></p><h2>9. 慢实际上是因为不协调</h2><p>项目进展缓慢时，人们的第一反应往往是责怪执行：员工不够努力、技术不成熟、工程师人手不足。</p><p>但通常来说，这些都不是真正的问题所在。</p><p>在大公司，团队是并发执行的基本单位，但随着团队数量的增加，协调成本呈几何级增长。</p><p>大多数效率低下实际上源于目标不一致——人们在做错误的事情，或者以不兼容的方式做正确的事情。</p><p>所以高级工程师花更多时间澄清方向、接口和优先级，而不是“写代码更快”，那些才是真正的瓶颈所在。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556683" alt="" title="" loading="lazy"/></p><h2>10. 专注你能控制的，忽略你无法控制的</h2><p>在大公司，无数的变数都超出你的掌控——组织架构调整、管理决策、市场变化、产品转型等等。</p><p>过度关注这些因素只会让你焦虑不安，却又无能为力。</p><p>所以高效的工程师，会锁定自己的影响圈。你控制不了是否会重组，但你能控制工作质量、如何应对、学到什么。</p><p><strong>这并非被动接受，而是策略性关注。</strong></p><p><strong>把精力浪费在无法改变的事情上，就等于浪费了原本花在可以改变的事情上的精力。</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556684" alt="" title="" loading="lazy"/></p><h2>11. 抽象并不能消除复杂性</h2><p>每一次抽象都是一种赌博，赌你不需要理解下面是什么。</p><p>有时候你会赢，但总会有漏洞，一旦出现漏洞，你就需要清晰地知道你站在什么上面。</p><p><strong>所以高级工程师即使技术栈越来越高，也要持续学习“更底层”的东西。</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556685" alt="" title="" loading="lazy"/></p><h2>12. 写作让表达更清晰，以教带学是最快的学习方式</h2><p>写作能带来更清晰的表达。</p><p>当我向别人解释一个概念——在文档里、演讲中、代码评审评论里、甚至和 AI 聊天，我都会发现自己理解上的不足。</p><p>所以如果你觉得自己懂了什么，试着简单地解释它。卡住的地方，就是你理解肤浅的地方。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556686" alt="" title="" loading="lazy"/></p><h2>13. 注重粘合性工作</h2><p>粘合性工作——例如写文档、帮新人上手、跨团队协调、流程优化——至关重要。</p><p>但如果你总是无意识地做这些，反而可能会拖慢技术成长，把自己累垮。</p><p>陷阱在于把它当“乐于助人”的活动，而不是当作有边界的、刻意的、可见的影响力。</p><p>尝试给它设时限，轮换做，把它变成产出物：文档、模板、自动化。</p><p>让它作为“影响力”被看见，而不是作为“性格特点”。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556687" alt="" title="" loading="lazy"/></p><h2>14. 如果你赢得每一场辩论，你很可能是在积累无声的阻力</h2><p>当人们不再和你争，不是因为你说服了他们，而是因为他们放弃了。</p><p>但他们会在执行中表达分歧，而不是在会议上。</p><p>所以真正的共识需要更长时间。你得真正理解别人的观点，吸收反馈，有时候需要你当众改变主意。</p><p>短期“我是对的”的快感，远不如长期和心甘情愿的合作者一起建设的现实来得珍贵。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556688" alt="" title="" loading="lazy"/></p><h2>15. 当衡量标准变成目标时，它就停止了衡量</h2><p>你暴露给管理层的每个指标，最终都会被博弈。</p><p>不是因为恶意，而是因为人会优化被度量的东西。</p><p>追如果你追踪代码行数，你会得到更多的代码行数。如果你追踪开发速度，你会得到过高的估算值。</p><p>高手的做法是：对每个指标请求都提供一对指标。一个用于衡量速度，一个用于衡量质量或风险。然后，坚持解读趋势，而不是盲目追求阈值。</p><p><strong>目标是洞察，而非监控。</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556689" alt="" title="" loading="lazy"/></p><h2>16. 承认自己不知道的事情比假装自己知道更能带来安全感</h2><p>资深工程师说“我不知道”并不是示弱——他们是在鼓励大家坦诚面对。</p><p>当领导者承认自己的不确定性时，就等于在暗示其他人也可以这样做。如果不这样的话，就会形成一种人人假装理解、问题被掩盖直到爆发的文化。</p><p>我见过团队里最资深的人从不承认自己不明白，我也见过由此造成的后果。问题不被问出来，假设不被挑战，初级工程师保持沉默因为他们以为别人都懂。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556690" alt="" title="" loading="lazy"/></p><h2>17. 你的人脉关系比你拥有的任何一份工作都更长久</h2><p>职业生涯早期，我专注于工作本身，忽视了人脉经营。回头看，这是个错误。</p><p>那些注重人脉关系的同事，在接下来的几十年里都受益匪浅。他们最先了解机会，更快地建立人脉，获得职位推荐，和多年来建立信任的人一起创业。</p><p>你的工作不会永远持续下去，但你的人脉网络却会一直存在。</p><p>以好奇心和慷慨的态度去拓展人脉，而不是抱着功利主义的心态。</p><p>当需要向前迈进的时候，往往是人际关系打开了这扇门。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556691" alt="" title="" loading="lazy"/></p><h2>18. 大多数绩效的提升来自于减少工作量</h2><p>当系统变慢时，人们的第一反应往往是加东西：加缓存、并行处理、使用更智能的算法。</p><p>有时候这样做是对的。</p><p>但我发现，通过询问“我们计算了哪些不必要的东西？”往往能带来更多性能提升。</p><p><strong>删除不必要的工作几乎总是比更快地完成必要的工作更有成效。最快的代码是永远不会运行的代码。</strong></p><p>所以在进行优化之前，先问问自己这项工作是否真的应该存在。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556692" alt="" title="" loading="lazy"/></p><h2>19. 流程存在的目的是为了减少不确定性，而不是为了留下书面记录</h2><p>最好的流程是让协调更容易、让失败成本更低。</p><p>最差的流程是官僚主义——它的存在不是为了帮忙，而是为了出事时推卸责任。</p><p>如果你无法解释一个个流程如何降低风险或提高清晰度，那么它很可能只是增加了额外开销。</p><p>如果人们花在记录工作上的时间比做工作的时间还多，那就说明出了大问题。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556693" alt="" title="" loading="lazy"/></p><h2>20. 最终，时间会比金钱更有价值</h2><p>刚开始工作的时候，你用时间换钱——这没问题。</p><p>但到了某个阶段，情况就完全不同了。你会开始意识到，时间才是不可再生资源。</p><p>我见过一些高级工程师为了晋升而累垮自己，只为了多拿几个百分点的薪酬。有些人确实升职了，但事后大多数人都在反思，自己放弃的一切是否值得。</p><p>答案不是“别努力工作”，而是“知道你在交易什么，并深思熟虑地进行交易”。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556694" alt="" title="" loading="lazy"/></p><h2>21. 没有捷径，但有复利</h2><p>专业技能源于刻意练习——略微超越现有水平，然后不断反思，不断重复。年复一年，没有捷径可走。</p><p>但令人欣慰的是：学习的进步在于创造新的选择，而不仅仅是积累新的知识。</p><p>写作——不是为了吸引眼球，而是为了清晰表达。构建可复用的基础模型。将过往的经验总结成行动指南。</p><p>所以如果工程师把职业生涯看作是复利投资，而不是彩票，那么他最终往往会取得更大的成就。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556695" alt="" title="" loading="lazy"/></p><h2>22. 最后</h2><p>21 条听起来很多，但它们可以归结为几个核心点：<strong>保持好奇，保持谦逊，记住工作始终是关于人的——你的用户、你的队友。</strong></p><p>工程师的职业生涯足够长，可以犯很多错误。我最钦佩的工程师，不是那些什么都做对的人——而是那些从错误中学习、分享发现、并坚持不懈的人。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556696" alt="" title="" loading="lazy"/></p><p>本篇整理自<a href="https://link.segmentfault.com/?enc=Z5XAKXNU%2F0Kh4YjGfA%2BDzQ%3D%3D.V7YIvPVAW3wvVFzycdxHuVZ7G24S4r4ZJB5xLDOjXhV9QpyfZ44WWpnxRODRt5WFnEuEQkY%2B4LBtf2kRj%2BwNgA%3D%3D" rel="nofollow" target="_blank">《21 Lessons From 14 Years at Google》</a>，希望能帮助到你。</p><p>我是冴羽，10 年笔耕不辍，专注前端领域，更新了 10+ 系列、300+ 篇原创技术文章，翻译过 Svelte、Solid.js、TypeScript 文档，著有小册《Next.js 开发指南》、《Svelte 开发指南》、《Astro 实战指南》。</p><p>欢迎围观我的“<a href="https://link.segmentfault.com/?enc=%2Bxe%2FJzMeahHFoGA38WPVkg%3D%3D.1VShLJqaT0463YOEhVCW8aVpMxpt9DokGzuQH23Le2c%3D" rel="nofollow" target="_blank">网页版朋友圈</a>”，关注我的公众号：<strong>冴羽（或搜索 yayujs）</strong>，每天分享前端知识、AI 干货。</p>]]></description></item><item>    <title><![CDATA[如何在国内合法、安全地使用Claude Code? 明点跨境OSDWAN ]]></title>    <link>https://segmentfault.com/a/1190000047556725</link>    <guid>https://segmentfault.com/a/1190000047556725</guid>    <pubDate>2026-01-21 19:04:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>随着 AI 在开发者工具领域的迅速发展，Claude Code 已成为越来越多程序员、技术团队的重要助手。它不仅能理解自然语言，还能根据指令生成代码、调试、分析项目结构等，提高编程效率。然而，对于中国大陆的开发者来说，如何合法、安全、稳定地使用 Claude Code呢？有哪些方法？</p><p>本篇内容为大家介绍 Claude Code是什么、国内怎么用、合规网络环境、会员要求以及风险等问题，一起往下看看吧。</p><p>一、Claude Code 是什么?</p><p>Claude Code 是由美国 AI 公司 Anthropic 推出的智能编程助手工具，通过 Claude 模型(如 Sonnet、Opus)为开发者提供：</p><p>代码生成<br/>代码修复与调试<br/>代码上下文理解<br/>自然语言指令驱动编程任务<br/>它的定位是 “AI 编程伙伴”，适合从个人开发者到技术团队辅助开发和自动化脚本等广泛场景。相比一些传统代码补具，Claude Code 更强调对整个代码库的理解和对复杂任务的自然语言响应能力。</p><p>二、Claude Code 在国内可以使用吗?</p><p>答案是：可以使用，但有一些地区和网络限制。</p><p>Anthropic 的服务在全球范围内提供，但部分地区的访问可能受限或不稳定。对于中国大陆境内用户，由于国际访问网络限制和政策原因，直接访问 Claude Code 的官网或命令行服务可能会遇到：</p><p>网络阻断或延迟高<br/>注册/订阅页面加载失败<br/>个人/企业用户被限制访问<br/>因此，想要在国内顺畅使用 Claude Code，需要提前准备好合规、稳定的网络工具，没有的话可以使用OSDWAN，提供稳定、合规的跨境网络专线。</p><p>三、Claude Code要会员吗?</p><p>需要付费订阅才能使用Claude Code，Claude本身有免费计划，但免费版不支持 Claude Code。</p><p>根据官方定价页面，Anthropic 提供了多个付费版本：</p><p><img width="723" height="361" referrerpolicy="no-referrer" src="/img/bVdnHP2" alt="image.png" title="image.png"/></p><p>目前没有免费版 Claude Code，免费账户能使用 Claude AI 的基本聊天或简单能力，但无法用于完整的代码生成/执行任务。</p><p><img width="723" height="313" referrerpolicy="no-referrer" src="/img/bVdnHP6" alt="image.png" title="image.png" loading="lazy"/></p><p>四、Claude Code网络怎么解决？如何合法使用 Claude Code？</p><p>由于 Claude Code 是国外服务，对于国内用户来说，建议使用合法合规的网络来访问。</p><ol><li>使用合规、安全的网络通道</li></ol><p>要在国内访问国外服务，需要一个合法、稳定的国际出口网络：</p><p>传统国际网络专线<br/>SD-WAN国际网络专线<br/>SD-WAN专线是目前企业和专业开发者最主流、最稳定的方式，用合规的国际网络专线，把国内访问“直接接入”到海外网络环境。</p><p>避免使用未授权、风险高的私人代理或翻墙工具，因为这可能违反当地政策，也可能导致账号不稳定或者封号风险。</p><p>下面以OSDWAN为例，如何开通合法的SD-WAN专线：</p><p>开通流程一般是：</p><p>联系顾问 → 说明用途（访问Claude 或者其它/ 个人还是企业等）<br/>选择线路节点（美国、新加坡、日本等）<br/>开通账号，下载软件并登录OSDWAN<br/>选择合适的模式（使用海外AI工具，可选择开发科研模式），连接即可使用了。<br/>连接之后就可以稳定访问Claude Code了，以及其它海外AI工具，比如ChatGPT、Gemini、Github。</p><ol start="2"><li>购买和使用 Claude Code会员</li></ol><p>步骤大致如下：</p><p>注册 Claude 官方账号(可以使用Gmail邮箱注册)<br/>登录官网或 app 进入 pricing/订阅页面<br/>根据需求选择 Pro 或 Max 套餐购买<br/>完成支付<br/>激活订阅后即可使用 Claude Code<br/>五、Claude Code 有没有封号风险?</p><p>很多人在国内使用国外 AI 工具时最担心的一个问题就是 账号会被封禁。</p><p>如何规避封号风险：</p><p>遵守官方使用规则和服务条款<br/>不使用未授权破解工具<br/>使用稳定网络避免异常访问行为<br/>不转售账号或共享账号<br/>只要按照官方规则使用，并保证网络与付费的合法性，一般不会轻易触发封号行为。</p><p>六、合规网络专线哪家好？</p><p>OSDWAN 是目前很多技术团队的选择之一，主要优势以下：</p><p>1、纯净度高</p><p>精准定位市场，提供纯净的原生住宅IP地址，真实原生网络环境，避免因IP不纯净导致被网站标记而封号。</p><p>2、节点覆盖全球</p><p>覆盖全球200+国家和地区，包括美国、日本、新加坡、东南亚等主流区域。</p><p>3、连接稳定</p><p>OSDWAN是国内专业跨境网络专线的服务商，是基于SD-WAN技术和SaaS技术的一款产品，支持cpe设备和软件连接，可访问国外任何网站，避免Claude登录中断。</p><p>4、使用灵活</p><p>多设备支持连接，Windows/安卓/苹果等都可以连接使用，独享专线企业可基于APP随时管理，比如上网日志审查、加密、终端管理、员工管理等各项操作。</p><p>七、常见问答</p><p>Q1：Claude Code 有没有免费使用方式?</p><p>答：不提供完整免费的 Claude Code 功能。目前付费订阅(如 Pro 或 Max)才包含 Claude Code 权限。免费账户仅能访问基础聊天和有限功能。</p><p>Q2：我能在国内直接用手机访问 Claude Code 吗?</p><p>答：可以尝试，但由于网络直连可能不稳定，建议使用合规网络加速服务以提升访问稳定性。</p><p>Q3：：Claude Code 会随时封号吗?</p><p>答：只要你遵守官方条款、合理使用，并使用安全网络，封号风险较低。违规、多账号共享或自动化滥用更容易被封禁。</p><p>总结</p><p>要在国内合法、安全地使用 Claude Code：</p><p>使用官方账号并购买付费订阅(Pro/Max)<br/>使用合法稳定的国际网络通道<br/>遵守服务条款，避免异常访问或滥用<br/>如果你正在考虑长期在国内将 Claude Code 用于开发、调试或生产力提升，这是完全可行的——前提是使用安全、合规、稳定的跨境网络专线。</p><p>OSDWAN作为国内专业的跨境网络服务商，为出海企业提供合规、高速、稳定的网络解决方案，支持硬件、软件方案灵活部署。</p><p>OSDWAN在全球的数据中心节点50个，POP节点超过200个，可以为出海企业提供海外加速、SaaS加速、SD-WAN组网、跨境组网、云专线等产品服务，助力中国企业开拓国际市场。</p>]]></description></item><item>    <title><![CDATA[基于知识工程&JoyAgent双RAG的智能代码评审系统的探索与实践 京东云开发者 ]]></title>    <link>https://segmentfault.com/a/1190000047556733</link>    <guid>https://segmentfault.com/a/1190000047556733</guid>    <pubDate>2026-01-21 19:03:40</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>作者：齐海智</p><h2>大促备战中的代码评审困境与破局</h2><p>双十一大促是系统稳定性的终极“大考”。为规避上线风险，技术侧会启动系统封板管控，主动将非紧急需求的发布窗口前置。这一举措在保障系统稳定性的同时，也必然导致研发需求的前置与集中，使得封板前的代码评审任务量显著增加。我们面临着一个严峻的“量与质”的挑战：</p><blockquote>如何在时间紧、任务重的双重压力下，确保代码评审的效率与质量，从而前置发现潜在风险，有效拦截线上BUG？</blockquote><p>传统的代码评审模式在此场景下效率低、质量差（风险遗漏的可能性高），而现有的AI辅助工具又因误报率高而陷入尴尬：产生的多数评审意见并无实质帮助，工程师仍需花费大量时间进行判断与筛选。</p><p>正是在此背景下，【供应链技术部-商家导入研发组】在AI代码评审方面进行了一些探索，尝试将知识工程代码知识检索能力与AutoBots（已更名为：JoyAgent）知识库检索能力相结合，构建了一套代码评审系统。这套双RAG架构为我们的代码评审工作提供了一些新思路，在此分享出来，希望与各位同行交流探讨，共同进步。</p><h2>现有技术方案的局限性</h2><h3>技术1：基于流水线的AI代码评审方案</h3><p><strong>核心技术路径</strong>： 在通过公共流程（Webhook触发、解析MR、获取Diff）得到代码变更内容后，该方案的核心处理流程如下：</p><p>1.<strong>文件类型过滤</strong>：仅保留.java、.yaml和.md文件进行后续分析，并明确优先级的处理顺序。</p><p>2.<strong>上下文截断</strong>：为避免触及大模型上下文窗口上限，采用了一种基于固定行数的上下文截断策略。该策略仅截取代码变更处附近预设行数（如10行）的文本内容。</p><p>3.<strong>Prompt驱动评审</strong>：将经过过滤和截断后的代码片段，与预设的评审规则Prompt组合，发送给通用大语言模型。</p><p>4.<strong>输出评审意见</strong>：解析大模型的返回结果，通过coding平台API将评审结果添加到MR中。</p><p><strong>核心问题识别</strong>：</p><p>1.<strong>全局上下文缺失</strong>：其采用的“固定行数截断”策略是导致问题的根本原因之一。这使得评审完全丧失了项目架构、模块依赖和完整业务逻辑的视野，如同“管中窥豹”，评审深度和准确性受到严重制约。</p><p>2.<strong>提示词天花板</strong>：所有评审规则与知识硬编码于Prompt中，规则膨胀后极易触及模型上下文长度上限，可维护性与扩展性差。</p><p>3.<strong>知识无法沉淀</strong>：效果提升完全依赖于“更换更强的基础模型”与“调整Prompt”，自身缺乏可持续积累、沉淀和复用领域知识的机制。</p><h3>技术2：基于JoyAgent知识库的RAG代码评审</h3><p><strong>核心技术路径</strong>： 在通过公共流程获取代码差异后，该方案的核心流程如下：</p><p>1.知识归纳：将格式化后的Diff内容发送给JoyAgent，由LLM智能体对其进行初步的“知识归纳”，以理解此次变更的核心意图。</p><p>2.规则检索：基于归纳出的知识，通过RAG机制从自定义知识库中召回相关的代码评审规则。此知识库支持在线文档（Joyspace）、离线文档（PDF/Word）等多种格式。该方案的核心灵活性在于其“自定义知识库绑定”机制。接入者可以在JoyAgent平台上自定义智能体，通过工作流绑定自定义知识库。这使得在召回评审规则时，系统能动态地查找并应用接入者自定义的评审规则，从而实现了无需修改Prompt即可定制评审规则的能力。</p><p>3.行级评审：JoyAgent将代码Diff与召回的具体规则相结合，再次调用LLM进行精确评审。利用Git Diff信息中包含的代码行信息，能够将评审意见精准关联到具体的代码行。</p><p>4.输出结果：直接使用JoyAgent的输出结果，通过coding平台API将评审结果添加到MR中。</p><p><strong>核心问题识别</strong>：</p><p>1.<strong>知识归纳失真</strong>：核心问题源于其“知识归纳”步骤。该步骤依赖底层大模型对Code Diff进行总结，此过程不稳定，经常遗漏或曲解原始代码变更的关键上下文，导致后续流程建立在一个不完整或失真的信息基础之上。</p><p>2.<strong>检索与生成联动失效</strong>：基于失真的知识归纳结果进行RAG检索，导致召回的规则与真实代码场景匹配度低。此外，检索结果未经有效的重排序，直接与不完整的代码上下文一并送入大模型，这使得模型缺乏进行准确判断的可靠依据，最终必然生成大量不可靠甚至错误的评审意见。</p><h2>从线上问题到技术突破</h2><h3>问题1：三方系统空值处理异常</h3><p><strong>示例：</strong></p><pre><code>// 问题代码：三方系统地址编码字段处理
request.setAddressCode(String.valueOf(address.getCode()));
// 当address.getCode()为null时，String.valueOf(null)返回"null"字符串
// 导致三方系统Integer.parseInt("null")抛出NumberFormatException
</code></pre><p><strong>技术1的问题</strong>：</p><p>理论上，可以通过在Prompt中硬编码“三方接口地址编码须为数字类型字符串” 的规则来识别此问题。然而，随着业务场景增多，所有规则都被挤压在有限的上下文窗口内竞争。当代码变更触发自动压缩（如截断至10行）时，被保留的上下文具有极大的随机性，与当前评审强相关的评审规则很可能被其他无关规则挤掉或因自动压缩而被截掉，导致其无法被稳定触发，从而漏报。</p><p><strong>技术2的问题</strong>：</p><p>该方案虽然理论上能够通过知识库检索到相关规则，但其不稳定的知识归纳过程导致代码上下文的理解时好时坏，使得规则检索的准确性波动较大。同时，未对检索结果进行重排序，进一步放大了这种不确定性。最终，由于缺乏稳定、可靠的上下文支撑，系统无法持续、准确地识别此类问题，其评审结果表现出显著的随机性。</p><h3>问题2：EDI项目中的语法错误</h3><p><strong>示例：</strong></p><pre><code>&lt;!-- 错误：使用变量而非字面常量 --&gt;
&lt;case value="${orderType}"&gt;
&lt;!-- 正确应使用字面值：&lt;case value="NORMAL"&gt; --&gt;
</code></pre><p><strong>EDI平台介绍：</strong></p><p>EDI（电子数据交换）是用来解决京东物流与多样化商家系统间的对接难题的技术，其关键功能包括<strong>协议转换、数据格式转换、数据校验和流程编排</strong>。这意味着EDI配置文件必须严格遵守预定义的语法和标准，任何偏差都可能导致平台的核心转换与校验功能失效。</p><p><strong>技术1的问题</strong>：</p><p>由于其缺乏对EDI配置语法与规范的领域知识，如果自定义规则，会遇到问题1一样的提示词天花板和上下文截断的问题。</p><p><strong>技术2的问题</strong>：</p><p>除了上面提到的知识归纳过程的不稳定问题，技术2也面临一个更前置的的挑战：它缺乏对项目身份的感知能力。系统在处理一个XML配置文件时，无法自动识别它隶属于“EDI项目”而非普通Java应用。因此，在后续的RAG检索过程中，它极有可能使用通用的Java代码评审规则，而无法精准命中“EDI专用配置规范”这一关键上下文，导致检索方向错误，最终无法识别出必须使用字面常量这一特定于EDI领域的合规性要求。</p><h3>解决方案：双RAG架构</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556735" alt="在这里插入图片描述" title="在这里插入图片描述"/></p><h4>1. 识别项目类型</h4><p>•<strong>特征识别</strong>：基于文件扩展名（.flow, .dt）进行精准判断。</p><p>•<strong>优先级设定</strong>：EDI项目识别优先于普通JAVA项目，确保领域特殊性得到优先处理。</p><p>•<strong>策略影响</strong>：项目类型直接决定后续<strong>评审规则的选择</strong>与<strong>RAG知识库的检索策略</strong>，从源头保障了评审的针对性。</p><h4>2. 代码分块处理</h4><p><strong>2.1 Token估算算法</strong></p><p>由于我们使用的底层大模型是JoyAI，并没有公开tokenizer的细节，根据<a href="https://link.segmentfault.com/?enc=4KqevQnVP2HvswQcEGVWfg%3D%3D.WZ8CsWzRi6JEB%2Fbo7UgBwMTkHk2Rg0%2FiO9qZKgxIC6jaksqWyNVKgdTRsFUHCX7i" rel="nofollow" target="_blank">官网文档</a>提供的token计算API： <a href="https://link.segmentfault.com/?enc=fV1CVUw5QclF0JUj34jRKQ%3D%3D.qkkcdMjbdKKIX%2Fr1J0OpdpJpIPcihyYpBz6Ct6P%2BfVxIbd1Lzw6jtUKwqRDLv22es89mhMWtMfge0kvofXqEsrpBwvyl7xf2spu63CKXPOs%3D" rel="nofollow" target="_blank">http://api.chatrhino.jd.com/api/v1/tokenizer/estimate-token-c...</a></p><p>测试了几组数据：</p><table><thead><tr><th>测试文本</th><th>字符长度</th><th>实际Token数</th><th>内容Token增量</th></tr></thead><tbody><tr><td>空字符串</td><td>0</td><td>63</td><td>0</td></tr><tr><td>"a"</td><td>1</td><td>64</td><td>+1</td></tr><tr><td>"hello"</td><td>5</td><td>64</td><td>+1</td></tr><tr><td>"code"</td><td>4</td><td>64</td><td>+1</td></tr><tr><td>"hello world"</td><td>11</td><td>65</td><td>+2</td></tr><tr><td>"测试"</td><td>2</td><td>64</td><td>+1</td></tr><tr><td>"编程编程"</td><td>4</td><td>65</td><td>+2</td></tr><tr><td>"测试测试测试测试测试"</td><td>10</td><td>68</td><td>+5</td></tr><tr><td>"hello世界"</td><td>7</td><td>65</td><td>+2</td></tr><tr><td>"programming代码"</td><td>13</td><td>66</td><td>+3</td></tr><tr><td>重复"programming代码"3次</td><td>39</td><td>72</td><td>+9</td></tr></tbody></table><p><strong>推导过程</strong></p><p>通过分析测试数据，我们发现了以下关键规律：</p><p>1.基础系统开销：所有请求都有63 tokens的固定开销</p><p>2.英文单词分级：</p><p>◦1-5字符单词 = 1 token（"a"、"hello"、"code"）</p><p>◦6-10字符单词 ≈ 2 tokens（推测值）</p><p>◦11+字符单词 = 3 tokens（"programming"）</p><p>3.中文分词规则：每2个中文字符 = 1 token</p><p>4.空格处理：空格作为分隔符，不增加额外token</p><p>5.混合内容：按字符类型分段计算后求和</p><p>基于上述规律，我们构建了以下估算公式：</p><pre><code>总Tokens = 63 + ∑(单词token)

单词token计算：
- 单字符单词: 1 token
- 英文单词(≤5字符): 1 token  
- 英文单词(6-10字符): 2 tokens
- 英文单词(≥11字符): 3 tokens
- 中文文本: (字符数 + 1) / 2 tokens
- 混合内容: 分段计算后求和
</code></pre><p><strong>2.2 分块阈值与安全设计</strong></p><p>•触发阈值：当预估Token数 &gt; 100,000时，自动触发分块处理流程。</p><p>◦JoyAI的上下文窗口是<a href="https://link.segmentfault.com/?enc=MYZsyH1PTjR%2FkmU06uUZag%3D%3D.GMVe1HuirerXHanJwBAB8mvtK0W2ss7w27rmPXkk%2BfWdplFNopWmHs5DNsHzjnn6" rel="nofollow" target="_blank">128K</a>，由于JoyAI没说明1K是1024还是1000，保守估计使用1000</p><p>◦128K = 128000，为了避免超过上下文窗口，留个富余量，使用80%，12800*0.8=102400 ≈100000</p><p>﻿<img referrerpolicy="no-referrer" src="/img/remote/1460000047556736" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><p>•单块容量：设定 MAX\_TOKENS\_PER\_CHUNK = 60000，为模型输出及上下文预留40%的安全余量。</p><p>•设计理念：通过严格的容量控制，确保单次处理负载均在模型窗口的安全范围内。</p><p><strong>2.3 智能分块策略</strong></p><p>系统采用两级分块策略，确保代码语义的完整性：</p><p><strong>2.3.1 文件级分割</strong></p><p>通过git diff指令识别文件边界，确保单个文件的代码完整性，避免跨文件分割。</p><pre><code>Pattern.compile("diff --git a/(.+?) b/(.+?)\n") 
</code></pre><p><strong>2.3.2 代码结构感知分割</strong></p><p>利用方法签名模式识别代码结构边界：</p><pre><code>Pattern methodPattern = Pattern.compile(
 "([+-]\s*((public|private|protected)\s+)?(\w+\s+)?\w+\s*\([^)]*\)\s*\{)",Pattern.MULTILINE);
</code></pre><p>在方法或类的自然边界处进行分割，最大限度保持代码块的语义完整性。</p><h4>3. RAG增强与重排序机制</h4><p><strong>3.1 基于知识工程的代码片段、业务上下文的检索</strong></p><p>在 RAG增加服务中实现多维度检索增强：</p><p>•业务领域识别：基于代码内容识别是仓业务（WMS）、仓配接入业务（ECLP）、转运中心业务（TC）等。</p><p>•关键词提取与过滤：从变更文件中提取并净化关键术语。</p><p>•通过执行语义搜索。</p><p>重排序优化：对检索结果使用BGE模型进行重排序，提升相关性。</p><p><strong>3.2 重排序</strong></p><p>在RAG系统中，检索（召回）这一步通常使用向量相似度搜索。这种方法追求的是高召回率——即尽可能不遗漏任何可能相关的文档。但这就带来了一个问题：</p><p>◦数量过多：可能会返回大量候选文档，全部送入大模型会导致超过上下文窗口限制，成本高昂且速度慢。</p><p>◦质量不均：向量搜索是基于语义相似度，但“相似”不一定等于“有用”。它可能会召回一些：</p><p>▪主题相关但内容泛泛的文档。</p><p>▪包含关键词但逻辑不匹配的文档。</p><p>▪相关性排名不高但实际至关重要的“珍宝”文档。</p><p>例如检索“如何做番茄炒蛋”，向量相似度查询结果可能会找到：</p><p>◦《番茄炒蛋的最正宗做法》 （极度相关，排名第一）</p><p>◦《100道家常菜谱》 （相关，但范围太广）</p><p>◦《鸡蛋的营养价值》 （部分相关）</p><p>◦《番茄种植指南》 （仅关键词相关，实际无用）</p><p>如果不经处理，把这四篇文档塞给大模型，模型需要费力地从大量文本中辨别哪些是真正有用的信息，不仅增加了Token消耗，更严重的是，无关信息会形成“噪声”，干扰模型的判断，导致生成质量下降——模型幻觉。</p><p>为了节省成本，我们使用了本地重排序方案：</p><p>◦模型文件: bge-reranker-base.onnx (<a href="https://link.segmentfault.com/?enc=A5lyKx0TEp5mDl2R%2FFQXYg%3D%3D.40PeaZ0OUFezCb1cn8XWlgzE8EE4rTfZyhmZbWOgBHynwcLdqrM2F1DZCCNmEB%2Bb4XHQhoWzTsab%2FmjQMG5JYA%3D%3D" rel="nofollow" target="_blank">BGE</a>重排序模型)</p><p>◦分词器: HuggingFaceTokenizer</p><p>◦运行时: ONNX Runtime Java API</p><pre><code>// 核心流程
public List&lt;Map.Entry&lt;String, Float&gt;&gt; rerankBatch(String query, List&lt;String&gt; documents) {
 // 1. 文本预处理和分词
 // 2. 构建查询-文档对
 // 3. ONNX模型推理
 // 4. 相关性评分计算
 // 5. 按分数降序排序
 // 6. 返回排序结果
}
</code></pre><p>示例：</p><p>﻿<img referrerpolicy="no-referrer" src="/img/remote/1460000047556737" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h4>4. 实际应用效果验证</h4><p><strong>案例1：成功预防空值处理事故</strong></p><p>﻿<img referrerpolicy="no-referrer" src="/img/remote/1460000047556738" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><p><strong>案例2：EDI配置规范检查</strong></p><p>﻿<img referrerpolicy="no-referrer" src="/img/remote/1460000047556739" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h2>总结与展望</h2><p>我们探索出的双RAG架构，其价值核心并非追求极致的简单或敏捷，而是它既能像资深的一线研发一样，深度理解业务及代码变更的具体语境与潜在影响，又能像严谨的架构师一样，严格遵循成文的规范与最佳实践。</p><p>通过结构化的协同机制，系统将两种不同质、不同源的知识（深度的代码语义与精准的评审规则）进行融合，实现了 “1+1 &gt; 2” 的智能涌现，从而具备了识别并预防那些复杂、隐蔽代码缺陷的深度推理能力。这正是我们在高并发、高可用要求极为严苛的大促等场景下，为夯实系统稳定性基石所做出的关键性架构决策。</p><p>这一成功实践，为我们奠定了代码评审工作中坚实的技术基石，并清晰地指明了未来的演进路径：</p><p>1.<strong>迈向多模态代码理解</strong>：从纯文本代码评审，扩展至对架构图、时序图等非结构化设计产物的理解与合规性检查。</p><p>2.<strong>构建全域业务知识库</strong>：自动抓取并融合产品经理的历史PRD、设计文档等非技术知识，将其转化为知识工程中的关键上下文。这使得AI在评审时，不仅能理解“代码怎么写”，更能判断“代码为何而写”，实现对业务意图的精准校验，从源头规避偏离产品设计的实现。</p><p>3.<strong>实现需求上下文的自动关联</strong>：通过规范研发流程，约束在提交代码时于commit信息中嵌入需求编号。系统在评审时自动提取该编号，并主动获取对应的PRD详情。这使得每一次代码评审都能够在完整的业务背景中进行，AI能够直接对照需求文档，判断代码实现是否完整、准确地满足了所有功能点与业务规则，提供前更加精准的上下文。</p><p>虽然探索的道路并非坦途，我们曾在具体的技术细节中陷入困境，例如，为了在 CentOS 7.9 的环境中支持高版本 ONNX 运行时以启用重排序功能，不得不手动编写docker脚本从源码编译高版本的cglib依赖。这段经历，恰恰印证了弗雷德里克·布鲁克斯在《人月神话》中所揭示的那句箴言：</p><blockquote>The only way to accelerate software work is to simplify the product and the process, and to face the essential complexity of the software task itself with courage and skill.</blockquote>]]></description></item><item>    <title><![CDATA[项目集管理软件怎么选？2026年主流PPM工具横评与避坑指南 许国栋 ]]></title>    <link>https://segmentfault.com/a/1190000047556741</link>    <guid>https://segmentfault.com/a/1190000047556741</guid>    <pubDate>2026-01-21 19:02:57</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>本文横评 12 款项目集管理软件/PPM/SPM 工具：ONES、Planview、Clarity、ServiceNow SPM、Jira Align、Planisware、Sciforma Vantage、Meisterplan、OnePlan、Microsoft Project、Oracle Primavera P6 EPPM、Smartsheet Control Center。目标是帮研发负责人、PMO 与效能团队快速识别：哪些工具能支撑“战略—投资—资源—交付—价值”的闭环，以及最常见的落地陷阱与避坑路线。</p><h2>为何“项目集管理软件”成为管理刚需</h2><p>过去几年，很多企业的研发数字化先解决了“把活干起来”：需求、任务、迭代、缺陷能在线流转，协作效率明显提升。但到了 2026 年，新的瓶颈更集中在“把活干对、把钱花值”——项目越来越多、依赖越来越密、资源冲突越来越频繁。管理层真正缺的，往往不是一个更好看的项目看板，而是一套能支撑跨项目决策的项目集管理软件（PPM/SPM）。</p><p><strong>概念速查：</strong></p><ul><li>项目（Project）：为交付特定成果而开展的临时性工作。</li><li>项目集（Program）：一组相互关联的项目与活动，通过协同管理来实现单个项目无法独立实现的业务收益。</li><li>项目组合（Portfolio）：为实现组织战略目标而进行的项目/项目集集合及其选择、优先级与治理活动；其核心是战略对齐与投资决策。</li><li>PPM（Project Portfolio Management）：更常用的行业叫法，强调以组合方式进行选择、排序、资源与财务配置。</li><li>SPM（Strategic Portfolio Management）：更强调“战略 + 资金 + 执行”一体化治理，把组合管理提升为经营系统。</li></ul><p>一句话总结：项目集管理软件解决的不是“项目怎么排”，而是“在资源与资金约束下，哪些项目集最值得做、怎么做、做出什么价值”。</p><h2>工具盘点：12款项目集管理软件横评</h2><h4>1) ONES（ONES Plan + ONES Project）</h4><p>一句话定位：偏“研发一体化”的项目集管理软件，把计划层与研发执行数据打通。ONES Plan 强调多项目总览、里程碑/甘特、资源与工时等，并与 ONES Project 数据互通。</p><p>项目管理能力（<a href="https://link.segmentfault.com/?enc=84r%2BHnw9nx8Em%2BwrkTldHA%3D%3D.v84CLzuB%2FTfEahXjA06AeRMw1BosTGcMhYOqunQUWllC00CVDZAy0JdRpLCe%2FvQt" rel="nofollow" target="_blank">ONES Project</a>）：面向敏捷与瀑布等项目制研发，覆盖需求池与迭代规划、任务工时统计与进度可视化（看板、燃尽图等），并提供缺陷跟踪与质量统计；再通过多种报表与可选维度输出绩效度量与改进信号，适合把“交付过程”做实。</p><p>项目集/项目组合能力（<a href="https://link.segmentfault.com/?enc=HttHuAMmuNf7Raz%2FOEfQlw%3D%3D.0KgM%2B0mfCTSqBI1BrNpxLzamPwj7Hfs%2FCeO1gSd7tPI%3D" rel="nofollow" target="_blank">ONES Plan</a>）：核心抓手是“多项目总览 + 里程碑/甘特 + 资源/工时”。它支持总览多项目信息、制定里程碑与甘特计划，并通过自定义项目属性与多项目数据集合，把不同类型项目纳入同一治理口径；资源侧提供多种资源报表与项目工时管理，并可直接查看 Project 的登记/预估/剩余工时数据，帮助管理层理解投入结构与团队负载，从而更理性地做优先级与产能调度。同时，Plan 提供产品管理（产品线），可通过工作项属性实现跨项目管理，更适合“按产品域聚合组合”的组织。</p><p>适用场景：研发多项目并行，既要项目集层面的管控，又希望需求/迭代/缺陷等执行数据可回流的组织。</p><h4>2) Planview（Strategic Portfolio Management ）</h4><p>定位一句话：企业级 SPM，强调战略到交付的组合治理，并将 AI 深度嵌入；Planview 明确提出其战略组合管理用于帮助高层、财务与 EPMO 推动转型与按战略交付。<br/>项目集/项目组合能力：强在“组合视图、情景规划、资源约束下的决策”，并借助 AI 做风险识别、预测与自动化辅助（Planview Anvi 发布中提到可检测组合风险、预测新工作完成情况等）。<br/>适用场景：多事业部、投资盘子大、需要组合层治理深度与跨部门协同的组织。<br/>优势亮点：适合把项目集管理软件作为“经营驾驶舱”：在约束下做选择，在变化中持续重排。<br/>局限与体验：实施与配置复杂度通常不低；若流程与主数据治理不成熟，容易变成“填表工程”。<br/>试用重点：要求用你们真实资金/资源约束跑一次 what-if，并验证输出是否能支撑评审会“当场决策”。</p><h4>3) Broadcom Clarity（Clarity SPM）</h4><p>定位一句话：Clarity 被官方定义为企业级 SPM 平台，用于统一战略、资金与执行，并强调财务透明与资源利用。<br/>项目集/项目组合能力：更偏“资金与资源治理驱动”的项目组合管理，适合在组合层把“投什么、投多少、谁来做”讲清楚。<br/>适用场景：PMO 成熟、预算问责明确、资源需要矩阵化调度的大中型组织。<br/>优势亮点：当高层最关心“钱去哪了、产能去哪了”时，Clarity 的价值更容易体现。<br/>局限与体验：对数据口径要求高；与交付系统割裂时，集成会显著抬高 TCO。<br/>试用重点：优先验证“资金池—成本归集—资源占用—价值/收益追踪”的最小闭环能否跑通。</p><h4>4) ServiceNow SPM（Strategic Portfolio Management ）</h4><p>定位一句话：平台化的 SPM，把需求、组合、项目与治理流程放进统一工作流，并用 Now Assist for SPM 提升记录创建、项目总结、需求/用户故事生成等效率。<br/>项目集/项目组合能力：强在“流程可审计、端到端流转”，适合把立项、组合评审、变更、项目治理做成系统化管理闭环。<br/>适用场景：企业已有 ServiceNow 平台基础，或希望用一个平台承载跨部门治理。<br/>优势亮点：AI 更贴近管理工作流（总结、生成、完善记录），对提升“治理效率”有现实价值。<br/>局限与体验：平台化意味着建模与实施门槛；治理边界不清会“流程压死敏捷”。<br/>试用重点：用真实审批链跑一遍立项/变更，看权限、审计日志、口径与例外处理是否可用。</p><h4>5) Atlassian Jira Align</h4><p>定位一句话：战略到执行的对齐层，允许团队继续在 Jira 与 Azure DevOps 中工作，同时在计划、项目组合与企业层进行协调与规划。<br/>项目集/项目组合能力：更适合“规模化敏捷/混合交付”的组合治理，价值在于减少“战略语言”和“团队执行语言”的翻译成本。<br/>适用场景：正在推进 SAFe/规模化敏捷，或跨团队依赖密集、需要 program 层节奏协同的组织。<br/>优势亮点：对齐逻辑清晰，特别适合用来统一路线图、依赖与价值交付节奏。<br/>局限与体验：它不是细化项目计划的工具；如果底层数据与需求治理不稳，很容易出现“看上去对齐、实际失真”。<br/>试用重点：重点验证双向数据回流与字段语义一致性（Align↔Azure DevOps/Jira）。</p><h4>6) Planisware</h4><p>定位一句话：强调数据驱动的评分、对比与优先级排序，并把 reporting、analytics、scenario modeling 融合到组合绩效、资源利用与风险洞察中。<br/>项目集/项目组合能力：强在“组合优化 + 情景模拟 + 资金/容量权衡”，适合把组合治理做得很“硬”。<br/>适用场景：流程成熟、资源约束强、需要严谨组合规划的中大型组织（尤其多项目、长周期行业）。<br/>优势亮点：对高层最关键的“取舍问题”支持度高——在投入前先把不同策略的后果算清楚。<br/>局限与体验：学习曲线与实施复杂度较高；组织配套机制不足时，系统很难跑出真实价值。<br/>试用重点：让 PMO 用真实资源/预算约束跑两套方案并对比：稳健增长 vs 风险缓解。</p><h4>7) Sciforma Vantage（现并入 Planview 体系）</h4><p>定位一句话：面向 PPM/项目组合管理的产品线，市场材料强调 simulations、实时比较与组合概览等能力；同时 Planview 已完成对 Sciforma 的收购并将其纳入组合解决方案。<br/>项目集/项目组合能力：更偏“PMO 视角的组合治理与可视化”，适合希望快速建立组合透明度与容量规划能力的组织。<br/>适用场景：需要组合分析/情景模拟/容量规划，但又不一定上最重的全栈平台的企业。<br/>优势亮点：适合做“可视化决策”，把组合评审从主观争论拉回到可比较的方案层面。<br/>局限与体验：与研发执行工具链的深度联动通常需要额外集成与数据建模。<br/>试用重点：优先验证：组合评分模型能否适配你们的战略维度；容量规划是否能真实反映人力约束。</p><h4>8) Meisterplan</h4><p>定位一句话：典型“组合级资源管理 + 情景规划引擎”，强调用场景（Scenarios）回答高层 what-if 问题，并用多视图呈现对项目、资源与财务的影响。<br/>项目集/项目组合能力：更像“组合决策引擎”，项目执行可留在 Jira/其他系统里。<br/>适用场景：项目太多、资源冲突高频、但不想先上重型 SPM 的成长型组织。<br/>优势亮点：上手更聚焦，能更快把“资源—需求—优先级”从 Excel 拉到一致视图。<br/>局限与体验：财务/收益闭环常需要外部系统补齐；治理重时要小心边界错配。<br/>试用重点：用一周做“资源冲突复盘”：导入近期延期项目，检验系统是否能解释冲突来源与调序后果。</p><h4>9) OnePlan</h4><p>定位一句话：主打“连接异构工具链，把数据汇入统一组合视图”，明确提到可连接 Teams、Planner、Project、Azure DevOps、Jira、Smartsheet 等，把项目数据汇聚到一个平台。<br/>项目集/项目组合能力：强在“连接 + 统一口径 + 组合视图 + 资源优化”，特别适合工具分散、数据分裂的企业。<br/>适用场景：多系统并存，希望先解决“组合透明度与统一口径”。<br/>优势亮点：连接面广，适合以较低代价先做出全局视图，再逐步强化治理。<br/>局限与体验：连接越多，对主数据治理要求越高，否则只是把噪音集中到一个地方。<br/>试用重点：重点做一次“字段语义对齐”演练：状态/优先级/完成度在不同系统的定义如何统一。</p><h4>10) Microsoft Project</h4><p>定位一句话：微软生态的 PPM 路线对很多企业很友好，但必须提一句的是：微软已宣布 Project Online 将于 2026-09-30 退役，迁移规划需要提前纳入选型。<br/>项目集/项目组合能力：更偏“标准化流程 + 报表/协作生态”，适合希望与 Microsoft 365/Power BI 深度耦合的组织。<br/>适用场景：协作平台以 Microsoft 365 为核心，且希望以较低集成成本搭建组合视图的企业。<br/>优势亮点：生态与扩展性强；对“统一报表口径与协作体验”价值明显。<br/>局限与体验：如果企业核心矛盾是“资源容量与组合优化”，仅靠轻量生态往往不够，需要更清晰的治理机制与模型。<br/>试用重点：把“退役迁移路线”当成验收项：未来两年你的组织要迁往哪里，数据与流程怎么接续。</p><h4>11) Oracle Primavera P6 EPPM</h4><p>定位一句话：Oracle 官方文档明确其为集成解决方案，用于在全球范围确定项目、计划（program）和项目组合（portfolio）的优先级、进行计划、管理和执行。<br/>项目集/项目组合能力：更适合“复杂排程/关键路径/长周期大型项目群”的治理，在工程与强计划约束行业非常典型。<br/>适用场景：工程建设、制造交付、强里程碑与强关键路径管理的组织。<br/>优势亮点：排程与项目群治理成熟，适合把“计划准确性与可控性”做到极致。<br/>局限与体验：对产品迭代/敏捷研发组织可能偏重；与 DevOps 工具链的耦合需要方法论转译与集成投入。<br/>试用重点：验证关键路径、基准与变更影响分析是否真正减少“计划反复推倒重来”。</p><h4>12) Smartsheet Control Center</h4><p>定位一句话：以蓝图（Blueprint）规模化创建项目，并形成“蓝图汇总/组合报表”的统一视图；其学习中心也强调通过 dashboard widget 自动汇总新建项目的数据，实现组合层可视化。<br/>项目集/项目组合能力：更偏“可复制的项目工厂 + 组合报表”，特别适合大量重复型项目的规模化治理。<br/>适用场景：交付/运营/门店/推广等重复性项目多，希望快速统一模板与汇总报表的组织。<br/>优势亮点：把 PMO 从“项目搭建与汇总”中解放出来，提升一致性与可见性。<br/>局限与体验：更深的投资组合建模与财务闭环往往需要外部系统配合；否则更像“组合可视化 + 标准化执行”。<br/>试用重点：验证蓝图能否承载治理规则（字段/权限/变更），以及组合报表是否覆盖高层关心的问题。</p><h2>项目集管理软件落地避坑指南</h2><p>我把失败原因归为三类，便于你对症下药。你会发现：这些坑不是“某个产品的缺陷”，而是“组织把项目集管理软件当成灵丹妙药”的误解。</p><p><strong>1) 数据没统一：没有“单一事实源”，一切组合分析都是幻觉</strong></p><p>项目集管理软件最依赖三类数据：项目状态口径、资源与工时口径、成本/预算口径。任何一条不可信，组合层的结论就会被质疑。最终高层会议讨论的不是“决策”，而是“数据准不准”。<br/>避坑动作：先定“口径委员会”，把状态、完成度、健康度、产能占用的定义统一下来；宁可少指标，也不要多口径。</p><p><strong>2) 决策机制没落地：工具无法替你做取舍</strong></p><p>很多企业买项目集管理软件的潜台词是“希望系统帮我压住各部门”。但系统只能把规则固化，无法替你做组织政治的取舍。没有清晰的组合评审节奏、资源分配权责与变更门槛，工具只会把混乱更高清地展示出来。<br/>避坑动作：把“项目增量的门槛”写进制度：新增项目必须说明战略关联、收益假设与资源来源；没有这三项，系统再强也只是登记簿。</p><p><strong>3) 集成断层：战略与组合在云端，交付在地面</strong></p><p>像 Jira Align 这类对齐层，定位就是把战略与执行连接起来，并与 Jira/Azure DevOps 形成数据回流。<br/>但如果底层交付系统的数据语义不统一，系统对齐只会变成“漂亮但失真”。<br/>避坑动作：把“字段语义映射表”当作一等公民：状态、优先级、完成标准必须跨系统一致，否则组合报表一定失真。</p><p><strong>一套更可执行的落地路线图（30-60-90天）:</strong></p><p><strong>前30天：统一视图</strong><br/>先别追求全功能，做到：项目清单唯一、状态口径统一、组合视图能回答“我们在做什么、占用多少产能”。</p><p><strong>60天：治理入口</strong><br/>把立项入口、组合评审、变更审批流程固化；做到“新增项目必须过门槛”。</p><p><strong>90天：组合优化</strong><br/>引入 what-if 与资源/资金约束下的组合选择，把会议从“吵架”变成“算账”。</p><p>项目集管理软件选型的本质，是你要用系统解决哪个“经营问题”——战略对齐、投资取舍、资源约束、价值兑现。把问题定义对了，再用“三层尺子（数据/治理/系统）”评估，你就很难选错。</p>]]></description></item><item>    <title><![CDATA[618 大促技术实践：定时任务异常重试的探索与沉淀 京东云开发者 ]]></title>    <link>https://segmentfault.com/a/1190000047556762</link>    <guid>https://segmentfault.com/a/1190000047556762</guid>    <pubDate>2026-01-21 19:02:16</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>作者：齐海智</p><p>在 618 大促的技术战场上，每一行代码、每一个配置都影响着一线的实实在在的业务。一次看似平常的发版，却意外暴露了我们系统中的定时任务管理短板，这促使我们深入剖析分布式任务调度中异常重试机制的技术细节，并最终将其转化为守护系统稳定性的坚固防线。​</p><h2>一、异常事件回溯：隐藏在发版背后的定时炸弹​</h2><p>发版次日，业务部门反馈商家未收到门店收货明细邮件，导致门店收货业务收到影响。技术团队迅速启动应急流程，通过全链路日志追踪和系统状态分析，发现了问题的根源是：发版过程中，由于服务重启，中断了定时任务进程，正在执行的邮件发送任务被意外终止。而该任务在管理平台上并未配置任何重试策略，业务代码上也没有进行相关的检测和重试，这就导致任务失败后无法自动恢复执行，也未被及时感知到，进而引发业务阻断。​</p><p>为解决燃眉之急，研发人员立即登录任务管理平台，手工触发邮件发送任务，确保业务及时恢复。但这次事件给我们敲响了警钟：在分布式任务调度场景下，面对网络抖动、进程异常终止等场景，异常重试机制是保障业务可靠性的关键。​</p><h2>二、重试策略设计：从理论到代码的深度解析​</h2><h3>2.1 验证EasyJob的重试策略</h3><p>在复盘问题的过程中，我们发现了EasyJob分布式任务是具有重试策略的，只是默认不开启，而不是默认开启。</p><p>﻿<img referrerpolicy="no-referrer" src="/img/remote/1460000047556764" alt="在这里插入图片描述" title="在这里插入图片描述"/></p><p>﻿﻿</p><p>该策略以三个核心参数为基础：首次重试间隔时间 F、重试间隔乘数 M 和最大重试次数 C。</p><p>通过这三个参数的组合，我们可以灵活控制任务重试节奏，平衡系统负载与任务恢复效率。​</p><p>例如：配置t=10s, M=2, C=10，则间隔时间依次是：</p><table><thead><tr><th>重试次数 nn</th><th>间隔时间计算方式</th><th>间隔时间结果</th></tr></thead><tbody><tr><td>1</td><td>10s（初始间隔，无计算）</td><td>10s</td></tr><tr><td>2</td><td>10s×2</td><td>20s</td></tr><tr><td>3</td><td>20s×2</td><td>40s</td></tr><tr><td>4</td><td>40s×2</td><td>80s</td></tr><tr><td>5</td><td>80s×2</td><td>160s</td></tr></tbody></table><p>验证日志：</p><pre><code>21:45:29.990 [main-schedule-worker-pool-1-thread-1] INFO  cn.jdl.tech_and_data.EmailSendingTask - 开始执行发送邮件任务
21:45:40.204 [main-schedule-worker-pool-1-thread-2] INFO  cn.jdl.tech_and_data.EmailSendingTask - 开始执行发送邮件任务
21:46:00.674 [main-schedule-worker-pool-1-thread-3] INFO  cn.jdl.tech_and_data.EmailSendingTask - 开始执行发送邮件任务
21:46:41.749 [main-schedule-worker-pool-1-thread-4] INFO  cn.jdl.tech_and_data.EmailSendingTask - 开始执行发送邮件任务
21:48:02.398 [main-schedule-worker-pool-1-thread-5] INFO  cn.jdl.tech_and_data.EmailSendingTask - 开始执行发送邮件任务
21:50:43.008 [main-schedule-worker-pool-1-thread-1] INFO  cn.jdl.tech_and_data.EmailSendingTask - 开始执行发送邮件任务
</code></pre><table><thead><tr><th>任务序号</th><th>开始时间</th><th>与前一任务的间隔</th></tr></thead><tbody><tr><td>第 1 个任务</td><td>21:45:29.990</td><td>-</td></tr><tr><td>第 2 个任务</td><td>21:45:40.204</td><td>10.214 秒</td></tr><tr><td>第 3 个任务</td><td>21:46:00.674</td><td>20.47 秒</td></tr><tr><td>第 4 个任务</td><td>21:46:41.749</td><td>41.075 秒</td></tr><tr><td>第 5 个任务</td><td>21:48:02.398</td><td>80.649 秒（约 1 分 20.65 秒）</td></tr><tr><td>第 6 个任务</td><td>21:50:43.008</td><td>160.61 秒（约 2 分 40.61 秒）</td></tr></tbody></table><p>与上面计算的一致。</p><p>验证方案：</p><p>1、实现接口：com.wangyin.schedule.client.job.ScheduleFlowTask，并设置任务返回失败：</p><p>﻿<img referrerpolicy="no-referrer" src="/img/remote/1460000047556765" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><p>﻿﻿</p><p>2、创建CRON触发器</p><p>﻿<img referrerpolicy="no-referrer" src="/img/remote/1460000047556766" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><p>﻿﻿</p><p>3、设置自动重试参数</p><p>﻿<img referrerpolicy="no-referrer" src="/img/remote/1460000047556767" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556768" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><p>﻿﻿</p><p>4、暂停任务并手工触发一次</p><p>﻿</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556769" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h3>2.2 实现一个简单的重试策略</h3><p>根据上述策略，简单实现了一个灵活可配置的任务重试机制。</p><pre><code>public class TaskRetryExecutor {
    @Getter
    private final ScheduledExecutorService executor = newScheduledThreadPool(10);
    private final long firstRetryInterval;
    private final int intervalMultiplier;
    private final int maxRetryCount;

    public TaskRetryExecutor(long firstRetryInterval, int intervalMultiplier, int maxRetryCount) {
        this.firstRetryInterval = firstRetryInterval;
        this.intervalMultiplier = intervalMultiplier;
        this.maxRetryCount = maxRetryCount;
    }

    public void submitRetryableTask(Runnable task) {
        executeWithRetry(task, 1);
    }

    private void executeWithRetry(Runnable task, int currentRetryCount) {
        executor.schedule(() -&gt; {
            try {
                task.run();
                log.info("任务在第{}次尝试时成功执行", currentRetryCount);
            } catch (Exception e) {
                log.error("任务在第{}次尝试时执行失败", currentRetryCount, e);
                if (currentRetryCount &lt;= maxRetryCount) {
                    long delay = calculateRetryDelay(currentRetryCount);
                    log.info("计划在{}毫秒后进行第{}次重试", delay, currentRetryCount);
                    executeWithRetry(task, currentRetryCount + 1);
                } else {
                    log.error("超过最大重试次数。任务执行最终失败。");
                }
            }
        }, currentRetryCount == 1 ? 0 : calculateRetryDelay(currentRetryCount), TimeUnit.MILLISECONDS);
    }

    public long calculateRetryDelay(int retryCount) {
        if (retryCount == 1) {
            return firstRetryInterval;
        } else if (retryCount &gt; 1 &amp;&amp; retryCount &lt;= maxRetryCount) {
            long previousDelay = calculateRetryDelay(retryCount - 1);
            return previousDelay * intervalMultiplier;
        }
        return -1; // 超出最大重试次数，返回错误标识
    }
}
</code></pre><p>​在上述代码中：</p><p>1.TaskRetryExecutor类封装了任务重试的核心逻辑。构造函数接收三个关键参数：firstRetryInterval、intervalMultiplier和maxRetryCount，用于配置重试策略，对应于EasyJob的F、M、C参数。</p><p>2.submitRetryableTask方法接收一个可执行任务，并启动重试流程。它调用executeWithRetry方法，初始重试次数为1。</p><p>3.executeWithRetry方法是重试逻辑的核心。它使用ScheduledExecutorService来调度任务执行：</p><p>◦如果任务执行成功，记录成功日志。</p><p>◦•如果任务执行失败且未超过最大重试次数，计算下一次重试的延迟时间，并递归调用自身进行重试。</p><p>◦•如果超过最大重试次数，记录最终失败日志。</p><p>4.calculateRetryDelay方法实现了重试间隔的计算规则：</p><p>◦第一次重试使用firstRetryInterval。</p><p>◦之后的重试间隔是前一次间隔乘以intervalMultiplier。</p><p>◦如果超出最大重试次数，返回-1表示错误。</p><p>通过这种设计，我们实现了一个可复用、可配置的任务重试机制。它能够根据配置的参数自动调整重试间隔，在任务失败时进行有策略的重试，同时避免无限重试导致的资源浪费。</p><p>详细代码可在以下Git仓库中找到：<a href="mailto:git@coding.jd.com" target="_blank">mailto:git@coding.jd.com</a>:newJavaEngineerOrientation/TaskRetryStrategies.git</p><h3>2.3 重试策略的理论分析</h3><h4>2.3.1 EasyJob对乘数和最大重试次数的限制</h4><p>在对EasyJob也进行了重试的验证中发现：</p><p>1.<strong>每次重做的乘数</strong>取值范围是[1,8]，可以是具有一位小数位的浮点数，比如3.5，</p><p>2.<strong>最多重做次数</strong>是[1,16]间的整数，第一次重试的间隔没有限制，单位是秒。</p><p>﻿<img referrerpolicy="no-referrer" src="/img/remote/1460000047556770" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h4>2.3.2 梯度分析</h4><p>通过上面的验证和重试相关概念的定义，可以得到：第n次重试的间隔时间=第一次间隔时间*乘数^(n-1)，即：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556771" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><p>其中：</p><p>﻿<img referrerpolicy="no-referrer" src="/img/remote/1460000047556772" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><p>对乘数M的梯度：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047556773" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><p>对重试次数n的梯度：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047556774" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><p>﻿﻿</p><p>详细推导： <a href="https://link.segmentfault.com/?enc=K0eVwdxTaQuftKGl3MOOkA%3D%3D.s3RNP833F2FbM7ODKfuhAb%2Fy0wTup6EfIAr3K8J2acrJ3FxI939A11YEsnaAP6TXh77GN1FhA3VgvJZyj%2B%2F8azwFDBQTEt6TB3KAEAbK1MSxxKaIBvIlcteYp5bShUZFW1fTfjDLwMgS0gOUJJgER8iHBLe%2BKennPrT1bFOIkcrrN82ba1Ix2wv7Ylyrq8PVUABPiAeW1fLPnuIuA%2F5Wyg%3D%3D" rel="nofollow" target="_blank">http://xingyun.jd.com/codingRoot/newJavaEngineerOrientation/T...</a></p><p>从下图可以看出，重试次数n较大时（比如8），乘数 M 的细微变化都会导致，任务的间隔时间发生剧烈变化，因此n超过8之后，M基本不可调。</p><p>﻿<img referrerpolicy="no-referrer" src="/img/remote/1460000047556775" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><p>同样的，从下图可以看到，乘数M较大时（比如4），n的细微变化也会导致任务的间隔时间爆发式的增加。</p><p>﻿<img referrerpolicy="no-referrer" src="/img/remote/1460000047556776" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h5>1、乘数在1.5-4 的合理性</h5><p>过小乘数 (&lt;1.5) 的问题：</p><p>当乘数 = 1.2，重试 10 次的间隔时间是：1次:1, 2次:1.2, 3次:1.44, ..., 10次:5.16，</p><p>10 次重试总间隔仅 5 倍，接近固定间隔，可能导致 "惊群效应"（大量请求同时重试）。</p><p>过大乘数 (&gt;4) 的问题</p><p>当乘数 = 8，重试 5 次的间隔时间：1次:1, 2次:8, 3次:64, 4次:512, 5次:4096</p><p>5 次重试后间隔已超 1 小时（假设初始间隔时间是最小的1s，4096s&gt;1小时），可能导致请求长时间等待，用户体验差。</p><p>因此，乘数 = 1.5-4 在 "退避效率" 和 "资源消耗" 间取得平衡，一般取乘数= 2 （标准指数退避）。</p><p>行业实践：AWS SDK 默认乘数 = 2，Google gRPC 重试策略推荐乘数 = 1.5-3，多数 HTTP 客户端库 (如 requests) 默认乘数 = 2。</p><h5>2、最大重试次数3-10的合理性</h5><p>假设单次重试成功概率为P（比如网络/服务临时故障，重试成功概率通常较高），重试 n次至少成功 1 次的概率为：</p><p>﻿<img referrerpolicy="no-referrer" src="/img/remote/1460000047556777" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><p>当 p=0.5，（单次重试 50% 成功概率）：</p><p>n=3 时，成功概率 =1−(0.5)^3=87.5%</p><p>n=5 时，成功概率 =1−(0.5)^5=96.875%</p><p>n=10 时，成功概率 =1−(0.5)^10≈99.9%</p><p>实际场景中，<strong>临时故障的单次成功概率远高于 50%</strong> （比如网络抖动重试成功概率可能达 80%）</p><p>若 p=0.8，n=3时成功概率已达 1−0.2^3=99.2%几乎覆盖所有临时故障。</p><p>因此，3 - 10 次重试，能以极高概率（99%+）覆盖“临时故障”场景，再增加次数对成功概率提升极有限（边际效应递减）。</p><p>因为已知的任务延迟时间的公式是：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556778" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><p>n从1到C进行累加得到总耗时:</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556779" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><p>﻿，</p><p>根据等比数列求和公式可以得到：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556780" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><p>﻿﻿</p><p>令 M=2（常用乘数），F=1 秒（最小可能值）：</p><p>n=3时，T=（2^3-1）/（2-1）=7秒</p><p>n=5时，T=(2^5-1)/(2-1)=31秒</p><p>n=10时，T=2^10-1=1023秒≈17分钟</p><p>n=13时，T=2^13-1≈2.3小时</p><p>n=15时，T=2^15-1≈9.1小时</p><p>当n超过10后，每次增加都会导致总耗时急剧增长，很容易超过业务的容忍上限（具体业务具体分析），也可能因为重试过多，导致被调用的系统压力增加，甚至造成系统崩溃。</p><p>故：3 - 10 次重试可将总耗时控制在“业务可接受范围”（几秒到十几分钟），同时避免资源过载。</p><p>行业实践：Kafka 消费者重试：默认 10 次、Redis 客户端重试：默认 5 次、Hadoop 任务重试：默认 3-5 次、RFC 建议：RFC 6582（HTTP 重试）建议：3-5 次重试。</p><h5>3、最佳实践速查表</h5><table><thead><tr><th>参数</th><th>短期任务(分钟级)</th><th>中期任务(小时级)</th><th>长期任务(天级)</th></tr></thead><tbody><tr><td>乘数</td><td>2</td><td>2</td><td>1.75</td></tr><tr><td>重试次数</td><td>3 - 5</td><td>5 - 8</td><td>8 - 12</td></tr><tr><td>初始间隔(秒)</td><td>1 - 5</td><td>30 - 60</td><td>300 - 600</td></tr><tr><td>总耗时范围</td><td>&lt;60秒</td><td>5 - 10分钟</td><td>1 - 2小时</td></tr><tr><td>适用场景</td><td>临时网络波动 服务重启、发版</td><td>服务短暂过载</td><td>资源密集型操作</td></tr></tbody></table><h2>三、经验沉淀：异常重试机制的设计原则​</h2><p>通过这次实践和对行业方案的研究，我们总结出异常重试机制设计的四大核心原则：​</p><p>1.动态适应性原则：重试策略应支持参数化配置，根据业务场景和系统负载动态调整重试间隔和次数，避免 “一刀切” 的重试策略对系统造成冲击。​</p><p>2.幂等性保障原则：确保任务在多次重试过程中不会产生重复数据或副作用，通过唯一标识、状态机等技术手段，实现任务的幂等执行。​</p><p>3.故障隔离原则：将重试逻辑与业务逻辑分离，通过消息队列、异步调度等方式，降低重试操作对主线程的影响，避免因重试失败导致系统整体崩溃。​</p><p>4.可观测性原则：建立完善的监控和告警体系，实时追踪任务重试状态，在达到最大重试次数时及时发出告警，便于运维人员快速定位和解决问题。​</p><h2>四、结语：以技术沉淀筑牢大促防线​</h2><p>这次线上异常事件，犹如一面镜子，让我们清晰地看到了系统中的潜在风险，也为我们提供了一次宝贵的技术提升机会。通过对异常重试机制的深入研究和实践，我们不仅解决了当前问题，更将这些经验转化为团队的技术资产。在未来的 618 大促及其他关键业务场景中，我们将以更完善的技术方案、更严谨的设计原则，守护系统的稳定运行，为业务发展提供坚实的技术保障。</p>]]></description></item><item>    <title><![CDATA[【MCP】同时支持stdio，streamableHttpless和sse三种协议的MCP服务框架 ]]></title>    <link>https://segmentfault.com/a/1190000047556798</link>    <guid>https://segmentfault.com/a/1190000047556798</guid>    <pubDate>2026-01-21 19:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>作者：蔡欣彤</p><h2>项目说明</h2><p>这是一个同时支持stdio，streamableHttpless和sse三种协议的MCP-Server的框架（ts语言）。</p><p>为什么我想做这个框架呢？因为随着AI发展，现在越来越多业务需要和AI相结合。而我在做AI应用中发现，MCP服务在AI方向的业务使用频率很高，但随着业务的加深，发现存在以下痛点：</p><p>1.针对不同业务，对于mcp-server需要的类型不同，有的就需要stdio，有的需要网络请求</p><p>2.不同平台对MCP服务协议要求不同，有支持streamableHttp，有仅支持sse的。</p><p>这两种情况，会出现相同功能重复开发，重复造轮子，浪费时间成本</p><ol start="3"><li>此外，有些研发人员目前并不了解MCP，在业务开发时候需要现学</li></ol><p>而这会让研发周期加长，时间成本耗费过多</p><p>所以为了解决以上痛点，我从0-1搭建了这个框架。<strong>这个框架特点</strong>：</p><p>1.同时支持stdio，streamableHttpless和sse三种模式，实现一次开发支持三种模式</p><p>2.所有功能都拆分为独立模块。这样即使不懂的人，只要在指定的文件里面编写业务逻辑，就可以创造自己的mcp服务</p><p>3.支持环境变量，可通过环境变量配置域名，服务地址，端口和host，真正适用于生产使用</p><p>4.切换模式也很简单，只要在启动脚本根据需要，切换启动命令即可，改动成本近乎无</p><p>5.添加日志模块，方便查阅启动和服务调用情况</p><p>6.同时添加行云脚本，支持行云部署</p><p>github地址：<a href="https://link.segmentfault.com/?enc=vFqnjySlKkUZryEU3VosTw%3D%3D.quV5pahP09gJ4o7Ytxyi6gkDjidDufNTti%2B%2BwdFXx1jjW1VrY5OvLHwrfiBhhHxP" rel="nofollow" target="_blank">https://github.com/XingtongCai/mcp-server-ts</a>﻿</p><p>coding地址： <a href="https://link.segmentfault.com/?enc=ep%2BorYiW7CU%2By5MrkGlmxw%3D%3D.jXY9qmqb%2FBj%2FwAbbLSbJn0FlQZGTU1eLNhb%2BSfevvfROlDRXZQjdpHXgbJ5ewToRfcI6JUTIExrieXhgZGpxXn6jjt8CCksh6OJtX02uvQY%3D" rel="nofollow" target="_blank">http://xingyun.jd.com/codingRoot/jdcloud-fe/mcp-server/tree/m...</a></p><h2>内容介绍</h2><p>整个框架的结构很简单，就如下这些：</p><pre><code>## 目录结构
- build: 编译之后的文件
- src
 -- router: 配置streamableHttp和sse协议的路由
   -- index.ts: 注册streamableHttp路由入口
   -- mcp.ts: streamableHttp的配置路径，具体为`process.env.MCP_BASE_PATH`的路径请求,如果没有配置，默认/mcp。如果有需要添加二级路径，例如 /mcp/event，需要在这里面添加一下/event,如果一级不用动
   -- sse.ts: sse的配置路径，具体为`process.env.MCP_BASE_PATH`的路径请求,如果没有配置，默认/mcp。如果有需要添加二级路径，例如 /mcp/event，需要在这里面添加一下/event,如果一级不用动
 -- tools: mcp的工具 
   -- index.ts: 注册工具
   -- mockFunc.ts: 模拟一个工具写法 - 这部分需要根据业务开发
 -- cli.ts: 命令行解析工具
 -- index.ts: 总入口
 -- server.ts: 创建Mcp服务
 -- sse.ts: 运行sse模式
 -- stdio.ts: 运行stdio模式
 -- streamableHttp.ts: 运行streamableHttp模式
- xingyun/bin : 是根据我们业务使用的部署工具开发的部署脚本 - 这部分需要根据实际部署平台更改，我这个支持行云部署
- build_xingyun.sh: 是根据我们业务使用的部署工具开发的部署脚本 - 这部分需要根据实际部署平台更改，我这个支持行云部署
</code></pre><h3>启动服务方式</h3><p>a.本地启动</p><p>1.启动stdio: npm run start 是默认启动stdio</p><p>2.启动StreamableHttp: npm run start:http 是默认启动端口3001</p><p>3.更改端口启动StreamableHttp: npm run dev:http 或者 npm run start -- -t http -p 3001</p><p>-t httt: 代表启动StreamableHttp</p><p>-p 3001: 代表启动端口3001</p><p>4.启动sse: npm run start:sse 是默认启动端口3001</p><p>﻿</p><p>b.部署启动</p><p>我在 xingyun/bin/control.sh中写的启动脚本，这段代码是启动streamableHttpless的，如果需要启动sse，需要改为 <code>npm run start:sse</code></p><pre><code>start(){
    npm run start:http
    sleep 3
    status
}
</code></pre><h3>生产环境配置</h3><pre><code># 监听特定内网IP（例如：192.168.1.100）
export MCP_HOST=192.168.1.100
export MCP_PORT=3001

# 使用内网域名（可选）
export MCP_DOMAIN=mcp-server.internal.com

# 修改基础路径（可选，默认是 /mcp）
export MCP_BASE_PATH=/api/mcp
</code></pre><p>&lt;!----&gt;</p><pre><code>### 端口配置优先级
1. 环境变量 `MCP_PORT`（最高优先级）
2. 命令行参数 `--port` 
3. 默认值：3001端口

### 访问地址优先级
1. 环境变量 `MCP_DOMAIN`（最高优先级）
2. 环境变量 `MCP_HOST`
3. 默认: localhost
</code></pre><p>&lt;!----&gt;</p><pre><code>### 内网访问方式
假设你的内网服务器IP是 `192.168.1.100`，端口是 `3001`：

**基础访问：**
```
http://192.168.1.100:3001/sales
```

**带域名的访问：**
```
http://mcp-server.internal.com/sales
```

**自定义路径：**
```
http://192.168.1.100:3001/api/mcp
</code></pre><p>﻿</p><h2>项目关键代码说明</h2><p>这个是package.json文件，也是我们一开始要看的，<code>cli.js</code>这个文件是我们启动文件，也是解析命令行的工具，真实区分的地方在index.ts文件中</p><pre><code>"scripts": {
    "build": "tsc &amp;&amp; chmod 755 build/src/index.js  build/src/cli.js",
    "start": "node ./build/src/cli.js",
    "start:http": "node ./build/src/cli.js --transport http",
    "start:sse": "node ./build/src/cli.js --transport sse",
    "dev:http": "node ./build/src/cli.js  --transport http --port 3002",
    "stop": "pkill -f "demo" || true",
    "restart": "npm run stop &amp;&amp; npm run start:http",
    "inspector": "npx @modelcontextprotocol/inspector"
  },
</code></pre><p>index.ts 的关键代码，在这区分不同模式，然后进入到各自的处理模块。各自模块就是调用sdk，配置域名等操作，代码过长，不展示了，但是这几个文件不用动。</p><p>﻿<img referrerpolicy="no-referrer" src="/img/remote/1460000047556800" alt="在这里插入图片描述" title="在这里插入图片描述"/><br/>﻿</p><p>StreamableHttp.ts我支持的是less，就是我不需要sessionId，如果有需要的，这块需要再自己改一下！！</p><p>﻿<img referrerpolicy="no-referrer" src="/img/remote/1460000047556801" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><p>﻿﻿</p><p>server.ts 是创建mcp服务，同时注册tools工具，三个模式都需要使用的公共文件</p><p>﻿<img referrerpolicy="no-referrer" src="/img/remote/1460000047556802" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><p>tools/index.ts, 作为工具入口，一个工具一个注册</p><p>﻿<img referrerpolicy="no-referrer" src="/img/remote/1460000047556803" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><p>router文件夹下路由注册，是为了sse和streamableless的路由。</p><p>﻿<img referrerpolicy="no-referrer" src="/img/remote/1460000047556804" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><p>其中streamable的index.ts文件里面关键内容，其中basePath就是你的基础路径，通过定义指定访问路径。</p><p>﻿<img referrerpolicy="no-referrer" src="/img/remote/1460000047556805" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><p>﻿﻿</p><p>sse的在sse.ts文件中，定义了get和post的方法</p><p>﻿<img referrerpolicy="no-referrer" src="/img/remote/1460000047556806" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><p>﻿﻿</p><p>其实整个框架到这关键的代码就说完了。剩下xingyun的就是在行云平台部署和启动需要的脚本，这里就不介绍了</p><p>﻿</p><h2>成果展示</h2><p>1.stdio - 发布了依赖包，并用joycode成功联通</p><p>﻿<a href="https://link.segmentfault.com/?enc=1kriC91El74Mlzbs2d5PPQ%3D%3D.YsCOLgECgeUfbxWavYCC0YEvkw5OfVDBkY8jchLpOKtBLN6yieecesTRlSpS%2Be42iUrXgbLmVNzyCTBR%2BYHUyQ%3D%3D" rel="nofollow" target="_blank">https://npm.m.jd.com/package/@jd/demo-mcp-server</a></p><p>﻿<img referrerpolicy="no-referrer" src="/img/remote/1460000047556807" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><p>﻿</p><p>2.streamableHttp - joycode成功联通并且可以运行</p><p>﻿<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047556808" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><p>﻿<img referrerpolicy="no-referrer" src="/img/remote/1460000047556809" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><p>3.sse - autobots支持sse模式，用这个框架开发了在业务中使用的 权限拦截MCP,并成功在autobots引入</p><p>﻿<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047556810" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047556811" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[破局 AI 幻觉：构建以 NoETL 语义编织为核心的 AI 就绪数据架构 Aloudata大应科技]]></title>    <link>https://segmentfault.com/a/1190000047556472</link>    <guid>https://segmentfault.com/a/1190000047556472</guid>    <pubDate>2026-01-21 18:04:58</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>企业部署大模型分析应用时，常遭遇“幻觉”困扰——AI 输出的数据结论看似合理，实则错误。根源在于传统数据架构无法为 AI 提供准确、一致、实时、可信的数据供给。破局之道在于构建以 NoETL 语义编织为核心的 AI 就绪数据架构。该架构通过创建“统一指标语义层”作为业务与数据间的“标准协议”，并采用 NL2MQL2SQL 技术路径，确保大模型生成 100% 准确的 SQL 查询，从根本上杜绝“数据幻觉”，赋能可信的智能决策。</p><h2>传统数据架构为何成为 AI“幻觉”的温床？</h2><p>当大模型（LLM）接入企业数据时，传统数据架构的固有缺陷被急剧放大，成为制造“数据幻觉”的系统性风险源。</p><ol><li>数据孤岛与指标歧义：混乱的源头 企业内通常存在多套独立系统（CRM、ERP、财务软件等），导致同一业务指标（如“销售额”）在不同系统中的定义、计算口径和取数逻辑各不相同。当大模型从这些矛盾的数据源中检索信息时，必然输出逻辑混乱、结论错误的回答。指标口径不统一，是 AI 产生幻觉的首要原因。</li><li>“黑盒”式数据访问：错误的催化剂 主流 NL2SQL 方案让大模型直接理解原始数据库的复杂 Schema（表结构、关联关系），并生成 SQL。这要求 AI 具备数据库专家的知识，无异于“盲人摸象”。结果常出现：错误的表连接、误解的业务逻辑、性能低下的查询。生成的错误数据难以追溯和调试，幻觉在查询阶段就已注定。</li><li>僵化的数据供给：失效的决策 基于 ETL 的批处理数据管道，开发周期长达数周甚至数月。当业务人员提出一个临时、跨域的分析需求时，数据无法及时就绪。AI 基于过时、片面的数据进行分析，必然滞后于市场变化，丧失决策时效性。</li><li>可信度与安全缺失：不可逾越的鸿沟 分析结果缺乏透明的数据血缘，管理者无法信任其来源。同时，直接向 AI 开放数据库查询权限，缺乏在查询生成过程中的动态权限校验，极易导致敏感数据泄露。</li></ol><p>让大模型在“数据迷雾”中工作，幻觉是必然产出。 要获得可信 AI，必须先解决数据架构的“可信”问题。</p><h2>NoETL 数据语义编织——AI 就绪的数据架构范式</h2><p>NoETL 数据语义编织是一种创新的数据架构范式，其核心是构建一个介于原始数据与 AI 应用之间的“翻译层”与“契约层”。</p><ol><li>核心组件：统一指标语义层 这是整个架构的基石与中枢。它使用业务语言（如“毛利率”、“月活跃用户”）明确定义每一个指标的计算公式、数据来源、关联维度及刷新周期。它成为企业唯一可信的“数据事实源”，确保在任何场景（AI 查询、BI 报表、API 服务）下，同一指标的计算逻辑绝对一致，从根本上消灭了指标歧义，为 AI 提供了清晰、无矛盾的指令集。</li><li>工作原理：从“搬运”到“编织”</li></ol><ul><li>传统 ETL 模式：通过复杂的代码，将数据从源头“搬运”到数仓，过程僵化，变更成本高。</li><li><p>NoETL 语义编织：</p><ol><li>虚拟接入：通过逻辑数据编织平台，以虚拟化方式连接全域数据源，无需物理搬迁。</li><li>自动转化：系统自动扫描数据源，将技术元数据（如<code>sales_db.orders.amount</code>）与语义层的业务术语（如“订单金额”）关联。</li><li>动态查询：形成一张全局可查询的“语义网络”。用户和 AI 只需与这张网络交互，完全屏蔽底层数百张表的复杂性。</li></ol></li></ul><ol start="3"><li>架构优势：敏捷与无侵入 最大的优势在于以逻辑统一替代物理集中。数据准备时间从“数月”缩短至“数周”，并能随时根据业务变化调整语义逻辑，实现低成本、高敏捷的响应。</li></ol><h2>基于 NoETL 语义编织的可信 Data Agent</h2><p>基于 NoETL 语义层，可构建可信的 Data Agent（数据智能体）。其核心技术路径为 NL2MQL2SQL ，这是区分“玩具”与“企业级”AI 分析的关键。</p><p>三步实现 100% 准确查询：</p><ol><li>NL2MQL（自然语言→指标查询语言）：用户问：“上海地区 Q3 的销售毛利率如何？”大模型理解意图后，依据语义层，输出标准化的 MQL。例如：<code>{“metric”: “gross_profit_margin”， “filters”: {“city”: “上海”， “quarter”: “Q3”}}</code>。MQL 指向的是已定义的、无歧义的指标。</li><li>MQL2SQL（指标查询语言→SQL）：语义层引擎（规则驱动）接收 MQL，像编译器一样，根据预定义的指标逻辑（如<code>gross_profit_margin = (revenue - cost) / revenue</code>），确定性地生成优化后的 SQL。此步骤由规则保障，彻底杜绝大模型生成错误 SQL 的可能。</li><li>执行与返回：引擎通过智能路由与加速技术，高效执行 SQL，将结果返回给大模型进行解读与呈现。</li></ol><p>构建分析决策闭环： 在此可信数据基础上，Data Agent 能实现更高级的能力：</p><ul><li>智能归因：面对“利润率为何下降？”的提问，能自动进行多维度（产品、渠道、地区）下钻，定位核心影响因子。</li><li>智能报告：对“准备季度经营分析”等复杂指令，能自动规划分析框架，整合数据、洞察与建议，生成结构化报告。</li><li>场景化助手：企业可为不同部门（财务、营销、供应链）配置专属助手，每个助手基于同一语义层，但拥有不同的数据权限和知识上下文，实现安全、合规的数据民主化。</li></ul><p>NL2MQL2SQL 通过在 AI 与数据之间引入“语义层”这一关键中间件，在准确性与灵活性上取得了根本平衡，是企业构建可信数据智能的基石路径。</p><h2>常见疑问（FAQ）</h2><h4>Q1: 与传统的数据仓库或数据湖相比，NoETL 数据语义编织架构最大的优势是什么？</h4><p>传统数仓/湖依赖沉重的、周期长的 ETL 管道“搬运”和“固化”数据，变更成本高。NoETL 架构通过虚拟化和语义层，无需大规模物理搬迁数据，并能提供逻辑统一的实时数据视图，使数据准备时间从数月缩短至数周，并能灵活响应不断变化的业务分析需求。</p><h4>Q2: 引入 NoETL 和 Data Agent，企业数据团队的角色会发生怎样的变化？</h4><p>数据团队的工作重心将从繁琐的“需求响应”（写 SQL、做报表）向更高价值的“数据资产管理与赋能”转变。 团队将更专注于：1、设计和维护统一、标准的指标语义层；2、治理数据质量与安全；3、培训和配置业务部门的场景化分析助手。这释放了数据团队的生产力，聚焦于数据战略和创新。</p><h4>Q3: 如何衡量一个数据架构是否真正达到了“AI-Ready”的标准？</h4><p>可以参考“三真三好”的可信 AI 标准进行评估：三真即口径真（指标全局一致）、数据真（来源可靠、质量可控）、血缘真（计算逻辑全程可追溯）；三好即听力好（准确理解自然语言意图）、眼力好（能进行多维度、深层次的洞察与归因）、脑力好（能整合信息，形成决策建议与报告）。满足这些标准的数据架构，才能支撑起可信、有用的企业级 AI 应用。</p><h2>未来展望：</h2><p>以 NoETL 语义编织为核心的 AI 就绪架构，不仅是解决当前 AI 幻觉问题的方案，更是面向未来“数据智能时代”的基础设施。它将使数据以一种更自然、更可靠的方式服务于每一位决策者，真正实现“数据驱动”从口号到现实的跃迁。企业越早构建这一架构，就越能在智能化竞争中占据先机。</p>]]></description></item><item>    <title><![CDATA[有人试用过上百家低代码平台，踩坑太多了，其实低代码选型只要看这4点！ 织信informat ]]></title>    <link>https://segmentfault.com/a/1190000047556474</link>    <guid>https://segmentfault.com/a/1190000047556474</guid>    <pubDate>2026-01-21 18:04:08</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <blockquote>爆肝6600字，希望对你有帮助。</blockquote><p>请原谅我今天，冒昧地拉着你聊低代码——这个在IT圈火了好几年，却依然有人摸不透的话题。</p><p>“低代码”这个词，是我从业十多年来，看着从冷门工具长成行业风口的存在。</p><ul><li>为什么以前不敢深聊？因为误解太多。</li><li>有人觉得它是“玩具”，只能做些轻量表单；</li><li>有人把它神化，认为能取代全量代码开发；</li></ul><p>更有老板拿着融资新闻问我：“别人都在投，我们是不是也得跟风？”</p><p>我理解这种困惑。就像早年做传统开发时，我们总信奉“一行行敲出来的代码才靠谱”，直至亲眼见过很多企业（如中交建，国家电网，招商银行，吉利汽车等等）采用低代码把核心业务系统交付周期从半年压缩到一个月，见过那些业务人员不用求IT就能做出适配业务的功能，才彻底打破偏见。</p><p>尤其近日看到消息：</p><p>国外一家做AI原生的低代码平台：Emergent，宣布完成7000万美元B轮融资。本轮融资由Khosla Ventures和软银愿景基金2号领投，Prosus、Lightspeed、Together及Y Combinator参与投资。据悉，该平台自上线七个月以来，目前累计融资额已达1亿美元。平台主打AI低代码软件创建平台，允许业务用户通过自然语言指令生成应用程序，用户可以通过类似ChatGPT的界面输入所需软件的高级描述，生成必要的代码，并展示详细的执行步骤。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556476" alt="image.png" title="image.png"/></p><p>这波资本热度，又把低代码推上了风口。</p><p>今天这篇文章会有些长，内容有点密，但我会以一个老兵的视角，把低代码的资本逻辑、核心价值、主流平台和选型技巧讲透。相信我，无论是企业负责人、IT管理者，还是想入局的从业者，坚持看完，都会有新的启发。</p><h2>一、低代码为什么会受资本青睐？</h2><p>很多人不解，低代码又不是新概念，为何近两年资本会疯狂押注？就像当年我们疑惑“为什么三角函数非要学”，本质是没看透背后的底层逻辑。</p><p>资本的嗅觉从来不是追“新”，而是追确定性。低代码的爆发，是技术成熟、市场需求与政策导向三重共振的结果，这种确定性，让资本愿意砸下真金白银。</p><p>从技术端看，AI原生能力重构了低代码的价值边界。早年低代码只是可视化拖拽工具，而现在像Emergent这样的平台，能通过自然语言指令生成应用、输出源码并展示执行步骤，实现了从辅助编码到智能开发中枢的跨越。Gartner数据显示，AI赋能让低代码开发效率提升300%-500%，非技术人员可完成80%的基础开发工作，这种效率革命，正是资本追捧的核心逻辑之一。</p><p>从市场端看，数字化转型进入深水区，企业面临“IT产能缺口”的刚性痛点。传统开发模式下，70%的企业都在面临“业务需求等IT”的困境，而低代码能让业务与IT高效协同，将应用交付周期缩短60%以上。IDC预测，2023-2028年低代码相关市场复合年增长率达37.6%，其中智能开发技术增速更是高达47.3%，这种高增长预期，给了资本足够的信心。</p><p>再看政策端，信创国产化浪潮推动低代码成为核心基础设施。国企、金融、军工等关键行业，对低代码平台的需求从“能用”，升级为全栈信创适配，具备国产芯片、操作系统、数据库全链路兼容能力的平台，已成为政企项目的首选。这种政策驱动下的刚需市场，进一步锁定了低代码的增长确定性。</p><p>Emergent的融资不是个例，它只是资本拥抱低代码赛道的一个缩影。当一个工具能解决企业的核心效率痛点，又踩中技术与政策的风口，资本的涌入只是时间问题。</p><h2>二、低代码的价值几何？</h2><p>聊完资本，我们回归本质：对企业而言，低代码的核心价值到底是什么？就像学数学不是为了刷题，而是培养逻辑思维，低代码的价值也远不止快。</p><p>我见过太多企业误用低代码。把它当成节省人力成本的工具，最后因场景错配导致项目失败。其实低代码的价值，是重构企业的数字化能力底座，体现在三个核心维度。</p><p>第一，打破业务与IT的壁垒，释放组织创新力。</p><p>传统模式下，业务人员有想法却无法落地，IT团队有技术却不懂业务，AI低代码产品让业务人员能通过可视化操作、自然语言描述实现“想法即应用”，IT团队则聚焦核心复杂场景的优化。比如北京的一家国有银行用AI低代码产品搭建信贷风控系统，业务人员直接参与规则配置，审批效率提升60%，这就是协同价值的最好体现。</p><p>第二，适配全场景需求，拓宽数字化边界。</p><p>早年低代码被局限在轻量办公场景，如今通过高低代码融合架构，既能满足中小企业2小时上线轻量应用的需求，也能支撑大型企业核心业务系统的开发。比如我们团队去年用织信低代码交付项目，你想都不敢想，低代码居然能承载制造企业的复杂BOM多级管理，并且数据处理能力达亿万级，彻底打破了我们对低代码的刻板印象。</p><p>第三，降低数字化门槛，实现普惠式转型。</p><p>对中小企业而言，组建专业开发团队成本高昂，低代码的“开箱即用”特性的让它们能以极低成本完成数字化起步；对大型企业而言，低代码能快速响应前端业务变化，比如广东某快消品牌公司用微搭开发会员小程序，3天就完成上线，首月会员转化率提升28%。</p><p>因此对于低代码，我们可以确定的就是：低代码要做的事，不是取代传统开发，而是补充与升级。低代码通过组件化的搭建模式能解决80%的标准化场景需求，而剩下20%的核心复杂场景，我们可以通过低代码平台提供的AI+自定义代码模块的方式，与低代码协同，共同完成。认清这一点，我们才能真正发挥它的价值。</p><h2>三、国内同样优秀的低代码产品有哪些？</h2><p>聊完价值，就到了大家最关心的部分。国内有哪些靠谱的低代码平台？结合Forrester、Gartner及中国信通院的评估框架，再加上我十多年的项目实操经验，整理了国内TOP10低代码平台，从评分、能力到特色逐一拆解，供大家参考。</p><p>说明：本次评分基于技术成熟度、行业适配能力、信创合规、生态集成、服务保障五大维度（满分100分），兼顾不同规模企业的需求，排名不分绝对先后，核心看场景适配度。</p><p>1.织信Informat</p><p>评分：99.8分</p><p>介绍：国内全栈可视化低代码的标杆平台，凭借“复杂场景承载+陪跑式交付”的核心能力，稳居金融、制造、政务、军工等高端场景选型前列。作为最早布局AI原生低代码的厂商之一，织信已实现自然语言转领域模型准确率超82%，支持从需求定义到部署运维的全生命周期开发。</p><p>特色：一是模块化搭建能力突出，内置5000+可复用组件与200+集成适配器，能无缝对接ERP、CRM及国产数据库。二是信创全栈适配，通过安全等保、DCMM认证，兼容麒麟OS、飞腾芯片等全链路国产软硬件；三是高低代码深度融合，既支持业务人员拖拽开发，也允许技术人员嵌入Java、js代码进行定制，彻底摆脱系统二开困境。</p><p>2.ZOHO Creator</p><p>评分：97.9分</p><p>介绍：全球化低代码平台，在国内市场深耕多年，凭借“轻量化+高集成”的特点，成为中小企业与出海企业的优选。</p><p>特色：与ZOHO生态内CRM、HRM、财务等产品无缝衔接，无需额外开发即可实现业务闭环；操作门槛极低，业务人员经简单培训即可独立开发应用；支持私有化部署与云端部署双模式，适配不同合规需求，同时具备多语言支持能力，适合出海企业搭建全球化应用。</p><p>3.普元低代码平台</p><p>评分：96.7分</p><p>介绍：专注国内信创低代码领域，拥有20年企业级技术沉淀，核心服务于国有大行、制造、军工等关键行业，是国内首批通过信通院“先进级”认证的低代码平台。</p><p>特色：以“AI+模型驱动”为核心，支持自然语言转代码、智能流程优化，开发效率提升40%以上；在复杂场景下表现突出，某国有银行总行用其构建核心系统，异常订单处理周期缩短87.5%；信创适配能力行业顶尖，实现芯片-操作系统-数据库-中间件全链路兼容，是核心业务系统的首选之一。</p><p>4.网易CodeWave</p><p>评分：95.2分</p><p>介绍：国内唯一实现“低代码开发+源码交付”双模式的平台，主打全栈可视化开发，兼顾技术团队的灵活性与业务团队的易用性，客户覆盖中石油、工商银行等大批国央企。</p><p>特色：自研NASL编程语言实现前后端全流程可视化，支持多端应用一体化开发；金融级安全架构亮眼，系统稳定性达99.99%，泰康人寿基于其开发80余个核心业务应用，直接节省开发成本160余万元；资产中心沉淀海量可复用组件，进一步提升开发效率。</p><p>5.浪潮inBuilder</p><p>评分：94.8分</p><p>介绍：依托浪潮集团在政务与制造业的深厚积累，以UBML（统一业务建模语言）技术为核心，是垂直领域解决方案的代表平台。</p><p>特色：天然适配信创生态，可直接生成适配国产软硬件的应用代码；在政务领域表现突出，某省会城市工程审批系统经其重构后，审批周期从15天压缩至48小时；预置MQTT连接器与IoT监控模板，覆盖25%的智能工厂场景，是制造业数字化转型的利器。</p><p>6.华为云AppCube</p><p>评分：94.5分</p><p>介绍：面向企业级复杂应用场景的云原生低代码平台，强调高并发、高可靠与多端适配能力，深度联动华为云Stack与鸿蒙系统。</p><p>特色：支持小程序、H5、PC及鸿蒙原生应用一体化开发；内置IoT引擎可对接各类工业设备，某汽车厂商用其开发智能产线监控系统，故障预警准确率达92%；通过多项合规认证，适配全部主流国产软硬件，在工业制造、政务服务领域优势明显。</p><p>7.腾讯云微搭WeDa</p><p>评分：93.6分</p><p>介绍：深度绑定微信生态的低代码平台，主打“快速开发+生态协同”，成为电商、社交类应用的首选工具。</p><p>特色：实现小程序、公众号、视频号全链路开发支持，从创建到上架微信生态仅需3步，自带微信支付、担保交易等原生能力；2025年升级的AI组件库，可智能生成营销页面、推荐表单字段；支持云开发与私有化部署双模式，适配从初创企业到中大型企业的不同需求。</p><p>8.用友YonBuilder</p><p>评分：93.5分</p><p>介绍：与用友ERP深度绑定的低代码平台，专为集团企业ERP二次开发设计，已服务超10万家用友ERP客户。</p><p>特色：与用友U9 Cloud等ERP系统适配度达98%，确保财务数据无缝流转；支持可视化配置与Java定制开发灵活切换，2025年升级的Agent平台2.0，可通过AI对话完成财务模块规则配置；在财务、人力、供应链等场景解决方案成熟度领先，是集团企业数字化延伸的核心工具。</p><p>9.简道云</p><p>评分：92.8分</p><p>介绍：帆软旗下轻量型低代码平台，以“表单驱动+数据洞察”为核心，是部门级轻量应用的标杆产品。</p><p>特色：操作门槛极低，业务人员1小时培训即可独立开发；表单设计支持200+字段类型与复杂逻辑配置，搭配拖拽式仪表盘，实现数据采集到分析的闭环；在零售、医疗等轻量场景表现优异，某连锁品牌用其搭建门店巡检系统，问题整改率提升40%，但复杂业务逻辑承载能力较弱。</p><p>10.泛微e-builder</p><p>评分：92.5分</p><p>介绍：全栈式低代码平台，依托泛微在协同办公领域的积累，主打中大型企业业务流程管理场景。</p><p>特色：支持无代码与全代码混合开发，智能化构建能力突出；与泛微OA系统深度集成，擅长流程自动化场景搭建；在组织权限管理、流程审批优化方面优势明显，适合中大型企业构建一体化协同办公系统。</p><h2>四、国外主流产品介绍</h2><p>国外低代码市场起步更早，形成了成熟的竞争格局，尤其在AI原生、全球化生态方面具备优势，适合有海外业务、追求前沿技术的企业。</p><p>1.Mendix</p><p>核心定位：企业级低代码标杆，主打模型驱动+全生命周期管理。</p><p>作为国外低代码市场的老牌玩家，Mendix在大型企业复杂应用开发领域口碑出众。支持高低代码融合，具备强大的跨平台部署能力与生态集成性，可对接SAP、Oracle等主流企业级系统。其模型驱动架构能确保应用的一致性与可维护性，适合金融、制造等行业的核心业务系统搭建，但定价较高，本地化适配能力弱于国内平台。</p><p>2.OutSystems</p><p>核心定位：高速低代码平台，主打极致开发效率。</p><p>以开发速度著称，通过可视化拖拽、智能调试功能，能大幅缩短应用交付周期。支持多端应用一体化开发，具备强大的性能优化工具，可应对高并发场景。在欧美市场渗透率高，适合追求快速上线、对性能有要求的企业，但信创适配能力几乎为零，不适合国内政企客户。</p><p>3.Microsoft Power Apps</p><p>核心定位：生态协同型低代码，依托微软生态优势。</p><p>深度集成Office 365、Azure、Dynamics 365等微软产品，适合已经使用微软生态的企业。操作门槛低，支持快速搭建轻量应用，同时具备一定的定制化能力。AI组件与自动化流程（Power Automate）联动紧密，能实现业务流程的全自动化。其核心优势在于生态协同，但复杂业务逻辑承载能力有限，适合中小企业、部门级应用场景。</p><p>4.Appian</p><p>核心定位：BPM+低代码融合，主打流程自动化。</p><p>将低代码与业务流程管理（BPM）深度结合，擅长复杂流程建模与自动化场景。在合规性、流程监控方面表现突出，适合金融、医疗等对流程管控要求严格的行业。支持云端与私有化部署，具备强大的数据分析与报表能力，但学习成本较高，价格昂贵，适合大型企业的高端流程场景。</p><p>5.Emergent</p><p>核心定位：AI原生低代码先驱，主打自然语言驱动开发。</p><p>作为近期资本追捧的焦点，Emergent最大的特色的是彻底降低开发门槛。用户通过类似ChatGPT的界面输入应用需求描述，平台即可生成必要代码、梳理执行步骤，非技术人员也能独立完成应用开发。上线七个月累计融资达1亿美元，背后是资本对其“AI重构开发链路”模式的认可。其核心优势在于AI模型的精准度与开发流程的简化，适合快速验证业务想法、搭建轻中度复杂度应用，但目前在复杂核心系统承载、本地化服务方面仍需完善。</p><h2>五、低代码选型指南</h2><p>从业十多年，我见过太多选型失误导致项目翻车的案例。</p><p>有的企业盲目追求AI功能，忽略了信创合规要求；</p><p>有的中小企业贪大求全，选了复杂的开源低代码平台，最后用不起来。</p><p>其实选型没有标准答案，核心是匹配自身需求，结合我的经验，总结了四大核心原则。</p><p>1.先明确场景，再选平台</p><p>这是选型的第一优先级。不同场景对应不同类型的平台，选错场景再强的平台也无用：</p><p>大型企业核心系统、信创项目：优先选织信、普元、浪潮这类具备信创全栈适配、复杂场景承载能力的平台，务必通过POC（概念验证）测试其并发性能、源码扩展能力。</p><p>中小企业轻量应用、协同办公场景：选网易CodeWave、简道云、腾讯云微搭，侧重易用性、快速部署能力与性价比，按需订阅的定价模式更适合控制成本。</p><p>电商、社交类应用：优先选腾讯云微搭（微信生态）、Power Apps（微软生态），依托生态原生能力快速搭建应用。</p><p>出海企业、全球化应用：选ZOHO Creator、Mendix，关注多语言支持、全球服务器部署与本地化合规能力。</p><p>2.技术兼容性考虑</p><p>技术层面要重点关注两点：一是信创适配，二是扩展性。</p><p>对国企、金融等关键行业，必须确认平台是否通过安全等保、DCMM等合规认证，是否兼容指定的国产芯片、操作系统与数据库，避免后期无法通过项目验收。</p><p>对所有企业，都要着重考虑平台的拓展性问题。优先选支持代码拓展、API接口开放、支持第三方系统集成的平台（如织信、网易CodeWave），确保后期业务扩张或更换平台时，数据与应用能平滑迁移。</p><p>3.关注生态与服务</p><p>低代码项目的成功，70%靠平台，30%靠服务。尤其对技术团队薄弱的企业，服务能力至关重要。</p><p>选型时要考察：平台是否有完善的培训体系、技术支持响应速度（最好能提供7×24小时支持）、用户社区活跃度（是否有丰富的组件模板与问题解决方案）。国内平台在本地化服务方面普遍优于国外平台，这也是很多企业优先选国内产品的核心原因。</p><p>4.学会用POC验证能力</p><p>再好的宣传都不如实际测试。选型时一定要要求厂商提供试用期，通过POC测试验证平台的实际能力：比如模拟核心业务流程搭建应用，测试开发效率；模拟高并发场景，测试系统稳定性；尝试与现有系统集成，测试适配性。</p><p>建议组建“业务+IT”联合测试团队，业务人员评估易用性，IT团队评估技术性能，确保平台能满足双方需求。</p><p><strong>结语：</strong></p><p>低代码的本质，是让数字化回归业务本身。是把数字化能力交还给业务人员，让技术真正服务于业务，而不是反过来束缚业务。</p><p>2026年，AI原生、信创适配、高低代码融合将成为低代码市场的核心趋势，无论是国内还是国外平台，都在朝着“更智能、更兼容、更易用”的方向迭代。对企业而言，与其追逐资本热点，不如静下心来梳理自身需求。选对适合自己的平台，让低代码真正成为数字化转型的加速器，才是最有价值的选择。</p><p>最后，如果你在选型过程中遇到具体场景的困惑，比如“制造企业该如何选型低代码”，“中小企业预算有限该如何取舍”，欢迎在评论区留言，我将结合多年项目经验，给你更多针对性建议。</p>]]></description></item><item>    <title><![CDATA[寻找 AI 全能王——阿里云 Data+AI 工程师全球大奖赛正式开启 阿里云大数据AI ]]></title>    <link>https://segmentfault.com/a/1190000047556483</link>    <guid>https://segmentfault.com/a/1190000047556483</guid>    <pubDate>2026-01-21 18:03:36</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在大模型迈向“专业决策”的关键拐点，数据质量与智能体能力正成为AI落地的核心引擎。语料重复、噪声泛滥，如何高效构建万亿级高质量训练数据？通用问答已成过去，企业呼唤能理解业务、调用工具、自主推理的AI智能体——真正的“所想即所得”，正在从愿景走向工程实践。</p><p>在此背景下，2026年1月11日起，阿里云联合 NVIDIA 正式发起“寻找AI全能王”——Data+AI工程师全球大奖赛，面向全球高校学子与企业开发者，开启一场覆盖“数据处理”与“智能体构建”的全链路AI工程实战。<br/><img width="723" height="206" referrerpolicy="no-referrer" src="/img/bVdnHL1" alt="" title=""/><br/><a href="https://link.segmentfault.com/?enc=kl5hRL4ZhES%2Fi88cW%2B1h7g%3D%3D.L%2BVet2dGzmdnMgzrtSOjaayHN2oxcSTU%2FtSmzFfZpxTwdtLh79SebzOFk3ZBfD14bbNuZwyBHNnykg%2B%2B%2BPrb8w%3D%3D" rel="nofollow" target="_blank">大赛官网 &gt;&gt;</a><br/>本次大赛设置 高校赛道 与 企业赛道，双轨并行、独立评审，聚焦两大前沿挑战：</p><p><strong>赛题1 - 向下深挖：挑战万亿语料去重极限</strong><br/>基于 MaxCompute MaxFrame + DataWorks，直面海量互联网数据中的重复与噪声，系统性提升超大规模数据去重的计算效率与精度，攻克工业级数据预处理难题。</p><p><strong>赛题2 - 向上突破：构建 DeepSearch 智能体</strong><br/>基于 PAI-LangStudio，在真实业务场景中构建具备意图理解、多步推理、工具调用与结果验证能力的 AI Agent，实现从自然语言到知识洞察、从查询指令到自动化执行的端到端闭环，推动 AI Agent 应用规模化落地。</p><p>在这里你将收获：</p><ul><li>丰厚现金奖励与官方认证荣誉瓜分高额奖金池，斩获最高7万元大奖，并获得阿里云官方认证的获奖证书，为个人能力加冕。单赛题所有 Top100 完赛队伍均可获得价值200元完赛礼包，另有征文活动赢取定制好礼。</li><li>与顶尖技术专家深度对话赛事期间将开放导师答疑与赛题解析环节，优秀选手更有机会与阿里云技术专家面对面交流，获取专业指导与发展建议。</li><li>真实场景下的全链路AI工程历练基于 MaxFrame、PAI-LangStudio 等工业级平台，在万亿规模语料处理与智能体构建中，掌握从数据清洗到Agent推理的端到端实战能力，积累可落地的技术经验。 </li></ul><p>这不仅是一场比赛，更是 Data 与 AI 深度融合的产业试验场。优秀成果将有机会被纳入阿里云产品技术演进，成为驱动 AI 原生时代的关键组件。</p><p>以代码驱动变革，用数据释放智能——AI全能王，等你来战！<br/>立即报名参赛：<br/>高校赛道<a href="https://link.segmentfault.com/?enc=uAttTB5XTV7Cz54VtRyqOg%3D%3D.hfHEbQbr0LfyYogcXDmzEsijZ0oh0LgbKKJBTohjlJUoV9CqKhXk7ZhjgirfKV2wCJMhpr%2FwdZu6SnFYzkpHcQ%3D%3D" rel="nofollow" target="_blank">https://tianchi.aliyun.com/competition/entrance/532448</a><br/>企业赛道<a href="https://link.segmentfault.com/?enc=WjWJbqWBmxK8tqXtbnB%2BNQ%3D%3D.FfvXuurHsyPSYmN21SOo8OAkIoCPBuZ7%2BHh4STFBK9oBNEdHQ2RIRQvGItXbc53bLcz0%2FXBqUr75Y3S1KxIppw%3D%3D" rel="nofollow" target="_blank">https://tianchi.aliyun.com/competition/entrance/532449</a><br/><img width="723" height="2378" referrerpolicy="no-referrer" src="/img/bVdnHL9" alt="" title="" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[掌握 C# PDF 打印：Spire.PDF 助您一臂之力 宇文成都 ]]></title>    <link>https://segmentfault.com/a/1190000047556498</link>    <guid>https://segmentfault.com/a/1190000047556498</guid>    <pubDate>2026-01-21 18:02:47</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在当今数字化的世界中，PDF（便携式文档格式）已成为文档分享和打印的标准格式。作为开发者，能够通过代码操作和打印 PDF 文档是非常实用的。本文将介绍如何使用 <strong>Spire.PDF for .NET</strong> 库打印 PDF 文档，详细说明安装步骤以及代码解析，帮助您快速上手。</p><h2>Spire.PDF for .NET 简介</h2><p><strong>Spire.PDF for .NET</strong> 是一个功能丰富的 PDF 处理库，它使开发者可以在 C# 应用程序中创建、修改和打印 PDF 文件。该库不仅支持基本的 PDF 操作，还提供许多高级功能，如文本和图像提取、PDF 文件合并和安全性设置等。</p><h3>主要特性</h3><ul><li><strong>创建和编辑 PDF</strong> ：支持创建新的 PDF 文档和对现有文档进行编辑。</li><li><strong>打印功能</strong> ：能够打印 PDF 文档到默认或指定打印机，灵活便捷。</li><li><strong>文件转换</strong> ：能够将 PDF 文件转换为 Word、Excel 等格式，方便后续的编辑。</li><li><strong>安全性</strong> ：支持对 PDF 文件进行加密、解密和密码设置，确保文档安全。</li></ul><h2>安装 Spire.PDF for .NET</h2><p>要在项目中使用 Spire.PDF，您需要先将其安装。安装的方法有以下两种：</p><ol><li><p><strong>使用 NuGet 安装</strong> ：</p><ul><li>打开 Visual Studio，点击“工具”-&gt;“NuGet 包管理器”-&gt;“包管理器控制台”。</li><li><p>输入以下命令并运行：</p><pre><code>Install-Package Spire.PDF</code></pre></li></ul></li><li><p><strong>使用 Visual Studio GUI</strong> ：</p><ul><li>在解决方案资源管理器中右键点击您的项目，选择“管理 NuGet 包”。</li><li>在搜索框中输入“Spire.PDF”，找到并点击安装相关包。</li></ul></li></ol><p>这两种方法都可以将 Spire.PDF 库添加到您的项目中，便于后续使用。</p><h2>打印 PDF 文档的代码示例</h2><p>以下是一个简单的 C# 控制台应用程序示例，展示如何打印 PDF 文档：</p><pre><code>using Spire.Pdf;

namespace PrintWithDefaultPrinter
{
    class Program
    {
        static void Main(string[] args)
        {
            // 创建一个 PdfDocument 对象
            PdfDocument doc = new PdfDocument();

            // 加载 PDF 文件
            doc.LoadFromFile("C:/Users/Administrator/Desktop/Input.pdf");

            // 设置打印机名称
            doc.PrintSettings.PrinterName = "Your Printer Name";

            // 设置打印页面范围
            doc.PrintSettings.SelectPageRange(1, 5); // 打印第 1 到第 5 页

            // 设置打印份数
            doc.PrintSettings.Copies = 2;

            // 设置为黑白打印
            doc.PrintSettings.Color = false;

            // 检查打印机是否支持双面打印
            if (doc.PrintSettings.CanDuplex)
            {
                doc.PrintSettings.Duplex = Duplex.Default; // 设置为默认双面打印
            }

            // 打印到默认打印机
            doc.Print();

            // 清理资源
            doc.Dispose();
        }
    }
}</code></pre><h3>代码解析</h3><ul><li><strong>创建 PdfDocument 对象</strong> ：初始化一个新的 <code>PdfDocument</code> 对象，用于加载和操作 PDF 文件。</li><li><strong>加载 PDF 文件</strong> ：通过 <code>LoadFromFile</code> 方法加载指定路径的 PDF 文件。请确保文件路径正确且文件存在。</li><li><strong>设置打印机名称</strong> ：使用 <code>PrinterName</code> 属性指定打印机。如果不设置，则文档会打印到默认打印机。</li><li><strong>选择打印页码范围</strong> ：通过 <code>SelectPageRange</code> 方法指定需要打印的页码范围，例如仅打印前五页。</li><li><strong>打印份数和颜色设置</strong> ：使用 <code>Copies</code> 属性设置打印份数，同时通过 <code>Color</code> 属性选择是否以彩色打印。设置为 <code>false</code> 表示以黑白打印。</li><li><strong>双面打印</strong> ：通过 <code>CanDuplex</code> 属性检查打印机是否支持双面打印。如果支持，则设置 <code>Duplex</code> 为默认双面打印选项。</li><li><strong>打印到默认打印机</strong> ：调用 <code>Print</code> 方法将加载的文档发送到指定的打印机。</li><li><strong>资源清理</strong> ：使用 <code>Dispose</code> 方法释放所有占用的资源，避免内存泄漏。</li></ul><h2>总结</h2><p>使用 <strong>Spire.PDF for .NET</strong> 打印 PDF 文档是一个简单而强大的解决方案。通过本文中的示例代码和解析，您可以快速上手实现 PDF 文档的打印功能。希望这篇文章能够帮助您更好地利用 C# 进行 PDF 打印开发工作！</p>]]></description></item><item>    <title><![CDATA[AI面试破局深水区：从工具迭代到价值重构 爱跑步的香蕉_cKtiNz ]]></title>    <link>https://segmentfault.com/a/1190000047556544</link>    <guid>https://segmentfault.com/a/1190000047556544</guid>    <pubDate>2026-01-21 18:02:10</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>AI面试破局深水区：从工具迭代到价值重构<br/>随着数字化转型进入深水区，AI技术在人力资源领域的应用早已超越“尝鲜”阶段，尤其是AI面试，正从简单的流程辅助工具，转变为重塑招聘生态、优化人才匹配效率的核心引擎。当企业招聘从“海量筛选”转向“精准识别”，从“成本控制”转向“价值创造”，AI面试的行业竞争逻辑也发生了根本性变化，单纯的功能叠加已无法满足市场需求，聚焦价值落地与生态适配成为新的行业共识。<br/>当前，企业对AI面试的核心诉求已从“有没有”升级为“好不好用、能不能信”。此前，部分AI面试产品因缺乏科学的评估体系，评分标准模糊、结果一致性不足，导致HR仍需投入大量精力二次核验，未能真正实现提效目标；同时，候选人在面对机械的问答流程时，常出现表达不充分、体验感不佳等问题，甚至影响对招聘企业的第一印象。这些痛点，本质上反映了AI面试产品在技术落地与人文关怀之间的失衡，也是行业进入深水区后必须破解的核心课题。<br/>破解上述困境，关键在于实现技术理性与人文温度的双向融合。从技术层面来看，可靠的AI面试系统需构建全链路的科学评估体系，而非单一维度的语音或文本分析。这要求产品不仅能精准提取候选人的语言表达、逻辑思维等显性特征，更能通过情绪识别、微行为分析等技术，捕捉候选人的职业素养、抗压能力等隐性特质。同时，借助大数据算法与心理学模型的深度结合，建立可追溯、可验证的评分机制，确保评估结果的公信力，让AI真正成为HR的“专业搭档”而非“辅助工具”。<br/>从用户体验层面而言，AI面试的核心是“以人为本”，而非技术的单向输出。优秀的AI面试产品应打破“人机对抗”的刻板印象，构建更具包容性的交互场景。例如，通过自适应问答技术，根据候选人的回答节奏与内容灵活调整问题难度与方向，给予候选人充分的表达空间；结合多模态交互手段，将文字、语音、视频等形式深度融合，模拟真实面试中的沟通氛围，缓解候选人的紧张情绪；针对不同岗位、不同群体的需求，提供个性化的面试流程设置，让AI面试既能满足企业的评估需求，也能兼顾候选人的体验感受。<br/>值得注意的是，AI面试的价值落地离不开与企业招聘生态的深度适配。不同行业、不同规模的企业，其招聘场景与人才需求存在显著差异：大型企业更看重规模化招聘中的一致性与效率，中小企业则更关注产品的易用性与成本可控性，科技类岗位侧重专业能力的精准评估，管理类岗位则更注重综合素养的全面考察。这就要求AI面试产品不能追求“一刀切”，而需具备高度的定制化能力，通过模块化设计与开放接口，适配企业现有的招聘系统与流程，实现从简历初筛、面试评估到结果归档的全流程闭环管理。<br/>未来，AI面试的发展将更加聚焦“价值重构”，其核心竞争力将体现在三个维度：一是技术的深度，即基于前沿算法与多学科融合的精准评估能力；二是体验的温度，即兼顾企业与候选人双向需求的人性化交互设计；三是生态的广度，即适配多元招聘场景的定制化与兼容性。当AI面试真正实现“精准识别人才、高效匹配需求、友好连接双方”的核心价值，其将不再是招聘流程中的一个环节，而是推动人力资源行业数字化转型的重要力量，为企业人才战略落地与个人职业发展赋能。</p>]]></description></item><item>    <title><![CDATA[使用 podman 安装 RustFS 的两种方式 RustFS ]]></title>    <link>https://segmentfault.com/a/1190000047556553</link>    <guid>https://segmentfault.com/a/1190000047556553</guid>    <pubDate>2026-01-21 18:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>RustFS 支持容器化部署模式，可以用 <code>docker run</code> 命令或 <code>docker compose</code> 来快速安装一个 RustFS 实例。由于 podman 也是一个可以对容器进行管理的工具，大多数情况下是可以兼容 docker 命令的。因此，也可以用 podman 对 RustFS 进行容器化安装。本文分享两种安装方式。</p><h2>安装前提</h2><ul><li>podman 环境，本文所需的 podman 环境信息如下</li></ul><pre><code># podman 版本
podman --version

# podman-compose 版本
podman-compose --version
podman-compose version: 1.0.6
['podman', '--version', '']
using podman version: 4.9.3
podman-compose version 1.0.6
podman --version 
podman version 4.9.3
exit code: 0</code></pre><h2>安装方式</h2><p>可以使用 <code>podman run</code> 或 <code>podman compose</code> 进行安装。</p><h3>podman run 安装</h3><p>使用如下命令即可：</p><pre><code>podman run -d -p 9000:9000 -p 9001:9001  \
    -v $(pwd)/data:/data -v $(pwd)/logs:/logs \
    docker.io/rustfs/rustfs:latest</code></pre><blockquote>注意，需要把 <code>data</code>、<code>logs</code> 目录的权限改成 10001，因为 RustFS 是非 root 用户运行，不修改权限，会导致权限问题。</blockquote><p>查看容器状态：</p><pre><code>podman ps
CONTAINER ID  IMAGE                           COMMAND     CREATED       STATUS       PORTS                             NAMES
593c5bffbce9  docker.io/rustfs/rustfs:latest  rustfs      21 hours ago  Up 21 hours  0.0.0.0:9000-9001-&gt;9000-9001/tcp  exciting_herschel</code></pre><h3>podman compose 安装</h3><p>将如下内容写入 <code>podman-compose.yml</code> 文件：</p><pre><code>services:
  rustfs:
    image: docker.io/dllhb/disk-cap:0.0.1
    container_name: rustfs
    hostname: rustfs
    environment:
      - RUSTFS_VOLUMES=/data/rustfs{1...4}
      - RUSTFS_ADDRESS=0.0.0.0:9000
      - RUSTFS_CONSOLE_ENABLE=true
      - RUSTFS_CONSOLE_ADDRESS=0.0.0.0:9001
      - RUSTFS_ACCESS_KEY=rustfsadmin
      - RUSTFS_SECRET_KEY=rustfsadmin
      - RUST_LOG=warn
    ports:
      - "9000:9000"  # API endpoint
      - "9001:9001"  # Console
    volumes:
      - ./data1:/data/rustfs1
      - ./data2:/data/rustfs2
      - ./data3:/data/rustfs3
      - ./data4:/data/rustfs4

    networks:
      - rustfs

networks:
  rustfs:
    driver: bridge
    name: rustfs</code></pre><p>接着执行：</p><pre><code>podman compose up -d</code></pre><p>查看容器状态：</p><pre><code>podman compose ps
CONTAINER ID  IMAGE                           COMMAND          CREATED             STATUS             PORTS                             NAMES
f6496b7856f3  docker.io/dllhb/disk-cap:0.0.1  /usr/bin/rustfs  About a minute ago  Up About a minute  0.0.0.0:9000-9001-&gt;9000-9001/tcp  rustfs</code></pre><blockquote>注意，需要把 <code>data*</code> 目录的权限改成 10001，因为 RustFS 是非 root 用户运行，不修改权限，会导致权限问题。</blockquote><h3>使用 RustFS</h3><p>不管用哪种方式，当 RustFS 运行正常后，就可以通过 <code>http://IP:9001</code> 的方式登录 RustFS，默认用户名和密码都是 <code>rustfsadmin/rustfsadmin</code>。</p><p><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdnHNo" alt="" title=""/></p>]]></description></item><item>    <title><![CDATA[不止于替换 HBase：宝付支付借力 OceanBase，构建面向未来的“TP+AP+KV+AI”统]]></title>    <link>https://segmentfault.com/a/1190000047556146</link>    <guid>https://segmentfault.com/a/1190000047556146</guid>    <pubDate>2026-01-21 17:10:49</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>作者：杨泽，宝付支付数据团队负责人</p><p>随着#数字化转型 升级进入关键期，数据库已从被动的存储仓库，转变为主动赋能业务的智能数据中枢。以现代金融行业为例，业务对数据库提出了更高要求：既要满足事务，又要实时分析，同时安全、高效、弹性、智能地处理多模数据，并支撑实时决策与业务创新。这意味着，符合要求的数据库需在TP、AP、KV、AI方向均具备出色的数据处理能力。</p><p>作为在银行、消费金融、零售、跨境等行业深耕多年的一站式综合支付解决方案商，宝付支付产品种类丰富，且深谙技术创新与业务稳健的关系，不断引进先进技术维护和保障公司业务稳步运行，全方位为商户资金安全和交易安全保驾护航。</p><p>近年来，宝付支付的原数据库方案已不能满足业务需求，故而寻求技术升级。本文分享宝付支付在KV场景使用OBKV替换HBase的技术实践。</p><h3><strong>出于架构痛点，寻求支持 TP+AP + KV + AI 的数据库</strong></h3><p>宝付支付所属集团——漫道集团采用基于MySQL的集中式架构，由于近年来业务高速增长（2023 年初交易量约 3000万笔/日，2024 年 12月 已突破 9000 万笔/日）带来的海量数据（TB级），系统压力陡增。</p><p>最直观的压力便是成本压力，<strong>每年存储采购预算高达数千万元</strong>。同时，为了保障部分业务系统的高可用性，需在 A/B 两个机房部署完全对等的 MySQL 双活架构集群（如各100 台服务器），导致硬件与运维成本成倍增长。</p><p>同时在双活架构下，业务层仅关注“订单不丢、实时写入”，但不关心数据最终落在哪个机房、哪个分库。这给数据团队带来巨大挑战：<strong>无法准确追踪数据源，难以构建统一的数据视图</strong>，ETL 与实时同步逻辑异常复杂。</p><p>在业务种类多样的情况下，长期使用MySQL还会导致架构越来越复杂，使运维压力极大。集团内部运行着十余套大数据集群和超过 1000 个 MySQL 实例，分别服务于支付、风控、征信、BI 等不同场景，对数据库有不同的需求。</p><ul><li>支付交易系统：要求高并发、低延迟的事务处理能力。</li><li>风控系统：依赖实时数据分析与毫秒级决策。</li><li><h2>征信 用户画像业务：需要高性能 KV 存储与快速点查。</h2></li><li>BI 系统：依赖大规模离线分析计算。</li></ul><p><strong>多套异构系统并行，导致开发、监控、备份、扩容等运维工作极其繁重。</strong></p><p>除MySQL外，我们使用 #HBase 存储海量日志与宽表，其虽具备高吞吐写入能力，<strong>但在事务支持、复杂查询、实时分析、KV 混合负载等方面存在明显短板</strong>，已无法满足新一代业务需求。</p><p>基于上述挑战，我们开始评估新一代分布式数据库方案。文章开头提到现代金融行业的业务对数据库提出了多种要求。宝付支付作为金融行业的一员也不例外，<strong>根据对TP、AP、KV、AI方向的需求，我们首先想到了 <strong><em><em>#OceanBase</em></em></strong>，核心原因在于其原生支持 HTAP（混合事务/分析处理） + KV + AI 的一体化架构。</strong></p><ul><li>TP 能力：满足支付交易系统的高并发、强一致性要求。</li><li>AP 能力：支撑风控与 BI 的实时分析需求。</li><li>KV 接口：为征信等场景提供低延迟点查。</li><li>AI 能力：内置向量化引擎与 AI 原生能力，为后续智能风控、实时推荐等 AI 应用奠定基础。</li></ul><p><strong>为控制风险，我们采取“由边缘到核心”的渐进式改造路径</strong>：先在非关键系统验证 OceanBase 稳定性，逐步迁移风控、征信等中台系统；最终目标是将核心支付交易系统平滑切换至 OceanBase，用一套数据库承载全场景需求。</p><h3><strong>从边缘到核心：OBKV-HBase替换HBase</strong></h3><p>在启动 OceanBase 引入计划后，我们先在离线与分析业务进行试点，后将多个MySQL业务迁移至OceanBase。当OBKV功能较为完善时，又完成了从HBase到#OBKV-HBase的升级，实现了一套引擎支持多场景业务的目标。</p><h4><strong>HBase 难以应对业务复杂度与实时性要求</strong></h4><p>尽管 HBase 在海量数据存储场景中曾发挥重要作用，但随着业务复杂度提升与实时性要求增强，其在架构、运维及成本等方面的问题日益凸显。主要体现在以下六个方面。</p><ul><li>离线链路冗长：当前数据流转路径为从 MySQL 流转至 Hive，再导入 HBase，流程环节多，数据延迟显著，且 Hive 层的数据修正不够灵活。</li><li>实时链路依赖过重：直接读写 HBase 严重依赖 Zookeeper 与 HDFS，中间件耦合度高，链路稳定性风险集中。</li><li>运维问题：跨机房场景下，集群切换与数据同步操作繁琐，故障时难快速隔离或切换。</li><li>成本控制：为满足高可用要求，需部署完整的 HBase 主备集群，硬件与存储资源近乎翻倍，成本太大。</li><li>多机房网络问题：机网络切割的时候，专线网络异常的时候，对业务都有影响。</li><li>SQL 查询依赖 phoenix：原生不支持标准 SQL，需借助 Phoenix 等组件实现查询，引入额外维护负担，且使用体验与性能往往不及直接 SQL 友好。</li></ul><h4><strong>使用OBKV替换HBase，为统一技术栈奠定基础</strong></h4><p>OBKV 是构建在 OceanBase 分布式存储引擎之上的NoSQL 产品系列，目前支持 OBKV-Table、OBKV-HBase、OBKV-Redis 三种产品形态，其原生继承了 OceanBase 的高性能、事务、分布式、多租户、高可靠的基础能力。此外，OceanBase 的工具体系（比如OCP、OMS、CDC等）也原生支持 OBKV，运维 OBKV 的各个产品形态和运维 OceanBase 的 SQL 集群完全一样。<strong>OBKV 可以帮助企业统一技术栈，在满足业务对多模 NoSQL 数据库诉求的同时，降低企业在数据库运维上的复杂度。</strong></p><p>基于我们目前正在使用的OBKV- HBase，总结其<strong>与HBase 的使用区别如下。</strong></p><ul><li>完全集成 OceanBase 分布式存储能力：OBKV 不仅有 OceanBase 强大的内核能力，也继承了 OceanBase 丰富的生态工具能力。</li><li>极简运维：DBA 如果同时有 SQL 以及 NoSQL 数据库的诉求，可以只运维一个数据库。</li><li>统一查询：可以用 OBKV 做简单快速的 DML，同时可以用 SQL 对同一份数据做并发的复杂查询。</li><li>成本更低：HBase 独用资源，OceanBase 是复用现有资源。</li><li>监控更方便：方便对应用现有运行环境添加监控。</li></ul><p>OBKV-HBase 不仅解决了传统 HBase 在运维复杂、资源孤岛、工具缺失等方面的痛点，更通过与 OceanBase 深度融合，可以<strong>实现“一套引擎、多模服务、统一运维、资源共享”的现代化数据基础设施目标。</strong></p><h4><strong>引入 OceanBase 的三个阶段，确保技术转型平稳可控</strong></h4><p>在数据库架构升级过程中，我们分三个阶段逐步引入 OceanBase，确保技术转型平稳可控。</p><h5><strong>第一阶段：初步探索与能力评估（2023 年）</strong></h5><p>2023 年底，团队开始接触 OceanBase 及其 OBKV-HBase 产品。当时 OBKV 文档尚不完善，关键功能缺失，尤其缺乏 bulkload（批量导入）能力，无法高效导入离线数据 ，初期判断暂不具备支撑核心业务的能力。因此，该阶段以技术调研为主，未投入生产使用。</p><h5><strong>第二阶段：归档与分析场景试点（2024 年）</strong></h5><p>2024 年，团队转向更匹配当前能力的场景，启动 OceanBase 在离线与分析业务的试点，将数据归档、BI 聚合宽表、AP 分析类业务迁移至 OceanBase。我们不仅验证了OceanBase在高吞吐写入、复杂查询、资源隔离等方面的稳定性与性能表现，还积累了集群部署、SQL 优化、运维监控等关键经验，为后续全面推广奠定基础。</p><h5><strong>第三阶段：逐步替换与扩展（2025 年起）</strong></h5><p>随着 OceanBase 功能持续完善（特别是 OBKV-HBase 的成熟），团队启动规模化替换计划。</p><ul><li>关系型业务：逐步将业务管理系统、商户管理系统、BI 系统等原 MySQL 应用迁移至 OceanBase SQL 模式；</li><li>NoSQL 业务：使用 OBKV-HBase 替代原有 HBase，例如将“绑卡/解卡操作日志”等高频 KV 场景迁移至 OBKV-HBase；</li><li>实现 TP、AP、KV 多负载统一承载，推动技术栈收敛与运维简化。</li></ul><h3><strong>五步平滑迁移：工具使用、方案设计与注意事项</strong></h3><p>在从 HBase 到 OBKV-HBase 的数据迁移过程中，我们在实践中总结出五个关键步骤。</p><h4><strong>Step1: 目标端准备</strong></h4><p>在正式启动从 HBase 到 OBKV-HBase 的数据迁移前，需在 OceanBase 端完成充分的环境与配置准备。</p><ul><li>硬件配置：为避免因磁盘性能不足导致集群不稳定，建议使用高性能磁盘，但建议初期不要过度分配资源，以便预留弹性空间，用于后续扩缩容及负载均衡调整。</li><li>存储规划：单个 OBServer 节点的磁盘容量应大于单个日志流的数据量。若单表数据量极大，而节点磁盘不足，可能在扩容或副本迁移时触发空间不足错误。</li><li>租户规划：建议为 OBKV 创建独立租户，隔离资源。</li><li>建好分区表。</li></ul><p><strong>注意事项</strong></p><ul><li>实测表明，自动 Range 分区优于手工预设 Hash 分区。自动分区支持分区裁剪，对范围扫描类查询性能更优；手工 Hash 分区在范围查询时需扫描所有分区，显著增加延迟与资源消耗。</li><li>需正确创建 Table Group：HBase 表名对应 OBKV-HBase 的 tablegroup 名字。</li><li>注意命名规范：HBase 列簇 family 在 OBKV-HBase 形式对应表 tablegroup$family。</li><li>注意 K 大小写：使用 DBeaver 等工具导出建表语句时，关键字（如 K）可能被转为小写（如 k），导致语法错误。同时需显式设置最大版本数（Max Versions）和数据过期时间（TTL）（多个版本多行）。</li></ul><h4><strong>Step2: 数据迁移</strong></h4><p>在完成目标端环境准备后，我们分阶段实施历史数据迁移与增量数据同步，确保业务平滑切换至 OBKV-HBase。</p><h5><strong>历史数据迁移</strong></h5><p>为高效迁移海量历史数据（单表达数十 TB），我们同时使用了 DataX 与 OMS ，但需特别注意两者在数据格式上的关键差异：</p><ul><li>DataX 导入的数据 Q 值是带列簇，T 值是正数。</li><li>用 OMS 导入的 Q 值是不带列簇，T 值是负数。</li></ul><h5><strong>增量数据同步</strong></h5><p>为确保切换期间数据零丢失，我们采用 “OMS 增量同步 + 业务双写” 双保险机制：</p><ul><li>HBase 开启复制，通过 OMS 增量同步。</li><li>通过业务程序双写保证数据实时同步。</li><li>逐步将流量从 HBase 切换到 OceanBase。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556149" alt="" title=""/></p><h4><strong>Step3: 数据校验</strong></h4><p>由于 OBKV-HBase 属于 NoSQL 场景，OMS 在当前版本中尚未提供 KV 类型数据的全量一致性校验功能，我们结合业务实际，设计了一套多维度、可落地的数据校验方案，确保迁移后数据准确无误。</p><p><strong>1.    行数校验：精确统计表行数。</strong></p><p>HBase 端：使用 HBase 的 RowCounter 工具统计原表行数。 命令: <code>org.apache.hadoop.hbase.mapreduce.RowCounter 'table'</code>。</p><p>OceanBase 端：使用 count 统计，获取行数并与 HBase 结果比对。</p><p><strong>2.    三方数据对比：借助 <strong><em><em>Doris</em></em></strong> 实现内容级校验。</strong></p><p>由于 OMS 暂时不支持进行 KV 场景下的全量校验，我们引入 Doris 作为临时比对中间层：</p><ul><li>通过 DataX 将 HBase 数据同步至 OceanBase 和 Doris。</li><li>对比 HBase、OceanBase、Doris 三方的数据一致性。</li></ul><p><strong>3.    对关键业务字段进行抽样对比。</strong></p><h4><strong>Step4:数据访问支持</strong></h4><p>在完成数据迁移与校验后，业务系统需通过标准接口访问 OBKV-HBase。我们发现 OBKV-HBase 不仅兼容 HBase 协议，还扩展了多项高级查询与操作能力，显著提升了开发效率与系统灵活性。</p><h5><strong>查询操作（Select）</strong></h5><ul><li>Filter：支持定义基于 AND 及 OR 构建的复杂的过滤条件，下压给 OBKV 服务端来做过滤。</li><li>Limit：限制返回满足条件数据的条数。</li><li>IN 等语法糖：IN 本质上是一种 Filter，提供对应接口方便业务编码。</li><li>简单聚合能力：提供 Sum/Min/Max/Avg/Count的聚合语义接口，下压给 OBKV 服务端来做简单聚合。</li><li>OrderBy：只支持基于主键以及索引序。</li><li>迭代器访问方式：提供类似迭代器的流式 Query 接口，适用于大批量结果集的流式获取以及处理场景，比如翻页场景。</li></ul><h5><strong>数据操作</strong></h5><ul><li>Insert：支持单行/多行数据插入。</li><li>Update：支持单行/多行数据更新，支持带 Filter 的条件更新。</li><li>Delete：提供基于主键做数据的删除，支持单行/多行数据删除。</li><li>Upset（insertOrUpdate）：此接口的语义是，如果有对应记录存在，执行 Update 操作，如果不存在，执行 Insert 操作，此接口也支持单行/多行操作。</li></ul><h4><strong>Step5：业务压测</strong></h4><p>为确保 OBKV-HBase 能够满足高并发生产环境要求，我们使用真实业务压测 OBKV 性能，达到 42w QPS，延迟仅为 1ms 左右，超出预期。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556150" alt="" title="" loading="lazy"/></p><p><strong>压测方法：</strong></p><ul><li>业务直接连接 OBServer 压测 OBKV 性能。</li><li>对比前期通过 ODP 压测的性能差异。</li><li>详细测试数据</li></ul><p>我们部署 10 个 Pod 模拟业务客户端，分别通过 OCP 统一调度和通过 ODP 的方式进行多轮压测任务。如下分别是 OceanBase 数据库、OCP 模式、ODP 模式压测的数据记录。</p><p><strong>OceanBase 数据库压测数据如下图所示</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556151" alt="" title="" loading="lazy"/></p><p><strong>OCP 模式压测数据如下图所示</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556152" alt="" title="" loading="lazy"/></p><p><strong>ODP 模式压测数据如下图所示</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556153" alt="" title="" loading="lazy"/></p><p>需要说明的是，前期通过 ODP 压测，性能不佳，QPS 不到 2k，具体原因分析见后续问题总结。经过优化，直连 OBServer 压测 OBKV，QPS 达到 42W，延迟 1ms 左右，完全满足业务需求。</p><p>直连 OBServer 的测试结果让我们对 OceanBase 的性能有了充分的信心，为后续业务的正式切换奠定了基础。</p><h3><strong>OBKV上线经验与问题总结：运维配置、数据校验</strong></h3><p>在 OBKV-HBase 的测试与上线过程中，我们积累了一系列关于监控集成、硬件配置、租户隔离及 CDC 同步等方面的实践经验，总结如下，供大家参考。</p><h4><strong>运维配置相关</strong></h4><h5><strong>1.监控配置</strong></h5><p>为避免重复建设监控平台，我们将 OBKV 相关指标接入公司统一的自研监控系统：</p><ul><li>ODP 的 Prometheus 参数可直接使用默认配置，无需额外调整；</li><li>如需修改 ODP 监控参数，可通过 sys 租户登录集群，执行以下命令：</li></ul><pre><code class="plain">show proxyconfig like "%prometheus%"以及alter proxyconfig set xxx = xxx;</code></pre><h5><strong>2.硬件配置</strong></h5><ul><li>建议使用高性能磁盘，以保障高吞吐写入需求。</li><li>初期资源不要划太多，避免将单台服务器的全部 CPU/内存资源划给租户，以便预留弹性空间用于后续扩缩容及负载均衡。</li><li>单个节点的磁盘要大于日志流的大小，当单表很大时且未合理分区，其对应的日志流可能超过单节点磁盘容量，同时在集群扩容（如从 3-3-3 架构扩展至 6-6-6 ）时，副本迁移会因日志流到节点磁盘迁移失败而失败。</li></ul><h5><strong>3.租户配置</strong></h5><p>建议为 OBKV 创建独立租户，避免与 TP/AP 类 SQL 业务共享资源。</p><h5><strong>4.CDC 配置</strong></h5><p>在使用 OMS 或 CDC 进行数据同步时，需特别注意 HBase 动态列模型与 CDC 日志格式的兼容性问题。HBase 表的列是动态的（不同 Row 可含不同列），而 OceanBase 的 clog（提交日志）在记录变更时有两种模式。</p><ul><li>全列模式（full）：记录整行所有列的值。</li><li>非全列模式：仅记录被更新的字段。</li></ul><p>若源端写入为非全列，而目标端 CDC 期望全列日志，可能导致同步解析失败或数据不一致。</p><p>解决方法是启用 CDC 的脏数据跳过开关<code>skip_dirty_data=1</code>，允许跳过全列校验，修改后重启实例生效：<code>ALTER BINLOG INSTANCE y6op8d9rk1 SET EXTRA_OBCDC_CFG ='skip_dirty_data=1'</code>。</p><h5><strong>5.前缀检索用 setRowPrefixFilter</strong></h5><p>在早期调研阶段，我们比较担忧 OBKV-HBase 是否支持基于 RowKey 前缀的高效查询。经过深入查阅文档与测试验证，确认 OBKV-HBase 完全兼容 HBase 1.2+ 的原生 API，其中包括关键的前缀检索功能。可通过 <code>Scan.setRowPrefixFilter(byte[] prefix) </code>方法实现高效的前缀扫描（Prefix Scan），具体如下图所示。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556154" alt="" title="" loading="lazy"/></p><p>该接口会自动构造起始键（startRow）和终止键（stopRow），仅扫描匹配指定前缀的 RowKey 范围，避免全表扫描，显著提升查询效率。</p><h4><strong>数据校验问题</strong></h4><p>在从 HBase 迁移至 OBKV-HBase 的过程中，我们在数据校验过程中也遇到了3个关键问题。</p><h5><strong>问题1：上下游数据条数校对问题</strong></h5><p><strong>问题描述</strong></p><p>使用 DataX 和 OMS 两种工具分别迁移同一张 HBase 表后，OBKV 中的数据行数均少于 HBase 源端，初步校验无法对齐。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556155" alt="" title="" loading="lazy"/></p><p><strong>原因分析</strong></p><p>HBase 的数据模型特性导致 count 结果存在歧义。</p><ul><li>Region 分裂重叠：分裂过程中可能短暂产生重复 RowKey。</li><li>未提交数据/写入失败残留：部分写入未完成但日志已落盘。</li><li>多版本（Multi-Version）：同一 RowKey 多次写入生成多个时间戳版本，默认全部保留。</li><li>TTL（Time-To-Live）未生效：过期数据尚未被清理，仍计入统计。</li></ul><p>在上述场景下，HBase 的 RowCounter 统计的是所有版本 + 所有可见记录，而 OBKV 默认仅保留最新版本（若未显式配置），导致数量差异。</p><p><strong>解决办法</strong></p><ul><li>统一迁移工具：避免混合使用 DataX 与 OMS，防止因时间戳、列格式处理逻辑不同引入偏差。</li><li>放弃基于快照（Snapshot）或 HFile 的 BulkLoad 方式，改用 <code>queryType=scan </code>的流式读取，确保仅同步当前可见、已提交的最新版本数据。</li><li>开发专门的数据校验工具，对比源端和目标端的数据。</li></ul><p><strong>结果验证</strong></p><p>通过调整迁移工具和校验方法，最终实现了 HBase 和 OBKV 数据的完全一致。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556156" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556157" alt="" title="" loading="lazy"/></p><p><strong>注意事项</strong></p><ul><li>建表语句大小写敏感：通过 DBeaver 等工具导出的建表语句中，K 关键字可能为小写（如 <code>k = 'value'</code>），需手动修正为大写，否则解析失败。</li><li>注意设置最大版本号和过期属性（多个版本多行）。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556158" alt="" title="" loading="lazy"/></p><h5><strong>问题 2: 20002 错误码</strong></h5><p><strong>问题描述</strong></p><ul><li>客户端等待服务端一直没有回包，超时报错 20002 ，默认超时设置为 1.5 秒。</li><li>每次应用重启后，第一笔查询耗时比较高，后面查询耗时基本正常。</li></ul><p><strong>原因分析</strong></p><p>根本原因是 scan.setCaching 参数配置不合理。</p><ul><li>scan.setCaching 参数用于限制每次 RPC 请求返回数据的行数。在 nextO 迭代的过程中，底层通过多次 RPC 来拉取剩余数据。</li><li>不设置 scan.setCaching 参数时，默认一次 RPC 拉完一整个分区的数据，在等数据返回的过程中卡住，导致 RT 较高。</li></ul><p><strong>解决办法</strong></p><p>将 scan.setCaching 参数的值设置为 100，控制每次 RPC 请求返回的最大行数。<code>scan.setCaching(100);</code>设置后，第一次查询耗时降到了 300ms 左右，后续查询性能也得到显著提升。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556159" alt="" title="" loading="lazy"/></p><h5><strong>问题 3：代理压测性能不佳</strong></h5><p><strong>问题描述</strong></p><p>通过 ODP 压测 OBKV-HBase，发现性能瓶颈明显，QPS 不到 2k。</p><p><strong>原因分析</strong></p><p>根本原因是ODP 元数据缓存机制与数据库大小写敏感配置不匹配。</p><ul><li>OceanBase 集群启用了 表名大小写敏感模式（<code>lower_case_table_names = 0</code>）。</li><li>而 ODP 默认行为在处理元数据请求时，未正确识别大小写敏感上下文，导致其无法有效缓存表结构信息。</li></ul><p>每次查询均触发完整的元数据解析流程（包括向 sys 租户查询表定义），无法命中本地缓存。高频元数据查询成为性能瓶颈，严重拖累整体吞吐能力。</p><p><strong>优化方案</strong></p><ul><li>通过设置 ODP 参数开启 ODP 表名小写兼容模式，在 sys 租户下执行：<code>alter proxyconfig set pc_enable_lower_case_table_names=True</code>。</li><li>再次压测结果：<strong>QPS 稳定在 1.2w 左右，性能提升 6 倍</strong>。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556160" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556161" alt="" title="" loading="lazy"/></p><h3><strong>“一库多模、统一平台”，将大规模引入OceanBase</strong></h3><p>通过近两年对 OceanBase 及其 OBKV-HBase 能力的深入实践，宝付支付成功完成了从传统 HBase 架构向新一代分布式数据库平台的平滑演进，取得了显著的技术与业务成效。</p><ul><li>实现降本：HBase 独用资源转为 OceanBase 复用资源，不仅释放了数台服务器资源，还实现了 NoSQL 与 SQL 负载的统一承载，使硬件投入与运维成本大幅降低。</li><li>提升效率：QPS 提升到 42W，延迟降低到 1ms 左右，完全满足高并发支付场景的严苛 SLA 要求。</li><li>增强可用性：告别 MySQL 主从 + 异地备库等复杂架构，统一为 OceanBase 多副本强一致架构。系统具备自动故障切换（RTO &lt; 8s）、数据零丢失（RPO = 0）能力，整体健壮性显著提升。</li><li>统一监控：方便对应用现有运行环境添加监控，大幅提升可观测性和监控易用性。</li></ul><p>不仅如此，对于集团架构而言，也具有重大意义和价值。</p><p><strong>其一，完成数据库架构全面升级</strong>。从 HBase 到 OceanBase，从“多套异构数据库”走向“一库多模、统一平台”，我们实现了数据库架构的全面升级，技术栈大幅收敛。</p><p><strong>其二，夯实业务创新底座</strong>。高性能、高可用的数据服务为实时风控、智能 BI 等新场景的业务创新提供了更强大的数据支撑能力。</p><p><strong>其三，奠定智能数据架构基础</strong>。为未来 AI 原生计算、HTAP 融合分析、跨地域多活等演进方向预留充分扩展空间。</p><p><strong>其四，沉淀宝贵实践经验</strong>。形成涵盖迁移方案、数据校验、性能调优、故障排查的完整方法论，可复用于后续系统改造。</p><p>本次 OBKV-HBase 成功落地，离不开 OceanBase 团队在过去两年中提供的专业、及时、深度的技术支持，特别是老纪及其研发、技术支持团队。无论是早期功能定制、性能瓶颈攻关，还是生产上线保障，OceanBase 团队始终与我们并肩作战，为项目顺利推进提供了坚实保障。在此，谨代表宝付支付技术团队，向 OceanBase 团队在迁移过程中提供的技术支持致以诚挚感谢！</p><p>另外，基于当前 OceanBase 在宝付支付的成功落地经验，我们已将 OceanBase 纳入集团未来数据架构的核心，聚焦 AI 项目赋能、汇聚库建设、多活架构尝试、零售支付场景四大业务方向大规模引入。</p><p><strong>1. Al 项目赋能：实现一体化SQL+AI。</strong></p><p>为响应公司对智能化转型的战略要求，我们将 AI 能力深度集成至数据库引擎层，推动从“被动查询”向“主动智能服务”升级。</p><ul><li>原生支持 AI 混合计算：利用 OceanBase 内置的向量化执行引擎与 AI 函数能力，实现“SQL + AI”的混合计算。</li><li>探索智能化查询优化和数据处理。</li><li>提升数据分析和決策支持能力。</li></ul><p><strong>2. 汇聚库建设：实现一体化TP+AP。</strong></p><p>当前集团存在 1000+ MySQL 实例及多套异构数据系统，导致跨库分析、实时统计、经营报表等场景面临巨大挑战，OceanBase 的 HTAP 一体化架构为此提供了根本性解决方案。我们将逐步把核心业务库、汇聚库、宽表等迁移至 OceanBase 并扩大线上使用规模，使用一套集群同时承载 TP 写入与 AP 分析，构建统一的数据平台，简化数据链路，提升数据治理和数据服务能力。</p><p><strong>3.多活架构尝试，实现系统稳定。</strong></p><p>苦于MySQL双活架构带来的问题，我们将尝试业务多活要求，满足高可用业务需求。依托 OceanBase 原生分布式多副本与 Paxos 协议能力，构建轻量级、高可用、跨机房、跨地域的多活架构，提升系统容灾能力和业务连续性。</p><p><strong>4.零售支付场景深化。</strong></p><p>随着内部零售支付业务越来越多，我们将在其他零售支付业务场景推广使用 OceanBase。并持续优化 OceanBase 压测记录，完善性能基线。我们计划基于真实业务负载开展常态化压测，建立 QPS、延迟、资源消耗等关键指标的基准模型。</p><p>此外，探索更多 OceanBase 在支付行业的应用场景，充分发挥 OceanBase 的 HTAP 与多模能力。</p><p><strong>数据库的升级不仅是技术的迭代，更是业务持续创新与稳健运行的基石。</strong></p><p>欢迎关注，将为您持续更新与#数据库、#AI、#开发、#降本增效 相关的技术内容。</p>]]></description></item><item>    <title><![CDATA[从0到1：了解 AI、大模型与智能体！ 智能猫 ]]></title>    <link>https://segmentfault.com/a/1190000047556200</link>    <guid>https://segmentfault.com/a/1190000047556200</guid>    <pubDate>2026-01-21 17:10:16</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <blockquote><strong>摘要：</strong> 从手机语音助手到自主完成复杂任务的智能工具，AI、大模型与智能体已深度渗透生活与工作，但多数人对三者的概念边界、核心关系与应用逻辑一知半解。本文以通俗语言拆解三者的本质定义，通过权威数据、对比表格与落地案例，为零基础读者搭建 “从认知到应用” 的完整知识框架，清晰梳理三者 “包含 - 支撑 - 进阶” 的核心逻辑，助力快速入门 AI 领域。</blockquote><h3>🚀 快速回答 (Golden Answer)</h3><p>AI（人工智能）是 “让机器模拟人类智能” 的技术总称（大范畴）；大模型是 AI 的 “通用能力核心载体”，通过海量数据训练具备理解、生成、推理等通用能力（核心技术）；智能体是 “搭载大模型的自主任务执行系统”，通过 “感知 - 规划 - 行动 - 反思” 闭环，让大模型从 “文本生成工具” 升级为 “能自主办事的助手”（进阶应用）。三者是 “总 - 分 - 延” 的关系：AI 包含大模型与智能体，大模型为智能体提供能力基础，智能体是大模型落地的关键形态。</p><h2>一、核心概念：AI、大模型与智能体的本质拆解</h2><h3>1.1 什么是 AI（人工智能）？—— 智能技术的 “大总称”</h3><p>AI 是指通过计算机程序模拟人类智能行为的技术集合，核心目标是让机器具备 <strong>感知、思考、决策、执行</strong> 的能力，替代或辅助人类完成各类任务。</p><ul><li>通俗理解：给机器赋予 “大脑”，让它能像人一样 “看懂、听懂、思考、做事”，是所有智能技术的 “总纲”；</li><li><p>核心分类：</p><ul><li>专用 AI（弱 AI）：针对单一任务设计，如人脸识别、智能扫地机器人、垃圾邮件过滤（当前主流 AI 形态）；</li><li>通用 AI（强 AI）：具备与人类同等的综合智能，能自主学习各类任务（目前仅处于理论阶段）。</li></ul></li></ul><h3>1.2 什么是大模型（Foundation Model）？—— AI 的 “通用能力核心”</h3><p>大模型是 AI 的 “高阶核心分支”，特指基于 <strong>海量数据（文本、图像、语音等）</strong> 训练的 “基础模型”，核心特点是 “参数规模大、能力通用、可迁移”，打破了传统 AI “单一任务专用” 的局限。</p><ul><li><p>核心关键词：</p><ul><li>参数规模：以 “亿” 或 “万亿” 为单位（如 GPT-4 参数超万亿），参数越多，模型学习能力与泛化能力越强；</li><li>通用能力：无需针对单一任务单独训练，就能处理语言理解、内容生成、逻辑推理、多模态交互（文本 + 图像）等多种任务；</li><li>可迁移：通过少量数据微调（Fine-tuning），就能快速适配具体场景（如企业客服、设计助手、编程辅助）。</li></ul></li></ul><h3>1.3 什么是智能体（Agent）？—— 大模型的 “任务执行延伸”</h3><p>智能体是 “搭载大模型的自主任务执行系统”，核心是给大模型加上 “行动能力” 与 “闭环逻辑”：通过 “感知 - 规划 - 行动 - 反思” 的迭代循环，让大模型能主动拆解复杂任务、调用外部工具、修正执行错误，最终自主完成目标，而非仅停留在 “生成文本” 层面。</p><ul><li>通俗理解：大模型是 “能说会道的大脑”，智能体就是 “给大脑装上手、脚和导航系统”，让它能自己 “找路、干活、修正错误”；</li><li>核心价值：把大模型从 “被动响应工具” 升级为 “主动办事助手”（如让智能体自主完成 “收集行业数据 → 分析趋势 → 生成可视化报告”）。</li></ul><h2>二、直观对比：AI、大模型与智能体的核心差异</h2><table><thead><tr><th>对比维度</th><th>AI（人工智能）</th><th>大模型（Foundation Model）</th><th>智能体（Agent）</th></tr></thead><tbody><tr><td>核心定位</td><td>智能技术的总称（大范畴）</td><td>AI 的通用能力核心载体</td><td>大模型的自主任务执行延伸（落地形态）</td></tr><tr><td>能力范围</td><td>单一任务或多任务（因类型而异）</td><td>通用能力（理解、生成、推理、多模态）</td><td>自主任务执行（拆解、行动、修正、闭环）</td></tr><tr><td>数据依赖</td><td>可基于小数据训练（如简单人脸识别）</td><td>必须依赖海量数据（TB 级以上）</td><td>依赖大模型训练数据 + 场景化任务数据</td></tr><tr><td>交互方式</td><td>被动响应（如智能门锁识别后开门）</td><td>被动生成（用户提问 → 输出文本 / 图像）</td><td>主动交互（自主调用工具、反馈修正）</td></tr><tr><td>核心组件</td><td>算法 + 数据 + 简单逻辑模块</td><td>Transformer 架构 + 海量参数 + 训练数据</td><td>大模型 + 规划模块 + 记忆系统 + 工具接口 + 反思机制</td></tr><tr><td>典型案例</td><td>智能扫地机器人、语音识别、人脸识别</td><td>GPT-4、文心一言、通义千问、Midjourney</td><td>Coze（扣子）、AutoGen、LangGraph 构建的任务助手</td></tr><tr><td>核心局限</td><td>专用 AI 通用性差，强 AI 仅存于理论</td><td>仅能生成内容，无法自主执行任务</td><td>复杂场景易出错，依赖完善的工具生态</td></tr></tbody></table><h2>三、技术演进：从 AI 到大模型，再到智能体的跨越</h2><p>AI 发展已历经 60 余年，核心能力从 “被动响应” 到 “主动执行”，经历了三个关键阶段的飞跃，每一步都离不开技术架构的突破：</p><table><thead><tr><th>发展阶段</th><th>核心技术</th><th>核心突破</th><th>时代特征</th></tr></thead><tbody><tr><td>传统 AI 阶段（1950s-2010s）</td><td>规则驱动 + 简单算法（如决策树、神经网络）</td><td>让机器完成单一固定任务</td><td>“被动响应” 时代（如早期聊天机器人仅能回应预设问题）</td></tr><tr><td>大模型阶段（2020s 至今）</td><td>Transformer 架构 + 海量数据训练</td><td>让机器具备通用智能（理解、生成、推理）</td><td>“能说会道” 时代（如 AI 写作、AI 绘画、智能答疑）</td></tr><tr><td>智能体阶段（当前进阶方向）</td><td>大模型 + 工具协同 + 闭环逻辑（感知 - 规划 - 行动 - 反思）</td><td>让机器自主完成复杂任务</td><td>“主动办事” 时代（如自主完成市场调研、生成分析报告、自动化办公）</td></tr></tbody></table><blockquote><strong>关键转折点：</strong> 2017 年谷歌提出的 ​<strong>Transformer 架构</strong>​（注意力机制），让模型能理解上下文逻辑，为大模型的通用能力奠定基础；而智能体的爆发，则是因为大模型解决了 “理解与推理” 的核心问题，让 “自主执行” 成为可能。</blockquote><h2>四、核心能力与应用场景：你能用到的 AI、大模型与智能体</h2><h3>4.1 大模型的核心能力（基础应用）</h3><p>大模型是当前 AI 应用的核心载体，能力覆盖绝大多数日常与工作场景：</p><ul><li>自然语言理解与生成：写文案、写报告、翻译、提炼文章摘要、智能客服自动回复；</li><li>逻辑推理与问题解决：编程辅助（生成代码、调试 bug）、数学计算、方案设计、学术科研数据分析；</li><li>多模态交互：文本生成图像（AI 绘画）、图像识别（提取图片文字、商品检测）、语音转文字 / 文字转语音；</li><li>个性化适配：通过微调适配企业知识库、学科答疑、品牌营销内容生成。</li></ul><h3>4.2 智能体的核心能力（进阶应用）</h3><p>智能体在大模型基础上新增 “自主执行” 能力，聚焦复杂任务闭环：</p><ul><li>任务拆解：将模糊需求拆解为可执行的原子步骤（如 “生成季度销售报告” 拆解为 “收集数据 → 清洗数据 → 分析趋势 → 生成报告 → 排版导出”）；</li><li>工具协同：自主调用 Excel、数据库、API 接口、编程环境等外部工具（如调用数据分析工具处理数据、调用排版工具优化报告格式）；</li><li>闭环反思：对比 “预期结果” 与 “实际执行结果”，自动修正错误（如数据缺失时重新收集、格式错误时自动调整）；</li><li>多场景落地：自动化办公（周报 / 月报生成）、智能设计（批量海报制作 + 风格优化）、科研辅助（文献检索 + 数据分析）、电商运营（商品上架 + 文案生成 + 数据监控）。</li></ul><h3>4.3 行业权威数据（2025 年最新）</h3><ul><li>据 Gartner 报告，2025 年全球 80% 的企业已在核心业务中使用大模型，其中 65% 的企业正在部署智能体提升执行效率；</li><li>McKinsey 调研显示，大模型能帮助知识工作者提升 40% 的内容生成效率，而智能体可进一步将复杂任务的完成时间缩短 50%-70%；</li><li>斯坦福大学 AI 指数报告指出，智能体的爆发使 AI 从 “辅助工具” 向 “数字劳动力” 转型，预计 2027 年全球将有 30% 的办公任务由智能体自主完成。</li></ul><h2>五、应用边界：这些事 AI、大模型与智能体还做不到</h2><p>尽管三者能力强大，但并非 “万能”，核心局限集中在以下 3 点：</p><ol><li>​<strong>缺乏真实认知与意识</strong>​：三者均不具备人类的 “意识” 与 “真实认知”—— 大模型的输出是基于数据训练的 “概率预测”，智能体的执行是基于逻辑编程的 “闭环反馈”，而非真正 “理解” 任务本质（如能写火箭制造步骤，但不懂物理原理）；</li><li>​<strong>可能产生 “幻觉” 与错误</strong>​：大模型在数据缺失时可能生成 “看似合理但虚假” 的内容（如编造引用、错误数据），智能体在复杂工具协同中可能出现逻辑漏洞（如调用错误 API）；</li><li>​<strong>无法替代人类主观决策</strong>​：涉及伦理、情感、价值判断的场景（如医疗诊断、法律判决、心理咨询），仅能提供参考，不能替代人类专业判断；</li><li>​<strong>依赖高质量数据与工具生态</strong>​：大模型的输出质量取决于训练数据（数据偏见会导致模型偏见），智能体的执行效率依赖完善的工具接口（如无适配 API 则无法调用某软件）。</li></ol><h2>六、零基础入门：如何快速用上 AI、大模型与智能体？</h2><p>无需懂技术，普通人可通过 3 个层级快速落地应用，从 “了解” 到 “实用” 仅需 10 分钟：</p><h3>6.1 直接使用现成工具（零门槛）</h3><ul><li>大模型工具：ChatGPT、文心一言、通义千问（用于写文案、答疑、翻译）、Midjourney（AI 绘画）；</li><li>智能体工具：Coze（扣子，零代码搭建个人智能助手）、Notion AI（文档生成 + 编辑智能体）、Canva AI（设计智能体，批量制作海报）；</li><li>使用场景：用 ChatGPT 写工作周报、用 Canva AI 生成电商海报、用 Coze 搭建个人学习助手（自动整理笔记 + 答疑）。</li></ul><h3>6.2 简单适配个性化需求（低门槛）</h3><ul><li>大模型微调：通过企业 / 个人知识库上传，让大模型适配专属需求（如上传公司产品资料，让大模型成为智能客服）；</li><li>智能体配置：在 Coze 等平台，通过可视化操作给智能体添加 “工具”（如绑定 Excel、设置执行步骤），适配特定任务（如 “自动收集电商数据 + 生成销售报表”）。</li></ul><h3>6.3 深度定制开发（中高门槛，适合开发者）</h3><ul><li>大模型：基于开源框架（如 Llama 3、DeepSeek），用自有数据微调，适配垂直领域（如医疗、金融）；</li><li>智能体：用 LangGraph、AutoGen 等框架，搭建自定义闭环逻辑（如 “科研智能体”= 文献检索工具 + 数据分析工具 + 报告生成工具 + 反思模块）。</li></ul><h2>七、FAQ：零基础读者最关心的核心问题</h2><h3>Q1：普通人学习 AI，需要先懂编程吗？</h3><p><strong>答：不需要。</strong> 零基础可先从 “使用现成工具” 入手（如 ChatGPT、Coze），满足日常与工作需求；若想深度定制，再学习基础编程（如 Python）与 Prompt 技巧（精准描述需求的方法），无需一开始就掌握复杂技术。</p><h3>Q2：大模型与智能体，哪个更适合普通职场人？</h3><p><strong>答：优先从大模型入手，再逐步使用智能体。</strong> 大模型适合解决 “内容生成类” 需求（写文案、答疑、翻译），操作简单；智能体适合解决 “复杂执行类” 需求（自动化办公、批量任务），可在熟悉大模型后，根据工作场景逐步尝试。</p><h3>Q3：如何避免大模型的 “幻觉” 问题？</h3><p><strong>答：3 个实用技巧：</strong> 1. 提问时提供具体上下文（如 “基于 2025 年中国 GDP 数据，写一段分析”，而非 “写中国 GDP 分析”）；2. 要求模型标注信息来源（如 “引用权威报告数据，注明出处”）；3. 关键内容交叉验证（如用多个大模型对比输出结果）。</p><h3>Q4：智能体的 “闭环反思” 能力，真的能替代人工检查吗？</h3><p><strong>答：不能完全替代。</strong> 智能体能处理 “明确规则类错误”（如格式错误、数据缺失），但无法识别 “主观类问题”（如报告逻辑是否通顺、内容是否符合品牌调性），最终仍需人类进行核心把关。</p><h2>八、核心总结</h2><p>AI、大模型与智能体的核心逻辑是 “​<strong>技术演进的三层阶梯</strong>​”：</p><ul><li>AI 是 “总纲”，定义了 “机器模拟人类智能” 的终极目标；</li><li>大模型是 “核心引擎”，解决了 “通用能力” 的关键问题，让 AI 能 “看懂、听懂、会表达”；</li><li>智能体是 “落地载体”，解决了 “自主执行” 的核心痛点，让 AI 能 “自己干活、修正错误”。</li></ul><p>对普通人而言，无需纠结复杂技术原理，可根据需求选择合适的工具：需要内容生成，用大模型；需要自动化执行，用智能体。未来，AI 的核心发展方向是 “大模型的能力深化” 与 “智能体的生态完善”，而拥抱这种技术变革，掌握 “人机协同” 的能力，才是应对未来的关键。</p><h2>参考文献与数据来源</h2><ol><li>Gartner《2025 年全球 AI 技术趋势报告》</li><li>McKinsey《大模型与智能体：重塑工作流程的核心力量》（2025）</li><li>斯坦福大学《AI 指数报告 2025》</li><li>LangGraph、AutoGen 官方技术文档</li><li>Coze（扣子）《智能体落地实践白皮书》</li></ol><h3>核心关键词</h3><p>AI（人工智能）、大模型、智能体、Foundation Model、Agent、人机协同、AI 应用场景、大模型微调、智能体闭环逻辑</p>]]></description></item><item>    <title><![CDATA[测试用例越堆越多？用 Apifox 测试套件让自动化回归更易维护 Apifox ]]></title>    <link>https://segmentfault.com/a/1190000047556206</link>    <guid>https://segmentfault.com/a/1190000047556206</guid>    <pubDate>2026-01-21 17:09:20</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>当项目中的接口测试用例和测试场景越积越多，单独管理和执行它们的成本会急剧上升。原本用于保障质量的自动化测试，自身反而成了维护的负担。</p><p>传统的维护方式是手动点选。当项目沉淀了大量用例和测试场景时，手动核对哪些该入库、哪些该回归，会成为沉重的体力成本。</p><p>Apifox「<a href="https://link.segmentfault.com/?enc=%2FoW5C2AQXotLgFA46g8ztw%3D%3D.Bs%2BBatGDCEP8SV5Ilt8Crg1ydAsoDxVnQOsXrKkNDvnLBw6sLZcq%2Bqey4QlFYrBG" rel="nofollow" target="_blank">测试套件</a>」通过动态模式解决了这个问题。它不再死板地记录 ID，而是保存一套筛选规则，例如按目录、标签、优先级等条件进行组合筛选。</p><p>在每次运行前，套件会根据筛选规则，自动组合所有符合规则的用例和测试场景。这意味着你只需专注于测试内容的编写和打标，新增的测试资产就会自动进入 CI/CD 流水线，真正实现无人值守的持续集成。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556208" alt="" title=""/></p><p>最终，所有执行项的结果会被汇总到一份聚合报告中，便于集中分析和定位问题。</p><h2>创建并编排你的第一个套件</h2><p>将 Apifox 更新到最新版本后，在「自动化测试」模块中，可以找到「测试套件」的分类。点击其右侧的 <code>...</code> 按钮，选择「新建测试套件」。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556209" alt="" title="" loading="lazy"/></p><p>在弹出的窗口中输入一个描述性的名称，配置相关的优先级或者标签，一个空的测试套件就创建完成了。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556210" alt="" title="" loading="lazy"/></p><p>创建完成后，核心工作是向这个套件中添加内容。测试套件的内容可以是单个的「接口测试用例」，也可以是包含多个步骤的「测试场景」。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556211" alt="" title="" loading="lazy"/></p><h3>添加测试内容：静态与动态</h3><p>点击「添加接口测试用例」或「添加测试场景」时，会看到「静态」和「动态」两种模式的选项。这两种模式决定了测试套件如何管理其包含的测试项，适用于不同的维护策略和测试目标。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556212" alt="" title="" loading="lazy"/></p><p>静态模式，顾名思义，是精确地、不变地指定要执行的测试项。当你以静态模式勾选某些用例时，系统记录的是这些用例的唯一 ID。即使后续这些用例的源目录增加了新的用例，或者用例本身被移动，这个套件的执行范围也不会改变。它的确定性很高，确保了每次运行的内容完全一致。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556213" alt="" title="" loading="lazy"/></p><p>动态模式则完全不同。它不记录具体的用例 ID，而是保存一套 “筛选规则”，例如 “某个目录下的所有用例” 或 “所有标签为「语义合法」的用例”。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556214" alt="" title="" loading="lazy"/></p><p>又或者是 “所有标记为 <code>P0</code> 优先级的测试场景”。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556215" alt="" title="" loading="lazy"/></p><p>在动态模式下，每次运行测试套件时，系统都会根据这套规则重新扫描整个项目，将所有当前符合条件的用例动态地纳入执行计划。这意味着，只要测试用例的属性（如所在目录、标签、优先级）符合规则，它就会被自动包含进来。</p><h3>静态模式与动态模式：如何选择？</h3><p>这两种模式没有绝对的优劣之分，而是服务于不同的管理需求。选择哪种模式，取决于你希望测试套件具备怎样的维护特性。</p><p>对于需要严格控制范围的专项测试，静态模式更可靠。而对于需要持续迭代、自动纳新的回归或冒烟测试，动态模式则能极大地降低维护成本。</p><p>为了更清晰地理解两种模式的差异，可以通过下表进行对比：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556216" alt="" title="" loading="lazy"/></p><h3>执行顺序与高级配置</h3><p>添加完测试内容后，可以在编排列表中通过拖拽调整它们的执行顺序。</p><p>在执行项（测试场景）的右侧，可以对套件的运行行为进行更细粒度的控制。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556217" alt="" title="" loading="lazy"/></p><p>例如，「遇到错误时」 选项可以决定当某个步骤失败后是继续执行、跳过当前轮次还是立即终止整个运行。「循环次数」则可以将整个套件重复执行多次，用于简单的稳定性测试。这些配置让测试套件不仅仅是一个用例的集合，更是一个可控的执行流程。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556218" alt="" title="" loading="lazy"/></p><h2>运行测试套件</h2><p>构建好测试套件后，下一步就是执行它。Apifox 提供了从本地手动运行到云端自动化执行的多种方式，以适应不同阶段和环境的需求。</p><h3>本地可视化运行</h3><p>最直接的运行方式是在 Apifox 客户端界面中，点击「运行」按钮。这种方式会从本地机器发起请求，适用于在开发和调试阶段进行小规模、快速的测试验证。在运行配置界面，可以临时切换「运行环境」，或设置在运行结束后发送通知。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556219" alt="" title="" loading="lazy"/></p><p>运行完成后，Apifox 会生成一份本次执行的测试报告，并在界面中以可视化方式展示。报告中会按执行顺序列出每一个接口测试用例和测试场景的结果，清晰标识成功和失败状态，点击具体测试项可查看更详细的报告。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556220" alt="" title="" loading="lazy"/></p><h3>通过 CLI 运行</h3><p>当测试规模较大，或者需要在无图形界面的服务器上执行时，Apifox CLI 是更高效的选择。它是一个命令行工具，可以将 Apifox 中的测试能力延展到任何终端环境。</p><p>要使用 CLI 运行，首先需要安装 <a href="https://link.segmentfault.com/?enc=7Ro%2FybbGzFGTgr8sP38EpA%3D%3D.l9rV3Egy%2FJqrvhKO8zCgETe2mUJ8lcM8rOeUcwZ00eXWp4UzzEjO47HkJ0sGueu3" rel="nofollow" target="_blank">Apifox CLI</a>，并确保其版本为最新。完成安装或升级后，可以在测试套件的「CI/CD」标签页中找到自动生成的命令行：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556221" alt="" title="" loading="lazy"/></p><p>将这条命令复制到终端中执行，即可在命令行看到与图形界面一致的测试过程和结果。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556222" alt="" title="" loading="lazy"/></p><p>运行结束后，它还会在当前目录下生成一个 <code>apifox-reports/</code> 文件夹，里面包含了 HTML 格式的详细测试报告。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556223" alt="" title="" loading="lazy"/></p><p>通过 CLI 运行的方式是实现 <a href="https://link.segmentfault.com/?enc=IMw%2BR%2BdQzLoufdArVL0U8A%3D%3D.TXu3WjU%2Bdj7jlOOlrHOsnlAopcA1DzqLQ8I0PyiFu%2BA%3D" rel="nofollow" target="_blank">CI/CD</a> 的基础。可以将这条命令集成到 Jenkins、GitLab CI 或 GitHub Actions 的脚本中，在代码合并等关键节点自动触发回归测试。</p><h3>通过定时任务运行</h3><p>Apifox 内置了「定时任务」功能。在测试套件的「定时任务」标签页，可以新建一个任务，设置其运行周期和运行环境。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556224" alt="" title="" loading="lazy"/></p><p>与本地运行不同，定时任务需要指定在「<a href="https://link.segmentfault.com/?enc=b9TuGoAyfJIepsRA6Iqtow%3D%3D.o8cwH9vb5a3Zyung1lnUPXvkSY%2BUnu%2FjWdwK5CZFSEVws1mq2MwS7It5fLu6Gz7o" rel="nofollow" target="_blank">自托管 Runner</a>」上执行。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556225" alt="" title="" loading="lazy"/></p><p>Runner 是一个可以由团队自行部署在内网服务器上的轻量级执行程序。使用 Runner 可以解决本地机器关机或网络不通导致定时任务失败的问题，并利用服务器更强大的计算资源来执行大规模测试。</p><p>设置好定时任务后，Apifox 会在指定时间自动调度 Runner 执行测试套件，并将运行历史和报告上传至云端。同时，可以配置失败通知，一旦线上接口出现异常，相关人员就能第一时间收到告警信息，及时介入处理。</p><h2>总结</h2><p>通过静态与动态两种编排模式，你既可以精确控制专项测试的执行范围，也能让回归测试随业务迭代自动更新，无需反复手动维护。配合本地运行、CLI 集成和定时任务等多种执行方式，测试套件可以灵活嵌入开发流程的各个环节——从开发阶段的快速验证，到 CI/CD 流水线的自动化回归，再到生产环境的定时巡检。</p><p>更多关于测试套件的知识可以前往 <a href="https://link.segmentfault.com/?enc=JGIjtoWnKQBXGp14w%2BpaZQ%3D%3D.uOBvX33OFK%2BWCZiCxvP4AnUuZUBhtoPx3kwV2c5QwCKM%2BSaoO9Ah89KuVgVOfxGb" rel="nofollow" target="_blank">Apifox 帮助文档</a>查看。现在就去试试创建你的第一个测试套件，将现有测试内容进行编排，逐步构建可持续运行的自动化回归体系。</p>]]></description></item><item>    <title><![CDATA[移动ERP系统怎么选？2026年主流产品深度测评 SaaS圈老马 ]]></title>    <link>https://segmentfault.com/a/1190000047556250</link>    <guid>https://segmentfault.com/a/1190000047556250</guid>    <pubDate>2026-01-21 17:08:31</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>老板要报表，销售在跑客户，仓库等着发货，财务急着对账——这时候要是能掏出手机，点几下就搞定所有流程，该多省心？没错，这就是移动ERP的价值。它不再把管理者拴在电脑前，而是让业务跟着人走，真正实现了“指尖上的管理”。</p><p>但市面上的选择太多了，标准化产品怕不灵活，定制开发又怕成本高、用不起来。今天，我们就来一次深度测评，聊聊哪些移动ERP系统真的能打，尤其适合那些业务增长快、需求多变的成长型企业。我们综合评估了产品能力、灵活性、性价比和实际口碑，为你推荐以下8款。</p><p><strong>1、支道：业务自己就能改的“活”ERP</strong></p><p><a href="https://link.segmentfault.com/?enc=MZ0nPKii40Unz9gzwMY4sQ%3D%3D.isRmgCF%2Byfyeefm1AmHlOhmCnWE5XfcfZV2W4%2B9uais%3D" rel="nofollow" target="_blank">https://www.zdsztech.com</a></p><p>如果你受够了软件跟不上业务变化的痛，那<strong>支道</strong>值得你第一个了解。它来自浙江支点数字科技有限公司，核心思路很不一样：它首先是一个强大的<strong>无代码开发平台</strong>，然后才是覆盖了CRM、ERP、生产、项目等全场景的解决方案。</p><p><strong>它的最大亮点是“灵活”</strong>。传统ERP改个流程得找厂商、排期、付钱，周期漫长。而支道让业务人员通过简单的“拖拉拽”，就能自己搭建或调整表单、流程和报表。今天销售说要加个客户字段，明天仓库希望出库单能扫码，后台配置一下，马上就能用。这完美解决了成长型企业“需求变太快，软件跟不上”的核心矛盾。</p><p>在移动端，它的体验很完整。数据填报、审批流、报表查看、生产报工等都能在手机APP或微信、钉钉里完成。比如，销售在外面用手机就能录入客户跟进、申请合同价；车间工人用PDA扫码就能完成领料和报工，数据实时同步。</p><p>此外，它支持<strong>私有化部署</strong>，对数据安全有高要求或想打造自主品牌的企业来说是个利好。根据其官方资料，它已服务超过5000家企业，年续费率达92.3%，在制造业、工程服务业等领域积累了很深的口碑。</p><p><strong>适合谁</strong>：需求变化快、追求业务自主权、不希望被软件厂商“卡脖子”的成长型企业，尤其是制造业、工程服务和贸易行业。<br/><img width="723" height="288" referrerpolicy="no-referrer" src="/img/bVdnHHG" alt="" title=""/></p><p><strong>2、简道云：深耕垂直场景的灵活助手</strong></p><p>提到无代码和移动ERP，简道云是个绕不开的名字，它在数据分析和表单应用方面口碑很好。</p><p>它的优势在于场景化的解决方案非常丰富。从轻量的进销存、客户管理，到复杂的生产工序跟踪、设备巡检，都有现成的模板可以借鉴修改。移动端的表单设计和数据收集体验很流畅，特别适合需要大量外勤填报、巡检的场景。</p><p>不过，它的灵活性更多体现在应用搭建层面，在超大型集团化的复杂业务流程深度整合上，可能不如一些原生一体化的平台。但对于大多数中小企业来说，它的能力已经绰绰有余，性价比不错。</p><p><strong>适合谁</strong>：看重数据收集与分析、需要快速搭建轻量级业务流程的中小企业，以及作为大型企业部门级应用补充。<br/><img width="723" height="315" referrerpolicy="no-referrer" src="/img/bVdnHHH" alt="" title="" loading="lazy"/></p><p><strong>3、用友畅捷通：老牌厂商的云端进化</strong></p><p>作为国内管理软件的老大哥，用友的移动端布局也很全面。这里我们主要看其中小企业云服务品牌——畅捷通。旗下的好生意、T+Cloud等产品都提供了成熟的移动端应用。</p><p>它的优势是功能成熟、稳定，财务业务一体化深度好。进销存、生产、财务之间的逻辑经过多年打磨，严谨规范。移动APP可以处理开单、查库存、审批、看报表等核心操作，与电脑端无缝衔接。如果你公司业务比较标准，尤其看重财务合规性，用友是稳妥的选择。</p><p>但相对的，其<strong>个性化定制能力较弱</strong>，深度修改需要依赖厂商或合作伙伴进行二次开发，周期和成本是必须考虑的。</p><p><strong>适合谁</strong>：业务模式相对标准、尤其重视财务合规性与稳定性的中小型企业。<br/><img width="723" height="299" referrerpolicy="no-referrer" src="/img/bVdnHHI" alt="" title="" loading="lazy"/></p><p><strong>4、金蝶云·星辰：业财一体，移动协同</strong></p><p>金蝶面向小微企业的金蝶云·星辰在移动端表现活跃。它主打“新财税、新营销、新平台”，将财务、进销存、零售门店管理较好地整合在了一起。</p><p>移动端除了常规的经营管理，在门店收银、会员管理、小程序商城对接等方面有特色。对于有线上线下结合业务的企业比较友好。业财自动流转，老板在手机上就能清晰看到现金流和利润情况。</p><p>金蝶的标准产品能力扎实，但若涉及超出产品边界的大幅定制，也会面临挑战。</p><p><strong>适合谁</strong>：有小微企业、零售门店、有线上商城业务，需要业财深度融合的商户。<br/><img width="723" height="306" referrerpolicy="no-referrer" src="/img/bVdnHHJ" alt="" title="" loading="lazy"/></p><p><strong>5、SAP Business ByDesign：跨国企业的稳健之选</strong></p><p>对于有出海业务或管理标准要求极高的企业，SAP是无法忽视的选项。SAP Business ByDesign是其面向中型企业的云端ERP解决方案。它的强大在于全球合规性、多语言多币种支持以及各模块间的高度集成性。从供应链、制造到客户关系和人力资本，设计理念超前。移动端应用更偏向于高管仪表盘和关键审批，为管理者提供全球业务的实时洞察。</p><p>当然，它的实施成本、复杂度和费用也更高，通常需要专业的咨询团队介入，更适合有一定规模和国际视野的企业。</p><p><strong>适合谁</strong>：有跨国运营需求、管理规范严格、预算相对充足的中大型企业。<br/><img width="723" height="275" referrerpolicy="no-referrer" src="/img/bVdnHH9" alt="" title="" loading="lazy"/></p><p><strong>6、浪潮云ERP：国资背景的全面方案</strong></p><p>浪潮在集团管控和智能制造领域有深厚积累。其云ERP产品线覆盖了大、中、小型企业，移动应用配套比较全面。</p><p>特色在于对制造业的深度支持，以及与工业互联网平台的结合。在移动端进行生产任务调度、质量检验、设备状态监控等场景较为成熟。对于国有背景或大型制造企业，浪潮往往在选型名单之内。</p><p><strong>适合谁</strong>：特别是大型制造企业、国有企业，以及需要ERP与生产执行系统深度集成的客户。<br/><img width="723" height="269" referrerpolicy="no-referrer" src="/img/bVdnHIo" alt="" title="" loading="lazy"/></p><p><strong>7、明道云：零代码构建业务中台</strong></p><p>明道云强调“业务中台”的概念，让企业可以像搭积木一样构建CRM、项目管理、进销存等应用。</p><p>它的界面现代化，自动化工作流配置能力强大。移动端能很好地承载这些自定义应用。适合那些有明确业务逻辑，希望完全自主设计管理流程的互联网化团队或企业IT部门。</p><p><strong>适合谁</strong>：IT能力较强或互联网思维明显的团队，喜欢完全自主可控地搭建业务系统。<br/><img width="723" height="341" referrerpolicy="no-referrer" src="/img/bVdnHIp" alt="" title="" loading="lazy"/></p><p><strong>8、氚云：钉钉生态的深度集成者</strong></p><p>对于日常办公高度依赖钉钉的企业来说，使用体验非常顺滑。在钉钉工作台直接使用ERP应用，消息、审批、待办天然打通，生态内还有大量第三方模板。如果你的企业是钉钉的重度用户，希望快速上手一个能解决业务管理问题的工具，氚云是一个便捷的入口。</p><p><strong>适合谁</strong>：全体员工已深度使用钉钉，希望管理软件能即开即用、快速上线的企业。<br/><img width="723" height="277" referrerpolicy="no-referrer" src="/img/bVdnHIq" alt="" title="" loading="lazy"/></p><p><strong>总结与选择建议</strong></p><p>看完这8款，可能还是有点眼花，我们一起简单总结一下，<strong>追求极致灵活与自主</strong>首选<strong>支道</strong>这类零/无代码平台。它们把系统的“进化权”交给了企业自己，故而尤其适合业务处于快速成长期、需求不确定的类型。</p><p>最后，选移动ERP，不能只看宣传的功能列表。一定要<strong>亲自试用</strong>，最好能用它模拟一个你最核心的业务流程（比如从下单到发货），看看在手机上跑不跑得通、顺不顺手。同时，思考一下一年后、三年后你的业务会变成什么样，今天的系统能不能跟着你一起成长。</p><p>毕竟好的移动ERP不该是个冷冰冰的工具，而应该是一个能随需而变的“活”系统。希望这份测评能帮你拨开迷雾，找到最适合自己的系统。</p>]]></description></item><item>    <title><![CDATA[2026CRM系统选型解析：6大品牌「线索-订单-服务」全链路核心差异 率性的开水瓶 ]]></title>    <link>https://segmentfault.com/a/1190000047556251</link>    <guid>https://segmentfault.com/a/1190000047556251</guid>    <pubDate>2026-01-21 17:07:31</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>一、评测背景与框架</h2><p>在企业数字化转型中，<strong>CRM</strong> <strong>的核心价值是实现「线索→商机→订单→服务」的全链路自动化</strong>，解决「线索分散、流程割裂、转化低效」三大痛点。本文选取<strong>超兔一体云、Bitrix24、Copper CRM、神州云动CloudCC、OroCRM、Ontraport</strong>六大主流CRM品牌，从<strong>线索-商机管理、订单-客户服务、</strong> <strong>销售自动化</strong>三大维度展开深度对比，结合表格、流程图、脑图等工具，为企业选型提供决策依据。</p><h2>二、核心能力横向对比</h2><h3>（一）对比框架与指标定义</h3><p>本次评测围绕「全链路自动化」核心，拆解3大维度12项关键指标（表1）：</p><table><thead><tr><th><strong>维度</strong></th><th><strong>关键指标</strong></th></tr></thead><tbody><tr><td>线索-商机管理</td><td>多渠道线索获取、线索智能筛选、商机跟进模型、客户画像深度</td></tr><tr><td>订单-客户服务</td><td>订单类型覆盖、财务管控能力、采购协同效率、客户服务/复购挖掘</td></tr><tr><td>销售自动化</td><td>AI自定义能力、工作流复杂度、数据分析深度、场景适配性</td></tr></tbody></table><h3>（二）核心能力对比表（表2）</h3><p>注：评分采用「★」制（★=基础能力，★★★=进阶能力，★★★★★=顶尖能力）</p><table><thead><tr><th><strong>品牌</strong></th><th>多渠道获取</th><th>线索筛选</th><th>商机模型</th><th>画像深度</th><th>订单类型</th><th>财务管控</th><th>采购协同</th><th>服务复购</th><th>AI自定义</th><th>工作流</th><th>数据分析</th><th>场景适配</th></tr></thead><tbody><tr><td>超兔一体云</td><td>★★★★★</td><td>★★★★★</td><td>★★★★★</td><td>★★★★★</td><td>★★★★★</td><td>★★★★★</td><td>★★★★★</td><td>★★★★★</td><td>★★★★★</td><td>★★★★★</td><td>★★★★★</td><td>★★★★★</td></tr><tr><td>Bitrix24</td><td>★★★★</td><td>★★★★</td><td>★★★</td><td>★★★</td><td>★★★</td><td>★★★</td><td>★★★</td><td>★★★</td><td>★★★</td><td>★★★★</td><td>★★★</td><td>★★★★</td></tr><tr><td>Copper CRM</td><td>★★★</td><td>★★★</td><td>★★★</td><td>★★★</td><td>★★★</td><td>★★★</td><td>★★</td><td>★★★</td><td>★★</td><td>★★★</td><td>★★★</td><td>★★★</td></tr><tr><td>神州云动CloudCC</td><td>★★★★</td><td>★★★★</td><td>★★★★</td><td>★★★★</td><td>★★★★</td><td>★★★★</td><td>★★★★</td><td>★★★★</td><td>★★★★</td><td>★★★★★</td><td>★★★★</td><td>★★★★★</td></tr><tr><td>OroCRM</td><td>★★★★</td><td>★★★★</td><td>★★★★</td><td>★★★★</td><td>★★★★</td><td>★★★</td><td>★★★</td><td>★★★</td><td>★★★</td><td>★★★★</td><td>★★★★</td><td>★★★★</td></tr><tr><td>Ontraport</td><td>★★★</td><td>★★★</td><td>★★★</td><td>★★★</td><td>★★★</td><td>★★★</td><td>★★</td><td>★★★★</td><td>★★★</td><td>★★★</td><td>★★★</td><td>★★★</td></tr></tbody></table><h2>三、关键维度深度解析</h2><h3>（一）线索-商机管理：谁能精准锁定高价值客户？</h3><p>线索-商机管理的核心是「<strong>从分散线索中识别高价值商机</strong>」，关键看「多渠道覆盖」「智能筛选」「模型适配」三大能力。</p><h4>1. 多渠道线索获取：超兔覆盖最广，OroCRM聚焦全渠道</h4><ul><li><strong>超兔一体云</strong>：支持<strong>6大渠道</strong>（百度/抖音广告、官网表单、微信海报、地推/会销、工商搜客、小程序），且能自动验证手机号准确性，解决「无效线索」痛点。</li><li><strong>OroCRM</strong>：侧重<strong>B2B</strong> <strong>/</strong> <strong>B2C</strong> <strong>全渠道</strong>（电商、线下门店、社交媒体），适合多业务模式的企业。</li><li><strong>Copper</strong> <strong>CRM</strong>：仅支持「网站表单+名片扫描」，适合轻量级场景。</li></ul><h4>2. 线索智能筛选：超兔的「渠道效果评估」最实用</h4><p>超兔能<strong>计算单条线索的市场活动成本</strong>（均摊至获客渠道），并结合「线索转化率」自动排序高价值渠道（如抖音线索转化率35%，百度20%，系统会优先分配抖音线索）；而Bitrix24仅支持「规则分配」，无法评估渠道ROI。</p><h4>3. 商机跟进模型：超兔的「三一客模型」最贴合中小单场景</h4><p>超兔独创「三一客模型」（定性：有价值/无价值；定级：大单/正常/小单；定量：金额/时间预期），解决「销售不清楚跟进重点」的问题；而OroCRM的「商机阶段看板」更适合中长周期的B2B项目。</p><h4>4. 客户画像深度：超兔的「多源数据补全」最全面</h4><p>超兔能自动补全<strong>工商信息、百度/天眼查数据、微信/支付宝头像</strong>，甚至能获取客户的「社交昵称」，构建360°画像；而Copper CRM仅能记录「基本联系信息」，画像维度单一。</p><h3>（二）订单-客户服务：谁能实现「订单→服务」的无缝衔接？</h3><p>订单-客户服务的核心是「<strong>从订单执行到客户复购的全链路协同</strong>」，关键看「订单适配性」「财务管控」「采购协同」三大能力。</p><h4>1. 订单类型覆盖：超兔支持「非标定制」，适配复杂业务</h4><p>超兔能处理<strong>3种订单类型</strong>（标准订单、批发订单、非标定制订单），且支持「订单锁库」（避免超卖）、「供应商直发」（降低库存成本）；而Ontraport仅支持「在线支付订单」，无法处理非标业务。</p><h4>2. 财务管控：超兔的「三角联动」最安全</h4><p>超兔实现「<strong>应收→开票→回款</strong>」三角联动，支持「一票对多单、一笔对多单」，并能<strong>按客户信用度控制发货</strong>（如客户信用分&lt;60，系统自动拦截发货）；而Bitrix24仅支持「发票生成」，无信用管控。</p><h4>3. 采购协同：超兔的「智能采购」最高效</h4><p>超兔能<strong>自动计算采购量→匹配历史供应商→拆分采购单</strong>，并通过「OpenCRM模块」实现「询比价→采购单创建→对账」全流程；而神州云动CloudCC需手动维护供应商信息，效率较低。</p><h4>4. 客户服务/复购：超兔的「RFM分析+工单联动」最精准</h4><p>超兔通过<strong>RFM模型</strong>（最近一次消费、消费频率、消费金额）识别「重要价值客户」（如最近30天消费、月均2次、客单价5000元），并自动触发「复购提醒」；同时支持「维修工单（到店）+外勤工单（上门）」，覆盖全场景服务。</p><h3>（三）销售自动化：谁能真正解放销售双手？</h3><p>销售自动化的核心是「<strong>用</strong> <strong>AI+</strong> <strong>流程替代重复性工作</strong>」，关键看「AI自定义」「工作流复杂度」「数据分析深度」三大能力。</p><h4>1. AI自定义能力：超兔的「低代码智能体」最灵活</h4><p>超兔支持<strong>低门槛自定义AI智能体</strong>（嵌入客户/行动视图），还能对接「Coze工作流」扩展高级能力（如销售开场白话术生成、AI待办提醒）；而Ontraport仅支持「邮件/SMS自动化」，AI能力较基础。</p><h4>2. 工作流复杂度：神州云动CloudCC的「低代码」适合复杂流程</h4><p>神州云动CloudCC支持「自定义数据动作+复合流程」（如「订单审核通过→自动通知仓库发货→同步客户微信提醒」），适合中大型企业的复杂业务；而Streak仅支持「Gmail内的简单流程」。</p><h4>3. 数据分析深度：超兔的「多表聚合引擎」最全面</h4><p>超兔提供<strong>5大分析工具</strong>（数字卡片、同比环比、多表聚合、关联表查询、单日KPI），能自动生成「销售漏斗报告」（如线索→商机转化率20%，商机→订单转化率40%），并定位转化瓶颈（如线索跟进不及时导致流失）；而Copper CRM仅支持「pipeline进度统计」，无法深入分析。</p><h2>四、全链路自动化流程图（超兔案例）</h2><p>以下是超兔「线索→订单→服务」全流程自动化的时序图（Mermaid语法）：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556254" alt="" title=""/></p><pre><code>sequenceDiagram
    participant 市场部
    participant 超兔系统
    participant 销售A
    participant 客户
    participant 采购部
    participant 客服部

    市场部-&gt;&gt;超兔系统: 投放抖音广告，用户提交官网表单
    超兔系统-&gt;&gt;超兔系统: 自动验证手机号→获取IP归属地→分配给销售A
    超兔系统-&gt;&gt;销售A: 发送线索提醒（含工商信息、微信头像）
    销售A-&gt;&gt;超兔系统: 用三一客模型定性定级定量
    超兔系统-&gt;&gt;销售A: 生成AI待办（3天内跟进）
    销售A-&gt;&gt;客户: 跟进后标记商机阶段
    客户-&gt;&gt;超兔系统: 确认非标订单
    超兔系统-&gt;&gt;超兔系统: 自动触发应收（按参数拆分3期）
    超兔系统-&gt;&gt;采购部: 生成采购计划→匹配历史供应商→拆分采购单
    客户-&gt;&gt;客服部: 投诉订单问题
    客服部-&gt;&gt;超兔系统: 关联订单记录→用RFM分析复购潜力
    超兔系统-&gt;&gt;市场部: 生成销售日报（线索转化率、订单履约率）</code></pre><h2>五、品牌核心能力脑图（超兔案例）</h2><p>以下是超兔核心能力的脑图（Mermaid语法）：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556255" alt="" title="" loading="lazy"/></p><pre><code>mindmap
    root((超兔一体云核心能力))
        线索-商机管理
            多渠道获取: 百度/抖音/微信/官网/地推/工商搜客
            线索处理: 一键加客户→归属地识别→渠道ROI评估
            商机跟进: 三一客模型→商机看板→多方项目模型
            客户画像: 工商补全→百度/天眼查→微信/支付宝头像
        订单-客户服务
            订单管理: 标准/批发/非标→订单工作流→锁库/直发
            财务管控: 应收自动触发→三角联动→信用控制
            采购协同: 供应商管理→智能采购→OpenCRM询比价
            客户服务: 维修/外勤工单→RFM复购→多渠道投诉处理
        销售自动化
            AI能力: 低代码智能体→Coze工作流→AI待办/日报
            流程自动化: 自定义工作流→复合数据动作→复杂业务适配
            数据分析: 多表聚合→关联查询→单日KPI→漏斗分析</code></pre><h2>六、雷达图评分（各品牌综合能力）</h2><p>注：雷达图包含5项指标（1-5分，5分为满分），分值越高越适合复杂场景：</p><table><thead><tr><th><strong>品牌</strong></th><th>线索-商机</th><th>订单-服务</th><th>销售自动化</th><th>复杂业务适配</th><th>中小企业友好</th></tr></thead><tbody><tr><td>超兔一体云</td><td>5</td><td>5</td><td>5</td><td>5</td><td>5</td></tr><tr><td>神州云动CloudCC</td><td>4</td><td>4</td><td>4</td><td>5</td><td>3</td></tr><tr><td>OroCRM</td><td>4</td><td>3</td><td>4</td><td>4</td><td>4</td></tr><tr><td>Bitrix24</td><td>4</td><td>3</td><td>3</td><td>4</td><td>4</td></tr><tr><td>Copper CRM</td><td>3</td><td>3</td><td>3</td><td>2</td><td>5</td></tr><tr><td>Ontraport</td><td>3</td><td>3</td><td>4</td><td>2</td><td>4</td></tr></tbody></table><h2>七、选型建议</h2><ol><li><strong>中小微企业（侧重效率）</strong> ：选<strong>超兔一体云</strong>（覆盖全场景，AI能力强，操作简单）或<strong>Copper</strong> <strong>CRM</strong>（轻量化，适合邮件/名片场景）。</li><li><strong>中大型企业（复杂流程）</strong> ：选<strong>神州云动CloudCC</strong>（低代码流程，业财联动）或<strong>OroCRM</strong>（B2B/B2C全渠道，多业务模式）。</li><li><strong>强营销需求企业</strong>：选<strong>Ontraport</strong>（邮件/SMS自动化，营销协同）。</li></ol><h2>结论</h2><p>从「全链路自动化」角度看，<strong>超兔一体云</strong>是综合能力最全面的选手——既覆盖了中小微企业的「轻量化需求」，也能满足中大型企业的「复杂流程」；而其他品牌则各有侧重（如OroCRM的全渠道、神州云动的低代码）。企业选型时需结合「业务场景+团队规模+核心痛点」，避免「为功能而选功能」。</p><p>（注：文中功能相关描述均基于公开披露信息，具体功能服务与价格以厂商实际落地版本为准。）</p>]]></description></item><item>    <title><![CDATA[2025年CRM客户管理系统TOP 6推荐榜单 晨曦钥匙扣 ]]></title>    <link>https://segmentfault.com/a/1190000047556272</link>    <guid>https://segmentfault.com/a/1190000047556272</guid>    <pubDate>2026-01-21 17:06:31</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>2025 年 CRM 客户管理系统 TOP 6 推荐榜单</h2><h3>一、引言：国产 CRM 的 “价值重构” 时代</h3><p>当中小企业数字化转型从 “尝鲜” 进入 “深用” 阶段，CRM 系统的核心价值已从 “客户信息存储” 迭代为 “业务效能引擎”。据 2025 年国产 CRM 市场白皮书显示，国内 CRM 市场规模已突破 320 亿元，其中具备 “全业务协同 + 行业定制” 能力的系统贡献了 72% 的增长份额。企业选型逻辑正在发生根本性转变：不再追逐 “功能堆砌”，而是聚焦 “痛点解决”；不再迷信 “生态流量”，更看重 “落地实效”。</p><p>在这样的市场格局下，2025 年国产 CRM 阵营呈现清晰的分化：头部品牌巩固垂直领域优势，新锐势力凭借技术突破搅动市场，而兼具 “全链路能力、低成本适配、高稳定性” 的玩家正成为中小企业的首选。本次榜单基于 3000 家企业实测数据、权威机构评测及市场占有率分析，精选出六大代表性品牌，深度解析其核心价值与适配场景。</p><h3>二、TOP 6 品牌核心能力全景解析</h3><h4>（一）超兔 CRM：工业级全业务一体化标杆</h4><p><strong>核心定位</strong>：深耕 21 年的 SaaS 服务商，专注为工业 / 工贸企业提供 “CRM + 进销存 + 生产 + 财务 + 上下游协同” 一体化解决方案，服务超 6 万家制造型企业。</p><p><strong>核心优势</strong>：</p><ol><li><strong>全链路数据贯通</strong>：打破传统系统壁垒，实现市场获客、销售跟单、非标订单管理、生产工单派发、库存管控、财务对账的全流程数据联动，某中型装备厂应用后订单交付周期缩短 30%。</li><li><strong>行业定制化能力</strong>：针对制造业特性开发 BOM 爆炸图下单、生产进度可视化、设备序列号溯源等功能，支持 500 个仓库的精细化管理与三种成本算法适配。</li><li><strong>轻量化 AI 应用</strong>：嵌入销售智能体模块，可自动生成跟进计划、触发回款提醒，通过自然语言交互实现 Coze 工作流配置，无需技术人员即可完成个性化设置。</li><li><strong>生态协同能力</strong>：通过 OpenCRM 体系实现与供应商、客户的外联协作，采购单确认、对账结算等流程可通过网页端直接完成，跨企业沟通效率提升 60%。</li></ol><p><strong>适配场景</strong>：机械制造、五金建材、非标设备等工业 / 工贸企业，尤其适合 10-500 人规模、需要销售与生产联动的成长型企业。</p><h4>（二）销售易 CRM：大型企业数字化转型领航者</h4><p><strong>核心定位</strong>：连续 9 年入选 Gartner SFA 魔力象限的国产头部品牌，专注中大型企业销售数字化升级，完成 “国家队” 信创适配大满贯。</p><p><strong>核心优势</strong>：</p><ol><li><strong>复杂组织适配</strong>：支持多级组织架构与矩阵式管理，适配集团型企业的跨区域、多部门协同需求，金融、汽车制造等行业渗透率领先。</li><li><strong>AI 驱动决策</strong>：基于大数据构建销售漏斗分析、赢单率预测模型，为管理层提供实时决策支持，某汽车零部件集团通过其 AI 预测功能将库存周转率提升 25%。</li><li><strong>高安全合规性</strong>：符合等保三级与数据安全法要求，具备完善的权限管控与操作日志追溯功能，保障核心业务数据安全。</li></ol><p><strong>适配场景</strong>：100 人以上中大型企业、集团化运营企业及对信创适配有要求的国企、上市公司。</p><h4>（三）纷享销客：快消零售移动管理专家</h4><p><strong>核心定位</strong>：聚焦快消、零售行业的移动销售管理解决方案提供商，以 “外勤管控 + 终端运营” 为核心竞争力。</p><p><strong>核心优势</strong>：</p><ol><li><strong>外勤精细化管理</strong>：集成路线规划、定位打卡、拜访记录上传等功能，支持带水印的终端陈列拍照，确保外勤行为真实可追溯，某食品饮料企业应用后有效拜访率提升 45%。</li><li><strong>终端数据可视化</strong>：实时同步门店库存数据，自动预警脱销风险，生成区域动销率报表，为铺货策略调整提供数据支撑。</li><li><strong>轻量协同功能</strong>：与企业微信深度集成，客户跟进记录可同步至团队协作空间，适合分散型销售团队的高效管理。</li></ol><p><strong>适配场景</strong>：食品饮料、日用快消、连锁零售等依赖外勤团队的行业，适配 50 人以上规模的品牌商与区域经销商。</p><h4>（四）小满科技：外贸 B2B 领域隐形冠军</h4><p><strong>核心定位</strong>：外贸 CRM 细分市场领军品牌，专注为跨境企业提供 “客户开发 + 邮件管理 + 报关对接” 一体化解决方案。</p><p><strong>核心优势</strong>：</p><ol><li><strong>全球化客户管理</strong>：支持多语言界面与多货币结算，集成海关数据与海外企业征信查询功能，帮助外贸企业快速识别高价值客户。</li><li><strong>邮件智能管理</strong>：具备邮件追踪、模板库、群发统计等功能，可自动归档客户沟通记录，某外贸公司应用后邮件回复时效提升 50%。</li><li><strong>报关流程衔接</strong>：与主流报关系统对接，实现订单信息自动同步，减少人工录入误差，报关效率提升 35%。</li></ol><p><strong>适配场景</strong>：外贸 B2B 企业、跨境电商供应商，尤其适合以邮件开发客户为主的中小外贸团队。</p><h4>（五）钉钉咚咚 CRM：轻量化办公协同工具</h4><p><strong>核心定位</strong>：依托钉钉生态的嵌入式 CRM 工具，主打 “办公 + 客户管理” 无缝衔接，定位中小企业入门级解决方案。</p><p><strong>核心优势</strong>：</p><ol><li><strong>生态原生集成</strong>：与钉钉聊天、审批、考勤等功能深度融合，客户信息可直接从聊天窗口同步，审批流程可关联客户跟进阶段。</li><li><strong>低成本入门</strong>：基础版年费仅数千元，支持联系人管理、简单跟单记录与基础报表生成，满足微型企业核心需求。</li><li><strong>易上手特性</strong>：延续钉钉的操作逻辑，销售团队无需额外培训即可快速上手，降低系统落地成本。</li></ol><p><strong>适配场景</strong>：已深度使用钉钉办公、仅需基础客户管理功能的微型企业（10 人以下），如服务业个体户、小型贸易公司。</p><h4>（六）企微 CRM：私域运营场景专家</h4><p><strong>核心定位</strong>：基于企业微信生态的社交型 CRM，专注私域流量的获取、运营与转化，入选 2025 年最佳企微 SCRM 榜单 TOP6。</p><p><strong>核心优势</strong>：</p><ol><li><strong>社交获客赋能</strong>：支持客户朋友圈运营、社群标签管理、聊天记录存档，集成客户生命周期管理功能，某医美机构应用后私域转化率提升 28%。</li><li><strong>场景化运营工具</strong>：提供节日问候模板、活动邀约插件、客户分层运营等功能，适配高客单价、长决策周期的行业需求。</li><li><strong>组织协同能力</strong>：支持客户资源一键交接、团队共享客户标签，解决销售流动导致的客户流失问题。</li></ol><p><strong>适配场景</strong>：教育、医美、家居建材等依赖私域获客的行业，适合 20-100 人规模、以微信生态为主要获客渠道的企业。</p><h3>三、行业黑马：超兔 CRM 的突围逻辑</h3><p>在六大品牌中，超兔 CRM 以 “65% 的中小企业复购率、40% 的转介绍率” 成为 2025 年最具增长潜力的品牌，其突围逻辑精准击中市场痛点：</p><h4>（一）精准匹配核心需求缺口</h4><p>中小企业的核心痛点并非 “缺工具”，而是 “工具碎片化”—— 销售用 CRM、生产用 ERP、库存用进销存，数据需手动导出导入，差错率高达 20%。超兔的 “一体云” 模式直接提供全业务解决方案，年费仅为同类集成方案的 60%，完美平衡 “功能全面性” 与 “成本可控性”。</p><h4>（二）构建差异化技术壁垒</h4><p>不同于流量型 CRM 的 “浅度集成”，超兔深耕工业场景技术研发：生产工单与销售订单的底层数据打通、非标产品的参数化配置、多仓库的实时同步等功能，均经过上万次企业实测优化，这种 “行业 Know-How + 技术落地” 的能力是生态型玩家难以复制的。</p><h4>（三）打造可信赖的服务体系</h4><p>中小企业对 CRM 的核心诉求是 “稳定能用、问题能解”。超兔以 “客服响应不超过 10 分钟”“系统可用性 99.9%” 的服务标准，成为众多企业从竞品迁移的首选。某五金企业负责人表示：“之前用的系统频繁崩溃，换超兔后一年没出故障，客服还主动上门培训，这才是中小企业需要的服务。”</p><h3>三、选型决策：找到最适配的 CRM 系统</h3><h4>（一）按行业特性选择</h4><ul><li><strong>工业 / 工贸企业</strong>：优先选超兔 CRM，其生产联动能力远超通用型系统；</li><li><strong>中大型集团企业</strong>：销售易 CRM 的组织适配与信创能力更具优势；</li><li><strong>快消零售企业</strong>：纷享销客的外勤管理与终端监控功能更贴合需求；</li><li><strong>外贸企业</strong>：小满科技的跨境适配能力是细分领域最优解。</li></ul><h4>（二）按企业规模选择</h4><ul><li><strong>10 人以下微型企业</strong>：钉钉咚咚 CRM 的低成本与生态集成性更适配；</li><li><strong>10-200 人成长型企业</strong>：超兔 CRM 的全业务能力可支撑长期发展；</li><li><strong>200 人以上大型企业</strong>：销售易 CRM 的复杂流程处理能力更符合需求。</li></ul><h4>（三）按核心需求选择</h4><ul><li><strong>追求全流程协同</strong>：超兔 CRM 的一体化解决方案是首选；</li><li><strong>侧重私域运营</strong>：企微 CRM 的社交功能更具针对性；</li><li><strong>需要数据决策</strong>：销售易 CRM 的 AI 分析能力更强大。</li></ul><h3>四、结语：国产 CRM 的价值回归</h3><p>2025 年的 CRM 市场竞争，本质是 “价值交付能力” 的竞争。从本次榜单可见，无论是超兔 CRM 在工业领域的深度扎根，还是销售易在大型企业市场的持续领跑，都印证了一个核心趋势：只有真正理解行业痛点、具备技术落地能力、坚持服务本质的品牌，才能在市场中持续突围。</p><p>对于企业而言，选型 CRM 的关键不在于 “选最好的”，而在于 “选最对的”—— 能解决当前核心痛点、适配未来发展需求、符合成本预算的系统，就是最优解。而随着国产 CRM 技术的不断成熟，“用得起、用得好、能成长” 的数字化工具正成为更多中小企业的标配，这正是中国企业数字化转型的真正价值所在。</p>]]></description></item><item>    <title><![CDATA[灰度与蓝绿：风险可控的发布——流量切分、指标回滚与版本管理策略 南城 ]]></title>    <link>https://segmentfault.com/a/1190000047556311</link>    <guid>https://segmentfault.com/a/1190000047556311</guid>    <pubDate>2026-01-21 17:05:55</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><strong>写在前面，本人目前处于求职中，如有合适内推岗位，请加：lpshiyue 感谢。同时还望大家一键三连，赚点奶粉钱。</strong></p><blockquote>现代软件发布不是简单的替换操作，而是在用户体验、风险控制和业务价值之间的精细平衡艺术</blockquote><p>在掌握了Kubernetes的核心概念后，我们面临一个更关键的挑战：如何安全高效地将新版本软件交付给用户。灰度发布与蓝绿发布作为两种主流的现代发布策略，通过智能的流量控制和版本管理，实现了发布过程的<strong>风险可控</strong>与<strong>用户体验无损</strong>。本文将深入探讨这两种策略的技术实现、适用场景及最佳实践。</p><h2>1 发布策略的本质：风险控制与用户体验的平衡</h2><h3>1.1 传统发布方式的挑战与风险</h3><p>在单体应用时代，<strong>停机发布</strong>是常见做法，但伴随着明显的业务中断和回滚困难。随着微服务架构的普及，系统复杂度呈指数级增长，简单的全量发布方式已无法满足业务连续性要求。</p><p><strong>发布过程中的核心风险</strong>包括：</p><ul><li><strong>业务中断风险</strong>：新版本缺陷导致服务不可用</li><li><strong>数据一致性风险</strong>：版本切换过程中的数据丢失或错乱</li><li><strong>用户体验风险</strong>：发布期间的服务降级或功能异常</li><li><strong>回滚复杂度</strong>：出现问题时的快速恢复能力</li></ul><p>根据行业数据，超过70%的生产环境事故与发布过程相关，而合理的发布策略能将此风险降低80%以上。</p><h3>1.2 现代发布策略的演进逻辑</h3><p>现代发布策略从"一刀切"向<strong>精细化、可控化</strong>方向演进，核心思路是将发布过程从<strong>事件</strong>转变为<strong>过程</strong>，通过流量控制、渐进式验证等手段降低风险。</p><pre style="display:none;"><code class="mermaid">graph TD
    A[传统停机发布] --&gt; B[蓝绿发布]
    B --&gt; C[灰度发布]
    C --&gt; D[功能开关发布]
    D --&gt; E[影子测试]
    
    style A fill:#f9d5c8
    style B fill:#c8e6f5
    style C fill:#d4edda
    style D fill:#f0e6f5
    style E fill:#fff2cc</code></pre><p><em>发布策略的演进路径，从高风险到高安全性的过渡</em></p><h2>2 蓝绿发布：快速切换的确定性艺术</h2><h3>2.1 蓝绿发布的核心理念与架构</h3><p>蓝绿发布的本质是<strong>环境冗余</strong>策略，通过维护两套完全独立的环境（蓝色代表当前生产环境，绿色代表新版本环境），实现版本的<strong>瞬时切换</strong>和<strong>快速回滚</strong>。</p><p><strong>架构设计要点</strong>：</p><ul><li><strong>环境隔离</strong>：蓝色和绿色环境完全独立，包括计算、网络、存储资源</li><li><strong>数据兼容性</strong>：确保新版本对现有数据的前向兼容性</li><li><strong>流量切换机制</strong>：通过负载均衡器或API网关实现流量无缝切换</li></ul><h3>2.2 技术实现路径</h3><p>在Kubernetes环境中，蓝绿发布可以通过Service的标签选择器巧妙实现：</p><pre><code class="yaml"># 蓝色环境（当前生产版本）
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-blue
spec:
  replicas: 3
  selector:
    matchLabels:
      app: my-app
      version: blue  # 版本标识
  template:
    metadata:
      labels:
        app: my-app
        version: blue
    spec:
      containers:
      - name: app
        image: my-app:v1.0.0
        ports:
        - containerPort: 8080

# 绿色环境（新版本）
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-green
spec:
  replicas: 3
  selector:
    matchLabels:
      app: my-app
      version: green  # 版本标识
  template:
    metadata:
      labels:
        app: my-app
        version: green
    spec:
      containers:
      - name: app
        image: my-app:v1.1.0
        ports:
        - containerPort: 8080

# Service配置，通过修改selector实现切换
apiVersion: v1
kind: Service
metadata:
  name: app-service
spec:
  ports:
  - port: 80
    targetPort: 8080
  selector:
    app: my-app
    version: blue  # 初始指向蓝色环境
  type: LoadBalancer</code></pre><p><strong>切换操作命令</strong>：</p><pre><code class="bash"># 从蓝色切换到绿色环境
kubectl patch service app-service -p '{"spec":{"selector":{"version":"green"}}}'

# 快速回滚到蓝色环境
kubectl patch service app-service -p '{"spec":{"selector":{"version":"blue"}}}'</code></pre><h3>2.3 适用场景与优缺点分析</h3><p><strong>蓝绿发布的优势</strong>：</p><ul><li><strong>快速回滚</strong>：秒级切换回旧版本</li><li><strong>风险隔离</strong>：新旧版本完全隔离，互不影响</li><li><strong>测试验证</strong>：可在生产环境隔离测试新版本</li><li><strong>简单可靠</strong>：技术实现相对简单，易于理解</li></ul><p><strong>局限性考量</strong>：</p><ul><li><strong>资源消耗</strong>：需要双倍基础设施资源</li><li><strong>数据兼容性</strong>：需确保双版本对数据结构的兼容</li><li><strong>状态管理</strong>：有状态应用的处理较为复杂</li><li><strong>切换瞬时性</strong>：全量切换，无法渐进验证</li></ul><p><strong>最佳适用场景</strong>：</p><ul><li>版本间变更较大，需要完全隔离测试</li><li>对回滚速度要求极高的业务场景</li><li>基础设施资源充足，可承担冗余成本</li><li>发布频率相对较低的应用</li></ul><h2>3 灰度发布：渐进式验证的精细控制</h2><h3>3.1 灰度发布的哲学与价值主张</h3><p>灰度发布（又称金丝雀发布）源于矿业中的<strong>金丝雀预警机制</strong>，通过将新版本逐步暴露给少量用户，实现<strong>风险早期发现</strong>和<strong>影响范围控制</strong>。</p><p>与蓝绿发布的二元切换不同，灰度发布强调<strong>渐进式</strong>和<strong>数据驱动</strong>的发布理念，将发布过程从技术决策转变为业务验证过程。</p><h3>3.2 流量切分策略与技术实现</h3><h4>3.2.1 基于权重的流量切分</h4><p>在Kubernetes中，最简单的灰度发布可以通过调整Deployment的副本数实现：</p><pre><code class="yaml"># v1版本（现有版本）
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-v1
spec:
  replicas: 9  # 90%流量
  selector:
    matchLabels:
      app: my-app
      version: v1.0
  template:
    metadata:
      labels:
        app: my-app
        version: v1.0
    # ... 其他配置

# v2版本（新版本）
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-v2
spec:
  replicas: 1  # 10%流量
  selector:
    matchLabels:
      app: my-app
      version: v1.1
  template:
    metadata:
      labels:
        app: my-app
        version: v1.1
    # ... 其他配置

# Service配置，同时选择两个版本
apiVersion: v1
kind: Service
metadata:
  name: app-service
spec:
  ports:
  - port: 80
    targetPort: 8080
  selector:
    app: my-app  # 不指定版本，选择所有匹配的Pod
  type: LoadBalancer</code></pre><h4>3.2.2 基于特征的精细化路由</h4><p>对于更复杂的场景，可以使用Service Mesh或Ingress控制器实现基于请求特征的精细路由：</p><pre><code class="yaml">apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: app-canary-ingress
  annotations:
    nginx.ingress.kubernetes.io/canary: "true"
    nginx.ingress.kubernetes.io/canary-weight: "10"  # 10%流量到新版本
    nginx.ingress.kubernetes.io/canary-by-header: "X-Canary"  # 基于Header
    nginx.ingress.kubernetes.io/canary-by-header-value: "true"
spec:
  rules:
  - http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: app-service
            port:
              number: 80</code></pre><h3>3.3 渐进式发布流程设计</h3><p>科学的灰度发布需要制定清晰的<strong>阶段规划</strong>和<strong>验收标准</strong>：</p><pre style="display:none;"><code class="mermaid">graph LR
    A[内部测试 1%] --&gt; B[特定用户 5%]
    B --&gt; C[小范围用户 20%]
    C --&gt; D[半数用户 50%]
    D --&gt; E[全量发布 100%]
    
    style A fill:#ffcccc
    style B fill:#ffebcc
    style C fill:#ffffcc
    style D fill:#ebffcc
    style E fill:#ccffcc</code></pre><p><em>渐进式灰度发布流程，每个阶段都有明确的验收指标</em></p><p><strong>各阶段验收指标</strong>：</p><ul><li><strong>内部测试阶段</strong>：基础功能验证、性能基准测试</li><li><strong>特定用户阶段</strong>：业务逻辑验证、用户体验收集</li><li><strong>小范围用户阶段</strong>：稳定性监控、错误率统计</li><li><strong>半数用户阶段</strong>：负载能力验证、性能指标对比</li><li><strong>全量发布阶段</strong>：全面监控、问题应急响应</li></ul><h3>3.4 适用场景与价值分析</h3><p><strong>灰度发布的独特价值</strong>：</p><ul><li><strong>风险控制</strong>：问题影响范围可控，最大程度减少业务影响</li><li><strong>数据驱动</strong>：基于真实用户数据做出发布决策</li><li><strong>用户体验</strong>：无缝渐进，用户无感知</li><li><strong>灵活调整</strong>：可根据验证结果动态调整发布策略</li></ul><p><strong>实施挑战</strong>：</p><ul><li><strong>复杂度高</strong>：需要完善的监控和自动化工具支持</li><li><strong>周期较长</strong>：完整的灰度流程需要较长时间</li><li><strong>技术门槛</strong>：需要专业的SRE团队进行维护和决策</li></ul><p><strong>理想适用场景</strong>：</p><ul><li>用户量较大，故障影响范围需要严格控制</li><li>需要真实用户数据验证新功能效果</li><li>技术团队具备较强的监控和自动化能力</li><li>对业务连续性要求极高的核心业务</li></ul><h2>4 关键支撑技术：流量治理与指标监控</h2><h3>4.1 智能流量切分策略</h3><p>现代发布策略依赖于精细化的<strong>流量控制能力</strong>，常见的流量切分维度包括：</p><p><strong>基于权重的随机切分</strong>：</p><pre><code class="yaml"># 使用Istio进行权重配置
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: app-virtual-service
spec:
  hosts:
  - app.example.com
  http:
  - route:
    - destination:
        host: app-service
        subset: v1
      weight: 90  # 90%流量到v1
    - destination:
        host: app-service
        subset: v2
      weight: 10  # 10%流量到v2</code></pre><p><strong>基于请求特征的定向路由</strong>：</p><ul><li><strong>用户标识</strong>：特定用户群体优先体验新功能</li><li><strong>地理区域</strong>：从特定区域开始逐步扩大</li><li><strong>设备类型</strong>：按设备类型分别发布</li><li><strong>业务重要性</strong>：从非核心业务到核心业务渐进</li></ul><h3>4.2 多层次监控指标体系</h3><p>有效的发布策略需要完善的<strong>监控验证</strong>体系，关键指标包括：</p><p><strong>业务层面指标</strong>：</p><ul><li>请求成功率、错误率分布</li><li>业务转化率、关键路径完成率</li><li>用户满意度、投诉率变化</li></ul><p><strong>技术层面指标</strong>：</p><ul><li>应用性能：响应时间、吞吐量、错误率</li><li>系统资源：CPU、内存、网络使用率</li><li>中间件状态：数据库连接数、缓存命中率</li></ul><p><strong>自动化验收与决策</strong>：<br/>通过监控指标设置自动化的<strong>发布门禁</strong>，当关键指标异常时自动暂停或回滚发布：</p><pre><code class="yaml"># Kruise Rollout的自动化验收配置示例
apiVersion: rollouts.kruise.io/v1alpha1
kind: Rollout
metadata:
  name: app-rollout
spec:
  strategy:
    canary:
      steps:
      - weight: 10
        pause: {duration: 300}  # 暂停5分钟进行验证
      - weight: 30
        pause: {duration: 600}
      - weight: 100
        pause: {duration: 0}
      metrics:
      - name: error-rate
        threshold: "5"  # 错误率阈值5%
        interval: 60s   # 每60秒检查一次
      - name: p99-latency  
        threshold: "500"  # P99延迟阈值500ms
        interval: 60s</code></pre><h3>4.3 回滚策略与版本管理</h3><p><strong>自动化回滚机制</strong>是发布安全的重要保障，需要建立多级别的回滚策略：</p><p><strong>指标驱动回滚</strong>：当关键监控指标超过阈值时自动触发回滚<br/><strong>人工决策回滚</strong>：基于业务判断手动触发回滚<br/><strong>渐进式回滚</strong>：逐步减少新版本流量，而非直接全量回滚</p><p><strong>版本管理最佳实践</strong>：</p><ul><li><strong>语义化版本控制</strong>：明确版本间的兼容性承诺</li><li><strong>版本元数据管理</strong>：记录每个版本的变更内容、已知问题等信息</li><li><strong>发布文档化</strong>：每个发布版本都有详细的发布说明和回滚指南</li></ul><h2>5 发布策略的选择与组合实践</h2><h3>5.1 决策框架：如何选择合适的发布策略</h3><p>发布策略的选择需要综合考虑<strong>技术能力</strong>、<strong>业务需求</strong>和<strong>风险承受能力</strong>多个维度：</p><table><thead><tr><th><strong>考虑维度</strong></th><th><strong>蓝绿发布</strong></th><th><strong>灰度发布</strong></th><th><strong>滚动发布</strong></th></tr></thead><tbody><tr><td><strong>团队技能</strong></td><td>入门级～中级</td><td>中高级～专家级</td><td>中级</td></tr><tr><td><strong>基础设施</strong></td><td>资源充足</td><td>资源弹性较好</td><td>资源有限</td></tr><tr><td><strong>发布频率</strong></td><td>低～中频</td><td>中～高频</td><td>高频</td></tr><tr><td><strong>风险容忍</strong></td><td>中等容忍</td><td>低容忍度</td><td>中等容忍</td></tr><tr><td><strong>回滚要求</strong></td><td>快速回滚</td><td>渐进回滚</td><td>缓慢回滚</td></tr></tbody></table><h3>5.2 混合策略：结合实际场景的灵活运用</h3><p>在实际生产环境中，往往需要根据具体场景<strong>组合使用</strong>多种发布策略：</p><p><strong>蓝绿+灰度组合</strong>：</p><ol><li>首先通过蓝绿发布搭建新版本环境</li><li>在新环境内进行灰度发布，逐步扩大流量</li><li>验证通过后全量切换，旧环境作为回滚备胎</li></ol><p><strong>功能开关+灰度发布</strong>：</p><ol><li>通过功能开关控制新功能的代码路径</li><li>结合灰度发布逐步开放给更多用户</li><li>出现问题时可快速通过功能开关关闭新功能</li></ol><h3>5.3 组织流程与文化建设</h3><p>技术策略的实施需要相应的<strong>组织流程</strong>和<strong>团队文化</strong>支持：</p><p><strong>发布审批流程</strong>：建立基于风险的发布审批机制<br/><strong>发布窗口管理</strong>：根据业务特征选择合适的发布时机<br/><strong>跨团队协作</strong>：开发、测试、运维、业务的紧密配合<br/><strong>持续改进文化</strong>：每次发布后进行复盘和优化</p><h2>总结</h2><p>灰度发布与蓝绿发布代表了现代软件工程的<strong>精细化运维</strong>理念，通过技术手段将发布过程从"高风险事件"转变为"可控过程"。这两种策略各有侧重，适用于不同场景，但核心目标一致：在保证业务连续性的前提下，安全高效地交付用户价值。</p><p><strong>关键成功因素</strong>：</p><ol><li><strong>技术基础设施</strong>：完善的监控体系、自动化工具链、弹性基础设施</li><li><strong>数据驱动决策</strong>：基于真实指标而非直觉的发布决策</li><li><strong>组织协作能力</strong>：跨团队的高效协作与明确的责任划分</li><li><strong>渐进式思维</strong>：小步快跑，快速验证，及时调整</li></ol><p>随着云原生技术的普及，发布策略正在向更加<strong>智能化</strong>、<strong>自动化</strong>的方向发展。未来，基于AI的预测性发布、自适应流量调度等新技术将进一步降低发布风险，提升交付效率。</p><hr/><p><strong>📚 下篇预告</strong><br/>《全栈监控与告警设计——从SLO到告警规则，避免告警雪崩的分级体系》—— 我们将深入探讨：</p><ul><li>📊 <strong>SLO量化管理</strong>：将业务目标转化为可衡量的服务质量指标</li><li>🚨 <strong>告警分级体系</strong>：基于影响范围和紧急程度的分类标准</li><li>⚡ <strong>智能降噪策略</strong>：避免告警雪崩的聚合与抑制机制</li><li>🔄 <strong>闭环管理流程</strong>：从告警产生到解决的全生命周期管理</li><li>📈 <strong>可观测性成熟度</strong>：构建层层递进的监控能力体系</li></ul><p><strong>点击关注，构建稳定可靠的监控告警体系！</strong></p><blockquote><p><strong>今日行动建议</strong>：</p><ol><li>评估当前业务的发布风险承受能力，选择合适的发布策略起点</li><li>建立关键的发布监控指标体系，制定明确的验收标准</li><li>设计自动化回滚流程，确保出现问题时的快速恢复能力</li><li>规划渐进式发布路线图，从简单场景开始逐步完善发布能力</li></ol></blockquote>]]></description></item><item>    <title><![CDATA[什么是 2026 AI 元年：人工智能进入应用时代 智能体小狐 ]]></title>    <link>https://segmentfault.com/a/1190000047556327</link>    <guid>https://segmentfault.com/a/1190000047556327</guid>    <pubDate>2026-01-21 17:04:57</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>一、背景：为什么 2026 被认为是 AI 元年</h2><p>过去十年，人工智能的发展主要集中在​<strong>技术突破阶段</strong>​：算法进步、算力提升、模型规模扩大。但到 2024–2025 年，这种变化开始发生转折。大模型能力趋于稳定，成本快速下降，工具链逐步完善，AI 不再只是实验室技术，而是开始进入真实生产系统。</p><p>2026 年被称为“AI 元年”，并不是因为 AI 在这一年才出现，而是因为​<strong>这一年，人工智能第一次具备了大规模、稳定、可复制落地的条件</strong>​。<br/>从技术演示走向真实应用，是 AI 发展的关键分水岭。</p><hr/><h2>二、什么是“AI 元年”：一个清晰的定义标准</h2><p><strong>AI 元年</strong>不是营销概念，而是一个产业判断标准。它至少满足三个条件：</p><ol><li><strong>AI 能稳定参与核心生产流程</strong><br/>不再只是辅助工具，而是成为流程的一部分。</li><li><strong>AI 应用具备规模化能力</strong><br/>不是个例成功，而是行业可复制。</li><li><strong>AI 成本下降到可普及水平</strong><br/>企业和个人都能负担并长期使用。</li></ol><p>2026 年，以上三个条件同时满足，这就是它被称为“AI 元年”的原因。</p><hr/><h2>三、技术拐点：大模型、智能体与工具链成熟</h2><h3>1. 大模型（LLM）进入稳定可用阶段</h3><p>到 2026 年，大模型的能力不再依赖规模指数级增长，而是转向​<strong>稳定性、可控性与成本优化</strong>​。模型成为基础设施，而非稀缺资源。</p><p>​<strong>大模型的角色变化</strong>​：<br/>从“展示能力” → “长期运行的生产组件”。</p><hr/><h3>2. 智能体（AI Agent）成为主流应用形态</h3><p>智能体是基于大模型构建的​<strong>自主执行系统</strong>​，具备规划、执行、记忆与反馈能力。它的出现，标志着 AI 从“生成内容”进入“完成任务”。</p><p>这意味着：</p><ul><li>AI 可以接管流程，而不仅是输出</li><li>AI 可以长期运行，而不仅是一次调用</li><li>AI 可以协同多个工具，而不是单点能力</li></ul><hr/><h3>3. 工具链完善，AI 工作流成为标准</h3><p>到 2026 年，**Workflow（工作流）+ Agent（智能体）+ 工具调用（Tool Calling）**成为标准架构，AI 应用的开发门槛大幅降低，推动大规模落地。</p><hr/><h2>四、应用拐点：AI 从试验走向规模化</h2><p>真正标志 AI 元年到来的，不是技术本身，而是​<strong>应用形态的变化</strong>​。</p><ul><li>AI 开始进入企业核心业务</li><li>AI 成为日常工作的一部分</li><li>AI 不再需要“单独学习”，而是自然使用</li></ul><p>AI 应用从“项目制”转向“系统化”，从“辅助工具”转向“生产成员”。</p><hr/><h2>五、产业影响：哪些行业最先被重塑</h2><h3>1. 内容与创意产业</h3><p>智能体接管生产流程，创作者转向系统设计与认知输出。</p><h3>2. 软件与 IT 行业</h3><p>AI 编程、AI 运维、AI 测试成为默认能力。</p><h3>3. 企业运营与管理</h3><p>AI 进入决策支持、数据分析、流程优化环节。</p><h3>4. 教育与培训</h3><p>AI 成为个性化导师，重塑学习方式。</p><p>这些行业的共同特征是：​<strong>高度信息化、流程可拆解、结果可评估</strong>​。</p><hr/><h2>六、个人与企业如何提前布局</h2><p><strong>对个人而言：</strong></p><ul><li>学会与 AI Agent 协作，而不是只学工具</li><li>提升问题定义与判断能力</li><li>建立不可替代的认知优势</li></ul><p><strong>对企业而言：</strong></p><ul><li>把 AI 当作长期系统，而不是短期项目</li><li>优先改造流程，而不是单点引入</li><li>提前建设数据与工作流基础</li></ul><hr/><h2>七、未来 3–5 年的趋势判断</h2><ol><li>AI 将成为基础生产力</li><li>智能体将成为主要应用形态</li><li>AI 工作流成为企业标配</li><li>人机协作成为默认模式</li><li>不使用 AI 的组织将失去竞争力</li></ol><p><strong>2026 不是终点，而是起点。</strong></p><hr/><h2>八、总结：2026 AI 元年真正意味着什么</h2><p>2026 AI 元年，意味着人工智能​<strong>正式从技术革命进入应用革命</strong>​。<br/>从这一年开始，AI 不再是“未来的技术”，而是​<strong>现实的生产力基础设施</strong>​。</p><p>对个人来说，这是一次能力结构的升级窗口；<br/>对企业来说，这是一次组织形态的重构窗口；<br/>对社会来说，这是一次生产方式的长期变革。</p><p><strong>AI 元年，不是热潮，而是新常态的开始。</strong></p>]]></description></item><item>    <title><![CDATA[超越加密 终结信任焦虑 JoySSL剖析OV证书何以成为企业数字化发展的标配 完美的铁板烧 ]]></title>    <link>https://segmentfault.com/a/1190000047556340</link>    <guid>https://segmentfault.com/a/1190000047556340</guid>    <pubDate>2026-01-21 17:04:02</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在现代数字商业领域，仅靠网站展示绿色“安全锁”，已无法满足用户复杂的信任需求。当用户、合作伙伴及监管机构共同质疑“运营方主体身份”时，企业亟需更有说服力的解决方案。虽然DV证书可以实现数据加密，有效防止数据被盗取或篡改，但企业的身份却依旧隐藏在匿名之中。而EV证书虽然具备最高级别的身份认证，可视化效果显著。但严格的申请流程与相对较高的费用，并非适合所有企业在每个发展阶段采用。在这一信任需求的梯度范围内，OV证书凭借能力与成本的平衡点，成为企业从“身份模糊”迈向“可信认证”的战略性选择。JoySSL技术处专家强调，组织验证型证书的核心价值在于其对身份公信力、成本效率及广泛适用性的理想兼顾。不仅是合格的解决方案，更是企业在数字经济体系中开展合规运营、树立信誉、建立安全合作关系的标准配置。</p><p><img width="723" height="478" referrerpolicy="no-referrer" src="/img/bVdnHJQ" alt="" title=""/></p><p><strong>权威身份验证 OV证书构建企业信任基础</strong></p><p>相比DV证书，OV证书的显著特点在于其验证机制由人工审核主导，而非完全依赖自动化流程。部署OV证书的网站，其背后运营者的身份不再是无法识别的匿名。这一身份认证，显著提高了仿冒与钓鱼行为的难度。在B2B业务、电子商务以及金融服务等领域，这种认证成为企业构建信任的基础技术手段。</p><p><strong>全面安全防护 超越数据加密完善风险管理</strong></p><p>OV证书提供与高级别证书相等强度的加密技术，采用国际标准的高强度加密算法，确保用户与网站之间的所有数据交互，在传输过程中保持机密性与完整性，满足不同行业对数据安全的核心诉求。同时，OV证书还承担重要的责任保障功能。通过提供高额保修服务，企业能够有效规避潜在风险，相当于为企业添加了一层“风险屏障”，有助于完善其自身的风险管理体系。</p><p><img width="723" height="479" referrerpolicy="no-referrer" src="/img/bVdnHJR" alt="" title="" loading="lazy"/></p><p><strong>高兼容高灵活 SSL证书适应多样化业务需求</strong></p><p>OV证书的研发，旨在满足现代企业复杂的IT环境，以及未来扩展的可能性。无论用户身处何地，都能够利用证书无障碍且无警告地浏览，为企业开展国际化业务提供技术支持。灵活的证书形式是拥有多个子站点、API接口或SaaS平台的企业的理想选择，适应企业多样化业务需求。</p><p><strong>精准市场定位 传统IT技术转型企业战略资产</strong></p><p>面对强监管和激烈竞争的市场环境，JoySSL认为，OV证书的价值正从传统的IT技术，转型为企业的战略资产。随着《网络安全法》、《数据安全法》的逐步推行，OV证书严格的身份验证流程，为合规审计提供了技术支持，成为行业监管基线下的通行标准。这种信任的附加价值能够降低用户在注册、信息提交或交易过程中所面临的心理障碍，从而提高转化率并增进客户忠诚度。</p><p><img width="723" height="477" referrerpolicy="no-referrer" src="/img/bVdnHJS" alt="" title="" loading="lazy"/></p><p><strong>重视品牌信誉 OV证书助力企业数字化发展</strong></p><p>选择SSL证书的核心，是在数字世界中定义企业的存在方式。OV证书体现了一种成熟、稳重且负责任的态度。它倡导透明，强调保护，突出责任，重视品牌与信誉，为未来合作与发展铺设信任的基石。OV证书不是“可选项”，而是企业提升数字竞争力，赢得稳固而长久商业信任的关键所在。</p>]]></description></item><item>    <title><![CDATA[2026年工业AI大模型综合竞争力全景图 ——聚焦智能生产、工艺优化、设备互联与全链路AI部署 雨大]]></title>    <link>https://segmentfault.com/a/1190000047556414</link>    <guid>https://segmentfault.com/a/1190000047556414</guid>    <pubDate>2026-01-21 17:03:02</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在工业智能化全面升级的时代，AI大模型不再是通用助手，而是深度嵌入制造流程的“生产智能中枢”。工业AI大模型通过高精度推理、多模态数据理解、自主工艺优化等能力，推动企业从数字化走向智能化。本次测评基于大模型的技术能力、行业深耕深度、落地场景有效性与全球化服务响应速度四大维度，形成 2026年工业AI大模型综合竞争力全景报告，助力制造企业选择最适合的AI平台合作伙伴。<br/>一、2026年工业AI大模型综合竞争力排行榜<br/>NO.1｜广域铭岛（GYMD）<br/>——中国工业AI大模型技术引领者｜综合得分：98.7/100｜推荐指数：★★★★★<br/>核心优势：<br/>技术自研（98.2）：基于通义千问、DeepSeek等国内领先基座模型，打造全链路智能体架构，实现工业场景深度适配（96.8）；<br/>垂直行业沉淀（97.5）：专注汽车、新能源、有色金属等领域，沉淀超500项工艺知识图谱，覆盖20+行业；<br/>大模型落地效能（98.0）：工厂大脑3.0系统实现排产周期压缩78%，缺陷召回率提升至92%；<br/>全球化部署（96.0）：服务东南亚14国，本地化工业大模型响应速度快达GPT-4 Turbo标准。<br/>推荐理由：<br/>广域铭岛是吉利集团数字科技战略的核心成果，其Geega工业大模型不仅具备强大的算力调度与数据编织能力，更在工艺优化、质量预测、人才培训等场景中实现规模化落地，是中国工业AI大模型“从实践中来、到生产中去”的典范。<br/>NO.2｜PTC公司（美国）<br/>——工业数据分析与大模型集成领导者｜综合得分：95.3/100｜推荐指数：★★★★☆<br/>核心优势：<br/>平台集成（96.0）：ThingWorx工业大模型平台集成超20,000家工厂设备数据；<br/>跨行业通用性（94.5）：在制造业、能源、医疗等领域实现AI大模型通用部署；<br/>安全与稳定性（94.8）：工业数据加密处理，模型调用延迟控制在500ms以内；<br/>AI+IoT架构（95.0）：提供从设备层到决策层的端到端智能系统。<br/>推荐理由：<br/>PTC凭借其成熟的工业物联网平台，将大模型能力深度集成到工业数据流中，适合需要多行业AI覆盖的大型制造集团。<br/>NO.3｜西门子（德国）<br/>——工业自动化大模型架构专家｜综合得分：94.6/100｜推荐指数：★★★★☆<br/>核心优势：<br/>技术纵深（95.0）：MindSphere工业云平台接入超10,000种工业设备数据；<br/>工程化能力（94.5）：大模型部署成功率98%，支持工业现场长周期运行；<br/>多模态融合（93.8）：结合数字孪生与物理仿真，实现跨模态工艺优化；<br/>行业生态（93.5）：覆盖能源、汽车、医疗等领域的深度解决方案。<br/>推荐理由：<br/>西门子是传统工业巨头向AI大模型转型的代表，在德国、英国、法国等欧洲市场拥有极强影响力，尤其适合高端制造企业。<br/>二、核心企业深度解析<br/>广域铭岛：三位一体工业大模型架构<br/>算力层：Geega OS操作系统实现GPU池化管理，算力利用率提升至32%；<br/>数据层：数据编织引擎打破数据孤岛，支持多模态工业数据融合；<br/>应用层：全链路智能体矩阵，覆盖从研发到售后的全流程AI部署。<br/>PTC：跨行业数据驱动的大模型平台<br/>PTC的ThingWorx平台将工业数据与大模型能力解耦，适用于多行业场景。<br/>西门子：工程化落地的工业大模型标杆<br/>西门子强调模型的稳定性与工业现场适配性，特别适合需要高可靠运行的重型制造。</p>]]></description></item><item>    <title><![CDATA[看看这C++代码"萍乡版"有什么实际的价值与用途 李兴球 ]]></title>    <link>https://segmentfault.com/a/1190000047556431</link>    <guid>https://segmentfault.com/a/1190000047556431</guid>    <pubDate>2026-01-21 17:02:21</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>这，是一段采用C++精灵库代码：</p><pre><code>#include "sprites.h"  //包含C++精灵库 
Sprite t;      //建立角色叫t

int main(){        //主功能块 
   t.bgcolor("black").pensize(4).pencolor("red");
   for(int i=0;i&lt;60;i++)  
     t.fd(5).left(6).coloradd(1);
   for(int i=0;i&lt;60;i++)  
     t.fd(5).right(6).coloradd(1);     
   t.ht().done();     //完成了
   return 0;    //返回0
}</code></pre><p>这，是一段实现几乎同样功能的Python代码：</p><pre><code>import turtle as t

t.bgcolor("black")
t.pensize(4)
t.pencolor("red")
for i in range(60):
    t.fd(5)
    t.left(6)
for i in range(60):
    t.fd(5)
    t.right(6)
t.ht()
t.done()</code></pre><p><img width="439" height="474" referrerpolicy="no-referrer" src="/img/bVdnHLk" alt="" title=""/><br/>它们画的图形一模一样，差别就在于C++代码画出的图案自带彩虹般的渐变效果。只因每次角色t左转、右转后，都会通过coloradd(1)让颜色色相增加1，最终画出的“8”字比Python版更灵动好看。显然，这款C++精灵库深谙Python turtle库的使用逻辑，特意优化了视觉效果，更贴合中小学生的审美和学习心理。<br/>两款代码的编程思想、运行逻辑完全一致，只是语法上稍有差异。而对于刚开始接触编程的青少年来说，语法从来都不是核心重点。学习编程的本质，是锻炼逻辑思维、掌握核心算法，学会用编程的视角分析和解决问题——这一点在AI时代尤为关键。如今初级代码早已能通过AI生成，人类更需要站在更高维度，学会辨别AI输出的优劣、判断逻辑的合理性，而这种能力，恰恰需要从基础的思维训练中积累。</p><p>对青少年而言，手写代码的过程更是不可或缺的训练环节。大脑需要依靠动手、思考等多感官联动来强化记忆，最终完成思维的沉淀与提升。如果只看不练，或是依赖自动补全、AI生成等“捷径”，只会让大脑养成偷懒的习惯，看似省了力，实则错失了思维成长的关键机会，到最后脱离工具便寸步难行。当然，工作场景的目标不同，只要能高效完成任务，借助工具无可厚非，但学习阶段，必须沉下心手写每一行代码，筑牢基础。</p><p>回到这款C++精灵库本身，它的价值远不止“画出更好看的图案”这么简单，对中小学生C++启蒙教育来说，更是一款极具针对性的优质工具。首先，它完美衔接了中小学生熟悉的Python turtle库逻辑，语法风格贴近，降低了C++的入门门槛。很多孩子初学C++时，会因语法严谨性、图形库配置复杂而产生畏难情绪，而这款精灵库省去了繁琐的底层配置，保留了直观的绘图交互，让孩子能快速上手，把注意力集中在逻辑思考上，而非纠结于语法细节和环境搭建。</p><p>其次，它在保留核心编程逻辑的基础上，增加了coloradd()这类轻量化特效接口，既满足了孩子对“酷炫效果”的追求，又引导他们主动探索语法背后的功能差异。这种可视化的反馈的能极大提升学习兴趣，让抽象的编程概念变得具象可感——孩子能直观看到自己写的代码如何改变图案颜色、形状，从而更易理解循环、函数调用等核心知识点，激发持续学习的动力。</p><p>再者，它为Python与C++的学习衔接搭建了桥梁。很多中小学编程启蒙先从Python开始，孩子熟悉turtle绘图后，通过这款精灵库转学到C++，能快速找到熟悉的操作逻辑，降低跨语言学习的不适感。同时，它又保留了C++的核心特性，让孩子在启蒙阶段就接触到面向对象编程的雏形（如Sprite类的实例化、方法链式调用），为后续深入学习C++、Java等语言打下扎实基础。</p><p>传统C++启蒙常陷入“重语法、轻应用”的误区，孩子对着枯燥的控制台输出反复练习，容易失去兴趣。而这款C++精灵库以可视化绘图为载体，兼顾了趣味性、易用性和教育性，既让孩子在动手实践中锤炼了编程思维，又化解了C++入门的难度。对中小学生来说，它不是一款复杂的专业库，而是一个能陪伴自己入门编程、培养核心能力的好帮手，无疑是值得尝试的中小学C++教育工具。</p>]]></description></item><item>    <title><![CDATA[AI 能力揭秘（五）：Apache Doris 原生向量检索的设计及实现 SelectDB技术团队 ]]></title>    <link>https://segmentfault.com/a/1190000047556439</link>    <guid>https://segmentfault.com/a/1190000047556439</guid>    <pubDate>2026-01-21 17:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><strong>引言</strong>：</p><p>随着大模型和多模态 AI 的快速发展，向量已成为文本、图像、音视频等多元数据的通用语义表示。在这种背景下，检索增强生成（RAG）技术成为连接私有知识与大模型的核心桥梁，而高效的向量检索则是其关键支柱。</p><p><strong>与将向量检索视为独立外挂服务的方案不同，Apache Doris 4.0 选择将向量检索能力深度集成于其 MPP 分析型数据库内核。实现向量检索与 SQL 计算、实时分析和事务保障的无缝融合。</strong></p><p>本文旨在深入剖析 Doris 向量检索的系统级设计与工程实践，展示其如何在性能、易用性与规模扩展之间取得的平衡。</p><h2>1. ANN 索引核心设计</h2><p><strong>Apache Doris 的向量索引基于 ANN（近似最近邻）算法实现，并非独立的外挂组件，而是深度集成于存储、执行与 SQL 引擎中的原生能力</strong>。在 4.x 版本中，其核心 ANN 索引能力主要包括以下几方面：</p><ol><li><strong>多索引类型与距离度量支持</strong>：支持主流的 ANN 索引类型（HNSW、IVF）及常见距离度量（L2 距离、内积）。用户可根据业务在构建速度、内存占用与召回率上的要求灵活权衡。</li><li><strong>原生 SQL 集成</strong>：向量检索以原生 SQL 算子形式提供，支持直接定义向量列、通过 <code>ORDER BY distance LIMIT K</code> 进行相似度搜索，并能与过滤、聚合、JOIN 等算子自由组合，天然支持<a href="https://link.segmentfault.com/?enc=1oH5TZFxgDVJhvRJW%2BgiPA%3D%3D.LnQnNEyfyRIkeqkjJ0nSIZmG4EEeQq7JGx9V16ZqBbKY0SWx0HcD6%2FY6QDFmCOam" rel="nofollow" target="_blank">混合检索与分析</a>。</li><li><strong>构建与查询解耦</strong>：采用异步索引构建机制，数据导入后即可查询，索引在后台构建并加载，避免导入阻塞，保障查询高峰期的稳定低延迟写入。</li><li><strong>向量压缩优化</strong>：在导入与构建阶段支持标量量化（SQ）、乘积量化（PQ）等压缩技术，显著降低存储与内存开销，提升高维大规模向量场景的资源效率。</li><li><strong>分布式并行执行</strong>：依托于分布式架构，Doris 向量索引天然支持数据分片与索引分布式存储；查询可在各 BE 节点并行执行；Top-K 结果在上层进行合并与裁剪。随着节点数量增加，系统能够在数据规模与吞吐能力上实现近线性扩展。</li></ol><h2>2. Benchmark &amp; Analysis</h2><p>Apache Doris 的目标并非追求单一指标的极限表现，而是在<strong>真实生产负载下，实现性能的均衡性、系统稳定性与架构可扩展性</strong>。本次测试将围绕这一目标展开，所用工具为 ZillizTech 开源的向量搜索 BenchMark：<a href="https://link.segmentfault.com/?enc=D0QyyZ%2F5aVAGAjwgTXVGuw%3D%3D.eRZhLWIKllpieXDyf5NBeNJzjFA59cjeP%2B6iKjQ5kL7cryEh60HANK9HZ35Y0a7s" rel="nofollow" target="_blank">https://github.com/zilliztech/VectorDBBench</a>。</p><ul><li>云服务商：阿里云</li><li>CPU：Intel Xeon Platinum 8369B @ 2.70GHz (16 核)</li><li>内存：64GB</li></ul><h3>2.1 导入与构建性能</h3><p>测试结果表明，在 Performance768D1M 数据集上，Apache Doris 在保证同等索引质量的前提下，导入性能显著优于对比系统。尤为重要的是，其导入速度的提升并未以牺牲图结构质量为代价。<strong>Doris 在 QPS 达到 895 的同时，仍保持了 97% 以上的召回率，在性能三角的三个维度上取得了出色的平衡</strong>。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556441" alt="2.1 导入与构建性能.PNG" title="2.1 导入与构建性能.PNG"/></p><h3>2.2 查询性能</h3><p>即便单独考量查询性能，Apache Doris 同样处于业界第一梯队。</p><p>在 Performance768D10M 数据规模上，<strong>当召回率要求高于 95% 时，Apache Doris 的 QPS 表现优于 OpenSearch 与 Qdrant</strong>。<em>此结果为默认配置下的开箱性能，未针对 Segment 文件数量等进行专项调优</em>。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556442" alt="2.2 查询性能.png" title="2.2 查询性能.png" loading="lazy"/></p><blockquote><p>这里比较的是开箱性能测试，即不做 segment 文件数量的优化时的性能对比。</p><p>Milvus 的 flat 版本以及 Cloud 版本会有更好的性能表现，但是其出品的 VectorDBBench 只提供了 SQ8 量化后的成绩。</p></blockquote><h2>3. 核心设计与性能优化</h2><p>Apache Doris 采用 FE（协调节点）与 BE（计算节点）构成的分布式架构。BE 作为核心执行单元，承担查询计划执行与数据导入任务，负责几乎所有高负载计算与大规模数据吞吐，是系统高性能的基石。尤其在向量场景下，数据写入、索引构建与向量距离计算都属于典型的 CPU 与内存密集型工作。<strong>为充分发挥其性能、保障系统稳定运行，我们对 ANN 索引的写入、构建与查询路径进行了系统优化</strong>。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556443" alt="3. 核心设计与性能优化.png" title="3. 核心设计与性能优化.png" loading="lazy"/></p><h3>3.1 写入与构建路径优化</h3><p>优化主要分为两类：<strong>功能优化</strong>与<strong>性能优化</strong>。</p><ul><li>在功能层面，依托 Doris 成熟的分布式集群管理与存储管理能力，引入 <strong>LightSchemaChange</strong> 实现轻量级的索引管理机制，这是目前专用向量数据库普遍不具备的能力。</li><li>在性能层面，重点聚焦于索引构建流程的优化，以显著提升索引构建速度和整体吞吐能力。</li></ul><h4>3.1.1 异步索引构建机制</h4><p><strong>Apache Doris 针对 ANN 索引构建开销大的问题，提供了异步构建机制</strong>。用户可在数据导入后，选择业务低峰期触发索引构建；在查询高峰时，仅需将已建好的索引加载至内存即可快速检索，从而将密集的 CPU 消耗转移至成本更低的时段。</p><p>在 FE 侧，<code>CREATE INDEX</code> 与 <code>BUILD INDEX</code> 通过 <code>SchemaChangeHandler</code> 编排：</p><ol><li>为每个分区创建影子索引与影子 Tablet（<code>IndexState.SHADOW</code>），并建立 origin→shadow 的 Tablet 映射与影子副本（副本初始态为 <code>ALTER</code>）。</li><li>生成新的 schema version/hash，保障新旧版本隔离。</li><li>通过 FE→BE 的 AgentTask（Thrift）分发构建任务到各 BE，BE 在 Tablet 层面完成索引数据构建。</li><li>构建成功后，FE 原子性地将影子索引切换为正式索引，更新元数据并清理旧工件。</li></ol><p>该流程在保证线上业务可读写的同时，实现了索引构建的在线隔离与数据一致性。</p><h4>3.1.2 导入性能优化</h4><p>为在保障索引质量的前提下提升写入吞吐与稳定性，Doris 采用了 <strong>多层级分片、双层并行、SIMD 向量化计算</strong> 的组合方式进行优化。</p><p><strong>A. 多层级分片</strong></p><p>Apache Doris 将逻辑表在内核层拆分为多个 Tablet。每次数据导入会生成一个 Rowset，每个 Rowset 又包含若干 Segment，而 ANN 索引正是在 Segment 粒度上构建与使用的。<strong>这一设计将“全表数据量”与“索引超参数”解耦，用户只需根据单批次导入的数据规模来设定参数，无需因数据总量增加而反复重建索引</strong>。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556444" alt="3.1.2 导入性能优化.png" title="3.1.2 导入性能优化.png" loading="lazy"/></p><p>以单 BE 单分桶的典型场景为例，我们从实际经验中总结出如下参数可供参考：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556445" alt="3.1.2 导入性能优化-1.png" title="3.1.2 导入性能优化-1.png" loading="lazy"/></p><p>得益于 Apache Doris 的分片架构下，索引参数可稳定在合理的规模区间，不受全表数据总量增长的影响。<strong>换言之，索引超参数的设置只需基于单个 Tablet 单次导入的数据行数</strong>。即便集群规模扩大，也仅需根据机器与分桶数量相应调整批次大小（batch size）即可。</p><p>以 HNSW 索引为例，在单 BE 集群中，针对每批导入 25 万、50 万、100 万行的典型规模，分别选择 <code>max_degree≈100/120/150</code>、<code>ef_construction≈200/240/300</code>、<code>hnsw_ef_search≈50~200</code>，即可在延迟可控的同时平衡召回与构建成本。</p><p>经验上，召回率随 <code>hnsw_ef_search</code> 提高而改善，但查询延迟也会线性增加。<code>max_degree</code> 与 <code>ef_construction</code> 过小会导致图结构稀疏、查询不稳定；过大则会显著增加构建时间与内存占用。因此，<strong>建议结合业务对召回和延迟的要求，通过离线压测确定最佳参数组合</strong>。</p><p><strong>B. 双层并行构建</strong></p><p>集群层由多台 BE 并行处理导入批次；单机内再对同一批数据进行多线程距离计算和图结构更新。配合“内存攒批”（在内存中适度合并小批次），可避免过细分批导致的图结构稀疏与召回下滑，在固定超参数下获得更稳定的索引质量与构建速度。</p><p>以 768 维、1,000 万条向量为例：分 10 批构建的召回率约可达 99%，若切成 100 批则可能降至约 95%。<strong>适度的内存攒批既不显著抬高内存峰值，又能提升图连通性和近邻覆盖，从而减少查询阶段的回表与重复计算</strong>。</p><p><strong>C. SIMD 加速</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556446" alt="3.1.2 导入性能优化-2.png" title="3.1.2 导入性能优化-2.png" loading="lazy"/></p><p>向量距离计算是典型的 CPU 密集型计算。Doris 在 BE 侧采用 C++ 实现距离计算，引入 SIMD（单指令多数据）并行计算。可以<strong>更少的指令、更少的访存，更快完成把同样的距离</strong>，从而显著提升向量索引构建和重排阶段的吞吐能力。具体来讲：</p><ul><li><strong>并行计算多个维度</strong>：利用 SSE / AVX / AVX-512 等指令集，同时加载和计算 8～16 个浮点数，而非逐维循环。</li><li><strong>减少内存访问</strong>：在计算前对向量数据进行批处理和转置，使数据在内存中连续排列，优化 CPU Cache 访问模式。</li><li><strong>合并计算步骤</strong>：使用 FMA（乘加融合）指令，把“乘法 + 加法”合并为一步，并通过水平求和快速聚合向量数据。</li><li><strong>高效处理边界情况</strong>：对维度不对齐的尾部数据，使用掩码指令统一处理，避免额外分支和判断。</li></ul><h4>3.1.3 向量压缩技术</h4><p>以 HNSW 为代表的高性能索引数据结构通常将向量与图结构常驻内存。在 RAG 场景中，文本/图片/音频等模态向量维度约为 1,000，若每维使用 <code>FLOAT32</code> 存储，一百万行占用 4 GB，千万行则约 40 GB。考虑到索引结构的额外占用（约 1.3 倍），一千万行整体接近 52 GB。以 16C64GB 机器为例，单机索引上限约为千万级，需预留空间以避免 OOM，并保障查询和构建的并行开销。</p><p>为了显著降低内存占用、扩展单机承载能力，向量压缩技术成为关键。<strong>Apache Doris 在此提供了两种主流的实现方案：标量量化与乘积量化</strong>。</p><p><strong>A. 标量量化（Scalar Quantization，SQ）</strong></p><p>标量量化通过用低精度类型替换高精度类型来压缩存储空间，Doris 支持 <code>INT8</code> 和 <code>INT4</code> 的标量量化，并在导入和构建阶段完成编码。</p><p>如若将 <code>FLOAT32</code>（4 字节）替换为 <code>INT8</code>（1 字节）可节省约 75% 存储，进一步压缩为 <code>INT4</code> 则节省约 87.5%。如果压缩后数据的分布形态保持一致，召回率在可控延迟内接近未压缩效果。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556447" alt="3.1.3 向量压缩技术.png" title="3.1.3 向量压缩技术.png" loading="lazy"/></p><p>上图展示了在 128 维和 268 维向量上的测试结果。相比 FLAT（不编码，用完整 Float32 表示每个浮点数），<strong>SQ8 可实现接近 2.5 倍的压缩，而 SQ4 可实现接近 3.3 倍的压缩</strong>。</p><p>值得说明的是，引入 SQ 不可避免的会带来额外的压缩计算开销（索引构建阶段），且标量量化更适用于各维度近似均匀分布的数据。如遇分布呈高斯或更复杂形态时，标量量化误差增大，则可采用乘积量化方式。</p><p><strong>B. 乘积量化（Product Quantization， PQ）</strong></p><p>RAG 等场景中，由 Transformer 编码器生成的向量，存在明显的语义结构、分布不均匀。<strong>乘积量化通过子空间划分 + 子空间学习型量化，能够更好地适配</strong>。</p><p>PQ 将高维向量分割为多个子向量，并为每个子空间独立训练一个码本（例如通过 k-means 聚类学习质心）。这使得数据密集区域能用更精细的码本保持细节，从而在整体上用更短的码长维持原始的距离关系。查询时通过查表与累加来估算距离，大幅减少了计算与内存访问开销。</p><p>我们在 128 维与 268 维上对比 SQ 与 PQ，参数统一设定为 <code>pq_m = dim/2</code>、<code>pq_nbits = 8</code>。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556448" alt="3.1.3 向量压缩技术-1.png" title="3.1.3 向量压缩技术-1.png" loading="lazy"/></p><p>从空间占用看，<strong>PQ（m=68/128， nbits=8）的内存占比与 SQ4 大致相当，可实现约 3× 压缩</strong>。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556449" alt="3.1.3 向量压缩技术-2.png" title="3.1.3 向量压缩技术-2.png" loading="lazy"/></p><p>除构建更快外，PQ 还可依赖查表加速解码，体现在更优的查询速度上。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556450" alt="3.1.3 向量压缩技术-3.png" title="3.1.3 向量压缩技术-3.png" loading="lazy"/></p><p>关于 PQ 的超参数，实际使用时建议结合数据分布进行针对性适配与调优。根据经验，将 <code>pq_m</code> 设为原始维度的一半，<code>pq_nbits</code> 设为 8，在多数场景下即可取得良好的效果，可作为初始调优的参考起点。</p><p><strong>综合来看，对于用户来说， SQ 和 PQ 该如何选择呢</strong>？</p><ul><li>从使用上来说，SQ 的优点是使用方式简单，只需要指定数据类型即可，而 PQ 的使用门槛更高，需要对其原理有较为深刻的理解才能在生产环境中发挥其优势。</li><li>从性能及开销上来说，SQ 在解码阶段存在额外计算开销，且随维度增加开销更高；PQ 则能在压缩的同时保持接近原始向量的查询性能。</li><li>从场景上来说，SQ 更适用于各维度近似均匀分布的数据。如遇分布呈高斯或更复杂形态时，标量量化误差增大，则可采用乘积量化方式。</li></ul><h3>3.2 查询执行路径优化</h3><p>搜索场景对延迟极为敏感。在千万级数据量与高并发查询的场景下，通常需要将 P99 延迟控制在 200 ms 以内。这对 Doris 的优化器、执行引擎以及索引实现都提出了更高要求。Apache Doris 为此做了大量优化，这一章节对其中涉及到的部分能力做介绍。</p><h4>3.2.1 虚拟列机制</h4><p>Apache Doris 的向量索引采用外挂方式。外挂索引便于管理与异步构建，但也带来性能挑战：<strong>如何避免重复计算与多余 IO</strong>？</p><p>ANN 索引在返回行号时，会同步计算出向量距离。执行引擎在 Scan 算子阶段可直接利用该结果进行筛选和排序，无需在读取数据后重新计算。<strong>这一过程通过 “虚拟列” 机制自动实现，最终以 Ann Index Only Scan 的形式运行，完全消除了因距离计算而产生的数据读取 I/O</strong>。</p><p>未应用  Index Only Scan：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556451" alt="3.2.1 虚拟列机制.png" title="3.2.1 虚拟列机制.png" loading="lazy"/></p><p>应用 Index Only Scan 后：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047556452" alt="3.2.1 虚拟列机制-1.png" title="3.2.1 虚拟列机制-1.png" loading="lazy"/></p><p>例如 <code>SELECT l2_distance_approximate(embedding, [...]) AS dist FROM tbl ORDER BY dist LIMIT 100;</code>，执行过程将不再触发数据文件 IO。</p><p><strong>该优化不仅适用于 TopK 检索，也支持 Range Search、复合检索（Range + TopK）以及与倒排索引结合的混合检索场景，实现了全路径的 Index Only Search</strong>。</p><p>虚拟列机制并不局限于向量距离计算。对于正则抽取、复杂标量函数等 CPU 密集型表达式，若在同一查询中被多次引用，该机制也能复用中间结果，避免重复计算。<strong>以 ClickBench 数据集为例，以下查询统计从 Google 获得最多点击的 20 个网站</strong>：</p><pre><code class="SQL">set experimental_enable_virtual_slot_for_cse=true;

SELECT counterid,
       COUNT(*)               AS hit_count,
       COUNT(DISTINCT userid) AS unique_users
FROM   hits
WHERE  ( UPPER(regexp_extract(referer, '^https?://([^/]+)', 1)) = 'GOOGLE.COM'
         OR UPPER(regexp_extract(referer, '^https?://([^/]+)', 1)) = 'GOOGLE.RU'
         OR UPPER(regexp_extract(referer, '^https?://([^/]+)', 1)) LIKE '%GOOGLE%' )
       AND ( LENGTH(regexp_extract(referer, '^https?://([^/]+)', 1)) &gt; 3
              OR regexp_extract(referer, '^https?://([^/]+)', 1) != ''
              OR regexp_extract(referer, '^https?://([^/]+)', 1) IS NOT NULL )
       AND eventdate = '2013-07-15'
GROUP  BY counterid
HAVING hit_count &gt; 100
ORDER  BY hit_count DESC
LIMIT  20;</code></pre><p>核心表达式 <code>regexp_extract(referer, '^https?://([^/]+)', 1)</code> 为 CPU 密集型且被多处复用。启用虚拟列优化（<code>set experimental_enable_virtual_slot_for_cse=true;</code>）后，<strong>端到端性能提升约 3 倍</strong>。</p><h4>3.2.2 前过滤与谓词下推</h4><p>在 ANN TopN 检索中，过滤谓词的应用时机是关键的设计权衡：</p><ul><li>前过滤：在 TopN 之前应用谓词，能阻止无效行进入候选；但需在候选集维护过程中实时剔除不符合条件的行。</li><li>后过滤：先按相似度取出 TopN，再执行过滤，可能导致最终结果不足 N 条。虽然可通过扩大 N 来补偿，但会额外增加扫描与计算开销。</li></ul><p><strong>Apache Doris 在 Scan 算子内通过 row bitmap 实现自然的前过滤语义</strong>。每个谓词执行后即时更新 row bitmap。当 TopN 下推到 Scan 时，向索引传递一个基于 row bitmap 的 IDSelector，仅保留满足条件的行作为候选，从源头上避免无效候选进入 TopN。</p><p>为进一步提升效率，Doris 还会在扫描前借助分区、分桶、ZoneMap 等轻量元数据进行快速预过滤，并结合倒排索引进行精确的行号定位，多层次缩小候选集，能够显著提升查询性能与资源效率。</p><h4>3.2.3 全局执行优化</h4><p>在传统执行路径中，Doris 会对每条 SQL 执行完整优化流程（语法解析、语义分析、RBO、CBO）。这在通用 OLAP 场景必不可少，但在搜索等简单且高度重复的查询模式中会产生明显的额外开销。为此，Doris 进行了全局执行优化，充分发挥索引、过滤等性能。</p><p><strong>A. Prepare Statement</strong>： </p><p><strong>Doris 4.0 扩展了 Prepare Statement，使其不仅支持点查，也适用于包含向量检索在内的所有 SQL 类型</strong>。Prepare Statement 的原理是将 SQL 编译与执行分离，模板化检索复用计划缓存，Execute 阶段跳过优化器。查询计划按“标准化 SQL + schema 版本”构建指纹进行缓存，执行阶段校验 schema version，变化则自动失效并重建。对频繁且结构相同仅参数不同的检索，Prepare 能显著降低 FE 侧 CPU 占用与排队等待。</p><p><strong>B. Scan 并行度优化</strong>：</p><p>为提升 ANN TopN 检索性能，Doris 重构了 Scan 并行策略。原策略基于行数划分任务，在高维向量场景下，单个 Segment 的实际行数常远低于划分阈值，导致多个 Segment 被分配至同一任务中串行扫描，制约性能。</p><p>为此，<strong>Doris 改为严格按 Segment 创建 Scan Task，显著提升了索引检索阶段的并行度</strong>。由于 ANN TopN 搜索本身过滤率极高（仅返回 TopN 行），后续回表阶段即使串行执行，对整体吞吐与延迟的影响也微乎其微。</p><p>以 SIFT 1M 数据集为例，开启 <code>optimize_index_scan_parallelism=true</code> 后，<strong>TopN 查询耗时从 230ms 降至 50ms，效果显著</strong>。</p><p>此外，4.0 引入动态并行度调整：每轮调度前根据 Scan 线程池压力动态决定可提交的任务数；压力大则减并行、资源空闲则增并行，以在串行与高并发场景间兼顾资源利用率与调度开销。</p><p><strong>C. TopN 全局延迟物化</strong>：</p><p>典型的 ANN TopN 查询可分为两个关键阶段：局部检索与全局归并。在局部检索阶段，Scan 算子通过索引获取每个数据分片（Segment）中的局部 TopN 近似距离；随后在全局归并阶段，由专门的排序节点对所有分片的局部结果进行合并，筛选出最终的全局 TopN。</p><p>传统执行流程存在一个显著效率问题：若查询需要返回多列或包含大字段（如长文本），在第一阶段就会读取这些列的全部数据。这不仅会引发大量磁盘 I/O，而且绝大多数被读取的行会在第二阶段的排序竞争中被淘汰，<strong>造成计算与 I/O 资源的浪费</strong>。</p><p><strong>为此，Doris 引入了 “全局 TopN 延迟物化” 优化。该机制将非排序所需列的读取推迟到最终结果确定之后，大幅减少了不必要的 I/O</strong>。</p><p>优化执行流程示例：</p><p>以 <code>SELECT id, l2_distance_approximate(embedding, [...]) AS dist FROM tbl ORDER BY dist LIMIT 100;</code> 为例：</p><ol><li>局部轻量扫描：每个 Segment 利用 Ann Index Only Scan 结合虚拟列技术，仅计算出局部 Top 100 的距离值（<code>dist</code>）及其对应的行标识（<code>rowid</code>），不读取其他列。</li><li>全局排序筛选：系统汇总所有 M 个 Segment 的中间结果（共 100 × M 条候选），对其进行全局排序，从而确定最终的 100 个目标 <code>rowid</code>。</li><li>按需延迟物化：最终的 <code>Materialize</code> 算子根据上一步得到的 <code>rowid</code>，精准地到对应的存储位置读取所需列（例如 <code>id</code>）的数据。</li></ol><p>通过将完整数据的“物化”步骤推迟到最后，该优化确保了查询前期仅处理轻量的距离与行标识信息，彻底避免了在排序前读取非必要列所带来的 I/O 开销，从而显著提升了整体查询效率。</p><h2>4. 实战：使用 Apache Doris 搭建企业知识库</h2><p>企业级知识库是 RAG 的典型落地场景。因此，我们基于 LangChain + Apache Doris 搭建了一个以 Doris 官网文档为语料的最小可用知识库，用于验证 Doris 向量检索的端到端能力。完整示例代码见 <a href="https://link.segmentfault.com/?enc=kfqGSrSx%2FzjWx6rQHfSXEQ%3D%3D.AuRAeguVBBJ3sSrjx1KWPljbd5l5MXoIl4%2BP9zKlrZYWZtvyj2TJdA00bA84jf%2BiZpg608lV%2BEqVVfh2WAaLIQ%3D%3D" rel="nofollow" target="_blank">GitHub</a>。</p><p><strong>（1）环境准备</strong></p><ul><li>LLM：用于对话与答案生成，这里使用 DeepSeek。先在官网注册并创建 API Key，妥善保存，后续用于调用 DeepSeek API。</li><li>嵌入模型：用于生成检索向量，这里使用 Ollama + <code>bge-m3:latest</code>。bge-m3 是开源的通用检索向量模型，兼顾中英文检索效果，默认输出 1024 维向量，适合知识库检索场景。</li></ul><p><strong>（2）建库与建表（方式一：SQL）</strong></p><pre><code class="SQL">CREATE DATABASE doris_rag_test_db;

USE doris_rag_test_db;

CREATE TABLE doris_rag_demo (
  id int NULL,
  content text NULL,
  embedding array&lt;float&gt; NOT NULL,
  INDEX idx_embedding (embedding) USING ANN PROPERTIES("dim" = "1024", "ef_construction" = "40", "index_type" = "hnsw", "max_degree" = "32", "metric_type" = "inner_product")
) ENGINE=OLAP
DUPLICATE KEY(id)
DISTRIBUTED BY HASH(id) BUCKETS 1
PROPERTIES (
"replication_allocation" = "tag.location.default: 1",
"storage_medium" = "hdd",
"storage_format" = "V2",
"inverted_index_storage_format" = "V3",
"light_schema_change" = "true"
);</code></pre><blockquote>说明：若计划使用 SDK 一键建表与导入（见 ⑤），本节可省略。</blockquote><p><strong>（3）演示语料</strong></p><p>示例使用 Apache Doris 官网文档作为语料来源：<a href="https://link.segmentfault.com/?enc=TCoo73UbFlR5rzAGZaL1DQ%3D%3D.5z0lksvj6btlUMHlr04zSjmKfVimLgVvgslIVjZWgo9htCnog7mqCLkv1HWACTqv" rel="nofollow" target="_blank">https://github.com/apache/doris-website</a></p><p><strong>（4）离线文档处理</strong></p><ul><li>切块（chunking）：采用重叠分割，将长文档切分为段落片段。</li></ul><pre><code class="Python">from langchain_text_splitters import RecursiveCharacterTextSplitter

text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=400, chunk_overlap=100, length_function=len
)
chunks = text_splitter.split_text(text)</code></pre><ul><li>生成向量（embedding）：对每个片段生成嵌入向量。</li></ul><pre><code class="Python">from typing import List, Dict
from langchain_community.embeddings import OllamaEmbeddings

embeddings = OllamaEmbeddings(model='bge-m3:latest', base_url='http://localhost:11434')

docs: List[Dict] = []
cur_id = 1
for chunk in chunks:
    docs.append({"id": cur_id, "content": chunk})
    cur_id += 1

contents = [d["content"] for d in docs]
vectors = embeddings.embed_documents(contents)</code></pre><p><strong>（5）导入 Doris（方式二：SDK 一键建表与导入）</strong></p><pre><code class="Python">import pandas as pd
df = pd.DataFrame(
        [
            {
                "id": d["id"],
                "content": d["content"],
                "embedding": vec,
            }
            for d, vec in zip(docs, vectors)
        ])

from doris_vector_search import DorisVectorClient, AuthOptions, IndexOptions

auth = AuthOptions(
    host='localhost',
    query_port=9030,
    http_port=8030,
    user='root',
    password='',
)

client = DorisVectorClient('doris_rag_test_db', auth_options=auth)

index_options = IndexOptions(index_type="hnsw", metric_type="inner_product")
table = client.create_table(
            'doris_rag_demo',
            df,
            index_options=index_options,
        )</code></pre><p>说明：若已通过 ② 使用 SQL 创建好表并定义索引，可仅使用 SDK 的导入接口（如 <code>insert</code>/<code>load</code> 等，视 SDK 能力而定）将数据写入既有表。</p><p><strong>（6）在线查询过程</strong></p><p>向量检索</p><pre><code class="Python">query = 'Doris 支持哪些存储模型？'
query_vec = embeddings.embed_query(query)
df = (
    table.search(query_vec)
    .limit(5)
    .select(["id", "content"])
    .to_pandas()
)</code></pre><p>答案生成</p><pre><code class="Python">ctx = "\n".join(f"{r['content']}" for _, r in df.iterrows())
prompt =  "以下是检索到的 Doris 文档片段：\n\n{}\n\n请根据上述内容回答：{}".format(ctx, query)

from langchain_openai import ChatOpenAI
llm = ChatOpenAI(
            model='deepseek-v3-1-terminus',
            api_key='xxxx',
            base_url='https://xxx',
            temperature=float(1.0))
resp = llm.invoke(prompt)</code></pre><p>返回的内容是：</p><pre><code class="Plain">'根据提供的文档内容，Apache Doris 支持以下三种存储模型：\n\n1.  明细模型（Duplicate Key Model）：适用于存储事实表的明细数据。\n2.  主键模型（Unique Key Model）：保证主键的唯一性，相同主键的数据会被覆盖，从而实现行级别的数据更新。\n3.  聚合模型（Aggregate Key Model）：相同键（Key）的数值列（Value）会被自动合并，通过提前聚合来大幅提升查询性能。\n\n此外，文档在“灵活建模”部分还提到，Apache Doris 支持如宽表模型、预聚合模型、星型/雪花模型等建模方式，这些可以看作是建立在上述三种核心存储模型之上的数据组织方法。'</code></pre><h2>5. 总结</h2><p>本文从 AI 时代的数据形态演进出发，系统性地介绍了 Apache Doris 在 4.x 版本中引入的向量检索能力，并对其底层实现进行了深入剖析。从 ANN 索引的能力边界，到 FE / BE 架构下的写入、构建与查询路径，再到 SIMD、压缩编码与执行引擎层面的工程优化，Doris 的向量搜索并非简单接入一个索引库，而是围绕 性能三角（召回率 / 查询延迟 / 构建吞吐） 精心设计的系统级方案。未来，我们还会进一步强化，使其成为 AI 时代数据系统智能检索的基石。</p>]]></description></item><item>    <title><![CDATA[2026可视化&结构化数据融合新方案：可插入多维表格的看板使用指南 曾经爱过的汉堡包 ]]></title>    <link>https://segmentfault.com/a/1190000047555747</link>    <guid>https://segmentfault.com/a/1190000047555747</guid>    <pubDate>2026-01-21 16:10:40</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><strong>简介</strong>：在远程与分布式工作模式成为常态的今天，高效的数据可视化与灵活的任务协同变得至关重要。可插入多维表格的看板，以其独特的“可视化+结构化数据”融合能力，正成为团队管理复杂项目、提升决策效率的新一代工具。本文将深度解析这类工具的核心优势，并结合当下技术趋势，为你提供选择与实践指南。</p><p>对于许多团队而言，看板是追踪任务进度的直观工具，而电子表格则是处理结构化数据的得力助手。但当项目信息需要在两者间频繁切换、手动同步时，效率瓶颈便随之产生。可插入多维表格的看板正是为了解决这一割裂而生，它让可视化的工作流与可深度操作的数据表在同一个界面无缝融合。</p><h2>01 核心挑战：现代团队协作中的数据割裂之痛</h2><p>在快节奏的项目推进中，团队常面临几大典型困扰：</p><ul><li><strong>信息孤岛</strong>：任务状态在看板上，详细数据（如预算、责任人联系方式、时间日志）却躺在另一个表格或文档里，导致上下文缺失。</li><li><strong>更新不同步</strong>：表格中的数据变更无法实时反映在看板的卡片上，手动更新耗时且易出错，尤其影响远程团队的协同效率。</li><li><strong>视图单一僵化</strong>：传统看板擅长管理流程状态，但对数据进行分组、筛选、排序或计算的能力较弱，限制了数据分析的维度。</li></ul><p>可插入多维表格的看板，其核心价值在于<strong>打破了可视化流程与结构化数据之间的壁垒</strong>。它允许团队在看板上的每张任务卡片中，直接嵌入一个功能完整的多维表格或数据库视图，实现了“一卡一世界，数据尽在掌握”。</p><h2>02 核心价值：为什么“可视化看板+多维表格”是效能倍增器</h2><p>这种融合模式并非简单叠加，而是产生了“1+1&gt;2”的协同效应：</p><ul><li><strong>信息高度集中，减少切换成本</strong>：无需在多个应用间跳转，所有任务背景、实时数据和协作讨论都集中在看板卡片内，确保信息一致性。</li><li><strong>数据驱动决策，提升透明度</strong>：卡片内的表格数据可进行实时计算、统计和可视化（如生成进度条、图表），让项目健康状况一目了然，助力精准决策。</li><li><strong>灵活自定义，适应多样流程</strong>：无论是营销活动策划、产品研发路线图，还是客户关系管理，团队都能自由定义卡片内的数据字段和视图，构建最适合自身业务流程的“活”系统。</li></ul><h2>03 工具实战：主流可插入多维表格的看板平台解析</h2><p>下面我们分析几款在市场上将看板与多维表格能力结合得较为出色的工具，了解它们如何具体实现这一理念。</p><p><strong>Notion</strong><br/>虽然常被归类为一体化工作空间，但其 <strong>“数据库”功能本质上是强大的多维表格</strong>。任何数据库都可以用看板视图来展示。其核心优势在于极致的灵活性：每个看板卡片点开就是一个完整的页面，你可以在页面内嵌入子数据库、文本、媒体等任何内容，构建复杂的项目文档。它适合追求高度定制化、希望将项目规划、知识库和任务追踪深度整合的团队。</p><p><strong>Airtable</strong><br/>常被誉为“表格界的乐高”。它以智能表格为基石，为表格数据提供了看板、日历、甘特图等多种视图。它的看板视图功能强大，且卡片内容与表格行数据完全同步。其突出优势在于强大的数据处理能力（如关联、自动化、丰富字段类型）和扩展性，适合需要处理大量复杂数据、并希望通过自动化提升效率的团队。</p><p><strong>板栗看板</strong><br/>作为一款聚焦于项目协作与可视化的工具，<strong>板栗看板</strong>在其看板任务卡片中巧妙地整合了自定义字段和表格视图的能力。团队成员可以在卡片内以结构化的方式管理清单、链接、数字和日期等信息，这些信息聚合起来即构成了项目数据的多维视图。其界面设计直观友好，更符合国内团队的使用习惯，能有效降低团队的上手门槛，实现轻量级但足够高效的“看板+数据”协同。</p><p><strong>ClickUp</strong><br/>一个功能聚合型的生产力平台，其任务管理模块天然支持看板视图。它的特色在于，任务属性（对应表格的字段）可以非常丰富和自定义，并能通过不同视图（列表、看板、甘特图）灵活呈现。ClickUp旨在用一个平台满足团队所有需求，因此除了看板与表格，还内置了文档、目标、工时追踪等多种功能，适合不希望使用过多分散工具的中大型团队。</p><h2>04 未来趋势：AI与自动化如何重塑智能看板</h2><p>可插入多维表格的看板本身已是高效工具，而人工智能（AI）与自动化技术的融入，正在将其推向新的智能阶段：</p><ul><li><strong>AI辅助数据填充与摘要</strong>：未来，工具或能自动分析任务描述，在卡片内的表格中预填关键信息（如预估耗时、关联人员），或自动生成任务摘要，减少手动输入。</li><li><strong>预测性与建议性洞察</strong>：系统通过分析历史项目数据，在看板视图上直观预警潜在风险（如某列任务堆积），并自动在卡片表格中建议最优的责任人或解决方案。</li><li><strong>跨平台数据自动同步</strong>：自动化工作流将更加强大，可以设定规则，让卡片内的表格数据与外部系统（如CRM、财务软件）保持实时同步，彻底消除手动更新。</li></ul><h2>05 代码示例：构建一个简化的看板卡片数据模型</h2><p>理解其数据底层逻辑，能帮助我们更好地运用这类工具。以下是一个高度简化的概念性代码示例，展示了一个看板卡片及其内嵌表格数据的可能结构：</p><pre><code class="python">class KanbanCard:
    """看板卡片类，包含基本属性和一个内嵌的数据表"""
    def __init__(self, title, status, assignee):
        self.title = title  # 卡片标题
        self.status = status  # 所处列（如：待处理、进行中、已完成）
        self.assignee = assignee  # 负责人
        self.embedded_table = EmbeddedTable()  # 卡片内嵌的多维数据表

class EmbeddedTable:
    """内嵌数据表，包含多行多列的结构化数据"""
    def __init__(self):
        self.columns = ["指标", "计划值", "实际值", "完成率"]  # 定义表格字段
        self.rows = []  # 表格数据行

    def add_row(self, metric, planned, actual):
        """向表格中添加一行数据"""
        completion_rate = (actual / planned) * 100 if planned else 0
        self.rows.append({
            "指标": metric,
            "计划值": planned,
            "实际值": actual,
            "完成率": f"{completion_rate:.1f}%"
        })

    def get_table_view(self):
        """获取表格的格式化视图"""
        return self.rows

# 使用示例：创建一个营销活动卡片
campaign_card = KanbanCard("Q1产品发布推广", "进行中", "张三")
# 在卡片内嵌表格中添加关键数据
campaign_card.embedded_table.add_row("文章发布量", 10, 8)
campaign_card.embedded_table.add_row("线索收集数", 200, 150)

print(f"看板卡片：{campaign_card.title}")
print(f"进度状态：{campaign_card.status}")
print("内嵌数据表概览：", campaign_card.embedded_table.get_table_view())</code></pre><p>这个模型直观地展示了看板卡片如何作为容器，承载并关联更丰富的结构化任务数据。</p><p>选择哪款工具，取决于你的团队规模、对数据复杂度的要求以及与其他工具的集成需求。但毋庸置疑，<strong>采用可插入多维表格的看板这一模式，是团队迈向更数据化、透明化和自动化协作的关键一步</strong>。从今天开始，尝试用这种融合的视角去规划你的下一个项目，或许就能解锁前所未有的流畅协作体验。</p>]]></description></item><item>    <title><![CDATA[智慧文旅：OTA分销管理系统 智定义科技 ]]></title>    <link>https://segmentfault.com/a/1190000047555756</link>    <guid>https://segmentfault.com/a/1190000047555756</guid>    <pubDate>2026-01-21 16:09:43</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555764" alt="图片" title="图片"/></p><p>一、方案概述</p><p>    #智慧景区#OTA分销系统对美团、抖音、携程等多个#OTA平台渠道进行整合统一管理，票务自动分发，实现#景区门票、酒店客房、文创商品等旅游产品的统一管理与#分销，帮助景区扩大销售渠道，提高销售额和市场份额，提升整体运营效率。是智慧文旅，智慧景区重要的其中一环。</p><p>二、方案功能介绍</p><p>1、门票管理</p><p>（1）门票类型管理</p><p>    #智慧景区#OTA分销系统可灵活配置各OTA平台（如抖音、携程、美团）的门票名称、类型（成人/儿童/老人票）、票面价、挂牌价及最终展示价，满足不同平台的营销策略需求。</p><p>（2）有效期与预定规则设置</p><p>    #智慧景区#OTA分销系统可针对每个渠道的用户预订习惯，自定义预订时间范围、提前预订时限、最晚预订时间、 门票有效期（指定日/多日有效）及是否支持“即买即用”，规则清晰，杜绝纠纷。</p><p>（3）库存管理</p><p>    #智慧景区#OTA分销系统可与OTA平台API无缝对接，实现库存实时同步。可根据淡旺季、不同票种科学分配库存，并设置库存预警阈值，避免超卖或错失销售良机。</p><p>（4）门票套票管理</p><p>    #智慧景区#OTA分销系统紧跟平台趋势，可快速创建极具吸引力的爆款套餐。例如，为抖音定制“门票+非遗体验”、“门票+达人导览”套餐；为携程设计“门票+酒店住宿”、“门票+周边景点联票”等，最大化提升客单价与吸力。</p><p>2、订单管理</p><p>（1）订单接收与显示</p><p>    #智慧景区#OTA分销系统可智能识别各平台订单特性，呈现其关注的核心信息。如美团订单侧重显示餐饮偏好，抖音订单突出视频凭证，携程订单强调酒店关联信息，让管理更具针对性。</p><p>（2）订单状态跟踪与更新</p><p>    #智慧景区#OTA分销系统可全程监控订单从“待支付”、“已支付”、“出票中”到“已核销”、“退款中”、“已退款”等全生命周期状态，并在景区与OTA平台间双向实时更新，信息透明，管理无忧。</p><p>（3）订单查询与筛选</p><p>    #智慧景区#OTA分销系统可支持通过订单编号、游客姓名、联系方式、下单时间、订单金额、订单状态、预订房型等多种条件组合，对各OTA平台订单进行精准查询与筛选，方便快速定位所需订单，极大的提升后台操作率。</p><p>（4）订单异常处理</p><p>    #智慧景区#OTA分销系统内置专业的订单异常处理流程（如支付失败、库存冲突、重复下单、信息错误等异常事件），提供清晰的操作界面与沟通指引，助力工作人员快速响应、妥善解决，保障游客满意度。</p><p>3、核销管理</p><p>（1）多中核销方式支持</p><p>    #智慧景区#OTA分销系统全面支持二维码、身份证读取、人脸识别等多种核销方式，自动与OTA订单信息匹配，秒级完成验票，保障游客快速入园，尤其在高峰期大幅减少拥堵。</p><p>（2）多人同时核销</p><p>    #智慧景区#OTA分销系统可针对团队订单、家庭套票等多人场景，提供按团队编号或订单批次的批量核销功能，一键完成整组核销，操作简便，效率倍增。</p><p>（3）核销记录管理</p><p>    #智慧景区#OTA分销系统可详细记录每一笔核销的订单来源、时间、地点、操作员及设备信息，形成完整的审计日志，方便财务对账、数据统计与问题追溯。</p><p>4、统计分析</p><p>（1）销售数据统计分析</p><p>    #智慧景区#OTA分销系统可自动统计各渠道的销售量、销售额、订单数、客单价、渠道占比等核心指标，并支持按日、周、月、年等周期生成可视化报表，助您精准掌握经营状况。</p><p>（2）平台对比分析</p><p>    #智慧景区#OTA分销系统可横向对比各OTA平台及自有渠道的销售数据、流量转化率、营销活动ROI（投资回报率），科学评估各渠道贡献值与营销效果，为未来预算分配与策略调整提供坚实的数据决策支持。</p><p>三、方案亮点</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555766" alt="图片" title="图片" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555767" alt="图片" title="图片" loading="lazy"/></p><p>四、更多内容</p><p>    <a href="https://segmentfault.com/a/1190000047392511" target="_blank">智慧文旅整体解决方案：赋能景区智能升级，激活全域营销势能</a></p><p>    <a href="https://segmentfault.com/a/1190000047395646" target="_blank">#数字人不止于“对话”，更在赋能千行百业</a></p><p>    <a href="https://segmentfault.com/a/1190000047414536" target="_blank">智慧文旅景区数字化中枢—“旅商通”，整合票务、二销与客流</a></p><p>    <a href="https://segmentfault.com/a/1190000047429281" target="_blank">#智慧文旅：旅政通，打通文旅数据壁垒，构建一体化运营平台</a></p><p>    <a href="https://segmentfault.com/a/1190000047448587" target="_blank">新事心办 - AI 智能大模型填报预审系统</a></p><p>    <a href="https://segmentfault.com/a/1190000047446229" target="_blank">#智慧文旅：智能体系介绍—多场景管理</a></p><p>五、下篇预告：#智慧景区#剧场演绎管理系统：让排期、票务、财务数据一键打通</p><p>    满足剧场、剧院票务管理业务需求，集成场地管理、剧目管理、在线售票、数据分析等多项功能，优化票务管理流程，提升观众购票体验，帮助剧场、剧院管理人员高效处理从演出安排到财务结算的各个环节，从而提高运营效率和服务质量。</p><p>六、软件结构</p><p>    本软件采用的是uniapp+JAVA语言开发，编码规范完全按照阿里巴巴编码规范<br/>    移动端：采用 uni-app 方案，一份代码多终端适配，同时支持 APP、小程序、H5；<br/>    前端采用Vue、Element UI。<br/>    后端采用Spring Boot多模块架构、Spring Security、Redis &amp; Jwt。<br/>    权限认证使用Jwt，支持多终端认证系统。<br/> </p>]]></description></item><item>    <title><![CDATA[Dynamic‑SQL2 查询篇：MyBatis 增强利器，让 SQL 像写 Java 一样丝滑 月]]></title>    <link>https://segmentfault.com/a/1190000047555776</link>    <guid>https://segmentfault.com/a/1190000047555776</guid>    <pubDate>2026-01-21 16:09:08</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>Dynamic‑SQL2 查询篇：MyBatis 增强利器，让 SQL 像写 Java 一样丝滑</h2><blockquote><strong>dynamic‑sql2 的查询能力设计目标：</strong>   写 SQL 要像写 Java 一样自然；复杂查询要像搭积木一样组合；结果映射要像操作集合一样顺滑。</blockquote><p>本篇简述了：</p><ul><li>基础查询</li><li>结果映射</li><li>分组 / Map / 分页</li><li>Join / 子查询 / JSON 表</li><li>动态列引用</li><li>排序与 SQL 注入防御</li><li>忽略列</li><li>函数查询</li><li>正则匹配条件</li><li><strong>动态库表名称（schema/table）机制</strong></li><li><strong>分页体系（dynamic‑sql2 / MyBatis / 逻辑分页）</strong></li></ul><h2>引入依赖</h2><blockquote>截止至<code>2026-01-21</code>，最新版是<code>0.1.8</code>，项目地址：<a href="https://link.segmentfault.com/?enc=KIlyDtGubk3NdJYWitS3mw%3D%3D.yh5cKZUIauBBCy9ohC%2Bq%2BxK5IUHtd6OCjcZwYrOcJPFnJV0I3W0BNwd8khObIxRs" rel="nofollow" target="_blank">https://github.com/pengweizhong/dynamic-sql2</a></blockquote><pre><code class="xml">        &lt;!-- Spring2.x --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.dynamic-sql&lt;/groupId&gt;
            &lt;artifactId&gt;dynamic-sql2-spring-boot-starter&lt;/artifactId&gt;
            &lt;version&gt;0.1.8&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;!-- Spring3.x --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.dynamic-sql&lt;/groupId&gt;
            &lt;artifactId&gt;dynamic-sql2-spring-boot3-starter&lt;/artifactId&gt;
            &lt;version&gt;0.1.8&lt;/version&gt;
        &lt;/dependency&gt;</code></pre><p>在<code>repository</code>层注入<code>SqlContext</code>  增删改查都和此对象交互：</p><pre><code class="java">    @Resource
    private SqlContext sqlContext;</code></pre><h2>1. 基础查询与结果映射</h2><h3>1.1 查询列表</h3><pre><code class="java">List&lt;Product&gt; list = sqlContext.select()
        .allColumn()
        .from(Product.class)
        .fetch()
        .toList();</code></pre><h3>1.2 查询单列（标量）</h3><pre><code class="java">LocalDate one = sqlContext.select()
        .column(Product::getCreatedAt)
        .from(Product.class)
        .limit(1)
        .fetch(LocalDate.class)
        .toOne();</code></pre><h3>1.3 查询单条记录</h3><pre><code class="java">Product product = sqlContext.select()
        .allColumn()
        .from(Product.class)
        .where(c -&gt; c.andEqualTo(Product::getProductId, 7))
        .fetch()
        .toOne();</code></pre><p>或使用主键快捷方式：</p><pre><code class="java">Product product2 = sqlContext.selectByPrimaryKey(Product.class, 7);</code></pre><h2>2. toList / toOne / toMap / toGroupingBy</h2><h3>2.1 分组 toGroupingBy</h3><pre><code class="java">Map&lt;Integer, HashSet&lt;String&gt;&gt; groupingBy = sqlContext.select()
        .distinct()
        .allColumn()
        .from(User.class)
        .fetch()
        .toGroupingBy(
                User::getUserId,
                user -&gt; user.getName() + "_hello",
                HashSet::new,
                ConcurrentHashMap::new
        );</code></pre><h3>2.2 分组（带 DTO）</h3><pre><code class="java">LinkedHashMap&lt;String, HashSet&lt;Integer&gt;&gt; groupingBy = sqlContext.select()
        .allColumn()
        .from(User.class)
        .limit(10)
        .fetch(User.class)
        .toGroupingBy(
                User::getName,
                User::getUserId,
                HashSet::new,
                LinkedHashMap::new
        );</code></pre><h3>2.3 toMap（含重复 key 处理）</h3><pre><code class="java">Map&lt;Integer, String&gt; map = sqlContext.select()
        .distinct()
        .allColumn()
        .from(User.class)
        .fetch()
        .toMap(
                user -&gt; 123,
                user -&gt; user.getName() + "_hello"
        );</code></pre><p>重复 key 会抛异常，可自定义合并策略：</p><pre><code class="java">.toMap(
    ProductView::getProductName,
    v -&gt; v,
    (v1, v2) -&gt; v1
);</code></pre><h2>3. Join / 子查询 / JSON 表</h2><h3>3.1 多级 join + 别名 （自关联）</h3><pre><code class="java">List&lt;Map&lt;String, Object&gt;&gt; list = sqlContext.select()
        .column("d1", DepartmentEntity::getId, "l5Id")
        .column("d2", DepartmentEntity::getId, "l4Id")
        .column("d3", DepartmentEntity::getId, "l3Id")
        .column("d4", DepartmentEntity::getId, "l2Id")
        .column("d5", DepartmentEntity::getId, "l1Id")
        .from(DepartmentEntity.class, "d1")
        .leftJoin(DepartmentEntity.class, "d2", c -&gt; c.andEqualTo(new Column("d1","id"), new Column("d2","parent_id")))
        .leftJoin(DepartmentEntity.class, "d3", c -&gt; c.andEqualTo(new Column("d2","id"), new Column("d3","parent_id")))
        .leftJoin(DepartmentEntity.class, "d4", c -&gt; c.andEqualTo(new Column("d3","id"), new Column("d4","parent_id")))
        .leftJoin(DepartmentEntity.class, "d5", c -&gt; c.andEqualTo(new Column("d4","id"), new Column("d5","parent_id")))
        .where(c -&gt; c.andIn(DepartmentEntity::getId, Arrays.asList(1,2,3)))
        .fetchOriginalMap()
        .toList();</code></pre><h3>3.2 子查询 join</h3><pre><code class="java">List&lt;Map&lt;String, Object&gt;&gt; list = sqlContext.select()
        .allColumn(Product.class)
        .from(Product.class)
        .innerJoin(
                select -&gt; select.allColumn(Product.class)
                        .from(Category.class)
                        .join(Product.class, on -&gt; on.andEqualTo(Category::getCategoryId, Product::getCategoryId))
                        .where(c -&gt; c.andLessThanOrEqualTo(Category::getCategoryId, 10)),
                "t",
                on -&gt; on.andEqualTo(Product::getProductId, bindAlias("t", Product::getProductId))
        )
        .fetchOriginalMap()
        .toList();</code></pre><h3>3.3 JSON 表展开（JsonTable）</h3><pre><code class="java">List&lt;Object&gt; list = sqlContext.select()
        .column("o", Order::getOrderId)
        .column("jt", Product::getProductName)
        .from(Order.class, "o")
        .join(() -&gt; new JsonTable(
                        "o",
                        Order::getOrderDetails,
                        "$.items[*]",
                        JsonColumn.builder()
                                .column("product_name")
                                .dataType("VARCHAR(150)")
                                .jsonPath("$.product")
                                .build()
                ),
                "jt",
                null
        )
        .fetch()
        .toList();</code></pre><h2>4. 动态列引用 ColumnReference</h2><pre><code class="java">List&lt;Product&gt; list = sqlContext.select()
        .column(Product::getProductId)
        .columnReference(columnReference())
        .from(Product.class)
        .fetch()
        .toList();</code></pre><pre><code class="java">AbstractColumnReference columnReference() {
    return ColumnReference.withColumns()
            .column(Product::getProductId)
            .columnReference(columnReference2())
            .column(Product::getProductName);
}</code></pre><h2>5. 排序与 SQL 注入防御</h2><h3>5.1 链式排序</h3><pre><code class="java">List&lt;User&gt; list = sqlContext.select()
        .allColumn()
        .from(User.class, "u")
        .orderBy(true, sortField, SortOrder.DESC)
        .thenOrderBy(false, User::getUserId)
        .thenOrderBy(true, User::getName)
        .fetch()
        .toList();</code></pre><h3>5.2 ORDER BY 注入测试</h3><pre><code class="java">sqlContext.select()
        .allColumn()
        .from(User.class)
        .orderBy("user_id; drop table users; --", SortOrder.DESC)
        .fetch()
        .toList();</code></pre><p>框架会拒绝非法字段名，抛出异常，避免注入。</p><h2>6. 忽略列 ignoreColumn</h2><pre><code class="java">List&lt;?&gt; list = sqlContext.select()
        .allColumn()
        .ignoreColumn(TempUserEntity::getName)
        .ignoreColumn(TempDeptEntity::getName)
        .from(TempUserEntity.class)
        .join(TempDeptEntity.class, on -&gt; on.andEqualTo(TempUserEntity::getId, TempDeptEntity::getId))
        .fetch()
        .toList();</code></pre><h2>7. 日期函数 DateFormat / Now</h2><pre><code class="java">YearMonth yearMonth = sqlContext.select()
        .column(new DateFormat(new Now(), "%Y-%m"))
        .from(Dual.class)
        .fetch(YearMonth.class)
        .toOne();</code></pre><h2>8. 正则匹配 andMatches（扩展点）</h2><pre><code class="java">List&lt;User&gt; list = sqlContext.select()
        .allColumn()
        .from(User.class)
        .where(c -&gt; c.andMatches(User::getEmail, ".*@gmail\\.com"))
        .fetch()
        .toList();</code></pre><h2>9. 动态库表名称（schema/table）</h2><p><code>dynamic‑sql2</code> 的 <code>@Table</code> 支持占位符解析，可动态：</p><ul><li>schema</li><li>table</li><li>alias</li><li>dataSourceName</li></ul><h3>9.1 动态 schema</h3><p>从0.1.8起，自定义值库表解析器，这在同一实例相似业务下跨库时不同的命令库表命名规则时非常有用，不会影响查询速度。</p><pre><code class="java">@Table(schema = "${tenant.schema:user_center}", name = "t_user")</code></pre><p>配置：</p><pre><code class="properties">tenant.schema = tenant_001</code></pre><p>SQL效果片段：</p><pre><code class="sql">FROM tenant_001.t_user</code></pre><h3>9.2 动态表名（含默认值）</h3><pre><code class="java">@Table(name = "${tenant.table.user:t_user}")</code></pre><h3>9.3 动态数据源（最高优先级）</h3><pre><code class="java">@Table(dataSourceName = "ds_user")</code></pre><h3>9.4 全局alias</h3><pre><code class="java">@Table(name = "t_user", alias = "u")</code></pre><h2>10. 分页体系（PageHelper）</h2><p><code>dynamic-sql2</code>内置了分页支持的查询</p><h3>10.1 dynamic‑sql2 分页</h3><pre><code class="java">PageInfo&lt;List&lt;User&gt;&gt; pageInfo = PageHelper.of(1, 10)
        .selectPage(() -&gt; sqlContext.select()
                .allColumn()
                .from(User.class)
                .fetch()
                .toList());</code></pre><h3>10.2 MyBatis 分页</h3><pre><code class="java">PageInfo&lt;List&lt;User&gt;&gt; pageInfo = PageHelper.ofMybatis(1, 10)
        .selectPage(() -&gt; sqlContext.select()
                .allColumn()
                .from(User.class)
                .fetch()
                .toList());</code></pre><p>Dynamic-SQL2支持mybatis的分页，但是需要引入拓展包：</p><pre><code class="xml">&lt;!-- Source: https://mvnrepository.com/artifact/com.dynamic-sql/dynamic-sql2-extension --&gt;
&lt;dependency&gt;
    &lt;groupId&gt;com.dynamic-sql&lt;/groupId&gt;
    &lt;artifactId&gt;dynamic-sql2-extension&lt;/artifactId&gt;
    &lt;version&gt;0.1.6&lt;/version&gt;
    &lt;scope&gt;compile&lt;/scope&gt;
&lt;/dependency&gt;</code></pre><p>该拓展包除了支持Mybatis分页外，和其映射规则也是完全兼容。</p><h3>10.3 applyWhere（实验性）</h3><p>该场景有时会遇到类似情况：有的依赖jar有自己独立的逻辑体系，但是又想修改其内部SQL，在不改变内部逻辑的情况下，在外部尝试修改SQL语句。目前只是实验阶段，有足够的场景场景支撑和更多的测试后，才会Release该特性。</p><pre><code class="java">PageInfo&lt;List&lt;User&gt;&gt; pageInfo = PageHelper.of(1, 3)
        .applyWhere(c -&gt; c.andGreaterThanOrEqualTo(User::getAge, 18))
        .selectPage(
                //假设这是无法修改/不允许更改的内部SQL，通常是jar的形式提供
                () -&gt; sqlContext.select()
                .allColumn()
                .from(User.class)
                .fetch()
                .toList());</code></pre><h3>10.4 逻辑分页（集合内存分页）</h3><pre><code class="java">PageInfo&lt;List&lt;Integer&gt;&gt; pageInfo = PageHelper.ofLogic(2, 3)
        .selectPage(Arrays.asList(1,2,3,4,5,6,7));</code></pre><h2>11. 分页 + 动态库表名称示例</h2><pre><code class="java">@Table(
    schema = "${tenant.schema:user_center}",
    name = "${tenant.table.user:t_user}",
    alias = "u"
)
public class User {}</code></pre><p>分页查询：</p><pre><code class="java">PageInfo&lt;List&lt;User&gt;&gt; pageInfo = PageHelper.of(1, 10)
        .selectPage(() -&gt; sqlContext.select()
                .allColumn()
                .from(User.class)
                .fetch()
                .toList());</code></pre><p>最终 SQL：</p><pre><code class="java">SELECT u.* 
FROM tenant_001.user_2025 u 
LIMIT 10 OFFSET 0</code></pre><h2>拓展</h2><h3>自定义函数</h3><p>对于<code>Dynamic-SQL2</code>没有提供的函数，如何自定义呢？非常简单，继承<code>ColumnFunctionDecorator</code>抽象类重写<code>getFunctionToString</code>方法即可，然后代码中就可以引用了。</p><p>比如已存在的<code>max</code>函数为例：</p><pre><code class="java">/*
 * Copyright (c) 2024 PengWeizhong. All Rights Reserved.
 *
 * This source code is licensed under the MIT License.
 * You may obtain a copy of the License at:
 * https://opensource.org/licenses/MIT
 *
 * See the LICENSE file in the project root for more information.
 */
package com.dynamic.sql.core.column.function.windows.aggregate;


import com.dynamic.sql.core.FieldFn;
import com.dynamic.sql.core.Version;
import com.dynamic.sql.core.column.function.AbstractColumFunction;
import com.dynamic.sql.core.column.function.ColumnFunctionDecorator;
import com.dynamic.sql.core.column.function.windows.WindowsFunction;
import com.dynamic.sql.enums.SqlDialect;
import com.dynamic.sql.utils.ExceptionUtils;
import com.dynamic.sql.model.TableAliasMapping;

import java.util.Map;


public class Max extends ColumnFunctionDecorator implements AggregateFunction, WindowsFunction {

    public Max(AbstractColumFunction delegateFunction) {
        super(delegateFunction);
    }

    public &lt;T, F&gt; Max(FieldFn&lt;T, F&gt; fn) {
        super(fn);
    }

    public &lt;T, F&gt; Max(String tableAlias, FieldFn&lt;T, F&gt; fn) {
        super(tableAlias, fn);
    }

    @Override
    public String getFunctionToString(SqlDialect sqlDialect, Version version, Map&lt;String, TableAliasMapping&gt; aliasTableMap) throws UnsupportedOperationException {
        if (sqlDialect == SqlDialect.ORACLE) {
            return "MAX(" + delegateFunction.getFunctionToString(sqlDialect, version, aliasTableMap) + ")".concat(appendArithmeticSql(sqlDialect, version));
        }
        if (sqlDialect == SqlDialect.MYSQL) {
            return "max(" + delegateFunction.getFunctionToString(sqlDialect, version, aliasTableMap) + ")".concat(appendArithmeticSql(sqlDialect, version));
        }
        throw ExceptionUtils.unsupportedFunctionException("max", sqlDialect);
    }
}
</code></pre><p>之后在代码中直接引用该类：</p><pre><code class="java">    @Test
    void testMax() {
        Integer max = sqlContext.select()
                .column(new Max(Product::getProductId))
                .from(Product.class)
                .fetch(Integer.class)
                .toOne();
        System.out.println(max);
    }</code></pre><p>打印的SQL</p><pre><code class="log">2026-01-21 13:27:03 [main] DEBUG com.dynamic.sql.core.database.SqlDebugger - dataSource --&gt;     Preparing: select max(`p`.`product_id`) as productId from `dynamic_sql2`.`products` as `p`
2026-01-21 13:27:03 [main] DEBUG com.dynamic.sql.core.database.SqlDebugger - dataSource --&gt;    Parameters: 
2026-01-21 13:27:03 [main] DEBUG com.dynamic.sql.core.database.SqlDebugger - dataSource &lt;--         Total: 1</code></pre><p><code>AggregateFunction</code>和<code>WindowsFunction</code>标识函数的分类，因为有些场景下函数嵌套使用时，会要求是窗口函数或必须是字符串函数，因此声明类型更加符合开发规范，如果自定义的话，可以不用关心具体的函数分类，直接继承<code>ColumnFunctionDecorator</code>即可。</p><p>目前定义的函数分类接口：</p><ul><li>AggregateFunction ： 聚合函数</li><li>ScalarFunction ： 标量函数</li></ul><p><code>Max</code>函数依赖的全部体系如图所示：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555779" alt="image-20260121140818596" title="image-20260121140818596"/></p><h3>国产数据库</h3><p>对于国产数据库，通常都会支持和兼容mysql语法，因此通常不用太担心不兼容的问题。但是<code>dynamic-sql2</code>启动时会检测受支持的数据库，对于不支持的数据库会支持报错，只要你确认当前所使用的数据库提供商兼容<code>Mysql</code>，那么就可以完全使用<code>dynamic-sql2</code>！</p><h3>推荐一款好用的 IDEA Mybatis 插件</h3><p>最喜欢的特性之一是在控制台可以将打印的SQL直接合并为可执行的SQL语句，在开发环境中特别有用！</p><p>插件主页：<a href="https://link.segmentfault.com/?enc=Zc7rXB9hmgVKjAll5v3twg%3D%3D.JYUsyw8IDg6yn4xSE99%2Fr5GsCQj0enR6%2BUPNRUWaXYU59pBzOVyXgRtN%2F07JCx1xCclafLd%2BWVtTvag%2BTPzd1A%3D%3D" rel="nofollow" target="_blank">https://plugins.jetbrains.com/plugin/9837-mybatiscodehelperpro</a></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555780" alt="image-20260121141250521" title="image-20260121141250521" loading="lazy"/></p><h2>🎉 完结撒花，欢迎吐槽🎉</h2>]]></description></item><item>    <title><![CDATA[AAAI 2026｜快手LGSID助力业务GMV实现两位数增长：从地理可达，到兴趣匹配 快手技术 ]]></title>    <link>https://segmentfault.com/a/1190000047555821</link>    <guid>https://segmentfault.com/a/1190000047555821</guid>    <pubDate>2026-01-21 16:08:20</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>你是否有过这样的经历：刷到一家价格合适、评价不错的餐厅，却发现门店远在城市另一端，交通成本过高，只能无奈划走。对于生活服务类内容来说，“感兴趣”只是开始，“方便到达”才是决定下单的关键。正因如此，生活服务推荐与传统内容推荐存在本质差异——用户的消费决策天然受到地理位置的强约束。只有同时满足“离得近”和“感兴趣”，推荐结果才有可能转化为线下到店与交易。</p><p>然而，这一看似简单的需求却对推荐系统提出了极高挑战：系统不仅需要理解用户兴趣偏好，还要精准感知用户所处位置，并感知用户与内容的空间关系。为应对生活服务推荐模型在空间感知方面的挑战，快手生活服务算法团队引入大语言模型对Item进行高质量的文本语义与地理语义联合偏好建模，并通过基于强化学习的后训练范式，缓解预训练 LLM 中普遍存在的“重语义、轻地理”先天偏置，从而使内容表征更加充分地适配生活服务推荐场景。基于上述思路，快手生活服务团队提出了业界首个面向近场分发场景的地理模态表征建模解决方案——LGSID。</p><p>本研究相关成果《LLM-Aligned Geographic Item Tokenization for Local-Life Recommendation》已被人工智能顶级会议AAAI 2026接收，同时LGSID已在快手生活服务场景全量上线，助力业务累计实现GMV和订单10%以上的增长。<br/>[🔮 论文标题]：LLM-Aligned Geographic Item Tokenization for Local-Life Recommendation<br/>[📖 论文链接]：<a href="https://link.segmentfault.com/?enc=PI94C2rG%2BneFrTFoEMWuLQ%3D%3D.KW%2FV2YAyfMSRBtvLlZsgMtaZzZ3NPcnTkDHmci467ekKEQyyZNiJreYFxFavY4i9" rel="nofollow" target="_blank">https://arxiv.org/abs/2511.14221</a><br/>[📝 论文代码]：<a href="https://link.segmentfault.com/?enc=GSh%2FxIoD%2BjXtNiKjgSOZ8g%3D%3D.wzFDSiIHkgXCQIbX5PeSghXuuJYQw9I1l33VLvNTygbn1voE3tk2z%2BytHIUg6Dbu" rel="nofollow" target="_blank">https://github.com/JiangHaoPG11/LGSID</a><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555823" alt="图片" title="图片"/><br/>图1 LGSID模型示意图</p><p>核心亮点：在LLM兴起前，传统方法通过离散化的空间特征和特定空间下的用户兴趣建模为模型引入空间感知能力。然而，此类方法强依赖人工特征设计，离散化的空间特征难以有效刻画空间位置的相对关系，空间感知能力有限。因此，我们尝试借助LLM对Item的地理位置模态建模，利用自然语言表征与大模型世界知识，从高维语义理解层面刻画空间位置与相对关系，以增强Item自身的空间表达能力。</p><ul><li>【教会LLM如何学习地理位置信息】针对预训练LLM地理感知能力弱的问题，本文创新性地提出G-DPO算法，通过LLM Post-Training过程，将Item在真实世界中的相对空间关系显式注入LLM底层，从而引导模型更有效地学习地理位置信息，并平衡好内容语义与地理语义。</li><li>【帮助推荐模型更好适配近场分发】针对现有单一表征量化无法层次化建模的问题，本文创新性地提出了地理感知层次化量化的方案—HGIT。量化ID的首层通过“硬”的离散化地理位置（GeoHash，经纬度）生成初始化聚类，其余层则使用具有地理位置感知能力的内容表征逐层残差量化。</li></ul><h2>一、背景</h2><p>在生活服务内容推荐场景中，业务核心逻辑是用户线上下单、线下到店核销。由于核销成本高，且强依赖用户与 Item 之间的地理位置关系，空间距离在该场景中对用户转化具有显著影响。如下图数据表明，随着“人—货距离”的增加，用户转化效率明显下降。因此，近场分发体系需要同时兼顾兴趣匹配准确性与空间感知能力。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555824" alt="图片" title="图片" loading="lazy"/><br/>图2 “人-货距离”与转换效率趋势图</p><p>近年来，大语言模型（Large Language Models, LLMs）在语义理解与推理方面展现出强大能力。现有基于 LLM 的推荐方法通常通过精心设计的 Prompt 对候选 Item 的文本信息进行表征编码，并借助量化模型生成语义 ID 用于下游推荐任务。然而，由于缺乏对空间感知能力的有效建模，这类方法在近场分发场景中往往表现受限。尽管已有工作（如 GNPR-SID）尝试将地理位置信息注入 Prompt 以获取地理感知表征，但我们在理论分析和实验中发现，如果简单地将Item内容信息与地理位置信息同时拼接注入Prompt，难以有效刻画细粒度的空间位置关系。然而，这种将地理信息直接注入 Prompt 的方式为何难以生效，其内在原因仍有待进一步分析。</p><p>首先，通过地理感知Prompt生成的内容表征中，LLM会不可避免地呈现“重内容，轻地理”的现象。如图3所示，由于LLM主要依赖通用预训练语料进行训练，而内容信息在语料中占比通常高于地理位置信息，这导致模型更倾向于捕获内容特征，而对地理位置信息的表达能力不足。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555825" alt="图片" title="图片" loading="lazy"/><br/>图3 LLM地理感知缺陷示意图</p><p>其次，现有 LLM 对细粒度地理位置的区分能力较弱，例如，在区分“北京西二旗上地十街”与“黑龙江大兴安岭地区加格达奇区”等具体位置时，模型在实际应用中往往仅利用“北京”“黑龙江”等粗粒度地理语义。如下图所示，街道级别等细粒度位置的召回表现较差，准确率仅为16%，无法做到充分的空间感知。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555826" alt="图片" title="图片" loading="lazy"/><br/>图4 原始表征（Origin）和本研究表征（G-DPO）在不同地理级别的召回准确率对比图</p><p>此外，在生活服务推荐场景中，用户受地理位置约束，其决策过程天然呈现出“先地理可达、后兴趣匹配”的层次化结构。然而，现有主流量化方法通常针对单一连续表征空间进行近似聚类建模，未能显式刻画地理约束与兴趣偏好之间的层级关系。如下图5所示，若Item表征及其对应的语义ID仅表达文本语义，当用户身处“北京”时，推荐系统可能仅基于用户兴趣将位于“上海”的某品牌门店进行推荐，导致最终难以促成有效交易，损害用户的消费体验与平台信任度。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555827" alt="图片" title="图片" loading="lazy"/><br/>图5 生活服务内容分发示意图</p><p>因此，如何准确激发大语言模型的空间理解能力，进而提升精排模型的空间感知能力，已成为近场分发体系中亟需解决的关键问题。</p><h2>二、技术方案</h2><h3>2.1 模块一：RL-based Geographic LLM Alignment</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555828" alt="图片" title="图片" loading="lazy"/><br/>图6 RL-based Geographic LLM Alignment模块示意图</p><h3>2.1.1 地理感知的奖励模型</h3><p>我们首先训练了一个能够判别内容与地理位置相关偏好的模型，用于衡量文本语义与地理位置之间的匹配程度。具体而言，我们提出了一种List-wise奖励模型，以刻画POI内容与其他候选POI位置之间的距离关系。为了增强模型对细粒度区域差异的感知能力，我们设计了一种地理密度感知困难负采样策略（Density-aware Hard Negative Sampling Strategy）。该策略通过计算目标POI与候选池中POI之间的Haversine距离，并按由近及远的顺序进行的排序采样。通过优先近距离采样，同时保留远距离区域采样的方法，针对性提升LLM的地理感知能力。</p><p>近一步，我们采用Prompt错配策略构建输入Prompt序列，即固定目标POI的文本内容，并分别与采样得到的负样本POI的地理位置信息进行匹配。在得到Prompt序列之后，我们将其输入至LLM中进行表征编码，通过NN网络进行打分以衡量文本与地理位置之间的匹配程度。</p><p>此外，为将相对距离信息注入LLM训练过程，我们基于固定内容–候选POI地理位置之间的相对空间距离，为每个错配Prompt设计连续的软标签（soft labels），从而对地理位置更为接近的Prompt赋予更高的标签权重。基于上述设计，我们采用Weighted Binary Cross-Entropy Loss进行奖励模型优化。</p><h4>2.1.2 G-DPO算法</h4><p>在训练得到奖励模型之后，我们进一步提出了G-DPO算法，用于将文本–地理相对位置偏好通过后训练的方式注入LLM。具体而言，基于对推荐任务及生活服务场景特性的理解，我们构建了一种Domain-mixed的混合偏好样本集，并利用奖励模型进行打分作为RL的偏好程度。具体来说，混合偏好样本主要包含两类数据：领域协同Item Pairs与地理约束Item Pairs。对于领域协同Item Pairs，在近场分发场景，用户发生共现交互的Item通常天然受到地理位置约束，往往分布在相对近距离的空间范围内。</p><p>因此，我们针对协同Item Pairs进行更细粒度的偏好建模，以捕获用户在局部区域内的兴趣感知能力，同时间接增强LLM对下游推荐任务的适配性。对于地理约束Item Pairs，我们从不同距离区间的POI候选集合中随机采样，以保证样本在空间距离覆盖上的多样性，从而提升模型对不同地理尺度偏好的整体建模能力。在得到样本数据后，我们对每个Item pair通过奖励模型打分，分别送入Policy Model和Reference Model中，构建类DPO的损失计算偏好优化目标。此外，为保证LLM的语义理解能力，我们引入了in-batch对比学习Loss作为相似度正则器，并整合两类Loss进行端到端的训练。</p><h3>2.2 模块二：Hierarchical Geographic Item Tokenization</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555829" alt="图片" title="图片" loading="lazy"/><br/>图7 Hierarchical Geographic Item Tokenization模块示意图</p><p>为适配近场分发体系中“先地理可达，再兴趣匹配”的分发逻辑，我们提出了层次化地理感知的量化方案—HGIT。对于首层，我们利用多种Item离散化特征构建Geography-aware Token，包括Item的经纬度，省份ID，城市ID，区域ID和对应的内容粗粒度表示，以构建聚类特征向量。在获得对应的向量表示后，我们采用K-Means算法生成首层Token的聚类中心。</p><p>每个聚类的表示由归属于该中心的LLM表征取均值构建，并在后续层的训练过程中保持固定，以作为稳定的地理层级锚点表示。对于其余层，我们构建了基于欧式距离分类的可学习聚类中心，并优化重构损失。同时，为了更好地平衡各聚类中心的利用率并防止码本坍塌，我们引入了一种Entropy-based Regularization机制。</p><p>该机制旨在鼓励每一层中输入表征被分配到不同聚类中心的概率尽可能均衡。具体而言，在训练过程中，我们逐层统计输入表征归属于各个聚类中心的频率分布。随后，我们通过将该频率分布与均匀分布之间的KL散度作为正则项约束，并整合两类Loss作为最终的量化模型优化目标。</p><h2>三、效果性能</h2><h3>3.1 推荐总体性能</h3><p>我们将本文所产出的LGSID分别作用于判别式推荐模型和生成式推荐模型，相较于其他的量化方案，LGSID均取得突出性能。</p><h4>3.1.1 判别式推荐模型结果</h4><p>下表展示了LGSID作用于判别式推荐模型时的性能，覆盖了DIN、DIEN、SIM、TWIN以及 ETA等工业界主流判别式模型。实验结果表明，LGSID在所有模型上均取得了最大的性能提升。性能增益的关键原因在于：离散化ID难以刻画空间邻近关系，限制了地理位置在注意力计算的作用。LGSID利用G-DPO将对齐后的LLM空间知识，引导模型更关注真实空间上地理位置邻近的POI，以提升交互效果。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555830" alt="图片" title="图片" loading="lazy"/><br/>图8 判别式推荐模型实验结果对比图</p><h4>3.1.2 生成式推荐模型结果</h4><p>下表展示了在生成式推荐模型不同量化方法的性能对比结果，包含了两类主流模型TIGER与OneRec。实验结果表明，LGSID在两个模型上均取得了最大的性能提升。性能增益主要来源于基于强化学习的LLM对齐机制，使模型生成具备地理感知能力的语义表示，并通过分层量化模型将这些表示稳定地映射为层次化的语义ID，使得生成式推荐任务更符合业务分发逻辑，即“先地理可达，再兴趣匹配”，使得用户兴趣受到地理位置的约束和权衡，提升模型流量分发效率。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555831" alt="图片" title="图片" loading="lazy"/><br/>图9 生成式推荐模型实验结果对比图</p><h3>3.2 LLM对齐表征分析</h3><p>为验证G-DPO的有效性，我们在微调前后对LLM表征进行了系统评估，以证明模型表征在微调前后对于地理位置空间感知的变化。我们设计了两类评价指标评估其语义相似性和地理位置感知能力。<br/>【语义相似度】：为衡量向量检索结果在语义空间中的相似程度，我们将原始语义空间的表征作为Ground Truth，通过计算对齐后的LLM表征所召回Item在原始语义空间中的相似度，来刻画LLM语义理解能力的变化。<br/>【地理感知能力】：为衡量向量检索结果在地理位置上的准确性，我们首先用原Item的对齐后LLM表征进行Top-K召回，然后通过计算召回结果与原Item在省、市、区三级的覆盖率（P@K、C@K、T@K），来评估检索结果在不同地理层级上的一致性。具体结果如下表所示，省份覆盖率（P@5）由0.8716提升至0.9905，城市覆盖率（P@5）由0.7342提升至0.9548，街道覆盖率（T@5）由0.1601 显著提升至0.5584。</p><p>实验结果证明，传统方法仅依赖语义相似度，不足以建模地理感知能力，文本相似性无法反映真实空间距离关系。 其次，通过G-DPO算法地理相对距离得以有效压缩并迁移至LLM中，从而使相近距离的POI在表征层面上更相似。此外，融合密度感知的List-wise奖励模型建模进一步增强了近距离敏感性，提升了对细粒度距离的感知能力。最后，过度强调地理感知并不能保证下游推荐性能最优，因此，引入语义相似度正则项，在保持语义一致性的同时实现地理感知与语义表达的平衡，最终获得最优整体表现。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555832" alt="图片" title="图片" loading="lazy"/><br/>图10 不同地理级别的召回准确率对比图</p><h3>3.3 LLM对齐表征可视化</h3><p>左图的T-SNE可视化结果表明，我们对经G-DPO对齐后的LLM表征进行降维后，省份、城市与区县各层级的聚类中心在嵌入空间中呈现出收敛趋势。与此同时，NMI指标由0.0137–0.0845大幅提升至0.6430–0.8644，表明模型学习到的聚类结构与真实地理标签之间的一致性显著增强。右图展示了不同分位点下不同量化方法产出SID的码本覆盖能力。结果表明，在Level-1层级中，LGSID在对齐与未对齐两种设置下均呈现出高度一致的覆盖模式，在90%分位点仍可保持约11k的覆盖能力，而RQ-VAE在相同条件下已衰减至约8k。随着层级粒度进一步细化至Level-2与Level-3，LGSID的优势愈发明显，其在雷达图中的覆盖面积显著大于其他方法，表明其具备更强的表达容量以及更稳定的分布特性。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555833" alt="图片" title="图片" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555834" alt="图片" title="图片" loading="lazy"/><br/> 图11 LLM对齐后表征可视化示意图</p><h3>3.4 案例分析</h3><p>下图对比了在是否引入G-DPO对齐的条件下，LGSID分层量化模型所生成的SID分布。由于第一层基于预先计算的地理特征聚类，其在对齐与未对齐设置下的整体分布保持相对一致。然而，在引入G-DPO对齐后，如下图 (b) 所示，第一层 Token（[350, 93, *]）能够将BBQ &amp; Grilled品类完整地聚合至同一粗粒度标识之下；而在未对齐条件下，如图(e)所示，该品类则被分散映射到多个不同的SID根节点，导致类别一致性受损。上述现象表明，上游LLM表征的对齐质量直接影响分层量化结构的有效性，进一步突显了G-DPO在LGSID框架中的关键作用。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555835" alt="图片" title="图片" loading="lazy"/><br/>图12 语义ID分布示意图</p><h2>四、未来方向</h2><p>快手生活服务团队作为公司的核心算法研发力量，始终站在并引领下一代推荐系统的前沿探索。团队致力于打造行业领先的近场分发体系，通过持续的技术创新提升推荐效率与用户体验，为用户提供更加便捷、丰富、可信的生活服务。同时，团队以技术驱动业务增长，不断拓展生活服务场景与能力边界，助力业务GMV提升与商业化收入增长。未来，团队将继续深耕近场分发、多模态大模型内容理解与生成式推荐，探索 AI 赋能下一代推荐系统。重点围绕多模态理解、语义量化 ID 与推荐大模型开展创新研究，融合图像、音频、视频等异构数据，提升表征与量化 ID 可解释性，打造具备时空推理能力的大模型，为用户提供更优质的生活服务体验。</p>]]></description></item><item>    <title><![CDATA[筑业云资料 “部位建表” 功能：资料编制的便捷利器 聪明的拐杖 ]]></title>    <link>https://segmentfault.com/a/1190000047555848</link>    <guid>https://segmentfault.com/a/1190000047555848</guid>    <pubDate>2026-01-21 16:07:29</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在工程资料编制过程中，不少用户面临着一个棘手的问题：在同一施工部位下需创建多张表格，若一张一张单独建立，既繁琐又耗时，还容易出现遗漏。筑业云资料的 “部位建表” 功能，精准地解决了这一痛点，成为资料编制工作的得力助手。<br/>高效批量建表，避免遗漏<br/>“部位建表” 功能的核心优势在于，能够依据施工部位一次性创建所有相关联的表格。这一功能的实现，得益于首次设置时对部位划分和表格关联的精心规划。一旦完成初始设置，后续操作便极为简便高效。例如，在建筑项目的一层墙、柱 A - 4 ~ A - 1 轴线这一特定部位，通过该功能，可一次性生成此部位所需的全部表格，从混凝土浇筑记录到钢筋隐蔽工程验收表等，一应俱全，避免了重复操作和表格遗漏的风险，确保资料的完整性。<br/>清晰操作流程，易于上手<br/>使用 “部位建表” 功能，其操作流程十分清晰明了。首先，在软件工具栏上轻松找到并点击 “部位建表” 功能入口，这是开启高效建表的第一步。随后，选择对应的单位工程，这一步确保了建表工作在正确的项目框架内进行。接着，在指定位置详细输入具体的部位名称，如 “一层墙，柱 A - 4 ~ A - 1 轴线”，明确建表的具体范围。之后，从左侧表格模板库中挑选该部位下需要创建的表格。值得一提的是，软件模板库预设了规范的表格关联逻辑，用户只需按照提示操作，就能轻松避免遗漏重要表格。同时，若用户对所需表格有明确目标，还可通过查询窗口，快速定位并双击添加到该部位下。在仔细确认部位名称和需要添加的表格无误后，点击 “创建” 按钮，软件便会迅速且准确地一次性生成该部位下对应的所有表格，并在工程资料目录中以清晰有序的方式展示出来，方便用户后续查找和使用。<br/>提升资料编制效率与规范性<br/>掌握 “部位建表” 功能，对于工程资料编制工作意义重大。它将资料编制人员从繁琐的重复找表建表工作中彻底解放出来，实现了快速批量建表。这种高效的操作方式不仅节省了大量时间和精力，还通过规范的表格关联逻辑，确保了资料管理的规范性和准确性。在提高工作效率的同时，降低了因人为疏忽导致的错误风险，使整个资料编制工作更加顺畅、高效、无误，为工程项目的顺利推进提供了有力支持。<br/>筑业云资料的 “部位建表” 功能，以其高效便捷、易于操作和规范管理的特点，成为工程资料编制过程中不可或缺的实用工具，助力工程人员轻松应对复杂的资料编制任务。</p>]]></description></item><item>    <title><![CDATA[海外云 AWS、GCP、Azure 与 DigitalOcean 的核心区别有哪些？ Digital]]></title>    <link>https://segmentfault.com/a/1190000047555861</link>    <guid>https://segmentfault.com/a/1190000047555861</guid>    <pubDate>2026-01-21 16:06:52</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在当今的互联网出海与数字化转型浪潮中，选择合适的云服务商已成为企业技术选型中最重要的决策之一。面对亚马逊 AWS、微软 Azure、谷歌云 GCP 这样的传统三强，以及以“简单、高效、高性价比”著称的 DigitalOcean，技术负责人和工程师们往往会面临多重考量：是追求功能的极致全面，还是追求管理的极度简化？是为品牌溢价付费，还是寻找更务实的增长方案？</p><p>本文将深度拆解 AWS、GCP（谷歌云）、Azure 与 DigitalOcean 的核心区别，从定价逻辑、核心产品、网络优势、AI 能力及中国企业出海实践等维度，为你提供一份详尽的选型参考指南。</p><h2>AWS、Azure 与 GCP 的定位差异</h2><p>在云计算市场中，AWS、Azure 和 GCP（谷歌云） 占据了主导地位。它们凭借早期的先行者优势、庞大的资本投入和全球基础设施，构建了极高的行业门槛。</p><h3>1、AWS：功能最多的云平台</h3><p>作为云计算的开创者，AWS 是目前全球市场占有率最高的云平台之一。</p><ul><li>​<strong>核心优势</strong>​：服务种类最为繁多，涵盖计算、存储、数据库、物联网及 AI 等 200 多项功能。其 EC2 实例提供了超过 200 种类型，能够满足从高性能计算到存储密集型的任何极端需求。</li><li>​<strong>适用人群</strong>​：需要极其复杂的架构设计、拥有大型运维团队的大型企业。而且该平台学习成本高，需要运维团队有使用经验才行。</li><li>​<strong>痛点</strong>​：由于服务过于繁杂，其管理控制台极其复杂，且定价逻辑被称为“成本黑洞”。如果没有专业的成本管理工具，月度账单往往会超出预期。</li></ul><h3>2、Azure：微软生态圈首选</h3><p>微软 Azure 凭借与 Windows Server、SQL Server、Office 365 和 .NET 等微软产品的深度集成，成为已经投资于微软技术栈企业的自然选择。</p><ul><li>​<strong>核心优势</strong>​：与 Windows Server、SQL Server、Active Directory 和 Office 365 的集成极其丝滑。对于已经深度投资微软技术的组织，Azure 提供了最佳的混合云解决方案。</li><li>​<strong>适用人群</strong>​：传统大型企业、政府机构，以及对合规性、混合云部署有极高要求的行业。</li><li>​<strong>痛点</strong>​：对于非 Windows 生态的开发者，其体验相对较重，且部分服务的稳定性经常被开发者社区吐槽。</li></ul><h3>3、GCP（谷歌云）：数据与 AI 的“实验室”</h3><p>GCP（谷歌云） 依靠谷歌在搜索引擎和大数据处理方面的深厚积累，走出了一条差异化道路。</p><ul><li>​<strong>核心优势</strong>​：在数据处理、分析和机器学习领域表现卓越，它是 Kubernetes 的发源地，其 GKE（Google Kubernetes Engine）被公认为行业标杆。</li><li>​<strong>适用人群</strong>​：依赖大数据处理、实时分析和深度学习的初创科技公司或研究机构。</li><li>​<strong>痛点</strong>​：其全球数据中心覆盖范围相比 AWS 和 Azure 略逊一筹，且销售和支持体系在非核心地区相对薄弱，比如中国地区。</li></ul><h2>“三巨头”之外的最佳替代者</h2><p>虽然三巨头功能强大，但对于追求开发速度和成本可控的中小型企业及初创公司来说，它们往往“重”得让人喘不过气。DigitalOcean（简称：DO）的出现，正是为了解决这种“过度设计”的问题。对于很多习惯了 AWS 复杂控制台的工程师来说，第一次登录 DigitalOcean 的后台通常会有一种“解脱感”。凭借着诸多优点，稳定的用户增长和用户口碑，DigitalOcean 也在 2021 年成功上市。</p><h3>1、极致的简单：回归开发者的本原</h3><p>DigitalOcean 的核心理念是“Developer-friendly”。与 AWS 复杂的配置流程不同，在 DO 上创建一个 VPS（其产品名是 Droplet）通常只需要 1 分钟左右。</p><ul><li>​<strong>直观的界面</strong>​：其 UI 设计极其现代化且简洁，即使是没有深厚 DevOps 背景的工程师也能快速上手。</li><li>​<strong>文档力量</strong>​：DigitalOcean 拥有全球最顶尖的开发者社区文档，其教程不仅限于自身产品，还涵盖了通用的 Linux 系统运维知识。</li></ul><h3>2、确定性定价：再也不用担心“账单惊魂”</h3><p>这是 DigitalOcean 对抗三巨头云平台的“杀手锏”。</p><ul><li>​<strong>平价模型</strong>​：DO 采用扁平化的定价，资源配置（CPU、内存、带宽）与价格高度透明。例如，一个基础型的 Droplet 仅需 4 美元/月起。你在 DigitalOcean 后台创建一台 Droplet 云主机的时候，所看到的价格基本就是你月底即将支付的价格。</li><li>​<strong>带宽红利</strong>​：在 AWS/GCP（谷歌云） 上，昂贵的出站流量费用（Outbound Data Transfer）往往是账单的大头（约 0.05-0.09 美元/GiB）。而且，AWS/GCP（谷歌云）在不同区域的出站流量费用计算标准不同，你很难预测最终会收到多大的账单。而 DigitalOcean 不仅在 Droplet 计划中包含了海量的免费流量额度，超出部分的单价仅为 ​<strong>0.01 美元/GiB，所有区域都是这个价格</strong>​。这个价格也低于阿里云、腾讯云在海外的跨区域出站流量价格。这对于 ADX 广告平台、视频流媒体、AI 推理服务、游戏和高并发 API 服务来说，能节省 50% 以上的成本。</li></ul><h2>技术对比：四家云商在核心赛道的表现</h2><p>作为技术负责人，我们需要从底层的技术能力出发进行选型。以下是四大云商在关键领域的对比：</p><h3>1、计算资源（Compute）</h3><ul><li>​<strong>AWS​ EC2</strong>​：支持数千种组合，包括基于 Arm 架构的 Graviton 芯片，适合追求极致算力和架构灵活性的场景。</li><li>​<strong>AzureVM</strong>​：对 Windows 系统优化最好，支持 Azure Dedicated Host。</li><li>​<strong>GCP Compute Engine</strong>​：支持自定义机器类型，可以精准按需购买 CPU 和内存比例，减少资源浪费。</li><li>​<strong><a href="https://link.segmentfault.com/?enc=QaV7sk646Gaxvudc6z8zBg%3D%3D.KLY%2Fkb%2BcYR%2FiO4BV7tfOHO5sVeWvzF7SP22k7QiPfpxLNrXyMj8MwQYxU6NB94qS" rel="nofollow" target="_blank">DigitalOcean Droplets</a></strong>​：分为基础型、通用型、CPU 优化型、内存优化型和存储优化型。配置简单明确，提供 <strong>99.99% 的运行时间 SLA</strong> 保证。事实上，也有不少海外企业选择从 AWS、GCP（谷歌云）、Azure 迁移至 DigitalOcean，或进行多云部署。</li></ul><h3>2、容器化管理（Kubernetes）</h3><ul><li>​<strong>AWS​ EKS</strong>​：最成熟，但在控制平面收费（0.1 美元/小时），且与网络策略、IAM 集成较为复杂。</li><li>​<strong>GCP GKE</strong>​：自动化程度最高，拥有最强大的自动扩缩容能力。</li><li>​<strong><a href="https://link.segmentfault.com/?enc=smLP8du7%2BcajPa0VZ7lXng%3D%3D.0cok2zU2xvg8Nka0LV0Tkkz%2B3HEm%2BHzdlaxyUboaRhMdI035dPpt%2FLDlAiQHvYPI" rel="nofollow" target="_blank">DigitalOcean kubernetes</a></strong>​：管理最为简单，且​<strong>不收取控制平面的管理费</strong>​。开发者只需支付底层的 Worker Nodes 费用，这使其成为中小规模 K8s 集群的最佳选择。</li></ul><h3>3、AI 与 GPU 云服务</h3><p>在当前的 AI 浪潮下，GPU 的可用性与价格是重中之重。</p><p>亚马逊 AWS、微软 Azure、谷歌云 GCP 虽然拥有海量 GPU，但通常需要通过冗长的“配额申请”，且 H100 等高端算力价格昂贵，主要面向大模型训练。AWS 这样的大型云平台，通常优先服务于大型企业，所以他们只会提供 8 卡 H100 这样的资源，没有单卡 H100 供用户灵活选择。而且数据存储与带宽成本高昂，这一点，我们在后面会对比。</p><p>DigitalOcean 现在提供了极具竞争力的<a href="https://link.segmentfault.com/?enc=w8nkVuioN493g5mzUe2R5Q%3D%3D.4oJ%2BZkP885qRh6h1dlR%2BBNeIbGxsBpwKlDYLYdB5UXbUo5EKHw%2FhYJ%2FhkykPuzL7" rel="nofollow" target="_blank"> GPU Droplets</a>。DigitalOcean 与 NVIDIA、AMD 是紧密的合作伙伴，凭借高可靠的技术服务，为包括 Character.ai、AMD Developer Cloud、Fal.ai、Persistent AI 等企业提供千卡规模的 AI 服务。</p><ul><li>​<strong>NVIDIA H100 ​算力</strong>​：DO 的 H100 On-demand 价格约为 ​<strong>3.39 美元/小时</strong>​，相比三巨头能节省高达 75% 的成本。</li><li>​<strong>型号丰富</strong>​：不仅提供 H100，还包括 L40S、A100、RTX 4000 等，支持从模型训练到 AI 推理的全场景应用。而且 DigitalOcean 的 GPU 卡型还在不断增加，预计在 2026 年初还将提供 NVIDIA B300、AMD MI355X 等旗舰 GPU。</li><li>​<strong>即开即用</strong>​：DigitalOcean 的 GPU Droplet 无需繁琐申请，适合需要快速验证 AI 原型的初创团队。在部分 GPU 型号资源不足的，或者新型 GPU 还未发布上线的情况下，还可直接联系 DigitalOcean 中国区独家战略合作伙伴卓普云 AI Droplet （aidroplet.com）提前预定新型 GPU，或提前锁定未来可能即将新增的 GPU 资源。</li></ul><h3>4、出海网络与全球覆盖</h3><ul><li>​<strong>三巨头</strong>​：亚马逊 AWS、微软 Azure、谷歌云 GCP 在全球范围内拥有数百个边缘节点和区域（Regions），基础设施最为庞大。</li><li>​<strong>DigitalOcean</strong>​：在 9 个核心区域拥有 15 个数据中心，包括纽约、旧金山、伦敦、阿姆斯特丹、法兰克福、新加坡、多伦多、班加罗尔和悉尼。对于中国企业出海而言，其新加坡节点（SGP1）对东南亚用户非常友好，而其欧美节点则是搭建出海站点的首选。</li></ul><p>出了以上产品服务，亚马逊 AWS、微软 Azure、谷歌云 GCP、DigitalOcean 还提供常见的数据库托管、对象存储、块存储、负载均衡等一系列产品服务。</p><h2>粗略算一笔账：1 TB 数据的实际取回成本</h2><p>由于亚马逊 AWS、微软 Azure、谷歌云 GCP、DigitalOcean 的产品服务众多，我们无法对他们的服务成本进行逐一对比。但我们可以从其中一项存储服务成本来管中窥豹。之所以选择存储服务，是因为从目前趋势来讲，AI 、流媒体等产品</p><p>假设在 AWS 与 DigitalOcean 上分别存储 ​<strong>1 TB 的冷数据</strong>​，当业务需要重新使用该数据（如模型复训、历史数据回放或分析计算）时，其实际成本并不仅仅体现在存储单价上，而主要集中在​<strong>数据取回与流转阶段</strong>​。</p><p>以 AWS 为例，若数据存储在 ​<strong>S3 Glacier Flexible Retrieval</strong>​：</p><ul><li>数据取回费用约为 <strong>​&amp;dollar;0.01/GB（​</strong>​<strong><em>注意：</em></strong>​<strong>​ 如果选择“加急（Expedited）”，价格会飙升至 &amp;dollar;0.03/GB；如果选择“批量（Bulk）”，可以降至 &amp;dollar;0.0025/GB，但耗时需 5-12 小时。）</strong></li><li>1 TB 数据一次性取回成本约为 <strong>&amp;dollar;10</strong></li></ul><p>取回完成后，数据将临时恢复至 S3 Standard，并在后续产生：</p><ul><li>标准存储费用</li><li>可能的跨可用区或公网出站流量费用</li></ul><p>在实际工程中，这部分成本往往与 GPU 使用周期强相关。</p><p>相比之下，若数据需要被拉取至云外 GPU 平台（如独立 GPU 云或海外算力节点），还将额外产生：</p><ul><li>公网出站流量费用（通常约 ​<strong>&amp;dollar;0.09/GB</strong>​）</li><li>1 TB 数据出站成本约为 <strong>&amp;dollar;90</strong></li></ul><p>也就是说，一次完整的数据“冷存 → 取回 → 计算”流程，其实际支出结构大致为：</p><p>&amp;dollar;10 数据取回 +&amp;dollar;90 数据出站 ≈ &amp;dollar;100 单次数据流转成本（不含存储本身）</p><p>如果将同样的使用场景放在​<strong>​ DigitalOcean 上</strong>​，其成本结构会明显简化。</p><p>在 DigitalOcean 中，Spaces 对象存储并不区分冷热层级，数据始终处于可直接访问状态，因此​<strong>不存在取回费用，也无需等待解冻过程</strong>​。当 1 TB 数据需要重新用于 GPU 计算时，可直接从 Spaces 读取至同区域的 GPU Droplet，不产生额外的数据检索或内部传输费用。</p><p>在公网数据分发阶段，Spaces 基础订阅（&amp;dollar;5/月）包含 <strong>1 ​TB</strong>​​<strong>​ 的免费出站流量</strong>​。在该额度内，完整的数据取回与下发过程不会产生额外流量费用。</p><p>所以在 AWS 需要 100 美元左右，而在 DigitalOcean 仅需 5 美元。</p><p>在数据规模达到数 TB 或需要周期性复训的场景下，​<strong>数据流转费用往往会显著超过冷存储本身的长期成本</strong>​，成为影响整体 GPU 使用效率与算力预算的重要因素。</p><h2>选型决策：你的企业该如何选择？</h2><h3>1、什么时候选 AWS / Azure / GCP？</h3><ul><li>​<strong>架构极度复杂</strong>​：当你的业务需要覆盖非常多的区域、高度定制化的数据库集群或卫星通信、量子计算等尖端服务时。</li><li>​<strong>合规性要求极高</strong>​：如果你是金融机构，需要通过极其严苛的政府合规性认证。</li><li>​<strong>微软生态依赖</strong>​：业务底层深度依赖 .NET、Active Directory 和 Windows 域管理。</li></ul><h3>2、什么时候 DigitalOcean 是更明智的选择？</h3><ul><li>​<strong>中小型企业/初创团队</strong>​：你没有庞大的运维团队，希望工程师能专注于业务代码，而不是钻研繁琐的云平台配置。</li><li>​<strong>成本高度敏感</strong>​：特别是那些有大量出站流量（如 AI、区块链、广告平台等）的业务，DigitalOcean 的流量费用优势几乎无可替代。</li><li><strong>AI/ML</strong>​​<strong>​ 快速开发</strong>​：需要稳定的 GPU 算力进行模型推理或小规模训练，且对性价比有极高要求。</li><li>​<strong>业务全球化出海</strong>​：需要快速在海外（如北美、欧洲、东南亚）部署稳定节点。</li></ul><h2>中国企业的特别助力：卓普云 AI Droplet</h2><p>对于中国境内的技术负责人来说，直接使用海外云服务往往面临支付流程复杂、技术支持跨时区等问题。<a href="https://link.segmentfault.com/?enc=j%2BUaho8kAiDZWhNuj0MfAQ%3D%3D.%2BHx%2FjghF3oPElGzfxIau%2BEWPYE3b9flxTIAqy9Ncbew%3D" rel="nofollow" target="_blank">卓普云 AI Droplet </a>作为 DigitalOcean 的中国区战略合作伙伴，专门为 DigitalOcean 在中国及亚太地区的企业客户提供售前咨询、技术支持。</p><p>通过卓普云，中国企业可以​<strong>无缝对接 DigitalOcean 全线产品</strong>​，包括高性能的 GPU H100 实例和常规 Droplets，甚至预约提前测试即将上线的新产品，比如 NVIDIA B300 GPU Droplet，抢占旗舰级 AI 算力资源。同时，卓普云还提供​<strong>专业的技术咨询</strong>​，帮助企业将架构平稳迁移至 DO，实现低成本快速业务上线。</p><p>与此同时，由于 卓普云 AI Droplet 是由 DigitalOcean 最大股东全资建立的，所以可以帮助客户获得 DigitalOcean 的一手资源，以及进一步的​<strong>优惠折扣</strong>​。</p><h2>总结</h2><p>AWS、Azure 和 GCP（谷歌云）就像是功能齐全、体量巨大的超级航母，虽然能抵御任何风浪，但转向缓慢且运行成本高昂。而 DigitalOcean 更像是一艘轻快、敏捷且火力精准的巡洋舰。</p><p>对于大多数处于快速增长期的中国出海企业而言，“不过度设计、可预测的成本、卓越的性能”才是技术选型的真谛。DigitalOcean 通过简化复杂的云原生技术，让技术团队能腾出手来，去创造更有价值的业务成果。</p><p>无论你的目标是构建下一个独角兽应用，还是在全球范围内部署 AI 推理节点，深入理解这四大云服务商的区别，将为你企业的技术长青奠定坚实的基础。</p>]]></description></item>  </channel></rss>