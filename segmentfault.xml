<?xml version="1.0" encoding="UTF-8"?><rss version="2.0">  <channel>      <title>SegmentFault - 最近文章</title>      <link>https://segmentfault.com/blogs/newest</link>      <description>SegmentFault 思否</description>      <generator>python segmentfault.py @Pi20</generator>      <item>    <title><![CDATA[Compaction in Apache Iceberg 数新智能 ]]></title>    <link>https://segmentfault.com/a/1190000047461570</link>    <guid>https://segmentfault.com/a/1190000047461570</guid>    <pubDate>2025-12-09 17:11:49</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在 Apache Iceberg 的数据管理体系中，数据压缩（Compaction）是优化存储布局、提升查询性能的核心维护任务之一。通过 Binpack 重写策略、排序策略及 Z 序排序等机制，Iceberg 可高效合并小文件、重组数据分布，减少元数据冗余与查询扫描成本。本文结合表维护流程，深入解析 Compaction 的核心策略原理，以及过期快照清理、旧元数据删除、孤儿文件处理等配套机制，为优化 Iceberg 表存储效率提供实践指引。</p><p>原文：<a href="https://link.segmentfault.com/?enc=uJdfyPaK3A7riJxB9pLBQA%3D%3D.3HdHzXh%2FPRGtq4b5Dd3iFRqv%2Ff6FNwRbjGp6jeP11TiUxA8wL8YflrRVMOcTZgygV%2F56JZX52T%2FDNK60SsGW7QVXbseciwE9p9K3GLzfyEMwOpsA3CAJElzNRDxDfkcLQX%2FizOUVOkGhUfToSAssxt4BdAV26esIdB0twcYYNZskFJATqcBqBaB7s6AoAt%2F%2Fygx6%2F8BB6tZ4VmR0jhhNfzOlWa2DJVYIZfkFtByXGi3HIVQTZO7oYHyWANzGC2oayjC8pI%2BkGbwsQ5Agr%2BtjFw%3D%3D" rel="nofollow" target="_blank">https://www.dremio.com/blog/compaction-in-apache-iceberg-fine...</a> Tasks with Iceberg Tables在 数据湖上使用 iceberg有很多好处，如 partition/schema evolution、time-travel、version rollback 等等<br/>但数据摄取时会出现很多小问题，对于 hive 来说是很大问题，对于 ice-berg 可以用 压缩来解决<br/>对于 任何表格式来说，都需要定期清理，确保元数据文件不要太多<br/>iceberg提供 API的方式，可以expire snapshotsremove old metadata filesdelete orphan filesCompaction<br/>太多的小文件会导致性能问题，当执行压缩时使用 rewriteDataFiles procedure 来做压缩，可以选择压缩的文件，以及期望的结果大小spark 会将这些小文件读取，然后合并压缩为大文件之后是写 manifest files、manifest list、表元数据，最后提交这次修改到 catalog之前的旧文件还在，但不会被查询到了，除非指定了 time-travel<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047461573" alt="图片" title="图片"/><br/>使用 RewriteDataFiles 来做压缩，支持 spark3 和 flink<br/>这里指定了 event_date，大于 7 天前的数据<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047461574" alt="图片" title="图片" loading="lazy"/><br/>sql 方式<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047461575" alt="图片" title="图片" loading="lazy"/><br/>一些参数The table: Which table to run the operation onThe strategy: Whether to use the “binpack” or “sort” strategy (each are elaborated upon in the sections below)Options: Settings to tailor how the job is run, for example, the minimum number of files to compact, and the minimum/maximum file size of the files to be compacted其他参数Where: Criteria to filter files to compact based on the data in them (in case you only want to target a particular partition for compaction)Sort order: How to sort the data when using the “sort” strategy<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047461576" alt="图片" title="图片" loading="lazy"/><br/>The Binpack Rewrite Strategy<br/>这是默认的策略，将 很多小文件合并为目标大文件，没有再做其他优化了，所以压缩速度会很快<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047461577" alt="图片" title="图片" loading="lazy"/><br/>默认的目标 size 为 512M<br/>下面是压缩 最近一小时的数据<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047461578" alt="图片" title="图片" loading="lazy"/><br/>The Sort Strategy<br/>除了压缩小文件，还做了排序，这意味着最小/最大过滤的好处将会更大(扫描的文件越少，速度越快)<br/>未排序的压缩如下：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047461579" alt="图片" title="图片" loading="lazy"/><br/>由于没有排序，查询时需要扫描两个文件，而经过排序之后，就可以减少扫描文件的数量<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047461580" alt="图片" title="图片" loading="lazy"/><br/>排序策略如下，增加了 sort_order 参数：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047461581" alt="图片" title="图片" loading="lazy"/><br/>排序多个字段，以及如何对待 NULL<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047461582" alt="图片" title="图片" loading="lazy"/><br/>Z-Order Sorting<br/>跟多列排序不一样，他是将所有列等值的对待<br/>假设有 heigh_in_cm，以及 age，将他们记录到 四个象限中<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047461583" alt="图片" title="图片" loading="lazy"/><br/>之后将所有的记录 put 到这四个象限中，并将他们写入到合适的文件中，这对于 min/max 来说很有益<br/>比如当你搜索 age = 25,高度未 200cm，这样只会定位到一个文件，也就是左下方的象限<br/>z-order可以重复多次，在一个象限内创建另外四个象限，用户进一步微调集群，比如对左下进一步微调，就得到了下面这样：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047461584" alt="图片" title="图片" loading="lazy"/><br/>当运行 age 和 heigh_in_cm 查询时，可以有效的做裁剪，所以z-order适合多维度，也就是多个列同时查询<br/>可以通过下面这样配置z-order压缩<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047461585" alt="图片" title="图片" loading="lazy"/><br/>Expire Snapshots<br/>iceberg的有一个好处是，通过快照可以做 time-travel，verion rolback， 快照中的 manifest files不会被删除<br/>当手动指定删除不需要的快照时，对应的 manifest list、manifest files、data files 都会被删除<br/>如果这个 数据文件还被其他 有效的manifest files 关联，则不会被删除<br/>孤儿文件不关联任何快照，需要用其他的方式将其删除<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047461586" alt="图片" title="图片" loading="lazy"/><br/>下面是 删除所有 tsToExpire 之前的快照，也可以指定删除任意处理的快照，或者快照 ID<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047461587" alt="图片" title="图片" loading="lazy"/><br/>Removing Old Metadata files<br/>Snapshot isolation 是iceberg中非常有用的一个特性<br/>但流写入时，会出现很多新的小文件，删除过期文件可以将这些文件数据删除，但是处理不了 manifest 文件<br/>iceberg 可以允许你设置开启 最老的 manifest 文件删除功能，当新的一个创建时，就会删除掉老的 manifest文件<br/>还可以指定要保留的 manifest文件数量，下面是 保留 4 个<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047461588" alt="图片" title="图片" loading="lazy"/><br/>下面是设置删除最老的 manifest 文件，当新的创建时，默认为 false：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047461589" alt="图片" title="图片" loading="lazy"/><br/>下面设置要保留多少个 manifest文件，默认为 100<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047461590" alt="图片" title="图片" loading="lazy"/><br/>Delete Orphan Files<br/>job、task执行失败，可能会导致写入了部分数据，这些数据没有任何关联任何快照，因此也不能用正常的方式删除他们，因为没有任何关联关系<br/>正常的 快照过期，删除元数据都不行，需要用其他方式扫描表的目录，然后找到他们<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047461591" alt="图片" title="图片" loading="lazy"/><br/>deleteOrphanFiles 操作如下<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047461592" alt="图片" title="图片" loading="lazy"/><br/>这个操作是扫描每个有效的快照，然后找到哪些文件 关联了这些快照<br/>对于在 数据目录中，没有被有效快照关联的文件，就可以被删除了<br/>表的文件也可以存储在数据目录之外，因此需要定期的做清理olderThan，帮助预防删除正常处理的文件location，删除指定目录下的数据，这些数据不在 主数据目录中，肯恩是之前从其他地方迁移到 iceberg 中的<br/>Reference<br/>How Z-Ordering in Apache Iceberg Helps Improve Performance<br/>What Is a Data Lakehouse?<br/>OneTable github<br/>相关文章<br/>The Life of a Read/Write Query for Apache Iceberg Tables</p>]]></description></item><item>    <title><![CDATA[6款Vibe Coding工具，让开发从从容容游刃有余 烦恼的沙发 ]]></title>    <link>https://segmentfault.com/a/1190000047461712</link>    <guid>https://segmentfault.com/a/1190000047461712</guid>    <pubDate>2025-12-09 17:10:55</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>Vibe Coding 最近是越来越火了，但Vibe Coding 其实不关心代码是怎么实现的，只关心代码生成的结果对不对。</p><p>以下这6款Vibe coding让你的开发也越来越顺手。这几款工具分别从编辑器、环境配置、云端协作及工作流自动化等不同维度，诠释了什么是更高效的开发体验。</p><h3><a href="https://link.segmentfault.com/?enc=xQKrUeHhIbliCZPlxMGsow%3D%3D.WbhjCeAVK%2BnWCWLcSuO%2BeevbWvqZBzoCzWEO%2BUrOqGQ%3D" rel="nofollow" target="_blank">Windsurf</a></h3><p><strong>特点：保持心流的智能编辑器</strong></p><p><img width="720" height="424" referrerpolicy="no-referrer" src="/img/bVdni7y" alt="image.png" title="image.png"/></p><p>Windsurf 的设计初衷是让开发者维持在心流状态（flow state）。作为一款 AI 原生编辑器，它不仅能在开发者需要时提供代码补全，更通过 Cascade 模式实现了对上下文的深度理解。它能够分析开发者的意图，主动协助重构代码、解释复杂逻辑或生成功能模块。Windsurf 的介入感很低，它不会打断思路，而是让代码编写的过程变得更加连贯和平滑。</p><h3><a href="https://link.segmentfault.com/?enc=EnwPN1CBrHULmqgpMl%2BCDA%3D%3D.3KoRdqTUTi%2Ffq6Rmc1EhHvaEqzAPFhh01C%2BoCrjOPzE%3D" rel="nofollow" target="_blank">ServBay</a></h3><p><strong>特点：本地开发环境与模型的一键部署</strong></p><p><img width="723" height="458" referrerpolicy="no-referrer" src="/img/bVdni7z" alt="image.png" title="image.png" loading="lazy"/></p><p>在进入代码编写之前，繁琐的环境配置往往最消磨热情。ServBay 专注于解决<a href="https://link.segmentfault.com/?enc=3GJ%2B8j9IOB7j7oe3I7zJmA%3D%3D.QvAvp2dmJqk4x5Kd%2FNFHBmovk94T90ZQcnZsPWlS8WY%3D" rel="nofollow" target="_blank">web开发</a>上的这一痛点。它能够一键安装并管理各种 CLI 运行环境，例如 Node.js 和 Python，让开发者免去处理版本冲突和路径依赖的麻烦。</p><p>更值得一提的是，ServBay 支持一键在本地部署 Gemma、Llama 等开源大模型。对于希望在本地安全运行 AI 能力，或者需要快速搭建稳健开发环境的开发者而言，ServBay 提供了一种干净、可控的解决方案。</p><h3><a href="https://link.segmentfault.com/?enc=42SqL%2FuuV5vJrsDLi1yCBg%3D%3D.sfKX2TPClD0FDEmBC4Ruug%3D%3D" rel="nofollow" target="_blank">v0</a></h3><p><strong>特点：对话式的 UI 生成专家</strong></p><p><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdni7A" alt="image.png" title="image.png" loading="lazy"/></p><p>如果说 ServBay 解决了后端的环境问题，v0 则扫除了前端开发的视觉障碍。由 Vercel 推出的 v0 允许开发者通过简单的文本描述，即时生成基于 React 和 Tailwind CSS 的精美界面。它不是简单的代码片段拼凑，而是能理解设计美学和组件交互。对于不擅长 CSS 调整或希望快速验证产品原型的开发者，v0 能将耗时的界面搭建过程压缩到几秒钟，让想法瞬间可视。</p><h3><a href="https://link.segmentfault.com/?enc=A95Adzylz7alWjdwCdnieQ%3D%3D.512P9tgJSYzGoQLcLL9%2F19aYUNCn%2B48wXcpvFEwhCVw%3D" rel="nofollow" target="_blank">Cursor</a></h3><p><strong>特点：深度理解代码库的智能助手</strong></p><p><img width="723" height="405" referrerpolicy="no-referrer" src="/img/bVdni7B" alt="image.png" title="image.png" loading="lazy"/></p><p>Cursor 改变了开发者与 IDE 的交互方式。它不仅仅是修补当前行的代码，而是通过索引整个项目，实现了对全局代码库的感知。开发者可以使用自然语言直接对项目进行提问、修改或重构。无论是处理遗留代码还是开发新功能，Cursor 都能基于对整体架构的理解给出准确建议，大幅减少了阅读文档和搜索解决方案的时间。</p><h3><a href="https://link.segmentfault.com/?enc=PpgRc4ocHGbPE8Wa291i5A%3D%3D.YkkaAOz8mYmEjT%2F4%2BP9K4MWmgEfoS7U0qCNavWgtbqg%3D" rel="nofollow" target="_blank">Aider</a></h3><p><strong>特点：终端里的结对编程专家</strong></p><p><img width="723" height="356" referrerpolicy="no-referrer" src="/img/bVdni7C" alt="image.png" title="image.png" loading="lazy"/></p><p>Aider 是一款深受极客推崇的命令行 AI 编程工具。它不仅能与 GPT-4、Claude 3.5 等模型连接，最核心的优势在于它能直接编辑本地代码文件，并自动进行 Git 提交。开发者只需在终端输入需求，Aider 就能分析整个仓库，跨文件进行修改和调试。</p><p>对于习惯在终端工作且追求高可控性的开发者，Aider 提供了精准且高效的辅助体验</p><h3><a href="https://link.segmentfault.com/?enc=gWQxMPpF2%2BQaN0Ye8pbbXQ%3D%3D.JnO4eEn%2BPgX%2Bzq0xMSYdcw%3D%3D" rel="nofollow" target="_blank">n8n</a></h3><p><strong>特点：可视化的工作流自动化</strong></p><p><img width="723" height="356" referrerpolicy="no-referrer" src="/img/bVdni7C" alt="image.png" title="image.png" loading="lazy"/></p><p>并非所有功能都需要一行行代码来实现。n8n 采用基于节点的可视化界面，将 API 集成与业务逻辑自动化变得直观而高效。它能够连接 GitHub、Slack、Google Sheets 等数百种服务，既支持无代码拖拽，也允许通过 JavaScript 编写自定义逻辑。</p><p>n8n 减少了大量重复性的“胶水代码”，让开发者将精力集中在核心业务的构建上。</p><ul><li><ul><li>*</li></ul></li></ul><p>Vibe Coding 的核心在于流畅。上述这些工具，无论是为了解决环境配置的痛点，还是为了提升代码编写的效率，最终目的都是为了消除开发过程中的摩擦力。当工具足够得心应手，技术将不再是门槛，而是实现灵感的捷径。</p>]]></description></item><item>    <title><![CDATA[机器学习原理剖析与Python代码实现全流程 可爱的篮球 ]]></title>    <link>https://segmentfault.com/a/1190000047461714</link>    <guid>https://segmentfault.com/a/1190000047461714</guid>    <pubDate>2025-12-09 17:10:05</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在数字化浪潮席卷全球的今天，机器学习已不再是遥不可及的科技神话，而是逐渐渗透到教育、医疗、金融等各个领域，成为推动社会进步的重要力量。对于教育领域而言，如何将复杂的机器学习知识以通俗易懂的方式传授给初学者，尤其是零基础的学生，成为了一个亟待解决的问题。本文将以“7天搞定线性回归”为目标，从教育角度出发，剖析线性回归的原理，并规划一条高效的学习路径，帮助学习者在短时间内掌握这一机器学习基石。</p><p>第一天：理解机器学习与线性回归的基础<br/>教育目标：建立对机器学习的基本认知，明确线性回归在其中的地位。</p><p>内容设计：</p><p>机器学习简介：通过生动的案例，如推荐系统、自动驾驶等，让学生感受到机器学习的魅力，理解其“让机器从数据中学习”的本质。<br/>线性回归初探：以生活中的例子引入，比如预测房价基于面积、预测学生成绩基于学习时间等，说明线性回归是通过寻找数据间的线性关系来进行预测的模型。<br/>学习路径规划：明确7天的学习目标，每天的学习重点，以及预期达到的成果，让学生有清晰的学习方向。<br/>第二天：深入线性回归的数学原理<br/>教育目标：掌握线性回归的数学基础，理解其背后的逻辑。</p><p>内容设计：</p><p>线性方程回顾：复习一元一次方程，为理解多元线性回归打下基础。<br/>最小二乘法原理：通过图形直观展示，解释如何通过最小化误差平方和来找到最佳拟合线，这是线性回归的核心思想。<br/>损失函数与优化：引入损失函数的概念，说明如何通过梯度下降等优化算法来最小化损失，从而找到最优参数。<br/>第三天：线性回归的假设与评估<br/>教育目标：理解线性回归的前提假设，学会评估模型的好坏。</p><p>内容设计：</p><p>线性回归的假设：讲解线性关系、独立性、同方差性、无多重共线性等假设，让学生明白这些假设对于模型有效性的重要性。<br/>模型评估指标：介绍均方误差（MSE）、决定系数（R²）等评估指标，通过实例说明如何计算并解读这些指标，判断模型的拟合效果。<br/>第四天：线性回归的变体与扩展<br/>教育目标：拓宽视野，了解线性回归的多种形式及其应用场景。</p><p>内容设计：</p><p>多元线性回归：从一元扩展到多元，说明如何处理多个自变量的情况。<br/>正则化线性回归：介绍岭回归、Lasso回归等正则化方法，解释它们如何防止过拟合，提高模型的泛化能力。<br/>实际应用案例：分享线性回归在金融、医学、经济学等领域的成功应用，激发学生的学习兴趣。<br/>第五天：数据预处理与特征工程<br/>教育目标：掌握数据预处理和特征工程的基本技巧，为建模打下坚实基础。</p><p>内容设计：</p><p>数据清洗：讲解缺失值处理、异常值检测与处理等方法，确保数据质量。<br/>特征缩放：介绍标准化、归一化等特征缩放技术，说明它们对模型训练的影响。<br/>特征选择与构造：探讨如何选择重要特征，以及如何通过组合、转换等方式构造新特征，提升模型性能。<br/>第六天：模型训练与调优实战<br/>教育目标：通过实践，掌握线性回归模型的训练与调优过程。</p><p>内容设计：</p><p>模拟数据集实践：使用模拟数据集，👇🏻ke程：shanxueit点com/引导学生一步步完成数据预处理、模型训练、评估与调优的全过程。<br/>调优策略分享：介绍网格搜索、随机搜索等调优方法，帮助学生找到最优模型参数。<br/>问题解决技巧：总结在建模过程中可能遇到的问题，如过拟合、欠拟合等，并提供相应的解决策略。<br/>第七天：综合应用与项目展示<br/>教育目标：通过综合应用，巩固所学知识，提升解决实际问题的能力。</p><p>内容设计：</p><p>真实项目挑战：提供一个真实或接近真实的数据集，让学生分组完成从数据探索、预处理、建模到评估的全流程。<br/>项目展示与交流：各组展示项目成果，分享建模思路、遇到的挑战及解决方案，促进相互学习与交流。<br/>总结与展望：回顾7天的学习历程，总结线性回归的核心知识点，展望机器学习领域的未来发展趋势，鼓励学生继续深入学习。<br/>通过这7天的学习，学生不仅能够掌握线性回归的基本原理与实战技巧，更重要的是，他们将学会如何像数据科学家一样思考，具备解决实际问题的能力。机器学习的大门已为他们敞开，未来的数据科学之旅，正等待着他们去探索与发现。</p>]]></description></item><item>    <title><![CDATA[阿里云微服务引擎 MSE 及 API 网关 2025 年 11 月产品动态 阿里云云原生 ]]></title>    <link>https://segmentfault.com/a/1190000047461796</link>    <guid>https://segmentfault.com/a/1190000047461796</guid>    <pubDate>2025-12-09 17:09:07</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img width="723" height="2130" referrerpolicy="no-referrer" src="/img/bVdni8W" alt="image.png" title="image.png"/></p>]]></description></item><item>    <title><![CDATA[DigitalOcean AI 智能体评估功能全新升级：更快速，更深入 DigitalOcean ]]></title>    <link>https://segmentfault.com/a/1190000047461820</link>    <guid>https://segmentfault.com/a/1190000047461820</guid>    <pubDate>2025-12-09 17:08:32</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>评估 AI 智能体并非易事，尤其当现有工具无法契合你的思维和工作方式时。为此，我们很高兴宣布，DigitalOcean Gradient™ AI 平台中的智能体评估功能现已全面升级。新版本将帮助你更快速、更轻松地评估 AI 智能体、理解结果并定位问题。</p><h2>智能体评估功能有哪些更新？</h2><p>原有的评估功能虽然强大，但存在一些影响开发者使用体验的痛点。本次升级正是为了彻底解决这些问题：</p><ul><li>按目标归类的评估指标：评估指标现在按目标导向的逻辑分组呈现，例如“安全与防护”“准确性”“检索增强生成性能”等类别。“安全与防护”组已预设勾选，帮助开发者快速、安心地开始评估。</li><li>示例数据集：新增常见评估场景的示例数据集，助你高效创建自定义数据集。</li><li>明确且持续的报错提示：上传错误提示现在更清晰、持续显示且具体明确，例如“验证错误：缺少‘query’列”。开发者能轻松理解并修复问题，减少测试环节的阻碍。</li><li>可解读的结果与调用链路追溯：评估结果按设置时采用的指标组别分类展示，每个指标及其评分方式均配有提示说明。通过与可观测工具的深度集成，开发者可直接从低分项跳转至完整调用链路，快速调试并优化模型。</li></ul><h2>为何需要使用评估功能？</h2><p>评估功能帮助你系统化测试和改进 AI 智能体，更轻松地发现问题和优化性能。对于入门者，预设的“安全与防护”指标和示例数据集能快速检测常见问题（如不安全或有偏差的输出），让你对智能体的表现更有信心。</p><p>对于需要规模化部署的团队，自定义测试用例、针对“检索增强生成性能”等专项指标组，以及上传自有数据集的功能，将为你提供更深度的智能体表现洞察。结合调用链路追溯功能，你可深入分析低分项目，精准调试和改进智能体。评估功能能助你将结果快速转化为具体优化方案，帮助各阶段的开发者构建更安全、更可靠的 AI 智能体。</p><h2>如何开始使用智能体评估？</h2><p>准备好测试你的智能体了吗？在 DigitalOcean Gradient™ AI 平台中开始评估非常简单：</p><ol><li>在云控制台中打开你的智能体评估页面。</li><li>创建新测试用例并为其命名。建议使用独特且描述清晰的名称，体现测试目标或场景，便于后续查找。</li><li>选择要评估的指标，重点关注对你的智能体最为关键的维度。</li><li>选择数据集。如需创建自定义数据集，可参考文档中的示例快速生成 CSV 文件。</li><li>运行评估并查看结果。通过调用链路追溯功能深入分析低分项，高效调试智能体。</li></ol><p>现在就开始评估你的智能体吧！精准把控 AI 性能，及时发现潜在问题，优化智能体行为，打造可靠且可快速投入生产环境的系统。</p>]]></description></item><item>    <title><![CDATA[小参数大能量：美团开源模型破解中文AIG生图痛点 多情的青蛙 ]]></title>    <link>https://segmentfault.com/a/1190000047461822</link>    <guid>https://segmentfault.com/a/1190000047461822</guid>    <pubDate>2025-12-09 17:07:57</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>12月6日，美团LongCat团队正式开源图像生成模型LongCat-Image，以60亿参数的轻量化规模，实现了超越大参数模型的性能，尤其在中文文本渲染和图像编辑领域取得开源领先成绩，为中小企业和开发者带来“低成本高可用”的AI创作方案。</p><p><strong>当前AIGC生图领域存在“两难”：</strong>闭源模型性能强但无法二次开发，开源模型常陷“参数大则成本高、参数小则效果差”的困境。LongCat-Image打破了这一平衡，6B参数仅为主流模型的1/10，却在GenEval测试中取得0.87分，与20B参数的Qwen-Image持平，更超越80B参数的HunyuanImage-3.0。</p><p><strong>中文渲染难题被彻底攻克是其核心亮点。</strong>通过千万级合成数据与真实文本图像训练，模型覆盖8105个通用汉字，ChineseWord评测以90.7分大幅领先，连生僻字也能精准融入画面风格。某餐饮商家用其生成促销海报，输入“克莱因蓝背景下的橘猫探出头，配‘宠爱季’艺术字”，10秒即得符合要求的商用素材，效率提升近10倍。</p><p><strong>美团的开源策略意义深远。</strong>全流程代码与训练方案公开，开发者可在消费级显卡上部署，二次开发成本降低70%。这不仅填补了中文场景优质开源资源的空白，更以MIT许可协议打开商用大门，推动AIGC从互联网大厂走向街边小店。</p><p>LongCat-Image的突破证明，技术普惠无需依赖超大参数。当轻量化模型能精准匹配产业需求，AI生图才能真正成为实体经济的创作引擎。</p><p><img width="723" height="373" referrerpolicy="no-referrer" src="/img/bVdni9d" alt="企业微信截图_17652685055447.png" title="企业微信截图_17652685055447.png"/></p>]]></description></item><item>    <title><![CDATA[采购部从“背锅侠”到“价值引擎”：制造企业的数据突围战 容智信息 ]]></title>    <link>https://segmentfault.com/a/1190000047461826</link>    <guid>https://segmentfault.com/a/1190000047461826</guid>    <pubDate>2025-12-09 17:06:58</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047461828" alt="图片" title="图片"/><br/>“李经理，这批钢材的采购价格比近期市场均价高出约7%，财务部门再次提出质询。”“生产部急需的零部件，我们花了三个多小时才厘清库存与在途情况，他们还在催促。”在一家年采购额超过3亿元的装备制造企业，采购部经理李先生的日常工作长期被几类问题所困扰：成本管控缺乏依据：大量采购数据沉淀在ERP系统中，难以进行实时分析，无法精准把握价格趋势与采购批量的最优组合，时常被动接受供应商调价，事后复盘才发现成本高出行业平均水平。供应商管理依赖经验：对接的200多家供应商，评估多依靠“合作过几次”“交货还算及时”等主观印象，缺乏客观数据支撑，不时面临交期延迟或质量波动。跨部门协同效率偏低：面对生产部门的紧急需求，采购人员需要手动查询多系统库存、翻阅合同条款、询问供应商产能，沟通成本高，响应速度慢。一次典型事件促使管理层下定决心改变：某关键原材料的主力供应商突然断供，而备选供应商仅基于过往的一次合作经历进行评估，准备不足。采购部不得不紧急寻找新供应商，不仅导致采购成本上浮10%，更造成生产线停工两小时，直接经济损失超过20万元。李经理深刻意识到，必须建立基于数据的决策体系，彻底改变“凭经验、靠感觉”的工作模式。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047461829" alt="图片" title="图片" loading="lazy"/><br/>在一次行业数字化研讨活动中，李经理了解到一套专注于采购数据分析的解决方案（容智ReportAgent）。该方案旨在打通企业内部数据，针对成本分析、供应商评估及协同效率等痛点提供支持。企业随后启动了试点项目，系统在两周内完成了与现有ERP的数据对接，整合了采购价格、交货周期、质量合格率、供应商绩效等十余类关键数据，构建起统一的采购数据分析平台。其“对话式分析”功能在实际工作中迅速展现出价值。以往，若需分析不锈钢材料近三个月的市场价格趋势并测算最优采购批量，采购员需要协调IT部门导出数据，并手动进行多维度分析，流程冗长。如今，采购人员只需在系统中输入诸如“不锈钢S304近期价格趋势及建议采购批量”的自然语言问题，系统便能自动生成可视化图表与量化建议，甚至能对价格波动关键点进行提示。例如，某次系统监测到铜材价格进入下行通道，结合未来生产计划，自动给出了“增加30%采购批量”的优化建议。单次执行即为企业节省采购成本12万元。采购团队反馈，数据支持使其工作模式从“被动询价”转向“主动预判与规划”。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047461830" alt="图片" title="图片" loading="lazy"/><br/>成本管控：从事后核算到事前规划通过系统化的价格趋势分析与采购批量优化模型，企业针对核心物料的采购成本实现了平均约6.2%的降幅，预计年度可节约采购费用超过1800万元。供应商管理：从主观印象到客观量化系统根据历史合作数据，自动从交货准时率、质量合格率、价格稳定性、服务响应速度等多个维度对供应商进行量化评分与动态排名。运行半年后，基于数据的评估机制使核心优质供应商的留存率提升了35%，因供应商问题导致的交货延迟率从8.3%显著降低至1.5%。在上个月进行的一项核心零部件新供应商引入项目中，系统直接推荐了综合评分前列的3家备选企业。经实地审核与谈判，企业顺利签约，采购成本低于市场均价4%，同时有效控制了合作风险。跨部门协同：从小时级到分钟级响应现在，当生产部门提出紧急物料需求时，可在系统中直接查询：“XX型号零部件的当前库存、在途订单量及供应商最快交付周期是多少？”系统实时综合库存、采购在途及供应商产能数据，即刻生成准确答复。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047461831" alt="图片" title="图片" loading="lazy"/><br/>“过去，采购部门常被简单视为成本中心。如今，我们可以用切实的数据证明，采购是能够直接创造利润、保障供应链稳定的价值部门。”李经理在年度经营会议上总结道。在近期一次大型招标项目中，采购部依托系统的深度分析，精准识别并引入了综合性价比更具优势的合作伙伴，不仅在成本控制上取得了成效，也间接增强了终端产品的市场竞争力。<br/>对于制造企业而言，采购是供应链管理的核心环节，也是成本控制的关键节点。本次实践的价值，不在于技术的复杂程度，而在于将企业内部长期沉睡的数据资产激活，转化为可持续的、可执行的决策依据，驱动采购职能从被动执行向主动战略规划转型。正如李经理所感：“采购工作的本质，绝非简单的‘购买行为’。它应是通过数据智能，打通供应链上下游，成为驱动企业降本增效、保障运营韧性的核心引擎——这才是现代企业采购职能应当扮演的战略角色。”</p>]]></description></item><item>    <title><![CDATA[Joomla! 6正式发布 joomlachina ]]></title>    <link>https://segmentfault.com/a/1190000047461850</link>    <guid>https://segmentfault.com/a/1190000047461850</guid>    <pubDate>2025-12-09 17:06:07</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>Joomla官方于2025-10-14日正式发布Joomla6.0（代号：Kuimarisha）.这是Joomla项目团队两年多辛勤耕耘的结晶。作为中文社区的一员，我们自豪地宣布：Joomla 6中文语言包已经同步制作中，助力您的网站迈向更高水平！</p><h2>核心升级亮点</h2><p>Joomla 6 是一个全新的大版本。在该版本中带来了大量新功能、安全性和代码改进，并随着这些改进提升了速度。下面我们列举一下主要的特点，更加详情说明可以访问GitHub changes页面查看。</p><h3>全自动安全更新，一键守护网站安全</h3><ul><li>首次引入自动核心更新系统，开启后系统将自动完成漏洞修复与功能迭代</li><li>兼容TUF安全协议，确保更新过程零风险</li><li>彻底告别手动更新的繁琐操作</li></ul><h3>视觉改变：Cassiopeia模板全面进化</h3><ul><li>新增16组预设配色方案​ + 自定义字体库</li><li>响应式网格系统升级，移动端加载速度提升40%</li><li>集成CSS过渡动画，页面切换流畅度媲美专业SPA应用</li></ul><h3>内容管理革新</h3><ul><li>双新增字段类型：</li><li>备注字段：可在文章/表单任意位置插入灰色备注提示</li><li>数字字段：支持货币格式/千位分隔符等专业展示</li><li>版本控制强化：首次实现自定义字段历史回溯功能</li></ul><h3>开发者友好升级</h3><ul><li>TinyMCE 8编辑器：新增表格合并、代码高亮等专业功能</li><li>语言缓存优化：多语言站点加载速度提升3倍</li><li><p>REST API增强：原生支持OAuth2认证</p><h3>平滑过渡保障</h3></li><li>向后兼容插件：确保95%以上现有扩展无缝运行</li><li>渐进式升级策略：推荐先升级至5.4（已发布桥梁版），再一键迁移至6.0</li><li><p>本地化完善：简体中文语言包同步更新，支持GBK/UTF-8双编码</p><h3>如何升级</h3><p>如果你的站点核心是Joomla5,请在后台升级到最新的Joomla5.4(这是joomla6的桥梁衔接版本)，升级到Joomla5.4后再次点击升级到Joomla6.整个过程都可自动完成。当然任何的升级操作都是有风险的，请务必在升级前做一个全站备份。</p></li></ul><h3>是否应该升级</h3><p>目前joomla5仍然是主流版本，如果你的站点是在稳定的运行，没有任何的异常，那么不建议你升级到Joomla6.如果你是新建站点，那么可以直接上手joomla6。更多详情请访问<a href="https://link.segmentfault.com/?enc=U2iGAA3nc5LSasxMp4eEvw%3D%3D.9xttefI%2F8CH50hJXyhsAYc21kqJEucYUAIrzSb3BkC8%3D" rel="nofollow" target="_blank">https://www.joomlachina.cn</a></p>]]></description></item><item>    <title><![CDATA[企业级CRM管理软件核心能力横向对比：从“功能覆盖”到“场景适配”的专业解析 晨曦钥匙扣 ]]></title>    <link>https://segmentfault.com/a/1190000047461880</link>    <guid>https://segmentfault.com/a/1190000047461880</guid>    <pubDate>2025-12-09 17:05:10</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>企业级CRM管理软件核心能力横向对比：从“功能覆盖”到“场景适配”的专业解析</h2><p>在数字化转型浪潮中，企业选择CRM/ERP等管理软件的核心痛点已从“功能有无”转向“是否匹配业务场景”。本文基于<strong>超兔一体云、金蝶（含云·星辰）、用友、Salesforce、Microsoft CRM、HubSpot CRM、Zoho CRM、悟空CRM</strong>等8款主流产品的公开能力素材，围绕<strong>自动化流程</strong> <strong>、智能分析/AI推荐、移动端/小程序支持、权限与数据安全、可定制字段/流程、集成第三方应用</strong>六大核心维度展开横向对比，结合“实现逻辑-优势场景-适用企业”三层分析，为不同类型企业提供决策参考。</p><h3>一、自动化流程：从“减少人工”到“场景适配”的效率革命</h3><p>自动化流程的核心价值是<strong>通过规则引擎替代重复性操作</strong>，降低错误率并释放人力。各产品的差异集中在“流程覆盖广度”“配置门槛”“行业适配性”三方面：</p><h4>1. 核心能力对比</h4><table><thead><tr><th><strong>品牌</strong></th><th><strong>自动化流程</strong> <strong>核心能力</strong></th><th><strong>实现逻辑</strong></th><th><strong>优势场景</strong></th></tr></thead><tbody><tr><td><strong>超兔一体云</strong></td><td>自然语言AI生成工作流；订单-采购-锁库-直发全链路自动化；应收-开票-回款三角联动</td><td>基于“数据动作触发”的规则引擎，支持销售节点（如跟进完成）自动更新客户状态、创建待办</td><td>成长型企业的<strong>销售全流程自动化</strong>（低门槛配置）</td></tr><tr><td><strong>金蝶（含云·星辰）</strong></td><td>3步智能结账（凭证审核-对账-结账）；AI发票识别生成凭证（准确率99.8%）；电商订单自动同步应收</td><td>压缩传统财务流程至“小白友好”步骤，通过API对接电商平台实现订单→凭证自动转换</td><td>中小企业的<strong>财务-业务一体化</strong>（敏捷效率）</td></tr><tr><td><strong>用友</strong></td><td>AI代理实现业务模块协同；复杂流程规范化管控（如国企审批流）</td><td>依托大型ERP架构，通过“AI+规则引擎”实现跨模块（供应链-财务-HR）协同</td><td>大型企业的<strong>合规流程管控</strong>（复杂组织架构）</td></tr><tr><td><strong>Salesforce</strong></td><td>Flow流程引擎（拖拽式配置）；Apex代码支持复杂跨部门协作；线索-商机-订单全链路自动化</td><td>低代码（Flow）+ 代码（Apex）双模式，覆盖从“简单审批”到“跨国协作”的全场景</td><td>全球化企业的<strong>复杂流程定制</strong>（技术支持要求高）</td></tr><tr><td><strong>HubSpot</strong> <strong>CRM</strong></td><td>营销-销售-服务全流程自动化；AI生成内容并优化工作流（节省30%创作时间）</td><td>基于“全渠道获客（SEO/社媒）→ 销售管道可视化→ 工单自动分配”的闭环规则</td><td>营销驱动型企业的<strong>获客-转化自动化</strong></td></tr></tbody></table><h4>2. 关键结论</h4><ul><li><strong>中小企业优先选金蝶/超兔</strong>：金蝶的“3步结账”解决财务痛点，超兔的“自然语言生成工作流”降低配置门槛；</li><li><strong>大型企业选用友/Salesforce</strong>：用友的“AI代理+合规管控”适配国企复杂流程，Salesforce的“Flow+Apex”支持跨国协作；</li><li><strong>营销驱动型企业选HubSpot</strong>：全渠道获客与AI内容生成完美匹配B2B/B2C的营销转化需求。</li></ul><h3>二、智能分析/AI推荐：从“数据统计”到“决策赋能”的认知升级</h3><p>智能分析的核心是<strong>将数据转化为可行动的洞察</strong>，各产品的差异集中在“AI能力深度”“数据覆盖广度”“BI集成度”三方面：</p><h4>1. 核心能力对比</h4><table><thead><tr><th><strong>品牌</strong></th><th><strong>智能分析/AI核心能力</strong></th><th><strong>实现逻辑</strong></th><th><strong>优势场景</strong></th></tr></thead><tbody><tr><td><strong>超兔一体云</strong></td><td>AI待办（基于行动记录自动创建跟单任务）；AI日报（一键生成结构化销售日报）；多表聚合分析</td><td>基于“销售行动数据”的行为分析，通过自然语言处理（NLP）生成任务与报告</td><td>销售团队的<strong>跟单效率提升</strong>（减少人工整理）</td></tr><tr><td><strong>金蝶（含云·星辰）</strong></td><td>“小星辰”AI助手（发票识别/流水匹配/税务预警）；100+智能报表模板（利润表/库存周转率）</td><td>融合“财务小白视角”的规则引擎，通过实时数据同步生成可视化看板</td><td>中小企业的<strong>经营状况实时监控</strong>（零BI基础）</td></tr><tr><td><strong>Salesforce</strong></td><td>Einstein AI（线索评分/销售预测/客户流失预警）；多维度报表自定义与实时可视化</td><td>基于“客户全生命周期数据”的机器学习模型，覆盖从“线索挖掘”到“留存”的全链路</td><td>大型企业的<strong>精准销售预测</strong>（高数据复杂度）</td></tr><tr><td><strong>Microsoft CRM</strong></td><td>Power BI无缝集成；AI深度挖掘客户数据；智能预测模型</td><td>依托微软生态，通过“CRM数据+Power BI”实现“数据采集-分析-决策”闭环</td><td>微软生态企业的<strong>数据驱动决策</strong>（协同办公）</td></tr><tr><td><strong>HubSpot CRM</strong></td><td>AI内容生成（节省30%创作时间）；GDPR/CCPA合规工具；实时营销转化率追踪</td><td>基于“全渠道客户行为数据”的NLP模型，支持个性化内容推荐与合规风险预警</td><td>跨境企业的<strong>营销内容自动化+合规</strong></td></tr></tbody></table><h4>2. 关键结论</h4><ul><li><strong>销售团队优先选超兔</strong>：AI待办与日报直接解决“跟单遗漏”“日报繁琐”的痛点；</li><li><strong>财务/运营优先选金蝶</strong>：“小星辰”助手与100+报表模板覆盖中小企业核心数据需求；</li><li><strong>大型企业选Salesforce/Microsoft</strong>：Salesforce的Einstein聚焦销售预测，Microsoft的Power BI适合复杂数据建模；</li><li><strong>跨境企业选HubSpot</strong>：AI内容生成与国际合规工具完美匹配全球化营销需求。</li></ul><h3>三、移动端/小程序支持：从“多端覆盖”到“体验优化”的用户视角</h3><p>移动端的核心价值是<strong>让业务操作“随时随地”</strong> ，各产品的差异集中在“功能完整性”“操作便捷性”“生态协同性”三方面：</p><h4>1. 核心能力对比</h4><table><thead><tr><th><strong>品牌</strong></th><th><strong>移动端/小程序核心能力</strong></th><th><strong>实现逻辑</strong></th><th><strong>优势场景</strong></th></tr></thead><tbody><tr><td><strong>超兔一体云</strong></td><td>App聚焦销售全流程（客户管理/快目标/快行动）；语音输入/拍照上传；实时同步</td><td>采用“销售场景优先”的UI设计，将核心功能（如客户新建/行动记录）压缩至3步内</td><td>销售外勤的<strong>移动办公</strong>（便捷操作）</td></tr><tr><td><strong>金蝶（含云·星辰）</strong></td><td>移动端审批（报销/采购）；仓库扫码出库；20家门店数据当日汇总</td><td>基于“小白视角”的功能布局，核心操作（如审批）不超过3次点击</td><td>中小企业的<strong>异地协同</strong>（如门店/仓库）</td></tr><tr><td><strong>Salesforce</strong></td><td>全功能移动端（客户/商机/订单管理）；离线访问与修改（上线自动同步）</td><td>采用“多设备适配”架构，支持iOS/Android全功能覆盖</td><td>全球化团队的<strong>跨区域协作</strong>（如海外销售）</td></tr><tr><td><strong>Microsoft CRM</strong></td><td>与Teams联动（实时消息/语音/视频）；移动端数据分析（Power BI嵌入）</td><td>依托微软生态，将CRM功能与办公协同工具深度整合</td><td>微软生态企业的<strong>办公-业务联动</strong></td></tr></tbody></table><h4>2. 关键结论</h4><ul><li><strong>销售外勤选超兔</strong>：App聚焦销售场景，语音/拍照功能提升操作效率；</li><li><strong>中小企业异地协同选金蝶</strong>：3步核心操作+门店数据当日汇总解决“异地管理”痛点；</li><li><strong>全球化团队选Salesforce</strong>：全功能+离线支持适配海外销售的“无网络场景”；</li><li><strong>微软生态企业选Microsoft CRM</strong>：Teams联动实现“办公-业务”无缝切换。</li></ul><h3>四、权限与数据安全：从“防泄露”到“合规适配”的底线守护</h3><p>权限与数据安全的核心是<strong>保障“数据访问的合理性”与“存储的可靠性”</strong> ，各产品的差异集中在“权限粒度”“合规覆盖”“存储可靠性”三方面：</p><h4>1. 核心能力对比</h4><table><thead><tr><th><strong>品牌</strong></th><th><strong>权限与数据安全核心能力</strong></th><th><strong>实现逻辑</strong></th><th><strong>优势场景</strong></th></tr></thead><tbody><tr><td><strong>超兔一体云</strong></td><td>全局自动权限（上级管下级/同级隔离/助理跟随）；华为双指挥系统（行政+业务）</td><td>基于“角色-层级-业务场景”的三元权限模型，支持“销售经理看下属客户”等场景</td><td>成长型企业的<strong>简单权限管控</strong>（低配置成本）</td></tr><tr><td><strong>金蝶（含云·星辰）</strong></td><td>SSL 256位加密；阿里云存储（灾备99.99%）；细粒度权限（部门/角色数据隔离）</td><td>采用“公有云+加密”架构，满足中小企业的“基础安全需求”</td><td>中小企业的<strong>数据安全</strong>（如客户隐私）</td></tr><tr><td><strong>用友</strong></td><td>大型ERP权限分级（国企/机关单位合规）；数据备份（本地+云端）</td><td>依托“传统ERP”架构，支持“按岗位-部门-企业”三级权限</td><td>国企/机关单位的<strong>合规安全</strong>（如涉密数据）</td></tr><tr><td><strong>Salesforce</strong></td><td>细粒度权限（字段级控制）；GDPR/CCPA合规；多语言支持</td><td>基于“国际合规”设计，支持跨国企业的“区域数据隔离”（如欧盟客户数据本地化）</td><td>跨境企业的<strong>国际合规</strong>（如 GDPR 要求）</td></tr></tbody></table><h4>2. 关键结论</h4><ul><li><strong>成长型企业选超兔/金蝶</strong>：超兔的“双指挥系统”适配简单组织，金蝶的“阿里云灾备”保障基础安全；</li><li><strong>国企/机关选用友</strong>：大型ERP权限分级满足“涉密数据”的合规要求；</li><li><strong>跨境企业选Salesforce</strong>：GDPR/CCPA合规+字段级权限支持“全球数据管理”。</li></ul><h3>五、可定制字段/流程：从“被动适配”到“主动贴合”的柔性支撑</h3><p>可定制的核心价值是<strong>让软件适应业务，而非业务适应软件</strong>，各产品的差异集中在“定制灵活性”“配置门槛”“行业适配性”三方面：</p><h4>1. 核心能力对比</h4><table><thead><tr><th><strong>品牌</strong></th><th><strong>可定制核心能力</strong></th><th><strong>实现逻辑</strong></th><th><strong>优势场景</strong></th></tr></thead><tbody><tr><td><strong>超兔一体云</strong></td><td>自然语言AI生成工作流；自定义字段/模块/工作台；“搭积木”式UI定制</td><td>基于“低代码+自然语言”的配置工具，支持非技术人员快速搭建流程</td><td>成长型企业的<strong>快速定制</strong>（如新增业务模块）</td></tr><tr><td><strong>金蝶（含云·星辰）</strong></td><td>自定义凭证模板/报表格式/审批流程；“财务小白视角”界面设计</td><td>采用“模板化+拖拽式”配置，支持中小企业“零代码”调整</td><td>中小企业的<strong>财务个性化</strong>（如自定义报表）</td></tr><tr><td><strong>用友</strong></td><td>高度定制化配置工具（字段/流程/UI）；适配复杂组织架构（如集团化企业）</td><td>依托“ERP定制平台”，支持“按业务场景”调整（如制造企业的“生产流程”）</td><td>大型企业的<strong>流程改造</strong>（如集团化管控）</td></tr><tr><td><strong>Salesforce</strong></td><td>Canvas画布自定义UI；Flow+Apex支持复杂流程（如跨部门审批）</td><td>低代码（Flow）+ 代码（Apex）双模式，覆盖“简单到复杂”的全场景定制</td><td>技术型企业的<strong>深度定制</strong>（如自研模块）</td></tr></tbody></table><h4>2. 关键结论</h4><ul><li><strong>非技术企业选超兔/金蝶</strong>：超兔的“自然语言生成”、金蝶的“模板化拖拽”降低配置门槛；</li><li><strong>大型企业选用友</strong>：高度定制化工具适配“集团化”的复杂流程；</li><li><strong>技术型企业选Salesforce</strong>：Flow+Apex支持“自研模块”的深度整合。</li></ul><h3>六、集成第三方应用：从“数据打通”到“生态协同”的价值延伸</h3><p>集成的核心价值是<strong>打破信息孤岛</strong>，各产品的差异集中在“集成广度”“深度（实时性）”“生态适配性”三方面：</p><h4>1. 核心能力对比</h4><table><thead><tr><th><strong>品牌</strong></th><th><strong>集成核心能力</strong></th><th><strong>实现逻辑</strong></th><th><strong>优势场景</strong></th></tr></thead><tbody><tr><td><strong>超兔一体云</strong></td><td>RPA对接电商（淘宝/京东）/国税开票；API对接ERP/WMS</td><td>通过“RPA机器人”解决“非标准化系统”对接（如电商订单），API解决“标准化系统”（如ERP）</td><td>工业企业的<strong>业务自动化</strong></td></tr><tr><td><strong>金蝶（含云·星辰）</strong></td><td>电商平台（淘宝/京东）实时对接；进销存-财务同步（1.2万笔订单零错账）</td><td>采用“API+实时同步”架构，支持销售订单→应收凭证自动生成</td><td>零售/电商企业的<strong>业务-财务协同</strong></td></tr><tr><td><strong>用友</strong></td><td>供应链/HR系统深度集成；政务平台对接（国企/机关）</td><td>依托“ERP生态”，支持与“现有IT架构”的兼容（如国企的“政务系统”）</td><td>国企的<strong>现有系统兼容</strong>（如 legacy 系统）</td></tr><tr><td><strong>Salesforce</strong></td><td>1000+第三方应用（微信/钉钉/企业微信）；自研生态（Zoho邮箱/客服）</td><td>基于“AppExchange”市场，支持“一键安装”常用应用</td><td>全球化企业的<strong>生态覆盖</strong>（如海外工具）</td></tr></tbody></table><h4>2. 关键结论</h4><ul><li><strong>电商企业选超兔/金蝶</strong>：RPA/API对接电商平台解决“订单同步”痛点；</li><li><strong>国企选用友</strong>：供应链/政务平台集成适配“现有IT架构”；</li><li><strong>全球化企业选Salesforce</strong>：AppExchange市场覆盖“海外常用工具”。</li></ul><h3>七、综合推荐：基于企业类型的精准匹配</h3><p>结合上述分析，我们将各品牌的<strong>核心优势</strong>与<strong>适用企业</strong>总结如下：</p><table><thead><tr><th><strong>企业类型</strong></th><th><strong>核心需求</strong></th><th><strong>推荐品牌</strong></th></tr></thead><tbody><tr><td>成长型销售企业</td><td>销售全流程自动化、低门槛定制</td><td>超兔一体云</td></tr><tr><td>中小企业（财务为主）</td><td>财务-业务一体化、敏捷效率</td><td>金蝶（云·星辰）</td></tr><tr><td>大型国企/机关单位</td><td>合规管控、复杂流程改造</td><td>用友</td></tr><tr><td>全球化/技术型企业</td><td>复杂流程定制、国际合规</td><td>Salesforce</td></tr><tr><td>营销驱动型企业</td><td>获客-转化自动化、AI内容生成</td><td>HubSpot CRM</td></tr><tr><td>电商/零售企业</td><td>订单同步、移动端协同</td><td>超兔一体云/金蝶（云·星辰）</td></tr></tbody></table><h3>结语</h3><p>企业选择管理软件的本质是<strong>选择“匹配自身业务场景的能力”</strong> 。没有“最好的产品”，只有“最适合的产品”——中小企业需优先关注“低门槛、高敏捷”，大型企业需聚焦“合规性、定制化”，跨境企业需重视“国际合规、全球化支持”。通过本文的维度拆解与场景适配分析，企业可快速定位核心需求，找到最匹配的数字化工具。</p>]]></description></item><item>    <title><![CDATA[AgentScope Java v1.0 发布，让 Java 开发者轻松构建企业级 Agentic ]]></title>    <link>https://segmentfault.com/a/1190000047461905</link>    <guid>https://segmentfault.com/a/1190000047461905</guid>    <pubDate>2025-12-09 17:04:09</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>作者：亦盏</p><h2>AgentScope 简介</h2><p>AgentScope 是阿里巴巴推出的一款以开发者为核心，专注于智能体开发的开源框架，是继 ModelScope（魔搭社区）后在 Agent 层的战略产品。它的核心目标是解决智能体在构建、运行和管理中的难题，提供一套覆盖“开发、部署、调优”全生命周期的生产级解决方案，让智能体应用的开发更简单、运行更稳定、效果更卓越。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047461907" alt="image" title="image"/></p><p><strong>近期 AgentScope 迎来了 12 月版本的重大更新</strong>，这是一次面向生产级智能体应用的基建大升级，让智能体从“实验室原型”走向“业务落地”。<strong>本次更新围绕三大核心主线</strong>：开箱即用的智能体，即刻赋能多种真实场景；基建增强让智能体“变聪明”的底层能力全面升级；运行时 × 多语言 × 前端，三位一体交付生产就绪的智能体。</p><p>一直以来，Java 语言在金融、政务、电商等领域开发中都占着主导地位，开发者社区对于 AgentScope Java 版本的呼声也非常高，AgentScope 本次也重磅发布了 Java 的 1.0 版本，拥抱企业开发主流技术栈。</p><h2>AgentScope Java 1.0 重磅发布</h2><p>今天，我们很高兴地宣布 AgentScope Java 1.0 版本正式发布了，面向 Java 开发者提供企业级 Agentic 应用构建的能力。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047461908" alt="image" title="image" loading="lazy"/></p><p><strong>首先在开发范式上，</strong> AgentScope 采用领先的 ReAct（推理-行动）模式，支持高效的工具调用，并允许开发者对 Agent 执行过程进行实时介入，实现了自主性与可控性的完美平衡。</p><p><strong>其次，它提供了开箱即用的企业级能力。</strong> 框架提供安全沙箱保障代码执行安全，通过精细的上下文工程优化模型交互效果。作为 Java 框架，它易于集成到现有企业技术栈中，并具备高性能架构，确保生产环境的稳定可靠。</p><p><strong>最后，它拥有完善的开发与优化生态。</strong> 提供从开发态可视化调试、A/B 测试到评估与强化学习的完整工具链，构成了 Agent 开发、部署、调优的闭环，助力持续提升 Agent 效果。</p><h3>领先的开发范式</h3><p>在构建复杂的 AI Agent 应用时，开发者普遍面临众多挑战：僵化的工作流难以适应多变的任务、运行中的Agent 无法实时干预、海量工具导致管理混乱与性能瓶颈、模型输出格式不稳定等等。如何系统性地解决这些痛点，是提升开发效率和应用稳定性的关键。AgentScope 采用领先的 ReAct 范式，赋予 LLM 自主规划能力，并提供实时介入控制、高效的工具调用体系。此外，它还内置任务规划、结构化输出等强大工具，支持高效开发生产级应用。</p><ol><li><p><strong>领先的 ReAct 范式</strong>，赋予Agent自主规划能力。</p><ul><li>工作流（Workflow）模式：在这种模式下，LLM 与工具（Tool）的协作路径由开发者预先定义，开发者对系统的执行流程有完全的控制权，这保证了任务执行的稳定性和确定性。但是他的缺点是架构僵化，当业务逻辑变得复杂时，维护成本激增，而且无法享受 LLM 持续进化所带来的能力提升。</li><li>ReAct 范式：与 Workflow 相反，ReAct 赋予了 LLM 自主控制权。LLM 扮演大脑的角色，能够动态地进行推理（Reasoning）和规划，自主决定何时、如何调用工具来执行操作（Action），从而主导任务的完成。随着 LLM 在理解、规划和工具使用等关键能力上日趋成熟，这种高度自主的 Agent 架构已成为复杂应用场景下的首选。</li></ul></li><li><p><strong>实时的介入控制</strong>，让 Agent 运行全程可控。传统 Agent 一旦启动便无法安全干预，AgentScope 基于异步架构，实现了强大的实时介入机制。</p><ul><li>安全中断：支持随时暂停 Agent，并自动保存其上下文和工具状态，确保任务能无缝恢复。</li><li>实时打断：当任务偏离预期或耗时过长时，用户可立即终止，避免资源浪费。</li><li>灵活定制：开发者可以自定义中断处理逻辑，实现更精细化的管理。</li></ul></li><li><p><strong>高效的工具调用</strong>，随着可调用工具数量的激增，Agent 面临着工具管理复杂、执行效率低、上下文紧张的问题。AgentScope 构建了一套高效、可靠的工具管理体系。</p><ul><li>工具注册：提供标准化的注册接口，支持自动提取工具的 JSON Schema，提供参数预设和工具函数后处理接口，降低集成门槛。</li><li>便捷管理：AgentScope 通过结构化的组织方式和动态控制机制来高效支持工具的使用。工具组（Tool Group）按照功能对工具进行分类（例如浏览器、地图服务等），使 Agent 能够根据当前任务按需激活相关工具，从而有效缓解上下文窗口的压力；元工具（Meta-Tool）允许 Agent 在运行时动态启用或停用整个工具组，实现更加智能化的工具管理。</li><li>高效执行：采用统一接口处理所有工具调用，无论同步、异步或流式输出，在 AgentScope 中将被统一为异步流式返回，降低工具函数返回的处理复杂度。同时支持工具的并行调用，大幅提升运行效率。</li></ul></li><li><p><strong>强大的内置工具</strong>：AgentScope 内置了许多开箱即用的强大工具，开箱即用，加速生产级应用开发。</p><ul><li>PlanNoteBook 工具提供了强大的任务规划与执行能力。支持开发者手动定义结构化计划，也允许 Agent 在运行时自主创建和管理计划。通过 PlanNotebook 提供完整的计划管理功能，包括创建、修改、暂停、恢复和切换多个计划，引导 Agent 有序执行复杂计划。</li><li>结构化输出：传统的做法是在 Prompt 中写格式要求，要求模型“请按照以下 JSON 格式输出”，不断尝试和优化提示词，经常需要在外部代码中做二次解析和格式校验。AgentScope 通过内置工具确保 LLM 的输出严格遵循预定义的 JSON 格式，彻底告别繁琐的提示词调试和二次解析。</li></ul></li></ol><h3>企业级能力</h3><p>AgentScope 提供了安全工具沙箱和上下文工程能力，解决了安全与效果的核心痛点，确保 Agent 的输出效果满足生产标准。依托于 Java 在企业应用开发市场的强大生态，通过标准的 A2A 和 MCP 协议，提供了灵活的集成与被集成方案，这使得 Agent 既能作为独立服务嵌入现有系统，也能成为连接和调度其他服务的智能中枢。开发者无需关心底层集成细节，专注于业务逻辑即可快速构建生产级 Agent 应用。最后，依托于 AgentScope Runtime 提供的能力，支持将 Agent 一键部署到阿里云百炼和<a href="https://link.segmentfault.com/?enc=e86CsTZglGMyzGUCWeOOKg%3D%3D.5gcz%2FgJSGUMRHdtcHTtAEDRpOhR44Ujm3lmewK0uLjdvjC8O26ym1G6%2F88DB9OU9zZ9PU2mXy3V4HHy2%2FXfFywhvosg60tcjMVzJhk90sTefSXK%2FuwP3dxrDvR0HOoNfNmbGh0xzY9OLnSH32fYr8g%3D%3D" rel="nofollow" target="_blank">函数计算</a>平台，为您的 Agent 应用提供商业级的产品化保障。</p><ol><li><p><strong>安全沙箱</strong></p><ul><li>Agent 在执行工具调用或自动化任务时，可能访问敏感资源或引发不可控行为，需要沙箱提供安全隔离环境。AgentScope Runtime Sandbox 支持开发者将自定义工具部署在高度隔离的受控环境中安全运行，防止对系统造成意外影响或安全风险。</li><li>内置多种开箱即用的沙箱：GUI 沙箱提供完整桌面环境，支持鼠标、键盘和屏幕操作；文件系统沙箱实现隔离的文件读写与管理；移动端沙箱基于 Android 模拟器，支持点击、滑动、输入和截屏等真实移动交互。兼顾了安全性、灵活性与多平台覆盖，全面支撑工具执行、浏览器自动化、训练评测等复杂场景。</li></ul></li><li><p><strong>上下文工程</strong></p><ul><li>RAG：内置基于 Embedding 的标准实现，支持企业在面对复杂的多元业务数据情况下，私有化部署自有的知识库体系，实现对数据的完全自主可控；集成阿里云百炼企业级知识库，借助商业化产品获得更强大的检索与重排序能力。</li><li>Memory：AgentScope 定义了对短期、长期记忆的抽象，支持语义搜索与多租户隔离，提供自动管理、Agent 主动调用、混合模式三种控制方式。通过 ReMe 项目提供了记忆的最佳实践方案，让 Agent 能够理解用户偏好、提升任务表现和更聪明地使用工具，显著提升业务场景下的智能问答准确性与上下文连贯性，实现越用越好用。</li></ul></li><li><p><strong>易于集成</strong></p><ul><li>MCP 集成：基于 AgentScope Java 开源生态，现有的 HTTP 业务系统无需改动业务逻辑代码，通过简单配置即可被 Agent 无缝集成，快速成为 Agent 可调用的“手脚”，极大地扩展了 Agent 的能力边界。</li><li>A2A 集成：复杂的任务通常需要多个 Agent 协同工作。AgentScope Java 支持将描述 Agent 自身能力的 Agent Card 注册到 Nacos 等服务中心，调用方 Agent 只需连接 Nacos，即可自动发现并调用其他 Agent 的能力。这使得分布式 Multi Agent 系统的构建与协作变得像调用普通微服务一样简单。</li></ul></li><li><p><strong>高性能</strong></p><ul><li>轻量化：核心库仅依赖 Reactor Core、Jackson 和 SLF4J、RAG、长期记忆等能力通过可选扩展按需引入，目前基于厂商原生 SDK 实现模型调用，未来将基于 OkHttp 与 Jackson 原生实现，进一步精简内核依赖。</li><li>异步化：针对 AI 应用交互具有持续时间长、多轮次上下文依赖的特点，支持引入消息队列 RocketMQ 作为异步消息中枢，实现任务解耦与非阻塞调用，提升 Agent 的吞吐能力和响应速度。</li><li>Native 优化：联合 JVM 团队适配了 GraalVM 和 Leyden，将 Java 应用启动速度提升 3 到 10 倍，实现了 Agent 200ms 内冷启动，为 AI 应用 Serverless 毫秒级弹性奠定基础。</li></ul></li></ol><h3>强大的生态</h3><p>AI 原生应用架构正在深刻重塑软件工程范式，传统软件的确定性被 Agent 的非确定性所取代，其最终效果由模型、数据和上下文共同决定，这使得传统的“代码测试”演变为复杂的“效果评估”。由于任何微小的变更都可能引发效果的剧烈波动，A/B 测试已从过去的优化选项，转变为保障版本质量的核心发布流程。软件工程重心也必须从以代码为中心转向以数据为中心，成功的关键在于构建一个高效的数据飞轮。</p><p>面对这一挑战，AgentScope 提供了 Studio、RM Gallery 和 Trinity-RFT 等一系列生态工具，结合 Higress AI 网关和可观测系统，您可以快速实践 AI 原生应用数据飞轮。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047461909" alt="image" title="image" loading="lazy"/></p><p>在 Agent 开发阶段，我们采用 AgentScope Studio 可视化平台对 Agent 进行实时调试与观测，显著提升了开发效率，它深度集成了 OpenTelemetry 和 LoongSuite，实现了端到端的全链路追踪。</p><p>在部署架构中，Higress 作为统一的流量入口网关，负责将外部请求路由至相应的 Agent。Agent 则通过 Higress 内置的 AI 网关能力与 LLM 通信。借助 Higress 强大的插件体系，我们可以对流量进行灵活打标，从而实现对 Agent 和 LLM 的精准路由控制。</p><p>在发布后的 A/B 测试阶段，Higress 网关能根据请求内容（如用户地理位置、业务线、付费状态等）将流量分配到不同实验组。例如，将付费用户导向 Agent 的 A 版本，免费用户导向 B 版本，以进行效果对比。同时流量的分组标签会借助可观测在整个调用链路中透传。这样，AI 网关便能根据此标签将请求路由到对应的 LLM 版本。这一机制让我们在无需修改业务代码的情况下，实现了 Agent 与 LLM 的协同 A/B 测试。</p><p>在此过程中，全链路产生的所有数据——从用户输入、Agent 的提示词（Prompt），到模型的输出、时延与成本都会上报到可观测系统中。基于 RM Gallery 的奖励函数评估 Agent 在各实验组的业务表现，并筛选沉淀高质量的数据集。随后，我们的训练框架 Trinity-RFT 会运用这些数据集和奖励模型，通过强化学习对模型进行持续迭代，不断提升其解决业务问题的能力。</p><p>最终，这形成了一个以数据为驱动的自我优化闭环。系统通过持续采集线上真实数据、分析评估效果并转化为高质量的训练数据，不断增强模型能力，构筑起坚实的技术竞争壁垒。</p><h2>AgentScope Java Roadmap</h2><ul><li><strong>上下文工程持续优化：</strong> Agent 效果不够好的原因，要么是模型能力不够强，要么是提供的上下文不准确，上下文工程是工程能力的核心。AgentScope Java 会持续深耕上下文工程，致力于构建一个更加高效、低延迟的上下文管理系统。未来开发者不需要关心上下文的技术细节，只需要专注于定义好 Agent 的功能。</li><li><strong>实时全模态支持：</strong> 大模型的边界正在从文本扩展至图像、语音乃至视频，能够与物理世界互动的具身智能产品开始进入我们的生活，AgentScope Java 会构建对实时全模态的深度支持，帮助开发者更好地开发多模态的应用，未来 Agent 不只是文本输入，完全可以通过“眼睛”、“耳朵”和“手”更好地服务用户。</li><li><strong>评估与强化学习优化：</strong> 我们已经提供了观测、评估、优化的整体解决方案，但目前评估和强化学习的门槛仍旧比较高。后续会不断通过生态集成降低门槛，开发者只需编写业务逻辑与设计奖励函数，即可借助 AgentScope 的生态工具链，让 Agent 在与用户或环境的交互中不断进化，实现真正的自我成长与迭代。</li></ul><p>AgentScope Java 版 Github 地址：<a href="https://link.segmentfault.com/?enc=h0kXpcaJhddsWaIyoDK%2FBg%3D%3D.RJQQ0u2GmIMdfWqh%2BHMoBpOgCU2V2H%2BTd5oeH06vWf0kUqVC0ejXjbrtzJAfCDWg8stdvJJCnc9ScCy5UBA5tg%3D%3D" rel="nofollow" target="_blank">https://github.com/agentscope-ai/agentscope-java</a> </p><p>帮助文档：<a href="https://link.segmentfault.com/?enc=Aux6DyWq8HvFBhqUp2HxjQ%3D%3D.roE6b6NnnMUz%2FNzhTlYmgNdgQBjphHU80V5TNMNm%2BiQcg5Kj5CPznkW%2BMIeFMppJ" rel="nofollow" target="_blank">https://java.agentscope.io/en/intro.html</a></p><p>如果你觉得 AgentScope Java 不错，欢迎给我们的项目 Star 并加入我们开源社区，一起构建面向未来的 Agent 体系！</p><p>AgentScope Java 和 Spring AI Alibaba 有哪些不同，请查看：《<a href="https://link.segmentfault.com/?enc=ZgCgekD6boVyRulxUIcKbw%3D%3D.wDEp61iXBRbuvP%2FO6dtHLdEVvCqlfDqxW4kA9iWDMklYu5KSdg%2BwEEUuEz3T6nF4PMFYZCTxtVOEYgtGo3tP%2Bm6kie2RrhAUNj%2BBDg5TMUV4T4mSttGv6qf3UyeQ7Dv0Zzkncv6mAQ3KXQh8GCRaJoNz%2B1PBy2%2B4LIR9fw3SYI47qq47UJUkkCcJsK%2BEYNvl" rel="nofollow" target="_blank">Spring AI Alibaba 和 AgentScope 啥区别？</a>》</p>]]></description></item><item>    <title><![CDATA[数据库AI方向探索-MCP原理解析&DB方向实战｜得物技术 得物技术 ]]></title>    <link>https://segmentfault.com/a/1190000047461922</link>    <guid>https://segmentfault.com/a/1190000047461922</guid>    <pubDate>2025-12-09 17:03:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>一、MCP设计理念</h2><p>在浅析 MCP 原理之前，有必要搞清楚两个问题：<strong>MCP 是什么？为什么会出现？</strong> 以此明晰它存在的价值和意义。</p><p>首先，MCP（Model Context Protocol，模型上下文协议）是由人工智能公司 Anthropic 主导推出的一种<strong>开放标准协议，旨在统一大型语言模型（LLM）与外部数据源、工具及服务之间的交互方式</strong>。该协议<strong>通过JSON-RPC 2.0 标准消息格式</strong>定义通信规则，使模型能像使用"万能接口"（类比 Type-C 接口）一样即插即用地连接异构资源。</p><p><img width="641" height="123" referrerpolicy="no-referrer" src="/img/bVdni6C" alt="" title=""/></p><p>图片来源：<a href="https://link.segmentfault.com/?enc=VjMzkvDFg5OiNNTz3joFfw%3D%3D.WIIbCc7oV6J%2FTwMImuC0Q1agv9hStkM%2Bqn0TBITTm4pAxY%2Fg224VYAfqTCgiPKz7" rel="nofollow" target="_blank">https://zhuanlan.zhihu.com/p/598749792</a></p><p>其架构采用<strong>客户端-服务器模式，包含三个关键组件</strong>： </p><ul><li><strong>MCP Host</strong>：运行大模型应用（如 Cursor、Cline、Cherry Studio、Claude Desktop 等），负责发起任务请求。</li><li><strong>MCP Client</strong>：集成在 Host 中的协议客户端，解析任务需求并与服务器协调资源调用。</li><li><strong>MCP Server</strong>：<strong>轻量级</strong>服务程序，动态注册与暴露本地资源（例如文件、数据库）或远程服务（如云API），处理客户端请求并返回结构化数据，同时提供安全控制，包括访问权限管理和资源隔离。</li></ul><p>简单概括为 MCP 是一种开放标准，本质是应用层协议（Protocal），跟我们熟知的 TCP/IP，HTTP 协议类似。借助它开发者可以安全地在数据源和 AI 工具之间建立双向连接。其架构概括起来就是：</p><ul><li><strong>开发者可以通过 MCP 服务器公开他们的数据；</strong></li><li><strong>AI 应用（MCP 客户端） 可以连接到 MCP 服务器，获取所需数据，LLMs 再分析投喂的数据。</strong></li></ul><p><img width="723" height="235" referrerpolicy="no-referrer" src="/img/bVdni6D" alt="" title="" loading="lazy"/></p><p>那为什么会出现呢？这就要说到<strong>RAG和Function Calling</strong> 技术了。</p><p><strong>RAG（检索增强生成）</strong> 通过检索外部知识库获取与问题相关的实时信息并将其注入模型提示词，生成更精准、时效性更强的回答。 <strong>其工作原理为</strong>：当用户发出提问时，AI 应用通过向量检索、关键词匹配等方式，从外部知识库或数据源中搜索相关信息，再把检索到的信息作为上下文提供给大模型，让大模型基于补充的信息进行回答。<strong>技术流程：</strong> 用户提问→问题向量化→向量数据库相似度检索→拼接上下文提示词→模型生成答案。</p><p><img width="723" height="315" referrerpolicy="no-referrer" src="/img/bVdni6E" alt="" title="" loading="lazy"/></p><p>图片来源：ailydoseofds</p><p>而<strong>Function Calling（函数调用）</strong> 拓展了模型执行动作的能力，解决纯文本交互的局限性，即模型解析用户意图后生成结构化指令，调用预定义外部函数或 API（如发送邮件、查询天气）。<strong>其工作原理为</strong>：当用户发出提问时，应用会将集成的函数列表作为上下文发送给大模型。<strong>大模型根据用户输入判断应调用的函数，并生成相应的调用参数。随后，应用执行该函数并将结果发送给大模型，作为补充信息供其生成最终的总结或回答。技术流程</strong>：用户指令→ 模型识别需调用的函数→ 生成参数化调用指令→ 外部系统执行→ 返回结果至模型→ 生成用户响应。</p><p><img width="640" height="266" referrerpolicy="no-referrer" src="/img/bVdni6F" alt="" title="" loading="lazy"/></p><p>图片来源：ailydoseofds</p><p>但不同的 API 需要封装成不同的方法，且参数确定后，后期变更困难，很难在不同的平台灵活复用。  而我们可以认为，MCP 是在 Function Calling 的基础上做了进一步的抽象，目的是让应用更加简单、高效、安全地对接外部资源，更好地为大模型补充上下文信息。总结起来就是，MCP 把大模型运行环境称作 MCP Client，也就是 MCP 客户端，同时，把外部函数运行环境称作 MCP Server，也就是 MCP 服务器，然后，统一 MCP 客户端和服务器的运行规范，并且要求 MCP 客户端和服务器之间，也统一按照某个既定的提示词模板进行通信。</p><p><img width="723" height="431" referrerpolicy="no-referrer" src="/img/bVdni6G" alt="" title="" loading="lazy"/></p><p><strong>MCP vs Function Calling 对比：</strong></p><p><img width="723" height="146" referrerpolicy="no-referrer" src="/img/bVdni6H" alt="" title="" loading="lazy"/></p><p>综上，RAG与Function Calling 互补，前者用于知识检索，后者用于执行操作，二者均可提升模型实用性，但目标维度不同，且存在难集成，扩展性差的问题，开发者往往需为不同模型重复实现工具调用逻辑。</p><p><strong>MCP 则是对两者的整合与标准的规范化：</strong></p><ul><li><strong>标准化接口</strong>：MCP 为 RAG 的检索源接入（如数据库、文档库）和 Function Calling 的工具调用（如 API 服务）提供统一接入规范，避免为每个工具开发定制化适配。 比如 MCP 工具的inputSchema可定义多个参数，通过required标记必传参数。大模型在解析用户提问时，会根据工具的描述和参数定义，自动解析并提供相应参数值来调用工具。这种参数化设计方式提高了工具调用的灵活性，降低了 Function Calling 的开发复杂度。</li></ul><p>&lt;!----&gt;</p><pre><code>return Tool(
    name=self.name,
    description=self.description,
    inputSchema={
        "type": "object",
        "properties": {
            "host": {"type": "string", "description": "数据库主机地址"},
            "port": {"type": "integer", "description": "数据库端口"},
            "user": {"type": "string", "description": "数据库用户名"},
            "password": {"type": "string", "description": "数据库密码"},
            "database": {"type": "string", "description": "数据库名称"}
        },
        "required": ["host", "port", "user", "password", "database"]
    }
)
</code></pre><ul><li><strong>能力扩展</strong>：</li><li><ul><li>RAG 通过 MCP 接入实时数据流（如证券行情），突破静态知识库限制；</li><li>Function Calling通过 MCP 调用异构工具（如 IoT 设备），无需依赖特定模型的支持。</li></ul></li></ul><p>&lt;!----&gt;</p><ul><li><strong>系统效率</strong>：MCP 降低开发复杂度（如开发者无需为不同模型重复实现工具调用逻辑），促进工具生态共享。</li></ul><p><img width="723" height="319" referrerpolicy="no-referrer" src="/img/bVdni6J" alt="" title="" loading="lazy"/></p><p><strong>技术演进总结</strong>：</p><ul><li>RAG → Function Calling → MCP 代表了 AI 能力的三个重要维度：从静态知识检索到动态行动执行，再到标准化生态构建，标志着 AI 从知识增强到行动扩展再到生态标准化的发展趋势。</li><li>在 AI Agent 架构中：RAG 充当知识中枢，Function Calling 为执行手段，MCP 则是连接内外的“神经枢纽”。</li><li><strong>未来意义</strong>：MCP 的开放性将加速工具互操作性，推动复杂任务（如多 Agent 协作）的规模化落地，成为 AI 基础设施的关键组件。</li></ul><h2>二、MCP 架构详解</h2><p>了解 MCP 存在的价值后，我们还需要定位 MCP 在整个 AI 体系中所处的位置，如以 Agent 为例：</p><p><img width="723" height="115" referrerpolicy="no-referrer" src="/img/bVdni6L" alt="" title="" loading="lazy"/></p><p>了解完其在生态中所处的位置后，本节将结合 Python 版 SDK 源码和开源 MCP for DB 项目解读如何运用 MCP 以此了解其架构原理及使用方法。MCP Python SDK 提供了一个分层架构，通过多种传输协议将 LLM 应用程序连接到 MCP 服务器，同时具有高级和低级开发 API。</p><p>参考项目地址：<a href="https://link.segmentfault.com/?enc=5P8Z55GUHdUo4jQjGA9KGw%3D%3D.7GJfhvs8naG3xzlgdPymr6TI3ECFRgK%2FFLr%2BAeVC1erZfhy%2FfcxnArCDDDHARNCS" rel="nofollow" target="_blank">https://github.com/Eliot-Shen/MCP-DB-GPT</a></p><p>Python SDK：<a href="https://link.segmentfault.com/?enc=Gtz9aPezie4uX4WvL5WuYg%3D%3D.2DB7fALLLjisHGNAsf2DXIf8lthzsEDftV8hNbJaL%2Foxydyge215KwnrrSE11mdcJa95PD8oay9%2B4z0AI6An5w%3D%3D" rel="nofollow" target="_blank">https://github.com/modelcontextprotocol/python-sdk</a></p><h3>2.1MCP运行过程</h3><p>在此之前，有必要对 MCP 整体运行有个宏观上的认知，如下图所示，首先，需用户在主机上配置 MCP 服务，比如借助 VSCode 插件 Cline，根据使用的协议配置好 JSON文件即可。然后，用户输入问题，客户端让大语言模型选择 MCP 工具，大模型选择好工具后，客户端寻求用户同意，然后再请求 MCP 服务器， MCP 服务器调用工具并将工具的结果返回给客户端，客户端将模型调用结果和用户的查询发送给大语言模型，大语言模型组织答案给用户。</p><p><img width="640" height="369" referrerpolicy="no-referrer" src="/img/bVdni6N" alt="" title="" loading="lazy"/></p><p>可见，整个流程中最核心的部分就是<strong>Client 和 Server的交互</strong>，而在使用像 Cline 这种主机端软件时，整体感知如下图，Client 已经被嵌在 MCP Host 中，只需开发出对应的 MCP Server，在主机中配置好 JSON即可使用。</p><p><img width="723" height="448" referrerpolicy="no-referrer" src="/img/bVdni6O" alt="" title="" loading="lazy"/></p><p>接下来将结合项目和 SDK 源码详细解读 MCP 架构原理。</p><h3>2.2MCP运行原理</h3><p>MCP Server作为 MCP 架构的核心部分，在提升AI应用性能方面发挥着不可替代的关键作用。其 Python 版 SDK 提供的框架图如下：</p><p><img width="723" height="376" referrerpolicy="no-referrer" src="/img/bVdni6P" alt="" title="" loading="lazy"/></p><p><strong>我们着重关注其提供的三大核心功能</strong>：资源@mcp.resource、工具@mcp.tool、提示词@mcp.prompt。而这三大核心功能之间的协作逻辑大致如下：</p><ul><li><strong>资源为工具提供上下文</strong>：手动注入资源可增强模型对任务的理解（如提供参考文档）辅助其更准确调用工具。</li><li><strong>工具执行依赖资源输入</strong>：当工具操作外部数据时，如文件处理工具，可将指定文件 URI 作为工具参数输入。</li><li><strong>提示词封装工具与资源调用</strong>：复杂 Prompt 可预设工具调用顺序或资源使用规则，形成自动化工作流。</li></ul><p>&lt;!----&gt;</p><pre><code># 在工具中封装提示词模版存在的问题是该工具不一定能被LLM调用，导致不一定能达到预期效果，但使用cline这中客户端，服务端的提示词又不能被加载调用
async def run_tool(self, arguments: Dict[str, Any]) -&gt; Sequence[TextContent]:
    prompt = f"""
            - Workflow:
              1. 解析用户输入的自然语言指令，提取关键信息，如表描述和查询条件。
              2. 判断是否跨库查询、是否明确指定了目标表名（例如是中文的描述、英文的描述，偏向语义化的描述则判断为未明确表名）
              3. 未明确指定目标表名则调用“get_table_name”工具，获取对应的表名。
              4. 调用“get_table_desc”工具，获取表的结构信息。
              5. 根据表结构信息和用户输入的查询条件，生成SQL查询语句并调用“execute_sql”工具，返回查询结果。
            - Examples:
              - 例子1：用户输入“查询用户表张三的数据”
                解析结果：表描述为“用户表”，查询条件为“张三”。
                判断结果：1.没有出现跨库的情况 2.未明确指定表名，当前为表的描述，需调用工具获取表名
                调用工具“get_table_name”：根据“用户表”描述获取表名，假设返回表名为“user_table”。
                调用工具“get_table_desc”：根据“user_table”获取表结构，假设表结构包含字段“id”、“name”、“age”。
                生成SQL查询语句：`SELECT * FROM user_table WHERE name = '张三';`
                调用工具“execute_sql”：根据生成的SQL,获取结果。
                查询结果：返回张三的相关数据。
            - task: 
              - 调用工具“get_table_name”，
              - 调用工具“get_table_desc”，
              - 调用工具“execute_sql”
              - 以markdown格式返回执行结果
            """
    
    return [TextContent(type="text", text=prompt)]
</code></pre><p><strong>但出于安全考虑，大模型对资源/工具的访问能力受到限制：</strong></p><ul><li><strong>工具：支持自主调用</strong>。大模型通过解析服务端公开的工具描述，能主动发起工具调用请求 ，无需用户逐条指令干预。此能力依赖模型的 Function Calling 支持，否则需通过提示词工程实现。</li><li><strong>资源：禁止自主访问</strong>。资源始终由应用层或用户管控 ，模型仅能使用已注入的资源内容。避免模型随意访问敏感数据，保障安全性。</li></ul><p><strong>资源（Resources）</strong></p><p>资源是指由 MCP Server 向客户端提供的数据实体，这些实体作为统一的信息载体，旨在扩展 AI 模型的数据访问边界，并支撑其对动态、结构化与非结构化数据的实时处理能力。<strong>类似于 REST API中的 GET 端点</strong>——提供数据，但不应执行大量计算或产生副作用。</p><p>资源代表任何可供 AI 模型读取的数据形式，是你向LLM 暴露数据的方式，涵盖：</p><ul><li><strong>文件内容</strong>：包括文本文件、JSON、XML 等结构化文档，以及源代码、配置文件等文本数据（UTF-8 编码）。</li><li><strong>数据库记录</strong>：关系型或非关系型数据库查询结果（e.g. PostgreSQL或MySQL）。</li><li><strong>动态系统数据</strong>：包括实时日志、屏幕截图、多媒体（图像、视频）、传感器输出等二进制数据。</li></ul><p><strong>如 MCP-DB-GPT 项目中定义的访问本地 JSON 格式的日志数据资源接口如下：</strong></p><pre><code>@mcp.resource("logs://{session_id}/{limit}")
def get_query_logs(limit: str = "5", session_id: str = "anonymous") -&gt; Dict[str, Any]:
    """获取查询日志
    
    Args:
        limit: 可选参数，指定返回的日志数量，默认为5
        session_id: 可选参数，指定要获取的会话ID
    """
    try:
        limit_val = int(limit)
        if limit_val &lt;= 0:
            return {"success": False, "error": "Limit must be a positive integer"}
        
        logs = query_logger.get_logs(session_id=session_id, limit=limit_val)
        total = query_logger.total_query_count(session_id=session_id)
        
        return {"success": True, "logs": logs, "total_queries": total}
    except Exception as e:
        return {"success": False, "error": str(e)}
</code></pre><ul><li><strong>装饰器中资源类型以统一资源标识符（URI）为唯一寻址机制</strong>，格式为[协议]://[主机]/[路径]（如 file://home/user/report.pdf 或 postgres\://database/customers/schema）。此设计允许资源协议、主机与路径的灵活定制，支持跨本地与远程环境的无缝集成。</li></ul><p><strong>通过整合多模态数据（文本与二进制）资源使 AI 模型能访问私有或专属知识库（如企业内部文档）、实时外部 API 及系统动态信息，有效突破单一大模型数据孤岛。</strong></p><p><strong>工具（Tools）</strong></p><p>工具是服务器向客户端暴露的可执行函数集合，用于拓展大型语言模型（LLM）的操作能力，使其突破纯文本生成的局限，实现对外部系统的主动交互。<strong>其本质就是函数抽象</strong>，通过JSON Schema 严格定义输入/输出参数结构（如天气查询需输入位置参数，输出结构化天气数据）。</p><p><strong>如 MCP-DB-GPT 项目中定义的只读 SQL 查询工具接口如下：</strong></p><pre><code>@mcp.tool()
def query_data(sql: str, session_id: str = "anonymous") -&gt; Dict[str, Any]:
    """Execute read-only SQL queries"""
    logger.info(f"Executing query: {sql}")
    conn = get_connection()
    cursor = None
    try:
        # Create dictionary cursor
        cursor = conn.cursor(pymysql.cursors.DictCursor)
        
        # Start read-only transaction
        cursor.execute("SET TRANSACTION READ ONLY")
        cursor.execute("START TRANSACTION")
        
        try:
            cursor.execute(sql)
            results = cursor.fetchall()
            conn.commit()
            
            # 记录成功查询
            log_query(operation=sql, success=True, session_id=session_id)
            
            # Convert results to serializable format
            return {
                "success": True,
                "results": results,
                "rowCount": len(results)
            }
        except Exception as e:
            conn.rollback()
            log_query(operation=sql, success=False, error=str(e), session_id=session_id)
            return {
                "success": False,
                "error": str(e)
            }
    finally:
        if cursor:
            cursor.close()
        conn.close()
</code></pre><p>客户端通过标准协议接口（tools/list发现工具、tools/call 调用工具）与服务器交互，形成机器可读的自动化操作链路。<strong>其安全控制机制采用 “模型控制 + 人类监督” 双轨制：</strong></p><ul><li>LLM 自主决定工具调用的必要性（如识别用户请求中的查询数据库表信息意图）；</li><li>每次执行需用户显式授权（如弹出确认框），确保数据隐私与操作合规。</li></ul><p><img width="723" height="376" referrerpolicy="no-referrer" src="/img/bVdni6Q" alt="" title="" loading="lazy"/></p><p><strong>提示词（Prompts）</strong></p><p>提示词是服务器端预定义的可重用交互模板，用于标准化和引导大型语言模型（LLM）的任务执行。这些模板通过<strong>动态参数化设计</strong>，允许传入特定值（如任务变量或上下文数据）生成定制化指令，从而实现高效、一致的模型交互。其核心机制如下：</p><ul><li><strong>结构化要素</strong>：每个提示模板包含唯一标识符、任务描述、参数列表（如输入变量）以及可选的资源引用（如外部文件或API数据）。这种结构确保指令的明确性和可扩展性，减少模型输出歧义。例如，在文本生成任务中，模板可能定义输出格式要求（如字数限制或响应风格），并动态整合用户输入数据。</li><li><strong>上下文引导</strong>：提示词嵌入上下文关联机制（如历史对话片段或外部资源引用），帮助模型理解任务背景。例如，在问答场景中，模板可引入相关数据源（如知识库），提升响应准确性和相关性。</li><li><strong>工作流支持</strong>：支持链式交互设计，允许多个提示模板组合以处理复杂任务（如多步骤分析或迭代优化）。同时，模板常作为用户界面元素（如斜杠命令）集成，增强可用性。</li><li>⚠️：提示词模版需要与客户端联动，即服务端定义好之后，在与客户端交互时，客户端获取服务器端动态填充好的提示词模版再发给大模型，大模型按照提示词要求进行回答。<strong>如果嵌在工具中触发条件往往是被动的</strong>。</li></ul><p><strong>如MCP-DB-GPT 项目中服务端定义好的提示词接口如下：</strong></p><pre><code>@mcp.prompt()
def generate_db_gpt_prompt() -&gt; str:
    """Generate a prompt for LLM to interact with database."""
    # 获取数据库表列表
    tables_info = get_tables()
    database_name = tables_info["database"]
    tables = tables_info["tables"]
    
    # 获取所有表的描述信息
    table_definitions = []
    for table in tables:
        table_desc = get_table_description(table)
        if table_desc.get("success"):
            table_definitions.append(table_desc["table_definition"])
    return DB_GPT_SYSTEM_PROMPT.format(
        database_name=database_name,
        table_definitions="\n".join(table_definitions),
    )
</code></pre><p>DB\_GPT\_SYSTEM\_PROMPT 即是预先编写好的提示词模板，当你动态的获取参数后进行替换即可。一个简易的提示词模板如下：</p><pre><code>Baseline_SYSTEM_PROMPT = """
请根据用户选择的数据库和该库的所有可用表结构定义来回答用户问题.
数据库名:
    {database_name}
表结构定义:
    {table_definitions}


约束:
    1. 请根据用户问题理解用户意图，使用给出表结构定义创建一个语法正确的mysql sql。
    2. 将查询限制为最多10000个结果。
    3. 只能使用表结构信息中提供的表来生成 sql。
    4. 请检查SQL的正确性。
    5. 分析基于现有表结构和元数据信息，估算用户提供的 DQL 语句的索引推荐策略,并返回给用户explain执行结果


用户问题:
    {user_question}


请按照以下JSON格式回复：
{{
    "thoughts": "分析思路",
    "sql": "SQL查询语句",
    "explain": "优化后的DQL语句执行结果"
}}
"""
</code></pre><p>然后客户端建立通信连接后获取相关的资源、工具和提示词模版：</p><pre><code>    # methods will go here
    async def connect_to_server(self, server_script_path: str):
        """Connect to an MCP server
        
        Args:
            server_script_path: Path to the server script (.py or .js)
        """
        # try:
        is_python = server_script_path.endswith('.py')
        is_js = server_script_path.endswith('.js')
        if not (is_python or is_js):
            raise ValueError("Server script must be a .py or .js file")
        
        command = "python" if is_python else "node"
        server_params = StdioServerParameters(
            command=command,
            args=[server_script_path],
            env=None
        )
        stdio_transport = await self.exit_stack.enter_async_context(stdio_client(server_params))
        self.stdio, self.write = stdio_transport
        self.session = await self.exit_stack.enter_async_context(ClientSession(self.stdio, self.write))
        await self.session.initialize()
        print(f"Session_id: {self.session_id}")
        
        # List available tools
        response = await self.session.list_tools()
        tools = response.tools
        print("\nConnected to server with tools:", [tool.name for tool in tools])
        
        # List available resources
        resources_response = await self.session.list_resources()
        if resources_response and resources_response.resources:
            print("Available resources:", [resource.uri for resource in resources_response.resources])
        else:
            print("Available resources templates: ['logs']")


        prompts = await self.session.list_prompts()
        if prompts and prompts.prompts:
            print("Available prompts:", [prompt.name for prompt in prompts.prompts])
        else:
            print("No available prompts found.")
</code></pre><p><strong>MCP Client</strong></p><p>MCP Client 在整个模型交互过程中则起着至关重要的桥梁作用，连接着 LLM 与 MCP Server。其Python版 SDK 提供的框架图如下：</p><p><img width="723" height="612" referrerpolicy="no-referrer" src="/img/bVdni6U" alt="" title="" loading="lazy"/></p><p>此处，我们先不看他的通信机制，结合 MCP-DB-GPT 项目仅关注 ClientSession 是如何与服务器层交互的。从宏观上看，客户端与服务器端的消息流大致如下：</p><p><img width="723" height="545" referrerpolicy="no-referrer" src="/img/bVdni61" alt="" title="" loading="lazy"/><br/>而在 MCP-DB-GPT项目中定义了一个集成阿里通义千问大模型接口的 MCPClient类：</p><pre><code>class MCPClient:
    def __init__(self):
        # Initialize session and client objects
        self.session: Optional[ClientSession] = None
        self.exit_stack = AsyncExitStack()
        self.llm = TongYiAPI()
        self.session_id = str(uuid.uuid4())
        self.use_few_shot = True
        self.conversation_history = FEW_SHOT_EXAMPLES if self.use_few_shot else []
    
    # methods will go here
    async def connect_to_server(self, server_script_path: str):
        """Connect to an MCP server
    
    async def get_query_logs(self, limit: int = 5) -&gt; str:
        """获取查询日志"""
    
    async def get_schema(self, table_names: Optional[List[str]] = None) -&gt; str:
        """获取数据库结构信息"""


    async def process_query(self, query: str) -&gt; str:
        """使用通义千问处理数据库相关查询"""
</code></pre><p>客户端就是通过ClientSession对象与服务器交互，主要包括初始化连接、工具调用和资源访问：</p><ul><li><strong>连接建立</strong>：</li><li><ul><li>在connect\_to\_server方法中，客户端基于服务器脚本路径（如 Python 或 Node.js 脚本）初始化StdioServerParameters。</li><li>使用stdio\_client建立标准输入输出（Stdio）传输通道，创建ClientSession对象。调用session.initialize()初始会话，生成唯一会话 ID（session\_id），用于加密通信和日志跟踪。</li><li>随后通过session.list\_tools()获取可用工具列表（如query\_data、get\_schema），并通过session.list\_resources()列出可访问资源（如日志）。此阶段实现协议中的“工具发现”阶段，确保客户端了解服务器功能。</li></ul></li></ul><p>&lt;!----&gt;</p><ul><li><strong>工具调用过程</strong>：</li><li><ul><li>当执行具体操作时（如执行 SQL 或获取 Schema），客户端使用session.call\_tool(tool\_name, params)方法发送 JSON-RPC 请求。 </li><li><ul><li><strong>请求结构</strong>：以get\_schema为例，参数包括session\_id和可选table\_names，序列化为 JSON 格式。</li><li><strong>服务器响应</strong>：服务器执行工具（如查询数据库结构），返回JSON-RPC响应。响应包含content字段（如数据库结构信息），客户端解析 JSON 以提取结果。</li></ul></li><li><strong>错误处理</strong>：若响应包含success: false或error字段（如无法获取Schema），客户端返回错误信息。</li></ul></li></ul><p>&lt;!----&gt;</p><ul><li><strong>资源访问机制</strong>：</li><li><ul><li>通过session.read\_resource(uri)访问资源（如日志）。日志 URI 格式为logs\://{session\_id}/{limit}，服务器返回结构化的日志数据（JSON 格式）。</li><li><strong>安全性</strong>：所有交互依赖会话级加密（session\_id），并通过权限验证（用户需显式授权敏感操作）。</li></ul></li></ul><p><strong>典型案例运用</strong></p><p>MCP-DB-GPT 项目的一大亮点在于，其实现了结合提示词后，如何借助大模型解析自然语言生成 SQL 语句再与服务器进行交互并返回查询结果的完整过程。该功能能让初学者一步感知到 MCP 的工作流程以及它的灵活与强大。</p><p><strong>通过LLM解析自然语言生成SQL语句的流程</strong>：在process\_query方法中，LLM（通义千问 API）用于生成结构化工具调用（如 SQL 语句）。核心代码实现如下：</p><pre><code>async def process_query(self, query: str) -&gt; str:
    """使用通义千问处理数据库相关查询"""
    try:
        # 调用服务器层的提示词方法
        prompt = await self.session.get_prompt("generate_db_gpt_prompt")
        prompt = prompt.messages[0].content.text
        # 将封装好的提示词投喂给大模型
        llm_response = self.llm.chat(system_prompt=prompt, content=query, response_format="json_object",
                                     conversation_history=self.conversation_history)
        response_data = json.loads(llm_response)
</code></pre><ul><li>客户端通过session.get\_prompt("generate\_db\_gpt\_prompt")获取预定义提示模板（prompt），该模板描述可用工具（如query\_data）和任务规范，优化 LLM 对查询的理解和工具的调用。</li><li><strong>LLM 基于提示和对话历史，执行“意图解析”</strong> ：</li><li><ul><li>分析自然语言，匹配工具（如自动选择query\_data工具）。</li><li>输出 JSON 包含sql字段（生成的 SQL 语句）、direct\_response（当无需 SQL）或thoughts（推理过程）。</li><li>示例：查询“金额最高的订单”可能生成"sql": "SELECT * FROM orders ORDER BY amount DESC LIMIT 1"。</li></ul></li><li><strong>对话更新</strong>：用户查询和 LLM 响应添加到conversation\_history，保持上下文一致性。</li></ul><p><strong>生成 SQL 后与服务器层的二次交互</strong>：在process\_query中，如果 LLM 响应包含sql字段（如"sql":"SELECT * FROM users"），客户端自动调用session.call\_tool("query\_data", params)。</p><pre><code># 如果有SQL查询，执行它
if response_data.get("sql"):
    # 执行SQL查询
    query_result = await self.session.call_tool("query_data", {
        "sql": response_data["sql"],
        "session_id": self.session_id
    })
    # 构建最终响应
    final_response = {
        "thoughts": response_data["thoughts"],
        "sql": response_data["sql"],
        "display_type": response_data.get("display_type", "Table"),
        "results": json.loads(query_result.content[0].text) if query_result.content[0].text else None
    }
    
    return json.dumps(final_response, ensure_ascii=False, indent=2)
</code></pre><ul><li>所有查询（包括 LLM 生成的 SQL）通过write\_resource记录到日志资源，URI 为logs\://{session\_id}/{limit}，支持后续审计。</li></ul><p><strong>此交互完成 MCP 的“执行-响应”闭环：SQL 作为工具调用的参数，服务器执行后返回结构化数据，客户端整合为最终响应。</strong></p><h2>三、底层通信原理</h2><h3>3.1协议层：JSON-RPC 2.0基础</h3><p>MCP 的核心消息格式采用 JSON-RPC 2.0 协议，这是一个轻量级的 RPC 框架，用于结构化请求、响应和通知。在 Python SDK 中：</p><ul><li><strong>消息结构</strong>：每条消息都是 JSON 对象，包含 method（方法名，如 tool\_execute）、params（参数）和 id（请求 ID）。</li></ul><p>&lt;!----&gt;</p><pre><code>class JSONRPCRequest(Request[dict[str, Any] | None, str]):
    """A request that expects a response."""
    jsonrpc: Literal["2.0"]
    id: RequestId
    method: str
    params: dict[str, Any] | None = None
</code></pre><ul><li><strong>交互类型</strong>：</li><li><ul><li>请求（JSONRPCRequest） ：客户端（如 AI 应用）发送操作指令（如执行工具）。</li><li>响应（JSONRPCResponse） ：服务器返回结果。</li><li>错误响应（JSONRPCError）：服务器返回错误信息。</li><li>通知（JSONRPCNotification） ：用于异步事件（如服务器主动推送上下文更新），无需响应。</li></ul></li></ul><p>&lt;!----&gt;</p><ul><li><strong>优势</strong>：JSON-RPC 2.0 的标准化确保跨平台兼容性，源码中通过 JsonRPCRequest和JsonRPCResponse 类实现解析和验证，减少消息解析开销。如在 STDIO 传输中，消息的序列化和反序列化过程如下：</li></ul><p><strong>发送消息时</strong>：消息被序列化为 JSON 并添加换行符。</p><pre><code>try:
    async with write_stream_reader:
        async for session_message in write_stream_reader:
            json = session_message.message.model_dump_json(by_alias=True, exclude_none=True)
            await process.stdin.send(
                (json + "\n").encode(
                    encoding=server.encoding,
                    errors=server.encoding_error_handler,
                )
            )
except anyio.ClosedResourceError:
    await anyio.lowlevel.checkpoint()
</code></pre><p><strong>接收消息时</strong>：从输入流读取行，解析为JSON-RPC消息 。</p><pre><code>try:
    message = types.JSONRPCMessage.model_validate_json(line)
except Exception as exc:
    await read_stream_writer.send(exc)
    continue


session_message = SessionMessage(message)
await read_stream_writer.send(session_message)
</code></pre><h3>3.2传输层：双向通信实现</h3><p>MCP Python SDK 提供了多种传输机制，每种机制都针对不同的部署场景和通信模式进行了优化。所有传输机制都抽象为一个基于流的通用接口，同时支持特定于协议的功能。</p><p><img width="723" height="163" referrerpolicy="no-referrer" src="/img/bVdni63" alt="" title="" loading="lazy"/></p><p><strong>Stdio传输</strong></p><p>通过标准输入/输出（stdin/stdout）流进行同步或异步通信。源码中读取和写入流由如下函数实现：</p><ul><li><strong>读取流</strong>：MemoryObjectReceiveStream[SessionMessage | Exception]-从服务器标准输出接收消息</li><li><strong>写入流</strong>：MemoryObjectSendStream[SessionMessage]- 将消息发送到服务器标准输入</li></ul><p><strong>其适用于本地进程间通信（如 IDE 插件），低延迟但仅限单机。</strong> 关键代码包括stdin\_reader()和stdout\_writer方法，负责后台处理双向通信。<strong>其通信流程大致为以下七步</strong>：</p><ol><li>客户端以子进程的方式启动服务器</li><li>客户端往服务器的 stdin 写入消息</li><li>服务器从自身的 stdin 读取消息</li><li>服务端往自身的 stdout 写入消息</li><li>客户端从服务器的 stdout 读取消息</li><li>客户端终止子进程，关闭服务器的 stdin</li><li>服务器关闭自身的 stdout</li></ol><p><img width="723" height="675" referrerpolicy="no-referrer" src="/img/bVdni64" alt="" title="" loading="lazy"/></p><ul><li>⚠️⚠️⚠️：<strong>当客户端调用mcp.tool() 装饰的函数时，SDK 内部封装请求为 JSON-RPC，通过 stdio 发送给服务器进程，服务端通过装饰器装饰的函数在建立连接后被调用时，会自动进行注入并转换成 JSON格式的数据与客户端进行自动交互。</strong></li></ul><p><img width="723" height="570" referrerpolicy="no-referrer" src="/img/bVdni65" alt="" title="" loading="lazy"/></p><p><strong>服务端代码参考：</strong></p><pre><code>async def run_stdio():
    """运行标准输入输出模式的服务器
    
    使用标准输入输出流(stdio)运行服务器，主要用于命令行交互模式
    
    Raises:
        Exception: 当服务器运行出错时抛出异常
    """
    from mcp.server.stdio import stdio_server
    
    logger.info("启动标准输入输出(stdio)模式服务器")
    
    try:
        # 初始化资源
        await initialize_global_resources()
        
        async with stdio_server() as (read_stream, write_stream):
            try:
                logger.debug("初始化流式传输接口")
                await app.run(
                    read_stream,
                    write_stream,
                    app.create_initialization_options()
                )
                logger.info("标准输入输出模式服务结束")
            except Exception as e:
                logger.critical(f"标准输入输出模式服务器错误: {str(e)}")
                logger.exception("服务异常终止")
                raise
    finally:
        # 关闭资源
        await close_global_resources()
</code></pre><p><strong>Main 函数中调用：</strong></p><pre><code>try:
    if mode == "stdio":
        asyncio.run(run_stdio())
</code></pre><p><strong>配置 Cline 的JSON文件即可访问：</strong></p><pre><code>"mcp_db": {
      "timeout": 60,
      "type": "stdio",
      "command": "uv",
      "args": [
        "--directory",
        "/Users/admin/Downloads/Codes/MCP/mcp_for_db/src/",
        "run",
        "-m",
        "server.mcp.server_mysql",
        "--mode",
        "stdio"
      ],
      "env": {
        "MYSQL_HOST": "localhost",
        "MYSQL_PORT": "3306",
        "MYSQL_USER": "root",
        "MYSQL_PASSWORD": "password",
        "MYSQL_DATABASE": "mcp_db",
        "MYSQL_ROLE": "admin",
        "PYTHONPATH": "/Users/admin/Downloads/Codes/MCP/MCP-DB/"
      }
}
</code></pre><p><strong>SSE 传输</strong></p><p>SSE 传输使用服务器发送事件 (SSE) 传输服务器到客户端的消息，并使用 HTTP POST 请求传输客户端到服务器的消息，提供基于 HTTP 的通信。其本质是双向模拟，即 SSE 本质为单向，SDK 通过“请求/响应”对模拟双向通信（客户端发送 HTTP POST 请求携带JSON-RPC，服务器返回 SSE 流）。其通信流程也可概括为七步：</p><ol><li>客户端向服务器的 /sse 端点发送请求（一般是 GET 请求），建立 SSE 连接；</li><li>服务器给客户端返回一个包含消息端点地址的事件消息；</li><li>客户端给消息端点发送消息；</li><li>服务器给客户端响应消息已接收状态码；</li><li>服务器给双方建立的 SSE 连接推送事件消息；</li><li>客户端从 SSE 连接读取服务器发送的事件消息；</li><li>客户端关闭 SSE 连接。</li></ol><p><img width="723" height="888" referrerpolicy="no-referrer" src="/img/bVdni68" alt="" title="" loading="lazy"/></p><p><strong>服务器端</strong>：SseServerTransport为服务器端 SSE 传输实现提供了两个主要的 ASGI 应用程序。</p><p><img width="723" height="97" referrerpolicy="no-referrer" src="/img/bVdni7f" alt="" title="" loading="lazy"/></p><p><strong>客户端</strong>：sse\_client函数提供客户端 SSE 传输实现。</p><p><strong>二者通信的消息格式如下</strong>：每条 SSE 消息以 data: 前缀携带 JSON-RPC 负载，客户端监听事件流。</p><pre><code># 服务端
logger.debug("Starting SSE writer")
async with sse_stream_writer, write_stream_reader:
    await sse_stream_writer.send({"event": "endpoint", "data": client_post_uri_data})
    logger.debug(f"Sent endpoint event: {client_post_uri_data}")
    
    async for session_message in write_stream_reader:
        logger.debug(f"Sending message via SSE: {session_message}")
        await sse_stream_writer.send(
            {
                "event": "message",
                "data": session_message.message.model_dump_json(by_alias=True, exclude_none=True),
            }
        )
</code></pre><p><strong>其中涉及两种主要事件类型：</strong></p><ul><li><strong>endpoint事件</strong>：在连接建立时发送，告知客户端 POST 消息的端点 URL。</li><li><strong>message事件</strong>：传输实际的 JSON-RPC 消息。</li></ul><p><strong>客户端通过 sse\_reader 函数处理接收到的 SSE 事件：</strong></p><ul><li><strong>endpoint事件处理</strong>：验证端点 URL 的安全性，确保与连接源匹配。</li></ul><p>&lt;!----&gt;</p><pre><code>match sse.event:
    case "endpoint":
        endpoint_url = urljoin(url, sse.data)
        logger.debug(f"Received endpoint URL: {endpoint_url}")
        
        url_parsed = urlparse(url)
        endpoint_parsed = urlparse(endpoint_url)
        if (
            url_parsed.netloc != endpoint_parsed.netloc
            or url_parsed.scheme != endpoint_parsed.scheme
        ):
            error_msg = (
                "Endpoint origin does not match " f"connection origin: {endpoint_url}"
            )
            logger.error(error_msg)
            raise ValueError(error_msg)
        
        task_status.started(endpoint_url)
</code></pre><ul><li><strong>message事件处理</strong>：解析 JSON-RPC 消息并转换为 SessionMessage。</li></ul><p>&lt;!----&gt;</p><pre><code>case "message":
    try:
        message = types.JSONRPCMessage.model_validate_json(  # noqa: E501
            sse.data
        )
        logger.debug(f"Received server message: {message}")
    except Exception as exc:
        logger.error(f"Error parsing server message: {exc}")
        await read_stream_writer.send(exc)
        continue
    
    session_message = SessionMessage(message)
    await read_stream_writer.send(session_message)
</code></pre><p><strong>适用场景</strong>：远程或云端部署，支持高并发和实时更新（如工具调用的结果推送）。错误处理包括连接超时重试（源码中 retry 机制）。</p><p><strong>服务端代码参考</strong>：</p><pre><code>def run_sse():
    """运行SSE(Server-Sent Events)模式的服务器
    
    启动一个支持SSE的Web服务器，允许客户端通过HTTP长连接接收服务器推送的消息
    服务器默认监听0.0.0.0:9000
    """
    logger.info("启动SSE(Server-Sent Events)模式服务器")
    sse = SseServerTransport("/messages/")
    
    async def handle_sse(request):
        """处理SSE连接请求
        
        Args:
            request: HTTP请求对象
        """
        logger.info(f"新的SSE连接 [client={request.client}]")
        async with sse.connect_sse(
                request.scope, request.receive, request.send
        ) as streams:
            try:
                await app.run(streams[0], streams[1], app.create_initialization_options())
            except Exception as e:
                logger.error(f"SSE连接处理异常: {str(e)}")
                raise
        logger.info(f"SSE连接断开 [client={request.client}]")
        return Response(status_code=204)
    
    @contextlib.asynccontextmanager
    async def lifespan(app: Starlette) -&gt; AsyncIterator[None]:
        """SSE应用的生命周期管理"""
        try:
            # 初始化资源
            await initialize_global_resources()
            yield
        finally:
            # 关闭资源
            await close_global_resources()
    
    starlette_app = Starlette(
        debug=True,
        routes=[
            Route("/sse", endpoint=handle_sse),
            Mount("/messages/", app=sse.handle_post_message)
        ],
        lifespan=lifespan
    )
    
    logger.info("SSE服务器启动中 [host=0.0.0.0, port=9000]")
    # 创建配置并运行
    config = uvicorn.Config(
        app=starlette_app,
        host="0.0.0.0",
        port=9000,
        loop="asyncio",
        log_config=None  # 禁用uvicorn默认日志配置
    )
    
    server = uvicorn.Server(config)
    server.run()
</code></pre><p><strong>Main函数中调用</strong>：</p><pre><code>try:
    if mode == "sse":
        run_sse()
</code></pre><p><strong>配置 Cline 的 JSON文件即可访问：</strong></p><pre><code>"mysql_mcp_server": {
  "disabled": true,
  "timeout": 60,
  "type": "sse",
  "url": "http://localhost:9000/sse"
}
</code></pre><h3>3.3通信工作流程</h3><p>MCP通信遵循 JSON-RPC 2.0模式，主要包含三个消息类别：</p><p><img width="725" height="145" referrerpolicy="no-referrer" src="/img/bVdni7g" alt="" title="" loading="lazy"/></p><p>同时，理解 MCP 连接生命周期可以帮助我们更好地开发 MCP 服务器和 AI 应用。MCP 连接生命周期跟 TCP 的三次握手、四次挥手有点类似，也要经历建立连接、交换消息、断开连接等阶段。</p><p><img width="616" height="1337" referrerpolicy="no-referrer" src="/img/bVdni7j" alt="" title="" loading="lazy"/><br/>接下来，以 StreamableHTTP 机制为例，分析通信工作流程。StreamableHTTP 传输机制实现了基于 HTTP 的双向通信，结合了 HTTP POST 请求和 Server-Sent Events (SSE) 流来提供完整的客户端-服务器通信解决方案。</p><p><strong>整体架构流程</strong></p><p>StreamableHTTP 通信机制包含会话管理、双向消息传输和可选的事件重放功能：</p><ul><li>客户端传输初始化</li><li><ul><li>客户端通过 streamablehttp\_client 函数建立连接。</li><li>核心组件 StreamableHTTPTransport 负责管理会话状态和消息路由。<br/>*</li></ul></li><li>服务器端会话管理</li><li><ul><li>服务器端使用 StreamableHTTPSessionManager 管理多个并发会话。支持有状态和无状态两种模式：</li><li><strong>有状态模式</strong>：维护会话状态，支持连接恢复。</li><li><strong>无状态模式</strong>：每个请求创建新的传输实例。</li></ul></li></ul><p><strong>通信工作流程详解</strong></p><p><strong>初始化和会话建立</strong></p><ul><li>初始化请求：客户端发送 initialize 方法的 POST 请求。</li><li>会话 ID 分配：服务器生成唯一会话 ID 并通过 mcp-session-id 头返回。</li></ul><p>&lt;!----&gt;</p><pre><code>def _maybe_extract_session_id_from_response(
    self,
    response: httpx.Response,
) -&gt; None:
    """Extract and store session ID from response headers."""
    new_session_id = response.headers.get(MCP_SESSION_ID)
    if new_session_id:
        self.session_id = new_session_id
        logger.info(f"Received session ID: {self.session_id}")
</code></pre><p><strong>双向消息传输</strong></p><p>客户端到服务器（POST 请求）：客户端的post\_writer 方法处理出站消息。</p><pre><code>async def post_writer(
    self,
    client: httpx.AsyncClient,
    write_stream_reader: StreamReader,
    read_stream_writer: StreamWriter,
    write_stream: MemoryObjectSendStream[SessionMessage],
    start_get_stream: Callable[[], None],
    tg: TaskGroup,
) -&gt; None:
    """Handle writing requests to the server."""
</code></pre><ul><li><strong>消息序列化</strong>：将 JSON-RPC 消息序列化为 HTTP POST 请求体。</li><li><strong>请求处理</strong>：根据消息类型选择处理方式 - 普通请求或恢复请求。</li></ul><p>&lt;!----&gt;</p><pre><code>async def handle_request_async():
    if is_resumption:
        await self._handle_resumption_request(ctx)
    else:
        await self._handle_post_request(ctx)
# If this is a request, start a new task to handle it
if isinstance(message.root, JSONRPCRequest):
    tg.start_soon(handle_request_async)
else:
    await handle_request_async()
</code></pre><ul><li><strong>响应处理</strong>：支持 JSON 响应和 SSE 流响应两种模式。</li></ul><p><strong>服务器到客户端（SSE 流）</strong></p><p>服务器端通过不同的 HTTP 方法处理消息：</p><ul><li><strong>POST 请求处理</strong>：接收客户端消息并通过 SSE 或 JSON 响应</li></ul><p>&lt;!----&gt;</p><pre><code>if self.is_json_response_enabled:
    # Process the message
    metadata = ServerMessageMetadata(request_context=request)
    session_message = SessionMessage(message, metadata=metadata)
    await writer.send(session_message)
    try:
        # Process messages from the request-specific stream
        # We need to collect all messages until we get a response
        pass
    finally:
        await self._clean_up_memory_streams(request_id)
else:
    # Create SSE stream
    sse_stream_writer, sse_stream_reader = anyio.create_memory_object_stream[dict[str, str]](0)
    
    async def sse_writer():
        # Get the request ID from the incoming request message
</code></pre><ul><li><strong>GET 请求处理</strong>：建立独立的 SSE 流用于服务器主动推送 streamable\_http.py:511-601</li></ul><p>&lt;!----&gt;</p><pre><code>async def _handle_get_request(self, request: Request, send: Send) -&gt; None:
    """
    Handle GET request to establish SSE.
    
    This allows the server to communicate to the client without the client
    first sending data via HTTP POST. The server can send JSON-RPC requests
    and notifications on this stream.
    """
</code></pre><p><strong>实际使用示例</strong></p><p>从测试代码中可以看到完整的使用流程：</p><pre><code>@pytest.mark.anyio
async def test_streamablehttp_client_basic_connection(basic_server, basic_server_url):
    """Test basic client connection with initialization."""
    async with streamablehttp_client(f"{basic_server_url}/mcp") as (
        read_stream,
        write_stream,
        _,
    ):
        async with ClientSession(
            read_stream,
            write_stream,
        ) as session:
            # Test initialization
            result = await session.initialize()
            assert isinstance(result, InitializeResult)
            assert result.serverInfo.name == SERVER_NAME
</code></pre><ol><li>使用 streamablehttp\_client 建立连接</li><li>通过 ClientSession 进行初始化</li><li>执行各种 MCP 操作（工具调用、资源访问等）</li></ol><h3>3.4各协议对比分析</h3><p><img width="723" height="417" referrerpolicy="no-referrer" src="/img/bVdni7i" alt="" title="" loading="lazy"/></p><p>MCP vs REST API</p><p><img width="723" height="355" referrerpolicy="no-referrer" src="/img/bVdni7h" alt="" title="" loading="lazy"/><br/>MCP vs WebSocket</p><h2>四、项目初始化&amp;实战解析</h2><p>本节，将使用 uv 快速搭建 MCP 服务，然后结合 DW-DBA-MCP 实战项目进行介绍。</p><h3>4.1环境安装</h3><p>官方推荐使用 uv 进行虚拟环境及依赖的管理。uv 的安装可参考：<a href="https://link.segmentfault.com/?enc=Ir98Uf2eUVUcK%2B8DMFuivQ%3D%3D.rktocjbQzG71LCx0iS48Nn1zuSTyQ%2BLaCPFYgXX%2FVCNHh66hcdFBl5IgNs%2FE0Rcvzytra49xwUN9wr5JAbM7fVP0%2BSHqXvzJqswbvgAAyuPWCiI1lmPOX%2BjQPSKYjflYQ08SKRhWxVbqToDvJ0e%2FfGzVe2Y8Fjzo%2BRBbtC0qxhkLNTHqXAhLBYO1W%2FsmwveW77WK%2BnpfJPiUmyD2dXQXyg%3D%3D" rel="nofollow" target="_blank">https://docs.astral.sh/uv/#highlights。其他安装方式可参考：ht...</a></p><pre><code># macos
curl -LsSf https://astral.sh/uv/install.sh | sh
source $HOME/.local/bin/env


(base) Dewu-GK234XWXCT:~ admin$ uv --version
uv 0.7.13 (62ed17b23 2025-06-12)
</code></pre><p>同时，需要注意⚠️：SDK 需要 Python 3.10 或更高版本，支持 Python 3.10 至 3.13。</p><ul><li><strong>创建虚拟环境：</strong></li></ul><p>&lt;!----&gt;</p><pre><code># 初始化虚拟环境
uv init MCP-DB


# 切换目录
cd MCP-DB


# 安装mcp client依赖
uv add "mcp[cli]"


# 使用 uv 运行 mcp 命令
uv run mcp -help
</code></pre><p><img width="723" height="754" referrerpolicy="no-referrer" src="/img/bVdni7T" alt="" title="" loading="lazy"/></p><h3>4.2DW-DBA-MCP实战解析</h3><p>本项目旨在为数据库侧开发 MCP Server。同时，考虑到高可扩展性，项目采用微服务架构进行设计开发，这也便于与 Nacos MCP Server 进行集成，客户端配置Nacos MCP Server 服务，LLM 即可通过该网关高效路由到合适工具；考虑到易用性，通过封装 MCP Client 和 MCP Server，提供 FastAPI 接口处理用户的提问。项目目录结构如下：</p><pre><code>DW-DBA-MCP/
├── Dockerfile
├── LICENSE
├── README.md   
├── datas                          # 存放项目日志文件
│   ├── files                           # 存放工具执行的 SQL 语句
│   ├── logs                            # 存放日志文件
│   └── version   
├── mcp_for_db
│   ├── __init__.py
│   ├── client                    # 自建客户端
│   │   ├── __init__.py
│   │   ├── api.py                     # FastAPI 服务
│   │   └── client.py                  # MCP Client
│   ├── debug
│   │   ├── __init__.py
│   │   └── mcp_logger.py              # 记录 MCP Client 与 MCP Server 通信数据，用于白盒解析 MCP 通信协议
│   ├── envs
│   │   ├── common.env           # 多服务环境变量配置文件
│   │   ├── dify.env
│   │   └── mysql.env
│   ├── server
│   │   ├── __init__.py
│   │   ├── cli
│   │   │   ├── __init__.py
│   │   │   ├── dify_cli.py     # cli 方式启动 dify 服务
│   │   │   ├── mysql_cli.py    # cli 方式启动 mysql 服务
│   │   │   └── server.py
│   │   ├── common
│   │   │   ├── __init__.py
│   │   │   ├── base            # 公共的资源、工具和提示词自动注册和发现的基类包
│   │   │   ├── prompts.py      # 存放提示词模版
│   │   │   └── tools.py        # 存放工具描述
│   │   ├── core
│   │   │   ├── __init__.py
│   │   │   ├── base_server.py       # 微服务基类
│   │   │   ├── config_manager.py    # 环境变量配置器
│   │   │   ├── env_distribute.py    # stdio通信机制下多服务环境变量分发器
│   │   │   └── service_manager.py   # 多服务管理器
│   │   ├── server_dify              # dify 服务实现包
│   │   │   ├── __init__.py
│   │   │   ├── config
│   │   │   ├── dify_server.py      # dify 服务实现类
│   │   │   └── tools
│   │   ├── server_mysql             # mysql 服务实现包
│   │   │   ├── __init__.py
│   │   │   ├── config
│   │   │   ├── mysql_server.py     # mysql 服务实现类
│   │   │   ├── prompts
│   │   │   ├── resources
│   │   │   └── tools
│   │   └── shared
│   │       ├── __init__.py
│   │       ├── oauth
│   │       ├── security    # SQL鉴权
│   │       ├── templates
│   │       └── utils
│   └── test
├── pyproject.toml
├── requirements.txt
└── uv.lock
</code></pre><p><strong>项目设计思路</strong></p><p>本项目原先参考于开源项目：<a href="https://link.segmentfault.com/?enc=XMwGO7zD8K7E%2B7HHKNgm1g%3D%3D.bOzwNggxiPG8nfUaxkXMUOWjlEXwaX7Fo34n%2FHGkPCuWvWWnj%2FFJ6Jlk%2Bl%2Bel7ENsEh%2BluMmUnBUmGkq4ivhhVLr138KuPk3BlJOetxbX5iZG5UfIgz76V0YiTiGZo6Gv2DAyLyZ5eAKlZdi3L2eC0bwD%2F4XyHE0HvM%2BgoxBTakZmW%2BiVVca%2FZqfDGjZWvHlWfmjeKARemgQASeMTpccsQ%3D%3D" rel="nofollow" target="_blank">https://github.com/wenb1n-dev/mysql_mcp_server_pro，但针对微服务式的架构设计，又做了进一步改进，现阶段二者的差异如下：</a><br/><img width="723" height="709" referrerpolicy="no-referrer" src="/img/bVdni73" alt="" title="" loading="lazy"/><br/><img width="723" height="629" referrerpolicy="no-referrer" src="/img/bVdni77" alt="" title="" loading="lazy"/><br/><img width="723" height="759" referrerpolicy="no-referrer" src="/img/bVdni78" alt="" title="" loading="lazy"/></p><p>针对如何借助 Low-Level 接口自动注册和发现资源、工具和提示词，接下来则以我们扩展封装的资源为例进行介绍。</p><p>在多服务基类脚本base\_server.py中只需展示和读取资源即可，对应的类会自动将资源进行注册和读取。</p><pre><code>async def setup_server(self):
    """设置服务器路由"""
    if self.server_setup_completed:
        self.logger.debug("服务器路由已设置，跳过重复设置")
        return
    
    self.logger.info("开始设置服务器路由")
    
    # 注册资源处理器
    @self.server.list_resources()
    async def handle_list_resources() -&gt; List[Resource]:
        try:
            registry = self.get_resource_registry()
            if registry is None:
                self.logger.warning("资源注册表未初始化，返回空列表")
                return []
            
            if hasattr(registry, 'get_all_resources'):
                if asyncio.iscoroutinefunction(registry.get_all_resources):
                    return await registry.get_all_resources()
                else:
                    return registry.get_all_resources()
            return []
        except Exception as e:
            self.logger.error(f"获取资源列表失败: {str(e)}", exc_info=True)
            return []
    
    @self.server.read_resource()
    async def handle_read_resource(uri: AnyUrl) -&gt; str:
        try:
            self.logger.info(f"开始读取资源: {uri}")
            registry = self.get_resource_registry()
            if registry is None:
                raise ValueError("资源注册表未初始化")
            
            if hasattr(registry, 'get_resource'):
                if asyncio.iscoroutinefunction(registry.get_resource):
                    content = await registry.get_resource(uri)
                else:
                    content = registry.get_resource(uri)
            else:
                content = None
            
            if content is None:
                content = "null"
            self.logger.info(f"资源 {uri} 读取成功，内容长度: {len(content)}")
            return content
        except Exception as e:
            self.logger.error(f"读取资源失败: {str(e)}", exc_info=True)
            raise
</code></pre><p><strong>资源注册类：</strong></p><pre><code>

class ResourceRegistry:
    """资源注册表，用于管理所有资源实例"""
    _resources: ClassVar[Dict[str, 'BaseResource']] = {}
    
    @classmethod
    def register(cls, resource_class: Type['BaseResource']):
        """注册资源实例"""
        resource = resource_class()
        logger.info(f"注册资源: {resource.name} (URI: {resource.uri})")
        cls._resources[str(resource.uri)] = resource
    
    @classmethod
    def register_instance(cls, resource: 'BaseResource'):
        """手动注册资源实例"""
        uri_str = str(resource.uri)
        logger.info(f"注册资源实例: {resource.name} (URI: {uri_str})")
        cls._resources[uri_str] = resource
    
    @classmethod
    async def get_resource(cls, uri: AnyUrl) -&gt; str:
        """获取资源内容"""
        logger.info(f"请求资源: {uri}")
        parsed = urlparse(str(uri))
        uri_str = f"{parsed.scheme}://{parsed.netloc}/{parsed.path}"
        path_parts = parsed.path.strip('/').split('/')
        
        if not path_parts or not path_parts[0]:
            raise ValueError(f"无效的URI格式: {uri_str}，未指定表名")
        
        # 优先尝试精确匹配
        for resource in cls._resources.values():
            if str(resource.uri) == uri_str:
                return await resource.read_resource(uri)
        
        # 尝试后缀匹配
        for resource in cls._resources.values():
            if str(resource.uri).endswith(path_parts[0]):
                return await resource.read_resource(uri)
        
        logger.error(f"未找到资源: {uri}，已注册资源: {[r.uri for k, r in cls._resources.items()]}")
        raise ValueError(f"未注册的资源: {uri}")
    
    @classmethod
    async def get_all_resources(cls) -&gt; List[Resource]:
        """获取所有资源的描述"""
        result = []
        # 创建资源副本避免在迭代过程中修改原字典:扫描库时还会注册表资源
        resources_copy = list(cls._resources.values())
        for resource in resources_copy:
            try:
                logger.info(f"获取 {resource.name} 的资源描述")
                descriptions = await resource.get_resource_descriptions()
                result.extend(descriptions)
                logger.debug(f"{resource.name} 提供了 {len(descriptions)} 个资源描述")
            except Exception as e:
                logger.error(f"获取 {resource.name} 的描述失败: {str(e)}", exc_info=True)
        return result</code></pre><p><strong>封装后的资源基类：主要是借助\_\_init\_subclass\_\_方法自动注册</strong></p><pre><code>class BaseResource:
    """资源基类"""
    name: str = ""
    description: str = ""
    uri: AnyUrl
    mimeType: str = "text/plain"
    auto_register: bool = True
    
    def __init_subclass__(cls, **kwargs):
        """子类初始化时自动注册到资源注册表"""
        super().__init_subclass__(**kwargs)
        if cls.auto_register and cls.uri is not None:  # 只注册有 uri 的资源
            ResourceRegistry.register(cls)
    
    async def get_resource_descriptions(self) -&gt; List[Resource]:
        """获取资源描述，子类必须实现"""
        raise NotImplementedError
    
    async def read_resource(self, uri: AnyUrl) -&gt; str:
        """读取资源内容，子类必须实现"""
        raise NotImplementedError
</code></pre><p><strong>实现 MySQL 资源类：值得注意的是此处我们在设计时迫于上面的机制又设计了表资源类TableResource</strong></p><pre><code>class TableResource(BaseResource):
    """代表具体表资源的类"""
    auto_register: bool = False
    
    TABLE_EXISTS_QUERY = """
        SELECT COUNT(*) AS table_exists
        FROM information_schema.tables
        WHERE table_schema = %s AND table_name = %s
    """
    
    COLUMN_METADATA_QUERY = """
        SELECT COLUMN_NAME, DATA_TYPE
        FROM information_schema.columns
        WHERE table_schema = %s AND table_name = %s
        ORDER BY ORDINAL_POSITION
    """
    
    def __init__(self, db_name: str, table_name: str, description: str):
        super().__init__()
        self.db_name = db_name
        self.table_name = table_name
        self.name = f"table: {table_name}"
        self.uri = AnyUrl(f"mysql://{db_name}/{table_name}")
        self.description = description
        self.mimeType = "text/csv"
    
    async def get_resource_descriptions(self) -&gt; List[Resource]:
        """返回数据库表资源的描述:已返回"""
        return []
    
    async def read_resource(self, uri: AnyUrl) -&gt; str:
        """安全读取数据库表数据为CSV格式（带列类型信息）"""
        logger.info(f"开始读取资源: {uri}")
        try:
            # 安全解析表名
            table_name = extract_table_name(uri)
            logger.info(f"准备查询表: {table_name}")
            
            # 获取列元数据（用于优化CSV生成）
            column_metadata = await self.get_table_metadata(table_name)
            
            async with get_current_database_manager().get_connection() as conn:
                async with conn.cursor(aiomysql.DictCursor) as cursor:
                    # 使用参数化查询避免SQL注入
                    safe_query = _build_safe_query(table_name)
                    await cursor.execute(safe_query)
                    
                    # 直接获取列名
                    columns = [col[0] for col in cursor.description]
                    rows = await cursor.fetchall()
                    
                    logger.info(f"获取到 {len(rows)} 行数据")
                    
                    # 使用优化的CSV生成
                    return generate_csv(columns, rows, column_metadata)
        
        except Exception as e:
            logger.error(f"读取资源失败: {str(e)}", exc_info=True)
            raise
    
    async def get_table_metadata(self, table_name: str) -&gt; List[tuple]:
        """获取表列名和数据类型"""
        db_name = get_current_database_manager().get_current_config()["database"]
        
        async with get_current_database_manager().get_connection() as conn:
            async with conn.cursor(aiomysql.DictCursor) as cursor:
                # 首先验证表存在
                await cursor.execute(self.TABLE_EXISTS_QUERY, (db_name, table_name))
                exists = await cursor.fetchone()
                
                if not exists or not exists['table_exists']:
                    raise ValueError(f"表 '{table_name}' 在数据库 '{db_name}' 中不存在")
                
                # 获取列元数据
                await cursor.execute(self.COLUMN_METADATA_QUERY, (db_name, table_name))
                metadata = [(row['COLUMN_NAME'], row['DATA_TYPE']) for row in await cursor.fetchall()]
                
                return metadata




class MySQLResource(BaseResource):
    """MySQL数据库资源实现"""
    name = "MySQL数据库"
    uri = AnyUrl(f"mysql://localhost/default")
    description = "提供对MySQL数据库表的访问与查询"
    mimeType = "text/csv"
    auto_register = True
    
    # 重用这些常量查询
    TABLE_QUERY = """
        SELECT TABLE_NAME AS table_name,
               TABLE_COMMENT AS table_comment,
               TABLE_ROWS AS estimated_rows
        FROM information_schema.tables
        WHERE table_schema = %s
    """
    
    def __init__(self):
        """初始化资源管理"""
        super().__init__()
        self.cache = {}  # 查询结果缓存
    
    async def get_resource_descriptions(self) -&gt; List[Resource]:
        """获取数据库表资源描述（带缓存机制）"""
        logger.info("获取数据库资源描述")
        
        db_manager = get_current_database_manager()
        if db_manager is None:
            logger.error("无法获取数据库管理器，上下文未设置？")
            return []
        
        db_name = db_manager.get_current_config().get("database")
        if not db_name:
            logger.error("数据库配置中未指定数据库名称")
            return []
        
        # 使用缓存避免重复查询
        if 'table_descriptions' in self.cache:
            logger.debug("使用缓存的表描述")
            return self.cache['table_descriptions']
        
        try:
            async with db_manager.get_connection() as conn:
                async with conn.cursor(aiomysql.DictCursor) as cursor:
                    await cursor.execute(self.TABLE_QUERY, (db_name,))
                    tables = await cursor.fetchall()
                    logger.info(f"发现 {len(tables)} 个数据库表")
                    
                    resources = []
                    for table in tables:
                        table_name = table['table_name']
                        
                        # 添加表行数统计
                        description = table['table_comment'] or f"{table_name} 表"
                        if table['estimated_rows']:
                            description += f" (~{table['estimated_rows']}行)"
                        
                        # 创建表资源
                        table_resource = TableResource(db_name, table_name, description)
                        
                        # 手动注册表资源实例
                        ResourceRegistry.register_instance(table_resource)
                        
                        # 创建资源描述对象
                        resource_desc = Resource(
                            uri=table_resource.uri,
                            name=table_resource.name,
                            mimeType=table_resource.mimeType,
                            description=table_resource.description
                        )
                        resources.append(resource_desc)
                    
                    # 缓存结果
                    self.cache['table_descriptions'] = resources
                    logger.info(f"创建了 {len(resources)} 个表资源描述")
                    return resources
        
        except Exception as e:
            logger.error(f"获取资源描述失败: {str(e)}", exc_info=True)
            return []
    
    async def read_resource(self, uri: AnyUrl) -&gt; str:
        """读取根资源内容 - 返回数据库信息"""
        return json.dumps({
            "name": self.name,
            "uri": self.uri,
            "description": self.description,
            "type": "database_root"
        })
</code></pre><p>想实现其他资源，就编写对应的脚本，然后将包加入到对应的\_\_init\_\_.py脚本中：</p><pre><code>from .db_resource import MySQLResource, TableResource


__all__ = [
    "MySQLResource",
    "TableResource",
]
</code></pre><p>这样代码具有较高可扩展性，组织结构也很清晰。当然，也会有其他更好的实现方式。</p><p><strong>效果展示</strong></p><p>MCP Server 主要是通过工具暴露数据给LLMs，故基于上述的设计思路，实现起来相对简单且专一，主要就是实现工具所对应的 SQL 语句编写和对应的提示词即可，鉴于篇幅和代码量，此处不再展示源码，仅提供历史测试效果图。</p><p><strong>查询表中数据</strong></p><p>在 Cline 中配置好阿里通义千问大模型 API-KEY 后，进行提问： </p><p><img width="723" height="133" referrerpolicy="no-referrer" src="/img/bVdni8g" alt="" title="" loading="lazy"/></p><p>⚠️：阿里通义千问大模型配置可参考：<a href="https://link.segmentfault.com/?enc=niLAcinvF64Phkpvbtmtvg%3D%3D.%2FlEG60QxM%2BIVrr18k0LiboYCY%2BZDWnrgzZDtT7LYmyyTgYGhBJO6SCaFHeS5qSMM" rel="nofollow" target="_blank">https://help.aliyun.com/zh/model-studio/cline</a></p><p>随后，大模型开始解析执行任务：</p><p><img width="723" height="402" referrerpolicy="no-referrer" src="/img/bVdni8h" alt="" title="" loading="lazy"/><br/>发现解析错了，开始自动矫正： </p><p><img width="723" height="405" referrerpolicy="no-referrer" src="/img/bVdni8j" alt="" title="" loading="lazy"/></p><p>OK，现在看起来就对多了，开始执行工具运行指令并返回结果：</p><p><img width="723" height="372" referrerpolicy="no-referrer" src="/img/bVdni8o" alt="" title="" loading="lazy"/></p><p><strong>最终执行结果如下：</strong></p><p><img width="723" height="447" referrerpolicy="no-referrer" src="/img/bVdni8q" alt="" title="" loading="lazy"/></p><p><strong>其他的比如：查询某表中告警信息。此处给出了明确的库表信息，回答的就很精准。</strong></p><p><img width="723" height="496" referrerpolicy="no-referrer" src="/img/bVdni8r" alt="" title="" loading="lazy"/><br/><strong>慢SQL优化</strong></p><p><img width="723" height="183" referrerpolicy="no-referrer" src="/img/bVdni8t" alt="" title="" loading="lazy"/><br/>大模型在执行一些工具之后，给出了回答：</p><p><img width="723" height="343" referrerpolicy="no-referrer" src="/img/bVdni8y" alt="" title="" loading="lazy"/></p><p>并最终给出了如下预期效果：</p><p><img width="723" height="357" referrerpolicy="no-referrer" src="/img/bVdni8z" alt="" title="" loading="lazy"/></p><p><strong>高危操作验证</strong></p><p>在执行高危 SQL 语句前，会拦截并作解析，判断是否与预先允许的操作一致，不一致则不放行，模型无法操作数据库，报错终止任务。<strong>目前权限限定为查询操作 DQL</strong>。</p><p><img width="703" height="401" referrerpolicy="no-referrer" src="/img/bVdni8D" alt="" title="" loading="lazy"/></p><p>当想更新表中数据时：</p><p><img width="723" height="242" referrerpolicy="no-referrer" src="/img/bVdni8G" alt="" title="" loading="lazy"/></p><p><img width="723" height="319" referrerpolicy="no-referrer" src="/img/bVdni8I" alt="" title="" loading="lazy"/></p><p><strong>自建客户端提问</strong></p><p>实现自定义客户端时可调用服务端提示词进行任务编排，提高工具调用准确度和规避一连串的客户端continue操作，通过请求实现的FastAPI接口可直接运行出结果。</p><pre><code>当前数据库基本信息，以及包含哪些表，同时用户表有哪些字段。
</code></pre><p><img width="723" height="397" referrerpolicy="no-referrer" src="/img/bVdni8M" alt="" title="" loading="lazy"/></p><p><img width="723" height="519" referrerpolicy="no-referrer" src="/img/bVdni8P" alt="" title="" loading="lazy"/></p><p><strong>线上部署测试效果</strong></p><p>我们在 MCP 应用市场中上架了一个版本的 DW-DBA-MCP 服务，在 VSCode 中安装 EP-Copilot 插件即可安装使用该服务。</p><p><img width="732" height="125" referrerpolicy="no-referrer" src="/img/bVdni8T" alt="" title="" loading="lazy"/></p><p>然后在聊天界面中选择agent模式即可让 LLMs 选择合适的工具处理您的提问（注意为服务配置环境变量）：</p><p><img width="536" height="706" referrerpolicy="no-referrer" src="/img/bVdni8U" alt="" title="" loading="lazy"/><br/><img width="505" height="804" referrerpolicy="no-referrer" src="/img/bVdni8Y" alt="" title="" loading="lazy"/></p><h2>五、未来规划</h2><p>在<strong>AI4DB</strong>（AI for Database）领域，AI 技术正颠覆传统数据库的运维与调优逻辑，推动其从依赖人工介入的被动响应模式，全面迈向可自主诊断、智能调优、故障自愈的全链路智能自治新阶段，大幅降低运维成本的同时提升了数据库系统的稳定性与运行效率。</p><p>而在<strong>DB4AI</strong>（Database for AI）方向，适配 AI 场景的数据库解决方案已实现关键突破：不仅具备高性能向量检索、复杂分析计算及强事务一致性等核心能力，还能原生支持文本、图像等多模态数据的一体化存储与管理，为 AI 模型训练与推理提供了高效、可靠的数据基座。</p><p>在技术格局剧变的背景下，DBA 的角色定位也迎来重构。传统意义上，DBA 即 Database Administrator（数据库管理员），核心聚焦于数据库的日常运维与技术保障；但随着 AI 技术的井喷式发展，DBA 已突破单一运维属性，可进阶为<strong>Data Business Architect（数据业务架构师</strong>）—— 借助 AI 工具与能力，DBA 能从海量数据中挖掘潜藏价值，打通数据与业务的链路，实现技术能力向业务价值的转化。</p><p>面向未来，DBA 团队将持续强化两大核心能力：一是筑牢数据安全防线，构建全周期数据安全治理体系；二是夯实工程化落地能力，推动智能技术与业务场景的深度融合。以此为基础，充分释放 DBA 在数据库 “智能自治运维” 与 “全域数据价值挖掘” 领域的双重价值，为企业数字化与智能化转型提供坚实的数据支撑。</p><h2>六、资源推荐</h2><table><thead><tr><th><strong>资源</strong></th><th><strong>内容</strong></th></tr></thead><tbody><tr><td><strong>MCP Server 社区仓库推荐</strong></td><td>-   <a href="https://link.segmentfault.com/?enc=1ZLaLQR83UlbJZilxPSqXQ%3D%3D.7WBSPh5qbpsG8xwYhHU02UHhRuGf2UZT37EaU0tZ35VZsNhpa2X9G8GzbGOWQBpvi2OBp46A0HZctaIO95KzS2hd0mtxRtVC2F6ToO9ElNv74cX1TRoAoP6eJOJg8sDc" rel="nofollow" target="_blank">https://github.com/modelcontextprotocol/servershttps://github.com/punkpeye/awesome-mcp-servers</a></td></tr><tr><td><strong>当前支持 MCP 协议的客户端应用</strong></td><td><a href="https://link.segmentfault.com/?enc=Bq0VgqeZWJxutuny1SnnCA%3D%3D.mPV4Yztm%2BgpAv30%2BXzA1W%2B08zwNP1Nb0EDwaNxMbKjpGPk0H3ducKJQs0caVWvcL" rel="nofollow" target="_blank">https://modelcontextprotocol.io/clients</a></td></tr><tr><td><strong>MCP 市场</strong></td><td>-   <strong>ModelScope：</strong> <a href="https://link.segmentfault.com/?enc=yFoPBFw%2FGKlPKwbirnL8uQ%3D%3D.DCAx9IjTBt%2BghFtDwafI2DPlmMPaYzBb%2BIjbiNjahaQ%3D" rel="nofollow" target="_blank">https://modelscope.cn/mcp</a></td></tr><tr><td><strong>百炼 MCP 市场：</strong></td><td><a href="https://link.segmentfault.com/?enc=CrgTIJh5A7T5vv9ZNOrJSA%3D%3D.1hTZpXYuMy8zDXks9MZOLiC2rAl3uGOn4uuQlsOR%2F%2FudQBDGN03zYh8E5bPOwmeU43Cy4mjjO%2BE8x7OHHcdfcg%3D%3D" rel="nofollow" target="_blank">https://bailian.console.aliyun.com/?tab=mcp#/mcp-market</a></td></tr></tbody></table><p><strong>参考资料：</strong></p><p>[1] 一文带你 "看见" MCP 的过程，彻底理解 MCP 的概念（<a href="https://link.segmentfault.com/?enc=zfAqbwniHoP8iU2ReAd3xg%3D%3D.Nu%2FjzYgx5Lrakg3jjB5dnRoh%2Bq2HsJ7KkOivCBQR8IHQNF%2BAXxT9oEanjq4xGy4J" rel="nofollow" target="_blank">https://developer.aliyun.com/article/1665090）</a></p><p>[2] 100行代码讲透MCP原理（<a href="https://link.segmentfault.com/?enc=uMJ889KiTU3Wnms96gvejA%3D%3D.dlwHNepW6vBgP%2BHYPcEljfJWkWIP9mGCg%2Bf6Ul1CrpjHTGzVj1mFYCnm254aoH9q2w9T3H5PhdnPvjeI7jCsq4cieZePZHs7AOGycrjHPdozsy734FtfXW0pNlPC%2BmqjQP1qPayyAgpVBa7yJffg8w%3D%3D" rel="nofollow" target="_blank">https://ai.programnotes.cn/p/100%E8%A1%8C%E4%BB%A3%E7%A0%81%E...</a></p><h3>往期回顾</h3><p>1. 项目性能优化实践：深入FMP算法原理探索｜得物技术</p><p>2. Dragonboat统一存储LogDB实现分析｜得物技术</p><p>3. 从数字到版面：得物数据产品里数字格式化的那些事</p><p>4. 一文解析得物自建 Redis 最新技术演进</p><p>5. Golang HTTP请求超时与重试：构建高可靠网络请求｜得物技术</p><h3>文 /少晖、洪兆</h3><p>关注得物技术，每周更新技术干货</p><p>要是觉得文章对你有帮助的话，欢迎评论转发点赞～</p><p>未经得物技术许可严禁转载，否则依法追究法律责任。</p>]]></description></item><item>    <title><![CDATA[以我两年多前端的血泪😭经验，给大家一点警示 悲伤的煎鸡蛋_cQXuXF ]]></title>    <link>https://segmentfault.com/a/1190000047461925</link>    <guid>https://segmentfault.com/a/1190000047461925</guid>    <pubDate>2025-12-09 17:02:48</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>工作两年多了，踩过了许多坑，希望大家不要踩，常常想如果我刚毕业就知道这些东西就好了，但是没有如果<br/>一个人现在做了他多年以后认为正确的事情，他是很幸运的<br/><img width="723" height="424" referrerpolicy="no-referrer" src="/img/bVdnjaU" alt="" title=""/></p><h3>一、永远不要期待领导主动加薪</h3><p>不会还有人期待着领导某一天主动找你，小张，你来一下办公室，我有点事情给你说<br/>到办公室后，领导：你最近表现不错，公司决定给你涨薪20%，下个月开始执行<br/>你一脸春梦样子</p><p>大哥醒醒吧，梦里才有！</p><p>现在大部分公司不会主动给员工加薪，能不降薪就算不错了，没有领导无缘无故能给员工加薪，绝大部分都是这样的，老板和员工本身就是利益冲突的，你挣的钱多了，老板怎么买法拉利呐</p><p>所以永远不要期待领导给你主动加薪资，你需要有筹码，有底气，当然筹码与底气很重要，但是更重要的是：你要主动争取</p><p>主动权要始终掌握在自己手中！</p><h3>二、永远不要裸辞</h3><p>少看网上的一句梦想仗剑走天涯，就裸辞冲到了318。</p><p>裸辞只会导致你找工作的时候更加被动，和hr聊薪资的时候更加被动，徒增你的焦虑</p><p>从某种角度来说，裸辞百害无一利，除非你在这家公司非常非常非常不爽了，再裸辞，当然你有足够多的钱另当别论，但是你大概率没有，都tm干程序员了，你能有多有钱？</p><p>不要裸辞，动了辞职的念头，那就着手准备，公司的活干的说得过去就行</p><p>慢慢找，一定要找到比现在待遇好的再辞职，不要降低标准，除非一直拿不到理想的薪资，不然不要将就，怕就怕这一将就，后面都得将就了。</p><h3>三、一开始干程序员你就得明白，你得走</h3><p>这个走有两层意思<br/>1、你得跳槽，刚开始的时候千万不能觉得安逸，不想走，不想跳槽， 懂得都懂，这行得跳槽涨薪 你可能说安逸，不累，不想走，行，你20多k，不累，不走，很好，你很聪明</p><p>怕就怕有哥们11-12k的贪图安逸不走，你说你这薪资安逸个吊毛啊，再安逸就废了</p><p>该走就走</p><p>2、你能干到40？ 大部分都够呛吧，如果40还是一线大头兵程序员，嗯，，，，，，很难，<br/>刚开始干程序员就得明白，得在短期内快速攒钱，年纪大了得谋求后路，别以为现在挣的还可以，就嘎嘎花钱，到你年纪大一点有的后悔，得攒钱留后路。</p><p><strong>坑位</strong><br/>技术大厂，前端-后端-测试，新一线和一二线城市等地均有<a href="https://link.segmentfault.com/?enc=DStH2cBorsoaXTKS5os6yg%3D%3D.S1pnkXaSOMHSsg4gqxgCAwRVqe9PqbnCE%2BNGFkhxRls%3D" rel="nofollow" target="_blank">坑位</a>，感兴趣可以试试。待遇和稳定性都不错~</p><p>四、要敢于要价格<br/>这个世界从来都撑死胆大的，饿死胆小的<br/>从某种角度来说，你值多少钱取决于你自己敢要多少钱，你说老板会觉得要10k的程序员有多大价值吗？</p><p>大胆点，敢于争取自己想要的价格才是正道！</p><h3>五、自信点，大家都那个b样</h3><p>世界是一个巨大的草台班子，你以为别人牛逼的很，其实他也以为你牛逼的很，都一样，自信点，都挺傻逼的</p><p>现在这家公司的老板说过一句话，使我受益无穷</p><p>人一定要有自信，大家都那样，你以为他牛逼，其实也就那样，时刻问问自己，凭啥他行，我不行</p><h3>六、问问自己有核心竞争力吗</h3><p>大部分人都没有，程序员的竞争力无非这几种<br/>1、名校学历<br/>2、github 500star+项目作者<br/>3、长期积累的博客<br/>4、社区有知名度、影响力（CSDN、掘金、知乎、头条等）<br/>5、项目有亮点、难度<br/>6、大厂实习工作经历<br/>7、竞赛奖牌<br/>没事多更新简历，多投一下，知道自己在市场上还能混的下去不</p><h3>七、踏踏实实卷一段时间</h3><p>很多人都在说不要卷。开玩笑，市场资源有限，不卷怎么行<br/>但是不要焦虑，踏踏实实的，认认真真的卷一段时间，自己有了提升后，在谋求发展。<br/>自身没有价值之前，说再多都是瞎掰扯，没屌用</p><p>俗称，耐得住寂寞，踏踏实实的做学问，这一点我得深刻反思</p><p>以上纯属瞎扯，如有不赞同，那就是你对</p><p>——转载自：吃饺子不吃馅</p>]]></description></item><item>    <title><![CDATA[《ESP32-S3使用指南—IDF版 V1.6》第五十四章 TCPServer实验 正点原子 ]]></title>    <link>https://segmentfault.com/a/1190000047461943</link>    <guid>https://segmentfault.com/a/1190000047461943</guid>    <pubDate>2025-12-09 17:02:15</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>第五十四章 TCPServer实验</h2><p>本章笔者重点讲解lwIP的Socket接口如何配置TCP服务器，并在此基础上实现收发功能。<br/>本章分为如下几个部分：<br/>54.1 Socket编程TCPServer连接流程<br/>54.2 硬件设计<br/>54.3 软件设计<br/>54.4 下载验证</p><h3>54.1 Socket编程TCPServer连接流程</h3><p>在实现TCP协议之前，用户需要按照以下步骤配置结构体sockaddr_in的成员变量，以便建立TCPServer连接：<br/>①：配置ESP32-S3设备连接网络（必须的，因为WiFi是无线通信，所以需搭建通信桥梁）。<br/>②：将sin_family设置为AF_INET，表示使用IPv4网络协议。<br/>③：设置sin_port为所需的端口号，例如8080。<br/>④：设置sin_addr.s_addr为本地IP地址。<br/>⑤：调用函数Socket创建Socket连接。请注意，该函数的第二个参数指定连接类型。SOCK_STREAM表示TCP连接，而SOCK_DGRAM表示UDP连接。<br/>⑥：调用函数bind绑定本地IP地址和端口号。<br/>⑦：调用函数listen 监听连接请求<br/>⑧：调用函数accept监听连接<br/>⑨：调用适当的收发函数来接收或发送数据。<br/>通过遵循这些步骤，用户可成功地配置并建立TCPServer连接，以实现数据的发送和接收。</p><h3>54.2 硬件设计</h3><h4>1.例程功能</h4><p>本章实验功能简介：<br/>本实验主要通过Socket编程接口实现了一个TCPServer服务器。这个客户端具有以下功能：<br/>①：可以通过按键发送TCPServer数据发送至客户端。<br/>②：能够接收客户端发送的数据。<br/>③：实时将接收到的数据显示在LCD屏幕上。<br/>通过这个实验，用户可深入了解TCP协议的工作原理，并掌握如何使用Socket编程接口来实现TCP通信。这对于开发基于TCP的网络应用程序非常有用，例如实时传输、文件传输等。</p><h4>2.硬件资源</h4><p>1）LED灯<br/>LED-IO1</p><p>2）XL9555<br/>IIC_INT-IO0（需在P5连接IO0）<br/>IIC_SDA-IO41<br/>IIC_SCL-IO42</p><p>3）SPILCD<br/>CS-IO21<br/>SCK-IO12<br/>SDA-IO11<br/>DC-IO40（在P5端口，使用跳线帽将IO_SET和LCD_DC相连）<br/>PWR- IO1_3（XL9555）<br/>RST- IO1_2（XL9555）</p><p>4）ESP32-S3内部WiFi</p><h4>3.原理图</h4><p>本章实验使用的WiFi为ESP32-S3的片上资源，因此并没有相应的连接原理图。</p><h3>54.3 软件设计</h3><h4>54.3.1 程序流程图</h4><p>程序流程图能帮助我们更好的理解一个工程的功能和实现的过程，对学习和设计工程有很好的主导作用。下面看看本实验的程序流程图：<br/><img width="480" height="452" referrerpolicy="no-referrer" src="/img/bVdnhm2" alt="" title=""/><br/>图54.3.1.1 程序流程图</p><h4>54.3.2 程序解析</h4><p>在本章节中，我们主要关注两个文件：lwip_demo.c和lwip_demo.h。lwip_demo.h文件主要定义了发送标志位并声明了lwip_demo函数，这部分相对简单，所以我们暂不详细解释。主要关注点是lwip_demo.c文件中的函数。在lwip_demo函数中，我们配置了相关的TCPServer参数，并创建了一个名为lwip_send_thread的发送数据线程。这个线程通过调用scokec函数来发送数据到服务器。接下来，我们将分别详细解释lwip_demo函数和lwip_send_thread任务。</p><pre><code>/* 需要自己设置远程IP地址 */
#define IP_ADDR   "192.168.101.33"

#define LWIP_DEMO_RX_BUFSIZE    100                      /* 最大接收数据长度 */
#define LWIP_DEMO_PORT          8080                    /* 连接的本地端口号 */
#define LWIP_SEND_THREAD_PRIO    ( tskIDLE_PRIORITY + 3 )    /* 发送数据线程优先级 */
/* 接收数据缓冲区 */
uint8_t g_lwip_demo_recvbuf[LWIP_DEMO_RX_BUFSIZE]; 

/* 发送数据内容 */
uint8_t g_lwip_demo_sendbuf[] = "ALIENTEK DATA \r\n";
/* 数据发送标志位 */
uint8_t g_lwip_send_flag;
int g_sock = -1;
int g_lwip_connect_state = 0;
static void lwip_send_thread(void *arg);


/**
 * @brief       发送数据线程
 * @param       无
 * @retval      无
 */
void lwip_data_send(void)
{
xTaskCreate(lwip_send_thread, "lwip_send_thread", 4096, 
NULL, LWIP_SEND_THREAD_PRIO, NULL);
}

/**
 * @brief       lwip_demo实验入口
 * @param       无
 * @retval      无
 */
void lwip_demo(void)
{
    struct sockaddr_in atk_client_addr;
    err_t err;
    int recv_data_len;
    char *tbuf;
    
    lwip_data_send();                               /* 创建发送数据线程 */
    
    while (1)
    {
sock_start:
        g_lwip_connect_state = 0;
        atk_client_addr.sin_family = AF_INET;                 /* 表示IPv4网络协议 */
        atk_client_addr.sin_port = htons(LWIP_DEMO_PORT);    /* 端口号 */
        atk_client_addr.sin_addr.s_addr = inet_addr(IP_ADDR);    /* 远程IP地址 */
        g_sock = socket(AF_INET, SOCK_STREAM, 0);/* 可靠数据流交付服务既是TCP协议 */
        memset(&amp;(atk_client_addr.sin_zero), 0,
               sizeof(atk_client_addr.sin_zero));
        
        tbuf = malloc(200);                                     /* 申请内存 */
        sprintf((char *)tbuf, "Port:%d", LWIP_DEMO_PORT);       /* 客户端端口号 */
        lcd_show_string(5, 170, 200, 16, 16, tbuf, MAGENTA);
        
        /* 连接远程IP地址 */
        err = connect(g_sock, (struct sockaddr *)&amp;atk_client_addr, 
sizeof(struct sockaddr));

        if (err == -1)
        {
            lcd_show_string(5, 190, 200, 16, 16, "State:Disconnect", MAGENTA);
            g_sock = -1;
            closesocket(g_sock);
            free(tbuf);
            vTaskDelay(10);
            goto sock_start;
        }

        lcd_show_string(5,190,200,16,16,"State:Connection Successful", MAGENTA);
        g_lwip_connect_state = 1;
        
        while (1)
        {
            recv_data_len = recv(g_sock,g_lwip_demo_recvbuf,
                                 LWIP_DEMO_RX_BUFSIZE,0);
            if (recv_data_len &lt;= 0 )
            {
                closesocket(g_sock);
                g_sock = -1;
                lcd_fill(5, 190, lcd_self.width,320, WHITE);
                lcd_show_string(5,190,200,16,16,"State:Disconnect", MAGENTA);
                free(tbuf);
                goto sock_start;
            }
            
            printf("%s\r\n",g_lwip_demo_recvbuf);
            vTaskDelay(10);
        }
    }
}

/**
 * @brief       发送数据线程函数
 * @param       pvParameters : 传入参数(未用到)
 * @retval      无
 */
void lwip_send_thread(void *pvParameters)
{
    pvParameters = pvParameters;
    
    err_t err;
    
    while (1)
    {
        while (1)
        {
            if(((g_lwip_send_flag &amp; LWIP_SEND_DATA) == LWIP_SEND_DATA) 
&amp;&amp; (g_lwip_connect_state == 1)) /* 有数据要发送 */
            {
                err = write(g_sock, g_lwip_demo_sendbuf,
                            sizeof(g_lwip_demo_sendbuf));
                
                if (err &lt; 0)
                {
                    break;
                }
                
                g_lwip_send_flag &amp;= ~LWIP_SEND_DATA;
            }
            
            vTaskDelay(10);
        }
        
        closesocket(g_sock);
    }
}</code></pre><p>上述源码中，我们首先创建一个发送任务，用来发送ESP32-S3设备的数据，然后配置TCPServer网络参数，并调用函数connect连接远程服务器，当连接成功时，系统进入接收轮询任务，反次，重新连接客户端。发送线程在发送前会检查标志位，有效时则通过write发送数据并重置标志位。</p><h3>54.4 下载验证</h3><p>在程序中，首先需要设置好能够连接的网络账号和密码。然后，使用笔记本电脑作为终端，确保它与ESP32-S3设备处于同一网络段内。当ESP32-S3设备成功连接到网络时，它的LCD显示屏上会显示相应的内容：<br/><img width="308" height="233" referrerpolicy="no-referrer" src="/img/bVdnhm4" alt="" title="" loading="lazy"/><br/>图54.4.1 设备连接到网络时，LCD显示的信息<br/>打开网络调试助手，然后配置网络参数，如TCPClient 协议、端口号等，设置内容如下图所示。</p><p><img width="723" height="265" referrerpolicy="no-referrer" src="/img/bVdnhm5" alt="" title="" loading="lazy"/><br/>在确保网络连接正常后，可以通过按下开发板上的KEY0按键来发送数据至网络调试助手。当网络调试助手接收到“ALIENTEK DATA”字符串时，它会在显示区域展示这个信息。此外，用户还可以在调试助手的发送区域自行输入要发送的数据，然后点击发送键，将数据发送至ESP32-S3设备。此时，ESP32-S3的串口将打印接收到的数据，具体操作和输出如下图所示。<br/><img width="723" height="82" referrerpolicy="no-referrer" src="/img/bVdnaJg" alt="" title="" loading="lazy"/><br/>图54.4.3 接收网络调试助手的数据</p>]]></description></item><item>    <title><![CDATA[火语言 RPA 表格核心表达式：.Rows/.Count/.Rows.Count/ItemArray]]></title>    <link>https://segmentfault.com/a/1190000047461950</link>    <guid>https://segmentfault.com/a/1190000047461950</guid>    <pubDate>2025-12-09 17:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>不管你用 RPA 做什么表格操作（存数据、提数据、整理数据），这 4 个都是 “操作表格行数据” 的万能工具 —— 不用懂复杂逻辑，记准 “是什么、怎么用” 就行！<br/>1、.Rows → 表格所有行的总称</p><table><thead><tr><th>含义</th><th>用法</th><th>避坑提醒</th></tr></thead><tbody><tr><td>表格中所有行的集合（不管行里有没有数据，空行也包含在内）</td><td>想操作表格的某一行、数表格有多少行，必须先通过<code>.Rows</code>找到 “所有行”，相当于 “入口”</td><td>单独用没用！比如只写<code>我的表格.Rows</code>，RPA 不知道要做什么，必须跟<code>.Count</code>或<code>[i]</code>搭配使用</td></tr></tbody></table><p>✅ 举例：我的表格.Rows → 就是 “名为‘我的表格’的表格里，所有的行”（不管有 5 行还是 50 行）。</p><p>2、.Count → 计数工具（统计集合数量）</p><table><thead><tr><th>含义</th><th>用法</th><th>避坑提醒</th></tr></thead><tbody><tr><td>给 “集合类数据” 统计数量，返回纯数字（比如 0、8、30）</td><td>只能跟在 “集合” 后面，用来数集合里有多少个元素，最常用的就是跟<code>.Rows</code>搭配，数表格行数</td><td>单独用无效！比如只写<code>.Count</code>，RPA 不知道要数什么；必须跟在 “要统计的集合” 后面（比如<code>.Rows</code>）</td></tr></tbody></table><p>✅ 举例：我的表格.Rows.Count→ 统计 “我的表格所有行” 的数量，返回数字（比如 12）。</p><p>3、.Rows.Count → 表格总行数（最常用）</p><table><thead><tr><th>含义</th><th>用法</th><th>避坑提醒</th></tr></thead><tbody><tr><td>先找到表格所有行（.Rows），再统计这些行的总数（.Count），最终得到纯数字</td><td>① 统计表格总行数（比如 “这个表格有多少行数据”）；②作为 “下一行写入位置”（表格有 N 行，下一行就写第 N 行）</td><td>不用手动加 1！行索引从 0 开始，比如总行数是 5，下一行就是第 5 行，直接用这个数字当写入位置即可</td></tr></tbody></table><p>✅ 举例：<br/>新建空表格 → 我的表格.Rows.Count = 0（没有任何行，统计结果为 0）；<br/>写入 4 行数据后 → 我的表格.Rows.Count = 4（统计结果为 4，下一行写第 4 行）；<br/>表格有 15 行空行 → 我的表格.Rows.Count = 15（空行也会被统计）。</p><p>4、.Rows[i].ItemArray → 提取某一行纯数据</p><table><thead><tr><th>含义</th><th>用法</th><th>避坑提醒</th></tr></thead><tbody><tr><td>先找到表格所有行（.Rows）→ 定位到第 i 行（[i]）→ 只提取这一行的 “纯文字 / 数字”（过滤格式、隐藏属性等多余信息）</td><td>从表格中提取某一行的干净数据，用来写入其他表格、保存文本等</td><td>1. i从 0 开始（第一行是[0]，第二行是[1]，不是从 1 开始）；2. 必须加.ItemArray！否则会带出格式信息，导致数据乱码或空白</td></tr></tbody></table><p>✅ 为什么要加.ItemArray？<br/>我的表格.Rows[i] 包含行的格式、行号等多余信息，RPA 无法直接使用；加.ItemArray后，只保留行内的纯数据（比如 “手机、2999 元、黑色”），RPA 能直接识别。<br/>✅ 举例：<br/>我的表格.Rows[0].ItemArray → 提取 “我的表格” 第一行的纯数据；<br/>我的表格.Rows[3].ItemArray → 提取 “我的表格” 第四行的纯数据。</p><h4>核心总结：</h4><table><thead><tr><th>表达式</th><th>核心</th><th>结果类型</th><th>使用场景</th></tr></thead><tbody><tr><td><code>.Rows</code></td><td>找所有行（表格行的入口）</td><td>行集合</td><td>必须搭配<code>.Count</code>或<code>[i]</code>使用，是操作行数据的基础入口</td></tr><tr><td><code>.Count </code></td><td>数数量（仅跟集合后用）</td><td>纯数字</td><td>仅跟在<code>.Rows</code>等集合后，统计集合内元素数量</td></tr><tr><td><code>.Rows.Count</code></td><td>总行数（直接用，不用 + 1）</td><td>纯数字</td><td>1. 统计表格总行数；2. 作为表格下一行写入位置</td></tr><tr><td><code>.Rows[i].ItemArray</code></td><td>提单行纯数据（i 从 0 开始，必加.ItemArray）</td><td>数据集合（文字 / 数字）</td><td>提取表格第 i 行的干净数据（无格式 / 多余信息），用于写入其他表格等操作</td></tr></tbody></table><p><strong>核心：统计行数 / 确定写入位置用.Rows.Count，提取单行纯数据用.Rows[i].ItemArray；而.Rows是找行的基础、.Count是计数工具，二者需搭配使用才有效。</strong></p>]]></description></item><item>    <title><![CDATA[2025专业横评：8大CRM 品牌系统 “业务 - 财务 - 管理” 协同能力解析与选型指南 率性的]]></title>    <link>https://segmentfault.com/a/1190000047461404</link>    <guid>https://segmentfault.com/a/1190000047461404</guid>    <pubDate>2025-12-09 16:07:05</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>企业“业务-财务-管理”全维度能力横评：从“协同效率”到“价值闭环”的分层竞争</h2><p>在数字化转型进入“深水区”的今天，企业对“业务-财务-管理”的<strong>全维度协同</strong>需求已从“可选”变为“必选”。无论是集团企业的多业态跨国运营，还是中小微企业的轻量化管理，能否打通数据孤岛、实现流程闭环、适配组织架构，直接决定了企业的运营效率与风险抵御能力。</p><p>本文选取<strong>超兔一体云、Brevo、Bitrix24、</strong> <strong>SAP</strong> <strong>、用友、管家婆、SugarCRM、Freshworks</strong>8个典型品牌，围绕<strong>全业务一体化数据底座、应收智能触发与回款联动、九级组织权限+自定义</strong> <strong>工作台</strong>三大核心维度展开横向对比，结合表格、流程图、脑图与雷达图，拆解各品牌的能力边界与选型逻辑。</p><h3>一、维度一：全业务一体化数据底座——从“打通模块”到“协同深度”的能力分层</h3><p>全业务一体化数据底座的核心价值是<strong>消除</strong> <strong>数据孤岛</strong>，实现“业务动作-数据流转-决策支撑”的闭环。其能力差异主要体现在<strong>打通模块的广度</strong>、<strong>数据协同的深度</strong>与<strong>适用场景的精准度</strong>三个层面。</p><h4>1.1 核心逻辑：从“点式集成”到“全栈协同”的进化</h4><p>全业务一体化的能力层级可通过以下脑图拆解：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047461406" alt="" title=""/></p><pre><code>mindmap
  root((全业务一体化数据底座))
    打通广度
      核心模块（CRM/进销存/财务）
      扩展模块（ERP/SRM/PLM/项目管理）
      办公模块（团队协作/客户联络中心）
    协同深度
      原生集成（无第三方依赖）
      数据实时同步
      跨系统业务联动（如线索→订单→库存→财务）
    适用场景
      集团企业（多业态/跨国）
      中小微企业（轻量级）
      销售前端（线索/客户管理）</code></pre><h4>1.2 品牌对比：从“集团级深度”到“前端聚焦”的能力矩阵</h4><p>下表从<strong>打通模块、协同深度、适用场景</strong>三个维度对比各品牌的核心能力：</p><table><thead><tr><th>品牌</th><th>打通核心模块</th><th>扩展模块覆盖</th><th>协同深度</th><th>适用场景</th></tr></thead><tbody><tr><td><strong>SAP</strong></td><td>CRM/ERP/SRM/PLM</td><td>BTP平台（跨系统）</td><td>原生深度集成+实时同步</td><td>集团企业（多业态/跨国）</td></tr><tr><td><strong>Bitrix24</strong></td><td>CRM/进销存/财务</td><td>项目/协作/联络中心</td><td>全栈办公云原生集成</td><td>中小/中大型（全流程协同）</td></tr><tr><td><strong>用友</strong></td><td>CRM/进销存/财务</td><td>ERP</td><td>原生集成+实时同步</td><td>中大型企业（供应链/财务联动）</td></tr><tr><td><strong>超兔一体云</strong></td><td>CRM/进销存/财务</td><td>-</td><td>原生集成+业务联动</td><td>成长型企业（快速扩张）</td></tr><tr><td><strong>Brevo</strong></td><td>CRM/进销存/财务</td><td>-</td><td>原生集成+基础联动</td><td>中小微企业（高性价比）</td></tr><tr><td><strong>管家婆</strong></td><td>进销存/财务</td><td>-</td><td>轻量化集成（简单联动）</td><td>小微零售/批发</td></tr><tr><td><strong>SugarCRM</strong></td><td>CRM</td><td>-</td><td>无后端集成</td><td>销售前端（线索/客户管理）</td></tr><tr><td><strong>Freshworks</strong></td><td>CRM（线索/客户）</td><td>-</td><td>无后端集成</td><td>零售/电销（线索转化）</td></tr></tbody></table><h4>1.3 关键结论：</h4><ul><li><strong>集团级深度协同</strong>：SAP（Business Suite+ BTP平台）、Bitrix24（全栈办公云）可覆盖“ERP→CRM→PLM→协作”的全链路，适合多业态、跨国企业；</li><li><strong>成长型企业适配</strong>：超兔、Brevo、用友聚焦“CRM/进销存/财务”核心模块，兼顾协同效率与学习成本；</li><li><strong>前端轻量级管理</strong>：SugarCRM、Freshworks仅覆盖销售前端，适合以“线索转化”为核心的团队（如电销、零售）。</li></ul><h3>二、维度二：应收智能触发与回款联动——从“流程自动化”到“风险预判”的闭环能力</h3><p>应收管理的核心是<strong>从“被动核销”到“主动管控”</strong> ，其能力差异体现在<strong>流程自动化程度</strong>、<strong>风险预判精度</strong>与<strong>财务业务联动深度</strong>三个层面。</p><h4>2.1 核心流程：应收-开票-回款的闭环逻辑</h4><p>以<strong>超兔一体云</strong>为例，其应收触发与回款联动的流程可通过以下时序图拆解：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047461407" alt="" title="" loading="lazy"/></p><pre><code>sequenceDiagram
  participant 销售部 as 销售部（创建订单）
  participant 系统 as 超兔一体云系统
  participant 财务部 as 财务部（开票/回款）
  participant 仓库 as 仓库（发货）
  
  销售部-&gt;&gt;系统: 签订销售合同（触发应收规则）
  系统-&gt;&gt;系统: 自动拆分多期应收（按合同付款方式）
  系统-&gt;&gt;财务部: 同步应收记录（关联订单ID）
  仓库-&gt;&gt;系统: 确认发货（更新应收状态为“待开票”）
  财务部-&gt;&gt;系统: 开具发票（关联对应应收期）
  财务部-&gt;&gt;系统: 收到回款（匹配应收记录核销）
  系统-&gt;&gt;销售部: CRM同步客户回款状态（标记“已结清”）
  系统-&gt;&gt;系统: 逾期预警（超账期3天触发短信提醒）</code></pre><h4>2.2 品牌对比：从“跨国合规”到“基础关联”的能力分层</h4><p>下表从<strong>自动拆分应收、关联开票回款、风险管控</strong>三个维度对比各品牌的核心功能：</p><table><thead><tr><th>品牌</th><th>自动拆分多期应收</th><th>关联开票回款</th><th>风险管控能力</th><th>特殊功能</th></tr></thead><tbody><tr><td><strong>SAP</strong></td><td>✅（多币种/准则）</td><td>✅（全流程关联）</td><td>✅（跨国合规预警）</td><td>BTP平台支持跨业态财务协同</td></tr><tr><td><strong>Bitrix24</strong></td><td>✅</td><td>✅（关联订单）</td><td>✅（销售漏斗+流失预警）</td><td>客户沟通记录集中存储</td></tr><tr><td><strong>超兔一体云</strong></td><td>✅</td><td>✅（三角联动）</td><td>✅（账期限制发货）</td><td>应收触发规则自定义</td></tr><tr><td><strong>Brevo</strong></td><td>✅</td><td>✅</td><td>✅（流程规避）</td><td>交易邮件通道（财务邮件高打开率）</td></tr><tr><td><strong>用友</strong></td><td>✅</td><td>✅</td><td>✅（基础预警）</td><td>业财实时同步</td></tr><tr><td><strong>管家婆</strong></td><td>❌（手动拆分）</td><td>✅（简单关联）</td><td>❌</td><td>轻量化操作</td></tr><tr><td><strong>SugarCRM</strong></td><td>❌</td><td>❌（需第三方）</td><td>❌</td><td>无</td></tr><tr><td><strong>Freshworks</strong></td><td>❌</td><td>❌</td><td>❌</td><td>无</td></tr></tbody></table><h4>2.3 关键结论：</h4><ul><li><strong>集团级风险管控</strong>：SAP（多币种/多会计准则）、Bitrix24（销售漏斗+流失预警）可覆盖复杂场景的风险预判；</li><li><strong>成长型企业闭环</strong>：超兔、Brevo通过“自动拆分应收+关联开票回款”实现流程闭环，适合有分期收款需求的企业；</li><li><strong>小微基础管理</strong>：管家婆仅支持简单关联，适合“款到发货”的轻量化场景；</li><li><strong>前端缺失</strong>：SugarCRM、Freshworks无原生财务功能，需依赖第三方工具补充。</li></ul><h3>三、维度三：九级组织权限+自定义工作台——从“层级适配”到“效能聚焦”的精准能力</h3><p>组织权限与工作台的核心价值是<strong>适配企业层级架构</strong>，让“管理层看全局、基层看任务”，实现“权限安全”与“效率提升”的平衡。</p><h4>3.1 核心逻辑：从“层级覆盖”到“岗位聚焦”的设计</h4><p>九级组织权限与自定义工作台的能力可通过以下脑图拆解：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047461408" alt="" title="" loading="lazy"/></p><pre><code>mindmap
  root((九级组织权限+自定义工作台))
    组织权限
      层级覆盖（集团→分公司→部门→小组）
      权限控制（数据访问/操作权限/角色关联）
      安全保障（敏感数据隔离/操作日志）
    自定义工作台
      岗位适配（管理层/销售/财务/客服）
      指标聚焦（核心数据/任务提醒）
      操作简化（低学习成本）</code></pre><h4>3.2 品牌对比：从“集团级精准”到“前端轻量”的能力矩阵</h4><p>下表从<strong>组织权限层级、</strong> <strong>工作台</strong> <strong>定制能力、适用岗位</strong>三个维度对比各品牌的核心功能：</p><table><thead><tr><th>品牌</th><th>组织权限层级</th><th>自定义工作台能力</th><th>核心功能</th><th>适用岗位需求</th></tr></thead><tbody><tr><td><strong>SAP</strong></td><td>九级</td><td>✅（多维度定制）</td><td>集团级关键指标看板（如全球营收/库存）</td><td>管理层（全局视角）</td></tr><tr><td><strong>Bitrix24</strong></td><td>九级</td><td>✅（岗位专属）</td><td>实时看板（销售绩效/客服效率/回款进度）</td><td>全岗位（从基层到管理层）</td></tr><tr><td><strong>用友</strong></td><td>九级</td><td>✅（业财指标）</td><td>供应链/财务关键数据（如库存周转/应收占比）</td><td>中大型企业各部门</td></tr><tr><td><strong>超兔一体云</strong></td><td>九级</td><td>✅（专属驾驶舱）</td><td>销售/财务核心指标（如本月业绩/逾期应收）</td><td>成长型企业各岗位</td></tr><tr><td><strong>Brevo</strong></td><td>九级</td><td>✅（简易定制）</td><td>营销核心指标（如邮件打开率/线索转化量）</td><td>中小微企业（低学习成本）</td></tr><tr><td><strong>管家婆</strong></td><td>基础层级（≤3级）</td><td>❌（固定模板）</td><td>库存/销售基础数据（如今日销量/库存余量）</td><td>小微团队（快速上手）</td></tr><tr><td><strong>SugarCRM</strong></td><td>基础角色（≤2级）</td><td>❌（销售聚焦）</td><td>线索/客户跟进数据（如未跟进线索数/客户活跃度）</td><td>销售团队（前端管理）</td></tr><tr><td><strong>Freshworks</strong></td><td>轻量级（≤2级）</td><td>❌（线索转化）</td><td>线索评分/跟进任务（如高价值线索数/待跟进任务）</td><td>电销/零售（前端效率）</td></tr></tbody></table><h4>3.3 关键结论：</h4><ul><li><strong>集团级适配</strong>：SAP、Bitrix24、用友支持九级权限，可覆盖“集团→分公司→部门→小组”的复杂架构；</li><li><strong>成长型精准</strong>：超兔、Brevo通过“九级权限+专属工作台”平衡安全与效率，适合快速扩张的企业；</li><li><strong>小微轻量化</strong>：管家婆、SugarCRM、Freshworks仅支持基础权限，适合“扁平化”团队；</li></ul><h3>四、综合能力雷达图：各品牌的“全维度价值评分”</h3><p>基于三大维度的能力表现，我们对各品牌进行<strong>10分制评分</strong>（10分为满分，代表能力覆盖全面且深度足够），结果如下：</p><table><thead><tr><th>品牌</th><th>全业务一体化</th><th>应收管控</th><th>组织权限+工作台</th><th>综合得分</th></tr></thead><tbody><tr><td><strong>SAP</strong></td><td>10</td><td>10</td><td>10</td><td>30</td></tr><tr><td><strong>Bitrix24</strong></td><td>9</td><td>8</td><td>9</td><td>26</td></tr><tr><td><strong>用友</strong></td><td>8</td><td>9</td><td>8</td><td>25</td></tr><tr><td><strong>超兔一体云</strong></td><td>9</td><td>8</td><td>8</td><td>25</td></tr><tr><td><strong>Brevo</strong></td><td>7</td><td>7</td><td>7</td><td>21</td></tr><tr><td><strong>管家婆</strong></td><td>5</td><td>5</td><td>5</td><td>15</td></tr><tr><td><strong>SugarCRM</strong></td><td>3</td><td>2</td><td>3</td><td>8</td></tr><tr><td><strong>Freshworks</strong></td><td>2</td><td>1</td><td>2</td><td>5</td></tr></tbody></table><h3>五、选型建议：匹配“企业阶段”与“核心需求”</h3><p>根据企业规模与核心需求，可快速定位适配品牌：</p><ol><li><strong>集团企业（多业态/跨国）</strong> ：优先选择<strong>SAP</strong>（全模块深度协同）或<strong>Bitrix24</strong>（全栈办公云）；</li><li><strong>中大型企业（业财协同）</strong> ：选择<strong>用友</strong>（供应链+财务深度联动）或<strong>超兔一体云</strong>（成长型闭环）；</li><li><strong>中小微企业（高性价比）</strong> ：选择<strong>Brevo</strong>（轻量化协同+低学习成本）或<strong>管家婆</strong>（简单易上手）；</li><li><strong>销售前端团队</strong>：选择<strong>SugarCRM</strong>（线索管理）或<strong>Freshworks</strong>（线索转化）；</li></ol><h3>结语：从“功能堆叠”到“价值闭环”的未来</h3><p>企业“业务-财务-管理”的全维度协同，本质是<strong>用数据驱动决策</strong>，用流程降低风险，用架构适配成长。各品牌的竞争已从“功能堆叠”转向“价值闭环”——谁能更精准地匹配企业阶段、更深度地打通流程、更安全地管控权限，谁就能成为企业数字化转型的“基础设施”。</p><p>对于企业而言，选型的核心逻辑不是“选最好的”，而是“选最适合的”——结合自身规模、业务模式与长期战略，才能真正实现“协同效率”到“价值增长”的跨越。</p>]]></description></item><item>    <title><![CDATA[从“隐式内存治理”到“Java 内存全景分析”：SysOM 系统诊断的实践与进阶 阿里云云原生 ]]></title>    <link>https://segmentfault.com/a/1190000047461417</link>    <guid>https://segmentfault.com/a/1190000047461417</guid>    <pubDate>2025-12-09 16:06:11</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>作者：肖杰韬(六滔)</p><h2>背景</h2><p>在前一篇文章《<a href="https://link.segmentfault.com/?enc=Ihi%2B8Ct9t2%2FChWY4A%2B729A%3D%3D.f3kIknOxF2PLu2IEwxAOs5DaOXC9BGxCZdUbKX0Md4YyBc6i4owo5rPr7V%2Fc8s5bWaZKe8pUKRWPggbfMP0MkPZx4%2FqdebI3xm6PbbbagG8NU%2FRDn1KlAHuLt6Ku6Y81ZdqAJ%2FhK%2B11SFhKlg9%2FOt%2BPPTtKtGxPPAFPkzDWNhUNgYM%2Ba%2FlKw%2BJevVrQJEK8o" rel="nofollow" target="_blank">一次内存诊断，让资源利用率提升 40%：揭秘隐式内存治理</a>》 <strong>[</strong> <strong>1]</strong> 中，我们系统性地剖析了云原生环境中隐性内存开销的诊断方法，通过 SysOM 系统诊断实现了对节点/Pod 级由文件缓存、共享内存等系统级内存资源异常消耗的精准定位。</p><p>然而，部分场景下内存异常仍可能源于应用进程本身的内存申请，但是对于应用内存泄漏问题，尽管是应用的开发者，也需要投入大量的精力去利用对应语言的内存分析工具去找出根因；以 Java 应用为例，当传统线下 IDC 集群中的 Java 应用完成云原生架构转型后，伴随容器化封装与资源配额管控的实施，用户普遍反馈 Java 应用 Pod 出现持续性内存超限及 Kubernetes OOMKilled 事件。这一系列现象主要集中在三个关键矛盾点：</p><ol><li><strong>容器内存监控与 JVM 堆内存的显著差异：</strong> Pod 内存占用常超出 JVM 堆内存（含堆外内存）数倍，形成“消失的内存”谜团。</li><li><strong>容器化改造后的 OS 兼容性问题：</strong> 同一业务系统在切换 OS 或容器化后，出现内存占用模式突变。</li><li><strong>工具链覆盖盲区：</strong> 传统 Java 内存分析工具无法覆盖 JNI 内存、LIBC 内存等非 JVM 内存区域。</li></ol><p>为此，<a href="https://link.segmentfault.com/?enc=QGwXHat%2FG0SdC46h211FYw%3D%3D.8B6IP2WcnNbeu%2FwkoPU96vuWFOpnCzObxTlbgAr8u04BVf%2FJ0tNl%2FuVHn1ThHNHl6n453NOlVDsxVQDZ1aMuUus85%2BrJ0XX72n%2BdFwvcd7nf8tX07BghX%2Bk%2FbY6F5nJtOgZnCx6wpXL8kuBkB2UsKQ%3D%3D" rel="nofollow" target="_blank">云监控 2.0</a> <strong>[</strong> <strong>2]</strong> 中的 SysOM 系统诊断对应用内存进一步深挖，结合应用和操作系统的角度实现对主机、容器运行时及具体的 Java 应用进程进行内存占用拆解，快速有效地识别出 Java 内存占用的元凶。</p><h2>Java 内存全景分析</h2><p>为了找出消失的内存，我们首先要了解 Java 进程的主要内存组成以及现有工具和监控主要覆盖的部分；如下图所示可分为：</p><h4>JVM 内存</h4><ul><li><strong>堆内存：</strong> 可通过 -Xms/-Xmx 参数控制，内存大小可通过 memorymxbean 等获取。</li><li><strong>堆外内存：</strong> 包括元空间、压缩类空间、代码缓冲区、直接缓冲、线程栈等内存组成；它们分别可以通过 -XX:MaxMetaspaceSize（元空间）、-XX:CompressedClassSpaceSize（压缩类空间）、-XX:ReservedCodeCacheSize（代码缓冲区）、-XX:MaxDirectMemorySize （直接缓冲）、-Xss（线程栈）参数限制。</li></ul><h4>非 JVM 内存</h4><ul><li><strong>JNI 本地内存：</strong> 即通过本地方法接口调用 C、C++ 代码（原生库），并在这部分代码中调用 C 库（malloc）或系统调用（brk、mmap）直接分配的内存。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047461419" alt="image" title="image"/></p><h2>Java 常见“内存泄露”</h2><h3>JNI 内存泄漏</h3><p>经过上一章中对 Java 内内存全景的分析，其实已经可以揭开第一个容易造成内存黑洞的隐藏 Boss-<strong>JNI 内存</strong>，因为这部分内存暂时没有工具可以获取其占用大小。</p><p>通常来说，编写相关业务代码的同学会认为代码中没有使用本地方法直接调用 C 库，所以不会存在这些问题，但是代码中引用的各种包却有可能会使用到 JNI 内存，比如说经典的使用 ZLIB 压缩库不当导致的 JNI 泄漏问题 <strong>[</strong> <strong>3]</strong> 。</p><h3>LIBC 内存管理特性</h3><p>JVM 向 OS 申请内存的中间，还存在着一层中间层 -C 库，JVM 调用 malloc、free 申请/释放内存的过程中其实还要经过这一个二道贩子；以 gibc 中默认的内存分配器 ptmalloc 为例 glibc 的 ptmalloc 内存分配器存在以下特征：</p><ul><li><strong>Arena 机制：</strong> 每个线程维护 64M Arena，多线程场景下易产生内存碎片</li><li><strong>Top Chunk 管理：</strong> 内存空洞导致无法及时归还 OS</li><li><strong>Bins 缓存策略：</strong> JVM 释放的内存暂存于 bins 中，造成统计偏差 [4-5]</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047461420" alt="image" title="image" loading="lazy"/></p><h3>Linux 透明大页（THP）影响</h3><p>在 OS 层，Linux 中的透明大页（Transparent Huge Page）机制也是造成 JVM 内存和实际内存差异的一大元凶。简单来说，THP 机制就是 OS 会将 4kb 页变成 2M 的大页，从而减少 TLB miss 和缺页中断，提升应用性能，但是也带来了一些内存浪费。如应用申请了一段 2M 的虚拟内存，但实际只用了里面的 4kb，但是由于 THP 机制，OS 已经分配了一个 2M 的页了 <strong>[6</strong> <strong>]</strong> 。</p><h2>SysOM Java 内存诊断实践</h2><p>下面将以汽车行业客户在从线下 idc 集群迁移至云上 ACK 集群时遇到的由于 JNI 内存泄漏导致 Pod 频繁 OOM 为例，介绍如何通过<a href="https://link.segmentfault.com/?enc=q%2Bd9mLp9eYNWmSBt1qQMHA%3D%3D.HQmvS8juMtfbgWbkfJPMOGsni%2F0zYogl0uXkK0eSgiuH9XBuRKtAE0glZKHyf8mw7PnAmqfoAqwqJ7fu7IyCuJFX8qRHe%2Fp5aB5c8W0o3waWPvSoNNk4af%2FoXDwhy5ydvxy18K3yxxcv78hi8CUXPw%3D%3D" rel="nofollow" target="_blank">云监控 2.0</a> 的 SysOM 系统诊断来一步步找出 Java 内存占用的元凶。</p><p>诊断使用限制：</p><ul><li>目前仅支持 openJDK 1.8 以上版本</li><li>使用 JNI 内存 Profiling 功能需要至操作系统控制台先对实例进行纳管 <strong>[</strong> <strong>3]</strong> ，有一定的资源和性能开销（内存占用根据符号大小最高达 300MB）</li></ul><h3>C2 compiler JIT 内存膨胀案例</h3><h4>案例背景</h4><p>某汽车客户在 ACK 集群迁移过程中，多个 Java 服务 Pod 出现偶发性 OOM。特征表现为：</p><ul><li>Pod 内存接近限制时触发 OOM</li><li>JVM 监控显示内存正常</li><li>无明显请求异常或流量波动</li></ul><h4>排查过程</h4><ul><li>尝试在内存高水位时对 Pod 发起内存全景分析。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047461421" alt="image" title="image" loading="lazy"/></p><ul><li>我们可以了解到当 Pod 中容器内存使用已经接近 limit，从诊断结论和容器内存占用分析中，我们可以看到容器内存主要是由于 Java 进程内存占用导致。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047461422" alt="image" title="image" loading="lazy"/></p><p>对 Java 进程发起内存分析，查看诊断报告。报告展示了 Java 进程所在 Pod 和容器的 rss 和 WorkingSet（工作集）内存信息、进程 Pid、JVM 内存使用量（即 JVM 视角的内存使用量）、Java 进程内存使用量（进程实际占用内存），进程匿名用量以及进程文件内存用量。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047461423" alt="image" title="image" loading="lazy"/></p><p>通过诊断结论和 Java 内存占用饼图我们可以发现，进程实际内存占用比 JVM 监控显示的内存占用大 570M，全都由 JNI 内存所贡献 <strong>[</strong> <strong>4]</strong> 。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047461424" alt="image" title="image" loading="lazy"/></p><p>开启 JNI（Java Native Interface）内存分配 profiling，报告列出当前 Java 进程 JNI 内存分配调用火焰图，火焰图中为所有分配 JNI 内存的调用路径。（说明：由于是采样采集，火焰图中的内存大小不代表实际分配大小）。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047461425" alt="image" title="image" loading="lazy"/></p><ul><li>从内存分配火焰图中，我们可以看到主要的内存申请为 C2 compiler 正在进行代码 JIT 预热；</li><li>但是由于诊断的过程中没有发现 pod 有内存突增；所以我们进一步借助可以常态化运行的 Java CPU 热点追踪功能 <strong>[</strong> <strong>5]</strong> 尝试抓取内存升高时的进程热点，并通过热点对比 <strong>[</strong> <strong>6]</strong> 尝试对内存正常时的热点进行对比。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047461426" alt="image" title="image" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047461427" alt="image" title="image" loading="lazy"/></p><ul><li>通过热点栈和热点分析对比，发现内存突增时间点的 cpu 栈也是 c2 compiler 的 JIT 栈，且 c2 compiler 热点前有部分业务流量突增，且业务代码使用了大量反射操作（反射操作会导致 c2 compiler 进行新的预热）。</li></ul><h4>结论和解决方案</h4><p>C2 compiler JIT 过程申请 JNI 内存，且由于 glibc 内存空洞等原因导致申请内存放大且延时释放。</p><ol><li>调整 C2 compiler 参数，让其编译策略更保守，可以尝试调整相关参数，观察内存消耗变化。</li><li>调整 glibc 环境变量 MALLOC_TRIM_THRESHOLD_，让 glibc 及时将内存释放回操作系统。</li></ol><h2>总结</h2><p>通过系统化的内存诊断方法，我们得以穿透 JVM 黑盒，揭示 JNI、LIBC 及 OS 层面的内存管理特性。阿里云操作系统控制台的内存全景分析功能，为容器化 Java 应用提供了从进程级到系统级的立体化诊断能力，帮助开发者精准定位内存异常根源，有效避免 OOM 事件的发生。</p><p><strong>相关链接：</strong></p><p>[1]《<a href="https://link.segmentfault.com/?enc=%2BPjOue6lOcgmkn4ORYZFuA%3D%3D.%2FEG6UJUNRlmj%2FqS2cB%2BxSwLrEMQCJ9HHBHLr0OiFaT%2Ba2ZRyfXRUz3s8Tx3LGQcgL3bovcHlOmxi4ovQtezSN%2Bwowq4pXVyiyLcE8V5%2FB%2BfD23R8l7PdPALnEH0ki3mu9AD2m94alMteVDXFohwlM1QOCGykeu6BXw9%2F4QJgm2VnXymOaikyLgf1SnuXyhgg" rel="nofollow" target="_blank">一次内存诊断，让资源利用率提升 40%：揭秘隐式内存治理</a>》</p><p>[2] 云监控-ECS 洞察-SysOM 系统诊断</p><p><a href="https://link.segmentfault.com/?enc=XQq2GcJ3UxyZksZm9WiQtg%3D%3D.%2Fzdhfpkrth1199rda%2BH7PjdKarsxoaS8XC8cKX6%2B7bg8808hcpwKCJUTyWCdP82KlUBQraiPi2tngx%2FOmzP9MptR8VUSlyNsVXRtECzNukjLpKsTfH4vsNQSJIaDFI8Bs7NY6c%2Bs6EfNScZalreOh0Z6mTNZoWhkAY5JWxd9OBgqAkFHd5Lp%2F16P2S2zKkI5" rel="nofollow" target="_blank">https://cmsnext.console.aliyun.com/next/region/cn-shanghai/wo...</a></p><p>[3] 操作系统控制台实例纳管</p><p><a href="https://link.segmentfault.com/?enc=xyBrh201ovOYrrdj2bX3gA%3D%3D.QWXIMptLBB80%2BQZi2yEnKfBJ4tuAQurPNPhPMtuCWBMQ3QiqvdEs%2BRWEzll89UpihyU6zx5NzrzTx%2F9MAgFOh5tXOIChQYJ3hPTixF3wfFyVQrY8p%2FsAEco0Gr39MV7EXeXnQR9ubHbJXZpt92dSUsEZI7MhNV6EzD%2Bb%2BQ1QA9C3xplEj1sCfb24LNNINBIhSfEoBtO7%2FtpircTw37%2FMSUW4xS8duSBWVNMWPEP37rvz1i2RjJkXqp38Wm8XmdOV" rel="nofollow" target="_blank">https://help.aliyun.com/zh/alinux/user-guide/system-managemen...</a></p><p>[4] 操作系统控制台 Java 内存诊断</p><p><a href="https://link.segmentfault.com/?enc=rX%2BBoV4ylh52LQNV3GUn2w%3D%3D.ZSbnMhPOZn4uN88mEHC8Si%2BKh96BV9dd0fr3q418%2Fld4srt8gLxsfnGHG3%2BDf39Vgpgz6JvF7irfnQQHbm%2FjfHerxE70iIw2iuwvp9WZvbOcd%2BG9qlUxPPBFY%2F6XEdHYw0qQ7rbz4McgViJTNCItLxggnueBnoWzOayQkEaFC9TR%2FlBQ3eoPxBJ0wmoJEd7KDVN3gmVAlvJL2pfbQsoUWp1dIS49NBcIzX4fzemwsxaM8h5ku5FRjE2V0qRndp4k" rel="nofollow" target="_blank">https://help.aliyun.com/zh/alinux/user-guide/java-memory-diag...</a></p><p>[5] 操作系统控制台热点追踪</p><p><a href="https://link.segmentfault.com/?enc=Mv%2B%2FGA0ergPB3pVhhLeMMQ%3D%3D.H6wmJz%2Bp9jDuGJuqe%2BEXzOZPfjv5%2BKtGoXYBrAr0xv7AGGL%2BigXUPc9nDvv7mtnPIK39%2FckCveq5LrbNgx0mS2RvaPdyJ45OYc7TueQDCvQ%3D" rel="nofollow" target="_blank">https://help.aliyun.com/zh/alinux/user-guide/process-hotspot-...</a></p><p>[6] 操作系统控制台热点对比分析</p><p><a href="https://link.segmentfault.com/?enc=haT5OvRRamiYYtAQ0V0Phg%3D%3D.t14nKVUAyW6tuUcogUQtsyXdQIbTT7lVfpTi5V7FvzeGq6v5N%2B3V%2B8MvGcfbYLyOhobbkjxvgMAy%2BsuSqQyxnMsf3vQ9R3D88ZVw33QLeGo%3D" rel="nofollow" target="_blank">https://help.aliyun.com/zh/alinux/user-guide/hot-spot-compara...</a></p>]]></description></item><item>    <title><![CDATA[了解nginx huaweichenai ]]></title>    <link>https://segmentfault.com/a/1190000047461537</link>    <guid>https://segmentfault.com/a/1190000047461537</guid>    <pubDate>2025-12-09 16:05:25</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>一：nginx能做什么</h2><ol><li>Web服务器</li><li>反向代理</li><li>负载均衡</li><li>正向代理</li></ol><h2>二：Web服务器</h2><p>可以作为独立的 Web 服务器，直接处理和响应 HTTP/HTTPS 请求，静态文件（如 HTML、CSS、JavaScript、图片等）的传输效率非常高</p><p>简单配置</p><pre><code>server {
    listen       80;                                                         
    server_name  localhost;                                               
    client_max_body_size 1024M;
    location / {
        root   /data/www/test;
        index  index.html;
    }

    # 所有静态请求都由nginx处理，存放目录为/data/www/file 
    location ~ \.(gif|jpg|jpeg|png|bmp|swf|css|js)$ {  
        root    /data/www/file;  
    }  
}</code></pre><h2>三：反向代理</h2><p>反向代理应该是Nginx做的最多的一件事了，什么是反向代理呢，以下是百度百科的说法：反向代理（Reverse Proxy）方式是指以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器。简单来说就是真实的服务器不能直接被外部网络访问，所以需要一台代理服务器，而代理服务器能被外部网络访问的同时又跟真实服务器在同一个网络环境，当然也可能是同一台服务器，端口不同而已。</p><p>简单配置</p><pre><code>server {  
    listen       80;                                                         
    server_name  localhost;                                               
    client_max_body_size 1024M;
    location / {
        proxy_pass https://localhost:8080;
        proxy_set_header Host $host:$server_port;
    }
}</code></pre><p>当我们访问localhost的时候，就相当于访问localhost:8080</p><h2>四：负载均衡</h2><p>负载均衡也是Nginx常用的一个功能，负载均衡其意思就是分摊到多个操作单元上进行执行，例如Web服务器、FTP服务器、企业关键应用服务器和其它关键任务服务器等，从而共同完成工作任务。简单而言就是当有2台或以上服务器时，根据规则随机的将请求分发到指定的服务器上处理，负载均衡配置一般都需要同时配置反向代理，通过反向代理跳转到负载均衡。而Nginx目前支持自带3种负载均衡策略，还有2种常用的第三方策略。</p><h3>1：策略一：RR（默认）</h3><p>每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除此服务器</p><p>简单配置</p><pre><code>upstream test {
    server localhost:8080;
    server localhost:8081;
}
server {
    listen       80;                                                         
    server_name  localhost;                                               
    client_max_body_size 1024M;
    location / {
        proxy_pass https://test;
        proxy_set_header Host $host:$server_port;
    }
}</code></pre><p>这里我配置了2台服务器，当我们访问localhost的时候，会默认跳转到localhost:8080，Nginx会自动判断服务器的状态，如果这个服务器处于不能访问（服务器挂了），就不会跳转到这台服务器而是跳转到localhost:8081，所以也避免了一台服务器挂了影响使用的情况</p><h3>2：策略二：权重</h3><p>指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况</p><p>简单配置</p><pre><code>upstream test {
        server localhost:8080 weight=9;
        server localhost:8081 weight=1;
    }
server {
    listen       80;                                                         
    server_name  localhost;                                               
    client_max_body_size 1024M;
    location / {
        proxy_pass https://test;
        proxy_set_header Host $host:$server_port;
    }
}</code></pre><p>10次一般只会有1次会访问到8081，而有9次会访问到8080</p><h3>3：策略三：ip_hash</h3><p>上面的2种策略都有一个问题，那就是下一个请求来的时候请求可能分发到另外一个服务器，当我们的程序不是无状态的时候（采用了session保存数据），这时候就有一个很大的很问题了，比如把登录信息保存到了session中，那么跳转到另外一台服务器的时候就需要重新登录了，所以很多时候我们需要一个客户只访问一个服务器，那么就需要用iphash了，iphash的每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。</p><p>简单配置</p><pre><code>upstream test {
        ip_hash;
        server localhost:8080;
        server localhost:8081;
    }
server {
    listen       80;                                                         
    server_name  localhost;                                               
    client_max_body_size 1024M;
    location / {
        proxy_pass https://test;
        proxy_set_header Host $host:$server_port;
    }
}</code></pre><h3>4：策略四：fair（第三方）</h3><p>按后端服务器的响应时间来分配请求，响应时间短的优先分配</p><p>简单配置</p><pre><code>upstream test { 
        fair; 
        server localhost:8080;
        server localhost:8081;
    }
server {
    listen       80;                                                         
    server_name  localhost;                                               
    client_max_body_size 1024M;
    location / {
        proxy_pass https://test;
        proxy_set_header Host $host:$server_port;
    }
}</code></pre><p>fair第三方拓展安装</p><p>(1)：下载fair拓展：<a href="https://link.segmentfault.com/?enc=pEL8kDeAFlQtoo%2BVPqYIZw%3D%3D.IJR5VJqOItitbCqH6wvZQY9fCrvl4pmFVFamU%2BkviMVYrIaKotYJcvQwV8%2Fe3kST" rel="nofollow" target="_blank">https://github.com/gnosek/nginx-upstream-fair</a></p><p>(2)：安装fair拓展</p><pre><code>./configure --with-http_ssl_module --add-module=/xxx/nginx-upstream-fair
make #注意千万不要执行make install 避免覆盖
mv /etc/nginx /etc/nginx_bak #备份原来的nginx执行文件
cp objs/nginx /etc/nginx #将编译好的nginx复制到nginx执行文件下
nginx -s reopen #重启</code></pre><h3>5：策略五：url_hash（第三方）</h3><p>按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。 在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法</p><p>简单配置</p><pre><code>upstream test { 
        hash $request_uri; 
        hash_method crc32; 
        server localhost:8080;
        server localhost:8081;
    }
server {
    listen       80;                                                         
    server_name  localhost;                                               
    client_max_body_size 1024M;
    location / {
        proxy_pass https://test;
        proxy_set_header Host $host:$server_port;
    }
}</code></pre><p> url_hash第三方拓展安装</p><p>(1)：下载fair拓展：<a href="https://link.segmentfault.com/?enc=gfvy3II46UrBS7Exg5hhOw%3D%3D.XXYL9JTXefzty%2FZ2oyg4jeDF%2BQep7t5KnAkE4VEerxFy0SGgNoW29NMUmZ1%2FRbpzyVhU4ehkVQEoWA8Vs34n1g%3D%3D" rel="nofollow" target="_blank">https://github.com/evanmiller/nginx_upstream_hash</a></p><p>(2)：安装url_hash拓展</p><pre><code>./configure --with-http_ssl_module --add-module=/xxx/nginx_upstream_hash
make #注意千万不要执行make install 避免覆盖
mv /etc/nginx /etc/nginx_bak #备份原来的nginx执行文件
cp objs/nginx /etc/nginx #将编译好的nginx复制到nginx执行文件下
nginx -s reopen #重启</code></pre><h2>五：正向代理</h2><p>正向代理，意思是一个位于客户端和原始服务器(origin server)之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。客户端才能使用正向代理。当你需要把你的服务器作为代理服务器的时候，可以用Nginx来实现正向代理</p><p>简单配置</p><pre><code>server {
    resolver 8.8.8.8;    # 配置指定DNS解析IP地址(在/etc/resolv.conf查看)
    resolver_timeout 5s;     #超时时间（5秒）
    # 监听端口
    listen 8080;
    #access_log  /home/reistlin/logs/proxy.access.log;
    #error_log   /home/reistlin/logs/proxy.error.log;
    location / {
        # 配置正向代理参数
        proxy_pass https://$https_host$request_uri;
        # 解决如果URL中带"."后Nginx 503错误
        proxy_set_header Host $https_host;
        # 配置缓存大小
        proxy_buffers 256 4k;
        # 关闭磁盘缓存读写减少I/O
        proxy_max_temp_file_size 0;
         # 代理连接超时时间
        proxy_connect_timeout 30;
        # 配置代理服务器HTTP状态缓存时间
        proxy_cache_valid 200 302 10m;
        proxy_cache_valid 301 1h;
        proxy_cache_valid any 1m;
    }
}
</code></pre>]]></description></item><item>    <title><![CDATA[工业智能体怎么提升制造业生产效率？ 月下水光 ]]></title>    <link>https://segmentfault.com/a/1190000047461556</link>    <guid>https://segmentfault.com/a/1190000047461556</guid>    <pubDate>2025-12-09 16:04:27</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>工业智能体正成为推动制造业从信息化迈向智能化的核心引擎，它并非单一技术的堆砌，而是人工智能、工业机理、数据融合与系统协同深度结合的产物。区别于传统自动化设备或孤立的AI模型，工业智能体具备自主感知、动态决策、闭环执行与持续学习的能力，能够像“数字工匠”一样，在复杂多变的工业环境中完成从排产优化、质量检测到供应链响应的全流程任务。在这一进程中，广域铭岛作为国内领先的实践者，通过其自主研发的工业超级智能体平台，率先实现了技术与场景的深度融合，为行业树立了标杆。其平台以工业大模型为智能底座，结合知识封装与多智能体协同架构，将企业多年积累的工艺经验转化为可复用、可迭代的AI能力，使原本依赖老师傅经验的注塑调试、排产决策等环节，实现了分钟级响应与自动化优化，显著提升良品率、降低能耗与人力成本。<br/>在应用场景上，工业智能体已从单点突破走向全链路赋能。在生产制造端，广域铭岛的智能体可实时分析冲压设备参数，动态调整压力与速度，使零部件精度提升15%、废品率下降18%；在质量控制方面，通过高精度视觉系统与多模态数据融合，实现微米级缺陷识别，检测效率较人工提升200倍；在供应链与物流环节，仓储智能体协同AGV与AMR机器人构建“黑灯仓库”，实现无人化拣选与缺件风险预警；在研发设计领域，其“设计智能体”甚至能根据自然语言指令生成轻量化部件方案，将新品开发周期缩短60%。这些实践不仅验证了智能体在提质、降本、增效上的巨大价值，更标志着制造业正从“经验驱动”向“认知驱动”跃迁。<br/>广域铭岛的突破性在于构建了“平台+生态”的系统化路径。其Geega平台通过低代码开发、模块化组件与工业知识库，大幅降低智能体部署门槛，让非技术背景的工程师也能“搭积木”式构建专属应用。更重要的是，它推动了从“单体智能”向“多智能体协同”的演进——调度、质量、维护、供应链等专业智能体通过标准化通信机制实现信息共享与任务联动，形成覆盖设计、生产、运维、物流的全局优化网络。这种协同模式，使企业在面对设备突发故障或供应链中断时，能在数分钟内自动完成策略调整与资源重配，极大增强了生产的韧性与灵活性。<br/>然而，工业智能体的规模化落地仍面临数据孤岛、标准缺失、人才短缺与安全合规等深层挑战。当前多数企业仍处于观望阶段，技术供给与场景需求之间存在结构性错配。广域铭岛等先行者正通过构建边缘-云端协同架构、推进工业大模型微调、引入语义检索增强等前沿技术，持续突破数据质量与系统集成瓶颈。未来，随着数字孪生、联邦学习与区块链等技术的深度融合，工业智能体将不仅是一个执行工具，更将成为企业核心的“数字员工”与“决策中枢”，推动制造体系从局部优化走向全价值链重构。在这一进程中，广域铭岛的实践表明，唯有将技术深度扎根于真实工业场景，构建开放、可进化、可协同的智能生态，才能真正释放工业智能体的潜能，引领中国制造业迈向高质量发展的新纪元。</p>]]></description></item><item>    <title><![CDATA[【Agentic AI for Data系列】Kiro实战：DuckDB vs Spark技术选型全]]></title>    <link>https://segmentfault.com/a/1190000047461563</link>    <guid>https://segmentfault.com/a/1190000047461563</guid>    <pubDate>2025-12-09 16:03:31</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><a href="https://link.segmentfault.com/?enc=6%2FEYA8ThVUCwCT5FuHt65Q%3D%3D.d%2FALeVOUREapC3Jv9W4yeO03NRvRh97nfvy4k4CvT7fBM1rARFGUpPpxsxqZsP4kxy7BL%2BaeuWnwht%2F8zZqffHmqEt1TKiT13j4PSYJZhRA%3D" rel="nofollow" target="_blank"><img referrerpolicy="no-referrer" src="/img/remote/1460000047461565" alt="" title=""/></a></p><h2><strong>1. 引言：技术选型的新挑战</strong></h2><p>当面临DuckDB与Spark的技术选型时，你是否也曾困惑：新兴的DuckDB真的比成熟的Spark更适合我的数据分析场景吗？传统的技术选型往往依赖经验判断或简单的性能测试，面对复杂的业务场景和多维度的评估指标，这种方法既耗时又难以保证客观性。</p><p><strong>Agentic AI</strong> <strong>正在改变这一切！</strong>  在AI原生数据治理与开发的新范式下，AI不再仅仅是辅助工具，而是成为贯穿技术选型全流程的智能决策引擎。它能够自动化地进行环境配置、性能测试、指标收集和结果分析，将原本需要数周的手动验证工作压缩到几天内完成。</p><p>本文将通过一个真实案例展示这种变革：面对电商用户行为数据的营销分析任务，我们将使用AI开发助手Kiro进行了一次科学的比较。在3天内，AI自主完成了完整的性能对比测试，客观地给出选型报告。</p><blockquote>🔥 想利用生成式AI开发工具解放双手，却苦于应用效果不够完善、流程不够规范？<br/>✨ 亚马逊云科技 Kiro 登场！采用“规范驱动”开发理念，结合 Agent Hooks 自动化系统，1小时让小白变身生产级游戏制作人！<br/>🔛 速来云上探索实验室，体验 Kiro 开发独立游戏，从需求到部署全掌握！<br/>👉 <a href="https://link.segmentfault.com/?enc=HYxiFoB8EV8r9%2BSzIwSxew%3D%3D.Vh%2BhrDRAsBD0xwfCw3th7mn3r4pgL5pfgFSMkNPt19YJrdmR3AOP%2BC2dGBtbPiiIA%2F1r2qMp2Y%2Bv43DMNnDK5i3vfVPJ3euxirfP3dACBvf2OItq1ijnJLgrn9ZM971KuEiJ591aQfJJLYfzNLcaRLFbMFOTiwjDwEoziEoKnY5fCPrUwDr38JzSYRg5I%2Fn6oTjLH0SbvSpMRz5uLFkryp20Oe7ROAOE8izx4a7ei6o%3D" rel="nofollow" target="_blank">点击这里</a>，即刻开启 AI 开发之旅！</blockquote><h2><strong>2. 技术背景介绍</strong></h2><h3>2.1 <strong>DuckDB</strong> <strong>和</strong> <strong>Spark</strong> <strong>的产品定位</strong></h3><p>在深入AI驱动的技术选型实战之前，让我们先了解DuckDB和Spark的核心差异。设想这样一个场景：当你需要快速分析业务数据时，Spark需要启动集群、等待任务调度，整个过程可能需要数分钟；而DuckDB则可以立即执行SQL查询，几秒内得到结果。这种差异正是两种技术不同定位的体现。</p><p><strong>DuckDB</strong> <strong>的定位</strong></p><p>主要适合单机能够处理的数据量场景，其目标用户是熟悉SQL的数据分析师、科学家和业务人员。典型应用包括日报生成、数据探索、文件处理和交互式查询，核心优势在于零配置、即开即用的SQL原生支持[1]。</p><p><strong>Spark</strong> <strong>的定位</strong></p><p>更适合需要分布式处理的大规模数据场景，主要服务于大数据工程师。其典型应用涵盖大规模ETL、机器学习和流处理，核心优势体现在分布式处理能力、丰富的生态系统和企业级特性。</p><h3>2.2 <strong>DuckDB</strong> <strong>的优势与实际使用体验</strong></h3><p>从技术特点来看，DuckDB采用嵌入式架构，直接运行在Python进程内部，虽然受本地资源限制但避免了网络延迟。它提供完整的SQL支持，包括窗口函数、CTE、复杂JOIN等高级特性，同时支持多种数据格式，同一条SQL可以查询CSV、Parquet、Pandas DataFrame。DuckDB在性能方面，除了单机架构避免了网络和调度开销外，其核心在于其向量化执行引擎。该引擎以列式数据块（Vectors）为单位进行处理，而非传统的逐行处理，极大地减少了CPU指令的调用开销和缓存未命中（Cache Miss），在计算密集型任务（如聚合、过滤、去重）上展现出无与伦比的效率。特别值得一提的是，DuckDB与Amazon S3 Tables的集成让用户可以直接查询云端存储的Apache Iceberg格式数据，无需数据移动或复杂配置，既节省存储空间又保证数据安全性[2]。</p><p><strong>DuckDB</strong> <strong>实际使用体验</strong></p><pre><code>Python
import duckdb
# 直接查询S3数据，无需集群启动，几秒内完成
result = duckdb.sql("""
    SELECT region, SUM(revenue) as total_revenue
    FROM 's3://your-bucket/sales-data/*.csv'
    GROUP BY region
""").df()</code></pre><h3>2.3 <strong>技术选型的挑战</strong></h3><p>这些产品定位和技术特性信息为我们理解后续的测试提供了重要背景。但是，仅凭理论分析还不足以做出准确的技术选型决策，真正的答案需要通过科学的测试验证来获得。</p><p>正如《开发新范式：Agentic AI驱动的AI for Data革命》这篇博客中介绍的Agentic AI数据开发方法论，我们现在将其应用到具体的技术选型场景中，看看Agentic AI真实的生产力。</p><h2><strong>3. Agentic AI</strong> <strong>实战：</strong> <strong>Kiro</strong> <strong>驱动的智能技术选型</strong></h2><h3>3.1 <strong>什么是</strong> <strong>Kiro</strong> <strong>？</strong></h3><p>这次验证，我直接选择使用out-of-box的开发智能体Kiro，为大家展示Agentic AI驱动的数据开发全流程.</p><p>Kiro作为AI开发智能体，通过其核心功能展现了Agentic AI的革命性能力：自然语言交互的零门槛协作、Specs规范驱动开发，以及Agent Hooks支持的智能自动化[3]。这三个能力的有机结合，让Kiro不再是被动的工具，而是能主动思考、规划和执行的智能开发伙伴。</p><p><strong>自然语言交互</strong></p><p>让开发者无需学习复杂的命令或界面操作，直接用自然语言对话就能完成开发工作，就像和同事聊天一样自然；</p><p><strong>Specs</strong> <strong>规范驱动开发</strong></p><p>就像有个资深产品经理，能把你一句话的想法变成详细的产品需求文档、技术设计和开发任务清单；</p><p><strong>Agent Hooks</strong></p><p>则像个贴心助手，能自动处理那些重复枯燥的工作，比如代码保存时自动格式化、跑测试、检查错误。</p><h3>3.2 <strong>Kiro</strong> <strong>的工作流程展示：从自然语言到方案落地</strong></h3><p><strong>1. 和</strong> <strong>AI</strong> <strong>对话</strong></p><pre><code>Plaintext
输入："帮我对比DuckDB和Spark处理电商用户行为数据的性能，特别是小文件场景"</code></pre><p>Agentic AI能够从这一句话中提取关键信息，例如技术对比需求、业务场景、数据特点、指标关注点等等。</p><p><strong>2. 智能需求解析</strong></p><p>Kiro基于大模型的推理能力，专注于理解和分解自然语言需求，识别关键技术要素和业务意图。</p><pre><code>Plaintext
智能解析结果：
├── 核心任务识别
│   ├── 主要目标：性能对比分析
│   ├── 对比对象：DuckDB vs Spark
│   └── 决策支持：技术选型建议
├── 业务场景理解
│   ├── 数据类型：电商用户行为数据
│   ├── 数据特点：小文件分布式存储
│   └── 处理需求：去重、聚合、漏斗分析
├── 技术差异识别
│   ├── DuckDB特点：单机架构，列式存储，向量化执行
│   ├── Spark特点：分布式架构，内存计算，任务调度
│   └── 关键差异：小文件场景下的启动开销差异
└── 性能关注点
    ├── 执行时间：端到端处理时间；核心计算任务处理时间
    ├── 资源利用：CPU、内存使用效率
    └── 成本效益：DPU消耗和处理能力</code></pre><p><strong>3. 自动化方案生成（</strong> <strong>Specs</strong> <strong>规范驱动开发功能）</strong></p><p>基于需求解析结果，Kiro的自主决策架构自动生成完整的技术实现方案，这正是Kiro Specs功能的体现：</p><pre><code>Plaintext
Kiro生成的完整Specs方案：

Requirements（需求规范）：
- 用户故事：作为数据工程师，我需要科学对比两种引擎的性能表现
- 验收标准：获得可量化、可重复的性能对比数据
- 成功指标：基于真实数据得出客观的技术选型建议

Design（技术架构）：
- 测试环境：Amazon Glue cn-northwest-1区域，统一DPU配置
- 数据设计：38个Parquet小文件，共3780条电商行为记录
- 监控体系：双重指标收集（亚马逊云科技原生 + 自定义业务指标）
- 公平性保证：相同环境、等价逻辑、统一数据源

Implementation（执行计划）：
- [ ] 测试数据准备：生成标准化的电商用户行为数据集
- [ ] 脚本开发：创建DuckDB和Spark的等价处理脚本
- [ ] 环境配置：设置Amazon Glue作业和IAM权限
- [ ] 监控部署：配置CloudWatch指标收集和实时监控
- [ ] 测试执行：自动化运行并收集性能数据
- [ ] 结果分析：生成对比报告和技术选型建议</code></pre><p><strong>4. 自动化代码生成</strong></p><p>基于前面的需求理解和方案设计，Kiro自动生成了完整的性能测试代码。包括高效的SQL查询代码和完整性能指标收集，以及Spark版本的等价业务逻辑实现。为确保测试的公平性，DuckDB和Spark代码均使用相同的数据输入、等价的处理逻辑和统一的环境配置。</p><p>监控指标设计方面，采用双重监控策略，既收集Amazon Glue原生指标（CPU、内存、执行时间等系统级性能），也发布自定义业务指标（去重耗时、聚合计算、处理记录数等应用级性能），确保多个维度的全面性能分析。</p><p><strong>5. 实时协作与问题调试</strong></p><p>Kiro依照第3步产出的执行计划，向用户确认，得到用户许可后逐步第4步产出的代码。中间执行有任何问题，用户均可通过自然语言对话的方式去调整。</p><pre><code>Plaintext
Kiro：Spark作业正在运行...预计需要2-3分钟

用户：为什么Spark需要这么长时间？数据量不大啊

Kiro：让我实时查看执行情况...

实时分析：
- 集群启动时间：90秒（占总时间59%）
- 实际数据处理：62秒
- 对于小数据集，启动开销确实很大

用户：那DuckDB呢？

Kiro：DuckDB作业已经完成了！总共44秒：
- 无启动开销，直接开始处理
- 去重操作：0.69秒（比Spark快97%）
- 这就是单机架构的优势

用户：差异这么大？能确认测试的公平性吗？

Kiro：公平，让我展示对比数据：

公平性保证：
- 相同的Amazon Glue环境（cn-northwest-1）
- 相同的DPU配置（2 DPU）
- 等价的处理逻辑（我生成的代码确保功能一致）
- 相同的测试数据（38个Parquet文件，3780条记录）</code></pre><p><strong> 6. 执行计划完成</strong></p><p><strong> 7. 成果开源：</strong></p><pre><code>Plaintext
用户：太棒了，选型报告很完善！这套测试方法能开源给其他开发者使用吗？

当然！让我执行完整的开源项目准备：

开源项目：agentic-ai-glue-performance-comparison
├── 核心测试代码
│   ├── DuckDB性能测试脚本（含亚马逊云科技凭证智能配置）
│   ├── Spark等价测试脚本（确保公平对比）
│   └── 双重监控系统（22个维度性能指标）
├── 一键部署工具
│   ├── Amazon Glue作业自动创建
│   ├── IAM权限智能配置
│   └── 测试数据自动生成
├── 可视化分析
│   ├── CloudWatch监控面板
│   ├── 性能对比报告生成器
│   └── 技术选型决策矩阵
└── 完整文档
    ├── 快速开始指南
    ├── 配置参数说明
    └── 故障排除手册

🔗 GitHub: https://github.com/aws-samples/agentic-ai-glue-performance-comparison</code></pre><p>这个案例展示了Agentic AI的端到端执行能力。从最初的一句话需求”对比DuckDB和Spark处理电商用户行为数据的性能”，到最终交付测试报告给出选型建议，再到贡献完整的开源项目代码，整个过程体现了Agentic AI工具从理解需求到价值创造的完整闭环。</p><h2><strong>4. Agentic AI</strong> <strong>生成的测试报告与选型建议</strong></h2><p>经过完整的测试执行，Kiro基于收集到的22个维度性能数据，自动生成了详细的技术选型报告。这份报告不仅包含客观的性能对比数据，更重要的是提供了基于业务场景的智能选型建议。</p><h3>4.1 <strong>性能测试结果对比</strong></h3><p><strong>核心性能指标对比</strong>：</p><p><img width="721" height="415" referrerpolicy="no-referrer" src="/img/bVdni2d" alt="image.png" title="image.png" loading="lazy"/></p><p><strong>详细性能分析</strong>：</p><pre><code>Plaintext
🔍 Kiro的智能分析报告：

执行时间分解：
├── Spark (67.77秒总计)
│   ├── 数据处理: 28.51秒 (42.1%)
│   ├── 去重处理: 26.39秒 (38.9%)
│   ├── 数据缓存: 0.15秒 (0.2%)
│   └── 其他操作: 12.72秒 (18.8%)
│
└── DuckDB (6.48秒总计)
    ├── 初始化时间: 3.47秒 (53.5%)
    ├── 批处理时间: 2.67秒 (41.2%)
    ├── 去重处理: 0.69秒 (10.6%) ← 显著优势
    ├── 文件合并: 0.02秒 (0.4%)
    └── 其他检查: 0.03秒 (0.5%)

💡 关键发现：
- DuckDB总执行时间比Spark快90.4%，性能优势巨大
- DuckDB的去重操作比Spark快97.4%，体现了列式存储优势
- 数据吞吐量提升945%，从55.8条/秒提升到583.3条/秒
- 即使包含初始化开销，DuckDB仍然具有压倒性优势</code></pre><h3>4.2 <strong>Agentic AI</strong> <strong>的智能选型建议</strong></h3><p>基于测试数据和业务场景分析，Kiro提供了以下智能选型建议：</p><p><strong>推荐使用</strong> <strong>DuckDB</strong> <strong>的场景</strong></p><p><strong>🎯</strong> <strong>最佳适用场景</strong>：DuckDB在处理单机可处理的小数据量场景中表现卓越，特别适合小文件多且需要频繁去重的数据处理任务。对于需要交互式查询和快速迭代的业务场景，以及对低延迟、快速响应有要求的应用，DuckDB都能提供显著的性能优势。同时，在成本敏感的项目中，DuckDB能够有效控制计算成本。需要强调的是，现代服务器的‘单机’能力已非常强大，可以配备数百GB甚至TB级别的内存和高速NVMe SSD。在这种硬件环境下，DuckDB能够轻松处理数十亿行、数百GB甚至TB级别的中等规模数据集，其处理范围远超传统观念中的‘小数据’。</p><p><strong>推荐使用</strong> <strong>Spark</strong> <strong>的场景</strong></p><p><strong>🎯 Spark</strong> <strong>仍然最优的场景</strong>：当面对大数据量且需要分布式处理的复杂场景时，Spark依然是最佳选择。特别是在构建复杂的数据管道和机器学习工作流时，Spark丰富的生态系统组件提供了无可替代的价值。对于有高可用性和企业级治理要求的关键业务系统，Spark的成熟度和稳定性仍然是首选。</p><p><strong>混合架构策略</strong></p><pre><code>Plaintext
企业数据处理架构建议：
├── 交互层 → DuckDB
│   ├── 日报生成和临时查询
│   ├── 数据探索和原型开发
│   └── 小规模ETL和数据清洗
│
└── 批处理层 → Spark
    ├── 大规模数据处理
    ├── 复杂的机器学习管道
    └── 企业级数据治理</code></pre><h2><strong>5. 总结：</strong> <strong>Agentic AI</strong> <strong>重新定义技术选型</strong></h2><p>通过这次DuckDB vs Spark的完整技术选型实战，我们深刻体验了Agentic AI如何从根本上改变技术决策的方式。这次实战完美验证了Agentic AI数据开发的三大核心能力：AI自主理解业务需求并制定完整策略，通过自然语言交互大大降低技术选型门槛，实现从需求理解到开源项目交付的端到端智能流程。更重要的是，AI基于25个维度的量化数据进行客观决策，发现DuckDB在小文件处理场景下比Spark快90.4%，将传统2-3周的选型周期缩短到3天，效率提升80%，标志着我们正式迈入AI原生数据开发的新时代。</p><h2><strong>6. 系列文章导航</strong></h2><p><strong>第</strong> <strong>1</strong> <strong>篇：</strong> 【Agentic AI for Data系列】开发新范式：AI驱动的数据革命</p><p><strong>第</strong> <strong>2</strong> <strong>篇：</strong> 【Agentic AI for Data系列】Kiro实战：DuckDB vs Spark技术选型全流程（本篇）</p><h2><strong>7. 参考资料</strong></h2><p>[1]<a href="https://link.segmentfault.com/?enc=KTkxYoihmQZmdaqx%2Ful2eQ%3D%3D.QmHqJ0jUsrAYs%2Be7UJjgk0SnBFiWHr2pd8lQnkQmrdLCd1aIE3dFSjhK27x%2F8PkJgom5KuO1V4sCaMtKhBMcHIQckK1n%2FMQ4iNF4LbOrVnxhRqBMz4%2FkdcmNRgleFCe10Bzoc15yaTwuqV4BzqVYd%2BVemF5jATSvmYAMICKS%2B1W9mDvQmcYKoRCrBHIyqKqb%2BPlNTmjq8JZn6%2BWPvPiMwQ%3D%3D" rel="nofollow" target="_blank">当 PyIceberg 和 DuckDB 遇见 Amazon S3 Tables：打造 Serverless 数据湖”开源梦幻组合”</a></p><p>[2]<a href="https://link.segmentfault.com/?enc=jQZJCobDITNEuWyExgYrvw%3D%3D.KYM8kyJVtppT6o1bKjRAs6%2BeAByEGbp1ayiYPC49lIO%2BAaZy1SYS0F5VkP7c5OAwJ9qjwR%2BitrRqztroAYGtvg%3D%3D" rel="nofollow" target="_blank">DuckDB集成S3 Tables</a></p><p>[3]<a href="https://link.segmentfault.com/?enc=w%2B5SuUFAf196XIcpgasr5w%3D%3D.k2Vs%2Bc%2Bx0FN08%2B6Qx0yLap7BvblfD8D9M8ZXo1w9peCeD3R1Ip1jc6x%2BVujEjghr" rel="nofollow" target="_blank">Kiro功能完全指南</a></p><p><em>*前述特定亚马逊云科技生成式人工智能相关的服务目前在亚马逊云科技海外区域可用。亚马逊云科技中国区域相关云服务由西云数据和光环新网运营，具体信息以中国区域官网为准。</em></p><p><strong>本篇作者</strong><br/><img width="723" height="327" referrerpolicy="no-referrer" src="/img/bVdni1x" alt="image.png" title="image.png" loading="lazy"/></p><blockquote>🔥 想利用生成式AI开发工具解放双手，却苦于应用效果不够完善、流程不够规范？<br/>✨ 亚马逊云科技 Kiro 登场！采用“规范驱动”开发理念，结合 Agent Hooks 自动化系统，1小时让小白变身生产级游戏制作人！<br/>🔛 速来云上探索实验室，体验 Kiro 开发独立游戏，从需求到部署全掌握！<br/>👉 <a href="https://link.segmentfault.com/?enc=k5LSHnSNgOTRy1KkMXXybw%3D%3D.JQI1eV4YzuC9uwoU8b4M4EU2QXQz%2FkWvAHEdIDxGjbFIIJYYO%2FxEAXBbvnscSDNlxeqzNwpl2Dir9i%2FAFX1M%2FSqRRymcSgobsDFKO0uhMObIdIZ5%2BLIH8LJmOTHrxver8nJQ19oONTl0zz%2BLZE04yuQA86mqclD0p%2FnpUacneIV75truNVIEUi%2Fu0eBlKPPC%2BDtH5z8iDBz7TXXm86mAOq4V58l9AzHS3eTpmK3P1wA%3D" rel="nofollow" target="_blank">点击这里</a>，即刻开启 AI 开发之旅！</blockquote>]]></description></item><item>    <title><![CDATA[智能工厂怎么建设？从0到1的完整路径与关键步骤详解 月下水光 ]]></title>    <link>https://segmentfault.com/a/1190000047461568</link>    <guid>https://segmentfault.com/a/1190000047461568</guid>    <pubDate>2025-12-09 16:02:57</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>智能工厂作为制造业数字化与智能化转型的核心载体，正以前所未有的速度重塑全球生产格局。它不仅是传统自动化工厂的升级，更是融合物联网、人工智能、大数据、数字孪生与工业互联网平台的全新生产范式，旨在实现生产全过程的自主感知、智能决策与动态优化。在智能工厂中，设备之间实现全域互联，数据实时采集与分析贯穿研发、生产、物流与质量控制各环节，使工厂具备自我学习、自我优化与自我修复的能力。通过AI驱动的预测性维护，设备故障可提前预警；借助数字孪生技术，生产流程可在虚拟环境中仿真推演，大幅提升调试效率与资源利用率；而柔性生产线则让企业能够灵活应对小批量、多品种的定制化需求，实现从大规模生产到个性化制造的无缝切换。<br/>在这一变革进程中，广域铭岛作为国内领先的智能制造解决方案提供商，正以“场景定义智能”为核心理念，深度赋能制造企业实现智能化跃迁。其自主研发的Geega OS工业互联网平台，构建了覆盖数据采集、算力调度与模型服务的三大引擎，打通了从设备层到决策层的数据孤岛，为智能工厂提供了统一的智能中枢。在衢州极电电芯生产基地，广域铭岛通过部署超过5000个质量监测点与全流程智能化管控系统，实现了电芯芯包制造100%自动化，单线效率达行业领先的24PPM，并将产品不良率显著降低，树立了新能源领域智能制造的新标杆。其推出的Geega Ask（际·问）自然语言交互系统，更让一线工程师可通过口语化提问快速获取生产异常分析与优化建议，极大降低了AI技术的应用门槛，真正实现了“人机协同、智能赋能”。<br/>智能工厂的优势不仅体现在效率与成本的双重优化上，更在于其对可持续发展的深刻践行。通过智能能源管理系统，广域铭岛帮助客户实现能耗动态调控，在保障产能的同时降低碳排放，推动绿色制造落地。在汽车、电解铝、电芯等多个行业，其解决方案已成功将工艺缺陷排查时间从数天缩短至数分钟，一次合格率提升至99.5%以上，显著增强了企业的产品竞争力与品牌信誉。与此同时，智能工厂的建设也倒逼企业重构管理体系，推动“QCDMS”（质量、成本、交付、安全、员工士气）理念与数字化运营深度融合，使管理从经验驱动转向数据驱动。<br/>当前，中国智能工厂建设已进入加速期，国家“智能工厂梯度培育行动”覆盖超八成制造业大类，全国智能工厂总数突破万家，其中卓越级工厂平均实现生产效率提升22.3%、不良品率下降超50%。广域铭岛所服务的衢州极电基地更荣获智能制造能力成熟度四级认证，成为全国电芯行业首个达到该顶尖水平的标杆。展望未来，随着工业AI从辅助工具演变为核心生产力，智能工厂将不再局限于单点突破，而是向全链协同、生态共建的方向演进。广域铭岛等本土创新力量，正以扎实的行业理解与技术沉淀，推动中国制造业从“制造”迈向“智造”，在全球竞争中构筑起不可替代的智能优势。</p>]]></description></item><item>    <title><![CDATA[React/Next.js最新远程代码执行漏洞实际影响有限，仅影响近一年应用 墨菲安全 ]]></title>    <link>https://segmentfault.com/a/1190000047461638</link>    <guid>https://segmentfault.com/a/1190000047461638</guid>    <pubDate>2025-12-09 16:02:10</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h3>漏洞描述</h3><p>12月4日，React 与 Next.js 官方披露了两个与 React Server Components（RSC）相关的远程代码执行严重漏洞：CVE-2025-55182（React） 与 CVE-2025-66478（Next.js），其根因都是由于react-server-dom系列的三个实验性对Flight协议的反序列化实现不当，这些组件用于处理Flight协议到dom的转换：</p><ul><li>react-server-dom-webpack</li><li>react-server-dom-turbopack</li><li>react-server-dom-parcel</li></ul><h3>漏洞影响</h3><p>从当前实际使用情况来看，影响范围有限，其原因是：</p><ol><li><p>漏洞仅影响近一年发布的应用，漏洞最早受影响版本19.0 rc版于2024年5月发布，正式版发布于2024年12月，而19.0之前的更早版本不受影响；<br/><img width="723" height="95" referrerpolicy="no-referrer" src="/img/bVdni5b" alt="image.png" title="image.png"/></p><pre><code>             （react-server-dom-webpack版本发布时间）
</code></pre></li><li><strong>这3个组件的实际使用量在npm生态中不大</strong>，这3个组件官方声明都是实验性阶段的React Flight协议binding组件。其中react-server-dom-webpack受影响版本最近一周在NPM仓库下载量约15万、react-server-dom-turbopack每周下载量3万、react-server-dom-parcel 每周下载量不到3千。<br/><img width="723" height="639" referrerpolicy="no-referrer" src="/img/bVdni5i" alt="image.png" title="image.png" loading="lazy"/></li><li>从国内企业级应用的开发生态来看，绝大多数前端应用仍然采用“前后端分离”架构（React SPA + 后端 API），这种模式不会启用 React Server Components（RSC），next.js未广泛使用，因此整体受影响面相对有限。</li></ol><h3>排查处置建议</h3><p>当前墨菲安全SCA及漏洞情报产品已支持此漏洞排查，建议企业首先可基于当前已经披露的受影响版本范围排查：<br/>react-server-dom-parcel <br/>仓库类型npm受影响的版本[19.2.0,19.2.1)最小修复版本19.2.1<br/>仓库类型npm受影响的版本[19.1.0,19.1.2)最小修复版本19.1.2<br/>仓库类型npm受影响的版本[19.0,19.0.1)最小修复版本19.0.1<br/>react-server-dom-turbopack <br/>仓库类型npm受影响的版本[19.2.0,19.2.1)最小修复版本19.2.1<br/>仓库类型npm受影响的版本[19.1.0,19.1.2)最小修复版本19.1.2<br/>仓库类型npm受影响的版本[19.0,19.0.1)最小修复版本19.0.1<br/>react-server-dom-webpack <br/>仓库类型npm受影响的版本[19.0,19.0.1)最小修复版本19.0.1<br/>仓库类型npm受影响的版本[19.2.0,19.2.1)最小修复版本19.2.1<br/>仓库类型npm受影响的版本[19.1.0,19.1.2)最小修复版本19.1.2<br/>next <br/>仓库类型npm受影响的版本[15.1.1-canary.0,15.1.9)最小修复版本15.1.9<br/>仓库类型npm受影响的版本[14.3.0-canary.77,15.0.5)最小修复版本15.0.5<br/>仓库类型npm受影响的版本[15.5.1-canary.0,15.5.7)最小修复版本15.5.7<br/>仓库类型npm受影响的版本[15.2.0-canary.0,15.2.6)最小修复版本15.2.6<br/>仓库类型npm受影响的版本[15.3.0-canary.0,15.3.6)最小修复版本15.3.6<br/>仓库类型npm受影响的版本[15.4.0-canary.0,15.4.8)最小修复版本15.4.8<br/>仓库类型npm受影响的版本[16.0.0-canary.0,16.0.7)最小修复版本16.0.7</p><p>如果组件通过npm引入react-server-dom-webpack作为依赖，通过检查package-lock.json文件可以排查。但存在类似next.js这样将打包后的react-server-dom-webpack文件直接放到源代码目录的情况，会存在于应用./node_modules/next/dist/compiled/react-server-dom-webpack路径中，针对此类嵌入的场景我们也在梳理其影响范围，同时建议结合判断文件目录是否存在于主机中等多种方式排查。</p><h3>参考链接</h3><p><a href="https://link.segmentfault.com/?enc=yv%2FWlyqQliaTvmi%2F8axu7A%3D%3D.QtlfrFzuVCrHa%2FvlSHSHLOMtAcP44RRjqzDMP%2F%2Fj6mwhWhoQM4YxDWhSgFfwTyk2" rel="nofollow" target="_blank">https://www.oscs1024.com/hd/MPS-qgo0-ypd9</a><br/><a href="https://link.segmentfault.com/?enc=%2Birs%2BiY%2B88Y5Wm%2BUEEImaQ%3D%3D.hn7xtazy3Q%2BpJ2UMag%2FREXiibKGsUSYC1%2F19eTTjyxHTFTA5Eq9xP%2FhKK0PC4z5S" rel="nofollow" target="_blank">https://www.oscs1024.com/hd/MPS-qbkj-1z9n</a><br/><a href="https://link.segmentfault.com/?enc=MfTfsyZPJTBhtIIAhZ6eyA%3D%3D.wVIK42trOmT9olQlqe5mFY%2BCG7S0UTMy%2B2Pj5drgTTGYGe%2Br0eL2CiEWXS%2FR92pOx2M93OBHE5WuGGhDsVAslSou55Fa702TblWfEHwcEEk%3D" rel="nofollow" target="_blank">https://www.wiz.io/blog/critical-vulnerability-in-react-cve-2...</a><br/><a href="https://link.segmentfault.com/?enc=oeCWYgjlWB2BQHWObPDrsg%3D%3D.DqeNYW%2BAoCZRt%2BXbl7S%2Fmqpe%2FbBFiAKZx0zqDZmLX%2Fekbh5nWBPI0kKxa9A8twD72X5SIO99ds2cRhiRLEWhfA%3D%3D" rel="nofollow" target="_blank">https://github.com/advisories/GHSA-fv66-9v8q-g76r</a><br/><a href="https://link.segmentfault.com/?enc=ytKWqVLjnAYQgmVnOdB52Q%3D%3D.%2BeQB2qC05orCut4hOimwWig92gjhH27yXHpuBG0gnXejZcnmvnkX9wwGHAsxxD9i" rel="nofollow" target="_blank">https://vercel.com/changelog/cve-2025-55182</a></p><h3>联系我们</h3><p>需要排查协助或了解更多相关信息，可联系我们：<br/><img width="494" height="499" referrerpolicy="no-referrer" src="/img/bVdni6p" alt="image.png" title="image.png" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA["揭秘排产智能体：传统工厂一夜变身‘智慧大脑’的魔法" 雨大王 ]]></title>    <link>https://segmentfault.com/a/1190000047461641</link>    <guid>https://segmentfault.com/a/1190000047461641</guid>    <pubDate>2025-12-09 16:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>排产智能体：制造业数字化转型的智能中枢<br/>制造业正经历一场前所未有的智能化浪潮，而这其中，排产智能体扮演着越来越关键的角色。它不仅仅是一个工具，更是推动生产管理从经验驱动向数据驱动转变的核心力量。以美的集团为例，他们通过部署智能排产系统，将传统需要数小时完成的生产计划压缩到了分钟级，同时实现了设备利用率提升20%的目标。<br/>在实际应用中，排产智能体展现出了独特的优势。它能够实时整合订单优先级、设备负载率、人员技能水平等多维度数据，通过智能算法生成最优生产方案。这一点在疫情期间尤为明显，某汽车零部件企业通过排产智能体实现了70%的生产效率提升，成功应对了订单激增的挑战。<br/>排产智能体的技术架构也值得关注。它通常包含三个核心层次：数据采集层负责收集设备状态、物料信息等原始数据；AI处理层运用机器学习算法对数据进行清洗和分析；业务应用层则将分析结果转化为具体的生产指令。这种结构化的设计使得排产智能体能够适应复杂多变的生产环境。<br/>在电子制造领域，排产智能体同样发挥着重要作用。某大型电子企业部署后，订单交付周期缩短了30%，设备闲置时间减少了40%。这种显著的改进不仅体现在生产效率上，还反映在企业的整体运营成本下降上。<br/>排产智能体的五大核心价值<br/>排产智能体在制造业中的价值主要体现在五个方面：首先是提升生产效率，通过智能算法实现资源的最优配置；其次是降低运营成本，减少人工干预和资源浪费；第三是增强供应链韧性，能够在突发情况下快速调整生产计划；第四是提高决策质量，基于数据而非直觉进行生产调度；最后是推动可持续发展，将环保因素纳入生产优化考量。<br/>以广域铭岛的案例为例，他们的排产智能体在实际应用中展现了强大的功能。它不仅能够处理常规的生产排程，还能应对复杂的约束条件，比如在冲压车间中协调2000多种模具的切换，将换模时间从4小时缩短至1.5小时。<br/>实施排产智能体面临的挑战及应对策略<br/>企业在推进排产智能体应用时，往往会遇到一些挑战。首先是数据质量问题，如果基础数据不准确，智能体的决策能力就会大打折扣。其次是系统集成困难，需要与现有的ERP、MES等系统建立无缝连接。此外，人员观念转变也是一个重要因素，传统生产管理人员需要适应新的工作方式。<br/>针对这些挑战，企业可以采取分阶段推进的策略。先从关键车间开始试点，逐步扩展到全厂范围。同时，加强员工培训，帮助他们理解智能体的工作原理和价值。还可以引入专业的数据治理工具，确保数据的准确性和实时性。<br/>排产智能体的未来发展趋势<br/>随着技术的不断进步，排产智能体将呈现更加多元化的发展趋势。<br/>首先是技术融合，将与更多的AI技术如强化学习、知识图谱等紧密结合<br/>其次是功能扩展，不仅限于生产排程，还将覆盖更多制造环节<br/>第三是生态构建，形成包括设备厂商、软件服务商、咨询公司等在内的产业生态<br/>最后是全球化服务，支持跨国工厂的协同生产，在马来西亚，广域铭岛已为汽车、零部件、物流、农业、种植业等各行业提供了数字化转型服务。例如为宝腾打造了以“柔性、敏捷、智能、透明”为特征的数字化工厂系统，这些落地案例，让“中国方案”赢得了当地企业的信任。</p>]]></description></item><item>    <title><![CDATA[zfs数据恢复—ZFS存储迁移数据出现问题的数据恢复案例 北亚数据恢复 ]]></title>    <link>https://segmentfault.com/a/1190000047461001</link>    <guid>https://segmentfault.com/a/1190000047461001</guid>    <pubDate>2025-12-09 15:08:22</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><strong>存储故障：</strong><br/>管理员对一台存储设备内的文件进行迁移操作时，数据突然无法读取，管理界面出现报错。管理员查看数据时发现其中一个lun的数据丢失。</p><p><strong>存储数据恢复过程：</strong><br/>1、服务器数据恢复工程师对原存储设备中所有硬盘以只读方式进行完整镜像，在镜像过程中观测硬盘的物理状态。后续的数据分析和数据恢复操作基于镜像文件进行，避免对原始磁盘数据造成二次破坏。<br/>2、基于镜像文件分析后发现存储设备被划分为多个磁盘组，所有硬盘均由ZFS进行管理。<br/>3、ZFS文件系统会在状态更新时更新文件系统入口。通过分析获取到了最新的入口指针后，北亚企安数据恢复工程师编写解析程序对文件系统入口程序进行地址解析，获取到所有硬盘的文件系统入口点，并顺藤摸瓜找到lun节点。<br/>4、北亚企安数据恢复工程师编写数据重组恢复工具并提取存储数据。<br/>5、数据提取完成后，由机房管理员对恢复出来的数据进行验证。经过验证，确认所有文件均可以正常打开和编辑，用户方认可数据恢复结果。<br/>6、在机房管理员的配合下，北亚企安数据恢复工程师将恢复出来的数据迁移回用户方准备好的存储设备中。本次存储数据恢复工作完成。</p>]]></description></item><item>    <title><![CDATA[LongCat 上线 AI 生图！精准高效，AI 创作不设限 美团技术团队 ]]></title>    <link>https://segmentfault.com/a/1190000047461076</link>    <guid>https://segmentfault.com/a/1190000047461076</guid>    <pubDate>2025-12-09 15:07:25</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>美团 LongCat 全新上线 AI 生图功能，该功能基于 LongCat系列模型「LongCat-Image」打造而成。不仅在文生图任务中实现了“快、真、准” ：出图快速响应、达到摄影棚拍摄质感、中文渲染精准度高；更在图像编辑任务上做到了精准便捷，无需复杂指令，可以用自然语言对图像进行二次编辑。无论是追求高效出图的普通用户，还是需要精准落地创意的专业创作者，LongCat 都以 “轻量化模型 + 流畅体验” ，让 AI 生图真正成为人人可用的创作工具。</p><p>目前，AI 生图功能已在  LongCat APP 和 <a href="https://link.segmentfault.com/?enc=bFmZV4P9jHVNblkIQzST%2FA%3D%3D.WrqZ02ysdGCIuE3Y30eHFBu50ZLhct3HHissnkNYBi4%3D" rel="nofollow" target="_blank">https://longcat.ai/</a> 同步上线，轻松解锁高效创作新方式。</p><h2>LongCat · AI 生图「三大功能亮点 」</h2><h3>亮点一：图像生成 + 编辑一体化，创意落地无断点</h3><p>从 “文字生成图片” 到 “用嘴改图” 一步到位，帮你轻松拿捏专业创作：</p><ul><li><strong>简单提示词也能高效出图</strong>：基于深度优化语义理解能力，简单提示词也能生成效果高度契合画面、布局、氛围及内容，在保障质量的前提下大幅提升创作效率。</li><li><strong>全场景编辑无断点</strong>：支持物体增删、风格迁移、视角转换、人像精修、文本修改等 15 类细分任务，无论是简单的背景替换，还是复杂的多轮复合指令，均能精准执行。</li><li><strong>多轮编辑不丢质感</strong>：修改后画面和原图风格、光影保持一致，不会出现 “拼接感”，人像编辑保留面部特征，多轮编辑画面不跑偏。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047461079" alt="prompt：头发颜色变成灰色，衣服颜色变成米色，面带微笑" title="prompt：头发颜色变成灰色，衣服颜色变成米色，面带微笑"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047461080" alt="prompt：拉远镜头，显示更多室内场景" title="prompt：拉远镜头，显示更多室内场景" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047461081" alt="prompt：将人物变为棕色的熊，保持相同的姿态" title="prompt：将人物变为棕色的熊，保持相同的姿态" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047461082" alt="prompt：消除最左边的饮料" title="prompt：消除最左边的饮料" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047461083" alt="prompt：让猫闭上眼睛" title="prompt：让猫闭上眼睛" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047461084" alt="prompt：变成真的老虎，在海边" title="prompt：变成真的老虎，在海边" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047461085" alt="prompt：在红色圈添加一个白色的钟表，绿色框添加黑色的手提包，黑色框添加一只白色的猫" title="prompt：在红色圈添加一个白色的钟表，绿色框添加黑色的手提包，黑色框添加一只白色的猫" loading="lazy"/></p><h3>亮点二：中文文字生成超能打，生僻字也不翻车</h3><p>中文文字生成能力优异，生僻字生成也不在话下：</p><ul><li><strong>字符渲染优异</strong>：店铺牌匾、海报标题、书籍封面等场景的中文文字，无错字、漏字、字体扭曲，多行排版、段落文本均能精准渲染</li><li><strong>生僻字高覆盖率</strong>：非常见字、异体字、书法字体（楷体、行书）准确率较高，适配传统文化、专业领域等特殊创作需求</li><li><strong>智能排版</strong>：自动匹配场景调整文字大小、颜色、行距，如古风文案搭配书法字体，科技主题适配现代无衬线字体，无需手动调整</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047461086" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047461087" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047461088" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047461089" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047461090" alt="" title="" loading="lazy"/></p><h3>亮点三：快速生成摄影棚级质感画面</h3><ul><li><strong>快速响应不等待</strong>：轻量化技术优化让单张高清图高效生成，效率较同类工具有一定提升，高频创作无需久候。</li><li><strong>质感堪比棚拍实景</strong>：优化构图与光影美学，物体纹理、场景光影精准复刻真实世界，人物肢体、物体比例遵循物理规律，实现摄影棚拍质感。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047461091" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047461092" alt="" title="" loading="lazy"/></p><h2>强大功能背后的「技术底座」</h2><p>LongCat-Image具备出色的跨语言图像编辑能力，通过共享 MM-DiT+Single-DiT 混合主干架构与VLM条件编码器，文生图与编辑能力相互辅助，继承文生图的出图质量并具备出色的指令遵循、一致性保持能力，在主流公开评测基准上达到第一梯队水平。文字生成专项能力上，<strong>覆盖全量通用规范汉字</strong>并在在商业海报、自然场景文字上都展现出极强的适用性。此外，通过精细化模型设计及多阶段训练策略优化，极大提升生成真实度、合理性并可支持消费级显卡高效推理。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047461093" alt="文字生成基准测试" title="文字生成基准测试" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047461094" alt="图像编辑基准测试性能比较" title="图像编辑基准测试性能比较" loading="lazy"/></p><h2>用 LongCat 记录你的「灵感瞬间」吧！</h2><p><strong>LongCat APP 体验入口</strong>：在「LongCat APP」中，你可以：输入一句话，生成高质量图像，或对生成图像进行迭代编辑、多轮生成，快速响应。</p><p><strong>LongCat Web 端入口</strong>：</p><p>您可以登录 <a href="https://link.segmentfault.com/?enc=dzEPdTr4DwBJZxl9CylDnw%3D%3D.y6GDe0Yo7xk5UC4VJdN%2BBtjpOmMUXV23B9efbtGJeGw%3D" rel="nofollow" target="_blank">https://longcat.ai/</a>  ，体验高效的 AI 生图功能，或对生成图像进行多轮编辑。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047461095" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047461096" alt="iOS 用户可在 APPStore 中搜索 「LongCat」" title="iOS 用户可在 APPStore 中搜索 「LongCat」" loading="lazy"/></p><p><strong>更多玩法探索</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047461097" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047461098" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047461099" alt="" title="" loading="lazy"/></p><p>| 关注「美团技术团队」微信公众号，在公众号菜单栏对话框回复【2024年货】、【2023年货】、【2022年货】、【2021年货】、【2020年货】、【2019年货】、【2018年货】、【2017年货】等关键词，可查看美团技术团队历年技术文章合集。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000046195963" alt="" title="" loading="lazy"/></p><p>| 本文系美团技术团队出品，著作权归属美团。欢迎出于分享和交流等非商业目的转载或使用本文内容，敬请注明“内容转载自美团技术团队”。本文未经许可，不得进行商业性转载或者使用。任何商用行为，请发送邮件至 <a href="mailto:tech@meituan.com" target="_blank">tech@meituan.com</a> 申请授权。</p>]]></description></item><item>    <title><![CDATA[工厂大脑怎么帮助企业降低生产缺陷率？ 月下水光 ]]></title>    <link>https://segmentfault.com/a/1190000047461101</link>    <guid>https://segmentfault.com/a/1190000047461101</guid>    <pubDate>2025-12-09 15:06:42</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在制造业奔涌向智能纪元的浪潮之巅，一座无形却无处不在的中枢正在重塑工厂的灵魂——它不是冰冷的机器，也不是僵化的程序，而是被称为“工厂大脑”的智能体，是数据、知识与决策在物理世界中的神经网络。广域铭岛，作为这场变革的先驱者，以工业AI大模型为血脉，以“云-边-端”架构为骨骼，构建出的不仅是一套系统，更是一种认知范式的颠覆：工厂不再依赖老师傅的经验直觉，而是被赋予了能“看”懂图像、“听”辨异响、“读”解日志、“悟”透机理的多模态感知力。<br/>这颗大脑，拒绝孤岛。它撕裂了传统MES系统那狭隘的执行边界，将质量、设备、库存、能耗、供应链等曾经割裂的哑区，熔铸成一个动态流转的智能生态。在重庆某电池工厂，它自主巡检的智能体完成98%的常规任务，人工干预沦为历史注脚；在汽车焊装线上，它实时调校工艺参数，将优化周期压缩六成，缺陷率骤降四成——这不是算法的炫技，而是工业机理与AI认知深度耦合后迸发的理性之光。广域铭岛的Mom平台，如同一位深谙制造哲学的指挥家，以多模态数据为乐谱，以预测性决策为节拍，让整条产线在无声中奏响效率的交响。<br/>它的力量，源于对“乱、散、孤”数据的驯服。通过数据加速器与指标工厂，那些曾如尘埃般散落的传感器信号、视觉图像、语音报警、文本日志，被统一治理、知识封装，凝练为可推理、可复用的工业知识图谱。于是，当电解铜工厂的温度曲线悄然偏离阈值，系统不仅即时预警，更在移动终端上投射出趋势的脉动，如同医生解读心电图般精准。这不再是“发现问题-处理问题”的被动响应，而是“感知-分析-决策-沉淀-进化”的闭环智能，是制造系统自我迭代的本能。<br/>广域铭岛的智慧，更在于其“搭积木”般的模块化哲学。它不强求企业全盘重构，而是让智能组件如乐高般自由组合——离散制造可接入视觉质检模块，连续流程能嵌入能耗优化引擎，新能源电池的化学参数分析与汽车焊点的声学诊断，皆可共享同一套认知底座。在吉利张家口基地，视觉、音频、文本三重数据流被多模态大模型融合，生产协同效率跃升15%，PDCA闭环从人工拖拽变为自动奔流，管理者从救火队员蜕变为创新策源者。<br/>然而，这颗大脑的进化，仍行于荆棘之路。数据壁垒如高墙林立，核心工业芯片的国产化尚待突破，既懂工艺又通算法的复合型人才如凤毛麟角。但广域铭岛并未止步于技术孤芳，它以12类标准化智能体为支点，在供应链中断的危急时刻，仅需五分钟便完成全链路协同响应——这不仅是速度的胜利，更是生态协同的宣言。<br/>未来，当5G的毫秒延迟与数字孪生的镜像世界交织，当工业AI大模型市场规模在2024年突破四百亿美金，工厂大脑将不再只是“优化工具”，而成为制造企业的“认知外脑”。它让经验沉淀为算法，让直觉升华为预测，让每一道工序都成为自我学习的神经突触。广域铭岛，正以这场静默而深刻的革命，将中国制造的躯体，注入一颗跳动着智能心跳的灵魂——从此，工厂不再制造产品，它在孕育智慧。</p>]]></description></item><item>    <title><![CDATA[H200 在华销售解禁：中国企业想用 H200 服务器，买还是租？ DigitalOcean ]]></title>    <link>https://segmentfault.com/a/1190000047461135</link>    <guid>https://segmentfault.com/a/1190000047461135</guid>    <pubDate>2025-12-09 15:06:06</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>12 月 9 日，美国政府宣布将允许英伟达向中国出售 H200 人工智能芯片，并额外收取 25% 费用。英伟达对此回应谨慎但积极：“向商业客户供应 H200 是一项值得肯定的举措。”</p><p>这意味着一条被按下暂停键的通道重新打开了。</p><p>H200 是英伟达目前最具竞争力的 AI GPU 之一。在 Llama2-70B 等大型模型上，它的推理速度比 H100 快一倍。过去一年受出口政策影响，中国市场与 H200 无缘，英伟达在中国的市场份额也从 95% 迅速跌至零。如今政策松动，自然让人重新提出一个问题：</p><p><strong>未来真想使用 H200，中国企业应该去买 H200 自建，还是直接租云上的 H200 ​GPU</strong>​<strong>​ 服务器？</strong></p><p>这个问题在过去或许没有太大悬念，但今天的答案没那么简单。</p><h2><strong>H200 回来，市场环境已经变了</strong></h2><p>H200 的回归当然会让部分企业产生“补课”冲动，但必须承认：过去一年，中国算力生态已经发生了实质变化。</p><p>腾讯说 GPU 资源“完全够用”；百度把绝大多数推理任务放在昆仑芯 P800 上；越来越多公司在公开场合提到“国产替代”。与此同时，谷歌 TPU 等 ASIC 加速器在海外快速扩张，Anthropic 更计划在 2026 年部署百万颗 TPU。</p><p>换句话说，<strong>H200 不再是“一出生就占据绝对中心位置”的那个 ​GPU</strong>​<strong>​ 了。</strong></p><p>企业在考虑它时，不只是在评估性能本身，而是在权衡一整套新现实：供应链、国产化趋势、预算、业务节奏，以及未来两三年的技术不确定性。</p><p>在这样的市场背景下，“买还是租”，变成了一道涉及战略与运营的实际选择题。</p><h2><strong>购买 H200 服务器：昂贵、缓慢，但在某些场景仍然必要</strong></h2><p>如果选择购买 H200 服务器，企业要面对的​<strong>首先是成本压力</strong>​。H200 本身就比 H100 贵，加上 25% 的政策费用，一台完整服务器的价格很容易冲到​<strong>几十万甚至百万人民币</strong>​。而且供应链也不可能立刻恢复：渠道排期、交付时间、整机溢价……这些都不是能快速解决的问题。</p><p>更关键的，是技术节奏的变化。大型模型领域更新太快，一台服务器往往要用​<strong>三年以上才能摊薄成本</strong>​，但行业可能不到一年就一次“代际跃迁”。对于预算有限、业务方向不稳定的公司来说，这样的投入意味着把手脚牢牢绑在硬件周期上。</p><p>当然，对于有稳定、大规模训练任务的大厂来说，购买仍然是合理的选择：</p><p>​<strong>内部数据敏感、任务量长期饱和、有运维团队、有机房、有资本</strong>​——这些因素叠加在一起，自建 H200 集群仍然划算。</p><p>但放眼整个市场，这类企业终究是少数。</p><h2>​<strong>租用 H200 云 ​GPU</strong>​<strong>：灵活、风险小，也更适合打造产品</strong></h2><p>越来越多 AI 企业，尤其是应用层团队，已经从“买服务器”转向“租云 GPU”。原因并不复杂：</p><p>在这个变化迅速的行业里，灵活比拥有更重要。</p><p>以 DigitalOcean 云平台为例，<a href="https://link.segmentfault.com/?enc=hlbhSJfKWo3vdYpipu3GOw%3D%3D.qrbXwaSvS3gvrLjS8sZ6JLEDUO2rcrgM%2F1rt%2FKySGOXvtgQSiGgEVHp069r5suMB" rel="nofollow" target="_blank">DigitalOcean 的 H200 GPU Droplet</a> 按需价格是 ​<strong>&amp;dollar;3.44/GPU/小时</strong>​。</p><p>这个数字意味着什么？ ——意味着一个中等规模的推理业务，<strong>一个月</strong>就算要用 200 小时 GPU，也不过​<strong>几百美元</strong>​； ——意味着企业想测试一个新模型、新方向，不需要等待服务器排产，也不需要先压上几十万人民币； ——意味着忙的时候扩容，闲的时候立刻停机，不需要为“高峰期可能会很忙”买整套设备。</p><p>尤其在中国企业向海外拓展业务的背景下，云上使用 H200 的另一个现实优势是：</p><p><strong>不需要和供应链搏斗。</strong></p><p>新 GPU 一上市，云厂商往往优先上架，企业只需要在后台切换规格即可。</p><p>对大多数创业团队、创新团队、海外业务部门而言，这已经足够构成决定性的吸引力。</p><h2><strong>为什么以 DigitalOcean 为例？因为云的复杂度本不该压在企业身上</strong></h2><p>有人可能会问：分析云租赁，为什么不直接用 AWS 或 GCP 的定价？</p><p>原因其实很简单：对于希望用好 GPU、但不想把时间花在看懂定价模型上的企业来说，DigitalOcean 的体验更接近“工程师真正习惯的云”。</p><p>AWS 和 GCP 的实力无可否认，但两者的 GPU 使用成本经常伴随：</p><ul><li>区域间巨大且复杂的价差；</li><li>令人难以预测的出站流量费用；</li><li>涉及上百种规格和组合的产品矩阵，学习成本高。</li></ul><p>当一个 AI 团队只想以最少的阻力、最低的可控成本把模型跑起来，这样的复杂度本身也会成为隐性成本。</p><p>DigitalOcean 的做法更直接：</p><ul><li>定价清晰透明，没有隐藏项；</li><li>GPU 实例规格简单，不需要在几十种组合里做选择；</li><li>跨境产品团队非常容易部署，而且中国区有独家战略合作伙伴卓普云 AI Droplet 为中国企业提供专业技术支持与商务对接；</li><li>甚至流量费用也是固定且易计算的，超出套餐额度的流量，所有区域都按照 0.01 美元/GB 计算，这个价格大约是 AWS 的十分之一（这是 AWS/GCP 最难控制的一项成本）。</li></ul><p>因此，在讨论“租 GPU”时，它是一个更适合作为示例的对象，也更贴近大多数企业和开发团队的日常。</p><h2><strong>给中国 AI 企业的一句话建议</strong></h2><p>如果企业已经有成熟的大模型训练体系，有固定算力需求，有稳定的机房和技术团队，也有足够的预算——那么 H200 回归，当然值得买上一批。</p><p>但如果企业正在探索业务方向、预算有限、应用层迭代较快，或者正在做海外业务——那么租用云上的 H200，尤其是类似 DigitalOcean 这种费用透明、扩缩容易的方案，会更符合今天的时代节奏。而且 DigitalOcean 即将在近期发布基于 NVIDIA B300 的 GPU Droplet 服务器，性能比 H200 高出 7～8 倍（根据官方数据，FP4 算力达 30 PFLOPS）。如果你希望抢先预订 B300，也可以提前咨询<a href="https://link.segmentfault.com/?enc=ZbidPxMz9twYpIDGuR%2BzvA%3D%3D.P8DVJE61rOPJz60fkkAAawsZHTrMQXgWwu4%2BKG%2FI%2BmU%3D" rel="nofollow" target="_blank"> DigitalOcean 中国区独家战略合作伙伴卓普云 aidroplet.com</a>。</p><p>简单总结来讲就是：<strong>买，是稳定期的策略；租，才是创新期的工具。</strong></p><p>而在中国 AI 行业仍处高速试错的当下，多数企业正处于“创新期”。</p>]]></description></item><item>    <title><![CDATA[公网访问开源 Stirling-PDF 工具，提升办公效率 ZeroNews内网穿透 ]]></title>    <link>https://segmentfault.com/a/1190000047461138</link>    <guid>https://segmentfault.com/a/1190000047461138</guid>    <pubDate>2025-12-09 15:05:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在日常工作中，PDF 文档的处理与编辑是常见需求。<br/>Stirling-PDF 作为一款功能强大、开源且基于网页的 PDF 工具箱，允许用户通过浏览器对 PDF 文件执行多种操作，而无需依赖在线服务，有效保障了数据隐私安全。<br/>本文将详细介绍如何在 Windows 系统本地部署 Stirling-PDF，并借助内网穿透技术实现外网访问，从而突破地域限制，提升工作效率。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047461141" alt="图片" title="图片"/><br/>一、 安装Stirling-PDF工具</p><ol><li>下载环境Stirling PDF for Windows 有两个版本：供个人使用的桌面应用程序和用于托管和与他人共享的服务器版本。<br/>我们本次使用的是服务器版本。<br/>下载：Stirling-PDF-with-login.jar<br/>需要用户帐户才能访问<br/>更适合共享/商业环境<br/>必需： Java JDK 21 - 服务器版本需要安装 Java</li><li>安装服务器<br/>根据上面的链接下载安装 Java JDK 21。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047461142" alt="图片" title="图片" loading="lazy"/></li></ol><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047461143" alt="图片" title="图片" loading="lazy"/><br/>运行刚才下载的 Stirling-PDF-with-login.jar 文件<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047461144" alt="图片" title="图片" loading="lazy"/></p><ol start="3"><li>运行本地环境<br/>在浏览器输入 http://<em>*</em>*:8080，然后按Enter 访问<br/>就可以打开刚安装的 Stirliing-PDF 服务器，然后输入下方展示的默认账号密码即可<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047461145" alt="图片" title="图片" loading="lazy"/><br/>首次登录后，记得修改密码。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047461146" alt="图片" title="图片" loading="lazy"/><br/>进入操作界面：支持 PDF 合并、拆分、压缩、水印等 10+ 功能<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047461147" alt="图片" title="图片" loading="lazy"/><br/>至此，本地 PDF 处理服务已就绪。<br/>接下来，我们来创建公网访问PDF的部分。</li></ol><p>二、 创建 ZeroNews 映射服务<br/>1、 首先，打开 ZeroNews 网站，然后选择您的系统，并按照对应的步骤和命令安装运行 Agent 服务。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047461148" alt="图片" title="图片" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047461149" alt="图片" title="图片" loading="lazy"/><br/>2、 运行完成之后，您可以在 Agent 页面看到已经在线的 Agent 服务。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047461150" alt="图片" title="图片" loading="lazy"/><br/>3、 接着，我们在域名端口页面，创建一个可用的公网域名，并勾选 HTTPS 协议端口。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047461151" alt="图片" title="图片" loading="lazy"/><br/>4、 域名创建完成之后，我们继续打开映射页面，并按下面的步骤添加映射。a) Agent：选择第一步运行的 Agentb) 映射协议：选择 HTTPS 协议c) 域名：选择刚创建好的域名d) 带宽：根据需要选择带宽大小e) 内网IP：我们是本地部署，直接使用 127.0.0.1 即可f) 内网端口：输入本地服务的端口 8080 即可<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047461152" alt="图片" title="图片" loading="lazy"/><br/>5、 按照上述步骤创建完成之后，我们就可以得到一条可公网访问的映射域名<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047461153" alt="图片" title="图片" loading="lazy"/></p><p>三、 公网访问与协作</p><ol><li>远程使用服务我们在任意有网络访问电脑的浏览器上，复制上面的链接 https://<strong><em>.<strong>.</strong></em></strong>. 并打开访问。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047461154" alt="图片" title="图片" loading="lazy"/><br/>输入刚才修改后的账号密码。即可在线使用所有 PDF 处理功能（效果与本地一致）<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047461155" alt="图片" title="图片" loading="lazy"/></li><li>团队协作<br/>将公网地址分享给同事/客户<br/>对方无需安装任何软件，通过浏览器即可安全操作 PDF</li></ol><p>最后<br/>通过本地部署 Stirling-PDF 并结合 ZeroNews 内网穿透技术，可以构建了一个既安全又便捷的远程 PDF 处理方案。此方案不仅充分发挥了开源软件免费、灵活的优势，还通过内网穿透解决了公网访问的难题，特别适合对数据安全有要求的办公场景以及需要远程协作的团队，显著提升了文档处理的灵活性与工作效率。</p><p>希望本教程对您有所帮助！如果您在部署过程中遇到问题，可以联系我们官网客服处理。</p>]]></description></item><item>    <title><![CDATA[产业大脑怎么帮助企业降低生产良率波动？ 月下水光 ]]></title>    <link>https://segmentfault.com/a/1190000047461176</link>    <guid>https://segmentfault.com/a/1190000047461176</guid>    <pubDate>2025-12-09 15:04:47</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在数字经济的深海中，一座无形却磅礴的智慧中枢正悄然崛起——产业大脑。它不是冰冷的数据库，也不是简单的可视化看板，而是以数据为血脉、以AI为神经、以产业链为骨骼，重构区域经济命脉的数字生命体。它穿透企业孤岛，缝合供应链断点，将散落于税务、专利、招投标、舆情与生产日志中的碎片化信息，淬炼成可感知、可预测、可干预的产业认知图谱。在这场从经验驱动到数据驱动的文明跃迁中，产业大脑成为地方政府手中那支能精准描摹产业脉络、预判风险潮汐、引导资源流向的数字画笔。<br/>它不满足于静态的产业地图，而是构建动态的“数字孪生生态”——每一台设备的振动、每一批原材料的流转、每一笔融资的流向，都被纳入其感知网络。当某地电解铝企业因能源成本飙升而濒临停产，产业大脑能瞬间联动碳足迹数据、电网负荷曲线与区域补贴政策，推演出最优的绿电置换路径；当新能源汽车供应链因某地电池材料断供而震颤，它便能以图谱为刃，精准切割出替代供应商网络，甚至预判下游整车厂的产能瓶颈。这种能力，早已超越了传统统计报表的范畴，它让决策者不再在迷雾中摸索，而是在数据的星图中航行。<br/>在这场变革的前沿，广域铭岛的Geega平台正以工业智能体为引擎，为产业大脑注入前所未有的“行动力”。它不只提供数据，更赋予系统“思考”与“执行”的意志。当产业大脑识别出某区域汽车零部件集群存在焊装良率波动的隐忧，广域铭岛的工业智造超级智能体便如隐匿于产线深处的神经元集群，自动调取287条焊接工艺知识规则，结合实时设备振动与温度数据流，生成优化参数组合，并通过API中台无缝注入MES系统——整个过程无需人工干预，响应速度提升80%，年省千万质量成本。这不是技术叠加，而是认知升维：产业大脑看见问题，广域铭岛的智能体则亲手修复它。<br/>更令人震撼的是，这种协同正从单点突破走向生态共振。在领克成都工厂，每日1.2亿次系统交互曾如巴别塔般混乱，而广域铭岛以API全生命周期管理为经，以工业智能体为纬，编织出一张跨系统、跨企业、跨协议的智能神经网。当某铝加工企业突发断供，12类智能体在5分钟内协同推演3套应急方案，历史数据验证、物流路径重排、供应商信用评估一气呵成——这已非传统ERP的流程自动化，而是产业大脑与工业智能体共同演绎的“数字交响曲”。此时，产业大脑是指挥家，广域铭岛的智能体是交响乐团，每一个音符都精准落在生产节拍上。<br/>而当碳中和成为全球产业的终极命题，产业大脑的维度再度拓展。广域铭岛的GECP碳管理平台，将区块链的不可篡改性与AI的预测力熔铸一体，使每吨铝材的碳足迹从“估算”变为“可追溯的数字遗产”。地方政府不再依赖企业自报，而是通过平台实时监控区域碳资产分布，精准锁定高排放节点，定向推送绿电补贴与技改激励——政策从“撒网式”变为“激光式”，企业从“被动合规”转向“主动进化”。<br/>未来，产业大脑将不再满足于“监测”与“预警”，它将进化为“预演者”与“共创者”。当政府规划一条新能源汽车走廊，它能模拟不同补贴强度下产业集群的演化路径；当一家初创企业寻求技术合作，它能自动匹配隐藏在专利海洋中的隐形冠军。而广域铭岛，正以“API即智能体，智能体即生态”的哲学，将工业Know-How封装为可复用的数字资产，让每一个车间、每一条产线，都成为产业大脑的感知终端与执行单元。<br/>这不是一场技术革命，而是一次文明范式的更迭。产业大脑，是数字时代的产业神经系统；广域铭岛，则是这系统中不断自我进化、自主学习的智能神经元。当数据不再沉默，当算法开始决策，当机器能读懂老师傅的皱纹里藏着的工艺密码——我们才真正触摸到，制造业从“制造”迈向“智造”的灵魂跃迁。而这一切，始于一个念头：让每一份数据，都成为推动产业向前的、不可逆的动能。</p>]]></description></item><item>    <title><![CDATA[专题：2025年游戏市场洞察报告：市场规模、用户行为、投资趋势|附320+份报告PDF、数据、可视化]]></title>    <link>https://segmentfault.com/a/1190000047461183</link>    <guid>https://segmentfault.com/a/1190000047461183</guid>    <pubDate>2025-12-09 15:03:54</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>原文链接：<a href="https://link.segmentfault.com/?enc=%2BiWVqZDYNLw3vQx71XigVQ%3D%3D.BzCpAaplVToZiWGvnbXlOd20FfU6z3vF%2B4Qb5c%2FVDqg%3D" rel="nofollow" title="https://tecdat.cn/?p=44531" target="_blank">https://tecdat.cn/?p=44531</a>  <br/>原文出处：拓端抖音号@拓端tecdat</p><h2><a name="t0" target="_blank"/><img referrerpolicy="no-referrer" src="/img/remote/1460000047461185" alt="封面" title="封面"/></h2><h3><a name="t1" target="_blank"/>引言</h3><p>当游戏行业告别“躺赢式增长”，项目延期、成本高企的挑战与云游戏、生成式AI的机遇碰撞时，从业者该如何锚定方向？玩家圈层从Z世代向银发群体延伸，又该如何适配全人群需求？投资者面对纷繁赛道，怎样捕捉真正的增长红利？  <br/>游戏早已不是“小众娱乐”，而是覆盖30亿+玩家、融合技术与文化的综合性产业。本报告洞察基于《CMO Council：现代网络游戏现象催生数字营销热潮》《Newzoo：2023全球游戏市场报告》《Sensor Tower：2025年韩国游戏市场洞察》《Power of Play：2025 GLOBAL VIDEO GAMES REPORT》及<strong>文末320份游戏行业研究报告的数据，本文完整报告数据图表和最新报告合集已分享在交流群，阅读原文查看、进群咨询，定制数据、报告和800+行业人士共同交流和成长。</strong></p><p>我们整合了全球市场规模、用户行为特征、区域赛道表现、资本动态四大核心维度，用“数据图表+落地建议”的形式，为开发者、投资者、营销人员提供可直接复用的决策参考，帮你在变革期找到确定性增长路径。</p><h3><a name="t2" target="_blank"/>一、全球游戏市场规模：技术与需求双轮驱动，十年规模将翻倍</h3><p>全球游戏市场正从“高速增长”转向“高质量增长”，2024年在线游戏市场规模已达2083.3亿美元，这个数字意味着什么？相当于全球电影市场规模的3倍多。更关键的是，预计2025年将突破2252.8亿美元，到2032年更是有望飙升至4241.4亿美元，十年近乎翻倍，复合年增长率稳定在9.5%。这背后不只是移动设备的普及，更有云游戏降低体验门槛、生成式AI提升开发效率的技术赋能——比如Unity最新AI工具已能将场景建模时间缩短40%，直接推动中小团队加速产品迭代。<img referrerpolicy="no-referrer" src="/img/remote/1460000047461186" alt="" title="" loading="lazy"/></p><h4><a name="t3" target="_blank"/>全球在线游戏市场规模预测折线图表1</h4><p>全球在线游戏市场规模预测折线图表1图表数据及PDF模板已分享到会员群  <br/>3秒解读：2025年是行业“承前启后”关键年，前有疫情后需求回稳，后有技术驱动新增长。  <br/>对应人群行动建议：开发者可聚焦2025-2030年窗口期，布局长线IP产品（如跨平台叙事类游戏）；投资者可重点关注头部企业的技术投入（如腾讯、网易的AI开发团队规模），技术迭代快的企业更易抢占先机。  <br/>如果说整体市场是“基本盘”，那游戏化与电子竞技就是“增长引擎”。2024年游戏化全球市场规模达430亿美元，预计2030年将冲至1724亿美元，复合年增长率高达26.1%——这源于品牌方对“游戏化营销”的追捧，比如星巴克用“咖啡种植小游戏”提升用户留存率35%。电子竞技同样不逊色，2025年全球收入预计达18.6亿美元，较2020年近乎翻倍，直播平台的赛事订阅、品牌赞助是核心动力，像《英雄联盟》S14全球总决赛赞助收入已突破2亿美元，赛事IP商业化日趋成熟。<img referrerpolicy="no-referrer" src="/img/remote/1460000047461187" alt="" title="" loading="lazy"/></p><h4><a name="t4" target="_blank"/>游戏化与电子竞技市场规模阴影条形图表2</h4><p>游戏化与电子竞技市场规模阴影条形图表2图表数据及PDF模板已分享到会员群  <br/>3秒解读：游戏化跨界、电竞商业化是未来5年最值得关注的两大细分赛道。  <br/>对应人群行动建议：品牌方可探索“产品功能+游戏化”场景（如健身APP加入关卡挑战）；电竞战队可加大赛事IP运营，比如开发战队周边、推出粉丝互动小程序，提升非赞助收入占比。</p><h3><a name="t5" target="_blank"/>二、用户行为与平台表现：全人群渗透下，如何抓准不同圈层需求？</h3><h4><a name="t6" target="_blank"/>（一）年龄破圈：55岁以上玩家占比22%，“银发市场”不能忽视</h4><p>全球玩家早已不是“年轻人专属”，25-34岁群体虽仍是核心（占比26%）——他们是《Valorant》《原神》等中核游戏的主力付费人群，月均付费可达150-300美元；但35-44岁群体占比23%，55岁以上群体合计占22%，这些“银发玩家”更偏爱轻量化、社交型游戏，比如《开心消消乐》海外版在55+人群中的留存率达60%，远超行业平均水平。这意味着“全年龄覆盖”不再是口号，而是必须落地的产品策略。</p><p>3秒解读：中老年玩家是“增量蓝海”，但需求与年轻群体差异显著。  <br/>对应人群行动建议：开发者可针对中老年群体设计“大字体、低操作门槛”的社交游戏（如线上麻将、广场舞互动游戏）；营销方可联合社区、老年大学开展线下体验活动，降低用户认知门槛。  <br/>玩家对游戏的价值认同也呈现“多维度分化”：超80%玩家认可游戏的“心理价值”——81%认为能提供心理刺激，80%觉得能减压，比如疫情期间《动物森友会》帮助超40%玩家缓解焦虑；但“社交价值”认可度相对较低，仅64%认为能减少孤独感，62%认可情感支持作用。这提示开发者：在玩法设计中需强化“轻社交”场景，比如加入“亲友组队副本”“社区聊天频道”，避免复杂社交门槛劝退用户。<img referrerpolicy="no-referrer" src="/img/remote/1460000047461188" alt="" title="" loading="lazy"/></p><h4><a name="t7" target="_blank"/>玩家同意游戏益处百分比雷达图表9</h4><p>玩家同意游戏益处百分比雷达图表9图表数据及PDF模板已分享到会员群  <br/>3秒解读：游戏的“心理疗愈”价值已获广泛认可，社交功能仍有优化空间。  <br/>对应人群行动建议：开发者可在游戏内加入“情绪日记”“好友互助任务”等功能，提升社交粘性；运营方可搭建玩家线下社群（如城市桌游局），将线上社交延伸至线下，增强情感联结。</p><h4><a name="t8" target="_blank"/>（二）平台选择：抖音“破圈”vs微博“沉淀”，双平台策略该怎么玩？</h4><p>做游戏IP营销，绕不开抖音与微博，但两者的定位截然不同。从声量看，抖音总声量27736，是微博（5036）的5倍多——抖音用户通过“角色仿妆”“玩法挑战”快速扩散内容，比如《鬼灭之刃》相关二创视频在抖音播放量超50亿次；而微博更侧重“官方信息发布”，核心粉丝在此沉淀，像#鬼灭之刃无限城篇定档#话题在微博互动量达16.8万，多为粉丝的深度讨论。<img referrerpolicy="no-referrer" src="/img/remote/1460000047461189" alt="" title="" loading="lazy"/></p><h4><a name="t9" target="_blank"/>微博与抖音平台声量对比横向比例条形图表3</h4><p>微博与抖音平台声量对比横向比例条形图表3图表数据及PDF模板已分享到会员群  <br/>3秒解读：抖音是“大众化破圈”主阵地，微博是“核心粉丝运营”关键场。  <br/>对应人群行动建议：营销方可在抖音投放“角色向二创素材”（如《Seven Knights Re:Birth》英雄技能演示），发起#我的本命英雄#挑战；在微博开展“官方问答”“粉丝共创活动”（如征集游戏皮肤设计），沉淀核心用户。  <br/>互动量的差距更明显：抖音总互动量615.5万，是微博（23.7万）的25倍。抖音的算法能精准推送优质内容，比如《Whiteout Survival》的“雪地生存技巧”视频，被推送给“策略游戏爱好者”后，互动率提升200%；而微博互动依赖官方与KOL引导，适合深度触达。<img referrerpolicy="no-referrer" src="/img/remote/1460000047461190" alt="" title="" loading="lazy"/></p><h4><a name="t10" target="_blank"/>微博与抖音平台互动量对比多边形条形图表4</h4><p>微博与抖音平台互动量对比多边形条形图表4图表数据及PDF模板已分享到会员群  <br/>3秒解读：抖音适合“快速拉新”，微博适合“用户留存”，两者需搭配使用。  <br/>对应人群行动建议：开发者可在抖音发起“游戏玩法教学”挑战，吸引潜在用户；在微博组织“玩家攻略征集”，优秀攻略可获游戏道具奖励，提升用户活跃度。</p><h4><a name="t11" target="_blank"/>（三）情感倾向：微博“正面”vs抖音“多元”，争议内容该如何引导？</h4><p>微博的讨论氛围更积极，平均净情感度60.31%，用户常表达对“无删减内容”“IP情怀”的认可；而抖音净情感度24.39%，因大量中性玩梗、CP争议拉低评分——比如《鬼灭之刃》“锖义”CP相关视频，既有粉丝支持，也有反对声音。<img referrerpolicy="no-referrer" src="/img/remote/1460000047461191" alt="" title="" loading="lazy"/></p><h4><a name="t12" target="_blank"/>微博与抖音平台净情感度对比灰底比例条形图表5</h4><p>微博与抖音平台净情感度对比灰底比例条形图表5图表数据及PDF模板已分享到会员群  <br/>3秒解读：微博适合传递“正面信息”，抖音需做好“争议管理”。  <br/>对应人群行动建议：运营方在微博可重点发布“游戏更新”“福利活动”等正面内容；在抖音设置“二创规范”（如禁止OOC内容），对争议话题及时发布“官方解读”，避免舆情发酵。  <br/>话题驱动逻辑也不同：抖音TOP话题多围绕角色（如#富冈义勇#互动量37.9万），用户通过二创推动热度；微博TOP话题聚焦官方事件（如#电影鬼灭之刃[超话]#互动量19万），PGC内容主导走向。<img referrerpolicy="no-referrer" src="/img/remote/1460000047461192" alt="" title="" loading="lazy"/></p><h4><a name="t13" target="_blank"/>抖音平台TOP话题互动量刻度线图表6</h4><p>抖音平台TOP话题互动量刻度线图表6图表数据及PDF模板已分享到会员群<img referrerpolicy="no-referrer" src="/img/remote/1460000047461193" alt="" title="" loading="lazy"/></p><h4><a name="t14" target="_blank"/>微博平台TOP话题互动量条形图表7</h4><p>微博平台TOP话题互动量条形图表7图表数据及PDF模板已分享到会员群  <br/>3秒解读：抖音要“盘活角色IP”，微博要“做好事件营销”，精准匹配平台特性。  <br/>对应人群行动建议：IP方可在抖音释放“角色素材包”（如高清立绘、配音素材），激发用户二创；在微博围绕“游戏上线”“版本更新”等节点制造话题，联合媒体发布深度报道，提升官方信息触达效率。</p><hr/><p><strong>相关文章</strong><img referrerpolicy="no-referrer" src="/img/remote/1460000047461194" alt="" title="" loading="lazy"/></p><h3><a name="t15" target="_blank"/>专题：2025全球游戏产业趋势洞察报告 | 附130+份报告PDF、数据、可视化模板汇总下载</h3><p>原文链接：<a href="https://link.segmentfault.com/?enc=4AqDJ5NTDNTAiQ7ouH8yRw%3D%3D.BHirjqlAKxbq%2BG5CqU%2BtT4k15sQgL2HsslPHQNRb0Dk%3D" rel="nofollow" title="https://tecdat.cn/?p=44307" target="_blank">https://tecdat.cn/?p=44307</a></p><hr/><h3><a name="t16" target="_blank"/>三、细分市场与投资趋势：区域爆发+资本活跃，哪些机会不能错过？</h3><h4><a name="t17" target="_blank"/>（一）移动游戏：全球稳增，韩国市场成“出海必争之地”</h4><p>移动游戏仍是全球市场“压舱石”，2024年内购收入810亿美元，超越2020年疫情高点，2025年预计增长6%至854亿美元，2028年将突破1050亿美元。这背后是智能手机性能的提升——比如iPhone 16的GPU性能提升30%，能流畅运行“主机级”手游《原神》4K画质；同时休闲与中核玩家需求双爆发，像《Royal Match》（休闲）与《Honkai: Star Rail》（中核）均跻身全球收入TOP10。<img referrerpolicy="no-referrer" src="/img/remote/1460000047461195" alt="" title="" loading="lazy"/></p><h4><a name="t18" target="_blank"/>全球手游内购收入折线图表12</h4><p>全球手游内购收入折线图表12图表数据及PDF模板已分享到会员群  <br/>3秒解读：手游收入稳步上升，2028年将迈入“千亿美金俱乐部”，中核与休闲赛道双增长。  <br/>对应人群行动建议：开发者可优化内购设计（如《Fortnite》赛季通行证模式，提升复购）；渠道方可强化“用户分层运营”，为休闲玩家推荐轻量内容，为中核玩家推荐深度玩法。  <br/>韩国手游市场是“区域明星”，2025年内购收入预计53亿美元，Google Play占比75%（因韩国Android用户占比高）。子品类中，回合制RPG增速最猛（138%），核心是《Seven Knights Re:Birth》的爆发——这款“七骑士”IP重制版，上线5个月吸金1.2亿美元，靠的是“经典角色重绘+现代化养成系统”；4X策略（25%）、合成类（89%）也增长显著，反映韩国玩家对“策略+收集”玩法的偏爱。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047461196" alt="" title="" loading="lazy"/></p><h4><a name="t19" target="_blank"/>韩国手游子品类收入同比增长率双轴图表13</h4><p>韩国手游子品类收入同比增长率双轴图表13图表数据及PDF模板已分享到会员群  <br/>3秒解读：韩国市场“IP改编+策略玩法”组合最吸金，新游是核心增长动力。  <br/>对应人群行动建议：开发者可优先选择韩国本土热门IP（如“高达”“泡菜漫画”）改编，玩法聚焦回合制RPG或4X策略；发行商可与Naver、Kakao Games等本土渠道合作，开展“IP联动推广”（如在Naver漫画植入游戏广告）。  <br/>发行商格局也有新变化：本土厂商Netmarble靠《Seven Knights Re:Birth》《RF Online Next》，收入环比增长71%；海外厂商不甘示弱，点点互动（77%）、柠檬微趣（101%）靠“本地化运营”突围——比如点点互动《Whiteout Survival》针对韩国玩家调整“雪地场景”美术风格，付费率提升15%。<img referrerpolicy="no-referrer" src="/img/remote/1460000047461197" alt="" title="" loading="lazy"/></p><h4><a name="t20" target="_blank"/>韩国手游发行商内购收入环比增长率瀑布图表14</h4><p>韩国手游发行商内购收入环比增长率瀑布图表14图表数据及PDF模板已分享到会员群  <br/>3秒解读：韩国市场“本土+海外”厂商共分蛋糕，本地化与新游节奏是关键。  <br/>对应人群行动建议：发行商可加大新游投放频率（如每季度1款重点产品），同时优化本地化（如韩语配音、韩国节日活动）；投资者可关注“有韩国渠道资源”的出海企业，这类企业更易降低市场风险。</p><h4><a name="t21" target="_blank"/>（二）资本市场：股票+VC双活跃，投资逻辑该怎么定？</h4><p>2025年游戏公司股票表现亮眼，Roblox以136.9%回报率领跑——它靠“用户生成内容（UGC）平台”模式，吸引超7000万月活开发者，UGC内容占比达60%；Unity（77.9%）、everplay（75.0%）受益于开发工具普及；中国企业网易（72.6%）、腾讯（59.6%）靠“本土稳健+全球化布局”，比如网易《永劫无间》海外收入占比已达40%。<img referrerpolicy="no-referrer" src="/img/remote/1460000047461198" alt="" title="" loading="lazy"/></p><h4><a name="t22" target="_blank"/>2025年游戏公司股票回报率半圆面积图表10</h4><p>2025年游戏公司股票回报率半圆面积图表10图表数据及PDF模板已分享到会员群  <br/>3秒解读：技术驱动型平台与全球化龙头更受资本青睐，增长性与稳定性兼顾。  <br/>对应人群行动建议：投资者可关注两类企业——一是“工具+平台”型（如Roblox、Unity），二是“本土+海外”双轮驱动型（如网易、腾讯）；企业可加大研发投入（如AI开发工具）与海外团队建设，提升长期竞争力。  <br/>VC领域也热闹，近12个月BITKRAFT以15笔交易成最活跃投资者，重点布局移动与区块链游戏；Play Ventures（14笔）、Griffin Gaming Partners（13笔）聚焦初创公司。移动游戏因“用户基数大、变现成熟”受捧，区块链游戏靠“玩赚（P2E）”模式吸引资本，比如《Axie Infinity》开发商新获2亿美元融资，用于优化P2E经济模型。<img referrerpolicy="no-referrer" src="/img/remote/1460000047461199" alt="" title="" loading="lazy"/></p><h4><a name="t23" target="_blank"/>游戏行业顶级投资者交易数热图表11</h4><p>游戏行业顶级投资者交易数热图表11图表数据及PDF模板已分享到会员群  <br/>3秒解读：VC资本偏爱“成熟赛道+创新模式”，移动与区块链是当前热点。  <br/>对应人群行动建议：初创公司可聚焦“移动策略”“区块链+UGC”赛道，打磨核心玩法后主动对接活跃投资者；投资者可重点评估项目的“技术壁垒”（如AI生成内容工具）与“用户留存”，避免盲目追风口。</p><h3><a name="t24" target="_blank"/>四、核心数据对比与落地指引：用数据避坑，用行动落地</h3><h4><a name="t25" target="_blank"/>（一）不同报告数据差异对比表</h4><table><thead><tr><th>核心主题</th><th>报告名称</th><th>核心结论</th><th>数据差异</th><th>原因分析</th></tr></thead><tbody><tr><td>全球游戏市场规模</td><td>《CMO Council：现代网络游戏现象催生数字营销热潮》</td><td>2024年2083.3亿美元，2032年4241.4亿美元，CAGR 9.5%</td><td>与《Newzoo：2023全球游戏市场报告》2023年187.7亿美元基数一致，但长期CAGR高2.1个百分点</td><td>统计范围不同：CMO Council聚焦“在线游戏”（含移动、PC、主机在线）；Newzoo覆盖全品类（含线下桌游），长期预测更保守</td></tr><tr><td>手游内购收入</td><td>《Sensor Tower：2025年韩国游戏市场洞察》</td><td>2024年全球810亿美元，2028年1050亿美元</td><td>与《Power of Play：2025 GLOBAL VIDEO GAMES REPORT》相比，2028年预测值高8%</td><td>时间周期与口径不同：Sensor Tower仅统计内购（不含广告）；Power of Play含广告收入，且预测至2030年，分摊短期增长</td></tr><tr><td>玩家年龄占比</td><td>《Power of Play：2025 GLOBAL VIDEO GAMES REPORT》</td><td>25-34岁占26%，55岁以上占22%</td><td>与《Sensor Tower：2025年日本游戏市场洞察》相比，55岁以上占比高7个百分点</td><td>样本范围不同：Power of Play覆盖21国（含多成熟市场）；Sensor Tower日本报告聚焦单一区域，中老年渗透较低</td></tr><tr><td>电竞收入</td><td>《CMO Council：现代网络游戏现象催生数字营销热潮》</td><td>2025年全球18.6亿美元</td><td>与《DRAKE STAR：2025年第三季度全球游戏报告》相比，高12%</td><td>统计内容不同：CMO Council含赛事门票、周边；DRAKE STAR仅统计赞助与直播</td></tr></tbody></table><h4><a name="t26" target="_blank"/>（二）可落地的3件事（本周就能动起来）</h4><ol><li><strong>游戏开发者</strong>：①针对25-34岁与55+人群，同步推进两款demo——中核款做“回合制RPG+IP改编”（参考《Seven Knights Re:Birth》），轻量化款做“合成类+社交功能”（如加入亲友助力）；②对接韩国Naver、Kakao渠道，准备“本地化素材包”（韩语配音、中秋活动策划）；③在游戏内加入“UGC编辑器”（参考Roblox），邀请100名核心玩家测试，收集优化建议。</li><li><strong>营销人员</strong>：①本周启动“抖音+微博”双平台测试——抖音投放《Whiteout Survival》“雪地生存技巧”二创视频，带#策略游戏攻略#话题；微博发起“#我心中的本命英雄#”征集，优秀作品奖励游戏周边；②联系瑞幸咖啡，初步洽谈“游戏IP联名”（如《鬼灭之刃》主题饮品），明确合作成本与曝光资源；③监测两平台情感倾向，对抖音“CP争议”内容，发布“官方角色关系解读”，引导正面讨论。</li><li><strong>投资者</strong>：①梳理“技术驱动型平台”股票池（Roblox、Unity）与“全球化龙头”（网易、腾讯），对比近3个季度研发投入占比，筛选投入持续增长的标的；②联系BITKRAFT、Play Ventures，获取其投资的初创项目清单，重点评估“移动策略”“区块链+UGC”项目的用户留存数据；③制作“韩国市场数据跟踪表”，每周更新Netmarble、点点互动等厂商的新游表现，捕捉出海机会。</li></ol><h4><a name="t27" target="_blank"/>（三）风险提示与应对方案（附社群支持）</h4><ol><li><strong>风险</strong>：生成式AI开发侵权——用AI生成的角色形象，可能与现有IP相似，引发法律纠纷。  <br/>  应对方案：①建立“AI内容审核流程”，用开源数据集训练模型，生成后与知名IP库比对（可使用百度AI侵权检测工具）；②加入“游戏行业合规社群”（本报告交流群内有合规专家），获取《AI生成内容版权指南》；③若改编IP，提前与版权方签订“AI使用授权协议”，明确“AI生成内容归属”条款。</li><li><strong>风险</strong>：移动隐私政策收紧——苹果ATT政策、欧盟《数字市场法案》导致用户获取成本上升30%，精准度下降。  <br/>  应对方案：①本周调整获客策略，从“广告投放”转向“内容营销”——在B站发布“游戏开发幕后”视频，带#独立游戏制作#话题；②与Sensor Tower合作，基于“匿名用户行为数据”优化投放，避免触碰隐私红线；③在交流群内领取《全球隐私政策适配模板》，对照调整APP权限申请文案。</li><li><strong>风险</strong>：海外IP内容审查——引进日本动漫IP时，内容可能因文化差异被要求删减，引发核心粉丝不满。  <br/>  应对方案：①提前调研目标市场审查标准（如中国广电总局“暴力画面限制”、韩国“角色服装规范”），在开发阶段预留“可调整版本”；②通过微博超话，发布“内容适配说明”，邀请100名核心粉丝参与“调整方案投票”；③同步推出“完整版设定集”（含未删减角色设计），在交流群内优先发售，补偿粉丝情感需求。</li></ol><h4><a name="t28" target="_blank"/>（四）核心数据汇总表</h4><table><thead><tr><th>指标分类</th><th>具体指标</th><th>数值</th><th>时间维度</th><th>数据来源</th></tr></thead><tbody><tr><td>市场规模</td><td>2024年全球在线游戏市场规模</td><td>2083.3亿美元</td><td>年度</td><td>《CMO Council：现代网络游戏现象催生数字营销热潮》</td></tr><tr><td>市场规模</td><td>2032年全球在线游戏市场规模预测</td><td>4241.4亿美元</td><td>年度</td><td>《CMO Council：现代网络游戏现象催生数字营销热潮》</td></tr><tr><td>市场规模</td><td>2024-2032年全球在线游戏CAGR</td><td>9.5%</td><td>复合年增长率</td><td>《CMO Council：现代网络游戏现象催生数字营销热潮》</td></tr><tr><td>市场规模</td><td>2024年全球游戏化市场规模</td><td>430亿美元</td><td>年度</td><td>《CMO Council：现代网络游戏现象催生数字营销热潮》</td></tr><tr><td>市场规模</td><td>2030年全球游戏化市场规模预测</td><td>1724亿美元</td><td>年度</td><td>《CMO Council：现代网络游戏现象催生数字营销热潮》</td></tr><tr><td>市场规模</td><td>2024-2030年全球游戏化CAGR</td><td>26.1%</td><td>复合年增长率</td><td>《CMO Council：现代网络游戏现象催生数字营销热潮》</td></tr><tr><td>市场规模</td><td>2025年全球电竞收入预测</td><td>18.6亿美元</td><td>年度</td><td>《CMO Council：现代网络游戏现象催生数字营销热潮》</td></tr><tr><td>手游数据</td><td>2024年全球手游内购收入</td><td>810亿美元</td><td>年度</td><td>《Sensor Tower：2025年韩国游戏市场洞察》</td></tr><tr><td>手游数据</td><td>2028年全球手游内购收入预测</td><td>1050亿美元</td><td>年度</td><td>《Sensor Tower：2025年韩国游戏市场洞察》</td></tr><tr><td>手游数据</td><td>2025年韩国手游内购收入预测</td><td>53亿美元</td><td>年度</td><td>《Sensor Tower：2025年韩国游戏市场洞察》</td></tr><tr><td>玩家行为</td><td>25-34岁玩家占比</td><td>26%</td><td>2025年</td><td>《Power of Play：2025 GLOBAL VIDEO GAMES REPORT》</td></tr><tr><td>玩家行为</td><td>55岁以上玩家占比</td><td>22%</td><td>2025年</td><td>《Power of Play：2025 GLOBAL VIDEO GAMES REPORT》</td></tr><tr><td>玩家行为</td><td>游戏心理刺激认可度</td><td>81%</td><td>2025年</td><td>《Power of Play：2025 GLOBAL VIDEO GAMES REPORT》</td></tr><tr><td>玩家行为</td><td>游戏减压效果认可度</td><td>80%</td><td>2025年</td><td>《Power of Play：2025 GLOBAL VIDEO GAMES REPORT》</td></tr><tr><td>资本市场</td><td>Roblox 2025年股票回报率</td><td>136.9%</td><td>年度</td><td>《DRAKE STAR：2025年第三季度全球游戏报告》</td></tr><tr><td>资本市场</td><td>BITKRAFT近12个月游戏交易数</td><td>15笔</td><td>年度</td><td>《DRAKE STAR：2025年第三季度全球游戏报告》</td></tr><tr><td>资本市场</td><td>网易2025年股票回报率</td><td>72.6%</td><td>年度</td><td>《DRAKE STAR：2025年第三季度全球游戏报告》</td></tr></tbody></table><h3><a name="t29" target="_blank"/>文末数据图表列表</h3><ol><li>全球在线游戏市场规模预测折线图表1</li><li>游戏化与电子竞技市场规模阴影条形图表2</li><li>微博与抖音平台声量对比横向比例条形图表3</li><li>微博与抖音平台互动量对比多边形条形图表4</li><li>微博与抖音平台净情感度对比灰底比例条形图表5</li><li>抖音平台TOP话题互动量刻度线图表6</li><li>微博平台TOP话题互动量条形图表7</li><li>2025年全球游戏玩家年龄分布华夫图表8</li><li>玩家同意游戏益处百分比雷达图表9</li><li>2025年游戏公司股票回报率半圆面积图表10</li><li>游戏行业顶级投资者交易数热图表11</li><li>全球手游内购收入折线图表12</li><li>韩国手游子品类收入同比增长率双轴图表13</li><li>韩国手游发行商内购收入环比增长率瀑布图表14</li></ol><h3><a name="t30" target="_blank"/>本专题内的参考报告（PDF）目录</h3><ul><li>鬼灭之刃游戏近期营销事件及热度反馈分析-数说故事.pdf</li><li>2025-11-24 15:04</li><li>Newzoo：2023全球游戏市场报告（英文免费版）.pdf</li><li>2025-11-21 16:43</li><li>现代网络游戏现象催生数字营销热潮.pdf</li><li>2025-11-18 16:31</li><li>百度安全：2025年危险游戏：智能驾驶一线攻防实战报告.pdf</li><li>2025-11-11 15:19</li><li>DRAKE STAR：2025年第三季度全球游戏报告（英文版）.pdf</li><li>2025-11-05 16:47</li><li>2025年第三季度全球游戏报告.pdf</li><li>2025-11-04 16:49</li><li>2025年韩国游戏市场洞察-SensorTower.pdf</li><li>2025-11-03 15:57</li><li>2025年第三季度视频游戏报告.pdf</li><li>2025-11-01 22:06</li><li>Sensor Tower：2025年日本游戏市场洞察报告.pdf</li><li>2025-10-28 16:33</li><li>点点数据：2025年全球模拟类移动游戏发展趋势报告.pdf</li><li>2025-10-26 08:56</li><li>2025年第二季度游戏行业报告.pdf</li><li>2025-10-26 08:55</li><li>2025年全球电子游戏产业报告（英文版）-游戏之力.pdf</li><li>2025-10-21 16:54</li><li>游戏行业：《卡厄思梦境》深度分析-数说故事.pdf</li><li>2025-10-20 14:53</li><li>2025年Q3小游戏买量数据观察-DataEye.pdf</li><li>2025-10-20 14:50</li><li>商贸零售行业IP系列深度之三：海外复盘，任天堂——创造惊喜的游戏王国.pdf</li><li>2025-10-18 17:10</li><li>Meetgames：2024年小游戏出海如何精准把握市场机遇报告.pdf</li><li>2025-09-25 16:12</li><li>点点数据：2025年全球SLG移动游戏发展趋势报告.pdf</li><li>2025-09-24 16:27</li><li>华泰证券：互联网行业：日本游戏行业洞察，穿越周期之道.pdf</li><li>2025-09-24 16:20</li><li>2025年全球PC_主机游戏报告.pdf</li><li>2025-09-22 16:23</li><li>Newzoo：2025年全球游戏市场报告（英文版）.pdf</li><li>2025-09-20 16:56</li><li>2025年欧洲视频游戏报告.pdf</li><li>2025-09-18 16:34</li><li>电子竞技游戏赛事执行文娱活动策划方案.pdf</li><li>2025-09-17 16:32</li><li>2024年欧洲游戏产业现状及潜力全面释放路径研究报告（英文版）.pdf</li><li>2025-09-16 16:07</li><li>（英）2025年全球游戏发行与营销行业研究报告.pdf</li><li>2025-09-11 15:18</li><li>2025年德国游戏行业报告.pdf</li><li>2025-09-11 15:18</li><li>2025年游戏标杆企业组织效能报告-顺为人和.pdf</li><li>2025-09-01 16:35</li><li>PC_主机游戏指数：纵观2025年至今的顶级游戏、发行商和平台，以及它们成功所凭借的制胜策略。-SensorTower.pdf</li><li>2025-09-01 16:32</li><li>2025游戏服务行业的数据应用实践白皮书-多主体赋能游戏账号交易平台的全链路分析体系构建.pdf</li><li>2025-08-27 16:54</li><li>日本机会品类动向调查-PC游戏类产品.pdf</li><li>2025-08-25 16:30</li><li>贝恩：2025年全球游戏行业报告：突破边界 制胜未来（英文版）.pdf</li><li>2025-08-22 16:35</li><li>NewzooUkie：2025年日本游戏市场洞察报告（英文版）.pdf</li><li>2025-08-19 15:46</li><li>2024-2025上海游戏出版产业报告（摘要版）.pdf</li><li>2025-08-18 17:08</li><li>Omdia：2025年市场雷达：游戏云平台报告.pdf</li><li>2025-08-14 16:56</li><li>亚马逊广告：2025全球PC与主机游戏玩家洞察报告.pdf</li><li>2025-08-13 15:47</li><li>伽马数据：2025中国上市非上市游戏企业竞争力报告.pdf</li><li>2025-08-08 16:08</li><li>Sensor Tower：2025年海外游戏市场洞察报告.pdf</li><li>2025-08-03 18:31</li><li>Omdia：2025年游戏科技的AI革新研究报告.pdf</li><li>2025-08-03 18:30</li><li>点点数据：2025年H1全球移动游戏市场数据报告.pdf</li><li>2025-08-02 16:21</li><li>X出海营销：叙事力崛起：中国游戏的全球密码-2025年X游戏出海全球洞察白皮书.pdf</li><li>2025-08-02 16:20</li><li>游戏工委：2025年1-6月中国游戏产业报告.pdf</li><li>2025-08-02 16:08</li><li>2025H1非游戏应用全球趋势报告——从下载到营收：洞察变现新格局.pdf</li><li>2025-08-01 17:01</li><li>中国互联网行业：头部游戏公司录得强劲增长，未来产品管线可期.pdf</li><li>2025-07-31 16:48</li><li>Sensor Tower：2025年东南亚移动游戏市场洞察报告.pdf</li><li>2025-07-22 15:47</li><li>2025年1-6月上海游戏出版产业报告（摘要版）-伽马数据.pdf</li><li>2025-07-21 14:51</li><li>電競風潮與遊戲世代 2024遊戲與電競產業數據分析報告 .pdf</li><li>2025-07-21 14:49</li><li>顺为咨询：2025年游戏行业组织效能报告.pdf</li><li>2025-07-20 20:10</li><li>数数科技2025AI游戏行业应用白皮书.pdf</li><li>2025-07-18 16:43</li><li>量子位智库：2025年AI+游戏产业变革研究报告.pdf</li><li>2025-07-17 15:53</li><li>LnData：2024台湾游戏与电竞产业数据分析报告繁体版.pdf</li><li>2025-07-15 16:31</li><li>2025中国游戏产业新质生产力发展报告.pdf</li><li>2025-07-14 16:19</li><li>GDC：2025年游戏行业趋势报告（英文版）.pdf</li><li>2025-07-13 08:30</li><li>凯捷咨询-中国–人工智能行业：游戏之外.pdf</li><li>2025-07-09 16:17</li><li>Meta：2025年Meta应用与游戏行业全年CPM机会宝典2.0（Q3）.pdf</li><li>2025-07-03 16:32</li><li>2025年中国手机游戏市场现状报告-嘉世咨询.pdf</li><li>2025-06-30 15:11</li><li>2025小红书“超级玩家”：游戏行业内容种草与声量曝光的解决方案【互联网】【通案】.pdf</li><li>2025-06-27 16:37</li><li>2025中国单机游戏市场现状报告-MCR嘉世咨询.pdf</li><li>2025-06-20 15:07</li><li>上海英雄互娱游戏-下沉市场消费零售升级潜力白皮书.pdf</li><li>2025-06-13 16:16</li><li>解锁游戏.pdf</li><li>2025-06-09 13:32</li><li>Adjust：2025年游戏应用洞察报告-解锁移动营销增长机遇.pdf</li><li>2025-06-05 16:07</li><li>网络游戏诉讼蓝皮书（2014-2024）.pdf</li><li>2025-05-30 17:04</li><li>伽马数据：2025年1-3月中国游戏产业季度报告.pdf</li><li>2025-05-28 16:35</li><li>2024游戏安全白皮书.pdf</li><li>2025-05-26 16:57</li><li>2025 年移动游戏发展报告—头部 App 的应用内购买趋势.pdf</li><li>2025-05-26 16:56</li><li>广州游戏行业协会：2025年广州游戏出海指数报告.pdf</li><li>2025-05-25 16:53</li><li>2025年中国游戏科技发展白皮书.pdf</li><li>2025-05-24 16:42</li><li>腾讯游戏安全ACE全球最佳实践及解决方案.pdf</li><li>2025-05-20 17:05</li><li>点点数据：2025中东移动游戏发展趋势报告.pdf</li><li>2025-05-17 16:12</li><li>PubMatic：2025年东南亚移动游戏广告的成功秘钥报告.pdf</li><li>2025-05-16 16:57</li><li>2025年第一季度全球游戏行业报告（英文）.pdf</li><li>2025-05-10 15:40</li><li>MMORPG游戏上线策划案【线上游戏】【上市策划】.pdf</li><li>2025-05-05 17:34</li><li>淘天（范导）：一分钟一千万：天猫双十一背后的互动游戏引擎.pdf</li><li>2025-05-01 17:47</li><li>腾讯（陈和）：腾讯游戏活动开发提效之路.pdf</li><li>2025-05-01 17:47</li><li>网易雷火（刘媛媛）：体育游戏产品成功交互优化公式——打造创新机制，改善核心战斗体验.pdf</li><li>2025-05-01 17:47</li><li>微信（熊婷）：微信小游戏质量保障探索实践.pdf</li><li>2025-05-01 17:46</li><li>王杰：腾讯游戏SRE在复杂异构业务中的云原生服务实践.pdf</li><li>2025-04-30 17:16</li><li>AI应用系列报告（十一）：多邻国的增长密码，游戏化学习与AI应用.pdf</li><li>2025-04-29 15:55</li><li>AI游戏行业深度：驱动因素、发展前景、产业链及相关公司深度梳理.pdf</li><li>2025-04-23 15:58</li><li>2025年游戏行业白皮书-薪智.pdf</li><li>2025-04-21 10:09</li><li>伽马数据：2024年全球移动游戏市场企业竞争力报告.pdf</li><li>2025-04-17 16:55</li><li>2025Q1射击类移动游戏发展趋势报告-点点数据.pdf</li><li>2025-04-14 11:03</li><li>3A游戏行业深度研究：TakeTwo：曾取凌云志，再见拉满弓.pdf</li><li>2025-04-12 16:29</li><li>传媒行业GenAI系列之五十：国内云价值重估，AI游戏、AI社区、AI医疗、AI教育仍有低估.pdf</li><li>2025-04-12 16:29</li><li>万里汇：2025游戏开发者出海安全赚钱指南.pdf</li><li>2025-04-11 16:34</li><li>巨量引擎：2025年游戏行业抖音经营白皮书.pdf</li><li>2025-04-09 16:30</li><li>Shopee：2025年第二季度游戏电玩选品参考报告.pdf</li><li>2025-04-09 16:25</li><li>Sensor Tower：2025年移动游戏市场报告.pdf</li><li>2025-04-08 15:45</li><li>游戏行业深度之八暨GenAI系列报告之五十五：AI游戏，从增加供给到改变交互.pdf</li><li>2025-04-02 15:55</li><li>传媒行业深度报告：“赋能+重构”，AI游戏扬帆起航.pdf</li><li>2025-03-27 14:43</li><li>2025年1-2月俄罗斯游戏市移动场广告趋势洞察报告.pdf</li><li>2025-03-26 15:46</li><li>2025年亚洲和大洋洲游戏云平台.pdf</li><li>2025-03-21 15:56</li><li>2024年全球游戏报告.pdf</li><li>2025-03-19 14:41</li><li>2025年2月手游&amp;非游戏应用海外移动广告月报.pdf</li><li>2025-03-16 17:12</li><li>Konvoy：2024年第四季度游戏行业报告（英文版）.pdf</li><li>2025-03-16 17:11</li><li>点点数据：2025年全球移动游戏行业白皮书.pdf</li><li>2025-03-14 15:51</li><li>游戏应用洞察报告：解锁移动营销者的增长机遇.pdf</li><li>2025-03-13 17:06</li><li>2024年中国游戏市场变现报告.pdf</li><li>2025-03-12 15:48</li><li>2024年第四季度游戏行业报告.pdf</li><li>2025-03-12 15:43</li><li>游戏行业探寻系列报告-三-：二手游戏道具交易：一种新的游戏数字资产交易形式.pdf</li><li>2025-03-12 15:41</li><li>端游行业专题报告：《黑神话：悟空》破圈，多端互通驱动PC游戏发展.pdf</li><li>2025-03-01 16:48</li><li>扬帆出海：2025年中国游戏如何合规出海越南？.pdf</li><li>2025-02-28 16:30</li><li>游戏行业探寻系列报告-二-：展旗，AI+游戏的“风向标”渐进.pdf</li><li>2025-02-27 14:48</li><li>华宝证券&amp;华尔街见闻：无限游戏：2025年ETF展望报告.pdf</li><li>2025-02-26 14:59</li><li>2025年非洲游戏行业报告.pdf</li><li>2025-02-22 16:25</li><li>2025年游戏行业现状报告（英文版）.pdf</li><li>2025-02-18 15:55</li><li>2025年亚太发行商非游戏应用市场洞察报告.pdf</li><li>2025-02-15 14:53</li><li>伽马数据：2024中国游戏企业社会责任报告.pdf</li><li>2025-02-14 16:58</li><li>2023游戏出海行业及标杆企业研究（米哈游）.pdf</li><li>2025-02-13 20:10</li><li>2025区块链游戏与AI的融合如何重塑加密生态系统研究报告（英文版）.pdf</li><li>2025-02-12 14:40</li><li>2025年中国游戏云技术发展洞察报告.pdf</li><li>2025-02-12 14:39</li><li>DRAKE STAR：2024年全球游戏与电竞行业报告.pdf</li><li>2025-02-12 14:32</li><li>2025年中国移动游戏私域运营指南·进阶篇.pdf</li><li>2025-02-07 15:42</li><li>2024年中国移动智能硬件评测报告-手机游戏性能.pdf</li><li>2025-02-03 09:47</li><li>网易游戏（胡彪）：易游戏基于Apache Doris湖仓融合建设.pdf</li><li>2025-01-20 09:28</li><li>网易易盾：2024年度游戏安全观察与实践报告.pdf</li><li>2025-01-16 16:44</li><li>盛趣游戏：2024年度IP维权报告.pdf</li><li>2025-01-16 16:31</li><li>广东省游戏产业协会：2024年小游戏高质量发展报告.pdf</li><li>2025-01-15 15:50</li><li>嘉世咨询：2024年中国游戏出海行业简析报告.pdf</li><li>2025-01-14 16:19</li><li>FairGuard：游戏安全2024年度报告.pdf</li><li>2025-01-14 16:14</li><li>网易游戏（胡彪）：易游戏基于Apache Doris湖仓融合建设.pdf</li><li>2025-01-13 10:06</li><li>2024年人工智能重写汽车行业游戏规则的新动力研究报告.pdf</li><li>2025-01-11 16:12</li><li>广东省游戏产业协会：2024年广东游戏产业发展报告.pdf</li><li>2025-01-10 16:36</li><li>广东省游戏产业协会：2024年粤港澳大湾区电竞产业发展报告.pdf</li><li>2025-01-10 16:36</li><li>2024年移动游戏出海洞察：聚焦轻量化游戏及增长策略白皮书-展望篇.pdf</li><li>2025-01-09 16:43</li><li>游戏品牌机遇报告.pdf</li><li>2025-01-09 16:36</li><li>2024年人工智能重写汽车行业游戏规则的新动力研究报告（英文版）.pdf</li><li>2025-01-08 16:16</li><li>2024年中国内地移动游戏买量白皮书-DataEye.pdf</li><li>2025-01-06 10:09</li><li>腾讯游戏：AI时代的湖仓数据体系建设.pdf</li><li>2025-01-05 16:29</li><li>热力引擎&amp;Insightrackr：2024年微信小游戏买量获客报告.pdf</li><li>2025-01-04 17:24</li><li>李正兴：腾讯游戏知几语音合成大模型推理实践.pdf</li><li>2024-12-31 16:58</li><li>2024中国游戏出海研究报告.pdf</li><li>2024-12-26 15:57</li><li>2024加拿大PC端游戏玩家市场调查报告-维卓.pdf</li><li>2024-12-26 15:56</li><li>2024中国移动游戏广告营销报告.pdf</li><li>2024-12-25 15:56</li><li>2024年游戏技术报告.pdf</li><li>2024-12-25 15:54</li><li>2024游戏出海买量数据洞察.pdf</li><li>2024-12-23 16:45</li><li>DataEye研究院：2024年小游戏数据观察报告.pdf</li><li>2024-12-23 16:41</li><li>2024小游戏混合变现白皮书.pdf</li><li>2024-12-21 17:29</li><li>2024年第四季度消除移动游戏发展趋势报告.pdf</li><li>2024-12-21 17:25</li><li>2024年全球手机游戏产业展望.pdf</li><li>2024-12-20 16:11</li><li>伽马数据：2025年中国游戏产业趋势及潜力分析报告.pdf</li><li>2024-12-18 16:00</li><li>游戏工委：2024年中国游戏产业报告.pdf</li><li>2024-12-18 15:59</li><li>2024中国游戏产业未成年人保护报告.pdf</li><li>2024-12-17 15:42</li><li>伽马数据&amp;TapTap：2024年TapTap移动游戏行业白皮书.pdf</li><li>2024-12-17 15:41</li><li>GenAI正在改变医疗技术的游戏规则吗.pdf</li><li>2024-12-17 15:36</li><li>2024小游戏数据观察.pdf</li><li>2024-12-16 16:04</li><li>游戏及网络服务行业营销趋势洞察-增长黑盒.pdf</li><li>2024-12-16 16:00</li><li>李正兴：腾讯游戏知几语音合成大模型推理实践.pdf</li><li>2024-12-15 14:15</li><li>2024年引领游戏工作室走向未来白皮书.pdf</li><li>2024-12-12 16:35</li><li>2024年最大化ROAS：移动游戏中的尖端归因策略报告.pdf</li><li>2024-12-07 17:11</li><li>2024年第三季度全球游戏报告.pdf</li><li>2024-12-06 16:47</li><li>2024香港智能手机游戏玩家洞察报告.pdf</li><li>2024-12-05 17:09</li><li>2024年Q3竞技类移动游戏发展趋势报告.pdf</li><li>2024-12-01 20:54</li><li>2024年视频游戏重制的黄金时代报告（英文版）.pdf</li><li>2024-11-25 16:20</li><li>DataEye微信小游戏1-10月数据报告.pdf</li><li>2024-11-25 16:14</li><li>2024游戏技术现状报告-Perforce.pdf</li><li>2024-11-23 17:12</li><li>视频游戏重制的黄金时代.pdf</li><li>2024-11-22 15:50</li><li>2024年娱乐消费调研报告：游戏、体育与动漫（英文版）.pdf</li><li>2024-11-22 15:50</li><li>2024H1东南亚移动应用（非游戏）营销趋势洞察.pdf</li><li>2024-11-16 17:03</li><li>环游之旅2.0_B站游戏行业营销通案.pdf</li><li>2024-11-13 16:43</li><li>DDM：2024年第二季度游戏投资报告（英文版）.pdf</li><li>2024-11-10 20:08</li><li>DDM：2024年游戏开发商投资报告（英文版）.pdf</li><li>2024-11-10 20:08</li><li>伽马数据：2024年中国游戏产业IP发展报告.pdf</li><li>2024-11-08 15:39</li><li>DDM：2024年主机_电脑游戏投资报告（英文版）.pdf</li><li>2024-11-08 15:34</li><li>2024意大利电子游戏市场洞察报告-维卓.pdf</li><li>2024-11-07 16:59</li><li>2024游戏产业出海研究报告.pdf</li><li>2024-11-05 16:03</li><li>2024年全球二次元移动游戏市场研究报告.pdf</li><li>2024-11-04 15:35</li><li>2024生态大会-游戏专场内容合集.pdf</li><li>2024-11-01 16:25</li><li>2024上半年回顾游戏行业聚焦报告.pdf</li><li>2024-10-26 16:54</li><li>2024年版游戏生命周期白皮书-大推结束后.pdf</li><li>2024-10-26 16:54</li><li>2024游戏内置广告效率优化策略.pdf</li><li>2024-10-24 16:30</li><li>2024年9月手游&amp;非游戏应用海外移动广告月报.pdf</li><li>2024-10-24 16:30</li><li>2024年中国传奇游戏市场研究白皮书.pdf</li><li>2024-10-22 15:09</li><li>2024年版游戏生命周期白皮书-游戏大推.pdf</li><li>2024-10-22 15:07</li><li>AppGrowing：2024年7-8月日本游戏市场广告趋势洞察报告.pdf</li><li>2024-10-19 16:28</li><li>伽马数据：2024年8月中国游戏产业月度报告.pdf</li><li>2024-10-19 16:28</li><li>Unity：2024年移动游戏增长与变现报告.pdf</li><li>2024-10-17 15:47</li><li>2024小红书游戏行业营销通案.pdf</li><li>2024-10-17 15:42</li><li>高盛：中国游戏规则已变，沪深300冲向4600点.pdf</li><li>2024-10-10 15:15</li><li>维卓：2024全球纸牌游戏和拼图市场行业趋势报告.pdf</li><li>2024-10-10 15:15</li><li>游戏行业深度研究：《黑神话》开启“新征程”，国产3A前路漫漫亦灿灿.pdf</li><li>2024-10-05 16:19</li><li>刘克飞：云游戏全栈自主可控的底层逻辑与应用探索.pdf</li><li>2024-10-02 17:12</li><li>天风证券-游戏行业深度研究：《黑神话》开启“新征程”，国产3A前路漫漫亦灿灿.pdf</li><li>2024-09-27 15:53</li><li>音数协游戏工委：2023年全球主机游戏市场调查报告.pdf</li><li>2024-09-26 16:11</li><li>2024游戏行业简析报告-嘉世咨询.pdf</li><li>2024-09-26 16:05</li><li>电竞比赛&amp;游戏本品牌2024校园活动规划【电竞活动】【游戏笔记本】【校园活动策划】.pdf</li><li>2024-09-26 16:02</li><li>AppGrowing：2024年出海新风口：“小游戏like”出海营销策略分析报告.pdf</li><li>2024-09-23 15:21</li><li>Circana：2024年美国游戏分类报告（英文版）.pdf</li><li>2024-09-20 16:08</li><li>网易易盾：2024年上半年网易易盾游戏安全指南报告.pdf</li><li>2024-09-19 15:58</li><li>AI加速游戏：安全治理生态-网易.pdf</li><li>2024-09-19 15:55</li><li>2024年移动游戏支出报告.pdf</li><li>2024-09-14 16:43</li><li>伽马数据：2024年中国游戏产业新质生产力发展报告.pdf</li><li>2024-09-11 16:29</li><li>2024腾讯游戏云案例实践与解决方案——让游戏研发运维更简单.pdf</li><li>2024-09-09 16:22</li><li>招商银行-传媒行业之电子游戏篇①：路在脚下：中国电子游戏行业的悄然崛起.pdf</li><li>2024-09-07 16:34</li><li>贝恩公司：2024年游戏报告：把握时代脉搏：玩家如何改变游戏规则（英文版）.pdf</li><li>2024-09-07 16:34</li><li>伽马数据：2024年中国游戏产业趋势及潜力分析报告.pdf</li><li>2024-09-06 16:22</li><li>未成年人游戏防沉迷现状调研报告(2024).pdf</li><li>2024-09-06 16:21</li><li>点点数据：2024主机游戏趋势洞察报告.pdf</li><li>2024-09-03 16:57</li><li>Sensor Tower：2024年全球移动游戏市场展望报告（英文版）.pdf</li><li>2024-08-31 17:20</li><li>霞光智库：2024年中国游戏出海洞察报告——穿透“黑神话效应””，遥望中国游戏出海.pdf</li><li>2024-08-30 17:57</li><li>中国游戏产业AIGC发展前景报告-伽马数据.pdf</li><li>2024-08-28 16:50</li><li>2024年第二季度游戏行业报告.pdf</li><li>2024-08-28 16:45</li><li>国海证券-计算机行业动态研究：《黑神话：悟空》掀起游戏本升级换新潮.pdf</li><li>2024-08-28 16:39</li><li>维卓：2024日本手机游戏报告.pdf</li><li>2024-08-23 15:54</li><li>2024年第一季度游戏行业报告news.pdf</li><li>2024-08-23 15:48</li><li>Newzoo：2024年全球游戏市场报告（英文版）.pdf</li><li>2024-08-22 16:53</li><li>2023-2024中国游戏企业研发竞争力报告.pdf</li><li>2024-08-20 15:50</li><li>网易易盾：2024年上半年网易易盾游戏安全指南报告.pdf</li><li>2024-08-17 17:20</li><li>可持续产品创新正在如何改变产品开发游戏规则？（2024）-SAP.pdf</li><li>2024-08-16 16:07</li><li>2024游戏数据爆款案例手册.pdf</li><li>2024-08-15 17:31</li><li>伽马数据：2023全球移动游戏市场企业竞争力报告.pdf</li><li>2024-08-15 17:29</li><li>数数科技：2024超越成本-游戏数据平台效能提升之道白皮书.pdf</li><li>2024-08-14 16:56</li><li>2024中国上市非上市游戏企业竞争力报告.pdf</li><li>2024-08-11 19:38</li><li>2024中轻度游戏全球市场趋势洞察-飞书深诺.pdf</li><li>2024-08-09 17:37</li><li>2024年亚太发行商非游戏应用市场洞察报告-Sensor Tower.pdf</li><li>2024-08-08 16:31</li><li>Shopee：2024年第3季度游戏配件选品参考指南报告.pdf</li><li>2024-08-07 17:02</li><li>DataEye&amp;点点数据：2024上半年小游戏出海报告.pdf</li><li>2024-08-01 16:20</li><li>全球游戏移动广告市场洞察（2024H1）.pdf</li><li>2024-07-29 17:36</li><li>2024腾讯游戏云案例实践——让游戏研发运维更简单.pdf</li><li>2024-07-29 17:36</li><li>X出海营销：畅“游”全球 增长不已-2024年X游戏出海白皮书.pdf</li><li>2024-07-29 17:34</li><li>Liftoff&amp;广大大：2024年中国游戏厂商出海报告.pdf</li><li>2024-07-24 17:05</li><li>DataEye研究院：2024年Q2微信小游戏数据报告.pdf</li><li>2024-07-24 17:05</li><li>小红书游戏行业KFS投放方案.pdf</li><li>2024-07-24 16:51</li><li>2024年暑期档游戏趋势报告.pdf</li><li>2024-07-22 16:48</li><li>可持续产品创新正在如何改变产品开发游戏规则？.pdf</li><li>2024-07-22 16:43</li><li>点点数据：2024上半年全球移动游戏市场数据报告.pdf</li><li>2024-07-20 17:33</li><li>2024H1全球移动应用（非游戏）营销白皮书-广大大&amp;钛动.pdf</li><li>2024-07-18 17:30</li><li>2024全球电子游戏下-维卓.pdf</li><li>2024-07-18 17:28</li><li>2024年版游戏生命周期白皮书-大推后.pdf</li><li>2024-07-15 11:47</li><li>2024年版游戏生命周期白皮书大推期.pdf</li><li>2024-07-15 11:42</li><li>2024年版游戏生命周期白皮书-预注册.pdf</li><li>2024-07-15 11:42</li><li>生成式AI如何颠覆游戏体验.pdf</li><li>2024-07-14 10:31</li><li>2024年版游戏生命周期白皮书-游戏趋势综览-Meta &amp; PerforMad.pdf</li><li>2024-07-13 19:27</li><li>2024游戏行业组织效能报告-顺为咨询.pdf</li><li>2024-07-06 10:33</li><li>CTR&amp;磁力引擎：2024年快手移动游戏行业白皮书.pdf</li><li>2024-07-06 10:27</li><li>开源证券-哔哩哔哩-W-09626.HK-港股公司首次覆盖报告：游戏、会员、广告、IP变现全面发力，商业化提速.pdf</li><li>2024-07-06 10:18</li><li>2024年全球移动应用（非游戏）市场展望报告-Sensor Tower.pdf</li><li>2024-07-04 11:22</li><li>维卓-2024全球电子游戏.pdf</li><li>2024-07-04 11:15</li><li>Fandom：2024年游戏报告（英文版）.pdf</li><li>2024-07-03 10:20</li><li>2024年游戏报告.pdf</li><li>2024-06-28 10:46</li><li>2024美国移动游戏玩家洞察.PDF</li><li>2024-06-24 12:25</li><li>华金证券-致尚科技-301486-游戏零部件为主体，XR／光通讯两翼共促发展.pdf</li><li>2024-06-19 12:52</li><li>维卓-2024全球电脑游戏行业.pdf</li><li>2024-06-15 12:57</li><li>2024年中国移动游戏市场研究报告.pdf</li><li>2024-06-13 11:42</li><li>Snowflake：2024电信的未来：人工智能如何改变游戏规则报告（英文版）.pdf</li><li>2024-06-13 11:26</li><li>2024年中国VR游戏产业现状及发展趋势研究报告-智研咨询.pdf</li><li>2024-06-09 15:14</li><li>客户端游戏市场营销发展报告.pdf</li><li>2024-06-03 09:33</li><li>2024年手机游戏支出报告.pdf</li><li>2024-06-01 14:59</li><li>2024百度营销科学AIA游戏行业通案【互联网】【通案】.pdf</li><li>2024-05-31 14:51</li><li>CROWDSTRIKE：2024通过CrowdStrike提升你的游戏，为你的云检测和响应带来人工智能创新（英文版）.pdf</li><li>2024-05-30 10:59</li><li>2024游戏IP文旅共创新可能研究报告-中国旅游研究院.pdf</li><li>2024-05-22 11:14</li><li>国泰君安-恺英网络-002517-恺英网络公司深度研究：研发赋能IP，小游戏、手游双端并举.pdf</li><li>2024-05-22 10:53</li><li>国信证券-浙数文化-600633-游戏主业稳健，数据要素及AIGC产业链优势明显.pdf</li><li>2024-05-20 15:56</li><li>环境、社会及管治报告-网易游戏.pdf</li><li>2024-05-17 15:08</li><li>骏飞4月游戏衍生品周边趋势报告.pdf</li><li>2024-05-16 14:16</li><li>2024年休闲游戏报告-Liftoff.pdf</li><li>2024-05-14 14:54</li><li>2024年游戏行业报告.pdf</li><li>2024-05-09 14:40</li><li>Sensor Tower：2024年美国市场亚太游戏品牌数字广告洞察报告.pdf</li><li>2024-05-08 14:41</li><li>百度营销科学AIA游戏行业通案.pdf</li><li>2024-05-06 14:55</li><li>WEZO维卓：2024全球MOBA游戏市场洞察报告.pdf</li><li>2024-04-24 09:50</li><li>创证券-恺英网络-002517-深度研究报告：传奇奇迹赛道龙头，掘金IP向产品、拥抱游戏垂类大模型、布局出海发行.pdf</li><li>2024-04-20 12:07</li><li>维卓：2024巴西休闲游戏玩家洞察报告.pdf</li><li>2024-04-19 14:30</li><li>2024游戏应用洞察报告-解锁移动营销增长机遇-Adjust.pdf</li><li>2024-04-18 11:04</li><li>《HR必备的124个管理培训游戏》大全.pdf</li><li>2024-04-17 10:16</li><li>浦银国际证券-游戏引擎龙头，积极拓宽业务边界，顺应AI浪潮前进.pdf</li><li>2024-04-16 10:09</li><li>AppGrowing：2024Q1游戏出海移动广告创意与策略白皮书.pdf</li><li>2024-04-13 10:17</li><li>游戏应用洞察报告：解锁移动营销增长机遇.pdf</li><li>2024-04-13 10:11</li><li>2024年游戏行业抖音经营白皮书-内容共生，全域增长-抖音月狐数据.pdf</li><li>2024-04-09 10:56</li><li>长江证券-文化传媒-媒体行业海外研究系列-一-：新技术时代下游戏引擎的商业化与未来.pdf</li><li>2024-04-09 10:46</li><li>深度报告-20240408-国盛证券-巨人网络-002558.SZ-存量游戏筑基_新品周期开启_AI应用开拓新空间_26页_2mb.pdf</li><li>2024-04-09 10:44</li><li>糖果品牌&amp;三消游戏BD合作方案【零食】【IP联名】【跨界营销】.pdf</li><li>2024-04-08 15:06</li><li>2024手游品牌蛋友线下碰碰会执行手册【游戏】【线下活动】.pdf</li><li>2024-04-08 14:53</li><li>媒体行业海外研究系列（一）：新技术时代下游戏引擎的商业化与未来.pdf</li><li>2024-04-07 10:10</li><li>传媒行业跟踪报告：派对游戏激战正酣，AI游戏应用未来可期.pdf</li><li>2024-04-06 15:35</li><li>24年游戏开发者大会前瞻及游戏行业跟踪系列报告：梳理多家海内外巨头GDC议程，指引了哪些行业方向？.pdf</li><li>2024-04-04 10:23</li><li>2024年移动游戏市场报告-Sensor Tower.pdf</li><li>2024-04-02 10:53</li><li>2024年移动游戏市场报告-Sensor Tower.pdf</li><li>2024-04-02 10:38</li><li>游戏行业深度报告：AI生成3D：关注游戏行业“AI拐点”.pdf</li><li>2024-04-02 10:33</li><li>Fastdata极数：2024年中国游戏营销趋势报告.pdf</li><li>2024-03-30 11:07</li><li>传媒行业：出海专题（三）：游戏出海有望改善，小程序拓展新赛道，SLG看重题材创新.pdf</li><li>2024-03-17 13:22</li><li>维塔士2024游戏研究白皮书《游戏重制的黄金年代》.pdf</li><li>2024-03-16 11:28</li><li>全球IP移动游戏市场格局-2023年IP手游竞争格局变化分析报告-SensorTower.pdf</li><li>2024-03-13 11:05</li><li>游戏企业社会责任报告2023.pdf</li><li>2024-03-05 10:58</li><li>2023东南亚游戏市场洞察报告-维卓.pdf</li><li>2024-03-01 12:13</li><li>品牌广告与移动游戏行业：品牌广告支出转向游戏领域对发行商而言意义何在.pdf</li><li>2024-02-20 14:38</li><li>2023年度游戏安全观察与实践报告白皮书-网易易盾.pdf</li><li>2024-02-16 15:38</li><li>品牌广告与移动游戏——品牌广告支出转向游戏领域对发行商而言意义何在.pdf</li><li>2024-02-08 09:56</li><li>2023中国内地手游App与微信小游戏买量白皮书.pdf</li><li>2024-02-06 15:05</li><li>2024年中国游戏社交创作者生态创新研究报告-艾瑞咨询.pdf</li><li>2024-02-05 16:05</li><li>海外科技行业专题报告：全球渠道加速变革，游戏厂商有望全面崛起.pdf</li><li>2024-02-04 14:29</li><li>媒体行业深度报告：小游戏，内容变革及平台流量加持下的游戏赛道新增量.pdf</li><li>2024-02-04 14:23</li><li>游戏日报：2023全年度全球手游移动广告趋势洞察报告.pdf</li><li>2024-01-31 11:02</li><li>2023游戏安全白皮书.pdf</li><li>2024-01-29 14:53</li><li>DataEye：2023年全球移动游戏买量洞察报告.pdf</li><li>2024-01-25 15:06</li><li>传媒行业专题研究：《元梦之星》有望推升派对游戏市场空间.pdf</li><li>2024-01-21 08:51</li><li>2024年游戏行业抖音经营白皮书-内容共生，全域增长-抖音月狐数据.pdf</li><li>2024-01-19 13:22</li><li>广大大&amp;Flat Ads：2023年全球移动应用（非游戏）营销趋势白皮书.pdf</li><li>2024-01-17 15:23</li><li>人工智能行业C_Suite全球AI指标报告：AI是终极升级，四种方法来释放你的游戏改变AI和机器学习的潜力.pdf</li><li>2024-01-17 15:18</li><li>华安证券：2024年游戏行业极简投资手册.pdf</li><li>2024-01-16 10:49</li><li>腾讯音乐数据研究院：游戏+音乐：双赛道加持下的热门生意.pdf</li><li>2024-01-15 10:40</li><li>2023年海外移动游戏市场研究报告-点点数据.pdf</li><li>2024-01-13 14:56</li><li>网易易盾：2023年度游戏安全观察与实践报告白皮书.pdf</li><li>2024-01-13 10:28</li><li>IGEA：2023年澳大利亚游戏发展调查报告.pdf</li><li>2024-01-13 10:28</li><li>2023年澳大利亚游戏发展调查报告.pdf</li><li>2024-01-12 14:48</li><li>IGEA：2023年澳大利亚游戏发展调查报告（英文）.pdf</li><li>2024-01-12 14:47</li><li>DataEye：2023年国内游戏效果广告白皮书.pdf</li><li>2024-01-11 15:04</li><li>深度报告-20240108-国盛证券-神州泰岳-300002.SZ-游戏出海屡攀新高_AI应用再添动能_29页_2mb.pdf</li><li>2024-01-10 10:41</li><li>2023年全球SLG移动游戏市场趋势报告.pdf</li><li>2024-01-09 15:04</li><li>2023游戏行业总结与复盘：内容为王趋势强化，小程序仍具增长空间，AIGC有望初步落地.pdf</li><li>2024-01-06 15:50</li><li>传媒：游戏出海：中国游戏市场的重要增长极.pdf</li><li>2024-01-06 15:49</li><li>App Annie-2023 年 SLG游戏市场洞察报告.pdf</li><li>2024-01-03 12:58</li><li>2023年游戏行业薪酬报告.pdf</li><li>2024-01-01 10:13</li><li>2023年移动游戏效果广告白皮书.pdf</li><li>2024-01-01 10:13</li><li>游戏行业深度研究报告：中国游戏“而立”正壮，新规护航繁荣健康.pdf</li><li>2023-12-31 09:52</li><li>互联网行业专题研究：AI游戏：当下看能效，长远看内容.pdf</li><li>2023-12-31 09:48</li><li>传媒互联网行业专题：《网络游戏管理办法》促进游戏行业繁荣健康，征求意见后有较大调整空间.pdf</li><li>2023-12-31 09:47</li><li>游戏行业2024年度策略报告：小游戏有望贡献市场增量，看好AI技术长期对游戏生产方式的重塑.pdf</li><li>2023-12-29 10:47</li><li>TikTok&amp;伽马数据：2023年RPG游戏全球营销白皮书-玩家新阵地内容有经营.pdf</li><li>2023-12-28 15:19</li><li>2023年RPG游戏全球营销白皮书-玩家新阵地内容有经营-TikTok伽马数据.pdf</li><li>2023-12-25 15:32</li><li>传媒行业行业专题研究：乐趣生成：AIGC创新工具，深度赋能游戏研发.pdf</li><li>2023-12-24 10:04</li><li>Adyen&amp;伽马数据：2023中国游戏出海支付研究报告.pdf</li><li>2023-12-21 10:46</li><li>2023苹果应用侧载对移动游戏市场影响报告-点点数据.pdf</li><li>2023-12-20 15:10</li></ul>]]></description></item><item>    <title><![CDATA[工业智能体是什么？工业智能体未来发展的趋势如何？ 雨大王 ]]></title>    <link>https://segmentfault.com/a/1190000047461317</link>    <guid>https://segmentfault.com/a/1190000047461317</guid>    <pubDate>2025-12-09 15:03:04</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>工业智能体作为人工智能与制造业深度融合的关键技术，正在重塑全球制造业的格局。它不仅是一个技术概念，更是推动制造业从“信息化”迈向“智能化”的核心引擎。工业智能体的本质是融合信息技术、自动化技术与人工智能技术的综合智能系统，能够在复杂工业环境中自主完成任务，实现生产、研发、运维等环节的智能化控制与优化。<br/>在政策层面，中国积极推动工业智能体的应用。例如，国务院《关于深入实施“人工智能+”行动的意见》明确提出，到2027年工业智能体应用普及率需超过70%，到2030年达到90%。这一战略目标为工业智能体的落地提供了强有力的政策支持，也促使企业加快智能化转型的步伐。<br/>从技术架构上看，工业智能体可分为“眼、脑、手”三个核心部分。其中，“眼”是感知系统，依赖先进的传感器和数据采集技术；“脑”是决策中枢，基于工业大模型实现多模态数据融合与智能分析；“手”是执行系统，通过自动化设备将决策转化为实际行动。在2025年世界人工智能大会上，广域铭岛推出的Geega工业AI应用平台与工业智造超级智能体成为行业关注的焦点。这一系统通过"数据治理-知识封装-智能协同"的技术闭环，解决了传统制造业在AI应用落地过程中面临的诸多难题。例如，在领克汽车成都工厂的实践中，工业智能体实现了生产排程的自动化，将原本需要数小时的计算过程压缩至分钟级别，每年为工厂创造超过500万元的效益。这正是工业智能体“眼、脑、手”协同作用的典型案例。<br/>在石化行业，工业智能体的应用同样成效显著。江汉油田将中国石化长城大模型与钻井、压裂等环节结合，井下风险预警准确率超85%，压裂砂堵率降至千分之五。中国石油研发的昆仑大模型更是成为能源化工领域首个国家备案行业大模型，广泛应用于油气勘探和炼油化工等场景。<br/>工业智能体的技术挑战<br/>尽管工业智能体在多个行业取得了显著成果，但其落地仍面临诸多挑战。首先，技术适配难度大。不同工业子行业的流程、设备和合规要求差异显著，难以建立统一模型。其次，数据基础薄弱。制造业中符合AI训练要求的高质量数据仅占4%，部分现场数据采集能力不足，导致难以形成稳定的“感知-认知-执行”闭环。此外，人机信任度较低，工业智能体的“黑箱”特性让一线操作人员对其决策依据难以接受。<br/>应用推广的阻力<br/>在应用推广层面，企业认知不足和商业模式适配问题突出。许多传统制造企业对工业智能体的战略价值理解有限，缺乏懂技术、懂业务的复合型人才。同时，工业智能体的研发和算力投入较大，而收益却长期且难以量化，导致企业投资意愿不足。此外，商业模式需要从“买产品”转向“买长期服务”，但企业组织架构和付费体系尚未适配这一转变。<br/>生态协同的瓶颈<br/>生态协同不足是工业智能体发展的另一大瓶颈。大模型开发者、工业平台提供商和设备制造商尚未建立高效合作机制，导致不同厂商、代际的设备缺乏统一接口规范与开发框架。这使得工业智能体跨设备、跨场景的部署门槛较高。同时，行业评价体系不完善，企业难以判断自身应用水平在行业中的位置，进一步制约了规模化推广。<br/>未来发展路径<br/>为推动工业智能体的发展，业界提出了多维度的突破方向。首先，需通过政策统筹明确发展目标，打破数据壁垒。其次，聚焦核心技术攻关，特别是在大模型训练框架、多模态融合等领域，提升工业智能体与现有工业体系的融合度。此外，推进重点行业试点示范，打造可复制的标杆项目，同时完善数据共享、人才培养和标准制定等环境，促进产业链协同。<br/>案例：工业智能体在有色金属行业中的应用<br/>在有色金属行业，工业智能体同样发挥着重要作用。以广西百色百矿集团为例，广域铭岛的智能体系统通过预测生产计划与用能需求，自动推荐最优供能策略，年降低能耗成本50%以上。这种基于数据的智能决策不仅优化了能源使用，还提升了生产效率，为企业创造了可观的经济效益。<br/>综上所述，工业智能体正从单一技术向多智能体集群协作演进，成为制造业数字化转型的核心驱动力。其在钢铁、石化、汽车、电子制造等多个行业的成功应用，充分证明了其在降本增效、提升质量方面的巨大潜力。然而，技术适配、数据支撑、生态协同等问题仍需解决。通过政策引导、技术攻关和行业合作，工业智能体有望从实验室走向生产一线，成为制造业高质量发展的关键支撑。</p>]]></description></item><item>    <title><![CDATA[Entity 查询：让运维人员告别“大海捞针”，高效定位与分析实时实体数据 阿里云云原生 ]]></title>    <link>https://segmentfault.com/a/1190000047461319</link>    <guid>https://segmentfault.com/a/1190000047461319</guid>    <pubDate>2025-12-09 15:02:10</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>作者：路遥</p><p>点击<a href="https://www.bilibili.com/video/BV1aPSxBJE9R/" target="_blank">此处</a>，查看视频演示！</p><h2>背景</h2><p>在可观测性系统中，UModel 定义了统一的数据模型（Schema），UModel 查询专注于探索知识图谱元数据，而 Entity 查询则用于查询和检索具体的实体实例数据。Entity 查询基于 USearch 引擎，提供了强大的全文检索、精确查找、条件过滤等能力，支持跨域、跨实体类型的联合查询。</p><p>与 UModel 查询关注 Schema 定义不同，Entity 查询专注于<strong>运行时实体数据</strong>，帮助用户快速定位、检索和分析具体的实体实例，如服务实例、Pod 实例、主机实例等。</p><h3>1.1 Entity 查询解决的问题</h3><p>在实际的可观测性场景中，我们经常需要：</p><ol><li><strong>快速定位实体：</strong> 根据关键词、属性值快速找到相关实体</li><li><strong>跨域检索：</strong> 在多个域（APM、K8s、云资源等）中联合搜索</li><li><strong>精确查询：</strong> 根据已知的实体 ID 批量查询详细信息</li><li><strong>条件过滤：</strong> 基于实体属性进行复杂的条件筛选</li><li><strong>统计分析：</strong> 对实体数据进行聚合分析和计算</li></ol><p>Entity 查询通过 USearch 引擎的统一接口，解决了传统多系统查询的痛点，提供了高效、灵活的实体检索能力。</p><h3>1.2 三种查询类型的区别</h3><p>在 EntityStore 中，存在三种不同类型的查询：</p><blockquote>EntityStore 是 UModel 系统中的统一存储引擎，负责存储和管理可观测性领域的核心 Metadata 数据，包括 UModel 元数据、实体数据和实体关系数据。它为可观测性分析提供高性能的数据存储和查询能力。</blockquote><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047461321" alt="image" title="image"/></p><p>Entity 查询专注于<strong>实体实例数据</strong>，是日常运维和问题排查中最常用的查询方式。</p><h2>Entity 查询介绍</h2><h3>2.1 数据模型</h3><h4>三层存储结构</h4><p>USearch 采用分层存储结构，确保数据的逻辑隔离和高效查询：</p><ol><li><strong>Workspace 层：</strong> 最顶层隔离单位，不同 workspace 之间完全隔离</li><li><strong>Domain 层：</strong> 域级别的分类，用于业务逻辑分组（如 apm、k8s、acs 等）</li><li><strong>EntityType 层：</strong> 具体的实体类型，包含实际的实体数据（如 apm.service、k8s.pod 等）</li></ol><pre><code>Workspace: my-observability
├── Domain: apm
│   ├── EntityType: apm.service
│   ├── EntityType: apm.host  
│   └── EntityType: apm.instance
├── Domain: k8s
│   ├── EntityType: k8s.pod
│   ├── EntityType: k8s.node
│   └── EntityType: k8s.service
└── Domain: acs
    ├── EntityType: acs.ecs.instance
    └── EntityType: acs.rds.instance</code></pre><h4>数据存储特点</h4><ul><li><strong>唯一性保证：</strong> 在同一 EntityType 下，<code>__entity_id__</code> 保证唯一性</li><li><strong>列式存储：</strong> 支持多行多列的表结构数据，支持 SPL 进行统计分析</li><li><strong>索引优化：</strong> 针对检索场景进行全文索引优化，支持多关键词检索和 Ranking 打分</li><li><strong>时序支持：</strong> 支持基于时间范围的数据查询和过滤，支持回溯任意时刻的实体和关系状态</li></ul><h3>2.2 USearch 核心功能</h3><h4>检索能力</h4><p>USearch 提供强大的全文检索能力，支持：</p><ul><li><strong>多类型联合检索：</strong> 跨多个 domain 和 entity_type 进行联合查询，统一打分排序</li><li><strong>多关键词检索打分：</strong> 基于词权重、字段权重等信息计算相关性分数</li><li><strong>智能分词：</strong> 自动分词和相关性打分，提高检索准确性</li></ul><pre><code>-- 检索所有domain中包含"cart"的实体
.entity with(domain='*', name='*', query='cart') </code></pre><h4>扫描能力</h4><p>除了检索模式，USearch 还支持扫描模式，读取原始数据后通过 SPL 进行更多的过滤和计算，适用于需要复杂数据处理的场景。</p><pre><code>-- 扫描apm域中香港区域的应用数量
.entity with(domain='apm', name='apm.service') 
| where region_id = 'cn-hongkong'
| stats count = count() </code></pre><h3>2.3 查询语法</h3><h4>基础语法结构</h4><pre><code>.entity with(
    domain='domain_pattern',     -- 域过滤模式
    name='type_pattern',         -- 类型过滤模式  
    query='search_query',        -- 查询条件
    topk=10,                     -- 返回条数
    ids=['id1','id2','id3']      -- 精确ID查询
)</code></pre><h4>参数详解</h4><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047461322" alt="image" title="image" loading="lazy"/></p><p><strong>fnmatch 语法说明：</strong> 支持通配符匹配，如 <code>*</code> 匹配任意字符，<code>?</code> 匹配单个字符。参考 fnmatch 文档：<a href="https://link.segmentfault.com/?enc=61xCx%2FFP1Rdb7JbkVvft%2FQ%3D%3D.GpxnuZnEBmB3PB9fFUEniIXm2ZUs2IoXjmzPhC6bH8ocIR12Q6VqOp48O72POymI" rel="nofollow" target="_blank">https://docs.python.org/3/library/fnmatch.html</a>。</p><h4>域和类型过滤模式</h4><pre><code>-- 匹配模式示例
.entity with(domain='ac*')           -- ac开头的domain
.entity with(domain='a*c')           -- a开头、c结尾的domain  
.entity with(name='*instance')       -- 以instance结尾的类型
.entity with(name='k8s.*')           -- k8s域下的所有类型
.entity with(domain='*', name='*')   -- 所有domain和类型</code></pre><h2>查询模式详解</h2><h3>3.1 精确 ID 查询</h3><p>当知道具体的实体 ID 时，使用 ids 参数进行精确查询：</p><pre><code>-- 查询特定ID的实体
.entity with(
    domain='apm', 
    name='apm.service', 
    ids=['4567bd905a719d197df','973ad511dad2a3f70a']
)</code></pre><p><strong>适用场景：</strong></p><ul><li>根据告警中的实体 ID 查询详细信息</li><li>验证特定实体的存在性和状态</li><li>批量查询已知 ID 的实体信息</li></ul><h3>3.2 全文检索模式</h3><h4>基础全文搜索</h4><pre><code>-- 简单关键词搜索
.entity with(query='web application')
-- 多词OR关系（默认行为）
.entity with(query='kubernetes docker container')</code></pre><p><strong>搜索特性：</strong></p><ul><li>多个词之间是 OR 关系，出现任意一个词即满足条件</li><li>搜索所有字段，包括系统字段和自定义字段</li><li>自动分词和相关性打分</li></ul><h4>短语搜索</h4><p>对于通过符号连接（-）的词，必须在同一字段下完整匹配：</p><pre><code>-- 完整短语匹配
.entity with(query='opentelemetry.io/name-fraud-detection')
-- 普通搜索（命中任意一个词）
.entity with(query='opentelemetry.io/name cart')</code></pre><h4>字段限定搜索</h4><p>指定在特定字段中搜索：</p><pre><code>-- 在描述字段中搜索
.entity with(query='description:"error handling service"')
-- 在自定义属性中搜索
.entity with(query='cluster_name:production')
-- 在标签中搜索
.entity with(query='labels.team:backend')</code></pre><h4>逻辑条件组合</h4><p>支持 and、or、not 逻辑运算符：</p><pre><code>-- AND条件：同时满足两个条件
.entity with(query='service_name:web AND status:running')
-- OR条件：满足任一条件
.entity with(query='environment:prod OR environment:staging')
-- NOT条件：满足左侧、不满足右侧
.entity with(query='type:service NOT status:stopped')
-- 复杂组合
.entity with(query='(cluster:prod OR cluster:staging) AND NOT status:maintenance')</code></pre><p><strong>特殊字符处理：</strong></p><ul><li>包含特殊字符（如 |、:）的查询必须用双引号包含</li><li>示例：<code>query='description:"ratio is 1:2"'</code></li></ul><h3>3.3 多类型联合检索</h3><p>支持跨多个 domain 和 entity_type 进行联合查询，统一打分排序：</p><pre><code>-- 检索所有domain中包含"cart"的实体
.entity with(domain='*', name='*', query='cart') 
-- 检索所有domain中包含"service"的实体类型，属性中存在"production"的实体
.entity with(domain='*', name='*service*', query='production')
-- 检索特定domain下的多种实体类型，属性中存在"error"或"rate"的实体
.entity with(domain='apm', name='apm.*', query='error rate')</code></pre><h3>3.4 结合 SPL 进行数据计算分析</h3><p>无论检索模式还是扫描模式，都可以结合 SPL 进行更深入的数据计算：</p><pre><code>-- 检索apm域中在香港区域的不同语言的应用数量，按照应用数量降序排列
.entity with(domain='apm', name='apm.service') 
| where region_id = 'cn-hongkong'
| stats count = count() by language 
| project language, count 
| sort count desc</code></pre><h2>打分和排序机制</h2><h3>4.1 相关性打分</h3><p>USearch 使用多因素综合打分算法：</p><ol><li><strong>词频权重：</strong> 关键词在文档中出现的频率</li><li><strong>字段权重：</strong> 不同字段的重要性权重（如名称字段权重高于描述字段）</li><li><strong>文档长度：</strong> 较短文档中的匹配通常得分更高</li><li><strong>逆文档频率：</strong> 稀有词汇获得更高权重</li></ol><h3>4.2 排序规则</h3><p>默认按相关性分数降序排列，分数相同时按时间戳排序：</p><pre><code>-- 默认相关性排序
.entity with(query='web service error', topk=20)
-- 结合SPL自定义排序
.entity with(query='kubernetes pod')
| sort __last_observed_time__ desc
| limit 50
-- 多字段排序
.entity with(domain='apm', name='apm.service')
| sort cluster asc, service_name asc</code></pre><h2>Entity 查询具体应用场景</h2><h3>5.1 场景一：快速定位和检索实体</h3><p><strong>问题描述：</strong> 线上出现告警或需要查找特定实体时，需要快速定位相关实体实例。</p><p><strong>解决方案：</strong> 根据场景选择不同的查询方式。</p><pre><code>-- 方式1：根据告警中的实体ID精确查询
.entity with(
    domain='apm', 
    name='apm.service', 
    ids=['4567bd905a719d197df','973ad511dad2a3f70a']
)
-- 方式2：根据关键词全文检索
.entity with(query='user-service error', topk=10)
-- 方式3：字段限定精确查询
.entity with(query='service_name:user-service')
-- 方式4：通过标签查找特定团队的服务
.entity with(
    domain='apm', 
    name='apm.service', 
    query='labels.team:backend AND labels.language:java AND status:running'
)</code></pre><p><strong>效果：</strong> 快速获取问题实体的完整信息，包括状态、属性、标签等，支持多种查询方式满足不同场景需求。</p><h3>5.2 场景二：跨域联合检索</h3><p><strong>问题描述：</strong> 需要在多个域（APM、K8s、云资源等）中搜索包含特定关键词的实体，避免在多系统间切换。</p><p><strong>解决方案：</strong> 使用多类型联合检索。</p><pre><code>-- 在所有域中搜索包含"error"的实体
.entity with(domain='*', name='*', query='error', topk=50)
-- 检索特定前缀domain下的多种实体类型
.entity with(domain='apm*', name='*', query='error', topk=50)</code></pre><p><strong>效果：</strong> 统一接口检索跨域实体，打破数据孤岛，提高查询效率。</p><h3>5.3 场景三：条件过滤和数据分析</h3><p><strong>问题描述：</strong> 需要找出满足特定条件的实体，并进行统计分析，识别问题模式或进行数据洞察。</p><p><strong>解决方案：</strong> 结合 SPL 进行条件过滤和聚合分析。</p><pre><code>-- 找出java语言的apm服务，按集群统计
.entity with(domain='apm', name='apm.service') 
| where language='java'
| stats count=count() by cluster
-- 查询生产环境或预发环境中运行的服务
.entity with(query='(environment:prod OR environment:staging) AND status:running')
| stats count=count() by environment, cluster
-- 检索apm域中ARMS生产应用在不同区域的数量，按照应用数量降序排列
.entity with(domain='apm', query='environment:prod') 
| where telemetry_client='ARMS' 
| stats service_count = count() by service, region_id 
| project region_id, service, service_count 
| sort service_count desc</code></pre><p><strong>效果：</strong> 快速识别问题实体，进行数据聚合分析，发现数据模式。</p><h2>性能优化建议</h2><h3>6.1 使用精确匹配</h3><p>字段限定查询比全文搜索更高效：</p><pre><code>-- ❌ 全文搜索（较慢）
.entity with(query='production')
-- ✅ 字段限定（更快）
.entity with(query='environment:production')</code></pre><h3>6.2 避免前缀通配符</h3><p>后缀通配符比前缀通配符性能更好：</p><pre><code>-- ❌ 前缀通配符（较慢）
.entity with(name='*service')
-- ✅ 后缀通配符（更快）
.entity with(name='service*')</code></pre><h3>6.3 合理使用逻辑运算符</h3><p>简单的 AND 条件比复杂的 OR 条件更高效：</p><pre><code>-- ✅ 简单AND条件
.entity with(query='status:running AND cluster:prod')
-- ⚠️ 复杂OR条件（性能较差）
.entity with(query='name:a OR name:b OR name:c OR name:d')</code></pre><h3>6.4 合理设置 topk</h3><p>根据实际需求设置 topk 值，避免返回过多不必要的数据：</p><pre><code>-- 只需要前10条结果
.entity with(query='error', topk=10)
-- 需要更多结果时再增加
.entity with(query='error', topk=100)</code></pre><h2>总结</h2><p>Entity 查询作为 EntityStore 中用于查询实体实例的核心接口，为可观测性场景提供了强大的检索和分析能力。通过 Entity 查询，用户可以：</p><ol><li><strong>快速定位：</strong> 通过关键词、ID、条件快速找到目标实体</li><li><strong>跨域检索：</strong> 统一接口查询多个域的实体数据</li><li><strong>精确查询：</strong> 支持字段限定、逻辑组合等精确查询方式</li><li><strong>数据分析：</strong> 结合 SPL 进行复杂的数据过滤和统计分析</li></ol><p>这些能力使得 Entity 查询成为日常运维、问题排查、数据分析等场景中不可或缺的工具，为可观测性数据的有效利用提供了坚实的基础。</p><p>点击<a href="https://www.bilibili.com/video/BV1aPSxBJE9R/" target="_blank">此处</a>查看视频演示。</p>]]></description></item><item>    <title><![CDATA[美团发布 LongCat-Image 图像生成模型，编辑能力登顶开源SOTA 美团技术团队 ]]></title>    <link>https://segmentfault.com/a/1190000047461335</link>    <guid>https://segmentfault.com/a/1190000047461335</guid>    <pubDate>2025-12-09 15:01:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>当前 AI 图像生成技术需求旺盛，但行业陷入 “两难困境”：闭源大模型性能强劲但无法自行部署或二次定制开发，开源方案普遍存在轻量化与模型性能难以兼顾、面向商用专项能力不足的痛点，制约商业创作与技术普惠。为此，美团 LongCat 团队正式发布并开源 LongCat-Image 模型，通过高性能模型架构设计、系统性的训练策略和数据工程，以6B参数规模，成功在文生图和图像编辑的核心能力维度上逼近更大尺寸模型效果，为开发者社区与产业界提供了 “高性能、低门槛、全开放” 的全新选择。</p><h2>技术亮点</h2><p>LongCat-Image 采用文生图与图像编辑同源的架构设计，并结合渐进式学习策略，在仅 6B 的紧凑参数规模下，实现了指令遵循精准度、生图质量与文字渲染能力的高效协同提升。尤其在<strong>单图编辑的可控性和文字生成的汉字覆盖度</strong>方面独具优势。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047461338" alt="模型架构" title="模型架构"/></p><h3>亮点一：图像编辑高度可控</h3><p><strong>LongCat-Image 在图像编辑领域的多个重要基准测试中（如GEdit-Bench、ImgEdit-Bench）均达到开源SOTA水平</strong>，实现性能突破的背后在于一套紧密协同的训练范式和数据策略。为有效继承文生图模型的知识和美感，同时避免文生图后训练阶段收窄的状态空间对编辑指令多样性的限制，基于文生图Mid-training阶段模型进行初始化，并采用指令编辑与文生图多任务联合学习机制，深化对复杂多样化指令的理解。此外通过预训练阶段的多源数据及指令改写策略，以及SFT阶段引入人工精标数据，最终实现了指令遵循精准度、泛化性和编辑前后视觉一致性的共同提升。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047461339" alt="风格迁移与属性编辑能力对比" title="风格迁移与属性编辑能力对比" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047461340" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047461341" alt="结构编辑与构图编辑的能力对比" title="结构编辑与构图编辑的能力对比" loading="lazy"/></p><h3>亮点二：中文文字生成精准覆盖</h3><p>针对中文文本渲染这一行业痛点，<strong>LongCat-Image 通过课程学习策略来提升字符覆盖度和渲染精准度</strong>：预训练阶段基于千万量级合成数据学习字形，覆盖通用规范汉字表的8105个汉字；SFT 阶段引入真实世界文本图像数据，提升在字体、排版布局上的泛化能力；RL 阶段融入 OCR 与美学双奖励模型，进一步提升文本准确性与背景融合自然度。此外通过对 prompt 中指定渲染的文本采用字符级编码，大幅降低模型记忆负担，实现文字生成学习效率的跨越式提升。通过该项能力加持，<strong>有效支持海报设计、商业广告作图场景中复杂笔画结构汉字的渲染，以及古诗词插图、对联、门店招牌、文字Logo等设计场景的生僻字渲染</strong>。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047461342" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047461343" alt="文字生成能力对比" title="文字生成能力对比" loading="lazy"/></p><p>此外，LongCat-Image通过系统性的数据筛选与对抗训练框架，实现了出图纹理细节和真实感的提升。预训练和中期训练阶段严格过滤AIGC数据，避免陷入“塑料感”纹理的局部最优；在SFT阶段，所有数据均经过人工精筛来对齐大众审美；在RL阶段，创新性地<strong>引入AIGC内容检测器作为奖励模型，利用其对抗信号逆向引导模型学习真实世界的物理纹理、光影和质感。</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047461344" alt="图像生成综合能力对比" title="图像生成综合能力对比" loading="lazy"/></p><h2>性能验证</h2><h3>客观基准评测</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047461345" alt="客观基准测试性能对比" title="客观基准测试性能对比" loading="lazy"/></p><p>全面的客观基准测试充分验证了 LongCat-Image 的核心竞争力：图像编辑任务中，ImgEdit-Bench（4.50分）、 GEdit-Bench 中英文得分（7.60/7.64分）分别达到开源SOTA水平，且逼近头部闭源模型水平；文字渲染方面，ChineseWord 评测以 90.7 分的成绩大幅领先所有参评模型，实现常用字、生僻字的全量精准覆盖；文生图任务上，GenEval 0.87 分、DPG-Bench 86.8 分的表现，使其在生图基础能力上相比头部开源与闭源模型依然具备强竞争力。</p><h3>综合主观评测</h3><p>在衡量模型的通用能力时，我们始终将用户的真实体验放在首位。为此，我们采用业界公认的主观评价方法，对LongCat-Image在“文生图”与“图像编辑”两大核心场景下的表现进行了系统评估。</p><p>在文生图方面采用大规模的人工主观评分（MOS）方法，核心覆盖 文本-图像对齐、视觉合理度、视觉真实度、美学质量4个维度，LongCat-Image 的真实度相比主流开闭源模型表现出色，同时在文本-图像对齐与合理度上也达到开源SOTA水平。在图像编辑方面采用严格的并列对比评估（Side-by-Side, SBS）方法，聚焦于综合编辑质量、视觉一致性这两个用户体验的维度，评测结果表明，LongCat-Image 虽然与 Nano Banana、Seedream 4.0 等商业模型存在一定差距，但显著超越了其他开源方案。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047461346" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047461347" alt="人类主观评分（MOS）对比&amp; 并列对比评估胜率（SBS）" title="人类主观评分（MOS）对比&amp; 并列对比评估胜率（SBS）" loading="lazy"/></p><h2>开源开放</h2><p>为了构建一个更透明、开放、协作的开源生态系统，我们全面开源文生图的多阶段模型（Mid-training、Post-training）和图像编辑模型，旨在无缝支持从前沿研究到商业应用的全流程。我们坚信，真正的技术进步源于社区的集体智慧。诚邀广大开发者体验模型、参与共建，让我们共同基于这个高效能模型，探索视觉生成的更多可能。</p><p>🔗 资源链接：</p><p>| Hugging Face: <a href="https://link.segmentfault.com/?enc=3KhJmk%2BlTVRcf%2FXqeK458g%3D%3D.9Yt%2Fp%2FCzSBdNaFBjDRwZWutqjtdX5xkPDDlzZ8rgs674Gpc8FV9N%2FFNHC6TIs76B5kY4RQd4owYFO6FLsVaFFw%3D%3D" rel="nofollow" target="_blank">https://huggingface.co/meituan-longcat/LongCat-Image</a></p><p>| GitHub: <a href="https://link.segmentfault.com/?enc=pbxj5Gf96LKBfiPyTM7R8A%3D%3D.LGsXuuHNQK16DDWLzGOysi9FwVCKxn17Uq9cqQh5LsKIZTqmLTgQGw1%2BFVl%2B0nW4DQdu7lt6sdk1H3nCF98GyQ%3D%3D" rel="nofollow" target="_blank">https://github.com/meituan-longcat/LongCat-Image</a></p><h2>零门槛解锁 AI 创作新可能</h2><h3>LongCat APP：一键生成专业级图像</h3><p>继文生图功能上线后，「LongCat APP」全新升级图生图能力！上传任意素材（风景照、自拍照、草稿线稿均可），模型将精准捕捉核心元素，按需求生成全新图像。同步上线 24 个零门槛图片玩法模板，涵盖海报设计、人像精修、场景改造等多重场景，点击 “AI 创作” 直接套用，彻底告别 “提示词焦虑”，小白也能快速产出专业级作品。</p><h3>LongCat.ai：网页端高效创作入口</h3><p>进入<a href="https://link.segmentfault.com/?enc=LElwrKIYnVt5FuvGFuWueA%3D%3D.OLhSmMJs1ixPjCQsMB%2BFWm54fj6u1sK1Gv4oh1vCpIw%3D" rel="nofollow" target="_blank">https://longcat.ai/</a>点击「图片生成」，可上传参考图、自由调整比例、选择心仪风格，无需复杂配置即可快速获得高质量生成结果。无论是商业设计初稿、社交媒体素材，还是个性化创意创作，都能高效完成。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047461348" alt="" title="" loading="lazy"/></p><p>扫描下方二维码即可体验 web 端及下载 LongCat APP 安卓版本（iOS 用户可直接在 APP Store 中搜索“LongCat”）</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047461349" alt="" title="" loading="lazy"/></p><p>快翻出相册里压箱底的素材，即刻使用 LongCat-Image 解锁图片创作的无限可能～</p><p>| 关注「美团技术团队」微信公众号，在公众号菜单栏对话框回复【2024年货】、【2023年货】、【2022年货】、【2021年货】、【2020年货】、【2019年货】、【2018年货】、【2017年货】等关键词，可查看美团技术团队历年技术文章合集。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000046195963" alt="" title="" loading="lazy"/></p><p>| 本文系美团技术团队出品，著作权归属美团。欢迎出于分享和交流等非商业目的转载或使用本文内容，敬请注明“内容转载自美团技术团队”。本文未经许可，不得进行商业性转载或者使用。任何商用行为，请发送邮件至 <a href="mailto:tech@meituan.com" target="_blank">tech@meituan.com</a> 申请授权。</p>]]></description></item><item>    <title><![CDATA[Python 3.11安装教程（超级详细，附安装包） 2025最新版详细图文安装教程 0day漏洞文]]></title>    <link>https://segmentfault.com/a/1190000047460724</link>    <guid>https://segmentfault.com/a/1190000047460724</guid>    <pubDate>2025-12-09 14:08:36</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h5>文章目录</h5><ul><li><a href="#_5" target="_blank">前言</a></li><li><a href="#Python_311_10" target="_blank">一、Python 3.11安装包下载</a></li><li><ul><li><a href="#1_Python_311_11" target="_blank">1. Python 3.11下载与安装</a></li></ul></li><li><a href="#python311_17" target="_blank">二、python3.11安装步骤</a></li><li><a href="#_40" target="_blank">三、验证</a></li><li><a href="#_45" target="_blank">四、最后点个赞，关注一下。（超级重要）</a></li></ul><hr/><h3>前言</h3><p>本文为 Python 3.11安装教程，详尽阐述了从下载 Python 3.11  <br/>到完成安装的每一步操作流程，并分享了实用的安装技巧。  <br/>Python 3.11  <br/>作为最新正式版本，是一门强大且功能完备的通用型面向对象直译式计算机程序设计语言。它语法简洁清晰，具备高度的跨平台性，几乎能在所有操作系统上流畅运行，十分适合处理各类高层任务。并且，随着持续更新优化，它在独立大型项目开发中也日益发挥重要作用。</p><hr/><h3>一、Python 3.11安装包下载</h3><h4>1. Python 3.11下载与安装</h4><blockquote>python3.11下载地址： <a href="https://link.segmentfault.com/?enc=72mCnm2lX%2BJkMPs2ag92eA%3D%3D.ooZdiC4y%2FFsb9R9o58806DrJKTGWPwV82pUY5ZhFKeSM05nQr3DMP192AIuRl84b" rel="nofollow" target="_blank">https://pan.quark.cn/s/b2042850c6f2</a></blockquote><ul><li>下载完成包含以下文件：  <br/> <img referrerpolicy="no-referrer" src="/img/remote/1460000047460727" alt="111" title="111"/></li></ul><h3>二、python3.11安装步骤</h3><ul><li>1.右键以管理员身份运行安装程序。  <br/> <img referrerpolicy="no-referrer" src="/img/remote/1460000047460728" alt="111" title="111" loading="lazy"/></li><li>2.勾选【Add Python…】然后点击【Customize…】。  <br/> <img referrerpolicy="no-referrer" src="/img/remote/1460000047460729" alt="Python3.11安装教程" title="Python3.11安装教程" loading="lazy"/></li><li>3.页面点击【Next】。  <br/> <img referrerpolicy="no-referrer" src="/img/remote/1460000047460730" alt="Python3.11安装教程" title="Python3.11安装教程" loading="lazy"/></li><li>4.勾选【Install For All users】，可根据需要修改Python  <br/>3.11安装路径地址中的安装位置，点击【Install】。  <br/> <img referrerpolicy="no-referrer" src="/img/remote/1460000047460731" alt="python3.11安装教程" title="python3.11安装教程" loading="lazy"/></li><li>5.Python 3.11安装中，等待安装完成  <br/> <img referrerpolicy="no-referrer" src="/img/remote/1460000047460732" alt="python3.11安装教程" title="python3.11安装教程" loading="lazy"/></li><li>6.Python 3.11安装完成，点击【Close】。  <br/> <img referrerpolicy="no-referrer" src="/img/remote/1460000047460733" alt="python3.11安装教程" title="python3.11安装教程" loading="lazy"/></li><li>7.打开系统开始菜单，搜索python，点击运行IDLE(Python 3.11)安装软件。  <br/> <img referrerpolicy="no-referrer" src="/img/remote/1460000047460734" alt="python3.11怎么运行" title="python3.11怎么运行" loading="lazy"/></li><li>8.Python 3.11安装完成，运行界面如下。  <br/> <img referrerpolicy="no-referrer" src="/img/remote/1460000047460735" alt="python3.11怎么运行" title="python3.11怎么运行" loading="lazy"/></li><li>9.到此Python 3.11安装结束。</li></ul><h3>三、验证</h3><ul><li>1.同时按住键盘win + R，打开cmd命令行，出现如图，Python 3.11安装完成。</li></ul><blockquote>python --version</blockquote><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047460736" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h3>四、最后点个赞，关注一下。（超级重要）</h3>]]></description></item><item>    <title><![CDATA[2025年10佳远程办公解决方案项目管理工具排名（安全性能/跨平台支持/客户案例） 3Q聊工具 ]]></title>    <link>https://segmentfault.com/a/1190000047460852</link>    <guid>https://segmentfault.com/a/1190000047460852</guid>    <pubDate>2025-12-09 14:07:58</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <blockquote>本文将为大家系统评测2025年远程办公场景下的10佳项目管理工具，分别是禅道、ClickUp、Asana、Monday.com、Trello、Jira、飞书项目、Teambition、Gitee、Oracle Primavera P6。在远程办公渗透率已达68%的2025年，项目管理工具的安全性能与跨平台支持直接决定团队协作效率，而真实客户案例更能验证工具的实战价值。但随之而来的是两个核心疑问：如何在保障核心数据安全的前提下提升远程协作效率？不同规模的团队该如何从众多工具中筛选出适配自身场景的那一款？带着这两个问题，我们将从核心维度逐一解析每款工具的价值，为远程办公团队提供权威选型参考。</blockquote><h2>1. 禅道：国产信创场景下的全流程管理标杆</h2><p>​<strong>安全性能</strong>​：作为国产项目管理工具的领军者，禅道在安全合规上构建了全栈防护体系。已完成龙芯、鲲鹏等国产芯片适配，兼容统信UOS、银河麒麟等国产操作系统，累计取得16项信创互认证书。其开源架构支持企业自主审查代码，从根源规避“后门”风险，混合云部署模式更满足金融、政务等敏感场景的数据隔离需求。2025年通过CMMI 5级认证与等保2.0三级认证，形成“代码审计+权限管控+合规审计”的三重安全屏障。</p><p>​<strong>跨平台支持</strong>​：采用微服务架构设计，实现全终端无缝适配，支持Windows、macOS、Linux桌面端，iOS、Android移动端，同时针对国产终端生态优化了鸿蒙系统适配体验。云端版本支持浏览器直接访问，私有化部署版本可与企业现有IT架构深度融合，插件市场提供300+扩展模块，实现与Git、Jenkins等工具的无缝集成。</p><p>​<strong>客户案例</strong>​：某省级政务平台迁移禅道后，借助其国产化适配能力与漏洞管理模块，系统漏洞修复效率提升60%，运维成本降低35%。某医疗设备厂商通过禅道实现软硬件协同开发，依托需求-任务-缺陷的闭环管理，达成需求追溯率100%的行业严苛标准。此外，国家电网、航天科工等关键领域企业也将禅道作为核心项目管理工具，支撑多项目并行管控。<br/><img width="723" height="357" referrerpolicy="no-referrer" src="/img/bVdl902" alt="" title=""/></p><h2>2. ClickUp：AI赋能的全能型远程协作平台</h2><p>​<strong>安全性能</strong>​：通过SOC 2 Type II、GDPR、HIPAA等多项国际合规认证，采用AES-256加密技术保障数据传输与存储安全。2025年新增“安全态势感知”模块，AI助手可实时监测异常访问行为并自动触发预警，权限管理支持按项目、任务层级精准分配操作权限，有效防范远程协作中的数据泄露风险。</p><p>​<strong>跨平台支持</strong>​：推出ClickUp 3.0混合现实工作台，支持MR眼镜、PC、手机、平板多终端同步，研发团队可通过MR设备实时标注3D模型并同步至全球协作节点，跨时区协作延迟降低40%。兼容Windows、macOS、Linux、iOS、Android全系统，与Slack、Google Workspace、Zoom等200+办公工具深度集成，开放API支持企业自定义生态对接。</p><p>​<strong>客户案例</strong>​：Netflix利用ClickUp管理全球内容制作项目，通过多视图切换（看板、甘特图、日历）功能协调不同地区拍摄团队，项目交付效率提升32%。某新能源企业借助其“数字孪生”功能，将生产线设备状态实时映射至项目管理界面，远程监控研发进度，新产品上市周期缩短28%。免费版已能支撑10人以下远程团队的全流程管理，付费版在千人级企业中适配性良好。<br/><img width="723" height="357" referrerpolicy="no-referrer" src="/img/bVdmdGC" alt="" title="" loading="lazy"/></p><h2>3. Asana：跨部门远程协作的流程管控专家</h2><p>​<strong>安全性能</strong>​：构建“数据加密+行为审计+权限隔离”的安全体系，传输过程采用TLS 1.3加密标准，存储数据实现异地容灾备份。针对远程办公场景优化了离职员工权限回收机制，支持一键冻结账户并导出历史操作日志，满足企业数据溯源需求。通过ISO 27001信息安全管理体系认证，金融、医疗行业客户适配性良好。</p><p>​<strong>跨平台支持</strong>​：全终端覆盖Windows、macOS、iOS、Android系统，网页端支持Chrome、Firefox、Safari等主流浏览器无插件运行。“Portfolios”模块支持多终端同步查看项目组合进度，与Microsoft Teams、Slack、Google Drive的集成可实现文件实时共享与任务状态同步，远程跨部门协作时无需频繁切换工具。</p><p>​<strong>客户案例</strong>​：Adobe营销团队通过Asana管理全球 campaigns 项目，利用任务依赖关系设置与截止日期提醒功能，协调设计、文案、投放等多远程团队，项目延期率从22%降至8%。某跨国咨询公司借助其报告生成模块，自动汇总各地区项目数据，管理层远程决策效率提升40%。<br/><img width="723" height="357" referrerpolicy="no-referrer" src="/img/bVdmc6i" alt="" title="" loading="lazy"/></p><h2>4. Monday.com：低代码适配的远程场景灵活搭建工具</h2><p>​<strong>安全性能</strong>​：采用银行级加密技术，通过SOC 2、ISO 27001、GDPR等合规认证。2025年新增“安全围栏”功能，可按团队或项目划分数据隔离区域，远程员工仅能访问权限范围内的信息。提供完整的操作日志与审计报告，支持自定义安全规则，满足不同行业的远程办公合规要求。</p><p>​<strong>跨平台支持</strong>​：以拖拽式操作实现多终端适配，Windows、macOS、iOS、Android端界面风格统一，学习成本降低60%。移动端App优化了触控操作体验，支持离线编辑任务并在联网后自动同步。与Zapier、IFTTT等自动化工具集成，可实现远程办公场景下的流程自动化触发，如收到邮件自动创建任务。</p><p>​<strong>客户案例</strong>​：Spotify利用Monday.com搭建专属远程音乐制作管理面板，通过预设模板快速配置录音、混音、审核等流程，远程团队协作效率提升35%。某电商企业借助其低代码特性，3天内搭建完成直播带货排期管理系统，支持10个远程主播团队的任务分配与数据统计。<br/><img width="723" height="357" referrerpolicy="no-referrer" src="/img/bVdmdGE" alt="" title="" loading="lazy"/></p><h2>5. Trello：轻量远程协作的可视化看板工具</h2><p>​<strong>安全性能</strong>​：基础版提供数据传输TLS加密，高级版新增企业级权限管控与数据本地备份功能，通过SOC 2 Type II认证。针对远程小团队场景优化了共享权限设置，可精准控制卡片查看、编辑、评论权限，避免敏感信息误传。支持操作日志导出，满足小型企业的远程办公安全审计需求。</p><p>​<strong>跨平台支持</strong>​：以简洁看板为核心，实现全终端无缝适配，Windows、macOS、iOS、Android端均支持卡片拖拽与状态更新。网页端无需安装插件即可运行，与Buttercup、Slack等工具集成，可实现远程办公中的任务提醒与文件共享。免费版已支持多终端同步，满足轻量协作需求。</p><p>​<strong>客户案例</strong>​：某初创设计公司15人远程团队使用Trello管理项目，通过卡片式任务分配与状态标注，实现设计稿从初稿到定稿的全流程可视化，沟通成本降低50%。宜家门店运营团队借助其看板功能，远程协调全国200+门店的促销活动布置任务，执行差错率下降18%。<br/><img width="723" height="357" referrerpolicy="no-referrer" src="/img/bVdmc6h" alt="" title="" loading="lazy"/></p><h2>6. Jira：技术团队远程研发的专业管理工具</h2><p>​<strong>安全性能</strong>​：具备企业级权限控制系统，支持按角色、项目、操作维度精细化授权，通过SOC 2、ISO 27001、GDPR等多项国际认证。私有化部署版本可实现数据本地存储，满足技术团队远程研发中的代码与缺陷数据安全需求。插件市场提供安全扫描工具，可集成实现研发过程中的漏洞检测。</p><p>​<strong>跨平台支持</strong>​：支持Windows、macOS、Linux桌面端，iOS、Android移动端适配研发场景，可实时查看缺陷状态与迭代进度。与GitHub、GitLab、Jenkins等研发工具深度集成，远程开发团队可实现代码提交与任务状态自动关联，无需手动同步数据。网页端支持自定义仪表盘，适配不同远程研发角色的查看需求。</p><p>​<strong>客户案例</strong>​：亚马逊AWS研发团队通过Jira管理分布式系统开发项目，利用Scrum框架支持与缺陷跟踪功能，协调全球12个地区的远程开发人员，迭代交付效率提升25%。某芯片设计企业借助其权限管控与插件扩展能力，实现远程研发过程中的知识产权保护，代码泄露风险降低90%。<br/><img width="723" height="357" referrerpolicy="no-referrer" src="/img/bVdl909" alt="" title="" loading="lazy"/></p><h2>7. 飞书项目：生态协同的远程办公一体化工具</h2><p>​<strong>安全性能</strong>​：通过等保三级认证与ISO 27001认证，采用飞书统一安全架构，实现身份认证、数据加密、行为审计的全链路防护。支持数据本地备份与私有化部署，针对远程办公场景优化了设备管理功能，可远程擦除离职员工设备上的项目数据。与飞书安全中心联动，可实时监测异常登录行为。</p><p>​<strong>跨平台支持</strong>​：实现全系统覆盖，支持Windows、macOS、Linux、iOS、Android、鸿蒙系统，不同终端数据实时同步。深度集成飞书文档、飞书会议、飞书多维表格，远程团队可在任务详情页直接发起会议、共享文档，无需跨平台切换。2025年升级后支持单表1000万热行数据存储，毫秒级计算适配大型远程项目数据管理。</p><p>​<strong>客户案例</strong>​：理想汽车利用飞书项目管理远程研发与供应链协同，通过任务与多维表格联动功能，实时同步零部件研发进度与供应商交付状态，项目延期率下降22%。某直播电商企业借助其与抖音生态的连通性，实现直播排期、选品、数据复盘的远程一体化管理，复盘报告生成效率提升60%。<br/><img width="723" height="357" referrerpolicy="no-referrer" src="/img/bVdmc6j" alt="" title="" loading="lazy"/></p><h2>8. Teambition：钉钉生态下的远程轻量化协作工具</h2><p>​<strong>安全性能</strong>​：通过等保三级认证，支持数据本地备份与混合云部署，2025年升级“企业安全围栏”功能，实现远程团队数据的隔离存储。与阿里云深度捆绑，采用阿里云OSS存储技术保障数据安全，提供操作日志追溯与异常行为预警，满足中小企业远程办公的合规需求。</p><p>​<strong>跨平台支持</strong>​：适配Windows、macOS、iOS、Android系统，与钉钉生态深度整合，可在钉钉内直接打开任务、查看进度。支持网页端与移动端离线操作，联网后自动同步数据，针对远程办公场景优化了轻量化交互设计，新团队平均1天上手。</p><p>​<strong>客户案例</strong>​：三只松鼠通过Teambition管理全国50+仓库的远程运营项目，借助钉钉生态的消息触达与任务提醒功能，库存盘点效率提升40%。某教育机构利用其轻量化特性，搭建远程课程开发管理流程，协调讲师、课件制作、审核等团队，课程上线周期缩短30%。<br/><img width="723" height="357" referrerpolicy="no-referrer" src="/img/bVdmAV0" alt="" title="" loading="lazy"/></p><h2>9. Gitee：国产化DevOps远程研发管理平台</h2><p>​<strong>安全性能</strong>​：作为国产DevOps标杆平台，完成龙芯、鲲鹏等国产芯片全栈适配，支持政府/金融行业专属私有化部署方案。AI驱动的DevOps 3.0体系可自动识别代码安全漏洞，合规审计报告生成效率提升300%，通过16项信创认证，成为党政军领域远程研发的首选工具。</p><p>​<strong>跨平台支持</strong>​：支持Windows、macOS、Linux桌面端，iOS、Android移动端适配研发场景，可实时查看代码提交记录与项目进度。与国产研发工具生态深度集成，支持与禅道、Jenkins等工具联动，实现远程研发全流程的国产化工具链闭环。</p><p>​<strong>客户案例</strong>​：某航天研究院借助Gitee实现导弹控制系统的远程研发管理，通过代码安全扫描与国产化适配能力，满足军工领域的安全合规要求，研发周期缩短20%。某互联网大厂利用其AI缺陷预测功能，远程协调多个研发中心，代码缺陷率下降35%。<br/><img width="723" height="357" referrerpolicy="no-referrer" src="/img/bVdmdGv" alt="" title="" loading="lazy"/></p><h2>10. Oracle Primavera P6：大型远程项目的进度管控工具</h2><p>​<strong>安全性能</strong>​：采用Oracle数据库安全架构，支持数据加密存储与传输，通过ISO 27001、SOC 2等国际认证。具备精细化权限管控功能，可按项目阶段、部门划分远程团队的操作权限，提供完整的审计轨迹与合规报告，适配大型工程、能源等行业的远程项目安全需求。</p><p>​<strong>跨平台支持</strong>​：支持Windows、macOS桌面端，iOS、Android移动端可查看项目进度与关键路径，网页端支持大型项目计划的编制与修改。与Oracle EBS、SAP等企业级系统集成，可实现远程项目与财务、人力资源系统的数据同步，满足大型企业的跨部门协同需求。</p><p>​<strong>客户案例</strong>​：中国建筑集团使用Oracle Primavera P6管理全球30+海外工程项目，通过关键路径法与资源优化功能，远程监控200+子项目进度，项目成本超支率从15%降至7%。某石油企业借助其与ERP系统的集成能力，远程协调勘探、开采、运输团队，项目整体效率提升18%。<br/><img width="723" height="357" referrerpolicy="no-referrer" src="/img/bVdmWLs" alt="" title="" loading="lazy"/></p><h2>全文总结：远程办公工具选型的核心逻辑与价值回归</h2><p>2025年远程办公项目管理工具市场呈现“国产化崛起+AI赋能+生态协同”三大趋势，Gartner预测中国市场复合增长率达28%，远超全球平均水平。从本次评测的10款工具来看，<strong>安全性能</strong>已从附加需求升级为核心门槛，信创认证、数据加密、权限管控成为企业选型的基础指标，禅道、Gitee等国产工具在这一领域形成独特优势；<strong>跨平台支持</strong>正向“全终端适配+生态集成”演进，ClickUp的MR技术、飞书项目的多维表格集成，打破了远程协作的场景壁垒；<strong>客户案例</strong>则印证了工具的场景适配性——轻量工具适配初创团队（如Trello），专业工具支撑技术研发（如Jira），大型工具管控复杂项目（如Oracle Primavera P6）。</p><p>选型时需把握三大原则：一是匹配团队规模，10人以下轻量协作优先选择Trello、Teambition；50-100人中型团队推荐禅道、ClickUp；千人级企业或大型项目适配Jira、Oracle Primavera P6。二是聚焦核心场景，研发团队侧重代码集成与缺陷管理（如Gitee、Jira），跨部门协作侧重流程可视化（如Asana、Monday.com），国产化需求优先选择禅道、Gitee。三是兼顾长期成本，开源工具（如禅道开源版）降低初期投入，生态集成工具（如飞书项目）减少后期协同成本。</p><h2>FAQ：远程办公项目管理工具常见问题解答</h2><h3>Q1：远程办公场景下，如何判断工具的安全性能是否达标？</h3><p>核心关注三项指标：一是合规认证，国内场景优先选择通过等保三级、信创认证的工具（如禅道、Gitee），国际场景需具备SOC 2、GDPR认证（如ClickUp、Asana）；二是部署模式，敏感行业优先选择私有化部署或混合云部署（如禅道、Oracle Primavera P6）；三是权限管控，需支持按角色、项目精细化授权与操作日志追溯（如Jira、飞书项目）。某省级政务平台选择禅道正是基于其16项信创认证与混合云部署能力，实现远程办公数据安全可控。</p><h3>Q2：跨平台支持的核心评判标准是什么？仅看终端覆盖够吗？</h3><p>终端覆盖是基础，更关键的是“协同流畅性”与“生态适配性”。协同流畅性要求多终端数据实时同步、操作体验一致，如ClickUp的MR工作台与移动端可实现3D模型标注同步；生态适配性指工具与现有办公体系的集成能力，如Teambition与钉钉的深度整合、飞书项目与抖音生态的连通。此外，离线操作与自动同步功能也很重要，可应对远程办公中的网络不稳定场景（如Trello、Teambition）。</p><h3>Q3：国产工具与国际工具相比，在远程办公场景下各有哪些优势？</h3><p>国产工具的核心优势在本土化适配与安全合规，如禅道的信创适配、Gitee的国产化芯片支持，更符合政务、金融等行业需求，且具备Jira等国际工具的数据迁移能力；国际工具的优势在全球化协同与功能创新，如ClickUp的MR技术、Asana的多地区项目组合管理，适配跨国远程团队。从成本来看，国产工具开源版（如禅道）与免费版（如飞书项目基础版）更具性价比，国际工具高级功能收费较高（如Asana企业版）。</p><h3>Q4：AI功能在远程办公项目管理工具中的实际价值是什么？是否值得付费升级？</h3><p>AI已从辅助功能升级为核心生产力工具，实际价值体现在三大场景：一是效率提升，如ClickUp的AI任务摘要生成、Gitee的代码漏洞自动识别，可降低远程沟通成本；二是风险预警，如Monday.com的项目延期预测、禅道的缺陷趋势分析，帮助远程团队提前管控风险；三是流程自动化，如飞书项目的任务自动分配、Asana的报告自动生成。是否付费需看团队规模，10人以下团队免费版基础功能足够，50人以上团队升级付费版可显著提升远程协作效率，如某新能源企业借助ClickUp AI功能，研发周期缩短28%。</p><h3>Q5：从传统工具迁移到新的远程办公项目管理工具，如何保障平滑过渡？</h3><p>分三步实现平滑迁移：一是前期调研，参考同类客户案例，如从Jira迁移可选择禅道，其支持Jira数据一键迁移并保留历史issue；二是分阶段落地，先在小团队试点（如选择1-2个项目测试），再全团队推广，借助工具提供的培训资源（如Trello的新手教程、禅道的咨询服务）降低学习成本；三是数据保障，迁移前全量备份历史数据，迁移后验证数据完整性与权限正确性，如某医疗设备厂商迁移禅道后，通过需求追溯功能验证数据一致性。</p>]]></description></item><item>    <title><![CDATA[构筑网络信任的基石：详析SSL证书的三大核心作用 冷姐Joy ]]></title>    <link>https://segmentfault.com/a/1190000047460865</link>    <guid>https://segmentfault.com/a/1190000047460865</guid>    <pubDate>2025-12-09 14:06:58</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在当今数字时代，我们的日常生活与网络紧密相连，从在线购物、移动银行到信息浏览，大量敏感数据在指尖流动。然而，您是否曾思考过，这些信息如何在浩瀚的互联网中安全传输？答案的关键，便在于一个看似微小却至关重要的技术——SSL证书。当您在浏览器地址栏看到那把绿色的锁形标志或“https”开头的网址时，正是SSL证书在默默守护您的安全。它的作用远不止一把“锁”，其主要作用可归结为以下三大核心点。</p><p><img width="723" height="400" referrerpolicy="no-referrer" src="/img/bVddlwr" alt="" title=""/></p><h4><strong>一、 数据加密：构筑机密信息的“防护盾”</strong></h4><p>SSL证书最根本、最核心的作用在于加密。在没有SSL保护的普通HTTP协议下，数据在网络中以“明文”形式传输，这就像寄出一张没有信封的明信片，途径的任何一个节点（如路由器、服务器）都可能窥探甚至窃取您的隐私信息，包括密码、身份证号、银行卡信息、聊天记录等。</p><p>SSL证书通过一种称为“SSL/TLS握手”的流程，在用户的浏览器与网站服务器之间建立一条加密通道。这条通道利用非对称加密和对称加密相结合的技术，为数据传输加上一把坚实的“锁”。所有通过此通道的信息都会变成一串杂乱无章的密文。即使数据被第三方截获，在没有对应密钥的情况下，所看到的也只是一堆毫无意义的乱码，根本无法破解。这就好比将明信片放入一个只有收件人才能打开的保险箱中，确保了信息的端到端机密性，为用户隐私和财产安全提供了基础保障。</p><h4><strong>二、 身份认证：颁发网站可信的“身份证”</strong></h4><p>网络世界虚虚实实，充斥着大量仿冒正规网站的“钓鱼网站”。这些网站界面足以以假乱真，旨在诱骗用户输入账号密码。此时，SSL证书的第二个关键作用——<strong>身份认证</strong>，便显得尤为重要。</p><p>SSL证书并非随意生成，它需要向全球公认的、受信任的证书颁发机构申请。机构在签发证书前，会对申请者的身份进行严格审核。对于等级最高的扩展验证证书，甚至会核实企业的法律、物理和运营状态。通过审核后，证书中会包含经过认证的网站所有者的信息，如公司名称、域名等。</p><p>当浏览器与网站建立连接时，会验证这张“数字身份证”的真伪及其颁发者的可信度。如果验证通过，浏览器才会显示安全锁标志，表示您正在访问的是一个经过身份验证的真实实体，而非冒牌货。这一机制极大地增强了网站的可信度，帮助用户有效识别并远离网络诈骗，为线上交易和交互奠定了信任基础。</p><h4><strong>三、 确保数据完整性与提升信任感</strong></h4><p>除了加密和认证，SSL证书还能<strong>确保数据的完整性</strong>。在数据传输过程中，可能存在被恶意篡改的风险（例如，插入广告或修改收款账户）。SSL证书通过使用消息认证码技术，为每个传输的数据包生成一个独特的“数字指纹”。接收方在收到数据后，会重新计算并核对这个指纹。如果数据在传输过程中哪怕只被改动了一个字节，指纹都会完全不同，接收方便会拒绝接收，从而确保用户看到的和服务器发送的内容完全一致，分毫不差。</p><p>此外，SSL证书的作用已超越纯技术范畴，延伸至<strong>用户心理和商业信誉层面</strong>。那个熟悉的锁形标志和“https”已成为普通用户辨别网站安全性的最直观标识。拥有SSL证书的网站能瞬间传递给用户“此站安全、可信”的积极信号，从而提升用户体验、增强用户忠诚度，并最终提高网站的转化率。同时，谷歌等主流搜索引擎明确将“https”作为搜索排名的重要因素之一，部署SSL证书已成为网站优化的标配，能有效提升网站在搜索结果中的可见度。</p><p><strong>结语</strong></p><p>总而言之，SSL证书已从一项可选技术升级为网络安全的必备要素。它通过<strong>加密</strong>守护隐私，通过<strong>认证</strong>验明正身，通过<strong>完整性校验</strong>防篡改，三位一体地构筑了一道坚实的安全防线。它不仅是保护数据传输的技术工具，更是连接用户信任与数字世界的桥梁。在日益复杂的网络环境中，为您的网站部署SSL证书，既是对用户负责的体现，也是在数字经济中赢得长远发展的明智之举。</p>]]></description></item><item>    <title><![CDATA[如何“白嫖”SSL证书 细心的红酒 ]]></title>    <link>https://segmentfault.com/a/1190000047460871</link>    <guid>https://segmentfault.com/a/1190000047460871</guid>    <pubDate>2025-12-09 14:06:25</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><strong>1. JoySSL（最常用）</strong></p><p>特点：高兼容性与标准性,安全性与技术保障,性价比高、中文支持好、类型齐全。</p><p>获取方式：</p><p><strong>打开<a href="https://link.segmentfault.com/?enc=KwXgYMYrABK3cW%2FC%2FNo0sQ%3D%3D.6Jr7Q8R6jiIhqOjitmTNDXwTbitCmVCz4JYPo7zSka8%3D" rel="nofollow" target="_blank">JoySSL</a>官网</strong>，完成注册，注册码填写<strong>230976</strong></p><p><img width="569" height="278" referrerpolicy="no-referrer" src="/img/bVdnfvr" alt="" title=""/></p><p><strong>2. ZeroSSL（替代方案）</strong></p><p>提供免费证书（有效期 90 天），支持 Web 界面或 acme.sh 工具签发。</p><p>需注册账户，泛域名证书可能需要付费。</p><p><strong>3. 国内服务商免费证书</strong></p><p>腾讯云：TrustAsia 品牌，免费单域名证书（有效期 1 年），可续期。</p><p>阿里云：DigiCert 免费单域名证书（有效期 1 年）。</p><p>华为云/百度云：类似提供 1 年期免费证书。</p><p>注意：国内服务通常需实名认证，且仅限单域名（不支持泛域名）。</p><p><strong>4. 其他免费渠道</strong></p><p>SSL For Free（基于 Let's Encrypt）：在线生成，需验证域名所有权。</p><p>Cloudflare：若使用其 CDN，可启用 SSL（灵活/完全模式），但证书仅用于 Cloudflare 流量。</p><p><strong>注意事项：</strong></p><p>免费证书无法提供资金保障（如事故赔偿），商业项目建议考虑付费证书。</p><p>确保证书及时续期，避免服务中断。</p>]]></description></item><item>    <title><![CDATA[高端品牌SSL证书优势何在？ 追风的苦咖啡 ]]></title>    <link>https://segmentfault.com/a/1190000047460882</link>    <guid>https://segmentfault.com/a/1190000047460882</guid>    <pubDate>2025-12-09 14:05:53</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h3>一、<strong>高级别身份验证与信任度</strong></h3><ul><li><strong>严格审核机制</strong>：高端品牌（如DigiCert、GlobalSign）提供扩展验证（EV）证书，需企业提交详细的法律和财务文件进行审核，确保网站合法性。浏览器地址栏会直接显示企业名称，显著增强用户信任感，尤其适用于金融、电商等敏感领域。</li><li><strong>反钓鱼与中间人攻击防护</strong>：通过证书颁发机构（CA）的权威验证，建立可信的身份认证链，有效抵御仿冒网站和数据劫持风险。<br/><img width="650" height="407" referrerpolicy="no-referrer" src="/img/bVdmdBK" alt="" title=""/></li></ul><h3>二、<strong>顶级加密技术与兼容性</strong></h3><ul><li><strong>高强度加密标准</strong>：采用256位加密算法（如ECC 256/384位或RSA 2048位），远超普通证书的128位加密，可防范暴力破解和中间人攻击。例如，DigiCert支持TLS 1.3协议，进一步优化传输效率与安全性。</li><li><strong>多算法与跨平台兼容</strong>：支持ECC和RSA双算法，并覆盖99%以上的主流浏览器及操作系统，避免因兼容性问题导致的访问失败。GlobalSign的证书甚至兼容苹果ATS和谷歌CT标准，适应移动端与国际化需求。</li></ul><h3>三、<strong>专业化服务与运维支持</strong></h3><ul><li><strong>全天候技术支持</strong>：提供7×24小时的技术响应，涵盖证书安装、配置调试及续期提醒，降低企业运维门槛。例如，CFCA的三级客户服务体系可快速解决突发问题。</li><li><strong>自动化管理工具</strong>：支持多域名通配符证书和批量签发功能，简化大型企业的复杂域名管理。DigiCert的自动化流程可大幅缩短证书签发周期。</li></ul><h3>四、<strong>品牌增值与合规性</strong></h3><ul><li><strong>提升企业形象</strong>：高端证书附带安全签章，向用户传递“金融级安全”信号，间接提升品牌美誉度。研究显示，带有EV证书的网站转化率平均提高18%。</li><li><strong>满足全球合规要求</strong>：符合GDPR、PCI DSS等行业法规，帮助企业规避法律风险。例如，CFCA证书通过全部WebTrust审计认证，适用于跨境业务场景。</li></ul><h3>五、<strong>SEO优化与用户体验</strong></h3><ul><li><strong>搜索引擎排名优先</strong>：谷歌、百度等引擎明确将HTTPS作为排名权重因素，部署高端证书可避免被标记为“不安全”，从而降低跳出率。</li><li><strong>支持新一代技术</strong>：兼容HTTP/2、HTTP/3及PWA应用，加速页面加载速度，改善移动端访问体验。</li></ul><p>总之，高端品牌SSL证书不仅是技术工具，更是企业数字化战略的核心资产。其优势在于通过多重安全机制降低风险，同时以专业服务支撑业务连续性，最终转化为用户信任与商业竞争力的提升。对于涉及交易、隐私数据的中大型企业，选择GlobalSign、DigiCert等高端品牌的综合收益远高于成本投入。</p>]]></description></item><item>    <title><![CDATA[IP地址如何申请SSL证书？ 从未表白的莴苣 ]]></title>    <link>https://segmentfault.com/a/1190000047460890</link>    <guid>https://segmentfault.com/a/1190000047460890</guid>    <pubDate>2025-12-09 14:05:16</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>第一步：确认需求与选择证书类型</h2><p>首先明确你的IP地址必须是公网IP，内网IP通常无法申请。根据使用场景选择证书类型：</p><ul><li><strong>单IP证书</strong>：保护单个IP地址</li></ul><h3><a href="https://link.segmentfault.com/?enc=PuBPD49%2FDMu5WOL1akGimg%3D%3D.KeDkelklJyLYrjiLXAlIVzLoZtH%2FRacCKBXPs1kgiChSN6pI0D5OIF7v7NhnZamYlMLZlTki4GiSxBKU7hoUwnKE5kNTpStVtjpumJbeN18%3D" rel="nofollow" target="_blank">IP证书申请入口</a></h3><p><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdjhQC" alt="" title=""/></p><p><strong>直接访问JoySSL，注册一个账号记得填写注册码230931获取免费安装服务。</strong></p><h2>第二步：申请证书具体流程</h2><ol><li><strong>选择证书提供商</strong>：选择支持IP地址证书的CA机构，如JoySSL。</li></ol><ol start="3"><li><p><strong>提交验证</strong>：向证书机构提交申请，通常需要验证你对IP地址的所有权。验证方式包括：</p><ul><li>邮件验证（发送到特定管理员邮箱）</li><li>文件验证（在IP对应的网站上放置验证文件）</li><li>DNS验证（如果IP有反向DNS记录）</li></ul></li><li><strong>完成审核</strong>：验证通过后，CA机构会签发SSL证书。</li></ol><h2>第三步：安装与配置</h2><p>收到证书文件后，按以下步骤安装：</p><ol><li>将证书文件上传到服务器</li><li>在Web服务器（如Nginx、Apache）中配置证书路径</li><li>重启服务器使配置生效</li><li>访问https://你的IP地址 测试是否成功</li></ol><h2>重要注意事项</h2><ul><li>IPv4支持申请SSL证书</li><li>部分免费证书机构不支持纯IP证书，需选择商业CA</li><li>确保证书与服务器环境兼容</li><li>记得设置证书到期提醒，及时续费更新</li></ul><h2>总结</h2><p>虽然给IP地址申请SSL证书比域名稍复杂一些，但按照上述三步走，完全可以在30分钟内完成。关键是选择合适的证书类型、通过所有权验证、正确安装配置。现在就开始行动，为你的IP地址加上安全锁吧！</p>]]></description></item><item>    <title><![CDATA[数据资产管理：从定义到价值实现的全流程指南 老实的剪刀 ]]></title>    <link>https://segmentfault.com/a/1190000047460905</link>    <guid>https://segmentfault.com/a/1190000047460905</guid>    <pubDate>2025-12-09 14:04:34</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>一、什么是数据资产？<br/>1.1 数据的来源</p><pre><code>   数据源自企业在经营过程中不断累积的各类数字化记录。这些数据既包括传统结构化数据，也涵盖文本、语音、图像、照片、视频等多媒体信息，还延伸至微博、微信、消费与出行记录、各类文件等多种形式。凡是企业活动沉淀下的数字记录，都属于数据范畴。</code></pre><p>1.2 什么数据才能被视为资产？</p><pre><code>   会计学对“资产”的界定是：由企业过去的交易或事项形成，被企业拥有或控制，并能够带来未来经济利益的资源。据此，数据资产可理解为：由企业经营活动产生、由企业能够拥有或控制，并能在未来带来经济收益的，以物理或电子方式记录的数据资源，包括各类文档、数据库及电子化信息。因此，数据要成为“资产”，必须满足三个基本条件：</code></pre><ol><li>来源于企业过往的交易或事项；</li><li>能够被企业拥有或实际控制；</li><li><p>预期可为企业带来经济利益。</p><pre><code>需要注意的是，企业内部并非所有数据都构成“资产”。长期存储但难以产生价值、反而增加维护成本的数据，更接近于“负债”。只有能够创造可预期收益的数据资源，才能真正划入数据资产的范畴。</code></pre><p>二、数据资产管理的重要性<br/>2.1 数据资产管理的概念</p><pre><code>前文提到，只有具备可预期收益的数据才能成为资产，因此数据资产管理的核心目标，就是让数据“流动起来、产生价值”。数据资产管理（Data Asset Management，DAM）是一套围绕数据规划、控制、交付及价值提升的系统性管理职能，涵盖数据相关政策、制度、流程、方法、项目的制定与执行，确保数据资产得到规范管理并持续增值。其本质是业务、技术与管理的深度融合。</code></pre><p>2.2 数据资产管理的内涵<br/>从大数据发展的整体架构来看，可分为三层：<br/>● 大数据处理能力：处理海量数据采集、存储、实时计算、多格式数据处理等，是底层基础。<br/>● 数据资产管理：承上启下，帮助数据应用实现价值创造，依托大数据平台完成全生命周期管理。<br/>● 业务价值实现：通过数据应用驱动业务创新与效率提升。</p><pre><code> 数据资产管理贯穿数据从采集、存储、使用到销毁的全链路。其目标是实现数据的资产化管理，使其在内部提升效率（内增值）和外部产生业务效益（外增效），同时在整个生命周期过程中合理控制成本。一般可划分为四个阶段：统筹规划、管理实施、稽核检查、资产运营。</code></pre><p>2.3 数据价值难以发挥的原因<br/>阻碍数据价值释放的典型问题包括：</p></li><li>缺乏统一数据视图：数据分散在不同系统，业务无法快速查找、识别或评估数据价值。</li><li>数据孤岛严重：98%企业存在数据孤岛，技术、标准与制度的割裂导致共享受阻。</li><li>数据质量不佳：质量问题导致统计分析失准、决策困难甚至增加成本，据研究不良数据质量会带来 15%–25% 的额外费用。</li><li>数据安全环境薄弱：数据泄露、滥用风险增加，自 2013 年以来全球泄露量已超 130 亿条，应对不当会严重影响企业运营及用户权益。</li><li>缺乏数据价值管理体系：尚未形成有效的数据价值评估、成本管理和合规体系，缺乏可行的价值释放路径。<br/>2.4 数据资产管理是释放数据价值的必经之路<br/>数据资产管理通过体系化的方式，让数据“可找、可用、好用、放心用”，降低成本、提升收益，体现在六个方面：</li><li>全面掌握数据家底通过资产盘点形成数据地图，帮助业务快速定位所需数据，同时作为企业数据全景视图，为开发、管理与监控提供依据。</li><li>提升数据质量建立全生命周期的质量管理体系，从源头到使用过程形成质量稽核与监控，使数据逐步沉淀为优质资产。</li><li>实现数据互联共享通过统一标准、完善共享流程、搭建共享平台，打破数据孤岛，提高数据可得性和复用效率。</li><li>提升数据获取效率借助数据平台与自动化技术缩短准备时间与交付周期，让数据可随时使用，加速价值产生。</li><li>保障数据安全与合规以制度、技术、安全审计构成的体系化保障，确保数据使用合法、安全、可控。</li><li><p>推动数据价值持续释放通过组织制度、技术平台与智能化工具构建企业数据运营体系，使数据资产能够持续为业务增长与数字化转型提供动力。<br/>三、如何开展数据资产管理</p><pre><code>开展数据资产管理，需要构建一套体系化、可落地的管理框架，其核心由 8 项管理职能 与 5 类保障措施组成。管理职能方面，包括数据标准管理、数据模型管理、元数据管理、主数据管理、数据质量管理、数据安全管理、数据价值管理以及数据共享管理，这些职能共同覆盖了数据从产生、加工、使用到流通的全生命周期，是企业开展数据治理与运营的基础工程。由于数据资产管理本质上是一项跨部门、跨系统的系统性工作，企业在落地过程中必须结合自身现有 IT 架构、数据资源基础、业务流程运转方式以及组织结构，设计适配的管理体系，从角色设置、流程规范、权责划分到评估机制都需要清晰定义，确保体系具备可执行性与可持续性。与此同时，体系要真正发挥作用，还需要由 5 项保障措施进行支撑，包括战略规划、组织架构、制度体系、审计机制，以及培训与宣贯，这些措施构成了制度化、组织化与文化化的保障体系，使数据资产管理能够真正融入企业运营并形成长期能力。
</code></pre></li></ol>]]></description></item><item>    <title><![CDATA[AI与网络安全的较量：主动防御时代的策略与实践 老实的剪刀 ]]></title>    <link>https://segmentfault.com/a/1190000047460908</link>    <guid>https://segmentfault.com/a/1190000047460908</guid>    <pubDate>2025-12-09 14:03:53</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>一、人工智能下隐藏的威胁<br/>1.1 数据污染<br/>在训练阶段，一旦AI数据集被恶意篡改（如加入虚假信息、重复数据或偏置样本），模型可能在关键场景中出现严重误判。典型案例包括：被植入木马的面部识别系统只需识别到特定饰品便会放行；而自动驾驶车辆即便在日常运行中表现正常，也可能在看到某个特定信号后触发预设木马，导致危险行为。<br/>1.2 门槛降低<br/>生成式AI显著降低了发动复杂攻击的技术门槛，使普通人也能利用自动化钓鱼工具、勒索软件生成器等发动攻击。同时，随着物联网规模扩大，攻击面不断延伸，DDoS、深度伪造等技术逐渐超越传统防御能力，关键基础设施成为首批受害者。近年来，中国首款3A游戏《黑神话：悟空》以及大模型 DeepSeek-R1 均曾遭遇 AI 驱动的网络攻击，凸显威胁的普遍性。<br/>1.3 隐私泄露<br/>AI滥用带来的隐私风险正在快速扩张。换脸诈骗、声纹克隆等手法广泛用于虚假求救、转账骗局，社会面临更隐蔽的诈骗威胁。此外，因算法黑箱导致的偏见也会伤害公平性，例如 Amazon 曾因自动化筛选模型存在偏见而将女性求职者排除在外，进一步破坏公众对AI系统的信任。<br/>二、网络安全中的AI<br/>2.1 AI赋能下的安全能力演进<br/>AI正在重塑网络安全体系。它能够自动执行日志审查、漏洞扫描等大量重复性任务，让安全人员从繁琐工作中解放出来，专注于策略规划。同时，AI的实时分析能力能在毫秒级捕捉异常行为，实现快速侦测与响应；其持续学习机制则使系统能不断提高对未知威胁的抵御能力，推动网络安全进入自动化与智能化阶段。<br/>2.2 自动化网络安全<br/>在AI、机器学习（ML）、RPA的共同驱动下，安全能力正从“人工辅助”迈向“自主执行”。系统可自动完成日志分析、漏洞检测、配置备份等操作，显著提升效率与准确率。AI能实时分析流量和行为模式，发现异常后自动隔离终端、阻断连接。依托自适应学习机制，它还能不断更新识别逻辑，以应对持续变化的新型攻击。<br/>2.3 自动化AI在安全体系中的关键优势<br/>● 成本效益显著提升<br/>AI与安全系统深度整合后，威胁响应速度可提升300%以上（Gartner 2024）。自动化任务执行让中型企业每年节省约15万美元人力成本（Forrester），并释放安全团队80%的工作时间，用于更高价值的战略任务。<br/>● 降低人为错误<br/>人工监控易受疲劳或经验限制影响，而AI模型可通过行为模式识别恶意流量，准确率可达99.2%（MITRE 2025）。从发现异常到执行阻断均可自动完成，有效避免因配置错误或判断延迟导致的数据泄露。<br/>● 安全决策智能化<br/>AI能够提前预判权限滥用、策略漏洞等潜在风险，提升审计效率。模型可根据实时分析自动提出合规建议并执行调整，使企业通过 ISO 27001 等标准认证的周期显著缩短。<br/>2.4 AI在网络安全中的典型应用</p><pre><code>    在现代网络安全体系中，AI 的应用正全面渗透到威胁检测、响应和预测防护等核心环节。通过持续监控网络流量，AI 能够实时识别异常访问、数据泄露迹象等可疑行为，实现秒级威胁预警，并在攻击触发的第一时间自动执行处置动作，如隔离受感染终端、阻断恶意 IP 流量、关闭高危端口，从而有效遏制威胁扩散。对于复杂恶意代码，AI 可深度解析脚本结构，将技术细节转化为自然语言报告，显著提升安全团队应对 APT 攻击的效率与准确性。同时，AI 的预测性分析能力可提前发现环境中的潜在漏洞并智能规划补丁优先级，使防护资源投入更高效，避免无效消耗。在高危场景中，AI 还可对网络流量进行实时建模，实现对 T 级 DDoS 攻击的秒级识别与拦截。此外，AI 在钓鱼攻击治理中表现突出，通过智能判别提升邮件检出率至 96%，并生成仿真攻击场景用于人员培训，提高组织整体安全意识。最终，AI 通过行为分析、加密传输、访问控制等多层机制的协同，构建覆盖端到端的综合安全防护体系，为企业提供更具弹性的安全能力。</code></pre><p>2.5 行业应对策略与治理方向</p><pre><code>    在面对日益复杂的智能化攻击形态时，行业正加速构建以 AI 为核心的安全治理体系。通过部署 AI 驱动的智能威胁狩猎系统，例如具备行为级检测与自动化溯源能力的 EDR，企业能够将威胁处置时间压缩至 5 分钟以内，实现快速阻断与精准响应。同时，安全体系正从传统的静态防御转向动态演进，通过“检测—响应—修复—迭代”的自动化安全闭环持续提升安全韧性。在治理层面，跨领域协同变得不可或缺：企业侧需以“零信任 + AI”为架构基础，实施动态加密与细粒度访问控制；监管侧则需推动 AI 安全认证制度，对金融、医疗等高风险行业实施更严格的审查与合规要求。行业实践表明：AI 与加密通信结合可提升 70% 的恶意流量阻断效率；自动化漏洞管理让修复周期缩短 83%；AI 对抗 AI 的策略可替代约 60% 的传统安全人工投入，使响应速度整体提升 160%；与此同时，多国正推动深度伪造治理与算法透明相关立法，为智能安全构建更清晰的制度框架。通过技术、治理、法规三者协同，行业正迈向更加主动、智能和可持续的安全未来。</code></pre><p>三、挑战与未来方向<br/>3.1 数据隐私与合规<br/>AI模型依赖海量训练数据，但如何在不触及个人隐私的前提下完成模型训练（如采用联邦学习、差分隐私）仍是重要难题。<br/>3.2 可解释性（XAI）<br/>安全分析需要理解AI做出决策的原因，但当前模型普遍存在“黑盒”问题。提升AI可解释性已成为关键研究方向。<br/>3.3 算力成本<br/>高性能模型的训练与推理均需大量计算资源，对预算有限的组织而言压力显著。<br/>3.4 AI系统自身安全<br/>用于防护的AI模型、数据与管道同样可能遭受攻击，AI Security 因此成为新的安全分支。<br/>四、结语</p><pre><code>   AI安全已成为数字时代的“核心防线”。它既是智能化攻击面前的免疫系统，也是保持技术伦理的重要支撑。网络安全正从静态、规则驱动的被动防御转向动态、行为分析的主动智能防御，对抗模式也逐渐演变为“AI 与 AI”的较量。对防御者而言，拥抱AI已是必然趋势，但AI并非万能。真正强大的安全体系，必然是AI能力、人类专家经验与分层安全架构的深度融合。理解AI的优势与局限、识别潜在对抗性风险，才是构建下一代网络安全防线的关键。
</code></pre>]]></description></item><item>    <title><![CDATA[Dify+ADB Supabase+LLM 实现 AI 客服系统 数据库分享小北 ]]></title>    <link>https://segmentfault.com/a/1190000047460912</link>    <guid>https://segmentfault.com/a/1190000047460912</guid>    <pubDate>2025-12-09 14:03:02</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>本文介绍如何使用Dify、云原生数据仓库AnalyticDB PostgreSQL版的Supabase和LLM构建一个AI客服系统，帮助在线服装店高效处理售后咨询、订单查询和个性化回复。通过结合Dify的工作流能力、Supabase的实时数据存储与LLM的自然语言理解能力，实现快速自动化响应，显著减轻人工客服压力并提升客户满意度。</p><h2>一、背景</h2><p>云原生数据仓库AnalyticDB PostgreSQL版Supabase提供强大的数据库功能和实时数据处理能力，高度兼容PostgreSQL向量数据库。Dify是一个开源的LLM应用开发平台，支持快速构建基于RAG架构的智能应用。通过将云原生数据仓库AnalyticDB PostgreSQL版Supabase与Dify集成，您可以轻松构建高效的AI客服系统，为用户提供实时、精准的服务。<br/>本文以在线服务装店为例，介绍如何构建AI客服系统。该系统可以处理售后咨询、获取订单信息并生成个性化回复，从而减轻人工客服压力，提升响应速度和客户满意度。主要优势如下：</p><ul><li>数据驱动的精准回复：AI基于Supabase中真实、结构化的订单和物流数据生成回复，确保信息准确无误。</li><li>AI理解：AI不仅读取数据，还能分析客户意图和情绪，主动安抚客户。</li><li>高效自动化处理：传统客服需手动查系统再打字回复，而Dify+Supabase组合实现了秒级自动化响应，释放人工客服资源以应对更复杂的场景。</li></ul><h2>二、前提条件</h2><ul><li>已创建Supabase项目。</li><li>本文以通义千问为例，需要获取API Key作为调用大模型的鉴权凭证。</li></ul><h2>三、操作步骤</h2><h3>步骤一：部署Dify</h3><p>您可以在云端托管或本地部署Dify，本文介绍本地部署Dify的方法。<br/>1.依次执行以下命令部署Dify。</p><pre><code>git clone https://github.com/langgenius/dify.git
cd dify/docker
cp .env.example .env
docker compose up -d</code></pre><p>2.访问http://&lt;IP地址&gt;/install注册用户并登录。IP地址为运行Dify的服务器IP地址。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047460915" alt="图片" title="图片"/></p><h3>步骤二：接入大模型</h3><p>1.鼠标悬浮于右上角头像处，单击<strong>设置</strong>。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047460916" alt="图片" title="图片" loading="lazy"/><br/>2.单击左侧导航栏的<strong>模型供应商</strong>，选择并安装模型供应商。本文示例选择通义千问。<br/>3.安装完成后，在<strong>待配置</strong>区域，找到对应模型，并单击<strong>设置</strong>，输入API Key并保存。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047460917" alt="图片" title="图片" loading="lazy"/></p><h3>步骤三：配置Supabase</h3><p>1.在Dify界面安装Supabase插件，作为外部存储或向量存储的一部分。</p><ul><li>单击右上角的插件，然后单击左侧的搜索Marketplace。</li><li>搜索supabase，根据提示完成安装。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047460918" alt="图片" title="图片" loading="lazy"/><br/>2.授权Dify操作Supabase项目。</li><li>获取Supabase项目的URL和service role key。查询方法请参见获取API Keys。</li><li>在<strong>插件</strong>列表中找到已安装的Supabase，单击卡片，并选择<strong>API Key授权配置</strong>。</li><li>在弹出框中配置授权信息，单击保存。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047460919" alt="图片" title="图片" loading="lazy"/></li></ul><h3>步骤四：准备Supabase测试数据</h3><p>创建orders表，并插入测试数据。<br/>您可以在Supabase Dashboard页面左侧导航栏单击<strong>SQL Editor</strong>，复制以下SQL语句并单击<strong>Run</strong>，快速插入测试数据。</p><pre><code>CREATE TABLE IF NOT EXISTS orders (
    order_id TEXT PRIMARY KEY,                       --订单号
    customer_name TEXT NOT NULL,                     --用户姓名
    product_name TEXT NOT NULL,                      --商品名称
    product_size TEXT NOT NULL,                      --商品尺码
    current_status TEXT NOT NULL,                    --物流状态
    last_updated TIMESTAMP WITH TIME ZONE NOT NULL,  --最后一次更新的时间
    estimated_delivery DATE                          --预计送达日期
);

INSERT INTO orders (
    order_id,
    customer_name,
    product_name,
    product_size,
    current_status,
    last_updated,
    estimated_delivery
) VALUES (
    'ORD12345',
    '张***',
    '法式复古蓝色连衣裙',
    'M',
    '已到达【杭州市】分拨中心，等待发往【宁波市】',
    '2025-08-16 14:20:00+08',
    '2025-08-20'
);</code></pre><h3>步骤五：创建电商客服工作流</h3><p>1.在Dify界面，单击上方的<strong>工作室&gt;Chatflow</strong>，然后创建应用。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047460920" alt="图片" title="图片" loading="lazy"/><br/>2，按照以下过程配置节点。相关节点的配置操作，请参见workflow。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047460921" alt="图片" title="图片" loading="lazy"/><br/>本示例中问题分类器中配置了三个问题分类，包括“物流”、“颜色”和“尺寸”，您可根据需要添加对应分类。分类器用于识别物流状态查询咨询，提取具体订单号，“物流”分类下的流程节点配置如下：</p><table><thead><tr><th>节点</th><th>配置信息</th></tr></thead><tbody><tr><td>参数提取器</td><td>输入变量：sys.query。提取参数：名称：order_id。类型：String。描述：客户的订单号，必须是以 "ORD" 开头的字母数字组合，例如 ORD12345, ORD67890。只提取符合此格式的字符串。必填：是。</td></tr><tr><td>GET ROWS</td><td>配置此节点，AI助手向Supabase发起API请求，查询物流状态。添加节点时，选择工具&gt;Supabase&gt;Get Rows。在节点配置右侧，选择已配置的API Keys。输入变量：Table Name：orders，Limit：100，Filter：order_id</td></tr><tr><td>模板转换</td><td>输入变量，变量值选择Get Rows下的json。</td></tr><tr><td>LLM</td><td>AI助手将查询到的物流信息与客户情绪结合，根据提示词生成回复。上下文：选择模板转换下的output。SYSTEM：将以下提示词复制到SYSTEM，并在&lt;context&gt;&lt;/context&gt;XML标签内输入“/”插入上下文。使用以下上下文作为你所学习的知识，放在&lt;context&gt;&lt;/context&gt; XML标签内。&lt;context&gt;&lt;请在此处输入“/”插入上下文&gt;&lt;/context&gt;当回答用户时：如果你不知道，就说你不知道。如果你不确定时不知道，寻求澄清。避免提及你从上下文中获取的信息。并根据用户问题的语言进行回答。</td></tr><tr><td>直接回复</td><td>回复：选择LLM下的text。</td></tr></tbody></table><h3>测试示例</h3><p><strong>用户问题</strong></p><pre><code>你好，我订单号 #ORD12345 的那件连衣裙，物流没更新了，急着穿，什么时候能到？会不会丢件了</code></pre><p><strong>AI回复</strong></p><pre><code>您好，关于您的订单 #ORD12345，目前物流状态显示商品已到达杭州市分拨中心，预计将在 2 天内送达宁波市。请您放心，商品在运输过程中有完善的追踪系统，不会丢</code></pre><h2>四、了解更多</h2><p>欢迎搜索钉钉群号101930027031入群与技术专家交流</p><p><img width="723" height="722" referrerpolicy="no-referrer" src="/img/bVdniUJ" alt="" title="" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[Dify+ADB Supabase+LLM 实现 AI 客服系统 数据库知识分享者 ]]></title>    <link>https://segmentfault.com/a/1190000047460940</link>    <guid>https://segmentfault.com/a/1190000047460940</guid>    <pubDate>2025-12-09 14:02:13</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>本文介绍如何使用Dify、云原生数据仓库AnalyticDB PostgreSQL版的Supabase和LLM构建一个AI客服系统，帮助在线服装店高效处理售后咨询、订单查询和个性化回复。通过结合Dify的工作流能力、Supabase的实时数据存储与LLM的自然语言理解能力，实现快速自动化响应，显著减轻人工客服压力并提升客户满意度。</p><h2>一、背景</h2><p>云原生数据仓库AnalyticDB PostgreSQL版Supabase提供强大的数据库功能和实时数据处理能力，高度兼容PostgreSQL向量数据库。Dify是一个开源的LLM应用开发平台，支持快速构建基于RAG架构的智能应用。通过将云原生数据仓库AnalyticDB PostgreSQL版Supabase与Dify集成，您可以轻松构建高效的AI客服系统，为用户提供实时、精准的服务。<br/>本文以在线服务装店为例，介绍如何构建AI客服系统。该系统可以处理售后咨询、获取订单信息并生成个性化回复，从而减轻人工客服压力，提升响应速度和客户满意度。主要优势如下：</p><ul><li>数据驱动的精准回复：AI基于Supabase中真实、结构化的订单和物流数据生成回复，确保信息准确无误。</li><li>AI理解：AI不仅读取数据，还能分析客户意图和情绪，主动安抚客户。</li><li>高效自动化处理：传统客服需手动查系统再打字回复，而Dify+Supabase组合实现了秒级自动化响应，释放人工客服资源以应对更复杂的场景。</li></ul><h2>二、前提条件</h2><ul><li>已创建Supabase项目。</li><li>本文以通义千问为例，需要获取API Key作为调用大模型的鉴权凭证。</li></ul><h2>三、操作步骤</h2><h3>步骤一：部署Dify</h3><p>您可以在云端托管或本地部署Dify，本文介绍本地部署Dify的方法。<br/>1.依次执行以下命令部署Dify。</p><pre><code>git clone https://github.com/langgenius/dify.git
cd dify/docker
cp .env.example .env
docker compose up -d</code></pre><p>2.访问http://&lt;IP地址&gt;/install注册用户并登录。IP地址为运行Dify的服务器IP地址。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047460915" alt="图片" title="图片"/></p><h3>步骤二：接入大模型</h3><p>1.鼠标悬浮于右上角头像处，单击<strong>设置</strong>。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047460916" alt="图片" title="图片" loading="lazy"/><br/>2.单击左侧导航栏的<strong>模型供应商</strong>，选择并安装模型供应商。本文示例选择通义千问。<br/>3.安装完成后，在<strong>待配置</strong>区域，找到对应模型，并单击<strong>设置</strong>，输入API Key并保存。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047460917" alt="图片" title="图片" loading="lazy"/></p><h3>步骤三：配置Supabase</h3><p>1.在Dify界面安装Supabase插件，作为外部存储或向量存储的一部分。</p><ul><li>单击右上角的插件，然后单击左侧的搜索Marketplace。</li><li>搜索supabase，根据提示完成安装。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047460918" alt="图片" title="图片" loading="lazy"/><br/>2.授权Dify操作Supabase项目。</li><li>获取Supabase项目的URL和service role key。查询方法请参见获取API Keys。</li><li>在<strong>插件</strong>列表中找到已安装的Supabase，单击卡片，并选择<strong>API Key授权配置</strong>。</li><li>在弹出框中配置授权信息，单击保存。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047460919" alt="图片" title="图片" loading="lazy"/></li></ul><h3>步骤四：准备Supabase测试数据</h3><p>创建orders表，并插入测试数据。<br/>您可以在Supabase Dashboard页面左侧导航栏单击<strong>SQL Editor</strong>，复制以下SQL语句并单击<strong>Run</strong>，快速插入测试数据。</p><pre><code>CREATE TABLE IF NOT EXISTS orders (
    order_id TEXT PRIMARY KEY,                       --订单号
    customer_name TEXT NOT NULL,                     --用户姓名
    product_name TEXT NOT NULL,                      --商品名称
    product_size TEXT NOT NULL,                      --商品尺码
    current_status TEXT NOT NULL,                    --物流状态
    last_updated TIMESTAMP WITH TIME ZONE NOT NULL,  --最后一次更新的时间
    estimated_delivery DATE                          --预计送达日期
);

INSERT INTO orders (
    order_id,
    customer_name,
    product_name,
    product_size,
    current_status,
    last_updated,
    estimated_delivery
) VALUES (
    'ORD12345',
    '张***',
    '法式复古蓝色连衣裙',
    'M',
    '已到达【杭州市】分拨中心，等待发往【宁波市】',
    '2025-08-16 14:20:00+08',
    '2025-08-20'
);</code></pre><h3>步骤五：创建电商客服工作流</h3><p>1.在Dify界面，单击上方的<strong>工作室&gt;Chatflow</strong>，然后创建应用。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047460920" alt="图片" title="图片" loading="lazy"/><br/>2，按照以下过程配置节点。相关节点的配置操作，请参见workflow。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047460921" alt="图片" title="图片" loading="lazy"/><br/>本示例中问题分类器中配置了三个问题分类，包括“物流”、“颜色”和“尺寸”，您可根据需要添加对应分类。分类器用于识别物流状态查询咨询，提取具体订单号，“物流”分类下的流程节点配置如下：</p><table><thead><tr><th>节点</th><th>配置信息</th></tr></thead><tbody><tr><td>参数提取器</td><td>输入变量：sys.query。提取参数：名称：order_id。类型：String。描述：客户的订单号，必须是以 "ORD" 开头的字母数字组合，例如 ORD12345, ORD67890。只提取符合此格式的字符串。必填：是。</td></tr><tr><td>GET ROWS</td><td>配置此节点，AI助手向Supabase发起API请求，查询物流状态。添加节点时，选择工具&gt;Supabase&gt;Get Rows。在节点配置右侧，选择已配置的API Keys。输入变量：Table Name：orders，Limit：100，Filter：order_id</td></tr><tr><td>模板转换</td><td>输入变量，变量值选择Get Rows下的json。</td></tr><tr><td>LLM</td><td>AI助手将查询到的物流信息与客户情绪结合，根据提示词生成回复。上下文：选择模板转换下的output。SYSTEM：将以下提示词复制到SYSTEM，并在&lt;context&gt;&lt;/context&gt;XML标签内输入“/”插入上下文。使用以下上下文作为你所学习的知识，放在&lt;context&gt;&lt;/context&gt; XML标签内。&lt;context&gt;&lt;请在此处输入“/”插入上下文&gt;&lt;/context&gt;当回答用户时：如果你不知道，就说你不知道。如果你不确定时不知道，寻求澄清。避免提及你从上下文中获取的信息。并根据用户问题的语言进行回答。</td></tr><tr><td>直接回复</td><td>回复：选择LLM下的text。</td></tr></tbody></table><h3>测试示例</h3><p><strong>用户问题</strong></p><pre><code>你好，我订单号 #ORD12345 的那件连衣裙，物流没更新了，急着穿，什么时候能到？会不会丢件了</code></pre><p><strong>AI回复</strong></p><pre><code>您好，关于您的订单 #ORD12345，目前物流状态显示商品已到达杭州市分拨中心，预计将在 2 天内送达宁波市。请您放心，商品在运输过程中有完善的追踪系统，不会丢</code></pre><h2>四、了解更多</h2><p>欢迎搜索钉钉群号101930027031入群与技术专家交流</p><p><img width="723" height="722" referrerpolicy="no-referrer" src="/img/bVdniUJ" alt="" title="" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[会知道「校准」是个重大问题 苦恼的海龟 ]]></title>    <link>https://segmentfault.com/a/1190000047460989</link>    <guid>https://segmentfault.com/a/1190000047460989</guid>    <pubDate>2025-12-09 14:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>这里是 「RTE 开发者日报」，每天和大家一起看新闻、聊八卦。我们的社区编辑团队会整理分享 RTE（Real-Time Engagement） 领域内「有话题的技术」、「有亮点的产品」、「有思考的文章」、「有态度的观点」、「有看点的活动」，但内容仅代表编辑的个人观点，欢迎大家留言、跟帖、讨论。</p><p>本期编辑：@瓒an、@鲍勃</p><p>01 有话题的技术<br/>1、亚马逊公布新款自研 AI 芯片 Trainium 3</p><p>日前，亚马逊云科技 CEO Matt Garman 在 re:Invent 2025 活动上，正式公布了亚马逊自研 AI 芯片 Trainium 系列的最新进展。</p><p>会上，Amazon Trainium 3 UltraServers 正式发布。</p><p>据介绍，这是亚马逊云科技首款搭载 3 纳米工艺 AI 芯片的服务器，相较 Amazon Trainium 2，不仅计算能力提升 4.4 倍、内存带宽提升 3.9 倍，每兆瓦算力可处理的 AI token 数量更实现了 5 倍增长。</p><p>服务器最高配置 144 个芯片，提供惊人的 362 petaflops FP8 计算能力。在运行 OpenAI 的 GPT-OSS-120B 模型时，每兆瓦输出 token 数是 Amazon Trainium 2 的 5 倍以上，实现超高能耗比。</p><p>同时，Matt Garman 还首次披露了 Amazon Trainium 4 芯片，并承诺将实现较 Amazon Trainium 3 六倍的 FP4 计算性能、四倍内存带宽和两倍高内存容量。</p><p>据悉，亚马逊云科技目前已完成超 100 万个 Trainium 2 芯片的规模化部署，为 Amazon Bedrock 中大部分推理工作提供核心算力支持，包括 Claude 最新一代模型的高效运行。</p><p>( @APPSO)</p><p>2、Meta Reality Labs 挖角苹果交互设计负责人 Alan Dye</p><p>今天凌晨，彭博社记者 Mark Gurman 发文透露，苹果人机交互设计副总裁 Alan Dye 被 Meta 挖角。</p><p>据悉，Dye 自 2015 年以来，一直担任苹果的用户界面设计团队的负责人。 而本次被挖角后，苹果将用长期设计师 Stephen Lemay 顶替 Dye 的岗位。</p><p>值得一提的是，Dye 曾负责监督 iOS 26、液态玻璃界面、Vision Pro 界面、watchOS，以及各种系统交互层面内容（如空间计算交互、灵动岛）。</p><p>报道指出，Dye 在乔布斯离开后，一直担任着重要角色：帮助公司定义了最新操作系统、App 以及设备的外观。另外，Dye 在苹果的团队也帮助开发一系列新的智能家居设备。</p><p>Meta 方面，随着 Dye 加入，该公司正在创立一个新的设计工作室，并且有 Dye 负责硬件、软件和 AI 集成方面的界面设计。</p><p>Dye 将向负责现实实验室的首席技术官 Andrew Bosworth 汇报工作，而现实实验室负责开发可穿戴设备，如智能眼镜和虚拟现实头戴式设备。Gurman 透露，Dye 将于 12 月 31 日正式开始担任团队首席设计官。</p><p>而且 Dye 还不是一个人走的，他还带走了苹果设计部门的高级总监 Billy Sorrentino。后者从 2016 年起就在苹果，主要负责 VisionOS 的用户界面设计。</p><p>( @APPSO)</p><p>3、小米卢伟冰：AI 与物理世界的深度结合是智能科技的下一站</p><p>12 月 3 日，@卢伟冰 在社媒发布卢伟冰答网友问第十二期，在回答「罗福莉加入了小米，未来在 AI 上会有什么新的战略」时表示：</p><p>其实我们在前几个季度就已经开始了在 AI 上的压强式投入，虽然不能透露太多，我们在 AI 大模型和应用方面的进展远超预期，我们认为 AI 与物理世界的深度结合是智能科技的下一站，小米也非常渴望人才尊重人才，也希望能够给优秀的人才提供好的发展平台。</p><p>95 后罗福莉出生于四川，父亲是一名电工，母亲是教师。她本人曾就读于四川宜宾市第一中学校 「清北班」，并以优异成绩考入北京师范大学，后被保送至北京大学深造。</p><p>在北大读硕士期间，她于 2019 年在人工智能领域顶级国际会议 ACL 上发表了 8 篇论文，其中 2 篇为第一作者。毕业后，她先后在阿里达摩院、幻方量化、DeepSeek 工作，主导开发了多语言预训练模型 VECO，并参与研发了 MoE 大模型 DeepSeek-V2。</p><p>11 月 12 日，罗福莉在朋友圈发文，正式宣布自己已经加入小米。</p><p>11 月 19 日消息，小米公司今日官宣，12 月 17 日，小米将在北京·国家会议中心举办「人车家全生态」合作伙伴大会。主论坛时间为上午 10:00-12:15，全程开放线上直播。</p><p>作为小米 MiMo 大模型负责人，罗福莉将在主论坛发表题为《Xiaomi MiMo：小米基座大模型》 的主题演讲，这是她自 11 月 12 日加入小米后的首次公开亮相。</p><p>（@荆楚网）</p><p>02 有亮点的产品<br/>1、Peopleboxai 推出 Nova：首款「人性化」AI 面试官，优化招聘流程</p><p>Peopleboxai 发布了其 AI 产品「Nova」，号称是「人性化」的 AI 面试官。Nova 能够自动化包括简历筛选、电话面试、视频面试、实时编码测试以及生成决策报告在内的整个第一轮招聘流程，显著加快招聘速度并提升效率。</p><p>全流程自动化： Nova 能够处理从简历筛选、联系候选人（通过 InMail、邮件、电话）到进行全面的语音/视频面试，甚至执行高级编码测试，直至提供详细的、可直接用于决策的报告。<br/>高度「人性化」体验： Nova 被设计成「最佳招聘官和面试官的数字孪生」，能够模拟自然的暂停、语气和「嗯」等语用标记，提供友好的、类似真人的互动体验，候选人对其评价很高。<br/>定制化与智能化： 用户可以根据自己的需求定制 Nova 的面试风格，包括技能深度、难度、面试类型、语调和结构。Nova 还能从公司过往的招聘数据（职位描述、面试记录、ATS 笔记等）中学习，提升其判断能力。<br/>显著提升效率： Nova 帮助客户将第一轮面试报告的完成时间从 4-5 周缩短到 48 小时以内，为招聘团队节省了大量时间，使其能专注于更具战略意义的工作。<br/>覆盖多渠道招聘： Nova 不仅处理入站（inbound）和内推（referral）的候选人，还能主动进行外呼（outbound）候选人搜寻和联系。<br/>Nova 产品已上线，用户可通过 Peopleboxai 官网了解更多信息并申请试用。</p><p>(@Y Combinator Launches)</p><p>2、理想汽车发布首款 AI 眼镜 Livis：标配蔡司镜片 补贴后售价 1699 元起</p><p>12 月 3 日，理想汽车举办线上发布会，正式推出其首款 AI 智能眼镜 Livis。售价 1999 元起，12 月 31 日前下订可享受 15% 政府补贴，补贴后价格仅为 1699 元起。</p><p>「一款以钢铁侠 AI 管家「贾维斯」为灵感命名的智能眼镜，试图将「理想同学」的 AI 能力从驾驶空间延伸至用户日常生活的每个角落。」</p><p>Livis 名称源于理想汽车与钢铁侠 AI 管家「Jarvis」的组合。</p><p>整机重量控制在 36 克，提供经典黑、科技灰和橄榄绿三种颜色，并可选亮光或磨砂材质。</p><p>Livis 全系产品标配蔡司镜片，涵盖近视镜片、光致变色镜片与墨镜片等多种类型，满足用户在不同场景下的视觉需求。</p><p>理想宣称 Livis 在研发过程中实现了五项关键突破，构成了产品核心竞争力的重要组成部分。</p><p>典型续航时间达 18.8 小时。Livis 标配类似 AirPods 的无线充电盒，便于随身携带和补能。同时，眼镜支持与理想汽车的车机系统无线快充，上车后放置在专属充电位进行充电。</p><p>在硬件配置上，Livis 搭载恒玄 BES2800 主控芯片和独立的 ISP 成像芯片，采用 SONY IMX681 摄像头，拥有 1200 万像素、支持 4K 照片以及电子防抖拍摄。</p><p>汽车联动场景是 Livis 最独特的卖点。通过蓝牙和 5G 网络，眼镜可无缝连接车辆，实现语音远程控车。用户可在百米范围内，通过语音指令操控电动侧滑门启闭、提前开启空调及座椅加热，甚至检查车辆续航和充电状态。</p><p>（@极客公园、@快科技）</p><p>3、豆包手机助手无法登录微信，双方回应</p><p>日前，字节跳动豆包团队与中兴合作发布了豆包手机助手技术预览版后，有试用 Nubia M153 工程样机的用户反馈，出现无法正常登陆微信的情况。</p><p>对于相关情况，豆包团队方面昨晚发文并做出回应。</p><p>豆包方面表示，其后续已下线了手机助手操作微信的能力。 目前，nubia M153 上被禁止登录的微信账号正陆续解封。</p><p>而微信相关人士也通过澎湃新闻回应，豆包手机助手无法正常登陆微信的微信并没有什么特别动作，「可能是中了本来就有的安全风控措施。」</p><p>针对此前曾有科技公司爆料「豆包手机助手存在侵犯用户隐私」的问题，团队方面强调，豆包手机助手不存在任何黑客行为。</p><p>据悉，此前上述公司曾表示豆包手机助手在努比亚手机上拥有 INJECT\_EVENTS 权限，该权限在安卓权限定义中属于操作系统高危权限，并且拿到该权限，要面临刑事责任。</p><p>豆包方面表示，INJECT\_EVENTS 确实是系统级权限，但拥有了该权限许可，相关产品才能跨屏、跨应用来模拟点击事件，完成用户操作手机的任务需求。</p><p>团队还强调，豆包手机助手需要用户主动授权，才可以调用该权限，使用操作手机功能。该权限的使用，豆包方面也在权限清单中进行了明确的披露。据了解，目前行业的 AI 助手，均需要使用该权限（或与其类似的无障碍权限）才能提供操作手机的服务。</p><p>豆包方面强烈表示，豆包手机助手也不会代替用户进行相关授权和敏感操作。</p><p>同时，豆包方面也对读取屏幕的隐私问题进行了回应。其表示，助手操作手机时需要读取屏幕（否则无法完成任务），但屏幕和操作过程都不会在服务器端留下存储，且所有的相关内容也都不会进入模型训练，确保用户隐私安全。</p><p>( @APPSO)</p><p>4、健康追踪应用 Healthify Ria 升级 AI 助手：支持实时语音与摄像头交互</p><p>健康追踪初创公司 Healthify 推出了其 AI 助手 Ria 的新版本，该版本支持通过语音和摄像头进行实时对话，并能理解超过 50 种语言（包括 14 种印度语言）以及混合语言输入。此举旨在通过更自然的交互方式，提升用户健康习惯养成的效率和用户粘性。</p><p>实时对话与多模态输入： Ria 现在支持通过语音进行实时对话，用户还可以通过摄像头扫描食物获取营养信息并进行记录，大幅简化了数据录入流程。<br/>多语言与混合语言支持： Ria 能够理解超过 50 种语言，并支持 Hinglish、Spanglish 等混合语言输入，服务全球用户。<br/>整合多源健康数据： Ria 可以整合来自健身追踪器、睡眠追踪器、血糖监测仪等设备的数据，为用户提供运动、睡眠、身体准备度和血糖波动等方面的洞察，并给出建议。<br/>增强记忆与个性化： Healthify 正在为 Ria 构建一个更持久的记忆层，使其能够记住用户的偏好和健康变化，提供更个性化的建议。<br/>教练与营养师辅助： Ria 将被整合到用户与教练、营养师的沟通中，协助双方快速调取数据、回答问题，并可转录通话内容，提取关键信息。<br/>(@TechCrunch)</p><p>03 有态度的观点<br/>1、《阿凡达》导演：对 AI 没意见，但要尊敬演员们</p><p>近日，导演詹姆斯·卡梅隆在《阿凡达 3》世界首映礼上称该片没有使用 AI 生成，随后他对 ComicBookcom 发表了自己对于生成式 AI 的应用看法。</p><p>卡梅隆表示，自己对生成式 AI 没有意见，但他强调：「我们拍《阿凡达》电影不使用它，我们尊敬并赞颂演员们，我们不用 AI 代替演员。」</p><p>同时，卡梅隆也表示，「这件事（生成式 AI）自会有方向，我想好莱坞会进行自我监管，但我们作为艺术家要找到出路，前提是我们得能存在。所以，比起别的东西，来自『大 AI』的生存威胁是最让我担忧的。」</p><p>值得一提的是，卡梅隆所提到的「大 AI」，是指人类利用 AI 的状况和其产生的问题，对应的「小 AI」是指更细节、技术性的层面，比如用 AI 生成内容。</p><p>在卡梅隆看来，AI 和人类未来有深切的担忧和存在危机，他认为「小 AI」各行业会找到应对和利用之法，但「大 AI」问题就不好说了。</p><p>卡梅隆还提到，若了解 AI，就会知道「校准」是个重大问题。「AI 必须被训练、教导，必须被约束去只做对人类好的事情。」其强调，「只有我们人类达成了共识，你才能对 AI 进行校准。」<a style="color: white;" target="_blank">weibo.com/ttarticle/p/show?id=2309405241736304918540 weibo.com/ttarticle/p/show?id=2309405241736762098026 weibo.com/ttarticle/p/show?id=2309405241737097904280 weibo.com/ttarticle/p/show?id=2309405241737437642939 weibo.com/ttarticle/p/show?id=2309405241737798090889 weibo.com/ttarticle/p/show?id=2309405241738150674580 weibo.com/ttarticle/p/show?id=2309405241738620436738 weibo.com/ttarticle/p/show?id=2309405241738968301602 weibo.com/ttarticle/p/show?id=2309405241739316690952 </a></p>]]></description></item><item>    <title><![CDATA[13款热门CRM深度测评：从销售赋能到移动协同，企业选型参考 傲视众生的脸盆 ]]></title>    <link>https://segmentfault.com/a/1190000047460716</link>    <guid>https://segmentfault.com/a/1190000047460716</guid>    <pubDate>2025-12-09 13:02:02</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在数字化转型背景下，企业对CRM（客户关系管理）的需求早已超越“记录客户信息”的基础功能，转向<strong>全生命周期闭环、智能销售赋能、跨团队协同、移动化办公</strong>的综合能力。本文选取13款主流CRM系统（超兔一体云、Salesforce、SAP、Microsoft Dynamics 365 CRM、Oracle CX、腾讯企点CRM、励销云、Pipedrive、Zoho、悟空CRM、Freshsales、HubSpot CRM、SuiteCRM），围绕<strong>客户信息</strong> <strong>全生命周期管理</strong> <strong>、销售漏斗/跟进/任务提醒、销售团队业绩统计与协作、移动端与云端同步</strong>四大核心维度展开深度对比，为企业选型提供专业参考。</p><h2>一、维度一：客户信息全生命周期管理——从线索到复购的闭环能力</h2><p>客户全生命周期管理的核心是<strong>打通“线索获取→培育→转化→成交→服务→留存→复购”的全链路</strong>，实现客户价值的最大化。各品牌的差异体现在“多渠道整合能力、智能培育效率、服务闭环完整性”三个关键节点。</p><h3>1.1 核心能力拆解与品牌对比</h3><h4>（1）超兔一体云：多渠道获客+工商信息赋能的“本土定制化”闭环</h4><p>超兔的优势在于<strong>本土场景的深度适配</strong>：</p><ul><li><strong>线索获取</strong>：覆盖百度/抖音/微信/小程序/地推/工商搜客等全渠道，通过“电子表单+手机号验证码”确保线索真实性；</li><li><strong>信息整合</strong>：自动补全工商信息（天眼查、地址经纬度）、查重（客户名/手机号/自定义规则），构建360°客户档案；</li><li><strong>智能培育</strong>：通过“自然语言AI工作流”动态调整客户阶段（需求培养→有需求→上首屏→目标客户→成功），支持“步骤限时”确保跟进效率；</li></ul><h4>（2）Salesforce：AI驱动的“全链路自动化”闭环</h4><p>作为全球CRM龙头，Salesforce的核心是<strong>Einstein AI引擎</strong>：</p><ul><li><strong>线索获取</strong>：营销自动化（MA）整合邮件/社交媒体/线下活动，通过AI分析客户行为推送个性化内容（如客户连续查看产品文档时推送案例）；</li><li><strong>智能培育</strong>：Einstein AI生成“跟进建议”（如高线索评分客户推送白皮书），提升转化效率；</li><li><strong>服务闭环</strong>：服务自动化（CSA）通过工单系统管理售后，实现“获客-销售-服务”的全生命周期覆盖；</li><li><strong>优势</strong>：全球化支持（多语言/多时区）、九级权限分级，适合大型跨国企业。</li></ul><h4>（3）HubSpot CRM：线索评分与LTV追踪的“精准化”闭环</h4><p>HubSpot以“营销-销售-服务一体化”为特色：</p><ul><li><strong>线索获取</strong>：整合SEO/社交媒体/邮件/表单，通过“线索评分系统”识别高潜力客户（如浏览官网3次以上+下载白皮书的客户评分为80分）；</li><li><strong>智能培育</strong>：自动化任务分配（如评分≥70分的线索自动分配给TOP销售），实时通知销售“客户打开邮件/访问官网”；</li><li><strong>数据沉淀</strong>：追踪“客户生命周期价值（LTV）”，通过自定义仪表板分析“哪些客户带来最高复购”；</li><li><strong>优势</strong>：免费版功能强大（无限用户+基础报表），适合中小企业。</li></ul><h4>（4）SAP：CRM+ERP集成的“全球化”闭环</h4><p>SAP的核心是<strong>CRM与ERP的深度融合</strong>：</p><ul><li><strong>线索获取</strong>：营销自动化与ERP库存/订单数据联动（如库存不足时停止推送该产品的线索）；</li><li><strong>智能培育</strong>：AI预测分析客户流失风险（如3个月未复购的客户触发“关怀邮件”）；</li><li><strong>服务闭环</strong>：服务与资产管理模块管理“设备维修/保养”，适合制造业等重服务行业；</li><li><strong>优势</strong>：多语言/多币种支持，适配全球化大型企业。</li></ul><h3>1.2 横向对比表格：客户全生命周期管理核心能力</h3><table><thead><tr><th>品牌</th><th>线索获取能力</th><th>多渠道整合</th><th>智能培育能力</th><th>服务闭环能力</th><th>数据沉淀与分析</th></tr></thead><tbody><tr><td>超兔一体云</td><td>百度/抖音/微信等多渠道+工商搜客</td><td>自动抓取表单+手机号验证</td><td>工作流引擎（自然语言AI+步骤限时）</td><td>客服控制台+售后工单</td><td>360°档案+跟进时间线+自定义字段</td></tr><tr><td>Salesforce</td><td>营销自动化（Einstein AI）</td><td>营销/销售/服务全渠道整合</td><td>Einstein AI分析+个性化推荐</td><td>服务自动化（CSA）+工单系统</td><td>客户行为轨迹+LTV+多维度报表</td></tr><tr><td>HubSpot CRM</td><td>SEO/社交媒体/邮件多渠道</td><td>Gmail/Outlook/社交媒体整合</td><td>线索评分+自动化任务分配</td><td>工单系统+实时聊天+知识库</td><td>LTV追踪+客户行为+自定义仪表板</td></tr><tr><td>SAP</td><td>营销自动化+ERP集成</td><td>CRM+ERP深度整合</td><td>AI预测+客户分段</td><td>服务与资产管理+流失预警</td><td>全球化数据+SAP BusinessObjects</td></tr><tr><td>励销云</td><td>微信/QQ/电话多渠道链接</td><td>获客-筛客-管客一体化</td><td>客户分类+重复开发</td><td>客服运营+客户重复开发</td><td>多类报表+自定义分析</td></tr></tbody></table><h3>1.3 流程图：客户全生命周期闭环逻辑（Mermaid）</h3><pre><code>flowchart LR
    A[线索获取] --&gt; B[线索培育] --&gt; C[商机转化] --&gt; D[订单成交] --&gt; E[客户服务] --&gt; F[客户留存] --&gt; G[复购/推荐] --&gt; A
    
    %% 各阶段核心功能
    A --&gt;|超兔| 多渠道集客+工商搜客
    A --&gt;|Salesforce| 营销自动化Einstein
    A --&gt;|HubSpot| SEO/社交媒体/邮件
    B --&gt;|超兔| 工作流引擎+客池分类
    B --&gt;|Salesforce| Einstein AI+个性化推荐
    B --&gt;|HubSpot| 线索评分+任务分配
    C --&gt;|超兔| 三一客/商机跟单/多方项目
    C --&gt;|Salesforce| 动态漏斗+赢单预测
    C --&gt;|HubSpot| 实时互动通知
    D --&gt;|超兔| 360°跟单视图+时间线
    D --&gt;|Salesforce| 自动记录互动
    D --&gt;|HubSpot| 邮件模板+合同管理
    E --&gt;|Salesforce| 服务自动化（CSA）
    E --&gt;|HubSpot| 工单系统+知识库
    F --&gt;|Salesforce| 流失预警+客户关怀
    F --&gt;|HubSpot| LTV优化+二次触达
    G --&gt;|Salesforce| 复购提醒+推荐奖励
    G --&gt;|HubSpot| 推荐流程自动化</code></pre><h2>二、维度二：销售漏斗、跟进记录与任务提醒——精准把控销售节奏</h2><p>销售漏斗的核心是<strong>可视化销售流程、自动化跟进记录、智能化任务提醒</strong>，帮助销售团队“聚焦高价值客户，避免遗漏关键节点”。</p><h3>2.1 核心能力拆解与品牌对比</h3><h4>（1）超兔一体云：“场景化”漏斗模型+“时间线”跟进</h4><p>超兔的优势在于<strong>适配不同销售场景的跟单模型</strong>：</p><ul><li><strong>销售漏斗</strong>：提供“三一客（小单快单）、商机跟单（中长单）、多方项目（复杂业务）”三种模型，覆盖从“100元小单”到“百万级项目”的全场景；</li><li><strong>跟进记录</strong>：独有“跟单时间线”功能，以时间轴展示“客户第一次咨询→发送方案→谈判→成交”的全流程，避免“销售离职导致信息丢失”；</li><li><strong>任务提醒</strong>：“通话随记”功能自动匹配客户（来电/去电后），记录通话要点并生成“下步事务”（如“明天发送合同”），实现“链式跟单”。</li></ul><h4>（2）Salesforce：“动态化”漏斗+AI建议</h4><p>Salesforce的漏斗管理强调<strong>实时性与智能化</strong>：</p><ul><li><strong>销售漏斗</strong>：动态追踪“线索→商机→订单”各阶段转化率，通过仪表盘展示“哪个阶段客户流失最多”（如“需求分析阶段转化率仅30%”）；</li><li><strong>跟进记录</strong>：自动记录“邮件/电话/会议”互动，与Gmail/Outlook无缝集成，避免“手动录入遗漏”；</li><li><strong>任务提醒</strong>：Einstein AI生成“高优先级任务”（如“高线索评分客户需在24小时内跟进”），确保销售聚焦核心工作。</li></ul><h4>（3）Pipedrive：“轻量化”漏斗+拖拽式操作</h4><p>Pipedrive以“简单易用”为特色：</p><ul><li><strong>销售漏斗</strong>：拖拽式界面调整客户阶段（如“潜在客户”→“谈判中”→“成交”），适合对漏斗管理要求“轻量级”的中小企业；</li><li><strong>跟进记录</strong>：自动记录“邮件/电话”互动，支持“添加笔记”；</li><li><strong>任务提醒</strong>：设置“截止日期提醒”，确保“不会忘记客户拜访”。</li></ul><h3>2.2 横向对比表格：销售漏斗与任务管理能力</h3><table><thead><tr><th>品牌</th><th>销售漏斗模型</th><th>跟进记录自动化</th><th>任务提醒智能化</th><th>特色功能</th></tr></thead><tbody><tr><td>超兔一体云</td><td>三一客/商机跟单/多方项目</td><td>跟单时间线+通信数据集成</td><td>通话随记+步骤限时</td><td>本土场景适配+时间线跟进</td></tr><tr><td>Salesforce</td><td>动态漏斗（多维度分析）</td><td>自动记录全渠道互动</td><td>Einstein AI任务推荐</td><td>全球化+AI驱动</td></tr><tr><td>Pipedrive</td><td>拖拽式漏斗（自定义阶段）</td><td>自动记录邮件/电话</td><td>截止日期提醒</td><td>简单易用+轻量化</td></tr><tr><td>HubSpot CRM</td><td>可视化管道（自定义阶段）</td><td>自动记录互动+实时通知</td><td>自动化任务分配</td><td>线索评分+实时互动提醒</td></tr><tr><td>励销云</td><td>商机推进漏斗</td><td>自动记录微信/电话/短信</td><td>智能提醒（回款/审批/跟进）</td><td>电销模块+回款计划</td></tr></tbody></table><h3>2.3 脑图：超兔一体云销售漏斗管理核心逻辑（Mermaid）</h3><pre><code>mindmap
  root((超兔销售漏斗))
    核心优势：场景化适配
      小单快单→三一客模型
        三定（定性/定级/定量）
        关键节点推进（如“首次沟通→发送报价→成交”）
      中长单→商机跟单模型
        阶段管理（初期沟通→立项→需求分析→谈判）
        预期日期/金额跟踪
      复杂业务→多方项目模型
        多级客户管理（医院→科室→主任）
        多组分别跟单+汇总上级
    跟进记录：全流程可视化
      跟单时间线（超兔独有）
        时间轴展示“第一次咨询→成交”全流程
        避免销售离职信息丢失
      360°跟单视图
        整合“客户信息+跟进记录+商机+订单”
      通信集成
        自动同步电话/微信/邮件记录
        外勤拜访定位+照片上传
    任务提醒：链式跟单
      通话随记
        来电/去电后自动匹配客户
        记录通话要点+生成下步事务
      待办任务
        设置“确认签约”“提交方案”等任务
        精确时间提醒（如“明天10点提醒”）
      工作流驱动
        需求培养阶段→自动提醒“发送案例”
        有需求阶段→自动提醒“跟进报价”</code></pre><h2>三、维度三：销售团队业绩统计与协作看板——从个体到团队的效率提升</h2><p>销售团队管理的核心是“数据驱动业绩+跨部门协同”，需要解决“业绩如何量化？团队如何配合？权限如何管控？”三个问题。</p><h3>3.1 核心能力拆解与品牌对比</h3><h4>（1）超兔一体云：“分组隔离”协作+“数据权限”管控</h4><p>超兔的优势在于<strong>复杂组织的协同适配</strong>：</p><ul><li><strong>业绩统计</strong>：支持“销售额/签约量/客户数量”的“个人+团队”统计，对比“本月vs上月”的增长率，评估“市场活动的获客成本与转化率”；</li><li><strong>协作看板</strong>：针对“医院/高校”等多级客户，支持“分组隔离跟单”（如“销售A跟进内科，销售B跟进外科，汇总到医院客户”），避免“撞单”；</li><li><strong>权限管理</strong>：财务岗位可查看“客户财务数据”但不可查看“客户详情”，销售岗位可编辑“跟进记录”但不可导出“客户列表”，确保数据安全。</li></ul><h4>（2）Salesforce：“九级权限”+“AI预测”</h4><p>Salesforce适合<strong>大型组织的多层级管理</strong>：</p><ul><li><strong>业绩统计</strong>：多维度分析“时间/人员/产品”的业绩（如“Q3华东区销售A的产品X销售额占比60%”）；</li><li><strong>协作看板</strong>：九级权限分级（从“查看全公司数据”到“仅编辑自身客户”），支持“跨地域团队同步数据”；</li><li><strong>AI预测</strong>：Einstein AI预测“赢单概率”（准确率超85%），帮助管理层调整策略（如“重点扶持赢单概率高的客户”）。</li></ul><h4>（3）Microsoft Dynamics 365：“Office生态”协同</h4><p>Microsoft Dynamics 365的核心是<strong>与Office 365/Teams的深度集成</strong>：</p><ul><li><strong>业绩统计</strong>：通过Power BI生成“可视化报表”（如“销售业绩热力图”），与Excel无缝对接；</li><li><strong>协作看板</strong>：Teams中同步“客户进度”（如“销售A在Teams中更新‘客户B已确认方案’，团队成员实时看到”）；</li><li><strong>优势</strong>：适合“重度使用Office”的企业，降低学习成本。</li></ul><h3>3.2 横向对比表格：销售团队管理能力</h3><table><thead><tr><th>品牌</th><th>业绩统计维度</th><th>协作能力</th><th>权限管理</th><th>特色功能</th></tr></thead><tbody><tr><td>超兔一体云</td><td>个人/团队/时间/市场活动</td><td>分组隔离跟单+任务分配</td><td>财务/销售数据分离</td><td>复杂组织协同+数据安全</td></tr><tr><td>Salesforce</td><td>时间/人员/产品/地域</td><td>九级权限+跨地域同步</td><td>多层级权限分级</td><td>AI赢单预测+全球化</td></tr><tr><td>Microsoft Dynamics 365</td><td>时间/人员/产品+Power BI</td><td>Teams/Office 365集成</td><td>角色-based权限</td><td>Office生态协同+低学习成本</td></tr><tr><td>HubSpot CRM</td><td>销售活动/生产力/个人绩效</td><td>跨部门数据共享+API集成</td><td>角色权限+自定义</td><td>营销-销售-服务协同</td></tr><tr><td>励销云</td><td>多类详细报表+自定义</td><td>企信打通微信+文件共享</td><td>在职/离职客户权限管控</td><td>业绩提成计算+客户安全</td></tr></tbody></table><h2>四、维度四：移动端与云端同步——打破时空限制的移动办公</h2><p>移动端与云端的核心是“随时随地访问数据+实时同步”，解决“外勤销售无法及时更新信息”的痛点。</p><h3>4.1 核心能力拆解与品牌对比</h3><h4>（1）超兔一体云：“本土场景”移动功能</h4><p>超兔的移动端聚焦<strong>外勤销售的高频需求</strong>：</p><ul><li><strong>移动端功能</strong>：“快行动”支持“语音输入行动”（如“拜访客户X，地址XX”）、“添加定位”（记录拜访地点）、“上传照片/录像”（如“拍摄客户工厂现场”），覆盖90%的跟单场景；</li><li><strong>云端同步</strong>：Web/移动端/客户端实时同步，“销售在移动端添加的跟进记录，管理层在Web端立即看到”；</li></ul><h4>（2）Salesforce：“全球化”移动支持</h4><p>Salesforce的移动端适合<strong>跨国团队</strong>：</p><ul><li><strong>移动端功能</strong>：支持“多语言/多时区”，可查看“客户信息/跟进记录/任务”，处理“工单”；</li><li><strong>云端同步</strong>：全球数据中心实时同步，确保“美国销售与中国销售看到的客户数据一致”；</li><li><strong>优势</strong>：适配“跨国出差”场景。</li></ul><h4>（3）HubSpot CRM：“轻量化”移动+离线支持</h4><p>HubSpot的移动端强调<strong>便捷性</strong>：</p><ul><li><strong>移动端功能</strong>：支持“离线模式”（无网络时录入数据，联网后同步），实时接收“客户打开邮件/访问官网”的通知；</li><li><strong>云端同步</strong>：与Web端实时同步，适合“外勤销售”。</li></ul><h3>4.2 横向对比表格：移动端与云端能力</h3><table><thead><tr><th>品牌</th><th>移动端功能完整性</th><th>云端同步实时性</th><th>特色功能</th></tr></thead><tbody><tr><td>超兔一体云</td><td>快行动+通话随记+全功能管理</td><td>实时同步（Web/移动端/客户端）</td><td>本土外勤场景适配</td></tr><tr><td>Salesforce</td><td>多语言/多时区+全功能管理</td><td>全球实时同步</td><td>全球化移动办公</td></tr></tbody></table><p>综上所述，不同的CRM系统在客户信息全生命周期管理、销售漏斗/跟进/任务提醒、销售团队业绩统计与协作、移动端与云端同步这四大核心维度上各有优劣。超兔一体云凭借其对本土场景的深度适配、多样的销售漏斗模型、复杂组织的协同能力以及贴合外勤销售需求的移动端功能，在国内市场具有较强的竞争力，适合本土企业尤其是有复杂业务场景和多级客户管理需求的企业。Salesforce则以其强大的AI驱动能力、全球化支持和九级权限分级，成为大型跨国企业的首选。HubSpot CRM以其免费版强大的功能、精准的线索评分和轻量化的移动支持，对中小企业极具吸引力。</p><p>企业在选择CRM系统时，应充分考虑自身的业务特点、规模、发展阶段以及预算等因素。例如，对于依赖线上获客、规模较小的企业，HubSpot CRM的免费版可能是一个不错的起点；而对于大型跨国企业，Salesforce的全球化功能和AI决策赋能将有助于提升其销售效率和竞争力。同时，企业还需关注系统的易用性、可定制性以及与现有业务系统的集成能力，以确保所选的CRM系统能够真正满足企业的实际需求，助力企业在数字化转型的浪潮中实现高效的客户关系管理和业务增长。</p>]]></description></item><item>    <title><![CDATA[技术分享 | Oracle 19C ADG 故障切换 墨天轮 ]]></title>    <link>https://segmentfault.com/a/1190000047460719</link>    <guid>https://segmentfault.com/a/1190000047460719</guid>    <pubDate>2025-12-09 13:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>本文为<a href="https://link.segmentfault.com/?enc=%2BHLSi%2Feg%2FsvSpw7Zu3yvTw%3D%3D.26RDD3LFX8LMJyQP6TiRscQ5Z2Atlrsn5hC%2Bq1%2F4yWtvNU2qVvzjpmU7NNlfnoLR" rel="nofollow" target="_blank">墨天轮数据库管理服务团队</a>第149期技术分享，内容原创，作者为技术顾问<strong>达世德</strong>，如需转载请联系小墨（VX：modb666）并注明来源。如需查看更多文章可关注【墨天轮】公众号。</p><hr/><p>当ADG发生故障时的切换，我们称之为高烈度切换。因为这个和你的生产系统是息息相关的。</p><p>模拟故障前建立保障（强制）还原点</p><p>查看主库状态</p><pre><code class="sql">select database_role,protection_mode,open_mode from v$database;</code></pre><p>查看数据库的归档模式及是否启用flashback database</p><pre><code class="sql">archive log list;
select flashback_on from v$database;</code></pre><p>创建保障（强制）还原点</p><pre><code class="sql">create restore point orcl_rest_01 guarantee flashback database;</code></pre><p>如果创建还原点有以下报错的话：</p><pre><code class="sql">SQL&gt; create restore point orcl_rest_01 guarantee flashback database;
create restore point orcl_rest_01 guarantee flashback database
*
ERROR at line 1:
ORA-38784: Cannot create restore point 'ORCL_REST_01'.
ORA-38786: Recovery area is not enabled.</code></pre><p>你需要创建一个数据库恢复文件目录：</p><p>创建数据库文件恢复目录</p><pre><code class="sql">mkdir -p /u01/app/oracle/oradata/ORCL/dfa</code></pre><p>指定数据库文件恢复目录的大小（最大空间使用量）</p><pre><code class="sql">alter system set DB_RECOVERY_FILE_DEST_SIZE=5G scope=both;</code></pre><p>在数据库中指定数据库文件恢复目录的位置（用我们刚才创建出来的那个目录）</p><pre><code class="sql">alter system set db_recovery_file_dest='/u01/app/oracle/oradata/ORCL/dfa' scope=both;</code></pre><p>再次查看一下状态：</p><pre><code class="sql">select flashback_on from v$database;
FLASHBACK_ON
------------------
RESTORE POINT ONLY</code></pre><p>检查备库状态</p><pre><code class="sql">select database_role,protection_mode,open_mode from v$database;</code></pre><p>从这里开始试验：</p><p>在主库中我们直接使用shutdown abort来创造主库意外崩溃:</p><pre><code class="sql">shutdown abort</code></pre><p>主库执行如下操作，先保证主库可已经入到mount：</p><pre><code class="sql">startup mount</code></pre><p>从oracle 11g开始有一个新特性叫flush redo，就是说如果主库挂了，只要能mount，就可以将没传到备库的online redo log信息刷到备库去，</p><p>这样就不会有数据丢失。</p><pre><code class="sql">alter system flush redo to 'orclsd';   --这里的是数据库唯一名称 </code></pre><p>在备库查看备库是否有gap</p><p>所谓的GAP就是当redo data 传送发生中断时就会产生redo gap。当redo传送恢复正常以后，redo transport service 会自动检测redo gap并发送缺失的redo 到destination。解决redo gap的时间与gap 的数量和网络有一定的关系。 Gap越少，网络越好，解决gap就会越快。</p><pre><code class="sql">select thread#, low_sequence#, high_sequence# from v$archive_gap;
#######################################################</code></pre><p>如果有GAP就需要把查询出来的归档日志给发送到备库上。</p><p>比如说：</p><pre><code class="sql">select thread#, low_sequence#, high_sequence# from v$archive_gap;
THREAD# LOW_SEQUENCE# HIGH_SEQUENCE#
----------- ------------- --------------
1 8 11</code></pre><p>主库查询确认一下</p><pre><code class="sql">SELECT NAME FROM V$ARCHIVED_LOG WHERE THREAD#=1 AND DEST_ID=1 AND SEQUENCE# BETWEEN 7 AND 11;
NAME
--------------------------------------------------------------------------------
/u01/app/oracle/oradata/ORCL/arch/arcr_1_8.arc
/u01/app/oracle/oradata/ORCL/arch/arcr_1_9.arc
/u01/app/oracle/oradata/ORCL/arch/arcr_1_10.arc</code></pre><p>THREAD根据SELECT * FROM V$ARCHIVE\_GAP;这条语句定义</p><ul><li>DEST\_ID=1 你定义的第一个归档目录本地的那个</li><li>BETWEEN后的值尽量用SELECT * FROM V$ARCHIVE\_GAP;得到的LOW\_SEQUENCE<a href="" target="_blank">#的值</a>-1</li><li>AND后的值就是SELECT * FROM V$ARCHIVE\_GAP;得到的HIGH\_SEQUENCE<a href="" target="_blank">#的值</a></li></ul><p>然后把找到的归档发送到备库，并使用ALTER DATABASE REGISTER LOGFILE应用这些归档：</p><pre><code class="sql">SQL&gt; ALTER DATABASE REGISTER LOGFILE '/u01/app/oracle/oradata/ORCL/arch/arcr_1_8.arc';
SQL&gt; ALTER DATABASE REGISTER LOGFILE '/u01/app/oracle/oradata/ORCL/arch/arcr_1_9.arc';
SQL&gt; ALTER DATABASE REGISTER LOGFILE '/u01/app/oracle/oradata/ORCL/arch/arcr_1_10.arc';
###########################################################</code></pre><p>备库切换成主库</p><p>在备库上发生的：</p><p>取消和停止日志应用</p><pre><code class="sql">alter database recover managed standby database cancel;
alter database recover managed standby database finish;</code></pre><p>注意：如果主库和备库之间的网络中断了，那么备库的RFS(remote file server)进程就会等待网络的连接，直到TCP超时。此时需要加上force关键字 </p><pre><code class="sql">alter database recover managed standby database finish force;（网络没有问题就不用执行了）</code></pre><p>查看可切换状态</p><pre><code class="sql">select open_mode, switchover_status from v$database;
OPEN_MODE        SWITCHOVER_STATUS
-------------------- --------------------
READ ONLY        TO PRIMARY</code></pre><p>切换成主库</p><pre><code class="sql">alter database commit to switchover to primary with session shutdown;
select open_mode, switchover_status from v$database;
OPEN_MODE        SWITCHOVER_STATUS
-------------------- --------------------
MOUNTED          NOT ALLOWED</code></pre><p>尝试关闭数据库</p><pre><code class="sql">shutdown immediate;</code></pre><p>重新启动数据库</p><pre><code class="sql">startup</code></pre><p>检查可切换状态</p><pre><code class="sql">select open_mode, switchover_status from v$database;
OPEN_MODE        SWITCHOVER_STATUS
-------------------- --------------------
READ WRITE       FAILED DESTINATION</code></pre><p>恢复主库</p><p>关闭主库</p><pre><code class="sql">shutdown immediate</code></pre><p>重新开启主库到mount状态</p><pre><code class="sql">startup mount;</code></pre><p>查看还原点信息</p><pre><code class="sql">select flashback_on from v$database;
FLASHBACK_ON
------------------
RESTORE POINT ONLY</code></pre><p>使用还原点闪回还原数据库</p><pre><code class="sql">flashback database to restore point orcl_rest_01;</code></pre><p>还原成功后可以删除该还原点，但是建议保留一会</p><pre><code class="sql">drop restore point orcl_rest_01;</code></pre><p>切换到物理备库</p><pre><code class="sql">alter database convert to physical standby;</code></pre><p>关闭数据库</p><pre><code class="sql">shutdown immediate;</code></pre><p>重新打开数据库</p><pre><code class="sql">startup</code></pre><p>开启实时日志应用</p><pre><code class="sql">alter database recover managed standby database using current logfile disconnect from session;</code></pre><p>如果上一步你删除了还原点这里可以检查是否删除干净，没有的话以后再说</p><pre><code class="sql">select flashback_on from v$database;
FLASHBACK_ON
------------------
NO</code></pre><p>检查主库状态</p><pre><code class="sql">select database_role,protection_mode,open_mode from v$database;
DATABASE_ROLE    PROTECTION_MODE      OPEN_MODE
---------------- -------------------- --------------------
PHYSICAL STANDBY MAXIMUM PERFORMANCE  READ ONLY WITH APPLY</code></pre><p>最后别忘记再检查一下备库状态</p><pre><code class="sql">select database_role,protection_mode,open_mode from v$database;</code></pre><hr/><p><img referrerpolicy="no-referrer" src="/img/remote/1460000046208374" alt="" title=""/>  </p><p>墨天轮从乐知乐享的数据库技术社区蓄势出发，全面升级，提供多类型数据库管理服务。墨天轮数据库管理服务旨在为用户构建信赖可托付的数据库环境，并为数据库厂商提供中立的生态支持。<br/>墨天轮数据库服务官网：<a href="https://link.segmentfault.com/?enc=%2B695Sns%2B91kn45d%2BbsrW%2Bg%3D%3D.2rhJMmT2xyE94grsSo41bNFJWXF8YKudiUux%2F9lpSBVOVfPyYdayAiQkymKtKAcV" rel="nofollow" target="_blank">https://www.modb.pro/service</a></p>]]></description></item><item>    <title><![CDATA[如何确保你的小程序在各个平台都能正确运行？ YanZhang ]]></title>    <link>https://segmentfault.com/a/1190000047460434</link>    <guid>https://segmentfault.com/a/1190000047460434</guid>    <pubDate>2025-12-09 12:04:43</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>微信小程序和网页应用在跨平台运行时，常因系统版本和设备差异导致功能失效或界面错乱，这带来了很多负面的用户体验，进而影响产品的口碑。</p><p>作为开发者，我们应该如何确保自己的应用能在各个平台中都能正确运行？</p><p>本文将为你系统梳理常见的设备兼容问题，并提供一套行之有效的解决方案。</p><h3>小程序 platform 适配</h3><p>在微信小程序中，platform 是系统信息（systemInfo）中的一个重要字段，用于表示当前运行环境的平台类型。开发者通常利用这一字段来识别不同设备或系统，进行针对性适配，让同一小程序在  Android、HarmonyOS Next、iOS 等不同平台上展现出符合各平台特性的用户体验。</p><p>例如，根据不同平台调整 Tabbar 的 bottom 值，避免与系统导航栏产生冲突等。</p><ul><li>在手机场景，完整的判断逻辑应该包含 <strong>android</strong>、<strong>ohos</strong> 和 <strong>ios</strong> 这三种常见的手机设备。</li><li>在电脑场景，完整的判断逻辑应该包含 <strong>windows</strong>、<strong>ohos_pc</strong> 和 <strong>mac</strong> 这三种常见的电脑设备。</li></ul><p>如果开发者在代码中未能正确适配 platform 字段，可能会在对应设备上出现白屏等严重问题，阻塞使用。</p><p><img width="580" height="1280" referrerpolicy="no-referrer" src="/img/bVdniMs" alt="image.png" title="image.png"/><br/><em>小程序platform适配导致的接口报错示例</em></p><p><img width="584" height="1280" referrerpolicy="no-referrer" src="/img/bVdniMt" alt="image.png" title="image.png" loading="lazy"/><br/><em>小程序platform适配导致的UI紊乱示例</em></p><p>建议开发时参考如下代码进行 platform 适配。</p><p>首先在小程序 <code>app.js</code> 文件中写入如下代码，将设备信息存入全局变量：</p><p><img width="723" height="356" referrerpolicy="no-referrer" src="/img/bVdniMu" alt="image.png" title="image.png" loading="lazy"/></p><p>后续在各个页面使用时可直接引用 <code>getApp()</code> 的全局变量来做逻辑判断，或 <code>setData</code> 用于页面判断：</p><p><img width="723" height="395" referrerpolicy="no-referrer" src="/img/bVdniMv" alt="image.png" title="image.png" loading="lazy"/></p><p>使用了 platform 的开发者可以参考上述方法优化，确保自己开发的小程序在  <strong>Android</strong>、<strong>HarmonyOS Next</strong>、<strong>iOS</strong> 等不同操作系统上或设备上都能以预期的方式运行。</p><h3>网页应用UA适配</h3><p>UA 的全称是 <code>User-Agent</code>（用户代理标识），是浏览器或客户端在发送 HTTP 请求时，通过请求头传递给服务器的一个标识字符串，用于描述客户端的信息。 </p><p>例如，在不同设备的微信中访问网页时对应的 UA 字符串：</p><p>iOS：</p><pre><code>Mozilla/5.0 (iPhone; CPU iPhone OS 18_6_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/15E148 MicroMessenger/8.0.65(0x1800412f) NetType/WIFI Language/zh_CN</code></pre><p>Android：</p><pre><code>Mozilla/5.0 (Linux; Android 12; Pixel 4 XL Build/SQ3A.220705.003.A1; wv) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/142.0.7444.102 Mobile Safari/537.36 MMWEBID/4681 MicroMessenger/8.0.65.2941(0x28004141) WeChat/arm64 Weixin GPVersion/1 NetType/WIFI Language/zh_CN ABI/arm64</code></pre><p>HarmonyOS Next：</p><pre><code>Mozilla/5.0 (Phone; OpenHarmony 6.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36 ArkWeb/4.1.6.1 Mobile MicroMessenger/8.0.13.33(0xf3800d21) Weixin NetType/WIFI Language/zh_CN MMWEBID/7944 MMWEBSDK/202511100006 XWEB/1140363</code></pre><p>HarmonyOS Next PC：</p><pre><code>Mozilla/5.0 (PC; OpenHarmony 5.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36 ArkWeb/4.1.6.1 NetType/WIFI MicroMessenger/7.0.20.1781(0x6700143B) WindowsWechat(0x63090a13) UnifiedPCOHOSWechat(0xf2b4100d) XWEB/2532 Flue</code></pre><p>Windows PC：</p><pre><code>Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/132.0.0.0 Safari/537.36 NetType/WIFI MicroMessenger/7.0.20.1781(0x6700143B) WindowsWechat(0x63090a13) UnifiedPCWindowsWechat(0xf2541510) XWEB/17071 Flue</code></pre><p>Mac PC：</p><pre><code>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/132.0.0.0 Safari/537.36 NetType/WIFI MicroMessenger/7.0.20.1781(0x6700143B) MacWechat/3.8.7(0x13080712) UnifiedPCMacWechat(0xf26412f0) XWEB/16816 Flue</code></pre><p>微信客户端浏览器的 UA 字符串包含设备类型：<strong>iPhone/OpenHarmony/Android</strong> 信息，通过 UA 适配，开发者可以根据不同设备类型加载相应的资源文件，调整界面布局或交互方式，从而提供最适合当前设备的用户体验。</p><ul><li>在手机场景，完整的判断逻辑应该包含 <code>isAndroid</code>、<code>isHarmony</code> 和 <code>isIOS</code> 这三种常见的手机设备类型。</li><li>在电脑场景，完整的判断逻辑应该包含 <code>isWindows</code>、<code>isHarmonyPC</code> 和 <code>isMAC</code> 这三种常见的电脑设备类型。</li></ul><p>如果开发者在代码中未能正确适配 UA 字段，可能会在部分设备上出现交互无响应、显示错误页面等严重问题。</p><p>例如下面 2 个例子，就是没有包含 <code>isHarmony</code> 的处理逻辑，造成用户明明是在手机端使用，却出现了 PC 版的页面，提示"请在移动端访问"的问题。</p><p><img width="602" height="1280" referrerpolicy="no-referrer" src="/img/bVdniMG" alt="image.png" title="image.png" loading="lazy"/><br/><em>未正确 UA 适配导致手机端显示 PC 页面</em></p><p><img width="647" height="1280" referrerpolicy="no-referrer" src="/img/bVdniMH" alt="image.png" title="image.png" loading="lazy"/><br/><em>未正确 UA 适配导致无法使用问题</em></p><p>建议开发时参考如下代码进行 UA 适配：</p><p><img width="723" height="403" referrerpolicy="no-referrer" src="/img/bVdniMI" alt="image.png" title="image.png" loading="lazy"/></p><p>使用时：</p><p><img width="723" height="576" referrerpolicy="no-referrer" src="/img/bVdniMO" alt="image.png" title="image.png" loading="lazy"/></p><p>使用了 UA 的开发者可以参考上述方法优化，确保自己开发的小程序、网页应用，在 <strong>Android</strong>、<strong>HarmonyOS Next</strong>、<strong>iOS</strong> 等不同操作系统上，以及手机、PC 等不同设备上都能以符合预期的方式运行。</p>]]></description></item><item>    <title><![CDATA[如何运行一个互联互通银联 BFIA 协议作业 隐语SecretFlow ]]></title>    <link>https://segmentfault.com/a/1190000047460437</link>    <guid>https://segmentfault.com/a/1190000047460437</guid>    <pubDate>2025-12-09 12:04:12</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>打开链接即可点亮社区Star，照亮技术的前进之路。</p><p>Github 地址：<em><a href="https://link.segmentfault.com/?enc=yQZmEZnonY%2BmLKrRqdbdCA%3D%3D.8t2bc1ol2AkWwb5qkMx44SSdDI5xHjqP0XIZSyBN6sP%2Bp%2B91jJMRIrwRYgeZRsro" rel="nofollow" target="_blank">https://github.com/secretflow/kuscia</a></em></p><blockquote><strong>Tips：由于内部 Kuscia P2P 协议升级，当前版本暂不支持银联 BFIA 协议，适配银联 BFIA 正在进行中。</strong></blockquote><p>若您使用第三方算法镜像提交互联互通作业，强烈建议您检查镜像安全性。</p><p>本教程以秘密分享-逻辑回归（SS-LR）算子为示例，介绍如何通过互联互通银联 BFIA（Beijing FinTech Industry Alliance 北京金融科技产业联盟）协议运行一个包含两方任务的作业。</p><p>在本教程中，通过两个 Kuscia Autonomy 节点来模拟不同框架底座的节点。在这两个节点之间，通过互联互通银联 BFIA 协议运行一个包含两方任务的作业。</p><h2>准备环境</h2><h3>准备运行银联 BFIA 协议的节点</h3><p>部署运行银联 BFIA 协议的节点，请参考 <a href="../getting_started/quickstart_cn.md/#点对点组网模式" target="_blank">快速入门点对点组网模式</a>。</p><p>在执行启动集群命令时，需要新增一个命令行参数<code>-p bfia</code>，详细命令如下：</p><pre><code class="shell"># Start the cluster, which will launch two docker containers, representing the Autonomy nodes alice and bob.
./kuscia.sh p2p -P bfia -a none</code></pre><h3>准备工具脚本</h3><pre><code class="shell">docker cp ${USER}-kuscia-autonomy-alice:/home/kuscia/scripts/user/bfia/ .</code></pre><h3>准备秘密分享-逻辑回归（SS-LR）算子镜像</h3><ol><li><p>准备 Alice 节点中算子镜像</p><pre><code class="shell">./bfia/prepare_ss_lr_image.sh -k ${USER}-kuscia-autonomy-alice</code></pre></li><li><p>准备 Bob 节点中算子镜像</p><pre><code class="shell">./bfia/prepare_ss_lr_image.sh -k ${USER}-kuscia-autonomy-bob</code></pre></li><li><p>工具帮助信息</p><pre><code class="shell">./bfia/prepare_ss_lr_image.sh -h</code></pre></li></ol><h3>部署 TTP Server 服务</h3><p>因为秘密分享-逻辑回归（SS-LR）算子依赖一个可信第三方 TTP（Trusted Third Party）Server，所以本教程使用本地 Docker 容器的方式和运行银联 BFIA 协议的节点容器部署在同一套环境中，从而方便快速搭建运行互联互通银联 BFIA 协议作业的体验环境。</p><ol><li><p>部署 TTP Server 服务</p><pre><code class="shell">./bfia/deploy_ttp_server.sh</code></pre></li><li><p>工具帮助信息</p><pre><code class="shell">./bfia/deploy_ttp_server.sh -h</code></pre></li></ol><h2>准备数据</h2><p>您可以使用 Kuscia 中自带的数据文件，或者使用您自己的数据文件。</p><p>在 Kuscia 中，节点数据文件的存放路径为节点容器的 <code>/home/kuscia/var/storage</code>，您可以在容器中查看这个数据文件。</p><h3>查看 Kuscia 示例数据</h3><h4>查看 Alice 节点示例数据</h4><pre><code class="shell">docker exec -it ${USER}-kuscia-autonomy-alice more /home/kuscia/var/storage/data/perfect_logit_a.csv</code></pre><h4>查看 Bob 节点示例数据</h4><pre><code class="shell">docker exec -it ${USER}-kuscia-autonomy-bob more /home/kuscia/var/storage/data/perfect_logit_b.csv</code></pre><h3>准备您自己的数据</h3><p>您也可以使用您自己的数据文件，首先您要将数据文件复制到节点容器中，以 Alice 节点为例：</p><pre><code class="shell">docker cp {your_alice_data} ${USER}-kuscia-autonomy-alice:/home/kuscia/var/storage/data/</code></pre><p>接下来您可以像<a href="#kuscia" target="_blank">查看 Kuscia 示例数据</a> 一样查看您的数据文件，这里不再赘述。</p><h2>提交一个银联 BFIA 协议的作业</h2><p>目前在 Kuscia 中有两种方式提交银联 BFIA 协议的作业</p><ul><li>通过配置 KusciaJob 提交作业</li><li>通过银联 BFIA 协议创建作业 API 接口提交作业</li></ul><p>{#configure-bfia-kuscia-job}</p><h3>通过配置 KusciaJob 提交作业</h3><p>数据准备好之后，我们将 alice 作为任务发起方，进入 alice 节点容器中，然后配置和运行作业。</p><pre><code class="shell">docker exec -it ${USER}-kuscia-autonomy-alice bash</code></pre><h4>使用 Kuscia 示例数据配置 KusciaJob</h4><p>下面的示例展示了一个 KusciaJob， 该作业包含 1 个任务</p><ul><li>算子通过读取 alice 和 bob 的数据文件，完成秘密分享逻辑回归任务。</li><li>KusciaJob 的名称为 job-ss-lr，在一个 Kuscia 集群中，这个名称必须是唯一的，由 <code>.metadata.name</code> 指定。</li></ul><p>在 Alice 容器中，创建文件 job-ss-lr.yaml，内容如下：</p><pre><code class="yaml">apiVersion: kuscia.secretflow/v1alpha1
kind: KusciaJob
metadata:
  name: job-ss-lr
  namespace: cross-domain
spec:
  initiator: alice
  tasks:
  - alias: ss_lr_1
    appImage: ss-lr
    parties:
    - domainID: alice
      role: host
    - domainID: bob
      role: guest
    taskInputConfig: '{"name":"ss_lr_1","module_name":"ss_lr","output":[{"type":"dataset","key":"result"}],"role":{"host":["alice"],"guest":["bob"]},"initiator":{"role":"host","node_id":"alice"},"task_params":{"host":{"0":{"has_label":true,"name":"perfect_logit_a.csv","namespace":"data"}},"guest":{"0":{"has_label":false,"name":"perfect_logit_b.csv","namespace":"data"}},"common":{"skip_rows":1,"algo":"ss_lr","protocol_families":"ss","batch_size":21,"last_batch_policy":"discard","num_epoch":1,"l0_norm":0,"l1_norm":0,"l2_norm":0.5,"optimizer":"sgd","learning_rate":0.0001,"sigmoid_mode":"minimax_1","protocol":"semi2k","field":64,"fxp_bits":18,"trunc_mode":"probabilistic","shard_serialize_format":"raw","use_ttp":true,"ttp_server_host":"ttp-server:9449","ttp_session_id":"interconnection-root","ttp_adjust_rank":0}}}'
    tolerable: false</code></pre><h4>算子参数描述</h4><p>KusciaJob 中算子参数由 <code>taskInputConfig</code> 字段定义，对于不同的算子，算子的参数不同</p><ul><li>秘密分享-逻辑回归（SS-LR）算子相关信息可参考 <a href="https://link.segmentfault.com/?enc=bBDH4Zoya4TJWbKaB7NN2w%3D%3D.T73YO8mknFFmYCjU6Yedlt0dyZ0OArdivYu5XIni8NdpAr%2Fwy%2FxmP64FDcRwblCplhxGAOA1cG%2Fj1XKw3%2BbAWg%3D%3D" rel="nofollow" target="_blank">SS-LR 参考实现</a></li><li>本教程秘密分享-逻辑回归（SS-LR）算子对应的 KusciaJob TaskInputConfig 结构可参考 <a href="#ss-lr-task-input-config" target="_blank">TaskInputConfig 结构示例</a></li></ul><h4>提交 KusciaJob</h4><p>现在已经配置好了一个 KusciaJob，接下来，让运行以下命令提交这个 KusciaJob。</p><pre><code class="shell">kubectl apply -f job-ss-lr.yaml</code></pre><h3>通过银联 BFIA 协议 API 接口提交作业</h3><p>数据准备好之后，将 Alice 作为任务发起方，进入 Alice 节点容器中。</p><pre><code class="shell">docker exec -it ${USER}-kuscia-autonomy-alice bash</code></pre><p>下面使用银联 BFIA 协议创建作业接口提交作业，该作业会提交给 Kuscia 互联互通 InterConn 控制器，该控制器将银联 BFIA 协议规定的创建作业请求参数转化为 Kuscia 中的 KusciaJob 作业定义。<br/>最后，InterConn 控制器在 Kuscia 中创建 KusciaJob 资源。</p><pre><code class="shell">curl -v -X POST 'http://127.0.0.1:8084/v1/interconn/schedule/job/create' \
--header 'Content-Type: application/json' \
-d '{"job_id":"job-ss-lr","dag":{"version":"2.0.0","components":[{"code":"ss-lr","name":"ss_lr_1","module_name":"ss_lr","version":"v1.0.0","input":[],"output":[{"type":"dataset","key":"result"}]}]},"config":{"role":{"host":["alice"],"guest":["bob"]},"initiator":{"role":"host","node_id":"alice"},"job_params":{"host":{"0":{}},"guest":{"0":{}}},"task_params":{"host":{"0":{"ss_lr_1":{"name":"perfect_logit_a.csv","namespace":"data","has_label":true}}},"arbiter":{},"guest":{"0":{"ss_lr_1":{"name":"perfect_logit_b.csv","namespace":"data","has_label":false}}},"common":{"ss_lr_1":{"skip_rows":1,"algo":"ss_lr","protocol_families":"ss","batch_size":21,"last_batch_policy":"discard","num_epoch":1,"l0_norm":0,"l1_norm":0,"l2_norm":0.5,"optimizer":"sgd","learning_rate":0.0001,"sigmoid_mode":"minimax_1","protocol":"semi2k","field":64,"fxp_bits":18,"trunc_mode":"probabilistic","shard_serialize_format":"raw","use_ttp":true,"ttp_server_host":"ttp-server:9449","ttp_session_id":"interconnection-root","ttp_adjust_rank":0}}},"version":"2.0.0"}}'</code></pre><p>提交作业接口请求参数内容结构请参考 <a href="#bfia-create-job-req-body" target="_blank">提交 SS-LR 作业接口请求内容示例</a>。</p><p>{#get-kuscia-job-phase}</p><h2>查看 KusciaJob 运行状态</h2><p>在提交完 KusciaJob 作业后，我们可以在 alice 容器中通过下面的命令查看 Alice 方的 KusciaJob 的运行情况。<br/>同样，也可以登陆到 bob 容器中查看 Bob 方的 KusciaJob 的运行情况。下面以 Alice 节点容器为例。</p><h3>查看所有的 KusciaJob</h3><pre><code class="shell">kubectl get kj -n cross-domain</code></pre><p>您可以看到如下输出：</p><pre><code class="shell">NAME            STARTTIME   COMPLETIONTIME   LASTRECONCILETIME   PHASE
job-ss-lr       3s                           3s                  Running</code></pre><blockquote>job-ss-lr  就是刚刚创建出来的 KusciaJob。</blockquote><h3>查看运行中的 KusciaJob 的详细状态</h3><p>通过指定 <code>-o yaml</code> 参数，能够以 Yaml 的形式看到 KusciaJob 的详细状态。job-ss-lr 是提交的作业名称。</p><pre><code class="shell">kubectl get kj job-ss-lr -n cross-domain -o yaml</code></pre><p>如果任务成功了，您可以看到如下输出：</p><pre><code class="yaml">apiVersion: kuscia.secretflow/v1alpha1
kind: KusciaJob
metadata:
  creationTimestamp: "2023-07-01T02:21:04Z"
  generation: 3
  labels:
    kuscia.secretflow/interconn-protocol-type: bfia
    kuscia.secretflow/self-cluster-as-initiator: "true"
  name: job-ss-lr
  namespace: cross-domain
  resourceVersion: "50438"
  uid: 408a03ae-69c2-4fa8-a638-b47b6dbf530f
spec:
  initiator: alice
  maxParallelism: 2
  scheduleMode: Strict
  stage: Start
  tasks:
  - alias: ss_lr_1
    appImage: ss-lr
    parties:
    - domainID: alice
      role: host
    - domainID: bob
      role: guest
    taskID: job-ss-lr-26e3489ac66e
    taskInputConfig: '{"name":"ss_lr_1","module_name":"ss_lr","output":[{"type":"dataset","key":"result"}],"role":{"host":["alice"],"guest":["bob"]},"initiator":{"role":"host","node_id":"alice"},"task_params":{"host":{"0":{"has_label":true,"name":"perfect_logit_a.csv","namespace":"data"}},"guest":{"0":{"has_label":false,"name":"perfect_logit_b.csv","namespace":"data"}},"common":{"algo":"ss_lr","batch_size":21,"field":64,"fxp_bits":18,"l0_norm":0,"l1_norm":0,"l2_norm":0.5,"last_batch_policy":"discard","learning_rate":0.0001,"num_epoch":1,"optimizer":"sgd","protocol":"semi2k","protocol_families":"ss","shard_serialize_format":"raw","sigmoid_mode":"minimax_1","skip_rows":1,"trunc_mode":"probabilistic","ttp_adjust_rank":0,"ttp_server_host":"ttp-server:9449","ttp_session_id":"interconnection-root","use_ttp":true}}}'
    tolerable: false
status:
  completionTime: "2023-07-01T02:21:14Z"
  conditions:
  - lastTransitionTime: "2023-07-01T02:21:04Z"
    status: "True"
    type: JobValidated
  - lastTransitionTime: "2023-07-01T02:21:04Z"
    status: "True"
    type: JobCreateInitialized
  - lastTransitionTime: "2023-07-01T02:21:04Z"
    status: "True"
    type: JobCreateSucceeded
  - lastTransitionTime: "2023-07-01T02:21:04Z"
    status: "True"
    type: JobStartInitialized
  - lastTransitionTime: "2023-07-01T02:21:04Z"
    status: "True"
    type: JobStartSucceeded
  lastReconcileTime: "2023-07-01T02:21:14Z"
  phase: Succeeded
  startTime: "2023-07-01T02:21:04Z"
  taskStatus:
    job-ss-lr-26e3489ac66e: Succeeded</code></pre><ul><li><code>status</code> 字段记录了 KusciaJob 的运行状态，<code>.status.phase</code> 字段描述了 KusciaJob 的整体状态，而 <code>.status.taskStatus</code> 则描述了包含的 KusciaTask 的状态。<br/>详细信息请参考 <a href="../reference/concepts/kusciajob_cn.md" target="_blank">KusciaJob</a>。</li></ul><h3>查看 KusciaJob 中 KusciaTask 的详细状态</h3><p>KusciaJob 中的每一个 KusciaTask 都有一个 <code>taskID</code>，通过 <code>taskID</code> 我们可以查看 KusciaTask 的详细状态。</p><pre><code class="shell">kubectl get kt job-ss-lr-26e3489ac66e -n cross-domain -o yaml</code></pre><p>KusciaTask 的介绍，请参考 <a href="../reference/concepts/kusciatask_cn.md" target="_blank">KusciaTask</a>。</p><h2>查看 SS-LR 算子运行结果</h2><p>可以通过 <a href="#get-kuscia-job-phase" target="_blank">查看 KusciaJob 运行状态</a> 查询作业的运行状态。 当作业状态 PHASE 变成 <code>Succeeded</code> 时，可以查看算子输出结果。</p><ol><li><p>进入节点 Alice 或 Bob 容器<br/>若已经在容器中，跳过该步骤</p><pre><code class="shell"># Enter the alice node container
docker exec -it ${USER}-kuscia-autonomy-alice bash

# Enter the bob node container
docker exec -it ${USER}-kuscia-autonomy-bob bash</code></pre></li><li><p>查看 KusciaJob 作业状态</p><pre><code class="shell">kubectl get kj job-ss-lr -n cross-domain
NAME        STARTTIME   COMPLETIONTIME   LASTRECONCILETIME   PHASE
job-ss-lr   13s         2s               2s                  Succeeded</code></pre></li><li><p>查看 SS-LR 算子输出结果</p><p>输出内容表示 SS-LR 算子权重向量的密态分片</p><pre><code class="shell"># View the output result in the alice container
more /home/kuscia/var/storage/job-ss-lr-host-0/job-ss-lr-{random-id}-result

# View the output result in the bob container
more /home/kuscia/var/storage/job-ss-lr-guest-0/job-ss-lr-{random-id}-result</code></pre></li></ol><h2>删除 KusciaJob</h2><p>当您想清理这个 KusciaJob 时，您可以通过下面的命令完成：</p><pre><code class="shell">kubectl delete kj job-ss-lr -n cross-domain</code></pre><p>当这个 KusciaJob 被清理时， 这个 KusciaJob 创建的 KusciaTask 也会一起被清理。</p><h2>参考</h2><p>{#ss-lr-task-input-config}</p><h3>SS-LR 算子对应的 TaskInputConfig 结构示例</h3><pre><code class="json">{
  "name": "ss_lr_1",
  "module_name": "ss_lr",
  "input":[],
  "output": [{
    "type": "dataset",
    "key": "result"
  }],
  "role": {
    "host": ["alice"],
    "guest": ["bob"]
  },
  "initiator": {
    "role": "host",
    "node_id": "alice"
  },
  "task_params": {
    "host": {
      "0": {
        "has_label": true,
        "name": "perfect_logit_a.csv",
        "namespace": "data"
      }
    },
    "guest": {
      "0": {
        "has_label": false,
        "name": "perfect_logit_b.csv",
        "namespace": "data"
      }
    },
    "common": {
      "skip_rows": 1,
      "algo": "ss_lr",
      "protocol_families": "ss",
      "batch_size": 21,
      "last_batch_policy": "discard",
      "num_epoch": 1,
      "l0_norm": 0,
      "l1_norm": 0,
      "l2_norm": 0.5,
      "optimizer": "sgd",
      "learning_rate": 0.0001,
      "sigmoid_mode": "minimax_1",
      "protocol": "semi2k",
      "field": 64,
      "fxp_bits": 18,
      "trunc_mode": "probabilistic",
      "shard_serialize_format": "raw",
      "use_ttp": true,
      "ttp_server_host": "ttp-server:9449",
      "ttp_session_id": "interconnection-root",
      "ttp_adjust_rank": 0
    }
  }
}</code></pre><p>字段说明</p><ul><li><code>name</code> 描述了任务算子的名称。</li><li><code>module_name</code> 描述了任务算子所属模块名称。</li><li><code>input</code> 描述了任务算子的输入，若任务不依赖其他任务的输出，则可以将该项置为空。</li><li><code>output</code> 描述了任务算子的输出。</li><li><code>role</code> 描述了任务的角色。</li><li><code>initiator</code> 描述了任务发起方的信息。</li><li><code>task_params</code> 描述了任务算子依赖的参数。</li></ul><p>{#bfia-create-job-req-body}</p><h3>提交 SS-LR 作业接口请求内容示例</h3><pre><code class="json">{
  "job_id": "job-ss-lr",
  "dag": {
    "version": "2.0.0",
    "components": [{
      "code": "ss-lr",
      "name": "ss_lr_1",
      "module_name": "ss_lr",
      "version": "v1.0.0",
      "input": [],
      "output": [{
        "type": "dataset",
        "key": "result"
      }]
    }]
  },
  "config": {
    "role": {
      "host": ["alice"],
      "guest": ["bob"]
    },
    "initiator": {
      "role": "host",
      "node_id": "alice"
    },
    "job_params": {
      "host": {
        "0": {}
      },
      "guest": {
        "0": {}
      }
    },
    "task_params": {
      "host": {
        "0": {
          "ss_lr_1": {
            "name": "perfect_logit_a.csv",
            "namespace": "data",
            "has_label": true
          }
        }
      },
      "arbiter": {},
      "guest": {
        "0": {
          "ss_lr_1": {
            "name": "perfect_logit_b.csv",
            "namespace": "data",
            "has_label": false
          }
        }
      },
      "common": {
        "ss_lr_1": {
          "skip_rows": 1,
          "algo": "ss_lr",
          "protocol_families": "ss",
          "batch_size": 21,
          "last_batch_policy": "discard",
          "num_epoch": 1,
          "l0_norm": 0,
          "l1_norm": 0,
          "l2_norm": 0.5,
          "optimizer": "sgd",
          "learning_rate": 0.0001,
          "sigmoid_mode": "minimax_1",
          "protocol": "semi2k",
          "field": 64,
          "fxp_bits": 18,
          "trunc_mode": "probabilistic",
          "shard_serialize_format": "raw",
          "use_ttp": true,
          "ttp_server_host": "ttp-server:9449",
          "ttp_session_id": "interconnection-root",
          "ttp_adjust_rank": 0
        }
      }
    },
    "version": "2.0.0"
  }
}</code></pre><h3>字段说明</h3><ul><li><code>job_id</code> 描述了作业的标识。</li><li><code>dag</code> 描述了作业的组件之间组合的配置。</li><li><code>config</code> 描述了作业运行时的参数配置。</li></ul>]]></description></item><item>    <title><![CDATA[Qwen3-TTS 升级，多音色、多语种和多方言；KaniTTS：开源实时语音小模型，消费级 GPU]]></title>    <link>https://segmentfault.com/a/1190000047460582</link>    <guid>https://segmentfault.com/a/1190000047460582</guid>    <pubDate>2025-12-09 12:03:37</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047460584" alt="" title=""/></p><p><strong>开发者朋友们大家好：</strong></p><p>这里是<strong>「RTE 开发者日报」</strong>，每天和大家一起看新闻、聊八卦。我们的社区编辑团队会整理分享 RTE（Real-Time Engagement） 领域内「有话题的<strong>技术</strong>」、「有亮点的<strong>产品</strong>」、「有思考的<strong>文章</strong>」、「有态度的<strong>观点</strong>」、「有看点的<strong>活动</strong>」，但内容仅代表编辑的个人观点，欢迎大家留言、跟帖、讨论。</p><p><em>本期编辑：@瓒an、@鲍勃</em>**</p><h2>01 有话题的技术</h2><p><strong>1、Qwen3-TTS 全面升级，49 种音色 + 10 种语言 + 9 种方言</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047460585" alt="" title="" loading="lazy"/></p><p><strong>Qwen3-TTS</strong> 是支持多音色、多语种和多方言的旗舰语音合成模型，致力于实现稳定、自然和高效的语音生成，目前可通过 Qwen API 访问。</p><p>主要改进：</p><ul><li><strong>更加丰富的音色支持</strong>：Qwen3-TTS 提供超过 49 种高品质音色，涵盖不同性别、年龄、地域特征与角色设定，满足多样化的场景需求。撒娇搞怪-茉兔，陪伴感满满的青梅竹马-小野杏，傲娇率性的女汉子-十三 ，严厉老师-墨讲师 ，智慧老者-沧明子，萝莉萌妹-萌小姬等众多角色等你探索。</li><li><strong>多语种多方言能力持续增强</strong>：Qwen3-TTS 支持中文、英文、德语、意大利语、葡萄牙语、西班牙语、日语、韩语、法语、俄语等 10 大主流语言，在 MiniMax TTS multilingual test set 上，平均词错误率（WER）优于 MiniMax、ElevenLabs 及 GPT-4o-Audio-Preview。支持更多音色的方言生成，包括普通话、闽南语、吴语、粤语、四川话、北京话、南京话、天津话和陕西话，真实还原地方口音特色与语言神韵。</li><li><strong>韵律/语速更加自然，更拟人化</strong>：相比于上一个版本，Qwen3-TTS 自适应根据文本调节语速和韵律的能力大幅提高，拟人化程度逼近真人。</li></ul><p>（@Qwen Team）</p><p><strong>2、NineNineSix 开源 KaniTTS：实时语音生成模型，性能比肩商业级产品</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047460586" alt="" title="" loading="lazy"/></p><p>吉尔吉斯斯坦 AI 初创公司 NineNineSix 发布了开源的文本转语音（TTS）模型 KaniTTS。该模型在消费级 GPU 上实现了接近实时的语音生成，性能可与 ElevenLabs、OpenAI 等商业模型媲美，并采用 Apache 2.0 许可证完全免费提供。</p><ul><li><strong>实时性与性能：</strong> 在消费级 NVIDIA RTX 5080 GPU 上，KaniTTS 可以在 1 秒内生成 15 秒的自然语音，实现真正的实时性能，无需企业级硬件。</li><li><strong>高表现力语音：</strong> KaniTTS 不仅能朗读文本，还能捕捉语音的意义、情感、节奏和细微差别，生成听起来自然、生动的语音。</li><li><strong>轻量化架构：</strong> 结合了高效的基于 Token 的生成机制和轻量级神经网络声码器（neural vocoder），实现了低延迟和高保真度。</li><li><strong>多语言支持：</strong> 当前支持英语、德语、韩语、阿拉伯语、中文和西班牙语，并计划增加吉尔吉斯语和日语。</li><li><strong>开源与可访问性：</strong> 采用 Apache 2.0 许可证，允许用户自由研究、改编和部署，降低了先进语音 AI 的门槛。</li><li><strong>参数量：</strong> 370M 参数。</li><li><strong>开发与支持：</strong> 由 NineNineSix 公司开发，并在吉尔吉斯共和国高科技园区（HTP）生态系统内完成。</li></ul><p>KaniTTS 模型已开源，可通过 Hugging Face 下载（已下载超过 15,000 次）。未来计划支持语音克隆功能。</p><p>Hugging Face:<br/> <a href="https://link.segmentfault.com/?enc=E20pGgza9Yqh1di4gsIURw%3D%3D.ALeXyXJwPwwV4mfWPezgzOy2OSZnYqo%2Bg5jnZMtVlL1lHfir%2FbLsWa7YQXIIRtGN" rel="nofollow" target="_blank">https://huggingface.co/nineninesix</a></p><p>(@TechIntelPro / NineNineSix)</p><p><strong>3、被 Gemini3 整怕了，曝 GPT-5.2 本周发布</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047460587" alt="" title="" loading="lazy"/></p><p>据 The Verge 援引知情人士消息称，OpenAI 计划最早于本周初发布 GPT-5.2 模型， 这一时间表较原定的 12 月下旬计划大幅提前。目前公司已将发布日期暂定为 12 月 9 日。</p><p>消息人士称， <strong>此次提前发布直接源于竞争对手施加的压力。</strong></p><p>Google 上月推出的 Gemini 3 模型在多项评测排行榜中领先， 其表现甚至令 OpenAI CEO Sam Altman 感到震惊。知情人士表示，GPT-5.2 的性能提升将有望缩小 Google 此前建立的领先优势。</p><p>最近，X 博主 @iruletheworldmo 也分享了关于这款基础模型的基准测试成绩。不过，真实性尚未得到确认，请谨慎看待。</p><p>除了新模型发布，OpenAI 正在调整产品战略方向。未来数月内，ChatGPT 的改进重点将从增加新奇功能转向提升 ChatGPT 的响应速度、系统稳定性和个性化定制能力。</p><p>( @APPSO)</p><h2>02 有亮点的产品</h2><p><strong>1、Meta XR 产品线大地震：全面拥抱 AI 可穿戴设备，高端 MR 头显延至 2027，Quest 4 聚焦游戏定位</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047460588" alt="" title="" loading="lazy"/></p><p>Meta 近日泄露的内部备忘录显示，公司正在大幅调整其扩展现实产品路线图。原计划于 2026 年下半年发布的超轻薄混合现实头显 Phoenix/Puffin 将推迟至 2027 年上半年上市，而新一代专注于沉浸式游戏的 Quest 4 已确认正在开发中。</p><p>备忘录揭示了 Meta 在 XR 和可穿戴设备战略上的重大转变：<strong>放缓高端 MR 头显进度以「打磨细节」，同时转向更务实、更注重盈利的产品策略。</strong></p><hr/><p>Meta 战略重心从「元宇宙优先」转向「AI 硬件优先」，计划对 Reality Labs 部门削减高达 30%预算，2026 年发布限量版可穿戴设备 Malibu 2。</p><p>收购 AI 硬件初创公司 Limitless 并从苹果挖来人机界面设计副总裁艾伦·戴伊等高管，加速 AI 可穿戴设备布局。</p><p>（@三次方 AIRX、@NathieVR\@X）</p><p><strong>2、ElevenLabs 推出「对话式读书」功能，用户可与书籍进行实时语音互动</strong></p><p>ElevenLabs 于 12 月 6 日通过其官方社交账号发布全新互动阅读功能，旨在为用户打造个性化的「语音读书俱乐部」。该功能依托其 ElevenLabs Agents 平台，允许读者与书籍进行语音对话，实现更深度的阅读体验。</p><p>用户可通过配套应用程序「ElevenReader」向书籍直接提问，内容涵盖人物、情节、背景、主题等任意方向。系统提供的虚拟叙述者能够记忆对话上下文，并严格依据书籍原文进行回应，帮助读者在阅读过程中随时探索故事细节。</p><p>官方示例界面展示了以《傲慢与偏见》为对象的对话场景，界面提示「向我提问…《傲慢与偏见》」，背景采用渐变粉紫色设计，突出沉浸式互动氛围，并强调让读者「走进最喜欢的故事」。</p><p><a href="https://link.segmentfault.com/?enc=1wIf1JP%2F7TuvJVAidp8Ckw%3D%3D.KMlew3G2OTbfb56pGLZqsUeIP3jvCv7Pr57Snlt9DNk%3D" rel="nofollow" target="_blank">https://elevenreader.io/</a></p><p>（@ElevenLabs\@X）</p><p><strong>3、众擎老板亲自挑战机器人，被一脚踹翻</strong></p><p>近期，众擎机器人官方发布视频称，团队十分好奇机器人 T800 一脚踹到人身上到底有啥感觉。对此「用老板做了个实验测试下」。</p><p>从众擎团队公布的视频来看，T800 对准众擎机器人 CEO 赵同阳伸腿后，赵同阳整个人向后「飞」出去。</p><p>挨踹后的赵同阳直呼：「太暴力了、太残暴了。如果不戴护具没人能撑得住，绝对会骨折。」有网友表示：「你们员工太狠了，让老板亲自上阵。多少带了点私人恩怨。」</p><p>据了解，众擎 T800 身高 1.73 米，自重 75 千克，系众擎发布的首款「打工机器人」，售价为 18 万元起。</p><p>( @APPSO)</p><h2>03 有态度的观点</h2><p>1、<strong>AI 教父 Hinton 预言：Google Gemini 将超越 OpenAI GPT，引领 AI 市场</strong></p><p>「AI 教父」 Geoffrey Hinton 近期表示，Google 凭借 Gemini 3、自研芯片、强大的数据资源和研究团队，正在超越 OpenAI。Hinton 认为 Google 凭借其综合优势，必将赢得这场 AI 领域的双雄之争，并且认为 Google「早该赢了」。</p><ul><li><p><strong>Gemini 3 Pro 的多模态能力：</strong> Google 发布了 Gemini 3 Pro，该模型在视觉理解方面取得突破，能从「看见」进化到「理解」，在文档、空间、屏幕和视频理解方面表现卓越。</p><ul><li><strong>文档理解：</strong> 具备高精度 OCR、复杂结构解析（如手写表格、数学公式）及「反渲染」能力，可将文档还原为结构化代码。在 CharXiv 基准测试中超越人类基线。</li><li><strong>空间理解：</strong> 能指向图像中的具体位置，并进行 2D 图像到「世界模型」的关键一步；开放词汇指代能力使其能理解物体及其意图，应用于机器人和 AR/XR 场景。</li><li><strong>屏幕理解：</strong> 显著提升了对桌面和移动设备界面的理解能力，支持计算机使用型智能体执行重复任务、QA 测试、UX 分析等。</li><li><strong>视频理解：</strong> 在高帧率（高于 1 FPS）和复杂因果关系推理方面取得进展，能实现长视频的总结和应用生成。</li></ul></li><li><strong>Google 的综合优势：</strong> Hinton 指出 Google 在模型（Gemini 3、Nano Banana Pro）、自研芯片（TPU）、数据量、研究团队以及庞大的数据中心方面拥有显著优势。</li><li><strong>市场竞争格局：</strong> Gemini 3 的发布带动了 Google 市值的增长。市场情报显示，Gemini 在下载增速、月活增速和用户使用时长方面正全面超越 ChatGPT，尽管 ChatGPT 仍拥有庞大的用户基数。</li><li><strong>Google 的策略转变：</strong> Hinton 提及 Google 曾因对品牌声誉的担忧而变得谨慎，例如早期聊天机器人的发布顾虑，以及近期 AI 图像生成器出现的问题。但 Gemini 3 的发布标志着其在多模态理解上迈出了关键一步。</li><li><strong>OpenAI 的挑战：</strong> ChatGPT 的增长势头趋缓，面临 Gemini、Claude 等竞品的压力。OpenAI CEO Sam Altman 已发出「红色警报」，要求团队聚焦提升 ChatGPT 的核心体验，以巩固用户飞轮优势。</li></ul><p>Gemini 3 Pro 已发布，并在多项基准测试中刷新纪录。Gemini 产品正通过 Android 系统内置等方式扩大其全球市场份额。</p><p>（@新智元）</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047460589" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047460590" alt="" title="" loading="lazy"/></p><p><a href="https://link.segmentfault.com/?enc=GsRh9ht69NhRFpdHkmu8cA%3D%3D.%2F3IT%2FvAldC%2BZHXtVBIC%2FL%2B0s6qEBlIJzTDGpu35imMk%3D" rel="nofollow" target="_blank">阅读更多 Voice Agent 学习笔记：了解最懂 AI 语音的头脑都在思考什么</a></p><p><strong>写在最后：</strong></p><p>我们欢迎更多的小伙伴参与<strong>「RTE 开发者日报」</strong>内容的共创，感兴趣的朋友请通过开发者社区或公众号留言联系，记得报暗号「共创」。</p><p>对于任何反馈（包括但不限于内容上、形式上）我们不胜感激、并有小惊喜回馈，例如你希望从日报中看到哪些内容；自己推荐的信源、项目、话题、活动等；或者列举几个你喜欢看、平时常看的内容渠道；内容排版或呈现形式上有哪些可以改进的地方等。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047460591" alt="" title="" loading="lazy"/></p><p>作者提示: 个人观点，仅供参考</p>]]></description></item><item>    <title><![CDATA[选型不踩坑！2025CRM闭环服务深度测评：超兔 / Salesforce 等13品牌全维度对比 正]]></title>    <link>https://segmentfault.com/a/1190000047460604</link>    <guid>https://segmentfault.com/a/1190000047460604</guid>    <pubDate>2025-12-09 12:02:39</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在数字化时代，企业的核心竞争力已从“单点效率”转向“全链路闭环效率”。一套能覆盖<strong>营销获客-销售管理-订单回款-售后服务</strong>的完整闭环CRM系统，不仅能消除数据割裂，更能通过流程自动化与AI驱动，实现“客户需求→业务执行→价值反馈”的正向循环。</p><p>本文基于<strong>全链路能力拆解+关键维度对比</strong>，对市场主流CRM系统的闭环服务能力进行深度横评，覆盖<strong>超兔一体云、Salesforce、腾讯企点CRM、用友CRM、HubSpot CRM</strong>等13个品牌，为不同规模、行业的企业提供选型参考。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047460606" alt="" title=""/></p><h2>一、对比框架：全链路4大环节+闭环核心能力</h2><p>我们将CRM闭环能力拆解为<strong>4大业务环节+1项底层支撑</strong>，每个环节提炼<strong>关键评价维度</strong>（见表1），确保对比的针对性与专业性。</p><table><thead><tr><th>环节</th><th>关键评价维度</th></tr></thead><tbody><tr><td>营销获客</td><td>渠道整合（线上/线下/社交/广告）、AI/自动化能力、线索质量（查重/补全/筛选）、生态集成</td></tr><tr><td>销售管理</td><td>流程可视化（漏斗/管道）、AI辅助（赢单预测/行动建议）、团队协同（权限/待办）、行业适配</td></tr><tr><td>订单回款</td><td>业财集成（ERP/财务联动）、自动化管控（应收/开票/回款）、风险预警（超发/信用）、复杂场景支持</td></tr><tr><td>售后服务</td><td>渠道覆盖（电话/在线/上门）、工单效率（分派/跟进）、复购挖掘（RFM/流失预警）、满意度管理</td></tr><tr><td>闭环一体化</td><td>数据连通（跨模块/系统）、流程自动化（工作流/AI）、定制化成本、适用企业规模</td></tr></tbody></table><h2>二、全链路能力深度对比</h2><h3>1. 营销获客：从“广撒网”到“精准触达”的效率竞赛</h3><p>营销获客的核心是“用最低成本获取最高质量的线索”，关键看渠道覆盖广度、线索处理精度与生态联动深度。</p><h4>核心品牌表现对比（表2）</h4><table><thead><tr><th>品牌</th><th>渠道整合</th><th>AI/自动化能力</th><th>线索质量管控</th><th>生态集成特色</th></tr></thead><tbody><tr><td><strong>超兔一体云</strong></td><td>覆盖百度/抖音/微信/地推/工商搜客</td><td>线索查重/工商信息自动补全</td><td>手机号/客户名查重、IP归属地分析</td><td>百度/抖音/微信广告生态深度联动</td></tr><tr><td><strong>Salesforce</strong></td><td>全渠道（邮件/短信/社交/广告）</td><td>Journey Builder营销自动化</td><td>Einstein AI线索评分</td><td>Marketing Cloud全链路营销生态</td></tr><tr><td><strong>腾讯企点</strong> <strong>CRM</strong></td><td>微信/QQ社交生态+网页表单</td><td>Magic Agent智能分群+NLP询价解析</td><td>2分钟生成报价单、私域线索沉淀</td><td>腾讯社交生态（微信/QQ/企业微信）</td></tr><tr><td><strong>HubSpot</strong> <strong>CRM</strong></td><td>SEO/社交媒体/网页表单</td><td>AI生成营销内容+线索评分</td><td>免费版含100万/年营销邮件</td><td>免费营销工具生态（表单/落地页）</td></tr><tr><td><strong>励销云</strong></td><td>大数据潜客+智能外呼</td><td>智能外呼线索评分</td><td>高价值客户筛选</td><td>无明确生态，但大数据能力突出</td></tr></tbody></table><h4>关键结论：</h4><ul><li>超兔的<strong>多渠道覆盖</strong>最全面（线上广告+社交+地推+工商搜客），适合需要“线上线下联动获客”的中小企业；</li><li>腾讯企点的<strong>社交生态深度</strong>无可替代，适合依赖微信私域的零售/服务企业；</li><li>Salesforce的<strong>全渠道自动化</strong>最强，适合大型企业的规模化营销。</li></ul><h3>2. 销售管理：从“流程混乱”到“精准推进”的效率升级</h3><p>销售管理的核心是“让销售团队聚焦高价值客户”，关键看流程可视化、AI辅助决策与团队协同能力。</p><h4>核心品牌表现对比（表3）</h4><table><thead><tr><th>品牌</th><th>流程可视化</th><th>AI辅助能力</th><th>团队协同</th><th>行业适配</th></tr></thead><tbody><tr><td><strong>超兔一体云</strong></td><td>三一客小单模型、多方项目模型</td><td>AI日报，AI分析微信/电话沟通，AI跟单策略</td><td>待办提醒/权限管理/自动日报</td><td>小单快单/中长单/大型项目全适配</td></tr><tr><td><strong>Salesforce</strong></td><td>可视化销售漏斗+SPM（销售绩效）</td><td>Einstein AI赢单预测+行动建议</td><td>销售地理管理/激励薪酬计算</td><td>大型企业/跨国业务/复杂项目</td></tr><tr><td><strong>Pipedrive</strong></td><td>可视化管道拖拽界面</td><td>AI赢单概率评估+资源分配建议</td><td>团队任务分配</td><td>中小企业销售驱动型团队</td></tr><tr><td><strong>腾讯企点</strong> <strong>CRM</strong></td><td>自动化任务流</td><td>Customer AI营销决策+异议响应</td><td>微信协同/待办提醒</td><td>社交零售/服务行业</td></tr><tr><td><strong>用友</strong> <strong>CRM</strong></td><td>销售漏斗+外勤打卡</td><td>无明确AI但有流程可视化</td><td>跨部门数据协同</td><td>制造/医药等本地化行业</td></tr></tbody></table><h4>关键结论：</h4><ul><li>超兔的“三一客”小单模型<strong>与</strong>“多方项目模型”是差异化优势，解决了“小单快转”与“大单复杂管理”的痛点；</li><li>Salesforce的SPM（销售绩效管理层）适合大型企业的销售团队管控（如区域划分、薪酬激励）；</li><li>Pipedrive的<strong>可视化管道</strong>最简洁，适合中小企业快速上手。</li></ul><h3>3. 订单回款：从“事后算账”到“事前管控”的风险防控</h3><p>订单回款的核心是“确保资金安全与流转效率”，关键看业财集成度、自动化管控与风险预警能力。</p><h4>核心品牌表现对比（表4）</h4><table><thead><tr><th>品牌</th><th>业财集成</th><th>自动化管控</th><th>风险预警</th><th>复杂场景支持</th></tr></thead><tbody><tr><td><strong>超兔一体云</strong></td><td>应收/开票/回款三角联动</td><td>自动触发应收+多期拆分</td><td>超发预警/客户信用度控制</td><td>30种订单模型（BOM/租赁/生产）</td></tr><tr><td><strong>Salesforce</strong></td><td>Revenue Cloud QTC（报价到回款）</td><td>自动化合同/发票/回款流程</td><td>客户信用度管控</td><td>复杂定价/多单关联</td></tr><tr><td><strong>用友</strong> <strong>CRM</strong></td><td>与用友ERP深度集成</td><td>订单-发货-回款全流程自动化</td><td>账期管理/坏账风险预警</td><td>制造行业生产工单联动</td></tr><tr><td><strong>超兔一体云</strong></td><td>业财三角联动</td><td>自动拆分多期应收</td><td>超发预警</td><td>30种订单模型</td></tr></tbody></table><h4>关键结论：</h4><ul><li>超兔的“30种订单模型”覆盖最广（B2C/B2B/O2O/生产/租赁），适合多业态经营的中小企业；</li><li>用友的<strong>业财集成深度</strong>最强（与用友ERP联动），适合制造/医药等需要“生产-销售-财务闭环”的企业；</li><li>Salesforce的<strong>QTC流程</strong>最完善，适合大型企业的复杂订单管理。</li></ul><h3>4. 售后服务：从“被动响应”到“主动复购”的价值挖掘</h3><p>售后服务的核心是“提升客户满意度+挖掘复购机会”，关键看渠道覆盖、工单效率与复购挖掘能力。</p><h4>核心品牌表现对比（表5）</h4><table><thead><tr><th>品牌</th><th>渠道覆盖</th><th>工单效率</th><th>复购挖掘</th><th>满意度管理</th></tr></thead><tbody><tr><td><strong>超兔一体云</strong></td><td>维修工单（到店）+外勤工单（上门）</td><td>工单分派+进度跟踪</td><td>RFM分析+流失预警</td><td>客服总控台+权限管理</td></tr><tr><td><strong>Salesforce</strong></td><td>Service Cloud（多渠道）+Field Service（上门）</td><td>自动化分单+知识库</td><td>无明确复购但服务闭环完善</td><td>Einstein推荐+满意度调查</td></tr><tr><td><strong>腾讯企点</strong> <strong>CRM</strong></td><td>微信/QQ/电话/在线聊天</td><td>AI舆情监控+工单系统</td><td>流失信号识别+复购提醒</td><td>满意度调查+服务评价</td></tr><tr><td><strong>HubSpot</strong> <strong>CRM</strong></td><td>聊天/邮件/电话</td><td>工单自动化+知识库</td><td>RFM分析+客户分段回访</td><td>免费版含客服工具</td></tr></tbody></table><h4>关键结论：</h4><ul><li>超兔的“维修+外勤工单”覆盖最全面，适合需要“上门服务”的零售/制造企业；</li><li>腾讯企点的<strong>AI舆情监控</strong>能主动识别客户流失信号，适合依赖私域的服务企业；</li><li>Salesforce的<strong>Field Service</strong>最专业，适合大型企业的上门服务（如设备安装/维修）。</li></ul><h3>5. 闭环一体化：从“数据割裂”到“全链路连通”的底层能力</h3><p>闭环一体化的核心是“数据与流程的底层打通”，关键看数据连通性、流程自动化与定制化成本。</p><h4>核心品牌表现对比（表6）</h4><table><thead><tr><th>品牌</th><th>数据连通</th><th>流程自动化</th><th>定制化成本</th><th>适用企业规模</th></tr></thead><tbody><tr><td><strong>超兔一体云</strong></td><td>CRM+进销存+供应链+财务+生产</td><td>工作流引擎（自然语言AI生成）</td><td>低成本（功能白名单+自定义菜单）</td><td>中小企业/多业态经营</td></tr><tr><td><strong>Salesforce</strong></td><td>CRM+ERP+Tableau</td><td>Einstein AI驱动流程</td><td>高成本（定制化需专业服务）</td><td>大型企业/跨国团队</td></tr><tr><td><strong>用友</strong> <strong>CRM</strong></td><td>CRM+用友ERP</td><td>订单-财务流程自动化</td><td>中高成本（行业方案定制）</td><td>中大型制造/医药企业</td></tr><tr><td><strong>HubSpot</strong> <strong>CRM</strong></td><td>营销+销售+服务</td><td>免费工具流程自动化</td><td>低成本（免费版+按需升级）</td><td>中小企业/线上获客</td></tr><tr><td><strong>SuiteCRM</strong></td><td>开源可定制（需技术）</td><td>流程自动化弱</td><td>低成本（开源）</td><td>技术型中小企业</td></tr></tbody></table><h4>关键结论：</h4><ul><li>超兔的<strong>数据连通深度</strong>最全面（覆盖生产/供应链），适合需要“生产-销售-售后闭环”的中小企业；</li><li>Salesforce的<strong>流程自动化</strong>最智能，适合大型企业的复杂流程；</li><li>HubSpot的<strong>成本最低</strong>（免费版含核心功能），适合刚起步的中小企业。</li></ul><h2>三、闭环一体化能力可视化：雷达图对比</h2><p>我们选取<strong>获客能力、销售效率、回款管控、服务体验、闭环成熟度</strong>5个核心维度，以10分为满分，对核心品牌评分如下（表7）：</p><table><thead><tr><th>品牌</th><th>获客能力</th><th>销售效率</th><th>回款管控</th><th>服务体验</th><th>闭环成熟度</th></tr></thead><tbody><tr><td><strong>超兔一体云</strong></td><td>8.5</td><td>9</td><td>8.5</td><td>8</td><td>9</td></tr><tr><td><strong>Salesforce</strong></td><td>9</td><td>9.5</td><td>9</td><td>9</td><td>9.5</td></tr><tr><td><strong>腾讯企点</strong> <strong>CRM</strong></td><td>8</td><td>8.5</td><td>7.5</td><td>8.5</td><td>8</td></tr><tr><td><strong>HubSpot</strong> <strong>CRM</strong></td><td>7.5</td><td>7</td><td>6.5</td><td>7.5</td><td>7.5</td></tr><tr><td><strong>用友</strong> <strong>CRM</strong></td><td>7</td><td>8</td><td>9</td><td>7</td><td>8.5</td></tr><tr><td><strong>SuiteCRM</strong></td><td>5</td><td>6</td><td>5</td><td>5</td><td>6</td></tr></tbody></table><h2>四、选型建议：根据企业需求精准匹配</h2><h3>1. 大型企业/跨国团队</h3><ul><li><strong>首选Salesforce</strong>：全链路AI驱动、复杂流程管控、全球化支持，适合需要“规模化、标准化”的大型企业；</li><li><strong>备选</strong> <strong>SAP</strong> <strong><em/></strong>CRM**：业财集成深度高，适合跨国制造企业；</li><li><strong>备选Oracle CX</strong>：全球化多渠道能力强，适合覆盖多区域的企业。</li></ul><h3>2. 中小企业/多业态经营</h3><ul><li><strong>首选超兔一体云</strong>：多渠道获客、多业态订单模型、低成本闭环，适合需要“线上线下联动、多业务线管理”的中小企业；</li><li><strong>备选腾讯企点</strong> <strong>CRM</strong>：微信生态深度、AI效率工具，适合依赖私域的零售/服务企业；</li><li><strong>备选HubSpot</strong> <strong>CRM</strong>：免费入门、线上获客能力强，适合刚起步的线上企业。</li></ul><h3>3. 制造/医药/本地化企业</h3><ul><li><strong>首选用友</strong> <strong>CRM</strong>：业财集成深度、行业方案定制，适合制造/医药等需要“生产-销售-财务闭环”的企业；</li><li><strong>备选超兔一体云</strong>：生产工单联动、多方项目模型，适合有大型项目需求的制造企业。</li></ul><h3>4. 技术型/开源需求企业</h3><ul><li><strong>首选SuiteCRM</strong>：开源免费、高度定制化，适合有技术团队的中小企业；</li><li><strong>备选Zoho</strong> <strong>CRM</strong>：开源版功能完善，适合技术型销售团队。</li></ul><h2>五、总结：闭环CRM的未来趋势</h2><p>从本次横评可以看出，<strong>闭环一体化</strong>已成为CRM的核心竞争力，未来的CRM系统将向以下方向发展：</p><ol><li><strong>更深度的生态联动</strong>：与社交/办公/生产生态的融合（如超兔的微信/百度联动、腾讯企点的微信生态）；</li><li><strong>更智能的AI驱动</strong>：从“流程自动化”向“决策自动化”升级（如Salesforce的Einstein AI、腾讯企点的Magic Agent）；</li><li><strong>更灵活的定制化</strong>：低成本定制满足中小企业的个性化需求（如超兔的功能白名单、HubSpot的免费版）。</li></ol><p>对于企业而言，选择CRM的关键不是“功能最全”，而是“最适配自身业务流程”——只有能覆盖<strong>获客-销售-回款-售后全链路</strong>，并能与自身生态联动的系统，才能真正提升效率、创造价值。</p><p><strong>附录：闭环流程Mermaid图</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047460607" alt="" title="" loading="lazy"/></p><pre><code>graph TD
    A[营销获客：多渠道集客→线索处理→营销物料] --&gt; B[销售管理：客户中心→跟单模型→通用能力]
    B --&gt; C[订单回款：合同订单→财务管控]
    C --&gt; D[售后服务：复购挖掘→客服工单]
    D --&gt; A[复购/转介绍]
    subgraph 闭环支撑
        E[数据底层连通：CRM+进销存+供应链+财务+生产]
        F[流程自动化：工作流引擎→AI生成→权限/限时]
        G[定制化：功能白名单→自定义菜单→自定义工作流]
    end
    E --&gt; A/B/C/D
    F --&gt; A/B/C/D
    G --&gt; A/B/C/D</code></pre><p><strong>附录：闭环一体化脑图</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047460608" alt="" title="" loading="lazy"/></p><pre><code>mindmap
    root((闭环一体化能力))
        数据底层连通
            CRM与进销存
            供应链与财务
            生产与销售
        流程自动化
            工作流引擎（自然语言AI生成）
            订单/工单自动推进
            待办/日程自动提醒
        低成本定制化
            功能白名单订阅
            自定义三级菜单
            自定义业务表/工作流
        AI深度应用
            智能体嵌入客户视图
            沟通内容AI分析
            自动生成日报/预测</code></pre>]]></description></item>  </channel></rss>