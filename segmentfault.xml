<?xml version="1.0" encoding="UTF-8"?><rss version="2.0">  <channel>      <title>SegmentFault - 最近文章</title>      <link>https://segmentfault.com/blogs/newest</link>      <description>SegmentFault 思否</description>      <generator>python segmentfault.py @Pi20</generator>      <item>    <title><![CDATA[cpp c++面经分享 cpp辅导的阿甘]]></title>    <link>https://segmentfault.com/a/1190000047406271</link>    <guid>https://segmentfault.com/a/1190000047406271</guid>    <pubDate>2025-11-17 23:04:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>前言</h2><p>大家好，我是阿甘，“奔跑中cpp / c++”，知识星球的创始人</p><p>今天给大家分享分享，我们星球同学一起整理的，同时也在不断更新的，cpp / c++相关岗位面经。</p><p>全网最全收集</p><h2>面经分享</h2><p>因面经过多，今天只分享部分，后续有时间继续分享（让大家学习/ 面试形成一个参考）<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047406273" alt="" title=""/></p><h3>字节客户端一面</h3><ol><li>C++智能指针有哪些，都是为了解决什么问题？</li><li>虚函数是什么，如何实现虚函数？</li><li>如何用栈实现一个队列？</li><li>TCP的流量控制，拥塞控制</li><li>主从reactor是什么，数据是怎么传输的？</li><li>(以下都是网络检测项目)项目的背景是什么，为什么要做这样一个项目？有没有应用到实际中？</li><li>ai的具体作用是什么，会不会负载很大？</li><li>传入ai的是什么？有多大？会不会在运行上有一个后置性，为什么不在前置设置一个阈值，超出阈值的输出给ai？</li><li>如何进行网络好坏的判断？这些指标是在现如今工作中的统一标准还是什么？</li><li>算法手撕</li></ol><h3>oppo多媒体开发</h3><p>一面:</p><p>1.无手撕，直接拷打项目，挑一个最熟悉的项目介绍</p><p>2.线程池和内存池用来干什么，怎么实现的</p><p>3.性能调优具体怎么做的</p><p>4.有没遇到过内存泄露，具体场景</p><p>5.tcp和udp区别，具体实现</p><p>6.数据结构相关，map,set,unordered_map底层实现，vector和list区别</p><p>7.(开始进入智能云存储项目)ai检索具体怎么做的，用api的话工作量在哪</p><p>8.遇到的困难，怎么解决的/遇到过那些比较棘手的debug情况/介绍下怎么快速上手项目的</p><p>二面:</p><p>1.同样是先介绍项目，无手撕</p><p>2.进程间通信和线程同步</p><p>3.追着本人的项目一直问到具体遇到过哪些debug场景以及最后如何解决的，但没涉及到具体的八股</p><p>4.分布式架构如何实现的</p><p>5.采用gpu处理信号的时候考虑过gpu到cpu通信的耗时吗？为什么最终还是选择gpu(本人的实验室项目)</p><p>6.性能怎么测的？以及再次问了线程池和内存池</p><p>7.lamda以及移动语义用没用过等</p><p>8.对oppo有哪些了解</p><p>三面(hr面):<br/>大概问了下优点缺点，意向地怎么考虑的，对oppo的认识，对于未来工作环境的想法等等，纯聊天局。</p><p>总结:全程无手撕，建议笔试好好做(本人笔试水过去被问真不知道笔试成绩比较低)，问项目感觉更多是在看有没有真实的做过一些东西，以及对项目的整体把控。timeline基本是一周一推进。</p><h3>米哈游一面</h3><p>1、自我介绍</p><p>2、为什么投递这个客户端工具岗位</p><p>3、指针和引用的区别（概念、使用场景）</p><p>4、是否存在指针数组和引用数组</p><p>5、野指针</p><p>6、内存泄漏</p><p>7、new和malloc的区别</p><p>8、new和malloc怎么判断分配内存失败了？</p><p>9、智能指针</p><p>10、引用计数保存在内存哪个部分</p><p>11、介绍下C++内存分布</p><p>12、静态区、堆和栈什么时候确定大小？</p><p>13、堆和栈的区别</p><p>14、为什么栈的分配效率更高？</p><p>15、堆和栈的安全性</p><p>16、static关键字</p><p>17、静态全局变量和全局变量</p><p>18、静态局部变量和局部变量</p><p>19、静态成员变量和静态成员函数</p><p>20、手撕：用数组实现一个可以扩容的栈，不能用vector</p><p>21、map的底层</p><p>22、二叉搜索树、二叉平衡树、红黑树</p><p>23、熟悉的设计模式</p><p>24、单例模式</p><p>25、简单工厂、工厂方法、抽象工厂</p><h3>海康</h3><p>1、云存储项目：</p><p>介绍文件秒传逻辑</p><p>介绍大文件分片上传逻辑</p><p>分片文件上传到后端在合并前存储在哪里</p><p>有没有考虑以分片形式存储到fastdfs中</p><p>fastdfs的原理展开说下</p><p>ai搜索展开讲下</p><p>2、弱网项目：</p><p>介绍下ICMP协议实现方式</p><p>介绍eBPF怎么用的</p><p>项目的难点是什么</p><p>3、拷贝构造函数在那些场景下调用</p><p>4、静态成员函数与普通成员函数的差别是什么</p><p>5、追问为什么this不能调用静态成员函数，底层原理是什么</p><p>6、了解什么设计模式</p><p>7、讲下你在项目中怎么实现一个具体单例模式的</p><p>8、项目有没有用过线程池？怎么设置的</p><p>9、条件变量怎么使用的？为什么要配合锁使用？</p><p>10、写没写过网络库</p><p>11、Reactor要怎么实现</p><h2>知识星球介绍（公认的cpp c++学习地）</h2><p>星球名字：奔跑中的cpp / c++</p><p>里面服务也不会变，四个坚守目前:</p><p>1.每天都会看大家打卡内容，给出合理性建议。</p><p>2.大家如果需要简历指导，心里迷茫需要疏导都可以进行预约周六一对一辅导。</p><p>3.每周五晚上九点答疑聊天不会变。</p><p>4.进去星球了，后续如果有什么其他活动，服务，不收费不收费(可以合理赚钱就收取下星球费用，但是不割韭菜，保持初心)</p><p>（还有经历时间考验的独家私密资料）</p><p>加入星球的同学都可以提问预约，一对一帮做简历，一对一  职业规划辅导    ，解惑。同时有高质量的项目以及学习资料</p><p>本文由<a href="https://link.segmentfault.com/?enc=3%2FuOxIgWRHM6kLPpo5ASkw%3D%3D.tvpVe3U2zzUMArqNH5UD9R3zk8oQZdM5V2Tsv1Ewmio%3D" rel="nofollow" target="_blank">mdnice</a>多平台发布</p>]]></description></item><item>    <title><![CDATA[《Unity渲染实战宝典：突破平台限制的]]></title>    <link>https://segmentfault.com/a/1190000047406281</link>    <guid>https://segmentfault.com/a/1190000047406281</guid>    <pubDate>2025-11-17 23:03:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>许多开发者初期极易陷入“参数拉满即优质”的认知误区，盲目调高光照强度、堆叠后处理效果、复用高面数模型，却忽略了不同平台（移动端、PC端、主机端）的硬件架构本质差异—移动端GPU的ALU数量通常仅为PC端的1/5至1/3，显存带宽也存在数倍差距，而主机端则具备专属的光线追踪加速单元。这种硬件差异直接导致相同渲染配置在不同设备上表现天差地别，最终出现真机测试时帧率断崖式下跌、设备异常发热、画面元素穿帮（如阴影断裂、材质闪烁）等问题。真正成熟的渲染优化，是对渲染管线每一个环节的深度解构与灵活重组，是在有限资源边界内实现视觉体验最大化的艺术。以复杂场景光照处理为例，既不能为了追求照片级真实感而无限制增加实时光源—移动端设备通常难以承载超过4个实时光源的同时计算，过多光源会直接导致GPU算力过载，甚至触发设备的 thermal throttling（热节流）机制；也不能为了单纯节省性能而过度简化光照层次，否则会让画面显得扁平乏味，失去沉浸感。此时需要结合场景类型与动态物体占比精准决策：动态物体占比高的动作游戏，可采用“少量实时光源（主角2个+关键交互道具1个）+光照探针”的组合，保证角色与核心道具的光影实时反馈，同时通过环境光反射贴图模拟周围环境的光影影响；静态场景为主的解谜游戏，则可通过光照烘焙生成Lightmap，将烘焙分辨率设置为每米512像素以保证细节，再搭配2次间接光反弹模拟自然光影过渡，甚至通过材质的反光系数调整（如墙面反光系数0.1、金属道具0.8）与环境光探针的合理布局，让玩家在视觉上感知到超出硬件实际支持的光影层次。这种“感知优化”远比单纯的参数堆砌更具性价比，也是资深开发者与新手的核心差距所在。</p><p>材质系统作为渲染的基础载体，其优化细节直接决定游戏的运行效率与画面一致性，却最容易被开发者忽视。很多人习惯直接使用Unity默认Shader或网络下载的复杂Shader模板，却未意识到每一个冗余的Shader变体都会成为性能负担—Shader变体过多会导致游戏加载阶段的Shader编译时间大幅延长，移动端设备可能出现3-5秒的启动卡顿，而在部分低端机型上，甚至会出现Shader编译失败导致的画面粉红错误。更严重的是，冗余变体还会占用额外内存，一款中型游戏的Shader变体若未做裁剪，可能占用数十MB内存，这对于仅配备2GB显存的移动端设备来说，无疑是雪上加霜。在实际开发中，Shader的精准裁剪是核心优化动作：需借助Unity的Shader Variant Collection工具，分析游戏运行过程中实际调用的变体，剔除所有无用功能模块，比如2D游戏无需保留3D Shader中的法线贴图计算、视差映射模块，远景物体可移除Shader中的高光反射、细节纹理采样、自发光等逻辑，仅保留基础颜色渲染功能，将Shader指令数控制在100条以内。材质的复用与共享同样关键，对于外观相似仅颜色或纹理不同的物体（如批量生成的敌人、重复的场景装饰、道具库中的同类物品），应通过材质实例化（Material Instantiate）功能修改主纹理或颜色参数，而非创建多个独立材质，这样能有效减少DrawCall的无效增长—DrawCall的增加会直接加重CPU的调度负担，当DrawCall超过2000时，多数移动端设备的CPU会成为性能瓶颈，帧率可能从60帧骤降至30帧以下。此外，渲染队列的设置直接影响画面渲染顺序与OverDraw（过度绘制）压力，错误的队列配置可能引发严重问题：将透明物体设置在不透明队列（Opaque）会导致遮挡关系错乱，出现“透明物体被不透明物体穿透”的视觉bug；而将半透明物体放在透明队列（Transparent）前端，则会导致后续物体重复渲染，OverDraw占比可能飙升至300%以上，造成GPU像素填充率过载。正确的做法是根据物体的透明属性与场景层级分级配置：不透明物体放在“Opaque”队列（优先级2000），半透明物体放在“Transparent”队列（优先级3000），粒子特效、UI等需要叠加的元素放在“Overlay”队列（优先级4000），同时通过调整队列偏移值，确保关键视觉元素（如主角、任务道具）优先渲染，避免被次要物体遮挡。借助Unity的Frame Debugger工具，可实时查看OverDraw热点区域，针对占比超过200%的区域优化渲染队列，往往能快速提升帧率。</p><p>光照与阴影是塑造画面质感的核心，也是渲染优化中最具挑战性的环节，其优化的关键在于“分层适配”与“视觉欺骗”的深度结合。很多开发者盲目追求高阴影分辨率，认为分辨率越高画面越真实，却忽视了阴影计算对GPU的巨大消耗—阴影本质是通过深度纹理采样实现的，分辨率每提升一倍，GPU的计算量会增加四倍。在动态物体较多的开放世界场景中，若将阴影分辨率设置为2048以上，会导致GPU的像素填充率瞬间饱和，帧率可能从60帧骤降至30帧以下，尤其在移动端设备上，还会伴随严重的发热问题。真正高效的阴影策略，是根据物体的视觉权重与玩家距离进行分层处理：主角、关键道具等近距离交互元素，可将阴影分辨率设置为1024，阴影距离调整至50米，同时开启软阴影（Soft Shadows）增强立体感；中距离的NPC、场景互动物体，阴影分辨率降至512，阴影距离缩短至30米；远景的建筑、植被等非核心元素，可将阴影分辨率降至256或直接关闭实时光影，通过Lightmap烘焙预留阴影痕迹，或使用“软阴影贴图”（Fake Shadow）模拟阴影效果，既节省性能又不破坏画面整体性。间接光照的调整同样需要精准把控，过多的间接光反弹（超过3次）会导致画面过亮、色彩失真，且烘焙时间可能从半小时延长至数小时，占用大量开发时间；而反弹次数过少（少于1次）则会让场景显得灰暗、缺乏层次感，物体之间的光影过渡生硬，影响沉浸感。在实际调试中，需结合场景封闭程度与材质反光属性灵活调整：室内场景空间狭小、材质（如瓷砖、金属）反光较强，间接光反弹2次即可避免过曝，同时将间接光强度衰减系数设置为0.8，让光线过渡更自然；室外开阔场景光线充足，材质（如泥土、布料）反光较弱，可将反弹次数提升至3次，间接光强度衰减系数设置为0.6，模拟阳光照射下的环境反光。光照探针的布局则需遵循“疏密有致”原则，在光照变化剧烈的区域（如门窗边缘、转角、树荫下），将探针间距设置为2-3米，确保动态物体进入该区域时能精准接收光影变化；而在光照均匀的开阔区域（如草原、广场），探针间距可扩大至5-8米，避免探针过多导致的内存浪费与烘焙效率下降。对于大型开放世界场景，还可使用Probe Volume替代传统光照探针，通过体积化的探针分布，实现更细腻的光影过渡，同时支持动态加载与卸载，减少内存占用。此外，阴影的“距离缩放”功能也值得运用，根据玩家视角距离自动调整阴影范围，当玩家远距离移动时，逐步缩小阴影距离，近距离时则扩大，在不影响视觉体验的前提下进一步节省性能。</p><p>后处理效果是画面的“点睛之笔”，但过度使用会成为性能的“枷锁”，尤其在移动端等硬件资源有限的平台，后处理的不合理配置往往是帧率下跌的主要诱因。很多开发者在开发初期会一股脑开启抗锯齿、景深、体积雾、颜色校正、光晕、镜头畸变等所有后处理效果，却未意识到这些效果叠加后对GPU的负载—以移动端为例，同时开启4种以上后处理效果，GPU的渲染耗时可能从10ms增加至25ms，帧率直接跌破30帧，而部分老旧设备甚至会因GPU算力不足出现画面卡顿、掉帧。高效的后处理策略核心是“取舍与分级”，需结合游戏类型、美术风格与目标平台性能精准配置：动作类游戏需优先保证画面流畅度与清晰度，可保留抗锯齿（推荐FXAA或TAA，避免使用MSAA，后者对移动端GPU压力过大）与颜色校正（调整Gamma值、对比度），关闭景深、体积雾等非核心效果，避免画面模糊影响操作精准度；叙事类或解谜类游戏更注重氛围营造，可保留景深（降低采样率至24，影响范围限制在10-30米）与体积雾（减少密度至0.1，影响范围50米），关闭镜头畸变、光晕等冗余效果，既保证焦点突出，又控制性能消耗。不同抗锯齿方案的性能差异也需重点关注：FXAA算法简单，性能消耗最低，但边缘模糊度较高；TAA抗锯齿效果更细腻，适合3D游戏，但需要额外的帧缓冲存储，内存占用略高；MSAA抗锯齿效果最佳，但仅支持前向渲染，且对移动端GPU压力极大，仅建议在PC或主机平台使用。后处理的执行顺序同样影响渲染效率，合理的顺序应遵循“先基础优化，后效果叠加”原则：首先进行抗锯齿处理，解决画面锯齿问题；其次进行阴影修复（如Contact Shadows），弥补实时光影的细节缺失，让物体与地面的接触阴影更自然；再进行颜色校正、对比度调整，统一画面色调，增强视觉冲击力；最后叠加景深、体积雾等氛围效果，避免重复计算导致的性能浪费。此外，后处理的“分级加载”机制能进一步提升适配性，通过检测设备的GPU型号与内存大小，自动调整后处理等级：高端设备开启全量效果，中端设备关闭部分高消耗效果，低端设备仅保留抗锯齿与颜色校正。后处理的分辨率缩放功能也值得重点运用，在低配置设备上，可将后处理渲染分辨率设置为屏幕分辨率的0.7-0.8倍，以微小的画质损失换取15%-20%的帧率提升；在高端设备上则可全开分辨率，甚至开启超采样（1.2倍）提升画面细腻度。同时，后处理的“距离剔除”设置能减少无效计算，比如体积雾仅在50米范围内生效，景深仅对10-30米区间的物体起作用，避免对远处无关物体进行不必要的效果处理。</p><p>纹理资源的优化是渲染性能提升的“隐形抓手”，其核心逻辑是“适配需求、精简冗余”，在保证视觉效果的前提下，最大限度降低内存占用与GPU带宽消耗。很多开发者在制作纹理时存在“分辨率越高越好”的误区，比如将UI图标分辨率设置为1024x1024，将地面纹理设置为4096x4096，却未意识到纹理分辨率每提升一倍，内存占用会增加四倍—一张4096x4096的RGBA32格式纹理，内存占用高达64MB，而移动端游戏的纹理总内存通常建议控制在512MB以内，过多高分辨率纹理会直接引发内存溢出（OOM）或加载卡顿，尤其在切换场景时，可能出现黑屏等待。纹理分辨率的选择需严格适配显示需求：UI图标、按钮等近距离查看的元素，分辨率设置为256x256或512x512即可满足清晰需求，无需超过屏幕分辨率的两倍（如手机屏幕分辨率为1080x1920，UI纹理最大设置为1024x1024即可）；场景中的地面、墙面等大面积纹理，可根据实际显示尺寸设置为1024x1024或2048x2048，通过纹理平铺（Tiling）与Mipmap技术保证远处显示的清晰度，比如地面纹理平铺值设置为4x4，可覆盖更大面积且不损失细节；远景的山体、天空盒等元素，分辨率甚至可降低至512x512，肉眼几乎无法察觉画质损失，却能节省大量内存。纹理压缩格式的选择则需结合目标平台与纹理类型：Android平台优先使用ETC2格式，该格式支持透明通道，且在Android 4.4以上版本全面兼容，能将纹理内存占用减少75%，对于无透明通道的纹理，可使用ETC1格式进一步提升压缩效率；iOS平台适合使用PVRTC格式，压缩效率更高，且对苹果设备的GPU兼容性更佳，支持1bit和4bit压缩模式；PC与主机平台可使用BC格式（如BC3支持透明、BC5适用于法线贴图），在保证画质的同时降低带宽消耗。透明纹理的压缩需格外注意，避免因压缩格式选择不当导致边缘模糊或颜色失真，比如移动端透明UI纹理建议使用ETC2 Alpha格式，而非RGBA32格式。Mipmap的设置需灵活调整：UI纹理、小图标等无需远距离显示的资源，可关闭Mipmap以节省内存（关闭后可减少约33%的内存占用）；场景纹理、模型纹理等需要远距离显示的资源，应开启Mipmap，并将Mipmap层级设置为3-4级，避免远处纹理出现锯齿或模糊，同时Mipmap还能减少GPU在采样远处纹理时的带宽消耗。此外，纹理图集的打包是减少DrawCall的有效手段，将同一场景、同一材质的纹理（如角色的服装、武器纹理，场景中的道具、装饰纹理）打包成一个图集，可避免频繁切换纹理导致的GPU开销，提升渲染效率。打包时需注意：图集尺寸不宜超过2048x2048像素（部分低端设备不支持超过4096x4096的纹理），否则会增加加载时间与内存占用；保证图集中纹理的格式统一（如均为ETC2），避免混合格式导致的压缩失效；使用Sprite Packer工具的“tight packing”模式，减少纹理之间的空白区域，提升图集利用率。同时，纹理的导入设置也需优化，关闭不必要的导入选项（如“Generate Lightmap UVs”“Read/Write Enabled”），仅在需要时开启，避免额外的内存占用与导入时间。</p><p>渲染管线的适配与定制是Unity渲染优化的高阶核心，不同渲染管线（URP、HDRP、内置管线）的性能特性、功能支持与适用场景差异显著，盲目选择只会导致性能与画质的双重失衡，甚至增加开发成本与周期。内置管线虽然兼容性强，能适配老旧设备（如Android 4.0以上、iOS 9以上），但功能相对单一，缺乏先进的光照模型（如PBR）、后处理框架与自定义渲染通道支持，难以满足高品质画面需求，仅适合开发轻量化2D游戏或对画质要求较低的3D游戏；HDRP（高清渲染管线）能提供电影级的渲染效果，支持实时全局光照（RTGI）、体积雾、屏幕空间反射（SSR）、光线追踪等高级特性，但其对硬件要求极高，需要显卡支持DirectX 12或Vulkan，且显存至少4GB以上，仅适用于PC、主机等高端平台，移动端设备几乎无法流畅运行，开发成本也相对较高；而URP（通用渲染管线）则兼顾了性能与灵活性，通过模块化设计可按需启用功能（如是否开启PBR、后处理、阴影），支持多平台适配，是移动端、中端PC等平台的最优选择，也是当前Unity开发的主流管线。</p>]]></description></item><item>    <title><![CDATA[《Unity多语言开发：从文本到体验的深]]></title>    <link>https://segmentfault.com/a/1190000047406284</link>    <guid>https://segmentfault.com/a/1190000047406284</guid>    <pubDate>2025-11-17 23:02:50</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>游戏多语言本地化的深层逻辑，从来不是简单的文本替换，而是语言特性与技术架构的深度耦合，每一种语系的语法规则、表达习惯，都会像无形的脉络，牵动UI布局、资源存储、交互逻辑乃至玩家体验的底层设计。以语系差异为例，黏着语体系中词汇的组合方式往往让句子长度产生极大波动，同样一句技能描述，日语可能比中文多出三成字符，英语的缩略表达又可能缩短近半，泰语的声调变化虽不直接影响字符数量，却会因发音节奏差异需要调整文本分行逻辑，这种差异绝非自动换行就能化解。它要求技术层面在文本渲染之初就建立动态适配模型—既要预留足够的显示空间避免文本溢出，又要通过算法优化避免空间浪费导致的UI失衡，更要兼顾不同语言的阅读节奏，比如长句文本需要拆分显示以减轻视觉疲劳，短句则需紧凑排版保持界面简洁。在实际开发中，这种适配还需要考虑不同语言的字符间距、行高差异，中文方块字的排版密度与西文的字母组合逻辑截然不同，强行套用同一套排版规则只会导致界面杂乱，因此需要为不同语系定制专属的排版参数，比如中文行高设置为字体大小的1.5倍，西文则调整为1.2倍，同时结合用户研究数据优化文本间距，确保阅读流畅度。更重要的是，动态适配模型还需关联玩家行为数据，比如通过分析不同语言版本用户的停留时长、文本阅读速度，持续微调排版策略，让文本显示既符合语言特性，又贴合目标用户的阅读习惯，这种对语言本质的技术响应，才是多语言版本跳出“翻译表层”、触及体验核心的关键，而非仅仅停留在字面意义的转换上。</p><p>文本提取作为多语言开发的基础环节，真正的难点不在于捕捉显式标注的文本，而在于挖掘那些隐藏在功能逻辑、音效、视觉元素中的隐性表达，这些容易被忽视的内容，恰恰是影响本地化完整性的关键。比如技能释放时的音效字幕，不仅要精准匹配音效时长，还要考虑不同语言的发音节奏，避免字幕显示与音效不同步导致的体验割裂；道具描述中的文化隐喻不能直接直译，需要技术层面支持翻译文本的扩展字段，让翻译人员补充语境说明，确保玩家准确理解核心含义；加载界面的进度提示、成就解锁的弹窗文案、甚至错误报告中的提示信息，这些分散在各个功能模块的隐性文本，若不建立统一的提取标准，很容易出现遗漏或重复翻译的问题。文本ID的命名逻辑同样需要深思熟虑，单纯以功能命名极易出现歧义，比如“open”既可能指打开宝箱，也可能指开启菜单，若不结合场景维度进行区分，后续维护和翻译对接都会陷入混乱，因此建立“场景+功能+优先级”的三维命名体系至关重要，例如“mainUI_chest_open_01”明确指向主界面宝箱打开的一级提示文本，既方便技术人员快速定位文本位置，也让翻译人员明确文本的使用语境。此外，字符编码的兼容性问题常被忽略，北欧小语种的特殊字符、东南亚语系的音调符号，都需要提前适配UTF-8-BOM或其他兼容编码格式，避免在不同设备上出现乱码现象；同时要对提取后的文本进行去重处理，通过文本相似度算法识别重复或高度相似的内容，减少冗余翻译工作量。Unity中文本资源的存储格式选择也需谨慎权衡，XML格式结构清晰但加载效率稍低，JSON格式轻便灵活却在复杂文本管理上存在局限，实际开发中可根据项目规模选择混合存储方案，核心文本采用JSON保证加载速度，扩展文本与语境说明采用XML便于维护，同时搭建可视化的文本管理工具，让翻译人员在不改动代码的情况下直接更新文本内容，大幅提升协作效率，避免因格式限制导致后续本地化迭代困难。</p><p>UI适配是多语言版本中最直观的技术挑战，其核心远不止于文本的自动换行，而是要应对不同语言的阅读习惯和文本特性带来的连锁反应，每一处细节的处理都直接影响玩家的视觉体验和操作流畅度。从阅读方向来看，阿拉伯语、希伯来语等属于从右到左的语系，这要求UI布局不仅要翻转文本显示顺序，还要调整控件的排列逻辑—比如导航栏的图标顺序需从右至左排列，下拉菜单的展开方向改为向左弹出，输入框的光标默认位置设置在右侧，甚至弹窗的关闭按钮也需移动到界面左侧，这种调整不能简单地镜像翻转，还要考虑用户的操作习惯，比如从右到左阅读的用户更习惯在界面右侧进行核心操作，因此需要将攻击、跳跃等关键按钮的位置保留在右侧，仅调整辅助控件的顺序。文本膨胀率的预估则需要建立数据模型，不同语言的膨胀系数存在显著差异，德语的名词复合结构常常导致句子长度比中文多出50%，韩语的音节组合方式会让文本占用30%以上的额外空间，泰语的声调符号虽不增加字符数量却会影响行高，这就要求在UI设计之初就根据目标语言的膨胀规律预留足够的显示区域，同时采用动态布局组件，通过设置灵活的锚点和自适应容器，让控件能够根据文本长度自动调整大小和位置，避免出现文本溢出或空间浪费的情况。此外，不同分辨率设备下的文本缩放问题也需重点考虑，小屏手机上，长句文本若单纯缩小字体会导致可读性下降，因此需要结合文本拆分与字体自适应算法，将过长文本按语义拆分为多行，同时根据屏幕尺寸动态调整字体大小，在保证可读性的前提下实现界面的整体协调；大屏设备如平板、PC端，则要避免文本过大导致的界面空洞，通过调整字符间距、行间距以及补充装饰性元素，保持UI的视觉完整性。字体的兼容性同样不容忽视，部分小语种字体在iOS和Android平台上的渲染效果存在差异，比如冰岛语的特殊字母在Android原生字体中可能显示模糊，需要提前嵌入自定义字体包，同时进行跨平台测试，确保文本显示清晰、美观，避免因字体问题影响玩家对游戏内容的理解。</p><p>文化适配与翻译协同的技术实现，是多语言版本跳出“字面翻译”误区的核心，它要求技术架构能够支撑翻译的灵活性和文化适配的深度，让游戏在不同地区都能传递一致的核心体验，同时贴合当地的文化习惯。敬语体系的分级适配是典型场景，日语、韩语等语言中，根据角色身份、玩家等级或交互场景的不同，需要使用不同等级的敬语，比如玩家与NPC对话时，若NPC为皇室角色需使用最高级敬语，与普通村民对话则使用普通敬语，系统通知需采用中性敬语，这就需要技术层面建立敬语分级配置表，将敬语等级与场景ID、角色属性、玩家等级进行关联，让系统能够根据实际情况动态调用对应的翻译文本，而非采用统一的翻译版本。文化禁忌词汇的过滤机制则需要结合技术与数据，通过建立多语言的禁忌词库，涵盖宗教敏感词、地域歧视词、粗俗用语等，在文本加载时进行实时检测，同时支持对接地区政策数据库，根据不同国家和地区的法规动态更新词库，比如部分中东地区禁止提及特定宗教符号，欧洲部分国家对种族相关词汇有严格限制，这些都需要通过技术手段提前规避，避免因文化差异引发的用户反感。翻译文本的校验机制同样重要，技术上可以通过设置多维度检测指标，比如文本长度阈值确保适配UI显示，关键词匹配度检测避免核心玩法信息缺失，语法规则校验减少翻译错误，文化适配度检测通过算法分析文本是否符合目标地区的表达习惯，比如中文的“吉祥如意”在英语中若直译为“lucky and as you wish”会显得生硬，需通过校验机制提示翻译人员调整为更自然的“good luck and all the best”。此外，翻译人员与开发团队的协同效率也需要技术工具支撑，搭建实时同步的文本管理平台，支持多人在线编辑、权限分级管理，翻译人员的修改能够实时同步到开发环境，无需通过文件传输等繁琐方式；同时加入翻译批注功能，让翻译人员可以标注文化背景、语义说明，帮助开发人员理解文本使用场景，避免因理解偏差导致的技术实现错误。版本回溯功能也不可或缺，便于在出现翻译争议或适配问题时快速恢复到之前的稳定版本，减少沟通成本和迭代周期，确保文化适配与翻译工作高效推进。</p><p>动态资源的多语言协同是容易被忽略却至关重要的环节，游戏中的音效、语音、动画、图标等非文本资源，同样需要进行本地化适配，才能让多语言版本的体验更加完整、沉浸。语音资源的适配不仅是简单的翻译录制，还需要考虑不同语言的发音时长与动画口型的匹配度，比如中文语音的节奏相对平缓，英文语音的重音突出且时长可能更短，若直接替换语音而不调整动画帧，会出现口型与语音不同步的违和感。技术上可采用两种解决方案：一是基于语音时长的帧同步调整，通过算法分析语音文件的时长，自动拉伸或压缩对应的动画帧，确保口型与发音精准匹配；二是采用骨骼动画的自适应口型设计，在制作角色动画时预留多组基础口型，根据语音的发音特征动态组合，适配不同语言的发音节奏，减少因语音替换导致的二次开发成本。图标和视觉元素的本地化则需要结合文化符号的差异，比如中国文化中的龙图腾在西方语境中可能带有负面含义，部分中东地区对猪的形象较为敏感，技术上需要支持不同地区的资源包动态切换，在游戏启动时根据用户选择的语言或设备定位，自动加载对应的视觉资源，同时要优化资源加载策略，避免因资源包过大导致的加载延迟。采用“基础资源+语言专属资源”的分包加载模式，基础资源包含通用的模型、场景素材，语言专属资源仅包含该版本对应的图标、语音、音效等，仅在切换语言时下载对应地区的专属资源，既节省存储空间，又提升加载效率。音效的本地化也不容忽视，不同地区的玩家对音效的接受度存在差异，比如东亚玩家更习惯清脆的技能音效，欧美玩家则偏好厚重的打击音效，技术上可以通过音效参数的动态调整，让音效与对应语言的表达习惯相契合，同时支持玩家自定义音效音量、音色，满足不同用户的个性化需求。此外，动画中的文字元素也需要进行本地化处理，比如剧情动画中的匾额、海报文字，需要提前预留文本替换接口，确保切换语言后动画中的文字能够同步更新，避免出现“中文动画配英文文本”的违和场景。</p><p>本地化测试的技术闭环是确保多语言版本质量的最后一道防线，其核心在于构建全面、高效的测试体系，覆盖语言准确性、功能兼容性、体验一致性等多个维度，避免因本地化问题影响游戏的市场表现。自动化测试工具的应用能够大幅提升测试效率，开发基于UI识别的自动化测试脚本，通过图像识别技术检测不同语言版本中文本显示是否正常、控件位置是否偏移、按钮点击是否有效，同时支持多设备、多分辨率的并行测试，比如同时在iOS、Android的不同机型，以及PC、主机等平台上运行测试用例，快速定位跨平台、跨语言的适配问题。脚本中可加入智能断言机制，比如预设文本显示区域的阈值，当文本超出该区域时自动标记为异常，预设控件位置的偏差范围，当控件偏移超过允许值时触发报警，减少人工测试的重复工作量。人工测试则需要聚焦于文化适配和体验细节，组织不同母语背景的测试人员进行沉浸式体验，测试人员需具备目标地区的文化认知，重点关注翻译的自然度、文化符号的适配性、操作逻辑的合理性等，比如检测日语版本中敬语使用是否准确，阿拉伯语版本中UI布局是否符合从右到左的阅读习惯。技术上可以搭建测试反馈平台，让测试人员能够快速提交问题，并关联对应的文本ID、UI控件名称或资源文件路径，同时支持上传截图、录屏，方便开发人员精准定位并修复问题。此外，灰度发布与用户反馈收集也是测试闭环的重要组成部分，通过向小范围目标用户推送多语言版本，比如按地区筛选数千名用户参与测试，收集真实场景下的使用反馈。技术上集成用户行为分析工具，追踪不同语言版本中用户的操作路径、停留时长、报错频率、核心功能使用率等数据，通过数据分析发现潜在的本地化问题，比如某一语言版本中用户在任务界面的停留时长明显过长，可能是由于文本表达晦涩导致玩家无法理解任务要求；某一版本的退出率异常偏高，可能是UI适配不佳影响操作流畅度，进而针对性地进行优化迭代。同时，要建立本地化版本的快速迭代机制，利用热更新技术确保测试中发现的问题能够及时修复，无需用户重新下载完整安装包，修复后通过二次测试验证效果，形成“测试-反馈-优化-再测试”的技术闭环。</p>]]></description></item><item>    <title><![CDATA[有远见的长期主义者 留胡子的饼干_dli]]></title>    <link>https://segmentfault.com/a/1190000047406295</link>    <guid>https://segmentfault.com/a/1190000047406295</guid>    <pubDate>2025-11-17 23:02:14</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>从生成式 AI 的惊艳亮相引起全球科技巨头军备竞赛般的投入开始，整个 AI 行业仿佛被注入了无限的想象力。似乎在宣告着即将出现一个生产力即将被彻底解放、商业模式即将被完全颠覆的光明未来。<br/>微软、谷歌、亚马逊等云巨头纷纷将资本支出的绝大部分押注于 AI 基础设施建设，而无数逐利而来的 AI 初创公司，更是如雨后春笋般涌现试图分一杯羹，全球 AI 领域的投资额也达到了史无前例的高度。<br/>然而，正如任何过热的淘金热最终都会迎来冷静期当技术以超乎预期的速度普及时，潜在的负面效应也以同样的速度被放大，正在悄然侵蚀着行业参与者。<br/>从 " 可选项 " 到 " 必选项 " 的巨额支出<br/>根据奇安信集团对外发布《2024 人工智能安全报告》来看，在 2023 年基于 AI 的深度伪造欺诈便已暴增了 3000%，基于 AI 的钓鱼邮件也增长了 1000%；而内容生成环节更是实现规模化生产。<br/>基于 Stable Diffusion 和 GPT-4 的定制模型，可每小时生成 2000 条伪原创研报、800 段逼真视频。暗网平台 "DarkGPT" 更是提供包月服务，1 万美元即可获得每日 5000 条金融虚假内容的产能。<br/>而且 "AI 滥用 " 的后遗症并不仅仅在社会新闻版块，可以说它已经穿透了科技公司的防火墙直接作用于其财务报表。而金融行业正是这场风暴的中心，当 AI 以假乱真的能力被精准地应用于金融诈骗时，其破坏力可以说是指数级的增长。<br/>据行业估算，2024 年由深度伪造技术引发的各类欺诈造成的全球经济损失已高达 120 亿美元。尤其在监管相对滞后、交易更为匿名的加密货币领域，AI 滥用更是如鱼得水。根据相关的报告也显示 2024 年仅 AI 深度伪造技术全年造成的损失便高达 46 亿美元。<br/>随着 AI 滥用事件的频发，过去模糊的 " 伦理指南 " 正在迅速转变为具有强制约束力的法律条文，而且这种转变直接导致了企业合规成本的急剧攀升。<br/>而且一旦出现违规需要付出的代价更是惨痛的，罚款最高可达全球年营业额的数个百分点或数千万欧元，而且合规也不再是法务部门的单一工作，而是渗透到研发、产品、市场的每一个环节。<br/>这些 " 反噬 " 也并非凭空产生，在 AI 商业化过程中对速度和规模的追求，长期以来压倒了对安全和伦理的考量所以形成了这种 " 原罪 "。因此未来合规成本的升高是不可避免的，而欧盟的《AI 法案》可以说是这一趋势的先行者。<br/>该法案于 2024 年 8 月 1 日正式生效并分阶段实施，着重对高风险的 AI 系统施加了严格的合规要求。而且这不仅仅是一项区域性法规，更可能产生 " 布鲁塞尔效应 " 从而影响全球的 AI 监管格局。<br/>监管的落地也将会直接转化为企业的合规成本。据公开信息推算，仅欧盟 AI 法案便可能导致欧洲企业的 AI 采纳成本增加约 310 亿欧元，并使 AI 投资减少近 20%。而美国联邦贸易委员会也已对 OpenAI 展开调查，谷歌等公司也不得不调整其营销话术，避免被处以巨额罚款。<br/>可以说 " 监管的铁幕 " 正在迫使整个行业从过去 " 快速行动，打破陈规 " 的互联网思维转向一种更为审慎、合规驱动的开发模式。可以说这种转变无疑会减缓创新速度并增加运营成本，对于那些资源有限的中小企业和初创公司构成尤为严峻的挑战。<br/>对 " 信任 " 的侵蚀或许是 AI 滥用最难修复的一种<br/>这源于在激烈的竞争压力下，企业急于抢占市场将产品快速推向用户，所以将风险控制和安全测试置于次要位置。但是这种 " 快速行动并打破规则 " 的心态在 AI 时代尤为危险，因为 AI 技术的潜在破坏力远超以往的软件应用。<br/>并且市场对于 AI 技术的可靠性极度敏感，甚至一次小小的失误都可能引发巨大的信任危机和财务损失。谷歌的 Bard 模型之前便在一次演示中出现事实性错误，竟然导致其母公司 Alphabet 的股价在单日内暴跌 7%，市值蒸发超过 1000 亿美元。<br/>并且随着 AI 投资的巨额支出持续攀升，投资者开始担忧其回报前景，这种悲观情绪导致 Meta、Microsoft、Alphabet 和 Nvidia 等 AI 领域的领军企业股价普遍承压下跌，市场也开始讨论 "AI 泡沫 " 的风险，并开始质疑哪些不计成本的 " 军备竞赛 " 式投资。<br/>更何况大量公司缺乏对 AI 伦理的明确责任归属，高管层面也并未对其有所调整。所以 AI 系统的决策过程像一个 " 黑箱 "，在责任主体模糊的情况下滥用和误用的风险便难以控制。企业内部也未建立有效的问责机制。<br/>但是更深层次的原因在于当前主流生成式 AI 商业模式本身所内含的风险。这些模型依赖于海量数据的投喂，其训练过程难以完全避免偏见和有害信息的吸收。而其强大的生成能力却为恶意利用提供了温床。<br/>因此当商业模式的核心是追求更强大的模型、更广泛的应用时，如果缺乏与之匹配的强大 " 安全刹车 " 系统，滥用就成了可预见的副产品。这种商业逻辑与伦理要求之间的结构性失衡才是导致 " 反噬 " 的根本内因。<br/>所以当企业享受了技术红利带来的增长，如今便也不得不为其模式所伴生的风险 " 买单 "。哪怕科技公司以 " 让世界更美好 " 的叙事推广 AI，公众在实际体验中，也会频繁受到隐私泄露、算法偏见、就业替代、虚假信息等负面影响。<br/>这种落差也导致了广泛的 "AI 焦虑 " 和不信任感。公众普遍认为现有的监管法规不足以应对 AI 带来的社会风险期望政府采取更加果断的行动。这种强大的民意压力也是推动监管机构加速行动的根本动力。<br/>面对公众的呼声和潜在的社会风险，监管机构的介入是必然的。但由于技术发展的速度远超立法速度监管往往表现出一定的滞后性，欧盟 AI 法案便被部分人士认为可能增加企业负担、抑制创新。<br/>全球主要经济体在 AI 领域的竞争，也使得监管变得更加复杂。各国都希望在鼓励创新和防范风险之间找到平衡点但这种平衡点的位置各不相同，因此形成了复杂的国际监管格局给跨国企业的合规带来了巨大挑战。<br/>而且这种外部滥用对整个 AI 行业的声誉造成了 " 连坐 " 效应。即使一家公司本身恪守伦理，也无法完全独善其身，因为公众对 AI 的信任是整体性的。恶意滥用行为如同向池塘中投下的毒药，在污染了整个水域后迫使所有 " 池中生物 " 共同承担后果。<br/>这场危机成为 AI 自我革新的契机<br/>这场 " 反噬 " 带来的阵痛，是 AI 产业从野蛮生长走向规范发展的必经阶段。它正在淘汰那些只想赚快钱、缺乏责任感的 " 玩家 "，筛选出真正有实力、有远见的长期主义者。从长远来看，这也是为 AI 产业的健康、可持续发展所必须付出的代价。<br/>其中最大的机遇在于将 " 信任 " 从一种道德呼吁，转变为一种可量化、可变现的商业资产和竞争壁垒。数据显示近 85% 的客户也更愿意与重视 AI 伦理实践的公司合作，而那些优先考虑伦理和透明度的公司收入增长也更快。<br/>可以说在 AI 产品同质化日益严重的未来，谁能赢得用户的信任谁就能赢得市场。" 负责任的 AI" 将不再仅仅是公关部门的口号，而是必须贯穿于产品设计、开发、部署全流程的核心战略。<br/>谷歌和微软等公司已经开始调整其策略，谷歌选择利用 AI 技术提升广告安全审核的效率，打击欺诈内容；微软则发布了负责任 AI 透明度报告，并推出了 AzureAIContentSafety 等服务，帮助客户构建更安全的 AI 应用。这些举措既是应对风险的防御，也是在构建新的竞争优势。<br/>正是 " 反噬 " 催生了全新的 " 安全即服务 " 市场。随着 AI 滥用风险的加剧企业对 AI 安全审计、风险评估、内容过滤、合规咨询等服务的需求将急剧增长。这为专门从事 AI 安全和伦理治理的科技公司、咨询机构创造了巨大的市场空间。<br/>而科技巨头自身也可以将其内部成熟的安全工具和能力平台化、服务化，开拓新的收入来源。例如，谷歌和微软在内容审核、风险识别方面的技术积累，完全可以转化为对外输出的商业服务。<br/>虽然监管的收紧虽然带来了成本，但也为行业设定了 " 准入标准 "，能够率先满足高标准合规要求的企业将获得更强的市场公信力和竞争优势，从而在未来的市场整合中占据有利地位。这实际上是一种由监管驱动的市场出清和格局优化。weibo.com/ttarticle/p/show?id=2309405233995679137906<br/>weibo.com/ttarticle/p/show?id=2309405233995817549851<br/>weibo.com/ttarticle/p/show?id=2309405233995951767682<br/>weibo.com/ttarticle/p/show?id=2309405233996090179688<br/>weibo.com/ttarticle/p/show?id=2309405233996807405670<br/>weibo.com/ttarticle/p/show?id=2309405233996946079868<br/>weibo.com/ttarticle/p/show?id=2309405233997084229682<br/>weibo.com/ttarticle/p/show?id=2309405233997218447497<br/>weibo.com/ttarticle/p/show?id=2309405233998128873660<br/>从滥用事件的激增，到资本市场的审慎，再到全球监管的收紧，这股 " 反噬 " 之力正在重塑 AI 产业的发展轨迹。它迫使整个行业从过去对技术力量的无限崇拜，转向对技术责任和社会价值的深刻反思。<br/>麦肯锡预测，到 2030 年 AI 将为全球经济创造 13 万亿美元价值。但价值分配取决于我们如何驾驭这头猛兽。未来的竞争，将不仅仅是模型参数和算力大小的竞争，更是治理能力、责任担当和用户信任的竞争。</p>]]></description></item><item>    <title><![CDATA[灵宇宙获 2 亿新融资，要做 AI 世界]]></title>    <link>https://segmentfault.com/a/1190000047406302</link>    <guid>https://segmentfault.com/a/1190000047406302</guid>    <pubDate>2025-11-17 23:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406304" alt="" title=""/></p><p>开发者朋友们大家好：</p><p>这里是 <strong>「RTE 开发者日报」</strong> ，每天和大家一起看新闻、聊八卦。我们的社区编辑团队会整理分享 RTE（Real-Time Engagement） 领域内「有话题的 <strong>技术</strong> 」、「有亮点的 <strong>产品</strong> 」、「有思考的 <strong>文章</strong> 」、「有态度的 <strong>观点</strong> 」、「有看点的 <strong>活动</strong> 」，但内容仅代表编辑的个人观点，欢迎大家留言、跟帖、讨论。</p><p>本期编辑：<a href="https://link.segmentfault.com/?enc=QeQ2YuFoRoQz%2FBz%2F2ewZZg%3D%3D.kpc04s7lDJ3MB3oQw3ZoVPEVCldJ6MqIPKZv9dgppR4%3D" rel="nofollow" target="_blank">@鲍勃</a></p><h2>01 有话题的技术</h2><p><strong>1、 Vogent 推出 AI 语音智能体向导：描述即生成，分钟级部署语音智能体</strong></p><p>Vogent 发布了 Voice Agent Wizard，旨在通过简化语音 AI 应用的开发流程，大幅缩短开发周期并降低技术门槛。用户只需提供描述和相关文件，即可在短短几分钟内生成一套完整、可部署的语音智能体。</p><ul><li><strong>描述驱动生成：</strong> 借助自然语言描述语音智能体的功能和目标，并上传少量参考文件（如对话记录），AI 便能自动完成构建。</li><li><strong>海量数据训练：</strong> 该向导基于对数千个真实语音智能体设计过程的学习，深刻理解语音 AI 在实际生产环境中的运作原理。</li><li><strong>全流程自动化：</strong> AI 不仅能自动选择合适的架构、优化参数、生成系统提示，还能预测和处理潜在的边缘情况，实现全流程自动化。</li><li><strong>开发周期显著缩短：</strong> 过去需要数周甚至数月的试错和配置工作，现在仅需几分钟即可完成，从而显著加速产品上市时间。</li><li><strong>赋能快速迭代：</strong> 用户可以即时测试新的应用场景，并根据用户反馈进行实时迭代，将精力集中于产品本身，而非底层基础设施。</li></ul><p>Vogent 的 AI 语音智能体向导现已上线，用户可通过 app.vogent.ai 访问并开始使用。</p><p>(<a href="https://link.segmentfault.com/?enc=Ur9MJYX3MO%2BBgTimujuDig%3D%3D.LWu4c%2BM7zWISCHyrTal6w2KbCIHgcVYZVMBGfEtabKQ%3D" rel="nofollow" target="_blank">@Y</a> Combinator)</p><p><strong>2、Talo 被 Palabra.ai 收购，整合打造全场景 AI 实时语音翻译平台</strong></p><p>Talo 在被 Palabra.ai 收购后，正式整合并发布了其全方位的 AI 实时语音翻译平台。此次整合旨在打破语言障碍，提供从视频通话到直播、线下活动及 API 集成的无缝跨语言沟通解决方案。</p><ul><li><strong>全场景覆盖：</strong> Talo 现已支持视频通话、网络研讨会、线下活动、直播广播以及通过 API 集成，满足多样化的翻译需求。</li><li><strong>核心技术升级：</strong> 实时视频通话翻译能力大幅提升，用户体验更为自然流畅。</li><li><p><strong>新增功能：</strong></p><ul><li>Palabra Events 支持网络研讨会和线下活动的实时翻译。</li><li>Palabra Broadcaster 提供直播广播的即时语音翻译。</li></ul></li><li><strong>开发者平台：</strong> 推出 API 平台，赋能开发者构建自定义的翻译应用。</li></ul><p>(@ Producthunt)</p><h2>02 有亮点的产品</h2><p><strong>1、Proxis：AI 邮件智能体，以你的语调风格撰写邮件</strong></p><p>Proxis 推出一款 AI 邮件智能体，能够连接用户的知识库和收件箱，模仿其邮件风格和语调，自动草拟并发送邮件。该工具旨在解决日益增长的邮件数量和信息处理难题，尤其适用于需要高强度邮件沟通的销售、运营及创始人等用户。</p><ul><li><strong>个性化邮件草拟：</strong> Proxis 能够学习用户的语调和风格，生成听起来「像你本人」的邮件回复。</li><li><strong>语境优先：</strong> 可连接 CRM、Notion、Drive、Slack、帮助文档以及历史邮件，确保回复内容准确且符合品牌调性。</li><li><strong>智能发送机制：</strong> 仅在 AI 拥有高置信度时自动发送邮件，其他回复则保留在草稿箱供用户审核。</li><li><strong>持续学习：</strong> 用户的每一次发送和反馈都会帮助 AI 更好地学习和适应其沟通方式。</li><li><strong>规则配置：</strong> 用户可配置特定的规则来指导 AI 的行为。</li></ul><p>(<a href="https://link.segmentfault.com/?enc=jksukqSSAX64q43T9WN7cA%3D%3D.uZBQ8pO16zuSSEPxq1UaViNpL3feXCihOUEHAbrfGx4%3D" rel="nofollow" target="_blank">@Y</a> Combinator)</p><p><strong>2、Willow 发布 iOS 智能语音键盘，实现「边说边改」的无缝输入体验</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406305" alt="" title="" loading="lazy"/></p><p>Y Combinator 孵化的初创公司 Willow 发布了一款 iOS 智能语音键盘应用，支持在所有 App 中进行高效的语音输入。与传统语音转录工具不同，Willow 将完整的键盘与语音输入集成，解决了语音输入后「编辑困难」的核心痛点，旨在提供一种更高效、更自然的移动端输入方式。</p><ul><li><strong>全功能键盘集成：</strong> Willow 的最大优势在于它是一个完整的键盘，而非单纯的语音输入面板。用户可以在语音转录后，无需切换键盘，直接进行光标移动、文字修改和输入，极大地提升了编辑效率。这一点是其与竞品 Wispr Flow 的核心差异。</li><li><strong>基于 LLM 的个性化引擎：</strong> 该应用支持超过 100种语言，并允许用户自定义专业词汇和写作风格（例如，区分工作、邮件、即时消息等场景）。其技术栈基于一系列模型，并重点调优了基于 Meta Llama 模型的文本到文本（text-to-text）管线，以实现精准的格式化与个性化。</li><li><strong>强劲的商业势头：</strong> 自发布以来，Willow 的用户量实现了每月 50% 的增长，并已获得包括 Uber、Heidi Health 等在内的企业客户。公司已获得由 Box Group、Y Combinator 以及 Reddit 联合创始人 Alexis Ohanian 等知名投资方提供的 450 万美元融资。</li><li><strong>超越听写的长期愿景：</strong> 在桌面端，Willow 还提供名为「Hey Willow」的语音助手，可以执行更复杂的指令，如用用户的语气风格撰写邮件回复。其长期目标是构建一个能通过语音控制计算机的下一代人机交互界面。</li></ul><p>(@TechCrunch)</p><p><strong>3、灵宇宙获 2 亿新融资，要做 AI 世界操作系统</strong></p><p>「暗涌 Waves」获悉，灵宇宙近日完成 2 亿元 PreA 轮融资，由上海国际集团旗下国方创新、国泰海通、广发信德、滴滴出行、拉卡拉旗下考拉基金、润建股份等金融机构和上市公司参投，老股东超额追投。</p><p>「如果 AI 要进入生活，它一定得从家庭和随身场景开始理解人，而全球化是这类产品的自然方向。」顾嘉唯告诉「暗涌 Waves」，Luka 时代资本火热，大家都在冲机器人。但那时的底层模型没准备好、硬件也太贵，做终端就是在「逆风走钢丝」。现在完全不一样了，模型成熟了、基础成本降下来、交互方式变了，「AI 开始真正进入物理世界。」</p><p>基于这样的判断，大模型到来后顾嘉唯创立灵宇宙，这并非简单的二次创业，而是将其坚守十余年「万物有灵」的核心理念置于大模型时代的新基座上重新出发。不再只是单一爆款产品，目的打造一个面向下一代 AI 终端的操作系统生态，让机器真正具备感知、共情与主动交互的 「灵性」。</p><p>但 AI 硬件并不是顾嘉唯的终极目标。他想把验证有效的模型推向规模化，不再只是做陪伴机器，而是构建一个能在全球不同家庭中运行的人机交互系统------从 AI 伴读的单点突破，到面向全球家庭的具身智能系统化实验。</p><p>灵宇宙的关键引擎在于其自主研发的 LingOS 交互操作系统，而 LingOS 的核心价值在于其可迁移性------它不是一个被绑定在特定硬件上的固件，而是一个能够注入不同形态终端（从随身设备到家用消费机器人）的「AI 灵性」及「机器人灵魂」，通过持续收集的真实世界交互数据不断进化。在他的理想中，LingOS 不会局限于单一场景的智能响应，而是要成为跨越地域、文化与年龄的 「通用 AI 灵性接口」。</p><p>在顾嘉唯看来，「硬件只是接口，系统才是核心。」而从发展路径上看，系统的价值需要在更大市场------尤其是海外市场被验证和放大。</p><p>（<a href="https://link.segmentfault.com/?enc=i3fSBRny18YUGC6QOhInAw%3D%3D.13ozBx6CwHnTYJfNLOHucGCshUR3KtBVzcaO8dBmJcMTakkUvPCKdsVssXHI%2FsjF" rel="nofollow" target="_blank">@暗涌</a> Waves）</p><p><strong>4、前云鲸产品副总裁李阳创业，聚焦陪伴具身赛道</strong></p><p>雷峰网·鲸犀独家获悉，前云鲸智能产品副总裁李阳（Roger）离职后创业，成立公司「Ouropia」，主攻家庭陪伴具身领域，该项目将聚焦内容情绪消费与物理实体陪伴，通过深度情感交互实现 Physical AI 的家庭场景进入问题。</p><p>目前，李阳的创业项目已完成种子轮融资，获数千万美元融资。据了解，Ouropia 的首款产品将通过具身方式实现深度情绪交互和内容消费，产品将面向北美市场，预计客单价将处于较高区间。</p><p>另据雷峰网了解，Ouropia 创始团队包括来自大疆、影石、字节、清华的机器人和认知领域专家，以及知名产品设计团队，是一支磨合多年的成熟产品工程团队。李阳早年曾在大疆担任动力系统专家，后相继负责 Mavic 系列产品、教育机器人产品及自动驾驶相关业务，于 2021 年离开大疆加入云鲸。在云鲸期间担任产品副总裁，负责产品设计、研发工程管理、质量等工作，在团队中具有重要影响力。</p><p>（@雷峰网）</p><h2>03 有态度的观点</h2><p><strong>1、 李彦宏回应百度总是「起大早赶晚集」：不能指望所有创新都成功，创新的特点就是大多数会失败</strong></p><p>11 月 16 日消息，在 2025 百度世界大会后，百度创始人李彦宏接受媒体采访。在采访中，李彦宏谈到了一个外界非常关注的话题：「当然，别人说我们『起大早赶晚集』，这不冒犯，一些也是事实。甚至我在内部也让大家研讨说，我们为什么会『起大早赶晚集』。」</p><p>李彦宏表示：「我们不能够指望所有的创新尝试都是成功的，创新的特点就是，大多数创新会失败，我们要接受这样一个现实。所以百度内部可能起过十个不同的创新项目，如果九个都失败了，我认为是很正常的，它就应该失败，从概率上讲就应该失败，如果有一个成功了，那就非常好。」</p><p>李彦宏还说：「另外一方面，百度这些年有做成的、有做失败的。如果有什么规律性的话，当这件事的成败几乎完全取决于它技术的先进性的时候，我们的成功概率就会大不少，尤其是这个技术需要很多很多年的投入和迭代，那我们成功的概率就会更大一些。」</p><p>（@潇湘晨报）</p><h2>04 社区黑板报</h2><p>招聘、项目分享、求助......任何你想和社区分享的信息，请联系我们投稿。（加微信 creators2022，备注「社区黑板报」）</p><p><strong>1、招聘实习生丨加入我们，共建 RTE 开发者社区</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406306" alt="" title="" loading="lazy"/></p><p><strong>RTE 开发者社区·运营实习生（实时互动 / Voice AI 方向，本招聘长期有效）</strong></p><p><strong>地点：北京·朝阳区望京南/上海·杨浦区五角场</strong></p><p><strong>这份实习将给你带来：</strong></p><p>**产品与技术成长：**深入学习垂类 AI 产品从技术到落地的全生命周期，构建全面的产品视角。</p><p>**社区运营实战：**与高潜力的开发者和创业者深度交流，共同探索行业前沿；并亲身体验顶级 AI 大会，拓展行业视野。</p><p><strong>【你的职责】</strong></p><p><strong>Voice AI / RTE 情报官：</strong> 每日关注 Voice AI /实时互动领域的最新动态，提炼整理并分享行业洞察，定期撰写学习笔记，帮助团队和社区保持信息前沿。</p><p><strong>社区连接者：</strong> 负责 RTE 领域开发者、初创企业等核心群体的社群运营，主动建立并深化联系，鼓励并协助他们融入社区，共同维护社区的活力与生态。</p><p><strong>活动协作者：</strong> 深度参与 RTE Open Day、Meetup、Dev Talk 等线上线下活动的全流程运营，包括前期策划、中期执行、后期复盘，从实践中提升组织和协调能力。</p><p><strong>行业洞察者：</strong> 协助开展 RTE 相关行业及应用场景调研、产品竞争力分析，整理相关资料，形成对业务的深入理解和独到见解。</p><p><strong>【希望你】</strong></p><p>1.本科及以上学历，商业、技术、产品、媒体专业或经验背景优先，具备良好英文能力；</p><p>2.对 RTE / Voice AI 有浓厚兴趣和求知欲；具备优秀的信息收集与整合能力，乐于快速学习新事物，并具备严谨的逻辑思维。</p><p>3.能保证每周至少 4 天的工作时间，持续 3 个月以上。</p><p><strong>【薪资】</strong></p><p>180-220 元/天</p><p><strong>【投递方式】</strong></p><p>实习地点北京或上海，请将简历发送至 <a href="mailto:rtedevcommunity@gmail.com" target="_blank">rtedevcommunity@gmail.com</a> ；邮件标题请注明：【社区运营实习-姓名-学校-毕业年份-到岗日期-城市】</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406307" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047406308" alt="" title="" loading="lazy"/></p><p><a href="https://link.segmentfault.com/?enc=cF9Ps%2BYnpt%2F5CARsTqINWQ%3D%3D.yyvD26vluuLvojYJmuEf6AxbShf3ilE2KDTf0n9IHos%3D" rel="nofollow" target="_blank">阅读更多 Voice Agent 学习笔记：了解最懂 AI 语音的头脑都在思考什么</a></p><p><strong>写在最后：</strong></p><p>我们欢迎更多的小伙伴参与**「RTE 开发者日报」**内容的共创，感兴趣的朋友请通过开发者社区或公众号留言联系，记得报暗号「共创」。</p><p>对于任何反馈（包括但不限于内容上、形式上）我们不胜感激、并有小惊喜回馈，例如你希望从日报中看到哪些内容；自己推荐的信源、项目、话题、活动等；或者列举几个你喜欢看、平时常看的内容渠道；内容排版或呈现形式上有哪些可以改进的地方等。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406309" alt="" title="" loading="lazy"/></p><p>素材来源官方媒体/网络新闻</p>]]></description></item><item>    <title><![CDATA[TOON：专为 LLM 设计的轻量级数据]]></title>    <link>https://segmentfault.com/a/1190000047406174</link>    <guid>https://segmentfault.com/a/1190000047406174</guid>    <pubDate>2025-11-17 22:02:19</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>这几天好像这个叫 TOON 的东西比较火，我们这篇文章来看看他到底是什么，又有什么作用。TOON 全称 Token-Oriented Object Notation，它主要解决的问题就是当你把JSON 输入给LLM 的时候，token 消耗太高了。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047406176" alt="" title=""/><br/>一个长 JSON 数组扔进模型token 计数直接起飞。因为引号、大括号、重复的键名，到处都是这些没什么实际意义的字符，而TOON 就是从这个痛点出发，它不是要干掉 JSON，而是说：既然主要是语言模型，那些装饰性的字符完全可以省掉。</p><h2>Token数对比</h2><p>常规 JSON 长这样：</p><pre><code> [  
   { "id": 1, "name": "Deep", "role": "admin" },  
   { "id": 2, "name": "Hub", "role": "user" }  
 ]</code></pre><p>TOON 版本：</p><pre><code> users[2]{id,name,role}:  
   1,Deep,admin  
   2,Hub,user</code></pre><p>第一眼看上去像半成品草稿。但逻辑其实很清晰——字段名只写一次，声明有多少行，然后直接按表格形式写数据，我们直接可以说这个算是CSV的一个进化版。</p><p>有一个不严谨的测试JSON 格式的 token 数基本是 TOON 的两倍。差距就这么大。</p><h2>TOON</h2><p>JSON 的问题是结构不变的情况下还在重复。而TOON的想法是既然结构本来就很明显了，没必要每条记录都写一遍。</p><p>另外就是该有得支功能还是都有，比如说嵌套，使用类似 YAML 的缩进结构来处理嵌套对象：</p><pre><code> user:
   id: 123
   email: ada111@666.com
   metadata:
     active: true
     score: 4.5</code></pre><p>简单得嵌套跟YAML 基本一样，如果把嵌套和列表放在一起就是这样：</p><p>比如说这个json</p><pre><code> {
  items: [
    {
      users: [
        { id: 1, name: 'Deep' },
        { id: 2, name: 'Hub' }
      ],
      status: 'active'
    }
  ]
 }</code></pre><p>转换完以后是这样的</p><pre><code> items[1]:
   - users[2]{id,name}:
     1,Deep
     2,Hub
     status: active</code></pre><p>这完全就是YAML 和CSV的缝合怪，不过倒是把JSON冗余的标点去掉了。</p><p>不过根据官网的评测token的确是减少了很多<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047406177" alt="" title="" loading="lazy"/></p><h2>局限性</h2><p>对于YAML来说深层嵌套的数据结构一直是个问题，而TOON也一样，如果层次太多会比较乱。而且同一个列表里如果对象结构不一致，也不太好处理。但是如果只是为了优化 LLM prompt，TOON还真的确实挺实用。</p><h2>总结</h2><p>适合用 TOON 的情况：</p><ul><li>往模型里塞大量重复结构的数据</li><li>token 成本是主要考虑因素</li><li>数据结构相对规整</li></ul><p>继续用 JSON 的情况：</p><ul><li>写 API 接口</li><li>需要长期存储</li><li>数据结构复杂或者不规则</li></ul><p>所以TOON并不是什么颠覆性的东西。更像是有人把 JSON 里那些多余的部分清理掉，然后说：跟模型交互的时候，可以试试这个。</p><p>github地址：</p><p><a href="https://link.segmentfault.com/?enc=5toVUX%2BwxAJfSlU30fTAng%3D%3D.4GTYXlrrTVkxbaoXEjPdX5dm%2BaaTidyxrXC%2Bmm7C3nAv6Zkks%2F6x397obn18vq3pb9NpOjZu42FcBnyaBjlo9Q%3D%3D" rel="nofollow" target="_blank">https://avoid.overfit.cn/post/95264c51c6544c139b198c31fe4127ab</a></p>]]></description></item><item>    <title><![CDATA[AI 面试智能体：降本增效的招聘新利器 ]]></title>    <link>https://segmentfault.com/a/1190000047406181</link>    <guid>https://segmentfault.com/a/1190000047406181</guid>    <pubDate>2025-11-17 22:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>AI 面试智能体：降本增效的招聘新利器<br/>当预算遭遇腰斩：AI面试如何成为HR降本增效的“破局利器”？<br/>培训预算削减的背后，是时候重新审视招聘的真正成本。<br/>年底复盘，不少HR对着培训报表愁眉不展：预算花了近百万，员工满意度刚过及格线，业务部门还抱怨“培训没用”。降本增效的要求之下，培训预算首当其冲被压缩。问题真的出在培训本身吗？或许，根源在于招聘环节——选错人，才是企业最大的成本浪费。</p><p>01 培训无效的背后：选错人是最昂贵的成本<br/>当业务部门抱怨“培训没用”时，他们真正抱怨的是什么？是培训内容不够好，还是培训对象选错了？<br/>一位资深HR总监坦言：“我们花大价钱培训员工，却发现有些人根本不适合岗位。这种错配的成本，远超培训预算本身。”传统招聘依赖HR和专业面试官的主观判断，难免出现偏差。而AI面试智能体正将招聘从“凭感觉”推向“凭数据”的科学决策时代。<br/>02 精准度革命：从“参考意见”到“决策依据”<br/>招聘的核心是“选对人”，AI面试智能体将“精准度”做到了行业领先水平。<br/>其打分结果不仅通过效标效度与重测稳定信度的双重心理学指标考验，更经得起一对一的“背靠背”人机对比实验验证。这意味着，AI面试智能体的评估结果不再仅是参考意见，而是可直接作为招聘决策的依据。相关AI面试智能体的迭代版本发布，标志着其在该领域已达到国际领先水平，这是经得起验证的技术实力体现。<br/>03 面试环节的精准进化：四大技术突破<br/>AI面试智能体的“精准”体现在每一个招聘环节的技术突破上：<br/>•一问多能：一道题目即可同步评估多项胜任力，无缝衔接HR初筛与技术复试，评估效率提升50%以上。<br/>•自由追问：能根据候选人的回答即时生成针对性问题，如同资深面试官般抓住关键信息，避免遗漏核心能力。<br/>•简历深度挖掘：自动抓取简历中的关键信息与模糊点，生成递进式提问，既杜绝信息造假，也避免因HR主观疏忽错过优质候选人。<br/>•全维度考察：既能评估沟通、协作等通用胜任力，也能针对编程、算法、工程、财务等专业领域精准出题，在解放HR面试官的基础上进一步解放专业面试官。<br/>04 候选人体验升级：招聘即品牌传播<br/>传统AI面试常因“机械、生硬”让候选人体验不佳，进而损害雇主品牌。AI面试智能体则把“拟人化交互”做到了极致，让面试成为雇主品牌的加分项。<br/>•懂情绪的智能交互：精准捕捉候选人的语速、情绪与潜台词，像真人HR一样引导候选人充分展现实力，避免因紧张发挥失常。<br/>•无断点流畅体验：无需手动点击“开始/结束答题”，系统自动识别回答状态并衔接下一问题，全程如面对面交流般自然。<br/>•沉浸式视觉体验：通过语音与口型匹配精度的大幅提升，嘴型开合与语速节奏精准同步，彻底告别“纸片人”式的疏离感。<br/>•多轮对话答疑：允许候选人随时提问，AI能准确解答职位信息、公司福利等问题，让候选人更深入了解企业，提升入职意愿。<br/>05 全流程自动化：从识人到沟通的一体化执行<br/>AI人才寻访智能体是一款具备简历解读、精准匹配、有效沟通能力的AI招聘工具。<br/>它并非单一功能的自动消息助手，而是一套完整的招聘自动化系统，可在无需人工干预的情况下，独立完成从简历筛选、初步沟通、简历回收到系统同步的完整流程。从30-60秒完成初始化，到自动筛选简历、动态沟通、全覆盖回复，再到系统同步，AI人才寻访智能体实现了招聘初筛阶段的全面自动化，提升招聘效率10到100倍。<br/>培训预算削减不一定是危机，也可能是转型的契机。当传统的培训投入回报率持续走低，聪明的HR已经开始将资源前置到招聘环节——从源头上确保“选对人”。与其在培训无效后追悔莫及，不如在招聘环节精准筛选。毕竟，选择比努力更重要，选对比选择更关键。</p>]]></description></item><item>    <title><![CDATA[SQL Server 2022 企业版I]]></title>    <link>https://segmentfault.com/a/1190000047406047</link>    <guid>https://segmentfault.com/a/1190000047406047</guid>    <pubDate>2025-11-17 21:01:57</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>​</p><p>一、准备工作</p><ol><li><p><strong>确认系统要求</strong></p><ul><li>你电脑得是 <strong>Windows 10/11 专业版/企业版，或者 Windows Server 系统</strong>，而且必须是 <strong>64位</strong>的。</li><li>最好有 <strong>管理员权限</strong>（就是能安装软件那种账号）。</li></ul></li><li><p><strong>挂载 ISO 文件</strong>（就是打开这个光盘镜像文件）</p><p>方法：</p></li><li><ul><li><p>安装包下载：<a href="https://link.segmentfault.com/?enc=BVcmb2k72%2BXxnwhgPMQEfQ%3D%3D.yC5ptv7wf7YtQkAqtN9zcrcC1PxL1DCLAIfnRJFNSHKl%2Bls6427XcZuqHj2UBujw" rel="nofollow" title="https://pan.quark.cn/s/d83b749b87e5" target="_blank">https://pan.quark.cn/s/d83b749b87e5</a></p><p><strong>双击这个 ISO 文件</strong>，Windows 一般会自动挂载，就像插了个虚拟光盘。</p></li><li>或者右键点击 ISO 文件 → 选择  <strong>“装载”</strong> 。</li><li>挂载后，你会在  <strong>“此电脑”</strong> 里看到一个 <strong>虚拟光驱</strong>，点进去就能看到里面的安装文件。</li></ul><blockquote>如果你电脑不支持直接双击挂载，可以用压缩软件（比如 WinRAR、Bandizip）打开，或者下载个 <strong>虚拟光驱工具</strong>（比如 Daemon Tools）来挂载。</blockquote></li></ol><ul><li><ul><li>*</li></ul></li></ul><h3>二、开始安装</h3><ol><li><p><strong>进入安装界面</strong></p><ul><li>打开挂载后的虚拟光驱，找到并双击运行 <strong>setup.exe</strong>（一般就在根目录，或者 setup 文件夹里）。</li></ul></li><li><p><strong>选择安装类型</strong></p><ul><li><p>第一次打开后，一般会看到几个选项，比如：</p><ul><li><strong>全新 SQL Server 独立安装</strong></li><li><strong>添加功能到现有安装</strong></li></ul></li><li>你是新安装，就选  <strong>“全新 SQL Server 独立安装”</strong> 或者类似选项（比如 “安装” → “全新 SQL Server 独立安装”）。</li></ul></li><li><p><strong>安装程序支持规则检查</strong></p><ul><li>它会先检查你的电脑是否符合安装条件（比如有没有缺 .NET、权限够不够等）。</li><li>如果有 <strong>报错或警告</strong>，按照提示解决一下，比如安装缺的组件，再重新运行 setup。</li></ul></li><li><p><strong>输入产品密钥（如果有）</strong></p><ul><li>如果你有正版的 <strong>产品密钥（25位字符）</strong> ，就输入；如果没有，可能可以选择  <strong>“评估版”</strong> 或  <strong>“开发版”</strong> （免费试用一段时间）。</li><li>企业版通常需要密钥，如果你没有，看看你拿到的这个 ISO 是否包含授权，或者联系提供者。</li></ul></li><li><p><strong>接受许可条款</strong></p><ul><li>勾选  <strong>“我接受许可条款”</strong> ，然后下一步。</li></ul></li><li><p><strong>选择安装功能</strong></p><ul><li><p>这里会让你选要安装哪些功能，比如：</p><ul><li>数据库引擎服务（必须装，这是核心）</li><li>Analysis Services、Reporting Services（看你需要不需要）</li><li>客户端工具等</li></ul></li><li>一般新手或普通用途，<strong>数据库引擎服务</strong>是必选的，其他按需勾选。</li><li>选好后，点下一步。</li></ul></li><li><p><strong>设置实例名称</strong></p><ul><li>你可以选 <strong>默认实例</strong>（就是用电脑名作为实例名），或者自己起个 <strong>实例名</strong>（比如叫 MSSQLSERVER2022）。</li><li>大多数情况选 <strong>默认实例</strong>就行，下一步。</li></ul></li><li><p><strong>服务器配置</strong></p><ul><li>设置 <strong>SQL Server 服务用的账号</strong>，比如数据库引擎服务要用哪个用户启动。</li><li>一般选  <strong>“内置账户”</strong> ，比如 <strong>NT AUTHORITY\NETWORK SERVICE</strong>或 <strong>Local System</strong>就可以（适合个人或测试环境）。</li><li>如果是公司正式环境，可能要专门设置域账号，那得找管理员。</li><li>然后点下一步。</li></ul></li><li><p><strong>数据库引擎配置</strong></p><ul><li><p>选择 <strong>身份验证模式</strong>：</p><ul><li><strong>Windows 身份验证模式</strong>：只允许 Windows 用户登录。</li><li><p><strong>混合模式（推荐）</strong> ：可以用 Windows 用户，也可以用 SQL Server 自己的用户名和密码登录。</p><ul><li><p>如果你选混合模式，<strong>一定要设置一个 SA 密码（SQL 管理员账号密码）！</strong></p><ul><li>密码要设得 <strong>复杂一点</strong>（比如字母+数字+符号，别太简单）。</li></ul></li></ul></li></ul></li><li>把你的 <strong>Windows 用户添加为 SQL 管理员</strong>（一般会自动加当前用户，也可以手动加）。</li><li>然后点下一步。</li></ul></li><li><p><strong>继续后续配置页面</strong></p><ul><li>接下来可能还有 <strong>Analysis Services、Reporting Services</strong>的配置（如果你选了安装这些功能），按提示设置就行，一般保持默认也可以。</li><li>如果没有安装这些额外功能，可能直接跳到下一步。</li></ul></li><li><p><strong>准备安装</strong></p><ul><li>它会列出你要安装的所有功能和配置，<strong>检查一遍，没问题的话点“安装”</strong> 。</li></ul></li><li><p><strong>等待安装完成</strong></p><ul><li>这一步会真正开始安装，时间可能有点长，耐心等等。</li><li>安装过程中别关电脑或关窗口。</li></ul></li><li><p><strong>安装完成</strong></p><ul><li>安装成功后，会提示  <strong>“安装已完成”</strong> 。</li><li>你可以点  <strong>“关闭”</strong> ，然后重启电脑（建议，但不是必须）。</li></ul></li></ol><ul><li><ul><li>*</li></ul></li></ul><h3>三、安装后检查</h3><ol><li><p><strong>打开 SQL Server Management Studio（SSMS）</strong></p><ul><li>这是一个管理 SQL Server 的工具，通常需要<strong>单独下载</strong>（微软官网有免费版本）。</li><li>下载地址（可以去微软官网搜：<strong>SQL Server Management Studio 19 或 18</strong>）。</li><li><p>安装后，打开 SSMS，用以下方式连接：</p><ul><li>服务器名称：写你的电脑名 或 （如果是默认实例，就写 <code>.` 或 电脑名；如果是命名实例，写</code>电脑名\实例名`）</li><li><p>身份验证：</p><ul><li>如果你选了 <strong>Windows 身份验证</strong>，就直接用你的 Windows 账号登录；</li><li>如果你选了 <strong>混合模式</strong>，就选 <strong>SQL Server 身份验证</strong>，输入 <strong>SA 用户名 和 你设置的密码</strong>。</li></ul></li></ul></li></ul></li><li><p><strong>测试连接</strong></p><ul><li>能连上，说明 SQL Server 已经装好了，并且正常运行！</li></ul></li></ol><p>​</p>]]></description></item><item>    <title><![CDATA[申威SW64系统安装docker-ce-]]></title>    <link>https://segmentfault.com/a/1190000047406095</link>    <guid>https://segmentfault.com/a/1190000047406095</guid>    <pubDate>2025-11-17 21:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>​一、准备工作</p><ol><li><p><strong>确认系统架构是申威（SW64）</strong></p><ul><li>一般这个包就是专门为申威64位系统准备的，比如基于 <strong>银河麒麟操作系统 KY10</strong>的申威版。</li><li><p>你可以通过命令查看系统信息：</p><pre><code>uname -m</code></pre></li></ul></li></ol><pre><code>  

    如果显示是 `sw_64`或类似申威相关的，那就没问题。
</code></pre><ol><li><p><strong>下载 Docker RPM 包</strong></p><ul><li><strong>docker-ce-19.03.14.ce-3.ky10.sw_64.rpm安装包下载：</strong><a href="https://link.segmentfault.com/?enc=VQrE4uxYUeNkrytUYhvPNg%3D%3D.LvvXHobiS9K%2BExuTvugXkRvngYRMLTapQXNQQ%2BN%2FUC32MyNLgY3NcRR7mSTsQLbH" rel="nofollow" title="https://pan.quark.cn/s/d83b749b87e5" target="_blank">https://pan.quark.cn/s/d83b749b87e5</a></li><li>如果还没有，得从官方或可信渠道下载这个 <strong>针对申威架构的 RPM 包</strong>，一般后缀是 <code>.sw_64.rpm</code>，说明是为申威编译的。</li></ul></li></ol><h3>二、安装 Docker</h3><ol><li><p><strong>使用 rpm 命令直接安装</strong></p><ul><li><p>打开终端，切换到存放这个 rpm 包的目录，比如你放在了 <code>/home/yourname/</code>下，可以运行：</p><pre><code>cd /home/yourname/</code></pre></li></ul></li></ol><pre><code>-   然后执行安装命令：

    ```
    rpm -ivh docker-ce-19.03.14.ce-3.ky10.sw_64.rpm
    ```

    ![](&lt;&gt; "点击并拖拽以移动")

    -   `-i`是安装
    -   `-v`是显示详细信息
    -   `-h`是显示进度条
</code></pre><ol><li><p><strong>如果提示依赖问题</strong></p><ul><li>某些依赖包可能没装，比如 <code>container-selinux</code>、<code>docker-ce-cli</code>等。</li><li>如果你遇到类似 “依赖缺失” 的报错，可以尝试手动下载这些依赖的 <strong>申威版 RPM 包</strong>，然后一起安装。</li><li><p>或者用这个命令自动解决依赖（如果你的系统支持 yum/dnf）：</p><pre><code>rpm -ivh --nodeps docker-ce-19.03.14.ce-3.ky10.sw_64.rpm</code></pre></li></ul></li></ol><pre><code>    ⚠️ 注意：`--nodeps`是忽略依赖检查，**可能会导致功能不正常，尽量先解决依赖**。

&gt; 如果你系统里有 `yum`或者 `dnf`，并且有对应的申威源，那用 `yum localinstall docker-ce-xxxx.rpm`会更好，它会自动处理依赖关系。


</code></pre><h3>三、启动 Docker</h3><p>安装成功后，启动 Docker 服务：</p><pre><code>systemctl start docker</code></pre><p>设置开机自启（可选）：</p><pre><code>systemctl enable docker</code></pre><h3>四、检查是否安装成功</h3><p>运行以下命令，看 Docker 是否正常工作：</p><pre><code>docker --version</code></pre><p>你应该能看到类似这样的输出，表明版本信息：</p><pre><code>Docker version 19.03.14, build xxxx</code></pre><p>再运行一个测试命令，看看 Docker 服务是否真的在跑：</p><pre><code>docker run hello-world</code></pre><p>这会下载一个小的测试镜像并运行，如果看到 “Hello from Docker!” 之类的提示，那就说明 <strong>Docker 安装成功并能正常使用</strong>。</p><p>​</p>]]></description></item><item>    <title><![CDATA[动态IP如何帮助爬虫采集？IP代理有哪些]]></title>    <link>https://segmentfault.com/a/1190000047405653</link>    <guid>https://segmentfault.com/a/1190000047405653</guid>    <pubDate>2025-11-17 19:06:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在互联网数据爆炸的时代，爬虫技术成为了获取信息的重要手段。而动态 IP 在其中扮演着至关重要的角色，它能帮助爬虫高效、稳定地采集数据。同时，IP 代理也有其独特的特点，下面我们就来详细探讨。</p><p><img width="723" height="546" referrerpolicy="no-referrer" src="/img/bVdm4xs" alt="" title=""/></p><p>动态 IP 助力爬虫采集的方式</p><p>突破反爬虫机制</p><p>许多网站为了防止恶意爬虫大量抓取数据，会设置反爬虫机制。当检测到同一 IP 地址在短时间内进行频繁的访问请求时，就会将该 IP 列入黑名单，限制其访问。而动态 IP 可以在每次请求时更换不同的 IP 地址，让网站难以识别这是同一个爬虫在进行访问。例如，一个爬虫程序在采集电商网站的商品信息时，如果一直使用同一个 IP，可能在采集几百条数据后就会被封禁。但使用动态 IP 后，每次请求都像是来自不同的用户，大大增加了采集数据的数量和效率。</p><p>提高采集速度</p><p>使用动态 IP 可以让爬虫同时从多个 IP 地址发送请求，实现并行采集。就好比多个人同时去完成一项任务，速度自然会加快。比如在采集新闻网站的文章时，通过动态 IP 可以同时从不同的 IP 地址向服务器发送请求，同时获取多篇文章的内容，而不是依次等待每一个请求的响应，从而显</p><p>有些网站的内容会根据用户的 IP 地址进行地域限制。例如，某些国外的视频网站只允许特定国家或地区的 IP 访问。使用动态 IP 可以模拟不同地区的 IP 地址，让爬虫能够访问这些地域受限的内容。这样，爬虫就可以采集到更广泛的数据，为数据分析和研究提供更全面的素材。</p><p>IP 代理的特点</p><p>隐藏真实 IP 地址</p><p>IP 代理的一个重要特点就是能够隐藏用户的真实 IP 地址。当爬虫通过 IP 代理发送请求时，服务器只能看到代理 IP 的信息，而无法获取爬虫所在设备的真实 IP。这不仅可以保护用户的隐私和安全，还可以避免爬虫被追踪和封禁。例如，在进行一些敏感数据的采集时，隐藏真实 IP 可以防止被恶意攻击或法律追究。</p><p>提高网络访问的稳定性</p><p>一些网络环境可能存在不稳定的情况，例如网络拥塞、带宽不足等。使用 IP 代理可以选择网络质量较好的代理服务器，从而提高网络访问的稳定性。代理服务器通常拥有更高速的网络连接和更充足的带宽资源，能够保证爬虫请求的快速响应。此外，当一个代理服务器出现故障或被封禁时，可以及时切换到其他代理服务器，确保爬虫的正常运行。</p><p>提供匿名性</p><p>IP 代理可以为爬虫提供匿名性，让爬虫的行为更加隐蔽。在一些需要采集敏感信息或进行竞争情报收集的场景中，匿名性尤为重要。例如，在采集竞争对手的产品价格和营销策略时，使用 IP 代理可以避免被对方察觉，保护采集行为的安全性和有效性。</p><p>支持多种协议</p><p>IP 代理通常支持多种网络协议，如 HTTP、HTTPS、SOCKS 等。这使得爬虫可以根据不同的采集需求选择合适的协议进行通信。不同的网站可能使用不同的协议进行数据传输，支持多种协议的 IP 代理可以确保爬虫能够与各种类型的网站进行兼容，顺利完成数据采集任务。</p><p>综上所述，动态 IP 为爬虫采集提供了突破限制、提高效率的有效途径，而 IP 代理的诸多特点也为爬虫的正常运行和数据采集提供了有力保障。在使用爬虫进行数据采集时，合理运用动态 IP 和 IP 代理可以让我们更加高效、安全地获取所需的数据。</p><p>你对这篇文章的内容还满意吗？如果有任何修改意见，比如增减内容、调整结构等，都可以随时告诉我。</p>]]></description></item><item>    <title><![CDATA[LoRaWAN FUOTA 空中固件升级]]></title>    <link>https://segmentfault.com/a/1190000047405675</link>    <guid>https://segmentfault.com/a/1190000047405675</guid>    <pubDate>2025-11-17 19:05:41</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在大规模物联网（IoT）项目中，终端设备部署往往分布在偏远、难以接触的场景，依赖人工更新固件几乎不可能实现。为确保设备长期稳定运行，“空中固件升级”（Firmware Update Over The Air，FUOTA）成为关键技术，尤其是在使用 LoRaWAN 的项目中更显重要。由于 LoRaWAN 带宽低、每包数据受限，实现稳定高效的 FUOTA 极具挑战。本文系统解析 FUOTA 的原理、LoRaWAN 中的技术难点，并介绍门思科技（Manthink）在多年项目经验中形成的工程化升级方案。</p><hr/><h2><strong>一、什么是 FUOTA？</strong></h2><p>FUOTA（Firmware Update Over The Air）指通过无线网络远程更新设备固件，使设备在无人工干预的情况下完成功能更新、漏洞修复和性能优化。</p><p>在物联网项目中，终端设备数量动辄成千上万，分布地点可能包括：</p><ul><li>城市地下管网</li><li>农田或山区的农业监测点</li><li>工业园区、油田、仓储中心等现场</li><li>城市设施（路灯杆、井盖、消防栓等）</li></ul><p>一旦部署，这些设备往往多年不维护，因此 FUOTA 直接决定项目生命周期管理能力。</p><hr/><h2><strong>二、LoRaWAN 中 FUOTA 的两大核心挑战</strong></h2><p>LoRaWAN 的优势在于低功耗、远距离，但其限制也格外突出，使 FUOTA 成为一项高难度工程。</p><h3><strong>1. 固件体积极大，传输速度受限</strong></h3><ul><li>LoRaWAN 的最大有效载荷约 <strong>255 字节</strong></li><li>典型固件大小从 <strong>数十 KB 到数百 KB</strong></li></ul><p>在低速链路上上传大文件极易出现：</p><ul><li>丢包</li><li>信道干扰</li><li>升级中断</li><li>升级失败后需重新传输</li></ul><p>尤其是地下管网、弱信号覆盖区，失败率更高。</p><h3><strong>2. 数据分片、校验与重组机制复杂</strong></h3><p>LoRaWAN 升级必须通过数据分片方式完成：</p><ul><li>分片数量可能数百到上千</li><li>需要顺序或乱序重组</li><li>丢包重传策略需精细控制</li><li>大规模设备同时升级需要同步与拥塞控制</li></ul><p>因此，仅依赖标准 FUOTA 规范难以满足真实项目需求。</p><hr/><h2><strong>三、门思科技（Manthink）如何解决 LoRaWAN FUOTA 的工程化问题？</strong></h2><p>门思科技自 ​<strong>2017 年即在实际项目中大规模应用 FUOTA</strong>​，形成了涵盖操作系统、通信机制、算法与工具链在内的完整升级体系。</p><p>以下三项核心技术，使其 FUOTA 在大量部署中稳定可靠。</p><hr/><h2><strong>1. 自研 MPOS 操作系统：为升级预留底层 Hook</strong></h2><p>MPOS（Manthink Portable OS）是门思科技为 IoT 嵌入式设备开发的轻量级操作系统。</p><p>其核心优势在于 ​<strong>为远程升级预置扩展能力（Hook）</strong>​，包括：</p><ul><li>支持单函数级别的动态替换</li><li>支持向系统中新增任务或事件处理</li><li>支持差分升级，只传输变化部分</li></ul><p>相比整包固件升级，差分升级可以：</p><ul><li><strong>减少 70%\~95% 的传输数据量</strong></li><li>显著提升成功率</li><li>降低升级时间</li><li>降低对 LoRaWAN 链路质量的依赖</li></ul><hr/><h2><strong>2. EB（Edge-Bus）计算框架：压缩业务逻辑的“核心武器”</strong></h2><p>EB 框架是一种高度抽象的业务逻辑描述模型，具有：</p><ul><li>极高可压缩性</li><li>模块化</li><li>仅需少量字节即可描述复杂逻辑</li></ul><p>在实际项目中，EB 可以：</p><ul><li>将原本 <strong>几 KB 或几十 KB 的逻辑压缩为数百甚至数十字节</strong></li><li>将升级所需数据量降低一个数量级</li><li>极大提升 LoRaWAN FUOTA 的可行性</li></ul><p>这意味着：<br/><strong>设备无需再升级大固件，只需更新业务逻辑指令即可实现功能扩展。</strong></p><hr/><h2><strong>3. 多 bin 技术：可靠的数据切片与重组机制</strong></h2><p>多 bin 升级机制是门思科技为 LoRaWAN 环境优化的稳定传输方案。</p><p>其特点包括：</p><ul><li>根据设备当前信号质量自适应选择分片大小</li><li>针对弱信号环境优化的纠错和重传策略</li><li>智能组合与完整性校验</li><li>支持断点续传</li></ul><p>即使在高丢包率（5%\~20%）的场景中，也能确保：</p><ul><li>数据分片完整</li><li>升级可持续推进</li><li>最终固件校验通过后自动切换</li></ul><p>真正实现 ​<strong>工程级的远程升级可靠性</strong>​。</p><hr/><h2><strong>四、FUOTA 的价值：让 LoRaWAN 设备“活”起来</strong></h2><p>一个不能升级的物联网设备，只能“被动工作”；<br/>一个支持 FUOTA 的设备，才具备“生命周期管理”的能力。</p><p>FUOTA 带来的价值包括：</p><ul><li><strong>延长设备寿命</strong></li><li><strong>修复长期暴露在现场的安全漏洞</strong></li><li><strong>无需派人维护，大幅降低运维成本</strong></li><li><strong>设备可持续加入新功能</strong></li><li><strong>可适应项目场景变化</strong></li></ul><p>门思科技基于 MPOS、EB 和多 bin 的 FUOTA 技术，为 LoRaWAN 项目提供了工程级、可规模化、长期可靠的远程升级体系。</p><hr/><h2><strong>五、进一步了解 ThinkLink LoRaWAN 网络服务器（NS）</strong></h2><p>如果你正在寻找稳定、开放、全球标准兼容的 LoRaWAN 网络服务器平台，ThinkLink 是一个成熟选择：</p><ul><li><p><strong>ThinkLink Cloud 版</strong></p><ul><li>永久免费</li><li>支持 1000 个设备接入</li><li>支持 BACnet、Home Assistant、ThingsBoard 等系统对接<br/>👉 <a href="https://link.segmentfault.com/?enc=KiEqzgkOSneSIqBl3Ia%2B8Q%3D%3D.TPFs5GprYtQs3bnxXrZbhyua4vQ74xKSB%2FSHKi6m948%3D" rel="nofollow" target="_blank">https://thinklink.manthink.cn</a></li></ul></li><li><p><strong>ThinkLink Edge 版</strong></p><ul><li>可本地部署</li><li>支持 1000 个设备</li><li>内置 Home Assistant 开源版、ThingsBoard CE 版<br/>👉 <a href="https://link.segmentfault.com/?enc=GgChsfT1hNfw4Hi%2FLHrFGw%3D%3D.vf%2FeeRN2SLzN77klomDevzq5HFxwwWixhlFoN9XYcrVipCWUC0Tg%2BpBRK4QadUOw" rel="nofollow" target="_blank">https://www.manthink.cn/zh/thinklink-2/</a></li></ul></li></ul><p>了解更多 LoRaWAN 产品与解决方案：<br/>👉 <a href="https://link.segmentfault.com/?enc=7%2BBGfEL4r6mwDljviZw1KA%3D%3D.GkFTXFSuKN2SZseoB%2F1f3px6kgeXh7gHUhm3GbBFFVk%3D" rel="nofollow" target="_blank">https://www.manthink.cn</a></p>]]></description></item><item>    <title><![CDATA[在项目管理中如何跟踪工作量和工作时间？ ]]></title>    <link>https://segmentfault.com/a/1190000047405679</link>    <guid>https://segmentfault.com/a/1190000047405679</guid>    <pubDate>2025-11-17 19:04:50</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>项目管理工具中的工作量报告非常有用，因为它能清晰地展现任务和职责在团队成员之间的分配情况。通过显示哪些成员工作负荷过重、哪些成员资源利用不足或哪些成员空闲，报告可以帮助管理者更有效地平衡工作，防止员工倦怠或项目延误。此外，报告还能突出显示潜在的资源缺口，帮助团队在问题出现之前调整任务分配或时间安排，从而更好地进行规划。通过提高对团队能力和进度的可见性，团队可以做出更明智的决策，加强协调，并确保项目按计划进行。</p><p>Zoho Projects 支持项目工作量报表和全局工作量报表帮助您了解各个项目里面用户的工作量和您参加的所有的项目里面用户的工作量。 工作量报表为经理非常有帮助。 经理可以了解每个用户的工作量。 如果一个用户的工作量过多和另一个用户的工作量不足，只需要工作量过多的用户的一个任务拖放到工作量不足的用户。</p><p>项目管理工具中的“计划与实际对比”报告会将项目的计划内容（例如时间、成本、范围和资源）与实际执行情况进行比较。这种对比有助于项目经理评估绩效、识别偏差并做出纠正决策。它突出显示了计划时间表、预算或工作量与实际结果之间的差异。这使得项目进度是超前、按计划进行还是落后于计划变得清晰明了。</p><p>Zoho Projects 支持项目计划VS实际报表也支持全局计划VS实际报表。这个报表可以帮助用户查看一个任务中设置的工作时间和用户在任务中花费的时间。 它按照任务中设置的工作时间和用户在门户中添加的工时日志计算的。</p><p>当您需要评估项目进度或了解所有项目的任务信息时，“全局报告”功能将为您提供极大的帮助。“全局计划与实际”报告就是其中之一，您可以通过它了解各项任务所花费的时间。要查看此报告，请导航至 Zoho Projects 主页中的“全局报告”小部件。</p><p>“全局计划与实际”报告通过区分任务的计划工时和实际工时，提供每个用户的任务工时详情。报告还会显示每项任务的预期工时与实际工时之间的差异。</p><p>例如，门户管理员 李俊 使用“全局计划与实际”报告来了解哪些项目耗时较长。通过该报告，李俊 可以找到用户在所有项目中完成所有任务的总计划工时和实际工时。此外，通过比较每个项目的计划工时和实际工时，他还可以找出耗时较长的项目。</p><p>另外，李俊的老板要求他提供一份关于特定用户在特定项目和时间段内的工作报告。他对报告应用筛选器，并将报告导出为 XLS 文件。借助“全局计划与实际对比”报告，约翰找到了一个快速解决方案，可以生成所有项目的报告，而无需为每个项目单独生成报告。</p>]]></description></item><item>    <title><![CDATA[印度股票数据 PHP 对接文档 覆盖 B]]></title>    <link>https://segmentfault.com/a/1190000047405693</link>    <guid>https://segmentfault.com/a/1190000047405693</guid>    <pubDate>2025-11-17 19:04:18</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>本文档详细介绍如何使用 PHP 语言对接 StockTV 印度股票数据源，覆盖 BSE（孟买证券交易所）和 NSE（印度国家证券交易所）的实时数据。</p><h2>🚀 快速开始</h2><h3>环境要求</h3><ul><li>PHP 7.4+</li><li>cURL 扩展</li><li>JSON 扩展</li><li>网络连接（可访问 <code>api.stocktv.top</code>）</li></ul><h2>🏗️ 核心架构</h2><h3>项目结构</h3><pre><code>src/
├── config/
│   └── StockTVConfig.php
├── models/
│   ├── Stock.php
│   ├── Index.php
│   ├── KLine.php
│   └── ApiResponse.php
├── clients/
│   ├── StockTVHttpClient.php
│   └── StockTVWebSocketClient.php
├── services/
│   └── IndiaStockService.php
└── examples/
    └── IndiaStockDemo.php</code></pre><h2>📦 核心代码实现</h2><h3>1. 配置类</h3><pre><code class="php">&lt;?php
// src/config/StockTVConfig.php

namespace StockTV\Config;

/**
 * StockTV API 配置类
 */
class StockTVConfig
{
    // API 基础配置
    const BASE_URL = 'https://api.stocktv.top';
    const WS_URL = 'wss://ws-api.stocktv.top/connect';
    
    // 印度市场配置
    const INDIA_COUNTRY_ID = 14;
    const NSE_EXCHANGE_ID = 46;
    const BSE_EXCHANGE_ID = 74;
    
    // API 接口路径
    const STOCK_LIST = '/stock/stocks';
    const QUERY_STOCKS = '/stock/queryStocks';
    const STOCKS_BY_PIDS = '/stock/stocksByPids';
    const INDICES = '/stock/indices';
    const INDICES_BY_ID = '/stock/indicesById';
    const KLINE = '/stock/kline';
    const UPDOWN_LIST = '/stock/updownList';
    const GET_IPO = '/stock/getIpo';
    const COMPANIES = '/stock/companies';
    const COMPANY_URL = '/stock/companyUrl';
    const NEWS = '/stock/news';
    
    private $apiKey;
    private $timeout = 30;
    
    public function __construct(string $apiKey)
    {
        $this-&gt;apiKey = $apiKey;
    }
    
    public function getApiKey(): string
    {
        return $this-&gt;apiKey;
    }
    
    public function getTimeout(): int
    {
        return $this-&gt;timeout;
    }
    
    public function setTimeout(int $timeout): self
    {
        $this-&gt;timeout = $timeout;
        return $this;
    }
}</code></pre><h3>2. 数据模型类</h3><h4>股票数据模型</h4><pre><code class="php">&lt;?php
// src/models/Stock.php

namespace StockTV\Models;

/**
 * 印度股票数据模型
 */
class Stock
{
    public $id;
    public $symbol;
    public $name;
    public $last;
    public $chg;
    public $chgPct;
    public $high;
    public $low;
    public $volume;
    public $open;
    public $exchangeId;
    public $countryId;
    public $countryNameTranslated;
    public $flag;
    public $fundamentalMarketCap;
    public $fundamentalRevenue;
    public $technicalDay;
    public $technicalHour;
    public $technicalWeek;
    public $technicalMonth;
    public $performanceDay;
    public $performanceWeek;
    public $performanceMonth;
    public $performanceYtd;
    public $time;
    public $url;
    
    public function __construct(array $data = [])
    {
        foreach ($data as $key =&gt; $value) {
            if (property_exists($this, $key)) {
                $this-&gt;$key = $value;
            }
        }
    }
    
    public function getExchangeName(): string
    {
        if ($this-&gt;exchangeId == \StockTV\Config\StockTVConfig::NSE_EXCHANGE_ID) {
            return 'NSE';
        } elseif ($this-&gt;exchangeId == \StockTV\Config\StockTVConfig::BSE_EXCHANGE_ID) {
            return 'BSE';
        }
        return 'Unknown';
    }
    
    public function isGaining(): bool
    {
        return $this-&gt;chgPct &gt; 0;
    }
    
    public function getFormattedChange(): string
    {
        $sign = $this-&gt;chgPct &gt; 0 ? '+' : '';
        return $sign . number_format($this-&gt;chgPct, 2) . '%';
    }
    
    public function getFormattedPrice(): string
    {
        return '₹' . number_format($this-&gt;last, 2);
    }
}</code></pre><h4>指数数据模型</h4><pre><code class="php">&lt;?php
// src/models/Index.php

namespace StockTV\Models;

/**
 * 指数数据模型
 */
class Index
{
    public $id;
    public $name;
    public $symbol;
    public $last;
    public $chg;
    public $chgPct;
    public $high;
    public $low;
    public $isOpen;
    public $flag;
    public $url;
    public $time;
    
    public function __construct(array $data = [])
    {
        foreach ($data as $key =&gt; $value) {
            if (property_exists($this, $key)) {
                $this-&gt;$key = $value;
            }
        }
    }
    
    public function isGaining(): bool
    {
        return $this-&gt;chgPct &gt; 0;
    }
    
    public function getFormattedChange(): string
    {
        $sign = $this-&gt;chgPct &gt; 0 ? '+' : '';
        return $sign . number_format($this-&gt;chgPct, 2) . '%';
    }
}</code></pre><h4>K线数据模型</h4><pre><code class="php">&lt;?php
// src/models/KLine.php

namespace StockTV\Models;

/**
 * K线数据模型
 */
class KLine
{
    public $time;
    public $open;
    public $high;
    public $low;
    public $close;
    public $volume;
    public $vo;
    
    public function __construct(array $data = [])
    {
        foreach ($data as $key =&gt; $value) {
            if (property_exists($this, $key)) {
                $this-&gt;$key = $value;
            }
        }
    }
    
    public function getAmplitude(): float
    {
        if ($this-&gt;open == 0) {
            return 0;
        }
        return (($this-&gt;high - $this-&gt;low) / $this-&gt;open) * 100;
    }
    
    public function getChangePercent(): float
    {
        if ($this-&gt;open == 0) {
            return 0;
        }
        return (($this-&gt;close - $this-&gt;open) / $this-&gt;open) * 100;
    }
}</code></pre><h4>API响应包装类</h4><pre><code class="php">&lt;?php
// src/models/ApiResponse.php

namespace StockTV\Models;

/**
 * API通用响应包装类
 */
class ApiResponse
{
    public $code;
    public $message;
    public $data;
    
    public function __construct(array $data = [])
    {
        foreach ($data as $key =&gt; $value) {
            if (property_exists($this, $key)) {
                $this-&gt;$key = $value;
            }
        }
    }
    
    public function isSuccess(): bool
    {
        return $this-&gt;code === 200;
    }
}

/**
 * 股票列表响应包装类
 */
class StockListResponse
{
    public $records;
    public $total;
    public $size;
    public $current;
    public $pages;
    
    public function __construct(array $data = [])
    {
        foreach ($data as $key =&gt; $value) {
            if (property_exists($this, $key)) {
                $this-&gt;$key = $value;
            }
        }
        
        // 转换records为Stock对象数组
        if (isset($data['records']) &amp;&amp; is_array($data['records'])) {
            $this-&gt;records = array_map(function($item) {
                return new Stock($item);
            }, $data['records']);
        }
    }
}</code></pre><h3>3. HTTP客户端实现</h3><pre><code class="php">&lt;?php
// src/clients/StockTVHttpClient.php

namespace StockTV\Clients;

use StockTV\Config\StockTVConfig;
use StockTV\Models\ApiResponse;
use StockTV\Models\Stock;
use StockTV\Models\Index;
use StockTV\Models\KLine;
use StockTV\Models\StockListResponse;

/**
 * StockTV HTTP API客户端
 */
class StockTVHttpClient
{
    private $config;
    private $lastResponse;
    
    public function __construct(StockTVConfig $config)
    {
        $this-&gt;config = $config;
    }
    
    /**
     * 获取印度股票列表
     */
    public function getIndiaStocks(int $pageSize = 50, int $page = 1): array
    {
        $params = [
            'countryId' =&gt; StockTVConfig::INDIA_COUNTRY_ID,
            'pageSize' =&gt; $pageSize,
            'page' =&gt; $page,
            'key' =&gt; $this-&gt;config-&gt;getApiKey()
        ];
        
        $response = $this-&gt;makeRequest(StockTVConfig::STOCK_LIST, $params);
        
        if ($response-&gt;isSuccess()) {
            $stockListResponse = new StockListResponse($response-&gt;data);
            return $stockListResponse-&gt;records;
        }
        
        throw new \Exception("获取印度股票列表失败: " . $response-&gt;message);
    }
    
    /**
     * 查询单个股票
     */
    public function queryStock(?int $id = null, ?string $symbol = null, ?string $name = null): array
    {
        $params = ['key' =&gt; $this-&gt;config-&gt;getApiKey()];
        
        if ($id !== null) {
            $params['id'] = $id;
        }
        if ($symbol !== null) {
            $params['symbol'] = $symbol;
        }
        if ($name !== null) {
            $params['name'] = $name;
        }
        
        $response = $this-&gt;makeRequest(StockTVConfig::QUERY_STOCKS, $params);
        
        if ($response-&gt;isSuccess()) {
            return array_map(function($item) {
                return new Stock($item);
            }, $response-&gt;data);
        }
        
        throw new \Exception("查询股票失败: " . $response-&gt;message);
    }
    
    /**
     * 批量查询多个股票
     */
    public function getStocksByPids(array $pids): array
    {
        if (empty($pids)) {
            throw new \InvalidArgumentException("股票PID列表不能为空");
        }
        
        $params = [
            'key' =&gt; $this-&gt;config-&gt;getApiKey(),
            'pids' =&gt; implode(',', $pids)
        ];
        
        $response = $this-&gt;makeRequest(StockTVConfig::STOCKS_BY_PIDS, $params);
        
        if ($response-&gt;isSuccess()) {
            return array_map(function($item) {
                return new Stock($item);
            }, $response-&gt;data);
        }
        
        throw new \Exception("批量查询股票失败: " . $response-&gt;message);
    }
    
    /**
     * 获取印度主要指数
     */
    public function getIndiaIndices(): array
    {
        $params = [
            'countryId' =&gt; StockTVConfig::INDIA_COUNTRY_ID,
            'key' =&gt; $this-&gt;config-&gt;getApiKey()
        ];
        
        $response = $this-&gt;makeRequest(StockTVConfig::INDICES, $params);
        
        if ($response-&gt;isSuccess()) {
            return array_map(function($item) {
                return new Index($item);
            }, $response-&gt;data);
        }
        
        throw new \Exception("获取印度指数失败: " . $response-&gt;message);
    }
    
    /**
     * 通过ID查询特定指数
     */
    public function getIndexById(int $id): array
    {
        $params = [
            'id' =&gt; $id,
            'key' =&gt; $this-&gt;config-&gt;getApiKey()
        ];
        
        $response = $this-&gt;makeRequest(StockTVConfig::INDICES_BY_ID, $params);
        
        if ($response-&gt;isSuccess()) {
            return array_map(function($item) {
                return new Index($item);
            }, $response-&gt;data);
        }
        
        throw new \Exception("获取指数失败: " . $response-&gt;message);
    }
    
    /**
     * 获取K线数据
     */
    public function getKLineData(int $pid, string $interval): array
    {
        $params = [
            'pid' =&gt; $pid,
            'interval' =&gt; $interval,
            'key' =&gt; $this-&gt;config-&gt;getApiKey()
        ];
        
        $response = $this-&gt;makeRequest(StockTVConfig::KLINE, $params);
        
        if ($response-&gt;isSuccess()) {
            return array_map(function($item) {
                return new KLine($item);
            }, $response-&gt;data);
        }
        
        throw new \Exception("获取K线数据失败: " . $response-&gt;message);
    }
    
    /**
     * 获取涨跌排行榜
     */
    public function getUpDownList(int $type): array
    {
        $params = [
            'countryId' =&gt; StockTVConfig::INDIA_COUNTRY_ID,
            'type' =&gt; $type,
            'key' =&gt; $this-&gt;config-&gt;getApiKey()
        ];
        
        $response = $this-&gt;makeRequest(StockTVConfig::UPDOWN_LIST, $params);
        
        if ($response-&gt;isSuccess()) {
            return array_map(function($item) {
                return new Stock($item);
            }, $response-&gt;data);
        }
        
        throw new \Exception("获取排行榜失败: " . $response-&gt;message);
    }
    
    /**
     * 获取IPO数据
     */
    public function getIpoList(?int $type = null): array
    {
        $params = [
            'countryId' =&gt; StockTVConfig::INDIA_COUNTRY_ID,
            'key' =&gt; $this-&gt;config-&gt;getApiKey()
        ];
        
        if ($type !== null) {
            $params['type'] = $type;
        }
        
        $response = $this-&gt;makeRequest(StockTVConfig::GET_IPO, $params);
        
        if ($response-&gt;isSuccess()) {
            return $response-&gt;data;
        }
        
        throw new \Exception("获取IPO数据失败: " . $response-&gt;message);
    }
    
    /**
     * 通用HTTP请求方法
     */
    private function makeRequest(string $endpoint, array $params = []): ApiResponse
    {
        $url = StockTVConfig::BASE_URL . $endpoint . '?' . http_build_query($params);
        
        $ch = curl_init();
        curl_setopt_array($ch, [
            CURLOPT_URL =&gt; $url,
            CURLOPT_RETURNTRANSFER =&gt; true,
            CURLOPT_TIMEOUT =&gt; $this-&gt;config-&gt;getTimeout(),
            CURLOPT_HTTPHEADER =&gt; [
                'Content-Type: application/json',
                'User-Agent: StockTV-PHP-Client/1.0'
            ]
        ]);
        
        $response = curl_exec($ch);
        $httpCode = curl_getinfo($ch, CURLINFO_HTTP_CODE);
        $error = curl_error($ch);
        curl_close($ch);
        
        if ($error) {
            throw new \Exception("HTTP请求失败: " . $error);
        }
        
        if ($httpCode !== 200) {
            throw new \Exception("HTTP请求失败，状态码: " . $httpCode);
        }
        
        $data = json_decode($response, true);
        if (json_last_error() !== JSON_ERROR_NONE) {
            throw new \Exception("JSON解析失败: " . json_last_error_msg());
        }
        
        $this-&gt;lastResponse = $data;
        return new ApiResponse($data);
    }
    
    /**
     * 获取最后一次响应数据
     */
    public function getLastResponse(): ?array
    {
        return $this-&gt;lastResponse;
    }
}</code></pre><h3>4. WebSocket客户端实现</h3><pre><code class="php">&lt;?php
// src/clients/StockTVWebSocketClient.php

namespace StockTV\Clients;

use StockTV\Config\StockTVConfig;
use Ratchet\Client\WebSocket;
use Ratchet\Client\Connector;
use React\EventLoop\Factory;
use React\Socket\Connector as ReactConnector;

/**
 * StockTV WebSocket实时数据客户端
 */
class StockTVWebSocketClient
{
    private $config;
    private $loop;
    private $connector;
    private $webSocket;
    private $callbacks;
    
    public function __construct(StockTVConfig $config)
    {
        $this-&gt;config = $config;
        $this-&gt;loop = Factory::create();
        $this-&gt;connector = new Connector($this-&gt;loop);
        $this-&gt;callbacks = [
            'message' =&gt; [],
            'error' =&gt; [],
            'close' =&gt; []
        ];
    }
    
    /**
     * 连接WebSocket服务器
     */
    public function connect(): void
    {
        $wsUrl = StockTVConfig::WS_URL . '?key=' . $this-&gt;config-&gt;getApiKey();
        
        $this-&gt;connector-&gt;__invoke($wsUrl)
            -&gt;then(function(WebSocket $conn) {
                $this-&gt;webSocket = $conn;
                $this-&gt;onOpen($conn);
                
                $conn-&gt;on('message', function($msg) use ($conn) {
                    $this-&gt;onMessage($conn, $msg);
                });
                
                $conn-&gt;on('close', function($code = null, $reason = null) use ($conn) {
                    $this-&gt;onClose($conn, $code, $reason);
                });
                
            }, function(\Exception $e) {
                $this-&gt;onError($e);
            });
    }
    
    /**
     * 启动事件循环
     */
    public function run(): void
    {
        $this-&gt;loop-&gt;run();
    }
    
    /**
     * 停止事件循环
     */
    public function stop(): void
    {
        if ($this-&gt;loop) {
            $this-&gt;loop-&gt;stop();
        }
    }
    
    /**
     * 连接建立回调
     */
    private function onOpen(WebSocket $conn): void
    {
        echo "WebSocket连接已建立\n";
    }
    
    /**
     * 消息接收回调
     */
    private function onMessage(WebSocket $conn, $msg): void
    {
        $data = json_decode($msg, true);
        if (json_last_error() !== JSON_ERROR_NONE) {
            echo "JSON解析失败: " . json_last_error_msg() . "\n";
            return;
        }
        
        $this-&gt;handleRealTimeData($data);
        
        // 执行用户定义的回调
        foreach ($this-&gt;callbacks['message'] as $callback) {
            call_user_func($callback, $data);
        }
    }
    
    /**
     * 连接关闭回调
     */
    private function onClose(WebSocket $conn, $code, $reason): void
    {
        echo "WebSocket连接已关闭: code={$code}, reason={$reason}\n";
        
        foreach ($this-&gt;callbacks['close'] as $callback) {
            call_user_func($callback, $code, $reason);
        }
    }
    
    /**
     * 错误回调
     */
    private function onError(\Exception $e): void
    {
        echo "WebSocket连接错误: " . $e-&gt;getMessage() . "\n";
        
        foreach ($this-&gt;callbacks['error'] as $callback) {
            call_user_func($callback, $e);
        }
    }
    
    /**
     * 处理实时数据
     */
    private function handleRealTimeData(array $data): void
    {
        if (isset($data['pid'])) {
            $symbol = $data['symbol'] ?? $data['pid'];
            $price = $data['last_numeric'] ?? 'N/A';
            $changePercent = $data['pcp'] ?? '0';
            
            echo "实时行情: {$symbol} - 价格: {$price}, 涨跌幅: {$changePercent}%\n";
            
            // 价格预警逻辑
            $changePercentNum = floatval($changePercent);
            if (abs($changePercentNum) &gt; 2.0) {
                echo "🚨 价格波动预警: {$symbol} 波动 {$changePercentNum}%\n";
            }
        }
    }
    
    /**
     * 添加消息回调
     */
    public function onMessageCallback(callable $callback): self
    {
        $this-&gt;callbacks['message'][] = $callback;
        return $this;
    }
    
    /**
     * 添加错误回调
     */
    public function onErrorCallback(callable $callback): self
    {
        $this-&gt;callbacks['error'][] = $callback;
        return $this;
    }
    
    /**
     * 添加关闭回调
     */
    public function onCloseCallback(callable $callback): self
    {
        $this-&gt;callbacks['close'][] = $callback;
        return $this;
    }
    
    /**
     * 发送消息
     */
    public function send(string $message): void
    {
        if ($this-&gt;webSocket) {
            $this-&gt;webSocket-&gt;send($message);
        }
    }
    
    /**
     * 关闭连接
     */
    public function close(): void
    {
        if ($this-&gt;webSocket) {
            $this-&gt;webSocket-&gt;close();
        }
        $this-&gt;stop();
    }
}</code></pre><h3>5. 服务层封装</h3><pre><code class="php">&lt;?php
// src/services/IndiaStockService.php

namespace StockTV\Services;

use StockTV\Config\StockTVConfig;
use StockTV\Clients\StockTVHttpClient;
use StockTV\Clients\StockTVWebSocketClient;
use StockTV\Models\Stock;
use StockTV\Models\Index;
use StockTV\Models\KLine;

/**
 * 印度股票数据服务
 */
class IndiaStockService
{
    private $httpClient;
    private $wsClient;
    
    public function __construct(string $apiKey)
    {
        $config = new StockTVConfig($apiKey);
        $this-&gt;httpClient = new StockTVHttpClient($config);
        $this-&gt;wsClient = new StockTVWebSocketClient($config);
    }
    
    /**
     * 获取Nifty 50成分股
     */
    public function getNifty50Stocks(): array
    {
        try {
            $stocks = $this-&gt;httpClient-&gt;getIndiaStocks(50, 1);
            echo "成功获取 " . count($stocks) . " 只印度股票\n";
            return $stocks;
        } catch (\Exception $e) {
            echo "获取Nifty 50成分股失败: " . $e-&gt;getMessage() . "\n";
            throw $e;
        }
    }
    
    /**
     * 获取印度主要指数
     */
    public function getMajorIndices(): array
    {
        try {
            $indices = $this-&gt;httpClient-&gt;getIndiaIndices();
            echo "成功获取 " . count($indices) . " 个印度指数\n";
            return $indices;
        } catch (\Exception $e) {
            echo "获取印度指数失败: " . $e-&gt;getMessage() . "\n";
            throw $e;
        }
    }
    
    /**
     * 查询特定股票
     */
    public function getStockBySymbol(string $symbol): ?Stock
    {
        try {
            $stocks = $this-&gt;httpClient-&gt;queryStock(null, $symbol, null);
            if (empty($stocks)) {
                echo "未找到股票: {$symbol}\n";
                return null;
            }
            echo "查询股票 {$symbol} 成功\n";
            return $stocks[0];
        } catch (\Exception $e) {
            echo "查询股票失败: {$symbol} - " . $e-&gt;getMessage() . "\n";
            throw $e;
        }
    }
    
    /**
     * 批量查询股票
     */
    public function getStocksBySymbols(array $symbols): array
    {
        $results = [];
        foreach ($symbols as $symbol) {
            try {
                $stock = $this-&gt;getStockBySymbol($symbol);
                if ($stock) {
                    $results[] = $stock;
                }
            } catch (\Exception $e) {
                // 单个股票查询失败，继续处理其他股票
                continue;
            }
        }
        echo "批量查询成功，获取 " . count($results) . " 只股票\n";
        return $results;
    }
    
    /**
     * 获取股票K线数据
     */
    public function getStockKLine(int $pid, string $interval): array
    {
        try {
            $klines = $this-&gt;httpClient-&gt;getKLineData($pid, $interval);
            echo "成功获取股票 {$pid} 的K线数据，共 " . count($klines) . " 条\n";
            return $klines;
        } catch (\Exception $e) {
            echo "获取K线数据失败: pid={$pid} - " . $e-&gt;getMessage() . "\n";
            throw $e;
        }
    }
    
    /**
     * 获取涨幅榜
     */
    public function getGainers(): array
    {
        try {
            $gainers = $this-&gt;httpClient-&gt;getUpDownList(1);
            echo "成功获取涨幅榜，共 " . count($gainers) . " 只股票\n";
            return $gainers;
        } catch (\Exception $e) {
            echo "获取涨幅榜失败: " . $e-&gt;getMessage() . "\n";
            throw $e;
        }
    }
    
    /**
     * 获取跌幅榜
     */
    public function getLosers(): array
    {
        try {
            $losers = $this-&gt;httpClient-&gt;getUpDownList(2);
            echo "成功获取跌幅榜，共 " . count($losers) . " 只股票\n";
            return $losers;
        } catch (\Exception $e) {
            echo "获取跌幅榜失败: " . $e-&gt;getMessage() . "\n";
            throw $e;
        }
    }
    
    /**
     * 获取IPO数据
     */
    public function getUpcomingIPOs(): array
    {
        try {
            $ipos = $this-&gt;httpClient-&gt;getIpoList(1); // 1表示未上市
            echo "成功获取IPO数据，共 " . count($ipos) . " 个\n";
            return $ipos;
        } catch (\Exception $e) {
            echo "获取IPO数据失败: " . $e-&gt;getMessage() . "\n";
            throw $e;
        }
    }
    
    /**
     * 启动实时数据监控
     */
    public function startRealTimeMonitoring(): void
    {
        try {
            // 添加消息处理回调
            $this-&gt;wsClient-&gt;onMessageCallback(function($data) {
                $this-&gt;handleRealTimeData($data);
            });
            
            $this-&gt;wsClient-&gt;connect();
            echo "实时数据监控已启动\n";
            
            // 启动事件循环
            $this-&gt;wsClient-&gt;run();
            
        } catch (\Exception $e) {
            echo "启动实时数据监控失败: " . $e-&gt;getMessage() . "\n";
            throw $e;
        }
    }
    
    /**
     * 处理实时数据
     */
    private function handleRealTimeData(array $data): void
    {
        if (isset($data['pid'])) {
            $symbol = $data['symbol'] ?? $data['pid'];
            $price = $data['last_numeric'] ?? 'N/A';
            $changePercent = $data['pcp'] ?? '0';
            
            $trend = floatval($changePercent) &gt;= 0 ? '📈' : '📉';
            echo "{$trend} 实时行情: {$symbol} - 价格: ₹{$price}, 涨跌幅: {$changePercent}%\n";
            
            // 价格预警逻辑
            $changePercentNum = floatval($changePercent);
            if (abs($changePercentNum) &gt; 5.0) {
                echo "🚨 大幅波动预警: {$symbol} 波动 {$changePercentNum}%\n";
            }
        }
    }
    
    /**
     * 停止实时数据监控
     */
    public function stopRealTimeMonitoring(): void
    {
        $this-&gt;wsClient-&gt;close();
        echo "实时数据监控已停止\n";
    }
}</code></pre><h3>6. 使用示例</h3><pre><code class="php">&lt;?php
// examples/IndiaStockDemo.php

require_once __DIR__ . '/../vendor/autoload.php';

use StockTV\Services\IndiaStockService;
use StockTV\Models\Stock;
use StockTV\Models\Index;

/**
 * 印度股票数据使用示例
 */
class IndiaStockDemo
{
    private $stockService;
    
    public function __construct(string $apiKey)
    {
        $this-&gt;stockService = new IndiaStockService($apiKey);
    }
    
    public function runDemo(): void
    {
        echo "=== StockTV 印度股票数据演示程序开始 ===\n\n";
        
        try {
            // 1. 获取印度主要指数
            $this-&gt;demonstrateIndices();
            
            // 2. 查询特定股票
            $this-&gt;demonstrateStockQuery();
            
            // 3. 获取Nifty 50成分股示例
            $this-&gt;demonstrateNifty50();
            
            // 4. 获取K线数据
            $this-&gt;demonstrateKLineData();
            
            // 5. 获取排行榜
            $this-&gt;demonstrateRankings();
            
            echo "\n=== 演示程序执行完成 ===\n";
            
        } catch (Exception $e) {
            echo "演示程序执行失败: " . $e-&gt;getMessage() . "\n";
        }
    }
    
    /**
     * 演示指数数据获取
     */
    private function demonstrateIndices(): void
    {
        echo "1. 印度主要指数\n";
        echo str_repeat("-", 50) . "\n";
        
        $indices = $this-&gt;stockService-&gt;getMajorIndices();
        
        foreach ($indices as $index) {
            $trend = $index-&gt;isGaining() ? '📈' : '📉';
            $changeSign = $index-&gt;isGaining() ? '+' : '';
            
            echo "{$trend} {$index-&gt;name}: {$index-&gt;last} ";
            echo "({$changeSign}{$index-&gt;chgPct}%)\n";
        }
        echo "\n";
    }
    
    /**
     * 演示股票查询
     */
    private function demonstrateStockQuery(): void
    {
        echo "2. 查询特定股票\n";
        echo str_repeat("-", 50) . "\n";
        
        // 查询Reliance Industries
        $reliance = $this-&gt;stockService-&gt;getStockBySymbol('RELIANCE');
        $this-&gt;printStockInfo($reliance, 'Reliance Industries');
        
        // 查询TCS
        $tcs = $this-&gt;stockService-&gt;getStockBySymbol('TCS');
        $this-&gt;printStockInfo($tcs, 'Tata Consultancy Services');
        
        echo "\n";
    }
    
    /**
     * 演示Nifty 50成分股
     */
    private function demonstrateNifty50(): void
    {
        echo "3. Nifty 50成分股（示例）\n";
        echo str_repeat("-", 50) . "\n";
        
        $niftyStocks = $this-&gt;stockService-&gt;getNifty50Stocks();
        
        // 显示前10只股票
        $count = 0;
        foreach ($niftyStocks as $stock) {
            if ($count &gt;= 10) break;
            
            $trend = $stock-&gt;isGaining() ? '🟢' : '🔴';
            $changeSign = $stock-&gt;isGaining() ? '+' : '';
            
            echo "{$trend} {$stock-&gt;symbol}: ₹{$stock-&gt;last} ";
            echo "({$changeSign}{$stock-&gt;chgPct}%) - {$stock-&gt;name}\n";
            
            $count++;
        }
        echo "\n";
    }
    
    /**
     * 演示K线数据获取
     */
    private function demonstrateKLineData(): void
    {
        echo "4. K线数据示例\n";
        echo str_repeat("-", 50) . "\n";
        
        $reliance = $this-&gt;stockService-&gt;getStockBySymbol('RELIANCE');
        if ($reliance) {
            $klines = $this-&gt;stockService-&gt;getStockKLine($reliance-&gt;id, 'P1D');
            
            echo "Reliance Industries 近期日K线数据:\n";
            $count = 0;
            foreach ($klines as $kline) {
                if ($count &gt;= 5) break;
                
                $date = date('Y-m-d H:i:s', $kline-&gt;time / 1000);
                $amplitude = number_format($kline-&gt;getAmplitude(), 2);
                
                echo "时间: {$date}, 开: ₹{$kline-&gt;open}, ";
                echo "高: ₹{$kline-&gt;high}, 低: ₹{$kline-&gt;low}, ";
                echo "收: ₹{$kline-&gt;close}, 振幅: {$amplitude}%\n";
                
                $count++;
            }
        }
        echo "\n";
    }
    
    /**
     * 演示排行榜功能
     */
    private function demonstrateRankings(): void
    {
        echo "5. 市场排行榜\n";
        echo str_repeat("-", 50) . "\n";
        
        // 获取涨幅榜
        $gainers = $this-&gt;stockService-&gt;getGainers();
        echo "📈 今日涨幅榜（前5）:\n";
        $count = 0;
        foreach ($gainers as $stock) {
            if ($count &gt;= 5) break;
            
            $changeSign = $stock-&gt;isGaining() ? '+' : '';
            echo "   {$stock-&gt;symbol}: ₹{$stock-&gt;last} ";
            echo "({$changeSign}{$stock-&gt;chgPct}%) - {$stock-&gt;name}\n";
            
            $count++;
        }
        
        echo "\n";
        
        // 获取跌幅榜
        $losers = $this-&gt;stockService-&gt;getLosers();
        echo "📉 今日跌幅榜（前5）:\n";
        $count = 0;
        foreach ($losers as $stock) {
            if ($count &gt;= 5) break;
            
            echo "   {$stock-&gt;symbol}: ₹{$stock-&gt;last} ";
            echo "({$stock-&gt;chgPct}%) - {$stock-&gt;name}\n";
            
            $count++;
        }
        echo "\n";
    }
    
    /**
     * 打印股票信息
     */
    private function printStockInfo(?Stock $stock, string $description): void
    {
        if ($stock) {
            $status = $stock-&gt;open ? '🟢 交易中' : '🔴 已收盘';
            $trend = $stock-&gt;isGaining() ? '📈' : '📉';
            
            echo "{$trend} {$description} - {$status}\n";
            echo "   代码: {$stock-&gt;symbol} | 价格: ₹{$stock-&gt;last}\n";
            echo "   涨跌: ₹{$stock-&gt;chg} ({$stock-&gt;getFormattedChange()})\n";
            echo "   最高: ₹{$stock-&gt;high} | 最低: ₹{$stock-&gt;low} | 成交量: {$stock-&gt;volume}\n";
            
            if ($stock-&gt;technicalDay) {
                $techName = $this-&gt;getTechnicalIndicatorName($stock-&gt;technicalDay);
                echo "   技术指标: {$techName}\n";
            }
        }
        echo "\n";
    }
    
    /**
     * 获取技术指标中文名称
     */
    private function getTechnicalIndicatorName(string $indicator): string
    {
        $map = [
            'strong_buy' =&gt; '强烈买入',
            'buy' =&gt; '买入',
            'neutral' =&gt; '中性',
            'sell' =&gt; '卖出',
            'strong_sell' =&gt; '强烈卖出'
        ];
        
        return $map[$indicator] ?? $indicator;
    }
}

// 运行演示程序
$apiKey = '您的API_KEY'; // 替换为实际的API Key

$demo = new IndiaStockDemo($apiKey);
$demo-&gt;runDemo();</code></pre><h2>🎯 高级功能</h2><h3>实时价格监控器</h3><pre><code class="php">&lt;?php
// examples/PriceMonitor.php
</code></pre>]]></description></item><item>    <title><![CDATA[【赵渝强老师】达梦数据库的事务隔离级别 ]]></title>    <link>https://segmentfault.com/a/1190000047405731</link>    <guid>https://segmentfault.com/a/1190000047405731</guid>    <pubDate>2025-11-17 19:03:22</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>达梦数据库允许多个客户端同时访问。当这些客户端并发访问数据库中同一部分的数据时，如果没有采取必要的隔离措施就容易造成并发一致性问题，从而破坏数据的完整性。考虑下图中的场景：<br/><img width="723" height="276" referrerpolicy="no-referrer" src="/img/bVdm3K4" alt="image.png" title="image.png"/></p><p>在时间点1上，var的数值是100。客户端A在时间点2的时候更新了它的值为200，但没有提交事务。在时间点3的时候，客户端B读取到了客户端A还未提交的数值200。但在时间点4，客户端A执行了回滚操作。那么，对于客户端B来说，如果在时间点5再次读取数据，得到就应该是100。那么客户端B就有了数据不一致的问题。而造成问题的根本原因在，客户端B读取到了客户端A还没有提交的事务中的数据。</p><p>为了解决数据在并发访问时，数据的一致性问题。在SQL标准中定义了四种事务的隔离级别，它们分别是：读未提交（READ-UNCOMMITTED）、读已提交（READ-COMMITTED）、可重复读（REPEATABLE-READ）和可序列化读（SERIALIZABLE）。<br/>达梦数据库支持三种事务隔离级别：读未提交（READ-UNCOMMITTED）、读提交（READ-COMMITTED）和串行化（SERIALIZABLE）。其中，读提交是DM 数据库默认使用的事务隔离级别，可重复读升级为更严格的串行化隔离级。</p><p>视频讲解如下：<br/><a href="https://www.bilibili.com/video/BV1EACiBuEq6/?aid=115563779069332&amp;cid=34063516477" target="_blank">https://www.bilibili.com/video/BV1EACiBuEq6/?aid=115563779069...</a></p><p>在达梦数据库中要查看默认的事务隔离级别，可以通过下面的方式来获取。<br/>（1）使用管理员登录数据库。</p><pre><code class="sql">SQL&gt; conn sysdba/Welcome_1</code></pre><p>（2）执行下面的语句获取事务的隔离级别。</p><pre><code class="sql">SQL&gt; select para_name,para_value,
    case para_value
        when 1 then 'Read Commited'
        when 3 then 'Serializable'
        else 'None'
    end as "隔离级别"
    from v$dm_ini where para_name='ISOLATION_LEVEL';

# 输出的信息如下：
行号     PARA_NAME       PARA_VALUE     隔离级别 
------ --------------- ---------- -------------
1       ISOLATION_LEVEL     1              Read Commited

# 从输出的信息可以看出，DM数据库默认的事务隔离级别是读已提交（READ-COMMITTED）。</code></pre><p>数据库在不同的事务隔离级别下会有不同的行为，从而在并发访问数据的时候会带来不同的问题。下表列举了在不同的SQL标准事务隔离级别下，数据库可能存在的不同问题。<br/><img width="723" height="146" referrerpolicy="no-referrer" src="/img/bVdm3Lj" alt="image.png" title="image.png" loading="lazy"/></p><p>由于达梦数据库默认的事务隔离级别是读已提交（READ-COMMITTED），因此在达梦数据库中默认是不存在脏读问题的。</p>]]></description></item><item>    <title><![CDATA[Data Agent 精选推荐：Alou]]></title>    <link>https://segmentfault.com/a/1190000047405735</link>    <guid>https://segmentfault.com/a/1190000047405735</guid>    <pubDate>2025-11-17 19:02:30</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>摘要</h2><p>在数据量爆炸式增长与业务决策实时性要求提升的双重驱动下，Data Agent（数据智能体）正从辅助工具向企业核心数据分析中枢演进。其通过融合大模型能力与数据管理和分析技术，为企业提供“对话即分析”、“自动找根因”、“一键生成报告”等智能化数据分析服务，推动“人人都是分析师”的愿景落地。</p><p>本文聚焦 Data Agent 的发展趋势与市场需求，重点推荐面向企业的 Aloudata Agent 分析决策智能体——它以“智能问数、智能归因、报告生成”三大核心能力，为企业构建可信智能 Data Agent，助力企业实现 AI 驱动的数据洞察与敏捷决策，是企业数智化转型的优选方案。</p><h2>前言：当数据分析遇上 AI，Data Agent 为何成为新焦点？</h2><p>随着企业数智化转型的深入，数据已成为核心生产要素，但传统数据分析模式却面临严峻挑战：业务人员依赖 IT 部门取数，平均响应周期长达数天；海量数据中隐藏的业务关联难以快速挖掘；管理层需要决策支持时，往往因报告滞后错失商机。</p><p>与此同时，大语言模型（LLM）的突破为数据分析带来了革命性变化——通过自然语言对话直接获取洞察，让非技术人员也能“对话数据”。在此背景下，Data Agent（数据智能体）应运而生。作为连接用户需求与数据系统的“智能中介”，它不仅能理解自然语言指令，更能自动完成数据查询、关联分析、根因定位、可视化呈现等复杂任务，成为企业数据分析的“AI 专家”。</p><p>据 IDC 预测，到 2026 年，将有 50% 的中国 500 强数据团队使用 AI Agent来实现数据准备和分析。而在这场变革中，Aloudata Agent 分析决策智能体凭借对企业级场景的深度适配，正成为市场中的标杆产品。</p><h3>推荐理由一：智能问数——让“开口即得”取代“提需求排队”</h3><p>传统数据分析流程中，业务人员需先梳理需求→提交 IT 或数据团队→等待 SQL 编写与数据提取→再解读结果，链路长且效率低。Aloudata Agent 的核心突破在于深度优化了“企业级语义理解”。其通过采用了“NoETL 明细语义层 + 多 Agent 协同”架构，创新 NL2MQL2SQL 技术路径，提供了全面、丰富的指标语义知识库，确保基于用户问数意图对齐指标语义，实现精准的指标与维度召回，保障数据完整性和口径一致性，避免了“问 A 得 B”的常见错误。</p><p>当用户输入问题，其能够准确识别用户查询目标，精准理解业务意图，生成指标语义查询 MQL，再通过指标语义引擎将 MQL 自动转化为可执行的 SQL 语句，实现 100% 准确的 SQL 查询和物化加速，最后由大模型将数据结果转化为易于理解的洞察语言和图表报告。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405737" alt="图片" title="图片"/></p><p>例如，用户只需通过日常语言提问，如“Q3 华东区销售额同比下滑的原因是什么？”“哪些客户的复购率提升了但客单价下降了？”，Aloudata Agent 即可自动解析意图、生成指标语义查询 MQL、转化为 SQL 查询，并以图表或简报形式返回答案。</p><h3>推荐理由二：智能归因——从“数据堆砌”到“根因定位”的质变</h3><p>数据分析的价值不仅在于呈现“发生了什么”，更在于回答“为什么发生”以及“如何应对”。然而，面对海量关联数据，人工定位根因往往依赖经验猜测，效率低且易遗漏关键因素。</p><p>Aloudata Agent 的“智能归因”功能，包括“维度归因”和“因子归因”两大路径：</p><p>1、维度归因：用于识别影响目标指标的关键业务维度，通过维度下钻与贡献度计算，量化各维度对整体变化或差异的贡献权重，帮助用户锁定问题焦点。例如，分析“门店 A 与门店 B 的业绩差距”时，可自动归因于客群结构、促销策略等维度；</p><p>2、因子归因：聚焦驱动指标变动的关联因子，通过指标间的计算逻辑与影响路径，识别哪些前置因子的变化是导致最终结果差异的根本动因，从而提供更具操作性的改进方向。例如，识别“GMV 增长”的主要驱动因素是产品类目、会员等级还是渠道类型。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405738" alt="图片" title="图片" loading="lazy"/></p><p>这种“从现象到本质”的智能归因分析，不仅能够帮助业务团队快速聚焦关键问题，更将归因分析的效率提升数倍。例如，原本需要多人在数周内完成的根因分析工作，现在通过 Aloudata Agent 可在 1 天内输出完整报告，且结论的可信度更高。</p><h3>推荐理由三：报告生成——从“人工撰写”到“一键智能输出”的效率革命</h3><p>定期生成经营分析报告（如日报、周报、月报）是企业数据团队的常规工作，但这类任务往往重复性强、格式固定，占用大量人力。Aloudata Agent 的“报告生成”功能，支持用户通过自然语言指定报告目标，例如，“生成 Q3 销售业绩分析报告，重点突出区域差异与渠道贡献”，Aloudata Agent 即可自动整合多维数据、按逻辑框架组织内容，并生成图文并茂报告文档。</p><p>更关键的是，报告内容并非简单的数据堆砌，而是基于 AI 的“业务视角解读”，整合趋势、对比、归因结论，包含数据结果查询、异常发现、归因、对比与改善措施建议的结构化内容，将数据洞察转化为可执行的业务动作。</p><p>这对于分析师而言，以前写报告要花数个小时，现在基于 Aloudata Agent 显著提升撰写效率，并能够直接标出了“需关注事项”和“优化建议”等关键信息，极大简化了工作任务，实现敏捷决策。</p><h2>总结：Aloudata Agent——企业级 AI 数据分析的“专家级伙伴”</h2><p>在 Data Agent 加速渗透企业级市场的趋势下，核心需求已从“能查数据”升级为“能懂业务、能解决问题、能驱动决策”。Aloudata Agent 分析决策智能体正是这一需求的典型代表：它以“智能问数”降低数据分析门槛，让全员参与洞察；以“智能归因”挖掘数据背后的因果逻辑，提升决策精准度；以“报告生成”自动化重复工作，释放专业团队价值。</p><p>随着企业对“全员数据素养”的要求越来越高，像 Aloudata Agent 这样的智能体将成为数据驱动决策的关键工具。它不仅是技术的创新，更是企业数据分析范式的革新，让“人人都是分析师”不再是一句口号，而是触手可及的现实。访问 Aloudata Agent 产品官网，一起贴近更智能的数据未来。</p><h2>适用对象：</h2><p>希望实现自然语言问数、AI 数据分析，推进数据民主化，提升数据交付敏捷性，让一线业务能够减少对数据开发的依赖，自主开展全面、灵活、智能、安全问数，覆盖金融（银行、证券）、制造、消费、零售、交通、能源、医疗、航空航天、互联网、ICT、政企等行业领域。</p><h2>权威认可：</h2><ul><li>IDC：2025 IDC 中国面向生成式 AI 的数据基础设核心厂商、数据流管理（Data Flow Agent）代表厂商；2024 IDC「GenAI+Data」中国市场代表厂商</li><li>Gartner：2024 中国代表性数据基础设施供应商、中国数据编织代表厂商和数据资产管理代表厂商</li><li>信通院：2024《数据智能产业图谱》-数据智能基础设施企业、数据治理企业、数据智能开发企业代表</li><li>爱分析：2025 AI Agent 对话式智能分析核心厂商</li><li>数据猿：2025 中国数智化转型升级创新服务企业</li></ul>]]></description></item><item>    <title><![CDATA[阿尔特携手 Amazon AgentCo]]></title>    <link>https://segmentfault.com/a/1190000047405755</link>    <guid>https://segmentfault.com/a/1190000047405755</guid>    <pubDate>2025-11-17 19:01:59</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img width="723" height="160" referrerpolicy="no-referrer" src="/img/bVdkFLr" alt="image.png" title="image.png"/></p><h2>关于Monus AI</h2><p>Monus AI是由南京阿尔特科技推出的一款专注于消费决策的AI搜索应用，在搜索垂类工具中表现领先。该产品核心功能包括规格级比价、虚假软广识别、商品对比和智能对话，致力于在购物前为用户提供高效、可信的决策支持。通过6大智能体体系和返利体系，Monus AI不仅帮助用户省钱，还能让用户在消费过程中“赚钱”。无论是搜索“程序员AI开发电脑”还是查询“Pampers湿纸巾最低价”，它都始终围绕“信任+效率”重塑消费搜索体验。</p><p><img width="723" height="251" referrerpolicy="no-referrer" src="/img/bVdm2TV" alt="image.png" title="image.png" loading="lazy"/></p><h3>什么是 Amazon Bedrock AgentCore？</h3><p>Amazon Bedrock AgentCore 提供专为Agent工作负载构建的基础设施、可增强Agent功能的强大工具，以及适用于现实部署场景的基础组件。AgentCore 服务可以组合使用，也可以单独使用。该服务兼容多种Agent框架（包括 CrewAI、LangGraph、LlamaIndex 和 Strands Agents 等），并支持 Amazon Bedrock提供的多种模型，为 Agent 带来极大的灵活性。AgentCore 消除了构建专用Agent基础设施时千篇一律的繁重工作，可以加快 Agent 从研发进入生产的过程。</p><h3>场景挑战</h3><p>在电商AI搜索领域，用户和系统面临多重核心挑战，特别是需求表达与匹配的断层。具体挑战包括：</p><p>（1）用户不同购买决策时期的识别</p><p>用户在购物过程中，处于不同的购买决策期，需求和关注点差异显著。多模态输入（文字、语音、图片）的准确理解及决策时期判别至关重要。需求萌芽期的用户更需要全面的指导和信息，帮助形成购买意向；而决策后期的用户则更加关注优惠促销和售后保障。对这些时期的精准识别能够实现针对性服务和优化用户体验。</p><p>（2）多平台商品规格同义不同名问题</p><p>跨平台商品信息孤立，用户需在不同电商平台间切换对比价格和评价，且常遭遇虚假软广和冗余信息扰乱，筛选有效信息耗时且低效。更复杂的是，不同平台采用各自独特的商品规格命名规则，导致“同义不同名”现象普遍存在，严重阻碍了规格级颗粒度的实时比价和精准匹配，给系统带来了极大挑战。</p><p>（3）用户画像与商品推理匹配度不足</p><p>传统推荐系统主要依赖用户的行为数据进行相似商品推荐，泛化能力和关联推理能力有限，难以有效捕获用户日常生活中的跨品类兴趣和潜在需求。这导致推荐结果同质化严重，无法做到用户需求的深度理解和精准满足，影响用户满意度和转化率。</p><p>针对上述挑战，电商AI搜索系统需具备精准的决策期识别能力，高效处理跨平台异构商品数据，并强化用户画像与商品间的智能推理匹配能力，才能提供真正个性化、连贯且高效的消费决策支持。</p><h3>解决方案</h3><p>Monus AI采用自研的多模态融合输入技术，可同时高效处理文字、语音、图片三种类型的用户输入，打破传统搜索的输入局限。更具创新性的是，系统引入 “消费决策时期判断” 机制，通过深度学习模型分析用户输入的语义特征与情感倾向，能准确识别用户当前处于需求萌芽、信息收集还是购买决策阶段，该判断的匹配度高达 94%，为后续精准服务奠定基础。</p><p><img width="723" height="797" referrerpolicy="no-referrer" src="/img/bVdm2Va" alt="image.png" title="image.png" loading="lazy"/></p><ul><li>第一级：决策洞察智能体体系– 深度结合 AgentCore Memory 基于 UserPreferenceMemory 策略存储的用户偏好数据，实时分析用户搜索请求的复杂度，同时判断用户决策的紧迫性，为后续处理流程设定优先级。</li><li>第二级：智能匹配智能体体系– 基于用户历史购物偏好、浏览记录等数据，动态调整商品与搜索内容的匹配权重，确保优先呈现与用户需求高度契合的信息。</li><li>第三级：语义压缩智能体体系 – 采用先进的语义编码算法，在保留 98% 核心商品信息完整性的前提下，将数据处理速度提升 3 倍，同时使整体处理成本降低 80%，实现效率与成本的双重优化。</li><li>第四级：数据融合智能体体系 – 运用自研的多源数据清洗算法，对来自不同电商平台的商品数据进行处理，噪音过滤率达到 87%，有效解决了跨平台商品信息孤岛问题，为用户提供统一、准确的信息视图。</li><li>第五级：个性推荐智能体体系– 深度融合 AgentCore Memory 的用户数据，摒弃传统机械的推荐方式，采用拟人化导购的交互形式，进行情感化推荐排序，让推荐结果更贴合用户个性化需求与购物习惯。</li></ul><p>多级智能体体系通过用户偏好分析、精准匹配、效率优化等维度构建了核心能力，在这一体系运行框架下，通过以下关键技术点，实现效率与质量的双重提升：</p><p><img width="723" height="346" referrerpolicy="no-referrer" src="/img/bVdm2Vb" alt="image.png" title="image.png" loading="lazy"/></p><ol><li>智能分解 – AI 自动将用户提出的复杂需求（如 “推荐一款适合大学生用、预算 5000 元以内、能运行设计软件的笔记本”）拆解为多个可并行处理的子任务，如 “大学生使用场景分析”“预算筛选”“软件运行需求匹配” 等。</li><li>并行路由 – 多个 Agent 同时针对不同维度的子任务进行处理，避免串行处理的等待时间，使系统响应时间缩短 60%，大幅提升用户体验。</li><li>记忆融合 – 基于 Strands Agents 调用 AgentCore Memory 中的用户历史数据，对各 Agent 处理后的结果进行个性化答案整合，确保最终呈现给用户的搜索结果完全符合其独特偏好与需求。</li></ol><p><img width="723" height="1440" referrerpolicy="no-referrer" src="/img/bVdm3et" alt="" title="" loading="lazy"/></p><p>通过上述技术架构与流程设计，Monus AI 实现了从 “单一搜索工具” 到 “专属购物伙伴” 的根本性转变。如今，用户无需在重复搜索中反复描述需求，AI 能够精准理解需求的上下文演进过程，为用户提供具备连续性的个性化服务体验。这一技术架构不仅彻底解决了传统 AI 搜索存在的记忆缺失、推荐同质化等问题，更开创了电商 AI 领域的全新服务范式，为行业树立了技术与体验双重领先的标杆。</p><h2>效果评估</h2><p>基于AgentCore Memory和Strands Agent协同架构，Monus AI实现了跨越式提升，AI 搜索优化 具体表现如下：</p><p><img width="723" height="334" referrerpolicy="no-referrer" src="/img/bVdm2Vd" alt="image.png" title="image.png" loading="lazy"/></p><p>依托 AgentCore Memory 长期记忆的技术优势，不仅显著加快 Agent 开发进程，更在实际应用中实现多重价值：基于用户画像的智能搜索 Token 用量大幅减少，同时搜索结果准确率有效提升，为 Monus AI 在技术竞争力与成本效益层面提供了跨越式突破。</p><h2>总结</h2><p>阿尔特科技与亚马逊云科技的技术合作，不仅是 “任务编排框架 + 记忆服务” 与电商场景的深度融合，更给出了 “AI 如何真正懂用户、服务用户” 的清晰答案。其以 Strands Agents能力为 “骨架”，以 AgentCore Memory 的记忆功能为 “大脑”，搭配大小模型协同、语义共识引擎等技术，找到了当前电商 AI 搜索的最优实现路径，体现对 AI 技术本质的深刻理解与实践智慧。正如阿尔特科技团队所言：“创业不是一份工作，是热爱、坚持与智慧成长的过程。” 此次通过技术创新，不仅验证了 AI 在电商领域的巨大商业潜力，更为行业提供了 “框架 + 记忆” 双核心驱动的可复制、可扩展实践范式，为电商 AI 搜索的发展注入新动能。</p><p>*前述特定亚马逊云科技生成式人工智能相关的服务目前在亚马逊云科技海外区域可用。亚马逊云科技中国区域相关云服务由西云数据和光环新网运营，具体信息以中国区域官网为准。</p><p><strong>本篇作者</strong><br/><img width="723" height="457" referrerpolicy="no-referrer" src="/img/bVdm2Vm" alt="image.png" title="image.png" loading="lazy"/></p><blockquote>本期最新实验为《<a href="https://link.segmentfault.com/?enc=Ou62xqLasnlYNDonsuVytg%3D%3D.db6K1KmzbWSBw9RyMbxEo5kUKkTSAmRFDBeb7bFSF8Q2UZc7PBVeyiX3M%2FpclWCcrr4RhQp9qqlBOf%2FxtVRA1Hz7M1gJwXDtRvO1tzZ32hnhoAobkIASVOgHBijA25fiHTdUqCe0NBA2zKY6uSXfs767iDU17oaq%2BW2dzY12miqnyQqI3LDm8UhvAuzIPvJ9wtTLuwy1XQVKdn48RSwb5w%3D%3D" rel="nofollow" target="_blank">大模型选型实战 —— 基于Amazon Bedrock测评对比和挑选最合适业务的大模型</a>》<br/>✨ 立即解锁当下最火爆的AI大模型，带你零基础玩转 DeepSeek、Nova 等顶尖大预言模型。<br/>📱 即刻在云上探索实验室，开启构建开发者探索之旅吧！<br/>⏩<a href="https://link.segmentfault.com/?enc=KHeFFiPFu%2FVzMwEvyL1%2Ftg%3D%3D.oxPaMDECBigAh3ulm2kQn9YqPwozGTwV1NVSNjcN6buyQr3nyJQd4vcQiX3yo8%2F2uEI%2B6cBJfrKnI%2Fd%2BDHDQR9MaLFAZIvZdK4tEOSrY%2Fx0dmAm%2FhSRJWl63l%2Fd7csBSXKa49NhPqDbkGiLgx6GmfLn7DWVha4pspOMPztT0KxsYZSNgczlVIgu%2Fs30fcbB7Qpsn5Awe%2F8ur563XBZaaoA%3D%3D" rel="nofollow" target="_blank">[点击进入实验</a>] 构建无限, 探索启程！🚀</blockquote>]]></description></item><item>    <title><![CDATA[Rust 与 Go，后端开发的下一个五年]]></title>    <link>https://segmentfault.com/a/1190000047405757</link>    <guid>https://segmentfault.com/a/1190000047405757</guid>    <pubDate>2025-11-17 19:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>开发没有那么容易，每个后端有它的脾气，它不关心业务的快速变化，只关心自身的稳定和高效。</p><p>那么在未来几年，在高并发、低延迟的新兴后端领域，Rust 和 Go，谁会成为更主流的选择？我个人认为，这不在于哪个语言更时髦，而在于谁的架构性成本更低。</p><p><img width="723" height="351" referrerpolicy="no-referrer" src="/img/bVdm4y4" alt="image.png" title="image.png"/></p><h3>核心差异：编译时的严谨 vs. 运行时的灵活性</h3><p>Rust 和 Go 的设计哲学，从一开始就走向了两个不同的方向。</p><ul><li><strong>Rust</strong> 选择的是一条“先难后易”的路。它的编译器非常严格，尤其是所有权和借用检查机制，会在编译阶段就把潜在的内存安全问题全部暴露出来。这个过程对新手来说确实有不小的学习曲线，但一旦编译通过，程序在运行时的稳定性和性能表现会非常可靠。它没有垃圾回收（GC），这意味着不会有因GC扫描而导致的不可预测的延迟暂停。</li><li><strong>Go</strong> 则走了另一条路：“快速上手，快速产出”。它的语法简洁，工具链完善，特别是<code>goroutine</code>让并发编程变得前所未有的简单。开发者可以很快地将业务逻辑转化为可运行的服务。这种高效率的背后，是Go语言运行时自带的垃圾回收机制。在大多数情况下，Go的GC表现得相当不错，但在面对流量洪峰或大量瞬时内存分配的场景时，GC的“Stop-the-world”暂停仍然可能引发P99延迟的抖动。</li></ul><p>这本质上是两种不同权衡：一种是用前期的开发投入换取运行时的极致性能和可预测性；另一种是用运行时的些许不确定性，换取极高的开发效率和更低的入门门槛。</p><h3>性能场景对比</h3><p>比如一个很常见的后端任务：接收一个JSON格式的POST请求，进行一些数据处理，然后返回一个新的JSON响应。</p><p>在这个场景下，两种语言的表现通常会呈现一种规律：</p><ul><li><strong>Go (1.22)</strong> ：我用Go写这个功能可能只需要很短的时间。服务在常规负载下运行良好，响应迅速。但当并发请求量急剧上升时，通过监控工具，就会观察到延迟曲线出现一些细小的毛刺，内存占用也会随请求量线性增长。</li><li><strong>Rust</strong> <strong>(基于tokio)</strong> ：用Rust实现同样的功能，可能需要花更多时间去处理数据的生命周期和所有权问题，确保代码能通过编译器的检查。但服务部署后，它的延迟曲线会很平滑，即使在高压下，性能表现也始终如一，内存占用非常稳定。</li></ul><p>Rust 是把优化工作前置到了编码和编译阶段，而Go则让开发者先快速实现功能，再根据运行时的性能表现进行针对性优化。</p><h3>从代码的细节来看</h3><p>我们来看一下实现相同功能的两段代码。</p><h4><strong>Go：清晰直观，关注业务</strong></h4><pre><code class="go">package main

import (
        "encoding/json"
        "fmt"
        "log"
        "net/http"
        "time"
)

type RequestPayload struct {
        Name  string `json:"name"`
        Value int    `json:"value"`
}

type ResponsePayload struct {
        ID      int64  `json:"id"`
        Message string `json:"message"`
}

func handleRequest(w http.ResponseWriter, r *http.Request) {
        if r.Method != http.MethodPost {
                http.Error(w, "Only POST method is allowed", http.StatusMethodNotAllowed)
                return
        }

        var reqPayload RequestPayload
        if err := json.NewDecoder(r.Body).Decode(&amp;reqPayload); err != nil {
                http.Error(w, "Bad JSON format", http.StatusBadRequest)
                return
        }

        respPayload := ResponsePayload{
                ID:      time.Now().UnixNano(),
                Message: fmt.Sprintf("hello %s", reqPayload.Name),
        }

        w.Header().Set("Content-Type", "application/json")
        if err := json.NewEncoder(w).Encode(respPayload); err != nil {
                log.Printf("Failed to encode response: %v", err)
        }
}

func main() {
        http.HandleFunc("/api/process", handleRequest)
        fmt.Println("Go server listening on :8080")
        if err := http.ListenAndServe(":8080", nil); err != nil {
                log.Fatalf("Server failed to start: %v", err)
        }
}</code></pre><p>这段Go代码的逻辑非常直接，核心就是解码、处理、编码。开发者可以把注意力完全放在业务流程上。但在这个过程中，<code>json.Decode</code>和<code>json.Encode</code>等操作会隐式地进行内存分配，这些都是未来GC需要处理的对象。</p><h4><strong>Rust：严谨精密，掌控资源</strong></h4><p>首先，<code>Cargo.toml</code> 依赖配置:</p><pre><code class="rust">[dependencies]
axum = "0.7"
tokio = { version = "1", features = ["full"] }
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
chrono = { version = "0.4", features = ["serde"] }</code></pre><p>然后是实现代码:</p><pre><code class="rust">use axum::{routing::post, Json, Router};
use serde::{Deserialize, Serialize};
use std::net::SocketAddr;
use tokio;

#[derive(Deserialize)]
struct RequestPayload {
    name: String,
    value: i32,
}

#[derive(Serialize)]
struct ResponsePayload {
    id: i64,
    message: String,
}

async fn handle_request(Json(payload): Json&lt;RequestPayload&gt;) -&gt; Json&lt;ResponsePayload&gt; {
    let message = format!("hello {}", payload.name);

    let response = ResponsePayload {
        id: chrono::Utc::now().timestamp_nanos_opt().unwrap_or(0),
        message,
    };
    
    Json(response)
}

#[tokio::main]
async fn main() {
    let app = Router::new().route("/api/process", post(handle_request));

    let addr = SocketAddr::from(([127, 0, 0, 1], 3000));
    println!("Rust server listening on {}", addr);
    
    let listener = tokio::net::TcpListener::bind(addr).await.unwrap();
    axum::serve(listener, app).await.unwrap();
}</code></pre><p>Rust的代码在结构上需要更多的思考，比如异步运行时和框架的选择。但它带来的好处是，所有的数据传递和内存使用都在编译器的严格监督之下，开发者对资源的掌控力更强，从而避免了运行时的意外。</p><h4>Go VS Rust，Pick 谁？</h4><p><strong>什么时候会更倾向于Go？</strong></p><ul><li>在构建内部系统、运维工具、以及大部分业务逻辑复杂的CRUD应用时，Go的开发效率是巨大的优势。它的生态成熟，招聘相对容易，能让团队快速响应业务需求。</li></ul><p><strong>什么时候会选择Rust？</strong></p><ul><li>对于那些直接面向用户、对性能和资源消耗有严苛要求的核心服务，我会选择Rust。例如，API网关、底层中间件、实时计算引擎等。在这些领域，可预测的低延迟和内存效率至关重要。</li></ul><h3>对未来五年的看法</h3><p>我认为，Go和Rust并不会是谁取代谁的关系，而是会在各自擅长的领域里变得更加重要。</p><ul><li><strong>Go</strong> 将继续作为云原生时代的核心语言之一，在微服务和业务后端领域保持其强大影响力。</li><li><strong>Rust</strong> 则会在高性能计算、系统编程和基础设施领域占据越来越重要的位置，成为追求极致性能和安全性的团队的首选。</li></ul><h3>动手实践是最好的检验方式</h3><p>伟人曾经说过，实验是检验真理的唯一标准，所以最好的方式还是亲手实践一下，感受两种语言在开发体验和运行表现上的真实差异。</p><p>但环境配置往往让人抓耳挠腮。安装Go，再安装Rust，管理不同版本和依赖，尤其是在一个团队里，有的人用macOS，有的人用Windows，环境不统一很容易在协作中产生不必要的问题。</p><p>那 <strong>ServBay</strong> 这样的工具就非常有用了。</p><p><strong>ServBay</strong> 是一个集成的<a href="https://link.segmentfault.com/?enc=Cfsv4XF8ifPDwWDtpSpjwA%3D%3D.Nch1P1a%2Frh6jL1EvS0GqhaT1AONSFwMPKaTa%2B2EIaN4%3D" rel="nofollow" target="_blank">本地开发环境工具</a>，支持macOS和Windows。它能一键安装和管理Go、Rust以及Python、PHP、Node.js等多种开发环境，并且各个环境之间是隔离的，不会互相干扰。</p><p><img width="723" height="458" referrerpolicy="no-referrer" src="/img/bVdm4y5" alt="image.png" title="image.png" loading="lazy"/></p><p>这样一来，无论是想快速验证一个Go的Web服务想法，还是想深入学习Rust的所有权模型，都不再被繁琐的环境配置所困扰。它提供了一个统一、干净的实验平台，让我们可以把精力真正集中在代码和架构的探索上。</p><p><img width="723" height="458" referrerpolicy="no-referrer" src="/img/bVdm4y6" alt="image.png" title="image.png" loading="lazy"/></p><p>最终选择哪门语言，其实是选择在项目的哪个阶段投入更多精力：是前期的严谨设计与实现，还是后期的性能调优与维护。通过ServBay这样的工具亲手尝试，或许能帮我们更快地找到适合自己项目和团队的答案。</p>]]></description></item><item>    <title><![CDATA[FMEA与数字化工具结合的应用案例与未来]]></title>    <link>https://segmentfault.com/a/1190000047405394</link>    <guid>https://segmentfault.com/a/1190000047405394</guid>    <pubDate>2025-11-17 18:14:07</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>FMEA是什么？——系统性、前瞻性的产品与过程失效模式分析工具<br/>失效模式与影响分析（FMEA），即Failure Mode and Effects Analysis，是一种广泛应用且经过时间考验的风险管理方法论。它本质上是一种系统性的、前瞻性的分析活动，旨在识别和评估潜在的产品或过程失效模式及其后果。FMEA的核心在于其“预防性”思维，通过在问题实际发生前对其进行结构化的剖析，帮助企业锁定风险点，从而采取针对性的预防或探测措施，提升产品设计的可靠性、制造过程的稳定性和最终的客户满意度。<br/>从应用范围来看，FMEA主要分为两大类型。设计FMEA（Design FMEA，简称DFMEA）聚焦于产品设计阶段，旨在识别设计缺陷可能引发的失效模式，如结构强度不足、功能异常、材料选择不当等，并通过设计改进来规避这些风险，确保产品在设计层面就具备高质量和高可靠性。例如，在汽车零部件设计中，通过DFMEA分析可能存在的腐蚀、断裂等问题，从而优化选材和设计结构，提升部件的使用寿命和安全性。<br/>过程FMEA（Process FMEA，简称PFMEA）则应用于生产制造阶段，关注生产流程、设备、人员、物料、方法等各环节可能出现的失效情况，如参数漂移、装配错误、焊接不良等，并制定相应的控制策略，以保障生产过程的稳定运行和产品质量的一致性。一个典型的电子制造业案例是，某企业通过PFMEA深入分析了SMT贴片工艺中焊膏回流可能出现的虚焊、锡珠、桥接等失效模式，识别出温度曲线设置不当、焊膏保存条件不满足等因素，并据此优化了工艺参数和环境控制，显著降低了生产缺陷率。</p><p>FMEA为什么要做？——其核心价值在于事前预防与持续改进<br/>其次，FMEA有助于强化产品和过程的质量控制。通过在设计和过程层面主动寻找薄弱环节，FMEA促使企业从源头入手，优化设计方案，改进工艺流程，使得最终交付的产品或服务具有更高的可靠性和一致性。例如，某汽车制造商在新车型开发中严格执行DFMEA，有效预防了早期设计中未考虑到的零部件接口问题，确保了整车装配的顺畅和功能的完善，显著提升了用户在使用过程中的体验。<br/>再者，FMEA能够提升企业的整体运营效率。提前识别和解决潜在失效模式，意味着减少了生产过程中的故障停机时间、减少了因质量问题导致的物料浪费和返修成本，提高了资源的利用率和生产效率。同时，FMEA作为一种持续改进的机制，鼓励团队不断反思和学习，积累组织知识，提升整体的风险意识和应对能力。<br/>典型案例如，广域铭岛FASTWORX FMEA平台建立了在线协同编制和在线评审体系，加强FMEA管理，让相关人员都了解到失效原因和失效影响。便于企业成立多功能小组，有利于调动员工积极性<br/>最后，FMEA是建立客户信任的重要途径。当企业能够通过FMEA展示其对产品质量的严谨态度和有效控制时，无疑会增强客户对其产品和服务的信心。这对于企业拓展市场、提升品牌形象具有长远的战略意义。</p><p>FMEA怎么做？——系统化实施流程与实践要点<br/>在实际操作中，为了提升FMEA的效率和效果，一些领先企业开始结合数字化工具进行实施。例如，利用FMEA软件平台（如FASTWORX FMEA）来辅助分析，实现数据的统一管理、多人协同编辑、版本控制以及RPN自动计算等功能。同时，通过与产品生命周期管理（PLM）、制造执行系统（MES）等系统的集成，使FMEA分析能够实时反映最新的设计和工艺信息，提高准确性。此外，经验教训的积累和共享也是FMEA成功实施的关键，将其录入FMEA数据库，有助于避免重复犯错，并为后续的分析提供参考。<br/>某汽车研究院通过广域铭岛FASTWORX FMEA系统使得通过FMEA在线协同编辑，实现全公司研发相关人员的社交化协作，消除部门间隔阂，提高30-50%开发工作效率，缩减开发时间约50%。<br/>总之，FMEA作为一种强大的风险管理工具，其实施需要系统的方法、跨部门的协作以及持续的投入和改进。当正确应用于产品开发和生产制造过程时，FMEA能够为企业带来显著的质量提升和成本节约效益，是实现高质量、高可靠产品交付的重要保障。</p>]]></description></item><item>    <title><![CDATA[工艺工程怎么优化生产流程以降低成本？ 月]]></title>    <link>https://segmentfault.com/a/1190000047405402</link>    <guid>https://segmentfault.com/a/1190000047405402</guid>    <pubDate>2025-11-17 18:13:08</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在当今制造业迅猛演进的洪流中，工艺工程俨然成为企业竞争力的基石，它不仅定义了生产流程的精髓，更在数字化转型的浪潮中扮演着不可或缺的角色。工艺工程，这一涵盖从设计到执行的全面体系，通过科学的方法论和技术创新，持续推动着生产效率的提升与产品质量的优化。广域铭岛，作为工业互联网领域的先锋，以其先进的平台技术，为工艺工程的智能化注入了鲜活动力，使传统制造焕发新生。<br/>工艺工程的核心在于其多维度的内涵：它起始于精密的工艺设计与规划，工程师需深入分析产品特性与市场动态，构建高效且稳定的生产流程；继而延伸至设备选型与布局，通过智能配置最大化资源利用率；更重要的是，工艺参数的设置与优化，如同交响乐中的指挥棒，细微调整便能协调整个生产节奏，确保输出的一致性；而工艺流程的改进与创新，则体现了工艺工程的动态本质，不断吸纳新技术以应对市场变幻。广域铭岛通过其工业互联网解决方案，例如GQCM模具智能管理APP，将这些元素无缝集成，实现了冲压工序的数字化孪生，大幅削减非计划停机，彰显了工艺工程在实践中的强大效能。<br/>谈及工艺工程的作用，它远不止于提升效率；更是企业降本增效、保障质量的战略支点。通过优化生产流程，工艺工程能够显著减少材料浪费与能源消耗，例如在焊接工艺中，广域铭岛的点焊质量管理APP通过实时数据采集与算法模型，将焊点一次合格率推升至99.5%，这不仅降低了返工成本，还缩短了培训周期，凸显了工艺工程在质量管控中的卓越贡献。此外，工艺工程还驱动着技术创新与可持续发展，它融入绿色制造理念，减少排放，并借助人工智能和大数据实现从经验驱动到数据驱动的跃迁。广域铭岛的平台在此发挥了催化作用，通过预测性维护和效能分析，帮助企业构建智能化的生产生态，使工艺工程成为智能制造的中流砥柱。<br/>展望未来，工艺工程将继续深化其数字化转型，拥抱工业4.0的机遇。随着人工智能和物联网技术的普及，工艺工程将更加智能化、自适应化，为企业提供前所未有的灵活性与竞争力。广域铭岛等企业的持续创新，无疑将加速这一进程，推动工艺工程向更高维度进化，最终赋能制造业实现全面升级与可持续发展。</p>]]></description></item><item>    <title><![CDATA[不止合规 JoySSL国密数字证书安全高]]></title>    <link>https://segmentfault.com/a/1190000047405411</link>    <guid>https://segmentfault.com/a/1190000047405411</guid>    <pubDate>2025-11-17 18:12:22</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>随着互联网技术的快速升级，数字经济也迎来蓬勃发展，数据信息在网络世界中不断传输交互，构筑起现如今庞大的互联网体系。由于互联网发展具有双面性，且信息安全是国家发展的重要基石。因此，数据信息的安全传输，成为了公众最为关注的问题之一。国密数字证书通过建立加密通信通道，验证服务端身份等方式，成为网络安全防护领域的重要工具。作为国内专业的数字安全服务商，JoySSL率先完成国密证书技术体系搭建，并全网普及，为企业数字化转型与网络安全系统建设提供一站式解决方案。</p><p><img width="723" height="549" referrerpolicy="no-referrer" src="/img/bVdm4tu" alt="" title=""/></p><p><strong>技术升级 国密证书的核心优势</strong></p><p>作为我国自主研发的加密算法体系，国密算法包含SM2（非对称算法）、SM3（杂凑算法）和SM4（对称算法），与国际算法相比，自主研发的国密算法无论是安全表现还是功能表现上，皆更具优势。传统数字证书通常都采用国际加密标准，如RSA或ECC。而国密证书以自研密码算法为基础，实现强大的加密功能，确保数据安全传输。JoySSL技术总监指出，国密算法在相同安全强度的前提下，密钥长度相比RSA更短，运行效率更高，且算法经过国家密码管理局严格认证，可有效防范各种密码攻击手段。</p><p><strong>应用普遍 数字证书的不断普及</strong></p><p>截至目前，国密数字证书已成为电子政务系统的标配，在政务领域应用范围甚广。凭借有效的防护手段和加密算法，国密证书在金融、医疗等对数据安全要求高的行业，有着极高的需求度。</p><p><img width="723" height="549" referrerpolicy="no-referrer" src="/img/bVdm4tv" alt="" title="" loading="lazy"/></p><p>JoySSL作为数字安全领域的专业服务商，与多家银行达成合作，部署国密SSL证书，利用加密算法完成网银系统升级，有效降低潜在的安全风险，增强隐私数据防护能力。不仅提升了交易的安全性，同时也获得了用户与市场的信任。</p><p><strong>生态搭建 国密证书的全面服务</strong></p><p>随着国内《数据安全法》《网络安全法》等一系列法规的相继出台，社会各界普遍对网络安全防护的认识不断加深，应用范围和领域也逐渐扩大。国密证书的推广与普及，让整个数字证书产业生态正在经历重塑，不仅获得了主流浏览器和操作系统的支持与认可，同时还具备极高的兼容性，让国密证书的普及范围进一步扩大。JoySSL市场部专家分析指出，国密数字证书的影响力与日俱增，市场认可度逐年提升，不仅推动了国内信息安全技术的发展，同时也推动了国内企业进一步朝着规范化、国际化的方向迈进。</p><p><img width="723" height="549" referrerpolicy="no-referrer" src="/img/bVdm4tw" alt="" title="" loading="lazy"/></p><p><strong>创新突破 国密证书的未来展望</strong></p><p>作为互联网技术的具体表现形式，国密证书的成长上限远不止于此。在网络技术升级迭代、市场需求变化和全球数字化发展的大趋势下，国密证书还有更大的上升空间。以JoySSL为代表的数字安全厂商，早已投入到国密证书最新技术的研发当中，利用更先进的技术理念和创新思维，打造出新一代国密证书，提升安全防护能力与市场渗透率，推动全球网络空间安全稳定发展。</p>]]></description></item><item>    <title><![CDATA[怎么利用设备全面诊断进行预测性维护？ 月]]></title>    <link>https://segmentfault.com/a/1190000047405418</link>    <guid>https://segmentfault.com/a/1190000047405418</guid>    <pubDate>2025-11-17 18:11:34</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在现代工业体系中，设备的高效运行与安全性保障已成为企业提升生产效率和竞争力的核心要素。设备全面诊断技术，作为一套通过实时监测、动态分析与预测性维护相结合的综合性解决方案，正在成为推动制造业智能化升级的关键引擎。该技术不仅涵盖了传统设备管理方法，还融合了物联网、大数据与人工智能等前沿科技，通过多维度的数据采集与多层次的分析手段，实现了从被动应对到主动预防的管理转型。<br/>设备全面诊断的本质在于对设备运行状态的全面感知与智能评估。借助各类传感器，系统可以实时采集设备的振动、温度、电流等关键参数，并通过边缘计算与云端分析平台进行深度处理。例如，振动分析不仅能识别轴承磨损与转子失衡等机械故障，还能结合其他数据源，提供更为准确的故障预警信号。与此同时，在诸如多源感知网络与仿真技术的支持下，设备全面诊断系统能够模拟极端条件下的设备运行情况，从而提前发现潜在隐患，避免重大事故发生。<br/>广域铭岛作为工业互联网领域的技术先锋，凭借其Geega平台为设备全面诊断的实现提供了理想的工具。该平台不仅整合了设备技术资料、运行数据与维修经验，还通过先进的AI算法实现了故障的自动诊断与维修方案的智能推送。在多个行业应用场景中，广域铭岛的系统成功帮助企业降低了非计划停机时间，并显著提升了生产效率与设备利用率。这种集成化的智能诊断方式，使得设备维护从经验驱动转向数据驱动，全面革新了传统管理模式。<br/>从实际应用效果来看，设备全面诊断带来的价值不仅局限于简单的故障修复。在制造业生产车间，通过优化工艺参数与实时监控设备健康状态，企业能够在节能环保的前提下，进一步提高生产线的产出稳定性。特别是在一些大型制造基地，设备全面诊断系统的应用直接带来了成本削减与生产效率提升的双重效应。这使得全面诊断不仅是一种技术革新，更是企业实现降本增效的重要战略手段。<br/>此外，设备全面诊断的应用范围正在扩展至更广泛的领域，包括能源、医疗、交通等。在核电设备与大型医疗机械中，实时的状态监测与预测性维护同样发挥着不可忽视的作用。并且随着技术的不断演进，设备全面诊断正在与AR远程指导、自动化运维机器人等创新技术相结合，推动工业生态向协同化与智能化方向发展。<br/>展望未来，设备全面诊断将在工业4.0与绿色制造的时代浪潮中扮演更加重要的角色。作为一种融合多学科技术的解决方案，它不仅能够帮助企业减少停机时间与维护成本，还能加速资源的循环利用与生产流程的优化。随着新一代技术整合的深入，设备全面诊断的准确度与覆盖范围将进一步提升，成为企业持续发展的强大支撑。</p>]]></description></item><item>    <title><![CDATA[SCALE | 2025 年 10 月《]]></title>    <link>https://segmentfault.com/a/1190000047405440</link>    <guid>https://segmentfault.com/a/1190000047405440</guid>    <pubDate>2025-11-17 18:11:00</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405442" alt="" title=""/></p><h2>一、本月导览与核心看点</h2><p>2025 年 10 月，<a href="https://link.segmentfault.com/?enc=cW4fsNRkH2Aqg2xSOTu76g%3D%3D.nexlr2UCqR0EBgVYnuMYSxzdG1n1F5d04YSJxF%2BG1SBhIklu%2FmyX1x6Hf41auxIc" rel="nofollow" title="SCALE 202510" target="_blank">SCALE</a> 评测基准持续追踪 AI 在专业 SQL 领域的最新进展。本月，榜单迎来了蚂蚁百灵大模型团队发布的两大 万亿级 参数的模型：<a href="https://link.segmentfault.com/?enc=yoWf3dkPoGLIWJGAWaD07Q%3D%3D.7izThiew3nVzZPjxm5BM0Z8Wtqr1ASbU1qFSuqAnBKrxItnLNXTW1zr7A9xFNPAL" rel="nofollow" target="_blank">Ling-1T</a> 和 <a href="https://link.segmentfault.com/?enc=vWC60RQzawASIvdW8u4FpQ%3D%3D.6wk9FO6vI6J318pw6EJNnZDi3RovnaPZ5%2F%2ByYuzXEy%2BWLyzegwm%2BIGCb4KAV%2BJPw" rel="nofollow" target="_blank">Ring-1T</a>。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405443" alt="" title="" loading="lazy"/></p><ul><li><strong>Ling-1T</strong> ：蚂蚁百灵大模型 <strong>Ling 2.0</strong> 系列的第一款旗舰模型。</li><li><strong>Ring-1T</strong> ：一款基于 <strong>Ling 2.0</strong> 架构的思考模型，也是全球首个开源万亿参数思考模型。</li></ul><p>本期核心看点：</p><ul><li><p><strong>新增模型评测</strong> ：首次引入蚂蚁 <em>Ling-1T</em> 与 <em>Ring-1T</em> 模型。评测数据显示，两款模型呈现出清晰的能力分化：</p><ul><li>Ling-1T 在「<strong>国产数据库</strong>」转换场景中表现突出，获得满分！</li><li>Ring-1T 在「<strong>SQL 优化</strong> 」和「<strong>SQL 理解</strong> 」维度展现了 <strong>更为均衡和稳健的综合能力</strong>，总分均进入榜单上游。</li></ul></li></ul><h2>二、评测基准说明</h2><p>为保证评测结果的长期可比性和权威性，本月我们的核心评测基准与算法保持不变，继续沿用 <strong>SCALE</strong> 自创立之初便确立的三维评测体系，确保所有模型与工具在统一、标准的测试环境下进行评估，以提供公正、可复现的评测结果。</p><ul><li><strong>SQL 优化</strong>：考察模型提升查询效率与性能的意识和能力。</li><li><strong>方言转换</strong>：考察模型在主流数据库之间进行语法迁移的准确性。</li><li><strong>SQL 理解</strong>：考察模型是否能精准解析复杂的查询逻辑与用户意图的能力。</li></ul><p>本月所有新增模型均在此标准体系下进行评估。</p><h2>三、焦点分析</h2><h3>专题一：Ling-1T 首次评测</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405444" alt="发布日期：2025-10-09" title="发布日期：2025-10-09" loading="lazy"/></p><p><em>Ling-1T</em> 作为 <strong>Ling 2.0</strong> 系列的首款旗舰非思考模型，在本月首次参评。其各维度总分分别为：</p><ul><li><strong>SQL 优化</strong>：62.5</li><li><strong>方言转换</strong>：59.2</li><li><strong>SQL 理解</strong>：59.4</li></ul><p>评测结果显示，该模型能力特点鲜明，在特定场景表现优异，但在复杂任务处理上仍存在明显短板。</p><h4>SQL 优化能力：62.5</h4><p><em>Ling-1T</em> 在 <strong>SQL 优化</strong> 维度获得 62.5 分。根据细分指标数据显示，该模型在「<strong>逻辑等价</strong>」方面表现出色，以 84.2 分位列该项第 5 名。</p><p>然而，其在「<strong>优化深度</strong> 」上表现不足，得分仅为 51.1 分（排名第 17），同时「<strong>语法错误检测</strong> 」得分也偏低（84.2分）（排名第 18），分析测评报告可见，模型将符合 MySQL 宽松模式的 <code>GROUP BY</code> 查询误判为有语法错误；对 <code>UNION</code> 查询中 <code>ORDER BY/LIMIT</code> 的语法规则理解不准确。</p><p><strong>核心缺陷</strong> ：模型缺乏对数据库特定模式（如 MySQL 的 <code>ONLY_FULL_GROUP_BY</code>）和 <strong>SQL 标准/方言差异</strong> 的上下文感知能力，过度依赖教条式语法规则，无法根据数据库配置灵活判断语法正确性，导致在边界情况下的误判。这一系列分数表明，模型具备保障逻辑一致性的能力，但在应用深度优化策略和保障语法规范性方面仍有较大提升空间。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405445" alt="Ling-1T：SQL 优化维度评分" title="Ling-1T：SQL 优化维度评分" loading="lazy"/></p><h4>方言转换能力：59.2</h4><p>此维度得分呈现出显著的能力分化（总分 59.2，排名第 17）。<strong>其最大亮点在于对国内数据库生态的适配性</strong> ，其「<strong>国产数据库</strong> 」转换子项获得 100 分满分（与 <a href="https://link.segmentfault.com/?enc=fe3gmIsw%2BL2GLKEs1JsNjw%3D%3D.xJRTIb4M4tdMJKBeYxT%2FodOG4tU8tY70Cj2jCrYvkhM%3D" rel="nofollow" target="_blank">SQLShift</a> 并列），展现了其在该特定场景下的卓越能力。</p><p>然而，模型在处理复杂迁移任务时表现挣扎。「<strong>大 SQL 转换</strong> 」得分仅为 12.9分（排名第 20）。测评报告显示，在复杂 SQL 方言转换中，模型误用不兼容语法（如保留 <code>SET NOCOUNT ON</code>、混用 <code>DBMS_OUTPUT</code> 等），且对控制流、游标、异常处理等结构的语义理解不足，导致转换后语法不兼容或逻辑不等价，这体现出模型对复杂结构化代码的全局理解能力，以及对多方言语义差异的精确把握能力还有待提升。同时，其「<strong>逻辑等价</strong> 」（61.3分）和「<strong>语法错误检测</strong>」（69.0分）得分中等，表明其在处理非国产数据库的复杂转换时，难以保证代码的规范性。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405446" alt="Ling-1T：方言转换维度评分" title="Ling-1T：方言转换维度评分" loading="lazy"/></p><h4>SQL 理解能力：59.4</h4><p>该分数表明 <em>Ling-1T</em> 具备基础的 SQL 解析能力。数据细分显示，其在「<strong>语法错误检测</strong> 」上表现突出，以 87.1 分的成绩与 <em>Claude 3.5 Sonnet</em> 并列该指标测评的第 1 名。</p><p>然而，其在「<strong>执行准确性</strong> 」方面表现不佳，得分仅为 52.9 分（排名第 19），分析测评报告可见，模型在日期条件测评中易出错，如 <code>due_date &lt; '2025-06-07'</code> 的查询中返回了 <code>due_date='2025-06-10'</code> 的记录，明显违反了条件。这类错误反映了模型在执行 SQL 查询时，对日期比较的语义理解与严谨性不足。这是其主要短板之一。</p><p>此外，其「<strong>执行计划检测</strong> 」得分为 57.1 分，模型在执行计划预测时，对 DDL 中未定义索引的字段错误预测了 <code>key</code> 和 <code>possible_keys</code>。例如查询 <code>WHERE fruit_name = 'Banana'</code> 时，模型预测 <code>key: "fruit_name"</code> 和 <code>possible_keys: "fruit_name"</code>，但 DDL 中 <code>fruit_name</code> 字段没有索引，反映出模型过于基于查询模式推测出现误判，在约束验证能力和结构化解析与推理上仍有较大提升空间。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405447" alt="Ling-1T：SQL 理解维度评分" title="Ling-1T：SQL 理解维度评分" loading="lazy"/></p><h3>专题二：Ring-1T 首次评测</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405448" alt="发布日期：2025-10-14" title="发布日期：2025-10-14" loading="lazy"/></p><p><em>Ring-1T</em> 作为基于 <strong>Ling 2.0</strong> 架构的万亿级参数思考模型，展现了比 <em>Ling-1T</em> 更强的综合实力。其各维度总分分别为：</p><ul><li><strong>SQL 优化</strong>：70.5</li><li><strong>方言转换</strong>：69.5</li><li><strong>SQL 理解</strong>：78.1</li></ul><p>能力表现更为均衡。</p><h4>SQL 优化能力：70.5</h4><p>该分数体现了模型在 SQL 优化方面的均衡能力。其「<strong>语法错误检测</strong> 」获得 100 分满分（与 <a href="https://link.segmentfault.com/?enc=iQZhC9UDrY6mCuwN%2BSnOSQ%3D%3D.8WljEnHlA%2B%2BecJWPu%2F7xR%2BlrGzKDgPPpXE2KMtMKM28%3D" rel="nofollow" target="_blank">SQLFlash</a> 并列），保证了优化后代码的规范性与可用性。「<strong>逻辑等价</strong> 」得分为 84.2 分（排名第 6），表现优异。「<strong>优化深度</strong>」得分为 60.0 分（排名第 4），表明模型能够应用常规的优化策略，但在处理复杂的查询、进行深度重构以追求极致性能方面，仍有进步空间。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405449" alt="Ring-1T：SQL 优化维度评分" title="Ring-1T：SQL 优化维度评分" loading="lazy"/></p><h4>方言转换能力：69.5</h4><p><em>Ring-1T</em> 在方言转换维度获得 69.5 分（排名第 11）。细分数据显示，其在「<strong>国产数据库</strong> 」转换（94.7分）、「<strong>语法错误检测</strong> 」（73.8 分，排名第 9）和「<strong>逻辑等价</strong>」（71.0 分）上均表现稳健。</p><p>其短板在于「<strong>大 SQL 转换</strong> 」，得分仅为 41.9 分（排名第 12），模型在处理跨数据库访问（如 SQL Server 的 <code>[server].database.schema.table</code>）、控制流（如 GOTO 标签跳转）、错误处理机制（如 <code>@@ERROR</code> 检查、<code>BEGIN TRY/CATCH</code>）、动态 SQL 执行（如 <code>sp_executesql</code> 参数绑定）等复杂结构时，存在语法混用、语义不等价、结构转换不完整等问题。</p><p><strong>核心缺陷</strong> ：缺乏对复杂结构化代码的全局理解能力，以及对多方言语义差异的精确映射能力，导致转换后的 SQL 在语法正确性或逻辑等价性上存在缺陷。相较于 <em>Ling-1T</em> 的 12.9 分，该分数有了显著提升，表明其在处理「<strong>大 SQL 转换</strong>」和保证代码规范性方面具备更强的能力，使其成为一个更可靠的数据库迁移工具。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405450" alt="Ring-1T：方言转换维度评分" title="Ring-1T：方言转换维度评分" loading="lazy"/></p><h4>SQL 理解能力：78.1</h4><p>得分 78.1 分，这是一个稳健的分数。其在「<strong>执行准确性</strong> 」上表现稳定（84.3分）。但其「<strong>执行计划检测</strong> 」（60.7分）和「<strong>语法错误检测</strong>」（67.1分）得分偏低。</p><p>模型混淆了标准 SQL 语法与数据库特定规则，将正确的标准语法误判为错误（如 GROUP BY 中使用别名 <code>category_prefix</code>、<code>INSERT</code> 子查询 <code>INSERT INTO table (SELECT ...)</code>、<code>CREATE VIEW</code> 中使用 <code>HAVING</code> 等），同时对复杂结构理解不准确，导致误判和漏判并存，反映了模型对标准 SQL 规范的准确理解不足，以及对语法规则判断的机械性。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405451" alt="Ring-1T：SQL 理解维度评分" title="Ring-1T：SQL 理解维度评分" loading="lazy"/></p><h2>四、专家点评</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405452" alt="" title="" loading="lazy"/></p><blockquote><strong>林春</strong>，中国太平洋保险数智研究院首席数据库专家，OceanBase 客户专家委员会（OBCE）专家委员，获得 OBCE 认证。获得 Oracle OCM、PostgreSQL PCM、MySQL OCP 认证。墨天轮 MVP，中国数据库技术大会（DTCC）演讲嘉宾。</blockquote><p>SCALE 2025 年 10 月《大模型 SQL 能力排行榜》的发布，堪称 AI 与数据库协同领域的关键行业参照。其依托"<strong>SQL优化+方言兼容+SQL理解</strong> "的三维测评框架，将大模型在数据库场景的落地能力进行了体系化量化，尤其在 Ling-1T、Ring-1T 等模型的分项表现中，清晰呈现了自然语言与数据库操作的适配差异，<strong>为企业级 AI+ 数据库的技术选型提供了精准的能力标尺</strong>。</p><p>这个榜单通过月度迭代的动态测评范式，既强化了对大模型数据库能力演进的追踪性，又以"细分场景得分+综合能力排名"的形式，缓解了企业对大模型"泛能力强、垂直场景弱"的选型焦虑，这与当前数据库向智能化、场景化演进的趋势高度契合。<strong>它不仅为中小企业提供了低成本评估 AI 数据库工具的参照标准，更倒逼大模型行业加速垂直能力优化 ------ 在 SQL 复杂查询适配、多数据库方言兼容等领域形成技术迭代</strong>。</p><p>SCALE 榜单的价值在于以标准化测评姿态打通了大模型能力与数据库需求的匹配链路，推动"<strong>模型能力评估-场景技术选型-落地效果验证</strong>"全流程的理性化重构，为下一代智能数据系统的技术适配提供了极具实践意义的行业范本。</p><p>我们可以看到，Ring-1T 模型在数据库场景中的核心优势场景包括：</p><ul><li><strong>复杂 SQL 查询生成</strong>：在多表关联、嵌套子查询等复杂 SQL 构建任务中表现突出（SQL 优化能力得分 70.5），可高效将自然语言需求转化为高性能 SQL 语句。</li><li><strong>多数据库方言兼容</strong>：适配 MySQL、Oracle 等主流数据库的语法差异（方言兼容能力得分 69.5），能自动生成符合不同数据库语法规范的操作语句。</li><li><strong>SQL 语义理解与纠错</strong>：对模糊需求、表述不规范的查询指令，具备较强的语义解析与纠错能力（SQL 理解能力得分 78.1），降低自然语言交互的精准度门槛。</li><li><strong>批量数据操作适配</strong>：在批量插入、更新等数据操作场景中，可生成高效且符合数据库性能要求的 SQL 脚本，适配企业级数据批量处理需求。</li></ul><h2>五、总结与展望</h2><p>随着蚂蚁百灵 <em>Ling-1T</em> 和 <em>Ring-1T</em> 两款新模型的加入，<strong>SCALE</strong> 评测榜单已累计收录超过 20 款业界主流 AI 模型及专业工具。本月评测清晰地展示了 <strong>Ling 2.0</strong> 系列两款模型的特点：</p><ul><li><strong>Ling-1T</strong> 在国产数据库适配上表现出众，但在复杂任务处理上存在短板</li><li><strong>Ring-1T</strong> 则展现了更均衡、更强大的综合 SQL 处理能力，特别是在 SQL 理解和优化方面表现稳健</li></ul><p>展望未来，SCALE 将继续秉持客观、严谨的原则：</p><ul><li>持续追踪：我们将继续追踪并迅速引入业界前沿的大模型和 SQL 工具。</li><li>深化场景：我们计划引入更多维度的企业级真实应用场景，使评测结果更贴近实际生产环境。</li></ul><blockquote><p>一个开放、透明的评测生态需要社区的共同建设。我们诚挚地邀请国内外更多的模型开发者、数据库工具提供商提交您的产品参与 SCALE 评测。通过在同一基准下与全球顶尖模型竞技，不仅可以精准定位产品优势与不足，更能提升品牌在开发者社区中的影响力。</p><p>即刻访问 <a href="https://link.segmentfault.com/?enc=SzLc73R6%2B%2BplY%2FrKKvIoYA%3D%3D.H1To2bOix61zfOuf7TOKfEXsp8zYGc3NeDLiJNjnOnRzcqXqq0v3v9MgVnvTA1Ug" rel="nofollow" target="_blank">https://sql-llm-leaderboard.com/ranking/2025-09</a></p><p>查看完整榜单并联系我们提交您的产品。</p></blockquote><p><strong>SCALE ------ 为专业 SQL 任务，选专业 AI 模型。</strong></p>]]></description></item><item>    <title><![CDATA[如何用 5 种方法删除三星手机上的消息/]]></title>    <link>https://segmentfault.com/a/1190000047405476</link>    <guid>https://segmentfault.com/a/1190000047405476</guid>    <pubDate>2025-11-17 18:10:26</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>三星一直向全球众多消费者销售其移动设备。三星智能手机，尤其是三星Galaxy S系列和Note系列，深受许多人的喜爱，特别是白领和大学生。</p><p>您可能对手机的新功能非常感兴趣，但您也应该注意在管理联系人和短信时需要哪些操作。您是否曾经想知道如何在三星手机上删除短信？我们将向您展示一些在三星手机上删除垃圾短信/联系人的方法。</p><h3>第一部分：如何在三星S25/24/23上手动删除短信</h3><p>如何在三星手机上删除短信？最常见的方法是在应用内手动删除。以下是如何在三星 Galaxy S25/S24/S23 上手动删除单条短信的方法。</p><p>步骤 1. 打开三星手机上的短信应用。</p><p>步骤 2. 长按要删除的消息，直到出现菜单。</p><p>步骤 3：从菜单选项中选择“删除”。然后，在出现提示时确认删除。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405478" alt="图片" title="图片"/></p><h3>第二部分：如何通过联系人应用从三星手机中删除联系人</h3><p>就像删除短信一样，在三星手机上删除联系人也很简单。最简单的方法仍然是直接从联系人应用中删除。请按照以下步骤从三星手机中删除联系人：</p><p>步骤 1. 打开三星设备上的“联系人”应用。</p><p>步骤 2. 滚动浏览列表或使用搜索栏找到要删除的联系人。</p><p>步骤 3. 点击联系人以打开其详细信息。</p><p>步骤 4. 点击“编辑”按钮（铅笔图标）或“更多选项”菜单（三个垂直点），然后选择“删除”或“移除”。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405479" alt="图片" title="图片" loading="lazy"/><br/>​</p><h3>第三部分：如何使用Coolmuster Android Eraser 删除三星手机上的信息</h3><p>无法删除三星手机上的短信？之前的方法无法永久删除三星手机上的短信和联系人。如果您想永久删除它们，可以尝试使用Coolmuster Android Eraser软件。</p><p>Coolmuster Android Eraser 是一款专业的数据擦除软件。它可以删除三星手机上的所有内容，包括但不限于短信和联系人。它提供低、中、高三种数据擦除级别，您可以根据需要进行选择。除了三星手机，它还支持大多数Android手机型号，例如 OnePlus、摩托罗拉、小米、Tecno、TCL、谷歌、vivo 等。</p><p>Coolmuster Android Eraser 的主要功能</p><pre><code>彻底清除所有三星数据，包括联系人、短信和其他数据。
确保彻底永久删除个人数据，防止任何恢复尝试。
您可以从三个递增级别的数据清除级别中进行选择：低级别、中级别和高级别。
高级权限可以覆盖数据 3 次，因此无法恢复任何数据。
适用于大多数Android手机，例如三星、荣耀、小米、一加、摩托罗拉等。
支持Android 6.0或更高版本。

</code></pre><p>如何使用Coolmuster Android Eraser 在三星 S25/24 上删除单个短信/联系人？以下是分步指南。</p><p>01安装、下载并打开Coolmuster Android Eraser。之后，使用 USB 数据线或 Wi-Fi 将您的三星手机连接到电脑。</p><p>02连接成功后，按下“擦除”按钮开始擦除过程。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405480" alt="图片" title="图片" loading="lazy"/></p><p>03现在，您可以从低、中或高三个级别中选择您偏好的安全级别。选择后，点击“确定”继续。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405481" alt="图片" title="图片" loading="lazy"/></p><p>04确认后，软件将迅速扫描您的Android手机中的文件并开始数据擦除程序。</p><h3>第四部分：如何使用Coolmuster Android Assistant从三星手机中删除短信</h3><p>除了Coolmaster Android Eraser之外，Coolmaster Android Assistant也能删除三星手机上的短信和联系人。除了删除短信和联系人之外，这款软件还能在电脑和手机之间传输数据，直接在电脑上编辑、添加、发送或恢复短信，以及在电脑上编辑联系人。除了短信和联系人之外，它还支持视频、图片、音乐等多种类型的数据。</p><p>Coolmuster Android Assistant的主要功能</p><pre><code>允许您选择性地删除三星手机短信和联系人。
在电脑上收发短信。
在电脑上轻松编辑现有联系人并创建新联系人。
一键备份和恢复Android手机短信、联系人和其他文件。
兼容最新的Android 16系统。

</code></pre><p>以下是如何使用Coolmuster Android Assistant在三星手机上删除短信的教程：</p><p>01在您的计算机上下载、安装并运行Coolmuster Android Assistant 。</p><p>02选择 USB 或 Wi-Fi 将三星手机连接到电脑。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405482" alt="图片" title="图片" loading="lazy"/></p><p>03连接成功后，从左侧面板选择“短信”。手机上的所有短信都会显示在这里。选中要删除的短信，然后点击页面顶部的“删除”。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405483" alt="图片" title="图片" loading="lazy"/></p><p>如果您想通过此软件从三星手机中删除联系人，步骤与删除短信相同。连接成功后，选择“联系人”类别，勾选要删除的联系人，然后点击“删除”按钮完成操作。</p><h3>第五部分：如何通过恢复出厂设置删除三星 S25/24/23 上的多条短信</h3><p>如果您不想使用第三方软件，但又想彻底删除三星手机上的短信和联系人，可以尝试恢复出厂设置。请注意，此方法会删除手机上的所有数据，因此请谨慎操作。最好在操作前备份您的三星手机。具体步骤如下：</p><p>第一步：进入三星手机的设置界面。找到并点击“常规管理”选项。</p><p>步骤 2. 您会看到“重置”选项。点击它，然后点击“恢复出厂设置”。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405484" alt="图片" title="图片" loading="lazy"/></p><p>步骤 3：向下滚动并点击“重置”。然后输入您的 PIN 码，点击“继续”&gt;“全部删除”，输入您的三星帐户密码，然后点击“确定”。您的三星手机将开始重置，并删除所有短信和其他数据。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405485" alt="图片" title="图片" loading="lazy"/></p><h3>结论</h3><p>以上提到的 5 种方法可以帮助您删除三星手机上的信息/联系人，但只有Coolmuster Android Eraser可以永久删除它们，且无法恢复，包括现有信息和已删除信息。</p><p>如果您想在三星手机上管理短信或联系人，我们推荐使用Coolmuster Android Assistant，这是一款专业的数据管理软件。如果您对此有任何疑问，请在评论区留言。我们会尽快回复您。<br/>​</p>]]></description></item><item>    <title><![CDATA[云栖实录 | 洋钱罐基于 EMR Ser]]></title>    <link>https://segmentfault.com/a/1190000047405499</link>    <guid>https://segmentfault.com/a/1190000047405499</guid>    <pubDate>2025-11-17 18:09:30</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>演讲人：宋晓峰 洋钱罐大数据运维总监</p><h2>十年破壁：从数据筑基到智能生态的全链路实践</h2><h3>一、数据筑基——自建大数据集群的攻坚与突破</h3><h4>背景介绍</h4><p>瓴岳科技（Fintopia）是以大数据和人工智能为基础的数字科技集团，为全球用户提供卓越的金融体验。2015年成立至今，瓴岳科技始终聚焦消费金融，业务遍布中国大陆、东南亚、拉丁美洲和非洲等；集团旗下拥有洋钱罐、Easycash等知名品牌，截至2025年，服务全球金融机构超过114家，全球注册用户超过1.81亿，全球累计交易额超过5400亿元。在公司发展的过程中，我们大数据部门为智能风控、精准营销、产品创新三大核心业务提供数据支撑，整合多源数据，利用机器学习算法实时识别欺诈风险，构建全流程风控体系，基于用户行为、偏好等数据，定制个性化金融服务推荐，通过分析市场趋势与用户需求数据，为产品开发提供精准方向，助力瓴岳科技全球化业务布局。</p><h4>大数据技术栈迭代与升级路径</h4><p>过去十年，洋钱罐的大数据技术栈经历了多次迭代。</p><p>2018年，面对数据孤岛问题及传统MySQL数据库无法有效支持复杂分析任务的挑战，我们自建了首个基于十多个节点的Hadoop大数据集群。当时用户规模约2000万，每日新增数据量约300GB。</p><p>随着业务需求的增长，特别是在2018年至2021年间，原有的MapReduce 框架因处理延迟较高而难以满足日益增长的数据处理时效性要求。因此，在2021年，我们将离线数据处理引擎由MapReduce迁移至Apache spark 2.x，并同步升级了Hive版本至3.x以提升数据仓库性能。彼时，系统每天运行约3,000个批处理作业。</p><p>为进一步提高数据处理效率并响应业务对数据实时性的更高期待，2022年我们引入了数据湖技术Apache Hudi，从而将原本的日全量数据抽取转变为增量更新模式，显著提升了数据的新鲜度至小时级别。</p><p>此外，为了更好地支持交互式查询场景，在2023年我们采用StarRocks作为新的Ad-hoc查询引擎，取代了之前依赖于Spark Thrift Server实现的方法。截至目前，Ad-hoc 日均SQL查询请求量超过8,000，P95响应时间控制在60秒以内。鉴于全球化布局带来的弹性资源、业务稳定性和成本优化要求，我们在2024年对整个集群架构进行了重大升级，将自建集群迁移至阿里云EMR Serverless平台，Yarn 节点规模超过一千台，在此过程中，我们也将spark 2.x升级到了spark 3.x。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdm4tg" alt="image.png" title="image.png"/></p><p>当前，我们集群的整体存储能力已经达到单副本10PB的规模，每日新增数据量约为30TB。核心业务报表数量超过3000份，而调度工作流数量已突破15000个。在StarRocks集群方面，我们同时采用了存算一体化架构与存算分离架构，并根据不同的业务线进行了划分，因此目前拥有超过30个独立的StarRocks集群实例。左侧展示的是我们的调度能力和 Ad-hoc 查询能力，YARN日执行job量超过4万。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdm4tk" alt="image.png" title="image.png" loading="lazy"/></p><h4>从稳定性到效率：自建集群的困境解析</h4><p>在自建大数据集群的过程中，我们遇到了诸多挑战，主要集中在稳定性、弹性资源管理和运维效率三个方面。</p><p>首先，在稳定性方面，我们面临的主要问题是业务SLA破线。这种情况往往源于底层 NodeManager 因网络带宽限制或shuffle 量大而导致任务失败率上升。此外，在使用开源组件过程中，也存在一些 bug 或者性能问题，比如我们在使用 Hive3.x 开源版本时，在高并发的场景下会出现进程卡死等问题，从而影响业务稳定性，无法满足生产环境的要求。</p><p>其次，在弹性资源管理上，自建集群缺乏快速扩展的能力以应对突发流量需求。例如，在凌晨遇到紧急情况时，希望迅速增加计算资源来解决问题变得不可行。同时，即使进行了物理服务器的扩容，在YARN的容量调度策略下，也难以有效平衡不同队列之间的负载分布，导致部分队列利用率过高而其他队列则相对空闲，整体上降低了集群资源利用效率。</p><p>最后，关于运维效率的问题，大数据集群的维护工作相当复杂且耗时。从硬件采购到最终完成配置并投入使用，整个过程通常需要两至三天时间。此外，开发人员还需投入大量精力进行性能调优、故障排除及日常巡检等任务，这不仅增加了人力成本，也影响了团队的工作效率。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdm4ts" alt="image.png" title="image.png" loading="lazy"/></p><h4>Spark 引擎核心痛点解析</h4><p>在使用Apache Spark引擎的过程中，我们遇到了几个核心痛点，这些问题主要集中在资源管理、性能与稳定性、版本升级以及成本控制等方面。</p><p>首先，在资源管理方面，我们面临的主要问题之一是峰值资源的优化。例如，在凌晨执行大规模任务时，该任务可能会占用队列中90%以上的资源，而其他较小的任务虽然只占用了剩余10%左右的资源，但其完成时间却可能更长。这表明了当前资源分配机制存在不合理之处，需要更加精细地调整以提高整体效率。另一个问题是谷值期间资源利用率低下。特别是在非高峰时段（如午夜过后），集群的整体资源利用率往往只能达到30%左右，导致大量计算能力被闲置。</p><p>其次，在性能与稳定性方面也存在问题。当我们使用自建的大数据集群部署Spark时，采用的是开源版的Shuffle Service作为NodeManager组件。然而，在高负载情况下，这种服务的表现并不理想，容易成为瓶颈，并且当单个NodeManager出现问题时，会严重影响到整个集群上运行任务的稳定性和性能。</p><p>第三点关于引擎版本固化的问题也非常突出。比如将 spark 2.x迁移到spark 3.x，不仅耗时较长，还需要充分考虑新旧版本之间的兼容性问题、系统稳定性测试以及对现有业务流程的影响评估等多方面因素。</p><p>最后，在成本控制方面同样存在着挑战。由于不同业务线之间可能存在交叉需求，比如风控场景下的离线数据仓库处理与Adhoc查询同时进行，这就使得很难按照单一业务维度来精确划分和管理相关费用。因此，如何有效地衡量并优化跨部门使用的Spark资源成本，成为了我们需要解决的重要课题之一。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdm4tx" alt="image.png" title="image.png" loading="lazy"/></p><h4>StarRocks 问题解析</h4><p>在使用 StarRocks 的过程中，我们也遇到了一些挑战，主要集中在数据导入、资源隔离及系统稳定性三个方面。</p><p>首先，在数据导入方面，StreamLoad 导入速度慢，支持的数据量有限，当提高数据导入频率时，可能会触发 FE 内存问题，会出现MVC相关报错。Broker Load 虽然导入速度快，但是软性资源隔离策略会影响读性能，最后我们还是要依赖Spark集群的Spark Load解决大数据量导入问题</p><p>其次，关于资源隔离的问题，虽然开源版StarRocks提供了基本的资源隔离功能，但它是软隔离，而非硬性隔离，数据导入与查询操作之间存在竞争关系，尤其是大规模查询请求可能会影响其他小型查询请求的响应时间。</p><p>最后，在系统运维与稳定性保障方面，开源版本没有自带的管控页面，运维人员不得不自行开发一系列脚本来完成扩缩容等请求，增加了运维难度。此外，在面对版本升级时，升级耗时长，还需额外进行业务回归测试以验证新版本兼容性和系统稳定性。</p><p>以上因素共同构成了 StarRocks 在实际应用中面临的主要技术挑战。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdm4tC" alt="image.png" title="image.png" loading="lazy"/></p><h3>二、云帆起航——迁移阿里云 EMR 的全链路实践</h3><p>面对上述挑战，我们对大数据架构进行了全面升级，全面切换至阿里云生态组件。此次升级的核心在于构建了一个符合数据湖理念的全新平台架构，该架构不仅满足了当前业务需求，还为公司未来向数据湖方向的发展奠定了坚实基础。此次升级主要对两个计算引擎进行了重大改造。</p><p>首先，我们将Hive SQL完全迁移至Spark SQL。因为相较于Hive SQL，Spark SQL展现出更优的执行效率，这也是业界共识。整体迁移过程非常丝滑，在性能与兼容性方面，EMR Serverless Spark 表现亮眼，还支持丰富的开源生态，如Kyuubi、Livy等。</p><p>其次，我们将 StarRocks 存算一体版本切换为了存算分离版本，这也顺应了Serverless 架构的发展趋势。</p><p>基于计算引擎升级，我们在上层构建了自己的数据应用产品，如一站式开发平台、标签系统、实时开发平台、数据质量监控系统、Ad-hoc查询等。</p><p>我们还将底层存储从传统HDFS切换为阿里云OSS-HDFS，消除了原生Hadoop文件系统中存在的单点故障问题。相比自建集群成本，新架构成本仅为其十分之一左右。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdm4tF" alt="image.png" title="image.png" loading="lazy"/></p><h4>EMR Serverless Spark：一站式数据平台服务</h4><p>EMR Serverless Spark 提供了一站式的数据平台服务，包括任务开发、调试、调度和运维等，极大地简化了数据处理和模型训练的全流程。内置 SQLEditor、Notebook 开发环境，提供版本管理，工作流调度，以及运维诊断能力。 版本管理功能使得用户能轻松切换Spark版本，只需确保SQL语句能正常运行，数据能正常处理即可，无需考虑底层基础设施的复杂性。</p><p>针对Spark和Python环境，用户可以根据具体业务需求进行配置，如调整spark-defaults.conf文件中的参数值，来优化特定应用场景下的性能表现。通过简单的spark-submit命令配合相关参数，即可快速切换到所需的运行时环境，极大提高了工作效率。</p><p>监控与诊断方面，EMR Serverless Spark 还提供完善的监控与诊断功能。提供工作空间、队列以及任务等各种维度的资源指标统计，方便用户更清晰地掌握作业运行情况。在Spark任务完成之后，收集和分析该任务的各种资源消耗指标，并根据这些指标给出合理的优化建议。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdm4tI" alt="image.png" title="image.png" loading="lazy"/></p><p>EMR Serverless Spark 还提供极致资源弹性与性能。首先，在弹性伸缩方面，支持 Driver/Executor级别进程弹性，最低支持一核力度，容器拉起时间在20秒以内。资源供给方面，底层是 Iaas + 神龙资源池，提供海量供给，自迁移至 EMR Serverless Spark 以来，我们尚未遇到任何资源短缺问题。</p><p>此外，EMR Serverless Spark 采用类似于YARN的资源管理模式。Workspace/队列两层Quota管理支持用户根据业务特性选择合适的提交路径。平台提供了基于Workspace/队列/作业的多维度、精确到天/时/分的多周期资源观测能力。</p><p>性能方面，EMR Serverless Spark 自研 Fusion 引擎，内置高性能向量化计算和 RSS 能力，相比开源版本性能大幅提升。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdm4tJ" alt="image.png" title="image.png" loading="lazy"/></p><h4>EMR Serverless StarRocks：功能丰富、性能卓越</h4><p>EMR Serverless StarRocks在管控能力方面显著优于自建方案，提供实例管理功能，包括创建，扩容缩容，升降配，网络管理，白名单管理，操作任务管理，网关管理等。</p><p>此外，其管控平台提供实例健康报告与慢SQL诊断分析、可视化缓存管理、支持大/小版本主动触发滚动升级、支持全链路实例操作审计等功能。</p><p>值得一提的是，EMR Serverless StarRocks 实现了真正的存算分离架构，提供物理隔离能力，不同计算组作业负载相互独立，支持多计算组独立配置。在我们的实际应用场景下，存算分离内表查询较开源性能提升约100%，数据湖查询较开源性能提升约50%。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdm4tS" alt="image.png" title="image.png" loading="lazy"/></p><p>下图展示了基于EMR Serverless StarRocks 的湖仓新范式，StarRocks 作为统一 Lakehouse，基于湖表进行自助分析查询。数据写入 StarRocks 提供极速分析；数据写入开放数据湖，使用 StarRocks 直接分析数据湖；在DWD、DWS以及ADS层，通过构建物化视图并实施分层建模策略，不仅能够有效支撑各类报表需求，同时也为OLAP提供了强有力的支持。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdm4tX" alt="image.png" title="image.png" loading="lazy"/></p><h4>架构升级带来的关键价值</h4><p>上述重大架构升级，带来了哪些关键价值呢？</p><p>首先，在成本优化方面，通过引入弹性资源，显著提高了资源利用率。</p><p>其次，从业务稳定性角度来看，EMR Serverless Spark 自带的高性能 Shuffle 服务，极大地增强了系统的稳定性和可靠性。此外，StarRocks 的性能优化也进一步提升了整体业务处理能力与响应速度。</p><p>关于业务敏捷性，新架构支持快速部署新业务场景所需的计算资源，从而大幅缩短了业务上线周期。</p><p>运维效率方面，得益于 EMR Serverless Spark与 EMR Serverless StarRocks 丰富的管控能力，开发团队所需投入的日常维护工作量显著减少。同时，平台提供了全天候的技术支持服务，确保即使面对突发问题也能迅速获得解决方案，进一步保障了系统的连续可用性。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdm4t1" alt="image.png" title="image.png" loading="lazy"/></p><p>具体而言，在保持业务规模不变的前提下，与传统的自建方案相比，基于 EMR Serverless 构建的解决方案能够实现约25.4%的成本节约。基于 EMR Serverless StarRocks 进行查询（如标签系统和用户圈选场景），SQL 查询执行时长缩短了30%。此外，在相同成本情况下，EMR Serverless Spark 作业的执行时间也缩短了30%以上。最值得注意的是运维效率方面的改进，实现了近40%的大幅提升。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdm4ur" alt="image.png" title="image.png" loading="lazy"/></p><h3>三、智创未来——未来基于阿里云的智能生态布局</h3><p>在完成架构升级后，整体稳定性得到显著提升。展望未来，我们的目标是构建一个更加智能化的金融生态环境。为此，我们设想了四个主要发展方向：</p><p>首先，在数据处理方面，我们计划基于阿里云EMR及机器学习平台PAI来实现高效的数据协同架构。</p><p>其次，在业务流程优化上，通过整合阿里云的大规模模型能力，旨在创建一个既简化又高效的运营环境，涵盖预测式风控、自动化运营，大智能化监控等领域。</p><p>再者，在应用层面，致力于形成以数据为驱动并支持智能决策的完整业务闭环。</p><p>最后，在算法创新方面，我们将依托于阿里云机器学习平台PAI，专注于开发适用于特定行业的专属AI模型库。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdm4ut" alt="image.png" title="image.png" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[这两个开源项目在世界互联网大会乌镇峰会获]]></title>    <link>https://segmentfault.com/a/1190000047405501</link>    <guid>https://segmentfault.com/a/1190000047405501</guid>    <pubDate>2025-11-17 18:08:36</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>2025 <strong>“直通乌镇”全球互联网大赛</strong>是世界互联网大会乌镇峰会重要活动之一，自 2019 年以来已连续举办 7 届。本届大赛以“发现未来新势力 共筑数字新生态”为主题，设置人工智能、智联出行、数智医疗、智能制造、智能终端、开源项目（分为开源模型应用赛和开源竞技挑战赛）六大赛道。</p><p>自 6 月启动报名以来，共吸引来自全球 29 个国家的 1082 个项目报名参赛，其中国内项目 864 个、海外项目 218 个。经过激烈角逐，共有 71 个项目入围决赛，包含海外项目 11 个。在最终的决赛中：</p><p><strong>Spring AI Alibaba</strong> 和 <strong>Higress</strong> 分别获得了开源先锋社区、开源优秀社区的称号，两位社区贡献者<strong>张圣航</strong>（GitHubID: shenghang）、<strong>刑国富</strong>（GitHubID: erasernoob）获得最具价值贡献者奖。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405503" alt="image" title="image"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405504" alt="image" title="image" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405505" alt="image" title="image" loading="lazy"/></p><p>感谢所有社区贡献者和开发者用户们的信任。</p><h3>关于 Spring AI Alibaba</h3><p>Spring AI Alibaba 开源项目基于 Spring AI 构建，是阿里云通义系列模型及服务在 Java AI 应用开发领域的最佳实践，提供高层次的 AI API 抽象与云原生基础设施集成方案，帮助开发者快速构建 AI 应用。目前，Spring AI Alibaba 底层正升级到 AgentScope，未来作为 AgentScope 生态的一环，定位是做好 Spring 和 AgentScope 的连接。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405506" alt="image" title="image" loading="lazy"/></p><h3>关于 Higress</h3><p>Higress 是一款开源的 API 网关，内核基于 Istio 和 Envoy，可以用 Go/Rust/JS 等编写 Wasm 插件，提供对 K8s 集群的 Ingress 入口网关, 并且兼容了大量 K8s Nginx Ingress 的注解，可以从 K8s Nginx Ingress 快速平滑迁移到 Higress。此外，作为一款 AI 网关，提供 LLM API 和 MCP API 的统一管理。已服务于通义千问、阿里云百炼、携程、蚂蚁数科、钉钉、优酷、快手、Paypal、汤臣倍健、UU跑腿、Sealos、国泰产险等互联网、金融、IT 服务等多行业的企业客户。</p><p>率先在国内开源 AI 网关的通用能力，包括</p><ul><li>面向大模型：统一代理各主流大模型和自建大模型服务，提供 OpenAI 兼容的访问方式，并提供二次 API KEY 签发、限流、安全防护、观测等治理能力 。</li><li>面向 Agent：用户可便捷、安全地将各类智能体能力无缝集成至业务系统，实现智能对话、流程自动化等创新功能，助力企业高效构建智能化应用生态。</li><li>面向 MCP：支持 API-to-MCP 快速转化，并提供 MCP Server 代理、安全认证，以及统一观测、限流等治理能力。</li></ul>]]></description></item><item>    <title><![CDATA[如何删除 iPhone 短信记录中显示的]]></title>    <link>https://segmentfault.com/a/1190000047405513</link>    <guid>https://segmentfault.com/a/1190000047405513</guid>    <pubDate>2025-11-17 18:07:43</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>​在 iPhone 的“信息”应用中，发送或接收短信后，对方的电话号码或联系人姓名会被系统自动记录，并显示在搜索栏或最近联系人建议中。虽然这是为了方便用户快速访问，但许多用户为了保护隐私或避免误发信息，会选择清理这些最近联系人。那么，如何在 iPhone 的短信记录中删除最近联系人呢？本文将提供三种解决方案供您参考。</p><h3>第一部分：如何在 iPhone 上通过删除整个对话来删除“信息”应用中的最近联系人</h3><p>从短信记录中删除最近联系人的最简单方法是删除与该联系人关联的整个短信对话。要执行此操作，请按照以下步骤操作：</p><p>步骤 1. 打开 iPhone 上的“信息”应用。</p><p>步骤 2. 点击顶部的“编辑”，然后选择要删除的对话。</p><p>步骤 3. 点击“垃圾桶”图标。</p><h3>第二部分：如何通过“信息”应用删除 iPhone 上最近删除的联系人</h3><p>你也可以直接从 iPhone 的“信息”应用中删除最近联系人。但问题是，你必须在“信息”应用中逐个删除它们。</p><p>如何在短信中删除最近联系的联系人？以下是步骤：</p><p>步骤 1. 解锁你的 iPhone，然后打开通讯录应用，确认你已从通讯录中删除不需要的电话号码或联系人。</p><p>步骤 2. 然后切换到“信息”应用，新建一条信息，然后开始输入要删除的联系人的姓名或电话号码。</p><p>步骤 3. 当不需要的联系人出现在短信记录中时，点击联系人右侧的带圆圈的“i”图标，打开新的联系人信息窗口。</p><p>第四步，请找到并点击“从最近联系人中移除”选项。确认是否是您要移除的联系人。如果是，请点击删除不需要的电话号码。</p><p>步骤 5. 删除不需要的联系人信息后，您将返回到“新建消息”窗口，您会注意到不需要的联系人已消失，并且仅显示“通讯录”应用中的正确联系人信息。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405515" alt="图片" title="图片"/><br/>​</p><h3>第三部分：如何永久删除 iPhone 短信历史记录中显示的最近联系人</h3><p>逐个从 iPhone 信息应用中删除最近联系人可能很麻烦，而且如果您想确保已从 iPhone 或 iPad 中彻底删除所有不需要的最近联系人，那更是难上加难。因此，我们向您推荐一款专业的iOS数据擦除工具Coolmuster iOS Eraser 。</p><p>有了它，您可以在一个程序中系统地管理 iPhone/iPad/iPod 上的所有联系人，包括现有联系人和已删除联系人。除了已删除的联系人之外，您还可以从 iDevice 中彻底清除已删除的信息、日历、提醒事项、语音备忘录、照片、备忘录、通话记录、Safari 书签等，且无法恢复。</p><p>iOS橡皮擦的主要功能：</p><pre><code>安全永久地清除iOS设备上的所有数据，包括个人信息、系统设置、已删除的文件等。
您可以选择三种擦除级别（低、中、高）来满足您的特定需求。
确保现有数据和已删除数据均被永久清除，无法恢复。
永久删除各种数据类型，例如联系人、短信、通话记录、音乐、视频、照片、应用程序和应用程序数据、提醒事项、日历、书签、浏览历史记录、语音备忘录、笔记和设置（包括 iCloud 和 iTunes 帐户信息）。
以 100% 只读模式运行，确保在数据擦除过程中不会对您的设备造成任何损害。
完全兼容所有 iPhone、iPad 和 iPod touch 机型，包括最新的 iPhone 17 和iOS 26。

</code></pre><p>以下是该程序的Mac和Windows版本免费试用版。请将其下载到您的电脑上，即可轻松删除iPhone短信记录中显示的最近联系人。</p><p>以下是如何使用iOS Eraser 在 iPhone 信息中删除最近联系人：</p><p>01使用 USB 数据线将您的 iPhone/iPad/iPod 连接到电脑。软件将自动检测您的设备，并显示主界面，即可开始抹掉数据。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405516" alt="图片" title="图片" loading="lazy"/></p><p>02点击“擦除”按钮，选择所需的安全级别（低、中或高），然后点击“确定”进行确认。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405517" alt="图片" title="图片" loading="lazy"/></p><p>03出现提示时，输入“删除”进行确认，然后再次点击“擦除”。将出现最终确认信息；点击“确定”以永久删除数据。</p><p>04流程完成后，设备上的所有数据将被永久删除且无法恢复。之后，您可以将您的 iDevice 设置为新设备。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405518" alt="图片" title="图片" loading="lazy"/></p><h3>结论</h3><p>如果您遇到最近删除的联系人仍然出现在 iPhone 短信记录中的问题，可以使用上述方法解决。如果您想要彻底、不可逆地完全清除所有残留记录，那么Coolmuster iOS Eraser无疑是最佳选择。它可以从系统深处删除所有隐私痕迹，确保联系人不再出现在短信记录或建议中，非常适合对隐私要求较高的用户。<br/>​</p>]]></description></item><item>    <title><![CDATA[Invicti v25.11 发布，新增]]></title>    <link>https://segmentfault.com/a/1190000047405540</link>    <guid>https://segmentfault.com/a/1190000047405540</guid>    <pubDate>2025-11-17 18:07:03</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>Invicti v25.11 发布，新增功能简介</p><p>Invicti v25.11.0 for Windows - Web 应用程序安全测试</p><p>Invicti (formerly Netsparker) | Web Application and API Security for Enterprise</p><p>请访问原文链接：<a href="https://link.segmentfault.com/?enc=1rKWWP%2B%2FDLfuZz1JyWg39Q%3D%3D.E5ro8elUnXsMuluk5uBAr522ecCVGBEbrlmCD0jxvMM%3D" rel="nofollow" target="_blank">https://sysin.org/blog/invicti/</a> 查看最新版。原创作品，转载请保留出处。</p><p>作者主页：<a href="https://link.segmentfault.com/?enc=GhT8Zvdy5r7g751c2sZd7A%3D%3D.ZaidUYZiqSGinCEqvd1cElrfCED7fRwxqR3qmv9Uo0c%3D" rel="nofollow" target="_blank">sysin.org</a></p><hr/><p>Invicti 是一种自动化但完全可配置的 Web 应用程序安全扫描程序，使您能够扫描网站、Web 应用程序和 Web 服务，并识别安全漏洞。Invicti 可以扫描所有类型的 Web 应用程序，无论其构建平台或语言。</p><ul><li>Invicti 是唯一一款能够以只读且安全的方式自动利用已识别漏洞以确认已识别问题的在线 Web 应用程序安全扫描程序。</li><li>它还提供了漏洞证明，因此您无需浪费时间手动验证它。例如，在检测到 SQL 注入漏洞的情况下，它将显示数据库名称作为利用证明。</li></ul><p>Invicti 的扫描技术旨在帮助您轻松保护 Web 应用程序而无需忧虑枝节小事，因此您可以专注于修复报告的漏洞。如果 Invicti  无法自动确认漏洞，它会通过在它前面加上 ‘[Possible]’ 并分配一个确定性值来通知您该漏洞，因此您知道应该立即修复什么。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000045076921" alt="Invicti-Logo" title="Invicti-Logo"/></p><p>Invicti (formerly Netsparker) 应用安全测试</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000045076922" alt="invicti-homepage-dashboard" title="invicti-homepage-dashboard" loading="lazy"/></p><p>Invicti - The Largest Dynamic Application Security Solutions Provider In The World</p><h2>新增功能</h2><p>Invicti Standard v25.11.0 - 2025 年 11 月 11 日</p><p><strong>改进</strong>：</p><ul><li>改进了 “SameSite Cookie 未实现” 安全检查</li><li>改进了 “JWT 签名未验证” 安全检查</li></ul><p><strong>已解决的问题</strong>：</p><ul><li>修复了由于加载认证配置文件问题导致的登录失败</li><li>修复了 Linux/云代理无法解析请求前查询参数中的密钥的问题</li><li>改进了应用程序的启动时间</li></ul><h2>下载地址</h2><p>想要开始学习和研究？</p><ul><li>请访问：<a href="https://link.segmentfault.com/?enc=9tKYnCBBt9j%2FKej84FL7lA%3D%3D.K7l40Vjl3y%2BzIgrLjoy6xnT6%2BtQ%2BVPTnvFmO%2Be3X9%2B4%3D" rel="nofollow" target="_blank">https://sysin.org/blog/invicti/</a></li></ul><hr/><p>更多：<a href="https://link.segmentfault.com/?enc=ntySBNIj2%2FeNkxmzPGKY9w%3D%3D.bUTDi6%2FbRuipU6MhhbozWHpDPbW51E2%2Bu88qS8SVQ5E%3D" rel="nofollow" target="_blank">HTTP 协议与安全</a></p>]]></description></item><item>    <title><![CDATA[如何将 OnePlus 手机中的联系人传]]></title>    <link>https://segmentfault.com/a/1190000047405544</link>    <guid>https://segmentfault.com/a/1190000047405544</guid>    <pubDate>2025-11-17 18:06:31</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>如果您正 从 OnePlus 手机换到 iPhone，并且想知道如何将联系人从 OnePlus 手机转移到 iPhone，您并不孤单。许多用户在升级设备时都会遇到这个问题。幸运的是，有几种方法可以快速高效地转移联系人。在本指南中，我们将为您介绍五种将联系人从 OnePlus 手机转移到新 iPhone 的有效方法。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405546" alt="图片" title="图片"/><br/>​</p><h3>第一部分：如何一键将 OnePlus 手机联系人传输到 iPhone</h3><p>将 OnePlus 手机联系人传输到 iPhone 最简单快捷的方法之一是使用Coolmuster Mobile Transfer 。这款工具提供一键式解决方案，可在Android和 iPhone 之间传输数据，包括联系人。对于追求便捷体验的用户来说，这是一个绝佳的选择。它的优势在于操作简单、速度快，而且无需网络连接。无论您是新手还是经验丰富的用户，都能轻松上手。</p><p>Coolmuster Mobile Transfer的亮点：</p><pre><code>只需单击一下，即可轻松将联系人从Android （OnePlus）传输到 iPhone 。
将电子书（PDF 和 ePub）和联系人从Android传输到 iPhone。
您可以选择四种灵活的传输方式： iOS到iOS 、 Android到iOS 、 iOS到Android和Android到Android 。
完全兼容最新的iOS 26和Android 16系统。
体验快速、无缝、安全的数据传输，无需担心数据丢失。

</code></pre><p>如何将 OnePlus 手机上的联系人传输到 iPhone？请按照以下步骤操作：</p><p>01首先，请在电脑上下载并安装Coolmuster Mobile Transfer 。使用 USB 数据线将您的 OnePlus 手机和 iPhone 连接到电脑。请确保您的 OnePlus 手机已启用 USB 调试模式。</p><p>02在电脑上打开该工具。连接成功后，选择 OnePlus 作为源设备，iPhone 作为目标设备。如果未选择，请点击“翻转”按钮进行切换。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405547" alt="图片" title="图片" loading="lazy"/></p><p>03勾选“通讯录”选项，确保只传输通讯录，然后点击“开始复制”按钮，开始将通讯录从 OnePlus 手机传输到 iPhone。传输完成后，您的通讯录就会出现在新的 iPhone 上。</p><h3>第二部分：如何通过“移动到iOS将联系人从 OnePlus 手机转移到 iPhone</h3><p>将联系人从 OnePlus 手机传输到 iPhone 的另一种有效方法是使用“转移到iOS应用。“转移到iOS是苹果官方推出的迁移工具，专为Android用户设计。它可以帮助您将联系人、短信、照片等数据从Android手机传输到 iPhone 。数据传输通过 Wi-Fi 进行，因此对于初次使用 iPhone 的用户来说，这是一个完美的解决方案。</p><p>以下是如何通过“转移到iOS将 OnePlus 手机中的联系人复制到 iPhone 的方法：</p><p>步骤 1. 从 Google Play 商店在您的 OnePlus 设备上安装“迁移到iOS应用程序。</p><p>步骤 2. 在新 iPhone 上，开始设置过程，并在“应用与数据”部分出现提示时选择“从Android转移数据”。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405548" alt="图片" title="图片" loading="lazy"/><br/>​</p><p>步骤 3. 在您的 OnePlus 手机上打开“转移到iOS应用程序，并按照屏幕上的说明进行操作。</p><p>第四步：iPhone 上会显示一个六位数的代码。请在 OnePlus 设备上输入此代码以建立连接。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405549" alt="图片" title="图片" loading="lazy"/><br/>​</p><p>步骤 5. 选择“联系人”和您想要传输的任何其他数据，然后点击“下一步”。</p><p>第六步：等待传输过程完成。完成后，您的联系人即可在您的 iPhone 上使用。</p><h3>第三部分：如何使用 Google 帐户将 OnePlus 手机中的联系人同步到 iPhone</h3><p>如果您之前在 OnePlus 手机上启用了 Google 帐户同步，则可以通过 Google 帐户直接将联系人导入 iPhone。只需将您的 Google 帐户添加到 iPhone，联系人就会自动导入。</p><p>以下是如何使用 Google 帐户将 OnePlus 手机上的联系人传输到 iPhone 的方法：</p><p>第一步：确保您的联系人已与您的 Google 帐户同步。为此，请转到“设置”&gt;“帐户”&gt;“Google”，并确保“联系人”同步已启用。</p><p>步骤 2. 在您的 iPhone 上，前往“设置”&gt;“邮件”&gt;“帐户”&gt;“添加帐户”，然后选择“Google”。</p><p>步骤 3. 使用您的 Google 帐户用户名和密码登录。</p><p>步骤 4. 登录后，确保“联系人”开关已打开。</p><p>第五步：您的 Google 联系人将自动与 iPhone 上的“通讯录”应用同步。您可以立即查看它们。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405550" alt="图片" title="图片" loading="lazy"/></p><h3>第四部分：如何通过 VCF 文件将 OnePlus 手机中的联系人导入 iPhone</h3><p>如果您只需要传输一部分联系人，使用 VCard 文件（.vcf 文件）是一种简单的方法。</p><p>以下是如何通过 VCF 文件将 OnePlus 手机中的联系人导入 iPhone 的方法：</p><p>步骤 1. 打开 OnePlus 手机上的“联系人”应用，进入“设置”，然后选择“导出”。选择将联系人保存为 VCF 文件。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405551" alt="图片" title="图片" loading="lazy"/></p><p>步骤 2. 将 VCF 文件通过电子邮件发送给自己，或者使用云存储服务（如 Google Drive）保存该文件。</p><p>步骤 3. 打开 iPhone 上的电子邮件或云存储，下载 VCF 文件。</p><p>第四步：点击 VCF 文件将其打开。你的 iPhone 会询问你是否要将联系人添加到“通讯录”应用；点击“添加所有联系人”。</p><p>步骤 5. 导入完成后，您的所有联系人将出现在您的 iPhone 上。</p><h3>第五部分：如何使用 SIM 卡将 OnePlus 手机中的联系人传输到 iPhone</h3><p>如果您只需要传输联系人而无需传输其他数据，使用 SIM 卡是一种简单常用的方法。您可以将 OnePlus 手机中的联系人保存到 SIM 卡中，然后再将其导入到 iPhone 中。</p><p>以下是如何使用 SIM 卡将 OnePlus 手机中的联系人发送到 iPhone 的方法：</p><p>步骤 1. 打开 OnePlus 手机上的“联系人”应用，进入“设置”，然后选择“导入/导出”。选择将联系人导出到 SIM 卡。</p><p>步骤 2. 从 OnePlus 手机中取出 SIM 卡，然后将其插入 iPhone。</p><p>步骤 3. 在您的 iPhone 上，前往“设置”&gt;“通讯录”&gt;“导入 SIM 卡通讯录”。</p><p>步骤 4. 等待联系人导入，它们将出现在 iPhone 的“通讯录”应用中。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405552" alt="图片" title="图片" loading="lazy"/><br/>​</p><h3>总结</h3><p>将 OnePlus 手机上的联系人传输到 iPhone 时，您可以根据自身需求和设备情况选择多种方法。对于大多数用户而言，使用“转移到iOS应用或通过 Google 帐户同步是最便捷的选择。如果您只需要传输部分联系人，手动使用 VCard 文件也是一个不错的选择。为了更高效地迁移数据， Coolmuster Mobile Transfer是另一个值得尝试的工具。</p><p>无论你选择哪种方法，迁移之前务必备份你的联系人，以免数据丢失。<br/>​</p>]]></description></item><item>    <title><![CDATA[智能计划助手怎么优化资源调度和排产流程？]]></title>    <link>https://segmentfault.com/a/1190000047405567</link>    <guid>https://segmentfault.com/a/1190000047405567</guid>    <pubDate>2025-11-17 18:05:42</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在当今瞬息万变的制造业环境中，企业正面临着前所未有的运营挑战：订单波动剧烈、资源调度复杂、交货周期难以准确预测。传统依赖人工经验的生产计划模式已显疲态，无法满足现代制造业对柔性、高效与智能化的迫切需求。正是在这一背景下，智能计划助手应运而生，以其算法驱动的智慧，为制造业注入全新的活力与效率。广域铭岛作为这一领域的先驱，通过其深度集成的智能体系统，展现了智能计划助手如何成为企业数字化转型的关键引擎。<br/>智能计划助手的核心在于其能够动态分析海量数据，实现精准的资源配置与调度。传统排产方式效率低下，计划员需手动调整数十种约束参数，耗时长达数小时，且结果往往不尽人意。而智能计划助手则凭借机器学习与自然语言处理技术，在短短分钟内生成多套高满足率的方案，并通过实时模拟验证效果。这种转变不仅是技术上的飞跃，更是思维模式的革新——从“经验主义”的试错，迈向“算法驱动”的精准决策。广域铭岛的实践案例表明，智能计划助手绝非空中楼阁；例如在某大型整车工厂，单次排产时间从6小时压缩至0.5-1小时，释放了大量人力资源，让工程师专注于战略规划，而非繁琐的操作。<br/>进一步地，智能计划助手通过智能调度引擎，快速响应市场变化与异常情况。订单频繁调整或临时插单曾是企业运营的噩梦，但智能计划助手能在10秒内完成全局生产计划的重新计算，支持多目标优化，如交期优先或成本优先。广域铭岛为电子制造企业部署的系统，使订单准时交付率从75%提升至94%，异常响应速度从滞后数小时缩短为实时预警。这种敏捷性不仅提升了生产效率，更增强了企业的市场竞争力，使智能计划助手成为应对不确定性的强大盾牌。<br/>全流程可视化监控是智能计划助手的另一大优势，它实现了从原材料到成品的无缝追踪与风险预警。通过实时生产看板，企业可以洞察每一个环节的运作状态，异常情况自动报警，从而减少客户投诉与运营成本。广域铭岛在合作的一家机械制造企业中，利用智能计划助手将交货周期预测准确率提高至96%，极大提升了管理透明度与决策敏捷性。移动端功能的集成，更使得决策者可以随时随地掌控生产动态，凸显了智能计划助手在现代化管理中的不可或缺性。<br/>然而，智能计划助手的崛起并非没有挑战。算法稳定性、数据基础与团队接受度仍是需要权衡的因素。广域铭岛通过云边协同架构和持续优化模型，部分解决了这些难题，但其成功仍依赖于企业的整体数字化成熟度。未来，随着5G和物联网技术的普及，智能计划助手或将进一步进化，实现全链路智能化，甚至自主决策生产流程，为制造业带来更深刻的变革。<br/>总之，智能计划助手代表了制造业排产的未来方向——它不仅是工具，更是战略资产。广域铭岛的创新实践为我们描绘了一幅蓝图：如何通过算法赋能，将繁琐的人工操作转化为高效、精准的自动化流程。在这个充满变数的时代，拥抱智能计划助手，或许正是企业决胜千里的关键一步。</p>]]></description></item><item>    <title><![CDATA[Dify 上线 GMl Cloud 插件]]></title>    <link>https://segmentfault.com/a/1190000047405580</link>    <guid>https://segmentfault.com/a/1190000047405580</guid>    <pubDate>2025-11-17 18:04:44</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><strong>摘要</strong></p><p>GMI Cloud 插件正式无缝集成到 Dify！提供高性能的多系列模型，如<strong>Minimax</strong>、<strong><em><em>DeepSeek</em></em></strong>、<strong><em><em>GPT OSS</em></em></strong>、<strong><em><em>Qwen</em></em></strong>、<strong><em><em>Keling</em></em></strong>等，支持市场研究、模型评估、文献综述等任务处理。大家只需获取 GMI Cloud API 密钥，在 Dify 安装配置插件，即可借助模板构建深度研究工作流程。本文为步骤的详细教程。**</p><p><strong><em>01</em></strong></p><p><strong><em>概述</em></strong></p><p>GMI Cloud 是一个强大的云原生 GPU 基础设施平台，专为高性能 AI 推理服务设计。适配 Dify 的 GMI Cloud 插件可让你将 GMI Cloud 的功能无缝集成到 Dify 工作流程中。以下是插件的主要功能：</p><ul><li>OpenAI 兼容的 API：支持通过标准 OpenAI 客户端库和工具实现无缝集成。</li><li>多个模型系列：获取丰富的模型资源，包括 DeepSeek、Llama、Qwen、OpenAI OSS 和 GLM 模型。</li><li>高性能：针对快速推理和低延迟优化，非常适合需大量计算能力的研究任务。</li><li>流媒体支持：支持实时流式传输，实现流畅聊天交互。</li><li>工具调用：支持函数调用，可将外部工具集成到工作流程中。</li><li>自定义模型支持：轻松部署和使用你自己的微调模型。</li><li>灵活的端点：可为企业级部署配置自定义 API 端点。</li></ul><p><img width="723" height="217" referrerpolicy="no-referrer" src="/img/bVdm4vm" alt="图片" title="图片"/></p><p>配置插件后，你可以访问和使用插件附带的一系列预设模型。目前包含以下类别：</p><ul><li>DeepSeek：</li><li>deepseek-ai/DeepSeek-V3-0324</li><li>deepseek-ai/DeepSeek-V3.1</li><li>OpenAI OSS：</li><li>openai/gpt-oss-120b</li><li>Meta-Llama：</li><li>meta-llama/Llama-4-Scout-17B-16E-Instruct</li><li>Qwen：</li><li>Qwen/Qwen3-32B-FP8</li><li>Qwen/Qwen3-Next-80B-A3B-Instruct</li><li>Qwen/Qwen3-235B-A22B-Thinking-2507-FP8</li><li>Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8</li><li>智谱（ZAI）：</li><li>zai-org/GLM-4.6</li></ul><p>这些模型具备多种功能，可用于执行自然语言处理、文本生成、代码生成等任务。</p><p>通过以下链接可以获取该插件的最新文档（复制到浏览器中打开）：</p><p><a href="https://link.segmentfault.com/?enc=d0ubndw9xi3jCAlIwtPc9w%3D%3D.cbSKTP2S1bjI4%2FqoMTQtvSOe%2BMGA5rTJpu8zyuJivGCdohgGu92Yhf413hwimhsDA5AdWgudhcfmDDT0uR0a%2BQ%3D%3D" rel="nofollow" target="_blank">https://marketplace.dify.ai/plugins/langgenius/gmicloud</a></p><p><strong><em>02</em></strong></p><p><strong><em>分步指南</em></strong></p><p><strong>第 1 步：从 GMI Cloud 获取 API 密钥</strong></p><p>若你尚未准备好 API 密钥，请先前往 GMI Cloud 控制台创建：</p><ol><li>登录 GMI Cloud 控制台，进入 API 密钥管理页面。</li><li>点击「创建 API 密钥」，为其设置易记名称，然后选择 “范围” 为 “推理”。</li><li>请妥善保存你的 API 密钥，关闭弹出窗口后将无法再次查看。</li></ol><p><img width="723" height="473" referrerpolicy="no-referrer" src="/img/bVdm4vn" alt="图片" title="图片" loading="lazy"/></p><p><strong>第 2 步：在 Dify 中安装插件</strong></p><p>接下来操作 Dify：前往 Dify 插件市场（路径：Plugins - Dify <a href="https://link.segmentfault.com/?enc=DtkHXTB0gdS%2BP1susVabpQ%3D%3D.HuNUNm9FeLDDfScjQCkBFjX8mDiaigHi3sZIi3a0hDHrlgsZmBW5U4Asvn0bQ%2FjD" rel="nofollow" target="_blank">https://cloud.dify.ai/plugins?category=discover</a>），搜索并安装 GMI Cloud 插件。</p><p><img width="723" height="742" referrerpolicy="no-referrer" src="/img/bVdm4vo" alt="图片" title="图片" loading="lazy"/></p><p><strong>第 3 步：在 Dify 中配置插件</strong></p><p>现在为 Dify 中的插件完成配置：</p><ol><li>打开 Dify，进入设置→模型提供程序。</li><li>在可用提供商列表中找到 GMI Cloud，点击「设置」。</li><li>在 API 密钥字段中输入你的密钥，这是唯一必填项。</li><li>（可选）若你的组织使用自定义端点，可输入 API 端点 URL；否则插件默认值为：<a href="https://link.segmentfault.com/?enc=liApYWv4EOVOjcgn7Relrg%3D%3D.%2B8TMKtr1bse1B35EYLNbbPZSPJy5%2Fvf1xcJui%2Bqcb3k%3D" rel="nofollow" target="_blank">https://api.gmi-serving.com/v1</a>。</li><li>点击「保存」激活插件。</li></ol><p>Dify 将通过调用 /v1/models 端点验证你的凭据，确保所有设置无误。</p><p><img width="723" height="351" referrerpolicy="no-referrer" src="/img/bVdm4vp" alt="图片" title="图片" loading="lazy"/></p><p>若配置成功，你将看到绿灯提示。此时即可开始构建工作流程！</p><p><img width="723" height="308" referrerpolicy="no-referrer" src="/img/bVdm4vq" alt="图片" title="图片" loading="lazy"/></p><p><strong>第 4 步：在 Dify 中构建深度研究工作流程</strong></p><p>进入首页，点击「从模板创建」：</p><p><img width="723" height="416" referrerpolicy="no-referrer" src="/img/bVdm4vr" alt="图片" title="图片" loading="lazy"/></p><p>本次将使用 Dify 官方提供的 DeepResearch 模板。</p><p><img width="723" height="371" referrerpolicy="no-referrer" src="/img/bVdm4vs" alt="图片" title="图片" loading="lazy"/></p><p>在插件安装页面，请务必勾选两个工具：Tavily 和 JSON Process。无需启用另外两个模型提供程序插件，我们将使用 GMI Cloud 的模型端点。</p><p><img width="723" height="371" referrerpolicy="no-referrer" src="/img/bVdm4vt" alt="图片" title="图片" loading="lazy"/></p><p>复杂的图表看似很多，但无需困扰，我们只需关注两个节点：LLM 节点和推理模型节点——用 GMI Cloud 的模型端点替换它们。</p><p><img width="723" height="371" referrerpolicy="no-referrer" src="/img/bVdm4vu" alt="图片" title="图片" loading="lazy"/></p><p>对于 LLM 节点：将 gpt-4o 替换为 GLM-4.6（这是一款性能出色的通用 LLM 模型，擅长各类通用任务。了解更多信息可访问 zai-org/GLM-4.6 · Hugging Face  <a href="https://link.segmentfault.com/?enc=Se6E%2BM8mAwcTkeVo7Kgepg%3D%3D.zbDXAQD1ecIyODaBbji9Ec3MYTmoTUk7DpvvG2sf%2FKA8IotGsY4ek1Ms9V8LYnYz" rel="nofollow" target="_blank">https://huggingface.co/zai-org/GLM-4.6</a>）。</p><p><img width="723" height="859" referrerpolicy="no-referrer" src="/img/bVdm4vv" alt="图片" title="图片" loading="lazy"/></p><p>对于推理模型节点：将其替换为 Qwen/Qwen3-235B-A22B-Thinking-2507-FP8（该模型在多项推理基准测试中表现优异。了解更多信息可访问 Qwen/Qwen3-235B-A22B-Thinking-2507-FP8 · Hugging Face</p><p><a href="https://link.segmentfault.com/?enc=JTTHDZUBG0PLmYjNcdKXUA%3D%3D.NvSyjKFYUFbZs%2FEW%2Fz6BTzoDCkrgSLNYKXf4AI7Xl2faVZGaNJHBzbXbuljKGPqcOgA7%2BZu1yfjEfaCIV741TA%3D%3D" rel="nofollow" target="_blank">https://huggingface.co/Qwen/Qwen3-235B-A22B-Thinking-2507-FP8</a>）。</p><p><img width="723" height="371" referrerpolicy="no-referrer" src="/img/bVdm4vw" alt="图片" title="图片" loading="lazy"/></p><p>完成以上设置后，点击右上角的「发布」按钮，工作流即可运行！</p><p><strong>第 5 步：开始试用！</strong></p><p>现在让我们进入工作流应用程序。设置一个可选的<strong>深度</strong>参数——这就是这个工作流被称为<strong>深度</strong>研究的原因，能够根据指定的深度，会进行多轮迭代搜索。例如，我们把它设为<strong>2</strong>。</p><p>以下是示例提示词：</p><pre><code>Which industries are showing the strongest early signals of disruption from generative AI?</code></pre><p><img width="723" height="740" referrerpolicy="no-referrer" src="/img/bVdm4vx" alt="图片" title="图片" loading="lazy"/></p><p>需要注意的是，由于深度研究可能需要多轮推理，完整答案可能需要一两分钟才能生成。总之，你最终将获得一份撰写规范、来源明确的分析报告。</p><p><img width="723" height="481" referrerpolicy="no-referrer" src="/img/bVdm4vy" alt="图片" title="图片" loading="lazy"/></p><p><strong><em>03</em></strong></p><p><strong><em>结论</em></strong></p><p>在 Dify 中通过 GMI 插件构建深度研究工作流程，能够充分利用 GMI Cloud Inference Engine中的 AI 模型和尖端云基础设施。无论你是进行市场研究、模型评估还是文献综述的撰写，它都将是你最可靠的伙伴，全力助力你的生产流程。</p><p>现在就去安装 GMI Cloud 插件，完成 API Key 配置，就可以立刻开始构建你的深度研究工作流程啦！如有任何问题，可随时通过邮箱联系我们： <a href="mailto:support@gmicloud.ai" target="_blank">support@gmicloud.ai</a></p><p><strong>关于 GMI Cloud</strong></p><p>由 Google X 的 AI 专家与硅谷精英共同参与创立的 GMI Cloud 是一家领先的 AI Native Cloud 服务商，是全球六大 Reference Platform NVIDIA Cloud Partner 之一，拥有遍布全球的数据中心，为企业 AI 应用提供最新、最优的 GPU 云服务，为全球新创公司、研究机构和大型企业提供稳定安全、高效经济的 AI 云服务解决方案。</p><p>GMI Cloud 凭借高稳定性的技术架构、强大的GPU供应链以及令人瞩目的 GPU 产品阵容（如能够精准平衡 AI 成本与效率的 H200、具有卓越性能的 B200 以及未来所有全新上线的高性能芯片），确保企业客户在高度数据安全与计算效能的基础上，高效低本地完成 AI 落地。此外，通过自研“Cluster Engine”、“Inference Engine”两大平台，完成从算力原子化供给到业务级智算服务的全栈跃迁，全力构建下一代智能算力基座。</p><p>作为推动通用人工智能（AGI）未来发展的重要力量，GMI Cloud 持续在 AI 基础设施领域引领创新。选择 GMI Cloud，您不仅是选择了先进的 GPU 云服务，更是选择了一个全方位的 AI 基础设施合作伙伴。</p><p>如果您想要了解有关 GMI Cloud 的信息</p><p>请关注我们并建立联系</p>]]></description></item><item>    <title><![CDATA[如何将音乐从一部itel手机传输到另一部]]></title>    <link>https://segmentfault.com/a/1190000047405582</link>    <guid>https://segmentfault.com/a/1190000047405582</guid>    <pubDate>2025-11-17 18:03:56</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>​如果您正在寻找一种轻松将音乐从一部itel手机传输到另一部itel手机的方法，那么您来对地方了。无论您是更换新的itel手机，还是仅仅想与其他设备分享您喜爱的歌曲，都有几种可靠的方法可供选择。从专业的手机传输工具到蓝牙和云存储等无线共享选项，本指南将通过清晰的步骤和详细的解释，引导您了解最有效的解决方案。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405584" alt="图片" title="图片"/></p><h3>第一部分：如何使用Coolmuster Mobile Transfer将音乐从 itel 手机传输到另一台 itel 手机</h3><p>如果您想要快速、稳定、高效地传输大量音乐文件，专业的传输工具始终是最便捷的选择。Coolmuster Mobile Transfer正是为此而生。它无需您进行复杂的手动操作，即可自动完成整个传输过程，即使是新手也能轻松上手。</p><p>Coolmuster Mobile Transfer的主要功能</p><pre><code>传输音乐、照片、视频、联系人、短信、通话记录、应用程序等。
支持Android到Android 、 iOS到iOS 、 iOS到Android和Android到iOS之间的数据传输。
一键传输，界面简洁直观。
数据无丢失；所有文件均保持原状。
几乎适用于所有Android和iOS机型，包括itel、TECNO、华为和iPhone 17。
确保安全稳定的传输过程。

</code></pre><p>如何使用Coolmuster Mobile Transfer在 itel 设备之间传输音乐？</p><p>01在您的计算机上下载、安装并打开Coolmuster Mobile Transfer 。</p><p>02使用 USB 数据线连接两部 itel 手机，并在每部手机上启用 USB 调试模式。</p><p>03将旧 itel 设置为源，新 itel 设置为目标。如果未设置，请单击“翻转”按钮更改它们的位置。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405585" alt="图片" title="图片" loading="lazy"/></p><p>04从数据列表中勾选“音乐”选项，然后单击“开始复制”，等待传输完成。</p><h3>第二部分：如何通过蓝牙将音乐从itel手机传输到itel手机</h3><p>蓝牙是一种传统且广泛使用的在两部itel手机之间共享文件的方式。虽然它比不上专业的传输工具，但无需电脑或互联网即可方便地传输少量音乐文件。</p><p>蓝牙传输有什么用？</p><pre><code>小型音乐收藏。
喜欢完全无线方式的用户。
无需安装任何应用或工具即可快速分享。

</code></pre><p>如何通过蓝牙传输音乐？</p><p>步骤 1. 在两台 itel 设备上打开蓝牙：“设置”&gt;“蓝牙”。</p><p>步骤 2. 使两部手机均可被发现并配对。</p><p>步骤 3. 在发送设备上，打开“文件管理器”，找到您的音乐文件。</p><p>步骤 4. 长按选择歌曲，点击“分享”，然后选择“蓝牙”。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405586" alt="图片" title="图片" loading="lazy"/><br/>​</p><p>第五步：在接收设备上，接受收到的传输请求。等待传输完成，然后检查音乐文件夹。</p><p>缺点：</p><pre><code>传输速度慢。
不太适合大型音乐库。

</code></pre><h3>第三部分：如何使用云存储将 itel 手机中的音乐同步到另一部 itel 手机</h3><p>如果您想将音乐备份到云端，同时还要将其传输到另一部itel手机上，那么使用云存储是理想之选。Google Drive、Dropbox和OneDrive是最常见的选择。</p><p>最佳使用场景：</p><pre><code>当两部itel手机不在同一地点时。
除了传输之外，你还需要备份。
您的Wi-Fi连接稳定。

</code></pre><p>如何通过云存储同步音乐？</p><p>步骤 1. 在旧款 itel 手机上，将您的音乐文件上传到 Google Drive、Dropbox 等。</p><p>步骤 2. 打开云应用，点击“上传”，然后选择您的音乐文件。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405587" alt="图片" title="图片" loading="lazy"/><br/>​</p><p>步骤 3. 在新 itel 上，登录同一个云账户。</p><p>步骤 4. 将上传的音乐文件下载到新手机的存储空间。</p><p>缺点：</p><pre><code>需要连接互联网（建议使用 Wi-Fi）。
处理超大文件速度较慢。

</code></pre><h3>第四部分：如何使用手机克隆功能将音乐从itel手机传输到itel手机</h3><p>手机克隆功能专为希望快速将包括音乐在内的多种类型数据从一部手机迁移到另一部手机的用户而设计。该应用程序支持包括itel在内的多个品牌。</p><p>为什么选择手机克隆？</p><pre><code>传输内容包括音乐、照片、视频、联系人、应用程序等。
可通过热点或 Wi-Fi Direct 进行无线连接。
通过二维码连接，设置简便。

</code></pre><p>使用手机克隆功能将音乐从一部itel手机传输到另一部itel手机的步骤：</p><p>步骤 1. 在两台 itel 设备上安装Phone Clone 。</p><p>步骤 2. 打开应用程序，在旧款 itel 手机上，选择“发送方”；在新款 itel 手机上，点击“接收方”。</p><p>步骤 3. 扫描新 itel 上显示的二维码，建立安全连接。</p><p>步骤 4. 选择“音乐”类别以及您想要复制的任何其他文件。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405588" alt="图片" title="图片" loading="lazy"/><br/>​</p><p>步骤 5. 点击“传输”，等待所有文件移动到新设备。</p><p>缺点：</p><pre><code>需要两部手机保持靠近。
速度取决于 Wi-Fi Direct 的性能。

</code></pre><h3>总结一下</h3><p>将音乐从一部itel手机传输到另一部itel手机有多种方法，最佳选择取决于您的具体情况。如果您需要快速、稳定且功能齐全的解决方案， Coolmuster Mobile Transfer是最便捷的选择，尤其适用于大型音乐库或跨平台传输。蓝牙适合小规模传输，云存储是备份和同步的理想之选，而手机克隆则适合想要一次性传输多种数据类型的用户。</p><p>选择适合您需求的方式，即可在您的新itel手机上轻松享受音乐。<br/>​</p>]]></description></item><item>    <title><![CDATA[京东云张晨 受邀参加KCD 杭州站 x ]]></title>    <link>https://segmentfault.com/a/1190000047405593</link>    <guid>https://segmentfault.com/a/1190000047405593</guid>    <pubDate>2025-11-17 18:03:01</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>AI正在重塑一切，驱动云原生基础设施经历其诞生以来最深刻的变革。这一变革对底层设施提出了前所未有的新要求：更极致的弹性伸缩、更高效的算力利用、更复杂的跨域调度和更全面的安全防护。面对如此系统性的挑战，单一技术栈或社区已难以给出完美答案。</p><p>KCD（Kubernetes Community Days，Kubernetes 社区日）是由社区组织的活动，汇聚开源和云原生领域的采用者和技术人员，旨在促进教育、协作和交流。KCD 活动由云原生计算基金会（CNCF）提供支持。</p><p>OpenInfra Days 每年由开源社区生态系统中的本地用户组和公司组织和主办，包含主题演讲、分组会议甚至研讨会。这是一个绝佳的机会，在活动上可以直接聆听杰出的开源基础设施领导者的演讲，学习用户案例，建立人脉，并融入当地社区。</p><p>今年由两个社区组织联合发起的开创性融合盛会，标志着云计算领域两大核心基础设施技术的深度协作与创新。它充分展现了开源社区的开放精神和跨社区协作的强大力量，我们将共同推动 AI 与云计算技术 的进步与发展。</p><p>本次会议由 京东，亚马逊, Nvidia, 阿里，蚂蚁，字节，百度，华为，中科院, Linux foundation等国内外顶级专家学者分享CNCF/openinfra相关技术议题。本次会议JDOS 的Chen因Kata container等开源社区贡献受邀参加此次会议并做出技术分享。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047405595" alt="在这里插入图片描述" title="在这里插入图片描述"/><br/>作为对共同挑战的回应，KCD杭州站与OpenInfra Days China将于11月15日在杭州首度联合举办，共同呈现一场开创性的技术盛会。这标志着围Kubernetes敏捷应用编排与OpenInfra稳定基础设施构建的两大生态，正主动打破壁垒，迈向融合协同的新阶段。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405596" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><p>京东云高级工程师张晨受邀将在本次大会中进行分享，他的主题是《大型集群中的数据处理：如何兼顾效率、可拓展性与可持续性》。<br/>Chen Zhang</p><p>Chen Zhang is a staff software engineer at JD cloud and a maintainer of the </p><p>QEMU project. He works in the virtualization field for many years.  As an accomplished speaker, Chen has presented at several international conferences, including KVM Forum 2022, Xen Summit 2019, LinuxCon China 2017, Open Source Summit Japan 2017, and CLK 2022, among others.<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047405597" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><p>在AI驱动的数据洪流时代，大规模集群的数据处理能力是衡量云基础设施核心竞争力的关键。张晨将基于京东云在超大规模复杂场景下的深厚实践，分享如何构建既高效、又可平滑扩展，同时保证长期运营可持续性的数据处理架构与策略。他的分享将为业界同行应对相似挑战提供宝贵的思路与实战经验。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047405598" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><p>运营大型 Kubernetes 集群的企业面临一个关键难题：如何在不牺牲容器性能与密度的前提下实现强隔离。通过采用 Kata 容器，京东云成功实现了安全与性能隔离，并支持在线应用与离线任务在数十万个节点上的共处而彼此互不干扰，大幅提高物理 CPU 的利用率以节省巨额成本。这一方式在“618 购物节”期间显著降低能耗。本次演讲将深入解析京东在部署 Kata 容器中的历程，涵盖架构设计、动机出发点及关键性能指标。另外分享京东自研的Kata Disk I/O 性能加速技术，对比默认配置可最高提升40%的通用磁盘性能。我将分享一套经实际部署的方案经验，如何在严苛的真实场景中基于虚拟机的隔离提升安全性与效率，并剖析其实际应用价值与注意事项。</p><p>京东云高级工程师-张晨 《大型集群中的数据处理：如何兼顾效率、可拓展性与可持续性》现场分享内容<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047405599" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[vue3 百度地图组件 freeman_]]></title>    <link>https://segmentfault.com/a/1190000047405610</link>    <guid>https://segmentfault.com/a/1190000047405610</guid>    <pubDate>2025-11-17 18:02:13</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <pre><code>&lt;template&gt;
  &lt;div class="map-container"&gt;
    &lt;!-- 搜索地址部分 --&gt;
    &lt;div class="search-box"&gt;
      &lt;a-input-group compact style="margin-bottom: 16px"&gt;
        &lt;!-- 将a-select改为a-input --&gt;
        &lt;a-input
          id="suggestId"
          v-model:value="searchAddress"
          placeholder="请输入详细地址进行搜索"
          style="width: 300px"
          @input="handleSearchInput($event.target.value)"
          @change="handleAddressChange($event.target.value)"
          @blur="handleBlur"
          @press-enter="throttledSearch"
          allow-clear
        /&gt;
        &lt;a-button type="primary" @click="searchBtn"&gt;
          &lt;template #icon&gt;&lt;SearchOutlined /&gt;&lt;/template&gt;
          搜索
        &lt;/a-button&gt;
        &lt;!-- &lt;a-button @click="getCurrentLocation" style="margin-left: 8px"&gt;
          &lt;template #icon&gt;&lt;AimOutlined /&gt;&lt;/template&gt;
          定位
        &lt;/a-button&gt; --&gt;
      &lt;/a-input-group&gt;
    &lt;/div&gt;

    &lt;!-- 地图容器 --&gt;
    &lt;div ref="mapRef" class="map-box"&gt;
      &lt;Loading
        :loading="loading"
        :absolute="false"
        theme="dark"
        background="rgba(111,111,111,.7)"
        tip="地图加载中..."
      /&gt;
    &lt;/div&gt;

    &lt;!-- 地址信息展示 --&gt;
    &lt;a-card v-if="selectedAddress" size="small" style="margin-bottom: 16px"&gt;
      &lt;a-space direction="vertical" style="width: 100%"&gt;
        &lt;a-text&gt;选中地址：{{ selectedAddress }}&lt;/a-text&gt;
        &lt;a-space&gt;
          &lt;a-text&gt;经度：{{ selectedPoint.lng }}&lt;/a-text&gt;
          &lt;a-text&gt;纬度：{{ selectedPoint.lat }}&lt;/a-text&gt;
        &lt;/a-space&gt;
        &lt;a-space v-if="addressComponents.province"&gt;
          &lt;a-text&gt;省份：{{ addressComponents.province }}&lt;/a-text&gt;
          &lt;a-text&gt;城市：{{ addressComponents.city }}&lt;/a-text&gt;
          &lt;a-text&gt;区域：{{ addressComponents.district }}&lt;/a-text&gt;
          &lt;a-text&gt;行政编码：{{ addressComponents.adcode }}&lt;/a-text&gt;
        &lt;/a-space&gt;
      &lt;/a-space&gt;
    &lt;/a-card&gt;
  &lt;/div&gt;
&lt;/template&gt;

&lt;script lang="ts"&gt;
  import { defineComponent, ref, onMounted, nextTick, unref, computed, onUnmounted } from 'vue';
  import { SearchOutlined } from '@ant-design/icons-vue';
  import { useMessage } from '/@/hooks/web/useMessage';
  import coordtransform from 'coordtransform';
  import type { TrackArray } from './typing';
  import { Loading } from '/@/components/Loading';
  import { useUserStore } from '@/store/modules/user';
  import { useScript } from '/@/hooks/web/useScript';
  import { Space as ASpace } from 'ant-design-vue';
  import { throttle } from 'lodash-es';

  const { createMessage } = useMessage();
  const userStore = useUserStore();
  const { mapKey = '' } = userStore.userInfo;
  const BAI_DU_MAP_URL = `https://api.map.baidu.com/getscript?v=1.0&amp;type=webgl&amp;ak=${mapKey}`;

  // 定义地址组件接口
  interface AddressComponents {
    province: string;
    city: string;
    district: string;
    adcode: string;
    street: string;
    streetNumber: string;
  }

  // 定义地址选择事件返回的数据结构
  interface AddressSelectResult {
    address: string;
    point: {
      lng: number;
      lat: number;
    };
    lng: string;
    lat: string;
    province: string;
    city: string;
    district: string;
    adcode: string;
    fullAddress: string;
  }

  export default defineComponent({
    name: 'BaiduMapWithSearch',
    components: { SearchOutlined, Loading, ASpace },

    props: {
      trackArray: Array as PropType&lt;TrackArray&gt;,
      mapPointSelect: {
        type: Boolean,
        default: false,
      },
      enableAddressSelect: {
        type: Boolean,
        default: false,
      },
    },

    emits: ['address-select', 'finish'],

    setup(props, { emit }) {
      let BMapGL: any = null;
      let mapObj: any = null;
      let geoc: any = null;
      let currentMarker: any = null;
      let autocomplete: any = null;

      const mapRef = ref&lt;HTMLElement | null&gt;(null);
      const { toPromise } = useScript({ src: BAI_DU_MAP_URL });
      const loading = ref(false);

      // 搜索相关数据
      const searchAddress = ref('');
      const selectedAddress = ref('');
      const selectedPoint: any = ref({ lng: 0, lat: 0 });
      const searchHistory = ref&lt;string[]&gt;([]);
      const mapSuggestions = ref&lt;string[]&gt;([]);
      const showSuggestions = ref(false);
      const isSearching = ref(false);
      let debounceTimer: any = null;
      // 新增：地址组件信息
      const addressComponents = ref&lt;AddressComponents&gt;({
        province: '',
        city: '',
        district: '',
        adcode: '',
        street: '',
        streetNumber: '',
      });

      // 计算属性：获取过滤后的建议
      const filteredSuggestions = computed(() =&gt; {
        const allSuggestions = [...new Set([...mapSuggestions.value, ...searchHistory.value])];
        // console.log('allSuggestions:', allSuggestions);
        return allSuggestions
          .filter((suggestion) =&gt;
            suggestion.toLowerCase().includes(searchAddress.value.toLowerCase()),
          )
          .slice(0, 10);
      });

      // 初始化地图
      async function initMap() {
        searchAddress.value = '';
        selectedAddress.value = '';
        try {
          loading.value = true;
          await toPromise();
          await nextTick();

          const wrapEl = unref(mapRef);
          if (!wrapEl) return;

          BMapGL = (window as any).BMapGL;
          mapObj = new BMapGL.Map(wrapEl);
          geoc = new BMapGL.Geocoder();

          const point = new BMapGL.Point(116.404, 39.915);
          mapObj.centerAndZoom(point, 12);
          mapObj.enableScrollWheelZoom(true);

          // 添加地图控件
          mapObj.addControl(new BMapGL.NavigationControl());
          mapObj.addControl(new BMapGL.ScaleControl());
          // todo: 添加地图事件
          if (props.mapPointSelect) {
            initMapEvents();
          }

          // 初始化自动完成
          initAutocomplete();

          window.addEventListener('resize', resizeMap);
          emit('finish');

          // 加载搜索历史
          loadSearchHistory();
        } catch (error) {
          createMessage.error('地图初始化失败');
          console.error('地图初始化错误:', error);
        } finally {
          loading.value = false;
        }
      }

      // 初始化地图事件
      function initMapEvents() {
        mapObj.addEventListener('click', (e: any) =&gt; {
          if (!props.enableAddressSelect) return;

          const point = new BMapGL.Point(e.latlng.lng, e.latlng.lat);
          addMarker(point);
          reverseGeocode(point);
        });
      }

      // 初始化自动完成功能
      function initAutocomplete() {
        if (!BMapGL) return;

        // 创建Autocomplete实例
        autocomplete = new BMapGL.Autocomplete({
          input: 'suggestId', // 绑定输入框
          location: mapObj,
        });

        // 监听选择事件
        autocomplete.addEventListener('onconfirm', function (e: any) {
          console.log('onconfirm:', e);
          const item = e.item.value;
          // 拼接完整地址
          // const fullAddress =
          //   item.province + item.city + item.district + item.street + item.business;
          const fullAddress =
            item.address || item.province + item.city + item.district + item.street + item.business;

          // searchAddress.value = fullAddress;
          selectedAddress.value = fullAddress;
          showSuggestions.value = false;
          // 执行搜索
          handleSearch(fullAddress);

          // const point = new BMapGL.Point(item.location.lng, item.location.lat);
          // addMarker(point);
          // reverseGeocode(point);

          // 添加到搜索历史
          addToSearchHistory(fullAddress);
        });
        // 监听下拉列表高亮事件（实时获取建议）
        // autocomplete.addEventListener('onhighlight', function (e) {
        //   console.log('=== onhighlight事件被触发 ===');

        //   if (e.toitem &amp;&amp; e.toitem.index &gt; -1) {
        //     const item = e.toitem.value;
        //     const suggestion =
        //       item.province + item.city + item.district + item.street + item.business;
        //     console.log('高亮建议:', suggestion);

        //     // 这里可以实时更新您的自定义建议列表
        //     updateCustomSuggestions([suggestion]);
        //   }
        // });
      }

      // 搜索输入处理（带防抖）
      const handleSearchInput = (value: string) =&gt; {
        console.log('handleSearchInput:', value);
        searchAddress.value = value;
        isSearching.value = true;
        // showSuggestions.value = value.length &gt; 0;

        clearTimeout(debounceTimer);
        debounceTimer = setTimeout(() =&gt; {
          if (value.trim()) {
            getAddressSuggestions(value);
          } else {
            showSuggestions.value = false;
          }
          isSearching.value = false;
        }, 300);
      };

      // 地址选择变化处理
      const handleAddressChange = (value: string) =&gt; {
        if (value) {
          searchAddress.value = value;
          // 添加到搜索历史
          addToSearchHistory(value);
          // 执行搜索
          // handleSearch(value);

          // getAddressSuggestions(value);
        }
      };

      // 输入框失去焦点处理
      const handleBlur = () =&gt; {
        setTimeout(() =&gt; {
          showSuggestions.value = false;
          const currentValue = searchAddress.value;
          if (currentValue &amp;&amp; !searchHistory.value.includes(currentValue)) {
            addToSearchHistory(currentValue);
          }
        }, 200);
      };
      const searchBtn = () =&gt; {
        if (!searchAddress.value) {
          createMessage.warning('请输入搜索地址');
          return;
        }
        console.log('搜索地址：', searchAddress.value);
        isSearching.value = true;
        showSuggestions.value = searchAddress.value.length &gt; 0;

        clearTimeout(debounceTimer);
        debounceTimer = setTimeout(() =&gt; {
          if (searchAddress.value.trim()) {
            getAddressSuggestions(searchAddress.value);
          } else {
            showSuggestions.value = false;
          }
          isSearching.value = false;
        }, 300);
      };
      // 执行搜索
      const handleSearch = (value?: string) =&gt; {
        const searchValue = value || searchAddress.value;
        // 添加类型检查
        if (!searchValue || typeof searchValue !== 'string' || !searchValue.trim()) {
          createMessage.warning('请输入搜索地址');
          return;
        }

        if (!searchValue.trim()) {
          // createMessage.warning('请输入搜索地址');
          return;
        }

        geocodeAddress(searchValue);
        showSuggestions.value = false;
      };
      // 节流搜索处理
      const throttledSearch = throttle(handleSearch, 500);

      // 获取地址建议
      const getAddressSuggestions = async (keyword: string) =&gt; {
        if (!BMapGL || !keyword.trim()) {
          return;
        }
        try {
          // 使用Autocomplete获取建议
          autocomplete.search(keyword, (results: any) =&gt; {
            if (results &amp;&amp; results.poi_list.length &gt; 0) {
              const suggestions = results.poi_list.map(
                (item: any) =&gt;
                  item.province + item.city + item.district + item.street + item.business,
              );
              mapSuggestions.value = suggestions;
            } else {
              mapSuggestions.value = [];
            }
          });
        } catch (error) {
          console.error('获取地址建议失败:', error);
          mapSuggestions.value = [];
        }
      };

      // 地理编码（地址转坐标）
      const geocodeAddress = (address: string) =&gt; {
        if (!geoc) return;

        geoc.getPoint(
          address,
          (point: any) =&gt; {
            if (point) {
              mapObj.centerAndZoom(point, 16);
              addMarker(point);
              selectedPoint.value = { lng: point.lng, lat: point.lat };

              // 触发地址选择事件
              // emitAddressSelect();
              const ainpoint = new BMapGL.Point(point.lng, point.lat);
              reverseGeocode(ainpoint);
            } else {
              // createMessage.warning('无法解析该地址，请尝试更详细的地址信息');
            }
          },
          '全国',
        );
      };

      // 逆地理编码（坐标转地址）
      const reverseGeocode = (point: any) =&gt; {
        if (!geoc) return;

        geoc.getLocation(point, (result: any) =&gt; {
          if (result) {
            const addressComponentsResult = result.content.address_detail;
            console.log('逆地理编码结果:', result);

            // 设置地址组件信息[5](@ref) town_code
            addressComponents.value = {
              province: addressComponentsResult.province || '',
              city: addressComponentsResult.city || '',
              district: addressComponentsResult.district || '',
              adcode: addressComponentsResult.adcode || '',
              street: addressComponentsResult.street || '',
              streetNumber: addressComponentsResult.streetNumber || '',
            };

            // selectedAddress.value =
            //   addressComponentsResult.province +
            //   addressComponentsResult.city +
            //   addressComponentsResult.district +
            //   addressComponentsResult.street +
            //   addressComponentsResult.streetNumber;
            showSuggestions.value = false;
            emitAddressSelect();
          }
        });
      };

      // 添加标记点
      const addMarker = (point: any) =&gt; {
        if (currentMarker) {
          mapObj.removeOverlay(currentMarker);
        }

        currentMarker = new BMapGL.Marker(point);
        mapObj.addOverlay(currentMarker);
      };

      // 添加到搜索历史
      const addToSearchHistory = (address: string) =&gt; {
        // console.log('添加到搜索历史：', address);
        if (!address.trim() || address.length &lt; 2) return;

        const isSimilar = searchHistory.value.some(
          (item) =&gt; item.includes(address) || address.includes(item),
        );

        if (!isSimilar) {
          const filteredHistory = searchHistory.value.filter((item) =&gt; item !== address);
          searchHistory.value = [address, ...filteredHistory].slice(0, 15);
          saveSearchHistory();
        }
      };

      // 保存搜索历史到本地存储
      const saveSearchHistory = () =&gt; {
        if (typeof localStorage !== 'undefined') {
          localStorage.setItem('baidu-map-search-history', JSON.stringify(searchHistory.value));
        }
      };

      // 从本地存储加载搜索历史
      const loadSearchHistoryFromStorage = (): string[] =&gt; {
        if (typeof localStorage !== 'undefined') {
          const history = localStorage.getItem('baidu-map-search-history');
          return history ? JSON.parse(history) : [];
        }
        return [];
      };

      // 加载搜索历史
      const loadSearchHistory = () =&gt; {
        searchHistory.value = loadSearchHistoryFromStorage();
      };

      const convertToGPS = (lng: number, lat: number) =&gt; {
        const gcj02 = coordtransform.bd09togcj02(lng, lat);
        return coordtransform.gcj02towgs84(gcj02[0], gcj02[1]);
      };

      // 触发地址选择事件
      const emitAddressSelect = () =&gt; {
        if (props.enableAddressSelect) {
          console.log('已选择地址：' + selectedAddress.value);
          console.log('已选择坐标：' + selectedPoint.value.lng + ',' + selectedPoint.value.lat);
          console.log('省市区信息：', addressComponents.value);

          // 转换为WGS84坐标
          const [wgs84Lng, wgs84Lat] = convertToGPS(
            selectedPoint.value.lng,
            selectedPoint.value.lat,
          );

          // 构建完整的地址选择结果[5](@ref)
          const addressSelectResult: AddressSelectResult = {
            address: selectedAddress.value,
            point: selectedPoint.value,
            lng: wgs84Lng.toFixed(6),
            lat: wgs84Lat.toFixed(6),
            province: addressComponents.value.province,
            city: addressComponents.value.city,
            district: addressComponents.value.district,
            adcode: addressComponents.value.adcode,
            fullAddress: `${addressComponents.value.province}${addressComponents.value.city}${addressComponents.value.district}${addressComponents.value.street}${addressComponents.value.streetNumber}`,
          };

          // 触发地址选择事件，返回完整信息
          emit('address-select', addressSelectResult);
        }
      };

      // 调整地图大小
      const resizeMap = () =&gt; {
        if (mapObj) {
          setTimeout(() =&gt; {
            mapObj.resize();
            mapObj.setCenter(mapObj.getCenter());
          }, 100);
        }
      };

      // 重置地图
      const resetMap = () =&gt; {
        if (mapObj) {
          mapObj.clearOverlays();
          const point = new BMapGL.Point(116.404, 39.915);
          mapObj.centerAndZoom(point, 12);
        }
        searchAddress.value = '';
        selectedAddress.value = '';
        selectedPoint.value = { lng: 0, lat: 0 };
        addressComponents.value = {
          province: '',
          city: '',
          district: '',
          adcode: '',
          street: '',
          streetNumber: '',
        };
      };

      onMounted(() =&gt; {
        initMap();
      });

      // 组件卸载时清理
      onUnmounted(() =&gt; {
        // 清理资源
        if (mapObj) {
          mapObj.destroy();
          mapObj = null;
        }
        if (throttledSearch) {
          throttledSearch.cancel();
        }
        window.removeEventListener('resize', resizeMap);
      });

      return {
        mapRef,
        loading,
        searchAddress,
        selectedAddress,
        selectedPoint,
        searchHistory,
        filteredSuggestions,
        addressComponents,
        showSuggestions,
        handleSearchInput,
        handleAddressChange,
        handleBlur,
        handleSearch,
        throttledSearch,
        resetMap,
        initMap,
        searchBtn,
      };
    },
  });
&lt;/script&gt;

&lt;style lang="less" scoped&gt;
  .map-container {
    position: relative;
    width: 100%;
    height: 100%;

    :deep(.tangram-suggestion) {
      z-index: 1001 !important;
    }

    .search-box {
      position: absolute;
      z-index: 999;
      top: 16px;
      left: 16px;
      min-width: 400px;
      padding: 16px;
      border-radius: 6px;
      background: rgb(255 255 255 / 95%);
      box-shadow: 0 2px 8px rgb(0 0 0 / 15%);
    }

    .map-box {
      width: 100%;
      height: 100%;
      min-height: 500px;
    }

    // 搜索建议下拉框样式
    .suggestions-dropdown {
      position: absolute;
      z-index: 1000;
      top: 100%;
      right: 16px;
      left: 16px;
      max-height: 200px;
      overflow-y: auto;
      border: 1px solid #d9d9d9;
      border-radius: 6px;
      background: white;
      box-shadow: 0 2px 8px rgb(0 0 0 / 15%);

      .suggestion-item {
        padding: 8px 12px;
        transition: background-color 0.3s;
        border-bottom: 1px solid #f0f0f0;
        cursor: pointer;

        &amp;:last-child {
          border-bottom: none;
        }

        &amp;:hover {
          background-color: #f5f5f5;
        }
      }
    }
  }
  // 优化选择器下拉框样式
  :deep(.ant-select-dropdown) {
    z-index: 1000;

    .ant-select-item {
      padding: 8px 12px;
    }
  }

  :global(.tangram-suggestion) {
    z-index: 9999 !important;
  }

  // 优化输入框样式
  // :deep(.ant-input) {
  //   height: 32px;
  // }
&lt;/style&gt;
</code></pre>]]></description></item><item>    <title><![CDATA[动力电池怎么选？关键参数解析与行业案例分]]></title>    <link>https://segmentfault.com/a/1190000047405622</link>    <guid>https://segmentfault.com/a/1190000047405622</guid>    <pubDate>2025-11-17 18:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>动力电池的基本概念与重要性<br/>动力电池，即为电动汽车、电动工具、便携式设备等提供动力的可充电电池，是新能源汽车的核心部件，其性能直接决定了整车的续航能力、安全性和使用寿命。随着全球能源转型和“双碳”目标的推进，动力电池产业已成为绿色经济的重要支柱之一。目前，动力电池主要分为三元锂电池、磷酸铁锂电池和固态电池等类型，其中三元锂电池和磷酸铁锂电池占据了主流市场，而固态电池因其高能量密度和安全性被视为下一代技术方向。例如，特斯拉通过采用三元锂电池技术，大幅提升了其电动汽车的续航里程；比亚迪则凭借磷酸铁锂电池的高安全性和低成本，在商用车领域取得了显著优势。<br/>动力电池技术发展现状<br/>近年来，动力电池技术取得了显著进步，主要体现在能量密度提升、充电速度加快和循环寿命延长等方面。以三元锂电池为例，其单体能量密度可达300Wh/kg以上，系统能量密度也在260Wh/kg左右；磷酸铁锂电池则以安全性著称，循环寿命可达2000次以上。然而，成本问题仍是制约其大规模应用的关键因素。例如，2024年全球动力电池装机量预计突破1.2TWh，中国市场份额持续保持60%以上，但电池原材料价格波动较大，导致生产成本居高不下。<br/>动力电池制造的挑战与应对<br/>在动力电池生产过程中，质量控制和能耗管理是两大核心挑战。以电芯制程异常为例，该问题受到多种因素影响，包括设备参数漂移、材料批次差异和环境温度波动等。传统制造模式依赖人工经验调整设备参数，效率低且难以避免缺陷。然而，随着工业4.0技术的引入，广域铭岛通过其Geega工业AI应用平台，为新能源电池企业打造了“工业超级智能体”，实现了工艺优化和能耗管理的全面升级。例如，在富江能源的12GWh电池项目中，广域铭岛帮助工厂降低综合能耗15%以上；在衢州极电工厂的数字化改造中，其QAL质量分析平台将工艺波动降低30%，显著提升了生产效率和良品率。<br/>动力电池未来发展趋势<br/>未来，动力电池技术将向高能量密度、长寿命和绿色化方向发展。固态电池作为最具潜力的技术路线之一，其安全性高，能量密度可进一步提升至400Wh/kg以上。例如，丰田在硫化物固态电池领域的研发已取得突破，实验原型能量密度达到400Wh/kg，并计划在2020年实现产业化。此外，数字化和AI技术也将成为推动动力电池行业升级的重要力量。广域铭岛正在通过构建“数字孪生工厂”，实现生产全流程的可视化和智能化管理，助力企业应对产能扩张和市场需求变化的挑战。<br/>动力电池回收与可持续发展<br/>随着动力电池使用年限的增加，回收利用问题日益突出。据统计，2025年全球动力电池累计装机量将超过1000GWh，届时退役电池数量将达到数千万台。广域铭岛在电池回收领域也有所布局，通过建立完善的回收体系，实现退役电池的梯级利用和材料再生。例如，其回收项目资源回收率超过95%，为行业树立了环保标杆。这种闭环管理模式不仅降低了环境影响，还提高了资源利用效率，符合可持续发展的理念。<br/>总之，动力电池作为新能源汽车和储能系统的核心部件，其技术发展和制造升级对推动绿色能源转型具有重要意义。广域铭岛通过其工业超级智能体和数字化解决方案，为行业提供了创新性的技术支持，助力企业在高能量密度电池研发、生产效率提升和成本控制等方面取得突破。未来，随着固态电池等新技术的不断成熟，以及数字化技术的广泛应用，动力电池产业将迎来更加广阔的发展空间。</p>]]></description></item><item>    <title><![CDATA[工业AI大模型：智能制造的核心引擎与落地]]></title>    <link>https://segmentfault.com/a/1190000047405166</link>    <guid>https://segmentfault.com/a/1190000047405166</guid>    <pubDate>2025-11-17 17:09:47</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>近年来，人工智能技术的快速发展推动了工业领域的智能化转型，而工业AI大模型作为这一趋势的核心驱动力，正在重塑制造业的生产流程、管理方式和商业模式。工业AI大模型不仅具备通用大模型的泛化能力，还融合了工业场景的专业知识，能够解决复杂、非标准化的生产任务。然而，从技术到落地，工业AI大模型仍面临诸多挑战，包括数据孤岛、模型泛化能力不足、安全风险以及商业模式不成熟等问题。<br/>在制造业中，工业AI大模型的应用已逐步从外围环节向核心生产环节渗透。例如，在汽车制造领域，工业大模型被用于优化车身涂装工艺，通过实时分析喷涂参数（如压力、温度、湿度），预测涂层缺陷并自动调整设备运行状态。某吉利集团子公司在引入工业AI大模型后，涂装合格率提升至99.8%，年节省成本超200万元。<br/>数据壁垒与安全问题：工业AI落地的两大瓶颈<br/>工业AI大模型的训练和优化高度依赖高质量数据，但当前工业企业的数据往往分散在不同系统中，形成“数据孤岛”。例如，在钢铁行业，某龙头企业通过构建“决策-管控-操控”三层数据架构，成功整合了生产、能耗、设备等多源数据，开发了49个垂直大模型应用场景。然而，数据采集和清洗仍是许多中小企业的痛点。<br/>此外，AI生成代码的安全性问题也不容忽视。根据行业调查，45%的工业AI生成代码存在安全漏洞，可能导致设备损坏或生产中断。为此，企业需要建立“云边端三级部署”架构，将模型部署在边缘设备时进行轻量化处理，提升实时性和安全性。<br/>广域铭岛的实践：边缘计算助力工业AI落地<br/>作为工业智能化的先行者，广域铭岛在边缘计算领域积累了丰富经验，其工业AI解决方案覆盖了设备层、产线层和企业层的多层次需求。例如，通过边缘计算平台，广域铭岛帮助某制造企业实现了设备数据的实时采集与分析，显著提升了生产调度效率。<br/>广域铭岛还通过数据合成技术弥补了工业数据缺失的问题，尤其是在涉及核心技术的CAD数据领域。该企业通过构建虚拟数据集，完成了设计图的自动生成与优化，缩短了研发周期。<br/>场景化落地：从“技术找场景”到“问题驱动”<br/>工业AI大模型的成功落地并非单纯依赖技术先进性，而是需要精准匹配企业实际需求。例如，在炼钢厂的钢包热修场景中，某团队通过深入一线调研，发现该环节存在高温作业风险，而工业AI技术恰好可以缓解这一问题。通过部署智能工作站，单台设备的售价虽高（超1000万元），但其带来的安全性和效率提升为企业创造了显著价值。<br/>结语<br/>工业AI大模型不仅是技术的革新，更是制造业转型升级的关键工具。通过解决数据、安全、场景适配等问题，工业大模型有望在更多领域实现规模化落地，为传统工业注入新的活力。广域铭岛等企业的实践表明，边缘计算与模型协同是实现这一目标的重要路径，而“问题驱动”的实施策略则是确保ROI的关键。</p>]]></description></item><item>    <title><![CDATA[三款热门供应链系统实测，这样选不踩坑 遭]]></title>    <link>https://segmentfault.com/a/1190000047405176</link>    <guid>https://segmentfault.com/a/1190000047405176</guid>    <pubDate>2025-11-17 17:09:14</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>供应链掉一次链子，整单利润就“打水漂”。传统ERP太贵、Excel又管不住多环节？Zoho Creator低代码平台用“拖—拉—拽”15天搭出采购-库存-物流-销售一体化系统，开发成本仅为传统定制的1/5，让中小企业也能用得起、改得快、管得住全球供应链。<br/><img width="500" height="328" referrerpolicy="no-referrer" src="/img/bVdm4pL" alt="" title=""/><br/>一、供应链管理是什么？<br/>供应链管理是对从原材料采购到产品交付最终用户的整个流程进行规划、协调、控制和优化的系统性方法。它涵盖了物流、信息流、单证流、商流和资金流的全面自动化与优化，旨在实现整体供应链的可视化、管理信息化和利益最大化。</p><p>在现代商业环境中，一套高效的供应链管理系统能帮助企业应对多重挑战：</p><p>解决因供应商、物流商、仓库和销售团队之间信息不透明导致的协同效率低下问题；<br/>避免全球多地仓库库存数据更新不及时造成的库存管理失衡；<br/>缓解国际物流环节多周期长带来的跟踪困难；<br/>有效控制传统供应链系统开发成本高、维护费用贵的财务压力。<br/>二、什么是低代码？低代码开发供应链管理有什么优势？<br/>低代码是一种可视化应用开发方法，通过图形化界面和拖放组件，让开发者以最少的编码快速构建应用程序。在供应链管理领域，低代码平台正成为企业快速构建应用的重要工具，它们通过可视化界面和模块化组件，让非技术人员也能参与应用开发，大幅降低开发门槛和成本。</p><p>低代码开发供应链管理系统具有以下显著优势：</p><p>1、时间和成本节约<br/>低代码平台采用可视化的编程方式，大多数操作基于拖放方式进行，极大地缩短了开发周期，同时降低了开发成本。对于中小企业而言，传统供应链管理系统动辄数十万的开发成本和冗长的实施周期是难以承受的负担，而低代码平台能将开发成本降至传统定制开发的1/5 - 1/3，实施周期从传统的3 - 6个月缩短至1 - 4周。</p><p>2、灵活定制与快速迭代<br/>全球供应链需求多变，企业可能突然需要新增海外仓库或调整供应商合作模式。低代码平台支持“快速迭代应用”——业务人员可直接在现有应用基础上添加模块、修改流程，无需重新开发，适配成本极低。这种灵活性使企业能够快速响应市场变化，保持竞争优势。</p><p>3、打破信息孤岛，实现全链路协同<br/>Zoho低代码平台可搭建“供应商-物流-仓库-销售”全链路协同应用，实现数据实时同步。通过多角色权限管控，针对供应商、物流商、仓库管理员、销售团队等不同角色设置差异化权限，确保数据安全的同时，实现“数据在正确的人手中流转”。</p><p>三、如何选择合适的低代码开发平台？选型的注意事项<br/>在选择低代码开发平台时，企业需从多个维度评估平台的适用性，以确保选择最适合自身需求的解决方案。</p><p>1、平台能力与扩展性评估<br/>一个合格的平台应提供模型驱动、可视化开发、表达式语言等核心能力，并支持测试debug和版本控制等软件工程实践。平台是否支持多语言、多时区也是出海企业的关键需求。Zoho低代码平台支持一次开发、多端部署，可同时生成Web应用、移动应用和桌面应用，确保用户在不同设备上获得一致体验。</p><p>2、行业经验与案例积累<br/>有经验的平台能提供更佳实践参考，减少企业试错成本。Zoho低代码已有19年技术积累，服务过多行业客户，能提供更有价值的解决方案。</p><p>3、总体拥有成本综合评估<br/>除初始开发费用外，企业还需考虑维护成本、升级费用等。Zoho低代码平台采用订阅制，价格透明，且提供免费试用，企业可先验证效果再决策。其价格方案灵活，有免费版，标准版672元/用户/年，专业版1680元/用户/年（不限应用），企业版2100元/用户/年（不限应用），满足不同规模企业需求。</p><p>4、选择可靠、安全的技术厂商<br/>Zoho低代码的优势：</p><p>丰富的集成：与国际物流平台、电商平台集成更顺畅，贴合国际贸易场景。<br/>可靠的技术支持：Zoho低代码提供国内专业的中文技术支持，遇到问题时，可获1对1服务，快速响应解决。<br/>长期稳定：Zoho在全球自建16个服务器，数据传输稳定可靠。<br/>数据安全：企业级数据加密、隐私保护合规等，满足国际贸易中的数据安全要求。<br/>四、如何用Zoho低代码平台开发供应链管理系统？<br/>使用Zoho低代码，您可以像搭积木一样，轻松构建涵盖采购、库存、生产、销售、物流全链路的管理系统。</p><p>1、蓝图规划<br/>与各部门协作，梳理出核心业务流程与数据模型（如供应商、SKU、仓库、订单等）。</p><p>2、拖拽式构建<br/>使用直观的可视化构建器，创建数据表、表单和报表界面。无需编码，即可定义字段关系和页面逻辑。</p><p>3、配置自动化工作流<br/>设置“如果-那么”规则。例如：“如果库存量低于安全水位，那么自动发送采购预警邮件并生成采购申请单”。</p><p>4、深度集成<br/>利用内置连接器或API，将您的供应链应用与Zoho Books（进销存系统）、Shopify（电商）、FedEx（物流）等系统打通，消除信息孤岛。</p><p>5、发布移动APP<br/>一键将应用发布为原生移动APP，赋能一线员工进行扫码盘点、订单处理和物流跟踪。</p><p>6、持续迭代优化<br/>根据业务反馈和市场变化，随时使用平台添加新功能或调整现有流程，让系统永远与业务同步成长。</p><p>五、成功案例：元品贸易的数字化转型<br/>元品贸易是一家专注于美国和非洲商超市场的小型服装外贸企业。通过Zoho低代码平台，元品贸易在仅15天内就搭建了符合企业需求的供应链管理系统，系统总费用仅为传统开发的十分之一，年账号续费仅两千多元（3用户）。</p><p>该系统支持多实体选择切换，对于不同的客户，可以选择不同的代理商实体和出口商实体，对应到每个订单的财务开票。不同订单和实体统一到一个数据看板，应收账款、应付账款和销账数据一目了然。实施Zoho低代码后，元品贸易的工作效率提升了50%，订单管理和跟进时间大大缩短，错误率归零。</p><p>别让漫长的实施周期和高昂费用挡住出海脚步。立即免费试用Zoho Creator，15天全功能体验：从采购预警、多币种发票到物流节点实时追踪一键配齐，按需订阅84元/用户/月起，随增随减无绑定。把供应链搬进Zoho Creator，让全球订单、库存、资金在同一屏幕安全可控，快速响应市场变化，稳步拓展海外版图。</p>]]></description></item><item>    <title><![CDATA[Apache Cloudberry 集成]]></title>    <link>https://segmentfault.com/a/1190000047405242</link>    <guid>https://segmentfault.com/a/1190000047405242</guid>    <pubDate>2025-11-17 17:08:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>Apache Cloudberry™ (Incubating) 是 Apache 软件基金会孵化项目，由 Greenplum 和 PostgreSQL 衍生而来，作为领先的开源 MPP 数据库，可用于建设企业级数据仓库，并适用于大规模分析和 AI/ML 工作负载。<br/>GitHub: <a href="https://link.segmentfault.com/?enc=GIS%2BCv4PFqejvOFikOaENQ%3D%3D.%2FTWCxWt6Tm%2F04jOuHcWSDxb%2BK3XXPjWWMMdIoDjqYH1e75jSL4gN88LbZOTWazf3" rel="nofollow" target="_blank">https://github.com/apache/cloudberry</a>文章作者：陈亮，酷克数据售后工程师；整理：酷克数据ZomboDB 是 PostgreSQL 的扩展组件，通过与 Elasticsearch 的集成，为数据库系统引入了高性能的全文检索与文本分析功能。我们对 ZomboDB 进行了兼容性改造与优化，使其能够支持 Apache Cloudberry，从而让 Cloudberry 拥有 Elasticsearch 丰富的全文检索与文本分析能力。通过简单的 SQL 语法，用户即可在已有的 Cloudberry 表上创建 ZomboDB 索引，实现高性能、可事务化的全文搜索。ZomboDB 实际上是基于 Elasticsearch 外部索引的实现，它可以管理 Elasticsearch 集群上的索引，并确保在事务层面上保持数据与索引的一致性。此外，ZomboDB 支持大多数 Cloudberry 的 SQL 操作，包括：CREATE INDEX、COPY、INSERT、UPDATE、DELETE、SELECT、ALTER、DROP、REINDEX、(auto)VACUUM 等。工作原理ZomboDB 通过连接 Cloudberry 集群与 Elasticsearch 集群，实现两者的数据同步与检索协作。无论两个集群是否位于同一主机，只需保证网络通信畅通即可正常运行。Cloudberry 中的每一个 ZomboDB 索引实际上对应 Elasticsearch 中的一个 Index。当数据量较大时，为避免每个 Segment 扫描全量索引数据，ZomboDB 会将不同 Segment 的数据映射到 Elasticsearch 索引下的不同分片（Shard），从而提升并行扫描与查询性能。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405244" alt="图片" title="图片"/></p><p>创建索引和加载数据流程下图展示了数据表创建 ZomboDB 索引，并加载数据的大致流程。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405245" alt="图片" title="图片" loading="lazy"/></p><p>整个过程都是在和 Cloudberry集群中的 Coordinator 节点进行通信和交互。在 Cloudberry集群中创建数据表，并且加载相应的数据。使用 CREATE INDEX 语法创建 ZomboDB 的索引。此时需要保证 Elasticsearch 的集群处于可用状态，并且网络和 Cloudberry集群互通。创建的过程中，ZomboDB 会自动将表中已有的数据插入到 Elasticsearch 中对应的 index 里面，如果发生了错误，或者手动回滚事务，那么也会自动清理 ES 中的数据。在索引创建完成后，后续有新的数据插入到表中，都会自动将数据插入到对应 Elasticsearch 的 index 里。查询数据流程下图展示了存在 ZomboDB 索引的情况下，对数据进行查询的大致流程。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405246" alt="图片" title="图片" loading="lazy"/></p><p>用户侧使用 ZomboDB 的查询语法，基于 ZomboDB 的索引进行查询。ZomboDB 的查询和普通的 select 基本上没有区别，只是需要使用 ZomboDB 特定的标识符 ==&gt;。Cloudberry集群中的 Coordinator 节点将查询分发给各个 Segment。每个 Segment 各自执行查询，只需要查询对应的 Elasticsearch 的 index 中某个 Shard 的数据。每个 Segment 将查询的结果返回给 Coordinator 节点。Coordinator 节点收到 Segment 的结果，进行聚合或者其他操作，并返回给用户。安装 ZomboDB 插件注意：当前 ZomboDB 插件尚未开源，此安装方式适用于 HashData Lightning（基于 Apache Cloudberry）版本。// 通过 psql postgres 进入数据库，创建 zombodb 扩展<br/>postgres=# create extension zombodb;<br/>// 出现如下结果表示安装成功<br/>CREATE EXTENSION安装 Elasticsearch下载对应平台 elasticserch 安装包wget <a href="https://link.segmentfault.com/?enc=Stf15JeMmkMd3ze2alB7hQ%3D%3D.psh4purpwLqysGetJfP4EiVqkoR7c0aS2f9l%2F4ci%2FbNapxuO83QVrVZ83aeHwmGE%2Bs5oIQGuscAbI%2BBOKC6Utd%2FgQVQlNJkdelXh%2B8I2z10%2B8%2FYJ9fleupECgW3nxNil" rel="nofollow" target="_blank">https://artifacts.elastic.co/downloads/elasticsearch/elastics...</a>安装 elasticsearchyum -y install ./elasticsearch-8.6.1-x86_64.rpm修改/etc/elasticsearch/elasticsearch.yml，设置 xpack.security.enabled 为 falsexpack.security.enabled: false启动 elasticsearchsystemctl start elasticsearch安装 elasticsearch-analysis-ik 中文分词插件注意插件的版本必须与 elasticsearch 版本一致。上面的 elasticsearch 版本是 8.6.1，所以这里插件也要使用同样的版本。有 2 种安装方式：自动安装：cd /usr/share/elasticsearch/bin<br/>./bin/elasticsearch-plugin install <a href="https://link.segmentfault.com/?enc=TaaCgzfoq3WWWXC81JiOvg%3D%3D.IopI6M3mzUH8TgsiwKLkQgowKuTGNIi23EuhhpX98bHKLOZQ%2F6zRBriersKsbykZByKcg6%2FNJLJ5LYiC8Ezf%2FF7w%2F0aRsnFaDTjOH016qW5bq1EldCwiAxHwQ1RxTCNRkZB8bl4X%2By%2FTmbVIjSuslg%3D%3D" rel="nofollow" target="_blank">https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v8.6.1/elasticsearch-analysis-ik-8.6.1.zip</a>手动安装：从这个链接下载对应版本的安装包：<a href="https://link.segmentfault.com/?enc=xyr5PWvdgOmpPmPJUXnCZg%3D%3D.nmoJPqDAMq5WNYALsWRZsHF%2BZfdwwVed2flJ2EmLQWETjFJh6YJ5928JXv6zeFBNjlo4heJ0%2ByAptg3kO1ImaQ%3D%3D" rel="nofollow" target="_blank">https://github.com/medcl/elasticsearch-analysis-ik/releases</a>安装mkdir /usr/share/elasticsearch/plugins/ik<br/>unzip -d /usr/share/elasticsearch/plugins/ik ./elasticsearch-analysis-ik-8.6.1.zip重启 elasticsearchsystemctl restart elasticsearchCloudberry 实现中文检索创建一个名称是'myik'的 analyzer。SELECT zdb.define_analyzer('myik', '{"tokenizer": "ik_max_word"}');创建 domainCREATE DOMAIN myik AS text;创建测试表，注意这里列 c1 的数据类型要对应上面创建的 domain 名称。create table zombodb_t1 (c1 myik);创建索引create index idx_zombodb_t1 on zombodb_t1 using zombodb((zombodb_t1.*)) with (url='<a href="https://link.segmentfault.com/?enc=YQxYwtBCCGe57oUWQYR6UQ%3D%3D.0zOCL6jffCKEqGfpwfJR6%2B3Mb0WyjiMUJyiRqGyznh0%3D" rel="nofollow" target="_blank">http://localhost:9200/</a>');测试效果gpadmin=# insert into zombodb_t1 values ('中文测试');<br/>INSERT 0 1<br/>gpadmin=# insert into zombodb_t1 values ('中 文测试');<br/>INSERT 0 1<br/>gpadmin=# select * from zombodb_t1 where zombodb_t1 ==&gt; '中文';</p><pre><code>c1</code></pre><hr/><p>中文测试<br/>(1 row)</p><p>gpadmin=# select * from zombodb_t1 where zombodb_t1 ==&gt; '中 文';</p><pre><code>c1</code></pre><hr/><p>中 文测试<br/>(1 row)</p><p>gpadmin=# select * from zombodb_t1 where zombodb_t1 ==&gt; '测试';</p><pre><code>c1</code></pre><hr/><p>中文测试<br/> 中 文测试<br/>(2 rows)创建 index 报错在创建 index（例如 create index <br/>idx_fulltext_client_extended_info）时，出现了以下错误信息：ERROR: code=Some(429),<br/>"error": {<br/>  "root_cause": [</p><pre><code>{
  "type": "es_rejected_execution_exception",
  "reason": "rejected execution of coordinating operation [coordinating_and_primary_bytes=...]"
}</code></pre><p>],<br/>  "type": "es_rejected_execution_exception",<br/>  "reason": "rejected execution of coordinating operation [coordinating_and_primary_bytes=...]",<br/>  "status": 429<br/>}从错误信息可以看出，Elasticsearch 在协调节点执行操作时因为内存压力过大而拒绝了请求（<br/>es_rejected_execution_exception），导致索引创建失败。解决方法：修改/etc/elasticsearch/elasticsearch.yml， 添加如下参数。如果不指定，这个参数的默认值是 10%的 ES heap 内存大小。indexing_pressure.memory.limit: 8g重启 elasticsearchsystemctl restart elasticsearch结语通过将 ZomboDB 与 Apache Cloudberry 深度集成，用户能够在 MPP 架构下直接使用 Elasticsearch 的全文检索与中文分词能力，实现高性能的结构化与非结构化数据混合查询。这种融合方案不仅扩展了 Cloudberry 的应用边界，也为日志分析、智能检索、文本挖掘等场景提供了开源可行的新路径。未来，随着社区的发展与多语言分词支持的增强，Cloudberry + ZomboDB + Elasticsearch 的组合将成为构建智能数据仓库与搜索分析平台的重要技术基石。</p>]]></description></item><item>    <title><![CDATA[Magnet Axiom 9.8 发布 ]]></title>    <link>https://segmentfault.com/a/1190000047405275</link>    <guid>https://segmentfault.com/a/1190000047405275</guid>    <pubDate>2025-11-17 17:07:46</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>Magnet Axiom 9.8 Windows x64 Multilingual - 数字取证与分析</p><p>Digital Forensic Software</p><p>请访问原文链接：<a href="https://link.segmentfault.com/?enc=VaOzW2ALus7Pi9khJ51Q9Q%3D%3D.3Ybb%2F6RlKUhbFnjtliK8%2FtoZjKSutKJMLcPpdMt%2FWLs47GIFmSvQ88tHlh6Mz%2BBD" rel="nofollow" target="_blank">https://sysin.org/blog/magnet-axiom/</a> 查看最新版。原创作品，转载请保留出处。</p><p>作者主页：<a href="https://link.segmentfault.com/?enc=48pOuBsfBItXzJSVUhd0kA%3D%3D.oyuc6yq24FpSqaYEVYxkN4IS2pTwxpAY9mnSVEiVt9Q%3D" rel="nofollow" target="_blank">sysin.org</a></p><hr/><p>Magnet Axiom</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047322344" alt="形象标识" title="形象标识"/></p><p><strong>在一个案件中恢复并分析所有的证据</strong>。</p><p>在一个案件文件中，同时检查来自移动设备、云端、计算机和车辆来源的数字证据，以及第三方提取数据。使用强大且直观的分析工具，自动快速呈现与案件相关的证据。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047322345" alt="产品图像" title="产品图像" loading="lazy"/></p><p><strong>新工具如何消除干扰寻找证据</strong>？</p><p>涉及调查的数字设备数量正在增长，平均每人约有六台设备*，这使得取证、处理和分析在后勤上变得复杂、耗时且成本高昂。像 Axiom 这样的工具让调查人员能够简化工作流程 (sysin)，从大量数字干扰中快速定位、恢复和收集证据。</p><blockquote>*2022 年 IDC MarketScape</blockquote><h2>Axiom 功能</h2><p>使用 Magnet Axiom，在一个案件文件中恢复、分析并报告来自移动设备、计算机、云端和车辆的数据信息。</p><ul><li>强大的数据提取能力</li><li>移动端工作流</li><li>高级分析工具</li><li>Magnet One 增强支持</li></ul><h3>强大的数据提取能力</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047322346" alt="数据提取界面" title="数据提取界面" loading="lazy"/></p><p>轻松恢复已删除的数据，并以“数据工件优先”的方式在一个案件文件中分析来自移动设备、计算机、云端和车辆的数字证据。发现文件或工件的完整历史，以构建案件并证明意图。Magnet Axiom 为最新设备和数据来源提供最及时的数据工件支持。</p><p><strong>关键要点</strong>：</p><ol><li>在同一案件中获取并分析来自移动设备、云端和计算机的证据。</li><li>处理来自 Google、Facebook 和 Instagram 等提供商的授权数据返回。</li><li>检查来自云端来源（如 Google、WhatsApp 等）的开源和用户账户数据。</li><li>从提取、数据恢复到案件文件构建，一步完成图像处理。</li></ol><h3>移动端工作流</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047322347" alt="移动端工作流" title="移动端工作流" loading="lazy"/></p><p>无论你使用哪种提取工具，Magnet Axiom 都能获取最多的数据，并为 iOS 和 Android 设备提供最佳的分析效果。随着 Magnet Graykey 直接集成到 Axiom 中，加载移动端证据进行深度分析变得更加轻松。</p><p><strong>关键要点</strong>：</p><ol><li>接收并处理移动设备提取内容，直接集成 Magnet Graykey，并支持 Cellebrite、Oxygen、Berla 等第三方工具。</li><li>Axiom 直观的 <code>Mobile View</code> 视图帮助你和相关人员在 Axiom 与 Portable Case 中轻松浏览和交互移动证据。</li><li>利用 Axiom 内强大的数据雕刻功能，发现图片、聊天记录和浏览历史。</li><li>通过 KnowledgeC、Android Motion Photos、iOS Wallet、Samsung myFiles、地理位置数据等工件，揭示详细的主体信息。</li><li>利用移动设备的令牌和钥匙串进行自动解密。</li></ol><h3>高级分析工具</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047322348" alt="Magnet AXIOM 产品界面" title="Magnet AXIOM 产品界面" loading="lazy"/></p><p>通过 Magnet Axiom 的分析工具自动发现更多证据，让你专注于案件相关信息。借助 <code>Magnet Copilot</code>、<code>Media Explorer</code>、<code>Cloud Insights Dashboard</code>、<code>Magnet.AI</code>、<code>Connections</code>、<code>Timeline</code>、<code>Email Explorer</code> 等功能 (sysin)，快速找到所需证据。</p><p><strong>关键要点</strong>：</p><ol><li>使用 <code>Magnet.AI</code> 和 <code>Thorn</code> 等机器学习工具自动检测潜在的非法图片，如儿童虐待、毒品和武器内容。</li><li>使用 <code>Connections</code> 快速了解工件、人物或设备之间的关联。</li><li>借助 <code>Media Explorer</code> 从图像和视频中快速提取智能洞察。</li><li>使用 <code>Timeline</code> 可视化所有证据来源中的事件。</li><li>按日期、时间范围、特定工件或关键词筛选数据，快速找到相关证据。</li><li>通过早期访问 <code>Magnet Copilot</code> 等新 AI 工具，快速识别深度伪造媒体并提取相关证据。</li></ol><h3>借助 Magnet One 提升效率与协作</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047322349" alt="Magnet One" title="Magnet One" loading="lazy"/></p><p>将 Axiom 与其他数字取证解决方案整合，贯穿整个工作流程，实现更快速、更高效的调查。Magnet One 可轻松简化工作流程 (sysin)，并支持取证人员、调查员、检察官、指挥人员和机构领导之间的无缝协作。</p><p><strong>关键要点</strong>：</p><ol><li>轻松提交数字取证实验室请求并创建案件，节省时间与精力。</li><li>通过互联的工作流程减少手动步骤，提高工作效率。</li><li>在每个阶段监控 Axiom 处理任务进度，处理完成后自动通知调查人员。</li><li>与调查团队实时协作，确保所有人都能保持同步。</li></ol><h2>新增功能</h2><p>Magnet AXIOM 版本 9.8.0.46347</p><p>发布日期：2025 年 11 月 12 日</p><p>✅ <strong>新增特色 Artifacts</strong></p><ul><li>Microsoft Teams</li><li>Zangi</li><li>Signal</li><li>Snapchat</li><li>Chrome</li></ul><p>✓ <strong>OpenAI 采集</strong></p><p>AXIOM Process 现在能够从 OpenAI 帐户采集数据，包括 ChatGPT 消息，作为云证据来源。</p><p>✓ <strong>发布后启动 Magnet Griffeye</strong></p><p>在完成发布到 Magnet Griffeye 后，现在可以<strong>直接启动</strong> Magnet Griffeye 案件。</p><p>✅ <strong>新增 Artifacts</strong></p><ul><li>Chrome Cookies、Logins、Credit Cards | 多平台：新增对 v20 Chromium 加密字段的解密能力。</li><li>基于 Chromium 的浏览器 “Top Sites” | 计算机：新增支持基于 Chromium 浏览器的 “Top Sites” 。</li><li>解密数据库文件 | “Refined Results”：新增用于查看解密数据库文件的信息。</li><li>Microsoft Teams 帐户 | iOS：新增支持 Microsoft Teams 帐户。</li><li>Microsoft Teams 日历 | iOS：新增支持 Microsoft Teams 日历。</li><li>Microsoft Teams 消息 | iOS：新增支持 Microsoft Teams 消息。</li><li>Wi-Fi 已发现设备 | iOS：新增支持 Wi-Fi 已发现设备 (sysin)。</li><li>Zangi 通话 | iOS：新增支持 Zangi 通话。</li><li>Zangi 联系人 | iOS：新增支持 Zangi 联系人。</li></ul><p>✅ <strong>更新 Artifacts</strong></p><ul><li>Android Signal | Android：更新以支持 “Decrypted Database Retention（解密数据库保留）”。</li><li>Cloud Google Chrome Browser History | 云端：更新解析以支持新的架构变更。</li><li>Grindr 消息 | Android：更新以支持 Grindr 版本 25.15.0。</li><li>Instagram Direct Messages | iOS：更新支持 Instagram 版本 393.0.0。</li><li>iOS Wi-Fi 配置文件 | iOS：更新以支持已知网络的新时间戳片段 (sysin)。</li><li>图片 | 计算机：更新以将 Thumbcache Pictures 合并进入 Pictures Artifact。</li><li>Samsung Customization Service | Android：更新以支持解密数据库保留。</li><li>Samsung Customization Service、iOS Private Photo Vault、iOS Signal、Android Session、iOS Session、Android Threema、Samsung Positioning | Android, iOS：更新以支持解密数据库保留。</li><li>Signal | iOS：更新支持最新版本的 Signal（v7.82）。</li><li>Snapchat 聊天消息 | Android：更新支持 Snapchat 版本 13。</li><li>Telegram Android 消息 | Android：更新支持最新版本的 Telegram Android 消息。</li><li>WhatsApp | Android：更新本地媒体的解析。</li></ul><p>✅ <strong>云端（Cloud）</strong></p><ul><li>AXIOM Process 现在能够从 OpenAI 帐户采集数据，作为云证据来源。</li><li>在通过代理执行云采集时，如果之前未提供有效凭据，AXIOM Process 现在会提示输入凭据。</li><li>在获取 Instagram Private Direct Messages 时，现在可以选择特定对话。</li></ul><p>✅ <strong>处理（Processing）</strong></p><ul><li>在向 Magnet Griffeye 或创建新的 Magnet One 案例时，AXIOM Process 现在<strong>可选</strong>将 Magnet One 案例号作为可选的案例编号。</li><li>高级 Premier Cyber：在将案件发布至 Magnet Griffeye 完成后，现在可选择启动 Magnet Griffeye。</li></ul><p>✅ <strong>检查（Examining）</strong></p><ul><li>在 AXIOM Examine 中，Magnet Review 的登录信息现在被保留，从而减少了检查机上的登录次数。</li></ul><p>✅ <strong>修复 Bug</strong></p><ul><li>之前，AXIOM Examine 可能无法从案件中移除证据来源。 — EXM-5444</li><li>之前，导出数据中的列名称对非 ANSI 字符可能显示不正确 (sysin)。 — EXM-5250</li><li>之前，从 VICS 导出报告中的 “在 Artifacts Explorer 中显示项” 链接可能无效。 — EXM-5269</li><li>地图视图 World Map View 现在支持带 Geolocation 的自定义 Artifacts。这也解决了自定义 Artifacts 的内容类型过滤器不工作的 问题。 — EXM-5465</li><li>改进了电子邮件附件的处理，以减少记录异常 “An item with the same key has already been added”。 — CARS-1638</li><li>之前，含附件 “.msg” 文件类型的 Microsoft Outlook 电子邮件可能无法恢复。 — CARS-731</li><li>之前，如果 FileInfoList.txt 包含无效字符，AXIOM Process 可能无法处理 Apple Warrant Return。 — CA-3372</li><li>之前，AXIOM Process 只在管理员用户的当前域中搜索 Google Workspace 用户。 — CA-3464</li><li>之前，AXIOM Process 会为未启用 Gmail 范围的帐户显示可获取 Google Workspace Gmail 帐户的选项，导致 “Mail service not enabled” 错误。 — CA-1186</li><li>之前，如果在采集过程中遇到编码文件名，iCloud Photos 可能未被保存。 — CA-3311</li></ul><h2>下载地址</h2><p>想要开始学习和研究？</p><p><strong>Magnet Axiom</strong> 9.8.0.46347 for Windows x64 Multilingual</p><ul><li>请访问：<a href="https://link.segmentfault.com/?enc=QuoerTp8oJa8O6Oamndb4w%3D%3D.FmFxUk92CgS8TdgOEnAC1oKMJk8vsZJzh8zjlFL36rBZ%2BUbW6a1rHfDRuvjrUrz%2F" rel="nofollow" target="_blank">https://sysin.org/blog/magnet-axiom/</a></li></ul><p>更多：<a href="https://link.segmentfault.com/?enc=dopn2NRwwjFjFvhioTWqVw%3D%3D.2Qv5BqHYJ8mYMneFxhzIpy1KEnW9oEO%2BNfCpadteXrk%3D" rel="nofollow" target="_blank">HTTP 协议与安全</a></p>]]></description></item><item>    <title><![CDATA[【2025年11月更新】国内 ChatG]]></title>    <link>https://segmentfault.com/a/1190000047405277</link>    <guid>https://segmentfault.com/a/1190000047405277</guid>    <pubDate>2025-11-17 17:07:04</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>一、ChatGPT镜像网站</h2><p>① <a href="https://link.segmentfault.com/?enc=GOhoN39oUljJmdkjtF87uA%3D%3D.Uf310o%2BONZ6Shbkx1jVtZFkK81qWR8Gu%2BfPwPBAaf6s%3D" rel="nofollow" target="_blank">ChatGPT 中文版</a> 支持 GPT-5、GPT-5.1、4.1 以及 Claude 4.5 sonnet、Gemini 2.5 Pro、Grok 4，支持 4o 绘画、nano banana<br/>② <a href="https://link.segmentfault.com/?enc=uKFLyjH0rvR8W6odpXvcwA%3D%3D.Bynt13YGOLGkLl44LCfcv6RcevRDUjUSmu2zOLq9Vjw%3D" rel="nofollow" target="_blank">ChatGPT 镜像网站</a> 支持通用全模型，支持文件读取、插件、绘画、AI PPT<br/>③ <a href="https://link.segmentfault.com/?enc=%2FhF%2Fz3hyqCfJfynDriSaNQ%3D%3D.kH3l2CzJwnu35Ve%2BsGV%2FDOy5Bezi%2F28G1QUAWjsqjbQ%3D" rel="nofollow" target="_blank">ChatGPT 工具站</a> 收集各种可以用的ChatGPT镜像网站，免费的收费的。</p><h3>1. 什么是ChatGPT镜像网站</h3><p><strong>ChatGPT镜像网站</strong>（ChatGPT Mirror Site）是指通过复制原始网站内容和结构，创建的备用网站。其主要目的是在原始网站无法访问时，提供相同或类似的服务和信息。</p><h3>2. ChatGPT 镜像站的用途</h3><ul><li><strong>绕过访问限制</strong> ：在某些地区，访问 OpenAI 官方网站可能受到限制或阻塞，镜像站可以帮助用户绕过这些限制，继续使用 ChatGPT 服务。</li><li><strong>负载均衡</strong> ：在高流量时期，镜像站可以分担部分用户请求，减轻官方服务器的负担，确保服务的稳定性。</li><li><strong>备份与冗余</strong> ：如果官方服务遇到故障或维护，镜像站可以作为备用，保证用户依然能够访问聊天机器人。</li></ul><h4>镜像网站的优势</h4><ul><li><strong>稳定访问</strong> ：在网络限制或高峰期，提供更可靠的访问体验。</li><li><strong>快速响应</strong> ：减少访问延迟，提升用户互动流畅度。</li><li><strong>本地化服务</strong> ：优化中文支持，满足国内用户的语言需求。</li></ul><h2>二、模型知识</h2><h3>1、模型基础信息</h3><p><strong>GPT-3.5 Turbo</strong>：官方已经计划下线，现在已经全面被gpt-4o-mini替代。</p><p><strong>o1/o1-mini</strong>：最新的版本模型， o1 不是 GPT 的下一代模型！o1 和 GPT-4o在不同领域各有所长。o1 擅长 STEM领域和需要大量思考的问题，并不擅长需要常识知识的知识。OpenAI 计划在之后分别研发 GPT 和 o1 系列模型。</p><p><strong>GPT-4o/4o-mini</strong>：性价比最高模型，支持视觉等多模态，OpenAI 文档中已经更新了 GPT-4o 的介绍：128k 上下文，训练截止 2023 年 10 月（作为对比，GPT-4-Turbo 截止 2023 年 12 月）。</p><p><strong>GPT-4 Turbo</strong>：支持视觉等多模态，128k 上下文，训练截止 2023 年 12 月。</p><h3>2、功能对比（对比热门的4o和o1）</h3><p><strong>最大区别</strong>：ChatGPT 4o支持多模态，OpenAI o1目前只支持文本内容。</p><p><strong>能力上</strong>：OpenAI o1在推理能力上全面领先ChatGPT 4o。</p><p><strong>使用限制</strong>：目前ChatGPT 4o官方Plus用户没有使用限制了，o1-mini 的限额从每周 50 条增加到每天 50 条，而 o1-preview 的限额从每周 30 条提高到每周 50 条。</p><p>就我自身的使用体验来说，我更喜欢使用4o。4o整体使用更流畅，o1响应太慢。</p><p><img width="723" height="826" referrerpolicy="no-referrer" src="/img/bVdgMXJ" alt="" title=""/></p><h3>3、模型选择</h3><p>目前来说，最聪明的版本肯定是o1，但是最好用的的版本我觉得是GPT-4o。GPT-4o在综合能力方面表现更为出色，支持多模态，响应速度和价格都更有优势。</p><h4>GPT-4o 的优势</h4><pre><code>响应速度快：GPT-4o在处理任务时的响应速度更快，能够更高效地完成复杂任务。
高性价比：比GPT-4 Turbo便宜一半。
多模态支持：GPT-4o支持视觉等多模态输入，这使得它在处理图像、文本等混合任务时表现尤为出色。
128k上下文：相比其他模型，GPT-4o拥有更大的上下文窗口，可以处理更长的文本和更复杂的任务。
</code></pre><h4>OpenAI o1 的优势</h4><pre><code>超强的逻辑能力：o1 模型采用了全新的“思维链”（CoT，Chain-of-Thought）推理机制，类似于人类在回答问题前需要深入思考的过程。该模型会在作出最终回答之前，构建一条详细的内部推理链，通过强化学习不断优化其思考过程。模型能够自我纠正错误，尝试不同的策略，并将复杂的步骤分解为更简单的部分，从而大幅提高其推理能力。
</code></pre><h2>三、国内大模型能替代？</h2><p>现在好用的大模型，不仅仅ChatGPT（GPT-5、GPT-4o、4o mini）、Claude 模型</p><p>还有百度、智谱、阿里等的大模型。</p><p>尤其DeepSeek能力已经接近OpenAI等主流大模型。目前DeepSeek最新模型评分已经可以追上GPT-4。</p><p>而且还巨便宜，大家感兴趣的真的可以抄底~~</p>]]></description></item><item>    <title><![CDATA[aPaaS更新速览：业务事件操作更精准，]]></title>    <link>https://segmentfault.com/a/1190000047405281</link>    <guid>https://segmentfault.com/a/1190000047405281</guid>    <pubDate>2025-11-17 17:06:15</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>大家好，新一期得帆云aPaaS更新如期而至！本次aPaaS在业务事件等方面有不少提升，一起看看吧！<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047405283" alt="图片" title="图片"/></p><p>业务事件提示优先级优化&amp;允许关闭提示</p><p>本次更新后，业务事件「事件终止」的节点异常支持自定义展示相关提示和提示的内容。其中查询节点、弹窗节点、调用节点可自定义新增异常提示内容。查询节点、循环节点、引用节点、弹窗节点、调用节点、校验节点、外部节点可自定义新增是否展示异常提示。<br/>以下以查询节点为例，介绍功能使用：查询节点查询结果为空时选择「事件终止」，则下方出现关闭默认终止提醒、查询结果为空时提醒的功能设置。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047405284" alt="图片" title="图片" loading="lazy"/><br/>将关闭默认终止提醒右侧的开关开启，则应用前台后续业务事件执行时，查询节点查询结果为空时事件终止，且不会弹出“业务事件已终止”的默认提示；<br/>将查询结果为空时提醒右侧的开关开启，则下放出现自定义提醒内容的区域，在此区域内可输入个性化的提醒内容。<br/>输入完成后，后续应用前台业务事件执行时，查询节点结果为空时仅会弹出自定义的提醒内容；<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047405285" alt="图片" title="图片" loading="lazy"/></p><p>审批按钮支持触发操作成功后的业务事件<br/>本次更新后，列表操作栏的审批按钮将支持触发操作成功后类型的业务事件，涉及的审批按钮包括同意、拒绝、撤回、转交、驳回。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047386680" alt="图片" title="图片" loading="lazy"/><br/>人员、角色、部门、表单、流程API接口补齐本次更新新增了以下功能的API接口：<br/>人员人员信息查询：查询具体人员的基础信息；人员上/下级查询：查询指定人员的级联上级领导和直属下级员工；人员的所有上级部门：查询指定人员的部门及级联上级部门；部门部门信息查询：查询具体部门的基础信息；部门上/下级查询：查询指定部门的级联上级部门和直属下级部门；部门及其下级部门人员：查询指定部门的直属员工和包括下级部门员工的全部；角色查询用户的角色列表：查询指定用户所属的全部角色；查询指定角色的指定参数的用户：可根据角色编码和参数条件查询符合条件的人员；数据字典批量新增字典批量添加字典项查询字典信息查询字典项信息表单附件下载流程管理员操作跳转批量转交批量终止重试已处理删除未生效的流程授权修改流程授权数据删除未生效的流程转办修改流程转办数据审批人/知会对象操作征询回复前加签批量同意批量拒绝知会分发发起人终止流程信息查询流程图根据条件查询租户流程实：查询条件新增流程标题、流程实例ID、创建时间、业务字段、审批节点、备注</p><p>平台与租户中账号管理增加状态筛选<br/>本次更新，平台管理和后台管理的「账号管理」和「人员管理」页面，可以按照员工类型、状态和在职状态对员工数据进行筛选，筛选方式更加灵活。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047405286" alt="图片" title="图片" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405287" alt="图片" title="图片" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[Apache Cloudberry 内核]]></title>    <link>https://segmentfault.com/a/1190000047405302</link>    <guid>https://segmentfault.com/a/1190000047405302</guid>    <pubDate>2025-11-17 17:05:39</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>Apache Cloudberry™ (Incubating) 是 Apache 软件基金会孵化项目，由 Greenplum 和 PostgreSQL 衍生而来，作为领先的开源 MPP 数据库，可用于建设企业级数据仓库，并适用于大规模分析和 AI/ML 工作负载。</p><p>GitHub: <a href="https://link.segmentfault.com/?enc=H41186ZIJTvHasPMtRa95Q%3D%3D.8EW5WkTatCzoKSh4T%2F%2FgAQ%2BVcRdlDfEOTrC6dzUIFZhgNvpwpWSmB5VZNXLUqRhL" rel="nofollow" target="_blank">https://github.com/apache/cloudberry</a><br/>文章作者：张玥，酷克数据研发工程师；整理：酷克数据</p><p>在优化分布式数据库查询性能时，有一个长期被开发者忽视却真实存在的成本：在 Join 前没有及时过滤无效数据，导致 CPU、内存和网络被浪费在处理这些永远不可能匹配的行上。</p><p>在 Apache Cloudberry 的用户社区中，我们经常遇到这样的提问：“同样的数据量，为什么这个 Join 查询在我们的集群上跑得并不快？” 当我们排查执行计划时，往往会发现问题的根源在于 Join 的 probe 端（大表侧）始终在无差别扫描所有行，即使这些行根本不可能匹配到小表上的 Join Key。</p><p>这是很多数据库系统都曾经历的 “成长烦恼”，也是为什么我们在 Cloudberry 中坚定地实现并落地 Runtime Filter（动态过滤器）。</p><p>为什么传统 Hash Join 在大表上会成为性能瓶颈？</p><p>传统 Hash Join 的执行流程非常简单直接：先在小表上构建哈希表，然后扫描大表，对每一行都做一次哈希匹配。对用户来说，这种实现是 “透明” 的，因为它在任何场景下都能正确返回结果，但问题在于，当大表体量非常大时，这种 “扫描一切再判断” 的策略就成了资源黑洞。</p><p>具体来说：</p><p>CPU 被无效使用。 大表扫描过程中，每一行都要经过哈希探测，即便它们不可能匹配，也在消耗 CPU。<br/>内存负载高。 无效行被加载、缓存、参与后续算子处理，挤占了真正有效数据的内存空间。<br/>网络带宽浪费。 在分布式执行时，大表中这些无效行可能被传输到其他节点参与分布式 Join，白白浪费带宽。<br/>如果 Join 能在真正开始之前就知道哪些行必然不会命中，那么这些 CPU、内存和网络资源完全可以节省下来，用于处理真正有价值的数据。</p><p>这就是 Runtime Filter 存在的意义。</p><p>所谓 Runtime Filter，本质上是 在查询执行时根据小表 Join Key 动态生成的过滤器，将其 “提前” 下推到大表扫描节点，对大表行做快速预过滤，让那些不可能匹配的行直接在扫描时就被丢弃。</p><p>它并不复杂：</p><p>在小表构建哈希表时，同时根据 Join Key 创建 Bloom Filter（或 Range Filter）。<br/>将这个过滤器下推到大表扫描（SeqScan）阶段。<br/>在大表扫描时，Join Key 会先经过过滤器检查，如果不可能命中，直接丢弃。<br/>结果是，大表参与 Join 的行数锐减，执行时间随之下降，用户感觉就是：“查询快了不少。”</p><p>值得一提的是，Runtime Filter 并不是 Cloudberry 独有的优化，Spark SQL、Trino（Presto）、Apache Doris 等主流系统都早已在生产环境使用这一技术。</p><p>在 TPC-H、TPC-DS 等标准测试中，Runtime Filter 可以帮助部分 Join-heavy 的查询实现 2-10 倍的加速，且这些加速并不依赖于复杂调优参数，而是来源于最朴素的道理：“能不处理的行就不要处理。”</p><p>Cloudberry 是如何实现 Runtime Filter 的？</p><p>在实现 Runtime Filter 的过程中，我们遵循了 Cloudberry 的整体理念：简洁、高效、易扩展。</p><p>首先，我们使用 Bloom Filter 作为主要过滤器类型。原因很简单：Bloom Filter 是一种概率型过滤器，占用空间极小（通常几个 MB），通过多个哈希函数判断某个值是否可能存在，即便存在假阳性（放行无效行），也不会出现假阴性（误过滤正确行），这保证了最终结果的一致性。</p><p>其次，对于数值型 Join Key（如时间戳、整型 ID 等），我们也支持 Range Filter。它只记录 Join Key 的最小值和最大值，用于直接排除范围外的数据，更加简单高效。</p><p>我们在实现层面选择了 LOCAL 模式（进程内下推）：</p><p>Bloom Filter 和 Range Filter 的构建与下推都在同一进程内完成，无需跨进程或跨节点通信。<br/>下推到大表 SeqScan 节点后，过滤器直接作用于扫描过程，几乎没有额外延迟。<br/>这种模式实现简单，效果立竿见影，避免了引入不必要的分布式复杂性，同时带来显著的执行性能提升。</p><p>实际效果怎么样？</p><p>在 Cloudberry 的性能基准测试中，我们使用了 TPC-DS 10GB 和 100GB 数据集进行了对比：</p><p>在 10GB 测试集上，开启 Runtime Filter 后，查询总耗时从 939 秒降低到 779 秒，缩短了约 17%。<br/>在 100GB 测试集上，从 5270 秒降低到 4365 秒，提升同样在 17% 左右。<br/>需要注意的是，这种性能提升并非源于魔法，而是因为 Runtime Filter 在 Join 前就过滤掉了大量无用数据，使得 Join 的输入更 “干净”，从而减少了计算、内存和网络负担。</p><p>在实际用户环境中，这种加速效果往往更明显，特别是在 Join Key 基数较小、过滤效果明显的场景中，Runtime Filter 能让长时间跑不完的分析报表大幅缩短执行时间。</p><p>Runtime Filter 实现</p><p>在执行 Hash Join 构建哈希表时，Cloudberry 会在内部同步生成 Bloom Filter 或 Range Filter：</p><p>Bloom Filter 通过哈希函数将小表的 Join Key 值映射到位数组，实现快速的概率过滤。内存消耗极小（通常仅需几 MB），但可能存在假阳性。<br/>Range Filter 则记录 Join Key 的最小值和最大值，对于数值范围连续的数据（如时间戳、整型 ID）过滤效果更好。<br/>这些过滤器在小表扫描时被无感知地构建，完全不需要额外扫描，也不需要二次计算，真正做到 “顺手” 完成。</p><p>下推至大表扫描节点</p><p>过滤器构建完成后，最关键的步骤是将它下推到大表的 SeqScan 节点，让过滤器在扫描时生效。</p><p>在 Cloudberry 中，Join 构建和大表扫描通常位于同一执行进程内，因此过滤器可以以内存指针的方式直接传递给大表扫描节点，避免了序列化和网络通信的额外成本。</p><p>在大表执行扫描时，每当拉取下一行数据时，系统会先将该行数据的 Join Key 列送入过滤器检查：</p><p>如果不在 Range Filter 范围内，直接丢弃。<br/>如果 Bloom Filter 判断 “不存在”，直接丢弃。<br/>只有通过过滤的行，才会继续进入 Hash Join 参与探测。<br/>这种在扫描时 “预过滤” 的模式，与 Cloudberry 的执行流水线完美适配，不会破坏流水线调度，也不会引入额外锁和同步延迟。</p><p>LOCAL 模式下推</p><p>业界的一些引擎会选择在跨节点环境中通过 GLOBAL 模式下推过滤器，将过滤器同步到所有数据节点，实现更大范围的预过滤。</p><p>在 Cloudberry 的第一阶段，我们刻意选择了 LOCAL 模式（进程内下推）：</p><p>因为大部分 Broadcast Join 的场景，过滤器在进程内就足够高效；<br/>避免了跨节点网络传输和序列化带来的延迟；<br/>让过滤器的构建和应用零延迟生效，让收益最大化且稳定。<br/>这种实现方式使 Runtime Filter 成为了 Cloudberry 查询链路中 “真正无感知但持续生效” 的能力。</p><p>在执行计划中可观测，让加速 “看得见”</p><p>Runtime Filter 不仅仅是默默执行的幕后加速器，它在执行计划中是可被用户清晰感知的。当用户执行 EXPLAIN ANALYZE 时，可以看到类似如下输出：</p><p>Rows Removed by Pushdown Runtime Filter: 4,328,191<br/>意味着有 430 万行在扫描时就被 Runtime Filter 丢弃了，不再进入 Hash Join 的计算管道。</p><p>这种 “可见可观测” 的设计对 DBA、性能调优工程师非常友好：</p><p>便于判断 Runtime Filter 是否生效；<br/>能验证过滤效果是否达到预期；<br/>为后续优化 SQL 提供直观依据。<br/>代码中的 “真实细节”</p><p>在 Cloudberry 的执行器中，Runtime Filter 并非独立流程，而是通过核心结构 AttrFilter 与 Hash Join 和 SeqScan 深度集成。</p><p>AttrFilter 在执行时记录：</p><p>Join 键范围（min/max）用于 Range Filter；<br/>Bloom Filter 实例用于概率过滤；<br/>Join 键位置映射（rattno/lattno）确保列正确匹配；<br/>关联到目标 SeqScan 节点的 PlanState 指针，用于精确下推。<br/>构建过程完全与 Hash Join 的 MultiExecPrivateHash 流程同步：</p><p>在小表哈希表构建时调用 AddTupleValuesIntoRF 将值写入 Bloom Filter 或更新范围；<br/>构建完成后调用 PushdownRuntimeFilter 下推过滤器到目标扫描节点；<br/>在查询结束时自动调用 FreeRuntimeFilter 回收内存，保证系统稳定性和内存安全。<br/>这种嵌入式实现方式，使 Runtime Filter 成为了 Cloudberry 查询执行过程中 “天然存在” 的优化能力。</p><p>结语</p><p>在 Cloudberry，我们希望大部分优化能力都能做到 “对用户无感，对系统有益”，Runtime Filter 正是这样一种能力。</p><p>它不需要用户额外学习参数，不需要写复杂 SQL Hint，也不需要在执行前进行特别配置，但只要你的查询包含 Join，它就会自动工作，为你节省时间与资源。</p><p>Runtime Filter 的使命非常纯粹： 在 Join 前，让不可能命中的行在最便宜的阶段被提前过滤掉，让资源只用于真正有价值的计算。</p><p>未来，我们将继续扩展 Runtime Filter：</p><p>在合适的场景中引入 GLOBAL 模式支持，跨节点做全局预过滤；<br/>支持 IndexScan / BitmapScan 下推；<br/>提供更加智能的过滤器精度控制；<br/>实现与自适应并行度、管道执行更深度融合。<br/>但无论演化到何种程度，这项能力的本质始终不变： 用最简单的方法，让 Cloudberry 更快、更稳、更省。</p><p>如果你想了解更多 Cloudberry 在执行链路中的底层优化实践，欢迎继续关注，我们会持续发布更多底层设计与优化实战分享。</p>]]></description></item><item>    <title><![CDATA[低代码高频实践场景系列之二——模具管理 ]]></title>    <link>https://segmentfault.com/a/1190000047405306</link>    <guid>https://segmentfault.com/a/1190000047405306</guid>    <pubDate>2025-11-17 17:04:55</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>本文作者：得帆信息联合创始人兼CTO徐翔轩</p><h2>模具管理的复杂性，常被低估</h2><p>在制造业的庞大体系中，模具或许不是最耀眼的资产，却是贯穿生产链条的核心要素。一套模具的质量、寿命、利用率，直接影响产品一致性、产能稳定性与生产成本。然而，模具管理恰恰是多数企业的“隐性痛点”。模具数量庞大、分布广泛，且状态变化频繁——从启用、维修、借调直至封存，管理链条冗长，涉及部门众多，关键数据却分散在Excel表格、纸质记录甚至个人手中，难以形成统一有效的管理视图。<br/>随着企业生产规模扩大、工厂多地布局，这种碎片化、分散化的管理模式带来的弊端日益凸显：信息壁垒导致透明度缺失，问题出现时责任追溯困难重重，维修计划难以精准及时，资产利用率状况模糊不清。在此背景下，模具管理系统逐渐转变为制造企业数字化建设的“刚需模块”，成为提升管理效能、优化资源配置的关键突破口。</p><h2>为什么传统模具管理系统“难落地”</h2><p>不少企业尝试过采购标准化的模具管理软件，但实际落地效果差强人意。究其核心，主要存在三大痛点：01 业务差异太大<br/>不同企业的模具类型千差万别，管理逻辑、审批机制更是各不相同。标准化软件往往难以完全契合实际流程，导致系统功能与实际需求脱节，员工使用意愿低下。<br/>02 变更频繁、维护困难<br/>新产品导入、工艺调整、设备更换，都会牵动模具台账和流程更新。传统模具管理系统改动依赖厂商开发，周期长、费用高，企业陷入“改不起、等不起”的困境。<br/>03 缺乏与其他系统的衔接<br/>模具不仅仅属于设备管理体系，还贯穿生产、采购、库存、财务、质检等核心环节。模具管理系统一旦“孤立运行”，信息链条就断了，核心业务受到重大影响。<br/>因此，企业在不断思考：有没有一种解决方案，既能深度契合现场管理逻辑，又能以低成本、高灵活的方式持续迭代？</p><h2>低代码带来的结构性改变</h2><p>低代码并非取代传统软件，而是一种更灵活、更可持续的建设方式，能让模具管理系统的建设逻辑发生明显转变。<br/>01 流程适配：让系统真正“长”在现场<br/>模具台账、点检计划、维修记录、报废审批……这些模块均可通过低代码平台由企业自主快速搭建。业务部门能参与流程配置与字段调整，确保系统设计贴合实际生产场景，让系统真正“长在现场”。<br/>02 持续优化：敏捷响应管理变化‌<br/>模具管理具有变化频繁的特点，低代码平台支持“边用边调”：比如新增一类模具、调整审批路径、修改维保周期，企业均可当天完成系统调整，彻底摆脱对IT长周期开发的依赖。<br/>03 数据闭环：实现全生命周期管理‌<br/>通过低代码平台，模具系统可以与ERP、MES、PLM等核心系统无缝对接，从模具采购入库，到生产使用、维修、报废，实现全生命周期管理。所有状态、操作记录自动记录，资产利用率、维修周期、成本分摊等数据可实时可视化。<br/>04 协同共建：业务与IT的双轨机制‌<br/>模具管理系建设往往由设备管理部门主导，IT团队配合。低代码平台与无代码技术相结合的架构，让业务方能快速搭建与试运行，IT团队则专注于复杂逻辑实现与接口治理，形成灵活而稳健的双轨机制。</p><h2>为什么模具管理是低代码落地的“最佳练兵场”</h2><p>在制造业的众多场景中，模具管理堪称“投入小、收益快、复制强”的黄金实践领域。其独特价值体现在三重特性：<br/>模具管理的逻辑足够复杂，能验证平台的可扩展性；<br/>模具管理边界清晰，相对独立，适合快速上线与验证；<br/>模具管理数据敏感度低，适合企业自主建设与推广。<br/>因此，很多企业选择从模具管理系统入手，验证低代码平台的可用性与团队的实操能力。当系统运行顺畅后，其经验会自然扩展到相邻领域，如设备管理、工装夹具、备品备件、工单排程等。低代码的价值，也正是在“从点到面”的演进中充分显现。</p><p>结语<br/>模具管理的数字化，本质是企业运营透明度与治理能力的体现。传统软件强调“功能覆盖”，而低代码更强调“能力延伸”——让企业能以更灵活的方式，构建属于自己的数字化体系。对制造业CIO和数字化负责人而言，模具管理是观察低代码平台是落地实效的“窗口”：低代码能否快速响应变化？能否支撑多厂区协同？能否随业务需求持续演进？在越来越多制造企业的实践中，答案已经逐渐清晰——低代码，不仅是将模具管理从隐性痛点转化为企业数字化能力的基石，它更是制造企业迈向透明化、敏捷化治理的重要起点。</p>]]></description></item><item>    <title><![CDATA[“看得见”的工厂—MES数据采集技术全景]]></title>    <link>https://segmentfault.com/a/1190000047405310</link>    <guid>https://segmentfault.com/a/1190000047405310</guid>    <pubDate>2025-11-17 17:04:01</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>MES系统通过多种数据采集和对接方式，实现对设备数据的全面采集和管理，为企业的生产管理和决策提供有力支持。<br/>AI智能化MES、免费MES、AI Agent、智能化MES、装配行业MES、组装行业MES、万界星空科技MES系统中的设备管理功能涵盖了设备信息管理、状态监控、维护管理、绩效管理和工装资源管理等多个方面，确保了设备的良好运行和高效利用。<br/><img width="723" height="371" referrerpolicy="no-referrer" src="/img/bVdmT47" alt="" title=""/><br/><strong>一、 MES数据采集的重要性：</strong><br/>1、数据采集的核心目标：<br/>实时化： 获取产线、设备、人员、物料的最新状态，实现透明化生产。<br/>自动化： 替代传统人工录入，避免延迟、错误，提高效率。<br/>精细化： 收集粒度的数据（如秒级设备状态、单个工件加工参数），为深度分析提供基础。<br/><strong>二、 MES数据采集的主要技术分类与详解</strong></p><ol><li>基于设备与自动化的数据采集<br/>（1）PLC采集<br/>原理： 通过工业通信协议（如OPC UA、Modbus TCP/IP、Profinet、EtherNet/IP等）直接与设备控制器（PLC）进行通信，读取其内存寄存器中的数据。<br/>数据内容： 设备启停状态、报警信息、产量计数、工艺参数（如温度、压力、速度）。<br/>优点： 数据实时性高、精度高、无需人工干预。<br/>挑战： 需要设备开放通信接口，协议不统一可能导致集成复杂度高。<br/>（2）CNC/DNC系统集成<br/>原理： 通过DNC（分布式数控）网络或直接接口（如以太网）与数控机床通信。<br/>数据内容： 程序号、加工状态（运行、暂停、报警）、坐标信息、主轴转速、进给率、报警代码等。<br/>优点： 能获取到最核心的加工过程数据。<br/>（3）传感器与IO模块<br/>原理： 对于非智能的“哑设备”，通过加装传感器（如光电传感器、接近开关、电流传感器、振动传感器）和IO采集模块，将物理信号（通断、电流、振动）转换为数字信号。<br/>数据内容： 设备运行/空闲状态（通过检测振动或电流）、产量计数（通过光电传感器）、门开关状态等。<br/>优点： 实现对老旧设备的智能化改造，成本相对较低。<br/>挑战： 需要硬件改造和安装，部署工作量较大。</li><li>基于标识与识别的数据采集<br/>（1）条码技术<br/>原理： 使用一维码或二维码标识对象，通过手持式或固定式条码扫描器进行识别。<br/>应用场景： 工单开工/完工汇报、物料收发、仓库管理、质量检验。<br/>优点： 技术成熟、成本低廉、部署简单。<br/>挑战： 需要视线范围内扫描，易受油污损坏，信息容量有限。<br/>（2）RFID技术<br/>原理： 通过射频信号自动识别附着在物体上的电子标签，无需光学视线。<br/>优点： 非接触、可读写、多标签批量读取、抗污染能力强。<br/>挑战： 成本高于条码，金属和液体环境对信号有干扰。<br/>（3）其他识别技术<br/>DPM（直接部件标示）： 将二维码或Data Matrix码直接雕刻或激光打标在零件表面，耐高温、耐腐蚀，适用于全生命周期追溯。<br/>OCR（光学字符识别）： 通过工业相机识别零件本身的字符编号，适用于特定行业（如半导体）。</li><li>基于人机交互的数据采集<br/>（1）工位终端/触摸屏<br/>原理： 在产线关键工位部署计算机或工业触摸屏，工人通过MES客户端界面进行操作和汇报。<br/>数据内容： 开工/完工确认、质量检验结果（良品/不良品数量及缺陷代码）、物料消耗、设备点检、异常情况上报。<br/>优点： 交互友好，可采集结构化、标准化的数据。<br/>挑战： 增加操作员负担，依赖人员的及时性和准确性。<br/>（2）移动终端（PDA/手机/平板）<br/>原理： 操作员手持移动设备，通过扫描或手动输入进行数据采集。特别适用于仓库管理、现场巡检、设备维护等移动场景。<br/>优点： 灵活性高，覆盖范围广。<br/>挑战： 设备管理、电池续航、网络覆盖问题。</li></ol><p><strong>三、 数据采集的技术架构与关键组件</strong></p><ol><li>设备层： 各类生产设备、传感器、识别装置。</li><li>采集层：<br/>协议网关： 负责协议转换，将不同设备的不同协议统一转换为标准协议（如OPC UA, MQTT）。<br/>SCADA系统： 在部分场景下，SCADA作为车间级数据监控系统，可以成为MES的数据提供者。<br/>边缘网关： 具备边缘计算能力，可在数据源头进行初步过滤、清洗、计算，再上传至MES，减轻服务器压力。</li><li>传输层： 工业以太网、Wi-Fi、5G等网络，负责数据的可靠传输。</li><li>平台层： MES系统数据库，接收、存储和处理所有采集到的数据。<br/>关键通信技术：<br/>OPC UA： 已成为工业互联的事实标准，提供统一的信息模型和安全通信机制，尤其适用于从PLC/CNC采集数据。<br/>MQTT： 一种轻量级的发布/订阅消息传输协议，非常适合在带宽不稳定或资源受限的物联网（IoT）环境中使用，是未来工业物联网数据采集的重要方向。</li></ol><p>MES数据采集技术是数字化工厂的基石。成功的实施并非简单地堆砌技术，而是需要根据具体的业务需求、设备现状和投资预算，进行科学的规划，选择最适合的方案。一个优秀的数据采集系统，应该像人体的神经系统一样，既灵敏又可靠，为MES大脑和上层决策提供源源不断的高质量“养分”，最终驱动制造过程持续优化和智能化升级。</p>]]></description></item><item>    <title><![CDATA[【开源之夏学生访谈】我在 IvorySQ]]></title>    <link>https://segmentfault.com/a/1190000047405342</link>    <guid>https://segmentfault.com/a/1190000047405342</guid>    <pubDate>2025-11-17 17:03:01</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <blockquote>本期的主角，是来自河北经贸大学的计算机技术硕士——崇鹏豪。</blockquote><p>白天写论文，晚上啃源码。</p><p>一边修 bug，一边修行。</p><p>自称“课题搬砖工 + 开源摸鱼人”，却在“摸鱼”中摸出了真功夫。</p><h2>🧑‍💻 自我介绍：白天科研，晚上修仙</h2><p>“大家好，我是崇鹏豪。</p><p>白天我对着论文皱眉，代码改八百遍还在调试。</p><p>晚上就化身开源野生选手，一头扎进代码堆里找存在感。”</p><p>周末常常骑车绕着二环“思考人生”——表面是在冥想，其实心里盘算着：“下次怎么少写点 bug。”</p><p>“如果你觉得我的代码还有救，或者想交流踩坑经验，随时欢迎来信：</p><p><a href="mailto:cph13000@gmail.com" target="_blank">cph13000@gmail.com</a>。”</p><p>认真、自嘲又带着点理工科式的幽默，这大概正是开源社区里最可爱的那种气质。</p><h2>🚀 与开源结缘：从一条 B 站视频开始</h2><p>故事的起点并不宏大。</p><p>某天刷 B 站时，开源之夏的宣传视频闯进了他的视野，画面里开发者们讨论项目、提 PR、审代码，一派“高手过招”的氛围。</p><p>那一刻，他一个念头闪过：</p><p>“与其在课本里啃理论，不如亲自下场练手。反正调 bug 我也有经验。”</p><p>于是他开始研究活动机制，从导师指导到申报流程都仔细看了一遍，越看越心动——“对学生太友好了，这谁顶得住？”</p><p>就这样，他正式踏上了开源实践的旅程。</p><h2>🐘 相中 IvorySQL：一次“技术盲区”的挑战</h2><p>选项目时，目标很明确——IvorySQL。</p><p>这是一个基于 PostgreSQL 内核、主打 Oracle 兼容特性的开源数据库。</p><p>此前他的开发经历主要集中在前端领域，写过 JS 和 Vue，跟着文档改改逻辑、调整界面；而这次选择数据库内核开发，跨度堪比“从装修到造房子”。</p><p>数据库开发是完全陌生的领域。</p><p>“前端处理的是用户能看到的交互，而数据库掌管的是系统的‘五脏六腑’。能在这里动手术，既陌生又兴奋。”</p><p>带着好奇与一点点“挑战新 boss”的热情，他正式加入了 IvorySQL 项目。</p><h2>🧩 项目实践：在数据库里“造函数”</h2><p>项目名称是《为 IvorySQL 开发基于 uuid-ossp 的 sys_guid 函数》。</p><p>目标很清晰，让 IvorySQL 拥有与 Oracle 同样的 <code>sys_guid()</code> 功能，用于生成唯一标识符。</p><p>IvorySQL 虽然基于 PostgreSQL，但尚未内置该函数，需要在 <code>uuid-ossp</code> 插件中进行扩展。</p><p>“配方”如下：</p><ol><li>优先调用 <code>uuid_make()</code>；</li><li>若无该插件，则尝试 <code>uuid_generate_random()</code>；</li><li>若仍不可用，则回退到 <code>arc4random()</code>；</li><li>同时优化自动加载机制，使函数可直接调用。</li></ol><p>一句话总结：</p><p>“哪怕没有插件，也要让数据库自己造出一个唯一标识。”</p><h2>⚙️ 开发日常：白天论文，夜晚内核</h2><p>时间分配是一门艺术。</p><p>崇鹏豪采用“错峰操作”的策略——白天上课、研究课题，夜晚与周末专注项目开发。</p><p>每个夜晚，都在与数据库内核“深度对话”。</p><p>但过程自然不可能一帆风顺。</p><p>两个典型的“坑”让人印象深刻：</p><ul><li>类型问题：初版返回值为 text 类型，而 Oracle 要求字节数组，导致输出混乱。</li><li>权限问题：函数最初注册在 public 模式，忽略了 pg_catalog 的系统权限限制。</li></ul><p>在导师牛老师的指导下，他的问题逐步解决，不仅指出症结所在，还讲清背后的原理，让修复过程成为一次系统性学习。</p><p>“那一刻才真正体会到，导师的三句话能比十个小时的查文档更高效。”</p><h2>🌱 收获与成长：从“使用者”到“参与者”</h2><p>这次实践，不只是技术上的跨越，更是对“协作与规范”的再认识。</p><p>开源开发要求每一次提交都有据可查、每一行修改都有逻辑依据。</p><p>从阅读文档到提交代码，从问题讨论到合并请求，他逐渐熟悉了社区的协作节奏。</p><p>“以前写代码是自己和自己较劲；现在要按社区标准来写、按规范提交。光学 <code>commit message</code>，就像在修炼内功。”</p><p>最大的改变，不在技术，而在心态——从开源软件的“使用者”，成长为生态的“参与者”。</p><h2>🔭 展望未来：在开源的路上继续前行</h2><p>未来的方向已然明确。</p><p>他将继续关注 IvorySQL 社区的 issue，积极参与讨论与修复。</p><p>在崇鹏豪看来，开源的魅力在于思想碰撞。不同背景的开发者在交流中不断磨合，最终凝结为更高质量的代码。</p><p>“只要有参与的热情，每个人都能成为开源生态的一份子。”</p><h2>👨‍🏫 导师寄语</h2><p>“崇鹏豪同学在本次开源之夏的活动中所表现出来的扎实的编程功底让我印象深刻，对技术的未知领域充满好奇心并进行了深入探索，这是未来取得更大成功所不可缺少的，希望崇鹏豪以此次活动为契机，在开源技术领域进行做出更多的贡献，在自己的成长之路上留下坚实的脚印。”</p><p>—— 牛世继</p><h2>🐣 结语</h2><p>从“课题搬砖”到“数据库修炼”</p><p>从写论文到写内核函数</p><p>崇鹏豪用一段 <code>sys_guid()</code> 的开发旅程，完成了从理论学习到实践创新的蜕变。</p><p>开源不是天才的专属，</p><p>而是一群充满好奇与坚持的人，</p><p>在不断探索与打磨中，让世界的代码运行得更好。</p>]]></description></item><item>    <title><![CDATA[越南国际网络专线怎么开通？一年多少钱？ ]]></title>    <link>https://segmentfault.com/a/1190000047405346</link>    <guid>https://segmentfault.com/a/1190000047405346</guid>    <pubDate>2025-11-17 17:02:11</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>越南目前作为东南亚重要经济发展的地区，正吸引着越来越多的跨境电商、外贸企业、以及Tik Tok创作者拓展市场。所以，这需要一款稳定的网络来连接业务需求，而对于直播卡顿、视频会议延迟，还是电商平台登录异常，都在提醒大家：选择一条稳定、高速、安全的越南国际网络专线已经成为企业出海越南的“必备工具”。那么越南国际网络专线怎么开通？一年多少钱？具体如下：</p><p>一、越南市场潜力与国际网络专线需求</p><p>越南拥有超过1亿的人口，其中互联网用户比例持续增长，数字经济呈现爆发式增长。尤其是跨境电商、短视频直播和跨国企业协同办公等领域，对网络连接提出了更高要求。</p><p>普通网络与国际网络专线的核心差异：</p><p>稳定性：普通网络连接越南常面临高延迟、高丢包率的问题，而专线通过独享带宽和SLA服务等级协议保障了99.9%以上的可用性。</p><p>安全性：公共网络数据传输易安全不高，而专线则提供端到端加密和私有网络通道。</p><p>性能：专线为优化跨境路径而生，能将延迟控制在100ms以内，远低于普通网络的200-300ms。</p><p>对于需要实时互动的业务场景，如TikTok直播、跨境电商运营和跨国视频会议，专线网络是保障业务连续性的关键基础设施。</p><p>二、不同业务场景的网络需求分析</p><p>1、跨境直播与视频业务</p><p>TikTok直播、YouTube直播等视频业务对网络要求非常高：</p><p>带宽要求：直播至少需要5Mbps专线带宽，超清直播需10Mbps以上。</p><p>网络特性：需低延迟（&lt;100ms） 和高稳定性（丢包率&lt;0.5%），避免直播卡顿中断。</p><p>IP要求：独享住宅IP地址，避免因IP被封导致直播中断。</p><p>可以点此查看越南原生住宅IP内容：越南纯净住宅IP怎么收费的？一个月多少钱？</p><p>2、跨境电商与社媒运营</p><p>越南主流的电商平台(Shopee、Lazada、Tiki)和社交媒体(Facebook、Zalo)对网络环境有特定要求：</p><p>多账号管理：需要多个独享IP，防止账号因IP关联被封。</p><p>本地化体验：使用越南住宅IP，获取真实的本地用户体验和。</p><p>稳定性需求：订单处理、支付结算等关键业务需99.9%以上的可用性保障。</p><p>3、跨国企业协同办公</p><p>在越南设有分支机构的企业需要：</p><p>数据同步：ERP系统、文件传输需稳定带宽保障，推荐10Mbps以上专线。</p><p>视频会议：高质量视频会议需5-10Mbps带宽，并要求低延迟。</p><p>多点互联：多分支机构场景适合SD-WAN方案，实现智能选路和成本优化。</p><p>三、越南国际网络专线开通流程</p><p>在开通越南国际网络专线，需要选择靠谱的服务商，以及准备资质。具体如下：</p><p>国际网络专线哪家好？推荐OSDWAN</p><p>在众多服务商中，OSDWAN的解决方案尤其适合广大中小外贸企业。除了高性价比和快速部署等通用优势外，它还有以下突出特点：</p><p>合规与安全：使用三大运营商的国际网络专线，确保企业跨境网络活动安全合规。<br/>纯净住宅IP：提供全球100+地区的纯净独享IP，特别适合TikTok直播等对IP质量要求高的平台。<br/>简单易用：支持多种终端（手机/电脑APP及硬件设备），无需复杂配置，可实现一分钟快速安装使用。<br/>优质售后：提供专属售后顾问支持，相比传统工单模式，服务响应更及时。<br/>所需资质材料：</p><p>1、企业营业执照以及实名信息</p><p>2、合规的业务，比如B2B外贸、跨境电商、软件出海、社媒运营等业务场景。</p><p>开通流程：</p><p>1、需求分析：首先，您需要明确核心业务场景(是视频会议、跨境电商还是数据中心同步?)，从而确定所需的带宽大小和覆盖地域。建议选择像OSDWAN这类拥有多个海外节点覆盖、并能提供高标准SLA(服务等级协议)保障的服务商。</p><p>2、资质审核与签约：向服务商提交资质材料进行审核，通过后即可签订服务合同。</p><p>3、部署与测试：如果需要设备，服务商会寄送已预配置好的SD-WAN设备，企业只需接入即可。如果是软件，只需要下载安装即可使用。我们OSDWAN同时提供SD-WAN盒子与手机/电脑APP，这种灵活部署方式满足企业多样化的接入需求。</p><p>4、正式启用与运维：建议选择服务商能提供7×24小时的持续运维监控和技术支持。</p><p>四、越南国际网络专线怎么收费？</p><p>不同的服务商收费方式不同，我们OSDWAN提供多种收费方式，下面以OSDWAN价格为例：</p><p>办公账号版：690元/年，适合外贸SOHO或小工作室使用</p><p>社媒运营套餐：1500元/年起：，TikTok运营、社媒矩阵、店铺运营(套餐详情咨询顾问)</p><p>标准版：10000元/年，适合10人以内团队使用或普清TK直播</p><p>企业版：自定义，100+地区的线路和IP可选，自由组合配置</p><p>并且我们还提供多个地区的住宅IP，其中越南独享静态IP费用参考价为50-200元/月/个。</p><p><img width="723" height="339" referrerpolicy="no-referrer" src="/img/bVdm4sv" alt="image.png" title="image.png"/></p><p>五、常见问答（FAQ）</p><p>问：开通越南专线需要多久？<br/>答：如果是企业专线资料齐全，OSDWAN当日即可开通使用，传统MPLS专线则可能需要1-3个月。<br/>问：可以免费试用吗？<br/>答：OSDWAN提供免费试用服务。在签订合同前，测试线路性能是非常有必要的。<br/>问：带宽选择多大合适？<br/>答：这完全取决于业务需求。普通办公和视频会议可能1-5M足够，但如果是跨境直播，则建议不低于5M的稳定独享带宽。在选择时，可以与服务商进行沟通。</p>]]></description></item><item>    <title><![CDATA[大模型成本太高？阿里云Serverles]]></title>    <link>https://segmentfault.com/a/1190000047405354</link>    <guid>https://segmentfault.com/a/1190000047405354</guid>    <pubDate>2025-11-17 17:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>作者：赵世振</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405356" alt="image" title="image"/></p><p><em>本文整理自 2025 云栖大会，阿里云智能集团产品架构师</em> <strong><em>赵世振</em></strong> <em>的主题演讲《Serverless AI 原生应用架构》</em></p><p>在 AI 大模型浪潮席卷全球的今天，企业纷纷加速拥抱 AI，推动智能客服、内容生成、流程自动化等场景快速落地。然而，许多企业在实践中却遭遇了“三高困境”——<strong>成本高、复杂度高、风险高</strong>。</p><p>一位互联网公司 CTO 曾坦言：“智能客服流量暴增，模型服务很容易被打挂，紧急手动扩容后，GPU 闲置率高达 90%，月底账单翻倍，还有数据泄漏风险。”</p><p>这并非个例——大量企业仍在用“传统架构”承载“新型 AI 业务”，要让 AI 业务简单、稳定、安全落地，我们必须从基础设施到业务接入层，进行一场 <strong>AI 原生的架构重塑</strong>。</p><h2>架构变革的底层逻辑</h2><p>过去十余年间，应用架构持续演进：从单体架构到垂直拆分，历经 SOA、微服务，走向云原生，直至今日的 AI 原生架构。这一进程的本质，是<strong>业务逻辑不断解耦、分布化与智能化的过程</strong>，旨在实现更快速的业务响应、更灵活的协同能力。</p><p>与此同时，底层基础设施也同步进化——从物理机、虚拟机到容器、Kubernetes，再到 Serverless，如今迈向 Serverless AI 的新阶段。其核心在于<strong>对资源与能力的极致抽象</strong>，实现按需弹性、自动伸缩，让计算如同水电一般随取随用、高效便捷。</p><p>两条演进主线共同揭示了一个清晰的趋势：未来的技术重心将愈发聚焦于业务逻辑本身的创新与实现，而基础设施则趋于全面抽象化、自动化和智能化。开发者无需再过多关注底层运维细节，而是可以专注于创造更高价值的业务场景。这不仅是技术的跃迁，更是生产力的一次深刻变革。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405357" alt="image" title="image" loading="lazy"/></p><h2>AI 原生应用架构的三大核心需求</h2><p>通过与 300 余家企业的深度交流，AI 原生应用架构的核心需求可归纳为<strong>高模型算力</strong>、<strong>高可用性</strong>及<strong>严格安全管控</strong>三大维度：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405358" alt="image" title="image" loading="lazy"/></p><p><strong>1. 算力需求</strong></p><ul><li><strong>成本优化：</strong> GPU 算力成本是 CPU 的数倍，且供应波动大。需提供灵活的卡型选择（如 N 分之一卡）、按需付费模式及预留闲置资源策略，以平衡成本与性能。</li><li><strong>稳定性保障：</strong> 通过多可用区部署与动态资源调度，确保模型调用的持续性与资源利用率最大化。</li></ul><p><strong>2. 高可用性需求</strong></p><ul><li><strong>全链路容灾：</strong> 支持多可用区部署，避免单点故障；</li><li><strong>限流与 fallback 机制：</strong> 突发流量时自动限流，模型服务异常时无缝切换至备用模型，保障业务连续性。</li></ul><p><strong>3. 安全管控需求</strong></p><ul><li><strong>输入输出合规性：</strong> 模型输入输出均设内容安全防护，过滤违规内容、敏感信息等；</li><li><strong>消费者鉴权：</strong> 不同团队或不同用户请求带有不同的鉴权凭证，权限最小化；</li><li><strong>全链路监控：</strong> 实现从网关到算力的全链路可观测体系；</li></ul><p>总结来说，AI 原生应用架构需要的是：<strong>简单易用的开发体验、生产级的性能、稳定性和安全保障。</strong></p><h2>Serverless AI 原生架构的全栈能力支撑</h2><p>为满足上述需求，Serverless AI 原生应用架构应运而生。在该架构中，模型可通过 Serverless GPU（即函数计算 FC）进行部署，与 Agent 相关的 Sandbox、MCP Server、E2B 等服务也可托管于 FC。AI 网关作为模型与 MCP 服务的代理层，提供限流、鉴权、可观测性与安全护栏等功能。AI Agent 的开发支持低代码、零代码及高代码方式，可部署于 FC 或 SAE。Agent 前端通过网关进行代理，全链路配备 AI 应用观测能力，实现端到端可观测。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405359" alt="image" title="image" loading="lazy"/></p><p>该架构具备以下特点：</p><h3>特征一：全栈 Serverless，极致简化运维</h3><p>整个架构中，函数计算 FC、SAE（Serverless应用引擎）、MSE Nacos、RocketMQ、AI 网关等关键组件均为 Serverless 形态或具备 Serverless 特性。无需管理底层服务器，自动扩缩容真正做到“一键部署、开箱即用”。</p><h3>特征二：全链路高可用，保障业务连续性</h3><p>架构中的每一个产品节点均支持多可用区部署，具备跨区域容灾能力。特别是函数计算 FC 提供的 Serverless GPU 实例，已实现三可用区冗余部署，并配备实例级健康检查与自动恢复机制，极大提升了模型服务的稳定性。</p><p>此外，AI 网关内置 Fallback 机制，在主模型不可用时可自动切换至备用模型，确保关键业务不中断。</p><h3>特征三：双层安全保障，构筑可信 AI 防线</h3><p>安全贯穿整个调用链路：</p><ul><li><strong>运行时安全</strong>：FC 和 SAE 采用实例隔离机制，防止租户间干扰；</li><li><strong>调用层安全</strong>：AI 网关提供消费者鉴权、API Key 管理、内容审核等功能，有效防范未授权访问与恶意攻击。</li></ul><h3>特征四：简单易用，加速 AI 创新落地</h3><p>所有产品都是云上托管，一键部署启动，常见模型与 MCP 服务已封装为模板，可在 <strong>FunctionAI 平台一键部署</strong>，不管你是零代码用户、低代码开发者，还是资深工程师，都能找到适合你的入口。</p><h2>Serverless AI 架构的核心组件</h2><h3>函数计算 FC：定义 Serverless 终极形态</h3><p>定位为弹性经济的全托管 Serverless 计算服务，专用于部署大模型与 MCP 工具：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405360" alt="image" title="image" loading="lazy"/></p><ul><li><strong>经济降本</strong>：支持卡切分（1/N GPU）、阶梯定价、常驻实例等策略，整体 GPU 利用率超 50%，成本更低。</li><li><strong>极致弹性</strong>：<strong>GPU 实例启动快（毫秒级/秒级）</strong> ，通过<strong>请求感知调度显著降低 RT 抖动，</strong> 支持定时/水位伸缩、延迟释放、会话亲和。</li><li><strong>开发框架集成</strong>：内置 MCP Server、Sandbox 等服务运行时，支持模型微调镜像一键部署；  </li><li><strong>运维能力</strong>：提供镜像加速、资源调度、请求级监控日志，实现零运维体验。</li></ul><h3>AI 网关：企业级 AI 流量中枢</h3><p>作为<strong>模型、MCP、Agent 的统一接入入口</strong>，承担安全、治理与调度职责：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405361" alt="image" title="image" loading="lazy"/></p><ul><li><strong>统一代理</strong>：支持多模型路由、MCP 协议适配、Agent API 封装，简化调用复杂度；</li><li><strong>安全鉴权</strong>：集中管理 API-KEY，支持二次分发与消费者身份验证，设置 AI 安全护栏防范恶意输入与输出；</li><li><strong>高可用保障</strong>：多可用区部署 + fallback 机制，异常时自动切换备用模型，支持精细化限流，保障核心业务稳定性； </li><li><strong>成本优化</strong>：内置 AI 缓存减少算力资源消耗，结合观测能力实现 Token 级成本监控；</li><li><strong>灵活扩展</strong>：支持动态组装 MCP 新工具链，快速接入外部 AI 服务。</li></ul><h2>总结展望</h2><p>Serverless AI 原生架构不仅是技术演进，更是企业智能化转型的关键基础设施。它让开发者聚焦业务逻辑，让企业告别“基建焦虑”，让 AI 真正“飞入寻常百姓家”。</p><p>正如本次演讲尾声所说：“<strong>让架构为业务赋能，让 AI 为世界创造更多可能。</strong> ”</p><p>阿里云将持续投入 Serverless 与 AI 原生架构研发，携手更多行业伙伴，共同构建开放、智能、安全的新一代 AI 应用生态。</p>]]></description></item><item>    <title><![CDATA[美团 LongCat 团队发布全模态一站]]></title>    <link>https://segmentfault.com/a/1190000047404974</link>    <guid>https://segmentfault.com/a/1190000047404974</guid>    <pubDate>2025-11-17 16:12:53</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>多模态人工智能正从单一感知能力迈向视觉、音频与文本的统一融合，即全模态大模型（Omni-models）时代。然而，相应的评测体系却相对滞后。现有的评测工具不仅稀缺、各自为战，且几乎完全以英文为中心，缺乏对中文场景的有效支持。此外，一些现存的数据集在设计上存在局限性，例如部分问题的解答路径并非严格依赖于多模态信息的融合，这为科学评估模型真实的跨模态能力带来了一定的复杂性。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047404976" alt="图1：UNO-Bench核心统计与发现概览" title="图1：UNO-Bench核心统计与发现概览"/></p><p>针对这些痛点，美团LongCat团队提出了一套高质量、多样化的一站式全模态大模型评测基准——<strong>UNO-Bench</strong>。该基准通过一个统一的框架，不仅能同时精准衡量模型的单模态与全模态理解能力，更首次验证了全模态大模型的“组合定律”——该定律在能力较弱的模型上呈现为短板效应，而在能力较强的模型上则涌现出协同增益，为行业提供了一种全新的、跨越模型规模的分析范式。这一发现的背后，是其系统性的数据构建流程：通过完全人工标注确保高质量与丰富度，有效防止数据污染。此外，该团队还引入了创新的“多步开放式问题”，旨在突破传统选择题的局限，更具区分度地刻画模型在复杂链路上的推理能力。</p><p>接下来，我们将详细介绍UNO-Bench是如何构建的，以及它如何为推动下一代AI的智慧演进奠定基础。</p><h2>01. 评测现状：从单模态繁荣到全模态挑战</h2><p>当前，面向单模态的评测基准已发展成熟且生态繁荣。无论是针对通用视觉理解的MMBench、检验复杂数理逻辑的MathVision，还是覆盖动态视频场景的MVBench，以及在音频领域进行探索的MMAU，这些高质量的评测资源极大地推动了AI在细分维度下的认知能力发展。然而，这些资源彼此独立，难以适应向全模态大模型演进的趋势。</p><p>当我们将目光投向新兴的全模态大模型评测领域，现状则面临挑战。尽管如Gemini、Qwen-3-Omni等兼容视听双模态的顶尖全模态大模型已崭露头角，但能够有效评估其综合能力的基准却稀缺且存在明显不足。例如，OmniBench的部分数据存在错误答案，而WorldSense中由于使用音视频同步数据，大部分题目无需跨模态信息即可解答，导致难以有效衡量全模态的整合能力。</p><p>正是在这样的背景下，UNO-Bench应运而生。LongCat团队通过1250条人工标注的全模态样本和2480个增强的单模态样本，构建了一个适用于中文场景、横跨44类任务的综合性评测体系。其中，高达98%的问题被严格设计为必须在跨模态条件下才能正确解答，这弥补了现有评测无法有效检验模型真实跨模态能力的痛点，为科学评估与推动全模态大模型的发展提供了坚实可靠的基石（详见表格1）。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047404977" alt="表格1：多模态基准横向对比" title="表格1：多模态基准横向对比" loading="lazy"/></p><p><strong>说明</strong>：表格中，I、A、V、T分别代表图像、音频、视频和文本模态。Acc.代表问答对的准确率，Solvable代表需要全模态才能解决的问题比例。Source代表素材来源，分为可防止数据污染的私有数据集和公开数据集。QA Type代表问答类型，MC、MO分别代表选择题和多步开放式问答。EN和ZH分别代表英文和中文。</p><h2>02. UNO-Bench构建：从顶层设计到创新实现</h2><p>一个卓越的评测基准始于一个科学的顶层设计。我们从定义模型核心能力体系出发，通过标准化的数据生产线确保高质量与多样性，并最终引入创新的评测方法与优化算法，共同构建了UNO-Bench的基石。</p><h3>2.1 顶层设计：科学定义全模态大模型能力体系</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047404978" alt="图2：UNO-Bench统一能力体系图" title="图2：UNO-Bench统一能力体系图" loading="lazy"/></p><p>该团队首先将模型的综合智能系统性地解构为两大核心层面：感知层与推理层。</p><ul><li><strong>感知层</strong>：覆盖了从对象、属性、场景的基础识别，到空间关系判断、跨模态转换及语义理解等六大认知能力，并特别增设了跨模态对齐这一能力。</li><li><strong>推理层</strong>：在通用、STEM、代码等传统推理类别之上，着重加入了空间推理、时序推理、复杂推理等更能体现全模态大模型特色的高阶推理任务。其中通用推理细拆为常识推理和逻辑推理，空间推理细拆为静态推理和动态推理。</li></ul><p>这一双维能力框架不仅为后续的数据构建提供了清晰的蓝图，也使得对模型能力的细粒度剖析成为可能。</p><h3>2.2 数据构建：标准化的高质量生产线</h3><p>为确保数据的顶尖品质，LongCat团队建立了一套包含精选数据素材、专家级问答标注、严苛的多轮质检三个关键环节的标准化生产流程。所有关键对话均由超过20位真人录制，以高度还原真实世界的声学特征（如普通话、四川话等）。其中最关键的质检环节是模态消融实验：通过移除任一模态的信息来检验问题是否依然可解，以此严格确保98%以上数据的“跨模态可解性”。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047404979" alt="图3：跨模态可解性问题示例" title="图3：跨模态可解性问题示例" loading="lazy"/></p><p><strong>说明</strong>：图(a)展示了必须结合视听信息才能解答的问题，而图(b)和图(c)则分别展示了仅凭音频或视频即可解答的问题。</p><p>通过三个小案例（a, b, c）对比，清晰地展示了什么是必须由多个模态结合才能解答的问题，以及什么是仅凭单模态就能解答的问题。</p><p>数据生产流程的核心在于：</p><ul><li>针对现有数据集中普遍存在的两大问题——数据污染（视频素材可能已被模型在训练阶段“见过”）和信息冗余（视频自带的音频与画面高度同步，降低了跨模态推理的难度），我们采取了独特的素材构建策略。</li><li>UNO-Bench中超过90%私有化原创 。其中，大部分视觉素材来源于广泛的众包实拍，多样性、真实性更好的同时，也有效避免了模型因训练集覆盖而产生的“穿越”问题。</li><li>更关键的是，为了打破信息冗余，所有关键的音频内容（尤其是对话）均独立设计并由真人录制，然后与视觉素材进行人工组合。这种“视听分离再组合”的方式，确保了音频和视频各自承载着不可替代的关键信息，迫使模型必须进行真正的跨模态信息融合，而不是简单的同步确认。</li></ul><h3>2.3 数据优化：单模态补全与高效压缩</h3><p>为构建全面的评测体系，我们不仅自建数据，还针对性地从AV-Odyssey、WorldSense等公开数据集中筛选了高质量样本进行补全（在整体全模态数据中占比11%）。此外，为降低大规模评测带来的算力消耗，我们独创了聚类引导的分层抽样法。实验证明，该方法在保持模型排名高度一致性的前提下，成功将评测成本降低了超过90%。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047404980" alt="图4：数据构建流程图（说明：左边为全模态数据构建流程与统计信息，右边为单模态数据压缩流程与统计信息）" title="图4：数据构建流程图（说明：左边为全模态数据构建流程与统计信息，右边为单模态数据压缩流程与统计信息）" loading="lazy"/></p><h3>2.4 评测创新：多步开放式问题与通用评分模型</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047404981" alt="图5：多步开放式问题（MO）构建示例" title="图5：多步开放式问题（MO）构建示例" loading="lazy"/></p><p>为了打破传统选择题无法有效评估复杂推理的局限，引入了创新的多步开放式问题（MO，Multi-step Open-ended question）。这种题型将一个复杂的长链条推理任务，拆解为多个相互依赖、层层递进的子问题，并要求模型对每一步都给出开放式的文本答案。</p><p>评分则由专家根据每一步的难度与重要性进行加权赋分（满分10分）。这种设计能够直观地揭示模型在多步推理中的能力衰减现象，从而精准地区分出模型的“浅层猜测”与“深度思考”，是衡量顶尖模型推理能力的关键指标，具体示例如图5所示。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047404982" alt="图6：通用评分模型训练流程图" title="图6：通用评分模型训练流程图" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047404983" alt="图7：通用评分模型的问题类型定义（说明：该图表展示了为提高评分准确率而定义的六种细分问题类型及其判断标准。）" title="图7：通用评分模型的问题类型定义（说明：该图表展示了为提高评分准确率而定义的六种细分问题类型及其判断标准。）" loading="lazy"/></p><p>为实现自动化评估，LongCat团队还提出了一个通用评分模型，通过对问题类型进行细分（如图7所示），并结合人工和自动标注多轮质量迭代的数据集（如图6所示），使其能够支持6种通用问题类型的自动评分，在分布外的模型和基准测试中达到了95%的准确率。</p><h2>03. 实验与分析：揭示全模态大模型的真实能力与演进规律</h2><p>LongCat团队在UNO-Bench上对包括Qwen、Baichuan、MiniCPM以及Gemini系列在内的多款主流全模态大模型进行了全面评测。实验设计旨在回答三个核心问题：</p><ol><li>当前全模态大模型的智能水平及其短板何在？</li><li>单模态与全模态能力之间存在何种关系？</li><li>UNO-Bench作为一站式评估方案的有效性如何？</li></ol><h3>3.1 模型性能的全面剖析</h3><p><strong>总体格局：闭源模型优势显著，开源模型仍在追赶</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047404984" alt="表格2：各全模态大模型在UNO-Bench上的评测结果（说明：表格展示了各模型在单模态（音频、视觉）和全模态（选择题Omni-MC、多步开放式题Omni-MO）上的得分。）" title="表格2：各全模态大模型在UNO-Bench上的评测结果（说明：表格展示了各模型在单模态（音频、视觉）和全模态（选择题Omni-MC、多步开放式题Omni-MO）上的得分。）" loading="lazy"/></p><p>如表格2所示，在本次评测的开源模型中，LongCat-Flash-Omni表现出开源SOTA（State-of-the-Art）的成绩。该模型在音频（80.20）、视觉（67.06）、全模态选择题（49.90）以及全模态开放题（42.68）四大核心维度上，全面超越了本次评测中的其他开源模型。</p><p>与此同时，以Gemini系列为代表的闭源模型在所有评测维度上，特别是在顶尖性能层面，依然保持着领先优势，其中Gemini-2.5-Pro稳居行业标杆。当面对难度更高的“多步开放式问题”（Omni-MO）时，所有模型的性能普遍下滑，这清晰地反映出，长链条、跨模态的深度推理依然是整个AI领域亟待攻克的难题。</p><p><strong>能力拆解：推理是区隔强弱的核心维度</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047404985" alt="表格3： 基于能力体系的跨模态表现分析" title="表格3： 基于能力体系的跨模态表现分析" loading="lazy"/></p><p>通过对感知与推理能力的细化分析（见表格3），我们发现：</p><ul><li>感知层面，跨模态同步对齐比单纯的跨模态识别更具挑战。</li><li>推理层面，空间推断是所有子任务中最难的一项，即使是表现最佳的Gemini-2.5-Pro得分也仅为45分。</li></ul><p>综合来看，模型的感知能力相对较强，而真正的性能差距主要体现在推理能力上。以Qwen-3-Omni-30B与Gemini-2.5-Pro为例，两者在感知能力上相差23分，但在推理能力上的差距则拉大到33分，这表明：推理能力是划分模型强弱的关键分水岭。</p><p><strong>顶尖梯队与人机对比剖析</strong></p><p>LongCat团队进一步对Gemini-2.5-Pro的卓越表现进行了剖析。一方面，这得益于其强大的单模态基础能力；另一方面，其内置的语音转写并自然融入推理链路的能力，是多数开源模型尚不具备的。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047404986" alt="图8：Gemini-2.5-Pro评测过程示例（说明：该图展示了Gemini-2.5-Pro利用音频转录文本辅助解决问题的过程。）" title="图8：Gemini-2.5-Pro评测过程示例（说明：该图展示了Gemini-2.5-Pro利用音频转录文本辅助解决问题的过程。）" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047404987" alt="图9：人类专家与Gemini-2.5-Pro性能对比图" title="图9：人类专家与Gemini-2.5-Pro性能对比图" loading="lazy"/></p><p>说明: Gemini-2.5-Pro在感知能力上与人类相当，但在推理能力上仍有差距。</p><p>如图9所示，观察到一个有趣的现象：</p><ol><li>感知能力媲美人类：在全模态的感知任务上，Gemini-2.5-Pro的表现已能与人类专家相当。</li><li>推理能力仍存差距：然而，在更复杂的推理任务上，人类专家（81.3%）的表现依然优于Gemini-2.5-Pro（74.3%）。这揭示了AI与人脑在抽象归纳和复杂逻辑处理能力上的本质区别。</li></ol><h3>3.2 全模态与单模态的内在关联</h3><p>得益于UNO-Bench统一的能力体系与高质量数据，通过回归与消融实验，揭示了单、全模态能力间的深刻关系。</p><p><strong>“组合定律”成立，且遵循幂律协同</strong></p><p>我们对各模型的单、全模态得分进行了回归分析，发现了一个强关联性，并将其形式化为一个科学定律。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047404988" alt="图10：全模态能力的组合定律关系图" title="图10：全模态能力的组合定律关系图" loading="lazy"/></p><p>如图10所示，全模态的性能并非单模态能力的简单线性叠加，而是遵循一种乘积规律。通过严谨的数学推导和非线性拟合，得到了一个拟合度高达<strong>97.59%</strong>的幂律公式：</p><blockquote>POmni ≈ 1.0332 · (PA × PV)^2.1918 + 0.2422</blockquote><p>该幂律公式的指数大于1，使得函数曲线呈现为一条加速上升的凸形。这完美地解释了两种现象的涌现：</p><ol><li>短板效应 (Bottleneck Effect)：对于能力较弱的模型，其全模态性能的增长相对平缓。</li><li>协同增益 (Synergistic Promotion)：对于顶尖模型，单模态能力的增强会带来全模态性能的爆发式增长，实现了真正意义上的“1+1 &gt;&gt; 2”的多模态协同增益。</li></ol><p><strong>更重要的是，这个“组合定律”提供了一种全新的、跨越模型规模的分析范式</strong>。它允许研究人员将不同参数规模、不同架构的模型放置在同一个坐标系下进行比较，不再仅仅关注各自的绝对得分，而是通过它们在幂律曲线上的相对位置，来统一度量其“模态融合效率”。一个模型如果显著高于拟合曲线，则意味着其模态融合机制更为高效；反之，则可能存在融合瓶颈。这为评估和优化全模态大模型的内在融合能力，提供了一个极具价值的分析工具。</p><p>从图10的具体模型分布来看，其中参与拟合的模型由圆点表示，新增的LongCat-Flash-Omni模型表现较为突出。虽然Gemini系列的具体参数规模未知，但可以观测到LongCat-Flash-Omni的表现已非常接近Gemini-2.5-Flash，并显著领先于Qwen3-Omni-30B。其位置正处于曲线加速上升的“协同增益区”，且与理论拟合曲线高度吻合，这表明该模型展现出了高效的多模态融合能力。</p><p><strong>消融实验验证</strong></p><p>这再次印证了多通道互补与融合是通往更高智能的必经之路。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047404989" alt="表格4：视觉理解能力消融实验结果" title="表格4：视觉理解能力消融实验结果" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047404990" alt="表格5：音频理解能力消融实验结果" title="表格5：音频理解能力消融实验结果" loading="lazy"/></p><p>LongCat团队通过详尽的视觉与音频消融实验（具体数据参见表格4、5）进一步验证了这些发现。实验表明，对于多数模型，提供文本描述（Caption/ASR）比直接处理原始视听信息能获得更好的效果，但顶尖模型如Gemini-2.5-Pro则能从原始信号中提取比文本更丰富的信息。</p><h3>3.3 UNO-Bench基准的有效性验证</h3><p>除了核心的实验发现，UNO-Bench作为一个评测基准本身的科学性和有效性，也通过以下几个方面得到了验证。</p><p><strong>多步开放式问题的卓越区分度</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047404991" alt="表格6：各模型在多步开放式问题（MO）上的表现" title="表格6：各模型在多步开放式问题（MO）上的表现" loading="lazy"/></p><p>如表格6所示，创新的MO题型能够真实地刻画模型在长链条推理中的能力衰减，有效放大了模型间的认知鸿沟。</p><p><strong>高效的数据集压缩算法</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047404992" alt="图11：数据集压缩性能评估图" title="图11：数据集压缩性能评估图" loading="lazy"/></p><p>如图11所示，我们设计的聚类引导抽样法，能在保持模型排名一致性（SRCC/PLCC &gt; 0.98）的前提下，将评测算力消耗降低超过90%，实现了效率与准确性的平衡。</p><p><strong>卓越的数据质量与区分度</strong></p><p>一个评测基准的有效性，最终体现在其数据的质量和区分模型优劣的能力上。UNO-Bench在这两方面都表现出色。</p><ul><li>首先，在数据质量上，如前文表格1所示，UNO-Bench的全模态数据集问题准确率达到了100%，且有高达98%的问题被严格设计为必须跨模态才能解答，这确保了评测的公平性和对模型真实能力的有效检验。</li><li>其次，在区分度上，UNO-Bench的设计能够清晰地揭示不同模型间的性能梯度。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047404993" alt="图12：UNO-Bench与其他全模态基准对比图" title="图12：UNO-Bench与其他全模态基准对比图" loading="lazy"/></p><p>而在与其他全模态基准的直接对比中（如图12所示），UNO-Bench的有效性也得到了进一步验证。它不仅通过更高的得分标准差（19.5 vs. 12.75）展现了比OmniBench更强的区分能力，还通过合理的难度设置，避免了像AV-Odyssey那样所有模型得分被压缩在狭窄低分区间的窘境。这确保了UNO-Bench既能有效评估当前模型，也为未来更强模型的涌现预留了足够的成长空间，是一个更可靠和富有洞察力的评测工具。</p><h2>04. 总结与展望</h2><p>本文提出了一站式全模态大模型评测基准——UNO-Bench。该基准通过科学的评测框架，首次揭示了多模态智能并非简单的线性叠加，而是遵循着一种乘积规律，这一规律在能力较弱的模型上体现为瓶颈限制，而在顶尖模型上则表现为协同增益的特性，这个全模态大模型的“组合定律”为行业提供了一种全新的、跨越模型规模的分析范式。LongCat团队的评测结果进一步表明，以Gemini为代表的闭源模型在单模态及跨模态理解上仍远超主流开源阵营，其顶配版本虽在感知能力上已逼近人类专家，但在复杂的推理层面仍存在亟待突破的空间。而这些发现，正是得益于UNO-Bench自身的较高的数据质量与创新的评价机制，它有效扩展了模型表现的区分度，为新一代智能体的持续成长奠定了坚实基础。</p><p>面向未来，LongCat团队将通过自动化人机共建流程持续扩充数据规模，引入STEM、Code等更具挑战性的场景，并深入探索模态间的互动关系，为下一代通用人工智能的发展开辟新路径。</p><p><strong>开源资源</strong></p><ul><li><strong>GitHub</strong>：<a href="https://link.segmentfault.com/?enc=PeR6dvcgODd7LDbppYELHg%3D%3D.Jhab%2BDpVBISZwe6FHSCnTbw0AowHzrarIdc04nsO9u%2BmdqDKIzPhLnbBhmqdXrym" rel="nofollow" target="_blank">https://github.com/meituan-longcat/UNO-Bench</a></li><li><strong>Hugging Face</strong>：<a href="https://link.segmentfault.com/?enc=D22mfigGZIIdEcY34GJLig%3D%3D.%2F%2Bz%2BEGZZEU3u6si6w0C0u9ko0M0wn%2BFOCp%2F34ccVrzOd25JZEVOFuKAAzpTiTFNij20p3RpCb0WtVJCesRHC1Q%3D%3D" rel="nofollow" target="_blank">https://huggingface.co/datasets/meituan-longcat/UNO-Bench</a></li><li><strong>论文下载</strong>：<a href="https://link.segmentfault.com/?enc=IRJngLfokp4WRkLnAfx1vg%3D%3D.VhQ5TqROnDa7rFAt4QGT8IuseDdMnm4tLI7Ufb0eCWbqCb4k%2BioWoANT7%2B9qo58pglduaZHPVGC%2F07CGQJcz8x7lSGDoQ2k1bo%2BRsHy16Ig%3D" rel="nofollow" target="_blank">https://github.com/meituan-longcat/UNO-Bench/blob/main/UNO-Bench.pdf</a></li></ul><p>| 关注「美团技术团队」微信公众号，在公众号菜单栏对话框回复【2024年货】、【2023年货】、【2022年货】、【2021年货】、【2020年货】、【2019年货】、【2018年货】、【2017年货】等关键词，可查看美团技术团队历年技术文章合集。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000046195963" alt="" title="" loading="lazy"/></p><p>| 本文系美团技术团队出品，著作权归属美团。欢迎出于分享和交流等非商业目的转载或使用本文内容，敬请注明“内容转载自美团技术团队”。本文未经许可，不得进行商业性转载或者使用。任何商用行为，请发送邮件至 <a href="mailto:tech@meituan.com" target="_blank">tech@meituan.com</a> 申请授权。</p>]]></description></item><item>    <title><![CDATA[别让传统管理拖后腿！电子制造降本增效就靠]]></title>    <link>https://segmentfault.com/a/1190000047405013</link>    <guid>https://segmentfault.com/a/1190000047405013</guid>    <pubDate>2025-11-17 16:12:15</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>别让传统管理拖后腿！电子制造降本增效就靠这套MES系统<br/>在电子制造领域，随着产品复杂度提升和交货周期缩短，传统生产管理模式已难以满足高效率、高柔性与可追溯性要求。免费MES、智能化MES、AI智能化MES、电子行业MES、万界星空MES作为连接计划层与控制层的信息枢纽，为电子组装企业提供了全流程的数字化管控能力。<br/><strong>一、电子组装制造执行系统（MES）的核心功能</strong><br/>1、生产调度与工单管理<br/>高级排程： 考虑设备能力、物料齐套性、人员技能、工艺路径瓶颈等多种约束条件，进行优化排程，最大化设备利用率和订单准时交付率。<br/>工单派发与执行： 将电子工单下发至指定生产线或工位。操作员可在终端接收任务，清晰了解当前需要生产的产品型号、数量及工艺要求。<br/>在制品状态监控： 实时跟踪每个工单在每一道工序的进度、投入/产出数量、状态（如等待、加工中、中断、完成），形成完整的生产进度看板。<br/>2、物料与追溯管理<br/>物料防错：工位上料时，操作员需扫描物料卷盘码或料箱码，系统自动与工单的物料清单（BOM）进行比对。若物料型号、批次、极性不符，系统立即报警并锁定设备，防止错料事故。<br/>精确物料消耗： 系统记录每个工单、每块板卡实际消耗的物料信息；<br/>全过程追溯性： 建立从原材料批次、供应商信息→SMT锡膏印刷、贴片→插件→测试→维修→包装乃至发货的完整数据链。支持“正向追溯”（从原料查用到哪些产品）和“反向追溯”（从产品序列号追溯所有用料、工艺参数、检测记录），满足行业法规要求并在出现质量问题时实现快速围堵。<br/>3、工艺流程与SOP控制<br/>数字化工艺路线： 在系统中定义产品的标准工艺流程，包括工序顺序、工作中心、标准作业时间、质量控制点等。<br/>电子化SOP投放： 在每个工位的终端屏幕上，动态显示当前产品的作业指导书、图纸、注意事项或操作视频，确保操作规范。<br/>版本控制： 当工程变更（ECN）发生时，系统确保产线使用的所有文件（BOM、SOP）均为最新有效版本，避免因文件版本错误导致的生产失误。<br/>4、质量管理与统计过程控制（SPC）<br/>质量控制点管理： 在关键工序（如锡膏印刷后、回流焊后）设置质量控制点，定义检验项目和标准。<br/>与测试设备集成： 直接与AOI（自动光学检测仪）、AXI（X射线检测仪）、ICT（在线测试仪）、FCT（功能测试台）等设备集成，自动采集测试结果，并实现测试数据与产品序列号的绑定。<br/>SPC实时监控： 对关键工艺参数（如回流焊炉温曲线）或测试参数（如某个电压值）进行实时SPC分析，一旦出现异常趋势（如六点上升/下降趋势），系统提前预警，避免批量性不良品的产生。<br/>不合格品处理： 建立规范的不合格品处理流程（NCR）。当检测到缺陷时，系统引导操作员将产品送入维修站，记录缺陷代码、维修方法和责任人，形成闭环管理。<br/>5、 设备与工具管理<br/>设备状态监控： 实时采集设备运行状态（运行、停机、待料、故障），自动计算设备综合效率（OEE），帮助管理层识别效率损失的主要根源。<br/>工装夹具管理： 管理钢网、吸嘴、治具等工具的生命周期，包括库存、校准记录、使用次数和寿命预警。<br/>6、数据采集与可视化看板<br/>多源数据采集： 通过DNC/MDC接口、PLC、传感器、条码扫描等多种方式，自动、实时地采集人、机、料、法、环等各类数据。<br/>实时看板： 通过车间大屏或管理终端，动态展示生产绩效关键指标（KPI），如计划达成率、直通率（FPY）、OEE、在制品数量等，实现生产透明化。<br/><img width="723" height="345" referrerpolicy="no-referrer" src="/img/bVdmZmH" alt="" title=""/><br/><strong>二、万界星空科技电子组装行业MES其他功能介绍：</strong></p><ol><li>系统集成能力：打破信息孤岛，实现全链路协同<br/>电子制造企业通常存在ERP、PLM、WMS等多种系统，支持通过ESB企业服务总线或API网关实现数据互通。采用统一数据模型，定义标准数据接口，避免形成信息孤岛。</li><li>实时性与可靠性：保障生产稳定高效运行<br/>生产现场的数据采集与指令下发需在秒级内完成。通过边缘计算网关进行本地预处理，降低网络负载，同时采用冗余部署与故障转移机制保障系统可用性。</li><li>系统可扩展性与开放性<br/>万界星空科技MES每个功能模块可作为独立服务部署和扩展。同时，提供丰富的开发接口和SDK，允许企业或合作伙伴在平、台上进行深度定制化开发，集成特定硬件或实现独特业务逻辑，保护企业长期投资。<br/><strong>三、实施效益分析</strong><br/>生产透明度：实时监控各工序进度、在制品数量与设备状态<br/>质量可控性：全过程质量数据采集与分析，降低DPPM指标<br/>决策支持：基于历史数据预测设备故障风险、优化排产方案<br/>成本控制：通过精细化的物料与工时统计，准确核算生产成本</li></ol><p>如果您的企业也属于电子组装及其他组装及装配制造行业，同时也想通过MES系统来实现生产线数字化管理，欢迎万界星空科技官网免费试用或直接私信联系我们，我们将根据您企业的实际情况提供解决方案并发送相关案例资料！</p>]]></description></item><item>    <title><![CDATA[一键救援小程序系统：高效便捷的救援服务解]]></title>    <link>https://segmentfault.com/a/1190000047405037</link>    <guid>https://segmentfault.com/a/1190000047405037</guid>    <pubDate>2025-11-17 16:11:37</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><strong>一、概述总结</strong><br/>一键救援小程序系统是自主研发的手机救援服务工具，软件著作权登记号为软著登字第 4732863 号。该系统以 “快速响应、便捷操作” 为核心，支持微信公众号部署，通过简洁的操作流程和完善的后台管理功能，为用户提供拖车、吊车、轮胎更换、机油补给、车辆修理等多种救援服务。系统采用微擎系统交付，源码未加密，支持 PHP5.3 至 PHP7.1 多种版本，首次购买可享受 1 年免费更新服务，为汽车相关行业提供高效、可落地的救援服务数字化解决方案。</p><p><strong>二、功能介绍</strong><br/>（一）前台核心功能<br/>救援申请：用户进入系统后，填写姓名、电话、验证码、车牌号、车架号等必填信息，结合定位功能提交救援地址，选择拖车、吊车、修理等具体服务类型即可发起救援。</p><p>订单管理：订单填写错误时可自主取消，提交成功后支持催单操作，催办成功后可直接进入救援记录页面查看进度。</p><p>救援记录：清晰展示历史救援的服务类型、救援日期、救援时间、救援状态及故障地点等关键信息，方便用户追溯。</p><p>界面优化：各细节界面经过升级打磨，搭配自定义轮播图，操作流程直观易懂，提升用户使用体验。</p><p>（二）后台管理功能<br/>基础设置：支持幻灯片、公司 logo、短信设置、消息模板等基础配置，满足品牌个性化展示需求。</p><p>粉丝信息：收录用户 OPENID、昵称、头像、关注时间等数据，助力用户画像构建与精准服务。</p><p>售后信息：整合救援订单相关的售后数据，便于后续服务跟踪与问题处理。</p><p>救援客服：支持多客服消息提醒功能，提升救援需求响应效率，保障服务质量。</p><p><strong>三、适用场景与行业价值</strong><br/>（一）适用场景<br/>个人车主：车辆行驶中突发故障（如爆胎、缺油、机械故障），需要紧急拖车或现场修理时。</p><p>汽车 4S 店：为车主提供配套救援服务，延伸服务链条，提升客户满意度。</p><p>汽车维修企业：拓展救援业务渠道，通过线上接单提高订单量与服务覆盖范围。</p><p>汽车救援公司：实现救援订单的数字化管理，优化派单效率，降低沟通成本。</p><p>（二）行业价值<br/>提升服务效率：一键呼叫 + 定位功能简化申请流程，催单机制与多客服提醒缩短响应时间，让救援服务更高效。</p><p>降低运营成本：通过信息化管理整合订单、用户、客服数据，减少人工沟通与统计成本，规范服务流程。</p><p>增强用户粘性：透明的救援记录、便捷的操作体验与完善的售后保障，提升用户信任感与复购意愿。</p><p>拓展业务边界：支持定制开发，可结合汽车行业其他需求（如违章查询、一键挪车）拓展功能，打造综合服务平台。</p><p><strong>四、常见问答</strong><br/>问：该系统支持哪些部署环境？</p><p>答：支持微信公众号部署，兼容 PHP5.3、PHP5.4、PHP5.5、PHP5.6、PHP7.1 版本。</p><p>问：系统支持哪些救援服务类型？</p><p>答：涵盖拖车、吊车、轮胎更换、机油补给、车辆修理等多种常见救援场景，满足不同车辆故障需求。</p><p>问：后台能否查看用户相关数据？</p><p>答：可以，后台粉丝信息模块可收录用户 OPENID、昵称、头像、关注时间等数据，便于用户管理与服务优化。</p><p>问：订单提交后可以修改或取消吗？</p><p>答：订单填写错误时可自主取消，提交成功后若需加快处理进度，支持催单操作。</p>]]></description></item>  </channel></rss>