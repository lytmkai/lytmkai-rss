<?xml version="1.0" encoding="UTF-8"?><rss version="2.0">  <channel>      <title>SegmentFault - 最近文章</title>      <link>https://segmentfault.com/blogs/newest</link>      <description>SegmentFault 思否</description>      <generator>python segmentfault.py @Pi20</generator>      <item>    <title><![CDATA[1024Foundation 发起人冯雷受邀于浙大EMBA项目、战略型企业家项目开展讲座 AI4AI]]></title>    <link>https://segmentfault.com/a/1190000047497760</link>    <guid>https://segmentfault.com/a/1190000047497760</guid>    <pubDate>2025-12-23 16:05:50</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>近日，1024Foundation发起人冯雷（Ray Von），受邀在浙大EMBA项目、战略型企业家项目中，进行《从数字化到数智化：战略进阶和实践案例》讲座，通过生动的案例和详实的理论，深度阐述企业如何完成从软件公司，到数据公司，再到数学（AI模型）公司的数字化三部曲。</p><p><img width="723" height="549" referrerpolicy="no-referrer" src="/img/bVdnsuR" alt="" title=""/></p><p>Ray结合自身的连续创业实践，为同学们生动梳理了科技企业的技术演进脉络。在创立拓数派之前，他曾在硅谷主导全球知名开源数据库Greenplum的研发，并成功推动公司Pivotal在纽交所上市，成为“云原生第一股”。如今，在腾讯天使投资的支持下，他创办拓数派，深耕数据计算领域。公司旗下的大模型数据计算系统，能够实现数据与模型的自主耦合，助力企业构建专属的智能体工场。目前，拓数派已成功将产品应用于中国电子、中国船舶等核心央企的多类场景，并在金融、政务等领域积极推进“Data+AI”驱动的数智化转型。<br/>随后，Ray 通过三个极具代表性的案例展开深度解析：他详细讲述了 Pivotal 如何助力 GE、福特等传统巨头向软件驱动型企业转型；Greenplum 如何赋能宝马完成从制造企业到数据驱动企业的跨越；以及拓数派如何推动中国电子、中国船舶、杭实集团等本土标杆企业，迈入以 AI 模型为核心的新阶段，让在场听众对技术赋能产业变革的逻辑有了更直观、深刻的理解。</p><p><img width="723" height="549" referrerpolicy="no-referrer" src="/img/bVdnsuS" alt="" title="" loading="lazy"/></p><p>本次讲座，Ray不仅系统勾勒出企业数字化进阶的清晰路径，更通过其横跨中美、贯穿不同产业阶段的亲身实践，揭示了技术战略与商业价值深度融合的核心逻辑。讲座在热烈的互动中落下帷幕，而关于如何将数据转化为智能、将技术沉淀为竞争力的思考，仍在持续延展。未来，1024Foundation将持续推进AI4AI普及公益，以AI驱动决策，持续赋能企业，推动数智转型平稳落地。</p>]]></description></item><item>    <title><![CDATA[鸿蒙ArkTS深度解析：从特性到实战，构建分布式全场景应用 逐梦AI ]]></title>    <link>https://segmentfault.com/a/1190000047497781</link>    <guid>https://segmentfault.com/a/1190000047497781</guid>    <pubDate>2025-12-23 16:05:16</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>鸿蒙ArkTS深度解析：从特性到实战，构建分布式全场景应用</h2><p>随着鸿蒙生态的快速崛起，分布式全场景体验成为行业主流趋势，而ArkTS作为鸿蒙生态的核心开发语言，无疑是解锁这一趋势的关键钥匙。作为TypeScript的超集，ArkTS不仅继承了静态类型检查的优势，更针对分布式场景进行了深度定制，让"一次开发、多端部署"的开发范式落地变得简单高效。本文将从ArkTS的核心定位出发，拆解其关键特性，结合实战案例讲解开发流程，并给出针对性的学习建议，助力开发者快速上手鸿蒙原生开发。</p><h3>一、认识ArkTS：鸿蒙生态的"语言基石"</h3><p>在深入技术细节前，我们首先要明确ArkTS的核心定位。ArkTS全称为HarmonyOS Ark TypeScript，是华为专为鸿蒙应用及服务开发打造的面向对象编程语言，它基于TypeScript扩展而来，同时融入了鸿蒙分布式架构的适配特性，是鸿蒙生态统一开发范式的核心载体。</p><p>理解ArkTS的定位，需要理清它与JavaScript、TypeScript的关系：JavaScript是基础脚本语言，TypeScript通过添加静态类型成为其超集，而ArkTS则在TypeScript的基础上进一步扩展，增加了声明式UI、状态管理、分布式数据同步等核心能力，同时通过语法规范约束剔除了TypeScript中过于灵活的特性（如any类型、运行时对象布局修改等），确保代码的稳定性和执行性能。简单来说，ArkTS就是"为鸿蒙量身定制"的开发语言，解决了传统语言在跨设备协同开发中的适配难题。</p><h3>二、ArkTS核心特性：分布式开发的核心优势</h3><p>ArkTS的魅力在于其贴合分布式场景的核心特性，这些特性不仅降低了开发门槛，更提升了应用的性能和可维护性。以下是最关键的四大特性解析：</p><h4>1. 声明式UI：简化界面开发流程</h4><p>声明式UI是ArkTS最具代表性的特性之一，区别于传统命令式开发需要逐行编写UI渲染逻辑，声明式开发只需描述"UI应该是什么样子"，开发者通过组合组件、绑定数据状态，即可实现UI的自动更新。在ArkTS中，我们通过<code>@Component</code>装饰器定义自定义组件，通过<code>build()</code>方法描述UI结构，代码简洁直观，可读性极强。</p><p>示例代码如下：</p><pre><code class="typescript">// 自定义HelloWorld组件
@Entry
@Component
struct HelloWorld {
  // 定义状态变量
  @State message: string = 'Hello HarmonyOS!'

  build() {
    // 垂直布局容器
    Column() {
      // 文本组件，绑定状态变量
      Text(this.message)
        .fontSize(30)
        .fontWeight(FontWeight.Bold)
        // 点击事件
        .onClick(() =&gt; {
          this.message = 'Hello ArkTS!';
        })
    }
    // 占满整个屏幕
    .width('100%')
    .height('100%')
    // 居中对齐
    .justifyContent(FlexAlign.Center)
  }
}</code></pre><p>上述代码中，我们仅需描述UI的结构（垂直布局+文本）和数据绑定关系，当<code>message</code>状态变量发生变化时，UI会自动更新，无需手动操作DOM，极大简化了界面开发和状态管理的复杂度。</p><h4>2. 强类型检查：提升代码质量与效率</h4><p>ArkTS继承了TypeScript的静态类型特性，并在此基础上强化了类型约束——强制要求变量、函数参数等必须明确类型定义，不允许使用any、unknown等模糊类型，若参数可能为空，必须显式声明undefined类型。这种强类型约束能让编译器在编译阶段就发现类型不匹配等错误，避免了运行时异常，同时也让代码的可读性和可维护性大幅提升。</p><p>示例对比：</p><pre><code class="typescript">// TypeScript允许的写法（ArkTS中报错）
let data: any = '123';
data = 456; // 类型随意切换，编译不报错

// ArkTS强制要求的写法
let data: string = '123';
// data = 456; // 编译报错：类型不匹配
let optionalData: string | undefined = '123'; // 允许为空的显式声明</code></pre><h4>3. 分布式能力原生支持：实现多端无缝协同</h4><p>作为鸿蒙生态的专属语言，ArkTS内置了分布式数据管理、跨设备调用等API，开发者无需额外编写复杂的适配代码，就能轻松实现"一次开发、多端部署"，让应用在手机、平板、智能手表、车载系统等鸿蒙设备间无缝协同。例如，通过<code>DeviceManager</code>可实现设备发现与连接，通过<code>DistributedDataObject</code>可实现跨设备数据同步。</p><p>跨设备数据同步示例：</p><pre><code class="typescript">import distributedDataObject from '@ohos.distributedDataObject';

// 创建分布式数据对象
let distributedObject = new distributedDataObject.createDistributedDataObject({
  name: 'deviceSyncData',
  data: { playStatus: false, currentSong: '未知歌曲' }
});

// 监听数据变化（跨设备同步）
distributedObject.on('dataChange', (data) =&gt; {
  console.log(`跨设备数据更新：${JSON.stringify(data)}`);
});

// 修改数据（自动同步到其他设备）
distributedObject.set('playStatus', true);
distributedObject.set('currentSong', '鸿蒙之歌');</code></pre><h4>4. 轻量高效：适配全场景设备</h4><p>ArkTS搭配鸿蒙的ArkCompiler编译器，代码可直接编译为机器码运行，相比传统解释型语言，执行效率更高，内存占用更优。这一特性让ArkTS不仅能适配手机、PC等高性能设备，还能完美运行在智能音箱、智能门锁等轻量化智能设备上，真正实现了全场景设备覆盖。</p><h3>三、实战演练：用ArkTS开发分布式音乐控制组件</h3><p>为了让大家更直观地感受ArkTS的开发流程，我们以"分布式音乐控制组件"为例，实现手机端控制智能音箱播放音乐的核心功能。</p><h4>1. 需求分析</h4><ul><li>手机端扫描并发现局域网内的鸿蒙智能音箱设备；</li><li>手机端向智能音箱发送播放/暂停指令；</li><li>跨设备同步音乐播放状态（播放/暂停、当前歌曲）。</li></ul><h4>2. 核心实现步骤</h4><h5>步骤1：设备发现与连接</h5><pre><code class="typescript">import deviceManager from '@ohos.distributedDeviceManager';

@Component
struct DeviceDiscovery {
  @State deviceList: Array&lt;{deviceId: string, deviceName: string}&gt; = [];

  // 初始化设备管理器
  private initDeviceManager() {
    let dm = deviceManager.createDeviceManager();
    // 监听设备上线事件
    dm.on('deviceOnline', (device) =&gt; {
      console.log(`发现设备：${device.deviceName}（${device.deviceId}）`);
      this.deviceList.push({
        deviceId: device.deviceId,
        deviceName: device.deviceName
      });
    });
    // 开始扫描设备
    dm.startDeviceDiscovery();
  }

  build() {
    Column() {
      Text('可用设备')
        .fontSize(20)
        .margin(10);
      List() {
        ForEach(this.deviceList, (device) =&gt; {
          ListItem() {
            Text(device.deviceName)
              .padding(10)
              .onClick(() =&gt; {
                // 选中设备，跳转至控制界面
                router.pushUrl({
                  url: 'pages/ControlPage',
                  params: { deviceId: device.deviceId }
                });
              });
          }
        });
      }
    }
    .onPageShow(() =&gt; {
      this.initDeviceManager();
    });
  }
}</code></pre><h5>步骤2：跨设备音乐控制</h5><pre><code class="typescript">import rpc from '@ohos.rpc';
import distributedDataObject from '@ohos.distributedDataObject';

@Component
struct MusicControl {
  // 接收选中的设备ID
  private deviceId: string = router.getParams().deviceId;
  // 分布式数据对象（同步播放状态）
  private syncData = new distributedDataObject.createDistributedDataObject({
    name: 'musicSync',
    data: { isPlaying: false, currentSong: '鸿蒙之歌' }
  });

  // 发送播放指令
  private playMusic() {
    // 调用远程设备的播放接口
    rpc.callRemoteMethod('playMusic', {
      songId: '123456',
      deviceId: this.deviceId
    }).then(() =&gt; {
      console.log('播放指令发送成功');
      // 更新同步状态
      this.syncData.set('isPlaying', true);
    }).catch((err) =&gt; {
      console.error(`播放失败：${err.message}`);
    });
  }

  // 发送暂停指令
  private pauseMusic() {
    rpc.callRemoteMethod('pauseMusic', {
      deviceId: this.deviceId
    }).then(() =&gt; {
      console.log('暂停指令发送成功');
      this.syncData.set('isPlaying', false);
    }).catch((err) =&gt; {
      console.error(`暂停失败：${err.message}`);
    });
  }

  build() {
    Column() {
      Text(`当前控制设备：${this.deviceId}`)
        .margin(10);
      Text(`当前歌曲：${this.syncData.get('currentSong')}`)
        .fontSize(18)
        .margin(10);
      Text(`播放状态：${this.syncData.get('isPlaying') ? '播放中' : '已暂停'}`)
        .margin(10);
      Row() {
        Button('播放')
          .onClick(() =&gt; this.playMusic())
          .margin(10);
        Button('暂停')
          .onClick(() =&gt; this.pauseMusic())
          .margin(10);
      }
    }
    .width('100%')
    .height('100%')
    .justifyContent(FlexAlign.Center);
  }
}</code></pre><h4>3. 关键技术点说明</h4><ul><li>设备管理：通过<code>deviceManager</code>接口实现设备发现与状态监听；</li><li>跨设备通信：使用<code>rpc.callRemoteMethod</code>实现远程设备接口调用；</li><li>状态同步：借助<code>DistributedDataObject</code>实现播放状态的跨设备同步。</li></ul><h3>四、ArkTS学习路径与资源推荐</h3><p>对于开发者而言，当前鸿蒙生态正处于快速发展期，掌握ArkTS已成为职业竞争力的重要加分项。结合官方资源和实战经验，推荐以下学习路径：</p><h4>1. 基础阶段：夯实语言基础</h4><ul><li>掌握JavaScript核心语法（变量、函数、对象、异步编程等）；</li><li>学习TypeScript基础（静态类型、接口、泛型等），理解其与JavaScript的差异；</li><li>熟悉ArkTS的语法规范，重点关注其与TypeScript的区别（如强制静态类型、禁止运行时对象布局修改等）。</li></ul><h4>2. 进阶阶段：核心能力突破</h4><ul><li>深入学习ArkUI声明式UI框架，掌握组件、布局、状态管理等核心能力；</li><li>研究分布式开发相关API，理解设备协同、数据同步的实现原理；</li><li>通过官方实战案例练习，提升代码编写和问题排查能力。</li></ul><h4>3. 推荐学习资源</h4><ul><li>官方文档：华为开发者联盟（<a href="https://link.segmentfault.com/?enc=TEd7s42LKTySglJWRcPXGA%3D%3D.Xt4HJS77gKS1TmHImkcCTcYB2b8CtrjNv2t2vDCBp3faOxkoTIGN%2B%2BqA4qnf1LSE" rel="nofollow" target="_blank">https://developer.huawei.com/consumer/cn/</a>），提供完整的ArkTS语法、API文档和教程；</li><li>开发工具：DevEco Studio，集成ArkTS编译器、多设备模拟器、调试工具等，是鸿蒙开发的必备工具；</li><li>实战项目：华为开发者联盟的"鸿蒙原生应用开发实战"系列教程，包含多个完整的项目案例。</li></ul><h3>五、总结与展望</h3><p>ArkTS作为鸿蒙生态的核心开发语言，凭借声明式UI、强类型检查、原生分布式支持、轻量高效等特性，为分布式全场景应用开发提供了高效、可靠的解决方案。对于开发者而言，掌握ArkTS不仅能快速切入鸿蒙生态，更能把握物联网时代全场景开发的技术趋势。</p><p>随着鸿蒙生态的持续壮大，ArkTS也将不断演进，未来有望在并行并发能力、系统类型增强、分布式开发范式优化等方面带来更多突破。如果你还未接触过鸿蒙开发，不妨从ArkTS开始，开启你的分布式全场景开发之旅！</p>]]></description></item><item>    <title><![CDATA[AI生图告别"开盲盒"：阿里开源Qwen-Image-Layered让机器拥有Photoshop思维]]></title>    <link>https://segmentfault.com/a/1190000047497810</link>    <guid>https://segmentfault.com/a/1190000047497810</guid>    <pubDate>2025-12-23 16:04:46</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <blockquote>2025年12月22日，阿里巴巴通义实验室开源全新图像生成模型Qwen-Image-Layered，首次在模型内实现Photoshop级的图层理解与图像生成——这意味着，AI不再把图片当作扁平的像素点阵，而是像专业设计师一样，能"脑补"出图像的立体结构和空间关系。这一突破标志着视觉大模型从"像素预测"迈向"结构重组"，或将彻底改写数字创意产业的生产逻辑。</blockquote><h3>技术内核：给AI装上"分层视觉"</h3><p>传统AI生图最大的痛点是"牵一发而动全身"。你想把画面里的猫向左移动10厘米，AI却不知道猫挪走后背景该是什么，只能重新生成整张图，结果猫和背景全变了样。这种随机性让AI在设计、影视等需要精准控制的领域始终只能是辅助工具。</p><p>Qwen-Image-Layered的破解之道是RGBA-VAE编码。技术报告显示，团队在传统的RGB三通道中加入了代表透明度的Alpha通道，让模型天生具备"图层"概念。配合创新的VLD-MMDiT架构和独特的图层级3D位置编码，AI能自动理解物体间的遮挡关系，并"脑补"被遮挡部分的背景纹理。更关键的是，训练数据来自海量专业Photoshop（PSD）文件，让模型从出生就浸染在设计师的"分层思维"中。</p><p>实测效果堪称惊艳。模型可将任意图像分解为3-8个RGBA图层，用户能对单个图层重新着色、替换人物、修改文字、删除物体或自由缩放移动，而其他部分完全不受影响。这种"零漂移"编辑能力，解决了困扰行业已久的"一致性难题"。<br/><img width="600" height="358" referrerpolicy="no-referrer" src="/img/bVdnsvO" alt="image.png" title="image.png"/></p><h3>场景革命：从"抽卡游戏"到"活素材库"</h3><p>对创意产业而言，Qwen-Image-Layered带来的不是效率提升，而是范式转移。过去AI生图像抽卡"开盲盒"，现在则成为"可无限调整的活素材库"。设计师无需再为抠图耗费数小时，动画师可在保持背景不变前提下重绘角色动作，影视后期人员能精准替换画面元素而不穿帮。</p><p>这一变革早有伏笔。早在2025年8月，阿里开源的Qwen-Image模型已在复杂文本渲染能力上实现突破，支持多行布局、段落级文本生成，在中文场景生成中大幅领先现有模型。而12月的新版本将能力从"生成"延伸至"编辑"，补上了关键拼图。</p><h3>结构重组为何比像素预测更重要？</h3><p>Qwen-Image-Layered的价值，在于它让AI真正理解了物理世界的层级与空间。主流视觉大模型的"扁平式思维"本质上是统计学游戏——预测下一个像素该是什么颜色。而"结构重组"则是让AI建立对物体、空间、遮挡关系的认知模型，这更接近人类的视觉理解方式。</p><p>从商业角度看，这步棋精准卡位了专业设计市场的爆发点。当AI生成内容的质量普遍达标后，可控性成为付费意愿的关键。模型已上线魔搭社区和Hugging Face，全球开发者可免费商用。考虑到阿里已开源近400个千问模型、累计下载量超7亿次，Qwen-Image-Layered有望快速构建生态壁垒，吸引更多设计师和内容创作者进入其AI服务体系。</p><p>图像生成领域的竞争已从"谁画得更像"转向"谁更能服服帖帖地改"。阿里选择开源这一核心技术，不仅是在展示肌肉，更是在邀请全行业共同定义"可编辑AI内容"的新标准。当越来越多的创意工作流程建立在"图层化AI"之上，中国的大模型生态或将从追赶者变为规则制定者。毕竟，在AI时代，最稀缺的不是算力，而是对真实世界结构的理解能力——而这，恰恰是Qwen-Image-Layered最锋利的地方。</p>]]></description></item><item>    <title><![CDATA[什么是分布式数据库？一文了解分布式数据库 星环科技 ]]></title>    <link>https://segmentfault.com/a/1190000047497859</link>    <guid>https://segmentfault.com/a/1190000047497859</guid>    <pubDate>2025-12-23 16:03:47</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>随着数字化转型的深入，企业所面对的数据规模、访问并发和业务复杂度持续攀升，传统集中式数据库在扩展性、可用性和性能方面逐渐显现瓶颈。分布式数据库正是在这样的背景下产生的一种新型数据库架构，它通过将数据和计算能力分布到多台服务器上，实现对海量数据的高效管理和稳定服务，成为现代数据基础设施的重要组成部分。</p><h3>什么是分布式数据库？</h3><p>分布式数据库是指数据在逻辑上属于同一个数据库系统，但在物理上分布存储在多台计算节点上的数据库系统。这些节点通过网络连接，在系统层面进行统一管理和调度，对外呈现为一个完整、透明的数据库服务。</p><p>与传统数据库不同，分布式数据库并不依赖单一服务器来存储和处理所有数据，而是通过多节点协同工作，实现数据的横向扩展、高可用和容错能力。用户在使用分布式数据库时，无需关心数据具体存放在哪个节点，数据库系统会自动完成数据路由、查询优化和一致性维护。</p><h3>分布式数据库是如何工作的？</h3><p>分布式数据库的核心工作机制在于数据拆分、分布式计算和一致性协调。首先，系统会按照一定规则将数据进行拆分（如按行、按范围或按哈希），并分布存储到不同节点上。每个节点既负责本地数据的存储，也承担部分计算任务。</p><p>当用户发起查询或事务请求时，分布式数据库会通过协调节点解析请求，将其拆解为多个子任务，并分发到相关数据节点执行。各节点并行处理后，再将结果汇总返回给用户。同时，系统通过分布式事务协议、一致性算法或日志复制机制，确保数据在多个副本之间保持一致。</p><h3>分布式数据库的用途是什么？</h3><p>分布式数据库的主要用途是支撑大规模、高并发和高可靠性的业务系统。能够满足企业在数据量快速增长、访问压力持续增大的情况下，对系统稳定性和性能的要求。</p><p>在互联网、金融、电信、制造、政务等行业，分布式数据库常被用于承载核心业务数据、分析型数据以及混合负载数据，帮助企业构建可持续扩展的数据底座，避免因硬件或节点故障导致业务中断。</p><h3>分布式数据库与传统数据库（集中式）比较</h3><p>传统集中式数据库通常部署在单一服务器或小规模集群上，数据集中存储，系统结构相对简单，但扩展能力有限。当数据规模或并发请求超过单机能力时，往往需要通过升级硬件来“纵向扩展”，成本高且存在上限。<br/>分布式数据库则采用“横向扩展”思路，通过增加节点来提升整体性能和容量。在可扩展性、容错能力和高可用性方面具有明显优势，但系统实现和运维复杂度相对更高，对架构设计和管理能力要求也更高。</p><table><thead><tr><th>对比维度</th><th>分布式数据库</th><th>传统数据库（集中式）</th></tr></thead><tbody><tr><td>架构模式</td><td>多节点分布式架构，数据与计算分散在多台服务器上</td><td>单机或小规模集中式架构，数据集中存储</td></tr><tr><td>扩展方式</td><td>横向扩展，通过增加节点提升性能和容量</td><td>纵向扩展，依赖升级 CPU、内存、存储等硬件</td></tr><tr><td>可扩展性</td><td>高，可随业务增长线性扩展</td><td>有限，受单机硬件上限制约</td></tr><tr><td>可用性</td><td>多副本机制，支持故障自动切换，高可用</td><td>单点故障风险高，需要额外主备或容灾方案</td></tr><tr><td>性能特征</td><td>多节点并行计算，适合高并发和大数据量场景</td><td>单节点处理，适合中小规模并发和数据量</td></tr><tr><td>数据一致性</td><td>通过分布式事务或一致性协议保障</td><td>天然强一致性，机制相对简单</td></tr><tr><td>系统复杂度</td><td>架构复杂，对设计和运维要求较高</td><td>架构简单，部署和管理成本较低</td></tr><tr><td>运维难度</td><td>较高，需要监控节点、网络和数据分布</td><td>较低，主要关注单实例运行状态</td></tr><tr><td>成本结构</td><td>可使用通用硬件，长期扩展成本可控</td><td>高端硬件成本高，扩容性价比低</td></tr><tr><td>适用场景</td><td>海量数据、高并发、核心业务系统</td><td>中小规模业务、单体或简单应用</td></tr></tbody></table><h4>分布式数据库功能</h4><p>一个成熟的分布式数据库通常具备以下核心功能：<br/>能够支持自动数据分片与负载均衡，避免热点问题；提供多副本机制，确保数据可靠性和高可用；支持分布式事务或最终一致性模型，满足不同业务一致性需求；同时还具备统一的 SQL 接口、权限管理、监控与运维能力，使用户能够像使用传统数据库一样使用分布式数据库。</p><h4>分布式数据库的优势</h4><p>分布式数据库最大的优势在于可扩展性和高可用性。通过增加节点即可提升系统处理能力，使数据库能够伴随业务增长持续扩展。同时，多副本和故障自动切换机制，使系统在部分节点宕机时仍能正常对外服务。<br/>此外，分布式数据库还能充分利用多节点并行计算能力，在大规模数据分析和复杂查询场景中显著提升性能，帮助企业降低整体 IT 成本。</p><h4>分布式数据库的挑战</h4><p>尽管优势明显，分布式数据库也面临不少挑战。首先是系统复杂度显著提高，涉及数据一致性、网络延迟、分布式事务等问题。其次，在跨节点事务和复杂查询场景下，性能优化难度较大。<br/>此外，对运维人员而言，分布式数据库在部署、监控、调优和故障排查方面都比传统数据库更具挑战性，需要配套的工具和成熟的运维体系。</p><h4>分布式数据库的类型</h4><p>从数据模型角度看，分布式数据库可以分为分布式关系型数据库和分布式非关系型数据库（NoSQL）。前者强调 SQL 兼容性和事务支持，后者则更关注扩展性和灵活的数据结构。<br/>从应用负载角度看，又可分为面向 OLTP 的事务型分布式数据库、面向 OLAP 的分析型分布式数据库，以及同时支持事务与分析的 HTAP 分布式数据库。 </p><h4>分布式数据库架构</h4><p>典型的分布式数据库架构通常采用计算与存储解耦或共享无设计。系统由协调节点、计算节点和存储节点组成，通过统一的元数据管理和调度机制，实现资源的灵活分配。<br/>这种架构不仅有利于弹性扩展，还能根据业务负载特征，对计算和存储资源进行独立扩容，提高资源利用效率。</p><h4>分布式数据库的应用场景</h4><p>分布式数据库广泛应用于高并发在线交易系统、实时数据分析平台、日志与行为数据分析、金融风控系统、物联网数据管理等场景。在这些场景中，数据规模大、访问频繁，对系统稳定性和实时性要求极高，分布式数据库能够提供更可靠的支撑。</p><h3>如何选择分布式数据库</h3><p>在选择分布式数据库时，企业需要综合考虑业务类型、数据规模、一致性要求和运维能力。如果业务对事务一致性要求高，应优先考虑成熟的分布式关系型数据库；如果更关注吞吐量和扩展性，则可以考虑 NoSQL 或分析型分布式数据库。<br/>同时，还应关注产品的生态成熟度、社区活跃度、厂商支持能力以及与现有系统的兼容性。</p><h3>国产分布式数据库产品有哪些？</h3><p>Transwarp ArgoDB是星环科技自主研发的分布式数据库，融合了高并发事务处理和实时分析能力，横向灵活扩展满足业务的弹性变化需求。ArgoDB 在兼容主流 SQL 标准的基础上，扩展支持 OLAP 语法和存储过程，兼容 MySQL、Oracle 等多种数据库方言，并与国内外主流数据库和工具高度兼容，为用户提供全面的数据库开发支持，具备高扩展、高性能、高安全、高可用、高兼容、易运维等特性，已助力政府、金融、医疗、交通等多个行业用户实现自主创新升级。</p><h3>分布式数据库常见问答</h3><p><strong>Q1：分布式数据库是否一定比传统数据库快？</strong><br/>不一定。分布式数据库在大规模数据和高并发场景下优势明显，但在小规模、简单业务中，传统数据库可能更高效。<br/><strong>Q2：分布式数据库是否支持事务？</strong><br/>支持。许多分布式关系型数据库提供完整的分布式事务能力，但实现方式和性能开销与单机事务有所不同。<br/><strong>Q3：分布式数据库适合哪些企业？</strong><br/>分布式数据库更适合数据规模大、业务并发高、对系统稳定性和扩展性要求高的企业，例如互联网与平台型公司、金融与支付机构、电商与零售企业、政企和运营商，以及正在推进数据中台和数字化转型的大中型企业。这类企业通常需要在多地域部署系统，支撑海量数据存储与高并发访问，同时具备横向扩展、容灾高可用和在线扩容能力，分布式数据库能够更好地满足其持续增长和复杂业务场景的需求。</p>]]></description></item><item>    <title><![CDATA[怎么实现模具智能管理来降低冲压设备停机率？ 月下水光 ]]></title>    <link>https://segmentfault.com/a/1190000047497872</link>    <guid>https://segmentfault.com/a/1190000047497872</guid>    <pubDate>2025-12-23 16:03:02</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在工业4.0的深度演进中，模具——这一制造业的“隐形核心”——正经历一场前所未有的身份蜕变。它不再仅仅是被反复使用、磨损后更换的消耗性工具，而是演变为具备自我表达能力、可预测寿命、能参与生产决策的智能资产。这场变革的核心，正是“模具智能管理”的全面落地，而广域铭岛作为行业先锋，正以技术与理念的双重创新，引领这场从“经验驱动”迈向“数据驱动”的深刻转型。<br/>传统模具管理长期依赖人工经验与固定周期，如“每三个月保养一次”或“出问题再修”，结果往往是“过维护”浪费资源、“欠维护”引发停机。据统计，超六成的模具故障源于微小隐患未被及时发现，而维修记录、冲压数据、停机事件等关键信息又分散在ERP、MES等孤立系统中，形成“数据孤岛”，让决策如盲人摸象。这种低效模式不仅推高了维护成本，更严重制约了生产稳定性与产品一致性。<br/>模具智能管理的破局之道，在于构建一个以数据为神经、AI为大脑的闭环系统。广域铭岛推出的GQCM模具智能管理APP与Geega工业AI平台，正是这一理念的实践载体。系统通过部署在模具与压机上的传感器网络，实时采集冲压次数、温度、振动、压力等多维数据，结合材料特性、产品复杂度、历史维修知识图谱，动态计算每副模具的“设备健康指数”（EHI）。这一指数不再是抽象指标，而是模具的“生命体征”——当某副用于生产高光件的注塑模具因表面易划伤，EHI值升高，系统会自动将保养周期从30天缩短至15天；当高强度钢模具因应力累积预警导柱磨损，系统即推送“更换导柱+优化润滑”的精准方案，实现从“定时体检”到“精准诊疗”的跃迁。<br/>更深远的价值在于协同与预测。广域铭岛的工业智造超级智能体，如同一个具备自主学习能力的“数字大脑”，能联动生产排程、库存管理与供应链系统。当某模具即将达到维护阈值，系统可提前48小时自动调整产线任务，将订单切换至健康模具，避免突发停机；一旦传感器报警，15分钟内即可生成包含设备切换、参数调整的应急方案。在领克汽车成都工厂，这一系统将故障响应时间从2小时压缩至15分钟，模具相关停机减少65%，润滑剂消耗下降18%，备件库存周转率提升40%。更重要的是，每副模具的全生命周期数据被完整记录，质量问题可追溯至具体保养环节，知识不再随技师退休而流失，而是沉淀为企业可复用的数字资产。<br/>这一模式已超越汽车行业，在家电、工程机械等领域广泛复制：大型覆盖件模具寿命从8万次提升至12万次，新模具开发周期缩短40%，甚至在芯片短缺危机中，系统能基于3000组模具状态数据，智能分配稀缺资源至故障风险最低的产线，保障核心交付。<br/>模具智能管理的本质，是工业文明范式的重构。它不再满足于“记录”与“提醒”，而是通过感知、分析、决策、执行、学习的完整闭环，让沉默的钢铁学会“说话”，让混沌的生产重获秩序。广域铭岛所代表的，不是一款软件的升级，而是一整套“数据+AI+协同”的新工业哲学：模具，应被理解、被预测、被珍视。未来，随着5G、边缘计算与数字孪生技术的深度融合，模具的“数字分身”将在虚拟空间中模拟百万次冲压，AI智能体将通过“自我对弈”持续优化策略，实现“一处学习，全网受益”的群体智能。</p>]]></description></item><item>    <title><![CDATA[2025实时云渲染产业全景洞察与趋势报告 点量实时云渲染 ]]></title>    <link>https://segmentfault.com/a/1190000047497878</link>    <guid>https://segmentfault.com/a/1190000047497878</guid>    <pubDate>2025-12-23 16:02:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>随着数字中国战略的深入以及人工智能、高性能计算等新一代信息技术的融合爆发，实时云渲染作为连接物理与数字世界的核心架构，其战略意义与应用深度正不断拓展。长期以来，该技术不仅是工业仿真、数字孪生、智慧城市等领域智能化升级的基石，更在“人工智能+”行动与数字经济政策推动下，走向赋能千行百业的广阔空间。本文梳理了2025年行业演进与前瞻技术趋势，点量云流实时云渲染正为各领域“数字视界”的建立，提供强有力的支撑。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdnsvP" alt="" title=""/></p><h3>一、政策引领与市场共振：产业规模化落地新周期</h3><p>国家层面对于数字经济、新质生产力及信创产业的持续政策支持，为实时云渲染提供了明确的战略导向和肥沃的应用土壤。产业数字化与数字产业化“双轮驱动”，促使制造业、建筑业、文旅教育等领域对高精度、可交互、协同化的三维可视化需求激增。市场要求能够有跨终端、实时交互的云端渲染能力，以打破硬件桎梏，实现数据与模型的深度应用与价值挖掘。<br/><img width="723" height="407" referrerpolicy="no-referrer" src="/img/bVdnsvW" alt="" title="" loading="lazy"/></p><h3>二、技术架构深化：从“云端计算”到“云-边-端协同”</h3><p>实时云渲染的产业链已形成从底层IaaS算力、云渲染平台、软件引擎到上层行业应用服务的完整生态。2025年的技术焦点，已超越基础的“将计算迁移至云端”，演进为“云-边-端协同”的精细化调度。这要求平台不仅具备强大的云端并行渲染与编码能力，更需要智能的网络传输优化、边缘节点部署及对异构终端（网页、移动端、XR设备等）的极致适配能力，以保障在复杂网络环境下始终如一的低延迟与高画质交互体验。</p><h3>三、核心能力突破：信创化、多开隔离与全应用流化</h3><p>技术的成熟度决定应用落地的广度。当前，领先的实时云渲染解决方案正围绕三大核心能力展开竞争：</p><ul><li><strong>全栈信创兼容：</strong>全面支持国产操作系统（如麒麟、统信等）与CPU架构，是保障关键行业数据安全与供应链自主可控的必由之路。</li><li><strong>大并发稳定支撑：</strong>通过类似“应用cell多开隔离”的技术，实现单台服务器上多实例应用的稳定、隔离运行，有效提升资源利用率与大规模并发支持能力。</li><li><strong>全应用生态覆盖：</strong>突破对特定游戏引擎的依赖，能够将包括Windows/Linux常规专业软件、自研应用及各类三维引擎内容（UE、Unity）推流为可跨端访问的视频流，极大扩展了技术边界。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdnswy" alt="" title="" loading="lazy"/></li></ul><h3>四、点量云流实时云渲染赋能产业创新</h3><p>在众多实践者中，点量云流作为国内首家实现全栈信创的实时云渲染平台，提供了颇具代表性的产业级解决方案。其核心价值在于，将部署在服务器（包括国产信创服务器）上的复杂3D应用或大型软件，实时编码推流成视频流。用户无需下载，即可通过任意终端的浏览器或轻量客户端，以接近本地的操作延迟进行交互。</p><p><strong>点量云流核心功能&amp;特点：</strong></p><ul><li><strong>开箱即用的部署效率：</strong>三分钟简单安装，极大降低了企业首次使用云渲染技术的门槛和周期。</li><li><strong>深入场景的功能适配：</strong>针对数字孪生、虚拟仿真、云协同设计等场景，提供私有化部署、负载均衡、P2P快速分发及丰富的API/SDK，支持与企业现有系统深度集成与二次开发。</li><li><strong>安全可靠的数据留存：</strong>“数据在云端”实现了多用户文件隔离与外部设备透传，让高性能图形应用在云端安全、流畅运行成为可能。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdmT11" alt="" title="" loading="lazy"/></li></ul><p>2025年，实时云渲染技术正站在从“技术成熟化”迈向“价值新创造”的关键节点。其发展轨迹清晰地指向更普适的接入、更智能的调度、更广泛的兼容与更深入的融合。点量云流实时云渲染平台，通过夯实全栈信创根基、攻克高并发稳定性难题、拓展全应用流化边界，正在为千行百业的数字化、智能化转型提供坚实且灵活的技术底座。未来，随着技术与场景的持续碰撞，点量云流实时云渲染必将更深刻地重塑我们创建、交互与理解数字世界的方式！</p>]]></description></item><item>    <title><![CDATA[LLM微调后回答不准还花天价？三步调教出你的“高智商”行业AI模型 DigitalOcean ]]></title>    <link>https://segmentfault.com/a/1190000047497886</link>    <guid>https://segmentfault.com/a/1190000047497886</guid>    <pubDate>2025-12-23 16:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>大型语言模型已经变得非常强大，但现成的模型往往在特定领域/应用上有所不足。LLM 微调是在自定义数据集上进一步训练预训练 LLM，使其专门针对特定任务/领域的过程。微调使你能够注入领域知识，使模型的语调/风格与你的品牌保持一致，并在特定任务上超越通用模型的性能。微调利用了模型的现有知识，节省了从头开始训练模型的巨大成本。</p><p>基础模型比以往任何时候都更强大，但要获得真正的价值，定制化至关重要。微调有助于让你的模型听起来像你公司的行话，理解你的特定语境，并满足严格的准确性或语调准则。为你的用例微调一个较小的模型，可能比通过 API 为每个请求调用一个大型通用模型要便宜得多。在本速成课程中，我们将涵盖相关概念、工具、PEFT（LoRA、QLoRA）、最佳实践和现实世界的例子。</p><h2>文章要点</h2><ul><li>微调通过注入特定任务的数据、术语、语调和约束，将通用 LLM 转变为领域专家——通常比依赖大型通用 API 提供更高的准确性和更低的推理成本。</li><li>并非每个问题都需要微调：提示工程适用于快速迭代，RAG 更适合快速变化的知识，而当行为、风格、延迟、隐私或离线使用真正重要时，微调是最佳选择。</li><li>参数高效微调（PEFT）是实践中的默认选项。像 LoRA 或 QLoRA 这样的技术使得能够用小型 GPU、极少量的可训练参数来微调大模型，并降低了灾难性遗忘的风险。</li><li>你的数据质量和评估方法比模型大小更重要：一个精心策划、具有代表性的训练数据集和一个健壮的评估流程（定量评估和人工评审的结合）是微调成功的最主要驱动力。</li><li>微调是一个生命周期，而非一次性任务：生产级系统需要监控、版本控制、回滚计划以及定期重新训练或数据收集，以确保长期的安全性、可靠性和高投资回报率。</li></ul><h2>你必须首先理解的关键概念</h2><p>在深入工作流程之前，让我们先了解一些关于 LLM 微调的基础概念和术语。</p><h2>预训练 vs. 微调 vs. 对齐</h2><p><strong>预训练</strong>是使用自监督学习在广泛语料库上对 LLM 进行的首次训练。此时，模型学会对一般语言进行建模（例如，预测数十亿个句子中的下一个单词）。预训练是无监督的，并且非常昂贵（想想训练 GPT 规模模型所需的数十亿美元计算资源）。</p><p><strong>微调</strong>发生在预训练之后。它是迁移学习的一种形式。你拿取预训练的模型（该模型具有“一般性知识”），并针对更具体的任务，在更具体、带标签的数据集上进一步训练它。微调是一个有监督的学习过程——你给模型提供示例输入和期望的示例输出（该任务的“真实情况”）并调整模型以产生这些输出。例如，在对互联网上所有文本进行预训练后，你可以在法律问答对的数据集上微调模型，以构建一个法律助手。</p><p><strong>对齐</strong>是一系列训练步骤，旨在调整模型的行为以更好地匹配人类意图、道德或偏好。最著名的对齐技术是<strong>基于人类反馈的</strong> <strong>强化学习</strong>。在 RLHF 中，在以监督方式进行微调之后，你使用人类评估员对模型的输出提供反馈，然后进一步训练模型以产生评分更高的输出。这是一种让模型不仅更具任务效能，而且根据人类评审员的定义，更乐于助人、无害和诚实的方法。对齐通常利用诸如先训练一个奖励模型（用于为输出评分），然后使用强化学习对 LLM 进行微调以优化该奖励分数的技术。</p><p>总结来说，预训练赋予模型通用能力，微调教给它特定任务的技能，而 RLHF 等对齐技术则调整其行为，使其对用户来说合适且安全。这些阶段之间的区别可能有些模糊（例如，指令调优既可以描述为微调也可以描述为对齐），但记住这些差异仍然是有帮助的。</p><p><strong>持续预训练</strong>（也称为领域自适应预训练）是一种相关方法。你在目标领域的无标签数据上继续训练模型以吸收行话，然后进行有监督的微调。这与常规微调的不同之处在于它是无监督的；它更像是使用专门文本对原始预训练的延伸。持续预训练可用于加深模型的领域知识，而微调则针对特定任务提高其性能。</p><h2>有监督微调 &amp; 指令调优</h2><p><strong>有监督</strong>微调是最简单的一种微调：你拥有输入和输出的配对，并且训练模型根据输入生成期望的输出。输出可以是分类标签、提示的预期续写等等。在客户电子邮件（输入）和最佳答案（输出）对的数据集上微调 GPT-3 就是有监督微调；模型学会将电子邮件作为输入并产生正确的响应。SFT 需要大量高质量的标注数据（创建成本可能很高），但对于定义明确的任务效果很好。</p><p><strong>指令</strong>调优是 SFT 的一种特定情况，其中数据集包含指令和理想响应。这种微调的目的是提高 LLM 遵循自然语言指令的能力。</p><p>在实践中，当为当今大多数应用程序微调模型时，你可能会使用一个经过指令调优的基础模型，并在你的领域指令上进一步微调（这实际上是特定领域的指令调优）。例如，你可能从一个模型的“instruct”版本（例如 Llama-2-13b-chat）开始，并在你公司的问答对上对其进行微调。在这种情况下，模型已经知道如何响应指令；现在你教它如何给出你类型的答案。这比微调原始模型效果更好，所需数据更少。模型已经具备遵循提示的通用能力。</p><h2>参数高效微调基础（LoRA、QLoRA、适配器）</h2><p>微调 LLM 的一个主要挑战是其规模。“完整”的微调会重新训练模型中的所有参数。对于一个 7B 的模型，这代表需要更新数十亿个权重（确实如此），而对于 70B 及更大的模型，数量级更高。这意味着仅仅为了模型和优化器就需要巨大的 GPU 内存(例如 <a href="https://link.segmentfault.com/?enc=z%2Bg1kH5l3XidptMh5lmYvA%3D%3D.Ukmiuq3o15Nb%2FB0q8ggBjjtUqvkm7ulvfOc6ZpiQl4xJzv2S6%2Flny%2FBFZ6dxOLO0" rel="nofollow" target="_blank">DigitalOcean 云平台的NVIDIA B300云服务器</a>），同时也存在过拟合或灾难性遗忘模型预训练能力的风险。<strong>参数高效微调</strong>应运而生：这是一组技术，它们只调整模型的一小部分参数，从而极大地减少资源需求。</p><p>使用 PEFT，你不是修改模型中 100% 的权重，而是添加一些小的适配器权重或低秩分解矩阵，并且只训练这些部分，同时让原始模型权重大部分保持冻结。这导致需要更新的参数数量少得多（通常 &lt;1%），内存使用更低，并且能够在单个 GPU 上微调非常大的模型。</p><p>两种流行的 PEFT 方法是 <strong>LoRA</strong> 和 <strong>QLoRA</strong>：</p><ul><li><strong>LoRA</strong> <strong>（低秩自适应）：</strong> 这种 PEFT 方法涉及将小型学习矩阵添加到模型的权重矩阵中。其思想（Hu 等人，2021）是适应模型所需的变化存在于一个低维子空间中。LoRA 不完全更新大小为 NxN 的权重矩阵 W0，而只学习两个小得多的矩阵 A 和 B（大小为 Nxr 和 rxN），使得 W0 + A*B 是微调后权重的良好近似。r 代表低秩（例如 4、8 或 16）。这大大减少了可训练参数的数量——例如，一个约有 59 万个参数的密集层可以用 &lt;7k 的总 LoRA 参数进行微调。此外，由于只有 A 和 B 有梯度，梯度和优化器的内存使用量很小，并且原始权重从不改变（避免了一些遗忘）。</li><li><strong>QLoRA（量化</strong> <strong>LoRA</strong> <strong>）：</strong> QLoRA 是一种相关方法，它在训练期间将基础模型的权重量化为 4 位精度。通常，要微调一个大模型，你会以 16 位或 32 位浮点精度加载它，这需要大量内存。QLoRA 使用 4 位整数值加载模型（同时使用一些技巧在保持准确性的前提下做到这一点），然后在上面应用 LoRA。这可以将内存使用量减少几个数量级——突然间，可以使用 QLoRA 在具有足够 VRAM 的单个 GPU 上微调 30B 或 65B 的模型。量化模型的权重是冻结的（通常完全不反向传播到 4 位权重，或以有限的方式进行），而你仍然以 16 位训练 LoRA 适配器权重。</li></ul><p>除了 LoRA/QLoRA，PEFT 还可以涵盖其他方法，例如<strong>适配器</strong>（在每个 Transformer 块中插入的小型前馈模块，仅训练这些模块而冻结主权重）或<strong>提示调优</strong>（学习软提示向量）。然而，就微调 LLM 而言，LoRA 风格的方法是目前最主流的方法，因为它们在简单性和有效性之间取得了良好的平衡。我们将在工作流程中展示如何使用它们。</p><h2>决策清单：你 <em>真的</em> 需要微调吗？</h2><p>在投入微调之前，请评估以下因素：</p><ul><li><strong>领域特异性</strong> – 你的用例是否是一个非常特定领域的用例，可能包含基础模型不熟悉的词汇或风格/术语？微调在这种情况下非常适用，因为它能够整合特定领域的知识/小众术语/行话。</li><li><strong>知识更新频率</strong> – 你的用例是否需要知识变化/频繁变化？如果是这样，微调可能是一个维护噩梦（你将不得不经常重新训练和重新部署）。对于动态信息（实时产品库存？每日新闻？），RAG 在此类用例中更有用。</li><li><strong>延迟和离线要求</strong> – 是否需要极低延迟，甚至无需外部调用的本地推理？微调后的模型将能够完全离线在你自己的硬件上运行，并且几乎可以即时回答（而 RAG 则需要检索文档）。这对于隔离部署或具有毫秒级延迟要求的情况来说是一个优势。RAG 的额外步骤会引入额外的延迟。</li><li><strong>隐私和合规性</strong> – 模型是否会处理敏感数据（客户数据、专有文档/文本）？使用微调且自托管的模型允许你将所有处理完全保持在内部。RAG 可以自托管，但微调是确保模型本身“内化”私有知识的唯一方式（在这种情况下 RAG 并不是一个真正的选择）。如果使用 RAG，模型将调用外部源，你需要自己托管该外部源。</li><li><strong>推理成本和规模</strong> – 微调模型允许使用更短的提示，因此每个请求的成本比增加检索开销的 RAG 要低。</li></ul><h2>怎么决定何时该微调 LLM ？</h2><p>微调是一项强大的技术，但它并不总是正确的解决方案。考虑它与其他方法的比较：</p><h3>微调 vs. 提示工程</h3><p>提示工程是编写模型输入以影响模型输出的过程。它不会改变模型参数本身。提示工程迭代速度快，无需训练：你只需编写指令或示例。它也是资源高效的（你不需要 GPU）。提示的缺点是它们可能会达到某种上限：你可能会遇到上下文长度限制，或者对于复杂任务，输出可能不一致或不准确。</p><p>微调通过在有标签的示例上训练模型来改变模型的权重。这允许更深层次的定制。微调后的模型将能够执行你想要的任何行为，而无需每次提供长提示，因为它已经学会了该行为。</p><p>权衡在于微调需要大规模的 GPU 计算和高质量的训练数据。在实践中，提示工程对于原型设计和管理简单用例或调整效果很好。当你对任务和想要训练的数据有明确的把握时，微调对于更持久、更稳健的变更更为有效。这两种方法并不互斥——许多项目利用提示修改，如果仅靠提示无法达到期望的准确性或一致性水平，则也执行微调。</p><h3>微调 vs. RAG vs. 工具/智能体</h3><p>检索增强生成是另一种选择：不是修改模型，而是赋予其访问外部知识源的能力。当查询时，RAG 系统搜索</p><p>并拉入相关文档整合到提示中。这有助于让模型的知识保持最新，并通过将答案植根于检索到的文本来帮助减少幻觉。当你需要最新的知识，或者你的数据太大/太不稳定而无法注入模型时，RAG 非常有用。</p><p>相比之下，微调将领域知识<strong>烘焙</strong>到模型的权重中。模型本身成为一个自包含的专家，不再需要查找信息来回答已知情况。这提供了低延迟的响应（在运行时无需检索），并使模型能够内化数据中更微妙的方面（例如上下文细微差别、风格）。然而，微调模型中的知识是<strong>静态</strong>的：如果数据更新，你必须重新训练以刷新模型的知识。微调本身也没有赋予模型引用来源/参考资料的能力，而 RAG 方法可以引用它检索到的文档。</p><p>对于许多应用，<strong>混合方法</strong>通常效果最好。你可以微调一个 LLM，为其提供一个良好的基础行为（例如，它已经擅长遵循指令和你领域的行话），然后使用 RAG 为其提供最新的事实。</p><p>有时，你可以通过使用带有工具的 LLM 来避免大量的微调。例如，不要微调模型来执行复杂的数学运算，而是使用一个提示来调用 API 处理困难部分（一种智能体方法）。</p><h2>LLM 微调工作流程</h2><p>本节将引导你完成从规划一直到部署的八个步骤的 LLM 微调工作流程。</p><h3><strong>步骤 1 – 定义你的用例和成功指标。</strong></h3><p>每个微调项目都应从一个明确的目标开始。你想构建什么？合同分析助手？客户支持聊天机器人？代码生成助手？还是其他？尽可能精确地定义用例；这将指导所有其他决策（数据、模型选择等）。与用例一起定义成功标准。选择能够捕捉模型期望行为的指标或评估标准。例如：</p><table><thead><tr><th>用例</th><th>主要目标 / 成功标准</th><th>示例评估指标</th></tr></thead><tbody><tr><td>客户支持助手</td><td>回答常见问题的高准确性；良好的用户满意度；高解决率</td><td>答案正确性（例如，与参考答案的 BLEU 或 ROUGE 分数）。用户满意度评分。来自支持人员的定性反馈。</td></tr><tr><td>法律文档分析器</td><td>正确提取特定字段；准确的条款摘要；法律解释中的最小错误</td><td>关键信息提取的精确率和召回率。律师对正确性和完整性的专家评估。</td></tr><tr><td>代码助手</td><td>功能正确的生成代码；有帮助的解释；减少开发人员的调试时间</td><td>生成解决方案在测试用例上的通过率。人类开发人员对有用性和正确性的评估。</td></tr></tbody></table><p>好的，这是你要求的“步骤 2 – 选择基础模型”中的完整表格：</p><h3>步骤 2 – 选择基础模型</h3><p>接下来，选择你想要微调的基础 LLM。你选择的基础模型至关重要；你需要一个 A) 对当前任务足够强大，B) 允许用于你的预期用途（许可证），C) 考虑到你的硬件，可以进行合理微调的模型。下表列出了在此步骤中需要考虑的一些因素：</p><table><thead><tr><th>因素</th><th>指导 / 注意事项</th><th>示例</th></tr></thead><tbody><tr><td>开源 vs 专有</td><td>开源：选择开源模型当你需要完全控制、本地部署、或者需要检查和修改模型时。 专有：专有 API 可以进行微调，但你会牺牲控制权，受供应商条款约束，并且可能产生更高的长期使用成本。</td><td>开源：LLaMA-3 系列、MosaicML MPT、EleutherAI 模型、Mistral 等。 专有：通过微调 API 使用 OpenAI GPT-4 / GPT-3.5。</td></tr><tr><td>模型大小与硬件</td><td>较小的模型（7B–13B）更便宜，微调更快，但在非常复杂的任务上可能表现不佳。 较大的模型（70B+）可以达到更好的质量，但训练和服务的成本更高。尽可能从小模型开始，必要时再扩大。</td><td>单个 24 GB GPU → 倾向于使用 PEFT（例如，LoRA）或 QLoRA 微调 ≤13B 或约 30B 的模型。多 GPU（例如 8×A100）→ 更大的模型（30B–70B+）变得可行。许多项目发现微调后的 7B 或 13B 模型足以满足生产任务。</td></tr><tr><td>架构与特性</td><td>选择与你的任务和限制条件相符的架构。为编程任务使用代码专用模型，为大文档使用长上下文模型，以及使用多语言模型当你需要多种语言时。</td><td>代码生成：StarCoder， CodeLlama。 长上下文 / 长文档：具有扩展上下文的模型（例如，100k 令牌）。 多语言：在多种语言上训练的模型或明确宣传为多语言的模型。</td></tr><tr><td>基础模型 vs 指令调优基础</td><td>指令调优基础：对于对话/问答用例来说数据效率更高，因为它们已经学会了理解指令。 基础/原始模型：如果你需要偏离一般指令遵循的、非常专业的自定义行为，在原始基础模型中构建该行为可能更容易。 常见模式：从指令模型开始，并在你的领域对话上进行微调。</td><td>指令调优：Llama-2-Chat， 其他“-Instruct/-Chat”变体 — 适合聊天机器人和问答。 基础/原始：非指令检查点 — 如果你需要非常自定义的行为则更好。</td></tr><tr><td>许可证与使用限制</td><td>始终验证许可证是否与你的预期用途（尤其是商业用途）相匹配。开源模型附带各种许可证（Apache 2.0， MIT， GPL， 自定义）。专有模型受提供商的服务条款约束。确保训练和部署都符合规定。</td><td>开源示例：Llama 2 — 在 Meta 的许可证下，符合某些大规模条件可用于商业用途。其他 OSS 模型（Apache 2.0， MIT， GPL 等）— 每个都有不同的重新分发/使用规则。 专有示例：OpenAI 等 — 受服务条款和数据使用条款约束。</td></tr></tbody></table><h3>步骤 3 – 收集并准备你的训练数据</h3><p>高质量的数据，并且是为你的任务量身定制的，是成功的关键。数据收集和准备是最耗时的环节。其子步骤包括数据收集、清理和格式化。</p><p>下表概述了为微调大型语言模型准备数据的端到端工作流程的高层次视图。它将引导你完成三个主要阶段：(1) 从所有来源收集数据（领域文档、任务演示、合成数据和公共数据集），(2) 清理和预处理这些数据，使其达到适当的质量、隐私和平衡性，以及 (3) 将数据格式化为模型就绪的输入-输出对，这些配对遵循模型在生产环境中将被提示的方式。</p><table><thead><tr><th>阶段</th><th>步骤</th><th>操作内容</th></tr></thead><tbody><tr><td>收集数据</td><td>领域文档与知识</td><td>收集与你的任务相关的所有领域特定文档和知识源。</td></tr><tr><td> </td><td>任务演示</td><td>创建或收集输入-输出对，向模型展示它应如何表现。</td></tr><tr><td> </td><td>合成数据生成</td><td>当真实数据稀缺时，提示一个更大或更强大的模型生成额外的示例。</td></tr><tr><td> </td><td>公共数据集</td><td>使用公共数据集来启动或增强你的训练数据。</td></tr><tr><td>清理和预处理数据</td><td>移除或匿名化敏感信息</td><td>剥离或匿名化个人身份信息和敏感数据。</td></tr><tr><td> </td><td>去重与过滤</td><td>移除重复或近似重复的条目，并过滤掉低质量或不相关的记录。</td></tr><tr><td> </td><td>标准化格式</td><td>将所有数据转换为训练流程期望的一致模式。</td></tr><tr><td> </td><td>平衡数据集</td><td>确保数据集不会被单一意图或主题所主导，以免模型对其产生偏见。</td></tr><tr><td> </td><td>分割为训练/验证/测试集</td><td>创建适当的分割以支持训练、超参数调优和无偏评估。</td></tr><tr><td>为模型格式化数据</td><td>指令遵循格式</td><td>将单轮任务格式化为指令-输出对。</td></tr><tr><td> </td><td>聊天机器人（多轮）格式</td><td>用明确的角色和消息顺序表示多轮对话。</td></tr><tr><td> </td><td>分类/信息提取格式</td><td>将分类或信息提取等任务表示为输入-标签对。</td></tr><tr><td> </td><td>匹配训练提示与推理使用方式</td><td>确保训练提示反映模型在生产中的使用方式。</td></tr><tr><td> </td><td>迭代增强与调优</td><td>将数据准备视为一个迭代过程；根据训练和评估反馈优化数据集。</td></tr></tbody></table><p>处理大规模训练数据需要可靠的存储。大多数大型云平台的存储与数据传输费用高昂，而 DigitalOcean 云平台则提供了极具性价比的解决方案。<a href="https://link.segmentfault.com/?enc=0Rx2mFV1k3NFpGMkBAHfzg%3D%3D.1QUnDplh0N2Gcll5yZ42ilyBC80f70Jud3vvv7FeCQ7dcUPZB02OmTnbYgpbuO3Q" rel="nofollow" target="_blank">DigitalOcean Spaces 对象存储 </a>服务不仅成本透明低廉，可以方便地从不同的训练实例高速读取，并确保数据持久性。</p><h3><strong>步骤 4 – 选择微调策略</strong></h3><p>现在你已经有了数据和模型——具体将如何进行微调呢？下表比较了适配大型语言模型的最常见策略：全参数微调、参数高效微调（PEFT，包括 LoRA 和 QLoRA）、上下文学习以及混合方法。</p><table><thead><tr><th>策略</th><th>内容描述</th><th>何时使用</th></tr></thead><tbody><tr><td>全参数微调</td><td>在你的任务/领域数据上更新模型的所有参数。</td><td>模型相对较小（约 ≤ 6B 参数），并且你有强大的 GPU。你绝对需要在微调领域达到最高性能。预算和基础设施允许进行繁重的训练运行（单 GPU 或多 GPU 设置）。</td></tr><tr><td>参数高效微调 (PEFT)</td><td>仅训练少量额外的参数（例如，适配器、低秩矩阵），同时保持基础模型冻结。</td><td>大多数生产场景的默认选择。你想要在有限的 GPU 内存上适配中/大型模型（7B–30B+）。你需要多个特定领域变体，但希望重用单个基础模型。</td></tr><tr><td>LoRA (低秩自适应) (PEFT 方法)</td><td>将小的低秩矩阵插入到选定的层（例如注意力投影层）中，并仅训练这些矩阵，原始权重保持冻结。</td><td>模型尺寸为中小型（例如 7B–13B），并且你有一个相当强大的 GPU。你希望在不量化基础模型的情况下进行高效的微调。</td></tr><tr><td>QLoRA (量化 LoRA) (PEFT 方法)</td><td>在将基础模型量化为 4 位的情况下应用 LoRA，大大减少了训练期间的内存占用。</td><td>你希望在单个 GPU 上微调大型模型（例如 30B+）。你的 GPU VRAM 有限，16 位训练不可行。你希望以最少的硬件获得接近全参数微调的性能。</td></tr><tr><td>仅上下文学习</td><td>完全不进行微调；而是在推理时通过少样本提示提供示例，让模型从上下文中推断模式。</td><td>任务简单，并且你只有少量示例。你需要零训练基线来验证微调是否值得。你希望快速迭代并且没有训练基础设施。</td></tr><tr><td>混合策略</td><td>结合多种方法，例如部分全参数微调加特定层的 LoRA，或分阶段微调（领域预训练后接指令调优）。</td><td>研究或非常高端的生产场景，需要精细控制。你希望尝试超出标准方案的进阶设置。</td></tr><tr><td>训练注意事项 (所有策略)</td><td>适用于所有微调方法的通用旋钮和优化。</td><td>选择训练轮数：对于较大的数据集通常为 1–3 轮；对于较小的数据集最多可达 5–10 轮。监控验证损失以防止过拟合（必要时提前停止）。选择适合模型大小的学习率、批次大小和调度器。</td></tr></tbody></table><h3><strong>步骤 5 – 设置你的工具和环境</strong></h3><p>确定策略后，设置运行微调的环境。下表总结了 LLM 微调的实际环境设置。它包括硬件要求、核心库和框架、可选的管理平台，以及配置和测试训练脚本的典型工作流程。</p><table><thead><tr><th>步骤 / 区域</th><th>操作内容</th><th>示例 / 技巧</th></tr></thead><tbody><tr><td>硬件设置</td><td>确保你有适当的 GPU/云实例用于微调。根据你的 VRAM 预算选择支持的模型大小和微调方法（全参数/LoRA/QLoRA）。对于本地设置，安装并验证适当的底层驱动程序（例如 CUDA）。</td><td>单块高端GPU（例如 A100 80GB）→ 可使用 QLoRA 微调超大型模型。 单块24GB GPU → 可使用 LoRA 微调 7B-13B 模型。 多块GPU → 对于更大的模型或更快的运行，使用多 GPU + 分布式训练（例如 8×A100，<a href="https://link.segmentfault.com/?enc=RRCTJu3l8IoyUfWq%2F7FboA%3D%3D.cpsVHEzg5SiYXp2Pirq9XLgQcASbXjQXVDOuyOnbWy2XUlgBRpyl7gb2rKafyTqO" rel="nofollow" target="_blank">DigitalOcean按需实例仅需3.09美元/小时/GPU</a>）。</td></tr><tr><td>库与框架</td><td>设置用于模型加载、数据处理和 PEFT 方法的核心软件栈。安装量化所需的其他库和分布式训练。</td><td>模型与数据：transformers, datasets。 PEFT：peft（用于 LoRA, QLoRA）。 训练助手：trl（例如 SFTTrainer），accelerate（用于分布式）。 量化：bitsandbytes（用于 4 位 QLoRA）。 替代堆栈：Keras, PyTorch Lightning 等（如果偏好）。</td></tr><tr><td>管理服务或平台</td><td>如果你不想自己管理基础设施，可以选择使用提供预配置环境和微调工具的托管或基于 UI 的平台。</td><td>开源工具包：Unsloth（带有即用型笔记本的微调/RL工具包）。 云ML平台：Databricks、AzureML 等，带有微调示例和 QLoRA 笔记本。 微调即服务：提供 GPU 托管服务的平台。</td></tr><tr><td>加载模型</td><td>使用 AutoModelForCausalLM.from_pretrained(...)。加载和预处理数据集（分词化、格式化）。使用 LoraConfig 和 get_peft_model 或 TRL 的 SFTTrainer 附加 LoRA/QLoRA。</td><td>设置学习率、批次大小、轮数、评估/保存策略等。从参考实现开始（例如 QLoRA 论文、Hugging Face 示例、GitHub 仓库）。</td></tr><tr><td>配置训练脚本</td><td>创建连接模型、数据和 PEFT 配置的训练脚本或笔记本。定义超参数和训练参数。</td><td> </td></tr><tr><td>运行小型测试</td><td>在进行完整训练之前，运行一个小规模测试以验证一切正常。确认数据格式化、GPU 利用率和分布式配置（如果有）。</td><td>操作：在数据的一个小子集上训练（例如几个批次）并验证损失下降。 检查项：GPU 内存使用情况、是否正确使用了设备。 多GPU配置：验证 accelerate 或 torchrun 设置以及所有设备都参与。 目的：现在修复格式化或运行时问题，以避免浪费长时间的训练运行。</td></tr></tbody></table><h3>步骤 6 – 训练循环和超参数</h3><p>是时候进行微调了！此步骤是运行实际的训练过程并调整超参数以使其能够学习。这里我们介绍关键的训练循环超参数以及微调 LLM 的操作实践。</p><table><thead><tr><th>超参数 / 步骤</th><th>控制内容</th><th>实用指南 / 示例</th></tr></thead><tbody><tr><td>学习率</td><td>控制每个优化步骤中参数更新的大小；过高可能导致发散，过低会减慢学习速度。</td><td>典型起始范围：1e-5 到 2e-4，取决于模型和数据大小。 大模型：通常需要较小的学习率。 对于 LoRA：常见值：2e-4 到 1e-4。 操作：尝试几个值或使用带预热然后衰减的调度器。</td></tr><tr><td>批次大小与梯度累积</td><td>决定有多少样本贡献于每次参数更新。梯度累积在 VRAM 有限时模拟更大的批次。</td><td>单设备批次：通常较小（例如，每个 GPU 1-4 个样本），受内存限制。 梯度累积：用于达到每次更新约 16-32 个样本的有效批次。 权衡：太小 → 训练嘈杂；太大 → 可能损害泛化能力或需要学习率缩放。</td></tr><tr><td>轮数/步数</td><td>控制模型对整个训练数据的遍历次数（轮数）或总优化步数。</td><td>常见选择：对于有数千个示例的数据集，2-3 轮。对于非常大的数据集，甚至 1 轮可能就足够。 关键监控：训练和验证损失。如果验证损失上升而训练损失下降，则提前停止（防止过拟合）。</td></tr><tr><td>LoRA 特定超参数</td><td>配置 LoRA 适配器的大小和放置，这决定了适应能力和内存使用。</td><td>秩 (r)：典型值 8, 16, 32；秩越高 = 能力越强但内存占用越多。 Alpha (α)：缩放因子；通常选择 alpha/r ≈ 1（例如 r=16, alpha=16 或 32）。 目标层：通常应用于注意力投影层（例如，q_proj, k_proj, v_proj, o_proj）。为获得最佳质量，许多人将 LoRA 应用于所有线性层。</td></tr><tr><td>正则化</td><td>用于减少过拟合并提高微调模型泛化能力的技术。</td><td>LoRA Dropout：在适配器层使用 Dropout（例如 ~0.1）。 权重衰减：在适配器参数上应用小的权重衰减（例如 0.01）。 提前停止：结合基于验证损失的提前停止。</td></tr><tr><td>梯度检查点</td><td>一种内存优化技术，通过在反向传播期间重新计算激活而不是存储所有激活来节省 GPU RAM。</td><td>何时启用：如果可用，以便将更大的模型或更大的批次装入内存。 权衡：由于重新计算，训练速度更慢，但内存使用显著降低。</td></tr><tr><td>训练循环实现</td><td>运行前向传播、计算损失和更新参数的代码或框架级结构。</td><td>使用高级 Trainer：使用 Trainer / SFTTrainer：配置模型、数据和训练参数，然后调用 trainer.train()。减少样板代码和错误。 手动 PyTorch：循环遍历批次，调用 model(...), loss.backward(), optimizer.step(), optimizer.zero_grad()。</td></tr><tr><td>监控与运行时间</td><td>观察训练行为并了解不同模型/数据规模下的预期训练时间。</td><td>监控日志：训练损失通常应下降；如果发散或变为 NaN，则降低学习率或调试。 验证损失：跟踪每个轮次或定期间隔的验证损失；上升表明过拟合。 训练时间：范围从几分钟（小模型、小数据）到几个小时/天（大模型、多 GPU 运行）。</td></tr><tr><td>训练输出与工件</td><td>训练结束时保存的内容以及如何用于部署。</td><td>全参数微调：保存包含所有更新权重的新模型检查点。 LoRA/PEFT：保存适配器权重（通常很小，几 MB）；在推理时与基础模型结合以重建微调模型。 版本控制：确保检查点进行版本控制并可重现，以供未来实验和回滚使用。</td></tr></tbody></table><h3>步骤 7 – 评估和验证</h3><p>训练好模型后，下一步是评估你的微调模型，看看它是否达到了步骤 1 中定义的成功标准。评估应包括定量指标和定性分析。</p><h4>评估维度 / 步骤</h4><table><thead><tr><th>评估维度 / 步骤</th><th>评估内容</th><th>实用指南 / 示例</th></tr></thead><tbody><tr><td><strong>定量评估</strong></td><td>使用自动指标在预留的验证集或测试集上衡量性能。</td><td>使用你预留的验证/测试集以避免对训练数据过拟合。生成任务：BLEU、ROUGE、METEOR 与参考答案（例如摘要任务）。分类/提取：准确率、精确率/召回率、F1 分数。</td></tr><tr><td><strong>人工评估</strong></td><td>使用领域专家或最终用户来判断模型输出的质量、相关性和安全性。</td><td>让专家审查采样的模型响应，并在相关性、正确性、清晰度、语调和无害性方面进行评分。客户支持场景：支持人员比较模型回复与真实情况或先前系统的响应。</td></tr><tr><td>回归检查</td><td>确保微调模型在基础模型处理良好的行为或提示上没有变得更糟。</td><td>维护一套小的“基线”提示集，其中基础模型的行为已知且可接受。在这些提示上比较基础模型与微调模型的响应。寻找回归：新错误、过于僵化的风格、不必要的冗长或有用能力的丧失。如果出现回归，考虑调整数据、降低学习率或使用 PEFT 而非全参数微调。</td></tr><tr><td>安全性与偏见评估</td><td>测试模型是否遵守安全约束并避免有偏见或有害的输出。</td><td>使用对抗性或敏感提示（有害指令、不允许的主题等）进行探查。检查模型是否仍然拒绝不允许的内容并遵守你的安全策略。</td></tr><tr><td><strong>泛化测试</strong></td><td>评估模型是否能将学习到的行为应用于新的、未见过的输入，而不是记忆训练数据。</td><td>创建在措辞或结构上与训练示例不同的测试提示。寻找过拟合的迹象，例如鹦鹉学舌般重复训练短语或仅在近似的重复项上表现良好。</td></tr><tr><td><strong>迭代与补救</strong></td><td>当评估结果不令人满意时，调整数据、超参数或架构的过程。</td><td>如果指标低或定性问题明显，优化你的数据集：添加更多示例、清理噪声、平衡意图。尝试另一轮训练或调整超参数（学习率、批次大小、LoRA 秩等）。</td></tr></tbody></table><h3>步骤 8 – 部署微调模型</h3><p>最后一步是将你的微调模型投入生产使用。对于 LLM，部署意味着使其能够在所需规模上为推理查询提供服务，并将其与你的应用程序集成。下表总结了如何在生产中部署和服务微调后的 LLM。</p><table><thead><tr><th>部署方面</th><th>涉及内容</th><th>实用指南 / 示例</th></tr></thead><tbody><tr><td>选择服务解决方案</td><td>决定是自托管模型还是使用托管服务平台。如果使用 LoRA/QLoRA，请确保支持 PEFT 适配器。</td><td>自托管：使用 Hugging Face Text Generation Inference (TGI)、vLLM、FasterTransformer 等服务器，或 Ollama 等轻量级运行时。对于 PEFT：可在运行时加载基础模型和 LoRA 适配器，或事先将其合并。另外，如果希望平衡控制力和运维简便性，可以考虑使用 <a href="" target="_blank">DigitalOcean App Platform（应用托管服务）</a> 来容器化并托管您的模型API，它支持从Git仓库自动部署。 托管服务：Hugging Face Inference Endpoints、AWS SageMaker、GCP Vertex AI 等接受自定义模型工件的云服务。对于需要更高扩展性的生产部署，可以使用 <a href="https://link.segmentfault.com/?enc=5Ftkbn%2BRcUdF%2FeypsJwSXQ%3D%3D.gP5d9Jdl%2B7RzVIbZBeJpn0e%2BDLLm3o3gT2RGkgyUcYtJFvnGy1GuVvVJtTwEv1ms" rel="nofollow" target="_blank">DigitalOcean Managed Kubernetes</a> 来编排模型服务，轻松实现负载均衡和自动扩缩。</td></tr><tr><td>模型格式考虑</td><td>选择并可能转换模型格式，以针对目标硬件（GPU、CPU、边缘、移动）和延迟/吞吐量要求进行优化。</td><td>常用格式：使用 Hugging Face 格式（适用于 TGI 等）。转换为 ONNX、GGML/GGUF 等格式以用于 CPU/移动端或嵌入式部署。 量化模型：QLoRA 训练后为 4 位；服务时可保持 4 位，或在 VRAM 允许时加载 8 位以提升质量。考虑使用 GPTQ 4 位等额外压缩来减少推理内存和成本。</td></tr><tr><td>扩展基础设施</td><td>设计基础设施以处理预期流量，包括自动扩缩、负载均衡和批处理，以提高 GPU 利用率。</td><td>容器化与编排：使用 Docker 容器化模型服务器，并用 Kubernetes 等工具编排。 实例选择：使用 GPU 实例进行低延迟推理（例如，7B 模型用 T4/A10；更大模型或更高 QPS 用 A100 或多个副本）。 性能优化：在支持的服务器（vLLM、TGI）上启用请求批处理以提高吞吐量。为波动的流量设置自动扩缩规则和负载均衡器。</td></tr><tr><td>与应用程序集成</td><td>通过简单 API 公开模型，并将其集成到应用后端，包括任何必要的后处理逻辑。</td><td>API 端点：提供 REST 或 gRPC 端点（例如，接受提示并返回补全结果的 POST /generate）。使用 TGI 或 Hugging Face Endpoints 的内置 API。 后处理：解析 JSON 输出、剥离角色令牌、强制输出格式等。 健壮性：添加应用级超时、重试和回退机制（例如，主模型过载或故障时回退到较小模型或外部 API）。</td></tr><tr><td>生产环境监控</td><td>上线后跟踪性能、可靠性和模型行为，以便及早发现问题。</td><td>关键指标：记录延迟、吞吐量、错误率（内存不足、超时、5xx 响应）。 输出监控：在隐私受控下采样和检查输出，以捕捉性能漂移或异常行为。 警报：对延迟峰值、错误激增、GPU 利用率异常等关键指标设置警报。</td></tr><tr><td>处理大模型挑战</td><td>解决服务大型 LLM 的操作复杂性，如内存、启动时间和推理成本。</td><td>内存与成本：使用量化（4/8 位）。对超大模型进行分片，跨多个 GPU 分布。 启动时间：加载 20B+ 模型可能需要数十秒或数分钟；尽可能保持实例“预热”或使用快照功能。</td></tr><tr><td>上线前的端到端测试</td><td>在全面推广前，使用类似生产的查询在真实环境中验证整个系统。</td><td>测试流程：通过应用 → API → 模型路径发送代表性提示并验证响应。 检查项：确保格式化、业务规则和后处理均正确。 上线策略：先进行冒烟测试和小范围金丝雀部署，再向所有用户开放。确认端到端行为符合预期后，方完成部署。</td></tr></tbody></table><h2>示例 PEFT 项目模板（高级代码大纲）</h2><p>让我们尝试组合一个 PEFT 微调项目的高级模板。这汇集了许多步骤。我们将使用伪代码/清单风格来呈现完整的项目结构和步骤：</p><p>1、  设置：选择模型并安装库。</p><pre><code>pip install transformers datasets peft bitsandbytes accelerate</code></pre><p>示例 MODEL_NAME（例如 "mistralai/Mistral-7B-Instruct-v0.2"）。</p><p>2、  以 4 位加载模型并添加 LoRA：</p><pre><code>import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training

model_name = "mistralai/Mistral-7B-Instruct-v0.2"

tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    load_in_4bit=True,
    device_map="auto",
    torch_dtype=torch.float16,
)

model = prepare_model_for_kbit_training(model)

lora_config = LoraConfig(
    r=8,
    lora_alpha=32,
    target_modules=["q_proj", "k_proj", "v_proj", "o_proj"],
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM",
)

model = get_peft_model(model, lora_config)
model.print_trainable_parameters()</code></pre><p>这里的 prepare_model_for_kbit_training 正在执行各种推荐的操作（梯度检查点、将层规范转换为 fp32 等）以确保 QLoRA 的稳定性。</p><p>3、  准备数据：</p><ul><li>将你的数据集加载或创建为训练示例列表。</li><li>进行分词化并格式化为输入 ID 和标签。</li></ul><p>4、  训练循环（使用 HF Trainer 或自定义）：</p><pre><code>from transformers import TrainingArguments, Trainer

training_args = TrainingArguments(
    output_dir="outputs/my-model",
    per_device_train_batch_size=2,
    gradient_accumulation_steps=16, # 有效批次大小 32
    num_train_epochs=3,
    learning_rate=2e-4,
    fp16=True,
    logging_steps=10,
    save_steps=50,
    save_total_limit=2,
    evaluation_strategy="epoch",
    report_to="none")
trainer = Trainer(model=model, args=training_args,
                  train_dataset=train_dataset, eval_dataset=val_dataset)
trainer.train()</code></pre><p>我们执行梯度累积以达到批次大小 32。我们定期保存检查点（每 50 步），并保留最后 2 个。如果可用，在每个轮次对 val_dataset 进行评估。</p><p>5、  <strong>评估：</strong></p><p>训练后，加载最佳模型（训练器应该已经保存了它，或者使用最后一个检查点）：</p><pre><code>model.eval() # 运行一些已知测试：
for prompt in ["Example user query 1", "Example user query 2"]:
    inputs = tokenizer(prompt, return_tensors='pt').to("cuda")
    outputs = model.generate(**inputs, max_new_tokens=100)
    print("Prompt:", prompt)
    print("Response:", tokenizer.decode(outputs[0], skip_special_tokens=True))</code></pre><p>如果你有结构化输出或参考答案，则计算指标。</p><p>6、  <strong>保存</strong> <strong>LoRA</strong> <strong><em/></strong>适配器**（或合并后的模型）：</p><pre><code>model.save_pretrained("outputs/my-model/lora") # 在 PEFT 中，默认情况下仅保存适配器</code></pre><p>默认情况下，get_peft_model 包装了基础模型，因此调用 save_pretrained 将保存一个配置 + LoRA 权重（而非基础权重）到 adapter_model.bin 或类似文件。你需要分别获取基础模型权重才能使用它们。或者，要获得一个独立的模型：</p><pre><code>merged_model = model.merge_and_unload()
merged_model.save_pretrained("outputs/my-model/full")</code></pre><p>这将生成一个包含完整模型（基础+适配器合并后）的目录。合并时要注意内存（你需要将整个模型加载到内存中）。</p><p>7、  <strong>部署准备：</strong></p><ul><li>如果使用 Transformers 进行推理，只需在那里加载合并后的模型，或者使用 PeftModel.from_pretrained(base_model, "outputs/my-model/lora") 动态应用适配器。</li><li>对于专用服务（如 TGI 或 vLLM），相应地打包模型（它们通常接受包含配置和权重的模型文件夹）。</li><li>可选地，你可以为了推理进一步量化它（如果你计划进行 CPU 服务，则转换为 int4 GGML；或者为了 GPU 转换为 int8 以减少内存占用）。</li></ul><p>8、  <strong>测试</strong>：如果可能，在暂存环境或真实数据的子集上进行最终测试，然后部署。</p><p>上面的模板省略了一些细节（精确的数据整理函数、任何自定义生成设置……），但它应该是你可以作为大多数任务起点的模式。</p><h2>真实用例</h2><p>微调不仅仅是理论练习——许多组织正在通过它来在特定应用中释放价值。让我们看几个用例。</p><h3>在历史工单上微调的客户支持助手</h3><p>假设一个组织多年来一直在生成客户支持日志：电子邮件、聊天记录、FAQ 文章等。他们想要一个 AI 助手，能够使用现有数据快速、一致地回答客户问题。GPT-4 和类似的开源模型可以回答任何可能想到的随机问题，但它们显然不了解该组织内部任何特定的产品规格、政策或过去的解决方案细节。在过去的支持工单/解决方案上微调 LLM，可以有效地为该组织创建一个自定义的支持领域专家模型。</p><h3>在合同和政策上微调的法律/合规助手</h3><p>法律/合规文档是专家知识存在于小众行话和精确定义概念中的经典例子。通用 LLM 不具备你公司特定合同语言、政策或合规义务的先验知识。然而，通过在你领域的文档语料库（合同、政策手册、监管文件等）上进行微调，你可以构建一个具备该专家知识的模型。</p><p>例如，你可以在大量合同文本上进行微调，然后让模型回答诸如“这份合同草案是否有竞业禁止条款？如果有，总结它施加了哪些限制。”这样的问题，其准确性将高于通用模型。它在训练期间已经看到了许多条款变体，并学会了如何提取/理解它们。</p><h3>特定领域的代码助手（针对特定技术栈）</h3><p>面向软件开发人员的 AI 编码助手已经被广泛使用。然而，许多是在通用代码和文档上训练的。内部公司框架、库和代码库细节不一定存在于通用 LLM 中。如果你在自己的代码库和文档上微调一个 LLM，你可以构建一个精通你技术栈的代码助手。</p><h3>LLM 微调中的常见陷阱（以及如何避免）</h3><p>微调 LLM 可能是一项强大的技术，但如果不小心操作，也可能造成严重错误。让我们来看看一些常见的反模式以及如何避免它们：</p><table><thead><tr><th>陷阱</th><th>发生原因</th><th>如何避免</th></tr></thead><tbody><tr><td>过拟合与通用能力丧失</td><td>模型在一个小的、狭窄的数据集上训练时间过长或过强。它开始记忆示例并忘记其更广泛的技能。</td><td>使用验证集和提前停止。限制训练轮数，使用小的学习率和轻量正则化。优先使用 PEFT/LoRA，并在训练中混合一些通用数据。</td></tr><tr><td>数据泄露与隐私问题</td><td>测试或评估数据意外进入训练集。敏感数据（个人身份信息、秘密、内部聊天记录）被用于微调，并且可能被模型复现。</td><td>保持严格的训练/验证/测试分割。在训练前匿名化或移除敏感细节。监控输出是否有泄露，并记录模型使用了哪些数据。</td></tr><tr><td>激励错位</td><td>模型仅针对狭窄的指标（例如，准确率、BLEU）进行优化。它学会了模仿训练答案，而不是真实世界的行为（例如，总是自信，从不说“我不知道”）。</td><td>使训练数据反映期望的行为（不确定性、礼貌、安全性）。使用多个指标和人工评审，而不仅仅是单一分数。添加人类反馈以引导乐于助人和无害的输出。</td></tr><tr><td>评估不佳与缺乏人工反馈</td><td>评估仅涵盖几个简单的测试或指标。没有现实的用户场景或边缘情况，并且人工很少评审输出。</td><td>构建一个包含典型和棘手查询的现实测试集。与人工评审员一起进行盲法比较（基础模型 vs 微调模型）。添加生产反馈循环（赞/踩、评论）并利用它来改进模型。</td></tr><tr><td>工程化不足（无监控、无回滚、无版本控制）</td><td>微调模型部署一次后被遗忘。没有监控、没有版本历史、没有快速回滚，也没有应对领域随时间变化的计划。</td><td>为每个模型进行版本控制，并在注册表中跟踪其数据和配置。记录输入/输出，监控质量和安全性，并设置警报。对新模型进行 A/B 测试，定期使用新数据重新训练，并为低置信度情况保留回退选项。</td></tr></tbody></table><h2>简单小结一下</h2><p>LLM 微调曾经是一个小众的优化步骤。然而，它正迅速成为将强大基础模型转化为可靠的、特定领域系统的默认方法。通过利用预训练能力作为起点，而不是从头开始训练，你可以将自己的数据、语调和约束注入模型，同时控制计算和工程工作量。有监督微调、指令调优和 RLHF 等对齐技术的结合，也提供了一个工具包来塑造模型知道什么以及如何行为。</p><p>LoRA 和 QLoRA 等参数高效微调方法允许使用适度的 GPU 和极少量的可训练参数来适应庞大的模型。这大大降低了实验的门槛。结合一个原则性的决策框架，你</p><p>可以为每个用例选择正确的技术，而不是默认选择最昂贵的选项。</p><p>有效的 LLM 微调更多是关于一个规范的微调生命周期：定义你的用例 → 选择合适的基础模型 → 策划高质量的数据 → 选择策略（全参数微调或 PEFT） → 使用合理的超参数进行训练 → 严格评估 → 部署并实施监控、版本控制和回滚。如果你将微调视为一个迭代的产品过程，而不是一次性的实验，你就可以将通用 LLM 转变为技术栈中可靠、高投资回报率的组件。</p>]]></description></item><item>    <title><![CDATA[Access开发实战：绘制漏斗图实现业务转化分析 access开发 ]]></title>    <link>https://segmentfault.com/a/1190000047496714</link>    <guid>https://segmentfault.com/a/1190000047496714</guid>    <pubDate>2025-12-23 14:08:56</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>hi，大家好！<br/>今天，我们我来讲解漏斗图。<br/><strong>什么是漏斗图 (Funnel Chart)</strong><br/>漏斗图是一种特殊的数据可视化图表，因其形状类似倒置的漏斗而得名。它通过递减的横向条形（或竖向梯形）来展示流程中各阶段的数据流失情况。</p><p>核心特征：</p><ul><li>阶段性递减：每个环节的数值必须小于或等于前一个环节。</li><li>流失可视化：条形宽度的变化直观反映了转化率或流失率。</li><li>多用于过程分析：强调"从多到少"的漏斗效应。</li></ul><p>典型的漏斗图结构示例：<br/>潜在客户 (1000)    ████████████████████████<br/>初步洽谈 (600)     ████████████████<br/>提交方案 (300)     ██████████<br/>签订合同 (120)     ████<br/>漏斗图的应用场景<br/>判断是否需要漏斗图可以参考以下几类业务需求：<br/>1️⃣销售漏斗 (Sales Funnel)追踪销售流程中的客户转化情况：线索获取 → 销售跟进 → 报价 → 成交典型问题：哪个环节流失最严重？<br/>2️⃣用户转化分析在网站或应用中监控用户行为：访问首页 → 注册 → 激活 → 付费关键指标：首次付费转化率（付费人数 / 访问人数）<br/>3️⃣招聘流程追踪人力资源部门可以用漏斗图分析：简历投递 → 初筛 → 面试 → Offer → 入职优化重点：哪一关拒绝率异常？<br/>4️⃣生产流程质检制造业的多道工序检验：原材料进厂 → 初加工 → 质检 → 成品 → 出货质量管理：哪个工序不良率最高？<br/>判断依据： 如果你的数据符合"有序递减"的特征，且需要关注中间环节的流失率，那么漏斗图就是最佳选择。接着，我们来看看怎么在access中实现漏斗图。</p><h2>1创建表</h2><p>我们先创建一个表，这次我把表结构的创建SQL直接给到大家，这样就不需要手工再创建了。</p><pre><code class="SQL">CREATE TABLE tbl_Vulnerabilities (
    ID AUTOINCREMENT PRIMARY KEY,
    VulnTitle TEXT(100) NOT NULL, -- 漏洞名称
    Severity TEXT(20),            -- 严重等级
    Status TEXT(20),              -- 当前状态 (Open/Closed等)
    Category TEXT(50),            -- 漏洞类型 (SQLi/XSS等)
    FoundDate DATETIME            -- 发现时间
);</code></pre><p>表创建好了，那就可以手工添加一些数据了，像我这样：<br/><img width="725" height="367" referrerpolicy="no-referrer" src="/img/bVdnsd6" alt="" title=""/></p><h2>2创建查询</h2><p>接着，我们再创建一个查询查询名称： </p><pre><code class="SQL">SELECT
    tbl_Vulnerabilities.Severity,
    Count(tbl_Vulnerabilities.Severity) AS VulnCount
FROM
    tbl_Vulnerabilities
GROUP BY
    tbl_Vulnerabilities.Severity;</code></pre><p>这个查询就作为图表的数据源。</p><h2>3创建图表控件</h2><p>数据有了，我们就可以来添加控件了。<br/><img width="176" height="174" referrerpolicy="no-referrer" src="/img/bVdnsd7" alt="" title="" loading="lazy"/><br/><img width="530" height="485" referrerpolicy="no-referrer" src="/img/bVdnsd8" alt="" title="" loading="lazy"/></p><h2>4图表设置</h2><p>设置一下图表，具体参考下图</p><p><img width="330" height="523" referrerpolicy="no-referrer" src="/img/bVdnsd9" alt="" title="" loading="lazy"/></p><h2>5运行查看</h2><p>最后，我们看一下效果。<br/><img width="723" height="520" referrerpolicy="no-referrer" src="/img/bVdnsea" alt="" title="" loading="lazy"/></p><p>本文详细介绍了漏斗图的定义、应用场景以及在 Access开发 中的实现方法。通过新图表控件，我们可以在不依赖第三方图表库的情况下，实现高度自定义的漏斗图效果。对于需要快速构建内部数据分析工具的开发者来说，掌握这种基于 Access 的轻量级开发技术，能够在有限的预算和时间内交付高质量的业务看板。喜欢这篇文章吗？欢迎点赞、在看、转发，让更多 Access 爱好者看到！</p>]]></description></item><item>    <title><![CDATA[云原生数据仓库 AnalyticDB Supabase 使用全攻略 数据库知识分享者 ]]></title>    <link>https://segmentfault.com/a/1190000047496748</link>    <guid>https://segmentfault.com/a/1190000047496748</guid>    <pubDate>2025-12-23 14:08:07</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>云原生数据仓库 AnalyticDB PostgreSQL 版 Supabase 是基于开源 Supabase 深度增强打造的全托管应用开发平台。平台延续原生 Supabase 的开发体验，提供数据库、用户鉴权、边缘函数等核心功能，并结合阿里云基础设置提供更高性能、更强安全性和更完善的生态支持。</p><h2>一、ADB Supabase 可以帮你做什么</h2><p><strong>ADB Supabase</strong> 可以帮助你快速构建 AI 驱动的现代应用，无需复杂后端开发。例如，你可以借助 ADB Supabase，结合 Dify 及大语言模型轻松构建 AI 客服系统，基于 Supabase 中真实、结构化的订单与物流数据，实现精准、自动的售后咨询与订单查询回复，通过秒级响应减轻人工负担，并借助 AI 的自然语言理解提供个性化服务，提升客户满意度。<br/>同时，ADB Supabase 也支持敏捷开发 AI 原生应用。并提供数据存储、对象存储和边缘函数能力，简化了传统后端开发的复杂性；AI 能力通过 ADB Supabase Edge Function 无缝集成通义千问等 AI 模型，实现图像编辑、内容生成等智能功能，从而高效构建和验证应用原型。<br/>此外，ADB Supabase还支持通过通义灵码或 Cursor，在 IDE 中以自然语言调用 Supabase MCP 工具实现全栈 Agent 自主开发，并且你还可以结合 Bolt 和 Qwen3-Coder 大模型，快速构建 Web、APP 和小程序等多样化应用。相较于开源自托管方案，云原生数据仓库 AnalyticDB PostgreSQL 版 Supabase 提供全面的托管能力，可按需选择计算与存储规格，同时原生支持支付宝、微信等第三方 OAuth 功能，补齐了开源方案缺失的 Edge Functions 等核心特性，并且保持与 Supabase Cloud 高度一致的用户体验和 API 兼容性，全流程轻量高效，助力 Vibe Coding 落地实践。<br/><strong>点此观看精彩演示</strong>：<a href="https://link.segmentfault.com/?enc=Q%2FWB14%2F3%2FIY5q%2FXfvmkSDg%3D%3D.EVrNjWWXwKStjdbwYpt%2B7IXHSDvmkiwYVVUNYdMImD%2ByN2GxN4e6cltDiyXZVXHA" rel="nofollow" target="_blank">https://developer.aliyun.com/live/255256</a></p><h2>二、优势</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047496726" alt="1" title="1"/></p><p><strong>原生支付宝/微信OAuth 支持</strong><br/>原生集成支付宝与微信第三方登录认证，无需自行适配OAuth流程，即开即用。适用于Web、App、小程序等多种应用场景，大幅降低接入成本。<br/><strong>Edge Functions 全周期体验</strong><br/>支持Supabase Edge Functions全生命周期（开发、部署、日志观测），提供低延迟调用、稳定执行与事件触发能力。此外，提供原生Secrets管理功能，可安全管理API Key、Token、密钥等敏感信息。<br/><strong>全链路日志可观测能力</strong><br/>Edge Functions、数据库、Auth、Storage等模块均具备清晰可观测的日志体系。开发者可在Dashboard中自助查看执行日志、调试信息及错误定位，显著提升开发效率和排障速度，实现真正的自服务开发体验。<br/><strong>生态兼容与便捷迁移</strong><br/>API、SDK 兼容，提供迁移方案，可轻松从官方Supabase迁移，无需修改应用代码。<br/><strong>MCP Server原生支持</strong><br/>支持Model Context Protocol（MCP）Server，使LLM、Agent 等智能应用可直接调用数据库、Storage、Edge Functions等资源，实现更自然、更强大的AI调用链路，适合构建智能助手、自动化服务与数据驱动应用。<br/><strong>企业级安全体系</strong><br/>提供VPC网络隔离、访问审计、加密传输、权限体系以及对象存储安全策略。<br/><strong>全托管与免运维体验</strong><br/>提供多种实例规格并支持扩缩容，以满足不同业务场景需求。提供版本升级、数据备份等企业级能力，让开发者专注业务，无需自建集群。</p><h2>三、如何创建 ADB supabase项目</h2><ol><li>登录<a href="https://link.segmentfault.com/?enc=szptQw%2BmKvvIdcDJRkgb9w%3D%3D.ByfcyfHkDfEno0VKchwkPXv8DhVejkg75PPxMdfTMRXflBkoHoYLyS20dJzXICzMFerNzprKYcs5O1gBXTNl3g%3D%3D" rel="nofollow" title="云原生数据仓库AnalyticDB PostgreSQL版控制台" target="_blank">云原生数据仓库AnalyticDB PostgreSQL版控制台</a>。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047496727" alt="2" title="2" loading="lazy"/></li><li>在控制台左上角，选择实例所在地域。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047496728" alt="3" title="3" loading="lazy"/></li><li>在左侧导航栏中，单击Supabase，再单击页面右上角的创建项目，选择免费测试创建或付费创建，可参考下表示例进行参数配置。</li></ol><h4>目前 ADB Supabase 已提供付费版项目，支持多种计算资源和存储资源规格！</h4><p>AnalyticDB PostgreSQL 版提供了两种计费方式：<br/>• 按量付费：属于后付费，即按小时扣费。适合短期需求，用完可立即释放实例，节省费用。<br/>• 包年包月：属于预付费，即在新建实例时需要支付费用。适合长期需求，价格比按量付费更实惠。<br/>AnalyticDB PostgreSQL 版存储弹性模式和 Serverless Pro 实例，如果单次购买超过1年，可享受包年优惠促销，即1年8.5折、2年7折、3年5折。<br/><a href="https://link.segmentfault.com/?enc=I1SvwNfYrNwcZT19S2K9xg%3D%3D.t%2B4WL5QTtYe6jBGTMWK2o7ElsLe%2FimAXL%2FVXdBs7QYawI5lLyAsYtxk1U5BIjZ7YdhZAc%2BENGPayauiGPuSPR1FJyYQT1TXc1h1F37IQi54X4BM%2FlW%2B%2FVGE1maKjTpI6" rel="nofollow" title="点此了解产品定价详情" target="_blank">点此了解产品定价详情</a><br/>• <strong>付费创建配置参考</strong><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047496729" alt="image" title="image" loading="lazy"/></p><ol start="4"><li>确认参数配置，完成项目创建。</li></ol><h2>四、免费试用权益</h2><p><strong>重磅福利抢先看！</strong> 阿里云 AnalyticDB PostgreSQL 版继续提供1核2GB 规格免费使用！<br/>零成本体验企业级云数据库，助力 Vibe Coding 极速开发，<strong><a href="https://link.segmentfault.com/?enc=xcRbsdLeorosK4QnGi%2BdJA%3D%3D.xxNeQ6T9IFWKnwpbx98%2FIGpX6jC0UwkM2lS31wuoS5tEhYKGCbihiX5yygRssv6lvutna6fQ5DJGaPrMCXv5g5q%2FhV3h9jUav8WcqHMaiDKkuWAs2yVIOIHpQkoJUnmv" rel="nofollow" title="点此立即开通免费试用" target="_blank">点此立即开通免费试用</a>！</strong><br/>如果你对 AnalyticDB Supabase 感兴趣，欢迎钉钉搜索群号“101930027031”或扫码加入钉群交流。</p>]]></description></item><item>    <title><![CDATA[怎么申请免费IP地址证书 力能扛鼎的毛豆 ]]></title>    <link>https://segmentfault.com/a/1190000047496757</link>    <guid>https://segmentfault.com/a/1190000047496757</guid>    <pubDate>2025-12-23 14:07:28</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h4>一、 什么是IP地址SSL证书？</h4><p>IP地址SSL证书是一种特殊类型的数字证书，其保护对象不是域名，而是<strong>公网IP地址本身</strong>（例如 <code>203.0.113.10</code>）。当用户通过HTTPS访问该IP地址时，浏览器会验证并显示安全锁标识，确保通信过程加密且可信，有效防止数据在传输过程中被窃听或篡改。</p><p>它与传统域名证书的核心区别在于“身份标识”。这种差异主要服务于特定的技术场景：</p><ul><li><strong>传统域名证书</strong>：验证并保护如 <code>www.example.com</code> 的域名。</li><li><strong>IP地址证书</strong>：验证并保护如 <code>203.0.113.10</code> 的公网IP地址。</li></ul><h4>二、 谁需要申请IP地址SSL证书？</h4><p>这项技术主要服务于无法或不便使用域名的特定场景：</p><ul><li><strong>工业物联网与嵌入式设备</strong>：工厂内的PLC控制器、智能摄像头等设备通常只有IP地址，无域名。使用IP证书可为设备间的通信提供加密。</li><li><strong>企业内网对外服务</strong>：一些企业的OA、ERP或VPN系统通过公网IP直接访问。为避免域名备案的繁琐或遵循安全策略，可直接为IP地址部署证书，消除浏览器“不安全”警告。</li><li><strong>边缘计算节点与CDN</strong>：大量边缘服务器可能没有独立域名，IP地址证书是满足其HTTPS合规要求的有效方式。</li><li><strong>开发与测试环境</strong>：在开发初期或进行内部测试时，使用IP地址证书可以快速搭建安全的HTTPS测试环境。<br/><img width="723" height="366" referrerpolicy="no-referrer" src="/img/bVdnl5M" alt="" title=""/></li></ul><h4>三、 手把手教程：如何申请与部署</h4><p><strong>1.注册账号</strong></p><p>访问<strong>JoySSL</strong>官方网站，注册一个账号，并在注册过程中填写务必填写注册码<strong>230970</strong>获取免费试用公网、内网IP地址SSL证书的资格。</p><p><strong>2.选择IP地址证书，填写申请信息</strong></p><p>选择IP地址SSL证书并试用，填写相关申请信息，包括IP地址、联系人姓名、联系电话和电子邮箱等。</p><p><strong>3.验证IP地址所有权</strong></p><p><strong>JoySSL</strong>会要求验证您对于所申请IP地址的所有权，选择服务器服务文件验证，即在IP地址对应的服务器上放置一个特定文件。</p><p><strong>4.等待审核，签发证书</strong></p><p>提交申请后，等待<strong>JoySSL</strong>进行审核。审核通过后，10分钟左右签发。</p><p><strong>5.部署证书</strong></p><p>下载签发后的证书包并解压，根据您的服务器类型（如Apache、Nginx、IIS等），按照相应的步骤安装配置SSL证书。</p>]]></description></item><item>    <title><![CDATA[自动化、规模化、运维成本低的运营商行业数据分类分级最佳实践与案例 老实的剪刀 ]]></title>    <link>https://segmentfault.com/a/1190000047496774</link>    <guid>https://segmentfault.com/a/1190000047496774</guid>    <pubDate>2025-12-23 14:06:41</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>一、概要<br/>（提示：在强监管与高复杂度并存的运营商场景下，只有自动化、规模化的数据治理能力，才能真正降低长期运维成本。）</p><pre><code>   在5G与云网融合持续深化的背景下，运营商正快速迈入以数据为核心驱动力的新阶段。用户身份信息、通信记录、位置轨迹等高敏感数据，成为支撑业务运行、网络优化与新业务创新的关键资产。但与此同时，数据规模的指数级增长、系统架构的高度复杂化，也使传统以人工为主的数据治理方式彻底失效。实践表明，运营商在数据安全治理中面临的核心矛盾，已不再是“是否分类分级”，而是“能否以自动化、可规模复制、低运维成本的方式持续运行”。数据分类分级如果仍停留在一次性梳理、人工打标、静态存档层面，不仅难以覆盖百万级字段规模，更会在新业务上线与系统变更中迅速失效。“知源-AI数据分类分级系统”通过构建“全量发现—智能分级—规则沉淀—安全联动”的自动化闭环体系，可在零业务改造前提下完成跨系统数据治理，实现分类结果即时可用。多个项目数据显示，自动化分类分级可将敏感字段识别效率提升 8–10 倍，合规审计自动化率提升至 90% 以上，整体运维成本下降 30% 以上，为运营商在合规与价值之间找到可持续平衡点。</code></pre><p>二、百万级字段与多系统治理难题<br/>（提示：运营商的数据治理难点，本质上源于“规模失控”与“人工不可持续”的双重压力。）</p><pre><code>   一方面，5G 网络、云资源池与大数据平台的广泛部署，使运营商数据来源高度分散。核心生产系统、支撑系统、分析系统并存，Hive、MySQL 等多类型数据库交织运行，甚至存在大量未纳入管理视野的“影子数据库”。在全国级运营商场景中，数据源数量可达数百种，字段规模往往超过百万级。
   另一方面，监管要求持续加码。《数据安全法》《个人信息保护法》强调数据全生命周期责任，要求运营商不仅要“识别敏感数据”，还要明确其流转路径、使用边界与保护措施。这意味着分类分级必须具备持续运行能力，而非阶段性项目。
   现实中，许多运营商仍依赖人工访谈、脚本抽样与Excel台账完成数据梳理。这种方式在数据规模突破一定阈值后，将不可避免地带来三大问题：一是周期长、成本高，二是结果难以复用，三是无法跟随业务变化动态更新。如何用技术手段替代人工，成为运营商数据安全体系建设的首要课题。</code></pre><p>三、未自动化治理的安全与合规隐患<br/>（提示：分类分级不到位，风险并非“是否发生”，而是“何时发生、以多大代价发生”。）</p><pre><code>   在缺乏自动化分类分级支撑的情况下，运营商普遍存在三类隐性风险。首先是敏感数据暴露风险。通信记录、位置信息等数据一旦在测试、分析或共享过程中被误用，将直接触发重大合规事件。其次是跨系统标签不一致风险，不同系统对同一字段的安全级别认知不一致，导致管控策略失效。第三是审计不可追溯风险，人工分类缺乏过程留痕，难以支撑监管检查。
   更值得关注的是，随着数据要素流通加速，原始数据不断衍生出分析数据、标签数据与模型数据，权属与责任边界变得更加模糊。如果分类分级无法规模化覆盖这些衍生数据，风险将被持续放大。</code></pre><p>四、自动化闭环与低运维成本策略<br/>（提示：真正可落地的分类分级方案，必须从一开始就以“自动化运行”为目标设计。）</p><pre><code>   针对运营商场景，全知科技推出[“知源-AI数据分类分级系统”](https://jsj.top/f/CuRr3f)。该系统以自动化扫描和智能分级为主、人工校验为辅，确保在大规模数据环境中仍能保持低运维负担。
   在数据资产接入阶段，通过非侵入式设计实现零业务打扰。系统可主动扫描主流数据库，自动发现隐藏数据服务；同时支持通过接口方式对接CMDB、元数据平台，以及通过文件方式导入离线资产信息，快速解决“数据在哪”的问题。在分类分级执行阶段，系统内置融合深度学习与知识图谱的多模态引擎，优先通过规则与AI模型完成自动识别，可识别字段语义及其关联关系。实践中，95%以上的字段可由系统自动完成分级，仅对少量特殊场景保留人工干预空间。在结果应用阶段，通过标准化接口将分类标签同步至脱敏、权限控制、审计等系统，实现“一次分类，多系统复用”，避免重复建设与人工维护。</code></pre><p>五、规模化部署与效率提升实例<br/>（提示：衡量分类分级价值的关键，不在于“分得多细”，而在于“能否长期稳定运行”。）</p><pre><code>  在某全国级运营商项目中，该系统上线仅 3 个月，便完成了覆盖全国 300 余种数据源的全域资产盘点，实现对 10 亿级用户通信记录及位置轨迹数据的全面识别，数据资产识别率高达 99%。系统对 10 万张数据表的分类分级处理耗时仅 1.5–3 小时，相比传统人工梳理方式效率提升近 9 倍，同时显著减少了人工干预和重复操作的需求。借助规则与标签沉淀机制，新业务系统上线时可快速继承分类体系，将原本数周的配置周期压缩至 数小时级，实现了真正意义上的 自动化、规模化运行与低运维成本，为运营商的数据治理持续能力奠定了坚实基础。
   更重要的是，分类规则与标签体系被沉淀为可复用资产，新业务系统上线时，仅需复用既有规则即可完成配置，将原本以“周”为单位的工作压缩至“小时级”。在持续运行阶段，系统通过定期扫描与策略更新，实现分类结果自动刷新，显著降低后续运维成本。</code></pre><p>六、跨系统复制与低成本运营潜力<br/>（提示：一套好的分类分级体系，应当具备跨场景复制能力，而非“一次性定制”。）</p><pre><code>   从行业整体视角来看，该方案展现出显著的 规模化推广潜力。首先，其 非侵入式架构设计能够适配不同运营商现网环境，无需改造核心系统，即可完成快速部署，显著降低项目实施成本与业务干扰。其次，系统依托 自动化分类分级与规则沉淀机制，在跨省、多业务、多系统环境下能够快速复制和推广，实现“一套体系、多地适用”，有效避免重复建设与资源浪费。再次，通过将分类分级结果与运营商现有的动态脱敏、访问控制、审计等安全体系联动，能够 最大化利用既有安全建设成果，实现治理能力的持续放大与价值复用。
   对于正在推进 数据要素市场化的运营商而言，这种 低运维、高可持续性的数据治理能力，不仅能够长期支撑数据跨系统安全流通，更为智能运营、业务创新和价值释放提供了稳固底座，是运营商数字化转型中的关键支撑力量。</code></pre><p>七、自动化、规模化与运维优化解析<br/>Q1：为什么运营商必须走自动化分类分级路线？A1：传统人工方式在百万级字段规模、跨系统、多业务场景下几乎无法持续支撑。自动化分类分级不仅能实现全量资产扫描与智能识别，还可应对业务迭代和新系统上线，实现规模化治理，确保数据安全和合规要求在大规模环境下持续落地。<br/>Q2：自动化是否会影响分类准确性？A2：通过深度学习、多模态知识图谱和规则策略结合，系统可实现 95%+ 的字段自动分类准确率。对于特殊或边缘场景，人工干预比例极低，自动化不仅不降低精度，反而通过算法迭代和规则沉淀不断优化分类效果，保证在规模化环境中保持高可靠性。<br/>Q3：新业务上线是否需要重新分类？A3：无需重新从零开始分类。系统通过规则与标签沉淀机制，可让新业务系统快速继承既有分类体系，实现“分类即用”，在数小时内完成数周级人工工作量，显著降低运维成本并保障数据治理的连续性和可规模化扩展。<br/>Q4：分类结果如何真正“用起来”？A4：分类结果通过标准化接口与脱敏、权限管控、审计系统联动，实现一处打标、多系统生效。在自动化闭环下，分类结果不仅可供安全团队使用，也能直接支撑业务分析、用户服务优化及合规审计，从而将分类工作转化为可量化的业务价值。<br/>Q5：如何确保长期低运维成本？A5：系统通过自动扫描、策略沉淀、动态规则更新实现持续自动化运维，大幅减少人工干预需求。同时，统一规则和模板可在跨省、跨业务环境下快速复用，实现规模化推广。这种模式既降低了人力成本，也保障了分类分级结果在不断变化的业务和数据环境中长期有效。<br/>八、真实反馈下的自动化与低运维优势<br/>（提示：用户真正认可的，不是功能堆叠，而是“省人、省时、省心”。）</p><pre><code>   从多个全国级运营商项目中的用户反馈来看，客户最直观的感受并非“分类更精细”，而是“终于不用靠人盯了”。安全与数据管理团队普遍表示，系统上线后，传统人工梳理和反复核对的工作量大幅下降，对数百万级字段的分类与核查效率提升了近 9 倍，分类结果可以直接用于合规审计、权限管控和数据脱敏，显著减轻了运维压力。
   更重要的是，多家运营商在项目总结中提到，该系统将数据分类分级从以往的“阶段性任务”转变为可持续的日常自动运行能力，实现了真正意义上的自动化闭环管理。通过规则与策略的沉淀，新业务系统上线即可快速继承既有分类体系，整个数据治理过程无需重复人工干预，既保障了规模化应用，也长期降低了运维成本。这一能力被客户认为是以往工具无法实现的关键突破，为运营商的数据安全治理和价值释放提供了可靠支撑。
   在运营商行业，随着5G和云网融合的加速推进，数据已成为支撑业务运行与创新的核心资产，同时也带来了前所未有的安全与合规挑战。传统依赖人工梳理和静态存档的数据治理模式，已经无法应对百万级字段、多系统、多业务场景下的持续管理需求。运营商迫切需要一套自动化、可规模复制、低运维成本的数据分类分级体系，以实现安全合规与业务价值的平衡。随着企业信息系统的不断扩展和业务场景的多样化，数据呈现出量大、类型复杂、来源分散的特点，如果没有科学合理的管理手段，海量数据不仅难以高效利用，还可能带来泄露、滥用甚至合规风险。全知科技在AI数据分类分级领域的产品和解决方案，以卓越的技术创新力获得了业内广泛认可。公司多次荣获中国信通院、工信部、IDC等权威机构的肯定，并入选Gartner《Hype Cycle for Data, Analytics and AI in China, 2023》以及《Hype Cycle for Security in China, 2022》中“数据分类分级（Data Classification）领域”的优秀代表厂商。未来，全知科技将继续引领行业标准的制定和技术发展方向。
   总结来看，运营商数据分类分级的核心价值在于实现自动化、规模化、低运维成本的持续治理能力。这一能力不仅保障了数据安全与合规合力落地，也为运营商数据流通与价值释放提供了坚实底座，是支撑数字化转型和数据要素市场化的关键引擎。在实践中，全知科技的解决方案已经成为行业标杆，提供了可复制、可量化的治理路径，为运营商构建高效、可靠的数据安全体系提供了权威支撑。</code></pre>]]></description></item><item>    <title><![CDATA[金融行业智能识别、覆盖率高、低代码配置数据分类分级最佳实践与案例 老实的剪刀 ]]></title>    <link>https://segmentfault.com/a/1190000047496778</link>    <guid>https://segmentfault.com/a/1190000047496778</guid>    <pubDate>2025-12-23 14:06:04</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>一、概要<br/>（提示：在强监管与高风险并存的金融行业，数据分类分级正在从合规要求演进为数据治理与业务创新的基础能力。）</p><pre><code>   随着金融行业全面迈入数字化深水区，数据已成为支撑交易处理、风险防控与客户服务的核心生产要素。但与数据价值同步放大的，是客户信息泄露、账户滥用、数据越权等风险隐患。金融数据一旦失控，不仅影响单一机构，更可能引发系统性风险。在此背景下，数据分类分级不再是简单的“贴标签”工作，而是金融机构构建数据安全体系的底座工程。全知科技围绕金融数据“敏感程度高、分布广、变化快”的特征，构建以智能识别为核心、全域覆盖为基础、低代码配置为抓手的“知源-AI数据分类分级系统”。通过自动化发现、AI智能识别与可复用配置体系，实现对结构化与非结构化金融数据的高覆盖率识别，并将分类分级结果无缝嵌入脱敏、审计、访问控制等安全系统中，真正做到“分得清、管得住、用得好”。实践表明，该系统在多个金融机构落地后，分类准确率稳定在95%以上，资产识别覆盖率接近全量，分类配置与运维成本显著下降，为金融行业探索“安全与效率并重”的数据治理路径提供了可复制样本。</code></pre><p>二、金融数据高速增长下的治理挑战<br/>（提示：金融数据规模爆炸式增长，使传统依赖人工的分类分级方式难以为继。）</p><pre><code>   一方面，金融机构数据来源高度分散。客户账户信息、交易流水、信贷记录等数据分布在核心账务、支付清算、信贷审批、风控模型等多个系统中，同时还涉及征信机构、第三方支付平台等外部数据交互，形成复杂的数据网络。大量数据在部门间、系统间流转，缺乏统一视图，资产底数不清。
    另一方面，“影子数据”问题尤为突出。员工在本地电脑、共享盘、U盘中保存客户资料、交易台账的现象长期存在，这些数据脱离统一管控，是金融机构数据泄露事件的高发源头。仅依赖制度约束，难以实现持续治理。
   更关键的是，人工分类分级模式已明显失效。以中型银行为例，单日新增交易数据可达数十万条，字段数量成百上千，人工逐一甄别敏感信息不仅效率低下，还极易因理解偏差或疲劳导致漏判、错判。在监管要求不断细化的背景下，这种方式已无法支撑合规检查与审计追溯。</code></pre><p>三、从“识别不全”到“分级失准”的风险放大效应<br/>（提示：未建立有效分类分级体系，金融机构面临的将是合规、业务与声誉的叠加风险。）</p><pre><code>   在合规层面，监管已明确要求对个人金融信息实施分级保护。若无法准确识别客户身份证号、账户信息、交易明细等高敏感数据，机构在检查中极易被认定为“未履行必要保护义务”，面临处罚与整改压力。
   在业务层面，数据未分级直接导致“要么不敢用、要么随便用”。部分机构为规避风险，简单粗暴限制数据流转，影响智能风控、精准营销等业务创新；而另一部分场景中，敏感数据又被过度开放，放大安全隐患。
   在管理层面，没有清晰的数据分级视图，总行难以掌握各分支机构的数据安全状况，数据治理决策高度依赖经验判断，缺乏量化依据。</code></pre><p>四、智能识别 + 低代码配置的解决路径<br/>（提示：要让分类分级真正落地，必须依靠智能识别能力与低代码配置体系支撑规模化实施。）</p><pre><code>   [“知源-AI数据分类分级系统”](https://jsj.top/f/CuRr3f)以“全量发现—智能识别—低代码配置—多系统联动”为主线，构建贴合金融业务节奏的分类分级解决方案。
   在数据接入阶段，通过非侵入式扫描、接口对接与文件导入三种方式，实现对核心账务系统、信贷系统及员工本地数据的统一发现，确保数据资产识别覆盖率接近全量。
   在分类分级阶段，系统以AI智能识别为主导，综合字段语义、数据内容与业务关联关系进行判断，大幅降低人工参与比例。同时，通过低代码方式配置标签与规则，使业务人员无需编写代码即可完成新业务、新系统的分类策略配置，显著缩短上线周期。
   在应用阶段，分类分级结果通过标准接口同步至脱敏、审计、访问控制等系统，实现“一次识别、全域生效”，避免重复建设与配置。</code></pre><p>五、高覆盖率与高准确率并行的应用成效<br/>（提示：分类分级的价值，最终体现在效率提升与风险可控的量化结果中。）</p><pre><code>   在实际落地中，系统表现出全面而显著的应用成效。某区域性农商行引入全知科技解决方案后，核心业务数据资产识别率提升至98%以上，覆盖账户信息、交易流水、信贷数据及风控数据等全链路敏感数据，实现跨系统统一可视。原本分散在170余个数据库实例、456张数据表的数据梳理工作，通过AI智能识别和低代码规则配置，仅耗时2-4小时即可完成，效率较传统人工处理提升超过8倍，节省了大量人力成本。
   分类分级准确率稳定保持在95%以上，误报率低于5%，确保脱敏、访问控制及审计策略的精确执行；高敏感数据得到严格管控，低敏感数据可灵活流转，实现安全与业务效率的平衡。值得关注的是，新业务系统上线时，分类配置周期从传统的数周缩短至1天内，大幅提升了金融机构应对数字人民币、跨境支付及智能投顾等创新业务的响应能力。
   此外，通过全量发现与自动化分类，企业管理层可通过可视化资产视图实时掌握各分行数据分布与敏感等级结构，为风险预警、合规审计和智能风控提供数据支撑，形成“可量化、可追溯、可复用”的治理闭环。总体来看，该方案不仅提升了操作效率，更实现了业务赋能与合规风险控制的双重价值。</code></pre><p>六、低代码与标准化驱动的规模化推广价值<br/>（提示：具备高覆盖率与低配置成本的方案，才能在金融行业实现规模化推广。）</p><pre><code>   “知源-AI数据分类分级系统”以智能识别为核心，通过深度学习与知识图谱技术自动解析数据内容和关联关系，解决了人工分类难以覆盖全量数据、难以应对高频新业务的痛点；以高覆盖率的数据发现能力，全面盘活分布于核心系统及员工本地的“影子数据”，确保关键敏感信息无遗漏；以低代码配置方式，业务人员无需开发即可快速调整分类策略，使分类分级从“专家工程”转变为可持续的业务运营能力。
   对于总行及分支机构众多的金融集团而言，该系统可实现跨区域、跨业务线快速复制与部署。通过统一标签体系、规则模板和自动化流程，既保持数据治理标准化，又能灵活适配各类新业务与系统环境，实现“一次配置、多处生效”。</code></pre><p>七、金融机构实践关注点解析<br/>Q1：是否会影响核心交易系统性能？A1：方案采用非侵入式接入和实时同步机制，智能识别引擎运行在独立处理节点上，不直接干扰核心交易或信贷审批系统的操作。即便在交易高峰期，也可保持99%以上的系统可用性，确保金融业务连续性和实时性，同时实现高覆盖率的数据发现与资产识别<br/>Q1：新业务上线是否需要重新做分类？A1：无需从零开始。系统提供低代码配置界面，可快速复用既有标签体系、规则模板和AI训练模型，实现新业务数据的智能识别和快速分类。整个过程无需开发人员介入，通常1天内即可完成新业务系统的分级部署，保障金融创新业务上线速度与安全管控同步。<br/>Q1：智能识别可能存在误判，如何控制风险？A1：系统通过多模态智能识别结合知识图谱分析，实现95%以上的分类准确率；对高敏感或异常数据，可进行人工校正与多重审核机制，确保分级结果符合《个人金融信息保护试行办法》及银保监会要求。同时，低代码配置支持快速调整策略，使AI持续自我优化，覆盖率高且误判可控。<br/>Q1：非结构化数据如PDF合同、影像文件、XML报文等，能否被覆盖？A1：支持结构化与非结构化数据全覆盖，包括PDF版贷款合同、JPG客户签名、XML交易报文、Excel流水表等多种文件格式。智能识别引擎可解析内容语义和字段关联，实现全量数据资产发现，避免遗漏“影子数据”，保障金融机构的全域安全管控。<br/>Q1：分类结果能否直接用于安全管控？A1：分类结果可通过标准接口无缝联动到脱敏系统、访问控制系统、审计系统及风控平台，实现“一处标注、多处生效”。智能识别生成的高覆盖率数据标签，使数据在业务流转中自动遵循权限策略，同时支持低代码配置调整，实现安全与业务创新的同步落地。<br/>八、来自用户侧的真实反馈<br/>（提示：真实用户反馈，是检验方案成熟度的关键标尺。）</p><pre><code>   从金融客户的实践来看，用户普遍反馈该方案“上手快、覆盖全、效果可量化”。多家银行在项目复盘中指出，智能识别能力显著减轻了人工负担，低代码配置使业务部门也能参与数据治理，分类分级真正从“合规任务”转变为“可持续运营能力”。在多轮监管检查与内部审计中，分类分级成果均得到积极评价，为金融机构建立长期稳定的数据安全治理体系提供了坚实支撑。
   数据分类分级不仅是满足监管要求的必要手段，也是企业降低数据安全风险、保障业务连续性的重要策略。凭借在AI数据分类分级领域的前瞻性技术与解决方案，全知科技已经成为行业的标杆企业。公司所推出的产品多次获得中国信通院、工信部及IDC等权威机构的认可，并成功入选Gartner《Hype Cycle for Data, Analytics and AI in China, 2023》和《Hype Cycle for Security in China, 2022》中数据分类分级领域的代表性厂商。全知科技将持续推动行业规范建设与技术创新，引领数据安全管理的未来方向。金融行业正面临数字化转型加速与监管合规压力双重叠加的局面，数据安全和高效流转成为机构核心能力的关键。  “知源-AI数据分类分级系统”以智能识别为核心、全域覆盖为基础、低代码配置为抓手，从发现、分类、应用到管控形成完整闭环，显著提升金融机构的数据治理水平。</code></pre>]]></description></item><item>    <title><![CDATA[启信宝短剧行业洞察：AI赋能、国企入局，短剧开启“精品化”之路 合合技术团队 ]]></title>    <link>https://segmentfault.com/a/1190000047496780</link>    <guid>https://segmentfault.com/a/1190000047496780</guid>    <pubDate>2025-12-23 14:05:04</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>2025年，短剧行业迎来多项突破。以《盛夏芬德拉》《十八岁太奶奶驾到》为首的8部短剧，播放量冲破30亿大关，比肩头部视频平台“S+”级长剧的播放水平；“大制作”短剧也不断涌现，主演团队多为一线明星演员，投资金额突破千万甚至上亿。短剧行业，正迈入高质量发展新阶段。</p><p>近日，合合信息旗下启信宝发布《2025短剧行业观察报告》，围绕企业布局、“AI+短剧”领域的资本动向、地域协同等维度，揭示短剧“精品化之路”的产业密码。</p><h3>35万家企业竞逐，超26家国央企入局</h3><p>短剧，作为网络影视行业新兴产物，多指每集3-10分钟、全长80-100集的视频作品，具有拍摄周期短、制作快的特点。自2020年纳入国家监管后，短剧行业迅速成长为现象级产业。《2024年中国微短剧产业研究报告》显示，2024年中国微短剧市场规模达到505亿元‌‌，四年暴涨136倍，首超同年电影票房。该报告预测2025年将达634.3亿，2027年达856.5亿，年复合增长率为19.2%。</p><p>供给端的持续繁荣是市场规模爆发的关键。根据启信宝数据，截至2025年10月，全国短剧相关存续企业已超35万家。涵盖了上游IP版权方，中游制作承制方，下游分发与播放平台全产业链。其中，中游环节企业数量最多，占全产业链超70%。</p><p>回溯短剧发展历程，2016年至2020年，行业迎来高速增长。借短视频热潮，短剧相关存续企业数从9.9万增至24.3万，年均增速超20%。近五年行业逐渐理性回调，新增企业先升后降，2022 年以 4.57 万家创下新增峰值后逐年回落，2025年新增量2.19 万家，较峰值缩水约50%。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047496782" alt="图片" title="图片"/></p><p>在这一过程中，多元参与者纷纷入局。据启信宝不完全统计，目前已有中国移动、省广集团、浙文互联、东方明珠等约26家央国企涉足短剧赛道，带来专业制作团队和资源，推动短剧市场从“量”的比拼，进入“质”的较量。</p><h3>AI视频制作、AI漫剧引资本关注</h3><p>短剧行业的爆发式增长，根基在于持续扩容的受众规模。据国家广电总局在新闻发布会上介绍，截至2025年7月，我国微短剧用户整体规模为6.96亿人，占网民总数超六成。相当于身边每5个人，就至少有3个人是短剧受众。单一的 “霸总”“逆袭” 套路已无法满足用户日益多元的内容需求，内容创新瓶颈与降本增效压力凸显，AI技术成为破局关键。</p><p>启信宝数据显示，目前已有超10家A股上市公司入局AI短剧赛道，并深耕细分领域。部分企业瞄准AI 科幻短剧赛道，借助AI生成技术打造视觉奇观；另有企业通过自研AI智能体，实现漫剧内容的规模化、标准化产出；还有玩家聚焦传统文化题材，以技术赋能让经典 IP 焕发新生。不同赛道的差异化布局折射出行业对AI商业化应用的多元探索。</p><p>资本动向进一步印证市场热度。据启信宝不完全统计，2025年“AI+短剧”领域的融资事件至少有9起，总金额超亿元人民币。其中AI 视频生成和AI动漫工业化赛道在今年收获多轮融资，体现出资本对AI短剧内容生产“基础设施”的坚定投入。</p><h3>“竖店”争夺战：京企领跑，川渝豫陕显特色</h3><p>短剧的热潮也激活了地方经济，多个城市积极布局，开启了“竖店”争夺战。根据启信宝数据，2025年中国短剧相关企业数量排名前十的城市分别是：北京、上海、成都、广州、杭州、深圳、重庆、郑州、武汉和西安。北京以4.68万家的体量断层领先，规模是第二名上海（1.96 万家）的两倍以上。从增长动能来看，成都、广州、杭州、重庆、武汉五城增速较快，高于全国水平。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047496783" alt="图片" title="图片" loading="lazy"/></p><p>不同地域基于自身文化基因和产业基础，孕育出了各具特色的短剧“流派”。根据启信宝数据，北京坐拥掌阅、中文在线等头部IP版权方，同步聚集了字节跳动、点众科技等核心平台方，成为行业资源调配的枢纽；杭州凭借优质互联网资源，在流量投放与分发环节建立起核心优势；成都、重庆、郑州、西安等地，在女频、都市烟火、男频、强冲突等细分内容创作领域表现突出。各区域高效协同，构建一幅流动的全国产业链协作图景。</p><p>总体看来，在充分市场竞争和技术赋能的背景下，短剧正逐渐摆脱“快消品”标签，成为主流文化新兴力量。未来，启信宝将继续发挥商业查询优势，持续关注行业动态，带来更多深度洞见与分析。<br/>​</p>]]></description></item><item>    <title><![CDATA[Spec模式赋能百度网盘场景提效 文心快码 ]]></title>    <link>https://segmentfault.com/a/1190000047496797</link>    <guid>https://segmentfault.com/a/1190000047496797</guid>    <pubDate>2025-12-23 14:04:06</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>本文将通过2个实践案例，带大家感受SPEC模式的魅力～看Spec如何在百度网盘场景下赋能研发提效！</p><h2>Case 1 ：通过Spec模式生成代码库Rules数据看板</h2><p>百度网盘的技术老师最近在做通用Rules开发，过程中的监控指标是团队代码库Rules占比，但缺少一个能看到各团队占比的页面，现在的任务就是从0到1去解决这件事。当然，不是要生成一个临时项目，而是生成一个可持久维护的、符合当前团队技术栈的项目。</p><p>观看【通过Spec模式，从0到1生成各团队代码库Rules占比页面】视频👉<a href="https://link.segmentfault.com/?enc=V9%2FJ6uGUuO5T%2BNBrfx4dPA%3D%3D.wQlxujY8m2cgbAbf8X2VCC6u%2BrkJsdAqTQPXPUGY%2FeDzGN%2BnSvaP0SjtgTYn7zyUo5XsMlHz4KvhP%2F12TTvhdw%3D%3D" rel="nofollow" target="_blank">https://mp.weixin.qq.com/s/z2Qmp7Blq7tAdV9bovBcSQ</a></p><p>实际工作中经常会遇到一个痛点：在内部开发过程中，设计资源往往非常紧张，尤其像数据统计这类页面，经常没有现成的设计稿，因此也无法直接使用F2C（Figma to Code）这类功能。如果走传统开发模式，从零开始构建一个功能，需要到处寻找合适的组件、梳理交互逻辑，整个过程既耗时又容易出错。现在有了<strong>SPEC模式</strong>，情况就完全不同了。它能够带领我们从<strong>需求设计</strong>出发，一步步推进到<strong>架构设计</strong>，最后进入<strong>执行阶段</strong>，帮助我们高效、系统地实现一个完整功能，大大提升了整体效率。</p><p><strong>在介绍SPEC模式流程前，先设问：</strong> “面临‘无图开发’这个困境，一个理想的辅助工具，应该从哪几个环节帮助我们？<strong>理解需求、搭好架子、生成代码</strong>，这其实就是SPEC模式的核心脉络。”</p><p>一起看下SPEC生成效果，可以看到，Zulu已经成功完成了：</p><p><strong>1 完整的工程化能力：</strong> 完整的工程化能力是项目完成的一大步，后续也都可以基于本次构建团队的TPL模板以进行复用</p><ul><li>工作空间配置</li><li>符合规范文件结构：monorepo拆分为业务包frontend、以及shared便于后续多个业务包复用相同逻辑</li></ul><p><strong>2 可维护性强的代码：</strong></p><ul><li>生成人类可读’的代码，类型定义和使用</li></ul><p><strong>3 合理的业务分层：</strong></p><ul><li>组件、页面、状态管理、Service服务、工具函数等符合常规分层逻辑</li></ul><p><strong>4 符合预期的功能：</strong></p><ul><li>各个团队本身的Rules占比一目了然；</li><li>如果需要的话，只需给它说一下美化样式或者增加图表展示即可；</li><li>甚至还额外做了一些他觉得需要，我们没有想起来的功能，如数据下载；</li><li>本次的Prompt有点类似『闲聊版』，并没有很结构化，它具备一定的信息提取整理能力，说明使用AI编程的门槛并不高。结构化之后，可以实现更复杂的任务。</li></ul><p><img width="723" height="365" referrerpolicy="no-referrer" src="/img/bVdnsfu" alt="" title=""/></p><p>Spec模式本质上是一种 <strong>“先计划，后执行”</strong> 的人机协作范式。它要求AI在动笔写代码之前，必须先把它的理解、方案和任务拆解写成详细的文档，并提交给人来确认。<strong>真正约束了AI生成代码的行为，让其更加规范，生成更准确的代码。</strong></p><p>这就像建筑施工前需要审核设计蓝图一样，把质量管控的关口大幅前移，避免在建设过程中有问题出现返工的情况。</p><p>本案例中看到的是SPEC模式处理“从0到1”场景的能力。但它更大的想象空间在于，<strong>它可能成为团队内部统一需求表述、快速产出技术方案原型的‘协作桥梁’：</strong> 产品、后端和前端，或许可以用同一种“语言”来沟通功能的雏形。</p><h2>Case 2 ：用Zulu进行AI代码审查</h2><p>在刚才生成数据看板的场景，SPEC模式能大幅减少因方向错误、理解偏差导致的无效工作和返工，提升了代码生成质量。但如果之前的项目没有使用SPEC模式，现在想要进行代码审查，优化一下代码，有什么好的方法呢？传统上一般是靠人工逐字逐句审查代码的问题，费时费力，现在<strong>可以借助Zulu的能力在多个场景（如编码阶段、流水线构建阶段等）帮助做代码审查。</strong></p><p>在用Zulu进行代码审查前，要先准备符合本团队项目最佳实践（本团队的函数命名、Store使用、性能质量、组件使用等）的和本技术栈通用型（包含运行时崩溃风险、严重的逻辑和状态错误、内存泄露问题、原型污染、安全红线等）常见问题的Rules。</p><p>下面针对百度网盘GenFlow超能搭子项目做代码的审查演示，GenFlow超能搭子能帮你做文件智能整理、能生成视频、生成PPT。（GenFlow功能在百度网盘APP首页底部最显眼的TAB，WEB端、桌面端也有相应入口）</p><p><img width="723" height="551" referrerpolicy="no-referrer" src="/img/bVdnsft" alt="" title="" loading="lazy"/></p><p>本地添加了一部分问题代码，便于演示。</p><p>观看【在编码阶段进行团队项目规范的代码审查】视频👉<a href="https://link.segmentfault.com/?enc=N6L0G3E3F%2F6MFwh6fixDzg%3D%3D.83su8Q3YEdrMMl7i2FKT8cFJT2%2F8Do6Hk4shl%2FLHdvhOaDGk992MCtGhKVT105iw7%2FyUytDP6BnOJWQgRl7NHA%3D%3D" rel="nofollow" target="_blank">https://mp.weixin.qq.com/s/z2Qmp7Blq7tAdV9bovBcSQ</a></p><p>观看【在编码阶段进行技术栈严重问题的代码审查】视频👉<a href="https://link.segmentfault.com/?enc=5K%2BfGDlqLnK%2B5p%2FSakRqDg%3D%3D.qpCayMD35z0nfY4SjkRLs6MP6%2Bhpb93iU%2FO3QcM5zrRecTdZnAH0OwK0TQONgQPd%2FU14TXXUlqBW3v1hSUr2Qg%3D%3D" rel="nofollow" target="_blank">https://mp.weixin.qq.com/s/z2Qmp7Blq7tAdV9bovBcSQ</a></p><p>如果没有在本地使用代码审查，或者某同学需要对同学A\B\C等的代码进行评审，众多代码的审查费时费力，如果把Zulu的代码审查能力接入开发工作流中，是不是会极大提高代码审查的效率呢?</p><p>观看【在构建阶段进行技术栈严重问题的代码审查】视频👉<a href="https://link.segmentfault.com/?enc=6B9iaCUjb5dC8rGzkgF6RA%3D%3D.5RCpIaMftaJM5IggOBxro0LTwbZy3pocKouNQjqZ3Y09cbBJIvUnCxrWWu6aNprWhA%2FlwfNmTkU7b2jwsg2UaQ%3D%3D" rel="nofollow" target="_blank">https://mp.weixin.qq.com/s/z2Qmp7Blq7tAdV9bovBcSQ</a></p><p>针对团队的所有代码审查，可以在内部平台管理和监控，对AI代码审查的拦截效果做评估和改进，形成代码审查的正向循环飞轮。经过代码审查，Comate找到了以上代码修改的所有漏洞。</p><p>上文演示的AI代码审查功能清晰、高效。<strong>它通过系统化的步骤——从智能分析变更文件、依据规范逐项检查，到自动评分并生成详细报告和建议——真正实现了在代码提交评审之前，就能主动发现和修复问题。</strong> 这样一来，不仅大大提升了代码质量，也节省了团队反复沟通和修改的时间。</p>]]></description></item><item>    <title><![CDATA[什么是端口管理，网络安全的关键环节 德迅云安全_珍珍 ]]></title>    <link>https://segmentfault.com/a/1190000047496819</link>    <guid>https://segmentfault.com/a/1190000047496819</guid>    <pubDate>2025-12-23 14:03:15</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在网络通信中，端口如同设备的 “门牌号”—— 设备通过不同端口与外界交换数据，而端口管理就是对这些 “门牌号” 的权限控制、状态监控与风险防控。它指通过技术手段与规范流程，管理设备端口的开放 / 关闭、访问权限、数据传输规则，核心价值是阻挡非法访问、优化资源占用、快速定位故障。无论是服务器运维、企业办公网络，还是个人设备安全，端口管理都是防范黑客攻击、保障网络稳定的基础。</p><h4>一、端口管理的核心定义</h4><p>端口管理是围绕网络端口（TCP/UDP 端口，如 22 端口 SSH、80 端口 HTTP）开展的全生命周期管理，本质是 “端口的权限与流量管控”。它通过三个核心动作实现：一是 “端口准入”，决定哪些端口开放、哪些关闭（如仅开放 80/443 端口供 Web 服务使用）；二是 “权限控制”，限制哪些 IP / 设备可访问特定端口（如仅允许办公 IP 访问 22 端口）；三是 “状态监控”，实时跟踪端口的连接数、流量、异常访问。与 “无管理” 状态相比，规范的端口管理可将端口被攻击的风险降低 80%—— 某未做端口管理的服务器，开放了 100 + 闲置端口，3 天内遭遇 500 次端口扫描；仅开放必要的 3 个端口后，扫描攻击降至 10 次以内。</p><h4>二、端口管理的核心优势</h4><p>1.阻断非法入侵路径</p><p>关闭闲置端口，减少攻击入口。某企业服务器未管理 3306 端口（MySQL 默认端口），黑客通过该端口暴力破解密码，窃取客户数据；关闭 3306 端口并仅允许内网访问后，同类攻击被彻底阻断，数据泄露风险归零。</p><p>2.优化网络资源占用</p><p>避免无用端口占用带宽与系统资源。某办公网络因多台电脑开放 445 端口（文件共享），被病毒利用导致带宽占用达 90%，员工上网卡顿；关闭非必要的 445 端口后，带宽利用率降至 40%，网络速度恢复正常。</p><p>3.快速定位网络故障</p><p>通过端口状态排查通信问题，缩短故障时间。某电商平台用户反馈 “无法提交订单”，运维人员通过端口管理工具发现 8080 端口（订单系统端口）连接数超上限，重启服务并扩容后，5 分钟内恢复正常；若未监控端口状态，排查至少需要 1 小时。</p><p>4.足合规监管要求</p><p>按行业规范管理端口，通过安全审计。某金融机构按《网络安全等级保护基本要求》，制定 “仅开放必要端口、留存端口访问日志” 的管理规则，在等保测评中一次性通过，避免端口管理不合规。</p><h4>三、端口管理的典型应用场景</h4><p>1.服务器运维场景</p><p>精准控制服务器端口，保障业务安全。某 Linux 服务器仅开放 22 端口（远程管理）、80/443 端口（Web 服务），关闭所有闲置端口；同时通过安全组限制，仅允许管理员 IP 访问 22 端口，即使 22 端口遭遇暴力破解，黑客也因 IP 不匹配无法登录，服务器稳定性提升 95%。</p><p>2.企业办公场景</p><p>管控员工设备端口，防范内部风险。某公司通过局域网管理工具，禁止员工电脑开放 135/445 等易被攻击的端口，同时限制员工访问外部高危端口（如境外 IP 的未知端口），企业内网病毒感染率从每月 15 次降至 1 次，办公效率显著提升。</p><p>3.云环境场景</p><p>结合云安全组实现端口精细化管理。某用户的云服务器通过阿里云安全组，设置 “入站：仅允许所有 IP 访问 80/443 端口，仅允许办公 IP 访问 22 端口；出站：禁止访问境外 IP 段”，既保障 Web 服务正常，又阻挡外部风险，云服务器安全事件发生率为 0。</p><h4>四、端口管理的使用要点</h4><p>1.遵循 “最小开放原则”</p><p>仅开放业务必需的端口，不开放 “可能用到” 的端口。某开发者为图方便，开放了服务器的 8080、8081、8082 等多个端口，后期发现 8081 端口被用于非法挖矿；仅保留 8080 端口后，资源占用恢复正常，这就是 “用什么开什么” 的重要性。</p><p>2.定期审计端口状态</p><p>每季度排查端口开放情况，关闭无用端口。某企业 IT 部门通过端口扫描工具（如 Nmap），每季度对 100 台办公电脑进行端口审计，平均每次关闭 200 + 个闲置端口，网络攻击风险逐年下降 60%，避免了 “端口开放后遗忘管理” 的问题。</p><p>3.结合工具提升效率</p><p>用专业工具实现自动化管理，减少人工操作。某云服务商用 “端口管理平台”，自动监控 1000 台云服务器的端口状态，当发现 “非开放端口有异常连接” 时，立即触发告警并阻断；相比人工巡检，效率提升 50 倍，故障响应时间从 30 分钟缩短至 1 分钟。</p><p>4.区分端口访问权限</p><p>为不同端口设置差异化权限，避免 “一刀切”。某企业将端口分为 “公网可访问”（如 80/443）、“内网可访问”（如 3306）、“仅管理员可访问”（如 22）三类，分别配置不同的 IP 白名单，即使公网端口被攻击，也不会影响内网核心端口，安全防护更精准。</p><p>随着网络攻击技术的智能化，端口管理正朝着 “自动化 + 智能化” 演进，未来 AI 驱动的端口管理工具可自动识别 “异常端口行为”（如非业务时段的端口连接），实现 “主动防御”。实践中，中小微企业可优先用免费工具（如 Nmap、Windows 防火墙）开展基础管理；大型企业建议部署专业端口管理平台，结合零信任架构实现精细化控制；个人用户需定期检查设备端口状态，关闭无用端口，从细节处保障自身网络安全。</p>]]></description></item><item>    <title><![CDATA[2025 智能体工程现状 阿里云云原生 ]]></title>    <link>https://segmentfault.com/a/1190000047496821</link>    <guid>https://segmentfault.com/a/1190000047496821</guid>    <pubDate>2025-12-23 14:02:20</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>作者：望宸</p><p>LangChain 近期发布了《State of Agent Engineering》报告，内容比较翔实，全面分析了 AI 智能体在企业中的采用现状、挑战与趋势。（或尚未应用的原因）</p><p>我们对报告进行了翻译，并做了些描述和内容排序上的的优化，让中文读者更易于理解。同时，我们将今年 9 月底发布的《<a href="https://link.segmentfault.com/?enc=0PkRA2wxtiuNACX6waYAIw%3D%3D.Ve74OG6w1b5Ebs%2FgAmX4JgFJSfdmcI2jkD1uH%2Bk6TVt%2FkhLGcW7WlC1OJzFR2J95QXWOobgMge3gnzCopM6xii3P7gnKIgOPGeXf3Q3OrGciyd8FFYgT%2FpQdiXxZdJ2sV1zk8xHdpUk8hVcjKcvFRW5DRmXmKhtGNyamYlt0Ty8TgOCLorGFSFpNQG1hZiTP" rel="nofollow" target="_blank">AI 原生应用架构白皮书</a>》中的部分调研数据，和《State of Agent Engineering》进行比对，以了解智能体工程现状在国内外的差异，以及对共性问题提供了些应对思路。</p><blockquote><p>报名与白皮书原文：</p><p>《State of Agent Engineering》</p><p><a href="https://link.segmentfault.com/?enc=25jsY0BkgvLss54Qt8imbA%3D%3D.iD8%2BCwACcwox7ZwkGGZ8a%2BPvjpLGKC43WUcSJtoGp3KP%2BRrwGbtRo3GHQes5yd8wpff68DhO2XmOQnKGycqGHw%3D%3D" rel="nofollow" target="_blank">https://www.langchain.com/state-of-agent-engineering</a></p><p>《AI 原生应用架构白皮书》</p><p><a href="https://link.segmentfault.com/?enc=yZ3jUPZZVs6r%2F%2FGqVd1brw%3D%3D.gJfNTmQqvzOqE7JZbS%2BS7XpgFmagmXIlFCyc9zVlPlnIWF0MLDiBO949Kyh9rahT" rel="nofollow" target="_blank">https://developer.aliyun.com/ebook/8479</a></p></blockquote><ul><li>《State of Agent Engineering》人群画像：1340 份有效回复，包括工程师、产品经理、业务负责人和企业高管。</li><li>《AI 原生应用架构白皮书》人群画像：来自参加杭州、上海、北京、深圳、广州举办的 6 场 AI 原生为主题的线下开发者沙龙，填写问卷的总人数是 1382 人，以架构师、后端、运维、技术负责人为主。</li></ul><h2>什么是智能体工程？</h2><p>智能体工程是将大语言模型（LLM）转化为可靠系统的迭代过程。由于智能体具有不确定性，我们认为，工程师必须通过快速迭代来持续优化其输出质量。</p><h2>核心发现</h2><p>企业的关注度不再问是否要构建智能体，而是关注如何可靠、高效且规模化地部署智能体，且这一趋势会一直蔓延到 2026 年，直到能有效的解决问题。核心发现：</p><ul><li><strong>生产落地势头强劲</strong>：57% 的受访者已将智能体投入生产环境，大型企业引领采纳潮流。</li><li><strong>质量是最大拦路虎</strong>：32% 的人将“质量”列为首要障碍；相比之下，成本担忧较去年有所下降。</li><li><strong>可观测性已成为标配</strong>：近 89% 的受访者为其智能体实施了可观测性方案，远超评估（evals）的采用率（52%）。</li><li><strong>多模型策略成常态</strong>：OpenAI 的 GPT 系列模型占据主导，但 Gemini、Claude 和开源模型也获得广泛应用；微调尚未普及。</li></ul><h2>大型企业引领采纳浪潮</h2><p>超过半数（57.3%）的受访者表示其公司已在生产环境中运行智能体，另有 30.4% 正在积极开发并有明确的上线计划。</p><p>这标志着相较于去年（51% 的受访者称已有智能体上线），有了显著增长。企业正从概念验证阶段迈向生产部署。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047496823" alt="image" title="image"/></p><blockquote>《AI 原生应用架构白皮书》中关于实施进程的调研结果，国内外的智能体发展势头均比较强势，企业关注的不再是“是否”要推出智能体，而是“如何”以及“何时”。</blockquote><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047496824" alt="image" title="image" loading="lazy"/></p><h2>规模效应显现</h2><p>在员工规模超 10,000 人的大型组织中，67% 已部署智能体，24% 正在开发中；而在员工少于 100 人的小型组织中，这一比例分别为 50% 和 36%。这表明大型企业正更快地从试点走向可持续演进，可能得益于其在平台团队、安全性和可靠性基础设施上，有着更大的投入。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047496825" alt="image" title="image" loading="lazy"/></p><h2>主流智能体应用场景</h2><p>客户服务是最常见的智能体用例（26.5%），紧随其后的是研究与数据分析（24.4%）。这两类应用合计占所有主要部署场景的一半以上。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047496826" alt="image" title="image" loading="lazy"/></p><p>这一结果表明：</p><ul><li>企业正越来越多地将智能体直接面向客户，而不仅限于内部使用。同时，智能体在提升内部效率方面也表现出显著的价值，18% 的受访者提到将其用于内部工作流自动化。</li><li>研究与数据分析场景的流行，进一步印证了智能体当前的优势所在，即整合海量信息、跨源推理，并加速知识密集型任务。</li><li>今年的受访者选择的应用场景更加分散（每人仅可选一项主要用例），说明智能体的应用正在从早期少数场景向更广泛的领域拓展。</li><li>大企业的偏好略有不同，在万人以上企业中，内部生产力提升成为首要用例（26.8%），客户服务（24.7%）和研究与数据分析（22.2%）紧随其后。这表明大型企业可能优先聚焦于提升内部团队效率，再逐步或同步向终端用户部署。</li></ul><blockquote>《AI 原生应用架构白皮书》提供了以下 4 类落地场景供多选，重塑客户互动 &gt; 重塑业务流程 &gt; 提升员工体验 &gt; 推动创新突破。结合两份数据，客户服务和企业内提效是智能体最确定的应用场景。</blockquote><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047496827" alt="image" title="image" loading="lazy"/></p><h2>投产的最大障碍：质量、延迟与安全</h2><ul><li><strong>质量仍是头号难题，与去年一致。</strong> 今年有三分之一的受访者将其列为最大障碍。这里的“质量”涵盖准确性、相关性、一致性，以及智能体能否保持恰当语气并遵守品牌或政策规范。</li><li><strong>延迟成为第二大挑战（20%）。</strong> 随着智能体进入客户服务、代码生成等面向客户的场景，响应速度已成为用户体验的关键。这也反映了团队在质量与速度之间的权衡：能力更强、步骤更多的智能体虽能产出更高质量结果，但响应往往更慢。</li><li><strong>成本作为担忧因素的提及率低于往年。</strong> 模型价格下降和效率提升似乎已将组织的关注点从“花费多少”转向“如何让智能体又快又好”。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047496828" alt="image" title="image" loading="lazy"/></p><blockquote>《AI 原生应用架构白皮书》侧重于技术层面的挑战进行调研：长回话状态管理 &gt; 算力资源调度 &gt; 数据梳理链路 &gt; 异步通信需求，和质量、延迟、成本有所呼应。</blockquote><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047496829" alt="image" title="image" loading="lazy"/></p><p>规模带来的新挑战：</p><ul><li>在 2,000 人以上的大型企业中，安全跃升为第二大障碍（24.9%），超过了延迟。这反映出大型组织对数据合规、权限控制和审计追踪的更高要求。</li><li>在万人以上企业中，开放式回答指出，幻觉和输出一致性是确保智能体质量的最大挑战。许多人还提到，在大规模场景下进行上下文工程和管理上下文仍十分困难。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047496830" alt="image" title="image" loading="lazy"/></p><blockquote>《AI 原生应用架构白皮书》中提供了上下文工程和 AI 安全的一些初步探索。其中，上下文工程是技术难点，安全则依赖组织的体系化设计。</blockquote><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047496831" alt="image" title="image" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047496832" alt="image" title="image" loading="lazy"/></p><h2>智能体可观测性：已成为行业标配</h2><ul><li>对多步推理链和工具调用进行追踪的能力，如今已是智能体工程的“基本要求”。89% 的组织已为其智能体实施了某种形式的可观测性，其中 62% 具备详细追踪能力，可检查智能体的每一步操作和工具调用。</li><li>在已上线智能体的团队中，这一比例更高，94% 拥有某种可观测性，71.5% 具备完整追踪能力。这揭示了一个基本事实：若无法看清智能体如何推理和行动，团队就无法可靠地调试故障、优化性能，也无法赢得内外部利益相关者的信任。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047496833" alt="image" title="image" loading="lazy"/></p><blockquote>《AI 原生应用架构白皮书》：调研了可观测的主流应用场景。</blockquote><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047496834" alt="image" title="image" loading="lazy"/></p><blockquote>同时，《AI 原生应用架构白皮书》提供了相关的理论和实践。解决以上痛点的关键能力是：端到端的全链路跟踪、全栈观测、自动化评估。</blockquote><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047496835" alt="image" title="image" loading="lazy"/></p><h2>智能体评估与测试：仍在追赶</h2><ul><li>尽管可观测性已广泛普及，但智能体评估（evals）的采用仍在追赶中。略超一半的组织（52.4%）报告会在测试集上运行离线评估，表明许多团队已意识到在部署前捕捉回归和验证行为的重要性。</li><li>在线评估（online evals）的采用率较低（37.3%），但正在快速增长，因为团队开始监控智能体在真实世界中的表现。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047496836" alt="image" title="image" loading="lazy"/></p><ul><li>对于已上线智能体的团队，评估实践明显更成熟：“不评估”的比例从 29.5% 降至 22.8%，而进行在线评估的比例升至 44.8%。这表明一旦智能体面对真实用户，团队就必须依赖生产数据实时发现问题。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047496837" alt="image" title="image" loading="lazy"/></p><ul><li>大多数团队仍从离线评估入手（因其门槛较低、设置更清晰），但许多正在叠加多种方法。在开展评估的组织中，近四分之一同时使用离线和在线评估。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047496838" alt="image" title="image" loading="lazy"/></p><p>这些团队通常结合人工评审与自动化方法：用 LLM-as-Judge 实现广度覆盖，用人工审核处理深度判断。</p><ul><li>总体而言，人工评审（59.8%）在高风险或需细腻判断的场景中仍不可或缺，而 LLM-as-Judge（53.3%）则被越来越多地用于规模化评估质量、事实准确性和合规性。</li><li>相比之下，传统的机器学习指标（如 ROUGE、BLEU）采用率很低，在开放式智能体交互中，往往存在多个有效答案，这些指标并不适用。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047496839" alt="image" title="image" loading="lazy"/></p><blockquote>《AI 原生应用架构白皮书》也认为传统的机器学习指标（如 ROUGE、BLEU），存在较高的局限性。</blockquote><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047496840" alt="image" title="image" loading="lazy"/></p><p>更流行的是 LLM-as-Judge 范式，并提供了利用在线数据，实现自动化评估的实践框架。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047496841" alt="image" title="image" loading="lazy"/></p><h2>模型与工具生态：开放、多元、务实</h2><ul><li>OpenAI 模型占据主导，但很少有团队押注单一供应商。超过三分之二的组织使用 OpenAI 的 GPT 系列模型，但超过四分之三（75%+）在生产或开发中使用多个模型。</li><li>团队越来越倾向于根据任务复杂度、成本和延迟等因素，将不同任务路由给不同模型，而非陷入平台锁定。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047496842" alt="image" title="image" loading="lazy"/></p><blockquote>《AI 原生应用架构白皮书》中提到多模型策略是常态，通过 AI 网关可以高效、安全、量化管理模型供应和 Token 的消耗。</blockquote><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047496843" alt="image" title="image" loading="lazy"/></p><ul><li><strong>尽管商业 API 使用便捷，但自托管模型仍是重要策略。</strong> 约三分之一的组织投入资源建设自有基础设施以部署开源模型。这可能是出于高用量下的成本优化、数据驻留/主权要求，或特定行业的监管约束。</li><li><strong>同时，微调仍未普及。</strong> 57% 的组织未进行任何微调，而是依赖基础模型结合提示工程和检索增强生成。由于微调需要大量投入（数据收集、标注、训练基础设施和持续维护），目前主要用于高影响力或高度专业化的场景。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047496844" alt="image" title="image" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[亚马逊公布新款自研 大力的乌龙茶 ]]></title>    <link>https://segmentfault.com/a/1190000047496875</link>    <guid>https://segmentfault.com/a/1190000047496875</guid>    <pubDate>2025-12-23 14:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>这里是 「RTE 开发者日报」，每天和大家一起看新闻、聊八卦。我们的社区编辑团队会整理分享 RTE（Real-Time Engagement） 领域内「有话题的技术」、「有亮点的产品」、「有思考的文章」、「有态度的观点」、「有看点的活动」，但内容仅代表编辑的个人观点，欢迎大家留言、跟帖、讨论。</p><p>本期编辑：@瓒an、@鲍勃</p><p>01 有话题的技术<br/>1、亚马逊公布新款自研 AI 芯片 Trainium 3</p><p>日前，亚马逊云科技 CEO Matt Garman 在 re:Invent 2025 活动上，正式公布了亚马逊自研 AI 芯片 Trainium 系列的最新进展。</p><p>会上，Amazon Trainium 3 UltraServers 正式发布。</p><p>据介绍，这是亚马逊云科技首款搭载 3 纳米工艺 AI 芯片的服务器，相较 Amazon Trainium 2，不仅计算能力提升 4.4 倍、内存带宽提升 3.9 倍，每兆瓦算力可处理的 AI token 数量更实现了 5 倍增长。</p><p>服务器最高配置 144 个芯片，提供惊人的 362 petaflops FP8 计算能力。在运行 OpenAI 的 GPT-OSS-120B 模型时，每兆瓦输出 token 数是 Amazon Trainium 2 的 5 倍以上，实现超高能耗比。</p><p>同时，Matt Garman 还首次披露了 Amazon Trainium 4 芯片，并承诺将实现较 Amazon Trainium 3 六倍的 FP4 计算性能、四倍内存带宽和两倍高内存容量。</p><p>据悉，亚马逊云科技目前已完成超 100 万个 Trainium 2 芯片的规模化部署，为 Amazon Bedrock 中大部分推理工作提供核心算力支持，包括 Claude 最新一代模型的高效运行。</p><p>( @APPSO)</p><p>2、Meta Reality Labs 挖角苹果交互设计负责人 Alan Dye</p><p>今天凌晨，彭博社记者 Mark Gurman 发文透露，苹果人机交互设计副总裁 Alan Dye 被 Meta 挖角。</p><p>据悉，Dye 自 2015 年以来，一直担任苹果的用户界面设计团队的负责人。 而本次被挖角后，苹果将用长期设计师 Stephen Lemay 顶替 Dye 的岗位。</p><p>值得一提的是，Dye 曾负责监督 iOS 26、液态玻璃界面、Vision Pro 界面、watchOS，以及各种系统交互层面内容（如空间计算交互、灵动岛）。</p><p>报道指出，Dye 在乔布斯离开后，一直担任着重要角色：帮助公司定义了最新操作系统、App 以及设备的外观。另外，Dye 在苹果的团队也帮助开发一系列新的智能家居设备。</p><p>Meta 方面，随着 Dye 加入，该公司正在创立一个新的设计工作室，并且有 Dye 负责硬件、软件和 AI 集成方面的界面设计。</p><p>Dye 将向负责现实实验室的首席技术官 Andrew Bosworth 汇报工作，而现实实验室负责开发可穿戴设备，如智能眼镜和虚拟现实头戴式设备。Gurman 透露，Dye 将于 12 月 31 日正式开始担任团队首席设计官。</p><p>而且 Dye 还不是一个人走的，他还带走了苹果设计部门的高级总监 Billy Sorrentino。后者从 2016 年起就在苹果，主要负责 VisionOS 的用户界面设计。</p><p>( @APPSO)</p><p>3、小米卢伟冰：AI 与物理世界的深度结合是智能科技的下一站</p><p>12 月 3 日，@卢伟冰 在社媒发布卢伟冰答网友问第十二期，在回答「罗福莉加入了小米，未来在 AI 上会有什么新的战略」时表示：</p><p>其实我们在前几个季度就已经开始了在 AI 上的压强式投入，虽然不能透露太多，我们在 AI 大模型和应用方面的进展远超预期，我们认为 AI 与物理世界的深度结合是智能科技的下一站，小米也非常渴望人才尊重人才，也希望能够给优秀的人才提供好的发展平台。</p><p>95 后罗福莉出生于四川，父亲是一名电工，母亲是教师。她本人曾就读于四川宜宾市第一中学校 「清北班」，并以优异成绩考入北京师范大学，后被保送至北京大学深造。</p><p>在北大读硕士期间，她于 2019 年在人工智能领域顶级国际会议 ACL 上发表了 8 篇论文，其中 2 篇为第一作者。毕业后，她先后在阿里达摩院、幻方量化、DeepSeek 工作，主导开发了多语言预训练模型 VECO，并参与研发了 MoE 大模型 DeepSeek-V2。</p><p>11 月 12 日，罗福莉在朋友圈发文，正式宣布自己已经加入小米。</p><p>11 月 19 日消息，小米公司今日官宣，12 月 17 日，小米将在北京·国家会议中心举办「人车家全生态」合作伙伴大会。主论坛时间为上午 10:00-12:15，全程开放线上直播。</p><p>作为小米 MiMo 大模型负责人，罗福莉将在主论坛发表题为《Xiaomi MiMo：小米基座大模型》 的主题演讲，这是她自 11 月 12 日加入小米后的首次公开亮相。</p><p>（@荆楚网）</p><p>02 有亮点的产品<br/>1、Peopleboxai 推出 Nova：首款「人性化」AI 面试官，优化招聘流程</p><p>Peopleboxai 发布了其 AI 产品「Nova」，号称是「人性化」的 AI 面试官。Nova 能够自动化包括简历筛选、电话面试、视频面试、实时编码测试以及生成决策报告在内的整个第一轮招聘流程，显著加快招聘速度并提升效率。</p><p>全流程自动化： Nova 能够处理从简历筛选、联系候选人（通过 InMail、邮件、电话）到进行全面的语音/视频面试，甚至执行高级编码测试，直至提供详细的、可直接用于决策的报告。<br/>高度「人性化」体验： Nova 被设计成「最佳招聘官和面试官的数字孪生」，能够模拟自然的暂停、语气和「嗯」等语用标记，提供友好的、类似真人的互动体验，候选人对其评价很高。<br/>定制化与智能化： 用户可以根据自己的需求定制 Nova 的面试风格，包括技能深度、难度、面试类型、语调和结构。Nova 还能从公司过往的招聘数据（职位描述、面试记录、ATS 笔记等）中学习，提升其判断能力。<br/>显著提升效率： Nova 帮助客户将第一轮面试报告的完成时间从 4-5 周缩短到 48 小时以内，为招聘团队节省了大量时间，使其能专注于更具战略意义的工作。<br/>覆盖多渠道招聘： Nova 不仅处理入站（inbound）和内推（referral）的候选人，还能主动进行外呼（outbound）候选人搜寻和联系。<br/>Nova 产品已上线，用户可通过 Peopleboxai 官网了解更多信息并申请试用。</p><p>(@Y Combinator Launches)</p><p>2、理想汽车发布首款 AI 眼镜 Livis：标配蔡司镜片 补贴后售价 1699 元起</p><p>12 月 3 日，理想汽车举办线上发布会，正式推出其首款 AI 智能眼镜 Livis。售价 1999 元起，12 月 31 日前下订可享受 15% 政府补贴，补贴后价格仅为 1699 元起。</p><p>「一款以钢铁侠 AI 管家「贾维斯」为灵感命名的智能眼镜，试图将「理想同学」的 AI 能力从驾驶空间延伸至用户日常生活的每个角落。」</p><p>Livis 名称源于理想汽车与钢铁侠 AI 管家「Jarvis」的组合。</p><p>整机重量控制在 36 克，提供经典黑、科技灰和橄榄绿三种颜色，并可选亮光或磨砂材质。</p><p>Livis 全系产品标配蔡司镜片，涵盖近视镜片、光致变色镜片与墨镜片等多种类型，满足用户在不同场景下的视觉需求。</p><p>理想宣称 Livis 在研发过程中实现了五项关键突破，构成了产品核心竞争力的重要组成部分。</p><p>典型续航时间达 18.8 小时。Livis 标配类似 AirPods 的无线充电盒，便于随身携带和补能。同时，眼镜支持与理想汽车的车机系统无线快充，上车后放置在专属充电位进行充电。</p><p>在硬件配置上，Livis 搭载恒玄 BES2800 主控芯片和独立的 ISP 成像芯片，采用 SONY IMX681 摄像头，拥有 1200 万像素、支持 4K 照片以及电子防抖拍摄。</p><p>汽车联动场景是 Livis 最独特的卖点。通过蓝牙和 5G 网络，眼镜可无缝连接车辆，实现语音远程控车。用户可在百米范围内，通过语音指令操控电动侧滑门启闭、提前开启空调及座椅加热，甚至检查车辆续航和充电状态。</p><p>（@极客公园、@快科技）</p><p>3、豆包手机助手无法登录微信，双方回应</p><p>日前，字节跳动豆包团队与中兴合作发布了豆包手机助手技术预览版后，有试用 Nubia M153 工程样机的用户反馈，出现无法正常登陆微信的情况。</p><p>对于相关情况，豆包团队方面昨晚发文并做出回应。</p><p>豆包方面表示，其后续已下线了手机助手操作微信的能力。 目前，nubia M153 上被禁止登录的微信账号正陆续解封。</p><p>而微信相关人士也通过澎湃新闻回应，豆包手机助手无法正常登陆微信的微信并没有什么特别动作，「可能是中了本来就有的安全风控措施。」</p><p>针对此前曾有科技公司爆料「豆包手机助手存在侵犯用户隐私」的问题，团队方面强调，豆包手机助手不存在任何黑客行为。</p><p>据悉，此前上述公司曾表示豆包手机助手在努比亚手机上拥有 INJECT\_EVENTS 权限，该权限在安卓权限定义中属于操作系统高危权限，并且拿到该权限，要面临刑事责任。</p><p>豆包方面表示，INJECT\_EVENTS 确实是系统级权限，但拥有了该权限许可，相关产品才能跨屏、跨应用来模拟点击事件，完成用户操作手机的任务需求。</p><p>团队还强调，豆包手机助手需要用户主动授权，才可以调用该权限，使用操作手机功能。该权限的使用，豆包方面也在权限清单中进行了明确的披露。据了解，目前行业的 AI 助手，均需要使用该权限（或与其类似的无障碍权限）才能提供操作手机的服务。</p><p>豆包方面强烈表示，豆包手机助手也不会代替用户进行相关授权和敏感操作。</p><p>同时，豆包方面也对读取屏幕的隐私问题进行了回应。其表示，助手操作手机时需要读取屏幕（否则无法完成任务），但屏幕和操作过程都不会在服务器端留下存储，且所有的相关内容也都不会进入模型训练，确保用户隐私安全。</p><p>( @APPSO)</p><p>4、健康追踪应用 Healthify Ria 升级 AI 助手：支持实时语音与摄像头交互</p><p>健康追踪初创公司 Healthify 推出了其 AI 助手 Ria 的新版本，该版本支持通过语音和摄像头进行实时对话，并能理解超过 50 种语言（包括 14 种印度语言）以及混合语言输入。此举旨在通过更自然的交互方式，提升用户健康习惯养成的效率和用户粘性。</p><p>实时对话与多模态输入： Ria 现在支持通过语音进行实时对话，用户还可以通过摄像头扫描食物获取营养信息并进行记录，大幅简化了数据录入流程。<br/>多语言与混合语言支持： Ria 能够理解超过 50 种语言，并支持 Hinglish、Spanglish 等混合语言输入，服务全球用户。<br/>整合多源健康数据： Ria 可以整合来自健身追踪器、睡眠追踪器、血糖监测仪等设备的数据，为用户提供运动、睡眠、身体准备度和血糖波动等方面的洞察，并给出建议。<br/>增强记忆与个性化： Healthify 正在为 Ria 构建一个更持久的记忆层，使其能够记住用户的偏好和健康变化，提供更个性化的建议。<br/>教练与营养师辅助： Ria 将被整合到用户与教练、营养师的沟通中，协助双方快速调取数据、回答问题，并可转录通话内容，提取关键信息。<br/>(@TechCrunch)</p><p>03 有态度的观点<br/>1、《阿凡达》导演：对 AI 没意见，但要尊敬演员们</p><p>近日，导演詹姆斯·卡梅隆在《阿凡达 3》世界首映礼上称该片没有使用 AI 生成，随后他对 ComicBookcom 发表了自己对于生成式 AI 的应用看法。</p><p>卡梅隆表示，自己对生成式 AI 没有意见，但他强调：「我们拍《阿凡达》电影不使用它，我们尊敬并赞颂演员们，我们不用 AI 代替演员。」</p><p>同时，卡梅隆也表示，「这件事（生成式 AI）自会有方向，我想好莱坞会进行自我监管，但我们作为艺术家要找到出路，前提是我们得能存在。所以，比起别的东西，来自『大 AI』的生存威胁是最让我担忧的。」</p><p>值得一提的是，卡梅隆所提到的「大 AI」，是指人类利用 AI 的状况和其产生的问题，对应的「小 AI」是指更细节、技术性的层面，比如用 AI 生成内容。</p><p>在卡梅隆看来，AI 和人类未来有深切的担忧和存在危机，他认为「小 AI」各行业会找到应对和利用之法，但「大 AI」问题就不好说了。</p><p>卡梅隆还提到，若了解 AI，就会知道「校准」是个重大问题。「AI 必须被训练、教导，必须被约束去只做对人类好的事情。」其强调，「只有我们人类达成了共识，你才能对 AI 进行校准。」<a style="color: white;" target="_blank">感刚weibo.com/ttarticle/p/show?id=2309405246806387982569 weibo.com/ttarticle/p/show?id=2309405246806740303881 weibo.com/ttarticle/p/show?id=2309405246807084499335 weibo.com/ttarticle/p/show?id=2309405246807449403565 weibo.com/ttarticle/p/show?id=2309405246807801463013 weibo.com/ttarticle/p/show?id=2309405246808279613520 weibo.com/ttarticle/p/show?id=2309405246808648974539 weibo.com/ttarticle/p/show?id=2309405246809013616862 weibo.com/ttarticle/p/show?id=2309405246809391366234 刚</a></p>]]></description></item><item>    <title><![CDATA[Google开源医疗语音识别模型MedASR；对话式AI招聘平台Jack&Jill融资2000万美元]]></title>    <link>https://segmentfault.com/a/1190000047496659</link>    <guid>https://segmentfault.com/a/1190000047496659</guid>    <pubDate>2025-12-23 13:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047496661" alt="" title=""/></p><p><strong>开发者朋友们大家好：</strong></p><p>这里是 <strong>「RTE 开发者日报」</strong>，每天和大家一起看新闻、聊八卦。我们的社区编辑团队会整理分享 RTE（Real-Time Engagement） 领域内「有话题的<strong>技术</strong>」、「有亮点的<strong>产品</strong>」、「有思考的<strong>文章</strong>」、「有态度的<strong>观点</strong>」、「有看点的<strong>活动</strong>」，但内容仅代表编辑的个人观点，欢迎大家留言、跟帖、讨论。</p><p><em>本期编辑：@瓒an、@鲍勃</em></p><h2>01 有话题的技术</h2><p><strong>1、借道日本，腾讯与 Nvidia 达成协议，AI 算力的「避风港」</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047496662" alt="" title="" loading="lazy"/></p><p>在美国严密的半导体出口禁令下，一场关于顶级 AI 算力的「暗度陈仓」正在日本大阪悄然上演。</p><p>AI 怪盗团 12 月 21 日消息，据英国《金融时报》等多方消息披露，腾讯已通过第三方与 Datasection 达成合作，获得后者位于大阪数据中心内约 15000 块英伟达 Blackwell B200 芯片的使用权。这笔交易的总价值据称超过 12 亿美元（约合 87 亿元人民币）。</p><p>在英伟达 H100、B200 等高端芯片被美国商务部严防死守、禁止直接对华出口的当下，这笔交易撕开了全球算力封锁网的一道口子。</p><p>完整报道：</p><p><a href="https://link.segmentfault.com/?enc=9aX0JUVkgxOEv8yJKSXrIA%3D%3D.6713gMwfrmtGF4XyZQjb7qiHpA6FGetAwW%2FWceAhBiIpzxFuqPTNt1spnhRSQ0OnA77WLIhZG3aCfmWQ7sJjUQ%3D%3D" rel="nofollow" target="_blank">https://mp.weixin.qq.com/s/BOK-LgVF0pSIKOLisc_Sdg</a></p><p>（@Al 怪盗团）</p><p><strong>2、Google 推出专为医疗场景优化的 ASR 模型「MedASR」，医疗听写 WER 降至 4.6%</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047496663" alt="" title="" loading="lazy"/></p><p>Google 推出专为医疗场景优化的 ASR 模型「MedASR」，采用 Conformer 架构并在超过 5000 小时的医疗专用脱敏音频上完成预训练与微调。该模型在放射科及全科医生听写任务中的识别精度显著优于 Gemini 2.5 Pro 和 Whisper v3 Large，旨在为医疗垂直领域的语音转文本应用提供高性能基础。</p><ul><li>轻量化 Conformer 架构与 105M 参数量：模型参数规模仅为 105M，基于 Conformer 架构设计，支持通过 AutoModelForCTC 进行高效推理，适用于对延迟和隐私有严苛要求的临床本地化部署。</li><li>垂直领域 WER 显著领先：在私有放射科数据集（RAD-DICT）测试中，MedASR 配合 6-gram 语言模型的词错率（WER）仅为 4.6%，远低于 Whisper v3 Large（25.3%）和 Gemini 2.5 Pro（10.0%）。</li><li>5000 小时医疗语料库微调：在 LibriHeavy 预训练基础上，引入超过 5000 小时的脱敏医生听写和医患对话数据，涵盖放射、内科、家庭医学等多个子学科的专业术语及医学实体标注。</li><li>JAX 与 ML Pathways 训练栈：模型利用 JAX 框架与 Google ML Pathways 系统，在 TPUv4p、TPUv5p/e 硬件上完成大规模分布式训练，优化了复杂矩阵运算的执行效率。</li><li>标准音频输入规范与 API 支持：原生支持 16kHz、单声道、int16 格式的音频输入；要求 transformers 库版本为 5.0.0+，支持通过 pipeline 接口实现流式或批处理识别。</li></ul><p>发布计划已在 Hugging Face 开源（需签署联系信息共享协议），遵循「Health AI Developer Foundations」使用条款。</p><p>Hugging Face: </p><p>https\://huggingface.co/google/medasr</p><p>(@Hugging Face Blog)</p><p><strong>3、英伟达开源基础模型 NitroGen，能打遍几乎所有游戏</strong></p><p>日前，英伟达公布了其最新开源基础模型「NitroGen」。</p><p>官方介绍，<strong>NitroGen 是一个统一的视觉到行动模型，可以直接从原始帧中玩游戏。并且能做到将视频游戏帧作为输入，同时输出游戏手柄操作。</strong></p><p>值得一提的是，NitroGen 支持后训练，因此模型在面对一款新游戏时，只需轻量微调或适配，就可以快速通用。</p><p>官方表示，与使用强化学习的模型不同，NitroGen 是通过在人类游戏视频上进行大规模模仿学习进行训练的。</p><p>据悉，NitroGen 通过逆动力学模型从 4 万小时互联网公开视频中「反推」玩家按键，合成海量训练数据，实现纯模仿学习。</p><p>当然，团队也指出了模型的不足：NitroGen 在为游戏手柄设计的游戏中表现最佳（例如动作、平台和赛车游戏），而在严重依赖鼠标和键盘的游戏（例如即时战略、多人在线战术竞技）中效果较差。</p><p>团队称，NitroGen 的目标是探索是否通过对多样化的人类游戏行为进行大规模训练，能够产生涌现式的通用具身能力，类似于规模扩展如何解锁大型语言模型中的涌现行为。</p><p>Hugging Face: </p><p><a href="https://link.segmentfault.com/?enc=GL9dKh4ZP%2F118W3QJ8UOYg%3D%3D.SD3bzqoYrpiKU1zUahaGceGyScp3qsUh8AsYZcf%2FNFXb6%2Fx44wwUheqegajy44yY" rel="nofollow" target="_blank">https://huggingface.co/google/medasr</a></p><p>(@APPSO)</p><h2>02 有亮点的产品</h2><p><strong>1、小米前 89 号董红光首款 AI 硬件曝光，预计发布全球首款带摄像头 AI 耳机</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047496664" alt="" title="" loading="lazy"/></p><p>AING 硬迹从多个信源获悉：AI 明星企业光帆科技将于<strong> 12 月 23 日</strong>举办产品发布会，范围精选控制，已有多个产业内高管及投资人收到邀请。<strong>将在发布会上推出全球首款带摄像头 AI 耳机。</strong></p><p><strong>这款产品有以下核心亮点：</strong></p><p>1）全球首款带摄像头 AI 耳机，<strong>独立设备、完全不依赖手机</strong>就可以完成一系列应用服务；</p><p>2）更强大的是这款硬件背后为 AI 原生交互而生的<strong>多模态 AI OS</strong>，直接使 AI 原生交互成为可能，打造 always-on 智能助理。</p><p>光帆科技能够快速推出产品，得益于其「高 P 团队」：汇集了来自小米、华为、字节、阿里、Minimax 等企业的资深专家，具有深厚的人工智能软硬件及应用开发能力。</p><p>据悉从去年 10 月份成立以来，光帆科技一年内连续完成多轮融资，投资方包括韶音、歌尔、联想、宁德、兆易创新等产业巨头。</p><p>（@AING 硬迹）</p><p><strong>2、融资 2000 万美元种子轮：Jack &amp; Jill 利用对话式 AI 智能体重构招聘流程，按效果付费</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047496665" alt="" title="" loading="lazy"/></p><p>由连续创业者 Matt Wilson 创立的英国初创公司「Jack &amp; Jill」宣布完成 2000 万美元种子轮融资，由 Creandum 领投。该平台旨在通过双向的对话式 AI 智能体替代传统的「简历+职位列表」模式，解决当前招聘市场因 AI 自动投递导致的信噪比极低（Signal-to-noise ratio）的问题。</p><ul><li><strong>双端 AI 智能体架构 （Dual-Agent System）：</strong> 平台由面向求职者的「Jack」和面向雇主的「Jill」组成。求职者需通过「Jack」进行 20 分钟的深度 AI 面试以建立动态画像，而「Jill」则根据雇主需求在库中筛选并提拔匹配度最高的候选人。</li><li><strong>结构化数据提取替代简历筛选：</strong> 针对 LinkedIn 等平台海量投递导致 HR 无法有效审阅的痛点，该系统通过对话交互将求职者的非结构化经验转化为可量化的技能节点，从而在首轮筛选中替代低效的人工简历扫描。</li><li><strong>全生命周期职业智能体：</strong> 除招聘匹配外，「Jack」侧集成了模拟面试和职业教练功能，利用 LLM 的对话能力在用户非投递期间维持高活跃度，建立长期人才库。</li><li><strong>基于录用的佣金商业模式：</strong> 不同于传统平台的职位发布费，「Jack &amp; Jill」采取标准化的成功录用佣金制，将 AI 匹配的精度与平台收益直接挂钩。</li><li><strong>规模化验证与地域扩张：</strong> 该服务已在伦敦市场先行上线并获取约 5 万名用户。本轮融资将重点用于美国市场的扩张以及进一步优化对话式 AI 的行业特定推理能力。</li></ul><p>服务目前已在伦敦地区上线并可用，正计划向美国市场推广。</p><p>(@TechCrunch)</p><p><strong>3、三星联手谷歌，将推出 Gemini AI 冰箱</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047496666" alt="" title="" loading="lazy"/></p><p>近期，三星电子表示，将于明年 1 月份正式推出一款搭载 Google AI 模型 Gemini 的新款高端冰箱。</p><p>官方表示，<strong>该冰箱所搭载的 Gemini 能通过 AI 视觉分析+冰箱内的摄像头，对存储的食材进行识别分析。</strong> 据介绍，此次升级扩展了冰箱自动识别物品的范围，超越了三星旧款冰箱的 37 种新鲜食品和 50 种包装产品的识别限制。</p><p>值得一提的是，Gemini 还能够识别食品容器上的手写或印刷标签，并自动将物品添加到数字购物清单中。</p><p>三星表示，冰箱的 Gemini 还支持 AI 食品管理功能，该功能根据用户的消费模式提供成分跟踪、食谱推荐和购物建议。</p><p>未来，三星还计划将升级版的 AI 视觉识别技术扩展到自家的葡萄酒冰柜。通过 AI 葡萄酒管理系统，冰箱能够识别存储的葡萄酒瓶，记录名称、品种、年份和存储位置等详细信息；当瓶子被移动或移除时，系统可以实时更新库存。</p><p>(@APPSO)</p><p><strong>4、Known 获 970 万美元种子轮融资：推出语音 AI 驱动的深度用户画像与约会匹配系统</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047496667" alt="" title="" loading="lazy"/></p><p>Known，一家专注于通过技术解决线下约会效率问题的科技初创公司，已成功获得 970 万美元种子轮融资。其核心产品利用语音 AI 进行用户深度画像构建，旨在显著提升匹配成功率和线下约会转化率。</p><ul><li><strong>语音 AI 深度画像</strong>： 用户通过语音交互完成引导式问答，平均时长 26 分钟，最长达 1 小时 38 分钟。AI 能够基于对话内容进行动态追问，获取比文本输入更丰富、更真实的个人偏好与需求，避免用户在文本输入中常见的自我审查。</li><li><strong>80% 线下约会转化率</strong>： 在旧金山 Beta 测试阶段，80% 的 AI 推荐匹配最终促成了线下约会，远超传统滑动式（swipe-based）约会应用。</li><li><strong>AI 智能体匹配与日程规划</strong>： 完成画像后，AI 智能体会向用户推荐潜在匹配。用户可通过 AI 智能体查询更多资料，并在配对成功后，双方需在 24 小时内接受介绍，并再次在 24 小时内确认约会。应用还支持 AI 协助根据用户偏好推荐餐厅，并与日历集成以安排首次约会。</li><li><strong>按成功约会付费模式</strong>： 在 Beta 阶段，平台对每成功完成一次线下约会收取 30 美元费用，此定价策略旨在鼓励真实互动并减少无效聊天与「放鸽子」现象。</li></ul><p>(@TechCrunch)</p><h2>03 有态度的观点</h2><p><strong>1、小岛秀夫：做一个给 AI 玩的游戏</strong></p><p>知名游戏制作人小岛秀夫上周在接受《日经 Xtrend》采访时，抛出了一系列极具野心的构想。</p><p>除了提及正在开发的恐怖游戏《OD》，和处于构想阶段的 PS 独占谍报游戏《Physint》外，他透露自己最想尝试的是两个「听起来有些离谱」的项目：一款在失重环境下游玩的游戏，以及一款专门「拿来给 AI 玩」的游戏。</p><p>对于「给 AI 玩的游戏」，小岛秀夫有着清晰的逻辑。他认为目前 AI 的知识储备仍然不足，因此这款游戏将作为 AI 的「学习素材」，旨在让 AI 感到愉悦并帮助其学习。</p><p><strong>他大胆预测，AI 将在 5 到 10 年内彻底改变游戏开发的方式，并最终进入更多不同的领域。</strong></p><p>针对外界对 AI 的抵触情绪，小岛秀夫表现出了理性且开放的态度。他将 AI 类比为当年的智能手机——起初饱受批评，如今却不可或缺。</p><p>他认为 AI 应被视为一种工具，用于根据玩家习惯微调游戏风格，或处理那些重复枯燥的工作，从而让创作者能将精力集中在更具创造性的部分。</p><p>重要的是，我们要在思考如何走向正确的同时，以能让人们感到幸福的方向来改进技术。</p><p>(@APPSO)</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047496668" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047496669" alt="" title="" loading="lazy"/></p><p><a href="https://link.segmentfault.com/?enc=KhNxUQLm7%2B992sn8T14QjQ%3D%3D.var2i5Xlsk35rnWJqimA4aDUpXUi4RtGxvLjOs%2BMDfA%3D" rel="nofollow" target="_blank">阅读更多 Voice Agent 学习笔记：了解最懂 AI 语音的头脑都在思考什么</a></p><p><strong>写在最后：</strong></p><p>我们欢迎更多的小伙伴参与<strong>「RTE 开发者日报」</strong>内容的共创，感兴趣的朋友请通过开发者社区或公众号留言联系，记得报暗号「共创」。</p><p>对于任何反馈（包括但不限于内容上、形式上）我们不胜感激、并有小惊喜回馈，例如你希望从日报中看到哪些内容；自己推荐的信源、项目、话题、活动等；或者列举几个你喜欢看、平时常看的内容渠道；内容排版或呈现形式上有哪些可以改进的地方等。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047496670" alt="" title="" loading="lazy"/></p><p>作者提示：个人观点，仅供参考</p>]]></description></item><item>    <title><![CDATA[CRM核心能力横向对比：从客户管理到多端协同，谁更适配你的业务？ 率性的开水瓶 ]]></title>    <link>https://segmentfault.com/a/1190000047496297</link>    <guid>https://segmentfault.com/a/1190000047496297</guid>    <pubDate>2025-12-23 12:02:15</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在数字化转型中，CRM（客户关系管理）的价值早已超越“记录客户信息”——它是企业实现<strong>从线索到复购的全链路数字化、从流程管控到智能决策的核心工具</strong>。本文选取7款主流CRM产品（超兔一体云、红圈营销、六度人和EC、Salesforce、SugarCRM、Freshsales、Pipedrive），从<strong>客户信息管理、销售跟踪与待办、报表与分析、多端同步</strong>四大核心维度展开深度对比，结合业务场景给出选型建议。</p><h2>一、客户信息管理：从“数据收集”到“价值沉淀”的能力比拼</h2><p>客户信息管理的核心是<strong>将多源数据转化为可复用的客户资产</strong>，关键看“全生命周期覆盖、数据整合深度、画像精准度、查重效率”四大能力。</p><h3>1.1 核心子指标对比</h3><table><thead><tr><th>子指标</th><th>超兔一体云</th><th>红圈营销</th><th>六度人和（EC）</th><th>Salesforce</th><th>SugarCRM</th><th>Freshsales</th><th>Pipedrive</th></tr></thead><tbody><tr><td><strong>全生命周期覆盖</strong></td><td>潜在-意向-成交-复购（含客池分类）</td><td>潜在-意向-成交-售后（关联服务记录）</td><td>获客-转化-复购（腾讯生态闭环）</td><td>线索-客户-商机-服务（销售云+服务云）</td><td>线索-客户-订单（模块化）</td><td>线索-客户-交易（社交媒体+行为）</td><td>线索-客户-管道阶段（绑定销售流程）</td></tr><tr><td><strong>多源数据整合</strong></td><td>百度/抖音/官网/微信/工商/天眼查</td><td>表单/导入/外勤记录</td><td>企业微信/电话/邮件/海关数据</td><td>邮件/表单/销售云/服务云</td><td>第三方应用集成（如Mailchimp）</td><td>社交媒体（LinkedIn）/邮件/表单</td><td>表单/邮件/Chrome插件</td></tr><tr><td><strong>360°画像能力</strong></td><td>基本信息+工商背景+互动时序+财务汇总</td><td>基本信息+订单+服务记录</td><td>腾讯生态数据+工商+采购偏好</td><td>多渠道数据整合+自定义字段</td><td>模块化视图+客户关系管理</td><td>社交媒体动态+行为轨迹+交易数据</td><td>管道阶段+基本信息+沟通记录</td></tr><tr><td><strong>查重与合并</strong></td><td>自定义规则（客户名/手机号+简称模糊）</td><td>自动查重+手动合并</td><td>重复数据智能清理</td><td>规则引擎+批量合并工具</td><td>手动/自动合并</td><td>自动合并重复线索</td><td>无明确说明</td></tr><tr><td><strong>自定义配置</strong></td><td>字段/布局/客池分类（如“需求培养”“成功客”）</td><td>字段/查询/报表自定义</td><td>标签/分层/行业模板（外贸/教育）</td><td>自定义对象/字段/页面布局</td><td>模块化自定义（如添加“会员等级”）</td><td>字段/视图/报表自定义</td><td>字段/标签/管道阶段自定义</td></tr></tbody></table><h3>1.2 深度分析：谁的“数据价值”转化更高效？</h3><ul><li><strong>超兔一体云</strong>：<strong>工商数据补全+自定义查重</strong>是核心亮点。通过百度/天眼查自动补充企业背景、注册地址、经纬度，解决“客户信息不全”痛点；支持“简称模糊查重”（如“阿里云”与“阿里云计算”合并），避免重复录入。适合<strong>B端企业</strong>（需要精准的企业客户背景）。</li><li><strong>六度人和（</strong> <strong>EC</strong> <strong>）</strong> ：<strong>腾讯生态深度整合</strong>是壁垒。打通企业微信、邮件、电话数据，结合工商/海关数据生成“精准画像”（如“某外贸客户的采购频率”），解决“私域数据分散”问题。适合<strong>依赖微信生态的企业</strong>（如教育、零售）。</li><li><strong>Salesforce</strong>：<strong>全域数据整合</strong>能力最强。销售云+服务云覆盖售前售后，自定义对象/字段支持复杂业务（如“医疗设备的售后维护记录”）。适合<strong>大型跨国企业</strong>（多渠道数据需要统一管理）。</li></ul><h3>1.3 客户信息管理的工作流（Mermaid时序图）</h3><pre><code>sequenceDiagram
    participant 多渠道 as 多渠道获客（百度/抖音/官网/微信）
    participant 超兔 as 超兔一体云
    participant 工商数据 as 工商/天眼查
    participant 销售 as 销售团队
    多渠道-&gt;&gt;超兔: 线索录入（电子表单/拍名片/通讯录）
    超兔-&gt;&gt;超兔: 自定义查重（客户名/手机号+简称模糊）
    超兔-&gt;&gt;工商数据: 自动查询企业背景
    工商数据-&gt;&gt;超兔: 返回注册地址/经纬度/法人信息
    超兔-&gt;&gt;销售: 呈现360°画像（基本信息+工商+历史互动）</code></pre><h2>二、销售跟踪与待办：从“流程管控”到“智能提效”的差异</h2><p>销售跟踪的核心是<strong>让销售“做对的事”</strong> ——通过流程设计减少遗漏，通过智能辅助提升效率。</p><h3>2.1 核心子指标对比</h3><table><thead><tr><th>子指标</th><th>超兔一体云</th><th>红圈营销</th><th>六度人和（EC）</th><th>Salesforce</th><th>SugarCRM</th><th>Freshsales</th><th>Pipedrive</th></tr></thead><tbody><tr><td><strong>流程覆盖</strong></td><td>线索-商机-项目-回款（小单/中长单/项目）</td><td>线索-商机-合同-回款（销售漏斗）</td><td>获客-转化-复购（AI电销+行业模板）</td><td>线索-商机-合同-回款（工作流自动化）</td><td>线索-商机-订单-回款</td><td>线索-商机-合同-回款（AI线索评分）</td><td>线索-商机-管道-回款（拖拽式管道）</td></tr><tr><td><strong>跟单模型</strong></td><td>三一客（小单快单）+商机阶段（中长单）+多方项目（全周期）</td><td>通用销售漏斗（7阶段）</td><td>外贸（海关数据选客）+教育（联动学邦ERP）</td><td>标准销售流程+自定义阶段</td><td>通用流程</td><td>无明确模型</td><td>拖拽式销售管道（如“初期沟通→合同签约”）</td></tr><tr><td><strong>AI辅助</strong></td><td>AI待办生成（行动记录触发）+行动分析</td><td>无明确AI功能</td><td>AI电销（优化线路）+商机价值评估</td><td>AI预测（如“商机转化率”）+流程触发</td><td>无明确AI功能</td><td>AI线索评分（优先级排序）</td><td>无明确AI功能</td></tr><tr><td><strong>外勤支持</strong></td><td>外勤拜访记录（关联客户位置）</td><td>LBS定位+轨迹跟踪+现场订单录入</td><td>无明确说明</td><td>无明确说明</td><td>无明确说明</td><td>无明确说明</td><td>无明确说明</td></tr><tr><td><strong>待办自动化</strong></td><td>行动记录自动生成待办（如“向客户发报价→3天内跟进”）</td><td>节点提醒（如“商机进入‘立项评估’需跟进”）</td><td>AI生成待办（如“某客户30天未复购→提醒复购”）</td><td>工作流自动化（如“合同审批通过→生成回款待办”）</td><td>手动设置+邮件提醒</td><td>智能排序（高价值线索优先）</td><td>逾期任务警示+日历同步</td></tr></tbody></table><h3>2.2 核心差异：“场景定制” vs “通用流程”</h3><ul><li><p><strong>超兔一体云</strong>：<strong>场景化跟单模型</strong>是绝对优势。</p><ul><li>小单快单用“三一客”：通过“三定”（定性、定级、定量）快速推进（如“定性为‘有需求’，定级为‘A类’，定量为‘10万订单’”）；</li><li>中长单用“商机阶段”：跟踪“初期沟通→立项评估→合同签约”的关键节点；</li><li>复杂项目用“多方项目模型” <strong>：在一个视图内管理项目组、合同、采购、收支，控制利润（如“某工程公司的‘办公楼装修项目’，同步合同金额、采购成本、收款进度”）。</strong> <strong>适合</strong>“小单+项目”混合的企业（如IT集成、设备销售）。</li></ul></li><li><strong>红圈营销</strong>：<strong>外勤与流程闭环</strong>是重点。LBS定位记录销售轨迹，现场录入订单，解决“外勤人员管理难”痛点；销售漏斗可视化（如“初期沟通有10个商机，转化为5个立项”），适合<strong>快消</strong> <strong>、农牧等线下重执行的行业</strong>（如“饮料经销商的终端门店巡店”）。</li><li><strong>六度人和（</strong> <strong>EC</strong> <strong>）</strong> ：<strong>AI+</strong> <strong>行业定制</strong>是特色。AI电销优化线路（如“优先拨打高意向客户”），外贸模板整合海关数据（如“筛选‘近3个月进口过电子产品的客户’”），教育模板联动学邦ERP（如“招生线索同步到教务系统”）。适合<strong>行业属性强的企业</strong>（如外贸、教育）。</li></ul><h3>2.3 销售跟踪的脑图（Mermaid）</h3><pre><code>mindmap
    root((销售跟踪与待办))
        流程覆盖
            线索分配
            商机挖掘
            合同审批
            销售回款
        跟单模型
            小单快单（超兔：三一客）
            中长单（超兔：商机阶段）
            多方项目（超兔：全周期管理）
            行业定制（EC：外贸/教育）
        AI辅助
            待办生成（超兔/EC）
            商机评分（Freshsales）
            电销优化（EC）
        外勤支持
            LBS定位（红圈）
            现场录入（红圈）
        待办自动化
            行动触发（超兔）
            流程驱动（Salesforce）
            逾期提醒（Pipedrive）</code></pre><h2>三、报表与分析：从“数据呈现”到“决策驱动”的进化</h2><p>报表与分析的核心是<strong>将数据转化为可执行的策略</strong>，关键看“可视化能力、分析模型、AI驱动”。</p><h3>3.1 核心子指标对比</h3><table><thead><tr><th>子指标</th><th>超兔一体云</th><th>红圈营销</th><th>六度人和（EC）</th><th>Salesforce</th><th>SugarCRM</th><th>Freshsales</th><th>Pipedrive</th></tr></thead><tbody><tr><td><strong>可视化能力</strong></td><td>数字卡片+销售漏斗+RFM图表</td><td>仪表盘+销售漏斗+满意度曲线</td><td>数字大屏+多维度报表（如“获客来源占比”）</td><td>Data Cloud+实时仪表盘</td><td>内置报表+图表工具</td><td>实时仪表盘+销售漏斗</td><td>销售预测报表+绩效排行</td></tr><tr><td><strong>分析模型</strong></td><td>RFM（客户价值分类）+销售漏斗</td><td>销售漏斗+满意度分析</td><td>销售漏斗+客户转化路径</td><td>销售漏斗+AI预测模型</td><td>销售绩效+订单分析</td><td>销售漏斗+转化率分析</td><td>销售预测+管道分析</td></tr><tr><td><strong>AI驱动</strong></td><td>智能日报（自动汇总当日数据）+复购预警</td><td>智能建议（如“服务响应延迟需优化”）</td><td>海关数据拓客+交叉销售建议</td><td>AI预测（如“下月销售额”）+Data Cloud</td><td>无明确说明</td><td>实时数据更新+趋势分析</td><td>无明确说明</td></tr><tr><td><strong>自定义报表</strong></td><td>支持</td><td>支持</td><td>支持</td><td>支持</td><td>支持</td><td>支持</td><td>支持</td></tr><tr><td><strong>跨链路闭环</strong></td><td>客户-行动-待办-业绩</td><td>线索-订单-服务-满意度</td><td>获客-转化-复购</td><td>多渠道数据闭环</td><td>无明确说明</td><td>线索-交易-行为</td><td>管道-交易</td></tr></tbody></table><h3>3.2 深度解读：谁的“分析”真正“驱动决策”？</h3><ul><li><p><strong>超兔一体云</strong>：<strong>RFM</strong> <strong>分析+智能日报</strong>解决“日常复盘”痛点。</p><ul><li>RFM模型：通过“最近消费、消费频率、消费金额”将客户分为“价值客户”“挽留客户”（如“最近30天消费、月均2次、累计10万→价值客户”），针对性制定复购策略；</li><li>智能日报：自动汇总当日数据（如“签约15.8万、新增2个客户”），支持主观填写“今日问题”，帮助销售快速复盘，老板实时掌握进度。适合<strong>注重客户复购的企业</strong>（如 SaaS、消费品）。</li></ul></li><li><strong>六度人和（</strong> <strong>EC</strong> <strong>）</strong> ：<strong>大数据+数字大屏</strong>是亮点。数字大屏实时展示“获客来源占比、转化率、复购率”，结合90亿+海关数据生成“拓客建议”（如“某外贸企业的‘潜在客户’是‘近6个月进口过五金的美国企业’”），某银行用其<strong>交叉销售率提升42%</strong> 。适合<strong>需要大数据支撑决策的企业</strong>（如金融、外贸）。</li><li><strong>红圈营销</strong>：<strong>满意度分析</strong>是特色。通过问卷收集客户反馈（如“对服务响应速度的评分”），生成“满意度曲线”，识别“服务薄弱环节”（如“售后响应时间超过24小时”）。适合<strong>服务导向的企业</strong>（如医疗、家政）。</li></ul><h2>四、多端同步：从“数据一致”到“生态协同”的能力</h2><p>多端同步的核心是<strong>让销售在任何场景下都能访问最新数据</strong>，关键看“端覆盖、实时同步、生态兼容”。</p><h3>4.1 核心子指标对比</h3><table><thead><tr><th>子指标</th><th>超兔一体云</th><th>红圈营销</th><th>六度人和（EC）</th><th>Salesforce</th><th>SugarCRM</th><th>Freshsales</th><th>Pipedrive</th></tr></thead><tbody><tr><td><strong>端覆盖</strong></td><td>Web/App/小程序/RPA插件</td><td>Web/APP（iOS/Android）</td><td>Web/App/企业微信/视频号</td><td>Web/App/阿里云/微信</td><td>Web/App（iOS/Android）</td><td>Web/App/Freshworks生态</td><td>Web/App/Chrome插件</td></tr><tr><td><strong>实时同步</strong></td><td>支持（App记录的拜访同步到Web）</td><td>支持（APP与电脑端同步）</td><td>支持（企业微信消息同步到EC）</td><td>支持（多渠道数据实时更新）</td><td>支持</td><td>支持</td><td>支持</td></tr><tr><td><strong>离线支持</strong></td><td>无明确说明</td><td>支持（离线录入后联网同步）</td><td>无明确说明</td><td>无明确说明</td><td>支持</td><td>无明确说明</td><td>无明确说明</td></tr><tr><td><strong>生态兼容</strong></td><td>RPA插件（自动化录入）+自定义集成</td><td>无明确说明</td><td>企业微信/腾讯会议/视频号</td><td>阿里云/微信/第三方应用（如Slack）</td><td>第三方应用集成（如Mailchimp）</td><td>Freshdesk（售后）/Freshservice</td><td>无明确说明</td></tr></tbody></table><h3>4.2 核心差异：“多端覆盖” vs “生态深度”</h3><ul><li><strong>超兔一体云</strong>：<strong>多端全场景覆盖</strong>。Web端适合后台管理，App端适合外勤（记录拜访、查看待办），小程序适合客户互动（如“客户查看报价单”），RPA插件自动化录入（如“自动导入Excel线索”）。适合<strong>需要自动化提效的企业</strong>（如电商、制造业）。</li><li><strong>六度人和（EC）</strong> ：<strong>腾讯生态深度绑定</strong>是壁垒。打通企业微信、腾讯会议、视频号，实现“直播获客→企业微信跟进→EC转化”闭环（如“视频号直播的线索同步到EC，自动生成‘跟进待办’”）。适合<strong>依赖微信生态的企业</strong>（如零售、教育）。</li><li><strong>红圈营销</strong>：<strong>离线支持</strong>解决外勤痛点。线下无网络时，销售可录入“拜访记录”“订单”，联网后自动同步，避免“数据丢失”。适合<strong>户外作业多的企业</strong>（如快消、农牧）。</li></ul><h2>五、综合能力雷达图与选型建议</h2><h3>5.1 各品牌雷达图评分（10分制）</h3><table><thead><tr><th>维度</th><th>超兔一体云</th><th>红圈营销</th><th>六度人和（EC）</th><th>Salesforce</th><th>SugarCRM</th><th>Freshsales</th><th>Pipedrive</th></tr></thead><tbody><tr><td>客户信息管理</td><td>8.5</td><td>8.0</td><td>8.8</td><td>9.0</td><td>7.5</td><td>8.2</td><td>7.8</td></tr><tr><td>销售跟踪与待办</td><td>9.0</td><td>8.2</td><td>8.5</td><td>8.8</td><td>7.6</td><td>8.3</td><td>8.0</td></tr><tr><td>报表与分析</td><td>8.5</td><td>8.0</td><td>9.0</td><td>8.9</td><td>7.4</td><td>8.1</td><td>7.9</td></tr><tr><td>多端同步</td><td>8.8</td><td>8.1</td><td>9.2</td><td>8.5</td><td>7.7</td><td>8.4</td><td>8.0</td></tr></tbody></table><h3>5.2 选型建议</h3><table><thead><tr><th>企业类型</th><th>推荐品牌</th><th>核心原因</th></tr></thead><tbody><tr><td>B 端企业（需要精准的企业客户背景）</td><td>超兔一体云</td><td>工商数据补全+自定义查重是核心亮点，能通过百度/天眼查自动补充企业背景等信息，支持“简称模糊查重”，避免重复录入，适合需要精准企业客户信息的 B 端企业。</td></tr><tr><td>依赖微信生态的企业（如教育、零售）</td><td>六度人和（EC）</td><td>腾讯生态深度整合是壁垒，打通企业微信、邮件、电话数据，结合工商/海关数据生成“精准画像”，解决“私域数据分散”问题，还能实现“直播获客→企业微信跟进→EC 转化”闭环。</td></tr><tr><td>大型跨国企业（多渠道数据需要统一管理）</td><td>Salesforce</td><td>全域数据整合能力最强，销售云+服务云覆盖售前售后，自定义对象/字段支持复杂业务，可对多渠道数据进行统一管理。</td></tr><tr><td>“小单+项目”混合的企业（如 IT 集成、设备销售）</td><td>超兔一体云</td><td>场景化跟单模型是绝对优势，小单快单用“三一客”、中长单用“商机阶段”、复杂项目用“多方项目模型”，能满足不同业务场景需求。</td></tr><tr><td>快消、农牧等线下重执行的行业</td><td>红圈营销</td><td>外勤与流程闭环是重点，LBS 定位记录销售轨迹，现场录入订单，解决“外勤人员管理难”痛点，销售漏斗可视化便于管理。</td></tr><tr><td>行业属性强的企业（如外贸、教育）</td><td>六度人和（EC）</td><td>AI+行业定制是特色，AI 电销优化线路，外贸模板整合海关数据，教育模板联动学邦 ERP ，能满足不同行业的特定需求。</td></tr><tr><td>注重客户复购的企业（如 SaaS、消费品）</td><td>超兔一体云</td><td>RFM 分析+智能日报解决“日常复盘”痛点，RFM 模型将客户分类，针对性制定复购策略，智能日报自动汇总当日数据，帮助销售复盘和老板掌握进度。</td></tr><tr><td>需要大数据支撑决策的企业（如金融、外贸）</td><td>六度人和（EC）</td><td>大数据+数字大屏是亮点，数字大屏实时展示数据，结合 90 亿+海关数据生成“拓客建议”，能为企业决策提供有力支持。</td></tr><tr><td>服务导向的企业（如医疗、家政）</td><td>红圈营销</td><td>满意度分析是特色，通过问卷收集客户反馈，生成“满意度曲线”，识别“服务薄弱环节”，有助于提升服务质量。</td></tr><tr><td>需要自动化提效的企业（如电商、制造业）</td><td>超兔一体云</td><td>多端全场景覆盖，Web 端适合后台管理，App 端适合外勤，小程序适合客户互动，RPA 插件自动化录入，可提高企业工作效率。</td></tr><tr><td>户外作业多的企业（如快消、农牧）</td><td>红圈营销</td><td>离线支持解决外勤痛点，线下无网络时销售可录入数据，联网后自动同步，避免“数据丢失”。</td></tr></tbody></table><p>（注：文中功能相关描述均基于公开披露信息，具体功能服务以厂商实际落地版本为准。）</p>]]></description></item><item>    <title><![CDATA[多模态数据中台为什么说是被“逼出来”的？ 袋鼠云数栈 ]]></title>    <link>https://segmentfault.com/a/1190000047496321</link>    <guid>https://segmentfault.com/a/1190000047496321</guid>    <pubDate>2025-12-23 12:01:22</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>2025年算是Agent元年，回望这一年，我们听到最多的企业内部需求，大概是这样的：</p><p>“能不能做个智能体，让业务同事直接问？”</p><p>“我们也想上大模型，把知识库、报表全串起来。”</p><p>“视频、IoT、日志、告警都在，就是没人能‘一口气’看完一件事。”</p><p>再往下问一句：</p><p>你们是不是已经有一套还算完整的数据中台了？</p><p>——有的，数仓有了，指标有了，报表有了，数据中台也上线好多年了。</p><p>问题就出在这里：看上去“齐活”的数据基础设施，遇到 AI 项目的时候，却越来越“不顺手”。</p><p>这不是某一家企业的特例，而是很多头部企业在今年共同遇到的现实。</p><p>多模态数据中台，不是哪个厂商的新品类，而是被这些现实一点点“逼”出来的结果。</p><h3>一、项目一个接一个，为什么“好用的 AI”依然很少？</h3><p>如果把技术名词先放一边，只看业务一线在日常中遇到的那些烦恼，基本可以归结为三类。</p><h4>第一类：问题本身，已经不是几张表能说清的了。</h4><p>投诉率上升，是产品问题，还是服务问题，还是运营动作出了偏差？</p><p>一条产线良率波动，是设备状态变差了，还是某个班组操作习惯改了，抑或原材料批次有差异？</p><p>一个片区的安全事件频率变高，是人流结构变化了，还是设施老化，还是历史事件叠加影响？</p><p>这些问题的线索，散落在录音文本、服务记录、工单流转、IoT 时序曲线、告警日志、监控视频、轨迹数据、甚至三维场景里。但在大多数企业的系统版图里，它们是这样的：</p><p>表格在数仓和中台；</p><p>日志在监控系统；</p><p>IoT 在边缘平台；</p><p>文档在知识库；</p><p>视频在安防系统或第三方云。</p><p>一个问题，天然跨多个系统。而传统数据中台，更多还是围绕结构化数据在组织世界。</p><h4>第二类：数据“都在”，但真正用起来总有点别扭。</h4><p>你去问数据团队，大概率会得到这样的回答：</p><p>“有，这个字段在某某表；那个数据要从日志库拉；</p><p>视频要去另外一个平台查；IoT 在边缘那边。”</p><p>于是，每做一个新的 AI 场景——智能客服、智能质检、预测性维护、智能风控、风险研判、智能问数与归因分析……都要从头打一条“专用数据链路”：</p><p>从五六个系统里各拎一段，再临时拼在一起。</p><p>做好一个项目不难，难的是：</p><p>几个项目之后，大家发现手上有的是一堆“各自为战”的小链路，而不是一块越来越厚的数据地基。</p><h4>第三类：智能总是“停在屏幕里”，很难进入日常工作。</h4><p>企业对 AI 的期待，其实很朴素：</p><p>业务能直接问；</p><p>不用切十个系统；</p><p>能看懂“为什么是这个结论”；</p><p>能把智能变成流程的一部分，而不是一次演示。</p><p>现实却往往是：</p><p>报表在一套系统，知识问答在一套系统，流程机器人在另一套系统；</p><p>每个“智能助手”背后连的是不同的数据源、不同的口径，能力不统一，体验也割裂。</p><p>久而久之，管理层会问一句：</p><p>我们到底是“有很多 AI 项目”，还是“真的多了一个和我们一起工作的智能同事”？</p><h3>二、沿着这些烦恼往下拆，企业真正缺的是什么？</h3><p>如果不从“我要不要上一个多模态数据中台”出发，而是老老实实从用户的烦恼往下拆，很快会发现：企业想要的，不是更多的“点状应用”，而是一块可复用的 Data+AI 地基。这块地基，要帮企业做三件事。</p><h4>第一件事：让业务问题可以被完整地“摊开”。</h4><p>“投诉率为什么上升”这个问题，背后需要的，不只是投诉表和订单表；“良率为什么波动”，需要的不只是工单和生产记录。如果企业内部没有一处地方，能围绕“客户、设备、订单、工单、门店、产线、场站”等对象，把结构化数据、日志、文本、音视频、时序、空间位置这些信息收拢在一起，那么任何一个 AI 模型，看到的都只是一块块碎片。</p><p>你很难指望一个模型，在看不到录音和工单的前提下，对投诉原因做出什么可靠判断。你也很难指望一个模型，在看不到工艺曲线和设备历史后，对良率问题给出负责任的建议。换句话说，如果问题本身是多模态的，数据视图却还是单模态的，那么所有智能，天然就被“打了折扣”。</p><h4>第二件事：让数据治理这件事，不再是“一次性的体力活”。</h4><p>数据团队并不怕辛苦做一遍数据治理，怕的是永远在做同一件事：</p><p>为了客服智能质检，清洗了一轮录音与文本；</p><p>为了质检优化，又清洗了一轮生产日志和视频；</p><p>为了城市治理，又清洗了一轮时空轨迹与告警事件。</p><p>每一轮都像是新品类，缺乏统一的标准和资产视角，项目一结束，这些成果就“躺”在各自专用库里，很难被后续场景继承。如果有一块工具，能把结构化数据、日志、文档、音视频、IoT、时空数据，以及 Embedding、标签这类“AI 产物”，统统纳入统一的元数据、血缘、权限和质量框架之中；</p><p>那每一次项目做完，企业的数据家底都会实实在在“厚”一截，而不是只多一套 Demo。</p><h4>第三件事：让智能有机会变成“默认存在”，而不是“偶尔出现”。</h4><p>所谓“默认存在”，就是：业务习惯了把问题直接抛给一个入口；</p><p>这个入口背后，能够自动把相关的数据、文档、案例、场景调度起来；</p><p>智能体给出的结论，可以被追问“为什么”，也可以在事后通过效果数据验证“对不对”。</p><p>要做到这一点，底层工具必须天然考虑：模型和智能体不是“外部调用者”，而是它的核心用户之一。它要提供的不只是数据查询接口，而是一整套为 AI 准备好的特征服务、向量服务、语义检索、算子编排能力。说到底，企业缺的不是一个“下一代中台”的名字，而是这么一块东西：</p><p>能看懂业务问题是多模态的，能让数据治理变成一件长期有复利的事，能让 AI 站在它上面，成为日常工作的一部分。叫“地基”也好，叫“操作系统”也好，本质就是这三件事。</p><h3>三、顺着这条线往下走，那块地基自然会长成“多模态数据中台”</h3><p>现在再回头看传统数据中台，它的价值并没有消失，只是边界暴露得越来越清晰。对结构化世界来说，它做得已经够好：</p><p>帮企业把“谁、在哪、做了什么、结果如何”这样的数字，收拢、建模、标准化，形成可被全公司共享的指标体系和分析框架。</p><p>问题在于，业务世界已经不只是一堆数字了。客户在通话里的情绪、工程师在工单里的备注、生产线上某段视频里的异常动作、某个设备在空间里的位置变化、某条路线的拥堵模式……这些东西，越来越频繁地出现在“关键问题”的证据链条上。</p><p>如果企业的地基仍然只为结构化数据设计，那么所有这些多模态线索，要么被挂在附件里，要么孤立在专用平台中，AI 想用，就得一次次“单飞”。沿着用户的问题继续往下走，能看到一个更清晰的图景：</p><p>在建模视角上，那块地基必须把“对象、事件、时空关系”当成核心事项，而不是只把表和字段当成世界的基本单元；</p><p>在治理视角上，它必须同时管理结构化、非结构化、时空数据和 AI 产物，让任何一条智能链路都可以被追溯、被评估；</p><p>在服务视角上，它必须把模型和智能体视为首要服务对象，提供适合它们的特征、向量、语义与编排能力。</p><p>当这些要求放在一起，你自然会得到这样一个结论：这块地基，长出来的样子，很像一个“多模态数据智能中台”。它不是简单地“加几种数据源”，而是回答了三个问题：</p><p>业务问题能不能被完整描述？</p><p>数据资产能不能持续积累？</p><p>AI 能不能站在这块地基上迭代，而不是每次旁路重造？</p><p>名字可以有很多，逻辑只有一个。从这个意义上讲，多模态数据中台并不是某个厂商的新故事，而是企业在 Data+AI 实践中，被一次次逼出来的共同答案。</p><h3>四、袋鼠云为什么会走到这一步？</h3><p>这时候再看袋鼠云，就会发现它的那条路其实并不复杂：</p><p>从大数据基础软件起步，先帮企业把结构化的那部分地基打牢；</p><p>随着客户在 AI、智能体、数字孪生等业务场景上的需求越来越多，逐渐意识到：</p><p>如果底层不能理解多模态，不能为 AI 提供原生的数据供给，再强的上层能力都会显得吃力。</p><p>于是，“数栈”开始往多模态方向延展：</p><p>一头兼容日志、文档、图像、音视频、IoT、时空数据，把它们纳入统一的元数据和治理框架；</p><p>一头与智能指标平台、智能体开发应用平台、空间智能产品家族打通，让智能问数、业务 Agent、数字孪生、空间智能、场景推演这些东西，都能站在同一块地基上生长。</p><p>你可以把它看成一个厂商的产品演进；也可以把它看成，是一批真实项目累积之后，对“那块缺席的地基”做的一次系统回应。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047496323" alt="图片" title="图片"/></p><h3>先承认世界是多模态的，再谈怎么做 AI</h3><p>回头看过去几年，很多企业在 AI 上的挫折感，其实来自一个很简单的错位：</p><p>业务提出的问题，天然是多模态的；</p><p>引进的模型，天然能处理多模态；</p><p>唯独数据基础设施，仍然是“表格世界”的设计。</p><p>在这样的前提下，再谈“知识问答”“智能体”“世界模型”，多少都有点“离地”。</p><p>所以，也许更现实的顺序是：</p><p>先承认业务世界就是多模态的；</p><p>再承认现有的数据地基对这件事准备不足；</p><p>然后，再思考一块怎样的基础设施，能把这两头重新接起来。</p><p>多模态数据中台，恰好是对这三个判断的同一个回答。它不是终点，只是一块起点——但如果没有这块起点，后面的 Data+AI，很难真正走得远。</p>]]></description></item><item>    <title><![CDATA[技术分享 | MySQL间隙锁原理深度详解 墨天轮 ]]></title>    <link>https://segmentfault.com/a/1190000047495731</link>    <guid>https://segmentfault.com/a/1190000047495731</guid>    <pubDate>2025-12-23 11:03:06</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>本文为<a href="https://link.segmentfault.com/?enc=pFVRseFSkUaQ2GsurHNeKw%3D%3D.RzZ%2BlUL9%2BuJqy%2FS7MLJHklDeZC%2FkYdZ1ALlN3QIlQa2RSNTx%2Bw06rsBRt8Q6kOAl" rel="nofollow" target="_blank">墨天轮数据库管理服务团队</a>第150期技术分享，内容原创，作者为技术顾问<strong>陈洋</strong>，如需转载请联系小墨（VX：modb666）并注明来源。如需查看更多文章可关注【墨天轮】公众号。</p><h2><strong>一、间隙锁概述</strong></h2><p>间隙锁（Gap Lock）是InnoDB存储引擎在<code>REPEATABLE READ</code>（可重复读）隔离级别下为了解决幻读（Phantom Read）问题而引入的一种锁机制。它锁定的是索引记录之间的“间隙”，而不是实际存在的记录。这意味着，即使间隙中没有数据，间隙锁也能阻止其他事务在该间隙内插入新的数据，从而保证了在同一事务中多次读取相同范围的数据时，结果集保持一致。</p><h2><strong>二、幻读问题</strong></h2><p>幻读是指在同一个事务中，两次执行相同的查询语句，但第二次查询却看到了第一次查询没</p><ol><li>事务A在某个范围内执行了查询。</li><li>事务B在该范围内插入了新的行并提交。</li><li>事务A再次执行相同的查询，看到了事务B插入的新行，导致前后两次查询结果不一致。</li></ol><p>在<code>REPEATABLE READ</code>隔离级别下，MySQL通过两种方式解决幻读问题：</p><ul><li><strong>快照读（Snapshot Read）</strong>：对于普通的<code>SELECT</code>语句，InnoDB通过MVCC（多版本并发控制）机制，在事务开始时生成一个Read View（一致性视图），后续的快照读都基于这个视图，因此不会看到其他事务提交的新数据。这种方式解决了普通<code>SELECT</code>语句的幻读。</li><li><strong>当前读（Current Read）</strong>：对于<code>SELECT ... FOR UPDATE</code>、<code>SELECT ... LOCK IN SHARE MODE</code>、<code>INSERT</code>、<code>UPDATE</code>、<code>DELETE</code>等语句，它们需要读取最新的数据版本，因此称为当前读。在当前读情况下，MVCC无法解决幻读问题，此时就需要间隙锁来防止其他事务插入新数据。</li></ul><h2><strong>三、间隙锁的实现原理</strong></h2><p>间隙锁是基于索引的，它锁定的是索引记录之间的空隙。当对某个范围的数据进行当前读操作时，InnoDB不仅会锁定符合条件的记录本身（记录锁），还会锁定这些记录前后的间隙，以及第一个记录之前的间隙和最后一个记录之后的间隙。这种记录锁和间隙锁的组合被称为<code>Next-Key Lock</code>。</p><p><strong>3.1 Next-Key Lock</strong></p><p><code>Next-Key Lock</code>是InnoDB默认的行锁类型，它结合了记录锁（Record Lock）和间隙锁（Gap Lock）。一个<code>Next-Key Lock</code>会锁定一个索引记录以及该记录之前的间隙。其锁定范围是<code>(前一个索引记录, 当前索引记录]</code>。</p><p>例如，在一个索引包含值10、20、30的表中，<code>Next-Key Lock</code>可能锁定的区间包括：</p><ul><li><code>(-∞, 10]</code></li><li><code>(10, 20]</code></li><li><code>(20, 30]</code></li><li><code>(30, +∞)</code></li></ul><p><strong>3.2 间隙锁的特性</strong></p><ul><li><strong>只在<code>REPEATABLE READ</code>隔离级别下生效</strong>：在<code>READ COMMITTED</code>（读已提交）隔离级别下，没有间隙锁，因此可能会出现幻读。</li><li><strong>不区分共享锁和排他锁</strong>：间隙锁的唯一目的是防止其他事务插入数据，因此它不区分共享（S）锁和排他（X）锁。任何事务持有间隙锁，都会阻止其他事务在该间隙内插入数据。</li><li><strong>间隙锁之间不冲突</strong>：不同事务可以同时持有同一个间隙的间隙锁。因为间隙锁的目的是阻止插入，而不是阻止读取或修改已存在的数据。</li><li><strong>与索引相关</strong>：间隙锁是加在索引上的，而不是数据行本身。如果查询没有使用索引，或者使用的索引不能有效地限制扫描范围，间隙锁可能会锁定整个表，导致并发性能下降。</li></ul><h2><strong>四、间隙锁的加锁规则</strong></h2><p>间隙锁的加锁规则相对复杂，主要取决于查询条件、索引类型以及是否是唯一索引：</p><ol><li><strong>等值查询与唯一索引</strong>：</li></ol><ul><li>如果查询条件是唯一索引的等值查询，并且找到了对应的记录，那么<code>Next-Key Lock</code>会退化为记录锁，只锁定该行，不会产生间隙锁。因为唯一索引保证了该值是唯一的，不会有新的数据插入到该位置。</li><li>如果查询条件是唯一索引的等值查询，但没有找到对应的记录，那么会在不存在的记录位置形成一个间隙锁，锁定该间隙，防止其他事务插入该值。</li></ul><ol start="2"><li><strong>等值查询与非唯一索引</strong>：</li></ol><ul><li>如果查询条件是非唯一索引的等值查询，无论是否找到记录，都会在扫描到的符合条件的记录以及其前后的间隙上加<code>Next-Key Lock</code>。这是因为非唯一索引可能存在多个相同的值，需要锁定一个范围来防止幻读。</li></ul><ol start="3"><li><strong>范围查询</strong>：</li></ol><ul><li>对于范围查询（如<code>WHERE id &gt; 10</code>或<code>WHERE id BETWEEN 10 AND 20</code>），无论是否是唯一索引，都会在扫描到的所有符合条件的记录及其前后的间隙上加<code>Next-Key Lock</code>。扫描会持续到第一个不满足条件的记录，并锁定该记录之前的间隙。</li></ul><ol start="4"><li><strong>无索引或索引失效</strong>：</li></ol><ul><li>如果查询没有使用索引，或者索引失效，那么InnoDB会进行全表扫描。在这种情况下，为了防止幻读，InnoDB会给整个表的所有索引记录都加上<code>Next-Key Lock</code>，这会严重影响并发性能。</li></ul><h2><strong>五、间隙锁的示例</strong></h2><p>假设有一个<code>products</code>表，其中包含<code>id</code>（主键）、<code>name</code>和<code>price</code>字段，并且<code>id</code>是自增主键。</p><pre><code class="sql">CREATE TABLE `products` (
  `id` int NOT NULL AUTO_INCREMENT,
  `name` varchar(255) DEFAULT NULL,
  `price` decimal(10,2) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
INSERT INTO `products` (`id`, `name`, `price`) VALUES
(1, 'Laptop', 1200.00),
(5, 'Mouse', 25.00),
(10, 'Keyboard', 75.00);</code></pre><p>当前<code>products</code>表中的<code>id</code>值有1, 5, 10。那么存在的间隙包括：</p><ul><li><code>(-∞, 1]</code></li><li><code>(1, 5]</code></li><li><code>(5, 10]</code></li><li><code>(10, +∞)</code></li></ul><h3>示例1：等值查询（唯一索引，找到记录）</h3><p><strong>事务A:</strong></p><pre><code class="sql">BEGIN;
SELECT * FROM products WHERE id = 5 FOR UPDATE;</code></pre><p><strong>分析</strong>：<code>id</code>是主键（唯一索引），查询条件是等值查询且找到了记录。此时，<code>Next-Key Lock</code>会退化为记录锁，只锁定<code>id = 5</code>的行。其他事务可以插入<code>id = 2</code>或<code>id = 7</code>的记录，但不能修改或删除<code>id = 5</code>的记录。</p><h3>示例2：等值查询（唯一索引，未找到记录）</h3><p><strong>事务A:</strong></p><pre><code class="sql">BEGIN;
SELECT * FROM products WHERE id = 3 FOR UPDATE;</code></pre><p>分析：<code>id</code>是主键（唯一索引），查询条件是等值查询但未找到记录。此时，会在<code>(1, 5]</code>这个间隙上加间隙锁，阻止其他事务插入<code>id</code>为2、3、4的记录。例如，事务B尝试插入<code>id = 2</code>的记录会被阻塞。</p><h3>示例3：范围查询</h3><p><strong>事务A:</strong></p><pre><code class="sql">BEGIN;
SELECT * FROM products WHERE id &gt; 5 FOR UPDATE;</code></pre><p><strong>分析</strong>：查询条件是范围查询。InnoDB会扫描<code>id = 10</code>的记录，并锁定<code>(5, 10]</code>和<code>(10, +∞)</code>这两个间隙。这意味着，其他事务不能插入<code>id</code>为6、7、8、9的记录，也不能插入<code>id</code>大于10的记录。同时，<code>id = 10</code>的记录本身也会被锁定。</p><h2><strong>六、间隙锁的优缺点</strong></h2><p><strong>优点</strong>：</p><ul><li>解决幻读：在<code>REPEATABLE READ</code>隔离级别下，间隙锁有效地防止了幻读的发生，保证了数据的一致性。</li></ul><p><strong>缺点</strong>：</p><ul><li>降低并发性：间隙锁锁定的不是具体的行，而是索引的范围，这可能导致不必要的锁定，从而降低了数据库的并发性能。即使没有数据，间隙也会被锁定。</li><li>死锁风险：间隙锁增加了死锁的风险，因为多个事务可能在不同的间隙上持有锁，并尝试获取对方持有的间隙上的锁，从而形成死锁。</li><li>难以理解和排查：间隙锁的加锁规则相对复杂，使得在出现性能问题或死锁时，排查和定位问题变得更加困难。</li></ul><h2><strong>七、总结</strong></h2><p>间隙锁是MySQL InnoDB存储引擎在<code>REPEATABLE READ</code>隔离级别下解决幻读问题的关键机制。理解其原理、加锁规则以及优缺点对于数据库性能优化和问题排查至关重要。在实际应用中，应根据业务需求和并发量，合理选择事务隔离级别，并注意避免因间隙锁导致的性能瓶颈和死锁问题。</p><h2><strong>八、间隙锁的排查与定位</strong></h2><p>在实际的数据库运维和开发中，间隙锁可能导致性能问题甚至死锁。因此，了解如何排查和定位间隙锁是至关重要的。</p><p><strong>8.1 识别间隙锁导致的性能问题</strong></p><ul><li><p><strong>慢查询日志</strong></p><p>：检查MySQL的慢查询日志，特别是那些执行时间长、涉及范围查询且隔离级别为<code>REPEATABLE READ</code>的<code>SELECT ... FOR UPDATE</code>、<code>INSERT</code>、<code>UPDATE</code>、<code>DELETE</code>语句。这些语句很可能触发了间隙锁。</p></li><li><strong><code>SHOW PROCESSLIST</code></strong>：通过<code>SHOW PROCESSLIST</code>命令可以查看当前正在执行的SQL语句。如果发现有大量事务长时间处于<code>Locked</code>或<code>Waiting for table metadata lock</code>状态，并且涉及的SQL语句是范围查询，则可能与间隙锁有关。</li><li><strong><code>information_schema</code>数据库</strong>：<code>information_schema</code>数据库提供了许多关于MySQL服务器状态的信息。以下几个表对于排查锁问题非常有用：</li><li><code>information_schema.INNODB_TRX</code>：显示当前所有正在运行的InnoDB事务的信息，包括事务ID、事务状态、锁等待情况等。</li><li><code>information_schema.INNODB_LOCKS</code>：显示当前被锁定的资源以及持有锁的事务信息。可以查看锁的类型（如<code>RECORD</code>、<code>GAP</code>、<code>AUTO_INC</code>等）和锁定的索引。</li><li><code>information_schema.INNODB_LOCK_WAITS</code>：显示当前存在的锁等待关系，可以帮助识别死锁或长时间的锁等待。</li></ul><p><strong>8.2 使用SHOW ENGINE INNODB STATUS排查</strong></p><p><code>SHOW ENGINE INNODB STATUS</code>命令是排查InnoDB存储引擎问题（包括锁问题）的强大工具。它会输出大量关于InnoDB内部状态的信息，其中<code>LATEST DETECTED DEADLOCK</code>和<code>TRANSACTIONS</code>部分对于分析间隙锁导致的死锁和锁等待尤为重要。</p><p><strong>输出解读要点：</strong></p><ul><li><strong><code>LATEST DETECTED DEADLOCK</code></strong>：如果发生了死锁，这一部分会详细记录最近一次死锁的信息，包括死锁涉及的事务、它们尝试获取的锁、持有的锁以及等待的资源。通过分析这里的信息，可以明确是哪些事务在哪些间隙上发生了死锁。</li><li><strong><code>RECORD LOCKS</code></strong>：表示记录锁。</li><li><strong><code>GAP LOCKS</code></strong>：表示间隙锁。</li><li><strong><code>NEXT-KEY LOCKS</code></strong>：表示临键锁（记录锁+间隙锁）。</li><li><strong><code>TRANSACTIONS</code></strong>：这一部分列出了所有活跃的事务，包括它们的事务ID、状态、执行的SQL语句、持有的锁以及等待的锁。通过查看<code>LOCK WAIT</code>状态的事务，可以找到正在等待锁的事务，并进一步分析其等待的原因。</li><li>查找<code>LOCK WAIT</code>状态的事务。</li><li>查看<code>LOCKED TABLES</code>和<code>WAITING FOR THIS LOCK TO BE GRANTED</code>部分，了解事务正在等待的锁类型和资源。</li><li>结合SQL语句，判断是否是间隙锁导致的等待。</li></ul><p><strong>示例：</strong></p><pre><code class="sql">SHOW ENGINE INNODB STATUS\G</code></pre><p>执行上述命令后，会得到一个详细的报告。你需要仔细阅读其中的<code>LATEST DETECTED DEADLOCK</code>和<code>TRANSACTIONS</code>部分。</p><p><strong>8.3 模拟和复现间隙锁</strong></p><p>为了更好地理解和排查间隙锁，可以在测试环境中模拟和复现间隙锁的场景。这通常涉及：</p><ol><li>设置数据库隔离级别为<code>REPEATABLE READ</code>。</li><li>创建包含索引的测试表。</li><li>开启多个事务，在不同的事务中执行会触发间隙锁的SQL语句（如范围查询的<code>FOR UPDATE</code>语句），并尝试在间隙中插入数据，观察事务的阻塞和死锁情况。</li></ol><p>通过模拟，可以加深对间隙锁行为的理解，并验证排查方法是否有效。</p><p><strong>8.4 避免间隙锁导致的性能问题</strong></p><ul><li><strong>降低隔离级别</strong>：如果业务允许，可以将事务隔离级别从<code>REPEATABLE READ</code>降至<code>READ COMMITTED</code>。在<code>READ COMMITTED</code>隔离级别下，InnoDB不会使用间隙锁，从而避免了幻读和间隙锁带来的性能问题。但需要注意的是，这可能会引入其他并发问题，需要根据业务场景权衡。</li><li><strong>优化SQL语句</strong></li><li>尽量使用等值查询，避免不必要的范围查询。</li><li>确保查询条件能够命中索引，避免全表扫描。全表扫描会导致整个表被间隙锁锁定，严重影响并发。</li><li>对于范围查询，尽量缩小查询范围，减少间隙锁锁定的范围。</li><li><strong>避免不必要的<code>FOR UPDATE</code>或<code>LOCK IN SHARE MODE</code></strong>：只有在确实需要对查询结果进行更新或需要保证数据一致性时，才使用这些语句。</li><li><strong>拆分大事务</strong>：将长时间运行的大事务拆分为多个小事务，减少事务持有锁的时间，从而降低间隙锁冲突的概率。</li><li><strong>使用乐观锁</strong>：对于某些业务场景，可以考虑使用乐观锁（通过版本号或时间戳）来替代悲观锁，减少数据库层面的锁竞争。</li><li><strong>调整索引</strong>：合理设计索引，确保查询能够高效地利用索引，减少不必要的全表扫描或索引扫描。</li></ul><p>通过上述方法，可以有效地排查、定位和避免MySQL间隙锁带来的性能问题和死锁风险。</p><h2><strong>九、间隙锁死锁案例分析与解决方案</strong></h2><p>间隙锁虽然解决了幻读问题，但它引入了死锁的风险。当两个或多个事务在获取间隙锁时形成循环等待，就会发生死锁。以下是一个典型的间隙锁死锁案例及其解决方案。</p><p><strong>9.1 案例场景：并发插入导致的间隙锁死锁</strong></p><p>假设我们有一个<code>orders</code>表，其中包含<code>id</code>（主键）、<code>order_no</code>（唯一索引）和<code>amount</code>字段。为了简化，我们只关注<code>id</code>和<code>order_no</code>。</p><pre><code class="sql">CREATE TABLE `orders` (
  `id` int NOT NULL AUTO_INCREMENT,
  `order_no` varchar(255) UNIQUE,
  `amount` decimal(10,2),
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
INSERT INTO `orders` (`id`, `order_no`, `amount`) VALUES
(1, 'A001', 100.00),
(5, 'A005', 200.00),
(10, 'A010', 300.00);</code></pre><p>当前<code>orders</code>表中的<code>order_no</code>值有’A001’, ‘A005’, ‘A010’。假设现在有两个事务（事务A和事务B）几乎同时尝试插入<code>order_no</code>在’A001’和’A005’之间的记录，例如’A003’和’A004’。</p><p><strong>事务A:</strong></p><pre><code class="sql">-- 事务A
SET SESSION TRANSACTION ISOLATION LEVEL REPEATABLE READ;
BEGIN;
-- 步骤1: 事务A尝试插入 'A003'
INSERT INTO orders (order_no, amount) VALUES ('A003', 150.00);</code></pre><p><strong>事务B:</strong></p><pre><code class="sql">-- 事务B
SET SESSION TRANSACTION ISOLATION LEVEL REPEATABLE READ;
BEGIN;
-- 步骤1: 事务B尝试插入 'A004'
INSERT INTO orders (order_no, amount) VALUES ('A004', 180.00);</code></pre><p><strong>死锁发生过程：</strong></p><ol><li><strong>事务A执行<code>INSERT ('A003', ...)</code></strong>：</li></ol><ul><li>为了插入’A003’，InnoDB需要检查<code>order_no</code>唯一索引中<code>(A001, A005)</code>这个间隙。事务A会在这个间隙上加一个意向插入锁（Insert Intention Lock），这是一种特殊的间隙锁，表示事务A打算在这个间隙中插入一条记录。同时，为了保证唯一性，它可能还需要对<code>A001</code>和<code>A005</code>这两个记录加S锁或X锁（具体取决于索引类型和操作）。</li></ul><ol start="2"><li><strong>事务B执行<code>INSERT ('A004', ...)</code></strong>：</li></ol><ul><li>几乎同时，事务B也尝试插入’A004’。它也需要检查<code>order_no</code>唯一索引中<code>(A001, A005)</code>这个间隙。事务B也会在这个间隙上加一个意向插入锁。</li></ul><ol start="3"><li><strong>冲突与死锁</strong>：</li></ol><ul><li>虽然意向插入锁之间通常不会直接冲突，但当两个事务都试图在同一个间隙内插入数据时，它们可能会尝试获取间隙内的其他锁（例如，为了检查唯一性而对相邻记录加的锁），或者在内部对间隙进行更细粒度的锁定。在这种情况下，如果事务A持有了间隙<code>(A001, A005)</code>的一部分锁，并等待事务B持有的另一部分锁；同时事务B持有了间隙<code>(A001, A005)</code>的另一部分锁，并等待事务A持有的锁，就会形成循环等待，导致死锁。</li><li>MySQL的死锁检测机制会发现这个循环，并选择其中一个事务作为“牺牲品”（通常是修改行数较少的事务），回滚该事务，从而解除死锁。被回滚的事务会收到<code>ERROR 1213 (40001): Deadlock found when trying to get lock; try restarting transaction</code>错误。</li></ul><p><strong>9.2 解决方案</strong></p><p>针对这种因间隙锁导致的死锁，可以采取以下几种策略：</p><ol><li><strong>降低事务隔离级别</strong>：将事务隔离级别从<code>REPEATABLE READ</code>降至<code>READ COMMITTED</code>。在<code>READ COMMITTED</code>级别下，<code>INSERT</code>操作通常只在插入的行上加行锁，而不会加间隙锁，从而避免了这类死锁。但需要注意的是，<code>READ COMMITTED</code>隔离级别下可能出现幻读（对于快照读），需要根据业务场景权衡。</li><li><strong>优化SQL语句和索引</strong>：</li></ol><ul><li><strong>避免在非唯一索引上进行范围查询的<code>FOR UPDATE</code>或<code>LOCK IN SHARE MODE</code></strong>：如果业务允许，尽量避免在非唯一索引上使用<code>FOR UPDATE</code>或<code>LOCK IN SHARE MODE</code>进行范围查询，因为这会更容易触发间隙锁。</li><li><strong>合理设计唯一索引</strong>：如果<code>order_no</code>是唯一的，并且业务逻辑允许，可以考虑在插入前先进行一次<code>SELECT ... FOR UPDATE</code>来预先锁定范围，但这会降低并发性。</li></ul><ol start="3"><li><strong>应用程序层面处理死锁</strong>：在应用程序代码中捕获死锁异常（错误码1213），并实现事务重试机制。当发生死锁时，回滚当前事务，并等待一小段时间后重新尝试执行事务。这是处理死锁的常见且有效的方法。</li><li><strong>使用自增主键作为插入依据</strong>：如果<code>order_no</code>不是严格递增的，或者其生成逻辑复杂，可以考虑让<code>id</code>（自增主键）作为主要的插入依据，而<code>order_no</code>作为普通唯一索引。在某些情况下，这可以减少间隙锁的冲突。</li><li><strong>批量插入</strong>：如果需要插入大量数据，可以考虑使用批量插入（<code>INSERT INTO ... VALUES (...), (...);</code>）而不是单条插入。批量插入可以减少事务的数量和锁的竞争。</li><li><strong>调整业务逻辑</strong>：重新审视业务逻辑，看是否可以调整操作顺序或数据模型，以减少并发事务对相同间隙的竞争。</li></ol><hr/><p><img referrerpolicy="no-referrer" src="/img/remote/1460000046208374" alt="" title=""/>  </p><p>墨天轮从乐知乐享的数据库技术社区蓄势出发，全面升级，提供多类型数据库管理服务。墨天轮数据库管理服务旨在为用户构建信赖可托付的数据库环境，并为数据库厂商提供中立的生态支持。<br/>墨天轮数据库服务官网：<a href="https://link.segmentfault.com/?enc=2NFB4QTaSwYz%2FQCL3U4HLw%3D%3D.nVIMujpWFzGfX4RNbfd%2B1J7EUCgVSplTtId2U2W01AImxz0u8V9jTulk4w0S18vX" rel="nofollow" target="_blank">https://www.modb.pro/service</a></p>]]></description></item><item>    <title><![CDATA[同城陪玩小程序搭建指南：UniApp+PHP 源码适配 + 定位功能实现 伊伊DK ]]></title>    <link>https://segmentfault.com/a/1190000047495808</link>    <guid>https://segmentfault.com/a/1190000047495808</guid>    <pubDate>2025-12-23 11:02:05</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>相比普通陪玩平台，同城陪玩小程序的核心优势在于 “地域聚焦”—— 用户可快速找到身边的陪玩师（如同城游戏开黑、线下桌游、运动陪伴、技能教学等场景），解决 “跨城沟通不便”“线下约见难匹配” 的痛点；对创业者而言，同城模式获客成本更低（可深耕本地社群、线下推广），用户粘性更强，盈利转化更高效。<br/>而选择<strong> UniApp+PHP</strong> 技术栈搭建，既能借助 UniApp 跨端优势（一套源码覆盖微信小程序 / 支付宝小程序 / H5），又能依托 PHP 后端的高兼容性，轻松实现同城核心的 “定位匹配” 功能，不用从零开发，降低 80% 搭建门槛。<br/><img width="640" height="910" referrerpolicy="no-referrer" src="/img/bVdmVL2" alt="" title=""/><img width="723" height="654" referrerpolicy="no-referrer" src="/img/bVdmPC3" alt="" title="" loading="lazy"/><br/><strong>一、核心步骤：源码适配 + 定位功能实现（全程实操）</strong><br/>定位功能实现（核心操作，分 3 个关键环节）<br/>同城陪玩的核心是 “精准定位 + 距离匹配”，需通过 “小程序获取坐标→地图 API 解析地址→后端筛选匹配” 实现，具体步骤如下：</p><ol><li>申请地图 API 密钥（以腾讯地图为例）<br/>登录腾讯地图开放平台，注册并创建应用，申请 “微信小程序 JavaScriptAPI v2” 密钥；<br/>配置密钥的 “Referer 白名单”（填写自己的小程序 AppID），确保仅自身小程序可调用该 API。</li><li>前端：获取用户 / 陪玩师地理位置（UniApp 端开发）<br/>调用 UniApp 定位接口：在用户注册 / 登录时，通过 uni.getLocation() 方法获取用户的经纬度坐标（需用户授权 “获取地理位置” 权限）；<br/>陪玩师入驻时定位：陪玩师提交入驻资料页面，添加 “获取当前位置” 按钮，自动获取其经纬度并存储到数据库（后续用于匹配同城用户）；<br/>地址解析：将获取的经纬度通过腾讯地图 API 转换为具体地址（如 “北京市朝阳区 XX 街道”），展示在用户 / 陪玩师个人资料页，提升体验。</li><li>后端：实现同城筛选与距离排序（PHP 端开发）<br/>坐标存储：在用户表、陪玩师表中新增 “latitude（纬度）”“longitude（经度）” 字段，存储前端上传的坐标数据；<br/>距离计算：通过 PHP 编写 “球面距离计算公式”（或调用腾讯地图 API），根据用户坐标与陪玩师坐标，计算两者之间的实际距离（单位：公里）；<br/>同城筛选逻辑：<br/>用户端：在 “同城陪玩” 页面，默认展示 “5 公里内” 的陪玩师，支持手动调整距离范围（10 公里 / 20 公里 / 50 公里）；<br/>排序功能：按 “距离由近及远”“评分由高到低”“价格从低到高” 排序，方便用户快速筛选；<br/>订单关联：用户下单时，自动记录订单的 “同城标识”，后端统计同城订单数据，方便运营分析。<br/><img width="723" height="697" referrerpolicy="no-referrer" src="/img/bVdcACU" alt="" title="" loading="lazy"/><img width="723" height="697" referrerpolicy="no-referrer" src="/img/bVdeT7E" alt="" title="" loading="lazy"/><img width="723" height="247" referrerpolicy="no-referrer" src="/img/bVdmcMZ" alt="" title="" loading="lazy"/></li></ol>]]></description></item><item>    <title><![CDATA[Apache Parquet 优势与日志应用场景解析 东风微鸣云原生 ]]></title>    <link>https://segmentfault.com/a/1190000047495814</link>    <guid>https://segmentfault.com/a/1190000047495814</guid>    <pubDate>2025-12-23 11:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>写作背景</h2><p>近期看了几篇关于日志解决方案的文章, 发现它们都在使用 Apache Parquet 作为存储文件格式. 如下:</p><ul><li><a href="https://link.segmentfault.com/?enc=leh41Q%2Bpvyi2BTRyCTixEg%3D%3D.ZpG0Cqt9kyOnSJgaVnNPJ2WNd%2BmudocJdbq%2B8ZkJIr62BrFAjpkTXKRWHQgUBQUh52MIBie5%2BuIlHCWSQWL4bw%3D%3D" rel="nofollow" target="_blank">Yelp 发布大规模管理 S3 服务器访问日志的方案_架构_InfoQ精选文章</a></li><li><a href="https://link.segmentfault.com/?enc=ki9BJFbrwza59giqzvWfxQ%3D%3D.QR7FVYgeoV2B%2BefNkZrKCLgLi476xpDj2E0QrBpxDYnbfmLYpKOr%2Bu%2BYvF7Lo7%2BA" rel="nofollow" target="_blank">Cloudflare Log Explorer is now GA, providing native observability and forensics</a></li><li><a href="https://link.segmentfault.com/?enc=ioCVYLgODdrF%2FgZxUE1AsA%3D%3D.se%2BhOgHK78gZm6oB%2FpR%2FgdWpenOamd8iKyg9qRvMKb6%2BbB8S7ifgP%2F2hFeeSfmayNf8jSd67A4dtqMFfK6PTJg%3D%3D" rel="nofollow" target="_blank">逆势降本：云上数据平台年复削减30%的治理实践_云计算_吴建阳_InfoQ精选文章</a></li><li><a href="https://link.segmentfault.com/?enc=G47S5H2b5W2lT%2BCXRaKmxQ%3D%3D.VRzdaum4t58D8sf%2F1X95OlgSLQt16lV0pKOPj5S691vMjQhIts0g1jdlQB48%2FOuWljT%2Bs%2FifpENm1LK9u%2FFrFEyWfEZ%2By8hzH3yGQDkLeMIFi5Uv90W54sHZWbO%2F4pzG" rel="nofollow" target="_blank">AWS Debuts a Distributed SQL Database, Amazon S3 Tables for Iceberg - The New Stack</a></li><li><a href="https://link.segmentfault.com/?enc=nu%2Bzzv2XS4NJTNFbgmw%2BVA%3D%3D.JsJ8S6gjtLkTiZ50Ilznmy0%2BigAhWWvk9oMykAlH4ZGUDHinCz4lWRbBi0vZmjvoUQq%2FgjlgLEstx%2BKv6ZIGVG8SNVZfoL8VM28T66WCK7GGPX%2Bw%2FM61ddPR0XuUzagHcfNV3Q994NlsKqAVtFJCfw%3D%3D" rel="nofollow" target="_blank">Grafana Tempo 2.5 release: vParquet4, streaming endpoints, and more metrics | Grafana Labs</a></li><li><a href="https://link.segmentfault.com/?enc=6qPMn%2F4vV6qn5Kw7HENSug%3D%3D.cA6gec4ViEW8%2BWlIRf8smfi6AZVkdMfnKP4yj9BwGuneBVgK1RVuqpWR4LeNliogg8AyjAB8kGQqXG5svq2Po0AEO1%2FswE%2FCumYFJFjBtzo%3D" rel="nofollow" target="_blank">对象存储应用：云原生最新架构 - The New Stack --- Object Store Apps: Cloud Native's Freshest Architecture - The New Stack</a></li></ul><p>这勾起了我的好奇心:</p><ul><li>Apache Parquet 是什么?</li><li>有什么优势?</li><li>什么软件可以处理 Apache Parquet?</li><li>近期发现很多日志解决方案会将日志转换为 Apache Parquet, 为什么要这样处理, 有什么优势?</li></ul><h2>Apache Parquet 简介</h2><p><strong>Apache Parquet</strong> 是一种开源的列式存储文件格式，专门为大数据处理框架设计，最初由 Twitter 和 Cloudera 联合开发，现为 Apache 顶级项目。</p><h2>核心优势</h2><h3>1. <strong>列式存储结构</strong></h3><ul><li>与传统行式存储不同，Parquet 按列存储数据</li><li>查询时只需读取相关列，大幅减少 I/O</li><li>示例对比：</li></ul><pre><code class="log">行式存储：Row1[col1,col2,col3], Row2[col1,col2,col3], ...
列式存储：Column1[所有行的值], Column2[所有行的值], ...</code></pre><h3>2. <strong>高效的压缩和编码</strong></h3><ul><li>同列数据类型一致，压缩效率更高（可达行式存储的 1/10）</li><li>支持多种编码：RLE、字典编码、Delta 编码等</li><li>支持多种压缩：Snappy、Gzip、LZO、Zstd</li></ul><h3>3. <strong>Schema 演化支持</strong></h3><ul><li>支持向后/向前兼容的 schema 变更</li><li>可以添加新列、删除列、修改列类型</li></ul><h3>4. <strong>谓词下推</strong>（Predicate Pushdown）</h3><ul><li>查询引擎可以在读取数据前过滤不相关的数据块</li><li>利用列统计信息（min/max 值）跳过无关数据块</li></ul><h3>5. <strong>嵌套数据结构支持</strong></h3><ul><li>原生支持复杂嵌套数据类型（数组、映射、结构体）</li><li>使用 Dremel 记录 shredding 算法高效存储嵌套数据</li></ul><h2>能处理 Parquet 的软件/框架</h2><h3>大数据处理框架</h3><ul><li><strong>Apache Spark</strong>（主要使用场景）</li><li><strong>Apache Hive</strong></li><li><strong>Apache Impala</strong></li><li><strong>Presto/Trino</strong></li><li><strong>Apache Flink</strong></li><li><strong>Apache Arrow</strong>（内存格式转换）</li></ul><h3>查询引擎</h3><ul><li><strong>AWS Athena</strong></li><li><strong>Google BigQuery</strong></li><li><strong>Azure Synapse</strong></li><li><strong>DuckDB</strong></li><li><strong>Polars</strong></li></ul><h3>编程语言支持</h3><ul><li>Python（PyArrow、pandas）</li><li>Java</li><li>R</li><li>Go</li><li>.NET</li></ul><h3>日志解决方案</h3><ul><li>Cloudflare Log Explorer</li><li>OpenObserve</li><li>Grafana Tempo</li><li>Yelp</li><li>AWS 官方参考架构: <a href="https://link.segmentfault.com/?enc=2wjCHoId9L6HfhFi4g3igg%3D%3D.nr%2Bh7vBlzzPVkfBe4FchtQYyTkD8BJgIWyxBncwCJo3nn1HYBhdq2JSzm6VKluj4ZA5STUNioUzhgF%2F08UcgsBftxVAcuSVadw5rtHLRTQT18Q6qNa4I6DpsIrr3V3vTMwfQ%2Fimoe1SWQJfnLkpKUhK0bwALu2rdAw1rARGFIQE%3D" rel="nofollow" target="_blank">Extracting key insights from Amazon S3 access logs with AWS Glue for Ray | AWS Big Data Blog</a></li></ul><h2>日志解决方案转用 Parquet 的原因</h2><h3>1. <strong>成本效益</strong></h3><pre><code class="log"># 示例：日志存储成本对比

原始 JSON 日志：1TB → 存储成本 $$$$
Parquet 压缩后：~100GB → 存储成本 $</code></pre><ul><li>存储成本降低 70-90%</li><li>网络传输成本显著降低</li></ul><h3>2. <strong>查询性能提升</strong></h3><pre><code class="sql">-- 典型日志查询场景
SELECT COUNT(*), error_code 
FROM logs 
WHERE date &gt;= '2024-01-01' 
  AND status = 'ERROR' 
GROUP BY error_code;

-- Parquet 优势：
-- 1. 只读取 date, status, error_code 三列
-- 2. 利用列统计快速跳过无关日期分区
-- 3. 压缩数据减少磁盘 I/O</code></pre><h3>3. <strong>适合时序数据分析</strong></h3><ul><li>日志数据天然具有时间属性</li><li>Parquet 支持按时间分区，优化时间范围查询</li><li>结合分区剪枝（Partition Pruning）大幅提升性能</li></ul><h3>4. <strong>兼容现代数据栈</strong></h3><pre><code class="log"># 典型日志处理管道
原始日志 → Fluentd/Logstash → Kafka → 
Spark Streaming → Parquet (S3/ADLS) → 
Trino/Athena 查询 → BI 工具</code></pre><h3>5. <strong>长期存储和分析</strong></h3><ul><li>Parquet 是分析型工作负载的理想格式</li><li>支持数据湖架构（Delta Lake、Iceberg、Hudi）</li><li>便于历史日志的趋势分析和机器学习</li></ul><h2>具体应用场景示例</h2><h3>案例：ELT 日志分析管道</h3><pre><code class="log">原始日志 (JSON/文本)
       ↓
实时处理层 (Kafka)
       ↓
批处理层 (Spark) → 转换为 Parquet
       ↓
云存储 (S3/GCS) → 分区: dt=2024-01-01/
       ↓
查询层 (Athena/Presto)
       ↓
可视化 (Grafana/Tableau)</code></pre><h3>性能对比数据</h3><ul><li><strong>存储空间</strong>：较 JSON 减少 75-90%</li><li><strong>查询速度</strong>：提升 10-100 倍（取决于查询模式）</li><li><strong>扫描数据量</strong>：减少 60-95%（列裁剪效果）</li></ul><h2>注意事项</h2><ol><li><p><strong>不适合场景</strong>：</p><ul><li>高频单行读写（OLTP）</li><li>需要流式逐行处理的场景</li><li>小文件过多会影响性能</li></ul></li><li><p><strong>最佳实践</strong>：</p><ul><li>合理设置文件大小（128MB-1GB）</li><li>按时间分区组织数据</li><li>选择适当的压缩算法（平衡速度/比率）</li></ul></li></ol><p>Parquet 已成为现代数据湖和日志分析的事实标准格式，特别适合需要长期存储、批量分析和成本优化的日志管理场景。</p>]]></description></item><item>    <title><![CDATA[跟老卫学仓颉编程语言开发：标识符与程序结构 waylau ]]></title>    <link>https://segmentfault.com/a/1190000047495117</link>    <guid>https://segmentfault.com/a/1190000047495117</guid>    <pubDate>2025-12-23 09:03:06</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>本节介绍仓颉编程语言的标识符和程序结构。</p><h3>标识符</h3><p>在仓颉编程语言中，开发者可以给一些程序元素命名，这些名字也被称为“标识符”，标识符分为普通标识符和原始标识符两类，它们分别遵从不同的命名规则。</p><p>普通标识符不能和仓颉关键字相同，可以取自以下两类字符序列：</p><p>由“XID_Start”字符开头，后接任意长度的“XID_Continue”字符<br/>由一个“_”开头，后接至少一个“XID_Continue”字符<br/>其中，“XID_Start”、“XID_Continue”定义见Unicode标准。仓颉使用Unicode标准15.0.0（<a href="https://link.segmentfault.com/?enc=1FQiwVPS0pmeKjYFkGuP3Q%3D%3D.JWL7QRGEFYOL%2Bn%2FkXA97rePuGAZSe3FDcFjj0iYDMCrzAwP%2BJjbRxuJu%2FLR%2FBoPaqI6eOupwVcZHIDBqgInR%2FQ%3D%3D" rel="nofollow" target="_blank">https://www.unicode.org/reports/tr31/tr31-37.html</a>）。</p><p>仓颉把所有标识符识别为Normalization Form C (NFC) 后的形式。两个标识符如果在NFC后相等，则认为是相同的标识符。</p><p>例如，以下每行字符串都是合法的普通标识符：</p><pre><code>abc
_abc
abc_
a1b2c3
a_b_c
a1_b2_c3
仓颉
__こんにちは</code></pre><p>以下每行字符串都是不合法的普通标识符：</p><pre><code>ab&amp;c  // 使用了非法字符 “&amp;”
3abc  // 数字不能出现在头部
while // 不能使用仓颉关键字</code></pre><p>原始标识符是在普通标识符或仓颉关键字的外面加上一对反引号，主要用于将仓颉关键字作为标识符的场景。</p><p>例如，以下每行字符串都是合法的原始标识符：</p><pre><code>`abc`
`_abc`
`a1b2c3`
`if`
`while`
`à֮̅̕b`</code></pre><p>以下每行字符串，由于反引号内的部分是不合法的普通标识符，所以它们整体也是不合法的原始标识符：</p><pre><code>`ab&amp;c`
`3abc`</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047495119" alt="" title=""/></p><h3>程序结构</h3><p>通常，我们都会在扩展名为<code>.cj</code>的文本文件中编写仓颉程序，这些程序和文件也被称为源代码和源文件，在程序开发的最后阶段，这些源代码将被编译为特定格式的二进制文件。</p><p>在仓颉程序的顶层作用域中，可以定义一系列的变量、函数和自定义类型（如struct、class、enum和interface等），其中的变量和函数分别被称为全局变量和全局函数。如果要将仓颉程序编译为可执行文件，则需要在顶层作用域中定义一个main函数作为程序入口，它可以有<code>Array&lt;String&gt;</code>类型的参数，也可以没有参数，它的返回值类型可以是整数类型或Unit类型。</p><p><strong>注</strong>：定义main函数时，不需要写func修饰符。此外，如果需要获取程序启动时的命令行参数，可以声明和使用<code>Array&lt;String&gt;</code>类型参数。</p><p>例如在以下程序中，我们在顶层作用域定义了全局变量g和全局函数b，还有自定义类型C、D和E，以及作为程序入口的main函数。</p><pre><code>let g = 2022
func b() {}
struct C {}
class D {}
enum E { F | G }

main() {
    println(g)
}</code></pre><p>在非顶层作用域中不能定义上述自定义类型，但可以定义变量和函数，称之为局部变量和局部函数。特别地，对于定义在自定义类型中的变量和函数，称之为成员变量和成员函数。</p><p><strong>注</strong>：enum和interface中仅支持定义成员函数，不支持定义成员变量。</p><p>例如在以下程序中，我们在顶层作用域定义了全局函数a和自定义类型A，在函数a中定义了局部变量b和局部函数c，在自定义类型A中定义了成员变量b和成员函数c。</p><pre><code>func a() {
    let b = 2023
    func c() {
        println(b)
    }
    c()
}

class A {
    let b = 2024
    public func c() {
        println(b)
    }
}

main() {
    a()
    A().c()
}</code></pre><p>运行以上程序，将输出：</p><pre><code>2023
2024</code></pre><p>本节示例可以在“program_structure_demo”应用下找到。</p><h3>参考引用</h3><ul><li>免费开源书<a href="https://link.segmentfault.com/?enc=02SD0srpY9xvgKf2y7FNbQ%3D%3D.zib%2FVwP%2FUcbQJcBR9G22Z9w%2FOzUa5S1t6yrlZC8fQyZgJ9z%2Fc1X4Zaj%2FYTFnwjLUuRf9v2%2BSAznJ70eLZgF1GQ%3D%3D" rel="nofollow" target="_blank">《跟老卫学仓颉编程语言开发》</a></li><li>免费开源书<a href="https://link.segmentfault.com/?enc=U29IRfe1A7Nsq3kDloVTvg%3D%3D.pCKj1Uf2RxZKWPiU9LQpqSS7Y6HIqK4guBuTwIj0V09%2FeStXSRi9ZMj23aiRmz2t" rel="nofollow" target="_blank">《跟老卫学HarmonyOS开发》</a></li><li><a href="https://link.segmentfault.com/?enc=jTBlYp%2F3GIfi9SHJ0j55pQ%3D%3D.1GDs2BQpV43JxWpsSmerODXYYJUjTXBnyxDaHyX0nsmra8f1rMIEiosLnrnuzeG%2F" rel="nofollow" target="_blank">HarmonyOS NEXT+AI大模型打造智能助手APP（仓颉版）</a>（视频）</li><li><a href="https://link.segmentfault.com/?enc=V1slGi2qrkUBpgNM01%2FgrQ%3D%3D.sWCbesEpjP1GPBc%2BZ%2Fs4%2BJ32F5g6lEx0N0NZE8qd%2B4l7RvwXTe2a5jfU0Hh4aOiBp2i1HzYe27iwXUAuXYIZj%2BMnT5AOleIkC7cFjUYLjVs%3D" rel="nofollow" target="_blank">仓颉编程从入门到实践</a>（北京大学出版社）</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047495120" alt="" title="" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[AI编程正在"腐烂"，而解决方案在40年前就存在了 reddish ]]></title>    <link>https://segmentfault.com/a/1190000047495123</link>    <guid>https://segmentfault.com/a/1190000047495123</guid>    <pubDate>2025-12-23 09:02:13</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>提到AI编程呢，真的是让人欢喜让人优。爱得不行又恨得不行。 写出来的东西前期是好得不得了，后期就垃圾遍地，错觉横飞。 因为他的能力强大，对于研发和产品来说很难割舍不用，但他不受控制，也给后期维护带来的极大地麻烦。</p><p>经常行走江湖的朋友都知道，一旦被毒蛇咬了，不要怕，不要慌，剧毒之物，五步之内必有解药。</p><p>那问题来了，对于AI编程的这种困境，五步之内是否有解药呢？</p><p>我们梳理了一下这些年来的软件工程的编程模型，a~~~,还真的有一个软件的设计架构，刚好可以补足AI编程的短板。只是这个架构太古老了，估计很多人都没有听说过。 这个架构就是命令行Pipeline架构(不记得有没人定义过明确的名称，大概是这个意思)。</p><h2>AI编程的三大绝症</h2><p>要解决问题，第一步就是要识别问题，找出他的<code>根本原因</code> <sup id="fnref-1"><a href="#fn-1" class="footnote-ref">1</a></sup>。</p><p>AI编程前面一开始很厉害，但是越到后期越糟糕，而且是指数级的下降。这种现象被业内人士称为"上下文腐烂"。</p><p>它不仅会导致代码质量下降，处处埋伏隐患，而且还无法维护。给实际生成应用带来了很大的挑战。 最新的OpenAI的<code>访谈</code> <sup id="fnref-2"><a href="#fn-2" class="footnote-ref">2</a></sup>里就提到一个数据就是说目前主流应用AI编程的公司，其工作量100个小时有80个小时都花在AI编码后的验证和确认上。</p><p>问题在哪儿呢？</p><ul><li><strong>金鱼记忆</strong>：上下文窗口的诅咒<br/>  大语言模型在长上下文中的注意力衰减问题。简单来说就是AI的记忆力非常有限。 就跟鱼一样只有7秒的记忆。 注意，这不是说他能力不行，相反能力是很强大的。怎么说呢，就像是一条鲸鱼，随便拍拍尾巴就能掀起巨浪，但他的记忆就只有7秒。 他能一下子把人拍飞，也百分百听你的话，但你让他干点复杂的事情，不好意思，拍一下能解决的他能干的很好，拍两下能解决的他能弄得鸡飞狗跳， 拍第二下的时候忘了第一下，连目标都可能丢失了，还顺带造成附加损伤。</li><li><strong>代码瘟疫</strong>：训练数据的技术债传染<br/>  AI模型在训练过程中需要大量的数据训练，比如说来自github的代码库。问题是不是所有的代码都是大师级别的规范设计的，就是经过筛选，也难免其中混杂一些奇怪的思路和做法，这些都会在训练过程中被AI吸收，然后在某个不知道什么时机的点传播到生成结果中。如果仅仅是思路和逻辑弱一点倒也罢了，但如果是存在严重的安全隐患和漏洞，那后果就麻烦了。</li><li><strong>沟通深渊</strong>：听话的AI是好AI么?<br/>  AI编码能力是从程序员学来的，当然毛病也有点一样，就是都喜欢写新的代码，不愿意修改现有代码。AI编码在修改现有代码时，尤其容易出现顾此失彼的问题。并且当开发者给出指示后，AI很大部分程度上是对指示100%遵循的。包括你对他说这块颜色不对要黑色中带点五彩斑斓的感觉。或者是这块能不能让他调小一些，但是内容显示的更大。这些要求如果是对人当面沟通，多半就会掀桌子。但AI仍会回复你说：你说的有道理，我立刻按你的要求来改， 然后大肆发挥，你就等着看结果就行，反正你要对结果负责，AI不对结果负责。</li></ul><h2>命令行架构模式, 四十年前的解药</h2><p>针对AI编码的问题和根源，不难发现，古老的命令行Pipeline架构正恰恰好弥补了AI编码的短板。</p><p>命令行Pipeline架构是一种非常实用的古老的软件设计架构。他是如此的简洁、清晰，以至于并没有人为他专门定义过什么理论或者专有名词（我印象中是没有的）。这里我称呼为命令行Pipeline架构，可能不大准，但意思是没问题的。</p><p>命令行Pipeline架构的核心思想是 <strong>一个工具只做一件事，然后遵循标准的输入和输出</strong>。在命令行环境中，多个工具通过管道(|)符号串联，形成一个工作流。前一个工具的标准输出成为下一个工具的标准输入，数据在进程间通过内存缓冲区传递，无需落地为临时文件。</p><p><strong>命令行Pipeline架构的核心优势在于其清晰的定义、简单的结构和各步骤间的低耦合性。这种架构直接对抗了AI编程腐烂的三大根源：</strong></p><ul><li><strong>进程隔离</strong>：让AI编码只敢简单的同时逻辑性强的事<br/>  命令行Pipeline将整个任务拆分为多个独立进程，每个进程专注于单一功能。这种设计使得AI生成的代码即使存在缺陷，也不会污染整个工作流。例如，如果数据清洗步骤中的AI生成代码出现错误，后续的特征工程步骤将不会受到影响，开发者可以快速定位问题并进行修复。 同时最核心的一点，就是拆分成的<strong>子任务（独立程序）通常是用途单一且明确的，而且范围也不大</strong>，其复杂度还可以控制在刚好能在AI腐烂前能解决。这样子AI能一次或简单的几次迭代就能搞定，质量还高。</li><li><strong>标准IO协议</strong>：用最常见最普通的规则代替混乱<br/>  命令行Pipeline强制使用标准输入输出进行数据传递，减少了硬编码和隐式依赖。完全一致的输入输出处理，而且也都是很成熟简单的参数传递机制，使得AI无需额外的过多约束规格定义就能很好的满足整体架构设计的的代码。有点像遵循Restful规范，逻辑上似乎意义不大，但在整体架构上，能提供简单清晰一致的理解和思路，从而简化问题，避免一碗面条式的逻辑。例如，在数据预处理阶段，AI生成的代码必须将处理后的数据输出到标准输出，而后续步骤只需读取标准输入，无需关心具体实现细节。</li><li><strong>组合起来威力无边</strong>：最为重要的是，每个子任务（独立程序）都可以独立运行，单独工作，简单的测试和验证，独立升级维护。 这使得系统的开发调试运行维护都极为简便，同时组合起来功能强大。</li></ul><p>命令行模式是所有模式中难得见到的可以将系统实现简化，操作简化，但是功能却超越预设的强大的一种。所有的按部就班设计的系统，最好的结果就是按照设计的工作。 而命令行模式的各种组合，其形式几乎可以是无穷无尽的。</p><p>由于每个子任务（独立程序）都可以单独运行并完整的完成自己的任务，因此多个子任务可以任意的前后组合起来，形成复杂的工作流。 而这一步，只需要简单的shell,bash, cmd脚本批处理就可以做到了。</p><p>假设你有10个可独立运行的子任务，一个5层的工作流，理论上来说，就有100000种不同的使用场景。而unix/linux,mac,windows/dos的命令行，通常只有几十到百来个命令。 而这些命令的组合，基本就能满足日常整个操作系统维护的需求。</p><p>所以依靠命令行pipeline架构的简单设计，就能实现非常庞大复杂的系统能力。 这是一种化繁为简的神兵利器。</p><h2>命令行架构在AI编程中的实践</h2><p>命令行架构这么强大，那么，要到哪里才能买...啊不对，要怎么才能用起来呢？</p><p>首先，顾名思义，命令行架构，如果你的系统是后端的，不需要UI界面的，基本都可以直接套用。而且思路和设计也极为简单，就是将整个大的系统，尽可能的拆分成可以独立运行的子任务（子系统）。拆的越细越好，越多越好。 每个子任务（子系统）因为是独立运行，因此也可以独立设计，独立开发，如果是多人协作的话，还可以分给不同的人，甚至是外包。</p><p>当然这些的前提是子任务的功能足够的清晰，明确，单一；所以要拆的足够的细。举例来说，文件操作很多，也很复杂。单个子任务来维护文件操作就过于庞大了，就可以继续拆分。像是 stat命令，就只做一件事情，返回文件的修改时间访问时间创建时间等几个属性。</p><p>基本上，只要能拆到这么细的程度，整个系统架构就算是完成了。</p><p>拆的足够细是保证系统能够非常简单的构建。 但要做到想命令行架构一样的强大的组合能力，还需要遵循标准输入输出模式。 这样子才可以将任意的子任务任意的组合起来，形成复杂的工作流。</p><p>这里举个简单的例子：</p><blockquote><blockquote>在某电商平台的用户数据分析项目中，开发团队采用了命令行Pipeline架构来处理海量用户数据。整个管道包含数据采集、清洗、特征工程、验证和存储五个步骤：</blockquote></blockquote><pre><code class="bash">python collect_data.py --start_date 2025-01-01 | python clean_data.py | python extract_features.py | python validate_features.py | python store_data.py</code></pre><p>上面的例子是最简单的直接输入输出重定向，管道串联的例子。 实际使用上，还可以借助shell bash或cmd bat的脚本批处理做粘合剂，实现条件判断，流程跳转，函数调用等等复杂的逻辑。</p><p>那是不是仅仅只有后台无界面应用才适合命令行架构模式呢？ </p><p>也不是的。即便是UI界面丰富的应用，一些情况下也是可以采用或部分采用命令行架构模式的。</p><p>在经典的设计模式中，就有一种命令模式的，它的基本思想是将请求封装成一个对象，从而使你可以用不同的请求对客户进行参数化，对请求排队或记录请求日志，以及支持可撤销的操作。 其思路也是跟命令行架构非常相似的。每个菜单项单独配置一个Action，每个Action都可以独立运行和测试。</p><p>另一种思路也是部分软件系统在采用的，就是将整个系统都设计成后端服务模式，一些必要的UI界面功能，单独通过提供一个网页的形式来操作。 这样子不仅简化了实现，UI界面的调整也变得非常简单。</p><p>还有哪些可以应用命令行架构模式的场景呢？欢迎各位分析师来分享和补充。</p><p>::: {#author name=reddish}<br/><em>本文同步发表在 <a href="https://link.segmentfault.com/?enc=fv6TZXytW0Ys9SV3TnMTCg%3D%3D.NHcHfxsEdAtQVnaEFCTGRw%3D%3D" rel="nofollow" target="_blank">软件需求探索</a>的<a href="https://link.segmentfault.com/?enc=Dk4mlD6bCsLdhTw%2F7QhpkA%3D%3D.YT4MRkbSuM2Upki91JprlkYsJ1CAz7JNN1MbIXLzL1JEjfGEk5%2F%2F8Ep9cURO61s55qq7gfg7ctkXvptCNhin%2B4VZp3wKT5UI5tqYZQqwilY%3D" rel="nofollow" target="_blank">https://srs.pub/thinking/commandline-is-the-best-architecture...</a></em></p><p><em>作者: <a href="mailto:reddish@srs.pub" target="_blank">reddish@srs.pub</a></em><br/>:::</p><div class="footnotes"><hr/><ol><li id="fn-1"> 商业分析中的五十种分析方法和技巧之40-根本原因分析.  <a href="https://link.segmentfault.com/?enc=YOsxbOEjE35W7foQfmKMQQ%3D%3D.Z0mFEHi8aAkNB3OfvLUIeixNvTPFDB3CqSVxN8XEd1QJg8V7Knh1bUGqozsQ%2BWWHhppVlFxDOIk%2BDw2KdMLUEHf3uZNF%2B%2BLvw2xou1H0LMJ%2BjMqkzgbf3%2BlSXWsbLQ5o" rel="nofollow" target="_blank">https://srs.pub/babok/genbenyuanyin-fenxi.htmlahref=#fnref-1c...</a></li><li id="fn-2"> 商业分析中的五十种分析方法和技巧之25-访谈.  <a href="https://link.segmentfault.com/?enc=mPIZuVvX2l7zIeU2sWq0WQ%3D%3D.b4yV8w2fYc06jk0OAQ5ipO2jvvKWyEvzzkBG50GV%2BPBQc9wMM0Smo6B4DCxJdW1kGJPkr7qNSLUDJngvb9AEhzjgPSUC08Gdg3NT8oQSoAk%3D" rel="nofollow" target="_blank">https://srs.pub/babok/fangtan.htmlahref=#fnref-2class=footnot...</a></li></ol></div>]]></description></item><item>    <title><![CDATA[剑指offer-53、表达数值的字符串 SevenCoding ]]></title>    <link>https://segmentfault.com/a/1190000047490390</link>    <guid>https://segmentfault.com/a/1190000047490390</guid>    <pubDate>2025-12-23 09:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>题⽬描述</h2><p>请实现⼀个函数⽤来判断字符串str是否表示数值（包括科学计数法的数字，⼩数和整数）。科学计数法的数字(按顺序）可以分成以下⼏个部分:</p><ol><li>若⼲空格</li><li>⼀个整数或者⼩数</li><li>（可选）⼀个 ' e ' 或 ' E ' ，后⾯跟着⼀个整数(可正可负)</li><li>若⼲空格</li></ol><p>⼩数（按顺序）可以分成以下⼏个部分：</p><ol><li>若⼲空格</li><li>（可选）⼀个符号字符（'+' 或 '-'）</li><li><p>可能是以下描述格式之⼀:</p><ol><li>⾄少⼀位数字，后⾯跟着⼀个点 '.'</li><li>⾄少⼀位数字，后⾯跟着⼀个点 '.' ，后⾯再跟着⾄少⼀位数字</li><li>⼀个点 '.' ，后⾯跟着⾄少⼀位数字</li></ol></li><li>若⼲空格</li></ol><p>整数（按顺序）可以分成以下⼏个部分：</p><ol><li>若⼲空格</li><li>（可选）⼀个符号字符（' + ' 或 ' - ')</li><li>⾄少⼀位数字</li><li>若⼲空格</li></ol><p>例如，字符串["+100","5e2","-123","3.1416","-1E-16"] 都表示数值。</p><p>但是["12e","1a3.14","1.2.3","+-5","12e+4.3"] 都不是数值。</p><p>提示:</p><ol><li>1 &lt;= str.length &lt;= 25</li><li>str 仅含英⽂字⺟（⼤写和⼩写），数字（0-9），加号 '+' ，减号 '-' ，空格 ' ' 或者点 '.' 。</li><li>如果怀疑⽤例是不是能表示为数值的，可以使⽤python 的print(float(str)) 去查看</li></ol><p>示例1<br/>输⼊："123.45e+6"<br/>返回值：true</p><p>示例2<br/>输⼊："1.2.3"<br/>返回值：false</p><h2>思路及解答</h2><h3>暴力分析拆解</h3><p>主要是分析好判断分⽀，可以定义⼏个变量：</p><ul><li>hashNum : 是否已经有数字</li><li>hashE ：是否已经有E</li><li>hasSign ：是否已经有符号</li><li>hasDot ：是否已经有⼩数点</li></ul><p>⾸先，初始化当前的索引index =0 ，字符串头部的空格需要跳过。</p><ul><li><p>循环判断索引是否在有效的范围内：</p><ul><li>循环判断是否是数字，是数字则更新hasNum = true ,并且索引后移，直到不是数字的时候，跳出循环。</li></ul></li><li>跳出循环后，需要判断当前的index 是否合法，不合法直接break</li><li><p>取出当前索引的字符c ：</p><ul><li><p>如果c 是e 或者E ：</p><ul><li>如果前⾯已经出现过E ，或者前⾯没有数字，直接返回false</li><li>否则， hasE 置为true ，其他的置为false ，也就是E后⾯可以继续出现符号数字和⼩数点了</li></ul></li><li><p>如果c 是“ + ”或者“ - ”：</p><ul><li>前⾯如果已经出现过数字或者符号或者⼩数点，都不是合法的</li><li>否则hasSign 置为true ，表示符号出现过</li></ul></li><li><p>如果c 是⼩数点“ . ”</p><ul><li>如果前⾯已经有⼩数点或者有E出现了，那么就是⾮法的，返回false</li><li>否则hasDot 置为true</li></ul></li><li>如果c 为空格，直接跳出循环</li><li>否则，直接返回false</li></ul></li><li>最后也需要跳过空格</li><li>最后判断是否合法的条件是：是否到达最后⼀个字符，并且出现过数字</li></ul><pre><code class="java">public boolean isNumeric(String str) {
    int size = str.length();
    int index= 0 ;
    // 默认全部是false
    boolean hashNum=false ,hasE=false ,hasSign=false ,hasDot=false;
    // 跳过空格
    while(index&lt;size&amp;&amp;str.charAt(index)==' '){
        index++;
    }
    
    while(index&lt;size){
        while(index&lt;size&amp;&amp;str.charAt(index)&gt;='0'&amp;&amp; str.charAt(index)&lt;='9'){
            index++;
            // 表示前⾯有数字
            hashNum = true;
        }
- 
        // 到末尾直接跳出
        if(index==size){
            break;
        }
- 
        char c = str.charAt(index);
        if(c=='e'||c=='E'){
            // 前⾯有E或者没有数字在前⾯
            if(hasE||!hashNum){
                return false;
            }
            hasE = true;
            // 出现E了后⾯⼜可以出现数字了
            hashNum = false;
            hasSign = false;
            hasDot = false;
        }else if(c=='+'||c=='-'){
            if(hasSign||hashNum||hasDot){
                return false;
            }
            hasSign = true;
        }else if(c=='.'){
            if(hasDot||hasE){
                return false;
            }
            hasDot =true;
        }else if(c==' '){
            break;
        }else{
            return false;
        }
        index++;
    }
    // 跳过空格
    while(index&lt;size&amp;&amp;str.charAt(index)==' '){
        index++;
    }
    return hashNum &amp;&amp;index==size;
}</code></pre><p>这道题，其实本质是状态的切换，最最重要的⼀点，是 E 出现之后，其实⼩数点和符号，和数字，都是可以再出现的，可以理解为 E 就是⼀个分割线。</p><h3>正则表达式</h3><p>直接借助正则表达式进⾏匹配，但是并不太推荐这种解法：</p><pre><code class="java">public class Solution {

    public boolean isNumeric (String str) {
        // 核心正则表达式：处理空格、符号、小数、指数部分
        
        // ^表示开头 $ 表示结尾 java中两个\\ 代表⼀个\
        // \\s*开头可能有空格
        // * 零次或多次匹配前⾯的字符或⼦表达式
        // ？零次或⼀次匹配前⾯的字符或⼦表达式
        // + ⼀次或多次匹配前⾯的字符或⼦表达式
        // [] 字符集。匹配包含的任⼀字符
        // (:? )匹配 pattern 但不捕获该匹配的⼦表达式，即它是⼀个⾮捕获匹配
        String p = "^\\s*[+-]?(\\d*\\.\\d+|\\d+(\\.\\d*)?)(?:[eE][+-]?\\d+)?$";
        return Pattern.matches(p,str);
    }
}</code></pre><ul><li>O(n)时间复杂度</li><li>O(1)空间复杂度</li></ul><h3>有限状态机</h3><p>使用确定有限状态机(DFA)来精确建模数值的判断过程。</p><p>有限状态机法：通过状态转移精确控制数值格式。定义9种状态，根据输入字符进行状态转移</p><pre><code class="java">public boolean isNumberDFA(String str) {
    if (str == null) return false;
    
    // 状态定义：0-8共9种状态
    // 0: 起始空格 1: 符号 2: 整数数字 3: 小数点前无数字 
    // 4: 小数点后有数字 5: 指数e 6: 指数符号 7: 指数数字 8: 结尾空格
    int state = 0; // 初始状态
    
    // 状态转移表
    int[][] transitionTable = {
        // 空格 符号 数字 小数点 e/E 其他
        {0,   1,   2,   3,   -1, -1}, // 状态0: 起始空格
        {-1, -1,   2,   3,   -1, -1}, // 状态1: 符号
        {8,  -1,   2,   4,    5, -1}, // 状态2: 整数数字
        {-1, -1,   4,   -1,  -1, -1}, // 状态3: 小数点前无数字
        {8,  -1,   4,   -1,   5, -1}, // 状态4: 小数点后有数字
        {-1,  6,   7,   -1,  -1, -1}, // 状态5: 指数e
        {-1, -1,   7,   -1,  -1, -1}, // 状态6: 指数符号
        {8,  -1,   7,   -1,  -1, -1}, // 状态7: 指数数字
        {8,  -1,  -1,   -1,  -1, -1}  // 状态8: 结尾空格
    };
    
    for (char c : str.toCharArray()) {
        int inputType = getInputType(c);
        if (inputType == -1) return false;
        
        state = transitionTable[state][inputType];
        if (state == -1) return false;
    }
    
    // 可接受的状态：数字相关状态(2,4,7,8)
    return state == 2 || state == 4 || state == 7 || state == 8;
}

// 将字符分类为状态机输入类型
private int getInputType(char c) {
    switch (c) {
        case ' ': return 0; // 空格
        case '+': case '-': return 1; // 符号
        case '0': case '1': case '2': case '3': case '4': 
        case '5': case '6': case '7': case '8': case '9': 
            return 2; // 数字
        case '.': return 3; // 小数点
        case 'e': case 'E': return 4; // 指数符号
        default: return 5; // 其他字符
    }
}</code></pre><ul><li>时间复杂度：O(n)</li><li>空间复杂度：O(1)</li></ul>]]></description></item><item>    <title><![CDATA[ChatGPT可手动"调温"、谷歌推出 A2UI 标准、通义千问推出 Qwen-Image-Laye]]></title>    <link>https://segmentfault.com/a/1190000047494857</link>    <guid>https://segmentfault.com/a/1190000047494857</guid>    <pubDate>2025-12-23 00:04:02</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h3>ChatGPT可手动"调温"了！OpenAI上线热情度滑块，用户可自定义AI的"情绪浓度"</h3><p>OpenAI公司最近推出了一项非常有趣的新功能，允许用户通过热情度滑块来调节ChatGPT的"情绪浓度"。这项创新让用户可以根据不同场景和需求，自定义AI的响应风格，从专业严谨到活泼热情，实现真正个性化的AI交互体验。</p><p><strong>核心事件</strong>：OpenAI为ChatGPT增加了情感调节功能，用户可以控制AI的响应风格和情绪表达强度。</p><p><strong>技术细节</strong>：这一功能可能基于温度参数调整、提示词微调或者专门的微调模型，通过算法实现对AI输出风格的精确控制。用户不再只能接受预设的AI性格，而是可以根据具体需求调整AI的"热情度"，使得AI助手在不同场合下表现出合适的交互风格。</p><p><strong>行业影响</strong>：这一创新为AI对话系统提供了更丰富的交互维度，对开发者来说意味着更多API选择和更强大的功能。未来，我们可以期待更多类似的情感调节功能在各类AI产品中出现，这将提升用户体验，尤其是在客户服务、教育和娱乐等场景中。</p><p><strong>商业意义</strong>：OpenAI通过这一功能进一步增强了ChatGPT的差异化竞争力，满足了用户对个性化AI助手的需求，可能吸引更多付费用户。</p><h3>谷歌推出 A2UI 标准，让 AI 实时生成用户界面</h3><p>谷歌最近发布了A2UI标准（AI-to-User Interface），这是一项革命性的技术标准，允许AI实时生成用户界面。该标准将彻底改变传统的UI开发流程，设计师和开发者只需描述需求，AI即可实时生成相应的用户界面，极大地提升了开发效率。</p><p><strong>核心事件</strong>：谷歌推出的A2UI标准允许AI根据自然语言描述实时生成用户界面，这代表了UI开发范式的根本性变革。</p><p><strong>技术细节</strong>：A2UI标准整合了先进的多模态AI模型，能够理解设计需求的自然语言描述，并将其转换为具体的UI元素、布局和交互逻辑。通过这一标准，AI可以理解设计意图，生成符合现代设计规范的界面，并支持实时预览和迭代。</p><p><strong>行业影响</strong>：这一标准的推出将对整个UI/UX行业产生深远影响。前端开发者需要适应AI辅助的UI设计方式，而设计师可以将更多精力投入到创意和用户体验策略上，而非具体的实现细节。对开发者来说，这意味着开发流程的简化和效率的提升。</p><p><strong>商业意义</strong>：谷歌通过A2UI标准巩固了其在AI领域的领先地位，同时也为开发者提供了新的工具和工作流程，可能加速Web应用的开发速度和创新步伐。</p><h3>通义千问推出 Qwen-Image-Layered 模型，实现图片 "分层编辑" 突破</h3><p>阿里巴巴通义实验室发布了Qwen-Image-Layered模型，这一创新性技术实现了图片的"分层编辑"功能。与传统图像编辑方法不同，该模型能够将图像分离成多个图层，允许用户对图像的不同部分进行独立编辑，极大提升了图像编辑的灵活性和精确度。</p><p><strong>核心事件</strong>：通义千问团队发布了Qwen-Image-Layered模型，实现了AI驱动的图像分层编辑功能。</p><p><strong>技术细节</strong>：该模型采用先进的计算机视觉和深度学习技术，能够智能识别图像中的不同对象和区域，并将其分离成独立的图层。用户可以单独编辑每个图层的属性，如颜色、纹理、位置等，而不会影响其他部分。这种技术基于对图像语义内容的理解，实现了更加自然和精确的编辑。</p><p><strong>行业影响</strong>：图像分层编辑技术的突破，将为设计师、内容创作者和开发者提供更强大的工具。对AI开发者而言，这一技术展示了多模态模型在图像理解与编辑方面的巨大潜力，为未来图像生成和编辑模型的发展指明了方向。</p><p><strong>商业意义</strong>：阿里巴巴通过这一技术创新进一步巩固了在AI图像处理领域的地位，可能吸引更多设计师和内容创作者使用其AI服务，推动相关云服务的收入增长。</p><h3>谷歌 Chrome 迎重大 AI 更新：搜索框功能"大换血"，跨标签页协同成亮点</h3><p>谷歌Chrome浏览器迎来了一次重大的AI功能更新，搜索框功能进行了全面革新，实现了跨标签页协同操作。用户可以利用AI助手在多个标签页之间进行信息整合和任务协同，提升浏览效率。</p><p><strong>核心事件</strong>：Chrome浏览器引入了AI助手，实现跨标签页的信息整合和任务协同功能。</p><p><strong>技术细节</strong>：这一更新利用了大型语言模型的上下文理解能力，AI助手可以分析用户打开的多个标签页内容，并根据用户需求进行信息提取、比较和整合。通过自然语言指令，用户可以要求浏览器在不同标签页间执行任务，如"比较这三个产品价格"或"总结这三篇文章的主要观点"。</p><p><strong>行业影响</strong>：这体现了浏览器厂商对AI集成的深度探索，对前端开发者来说，意味着浏览器功能的扩展和新的API机会。浏览器不再只是内容展示工具，而是逐渐成为智能化的信息处理平台。</p><p><strong>商业意义</strong>：谷歌通过增强Chrome的AI功能，进一步巩固了其在浏览器市场的主导地位，同时为AI服务创造了更多使用场景。</p><h3>"股票"登顶千问App十大AI提示词榜首:AI成全民"理财顾问"</h3><p>最新数据显示，"股票"相关提示词已跃居通义千问App十大热门AI提示词榜首，这反映出AI在金融理财领域的应用正受到广泛关注。AI正逐渐成为普通用户的"理财顾问"，通过分析市场数据、提供投资建议等方式，降低金融投资的门槛。</p><p><strong>核心事件</strong>：AI金融咨询功能成为用户最常使用的AI应用之一，"股票"相关查询在AI助手使用中占据重要位置。</p><p><strong>技术细节</strong>：AI理财顾问功能整合了自然语言处理、数据分析和金融知识，能够理解用户的金融问题，提供市场趋势分析、投资建议和风险评估。这些功能基于对大量金融数据和市场信息的分析，结合机器学习算法，为用户提供个性化的理财建议。</p><p><strong>行业影响</strong>：AI理财顾问的普及降低了金融投资的门槛，让更多普通用户能够获得专业的金融分析和建议。对金融科技开发者来说，这代表了一个快速增长的应用领域，需要关注合规性和准确性要求。</p><p><strong>商业意义</strong>：AI理财功能的普及为金融科技公司和AI平台提供了新的商业模式，通过AI服务获取更多用户并创造收入。</p><h3>Claude Chrome插件正式全量开放！付费用户瞬间拥有AI浏览器助手</h3><p>Anthropic的Claude Chrome插件现已向所有付费用户开放，为浏览器用户提供了强大的AI助手功能。用户可以直接在浏览器中与Claude交互，实现研究、写作、信息整理等多种任务。</p><p><strong>核心事件</strong>：Claude浏览器插件正式全面开放，为用户提供便捷的AI辅助浏览体验。</p><p><strong>技术细节</strong>：该插件集成了Claude强大的语言理解能力，可以直接分析当前页面内容，回答用户问题，提供摘要或执行其他任务。插件采用轻量级架构，确保在浏览器中运行时的性能和响应速度。</p><p><strong>行业影响</strong>：AI浏览器助手的普及改变了用户与网页内容的交互方式，开发者需要考虑如何优化网页内容以更好地与AI助手协作。</p><p><strong>商业意义</strong>：这一功能增强了Claude产品的用户粘性，通过浏览器插件为AI服务创造了更多使用场景。</p><h3>告别电量焦虑与沉重感:夸克 AI 眼镜 G1新品开启预售，轻至40g 且支持换电</h3><p>阿里巴巴旗下的夸克AI眼镜G1新品开启预售，这款眼镜重量仅有40克，还支持换电功能，解决了智能眼镜的续航问题。轻便的设计和创新的换电方案，为智能眼镜的普及扫清了部分障碍。</p><p><strong>核心事件</strong>：夸克AI眼镜G1以超轻重量和换电设计解决了智能眼镜的续航和便携性问题。</p><p><strong>技术细节</strong>：G1眼镜采用了轻量化材料和紧凑设计，重量控制在40克以内，同时引入了创新的换电模块，用户可以快速更换电池，延长使用时间。眼镜集成了AI处理单元，支持语音交互、AR显示等功能。</p><p><strong>行业影响</strong>：轻量化和换电设计为智能眼镜行业树立了新标准，推动了可穿戴设备的实用性提升。对硬件开发者而言，这一设计展示了在有限空间内平衡性能、重量和续航的技术路径。</p><p><strong>商业意义</strong>：夸克通过G1眼镜进入快速增长的可穿戴设备市场，结合AI功能，有望在智能眼镜领域建立先发优势。</p><h3>苹果携手普渡大学研发 DarkDiff 技术:即使在极暗环境下也能拍出"夜视仪"级大片</h3><p>苹果公司与普渡大学合作研发了DarkDiff技术，这项技术即使在极暗环境下也能拍摄出高质量照片，效果堪比"夜视仪"。这项技术可能将应用于未来的iPhone相机功能中。</p><p><strong>核心事件</strong>：苹果与普渡大学合作开发的DarkDiff技术，实现了极暗环境下的高质量图像拍摄。</p><p><strong>技术细节</strong>：DarkDiff技术可能基于扩散模型（Diffusion Model）的改进算法，能够从极低光图像中恢复细节，生成高质量的明亮图像。该技术通过AI模型学习如何在保持图像自然性的同时，提升暗部细节和整体亮度。</p><p><strong>行业影响</strong>：这一技术突破将提升移动设备的摄影能力，对手机制造商来说，这是一个重要的差异化功能。对AI图像处理开发者而言，这展示了扩散模型在低光图像增强方面的巨大潜力。</p><p><strong>商业意义</strong>：苹果通过这一技术优势增强了iPhone的摄影卖点，可能在竞争激烈的高端手机市场获得更多优势。</p><h3>生成式 AI 席卷游戏圈:Steam 热销榜前十竟有一半出自"AI 拥护者"之手</h3><p>生成式AI技术正在游戏行业中掀起波澜，最新数据显示，Steam热销榜前十名中竟有一半是由"AI拥护者"开发的游戏。这表明AI生成内容技术在游戏开发中的应用已开始获得市场认可。</p><p><strong>核心事件</strong>：AI辅助开发的游戏在Steam市场上取得显著成功，反映了AI技术在游戏产业中的实际应用价值。</p><p><strong>技术细节</strong>：这些游戏可能使用了AI生成内容（AIGC）技术，包括AI生成的图像、文本、音效或程序代码。AI技术帮助独立开发者以较低成本创建高质量的游戏内容，加速了游戏开发流程。</p><p><strong>行业影响</strong>：AI在游戏开发中的成功应用降低了游戏制作门槛，让更多独立开发者能够创建高质量游戏。这对游戏开发行业来说，意味着开发模式的变革和更多创新游戏的出现。</p><p><strong>商业意义</strong>：AI游戏的成功证明了AIGC技术的商业价值，鼓励更多开发者采用AI工具进行游戏开发，推动了整个游戏产业的AI化进程。</p><h3>AI绘画提示词新利器：PromptFill上线！让复杂Prompt像填空题一样简单</h3><p>AI绘画工具PromptFill上线，它将复杂的提示词生成过程简化为填空题形式，让普通用户也能轻松创建高质量的AI绘画提示词。这一工具降低了AI艺术创作的门槛。</p><p><strong>核心事件</strong>：PromptFill推出简化版提示词生成工具，通过模板化方式降低AI艺术创作难度。</p><p><strong>技术细节</strong>：该工具可能使用了自然语言理解模型来解析用户意图，并将其转换为有效的AI绘画提示词。通过分类和预设模板，用户只需填写关键信息即可生成高质量的提示词。</p><p><strong>行业影响</strong>：这一工具进一步降低了AI艺术创作的门槛，让更多非技术用户能够使用AI绘画工具。对AI艺术工具开发者而言，这展示了用户界面创新的重要性。</p><p><strong>商业意义</strong>：通过简化用户体验，PromptFill有望吸引更多用户使用AI艺术创作工具，推动相关市场的增长。</p><h3>Meta 智能眼镜重大更新:AI 助听功能上线，还能根据眼前的风景点歌</h3><p>Meta的智能眼镜迎来重大更新，新增了AI助听功能，还能根据用户眼前的风景智能推荐音乐。这种多模态AI应用展示了智能穿戴设备的未来发展方向。</p><p><strong>核心事件</strong>：Meta智能眼镜增加了AI助听和场景音乐推荐功能，实现了多模态AI应用。</p><p><strong>技术细节</strong>：这一功能整合了计算机视觉、音频处理和音频增强技术，能够实时分析周围环境，为听力障碍用户提供增强音频体验，同时根据场景推荐合适的音乐。</p><p><strong>行业影响</strong>：多模态AI应用展示了智能设备的未来发展方向，对可穿戴设备开发者来说，这是一个重要的技术演进方向。</p><p><strong>商业意义</strong>：通过增加实用的AI功能，Meta提升了智能眼镜的价值和用户粘性。</p><h3>AI"自动运维工程师"Resolve AI获Lightspeed领投A轮融资</h3><p>AI运维公司Resolve AI获得了Lightspeed的A轮融资，其AI自动运维工程师能够自主发现、诊断和修复IT系统中的问题，代表了IT运维自动化的新趋势。</p><p><strong>核心事件</strong>：Resolve AI的自主运维技术获得资本认可，标志着AI在IT运维领域的重要进展。</p><p><strong>技术细节</strong>：该AI运维系统可能基于机器学习算法，能够监控IT系统状态，自动识别异常，分析问题根源，并执行修复操作，实现真正的无人化运维。</p><p><strong>行业影响</strong>：AI自主运维将显著提升IT运维效率，减少人为错误，对IT运维从业者来说，需要适应新的工作模式。</p><p><strong>商业意义</strong>：这一领域获得了资本关注，预示着AI运维市场的巨大潜力。</p><h2>语音聊26分钟，80%用户成功约会！AI约会新贵Known获970万美元融资</h2><p>AI约会应用Known凭借其独特的语音交互功能获得了970万美元融资。该应用通过26分钟的语音聊天，成功率达80%，展示了AI在社交领域的创新应用。</p><p><strong>核心事件</strong>：Known AI约会应用通过语音AI匹配取得高成功率，获得资本认可。</p><p><strong>技术细节</strong>：该应用可能使用了语音识别、情感分析和匹配算法，通过分析用户语音中的情感、语调和内容来实现更精准的匹配。</p><p><strong>行业影响</strong>：AI在社交领域的应用展示了其在理解人类情感和社交需求方面的潜力。</p><p><strong>商业意义</strong>：这一成功案例为AI在社交应用领域开辟了新的商业模式。</p><h3>多智能体可信标准在ITU立项：信通院、蚂蚁、中国电信等共同推动</h3><p>由信通院、蚂蚁集团和中国电信等机构共同推动，多智能体可信标准在国际电信联盟(ITU)成功立项。这一标准将为多智能体系统的可信性提供国际规范，推动AI系统的安全可靠发展。</p><p><strong>核心事件</strong>：多智能体可信标准在ITU成功立项，标志着中国在AI国际标准制定中的重要贡献。</p><p><strong>技术细节</strong>：该标准将涉及多智能体系统的安全性、可靠性、可解释性和公平性等可信性指标。</p><p><strong>行业影响</strong>：标准化工作为AI技术的健康发展提供了基础，对AI开发者来说，需要关注并遵循相关标准。</p><p><strong>商业意义</strong>：标准的制定有助于建立可信赖的AI生态系统，促进AI技术的广泛应用。</p><hr/><p>你对今天的哪个新闻最感兴趣？欢迎在评论区分享你的看法。关注我，每天获取最新的AI行业动态。</p><p>📌 <strong>关注我，第一时间掌握更多AI前沿资讯！</strong></p>]]></description></item><item>    <title><![CDATA[专用蚊子苍蝇检测数据集（含背景样本）：适用于目标检测任务 逐梦AI ]]></title>    <link>https://segmentfault.com/a/1190000047494875</link>    <guid>https://segmentfault.com/a/1190000047494875</guid>    <pubDate>2025-12-23 00:03:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>专用蚊子苍蝇检测数据集（含背景样本）：适用于目标检测任务</h2><h3>一、背景</h3><p>随着城市化进程的加快和气候环境的变化，蚊子、苍蝇等害虫在居民生活、公共卫生以及工业场景中造成的问题日益突出。它们不仅影响生活环境质量，还可能传播多种疾病，对公共健康构成威胁。</p><p>传统的蚊虫监测方式大多依赖人工观察或简单的诱捕统计方法，存在 <strong>效率低、实时性差、误判率高</strong> 等问题。随着计算机视觉和深度学习技术的发展，<strong>基于目标检测的蚊子、苍蝇智能识别系统</strong> 成为一种高效、可扩展的解决方案。</p><p>然而，在实际工程落地中，模型效果的好坏往往不取决于算法本身，而是 <strong>数据集质量</strong>。因此，一个 <strong>标注规范、类别清晰、包含真实背景干扰样本的数据集</strong>，是构建高精度蚊虫检测系统的核心基础。</p><p>本文将详细介绍一套 <strong>专用蚊子苍蝇检测数据集（含背景样本）</strong>，并结合 YOLOv8 模型，探讨其在真实目标检测任务中的价值与应用。</p><hr/><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047494877" alt="在这里插入图片描述" title="在这里插入图片描述"/></p><h3>二、数据集概述</h3><p>本数据集是一个 <strong>面向目标检测任务的专业级蚊子/苍蝇数据集</strong>，专门为 <strong>YOLO 系列模型（尤其是 YOLOv8）</strong> 设计，适用于科研实验与工程实践。</p><h3>数据集下载</h3><blockquote>链接:<a href="https://link.segmentfault.com/?enc=vNFHs8k%2Bhq4fg7fLjhPkug%3D%3D.F5Z2xNfar5ucFGR0uTMoNr5GhqlBa9sNUFYdxtjDbuY%2BTRRq4LJ64nSZHLgcGSCon2b449UJE7YdQQ8RcnhObA%3D%3D" rel="nofollow" target="_blank">https://pan.baidu.com/s/1nIqYq6bvYjB-piufPKOP1w?pwd=dcar </a><br/>提取码:dcar 复制这段内容后打开百度网盘手机App，操作更方便哦</blockquote><p>专用蚊子苍蝇检测数据集（含背景样本）</p><p>蚊子和苍蝇数据集包含 1400 多张图片和 1400 多个 yolo 格式的 txt 文件。其中 600 多张是蚊子，600 多张是苍蝇，还有 200 多张用于背景。<br/>该数据集用于基于 yolov8 模型的苍蝇蚊子检测系统。</p><p>训练集图片数量: 576<br/>验证集图片数量: 145</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047494878" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h4>数据集核心特点</h4><ul><li>🦟 <strong>蚊子样本</strong>：600+ 张</li><li>🪰 <strong>苍蝇样本</strong>：600+ 张</li><li>🌿 <strong>背景样本</strong>：200+ 张（无目标或复杂干扰）</li><li>📦 <strong>总图片数量</strong>：1500 张（已划分）</li><li>📝 <strong>标注格式</strong>：YOLO 标准格式（<code>.txt</code>）</li><li>🎯 <strong>任务类型</strong>：目标检测（Object Detection）</li><li>🚀 <strong>适配模型</strong>：YOLOv8 / YOLOv5 / YOLOv7 等</li></ul><p>通过引入 <strong>背景样本（Negative Samples）</strong>，数据集在真实环境中具备更强的泛化能力，有效减少误检与虚警。</p><hr/><h3>三、数据集详情</h3><h4>3.1 数据集结构</h4><p>数据集已经按照深度学习训练规范进行了划分，结构清晰，开箱即用：</p><pre><code>dataset/
├── train/
│   ├── images/
│   └── labels/
├── valid/
│   ├── images/
│   └── labels/</code></pre><p>对应数量如下：</p><table><thead><tr><th>数据划分</th><th>图片数量</th></tr></thead><tbody><tr><td>训练集</td><td>576</td></tr><tr><td>验证集</td><td>145</td></tr></tbody></table><blockquote>所有图片均配有对应的 YOLO 标注文件（<code>.txt</code>），背景样本则为空标注文件。</blockquote><hr/><h4>3.2 类别定义</h4><p>本数据集共定义 <strong>2 个目标类别</strong>：</p><table><thead><tr><th>类别 ID</th><th>类别名称</th></tr></thead><tbody><tr><td>0</td><td>mosquito（蚊子）</td></tr><tr><td>1</td><td>fly（苍蝇）</td></tr></tbody></table><p>标注遵循 YOLO 标准格式：</p><pre><code>&lt;class_id&gt; &lt;x_center&gt; &lt;y_center&gt; &lt;width&gt; &lt;height&gt;</code></pre><p>所有坐标均为 <strong>相对于图片宽高的归一化值</strong>，可直接用于 YOLOv8 训练。</p><hr/><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047494879" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047494880" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h4>3.3 背景样本的重要性</h4><p>在真实应用场景中，摄像头画面中 <strong>大多数时间并不存在蚊子或苍蝇</strong>。如果训练数据只包含目标样本，模型很容易出现：</p><ul><li>把噪点、阴影误识别为昆虫</li><li>对复杂纹理背景产生大量误报</li><li>实际部署效果严重劣化</li></ul><p>因此，本数据集特别加入了 <strong>200+ 张背景样本</strong>，包括：</p><ul><li>无蚊虫的室内环境</li><li>光照变化明显的背景</li><li>墙面、桌面、窗户等常见干扰元素</li></ul><p>这使模型在训练过程中学会 <strong>“什么时候不该检测”</strong>，显著提升实战可靠性。</p><hr/><h3>四、适用场景</h3><p>该蚊子苍蝇检测数据集可广泛应用于以下场景：</p><h4>4.1 智能家居与智慧安防</h4><ul><li>室内蚊虫监测</li><li>智能灭蚊设备触发</li><li>家庭环境健康评估</li></ul><hr/><h4>4.2 公共卫生与疾控监测</h4><ul><li>蚊媒疾病风险预警</li><li>社区环境蚊虫密度分析</li><li>智慧城市健康管理系统</li></ul><hr/><h4>4.3 工业与农业场景</h4><ul><li>食品加工厂虫害检测</li><li>农业温室环境监控</li><li>自动化虫害识别系统</li></ul><hr/><h4>4.4 AI 教学与科研实验</h4><ul><li>YOLOv8 目标检测教学案例</li><li>小样本检测与数据增强研究</li><li>背景负样本对模型泛化能力影响分析</li></ul><hr/><h3>五、目标检测实战：YOLOv8 训练示例</h3><h4>5.1 数据配置（data.yaml）</h4><pre><code class="yaml">path: dataset
train: train/images
val: valid/images

names:
  0: mosquito
  1: fly</code></pre><hr/><h4>5.2 启动训练</h4><pre><code class="bash">yolo detect train \
  model=yolov8n.pt \
  data=data.yaml \
  epochs=100 \
  imgsz=640 \
  batch=16</code></pre><p>YOLOv8 对小目标检测表现优秀，非常适合蚊子、苍蝇这类 <strong>尺度小、形态变化大的目标</strong>。</p><hr/><h4>5.3 训练效果提升建议</h4><ul><li>启用 Mosaic / MixUp 数据增强</li><li>适当提高输入分辨率（如 960）</li><li>使用 <code>yolov8s</code> 或 <code>yolov8m</code> 提升精度</li><li>增加背景样本比例，降低误检</li></ul><hr/><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047494881" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h3>六、结语</h3><p>在目标检测任务中，<strong>数据集永远是模型性能的上限</strong>。</p><p>这套 <strong>专用蚊子苍蝇检测数据集（含背景样本）</strong>：</p><ul><li>覆盖真实应用场景</li><li>标注规范、结构清晰</li><li>针对 YOLOv8 深度优化</li><li>兼顾检测精度与泛化能力</li></ul><p>无论你是进行 <strong>AI 工程落地、科研实验，还是教学示范</strong>，该数据集都可以作为一个 <strong>高质量、可扩展的基础数据源</strong>。</p><p>如果你正在构建 <strong>蚊虫智能识别系统</strong>，那么从一套“懂场景”的数据集开始，往往比盲目调参更重要。</p>]]></description></item><item>    <title><![CDATA[程序员的伪年薪百万还能持续多久？ 良许 ]]></title>    <link>https://segmentfault.com/a/1190000047494895</link>    <guid>https://segmentfault.com/a/1190000047494895</guid>    <pubDate>2025-12-23 00:02:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>大家好，我是良许。</p><p>前两天刷脉脉，看到一个帖子炸了——某大厂程序员晒出自己的年薪package，标题写着"年薪120万"，评论区一片羡慕。</p><p>但仔细一看，base只有40万，剩下的80万是股票、期权、年终奖的"理论值"。更狠的是，股票要分四年才能拿到，期权还没到行权期，年终奖能不能拿到还得看公司业绩。</p><p>这种伪年薪百万的游戏，还能玩多久？作为一个从大厂出来创业的过来人，我今天必须把这个话题说透了。</p><h2>1. 什么是伪年薪百万？</h2><p>先给不了解的人科普一下。现在很多大厂给程序员开offer，喜欢玩一个套路：把base、股票、期权、年终奖、各种补贴全加起来，算出一个"总包"（Total Compensation），然后告诉你"年薪XX万"。</p><p>比如一个典型的"年薪100万"offer可能是这样的：</p><ul><li>Base：35万</li><li>股票：40万（分四年，每年10万）</li><li>年终奖：15万（3-6个月，看绩效）</li><li>期权：10万（三年后才能行权，还得公司上市或被收购）</li></ul><p>听起来很美好对吧？但实际情况是：<strong>第一年你真正能拿到手的，可能只有50万左右</strong>。股票要慢慢解锁，期权能不能兑现还是未知数，年终奖拿多少全看公司心情。</p><p>更狠的是，如果公司股价跌了，你那40万的股票可能只值20万；如果公司裁员或者你没熬到解锁期就离职了，那些股票直接归零。</p><h2>2. 这个游戏为什么能玩起来？</h2><p>你可能会问，既然是伪年薪，为什么还有那么多人上当？这背后有几个原因。</p><p><strong>第一，信息不对称。</strong> 很多年轻程序员，尤其是应届生，根本搞不清楚股票、期权、RSU这些东西的区别。HR给你画大饼的时候，只会告诉你"总包多少"，不会详细解释每一部分的兑现条件和风险。等你真正入职了，才发现自己被套路了。</p><p><strong>第二，虚荣心作祟。</strong> 说实话，"年薪百万"这四个字太有杀伤力了。你在同学聚会上说自己年薪百万，立马就是人群中最靓的仔。至于这个百万是真百万还是伪百万，很多人根本不在乎，或者说不愿意承认。</p><p>我见过不少程序员，明明知道自己的年薪是"注水"的，但在外面还是说自己年薪百万。这种虚荣心，让大厂的套路越玩越溜。反正你愿意被骗，我就继续骗呗。</p><p><strong>第三，大厂需要这个故事。</strong> 对大厂来说，"年薪百万"是个很好的招聘工具。你想啊，如果告诉应届生"base只有35万，其他的都是不确定的"，谁还愿意来？但如果说"年薪100万"，立马就有一堆人抢着投简历。</p><p>而且，用股票和期权代替现金，对公司来说成本更低。现金是真金白银要从账上出去的，但股票只是一串数字，不需要实际支出。更狠的是，如果你没熬到解锁期就离职了，公司连这串数字都不用给你。这笔账，大厂算得门儿清。</p><h2>3. 这个泡沫什么时候会破？</h2><p>现在的问题是，这种伪年薪百万的游戏还能玩多久？我的判断是：<strong>这个泡沫已经在破了，而且会越破越快</strong>。</p><p><strong>第一个信号：大厂开始降薪裁员。</strong> 这两年你看看新闻，哪个大厂不在裁员？字节、腾讯、阿里、美团，裁员的消息一个接一个。裁员就算了，很多大厂还在降薪，取消大小周、砍年终奖、降低股票发放。那些拿着"年薪百万"offer入职的人，现在发现自己的实际收入可能只有当初承诺的60%-70%。</p><p><strong>第二个信号：股票和期权越来越不值钱。</strong> 前几年互联网大厂的股票一路涨，拿股票的人确实赚到了。但现在呢？你看看阿里、腾讯、美团的股价，跌得有多惨。很多人手里的股票，账面价值已经腰斩了。更别说那些还没上市的公司，给你的期权可能永远都兑现不了。</p><p>我做嵌入式和Linux这块，虽然不在互联网大厂，但也见过不少拿期权的人。有个做汽车电子的朋友，当年加入一家新能源车企，公司给了他一大堆期权，说是"未来价值千万"。结果公司融资失败，现在都快倒闭了，那些期权连废纸都不如。</p><p><strong>第三个信号：年轻人开始觉醒了。</strong> 现在的95后、00后程序员，比我们这代人聪明多了。他们不再迷信"年薪百万"的标签，而是会仔细算账：base多少？股票什么时候能解锁？年终奖的发放条件是什么？如果公司股价跌了怎么办？</p><h2>4. 真年薪和伪年薪的区别</h2><p>说了这么多，你可能会问：那怎么区分真年薪和伪年薪呢？我给你几个判断标准。</p><p><strong>第一，看现金占比。</strong> 如果base占总包的70%以上，那基本是真年薪。如果base只占50%甚至更低，剩下的都是股票、期权、年终奖，那就要小心了。</p><p><strong>第二，看股票的兑现条件。</strong> 如果股票是分四年解锁，而且公司股价稳定，那还算靠谱。但如果股票要分五年甚至更久，或者公司股价波动很大，那这部分收入的不确定性就很高了。</p><p>更狠的是期权。期权要等公司上市或被收购才能行权，这个周期可能是五年、十年，甚至永远等不到。我见过太多拿着期权的人，最后什么都没拿到。所以我的建议是：<strong>期权当作零，有就是惊喜，没有也不亏</strong>。</p><p><strong>第三，看年终奖的发放历史。</strong> 有些公司的年终奖是固定的，比如13薪、15薪，这种比较靠谱。但有些公司的年终奖完全看绩效和公司业绩，可能是3个月，也可能是0。如果你拿的offer里年终奖占比很高，一定要问清楚历史发放情况。</p><h2>5. 最后想说的</h2><p>伪年薪百万这个泡沫，本质上是互联网泡沫的一部分。前几年资本疯狂涌入，大厂疯狂扩张，给程序员开出天价offer。但现在资本退潮了，大厂开始降本增效，那些虚高的薪资自然也就撑不住了。</p><p>这不是坏事。泡沫破了，市场才能回归理性。程序员也才能更清楚地认识到，真正值钱的不是"年薪百万"的标签，而是你的技术能力、行业经验、解决问题的能力。</p><p>希望我的经历能给你一些启发。记住，职业发展是一场马拉松，不是百米冲刺。那些看起来跑得很快的人，可能只是在透支未来。真正能跑到最后的，是那些步伐稳健、持续积累的人。</p>]]></description></item><item>    <title><![CDATA[什么样的程序员在35岁以后依然被公司抢着要？ 良许 ]]></title>    <link>https://segmentfault.com/a/1190000047494901</link>    <guid>https://segmentfault.com/a/1190000047494901</guid>    <pubDate>2025-12-23 00:01:22</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>大家好，我是良许。</p><p>35岁这道坎，是每个程序员都绕不开的话题。我今年刚过36，这几年做公司招人，也接触了不少35岁以上的程序员。有的人简历一投过来，我恨不得立马打电话约面试；有的人，说实话，简历看完就石沉大海了。</p><p>这个差距到底在哪？今天我就从一个创业者和技术管理者的角度，跟你聊聊什么样的程序员在35岁以后依然抢手。</p><h2>我见过的两种35岁程序员</h2><p>先说两个真实的例子，都是我这两年接触过的。</p><p><strong>第一个，老张，38岁，做嵌入式驱动开发的。</strong> 简历投过来的时候，我看他年纪有点大，本来有点犹豫。但一聊发现是个宝。他之前在一家做工控设备的公司待了十年，Linux内核那套东西玩得特别溜。关键是，他不光会写代码，还能把整个产品的技术架构给你讲清楚，从硬件选型到驱动适配到应用层优化，整条线都能搞定。</p><p><strong>第二个，小李，36岁，也是做Linux应用开发的。</strong> 简历看着挺漂亮，换了七八家公司，每家都待一两年。面试的时候我问他做过什么项目，他说做过很多，但细问下去，要么是在团队里打打下手，要么就是做一些边缘的功能模块。技术栈倒是写了一大堆，C、C++、Python、Shell都会，但每个都不精。</p><p>最要命的是，我问他对我们公司的业务有什么想法，他说"我就是想找个稳定的工作，技术上能学点东西就行"。这话一出，我基本就没兴趣了。36岁了，还是打工心态，还在想着"学东西"，这不是我要找的人。</p><p>这两个人的差距，就是35岁以后程序员的分水岭。</p><h2>第一种：有深度的技术专家</h2><p>作为一个从机械转行到嵌入式的过来人，我太清楚技术深度的重要性了。</p><p>35岁以后还抢手的程序员，第一个特点就是<strong>在某个技术领域有足够的深度</strong>。注意，是"某个领域"，不是"所有领域"。</p><p>我当年在那家500强外企的时候，部门里有个老师傅，40多岁了，就专门搞汽车电子的CAN总线通信。这东西说起来不算特别高大上，但他能把CAN协议的每个细节、每个坑都摸得透透的。车厂那边一有通信问题，第一个就找他。公司每年给他加薪，生怕他跑了。</p><p><strong>为什么技术深度这么重要？</strong> 因为到了35岁，你的价值不再是写代码的速度，而是解决疑难问题的能力。年轻人可以996肝代码，但遇到底层的、复杂的、需要经验积累的问题，他们就抓瞎了。这时候，有深度的老程序员就是救火队长，是定海神针。</p><p>但这里有个误区：很多人以为技术深度就是会用很多工具、很多框架。不是的。真正的技术深度，是<strong>理解原理，能解决别人解决不了的问题</strong>。</p><p>我举个例子。做嵌入式开发，会用Linux命令的人一抓一大把，但真正遇到系统启动卡死、内存泄漏、实时性不达标这些问题，能快速定位并解决的人，凤毛麟角。这才是技术深度。</p><h2>第二种：能独当一面的项目负责人</h2><p>第二种35岁以后依然抢手的程序员，是<strong>能独立负责项目的人</strong>。</p><p>这个我太有体会了。创业之后，我最头疼的就是找不到能独当一面的人。很多程序员，技术不错，但一让他负责一个项目，就各种问题：需求理解不到位、进度把控不住、跟客户沟通不顺畅、团队协作出问题。</p><p>而那些35岁以后还抢手的程序员，往往是能把一个项目从头到尾搞定的人。从需求分析、技术方案设计、团队分工、进度管理、风险把控到最后交付，整个流程都能handle住。</p><p>我去年接了一个智能家居的项目，涉及到嵌入式Linux、云平台对接、移动端APP联调，技术栈挺复杂的。我找了个35岁的老哥来负责，他之前在一家物联网公司做过类似的项目。整个项目他带着团队三个月就交付了，中间遇到的各种问题，他都能提前预判并解决。客户特别满意，后续又给了我们两个项目。</p><p>这种人，你说我能不抢着要吗？</p><p>这些能力，不是一两年能练出来的，需要大量的项目经验积累。这也是为什么35岁以后的程序员，如果有这些能力，反而更值钱。</p><h2>第三种：有创业思维的人</h2><p>最后一种，也是我认为最稀缺的，就是<strong>有创业思维的程序员</strong>。</p><p>什么叫创业思维？不是说你一定要去创业，而是<strong>你要像老板一样思考问题</strong>。</p><p>我见过很多35岁以后的程序员，还是打工心态：给我安排什么任务我就做什么，做完就下班，其他的不关我事。这种人，说实话，公司不会太重视。</p><p>而那些抢手的程序员，会主动思考：这个项目怎么做能帮公司省钱？怎么做能提高效率？怎么做能让客户更满意？他们不是为了完成任务而工作，而是为了创造价值而工作。</p><p>技术人员还是要有点商业思维。你做的技术再牛，如果不能转化成商业价值，那对公司来说就是成本。但如果你能把技术和商业结合起来，那你就是公司的核心资产。</p><p>我自己就是因为有这种思维，才能在28岁开始创业。我不仅会写代码，还会谈客户、做方案、算成本、控风险。这些能力，让我在二线城市实现了买房买车，有了自己的小公司。</p><h2>最后想说的</h2><p>说了这么多，我想说的是：35岁焦虑，本质上不是年龄焦虑，而是能力焦虑。</p><p>如果你35岁了，还只是个普通的码农，技术不深、项目经验不足、行业积累不够、学习能力下降、思维还停留在打工层面，那确实会被淘汰。但如果你在这三个方面中的任何一个做到了极致，那你不仅不会被淘汰，反而会越来越值钱。</p><p>希望我的经历和思考，能给你一些启发。不管你现在多大年纪，都要记住：年龄不是问题，能力才是。</p>]]></description></item><item>    <title><![CDATA[别再浪费内存了：Python __slots__ 机制深入解析 本文系转载，阅读原文
https:/]]></title>    <link>https://segmentfault.com/a/1190000047494694</link>    <guid>https://segmentfault.com/a/1190000047494694</guid>    <pubDate>2025-12-22 23:04:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>Python 对象的灵活性大家都知道，可以随时给对象添加属性：</p><pre><code>class User:  
    pass  
u = User()  
u.name = "Alice"  
u.age = 30</code></pre><p>但这种灵活性的代价也很大，每个普通 Python 对象都有个 <code>__dict__</code> 字典来存储属性，对象一多内存开销就上来了，这时候 <code>__slots__</code> 就派上用场。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047494696" alt="" title=""/></p><h2><strong>slots</strong> 到底在干什么</h2><p><code>__slots__</code> 让你提前声明类会用到哪些属性：</p><pre><code>class User:  
    __slots__ = ["name", "age"]  
    def __init__(self, name, age):  
        self.name = name  
        self.age = age</code></pre><p>这样做之后对象就不会再创建 <code>__dict__</code> 了。属性存储变成静态的，查找和赋值都快了，尤其是创建大量实例时内存占用能降不少。</p><h2>底层存储机制的差异</h2><p>普通对象把每个属性当作 <code>__dict__</code> 里的键值对访问属性就要做哈希查找。而用了 <code>__slots__</code> 之后每个属性在内存里有个固定位置，访问变成了直接的数组索引操作省掉了字典查找的开销。</p><p>说白了就是把 Python 对象存储搞得像 C 的结构体一样紧凑。</p><h2>内存能省多少</h2><p>看个对比：</p><pre><code>class Normal:  
    def __init__(self):  
        self.a = 1  
        self.b = 2  
        
class Slotted:  
    __slots__ = ["a", "b"]  
    def __init__(self):  
        self.a = 1  
        self.b = 2</code></pre><p>如果要创建几百万个实例，用 <code>__slots__</code> 的版本能少用 50-70% 的内存。</p><p>属性访问快主要是因为：省掉了字典查找、不用算哈希值、也没有额外的内存间接访问，属性访问时间一般能减少 20-40%。</p><h2>使用限制</h2><p><code>__slots__</code> 也不是完美的，有些限制得注意。</p><p>最明显的是不能随便加属性了：</p><pre><code class="python">u = User()  
u.address = "NYC"  # ❌ AttributeError</code></pre><p>继承的时候也麻烦，子类得定义自己的 <code>__slots__</code>，而且混用带slots和不带slots的类要小心。多重继承更复杂只有slots名不冲突才行。</p><p>另外默认不支持弱引用，要用的话得在 <code>__slots__</code> 里显式加上 <code>__weakref__</code>。</p><h2>什么场景适合用</h2><p>几个典型场景：处理大数据集时有几百万个对象；科学计算里的轻量数据结构、游戏引擎里的实体和粒子系统等等，总之就是那些对内存和速度敏感的地方。</p><h2>一些实用技巧</h2><p>配合类型提示用能让代码更清晰。可以和 <code>@property</code> 装饰器结合，该灵活的地方还是保持灵活。空类直接用 <code>__slots__ = ()</code> 把开销降到最低。</p><h2>总结</h2><p><code>__slots__</code> 就是让你用灵活性换内存效率和更快的属性访问。对于高性能场景来说这是个必须掌握的优化手段。</p><p>就算项目暂时不缺内存，理解 <code>__slots__</code> 本身也很有价值。它能让你明白 Python 对象是怎么存属性的、属性查找为什么有成本、Python 在灵活性和效率之间怎么权衡。</p><p>这些知识对系统设计、性能调优、排查问题都有帮助。</p><p><a href="https://link.segmentfault.com/?enc=gR9fNJI0fv4OPYDP8oCktg%3D%3D.HPp6tK1EjLoukqJ9v3wKTTzBVguH1gwEQS0eQrl0sU5e%2Fhs%2BD74sUiNgFdPjYcbdbuBpVf56e43iHC4mI1T4Pw%3D%3D" rel="nofollow" target="_blank">https://avoid.overfit.cn/post/c18314c17e0047358cb13c0a990067ae</a></p><p>作者：Elshad Karimov</p>]]></description></item><item>    <title><![CDATA[《高质量游戏攻略与视频的优先级展示机制构建指南》 程序员阿伟 ]]></title>    <link>https://segmentfault.com/a/1190000047494714</link>    <guid>https://segmentfault.com/a/1190000047494714</guid>    <pubDate>2025-12-22 23:03:51</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>深夜的游戏社区里，不同需求的玩家都在经历着相似的困境—刚入坑开放世界游戏的新手，想找隐藏副本的触发路径，刷到的却是重复剪辑的战斗混剪，连关键NPC的位置都没有标注；深耕竞技游戏的核心玩家，渴望学习新版本的战术拆解，置顶内容却还是三个月前的基础操作教学，毫无参考价值；专注单机剧情的玩家，想解锁隐藏结局的关键选择，搜索结果里满是标题党视频，点进去全是无关的剧情吐槽。这种优质内容被海量低质信息淹没的现象，本质上是传统推荐机制陷入了“流量加权”的怪圈，只看重播放量、点赞量等表面数据，却忽略了内容本身的实用价值与用户的真实需求。游戏内容的核心竞争力，从来不是短暂的流量爆发，而是能否为玩家提供可落地的技巧、有深度的解析或沉浸式的体验。构建一套自动识别并优先展示高质量内容的机制，相当于为优质创作者与精准需求玩家搭建了一条专属通道，它需要跳出单一数据的评判逻辑，深入挖掘内容的质感内核，通过对场景、行为、信息的多维度拆解，让真正有价值的内容自然突破信息壁垒，这不仅是对创作者心血的尊重，更是维系游戏社区生态活力、提升用户粘性的关键所在。</p><p>要实现高质量游戏内容的精准识别，首要任务是拆解“内容质感”的核心维度，建立一套多维度、立体化的评估体系，而非被单一指标牵着鼻子走。很多平台之所以陷入“劣币驱逐良币”的困境，就是因为将播放量作为核心评判标准，却没意识到播放量背后的虚假繁荣—有的内容靠夸张标题和封面吸引点击，用户打开3秒就果断退出，这种“无效播放”根本不能反映内容价值；而有的内容虽然初始播放量不高，但用户会完整看完，甚至反复拖拽进度条回看关键知识点，评论区里满是真诚的提问与补充，这种“有效互动”才是内容价值的真实体现。因此，机制构建的第一步，是重新定义“高质量”的核心特征：从内容属性来看，优质攻略必须具备结构完整性、信息独特性与实操适配性，比如开放世界游戏的攻略，不仅要标注资源点的精准坐标，还要说明不同职业的适配策略、避开环境陷阱的细节，甚至补充资源刷新的时间规律，而非简单罗列流程；优质视频则需兼具画面质感、表达清晰度与内容稀缺性，比如竞技游戏的操作视频，不能只放击杀集锦，还要有慢动作解析、战术思路的实时讲解，甚至针对不同段位玩家的适配建议，让不同水平的用户都能有所收获。从用户行为来看，高质量内容往往伴随高完播率、长平均停留时长、有效互动率（如评论区的深度提问、有价值的补充建议、收藏后的二次分享）等特征，这些隐性数据能更真实地反映用户对内容的认可程度。此外，还需纳入创作者维度的辅助参考，比如长期深耕垂直领域、粉丝互动质量高、无搬运抄袭等违规记录的创作者，其内容的优质概率确实更高，但这一维度只能作为补充，不能成为核心权重，要避免陷入“头部创作者特权”的误区，给新人创作者的优质内容留出公平的曝光空间，让社区始终保持新鲜血液的注入。</p><p>数据采集与预处理是机制落地的基础，这一步的核心是穿透表面数据的迷雾，挖掘能反映内容本质的有效信息，同时建立严格的异常数据过滤机制，确保识别逻辑的准确性。传统的数据采集模式往往局限于播放量、点赞量、转发量等显性指标，但这些数据极易被刷量行为操纵，比如通过脚本批量点击、雇佣水军刷评论，导致优质内容被虚假数据挤压，识别机制彻底失效。因此，必须拓展数据采集的维度，纳入更多能反映用户真实行为的隐性数据—比如用户的停留轨迹，是否在关键知识点处暂停、反复拖拽进度条回看，是否完整看完后又点击了创作者的其他相关内容；互动质量的细分，评论内容是否包含具体的问题（如“这个技能的冷却时间是多少”“隐藏任务的触发条件有等级限制吗”）、有价值的补充建议，而非无意义的表情、刷屏文字或简单的“打卡”“沙发”；甚至可以通过后台数据间接验证内容的实用价值，比如用户在观看攻略后，游戏内的任务完成率是否提升、特定操作的成功率是否增加。同时，要建立一套完善的异常数据过滤机制，通过行为链路溯源来识别刷量行为：比如某条内容的播放量在1小时内激增数万，但用户的平均停留时长不足10秒，评论内容高度同质化，且IP地址集中在同一区域，甚至存在同一设备多次点击的情况，即可判定为异常数据，直接降低其权重或纳入低质内容池。数据预处理过程中，还需对不同类型的游戏内容进行场景化分类，比如将攻略细分为新手引导、进阶技巧、隐藏内容挖掘、版本更新解析、故障排查（非Bug类）等，将视频细分为操作教学、剧情解析、娱乐集锦、赛事复盘、创作者杂谈等，不同类型的内容采用差异化的评估指标权重，比如新手引导类攻略更看重清晰度与完整性，进阶技巧类则更看重独特性与实操性，娱乐集锦类视频更看重画面质感与趣味性，这样才能让识别逻辑更贴合不同场景的用户需求。</p><p>特征提取与动态权重分配是机制的核心所在，它需要让识别逻辑从“被动统计数据”转向“主动理解内容价值”，真正抓住优质内容的核心特质。特征提取不能停留在数据表面，而要深入内容的信息内核：对于文字攻略，可通过语义分析提取关键信息点的密度与独特性，比如是否包含全网稀缺的信息（如隐藏任务的触发暗号、专属装备的获取路径）、逻辑是否连贯（是否有明确的步骤顺序、因果关系）、是否针对不同用户群体提供差异化建议（如新手与老玩家的不同玩法思路）；对于视频内容，则可通过画面分析与语义理解提取信息密度与表达质量，比如是否有清晰的字幕标注、关键操作的特写镜头、图文结合的讲解方式，语速是否适中、语言是否专业且易懂，画面是否稳定、剪辑是否流畅，是否能准确传达核心知识点。权重分配不能采用固定不变的模板，而要建立动态调整机制，根据游戏类型、社区用户画像、内容生命周期进行实时优化。比如在某款竞技游戏的版本更新初期，玩家对新英雄的技能解析、出装思路需求迫切，此时可提高“版本适配性”“信息时效性”的权重，让最新的优质攻略快速获得曝光；当社区内新手用户占比激增时，可适当提高“清晰度”“完整性”的权重，降低“独特性”的权重，让基础扎实的优质内容优先展示，帮助新手快速入门；而对于成熟的游戏社区，玩家的需求更多集中在深度解析与独特玩法上，此时可提高“独特性”“深度解析”的权重，鼓励创作者产出更有价值的内容。此外，还需引入“用户反馈闭环”来持续优化权重分配，比如通过用户对内容的举报（低质、误导）、纠错、好评等功能，收集机制识别失误的案例，比如某条优质小众攻略因为初期互动量低被低估，或者某条低质内容靠刷量获得高权重，通过这些案例反向调整特征提取的维度与权重比例，让机制的识别精度不断提升。</p><p>动态校验与场景化适配是确保机制长期有效的关键，它需要让筛选逻辑能够敏锐捕捉游戏行业的迭代节奏与用户需求的变化，避免陷入“一劳永逸”的僵化状态。游戏内容的价值具有强烈的时效性与场景性，一款游戏的新版本上线后，旧版本的攻略可能瞬间失去实用价值；不同玩家群体的需求差异也极为明显，新手玩家需要基础操作与入门指南，核心玩家则追求深度战术与隐藏内容，休闲玩家更倾向于娱乐向视频。因此，机制必须建立动态校验体系：通过后台数据实时监控不同类型内容的展示效果，比如某类内容的曝光率很高但完播率极低，可能是权重分配不合理，需要及时调整评估指标；通过定期的用户调研收集需求反馈，了解玩家在不同阶段、不同场景下的内容偏好，比如玩家在工作日晚间更倾向于实用型攻略，希望利用碎片时间提升游戏技巧，而在周末则更偏爱娱乐向视频，用于放松消遣，机制可根据时段动态调整内容展示比例。场景化适配还需针对不同游戏类型定制差异化的识别模型，比如开放世界游戏的内容更看重探索性与独特性，评估维度应侧重隐藏内容挖掘、资源点精准度；竞技游戏的内容更看重实操性与时效性，评估维度应侧重战术解析、版本适配性；单机游戏的内容更看重剧情解析与情感共鸣，评估维度应侧重剧情深度、画面质感。同时，要兼顾内容生态的多样性，避免机制过度聚焦某一类内容导致社区生态单一，可通过设置“多样性权重”，在保证高质量的前提下，适当提升小众优质内容的曝光机会，比如独立游戏的攻略、冷门玩法的解析，鼓励创作者探索更多元的内容形式，让社区内容生态更加丰富。</p><p>机制落地后的效果验证与持续优化，是构建良性循环的核心，它需要用真实数据反馈指导迭代方向，让筛选逻辑不断贴近用户的真实需求与行业的发展趋势。效果验证不能只看单一数据指标，而要建立多维度的评估体系：比如优质内容的曝光率提升比例，这能直接反映机制是否有效挖掘了高质量内容；用户的平均停留时长、有效互动率的变化，这能体现用户对展示内容的认可程度；创作者产出优质内容的积极性，比如优质内容的更新频率、新创作者的入驻数量、创作者对社区的满意度，这能反映机制是否真正激励了优质创作。通过这些数据可以全面判断机制的运行效果，比如某平台上线机制后，优质内容的曝光率提升了40%，用户平均停留时长增加了25%，评论区有效互动率增长了30%，新创作者入驻数量环比增长了20%，这说明机制起到了积极作用。同时，要主动关注机制可能存在的漏洞，比如某些技术性较强的小众攻略，因为理解门槛高，初期的完播率和互动量较低，容易被机制误判为低质内容，此时可通过设置“新内容扶持权重”，对新发布的内容给予一定的初始曝光量，根据后续的用户反馈再调整展示优先级；比如某些直播回放类内容，虽然互动数据不如短视频，但包含完整的战术讲解与实操演示，价值极高，机制需要适配这类新兴内容形式，加入专属的评估维度，如直播过程中的观众提问解答效率、核心技巧的讲解时长、回放的收藏率等。</p>]]></description></item><item>    <title><![CDATA[《前端实人核验与后端未成年人社交内容管控实操指南》 程序员阿伟 ]]></title>    <link>https://segmentfault.com/a/1190000047494720</link>    <guid>https://segmentfault.com/a/1190000047494720</guid>    <pubDate>2025-12-22 23:03:18</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>年龄防护从来不是孤立的核验环节，而是贯穿用户从注册到使用全流程的双向管控体系，前端需搭建高防绕、高可信的身份核验屏障，后端要构建精细化、可追溯的权限管控网络，两者形成无缝联动，才能真正抵御未成年人接触不适配内容、陷入不良社交的风险。前端的核心诉求是“在不降低成年用户体验的前提下，提升验证可信度”，后端的关键目标是“基于真实年龄数据，实现差异化权益管控”，只有让每一次验证结果都成为后端权限分配的唯一依据，让每一次内容消费、社交互动都经过年龄权限的刚性校验，才能既满足合规要求，又切实履行产品对未成年人的保护责任，让防护不再是停留在表面的口号。</p><p>前端年龄验证的核心挑战，在于打破“简单输入即通过”的形式化困境，在严格防绕与流畅体验之间找到平衡点—既不能因流程过于繁琐导致成年用户流失，也不能因验证门槛过低让未成年人轻易规避。传统的手动输入出生日期模式，存在明显的漏洞，用户可随意填写虚假信息，甚至通过清除浏览器缓存、修改设备时间等方式重复尝试，因此需要构建多维度、分层级的核验体系，层层递进提升身份可信度。首先，基础层采用可视化日历组件替代手动输入，组件需预设合理的年龄范围（如仅允许选择18年前及更早的日期），屏蔽未来日期与不符合逻辑的年龄选择，同时加入日期选择逻辑校验，比如若用户选择的年份对应的年龄明显与行为特征不符（如选择1950年出生却频繁使用青少年偏好的功能），则触发风险提示。进阶层引入设备与行为画像交叉验证，通过分析设备历史登录记录、常用地域、使用时段、内容偏好等数据，构建用户行为基线，若首次登录设备与常用设备差异较大，或选择的出生日期与行为基线严重背离（如自称50岁却长期在晚间22点后高频使用），则启动二次验证。二次验证可接入权威数据源辅助核验，如在获得用户明确授权后，对接实名信息校验服务，通过姓名与身份证号的一致性比对确认真实年龄，或采用人脸核验技术，结合生物特征与年龄区间的匹配度判断，进一步提升验证结果的可信度。同时，前端需对验证数据进行脱敏与加密传输，避免完整出生日期在传输过程中被篡改，本地仅存储年龄分段标识（如“12岁以下”“12-16岁”“18岁以上”），既保障用户隐私，又降低数据泄露风险。在体验优化上，将验证流程嵌入首次登录或核心功能（如观看特定内容、发起社交互动）的入口，避免重复验证；对于已通过高可信验证的用户，后续登录可通过设备指纹快速校验，直接沿用年龄权限标识，减少不必要的操作成本。</p><p>前端核验的结果并非终点，后端需建立“年龄可信等级”评估体系，对前端传输的数据进行二次校验与权限绑定，确保每一次用户操作都经过刚性权限过滤，杜绝“前端验证通过、后端放任不管”的脱节问题。首先，后端需对前端传输的验证数据进行完整性与加密有效性校验，通过校验算法核对数据签名，剔除被篡改、缺失关键信息或加密失效的异常数据，对于未通过校验的用户，直接限制其访问核心功能，并返回明确的提示信息。其次，根据前端验证方式的可信度，划分不同的年龄可信等级：仅通过基础日历选择验证的用户为“低可信等级”，需进一步限制高风险功能（如私信、评论）的使用；通过设备行为交叉验证的用户为“中可信等级”，可开放部分中等风险功能；通过权威数据源或人脸核验的用户为“高可信等级”，可正常使用对应年龄适配的全部功能。后端数据库需对年龄信息与可信等级进行字段级加密存储，采用权限分级访问机制，仅授权服务可读取相关数据，同时记录数据修改日志，确保每一次权限变更都可追溯。建立实时同步机制，当用户年龄自然增长（如未成年人成年）或验证等级提升（如从低可信升级为高可信）时，后端需自动更新权限规则，无需用户手动操作；若发现用户存在伪造身份、篡改验证结果的行为，立即将其可信等级降至最低，并限制账号功能，情节严重的予以封禁。此外，后端需通过接口签名校验、请求来源合法性验证、访问频率限制等方式，拦截非法请求，杜绝黑客通过模拟合法请求、篡改参数等方式绕过年龄权限管控的行为，确保前端核验与后端权限管控形成闭环，让防护无死角。</p><p>未成年人的内容消费限制，核心是构建“内容-年龄”精准适配机制，通过内容分级与动态权限管控，实现差异化的内容分发，既不让未成年人接触不适配内容，也不影响成年用户的正常使用。首先，需建立科学的内容分级体系，结合法律法规要求与产品定位，将平台内容划分为不同的年龄适配等级，如“全年龄段适配”“12岁以上适配”“16岁以上适配”“18岁以上适配”，分级维度不仅包括内容主题（如暴力、恐怖、婚恋），还涵盖语言风格（如成人化表达、网络俚语）、视觉元素（如血腥画面、暴露图像）、价值观导向（如拜金、攀比）等，确保分级的全面性与准确性。后端需搭建内容分级数据库，将每一条内容（包括平台自制内容与用户上传的UGC内容）与对应的适配年龄绑定，同时构建智能内容审核引擎，对UGC内容进行实时分级校验，若发现未分级或分级错误的内容，立即拦截并退回修改，避免不适配内容流入平台。在内容分发层面，后端根据用户的年龄可信等级与内容适配等级进行精准匹配：对于12岁以下未成年人，仅展示全年龄段适配的内容，过滤所有含风险元素的内容，同时设置单日内容消费时长阈值（如1小时），累计使用时长达到阈值后，自动锁定娱乐类内容，仅保留教育类、益智类内容的访问权限，并向监护人发送使用提醒；对于12-16岁未成年人，可开放“12岁以上适配”的内容，屏蔽“16岁以上”及“18岁以上”的内容，消费时长限制为工作日单日1.5小时、节假日3小时，同时在使用过程中每隔45分钟弹出休息提醒；对于16-18岁未成年人，可开放“16岁以上适配”的内容，仍禁止访问“18岁以上适配”的内容，消费时长不做强制限制，但保留时长统计与提醒功能。此外，后端需对未成年人的内容消费行为进行轨迹记录，若发现其频繁搜索、访问高风险内容，或通过切换账号、清除记录等方式试图规避限制，立即触发预警，加强管控力度，如缩短当日剩余使用时长、限制搜索功能等。</p><p>社交功能是未成年人面临风险的高发场景，后端需构建“年龄梯度化社交权限”体系，根据用户年龄划分不同的社交互动边界，从关系建立、互动行为、隐私保护三个维度进行全流程管控，降低不良社交风险。首先，限制社交关系建立权限：对于12岁以下未成年人，禁止发起陌生人社交，仅允许与已通过监护人授权的亲友建立社交关系，亲友关系建立需通过双向验证（如输入监护人设置的验证码）；对于12-16岁未成年人，可允许添加陌生人，但限制每日添加次数（如5次），添加前需展示对方的年龄区间、兴趣标签等非隐私信息，同时提供“拒绝添加”“拉黑”“举报”等功能，赋予用户自主选择权，添加后需向监护人同步社交关系变化；对于16-18岁未成年人，放宽添加次数限制，但保留添加提醒功能，让用户明确知晓社交行为的边界。其次，规范社交互动行为：屏蔽未成年人社交场景中的高风险互动功能，如私信功能仅允许与亲友或已添加3天以上的好友使用，且消息内容需经过关键词过滤与语义分析，禁止发送含隐私信息、不当言论、诱导性内容的消息；评论功能限制发言频率（如每分钟不超过3条），过滤风险词汇与恶意言论，禁止@陌生人或批量@他人；群聊功能方面，未成年人创建群聊需限制人数上限（如20人），群聊主题需经过审核，禁止创建含不适配主题的群聊，同时赋予群主与管理员对未成年人用户的管理权限，可限制其发言频率或移出群聊。在隐私保护上，后端自动屏蔽未成年人个人主页中的年龄、地理位置、联系方式等敏感信息，仅展示昵称、头像、兴趣标签等非隐私内容，限制陌生人查看其社交动态与历史互动记录，若未成年人试图发布含隐私信息的内容，立即弹出风险提示并拦截。建立社交风险预警机制，通过分析社交行为数据（如频繁与陌生人互动、接收可疑链接、发送敏感信息、被多人举报等），构建风险评分模型，当评分达到阈值时，自动触发预警，采取限制社交功能使用、通知监护人等干预措施，防范潜在风险。</p><p>机制的落地并非一劳永逸，需要建立全链路的监控、反馈与迭代体系，通过数据驱动持续优化管控策略，在强化保护力度的同时，不断提升用户体验，确保机制的有效性与适应性。首先，构建多维度监控指标体系，包括年龄验证通过率、绕过验证尝试次数、未成年人违规行为发生率、内容适配准确率、社交风险预警次数、用户投诉率等，通过实时监控掌握机制运行状态，若发现某一指标异常（如绕过验证尝试次数激增），立即排查原因并采取针对性措施。其次，建立用户反馈收集渠道，通过APP内问卷、客服反馈、社群交流等方式，收集成年用户与未成年人监护人对验证流程、权限限制的体验评价，针对用户反映的问题（如验证流程繁琐、内容限制过于严格、社交权限不合理等）进行专项优化，在不降低防护标准的前提下，提升体验流畅度。密切关注法律法规与行业标准的更新动态，安排专人跟踪相关政策变化，及时调整内容分级标准、权限限制规则与验证方式，确保机制始终符合合规要求。定期开展安全测试与压力测试，模拟黑客绕过验证、篡改权限、非法访问等场景，检验机制的安全性与稳定性，针对测试中发现的漏洞，快速推进修复与迭代；同时，进行灰度发布与效果评估，将优化后的机制先面向部分用户开放，通过对比测试数据与用户反馈，确认效果后再全面推广。</p>]]></description></item><item>    <title><![CDATA[理解人类意图 烦恼的蜡烛 ]]></title>    <link>https://segmentfault.com/a/1190000047494807</link>    <guid>https://segmentfault.com/a/1190000047494807</guid>    <pubDate>2025-12-22 23:02:21</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>随着人工智能（AI）的蓬勃发展，许多金融专业人士都在权衡两个主要问题：人工智能市场是否存在泡沫，如果存在，它是否应该与21世纪初的互联网时代相提并论？</p><p>　　电影《大空头》真实原型之一、知名交易员Danny Moses认为这两个问题的答案都是肯定的。虽然他不否认人工智能热潮是真实存在的，而且是一个长期增长的故事，但他也看到了这两次科技热潮之间的强烈相似之处，这表明投资者需要谨慎行事。</p><p>　　Moses因在次贷危机期间做空房地产市场而一战成名，他在最新采访中谈到了人工智能市场正在出现的潜在问题，以及他认为投资者应该如何应对这个快速发展的领域。</p><p>　　“增长是真实的，但数学计算不正确，”他说：“我认为，我们正在达到一个数学不起作用的地步。”</p><p>　　Moses强调，他对AI市场潜在问题的看法并不是呼吁做空该行业。相反，他指出，这是在呼吁投资者做好功课，找到合适的公司，以便在市场持续增长的情况下获得有价值的敞口。</p><p>　　在他看来，这意味着要坚持投资科技行业最具主导地位的公司，这些公司拥有继续扩张的资源，而且不像一些规模较小的公司那样受到种种限制。最好的例子包括亚马逊、谷歌、Meta和微软。</p><p>　　“他们可以在任何时候减少资本支出，而且他们的现金流仍然是正的，而其他公司则依赖于人工智能领域的支出。”他补充道。</p><p>　　不过，Moses并非看好所有的大型科技公司。他以甲骨文为例，说明了人工智能市场存在的问题，并指出该公司的高债务水平和完成科技客户订单所需的现金方面存在风险。他还特别提到波动性较大的科技股，如超微电脑和CoreWeave，认为它们是人工智能领域风险较高的投资标的。</p><p>　　不过，在他看来，投资者终于开始考虑到这样一个事实，即并非所有的人工智能股票都是“生儿平等”的，因为相对表现优异和表现不佳之间的差距变得越来越难以忽视。</p><p>　　“我认为这证明投资者开始分辨交易的赢家和输家，他们更愿意投资那些资产负债表更稳健、更有保障的企业来表达人工智能主题，”他补充道。</p><p>　　Moses还表示，他看好铀，因为这种金属越来越被吹捧为人工智能建设的关键组成部分，这将是未来几年维持该行业所必需的。</p><p>　　由于美国电力供应紧张，一些数据中心倾向采用小型核电站作为主力电源，而铀正是核电站的主要原料。</p><p>　　“我喜欢的交易之一是铀，从主题上讲，这应该是可行的，但需要很长一段时间。人们认为企业将经历人工智能增长的时机，与推动人工智能增长所需的基础设施实际上存在不匹配。”他补充道。</p><p>　人形机器人板块12月4日早盘表现强势，华伍股份、骏亚科技、巨轮智能、睿能科技、龙溪股份纷纷涨停；三协电机、德马科技、江苏雷利则大涨超10%。此外，机器人执行器、减速器、同步磁阻电机等相关板块也涨幅靠前。<br/>　　人形机器人消息不断</p><p>　　消息面上，近期有关于人形机器人的利好新动态不断涌现。据中国基金报援引报道称，在发布加速人工智能发展计划五个月后，特朗普政府开始将目光转向机器人。此前，美国商务部长卢特尼克一直在与机器人行业的首席执行官们会面，并“全力以赴”加速该行业的发展。特朗普政府正在考虑明年发布一项关于机器人技术的行政令。据报道，一位知情人士透露，交通部也正准备宣布成立一个机器人工作组，可能在年底前公布。受此影响，隔夜美股的机器人概念股表现强势，iRobot收涨73.85%，Serve Robotics收涨18.24%。<br/>　　此外，特斯拉CEO马斯克在北京时间12月3日在社交平台转发了特斯拉擎天柱（Optimus）团队发布的一段“擎天柱”人形机器人跑步的短视频。<br/>　　12月2日，众擎机器人宣布，全尺寸极致高效能通用人形机器人众擎T800正式发布，产品发售进程也随即正式启动。同一天，阿童木机器人正式发布迭代版全栈自研人形机器人“天兵一号ATOM01”。</p><p>　　政策环境持续友好</p><p>　　从政策来看，从2025年蛇年春晚舞台的机器人扭秧歌，到北京亦庄的机器人马拉松，再到浙江杭州的机器人格斗赛……人形机器人正逐渐“破圈”，从“实验室”迈向各类“应用场”。而这背后，与政策环境的友好是密不可分的。</p><p>　　今年以来，以人形机器人为典型业态的具身智能成为我国培育未来产业的重要方向。北京、上海、广东深圳、浙江杭州等多地密集出台专项政策，形成了一场面向未来的产业竞逐。</p><p>　　作为全国较早将“具身智能”写入地方政府工作报告的省份，广东在今年2月明确提出，要加快启动布局人形机器人等重点领域研发项目。除了政策支持，北京、上海、深圳等10余个地方政府已建立或筹备建立相关产业基金。</p><p>　　从企业来看，头部企业已率先开启证券化。今年以来，宇树科技、乐聚智能、智元+k.机器人等人形机器人头部整机厂密集启动IPO、并购上市等资本化动作，行业开始迈入“产业化+资本化”双轮驱-+动发展阶段。<br/>　　融资客抢筹前20个股</p><p>　　从杠杆资金角度来看，部分人形机器人概念也被积极抢筹。比如瑞芯微，国庆后融资客融资净买入3.43亿元，该股前三季度归母净利润7.8亿元，同比大增121.65%。东方精工紧随其后，融资客融资净买入3.13亿元，前三季度赚了5.1亿元，同比增54.64%。东阳光居第三位，被融资净买入2.41亿元，前三季度赚了9.06亿元，同比大增189.8%。<br/>研发投入占比前20个股</p><p>　　而从研发投入占营收比角度来看，东方财富Choice数据显示，安路科技以69.45%排在首位。帝奥微紧随其后，研发投入占比为35.22%。当虹科技、创耀科技、芯朋微排名也靠前。<br/>　　2026年迎量产元年？</p><p>　　往后看，“2026年是人形机器人的量产元年，当前临界点已至。”开源证券分析师孟鹏飞指出，海外特斯拉和国内产业进展持续加速，后续催化因素较多。展望2026年，人形机器人将进入量产期，大厂躬身入局，政策支持和补贴有望进入实际阶段，“趋势走强、景气上行”的布局窗口已然开启。而国家发展改革委健全具身智能准入与退出机制、营造公平竞争环境的举措，既正向引导行业迈向良性发展轨道，也释放出人形机器人相关支持政策或已逐步临近的信号。</p><p>　　高工机器人产业研究所（GGII）数据显示，2024年全球人形机器人市场规模约10.17亿美元，预计2030年将达150亿美元，年复合增长率超56%；同期销量从1.19万台增至60.57万台。中国市场前景也很广阔，2030年规模预计达380亿元人民币，销量跃升至27.12万台，占全球份额44.77%。</p><p>　　不过，随着人形机器人的关注度提升，市场上有关于“速度”与“泡沫”的讨论也多了起来。国家发展改革委政策研究室副主任李超此前表示，“速度”与“泡沫”一直是前沿产业发展过程中需要把握和平衡的问题，这对于具身智能产业来讲，也是一样的。当前，人形机器人在技术路线、商业化模式、应用场景等方面尚未完全成熟，随着新兴资本的加速入场，我国目前已有超过150家人形机器人企业，这个数量还在不断增加，其中半数以上为初创或“跨行”入局，这对鼓励创新来讲是一件好事；但也要着力防范重复度高的产品“扎堆”上市、研发空间被压缩等风险。面对机遇与挑战并存的局面，关键在于合理引导。</p><p>11月摩根士丹利新发布的一份研究报告中预测，苹果这家行业巨头正在逐步推进他们的人形机器人计划，想要打造下一个超级增长引擎；结合此前8月份彭博社等财经媒体的相关报道，机器人市场可能真的要在不久的将来迎来苹果这头“巨鲸”了。</p><p>苹果为什么要在此时开始加速下注机器人赛道？</p><p>行业的热度自然是最显要的背景，而对苹果自身来说，驱动它进军机器人领域的自身动力也在这个时间点上异常的大----</p><p>长达15年的库克掌舵时代即将在明年宣告落幕，iPhone系列的辉煌历史之下，是缺乏新的拳头产品的现实，以及更重要的是进入AI时代后在这块领域进展的受挫。</p><p>这些不足和隐忧，让苹果必须加紧迈向机器人领域的步伐。</p><p>而在这个过程里，它有哪些占优的禀赋、有什么可能的不足，以及更关键的，它会为机器人行业带来什么影响？</p><p>苹果的优势<br/>如今，在太平洋两岸，已经有众多的巨头，在过去几年里以下场自研或者投资的方式，切入机器人赛道，试图在包括人工智能在内的技术层、制造层和应用层等方面卡住一个身位，拿到一张通向未来机器人时代的门票。</p><p>而苹果在这个过程里却扮演了一个相对“沉默者”的角色。</p><p>但摩根士丹利在内的分析者们，依旧看好苹果在这个赛道“后来居上”的能力：</p><p>首先是苹果在过去十多年积累下的品牌溢价以及规模化制造能力。</p><p>依靠着高端的设计感和坚持隐私保护的理念，苹果以iPhone为拳头产品已经在全球攒下了十多亿用户，其中不乏品牌的忠实拥趸，拥有其他行业玩家难以匹敌的用户基础。</p><p>而数十年在消费电子领域的量产经验，被认为是苹果在未来有望快速压低机器人硬件制造成本的根基。</p><p>其次是他们在机器人领域掌握的技术储备和经验。</p><p>虽然在经历近10年研发后，苹果的“Project Titan”项目还是被终止，宣告着他们的自动驾驶汽车项目失败，但依旧在计算机视觉、学习和embodied Ai技术等方面积攒下可以复用到机器人领域的经验。类似的还包括此前苹果报以期望的Vision Pro的空间技术等。</p><p>而机器人技术在苹果的生产供应链上也已经颇具“存在感”：富士康“熄灯工厂”已经使用机器人来生产iPhone一段时间了，而名为Dasiy的回收机器人已经能够在生产线上实现每小时200台的拆解效率。在工业场景的落地上，苹果的机器人经验其实已经不输给大部分巨头了。</p><p>此外，苹果在招聘、投入占比等方面也开始加大了对机器人领域的突出和倾斜，所带来的一个直观效果就是近年来苹果公司和机器人相关的专利始终在保持增长。</p><p>最后就是对苹果以往成功立下了汗马功劳的垂直生态整合能力。</p><p>苹果是业内少有的能做到核心部件在设计和量产上都能实现自研和可控的公司。而在软件层面，以庞大用户群体手里的数十亿台不同设备为基础，能帮助苹果积累海量视觉数据。</p><p>更关键的是，Siri、iCloud、HomePod等已经形成用户使用习惯的生态可以和机器人形成紧密结合，极大地降低用户上手难度。</p><p>苹果的劣势<br/>尽管看起来拥有如此多的优势，但苹果通向机器人行业领头羊地位的道路，也绝不会是一帆风顺。</p><p>除了目前已经在机器人赛道的自研和投资上落后其他巨头一个身位的客观事实之外，二姐觉得以下因素也会拖累苹果雄心勃勃的机器人计划。</p><p>机器人，尤其是目前最热门的人形机器人，其生产制造的供应链和苹果原本所熟悉的移动设备供应链依旧存在一定的差异，比如对机器人而言至关重要的精密执行器等方面，苹果也许还需要一些时间来“补课”。</p><p>马斯克就曾公开“诉苦”，坦诚就智能设备而言，做机器人比造汽车还要难，尤其是在硬件设计等层面。对于曾经“造车失败”的苹果来说，无疑接下来的这场“仰攻”还是挺有难度的。</p><p>其次是被认为大概率会发生在明年的高层人事变动：在担任CEO整整15年后，库克明年很有可能卸任，而根据彭博社的文章报道，新任CEO人选很有可能花落硬件工程高级副总裁约翰.特努斯（John Ternus）。在2001年加入苹果后，特努斯参与了苹果大部分硬件产品的工程设计工作。</p><p>但变数还是存在，其他候选人目前也依旧保有可能性。CEO的变化和相关而来的人事变动，最终会给苹果的机器人业务带来什么样的具体变化，还是未知数。</p><p>与人事变动相关联的，还有苹果日趋保守的公司文化和决策流程。有前员工披露，这家市值被库克带到了4万亿美元高峰的大公司，如今每个动作“都要经过财务评估和考虑对利润率的影响”。这种变化显然对于需要创新思维和突破勇气支撑的机器人业务并非利好因素。</p><p>最后，也是最关键的，苹果AI能力的相对落后。</p><p>早在2024年年中，苹果就推出了苹果智能（Apple Intelligence），但迄今为止这个被寄予厚望的AI系统依旧进展缓慢，以至于原定于今年推出的新版Siri已经确定将被推迟到最早明年面世。</p><p>AI能力的瓶颈，此前已经或多或少影响了苹果Vision Pro等硬件设备的销售和用户渗透状况。</p><p>Apple Intelligence被看作是苹果连接已有生态和未来机器人业务的重要纽带，而如果缺乏有力AI的加持，会影响机器人感知、推理和实时学习等核心能力，降低机器人场景的多模态交互和环境自适应水平，机器人也难言是真正有价值的具身智能。</p><p>苹果已经计划将未来的Siri置于机器人操作系统的核心位置，并为其设计可视化形象，增强真实感，以降低用户接受的难度。但如果作为Siri基础的AI大脑“发育”不良，以苹果的慎重作风，其机器人计划的整体延宕是很有可能的。</p><p>苹果机器人的到来可能会带来哪些影响<br/>就目前披露的信息，苹果会在2027年推出一个可以担任虚拟陪伴角色的桌面机器人，其用途主要包括工作、娱乐和生活管理等。</p><p>苹果想利用这款产品，来承载自身AI实体化的战略，但其实步子迈的并不大：一方面，这款机器人所能提供的功能基本上来自于苹果移动设备所具有功能的延伸，只不过因为有了AI，它可以更主动地发起对话和任务；另一方面，在外形上，它也没有选择激进但在目前确实火热的人形形态。</p><p>就目前来看，这款概念机器人虽然进入了家庭，但并不能实现家庭众多场景的覆盖，而且它所想解决的用户需求并不那么明确----看起来，它几乎像是一台“会说话、会做一定程度移动的iPad”。</p><p>但话说回来，这款机器人应该只是苹果对于领域的投石问路之作，他们对机器人的探索绝不会止步于此。</p><p>此前，苹果与大学相关机构一起研发了能解决人形机器人“在物品密集环境中进行运动规划时面临感知问题”的系统；包括其后还发布了关于增强人形机器人基于非语言表达来理解人类意图、实现沟通的能力的研究。</p><p>这些动作，都证实了在场景选择上，苹果会让机器人“先进家”，毕竟他们是一家成熟的to C公司。在消费产品思维导向下，即使是机器人产品，苹果也会倾向于将其打造成轻量易用的智能友好型产品。</p><p>而作为一家在全球已经拥有牢固用户基础的公司，苹果的这种产品方向，除了在技术层面的带动和示范效应外，在需求端也能激发用户对于机器人的使用习惯。让普通消费者与机器人的交互需要更频繁和紧密，就像当年iPhone的渗透带动了智能手机行业整体的普及和发展。</p><p>另外，苹果惯用的“硬件+服务”配套的商业模式，既为自身机器人在以后实现服务和场景升级覆盖预留了空间，对于推动整个机器人行业盈利模式的多元化和完善，也会起到相应的作用。</p><p>同时，苹果加速机器人发展，对上下游产业链还会构成一定的影响。</p><p>比如出于全球竞争和供应链安全的考虑，苹果正在主动加强自身供应链的韧性。比较典型的例子，是他们与美国本土唯一一家运营稀土矿的公司MP materialsweibo.com/ttarticle/p/show?id=2309405246650527645753<br/>weibo.com/ttarticle/p/show?id=2309405246650858995719<br/>weibo.com/ttarticle/p/show?id=2309405246651186151543<br/>weibo.com/ttarticle/p/show?id=2309405246651635204331<br/>weibo.com/ttarticle/p/show?id=2309405246651970486332<br/>weibo.com/ttarticle/p/show?id=2309405246652297642044<br/>weibo.com/ttarticle/p/show?id=2309405246652624797824<br/>weibo.com/ttarticle/p/show?id=2309405246653077782601<br/>weibo.com/ttarticle/p/show?id=2309405246653400744165价值5亿美元的合作。苹果想在美国本土建立稀土磁铁供应链，来保证包括高性能电机这样机器人核心部件在内的制造不会受到原材料的限制。这种降低对单一原材料和生产地依赖的办法，也许会在未来被越来越多的机器人厂商所采纳，从而在某些程度上改变行业的全球布局。</p>]]></description></item><item>    <title><![CDATA[技术层面的带动 烦恼的蜡烛 ]]></title>    <link>https://segmentfault.com/a/1190000047494810</link>    <guid>https://segmentfault.com/a/1190000047494810</guid>    <pubDate>2025-12-22 23:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>随着人工智能（AI）的蓬勃发展，许多金融专业人士都在权衡两个主要问题：人工智能市场是否存在泡沫，如果存在，它是否应该与21世纪初的互联网时代相提并论？</p><p>　　电影《大空头》真实原型之一、知名交易员Danny Moses认为这两个问题的答案都是肯定的。虽然他不否认人工智能热潮是真实存在的，而且是一个长期增长的故事，但他也看到了这两次科技热潮之间的强烈相似之处，这表明投资者需要谨慎行事。</p><p>　　Moses因在次贷危机期间做空房地产市场而一战成名，他在最新采访中谈到了人工智能市场正在出现的潜在问题，以及他认为投资者应该如何应对这个快速发展的领域。</p><p>　　“增长是真实的，但数学计算不正确，”他说：“我认为，我们正在达到一个数学不起作用的地步。”</p><p>　　Moses强调，他对AI市场潜在问题的看法并不是呼吁做空该行业。相反，他指出，这是在呼吁投资者做好功课，找到合适的公司，以便在市场持续增长的情况下获得有价值的敞口。</p><p>　　在他看来，这意味着要坚持投资科技行业最具主导地位的公司，这些公司拥有继续扩张的资源，而且不像一些规模较小的公司那样受到种种限制。最好的例子包括亚马逊、谷歌、Meta和微软。</p><p>　　“他们可以在任何时候减少资本支出，而且他们的现金流仍然是正的，而其他公司则依赖于人工智能领域的支出。”他补充道。</p><p>　　不过，Moses并非看好所有的大型科技公司。他以甲骨文为例，说明了人工智能市场存在的问题，并指出该公司的高债务水平和完成科技客户订单所需的现金方面存在风险。他还特别提到波动性较大的科技股，如超微电脑和CoreWeave，认为它们是人工智能领域风险较高的投资标的。</p><p>　　不过，在他看来，投资者终于开始考虑到这样一个事实，即并非所有的人工智能股票都是“生儿平等”的，因为相对表现优异和表现不佳之间的差距变得越来越难以忽视。</p><p>　　“我认为这证明投资者开始分辨交易的赢家和输家，他们更愿意投资那些资产负债表更稳健、更有保障的企业来表达人工智能主题，”他补充道。</p><p>　　Moses还表示，他看好铀，因为这种金属越来越被吹捧为人工智能建设的关键组成部分，这将是未来几年维持该行业所必需的。</p><p>　　由于美国电力供应紧张，一些数据中心倾向采用小型核电站作为主力电源，而铀正是核电站的主要原料。</p><p>　　“我喜欢的交易之一是铀，从主题上讲，这应该是可行的，但需要很长一段时间。人们认为企业将经历人工智能增长的时机，与推动人工智能增长所需的基础设施实际上存在不匹配。”他补充道。</p><p>　人形机器人板块12月4日早盘表现强势，华伍股份、骏亚科技、巨轮智能、睿能科技、龙溪股份纷纷涨停；三协电机、德马科技、江苏雷利则大涨超10%。此外，机器人执行器、减速器、同步磁阻电机等相关板块也涨幅靠前。<br/>　　人形机器人消息不断</p><p>　　消息面上，近期有关于人形机器人的利好新动态不断涌现。据中国基金报援引报道称，在发布加速人工智能发展计划五个月后，特朗普政府开始将目光转向机器人。此前，美国商务部长卢特尼克一直在与机器人行业的首席执行官们会面，并“全力以赴”加速该行业的发展。特朗普政府正在考虑明年发布一项关于机器人技术的行政令。据报道，一位知情人士透露，交通部也正准备宣布成立一个机器人工作组，可能在年底前公布。受此影响，隔夜美股的机器人概念股表现强势，iRobot收涨73.85%，Serve Robotics收涨18.24%。<br/>　　此外，特斯拉CEO马斯克在北京时间12月3日在社交平台转发了特斯拉擎天柱（Optimus）团队发布的一段“擎天柱”人形机器人跑步的短视频。<br/>　　12月2日，众擎机器人宣布，全尺寸极致高效能通用人形机器人众擎T800正式发布，产品发售进程也随即正式启动。同一天，阿童木机器人正式发布迭代版全栈自研人形机器人“天兵一号ATOM01”。</p><p>　　政策环境持续友好</p><p>　　从政策来看，从2025年蛇年春晚舞台的机器人扭秧歌，到北京亦庄的机器人马拉松，再到浙江杭州的机器人格斗赛……人形机器人正逐渐“破圈”，从“实验室”迈向各类“应用场”。而这背后，与政策环境的友好是密不可分的。</p><p>　　今年以来，以人形机器人为典型业态的具身智能成为我国培育未来产业的重要方向。北京、上海、广东深圳、浙江杭州等多地密集出台专项政策，形成了一场面向未来的产业竞逐。</p><p>　　作为全国较早将“具身智能”写入地方政府工作报告的省份，广东在今年2月明确提出，要加快启动布局人形机器人等重点领域研发项目。除了政策支持，北京、上海、深圳等10余个地方政府已建立或筹备建立相关产业基金。</p><p>　　从企业来看，头部企业已率先开启证券化。今年以来，宇树科技、乐聚智能、智元+k.机器人等人形机器人头部整机厂密集启动IPO、并购上市等资本化动作，行业开始迈入“产业化+资本化”双轮驱-+动发展阶段。<br/>　　融资客抢筹前20个股</p><p>　　从杠杆资金角度来看，部分人形机器人概念也被积极抢筹。比如瑞芯微，国庆后融资客融资净买入3.43亿元，该股前三季度归母净利润7.8亿元，同比大增121.65%。东方精工紧随其后，融资客融资净买入3.13亿元，前三季度赚了5.1亿元，同比增54.64%。东阳光居第三位，被融资净买入2.41亿元，前三季度赚了9.06亿元，同比大增189.8%。<br/>研发投入占比前20个股</p><p>　　而从研发投入占营收比角度来看，东方财富Choice数据显示，安路科技以69.45%排在首位。帝奥微紧随其后，研发投入占比为35.22%。当虹科技、创耀科技、芯朋微排名也靠前。<br/>　　2026年迎量产元年？</p><p>　　往后看，“2026年是人形机器人的量产元年，当前临界点已至。”开源证券分析师孟鹏飞指出，海外特斯拉和国内产业进展持续加速，后续催化因素较多。展望2026年，人形机器人将进入量产期，大厂躬身入局，政策支持和补贴有望进入实际阶段，“趋势走强、景气上行”的布局窗口已然开启。而国家发展改革委健全具身智能准入与退出机制、营造公平竞争环境的举措，既正向引导行业迈向良性发展轨道，也释放出人形机器人相关支持政策或已逐步临近的信号。</p><p>　　高工机器人产业研究所（GGII）数据显示，2024年全球人形机器人市场规模约10.17亿美元，预计2030年将达150亿美元，年复合增长率超56%；同期销量从1.19万台增至60.57万台。中国市场前景也很广阔，2030年规模预计达380亿元人民币，销量跃升至27.12万台，占全球份额44.77%。</p><p>　　不过，随着人形机器人的关注度提升，市场上有关于“速度”与“泡沫”的讨论也多了起来。国家发展改革委政策研究室副主任李超此前表示，“速度”与“泡沫”一直是前沿产业发展过程中需要把握和平衡的问题，这对于具身智能产业来讲，也是一样的。当前，人形机器人在技术路线、商业化模式、应用场景等方面尚未完全成熟，随着新兴资本的加速入场，我国目前已有超过150家人形机器人企业，这个数量还在不断增加，其中半数以上为初创或“跨行”入局，这对鼓励创新来讲是一件好事；但也要着力防范重复度高的产品“扎堆”上市、研发空间被压缩等风险。面对机遇与挑战并存的局面，关键在于合理引导。</p><p>11月摩根士丹利新发布的一份研究报告中预测，苹果这家行业巨头正在逐步推进他们的人形机器人计划，想要打造下一个超级增长引擎；结合此前8月份彭博社等财经媒体的相关报道，机器人市场可能真的要在不久的将来迎来苹果这头“巨鲸”了。</p><p>苹果为什么要在此时开始加速下注机器人赛道？</p><p>行业的热度自然是最显要的背景，而对苹果自身来说，驱动它进军机器人领域的自身动力也在这个时间点上异常的大----</p><p>长达15年的库克掌舵时代即将在明年宣告落幕，iPhone系列的辉煌历史之下，是缺乏新的拳头产品的现实，以及更重要的是进入AI时代后在这块领域进展的受挫。</p><p>这些不足和隐忧，让苹果必须加紧迈向机器人领域的步伐。</p><p>而在这个过程里，它有哪些占优的禀赋、有什么可能的不足，以及更关键的，它会为机器人行业带来什么影响？</p><p>苹果的优势<br/>如今，在太平洋两岸，已经有众多的巨头，在过去几年里以下场自研或者投资的方式，切入机器人赛道，试图在包括人工智能在内的技术层、制造层和应用层等方面卡住一个身位，拿到一张通向未来机器人时代的门票。</p><p>而苹果在这个过程里却扮演了一个相对“沉默者”的角色。</p><p>但摩根士丹利在内的分析者们，依旧看好苹果在这个赛道“后来居上”的能力：</p><p>首先是苹果在过去十多年积累下的品牌溢价以及规模化制造能力。</p><p>依靠着高端的设计感和坚持隐私保护的理念，苹果以iPhone为拳头产品已经在全球攒下了十多亿用户，其中不乏品牌的忠实拥趸，拥有其他行业玩家难以匹敌的用户基础。</p><p>而数十年在消费电子领域的量产经验，被认为是苹果在未来有望快速压低机器人硬件制造成本的根基。</p><p>其次是他们在机器人领域掌握的技术储备和经验。</p><p>虽然在经历近10年研发后，苹果的“Project Titan”项目还是被终止，宣告着他们的自动驾驶汽车项目失败，但依旧在计算机视觉、学习和embodied Ai技术等方面积攒下可以复用到机器人领域的经验。类似的还包括此前苹果报以期望的Vision Pro的空间技术等。</p><p>而机器人技术在苹果的生产供应链上也已经颇具“存在感”：富士康“熄灯工厂”已经使用机器人来生产iPhone一段时间了，而名为Dasiy的回收机器人已经能够在生产线上实现每小时200台的拆解效率。在工业场景的落地上，苹果的机器人经验其实已经不输给大部分巨头了。</p><p>此外，苹果在招聘、投入占比等方面也开始加大了对机器人领域的突出和倾斜，所带来的一个直观效果就是近年来苹果公司和机器人相关的专利始终在保持增长。</p><p>最后就是对苹果以往成功立下了汗马功劳的垂直生态整合能力。</p><p>苹果是业内少有的能做到核心部件在设计和量产上都能实现自研和可控的公司。而在软件层面，以庞大用户群体手里的数十亿台不同设备为基础，能帮助苹果积累海量视觉数据。</p><p>更关键的是，Siri、iCloud、HomePod等已经形成用户使用习惯的生态可以和机器人形成紧密结合，极大地降低用户上手难度。</p><p>苹果的劣势<br/>尽管看起来拥有如此多的优势，但苹果通向机器人行业领头羊地位的道路，也绝不会是一帆风顺。</p><p>除了目前已经在机器人赛道的自研和投资上落后其他巨头一个身位的客观事实之外，二姐觉得以下因素也会拖累苹果雄心勃勃的机器人计划。</p><p>机器人，尤其是目前最热门的人形机器人，其生产制造的供应链和苹果原本所熟悉的移动设备供应链依旧存在一定的差异，比如对机器人而言至关重要的精密执行器等方面，苹果也许还需要一些时间来“补课”。</p><p>马斯克就曾公开“诉苦”，坦诚就智能设备而言，做机器人比造汽车还要难，尤其是在硬件设计等层面。对于曾经“造车失败”的苹果来说，无疑接下来的这场“仰攻”还是挺有难度的。</p><p>其次是被认为大概率会发生在明年的高层人事变动：在担任CEO整整15年后，库克明年很有可能卸任，而根据彭博社的文章报道，新任CEO人选很有可能花落硬件工程高级副总裁约翰.特努斯（John Ternus）。在2001年加入苹果后，特努斯参与了苹果大部分硬件产品的工程设计工作。</p><p>但变数还是存在，其他候选人目前也依旧保有可能性。CEO的变化和相关而来的人事变动，最终会给苹果的机器人业务带来什么样的具体变化，还是未知数。</p><p>与人事变动相关联的，还有苹果日趋保守的公司文化和决策流程。有前员工披露，这家市值被库克带到了4万亿美元高峰的大公司，如今每个动作“都要经过财务评估和考虑对利润率的影响”。这种变化显然对于需要创新思维和突破勇气支撑的机器人业务并非利好因素。</p><p>最后，也是最关键的，苹果AI能力的相对落后。</p><p>早在2024年年中，苹果就推出了苹果智能（Apple Intelligence），但迄今为止这个被寄予厚望的AI系统依旧进展缓慢，以至于原定于今年推出的新版Siri已经确定将被推迟到最早明年面世。</p><p>AI能力的瓶颈，此前已经或多或少影响了苹果Vision Pro等硬件设备的销售和用户渗透状况。</p><p>Apple Intelligence被看作是苹果连接已有生态和未来机器人业务的重要纽带，而如果缺乏有力AI的加持，会影响机器人感知、推理和实时学习等核心能力，降低机器人场景的多模态交互和环境自适应水平，机器人也难言是真正有价值的具身智能。</p><p>苹果已经计划将未来的Siri置于机器人操作系统的核心位置，并为其设计可视化形象，增强真实感，以降低用户接受的难度。但如果作为Siri基础的AI大脑“发育”不良，以苹果的慎重作风，其机器人计划的整体延宕是很有可能的。</p><p>苹果机器人的到来可能会带来哪些影响<br/>就目前披露的信息，苹果会在2027年推出一个可以担任虚拟陪伴角色的桌面机器人，其用途主要包括工作、娱乐和生活管理等。</p><p>苹果想利用这款产品，来承载自身AI实体化的战略，但其实步子迈的并不大：一方面，这款机器人所能提供的功能基本上来自于苹果移动设备所具有功能的延伸，只不过因为有了AI，它可以更主动地发起对话和任务；另一方面，在外形上，它也没有选择激进但在目前确实火热的人形形态。</p><p>就目前来看，这款概念机器人虽然进入了家庭，但并不能实现家庭众多场景的覆盖，而且它所想解决的用户需求并不那么明确----看起来，它几乎像是一台“会说话、会做一定程度移动的iPad”。</p><p>但话说回来，这款机器人应该只是苹果对于领域的投石问路之作，他们对机器人的探索绝不会止步于此。</p><p>此前，苹果与大学相关机构一起研发了能解决人形机器人“在物品密集环境中进行运动规划时面临感知问题”的系统；包括其后还发布了关于增强人形机器人基于非语言表达来理解人类意图、实现沟通的能力的研究。</p><p>这些动作，都证实了在场景选择上，苹果会让机器人“先进家”，毕竟他们是一家成熟的to C公司。在消费产品思维导向下，即使是机器人产品，苹果也会倾向于将其打造成轻量易用的智能友好型产品。</p><p>而作为一家在全球已经拥有牢固用户基础的公司，苹果的这种产品方向，除了在技术层面的带动和示范效应外，在需求端也能激发用户对于机器人的使用习惯。让普通消费者与机器人的交互需要更频繁和紧密，就像当年iPhone的渗透带动了智能手机行业整体的普及和发展。</p><p>另外，苹果惯用的“硬件+服务”配套的商业模式，既为自身机器人在以后实现服务和场景升级覆盖预留了空间，对于推动整个机器人行业盈利模式的多元化和完善，也会起到相应的作用。</p><p>同时，苹果加速机器人发展，对上下游产业链还会构成一定的影响。</p><p>比如出于全球竞争和供应链安全的考虑，苹果正在主动加强自身供应链的韧性。比较典型的例子，是他们与美国本土唯一一家运营稀土矿的公司MP materials价值5亿美元的合作。苹果想在美国本土建立稀土磁铁供应链，来保证包括高性能电机这样机器人核心部件在内的制造不会受到原材料的限制。这种降低对单一原材料和生产地依赖的办法，也许weibo.com/ttarticle/p/show?id=2309405246653732356353<br/>weibo.com/ttarticle/p/show?id=2309405246654059249848<br/>weibo.com/ttarticle/p/show?id=2309405246654520885392<br/>weibo.com/ttarticle/p/show?id=2309405246654856167482<br/>weibo.com/ttarticle/p/show?id=2309405246656701661488<br/>weibo.com/ttarticle/p/show?id=2309405246657028817187<br/>weibo.com/ttarticle/p/show?id=2309405246657360429191<br/>weibo.com/ttarticle/p/show?id=2309405246657691779225<br/>weibo.com/ttarticle/p/show?id=2309405246658140569735会在未来被越来越多的机器人厂商所采纳，从而在某些程度上改变行业的全球布局。</p>]]></description></item><item>    <title><![CDATA[【完整回放】2022 HVV实战专题 梓源 ]]></title>    <link>https://segmentfault.com/a/1190000047494665</link>    <guid>https://segmentfault.com/a/1190000047494665</guid>    <pubDate>2025-12-22 22:02:15</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>HVV 红蓝对抗流程：教育视角下的信息安全培训<br/>引言<br/>随着信息技术的迅猛发展，网络安全成为了各个行业的重要课题。在这个背景下，HVV（红蓝对抗）作为一种有效的网络安全演练方式，越来越受到重视。红蓝对抗通过模拟攻击（红队）与防御（蓝队）的对抗，帮助组织识别安全漏洞，并提高整体安全防护水平。本文将从教育视角出发，探讨HVV红蓝对抗中的信息收集、内网横向攻击和蜜罐反制等关键流程及其在信息安全培训中的应用。<br/>一、信息收集</p><ol><li>信息收集的意义<br/>在红蓝对抗的第一阶段，信息收集是红队成功攻击的基础。这一阶段主要目的是获取目标环境的相关信息，包括网络拓扑、开放端口、服务、系统版本等。通过系统化的信息收集，红队能够制定有效的攻击策略。</li><li>教育实践中的应用<br/>在信息安全培训中，教育者可以通过模拟演练让学员掌握信息收集的技能。以下是几个推荐的培训活动：</li></ol><p>1.工具介绍与实践：教授学员使用工具如Nmap、Recon-ng等进行网络扫描和信息收集。<br/>2.案例分析：分析历史上的网络攻击案例，让学员识别信息收集如何影响攻击结果。<br/>3.小组合作：组织学员团队进行攻防对抗演练，增强协作与实践能力。</p><p>二、内网横向攻击</p><ol><li>横向攻击的概念<br/>内网横向攻击是在入侵成功后，利用已获得的权限继续渗透内网其他系统。这一过程涉及许多技术手段，比如凭证盗窃、利用信任关系等。</li><li>教育实践中的应用<br/>在内网攻击的教育培训中，可以通过设计完整的攻防演练以提高学员的意识和技能：</li></ol><p>4.红队攻击演示：由专业人员演示如何在内网内进行横向攻击，包括使用Mimikatz等工具。<br/>5.蓝队防御策略：教授蓝队如何监控和防止横向攻击，例如，通过网络流量分析和用户行为监测工具识别异常活动。<br/>6.实战演练：模拟真实环境中的内网攻击，让学员在对抗中学习和应用防御策略。</p><p>三、蜜罐反制</p><ol><li>蜜罐技术概述<br/>蜜罐是一种主动防御技术，旨在通过设置虚假的脆弱系统或服务，引导攻击者进行攻击，从而收集数据和分析其行为。这对于识别攻击模式与手法，提升防御能力具有重要意义。</li><li>教育实践中的应用<br/>在信息安全教育中，蜜罐的应用可帮助学生深化对网络攻击行为的理解：</li></ol><p>7.蜜罐的搭建与配置：手把手教导学生如何创建和配置蜜罐系统，理解其工作原理及价值。<br/>8.攻击数据分析：分析通过蜜罐收集到的攻击数据，帮助学生识别攻击者的行为模式和常用工具。<br/>9.开发反制策略：培训学员利用蜜罐数据制定更有效的网络防护措施，提高整体安全防护能力。</p><p>结语<br/>通过HVV红蓝对抗流程的全面介绍，可以看出信息安全教育在现代网络防护体系中的重要性。信息收集、内网横向攻击和蜜罐反制，这些环节既是红蓝对抗的基本组成部分，也可以有效地融入信息安全培训之中。教育者通过设计科学的教学活动，使学员能够在实践中巩固理论知识，提升自身的安全防护能力，从而更好地应对日益复杂的网络安全挑战。</p>]]></description></item><item>    <title><![CDATA[kubernetes实战与源码剖析-专享 资源999it点top ]]></title>    <link>https://segmentfault.com/a/1190000047494668</link>    <guid>https://segmentfault.com/a/1190000047494668</guid>    <pubDate>2025-12-22 22:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>Kubernetes 实战与源码剖析：核心组件运行机制与企业级部署全解析<br/>Kubernetes（K8s）作为现代云原生架构中的核心技术之一，已经成为企业级应用部署与管理的标准。自2014年由Google开源以来，Kubernetes以其强大的容器编排能力、灵活的扩展性和高可用性，逐渐形成了一套成熟的生态体系。本文将从教育、科技、人文发展和经济等多个角度深入探讨Kubernetes的核心组件及其企业级部署所带来的变革。<br/>教育：培养未来的IT人才<br/>随着Kubernetes的普及，相关的教育培训也应运而生。开发者、运维工程师以及IT管理人员需要掌握K8s的基础知识和实践能力。越来越多的高等院校以及职业培训机构开始开设Kubernetes相关课程，帮助学生和职场人士提升技能。<br/>此外，在线教育平台如Coursera、Udemy等也提供了丰富的Kubernetes课程。Kubernetes的学习不仅促进了计算机科学的学术研究，更推动了实践与理论的结合。通过实际项目的训练，学员们能够更好地理解Kubernetes的工作机制，从而有助于未来的职场竞争力。<br/>科技：推动技术的演进与创新<br/>Kubernetes的出现大大提升了云计算技术的灵活性与可管理性。它通过抽象化基础设施，使得开发者可以专注于应用程序的开发，而不必过于关注底层环境的配置。这种分离不仅提高了开发效率，也加速了新技术的迭代与创新。<br/>在技术演进方面，Kubernetes支持微服务架构，在大规模分布式系统中表现尤为出色。通过Docker等容器技术，K8s让应用的构建、测试、交付与部署过程变得更加自动化与标准化。此外，其丰富的生态工具链，例如Helm、Istio和Prometheus等，进一步增强了Kubernetes的功能，使得开发者和运维工程师能够更高效地管理复杂的微服务环境。<br/>人文发展：影响团队合作与文化<br/>Kubernetes的 adoption 不仅局限于技术层面，它还引发了文化与团队合作的变革。随着DevOps理念的深入，K8s使得开发与运维之间的墙变得模糊，促进了跨部门的协作。团队中的开发人员可以更快速地反馈和迭代，运维人员则通过集中的管理面板和自动化的监控工具减轻了日常运维的负担。<br/>此外，Kubernetes的开源特性使得全球的开发者能够参与到生态建设中，推动了一种共享知识和资源的文化。无论是通过贡献代码、解决Bug，还是撰写文档和教程，K8s的社区能够促进人们之间的合作和交流，成为一种推动技术人文发展的力量。<br/>经济：促进企业的数字化转型<br/>在经济层面，Kubernetes的企业级应用能够显著降低IT基础设施的成本，提高资源利用率。K8s的弹性扩展能力使得企业能够根据需求进行资源的灵活配置，从而避免了资源的浪费。这对于预算有限的中小企业尤为重要，它们可以在不进行大规模投资的情况下，充分利用云计算带来的灵活性。<br/>同时，使用Kubernetes的企业能够更快速地实现产品的上线和迭代，使企业在市场竞争中保持灵活性和响应速度。这种高效的开发和运维流程，使得企业能够更好地满足客户需求，从而提升整体业务的竞争力。<br/>结论<br/>Kubernetes的核心组件和企业级部署不仅在技术领域产生了深远影响，也在教育、人文和经济层面引发了一系列变革。无论是推动技术的创新与应用，还是促进团队文化的变革、帮助企业实现数字化转型，Kubernetes都以其独特的方式在现代科技的发展进程中扮演着重要角色。<br/>在未来，随着Kubernetes生态的不断完善，我们有理由相信，将有更多的机会去探索这一技术所带来的可能性，并为相关领域的进一步发展做出贡献。</p>]]></description></item><item>    <title><![CDATA[每日一个C++知识点|对象资源传递机制 图形学爱好者Wu ]]></title>    <link>https://segmentfault.com/a/1190000047494605</link>    <guid>https://segmentfault.com/a/1190000047494605</guid>    <pubDate>2025-12-22 21:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>C++是一门对内存资源配置要求较高的语言，其中对象资源传递在C++开发中无处不在，下面我将在浅拷贝、深拷贝、左值右值、移动语义、完美转发这5个方面层层递进地讲解C++对象资源传递机制，争取做到知识串联，深入浅出~</p><h2>浅拷贝</h2><p>我们从一个实际场景入手：写一个Image类，存储图片的像素数据，代码如下：</p><pre><code class="cpp">#include &lt;iostream&gt;
using namespace std;

// 图片类：管理堆内存中的像素数据
class Image {
public:
    // 构造函数：分配堆内存（相当于“买快递箱装图片数据”）
    Image(int w, int h) : width(w), height(h) {
        // 每个像素占4字节（RGBA），分配一大块堆内存
        pixels = new char[width * height * 4]; 
        cout &lt;&lt; "构造函数：分配内存，图片尺寸：" &lt;&lt; width &lt;&lt; "x" &lt;&lt; height &lt;&lt; endl;
    }

    // 析构函数：释放堆内存（相当于“扔掉快递箱”）
    ~Image() {
        if (pixels != nullptr) {
            delete[] pixels;
            cout &lt;&lt; "析构函数：释放了内存" &lt;&lt; endl;
        }
    }

private:
    int width, height;
    char* pixels; // 指向像素数据的指针（核心资源）
};

int main() {
    Image img1(1000, 1000); // 创建1000x1000的图片
    Image img2 = img1;      // 拷贝img1到img2
    return 0;
}</code></pre><p>这段代码看起来没问题，却会触发内存错误。原因就是编译器默认拷贝方式是<br/><code>浅拷贝</code></p><p>那么什么是浅拷贝呢？浅拷贝只拷贝成员变量的值，不拷贝资源本身，会造成两个对象共享同一块堆内存，相当于两个快递单号指向同一个快递箱。当多个对象共享资源，析构函数运行时就会崩溃。在上述代码中只把<code>img1</code>的<code>pixels</code>指针地址复制给<code>img2</code>,没有把资源本身复制一份，导致程序结束后<code>析构时双重释放</code>，<code>img2</code>先析构释放内存，<code>img1</code>析构时又去释放已经被释放的内存，直接崩溃</p><h2>深拷贝</h2><p>那么怎么解决浅拷贝带来的程序崩溃问题呢？一个简单的方法是使用<code>深拷贝</code>。深拷贝不仅拷贝成员变量，还为新对象重新分配资源并复制数据，使每个对象拥有独立资源，提升安全性。下面我们给<code>Image</code>类添加深拷贝构造函数（在原有代码的基础上直接添加，其他地方保持不变）：</p><pre><code class="cpp">// 深拷贝构造函数：参数是const左值引用（const 类名&amp;）
Image(const Image&amp; other) {
    // 第一步：复制基础属性
    width = other.width;
    height = other.height;
    // 第二步：关键！重新分配新的堆内存（买新快递箱）
    pixels = new char[width * height * 4]; 
    // （实际开发中会复制像素数据，这里重点是“新分配内存”）
    cout &lt;&lt; "深拷贝构造函数：新分配了内存" &lt;&lt; endl;
}</code></pre><p>以上拷贝构造函数会在编译器中自动执行，因而无需在main函数添加。</p><p>此时再运行代码，<code>img1</code>和<code>img2</code>各自拥有独立内存，程序正常结束。但是深拷贝的内存分配和数据复制会带来巨大性能开销，如果是为了处理临时数据而产生这么大的开销，有点浪费资源。那么我们可不可以在深拷贝完成之后对临时数据进行删除呢？</p><p>假设我们有一个函数，生成一张临时的<code>Image</code>对象:</p><pre><code class="cpp">// 返回临时Image对象（无名字，是“即将销毁”的右值）
Image createWhiteImage(int w, int h) {
    Image temp(w, h);
    return temp;
}</code></pre><p>因为<code>Image temp(w, h)</code>是在函数里实现的，也就是在栈内实现的，所以对象在函数执行时可以自动创建，函数运行结束后自动释放销毁;</p><p>再用深拷贝接收这个临时对象：</p><pre><code class="cpp">Image img3 = createWhiteImage(2000, 2000); // 深拷贝：耗时耗内存</code></pre><p>这样就实现了在深拷贝完成之后对临时数据进行删除，但是这就像 “把快递里的东西复制一份，再把原快递箱扔掉”，完全没必要，这时候移动语义就该登场了。</p><h2>左值和右值</h2><p>在了解移动语义之前，我们需要了解一个重要的概念——<code>左值</code>和<code>右值</code></p><p>左值通常在等号左边，右值通常在等号右边，<code>但是</code>，<code>左值并非是在等号左边的对象，右值也并非是在等号右边的对象</code></p><p>左值是有名字、能取地址的对象，是持久存在 的对象。</p><p>右值是无名字、不能取地址的临时对象，是即将销毁的对象。</p><p>在上述代码中，<code>img1</code>是左值，<code>int a = 10</code>;中的<code>a</code>是左值;<code>createWhiteImage()</code>的返回值是右值。了解左值和右值的基本概念后，我们就能在移动语义中使用它们了~</p><h2>移动语义</h2><p>移动语义本质是转移右值的资源所有权，而非执行资源拷贝，所以可以达到减少资源浪费的效果</p><h3>移动构造函数</h3><p>要实现移动语义，需要给Image类添加移动构造函数：</p><pre><code class="cpp">// 移动构造函数：参数是右值引用（类名&amp;&amp;），通常加noexcept
Image(Image&amp;&amp; other) noexcept {
    // 第一步：“偷”走源对象的资源（仅复制指针地址，无内存分配）
    width = other.width;
    height = other.height;
    pixels = other.pixels;

    // 第二步：关键！将源对象置为空（作废原快递单号，避免析构冲突）
    other.pixels = nullptr;
    other.width = 0;
    other.height = 0;

    cout &lt;&lt; "移动构造函数：直接转移资源，无内存分配！" &lt;&lt; endl;
}</code></pre><p>此时再接收临时对象：</p><pre><code class="cpp">Image img3 = createWhiteImage(2000, 2000); // 触发移动构造，瞬间完成</code></pre><p>这就像 “直接把快递箱的地址改成自己的，不用复制里面的东西”，性能直接拉满~</p><h3>std::move</h3><p><code>std::move</code>是把左值 “伪装” 成右值的小工具，如果想把左值的资源转移给其他对象，可以用<code>std::move</code></p><pre><code class="cpp">Image img4(1500, 1500); // 左值
Image img5 = std::move(img4); // 触发移动构造，img4变为空</code></pre><p>注意：它只是强制转换类型，不会真的移动数据</p><h2>完美转发</h2><p>移动语义解决了临时对象的拷贝问题，但在模板函数中，会遇到新问题：参数的左值和右值属性会丢失。</p><p>如下代码所示：</p><pre><code class="cpp">template &lt;typename T&gt;
void wrapper(T x) {
    Image img = x; // 无论x是左值还是右值，都触发深拷贝
}

// 调用：传入右值，却还是深拷贝
wrapper(createWhiteImage(1000, 1000));</code></pre><p>由于模板参数x是拷贝后的对象，已经变成了左值，丢失了原来的右值属性</p><p>这时候需要用到<code>完美转发</code>来解决上述问题，<code>完美转发</code>在模板中保留参数的左值 / 右值属性，它需要两个核心要素：<code>万能引用</code>和<code>std::forward</code></p><h3>万能引用</h3><p><code>T&amp;&amp;</code>是万能引用符号，仅在模板中使用，能绑定左值或右值</p><h3>std::forward</h3><p><code>std::forward</code>：根据参数的原始类型，转发为左值或右值</p><p>用代码举例如下：</p><pre><code class="cpp">template &lt;typename T&gt;
void wrapper(T&amp;&amp; x) { // 万能引用
    Image img = std::forward&lt;T&gt;(x); // 完美转发：保留属性
}

// 测试：属性保留
Image img6(800, 800);
wrapper(img6); // 传入左值，触发深拷贝（符合预期）
wrapper(createWhiteImage(800, 800)); // 传入右值，触发移动构造</code></pre><p>完美转发就像 “快递包装不拆，直接原封不动转发”，确保参数的属性不丢失。</p><h2>总结</h2><p>以上便是C++对象资源传递机制的主要内容，从浅拷贝、深拷贝、左值右值、移动语义、完美转发层层递进，如下图所示：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047494607" alt="" title=""/></p><ol><li>浅拷贝：绝对禁用（除非类无动态资源），会导致内存崩溃。</li><li>深拷贝：解决浅拷贝的内存崩溃，但需要更多内存开销。</li><li>移动语义：处理右值的性能方案，用资源转移代替拷贝，std::move可把左值转为右值。</li><li>完美转发：在模板中使用，保障移动语义在参数传递中生效。</li></ol><p>如果这篇文章文章对你有用的话, 欢迎点赞收藏加关注哦~</p>]]></description></item><item>    <title><![CDATA[硬件+软件协同交付怎么落地？2025 软硬件项目管理工具对比 研之有李 ]]></title>    <link>https://segmentfault.com/a/1190000047494367</link>    <guid>https://segmentfault.com/a/1190000047494367</guid>    <pubDate>2025-12-22 20:02:53</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>本文深度测评 ONES、Polarion、Codebeamer、Helix ALM、Jama Connect、SpiraTeam、Nuxeo、Hansoft、Nifty 等软硬件协同管理工具，帮助团队打通需求-缺陷-版本管理全流程。</p><h2>软硬件协同交付的难点</h2><p>在复杂系统研发里，软件团队习惯以迭代节奏驱动交付，硬件团队则以阶段评审与变更控制驱动质量。两种节奏并行并不矛盾，真正让项目失控的往往是：软硬件共享的关键对象没有被同一套机制锁定、追溯与复现。</p><p>我把常见痛点归为四类，但每一类背后都指向同一个本质——“对象与链路的缺失”：</p><ul><li>需求追溯断点：系统需求 → 子系统需求 → 软硬件分解需求 → 设计/实现 → 测试验证之间缺少稳定链接，影响分析只能靠经验与会议。</li><li>变更与版本对齐困难：硬件 ECR/ECN、固件/软件版本、测试基线、发布包（制品）各自为政，出现“同名不同物”，最后反噬质量与周期。</li><li>验证闭环效率低：测试结果停留在报告，没回到需求与缺陷对象上沉淀，回归成本上升，质量趋势难量化。</li><li>组织协同摩擦大：系统工程、硬件、嵌入式、应用、测试、供应商使用不同系统，信息在 IM、邮件、表格漂移，责任边界与决策记录不清晰。</li></ul><p>因此，讨论“软硬件项目管理工具”时，我更关心的不是看板够不够炫，而是它能否承载一条可运行的 ALM 数字主线（Digital Thread）：把需求管理、缺陷管理、版本管理、制品管理放进同一套“对象—关系—基线—证据”的体系。</p><h2>软硬件协同管理工具盘点与对比</h2><h4>ONES——集成化、本地化与软硬件协同落地的现实路径</h4><p>核心功能与定位：<a href="https://link.segmentfault.com/?enc=e5avVvM9zgTPFYHt%2BxXqzg%3D%3D.pnHP2SxjdQvt6WKOD2GO%2Bg%3D%3D" rel="nofollow" target="_blank">ONES</a> 研发管理平台覆盖流程、进度、协作、效能改进等，并支持 Agile / Waterfall / Hybrid 乃至 IPD 等不同方法论在同一套流程与数据上协同；同时提供企业级权限与审计等治理能力，适配云或本地部署的合规要求。</p><p>适用场景：</p><ul><li>软硬件并行交付需要统一节奏与透明化协同；</li><li>希望降低工具碎片化与集成成本，用一体化平台先跑通“需求—执行—测试—交付协作”的主干，再逐步扩展工具链；</li><li>在硬件研发管理上，ONES 能把硬件项目最关键的“计划—里程碑—依赖—变更协同”做成可执行的工程节奏；</li><li>在软件研发管理上，ONES 更接近 ALM 的“闭环能力”，强调覆盖 需求管理、路线图、迭代（Sprint）管理、质量控制、发布管理等生命周期关键环节。</li></ul><p>优势亮点：</p><ul><li>一体化降低推广成本：很多组织不是“工具买不起”，而是“流程推不动”。平台集成度越高，PMO 越容易建立统一模板、度量口径与跨团队协作机制。</li><li>本地化落地更可控：在私有化、合规、培训与持续运营上，本地化支持往往决定了工具是否能成为组织能力的一部分。</li></ul><p>局限性：</p><p>若组织追求某些系统工程专用能力的“极致深度”，仍建议用 POC 验证追溯粒度、复杂权限与跨域集成上限。<br/><img width="723" height="374" referrerpolicy="no-referrer" src="/img/bVdhI10" alt="" title=""/></p><h4>Polarion（Siemens）</h4><p>核心功能与定位：强调在统一平台定义、构建、测试与管理复杂系统，并保持端到端可追溯与可视化；同时强调面向审计/合规的追溯与变更控制能力。</p><p>适用场景：当你的组织需要系统工程级追溯、合规审计证据、跨团队协作的“单一事实源（Single Source of Truth）”，Polarion 更容易体现价值。</p><p>优势亮点：</p><ul><li>追溯不是报表，而是决策机制：影响分析从“开会问人”变成“在关系图上确认范围”，这会直接改变变更治理效率。</li><li>适合做组织级模板化：把 IPD 评审点、基线策略、交付证据输出固化为可复用资产，越大规模越有复利。</li></ul><p>局限与不足：</p><p>推行成本主要在“治理”而非“安装”：数据模型、权限边界、评审门禁要先统一。<br/>如果组织还未建立基线纪律，平台越强，反而越暴露管理短板——这不是坏事，但要有心理预期。<br/><img width="723" height="357" referrerpolicy="no-referrer" src="/img/bVdnnys" alt="" title="" loading="lazy"/></p><h4>Codebeamer（PTC）</h4><p>核心功能与定位：官方强调“需求管理 + 风险 + 测试与验证 + 产品线管理能力”在一个平台内，并主打“连接式 ALM”；同时提到可与 CI/CD、源码、PLM 等工具联动，服务更大的数字主线。</p><p>适用场景：多版本并行、变体/产品线工程、受监管行业（质量与合规压力高），以及希望把 ALM 放进更大的数字主线架构的组织。</p><p>优势亮点：</p><ul><li>把风险拉回主线：风险与需求、验证联动，比“表格式风险管理”更能落地到工程动作。</li><li>可配置性适合复杂流程：对成熟 PMO/质量体系团队，能把流程沉淀为平台能力。</li><li>局限与不足：</li><li>可配置意味着需要能力：没有流程架构与平台治理能力时，容易“配置过度/流程过重”。</li></ul><p>建议从一个产品线或一个系统域试点，把追溯粒度、基线与审批机制定住，再扩张。</p><h4>Helix ALM（Perforce）</h4><p>核心功能与定位：以需求、测试、缺陷/问题为核心对象形成追溯闭环；适合把验证结果与缺陷处理纳入同一条主线。</p><p>适用场景：嵌入式/工业软件团队想先把“需求—测试—缺陷”跑通，并逐步接入自动化验证与证据沉淀。</p><p>优势亮点：当验证证据能够回链到需求与缺陷，质量趋势才有统计意义，回归成本也更可控（尤其是多版本并行时）。</p><p>局限与不足：在“跨硬件变更、供应商协作、复杂门禁”上通常还要补集成与治理设计，才能形成真正端到端数字主线。</p><h4>Jama Connect（Jama Software）</h4><p>核心功能与定位：偏“需求与评审协作 + 追溯与影响分析”。其官方特性页明确 Review Center 用于实时协作评审与集中管理评审意见/批准记录。</p><p>适用场景：需求评审频繁、跨组织对齐成本高、且希望把评审记录纳入审计证据的系统工程团队（含供应商与外协参与）。</p><p>优势亮点：把评审从会议纪要变成结构化证据：对合规行业来说，评审记录往往就是审计准备工作量的大头。在 Jama 的公开内容中，也能看到关于缩短评审周期与降低审计准备时间的案例口径（建议按自身流程用 POC 验证）。</p><p>局限与不足：Jama 更强在需求与评审侧；要形成“从需求到制品”的发布闭环，通常仍需与开发、构建、制品库等工具链组合。</p><h4>SpiraTeam（Inflectra）</h4><p>核心功能与定位：倾向把需求、测试、计划、风险与缺陷整合为“基础 ALM 闭环”。<br/>适用场景：中型团队希望较快获得“闭环感”：需求能落到测试、缺陷能回到需求、发布有证据可查。</p><p>优势亮点：对“先跑通、再优化”的组织更友好：先建立对象体系与追溯，再谈规模化与深度集成。</p><p>局限与不足：面对多组织、多供应商、强合规的大规模场景时，数据模型/权限/流程会更快触顶，需要更强平台或更成熟的组合方案。</p><h4>Hansoft（规划侧更强）</h4><p>核心功能与定位：偏研发计划、组合与节奏治理，适合把多团队的里程碑与迭代节奏拉齐。</p><p>适用场景：硬件阶段门禁（EVT/DVT/PVT 等）与软件迭代并行，需要“节奏对齐 + 资源协调”的 PMO。</p><p>局限与不足：Hansoft 更像推进层补强；审计级追溯与证据链仍建议回到 ALM 主干。</p><p>ALM/系统工程工具的关键，不是“多功能”，而是能否把追溯链与基线机制做成组织级的默认动作。</p><h4>Nuxeo（Hyland Nuxeo）</h4><p>核心功能与定位：更像内容服务平台（Content Services）与数字资产底座；官方文档明确其提供原生 REST API，用于远程集成与构建自定义界面/能力。</p><p>适用场景：</p><p>大量规范、设计文档、验证报告、供应商资料需要版本/权限/流程/审计统一；<br/>希望把“证据库”与 ALM 主线关联，形成可审计的交付链。</p><p>优势亮点：把证据当资产管理：当组织进入合规与规模化交付阶段，证据不是“交付后补材料”，而应该伴随对象自然生成并归档。</p><p>局限与不足：它不替代 ALM 主线；如果证据无法回链到需求/测试/缺陷对象，最终仍会变成“更大的资料库”。</p><p>内容平台的价值在“证据可治理、可复用”，但前提是证据必须回链到工程对象。</p><h2>2025 的演进趋势与选型建议</h2><p><strong>趋势判断（你可以用作年度规划的判断框架）：</strong></p><ul><li>ALM 更强调单一事实源与合规追溯</li><li>“需求评审 + 证据链”产品化加速</li><li>数字主线从口号走向工程落地</li><li>本地化与可运营性成为现实权重</li></ul><p>不同规模与行业的建议（给硬件研发经理 / 系统工程 / PMO / 研发总监）：</p><ul><li>中小团队（几十人）：优先“最小闭环可运行”，一体化更容易落地；目标是把需求、缺陷、测试与发布证据先连起来。</li><li>中大型组织（数百到数千人）：采用“三层架构”，系统记录层先稳定，再用推进层做组合治理，用证据层做资产沉淀；避免一次性铺开导致推广失败。</li><li>强合规行业（汽车/医疗/工业控制等）：把“追溯、基线、证据链”放在第一优先级，推进效率排第二；合规不是文档工作量，而是工程对象是否可审计、可复现。</li></ul><p>硬件研发数字化转型的本质，是把系统工程与 IPD 的治理逻辑固化为“可复用的流程资产 + 可审计的数据资产”。当你用 ALM 数字主线把需求、缺陷、版本、制品锁进同一条链，软硬件协同交付才真正具备规模化复制能力。</p><h2>FAQ</h2><p>Q1：软硬件协同交付到底需要哪些“软件能力”？<br/>A：至少要具备需求管理、缺陷管理、版本管理、制品管理，并用测试管理与变更管理把证据链闭环，比如 ONES 等；协作工具只解决推进，不能替代审计级追溯。</p><p>Q2：一体化平台和最佳组合怎么选？<br/>A：如果你们的主矛盾是“推广与统一口径”，一体化更稳；如果你们有强集成能力与成熟治理体系，最佳组合可以在特定环节做到极致，但维护成本更高。</p><p>Q3：为什么我用了很多工具，交付还是混乱？<br/>A：通常是“基线策略缺失 + 追溯粒度不统一”。没有基线，版本与制品无法复现；没有统一追溯，影响分析与审计证据只能靠人扛。</p>]]></description></item><item>    <title><![CDATA[Verilog端口类型解析 星星上的柳树 ]]></title>    <link>https://segmentfault.com/a/1190000047494374</link>    <guid>https://segmentfault.com/a/1190000047494374</guid>    <pubDate>2025-12-22 20:02:03</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>“理解端口类型，是Verilog模块设计的关键。”<br/>在Verilog设计中，端口是模块与外界交互的桥梁。不同类型的端口——输入、输出与双向——在数据流向与信号驱动方式上有着严格的规则。若定义不当，不仅会引发编译错误，还可能导致仿真行为与硬件实现不一致。掌握Verilog端口类型的使用原则，能帮助设计者构建结构清晰、逻辑可靠的电路系统。</p><p>1、端口类型与信号流向Verilog模块的端口可分为三类：输入端口（input）、输出端口（output）和双向端口（inout）。它们决定了信号在模块间的流动方向，并影响端口的数据类型与驱动方式。输入端口：信号从外部流入模块内部。输出端口：模块内部生成信号并输出至外部。双向端口：信号可在模块间双向流动，常用于总线接口。<br/>端口类型不仅定义通信方向，更隐含了信号驱动规则：哪些信号可以被过程赋值、哪些必须通过连续赋值驱动。</p><p>2、输入端口：永远是nets在Verilog中，输入端口（input）始终被视为net类型。这意味着输入端口不能在过程块（always或initial中）被赋值，而只能接收外部驱动。<br/>例如：module adder (  input [3:0] a, b,  output [4:0] sum);  assign sum = a + b;endmodule<br/>这里，输入端口a与b都是nets类型，用于连接外部信号源。Verilog之所以规定输入端口为net，是因为它们仅承担信号传递功能，不具备存储能力。<br/>注意：若在模块内试图对输入端口赋值，如a = 1;，编译器会报错——因为nets不能在过程块中驱动。</p><p>3、输出端口：由驱动方式决定类型输出端口（output）的类型取决于其驱动方式，这一特性是Verilog端口规则的核心。若输出由过程块（如always）驱动，则必须声明为变量（reg或logic）类型。若输出由连续赋值（assign）语句驱动，则应为net类型。<br/>示例1（连续赋值驱动）：module and_gate (  input a, b,  output y);  assign y = a &amp; b;  // y为net类型endmodule<br/>示例2（过程赋值驱动）：module dff (  input clk, d,  output reg q);  always @(posedge clk)    q &lt;= d;           // q为变量类型endmodule<br/>这种区分源于Verilog的设计哲学：连续赋值用于组合逻辑，过程赋值用于时序逻辑。若错误声明输出类型，会导致编译器拒绝执行或仿真异常。例如，在过程块中驱动一个net类型输出，将产生非法赋值错误。</p><p>4、双向端口：始终为nets双向端口（inout）用于信号在模块间的双向流动，例如数据总线或IO接口。Verilog规定，双向端口必须为net类型，以确保信号的共享与驱动一致性。<br/>示例：module io_buffer (  inout wire data);  assign data = enable ? out_data : 1'bz; // 高阻态控制输出endmodule<br/>在此例中，data可根据控制信号enable决定是否驱动输出。当enable关闭时，data进入高阻态（z），允许外部模块驱动该信号。<br/>双向端口通常在FPGA或ASIC设计中用于总线系统，要求信号线在不同模块之间协调驱动，否则会出现信号冲突。</p><p>5、常见错误与调试建议Verilog端口类型规则明确，但新手在实践中常犯以下错误。过程赋值给netsalways @(posedge clk)  y = d; // 错误：nets不能在过程块中赋值正确做法是将输出定义为变量：output reg y;<br/>输出端口类型声明错误如果输出端口未被过程块驱动，却声明为reg，也会引发语义冲突。output reg y;  assign y = a &amp; b; // 错误：reg不能由assign驱动正确写法应为：output y;assign y = a &amp; b;<br/>双向端口错误声明为变量双向端口必须是net，否则多个驱动器会引发逻辑冲突：inout reg data; // 错误应改为：inout wire data;<br/>端口方向混淆部分初学者在设计模块时忽略信号方向，导致数据流不一致。应确保上层模块的输出连接下层模块的输入，双向端口则需明确高阻态控制。</p><p>6、Verilog-2001的改进：端口内联声明在Verilog-2001标准中，允许在模块头部直接定义端口类型与方向：module adder (  input wire [3:0] a, b,  output reg [4:0] sum);<br/>这种写法既简洁又直观，避免了早期Verilog-1995中必须分两步声明的繁琐结构。此外，现代工具也支持logic关键字替代reg，使代码兼容性更强。</p><p>7、端口类型选择的设计原则总结Verilog端口类型规则：<br/><img width="723" height="166" referrerpolicy="no-referrer" src="/img/bVdnrCr" alt="" title=""/><br/>设计时的关键思路是：谁驱动信号，就决定信号的类型。组合逻辑使用nets，时序逻辑使用reg，双向接口保持net结构。<br/>端口是模块交互的语言，类型是这门语言的语法。理解输入、输出与双向端口的类型规则，是写出可综合、高可靠Verilog代码的基础。掌握端口类型与驱动的关系，就能在设计初期避免许多低级错误，让电路在仿真与硬件中都能“说得通”。</p><pre><code>                    END</code></pre><p>《EDA网院》出品 · 与全球工程师一起探索芯片的世界</p>]]></description></item><item>    <title><![CDATA[Linux 麒麟系统安装 gcc-7.3.0 rpm 包步骤 无邪的课本 ]]></title>    <link>https://segmentfault.com/a/1190000047494389</link>    <guid>https://segmentfault.com/a/1190000047494389</guid>    <pubDate>2025-12-22 20:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>​</p><ol><li>找到 rpm 文件</li></ol><p><strong>安装包下载：</strong><a href="https://link.segmentfault.com/?enc=BKVJwZz2pP%2Bw0luTfFd%2FAQ%3D%3D.4KR6dxHrr4gqbg15fMrohDVrTuGTabJuCRSj9Fe3Jyy7K5p054K%2FRYq7t3Qs5roY" rel="nofollow" title="https://pan.quark.cn/s/9aac910b9f81" target="_blank">https://pan.quark.cn/s/9aac910b9f81</a>，下载完一般在 <strong>下载</strong>​ 目录，文件名：</p><pre><code>gcc-7.3.0-20190804.35.p06.ky10.x86_64.rpm</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000041378096" alt=" title=" title=" title="/></p><p>先确认一下：</p><pre><code>ls ~/下载/gcc-7.3.0*</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000041378096" alt=" title=" title=" title=" loading="lazy"/></p><p>如果是英文环境：</p><pre><code>ls ~/Downloads/gcc-7.3.0*</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000041378096" alt=" title=" title=" title=" loading="lazy"/></p><ul><li><ul><li>*</li></ul></li></ul><h3>2. 打开终端</h3><p>右键桌面 → “打开终端”，或者按 <code>Ctrl + Alt + T</code>。</p><ul><li><ul><li>*</li></ul></li></ul><h3>3. 切换到 rpm 所在目录</h3><pre><code>cd ~/下载</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000041378096" alt=" title=" title=" title=" loading="lazy"/></p><p>英文路径：</p><pre><code>cd ~/Downloads</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000041378096" alt=" title=" title=" title=" loading="lazy"/></p><ul><li><ul><li>*</li></ul></li></ul><h3>4. 检查是否已经安装了 gcc</h3><p>先试试：</p><pre><code>gcc --version</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000041378096" alt=" title=" title=" title=" loading="lazy"/></p><p>如果提示 “command not found” 就是没装；如果有版本号，想换版本就继续往下看。</p><ul><li><ul><li>*</li></ul></li></ul><h3>5. 安装 rpm 包</h3><p><strong>推荐方法</strong>（会自动装依赖）：</p><pre><code>sudo yum install ./gcc-7.3.0-20190804.35.p06.ky10.x86_64.rpm</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000041378096" alt=" title=" title=" title=" loading="lazy"/></p><p>注意 <code>./</code> 不要漏，表示安装当前目录的文件。</p><p>如果用 rpm 直接装（不推荐，容易缺依赖）：</p><pre><code>sudo rpm -ivh gcc-7.3.0-20190804.35.p06.ky10.x86_64.rpm</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000041378096" alt=" title=" title=" title=" loading="lazy"/></p><p>如果报错缺少依赖，就用 yum 补包，比如：</p><pre><code>sudo yum install glibc-devel</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000041378096" alt=" title=" title=" title=" loading="lazy"/></p><ul><li><ul><li>*</li></ul></li></ul><h3>6. 验证安装结果</h3><p>装完后运行：</p><pre><code>gcc --version</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000041378096" alt=" title=" title=" title=" loading="lazy"/></p><p>看到类似：</p><pre><code>gcc (Kylin) 7.3.0</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000041378096" alt=" title=" title=" title=" loading="lazy"/></p><p>说明安装成功。</p><ul><li><ul><li>*</li></ul></li></ul><h3>7. 常见问题</h3><ul><li><strong>权限不够</strong>：命令前加 <code>sudo</code>。</li><li><strong>依赖缺失</strong>：尽量用 <code>yum install</code> 安装 rpm 包，让系统自己找依赖。</li><li><p><strong>已有旧版本</strong>：可先卸载：</p><pre><code>sudo yum remove gcc</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000041378096" alt=" title=" title=" title=" loading="lazy"/></p></li><li><strong>安装后命令找不到</strong>：关闭终端重新打开，或执行 <code>source ~/.bashrc</code>。</li></ul><p>​</p>]]></description></item><item>    <title><![CDATA[推荐用于制造业的设备智能助手有哪些核心功能与应用场景？ 雨大王 ]]></title>    <link>https://segmentfault.com/a/1190000047494197</link>    <guid>https://segmentfault.com/a/1190000047494197</guid>    <pubDate>2025-12-22 19:05:19</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>设备智能助手的定义与核心功能<br/>在现代制造业转型升级的关键阶段，人工智能技术的引入正在重构生产管理的智能化水平。设备智能助手作为这一趋势的核心产物，本质上是一种基于人工智能技术的生产辅助系统，它能够通过多模态感知、知识推理和自然语言交互，为生产管理者、工艺工程师和一线操作人员提供实时决策支持和问题解决方案。<br/>设备智能助手的核心价值在于其具备跨领域知识整合能力和实时响应能力，它不仅仅是一个工具，更是制造业知识体系的数字化载体。例如，在注塑生产线管理中，智能助手可以同时理解材料特性、模具设计、温度控制、设备运行数据等多维度信息，实现从“经验驱动”到“数据驱动”的管理范式转变。<br/>其功能体系主要包括：<br/>即时问题诊断：面对设备故障或生产异常时，系统可在数秒内完成多维度分析，提供从简单排查到复杂修复的建议；<br/>工艺优化指导：基于历史数据和行业最佳实践，推荐参数组合并预测效果；<br/>质量标准解读：针对模糊或争议的检测标准，提供权威解释和操作参考；<br/>动态学习能力：通过持续交互不断优化知识库，适应不同企业的个性化需求。<br/>设备智能助手在制造业中的关键作用<br/>在制造业的生产现场中，设备智能助手扮演着“技术参谋”与“生产管家”双重角色。它不仅提高了生产效率，还显著降低了因设备异常、工艺失误和质量波动所导致的生产风险与成本。<br/>提升响应速度是智能助手带来的最直观改变。当生产线突发异常时，传统响应流程可能需要等待技术专家或查阅大量文档，而智能助手能够在几分钟内提供解决方案。<br/>增强决策科学性也是其重要优势。设备智能助手通过融合实时数据与知识图谱，能够为复杂场景下的工艺调整、设备调度和质量控制提供可靠依据。例如，在焊接工艺中，系统可根据材料特性实时推荐最佳参数，显著减少试错成本。<br/>此外，智能助手还促进了知识沉淀与传承，将原本分散在资深工程师经验中的专业知识系统化、结构化，避免了人才流失对企业技术能力的影响。<br/>设备智能助手的应用案例<br/>一、注塑生产线的智能优化案例<br/>，2025年在广东某企业案例中，系统在检测到产品出现翘曲后，通过算法推荐改用稍低的熔体温度并延长冷却时间，使产品合格率从87%提升至96%。同时，系统还提供了预期效果分析，帮助企业评估调整后的风险。<br/>二、焊接工艺的智能参数推荐<br/>在某新能源汽车电池生产车间，设备智能助手被用于焊接工艺管理。面对不同材料的新产品导入，系统能够根据材料特性自动推荐焊接参数，并提供前期调试建议，缩短工艺开发周期。在2025年的测试中，系统对新导入的某型号电池壳体的焊接参数推荐准确率达到92%，不仅大幅减少了工人的调试时间，还显著提升了焊接质量的一致性。<br/>三、设备操作标准化与培训<br/>广域铭岛Geega平台在成都汽车焊装车间的设备智能助手将焊接操作转化为 12项关键参数，实时抓拍工人的操作动作，给出评分和优化建议。新员工通过AI教练的指导，操作合格率迅速提升至 90%，接近老师傅水平。培训周期缩短 70%，设备操作错误率降低 80%。</p>]]></description></item><item>    <title><![CDATA[PMO实战：AI研发效能度量（DORA×SPACE）路线图 PM老周 ]]></title>    <link>https://segmentfault.com/a/1190000047494227</link>    <guid>https://segmentfault.com/a/1190000047494227</guid>    <pubDate>2025-12-22 19:04:25</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>DORA 2025 报告指出：AI 采用率上升可能伴随吞吐与稳定波动，根因在于交付基本功与治理护栏没跟上。本文用 DORA×SPACE 给 PMO 一套 AI 研发效能度量路线图：先对齐口径，再做可对照试点，最后规模化治理，并说明如何把 AI 放进研发管理流程、跑成持续改进闭环。</p><h4>阅读本文你将获得：</h4><ul><li>一套可复用的 AI 研发效能度量指标体系：DORA（结果）× SPACE（机制）</li><li>一条从 0 到规模化的 PMO 路线图（含试点实验与护栏）</li><li>一张“症状—机制—指标”映射思路，避免只谈使用率与工时</li><li>一个“把 AI 放进流程”的落地方式：以 <a href="https://link.segmentfault.com/?enc=RN0lj9059UTCqWIrIkQWpA%3D%3D.Pq34Tkbdigs7gcyvtndSGDt3o6AgPFK5%2Fk%2BQ9UpNx9A%3D" rel="nofollow" target="_blank">ONES Copilot</a> 为例（不绑定工具，可替换）</li></ul><h2>AI 研发效能度量、DORA、SPACE 到底是什么</h2><p><strong>1. AI 研发效能度量是什么？</strong></p><p>一句话：用可验证的数据衡量“AI 是否让交付更快更稳、更可持续”，并据此驱动改进。它不等于“AI 使用次数”，也不等于“节省工时”，而是把 AI 放进端到端交付系统，衡量系统结果与系统机制。</p><p><strong>2. DORA 四项指标（软件交付性能）</strong></p><p>DORA 给出衡量软件交付结果的“四项关键指标（Four Keys）”。</p><ul><li>部署频率（Deployment Frequency）</li><li>变更前置时间（Lead Time for Changes）</li><li>变更失败率（Change Failure Rate）</li><li>故障恢复时间（Time to Restore Service）</li></ul><p><strong>3. SPACE 五维（开发者生产力）</strong></p><p>SPACE 强调：生产力不能用单一指标定义，需要从五个维度组合观测：满意度与幸福感、绩效、活动、沟通协作、效率与心流。</p><p>总结一下，从治理语言翻译：DORA 看“交付结果”，SPACE 解释“为什么结果变成这样”。</p><h2>方法论：PMO 的 DORA×SPACE 路线图（从0到规模化）</h2><p>我在不少企业的复盘会上听过类似对话：研发说“写得更快了”，测试说“回归更重了”，运维说“变更更频繁但故障没少”，而 PMO 最难回答的是：“领导问 ROI，我们只剩使用次数。”</p><p>很多时候，问题不在 AI，而在落地方式——把 AI 当成 IDE 插件，只能优化局部；PMO 关心的是端到端交付系统。更有效的做法，是把 AI 放进研发管理流程里：让它落在“工作项、文档、动态总结、项目数据洞察”这些可治理、可追溯的对象上。比如 ONES Copilot，就是围绕这些对象提供智能创建工作项、文档生成、总结动态、筛选查找与数据洞察等能力，并强调透明、负责、可控的原则。</p><h4>路线图总览（一屏版）</h4><ul><li>对齐目标与边界</li><li>建立指标字典（DORA×SPACE×AI三层）</li><li>试点做成实验（基线/对照/护栏/停机条件）</li><li>规模化治理（权限、透明追溯、质量门禁）</li><li>变成持续改进引擎（洞察→决策→行动闭环）</li></ul><h4>第 1 阶段：对齐目标与边界（2–4 周）</h4><p>AI 不是“买工具项目”，而是“交付系统再设计项目”。PMO 先把三件事写清楚：<br/>北极星目标（建议一条就够）：例如，在不提高变更失败率的前提下，将核心服务 Lead Time 缩短 30%。</p><ul><li>度量对象边界：按服务/产品线拆分，避免大盘混算。</li><li>AI 治理边界（先立护栏）：把“责任归属、权限控制、透明追溯”写进章程。</li></ul><p>ONES Copilot 的原则表述（透明优先、负责、可控、人类监督与审查）很适合直接转译成 PMO 的治理条款：关键输出必须经人类评审，权限遵从所有者设定，动作通过日志可追踪。</p><p>这一步看似慢，但它决定后面你能不能把数据说清、把风险控住。</p><h4>第 2 阶段：建立指标字典（4–6 周）</h4><p>AI 研发效能度量最怕“指标很全、口径在吵”。建议分三层建字典：</p><p><strong>2.1 结果层：DORA 四项（速度×稳定）</strong></p><p>先把 DORA 四项跑起来，并统一口径：</p><ul><li>Lead Time 起点/终点：提交→合入→发布？</li><li>部署频率：只算生产成功发布还是包含灰度？</li><li>失败定义：回滚算不算、事故等级如何映射？</li></ul><p>DORA 官方对“四项指标”的定义与定位非常清楚，适合作为口径基准。</p><p><strong>2.2 机制层：SPACE 五维（解释原因）</strong></p><p>用 SPACE 解释 DORA 的变化，优先选“低摩擦、可持续”的采集方式：</p><ul><li>S：双月脉搏问卷（工具摩擦、认知负荷、信任与焦虑）</li><li>A：PR 周期、评审等待、变更批次</li><li>C：评审往返轮次、跨团队依赖、返工原因</li><li>E：WIP、等待占比、被打断次数</li><li>P：与产品结果/OKR挂钩，但避免落到个人产出考核</li></ul><p>SPACE 的五维定义与“不要用单指标衡量生产力”的主张，是这层的理论底座。</p><p><strong>2.3 AI 层：从“使用率”升级为“贡献率”</strong></p><p>把 AI 指标拆成三类，避免“热闹但无用”：</p><ul><li>Leading（采用与熟练度）：覆盖哪些工作类型（需求/文档/排障/测试/编码）、有效采纳率</li><li>Guardrail（风险护栏）：AI 相关缺陷占比、安全告警趋势、团队信任度</li><li>Lagging（交付影响）：最终回扣 DORA 四项趋势</li></ul><p>如果你的 AI 能把动作留痕，PMO 的口径工作会轻很多。以 ONES Copilot 为例，它强调所有生成结果可通过日志与标记追踪，动作被详细记录，并要求关键输出经人类评审才进入协作流程——这类机制能显著降低“AI 到底改了什么”的争议，让复盘更像治理而不是辩论。<br/><img width="723" height="422" referrerpolicy="no-referrer" src="/img/bVdnrz4" alt="" title=""/></p><h4>第 3 阶段：试点与实验设计（6–12 周）</h4><ul><li>试点要像实验：有基线、有对照、有护栏、有停机条件。推荐从“管理链路低风险闭环”先赢一仗</li><li>智能创建工作项：把原始反馈/会议纪要转成结构化工作项</li><li>文档生成与优化：减少知识沉没，提高可复用性</li><li>总结动态与相似工单：让评审与决策基于事实</li><li>自然语言筛选与查找：降低检索成本，把信息流做顺</li></ul><p>这些能力与对象（工作项、文档、动态、数据洞察）天然更利于 PMO 度量与治理。</p><p><strong>试点章程建议包含 5 个硬要素</strong></p><ul><li>基线期：2–4 周先跑通数据，识别自然波动</li><li>成功标准：Lead Time ↓，且 CFR 不上升（或可控下降）</li><li>护栏指标：评审等待不许失控；回归缺陷不许飙升</li><li>停机条件：稳定性连续恶化且无法解释时，立即收敛范围</li><li>复盘节奏：每两周一次（DORA 看结果 + SPACE 找原因 + 行动项闭环）</li></ul><p>记住：试点不是证明“AI 很强”，而是证明“系统交付更好”。</p><h4>第 4 阶段：规模化与治理（3–6 个月）</h4><p>规模化的关键，不是“全员开通”，而是“护栏前置”。PMO 建议制度化三件事：</p><ul><li>权限与可控：不同角色能用 AI 写入哪些字段？哪些输出必须二次确认？</li><li>透明与追溯：AI 参与过的内容要能回溯来源与改动</li><li>质量门禁：自动化测试、评审清单、灰度与回滚预案</li></ul><p>DORA 2025 的提醒非常现实：如果没有小批量与健壮测试机制，改进开发过程不一定带来交付改善；规模化时更要把这些基本功变成制度，而不是寄希望于“工具自带魔法”。</p><h4>第 5 阶段：把路线图做成“持续改进引擎”（长期）</h4><p>到这一阶段，AI 不再是一个项目，而是一种能力：组织学会在不确定性中持续改进。</p><p>建议沉淀三张“管理可读”的图：</p><ul><li>DORA 结果看板：速度与稳定趋势</li><li>SPACE 机制看板：摩擦点与瓶颈</li><li>AI 影响图谱：哪些场景值得加码，哪些要收敛或加护栏</li></ul><p>你会发现，PMO 的工作开始从“追数字”升级为“给洞察、推行动”：用数据把讨论从“感觉更忙”拉回到“系统哪里卡住了、下一步改什么”。</p><h2>FAQ：</h2><p><strong>Q1：AI 研发效能度量最小可行版本（MVM）是什么？</strong></p><p>A：先跑通 DORA 四项趋势，再用 SPACE 选 3–5 个低摩擦指标解释波动；AI 指标只做“采用、护栏、交付影响”三层即可。</p><p><strong>Q2：DORA 与 SPACE 是竞争关系吗？</strong></p><p>A：不是。DORA 是交付结果，SPACE 是机制解释；对 PMO 来说是“结果+因果”的组合拳。</p><p><strong>Q3：PMO 如何回答“AI 的 ROI”？</strong></p><p>A：用“护栏下的交付改善”回答：Lead Time 是否缩短、CFR 是否可控、恢复是否更快；同时用 SPACE 证明摩擦点是否减少，而不是用使用次数。</p><p><strong>Q4：怎样避免 AI 让稳定性变差？</strong></p><p>A：坚持小批量、强测试、质量门禁与可追溯审查；把 AI 输出纳入流程治理，而不是只在个人侧加速产出。</p><p><strong>Q5：ONES Copilot 在这套体系里扮演什么角色？</strong></p><p>A：它是一种“把 AI 放进可治理对象”的落地方式：围绕工作项、文档、动态总结与数据洞察，让 PMO 更容易做口径对齐、留痕追溯与闭环复盘；同样的治理逻辑也可迁移到其他平台。</p><h2>结尾：让 AI 成为“可度量的改进资产”</h2><p>AI 时代，PMO 的价值不是做更漂亮的周报，而是让组织具备一种能力：用 DORA 看结果，用 SPACE 找原因，用试点实验验证杠杆，用治理护栏放大收益。</p><p>如果你的组织已在使用 ONES 研发管理平台，那么 ONES Copilot 围绕工作项、文档、动态总结、查找筛选与数据洞察的能力，可以成为你把 AI 研发效能度量跑成闭环的“天然载体”；如果你使用的是其他平台，也同样可以借鉴这套思路：工具会变，治理逻辑不变——把 AI 放进流程、纳入度量、接受审查，才能真正把它变成组织的交付能力。</p>]]></description></item><item>    <title><![CDATA[Hologres Dynamic Table：高效增量刷新，构建实时统一数仓的核心利器 阿里云大数据]]></title>    <link>https://segmentfault.com/a/1190000047494247</link>    <guid>https://segmentfault.com/a/1190000047494247</guid>    <pubDate>2025-12-22 19:03:47</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在企业数据架构逐步走向实时化与一体化的过程中，如何高效处理“大量历史 + 少量新增”的业务数据，已成为建设统一数仓与实时数仓时绕不开的关键挑战。</p><p>传统全量刷新方式在面对亿级历史数据时，往往面临刷新延迟高、计算成本大、链路复杂等问题。为了解决这些痛点，业界逐渐形成了一种新的数据处理范式——Dynamic Table（动态表），它通过声明式语法自动维护物化结果，并支持高效的增量刷新能力。</p><p>阿里云 Hologres 作为高性能实时数仓引擎，原生提供了 Dynamic Table，并基于有状态增量计算模型，在多表关联、聚合等复杂场景下展现出显著性能优势。本文将深入解析 Hologres Dynamic Table 的技术原理与实践价值。</p><h2><strong>为什么需要增量刷新能力？</strong></h2><p><img width="723" height="397" referrerpolicy="no-referrer" src="/img/bVdnrzG" alt="image.png" title="image.png"/></p><h3>典型业务场景</h3><p>在电商、互联网、金融等行业，以下场景极为常见：</p><p><strong>实时运营分析</strong></p><ul><li>订单、支付、退款等多源数据，按用户、商品、活动等维度进行关联与聚合，形成实时运营看板；</li><li>运营与业务团队希望以分钟级、甚至更高频率刷新核心指标。</li></ul><p><strong>用户与商品特征构建</strong></p><ul><li>将用户信息、行为数据、订单数据、商品信息、支付信息等多张表进行 Join，生成统一的特征宽表；</li><li>这些宽表通常是推荐、风控、画像等应用的输入，需要稳定、快速地更新。</li></ul><p><strong>资金与交易监控</strong></p><ul><li>交易流水、账户信息、风控结果等数据源不断产生新的记录；需要以较短的刷新间隔计算聚合指标或风控特征。</li></ul><p>这些场景的共同特点是：</p><blockquote><strong>历史数据规模庞大（亿级），但每次新增或变更的数据量很小（通常 &lt;1%）。</strong></blockquote><h3>传统数据加工的局限</h3><p>在缺少增量引擎的情况下，常见做法是：</p><ul><li>使用一条或多条 SQL 定义目标宽表或汇总表；</li><li>定时执行全量计算（如 INSERT OVERWRITE、CTAS），每次从基表完整扫描数据、执行多表 Join、再进行聚合；</li><li>通过调度系统编排上游任务和下游任务之间的依赖。</li></ul><p>这种模式存在若干明显不足：</p><ul><li><strong>刷新时延受限：</strong>数据规模增大后，每次全量扫描和计算耗时较长。当业务希望从“每小时刷新”提升到“每 5 分钟刷新”时，往往需要成倍增加计算资源，也可能遇到物理资源上限。</li><li><strong>计算成本较高</strong>：即使每次只有 1% 左右的数据发生变化，全量模式仍需对 100% 数据进行扫描和计算，CPU、IO 和网络资源利用效率不高。</li><li><strong>链路复杂，维护成本高</strong>：为降低单任务压力，工程实践中常将复杂逻辑拆解为多层中间表，形成较长的任务链路。链路越长，依赖越多，维护难度和变更风险也随之上升。</li></ul><p>因此，在“历史数据量大、实时数据实时产生”的场景下，引入真正高效的增量刷新机制，是提升数据时效与降低资源利用率的关键。</p><h2>二、什么是 Dynamic Table？Hologres 的增量刷新如何工作？</h2><p>Dynamic Table是当前一种主流的声明式数据处理架构，该架构可以自动处理并存储一个或者多个基表（Base Table）对象的数据关联、聚合结果，内置不同的数据刷新策略，业务可以根据需求设置不同的数据刷新策略，实现数据从基表对象到Dynamic Table的自动流转，满足业务统一开发、数据自动流转、处理时效性等诉求。</p><p>增量（incremental）、全量（full）是Dynamic Table的两种不同刷新方式，底层实现原理具有显著的差异：</p><ul><li><strong>全量刷新</strong>是指每次执行刷新时，都以全量的方式进行数据处理，并将基表的关联、聚合结果物化写入Dynamic Table，其技术原理类似于INSERT OVERWRITE。</li><li><strong>增量刷新</strong>模式下，每次刷新时只会读取基表中<strong>新增</strong>的数据，根据中间聚合状态和增量数据计算最终结果并更新到Dynamic Table中。相比全量刷新，增量刷新每次处理的数据量更少，效率更高，从而可以非常有效地提升刷新任务的时效性，同时降低计算资源的使用。</li></ul><p>增量Dynamic Table的计算遵循如下计算模式：</p><ol><li><strong>增全量刷新</strong>阶段：Dynamic Table的第一次刷新会把已有的所有历史数据都进行计算，即相当于把所有历史数据都当作增量来进行计算。这一阶段一般耗时比较长。</li><li><strong>增量刷新</strong>阶段：在增全量刷新完成后，以后的每次Dynamic Table刷新仅针对增量数据进行计算。理论上这些刷新应该耗时较短。</li></ol><p>在增量 Dynamic Table 的实现上，业界存在不同的技术路径。一种常见的做法是采用<strong>无状态增量计算模型</strong>：每次刷新时，系统仅基于源表的变更数据，重新推导整个查询逻辑，而不持久化任何中间计算状态。这种方式虽然节省存储，但在面对复杂查询（如多表关联、去重聚合等）时，往往需要反复扫描大量历史数据，导致刷新效率低下，甚至在某些场景下增量计算的开销反而超过全量。</p><p>相比之下，Hologres 采用了<strong>有状态增量计算模型</strong>：在首次全量构建 Dynamic Table 时，同步生成并持久化关键的中间状态（例如聚合结果、多表 Join 的中间产物等）。后续的增量刷新只需将新增或变更的数据与这些状态表进行高效合并，无需重复处理历史数据。这种设计以有限且可控的额外存储开销为代价，<strong>显著提升了复杂场景下的刷新性能和资源利用率，尤其适合“海量历史 + 少量增量”的典型业务负载</strong>。<br/><img width="723" height="407" referrerpolicy="no-referrer" src="/img/bVdnrzH" alt="image.png" title="image.png" loading="lazy"/></p><h2>三、Hologres 增量刷新的实战优势</h2><p>我们通过三个典型场景验证 Hologres 的性能表现（测试环境：Hologres 15CU Serverless，竞品采用相似规格）。</p><p>对于增量数据，本实验模拟两种场景：</p><ol><li>Append only：即源表的增量数据只有新增（Insert），没有修改（update和delete）。这在日志、埋点数据表中非常常见。</li><li>Retraction（回撤）：源表的增量数据包含Insert、Update和Delete的数据。这适用于数据库类的表。</li></ol><p>对于Append only的源表，很多增量计算算子都可以大幅简化，状态表也可以大幅缩小。所以在性能环节，可以看到Append only源表的增量计算性能会更好。</p><h3>场景 1：单表聚合（COUNT DISTINCT + SUM）</h3><p>该场景使用的工作负载如下所示：<br/><img width="681" height="135" referrerpolicy="no-referrer" src="/img/bVdnrzI" alt="image.png" title="image.png" loading="lazy"/></p><p>Hologres建表SQL如下：</p><pre><code class="sql">CREATE DYNAMIC TABLE DT_ORDER_DETAIL_AGG with (
    auto_refresh_mode = 'incremental', 
    auto_refresh_enable = 'false', 
    freshness = '1 minutes'
)AS 
SELECT
  PRODUCT_ID,
  COUNT(DISTINCT USER_ID) AS UV,
  SUM(LINE_AMOUNT) AS SUM_LINE_AMOUNT,
  MAX(QUANTITY) AS MAX_QUANTITY
FROM ORDER_DETAIL
GROUP BY PRODUCT_ID;</code></pre><p>测试结果如下表所示（完整测试SQL见附录）：</p><table><thead><tr><th><strong>刷新</strong></th><th><strong>源表行数</strong></th><th> </th><th><strong>某国际知名产品无状态增量计算刷新耗时(s)</strong></th><th> </th><th><strong>Hologres刷新耗时(s)</strong></th><th> </th></tr></thead><tbody><tr><td> </td><td><strong>Retraction</strong></td><td><strong>Appendonly</strong></td><td><strong>Retraction</strong></td><td><strong>Appendonly</strong></td><td><strong>Retraction</strong></td><td><strong>Appendonly</strong></td></tr><tr><td><strong>增全量刷新</strong></td><td>ORDER\_DETAIL: 10M</td><td> </td><td>1.5</td><td>1.3</td><td>4.6</td><td>3.9</td></tr><tr><td><strong>增量第一次</strong></td><td>每张表 <br/>UPDATE 0.5%<br/>INSERT 0.5%</td><td>每张表 <br/>INSERT 1.0%</td><td>7.8</td><td>2.4</td><td>0.59</td><td>0.48</td></tr><tr><td><strong>增量第二次</strong></td><td> </td><td> </td><td>8.1</td><td>2.7</td><td>0.49</td><td>0.41</td></tr><tr><td><strong>增量第三次</strong></td><td> </td><td> </td><td>7.8</td><td>2.9</td><td>0.45</td><td>0.3</td></tr></tbody></table><p>可以看到Hologres增全量刷新阶段较慢，但后面的每次增量刷新都很快，符合预期。</p><p>无状态增量刷新性能较差的主要原因是无状态增量执行计划变得更加复杂，包含36个计算节点，且变更数据触及了大量分区，需要从源表重新扫描计算所有的数据。在有回撤数据时，处理数据变更前后因果关系会导致计算逻辑会变得更加复杂，进一步变慢，增量计算显得没有意义。</p><p>Hologres增量刷新快的核心原因是每次增量计算都是基于上次计算生成的状态表（State），这极大的简化了增量计算逻辑。此例中Hologres中各表存储大小如下所示（源表是Retraction的情况），结果表很小，而因为min/max/count distinct这两种聚合函数与sum/count这类不同，状态表需要存储对应列的所有原始数据，所以相比结果表要大很多。</p><table><thead><tr><th> </th><th><strong>源表</strong></th><th><strong>结果表</strong></th><th><strong>状态表</strong></th></tr></thead><tbody><tr><td><strong>存储</strong></td><td>252 MB</td><td>1 MB</td><td>93 MB</td></tr></tbody></table><h3>场景 2：两表 Join（订单 + 明细）</h3><p>两表Join是大数据处理中一种较为简单的基本场景，测试使用的具体工作负载如下图所示<br/><img width="723" height="221" referrerpolicy="no-referrer" src="/img/bVdnrzU" alt="image.png" title="image.png" loading="lazy"/></p><p>Hologres建表SQL如下：</p><pre><code class="sql">CREATE DYNAMIC TABLE DT_ORDER_DETAIL
WITH (
  auto_refresh_mode = 'incremental', 
  auto_refresh_enable = 'false', 
  freshness = '1 minutes'
) AS 
SELECT
  o.ORDER_ID,
  o.ORDER_DATE,
  o.ORDER_STATUS,
  oi.ORDER_ITEM_ID,
  oi.PRODUCT_ID,
  oi.QUANTITY,
  oi.UNIT_PRICE,
  oi.LINE_AMOUNT
FROM ORDERS o
JOIN ORDER_ITEMS oi
  ON o.ORDER_ID = oi.ORDER_ID;</code></pre><p>测试结果如下表所示（完整测试SQL见附录），无状态增量刷新引擎在数据含有回撤的时候执行计划包含50个节点，源表大部分分区的数据被反复读取参与聚合，导致性能不佳。而数据不包含回撤（Appendonly）时，无状态增量刷新执行计划相对简单，含有35个节点，且新增数据不会触及太多分区，表现良好，体现出了增量计算的意义。</p><table><thead><tr><th> </th><th><strong>源表行数</strong></th><th> </th><th><strong>某国际知名产品无状态增量计算(s)</strong></th><th> </th><th><strong>Hologres刷新耗时(s)</strong></th><th> </th></tr></thead><tbody><tr><td> </td><td><strong>Retraction</strong></td><td><strong>Appendonly</strong></td><td><strong>Retraction</strong></td><td><strong>Appendonly</strong></td><td><strong>Retraction</strong></td><td><strong>Appendonly</strong></td></tr><tr><td><strong>增全量刷新</strong></td><td><strong>ORDERS</strong>: 5M<br/><strong>ORDER\_ITEMS</strong>: 10M</td><td> </td><td>10</td><td>8.7</td><td>9.2</td><td>6.29</td></tr><tr><td><strong>增量第一次</strong></td><td>每张表 <br/>UPDATE 0.5%<br/>INSERT 0.5%</td><td>每张表 <br/>INSERT 1.0%</td><td>22</td><td>1.1</td><td>2.2</td><td>0.68</td></tr><tr><td><strong>增量第二次</strong></td><td> </td><td> </td><td>19</td><td>2.2</td><td>1.1</td><td>0.50</td></tr><tr><td><strong>增量第三次</strong></td><td> </td><td> </td><td>22</td><td>1.7</td><td>1.9</td><td>0.51</td></tr></tbody></table><p>Hologres中各表存储大小如下所示，在这种场景下状态表存了源表的部分列数据，实际存储小于源表。</p><table><thead><tr><th> </th><th><strong>源表</strong></th><th><strong>结果表</strong></th><th><strong>状态表</strong></th></tr></thead><tbody><tr><td><strong>存储</strong></td><td>370 MB</td><td>350 MB</td><td>228 MB</td></tr></tbody></table><h3>场景 3：五表复杂 Join（订单 + 用户 + 商品 + 支付等）</h3><p>多表Join是一种相对更常见、真实的场景，测试具体使用的工作负载如下:<br/><img width="723" height="268" referrerpolicy="no-referrer" src="/img/bVdnrzT" alt="image.png" title="image.png" loading="lazy"/></p><p>Hologres的测试脚本如下：</p><pre><code class="sql">CREATE DYNAMIC TABLE DT_ORDER_DETAIL
WITH (
  auto_refresh_mode = 'incremental', 
  auto_refresh_enable = 'false', 
  freshness = '1 minutes'
) AS 
SELECT
  o.ORDER_ID,
  o.ORDER_DATE,
  o.ORDER_STATUS,
  u.USER_ID,
  u.USER_NAME,
  u.EMAIL,
  u.STATUS AS USER_STATUS,
  oi.ORDER_ITEM_ID,
  oi.PRODUCT_ID,
  p.PRODUCT_NAME,
  p.CATEGORY,
  p.PRICE       AS PRODUCT_PRICE,
  oi.QUANTITY,
  oi.UNIT_PRICE,
  oi.LINE_AMOUNT,
  pay.PAYMENT_ID,
  pay.PAY_AMOUNT,
  pay.PAY_METHOD,
  pay.PAY_TIME
FROM ORDERS o
JOIN USERS u
  ON o.USER_ID = u.USER_ID
JOIN ORDER_ITEMS oi
  ON o.ORDER_ID = oi.ORDER_ID
JOIN PRODUCTS p
  ON oi.PRODUCT_ID = p.PRODUCT_ID
LEFT JOIN PAYMENTS pay
  ON o.ORDER_ID = pay.ORDER_ID;</code></pre><p>测试结果如下表所示（完整测试SQL见附录），无状态增量计算引擎无论是只包含插入还是有回撤，性能都相对较差，原因也是类似的。五表Join的场景下，增量计算的执行节点超过140个，会大量读取源表数据。</p><table><thead><tr><th> </th><th><strong>源表行数</strong></th><th> </th><th><strong>某国际知名产品无状态增量计算(s)</strong></th><th> </th><th><strong>Hologres刷新耗时(s)</strong></th><th> </th></tr></thead><tbody><tr><td> </td><td><strong>Retraction</strong></td><td><strong>Appendonly</strong></td><td><strong>Retraction</strong></td><td><strong>Appendonly</strong></td><td><strong>Retraction</strong></td><td><strong>Appendonly</strong></td></tr><tr><td><strong>增全量刷新</strong></td><td><strong>ORDER\_ITEMS</strong>: 10M<br/><strong>PAYMENTS</strong>: 4.9M<br/><strong>ORDERS</strong>: 5M<br/><strong>PRODUCTS</strong>: 50K<br/><strong>USERS</strong>: 500K</td><td> </td><td>23</td><td>23</td><td>30</td><td>22</td></tr><tr><td><strong>增量第一次</strong></td><td>每张表 <br/>UPDATE 0.5%<br/>INSERT 0.5%</td><td>每张表 <br/>INSERT 1.0%</td><td>55</td><td>26</td><td>3.9</td><td>2.8</td></tr><tr><td><strong>增量第二次</strong></td><td> </td><td> </td><td>58</td><td>27</td><td>3.2</td><td>1.8</td></tr><tr><td><strong>增量第三次</strong></td><td> </td><td> </td><td>60</td><td>26</td><td>2.9</td><td>1.8</td></tr></tbody></table><p>Hologres中各表存储大小如下所示，状态表会存储每一次Join的中间结果</p><table><thead><tr><th> </th><th><strong>源表</strong></th><th><strong>结果表</strong></th><th><strong>状态表</strong></th></tr></thead><tbody><tr><td><strong>存储</strong></td><td>594 MB</td><td>1218 MB</td><td>1094 MB</td></tr></tbody></table><h2>四、有状态增量计算：为何更高效？</h2><p>基于前面的实验结果，不难看出，无状态增量计算方案适用条件其实比较苛刻，在很多场景中基于少量数据的增量计算开销甚至会超过第一次的全量计算，丧失了增量计算的意义。</p><p>而相比较之下，Hologres的有状态增量计算方案可以适用于大多数的场景，通常只需要满足增量数据较少这一个条件即可。下图以单表聚合场景(<code>sum(value) group by key</code>)为例，展示了有状态方案的基本原理，增量计算过程中可以从状态表中直接获取历史数据的聚合结果，而不需要基于历史表的原始数据重新计算。此外在读取状态表数据时，也进一步引入了OLAP查询中常用的runtime filter优化，在增量数据较少的场景中，大幅减少状态表数据读取量，使刷新性能得到了显著的提升。<br/><img width="723" height="381" referrerpolicy="no-referrer" src="/img/bVdnrzY" alt="image.png" title="image.png" loading="lazy"/></p><p>有状态方案一个显著的缺点是与无状态方案相比会需要占用额外的存储空间用于状态表的存储。如上述实验数据所示，实际额外存储大小通常与涉及到的源表、结果表的大小相关。</p><p>这一缺点通常是可以接受的，因为在业务实践操作中，这部分存储一般是可控的,不会无限增长。这是因为：</p><ul><li>分区表的场景中，只有活跃分区需要状态表，历史分区转全量刷新后不再需要状态表（这个过程是自动的，分区不再活跃后会自动清理状态表）。因此只有最近的一两个分区才需要状态表，这极大地减少了状态表的存储空间。因此Hologres Dynamic Table增量计算状态表没有Flink常见的状态膨胀问题。</li><li>非分区表场景中，可以为状态表配置合适的TTL，丢弃一些不再需要的历史状态减少存储空间</li></ul><h2>总结：Hologres Dynamic Table 的核心价值</h2><p>面对企业日益增长的实时分析需求，Hologres 的 Dynamic Table 通过有状态增量计算引擎，从根本上解决了传统方案在复杂查询下“增量不增效”的痛点。它不仅大幅缩短了数据刷新延迟，还显著降低了计算资源消耗和运维复杂度，真正实现了“写一次 SQL，自动高效更新”的体验。无论你是构建实时看板、用户画像宽表，还是风控特征管道，Hologres 都能以稳定、高性能、低成本的方式支撑你的核心数据链路。</p><h2>附录</h2><h3>无状态 &amp; 有状态增量计算底层原理对比分析</h3><p>从上面的实验结果来看，Hologres的有状态实现方案在大多数的场景中是要优于无状态增量计算引擎的，本小节将对两者的底层计算原理进行对比分析，说明造成这种性能差异的根本原因。</p><h4>符号说明</h4><p><img width="723" height="379" referrerpolicy="no-referrer" src="/img/bVdnrAd" alt="image.png" title="image.png" loading="lazy"/></p><h4>多表Join场景</h4><h5>无状态实现Hologres Dynamic Table：高效增量刷新，构建实时统一数仓的核心利器</h5><p>无状态多表Inner Join的增量计算公式如下（原理可参考<a href="https://link.segmentfault.com/?enc=H5kzk0H1LZqTSiA40XsElg%3D%3D.vRiV9k43KJDTqDPLpt3d68HbVvooo7Gjfe%2FiT0%2B7Fp8k%2FXl64BZJ55gfKgM6mz27" rel="nofollow" target="_blank">论文</a>），根据实际执行计划推测某无状态增量计算引擎的多表Join增量计算应该也是基于该公式实现的<br/><img width="723" height="151" referrerpolicy="no-referrer" src="/img/bVdnrAe" alt="image.png" title="image.png" loading="lazy"/><br/>该方案主要会有如下弊端：<br/><img width="723" height="155" referrerpolicy="no-referrer" src="/img/bVdnrAf" alt="image.png" title="image.png" loading="lazy"/></p><h5>有状态实现</h5><p>Hologres的有状态多表Join计算公式原理大致如下，因为所有的中间计算结果状态会通过状态表（State）持久化保存下来，因此可以按照两表Join的公式做简单展开<br/><img width="723" height="79" referrerpolicy="no-referrer" src="/img/bVdnrAh" alt="image.png" title="image.png" loading="lazy"/></p><p>有状态方案以额外的存储开销为代价换来了：<br/><img width="723" height="104" referrerpolicy="no-referrer" src="/img/bVdnrAk" alt="image.png" title="image.png" loading="lazy"/></p><h4>单表聚合场景</h4><p>单表聚合场景相对较为简单，无状态、有状态两种方案的计算公式原理分别如下：<br/><img width="723" height="118" referrerpolicy="no-referrer" src="/img/bVdnrAn" alt="image.png" title="image.png" loading="lazy"/></p><p>公式大体是比较相似的，主要区别是Hologres的有状态方案持久化存储了历史数据的聚合结果，因此有以下优势：</p><ul><li>不需要重新计算历史数据的聚合结果</li><li>State表数据量极小，Join 操作可以显著减少读取数据量</li></ul>]]></description></item><item>    <title><![CDATA[Excelize 开源社区荣获 2025 红山开源明星项目三等奖 xuri ]]></title>    <link>https://segmentfault.com/a/1190000047494249</link>    <guid>https://segmentfault.com/a/1190000047494249</guid>    <pubDate>2025-12-22 19:02:53</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>2025 年 11 月 16 日，由红山开源平台主办的“2025 红山开源大会”，在北京香山颐和宾馆红山厅成功落下帷幕。为表彰在开源领域做出卓越贡献的项目，大会特别设立 2025 年度红山开源平台明星项目颁奖环节。</p><p>Excelize 开源社区荣获了 2025 红山开源明星项目三等奖，活动详情详见文章：<a href="https://link.segmentfault.com/?enc=0fY6kt4dAVh%2F%2F9WhDy5GMQ%3D%3D.ESXqDX15mNQMCo4fjdWRAJqISF83iqSEbZF3gcRBXtOWBV3YsgWIWOEFmeOondtIYp4%2FYGkjOpfbayeKXECKtw%3D%3D" rel="nofollow" target="_blank">2025 红山开源大会圆满收官，共筑开源生态新未来</a></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047494251" alt="Excelize 荣获 2025 红山开源明星项目三等奖" title="Excelize 荣获 2025 红山开源明星项目三等奖"/></p><p>Excelize 是用于操作电子表格办公文档的开源基础库，开源地址：<a href="https://link.segmentfault.com/?enc=1AAjbIbAFAnNBfhvHDkiOQ%3D%3D.Qvq75emknm8lr13YXPatxBnlACpUJ12YHQLIOVYRBk6BX10OMY7DYj7I%2FmxYwcwX" rel="nofollow" target="_blank">github.com/xuri/excelize</a>，遵循 BSD 3-clause 开源协议，基于 ISO/IEC 29500 国际标准。可以使用它来读取、写入由 Excel 、WPS 、OpenOffice 等办公软件创建的电子表格文档。支持 XLAM / XLSM / XLSX / XLTM / XLTX 等多种文档格式，高度兼容带有样式、图片 (表)、透视表、切片器等复杂组件的文档，并提供流式读写支持，用于处理包含大规模数据的工作簿。可应用于各类报表平台、云计算、边缘计算等系统。自 2016 年开源以来已成为云原生应用尤其是 Go 语言开发者在处理电子表格办公文档时的热门选择，正在被广泛应用于大型互联网公司、中小企业客户和初创公司。</p><p>Excelize 开源基础库曾荣获 2025 上海开源创新菁英奖——优秀开源项目奖、2025 年 GitCode 百大开源项目、2022 年中国开源创新大赛一等奖、2018 年开源中国码云最有价值开源项目 GVP (Gitee Most Valuable Project) 等奖项。</p>]]></description></item><item>    <title><![CDATA[招聘终极战场：AI重构首轮筛选的精准与效能革命 爱跑步的香蕉_cKtiNz ]]></title>    <link>https://segmentfault.com/a/1190000047494313</link>    <guid>https://segmentfault.com/a/1190000047494313</guid>    <pubDate>2025-12-22 19:02:00</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>招聘终极战场：AI重构首轮筛选的精准与效能革命<br/>国务院《关于深入实施“人工智能+”行动的意见》明确划定：2027年，70%的岗位面试将由AI或智能体完成。当智能化浪潮不可逆地渗透企业运营，你的招聘体系是否仍停留在简历海投、人力初筛、凭感觉提问的“前AI时代”？效率鸿沟已悄然拉开——当对手用AI数小时内完成千人筛选与精准初评，你的团队是否还在无尽简历与重复问答中消耗战略时间？HR向“数据驱动的决策伙伴”转型，已非未来愿景，而是当下生存必备技能，而这场转型的关键，始于面试智能化的两大核心：评估精准度与候选人体验。</p><p>一、数据驱动决策：超越直觉的可验证精准<br/>招聘最大的隐性成本是选错人，AI面试智能体将“精准”定义为可严格验证的标准：评分结果既通过与资深面试官“背靠背”对比实验，又经受效标效度与重测信度等心理学指标检验，从“辅助参考”进阶为“决策依据”。这种精准贯穿评估全流程：<br/>•一问多能：单题同步评估多项胜任力，无缝衔接初筛与专业复试，评估效率提升超50%；<br/>•智能追问：依据回答即时生成深度问题，如资深面试官般捕捉逻辑漏洞与能力闪光点，杜绝表面化评判；<br/>•简历深挖：自动解析简历关键信息与模糊点，生成递进式提问链，既验证真实性，又挖掘文本掩盖的胜任力；<br/>•全维度覆盖：兼顾通用素质与编程、财务等专业领域精准评估，同步解放HR与业务面试官。<br/>二、体验即品牌：让面试成为雇主形象加分项<br/>糟糕的AI面试体验足以劝退顶尖人才，AI面试智能体将“拟人化交互”作为技术核心，让面试成为雇主品牌传播的重要载体：<br/>•情绪感知交互：识别语速、语调中的紧张或犹豫，通过人性化引导帮助候选人展现最佳状态；<br/>•无缝对话流：无需手动操作“开始/停止”，答案结束后自动衔接下一题，还原真人对话的自然节奏；<br/>•高拟真视觉呈现：唇形与语音精准同步，大幅削弱传统虚拟面试的“机械感”；<br/>•实时答疑能力：候选人可随时咨询职位、团队、福利等问题，AI精准解答，成为传递企业信息的智能窗口。<br/>三、流程革命：招聘全链路迈入“无人驾驶”<br/>面试智能化仅是起点，AI人才寻访智能体将自动化延伸至招聘最前端的寻访环节。它并非简单群发工具，而是能自主完成“筛选-沟通-索要简历-系统录入”全链条动作的智能系统：<br/>•极速启动：30-60秒完成初始化，无需人工值守即可独立运作；<br/>•智能筛选：按预设条件精准筛选平台简历，锁定目标候选人；<br/>•拟人化沟通：发起自然对话，遍历回复所有未读消息，信息缺失时主动“索要简历”；<br/>•系统无缝同步：将获取的简历自动同步至企业ATS，形成完整数据闭环。<br/>这不仅将HR从重复劳动中彻底解放，更通过大模型技术，将寻访动作从“机械执行”升级为“有判断力的决策”。<br/>四、实践验证：顶尖组织的共同选择<br/>AI招聘解决方案已获得西门子中国、招商银行、阿里巴巴国际、TCL及浙江大学等上千家领先企业与高校的认可。通过引入该系统，这些组织成功将招聘流程搭建在智能化基座之上，实现了效率与精准度的双重飞跃，为行业树立了可复制的实践标杆。<br/>智能化趋势已明确，观望即是最大风险。AI招聘的下一轮竞争，始于对新模式的验证与落地。当精准评估、优质体验与全流程自动化形成闭环，招聘将不再是成本消耗，而是驱动企业人才竞争力提升的核心引擎。</p>]]></description></item><item>    <title><![CDATA[FundingRate/资金费率套利 云梦量化科技 ]]></title>    <link>https://segmentfault.com/a/1190000047494330</link>    <guid>https://segmentfault.com/a/1190000047494330</guid>    <pubDate>2025-12-22 19:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>资金费率介绍</h2><p>由于永续合约没有传统意义上的到期日/交割日，也就没有传统的价格收敛机制，因此需要使用一种新的机制来确保永续合约价格与现货价格锚定在一起，这就是资金费率机制。资金费率是多空双方之间定期交换的费用，通常每8小时结算一次。如果资金费率为正，多头支付空头；如果资金费率为负，空头支付多头。\<br/>当合约价格比现货价格高时，资金费率通常为正，鼓励交易者做空合约以推动价格下跌；同样当合约价格低于现货价格时，资金费率通常为负，鼓励交易者做多合约以推动价格上涨。通过这种机制，永续合约的价格能够与现货价格进行锚定。</p><h2>资金费率的定价</h2><p>根据某安的资金费率定价公式:</p><p>$$
\begin{align}
funding\_rate &amp;= avg\_premium\_index + clamp(interest\_rate - avg\_premium\_index, -0.05\%, 0.05\%) \\
funding\_rate &amp;= clamp(funding\_rate, lower\_bound, upper\_bound)
\end{align}
$$</p><p>其中avg_premium_index是平均溢价指数，表示合约与现货的偏离程度，interest_rate是利率，一般是日化0.03%，lower_bound和upper_bound分别是资金费率的下限和上限。<br/>其中对于平均溢价指数的计算公式为(以8小时周期为例):</p><ol><li><p>首先计算每个时间点的溢价指数, 溢价指数 = [Max(0, 冲击买价 - 价格指数) - Max(0, 价格指数 - 冲击卖价)] / 价格指数</p><pre><code>- 注：其中提到的冲击买价为使用200USDT*最大杠杆的资金冲击买盘，冲击卖价同理，价格指数为各个交易所的现货价格加权平均得到的价格</code></pre></li><li>然后根据不同的时间段赋予不同的权重，具体为，第1分钟权重为1，第2分钟权重为2...第480分钟权重为480，根据时间权重计算得到平均溢价指数</li></ol><p>对于这里提到的溢价指数计算公式，其实可以简单理解为（合约价-现货价）/现货价</p><p>在这个定价公式中，$interest\_rate$是一个非常重要的参数，这个参数决定了使用合约的资金成本（对于多头而言）。考虑此时合约价与现货价格一致，或者合约价与现货价的偏离程度在一个非常小的范围内，那么此时对于$interest\_rate-avg\_premium\_index$就应该位于-0.05%到0.05%的范围内，此时资金费率就等于$funding\_rate=avg\_premium\_index+(interest\_rate-avg\_premium\_index)=interest\_rate$，也就是说此时资金费率就等于利率。那么对于这个日化0.03%的利率来说，年化收益率为0.03%*365=10.95%。对于多头来说，这是非常高的资金成本，但是对于空头来说，却是一个非常好的收益来源。此时考虑买入现货卖出合约以赚取这部分无风险收益。这里选择反向（Reverse）合约，因为反向合约的资金费率更加稳定，长期来看要高于正向（Linear）合约的资金费率收益。</p><h2>买入现货卖出反向合约</h2><p>做空反向合约的盈亏计算方式为:</p><p>$$
\begin{align}
PnL_{short} = number\_of\_contracts * contract\_value * (\frac{1}{exit\_price} - \frac{1}{entry\_price})
\end{align}
$$</p><h3>无风险</h3><p>从直觉上来看，买入现货卖出等量的合约应该是无风险的，实际上也是如此。<br/>举例来说：假设当前现货价格为100000，对应反向合约价格为100000，此时买入1个现货，同时卖出1个反向合约，合约面值为100000。</p><ol><li>如果价格上涨到110000，此时现货价值上涨到110000，现货部分盈利10000；而合约部分亏损为100000 * (1/110000 - 1/100000)=0.0909个现货，乘上当前价格110000，合约部分亏损为10000，总体盈亏为0</li><li>如果价格下跌到90000，此时现货价值下跌到90000，现货部分亏损10000；而合约部分盈利为100000 * (1/90000 - 1/100000)=0.1111个现货，乘上当前价格90000，合约部分盈利为10000，总体盈亏为0</li></ol><p>再看是否存在爆仓风险，假设合约开仓时合约价格为P0, 此时为P, 考虑买入一个现货并卖出等量的反向合约，此时合约面值为1*P0<br/>币本位合约的维持保证金计算方式为:</p><p>$$
\begin{align}
% 先计算权益
equity\_value = 1 * P + 1 * P0 * (\frac{1}{P} - \frac{1}{P0}) * P = P + P0 - P = P0 \\
equity\_quantity = \frac{equity\_value}{P} = \frac{P0}{P} \\
% 计算维持保证金
MM = \frac{MMR*P0}{P}
\end{align}
$$</p><p>其中MMR为维持保证金率<br/>由于MMR为一个小于1的常数，因此有$equity\_quantity=\frac{P0}{P}&gt;\frac{MMR*P0}{P}=MM$，也就是说不会爆仓。</p><h3>收益分析</h3><p>获取了2024-09-30到2025-09-30期间某安上的主流的8个现货（图表标题为其市值排名）的反向合约资金费率数据<br/>计算累计资金费率收益如下图所示：<br/><img width="723" height="732" referrerpolicy="no-referrer" src="/img/bVdnrBG" alt="" title=""/><br/>可以看到基本上都是一条直线往上走，但其中有三个反向合约的累计资金费率收益分别是5.04%, 7.01%, 6.83%, 远小于其余的5个反向合约。考虑到分散风险的角度，构建等权重的组合，计算其累计资金费率收益如下图所示：<img width="723" height="439" referrerpolicy="no-referrer" src="/img/bVdnrBH" alt="" title="" loading="lazy"/><br/>进一步将其中收益较低的三个剔除，构建剩余5个的等权重组合，计算其累计资金费率收益如下图所示：<img width="723" height="439" referrerpolicy="no-referrer" src="/img/bVdnrBI" alt="" title="" loading="lazy"/><br/>可以发现其总收益可以达到9.67%，接近理论上的10.95%的无风险收益率。</p><h2>结论</h2><p>由于资金费率定价公式中的设定利率较高，导致这个市场上的无风险收益率也非常高。<br/>这使得通过买入现货并卖出反向合约，可以赚取一个非常高的无风险收益率，可以达到接近10%左右。并且通过组合分散风险，可以进一步提升收益的稳定性。</p><p>此文章内容由云梦量化科技高频策略实习生skylen创作投稿。</p>]]></description></item><item>    <title><![CDATA[怎么实现制造业数字化转型？实战案例解析 月下水光 ]]></title>    <link>https://segmentfault.com/a/1190000047493984</link>    <guid>https://segmentfault.com/a/1190000047493984</guid>    <pubDate>2025-12-22 18:13:38</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在全球制造业加速向智能化、网络化演进的今天，工业数字化转型已不再是可选的优化路径，而是企业生存与发展的战略刚需。它超越了传统信息化升级的范畴，是一场涵盖研发、生产、供应链、设备管理与服务体系的全方位重构，其核心在于通过数据驱动、智能协同与平台赋能，打通“研、产、供、销、服”全链条，实现从经验决策向智能决策、从孤立系统向生态协同的根本跃迁。<br/>在这一转型浪潮中，广域铭岛作为中国工业互联网领域的先锋力量，凭借其自主研发的Geega工业互联网平台，构建了“平台+解决方案+工业软件”的完整生态体系，为制造业提供了可落地、可复制、可进化的数字化转型范式。其实践表明，真正的工业数字化转型，必须实现技术、流程与理念的三重突破。<br/>在研发端，广域铭岛的FastWorx设计研发协同平台，以BOM管理、三维工艺引擎与AI驱动的工艺专家系统为核心，打通了从概念设计到产品交付的全周期闭环。通过结构化知识管理与智能校核，企业零部件复用率提升35%，研发周期显著缩短，工程师从重复性劳动中解放，创造力得以释放。这标志着研发正从“人驱动”转向“数据+算法驱动”。<br/>在生产端，设备数字化协同与数字孪生技术成为提质增效的关键。广域铭岛在领克汽车成都工厂部署的焊接质量预警系统，整合3000+焊点参数，实现虚焊、飞溅等缺陷的实时识别与自动预警，将问题排查时间从72小时压缩至5分钟。其设备数字孪生模型可精准模拟反应釜、工业机器人等关键装备的运行状态，实现预测性维护，使设备综合效率（OEE）提升20%以上，运维成本大幅降低。<br/>在供应链与质量管理层面，广域铭岛的GOS-知识库系统融合多源异构数据采集、AI知识图谱与区块链技术，构建了端到端的智能协同网络。在百矿集团，系统通过实时优化氧化铝浓度，单吨铝电解能耗降低300千瓦时，年节电费超7000万元；在汽车产业链中，其GECP碳管理平台实现全生命周期碳足迹追踪，助力企业应对CBAM等绿色贸易壁垒。同时，智能计划助手将排产时间从6小时缩短至1小时，质量不良率从8%降至0.8%，真正实现了“质量可追溯、成本可预测、响应可敏捷”。<br/>当前，工业数字化转型正从单点技术应用迈向系统性生态构建。广域铭岛的实践印证：成功的转型不是工具的堆砌，而是以平台为中枢，打通数据孤岛、重构业务流程、激活组织潜能的系统工程。随着5G、AI大模型与量子计算等技术的深度融合，工业数字化将加速向“自感知、自决策、自优化”的智能体时代演进。<br/>未来，谁能率先完成这场从“制造”到“智造”的蜕变，谁就能在新一轮全球产业竞争中占据制高点。广域铭岛等领先服务商，正以技术为笔、数据为墨，为制造业绘制一幅智能、绿色、韧性的新蓝图——这不仅是技术的升级，更是中国制造业迈向高质量发展的必由之路。</p>]]></description></item><item>    <title><![CDATA[工业物联网IIOT如何重塑整车制造行业？ 雨大王 ]]></title>    <link>https://segmentfault.com/a/1190000047494018</link>    <guid>https://segmentfault.com/a/1190000047494018</guid>    <pubDate>2025-12-22 18:12:56</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>导言：制造业数字化转型的新引擎<br/>当前全球制造业正经历着以工业物联网为代表的第四次工业革命浪潮。作为工业4.0的核心技术，IIoT通过将传感器、设备和系统相互连接，实现了制造过程的数字化、网络化和智能化。在技术密集型的汽车制造领域，IIoT正在从根本上改变传统生产模式，推动制造业向智能化、柔性化方向发展。从供应链管理到生产线优化，从质量管控到能效提升，IIoT技术正在汽车制造的全价值链中发挥着越来越重要的作用。<br/>值得注意的是，IIoT的应用已经超越了简单的设备联网和数据采集阶段，正在向智能决策和自主优化演进。通过大数据分析、人工智能和数字孪生等技术的深度融合，IIoT正在帮助汽车制造企业构建更加智能、高效的生产体系。这种转变不仅提升了制造效率，更重要的是重塑了汽车制造业的竞争格局。<br/>IIoT技术的核心价值与应用场景<br/>工业物联网在整车制造中的应用价值主要体现在三个层面：设备层、系统层和决策层。在设备层面，通过部署各类智能传感器和物联网终端，实现了生产设备运行状态的实时监测和预警。在系统层面，通过数据集成和交互，打破了传统制造系统中的信息孤岛，实现了生产过程的协同优化。在决策层面，基于大数据分析和人工智能算法，为企业管理层提供了更加科学、精准的决策支持。<br/>具体到应用场景，IIoT技术在质量控制方面的表现尤为突出。传统制造模式下，质量检测往往依赖于人工抽检，存在效率低、漏检率高的问题。而通过部署机器视觉检测系统和智能传感器，实现了对产品质量的全程监控和实时预警。例如在焊接工序中，智能监测系统可以实时采集焊接电流、电压等参数，通过算法分析及时发现问题，将质量缺陷消灭在萌芽状态。这种转变不仅提升了产品质量，更重要的是建立了可追溯的质量管理体系。<br/>典型案例：IIOT赋能汽车制造业创新实践<br/>在具体应用中，广域铭岛为某大型汽车制造企业部署了完整的数字孪生系统。通过构建虚拟工厂，实现了对物理工厂的实时映射和动态仿真。更值得一提的是，平台通过人工智能算法，实现了生产参数的自主优化，使整车生产效率提升了22%，同时能耗降低了15%。在质量管理方面，系统能够实时采集超过2000个质量参数，通过机器学习算法建立质量预测模型，将产品缺陷率降低了40%。广域铭岛通过构建供应链协同平台，实现了与300多家供应商的实时数据交互。平台通过智能算法预测零部件需求，优化库存管理，将库存周转率提升了35%，同时确保了生产物料的及时供应。<br/>吉利集团的数字化转型堪称典范。该集团在全球四大研发中心部署了IIoT平台，实现了从冲压、焊接、涂装到总装的全流程数字化监控。特别是在宁波工厂，他们通过引入数字孪生技术，构建了与物理工厂完全对应的虚拟镜像，能够提前发现并解决生产线切换过程中的各种问题。这一创新实践使新车型导入时间缩短了40%，同时将整车生产效率提升了25%。<br/>特斯拉则在智能制造的另一条路径上走得更深。其超级工厂采用了完全自动化的生产体系，通过机器视觉和AI算法实时监控焊接质量，实现了99.99%的缺陷检出率。同时，工厂的能源管理系统也通过IIoT技术实现了能耗的精细化控制，将每台汽车的能源消耗降低20%以上。这种极致的自动化和智能化，使特斯拉在激烈的市场竞争中保持了领先优势。<br/>未来展望：IIoT驱动制造业创新发展<br/>随着5G、人工智能、数字孪生等新技术的成熟应用，IIoT在汽车制造领域的应用将更加深入。未来，我们可以预见更加智能的自主决策系统，更加柔性化的生产模式，以及更加协同的制造生态。工业互联网平台如广域铭岛等，将继续推动制造业向网络化、智能化、服务化方向转型升级。<br/>然而，IIoT的深度应用仍面临诸多挑战，包括数据安全、系统集成、人才培养等方面。制造企业需要制定清晰的数字化转型战略，选择合适的技术合作伙伴，建立完善的数据治理体系。只有这样才能真正释放IIoT技术的价值，在数字化浪潮中赢得竞争优势。<br/>最终，IIoT技术的成功应用不在于技术的先进性，而在于能否为企业创造实际价值。制造企业应该以业务需求为导向，以价值创造为目标，循序渐进地推进数字化转型。通过IIoT技术的创新应用，汽车制造业必将迎来更加智能化、高效化的未来。</p>]]></description></item>  </channel></rss>