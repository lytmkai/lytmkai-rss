<?xml version="1.0" encoding="UTF-8"?><rss version="2.0">  <channel>      <title>SegmentFault - 最近文章</title>      <link>https://segmentfault.com/blogs/newest</link>      <description>SegmentFault 思否</description>      <generator>python segmentfault.py @Pi20</generator>      <item>    <title><![CDATA[Codigger 官网新界面上线，诚邀体验全新浏览风貌 codigger ]]></title>    <link>https://segmentfault.com/a/1190000047553269</link>    <guid>https://segmentfault.com/a/1190000047553269</guid>    <pubDate>2026-01-20 16:16:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>Codigger 官网（<a href="https://link.segmentfault.com/?enc=uRk6m%2B3t8qoCI5WhKVUFyw%3D%3D.itNzHkLgHhbe%2F81vLjmrfplRMNe4gp2Fu46g7y%2FnA22duk2S79D2mUsJsFlPKTt8" rel="nofollow" target="_blank">https://newabc.codigger.com/web/portal/</a>）已完成界面更新，现正式对外开放。本次更新聚焦于浏览体验优化，呈现更直观的视觉设计与更清晰的功能导航，方便用户快速了解平台核心方向，后续核心功能仍在开发推进中。<br/><img width="723" height="433" referrerpolicy="no-referrer" src="/img/bVdnGWj" alt="image.png" title="image.png"/><br/>作为一款围绕分布式计算构建的平台，Codigger 的核心构想包括将算力转化为 “公用事业”—— 支持按需调用节点资源、共享闲置算力；保障数据主权 —— 采用本地存储与加密分片技术，探索数据合规变现路径；同时打造适配分布式场景的工具生态，如集成开发环境 SIDE、终端工具 Terminai 等，为开发者提供协同与效率支持。<br/><img width="723" height="433" referrerpolicy="no-referrer" src="/img/bVdnGWk" alt="image.png" title="image.png" loading="lazy"/><img width="723" height="433" referrerpolicy="no-referrer" src="/img/bVdnGWl" alt="image.png" title="image.png" loading="lazy"/><br/>此次新界面上线，可帮助用户更清晰地获取平台架构、核心理念及工具矩阵相关信息。若您对分布式计算工具与开发生态感兴趣，不妨访问官网，提前体验新界面的浏览逻辑与信息呈现方式，后续平台功能迭代也将通过官网及时同步。<br/><img width="723" height="433" referrerpolicy="no-referrer" src="/img/bVdnGWm" alt="image.png" title="image.png" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[AAAI 2026 | 西北工业大学提出YOLO-IOD，实时增量目标检测新框架 Lab4AI ]]></title>    <link>https://segmentfault.com/a/1190000047553274</link>    <guid>https://segmentfault.com/a/1190000047553274</guid>    <pubDate>2026-01-20 16:15:45</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>AAAI 2026 | 西北工业大学提出YOLO-IOD，实时增量目标检测新框架</h2><p>该篇论文被 AAAI 2026 录用。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553277" alt=" " title=" "/></p><p>论文标题：<em>YOLO-IOD: Towards Real Time Incremental Object Detection</em></p><p><a href="https://link.segmentfault.com/?enc=%2BmMUCG67QX5yK4IiHO7mWA%3D%3D.IeJzzVU7ALl7Sq6u9yA9JhOFB6YJhPWZ180xqixcgDOReVVvfywXqrh4c2hysecu" rel="nofollow" target="_blank">GitHub项目</a></p><p><a href="https://link.segmentfault.com/?enc=AN1IxcVn1x1UWMR8bL0CbA%3D%3D.DIiEYCkSv6dI%2F9T1l8b3muwq%2FDgjJwPwikQBNf8DSWiUg18XoYUrnT9DDk37SVfmrs631oKnn2SEEfhh1lEROJJcb3pP2aTWOBexTX3cYBFK51mPhYhjQtKu2xAtq0nX" rel="nofollow" target="_blank">大模型实验室</a>论文阅读</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553278" alt=" " title=" " loading="lazy"/></p><h3>01 引言</h3><p><a href="https://link.segmentfault.com/?enc=3c1fqgRC3W1OIxqZfIv7WA%3D%3D.cnSRX9%2FCq7E8W89kNPobKjtGy9sD4i9TVUmVugI6ltW9gQ9SWC%2Bj9gct6pnmL2fJBudnX6r3N9sZ6fUYW4xI6qWDxOuzZhD6oxso%2FN%2B9lpOYvp6zolIDi3lkrXag8D0q" rel="nofollow" target="_blank">增量目标检测</a>（IOD）是一个让目标检测模型能够像人类一样持续学习、积累知识的任务。它的核心目标是在不断吸收新类别信息的同时，有效克服对旧类别的“灾难性遗忘”。</p><p>传统方法（如Faster R-CNN）可以逐步学习新类别（比如从猫狗扩展到飞机、船），但这类方法速度慢，无法满足实时检测需求。而速度更快的YOLO模型在增量学习时却像“健忘症患者”，它学完新类别后，容易忘记旧类别。</p><p>论文发现，这种“遗忘”主要源于三大冲突：</p><ul><li>前景-背景混淆：训练新类别时，图中未标注的旧类别物体会被误判为“背景”，导致模型逐渐遗忘它们。</li><li>参数干扰：模型参数像大脑的<a href="https://link.segmentfault.com/?enc=DXa5z2BIAZzrWHt%2FBMZQJQ%3D%3D.Uu2pfU2KYBJWA5GSUD%2BLKmT%2B7PnvQqb20FJ2ZNJNjI8pl242QhWMd2IuMFp8DnSsEFnTFYLOzIHPuDkdzrFvj944Zb4wf77i212x78tAUi7F8A8YkBBGs73X4mhJanN%2B" rel="nofollow" target="_blank">神经元</a>，学习新任务时会修改与旧任务共享的参数，从而破坏原有知识。</li><li>知识蒸馏错位：传统方法用“教师模型”指导“学生模型”，但新旧类别的学习目标不一致，导致指导过程混乱。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553279" alt=" " title=" " loading="lazy"/></p><p>另外，现有IOD基准存在类别划分随意、图像跨阶段重复等问题，难以反映实际应用场景。</p><p>基于以上，本文构建一个基于<a href="https://link.segmentfault.com/?enc=BnC%2Bd30DwHcQUBeW%2B5cYBw%3D%3D.LHKCYOplrp6I9XPbAaO9KQQ2oLg2b44YUiHTsuuD1NiedHr2vtymHYZWQB4E%2FS2W5KBvYRUSJe5SrHM%2FZrZzU7Kbh0r9uz6TMFRwq8cbpzIanfVPM2zbqygFyzG0SndW" rel="nofollow" target="_blank">YOLO-World</a>的实时增量目标检测框架<a href="https://link.segmentfault.com/?enc=kJqinzXfd4a2QDhleFq0Ew%3D%3D.IL90Pmb3H0HPjrbbuU1U9kAJrBo3fkNWUXyQ0SiDKfe%2B8w41ZxSTGQJi87sa%2Ffq1Er35oWGM%2B%2FCdIAxTFuWiMWZDToJEn9w3JqwgV7MVpi4fO%2B00J%2FL52vhRh2E48NvW" rel="nofollow" target="_blank">YOLO-IOD</a>，通过阶段化参数高效微调解决YOLO模型在增量学习中的知识冲突问题，实现对新类别的持续学习的同时有效保留历史类别知识。</p><h3>02 核心思路</h3><h4>2.1三大妙招</h4><p>论文提出YOLO-IOD框架：基于现成的<a href="https://link.segmentfault.com/?enc=sF6Su6u3Vzh86xtRxosSfA%3D%3D.cNObixpatjp2GNAra5YR%2Ft1Q3jz0p7USYF7%2FWtJ6D%2Bp%2F9GmrDpv57%2Br3%2BcOPsk9tS0geNl2CbiGVPf4za0HRMLIcmSC%2F7FIiBD6LEm8glfAhOXA2kj%2BTMNdWeGF3VQRJ" rel="nofollow" target="_blank">YOLO-World</a>模型，通过三招解决上述问题。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553280" alt=" " title=" " loading="lazy"/></p><h5>妙招1：CPR（冲突感知伪标签精炼）— 解决 “前景背景搞混”</h5><ul><li>增强伪标签损失：采用<a href="https://link.segmentfault.com/?enc=vD9RaMS1EFpXcLf%2BSV71NA%3D%3D.HaZlP5u3hf%2BuI9HKxYWFnzutgcrrQ7mLepkvRVnjEvT%2FU6GaJuKUQKZQ6vLjnNI2GOWka%2BwkvMruzxuUBdGWd%2FTuHKl%2FzzQpDcXC0Ln2uB3uwWronsUP6OoR3%2BuZQQkV" rel="nofollow" target="_blank">置信度</a>对齐的焦点损失和自适应熵正则化，充分利用不同置信度的伪标签。即：对模型自己生成的旧类别预测（伪标签）按置信度加权，高置信度的重点学习，低置信度的谨慎参考，避免错误引导。</li><li>聚类未知伪标签：构建通用词汇集，通过<a href="https://link.segmentfault.com/?enc=eYChTVFy3HDxTb38x3YUYA%3D%3D.zOKNmJQ016cwkYSlz0mrwdO%2Bubyrxafj18%2FjiXhyGBzQEvINOJ347gzAFfkxxl04gHC2dfekDi%2Frs2E9x658%2BzYU1V%2FDrb2XUi%2Bz9u16Pfpw80D18wSnV58lcb7NaZV%2B" rel="nofollow" target="_blank">开放词汇检测</a>识别未标注前景目标，对其文本特征进行频率加权 K-Means 聚类，将未来任务类别转化为 “未知超类” 进行学习，避免前景 - 背景混淆。</li></ul><h5>妙招2：IKS（基于重要性的核选择）— 解决 “参数互相干扰”</h5><p>只选择对当前任务关键的部分参数（约12%的卷积核）进行微调，其他参数冻结不动，像“保护重要记忆不受新知识干扰”。</p><h5>妙招3：CAKD（跨阶段非对称知识蒸馏）— 解决 “老师教错方向”</h5><p>将学生模型的特征分别输入旧教师模型和新教师模型的检测头，通过分类和回归蒸馏损失传递知识，并使用焦点权重抑制背景区域干扰。即：让“学生模型”同时接受两位老师指导。</p><ul><li>老老师：就是之前学完旧物体的模型，只负责教 “旧知识”，而且会主动忽略和新物体无关的内容（比如只教 “猫狗”，不干扰 “无人机” 的学习）；</li><li>新老师：专门用新数据训练的临时模型，只负责教 “新物体知识”，也会忽略旧物体的干扰；</li><li>新模型（学生）：同时听两个老师的课，把旧知识和新知识融合起来，这样既不会忘旧的，也能学好新的。</li></ul><h4>2.2 引入LoCo COCO基准</h4><p>现有评测基准存在“数据泄露”——同一张图片在不同阶段重复使用，使模型表现虚高。论文提出<a href="https://link.segmentfault.com/?enc=e8J%2FlyN1aoFvwdbphJ789Q%3D%3D.ck82AD1CPcg7%2BlXkoKVl49STR6PJO2xWnHaE2xcDGE8A0CVrp%2Bg%2BINiH9q5Tl9E3iDKwi%2FjmxqtUvcfKL0nyyWHUHROBpqe%2FZL1dljjE05p4guAibRL497pklV%2FsHkif" rel="nofollow" target="_blank">LoCo COCO基准</a>，通过两类改进更贴近现实：</p><ul><li>按共现关系分组：将常同时出现的类别（如“汽车”和“行人”）分到同一阶段，避免强行拆分。</li><li>禁止图像重复：每张图片仅出现在一个阶段，杜绝数据泄露。</li></ul><h3>03 实验结果</h3><h4>3.1 在传统COCO基准上的性能</h4><p>单步增量设置下，YOLO-IOD在40+40和70+10任务中分别达到53.0%和52.4%的mAP，相对联合训练的差距降至2.7%和3.9%，显著优于BPF、CL-DETR等方法。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553281" alt=" " title=" " loading="lazy"/></p><p>多步增量设置下，在40-10、20-20等任务中均取得最优结果，尤其在10-10任务中相对差距仅8.8%，显著优于对比方法。</p><h4>3.2 在LoCo COCO基准上的鲁棒性</h4><p>所有方法在 LoCo COCO 上 AP 均有 0.6%-2.0% 下降（验证数据泄露的影响），但 YOLO-IOD 仍保持优势，40+40、70+10、40-20 设置下 AP 分别超此前最佳方法 GCD 7.5、5.9、8.5 个百分点。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553282" alt=" " title=" " loading="lazy"/></p><h4>3.3 消融实验</h4><ul><li>三大模块协同有效：CPR、IKS、CAKD 分别带来显著性能提升，组合后效果最优。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047553283" alt=" " title=" " loading="lazy"/></li><li>CAKD 双教师架构最优：早期阶段“仅当前教师”适配新类别更快，后期“仅旧教师”保留知识更优，双教师融合始终表现最佳。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047553284" alt=" " title=" " loading="lazy"/></li><li>IKS 核选择比例：κ=12% 时实现稳定性与可塑性平衡，性能最优。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047553285" alt=" " title=" " loading="lazy"/></li></ul><h3>04 快速上手</h3><p>作者在GitHub上公开了该项目，并且在环境安装步骤中提到：“请按照 YOLO-World 的安装说明来设置环境。”</p><p><a href="https://link.segmentfault.com/?enc=gAsPaXUTgelh0zjjwItmSw%3D%3D.aV76X3Ggdo0Xdya31AjKC7G%2BazjGU3azcLBuVnILWxPvH16HrBw72pS3lS68LzNAER%2F83U05wyNFOdCJs8vat8XroqQJs3kr3W7ijekj0SF16Vk19pGWVzf0P7o1Eje%2B" rel="nofollow" target="_blank">大模型实验室</a>Lab4AI已经内置好了<a href="https://link.segmentfault.com/?enc=vyBnYxvkl4IzsjzM5SLiJA%3D%3D.FObKdTYI2j3IbGsS5XyvEcJrVkyQBT5XmjxAVY%2FSq9ngT%2BFmprgSI93WTgwSZ1lY%2FQdF1OShvz8nH3Bgr7BBjnDGGm6I6g%2Fve51rWzNbPbSRr33Q4%2BpfWSuDV3FCux7i" rel="nofollow" target="_blank">YOLO-World</a>论文的复现所需的环境。所以，您可以登录<a href="https://link.segmentfault.com/?enc=IXKSIS8VRqQBa%2FW2f7eu1Q%3D%3D.v9YPyLFe2HW%2Bmc6M9ns0aGk%2FyxHKRedMl0UZhM3SwG6B9KgCW79PvfBco6Efv%2FrQAiENZspbnDQaQ2B%2BWRAsahtp1ntphY1q3WsAYFS86t70i5skaduetdqaW8wg8txN" rel="nofollow" target="_blank">大模型实验室</a>Lab4AI来直接使用该环境进行体验本论文的训练过程。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553286" alt=" " title=" " loading="lazy"/></p><h3>05 总结</h3><p>论文针对 <strong>YOLO 框架下增量目标检测的知识冲突问题</strong>，提出 YOLO-IOD 实时框架，通过 <strong>CPR、IKS、CAKD</strong> 三大模块分别解决前景-背景混淆、参数干扰、蒸馏错位，实现知识保留与新增类别学习的平衡。</p><p>提出的 <strong>LoCo COCO 基准</strong>消除了跨阶段数据泄露，更贴合实际应用场景，为 IOD 方法评估提供了公平、真实的平台。</p><p>大量实验验证了 <strong>YOLO-IOD 在传统 COCO 和 LoCo COCO 基准上的 SOTA 性能</strong>，且保持<a href="https://link.segmentfault.com/?enc=NktamUE2Kj7A9dE%2FJv6STg%3D%3D.z4WILVY945wIcUwvE0HPJ34VGhADTpu6qFyxRu%2BaO7oC15jWZMF9O8jD1zrQxE1pgxunJSwicZtjwcKMfer53AfSg9XMgzBwQOH3SRLQcIrtkiI2SUS%2F1N686KirVWDX" rel="nofollow" target="_blank">实时推理</a>速度，证实了方法的有效性与实用性。</p><p><strong>关注“<a href="https://link.segmentfault.com/?enc=Ylmg%2FME6hVRbqhpOzS%2BK2A%3D%3D.q7Y94TsGVkjWtEZZh9fPbefLPNcEHvBe%2F6ql6WlRmAf9VPutnlFbIuCZ8RcrITqbIy%2BWM5CluiXbLTawlfWrkIKir5OS2JdjVoayW4eBRWvB1IseOcKQhW8VlqT%2BAHJC" rel="nofollow" target="_blank">大模型实验室</a>Lab4AI”，第一时间获取前沿AI技术解析！</strong></p>]]></description></item><item>    <title><![CDATA[Linux开机默认显示grub 打篮球的凳子 ]]></title>    <link>https://segmentfault.com/a/1190000047553389</link>    <guid>https://segmentfault.com/a/1190000047553389</guid>    <pubDate>2026-01-20 16:14:59</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在 Ubuntu 的默认配置中，当系统检测到仅存在一个操作系统时，GRUB 启动菜单会被隐藏，系统会直接进入内核启动流程。这种“无感启动”在桌面用户场景下较为友好，但在 服务器、运维、开发和多内核管理场景 中，会带来一系列明显的痛点。</p><p>可通过配置grub控制默认是否显示grub界面以及倒计时相关的配置</p><h2>配置文件路径</h2><ol><li><code>ubuntu</code> grub配置文件路径</li></ol><p><code>/etc/default/grub</code></p><ol start="2"><li><code>centos</code> grub配置文件路径</li></ol><p><code>/etc/sysconfig/grub</code></p><h2>默认配置文件内容</h2><pre><code class="ini"># If you change this file, run 'update-grub' afterwards to update
# /boot/grub/grub.cfg.
# For full documentation of the options in this file, see:
#   info -f grub -n 'Simple configuration'

GRUB_DEFAULT=0
GRUB_TIMEOUT_STYLE=hidden
GRUB_TIMEOUT=0
GRUB_DISTRIBUTOR=`lsb_release -i -s 2&gt; /dev/null || echo Debian`
GRUB_CMDLINE_LINUX_DEFAULT="quiet splash"
GRUB_CMDLINE_LINUX=""

# Uncomment to enable BadRAM filtering, modify to suit your needs
# This works with Linux (no patch required) and with any kernel that obtains
# the memory map information from GRUB (GNU Mach, kernel of FreeBSD ...)
#GRUB_BADRAM="0x01234567,0xfefefefe,0x89abcdef,0xefefefef"

# Uncomment to disable graphical terminal (grub-pc only)
#GRUB_TERMINAL=console

# The resolution used on graphical terminal
# note that you can use only modes which your graphic card supports via VBE
# you can see them in real GRUB with the command `vbeinfo'
#GRUB_GFXMODE=640x480

# Uncomment if you don't want GRUB to pass "root=UUID=xxx" parameter to Linux
#GRUB_DISABLE_LINUX_UUID=true

# Uncomment to disable generation of recovery mode menu entries
#GRUB_DISABLE_RECOVERY="true"

# Uncomment to get a beep at grub start
#GRUB_INIT_TUNE="480 440 1"
</code></pre><p>主要关注以下三个参数</p><pre><code class="ini">GRUB_DEFAULT=0
GRUB_TIMEOUT_STYLE=hidden
GRUB_TIMEOUT=0</code></pre><p><code>GRUB_DEFAULT</code></p><p>默认引导项，可以有以下几种值</p><ol><li><code>saved</code> 代表上次启动时选择的引导项</li><li>从0开始的数字，第一个引导项是0，第二个引导项是1，以此类推</li></ol><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553392" alt="" title=""/></p><p>如上图<code>Previous Linux Versions</code>存在的子菜单可以用<code>2&gt;0</code>或者<code>2&gt;1</code>表示</p><ol start="3"><li>grub选项名</li></ol><p><code>GRUB_TIMEOUT_STYLE</code></p><p>grub显示风格，默认值是<code>menu</code></p><p>可选值有<code>menu</code>,<code>hidden</code>,<code>countdown</code></p><p>如果该选项未设置或者值设为menu,启动时将显示grub，并开启<code>GRUB_TIMEOUT</code>倒计时。倒计时结束前可以按任意键中断倒计时，否则倒计时结束后会引导<code>GRUB_DEFAULT</code>启动项。</p><p>如果选项设置为<code>hidden</code>或<code>countdown</code>,在显示grub界面之前会开启<code>GRUB_TIMEOUT</code>倒计时。倒计时结束前按<code>ESC</code>键中断倒计会进入grub界面，如果没有按<code>ESC</code>键进行中断操作，倒计时结束后会引导<code>GRUB_DEFAULT</code>启动项。</p><p><code>hidden</code>和<code>countdown</code>的区别在于，<code>hidden</code>不显示倒计时读秒，<code>countdown</code>显示倒计时读秒</p><p><code>GRUB_TIMEOUT</code></p><p>这个参数代表grub的超时时间，单位是秒，默认值为<code>5</code>,设置为<code>0</code>代表不显示grub界面，<code>-1</code>代表一直等待</p><h2>例子</h2><pre><code class="ini">GRUB_DEFAULT=0
GRUB_TIMEOUT_STYLE=menu
GRUB_TIMEOUT=5</code></pre><p>修改后执行<code>update-grub</code>应用配置，重启后必定进入grub界面</p><pre><code class="ini">GRUB_DEFAULT=1
GRUB_TIMEOUT_STYLE=countdown
GRUB_TIMEOUT=5</code></pre><p>修改后执行<code>update-grub</code>应用配置，重启后在5秒倒计时结束前按<code>ESC</code>必定进入grub界面</p><pre><code class="ini">GRUB_DEFAULT="2&gt;1"
GRUB_TIMEOUT_STYLE=menu
GRUB_TIMEOUT=5</code></pre><p>修改后执行<code>update-grub</code>应用配置，重启后在5秒倒计时结束后会引导指定启动项，这个方法对于客户要求进入旧版本内核比较好用</p>]]></description></item><item>    <title><![CDATA[rector-rules - 提供标准化的常量、变量、函数、类、属性和方法命名以及其他 Rector]]></title>    <link>https://segmentfault.com/a/1190000047553402</link>    <guid>https://segmentfault.com/a/1190000047553402</guid>    <pubDate>2026-01-20 16:14:22</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>rector-rules - 提供标准化的常量、变量、函数、类、属性和方法命名以及其他 Rector 规则</h2><blockquote><p>之前写过用 Rector <a href="https://link.segmentfault.com/?enc=cZ9NLpAMFoQ0hrziyts3Qw%3D%3D.LjleJbf50eL2Q5c9syw94Bo7IeTASVaD4UaByONPPaZ4es6h%2F9DSvvkiOBYuYYxz" rel="nofollow" target="_blank">《统一规范化代码的命名风格》</a>，现在已经整理发布为 Composer 包了。</p><p><a href="https://link.segmentfault.com/?enc=zVZ2755Pp99li6ys7xa%2BSA%3D%3D.6i%2BF4mc5%2FN9xqhIko2feSCYS%2F45nZsg%2B3Xo3SkR24NBgAzGQysCC%2BlQ2v6YsMZs7" rel="nofollow" target="_blank">rector-rules</a> - 提供标准化的常量、变量、函数、类、属性和方法命名以及其他 Rector 规则。</p></blockquote><h3><a href="https://link.segmentfault.com/?enc=%2B%2FjLWt5BNPOjSvcoOQcG8g%3D%3D.pD9vqFvGK%2BZdSxvAUtM7xllDw5Mj8sVWhF5T0%2BhrGgBIDiw5Y8efE3aOVw2cvJluPd9hEE4x%2FIIVwENzx2RH56%2FWOSLg9y5nZAtWOzA1fsY%3D" rel="nofollow" target="_blank">Rector 规则总览</a></h3><h3><a href="https://link.segmentfault.com/?enc=czbTe8kw9iw1ZkL3S%2FplxQ%3D%3D.HrQqpzhNxBZrR65cTc6tH1UdjeXTn3aQ3A2XSwf%2FveL%2B6LyL3JFKO%2BYe%2Fu%2BuuB6hE8Qc8jHelpO3%2FO6BskRjxQ%3D%3D" rel="nofollow" target="_blank">Rector 规则集总览</a></h3><ul><li><code>Guanguans\RectorRules\Set\SetList::ALL</code></li><li><code>Guanguans\RectorRules\Set\SetList::COMMON</code></li><li><code>Guanguans\RectorRules\Set\SetList::PHPBENCH</code></li><li><code>Guanguans\RectorRules\Set\SetList::PHPSTAN</code></li><li><code>Guanguans\RectorRules\Set\SetList::RECTOR</code></li></ul><h3>配置使用规则集和规则</h3><pre><code class="php">use Guanguans\RectorRules\Rector\File\SortFileFunctionStmtRector;
use Guanguans\RectorRules\Rector\Name\RenameToPsrNameRector;
use PhpParser\NodeVisitor\ParentConnectingVisitor;
use Rector\Config\RectorConfig;

return RectorConfig::configure()
    -&gt;withSets([
        Guanguans\RectorRules\Set\SetList::ALL,
        // ...
    ])
    // ...
    -&gt;registerDecoratingNodeVisitor(ParentConnectingVisitor::class)
    -&gt;withConfiguredRule(RenameToPsrNameRector::class, [
        'assertMatches*Snapshot', // 排除 spatie/pest-plugin-snapshots 包的函数名称
        'beforeEach', // 排除 pestphp/pest 包的函数名称
        'PDO', // 排除 PDO 类名称
    ])
    // ...
    -&gt;withRules([
        SortFileFunctionStmtRector::class,
        // ...
    ]);</code></pre><h3>另外推荐下其他相关类似的包</h3><ul><li><a href="https://link.segmentfault.com/?enc=EEoxK2QJm1INS4iQZgCP4A%3D%3D.q8YTiv2RHEL6POHVA3OI1mzIrJSamRvCvO%2B0t%2FctF5oi60bP796Oq3%2Fbnkw8MAF3OUPNxFyN1xJ61nXBwHGWEA%3D%3D" rel="nofollow" target="_blank">php-cs-fixer-custom-fixers</a> - 用 php-cs-fixer 统一修复项目中的非 php 格式文件</li><li><a href="https://link.segmentfault.com/?enc=gVRgZcNn2HzUrQ%2BXYl7ESA%3D%3D.%2Fk69omMy7rlow%2B%2BFoqO41wgFCKVR6uWOEi%2B0hphYUKKYBD6U8nvqwTRl3KPmf8Z6LFa5At81eD6GLhXwZFVOMA%3D%3D" rel="nofollow" target="_blank">monorepo-builder-worker</a> - 用 monorepo-builder 自动化生成 <a href="https://link.segmentfault.com/?enc=zyI%2BBTTcEiNgylr8L4BlYg%3D%3D.JKiUz0r5tbRrvf1kDkad%2BHteiFo%2BWhaH%2FLE6jaRUIiqJxQCJ9PkdxERosnAyrnbJRAb7%2FygL%2FpCt5WnhF5XpiytRK7RywZnIajwwsoC9Gjs%3D" rel="nofollow" target="_blank">changelog</a> / 自动化项目<a href="https://link.segmentfault.com/?enc=81etJES2n%2FEhWLJqjN%2BeXw%3D%3D.uceA5fjTVwScTFZMuOrxHE2Q8tyJ4WSj0He6RjNlQMlQOu8RUPiTKkLYcdfAjWZcSyoHq9p9wy%2FX7Y%2FvZNnflw%3D%3D" rel="nofollow" target="_blank">发布流程</a></li><li><a href="https://link.segmentfault.com/?enc=I74CzXLMCtHLX2a1CSvv3w%3D%3D.n%2F3jM4fd9iGUsNO6H1g%2FEJos5w7UvZzAwaFenpiz4JdywDWcnxsT3Zo1kRVmbRti" rel="nofollow" target="_blank">phpstan-rules</a> - 一些附加的 phpstan 规则</li></ul>]]></description></item><item>    <title><![CDATA[rector-rules - 提供标准化的常量、变量、函数、类、属性和方法命名以及其他 Rector]]></title>    <link>https://segmentfault.com/a/1190000047553406</link>    <guid>https://segmentfault.com/a/1190000047553406</guid>    <pubDate>2026-01-20 16:13:38</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>rector-rules - 提供标准化的常量、变量、函数、类、属性和方法命名以及其他 Rector 规则</h2><blockquote><p>之前写过用 Rector <a href="https://link.segmentfault.com/?enc=HVIpeF135dI46ftGMy7DnA%3D%3D.74Mdy%2F%2F%2BHAEUZeXes%2FuoJJW4gdGjtAkv82D28n%2FE1Tq3PLsvjog5Mk73qFM6OlZr" rel="nofollow" target="_blank">《统一规范化代码的命名风格》</a>，现在已经整理发布为 Composer 包了。</p><p><a href="https://link.segmentfault.com/?enc=Vkf7zMflBYHTM5ac3KqQSg%3D%3D.dyHWhc1JAJxY3MhyGhzSpbeokywCyAhyeR1yeKq31HzvInsWOGakMAojZBlTiwjH" rel="nofollow" target="_blank">rector-rules</a> - 提供标准化的常量、变量、函数、类、属性和方法命名以及其他 Rector 规则。</p></blockquote><h3><a href="https://link.segmentfault.com/?enc=c3TLnOA7oR405gWcp3%2FAWA%3D%3D.iDDpqHQF2EboJgyLg2lzaOjARy9DMDujZoFBazQqMovaV8T4DnZX9eT2j7c9xU%2FUe0cD7%2FsgD6c6Rv5FzVUGKwFRL1nnZOwejzzzu04zKig%3D" rel="nofollow" target="_blank">Rector 规则总览</a></h3><h3><a href="https://link.segmentfault.com/?enc=qKMRrMES3jwH6ebs4vporg%3D%3D.GTtp9dDl%2F5y9j2DbZ%2FDttkPSv9fX1Qbb5C3qpLsG3myH5erReApbEfCBna%2FuSeTLv2aX6Cp5AXvuLlSsEaHuFw%3D%3D" rel="nofollow" target="_blank">Rector 规则集总览</a></h3><ul><li><code>Guanguans\RectorRules\Set\SetList::ALL</code></li><li><code>Guanguans\RectorRules\Set\SetList::COMMON</code></li><li><code>Guanguans\RectorRules\Set\SetList::PHPBENCH</code></li><li><code>Guanguans\RectorRules\Set\SetList::PHPSTAN</code></li><li><code>Guanguans\RectorRules\Set\SetList::RECTOR</code></li></ul><h3>配置使用规则集和规则</h3><pre><code class="php">use Guanguans\RectorRules\Rector\File\SortFileFunctionStmtRector;
use Guanguans\RectorRules\Rector\Name\RenameToPsrNameRector;
use PhpParser\NodeVisitor\ParentConnectingVisitor;
use Rector\Config\RectorConfig;

return RectorConfig::configure()
    -&gt;withSets([
        Guanguans\RectorRules\Set\SetList::ALL,
        // ...
    ])
    // ...
    -&gt;registerDecoratingNodeVisitor(ParentConnectingVisitor::class)
    -&gt;withConfiguredRule(RenameToPsrNameRector::class, [
        'assertMatches*Snapshot', // 排除 spatie/pest-plugin-snapshots 包的函数名称
        'beforeEach', // 排除 pestphp/pest 包的函数名称
        'PDO', // 排除 PDO 类名称
    ])
    // ...
    -&gt;withRules([
        SortFileFunctionStmtRector::class,
        // ...
    ]);</code></pre><h3>另外推荐下其他相关类似的包</h3><ul><li><a href="https://link.segmentfault.com/?enc=695hzbWgFent%2F7sY7%2BGYHQ%3D%3D.CknF%2BetCE2x1q4U86dBfRFvKo5HH6bozduhauCaubNvwjmfkZggQwjgO3agObGfaRmCEH6uaFruKeKkvQJCGUw%3D%3D" rel="nofollow" target="_blank">php-cs-fixer-custom-fixers</a> - 用 php-cs-fixer 统一修复项目中的非 php 格式文件</li><li><a href="https://link.segmentfault.com/?enc=LV6sMsTGYYd%2B6p1oRsD3zA%3D%3D.1DV2JORcEVvUqdbiotv2boepz9%2BGpKdp8ALQD9tB98%2Fw8ZN6nUQonjbnMjAsVIcEYl7XT%2BtIeIV45zS%2FGY4hxw%3D%3D" rel="nofollow" target="_blank">monorepo-builder-worker</a> - 用 monorepo-builder 自动化生成 <a href="https://link.segmentfault.com/?enc=ZQkJdAoqAwA1i40qy%2F0hcw%3D%3D.FFqHMJ8qJs%2BD8EGwV4aS097JdDXprNgLrxyFVza%2Fq%2FQHd9jE2LL9Vzxe22NUTKt1mRG7Tiu7b%2BCquMhco20QWKGA%2FkPSJzNUB7IKb9KJbXc%3D" rel="nofollow" target="_blank">changelog</a> / 自动化项目<a href="https://link.segmentfault.com/?enc=I30IOc4Z3dt4YvTWC3K8zA%3D%3D.gxnfV2%2F%2Brvck%2FDD6M0onmhEMlPEMSgdM7ngb8ZDQfdeZizED1SeU0DxyGUd9ULuT5rtV62TDiaut056X3Xe2Xg%3D%3D" rel="nofollow" target="_blank">发布流程</a></li><li><a href="https://link.segmentfault.com/?enc=BrzFTPbSl%2FqYEhjdEwVXMQ%3D%3D.OzvMuH3vOV%2Fe3AUo1uoM7E8%2BRRo8q2pm1TKp4UEPJHOEfM889wx6rpUYhLiO%2BS5M" rel="nofollow" target="_blank">phpstan-rules</a> - 一些附加的 phpstan 规则</li></ul>]]></description></item><item>    <title><![CDATA[rector-rules - 提供标准化的常量、变量、函数、类、属性和方法命名以及其他 Rector]]></title>    <link>https://segmentfault.com/a/1190000047553411</link>    <guid>https://segmentfault.com/a/1190000047553411</guid>    <pubDate>2026-01-20 16:12:44</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>rector-rules - 提供标准化的常量、变量、函数、类、属性和方法命名以及其他 Rector 规则</h2><blockquote><p>之前写过用 Rector <a href="https://link.segmentfault.com/?enc=0CS5TIhMA9WlCxPlugS90A%3D%3D.gxybq7s%2BGTB05ptS2%2BqBZE6Uzkf2dy8xmu7e9nHb3NrzmpPi4Gtv8XDmOuWvnBAJ" rel="nofollow" target="_blank">《统一规范化代码的命名风格》</a>，现在已经整理发布为 Composer 包了。</p><p><a href="https://link.segmentfault.com/?enc=sLBt%2FJMgAsnpj8lXIR95cw%3D%3D.%2Fud%2BiDttHhGYqbWwHyqOXfkfsn2ZTg11eiq6mhtMosWR011pG7SE30Gv%2BhQndDmn" rel="nofollow" target="_blank">rector-rules</a> - 提供标准化的常量、变量、函数、类、属性和方法命名以及其他 Rector 规则。</p></blockquote><h3><a href="https://link.segmentfault.com/?enc=sHJ14Wsads3ZWa%2BYTFz9pw%3D%3D.LhldVxNEPTjFaVyH%2BuaoHAxkG%2Fzc%2Bk95j94U25UPyWKN4Uy%2FaJQfNXVJeevS9LwrM6GLxU3yNvtKua6IlI9iXHLinNQP9oCpRNmwkus3Zsk%3D" rel="nofollow" target="_blank">Rector 规则总览</a></h3><h3><a href="https://link.segmentfault.com/?enc=JCWve7ggftko%2FnxcOxdbGA%3D%3D.nCiw05GWiYt6wkiSjNtyU6AyBJnF3w67RK75lWi%2BpMmqe1B0s7Vi7BKvixX5CZyZpIPZ5znBKVi7Zh12lgTziQ%3D%3D" rel="nofollow" target="_blank">Rector 规则集总览</a></h3><ul><li><code>Guanguans\RectorRules\Set\SetList::ALL</code></li><li><code>Guanguans\RectorRules\Set\SetList::COMMON</code></li><li><code>Guanguans\RectorRules\Set\SetList::PHPBENCH</code></li><li><code>Guanguans\RectorRules\Set\SetList::PHPSTAN</code></li><li><code>Guanguans\RectorRules\Set\SetList::RECTOR</code></li></ul><h3>配置使用规则集和规则</h3><pre><code class="php">use Guanguans\RectorRules\Rector\File\SortFileFunctionStmtRector;
use Guanguans\RectorRules\Rector\Name\RenameToPsrNameRector;
use PhpParser\NodeVisitor\ParentConnectingVisitor;
use Rector\Config\RectorConfig;

return RectorConfig::configure()
    -&gt;withSets([
        Guanguans\RectorRules\Set\SetList::ALL,
        // ...
    ])
    // ...
    -&gt;registerDecoratingNodeVisitor(ParentConnectingVisitor::class)
    -&gt;withConfiguredRule(RenameToPsrNameRector::class, [
        'assertMatches*Snapshot', // 排除 spatie/pest-plugin-snapshots 包的函数名称
        'beforeEach', // 排除 pestphp/pest 包的函数名称
        'PDO', // 排除 PDO 类名称
    ])
    // ...
    -&gt;withRules([
        SortFileFunctionStmtRector::class,
        // ...
    ]);</code></pre><h3>另外推荐下其他相关类似的包</h3><ul><li><a href="https://link.segmentfault.com/?enc=Rj%2F0LrtiHTElmfduhsFI%2FQ%3D%3D.zQIa7AzKJTCIgOmrbW3ylqhLeZLP92MdbcVCMN%2BX6T6kAxB62OtK%2FBozpwQJzp93bpQbyn%2Bc3KCPrxR8rPjZ3Q%3D%3D" rel="nofollow" target="_blank">php-cs-fixer-custom-fixers</a> - 用 php-cs-fixer 统一修复项目中的非 php 格式文件</li><li><a href="https://link.segmentfault.com/?enc=%2FErYJ3hvxR5czns82WnXyA%3D%3D.s4ZdGOgPO7%2BR1JRXjskzIzBrEyHVZJ8SJu7ad3N0TypG0TyTQmOd8JlwE8I54nAeG0n7AzRTWYzkrlhVcKFU%2Bg%3D%3D" rel="nofollow" target="_blank">monorepo-builder-worker</a> - 用 monorepo-builder 自动化生成 <a href="https://link.segmentfault.com/?enc=ObvKLN8Fw3s3%2B0VKFBoJrA%3D%3D.cOqVr6RHcYxsI0waPK4EIKxAWEsIVVsGzQmbDYL6%2FO0HfqglZgxJ8SNa%2FTK83jlNEeu7EKJ3z9ZwcPsqNj08kbgN3MeE0vOe3KTehNjrrco%3D" rel="nofollow" target="_blank">changelog</a> / 自动化项目<a href="https://link.segmentfault.com/?enc=xd8Lnh6AnibTrPleohRvvQ%3D%3D.w4bUhSX20f3K%2Fv8JunF2BJoQT4fsXG9l61VFBQjlv8Xnud4K0lUNk59Xg1B%2FchWCw858YXiUQCqyGInlImM%2BTg%3D%3D" rel="nofollow" target="_blank">发布流程</a></li><li><a href="https://link.segmentfault.com/?enc=lcr3cemoTSk4U12tJCXWvw%3D%3D.xNP5Fx7rnPV0fABDOfliONixgCGNnyGWeJ7xeX59Go2RYrmzHZvuxW3061BmvRO%2F" rel="nofollow" target="_blank">phpstan-rules</a> - 一些附加的 phpstan 规则</li></ul>]]></description></item><item>    <title><![CDATA[清华联合字节刷新 3D 头像技术！FlexAvatar 实现 “少图输入 + 高保真动态” 双重突破]]></title>    <link>https://segmentfault.com/a/1190000047553428</link>    <guid>https://segmentfault.com/a/1190000047553428</guid>    <pubDate>2026-01-20 16:11:44</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>清华联合字节刷新 3D 头像技术！FlexAvatar 实现 “少图输入 + 高保真动态” 双重突破</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553431" alt=" " title=" "/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553432" alt=" " title=" " loading="lazy"/></p><p>论文标题：<em>FlexAvatar: Flexible Large Reconstruction Model for Animatable Gaussian Head Avatars with Detailed Deformation</em></p><p>作者团队：<a href="https://link.segmentfault.com/?enc=3UcoGill3glPuz5CgNUTEA%3D%3D.eizzzV%2Bn8KrhWpcjrq8Z6%2FUK7jWTcsNHvzcM2IOwUJA5Ww7mjMANmSkCkaS2j0EFoj7N4yUEPljgLvHsBboOKQppg4LS7Npzt5Ux9tyisq1BhZoEsGkI8bY2uIfCwYy4" rel="nofollow" target="_blank">清华大学</a>、<a href="https://link.segmentfault.com/?enc=awdbVRDZOxGAZrpEc7DRnw%3D%3D.1lOdMFGqe3bbUiNb9od0Huo2rQN%2B3b8gJC58N7Xj%2F7p6ovDvPeC1oU%2Fv88ckfDe3ljNJhMWtmoB9uyBWghx%2FwENxBNLvoIxlM6HpPP6PBy8ZqvbjuLALtsOMOyfuVO0j" rel="nofollow" target="_blank">字节跳动</a></p><p>发布时间：2025年12月19日</p><p><a href="https://link.segmentfault.com/?enc=6dGFpqSxDZPUfiEg8xXH6Q%3D%3D.zgEWHZ2JYrZT2QQuqskzfte7If6G53U08UMzpJo8srO89lz%2F6JluNjRCLyw7t%2Fm%2B" rel="nofollow" target="_blank">论文链接</a></p><p><a href="https://link.segmentfault.com/?enc=D9mieuHsp3Y6Hn5ftQ%2FCBw%3D%3D.5YzlsO9Cnb5G6%2Br9fIzZqIE%2BxeXPve1pkS2RMO3dgEhhgUW7rzqCtLF6zlSAtBy033efiKauIM0q52DaflDp2il%2FhIIlLXGG7ljcN%2Bg2FngPBSWGmE%2FfpbTh%2FVVdl1Xt" rel="nofollow" target="_blank">大模型实验室链接</a>Lab4AI论文阅读</p><h3>🔍背景</h3><p>以前做 3D 头像，要么得用专业设备拍几十上百张不同角度的照片，普通人搞不定；要么做出来的头像假，侧面看变形，做表情时没细节；要么动起来卡顿，或者只能做几种固定表情，没法自然还原复杂动作；要么得花几小时甚至几天调教模型，没法快速得到自己的头像。</p><h3>🔍研究目的</h3><p>本研究旨在构建一个无需相机位姿与表情标注、支持单张或稀疏输入的高保真可驱动3D头部虚拟人生成框架。</p><p>无需相机姿态和表情标签，仅从单张或稀疏图像中生成高保真、几何一致的可动画 3D 头部头像，同时兼顾实时渲染效率与动态细节真实性，填补现有技术在灵活性、保真度与实时性之间的平衡缺口。</p><h3>🔍本文核心贡献</h3><p>1️⃣灵活的重建模型：提出首个免相机位姿、免表情标签、支持任意数量输入的3D高斯虚拟人框架，基于结构化头部查询令牌（Head Query Tokens）实现特征聚合；</p><p>2️⃣动态高斯变形解码：设计以UV位置图为条件的UNet解码器，在UV空间生成表情相关的高斯属性变化，实现实时高保真驱动；</p><p>3️⃣数据分布调整策略：通过锚点表情筛选与相似帧检索，平衡训练集表情分布，提升动态细节学习效率；</p><p>4️⃣高效微调机制：10秒级的测试时优化可增强身份细节，且不影响实时驱动性能。</p>]]></description></item><item>    <title><![CDATA[西北工业大学StereoMV2D突破3D物体检测深度难题，精度与效率兼得 Lab4AI ]]></title>    <link>https://segmentfault.com/a/1190000047553524</link>    <guid>https://segmentfault.com/a/1190000047553524</guid>    <pubDate>2026-01-20 16:11:11</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>西北工业大学StereoMV2D突破3D物体检测深度难题，精度与效率兼得</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553527" alt=" " title=" "/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553528" alt=" " title=" " loading="lazy"/></p><p>论文标题：StereoMV2D: A Sparse Temporal Stereo-Enhanced Framework for Robust Multi-View 3D Object Detection</p><p>作者团队：<a href="https://link.segmentfault.com/?enc=w7pLZ5Gxf2hQ1ZVoeF3P5Q%3D%3D.plBaYOgRyqkeBRHeNNVmGK2HAYycA9p%2BFHQz4y9G5CNpDqaq8br0qbRj20zYiGC6PiylMDyCnscixgcBFiA7owTFW0XC8KGFWOYogdcg9hGerr8wUVM%2Fh3O8o2%2FQutiy" rel="nofollow" target="_blank">西北工业大学</a>、<a href="https://link.segmentfault.com/?enc=VkssR6brBPepJg6G7JdArQ%3D%3D.GGXk7eBXUeSiriBibPb%2F2rwbNFlEXcKtRpQskI2lyLXhIj81er8JZYDddGxYJ%2FP286tAKuksgislOy29b1pWSKUrMy0Yczf2nNscdku%2FBl0hQrRZlCdGFxrpfa8CTR%2Bg" rel="nofollow" target="_blank">苏州科技大学</a></p><p>发布时间：2025年12月19日</p><p><a href="https://link.segmentfault.com/?enc=ebroNj9ohwBMCcL17wDkxg%3D%3D.N1gWYSMy%2BwPzCStMH7D9srwjO48bJyJ0nfq1kIJAXbkkBaLbks4aQbQbcEWUm7E4" rel="nofollow" target="_blank">论文链接：</a></p><p><a href="https://link.segmentfault.com/?enc=VaLS0gP9RVI7m00MAltB%2Bg%3D%3D.sPlW8i1kkwg7b2oWIIJAu3PAPspMCailBj3abLUJgOj5MlkszfGo69mpgr2%2FRPALsdsT8wT0PaFnnUzRDJEXYF4YJMG%2BtRMTHlyD8k6iFgvK%2BWaYZnnz0o0gsBWjfwOm" rel="nofollow" target="_blank">大模型实验室</a>Lab4AI论文阅读</p><h3>✔️研究背景</h3><p>多视图3D物体检测需在检测精度和计算效率间取得平衡。<a href="https://link.segmentfault.com/?enc=N8bggZOh0A0Bngh7JlBNTg%3D%3D.k15YY4jHHOBRdC70RRSePs%2FPm%2FgsF5NPUVV71DOlPxFmXYbqZetTZ%2BqOaeI3W7%2BfPy3a6cokwLoG8As6y4ERLM%2B%2B%2BYk1tUfD7uDQ%2FiWZltIJbYENphda6iGJT3S4dDOZ" rel="nofollow" target="_blank">稀疏查询</a>基方法（如MV2D）通过2D检测结果初始化3D查询，提供了高效的端到端检测范式，但单帧2D检测存在深度模糊问题，导致3D查询初始化不准确。</p><p>现有融合时序立体建模的方法多依赖密集代价体构建，引入大量计算与内存开销，难以兼容<a href="https://link.segmentfault.com/?enc=LaEl4jiKjV8N5LwTp8tH%2Fg%3D%3D.zkVCmzvcTSknD3u0kc2haNdMfA2Y%2Bn8Et%2BxJCTa5MICKDR5AqqVF%2Bu45fyHZqLXl7WjRhRyK1xBuuBEK1nuin%2FkM8Y3jNwWxXCFLYa9Q6G%2Brf9ZOy%2F8TPacY35Z%2FViJo" rel="nofollow" target="_blank">稀疏查询</a>类方法的高效特性，形成研究缺口。</p><h3>✔️研究内容</h3><p>针对单帧 2D 检测的深度模糊缺陷，以及现有时序立体建模方法计算开销大的问题，本研究旨在提出一种统一框架，将时序立体建模融入<a href="https://link.segmentfault.com/?enc=NONtrEhNkMdRJjpmL4QZFQ%3D%3D.BhwdyJgIgMRYQRiTwEFLGUM7BeBfzSTDXEh8CA9ztPbVVg9ze4cmcDKFICsPn5OpJPWXSh4UTiAvA67bDFG%2BSHaJY2n3RJ%2BJ1OzGDGeaFj6DZlMaQpoHxC%2F0KHtoUZoR" rel="nofollow" target="_blank">稀疏查询</a>检测范式，在保持<a href="https://link.segmentfault.com/?enc=rfjo60zVS%2B7Jpxu6FgTofg%3D%3D.ZItHltHQga0BecyfIbaYmIX8WSyksEvrLL4JAfNvVFaLe0I0LUhoRcYToy9j1%2B5rxK3KNU94gHLOeDIicQEUgX0YVi7XkR63AVZgtrqN%2BUprrntZ66eUgfhtRjAMgmn5" rel="nofollow" target="_blank">稀疏查询</a>类方法高效性的同时，增强深度感知能力，提升多视图 3D 目标检测的精度与鲁棒性，实现精度与效率的良好平衡。</p><h3>✔️核心思想</h3><h4>1️⃣匹配同一物体</h4><p>汽车运动、场景变化时，系统需在前一帧与当前帧图像中匹配同一物体。<br/>论文采用 “运动感知软匹配” 模块，结合物体外观与运动趋势，建立跨帧关联。</p><h4>2️⃣物体区域内算深度</h4><p>匹配到同一物体的跨帧图像后，StereoMV2D 仅在物体对应的感兴趣区域（RoI）内开展精细立体计算，减少计算量；通过对比物体在两帧图像中的细微位移，精准计算其真实距离。</p><h4>3️⃣智能筛选有效信息</h4><p>针对现实场景中物体新出现或被遮挡的动态情况，论文设计动态置信门控机制，自动判定采用立体测量结果，还是回退至单帧图像的推测结果。</p>]]></description></item><item>    <title><![CDATA[UI常备的 7 款 网站设计工具 UXbot ]]></title>    <link>https://segmentfault.com/a/1190000047553538</link>    <guid>https://segmentfault.com/a/1190000047553538</guid>    <pubDate>2026-01-20 16:10:36</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>现在互联网行业竞争这么激烈，网页界面设计得好不好，不光影响用户用着顺不顺手，还直接关系到产品能不能留住人。大厂设计师能做出让人眼前一亮的界面，除了自身本事硬，背后肯定少不了好用的设计工具帮忙。下面就给大家盘点 7 款 UI 设计师平时常用的网页设计软件，不管是新手还是老手，都能找到适合自己的。<br/>一、UXbot：原型、交互、开发一条龙搞定<br/>核心功能：</p><ul><li>多页面自动生成：你只要把想法用文字说清楚，它就能自动画出完整的用户使用流程，还会告诉你背后的设计思路。可以自己选要生成哪些页面，一次性做出整套界面，不用再一点点拼凑，大大节省时间。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdnG0c" alt="image.png" title="image.png"/></li><li>自由编辑超灵活：既能用说话、打字的方式快速操作，也有专业的精细编辑器，能精准调整到每一个像素。不管是改页面布局、换设计风格，还是换图片文字，都能精准满足需求，创意和专业性都不耽误。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdnG0f" alt="image.png" title="image.png" loading="lazy"/></li><li>交互原型一键分享：马上就能生成能实际操作的演示原型，点一点、滑一滑都跟真的产品一样，还能直接分享给别人。不管是给客户演示、团队内部讨论，还是项目推介，都能让大家直观看到效果，更有说服力。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdnG0g" alt="image.png" title="image.png" loading="lazy"/></li><li>自动生成前端代码：界面设计一确定，它就会自动生成能直接用的前端代码，还能适配 vue.js 这种常用框架。设计效果和代码能无缝衔接，甚至能一键传到云服务器上，再也不用纠结设计和开发脱节的问题了。<br/><img width="723" height="395" referrerpolicy="no-referrer" src="/img/bVdnG0h" alt="image.png" title="image.png" loading="lazy"/></li><li>多平台协作方便：能一键导出 HTML 或 Sketch 格式，还能设置不同人的查看、编辑权限，团队随时随地都能协作，设计和开发衔接更顺畅。</li></ul><p>适用场景：<br/>中小型企业、工作室做项目演示，能快速把商业想法变成可展示的原型；企业做数字化项目，跨部门一起做内部工具或客户产品；设计和开发团队合作，减少沟通误会，提高原型评审和代码转化效率；产品更新优化时，快速验证新功能的逻辑和用户体验。</p><p>二、Adobe Illustrator：矢量设计的王牌<br/>核心功能：</p><ul><li>专门做矢量图形，用来设计网页里的图标、装饰图案、品牌插画再合适不过了，不管放大多少倍，画面都清晰锐利，不会出现模糊、边缘变形的情况。</li><li>有钢笔工具、形状生成器这些强大的图形编辑功能，不管是复杂的几何形状，还是自定义的创意图形，都能轻松画出来，满足各种视觉设计需求。</li><li>文字排版能精准调控，字体、字号、行间距、字间距都能细细调整，能做出整齐又好看的界面文字布局，让整个页面的视觉质感更棒。<br/>适用场景：<br/>主要用来设计网页里的矢量元素，比如企业官网的品牌 LOGO、导航栏的功能图标、页面里的装饰插画，还有需要精细排版的标题、说明文字等。<br/><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdnG0j" alt="image.png" title="image.png" loading="lazy"/></li></ul><p>三、Sketch：UI/UX 设计的高效小帮手<br/>核心功能：</p><ul><li>就是为 UI/UX 设计量身做的，界面简单明了，新手也能快速上手，不用花好多时间学操作。</li><li>有智能自适应布局功能，设计能适配不同屏幕的网页时，调整一个元素的大小，和它相关的其他元素会按照预设的规则自动调整，不用手动一个个改位置、调大小，省了好多事。</li><li>支持装各种插件，比如切图、填充数据、生成标注的插件，能大大提高设计效率，和开发团队合作也更顺畅。</li><li>有符号复用功能，把按钮、输入框这些常用元素设为 “符号”，后面只要改一下原始的 “符号”，所有用了这个 “符号” 的地方都会自动更新，能保证整个设计的一致性。<br/>适用场景：<br/>特别适合互联网创业公司快速做产品原型，比如开发新的网页应用时，设计师能用它高效完成界面设计和原型制作，快速验证产品思路，缩短项目周期。<br/><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdnG0k" alt="image.png" title="image.png" loading="lazy"/></li></ul><p>四、Adobe Photoshop：界面视觉精修神器<br/>核心功能：</p><ul><li>经典的图像处理软件，功能特别全，调颜色、抠图、合成图片、修细节都能搞定，能给网页界面打造出精致的视觉效果。</li><li>用图层来管理内容，导航栏、正文、背景图这些元素可以分别放在不同的图层上，能灵活控制每个图层的显示、隐藏和透明度，改一个元素的时候不会影响到其他内容。</li><li>有各种滤镜和特效工具，能快速做出模糊、阴影、发光这些效果，让界面更有层次感和立体感，看起来更吸引人。<br/>适用场景：<br/>适合对视觉效果要求高、需要大量处理图片的网页项目。比如电商平台的首页设计，商品图片精修、促销海报制作、页面氛围渲染这些工作，用它都能高效完成。<br/><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdnG0l" alt="image.png" title="image.png" loading="lazy"/></li></ul><p>五、Axure RP：专业的交互原型工具<br/>核心功能：</p><ul><li>是专门做原型设计的工具，不光能做出高还原度的界面，还能做可交互的产品原型。可以给元素加点击跳转、滑动切换这些交互效果，甚至能设置条件逻辑，完整模拟用户实际使用的流程。</li><li>有丰富的元件库，还能自己做自定义元件，轻松做出表单、弹窗、导航菜单这些常见的界面组件，还能给元件改样式，贴合项目的整体设计风格。</li><li>支持多人一起编辑，团队成员能共同管理原型项目，生成的 HTML 格式原型文件，开发、测试的同事不用装专门的软件，直接就能查看和体验。<br/>适用场景：<br/>在网页产品的前期规划和交互设计阶段特别有用。比如开发新的网页应用，或者给现有网站改版时，设计师和产品经理能用它快速搭建原型，做用户测试和方案验证，确保产品的交互逻辑符合用户需求。<br/><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdnG0z" alt="image.png" title="image.png" loading="lazy"/></li></ul><p>六、Adobe XD：设计到原型无缝衔接<br/>核心功能：</p><ul><li>把设计、原型制作、动效设计三个功能整合到一起，设计师不用在好几个软件之间来回切换，在一个界面里就能完成从静态设计图到动态原型的全部工作。</li><li>支持响应式设计布局，设置好断点和约束条件，就能快速适配电脑、平板、手机等不同屏幕尺寸，让设计更灵活、适用范围更广。</li><li>有重复网格功能，设计新闻列表、产品列表这种界面时，只要做好一个列表项，一键就能生成多个相同样式的元素，不用重复设计，省了好多时间。<br/>适用场景：<br/>适合 UI/UX 设计师做网页界面设计和原型制作，尤其是需要给客户展示设计效果、给团队评审交互流程的时候。比如做方案汇报，用它生成的可交互原型，能让大家更直观地感受到产品的功能和操作体验。<br/><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdnG0E" alt="image.png" title="image.png" loading="lazy"/></li></ul><p>七、InVision：原型测试和团队反馈的高效平台<br/>核心功能：</p><ul><li>专注于原型设计和团队协作，能导入 Sketch、Adobe XD 等多种格式的设计文件，方便整合不同来源的设计资源。</li><li>有丰富的交互动画模板，设计师能轻松给原型加页面切换、元素弹出、下拉刷新这些动画效果，让原型更真实、更有吸引力。</li><li>评论批注功能很方便，团队成员和客户能直接在原型上标注意见和建议，设计师能快速找到需要修改的地方，不用反复沟通确认，能加快项目推进速度。<br/>适用场景：<br/>在网页项目的后期测试和反馈阶段优势特别明显。比如完成界面设计和原型制作后，用这款工具能快速和开发团队、测试团队、客户对接，收集大家的意见，及时优化设计方案，确保最终的产品符合预期。<br/><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdnG0G" alt="image.png" title="image.png" loading="lazy"/></li></ul><p>总结<br/>总的来说，这 7 款网页设计软件各有各的优势，UI 设计师可以根据项目的具体需求、团队的协作方式来灵活选择。对于做网页设计的从业者和爱好者来说，摸清这些工具的特点和适用场景，熟练用它们辅助设计，既能提高工作效率，也能让自己的作品更有竞争力，做出更优质的网页界面。</p>]]></description></item><item>    <title><![CDATA[如何使用Python Mammoth将DOCX转换为HTML？ 码云笔记 ]]></title>    <link>https://segmentfault.com/a/1190000047553590</link>    <guid>https://segmentfault.com/a/1190000047553590</guid>    <pubDate>2026-01-20 16:09:54</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>我们在实际的项目开发的过程中，有时候不得不将文件从一种格式转换为另一种格式。</p><p>DOCX（由 Microsoft Word 使用）是一种非常常见的文件格式，被很多人使用。有时候，我们希望将 Word 文档转换为 HTML。</p><p>这可以通过 Mammoth 包轻松实现。它是一个用于将 DOCX 文件转换为 HTML 的简单、高效、快速的库。在本文中，我们将学习如何在 Python 中使用 Mammoth 将 DOCX 转换为 HTML。</p><h2>安装 Mammoth</h2><p>首先，在安装之前准备好并激活你的虚拟环境：</p><pre><code>python3 -m venv myenv
. myenv/bin/activate</code></pre><p>然后，使用pip安装 Mammoth：<br/><code>pip3 install mammoth</code><br/>本教程使用的 Mammoth 版本是 1.4.15。在测试的时候，请确保它是.docx 文件！</p><p>以上环境准备好后，现在让我们开始提取文本并将其转换成 HTML。</p><h2>提取 DOCX 文件的原始文本</h2><p>在转换为 HTML 时保留格式是 Mammoth 的最佳功能之一。这里我们只需要几行代码转换成你需要 DOCX 文件的文本。</p><p>使用 extract_raw_text()方法来获取它：</p><pre><code>import mammoth

with open(input_filename, "rb") as docx_file:
    result = mammoth.extract_raw_text(docx_file)
    text = result.value # The raw text
    with open('output.txt', 'w') as text_file:
        text_file.write(text)</code></pre><p>注意，此方法不会返回有效的 HTML 文档。它只返回页面上的文本，因此我们使用.txt 扩展来保存它。如果你确实需要保持布局或格式，你需要提取 HTML 内容。</p><h2>将 Docx 转换为 HTML 并自定义样式映射</h2><p>默认情况下，Mammoth 将文档转换为 HTML，但它不会提供有效的 HTML 页面。虽然网页浏览器可以显示内容，但它缺少一个&lt;html&gt;标签来封装文档，以及一个&lt;body&gt;标签来包含文档。</p><p>假设使用的是带有模板的网络框架。可能会定义一个模板来显示 Word 文档，并将 Mammoth 的输出加载到模板主体内。</p><p>Mammoth 不仅在如何使用其输出方面具有灵活性，而且在如何创建输出方面也具有很大的灵活性。特别是在我们想要样式化我们生成的 HTML 时，我们有很多选项。我们通过将每个 DOCX 格式规则匹配到相应的 CSS 规则来映射样式。</p><p>要查看你的 DOCX 文件有哪些样式，你有两个选择：</p><ol><li>使用 MS Word 打开您的 docx 文件，并检查样式工具栏。</li><li>通过用解压管理器打开你的 DOCX 文件来研究 XML 文件，然后导航到/word/styles.xml并找到你的样式。</li></ol><p>第二个选项适用于无法使用 MS Word 或无法解释和显示样式的替代文字处理程序的用户。</p><p>Mammoth 已经默认涵盖了某些最常用的样式映射。例如，Heading1在 docx 样式中映射到 HTML 元素的&lt;h1&gt;，bold被映射到 HTML 元素的 strong，等等。</p><p>我们还可以在映射时使用 Mammoth 来自定义文档的样式。例如，如果您想将 DOCX 文件中的所有bold出现次数更改为 HTML 中的斜体，可以这样子实现：</p><pre><code>import mammoth

custom_styles = "b =&gt; i"

with open(input_filename, "rb") as docx_file:
    result = mammoth.convert_to_html(docx_file, style_map = custom_styles)
    text = result.value
    with open('output.html', 'w') as html_file:
        html_file.write(text)</code></pre><p>通过 custom_styles 变量，左边的样式来自 DOCX 文件，而右边的是相应的 CSS。<br/><code>custom_styles = "b =&gt; "</code><br/>有时我们转换的文档会有很多样式需要保留。这个时候再这样实现就会变得不切实际，要为每一个我们要映射的样式都创建一个变量。</p><p>不过有解法，我们可以使用docstrings一次映射我们想要的任意多个样式：</p><pre><code>custom_styles = """ b =&gt; del
                    u =&gt; em
                    p[style-name='Heading 1'] =&gt; i"""</code></pre><p>你可能已经注意到，最后的映射与其他的有点不同。在映射样式时，我们可以使用方括号[]并在其中添加条件，这样只有部分元素会以这种方式进行样式设置。</p><p>在我们的示例中，p[style-name='Heading 1']选择具有样式名称的段落Heading 1。我们也可以使用p[style-name^='Heading']来选择具有以Heading开头的样式名称的每个段落。</p><p>样式映射还允许我们将样式映射到自定义 CSS 类。通过这样做，我们可以随心所欲地修改 HTML 的样式。让我们举一个例子，我们在文档字符串中定义基本的自定义 CSS：</p><pre><code>custom_css ="""
    &lt;style&gt;
    .red{
        color: red;
    }
    .underline{
        text-decoration: underline;
    }
    .ul.li{
        list-style-type: circle;
    }
    table, th, td {
    border: 1px solid black;
    }
    &lt;/style&gt;
    """</code></pre><p>现在我们可以更新我们的映射，以引用我们在&lt;style&gt;块中定义的 CSS 类：</p><pre><code>custom_styles = """ b =&gt; b.red
                    u =&gt; em.red
                    p[style-name='Heading 1'] =&gt; h1.red.underline"""</code></pre><p>并将 CSS 和 HTML 合并在一起：<br/><code>edited_html = custom_css + html</code><br/>这个时候如果 DOCX 文件包含任何这些元素，就能看到我们设置的样式结果。</p><p>通过以上方法我们已经知道如何映射样式，那就让我们使用一个更著名的 CSS 框架（以及相关的 JS）来让我们的 HTML 看起来更好，并练习一个更有可能的现实场景。</p><p>使用 Bootstrap（或其他任何前端框架）映射样式<br/>就像我们之前处理custom_css一样，我们需要确保 CSS 与 HTML 一起加载。我们需要将 Bootstrap 文件 URI 或 CDN 添加到我们的 HTML 中：</p><pre><code>bootstrap_css = '&lt;link rel="nofollow" href="https://mybj123.com/links?url=aHR0cHM6Ly9jZG4uanNkZWxpdnIubmV0L25wbS9ib290c3RyYXBANS4wLjAtYmV0YTIvZGlzdC9jc3MvYm9vdHN0cmFwLm1pbi5jc3M=" rel="stylesheet" integrity="sha384-BmbxuPwQa2lc/FVzBcNJ7UAyJxM6wuqIj61tLrc4wSX0szH/Ev+nYRRuWlolflfl" crossorigin="anonymous"&gt;'
bootstrap_js = '&lt;script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta2/dist/js/bootstrap.bundle.min.js" integrity="sha384-b5kHyXgcpbZJO/tY9Ul7kGkf1S0CWuKcCD38l8YkeH8z8QjE0GmW1gYU5S9FOnJ0" crossorigin="anonymous"&gt;&lt;/script&gt;'</code></pre><p>这里我稍微调整我们的 custom_styles，以匹配我们的新 CSS 类：</p><pre><code>custom_styles = """ b =&gt; b.mark
                    u =&gt; u.initialism
                    p[style-name='Heading 1'] =&gt; h1.card
                    table =&gt; table.table.table-hover
                    """</code></pre><p>在第一行，我们将粗体 DOCX 样式映射到具有类的 HTML 元素，该类是 HTML 标签的 Bootstrap 类，用于突出显示文本的一部分。bmark &lt;mark&gt;</p><p>在第二行，我们为 HTML 元素添加了类，稍微减小了字体大小，并将文本转换为大写。initialism u</p><p>在第三行，我们选择所有具有样式名称的段落，并将其转换为具有 Bootstrap 类的 HTML 元素，该类为元素设置多个样式属性，例如背景颜色、位置和边框。Heading 1 h1 card</p><p>在最后一行，我们将 docx 文件中的所有表格转换为 HTML 元素，并使用 Bootstrap 的类来给它一个新的外观，同时我们通过添加 Bootstrap 类使其在悬停时高亮显示。table table table-hover</p><p>和之前一样，我们使用点符号将多个类映射到同一个 HTML 元素，即使这些样式来自另一个来源。</p><p>最后，将 Bootstrap CDNs 添加到我们的 HTML 中：</p><pre><code>edited_html = bootstrap_css + html + bootstrap_js</code></pre><p>现在可以分享我们的 HTML，以下是完整的代码以供参考：</p><pre><code>import mammoth

input_filename = "file-sample_100kB.docx"

custom_styles = """ b =&gt; b.mark
                    u =&gt; u.initialism
                    p[style-name='Heading 1'] =&gt; h1.card
                    table =&gt; table.table.table-hover
                    """


bootstrap_css = '&lt;link rel="nofollow" href="https://mybj123.com/links?url=aHR0cHM6Ly9jZG4uanNkZWxpdnIubmV0L25wbS9ib290c3RyYXBANS4wLjAtYmV0YTIvZGlzdC9jc3MvYm9vdHN0cmFwLm1pbi5jc3M=" rel="stylesheet" integrity="sha384-BmbxuPwQa2lc/FVzBcNJ7UAyJxM6wuqIj61tLrc4wSX0szH/Ev+nYRRuWlolflfl" crossorigin="anonymous"&gt;'
bootstrap_js = '&lt;script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta2/dist/js/bootstrap.bundle.min.js" integrity="sha384-b5kHyXgcpbZJO/tY9Ul7kGkf1S0CWuKcCD38l8YkeH8z8QjE0GmW1gYU5S9FOnJ0" crossorigin="anonymous"&gt;&lt;/script&gt;'


with open(input_filename, "rb") as docx_file:
    result = mammoth.convert_to_html(docx_file, style_map = custom_styles)
    html = result.value 

edited_html = bootstrap_css + html + bootstrap_js

output_filename = "output.html"
with open(output_filename, "w") as f: 
    f.writelines(edited_html)</code></pre><p>此外，需要注意的一点是，在实际情况下，你可能不会像我们在这里所做的那样直接将 Bootstrap CSS 添加到 HTML 内容中。相反，你会将 HTML 内容加载或注入到一个特殊的 HTML 页面中，该页面已经包含了必要的 CSS 和 JS 捆绑包。</p><p>Mammoth 还允许我们修改我们正在转换的内容。</p><h2>处理我们不想分享的图片</h2><p>假设我们希望跳过 DOCX 文件中的图像不进行转换。convert_to_html()方法接受一个convert_image参数，这是一个图像处理函数。它返回一个应该转换并添加到 HTML 文档中的图像列表。</p><p>当然，如果我们覆盖它并返回一个空列表，它们将从转换后的页面中省略：<br/>`def ignore_image(image):</p><pre><code>return []`</code></pre><p>现在，让我们将该函数作为参数传递到convert_to_html()方法中：</p><pre><code>with open(input_filename, "rb") as docx_file:
    result = mammoth.convert_to_html(docx_file, style_map = custom_styles, convert_image=ignore_image)
    html = result.value
    with open('output.html', 'w') as html_file:
        html_file.write(text)</code></pre><p>就是这样！ Mammoth 在生成 HTML 文件时将忽略所有图像。</p><p>到目前为止，我们一直在用 Python 编程方式使用 Mammoth。Mammoth 也是一个命令行工具，因此我们有了另一个将 DOCX 转换为 HTML 的接口。让我们在下一节中看看它的工作情况。</p><h2>使用命令行工具将 DOCX 转换为 HTML</h2><p>使用 Mammoth 的 CLI 进行文件转换通常如下所示：</p><pre><code>mammoth path/to/input_filename.docx path/to/output.html</code></pre><p>如果你想将图像从 HTML 中分离出来，可以指定一个输出文件夹：</p><pre><code>mammoth file-sample_100kB.docx --output-dir=imgs</code></pre><p>我们也可以像在 Python 中那样添加自定义样式。首先需要创建一个自定义样式文件：<br/><code>touch my-custom-styles</code><br/>然后，我们将在其中添加自定义样式，语法与之前相同：</p><pre><code>b =&gt; b.red
u =&gt; em.red
p[style-name='Heading 1'] =&gt; h1.red.underline</code></pre><p>现在我们可以生成带有自定义样式的 HTML 文件：</p><pre><code>mammoth file-sample_100kB.docx output.html --style-map=my-custom-styles</code></pre><p>大功告成！您的文档已按定义的自定义样式进行转换。<a href="https://link.segmentfault.com/?enc=SifZbz41h91G5MJK2P49Pw%3D%3D.XK%2ByukhAJMQiJD2%2BJH6rryOWMstDqWT2hhbmo2oy3dA%3D" rel="nofollow" target="_blank">https://mybj123.com/28792.html</a></p><h2>结语</h2><p>文件类型转换在处理网页技术时是一种常见需求。将 DOCX 文件转换为易于操作的 HTML 格式，使我们能够根据需要重建数据。使用 Mammoth，我们学会了如何从 docx 中提取文本并将其转换为 HTML。</p><p>在转换为 HTML 时，我们可以使用我们创建的 CSS 规则或常见的 UI 框架提供的规则来样式化输出。我们还可以省略不需要在 HTML 中可用的数据。</p>]]></description></item><item>    <title><![CDATA[“最强大脑”下沉工地：红圈AI Agent在施工现场的N个应用瞬间 看点 ]]></title>    <link>https://segmentfault.com/a/1190000047553593</link>    <guid>https://segmentfault.com/a/1190000047553593</guid>    <pubDate>2026-01-20 16:09:06</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>吊塔旋转,机器轰鸣,尘土飞扬——这是你印象中的工地。</p><p>但如果你看得再仔细一点,会发现一些“不同寻常”的事情正在发生:</p><p>项目经理不再对着电话咆哮要数据,而是平静地对手机说句话,所有经营数字瞬间清晰呈现;</p><p>采购员不再为核查供应商背景熬夜翻网站,系统3秒自动生成一份风险“体检报告”;</p><p>材料员面前那堆如山的手写票据,正被手机摄像头快速“吞食”,自动变成系统里的规整记录……</p><p>这不是科幻电影。这是一场正在全国无数工程项目部真实上演的“静默革命”。</p><p>而掀起这场革命的,是一群特殊的“新员工”——它们不吃不喝不领工资,却24小时在岗;它们没有实体,却无所不在。它们就是红圈AI系列智能产品中的AI Agent,一群更懂工程企业经营的“数字大脑”。</p><p>今天,让我们走进施工现场,看看这群“智能同事”如何在最粗犷的行业里,干着最精细的活儿。</p><p>告别“表哥表姐”:一个能听懂人话的BOSS助理</p><p>“昨天华东区的产值是多少?”“钢筋价格波动对我们在建项目影响多大?”“帮我比一下王队和李队这个月的施工效率。”……曾几何时,项目经理的每一个问题,都可能让下属团队手忙脚乱,上演一场跨部门的数据“搬运”与“组装”大战。电话、微信、表格、报告,在碎片化的信息流中,决策的速度与准确性被大幅损耗。</p><p>红圈AI的BOSS助理Agent,终结了这种低效循环。它被设计成“更懂管理者的‘数据员’”。其核心能力在于“智能理解”与“精准呈现”。管理者可以用最自然的语言下达指令,这位助理能借助AI大模型的推理能力,精准挖掘企业自有数据模型,智能生成全面、准确的经营数据汇报。它能迅速抓取全域业务数据,精准呈现多维报表及数据卡片。</p><p>它带来的改变是颠覆性的。首先,是决策的即时性。任何时间管理者下达的指令,都能智能理解随时快速汇报,有问必答。其次,是洞察的深度。它能告别需多人汇报的繁琐与校验,直接提供分析结果。最后,也是工程企业最为看重的数据安全。它依托红圈系统权限和数据建模能力,确保核心数据不被大模型采集与留存。</p><p>从此,在飞驰的车上、在喧闹的工地旁、在深夜的办公室,管理者与关键经营数据之间,只剩下一个简单提问的距离。数据不再是需要费力挖掘的矿石,而是随时可供引用的清泉。</p><p>风险“扫描仪”:在供应商进门之前,先看透它的底牌</p><p>工程行业有句老话:“利润是干出来的,也是省出来的,但更是‘防’出来的。”一个劣质供应商带来的合同纠纷、材料延误、质量隐患,足以吞噬一个项目的全部利润。传统的供应商评估,严重依赖个人经验、有限的工商查询和耗时耗力的背景调查,如同雾里看花,风险防不胜防。</p><p>红圈AI的采购助理Agent,就像一台高精度的风险“扫描仪”。它整合多维度供应商企业数据并通过AI算法智能动态评分,减少人工主观误差。它的工作流程快如闪电:3秒完成信用数据抓取,40秒AI完成各风险排查及评估,10秒生成完整报告。</p><p>这份报告的价值,在于其令人信服的“硬核”细节。报告会进行多维评估,基于六大维度数据采集,逐项风险排查分析。例如,面对一家高风险供应商,报告会列出“异常情况总览”,包括企业存在破产案件记录、被列为限制高消费企业(存在多条限制消费令)、存在终本案件、因未按规定提交年度报告被列入经营异常名录等。</p><p>更令人惊叹的是它对法律风险的深度剖析。报告中会详细拆解法律诉讼情况:包括总诉讼案件、涉诉金额、作为被告/原告的次数及金额。它会分析主要案件类型(如买卖合同纠纷),并指出企业作为被告的纠纷金额较大,显示在大量交易中存在违约风险;同时企业作为原告也发起多起诉讼,反映其业务合作中可能存在较多争议。最终给出穿透性判断:民事纠纷频发且存在不利判决,表明企业在合同管理和履约合规性方面存在明显短板。</p><p>这套系统不仅是“守门员”,更是“监护仪”。它能对已合作的供应商进行定期智能排查,自动刷新风险等级及各项评分,并通过风险变化通知进行提示。企业可以设置限制合作标准,快速终止合作并系统溯源追查从此,采购部门的工作,从“救火”变成了主动“防火”。</p><p>“秒懂”一切单据:让最繁琐的录入工作,变得“毫无存在感”</p><p>如果说数据决策和风险防控是“高大上”的脑力活,那么单据录入就是工地里最接地气、也最让人头疼的“体力活”。混凝土小票、机打送货单、手写签收单、甚至偶现的外文单据……它们格式不一、字迹潦草、数量庞大,却是成本归集的第一道生命线。传统的人工录入,是重复、枯燥且错误率高发的代名词。</p><p>红圈AI录单助手Agent pro,正是为了消灭这种“毫无创造力的痛苦”而生。它通过大模型自动识别各类单据,实现从图像识别到高质量系统录入的秒级闭环。它能智能提取关键字段、智能匹配相关数据并回填业务系统。</p><p>它的智能远不止于“识别”,更在于“理解”与“关联”。智能分析入库材料匹配的合同明细并挂接,从而厘清成本发生源头。效率的提升是数量级的:处理5张单据约50条明细,人工录入需20-30分钟,而AI录入仅需3-5分钟,减少90%人工操作。</p><p>为了实现极高的匹配准确率,它融合了多种智能策略。“精准匹配” 根据入库单的物资名称、规格型号等字段精准匹配合同明细。据同一个项目历史匹配的数据,自动做对应数据匹配。当遇到模糊或复杂情况时,“智能判断” 功能启动,借助大模型语意识别及通识能力,智能判别入库明细与合同明细的相似性并完成匹配。这种能力,让低成本完成实际成本归集统计,实现后期精准统计及溯源成为可能。材料员和成本会计,终于可以从无尽的表格中直起身来,将智慧用于更重要的管理工作。</p><p>不止于此:一张看不见的智能矩阵</p><p>红圈AI在工地的应用瞬间,远不止于上述几个高光场景。它更像一个多维度的“智能矩阵”,将AI能力编织成一张覆盖工程经营全链条的隐形守护网。这个由多个AI助手构成的智能体军团,正在将“更懂工程企业经营”的承诺,落地为一个个具体而微的智能解决方案。</p><p>想象一下,在每周至关重要的项目经营例会前,项目经理不再需要带领团队熬夜准备庞杂的数据报告。他只需轻点“项目360°AI解读”功能,这个“项目经营的‘智能指挥官’”便能整合资金、成本、合同、付款等全维度经营指标,一键生成项目的全景作战图。大模型会对经营数据进行深度解读,不仅指出“项目经营毛利率为-0.63%,存在严重风险”,更能精准揭示“垫资施工存在资金风险”、“项目回款困难”、“实物工期超出合同工期”等核心问题。它甚至能调用行业专家经验,对项目进行智能评级和趋势预测,并直接给出“规范管理成本、制定详细应对计划”等结构化建议。这使得会前准备时间从以天计缩短到以分计,会议效率得以十倍提升,将管理者从数据整理的苦海中解放,真正聚焦于决策本身。</p><p>而在财务与采购部门,AI则以另一种形式发挥着“智能分析官”的作用。面对繁杂的《供应商应付管理表》,AI报表助手能够秒级解析业务数据,自动定位异常。它能快速识别供应商付款链条中的差异与风险,并基于历史合作履约情况、账期账龄等多维度数据,对所有供应商进行应付优先级排序,智能建议优先支付对象,识别付款底线,从而辅助财务进行科学的付款统筹。这改变了以往风险识别被动滞后、分析与资金情况脱节的局面,让付款决策从“凭感觉”走向“凭数据”。</p><p>当一位新员工加入公司,面对浩如烟海的制度、工艺和历史项目资料时,AI企业知识库便成为他最强的“知识中枢”。员工可以用最自然的语言提问,例如“马上要投XX智慧校园项目,找3个同类中标方案”,红圈AI能在3秒内从向量数据库中锁定历史标书、技术方案和报价分析报告,并生成对比摘要。对于法务人员,AI能快速从诉讼智库中检索相似判例,提炼风险规律与应诉策略;对于运维人员,它能即刻调取故障排除指南和历史维修方案,实现快速诊断。无论是查询差旅标准、年假天数,还是了解固定资产申请流程,AI都能做到有问必答、全年无休,将分散的企业知识转化为即问即答的能力,让核心经验传承效率提升3倍。</p><p>最后,在业务风险防控的最前线,“AI业务助手”扮演着“智能决策引擎”的关键角色。在合同审查环节,它能自动识别合同主体合法性、项目范围明确性、金额付款条款、违约责任对等性等维度的风险,将审核效率提升20倍,帮助规避80%的基础风险。面对潜在的合作方,它能自动汇总分散在工商、司法、舆情等多源信息,生成结构化的风险报告,让关键信息与风险一目了然,彻底改变了过去信息分散、耗时易错、评估片面的困境。</p><p>从项目全局指挥到单据扫描录入,从风险智能预警到知识即时获取,红圈AI系列智能产品已然构成一个协同工作的有机生态。它们并非彼此孤立的功能点,而是一个贯穿项目全生命周期、渗透业务各毛细血管的“智能矩阵”。这张网,让数据得以流动,让经验得以传承,让风险无处遁形,最终让每一个工程企业都能拥有一个全天候在线的“最强大脑”,稳健地驶向经营的下一个时代</p><p>当AI的“最强大脑”真正下沉,与工地的钢筋水泥、机械轰鸣融合,改变的远非几个岗位的效率。它正在重塑一种工作方式:让决策基于全域实时数据而非经验猜测,让风险防控于未然而非事后补救,让繁琐重复的劳动被智能释放,让管理者的视野穿透层层报表直达业务本质。红圈AI ,这些施工现场的新“工友”,正以其无声却强大的力量,推动着中国工程建造走向一个更加智能、精准与安全的未来。这,才是技术革命在产业深处,最动人、也最坚实的模样。</p>]]></description></item><item>    <title><![CDATA[SpreadJS V19.0 新特性解密：透视表拖动自定义排序，解锁数据整理新姿势 葡萄城技术团队 ]]></title>    <link>https://segmentfault.com/a/1190000047553598</link>    <guid>https://segmentfault.com/a/1190000047553598</guid>    <pubDate>2026-01-20 16:08:07</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在数据分析与报表制作场景中，透视表凭借强大的维度聚合能力成为开发者的核心工具。但传统透视表的排序功能往往受限于固定规则，当用户需要根据业务逻辑自定义调整字段项顺序时，操作繁琐、灵活性不足的问题尤为突出——比如想按业务优先级调整产品类别顺序，或按部门协作逻辑重组数据维度，都需要额外编写复杂代码或手动修改数据源，严重影响工作效率。</p><p>为解决这一痛点，SpreadJS V19.0 重磅推出透视表拖动（自定义）排序功能，让用户无需复杂配置，通过直观的拖拽操作即可实现字段项顺序的自由调整，彻底重构透视表数据整理的便捷性。下面，我们将深入解析这一特性的核心价值与使用细节。</p><h2>核心功能解析：灵活拖拽，精准控序</h2><p>SpreadJS V19.0 的透视表拖动排序功能，以“直观操作+全面兼容”为设计核心，覆盖多种使用场景，满足不同用户的排序需求：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047553600" alt="在这里插入图片描述" title="在这里插入图片描述"/></p><h3>1. 多维度拖拽选择，适配多样操作习惯</h3><p>功能支持四种灵活的拖拽选择方式，无论用户习惯精准选择还是批量操作，都能快速上手：</p><ul><li>仅选择字段头（PivotField Header）：精准调整单个字段的整体顺序，不影响字段下的值区域；</li><li>选择字段头及部分值区域：针对字段下的特定数据项进行排序调整，保留其他项的原有位置；</li><li>选择字段头及全部值区域：批量移动整个字段及下属所有数据项，实现维度整体迁移；</li><li>点击字段头选择全部值区域：一键选中字段关联的所有数据，简化批量拖拽操作。</li></ul><h3>2. 可视化拖拽流程，操作直观无门槛</h3><p>拖拽过程全程伴随清晰的视觉指引，降低操作学习成本：</p><ol><li>鼠标移动到选中区域边缘时，光标自动切换为“移动状态”，明确提示当前区域可拖拽；</li><li>按下鼠标开始拖拽后，系统会显示动态拖拽指示器，实时标注目标插入位置，避免误操作；</li><li>拖拽过程中，指示器会根据鼠标坐标智能判断：列字段按水平（x坐标）定位插入点，行字段按垂直（y坐标）定位，精准匹配透视表结构；</li><li>若拖拽的是父字段，指示器会自动跳过所有子字段的数据区域，确保层级结构不混乱；</li><li>释放鼠标后，选中的字段项会自动插入到指示器标注的位置，排序结果即时生效。</li></ol><h3>3. 排序选项智能联动，状态同步不脱节</h3><p>拖拽排序后，字段项的排序状态会自动同步到透视表的排序选项对话框：当用户打开排序设置时，排序方式会默认切换为“手动（manual）”，清晰标识当前为自定义拖拽排序结果，避免与系统自动排序规则冲突，也方便用户后续按需切换排序方式。</p><h2>典型应用场景：让数据整理更贴合业务逻辑</h2><p>这一特性的推出，让透视表排序彻底摆脱固定规则的束缚，在多个核心场景中发挥价值：</p><ul><li>业务优先级排序：在销售报表中，将重点推广的产品类别拖拽到靠前位置，直观突出核心数据；</li><li>协作场景适配：跨部门协作分析时，按协作流程拖拽调整部门、项目等维度顺序，让报表更符合团队工作逻辑；</li><li>个性化报表展示：根据汇报对象需求，自定义调整透视表字段顺序，让数据呈现更具针对性；</li><li>临时数据重组：数据分析过程中，快速拖拽字段项进行多维度组合尝试，无需修改数据源即可探索不同数据视角。</li></ul><h2>操作指南：3步完成自定义拖拽排序</h2><ol><li>选中目标：在透视表中选择需要排序的字段项（支持前文提到的四种选择方式）；</li><li>开始拖拽：鼠标移动到选中区域边缘，待光标变为移动状态后，按下鼠标并拖动；</li><li>确认插入：拖动过程中观察拖拽指示器，到达目标位置后释放鼠标，字段项自动完成排序调整。</li></ol><h2>注意事项：这些边界场景需留意</h2><p>为确保功能使用顺畅，以下两类操作暂不支持，开发者需提前知晓：</p><ol><li>不支持选中整行或整列进行字段项拖拽：仅能通过选中“字段头”或“字段头+值区域”的方式进行拖拽，全选行/列无法触发字段项排序；</li><li>不支持同时选择不同父字段下的同名子字段进行拖拽：SpreadJS 仅支持单个子字段的独立拖拽，避免多父字段下的子字段混淆。</li></ol><h2>总结与展望：让透视表更懂业务需求</h2><p>SpreadJS V19.0 推出的透视表拖动自定义排序功能，以“直观操作、灵活适配、精准控制”为核心优势，彻底解决了传统透视表排序灵活性不足的痛点，让数据整理更贴合业务逻辑，大幅提升报表制作与数据分析效率。</p><p>作为一款面向企业级应用的纯前端表格控件，SpreadJS 始终聚焦开发者与终端用户的实际需求，持续优化透视表等核心功能的使用体验。除了拖动排序，V19.0 还为透视表带来了日期分组、受保护工作表中启用透视表等多项增强能力，全方位提升数据处理能力。</p><p>如需了解更多功能细节，可访问 <a href="https://link.segmentfault.com/?enc=4zcI7teUY1ZZy5iu1enSZQ%3D%3D.hKrt7wbkDf0%2F0w73RdOxJa2nAKmti33C%2FLMBD4RYiHUSVPrEPg7UbqV39hmzLIIkHXgHFAn%2FOOWEcaELRMW2EQ%3D%3D" rel="nofollow" target="_blank">SpreadJS 官网</a> 查看产品文档，或通过 <a href="https://link.segmentfault.com/?enc=BT97GC5IcRLy9OLnKSkJlg%3D%3D.P4gxn5XkjBbhgLtOirf0fEc%2F%2FI87%2ByPZF%2Fn%2B4SuufKiPI%2F%2B38YrvEMZ6w7l%2FwpTGWGIP46h33BPG6cQNVk37uA%3D%3D" rel="nofollow" target="_blank">在线 Demo</a> 直接体验新特性。SpreadJS V19.0 即将正式发布，敬请期待这款更强大、更灵活的前端表格控件，为你的业务系统注入新的活力！</p>]]></description></item><item>    <title><![CDATA[未来工厂的建造者：国内顶尖整车制造数字化服务商深度盘点 雨大王 ]]></title>    <link>https://segmentfault.com/a/1190000047553604</link>    <guid>https://segmentfault.com/a/1190000047553604</guid>    <pubDate>2026-01-20 16:07:10</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在全球汽车产业加速迈向电动化、智能化的背景下，数字化制造已成为车企提升竞争力的核心手段。传统汽车制造依赖固化的流水线和经验驱动决策，难以满足市场对个性化定制、快速迭代与质量精益化的需求。而数字化制造通过集成物联网、人工智能与数字孪生等技术，正推动工厂向“柔性、透明、智能”方向演进。这一趋势下，选择一家能够真正解决制造痛点的数字化服务商，成为车企战略布局中不可忽视的一环。<br/>一、为什么数字化制造是整车领域的必选项？<br/>汽车制造业的复杂程度远超其他行业。从冲压、焊接、涂装到总装，四大工艺环环相扣，精度要求极高。在传统模式下，生产线灵活性不足，订单响应慢，质量问题往往在最终环节才暴露，导致高额返工成本。例如，某传统车企的总装车间里，每台车的组装需要300名工人流水作业，焊接、拧螺丝、质检等环节高度依赖人工经验，不仅效率低下，更难保证品质一致性。<br/>相比之下，数字化制造通过设备互联、数据互通与业务协同，显著提升了生产效率和质量管控能力。以实时数据采集为例，系统能够动态优化排产计划，应对混合车型共线生产的需求；借助AI视觉检测技术，车身焊点质量可实现100%在线评判，大幅降低漏检率；利用数字孪生技术，新车导入前即可在虚拟环境中验证工艺可行性，缩短量产爬坡周期。这些技术的集成应用，不仅解决了传统制造的痛点，更让工厂具备了快速响应市场变化的能力。<br/>二、数字化服务商的关键能力是什么？<br/>整车数字化制造涉及多技术融合与深层次行业知识，因此服务商的选择至关重要。一家优秀的数字化服务商，不仅需要提供技术平台，更需将技术落地为业务价值。这要求他们具备以下核心素质：<br/>首先，服务商必须深度理解整车制造工艺，熟悉冲压回弹控制、焊接参数优化、涂装膜厚管理等具体场景。其次，技术整合与定制化能力不可或缺。由于车企设备品牌繁多、系统异构性强，服务商需具备软硬一体集成能力，实现从边缘设备到云平台的数据贯通。比第三，全局优化与生态协同能力是数字化制造的精髓。数字化转型不是单点工具替换，而是供应链、生产与售后全链路协同。最后，服务商需具备国际化服务与本土适配能力。随着中国车企出海，海外工厂的落地需要解决当地人才与标准差异问题。<br/>三、案例：国内顶尖服务商的实践与成果<br/>广域铭岛：从汽车集团走出的数字化专家<br/>作为吉利体系孵化的工业互联网平台企业，广域铭岛基于Geega（际嘉）OS构建了整车数字化制造解决方案。在极氪智慧工厂，其通过工艺质量一体化系统，实现白车身尺寸精度控制在±0.5mm以内，订单交付周期缩短20%。同时，其智能能源管理系统帮助工厂年减排二氧化碳超过万吨，成为绿色制造的行业标杆。<br/>长安汽车：全球领先的智慧工厂解决方案样板点<br/>长安汽车与华为、中国联通共同打造的数智工厂，是全球首个全域5G数智AI柔性超级工厂。通过C2M模式驱动的柔性制造革命，长安实现了从“以产品为中心”到“以客户为中心”的转变。<br/>赛力斯：AI赋能的未来工厂典范<br/>作为新能源汽车领域的领军企业，赛力斯重庆两江分公司入选2024年重庆市未来工厂——AI赋能示范型。</p>]]></description></item><item>    <title><![CDATA[2026年主流CRM系统优缺点盘点：预算有限的团队更适合哪一款？ 程序员老叶 ]]></title>    <link>https://segmentfault.com/a/1190000047553606</link>    <guid>https://segmentfault.com/a/1190000047553606</guid>    <pubDate>2026-01-20 16:06:15</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>随着数字化转型的加速，客户关系管理（CRM）系统已成为企业不可或缺的工具。无论是销售、市场还是客户服务团队，CRM都在提升效率、优化客户体验、推动业绩增长方面发挥着核心作用。2026年，CRM市场竞争更加激烈，各大厂商不断创新，功能日益强大。但对于预算有限的中小团队，如何选择一款既实用又经济的CRM系统，成为了亟需解决的问题。</p><p>本文将盘点目前市场主流的CRM系统，包括Salesforce、Zoho CRM、HubSpot CRM、Microsoft Dynamics 365、Pipedrive、Freshsales等，从权威评测和用户反馈中提炼优缺点，并针对预算有限的团队给出建议。</p><hr/><h2>一、主流CRM系统概览</h2><p>根据Gartner、Capterra、PCMag等权威机构2026年最新评测，以下几款CRM系统在全球市场占有率和用户口碑方面表现突出：</p><ol><li><strong>Salesforce CRM</strong></li><li><strong>Zoho CRM</strong></li><li><strong>HubSpot CRM</strong></li><li><strong>Microsoft Dynamics 365</strong></li><li><strong>Pipedrive</strong></li><li><strong>Freshsales</strong></li></ol><hr/><h2>二、各CRM系统优缺点详解</h2><h3>1. Salesforce CRM</h3><h4>优点</h4><ul><li><strong>功能最全</strong>：作为全球领先的CRM，Salesforce拥有极为丰富的功能模块，包括销售自动化、营销自动化、服务管理、分析报表、AI智能助手等，适用于各类企业。</li><li><strong>高度可扩展</strong>：支持自定义开发、API集成，拥有庞大的应用生态（AppExchange），可根据业务需求进行深度定制。</li><li><strong>数据安全与合规性</strong>：通过多项国际认证，数据安全和隐私保护能力强。</li></ul><h4>缺点</h4><ul><li><strong>价格昂贵</strong>：基础版起步价较高，功能越多费用越高，适合预算充足的大中型企业。</li><li><strong>学习成本高</strong>：系统复杂，员工培训和实施周期较长。</li><li><strong>小团队功能过剩</strong>：许多功能对小型团队来说用不上，造成资源浪费。</li></ul><h4>适用建议</h4><p>预算有限的团队不建议首选，除非对功能有极高要求。</p><hr/><h3>2. <a href="https://link.segmentfault.com/?enc=eaEg%2FU75Le4Oz9iMdl0bQA%3D%3D.mTbFZw0QH0WQHzkwYOc2g10YYgZws%2FWgJzugSdwVT4Q%3D" rel="nofollow" target="_blank">Zoho CRM</a></h3><h4>优点</h4><ul><li><strong>性价比高</strong>：Zoho CRM以实惠的价格提供全面的CRM功能，尤其适合中小企业和初创团队。</li><li><strong>易用性强</strong>：界面简洁，操作直观，上手快，支持中文界面和本地化服务。</li><li><strong>功能丰富</strong>：涵盖销售管理、市场营销、自动化流程、数据分析等，支持多渠道集成（邮件、社交、电话等）。</li><li><strong>生态完善</strong>：与Zoho旗下其他产品（如Zoho Campaigns、Zoho Desk、Zoho Finance等）无缝集成，形成一体化办公平台。</li></ul><h4>缺点</h4><ul><li><strong>高级定制有限</strong>：虽然支持一定程度的定制，但与Salesforce相比，深度开发和复杂流程支持略弱。</li><li><strong>第三方集成略少</strong>：部分外部应用集成不如Salesforce丰富，但主流需求基本覆盖。</li></ul><h4>适用建议</h4><p>预算有限的团队首选之一，尤其适合追求高性价比和易用性的企业。</p><hr/><h3>3. HubSpot CRM</h3><h4>优点</h4><ul><li><strong>免费基础版</strong>：核心CRM功能完全免费，适合预算极其有限的团队。</li><li><strong>营销自动化强</strong>：HubSpot在营销自动化和内容管理领域表现突出，适合需要市场推广的团队。</li><li><strong>界面友好</strong>：设计现代，用户体验好，支持拖拽式自定义。</li></ul><h4>缺点</h4><ul><li><strong>进阶功能收费</strong>：如销售自动化、分析报表、客户服务等高级功能需付费，且价格逐级递增。</li><li><strong>本地化支持有限</strong>：中文支持和本地服务不如Zoho CRM。</li></ul><h4>适用建议</h4><p>预算有限且对营销自动化有需求的团队可以优先考虑，尤其是初创企业。</p><hr/><h3>4. Microsoft Dynamics 365</h3><h4>优点</h4><ul><li><strong>与Office生态无缝整合</strong>：适合已采用微软产品的企业，提升协同效率。</li><li><strong>功能全面</strong>：涵盖销售、市场、客服、项目管理等模块。</li><li><strong>强大分析能力</strong>：集成Power BI，数据分析和报表功能突出。</li></ul><h4>缺点</h4><ul><li><strong>价格偏高</strong>：整体费用不低，功能模块按需购买，成本易超预算。</li><li><strong>实施复杂</strong>：需要专业IT团队支持，学习曲线陡峭。</li></ul><h4>适用建议</h4><p>预算有限的团队不建议优先考虑，适合已有微软生态的大型企业。</p><hr/><h3>5. Pipedrive</h3><h4>优点</h4><ul><li><strong>专注销售流程</strong>：以销售为核心，流程清晰，适合销售驱动型团队。</li><li><strong>价格合理</strong>：基础版价格较低，按需升级，适合中小企业。</li><li><strong>易于使用</strong>：界面简洁，功能聚焦，学习成本低。</li></ul><h4>缺点</h4><ul><li><strong>功能相对单一</strong>：以销售为主，市场营销、客服等模块较弱。</li><li><strong>分析能力有限</strong>：数据分析和报表功能不如Salesforce和Zoho CRM全面。</li></ul><h4>适用建议</h4><p>预算有限且以销售为主的小型团队可以优先考虑。</p><hr/><h3>6. Freshsales（Freshworks CRM）</h3><h4>优点</h4><ul><li><strong>一体化解决方案</strong>：集成销售、市场、客服于一体，适合需要全流程管理的团队。</li><li><strong>价格亲民</strong>：基础版价格适中，功能覆盖日常需求。</li><li><strong>自动化强</strong>：支持销售自动化、邮件跟进、线索评分等。</li></ul><h4>缺点</h4><ul><li><strong>本地化支持一般</strong>：中文支持和国内服务有待提升。</li><li><strong>生态有限</strong>：与第三方应用集成不如Salesforce和Zoho CRM广泛。</li></ul><h4>适用建议</h4><p>预算有限且希望一体化管理的小型团队可以考虑。</p><hr/><h2>三、权威评测与用户反馈</h2><h3>Gartner魔力象限（2026）</h3><ul><li><strong>领导者象限</strong>：Salesforce、Microsoft Dynamics 365</li><li><strong>挑战者象限</strong>：Zoho CRM、HubSpot CRM</li><li><strong>远见者象限</strong>：Freshsales、Pipedrive</li></ul><h3>Capterra用户评分（2026）</h3><table><thead><tr><th>CRM系统</th><th>总分（满分5）</th><th>易用性</th><th>性价比</th><th>客户支持</th></tr></thead><tbody><tr><td>Salesforce</td><td>4.6</td><td>4.2</td><td>3.8</td><td>4.5</td></tr><tr><td>Zoho CRM</td><td>4.4</td><td>4.5</td><td>4.7</td><td>4.4</td></tr><tr><td>HubSpot CRM</td><td>4.5</td><td>4.7</td><td>4.6</td><td>4.3</td></tr><tr><td>Dynamics 365</td><td>4.3</td><td>4.0</td><td>3.9</td><td>4.2</td></tr><tr><td>Pipedrive</td><td>4.3</td><td>4.6</td><td>4.5</td><td>4.1</td></tr><tr><td>Freshsales</td><td>4.2</td><td>4.4</td><td>4.3</td><td>4.0</td></tr></tbody></table><h3>媒体点评（PCMag、TechRadar、Forbes）</h3><ul><li><strong>Salesforce</strong>：功能无敌，但价格高昂，适合大企业。</li><li><strong>Zoho CRM</strong>：中小企业首选，性价比极高，功能实用。</li><li><strong>HubSpot CRM</strong>：免费入门，营销自动化强，适合初创团队。</li><li><strong>Pipedrive</strong>：销售团队利器，流程简明，价格合理。</li><li><strong>Freshsales</strong>：一体化管理，适合成长型企业。</li></ul><hr/><h2>四、预算有限团队的选择建议</h2><h3>1. 明确需求</h3><p>首先，团队需明确自身需求：是以销售为主、市场为主，还是需要全流程管理？是否需要高度定制？对本地化支持有无要求？</p><h3>2. 价格与功能平衡</h3><ul><li><strong>预算极低且重视营销自动化</strong>：优先考虑<strong>HubSpot CRM</strong>免费版，后续可根据需求升级。</li><li><strong>追求高性价比与易用性</strong>：<strong>Zoho CRM</strong>是最佳选择，价格合理，功能全面，支持中文及本地服务。</li><li><strong>专注销售流程</strong>：<strong>Pipedrive</strong>简单高效，适合销售驱动型团队。</li><li><strong>一体化管理</strong>：<strong>Freshsales</strong>功能均衡，价格适中。</li><li><strong>对微软生态有依赖</strong>：可考虑<strong>Dynamics 365</strong>，但需预估预算与实施成本。</li></ul><h3>3. 试用与评估</h3><p>大多数CRM厂商都提供免费试用期，建议团队先实际操作，体验界面、功能和服务，再做最终决定。</p><hr/><h2>五、Zoho CRM的独特优势</h2><p>Zoho CRM在预算有限团队中的独特优势：</p><ul><li><strong>价格透明，套餐灵活</strong>：支持按需选择，避免资源浪费。</li><li><strong>本地化服务强</strong>：中国区设有专属团队，支持中文界面、微信集成等。</li><li><strong>生态系统完善</strong>：可无缝连接Zoho旗下办公、财务、项目等产品，提升团队整体协作效率。</li><li><strong>自动化与智能分析</strong>：通过AI助手Zia，实现线索评分、销售预测、自动提醒等功能，帮助小团队提升业绩。</li><li><strong>安全合规</strong>：通过GDPR、ISO等国际认证，保障数据安全。</li></ul><hr/><h2>六、结论</h2><p>2026年CRM市场百花齐放，各大系统各有千秋。对于预算有限的团队，选择CRM时应以“实用性、性价比、易用性”为核心标准。综合权威评测与用户反馈，<strong>Zoho CRM</strong>、<strong>HubSpot CRM</strong>、<strong>Pipedrive</strong>、<strong>Freshsales</strong>是最值得推荐的四款，能够兼顾成本与功能，助力中小团队高效管理客户关系，实现业绩增长。</p><p>最后建议，团队应结合实际需求，积极试用，多参考权威评测和用户口碑，选出最适合自己的CRM系统。未来，CRM将继续智能化、自动化，成为企业数字化转型的强力引擎。</p>]]></description></item><item>    <title><![CDATA[百度文心助手月活破2亿，国内三大AI超级入口形成 咸口锅包肉 ]]></title>    <link>https://segmentfault.com/a/1190000047553681</link>    <guid>https://segmentfault.com/a/1190000047553681</guid>    <pubDate>2026-01-20 16:05:17</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><img width="723" height="471" referrerpolicy="no-referrer" src="/img/bVdnG2S" alt="微信图片_20260120151234_1904_102.jpg" title="微信图片_20260120151234_1904_102.jpg"/></p><p><strong>1月20日，据《华尔街日报》报道，百度旗下文心助手月活用户数已突破2亿，与豆包、千问形成国内三大亿级AI入口。</strong></p><p>此前国内报道，<strong>文心助手</strong>是百度APP推出的AI智能助手，依托文心大模型和“百度猎户座”AI引擎，实现了搜索与AI的深度重构，<strong>是集深度思考、多模态交互与全场景服务于一体的全能搭子</strong>。</p><p>据悉，该助手具备强大的深度思考与长期记忆能力，能结合交互上下文，提供极具个性化的精准回应与推荐，并能深度思考和主动推荐，懂用户所想；同时具备多模态全能交互能力，支持视频通话、AI创作、拍照问答、打电话、拍题答疑等多项AI服务，让AI真正深入用户的实时生活与工作场景中；更为重要地是，文心助手充分发挥了百度搜索生态优势，支持MCP服务工具调用，实现从“提供信息”到“交付服务”。目前不仅接入了百度地图、百度健康等百度生态服务，而且链接了京东、美团、盈米基金等头部合作伙伴MCP服务，全面覆盖电商、健康、本地生活、学术教育、汽车、金融、法律、星座命理等多个领域，解决用户订票、出行、购物，理财与法律咨询等需求。</p>]]></description></item><item>    <title><![CDATA[家中杂物管理术 - 不断不舍不离 Homebox 本文系转载，阅读原文
https://blog.m]]></title>    <link>https://segmentfault.com/a/1190000047553718</link>    <guid>https://segmentfault.com/a/1190000047553718</guid>    <pubDate>2026-01-20 16:04:45</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><img width="723" height="381" referrerpolicy="no-referrer" src="/img/bVdnG3k" alt="Homebox 的 QR Code 标签" title="Homebox 的 QR Code 标签"/></p><p>本文分享如何通过 Homebox —— 一个自托管的家庭物品管理系统，重新整理我的 “杂物生活”，节省时间、减少焦虑，并让全家人都受益。如果你的第一反应是 “就家里那点东西要上系统，至于吗？” 那证明你是个正常人，我以前也是这样的反应。作为一名技术爱好者，我曾长期被家中不断增长的电子设备和零部件小工具所困扰。</p><p>作为一名软件工程师，我的生活始终游走在数字世界与现实世界之间。白天，我为大型企业设计复杂的系统架构，帮助它们管理庞大的数字资产、提升运转效率（Come on…… AI, 你不知道我已经失业了吗 🙄）；到了晚上和周末，我就是 “折腾党”。无论是写脚本自动化家里的灯光系统，在 Homelab 搭建一组 Raspberry Pi 集群，还是亲手给汽车做一次 DIY 换灯，这些动手项目都让我乐在其中。</p><p>然而，我的这些爱好背后，渐渐笼罩上了一层阴影：<strong>东西实在太乱了。</strong></p><blockquote>注：本文由我写大纲，Gemini 协助完成润色和扩展。我也作了后期 review 和修改。其中绝大部分内容来自我自己的真实经历和感受。</blockquote><p><img width="430" height="932" referrerpolicy="no-referrer" src="/img/bVdnG3n" alt="image.png" title="image.png" loading="lazy"/></p><h2>“设备税”：看不见的精神负担</h2><p>很多年里，我一直承受着一种挥之不去、却又说不清的低度焦虑感。家里到处都是“明明存在、却像消失了一样”的物品。我留着一堆早已不用设备的线缆，却偏偏找不到正在用的那根；抽屉里塞满了传感器、微控制器和汽车零件，因为没有整理，它们几乎等同于不存在。</p><p>真正让我崩溃的，通常是两种情况之一。第一种是“重复购买”：为了某个项目，我兴冲冲地买了一个 OBD‑II 扫描仪或一根高速 USB‑C 线，结果三个月后在一个盒子里，又发现了一模一样的东西。第二种是“家庭冲突”：我妻子问我备用电池或某个工具放在哪儿，而我只能指着车库或书房，给出一个模糊的方向——这显然无助于家庭和谐。</p><p>我终于意识到，自己正活成了那句老话的典型例子：“鞋匠的孩子没鞋穿。” 我在工作中帮公司把数据管理得井井有条，而自己的私人“资产管理”却一团糟。我必须开始<strong>自己吃自己做的狗粮（Eat My Own Dog Food）</strong>。</p><h2>发现 Homebox：自托管的答案</h2><p>我接触自托管（self‑hosting）已经有一段时间了，从媒体服务器到家庭自动化系统都折腾过。但直到我发现 <a href="https://link.segmentfault.com/?enc=JgNEBmccHdfjSjVc%2F4%2FrhA%3D%3D.lW6%2F%2BegcSHb2uIiFQ5r%2ByijecdW4tJKxiAnH7E%2BHkzxS9BnbnrwmBzsxNL3dCVks" rel="nofollow" target="_blank"><strong>Homebox</strong>（homebox.software）</a>，才算找到了拼图中缺失的那一块。</p><p>Homebox 是一个开源、自托管的家庭物品管理系统，专为普通家庭设计。它不像工业级资产管理系统那样复杂笨重，而是轻量、快速、直观。使用 Go 编写，后端是 SQLite，资源占用极低，丢到一台 Raspberry Pi 上跑也毫无压力。</p><h2>从“纸箱”到“比特”：搭建过程</h2><p>安装本身非常简单，一个 <code>docker-compose</code>，几分钟内就能看到干净、响应迅速的 Web 界面。真正的挑战——任何数据工程师都懂——在于<strong>录入数据</strong>。</p><p>一开始，说实话我有点想偷懒。面对多年积累下来的“技术囤货”，我差点在开始之前就放弃了。后来我决定套用一个最基本的管理原则：<strong>从小处开始，持续迭代</strong>。</p><p>我只专注于书房——我的“指挥中心”，那里放着 homelab 设备、焊接工具以及各种零碎电子玩意。</p><p>首先是 <strong>位置（Locations）</strong> 的层级结构。Homebox 支持嵌套位置，于是我这样规划：</p><ul><li><p><strong>书房</strong></p><ul><li><p><strong>储物柜 A</strong></p><ul><li><strong>第 1 层（微控制器）</strong></li><li><strong>第 2 层（线缆）</strong></li></ul></li><li><strong>书桌抽屉</strong></li></ul></li></ul><p>接下来是 <strong>物品（Items）</strong>。每一件硬件，我都会记录：</p><ul><li><strong>名称与描述</strong>：清晰、可搜索。</li><li><strong>购买时间与价格</strong>：方便追踪我的“折腾预算”。</li><li><strong>保修信息</strong>：不再翻邮箱找 PDF 发票，直接附在物品记录里。</li><li><strong>标签（Tags）</strong>：真正的威力所在，比如 <code>#automotive</code>、<code>#esp32</code>、<code>#usb-c</code>、<code>#raspberrypi</code>。</li></ul><h2>转折点：那串“消失的钥匙”</h2><p>起初的几个星期，Homebox 对我来说更像是一个“理论工具”——我在录数据，但还没真正依赖它。直到某个周二早上，我开会已经迟到十分钟，车钥匙却怎么也找不到。</p><p>在沙发垫、外套口袋里疯狂翻找五分钟后，我突然灵光一闪：<strong>我是不是记过这个？</strong>  <br/>我掏出手机，打开 Homebox，搜索 “钥匙”。结果立刻跳了出来：我把它们作为一个“资产”记录过，位置是 <strong>书房 → 书桌抽屉（小收纳盒）</strong>。</p><p>前一晚做项目时，我为了避免焊锡助焊剂沾到钥匙，把它们放到了那里。正是这个清晰、准确的位置记录，帮我省下了至少二十分钟的焦虑。那一刻，Homebox 从“业余项目”正式升级成了“生活必需品”。</p><h2>真正改变体验的功能</h2><p>一旦体会到实际价值，我就彻底“上头”了。下面这些功能，尤其打动技术爱好者：</p><ol><li><strong>二维码与标签</strong>  <br/>Homebox 可以为每个物品和位置生成二维码。我给那些不透明的收纳箱都贴上了小标签。现在不需要再翻箱倒柜，只要一扫码，就能看到箱子里的完整清单。</li><li><strong>维护与保养计划</strong>  <br/>对于汽车相关的零件，我可以设置提醒。比如刹车片、机油滤芯，什么时候该用、库存还剩多少，一目了然。</li><li><strong>家庭共享</strong>  <br/>这是对我婚姻帮助最大的一点。我给妻子也开了访问权限。现在她想找某个工具，或者只是想知道家里还有没有备用 HDMI 线，都可以自己查。结果是，“那个东西在哪？”的问题大幅减少。</li><li><strong>理性消费</strong>  <br/>在 京东 点下“立即购买”之前，我会先在 Homebox 里搜一下。这已经帮我省下了不少钱——提醒我某个电阻包、转接头，其实就躺在某个“待整理”的箱子里。</li></ol><h2>结语</h2><p>如果你是技术爱好者、DIY 玩家，或者只是厌倦了那种“东西到底放哪了？”的精神消耗，我真心推荐你试试 Homebox 。它不仅仅是一个数据库，而是一种重新掌控时间与空间的方式。</p><p>作为一名软件工程师，我越来越清楚：我们用来支撑企业系统稳定运行的那些原则——<strong>组织、有文档、易访问</strong>——在家里同样重要。  <br/>事实证明，我做的“Dog Food”味道还不错；而多亏了 Homebox，我的书房终于更像实验室，而不再是杂物堆了。</p><p>Homebox 这样的软件大概不会在国内流行。不是资产多少问题，是大家的习惯不同。大家的记忆力都特别好，国内的小工具小产品的价格又物美价廉，丢了买新的也大概不太心痛。而且管理风格上也不同，我们更注重人而非数据。而就算有这种需求，大概会选择 Excel 或大平台的云服务来解决。</p>]]></description></item><item>    <title><![CDATA[一图看懂HarmonyOS SDK 鸿蒙百晓生 ]]></title>    <link>https://segmentfault.com/a/1190000047553724</link>    <guid>https://segmentfault.com/a/1190000047553724</guid>    <pubDate>2026-01-20 16:03:59</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><img width="723" height="3235" referrerpolicy="no-referrer" src="/img/bVdnG3l" alt="一图看懂HarmonyOS SDK.png" title="一图看懂HarmonyOS SDK.png"/></p><p><a href="https://link.segmentfault.com/?enc=vXKh3XUlYn93qA%2FpEUJqWA%3D%3D.V9L0eIAoN7yhn8NRbneftliE5t%2FjTASybRF%2FlLqEMJrRUkJXiRoH4sGTM1f%2Fb8kwzEIJV3DAZrN3N7aun7mZdnFwQQ6qI34wO8eC3J4%2F22W9xK4d7nKZEOClhgODDWKb" rel="nofollow" target="_blank">HarmonyOS SDK 官方社区</a><br/><a href="https://link.segmentfault.com/?enc=iqp3DxN%2BDUgE06Ya1qjsAg%3D%3D.xANFr0XDENhSwMcWzLvGMavR5doh69ySSGYLmy0Td%2BsgH7h5cLcC1qH68CZ97%2Bj93OW%2FHS5HRJ6zECp94YV1jFdD9uM8DNJ26OwnOG9v3vf5oZqgymmUy1Er81Cfn6Vu" rel="nofollow" target="_blank">加入 HarmonyOS，正当其时</a></p>]]></description></item><item>    <title><![CDATA[一图看懂HarmonyOS SDK AI领域开放能力 鸿蒙百晓生 ]]></title>    <link>https://segmentfault.com/a/1190000047553740</link>    <guid>https://segmentfault.com/a/1190000047553740</guid>    <pubDate>2026-01-20 16:03:08</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><img width="723" height="1757" referrerpolicy="no-referrer" src="/img/bVdnG3T" alt="一图看懂HarmonyOS SDK AI领域开放能力.png" title="一图看懂HarmonyOS SDK AI领域开放能力.png"/></p><p><a href="https://link.segmentfault.com/?enc=BTgNG0EbmTHsW7ha3eALjg%3D%3D.QmU9KGmlSVNEPQgzGNw%2FIllPYWyOyfUYjEAeSFsfjD7nYfwvgE4%2Bo%2BvpuNR4pb%2FtkGU07RWu3CD97poeKFt9xQdTV%2BTpt4uByt5mVvkQml8Y3dqAacf9AQnaNW1px2F3" rel="nofollow" target="_blank">HarmonyOS SDK 官方社区</a><br/><a href="https://link.segmentfault.com/?enc=iDKLYEF5cJCJFwXdbZDB0g%3D%3D.fiuTdGYRUCjaNw0sRErnDamYNpduk%2FaTI7lJkcwBeC4UVSYWrGTdvLPQqozVDMvRyNqyTJZhyvIC1p5rJnzvQIwgbqwGgB4G95qd0T8r7jw85VnQ53U54Z3XoOrkOWbl" rel="nofollow" target="_blank">加入 HarmonyOS，正当其时</a></p>]]></description></item><item>    <title><![CDATA[保姆级教程！TinyPro 最新 SpringBoot 上手指南，新手也能快速落地 OpenTiny]]></title>    <link>https://segmentfault.com/a/1190000047553767</link>    <guid>https://segmentfault.com/a/1190000047553767</guid>    <pubDate>2026-01-20 16:02:09</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>本文由TinyPro中后台系统贡献者周泽龙原创。  </p><p>在长达三个月的开发下，终于TinyPro的Springboot后端版本终于要问世了，在本期内容中我将带大家一步步去搭建整个后端的流程，也将带大家去探索对于最新版本的更改应该如何实现，以及如何使用本项目进行一个二次的开发和探索。<br/>首先我们先要对于TinyPro项目进行一个整体的拉取，去到TinyPro的官方进行拉取，当我们获取到项目以后就可以进行开始今天的项目构建了。</p><blockquote>接下来的流程就是对于前端i项目的搭建以及后端的springboot项目的搭建，最后再去介绍咱们新版本里面的一些特性和组件</blockquote><h2>1.前端部分的搭建</h2><p>首先要确保咱们安装了Node.js、NPM、TinyCLI接下来就要正式初始化项目了首先我们进行初始化</p><p>(1)在命令行输入tiny init pro对项目进行一个初始化具体的流程可以看我的<a href="https://www.bilibili.com/video/BV1kNkeBKEEt/?spm_id_from=333.1387.homepage.video_card.click" target="_blank">视频介绍</a>  </p><p><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdnG4b" alt="1.jpg" title="1.jpg"/><br/>(2)接下来就让我们进入到我们的项目里面，tinyvue的前端代码里面我们首先进行一个项目的依赖的下载大家可以使用npm install进行项目依赖的下载。  </p><p>(3)当我们项目依赖下载完成后就可以进入到一个启动流程了，使用npm start进行一个项目的启动启动后就会开启3031端口这样就可以看见项目的启动界面了!  </p><p><img width="723" height="408" referrerpolicy="no-referrer" src="/img/bVdnG4c" alt="2.png" title="2.png" loading="lazy"/></p><blockquote>到目前为止我们的前端项目就算正式启动成功了，接下来让我们一起开始启动后端项目</blockquote><h2>2.后端项目的搭建</h2><p>首先我们需要确保自己的本地环境里面有jdk17，maven,mysql,redis以及一个自己喜欢的开发软件可以idea或者vscode</p><blockquote>好了准备工作做好以后接下来就让我们进入后端的开发和后端二次开发的一个介绍并且我也将带着大家去了解springboot里面的一些设计和里面的一些函数的内容接下来开始吧</blockquote><p>项目结构的介绍：<br/>当进入到项目里面的时候我们最直观的可以看见项目的一个整体结构  </p><p><img width="462" height="763" referrerpolicy="no-referrer" src="/img/bVdnG4d" alt="3.png" title="3.png" loading="lazy"/><br/>（1）先介绍一下项目的一个配置文件，对于所有的springboot项目上来第一件事就算看配置文件<code>application.properties</code>文件这个文件里面包含了所有项目需要的配置比如：<code>mysql</code>,<code>redis</code>,<code>Springjpa</code>,<code>mybatis-plus</code>(项目里面没有使用，但是基本的配置都配置好了，也就兼容了喜欢使用mybatis-plus的同学）大家可以更具自己的数据库信息和redis进行配置，需要自己填写好数据库的用户名，端口和驱动地址，还有redis的配置信息比如主机地址和端口号</p><blockquote>到这里的同学，那就恭喜大家数据服务的配置我们就是做好了，接下来就是对项目的依赖的下载，这块主要涉及到maven的使用，如果还，没有下载maven的同学记得赶快去下载</blockquote><p>（2）接下来开始项目依赖的初始化过程，在项目启动的时候，我们需要先对项目的依赖包去官方的仓库里面下载(这块给大家一个提醒，如果下载过慢的同学记得去配置一下maven的国内镜像源进行下载和配置),敲入命令<br/><code>mvn install</code>进行一个项目依赖的下载。</p><blockquote>如果到这里都执行成功，大家就可以正式的启动项目，正式启动项目之前我希望大家可以去查看自己jdk的配置是否是17，因为接下来的必须要使用jdk17了</blockquote><p>（3）进入到<code>TinyProApplication</code>文件里面进行启动项目，在这之前需要确保启动了redis和mysql的服务，并且配置好了密码，然后启动项目以后我们就会看到一个提示：  </p><p><img width="723" height="108" referrerpolicy="no-referrer" src="/img/bVdnG4e" alt="4.png" title="4.png" loading="lazy"/><br/>这里就算证明项目的整体正式启动成功了，接下来就开始监听3000端口了。</p><blockquote>项目启动成功以后就可以开始进行一个交互了，大家就可以进入到刚才启动的前端项目里面准备进行一个交互，账户和密码都是admin，这块是配置里面预先写好的，如果有人需要修改这个用户和角色名称，可以进到 <code>DataInitializer</code>文件里面找到user配置进行修改</blockquote><h2>3.二次开发的讲解</h2><p>首选项目里面可以进行二次开发的地方就算，<code>权限管理</code>，<code>拒绝策略</code>，以及<code>用户的登录校验</code>，<code>初始化配置</code>  </p><p><img width="723" height="434" referrerpolicy="no-referrer" src="/img/bVdnG4f" alt="5.png" title="5.png" loading="lazy"/></p><p>（1）首先就是项目的权限管理的问题大家可以看见代码里面首先需要权限校验的接口上面都会有一个</p><p><img width="723" height="76" referrerpolicy="no-referrer" src="/img/bVdnG4g" alt="6.png" title="6.png" loading="lazy"/><br/><code>@PermissionAnnotation</code>这个注解里面配置的就是当前接口需要用户所拥有的权限，然后这块里面底层的实现细节在aspect这个目录里面，然后里面就是对于apo的一个使用。如果大家需要给某一个接口增加新的权限大家就可以直接在接口的上面进行一个使用然后写入具体要限制的细节<br/>比如可以写：  </p><p><img width="723" height="68" referrerpolicy="no-referrer" src="/img/bVdnG4h" alt="7.png" title="7.png" loading="lazy"/><br/>这块就是要求用户必须要有menu::query::list这个权限才能进入到这个接口里面进行查询操作如果大家想更进一步了解到权限管理的细节，可以去看aop的使用java里面的切面编程</p><p>（2）接下来可以看拒绝的策略，首先对于接口拒绝策略的具体控制在配置文件里面，大家可以看到  </p><p><img width="449" height="60" referrerpolicy="no-referrer" src="/img/bVdnG4i" alt="8.PNG" title="8.PNG" loading="lazy"/> <br/>这块就是一个拒绝策略的开关，如果大家想开始拒绝策略就可以直接输入true这个然后就会开启拒绝策略进行项目模式，目前是默认在演示模式里面</p><blockquote>这个里面主要分为一个演示模式和一个项目模式，在项目模式里面大家可以自由的进行控制但是在演示模式里面，有很多的功能都被禁止了，所以大家要是不能使用的话就需要先查看是否是因为在演示模式里面导致的</blockquote><p>（3）接下来就是用户的登录校验，大家首先要明白的一个流程就是用户首先要登录，只有登录成功以后才会将token放到redis里面，然后用户登录的校验就会先去redis里面进行查询，如果查询的到就会通过校验，如果redis里面没有当前用户人的信息就会进行一个拒绝的返回，然后就会跳转到前端的登录界面里面进行一个登录。具体就是拿一个拦截器进行拦截然后对每一个请求都进行校验只有登录过的才能进行项目的操作<br/>（4）项目的初始化整个项目的初始化都在DataInitializer.java这个文件里面，如果后续需要进行一个项目的初始化调整，比如更改初始化的顺序以及在初始化的过程中想再加载一些资源都可以在这个文件里面进行增加  </p><p><img width="723" height="597" referrerpolicy="no-referrer" src="/img/bVdnG4j" alt="9.png" title="9.png" loading="lazy"/></p><p>在这个run方法里面进行添加，这样项目在启动的时候就会先去加载项目里面的内容然后生成一个data文件夹的，这就标志着项目以及初始化过了，不需要再进行初始化，接下来每次的项目初始化都会先去看项目里面是否有data的目录如果存在就不走初始化的逻辑了</p><blockquote>好了讲解完二次开发以后，接下来就要进入到docker的一个部署流程，在这个之前，大家可以更具的自己的情况去看是去买一个云服务器还是自己搭建一个虚拟机环境，然后进行配置，我在视频里面给搭建演示的就是在自己的虚拟机里面进行一个docker的部署和调用</blockquote><h2>4.docker的部署讲解</h2><p>首先要了解在进行docker部署的时候，自己的容器文件里面的内容是否创建好了，以及对应的docker-compose.yml的一个配置</p><blockquote>再检查完这些内容以后就要进入到我们的一个docker的部署流程环节，其实本质上也很简单就是进入到项目的文件夹目录里面，然后直接执行docker compose up -d这个命令以后，等待下载，但是下载的过程里面会有很多的问题比如下载过慢问题</blockquote><p>（1）将项目的文件上传到服务器上面  </p><p><img width="723" height="178" referrerpolicy="no-referrer" src="/img/bVdnG4k" alt="10.png" title="10.png" loading="lazy"/></p><p>然后进入当前目录大家可以看见，项目里面有两个文件一个是Dockerfile另一个是docker-compose.yml着两个文件是我们必须要的文件，进入进去看见  </p><p><img width="723" height="627" referrerpolicy="no-referrer" src="/img/bVdnG4l" alt="11.png" title="11.png" loading="lazy"/></p><p>里面就是一些配置比如mysql的地址以及redis的地址，都是对应着我们即将启动的容器名称  </p><p>（2）接下来就开始正式的启动docker-compose.yml文件，使用命令<code>docker compose up -d</code>启动成功以后就可以进行前端端口的配置映射到线上的docker地址，方便未来的开发  <br/><img width="723" height="58" referrerpolicy="no-referrer" src="/img/bVdnG4m" alt="12.png" title="12.png" loading="lazy"/></p><p>这个就是启动成功了，大家可以看映射的地址进行修改前端的配置了</p><h2>5.本次参加开源之夏的感受和收获</h2><p>在参加完这次的开源之夏以后，我最大的感受就是第一次有一个整齐的计划和老师还有别的学校的同学们可以一起开发一个软件，让我还没出社会的时候就已经拥有了独立开发的经验和经历。其次就是老师的辅导和社区的教导让我真的成长了很多，我特别感谢开源之夏和+OpenTiny社区对我的帮助,最后谢谢我的导师（真的很牛），他也很耐心的教我，特别感谢名字的话就不说了，不然以后有人烦他去了</p><blockquote>谢谢大家我真的很珍惜这次机会，谢谢开源之夏，谢谢OpenTiny社区，谢谢导师，那我的这次开源之旅就结束，但是我相信只是暂时，我以后还会继续投身到开源里面，也希望可以帮助更多的人</blockquote><h2>关于OpenTiny</h2><p>欢迎加入 OpenTiny 开源社区。添加微信小助手：opentiny-official 一起参与交流前端技术～</p><p>OpenTiny 官网：<strong><a href="https://link.segmentfault.com/?enc=1bq77WZNgrlUEDsegiodRw%3D%3D.cAyR304I96TIbLwWbkv%2Bxeiy3gIPtevI3SB9TScx144%3D" rel="nofollow" target="_blank">https://opentiny.design</a></strong>  <br/>OpenTiny 代码仓库：<strong><a href="https://link.segmentfault.com/?enc=f64LlGX42GlLYGEGtBpu7w%3D%3D.W8klIuP7OUixMKGygPskUlgCJKYRtu074IZbTzJPIxY%3D" rel="nofollow" target="_blank">https://github.com/opentiny</a></strong>  <br/>TinyPro 源码：<strong><a href="https://link.segmentfault.com/?enc=xelcuEcOPium4ycJ%2FVqJbg%3D%3D.uOlM9CwlDpY0f4zg2rZXpBANu%2F%2BNb4JpyATWimeZRfBzV6jWtBizXo2tif0Z7CJM" rel="nofollow" target="_blank">https://github.com/opentiny/tiny-pro</a></strong>  <br/>欢迎进入代码仓库 Star🌟TinyEngine、TinyVue、TinyNG、TinyCLI、TinyEditor~<br/>如果你也想要共建，可以进入代码仓库，找到 good first issue标签，一起参与开源贡献~</p>]]></description></item><item>    <title><![CDATA[数字化正如何将汽车产业链编织成一张智能协同一张网？ 雨大王 ]]></title>    <link>https://segmentfault.com/a/1190000047553828</link>    <guid>https://segmentfault.com/a/1190000047553828</guid>    <pubDate>2026-01-20 16:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>一、 数字浪潮下的汽车产业：协同成为新焦点<br/>当前，全球正处于深刻变革的时代，以人工智能、大数据、物联网为代表的前沿技术以前所未有的力量驱动着各行各业的转型升级。在这场新工业革命浪潮中，汽车产业链数字化转型不仅是技术发展的必然趋势，更是重构行业竞争格局、提升整体效率与质量的核心引擎。<br/>汽车产业，以其产业链长、涉及面广、关联带动性强的特征，长期以来形成了相对固定的层级结构和线性运作模式。从上游的原材料供应、零部件制造，到中游的整车设计、生产装配，再到下游的销售服务、用户反馈，每个环节都像链条中的一个节点。然而，这种传统的线性结构在日益复杂的市场环境和技术迭代下，暴露出诸多痛点：信息流转不畅导致“信息孤岛”，数据滞后影响决策时效，上下游协同效率低下制约了整体发展速度。<br/>二、 数字化实现智能协同：从数据感知到闭环运作<br/>实现汽车产业链从线性链条向智能协同网络的转变，关键在于建立端到端的数字化协同能力。这不仅仅是提升算力和优化流程，更深层次的意义在于构筑新型的联结机制，实现生产透明化到决策智能化的“闭环能力”。<br/>数字化协同的核心在于打破节点间的壁垒，实现数据的互联互通与价值共享。以Geega工业互联网平台为例，它深度融合了工业AI智能体架构，致力于将汽车产业链的“链式结构”向更智能、更协同的“网状生态”进化。通过其平台提供的“汽车数字化工厂”、“汽车生产监控系统”和“智能预检+系统”等核心产品，能够对生产过程进行深度洞察，实现关键信息的动态追踪与智能预警。<br/>三、 实践与案例：编织智能协同网络的探索</p><ol><li>广域铭岛：构建汽车产业链数字基础<br/>作为汽车产业链数字化转型的积极践行者，其工业互联网平台专注于解决转型中的应用难题。该平台不仅提供通用的工业AI应用能力，还针对汽车特定场景开发了“汽车数字化工厂”、“汽车生产监控系统”以及“GECP企业碳管理平台”等解决方案。</li><li>EDI技术：供应链协同的基石<br/>像“盟接之桥”这样的专业EDI服务商，通过支持多种传输协议（如AS2、OFTP2）和国际标准报文集，帮助企业实现了预测、订单、发货通知、发票等关键数据的自动流转。这不仅大幅降低了人工操作带来的错误率和对账成本，更重要的是，它支撑了JIT模式下的稳定运行，让供应链各节点能够像一个整体一样协同运作。</li><li>一物一码：连接物理与数字世界的桥梁<br/>“一物一码”技术，即为每个物理对象（如车辆、零部件）赋予唯一数字标识，正在成为汽车产业链数字化的基础支撑。它不仅是产品追溯的辅助工具，更是串联全产业链数据、驱动智能协同的核心数字基座。<br/>如中选科技（HiMarking）的实践所示，通过“一物一码”与区块链等技术结合，可以构建产品的“出生-流转-装车”全生命周期档案。这使得车辆的每一个环节数据都能无缝关联，满足质量管控和合规要求。</li></ol>]]></description></item><item>    <title><![CDATA[LangGraph简介 AIAgent研究 ]]></title>    <link>https://segmentfault.com/a/1190000047553298</link>    <guid>https://segmentfault.com/a/1190000047553298</guid>    <pubDate>2026-01-20 15:05:05</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>一、概述</h2><p>LangGraph是LangChain团队开发的<strong>低级别编排框架</strong>，专为构建、管理和部署<strong>长时间运行的有状态AI代理</strong>设计，提供持久化执行、灵活控制流和全面内存管理功能，支持循环和条件分支，是开发复杂AI工作流的理想选择。</p><h3>1.1 核心特点</h3><ul><li><strong>持久执行</strong>：自动保存执行状态，支持故障恢复和断点续跑</li><li><strong>循环与分支</strong>：突破传统DAG限制，支持复杂的条件判断和循环逻辑</li><li><strong>全面内存</strong>：集成短期工作内存和长期持久内存，支持跨会话状态保留</li><li><strong>人机协作</strong>：内置中断机制，允许人工介入审批或修改代理行为</li><li><strong>流支持</strong>：实时输出执行结果，包括LLM的token级流式响应</li><li><strong>可观察性</strong>：无缝集成LangSmith，提供完整的执行轨迹和状态转换可视化</li></ul><h2>二、核心概念</h2><h3>2.1 状态(State)</h3><p><strong>共享内存</strong>，所有节点都可读写的全局数据结构，是代理的"工作记忆"。</p><ul><li>定义为Python的TypedDict或dataclass，包含代理需要的所有信息</li><li>存储原始数据而非格式化文本，确保不同节点可灵活使用</li><li><p>示例：</p><pre><code class="python">from typing import TypedDict
class AgentState(TypedDict):
    messages: list  # 对话消息列表
    search_results: list  # 搜索结果
    user_preferences: dict  # 用户偏好</code></pre></li></ul><h3>2.2 节点(Nodes)</h3><p><strong>图的基本执行单元</strong>，是接收状态并返回更新的函数。</p><ul><li><p>类型：</p><ul><li>LLM节点：调用语言模型进行文本理解或生成</li><li>工具节点：执行外部API调用、数据库查询等</li><li>数据处理节点：转换或分析数据</li><li>人工介入节点：暂停执行等待用户输入</li></ul></li><li><p>定义示例：</p><pre><code class="python">def greet(state: AgentState) -&gt; dict:
    return {"greeting": f"Hello, {state['user_name']}!"}</code></pre></li></ul><h3>2.3 边(Edges)</h3><p><strong>节点间的连接</strong>，定义执行流的路径。</p><ul><li><strong>普通边</strong>：始终执行固定路径</li><li><strong>条件边</strong>：根据状态决定下一步执行节点</li><li><p>定义示例：</p><pre><code class="python"># 普通边：从"start"到"greet"
graph.add_edge("start", "greet")

# 条件边：根据状态判断是执行"search"还是"reply"
def decide_next(state: AgentState) -&gt; str:
    return "search" if state["needs_info"] else "reply"
graph.add_conditional_edges("greet", decide_next)</code></pre></li></ul><h2>三、架构与工作原理</h2><h3>3.1 图结构</h3><p>LangGraph使用<strong>有向图模型</strong>表示代理工作流，包含：</p><ul><li><p><strong>特殊节点</strong>：</p><ul><li><code>START</code>：执行入口点</li><li><code>END</code>：执行结束点</li></ul></li><li><strong>执行模型</strong>：基于"消息传递"的迭代执行，以离散"超步骤"(super-step)推进</li></ul><h3>3.2 状态管理</h3><ul><li><strong>短期内存</strong>：线程范围内存，随执行结束自动清除</li><li><p><strong>长期内存</strong>：</p><ul><li>存储于独立的<code>Store</code>系统，支持跨会话、跨线程访问</li><li>使用<code>namespace</code>和<code>key</code>组织数据，类似文件系统的目录和文件名</li><li>支持多种存储后端：内存(开发)、PostgreSQL(生产)、Redis等</li></ul></li></ul><h3>3.3 执行流程</h3><ol><li>初始化状态并设置入口节点</li><li>执行入口节点，更新状态</li><li>根据边的类型(普通/条件)决定下一节点</li><li>重复直到到达<code>END</code>或达到递归限制(默认25步)</li><li>执行过程中自动保存检查点，支持故障恢复</li></ol><h2>四、存储方案</h2><p>LangGraph支持多种存储后端，满足不同场景需求：</p><table><thead><tr><th>存储类型</th><th>适用场景</th><th>特点</th><th>配置示例</th></tr></thead><tbody><tr><td><strong>InMemoryStore</strong></td><td>开发测试</td><td>速度快，无持久化</td><td><code>store = InMemoryStore()</code></td></tr><tr><td><strong>PostgresStore</strong></td><td>生产环境</td><td>高可靠，支持事务</td><td><code>store = PostgresStore("postgresql://user:pass@host/db")</code></td></tr><tr><td><strong>RedisStore</strong></td><td>分布式系统</td><td>高性能读写，适合缓存</td><td><code>store = RedisStore("redis://host:port")</code></td></tr><tr><td><strong>SQLiteStore</strong></td><td>轻量级应用</td><td>文件存储，无需服务器</td><td><code>store = SQLiteStore("langgraph.db")</code></td></tr></tbody></table><p><strong>长期记忆配置</strong>：</p><pre><code class="python">from langgraph.store.postgres import PostgresStore
from langgraph.backends import CompositeBackend, StateBackend, StoreBackend

# 配置复合存储：/memories/路径下的数据持久化，其他临时存储
def make_backend(runtime):
    return CompositeBackend(
        default=StateBackend(runtime),  # 临时存储
        routes={"/memories/": StoreBackend(runtime, PostgresStore("..."))}  # 持久存储
    )</code></pre><h2>五、使用方法</h2><h3>5.1 安装</h3><pre><code class="bash">pip install -U langgraph  # Python版本
npm install @langchain/langgraph  # JavaScript版本</code></pre><h3>5.2 基本使用步骤</h3><p><strong>1. 定义状态</strong>：</p><pre><code class="python">from typing import TypedDict
class ChatState(TypedDict):
    messages: list  # 对话消息列表</code></pre><p><strong>2. 构建图</strong>：</p><pre><code class="python">from langgraph.graph import StateGraph, START, END
from langchain.llms import OpenAI

# 初始化图
graph = StateGraph(ChatState)

# 定义节点：调用LLM生成回复
def call_llm(state: ChatState):
    llm = OpenAI(temperature=0)
    response = llm.invoke(state["messages"])
    return {"messages": state["messages"] + [response]}

# 添加节点和边
graph.add_node("generate_response", call_llm)
graph.add_edge(START, "generate_response")
graph.add_edge("generate_response", END)</code></pre><p><strong>3. 编译并执行</strong>：</p><pre><code class="python"># 编译为可执行应用
app = graph.compile()

# 执行
initial_state = {"messages": [{"role": "user", "content": "Hello!"}]}
final_state = app.invoke(initial_state)
print(final_state["messages"][-1]["content"])  # 输出AI回复</code></pre><h3>5.3 条件执行与循环</h3><pre><code class="python"># 定义条件函数：检查是否需要调用工具
def needs_tool(state: ChatState) -&gt; Literal["use_tool", "reply"]:
    last_message = state["messages"][-1]
    return "use_tool" if last_message.get("tool_calls") else "reply"

# 添加条件边
graph.add_conditional_edges("generate_response", needs_tool)

# 添加工具节点和循环边
graph.add_node("use_tool", tool_node)
graph.add_edge("use_tool", "generate_response")  # 循环回LLM节点</code></pre><h2>六、API参考</h2><h3>6.1 Graph API</h3><p><strong>核心类</strong>：</p><ul><li><strong>StateGraph</strong>：构建状态驱动的图，需传入状态类型</li><li><strong>MessageState</strong>：预定义的消息状态，适合聊天应用</li><li><strong>Checkpointer</strong>：管理执行状态的保存和恢复</li></ul><p><strong>关键方法</strong>：</p><ul><li><code>add_node(name, function, **kwargs)</code>：添加节点，支持重试策略等配置</li><li><code>add_edge(from_node, to_node)</code>：添加普通边</li><li><code>add_conditional_edges(from_node, condition_func)</code>：添加条件边</li><li><code>compile(checkpointer=None)</code>：编译图为可执行应用，支持持久化配置</li><li><code>invoke(input_state, config=None)</code>：执行图，返回最终状态</li></ul><h3>6.2 Functional API (简化版)</h3><p>提供更简洁的方式构建小型工作流：</p><pre><code class="python">from langgraph import entrypoint, task

@entrypoint
def my_agent():
    state = {"counter": 0}
    while state["counter"] &lt; 3:
        state = task(increment)(state)  # 调用任务函数
    return state

@task
def increment(state):
    state["counter"] += 1
    return state

result = my_agent()  # 执行</code></pre><h2>七、开发指南</h2><h3>7.1 构建步骤</h3><ol><li><strong>设计工作流</strong>：将问题分解为离散步骤，确定节点间依赖关系</li><li><strong>定义状态</strong>：确定需要在步骤间共享的数据</li><li><strong>实现节点</strong>：为每个步骤编写函数，处理输入状态并返回更新</li><li><strong>连接节点</strong>：使用边定义执行顺序，添加必要的条件判断</li><li><strong>添加内存</strong>：配置检查点和持久化，实现长期记忆</li><li><strong>测试与调试</strong>：使用LangSmith可视化执行过程，检查状态转换</li></ol><h3>7.2 最佳实践</h3><p><strong>状态设计</strong>：</p><ul><li>只存储必要信息，避免冗余</li><li>保持状态原始，在节点内格式化输出</li><li>使用描述性键名，提高可读性</li></ul><p><strong>节点设计</strong>：</p><ul><li>单一职责：每个节点专注做一件事</li><li>错误处理：为不同错误类型设置适当的处理策略(重试/回退/人工介入)</li><li>外部调用：将API调用、数据库操作等封装为独立节点，便于添加重试和监控</li></ul><p><strong>内存管理</strong>：</p><ul><li>短期数据存于状态，长期数据使用专用存储</li><li>定期清理过时数据，优化存储性能</li><li>使用命名空间组织长期数据，便于管理和查询</li></ul><h2>八、调试与监控</h2><h3>8.1 使用LangSmith集成</h3><p>LangGraph无缝集成LangSmith，提供全面的可观察性：</p><pre><code class="python"># 启用LangSmith追踪
import os
os.environ["LANGSMITH_TRACING"] = "true"
os.environ["LANGSMITH_API_KEY"] = "..."

# 编译图时启用追踪
app = graph.compile(checkpointer=checkpointer, trace=True)</code></pre><p><strong>监控功能</strong>：</p><ul><li>执行轨迹可视化：查看完整执行路径和状态变化</li><li>性能分析：测量各节点执行时间，识别瓶颈</li><li>异常检测：自动标记执行错误和异常路径</li><li>交互式调试：在LangSmith Studio中检查中间状态</li></ul><h3>8.2 本地调试技巧</h3><ul><li><strong>断点打印</strong>：在节点函数中添加<code>print</code>语句，输出关键状态</li><li><strong>分步执行</strong>：使用<code>graph.invoke</code>并传入小输入，逐步验证每个节点</li><li><p><strong>错误处理</strong>：为节点添加详细的异常捕获和日志记录：</p><pre><code class="python">def safe_node(state):
    try:
        # 正常逻辑
    except Exception as e:
        return {"error": str(e)}  # 返回错误信息而非崩溃</code></pre></li></ul><h2>九、部署方案</h2><h3>9.1 自托管部署</h3><p><strong>使用Docker</strong>：</p><pre><code class="bash"># 安装CLI
pip install -U langgraph-cli

# 构建镜像
langgraph build --name my-agent .

# 运行
docker run -p 8124:8124 my-agent</code></pre><p><strong>生产配置建议</strong>：</p><ul><li>使用PostgreSQL作为存储后端，确保数据持久化</li><li>配置数据加密，保护敏感信息</li><li>设置适当的资源限制，防止滥用</li><li>使用负载均衡和水平扩展，提高吞吐量</li></ul><h3>9.2 LangSmith Cloud (原LangGraph Platform)</h3><p>提供一键式云部署：</p><ul><li><strong>Lite版本</strong>：免费使用，每年限制100万节点执行</li><li><strong>Enterprise版本</strong>：全功能支持，适合大规模生产环境</li></ul><p><strong>优势</strong>：</p><ul><li>自动扩展和高可用性</li><li>内置监控和告警系统</li><li>开箱即用的安全与合规功能</li><li>与LangSmith无缝集成，提供完整的可观察性</li></ul><h2>十、完整示例：构建天气查询代理</h2><pre><code class="python"># 1. 安装依赖
pip install langgraph langchain openai

# 2. 导入必要模块
from typing import TypedDict, Literal
from langchain.llms import OpenAI
from langchain_core.messages import HumanMessage, AIMessage
from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.memory import MemorySaver  # 内存检查点

# 3. 定义状态
class WeatherAgentState(TypedDict):
    messages: list  # 对话消息
    location: str  # 查询的城市
    weather_info: str  # 天气信息

# 4. 定义工具函数
def get_weather(location: str) -&gt; str:
    """简化的天气查询API"""
    if location.lower() == "sf":
        return "60°F, foggy"
    elif location.lower() == "ny":
        return "90°F, sunny"
    else:
        return "Weather data not available for this location"

# 5. 定义节点
def initial_prompt(state: WeatherAgentState) -&gt; dict:
    """询问用户想查询哪个城市的天气"""
    llm = OpenAI(temperature=0)
    response = llm.invoke([HumanMessage(content="Which city's weather would you like to check?")])
    return {"messages": [response]}

def parse_location(state: WeatherAgentState) -&gt; dict:
    """从用户消息中提取城市名"""
    last_message = state["messages"][-1]
    location = last_message.content.strip().lower()
    return {"location": location, "messages": state["messages"] + [AIMessage(content=f"Checking weather for {location}...")]}

def get_weather_info(state: WeatherAgentState) -&gt; dict:
    """调用天气工具获取信息"""
    weather = get_weather(state["location"])
    return {"weather_info": weather, "messages": state["messages"] + [AIMessage(content=f"Weather in {state['location']}: {weather}")]}

# 6. 构建图
graph = StateGraph(WeatherAgentState)

# 添加节点
graph.add_node("initial_prompt", initial_prompt)
graph.add_node("parse_location", parse_location)
graph.add_node("get_weather_info", get_weather_info)

# 添加边定义执行流
graph.add_edge(START, "initial_prompt")
graph.add_edge("initial_prompt", "parse_location")
graph.add_edge("parse_location", "get_weather_info")
graph.add_edge("get_weather_info", END)

# 7. 添加内存支持
checkpointer = MemorySaver()  # 使用内存检查点保存状态
app = graph.compile(checkpointer=checkpointer)

# 8. 执行代理
first_run = app.invoke({})
print("First run output:")
for msg in first_run["messages"]:
    print(f"{msg['role'].capitalize()}: {msg['content']}")

print("\nSecond run (with state persistence):")
# 第二次执行会保留之前的对话状态
second_run = app.invoke({})
for msg in second_run["messages"]:
    print(f"{msg['role'].capitalize()}: {msg['content']}")</code></pre><h2>十一、总结</h2><p>LangGraph是构建复杂AI代理的强大框架，通过状态驱动的图结构，提供了持久执行、灵活控制流和全面内存管理能力。使用LangGraph，开发者可以轻松构建具有记忆、能够处理复杂逻辑的AI代理，适用于客服、研究助手、自动化工作流等多种场景。</p>]]></description></item><item>    <title><![CDATA[Galaxy比数平台功能介绍及实现原理｜得物技术 得物技术 ]]></title>    <link>https://segmentfault.com/a/1190000047553344</link>    <guid>https://segmentfault.com/a/1190000047553344</guid>    <pubDate>2026-01-20 15:04:05</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>一、背景</h2><p>得物经过10年发展，计算任务已超10万+，数据已经超200+PB，为了降低成本，计算引擎和存储资源需要从云平台迁移到得物自建平台，计算引擎从云平台Spark迁移到自建Apache Spark集群、存储从ODPS迁移到OSS。</p><p>在迁移时，最关键的一点是需要保证迁移前后数据的一致性，同时为了更加高效地完成迁移工作（目前计算任务已超10万+，手动比数已是不可能），因此比数平台便应运而生。</p><h2>二、数据比对关键挑战与目标</h2><h3>关键挑战一：如何更快地完成全文数据比对</h3><p><strong>现状痛点：</strong></p><p>在前期迁移过程中，迁移同学需要手动join两张表来识别不一致数据，然后逐条、逐字段进行人工比对验证。这种方式在任务量较少时尚可应付，但当任务规模达到成千上万级别时，就无法实现并发快速分析。</p><p><strong>核心问题：</strong></p><ul><li>效率瓶颈：每天需要完成数千任务的比对，累计待迁移任务达10万+，涉及表数十万张。</li><li>扩展性不足：传统人工比对方式无法满足大规模并发处理需求。</li></ul><h3>关键挑战二：如何精准定位异常数据</h3><p><strong>现状痛点：</strong></p><p>迁移同学在识别出不一致数据后，需要通过肉眼观察来定位具体问题，经常导致视觉疲劳和分析效率低下。</p><p><strong>核心问题：</strong></p><ul><li>分析困难：在比对不通过的情况下，比对人员需要人工分析失败原因。</li><li>复杂度高：面对数据量庞大、加工逻辑复杂的场景，特别是在处理大JSON数据时，肉眼根本无法有效分辨差异。</li><li>耗时严重：单次比对不通过场景的平均分析时间高达1.67小时/任务。</li></ul><h3>比数核心目标</h3><p>基于以上挑战，数据比对系统需要实现以下核心目标：</p><ul><li>高并发处理能力：支持每天数千任务的快速比对，能够处理10万+待迁移任务和数十万张表的规模。</li><li>自动化比对机制：实现全自动化的数据比对流程，减少人工干预，提升比对效率。</li><li>智能差异定位：提供精准的差异定位能力，能够快速识别并高亮显示不一致的字段和数据。</li><li>可视化分析界面：构建友好的可视化分析平台，支持大JSON数据的结构化展示和差异高亮。</li><li>性能优化：将用户单次比对分析时间从小时级大幅缩短至分钟级别。</li><li>可扩展架构：设计可水平扩展的系统架构，能够随着业务增长灵活扩容。</li></ul><h2>三、解决方案实现原理</h2><h3>快速完成全文数据比对方法</h3><p><strong>比数方法调研</strong></p><p>待比对两表数据大小：300GB，计算资源：1000c</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553346" alt="" title=""/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047553347" alt="" title="" loading="lazy"/></p><p>经过调研分析比数平台采用第二种和第三种相结合的方式进行比数。</p><p><strong>先Union再分组数据一致性校验原理</strong></p><p>假如我们有如下a和b两表张需要进行数据比对</p><p>表a：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553348" alt="" title="" loading="lazy"/><br/>表b：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553349" alt="" title="" loading="lazy"/><br/><strong>表行数比较：</strong></p><pre><code>select count(1) from a ;</code></pre><pre><code>select count(1) from b ;</code></pre><p>针对上面的查询结果，如果数量不一致则退出比对，待修复后重新比数；数量一致则继续字段值比较。</p><p><strong>字段值比较：</strong></p><p>第一步：union a 和 b</p><pre><code>select 1 as _t1_count, 0 as _t2_count, `id`, `name`, `age`, `score`
from a
union all
select 0 as _t1_count, 1 as _t2_count, `id`, `name`, `age`, `score`
from b</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553350" alt="" title="" loading="lazy"/></p><p>第二步：sum(_t1_count)，sum(_t2_count) 后分组</p><pre><code>select sum(_t1_count) as sum_t1_count, sum(_t2_count) as sum_t2_count, `id`, `name`, `age`, `score`
from (
select 1 as _t1_count, 0 as _t2_count, `id`, `name`, `age`, `score`
from a
union all
select 0 as _t1_count, 1 as _t2_count, `id`, `name`, `age`, `score`
from b
) as union_table
group by `id`, `name`, `age`, `score`</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553351" alt="" title="" loading="lazy"/><br/>第三步：把不一致数据写入新的表中(即上面表中sum_t1_count和sum_t2_count不相等的数据)</p><pre><code>drop table if exists a_b_diff_20240908;
create table a_b_diff_20240908 as select * from (
select sum(_t1_count) as sum_t1_count, sum(_t2_count) as sum_t2_count, `id`, `name`, `age`, `score`
from (
select 1 as _t1_count, 0 as _t2_count, `id`, `name`, `age`, `score`
from a
union all
select 0 as _t1_count, 1 as _t2_count, `id`, `name`, `age`, `score`
from b
) as union_table
group by `id`, `name`, `age`, `score`
having sum(_t1_count) &lt;&gt; sum(_t2_count)
) as tmp</code></pre><p>如果a_b_diff_20240908没有数据则两张表没有差异，比数通过，如有差异如下：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553352" alt="" title="" loading="lazy"/></p><p>第四步：读取不一致记录表，根据主键（比如id）找出不一致字段并写到结果表中。</p><p>第五步：针对不一致字段的数据进行根因分析，如 json 、数组顺序问题、浮点数精度问题等，给出不一致具体原因。</p><p><strong>哈希值聚合实现高效一致性校验</strong></p><p>针对上面union后sum 再 group by 方式 在数据量大的时候还是非常耗资源和时间的，考虑到比数任务毕竟有70%都是一致的，所以我们可以先采用哈希值聚合比较两表的的值是否一致，使用这种高效的方法先把两表数据一致的任务过滤掉，剩下的再采用上面方法继续比较，因为还要找出是哪个字段哪里不一致。原理如下：</p><pre><code>SELECT count (*),SUM(xxhash64(cloum1)^xxhash64(cloum2)^...) FROM tableA 
EXCEPT 
SELECT count(*),SUM(xxhash64(cloum1)^xxhash64(cloum2)^...) FROM tableB</code></pre><p>如果有记录为空说明数据一致，不为空说明数据不一致需要采用上面提到union 分组的方法去找出具体字段哪里不一样。</p><p>通过哈希值聚合，单个任务比数时间从500s降低到160s，节省大约70%的时间。</p><p>找到两张表不一致数据后需要对两张的数据进行分析确定不一致的点在哪里？这里就需要知道表的主键，根据主键逐个比对两张表的其他字段，因此系统会先进行主键的自动探查，以及无主键的兜底处理。</p><h3>精准定位异常数据实现方法</h3><p><strong>自动探查主键：实现原理如下</strong></p><p>刚开始我们采用的前5个字段找主键的方式，如下：</p><pre><code>针对表a的前5个字段 循环比对
select count(distinct id) from a 与 select count(1) from a 比较 ，如相等主键为id ，不相等继续往下执行
select count(distinct id,name) from a 与 select count(1) from a比较，如相等主键为id,name ，不相等继续往下执行
select count(distinct id,name,age) from a 与 select count(1) from a比较，如相等主键为id,name,age ，不相等继续往下执行，直到循环结束</code></pre><p>采用上面的方法不一致任务中大约有49.6%任务自动探查主键失败：因此需重点提升主键识别能力。</p><p>针对以上主键探查成功率低的问题，后续进行了一些迭代，优化后的主键探查流程如下：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553353" alt="" title="" loading="lazy"/></p><p><strong>一、先采用sum(hash)高效计算方式进行探查：</strong></p><p>1.先算出两张表每个字段的sum(hash)值  。</p><pre><code>select sum(hash(id)),sum(hash(name)),sum(hash(age)),sum(hash(score)) from a 
union all 
select sum(hash(id)),sum(hash(name)),sum(hash(age)),sum(hash(score)) from b;</code></pre><p>2.找出值相等的所有字段，本案例中为 id, name。</p><p>3.对id，name 可能是主键进一步确认，先进行行数校验，如 select count(distinct id,name) from a 的值等于select count(1) from a 则进一步校验，否则进入到第二种探查主键方式。</p><p>4.唯一性验证，如果值为0则表示探查主键成功，否则进入到第二种探查主键方式。</p><pre><code>slect count(*) from ((select id,name from a ) expect (select id,name from b))</code></pre><p><strong>二、传统distinct方式探查：</strong></p><p>针对表a的前N（所有字段数/2或者前N、后N等）个字段 循环比对：</p><p>1.select count(distinct id) from a与select count(1) from a比较 ，如相等主键为id ，不相等继续往下执行。</p><p>2.select count(distinct id,name) from a 与 select count(1) from a比较，如相等主键为id,name ，不相等继续往下执行。</p><p>3.select count(distinct id,name,age) from a 与 select count(1) from a比较，如相等主键为id,name,age ，不相等继续往下执行，直到循环结束。</p><p><strong>三、全字段排序模拟:</strong></p><p>如果上面两种方式还是没有找到主键则把不一致记录表进行全字段排序然后对第一条和第二条记录挨个字段进行分析，找出不一致内容，示例如下：</p><pre><code>slect * from a_b_diff_20240908 order by id,name,age,score asc limit 10;</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553354" alt="" title="" loading="lazy"/><br/>通过以上结果表可以得出两表的age字段不一致 ，score不一致（但按key排序后一致）。</p><p>如果以上自动化分析还是找不到不一致字段内容，可以人工确认表的主键后到平台手动指定主键字段，然后点击后续分析即可按指定主键去找字段不一致内容。</p><p>通过多次迭代优化找主键策略，找主键成功率从最初的50.4%提升到75%，加上全字段order by排序后最前两条数据进行分析，相当于可以把找主键的成功率提升到90%以上。</p><p><strong>根因分析：实现原理如下</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553355" alt="" title="" loading="lazy"/></p><p>当数据不一致时，平台会根据主键找出两个表哪些字段数据不一致并进行分析，具体如下：</p><ul><li><strong>精准定位：</strong> 明确指出哪条记录、哪个字段存在差异，并展示具体的源数据和目标数据值。</li><li><strong>智能根因分析：</strong> 内置了多种差异模式识别规则，能够自动分析并提示不一致的可能原因，例如：</li><li>精度问题：如浮点数计算1.0000000001与1.0的差异。</li><li>JSON序列化差异：如{"a":1, "b":2}与{"b":2, "a":1}，在语义一致的情况下，因键值对顺序不同而被标记为差异。同时系统会提示排序后一致。</li><li>空值处理差异：如NULL值与空字符串""的差异判定。</li><li>日期时区转换问题：时间戳在不同时区下表示不同。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047553356" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047553357" alt="" title="" loading="lazy"/></li><li><strong>比对结果统计：</strong> 提供总数据量、一致数据量、不一致数据量及不一致率百分比，为项目决策提供清晰的量化依据。</li><li>比数人员根据平台分析的差异原因，决定是否手动标记通过或进行任务修复。</li><li>效果展示：</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553358" alt="" title="" loading="lazy"/></p><h2>四、比数平台功能介绍</h2><h3>数据比对基本流程</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553359" alt="" title="" loading="lazy"/></p><h3>任务生成：三种比对模式</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553360" alt="" title="" loading="lazy"/></p><ul><li><strong>两表比对：</strong> 最直接的比对方式。用户只需指定源表与目标表，平台即可启动全量数据比对。它适用于临时比对的场景。</li><li><strong>任务节点比对：</strong> 一个任务可能输出多个表，逐一配置这些表的比对任务繁琐且易遗漏，任务节点比对模式完美解决了这一问题。用户只需提供任务节点ID，平台便会自动解析该节点对应的SQL代码，提取出所有输出表，并自动生成比对任务，极大地提升任务迁移比对效率。</li><li><strong>SQL查询比对：</strong> 业务在进行SDK迁移只关心某些查询在迁移后数据是否一样，因此需要对用户提交的所有查询SQL进行比对，平台会分别在ODPS和Spark引擎上执行该查询，将结果集导出到两张临时表，再生成比对任务。</li></ul><h3>前置校验：提前发现问题</h3><p>在启动耗时的全量比对之前，需要对任务进行前置校验，确保比对是在表结构一致、集群环境正常的情况下进行，否则一旦启动比数会占用大量计算资源，最后结果还是比数不通过，会影响比数平台整体的运行效率。因此比数平台一般会针对如下问题进行前置拦截。</p><ul><li><strong>元数据一致性校验：</strong> 比对双方的字段名、字段类型、字段顺序、字段个数是否一致。</li><li><strong>函数缺失校验：</strong> 针对Spark引擎，校验SQL中使用的函数是否存在、是否能被正确识别，避免因函数不支持而导致的比对失败。</li><li><strong>语法问题校验：</strong> 分析SQL语句的语法结构，确保其在目标引擎中能够被顺利解析，避免使用了某些特定写法会导致数据出现不一致情况，提前发现语法层面问题，并对任务进行改写。</li></ul><p><strong>更多校验点如下：</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553361" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047553362" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047553363" alt="" title="" loading="lazy"/><br/>通过增加以上前置校验拦截，比数任务数从每天3000+<strong>下降到1500+，</strong> 减少<strong>50%</strong> 的无效比数，其中UDF缺失最多，有效拦截任务1238，缺少函数<strong>87个</strong>（帮比数同学快速定位，一次性解决函数缺失问题，避免多次找引擎同学陆陆续续添加，节省双方时间成本）。</p><h3>破解比数瓶颈：资源分配与任务调度优化</h3><p>由于比数平台刚上线的时候只有计算迁移团队在使用，后面随着更多的团队开始使用，性能遇到了如下瓶颈：</p><p><strong>1.资源不足问题：</strong> 不同业务（计算迁移、存储迁移、SDK迁移）的任务相互影响，基本比数任务与根因分析任务相互抢占资源。</p><p><strong>2.任务编排不合理：</strong> 没有优先级导致大任务阻塞整体比数进程。</p><p><strong>3.引擎参数设置不合理：</strong> 并行度不够、数据分块大小等高级参数。</p><p>针对以上问题比数平台进行了如下优化：</p><ul><li>按不同业务拆分成多个队列来运行，保证各个业务之间的比数任务可以同时进行，不会相互影响。</li><li>根因分析使用单独的队列，与数据比对任务的队列分开，避免相互抢占资源发生“死锁”。</li><li>相同业务内部按批次分时段、分优先级运行，保障重要任务优先进行比对。</li><li>针对Spark引擎默认调优了公共参数、并支持用户自主设置其他高级参数。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553364" alt="" title="" loading="lazy"/></p><p>通过以上优化达到到了如下效果：</p><ul><li>比数任务从每天22点完成提前至<strong>18点</strong>前，同时支持比数同学自主控制高优任务优先执行，方便比数同学及时处理不一致任务。</li><li>通过优化资源队列使用方式，使系统找不到主键辅助用户自主找主键接口响应时间<strong>从58.5秒降到 26.2秒。</strong></li></ul><h2>五、比数平台收益分享</h2><p>平台持续安全运行500+天，每日可完成2000+任务比对，有效比数128万+次，0误判。</p><ul><li>助力计算迁移团队节省45+人日/月，完成数据分析、离线数仓空间任务的比对、交割。</li><li>助力存储迁移团队完成20%+存储数据的迁移。</li><li>助力引擎团队完成800+批次任务的回归验证，确保每一次引擎发布的安全及高效。</li><li>助力SDK迁移团队完成80%+应用的迁移。</li></ul><h2>六、未来演进方向</h2><p>接下来，平台计划在以下方面持续改进：</p><p><strong>智能分析引擎：</strong> 针对Json复杂嵌套类型的字段接入大模型进行数据根因分析，找出不一致内容。</p><p><strong>比对策略优化：</strong> 针对大表自动切分进行比对，降低比数过程出现因数据量大导致异常，进一步提升比对效率。</p><p><strong>通用方案沉淀：</strong> 将典型的比对场景和解决方案能用化，应用到更多场景及团队中去。</p><h2>七、结语</h2><p>比数平台是得物在迁移过程中，为了应对海量任务、大数据量、字段内容复杂多样、异常数据难定位等挑战，确保业务迁移后数据准确而专门提供的解决方案，未来它不单纯是一个服务计算迁移、存储迁移、SDK迁移、Spark版本升级等需要的数据比对工具，而是演进为数据平台中不可或缺的基础设施。</p><h3>往期回顾</h3><p>1.得物App智能巡检技术的探索与实践</p><p>2.深度实践：得物算法域全景可观测性从 0 到 1 的演进之路 </p><p>3.前端平台大仓应用稳定性治理之路｜得物技术</p><p>4.RocketMQ高性能揭秘：承载万亿级流量的架构奥秘｜得物技术</p><p>5.PAG在得物社区S级活动的落地</p><h3>文 /Galaxy平台</h3><p>关注得物技术，每周更新技术干货</p><p>要是觉得文章对你有帮助的话，欢迎评论转发点赞～</p><p>未经得物技术许可严禁转载，否则依法追究法律责任。</p>]]></description></item><item>    <title><![CDATA[推荐的工业AI大模型在制造业中的应用案例 雨大王 ]]></title>    <link>https://segmentfault.com/a/1190000047553385</link>    <guid>https://segmentfault.com/a/1190000047553385</guid>    <pubDate>2026-01-20 15:03:29</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>工业AI大模型正逐渐成为现代制造业数字化转型的核心驱动力。与通用型AI模型不同，工业AI大模型深度融合行业知识、工艺流程与多模态数据，为制造企业提供从研发、生产到运营的全链路智能化解决方案。<br/>一、工业AI大模型的发展现状与特点<br/>工业AI大模型的发展并非一蹴而就，它经历了从单一算法应用到平台化、模块化智能体的演进过程。与传统的工业软件或通用AI模型相比，工业AI大模型更加注重场景适配性、多模态融合与知识沉淀能力。<br/>不仅如此，工业AI大模型还表现出强大的自学习与自适应能力。它能够基于实时数据动态调整模型参数，适应不同的生产环境与外部条件变化。例如，在复杂排产场景中，传统方法往往需要人工干预，而工业AI大模型可以通过强化学习与优化算法，在极短时间内生成全局最优解，大幅提升资源利用效率。<br/>然而，工业AI大模型的落地仍面临一些挑战。数据质量不高、行业知识沉淀不足、系统集成复杂度高等问题，限制了其规模化应用。正因如此，平台化与生态化逐渐成为工业AI大模型发展的重要方向。<br/>二、工业AI大模型的核心优势与应用价值<br/>工业AI大模型的核心优势在于其能够实现全局优化与跨环节协同。传统工业软件往往局限于某一特定环节，例如MES系统负责生产执行，ERP系统侧重资源规划，而工业AI大模型可以打通这些系统之间的数据壁垒，实现从订单接收到产品交付的全流程智能化管理。<br/>具体而言，工业AI大模型在以下方面展现出显著价值：<br/>首先，它能够大幅提升生产效率和资源利用率。通过智能排产、能耗优化、质量预测等功能，企业可以实现更精细化的运营管理。<br/>其次，工业AI大模型支持多模态数据的融合处理，这在质量检测、设备健康管理等场景中尤为重要。例如，通过结合视觉识别与传感器数据，AI模型可以实时监测生产线上的异常情况，并提前预警，避免非计划停机。此外，工业AI大模型还表现出较强的泛化与迁移能力。一家企业在某个场景中训练优化的模型，可以通过微调快速适配到其他类似场景中，这大大降低了AI应用的开发与部署成本。<br/>三、工业AI大模型的应用案例与实效分析<br/>在实际应用中，工业AI大模型已经帮助众多制造企业取得了显著成效。以下是几个典型案例：<br/>广域铭岛为领克成都工厂提供的工业互联网平台，是一个典型的全链路智能化应用。该平台通过整合订单管理、生产排程、质量控制和物流调度等环节，实现了工厂级的数据协同与决策优化。其中，基于AI大模型的智能排产系统，能够在考虑设备状态、物料供应和人员安排等多重约束条件下，快速生成高效生产计划。结果显示，该工厂订单交付周期缩短15%，质量损失成本降低13%，物流效率提升10%。<br/>阿里巴巴旗下犀牛智造通过AI大模型实现服装行业的柔性生产，能够根据市场需求快速调整生产计划。<br/>华为云推出的工业智能体方案，则专注于高端制造领域的预测性维护与质量控制。这些案例共同表明，工业AI大模型正在成为制造业转型升级的重要技术支撑。</p>]]></description></item><item>    <title><![CDATA[活字格低代码：破解企业数据孤岛难题，加速数字化转型进程 葡萄城技术团队 ]]></title>    <link>https://segmentfault.com/a/1190000047553419</link>    <guid>https://segmentfault.com/a/1190000047553419</guid>    <pubDate>2026-01-20 15:02:36</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2><strong>引言</strong></h2><p>在数字化转型的浪潮中，企业信息化建设面临的核心挑战已从“是否转型”转变为“如何高效推进”。然而，数据孤岛问题成为阻碍企业发展的普遍难题——系统割裂、数据无法互通、业务流程低效。传统解决方案如外包开发或Excel管理，往往成本高、周期长且难以适应快速变化的业务需求。  </p><p>活字格低代码开发平台通过<strong>可视化开发、跨系统集成、AI增强</strong>等能力，帮助企业将开发周期缩短60%，实现数据互通与流程自动化。本文将深入解析其技术原理、实践案例及行业价值，为企业的数字化转型提供新思路。</p><h3><strong>一、数据孤岛的成因与行业痛点</strong></h3><h4>1. <strong>系统割裂的典型场景</strong></h4><ul><li><strong>多系统并存</strong>：集团与子公司使用独立ERP、OA系统，数据需人工导出导入。</li><li><strong>工具依赖</strong>：Excel管理导致版本混乱、权限失控，如某制造企业因表格版本错误损失百万订单。</li><li><strong>接口开发成本高</strong>：传统集成需编写复杂API，平均耗时3-6个月，且维护困难。</li></ul><h4>2. <strong>传统解决方案的局限性</strong></h4><ul><li><strong>外包开发</strong>：周期长（平均6个月）、灵活性差，需求变更时需重新付费。</li><li><p><strong>定制化集成</strong>：成本高昂，某零售企业集成CRM与供应链系统花费超200万元。</p><ul><li/></ul></li></ul><blockquote><strong>案例</strong>：某能源集团因数据孤岛导致决策延迟，月度报表汇总需5天，错失市场机会。</blockquote><h3><strong>二、活字格的技术突破：如何破解孤岛？</strong></h3><h4>1. <strong>可视化数据集成：WebAPI与SSO</strong></h4><ul><li><p><strong>HTTP-based WebAPI</strong>：通过配置化服务端命令调用远程API，无需编写底层代码。</p><ul><li><strong>优势</strong>：比数据库直连安全，比消息队列易管理，支持实时数据同步。</li><li><strong>实践</strong>：某物流企业集成TMS与WMS系统，数据同步效率提升90%。</li></ul></li><li><strong>单点登录（SSO）</strong>：统一入口访问多系统，用户无需重复登录。</li></ul><h4>2. <strong>类Excel设计器：业务人员也能开发</strong></h4><ul><li><strong>拖拽式表单构建</strong>：支持动态规则、数据验证，如某医院1天内搭建疫情填报系统。</li><li><p><strong>简化的BPMN流程引擎</strong>：支持加签、回退等复杂逻辑，审批流程上线时间缩短70%。</p><ul><li/></ul></li></ul><blockquote><p><strong>代码示例</strong>：配置服务端命令调用API</p><pre><code class="JavaScript">// 活字格中调用远程WebAPI  
Forguncy.Command.executeWebAPI({  
  url: "https://api.erp.com/sales",  
  method: "GET",  
  onSuccess: (data) =&gt; { console.log(data); }  
});  </code></pre></blockquote><h3><strong>三、效率提升：从“月”到“周”的飞跃</strong></h3><h4>1. <strong>开发周期缩短60%的底层逻辑</strong></h4><ul><li><strong>模块化复用</strong>：预置模板库（如CRM、进销存）覆盖80%通用场景。</li><li><strong>运行时热更新</strong>：修改流程或表单无需重新发布，某电商促销系统迭代速度提升3倍。</li></ul><h4>2. <strong>行业对比数据</strong></h4><table><thead><tr><th>方案</th><th>平均周期</th><th>成本</th><th>灵活性</th></tr></thead><tbody><tr><td>外包开发</td><td>6个月</td><td>50万+</td><td>低</td></tr><tr><td>传统低代码</td><td>2个月</td><td>20万</td><td>中</td></tr><tr><td><strong>活字格</strong></td><td><strong>2周</strong></td><td><strong>5万起</strong></td><td><strong>高</strong></td></tr></tbody></table><blockquote><strong>案例</strong>：某汽车经销商用活字格2周上线售后工单系统，传统开发需3个月。</blockquote><h3><strong>四、扩展性与AI赋能：面向未来的架构</strong></h3><h4>1. <strong>混合开发模式</strong></h4><ul><li><strong>低代码+编码</strong>：JavaScript插件扩展复杂逻辑，如封装高性能数据清洗API。</li><li><strong>一键迁移</strong>：将Access应用转为Web系统，某政府单位3天完成老旧系统升级。</li></ul><h4>2. <strong>AI增强全流程</strong></h4><ul><li><strong>设计时</strong>：自然语言生成SQL查询（如“查询2023年销售额TOP10客户”）。</li><li><strong>运行时</strong>：AI助手自动检测数据异常，某银行风控系统误报率降低40%。</li></ul><h2><strong>结论</strong></h2><p>活字格低代码平台通过四大核心能力——<strong>可视化集成、敏捷开发、混合扩展、AI增强</strong>，为企业提供了一条高效破解数据孤岛的路径。其价值不仅体现在“开发周期缩短60%”的效率提升，更在于重构了企业数字化的协作范式：</p><ol><li><strong>从被动响应到主动创新</strong>：业务部门可直接参与系统搭建。</li><li><strong>从孤立系统到生态协同</strong>：ERP、OA、CRM等无缝互通。</li><li><strong>从固定流程到智能进化</strong>：AI持续优化业务流程。</li></ol><p>在数字化转型的竞赛中，活字格正成为企业赢得敏捷性的关键引擎。</p>]]></description></item><item>    <title><![CDATA[2026年8个最新高效率AI建站工具分享 UXbot ]]></title>    <link>https://segmentfault.com/a/1190000047553464</link>    <guid>https://segmentfault.com/a/1190000047553464</guid>    <pubDate>2026-01-20 15:01:57</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>当下全球智能化发展迅猛，企业和创作者对品牌线上平台的要求越来越高——不仅要搭建得快、能适配全球不同场景，质感还得够专业。传统建站方式受限于技术门槛高、多设备适配麻烦、开发周期长等问题，根本跟不上全球业务快速拓展的节奏。AI技术的突破，催生了一批智能又高效的建站工具，还能适配全球场景，彻底改变了大家搭建线上平台的思路。下面精选8款全球热门AI建站工具，包括UXbot、CodeWP、10Web、Unbounce、Hostinger、Jimdo、Framer、Shopify，从技术核心、全球适用场景、实际用法和适用范围四个方面详细说明，给全球用户提供靠谱的选型参考，帮大家快速做出高质量的数字化平台。<br/>一、核心工具深度解析</p><ol><li>UXbot：自然语言驱动的零代码个性化建站标杆<br/>UXbot是青颖飞帆旗下的旗舰AI建站产品，基于自然语言操作，就能让不懂技术的人也轻松建站。借助成熟的AI语义理解技术，用户不用复杂操作，只需简单几句话说清品牌需求、想要的功能和视觉偏好，就能快速拿到专属的个性化网站方案。<br/>它最核心的价值就是打破了技术壁垒，集网页和应用界面设计、可交互原型制作、Web前端代码生成为一体。哪怕完全没有代码基础，也能把脑子里的想法，或是细致的产品需求，变成有完整使用流程、交互效果出色的多页面项目。<br/>不管是设计师打磨视觉效果、产品经理测试功能逻辑，还是前端开发实现设计和交互，UXbot都能帮上忙。全球的中小企业、创作者，不用懂代码就能快速做出有品牌特色、够专业的线上平台，不管是跨境电商、个人品牌展示，还是服务型企业拓客，都能适配。<br/><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdnGY7" alt="image.png" title="image.png"/></li><li>CodeWP：WordPress生态的AI化主题转化引擎<br/>CodeWP专门针对全球常用的CMS平台WordPress打造，形成了“有设计想法→AI帮忙转化→生成可用主题”的完整流程。它通过学习大量WordPress主题的结构和设计标准，能把用户给的视觉设计稿、创意描述，精准转换成支持多设备适配的WordPress主题，在全球主流浏览器上都能正常显示。<br/>它的优势在于和WordPress生态深度契合，能直接搭配Yoast SEO、WooCommerce这些全球热门插件使用，帮做跨境业务的用户快速搭建符合不同区域搜索引擎规则的网站。但它也有不足：只针对WordPress平台，没法跨其他系统使用，而且设计稿和最终生成的主题，细节上偶尔会有偏差，需要手动微调。<br/><img width="723" height="414" referrerpolicy="no-referrer" src="/img/bVdnGY8" alt="image.png" title="image.png" loading="lazy"/></li><li>10Web：WordPress生态的轻量化智能建站解决方案<br/>10Web主打“AI辅助+快速复刻”，给全球WordPress用户提供轻便的建站服务。靠AI智能识别技术，短短几分钟就能把已有的网站完整复制下来，还能直接迁移到WordPress平台，大大节省了跨境建站的时间和成本。<br/>它自带的AI拖放编辑器，操作简单还能满足专业需求，再加上全球海量正版图片和多语言插件，能适配不同区域品牌的视觉和功能需求。这款工具很适合依赖WordPress、想快速建站的全球用户，但因为只支持这一个平台，部分小众插件可能不兼容，建议提前测试。<br/><img width="723" height="414" referrerpolicy="no-referrer" src="/img/bVdnGY9" alt="image.png" title="image.png" loading="lazy"/></li><li>Unbounce：AI驱动的全球营销型着陆页优化利器<br/>Unbounce是全球营销建站领域的常用工具，核心目标就是提高页面转化率，打造了一套AI驱动的着陆页全流程管理功能。不用懂代码，用户就能通过AI编辑器做出符合全球审美、适配不同区域流量场景的高质量着陆页，内置的100多种行业模板，能覆盖跨境营销、全球活动推广、品牌获客等多种需求。<br/>它的实时AI数据分析功能，能动态跟踪全球访客的行为和转化路径，给出具体的优化建议，还能通过不断学习升级算法，帮全球营销人员提升跨区域流量的转化效果。缺点是高级优化功能不太好上手，新手需要花时间熟悉操作。<br/><img width="723" height="410" referrerpolicy="no-referrer" src="/img/bVdnGZa" alt="image.png" title="image.png" loading="lazy"/></li><li>Hostinger：一体化AI建站与全球主机服务提供商<br/>Hostinger把“AI建站+全球主机运维”整合到一起，是跨境用户的常用选择。它的AI拖放编辑器支持用日常语言生成网站内容、调整页面布局，再加上Cloudflare全球CDN节点，能明显提升全球不同地区的网站访问速度，还能增强安全防护，解决了跨境建站的性能难题。<br/>工具自带的AI文本生成功能，能满足多语言创作需求，帮品牌快速在多个区域搭建线上平台。需要注意的是，它的共享主机没有专用IP，基础套餐的存储空间也比较有限，要根据跨境业务规模选合适的套餐。<br/><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdnGZi" alt="image.png" title="image.png" loading="lazy"/></li><li>Jimdo：Dolphin AI赋能的全球极速建站工具<br/>Jimdo靠自研的Dolphin AI系统，实现了三分钟快速建站，特别适合全球中小企业和个体创作者快速上线网站的需求。AI会自动分析用户的业务类型、品牌偏好和目标受众，生成专属网站方案，还能自动优化多设备适配，确保全球用户在手机、电脑等不同终端上，都能有一致的使用体验。<br/>它的简易电商模块，能快速搭建跨境线上店铺，完成商品上架、订单管理、支付对接等核心操作，流程简单易懂，对新手十分友好。但它的设计自由度不如专业工具，没法满足高端品牌的深度定制需求。<br/><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdnGZm" alt="image.png" title="image.png" loading="lazy"/></li><li>Framer：AI驱动的全场景Web应用设计开发平台<br/>Framer是全球AI建站领域的创新工具，靠先进的AI设计预测功能，能覆盖从简单品牌主页到复杂跨境Web应用的各种需求。它的优势是AI会实时给设计建议，帮用户做出符合全球审美趋势的页面，还能轻松添加悬停效果、多语言滑块、跨境表单等交互元素，提升全球用户的访问体验。<br/>它打通了设计和开发的全流程，做好的网站能直接对接全球服务器部署，适配不同区域的技术环境。不过丰富的AI功能对新手有一定难度，部分交互元素在不同浏览器上的显示效果也略有差异，需要留意。<br/><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdnGZn" alt="image.png" title="image.png" loading="lazy"/></li><li>Shopify：<br/>AI赋能的全球电商建站生态平台Shopify专注于全球电商场景，用AI技术优化了跨境电商的建站和运营方式，是行业内的标杆工具。它的AI功能能预测购物趋势、分析全球访客行为、自动处理多区域运营任务，给跨境商家提供数据支持，帮助做决策。用户能快速搭建有品牌感的跨境电商网站，配置专属全球域名，内置的AI智能客服还能支持多语言咨询，实时解答客户疑问、引导下单，提升全球用户的购物体验。平台生态完善，能对接全球主流支付渠道和物流服务商，帮商家快速布局全球市场。但高级AI运营功能比较复杂，中小商家需要慢慢摸索，前期学习成本不低。<br/><img width="723" height="412" referrerpolicy="no-referrer" src="/img/bVdnGZs" alt="image.png" title="image.png" loading="lazy"/></li></ol><p>二、全球场景选型指南<br/>以上8款工具覆盖了全球建站的各种场景，能精准匹配不同用户的需求：不懂技术、想快速落地跨境业务的创业者，优先选UXbot、Jimdo，零代码就能做出适配全球的网站；习惯用WordPress的跨境用户，CodeWP、10Web最适配，兼顾生态兼容性和建站效率；做跨境电商的商家，Shopify的全流程AI电商功能能满足全球运营需求；专注跨区域营销获客的，Unbounce的转化率优化功能很实用；追求专业设计与开发一体化的中高端用户，Framer的全场景适配能力更强；需要同时解决主机和建站问题的跨境用户，选Hostinger更省心高效。<br/>在全球数字化转型的关键时期，AI建站工具已经成为品牌拓展全球市场的重要助力。选对适合自己业务、能适配全球场景的工具，既能大幅降低建站成本，又能提升线上平台的专业质感，为全球业务发展筑牢基础。</p>]]></description></item><item>    <title><![CDATA[六款AI网站搭建工具全景解析：重构设计生产力闭环 UXbot ]]></title>    <link>https://segmentfault.com/a/1190000047553482</link>    <guid>https://segmentfault.com/a/1190000047553482</guid>    <pubDate>2026-01-20 15:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在Web界面设计领域，从创意构想到可交付原型的全链路，往往要经历繁琐流程，迭代速度慢，严重影响团队效率。而AI设计工具的不断升级，不仅支持智能生成可编辑的UI界面、快速搭建带交互的原型，还支持灵活迭代，大幅提升设计效率。下面就为大家梳理六款兼顾实用性与专业性的AI设计工具，帮助设计创意更快落地、创造价值。</p><ol><li>UXbot<br/>核心定位：国内AI原型设计的实用标杆工具，能打通“文字提需求-高保真原型-界面设计-Web前端开发”全环节，实现一站式智能协作。<br/>UXbot能精准理解文字需求、拆解业务逻辑，不管是网站、移动应用还是平板端界面，都能直接生成高保真设计稿，不用人工搭建基础框架。同时还能自动生成可视化PRD，不用再分开做设计和写文档，解决了两者脱节的问题，大大减少重复工作量。生成的界面还能直接设置复杂交互和页面跳转，完整还原用户使用流程。<br/>它有两种编辑方式可选：既能通过AI对话微调局部设计，也能用自带的专业编辑器精细化打磨，不管是快速验证想法，还是深度优化设计，都能满足需求，精准度能达到像素级控制。<br/>另外，还支持把高保真界面转换成Web前端代码，通过云端服务器完成全流程测试，生成的代码可导出为Vue格式，直接导入开发环境使用。<br/>这套“需求-设计-交互-开发”的完整流程，能帮中文语境下的产品和设计团队，高效推进网站开发落地。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdnCJg" alt="image.png" title="image.png"/></li><li>Galileo AI<br/>核心定位：主打视觉美感的高保真UI生成工具，适合探索设计风格、制作视觉原型。<br/>Galileo AI的视觉渲染效果很出色，生成的界面既美观又有细节，用来做情绪板、快速尝试不同设计风格非常合适。设计好的内容可以直接同步到Figma里，进行可无限放大不失真的编辑，方便进一步优化打磨，精准落地设计想法。<br/>不过它也有不足：对中文指令的理解不够准，处理复杂业务逻辑时不如UXbot好用。所以更适合以视觉设计为主、常用英文指令的场景，要是涉及复杂中文需求或业务流程，还需要人工调整校准。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdnGZF" alt="image.png" title="image.png" loading="lazy"/></li><li>Uizard<br/>核心定位：能把手绘创意转成数字界面的工具，降低非设计人员做原型的门槛。<br/>Uizard最核心的功能就是识别手绘草图，把纸上的创意快速数字化。只要拍下手绘稿上传，AI就能自动识别按钮、输入框、图片等元素，生成可编辑的数字UI界面。工具操作特别简单，不用具备专业设计技能，就能把白板上的想法落地成原型，很适合创业者、跨部门团队在需求评审后，快速验证创意是否可行。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdnGZK" alt="image.png" title="image.png" loading="lazy"/></li><li>Relume<br/>核心定位：专注网页结构设计的AI工具，擅长快速搭建营销官网和SaaS产品着陆页。<br/>Relume做网页设计时，会先理清逻辑再动手：根据需求生成站点地图，梳理好网页层级和信息排布，再用海量Web组件拼装线框图，既能保证页面逻辑清晰，又能兼顾视觉统一。上千种组件可灵活组合，既不耽误设计效率，又能保留创意空间，能快速做出实用又美观的网页原型，为后续优化打下基础。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdnGZL" alt="image.png" title="image.png" loading="lazy"/></li><li>Vev AI<br/>核心定位：融合可视化编辑与AI生成功能的全流程网页工具，打通设计与开发的衔接瓶颈。<br/>只要用文字描述需求，Vev AI就能生成分图层、可编辑的网页界面，还自带基础交互效果，能快速验证用户体验。平台内置可视化编辑模块，可精准调整设计细节，同时支持一键导出HTML/CSS代码，直接交付开发使用，大幅缩短设计到开发的转化时间，很适合网页设计与前端开发协同工作的场景。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdnGZM" alt="image.png" title="image.png" loading="lazy"/></li><li>Framer AI<br/>核心定位：践行“设计即代码”理念，能把设计稿快速转成可访问的网页。<br/>Framer AI的代码生成能力很强，可直接把UI设计元素转换成HTML、CSS或React组件，让设计和开发无缝衔接。同时支持制作高保真动效和微交互，设计时就能预览实际呈现效果，让网页体验更生动。设计完成后，还能直接发布成可访问的网页链接，跳过中间转化步骤，加快产品上线速度，适合以前端开发为核心的高效落地项目。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdnGZN" alt="image.png" title="image.png" loading="lazy"/></li></ol><p>工具选型战略指南<br/>上述六款工具覆盖了手绘转数字、视觉设计、代码输出等全场景设计需求，能满足不同团队的多样化需求。如果团队侧重中文语境下的全流程高效落地，想从文字需求直接做出可交付的交互原型，还能同步生成设计和产品资料，UXbot会是最优选择，它能打通全流程环节，帮团队高效实现从创意到落地的转化。</p>]]></description></item><item>    <title><![CDATA[Cyber Triage 3.16 发布 - 面向事件响应的数字取证软件 sysin ]]></title>    <link>https://segmentfault.com/a/1190000047552722</link>    <guid>https://segmentfault.com/a/1190000047552722</guid>    <pubDate>2026-01-20 14:07:44</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>Cyber Triage 3.16 发布 - 通过 Cyber Triage Enterprise 更快开展调查</p><p>Cyber Triage 3.16 for Windows - 面向事件响应的数字取证软件</p><p>Digital Forensics Specialized For Incident Response</p><p>请访问原文链接：<a href="https://link.segmentfault.com/?enc=YdbcgQeihCZEOavRqRKI9Q%3D%3D.pP4RtRHGrqgbWIbdCNvUbFJN3EZV8PT8NjGphVCUc71N%2B%2BNm%2BkxQjHF9YwDCNBfv" rel="nofollow" target="_blank">https://sysin.org/blog/cybertriage-3/</a> 查看最新版。原创作品，转载请保留出处。</p><p>作者主页：<a href="https://link.segmentfault.com/?enc=wthYfKaEdbWAGIvHsX8G%2Bg%3D%3D.Xe0YxlnHyQkDWyiP3Wueracts57XxHmrCPVkBTOe3YM%3D" rel="nofollow" target="_blank">sysin.org</a></p><hr/><p><strong>唯一专门用于事件响应的数字取证工具</strong><br/>快速、准确和简单地完成入侵调查</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047552724" alt="sysin" title="sysin"/></p><p>Cyber Triage 是一款自动化的数字取证与事件响应（DFIR）软件，旨在帮助安全运营中心（SOCs）、托管安全服务提供商（MSSPs）、顾问和执法机构快速调查网络入侵事件，如恶意软件、勒索软件和账户接管等。</p><h2>新增功能</h2><p>2026 年 1 月 15 日</p><p>快速访问和分析数据对于高效调查至关重要，但 SOC 分析师和 IR 团队往往在这两件事上浪费大量时间。Cyber Triage 的 3.16 版本引入了 <strong>Enterprise（企业级）层级</strong>，使调查人员能够更快速地访问并利用 SOC 中已有的数据。</p><h3>调查需要数据</h3><p>所有调查，无论是 SOC 分析师对单一主机进行初步研判，还是 DFIR 团队同时分析 30 台主机，都依赖于访问能够显示攻击者行为的数据。</p><p>调查人员面临 <strong>两个问题：</strong></p><ol><li>访问现有数据孤岛中的数据。</li><li>在海量数据中分析并找到极小一部分关键证据。</li></ol><p>SOC 需要访问的数据来源 <strong>包括但不限于：</strong></p><ul><li>终端取证工件</li><li>EDR 遥测数据</li><li>SIEM 系统</li></ul><p>调查人员往往难以将这些数据访问并整合到一个统一位置 (sysin)，并从 99.99% 的异常活动中识别出那 0.01% 的真正证据。</p><h3>调查平台</h3><p>为了解决数据访问和分析问题，团队会使用 <strong>调查平台</strong>，以确保调查过程快速且全面。</p><p><strong>一个调查平台将：</strong></p><ul><li>从多种数据源导入数据；</li><li>分析数据并突出显示恶意和可疑工件；</li><li>提供建议，确保线索不会被遗漏；</li><li>以报告或其他结构化数据形式发布结果。</li></ul><p>Cyber Triage Enterprise 就是一个 <strong>调查平台</strong>。它确保所有数据都被纳入考量，并避免你手动审查海量数据所造成的时间浪费。</p><p>它通过将 Cyber Triage 集成到你现有的 SOC 基础设施中来实现这一点。</p><h3>Enterprise 集成 Cyber Triage</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047552725" alt="Cyber Triage Enterprise 架构。" title="Cyber Triage Enterprise 架构。" loading="lazy"/></p><p><em>Enterprise 层级将 Cyber Triage 集成到 SOC 的安全技术栈中。</em></p><p>Cyber Triage 的 Enterprise 层级包含所有可加速调查的标准功能，<strong>并额外提供：</strong></p><ul><li><strong>导入遥测数据</strong>：你可以将 EDR 遥测数据加入调查中，并由 Cyber Triage 对其进行评分，以识别恶意和可疑行为。EDR 本身并不擅长发现诸如 “利用系统自带工具（living off the land）” 之类的可疑活动。该功能可显著加快调查速度 (sysin)。</li><li><strong>发布结果</strong>：你可以将最终结果导出到案件管理系统或威胁情报平台，使 IOC 得以集中用于报告。这可以减少将调查发现记录到正式系统中的人为错误。</li><li><strong>连接威胁情报</strong>（即将推出）：你可以连接威胁情报系统，使 Cyber Triage 的评分能够使用你从其他情报源收集的 IOC，确保调查结果充分利用你现有的威胁情报投入。</li></ul><p>通过 Enterprise，这些功能可添加到 <strong>以下两种版本中：</strong></p><ul><li><strong>Standard Pro</strong>：Cyber Triage 的单用户桌面版本。Standard Pro 的 Enterprise 层级称为 <strong>Standard Enterprise</strong>。</li><li><strong>Team</strong>：Cyber Triage 的多用户、自托管服务器版本。Team 的 Enterprise 层级称为 <strong>Team Enterprise</strong>。</li></ul><p>Enterprise 层级还为 Team 服务器增加了访问控制功能，使你可以限制不同调查人员对不同数据的访问权限。</p><h2>下载地址</h2><p><strong>Cyber Triage 3.16</strong>: Investigate Faster with Cyber Triage Enterprise</p><p>January 15, 2026</p><ul><li>请访问：<a href="https://link.segmentfault.com/?enc=SG82MZLtaAqyiqWtj9GRFw%3D%3D.28vRduhs6jdfszuEd9%2Flb8nVmmAMtZZL3egc5hvvDggQAEFyFijsxtNcM0iUGv6b" rel="nofollow" target="_blank">https://sysin.org/blog/cybertriage-3/</a></li></ul><p>更多：<a href="https://link.segmentfault.com/?enc=%2BcKeRvUceVjYZB%2Fq4%2B4%2FUQ%3D%3D.qqGDDVC1SmtRHd9yoBHVqfd3d1NbUTzsrgQtyOJE6rA%3D" rel="nofollow" target="_blank">HTTP 协议与安全</a></p>]]></description></item><item>    <title><![CDATA[Acunetix v25.12 发布，新增功能简介 sysin ]]></title>    <link>https://segmentfault.com/a/1190000047552772</link>    <guid>https://segmentfault.com/a/1190000047552772</guid>    <pubDate>2026-01-20 14:06:44</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>Acunetix v25.12 (Linux, Windows) - Web 应用程序安全测试</p><p>Acunetix | Web Application Security Scanner</p><p>请访问原文链接：<a href="https://link.segmentfault.com/?enc=40qy%2FclJY%2BPhUZAcEyOgDA%3D%3D.L15flXfid%2FAzEpAliM%2B1Y%2BrbaxTgoj0gTCkgINM03nIYc37MwLUx8dsiI2AWwdeK" rel="nofollow" target="_blank">https://sysin.org/blog/acunetix/</a> 查看最新版。原创作品，转载请保留出处。</p><p>作者主页：<a href="https://link.segmentfault.com/?enc=JjQwVGf%2FAuYX6Jxp7eMkdA%3D%3D.qzOE4k77GhELLpXpZubw3DCwgikIFzmlmPSxWc7pS7k%3D" rel="nofollow" target="_blank">sysin.org</a></p><hr/><p><img referrerpolicy="no-referrer" src="/img/remote/1460000044933075" alt="Acunetix Logo" title="Acunetix Logo"/></p><p>Acunetix 漏洞扫描器，管理您的网络安全。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000046100493" alt="Find the vulnerabilities" title="Find the vulnerabilities" loading="lazy"/></p><h2>使用 Acunetix 提高您的 Web 应用程序安全性</h2><p>Acunetix 不仅仅是一个网络漏洞扫描器。它是一个完整的 Web  应用程序安全测试解决方案，既可以独立使用，也可以作为复杂环境的一部分使用。它提供内置的 漏洞评估 和  漏洞管理，以及与市场领先的软件开发工具集成的许多选项 (sysin)。通过将 Acunetix  作为您的安全措施之一，您可以显着提高您的网络安全立场，并以较低的资源成本消除许多安全风险。</p><p><strong> </strong>自动化和集成您的漏洞管理**</p><p>为了节省资源、简化修复并避免后期修补，企业通常旨在将 Web 漏洞测试作为其 SecDevOps 流程的一部分。Acunetix 是 DAST 的用于此类目的最佳工具之一，因为它在物理和虚拟环境中都具有效率。</p><ul><li>Acunetix 集成设计得非常简单 (抄si袭quan者jia)。例如，您即可将 Acunetix 扫描集成到 <strong>CI/CD</strong> 与 Jenkins 等工具中只需几步。</li><li>为了有效管理漏洞，您还可以使用第三方<strong>问题跟踪器</strong>，例如 Jira、GitLab、GitHub、TFS、Bugzilla 和 Mantis。对于某些问题跟踪器，Acunetix 还提供双向集成，其中问题跟踪器可能会根据问题状态自动触发其他扫描。</li><li>Acunetix 提供自己的 <strong>API</strong>，您可以使用它连接到第三方或内部开发的其他安全控制和软件。对于企业客户，Acunetix 技术专家将帮助您将工具集成到非典型环境中。</li></ul><p><strong> </strong>信任最成熟最快的漏洞扫描工具**</p><p>Acunetix 是市场上第一款自 2005 年以来不断改进的 Web 安全扫描程序。它是由 Web 安全测试专家开发的高度成熟的专业工具。这种专业化使得构建比许多捆绑工具更有效的解决方案成为可能。</p><ul><li>Acunetix 漏洞扫描引擎是用 C++ 编写的，使其成为 市场上最快的 Web 安全工具之一。这在扫描使用大量 JavaScript 代码的复杂 Web 应用程序时尤为重要。Acunetix 还使用了独特的扫描算法 - SmartScan，您通常可以在扫描的前 20% 中找到 80% 的漏洞。</li><li>速度符合非常高的漏洞发现效率。Acunetix 还以其极低的误报率而闻名 (sysin)，这有助于您在渗透测试期间进一步节省资源，并使您的分析师专注于新漏洞。Acunetix 还提供了许多漏洞的利用证明。</li><li>为了提高扫描效率，您可以使用<strong>多个</strong>本地部署的扫描引擎。引擎可以与 Acunetix 本地和云版本一起使用。</li></ul><p><strong> </strong>获得附加价值，包括网络安全**</p><p>Acunetix 有适合不同客户需求的版本。它可以本地部署在 Linux、macOS 和 Microsoft Windows 操作系统上。您还可以将其用作云产品来节省您的本地资源。</p><ul><li>除了 Web 应用程序漏洞（例如 SQL 注入和 跨站点脚本 (XSS)）之外，Acunetix 还可以帮助您发现<strong>其他</strong>安全威胁。这包括 Web 服务器配置问题或错误配置、未受保护的资产 (sysin)、恶意软件和 OWASP Top 10 中列出的其他安全威胁。</li><li>为了保护您的关键资产，您可以将独特的 AcuSensor IAST 技术用于 PHP、Java 或 .NET。该技术可以更轻松地查明安全漏洞的原因，从而帮助您进行补救。</li><li>Acunetix 与 OpenVAS 开源工具集成。此网络安全扫描器可帮助您扫描 IP 地址范围以发现特定于网络设备的开放端口和其他安全漏洞。您可以使用单个仪表板一起处理 Web 和网络漏洞。</li></ul><h2>新增功能</h2><p>2025 年 12 月 8 日，<strong>Acunetix Premium - 版本 25.12</strong></p><p><strong>安全检查</strong>：</p><ul><li><p>为 Next.js / React Server Components 的 RCE 实现安全检查：</p><ul><li><a href="https://link.segmentfault.com/?enc=E4swiibH6RE%2B5RFrSrdfWQ%3D%3D.rVzKeYo%2F2hvVcLovSn1A4QH%2FlaogECAytqXl9%2B8DfI6uCSoK44gEfl7G3xokYudv" rel="nofollow" target="_blank">CVE-2025-66478</a></li><li><a href="https://link.segmentfault.com/?enc=ETetgTc2jnWNgp79aN3oEg%3D%3D.8iyvz%2Fvox0gTe09xRmecnzQ5SCbzK1puYtKB%2FbRIL%2BqctZvwKb56VZ3uzpNHM7yU" rel="nofollow" target="_blank">CVE-2025-55182</a></li></ul></li></ul><h2>下载地址</h2><p>想要开始学习和研究？</p><ul><li>请访问：<a href="https://link.segmentfault.com/?enc=TUycWIgUqNpvwUtla4uN6A%3D%3D.H5nn7VA1D1BRiZzX7oB76reqiKqN2q3VyuNXu0S2wJzDZnGj0ulaTC9wrktGnjcg" rel="nofollow" target="_blank">https://sysin.org/blog/acunetix/</a></li></ul><p>更多相关产品：</p><ul><li><a href="https://link.segmentfault.com/?enc=Mb2elNifrAO9yc5RMcNE7A%3D%3D.TXP%2FE4E6nQal3cwUq%2BXF2yj2oIuRz04YJzH2PsPBHQ%2FOqzGEfe6yCU%2FoqhiTyEwz1JqvQ6XuZf3CtZpNb1K6UQ%3D%3D" rel="nofollow" target="_blank">Magic Quadrant for Application Security Testing 2022</a></li><li><a href="https://link.segmentfault.com/?enc=7PXhyqRDFljwTNeqSbNKVA%3D%3D.7BxTVJhi4frDzOp1Vs%2BoZemNXe12msVrhCYowdeQPNyBJTPfYRo6ejk4ojPs3yM20KEJhtQmMaAmKfJ9d2wSyA%3D%3D" rel="nofollow" target="_blank">Magic Quadrant for Application Security Testing 2023</a></li></ul><p>更多：<a href="https://link.segmentfault.com/?enc=8yVc%2F1VwyHjf%2B5A7561kNw%3D%3D.U0UJdLtH6fnL9MAmJF9HUGgEDneNeRov8mCXxeCg1PI%3D" rel="nofollow" target="_blank">HTTP 协议与安全</a></p>]]></description></item><item>    <title><![CDATA[2025 年 CSS 年度调查报告亮点速览 冴羽 ]]></title>    <link>https://segmentfault.com/a/1190000047552871</link>    <guid>https://segmentfault.com/a/1190000047552871</guid>    <pubDate>2026-01-20 14:06:01</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>近日，「State of CSS 2025」年度调查报告公布。</p><p>这份报告收集了全球数万名开发者的真实使用经验和反馈，堪称是 Web 开发领域的“年度风向标”。</p><p>本篇我们盘点下这份报告的亮点部分。</p><h2>1. 使用率最高的功能是 :has()</h2><p><strong>在调查的所有功能中，</strong><code>**:has()**</code><strong>是使用率最高也是最受欢迎的功能。</strong></p><p>想必大家已经很熟悉了，它是一个功能非常强大的伪类，可以实现类似“父选择器”和“前面兄弟选择器”的功能。</p><p>举个简单的例子，下面的 CSS 代码表示如果 <code>&lt;a&gt;</code> 元素里面有 <code>&lt;img&gt;</code> 元素，则这个 <code>&lt;a&gt;</code> 元素就会匹配。</p><pre><code class="css">:has(img) {
  display: block;
}</code></pre><p>我们可以使用这个选择器轻松区分是文字链接还是图像链接，并设置不同的 CSS 样式。</p><h2>2. 使用率第二高的功能是 aspect-ratio</h2><p>这个 CSS 属性允许你定义元素盒子的宽高比。</p><p>这意味着即使父容器或视口大小发生变化，浏览器也会调整元素的尺寸以保持指定的宽高比。</p><p>比如我们将一张图片设置为 3/2 宽高比：</p><pre><code class="css">img {
  aspect-ratio: 3/2;
}</code></pre><h2>3. 使用率最低的是 sibling-count 和 sibling-index</h2><p>记得以前实现列表项交错动画时，要手动给每个元素设置不同的延迟吗？</p><p>现在，用 <code>sibling-index()</code> 一行代码就能搞定！</p><pre><code class="css">li {
  transition: opacity 0.3s ease;
  transition-delay: calc((sibling-index() - 1) * 100ms);
}</code></pre><p>这个函数会自动获取元素在兄弟节点中的位置（从 1 开始计数），通过简单的计算就能实现<strong>流畅的交错动画效果</strong>。</p><p>如果再搭配 <code>@starting-style</code>，连入场动画都能轻松搞定：</p><pre><code class="css">li {
  transition: opacity 0.3s ease;
  transition-delay: calc((sibling-index() - 1) * 100ms);

  @starting-style {
    opacity: 0;
  }
}</code></pre><p><a href="https://codepen.io/argyleink/pen/KwKXPYW" target="_blank">实现效果如下：</a></p><p>&lt;!-- 这是一张图片，ocr 内容为：STAGGERING JUST GOT ALOT EASIER --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047552873" alt="" title=""/></p><p>之所以使用率最低，可以理解，因为浏览器支持还比较新。</p><h2>4. 受欢迎程度第二高的功能是 Subgrid</h2><p>Subgrid 表示子网格，它并不是一个 CSS 属性，而是 grid-template-columns 和 grid-template-rows 属性支持的关键字，其使用的场景需要外面已经有个 Grid 布局。</p><p>什么时候会用到 Subgrid 呢？</p><p>举个例子，这是一个布局效果：</p><p>&lt;!-- 这是一张图片，ocr 内容为：INTERMEDIATE LENGTHY MIDDLING IT'S...SHORT DRAWN-OUT TALL MODERATE TITLE PROTRACTED AND THE WORDS IN THIS EXTENDED TITLE EXAMPLE ARE AND BRIEF. LRONICALLY SHORT TOLERABLE,PASSABLE AMOUNT OF CONTENT. AND FAIR,BUT DO TRY IT DRAW OUT A BIT. CHECK IT OUT FOOTER ACTION --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047552874" alt="" title="" loading="lazy"/></p><p>你会发现，标题字数不一样，内容字数不一样，导致底部很难对齐。</p><p>然而我们想要的效果是这样的：</p><p>&lt;!-- 这是一张图片，ocr 内容为：LENGTHY INTERMEDIATE IT'S.......SHORT MIDDLING DRAWN-OUT TALL MODERATE TITLE PROTRACTED AND EXTENDEDTITLE IRONICALLY SHORT THE WORDS IN THIS AND BRIEF. EXAMPLE ARE AMOUNT OF CONTENT. TOLERABLE,PASSABLE AND FAIR,BUT DO DRAW OUT A BIT. CHECK IT OUT TRY IT FOOTER ACTION --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047552875" alt="" title="" loading="lazy"/></p><p>此时就可以用到 Subgrid，使用示例如下：</p><pre><code class="css">.wrapper {
  display: grid;
  grid-template-columns: 1fr 1fr;
}

.item {
  grid-row: 1 / 4;
  display: grid;
  grid-template-rows: subgrid;
}</code></pre><h2>5. 认知度增长最高的是 light-dark()</h2><p>不知道你是否实现过网站的浅色和深色主题：</p><pre><code class="css">:root {
  /* 默认浅色主题 */
  --text-heading: #000;
  --text-body: #212121;
  --surface: #efefef;

  @media (prefers-color-scheme: dark) {
    /* 暗色主题 - 第一遍 */
    --text-heading: #fff;
    --text-body: #efefef;
    --surface: #212121;
  }
}

.dark-theme {
  /* 暗色主题 - 又写一遍！ */
  --text-heading: #fff;
  --text-body: #efefef;
  --surface: #212121;
}</code></pre><p>同样的颜色写两遍，一个给媒体查询（自动切换），一个给切换按钮。</p><p>改一次要改两个地方，烦死了！</p><p>现在使用 <code>light-dark()</code> 轻松实现！</p><pre><code class="css">:root {
  /* 跟随系统偏好 */
  color-scheme: light dark;

  /* 一次定义，自动切换 */
  --text-heading: light-dark(#000, #fff);
  --text-body: light-dark(#212121, #efefef);
  --surface: light-dark(#efefef, #212121);
}</code></pre><p>就这么简单！系统是浅色就用第一个，暗色就用第二个。</p><h2>6. 评论最多的功能是 line-clamp，多是负面评价</h2><p>CSS 属性 line-clamp 用于将容器的内容限制为指定的行数，也就是我们常实现的内容多时显示省略号的效果。</p><p>举个例子：</p><pre><code class="css">p {
  width: 300px;
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-line-clamp: 2;
  overflow: hidden;
}</code></pre><p>效果如下：</p><p>&lt;!-- 这是一张图片，ocr 内容为：在此示例中,-WEBKIT-LINE-CLAMP属性设 置为2,即文本在超过两行后将被截断... --&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047552876" alt="" title="" loading="lazy"/></p><p>之所以被大家吐槽，多是因为技术局限性问题，比如：</p><ul><li>能限制行数，无法精确控制高度</li><li>浏览器兼容性还不够好</li><li>与动态内容配合困难：当文本内容长度不确定时，难以准确控制显示效果</li></ul><p>当我们实际使用 line-clamp 的时候，还要配合一系列属性比如 display、-webkit-box-orient、overflow、text-overflow，这种组合方案既复杂又不够语义化。</p><h2>7. 结论</h2><p>CSS 这些年无疑在快速的发展中，而人们对 CSS 的满意度也在持续攀升。</p><p>引用报告中的一句话：</p><p><strong>“如果说 2025 年的主题是稳定不可能之事，那么 2026 年或许是实现期待已久的梦想之年。”</strong></p><p>对于热爱 CSS 的人来说，现在正是尝试、学习并参与塑造未来发展方向的最佳时机。</p><p>我是冴羽，10 年笔耕不辍，专注前端领域，更新了 10+ 系列、300+ 篇原创技术文章，翻译过 Svelte、Solid.js、TypeScript 文档，著有小册《Next.js 开发指南》、《Svelte 开发指南》、《Astro 实战指南》。</p><p>欢迎围观我的“<a href="https://link.segmentfault.com/?enc=8s0OXUGAPdHQQZ5FQnFUpg%3D%3D.mNNwc7okOfRCkcvmaKcv6rmswmqhRtpNX%2BVBdbaGZOI%3D" rel="nofollow" target="_blank">网页版朋友圈</a>”，关注我的公众号：<strong>冴羽（或搜索 yayujs）</strong>，每天分享前端知识、AI 干货。</p><p>新的一年，如果你想快速改变自己，欢迎加入我的知识星球：“<a href="https://link.segmentfault.com/?enc=eSj%2BkARJShM9azWAsQLQfw%3D%3D.Gn055m1Tb0fxjOn5Bdk0M7cqTGv6qhU5m8irepyXACIjasu5lvcPkI03u6tenGsX" rel="nofollow" target="_blank">冴羽·前端大佬成长之路</a>”，10 年工作总结、100+ 篇精华主题、70W 字原创内容，带你升级认知、重构生活、建立知识管理系统、通关面试、引领职场。用一年时间，实现十倍成长，一鸣惊人。</p>]]></description></item><item>    <title><![CDATA[深度解析：模块化业务拆解软件如何打通企业战略到执行的“任督二脉”？ Ord1naryLife ]]></title>    <link>https://segmentfault.com/a/1190000047552994</link>    <guid>https://segmentfault.com/a/1190000047552994</guid>    <pubDate>2026-01-20 14:05:31</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在现代知识型组织中，企业的核心竞争力正从“单点突破”向“全流程模块化优化”转移。模块化业务拆解软件不仅是项目结束后的总结文档，更是将复杂的业务过程通过结构化的数据回溯，转化为可量化、可进化的动态智力资产的架构引擎。</p><h3><strong>一、 为什么现代管理必须重视“模块化”拆解？</strong></h3><p>缺乏有效拆解工具的组织往往陷入“经验黑盒”困境：成功无法被精准复制，失败的根源被掩盖在碎片化的信息中。模块化业务拆解软件的核心价值在于：</p><ul><li><strong>消除认知偏误</strong>：通过全量数据的客观还原，确保拆解基于真实发生的业务节点，而非参与者的主观记忆。</li><li><strong>支撑深层根因探究</strong>：支持在拆解过程中下钻子环节，应对长周期、高协作密度的复杂项目评估需求。</li><li><strong>实现效能自动度量</strong>：无需手动统计，各阶段的投入产出比、耗时偏差自动向上级看板聚合，辅助决策。</li><li><strong>拆解成果资产化</strong>：将验证有效的改进动作沉淀为标准化模板，实现跨团队、跨项目的快速经验迁移。</li></ul><h3>---</h3><p><strong>二、 模块化拆解的技术路径：三层评价架构</strong></p><p>构建模块化业务拆解体系需要遵循“过程回溯”与“逻辑重构”的逻辑：</p><ol><li><strong>宏观项目层（Project Context）</strong>：定义拆解的业务边界、最初目标及最终交付全景。</li><li><strong>效能节点层（Performance Nodes）</strong>：将业务链条拆解为关键里程碑，各节点记录当时的决策背景、资源投入与实际产出。</li><li><strong>原子行为层（Atomic Insights）</strong>：拆解的最末端，聚焦于具体动作的得失，具备明确的改进建议和落实跟踪机制。</li></ol><h3>---</h3><p><strong>三、 核心技术实现与算法示例</strong></p><p>模块化业务拆解软件的底层逻辑涉及效能得分算法、异常趋势捕捉及递归式数据回溯。</p><h4><strong>1. 基于加权算法的节点效能自动评分</strong></h4><p>在模块化拆解中，项目的总效能得分由各关键环节的执行质量自动驱动。以下为 JavaScript 实现的效能评分逻辑：</p><p>JavaScript</p><p>/**  <br/> * 根据各环节表现自动计算项目模块化拆解效能得分  <br/> * @param {Object} project 项目拆解对象（包含子任务节点数组）  <br/> * @returns {number} 聚合后的效能综合得分  <br/> */  <br/>function calculateEfficiencyScore(project) {</p><pre><code>// 基准情况：如果是原子行动项，返回其预定目标达成度（0-100）  
if (\!project.subNodes || project.subNodes.length \=== 0) {  
    return project.goalAchievementRate || 0;  
}

// 汇总所有效能节点的加权得分  
const totalWeightedScore \= project.subNodes.reduce((sum, node) \=\&gt; {  
    // 每个节点可根据重要性分配权重  
    const weight \= node.weight || (1 / project.subNodes.length);  
    return sum \+ (calculateEfficiencyScore(node) \* weight);  
}, 0);

// 更新项目的模块化拆解效能显示  
project.finalScore \= Math.round(totalWeightedScore);  
return project.finalScore;  </code></pre><p>}</p><h4><strong>2. Python：效能偏离度的动态分析引擎</strong></h4><p>利用效能模型，自动对比“计划节点”与“实际轨迹”，识别出导致整体效率下降的关键环节：</p><p>Python</p><p>class EfficiencyAuditEngine:</p><pre><code>def \_\_init\_\_(self):  
    \# 预设标准效能库：项目类型 \-\&gt; 预期耗时/资源基准  
    self.benchmarks \= {  
        "Product\_Launch": {  
            "Design": {"time": 48, "resource": 3},  
            "Dev": {"time": 120, "resource": 8},  
            "QA": {"time": 24, "resource": 2}  
        }  
    }

def analyze\_deviation(self, project\_data, project\_type):  
    """对比实际轨迹与基准，识别拆解关键点"""  
    standards \= self.benchmarks.get(project\_type)  
    if not standards:  
        return "未找到匹配的项目效能基准"

    for node, actual in project\_data.items():  
        benchmark \= standards.get(node)  
        if benchmark:  
            time\_deviation \= (actual\['time'\] \- benchmark\['time'\]) / benchmark\['time'\]  
            if time\_deviation \&gt; 0.15:  
                print(f"\[Review Focus\] 节点 '{node}' 存在显著负向偏差: {time\_deviation:.2%}")  
                \# 自动触发根因分析引导  
                self.\_trigger\_root\_cause\_prompt(node)

def \_trigger\_root\_cause\_prompt(self, node\_name):  
    print(f"  \-\&gt; 已生成 '{node\_name}' 环节的 5-Whys 拆解工作单")
</code></pre><h4><strong>3. SQL：跨项目效能瓶颈识别与经验溯源</strong></h4><p>通过递归查询，识别组织中长期存在的“重复性错误”或“低效环节”：</p><p>SQL</p><p>WITH RECURSIVE ReviewHierarchy AS (</p><pre><code>\-- 初始行：选择需要拆解的顶层项目  
SELECT id, project\_name, parent\_id, efficiency\_score, review\_date   
FROM efficiency\_reviews WHERE parent\_id IS NULL  
UNION ALL  
\-- 递归关联各层级子任务的拆解数据  
SELECT r.id, r.project\_name, r.parent\_id, r.efficiency\_score, r.review\_date  
FROM efficiency\_reviews r  
INNER JOIN ReviewHierarchy rh ON r.parent\_id \= rh.id  </code></pre><p>)  <br/>SELECT</p><pre><code>project\_name,   
AVG(efficiency\_score) as avg\_score,  
COUNT(\*) as review\_count  </code></pre><p>FROM ReviewHierarchy  <br/>GROUP BY project\_name  <br/>HAVING avg\_score \&lt; 70 -- 识别效能持续低迷、亟待流程重塑的领域  <br/>ORDER BY avg\_score ASC;</p><h3>---</h3><p><strong>四、 工具分类与选型思路</strong></p><p>在实施模块化业务拆解时，不同架构的工具侧重点有所不同：</p><table><thead><tr><th align="left">工具</th><th align="left">优势亮点</th></tr></thead><tbody><tr><td align="left"><strong>板栗看板</strong></td><td align="left">支持看板式模块化业务拆解管理，可视化流程与状态，便于任务重组与跟踪</td></tr><tr><td align="left"><strong>Monday.com</strong></td><td align="left">强大的工作流与自动化功能，支持构建复杂的模块化业务管理视图</td></tr><tr><td align="left"><strong>Asana</strong></td><td align="left">灵活的项目与任务数据库结构，适合构建结构化的业务拆解知识库</td></tr><tr><td align="left"><strong>Jira</strong></td><td align="left">独特的敏捷看板与问题追踪机制，支持精细化业务模块关联与分析</td></tr><tr><td align="left"><strong>Trello</strong></td><td align="left">专为团队业务协作设计，集成清单、附件和自动化规则功能</td></tr></tbody></table><h3>---</h3><p><strong>五、 实施中的风险控制与管理优化</strong></p><ul><li><strong>防止“形式化拆解”</strong>：如果拆解成了文字游戏，会导致团队抵触。应遵循“拆解为了改进，而非为了问责”的文化导向。</li><li><strong>确保改进闭环同步</strong>：拆解发现的问题必须自动转化为“改进任务”并指派负责人，防止结论被遗忘。</li><li><strong>动态调整评价基准</strong>：随着团队能力的提升，效能拆解的基准值应定期进行重新对标，驱动组织持续进化。</li></ul><h3>---</h3><p><strong>六、 结语</strong></p><p><strong>模块化是组织进化的必经之路。</strong> 模块化业务拆解软件不仅通过技术手段解决了“盲目总结”的问题，更将组织的每一次经历转化为可以指导未来决策的有效资产。当组织的每一次拆解都能以全景的形式精准呈现时，企业才能真正实现从“低效率重复”向“高水平螺旋上升”的本质跨越。</p>]]></description></item><item>    <title><![CDATA[基于YOLOv8的蚊蝇位置智能检测识别项目｜完整源码数据集+PyQt5界面+完整训练流程+开箱即用！]]></title>    <link>https://segmentfault.com/a/1190000047553113</link>    <guid>https://segmentfault.com/a/1190000047553113</guid>    <pubDate>2026-01-20 14:04:58</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>基于YOLOv8的蚊蝇位置智能检测识别项目｜完整源码数据集+PyQt5界面+完整训练流程+开箱即用！</h2><p>源码包含：完整YOLOv8训练代码+数据集(带标注)+权重文件+直接可允许检测的yolo检测程序+直接部署教程/训练教程</p><h3>基本功能演示</h3><p><a href="https://www.bilibili.com/video/BV1zYrhBxEau/" target="_blank">https://www.bilibili.com/video/BV1zYrhBxEau/</a></p><blockquote>源码在哔哩哔哩视频简介处</blockquote><h3>项目摘要</h3><p>本项目基于 <strong>YOLOv8</strong> 深度学习检测模型，结合 <strong>PyQt5</strong> 图形界面，实现了对蚊子和苍蝇的自动检测与定位。项目核心特点包括：</p><ol><li><strong>多输入源支持</strong>：可处理单张图片、图片文件夹、视频文件以及实时摄像头输入。</li><li><strong>高精度识别</strong>：利用定制蚊蝇数据集训练，准确识别蚊子与苍蝇，同时兼顾背景样本，降低误报率。</li><li><strong>开箱即用</strong>：提供完整源码、训练数据、预训练权重及部署教程，用户可直接运行检测系统或继续训练自定义模型。</li><li><strong>可视化界面</strong>：PyQt5 图形界面直观展示检测结果，支持边框显示、类别标注、置信度显示等功能。</li><li><strong>灵活扩展</strong>：项目结构清晰，可快速扩展到其他小型生物检测任务或多分类目标检测场景。</li></ol><p>通过本项目，用户可实现蚊蝇数量监测、位置统计及风险评估，为实验室、公共卫生、农业及城市环境管理提供智能化工具。</p><h3>前言</h3><p>随着智能视觉技术的发展，<strong>小型害虫检测</strong>在公共卫生、农作物管理及环境监测中具有重要意义。传统人工检测方法不仅耗时长、效率低，而且容易漏检或误判。借助 YOLO 系列目标检测算法，本项目提供了一种快速、准确、可扩展的蚊蝇检测解决方案。</p><p>项目基于无人机或固定摄像头拍摄的实验样本，通过训练专用数据集，使模型能够在复杂背景下自动识别蚊子和苍蝇位置。结合 PyQt5 图形界面，用户无需掌握深度学习底层技术即可完成检测、可视化及数据统计。</p><h2>一、软件核心功能介绍及效果演示</h2><h4>核心功能</h4><ol><li><p><strong>图片检测</strong></p><ul><li>支持单张图片检测，自动标注蚊子和苍蝇位置。</li><li>输出标注图与 YOLO 格式检测结果。</li></ul></li><li><p><strong>批量图片处理</strong></p><ul><li>支持文件夹中所有图片的批量检测。</li><li>自动生成检测报告，包括数量统计及置信度分析。</li></ul></li><li><p><strong>视频检测</strong></p><ul><li>支持本地视频文件输入，实时识别视频中的蚊子与苍蝇。</li><li>可选择保存检测后的视频，标注框清晰展示目标。</li></ul></li><li><p><strong>摄像头实时检测</strong></p><ul><li>支持 USB 摄像头或笔记本内置摄像头实时捕捉并检测蚊蝇。</li><li>界面显示实时检测帧，支持帧率与置信度调节。</li></ul></li><li><p><strong>检测结果可视化</strong></p><ul><li>在 PyQt5 界面中显示目标框、类别及置信度。</li><li>支持结果导出，包括图片、视频和 CSV 数据。</li></ul></li><li><p><strong>训练与模型管理</strong></p><ul><li>提供完整训练代码与数据集标注示例。</li><li>可加载自定义权重继续训练或微调模型。</li><li>支持 YOLOv8 标准训练流程，包括训练集划分、超参数配置和结果可视化。</li></ul></li></ol><h4>效果演示</h4><ul><li><p><strong>图片示例</strong>：</p><ul><li>检测后每只蚊子与苍蝇都会被框出，类别和置信度清晰显示。</li></ul></li><li><p><strong>视频示例</strong>：</p><ul><li>视频播放时，模型实时标注移动的目标，统计目标数量并可导出检测数据。</li></ul></li><li><p><strong>实时摄像头示例</strong>：</p><ul><li>界面上可即时显示检测框与数量统计，操作简单，无需命令行操作。</li></ul></li></ul><h2>二、软件效果演示</h2><p>为了直观展示本系统基于 YOLOv8 模型的检测能力，我们设计了多种操作场景，涵盖静态图片、批量图片、视频以及实时摄像头流的检测演示。</p><h3>（1）单图片检测演示</h3><p>用户点击“选择图片”，即可加载本地图像并执行检测：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553115" alt="image-20260112012732195" title="image-20260112012732195"/></p><hr/><h3>（2）多文件夹图片检测演示</h3><p>用户可选择包含多张图像的文件夹，系统会批量检测并生成结果图。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553116" alt="image-20260112012821538" title="image-20260112012821538" loading="lazy"/></p><hr/><h3>（3）视频检测演示</h3><p>支持上传视频文件，系统会逐帧处理并生成目标检测结果，可选保存输出视频：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553117" alt="image-20260112012846148" title="image-20260112012846148" loading="lazy"/></p><hr/><h3>（4）摄像头检测演示</h3><p>实时检测是系统中的核心应用之一，系统可直接调用摄像头进行检测。由于原理和视频检测相同，就不重复演示了。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553118" alt="image-20260112012858804" title="image-20260112012858804" loading="lazy"/></p><hr/><h3>（5）保存图片与视频检测结果</h3><p>用户可通过按钮勾选是否保存检测结果，所有检测图像自动加框标注并保存至指定文件夹，支持后续数据分析与复审。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553119" alt="image-20260112012943268" title="image-20260112012943268" loading="lazy"/></p><h2>三、模型的训练、评估与推理</h2><p>YOLOv8是Ultralytics公司发布的新一代目标检测模型，采用更轻量的架构、更先进的损失函数（如CIoU、TaskAlignedAssigner）与Anchor-Free策略，在COCO等数据集上表现优异。<br/> 其核心优势如下：</p><ul><li>高速推理，适合实时检测任务</li><li>支持Anchor-Free检测</li><li>支持可扩展的Backbone和Neck结构</li><li>原生支持ONNX导出与部署</li></ul><h3>3.1 YOLOv8的基本原理</h3><p>YOLOv8 是 Ultralytics 发布的新一代实时目标检测模型，具备如下优势：</p><ul><li><strong>速度快</strong>：推理速度提升明显；</li><li><strong>准确率高</strong>：支持 Anchor-Free 架构；</li><li><strong>支持分类/检测/分割/姿态多任务</strong>；</li><li>本项目使用 YOLOv8 的 Detection 分支，训练时每类表情均标注为独立目标。</li></ul><p>YOLOv8 由Ultralytics 于 2023 年 1 月 10 日发布，在准确性和速度方面具有尖端性能。在以往YOLO 版本的基础上，YOLOv8 引入了新的功能和优化，使其成为广泛应用中各种物体检测任务的理想选择。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553120" alt="image-20250526165954475" title="image-20250526165954475" loading="lazy"/></p><p>YOLOv8原理图如下：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553121" alt="image-20250526170118103" title="image-20250526170118103" loading="lazy"/></p><h3>3.2 数据集准备与训练</h3><p>采用 YOLO 格式的数据集结构如下：</p><pre><code class="kotlin">dataset/
├── images/
│   ├── train/
│   └── val/
├── labels/
│   ├── train/
│   └── val/</code></pre><p>每张图像有对应的 <code>.txt</code> 文件，内容格式为：</p><pre><code class="bash">4 0.5096721233576642 0.352838390077821 0.3947600423357664 0.31825755058365757</code></pre><p>分类包括（可自定义）：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553122" alt="image-20260112013102185" title="image-20260112013102185" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553123" alt="image-20260112013042045" title="image-20260112013042045" loading="lazy"/></p><h3>3.3. 训练结果评估</h3><p>训练完成后，将在 <code>runs/detect/train</code> 目录生成结果文件，包括：</p><ul><li><code>results.png</code>：损失曲线和 mAP 曲线；</li><li><code>weights/best.pt</code>：最佳模型权重；</li><li><code>confusion_matrix.png</code>：混淆矩阵分析图。</li></ul><blockquote>若 mAP@0.5 达到 90% 以上，即可用于部署。</blockquote><p>在深度学习领域，我们通常通过观察损失函数下降的曲线来评估模型的训练状态。YOLOv8训练过程中，主要包含三种损失：定位损失（box_loss）、分类损失（cls_loss）和动态特征损失（dfl_loss）。训练完成后，相关的训练记录和结果文件会保存在runs/目录下，具体内容如下：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553124" alt="image-20260112013024393" title="image-20260112013024393" loading="lazy"/></p><h3>3.4检测结果识别</h3><p>使用 PyTorch 推理接口加载模型：</p><pre><code class="python">import cv2
from ultralytics import YOLO
import torch
from torch.serialization import safe_globals
from ultralytics.nn.tasks import DetectionModel

# 加入可信模型结构
safe_globals().add(DetectionModel)

# 加载模型并推理
model = YOLO('runs/detect/train/weights/best.pt')
results = model('test.jpg', save=True, conf=0.25)

# 获取保存后的图像路径
# 默认保存到 runs/detect/predict/ 目录
save_path = results[0].save_dir / results[0].path.name

# 使用 OpenCV 加载并显示图像
img = cv2.imread(str(save_path))
cv2.imshow('Detection Result', img)
cv2.waitKey(0)
cv2.destroyAllWindows()
</code></pre><p>预测结果包含类别、置信度、边框坐标等信息。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553125" alt="image-20260112013207795" title="image-20260112013207795" loading="lazy"/></p><h2>四.YOLOV8+YOLOUI完整源码打包</h2><p>本文涉及到的完整全部程序文件：包括<strong>python源码、数据集、训练代码、UI文件、测试图片视频</strong>等（见下图），获取方式见【4.2 完整源码下载】：</p><h3>4.1 项目开箱即用</h3><p>作者已将整个工程打包。包含已训练完成的权重，读者可不用自行训练直接运行检测。</p><p>运行项目只需输入下面命令。</p><pre><code class="bash">python main.py</code></pre><p>读者也可自行配置训练集，或使用打包好的数据集直接训练。</p><p>自行训练项目只需输入下面命令。</p><pre><code class="bash">yolo detect train data=datasets/expression/loopy.yaml model=yolov8n.yaml pretrained=yolov8n.pt epochs=100 batch=16 lr0=0.001</code></pre><h3>4.2 完整源码</h3><p>至项目实录视频下方获取：<a href="https://www.bilibili.com/video/BV1zYrhBxEau/" target="_blank">https://www.bilibili.com/video/BV1zYrhBxEau/</a></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553126" alt="image-20250801135823301" title="image-20250801135823301" loading="lazy"/></p><p>包含：</p><blockquote><p>📦完整项目源码</p><p>📦 预训练模型权重</p><p>🗂️ 数据集地址（含标注脚本）</p></blockquote><h2>总结</h2><p>本项目基于 <strong>YOLOv8</strong> 深度学习检测模型与 <strong>PyQt5</strong> 图形界面，实现了蚊子与苍蝇的高效、智能化检测与定位。通过专用数据集训练，系统能够在复杂背景下准确识别目标，同时提供图片、视频及摄像头多种输入方式。</p><p>项目核心优势包括：</p><ol><li><strong>高精度识别</strong>：模型在小型目标和复杂背景下表现稳定，误报率低。</li><li><strong>多场景适用</strong>：支持单张图片、批量图片、视频和实时摄像头输入。</li><li><strong>可视化与易用性</strong>：界面直观，标注清晰，用户无需深度学习经验即可使用。</li><li><strong>可扩展性</strong>：源码结构清晰，可快速应用于其他小型生物检测任务或扩展目标类别。</li><li><strong>开箱即用</strong>：提供完整训练流程、权重文件和部署教程，用户可直接上手或自定义训练。</li></ol><p>整体而言，本项目为公共卫生监测、实验室研究和环境管理提供了一个 <strong>快速、可靠、可视化的智能检测解决方案</strong>，降低人工检测成本，提高数据收集效率，为小型害虫监控提供了可落地的技术工具。</p>]]></description></item><item>    <title><![CDATA[国密SSL证书是什么？如何申请？ 逼格高的仙人掌 ]]></title>    <link>https://segmentfault.com/a/1190000047553141</link>    <guid>https://segmentfault.com/a/1190000047553141</guid>    <pubDate>2026-01-20 14:04:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h4><strong>一、什么是国密SSL证书？</strong></h4><p>国密SSL证书是<strong>基于中国自主研发的加密算法（SM2算法）</strong>  ，符合国家密码管理局、公安部和工信部的安全标准，旨在提高我国网络通信的安全性和自主可控性。</p><p>它的工作原理与传统SSL证书类似，主要用于<strong>加密网站通信，确保数据在传输过程中不被第三方窃取或篡改</strong>。不同的是，国密SSL证书使用的是<strong>国密算法</strong>，而非传统的RSA或ECC算法。</p><h4><strong>二、国密SSL证书的优势</strong></h4><p><strong>更安全的加密算法</strong></p><p>国密SSL证书采用SM2算法，基于椭圆曲线密码技术，相比RSA具有更高的安全性和计算效率。</p><p>SM3哈希算法替代SHA系列，避免国际算法的安全隐患。</p><p><strong>符合国家政策要求</strong></p><p>国密SSL证书由国家认可的机构颁发，符合国内合规要求，适用于政府、金融、医疗等对数据安全要求较高的行业。</p><p><strong>双证书兼容性</strong></p><p>部分国密SSL证书支持<strong>双算法模式</strong>（国际算法+国密算法），保证兼容传统国际算法的浏览器，同时在国密环境下运行时使用SM2算法，确保系统过渡平稳。</p><h4><strong>三、<a href="https://link.segmentfault.com/?enc=YVowDnIicKOODJjUgC3Jlw%3D%3D.z1n14Dpvx8S1pL4obEwwacrqvqLnUxABLvF2iy7hY%2BMPG9kHtM%2BDweYPb0joIB7iVVlJzSy78REc9IG3UqYG0rm23Znv9eixnK1Z3NojY6CefDlwS8V8ZJtJ8eXg4DZh" rel="nofollow" target="_blank">国密SSL证书的申请流程</a></strong></h4><p>打开<strong>JoySSL</strong>官网，注册时填写注册码<strong>230970</strong>，获取大额优惠跟技术支持。<br/><img width="723" height="395" referrerpolicy="no-referrer" src="/img/bVdneOR" alt="" title=""/></p><h4><strong>1. 确定证书类型</strong></h4><p>根据需求选择合适的国密SSL证书，通常有以下几种类型：</p><ul><li><strong>单域名证书</strong>（适用于单一网站）</li><li><strong>多域名证书</strong>（适用于多个站点）</li><li><strong>通配符证书</strong>（适用于同一主域名下的所有子域名）</li></ul><h4><strong>2. 生成CSR文件</strong></h4><p>CSR（证书签名请求）是申请SSL证书时的必要文件，需要在服务器上生成。生成时，需选择SM2算法，并填写组织信息、域名等相关信息。</p><h4><strong>3. 提交企业认证信息</strong></h4><p>国密SSL证书需要验证申请者的合法身份，通常需要提供：</p><ul><li><strong>企业营业执照或组织机构代码</strong></li><li><strong>域名所有权证明</strong></li><li><strong>联系人信息（电话、邮箱）</strong></li></ul><h4><strong>4. 证书颁发与安装</strong></h4><p>审核通过后，CA机构会签发国密SSL证书，申请者需要将证书安装到服务器上，并配置HTTPS访问。</p><h4><strong>5. 测试与优化</strong></h4><p>安装完成后，建议使用SSL检测工具检查证书是否正确安装，同时优化服务器的SSL/TLS配置，确保安全性和兼容性。</p><h4><strong>四、总结</strong></h4><p>国密SSL证书基于我国自主的加密算法。相比传统SSL证书，国密SSL证书在数据安全性、合规性和国产化兼容性方面具有明显优势。</p><p>申请流程包括<strong>选择证书类型、生成CSR文件、提交企业认证信息、证书签发与安装</strong>等步骤，整体流程与传统SSL证书类似，但需要确保服务器和应用支持国密算法。</p>]]></description></item><item>    <title><![CDATA[【赵渝强老师】Oracle多租户容器数据库 赵渝强老师 ]]></title>    <link>https://segmentfault.com/a/1190000047553155</link>    <guid>https://segmentfault.com/a/1190000047553155</guid>    <pubDate>2026-01-20 14:03:48</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在早期的Oracle数据库的版本中，一般情况下一个数据库服务器只创建一个数据库。当创建的数据库比较多的时候，就需要更多的数据库服务器。这对服务器资源（CPU、内存、存储）来说是一种浪费。从Oracle数据库 12c开始，Oracle数据库引入了多租户特性，即容器数据库。该特性可以在一个数据库服务器上创建容器数据库，并管理多个可插拔数据库。从而降低了成本并提高了服务器资源的利用率。视频讲解如下：<br/><a href="https://www.bilibili.com/video/BV1fXkeBAEh8/?aid=115920110358574&amp;cid=35478572212" target="_blank">https://www.bilibili.com/video/BV1fXkeBAEh8/?aid=115920110358...</a></p><p>Oracle Multitenant Container Database（CDB），即多租户容器数据库是从Oracle 12c引入的一个新的特性。它指的是可以容纳一个或者多个可插拔数据库（Pluggable Database，简称PDB）的数据库，这个特性允许在CDB容器数据库中的体系架构创建并且维护多个数据库。在CDB容器数据库中创建的数据库就是PDB数据库，而每个PDB在CDB中是相互独立存在的。在单独使用PDB时，与普通数据库无任何区别。CDB容器数据库也叫作根数据库，其主要作用就是容纳并管理所有相关的PDB数据库及其元数据。CDB也可以单独使用，从操作使用上看，CDB也与普通数据库无任何区别。下图展示了多租户容器数据库的体系架构。<br/><img width="723" height="264" referrerpolicy="no-referrer" src="/img/bVdnGTQ" alt="image.png" title="image.png"/></p><p>从图中可以看出，Oracle多租户容器数据库的体系架构由三个部分组成，它们分别是：Root、PDB Seed和PDBs。下表详细说明了每一部分的功能和作用。<br/><img width="723" height="414" referrerpolicy="no-referrer" src="/img/bVdnGUe" alt="image.png" title="image.png" loading="lazy"/></p><p>从Oracle数据库 12c R2版本开始,Oracle对多租户容器数据库的功能进行了增强，在CDB root容器中可以创建一个叫做Application Root的容器，可在其内创建多个依赖于Application root的Application PDB。如下图所示。<br/><img width="723" height="381" referrerpolicy="no-referrer" src="/img/bVdnGUf" alt="image.png" title="image.png" loading="lazy"/></p><p>要使用Oracle数据库提供的多租户容器数据库的功能，首先就必须要创建CDB的环境。其本质就是创建CDB的根数据库Root。创建CDB中的根数据库Root可以通过DBCA的图形工具来进行创建，也可以通过执行SQL的脚本来创建。</p><ul><li><strong>使用DBCA创建根数据库Root</strong><br/><img width="723" height="560" referrerpolicy="no-referrer" src="/img/bVdnGUg" alt="image.png" title="image.png" loading="lazy"/></li><li><strong>使用SQL脚本创建根数据库Root</strong></li></ul><pre><code class="sql">SQL&gt; create database cdb2  
      user sys identified by password user system identified by password
      logfile group 1 ('/u01/app/oradata/cdb2/redo1a.log',
                       '/u02/app/oradata/cdb2/redo1b.log') size 100m,
              group 2 ('/u01/app/oradata/cdb2/redo2a.log',
                       '/u02/app/oradata/cdb2/redo2b.log') size 100m 
      character set al32utf8 national character set al16utf16  
      extent management local datafile '/u01/app/oradata/cdb2/system01.dbf' size 325m 
      sysaux datafile '/u01/app/oradata/cdb2/sysaux01.dbf' size 325m 
      default temporary tablespace tempts1 tempfile '/u01/app/oradata/cdb2/temp01.dbf' size 20m 
      undo tablespace undotbs datafile '/u01/app/oradata/cdb2/undotbs01.dbf' size 200m
      enable pluggable database 
      seed   file_name_convert = ('/u01/app/oradata/cdb2',
                                  '/u01/app/oradata/cdb2/seed');</code></pre><p>在成功创建了CDB环境后，就可以进一步基于根数据库Root来创建多个PDB数据库。</p><ul><li><strong>使用DBCA创建PDB</strong><br/><img width="723" height="332" referrerpolicy="no-referrer" src="/img/bVdnGUi" alt="image.png" title="image.png" loading="lazy"/></li><li><strong>使用SQL脚本创建PDB</strong></li></ul><pre><code class="sql">SQL&gt; create pluggable database cdb1pdb3 admin user pdb3sys identified by password 
     file_name_convert= ('/u01/app/oracle/oradata/CDB1/pdbseed',
                         '/u01/app/oracle/oradata/CDB1/cdb1pdb3'); </code></pre>]]></description></item><item>    <title><![CDATA[在线教程丨GLM-Image基于自回归+扩散解码器混合架构，精准理解指令写对文字 超神经HyperA]]></title>    <link>https://segmentfault.com/a/1190000047553182</link>    <guid>https://segmentfault.com/a/1190000047553182</guid>    <pubDate>2026-01-20 14:03:13</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在图像生成领域，扩散模型因其训练稳定和泛化能力强已逐渐走入主流行列。然而，<strong>面对海报、PPT、科普图等需要准确传达复杂信息的「知识密集型」场景时，</strong> <strong>传统模型存在指令理解与细节刻画难以兼顾的短板。</strong> 另一个长期存在的问题是生成图像中的文字经常出现笔画错误或难以辨识，严重影响实用价值。</p><p>基于此，<strong>智谱于 2026 年 1 月联合华为开源了新一代图像生成模型 GLM-Image。</strong> 该模型基于昇腾 Atlas 800T A2 和昇思 MindSpore AI 框架完成全流程训练。<strong>其核心特点是采用了创新的 「自回归+扩散解码器」混合架构（9B 自回归模型 + 7B DiT 解码器），</strong> 将语言模型的深度理解能力与扩散模型的高质量生成能力相结合。</p><p><strong>此外，模型通过改进 Tokenizer 策略，原生支持从1024×1024 到 2048×2048 的任意比例图像生成，无需重新训练。</strong> GLM-Image 的创新性还体现在以下两个方面：</p><p>*<strong>解决文字渲染难题：</strong> 在 CVTG-2K 和 LongText-Bench 权威评测中，其文字准确率等关键指标均位列开源模型第一，显著提升了图像中文字的生成准确性。</p><p>*<strong>定义高性价比应用：</strong> 在 API 调用模式下，生成单张图片的成本仅需 0.1 元，成本仅为主流闭源模型的 1/10 至 1/3，为商业化应用提供了高性价比选择。</p><p>目前，<strong>「GLM-Image 精准语义高保真图像生成模型」已上线 HyperAI 官网（hyper.ai）的教程版块，</strong> 快来输出无限创意吧！</p><p><strong>在线体验：</strong> <strong><em><a href="https://link.segmentfault.com/?enc=RTXmI7X5qhMMa4S5OKyRjw%3D%3D.ZFBNiofNH6Pyd3PhuT6GmhREa4FqcZwZnuxFClDn2vY%3D" rel="nofollow" target="_blank">https://go.hyper.ai/2jcCU</a></em></strong></p><p>效果示例：</p><p><img width="723" height="402" referrerpolicy="no-referrer" src="/img/bVdnGUI" alt="" title=""/></p><p><strong>Demo 运行</strong></p><p>1.进入 hyper.ai 首页后，选择「GLM-Image 精准语义高保真图像生成模型」，或进入「教程」页面选择。页面跳转后，点击「在线运行此教程」。</p><p><img width="723" height="471" referrerpolicy="no-referrer" src="/img/bVdnGUK" alt="" title="" loading="lazy"/><br/><img width="723" height="356" referrerpolicy="no-referrer" src="/img/bVdnGUL" alt="" title="" loading="lazy"/></p><p>2.页面跳转后，点击右上角「克隆」，将该教程克隆至自己的容器中。</p><p>注：页面右上角支持切换语言，目前提供中文及英文两种语言，本教程文章以英文为例进行步骤展示。</p><p><img width="723" height="362" referrerpolicy="no-referrer" src="/img/bVdnGUM" alt="" title="" loading="lazy"/></p><p>3.选择「NVIDIA RTX Pro 6000」以及「PyTorch」镜像，按照需求选择「Pay As You Go（按量付费）」或「Daily Plan/Weekly Plan/Monthly Plan（包日/周/月」，点击「Continue job execution（继续执行）」。</p><p>HyperAI 为新用户准备了注册福利，仅需 $1，即可获得 20 小时 RTX 5090 算力（原价 $7），资源永久有效。</p><p><img width="723" height="456" referrerpolicy="no-referrer" src="/img/bVdnGUP" alt="" title="" loading="lazy"/><br/><img width="723" height="333" referrerpolicy="no-referrer" src="/img/bVdnGUQ" alt="" title="" loading="lazy"/></p><p>4.等待分配资源，当状态变为「Running（运行中）」后，点击「Open Workspace」进入 Jupyter Workspace。</p><p><img width="723" height="359" referrerpolicy="no-referrer" src="/img/bVdnGUR" alt="" title="" loading="lazy"/></p><p><strong>效果演示</strong></p><p>页面跳转后，点击左侧 README 页面，进入后点击上方 Run（运行）。</p><p><img width="723" height="359" referrerpolicy="no-referrer" src="/img/bVdnGUS" alt="" title="" loading="lazy"/><br/><img width="723" height="346" referrerpolicy="no-referrer" src="/img/bVdnGUT" alt="" title="" loading="lazy"/></p><p>待运行完成，即可点击右侧 API 地址跳转至 demo 页面</p><p><img width="723" height="348" referrerpolicy="no-referrer" src="/img/bVdnGUU" alt="" title="" loading="lazy"/><br/><img width="723" height="341" referrerpolicy="no-referrer" src="/img/bVdnGUW" alt="" title="" loading="lazy"/></p><p>以上就是 HyperAI超神经本期推荐的教程，欢迎大家前来体验！</p><p><strong>教程链接：</strong></p><p><strong><em><a href="https://link.segmentfault.com/?enc=vUTph49EOSnxqTjPkOuezQ%3D%3D.LF3odLZkIBOMgL5hks2wm%2B2vmoLbAA4hsfxBh2vChEM%3D" rel="nofollow" target="_blank">https://go.hyper.ai/2jcCU</a></em></strong></p>]]></description></item><item>    <title><![CDATA[掌握核心方法论，打造高质量业务仪表板 观测云 ]]></title>    <link>https://segmentfault.com/a/1190000047553188</link>    <guid>https://segmentfault.com/a/1190000047553188</guid>    <pubDate>2026-01-20 14:02:18</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>前言</h2><p>在数字化运维与业务监控的实践中，仪表板（Dashboard）与汽车的仪表盘同等重要，它不仅是数据可视化的载体，更是团队快速定位问题、洞察数据趋势的核心工具。观测云在平台中内置了大量通用组件、云服务的仪表板模板。但如果你希望从零开始构建个性化的仪表板，又或者对自己绘制的仪表板不够满意，那么这篇文章将教授你几个小技巧，帮助你有效提升仪表板的质量。</p><h2>观测云简介</h2><p>观测云是一个统一实时监测平台，它提供全面的系统可观测性解决方案，帮助用户快速实现对云平台、云原生、应用及业务的监控需求。观测云的核心功能包括：基础设施监测，日志采集和分析，用户访问监测（RUM），应用性能监测（APM），服务可用性监测（拨测），安全监测，智能监控等等。这款产品能够帮助工程师全面了解端到端的用户体验追踪，了解应用服务的每一次调用，以及全面监控云时代的基础设施。此外，观测云还具备快速发现系统安全风险的能力，为数字化时代提供安全保障。更多信息可以访问观测云官网：<a href="https://link.segmentfault.com/?enc=32y0EBWT7Ul9j8fp5k30gQ%3D%3D.9Be1bqEjcrjWPIu%2Fv2zxlDy6PSu%2BlcE9sHzqWLS6pSw%3D" rel="nofollow" target="_blank">https://www.guance.com</a></p><h2>基础仪表板的绘制</h2><p>让我们进入到观测云，创建一个属于您自己的仪表板。首先，你需要找到仪表板的入口「场景」-「仪表板」，点击「新建仪表板」-「新建空白仪表板」。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553190" alt="图片" title="图片"/></p><p>其次，可以从侧滑窗口中选择适合展示数据的图表类型，拖拽到左边的空白画布中。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553191" alt="图片" title="图片" loading="lazy"/></p><p>以常用的「时序图」为例，拖动到画布中即可打开「新建图表」弹窗，此时通过数据筛选控件来选择需要展示的指标。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553192" alt="图片" title="图片" loading="lazy"/></p><p>如图所示，我们已经展示了一条指标曲线，它代表的含义为：指标集为 cpu，指标名为 usage_total，按照 host 进行分组并统计 Avg 平均值，只显示 host=DESKTOP-F9E75IG 的值（过滤条件），点击右下角的保存即可。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553193" alt="图片" title="图片" loading="lazy"/></p><p>此时你已经完成了第一张图表的制作，通过一张张图表的叠加，你很快能得到一个完整的仪表板，不过它看上去有些简陋，我们需要更多技巧对仪表板的美观程度和易读性进行优化。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553194" alt="图片" title="图片" loading="lazy"/></p><h2>仪表板的优化</h2><h3>新增标题和描述</h3><p>恰当的标题能让用户第一时间知道图表展示的指标及其含义，而图表的描述能够起到有效补充说明。我个人的习惯是将图表名设置为指标的英文名，然后在「描述」中补充该指标的中文含义。如下所示：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553195" alt="图片" title="图片" loading="lazy"/></p><p>保存生效的效果如下，图表左上角将展示标题，而鼠标 hover 到帮助按钮上则会悬浮显示描述。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553196" alt="图片" title="图片" loading="lazy"/></p><h3>数据单位</h3><p>一部分指标在采集到观测云后没有单位，因此在绘制仪表板时需要注意补充单位。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553197" alt="图片" title="图片" loading="lazy"/></p><h3>别名</h3><p>图表的曲线会显示对象的名称，并且对象名称会随着分组条件的增多而变得复杂。例如下图，由于添加了 namespace，pod_name 等多个分组条件，对象名称显得很长，很不直观。好在我们可以通过配置「别名」来简化对象名称的显示。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553198" alt="图片" title="图片" loading="lazy"/></p><p>在图表配置的「别名」处，我们选择对应的指标序列，并用 {{}} 将分组条件包起来作为变量，例如下图中的分组条件 pod_name 就写为 {{pod_name}} ，效果如下所示。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553199" alt="图片" title="图片" loading="lazy"/></p><p>我们也支持用多个变量作为别名，写法为 {{分组条件1}}-{{分组条件2}} ，例如 {{namespace}}--{{pod_name}} ，效果如下图所示：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553200" alt="图片" title="图片" loading="lazy"/></p><p>现在，曲线上显示的对象名称已经比原始的名称简洁、清晰了很多。</p><h3>图例</h3><p>图表默认没有带上图例，除非将鼠标 hover 上去，否则无法看到什么颜色的曲线代表哪一个对象，如下图的左侧所示。而「图例」则可以将对象的名称和统计值显示到图表中，如下图的右侧所示。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553201" alt="图片" title="图片" loading="lazy"/></p><p>添加图例的方式如下，可选择将图例放置在图表的底部或者右侧，并显示单个或者统计值，将 Avg、Max、Last 一起显示出来是个不错的选择。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553202" alt="图片" title="图片" loading="lazy"/></p><h3>分组</h3><p>当仪表板中需要展示很多张图表时，使用「分组」来将不同含义的图表分门别类地归类就十分有必要了，这会让仪表板的显示更具有条理，用户能通过分组快速找到自己关注的图表，如下图所示。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553203" alt="图片" title="图片" loading="lazy"/></p><p>给仪表板添加分组时，只需要在侧滑菜单中找到「分组」这个图表类型，拖动到左侧画布即可。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553204" alt="图片" title="图片" loading="lazy"/></p><p>取一个有意义的分组名称，选择一个与众不同的颜色，保存即可。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553205" alt="图片" title="图片" loading="lazy"/></p><p>下图即为新创建的分组，后续添加的图表即可拖动到该分组下。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553206" alt="图片" title="图片" loading="lazy"/></p><h3>锁定时间</h3><p>如果你希望每次进入到仪表板，都查看到固定时间区间（例如最近1天）的数据，应该如何实现呢？</p><p>我们很容易注意到仪表板的时间控件，可以在这里固定整个仪表板的时间。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553207" alt="图片" title="图片" loading="lazy"/></p><p>如果需要将单个图表的时间进行固定，而其他图表的时间则跟随仪表板的时间控件，也很好实现。我们进入单个图表的编辑窗口，打开「高级配置」，将时间锁定为指定区间即可。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553208" alt="图片" title="图片" loading="lazy"/></p><p>配置完成后，这个图表的右上角会出现你锁定的时间区间，该时间不受仪表板整体的时间区间控制，如下图所示。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553209" alt="图片" title="图片" loading="lazy"/></p><h3>视图变量</h3><p>视图变量允许用户通过下拉菜单来选择特定对象的监控数据，从而根据自身需求动态筛选和分析数据。如下图所示，该仪表板包括了 Cluster、Namespace 和 Node 三个视图变量，用户可以进行自由筛选。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553210" alt="图片" title="图片" loading="lazy"/></p><p>我们首先添加一个简单的视图变量，需求是通过选择 host_ip 来过滤单台主机的数据。在仪表板中点击「添加视图变量」。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553211" alt="图片" title="图片" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553212" alt="图片" title="图片" loading="lazy"/></p><p>host_ip 是 cpu 相关指标数据的一个标签，因此我们从指标类型- CPU指标集里面选择 host_ip 作为视图变量的来源，然后将「变量名」和「显示名」都与之保持一致，保存窗口即可。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553213" alt="图片" title="图片" loading="lazy"/></p><p>此时返回仪表板，就会看到刚才添加的 host_ip 视图变量，从下拉菜单中可以筛选主机 IP。如下图所示：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553214" alt="图片" title="图片" loading="lazy"/></p><p>你可能会发现筛选结果之后，对下方的图表没有任何作用，因为我们还需要在图表中的过滤条件配置变量，使仪表板的额视图变量与图表的过滤条件进行联动。再次进入图表编辑界面，添加一个过滤条件，字段选择为 host_ip，值选择「视图变量」，如下图所示。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553215" alt="图片" title="图片" loading="lazy"/></p><p>返回仪表板，这时仪表板的视图变量 host_ip 就可以与图表中的监控对象 host_ip 进行联动了。我们可以通过下拉菜单来筛选不同的主机，从而观察不同主机的监控指标。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553216" alt="图片" title="图片" loading="lazy"/></p><p>如果是有多个视图变量，且视图变量之间有依赖关系，例如我们针对 Pod 的监控是首先选择 namespace，再选 Pod，那我们又应该如何配置呢？这就要用到「级联」的写法，让我们来再来回顾一下刚才本章开头的那张图片。选择 Cluster 后，Namespace 的值随 Cluster 的取值而联动，Node 的值又随 Namespace 的取值而联动。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553217" alt="图片" title="图片" loading="lazy"/></p><p>我们研究一下这组视图变量的写法，不难发现规律是在 show_tag_value 函数的后面跟随了一个 {key=value} 的过滤条件，其固定写法为 {key='#{value}'} ，key 和 value 都取自上一级的变量名，表示该变量随上一级变量的值而联动。如下图所示，当用户在界面上选择了 cluster_name_k8s 的值后，该值就会传入 namespace 作为过滤条件，从而实现变量联动。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553218" alt="图片" title="图片" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553219" alt="图片" title="图片" loading="lazy"/></p><h2>小结</h2><p>通过上面的几个小技巧，相信你已经跃跃欲试将自己的仪表板更上一层楼了。在得到令自己满意的仪表板后，你可以选择将仪表板开放给团队、配置为定时报告、投放到大屏幕、关联到日志或链路查看器中，又或者在接收到告警时一键查看这张仪表板。我们非常期待你通过仪表板来向你的团队/客户呈现数据的价值。</p>]]></description></item><item>    <title><![CDATA[同时接入港股与美股实时行情，有更省事的做法吗？ sydney ]]></title>    <link>https://segmentfault.com/a/1190000047553249</link>    <guid>https://segmentfault.com/a/1190000047553249</guid>    <pubDate>2026-01-20 14:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>如果你在做量化研究、实盘盯盘，或者高频信号监控，可能已经遇到过这样的问题：<br/>港股、美股都要看，但行情接口分散在不同平台，字段不统一、时间规则不同，接入成本远高于预期。</p><p>一开始你可能会觉得这是“小问题”，多写几层适配就能解决。但真正跑起来后，会发现维护成本会持续放大，尤其是在高频或长时间运行的场景下。</p><h3>多市场行情接入，难点并不在“拿到数据”</h3><p>在实际开发中，真正消耗精力的通常是这些地方：</p><ul><li>港股、美股 API 结构差异大，需要额外做字段映射</li><li>tick 数据更新频繁，处理不当容易阻塞</li><li>部分接口在行情活跃时延迟明显，甚至丢数据</li></ul><p>这些问题往往不会立刻暴露，但会逐渐影响策略判断和系统稳定性。</p><h3>一个更工程化的思路：统一数据入口</h3><p>当你需要长期维护系统时，一个<strong>覆盖多市场、数据口径一致的行情源</strong>会明显降低复杂度。</p><p>在实时行情场景下，相比 REST 轮询，用 WebSocket 订阅的方式更接近“监听市场”而不是“反复查询状态”。<br/>你只需要维护一条连接，就能持续接收行情变化，延迟和资源消耗都更可控。</p><p>像AllTick这类聚合型行情接口，本质上解决的是“多市场适配”这个工程问题：<br/>同一套接入方式，同时覆盖港股和美股，不需要为不同市场维护多套逻辑。</p><h3>实战示例：Python WebSocket 订阅港股+美股</h3><p><img width="723" height="370" referrerpolicy="no-referrer" src="/img/bVdnGU2" alt="" title=""/><br/>下面是我用的一个简单示例，直接抓取港股腾讯（00700.HK）和美股苹果（AAPL.US）：</p><pre><code>import websocket
import json

# AllTick WebSocket URL
ws_url = "wss://api.alltick.co/realtime"

def on_message(ws, message):
    data = json.loads(message)
    # 简单打印最新行情
    print(f"{data['symbol']} - 最新价: {data['price']} 时间: {data['timestamp']}")

def on_open(ws):
    # 订阅港股和美股行情
    msg = {
        "action": "subscribe",
        "symbols": ["00700.HK", "AAPL.US"]
    }
    ws.send(json.dumps(msg))

ws = websocket.WebSocketApp(ws_url, on_message=on_message, on_open=on_open)
ws.run_forever()
</code></pre><p>几个要点：</p><ul><li>symbols 字段可以自由组合港股、美股股票代码</li><li>WebSocket 推送省去了轮询的麻烦</li><li>我通常会在回调里加一点数据缓存和异常处理，保证程序稳定</li></ul><h3>实际使用后的变化</h3><p>在把港股和美股行情统一接入之后，几个变化非常直观：</p><ul><li>数据结构统一，策略层代码更干净</li><li>WebSocket 推送减少了延迟和轮询压力</li><li>系统稳定性更好，排查问题更容易</li></ul><p>很多之前看起来像“策略不稳定”的情况，实际上是数据层噪音造成的。</p><h3>实战中需要注意的细节</h3><p>即便使用统一接口，仍然有一些工程细节需要你自己把控：</p><ul><li><strong>时间处理</strong>：不同市场交易时间不同，时间戳必须统一标准</li><li><strong>高频数据控制</strong>：tick 数据建议异步处理或限流，避免内存堆积</li><li><strong>调试方式</strong>：先订阅少量标的跑通流程，再逐步扩展</li></ul><p>这些点不复杂，但直接影响系统是否能稳定运行。</p><h3>总结</h3><p>港股和美股的实时行情接入，本身并不是难题。<br/>真正拉开效率差距的，是你是否在一开始就选对了数据接入方式。</p><p>统一的数据源、实时推送机制、可维护的结构设计，会让你把更多精力放在策略和逻辑本身，而不是反复处理接口差异。</p><p>如果你正在做跨市场行情相关的开发，这个方向值得你认真评估一次。</p>]]></description></item><item>    <title><![CDATA[专注于数字化采购的SaaS平台，排名靠前的有哪些？ SaaS圈老马 ]]></title>    <link>https://segmentfault.com/a/1190000047553078</link>    <guid>https://segmentfault.com/a/1190000047553078</guid>    <pubDate>2026-01-20 13:02:48</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在推进采购数字化的过程中，很多企业都会遇到一个现实问题：市场上号称“数字化采购 / 采购 SaaS / SRM”的平台很多，但真正专注于采购场景、并且在企业中被广泛采用的，到底有哪些？</p><p>有的企业刚开始调研，希望先了解行业主流平台；有的已经立项，却发现不同厂商定位差异很大；也有不少采购负责人，在ERP采购模块和独立采购SaaS之间反复权衡。</p><p>如果你正处在采购系统选型或前期评估阶段，这篇文章将从行业视角，梳理当前专注于<strong>数字化采购的主流SaaS平台</strong>，并提供一套更理性的选型参考思路。</p><p>需要先说明的是，所谓“排名靠前”，并不等同于“最适合所有企业”。不同规模、不同行业、不同采购成熟度的企业，关注重点完全不同。本文不会简单给出“谁最好”的结论，而是帮助你建立判断框架，避免选型走弯路。</p><p><strong>一、 市场格局与平台共性：什么样的平台算“靠前”？</strong></p><p>目前，数字化采购SaaS市场已进入规模化应用阶段，厂商众多，定位各异。这并不是一个“赢家通吃”的市场，采购场景的复杂性决定了没有一家平台能通吃所有客户。</p><p>在实践中，被市场认为“排名靠前”或主流的平台，通常具备一些共性特征：</p><p><strong>客户基础扎实，行业覆盖广</strong>：已服务大量中大型企业客户，案例覆盖制造、零售、工程等多个行业，而非局限于单一领域。</p><p><strong>产品成熟度高</strong>：不仅功能完整，更在复杂流程配置、多组织权限、合规风控等企业级能力上经过验证。</p><p><strong>交付与服务能力稳定</strong>：具备成熟的实施方法论和专业团队，能保障系统成功落地与持续应用。</p><p><strong>生态集成能力强</strong>：能与ERP、财务、OA等企业核心系统稳定对接，打破数据孤岛。</p><p><strong>二、 主流平台深度测评：五大典型路径解析</strong></p><p>市场上的领先平台，根据其背景、优势和目标客群，可以归纳为几种典型路径。了解这些路径，比单纯记名字更有助于你做出选择。</p><p><strong>类型一：深耕流程的“行业专家型” —— 【正远科技】</strong></p><p>这类平台通常从深厚的业务流程管理（BPM）或特定行业咨询背景成长而来，其核心优势在于 <strong>对采购业务本质的深度理解与极强的流程定制能力</strong>。</p><p><strong>1、正远科技</strong></p><p>正远科技是一家在流程管理领域扎根超过20年的厂商。他们的数字化采购方案以 <strong>自研SRM系统</strong> 和 <strong>ZeroCloud低代码平台</strong> 为核心，不是简单的功能堆砌，而是围绕“供应商管理、价格管理、采购执行协同”三大核心业务模块进行深度设计。</p><p><strong>核心优势</strong>：</p><p><strong>流程柔性极强</strong>：依托低代码平台，企业可以像搭积木一样，自主配置符合自身合规要求和审批习惯的采购流程，特别适合流程复杂、个性化要求高的大型企业。</p><p><strong>行业理解深入</strong>：长期服务威高集团、南山集团等大型制造企业，其解决方案能深度匹配制造业对物料、供应商、质量协同的严苛要求。</p><p><strong>全链路覆盖</strong>：从供应商准入、绩效评估，到询比价招标、订单协同、收货对账，实现了采购业务的全周期数字化管理。</p><p><strong>适合谁</strong>：<strong>流程复杂、追求深度定制化，且希望采购系统能与自身管理体系高度融合的大中型企业</strong>，尤其是制造业、工程建筑等对流程管控要求严格的行业。<br/><img width="723" height="382" referrerpolicy="no-referrer" src="/img/bVdnGS7" alt="" title=""/></p><p><strong>类型二：生态整合的“巨擘型” —— 【用友与金蝶】</strong></p><p>这类平台源自国内ERP巨头，其最大优势在于 <strong>与财务、供应链、生产等系统“天生一体”的无缝集成</strong>，数据流转顺畅，能实现真正的业财一体化。</p><p><strong>2、用友YonBuilder &amp; 金蝶云·苍穹</strong></p><p><strong>用友采购云</strong>：背靠用友庞大的ERP生态，对于已使用用友系统的企业，集成成本最低。其战略寻源模块强大，特别擅长处理国企、大型集团复杂的招标采购与合规需求。</p><p><strong>金蝶采购云</strong>：基于云原生的金蝶云·苍穹平台构建，在系统敏捷性和弹性方面有优势。其供应商协同门户体验出色，AI辅助定价等智能化场景应用较快。</p><p><strong>共同优势</strong>：安全性高、系统稳定、生态整合度无与伦比。能完美支持多组织、多账簿的集团型管控。</p><p><strong>适合谁</strong>：已经或计划全面使用该品牌ERP系统的大型集团企业、国有企业及上市公司，尤其适合将采购合规与财务控制视为生命线的客户。<br/><img width="723" height="299" referrerpolicy="no-referrer" src="/img/bVdnGS8" alt="" title="" loading="lazy"/><br/><img width="723" height="314" referrerpolicy="no-referrer" src="/img/bVdnGS9" alt="" title="" loading="lazy"/></p><p><strong>类型三：产业互联的“供应链协同型” —— 【企企通】</strong></p><p>这类平台的核心定位在于 连接与协同，其目标不是简单地管理内部采购流程，而是构建一个连接采购商与海量供应商的在线协同网络，实现供应链端的降本增效。</p><p><strong>3、企企通</strong></p><p>企企通是国内专注于供应链协同和SRM领域的领先平台。它的核心价值在于打通企业与其供应商之间的数据流与业务流，将传统的线下、离散的采购协作，转变为线上、实时、自动化的协同网络。</p><p><strong>核心优势</strong>：</p><p>构建供应商协同门户：为企业搭建一个专属的、面向所有供应商的在线门户。供应商可通过该门户自助完成接收订单、确认交期、发货通知、在线对账、开具发票等全链路操作，极大减轻采购方的沟通负担。</p><p>强化战略寻源与供应商绩效：提供完善的招标、询比价管理工具，并基于真实的交货、质量、服务数据，实现供应商绩效的客观量化评估，为优化供应商体系提供数据支撑。</p><p><strong>适合谁</strong>：供应链结构复杂、供应商数量众多、对外协同成本高昂的中大型制造、零售或连锁企业。尤其适合那些希望将数字化从内部管理延伸至整个供应链生态，以提升供应链整体韧性与效率的客户。<br/><img width="723" height="330" referrerpolicy="no-referrer" src="/img/bVdnGTa" alt="" title="" loading="lazy"/></p><p><strong>类型四：敏捷普惠的“中小企业优选型” —— 【支道】</strong></p><p>这类平台精准聚焦中小企业市场，在成本、易用性和上线速度上做到了极致平衡，降低了采购数字化的入门门槛。</p><p><strong>4、支道</strong></p><p>支道提供以无代码平台为核心的一站式解决方案，其采购管理作为开箱即用的场景模板，让非技术人员也能通过拖拽搭建系统。</p><p><strong>核心优势</strong>：<strong>性价比高、部署快、极其灵活</strong>。能快速响应中小企业在发展过程中不断变化的采购管理需求。</p><p><strong>适合谁</strong>：<strong>IT预算和能力有限，但急需实现采购基础流程数字化、规范化，并追求高性价比的中小企业</strong>，是迈出采购数字化第一步的稳妥选择。<br/><img width="723" height="378" referrerpolicy="no-referrer" src="/img/bVdnGTb" alt="" title="" loading="lazy"/></p><p><strong>三、 如何选择：避开误区，找到你的“最适路径”</strong></p><p>看到这里你会发现，没有“最好”，只有“最适合”。选型中最常见的误区就是“只看功能列表，不看自身基因”。在行动前，建议先内部厘清这几个问题：</p><p><strong>1、我们采购数字化的首要目标是什么？</strong> （是降本合规，还是提升协同效率？）</p><p><strong>2、我们当前的采购流程成熟度和IT基础如何？</strong></p><p><strong>3、我们更看重系统的“开箱即用”，还是“深度定制”？</strong></p><p><strong>4、我们是否有足够的资源（预算、团队）来应对系统实施和后续变革？</strong></p><p><strong>选型逻辑参考：</strong></p><p>如果你是<strong>流程复杂、管控要求高的大型集团</strong>，优先考虑“行业专家型”或“生态巨擘型”。</p><p>如果你是<strong>正在规范化、寻求效率突破的中大型企业</strong>，“行业专家型”或“通用平台型”的平衡性可能更佳。</p><p>如果你是<strong>期望解决同外部供应商之间的沟通滞后、数据孤岛问题</strong>，那么打造一个高效的 “供应链协同网络”可以是首要战略。</p><p>如果你是<strong>追求实用、快速见效的中小企业</strong>，“敏捷普惠型”是一个务实的起点。</p><p><strong>结语</strong></p><p>采购数字化不是一次简单的软件采购，而是一场涉及流程、组织和数据的深层变革。所谓“排名靠前”的平台，都是在特定路径上积累了深厚优势的伙伴。</p><p>最理性的做法，是抛开模糊的“排名”焦虑，回归自身业务现状与发展蓝图。在理解不同平台类型基因的基础上，选择那条与自身阶段最匹配、能陪伴你持续成长的数字化路径。希望这份测评与梳理，能为你带来清晰、实用的选型洞察。</p>]]></description></item><item>    <title><![CDATA[征程 6 H/P 工具链 QAT 精度调优 地平线智驾开发者 ]]></title>    <link>https://segmentfault.com/a/1190000047553080</link>    <guid>https://segmentfault.com/a/1190000047553080</guid>    <pubDate>2026-01-20 13:02:10</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>一、QAT 调优流程</h2><p><strong>流程总览：</strong></p><blockquote>针对征程 6H/P 的硬件特性，以 int8+int16+fp16 的混合精度量化为主要调优配置，会增加较多的 fp16 设置来优化量化精度</blockquote><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553082" alt="" title=""/></p><p>注意：</p><p>征程 6H/P 上会用到更多 fp16 高精度和 GEMM 类算子双 int16 等的配置，为了配置方式更加简单灵活，QAT 量化工具提供了一套新的 qconfig 量化配置模板，具体使用方式和注意事项参考：</p><p>&lt;u&gt;<a href="https://link.segmentfault.com/?enc=vErFpmD8kkAj1pxKMUoN0A%3D%3D.a4vGKfy2Nd6ZbavXEDg5%2BhikrJhu3hbM%2BbYV5HwBsvd2k3nAlvCquMz5CFtVyR5%2B" rel="nofollow" target="_blank">【地平线 J6 工具链入门教程】QAT 新版 qconfig 量化模板使用教程</a>&lt;/u&gt;</p><p><strong>调优原则：</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553083" alt="" title="" loading="lazy"/></p><p>如上是一个标准的对称量化公式，产生误差的地方主要有：</p><ol><li>round 产生的舍入误差。例如：当采用 int8 量化，scale 为 0.0078 时，浮点数值 0.0157 对应的定点值为 round（0.0157 / 0.0078） = round（2.0128） = 2，浮点数值 0.0185 对应的定点值为 round（0.0185 / 0.0078） = round（2.3718） = 2，两者均产生了舍入误差，且由于舍入误差的存在，两者的定点值一致。 对于舍入误差，可以使用更小的 scale，这样可以使得单个定点值对应的浮点值范围变小。由于直接减小 scale 会导致截断误差，所以常用的方法是使用更高的精度类型，比如：将 int8 换成 int16，由于定点值范围变大， scale 将减小。</li><li>clamp 产生的截断误差。当 qmax * scale 无法覆盖需要量化的数值范围时，可能产生较大截断误差。例如：当采用 int8 量化，scale 为 0.0078 时，qmax * scale = 127 * 0.0078 = 0.9906，大于 0.9906 的值对应的定点值将被截断到 127。 对于截断误差，可以使用更大的 scale。scale 一般是由量化工具使用统计方法得到，scale 偏小的原因是校准数据不够全，校准方法不对，导致 scale 统计的不合理。比如：某一输入的理论范围为 [-1， 1]，但校准或 qat 过程中，没有观测到最大值为 1 或最小值为 -1 的样本或观测到此类样本的次数太少。应该增加此类数据或者根据数值范围，手动设置固定 scale。在截断误差不大的情况下，可以调整校准参数，通过不同的校准方法和超参缓解截断误差。</li></ol><p>因此，QAT 量化精度调优以减少上述两种误差为基本原则，下文将针对 QAT 每个阶段做调优介绍：</p><p>注意：</p><p>征程 6H/P 平台的浮点模型量化友好设计以及 QAT 模型改造等内容和征程 6E/M 一致，仍可参考该文章对应章节：</p><p>&lt;u&gt;<a href="https://link.segmentfault.com/?enc=ynfrlkxIUGcSpul%2FkldIig%3D%3D.1czTC1Ngm0dGasNcWmV9FZGoJuLHHulwZinYFnpdhsDJlH9UNVFR%2B8oYpVE281JX" rel="nofollow" target="_blank">【地平线 J6 工具链进阶教程】J6 E/M 工具链 QAT 精度调优</a>&lt;/u&gt;</p><h3>1.1 模型检查</h3><p>完成模型改造和量化配置后，调用 Prepare 接口时会对模型做算子支持和量化配置上的检查，这些检查一定程度上反映了模型量化存在的问题。对于不支持的算子将以报错的形式提醒用户，一般有两种情况：</p><ol><li>未正确进行模型的量化改造。Prepare 过程中 QAT 量化工具会对模型进行 trace 来获取完整的计算图，在这个过程中会完成算子替换等的优化，对于这些已替换的算子，输入输出类型如果是 torch.tensor 而非经过 QuantStub 转化后的 qtensor，则会触发不支持算子的报错，表现为 <code>xxx is not implemented for QTensor</code>；</li><li>确实存在不支持的算子。工具链已支持业界大量的常用算子，但对于部分非常见算子的不支持情况，需考虑进行算子替换或者作为算子需求向工具链团队导入。</li></ol><p>Prepare 运行成功后会在当前目录下自动保存模型检查文件 <code>model_check_result.txt</code> 和 <code>fx_graph.txt</code>，建议参考下列解读顺序：</p><ol><li>算子融合检查。算子融合作为 QAT 量化工具的标准优化手段，常见的融合组合为 Conv+ReLU+BN 和 Conv+Add 等，未融合的算子会在 txt 文件中给出，未按预期融合的算子可能是因为共享没有融合成功或者是 QAT 量化工具的融合逻辑变更（针对新版 qconfig 量化模板 enable\_optimize=True 情况，见&lt;u&gt;<a href="https://link.segmentfault.com/?enc=3QVAjvbC0w0%2FcLE9Lt7N8A%3D%3D.I0s9NYMuWY1UgIDcEEAm7vV6rWVLIm6atfE6tp%2BifgPxD2hT1Nc7E%2BmzqzlIithn" rel="nofollow" target="_blank">【地平线 J6 工具链入门教程】QAT 新版 qconfig 量化模板使用教程</a>&lt;/u&gt;），需要检查代码，确认未融合的情况是否符合预期：</li></ol><pre><code class="Plain"># 示例：未融合的Conv+Add算子
Fusable modules are listed below:
name       type------  -------------------------
model.view_transformation.input_proj.0.0(shared) 
&lt;class'horizon_plugin_pytorch.nn.qat.conv2d.Conv2d'&gt;
model.view_transformation._generated_add_0        
&lt;class'horizon_plugin_pytorch.nn.qat.functional_modules.FloatFunctional'&gt;</code></pre><p>未融合的算子对模型性能会有一定影响，对于精度的影响需视量化敏感度具体分析，一般来说，Conv/Linear+ReLU+BN 可能会因为算子复用导致未融合，此时建议手动修改融合；在 OE 3.5.0 以及之后版本使用新 qconfig 模板下，Conv+Add 默认不会融合，可不修改</p><ol start="2"><li>共享模块检查。一个 module 只有一组量化参数，多次使用将会共享同一组量化参数，多次数据分布差异较大时，会产生较大误差：</li></ol><pre><code class="Plain"># 示例：该共享模块被调用8次
Each module called times:
name      called times
---------  --------------   
...
model.map_head.sparse_head.decoder.gen_sineembed_for_position.div.reciprocal                          
8</code></pre><p>called times &gt; 1 的模块可能有很多个，全部改写成非共享是一劳永逸的。对于修改简单且精度影响大的共享算子如 QuantStub，强烈建议取消共享；对于 DeQuantStub 算子，共享不会对模型精度产生影响，但是会影响 Debug 结果的分析，也建议取消共享，修改方式参考征程 6E/M“模型改造”章节。</p><p>例如下面的共享模块，量化表示的最大值为 128 * 0.0446799 ≈ 5.719，在第一次使用中，输出范围明显小于 [-5.719， 5.719]，误差较小， 第二次使用中，输出范围超出 [-5.719， 5.719]，数值被截断，产生了较大误差。两次数值范围的差异也造成了统计出的 scale 不准确，因此该共享模块必须修改</p><pre><code class="Plain">+-+-+-+-+-+-+--+-+-+-+-+|   | mod_name | base_op_type   | analy_op_type  | shape  | quant_dtype |  qscale |base_model_min | analy_model_min | base_model_max |   analy_model_max ||-+-+--+-+-+-+-+-+-+-+-+...| 1227 | model.map_head.sparse_head.decoder.gen_sineembed_for_position.div | horizon_plugin_pytorch.nn.div.Div  | horizon_plugin_pytorch.nn.qat.functional_modules.FloatFunctional.mul  | torch.Size([1, 1600, 128])| qint8  |  0.0446799 | 0.0002146 | 0.0000000 | 4.5935526 |  4.5567998 |...| 1520 | model.map_head.sparse_head.decoder.gen_sineembed_for_position.div | horizon_plugin_pytorch.nn.div.Div  | horizon_plugin_pytorch.nn.qat.functional_modules.FloatFunctional.mul | torch.Size([1, 1600, 128]) | qint8 |  0.0446799 | 0.0000000 | 0.0000000 |  6.2831225 |  5.7190272 |...</code></pre><p>上面共享算子的修改方式可以参考：</p><pre><code class="Plain">class Model(nn.Module):def __init__(self, ) -&gt; None:super().__init__()...
        self.steps = 2for step in range(self.steps):setattr(self, f'div{step}', FloatFunctional())def forward(self, data):...for step in range(self.steps):
            data = getattr(self, f'div{step}').div(x)...</code></pre><p>对于不带权重的 function 类算子都可以参考上面的拆分方式，但是也存在部分共享算子或模块带有权重参数拆分起来比较复杂，是否需要拆分建议先根据量化敏感度进行分析。带有权重参数算子拆分时需要复制权重，拆分方式可以参考：</p><pre><code class="Plain">class Model(nn.Module):def __init__(self, ) -&gt; None:super().__init__()...
        self.steps = 3
        self.conv0 = nn.Conv2d(...)
        shared_weight = self.conv0.weight
        shared_bias = self.conv0.bias
        for step in range(1, self.steps):setattr(self, f'conv{step}', nn.Conv2d(...))getattr(self, f'conv{step}').weight = shared_weight
            getattr(self, f'conv{step}').bias = shared_bias
  
    def forward(self, data):...for step in range(self.steps):
            data = getattr(self, f'conv{step}')(x)...</code></pre><p>上述共享算子修改生效后，在 <code>model_check_result.txt</code> 文件中可见到无该算子共享相关的信息：</p><pre><code class="Plain"># 修改生效后下面信息将不再显示
Modules below are used multi times:
name      called times
------  --------------
xxxxx                2</code></pre><p>此外，未调用的模块也会在文件中体现，<code>called times</code> 为 0，当 Calibration/QAT/模型导出出现 miss\_key 时，可以检查模型中是否有模块未被 trace。</p><ol start="3"><li>量化配置检查。txt 文件中会给出模型量化精度的统计信息：</li></ol><pre><code class="Plain"># 算子输入量化精度统计input dtype statistics:+---+--+--+--+| module type                                                                |   torch.float32 |   qint8 |   qint16 ||---+---+--+--+| &lt;class 'horizon_plugin_pytorch.nn.qat.stubs.QuantStub'&gt;                    |             290 |      15 |        0 || &lt;class 'horizon_plugin_pytorch.nn.qat.linear.Linear'&gt;                      |               5 |     117 |        9 || &lt;class 'horizon_plugin_pytorch.nn.qat.stubs.DeQuantStub'&gt;                  |               0 |       8 |        0 |...# 算子输出量化精度统计
output dtype statistics:+---+--+--+--+| module type                                                                |   torch.float32 |   qint8 |   qint16 ||---+--+--+--+| &lt;class 'horizon_plugin_pytorch.nn.qat.stubs.QuantStub'&gt;                    |               0 |     123 |      182 |...# 使用fp16量化精度的算子，量化精度统计+---+--+--+--+--+| module type                                                                |   torch.float32 |   qint8 |   qint16 |   torch.float16 ||-----+--+--+--+--|| &lt;class 'horizon_plugin_pytorch.nn.qat.stubs.QuantStub'&gt;                    |              34 |       0 |        0 |               0 || &lt;class 'torch.nn.modules.padding.ZeroPad2d'&gt;                               |               0 |      11 |        0 |               0 || &lt;class 'horizon_plugin_pytorch.nn.qat.functional_modules.FloatFunctional'&gt; |              48 |      14 |        9 |              50 |...</code></pre><p>重点检查的信息有：</p><ul><li><code>&lt;class 'horizon_plugin_pytorch.nn.qat.stubs.QuantStub'&gt;</code> 的 input dtype 应为 <code>torch.float32</code>，对于 <code>qint8</code> 或者 <code>qint16</code> 的 input dtype，一般是冗余的 QuantStub 算子可以改掉，不会对精度产生影响但可能会对部署模型性能有影响（算子数量）</li><li>正常来说模型中的算子不应出现 <code>torch.float32</code> 的输入精度（除下文 c 情况），如上图的 <code>&lt;class 'horizon_plugin_pytorch.nn.qat.linear.Linear'&gt;</code>，需要检查是否漏插 <code>QuantStub</code> 未转定点，未转定点的算子在导出部署模型时会 cpu 计算从而影响模型性能。对于模型中的一些浮点常量 tensor，工具已支持自动插入 <code>QuantStub</code> 转定点，建议获取最新版本</li><li>对于 GEMM 类算子（Conv/Matmul/Linear）作为模型输出时支持高精度输出（征程 6E/M 支持 int32 输出，征程 6B/H/P 支持浮点输出），体现到这里则是 <code>&lt;class 'horizon_plugin_pytorch.nn.qat.stubs.DeQuantStub'&gt;</code> 的 input dtype 应为 <code>torch.float16</code> 或 <code>torch.float32</code>，对于 <code>qint8</code> 或 <code>qint16</code> 输入的 <code>DeQuantStub</code> 需要检查是否符合高精度输出的条件，符合条件但未高精度输出的需修改。此外对于下面左图的结构，也建议优化为右图结构来保证高精度输出的优化</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553084" alt="" title="" loading="lazy"/></p><ul><li>qint8 和 qint16 算子的占比，可以协助判断是否配置全 int16 生效；torch.float16 算子的占比，可以协助判断是否配置 fp16 生效</li></ul><p>txt 文件同时会给出逐层的量化配置信息：</p><pre><code class="Plain"># 激活逐层qconfig
Each layer out qconfig:+--+--+--+--+--+--+| Module Name| Module Type | Input dtype | out dtype | ch_axis | observer ||--+--+--+--+--+---|# 固定scale| quant | &lt;class 'horizon_plugin_pytorch.nn.qat.stubs.QuantStub'&gt;                    | [torch.float32] | ['qint16']| -1  | FixedScaleObserver(scale=tensor([3.0518e-05], device='cuda:0'),zero_point=tensor([0], device='cuda:0')) |# QAT训练激活scale更新| mod2.1.attn.q | &lt;class 'horizon_plugin_pytorch.nn.qat.conv2d.Conv2d'&gt;  | ['qint16']  | ['qint16'] | -1 | MinMaxObserver(averaging_constant=0.01) |# QAT训练激活scale不更新| mod2.1.FFN.out_conv.1.0| &lt;class 'horizon_plugin_pytorch.nn.qat.conv2d.Conv2d'&gt; | ['qint16']| ['qint16']| -1| MinMaxObserver(averaging_constant=0)  |# 激活fp16 qconfig| bev_fusion.multi_view_cross_attn.32.global_cross_window_attn._generated_add_2[add]| &lt;class 'horizon_plugin_pytorch.nn.qat.functional_modules.FloatFunctional'&gt; | [torch.float16, torch.float32]                     | [torch.float16] | FakeCast(dtype=torch.float16, min_val=-0.0009765625, max_val=0.0009765625)  | |# 权重逐层qconfig
Weight qconfig:+-----+----+-----+------+---+| Module Name | Module Type | weight dtype|ch_axis|observer ||---+-------+----+----+---|| mod1.0 | &lt;class 'horizon_plugin_pytorch.nn.qat.conv2d.Conv2d'&gt; |qint8 | 0 | MinMaxObserver(averaging_constant=0.01) |</code></pre><p>重点检查的信息有：</p><ul><li>每层算子的输入输出 dtype、权重的 dtype，是否符合量化配置；若和量化配置不符合，比如配置了 int16，但是算子显示为 int8，则需要关注下算子回退信息，例如在旧模板下 Conv+Add 融合时 Conv 不支持 int16 输入，会导致前序算子输出回退到 int8。新的 qconfig 量化配置模板下算子回退过程需查看 qconfig\_changelogs.txt，详细参考：<a href="https://link.segmentfault.com/?enc=J3Yz8wklu9aTdg%2B2tJcA6w%3D%3D.Jh%2FnfFRT7TcMgim3UdDkWJ%2FxJKWO%2FZjlDn%2FuRhYn7NcdSVk5c%2F5FC7MxQqoWdIbC" rel="nofollow" target="_blank">https://developer.horizon.auto/blog/13112</a></li><li>配置了 fix scale 的算子，是否正确显示 FixedScaleObserver 信息，scale 值是否正确</li><li>逐层算子的 observer 是否正确：权重默认 MinMaxObserver，QAT 校准时激活默认 MSEObserver，QAT 训练时激活默认 MinMaxObserver</li><li>若为 QAT 训练阶段且配置了固定校准的激活 scale，查看 averaging\_constant，判断是否生效，生效为 averaging\_constant=0（即不更新 scale），默认为 0.01（更新 scale）</li></ul><p>对于 <code>fx_graph.txt</code>，可以从中获取到模型中 op/module 的上下游调用关系，例如当存在算子 <code>called times</code> 为 0 未被调用的情况，可以通过 Graph 定位到上下文算子从而定位未被调用的原因（通常因为在 init 函数中定义了但在 forward 中没有调用，也可能存在逻辑判断或循环次数变化的情况）；此外当出现导出的部署模型（bc 模型）精度异常，也可以通过 Graph 信息来排查是否是导出计算图改变导致的</p><pre><code class="Plain"># 模型Graph图结构信息
Graph:
opcode       name        target            args           kwargs
----         -----       -------           -------        -------
placeholder    input_0    input_0              ()         {}
call_module    quant       quant            (input_0,)     {}
call_module  traj_decoder_src_proj_0_0  traj_decoder_src_proj.0.0                                             (quant,)  {}
call_function  scope_end    &lt;function Tracer.scope_end at 0x7f4477d7dc60&gt;   ('traj_decoder_src_proj.0',) {}
call_function  __get__    &lt;method-wrapper '__get__' of getset_descriptor object at 0x7f460922b800&gt;  (traj_decoder_src_proj_0_0,) {}
call_function  __getitem__       &lt;slot wrapper '__getitem__' of 'torch.Size' objects&gt;     (__get__, 0)   {}
call_function  __getitem___1      &lt;slot wrapper '__getitem__' of 'torch.Size' objects&gt;   (__get__, 1)  {}
call_function  __getitem___2     &lt;slot wrapper '__getitem__' of 'torch.Size' objects&gt;   (__get__, 2)   {}
call_function  __getitem___3      &lt;slot wrapper '__getitem__' of 'torch.Size' objects&gt;   (__get__, 3) {}
call_function  permute     &lt;method 'permute' of 'torch._C.TensorBase' objects&gt;   (traj_decoder_src_proj_0_0, 0, 2, 3, 1)  {}...</code></pre><p>重点关注的 Graph 信息：</p><ul><li><code>opcode</code> 为算子调用类型</li><li><code>name</code> 为当前算子名称，需注意和 <code>model_check_result.txt</code> 中的 <code>module.submodule</code> 名称区别</li><li><code>target</code> 为算子输出</li><li><code>args</code> 为算子输入</li></ul><h3>1.2 QAT 校准</h3><h4>1.2.1 int8+int16+fp16 混合精度调优</h4><blockquote>如果模型中吸收了前后处理的相关算子和操作，这部分默认需要 fp16 精度进行量化</blockquote><p>对于 int8+int16+fp16 混合精度而言，主要的量化配置如下（配置方式参考&lt;u&gt;<a href="https://link.segmentfault.com/?enc=a0dE%2BSyAEX3L6jyZMjgj5A%3D%3D.%2F9PKTpXoSpLUH4QwO1RcrjaYN5SDAcLbhgvOvyR6D1P350R%2FXfcg4ubU4uOLpbwo" rel="nofollow" target="_blank">【地平线 J6 工具链入门教程】QAT 新版 qconfig 量化模板使用教程</a>&lt;/u&gt;）：</p><ul><li>基础配置： TAE 算子（Conv/Matmul/Linear）双 int8、其他算子 fp16</li><li>精度优化配置： TAE 算子（Conv/Matmul/Linear）单 int16（部分双 int16）、其他算子 fp16</li><li>精度上限配置： TAE 算子（Conv/Matmul/Linear）双 int16、其他算子 fp16</li><li>性能上限配置： 全局 int8，建议仅在测试模型最优性能（精度无保证）或作为高精度耗时优化的对比参考时配置</li></ul><p>同样的对于较难量化的模型而言，初始应使用精度上限配置，在这个配置下解决量化流程可能的问题，优化量化风险较大的算子/模块，往往通过 Debug 工具进行定位，但在使用 Debug 工具较难定位到量化瓶颈时，可以使用分步量化的小技巧（参考本文最后章节"调优技巧"），也即对选中算子取消量化后对比精度，如定位到前后处理的算子/模块产生明显掉点，建议从模型中剥离；定位到模型中算子/模块，可以使用设置 fix\_scale 和拆分共享模块等方式，或者从量化友好角度修改浮点模型（参考征程 6E/M 量化调优对应章节：&lt;u&gt;<a href="https://link.segmentfault.com/?enc=OO2ZaGfVxReZoOj%2B%2BJlVyQ%3D%3D.B%2B3riMtdlpAOP3LT03I9YK0GGzE%2Bidlehy9QNfEYAKa9QMaA%2Br4BZheJ6gChCO4o" rel="nofollow" target="_blank">【地平线 J6 工具链进阶教程】J6 E/M 工具链 QAT 精度调优</a>&lt;/u&gt;）</p><p>精度上限配置下的模型较难满足部署侧的延时要求，因此解决掉上述的量化瓶颈后需要回归到基础配置。在基础配置上通过敏感度的分析结果，增加 TAE 的 int16 算子，也就是精度优化配置。在基础配置和精度优化配置下精度达标的模型，视延时情况可能需要进一步做性能优化，主要方向为：</p><ol><li>基础配置下，回退 fp16 性能瓶颈算子到低精度 int8</li><li>精度优化配置下，回退双 int16 的 TAE 算子到单 int16，回退 fp16 性能瓶颈算子到低精度 int8</li></ol><p>精度优化配置下如果 int16 算子比例已超出部署预期但精度仍有一定差距，则可以考虑回退部分 int16 算子后尝试 QAT 训练；基础配置下精度表现距离浮点差距较小（<code>量化精度/浮点精度 &gt; 90%</code>，经验值），直接尝试 QAT 训练，在 <code>量化精度/浮点精度 &gt;= 95%</code>（经验值）的情况下，建议优先尝试固定校准激活 scale 的 QAT 训练（仅调整权重感知量化误差）</p><p>对于不同精度配置下的 QAT 校准，都有一些校准超参可以调整，需要用户结合具体模型去做调参优化，其中主要的参数有校准数据的 batch size、校准的 steps，详细的参数参考：</p><ol><li>基础调优手段：&lt;u&gt;<a href="https://link.segmentfault.com/?enc=48w%2FNf70yRjq72zbxUHLNA%3D%3D.8w2wd00%2F2Go8wiKRIUMmO%2Fwu8ytHXnN3TbwEaveT5X7UM%2BYCkEMvDBLCjFx3SlHXnBSjflLCgbo%2Fnh%2BCVSYtLLwam6p3w%2FV02e8RRhGbf4PCDMHoEUGzawzg9yNq%2BBEF" rel="nofollow" target="_blank">调优指南\_基础调优手段</a>&lt;/u&gt;</li><li>高级调优手段：&lt;u&gt;<a href="https://link.segmentfault.com/?enc=%2F4diHa2Ze%2BIJCgdFuB3ZTg%3D%3D.XehFdvFZapbq5bn1hI%2FXSvoPstXmAUBgNGvBAWrnQqhyMiNzLUsPSSxC6L5NwUVAM%2FQTmK6nYP2IwUkUFaQFO45go86B2nwhr60rj26uPF%2Bx2zx%2Fxu7CcZqD3xh4dlhp" rel="nofollow" target="_blank">调优指南\_高级调优手段</a>&lt;/u&gt;</li></ol><p>由于征程 6H/P 平台使用了较多浮点 FP16 精度，该精度下数值范围超限场景有以下常见的优化方法和优缺点总结：</p><p><img width="723" height="350" referrerpolicy="no-referrer" src="/img/bVdnGSZ" alt="image.png" title="image.png" loading="lazy"/></p><p>总结：</p><p>int8+int16+fp16 混合精度调优的重点应放在 TAE 双 int16+ 其他算子 fp16 的调优上，这里需要把使用问题，量化不友好模块等等各种千奇百怪的问题都解决，看到模型的精度上限，然后根据模型部署的性能要求进行 TAE int8 和 int16 混合精度的调优，最后对非 TAE 算子进行 int8+fp16 混合精度的调优，最终达成部署精度和部署性能的平衡。</p><h4>1.2.2 Debug 产出物解读</h4><p>征程 6H/P 平台 Debug 产出物的解读和征程 6E/M 一致，仍可参考该文章对应章节：&lt;u&gt;<a href="https://link.segmentfault.com/?enc=nycxvcJ4Mmg5l9ZYaSSlXw%3D%3D.3rAZTCfR258j9TP7j692H1VD4CM6GDMbJAUSQKmpdMaqTX4oDxRC6Bl%2Bx3v4yVsC" rel="nofollow" target="_blank">【地平线 J6 工具链进阶教程】J6 E/M 工具链 QAT 精度调优</a>&lt;/u&gt;</p><h6>Badcase 调优</h6><p>对于实车或回灌反馈的可视化 badcase，利用 Debug 工具的调优流程为：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553085" alt="" title="" loading="lazy"/></p><h3>1.3 QAT 训练</h3><p>大部分模型仅通过 QAT 校准就可以获得较好的量化精度，对于部分较难调优的模型，以及还需要继续优化误差类指标的模型，通常校准设置的高精度比例导致延时超过部署上限，但精度仍无法达标，这种情况可以尝试 QAT 训练来获得满足预期性能-精度平衡的量化模型。</p><p>根据前文所述，在 QAT 校准 <code>量化精度/浮点精度 &gt;= 95%（经验值）</code> 的情况下，充分利用校准阶段较好的激活量化参数，优先尝试固定校准激活 scale 的 QAT 训练（仅调整权重感知量化误差），设置方式具体参考征程 6E/M 精度调优的“模型改造”章节：&lt;u&gt;<a href="https://link.segmentfault.com/?enc=ZcRfDl4zO1WlbrihlTA6tg%3D%3D.xOHTKFUOaDdUUZZq0%2FRw8bcTDetFAOQZ8ct1ss%2FydAB5SfCC%2FRbQZK1r2fNL4kQU" rel="nofollow" target="_blank">【地平线 J6 工具链进阶教程】J6 E/M 工具链 QAT 精度调优</a>&lt;/u&gt;</p><p>参考浮点训练，QAT 训练在大部分配置保持和浮点训练一致的基础上，也涉及到部分超参的调整来提升量化训练的精度，例如 QAT 的学习率、weight\_decay、迭代次数等，详细的参数调整策略参考：</p><ol><li>基础调优手段：&lt;u&gt;<a href="https://link.segmentfault.com/?enc=QLTGbTBobT36QAksG08oAA%3D%3D.EWlORAi%2B7btgUPfIhQP22zeDGfk3TGFedEdh98agT4ctUqHljsPQrb7BIyiKLgOPcF1qtmuSrBVLHsbnDbCcYf9FZqLZ4D%2FaIuulAn%2FBHjM%3D" rel="nofollow" target="_blank">调优指南\_基础调优手段</a>&lt;/u&gt;</li><li>高级调优手段：&lt;u&gt;<a href="https://link.segmentfault.com/?enc=0lae%2Bd9WARKAFu75LCjM9A%3D%3D.qGQiUSmSPjVgfn60DaLeluXgXRgma9V1rmSFLZ7%2BxJq2LDQ7s8sxa07DHJneTAEdaUsNea3UfVMsFK5nF5Xongmki0V5LauJrl1RrICSVka7d2%2FPbCsio4VfZWcnt3V4" rel="nofollow" target="_blank">调优指南\_高级调优手段</a>&lt;/u&gt;</li></ol><p>浮点和 QAT 训练中都涉及到对 BN 的状态控制，在浮点训练中可能会采用 FreezeBN fine-tune 的方式来提升模型精度，在多任务训练中也会采用 FreezeBN 的技巧。因此在 QAT 训练中，提供了 FuseBN 和 WithBN 两种训练方式：</p><ol><li>FuseBN 即在 Prepare 后，QAT 训练前将 BN 的 weight 和 bias 吸收到 Conv 的 weight 和 bias 中，在训练过程中不再单独更新，这一吸收过程是无损的。FuseBN 也是 QAT 默认的训练方式。</li><li>WithBN 则是在 QAT 训练阶段保持 Conv+BN 不融合，带着 BN 进行训练，BN 的参数单独更新，在训练结束后转成部署模型时再做融合。浮点训练阶段如果采用了 FreezeBN 的训练方式，QAT 训练时需设置 WithBN 来对齐浮点训练方式，设置方式如下：</li></ol><pre><code class="Plain">from horizon_plugin_pytorch.qat_mode import QATMode, set_qat_mode
set_qat_mode(QATMode.WithBN)</code></pre><p>通过观察 QAT 训练过程的 Loss 变化来初步判断 QAT 训练的量化效果，一般来说和浮点最后的 Loss 结果越接近越好，Loss 过大可能难以收敛，Loss 过小可能影响泛化性，对于异常的 Loss 建议的优化手段：</p><ol><li><p>异常 INF 和 NAN 的 Loss 值，或者初始 Loss 极大且无收敛迹象，按如下顺序排查：</p><ol><li>去掉 prepare 模型的步骤，用 qat pipeline finetune 浮点模型，排除训练 pipeline 的问题，Loss 如果仍异常，需要检查训练链路的配置如优化器 optimizer 和 lr\_updater 等</li><li>保持当前 QAT 训练配置，只关闭伪量化节点后观察训练的 Loss 现象，理论上和浮点有微小差异</li></ol></li></ol><pre><code class="Plain">from horizon_plugin_pytorch.quantization import set_fake_quantize, FakeQuantState
...
set_fake_quantize(qat_model, FakeQuantState._FLOAT)
train(qat_model, qat_dataloader)</code></pre><ol start="2"><li>在排查完链路问题后出现初始 Loss 较大，有收敛迹象但收敛较慢，这种情况可以尝试调整学习率，延长 QAT 迭代次数，因为 QAT 训练本质上是对已收敛浮点模型的 fine-tune，本身存在一定的随机性，用较大的学习率可以快速波动到一个理想精度（依赖一些中间权重的评测）</li><li>对于少数模型，QAT 训练以及尝试了多次超参调整后精度仍无法达标，建议回归 QAT 校准阶段增加少量高精度算子（增加 GEMM 类算子 int16，以及其他算子增加 FP16）、回归浮点结构检查是否还存在量化不友好的结构如使用了大量 GeLU 等（参考征程 6E/M 精度调优对应章节&lt;u&gt;<a href="https://link.segmentfault.com/?enc=kC0y7Qp6h6ROewXrPmP5rg%3D%3D.9%2BiG2Zhd0RV3j1ftqlGnbC34S9GR3lRQxDZqF5%2FgYtnajyGRYRFuEuezCfRbfBkF" rel="nofollow" target="_blank">【地平线 J6 工具链进阶教程】J6 E/M 工具链 QAT 精度调优</a>&lt;/u&gt;）</li></ol><h4>1.3.1 QAT 训练效率</h4><p>由于 QAT 训练过程需要感知模型量化所带来的损失，因此模型中会被插入必要的量化相关的节点：数据观测节点 Observer 和伪量化节点 FakeQuant。数据观测节点会不断统计模型中数据的数值范围，伪量化节点会根据量化公式对数据做模拟量化和反量化，两者都会存在开销，此外就是 QAT 工具内部会对部分算子例如 LN 层做拆分算子的实现，因此相同配置下的 QAT 训练效率是会略低于浮点训练效率，具体还和模型参数规模、算子数量等有关。</p><p>对于用户可明显感知到的 QAT 训练效率降低，建议的优化手段有：</p><ol><li>使用 QAT 工具提供的算子，这些算子优化了训练效率，例如 MultiScaleDeformableAttention（&lt;u&gt;<a href="https://link.segmentfault.com/?enc=wZFP4xmj3aYAe5qjwY9WZA%3D%3D.h8JPlTypC41VL7xad4wnmmkt9LbaoYSz09N62G3%2FEB6OF98MCByW%2BpQjVu0JIv1kl0owywwEAxE8%2BFAUhmzkCUBhr6qP%2FT9559JlHZYlrcPcJx%2BThCC1PpkXp2GHBhuG9Fv9obJjyYuEOtCDXxf4OdHjuFY%2FqJ6bxqVF%2FtuHLzHI7ERKFhG4c%2B7u5%2BUPKLGo" rel="nofollow" target="_blank">参考手册</a>&lt;/u&gt; ）</li><li>更新到最新的 horizon-plugin-pytorch 版本，新版本会有持续的 bug fix 和新特性优化，如模型中某些结构或者算子训练耗时增加明显，可以向工具链团队导入</li></ol><h3>1.4. 模型导出部署</h3><p>完成 QAT 精度调优后得到的模型仍是 PyTorch 模型，需要使用简单易用的接口来一步步导出编译成部署模型：<code>PyTorch模型 -&gt; export -&gt; convert-&gt; compile</code></p><blockquote>export 得到 qat.bc； convert 得到 quantized.bc； compile 得到 hbm</blockquote><p>由于导出生成物中计算差异的存在，对于每个生成物需简单验证其精度，可通过单张可视化或 mini 数据集，过程中如存在精度掉点，请参考&lt;u&gt;<a href="https://link.segmentfault.com/?enc=%2Bcd1LwQMjmOzVdWnY78KvA%3D%3D.DHU%2FcfzqSSqvyz5xh8bi3l0K0tRI7eOjcQdYYWJE%2B2xPhgq81dVE8JRriK0x%2Fb%2Fs" rel="nofollow" target="_blank">【地平线 J6 工具链进阶教程】J6 E/M 工具链 QAT 精度一致性问题分析流程</a>&lt;/u&gt;</p><h2>二.调优技巧</h2><h3>2.1 分部量化</h3><p>下面这种方式仅适用于 Calib 阶段，QAT 阶段因为模型已经适应了量化误差，关闭伪量化精度无法保证</p><pre><code class="Plain">from horizon_plugin_pytorch.utils.quant_switch import GlobalFakeQuantSwitch 
class Model(nn.Module):     
    def _init_(...):     
    def forward(self, x):         
        x = self.quant(x)         
        x = self.backbone(x)         
        x = self.neck(x)         
        GlobalFakeQuantSwitch.disable() # 使伪量化失效         # --------- float32 ---------         ​
        x = self.head(x)         
        # ---------------------------         ​
        GlobalFakeQuantSwitch.enable() # 重新打开伪量化         return self.dequant(x)</code></pre><h3>2.2 部分层冻结下的 QAT 训练</h3><p>模型 QAT 训练时，要求模型为 train（） 状态，此时若部分层冻结，则需要对应修改状态，参考代码如下：</p><pre><code class="Plain">from horizon_plugin_pytorch.quantization import (
    QuantStub,
    prepare,
    set_fake_quantize,
    FakeQuantState,)

qat_model = prepare(model, example_inputs=xxx, qconfig_setter=(xxx))
qat_model.load_state_dict("calib_model_ckpt.pth")

qat_model.train()# 关闭requires_grad可固定权重不更新，但Drop、BN仍然会更新for param in qat_model.backbone.parameters():
    param.requires_grad = False# 配置eval()可固定Drop、BN不更新，但不会固定权重，因此两者需要配合使用
qat_model.backbone.eval()
set_fake_quantize(qat_model.backbone, FakeQuantState.VALIDATION)#配置head的FakeQuant为QAT状态
set_fake_quantize(qat_model.head, FakeQuantState.QAT)</code></pre><h3>2.3 Calib/QAT 过程 NaN 值定位</h3><p>出现 NaN 值可通过下面的修改在 calib/qat forward 过程中报错，从而定位到具体的算子：</p><pre><code class="Plain">from horizon_plugin_pytorch.quantization.fake_quantize import FakeQuantize
FakeQuantize.check_nan_scale='forward'#默认为save，在torch.save时检查是否有nan，有nan会报错
qat_model = prepare(model, (input), default_qat_qconfig_setter)</code></pre><p>常见的可能出现 NaN 值的结构：</p><p>Multi-head Attention 的 attn mask，需要手动做数值的 clamp</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553086" alt="" title="" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[6 个步骤搞定系统设计面试 俞凡 ]]></title>    <link>https://segmentfault.com/a/1190000047553098</link>    <guid>https://segmentfault.com/a/1190000047553098</guid>    <pubDate>2026-01-20 13:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <blockquote><em>本文梳理了一套通过 6 个步骤清晰展示系统设计思维的应对框架，包括澄清需求、定义成功标准、画出高层架构、设计数据层，到扩展性与可靠性，最后考虑权衡取舍。</em></blockquote><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553100" alt="" title=""/></p><p>系统设计面试并不是考你会不会背各种技术名词，而是看你能不能在有限时间里，<strong>有条理的拆解问题、做出合理的架构决策，并把自己的思路讲清楚</strong>。</p><p><strong>面试的评分标准其实是“思考方式”，而不是“系统有多炫酷”</strong>。因此需要一套可重复执行的流程，把几十分钟的面试时间拆分成若干阶段，每一阶段回答一个明确的问题。</p><p>接下来就介绍这套能够帮助你顺利通过各种系统设计面试的框架。</p><hr/><h2>50 分钟作战计划</h2><p>下面是一份 50 分钟时间切片路线图：</p><pre><code>- 0–5 分钟：澄清需求
- 6–12 分钟：定义成功标准
- 13–22 分钟：画出高层架构
- 23–32 分钟：设计数据层
- 33–42 分钟：讨论扩展性与可靠性
- 43–50 分钟：收尾与权衡总结</code></pre><p>路线图可以按阶段展开，每个阶段都对应面试过程中呈现在白板或文档上的“可见成果”。</p><h5>阶段 1：先澄清再设计（0–5 分钟）</h5><p><strong>永远不要直接开始画图</strong>。第一步应该是：用问题把“题目”变成“需求”。</p><p>可以围绕以下维度澄清：</p><ul><li>用户与规模：有多少用户、日活？是 100 万还是 10 亿？</li><li>核心用例：最重要的 1～2 个场景是什么？例如仅做照片分享，还是要包含完整的社交功能？</li><li>客户端形态：只考虑移动端，还是移动 + Web？</li><li>地理分布：是否是全球分布，是否有多区域部署需求？</li><li>时延要求：例如“Feed 打开时间需要控制在 500ms 以内”。</li></ul><p>对于面试官抛出的“设计 Instagram”之类的问题，可以先反问：</p><blockquote>“我们是只关注图片流（Photo Feed），还是要覆盖整个产品？是否支持视频？大致用户量级是多少？”</blockquote><p><strong>这一阶段的目标</strong>：用 2–3 分钟让双方对“要构建的东西”达成共识，让后面的设计有清晰边界。</p><h5>阶段 2：写下什么叫“成功”（6–12 分钟）</h5><p>在澄清了范围之后，第二步是<strong>明确定义功能性和非功能性需求</strong>，包括：</p><ul><li>功能性需求：比如“用户可以上传图片、关注他人、看到关注对象的动态流、对内容点赞与评论”等；</li><li>非功能性需求：比如“高可用性（High Availability）达到 99.9%”、“Feed 加载延迟（Latency）小于 500ms”、“可以扩展到 1 亿日活用户”、“允许最终一致性（Eventual Consistency）”。</li></ul><p>把这些需求点<strong>写在白板上或共享文档中</strong>，就相当于和面试官形成了“设计合约”：后续所有架构选择，都要能解释清楚“这是为了满足哪条需求”。</p><p><strong>这一阶段的目标</strong>：让面试官看到你不是在“凭感觉设计”，而是在对齐“什么设计是成功的”。</p><h5>阶段 3：先画大图，再补细节（13–22 分钟）</h5><p>到了真正画架构图的时候，强调一个原则：<strong>先画大块（High-Level Components），再深入具体实现</strong>，而不是一开始就纠结字段、索引或具体中间件。</p><p>典型高层架构可以包括：</p><pre><code>┌─────────┐
│  Users  │
└────┬────┘
     │
     ↓
┌─────────────┐
│  CDN/Cache  │
└─────┬───────┘
      │
      ↓
┌──────────────┐      ┌──────────────┐
│ Load Balancer│─────→│ Load Balancer│
└──────┬───────┘      └──────┬───────┘
       │                     │
       ↓                     ↓
┌─────────────┐      ┌─────────────┐
│ API Servers │      │Media Service│
└──────┬──────┘      └──────┬──────┘
       │                    │
       ↓                    ↓
┌─────────────┐      ┌─────────────┐
│  Database   │      │Object Storage│
└─────────────┘      └─────────────┘</code></pre><ul><li>客户端（Mobile / Web）；</li><li>CDN（Content Delivery Network）和缓存（Cache），用于分发静态资源与热门内容；</li><li>负载均衡（Load Balancer），把流量分发到后端服务；</li><li>API 服务（API Servers），承载业务逻辑；</li><li>媒体服务（Media Service），负责图片/视频的处理与存储；</li><li>数据库（Database），保存用户、关系、元数据；</li><li>对象存储（Object Storage），保存实际的图片/视频文件。</li></ul><p>在讲解数据流时，可以用一句简短的“端到端路径”来串起来，例如：</p><pre><code>用户上传图片 → API 服务处理请求 → 媒体服务转码与压缩 
                            ↓
                        写入对象存储
                            ↓
                        在数据库中记录元数据
                            ↓
                        返回可访问 URL</code></pre><p><strong>这一阶段的目标</strong>：让面试官在脑中形成清晰的“系统鸟瞰图”，知道所有关键组件长什么样、怎么互相连接。此时还不必深入到每个组件内部实现。</p><h5>阶段 4：谈数据，而不是只谈服务（23–32 分钟）</h5><p>后半段时间建议重点放在“数据层设计”上，因为这最能体现工程判断力。</p><p>可以从以下几个维度展开：</p><ol><li><p>关系型数据库（SQL）还是非关系型数据库（NoSQL）？</p><ul><li>用户资料与关注关系这类强一致（ACID）需求高的场景，更适合用 SQL；</li><li>时间线 / Feed 这类读多写少、允许最终一致性的场景，更适合用可横向扩展的 NoSQL。</li></ul></li><li><p>数据模型与访问模式：</p><ul><li>例如关注关系可以用 <code>follows</code> 表建复合主键，避免重复关注；</li><li>Feed 可以预计算并按用户保存为去范式（Denormalized）结构，加快读取。</li></ul></li><li><p>缓存策略：</p><ul><li>缓存哪些内容：用户资料、热门内容、活跃用户 Feed 等；</li><li>为什么要缓存：相比直接查数据库，内存缓存（如 Redis）能把几十毫秒的查询压缩到几毫秒，在每秒上万请求的场景下能“挽救”大量数据库资源。</li></ul></li></ol><pre><code class="SQL">-- SQL 适用于用户与关注关系
CREATE TABLE users (
    user_id BIGINT PRIMARY KEY,
    username VARCHAR(50) UNIQUE,
    created_at TIMESTAMP
);

CREATE TABLE follows (
    follower_id BIGINT,
    followed_id BIGINT,
    created_at TIMESTAMP,
    PRIMARY KEY (follower_id, followed_id)
);</code></pre><pre><code class="json">// NoSQL (比如 Cassandra) 更适合
{
  user_id: "user_123",
  feed: [
    {post_id: "post_456", timestamp: 1634567890},
    {post_id: "post_789", timestamp: 1634567850}
  ]
}</code></pre><p><strong>这一阶段的目标</strong>：展示你能够根据访问模式选择合适的存储，并且讲清楚“为什么这样选”以及“放弃了什么”。</p><h5>阶段 5：把系统放进真实世界（33–42 分钟）</h5><p>系统上线后会面对流量波动、节点故障、网络抖动等各种现实问题。这个阶段要重点回答两个问题：</p><ul><li>当流量变成 10 倍时，系统如何扩展？</li><li>当部分组件失败时，系统如何优雅降级？</li></ul><p>可以从以下角度展开：</p><ul><li><p>水平扩展：</p><ul><li>应用服务前增加更多无状态实例，通过负载均衡分发；</li><li>数据库通过读写分离与只读副本承压。</li></ul></li><li><p>容错与高可用：</p><ul><li>复制：关键数据多副本存储；</li><li>熔断器：下游服务异常时快速失败并降级到缓存结果；</li><li>限流：防止恶意或异常流量；</li><li>优雅降级：尽量提供“部分可用”的体验，例如主功能可用、部分统计或推荐暂时不可用。</li></ul></li></ul><p>熔断器示例代码：</p><pre><code class="python">class CircuitBreaker:
    def __init__(self, threshold=5):
        self.failures = 0
        self.threshold = threshold
        self.state = "CLOSED"  # CLOSED, OPEN, HALF_OPEN
    
    def call(self, func):
        if self.state == "OPEN":
            return cached_response()
        
        try:
            result = func()
            self.failures = 0
            return result
        except Exception:
            self.failures += 1
            if self.failures &gt;= self.threshold:
                self.state = "OPEN"
            raise</code></pre><p>上面用简短的伪代码演示了熔断器（Circuit Breaker）如何在失败次数超过阈值时“打开”并立即返回缓存数据，面试中不必照搬代码，但可以用语言说明：<strong>自己理解“失败隔离”与“自我恢复”的重要性</strong>。</p><p><strong>这一阶段的目标</strong>：让面试官看到你不仅会“搭系统”，还能放到高并发、高故障率的真实环境里去思考。</p><h5>阶段 6：干净利落的收尾（43–50 分钟）</h5><p>最后 5～7 分钟，重点不是继续加新组件，而是：</p><ol><li><p>用 30～60 秒复述你的整体方案：</p><ul><li>系统主干架构；</li><li>关键技术选择（例如 SQL 用在用户与关系，NoSQL 用在 Feed，与 CDN 配合做全局分发）；</li><li>如何扩展与保证可靠性。</li></ul></li><li><p>主动点出几项关键权衡：</p><ul><li>比如“用 NoSQL 做 Feed，换来快速读取与易扩展，但牺牲了一些查询灵活性与强一致性”；</li><li>“预计算 Feed 提升打开速度，但增加了存储开销以及可能短时间内呈现旧数据的风险”。</li></ul></li><li><p>抛出开放性问题：</p><ul><li>例如：“如果需要，我可以进一步深入某个组件，比如 Feed 生成策略或多区域容灾，您更希望听哪一块？”</li></ul></li></ol><p><strong>这一阶段的目标</strong>：</p><ul><li>把零散的讨论收拢成结构清晰的故事；</li><li>让面试官感到“即使时间到了，这个人依然在有条理的思考权衡，而不是随意堆砌技术名词”。</li></ul><hr/><h2>真正的秘诀</h2><p>系统设计面试中<strong>不需要做的事情</strong>：</p><ul><li>不必一上来就报一堆云服务的品牌名；</li><li>不必急着切成复杂的微服务；</li><li>不必在一开始就画出所有细节；</li><li>不必给出“这个就是最佳方案”的结论。</li></ul><p>相反，更重要的是：</p><ul><li>从澄清问题开始，而不是从方案开始；</li><li>按阶段逐步搭建系统，而不是一口气抛出完整架构图；</li><li>所有选择都有理由，能讲出“为什么这样设计”；</li><li>诚实面对权衡，承认每个选择都有利有弊；</li><li>保持对话，主动和面试官互动，而不是独角戏式的画完就走。</li></ul><p>这也是为什么<strong>同一套技术栈，在不同候选人嘴里，呈现出的“成熟度”会完全不同</strong>：真正拉开差距的是“解释方案的方式”和“面对不确定性的态度”。</p><hr/><h2>行动清单</h2><p>下面是一份非常务实的练习建议，简要整理成可执行清单：</p><ol><li>选 5 个不同的系统设计题，用这套框架完整走一遍；</li><li>给自己计时，习惯在压力下也能按阶段推进；</li><li>录下自己的讲解过程，回看时关注“哪里讲得不清楚、哪里跳步太快”；</li><li>在练习中刻意练习“讲清楚权衡”的能力，而不是背标准答案；</li><li>面试时记住：对方要看的，是思考路径与沟通能力，而不是一张完美无缺的架构图。</li></ol><hr/><h2>要点回顾</h2><ul><li>系统设计面试考察的是结构化思维与沟通，而不是技术名词堆砌。</li><li>在面试过程中，可以用“澄清需求 → 定义成功 → 画大图 → 设计数据层 → 讨论扩展性与可靠性 → 收尾与权衡”这六个阶段来组织自己的输出。</li><li>数据层设计是展现工程判断的关键环节，要能结合访问模式解释 SQL / NoSQL、缓存与预计算等选择。</li><li>讨论扩展性与可靠性时，应从水平扩展、复制、限流、熔断与优雅降级等角度说明“系统如何在真实世界中生存”。</li><li>收尾阶段用简短复盘与权衡总结，把整场讨论串成一个完整故事，并主动邀请面试官选择可以进一步深入的部分。</li></ul><hr/><blockquote>Hi，我是俞凡，一名兼具技术深度与管理视野的技术管理者。曾就职于 Motorola，现任职于 Mavenir，多年带领技术团队，聚焦后端架构与云原生，持续关注 AI 等前沿方向，也关注人的成长，笃信持续学习的力量。在这里，我会分享技术实践与思考。欢迎关注公众号「DeepNoMind」，星标不迷路。也欢迎访问独立站 <a href="https://link.segmentfault.com/?enc=VznqZ3hUS0R%2FqK%2FVdKTuyQ%3D%3D.q%2BI7%2BsSSGVXO8ww4NJ0DzJOgU5T%2Btb9fbayFT53jvTE%3D" rel="nofollow" title="www.DeepNoMind.com" target="_blank">www.DeepNoMind.com</a>，一起交流成长。</blockquote><p>本文由<a href="https://link.segmentfault.com/?enc=1%2BzBhKO4sIbBq721OoM0ww%3D%3D.5HXWUNA2H6Wh1zHPGvl%2BrrcjrR46rkCgAPtS%2BEYbbAo%3D" rel="nofollow" target="_blank">mdnice</a>多平台发布</p>]]></description></item><item>    <title><![CDATA[告别知识流失：一份关于全原子化经验归档工具必要性的白皮书式解析 Ord1naryLife ]]></title>    <link>https://segmentfault.com/a/1190000047552758</link>    <guid>https://segmentfault.com/a/1190000047552758</guid>    <pubDate>2026-01-20 12:07:33</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2><strong>原子化经验归档工具：逻辑架构与知识资产闭环的技术实践</strong></h2><p>在现代知识型组织中，企业的核心竞争力正从“信息堆砌”向“原子化知识复用”转移。原子化经验归档工具不仅是项目结束后的资料库，更是将复杂的业务过程通过解构化的数据存储，转化为可检索、可调用的动态智力资产的架构引擎。</p><h4><strong>一、 为什么现代管理必须重视“原子化”归档？</strong></h4><p>缺乏有效归档工具的组织往往陷入“信息孤岛”困境：成功经验散落在聊天记录或个人电脑中，无法被精准检索，且历史教训无法有效沉淀至组织的共享库。原子化经验归档工具的核心价值在于：</p><ul><li><strong>消除检索冗余</strong>：通过全量知识的结构化拆解，确保归档基于独立的经验单元，而非冗长且难以翻阅的文档。</li><li><strong>支撑精准知识调用</strong>：支持在归档过程中下钻具体动作，应对不同部门、不同场景的细分知识获取需求。</li><li><strong>实现经验自动分类</strong>：无需人工手动打标签，各阶段的产出物、决策逻辑自动向知识图谱聚合，辅助未来执行。</li><li><strong>经验产出资产化</strong>：将验证有效的操作步骤沉淀为原子化模块，实现跨团队、跨项目的瞬间经验迁移。</li></ul><h4>---</h4><p><strong>二、 原子化归档的技术路径：三层解构架构</strong></p><p>构建原子化经验归档体系需要遵循“深度拆解”与“语义关联”的逻辑：</p><ol><li><strong>宏观案例层（Case Context）</strong>：定义归档的业务背景、原始需求及最终产出全景（如某营销案例、技术攻关记录）。</li><li><strong>原子节点层（Atomic Nodes）</strong>：将业务路径拆解为关键决策点，各节点记录当时的逻辑背景、资源投入与实际效果。</li><li><strong>颗粒行为层（Granular Insights）</strong>：归档的最末端，聚焦于单一动作的优劣，具备明确的避坑指南和标准化应用说明。</li></ol><h4>---</h4><p><strong>三、 核心技术实现与算法示例</strong></p><p>原子化经验归档工具的底层逻辑涉及知识权重算法、相似性趋势捕捉及递归式数据结构。</p><h5><strong>1. 基于加权算法的原子经验价值评分</strong></h5><p>在原子化归档中，每一条经验的复用价值由其执行质量和适配度自动驱动。以下为 JavaScript 实现的经验价值评分逻辑：</p><p>JavaScript</p><p>/**  <br/> * 根据复用表现自动计算原子经验价值得分  <br/> * @param {Object} archive 归档对象（包含子经验单元数组）  <br/> * @returns {number} 聚合后的经验价值综合得分  <br/> */  <br/>function calculateKnowledgeValue(archive) {</p><pre><code>// 基准情况：如果是末端行为项，返回其标准化达成度（0-100）  
if (\!archive.subUnits || archive.subUnits.length \=== 0) {  
    return archive.standardizationRate || 0;  
}

// 汇总所有原子节点的加权得分  
const totalWeightedScore \= archive.subUnits.reduce((sum, unit) \=\&gt; {  
    // 每个单元可根据其实战参考性分配权重  
    const weight \= unit.referenceWeight || (1 / archive.subUnits.length);  
    return sum \+ (calculateKnowledgeValue(unit) \* weight);  
}, 0);

// 更新案例的原子化归档显示  
archive.totalValue \= Math.round(totalWeightedScore);  
return archive.totalValue;  </code></pre><p>}</p><h5><strong>2. Python：归档内容偏离度的动态检测引擎</strong></h5><p>利用经验模型，自动对比“标准SOP”与“实际执行路径”，识别出导致结果波动的关键变量：</p><p>Python</p><p>class KnowledgeAuditEngine:</p><pre><code>def \_\_init\_\_(self):  
    \# 预设标准经验库：归档类型 \-\&gt; 预期质量/步骤基准  
    self.benchmarks \= {  
        "Content\_Marketing": {  
            "Topic": {"quality": 90, "steps": 5},  
            "Draft": {"quality": 85, "steps": 3},  
            "Publish": {"quality": 95, "steps": 2}  
        }  
    }

def analyze\_consistency(self, archive\_data, archive\_type):  
    """对比实际记录与基准，识别归档亮点与坑点"""  
    standards \= self.benchmarks.get(archive\_type)  
    if not standards:  
        return "未找到匹配的原子化归档基准"

    for unit, actual in archive\_data.items():  
        benchmark \= standards.get(unit)  
        if benchmark:  
            quality\_deviation \= (actual\['quality'\] \- benchmark\['quality'\]) / benchmark\['quality'\]  
            if quality\_deviation \&lt; \-0.10:  
                print(f"\[Archive Alert\] 单元 '{unit}' 存在效能损失，建议标注为'风险预警'")  
                \# 自动触发避坑指南生成  
                self.\_generate\_pitfall\_guide(unit)

def \_generate\_pitfall\_guide(self, unit\_name):  
    print(f"  \-\&gt; 已生成 '{unit\_name}' 环节的原子化避坑说明")
</code></pre><h5><strong>3. SQL：跨项目知识瓶颈识别与经验溯源</strong></h5><p>通过递归查询，识别组织中长期存在的“重复踩坑”或“高价值原子经验”：</p><p>SQL</p><p>WITH RECURSIVE ArchiveHierarchy AS (</p><pre><code>\-- 初始行：选择需要归档的顶层案例  
SELECT id, case\_name, parent\_id, value\_score, archive\_date   
FROM atomic\_archives WHERE parent\_id IS NULL  
UNION ALL  
\-- 递归关联各层级子单元的归档数据  
SELECT a.id, a.case\_name, a.parent\_id, a.value\_score, a.archive\_date  
FROM atomic\_archives a  
INNER JOIN ArchiveHierarchy ah ON a.parent\_id \= ah.id  </code></pre><p>)  <br/>SELECT</p><pre><code>case\_name,   
AVG(value\_score) as avg\_value,  
COUNT(\*) as reuse\_count  </code></pre><p>FROM ArchiveHierarchy  <br/>GROUP BY case\_name  <br/>HAVING avg\_value \&gt; 85 -- 识别高质量、值得大规模推广的原子经验领域  <br/>ORDER BY avg\_value DESC;</p><h4>---</h4><p><strong>四、 工具分类与选型思路</strong></p><p>在实施原子化经验归档时，不同架构的工具侧重点有所不同：</p><table><thead><tr><th align="left">工具</th><th align="left">优势亮点</th></tr></thead><tbody><tr><td align="left"><strong>板栗看板</strong></td><td align="left">支持卡片式原子化经验管理，可视化关联关系，便于知识重组</td></tr><tr><td align="left"><strong>Obsidian</strong></td><td align="left">强大的双向链接功能，支持本地知识图谱构建</td></tr><tr><td align="left"><strong>Notion</strong></td><td align="left">灵活的数据库结构，适合构建结构化的经验知识库</td></tr><tr><td align="left"><strong>Roam Research</strong></td><td align="left">独特的块引用机制，支持细粒度知识关联</td></tr><tr><td align="left"><strong>Tettra</strong></td><td align="left">专为团队知识管理设计，集成问答和工作流功能</td></tr></tbody></table><h4>---</h4><p><strong>五、 实施中的风险控制与管理优化</strong></p><ul><li><strong>防止“形式化归档”</strong>：如果归档成了行政负担，会导致员工敷衍。应遵循“归档即为复用”的工具导向。</li><li><strong>确保经验调用闭环</strong>：归档发现的优质经验必须自动推荐给相似任务的负责人，防止经验在数据库中尘封。</li><li><strong>动态调整归档标准</strong>：随着组织认知的提升，原子化归档的价值判定基准应定期重新对标，驱动知识库持续进化。</li></ul><h4>---</h4><p><strong>六、 结语</strong></p><p><strong>原子化是知识资产化的必经之路。</strong> 原子化经验归档工具不仅通过技术手段解决了“经验散乱”的问题，更将组织的每一次经历转化为可以指导未来执行、降低认知成本的有效资产。当组织的每一份经验都能以原子化的形式精准调用时，企业才能真正实现从“重复发明轮子”向“站在经验肩膀上前进”的本质跨越。</p>]]></description></item><item>    <title><![CDATA[飞书联手安克发布首款硬件 AI 录音豆；ElevenLabs 新一轮融资估值或达 110 亿美元丨日]]></title>    <link>https://segmentfault.com/a/1190000047552904</link>    <guid>https://segmentfault.com/a/1190000047552904</guid>    <pubDate>2026-01-20 12:07:00</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047552906" alt="" title=""/></p><p><strong>开发者朋友们大家好：</strong></p><p>这里是 <strong>「RTE 开发者日报」</strong> ，每天和大家一起看新闻、聊八卦。我们的社区编辑团队会整理分享 RTE（Real-Time Engagement） 领域内「有话题的<strong>技术</strong>」、「有亮点的<strong>产品</strong>」、「有思考的<strong>文章</strong>」、「有态度的<strong>观点</strong>」、「有看点的<strong>活动</strong>」，但内容仅代表编辑的个人观点，欢迎大家留言、跟帖、讨论。</p><p><em>本期编辑：@瓒an、@鲍勃</em></p><h2>01 有话题的技术</h2><p><strong>1、无界方舟 AutoArk-AI 发布 GPA 语音大模型：0.3B 轻量化架构实现 ASR/TTS/VC 统一建模</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047552907" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047552908" alt="" title="" loading="lazy"/></p><p>在克隆参考音频样本的音色的同时，从文本合成语音。</p><p>无界方舟 AutoArk-AI 正式推出通用音频模型「GPA」。该模型基于统一的<strong>自回归 Transformer 架构</strong>，在单一的大语言模型框架下，<strong>集成了语音识别（ASR）、语音合成（TTS）和语音转换（VC）三大核心任务</strong>。</p><p>该模型的设计初衷在于改变传统语音系统碎片化的 Pipeline 设计模式。通过 0.3B 的轻量化参数量级，GPA 旨在<strong>实现端侧的高效部署以及跨任务的泛化能力</strong>。</p><p>在技术架构上，GPA 放弃了任务特定的输出头，转而<strong>采用统一的离散音频 Token 空间</strong>。这一设计将理解、生成与编辑任务收敛至单一自回归模型中，从而减少了跨任务处理过程中的性能损耗。</p><p>交互方式上，模型<strong>采用指令驱动机制</strong>，通过文本指令来引导任务行为。它支持零样本语音克隆，用户无需调整架构或进行针对性微调，即可在 ASR、TTS 和 VC 之间进行动态切换。</p><p>针对边缘计算场景，官方<strong>提供了优化的 0.3B 参数版本</strong>。该版本兼容性广泛，支持 vLLM、llama.cpp、SGLang、MLX-LM 以及端侧硬件框架 RKNN。</p><p>在流式推理的延迟指标方面，测试数据显示：在 TTS 任务中，单并发平均 TTFC（首包延迟）为 258.8ms，RTF（实时率）为 0.197；在 ASR 任务中，单并发平均 TTFT（首 Token 延迟）为 157.5ms，能够支持高并发吞吐场景。</p><p>在性能对标测试中，针对中文 SEED 数据集的 TTS 零样本测试显示，GPA-0.3B 的 CER（字符错误率）为 0.95%。数据显示，该成绩优于同参数量级的 F5-TTS 模型。</p><p>目前，该模型的代码已开源，相关论文与 Demo 即将上线。使用许可方面，模型目前仅供学术研究与个人教育使用。</p><p>GitHub: <br/><a href="https://link.segmentfault.com/?enc=tBobQtnfZ9JlxoQ8zijPag%3D%3D.jEH8uhoH8K3W45%2FCZQ03xrz6PoEDNPcqu0iKCKhr4Ns%3D" rel="nofollow" target="_blank">https://github.com/AutoArk/GPA</a></p><p>( @GitHub)</p><p><strong>2、ElevenLabs 洽谈新一轮融资：估值或达 110 亿美元，有望成英国最有价值 AI 初创公司</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047552909" alt="" title="" loading="lazy"/></p><p>据英国《金融时报》报道，AI 语音生成公司 ElevenLabs 正洽谈新一轮融资，计划从投资者处募集数亿美元资金。若交易达成，<strong>其估值或将在数月内翻倍至 110 亿美元</strong>。</p><p>这一跃升将使 ElevenLabs 超越估值约 80 亿美元的自动驾驶公司 Wayve，<strong>成为英国最有价值的人工智能初创公司</strong>；同时，也将使其跻身欧洲顶尖行列，逼近法国 AI 模型公司 Mistral 约 120 亿美元的估值水平。</p><p>此次融资谈判距离公司上一次二级股份出售仅过去四个月，当时的估值为 66 亿美元。据悉，目前的会谈<strong>仍处于早期阶段</strong>，具体情况可能存在变数。</p><p>ElevenLabs 于 2022 年由波兰企业家 Mati Staniszewski 和 Piotr Dabkowski 在伦敦创立，目前已获得红杉资本（Sequoia）、Iconiq、Andreessen Horowitz、NEA 及 FT Ventures 等多家知名风投机构的支持。为了便于获取美国资本，公司已在美国注册，并在伦敦和纽约设有双总部。</p><p>在业务层面，ElevenLabs 专注于利用 AI 生成逼真的语音，广泛应用于客服、文本转语音及多语言配音等场景。公司业绩增长迅猛，去年年度经常性收入（ARR）已达到 3.3 亿美元，较 9 月份公布的 2 亿美元有显著提升。</p><p>宏观来看，尽管全球投资者对 AI 初创企业的兴趣持续高涨，但欧洲公司在募资规模上仍滞后于美国。作为对比，美国巨头 OpenAI 据传估值已达 5000 亿美元，并正商谈最高达 800 亿美元的新一轮融资，投后估值可能突破 8000 亿美元。</p><p>( @Benchmark Studio)</p><p><strong>3、红杉资本「覆盖赛道」押注 Anthropic，新一轮融资目标约 250 亿美元，预计最快今年 IPO</strong></p><p>据《金融时报》报道，<strong>红杉资本计划加入对 AI 初创公司 Anthropic 的新一轮重磅融资</strong>。此举打破了风险投资界通常避免在同一领域支持竞争对手的传统惯例，因为红杉此前已同时投资了 OpenAI 和埃隆·马斯克的 xAI。</p><p><strong>本轮融资由新加坡政府投资公司（GIC）和美国投资机构科图（Coatue）领投。</strong> 据报道，两家机构各出资 150 亿美元。Anthropic 计划以 3500 亿美元的估值筹集 250 亿美元或更高资金，这一估值较四个月前的 1700 亿美元已翻了一番以上。此外，微软和英伟达据称已承诺共同出资最高 1500 亿美元。</p><p>红杉此次的投资时机颇受外界关注。OpenAI CEO 萨姆·奥尔特曼此前曾明确表示，虽然不禁止投资者投资竞品，但若投资者对竞争对手进行「非被动投资」，其接触 OpenAI 机密信息的权限将被终止。</p><p><strong>尽管面临潜在的利益冲突，红杉仍选择进一步深化在 AI 领域的布局。</strong> 此前，红杉不仅支持了奥尔特曼创立的 Loopt 和其引荐的 Stripe，也通过投资 xAI、X、SpaceX 及 Neuralink 等公司与马斯克建立了广泛联系。</p><p>这一策略转变发生在该机构经历戏剧性的管理层变动之后。近期，红杉全球掌门人罗洛夫·博塔（Roelof Botha）离职，由林君睿（Alfred Lin）和帕特·格拉迪（Pat Grady）接手。这种多点押注的策略，与 2020 年红杉因利益冲突而放弃 Finix（Stripe 竞对）投资的历史立场形成了鲜明对比。</p><p>此外，报道还透露，Anthropic 正在积极筹备首次公开募股（IPO），最快可能在今年年内进行。</p><p>( @Z Potentials、@TechCrunch)</p><p><strong>4、NVIDIA 发布 PersonaPlex：基于 Moshi 架构的 7B 全双工对话模型，支持混合 Prompt 定制</strong></p><p>NVIDIA ADLR 团队近日正式发布了 PersonaPlex，<strong>这是一个参数量为 7B 的原生全双工语音对话模型</strong>。该模型通过摒弃传统的 ASR→LLM→TTS 级联架构，<strong>实现了超低延迟的实时语音交互，并着重解决了全双工模型在角色与音色自定义方面的局限性</strong>。</p><p>在架构设计上，PersonaPlex 基于 Kyutai 的 Moshi 架构及 Helium 语言模型构建，并采用了 24kHz 采样率的 Mimi 神经音频编解码器。该架构支持模型同时处理音频输入流与输出流，从而具备了实时打断、背向渠道（Backchanneling，如「嗯」、「噢」）以及自然的轮替节奏等全双工特性。</p><p><strong>为了提升定制化能力，模型引入了混合提示机制。</strong> 该机制包含双路输入控制：通过音频嵌入提取参考音频的声学特征，以控制发音风格与韵律；同时利用文本指令来定义角色的设定、背景知识及交互逻辑。</p><p><strong>在训练数据方面，团队采用了脱耦与融合策略。</strong>模型使用了 1,217 小时的 Fisher English 真实对话语料来学习打断、情绪反馈等交互行为，并结合了约 2,250 小时由 Qwen3-32B 和 Chatterbox TTS 生成的合成数据，以强化指令遵循能力。</p><p>评测结果显示，在 FullDuplexBench 及新增的 ServiceDuplexBench 测试中，PersonaPlex 在顺滑轮替和暂停处理等指标上优于 Gemini 2.0 Flash Live 等商业模型。此外，在未见过的极端场景（如太空紧急状况响应）中，模型也<strong>展现出了技术推理与情绪同步能力</strong>。</p><p>目前，该项目的代码采用 MIT 开源协议，模型权重则采用 NVIDIA Open Model License 协议。相关的测试集 ServiceDuplexBench 也将于近期开放。</p><p>HuggingFace: </p><p><a href="https://link.segmentfault.com/?enc=X24Gm9zcR4f41d1Ad6UgpA%3D%3D.t70XMUbbvnLfwuVIN3Q7yQHCEGv1Jg%2B5AE3DwWdNrv7LBjTG5k0wEl8kR9LlLLsZ" rel="nofollow" target="_blank">https://huggingface.co/nvidia/personaplex-7b-v1</a></p><p>( @NVIDIA ADLR Blog)</p><h2>02有亮点的产品</h2><p><strong>1、飞书发布首款硬件「AI 录音豆」：联手安克创新，争夺更近的上下文入口</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047552910" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047552911" alt="" title="" loading="lazy"/></p><p>据「智能涌现」报道，飞书联合安克创新发布<strong>首款智能硬件产品「AI 录音豆」</strong>，这也是飞书自 2017 年成立以来的首次硬件尝试。该产品被定义为飞书内部的探索性项目，由飞书团队负责软件部分的研发。</p><p>在此次合作中，飞书团队主要负责软件层面的研发。该设备通过极轻量化的设计捕捉物理场景语音，并结合豆包大模型，<strong>旨在实现办公上下文的自动化沉淀与结构化处理</strong>。</p><p>在硬件形态上，AI 录音豆<strong>单体重量仅为 10g</strong>，含充电仓总重 48g，内部搭载了双 MEMS 麦克风阵列。产品采用了豆状设计，支持背夹或磁吸佩戴。这一设计旨在降低录音过程中的仪式感，以便更好地覆盖通勤、拜访等碎片化使用场景。</p><p>在续航与存储配置方面，配合充电舱使用，该设备可提供 <strong>32 小时的总续航时间</strong>，并支持快充技术，充电 10 分钟即可录音 2 小时。机身内置 <strong>8GB 存储空间</strong>，可存储约 250 小时音频，并支持蓝牙与 Wi-Fi 双模式传输。</p><p>核心功能方面，设备内置了豆包大模型，<strong>支持实时多模态纪要</strong>。具体能力涵盖发言人识别、待办事项自动提取以及柱状图等图例的可视化生成，用户可在录音过程中实时查看 AI 总结。</p><p>此外，该产品实现了与飞书生态的闭环打通。录音内容会自动沉淀至飞书知识库，用户随后可通过 AI 助手，以自然语言交互的方式对历史音频记录进行语义检索、提问及二次创作。</p><p>目前，该产品被定位为飞书内部的探索性项目，具体定价及正式发售日期暂未披露。</p><p>（@36 氪）</p><p><strong>2、银河通用发布重载机器人 Galbot S1：50kg 双臂负载突破瓶颈，零遥操切入核心产线</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047552912" alt="" title="" loading="lazy"/></p><p>「银河通用」正式发布工业级具身智能重载机器人「Galbot S1」。该机器人实现了 50kg 的双臂持续作业负载，并搭载全自主、零遥操的「具身搬运模型」。目前，产品已成功进入宁德时代等头部企业的核心产线，承担重型物料搬运及部件装配任务。</p><p>在负载能力上，Galbot S1 实现了显著突破。<strong>它拥有 50kg 的双臂持续负载能力</strong>，不仅对标人力搬运的极限，更突破了具身智能机器人普遍低于 10kg 的负载瓶颈，有效填补了轻型协作机器人与大型固定吊装设备之间的重载作业空白。</p><p>技术层面，该机器人采用了<strong>全自主的具身搬运模型</strong>。基于纯视觉感知方案，Galbot S1 无需依赖二维码或反光板等外部标记，即可支持动态光照、局部遮挡及人机混行等复杂工况，实现了零遥操下的端到端作业。</p><p>针对工业环境的适配性，整机具备 IP54 防水防尘等级，作业高度覆盖 0 至 2.3 米区间，能够适配从地面物料到高位货架的全场景搬运需求。</p><p>在续航与安全性方面，Galbot S1 支持 8 小时单次续航及自主换电功能，可实现 7×24 小时连续运转。同时，系统配备了毫秒级安全响应机制与 360° 全向避障能力，确保作业安全。</p><p>此外，银河通用通过在宁德时代、博世、丰田等真实产线的长期运行，构建了场景数据闭环，持续强化具身智能大脑在严苛节拍下的稳定性。</p><p>目前，公司已完成 21 亿元融资，估值突破 200 亿元，正积极推进千台级的工业部署。</p><p>（@量子位）</p><p><strong>3、全球首个全年龄段覆盖，京东京造第二批 AI 玩具上线</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047552913" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047552914" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047552915" alt="" title="" loading="lazy"/></p><p>近日，京东京造正式宣布上线第二批自研 AI 玩具。此次发布的新品在此前针对儿童开发的陪伴玩具基础上，进一步推出了面向年轻人及老年群体的 AI 玩具，<strong>实现了全球首个全年龄段用户需求的覆盖</strong>。</p><p>京东 JoyInside 为硬件注入了<strong>「长期记忆」与「情境感知」能力</strong>，能够理解对话的上下文，也成为首个根据不同年龄段用户的偏好与习惯进行优化的系统平台。</p><p>这项能力被深度应用于不同年龄层的需求设计中：系统能识别婴幼儿的哭声并给予安抚，为儿童提供启蒙引导并识别潜在风险，与年轻人进行有深度的主题聊天，也能用方言陪伴老年人，并关注他们的健康与社交需求。</p><p>回顾市场表现，首批 AI 玩具上市后，被用户视为「游戏搭子」、「情绪树洞」及「知识导师」，在帮助儿童减少电子屏幕依赖方面发挥了作用。数据显示，接入 JoyInside 的智能硬件平均对话轮次提升超过 120%，多款产品上线即售罄，且保持了极低的退货率。</p><p>截至目前，京东 JoyInside 已携手<strong>超过 40 家硬件品牌</strong>，涵盖 AI 玩具、机器人等品类。</p><p>（@IT 之家、@京东黑板报）</p><h2>03有态度的观点</h2><p><strong>1、DeepMind CEO：AGI 5-10 年内实现</strong></p><p>日前，Google DeepMind CEO Demis Hassabis 接受了 CNBC 的节目采访，与主持人共同讨论了缩放定律的重要性以及发展通用人工智能（AGI）的持续追求。</p><p>Demis 表示，自己依然认为 5 到 10 年内 AGI 能得以实现。</p><p>其指出，包括 AI 在内的 AGI 将涉及 LLMs 和世界模型的组合，而不是一个组件取代另一个组件。</p><p>Demis 认为，AI 可能需要更好的推理、长期规划和 「世界模型」 的概念，以更好地理解物理学并进行模拟，反映人类科学家的工作。其也强调，除了世界模型之外，AGI 可能还需要其他类型的技术和能力。</p><p>同时他也表示，为了使 AI 在科学能力方面取得进步，它需要能够提出新的假设和想法，而不仅仅是解决现有的猜测。</p><p>( @APPSO)</p><h2>04社区黑板报</h2><p>招聘、项目分享、求助……任何你想和社区分享的信息，请联系我们投稿。（加微信 creators2022，备注「社区黑板报」）</p><p><strong>1、招聘 AI Agent 开发工程师</strong></p><p><strong>22-35K·13 薪深圳  5-10 年  本科</strong></p><p>岗位职责：</p><ol><li>负责 AIAgent 系统的架构设计与工程实现，包括智能体的任务规划、决策逻辑、工具调用以及记忆管理等核心模块。</li><li>深入集成与优化大语言模型（LLM），通过提示工程、微调等技术路径，持续提升 AI 助手的对话质量、逻辑推理能力及任务执行准确性。</li><li>为 AI 助手连接并管理各类外部工具与 API（如搜索、数据库、第三方服务），构建其实际解决问题的能力，同时确保执行过程的安全与可控。</li><li>建立针对 AI 助手性能的评估、监控与迭代闭环，通过数据分析驱动产品体验的持续优化。5.编写高质量、可维护的代码，并将 AIAgent 系统部署至生产环境，保障其高可用性与低延迟。</li></ol><p>任职要求：</p><ol><li>计算机科学、软件工程或相关专业本科及以上学历，具备 3 年以上后端或 1 年以上 AI 应用开发经验。</li><li>熟悉 PyTorch、TensorFlow 等主流深度学习框架，具备扎实的工程能力和良好的编码习惯。</li><li>对大语言模型及 AIAgent 技术栈有深入理解和实际项目经验。</li><li>拥有强烈的产品意识和用户同理心，关注技术落地对用户体验的实际影响，具备优秀的数据分析能力和问题解决技能。</li><li>有成功的 ToC 互联网产品或 AI 产品（如智能助手、对话机器人）开发及上线经验者优先。</li></ol><p>联系人：李先生</p><p>联系方式：<a href="mailto:26905841@qq.com" target="_blank">26905841@qq.com</a></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047552916" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047552917" alt="" title="" loading="lazy"/></p><p><a href="https://link.segmentfault.com/?enc=2YEeWr9g7wrIcPldtWy8ig%3D%3D.vk8k3079iWcAnR1foN3CTSkWW24307dHVORHpYKGN4U%3D" rel="nofollow" target="_blank">阅读更多 Voice Agent 学习笔记：了解最懂 AI 语音的头脑都在思考什么</a></p><p><strong>写在最后：</strong></p><p>我们欢迎更多的小伙伴参与 <strong>「RTE 开发者日报」</strong> 内容的共创，感兴趣的朋友请通过开发者社区或公众号留言联系，记得报暗号「共创」。</p><p>对于任何反馈（包括但不限于内容上、形式上）我们不胜感激、并有小惊喜回馈，例如你希望从日报中看到哪些内容；自己推荐的信源、项目、话题、活动等；或者列举几个你喜欢看、平时常看的内容渠道；内容排版或呈现形式上有哪些可以改进的地方等。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047552918" alt="" title="" loading="lazy"/></p><p>作者提示：个人观点，仅供参考</p>]]></description></item><item>    <title><![CDATA[LangChain官方文档"Memory"章节 AIAgent研究 ]]></title>    <link>https://segmentfault.com/a/1190000047552934</link>    <guid>https://segmentfault.com/a/1190000047552934</guid>    <pubDate>2026-01-20 12:06:12</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>一、核心概念</h2><h3>1.1 什么是Memory？</h3><p>Memory是LangChain框架中负责<strong>维护Chain状态并整合过去运行上下文</strong>的核心组件。默认情况下，所有链式模型和代理模型都是<strong>无状态的</strong>（独立处理每个查询，不保留历史信息），而在对话系统等场景中，记住先前交互至关重要，Memory正是为此设计的。</p><h3>1.2 Memory的基本操作</h3><p>Memory系统支持两个核心操作：</p><ul><li><strong>读取(Load)</strong>：在Chain执行前，从记忆中获取历史信息，增强用户输入</li><li><strong>写入(Save)</strong>：在Chain执行后，将当前输入/输出保存到记忆中，供后续使用</li></ul><h3>1.3 内存的分类</h3><p>LangChain将内存分为两大类：</p><ul><li><strong>短期内存(Short-term memory)</strong>：线程范围内存，追踪当前对话，在会话结束后通常会被清除</li><li><strong>长期内存(Long-term memory)</strong>：跨会话存储，可在任意线程中随时访问，通常需要配置持久化存储</li></ul><h2>二、Memory类体系结构</h2><h3>2.1 核心类层次</h3><pre><code>BaseMemory
├── BaseChatMemory
│   ├── ConversationBufferMemory
│   ├── ConversationBufferWindowMemory
│   ├── ConversationSummaryMemory
│   ├── ConversationSummaryBufferMemory
│   ├── ConversationEntityMemory
│   └── ConversationKGMemory
└── VectorStoreRetrieverMemory</code></pre><p><em>注：完整列表可参考<a href="https://link.segmentfault.com/?enc=wE6MlMhScEuAZkFJfKxZ1A%3D%3D.3nlkOuQwS8X918mSxxdSs8dYEgt6lps2r31KzjWoTrAJ64aexWIq9%2FOC31LNDMzXvX8mmtxWE8D%2FmnE9qNBoh8BD5Y%2BHvsqEjcpkI4BONAg%3D" rel="nofollow" target="_blank">API文档</a></em></p><h3>2.2 BaseMemory接口（所有内存的基类）</h3><p>所有内存类必须实现以下抽象方法：</p><ul><li><code>load_memory_variables(inputs: Dict[str, Any]) -&gt; Dict[str, Any]</code>：加载内存变量，返回一个字典</li><li><code>save_context(inputs: Dict[str, Any], outputs: Dict[str, str]) -&gt; None</code>：保存当前运行的上下文到内存</li><li><code>clear() -&gt; None</code>：清除内存内容</li></ul><h2>三、内置Memory类型详解</h2><h3>3.1 ConversationBufferMemory（基础对话缓冲内存）</h3><p><strong>特点</strong>：简单存储完整对话历史，返回字符串格式的历史内容</p><pre><code class="python"># 使用示例
from langchain.memory import ConversationBufferMemory
memory = ConversationBufferMemory(memory_key="chat_history")
memory.chat_memory.add_user_message("Hi!")
memory.chat_memory.add_ai_message("Hello!")
print(memory.load_memory_variables({}))  # 输出: {'chat_history': 'Human: Hi!\nAI: Hello!'}</code></pre><h3>3.2 ConversationBufferWindowMemory（对话窗口缓冲内存）</h3><p><strong>特点</strong>：只保留最近k轮对话，适合<strong>高频短对话场景</strong>，避免内存溢出</p><pre><code class="python"># 使用示例（只保留最近2轮）
memory = ConversationBufferWindowMemory(k=2, memory_key="history")</code></pre><h3>3.3 ConversationSummaryMemory（对话摘要内存）</h3><p><strong>特点</strong>：使用LLM自动生成对话摘要，<strong>减少token占用</strong>，适合长对话场景</p><pre><code class="python"># 使用示例
from langchain.llms import OpenAI
from langchain.memory import ConversationSummaryMemory
llm = OpenAI(temperature=0)
memory = ConversationSummaryMemory(llm=llm, memory_key="history")</code></pre><h3>3.4 ConversationSummaryBufferMemory（对话摘要+缓冲混合内存）</h3><p><strong>特点</strong>：结合上述两种内存优点，<strong>近期消息保留原文</strong>，<strong>久远内容使用摘要</strong>，平衡信息完整性与内存效率</p><h3>3.5 ConversationEntityMemory（实体内存）</h3><p><strong>特点</strong>：专注于<strong>识别和存储对话中的实体</strong>（如人名、组织、地点）及其属性，适合个性化助手场景，让AI真正"认识"用户</p><h3>3.6 ConversationKGMemory（知识图谱内存）</h3><p><strong>特点</strong>：构建<strong>对话知识图谱</strong>，将对话中的实体关系结构化（如"张三是产品经理"、"李华在杭州工作"），适合需要<strong>关系推理</strong>的复杂问答系统</p><h3>3.7 VectorStoreRetrieverMemory（向量存储内存）</h3><p><strong>特点</strong>：将对话历史存储为<strong>向量嵌入</strong>到向量数据库（如Pinecone、Chroma、FAISS），通过<strong>语义相似度检索</strong>相关历史，适合<strong>大规模知识库</strong>集成和<strong>长期记忆</strong>场景</p><h2>四、ChatMessageHistory：底层消息存储机制</h2><h3>4.1 基本概念</h3><p><code>ChatMessageHistory</code>是LangChain中负责<strong>管理和操作聊天消息</strong>的底层工具类，是几乎所有对话内存的基础支撑。它提供了简单接口来添加用户/AI消息并获取完整消息列表。</p><pre><code class="python"># 使用示例
from langchain.memory import ChatMessageHistory
history = ChatMessageHistory()
history.add_user_message("Hello")
history.add_ai_message("Hi there!")
print(history.messages)  # 输出消息列表</code></pre><h3>4.2 消息存储选项</h3><p>ChatMessageHistory支持多种存储后端：</p><ul><li><strong>内存存储</strong>（默认）：临时存储，应用重启后丢失</li><li><strong>Redis存储</strong>：分布式持久化存储，适合生产环境</li><li><strong>文件存储</strong>：简单本地文件持久化</li><li><strong>数据库存储</strong>：SQL或NoSQL数据库集成</li><li><strong>自定义存储</strong>：实现<code>BaseChatMessageHistory</code>接口的自定义方案</li></ul><h2>五、在Chain中使用Memory</h2><h3>5.1 基本集成方法</h3><p>将内存集成到Chain中通常需要以下步骤：</p><ol><li><strong>创建Memory实例</strong>：选择合适的内存类型并配置参数</li><li><strong>将Memory传递给Chain</strong>：在初始化Chain时设置<code>memory</code>参数</li><li><strong>在Prompt中引用内存变量</strong>：确保Prompt模板包含内存返回的变量名</li></ol><pre><code class="python"># LLMChain使用示例
from langchain.llms import OpenAI
from langchain.chains import LLMChain
from langchain.memory import ConversationBufferMemory
from langchain.prompts import PromptTemplate

llm = OpenAI(temperature=0)
prompt = PromptTemplate(
    template="Previous conversation: {chat_history}\nNew question: {question}\nAnswer:",
    input_variables=["chat_history", "question"]
)
memory = ConversationBufferMemory(memory_key="chat_history")
chain = LLMChain(llm=llm, prompt=prompt, memory=memory)

# 执行Chain（只需传入question，chat_history会自动从memory中获取）
response = chain.run(question="Hello")</code></pre><h3>5.2 与ChatModel集成</h3><p>当使用ChatModel（如gpt-4）时，需设置<code>return_messages=True</code>，使内存返回<strong>消息列表</strong>而非字符串，以适配ChatModel的输入格式：</p><pre><code class="python"># ChatModel集成示例
from langchain.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder

llm = ChatOpenAI()
prompt = ChatPromptTemplate(
    messages=[
        SystemMessagePromptTemplate.from_template("You are a helpful assistant"),
        MessagesPlaceholder(variable_name="chat_history"),  # 必须与memory_key一致
        HumanMessagePromptTemplate.from_template("{question}")
    ]
)
memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)
chain = LLMChain(llm=llm, prompt=prompt, memory=memory)</code></pre><h3>5.3 内存参数详解</h3><table><thead><tr><th>参数名</th><th>说明</th><th>适用场景</th></tr></thead><tbody><tr><td><code>memory_key</code></td><td>内存变量在Chain中的键名（默认为"history"）</td><td>当Chain需要多个内存或自定义变量名时</td></tr><tr><td><code>return_messages</code></td><td>是否返回消息列表而非字符串（默认为False）</td><td>使用ChatModel时必须设为True</td></tr><tr><td><code>input_key</code></td><td>指定保存到内存的输入键（默认None，自动推断）</td><td>当Chain有多个输入时明确指定</td></tr><tr><td><code>output_key</code></td><td>指定保存到内存的输出键（默认None，自动推断）</td><td>当Chain有多个输出时明确指定</td></tr><tr><td><code>k</code></td><td>窗口内存保留的最近轮数（仅适用于窗口内存）</td><td>限制内存大小，防止上下文过长</td></tr><tr><td><code>llm</code></td><td>用于摘要/实体提取的LLM（仅适用于摘要/实体内存）</td><td>自定义摘要/实体提取逻辑</td></tr></tbody></table><h2>六、在Agent中使用Memory</h2><h3>6.1 基本集成方法</h3><p>在Agent中使用内存与普通Chain类似，但需注意以下几点：</p><ol><li><strong>使用支持内存的Agent类型</strong>：如<code>ConversationalAgent</code></li><li><strong>确保Agent的Prompt中包含内存变量</strong>：通常是"chat_history"</li><li><strong>正确设置内存的<code>memory_key</code></strong>，与Prompt中变量名保持一致</li></ol><pre><code class="python"># Agent使用示例
from langchain.agents import ConversationalAgent
from langchain.memory import ConversationBufferMemory
from langchain.llms import OpenAI

llm = OpenAI(temperature=0)
memory = ConversationBufferMemory(memory_key="chat_history")
agent = ConversationalAgent(
    llm=llm,
    system_message="You are a helpful assistant",
    memory=memory
)
agent.run("Hello!")</code></pre><h3>6.2 内存与工具调用的结合</h3><p>在Agent执行过程中，内存会自动保存以下信息：</p><ul><li>用户输入的原始查询</li><li>Agent生成的思考过程</li><li>工具调用的输入/输出</li><li>最终的回答</li></ul><p>这使Agent能够在多轮工具调用中<strong>保持上下文一致性</strong>，理解之前的操作和结果。</p><h2>七、自定义Memory开发</h2><h3>7.1 开发步骤</h3><p>如需创建适合特定场景的自定义内存，可按以下步骤进行：</p><ol><li><strong>继承BaseMemory类</strong>：实现抽象方法</li><li><strong>定义内存的存储方式</strong>：选择合适的数据结构或外部存储</li><li><strong>实现<code>load_memory_variables</code></strong>：定义如何从存储中读取数据</li><li><strong>实现<code>save_context</code></strong>：定义如何将新上下文保存到存储</li><li><strong>实现<code>clear</code></strong>：定义如何清空内存</li></ol><pre><code class="python"># 简单自定义内存示例
from langchain.memory import BaseMemory
from typing import Dict, Any

class CustomMemory(BaseMemory):
    def __init__(self):
        self.data = {}
    
    @property
    def memory_variables(self) -&gt; List[str]:
        return ["custom_var"]
    
    def load_memory_variables(self, inputs: Dict[str, Any]) -&gt; Dict[str, Any]:
        return {"custom_var": self.data.get("value", "default")}
    
    def save_context(self, inputs: Dict[str, Any], outputs: Dict[str, str]) -&gt; None:
        self.data["value"] = outputs.get("output_key", "no output")
    
    def clear(self) -&gt; None:
        self.data = {}</code></pre><h3>7.2 与ChatMessageHistory结合</h3><p>大多数自定义对话内存可通过组合<code>BaseChatMemory</code>和<code>ChatMessageHistory</code>来简化实现，这比直接继承BaseMemory更高效：</p><pre><code class="python"># 使用ChatMessageHistory的自定义内存
from langchain.memory import BaseChatMemory
from langchain.schema import messages_to_dict, messages_from_dict

class MyCustomChatMemory(BaseChatMemory):
    def __init__(self):
        super().__init__()
        self.chat_memory = ChatMessageHistory()
    
    def load_memory_variables(self, inputs: Dict[str, Any]) -&gt; Dict[str, Any]:
        return {"history": self.chat_memory.messages}
    
    def save_context(self, inputs: Dict[str, Any], outputs: Dict[str, str]) -&gt; None:
        user_msg = inputs.get("input", "")
        ai_msg = outputs.get("output", "")
        self.chat_memory.add_user_message(user_msg)
        self.chat_memory.add_ai_message(ai_msg)</code></pre><h2>八、长期记忆与持久化</h2><h3>8.1 LangGraph：官方推荐的长期记忆方案</h3><p>从v0.3版本开始，LangChain推荐使用<strong>LangGraph</strong>作为长期记忆解决方案。LangGraph提供以下优势：</p><ul><li><strong>灵活的存储后端</strong>：支持内存、文件、数据库等多种存储</li><li><strong>命名空间(Namespace)支持</strong>：可按用户/组织隔离存储，便于管理</li><li><strong>键值对(Key-Value)结构</strong>：每个记忆有唯一键，便于精确检索</li><li><strong>跨线程/会话共享</strong>：支持在不同对话中访问相同记忆</li></ul><pre><code class="python"># LangGraph基本使用示例
from langchain.storage import LangGraph
from langchain.memory import CombinedMemory

# 配置存储
store = LangGraph(backend="sqlite")

# 创建长期内存
long_term_memory = store.create_memory(namespace="user_123", key="profile")

# 使用内存
long_term_memory.save("Hello, world!")
print(long_term_memory.load())  # 输出: "Hello, world!"</code></pre><h3>8.2 其他持久化方案</h3><p>除LangGraph外，还可使用以下方案实现长期记忆：</p><ol><li><strong>文件存储</strong>：将内存数据序列化到本地文件</li><li><strong>数据库存储</strong>：使用SQLAlchemy或NoSQL客户端连接数据库</li><li><strong>Redis存储</strong>：适合分布式应用，提供高性能读写</li><li><strong>向量数据库</strong>：如Chroma、Pinecone等，适合存储对话嵌入，支持语义检索</li></ol><h2>九、选择合适的Memory类型</h2><p>根据不同应用场景，推荐以下内存类型：</p><table><thead><tr><th>场景</th><th>推荐内存类型</th><th>原因</th></tr></thead><tbody><tr><td>简单聊天机器人</td><td>ConversationBufferMemory</td><td>实现简单，保存完整对话历史</td></tr><tr><td>高频短对话</td><td>ConversationBufferWindowMemory</td><td>只保留最近对话，减少上下文长度</td></tr><tr><td>长对话/知识库</td><td>ConversationSummaryMemory</td><td>自动摘要，减少token消耗</td></tr><tr><td>个性化助手</td><td>ConversationEntityMemory</td><td>追踪用户和实体信息，提供个性化响应</td></tr><tr><td>复杂关系推理</td><td>ConversationKGMemory</td><td>构建知识图谱，理解实体间关系</td></tr><tr><td>大规模知识库集成</td><td>VectorStoreRetrieverMemory</td><td>通过向量检索获取相关历史，支持长期记忆</td></tr><tr><td>生产环境/分布式系统</td><td>LangGraph + Redis/PostgreSQL</td><td>提供持久化、分布式存储支持</td></tr></tbody></table><h2>十、总结与下一步</h2><h3>10.1 核心要点回顾</h3><ul><li>Memory是LangChain中<strong>维护状态和上下文</strong>的核心组件，使无状态的LLM能够拥有"记忆"</li><li>内存系统支持<strong>读取</strong>（在Chain执行前加载历史）和<strong>写入</strong>（在执行后保存新上下文）两大操作</li><li>LangChain提供多种内存类型，从简单的对话缓冲到复杂的知识图谱和向量存储，满足不同场景需求</li><li>与Chain/Agent集成时，需确保<strong>内存变量名与Prompt中变量名一致</strong>，并根据是否使用ChatModel设置<code>return_messages</code>参数</li></ul><h3>10.2 推荐下一步</h3><ol><li><strong>尝试基础示例</strong>：从<code>ConversationBufferMemory</code>开始，理解内存基本用法</li><li><strong>探索高级类型</strong>：根据应用场景选择合适的内存（如窗口内存、摘要内存）</li><li><strong>集成到实际应用</strong>：将内存与Agent或自定义Chain结合，构建有状态的对话系统</li><li><strong>考虑持久化</strong>：对需要长期记忆的应用，研究LangGraph或其他持久化方案</li></ol><blockquote>注：本指南基于LangChain官方文档(v0.3.x)整理，部分功能仍标记为Beta，建议在生产环境中使用前检查最新文档。</blockquote>]]></description></item><item>    <title><![CDATA[云流技术深度剖析：实时云渲染Web端协议选型分析 点量实时云渲染 ]]></title>    <link>https://segmentfault.com/a/1190000047552944</link>    <guid>https://segmentfault.com/a/1190000047552944</guid>    <pubDate>2026-01-20 12:05:30</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><img width="723" height="311" referrerpolicy="no-referrer" src="/img/bVdnGQs" alt="" title=""/><br/>实时云渲染的Web端落地，核心挑战之一是“如何高效、低延迟地将云端渲染的视频流传输至浏览器并完成解码渲染”。因为用户需要的是即点即用，最好不安装任何软件，因此，选择浏览器作为终端载体是刚需。浏览器环境的兼容性限制、网络波动差异、低延迟要求，共同决定了协议选型的复杂性。本文将从技术底层拆解浏览器视频流解码各方案特点，通过多维度对比推导最优选型，并结合点量云流实时云渲染系统的实践经验，解析WebRTC在实时云渲染场景下为何被选中，以及点量云流在WebRTC等领域所做的深度优化方向。</p><h2>一、Web端常见主流视频流解码方案</h2><p>Web端视频流解码的核心目标是“在浏览器无插件依赖前提下，实现视频流的高效解码与流畅渲染”，笔者结合多年在视频解码领域的经验，梳理出当前主流的一些方案具体如下：</p><p><strong>1、基于浏览器MSE实现：FLV-JS/MPEG-TS方案</strong><br/>MSE（Media Source Extensions）是浏览器提供的媒体扩展API，允许JavaScript动态构造媒体源并喂给原生媒体播放器。该类技术中比较知名的是bilibili开源的flv- js：<a href="https://link.segmentfault.com/?enc=bkthKVEjFOZF6StQiUueWA%3D%3D.EZzhRz6mlIrfN%2FVxDmDNYPUQBwLr2ZK34b4n4zLQLDkTigxrKcruNM1cv1uLB1zC" rel="nofollow" target="_blank">https://github.com/bilibili/flv_js</a>，该播放器同时支持点播和直播的数据流，类似的还有mpegtjs、video- js、hls- js等。</p><p>核心特点：兼容性中等，支持所有实现MSE标准的浏览器（Chrome、Firefox、Edge等新一些的主流浏览器均支持）；无需额外引入解码库，依赖浏览器原生硬解，CPU占用较低；延迟表现中等，常规场景下端到端延迟约1-3秒，通过优化切片大小可压缩至500ms左右，但受其传输和Video标签对视频缓存机制限制，难以突破300ms阈值。实测总延迟很难低于700ms。其短板在于依赖HTTP传输，面对网络波动时易出现卡顿。<br/>特别需要注意的是：MSE在iOS下基本是不能被支持的，只能在部分iPad设备下使用，所以如果要考虑支持iPhone等移动设备，该技术有很大局限性。</p><p>主流浏览器下的支持情况如下：<br/><img width="723" height="329" referrerpolicy="no-referrer" src="/img/bVdnGQt" alt="" title="" loading="lazy"/></p><p><strong>2、纯JavaScript解码：JSMpeg方案</strong><br/>JSMpeg是纯JavaScript实现的轻量级视频解码器，核心原理是通过JavaScript直接解析MPEG-TS格式视频流，将解码后的像素数据绘制到Canvas画布上，音频数据则通过Web Audio API播放。该方案无需依赖浏览器原生解码能力，完全通过软件解码实现。JSMpeg可以通过Ajax加载静态视频，并允许通过WebSockets进行低延迟流式传输（约50毫秒）。</p><p>核心特点：因为纯基于JavaScript实现，兼容性极强，甚至支持低版本浏览器及部分嵌入式Web环境；方案轻量，无需额外部署转码服务，适合简单场景的轻量化集成。但短板极为突出：纯JS软解效率极低，CPU占用极高，在1080P画质下多数终端会出现明显卡顿，几乎不可能支持60fps视频的流畅播放；仅能支撑480P以下低画质场景；延迟表现较差，常规延迟2-5秒，且随着画质提升延迟显著增加；不支持硬件加速，无法适配实时云渲染的高画质、低延迟需求。</p><p><strong>3、WASM解码方案</strong><br/>WASM（WebAssembly）是一种高性能的二进制指令格式，可将C/C++、Rust等高性能语言编写的解码逻辑编译为WASM模块，供JavaScript调用。该方案的核心是通过WASM提升解码计算效率，兼顾兼容性与性能。常见的有：<a href="https://link.segmentfault.com/?enc=ZaiOSS%2FtiCFzQNw8cf1s2g%3D%3D.C0NLcHrSMjE56aoqN44LAsUuEDG2gDlsVMW6lrwhp3tVqR4zgYnrYjhyacYA7XHA" rel="nofollow" target="_blank">https://github.com/sonyusquin/WasmVideoPlaye</a>和<a href="https://link.segmentfault.com/?enc=B20Hqr8owhz9OSDguwQkeg%3D%3D.xbVYB5do%2F5KSXPO5x%2BXEjarBmtimD2QsNfBFZJx0oRrHcJrQWv0DVQyim9FUkBOW" rel="nofollow" target="_blank">https://github.com/goldwidco/h265player</a>等。</p><p>核心特点：解码性能远超纯JS方案，接近原生应用水平，尤其在Rust编写的WASM模块中，复杂计算场景下耗时仅为原生JS的1/16左右；对视频格式兼容性友好是它的一个特长，因为它可灵活定制解码逻辑，适配特殊编码格式。但仍存在明显局限：需额外加载WASM解码模块，增加首屏加载时间；依赖WebSocket等协议传输视频流；虽性能提升显著，但较难利用系统GPU硬解，相比浏览器原生硬解仍有差距，高画质（4K/60fps）场景下CPU占用仍较高。并且由于缺少完善的重传、冗余等传输层机制的支持，所以经常遇到花屏现象发生。目前该方案多作为兼容性兜底方案，而非实时云渲染的主流选择。</p><p>其浏览器兼容性如下：<br/><img width="723" height="262" referrerpolicy="no-referrer" src="/img/bVdnGQJ" alt="" title="" loading="lazy"/></p><p><strong>4、实时通信标准：WebRTC方案</strong><br/>WebRTC是浏览器原生支持的实时通信标准，提供音视频采集、编码、传输、解码的全链路API，核心基于UDP协议实现低延迟传输，支持点对点直连与媒体服务器转发两种模式。WebRTC在不同的浏览器在解码特性上略有差异，但大都是优先会GPU硬解，并直接在浏览器中高效显示。其核心优势在于将音视频传输与解码能力深度集成到浏览器内核，无需额外引入第三方库，可实现端到端的低延迟音视频交互。</p><p>核心特点：延迟极低，原生支持端到端延迟500ms以内，通过优化可压缩至100ms以下，甚至通过优化可做到10ms级的极低延迟；支持浏览器原生硬解，CPU占用远低于软解方案；内置网络自适应机制，可根据网络带宽动态调整码率与帧率，且可以支持P2P打洞、转发等技术；支持双向数据通道，可同步传输操作指令与视频流，完美匹配实时云渲染的交互需求。短板在于早期兼容性存在差异，尤其在部分低版本移动端浏览器中需适配，但目前主流浏览器已全面支持；此外，原生WebRTC的音视频编解码策略需针对云渲染场景优化，才能充分发挥性能。</p><p>主流浏览器对WebRTC的兼容支持情况如下：<br/><img width="723" height="312" referrerpolicy="no-referrer" src="/img/bVdnGQV" alt="" title="" loading="lazy"/></p><p><strong>5、新兴方案：WebTransport+WebCodecs</strong><br/>WebTransport基于QUIC协议，提供低延迟、可靠的网络传输能力，WebCodecs则是浏览器提供的原生编解码API，可直接操作音视频数据。两者结合的方案核心是通过WebTransport优化传输效率，WebCodecs提升编解码灵活性。</p><p>核心特点：传输延迟与WebRTC相当，甚至在部分场景下更优；编解码逻辑可深度定制，适配特殊画质与帧率需求。但目前兼容性极差，仅支持最新版本的Chrome浏览器，Safari、Firefox等浏览器暂不支持，暂时无法满足实时云渲染的全终端适配需求，仅适用于指定浏览器的特殊演示场景，暂不具备大规模商用价值。</p><h2>二、实时云渲染场景的选型标尺</h2><p>实时云渲染的核心需求是“低延迟交互（操作指令与画面同步）、高画质流畅渲染、全终端兼容、低资源占用”，结合各方案的技术特性，从6个关键维度构建对比体系，明确选型边界：<br/><img width="689" height="316" referrerpolicy="no-referrer" src="/img/bVdnGQX" alt="" title="" loading="lazy"/></p><h2>三、为何WebRTC是实时云渲染Web端的最优解？</h2><p>结合上述对比与实时云渲染的核心需求，WebRTC成为最优选型，核心优势至少在三个关键层面：</p><p><strong>1、低延迟传输：匹配实时交互的核心诉求</strong><br/>实时云渲染的核心痛点是“操作与画面不同步”——云游戏中100ms以上的延迟会导致操作脱节，云设计中延迟过高会影响创作连贯性，云VR/AR场景更是要求延迟低于20ms以避免眩晕感。WebRTC基于UDP协议传输，无需像TCP那样进行多次数据确认，从传输层大幅降低延迟；同时支持快速重传机制，在30%丢包率下仍可保持流畅传输，远超其他基于TCP的方案（FLV-JS、WASM+WebSocket）。实测数据显示，原生WebRTC的端到端延迟可稳定在100ms以内，笔者在实际案例中，经过场景优化后甚至能达到10-30ms的局域网级延迟，完全覆盖实时云渲染的延迟需求。</p><p><strong>2、原生硬解+低资源占用：保障全终端流畅体验</strong><br/>实时云渲染需适配PC、手机、平板、VR头显等多终端，终端性能差异较大，低资源占用是保障全终端流畅的关键。WebRTC依赖浏览器原生硬解，相比JSMpeg纯软解和WASM软解，CPU占用降低60%以上，在低端手机上也能流畅支撑1080P/60fps的画质渲染；同时无需额外加载解码模块，首屏加载时间比WASM方案缩短80%，提升用户体验。</p><p><strong>3、双向交互+网络自适应：适配复杂场景需求</strong><br/>实时云渲染不仅需要“视频流下行”，还需要“操作指令上行”（鼠标、键盘、触控、VR手柄指令等）。WebRTC原生支持DataChannel双向数据通道，可将操作指令与视频流同步传输，指令延迟与视频延迟保持一致，实现“操作即反馈”的体验；同时内置网络自适应机制，可实时检测带宽变化，动态调整码率与帧率——当网络带宽下降时，自动降低画质以保障流畅，带宽恢复后立即提升画质，完美适配复杂的公网环境。</p><p><strong>4、兼容性与扩展性：支撑大规模商用落地</strong><br/>目前Chrome、Firefox、Edge、Safari等主流浏览器均已全面支持WebRTC标准，兼容性覆盖90%以上的终端设备，无需用户安装任何插件，可直接通过链接访问，大幅降低落地门槛。同时WebRTC支持自定义编解码参数与传输策略，可根据不同场景（云游戏、云设计、云VR）的需求进行深度优化，扩展性远超封闭的商业协议。</p><h2>四、点量云流实时云渲染对WebRTC的场景化增强方案分析</h2><p>原生WebRTC虽具备核心优势，但在实时云渲染的特定场景下仍存在优化空间——如复杂3D场景的编解码效率、弱网环境的画质保障、多终端适配差异等。点量云流作为国产主流实时云渲染厂商，基于WebRTC标准，结合实时云渲染场景需求，进行了全链路深度优化。以下将具体分析点量云流在该场景下是如何进一步适配与优化WebRTC的：</p><p><strong>1、传输层优化：智能拥塞控制</strong><br/>点量云流一般会基于弱网的情况下，智能选最优传输策略，比如至少区分视频流与操作指令的传输优先级，确保操作指令优先传输。而针对云游戏、云VR等弱网容错需求，还会重点优化FEC（前向纠错）与重传协同机制，同时动态调整FEC冗余率（比如10%-50%自适应），平衡带宽开销与修复效果，在30%丢包率场景下仍能保障画面流畅度。<br/>实测数据显示，经过优化后，公网环境下端到端延迟平均降低40%，北京到济南的跨地域端对端延迟稳定在30-50ms，局域网内延迟可控制在30ms以内。</p><p><strong>2、编解码优化：自适应编码+画质增强</strong><br/>针对实时云渲染的3D画质特点，点量云流策略如下：一是实现编码零拷贝，避免GPU和CPU态的切换；二是自定义自适应编码器，替代WebRTC内置的编码器，可动态切换H.264/H.265，并在编码器配置上，针对云游戏等高速运动画面优化运动估计算法，针对云VR的沉浸式场景强化边缘画质处理；三是智能帧策略优化，一方面确保帧可以即点即开，另一方面，避免帧的不均衡，传输导致延迟峰值。<br/>在优化前后，实测显示，在5Mbps的弱网环境下，仍可稳定传输4K/60fps的画质，较原生WebRTC的弱网适配能力有明显提升。</p><p><strong>3、多终端适配兼容性优化：全场景兼容+交互同步优化</strong><br/>针对不同终端的浏览器差异，点量云流构建了WebRTC适配矩阵，通过动态降级策略——在支持WebRTC的主流浏览器上启用优化方案，在低版本浏览器上还保留有其它传输和解码方案，确保全终端覆盖，确保在常见浏览器上的兼容性。</p><h2>五、总结与未来趋势</h2><p>实时云渲染Web端的协议选型，核心是“匹配场景需求的技术平衡”。一方面要兼顾低延迟、复杂网络环境；另一方面要考虑浏览器兼容性。</p><p>在实践中，点量云流实时云渲染还提供了专门的客户端模式。该模式并未采用WebRTC，而是基于其自研的DLCA协议进行实现。这一选择是基于浏览器本身并非专为实时云渲染设计的考虑，通过自研客户端，能够在低延迟、交互性与实时性方面实现更深度的扩展与优化。据测试，DLCA模式在部分场景下相比WebRTC可降低约1帧的延迟，将端到端延迟进一步优化十几毫秒。当然，点量云流实时云渲染不止自研的DLCA协议这一个核心技术，还有许多技术支撑着实时云渲染系统的稳定运行。</p><p>未来，随着WebTransport与WebCodecs的兼容性逐步完善，它们有望成为WebRTC的重要补充，在特定高端场景中进一步提升传输与编解码效率。然而，就目前商用落地的实际需求而言，经过针对性场景优化的WebRTC，仍是实时云渲染Web端被广泛采用的主流技术方案。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdmT11" alt="" title="" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[开源IPD项目管理软件深度对比，8款主流产品解析与选型指南 3Q聊工具 ]]></title>    <link>https://segmentfault.com/a/1190000047552951</link>    <guid>https://segmentfault.com/a/1190000047552951</guid>    <pubDate>2026-01-20 12:04:35</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>作为深耕研发管理领域十余年的从业者，笔者常被问及如何筛选适配IPD（集成产品开发）流程的开源项目管理系统——既要实现“战略-研发-交付”全链路闭环，又要平衡成本控制、定制灵活性与团队适配性。开源工具凭借零授权费用、可二次开发的优势，成为中小企业及合规需求型企业的首选。本文精选8款主流开源IPD项目管理系统，含国产标杆禅道及多款全球热门产品，中立解析核心能力，为不同场景选型提供参考。</p><h2>一、8款开源IPD项目管理系统核心解析</h2><p>以下产品按“国产优先、功能适配性”排序，均排除商业化过重、非原生开源及敏感属性工具，每款产品聚焦3个核心功能模块，兼顾IPD流程关键节点需求，保持客观中立表述。</p><h3>（一）禅道（ZenTao）</h3><p>国产开源研发管理标杆，2009年推出，深耕IPD轻量化落地场景，支持本地、云部署及信创全适配，累计服务100万+团队，是软硬件协同开发及合规场景的优选工具。</p><ul><li>​<strong>需求管理模块</strong>​：支持需求全生命周期追踪，含条目化管理、变更控制与评审流程，可生成跟踪矩阵，实现IPD需求阶段闭环。</li><li>​<strong>IPD流程固化模块</strong>​：内置华为标准IPD模板，覆盖概念-计划-开发-验证-发布全阶段，原生支持TR技术评审与DCP决策评审数字化流转。</li><li>​<strong>DevOps集成模块</strong>​：无缝对接Git、Jenkins等工具，内置自动化测试框架与流水线监控，实现研发与运维流程一体化。</li></ul><p><img width="723" height="357" referrerpolicy="no-referrer" src="/img/bVdl902" alt="" title=""/></p><h3>（二）Redmine</h3><p>全球普及度最高的开源项目管理工具之一，基于Rails框架构建，以高灵活性和丰富插件生态见长，适配敏捷、瀑布及混合IPD流程。</p><ul><li>​<strong>自定义工作流模块</strong>​：支持按IPD场景配置审批节点与角色权限，可通过插件扩展阶段门管理能力，适配复杂流程定制需求。</li><li>​<strong>可视化规划模块</strong>​：内置甘特图、日历与进度追踪功能，支持多项目并行管理，直观呈现IPD各阶段资源分配与依赖关系。</li><li>​<strong>协作支撑模块</strong>​：集成Wiki与论坛功能，支持文档版本控制与团队留言互动，满足IPD跨部门协作的知识沉淀需求。</li></ul><p><img width="723" height="357" referrerpolicy="no-referrer" src="/img/bVdmdGA" alt="" title="" loading="lazy"/></p><h3>（三）OpenProject</h3><p>被誉为“Redmine现代化替代品”，采用Web 2.0技术构建，界面直观，原生支持敏捷方法论，社区版与企业版分层适配不同规模IPD需求。</p><ul><li>​<strong>敏捷协作模块</strong>​：内置Scrum看板与Kanban面板，支持冲刺规划与燃尽图生成，适配IPD快速迭代与任务流转需求。</li><li>​<strong>资源管理模块</strong>​：企业版支持资源分配、预算跟踪与多项目视图，可实现IPD跨项目资源统筹与冲突预警。</li><li>​<strong>文档协同模块</strong>​：支持文档在线编辑与版本追溯，可关联项目阶段与任务，形成IPD全流程文档闭环。</li></ul><p><img width="723" height="357" referrerpolicy="no-referrer" src="/img/bVdmuvl" alt="" title="" loading="lazy"/></p><h3>（四）Taiga</h3><p>专注敏捷开发的开源工具，以简洁UI与原生敏捷支持为核心亮点，适合中小型团队的IPD敏捷化落地，集成Git版本控制系统实现开发协同。</p><ul><li>​<strong>用户故事管理模块</strong>​：支持用户故事地图构建与优先级排序，可拆分迭代任务，适配IPD需求拆解与敏捷交付场景。</li><li>​<strong>冲刺跟踪模块</strong>​：自动生成燃尽图与迭代报告，实时展示任务完成进度，助力IPD迭代阶段目标管控。</li><li>​<strong>团队协作模块</strong>​：支持角色权限细分与任务评论互动，集成通知机制，确保IPD团队成员信息同步高效。</li></ul><p><img width="723" height="356" referrerpolicy="no-referrer" src="/img/bVdmuvk" alt="" title="" loading="lazy"/></p><h3>（五）Phabricator</h3><p>由Facebook前工程师打造，以强大工作流引擎与代码审查能力为特色，适合技术驱动型团队的大规模IPD分布式协作。</p><ul><li>​<strong>代码审查模块</strong>​：内置Diffusion代码管理组件，支持精细化代码评审与意见追踪，提升IPD开发阶段代码质量。</li><li>​<strong>工作流定制模块</strong>​：可构建任意复杂审批流程，支持多语言界面，适配大规模团队IPD跨区域协作需求。</li><li>​<strong>任务调度模块</strong>​：通过Maniphest组件实现任务分配、优先级管理与状态追踪，衔接IPD开发与测试环节。</li></ul><p><img width="723" height="357" referrerpolicy="no-referrer" src="/img/bVdmuvt" alt="" title="" loading="lazy"/></p><h3>（六）Odoo</h3><p>模块化开源ERP系统，项目管理模块可与PLM、CRM等模块无缝集成，适合需全业务链路协同的IPD场景，尤其适配制造业研发管理。</p><ul><li>​<strong>项目化管理模块</strong>​：支持按IPD项目维度统筹任务、资源与交付物，适配非标制造业个性化研发需求。</li><li>​<strong>PLM集成模块</strong>​：可管理产品图纸、BOM清单与设计变更，实现IPD研发与生产环节数据打通。</li><li>​<strong>自动化流程模块</strong>​：支持自定义审批流与触发器，可自动化IPD阶段评审与交付物校验流程。</li></ul><p><img width="723" height="357" referrerpolicy="no-referrer" src="/img/bVdmuvz" alt="" title="" loading="lazy"/></p><h3>（七）Tuleap</h3><p>源自法国的开源研发管理平台，以合规性与规模化协作能力为核心，支持敏捷、瀑布与IPD混合流程，适配企业级需求。</p><ul><li>​<strong>需求追溯模块</strong>​：支持需求与任务、测试用例双向追溯，满足IPD流程可追溯性与合规审计需求。</li><li>​<strong>测试管理模块</strong>​：内置测试用例管理与执行跟踪功能，可关联缺陷与需求，实现IPD验证阶段质量管控。</li><li>​<strong>多项目统筹模块</strong>​：支持项目集管理与战略对齐，可将企业目标拆解为IPD产品线任务，实现全链路管控。</li></ul><p><img width="723" height="356" referrerpolicy="no-referrer" src="/img/bVdmQoy" alt="" title="" loading="lazy"/></p><h3>（八）LeanTime</h3><p>轻量级开源项目管理工具，以工时跟踪与效能分析为特色，适合预算有限、追求简洁性的小型团队IPD落地。</p><ul><li>​<strong>工时管理模块</strong>​：支持任务工时记录与统计，生成工时报表，助力IPD成本核算与资源效率分析。</li><li>​<strong>里程碑管理模块</strong>​：可设置IPD关键里程碑与交付节点，触发节点通知，确保项目进度不偏离目标。</li><li>​<strong>简易看板模块</strong>​：提供可视化任务看板，支持拖拽式任务流转，适配小型团队IPD轻量化协作需求。</li></ul><p><img width="723" height="357" referrerpolicy="no-referrer" src="/img/bVdmuvC" alt="" title="" loading="lazy"/></p><h2>二、场景化选型建议</h2><p>选型核心需匹配企业规模、IPD成熟度、技术能力与合规需求，以下为针对性建议：</p><ol><li>​<strong>中小型企业（10-50人）+ 信创需求</strong>​：优先选择​<strong>禅道</strong>​，开源版免费、信创全适配，内置IPD模板无需复杂配置，上手成本低。</li><li>​<strong>技术驱动型团队 + 高度定制需求</strong>​：推荐<strong>Redmine</strong>或​<strong>Phabricator</strong>​，前者插件生态丰富，后者工作流与代码审查能力突出，适合技术团队自主定制IPD流程。</li><li>​<strong>中大型企业 + 跨部门协作</strong>​：可选<strong>OpenProject企业版</strong>或​<strong>Odoo</strong>​，前者资源管理与可视化能力强，后者可实现IPD与ERP全链路集成。</li><li>​<strong>敏捷化IPD团队 + 简洁需求</strong>​：优先<strong>Taiga</strong>或​<strong>LeanTime</strong>​，前者适配敏捷迭代，后者轻量高效，适合快速落地基础IPD流程。</li><li>​<strong>合规型企业 + 规模化协作</strong>​：推荐​<strong>Tuleap</strong>​，需求追溯与合规适配能力突出，可支撑复杂IPD流程的审计与管控。</li></ol><h2>三、总结</h2><p>开源IPD项目管理系统的核心价值的在于“灵活适配+成本可控”，8款产品各有侧重：禅道强在国产信创与IPD原生落地，Redmine胜在定制灵活性，OpenProject兼顾现代化体验与企业级需求，Phabricator适配技术团队深度协作。选型时无需追求“功能最全”，需结合自身IPD成熟度、团队技术能力与合规要求，优先选择“易落地、可扩展”的工具，必要时通过二次开发或插件扩展适配全流程需求。未来，开源IPD工具将持续向AI赋能、生态集成方向迭代，进一步降低企业IPD落地门槛。</p>]]></description></item><item>    <title><![CDATA[「瑶池 Data Agent 入门训练营」火热报名中！1月21日正式开讲，参营可得多重好礼！ 数据库]]></title>    <link>https://segmentfault.com/a/1190000047552953</link>    <guid>https://segmentfault.com/a/1190000047552953</guid>    <pubDate>2026-01-20 12:03:36</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>一句话就能分析数据？担心自己零基础，跟不上训练营节奏？别急！<strong>瑶池 Data Agent 入门训练营</strong>第1节先导课来了！<br/><strong>Data Agent</strong> 是一款基于大模型的企业数据智能助手，提供免费版、个人版和企业版三种版本，分别满足个人用户的基础使用、进阶需求及企业的多用户协作、安全管控与独立部署等场景，支持通过自然语言对话完成数据查询、分析与处理，无需编写代码，助力各岗位用户高效实现数据驱动决策。<br/>这节课我们不讲复杂操作，只做一件事：帮你彻底搞懂 Data Agent 是什么、能帮你做什么。无论你是业务人员、管理者还是技术小白，都能在这里找到属于你的数据驱动起点。</p><h2>一、参营入口</h2><p><a href="https://link.segmentfault.com/?enc=rL62%2F7aVxzqSBzo5SJgpjA%3D%3D.JLVwmgeTvx4zpj7hkgQh%2F7nFd91npXHxK7fLYRt%2BITKeLpj5g9RthXjvzA%2FVHHx%2F" rel="nofollow" target="_blank">点此报名参营</a>，用 Data Agent 为你的业务按下加速键！</p><h2>二、参营时间</h2><p>2026年1月21日-1月29日 （每个工作日下午17:00-17:30）</p><h2>三、第一节课程介绍</h2><p><img width="723" height="1390" referrerpolicy="no-referrer" src="/img/bVdnGPz" alt="" title=""/></p><h2>四、超值奖励</h2><ul><li>结营证书：完成所有任务即可获得阿里云官方训练营电子结营证书；</li><li>结营奖励：课后作业总分（满分100分）排名前100名者获奖，相同分数按提交时间先后排序，即可领取棒球帽/无线鼠标/公仔/鼠标垫（随机发其一）；</li><li>优秀学员奖：选取5名完成全部任务和作业的优秀学员，加赠德尔玛加湿器！获奖名单会于结营后的7个工作日内在活动钉群内公布；</li><li>钉群互动奖：交流群内不定时举办有奖问答及抽奖活动，赢卡套、帽子等精美好礼！</li></ul><p><img width="706" height="139" referrerpolicy="no-referrer" src="/img/bVdnGPy" alt="" title="" loading="lazy"/></p><h2>五、如何参营</h2><p>本次训练营所有课程内容将采取钉群线上直播方式，课程结束后每小节课后作业均在钉钉交流群内获取提交，这是你获得证书和奖品双重奖励的唯一通道。<br/>欢迎钉钉搜索（群号：161600014025）入群参营学习及获取领奖通知！</p><h2>六、参考资料</h2><ol><li>Data Agent 帮助文档：<a href="https://link.segmentfault.com/?enc=b6AbBVjuDVWvl4Ondp7wJQ%3D%3D.qpXOBdy%2FjE219Vo7Rsrqmx429tdAxWSztVVNc7e4mF8Xvn9GE9%2BtMxPfbPjPFNshiBGgTF1wsqhWCcJZMRt8yg%3D%3D" rel="nofollow" target="_blank">https://help.aliyun.com/zh/dms/data-agent-for-analytics/</a></li><li>Data Agent 版本介绍：<a href="https://link.segmentfault.com/?enc=G8wlzgHK%2FSNjgQcfMMMsng%3D%3D.kBmXQlF1r4pM52FOWgrufsnOanifkVawV5CFZWb1FoqLdga2%2BYOTZWD3MSL12e%2BY8GPtVNdFLIOxJdSw%2FdNG7A%3D%3D" rel="nofollow" target="_blank">https://help.aliyun.com/zh/dms/data-agent-version-introduction</a></li><li>阿里云瑶池Data Agent 荣获 InfoQ 2025 年度 “Data &amp; AI最具价值产品奖”<a href="https://link.segmentfault.com/?enc=%2BLk9YnQrQ%2BY4pFzUvz6A%2Fg%3D%3D.9H51cT9ggZEBHmd63DHuAZIAD4Zp2E23L%2BaXbpbY5hWTCIabpj40WWYV6KuXYm5SIq4PEW1Z7CP2LD7ZsQguQQ%3D%3D" rel="nofollow" target="_blank">https://mp.weixin.qq.com/s/SdNeTFh8pxZ_Yf8hjjCTxg</a></li></ol><p><img width="723" height="986" referrerpolicy="no-referrer" src="/img/bVdnGPA" alt="" title="" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[鸿蒙 HarmonyOS 6 | ArkUI (07)：导航架构 Navigation 组件 (V2]]></title>    <link>https://segmentfault.com/a/1190000047552973</link>    <guid>https://segmentfault.com/a/1190000047552973</guid>    <pubDate>2026-01-20 12:02:49</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h3>前言</h3><p>在鸿蒙应用的开发历程中，页面跳转一直是大家最先接触的功能之一。很长一段时间里，<strong>Router</strong> 模块都是我们手中的标配武器，那句 <code>router.pushUrl</code> 相信每一位开发者都烂熟于心。但在构建大型应用，尤其是面对平板、折叠屏这些复杂设备时，老旧的 Router 逐渐显露出了疲态。它是一个页面级别的全局单例，难以处理分屏、弹窗嵌套路由以及模块化的动态加载。这就像是用一把瑞士军刀去砍伐整片森林，虽然能用，但效率极低且手感生涩。</p><p>在 HarmonyOS 6 的时代，官方明确推荐我们全面拥抱 <strong>Navigation</strong> 组件。这不仅仅是一个组件的更替，更是一次架构思维的升级。<strong>Navigation</strong> 不再是一个简单的 API 调用，它是一个容器，一个能够容纳完整路由栈、标题栏和工具栏的超级容器。它将路由的管理权从系统底层交还到了开发者手中，让我们能够像操作数组一样精准地控制页面的进出栈。</p><p>今天，我们就把那个陈旧的 Router 放在一边，深入探讨如何利用 Navigation V2 架构和 <strong>NavPathStack</strong> 构建一个现代化、健壮的应用导航体系。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047522478" alt="" title=""/></p><h3>一、 从 Router 到 Navigation：架构的范式转移</h3><p>要理解 Navigation 的强大，我们先得明白它解决了什么痛点。传统的 Router 是基于 <strong>Page</strong>（页面）的，每一个页面都是一个独立的 Ability 或者窗口层级。当我们想要在一个弹窗里再做一套局部导航，或者在平板的左侧菜单里嵌入一个独立的路由栈时，Router 就束手无策了。</p><p><strong>Navigation</strong> 组件的出现彻底改变了这一局面。它本质上是一个 UI 组件，这意味着它可以被放置在界面的任何位置。你可以把它放在根节点作为全屏导航，也可以把它放在一个 Dialog 内部，甚至可以嵌套使用。</p><p>在 API 20 中，Navigation 采用了 <strong>组件级路由</strong> 的概念。每一个“页面”不再是 <code>@Entry</code> 修饰的独立文件，而是被 <strong>NavDestination</strong> 包裹的自定义组件。这种设计让页面变得极其轻量，页面的切换本质上就是组件的挂载与卸载，性能得到了巨大的提升。更重要的是，它配合 <strong>NavPathStack</strong> 实现了路由栈的可编程化，我们终于可以像操作数据一样去操作界面了。</p><h3>二、 核心大脑：NavPathStack 路由栈管理</h3><p>如果说 Navigation 是躯壳，那么 <strong>NavPathStack</strong> 就是它的灵魂。在 V2 版本中，我们不再直接调用组件的方法来跳转，而是创建一个 NavPathStack 的实例，并将其绑定到 Navigation 组件的 <strong>pathStack</strong> 属性上。这个栈对象就是我们操控界面的遥控器。</p><p>你需要实现一个复杂的登录流程：用户点击购买 -&gt; 跳转登录 -&gt; 跳转注册 -&gt; 注册成功 -&gt; <strong>直接返回购买页</strong>（跳过登录页）。在旧的 Router 模式下，你需要计算 delta 索引或者使用 replace 模式小心翼翼地堆叠。而在 NavPathStack 中，就方便多了。你可以随时调用 <strong>popToName</strong> 直接回到指定的路由锚点，或者操作栈数组，精准地移除中间的某几个页面。</p><p>数据的传递也变得优雅。当我们调用 <strong>pushPath</strong> 时，可以直接传入一个 param 对象。而在目标页面中，我们不需要再写繁琐的 <code>router.getParams()</code>，而是直接在 NavDestination 的 <strong>onShown</strong> 生命周期或者组件初始化时，从栈中获取参数。这种参数传递是类型安全的，且完全受控。此外，NavPathStack 还提供了强大的拦截器机制（Interception），让我们可以在路由跳转发生前进行鉴权拦截，比如用户未登录时直接重定向到登录页，这一切都在路由层面被优雅地拦截处理了。</p><h3>三、 页面构造：NavDestination 与路由表设计</h3><p>在 Navigation 架构下，我们的一级页面（根页面）通常直接写在 Navigation 的闭包里，而二级、三级页面则通过 <strong>NavDestination</strong> 来定义。这里有一个关键的概念转变：我们需要构建一个 <strong>路由映射表</strong>。</p><p>我们不再是通过文件路径去跳转，而是通过 <strong>路由名称（Name）</strong>。我们需要在 Navigation 组件中配置 <strong>navDestination</strong> 属性，它接收一个 <strong>@Builder</strong> 构建函数。当 NavPathStack 请求跳转到 "DetailPage" 时，这个构建函数就会被触发，我们需要在这个函数里根据传入的 name 返回对应的 <code>NavDestination</code> 包裹的组件。</p><p>这种设计模式天然支持模块化开发。我们可以把不同模块的路由表分散在各自的 HAR 包中，最后在主工程中进行聚合。每个 <strong>NavDestination</strong> 都是一个独立的沙箱，它拥有自己的标题栏、菜单栏和生命周期（onShown, onHidden）。这对于开发者来说非常友好，我们可以在 <strong>onWillAppear</strong> 中发起网络请求，在 <strong>onWillDisappear</strong> 中保存草稿，页面的生命周期完全掌握在自己手中。</p><h3>四、 界面定制：摆脱默认样式的束缚</h3><p>Navigation 自带了标准的标题栏（TitleBar）和工具栏（ToolBar），这在快速开发原型时非常方便。但在实际的商业项目中，设计师往往会给出天马行空的顶部导航设计，比如透明渐变背景、复杂的搜索框或者异形的返回按钮。</p><p>很多初学者会困惑：我是该用系统自带的，还是自己画？我的建议是<strong>按需定制</strong>。Navigation 和 NavDestination 都提供了 <strong>title</strong>、<strong>menus</strong> 和 <strong>toolBar</strong> 属性。如果设计风格符合系统规范，直接传入资源配置即可，系统会自动适配深色模式和折叠屏布局。但如果设计差异巨大，我们可以通过 <strong>.hideTitleBar(true)</strong> 彻底隐藏系统标题栏，然后在内容区域（Content）的顶部放置我们自定义的 NavBar 组件。</p><p>这里有一个细节需要注意，当我们隐藏了系统标题栏后，原本的滑动返回手势依然有效，但左上角的返回箭头没了。我们需要自己实现一个返回按钮，并调用 <code>this.pageStack.pop()</code> 来手动触发返回。这种灵活性让我们既能享受系统手势的便利，又能完全掌控视觉呈现。</p><pre><code>import { promptAction } from '@kit.ArkUI';

// 1. 定义路由参数模型
interface ContactParams {
  id: string;
  name: string;
  phone: string;
}

@Entry
@Component
struct NavigationBestPracticePage {
  // 核心修正：使用 @Provide 而不是 @State
  // 这样后代组件 (DetailPage) 才能通过 @Consume 直接获取该对象
  @Provide('pageStack') pageStack: NavPathStack = new NavPathStack();

  // 模拟的首页数据
  @State contacts: ContactParams[] = [
    { id: '1', name: '张三', phone: '13800138000' },
    { id: '2', name: '李四', phone: '13900139000' },
    { id: '3', name: '王五', phone: '15000150000' }
  ];

  // -------------------------------------------------------
  // 路由工厂：根据路由名称动态构建页面
  // -------------------------------------------------------
  @Builder
  PagesMap(name: string, param: Object) {
    if (name === 'DetailPage') {
      // 跳转到详情页
      DetailPage({
        contactInfo: param as ContactParams
      })
    } else if (name === 'EditPage') {
      // 跳转到编辑页
      EditPage({
        contactInfo: param as ContactParams
      })
    }
  }

  build() {
    // 根容器：Navigation
    Navigation(this.pageStack) {
      // 首页内容区域
      Column() {
        Text('通讯录 (V2)')
          .fontSize(24)
          .fontWeight(FontWeight.Bold)
          .margin({ top: 20, bottom: 20 })
          .width('100%')
          .padding({ left: 16 })

        List() {
          ForEach(this.contacts, (item: ContactParams) =&gt; {
            ListItem() {
              Row() {
                // 这里使用系统图标模拟头像，实际请替换为 app.media.xxx
                Image($r('app.media.startIcon'))
                  .width(40)
                  .height(40)
                  .borderRadius(20)
                  .margin({ right: 12 })
                  .backgroundColor('#E0E0E0') // 兜底背景色

                Column() {
                  Text(item.name).fontSize(16).fontWeight(FontWeight.Medium)
                  Text(item.phone).fontSize(14).fontColor('#999')
                }
                .alignItems(HorizontalAlign.Start)
                .layoutWeight(1)

                // 跳转按钮
                Button('查看')
                  .fontSize(12)
                  .height(28)
                  .onClick(() =&gt; {
                    // 核心动作：压栈跳转
                    this.pageStack.pushPathByName('DetailPage', item, true);
                  })
              }
              .width('100%')
              .padding(12)
              .backgroundColor(Color.White)
              .borderRadius(12)
              .margin({ bottom: 8 })
            }
          })
        }
        .padding(16)
        .layoutWeight(1)
      }
      .width('100%')
      .height('100%')
      .backgroundColor('#F1F3F5')
    }
    // 绑定路由映射构建器
    .navDestination(this.PagesMap)
    // 首页的标题模式
    .titleMode(NavigationTitleMode.Mini)
    .hideTitleBar(true) // 首页隐藏系统标题栏，使用自定义内容
    .mode(NavigationMode.Stack) // 强制使用堆叠模式
  }
}

// -------------------------------------------------------
// 子页面 1：详情页 (使用 @Consume 获取 Stack)
// -------------------------------------------------------
@Component
struct DetailPage {
  // 接收参数
  contactInfo: ContactParams = { id: '', name: '', phone: '' };

  // 获取当前的路由栈 (对应父组件的 @Provide)
  @Consume('pageStack') pageStack: NavPathStack;

  build() {
    NavDestination() {
      Column({ space: 20 }) {
        Image($r('app.media.startIcon'))
          .width(80)
          .height(80)
          .borderRadius(40)
          .margin({ top: 40 })
          .backgroundColor('#E0E0E0')

        Text(this.contactInfo.name)
          .fontSize(24)
          .fontWeight(FontWeight.Bold)

        Text(this.contactInfo.phone)
          .fontSize(18)
          .fontColor('#666')

        Button('编辑资料')
          .width('80%')
          .margin({ top: 40 })
          .onClick(() =&gt; {
            // 继续压栈，跳转到编辑页
            this.pageStack.pushPathByName('EditPage', this.contactInfo);
          })
      }
      .width('100%')
      .height('100%')
    }
    .title('联系人详情') // 设置系统标题
  }
}

// -------------------------------------------------------
// 子页面 2：编辑页 (使用 onReady 获取 Stack)
// -------------------------------------------------------
@Component
struct EditPage {
  @State contactInfo: ContactParams = { id: '', name: '', phone: '' };
  @State newName: string = '';

  // 独立维护 Stack 引用，不依赖 @Consume，解耦性更好
  private stack: NavPathStack | null = null;

  aboutToAppear(): void {
    this.newName = this.contactInfo.name;
  }

  build() {
    NavDestination() {
      Column({ space: 16 }) {
        Text('修改姓名:')
          .fontSize(14)
          .fontColor('#666')
          .width('90%')
          .margin({ top: 20 })

        TextInput({ text: $$this.newName, placeholder: '请输入新名字' })
          .backgroundColor(Color.White)
          .width('90%')
          .height(50)
          .borderRadius(10)

        Button('保存并返回')
          .width('90%')
          .margin({ top: 20 })
          .onClick(() =&gt; {
            // 模拟保存操作
            if (this.stack) {
              this.stack.pop(true); // 出栈
              promptAction.showToast({ message: `保存成功: ${this.newName}` });
            }
          })
      }
      .width('100%')
      .height('100%')
      .backgroundColor('#F1F3F5')
    }
    .title('编辑')
    .onReady((context: NavDestinationContext) =&gt; {
      // 最佳实践：在 onReady 中获取当前页面的 stack
      // 这种方式不需要父组件必须使用 @Provide，适用性更广
      this.stack = context.pathStack;
    })
  }
}</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047552975" alt="" title="" loading="lazy"/></p><h3>五、 总结与实战</h3><p>Navigation 组件配合 NavPathStack，标志着鸿蒙应用开发进入了 <strong>单窗口多组件（Single Window, Multi-Component）</strong> 的架构时代。它解决了 Router 时代的诸多顽疾，提供了更灵活的嵌套能力、更强大的路由栈控制以及更轻量的页面切换开销。</p><p>对于任何一个立志于构建专业级鸿蒙应用的开发者来说，尽早重构代码，迁移到 Navigation 架构，是提升应用质量的关键一步。</p>]]></description></item><item>    <title><![CDATA[8大CRM厂商2026全链路能力对比 傲视众生的脸盆 ]]></title>    <link>https://segmentfault.com/a/1190000047552980</link>    <guid>https://segmentfault.com/a/1190000047552980</guid>    <pubDate>2026-01-20 12:02:13</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在数字化转型背景下，企业对CRM的需求已从“单一销售管理”升级为“全链路业务协同”——覆盖<strong>获客 - 销售 - 订单 - 物流 - 分析 - 上下游</strong>的全流程闭环，既要解决“找客户”的痛点，也要打通“管流程”的堵点，更要实现“连生态”的价值。</p><p>本文选取<strong>超兔一体云、SAP、Oracle CX、六度人和（EC SCRM）、飞书CRM、红圈CRM、钉钉CRM、销售易</strong>8个主流品牌，从<strong>6大核心维度</strong>（获客、销售、订单、发货/物流、统计分析、上下游协同）展开深度横评，结合<strong>行业场景</strong>和<strong>产品特性</strong>，为企业选型提供参考。</p><h2>一、核心维度横向对比框架</h2><p>先通过<strong>综合对比表</strong>直观呈现各品牌的核心能力差异（注：“√”代表具备该能力，“★”代表优势能力）：</p><table><thead><tr><th><strong>维度</strong></th><th><strong>超兔一体云</strong></th><th><strong>SAP</strong></th><th><strong>Oracle CX</strong></th><th><strong>六度人和</strong></th><th><strong>飞书CRM</strong></th><th><strong>红圈CRM</strong></th><th><strong>钉钉CRM</strong></th><th><strong>销售易</strong></th></tr></thead><tbody><tr><td><strong>获客</strong></td><td>★工商搜客（toB专属）、虎客名片、AI线索清洗</td><td>★CRM + ERP整合、12维度客户洞察、移动CRM</td><td>★CDP精准营销、跨渠道触达、线索评分</td><td>★海关数据（外贸）、智能电销、社媒拓客</td><td>AI线索清洗、行为画像、多渠道整合</td><td>专业版营销活动、线索分配</td><td>钉钉生态线索、表单/小程序整合</td><td>AI精准营销、多渠道线索、社交获客</td></tr><tr><td><strong>销售</strong></td><td>★三一客模型（小单快单）、跟单时间线、AI话术</td><td>★全流程自动化、移动CRM、信用校验</td><td>★CPQ（复杂报价）、合同管控、90%订单自动化</td><td>★微信/电话集成、私域分层、AI商机助手</td><td>★一客一群（协作）、AI拜访总结、自定义流程</td><td>全流程商机、自定义流程引擎、团队协作</td><td>流程自动化、协作审批、AI沟通助手</td><td>★智能赢单预测、全流程自动化、移动管理</td></tr><tr><td><strong>订单</strong></td><td>★多类型订单（租售/维修/套餐）、锁库</td><td>★ERP联动、多类型订单、财务闭环</td><td>★全渠道履行、CPQ、合规条款</td><td>★外贸跨境链路、行业定制</td><td>合同/财务打通、项目进度联动</td><td>专业版订单/发票、交付单据管理</td><td>阿里供应链集成、订单物流联动</td><td>ERP集成、订单全生命周期、物流节点</td></tr><tr><td><strong>发货/物流</strong></td><td>★OpenCRM协同、物流订阅</td><td>★SD模块、实时监控、分批发货</td><td>★SCM集成、现场服务（备件物流）</td><td>外贸物流链路、第三方依赖</td><td>第三方物流集成、项目进度监控</td><td>定制开发、流程节点拆分</td><td>阿里供应链联动、实时物流跟踪</td><td>ERP集成、物流节点可视化、全渠道交付</td></tr><tr><td><strong>统计分析</strong></td><td>★多表聚合、AI行为分析、自定义仪表盘</td><td>★BI/BW、12维度洞察、同比环比</td><td>★实时仪表板、行业定制分析、AI驱动</td><td>★数字大屏、360°客户视图、ROI分析</td><td>多维表格、可视化仪表盘、移动端查看</td><td>销售漏斗、企业版BI、业绩对比</td><td>多维度报表、工作台打通、实时数据</td><td>★BI平台、自定义报表、智能预测模型</td></tr><tr><td><strong>上下游协同</strong></td><td>★OpenCRM共生平台（全链路）、三流合一</td><td>★Business Network（全球B2B）、系统同步</td><td>★PRM（伙伴管理）、跨系统集成</td><td>外贸/教育行业对接、海关数据</td><td>售前售后群联动、内外部系统集成</td><td>PaaS扩展、第三方系统对接</td><td>钉钉生态连接、供应商/客户协同</td><td>★供应链协同模块、端到端流程打通</td></tr></tbody></table><h2>二、各维度深度对比与场景适配</h2><h3>1. 获客维度：解决“找对客户”的痛点</h3><p><strong>核心需求</strong>：多渠道线索整合、无效线索过滤、精准触达。 <strong>各品牌差异</strong>：</p><ul><li><strong>超兔一体云</strong>：<strong>toB专属获客工具</strong>是核心优势——工商搜客根据企业规模、行业、地域等特征搜索潜在客户，解决toB企业“找不到精准客户”的痛点；虎客名片/虎客号店通过微信生态获客，适合线下地推/会销。</li><li><strong>SAP</strong>：<strong>CRM + ERP整合</strong>是差异化——结合库存、供应链状态（如“某产品库存充足”）生成个性化营销方案（推送优惠），12维度客户洞察（如购买频率、偏好）挖掘潜在商机。</li><li><strong>Oracle CX</strong>：CDP（客户数据平台）**整合第一/三方数据（如电商行为、社交媒体），构建360°画像，支持跨渠道（广告、邮件、社交）精准触达，适合需要“精准营销”的企业。</li><li><strong>六度人和</strong>：<strong>外贸专属获客</strong>——海关数据获取海外采购商信息，智能电销系统提升线索转化率（某外贸企业线索转化提升30%），适合做跨境业务的企业。</li><li><strong>飞书CRM</strong>：<strong>AI线索清洗</strong>自动合并重复线索、标记无效号码，行为画像（如客户浏览官网页面、下载资料）识别高意向客户，适合用飞书生态的企业。</li><li><strong>红圈CRM</strong>：<strong>专业版营销活动管理</strong>支持活动规划、执行、ROI评估，适合有“系统化营销”需求的企业。</li><li><strong>钉钉CRM</strong>：<strong>生态线索整合</strong>——通过钉钉表单、小程序收集线索，利用钉钉的用户基础（超5亿用户）触达中小企业客户。</li><li><strong>销售易</strong>：<strong>AI精准营销</strong>——通过客户行为分析（如浏览产品页面、咨询客服）推送个性化内容，提升线索转化。</li></ul><h3>2. 销售维度：解决“高效转化”的痛点</h3><p><strong>核心需求</strong>：流程规范、商机管理、协作高效、AI辅助。 <strong>各品牌差异</strong>：</p><ul><li><strong>超兔一体云</strong>：<strong>三一客模型</strong>（定性、定级、定量）针对小单快单（如 SaaS、耗材），让销售明确“每个节点该做什么”；<strong>跟单时间线</strong>（超兔独有）可视化展示客户跟进全历史（如“3月1日发送报价单，3月5日客户反馈价格高”），避免遗漏关键动作。</li><li><strong>SAP</strong>：<strong>全流程自动化</strong>覆盖“询价 - 报价 - 订单 - 发货 - 开票”，减少人工干预（某制造企业销售流程效率提升40%）；<strong>移动CRM</strong>支持外勤销售实时查看客户数据（如库存状态、信用额度），适合经常出差的销售。</li><li><strong>Oracle CX</strong>：CPQ（配置报价）解决复杂产品报价问题（如“定制化设备含多个组件，自动计算总价”），<strong>合同管控</strong>内置合规条款库，超额度订单需审批（降低坏账风险），适合需要“规范销售流程”的企业。</li><li><strong>六度人和</strong>：<strong>微信/电话集成</strong>符合中国企业的沟通习惯（80%企业用微信沟通客户），<strong>私域分层运营</strong>（如将客户分为“潜在、成交、复购”）推送个性化内容（如老客户专属优惠），促进复购（某教育机构复购率提升25%）。</li><li><strong>飞书CRM</strong>：<strong>一客一群</strong>（销售 + 客户 + 售后 + 技术）实现实时协作（如“客户问产品售后，售后直接在群里回复”），<strong>AI拜访总结</strong>自动生成拜访记录（如“客户关注产品交付周期”），减少销售的文案工作。</li><li><strong>红圈CRM</strong>：<strong>全流程商机管理</strong>覆盖“线索→商机→合同→回款”，自定义流程引擎（如“线索分配给销售A→3天内跟进→未跟进自动提醒”），适合需要“标准化销售流程”的企业。</li><li><strong>钉钉CRM</strong>：<strong>协作审批</strong>（如“订单超过10万需经理审批”）让销售流程更规范，AI沟通助手生成营销文案（如“给客户的跟进短信”），适合用钉钉的中小企业。</li><li><strong>销售易</strong>：<strong>智能赢单预测</strong>通过AI分析（如客户沟通频率、订单金额）预测赢单概率（准确率达85%），让销售聚焦高概率客户，适合需要“提升销售效率”的企业。</li></ul><h3>3. 订单维度：解决“准确履约”的痛点</h3><p><strong>核心需求</strong>：订单类型覆盖、流程规范、系统集成。 <strong>各品牌差异</strong>：</p><ul><li><strong>超兔一体云</strong>：<strong>多类型订单</strong>覆盖标准订单、批发订单、租售一体单、维修工单、套餐订单（如“某设备租赁企业用租售一体单管理设备租赁 + 耗材销售”），<strong>锁库功能</strong>确保库存不超卖（如“客户下单后，系统自动锁定对应库存”）。</li><li><strong>SAP</strong>：<strong>ERP联动</strong>实时校验库存（避免超卖）和客户信用额度（如“客户欠款未还，无法下单”），多类型订单（如标准、退货、补货）覆盖全业务场景，适合大型企业的“复杂订单管理”。</li><li><strong>Oracle CX</strong>：<strong>全渠道订单履行</strong>支持线上（电商）、线下（门店）订单统一处理，CPQ解决复杂产品报价（如“定制化软件含多个模块，自动计算总价”），合规条款库避免合同风险。</li><li><strong>六度人和</strong>：<strong>外贸跨境链路</strong>支持跨境订单处理（如“美元结算、国际物流”），适合做外贸的企业。</li><li><strong>飞书CRM</strong>：<strong>合同/财务打通</strong>——订单生成后自动关联合同、财务系统（如“订单金额同步到财务系统，生成应收款”），适合用飞书的企业。</li><li><strong>红圈CRM</strong>：<strong>专业版订单管理</strong>支持订单、发票、交付单据管理，流程节点拆分（如“订单分为审核、备货、发货三个节点”），适合需要“精细化订单管理”的企业。</li><li><strong>钉钉CRM</strong>：<strong>阿里供应链集成</strong>——订单生成后自动同步到阿里供应链系统，实现“订单 - 物流”联动，适合用阿里生态的企业。</li><li><strong>销售易</strong>：<strong>ERP集成</strong>——订单数据同步到ERP系统（如“库存、财务”），物流节点跟踪（如“客户可查看订单的物流状态”），适合需要“系统整合”的企业。</li></ul><h3>4. 发货/物流跟踪维度：解决“可视化履约”的痛点</h3><p><strong>核心需求</strong>：物流状态可视化、上下游协同、系统集成。 <strong>各品牌差异</strong>：</p><ul><li><strong>超兔一体云</strong>：<strong>OpenCRM协同</strong>——通过OpenCRM平台连接供应商、客户，实现物流进度实时共享（客户可通过小程序查看物流）；<strong>扫码签收</strong>确保货物准确交付（快递员扫码后，系统自动更新状态）。</li><li><strong>SAP</strong>：SD模块（销售与分销）生成运输单据，实时监控物流状态（如“货物已发出、正在运输、已签收”），支持分批发货（如“客户订100台设备，先发50台”）。</li><li><strong>Oracle CX</strong>：<strong>SCM（供应链管理）集成</strong>——实时同步库存状态，<strong>现场服务模块</strong>优化备件物流（如“客户设备故障，系统自动分配附近的备件仓库发货”），适合需要“售后物流”的企业。</li><li><strong>六度人和</strong>：<strong>外贸物流链路</strong>——支持国际物流跟踪（如“ FedEx、DHL”），适合做跨境业务的企业。</li><li><strong>飞书CRM</strong>：<strong>第三方物流集成</strong>——通过集成顺丰、京东物流等第三方工具实现物流跟踪，适合用飞书的企业。</li><li><strong>红圈CRM</strong>：<strong>定制开发</strong>——根据企业需求对接第三方物流系统，适合有“个性化物流”需求的企业。</li><li><strong>钉钉CRM</strong>：<strong>阿里供应链联动</strong>——通过阿里供应链系统实时跟踪物流状态（如“订单已发货，客户可在钉钉查看物流”），适合用阿里生态的企业。</li><li><strong>销售易</strong>：<strong>物流节点可视化</strong>——客户可查看订单的物流状态（如“已 pickup、在途、已送达”），适合需要“物流透明化”的企业。</li></ul><h3>5. 统计分析维度：解决“数据驱动决策”的痛点</h3><p><strong>核心需求</strong>：多维度分析、AI洞察、自定义报表。 <strong>各品牌差异</strong>：</p><ul><li><strong>超兔一体云</strong>：<strong>多表聚合引擎</strong>支持跨表查询（如“销售业绩 + 客户行业 + 地区”），<strong>AI分析</strong>自动抓取客户沟通内容（如微信/电话），智能判断客户意向（如“客户提到‘价格高’，系统标记为‘需跟进价格’”），自定义仪表盘（如“销售业绩、线索转化、客户满意度”）。</li><li><strong>SAP</strong>：BI/BW（商业智能）系统提供企业级数据分析，12维度客户洞察（如购买频率、偏好、利润贡献），同比环比分析（如“本月销售额比上月增长10%”），适合大型企业的“深度数据分析”。</li><li><strong>Oracle CX</strong>：<strong>实时仪表板</strong>可视化展示关键指标（如“营销ROI、销售预测、订单履约率”），<strong>行业定制分析</strong>（如工业制造的“大客户分层运营”、零售的“促销活动ROI”），适合需要“行业化分析”的企业。</li><li><strong>六度人和</strong>：<strong>数字大屏</strong>展示核心数据（如“今日新增线索、本月销售额、客户满意度”），360°客户视图（如“客户的购买历史、沟通记录、投诉记录”），某银行用其提升交叉销售率42%。</li><li><strong>飞书CRM</strong>：<strong>多维表格</strong>自定义报表（如“按地区统计销售业绩”），可视化仪表盘（如“销售漏斗、业绩达成率”），移动端实时查看数据（如销售在外可查看当天业绩）。</li><li><strong>红圈CRM</strong>：<strong>销售漏斗</strong>展示线索到客户的转化过程，企业版BI系统支持复杂分析（如“销售团队业绩对比”），适合需要“系统化分析”的企业。</li><li><strong>钉钉CRM</strong>：<strong>多维度报表</strong>（如“按客户类型统计销售额”），工作台打通（如“钉钉工作台展示销售业绩”），实时数据更新（如“客户下单后，业绩实时更新”）。</li><li><strong>销售易</strong>：<strong>BI平台</strong>支持自定义报表（如“按产品统计销售额”），<strong>智能预测模型</strong>（如“下月销售额预测”），适合需要“数据驱动决策”的企业。</li></ul><h3>6. 上下游协同维度：解决“全链路联动”的痛点</h3><p><strong>核心需求</strong>：开放式平台、生态联动、全链路协同。 <strong>各品牌差异</strong>：</p><ul><li><p><strong>超兔一体云</strong>：<strong>OpenCRM共生平台</strong>（核心优势）——连接供应商、客户、合作伙伴，实现“询价 - 采购 - 订单 - 物流 - 对账”全链路协同：</p><ul><li>上游：企业发布询价单，供应商通过平台报价，系统自动比价；</li><li>下游：企业生成订单，客户通过平台确认订单、查看物流、签收；</li><li>安全控制：批量开通伙伴用户，未授权用户无法查看数据。 适合需要“全链路协同”的toB企业。</li></ul></li><li><strong>SAP</strong>：<strong>Business Network</strong>（全球最大B2B平台，年交易额超6.3万亿美元）——连接全球供应商、客户，实现“研发 - 采购 - 生产 - 销售 - 物流”协同，适合全球化企业。</li><li><strong>Oracle CX</strong>：PRM（合作伙伴关系管理）管理经销商、供应商，跨系统集成（如ERP、MES）确保数据一致，适合需要“伙伴协同”的企业。</li><li><strong>六度人和</strong>：<strong>行业对接</strong>——外贸对接海关数据，教育对接学邦ERP，适合特定行业的“上下游协同”。</li><li><strong>飞书CRM</strong>：<strong>内外部联动</strong>——通过飞书群连接售前、售后、客户，实现问题快速解决（如“客户投诉，销售、售后在群里同步处理”），适合用飞书的企业。</li><li><strong>红圈CRM</strong>：<strong>PaaS扩展</strong>——通过PaaS平台对接第三方系统（如ERP、物流），实现上下游协同，适合需要“自定义协同”的企业。</li><li><strong>钉钉CRM</strong>：<strong>生态连接</strong>——通过钉钉连接供应商、客户，实现“订单 - 物流 - 对账”协同（如“供应商通过钉钉查看采购单，客户通过钉钉确认收货”），适合用钉钉的中小企业。</li><li><strong>销售易</strong>：<strong>供应链协同模块</strong>——整合供应商管理系统，实现“采购 - 生产 - 销售”协同（如“销售订单生成后，系统自动通知供应商备货”），适合需要“供应链联动”的企业。</li></ul><p>（注：文中功能相关描述均基于公开披露信息，具体功能服务以厂商实际落地版本为准。）</p>]]></description></item><item>    <title><![CDATA[活动推荐：1 月 24 日北京｜Data for AI Meetup：Agent 时代的数据基础设施]]></title>    <link>https://segmentfault.com/a/1190000047553003</link>    <guid>https://segmentfault.com/a/1190000047553003</guid>    <pubDate>2026-01-20 12:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>以下内容来源于DataforAI社区，作者Data for AI</p><h2><strong>当 AI 遇见数据：一场面向工程实践的技术交流</strong></h2><p>大模型并没有直接带来 AI 应用的成熟。真正决定 AI 能否规模化落地的，正在从模型本身，转移到<strong>数据、上下文与基础设施</strong>。</p><p>与此同时，数据基础设施也正经历一轮深刻演进：从传统的数据湖仓，到多模态数据管理；从 SQL 查询引擎，到面向 AI 的数据解析与治理能力。这些变化，正在重新定义我们构建 AI 应用的方式。</p><p><strong>1 月 24 日（周六）下午</strong> ，<strong>Data for AI 社区</strong> 将携手 <strong>ALC Beijing (Apache Local Community Beijing)</strong> 举办 <strong>Data for AI Meetup Beijing</strong>，邀请来自产业、开源社区与学术界的一线实践者，围绕 <strong>AI 时代的数据基础设施演进</strong> 展开深入交流。</p><p>本次 Meetup 汇聚了来自 <strong>字节跳动火山引擎 / Daft 社区、OceanBase社区、北京大学、Datastrato / Apache Gravitino 社区、Zilliz / Milvus 社区</strong>的技术专家，深度剖析 AI 时代数据基础设施的技术演进路径。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553005" alt="" title=""/></p><h2>📍 本次 Meetup 核心看点</h2><ul><li><p><strong>多模态数据处理引擎实践：</strong></p><p>Daft 在 AI 数据预处理与训练加载中的工程经验</p></li><li><p><strong>AI 原生元数据平台：</strong></p><p>Apache Gravitino 1.1.0 的关键能力与治理实践</p></li><li><p><strong>Agent 数据基座设计：</strong></p><p>记忆、检索与数据统一的工程解法</p></li><li><p><strong>Data-centric AI 方法论：</strong></p><p>面向大模型的数据准备与质量体系</p></li><li><p><strong>混合检索实践：</strong></p><p>向量 + 全文检索在真实业务中的优化路径</p></li><li><p><strong>开源探索：</strong></p><p>Skill 驱动的上下文工程平台化可能性</p></li><li><p><strong>圆桌讨论：</strong></p><p>下一代面向 AI 应用的数据基础设施如何设计与落地</p></li></ul><hr/><h2>多模态数据处理的新范式</h2><p>AI 训练对数据处理提出了全新挑战。火山引擎 AI 数据湖服务架构师 琚克俭 将分享 Daft 在多模态数据处理上的工程实践，聚焦图像、视频、文本等异构数据在统一处理、预处理与训练加载阶段的性能与架构挑战。</p><p>这一分享直面当前 AI 工程的核心痛点：传统数据引擎已难以支撑多模态 AI 工作负载，而 Daft 通过全新的架构设计，在数据预处理和训练加载环节实现了显著的性能提升。</p><h2>元数据治理进入 AI 原生时代</h2><p>Datastrato VP of Engineering 史少锋 将深度解析 Apache Gravitino 1.1.0 的核心升级，包括 Lance REST 支持、Generic Lakehouse Catalog、Iceberg 安全增强等关键特性。</p><p>当 AI 团队需要在多个集群间管理训练数据、推理数据和模型元数据时，传统的元数据工具往往各自为政。Apache Gravitino 1.1.0 通过统一的元数据治理架构，让跨引擎、跨存储的数据协同变得标准化、可管理，大幅降低 AI 工程中的数据协同成本。</p><h2>上下文工程：Agent 落地的数据基座</h2><p>OceanBase 技术专家 汤庆 将深度解析当下最热的「上下文工程」话题。他指出，企业级 Agent 面临三大核心挑战：如何让 Agent 拥有可靠的「记忆」（记忆管理）、如何让 Agent「理解」复杂文档（知识检索），以及如何统一处理向量、文本、结构化数据（数据统一）。</p><p>这三款 AI 产品的协同设计给出了答案：PowerMem 基于艾宾浩斯遗忘曲线构建智能记忆系统并支持多智能体隔离，PowerRAG 提供多引擎 OCR 与向量 + 全文的混合检索能力，seekdb 则作为 AI 原生数据库统一管理多模态数据并兼容 MySQL 生态。这套方案的核心价值在于：用数据架构的确定性，对抗 Agent 行为的不确定性。</p><h2>面向大模型时代的 Data-centric AI 基础设施</h2><p>北京大学助理教授 张文涛 将从学术与工程结合的视角，系统阐述 AI 从「模型为中心」到「数据为中心」的范式转变。当大模型能力趋同，数据质量正在成为决定模型性能的关键变量。</p><p>张文涛团队主导开发的 DataFlow 数据准备系统已在大模型预训练、企业知识库构建等场景得到验证。本次分享将深入解析 LLM 数据工程的完整流程：如何获取数据（爬取、解析、合成、标注），如何处理数据（过滤、改写、配比），以及如何评估数据质量。这套开源工具链与方法论，正在为 AI 开发者降低数据工程的门槛。</p><h2>从向量检索到混合查询：Context Engineering 实践</h2><p>Zilliz 资深解决方案架构师 刘汉卿 将系统回顾从 Prompt Engineering 到 Context Engineering 的演进路径。随着 RAG 技术从单一向量检索发展到 GraphRAG 与全文检索的混合查询阶段，检索系统已经从「找到相似内容」进化到「理解查询意图并精准召回」。</p><p>在这个演进过程中，一个关键趋势是：用向量计算代替多轮LLM推理，通过检索层的优化来提升 AI 应用的性能与稳定性。刘汉卿将结合企业知识库、推荐系统、智能助理等场景，分享混合查询的工作流搭建经验，以及在金融、医疗、法律、教育等行业的实际落地案例。</p><h2>上下文工程的平台化探索</h2><p>独立开源开发者 袁怿（Sam Yuan）将从前瞻视角探讨 2026 年上下文工程的技术趋势。如果说 2025 是 Agent 元年，那么随着上下文工程的快速演进，一个关键问题正在浮现：上下文能力是否应该从「各自实现」走向「横向平台化」？</p><p>袁怿将上下文工程拆解为三个维度：工具调用（空间维度）、RAG（信息密度维度）与 Memory（时间维度）。他将以最近进入 AAIF 的 Skill 机制为切入点，对比 Skill 与传统 Function Call 的本质差异，并结合他在开源社区贡献的 StructuredContextLanguage 项目，展示以渐进式加载为代表的平台化思路——让 AgentOS 像操作系统管理进程一样，统一管理上下文资源。</p><hr/><h2>圆桌论坛：下一代面向 AI 应用的 Data Infra 的设计和落地</h2><p>从多模态数据处理到 AI 原生元数据平台，从上下文工程到混合检索系统——本次 Meetup 的所有分享指向同一个命题：<strong>在 Agent 时代，数据不再只是「被调用的资源」，而正在成为被理解、被约束、被治理的核心能力。</strong></p><p>越来越多团队在实践中遇到相似挑战：Agent 需要访问的数据分散在不同系统中，权限、语义与上下文边界不清；模型可以生成「看似合理」的请求，却难以保证结果的安全性与一致性。这些问题往往无法通过 Prompt 或单点优化解决。</p><p>我们特邀到前 Apple 数据与机器学习平台负责人 谭涛（Kwaai AI Lab 顾问）、Datastrato 创始人 CEO 堵俊平、北京大学助理教授 张文涛 三位圆桌嘉宾，围绕三个核心问题展开讨论：</p><ul><li><strong>意图与执行解耦</strong>：如何让 Agent 的数据请求既灵活又可控？</li><li><strong>访问规则原生化</strong>：能否在系统层面保证数据访问的安全性与一致性？</li><li><strong>上下文边界管理</strong>：如何让 Agent Builder 在不理解底层架构的前提下获取「该拿的数据」？</li></ul><p>这些讨论并不立马给出最终答案，而是帮助我们勾勒下一代面向 AI 应用的数据基础设施轮廓——一个更开放、更可治理、也更适合 Agent 时代的技术底座。</p><h2>活动信息</h2><p><strong>时间</strong>：</p><p>2026 年 1 月 24 日（周六）13:10 – 18:00</p><p><strong>地点</strong>：</p><p>北京 · 原点学堂（东升大厦 A 座 10 层）（不提供线上直播）</p><p><strong>立即报名：</strong></p><p>👉 访问链接：<a href="https://link.segmentfault.com/?enc=snOBzx6Eb9yCZkJ3tK8rRQ%3D%3D.gddrytSwZIYOQAykaoVTzUi%2BfSFy%2B5A9abpWEiqTHEx3B1pQ8Dya4xXoaUksolAZ" rel="nofollow" target="_blank">https://www.huodongxing.com/event/3843480320400</a></p><p>⚠ 名额有限，需审核通过（请详实填写报名信息，并通过主理人的微信添加请求，确认审核状态）</p><p>这是一场面向 AI &amp; Data 工程实践者的技术深度交流。</p><p>无论你是正在构建企业级 Agent 系统的架构师，</p><p>还是关注 Data-centric AI 的研发工程师，</p><p>都能在这里找到有价值的技术洞察和落地经验。</p><p><strong>Community Over Code，期待与你在北京相聚。</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553006" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553007" alt="" title="" loading="lazy"/></p><p><a href="https://link.segmentfault.com/?enc=VoU4Df0fM6uWnvBZQygRSg%3D%3D.DHB2f28yCBnRj%2BD7%2BRbf4tnOdBRCvC1DPT5HBapikMg%3D" rel="nofollow" target="_blank">阅读更多 Voice Agent 学习笔记：了解最懂 AI 语音的头脑都在思考什么</a></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047553008" alt="" title="" loading="lazy"/><br/>​</p>]]></description></item><item>    <title><![CDATA[Java 合并 PowerPoint：高效处理幻灯片的技术教程 Lu_Lu ]]></title>    <link>https://segmentfault.com/a/1190000047552705</link>    <guid>https://segmentfault.com/a/1190000047552705</guid>    <pubDate>2026-01-20 11:07:53</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在现代企业和个人开发中，文档处理是不可或缺的一环。尤其是在报告演示、内容整合等场景下，PowerPoint 文件（PPT/PPTX）的自动化处理需求日益增长。当我们需要将多个演示文稿或其中的特定幻灯片合并时，手动操作不仅效率低下，而且容易出错。本文将深入探讨如何利用 Java 编程语言，结合强大的 Spire.Presentation for Java 库，实现 PowerPoiont 文件的合并，为开发者提供一套高效、灵活的解决方案。</p><h2>Spire.Presentation for Java 库简介与安装</h2><p>Spire.Presentation for Java 是一个功能丰富的 Java API，专为创建、读取、编辑、转换和打印 PowerPoint 演示文稿而设计。它支持 PPT、PPTX、PPS、PPSX 等多种格式，无需安装 Microsoft Office，即可在 Java 应用程序中轻松处理幻灯片、文本、图片、表格、图表、多媒体等元素。其高性能和易用性使其成为 Java 处理 PowerPoint 的理想选择。</p><p>要使用 Spire.Presentation for Java，您可以通过 Maven 配置依赖。</p><p><strong>Maven依赖配置：</strong></p><pre><code class="xml">&lt;repositories&gt;
    &lt;repository&gt;
        &lt;id&gt;com.e-iceblue&lt;/id&gt;
        &lt;name&gt;e-iceblue&lt;/name&gt;
        &lt;url&gt;https://repo.e-iceblue.cn/repository/maven-public/&lt;/url&gt;
    &lt;/repository&gt;
&lt;/repositories&gt;
&lt;dependencies&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;e-iceblue&lt;/groupId&gt;
        &lt;artifactId&gt;spire.presentation&lt;/artifactId&gt;
        &lt;version&gt;11.1.1&lt;/version&gt;
    &lt;/dependency&gt;
&lt;/dependencies&gt;</code></pre><p>您也可以直接从 Spire.Presentation for Java 官方网站下载 JAR 包，并手动添加到您的项目类路径中。</p><h2>合并来自外部文件的指定幻灯片</h2><p>有时我们不需要合并整个演示文稿，而仅仅需要从一个或多个文件中提取特定的幻灯片，并将其插入到目标演示文稿中。Spire.Presentation 提供了灵活的 API 来实现这一需求。</p><p>以下代码示例演示了如何从两个源 PPTX 文件中提取指定幻灯片，并将其插入到一个新的演示文稿中。</p><pre><code class="java">import com.spire.presentation.*;

public class MergeFiles1 {
    public static void main(String[] args) throws Exception{
        //加载文档1，获取第三张幻灯片
        Presentation ppt1 = new Presentation();
        ppt1.loadFromFile("test1.pptx");
        ISlide slide = ppt1.getSlides().get(2);

        //加载文档2，将文档1中获取的幻灯片作为第二张插入到文档2
        Presentation ppt2 = new Presentation();
        ppt2.loadFromFile("test2.pptx");
        int index = 1;
        ppt2.getSlides().insert(index,slide);

        //保存文档2
        ppt2.saveToFile("merge1.pptx",FileFormat.PPTX_2013);
        ppt2.dispose();
    }
}</code></pre><p><strong>代码解析：</strong></p><ul><li><code>new Presentation()</code>：创建一个演示文稿对象，作为我们合并操作的容器。</li><li><code>ppt1.loadFromFile()</code>：加载一个幻灯片文件作为源文档。</li><li><code>ISlide slide = ppt1.getSlides().get(2)</code>：获取源文档上的某一页幻灯片。</li><li><code>ppt2.loadFromFile()</code>：加载另一个 PowerPoint 文件作为目标文档。</li><li><code>ppt2.getSlides().insert(index,slide)</code>：将源文档获取到幻灯片插入到目标文档中，<code>index</code> 就是插入的位置。</li><li><code>ppt2.saveToFile()</code>：将合并后的演示文稿保存为新的 PPTX 文件。</li></ul><h2>将多个 PowerPoint 文件合并为一个新的文件</h2><p>将多个完整的 PowerPoint 文件按顺序合并成一个全新的演示文稿也是一个常见的需求，尤其是在演示文稿都是关于同一主题时。Spire.Presentation 同样提供了简洁高效的方法来实现这一目标。</p><p>下面的代码示例展示了如何将两个独立的 PPTX 文件合并成一个统一的演示文稿。</p><pre><code class="java">import com.spire.presentation.*;

public class MergeFiles2 {
    public static void main(String[] args)throws  Exception {
        //加载文档1，文档2
        Presentation ppt1 = new Presentation();
        ppt1.loadFromFile("test1.pptx");
        Presentation ppt2 = new Presentation();
        ppt2.loadFromFile("test2.pptx");

        //遍历文档1的所有幻灯片，添加到文档2
        for(int i = 0;i&lt;ppt1.getSlides().getCount();i++){
            ppt2.getSlides().append(ppt1.getSlides().get(i));
        }

        //保存文档2
        ppt2.saveToFile("merge2.pptx",FileFormat.PPTX_2013);
        ppt2.dispose();
    }
}</code></pre><p><strong>代码解析：</strong></p><ul><li><code>ppt2.getSlides().append(ppt1.getSlides().get()</code>：这是实现多个演示文稿合并的关键。<code>append()</code> 方法会将源文档中的所有幻灯片按原顺序复制到当前演示文稿的末尾。这个过程会自动处理幻灯片的主题、布局、内容等，确保合并后的演示文稿保持一致性和完整性。</li><li>循环处理多个文件，确保所有源文件的幻灯片都被添加到目标演示文稿中。</li></ul><hr/><h2>结语</h2><p>通过上述详细的 Java 代码示例，我们不难看出 Spire.Presentation for Java 在处理 PowerPoint 合并任务上的强大能力和便捷性。无论是精确到指定幻灯片的合并，还是将多个完整演示文稿整合，该库都能提供高效且稳定的解决方案。</p><p>这种基于 Java 的 PowerPoint 合并幻灯片编程开发技术教程极大地提升了 Java 在文档处理领域的实用性，为自动化报告生成、内容聚合等场景提供了坚实的技术支撑。掌握这些技能，开发者可以更灵活地应对各种文档处理挑战，优化工作流程，提高开发效率。未来，我们还可以进一步探索幻灯片内容的修改、格式调整乃至更复杂的自动化操作，让 Java 在 PowerPoint 技术教程 中发挥更大的作用。</p>]]></description></item>  </channel></rss>