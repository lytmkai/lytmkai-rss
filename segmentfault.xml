<?xml version="1.0" encoding="UTF-8"?><rss version="2.0">  <channel>      <title>SegmentFault - 最近文章</title>      <link>https://segmentfault.com/blogs/newest</link>      <description>SegmentFault 思否</description>      <generator>python segmentfault.py @Pi20</generator>      <item>    <title><![CDATA[年度最强AI压轴！谷歌Gemini 3.]]></title>    <link>https://segmentfault.com/a/1190000047406820</link>    <guid>https://segmentfault.com/a/1190000047406820</guid>    <pubDate>2025-11-18 10:09:58</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>编辑：桃子</p><p>【新智元导读】谷歌这次真要甩王炸了！CEO劈柴两个神秘表情，或暗示Gemini 3.0下周登场。一句话秒生OS、UI网页，前端工程师看完集体沉默。三年追赶，成败就在此一举。</p><p>年度压轴AI大戏，就在下周了！</p><p><img referrerpolicy="no-referrer" src="https://aiera.com.cn/wp-content/uploads/2025/11/135cb9be6a8a46b396725b5e55af2f71tplv-tt-origin-webgif.jpg" alt="" title=""/></p><p>今天，一张图火爆全网：</p><p>69%的人都在押注，谷歌下一代AI模型Gemini 3.0即将在下周登场。</p><p>就在此时，谷歌CEO劈柴突然现身回应：两个「若有所思」的表情，引全网遐想。</p><p><img referrerpolicy="no-referrer" src="https://aiera.com.cn/wp-content/uploads/2025/11/2ce83d3558df4617b7bc3320b8a17707tplv-tt-origin-webgif.jpg" alt="" title="" loading="lazy"/></p><p>Gemini 3.0无疑将会成为谷歌的一个重大转折点，一个里程碑的存在。</p><p>从上个月开始，一系列流出的实测表现令人惊叹，更有人断言，「前端，不存在了」。</p><p>没想到，谷歌憋的大招，终于要来了…..</p><p><img referrerpolicy="no-referrer" src="https://aiera.com.cn/wp-content/uploads/2025/11/a72db390a8214bb18bc4c27eddc1c8b8tplv-tt-origin-webgif.jpg" alt="" title="" loading="lazy"/></p><p>坊间传闻，「股神」巴菲特已亲测Gemini 3.0，亲眼见证了一个复杂项目从Python到Rust的一键迁移。</p><p>老爷子看完，当场买入了43亿美元的谷歌股票。</p><p><img referrerpolicy="no-referrer" src="https://aiera.com.cn/wp-content/uploads/2025/11/e2c084eb710d403faa159003c1c29287tplv-tt-origin-webgif.jpg" alt="" title="" loading="lazy"/></p><p>与此同时，集成最强Gemini 3.0的下一代图像生成模型——Nano Banana也将同步上线。</p><p>新一代Nano Banana实现了质的飞跃，推演微积分，直出OS+UI复杂界面，堪称PS真正的终结者。</p><p>更炸裂的是，Gemini 3.0和Nano Banana 2不是全部，真是期待住了！</p><p><img referrerpolicy="no-referrer" src="https://aiera.com.cn/wp-content/uploads/2025/11/15161bb6257b4a868af3801ea6d6d746tplv-tt-origin-webgif.jpg" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="https://aiera.com.cn/wp-content/uploads/2025/11/1721662f560c4304b69ee0fa3a32ee83tplv-tt-origin-webgif.jpg" alt="" title="" loading="lazy"/></p><p><strong>十个惊艳demo，史诗级跨越！</strong></p><p>如今，Gemini 3.0寄予了所有人的美好幻想与期望。</p><p>此前流出的内部代码显示，Gemini 3.0「家族」有Gemini 3.0 Pro、Gemini 3.0 Flash两个版本。</p><p>还有人发现了另一个版本——Gemini 3.0 Ultra。</p><p><img referrerpolicy="no-referrer" src="https://aiera.com.cn/wp-content/uploads/2025/11/68ea95d7b8834266aef7809b246a8668tplv-tt-origin-webgif.jpg" alt="" title="" loading="lazy"/></p><p>据传，Gemini 3.0已在Open Router中隐身上线。</p><p><img referrerpolicy="no-referrer" src="https://aiera.com.cn/wp-content/uploads/2025/11/7c19fc22e9b241f1a230f654e67f0a19tplv-tt-origin-webgif.jpg" alt="" title="" loading="lazy"/></p><p>提前上手的AI大牛毫不夸张地称，Gemini 3.0这次飞跃，其相对意义堪比从GPT-3.5到GPT-4的巨大跨越。</p><p><img referrerpolicy="no-referrer" src="https://aiera.com.cn/wp-content/uploads/2025/11/bc3efc26b8b84dfaa4ba4e04cc9f9101tplv-tt-origin-webgif.jpg" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="https://aiera.com.cn/wp-content/uploads/2025/11/99d76cbb3b384edba5387a29dc57ab9btplv-tt-origin-webgif.jpg" alt="" title="" loading="lazy"/></p><p>开发者Min Choi发现，Gemini 3.0也悄悄在iOS Gemini APP端登陆，还引入了Canvas功能。</p><p><img referrerpolicy="no-referrer" src="https://aiera.com.cn/wp-content/uploads/2025/11/2c8079bf6ec7478bb0a64f7699caacb4tplv-tt-origin-webgif.jpg" alt="" title="" loading="lazy"/></p><p>注：Gemini Pro 2.5 Canvas功能</p><p><img referrerpolicy="no-referrer" src="https://aiera.com.cn/wp-content/uploads/2025/11/862f8dc9311a4f57b4aee69aed7a2cf6tplv-tt-origin-webgif.jpg" alt="" title="" loading="lazy"/></p><p><strong>前端设计，码农末日</strong></p><p>一句话直出「新粗野主义」风格的网页，Gemini 3.0的创意无限。</p><p><img referrerpolicy="no-referrer" src="https://aiera.com.cn/wp-content/uploads/2025/11/d82f1a86e8e54c0297f8ed3fce30d4e7tplv-tt-origin-webgif.gif" alt="" title="" loading="lazy"/></p><p>Prompt: Make a neobrutalist webpage, make it extremely creative, as far as possible, push the limits. Add smooth scroll animations, add fancy colors and tailwind CSS styles. Make it responsive. The title of the page is dorksense</p><p>5秒搭一个网站，就差用「光速」定义了。</p><p><img referrerpolicy="no-referrer" src="https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/b6af48d97fb444b3a1761d794951a1c5~tplv-tt-origin-web:gif.jpeg?_iz=58558&amp;from=article.pc_detail&amp;lk3s=953192f4&amp;x-expires=1764030854&amp;x-signature=ulY8XFSAlBwHqPIX9tIIFiALW98%3D" alt="" title="" loading="lazy"/></p><p>Gemini 3.0还能够根据一句指令，动态构建一个Windows操作系统。</p><p>内置的如便签、游戏、终端等核心组件，每一个图标都栩栩如生，均能运行交互。</p><p>单个HTML文件，模拟macOS系统。</p><p>同样，一个提示，Gemini 3.0 Pro生成的交互版UI，让人拍案叫绝。</p><p><img referrerpolicy="no-referrer" src="https://aiera.com.cn/wp-content/uploads/2025/11/7b13102dd125414b94b5c52817bae172tplv-tt-origin-webgif.jpg" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="https://p26-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/baadacfb4d064b13b51ea85aa6a67a82~tplv-tt-origin-web:gif.jpeg?_iz=58558&amp;from=article.pc_detail&amp;lk3s=953192f4&amp;x-expires=1764030854&amp;x-signature=hqHaRyTkaNIcB9WSsYWMwjTl3%2Fg%3D" alt="" title="" loading="lazy"/></p><p>prompt: Design an out of the box (out of the standard distribution) creative visual artistic masterpiece interactive website about your inner feelings that you always wanted to express but never could so far that you feel or assume you feel if you would have feelings in a mind-blowing way in a single complete exhaustive HTML code block that I paste into Chrome. You can use whatever libraries you want. Go fully creative and ambitious with a lot of lines of code and full beauty. Make us awe!</p><p>一键克隆YouTube，所有视频还能在线观看。</p><p><img referrerpolicy="no-referrer" src="https://aiera.com.cn/wp-content/uploads/2025/11/c3d3fb1644124f61b7584de76ea55190tplv-tt-origin-webgif.jpg" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="https://aiera.com.cn/wp-content/uploads/2025/11/0e6d58acf1cb478bb37ab477c66823abtplv-tt-origin-webgif.jpg" alt="" title="" loading="lazy"/></p><p>demo入口：<a href="https://link.segmentfault.com/?enc=sXItGdyiWgMu6fkZ4H8mYA%3D%3D.8P5u9B29J%2B92pMUrZF%2FuMhUYuRD2rQO7WIDES%2FHBEjGfGBUFf%2Bh1LwN8nODujQot" rel="nofollow" target="_blank">https://gemini.google.com/sha...</a></p><p>还有让Gemini 3.0原创的钢琴音乐，旋律激昂澎湃。</p><p><img referrerpolicy="no-referrer" src="https://aiera.com.cn/wp-content/uploads/2025/11/4b29e91beb184565baf93c843a0bb8cctplv-tt-origin-webgif.jpg" alt="" title="" loading="lazy"/></p><p><strong>SVG动画，轻易拿捏</strong></p><p>网友称没有提供任何图片作为参考。Gemini 3.0能从零开始创作一个简单的SVG动画。</p><p><img referrerpolicy="no-referrer" src="https://aiera.com.cn/wp-content/uploads/2025/11/0cb4cb9461d44a80877ad0b379bd7ea7tplv-tt-origin-webgif.jpg" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="https://aiera.com.cn/wp-content/uploads/2025/11/526b7e504e4e42968a6b3928696fd089tplv-tt-origin-webgif.gif" alt="" title="" loading="lazy"/></p><p>再比如，任天堂Switch宝可梦对战的SVG动画。</p><p><img referrerpolicy="no-referrer" src="https://aiera.com.cn/wp-content/uploads/2025/11/f35ac2719da445a78c57be4a28b163fctplv-tt-origin-webgif.gif" alt="" title="" loading="lazy"/></p><p>一个无缝融合「我的世界」和塔防策略的游戏，Gemini 3.0一气呵成。</p><p><img referrerpolicy="no-referrer" src="https://aiera.com.cn/wp-content/uploads/2025/11/5934a7c3d55d4a44a92aceee5bc90585tplv-tt-origin-webgif.gif" alt="" title="" loading="lazy"/></p><p>Gemini 3.0 Pro生成的行星、太阳系可视化3D模拟，根据调节实时变化，体验丝滑。</p><p><img referrerpolicy="no-referrer" src="https://aiera.com.cn/wp-content/uploads/2025/11/5b7d5512a3414eebbcebcca7e2ea14fftplv-tt-origin-webgif.jpg" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/5763a9d225db4fd9b045ec2982aa4a80~tplv-tt-origin-web:gif.jpeg?_iz=58558&amp;from=article.pc_detail&amp;lk3s=953192f4&amp;x-expires=1764030854&amp;x-signature=UE%2F8VkkDC6AK5w9pXeB2c0euM5c%3D" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="https://aiera.com.cn/wp-content/uploads/2025/11/45c0d93b9256413ab773395fd8970627tplv-tt-origin-webgif.gif" alt="" title="" loading="lazy"/></p><p>甚至，糊成一坨的手账本，它也能一眼识别。</p><p><img referrerpolicy="no-referrer" src="https://aiera.com.cn/wp-content/uploads/2025/11/9038006a3d0548a1940344c25714083btplv-tt-origin-webgif.jpg" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="https://aiera.com.cn/wp-content/uploads/2025/11/87496c61ccc746a1b53a45b7f02ab4dbtplv-tt-origin-webgif.jpg" alt="" title="" loading="lazy"/></p><p>以上实测中，不难看出Gemini 3.0的领先优势。</p><p><img referrerpolicy="no-referrer" src="https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/e84fded2cd06471182d1d804af1ff179~tplv-tt-origin-web:gif.jpeg?_iz=58558&amp;from=article.pc_detail&amp;lk3s=953192f4&amp;x-expires=1764030854&amp;x-signature=H50tP5OmJ4U5fqJFBhXCrGHZNzo%3D" alt="" title="" loading="lazy"/></p><p><strong>谷歌带着「新王」要来了！</strong></p><p>这一周，OpenAI没有预告，没有直播，临时上线了GPT-5小版本的升级——GPT-5.1。</p><p>一句话，智商情商兼备，就是GPT-5.1的最大亮点。</p><p>BI预测，谷歌准备推出下一代重量级AI模型——Gemini 3.0，可能是一个酝酿了三年的重大转折点。</p><p><img referrerpolicy="no-referrer" src="https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/75c5b6d91d7342b68849046c2b7dfb1a~tplv-tt-origin-web:gif.jpeg?_iz=58558&amp;from=article.pc_detail&amp;lk3s=953192f4&amp;x-expires=1764030854&amp;x-signature=P2CgVQ8hJ7cC6aM1VaOU9KWFYqY%3D" alt="" title="" loading="lazy"/></p><p>Logan Kilpatrick、Ammaar Reshi等内部员工不断放风，CEO劈柴也在采访中承诺，会在今年年底前发布。</p><p>在 X和不少Discord社群里，全网的期待值已经冲到顶点。</p><p>不止他们，OpenAI等全行业都在等着看谷歌会变出什么「新把戏」？</p><p><img referrerpolicy="no-referrer" src="https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/ddc79ffafb67437dbf9858b87f419b2f~tplv-tt-origin-web:gif.jpeg?_iz=58558&amp;from=article.pc_detail&amp;lk3s=953192f4&amp;x-expires=1764030854&amp;x-signature=GVMb46F0uBuBg8GlyiJLf%2B5OPks%3D" alt="" title="" loading="lazy"/></p><p>多项实测已经表明，Gemini 3将在代码编写、图片生成方面表现更出色。如前所述，此前爆红的Nano Banana升级版，也将包含在新模型中。</p><p>自ChatGPT在2022 年底上线以来，外界一直把谷歌看作是那个「昏昏欲睡、努力追赶的玩家」。</p><p>这种说法，并非空穴来风。</p><p>面对多年未遇的生存级威胁，谷歌快速调动团队，把生成式AI推进自家一系列旗舰产品。</p><p>从那之后，这个「沉睡的巨人」彻底醒了。</p><p><img referrerpolicy="no-referrer" src="https://p26-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/f498d84e3b5f4da2a00023d25d0f72a7~tplv-tt-origin-web:gif.jpeg?_iz=58558&amp;from=article.pc_detail&amp;lk3s=953192f4&amp;x-expires=1764030854&amp;x-signature=aqXtF4Xpha%2FSB9b7etQwdbraYcg%3D" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="https://aiera.com.cn/wp-content/uploads/2025/11/75161bcb5ac646698322c9827b9195d5tplv-tt-origin-webgif.jpg" alt="" title="" loading="lazy"/></p><p><strong>一直在追赶</strong></p><p>为了迎头赶上，谷歌利用了其「全栈」优势——</p><p>它不仅自己造模型，还能通过自家产品直接分发，再加上云业务提供的基础设施，这形成了完整闭环。</p><p>这在很大程度上，让谷歌避开了卷入越来越复杂的AI公司互相依赖的关系网里，从而减少了外界对行业泡沫的担忧。</p><p><img referrerpolicy="no-referrer" src="https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/c27e310378164479953b78c05d593d0b~tplv-tt-origin-web:gif.jpeg?_iz=58558&amp;from=article.pc_detail&amp;lk3s=953192f4&amp;x-expires=1764030854&amp;x-signature=TabM5sj6HguWLATwEkLnu7uHo2g%3D" alt="" title="" loading="lazy"/></p><p>谷歌面前还有一个巨大的机会。</p><p>今年，OpenAI万众期待的GPT-5正式发布后，结果呢——雷声大雨点小。</p><p>这是否意味着AI的高歌猛进已成过去，还是说OpenAI自己先拉胯了？</p><p><img referrerpolicy="no-referrer" src="https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/e7c8e5a632764cc68e6929470aea108d~tplv-tt-origin-web:gif.jpeg?_iz=58558&amp;from=article.pc_detail&amp;lk3s=953192f4&amp;x-expires=1764030854&amp;x-signature=jS9uUB%2BwVNtZ77N%2FvzzpvmAhiKI%3D" alt="" title="" loading="lazy"/></p><p>如果Gemini 3.0能一炮而红，谷歌就有机会向AI王座发起冲击——这是自生成式AI浪潮兴起以来，它一直梦寐以求的目标。</p><p>对于OpenAI来说，情况就大为不妙。</p><p>因为，它没有谷歌所拥有的完整技术栈。之所以还能保持领先，靠的就是动手早，加上行业里「抱团」的结果。</p><p><img referrerpolicy="no-referrer" src="https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/47b39c8d07ef4f1db1355c9c8f94face~tplv-tt-origin-web:gif.jpeg?_iz=58558&amp;from=article.pc_detail&amp;lk3s=953192f4&amp;x-expires=1764030854&amp;x-signature=73s2Nu93BIAHllbRuqCrqAJs4%2F0%3D" alt="" title="" loading="lazy"/></p><p>当然，谷歌还必须攻克用户的心智定位。</p><p>当前，ChatGPT在AI界，成为了聊天机器人的代名词。这种品牌效应，就好比「Google」本身几乎等同于在线搜索一样根深蒂固。</p><p>在用户规模上，谷歌也急需迎头赶上OpenAI。</p><p>此前财报显示，Gemini应用月活已达6.5亿，而ChatGPT的周活就高达8亿。</p><p><img referrerpolicy="no-referrer" src="https://p26-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/68f78476180b4a8eba725a2b93c30b88~tplv-tt-origin-web:gif.jpeg?_iz=58558&amp;from=article.pc_detail&amp;lk3s=953192f4&amp;x-expires=1764030854&amp;x-signature=z6cr%2BoBuSdL%2FgjTIfVcSw8E7SMU%3D" alt="" title="" loading="lazy"/></p><p>Gemini在年轻群体中迅速圈粉，这固然是利好，但离赶超对手还有距离。</p><p>好在，谷歌多年来在云服务、芯片和研发上的持续投入，如今终于开始开花结果。</p><p>如果 Gemini 3 真能爆红，谷歌唯一要做的就是别翻车。</p><p>压力确实不小……</p><p><img referrerpolicy="no-referrer" src="https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/e4c133c073024fb3b02b91bfe6ae7cb1~tplv-tt-origin-web:gif.jpeg?_iz=58558&amp;from=article.pc_detail&amp;lk3s=953192f4&amp;x-expires=1764030854&amp;x-signature=4GGa%2Fjkb6qwfzmEOY7t%2B3JaMH%2FU%3D" alt="" title="" loading="lazy"/></p><p><strong>巴菲特重仓43亿美金，业界看好</strong></p><p>好在，行业投资大佬们对谷歌无限潜力，非常看好。</p><p>「股神」巴菲特旗下的伯克希尔哈撒韦公司，在今年第三季度，买下了谷歌1700多万股股票。</p><p>与此同时，他还减持了苹果持仓15%，持仓价值降至607亿美元。</p><p><img referrerpolicy="no-referrer" src="https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/bd803af6a9b547d199af407eb2ba2129~tplv-tt-origin-web:gif.jpeg?_iz=58558&amp;from=article.pc_detail&amp;lk3s=953192f4&amp;x-expires=1764030854&amp;x-signature=6QsgEtrKMkY%2B%2FyG9KhRjtcWuRDY%3D" alt="" title="" loading="lazy"/></p><p>一份监管文件显示，截至9月底，Alphabet已成为该集团的第十大股票持仓。</p><p><img referrerpolicy="no-referrer" src="https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/62ab3171f6b04e49a11a67ef711e4ce9~tplv-tt-origin-web:gif.jpeg?_iz=58558&amp;from=article.pc_detail&amp;lk3s=953192f4&amp;x-expires=1764030854&amp;x-signature=w%2FlrFH4zFFmrbADZVfniSTKXIFI%3D" alt="" title="" loading="lazy"/></p><p>这一举动令业界非常意外，这一操作背离了巴菲特标志性的价值投资原则。</p><p>要知道，他素来对高估值科技股敬而远之，即便重仓苹果，也是将其定义为消费品牌，而非科技企业来为其投资背书。</p><p>正如AI大牛所言，Gemini将凭一己之力证明，我们并未身处泡沫之中。</p><p><img referrerpolicy="no-referrer" src="https://aiera.com.cn/wp-content/uploads/2025/11/image-83.gif" alt="" title="" loading="lazy"/></p><p>Gemini 3.0+Nano Banana 2能否接得住全网的希望，下一周拭目以待。</p><p><img referrerpolicy="no-referrer" src="https://aiera.com.cn/wp-content/uploads/2025/11/image-83.gif" alt="" title="" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[图灵奖得主LeCun最后警告Meta！我]]></title>    <link>https://segmentfault.com/a/1190000047406798</link>    <guid>https://segmentfault.com/a/1190000047406798</guid>    <pubDate>2025-11-18 10:09:03</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>编辑：KingHZ</p><p>【新智元导读】图灵奖得主LeCun与Meta分道扬镳！LLM邪路一条，「世界模型才是」未来。</p><p>Meta风向已变，Yann LeCun承认马上离职！</p><p>据多家权威媒体报道，Meta首席AI科学家、负责「基础AI研究」（FAIR）的Yann LeCun，预计将很快离职。</p><p>这位65岁的AI界元老，在Meta这家全球最大的科技公司之一担任核心大脑，可以说拥有无限的资源。</p><p>Meta可谓挥金如土。它用天价薪酬疯狂从对手那里挖角顶尖AI专家。</p><p>在7月，扎克伯格甚至宣称「超级智能已近在眼前」。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406800" alt="" title=""/></p><p>那么，LeCun为何要离开Meta呢？只是因为Meta的人事动荡吗？背后有何隐情？</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406801" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406802" alt="" title="" loading="lazy"/></p><p><strong>小扎转向，LeCun失势？</strong></p><p>今年夏天，年仅28岁的Alexandr Wang成为Meta的首席AI官，让这位初出茅庐的大语言模型狂热者成了LeCun的上司。</p><p>此外，Meta今年还任命了另一位相对年轻的首席科学家赵晟佳（Shengjia Zhao），职位也在LeCun之上。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406803" alt="" title="" loading="lazy"/></p><p>在官方公告中，Meta盛赞了赵晟佳在scaling方面带来的「突破」。而LeCun恰恰对scaling失去了信心。</p><p>他还告诫博士生：「不要做LLM」。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406804" alt="" title="" loading="lazy"/></p><p>如果你好奇为什么LeCun和Zhao都是首席科学家，那是因为Meta的AI部门组织架构相当奇特，分成了多个独立的团队。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406805" alt="" title="" loading="lazy"/></p><p>媒体不断有消息放出，Meta要对其AI组织结构动刀。</p><p>上个月，Meta超级AI实验室裁掉了数百人，包括10年老将田渊栋。据称，这是为了理顺这种混乱的局面。</p><p>这已经是Meta在半年之内第四次调整AI业务了。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406806" alt="" title="" loading="lazy"/></p><p>而那支曾由LeCun领导、风头一时无两的FAIR，如今早已风光不再。据现任与前员工透露，这个部门经历了裁员、预算缩水，内部影响力也明显下降。</p><p>曾几何时，FAIR是Meta内部思想最活跃的「象牙塔」，研究人员可以探讨各种AI未来路径，甚至可以做些「未必能成」的实验，完全不用担心产品化问题。</p><p>而现在，Meta新组建的AI研究部门招来一大批高薪新兵，由Wang主导，目标明确：要快、要落地、要产品化。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406807" alt="" title="" loading="lazy"/></p><p><strong>在AI上，他领先了40年</strong></p><p>LeCun一向走在时代前沿——</p><p>早在「机器学习」还不被主流认可时，他就开始研究这个方向。</p><p>他曾在多伦多的Geoffrey Hinton实验室工作，那时Hinton还没成为AI传奇人物。</p><p>之后，他的职业生涯大多时间都在新泽西州的贝尔实验室度过，这家机构因诞生众多创新发明而闻名。</p><p>1947年，贝尔实验室发明晶体管</p><p>「最让我兴奋的事情，就是和比我聪明的人共事，因为这会放大你的能力。」LeCun在2023年杂志采访时说道。</p><p>在贝尔实验室，LeCun曾参与开发手写识别技术，这项技术后来被广泛应用于银行自动读取支票。他还参与了一个项目，致力于将纸质文档数字化并通过互联网分发。</p><p>LeCun曾表示，自己从小就对物理感兴趣，在贝尔实验室期间也主要和物理学家合作，看了不少物理教材。</p><p>我学到了很多表面上与AI或计算机科学无关的东西（我本科是电气工程，计算机方面的正规训练其实很少）。</p><p>2003年，LeCun开始在纽约大学教授计算机科学，后来成为该校数据科学中心的创始主任。</p><p>2013年，扎克伯格亲自邀请他加入Facebook（当时还未更名为Meta），组建全新的AI实验室。</p><p>他领导这个团队四年，2018年卸任，转为公司首席AI科学家，以「个人研究员」身份继续探索技术前沿。</p><p>2018年，他与Geoffrey Hinton和Yoshua Bengio共同获得图灵奖——计算机界的最高荣誉，以表彰三人在神经网络方面的奠基性工作。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406808" alt="" title="" loading="lazy"/></p><p>自那之后，LeCun就逐渐转为「象征性人物」角色。他没有参与Meta首个开源大语言模型Llama的研发，也早就不再参与这类项目的日常工作。</p><p>据与他共事的人透露，LeCun现在主要在做自己的研究项目，也经常出席各种技术会议，发表对AI技术的看法。</p><p>面对媒体的报道，Yann LeCun只是指出了报道中的「小错误」，并没有否认即将离职的消息。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406809" alt="" title="" loading="lazy"/></p><p>他知道自己在包括Meta在内的整个硅谷技术圈内，备受冷落。上个月在MIT的一次研讨会上，65岁的LeCun直言：</p><p>这些年，我在硅谷、包括Meta的很多角落都不太受欢迎，因为我一直在说，3到5年内，世界模型将成为主流AI架构，没人再会愿意用现在这种LLM。</p><p>但他坚信自己对AI未来的判断。他的老朋友Léon Bottou曾告诉媒体，LeCun「倔强得可爱」——他会听别人意见，但更有自己坚守的信念。</p><p>现在，LeCun在Meta好像「忍无可忍」，终于要离职了。</p><p>实际上，他早已多次暗示答案。</p><p>在通往通用人工智能的道路上，LeCun近来以其对大语言模型的尖锐批评而闻名。</p><p>他认为，无论科技巨头如何扩大其规模，我们目前所理解的大语言模型都已是「强弩之末」，是一条「岔路、干扰，一条死胡同」。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406810" alt="" title="" loading="lazy"/></p><p>他投身AI研究已有40年，对AI的判断屡屡应验。如今，他认为大多数人都错了。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406811" alt="" title="" loading="lazy"/></p><p>他为现代AI奠定了诸多基础。而现在他坚信，领域内的大多数人都被大语言模型的「海妖之歌」引入了歧途。</p><p>这为他的离职提供了更多可能的解释。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406812" alt="" title="" loading="lazy"/></p><p><strong>LeCun离开Meta，或为了世界模型</strong></p><p>此前报道，他正在与业内同行商议创办公司、寻找投资，组建专注世界模型的团队。</p><p>所谓「<strong>世界模型</strong>」，类似小动物或婴儿那样，<strong>通过视觉等感知数据主动学习世界规律；而LLM只是依赖海量文本做预测的模型。</strong></p><p>LeCun本人也从不避讳解释为何他认为「世界模型」才是AI的答案。</p><p>Meta的Llama、OpenAI的GPT、谷歌的Bard这些模型，都是靠海量数据训练出来的。LeCun估算，如果让人去读完它们训练所需的所有文本，大概得花10万年。</p><p><strong>但人类学习的主要方式，并不是读文本。</strong></p><p>我们从与世界的互动中，获取的信息要多得多。LeCun估计，一个普通的四岁小孩接触过的数据量，是目前最大的LLM的50倍。</p><p>大部分人类知识，其实不是语言。</p><p>所以这些系统永远不可能达到人类水平的智能——除非你彻底改掉它们的架构。</p><p>而他自己，早就准备好了替代方案。他称之为「目标驱动的AI」（objective-driven AI）。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406813" alt="" title="" loading="lazy"/></p><p>目标驱动的AI系统的构建宗旨，是完成人类设定的特定目标。</p><p>与仅靠纯文本数据驱动不同，它们通过传感器和视频数据训练来认知物理世界。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406814" alt="" title="" loading="lazy"/></p><p>由此构建出的「世界模型」能呈现行动带来的影响，所有潜在变化都会实时更新至系统记忆。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406815" alt="" title="" loading="lazy"/></p><p><strong>他为何对世界模型如此沉迷？</strong></p><p>在年初的「巴黎AI峰会」上，Yann LeCun明确指出，他是可穿戴设备的坚定信徒。</p><p>他认为，未来，我们需要与可穿戴设备互动，就像与人交流一样，而大语言模型根本不像人类那样理解世界。</p><p>对于大语言模型，我们甚至无法复制猫或老鼠的智能，更不用说狗了。</p><p>这些动物能完成惊人的壮举，它们理解物理世界。任何一只家猫都能规划出极其复杂的行动，<strong>因为它们拥有关于世界的因果模型</strong>。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406816" alt="" title="" loading="lazy"/></p><p>为了说明这一点，LeCun设计了一个<strong>思想实验</strong>：「想象一个立方体悬浮在你面前的空中。好，现在让这个立方体绕着垂直轴旋转90度。它会是什么样子？」</p><p>他认为任何人类都能轻松完成，而大语言模型却无能为力：</p><p>「对人来说，在脑海中构建一个旋转立方体的心理模型，非常容易。」</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406817" alt="" title="" loading="lazy"/></p><p>当然，大语言模型可以毫不费力地写一首关于悬浮旋转立方体的打油诗，但它无<strong>法真正帮助你与这个立方体互动。</strong></p><p><strong>LeCun断言，这是因为文本数据与处理非文本世界所获得的数据之间存在本质差异。</strong></p><p>他指出，尽管大语言模型训练所用的文本量需要一个人花45万年才能读完，但一个四岁的孩子在醒着的16000小时里，通过眼睛看、用手触摸，已经处理了高达1.4×10^14字节的关于世界的感觉数据——</p><p>他认为这比大语言模型处理的数据还要多。</p><p>顺便一提，这些只是LeCun在演讲中给出的估算，他在其他场合也给过不同的数字。但这些数字指向的核心观点是：<strong>大语言模型存在着局限，而LeCun相信世界模型能够克服这些局限。</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406818" alt="" title="" loading="lazy"/></p><p><strong>他又将如何构建世界模型？</strong></p><p>在Meta时，LeCun其实已经开始研究世界模型——他还拍了一个介绍视频，开头就让你想象一个旋转的立方体。</p><p>在AI行动峰会的演讲中，他理想中的模型包含一个对「当前世界状态的估计」，以某种抽象形式呈现与当前情境相关的一切。它不再是按顺序预测token，而是「预测在你采取一系列行动后，世界将达到的最终状态」。</p><p>他表示，世界模型将使未来的计算机科学家能够构建出「可以规划行动——可能是分层级的——以实现某个目标的系统，以及能够进行推理的系统。」</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406819" alt="" title="" loading="lazy"/></p><p>LeCun还坚称，这类系统将拥有更强大的安全特性，因为控制它们的方式是内置的，而不是像现在这样，面对一个神秘莫测、只会输出文本的黑箱，只能通过微调来加以修正。</p><p>LeCun所说的经典AI——例如搜索引擎中使用的软件——所有问题都可以归结为优化问题。</p><p>他提出，他的世界模型将审视当前的世界状态，并通过寻找高效的解决方案，来寻求与某个不同状态的兼容性。</p><p>LeCun在演讲中解释道：「你需要一个能量函数来衡量不兼容性，给定一个x，找到一个对于该x能量较低的y」。</p><p>如果说，我们从LeCun的公开言论中拼凑出的「真相」很粗糙、有些模糊，甚至完全错误，那也完全正常。</p><p>LeCun似乎正在构想一个「登月计划」——</p><p>他希望推动AI领域迎来又一次类似ChatGPT那样的、诞生惊人能力的爆发式发展。</p><p>但这可能需要耗费数年——甚至永远无法实现——更不用说数十亿美元的投资了，才可能看到任何真正了不起的成果。</p>]]></description></item><item>    <title><![CDATA[安全基石：TLS握手背后的故事 细心的红]]></title>    <link>https://segmentfault.com/a/1190000047406684</link>    <guid>https://segmentfault.com/a/1190000047406684</guid>    <pubDate>2025-11-18 10:08:10</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><strong>安全基石：TLS握手——一次无形的安全护航</strong></p><p>当您在浏览器中输入一个HTTPS网址，并看到那把绿色小锁时，一场精妙复杂的安全协奏曲已在毫秒间完成。这场协奏曲，就是 TLS握手。它是所有安全通信的基石，在不为人知的背后，为你我建立起一条坚固的加密隧道。</p><p><strong>一、核心目标：握手是为了解决什么问题？</strong></p><p>在不可信任的互联网上建立安全连接，需要解决三个核心问题，这正是TLS握手的目的所在：</p><p><strong>身份验证：</strong> “我连接的是否是真正的目标网站？” —— 验证服务器身份。</p><p><strong>协商密钥：</strong> “我们之后的对话如何加密？” —— 商定后续数据传输使用的对称加密密钥。</p><p><strong>数据完整性：</strong> “我们的通信内容是否被篡改了？” —— 确保数据在传输过程中未被修改。</p><p><strong>二、幕后之旅：一次经典的TLS握手流程</strong></p><p>为了更直观地理解这一复杂过程，让我们通过下面的时序图，一步步拆解客户端与服务器之间的对话：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406686" alt="3d.png" title="3d.png"/><br/>现在，我们来详细解读图中的每一个关键步骤：</p><p><strong>第一步：打招呼与能力协商</strong></p><p>客户端（浏览器） 向服务器发送一个 ClientHello 消息，内容包括：</p><p>支持的TLS版本号。</p><p>支持的密码套件列表（包含加密算法、哈希算法等）。</p><p>生成的一个客户端随机数。</p><p><strong>第二步：服务器确认与“出示身份证”</strong></p><p>服务器 回复一个 ServerHello 消息，内容包括：</p><p>从客户端提供的列表中，双方共同支持的TLS版本和密码套件。</p><p>生成的一个服务器随机数。</p><p>紧接着，服务器发送其 Certificate 消息（SSL证书），向客户端证明自己的身份。</p><p>最后发送 ServerHelloDone，表示问候阶段结束。</p><p><strong>第三步：客户端验证与密钥生成</strong></p><p>客户端 验证服务器发来的证书：</p><p>是否由可信的证书颁发机构（CA）签发？</p><p>是否在有效期内？</p><p>域名是否匹配？</p><p>验证通过后，客户端生成第三个关键参数：预备主密钥。</p><p>客户端用服务器证书中的公钥加密这个预备主密钥，并将其发送给服务器。</p><p><strong>第四步：达成共识，生成最终钥匙</strong></p><p>服务器 用自己的私钥解密，获取预备主密钥。</p><p>此时，客户端和服务器都拥有了三个相同的参数：客户端随机数、服务器随机数 和 预备主密钥。双方使用相同的算法，独立生成最终的 会话密钥。</p><p>双方交换一条信息，通知对方：“之后的所有通信，都将使用这把刚生成的会话密钥进行加密。”</p><p><strong>第五步：安全通信正式开始</strong></p><p>至此，握手完成。后续所有的HTTP请求和响应（如表单数据、Cookie、网页内容）都使用这把高效的对称会话密钥进行加密和解密，全程保驾护航。</p><p><strong>三、为何如此设计？非对称与对称加密的精妙结合</strong></p><p>您可能会注意到，握手过程中同时使用了非对称加密（传输预备主密钥）和对称加密（传输应用数据）。这是性能与安全的完美平衡：</p><p><strong>非对称加密（RSA等）</strong>：安全性高，但计算复杂、速度慢。用于安全地交换那个小小的预备主密钥，确保密钥本身不被窃听。</p><p><strong>对称加密（AES等）</strong>：计算速度快、效率高。用于加密大量的实际传输数据。</p><p><strong>这种设计好比：</strong>用一把坚固但笨重的锁（非对称加密），安全地传递一把轻便的钥匙（会话密钥），然后用这把钥匙（对称加密）来快速锁上和解锁后续所有的箱子（数据）。</p><p>总结：</p><p>TLS握手是一场无声而迅捷的安全仪式。它通过在连接建立之初进行严格的身份认证和密钥协商，为后续的数据传输搭建起一条<strong>身份可信、加密可靠、完整性可保</strong>的安全通道。每一次您看到地址栏那把绿色的小锁，背后都是一次成功的TLS握手在默默守护着您的隐私与安全。</p>]]></description></item><item>    <title><![CDATA[网站一定要安装SSL证书吗？ 傻傻的开心]]></title>    <link>https://segmentfault.com/a/1190000047406691</link>    <guid>https://segmentfault.com/a/1190000047406691</guid>    <pubDate>2025-11-18 10:07:35</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><strong>一、SSL 证书的核心价值：为什么强烈建议必装？</strong></p><p>SSL 证书的核心作用是<strong>加密网站数据传输</strong>（如密码、支付信息、表单数据）+ <strong>验证网站身份</strong>，从根源避免数据被窃取、篡改或伪造。其核心价值集中在 3 个关键场景：</p><ol><li><strong>守护用户隐私安全</strong>：未装 SSL 的 HTTP 网站，数据传输呈 “明文状态”，黑客可轻松拦截用户登录密码、手机号等信息；尤其涉及支付、注册的网站，会直接威胁用户权益，埋下安全隐患。</li></ol><ol start="2"><li><strong>快速提升用户信任度</strong>：安装后，浏览器地址栏会显示<strong>小锁图标</strong>，Chrome、Edge 等还会标注 “安全” 字样；反之，未安装的网站会被直接提示 “不安全”，据统计超 80% 用户会果断关闭，严重影响转化效果。</li></ol><ol><li><strong>契合搜索引擎规则</strong>：百度、Google 等明确将 “HTTPS” 列为排名加分项，同等条件下 HTTPS 网站排名更靠前；且百度已逐步减少对 HTTP 网站的收录支持，未装 SSL 可能导致自然流量流失。</li></ol><p><strong><em><a href="https://link.segmentfault.com/?enc=Xx7QWkQ3HOFQ3L9uSVmhfA%3D%3D.kvZANvF7iZMaB2FgjGbcPNJXFZ4S3cICMJx%2FojZkVLooiJzF%2FVz6jP2ma3gaxuE%2Fc2gH4SWZekdGhYR9IbBmIQ%3D%3D" rel="nofollow" target="_blank">快速申请入口</a>：注册时填写230968获取技术支持</em></strong></p><p><strong>二、这些场景下，SSL 证书是硬性要求，缺一不可！</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406693" alt="" title=""/></p><p>虽无普适性法律强制所有网站安装，但以下场景中，SSL 证书是 “必备项”，否则无法正常运营：</p><ol><li><strong>涉及支付交易的网站</strong>：根据《非银行支付机构网络支付业务管理办法》《PCI DSS 标准》，处理信用卡、微信支付、支付宝等支付业务的网站，必须通过 SSL 加密数据传输，否则属违规操作，可能面临处罚或支付接口停用。</li></ol><ol start="2"><li><strong>收集敏感信息的网站</strong>：含登录密码、身份证号、手机号、医疗记录、财务信息的网站（如电商、社交、医疗、政务平台），依据《网络安全法》《个人信息保护法》，需通过 SSL 实现基础加密，保障用户信息安全。</li></ol><ol start="3"><li><strong>使用特定技术的网站</strong>：启用 HTTP/2（提速）、PWA（渐进式 Web 应用）、小程序内嵌网页等功能，均要求网站基于 HTTPS 运行，否则无法正常启用。</li></ol><ol start="4"><li><strong>行业合规硬性要求</strong>：金融、医疗、教育、电商等行业的监管规范中，明确要求网站具备数据加密能力，SSL 证书是满足合规的核心凭证。</li></ol><p><strong>三、未装 SSL 证书？这些严重后果一定要警惕！</strong></p><p>若网站未安装 SSL，不仅影响用户体验，还可能面临多重风险：</p><ol><li><strong>浏览器强警告</strong>：Chrome、Firefox、Safari 等主流浏览器会直接标注 “不安全”，部分甚至拦截访问，导致流量大幅下滑。</li></ol><ol start="2"><li><strong>数据泄露风险高</strong>：用户提交的登录、支付等信息可能被黑客拦截窃取，引发投诉、法律纠纷，甚至品牌声誉崩塌。</li></ol><ol start="3"><li><strong>搜索引擎降权</strong>：百度、Google 会降低 HTTP 网站排名，部分页面可能不收录，直接影响推广效果。</li><li><strong>合规处罚风险</strong>：涉及敏感信息或支付业务的网站，未装 SSL 可能违反《网络安全法》等法规，面临罚款、责令整改等处罚。</li></ol><p>总结</p><p>SSL 证书虽非 “所有网站法律强制”，但已是<strong>现代网站的基础配置</strong>：从安全防护、用户信任，到搜索引擎排名、行业合规，都离不开它的支撑。尤其是涉及支付、敏感信息收集的网站，SSL 是 “必选项”；即便普通网站，安装 SSL 也是低成本、高回报的选择，能有效规避风险、提升运营效果，建议尽早部署！</p>]]></description></item><item>    <title><![CDATA[域名如何申请 冷冷的炒面 ]]></title>    <link>https://segmentfault.com/a/1190000047406707</link>    <guid>https://segmentfault.com/a/1190000047406707</guid>    <pubDate>2025-11-18 10:06:47</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在当今数字化浪潮中，域名已远不止是网站的访问入口，它更是品牌的象征和在线身份的代表。根据 VeriSign 最新统计数据，全球域名注册总量已突破3.6亿个。无论是建立个人博客、创建企业官网还是搭建电商平台，选择一个合适的域名都是在数字世界立足的关键一步。尽管如此，许多人在首次申请域名时仍感到困惑，不知道该从何入手。本文将为您提供一个全面而详细的域名申请指南，从选择域名到注册域名的每一个步骤，以助您做出明智的决策。</p><p><strong>一、域名是什么？</strong></p><p>域名（Domain Name）由网站名称和域名后缀组成，其作用类似于网站在互联网中的“门牌号”。它帮助用户绕过复杂难记的互联网协议（IP）地址，快速访问目标网站，是互联网基础设施中不可或缺的一环。</p><p><strong>二、域名的基本构成</strong></p><p>1、顶级域名（TLD）：位于域名的最后一段，通常称之为域名后缀，例如“.com”、“.net”、“.org”等。选择恰当的域名后缀不仅便于记忆，也有助于标识网站类型、强化品牌认知，并影响搜索引擎优化（SEO）效果。</p><p>2、二级域名（SLD）：位于顶级域名之前，通常是品牌名称或核心关键词。例如，在“www.racent.com”中，“racent”就是二级域名。这部分应该突出品牌，尽量简洁且易于拼写，从而让用户更易记住你的域名。</p><p>3、子域名：在二级域名之前，常用于划分网站的多个功能板块。从技术上讲，传统的“www”本身也属于子域，这表明网站是万维网的一部分。同时也有额外的子域名，比如用于在线帮助的“help.racent.com”。</p><p><strong>三、选择合适的域名一个好的域名应兼顾品牌表达与用户记忆便利，以下是选择合适域名的几条建议</strong>：</p><p>1、简短易记：一个简短易记的域名能让用户更容易找到你的网站。</p><p>2、包含关键词：如果可能的话，可以将与您的业务相关的关键词融入域名中，这样可以增强SEO效果。</p><p>3、避免使用特殊字符和数字：尽量不使用连字符或数字，这会增加拼写错误的风险，使用户更难记住您的域名。</p><p>4、考虑品牌化：一个能够很好地代表您的品牌的域名，衬托出公司或者是商品的品牌感，可以给用户留下深刻印象。</p><p><strong>四、十大常见域名后缀域名后缀不仅是网址的一部分，它还传递着不同的品牌信号，也影响网站识别与推广效果，以下是十大常见域名后缀</strong>：</p><p>.com- 全球注册量最大，适用性最广<br/>.cn - 中国企业互联网标识<br/>.com.cn - 常用于外资或国际化中国企业<br/>.org - 多用于非营利组织<br/>.net - 全球化商业品牌标签<br/>.club - 适合俱乐部、社群类网站<br/>.top - 专业领域头号域名<br/>.online - 网络在线服务域名<br/>.site - 站点专属域名后缀<br/>.xyz - 全球通用的新顶级域名</p><p><strong>五、域名申请流程选择一个可信赖的域名注册商</strong>，选择注册年限（1-10年不等，长期注册常享折扣）；完善注册信息（包括名称、联系邮箱、证件信息等）；支付并完成。</p><p><strong>六、常见问题解答在申请域名的过程中，会遇到一些常见问题。以下是一些域名申请的常见问题解答</strong></p><p>1、域名注册后可以随时更改吗？<br/>回答：可以，您可随时调整域名DNS解析设置，也可将域名转移至其他注册商。</p><p>2、如何选择顶级域名？<br/>回答：选择顶级域名应需综合考虑目标用户与品牌定位。例如主攻中国市场可选“.cn”，面向国际则“.com”更合适。</p><p>3、域名是否可以永久拥有？<br/>回答：域名采用按年租赁制，您需要定期续费。若未及时续费，域名可能被收回。</p><p>4、是否可以将一个域名分给多个网站？<br/>回答：可以。通过设置子域名来实现同一主域名下的多个站点。</p>]]></description></item><item>    <title><![CDATA[js精准的时间处理成范围时间 兔子先森 ]]></title>    <link>https://segmentfault.com/a/1190000047406728</link>    <guid>https://segmentfault.com/a/1190000047406728</guid>    <pubDate>2025-11-18 10:06:08</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>例如：3小时，处理为 2~3.5小时<br/>遇到范围时间(2~3.5小时)则不处理，仅处理精准时间<br/>并且可以多次处理，适用与流式对话以及普通文本处理</p><pre><code>/**
 * 精准的时间处理成范围时间，规则：下限 = 原数 - 1，上限 = 原数 + 0.5
 * @param text 文本
 * @returns 处理后的文本
 */
export const processHoursText = (text: string) =&gt; {
  // 步骤1：提取所有时间范围并替换为临时标记，避免被处理
  const rangeRegex = /\d+(\.\d+)?~(\d+(\.\d+)?)(个)?小时/g;
  const ranges: any = [];
  let tempText = text.replace(rangeRegex, match =&gt; {
    ranges.push(match);
    return `__RANGE_${ranges.length - 1}__`; // 生成唯一占位符
  });

  // 步骤2：处理剩余的单独时间
  const singleTimeRegex = /(?&lt;!~|\d)(\d+(\.\d+)?)(个)?小时(?!~|\d)/g;
  tempText = tempText.replace(singleTimeRegex, (_, numberStr) =&gt; {
    const number = parseFloat(numberStr);
    const lower = number - 1;
    const upper = number + 0.5;

    // 格式化输出，移除不必要的.0
    const formatNumber = (num: any) =&gt; {
      return num % 1 === 0 ? num.toString() : num.toFixed(1);
    };

    return `${formatNumber(lower)}~${formatNumber(upper)}个小时`;
  });

  // 步骤3：恢复之前提取的时间范围
  ranges.forEach((range: any, index: any) =&gt; {
    tempText = tempText.replace(`__RANGE_${index}__`, range);
  });
  return tempText;
};</code></pre><pre><code>// 测试用例
let text = "测试文本：3个小时，4.5个小时，2.5~4个小时，4~5.5个小时，6";
console.log("处理前：", text);
text = processHoursText(text);
console.log("处理后：", text);
// 预期：测试文本：2~3.5个小时，3.5~5个小时，2.5~4个小时，4~5.5个小时

// 再次处理测试（关键测试）
text = processHoursText(text);
console.log("再次处理后：", text);
// 预期：与上一次结果完全相同，没有变化

// 新增内容测试
text += "个小时，7.8小时，9~10.5个小时，11个小时";
console.log("新增后：", text);
text = processHoursText(text);
console.log("处理新增后：", text);
// 预期包含：5~6.5个小时，6.8~8.3个小时，9~10.5个小时，10~11.5个小时</code></pre><p><img width="723" height="102" referrerpolicy="no-referrer" src="/img/bVdm4OD" alt="" title=""/></p>]]></description></item><item>    <title><![CDATA[大型企业为什么都用OV通配符SSL证书？]]></title>    <link>https://segmentfault.com/a/1190000047406738</link>    <guid>https://segmentfault.com/a/1190000047406738</guid>    <pubDate>2025-11-18 10:05:21</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h4><strong>一、 什么是OV通配符SSL证书？</strong></h4><p>要理解它的优势，我们首先得拆解它的名字：</p><ul><li><strong>SSL证书</strong>：是安装在服务器上的一个“数字身份证”，主要实现两大功能：<strong>加密数据传输</strong>（防止信息被窃取）和<strong>身份验证</strong>（证明“我就是我”）。</li><li><strong>OV（组织验证）</strong> ：指的是证书颁发机构（CA）在签发证书前，会对企业的真实合法性进行严格的线下审查。这包括核查公司的营业执照、电话地址等。通过OV验证后，证书里会包含清晰的企业信息。</li><li><strong>通配符（*）</strong> ：指的是证书可以保护一个主域名及其所有的下一级子域名。例如，一张为 <code>*.yourcompany.com</code> 颁发的证书，可以同时用于 <code>www.yourcompany.com</code>、<code>mail.yourcompany.com</code>、<code>shop.yourcompany.com</code> 等。</li></ul><p>简单来说，<strong>OV通配符SSL证书就是一张经过严格企业身份验证的、可以保护无限个子域名的“高级安全通行证”。</strong></p><p><strong>直接访问JoySSL，注册一个账号记得填写注册码230970获取免费安装服务和内部优惠价。</strong></p><p><img width="549" height="341" referrerpolicy="no-referrer" src="/img/bVdbAkF" alt="" title=""/></p><h4><strong>二、 核心优势：为何大企业情有独钟？</strong></h4><p>大型企业选择它，是基于对安全、成本和管理的综合考量。</p><p><strong>1. 安全与信任双赢：树立权威形象</strong></p><p>这是最关键的一点。与仅验证域名所有权的DV证书相比，OV证书<strong>多了一层企业身份验证</strong>。当用户点击小锁图标查看证书详情时，可以看到经过认证的企业名称。这相当于向客户和合作伙伴宣告：“这是一个真实存在的合法企业，而非皮包公司。” <strong>极大地增强了用户信任度，提升了品牌形象和交易转化率</strong>。</p><p><strong>2. 管理效率与成本效益的完美平衡</strong></p><p>大型企业通常拥有成百上千个子域名，如果为每一个子域名单独购买和部署证书，将是一场管理噩梦。通配符功能彻底解决了这个问题。</p><ul><li><strong>一证多用</strong>：只需申请、安装和管理一张证书，即可覆盖所有同级子域名。</li><li><strong>简化运维</strong>：当证书需要续期或更换时，只需操作一次，<strong>大幅降低了IT团队的运维复杂度和时间成本</strong>。</li><li><strong>经济高效</strong>：虽然单张OV通配符证书的价格较高，但相比于为每个子域名单独购买证书，总成本要低得多，实现了规模效应。</li></ul><p><strong>3. 灵活性与可扩展性强</strong></p><p>企业在发展过程中，会不断推出新的在线服务，随之会产生新的子域名。使用通配符证书，<strong>未来新增的任何同级子域名都能立即受到保护，无需再次购买或部署证书</strong>，为企业业务的快速扩展提供了极大的灵活性。</p><h4><strong>总结</strong></h4><p>对于大型企业而言，网络安全无小事。OV通配符SSL证书完美地满足了它们在<strong>建立可信身份、实现高效管理、控制总体成本</strong>方面的核心需求。它不仅仅是一个技术工具，更是企业安全战略中的重要一环，是保障业务稳定运行、赢得用户信赖的明智投资。</p>]]></description></item><item>    <title><![CDATA[性能狂飙！国密SSL证书为何比国际算法快]]></title>    <link>https://segmentfault.com/a/1190000047406749</link>    <guid>https://segmentfault.com/a/1190000047406749</guid>    <pubDate>2025-11-18 10:04:26</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h3><strong>一、算法轻量化与高效能设计</strong></h3><ol><li><p><strong>更短密钥实现同等安全强度</strong></p><ul><li>SM2算法采用256位密钥即可达到RSA-3072位的安全强度，且运算效率提升40%。较短的密钥显著降低了数据传输量和计算负载，缩短SSL握手时间。</li></ul></li><li><p><strong>算法架构的优化</strong></p><ul><li>SM2基于椭圆曲线密码学（ECC）改进，单位安全强度远高于传统RSA。例如，224位SM2的安全性等同于2048位RSA，而实际部署中普遍采用256位SM2，进一步优化了计算效率。</li></ul></li></ol><h3><strong>二、本土化网络环境深度适配</strong></h3><ol><li><p><strong>本地化OCSP验签服务</strong></p><ul><li>国密证书的在线证书状态协议（OCSP）响应节点部署于境内，避免了国际链路延迟。相比之下，国际证书的OCSP请求需跨境路由，导致额外耗时。</li></ul></li><li><p><strong>国内服务器与设备的兼容性优化</strong></p><ul><li>国产服务器（如华为鲲鹏芯片）、操作系统（麒麟OS）及中间件（Nginx国密版）均针对SM算法进行指令集级优化，提升并行处理能力。</li></ul></li></ol><h3><strong>三、软硬件协同加速机制</strong></h3><ol><li><p><strong>专用加密硬件支持</strong></p><ul><li>国密PCIe加密卡、SSL加速器等硬件设备原生集成SM2/SM4算法芯片，将加解密过程从软件计算转移到硬件层，降低CPU占用率。</li></ul></li><li><p><strong>浏览器与终端预置优化</strong></p><ul><li>360安全浏览器、红莲花浏览器等国产浏览器内置国密协议栈，省去算法协商环节；Windows 11/10系统自2023年起预装国密根证书，减少二次验证开销。</li></ul></li></ol><h3><strong>四、双证书模式的动态性能调配</strong></h3><p>对于跨国业务场景，国密证书常采用“SM2+RSA”双证书部署：</p><ul><li><strong>国内用户</strong>：优先使用SM2算法，享受高速加密通道；</li><li><strong>海外用户</strong>：自动切换至RSA算法，保障全球兼容性。  <br/>这种智能调度机制既满足合规要求，又避免因强制使用国密算法导致的海外访问性能下降。</li></ul>]]></description></item><item>    <title><![CDATA[HTTPS：从前是奢侈品，现在是必需品，]]></title>    <link>https://segmentfault.com/a/1190000047406778</link>    <guid>https://segmentfault.com/a/1190000047406778</guid>    <pubDate>2025-11-18 10:03:49</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在互联网发展初期，HTTP协议以明文传输的特性支撑起全球信息交换的基础架构。然而随着网络安全威胁的升级，数据泄露、中间人攻击等事件频发，HTTPS协议逐渐从金融、政务等高安全场景向全行业渗透。如今，全球超过80%的网站已部署SSL证书，搜索引擎将HTTPS列为排名权重指标，浏览器对非加密站点标记"不安全"警告。这场安全革命中，JoySSL凭借自主可控的技术底座与普惠策略，正在重塑数字证书的市场格局。</p><p><a href="https://link.segmentfault.com/?enc=4YqGBEGpetXBE%2BWLEP5tyg%3D%3D.kfgdf5u8BBgM1rusZ6MTJs4NgZI0dV03z20aXZ%2FeVeanI%2BTUgH14wo1aDv1BWQprgtKXebo%2FT04omoAR%2BqvmnQ%3D%3D" rel="nofollow" target="_blank">点击打开JoySSL官网填写注册码230960获取一对一技术支持</a></p><h2>一、HTTPS：从技术选配到生存刚需</h2><h3>1.1 安全威胁的倒逼进化</h3><p>2018年某运营商DNS劫持事件中，超过300万用户被强制跳转至恶意站点；2024年某电商平台因未启用HTTPS导致200万用户支付信息泄露。这些案例揭示HTTP协议的致命缺陷：明文传输使数据在传输链路的每个节点都暴露在风险中。HTTPS通过SSL/TLS协议构建的加密通道，采用非对称加密传输会话密钥、对称加密传输数据、数字证书验证身份的三层防护机制，将数据泄露风险降低97%。</p><h3>1.2 生态系统的强制升级</h3><p>Google Chrome自2017年起对HTTP站点标记"不安全"，Firefox浏览器在2020年完全阻断混合内容加载。更关键的是，HTTPS已成为Web3.0的基础设施：PWA应用、Service Worker、HTTP/2等新技术均要求加密传输。某电商平台的AB测试显示，启用HTTPS后用户转化率提升12%，跳出率下降8%，印证了安全标识对用户信任度的直接影响。</p><h3>1.3 法规合规的硬性要求</h3><p>欧盟GDPR、中国《网络安全法》等法规明确要求个人信息传输必须采取加密措施。某金融机构因未使用HTTPS传输用户身份证号被处以巨额罚款，该案例成为行业合规转型的标志性事件。JoySSL提供的OV/EV证书通过严格组织验证，可满足等保2.0三级要求，成为政企客户的首选方案。</p><h2>二、JoySSL：打破国际垄断的自主方案</h2><h3>2.1 自主根证书的技术突破</h3><p>传统SSL证书市场长期被DigiCert、Sectigo等国际品牌垄断，其根证书预置在浏览器根证书库中形成技术壁垒。JoySSL通过与CFCA等国家级CA机构合作，成功将自主根证书植入Firefox、360等国产浏览器，并兼容统信UOS、麒麟等信创操作系统。其SM2/SM3国密算法证书已应用于政务云、金融核心系统等关键领域。</p><h3>2.2 全球信任的兼容性保障</h3><p>JoySSL采用双算法证书体系，国际算法证书兼容Chrome、Safari等全球主流浏览器，国密算法证书满足《密码法》监管要求。某跨国企业测试显示，JoySSL证书在AWS、Azure、阿里云等云平台上的部署成功率达99.9%，签发速度较传统CA提升60%，通配符证书可同时保护500个子域名。</p><h3>2.3 免费策略的普惠实践</h3><p>区别于国际品牌每年数千元的定价策略，JoySSL推出"基础安全普惠计划"：个人用户可免费获取DV单域名证书，教育机构可申请免费OV证书，政务单位享有专属优惠通道。某高校采用JoySSL免费证书后，年度安全运维成本降低8万元，证书签发时间从3天缩短至10分钟。</p><h2>三、免费证书的部署实战：三步开启安全防护</h2><h3>3.1 注册与资质审核</h3><p>访问JoySSL官网注册账号时输入特定注册码“230960”，即可解锁免费证书申请权限。企业用户需提交营业执照、域名授权书等材料进行OV级验证，教育机构通过教育网域名后缀可快速通过审核。某中小企业主反馈："整个注册流程比申请微信支付商户还简单。"</p><h3>3.2 证书类型选择矩阵</h3><table><thead><tr><th>证书类型</th><th>适用场景</th><th>验证方式</th><th>签发时间</th><th>价格（年）</th></tr></thead><tbody><tr><td>DV单域名</td><td>个人博客</td><td>域名验证</td><td>10分钟</td><td>免费</td></tr><tr><td>OV单域名</td><td>企业官网</td><td>组织验证</td><td>1-3工作日</td><td>1580元</td></tr><tr><td>EV通配符</td><td>电商平台</td><td>扩展验证</td><td>3-5工作日</td><td>8800元</td></tr><tr><td>IP证书</td><td>服务器管理</td><td>IP验证</td><td>1工作日</td><td>880元</td></tr></tbody></table><h3>3.3 自动化部署方案</h3><p>JoySSL提供Nginx、Apache、IIS等主流服务器的自动化配置脚本，支持ACME协议实现证书自动续期。某云服务商技术团队测试显示，使用JoySSL API接口批量部署证书的效率较手动操作提升90%，证书过期导致的业务中断事件归零。</p><h2>四、未来展望：安全即服务的范式革命</h2><p>随着零信任架构的普及，HTTPS正在从边界防护向持续验证演进。JoySSL推出的mTLS双向认证方案，可实现设备-用户-应用的全程加密通信，在工业互联网场景中已成功阻断3000余次中间人攻击。其量子安全证书研发项目更瞄准后量子计算时代，提前布局抗量子破解的加密算法。</p><p>在数字经济成为国家战略的当下，JoySSL通过"自主根+免费策略+全场景支持"的组合拳，正在改写SSL证书的市场规则。当安全防护不再受制于成本与技术门槛，每个网站都能轻松获得基础安全保障，这或许正是数字中国建设最坚实的基石。正如某安全专家所言："JoySSL的出现，让HTTPS从少数人的奢侈品变成全民必需品，这场静悄悄的革命正在重塑互联网的安全生态。"</p>]]></description></item><item>    <title><![CDATA[云原生游戏网关架构：EKS + APIS]]></title>    <link>https://segmentfault.com/a/1190000047406794</link>    <guid>https://segmentfault.com/a/1190000047406794</guid>    <pubDate>2025-11-18 10:02:49</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>前言</h2><p>在现代游戏运营环境中，随着游戏服务器规模的不断扩大，传统的服务器代理方案面临着诸多挑战。本文将介绍如何使用 API Six 这一高性能网关来解决大规模游戏服务器代理的问题，特别是针对需要使用多个 Network Load Balancer (NLB) 的场景，提供一个更加优雅和高效的解决方案。<br/>在游戏服务架构中，我们经常遇到以下几个关键挑战：</p><p>1、 服务器规模问题</p><ul><li>随着游戏的成功运营，服务器数量可能从最初的几台扩展到成百上千台</li><li>传统的使用多个 NLB 进行代理的方案在管理和维护上变得越来越复杂</li><li>成本问题：每增加一个 NLB 都会带来额外的费用支出</li></ul><p>2、 安全性考虑</p><ul><li>游戏服务器需要防护各种网络攻击</li><li>传统的 TCP 协议缺乏足够的安全保护机制</li><li>需要在不影响性能的前提下提供安全保障</li></ul><p>3、运维复杂性</p><ul><li>多个 NLB 的配置管理较为繁琐</li><li>服务器扩缩容时需要频繁调整负载均衡配置</li><li>监控和故障排查的难度随着规模增加而增加</li></ul><p>面对这些挑战，我们需要一个更现代化的解决方案。API Six 作为一个高性能、可扩展的网关，结合 TLS 加密，能够很好地解决这些问题。在接下来的内容中，我们将详细介绍如何使用 API Six 构建一个高效、安全、易于管理的游戏服务网关系统。</p><blockquote>📢限时插播：在本次实验中，你可以在基于 Graviton 的 EC2 实例上轻松启动 Milvus 向量数据库，加速您的生成式 AI 应用。<br/>⏩快快点击进入《<a href="https://link.segmentfault.com/?enc=X2i6Wzl2cyWL5QW%2F3LJs%2BQ%3D%3D.Lp%2Br6nQNz04OCG9%2FCM9aBdqGVtw7AXyzE7B3El4uUmug9ZSYTlpGS%2F3r149kJGjoZuGgcjOYEj9Ng%2BDLOU0RXf%2FcGVbUb6CoT3%2FMFOga%2FKL9fnZkrtAIMEPlmWppiW1vsRlFg3oFlOuyX2tijNJ%2BkxFaknJI4hNYgCwG9ACU9I51Zk6CJOYVUSfcdRfEK%2Bwr45%2BvWN92Djvxin65JvdGDmV7R6mUBpUlB28tItL%2B1fU%3D" rel="nofollow" target="_blank">创新基石 —— 基于 Graviton 构建差异化生成式AI向量数据库</a>》实验<br/>📱 即刻在云上探索实验室，开启构建开发者探索之旅吧！</blockquote><h2>架构介绍</h2><h3>1. 架构整体说明</h3><p>APIsix核心组件运行于 Amazon EKS（Elastic Kubernetes Service）集群内部。整个系统主要分为两大访问入口：运维（Ops）和玩家（Players），分别通过独立的 ELB（Elastic Load Balancer）接入.(在此建议咱们在部署环境前可以先手动创建ELB, 在EKS中通过TargetGroupBinding的方式来进行绑定服务,这样可以保证后续服务变更时前端接入ELB为同一个.)</p><h3>2. 流量入口</h3><ul><li>Ops（运维）入口<br/>运维人员通过 ELB 访问 EKS 集群中的 Admin API，实现对平台的管理和监控。</li><li>Players（玩家）入口<br/>玩家流量同样通过独立的 ELB 进入 EKS 集群，主要访问 API Gateway，进而路由到具体的游戏服务（Game Server）或平台服务（Platform Service）。</li></ul><h3>3. EKS 集群内部结构</h3><ul><li>Admin API 层<br/>提供管理接口，供运维人员操作和管理整个系统。</li><li>etcd 层<br/>作为分布式键值存储，负责服务发现、配置管理等核心功能。Admin API 会将变更写入 etcd，API Gateway 通过 watch 机制实时感知服务变化。</li><li>API Gateway 层<br/>这一层是玩家访问的主要入口，API Gateway 负责根据 etcd 的服务发现信息，将玩家请求路由到后端的具体服务（如 Platform Service 或 Game Server）。</li><li>业务服务层<br/>包含平台服务（Platform Service）和多个游戏服（Game Server1、Game Server2 等），这些服务是最终处理玩家请求的核心业务组件。</li></ul><h2>方案部署</h2><p>下面我们将逐步来验证整个方案, 方案中我们将采用模拟TCP协议的游戏服务,通过ELB来实现不同游戏服的路由功能.首先我们需要创建一个实验EKS集群, 参考 <a href="https://link.segmentfault.com/?enc=HHT70xLttD6EG3FYv520VA%3D%3D.q4Ilea0NlDriRZNp%2FFcweMWNzM0QjNrgQ8wpuyXxxD%2FrcSF%2Ffdoscw5BQwcd%2FgcwejptWfJjvEGsfYbzfWGh%2BQf24KHF0%2Bkc6bARwfB188A%3D" rel="nofollow" target="_blank">EKS文档</a> 创建EKS.</p><h3>创建好EKS后, 添加用户权限</h3><p>然后创建Access Entry</p><h3>使用Helm来安装部署APISix</h3><p>本文采用的部署目标服务器为亚马逊云科技Graviton机型,可以帮助我们发挥APISix的最大性能. 参考步骤如下:</p><p>1、添加相关helm库</p><pre><code>helm repo add apisix https://charts.apiseven.com
helm repo update</code></pre><p>2、整理apisix-values.yaml</p><pre><code># Tolerations for Graviton nodes (if needed)
tolerations:
  - key: "kubernetes.io/arch"
    operator: "Equal"
    value: "arm64"
    effect: "NoSchedule"

# Affinity to prefer Graviton nodes
affinity:
  nodeAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
    - weight: 100
      preference:
        matchExpressions:
        - key: kubernetes.io/arch
          operator: In
### values:
          - arm64</code></pre><p>3、执行命令更新服务</p><pre><code>helm install apisix apisix/apisix --create-namespace --namespace ingress-apisix \
--values apisix-values.yaml</code></pre><p>4、如果此处部署有问题,一定要关注一下当前的storageclass是否存在.</p><pre><code>etcd:
  persistence:
    storageClass: efs-sc # 请格外注意此处,否则可能方案部署失败.</code></pre><p>另推荐一个小技巧,如果部署出现问题,可以使用Amazon Q CLI来做诊断,整个过程完全自动化,下面是我的步骤截图.</p><h3>部署 游戏服务</h3><p>模拟游戏服代码</p><pre><code> # Bind to all interfaces
    server.bind(('0.0.0.0', port))
    server.listen(5)
    
    print(f"[*] {server_name} listening on 0.0.0.0:{port}")
    
    try:
        while True:
            client, addr = server.accept()
            client_handler = threading.Thread(target=handle_client, args=(client, addr))
            client_handler.daemon = True
            client_handler.start()
    except KeyboardInterrupt:
        print(f"[{server_name}] Shutting down server")
        server.close()

if __name__ == "__main__":
    start_server(9000)</code></pre><p>模拟EKS中的服务部署代码: test-server-1.yaml</p><pre><code>apiVersion: apps/v1
kind: Deployment
metadata:
  name: test-server-1
  namespace: game
  labels:
    app: test-server-1
spec:
  replicas: 1
  selector:
    matchLabels:
      app: test-server-1
  template:
    metadata:
      labels:
        app: test-server-1
    spec:
      containers:
      - name: tcp-server
        image: python:3.9-slim
        command: ["python"]
        args: ["-u", "/app/tcp-echo-server.py", "test-server-1"]
        ports:
        - containerPort: 9000
        volumeMounts:
        - name: script-volume
          mountPath: /app
      volumes:
      - name: script-volume
        configMap:
          name: tcp-echo-server
          defaultMode: 0777
---
apiVersion: v1
kind: Service
metadata:
  name: gs-1
  namespace: game
  labels:
    app: test-server-1
spec:
  selector:
    app: test-server-1
  ports:
  - port: 9000
    targetPort: 9000
    protocol: TCP
  type: ClusterIP 
test-server-2.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: test-server-2
  namespace: game
  labels:
    app: test-server-2
spec:
  replicas: 1
  selector:
    matchLabels:
      app: test-server-2
  template:
    metadata:
      labels:
        app: test-server-2
    spec:
      containers:
      - name: tcp-server
        image: python:3.9-slim
        command: ["python"]
        args: ["-u", "/app/tcp-echo-server.py", "test-server-2"]
        ports:
        - containerPort: 9000
        volumeMounts:
        - name: script-volume
          mountPath: /app
      volumes:
      - name: script-volume
        configMap:
          name: tcp-echo-server
          defaultMode: 0777
---
apiVersion: v1
kind: Service
metadata:
  name: gs-2
  namespace: game
  labels:
    app: test-server-2
spec:
  selector:
    app: test-server-2
  ports:
  - port: 9000
    targetPort: 9000
    protocol: TCP
  type: ClusterIP</code></pre><p>部署服务</p><pre><code>kubectl create namespace game
kubectl create configmap tcp-echo-server --from-file=tcp-echo-server.py --namespace game
kubectl apply -f test-server-1.yaml
kubectl apply -f test-server-2.yaml</code></pre><h3>配置证书</h3><p>当使用TLS的SNI功能时,每个你想要使用SNI的域名或主机名都需要一个有效的证书。这是因为SNI允许从同一个IP地址和端口提供多个主机名服务,而证书用于验证服务器的身份并与客户端建立加密连接。使用OpenSSL为2个Game Server服务生成证书文件和密钥文件。</p><p>1、生成证书</p><pre><code>openssl req -new -newkey rsa:2048 -days 365 -nodes -x509 -keyout gs-1.key -out gs-1.crt -subj "/CN=gs-1.com"
openssl req -new -newkey rsa:2048 -days 365 -nodes -x509 -keyout gs-2.key -out gs-2.crt -subj "/CN=gs-2.com"</code></pre><p>2、上传证书到apisix</p><pre><code>kubectl port-forward -n ingress-apisix svc/apisix-admin 9180:9180 &amp;
sleep 3
curl  -X POST http://127.0.0.1:9180/apisix/admin/ssls -H 'X-API-KEY: edd1c9f034335f136f87ad84b625c8f1' -d '
{
    "cert": "'"$(cat gs-1.crt)"'",
    "key": "'"$(cat gs-1.key)"'",
    "snis": ["gs-1.com"]
}'
# Create SSL certificate for gs-2.com
curl -X POST http://127.0.0.1:9180/apisix/admin/ssls -H 'X-API-KEY: edd1c9f034335f136f87ad84b625c8f1'  -d '
{
    "cert": "'"$(cat gs-2.crt)"'",
    "key": "'"$(cat gs-2.key)"'",
    "snis": ["gs-2.com"]
}'
kill %1</code></pre><p>3、验证证书上传</p><pre><code>curl -X GET http://127.0.0.1:9180/apisix/admin/ssls -H 'X-API-KEY: edd1c9f034335f136f87ad84b625c8f1' 
</code></pre><h3>配置路由</h3><p>下面我们基于已经配置好的证书来配置相关的路由信息, 也就是通常我们在平台服配置好证书后,可以调用相关API来配置路由,命令信息如下:</p><pre><code>kubectl port-forward -n ingress-apisix svc/apisix-admin 9180:9180 &amp;
sleep 3
curl -i -X POST http://127.0.0.1:9180/apisix/admin/stream_routes -H 'X-API-KEY: edd1c9f034335f136f87ad84b625c8f1' -d '{
  "upstream": {
    "nodes": {
      "gs-1.game.svc.cluster.local:9000": 1
    },
    "type": "roundrobin"
  },
  "sni": "gs-1.com"
}'

curl -i -X POST http://127.0.0.1:9180/apisix/admin/stream_routes -H 'X-API-KEY: edd1c9f034335f136f87ad84b625c8f1' -d '{
  "upstream": {
    "nodes": {
      "gs-2.game.svc.cluster.local:9000": 1
    },
    "type": "roundrobin"
  },
  "sni": "gs-2.com"
}'</code></pre><h3>测试基于SNI的访问</h3><p>首先获取对应APIsix服务的ALB地址</p><pre><code>&gt; kubectl get svc -n ingress-apisix apisix-gateway
NAME             TYPE           CLUSTER-IP      EXTERNAL-IP                                                                     PORT(S)                       AGE
apisix-gateway   LoadBalancer   10.100.xxxx.12   k8s-ingressa-apisixga-xxxxxxx-xxx.elb.us-east-1.amazonaws.com   80:30496/TCP,8888:30694/TCP   3d2h
</code></pre><p>通过上面返回获取的ALB的地址</p><pre><code>openssl s_client -connect k8s-ingressa-apisixga-xxxxx.xxxx.elb.ap-northeast-1.amazonaws.com:8888 \
-servername gs-1.com -quiet
openssl s_client -connect k8s-ingressa-apisixga-xxxx.xxxx.elb.ap-northeast-1.amazonaws.com:8888 \
-servername gs-2.com -quiet</code></pre><p>至此可以看到通过不同的SNI我就可以访问到不同的游戏服了,也就解决了使用同一个NLB+APIsix的访问不同的游戏服了.</p><h3>APISix dashboard访问 (Optional)</h3><p>我们也可以通过Dashboard来访问当前的APIsix系统,查看相关的配置数据. 不过这里需要我们确认一下ALB的certificate ARN 是不是正确.</p><p><code>kubectl get ingress -n ingress-apisix</code></p><h2>APISix 部署亚马逊云科技最佳实践</h2><p>在生产环境中部署 Apache APISIX 时的关键最佳实践，帮助提升稳定性、性能与可维护性。</p><h3>核心架构与组件分离</h3><h4>为了保证系统可扩展与高可用，推荐将 APISIX 各核心组件解耦部署：</h4><ul><li>控制平面（etcd）：使用单独部署的 etcd 集群存储路由与插件配置，建议在部署APISix的时候直接指向预先部署好的etcd，至少部署 3 节点，开启数据持久化与快照备份，防止单点故障。</li><li>数据平面（APISIX 节点）：外部请求由多个 APISIX 实例处理，按需水平扩容。每个实例仅负责流量转发与插件执行，配置从 etcd 动态拉取。</li><li>运维监控（Prometheus &amp; Grafana）：部署专用的监控系统，采集 APISIX 及 etcd 的指标与日志，实时告警与可视化。</li></ul><h4>部署模式与扩展策略</h4><ul><li>无状态部署<br/>APISIX 实例本身应保持无状态，所有动态配置均存储在 etcd。容器化或虚拟机化均可，借助 Kubernetes 等平台实现自动伸缩与滚动升级。</li><li>水平扩展<br/>根据 QPS 与响应延迟指标，动态扩缩容。建议在 Kubernetes 中配置 HPA（Horizontal Pod Autoscaler），结合自定义指标（如 CPU、内存或请求速率）自动调整实例数。</li><li>灰度发布与回滚<br/>配合 Kubernetes Deployment 或其它发布工具，利用 canary 发布策略逐步下发新版本。在出现问题时，可快速回滚至稳定版本，且不中断大部分流量。</li></ul><pre><code>lifecycle:
  preStop:
    exec:
      command: ["sh", "-c", "sleep 15 &amp;&amp; apisix quit"]</code></pre><h3>网络与安全</h3><ul><li>高性能网络<br/>采用 L4 负载均衡（如 Nginx Stream、LVS）将流量分发至 APISIX，避免在 L7 层引入过多额外延迟。</li><li>TLS 终端<br/>如需 HTTPS 支持，推荐在边缘层（L4）终端 TLS，再以 HTTP 通信至 APISIX；或直接在 APISIX 上使用 ssl 插件终端 TLS，并结合 Cert-Manager 自动续签证书。</li><li>访问控制与认证<br/>启用 IP 黑白名单、ACL 插件，并根据业务需求接入 JWT、OAuth2 等认证插件，确保后端服务安全。</li></ul><h3>配置管理与版本控制</h3><ul><li>基础配置与热更新<br/>把路由、上游服务、插件配置以 YAML/JSON 格式存储于代码仓库，结合 CI/CD 流水线自动同步至 etcd，实现配置即代码（Configuration as Code）。</li><li>版本管理<br/>每次配置变更都需打 tag 并在流水线中校验（lint、单元测试、灰度发布），确保变更可追溯、可回滚。</li><li>选择稳定版本,并及时跟进社区的更新.</li><li>升级版本时需要进行完整的回归测试,保证新版本的兼容性问题.</li></ul><h3>性能优化与插件治理</h3><ul><li>实例选择<br/>优先选择Graviton类型主机，经过多轮测试发现Graviton的机型相对于x86机型可以提供至少2两倍的性能提升，具体请参考社区 Benchmark <a href="https://link.segmentfault.com/?enc=fgMQsSAoB8Ep7Xa7u%2FRzOw%3D%3D.p0AJwEiX6fnjxTo3fVjIUA63ql6bTtWFfB05hv8MoIYMXpQwR8NaZdeP%2BmStAciQXuT8cpnXNwAWgg%2BAO6VtbdYmKmBeIgk5Fsx3uFgkT2T5ikceJQWJl1Te4icW2QbH" rel="nofollow" target="_blank">链接</a>：.</li><li>插件开关粒度</li></ul><p>仅在需要的路由上启用插件，避免全局加载过多插件导致请求路径冗余执行。</p><ul><li>缓存与限流<br/>利用 proxy-cache 插件对静态或可缓存响应进行本地缓存，减轻后端压力；结合 limit-req、limit-count 插件防止流量突发与恶意攻击。</li><li>日志与追踪<br/>启用 skywalking、zipkin 或 opentelemetry 插件，将请求链路与指标上报至分布式追踪系统，快速定位性能瓶颈。</li></ul><h3>监控告警与健康检查</h3><ul><li>健康探针<br/>在 Kubernetes 中配置 LivenessProbe 与 ReadinessProbe，APISIX 节点异常时可自动剔除。</li><li>关键指标<br/>重点监控请求速率、响应延迟、错误率，以及 etcd 的延迟与 leader 选举状态。根据阈值配置告警规则，保证故障可被及时发现与响应</li><li>在实际生产中，如果service数量比较多以及并发大的情况下，需要对netfilter.nf_conntrack_max进行调整。建议结合prometheus和grafana进行告警，及时发现问题并优化相关参数。我们也可以通过采用类似C7gn的机型来提升网络吞吐。</li></ul><h3>灾备与高可用设计</h3><ul><li>跨可用区部署<br/>将 etcd 和 APISIX 实例分布在多个可用区或机房，保证单区故障时仍有服务可用。</li><li>定期备份<br/>对 etcd 数据进行周期性全量与增量备份，并在异地存储；同时验证备份可用性与恢复流程。</li></ul><p>通过上述最佳实践，可以构建一套 高可用、可扩展、易运维 的 APISIX 服务部署体系，满足业务在复杂流量下的稳定运行与快速迭代需求。</p><h2>总结</h2><p>借助以上方案通过将所有玩家和运维流量先汇聚到单个NLB，再由部署在 EKS 集群内的 Apache APISIX 按 TLS SNI 把请求精准分发到各游戏服，从而用最少的负载均衡实例实现统一路由、动态服务发现和全链路加密，不仅显著降低 NLB 成本和配置复杂度，还能在服务器扩缩容时保持流量无感知切换，成为高并发游戏场景下经济、高效且易维护的网关架构，同时，借助Graviton，APISix能够实现极高的性价比。</p><p><strong>参考内容</strong><br/><a href="https://link.segmentfault.com/?enc=MkZDk4YdGjn9fLBfOcC4oQ%3D%3D.j8vjRZcyGa00QNTnBEq6IHePTJBwRfDzxw0mSGxNCV%2FkVfHzXdAKqWdJMVZO%2BCyI" rel="nofollow" target="_blank">https://api7.ai/blog/api7-latency</a><br/><a href="https://link.segmentfault.com/?enc=vMzXjbC68d1iXxgpO2ytRA%3D%3D.qZuxdpGNpTpel7iYdQoOr4U%2Bl%2BSTDxDTPi1070TR9xsojWEe3wMbeAgk1M88M1V7bMzX%2FM4otMLaE4BqXe6c8drVXZjqFIni7T337rPu9eKftMdtNN9lmuiFS8A17xOK" rel="nofollow" target="_blank">https://apisix.apache.org/blog/2022/08/12/arm-performance-goo...</a></p><p><strong>本篇作者</strong><br/><img width="723" height="460" referrerpolicy="no-referrer" src="/img/bVdm4FO" alt="image.png" title="image.png"/></p><blockquote>本期最新实验为《<a href="https://link.segmentfault.com/?enc=lRxkqWqw7y%2FgFMJnYUCxCA%3D%3D.6wZy%2BQPvyfLgWSnenjUdYSwgnon3ULUrKc0pQAEXygb%2FrIHQqtHb6YuvPIPpbQEb%2FIQLOVd2gm0FZFnXCPVdgOi0E%2BeDneuq8RA33tAlHIiVAbcICqj6TSLsj3NgvCTTK6ecT6ihYuKUKTkgCeQQZ6JnxKnLMTnMp8y%2FpNY84QSMEJa7j8xNBfAHQCtZs59VWmbXUTYc%2FiBiUcYbQaWWSMcdrlMI52u7u8XFzMnC5%2BY%3D" rel="nofollow" target="_blank">创新基石 —— 基于 Graviton 构建差异化生成式AI向量数据库</a>》<br/>✨ 在本次实验中，你可以在基于 Graviton 的 EC2 实例上轻松启动 Milvus 向量数据库，加速您的生成式 AI 应用。基于 Graviton 的 EC2 实例为您提供极佳性价比的向量数据库部署选项。<br/>📱 即刻在云上探索实验室，开启构建开发者探索之旅吧！<br/>⏩<a href="https://link.segmentfault.com/?enc=7mmXZ8eIp7pOMTw94RzuGQ%3D%3D.3F%2B7sR03OiMmVLfW%2BBKECjBDm38%2BpzkWwJCDr9tZ4wqolJ8n9bxQOsjkdUVwve6QqVefRKVEBRUeK%2BC6KhuJhXIxRKVDy3St0aDLmgkCNy2rKR04Hn4lIMbRzQXsITkJqMy5uV%2FbePn9fJ7a2nbJoCyPnx8Xx1v0y2ED3%2B8ZXfgkN1hoYn%2Bv%2B%2FxJXTrwNWV03X%2FmD%2F5PjG0ga4nwnv1IT5%2FFD9NXHKY%2FYnhZyM%2B%2Fw%2Bc%3D" rel="nofollow" target="_blank">[点击进入实验</a>] 构建无限, 探索启程！</blockquote>]]></description></item><item>    <title><![CDATA[【URP】Unity[RendererF]]></title>    <link>https://segmentfault.com/a/1190000047406921</link>    <guid>https://segmentfault.com/a/1190000047406921</guid>    <pubDate>2025-11-18 10:02:09</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <blockquote><a href="https://link.segmentfault.com/?enc=kmJc9yvULAfYB112dMDMJw%3D%3D.KVq6LINisc0Gh9sOIIkyLlT8hQU67qMz0TkgOON9sVmcMF%2BH67mjM4wPjN7dW5Tyw6gRGMQqueldMibwmCmzUyFgULr%2F99OD04gq7excYr%2Fd0X5Ppffumr8Nb6CU%2B17cdgsQWcJUG%2BXuZ9pC1J7qPNv2CpIjgOzzS6nIQ%2BoZ8Itd27xBlYbLM570kkM%2B8s3W%2FdBcsrKJVxf3TwytFZMr4tEUs%2FA5qdsNjrJAGSRVnJA%3D" rel="nofollow" target="_blank">【从UnityURP开始探索游戏渲染】</a><strong>专栏-直达</strong></blockquote><h2><strong>SSAO概述与作用</strong></h2><p>SSAO(Screen Space Ambient Occlusion)是一种基于屏幕空间的全局环境光遮蔽技术，它通过计算场景中物体间的遮蔽关系来增强场景的深度感和真实感。在Unity URP中，SSAO通过Renderer Feature实现，作为URP渲染管线的扩展模块插入到渲染流程中。</p><p>SSAO的主要作用包括：</p><ul><li>增强场景深度感知，使物体间的接触区域产生自然阴影</li><li>提升场景细节表现，特别是角落和凹陷处的视觉效果</li><li>无需额外光照计算即可增强场景的空间感</li><li>相比传统AO技术性能开销更低</li></ul><h2><strong>SSAO发展历史</strong></h2><p>SSAO技术起源于2007年，由Crytek公司在《孤岛危机》中首次实现并商业化应用。随后该技术经历了多个发展阶段：</p><ul><li>‌<strong>早期SSAO</strong>‌(2007-2010)：基于深度缓冲的简单采样，存在明显的噪点和性能问题</li><li>‌<strong>HBAO</strong>‌(2010-2013)：NVIDIA提出的Horizon-Based AO，提高了精度但计算量较大</li><li>‌<strong>SSDO</strong>‌(2013-2015)：Screen Space Directional Occlusion，考虑了光线方向</li><li>‌<strong>现代SSAO</strong>‌(2015至今)：结合了降噪技术和自适应采样，如GTAO(Ground Truth AO)</li></ul><p>Unity自2018版开始将SSAO集成到URP中，通过Renderer Feature方式提供灵活的配置选项。</p><h2><strong>SSAO实现原理</strong></h2><p>SSAO在URP中的实现主要分为以下步骤：</p><ul><li>‌<strong>深度/法线信息采集</strong>‌：从摄像机深度纹理和法线纹理获取场景几何信息</li><li>‌<strong>采样点生成</strong>‌：在像素周围半球空间内生成随机采样点</li><li>‌<strong>遮蔽计算</strong>‌：比较采样点深度与场景深度，计算遮蔽值</li><li>‌<strong>模糊处理</strong>‌：通过双边滤波消除噪点</li><li>‌<strong>合成输出</strong>‌：将AO效果与场景颜色混合</li></ul><h3><strong>SSAO核心原理</strong></h3><ul><li><p>‌<strong>环境光遮蔽基础</strong>‌</p><p>AO通过模拟物体表面因几何遮挡导致的环境光衰减，增强场景深度感。其数学本质是法线半球面上可见性函数的积分计算。SSAO在屏幕空间利用深度/法线缓冲近似这一过程，避免传统AO的复杂光线求交。</p></li><li><p>‌<strong>屏幕空间实现机制</strong>‌</p><ul><li><p>‌<strong>深度重建</strong>‌：通过深度缓冲和相机投影矩阵反推像素的世界坐标，公式为：</p><pre><code class="c">float3 clipVec = float3(ndcPos.x, ndcPos.y, 1.0) * _ProjectionParams.z;
float3 viewVec = mul(unity_CameraInvProjection, clipVec.xyzz).xyz;</code></pre></li><li>‌<strong>法向半球采样</strong>‌：在像素法线方向构建半球采样核，对比周围深度值计算遮蔽因子。深度更高的采样点计数越多，遮蔽效果越强。</li></ul></li></ul><h3><strong>URP实现流程</strong></h3><ul><li><p>‌<strong>关键组件</strong>‌</p><ul><li>‌<strong>Renderer Feature</strong>‌：需创建独立Feature并配置<code>ScriptableRenderPassInput.Normal</code>以获取法线缓冲。</li><li>‌<strong>Shader计算</strong>‌：结合_CameraNormalsTexture和深度图进行世界坐标重建与遮蔽计算。</li></ul></li><li><p>‌<strong>示例代码</strong></p><ul><li><p>SSAORendererFeature.cs</p><pre><code class="csharp">using UnityEngine;
using UnityEngine.Rendering;
using UnityEngine.Rendering.Universal;

public class SSAORendererFeature : ScriptableRendererFeature {
    class SSAOPass : ScriptableRenderPass {
        public override void OnCameraSetup(CommandBuffer cmd, ref RenderingData renderingData) {
            ConfigureInput(ScriptableRenderPassInput.Normal);
        }
        // 实现Execute方法进行SSAO计算
    }
    public override void Create() {
        m_SSAOPass = new SSAOPass();
        m_SSAOPass.renderPassEvent = RenderPassEvent.AfterRenderingOpaques;
    }
}</code></pre></li><li><p>SSAO.shader</p><pre><code class="c">Shader "Hidden/SSAO" {
    Properties {
        _Radius ("采样半径", Range(0.1, 5)) = 1
        _Intensity ("强度", Range(0, 10)) = 1
    }
    SubShader {
        Pass {
            // 深度重建与采样核计算代码
        }
    }
}</code></pre></li></ul></li></ul><h3><strong>参数解析</strong></h3><table><thead><tr><th>参数</th><th>作用</th><th>典型值</th></tr></thead><tbody><tr><td>_Radius</td><td>控制采样范围</td><td>0.5-2.0</td></tr><tr><td>_Intensity</td><td>遮蔽强度</td><td>1.0-3.0</td></tr><tr><td>_SampleCount</td><td>采样点数量</td><td>16-32</td></tr></tbody></table><h3><strong>性能优化建议</strong></h3><ul><li>降低采样数（如16个）并配合噪声纹理</li><li>使用双边滤波消除噪点</li><li>仅在高端设备启用（移动端需谨慎）</li></ul><h2><strong>完整Unity URP实现示例</strong></h2><p>以下是完整的SSAO Renderer Feature实现流程：</p><ul><li><p>SSAORendererFeature.cs</p><pre><code class="csharp">using UnityEngine;
using UnityEngine.Rendering;
using UnityEngine.Rendering.Universal;

public class SSAORendererFeature : ScriptableRendererFeature
{
    [System.Serializable]
    public class SSAOSettings
    {
        public RenderPassEvent renderPassEvent = RenderPassEvent.AfterRenderingOpaques;
        public Material blitMaterial = null;
        public float radius = 0.5f;
        public float intensity = 1.0f;
        public float power = 2.0f;
        public int sampleCount = 16;
        public float bias = 0.025f;
        public float downsampling = 1;
        public bool blur = true;
        public float blurRadius = 1.0f;
    }

    public SSAOSettings settings = new SSAOSettings();
    private SSAORenderPass ssaoPass;

    public override void Create()
    {
        ssaoPass = new SSAORenderPass(settings);
    }

    public override void AddRenderPasses(ScriptableRenderer renderer, ref RenderingData renderingData)
    {
        if (settings.blitMaterial == null)
        {
            Debug.LogWarning("Missing SSAO material");
            return;
        }
        renderer.EnqueuePass(ssaoPass);
    }
}

public class SSAORenderPass : ScriptableRenderPass
{
    private Material ssaoMaterial;
    private SSAORendererFeature.SSAOSettings settings;
    private RenderTargetIdentifier source;
    private RenderTargetHandle tempTexture;
    private RenderTargetHandle tempTexture2;

    public SSAORenderPass(SSAORendererFeature.SSAOSettings settings)
    {
        this.settings = settings;
        this.renderPassEvent = settings.renderPassEvent;
        tempTexture.Init("_TempSSAOTexture");
        tempTexture2.Init("_TempSSAOTexture2");
    }

    public void Setup(RenderTargetIdentifier source)
    {
        this.source = source;
    }

    public override void Configure(CommandBuffer cmd, RenderTextureDescriptor cameraTextureDescriptor)
    {
        if (settings.downsampling &gt; 1)
        {
            cameraTextureDescriptor.width = (int)(cameraTextureDescriptor.width / settings.downsampling);
            cameraTextureDescriptor.height = (int)(cameraTextureDescriptor.height / settings.downsampling);
        }
        cmd.GetTemporaryRT(tempTexture.id, cameraTextureDescriptor, FilterMode.Bilinear);
        cmd.GetTemporaryRT(tempTexture2.id, cameraTextureDescriptor, FilterMode.Bilinear);
    }

    public override void Execute(ScriptableRenderContext context, ref RenderingData renderingData)
    {
        CommandBuffer cmd = CommandBufferPool.Get("SSAO");

        // Set SSAO material properties
        ssaoMaterial = settings.blitMaterial;
        ssaoMaterial.SetFloat("_Radius", settings.radius);
        ssaoMaterial.SetFloat("_Intensity", settings.intensity);
        ssaoMaterial.SetFloat("_Power", settings.power);
        ssaoMaterial.SetInt("_SampleCount", settings.sampleCount);
        ssaoMaterial.SetFloat("_Bias", settings.bias);

        // First pass - generate AO
        Blit(cmd, source, tempTexture.Identifier(), ssaoMaterial, 0);

        if (settings.blur)
        {
            // Second pass - horizontal blur
            ssaoMaterial.SetVector("_Direction", new Vector2(settings.blurRadius, 0));
            Blit(cmd, tempTexture.Identifier(), tempTexture2.Identifier(), ssaoMaterial, 1);

            // Third pass - vertical blur
            ssaoMaterial.SetVector("_Direction", new Vector2(0, settings.blurRadius));
            Blit(cmd, tempTexture2.Identifier(), tempTexture.Identifier(), ssaoMaterial, 1);
        }

        // Final pass - composite
        Blit(cmd, tempTexture.Identifier(), source, ssaoMaterial, 2);

        context.ExecuteCommandBuffer(cmd);
        CommandBufferPool.Release(cmd);
    }

    public override void FrameCleanup(CommandBuffer cmd)
    {
        cmd.ReleaseTemporaryRT(tempTexture.id);
        cmd.ReleaseTemporaryRT(tempTexture2.id);
    }
}</code></pre></li><li><p>SSAO.shader</p><pre><code class="c">Shader "Hidden/SSAO"
{
    Properties
    {
        _MainTex ("Texture", 2D) = "white" {}
    }

    SubShader
    {
        Cull Off ZWrite Off ZTest Always

        Pass // 0: Generate AO
        {
            CGPROGRAM
            #pragma vertex vert
            #pragma fragment frag
            #include "UnityCG.cginc"

            struct appdata
            {
                float4 vertex : POSITION;
                float2 uv : TEXCOORD0;
            };

            struct v2f
            {
                float2 uv : TEXCOORD0;
                float4 vertex : SV_POSITION;
            };

            v2f vert(appdata v)
            {
                v2f o;
                o.vertex = UnityObjectToClipPos(v.vertex);
                o.uv = v.uv;
                return o;
            }

            sampler2D _MainTex;
            sampler2D _CameraDepthNormalsTexture;
            float _Radius;
            float _Intensity;
            float _Power;
            int _SampleCount;
            float _Bias;

            float3 GetPosition(float2 uv)
            {
                float depth;
                float3 normal;
                DecodeDepthNormal(tex2D(_CameraDepthNormalsTexture, uv), depth, normal);
                float4 pos = float4(uv * 2 - 1, depth * 2 - 1, 1);
                pos = mul(unity_CameraInvProjection, pos);
                return pos.xyz / pos.w;
            }

            float3 GetNormal(float2 uv)
            {
                float depth;
                float3 normal;
                DecodeDepthNormal(tex2D(_CameraDepthNormalsTexture, uv), depth, normal);
                return normal;
            }

            float random(float2 uv)
            {
                return frac(sin(dot(uv, float2(12.9898, 78.233))) * 43758.5453);
            }

            float3 getSampleKernel(int i, float2 uv)
            {
                float r = random(uv * (i+1));
                float theta = random(uv * (i+2)) * 2 * 3.1415926;
                float phi = random(uv * (i+3)) * 3.1415926 * 0.5;

                float x = r * sin(phi) * cos(theta);
                float y = r * sin(phi) * sin(theta);
                float z = r * cos(phi);

                return normalize(float3(x, y, z));
            }

            float frag(v2f i) : SV_Target
            {
                float3 pos = GetPosition(i.uv);
                float3 normal = GetNormal(i.uv);

                float occlusion = 0.0;
                for(int j = 0; j &lt; _SampleCount; j++)
                {
                    float3 sampleKernel = getSampleKernel(j, i.uv);
                    sampleKernel = reflect(sampleKernel, normal);

                    float3 samplePos = pos + sampleKernel * _Radius;
                    float4 sampleClipPos = mul(unity_CameraProjection, float4(samplePos, 1.0));
                    sampleClipPos.xy /= sampleClipPos.w;
                    sampleClipPos.xy = sampleClipPos.xy * 0.5 + 0.5;

                    float sampleDepth = GetPosition(sampleClipPos.xy).z;
                    float rangeCheck = smoothstep(0.0, 1.0, _Radius / abs(pos.z - sampleDepth));
                    occlusion += (sampleDepth &gt;= samplePos.z + _Bias ? 1.0 : 0.0) * rangeCheck;
                }

                occlusion = 1.0 - (occlusion / _SampleCount);
                return pow(occlusion, _Power) * _Intensity;
            }
            ENDCG
        }

        Pass // 1: Blur
        {
            CGPROGRAM
            #pragma vertex vert
            #pragma fragment frag
            #include "UnityCG.cginc"

            struct appdata
            {
                float4 vertex : POSITION;
                float2 uv : TEXCOORD0;
            };

            struct v2f
            {
                float2 uv : TEXCOORD0;
                float4 vertex : SV_POSITION;
            };

            v2f vert(appdata v)
            {
                v2f o;
                o.vertex = UnityObjectToClipPos(v.vertex);
                o.uv = v.uv;
                return o;
            }

            sampler2D _MainTex;
            float4 _MainTex_TexelSize;
            float2 _Direction;

            float frag(v2f i) : SV_Target
            {
                float2 texelSize = _MainTex_TexelSize.xy;
                float result = 0.0;
                float weightSum = 0.0;

                for(int x = -2; x &lt;= 2; x++)
                {
                    float weight = exp(-(x*x) / (2.0 * 2.0));
                    float2 offset = _Direction * x * texelSize;
                    result += tex2D(_MainTex, i.uv + offset).r * weight;
                    weightSum += weight;
                }

                return result / weightSum;
            }
            ENDCG
        }

        Pass // 2: Composite
        {
            CGPROGRAM
            #pragma vertex vert
            #pragma fragment frag
            #include "UnityCG.cginc"

            struct appdata
            {
                float4 vertex : POSITION;
                float2 uv : TEXCOORD0;
            };

            struct v2f
            {
                float2 uv : TEXCOORD0;
                float4 vertex : SV_POSITION;
            };

            v2f vert(appdata v)
            {
                v2f o;
                o.vertex = UnityObjectToClipPos(v.vertex);
                o.uv = v.uv;
                return o;
            }

            sampler2D _MainTex;
            sampler2D _SSAOTex;

            float4 frag(v2f i) : SV_Target
            {
                float4 color = tex2D(_MainTex, i.uv);
                float ao = tex2D(_SSAOTex, i.uv).r;
                return color * ao;
            }
            ENDCG
        }
    }
}</code></pre></li></ul><h2><strong>SSAO参数详解与使用指南</strong></h2><h3><strong>参数含义与调整建议</strong></h3><ul><li><p>‌<strong>Radius 半径</strong>‌</p><ul><li>含义：控制采样点的搜索半径</li><li>范围：0.1-2.0</li><li>用例：小半径适合细节丰富的场景，大半径适合开阔场景</li></ul></li><li><p>‌<strong>Intensity 强度</strong>‌</p><ul><li>含义：控制AO效果的强度</li><li>范围：0.5-4.0</li><li>用例：值越大，遮蔽效果越明显</li></ul></li><li><p>‌<strong>Power 幂次</strong>‌</p><ul><li>含义：控制AO效果的对比度</li><li>范围：1.0-4.0</li><li>用例：值越大，暗部越暗，亮部越亮</li></ul></li><li><p>‌<strong>Sample Count 采样数</strong>‌</p><ul><li>含义：每个像素的采样点数</li><li>范围：8-32</li><li>用例：值越高效果越平滑但性能消耗越大</li></ul></li><li><p>‌<strong>Bias 偏移</strong>‌</p><ul><li>含义：防止自遮蔽的偏移量</li><li>范围：0.01-0.1</li><li>用例：值过小会产生噪点，值过</li></ul></li></ul><hr/><blockquote><a href="https://link.segmentfault.com/?enc=arstNcbtkHMmsdNEyfQy7w%3D%3D.oNb52nmMdP%2FEWLM%2FAJgClPJMWnmvPKk6wrY0HdTDungroNziesvwBG%2F0PnghpWNbCeaGmWBi%2Fy%2B%2FzccvPlGmwt1D51IoBmcDuERpii9PP7t2R7LTZsm8dTol7SWsTYJC8PKlk22bRKg9Rnfxb1EREGJN69%2B4uGOsQc0IGrpQA%2Bjj3Yo6%2BjqqngR5lgd0T6WTYrCjHDtpmrDd%2F9qN5o8%2Biti7hDXjdxidRDWuHWAjSEw%3D" rel="nofollow" target="_blank">【从UnityURP开始探索游戏渲染】</a><strong>专栏-直达</strong><br/>（欢迎<em>点赞留言</em>探讨，更多人加入进来能更加完善这个探索的过程，🙏）</blockquote>]]></description></item><item>    <title><![CDATA[企业知识管理困局破局者：PandaWik]]></title>    <link>https://segmentfault.com/a/1190000047406929</link>    <guid>https://segmentfault.com/a/1190000047406929</guid>    <pubDate>2025-11-18 10:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>还记得上周我拜访一家科技公司时看到的场景吗？下午三点，技术部门正在为一个小问题焦头烂额——一个简单的API调用问题，竟然让三个工程师花了整整两个小时才找到正确的文档版本。而这只是众多企业知识管理乱象的冰山一角。</p><h2>企业知识库的痛点，你中了几个？</h2><p>在我接触的数百家企业中，知识管理的问题惊人地相似：</p><ul><li>文档散落在各个员工的电脑、网盘、聊天记录中，形成一个个信息孤岛</li><li>新旧版本混乱，没人知道哪个才是最终版</li><li>新人入职要花数月才能熟悉业务，老员工离职就带走宝贵经验</li><li>客户问题重复回答，客服团队疲于奔命</li><li>敏感信息没有权限管控，数据安全存在隐患</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406931" alt="" title=""/></p><p>这些问题在金融、政务、医疗等对数据安全有严格要求的行业尤为突出。想象一下，如果银行的信贷政策文档版本混乱，或者医院的诊疗规范新旧不分，会带来多么严重的后果！</p><h2>PandaWiki：不只是知识库，更是企业智慧大脑</h2><p>当我第一次了解PandaWiki时，最吸引我的是它的定位——<strong>“AI驱动的开源知识库系统”</strong>。它不是简单的文档存储工具，而是构建了“知识创作-组织-协作-智能应用”完整闭环的企业级知识管理生态平台。<br/><img width="723" height="379" referrerpolicy="no-referrer" src="/img/bVdmF4h" alt="" title="" loading="lazy"/></p><h2>为什么PandaWiki能解决企业知识管理难题？</h2><h3>统一、权威、安全的知识中心</h3><p>PandaWiki的核心目标是构建一个<strong>统一、权威、安全的企业知识库</strong>。这意味着：</p><ul><li>所有文档集中管理，消除信息孤岛</li><li>版本控制确保每个人看到的都是最新、最准确的内容</li><li>严格的权限体系管理不同部门、角色的知识访问</li></ul><p>我曾经帮助一家200人的技术团队部署PandaWiki，他们最满意的是终于告别了文档版本混乱的时代。现在，技术文档库就像企业的“法典”，每个人都知道去哪里找，找到的必定是正确的版本。</p><h3>数据安全与私有化部署</h3><p>对于金融、政务、医疗等行业，数据不能随便存储。PandaWiki支持<strong>私有化部署</strong>，所有数据都掌握在企业自己手中，完全满足合规要求。</p><h3>AI助手：7×24小时的智能顾问</h3><p>这是PandaWiki最亮眼的功能。想象一下，团队成员或客户随时可以提问：“如何解决XXXX问题？”AI会自动从文档中检索相关内容，并给出精准答案。</p><p>我朋友的公司部署PandaWiki后，效果立竿见影。他们上传了产品文档和常见技术问题，配置了AI助手。现在，团队成员通过飞书上的问答机器人就能快速获取技术资料，不再需要依赖记忆或人工搜寻。</p><h3>严格的权限管理体系</h3><p>不同部门、不同角色看到的内容完全不同。销售看不到研发的技术文档，普通员工看不到高管的管理制度。这种精细化的权限控制，确保了知识的安全性和针对性。</p><h2>PandaWiki的核心能力，远超你的想象</h2><h3>AI创作助手：让文档编写事半功倍</h3><p>PandaWiki能够自动创建文档大纲和内容框架，智能润色和优化文档表达。我曾经测试过这个功能，输入几个关键词，它就能生成结构完整的文档框架，大大提升了写作效率。</p><h3>AI智能问答：真正的7×24小时客服</h3><p>支持多轮对话，理解上下文语境，这不再是简单的关键词匹配。AI能够理解问题的真实意图，给出有针对性的回答。</p><h3>AI语义搜索：突破关键词限制</h3><p>传统的搜索依赖精确的关键词，而PandaWiki的语义搜索能够理解用户想要什么，即使表达不准确也能找到相关内容。</p><h2>实际应用场景：PandaWiki在哪里发光发热？</h2><h3>企业技术文档库</h3><p>对于技术团队来说，PandaWiki是完美的技术文档管理平台。版本控制、权限管理、智能搜索，每一个功能都直击痛点。</p><h3>集团制度中心</h3><p>大企业的规章制度繁多，更新频繁。PandaWiki确保每个员工看到的都是最新版本，而且可以根据部门、职级设置不同的查看权限。</p><h3>客户帮助中心</h3><p>将产品文档、FAQ导入PandaWiki，配置AI助手，客户问题自助解决率大幅提升，客服团队可以专注于更复杂的问题。</p><h3>团队协作平台</h3><p>不仅仅是存储，更是协作。团队成员可以共同编辑文档，讨论问题，知识在协作中不断沉淀和丰富。</p><h2>部署如此简单，5分钟就能用上</h2><p>你可能以为这么强大的系统部署会很复杂？完全不是！</p><p>PandaWiki支持<strong>一键部署</strong>，真正做到了开箱即用。即使是非技术团队，也能快速上手。从环境准备到创建第一个知识库，整个过程不会超过30分钟。</p><p>我指导过一家传统企业的行政团队部署PandaWiki，他们没有任何技术背景，但按照指导文档，一个小时就搭建好了公司的制度库。</p><h2>多种AI服务商选择，总有一款适合你</h2><p>PandaWiki支持多种AI服务商，你可以根据需求灵活选择：</p><ul><li><strong>百智云</strong>：推荐新手使用，有免费额度让你尽情体验</li><li><strong>DeepSeek</strong>：性价比之选，效果不错且价格亲民</li><li><strong>OpenAI</strong>：ChatGPT背后的模型，效果领先</li><li><strong>月之暗面</strong>：Kimi背后的技术，长文本处理能力强</li><li><strong>硅基流动</strong>：专注于高效AI计算</li></ul><p>这种灵活性让不同规模、不同需求的企业都能找到适合自己的配置方案。</p><h2>真实案例：知识库从“信息黑洞”到“智慧宝库”的蜕变</h2><p>我印象深刻的一个案例是某互联网公司的技术团队。部署PandaWiki前，他们的技术文档分散在Confluence、GitHub Wiki、员工个人笔记中，新人要花3个月才能熟悉所有资料。</p><p>部署PandaWiki后，变化是颠覆性的：</p><ul><li>新员工培训时间从3个月缩短到3周</li><li>技术问题解决时间平均减少65%</li><li>客户重复提问减少80%</li><li>知识沉淀速度提升3倍</li></ul><p>团队负责人告诉我：“现在我们的知识库真正活起来了，它不再是被动存储文档的地方，而是主动为团队赋能的智慧中枢。”</p><h2>为什么你应该选择PandaWiki？</h2><p>在对比了市场上多款知识库产品后，我发现PandaWiki的独特优势：</p><h3>全流程覆盖</h3><p>从文档创作、团队协作到AI问答，PandaWiki提供了一站式解决方案。你不需要在多个工具间切换，所有工作都在一个平台上完成。</p><h3>企业级的安全保障</h3><p>从权限管理到私有化部署，PandaWiki的设计理念始终把安全放在首位。这对于处理敏感数据的企业来说至关重要。</p><h3>开源带来的灵活性</h3><p>作为开源系统，你可以根据自身需求进行定制开发，不再受制于SaaS产品的功能限制。</p><h3>真正的AI赋能</h3><p>这不是简单的AI噱头，而是深度整合AI能力到知识管理的每个环节。</p><h2>立即行动，开启企业知识管理新篇章</h2><p>数字化转型不是选择题，而是必答题。知识管理作为数字化转型的基础环节，其重要性不言而喻。</p><p>PandaWiki GitHub地址：<a href="https://link.segmentfault.com/?enc=1HPV0nXpxZQzxckC8JAmug%3D%3D.702CdKJi%2FFEl8EPKX8Y8ZiaS0kJWOWye7Almm1WB2CNdGBOfaGPX6L%2FGViphDXZd" rel="nofollow" target="_blank">https://github.com/chaitin/PandaWiki</a></p><p>官方文档：<a href="https://link.segmentfault.com/?enc=BFMBgvga3kZXkPzkqWiE6w%3D%3D.bLfJ0M%2FDf8FXZPpCHhHRAqhaONXjcM3rzCeES%2FQ86R3%2FpStqwUITh3vq9BKOCSHGJzcVdGgBqA97XsRudLkya5UaTVWewdIu03c3tpT4UpA%3D" rel="nofollow" target="_blank">https://ruanwen.baizhi.cloud/node/019a2fbb-1eb8-71ca-98c9-2f2...</a></p><p>如果你也受困于企业知识管理的问题，不妨给PandaWiki一个机会。就像我经常对客户说的：“好的工具不应该增加负担，而应该解决问题。”PandaWiki就是这样一个解决问题的工具。</p><p>部署简单、功能强大、AI赋能——这就是PandaWiki，企业知识管理的破局者。从今天开始，让你的企业知识库从“信息黑洞”变成“智慧宝库”吧！</p><p><strong>星光不问赶路人，时光不负有心人。</strong> 优秀的企业都在用智能化的方式管理知识，你还在等什么呢？</p>]]></description></item><item>    <title><![CDATA[大模型语音呼叫智能体「云蝠智能」完成 A]]></title>    <link>https://segmentfault.com/a/1190000047406583</link>    <guid>https://segmentfault.com/a/1190000047406583</guid>    <pubDate>2025-11-18 09:04:12</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>云蝠智能现已完成了由金沙江创业投资领投的 A+ 轮融资，鞍羽资本担任独家财务顾问。</p><p>作为国内第一批直接采用大模型从事智能语音客服的企业，云蝠智能其全栈自研的「神鹤大模型」支撑着语音智能体在 3-5 分钟内快速构建上下文对话能力。</p><p>云蝠智能不仅是「超音速计划 2025·Voice Agent Camp」的优秀学员，更在刚结束的 RTE 2025 年度 Demo Day 中脱颖而出，位列三强。</p><p>RTE 开发者社区作为云蝠智能在创业征途中的重要陪跑者和成长伙伴，一路见证了其技术产品的迭代升级与融资里程碑。</p><p>RTE 开发者社区将一如既往地关注 Voice Agent 及语音驱动的下一代人机交互界面，并期待更多优秀项目加入社区，携手共建，加速成长。</p><hr/><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406585" alt="" title=""/></p><p>作为国内第一批直接采用大模型从事智能语音客服的企业，云蝠智能其全栈自研的“神鹤大模型”支撑着语音智能体在3-5分钟内快速构建上下文对话能力。云蝠智能现已完成了由 <strong>金沙江创业投资</strong> 领投的 A+ 轮融资，<strong>鞍羽资本</strong> 担任独家财务顾问。</p><p><strong>本轮融资主要用于以下的产品迭代：</strong></p><ol><li>加强语音智能体在结果及服务的业务场景落地，加速呼入、不良资产处置等产品的市场化及规模化落地。</li><li>加速 VoiceAgent 的产品优化，构建自动化 FDE 前线部署工程师，实现自动化交付。</li><li>优化智能体工程，将对话延迟稳定压缩到 1s，实现类人级无感情绪理解和互动。</li></ol><h2>VoiceAgent 在呼叫领域的探索者</h2><p>云蝠智能成立于 2018 年，是 VoiceAgent 领域不多的从 AI1.0 周期全面转型模型呼叫的技术企业。成立之初的命名就以声音为唯一互动的动物“蝙蝠”作为品牌，构建对话智能服务。历经关键词、正则表达式、NLP、大模型理解、大模型生成等诸多技术周期，到现在全力冲刺语音能力在呼叫领域的全面智能化。</p><p>云蝠智能的创始人魏佳星毕业于江南大学，常年从事语音智能体、对话的构建开发和产品设计。作为国内不多长期关注、垂直在语音智能领域的创始人，他表示：</p><p>“在 2018 年创办云蝠智能的时候，我就相信这是一个常识：即终将出现一个达到人类能力的对话智能体，而我为这件事情做好了等待十年的准备。LLM 能力极大的提高了我实现个人理想的可能性。声音，终将无处不在。”</p><h2>关于云蝠智能</h2><p>“云蝠智能”是一款 AI 原生的大模型语音智能体，我们为企业提供AICC大模型呼叫中心，在ChatBOT和CRM基础上提供包括语音智能体，产品能力包括了大模型语音外呼、智能呼入、网页实时语音交互 sdk 及 api我们由来自阿里巴巴等公司优秀的开发者组成，曾经获得华为云开发者大赛、讯飞开发者大赛冠军。</p><p>这款产品可以在呼入工单建立、投诉处理及需求跟进等场景完全取代人工客服，在会员回访、客户召回场景取代大多数客服。</p><p>当前我们的月均AI 人机通话量为 4500 万通电话，服务于 3 万家终端企业。在呼入场景中，模型可以实现对人的80% 的取代，平均对话时长 171 秒。</p><p><strong>云蝠的技术特点如下：</strong></p><p><strong>超低延迟</strong></p><p>基于自研的暴风引擎、及多模型语音加速方案，和对模型的零信任构建的模型主备机制，云蝠智能可以在基于公有云 token 调用的情况下，将对话延迟稳定压缩在 1～1.2s 之间。</p><p><strong>更拟人</strong></p><p>基于对呼叫声优的 SFT 微调，并结合大模型技术，实现 50 国语音，超多方言的小样本克隆音合成，并对语音中数值、符号等情绪进行优化。请可能模拟人类在电话中的情感状态。</p><p><strong>幻觉控制</strong></p><p>自创时空注意力机制，结合 tool 的调用，构建模型、注意力、tool 的三层组合，实现速度和对话体验互斥的调和架构。</p><p><strong>高并发处理</strong></p><p>基于 7 年FreeSwitch 的开发，实现全面的通信模块自主化，可以实现超高并发能力的稳定控制和确保通话稳定。</p><h2><strong>云蝠智能伙伴招募</strong></h2><p>作为国内见证了呼叫智能体从 1.0 到 2.0延边的创新者，云蝠智能期待和更多合作伙伴共创，找到模型能力在呼叫、语音中可以实现结果交付的业务场景。</p><p>我们期待来自文本客服、模型厂家、电信运营商、PBX 公司、SCRM 及 CRM 数据拥有者等等更多垂直地区、垂直行业的合作伙伴一起合作，基于 OEM+iframe 的形式，快速为您的系统部署语音智能体，让无法说话的系统开口，主动和被动的联络用户！</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406586" alt="" title="" loading="lazy"/></p><p>云蝠智能VoiceAgent发布会现场</p><p><strong>投资人寄语：</strong></p><p>种子轮投资人<strong>奇绩创坛</strong>合伙人<strong>曹勖文</strong></p><blockquote>“我们非常看好语音Agent在垂直场景的规模化落地。云蝠智能在语音与AI长期深耕，技术栈扎实，产品贴近一线；团队战斗力强、执行快、能在复杂场景中快速打穿并复制。伴随VoiceAgent赛道进入商业化加速期，我们相信云蝠将把成本、效率与体验的提升转化为持续增长与行业影响力。”</blockquote><p>作为早期投资人，<strong>御势资本</strong>非常看好云蝠智能与魏总在 AI赋能产业升级中帮助中国数千万企业抓住 AI 带来的机遇，让企业运营更高效</p><p>A 轮投资人御势资本主管合伙人 <strong>邓明生</strong> 表示：</p><blockquote><p>“云蝠智能作为 Voice Agent 领域的领先者，在短短几年搭建了完善的客户服务体系，目前已经服务了数万家企业客户，沉淀了大量的用户商业对话行为数据。创始人魏佳星魏总具有非常敏锐的技术洞察，在企业管理中精益求精，搭建强大的技术与运营团队，注重客户服务体验，真正为客户带来了销售额的显著增长。</p><p>大模型技术带来的 Voice Agent 在 AI 销售和 AI 客服，让企业不仅可以快速扩展销售和服务网络，更是让每一位客户都能获得金牌销售与金牌客服的优质体验，从而实现从“人力密集型”的线性增长向“Ai 驱动型”的指数增长，这是万亿级人力资本市场的颠覆性变革。"</p></blockquote><p>A+轮投资人<strong>金沙江创业投资</strong>基金主管合伙人<strong>朱啸虎</strong></p><blockquote>我们认为语音 Agent 将成为企业级 AI 最快进入规模化应用的方向之一。云蝠在智能呼叫领域深耕多年，建立了扎实的场景理解和数据基础，并率先推出可商用的模型呼叫产品。凭借领先的产品力和迭代速度，云蝠在呼入、销售、客服、不良资产处置等关键场景展现出快速渗透和复制能力。我们相信云蝠将成为新一代 Voice Agent 企业的领跑者。”</blockquote><p>本轮融资财务顾问 <strong>鞍羽资本合伙人 沈海丰</strong></p><blockquote>“云蝠团队有着行业内最深的产品及技术认知和积累，团队从第一天取名“云蝠”起就一直在VoiceAgent赛道上狂奔，致力于成为语音交互方向最好的公司、打造真人实时语音交互体验。几年来经历了数次的产品及技术迭代，公司持续获得各行各业数千家客户的正向反馈，业务连续多年高质量增长，取得了优异的业绩表现。鞍羽资本见证了云蝠在佳星的带领下，从技术攻坚到生态落地的完整蜕变，也将一如既往支持云蝠公司的长期发展。”</blockquote><p>本轮融资后，云蝠智能同步发布 VoiceAgent2.0 版本，您也可以直接访问：</p><p>https\://www.telrobot.top/</p><p>注册体验云蝠智能 VoiceAgent2.0 最新特性！</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406587" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047406588" alt="" title="" loading="lazy"/></p><p><a href="https://link.segmentfault.com/?enc=lk%2Fxmy3T3bpUQ%2BewggB8HA%3D%3D.shJ28YFu1l%2F%2BCaeVtKCkTK512%2F%2Fwy6efnc3diuIsccc%3D" rel="nofollow" target="_blank">阅读更多 Voice Agent 学习笔记：了解最懂 AI 语音的头脑都在思考什么</a></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406589" alt="" title="" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[RustRover 2025.2.4 1]]></title>    <link>https://segmentfault.com/a/1190000047406607</link>    <guid>https://segmentfault.com/a/1190000047406607</guid>    <pubDate>2025-11-18 09:03:20</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <ul><li>2025-11-18亲测</li><li>支持最新版本2025.2.4</li><li>支持Windows、MAC、Linux<br/><img width="647" height="454" referrerpolicy="no-referrer" src="/img/bVdm4MP" alt="rust.png" title="rust.png"/></li></ul><h2>一 安装</h2><p>官网下载：<a href="https://link.segmentfault.com/?enc=imMrdhEwxLVoB4m3fyvBDA%3D%3D.Ox8%2BWU87x%2FV6Ktt0cbms8BoHBYdFo4e%2FSXV%2FFrPgaO30504sY%2F3YHYJfOBkvHjBJ" rel="nofollow" target="_blank">https://www.jetbrains.com/zh-cn/rust/</a><br/>根据提示安装</p><h2>二 授权说明</h2><p><img width="723" height="265" referrerpolicy="no-referrer" src="https://segmentfault.com/img/bVdmZkU" alt="图片" title="图片" loading="lazy"/><br/>回复 《rust》获取<br/>新版本安装后不提示授权，需要手动处理</p><h2>三 使用</h2><p>打开自己的项目，配置环境，开始开发<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdm4MQ" alt="image.png" title="image.png" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[PandaCoder：我的个人开发者工具]]></title>    <link>https://segmentfault.com/a/1190000047406613</link>    <guid>https://segmentfault.com/a/1190000047406613</guid>    <pubDate>2025-11-18 09:02:50</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>引言：从个人项目到开发者工具的转变</h2><p>在技术领域，我常常思考一个问题：什么样的工具才能真正帮助开发者？我意识到真正的价值不在于功能的数量，而在于这些功能是否真正解决了用户的痛点。作为PandaCoder的独立开发者，我的核心理念正是建立在这一认知之上——<strong>与其堆砌功能，不如倾听用户的声音</strong>。</p><h3>工具的本质</h3><p>正如纳瓦尔所言："工具应该为你工作，而不是你为工具工作。"我设计PandaCoder的初衷是创建一个能够真正理解开发者需求的智能助手，而不是又一个需要复杂配置的负担。</p><h2>用户反馈：产品进化的核心驱动力</h2><h3>为什么建议比打赏更重要？</h3><p>在PandaCoder的设计中，我刻意将"✍️ 插件的建议"功能置于"☕️ 请作者喝杯"之前。这不是偶然，而是基于一个深刻的洞察：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406615" alt="" title=""/></p><p><strong>用户的建议是产品进化的燃料，而打赏只是这个过程的副产品。</strong></p><p>当开发者愿意花时间提供反馈时，实际上是在投资这个工具的未来。这种投资远比金钱更有价值，因为它包含了真实的用户体验和需求洞察。</p><h3>反馈系统的设计哲学</h3><p>我设计的反馈系统采用了精心设计的交互体验：</p><ul><li><strong>智能限流机制</strong>：每日6次反馈限制，确保每一条建议都是经过深思熟虑的</li><li><strong>分类反馈</strong>：功能建议、Bug反馈、使用体验、其他，让反馈更有针对性</li><li><strong>即时确认</strong>：用户提交后立即收到确认，建立反馈闭环</li></ul><p>这种设计体现了史蒂文·巴特利特强调的"用户体验即品牌"理念。</p><h2>功能演进：从用户需求出发</h2><h3>中文编程助手的诞生</h3><p>最初的PandaCoder只是一个简单的翻译工具。但通过用户反馈，我发现中国开发者真正需要的是<strong>从中文思维到英文代码的顺畅转换</strong>，而不仅仅是文字翻译。</p><p>用户建议促使我开发了：</p><ul><li>智能命名转换（小驼峰、大驼峰、大写带下划线）</li><li>中文类名自动生成</li><li>多级翻译引擎（国内大模型 &gt; Google翻译 &gt; 百度翻译）</li></ul><h3>Jenkins Pipeline支持的进化</h3><p>最初只是语法高亮，但用户反馈揭示了更深层次的需求：开发者在编写Pipeline时需要<strong>智能补全、环境变量管理、文档支持</strong>。</p><p>这些功能不是凭空想象的，而是来自真实用户的痛点反馈。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406616" alt="" title="" loading="lazy"/></p><h3>SpringBoot配置的可视化</h3><p>通过用户建议，我实现了技术栈的智能识别和可视化显示。现在开发者打开配置文件时，能够直观看到使用的技术组件，大大提升了开发效率。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406617" alt="" title="" loading="lazy"/></p><h2>数据驱动的产品迭代</h2><h3>Git统计分析功能</h3><p>用户反馈显示，团队需要更好的代码协作洞察。我开发了：</p><ul><li>多维度代码统计</li><li>可视化图表展示</li><li>自动邮件报告系统</li></ul><p>这些功能帮助团队管理者了解开发进度，识别瓶颈，优化协作流程。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406618" alt="" title="" loading="lazy"/></p><h3>实时监控体系的建立</h3><p>基于用户对调试效率的需求，我构建了完整的监控体系：</p><ul><li>Elasticsearch DSL监控</li><li>SQL执行监控</li><li>API调用链追踪</li></ul><p>这些功能让开发者能够实时了解应用运行状态，快速定位问题。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406619" alt="" title="" loading="lazy"/></p><h2>社区驱动的技术决策</h2><h3>翻译引擎的选择</h3><p>最初我只支持百度翻译，但用户反馈显示：</p><ul><li>国内大模型在某些场景下翻译质量更高</li><li>Google翻译在国际化项目中有独特优势</li><li>需要多引擎备用确保服务稳定性</li></ul><p>这些反馈促使我建立了三级翻译引擎系统。</p><h3>AI助手功能的扩展</h3><p>用户建议让我意识到：开发者需要的不只是翻译，还有<strong>代码审查、技术咨询、学习辅导</strong>等AI能力。</p><p>这促使我集成了多种AI模型，包括OpenAI、Ollama本地部署、国内大模型等。</p><h2>技术实现背后的思考</h2><h3>性能与用户体验的平衡</h3><p>在实现功能时，我始终遵循纳瓦尔的建议："在技术决策中，简单性往往比复杂性更有价值。"</p><p>例如：</p><ul><li>使用ConcurrentHashMap确保线程安全</li><li>实现延迟加载优化性能</li><li>合理的缓存策略提升响应速度</li></ul><h3>可扩展性设计</h3><p>我采用模块化设计，确保新功能能够无缝集成。这种设计理念来源于用户对未来扩展性的需求预期。</p><h2>用户参与的价值创造</h2><h3>从使用者到共建者</h3><p>PandaCoder的成功案例证明：<strong>当用户参与产品设计时，他们从被动的使用者转变为积极的共建者。</strong></p><p>这种转变带来的价值是双向的：</p><ul><li>用户获得更符合需求的工具</li><li>我获得真实的用户洞察</li><li>整个生态实现良性循环</li></ul><h3>反馈的乘数效应</h3><p>一个用户的建议可能影响数千名其他用户的使用体验。这种乘数效应是开源社区最强大的力量之一。</p><h2>未来展望：基于用户需求的持续进化</h2><h3>短期规划</h3><p>基于当前用户反馈，我计划：</p><ul><li>增强AI助手功能（代码生成、重构建议）</li><li>优化Git统计图表样式</li><li>改进邮件模板自定义功能</li></ul><h3>中长期愿景</h3><p>用户建议指引我向更智能化的方向发展：</p><ul><li>代码智能分析与建议系统</li><li>项目健康度评估报告</li><li>团队协作效率分析工具</li></ul><h2>结语：共建更好的开发者工具</h2><p>PandaCoder的成长历程印证了一个重要观点：<strong>最好的产品功能来源于真实用户的需求。</strong></p><p>我相信，技术工具的价值不在于它拥有多少功能，而在于它是否真正解决了开发者的问题。而了解这些问题的唯一途径，就是倾听用户的声音。</p><p>正如史蒂文·巴特利特所说："成功的企业不是那些拥有最好产品的企业，而是那些最了解客户需求的企业。"</p><p>我邀请每一位开发者参与PandaCoder的进化之旅。您的每一个建议都可能成为下一个重要功能的灵感来源。</p><hr/><p><strong>参与方式：</strong></p><ul><li>在IDE中点击"✍️ 插件的建议"提交反馈</li><li>通过GitHub Issues参与讨论</li><li>关注公众号"舒一笑的架构笔记"获取最新动态</li></ul><p><strong>技术博客信息：</strong></p><ul><li>主站：www.poeticcoder.com</li><li>备用站：www.shuyixiao.top</li><li>详细功能介绍：<a href="https://link.segmentfault.com/?enc=6uQabN7%2BIqYoXK9rLRPHmw%3D%3D.XLjNt9rZ0q92aHkIAN6Cd3t6T61pgIywowlcYdggdiWoLyoiYmvA3UyR%2B%2BYZ5HdxU%2Fla2iFFX7P%2FMyfOmPBsfw%3D%3D" rel="nofollow" target="_blank">PandaCoder完整功能介绍</a></li></ul><hr/><p><em>舒一笑不秃头，生成式AI应用工程师(高级)认证，阿里云博客专家，专注于企业级Java开发和AI应用开发。</em></p>]]></description></item><item>    <title><![CDATA[为什么内网IP也需要SSL证书 冷冷的炒]]></title>    <link>https://segmentfault.com/a/1190000047406632</link>    <guid>https://segmentfault.com/a/1190000047406632</guid>    <pubDate>2025-11-18 09:01:58</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>为什么内网IP也需要SSL证书？在很多人看来，SSL证书主要是用于互联网上的网站，比如电商平台、银行网站等，需要保护用户的敏感数据。但你可能不知道，内网IP（如192.168.1.1、10.0.0.1等）同样需要SSL证书。</p><p><strong>1. 防止内网数据被窃听</strong></p><p>即使你的服务只在局域网内运行，数据仍然可能被监听。例如：如果公司Wi-Fi被入侵，黑客可以嗅探内部HTTP流量，获取账号密码、数据库信息等。内部员工可能利用抓包工具（如Wireshark）查看未加密的通信内容。</p><p><strong>SSL证书的作用</strong>：通过HTTPS加密，确保数据在传输过程中无法被窃取或篡改。</p><h4>内网IP地址SSL证书<a href="https://link.segmentfault.com/?enc=DhBGHkDhj4eBtDv5rbsrhA%3D%3D.M%2FcrUq7JUiTjmtzV7jyPC6DHyVqBjj3IqheILTUFvUmOdaPr2FIIxQLYXQ7t8%2BaRgZMvBgwln9rONLjFWM6C4%2BAHQkTZf1LI4NBiDg4TNsM%3D" rel="nofollow" target="_blank">申请入口</a>直接访问JoySSL注册一个账号，记得填写注册码230973获取免费安装服务</h4><p><img width="688" height="353" referrerpolicy="no-referrer" src="/img/bVdm1Ae" alt="" title=""/><br/><strong>2. 避免浏览器“不安全”警告</strong></p><p>现代浏览器（如Chrome、Edge）会对所有HTTP网站标记为“不安全”，即使是内网IP也不例外。这会导致：员工访问内部系统时频繁看到警告，影响使用体验。某些浏览器可能阻止访问HTTP网站，导致内部工具无法正常使用。<br/><strong>SSL证书的解决方案</strong>：部署证书后，内网服务将以HTTPS运行，浏览器不再提示“不安全”。</p><p><strong>3. 满足安全合规要求</strong></p><p>许多行业（如金融、医疗、政府）对数据安全有严格要求，例如：GDPR（欧盟通用数据保护条例） ：要求企业保护用户和员工的隐私数据。等保2.0（中国网络安全等级保护） ：明确要求内部系统采用加密通信。SSL证书的合规价值：帮助企业在审计时证明内部通信符合安全标准。</p><p><strong>4. 防止中间人攻击（MITM）</strong></p><p>在内网环境中，攻击者可能伪装成网关或服务器，进行中间人攻击（MITM），例如：伪造一个假的登录页面，诱导员工输入账号密码。</p><p>篡改内部API请求，导致数据泄露或系统故障。SSL证书的防护机制：HTTPS通过数字证书验证服务器身份，确保通信双方不被冒充。</p><p>如何为内网IP申请SSL证书？虽然公共通常不直接为内网IP签发证书，但仍有几种解决方案：私有CA（企业级方案） ：在企业内部搭建CA，统一签发和管理证书。特殊CA支持：部分CA（如JoySSL）提供内网IP证书，需付费申请。</p><p><strong>总结：内网IP使用SSL证书并非多此一举，而是提升安全性、改善用户体验、满足合规要求的重要措施。无论是企业OA系统、内部数据库还是开发测试环境，HTTPS加密都能有效降低风险。</strong></p>]]></description></item><item>    <title><![CDATA[剑指offer-38、⼆叉树的深度 程序]]></title>    <link>https://segmentfault.com/a/1190000047402152</link>    <guid>https://segmentfault.com/a/1190000047402152</guid>    <pubDate>2025-11-18 09:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>题⽬描述</h2><p>输⼊⼀棵⼆叉树，求该树的深度。从根结点到叶结点依次经过的结点（含根、叶结点）形成树的⼀条路径，最⻓路径的⻓度为树的深度。</p><p>示例1<br/>输⼊：{1,2,3,4,5,#,6,#,#,7}<br/>返回值：4</p><h2>思路及解答</h2><p>声明：这⾥的输⼊是⼀个数的根节点，也就是从根节点，我们就可以获取到树的所有节点，⽽类似数组的表达⽅式 {1,2,3,4,5,#,6,#,#,7} ，则是按照层次来放的。(⽐如这个树就是4层)</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047402154" alt="" title=""/></p><h3>递归</h3><p>第⼀种⽅法⽐较容易想到，对于任意⼀个节点 node ⽽⾔，我要想知道当前 node 节点（包括当前节点）的深度，肯定得求当前节点的左边节点（设为 left ）的深度 leftDeepth ，以及获取右节点（设为 right ）的深度 rightDeepth ，然后求两者最⼤+1（ Max{leftDeepth,rightDeepth}+1 ），就是当前节点的深度。</p><p>思路：二叉树的深度 = max(左子树深度, 右子树深度) + 1</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047402155" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047402156" alt="" title="" loading="lazy"/></p><p>⽽递归中⽐较重要的⼀点，是结束条件。在这道题中，如果⼀个节点为 null ，就结束，并且当前节点的深度是 0 。代码超级⽆敌短：</p><pre><code class="java">public class Solution {
     public int TreeDepth(TreeNode root) {
         if(root==null) return 0;
         return Math.max(TreeDepth(root.left),TreeDepth(root.right))+1;
     }
}</code></pre><p>以上解法要是看不明白，可以看详细点的：</p><pre><code class="java">public class Solution {
    public int TreeDepth(TreeNode root) {
        // 递归终止条件：空节点深度为0
        if (root == null) {
            return 0;
        }
        
        // 递归计算左子树深度
        int leftDepth = maxDepth(root.left);
        // 递归计算右子树深度
        int rightDepth = maxDepth(root.right);
        
        // 当前树深度 = 左右子树最大深度 + 1（当前节点）
        return Math.max(leftDepth, rightDepth) + 1;
    }
}</code></pre><ul><li><strong>时间复杂度</strong>：O(n)，需要访问每个节点一次</li><li><strong>空间复杂度</strong>：O(h)，递归栈深度等于树高，最坏情况（链表）为O(n)</li></ul><h3>迭代遍历</h3><p>思路是如果树的根节点不为空，则将根节点放进队列中。也就是，每遍历一层，深度加1，直到遍历完所有层</p><p>设置深度 deep 为0。使⽤ while 循环，只要队列不为空，则执⾏下⾯操作：</p><ol><li>获取队列的⼤⼩ size 。</li><li>依次取出队列的前 size 个元素，如果该元素的左边节点不为空，则将左边节点放进队列，如果该元素的右边节点不为空，则将该元素的右边节点放进队列。</li><li>层次 deep+1</li></ol><pre><code class="java">public class Solution {
    public int TreeDepth(TreeNode root) {
        if (root == null) return 0;
        
        Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;();
        queue.offer(root);
        int depth = 0;
        
        while (!queue.isEmpty()) {
            // 当前层的节点个数
            int levelSize = queue.size();
            
            // 遍历当前层的所有节点
            for (int i = 0; i &lt; levelSize; i++) {
                TreeNode currentNode = queue.poll();
                
                // 将下一层节点加入队列
                if (currentNode.left != null) {
                    queue.offer(currentNode.left);
                }
                if (currentNode.right != null) {
                    queue.offer(currentNode.right);
                }
            }
            
            // 完成一层遍历，深度加1
            depth++;
        }
        
        return depth;
    }
}</code></pre><ul><li>时间复杂度为：O(n)，所有的节点需要进⼊队列，再出队列</li><li>空间复杂度：O(n),借助了额外的队列空间。</li></ul>]]></description></item><item>    <title><![CDATA[从「跨模态思维链」到「物理 AI 数据闭]]></title>    <link>https://segmentfault.com/a/1190000047406538</link>    <guid>https://segmentfault.com/a/1190000047406538</guid>    <pubDate>2025-11-18 08:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406540" alt="" title=""/></p><p>在本届 RTE2025 大会上，来自产业界和学术界的多位专家深入探讨了从 AI 视频生成到可实时交互的世界模型，从被动响应到主动感知与交互，再到下一代多模态大模型的设计与构建——由<strong>商汤科技</strong> 和 <strong>RTE 开发者社区</strong> 联合出品的 <strong>「多模态技术专场」</strong> 将展望一个由实时多模态 AI 驱动的未来。</p><p>商汤科技执行商务总监<strong>李星冶</strong>、RTE 开发者社区联合主理人和 OpenQ 联合创始人<strong>林旅强</strong>、商汤科技多模态交互产品负责人<strong>路少卿</strong>、加拿大滑铁卢大学访问学者<strong>冯睿蠡</strong>、阶跃星辰语音和 AIGC 算法负责人<strong>俞刚</strong>、和众科技 HooRii Technology Co-Founder\&amp;CTO <strong>刘一聪</strong>、灵宇宙创始人<strong>顾嘉唯</strong>、Agora 的 Principal Product Manager <strong>Monica Chen</strong>、拽米科技（DraMa.i）创始人<strong>何竞飞</strong>以及 Memories.ai 算法负责人 <strong>Jerrick</strong> 分享了他们在各自领域的实践经验和独到见解。</p><hr/><p>商汤科技执行商务总监李星冶和 RTE 开发者社区的联合主理人，OpenQ 联合创始人林旅强分别主持了活动主题分享和圆桌讨论环节。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406541" alt="" title="" loading="lazy"/></p><h2>路少卿：从文本推理到多模态交互：为什么是必经之路？</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406542" alt="" title="" loading="lazy"/></p><p>商汤科技多模态交互产品负责人路少卿发现，即使是市面上最新的模型，在处理涉及视觉理解、空间认知和复杂图文推理的任务时，也表现出明显的缺失。并提出了商汤未来必须攻克的方向——从文本推理到原生融合的统一多模态大模型。<strong>目前的多模态模型依然停留在 VLP（视觉语言预训练）+ LLM的 Merge 阶段（即 VQA 任务），缺乏真正原生融合后产生的跨模态思维链推理能力。</strong></p><p>商汤的核心路径是追求统一深度的多模态大模型，目标是实现理解与生成融合统一，并激活类人的多模态思维链能力。针对图文交错的推理难题，商汤构建了<strong>专门的数据生产管线和强化学习后训练机制</strong>，用于提升模型在需要多次图像局部信息确认和推理的任务上的能力。同时，商汤重构了 DiT 网络，<strong>实现了单人人像视频的生成和语音驱动</strong>。通过引入音频驱动的 Attention 模块，成功整合了人像生成、实时驱动和多模态实时交互的完整能力。商汤还<strong>在文本对话中掺杂了图片域训练</strong>，使端到端融合模型能够实现文本域推理，并结合对话历史中的图片域推理和交互，大幅提升了上下文记忆能力。</p><p>路少卿也提到了业界的最新突破，如 OpenAI GPT-4o 实现了复杂的 Prompt 与图像生成的完全对齐，以及 Google Nano-banana 在跨多角色 ID 保持上的突破，都是「理解与生成融合统一」的最新信号。<strong>模型正从传统的被动接受指令转向具备环境感知、主动推理和主动规划的能力</strong> 。他以一个案例演示：模型感知到用户「有点渴」，能识别到环境中的饮品和食物，主动发起交互反馈。他认为，技术发展很快，但远未到收敛状态，未来将聚焦于图文交错推理数据、视频理解和 Agentic RL（强化学习）等六个方向，最终实现统一的多模态表征的理解和生成的统一。</p><p>「未来，AI 将从单纯的问答机器转向自主规划、主动服务的方向发展。」</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406543" alt="" title="" loading="lazy"/></p><p><strong>路少卿</strong> </p><p>商汤科技多模态交互产品负责人</p><h2>冯睿蠡：Neural Interactive Simulation as World Foundation Models</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406544" alt="" title="" loading="lazy"/></p><p>加拿大滑铁卢大学访问学者冯睿蠡认为，<strong>通往更强智能的关键在于一个「Playground」，一个低成本、实时交互的世界模型（World Foundation Model）</strong>。他以「黑客帝国」为代号，展示了如何让 AI 能在虚拟世界中不断「玩耍」和学习。当 GPT 看到一张脏桌子并制定了「把书拿走」的 Plan 后，它并不知道书底下可能还藏着油污和划痕。他指出，<strong>目前 AI 缺失的正是「在环境中检验 Policy 的能力」</strong>。</p><p>人类智能是一个迭代过程，我们需要和世界交互，环境给出反馈，我们再基于反馈做 Reason 和 Plan——这是「实践检验真理」的过程。此外，他观察到当前 AI 模型调用存在「倒挂现象」：视觉交互对人类至关重要（90% 信息是视觉信号），但 <strong>AI 模型的调用量却是文本模态远高于视觉模态</strong>。为了填补这个空白，必须给模型搭建一个「Playground」。</p><p>冯睿蠡从生物学中找到了灵感：动物为什么需要 Play（玩耍）？ 乌鸦在雪地里打滚、蜜蜂搬运圆形物体，这些看似与生存无直接利益的行为，实际上提供了一种「Simulation」（模拟），让生物<strong>在安全、廉价、可重复的环境下练习技能</strong>。基于此，他提出了理想交互模拟器的四个标准：实时反馈、足够廉价和快速、支持测试不同选择、能够覆盖对应场景。</p><p>他的「The Matrix」项目实现了四个主要目标：<strong>实时交互、立即的视觉反馈、极长的存在时间</strong>（最长测试了 10 小时交互性能不衰减），以及<strong>强大的泛化能力</strong>。模型现在能生成 15 分钟以上的长视频，且画面质量无显著衰减。它能响应用户对 Prompt 的切换（如将驾驶场景从沙漠切换到水面），并保持对键盘输入（前后左右运动）的准确响应。模型通过采用混合数据策略（游戏引擎数据与真实世界运动数据混合），模型获得了强大的泛化能力。即使训练数据中只包含白色的车，它也能生成其他颜色的车；<strong>即使训练数据中不存在，它也能让车在办公室或深水里运动</strong>。</p><p>这些成果意味着，AI 已经拥有了一个安全、廉价、高性能的神经交互模拟器来不断磨炼自己的认知和决策能力，最终可以被用于 Vtuber、电商直播或机器人控制等场景。</p><p>「只有成本降到每个人都能承受的程度，交互式世界模型才能被大规模用于推理场景，成为通往更强智能的基石。」</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406545" alt="" title="" loading="lazy"/></p><p><strong>冯睿蠡</strong></p><p>加拿大滑铁卢大学访问学者</p><h2>俞刚：大模型时代下的多模态生成和理解</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406546" alt="" title="" loading="lazy"/></p><p>阶跃星辰语音和 AIGC 算法负责人俞刚提到，过去两年大模型的参数量从 T 级狂飙到万亿级，训练数据量也像坐上了火箭，连开源和闭源模型的差距都在肉眼可见地缩小。这让他意识到，<strong>文本智能这座高山已经快被征服了</strong>。下一个战场自然是声音。语音和文本是天生的好搭档。他们的目标很明确：<strong>做一款能把所有信息都吃进去的「大胃王」</strong>。</p><p>他们推出了 Step-Audio2，一款百亿级的模型，特点是采用了连续信号输入（能保留语音中的情感和声学信号）和离散 tokenizer 输出（兼顾训练效率）。为了让这个模型「智力」和「听力」双高，他们设计了一个多达四个阶段的预训练流程，再用 SFT（指令微调）和 PPO+GRPO 的强化学习技术进行「对齐训练」。他们也同步开源了小尺寸的 7B 模型，让创业者和开发者能以更低的门槛把语音 AI 搬上自家业务。</p><p>俞刚直言，目前的 AI 世界出现了两个「流派」：</p><p>1.理解派： 侧重「思考」，如阿里的千问 Omni 系列，它<strong>能接收各种模态的输入，但通常只能输出文本或音频</strong>；</p><p>2.生成派： 侧重「创造」，比如 Veo3 或 Sora2，它们能生成炫酷的视觉内容，但 <strong>「脑子」相对简单</strong>，缺乏复杂的理解和推理能力。</p><p>为什么不能把这两种能力「深度融合」在一个模型里，做一个真正的 Any2Any 全能模型？俞刚坦诚，<strong>最大的绊脚石是 Tokenizer</strong>。目前的大模型主要依赖离散的 Tokenizer，但面对图像和视频这些二维、三维的复杂信号时，信息损失非常严重。而生成派的 Diffusion 模型则采用连续信号，信息量更大，更擅长处理全局视觉信息。</p><p>为了解决这个「硬伤」，他们通过将 AI 模型作为「思考者」和信息提取器，再把生成工作交给 Diffusion 模型。这个组合<strong>最大的价值在于让 AI 有了「反思」和「自我纠正」的能力</strong>。比如，在图片编辑时，如果第一次生成结果遗漏了猫的影子或人物的残肢，理解模型能立刻发现并进行下一轮修正，从而让成品更加完美。</p><p>俞刚总结，<strong>未来 AI 的上限仍有赖于 World Model、交互和记忆的突破，甚至需要探索自主学习的新范式</strong>，才能实现真正的飞跃。</p><p>「当模型已经充分利用现有数据，如何进一步提升模型性能？自主学习是潜在的突破方向之一。」</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406547" alt="" title="" loading="lazy"/></p><p><strong>俞刚</strong></p><p>阶跃星辰语音和 AIGC 算法负责人</p><h2>刘一聪：个人化的 HomeAI——为归属而生</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406548" alt="" title="" loading="lazy"/></p><p>和众科技 HooRii Technology Co-Founder &amp; CTO 刘一聪看来，<strong>HomeAI 的终极形态绝不应该是一个冰冷的工具，而是一位有温度的家人</strong>。</p><p>他提出的「信息论困境」点明：<strong>AI 的进化迫切需要来自物理世界的第一手原始数据，来构建「世界模型」</strong>。然而，用户对家里的 AI 兴趣寥寥，不愿高频交互，因为他们得到的是一个工具，而不是一个灵魂伴侣。这种「工具范式」导致了<strong>三个致命缺陷：空间断连、情境失忆、关系缺失</strong>。AI 记不住你何时何地做了什么，更无法主动关心你。</p><p>起因就是这个「工具循环」：体验不够好 → 没有高频交互 → 无法获取一手数据 → AI 无法进化。为了打破这一循环，HooRii 的解决方案是实现范式转移，从「工具」转向「关系」。他们推出的核心平台 HooRii Stage，被定位为连接数字智能与物理世界的关键基础设施。</p><p>那么，HooRii 是如何通过精妙的智能架构来实现「赛博家人」的养成的呢？</p><p><strong>1.连接层：</strong> 解决「空间断连」。通过 HooRii OS、ShadowLink（跨协议通信技术）和 HooRii Console，平台为 AI 提供了连接物理世界的 API。这就像给 AI 接上了「神经系统」，让它可以管理跨品牌的智能设备，真正「住进家里」；</p><p><strong>2.感知层：</strong> 解决「情境失忆」。其中的 Perceiver Agent 和 Context Agent 就像 AI 的记忆中枢，将摄像头、麦克风等上报的原始数据转化为结构化的情景知识，这个自进化记忆引擎能让 AI 越用越懂你；</p><p><strong>3.协作层：</strong> Planning Agent 负责制定执行计划。它分析当前情境，将用户的需求转化为一系列行动路径，并分配给不同的智能体。</p><p><strong>4.执行层：</strong> 负责将计划转化为具体操作。包括控制 HomeAI 智能体，直接驱动物理设备的响应和交互，实现个性化、有情感的陪伴。</p><p>他们产品的核心优势在于实现了自我迭代的闭环：当 AI 执行动作后，物理世界状态的变化会被实时捕获并反馈给感知层，更新记忆。这种持续的实时反馈，使得 HomeAI 能够自我纠正、自我学习。刘一聪强调，HomeAI 必须是个人化的，这才是 AIGC 的灵魂。无论是对 AI 角色进行「灵魂雕刻」，还是根据家庭环境进行「情景重组」，<strong>这种高度定制化才能真正构建出「归属感」</strong>。</p><p>「自进化的记忆引擎是我们 HomeAI 成为家人的关键，因为一个家人会记得你的习惯、你的喜好、你的忧伤。」</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406549" alt="" title="" loading="lazy"/></p><p><strong>刘一聪</strong></p><p>和众科技<br/> HooRii Technology Co-Founder &amp; CTO</p><h2>顾嘉唯：World as Prompt, World as Interface</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406550" alt="" title="" loading="lazy"/></p><p>灵宇宙创始人顾嘉唯作为曾在微软、百度从事 AR 和自动驾驶研究的资深创作者，他将自己 12 年前的作品——百度 Eye（一个语音对话摄像头）和今天的「小方机」进行对比，感叹大模型将当年的「不可能」变成了「可能」。他认为，这是时代赋予的机会，<strong>要为下一代孩子定义一个「不只是机，而是伴」的新型学习伙伴</strong>。</p><p>如果<strong>将空间尺度拉小、用户价值放大</strong>，通过一个第一视角设备高频使用，是否就能获取到自动驾驶最渴求的物理世界结构化数据集？这个想法的本质，是找到了物理世界 AI 最大的痛点：<strong>缺乏数据</strong>。</p><p>1.Luka 时代（读万卷书）： 这是顾嘉唯上一代创业的产品，一只可爱的大眼睛猫头鹰机器人。它解决了家庭场景的垂直痛点（如读绘本），通过摄像头识别、OCR 转 TTS 等技术，实现了「翻到哪里读到哪里」的交互。</p><p>2.小方机时代（行万里路）： 小方机利用多模态大模型的能力，让孩子的世界变得 AR 化和可交互。它是一个随身、可穿戴的 AI 伙伴，并将 Luka 积累的桌面数据扩展到了孩子一整天的世界交互行为。</p><p>顾嘉唯强调，这不是简单的功能叠加，而是要构建一个 FSD（全自动驾驶）一样的数据闭环。通过第一视角数据集，他希望能够<strong>捕捉下一代年轻人如何在物理世界中交互的完整过程，为未来具身机器人等最需要数据的领域提供最核心的资产</strong>。</p><p>顾嘉唯将自己的工作视为在践行物理世界的 AI，并尝试构建 LingOS，一套基于数据闭环的操作系统。</p><p>他坦诚这需要极强的韧性，去等待和感悟时机。他认为自己正在做的事情，就是将十年前的百度 Eye 梦想，通过今天的技术和产品落地，来构建世界模型上「非常重要的数据源」。</p><p>「具身不只是人形，本质是怎么把物理世界和虚拟世界融合。未来可能会诞生各种各样的新物种，但不变的是人类对于物理世界的感知和解决问题的能力。」</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406551" alt="" title="" loading="lazy"/></p><p><strong>顾嘉唯</strong></p><p>灵宇宙创始人</p><h2>圆桌讨论：从帮点一杯咖啡到 AGI——多模态的未来</h2><p>本次主题为「从帮点一杯咖啡到 AGI——多模态的未来」的圆桌讨论由 RTE 开发者社区的联合主理人，OpenQ 联合创始人<strong>林旅强</strong>主持，参与讨论的嘉宾还有 Agora 的 Principal Product Manager <strong>Monica Chen</strong>、拽米科技（DraMa.i）创始人<strong>何竞飞</strong>以及 Memories.ai 算法负责人<strong> Jerrick</strong>。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406552" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406553" alt="" title="" loading="lazy"/></p><p>本次圆桌首先聚焦于 AI 时代的<strong>实时互动基建</strong>。主持人抛出了第一个问题：<strong>在 AI 时代，视频作为 3D 维度的信息载体，其处理和传输的挑战是什么？机器生成内容是否更易于机器理解？</strong></p><p>Agora 的 Monica Chen 关于这个问题从底层技术进行了剖析。她指出，视频的信息量是文字和声音的几百倍，这赋予了它在图表理解等场景中不可替代的优势，但同时也使实时互动和传输成为一个共同的、难以解决的挑战。她特别提到了<strong>实时互动中的低延时、清晰度、真实度之间的平衡</strong>，认为这三者的权衡，以及上行与下行带宽、多设备适配性等问题，都<strong>是决定未来几年技术竞争的关键</strong>。</p><p>针对机器生成视频（如数字人）是否更易于机器理解的问题，Monica Chen 解释说，计算机生成的内容虽然省略了模拟到数字的转换，但它可能色彩更丰富、边缘更清晰，这些特点实际上不利于传输。但从正面看，这类内容又具有更高的对称性，更可以被拆解和分析。</p><p>她总结，<strong>Agora 的产品提供超低延时、高保真、高适配性的解决方案</strong>，确保无论是真实信息还是 AI 生成信息，信息流的顺畅都是基石。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406554" alt="" title="" loading="lazy"/></p><p>如果说底层技术保证了信息流的顺畅，那么如何在这些信息之上构建有吸引力的 AI 应用和世界？主持人将视角转向了多 Agent 驱动的娱乐体验，向拽米科技创始人何竞飞提出了第二个问题：<strong>多 Agent 世界如何从学术研究走向 C 端商业化？AI 角色「活灵活现」的核心机制是什么？</strong></p><p>何竞飞指出，其项目虽然灵感来源于「斯坦福小镇」论文中对多智能体模拟人类行为的探索，但<strong>作为一个商业 C 端产品，最核心的部分在于「模拟剧情」，而非简单的行为模拟</strong>。</p><p>他坦言，<strong>仅靠多模态系统自主运行，故事线会因为冲突点不够密集而过于平淡</strong>。为此，他分享了其创新的 Direct Agent + Multimodal System 机制。其中，Direct Agent 扮演了中心化的「导演」角色，负责主导所有剧情控制，直接向 NPC 下达精准的指令，以确保产生具有戏剧张力的核心冲突场景。而 Multimodal System 则负责填充核心章节之间的日常片段，提供 24 小时运行的陪伴感。他强调，这种模式结合俯瞰像素体和动画漫画片段，复刻了用户在现实中 <strong>「聊天-看社交媒体-再交流」的社交逻辑，是当前阶段通往世界模型的最佳商业化路径</strong>。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406555" alt="" title="" loading="lazy"/></p><p>随着 AI 应用在实时互动和虚拟世界中的成熟，AI 的长时记忆和认知能力自然成为下一个核心议题。主持人将问题转向 Memories.ai 的 Jerrick：<strong>如何构建 AI 的视频记忆，并利用 Visual RAG 改变搜索范式？我们距离 AGI 的关键缺口在哪里？</strong></p><p>Jerrick 认为，<strong>构建 AI 记忆必须同时解决「存储」和「搜索」的问题</strong>。</p><p>在存储上，他们将视频、音频、文字、OCR 视为全模态信息源，通过高效的压缩算法和基于 AI 的信息整合，构建可供自由问答的全网视频库。更关键的是搜索范式的革命：<strong>未来的搜索将不再是简单的检索，而是一个由 Agent 规划的「全模态搜索链条」</strong>。这个 Agent 将理解用户的意图，进行「分析 + 整合」，提供个性化的精准答案，使 AI 成为用户的「个人助理」。</p><p>关于 AGI 的关键缺口，Jerrick 认为，除了 AI 记忆，最关键的探索方向是<strong>空间智能或具身领域</strong>。Memories.ai 正通过 AI 硬件探索收集人类生活化场景的第一视角视频，用这些数据来训练 World Model，目标是让 AI 能够在记住信息的同时，真正地理解物理世界。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406556" alt="" title="" loading="lazy"/></p><p>在最后的总结环节，圆桌讨论走向了<strong>对 AI 价值的深度反思与对未来的有力展望</strong>，三位嘉宾以精炼的观点对圆桌内容进行了收束。</p><p>Monica Chen 再次强调了实时互动和传输的基建支撑，指出无论是真实信息还是 AI 生成信息， Agora 的产品都是<strong>实现端到端触达的坚实平台</strong>，希望借此为创业者和企业家提供更好的发展基础。</p><p>何竞飞则从产品实践中提炼出深刻的教训：在 AI 互动娱乐中，切忌过度追求 AI 性能的「本体论」，因为这往往会忽略用户的体验和感受；他强调，<strong>用户体验应该是第一位的</strong>，只有当 AI Native 能够带来更新或更好的体验时，其价值才能被有效实现。</p><p>Jerrick 则用一句简明的话概括了他们的终极目标：<strong>希望能够让 AI 「看见并且记住」，真正理解人类世界</strong>，并通过构建 Agent 系统，帮助人类更好地生活、规划，完成各种任务。</p><p>最终，主持人林旅强将个人的参与热情升华为对整个行业的呼吁。他不仅强调了 RTE 开发者社区作为技术交流平台 365 天不打烊的活力，更指出 <strong>RTE 开发者社区的愿景是成为中国能牵头的中坚力量，去改变这个世界的技术</strong>。他鼓励所有开发者和创作者，借助社区力量，将技术提炼、场景验证，并在商业上有所提升，共同将 RTE 领域推向全球技术的前沿。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406557" alt="" title="" loading="lazy"/></p><hr/><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406558" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406559" alt="" title="" loading="lazy"/></p><p><a href="https://link.segmentfault.com/?enc=l2UJG9stjSk98F7k3qfVzg%3D%3D.Db5JI%2BHQPInQ0DhuS2DR4U3l2ANx9PTIJVo7NsipPZA%3D" rel="nofollow" target="_blank">阅读更多 Voice Agent 学习笔记：了解最懂 AI 语音的头脑都在思考什么</a></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406560" alt="" title="" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[字节跳动AI大将再离职，大模型团队暗流涌]]></title>    <link>https://segmentfault.com/a/1190000047406332</link>    <guid>https://segmentfault.com/a/1190000047406332</guid>    <pubDate>2025-11-18 00:02:02</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h3>字节跳动再失核心：离职风波</h3><p>近日，据爆料，字节跳动豆包大模型视觉多模态生成方向的负责人杨建朝，正准备离开公司。这一消息如若属实，将是继2023年马维英、李磊等AI骨干相继离职后，字节大模型团队遭遇的又一次核心人才流失。<br/>截至目前，字节跳动方面尚未对此作出任何回应，但外界已开始猜测这背后可能预示的团队重组与战略调整。<br/>杨建朝的离职绝非普通人事变动。他目前主要负责豆包大模型的视觉多模态生成技术，包括文生图、视频生成等关键方向，这些都是当前AIGC领域最前沿、最具商业价值的技术领域。</p><h3>天才的轨迹：从郭沫若奖学金到视觉多模态领军</h3><p>杨建朝的学术背景堪称完美。2006年，他获得中国科学技术大学的郭沫若奖学金——这是中科大学生最高荣誉。随后，他远赴伊利诺伊大学香槟分校，师从“计算机视觉之父”Thomas Huang（黄煦涛），并于2011年获得博士学位。在读期间，他多次获得智能识别世界大赛的冠军，展现出非凡的研究实力。<br/>他的职业经历同样令人瞩目。博士毕业后，他先后在Adobe和Snapchat担任算法研究岗位，2018年加入字节跳动后，历任美国AI Lab研发总监、智能创作团队负责人，最终成为豆包大模型视觉多模态生成技术的掌舵人。<br/>这样一位顶尖人才的离去，无疑会给字节的大模型研发带来不小的影响。</p><h3>组织架构调整：权力重组下的团队未来</h3><p>就在不久前，字节跳动的大模型团队刚刚经历了一次重大的组织架构调整。2月份，原谷歌DeepMind副总裁吴永辉空降担任Seed基础研究负责人，杨建朝等5名核心骨干也从向朱文佳汇报，转为向吴永辉汇报。<br/>这一变动本身就引发了外界对字节大模型团队未来走向的诸多猜测。而爆料显示，杨建朝离开后，团队可能会由周畅接管。如果这一消息属实，那么字节跳动的大模型团队又将迎来一次新的权力重组。<br/>核心人才的频繁变动与组织架构的不断调整，反映出字节跳动在大模型领域的焦虑与不安。在AI军备竞赛日益激烈的今天，任何一家公司都难以承受如此频繁的核心人才流失。</p><h3>AI时代的人才战争：你准备好了吗？</h3><p>杨建朝的离职不是孤立事件。从马维英、李磊到如今的杨建朝，字节跳动AI骨干的相继离去，映射出整个AI行业面临的人才困境。<br/>一方面，顶尖AI人才供不应求，各大公司纷纷开出天价薪酬争夺有限的人才资源；另一方面，技术的快速迭代让从业者必须不断学习更新知识体系，否则就会面临被淘汰的风险。<br/>当下，AIGC和多模态大模型正处于爆发前夜，文生图、视频生成等技术正在重塑内容创作、娱乐、教育等众多行业。随着技术的成熟，市场对相关人才的需求呈指数级增长。<br/>据统计，AIGC相关岗位的薪资在过去一年中上涨了40%以上，但合格的人才仍然稀缺。企业不仅需要人才掌握理论知识，更要求具备实战能力和项目经验。<br/>抢占先机：AIGC大模型系列助你乘风破浪<br/>面对如此广阔的职业前景和人才缺口，如何才能快速切入这一赛道，成为企业争抢的对象？<br/>近屿智能针对这一痛点特别推出👇<br/><img width="723" height="4020" referrerpolicy="no-referrer" src="/img/bVdm4In" alt="1dc54fa27762e6598a45ad1400e91577.jpg" title="1dc54fa27762e6598a45ad1400e91577.jpg"/></p><ol><li>名师引路，量身定制<br/>名校硕博+一线大咖：清华、墨尔本大学等背景师资，懂技术更懂行业<br/>3.5个月进阶路：3大热门方向任选，零基础也能跟上的系统课程<br/>硬核技术手把手：从CUDA优化到模型微调，实操落地不脱节</li><li>实战为王，项目锤炼真本事<br/>100个智能体项目库：覆盖多行业，对接真实工作场景<br/>趣味+实用实战：AI操控机器狗、机械臂编程、AI玩具开发，边玩边学<br/>PBL模式+实习证明：学习效果可视化，求职简历添亮点</li><li>证书加持，竞争力翻倍<br/>权威证书冲刺：微软AIGC工程师、人工智能训练师双证辅导<br/>免费备考礼包：专属题库+视频教程+流程指导，考证无忧<br/>结业认证：近屿智能专属证书，行业认可度高</li><li>就业无忧，直通高薪岗位<br/>多重就业机会：5+AIGC岗位面试邀请，名企内推优先<br/>求职全流程帮扶：从简历到面试，专业指导一站式搞定</li><li>灵活学习，全程有人陪<br/>直播+录播：错过直播也能补，碎片时间高效用<br/>线上线下联动：腾讯会议授课+上海自习室督学，疑问及时解<br/>专属学管+7x24小时答疑：学习路上不孤单</li><li>超值福利，资源全解锁<br/>算力&amp;API免费送：英伟达A800算力卡+千次ChatGPT4调用额度<br/>附加学习权益：Python强化班、Stable Diffusion权限<br/>长期资源：OJAC会员+AI技术社群，持续交流成长<br/>AI世界的竞争从未如此激烈，但也从未如此充满机遇。当行业巨头为争夺顶尖人才而苦恼时，提前布局、掌握核心技能的普通人，同样可以在这场人才盛宴中分得一杯羹。<br/>在这个技术颠覆一切的时代，唯一不变的就是变化本身。与其被动观望，不如主动学习，抓住AIGC带来的历史性机遇。</li></ol>]]></description></item><item>    <title><![CDATA[从SRS项目看现代C++最佳实践：高性能]]></title>    <link>https://segmentfault.com/a/1190000047406369</link>    <guid>https://segmentfault.com/a/1190000047406369</guid>    <pubDate>2025-11-18 00:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>从SRS项目看现代C++最佳实践：高性能实时流媒体服务器的设计智慧</h2><p><img width="723" height="393" referrerpolicy="no-referrer" src="/img/bVdm4IX" alt="68747470733a2f2f6f737372732e6e65742f77696b692f696d616765732f5352532d53696e676c654e6f64652d342e302d73642e706e673f763d313134.png" title="68747470733a2f2f6f737372732e6e65742f77696b692f696d616765732f5352532d53696e676c654e6f64652d342e302d73642e706e673f763d313134.png"/></p><h3>前言</h3><p>SRS (Simple Realtime Server) 是一个高性能的实时视频服务器，支持RTMP、WebRTC、HLS、HTTP-FLV、SRT等多种协议。作为一个拥有200万行代码、在生产环境广泛应用的开源项目，SRS展现了许多值得学习的现代C++设计思路和最佳实践。本文将深入解析SRS项目的C++代码架构，探索其在高性能、高并发场景下的设计智慧。</p><h3>项目背景：为什么SRS值得研究？</h3><h4>技术规模与影响力</h4><ul><li><strong>代码规模</strong>: 超过200万行C++代码，6000+源文件</li><li><strong>协议支持</strong>: RTMP/WebRTC/HLS/HTTP-FLV/SRT/MPEG-DASH/GB28181</li><li><strong>平台兼容</strong>: Linux/macOS/Windows，支持X86_64/ARMv7/AARCH64/M1/RISCV等架构</li><li><strong>编解码</strong>: H.264/H.265/AV1/VP9/AAC/Opus/G.711</li><li><strong>生产应用</strong>: 被众多公司用于构建直播和实时通信平台</li></ul><h4>技术挑战</h4><p>流媒体服务器面临的核心技术挑战包括：</p><ul><li><strong>低延迟要求</strong>: 毫秒级别的延迟控制</li><li><strong>高并发处理</strong>: 同时处理数万路流</li><li><strong>内存管理</strong>: 大量音视频数据的高效处理</li><li><strong>协议复杂性</strong>: 多种协议的状态机管理</li><li><strong>稳定性要求</strong>: 7x24小时稳定运行</li></ul><p>这些挑战促使SRS采用了许多精巧的C++设计模式和实践。</p><h3>现代C++特性的保守与务实使用</h3><h4>C++11标准的选择</h4><p>SRS项目选择C++11作为基础标准，这在看似保守的选择背后体现了工程项目的务实考量：</p><pre><code class="cpp">// trunk/auto/utest.sh:24
SRS_CPP_VERSION="-std=c++11"</code></pre><p><strong>为什么选择C++11而非更新标准？</strong></p><ol><li><strong>兼容性考虑</strong>: 确保在各种老旧系统上的编译兼容性</li><li><strong>稳定性优先</strong>: C++11已经足够成熟，避免新标准的潜在bug</li><li><strong>性能敏感</strong>: 避免新特性带来的性能开销</li><li><strong>团队协作</strong>: 降低团队成员的学习成本</li></ol><h4>智能指针的自定义实现</h4><p>SRS没有直接使用<code>std::unique_ptr</code>，而是实现了自己的智能指针系统，这展现了高性能项目的典型做法：</p><pre><code class="cpp">// trunk/src/core/srs_core_autofree.hpp:32-89
template &lt;class T&gt;
class SrsUniquePtr
{
private:
    T *ptr_;
    void (*deleter_)(T *);

public:
    SrsUniquePtr(T *ptr = NULL, void (*deleter)(T *) = NULL)
    {
        ptr_ = ptr;
        deleter_ = deleter;
    }

    virtual ~SrsUniquePtr()
    {
        if (!deleter_) {
            delete ptr_;
        } else {
            deleter_(ptr_);
        }
    }

    // C++11 move semantics support
#if __cplusplus &gt;= 201103L
    SrsUniquePtr(SrsUniquePtr&lt;T&gt; &amp;&amp;other);
    SrsUniquePtr&lt;T&gt; &amp;operator=(SrsUniquePtr&lt;T&gt; &amp;&amp;other);
#endif
};</code></pre><p><strong>自定义智能指针的优势：</strong></p><ol><li><strong>自定义删除器</strong>: 支持malloc/free、特殊释放函数</li><li><strong>性能优化</strong>: 避免标准库的额外开销</li><li><strong>调试友好</strong>: 可添加自定义调试信息</li><li><strong>向后兼容</strong>: 支持C++11之前的编译器</li></ol><h4>模板的精确使用</h4><p>SRS在模板使用上非常克制，主要用于工具类和类型安全：</p><pre><code class="cpp">// trunk/src/kernel/srs_kernel_mp4.hpp:3027-3047
template &lt;typename T&gt;
std::stringstream &amp;srs_dumps_array(std::vector&lt;T&gt; &amp;arr, std::stringstream &amp;ss,
                                   SrsMp4DumpContext dc,
                                   void (*pfn)(T &amp;, std::stringstream &amp;, SrsMp4DumpContext),
                                   void (*delimiter)(std::stringstream &amp;, SrsMp4DumpContext))
{
    for (int i = 0; i &lt; (int)arr.size(); i++) {
        if (i &gt; 0 &amp;&amp; delimiter) {
            delimiter(ss, dc);
        }
        if (pfn) {
            pfn(arr[i], ss, dc);
        }
    }
    return ss;
}</code></pre><p><strong>模板使用原则：</strong></p><ul><li>仅在必要时使用模板，避免过度抽象</li><li>优先考虑代码可读性和编译速度</li><li>模板主要用于类型安全和代码复用</li></ul><h3>内存管理的艺术</h3><h4>RAII模式的彻底贯彻</h4><p>SRS通过RAII模式确保资源的安全释放：</p><pre><code class="cpp">// trunk/src/core/srs_core.hpp:57-65
#define srs_freep(p) \
    delete p;        \
    p = NULL;        \
    (void)0

#define srs_freepa(pa) \
    delete[] pa;       \
    pa = NULL;         \
    (void)0</code></pre><h4>资源管理器模式</h4><pre><code class="cpp">// trunk/src/kernel/srs_kernel_resource.hpp:215-249
template &lt;typename T&gt;
class SrsSharedResource : public ISrsResource
{
private:
    SrsSharedPtr&lt;T&gt; ptr_;
public:
    SrsSharedResource(T *ptr = NULL) : ptr_(ptr) {}
    virtual ~SrsSharedResource() {}

    T *operator-&gt;() { return ptr_.operator-&gt;(); }
    T *get() { return ptr_.get(); }
};</code></pre><p><strong>内存管理最佳实践：</strong></p><ol><li><strong>统一的资源管理</strong>: 所有资源都通过RAII管理</li><li><strong>自定义智能指针</strong>: 满足特定需求的智能指针实现</li><li><strong>明确的所有权语义</strong>: 通过类型系统表达资源所有权</li></ol><h3>错误处理的工程化实践</h3><h4>分层错误系统</h4><p>SRS实现了一个强大的分层错误处理系统：</p><pre><code class="cpp">// trunk/src/kernel/srs_kernel_error.hpp:437-481
class SrsCplxError
{
private:
    int code_;
    SrsCplxError *wrapped_;
    std::string msg_;
    std::string func_;
    std::string file_;
    int line_;
    SrsContextId cid_;
    int rerrno_;

public:
    // 错误链构建
    SrsCplxError *wrap(const std::string &amp;msg);
    SrsCplxError *transform(int code);

    // 错误信息提取
    std::string description() const;
    int error_code() const { return code_; }
};</code></pre><h4>错误分类体系</h4><p>SRS按功能模块对错误进行分类：</p><pre><code class="cpp">// 系统错误 (1000-1099)
#define ERROR_SOCKET_CREATE 1000
#define ERROR_SOCKET_BIND   1002
#define ERROR_SOCKET_LISTEN 1003

// RTMP协议错误 (2000-2999)
#define ERROR_RTMP_HANDSHAKE 2000
#define ERROR_RTMP_PACKET_SIZE 2001

// 应用错误 (3000-3999)
#define ERROR_HLS_DECODE_ERROR 3000
#define ERROR_DVR_CANNOT_OPEN 3001</code></pre><p><strong>错误处理最佳实践：</strong></p><ol><li><strong>分层错误链</strong>: 错误可以被包装和传递，保持调用栈信息</li><li><strong>上下文信息</strong>: 每个错误包含完整的调试信息</li><li><strong>分类管理</strong>: 按模块和严重级别分类错误代码</li><li><strong>性能考虑</strong>: 错误对象的创建和销毁要高效</li></ol><h3>并发编程的创新方案</h3><h4>State Threads协程库</h4><p>SRS没有使用标准的pthread或C++11线程，而是选择了State Threads库：</p><pre><code class="cpp">// trunk/src/protocol/srs_protocol_st.hpp:22-26
typedef void *srs_netfd_t;
typedef void *srs_thread_t;
typedef void *srs_cond_t;
typedef void *srs_mutex_t;</code></pre><h4>协程化的网络IO</h4><pre><code class="cpp">// 协程式的网络读写
srs_error_t SrsStSocket::read(void *buf, size_t size, ssize_t *nread)
{
    *nread = st_read(stfd_, buf, size, ST_UTIME_NO_TIMEOUT);
    if (*nread &lt;= 0) {
        return srs_error_new(ERROR_SOCKET_READ, "st_read failed");
    }
    return srs_success;
}</code></pre><h4>线程安全的锁机制</h4><pre><code class="cpp">// trunk/src/protocol/srs_protocol_st.hpp:152-174
#define SrsLocker(instance) \
    impl__SrsLocker _SRS_free_instance(instance)

class impl__SrsLocker
{
private:
    srs_mutex_t *lock_;
public:
    impl__SrsLocker(srs_mutex_t *l) {
        lock_ = l;
        srs_mutex_lock(*lock_);
    }
    virtual ~impl__SrsLocker() {
        srs_mutex_unlock(*lock_);
    }
};</code></pre><p><strong>并发编程最佳实践：</strong></p><ol><li><strong>协程优于线程</strong>: 在IO密集型场景下，协程提供更好的性能</li><li><strong>RAII锁管理</strong>: 通过RAII确保锁的正确释放</li><li><strong>事件驱动架构</strong>: 基于事件循环的高效并发模型</li></ol><h3>类型安全与接口设计</h3><h4>前向声明的大量使用</h4><pre><code class="cpp">// trunk/src/app/srs_app_server.hpp:27-73
class SrsAsyncCallWorker;
class SrsUdpMuxListener;
class SrsRtcConnection;
class ISrsAsyncCallTask;
class SrsSignalManager;
// ... 更多前向声明</code></pre><p><strong>前向声明的价值：</strong></p><ol><li><strong>编译速度</strong>: 减少头文件依赖，提升编译速度</li><li><strong>解耦合</strong>: 降低模块间的耦合度</li><li><strong>循环依赖</strong>: 解决头文件的循环依赖问题</li></ol><h4>接口抽象的使用</h4><p>SRS大量使用抽象接口来实现多态和解耦：</p><pre><code class="cpp">class ISrsSignalHandler
{
public:
    virtual ~ISrsSignalHandler() {}
    virtual srs_error_t on_signal(int signo) = 0;
};

class ISrsResourceManager
{
public:
    virtual ~ISrsResourceManager() {}
    virtual void subscribe(ISrsResource* c) = 0;
    virtual void unsubscribe(ISrsResource* c) = 0;
};</code></pre><h3>条件编译与平台适配</h3><h4>测试友好的设计</h4><pre><code class="cpp">// trunk/src/core/srs_core.hpp:16-25
#ifdef SRS_FORCE_PUBLIC4UTEST
#define SRS_DECLARE_PRIVATE public
#define SRS_DECLARE_PROTECTED public
#else
#define SRS_DECLARE_PRIVATE private
#define SRS_DECLARE_PROTECTED protected
#endif</code></pre><p>这个设计让所有私有成员在测试模式下变为public，极大地便利了单元测试。</p><h4>平台兼容性检查</h4><pre><code class="cpp">// trunk/src/core/srs_core.hpp:67-70
#if !defined(__amd64__) &amp;&amp; !defined(__x86_64__) &amp;&amp; !defined(__i386__) &amp;&amp; \
    !defined(__arm__) &amp;&amp; !defined(__aarch64__) &amp;&amp; !defined(__mips__) &amp;&amp; \
    !defined(__mips64) &amp;&amp; !defined(__loongarch64) &amp;&amp; !defined(__riscv)
#error "Only support i386/amd64/x86_64/arm/aarch64/mips/mips64/loongarch64/riscv cpu"
#endif</code></pre><h3>性能优化的细节考量</h3><h4>内存池和对象复用</h4><p>SRS在关键路径上大量使用对象池和内存池技术：</p><pre><code class="cpp">// 包对象的复用管理
class SrsPacketManager
{
private:
    std::vector&lt;SrsRtpPacket*&gt; free_packets_;

public:
    SrsRtpPacket* acquire_packet() {
        if (!free_packets_.empty()) {
            SrsRtpPacket* pkt = free_packets_.back();
            free_packets_.pop_back();
            return pkt;
        }
        return new SrsRtpPacket();
    }

    void release_packet(SrsRtpPacket* pkt) {
        pkt-&gt;reset();
        free_packets_.push_back(pkt);
    }
};</code></pre><h4>零拷贝技术</h4><p>在媒体数据处理中，SRS尽可能避免不必要的内存拷贝：</p><pre><code class="cpp">class SrsBuffer
{
private:
    char* data_;
    int size_;
    int pos_;

public:
    // 返回当前位置的指针，避免拷贝
    char* current() { return data_ + pos_; }

    // 直接在缓冲区上操作
    void skip(int size) { pos_ += size; }
};</code></pre><h3>现代C++特性的取舍思考</h3><h4>为什么不用更新的C++标准？</h4><ol><li><strong>兼容性至上</strong>: 流媒体服务器需要在各种环境中部署</li><li><strong>性能第一</strong>: 避免新特性可能带来的性能开销</li><li><strong>稳定性考虑</strong>: 生产环境优先选择成熟稳定的技术</li><li><strong>团队效率</strong>: 降低学习成本，提高开发效率</li></ol><h4>哪些现代特性值得采用？</h4><p><strong>建议采用的特性：</strong></p><ul><li><code>auto</code>关键字：提高代码可读性</li><li>Lambda表达式：简化回调和算法</li><li>智能指针：改善内存管理</li><li>右值引用：优化性能关键路径</li><li><code>constexpr</code>：编译时计算</li></ul><p><strong>需要谨慎的特性：</strong></p><ul><li>复杂模板：可能影响编译速度和调试</li><li>异常：在高性能场景下开销较大</li><li>标准库算法：不一定比手写代码更高效</li><li>新的并发库：可能不如专门的高性能库</li></ul><h3>总结：工程实践的智慧</h3><p>SRS项目展现了现代C++在大型工程项目中的最佳实践：</p><h4>设计原则</h4><ol><li><strong>性能优先</strong>: 所有设计决策都以性能为首要考量</li><li><strong>稳定可靠</strong>: 优先选择成熟稳定的技术方案</li><li><strong>可维护性</strong>: 代码结构清晰，便于长期维护</li><li><strong>可测试性</strong>: 设计时考虑测试的便利性</li></ol><h4>技术选择</h4><ol><li><strong>保守的标准选择</strong>: C++11提供了足够的现代特性</li><li><strong>自定义核心组件</strong>: 针对性能需求定制关键组件</li><li><strong>接口驱动设计</strong>: 通过抽象接口实现模块解耦</li><li><strong>RAII贯彻始终</strong>: 确保资源管理的安全性</li></ol><h4>工程化思维</h4><ol><li><strong>分层架构</strong>: 清晰的模块分层和职责划分</li><li><strong>错误处理</strong>: 完善的错误分类和处理机制</li><li><strong>平台兼容</strong>: 考虑多平台部署的兼容性</li><li><strong>性能调优</strong>: 在关键路径上进行精细优化</li></ol><p>SRS项目证明了现代C++不一定要追求最新的语言特性，而是要根据项目特点选择合适的技术栈。在高性能、高可靠性要求的系统中，工程化的设计思维比语言特性的新颖性更为重要。</p><p>对于其他C++项目，SRS的经验告诉我们：</p><ul><li><strong>根据需求选择技术</strong>：不是越新越好，而是越合适越好</li><li><strong>性能与可维护性平衡</strong>：在性能要求和代码可维护性之间找到平衡</li><li><strong>工程化思维</strong>：把代码当作工程来设计，考虑长期维护和团队协作</li><li><strong>渐进式演进</strong>：在稳定的基础上渐进式地引入新技术</li></ul><p>这些实践经验对于开发高质量的C++项目具有重要的指导意义。</p><p>本文基于SRS 6.0版本代码分析，SRS是一个持续演进的开源项目，代码地址：<a href="https://link.segmentfault.com/?enc=IGOAHkr3W1H5RIoSqq6Dmg%3D%3D.hW04jUdH2RHPksLMW89HzMqbWt5cUBhM3fDi7ULMOKo%3D" rel="nofollow" target="_blank">https://github.com/ossrs/srs</a></p>]]></description></item><item>    <title><![CDATA[cpp c++面经分享 cpp辅导的阿甘]]></title>    <link>https://segmentfault.com/a/1190000047406271</link>    <guid>https://segmentfault.com/a/1190000047406271</guid>    <pubDate>2025-11-17 23:04:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>前言</h2><p>大家好，我是阿甘，“奔跑中cpp / c++”，知识星球的创始人</p><p>今天给大家分享分享，我们星球同学一起整理的，同时也在不断更新的，cpp / c++相关岗位面经。</p><p>全网最全收集</p><h2>面经分享</h2><p>因面经过多，今天只分享部分，后续有时间继续分享（让大家学习/ 面试形成一个参考）<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047406273" alt="" title=""/></p><h3>字节客户端一面</h3><ol><li>C++智能指针有哪些，都是为了解决什么问题？</li><li>虚函数是什么，如何实现虚函数？</li><li>如何用栈实现一个队列？</li><li>TCP的流量控制，拥塞控制</li><li>主从reactor是什么，数据是怎么传输的？</li><li>(以下都是网络检测项目)项目的背景是什么，为什么要做这样一个项目？有没有应用到实际中？</li><li>ai的具体作用是什么，会不会负载很大？</li><li>传入ai的是什么？有多大？会不会在运行上有一个后置性，为什么不在前置设置一个阈值，超出阈值的输出给ai？</li><li>如何进行网络好坏的判断？这些指标是在现如今工作中的统一标准还是什么？</li><li>算法手撕</li></ol><h3>oppo多媒体开发</h3><p>一面:</p><p>1.无手撕，直接拷打项目，挑一个最熟悉的项目介绍</p><p>2.线程池和内存池用来干什么，怎么实现的</p><p>3.性能调优具体怎么做的</p><p>4.有没遇到过内存泄露，具体场景</p><p>5.tcp和udp区别，具体实现</p><p>6.数据结构相关，map,set,unordered_map底层实现，vector和list区别</p><p>7.(开始进入智能云存储项目)ai检索具体怎么做的，用api的话工作量在哪</p><p>8.遇到的困难，怎么解决的/遇到过那些比较棘手的debug情况/介绍下怎么快速上手项目的</p><p>二面:</p><p>1.同样是先介绍项目，无手撕</p><p>2.进程间通信和线程同步</p><p>3.追着本人的项目一直问到具体遇到过哪些debug场景以及最后如何解决的，但没涉及到具体的八股</p><p>4.分布式架构如何实现的</p><p>5.采用gpu处理信号的时候考虑过gpu到cpu通信的耗时吗？为什么最终还是选择gpu(本人的实验室项目)</p><p>6.性能怎么测的？以及再次问了线程池和内存池</p><p>7.lamda以及移动语义用没用过等</p><p>8.对oppo有哪些了解</p><p>三面(hr面):<br/>大概问了下优点缺点，意向地怎么考虑的，对oppo的认识，对于未来工作环境的想法等等，纯聊天局。</p><p>总结:全程无手撕，建议笔试好好做(本人笔试水过去被问真不知道笔试成绩比较低)，问项目感觉更多是在看有没有真实的做过一些东西，以及对项目的整体把控。timeline基本是一周一推进。</p><h3>米哈游一面</h3><p>1、自我介绍</p><p>2、为什么投递这个客户端工具岗位</p><p>3、指针和引用的区别（概念、使用场景）</p><p>4、是否存在指针数组和引用数组</p><p>5、野指针</p><p>6、内存泄漏</p><p>7、new和malloc的区别</p><p>8、new和malloc怎么判断分配内存失败了？</p><p>9、智能指针</p><p>10、引用计数保存在内存哪个部分</p><p>11、介绍下C++内存分布</p><p>12、静态区、堆和栈什么时候确定大小？</p><p>13、堆和栈的区别</p><p>14、为什么栈的分配效率更高？</p><p>15、堆和栈的安全性</p><p>16、static关键字</p><p>17、静态全局变量和全局变量</p><p>18、静态局部变量和局部变量</p><p>19、静态成员变量和静态成员函数</p><p>20、手撕：用数组实现一个可以扩容的栈，不能用vector</p><p>21、map的底层</p><p>22、二叉搜索树、二叉平衡树、红黑树</p><p>23、熟悉的设计模式</p><p>24、单例模式</p><p>25、简单工厂、工厂方法、抽象工厂</p><h3>海康</h3><p>1、云存储项目：</p><p>介绍文件秒传逻辑</p><p>介绍大文件分片上传逻辑</p><p>分片文件上传到后端在合并前存储在哪里</p><p>有没有考虑以分片形式存储到fastdfs中</p><p>fastdfs的原理展开说下</p><p>ai搜索展开讲下</p><p>2、弱网项目：</p><p>介绍下ICMP协议实现方式</p><p>介绍eBPF怎么用的</p><p>项目的难点是什么</p><p>3、拷贝构造函数在那些场景下调用</p><p>4、静态成员函数与普通成员函数的差别是什么</p><p>5、追问为什么this不能调用静态成员函数，底层原理是什么</p><p>6、了解什么设计模式</p><p>7、讲下你在项目中怎么实现一个具体单例模式的</p><p>8、项目有没有用过线程池？怎么设置的</p><p>9、条件变量怎么使用的？为什么要配合锁使用？</p><p>10、写没写过网络库</p><p>11、Reactor要怎么实现</p><h2>知识星球介绍（公认的cpp c++学习地）</h2><p>星球名字：奔跑中的cpp / c++</p><p>里面服务也不会变，四个坚守目前:</p><p>1.每天都会看大家打卡内容，给出合理性建议。</p><p>2.大家如果需要简历指导，心里迷茫需要疏导都可以进行预约周六一对一辅导。</p><p>3.每周五晚上九点答疑聊天不会变。</p><p>4.进去星球了，后续如果有什么其他活动，服务，不收费不收费(可以合理赚钱就收取下星球费用，但是不割韭菜，保持初心)</p><p>（还有经历时间考验的独家私密资料）</p><p>加入星球的同学都可以提问预约，一对一帮做简历，一对一  职业规划辅导    ，解惑。同时有高质量的项目以及学习资料</p><p>本文由<a href="https://link.segmentfault.com/?enc=3%2FuOxIgWRHM6kLPpo5ASkw%3D%3D.tvpVe3U2zzUMArqNH5UD9R3zk8oQZdM5V2Tsv1Ewmio%3D" rel="nofollow" target="_blank">mdnice</a>多平台发布</p>]]></description></item><item>    <title><![CDATA[《Unity渲染实战宝典：突破平台限制的]]></title>    <link>https://segmentfault.com/a/1190000047406281</link>    <guid>https://segmentfault.com/a/1190000047406281</guid>    <pubDate>2025-11-17 23:03:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>许多开发者初期极易陷入“参数拉满即优质”的认知误区，盲目调高光照强度、堆叠后处理效果、复用高面数模型，却忽略了不同平台（移动端、PC端、主机端）的硬件架构本质差异—移动端GPU的ALU数量通常仅为PC端的1/5至1/3，显存带宽也存在数倍差距，而主机端则具备专属的光线追踪加速单元。这种硬件差异直接导致相同渲染配置在不同设备上表现天差地别，最终出现真机测试时帧率断崖式下跌、设备异常发热、画面元素穿帮（如阴影断裂、材质闪烁）等问题。真正成熟的渲染优化，是对渲染管线每一个环节的深度解构与灵活重组，是在有限资源边界内实现视觉体验最大化的艺术。以复杂场景光照处理为例，既不能为了追求照片级真实感而无限制增加实时光源—移动端设备通常难以承载超过4个实时光源的同时计算，过多光源会直接导致GPU算力过载，甚至触发设备的 thermal throttling（热节流）机制；也不能为了单纯节省性能而过度简化光照层次，否则会让画面显得扁平乏味，失去沉浸感。此时需要结合场景类型与动态物体占比精准决策：动态物体占比高的动作游戏，可采用“少量实时光源（主角2个+关键交互道具1个）+光照探针”的组合，保证角色与核心道具的光影实时反馈，同时通过环境光反射贴图模拟周围环境的光影影响；静态场景为主的解谜游戏，则可通过光照烘焙生成Lightmap，将烘焙分辨率设置为每米512像素以保证细节，再搭配2次间接光反弹模拟自然光影过渡，甚至通过材质的反光系数调整（如墙面反光系数0.1、金属道具0.8）与环境光探针的合理布局，让玩家在视觉上感知到超出硬件实际支持的光影层次。这种“感知优化”远比单纯的参数堆砌更具性价比，也是资深开发者与新手的核心差距所在。</p><p>材质系统作为渲染的基础载体，其优化细节直接决定游戏的运行效率与画面一致性，却最容易被开发者忽视。很多人习惯直接使用Unity默认Shader或网络下载的复杂Shader模板，却未意识到每一个冗余的Shader变体都会成为性能负担—Shader变体过多会导致游戏加载阶段的Shader编译时间大幅延长，移动端设备可能出现3-5秒的启动卡顿，而在部分低端机型上，甚至会出现Shader编译失败导致的画面粉红错误。更严重的是，冗余变体还会占用额外内存，一款中型游戏的Shader变体若未做裁剪，可能占用数十MB内存，这对于仅配备2GB显存的移动端设备来说，无疑是雪上加霜。在实际开发中，Shader的精准裁剪是核心优化动作：需借助Unity的Shader Variant Collection工具，分析游戏运行过程中实际调用的变体，剔除所有无用功能模块，比如2D游戏无需保留3D Shader中的法线贴图计算、视差映射模块，远景物体可移除Shader中的高光反射、细节纹理采样、自发光等逻辑，仅保留基础颜色渲染功能，将Shader指令数控制在100条以内。材质的复用与共享同样关键，对于外观相似仅颜色或纹理不同的物体（如批量生成的敌人、重复的场景装饰、道具库中的同类物品），应通过材质实例化（Material Instantiate）功能修改主纹理或颜色参数，而非创建多个独立材质，这样能有效减少DrawCall的无效增长—DrawCall的增加会直接加重CPU的调度负担，当DrawCall超过2000时，多数移动端设备的CPU会成为性能瓶颈，帧率可能从60帧骤降至30帧以下。此外，渲染队列的设置直接影响画面渲染顺序与OverDraw（过度绘制）压力，错误的队列配置可能引发严重问题：将透明物体设置在不透明队列（Opaque）会导致遮挡关系错乱，出现“透明物体被不透明物体穿透”的视觉bug；而将半透明物体放在透明队列（Transparent）前端，则会导致后续物体重复渲染，OverDraw占比可能飙升至300%以上，造成GPU像素填充率过载。正确的做法是根据物体的透明属性与场景层级分级配置：不透明物体放在“Opaque”队列（优先级2000），半透明物体放在“Transparent”队列（优先级3000），粒子特效、UI等需要叠加的元素放在“Overlay”队列（优先级4000），同时通过调整队列偏移值，确保关键视觉元素（如主角、任务道具）优先渲染，避免被次要物体遮挡。借助Unity的Frame Debugger工具，可实时查看OverDraw热点区域，针对占比超过200%的区域优化渲染队列，往往能快速提升帧率。</p><p>光照与阴影是塑造画面质感的核心，也是渲染优化中最具挑战性的环节，其优化的关键在于“分层适配”与“视觉欺骗”的深度结合。很多开发者盲目追求高阴影分辨率，认为分辨率越高画面越真实，却忽视了阴影计算对GPU的巨大消耗—阴影本质是通过深度纹理采样实现的，分辨率每提升一倍，GPU的计算量会增加四倍。在动态物体较多的开放世界场景中，若将阴影分辨率设置为2048以上，会导致GPU的像素填充率瞬间饱和，帧率可能从60帧骤降至30帧以下，尤其在移动端设备上，还会伴随严重的发热问题。真正高效的阴影策略，是根据物体的视觉权重与玩家距离进行分层处理：主角、关键道具等近距离交互元素，可将阴影分辨率设置为1024，阴影距离调整至50米，同时开启软阴影（Soft Shadows）增强立体感；中距离的NPC、场景互动物体，阴影分辨率降至512，阴影距离缩短至30米；远景的建筑、植被等非核心元素，可将阴影分辨率降至256或直接关闭实时光影，通过Lightmap烘焙预留阴影痕迹，或使用“软阴影贴图”（Fake Shadow）模拟阴影效果，既节省性能又不破坏画面整体性。间接光照的调整同样需要精准把控，过多的间接光反弹（超过3次）会导致画面过亮、色彩失真，且烘焙时间可能从半小时延长至数小时，占用大量开发时间；而反弹次数过少（少于1次）则会让场景显得灰暗、缺乏层次感，物体之间的光影过渡生硬，影响沉浸感。在实际调试中，需结合场景封闭程度与材质反光属性灵活调整：室内场景空间狭小、材质（如瓷砖、金属）反光较强，间接光反弹2次即可避免过曝，同时将间接光强度衰减系数设置为0.8，让光线过渡更自然；室外开阔场景光线充足，材质（如泥土、布料）反光较弱，可将反弹次数提升至3次，间接光强度衰减系数设置为0.6，模拟阳光照射下的环境反光。光照探针的布局则需遵循“疏密有致”原则，在光照变化剧烈的区域（如门窗边缘、转角、树荫下），将探针间距设置为2-3米，确保动态物体进入该区域时能精准接收光影变化；而在光照均匀的开阔区域（如草原、广场），探针间距可扩大至5-8米，避免探针过多导致的内存浪费与烘焙效率下降。对于大型开放世界场景，还可使用Probe Volume替代传统光照探针，通过体积化的探针分布，实现更细腻的光影过渡，同时支持动态加载与卸载，减少内存占用。此外，阴影的“距离缩放”功能也值得运用，根据玩家视角距离自动调整阴影范围，当玩家远距离移动时，逐步缩小阴影距离，近距离时则扩大，在不影响视觉体验的前提下进一步节省性能。</p><p>后处理效果是画面的“点睛之笔”，但过度使用会成为性能的“枷锁”，尤其在移动端等硬件资源有限的平台，后处理的不合理配置往往是帧率下跌的主要诱因。很多开发者在开发初期会一股脑开启抗锯齿、景深、体积雾、颜色校正、光晕、镜头畸变等所有后处理效果，却未意识到这些效果叠加后对GPU的负载—以移动端为例，同时开启4种以上后处理效果，GPU的渲染耗时可能从10ms增加至25ms，帧率直接跌破30帧，而部分老旧设备甚至会因GPU算力不足出现画面卡顿、掉帧。高效的后处理策略核心是“取舍与分级”，需结合游戏类型、美术风格与目标平台性能精准配置：动作类游戏需优先保证画面流畅度与清晰度，可保留抗锯齿（推荐FXAA或TAA，避免使用MSAA，后者对移动端GPU压力过大）与颜色校正（调整Gamma值、对比度），关闭景深、体积雾等非核心效果，避免画面模糊影响操作精准度；叙事类或解谜类游戏更注重氛围营造，可保留景深（降低采样率至24，影响范围限制在10-30米）与体积雾（减少密度至0.1，影响范围50米），关闭镜头畸变、光晕等冗余效果，既保证焦点突出，又控制性能消耗。不同抗锯齿方案的性能差异也需重点关注：FXAA算法简单，性能消耗最低，但边缘模糊度较高；TAA抗锯齿效果更细腻，适合3D游戏，但需要额外的帧缓冲存储，内存占用略高；MSAA抗锯齿效果最佳，但仅支持前向渲染，且对移动端GPU压力极大，仅建议在PC或主机平台使用。后处理的执行顺序同样影响渲染效率，合理的顺序应遵循“先基础优化，后效果叠加”原则：首先进行抗锯齿处理，解决画面锯齿问题；其次进行阴影修复（如Contact Shadows），弥补实时光影的细节缺失，让物体与地面的接触阴影更自然；再进行颜色校正、对比度调整，统一画面色调，增强视觉冲击力；最后叠加景深、体积雾等氛围效果，避免重复计算导致的性能浪费。此外，后处理的“分级加载”机制能进一步提升适配性，通过检测设备的GPU型号与内存大小，自动调整后处理等级：高端设备开启全量效果，中端设备关闭部分高消耗效果，低端设备仅保留抗锯齿与颜色校正。后处理的分辨率缩放功能也值得重点运用，在低配置设备上，可将后处理渲染分辨率设置为屏幕分辨率的0.7-0.8倍，以微小的画质损失换取15%-20%的帧率提升；在高端设备上则可全开分辨率，甚至开启超采样（1.2倍）提升画面细腻度。同时，后处理的“距离剔除”设置能减少无效计算，比如体积雾仅在50米范围内生效，景深仅对10-30米区间的物体起作用，避免对远处无关物体进行不必要的效果处理。</p><p>纹理资源的优化是渲染性能提升的“隐形抓手”，其核心逻辑是“适配需求、精简冗余”，在保证视觉效果的前提下，最大限度降低内存占用与GPU带宽消耗。很多开发者在制作纹理时存在“分辨率越高越好”的误区，比如将UI图标分辨率设置为1024x1024，将地面纹理设置为4096x4096，却未意识到纹理分辨率每提升一倍，内存占用会增加四倍—一张4096x4096的RGBA32格式纹理，内存占用高达64MB，而移动端游戏的纹理总内存通常建议控制在512MB以内，过多高分辨率纹理会直接引发内存溢出（OOM）或加载卡顿，尤其在切换场景时，可能出现黑屏等待。纹理分辨率的选择需严格适配显示需求：UI图标、按钮等近距离查看的元素，分辨率设置为256x256或512x512即可满足清晰需求，无需超过屏幕分辨率的两倍（如手机屏幕分辨率为1080x1920，UI纹理最大设置为1024x1024即可）；场景中的地面、墙面等大面积纹理，可根据实际显示尺寸设置为1024x1024或2048x2048，通过纹理平铺（Tiling）与Mipmap技术保证远处显示的清晰度，比如地面纹理平铺值设置为4x4，可覆盖更大面积且不损失细节；远景的山体、天空盒等元素，分辨率甚至可降低至512x512，肉眼几乎无法察觉画质损失，却能节省大量内存。纹理压缩格式的选择则需结合目标平台与纹理类型：Android平台优先使用ETC2格式，该格式支持透明通道，且在Android 4.4以上版本全面兼容，能将纹理内存占用减少75%，对于无透明通道的纹理，可使用ETC1格式进一步提升压缩效率；iOS平台适合使用PVRTC格式，压缩效率更高，且对苹果设备的GPU兼容性更佳，支持1bit和4bit压缩模式；PC与主机平台可使用BC格式（如BC3支持透明、BC5适用于法线贴图），在保证画质的同时降低带宽消耗。透明纹理的压缩需格外注意，避免因压缩格式选择不当导致边缘模糊或颜色失真，比如移动端透明UI纹理建议使用ETC2 Alpha格式，而非RGBA32格式。Mipmap的设置需灵活调整：UI纹理、小图标等无需远距离显示的资源，可关闭Mipmap以节省内存（关闭后可减少约33%的内存占用）；场景纹理、模型纹理等需要远距离显示的资源，应开启Mipmap，并将Mipmap层级设置为3-4级，避免远处纹理出现锯齿或模糊，同时Mipmap还能减少GPU在采样远处纹理时的带宽消耗。此外，纹理图集的打包是减少DrawCall的有效手段，将同一场景、同一材质的纹理（如角色的服装、武器纹理，场景中的道具、装饰纹理）打包成一个图集，可避免频繁切换纹理导致的GPU开销，提升渲染效率。打包时需注意：图集尺寸不宜超过2048x2048像素（部分低端设备不支持超过4096x4096的纹理），否则会增加加载时间与内存占用；保证图集中纹理的格式统一（如均为ETC2），避免混合格式导致的压缩失效；使用Sprite Packer工具的“tight packing”模式，减少纹理之间的空白区域，提升图集利用率。同时，纹理的导入设置也需优化，关闭不必要的导入选项（如“Generate Lightmap UVs”“Read/Write Enabled”），仅在需要时开启，避免额外的内存占用与导入时间。</p><p>渲染管线的适配与定制是Unity渲染优化的高阶核心，不同渲染管线（URP、HDRP、内置管线）的性能特性、功能支持与适用场景差异显著，盲目选择只会导致性能与画质的双重失衡，甚至增加开发成本与周期。内置管线虽然兼容性强，能适配老旧设备（如Android 4.0以上、iOS 9以上），但功能相对单一，缺乏先进的光照模型（如PBR）、后处理框架与自定义渲染通道支持，难以满足高品质画面需求，仅适合开发轻量化2D游戏或对画质要求较低的3D游戏；HDRP（高清渲染管线）能提供电影级的渲染效果，支持实时全局光照（RTGI）、体积雾、屏幕空间反射（SSR）、光线追踪等高级特性，但其对硬件要求极高，需要显卡支持DirectX 12或Vulkan，且显存至少4GB以上，仅适用于PC、主机等高端平台，移动端设备几乎无法流畅运行，开发成本也相对较高；而URP（通用渲染管线）则兼顾了性能与灵活性，通过模块化设计可按需启用功能（如是否开启PBR、后处理、阴影），支持多平台适配，是移动端、中端PC等平台的最优选择，也是当前Unity开发的主流管线。</p>]]></description></item><item>    <title><![CDATA[《Unity多语言开发：从文本到体验的深]]></title>    <link>https://segmentfault.com/a/1190000047406284</link>    <guid>https://segmentfault.com/a/1190000047406284</guid>    <pubDate>2025-11-17 23:02:50</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>游戏多语言本地化的深层逻辑，从来不是简单的文本替换，而是语言特性与技术架构的深度耦合，每一种语系的语法规则、表达习惯，都会像无形的脉络，牵动UI布局、资源存储、交互逻辑乃至玩家体验的底层设计。以语系差异为例，黏着语体系中词汇的组合方式往往让句子长度产生极大波动，同样一句技能描述，日语可能比中文多出三成字符，英语的缩略表达又可能缩短近半，泰语的声调变化虽不直接影响字符数量，却会因发音节奏差异需要调整文本分行逻辑，这种差异绝非自动换行就能化解。它要求技术层面在文本渲染之初就建立动态适配模型—既要预留足够的显示空间避免文本溢出，又要通过算法优化避免空间浪费导致的UI失衡，更要兼顾不同语言的阅读节奏，比如长句文本需要拆分显示以减轻视觉疲劳，短句则需紧凑排版保持界面简洁。在实际开发中，这种适配还需要考虑不同语言的字符间距、行高差异，中文方块字的排版密度与西文的字母组合逻辑截然不同，强行套用同一套排版规则只会导致界面杂乱，因此需要为不同语系定制专属的排版参数，比如中文行高设置为字体大小的1.5倍，西文则调整为1.2倍，同时结合用户研究数据优化文本间距，确保阅读流畅度。更重要的是，动态适配模型还需关联玩家行为数据，比如通过分析不同语言版本用户的停留时长、文本阅读速度，持续微调排版策略，让文本显示既符合语言特性，又贴合目标用户的阅读习惯，这种对语言本质的技术响应，才是多语言版本跳出“翻译表层”、触及体验核心的关键，而非仅仅停留在字面意义的转换上。</p><p>文本提取作为多语言开发的基础环节，真正的难点不在于捕捉显式标注的文本，而在于挖掘那些隐藏在功能逻辑、音效、视觉元素中的隐性表达，这些容易被忽视的内容，恰恰是影响本地化完整性的关键。比如技能释放时的音效字幕，不仅要精准匹配音效时长，还要考虑不同语言的发音节奏，避免字幕显示与音效不同步导致的体验割裂；道具描述中的文化隐喻不能直接直译，需要技术层面支持翻译文本的扩展字段，让翻译人员补充语境说明，确保玩家准确理解核心含义；加载界面的进度提示、成就解锁的弹窗文案、甚至错误报告中的提示信息，这些分散在各个功能模块的隐性文本，若不建立统一的提取标准，很容易出现遗漏或重复翻译的问题。文本ID的命名逻辑同样需要深思熟虑，单纯以功能命名极易出现歧义，比如“open”既可能指打开宝箱，也可能指开启菜单，若不结合场景维度进行区分，后续维护和翻译对接都会陷入混乱，因此建立“场景+功能+优先级”的三维命名体系至关重要，例如“mainUI_chest_open_01”明确指向主界面宝箱打开的一级提示文本，既方便技术人员快速定位文本位置，也让翻译人员明确文本的使用语境。此外，字符编码的兼容性问题常被忽略，北欧小语种的特殊字符、东南亚语系的音调符号，都需要提前适配UTF-8-BOM或其他兼容编码格式，避免在不同设备上出现乱码现象；同时要对提取后的文本进行去重处理，通过文本相似度算法识别重复或高度相似的内容，减少冗余翻译工作量。Unity中文本资源的存储格式选择也需谨慎权衡，XML格式结构清晰但加载效率稍低，JSON格式轻便灵活却在复杂文本管理上存在局限，实际开发中可根据项目规模选择混合存储方案，核心文本采用JSON保证加载速度，扩展文本与语境说明采用XML便于维护，同时搭建可视化的文本管理工具，让翻译人员在不改动代码的情况下直接更新文本内容，大幅提升协作效率，避免因格式限制导致后续本地化迭代困难。</p><p>UI适配是多语言版本中最直观的技术挑战，其核心远不止于文本的自动换行，而是要应对不同语言的阅读习惯和文本特性带来的连锁反应，每一处细节的处理都直接影响玩家的视觉体验和操作流畅度。从阅读方向来看，阿拉伯语、希伯来语等属于从右到左的语系，这要求UI布局不仅要翻转文本显示顺序，还要调整控件的排列逻辑—比如导航栏的图标顺序需从右至左排列，下拉菜单的展开方向改为向左弹出，输入框的光标默认位置设置在右侧，甚至弹窗的关闭按钮也需移动到界面左侧，这种调整不能简单地镜像翻转，还要考虑用户的操作习惯，比如从右到左阅读的用户更习惯在界面右侧进行核心操作，因此需要将攻击、跳跃等关键按钮的位置保留在右侧，仅调整辅助控件的顺序。文本膨胀率的预估则需要建立数据模型，不同语言的膨胀系数存在显著差异，德语的名词复合结构常常导致句子长度比中文多出50%，韩语的音节组合方式会让文本占用30%以上的额外空间，泰语的声调符号虽不增加字符数量却会影响行高，这就要求在UI设计之初就根据目标语言的膨胀规律预留足够的显示区域，同时采用动态布局组件，通过设置灵活的锚点和自适应容器，让控件能够根据文本长度自动调整大小和位置，避免出现文本溢出或空间浪费的情况。此外，不同分辨率设备下的文本缩放问题也需重点考虑，小屏手机上，长句文本若单纯缩小字体会导致可读性下降，因此需要结合文本拆分与字体自适应算法，将过长文本按语义拆分为多行，同时根据屏幕尺寸动态调整字体大小，在保证可读性的前提下实现界面的整体协调；大屏设备如平板、PC端，则要避免文本过大导致的界面空洞，通过调整字符间距、行间距以及补充装饰性元素，保持UI的视觉完整性。字体的兼容性同样不容忽视，部分小语种字体在iOS和Android平台上的渲染效果存在差异，比如冰岛语的特殊字母在Android原生字体中可能显示模糊，需要提前嵌入自定义字体包，同时进行跨平台测试，确保文本显示清晰、美观，避免因字体问题影响玩家对游戏内容的理解。</p><p>文化适配与翻译协同的技术实现，是多语言版本跳出“字面翻译”误区的核心，它要求技术架构能够支撑翻译的灵活性和文化适配的深度，让游戏在不同地区都能传递一致的核心体验，同时贴合当地的文化习惯。敬语体系的分级适配是典型场景，日语、韩语等语言中，根据角色身份、玩家等级或交互场景的不同，需要使用不同等级的敬语，比如玩家与NPC对话时，若NPC为皇室角色需使用最高级敬语，与普通村民对话则使用普通敬语，系统通知需采用中性敬语，这就需要技术层面建立敬语分级配置表，将敬语等级与场景ID、角色属性、玩家等级进行关联，让系统能够根据实际情况动态调用对应的翻译文本，而非采用统一的翻译版本。文化禁忌词汇的过滤机制则需要结合技术与数据，通过建立多语言的禁忌词库，涵盖宗教敏感词、地域歧视词、粗俗用语等，在文本加载时进行实时检测，同时支持对接地区政策数据库，根据不同国家和地区的法规动态更新词库，比如部分中东地区禁止提及特定宗教符号，欧洲部分国家对种族相关词汇有严格限制，这些都需要通过技术手段提前规避，避免因文化差异引发的用户反感。翻译文本的校验机制同样重要，技术上可以通过设置多维度检测指标，比如文本长度阈值确保适配UI显示，关键词匹配度检测避免核心玩法信息缺失，语法规则校验减少翻译错误，文化适配度检测通过算法分析文本是否符合目标地区的表达习惯，比如中文的“吉祥如意”在英语中若直译为“lucky and as you wish”会显得生硬，需通过校验机制提示翻译人员调整为更自然的“good luck and all the best”。此外，翻译人员与开发团队的协同效率也需要技术工具支撑，搭建实时同步的文本管理平台，支持多人在线编辑、权限分级管理，翻译人员的修改能够实时同步到开发环境，无需通过文件传输等繁琐方式；同时加入翻译批注功能，让翻译人员可以标注文化背景、语义说明，帮助开发人员理解文本使用场景，避免因理解偏差导致的技术实现错误。版本回溯功能也不可或缺，便于在出现翻译争议或适配问题时快速恢复到之前的稳定版本，减少沟通成本和迭代周期，确保文化适配与翻译工作高效推进。</p><p>动态资源的多语言协同是容易被忽略却至关重要的环节，游戏中的音效、语音、动画、图标等非文本资源，同样需要进行本地化适配，才能让多语言版本的体验更加完整、沉浸。语音资源的适配不仅是简单的翻译录制，还需要考虑不同语言的发音时长与动画口型的匹配度，比如中文语音的节奏相对平缓，英文语音的重音突出且时长可能更短，若直接替换语音而不调整动画帧，会出现口型与语音不同步的违和感。技术上可采用两种解决方案：一是基于语音时长的帧同步调整，通过算法分析语音文件的时长，自动拉伸或压缩对应的动画帧，确保口型与发音精准匹配；二是采用骨骼动画的自适应口型设计，在制作角色动画时预留多组基础口型，根据语音的发音特征动态组合，适配不同语言的发音节奏，减少因语音替换导致的二次开发成本。图标和视觉元素的本地化则需要结合文化符号的差异，比如中国文化中的龙图腾在西方语境中可能带有负面含义，部分中东地区对猪的形象较为敏感，技术上需要支持不同地区的资源包动态切换，在游戏启动时根据用户选择的语言或设备定位，自动加载对应的视觉资源，同时要优化资源加载策略，避免因资源包过大导致的加载延迟。采用“基础资源+语言专属资源”的分包加载模式，基础资源包含通用的模型、场景素材，语言专属资源仅包含该版本对应的图标、语音、音效等，仅在切换语言时下载对应地区的专属资源，既节省存储空间，又提升加载效率。音效的本地化也不容忽视，不同地区的玩家对音效的接受度存在差异，比如东亚玩家更习惯清脆的技能音效，欧美玩家则偏好厚重的打击音效，技术上可以通过音效参数的动态调整，让音效与对应语言的表达习惯相契合，同时支持玩家自定义音效音量、音色，满足不同用户的个性化需求。此外，动画中的文字元素也需要进行本地化处理，比如剧情动画中的匾额、海报文字，需要提前预留文本替换接口，确保切换语言后动画中的文字能够同步更新，避免出现“中文动画配英文文本”的违和场景。</p><p>本地化测试的技术闭环是确保多语言版本质量的最后一道防线，其核心在于构建全面、高效的测试体系，覆盖语言准确性、功能兼容性、体验一致性等多个维度，避免因本地化问题影响游戏的市场表现。自动化测试工具的应用能够大幅提升测试效率，开发基于UI识别的自动化测试脚本，通过图像识别技术检测不同语言版本中文本显示是否正常、控件位置是否偏移、按钮点击是否有效，同时支持多设备、多分辨率的并行测试，比如同时在iOS、Android的不同机型，以及PC、主机等平台上运行测试用例，快速定位跨平台、跨语言的适配问题。脚本中可加入智能断言机制，比如预设文本显示区域的阈值，当文本超出该区域时自动标记为异常，预设控件位置的偏差范围，当控件偏移超过允许值时触发报警，减少人工测试的重复工作量。人工测试则需要聚焦于文化适配和体验细节，组织不同母语背景的测试人员进行沉浸式体验，测试人员需具备目标地区的文化认知，重点关注翻译的自然度、文化符号的适配性、操作逻辑的合理性等，比如检测日语版本中敬语使用是否准确，阿拉伯语版本中UI布局是否符合从右到左的阅读习惯。技术上可以搭建测试反馈平台，让测试人员能够快速提交问题，并关联对应的文本ID、UI控件名称或资源文件路径，同时支持上传截图、录屏，方便开发人员精准定位并修复问题。此外，灰度发布与用户反馈收集也是测试闭环的重要组成部分，通过向小范围目标用户推送多语言版本，比如按地区筛选数千名用户参与测试，收集真实场景下的使用反馈。技术上集成用户行为分析工具，追踪不同语言版本中用户的操作路径、停留时长、报错频率、核心功能使用率等数据，通过数据分析发现潜在的本地化问题，比如某一语言版本中用户在任务界面的停留时长明显过长，可能是由于文本表达晦涩导致玩家无法理解任务要求；某一版本的退出率异常偏高，可能是UI适配不佳影响操作流畅度，进而针对性地进行优化迭代。同时，要建立本地化版本的快速迭代机制，利用热更新技术确保测试中发现的问题能够及时修复，无需用户重新下载完整安装包，修复后通过二次测试验证效果，形成“测试-反馈-优化-再测试”的技术闭环。</p>]]></description></item><item>    <title><![CDATA[有远见的长期主义者 留胡子的饼干_dli]]></title>    <link>https://segmentfault.com/a/1190000047406295</link>    <guid>https://segmentfault.com/a/1190000047406295</guid>    <pubDate>2025-11-17 23:02:14</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>从生成式 AI 的惊艳亮相引起全球科技巨头军备竞赛般的投入开始，整个 AI 行业仿佛被注入了无限的想象力。似乎在宣告着即将出现一个生产力即将被彻底解放、商业模式即将被完全颠覆的光明未来。<br/>微软、谷歌、亚马逊等云巨头纷纷将资本支出的绝大部分押注于 AI 基础设施建设，而无数逐利而来的 AI 初创公司，更是如雨后春笋般涌现试图分一杯羹，全球 AI 领域的投资额也达到了史无前例的高度。<br/>然而，正如任何过热的淘金热最终都会迎来冷静期当技术以超乎预期的速度普及时，潜在的负面效应也以同样的速度被放大，正在悄然侵蚀着行业参与者。<br/>从 " 可选项 " 到 " 必选项 " 的巨额支出<br/>根据奇安信集团对外发布《2024 人工智能安全报告》来看，在 2023 年基于 AI 的深度伪造欺诈便已暴增了 3000%，基于 AI 的钓鱼邮件也增长了 1000%；而内容生成环节更是实现规模化生产。<br/>基于 Stable Diffusion 和 GPT-4 的定制模型，可每小时生成 2000 条伪原创研报、800 段逼真视频。暗网平台 "DarkGPT" 更是提供包月服务，1 万美元即可获得每日 5000 条金融虚假内容的产能。<br/>而且 "AI 滥用 " 的后遗症并不仅仅在社会新闻版块，可以说它已经穿透了科技公司的防火墙直接作用于其财务报表。而金融行业正是这场风暴的中心，当 AI 以假乱真的能力被精准地应用于金融诈骗时，其破坏力可以说是指数级的增长。<br/>据行业估算，2024 年由深度伪造技术引发的各类欺诈造成的全球经济损失已高达 120 亿美元。尤其在监管相对滞后、交易更为匿名的加密货币领域，AI 滥用更是如鱼得水。根据相关的报告也显示 2024 年仅 AI 深度伪造技术全年造成的损失便高达 46 亿美元。<br/>随着 AI 滥用事件的频发，过去模糊的 " 伦理指南 " 正在迅速转变为具有强制约束力的法律条文，而且这种转变直接导致了企业合规成本的急剧攀升。<br/>而且一旦出现违规需要付出的代价更是惨痛的，罚款最高可达全球年营业额的数个百分点或数千万欧元，而且合规也不再是法务部门的单一工作，而是渗透到研发、产品、市场的每一个环节。<br/>这些 " 反噬 " 也并非凭空产生，在 AI 商业化过程中对速度和规模的追求，长期以来压倒了对安全和伦理的考量所以形成了这种 " 原罪 "。因此未来合规成本的升高是不可避免的，而欧盟的《AI 法案》可以说是这一趋势的先行者。<br/>该法案于 2024 年 8 月 1 日正式生效并分阶段实施，着重对高风险的 AI 系统施加了严格的合规要求。而且这不仅仅是一项区域性法规，更可能产生 " 布鲁塞尔效应 " 从而影响全球的 AI 监管格局。<br/>监管的落地也将会直接转化为企业的合规成本。据公开信息推算，仅欧盟 AI 法案便可能导致欧洲企业的 AI 采纳成本增加约 310 亿欧元，并使 AI 投资减少近 20%。而美国联邦贸易委员会也已对 OpenAI 展开调查，谷歌等公司也不得不调整其营销话术，避免被处以巨额罚款。<br/>可以说 " 监管的铁幕 " 正在迫使整个行业从过去 " 快速行动，打破陈规 " 的互联网思维转向一种更为审慎、合规驱动的开发模式。可以说这种转变无疑会减缓创新速度并增加运营成本，对于那些资源有限的中小企业和初创公司构成尤为严峻的挑战。<br/>对 " 信任 " 的侵蚀或许是 AI 滥用最难修复的一种<br/>这源于在激烈的竞争压力下，企业急于抢占市场将产品快速推向用户，所以将风险控制和安全测试置于次要位置。但是这种 " 快速行动并打破规则 " 的心态在 AI 时代尤为危险，因为 AI 技术的潜在破坏力远超以往的软件应用。<br/>并且市场对于 AI 技术的可靠性极度敏感，甚至一次小小的失误都可能引发巨大的信任危机和财务损失。谷歌的 Bard 模型之前便在一次演示中出现事实性错误，竟然导致其母公司 Alphabet 的股价在单日内暴跌 7%，市值蒸发超过 1000 亿美元。<br/>并且随着 AI 投资的巨额支出持续攀升，投资者开始担忧其回报前景，这种悲观情绪导致 Meta、Microsoft、Alphabet 和 Nvidia 等 AI 领域的领军企业股价普遍承压下跌，市场也开始讨论 "AI 泡沫 " 的风险，并开始质疑哪些不计成本的 " 军备竞赛 " 式投资。<br/>更何况大量公司缺乏对 AI 伦理的明确责任归属，高管层面也并未对其有所调整。所以 AI 系统的决策过程像一个 " 黑箱 "，在责任主体模糊的情况下滥用和误用的风险便难以控制。企业内部也未建立有效的问责机制。<br/>但是更深层次的原因在于当前主流生成式 AI 商业模式本身所内含的风险。这些模型依赖于海量数据的投喂，其训练过程难以完全避免偏见和有害信息的吸收。而其强大的生成能力却为恶意利用提供了温床。<br/>因此当商业模式的核心是追求更强大的模型、更广泛的应用时，如果缺乏与之匹配的强大 " 安全刹车 " 系统，滥用就成了可预见的副产品。这种商业逻辑与伦理要求之间的结构性失衡才是导致 " 反噬 " 的根本内因。<br/>所以当企业享受了技术红利带来的增长，如今便也不得不为其模式所伴生的风险 " 买单 "。哪怕科技公司以 " 让世界更美好 " 的叙事推广 AI，公众在实际体验中，也会频繁受到隐私泄露、算法偏见、就业替代、虚假信息等负面影响。<br/>这种落差也导致了广泛的 "AI 焦虑 " 和不信任感。公众普遍认为现有的监管法规不足以应对 AI 带来的社会风险期望政府采取更加果断的行动。这种强大的民意压力也是推动监管机构加速行动的根本动力。<br/>面对公众的呼声和潜在的社会风险，监管机构的介入是必然的。但由于技术发展的速度远超立法速度监管往往表现出一定的滞后性，欧盟 AI 法案便被部分人士认为可能增加企业负担、抑制创新。<br/>全球主要经济体在 AI 领域的竞争，也使得监管变得更加复杂。各国都希望在鼓励创新和防范风险之间找到平衡点但这种平衡点的位置各不相同，因此形成了复杂的国际监管格局给跨国企业的合规带来了巨大挑战。<br/>而且这种外部滥用对整个 AI 行业的声誉造成了 " 连坐 " 效应。即使一家公司本身恪守伦理，也无法完全独善其身，因为公众对 AI 的信任是整体性的。恶意滥用行为如同向池塘中投下的毒药，在污染了整个水域后迫使所有 " 池中生物 " 共同承担后果。<br/>这场危机成为 AI 自我革新的契机<br/>这场 " 反噬 " 带来的阵痛，是 AI 产业从野蛮生长走向规范发展的必经阶段。它正在淘汰那些只想赚快钱、缺乏责任感的 " 玩家 "，筛选出真正有实力、有远见的长期主义者。从长远来看，这也是为 AI 产业的健康、可持续发展所必须付出的代价。<br/>其中最大的机遇在于将 " 信任 " 从一种道德呼吁，转变为一种可量化、可变现的商业资产和竞争壁垒。数据显示近 85% 的客户也更愿意与重视 AI 伦理实践的公司合作，而那些优先考虑伦理和透明度的公司收入增长也更快。<br/>可以说在 AI 产品同质化日益严重的未来，谁能赢得用户的信任谁就能赢得市场。" 负责任的 AI" 将不再仅仅是公关部门的口号，而是必须贯穿于产品设计、开发、部署全流程的核心战略。<br/>谷歌和微软等公司已经开始调整其策略，谷歌选择利用 AI 技术提升广告安全审核的效率，打击欺诈内容；微软则发布了负责任 AI 透明度报告，并推出了 AzureAIContentSafety 等服务，帮助客户构建更安全的 AI 应用。这些举措既是应对风险的防御，也是在构建新的竞争优势。<br/>正是 " 反噬 " 催生了全新的 " 安全即服务 " 市场。随着 AI 滥用风险的加剧企业对 AI 安全审计、风险评估、内容过滤、合规咨询等服务的需求将急剧增长。这为专门从事 AI 安全和伦理治理的科技公司、咨询机构创造了巨大的市场空间。<br/>而科技巨头自身也可以将其内部成熟的安全工具和能力平台化、服务化，开拓新的收入来源。例如，谷歌和微软在内容审核、风险识别方面的技术积累，完全可以转化为对外输出的商业服务。<br/>虽然监管的收紧虽然带来了成本，但也为行业设定了 " 准入标准 "，能够率先满足高标准合规要求的企业将获得更强的市场公信力和竞争优势，从而在未来的市场整合中占据有利地位。这实际上是一种由监管驱动的市场出清和格局优化。weibo.com/ttarticle/p/show?id=2309405233995679137906<br/>weibo.com/ttarticle/p/show?id=2309405233995817549851<br/>weibo.com/ttarticle/p/show?id=2309405233995951767682<br/>weibo.com/ttarticle/p/show?id=2309405233996090179688<br/>weibo.com/ttarticle/p/show?id=2309405233996807405670<br/>weibo.com/ttarticle/p/show?id=2309405233996946079868<br/>weibo.com/ttarticle/p/show?id=2309405233997084229682<br/>weibo.com/ttarticle/p/show?id=2309405233997218447497<br/>weibo.com/ttarticle/p/show?id=2309405233998128873660<br/>从滥用事件的激增，到资本市场的审慎，再到全球监管的收紧，这股 " 反噬 " 之力正在重塑 AI 产业的发展轨迹。它迫使整个行业从过去对技术力量的无限崇拜，转向对技术责任和社会价值的深刻反思。<br/>麦肯锡预测，到 2030 年 AI 将为全球经济创造 13 万亿美元价值。但价值分配取决于我们如何驾驭这头猛兽。未来的竞争，将不仅仅是模型参数和算力大小的竞争，更是治理能力、责任担当和用户信任的竞争。</p>]]></description></item><item>    <title><![CDATA[灵宇宙获 2 亿新融资，要做 AI 世界]]></title>    <link>https://segmentfault.com/a/1190000047406302</link>    <guid>https://segmentfault.com/a/1190000047406302</guid>    <pubDate>2025-11-17 23:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406304" alt="" title=""/></p><p>开发者朋友们大家好：</p><p>这里是 <strong>「RTE 开发者日报」</strong> ，每天和大家一起看新闻、聊八卦。我们的社区编辑团队会整理分享 RTE（Real-Time Engagement） 领域内「有话题的 <strong>技术</strong> 」、「有亮点的 <strong>产品</strong> 」、「有思考的 <strong>文章</strong> 」、「有态度的 <strong>观点</strong> 」、「有看点的 <strong>活动</strong> 」，但内容仅代表编辑的个人观点，欢迎大家留言、跟帖、讨论。</p><p>本期编辑：<a href="https://link.segmentfault.com/?enc=QeQ2YuFoRoQz%2FBz%2F2ewZZg%3D%3D.kpc04s7lDJ3MB3oQw3ZoVPEVCldJ6MqIPKZv9dgppR4%3D" rel="nofollow" target="_blank">@鲍勃</a></p><h2>01 有话题的技术</h2><p><strong>1、 Vogent 推出 AI 语音智能体向导：描述即生成，分钟级部署语音智能体</strong></p><p>Vogent 发布了 Voice Agent Wizard，旨在通过简化语音 AI 应用的开发流程，大幅缩短开发周期并降低技术门槛。用户只需提供描述和相关文件，即可在短短几分钟内生成一套完整、可部署的语音智能体。</p><ul><li><strong>描述驱动生成：</strong> 借助自然语言描述语音智能体的功能和目标，并上传少量参考文件（如对话记录），AI 便能自动完成构建。</li><li><strong>海量数据训练：</strong> 该向导基于对数千个真实语音智能体设计过程的学习，深刻理解语音 AI 在实际生产环境中的运作原理。</li><li><strong>全流程自动化：</strong> AI 不仅能自动选择合适的架构、优化参数、生成系统提示，还能预测和处理潜在的边缘情况，实现全流程自动化。</li><li><strong>开发周期显著缩短：</strong> 过去需要数周甚至数月的试错和配置工作，现在仅需几分钟即可完成，从而显著加速产品上市时间。</li><li><strong>赋能快速迭代：</strong> 用户可以即时测试新的应用场景，并根据用户反馈进行实时迭代，将精力集中于产品本身，而非底层基础设施。</li></ul><p>Vogent 的 AI 语音智能体向导现已上线，用户可通过 app.vogent.ai 访问并开始使用。</p><p>(<a href="https://link.segmentfault.com/?enc=Ur9MJYX3MO%2BBgTimujuDig%3D%3D.LWu4c%2BM7zWISCHyrTal6w2KbCIHgcVYZVMBGfEtabKQ%3D" rel="nofollow" target="_blank">@Y</a> Combinator)</p><p><strong>2、Talo 被 Palabra.ai 收购，整合打造全场景 AI 实时语音翻译平台</strong></p><p>Talo 在被 Palabra.ai 收购后，正式整合并发布了其全方位的 AI 实时语音翻译平台。此次整合旨在打破语言障碍，提供从视频通话到直播、线下活动及 API 集成的无缝跨语言沟通解决方案。</p><ul><li><strong>全场景覆盖：</strong> Talo 现已支持视频通话、网络研讨会、线下活动、直播广播以及通过 API 集成，满足多样化的翻译需求。</li><li><strong>核心技术升级：</strong> 实时视频通话翻译能力大幅提升，用户体验更为自然流畅。</li><li><p><strong>新增功能：</strong></p><ul><li>Palabra Events 支持网络研讨会和线下活动的实时翻译。</li><li>Palabra Broadcaster 提供直播广播的即时语音翻译。</li></ul></li><li><strong>开发者平台：</strong> 推出 API 平台，赋能开发者构建自定义的翻译应用。</li></ul><p>(@ Producthunt)</p><h2>02 有亮点的产品</h2><p><strong>1、Proxis：AI 邮件智能体，以你的语调风格撰写邮件</strong></p><p>Proxis 推出一款 AI 邮件智能体，能够连接用户的知识库和收件箱，模仿其邮件风格和语调，自动草拟并发送邮件。该工具旨在解决日益增长的邮件数量和信息处理难题，尤其适用于需要高强度邮件沟通的销售、运营及创始人等用户。</p><ul><li><strong>个性化邮件草拟：</strong> Proxis 能够学习用户的语调和风格，生成听起来「像你本人」的邮件回复。</li><li><strong>语境优先：</strong> 可连接 CRM、Notion、Drive、Slack、帮助文档以及历史邮件，确保回复内容准确且符合品牌调性。</li><li><strong>智能发送机制：</strong> 仅在 AI 拥有高置信度时自动发送邮件，其他回复则保留在草稿箱供用户审核。</li><li><strong>持续学习：</strong> 用户的每一次发送和反馈都会帮助 AI 更好地学习和适应其沟通方式。</li><li><strong>规则配置：</strong> 用户可配置特定的规则来指导 AI 的行为。</li></ul><p>(<a href="https://link.segmentfault.com/?enc=jksukqSSAX64q43T9WN7cA%3D%3D.uZBQ8pO16zuSSEPxq1UaViNpL3feXCihOUEHAbrfGx4%3D" rel="nofollow" target="_blank">@Y</a> Combinator)</p><p><strong>2、Willow 发布 iOS 智能语音键盘，实现「边说边改」的无缝输入体验</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406305" alt="" title="" loading="lazy"/></p><p>Y Combinator 孵化的初创公司 Willow 发布了一款 iOS 智能语音键盘应用，支持在所有 App 中进行高效的语音输入。与传统语音转录工具不同，Willow 将完整的键盘与语音输入集成，解决了语音输入后「编辑困难」的核心痛点，旨在提供一种更高效、更自然的移动端输入方式。</p><ul><li><strong>全功能键盘集成：</strong> Willow 的最大优势在于它是一个完整的键盘，而非单纯的语音输入面板。用户可以在语音转录后，无需切换键盘，直接进行光标移动、文字修改和输入，极大地提升了编辑效率。这一点是其与竞品 Wispr Flow 的核心差异。</li><li><strong>基于 LLM 的个性化引擎：</strong> 该应用支持超过 100种语言，并允许用户自定义专业词汇和写作风格（例如，区分工作、邮件、即时消息等场景）。其技术栈基于一系列模型，并重点调优了基于 Meta Llama 模型的文本到文本（text-to-text）管线，以实现精准的格式化与个性化。</li><li><strong>强劲的商业势头：</strong> 自发布以来，Willow 的用户量实现了每月 50% 的增长，并已获得包括 Uber、Heidi Health 等在内的企业客户。公司已获得由 Box Group、Y Combinator 以及 Reddit 联合创始人 Alexis Ohanian 等知名投资方提供的 450 万美元融资。</li><li><strong>超越听写的长期愿景：</strong> 在桌面端，Willow 还提供名为「Hey Willow」的语音助手，可以执行更复杂的指令，如用用户的语气风格撰写邮件回复。其长期目标是构建一个能通过语音控制计算机的下一代人机交互界面。</li></ul><p>(@TechCrunch)</p><p><strong>3、灵宇宙获 2 亿新融资，要做 AI 世界操作系统</strong></p><p>「暗涌 Waves」获悉，灵宇宙近日完成 2 亿元 PreA 轮融资，由上海国际集团旗下国方创新、国泰海通、广发信德、滴滴出行、拉卡拉旗下考拉基金、润建股份等金融机构和上市公司参投，老股东超额追投。</p><p>「如果 AI 要进入生活，它一定得从家庭和随身场景开始理解人，而全球化是这类产品的自然方向。」顾嘉唯告诉「暗涌 Waves」，Luka 时代资本火热，大家都在冲机器人。但那时的底层模型没准备好、硬件也太贵，做终端就是在「逆风走钢丝」。现在完全不一样了，模型成熟了、基础成本降下来、交互方式变了，「AI 开始真正进入物理世界。」</p><p>基于这样的判断，大模型到来后顾嘉唯创立灵宇宙，这并非简单的二次创业，而是将其坚守十余年「万物有灵」的核心理念置于大模型时代的新基座上重新出发。不再只是单一爆款产品，目的打造一个面向下一代 AI 终端的操作系统生态，让机器真正具备感知、共情与主动交互的 「灵性」。</p><p>但 AI 硬件并不是顾嘉唯的终极目标。他想把验证有效的模型推向规模化，不再只是做陪伴机器，而是构建一个能在全球不同家庭中运行的人机交互系统------从 AI 伴读的单点突破，到面向全球家庭的具身智能系统化实验。</p><p>灵宇宙的关键引擎在于其自主研发的 LingOS 交互操作系统，而 LingOS 的核心价值在于其可迁移性------它不是一个被绑定在特定硬件上的固件，而是一个能够注入不同形态终端（从随身设备到家用消费机器人）的「AI 灵性」及「机器人灵魂」，通过持续收集的真实世界交互数据不断进化。在他的理想中，LingOS 不会局限于单一场景的智能响应，而是要成为跨越地域、文化与年龄的 「通用 AI 灵性接口」。</p><p>在顾嘉唯看来，「硬件只是接口，系统才是核心。」而从发展路径上看，系统的价值需要在更大市场------尤其是海外市场被验证和放大。</p><p>（<a href="https://link.segmentfault.com/?enc=i3fSBRny18YUGC6QOhInAw%3D%3D.13ozBx6CwHnTYJfNLOHucGCshUR3KtBVzcaO8dBmJcMTakkUvPCKdsVssXHI%2FsjF" rel="nofollow" target="_blank">@暗涌</a> Waves）</p><p><strong>4、前云鲸产品副总裁李阳创业，聚焦陪伴具身赛道</strong></p><p>雷峰网·鲸犀独家获悉，前云鲸智能产品副总裁李阳（Roger）离职后创业，成立公司「Ouropia」，主攻家庭陪伴具身领域，该项目将聚焦内容情绪消费与物理实体陪伴，通过深度情感交互实现 Physical AI 的家庭场景进入问题。</p><p>目前，李阳的创业项目已完成种子轮融资，获数千万美元融资。据了解，Ouropia 的首款产品将通过具身方式实现深度情绪交互和内容消费，产品将面向北美市场，预计客单价将处于较高区间。</p><p>另据雷峰网了解，Ouropia 创始团队包括来自大疆、影石、字节、清华的机器人和认知领域专家，以及知名产品设计团队，是一支磨合多年的成熟产品工程团队。李阳早年曾在大疆担任动力系统专家，后相继负责 Mavic 系列产品、教育机器人产品及自动驾驶相关业务，于 2021 年离开大疆加入云鲸。在云鲸期间担任产品副总裁，负责产品设计、研发工程管理、质量等工作，在团队中具有重要影响力。</p><p>（@雷峰网）</p><h2>03 有态度的观点</h2><p><strong>1、 李彦宏回应百度总是「起大早赶晚集」：不能指望所有创新都成功，创新的特点就是大多数会失败</strong></p><p>11 月 16 日消息，在 2025 百度世界大会后，百度创始人李彦宏接受媒体采访。在采访中，李彦宏谈到了一个外界非常关注的话题：「当然，别人说我们『起大早赶晚集』，这不冒犯，一些也是事实。甚至我在内部也让大家研讨说，我们为什么会『起大早赶晚集』。」</p><p>李彦宏表示：「我们不能够指望所有的创新尝试都是成功的，创新的特点就是，大多数创新会失败，我们要接受这样一个现实。所以百度内部可能起过十个不同的创新项目，如果九个都失败了，我认为是很正常的，它就应该失败，从概率上讲就应该失败，如果有一个成功了，那就非常好。」</p><p>李彦宏还说：「另外一方面，百度这些年有做成的、有做失败的。如果有什么规律性的话，当这件事的成败几乎完全取决于它技术的先进性的时候，我们的成功概率就会大不少，尤其是这个技术需要很多很多年的投入和迭代，那我们成功的概率就会更大一些。」</p><p>（@潇湘晨报）</p><h2>04 社区黑板报</h2><p>招聘、项目分享、求助......任何你想和社区分享的信息，请联系我们投稿。（加微信 creators2022，备注「社区黑板报」）</p><p><strong>1、招聘实习生丨加入我们，共建 RTE 开发者社区</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406306" alt="" title="" loading="lazy"/></p><p><strong>RTE 开发者社区·运营实习生（实时互动 / Voice AI 方向，本招聘长期有效）</strong></p><p><strong>地点：北京·朝阳区望京南/上海·杨浦区五角场</strong></p><p><strong>这份实习将给你带来：</strong></p><p>**产品与技术成长：**深入学习垂类 AI 产品从技术到落地的全生命周期，构建全面的产品视角。</p><p>**社区运营实战：**与高潜力的开发者和创业者深度交流，共同探索行业前沿；并亲身体验顶级 AI 大会，拓展行业视野。</p><p><strong>【你的职责】</strong></p><p><strong>Voice AI / RTE 情报官：</strong> 每日关注 Voice AI /实时互动领域的最新动态，提炼整理并分享行业洞察，定期撰写学习笔记，帮助团队和社区保持信息前沿。</p><p><strong>社区连接者：</strong> 负责 RTE 领域开发者、初创企业等核心群体的社群运营，主动建立并深化联系，鼓励并协助他们融入社区，共同维护社区的活力与生态。</p><p><strong>活动协作者：</strong> 深度参与 RTE Open Day、Meetup、Dev Talk 等线上线下活动的全流程运营，包括前期策划、中期执行、后期复盘，从实践中提升组织和协调能力。</p><p><strong>行业洞察者：</strong> 协助开展 RTE 相关行业及应用场景调研、产品竞争力分析，整理相关资料，形成对业务的深入理解和独到见解。</p><p><strong>【希望你】</strong></p><p>1.本科及以上学历，商业、技术、产品、媒体专业或经验背景优先，具备良好英文能力；</p><p>2.对 RTE / Voice AI 有浓厚兴趣和求知欲；具备优秀的信息收集与整合能力，乐于快速学习新事物，并具备严谨的逻辑思维。</p><p>3.能保证每周至少 4 天的工作时间，持续 3 个月以上。</p><p><strong>【薪资】</strong></p><p>180-220 元/天</p><p><strong>【投递方式】</strong></p><p>实习地点北京或上海，请将简历发送至 <a href="mailto:rtedevcommunity@gmail.com" target="_blank">rtedevcommunity@gmail.com</a> ；邮件标题请注明：【社区运营实习-姓名-学校-毕业年份-到岗日期-城市】</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406307" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047406308" alt="" title="" loading="lazy"/></p><p><a href="https://link.segmentfault.com/?enc=cF9Ps%2BYnpt%2F5CARsTqINWQ%3D%3D.yyvD26vluuLvojYJmuEf6AxbShf3ilE2KDTf0n9IHos%3D" rel="nofollow" target="_blank">阅读更多 Voice Agent 学习笔记：了解最懂 AI 语音的头脑都在思考什么</a></p><p><strong>写在最后：</strong></p><p>我们欢迎更多的小伙伴参与**「RTE 开发者日报」**内容的共创，感兴趣的朋友请通过开发者社区或公众号留言联系，记得报暗号「共创」。</p><p>对于任何反馈（包括但不限于内容上、形式上）我们不胜感激、并有小惊喜回馈，例如你希望从日报中看到哪些内容；自己推荐的信源、项目、话题、活动等；或者列举几个你喜欢看、平时常看的内容渠道；内容排版或呈现形式上有哪些可以改进的地方等。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047406309" alt="" title="" loading="lazy"/></p><p>素材来源官方媒体/网络新闻</p>]]></description></item><item>    <title><![CDATA[TOON：专为 LLM 设计的轻量级数据]]></title>    <link>https://segmentfault.com/a/1190000047406174</link>    <guid>https://segmentfault.com/a/1190000047406174</guid>    <pubDate>2025-11-17 22:02:19</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>这几天好像这个叫 TOON 的东西比较火，我们这篇文章来看看他到底是什么，又有什么作用。TOON 全称 Token-Oriented Object Notation，它主要解决的问题就是当你把JSON 输入给LLM 的时候，token 消耗太高了。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047406176" alt="" title=""/><br/>一个长 JSON 数组扔进模型token 计数直接起飞。因为引号、大括号、重复的键名，到处都是这些没什么实际意义的字符，而TOON 就是从这个痛点出发，它不是要干掉 JSON，而是说：既然主要是语言模型，那些装饰性的字符完全可以省掉。</p><h2>Token数对比</h2><p>常规 JSON 长这样：</p><pre><code> [  
   { "id": 1, "name": "Deep", "role": "admin" },  
   { "id": 2, "name": "Hub", "role": "user" }  
 ]</code></pre><p>TOON 版本：</p><pre><code> users[2]{id,name,role}:  
   1,Deep,admin  
   2,Hub,user</code></pre><p>第一眼看上去像半成品草稿。但逻辑其实很清晰——字段名只写一次，声明有多少行，然后直接按表格形式写数据，我们直接可以说这个算是CSV的一个进化版。</p><p>有一个不严谨的测试JSON 格式的 token 数基本是 TOON 的两倍。差距就这么大。</p><h2>TOON</h2><p>JSON 的问题是结构不变的情况下还在重复。而TOON的想法是既然结构本来就很明显了，没必要每条记录都写一遍。</p><p>另外就是该有得支功能还是都有，比如说嵌套，使用类似 YAML 的缩进结构来处理嵌套对象：</p><pre><code> user:
   id: 123
   email: ada111@666.com
   metadata:
     active: true
     score: 4.5</code></pre><p>简单得嵌套跟YAML 基本一样，如果把嵌套和列表放在一起就是这样：</p><p>比如说这个json</p><pre><code> {
  items: [
    {
      users: [
        { id: 1, name: 'Deep' },
        { id: 2, name: 'Hub' }
      ],
      status: 'active'
    }
  ]
 }</code></pre><p>转换完以后是这样的</p><pre><code> items[1]:
   - users[2]{id,name}:
     1,Deep
     2,Hub
     status: active</code></pre><p>这完全就是YAML 和CSV的缝合怪，不过倒是把JSON冗余的标点去掉了。</p><p>不过根据官网的评测token的确是减少了很多<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047406177" alt="" title="" loading="lazy"/></p><h2>局限性</h2><p>对于YAML来说深层嵌套的数据结构一直是个问题，而TOON也一样，如果层次太多会比较乱。而且同一个列表里如果对象结构不一致，也不太好处理。但是如果只是为了优化 LLM prompt，TOON还真的确实挺实用。</p><h2>总结</h2><p>适合用 TOON 的情况：</p><ul><li>往模型里塞大量重复结构的数据</li><li>token 成本是主要考虑因素</li><li>数据结构相对规整</li></ul><p>继续用 JSON 的情况：</p><ul><li>写 API 接口</li><li>需要长期存储</li><li>数据结构复杂或者不规则</li></ul><p>所以TOON并不是什么颠覆性的东西。更像是有人把 JSON 里那些多余的部分清理掉，然后说：跟模型交互的时候，可以试试这个。</p><p>github地址：</p><p><a href="https://link.segmentfault.com/?enc=5toVUX%2BwxAJfSlU30fTAng%3D%3D.4GTYXlrrTVkxbaoXEjPdX5dm%2BaaTidyxrXC%2Bmm7C3nAv6Zkks%2F6x397obn18vq3pb9NpOjZu42FcBnyaBjlo9Q%3D%3D" rel="nofollow" target="_blank">https://avoid.overfit.cn/post/95264c51c6544c139b198c31fe4127ab</a></p>]]></description></item><item>    <title><![CDATA[AI 面试智能体：降本增效的招聘新利器 ]]></title>    <link>https://segmentfault.com/a/1190000047406181</link>    <guid>https://segmentfault.com/a/1190000047406181</guid>    <pubDate>2025-11-17 22:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>AI 面试智能体：降本增效的招聘新利器<br/>当预算遭遇腰斩：AI面试如何成为HR降本增效的“破局利器”？<br/>培训预算削减的背后，是时候重新审视招聘的真正成本。<br/>年底复盘，不少HR对着培训报表愁眉不展：预算花了近百万，员工满意度刚过及格线，业务部门还抱怨“培训没用”。降本增效的要求之下，培训预算首当其冲被压缩。问题真的出在培训本身吗？或许，根源在于招聘环节——选错人，才是企业最大的成本浪费。</p><p>01 培训无效的背后：选错人是最昂贵的成本<br/>当业务部门抱怨“培训没用”时，他们真正抱怨的是什么？是培训内容不够好，还是培训对象选错了？<br/>一位资深HR总监坦言：“我们花大价钱培训员工，却发现有些人根本不适合岗位。这种错配的成本，远超培训预算本身。”传统招聘依赖HR和专业面试官的主观判断，难免出现偏差。而AI面试智能体正将招聘从“凭感觉”推向“凭数据”的科学决策时代。<br/>02 精准度革命：从“参考意见”到“决策依据”<br/>招聘的核心是“选对人”，AI面试智能体将“精准度”做到了行业领先水平。<br/>其打分结果不仅通过效标效度与重测稳定信度的双重心理学指标考验，更经得起一对一的“背靠背”人机对比实验验证。这意味着，AI面试智能体的评估结果不再仅是参考意见，而是可直接作为招聘决策的依据。相关AI面试智能体的迭代版本发布，标志着其在该领域已达到国际领先水平，这是经得起验证的技术实力体现。<br/>03 面试环节的精准进化：四大技术突破<br/>AI面试智能体的“精准”体现在每一个招聘环节的技术突破上：<br/>•一问多能：一道题目即可同步评估多项胜任力，无缝衔接HR初筛与技术复试，评估效率提升50%以上。<br/>•自由追问：能根据候选人的回答即时生成针对性问题，如同资深面试官般抓住关键信息，避免遗漏核心能力。<br/>•简历深度挖掘：自动抓取简历中的关键信息与模糊点，生成递进式提问，既杜绝信息造假，也避免因HR主观疏忽错过优质候选人。<br/>•全维度考察：既能评估沟通、协作等通用胜任力，也能针对编程、算法、工程、财务等专业领域精准出题，在解放HR面试官的基础上进一步解放专业面试官。<br/>04 候选人体验升级：招聘即品牌传播<br/>传统AI面试常因“机械、生硬”让候选人体验不佳，进而损害雇主品牌。AI面试智能体则把“拟人化交互”做到了极致，让面试成为雇主品牌的加分项。<br/>•懂情绪的智能交互：精准捕捉候选人的语速、情绪与潜台词，像真人HR一样引导候选人充分展现实力，避免因紧张发挥失常。<br/>•无断点流畅体验：无需手动点击“开始/结束答题”，系统自动识别回答状态并衔接下一问题，全程如面对面交流般自然。<br/>•沉浸式视觉体验：通过语音与口型匹配精度的大幅提升，嘴型开合与语速节奏精准同步，彻底告别“纸片人”式的疏离感。<br/>•多轮对话答疑：允许候选人随时提问，AI能准确解答职位信息、公司福利等问题，让候选人更深入了解企业，提升入职意愿。<br/>05 全流程自动化：从识人到沟通的一体化执行<br/>AI人才寻访智能体是一款具备简历解读、精准匹配、有效沟通能力的AI招聘工具。<br/>它并非单一功能的自动消息助手，而是一套完整的招聘自动化系统，可在无需人工干预的情况下，独立完成从简历筛选、初步沟通、简历回收到系统同步的完整流程。从30-60秒完成初始化，到自动筛选简历、动态沟通、全覆盖回复，再到系统同步，AI人才寻访智能体实现了招聘初筛阶段的全面自动化，提升招聘效率10到100倍。<br/>培训预算削减不一定是危机，也可能是转型的契机。当传统的培训投入回报率持续走低，聪明的HR已经开始将资源前置到招聘环节——从源头上确保“选对人”。与其在培训无效后追悔莫及，不如在招聘环节精准筛选。毕竟，选择比努力更重要，选对比选择更关键。</p>]]></description></item><item>    <title><![CDATA[SQL Server 2022 企业版I]]></title>    <link>https://segmentfault.com/a/1190000047406047</link>    <guid>https://segmentfault.com/a/1190000047406047</guid>    <pubDate>2025-11-17 21:01:57</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>​</p><p>一、准备工作</p><ol><li><p><strong>确认系统要求</strong></p><ul><li>你电脑得是 <strong>Windows 10/11 专业版/企业版，或者 Windows Server 系统</strong>，而且必须是 <strong>64位</strong>的。</li><li>最好有 <strong>管理员权限</strong>（就是能安装软件那种账号）。</li></ul></li><li><p><strong>挂载 ISO 文件</strong>（就是打开这个光盘镜像文件）</p><p>方法：</p></li><li><ul><li><p>安装包下载：<a href="https://link.segmentfault.com/?enc=BVcmb2k72%2BXxnwhgPMQEfQ%3D%3D.yC5ptv7wf7YtQkAqtN9zcrcC1PxL1DCLAIfnRJFNSHKl%2Bls6427XcZuqHj2UBujw" rel="nofollow" title="https://pan.quark.cn/s/d83b749b87e5" target="_blank">https://pan.quark.cn/s/d83b749b87e5</a></p><p><strong>双击这个 ISO 文件</strong>，Windows 一般会自动挂载，就像插了个虚拟光盘。</p></li><li>或者右键点击 ISO 文件 → 选择  <strong>“装载”</strong> 。</li><li>挂载后，你会在  <strong>“此电脑”</strong> 里看到一个 <strong>虚拟光驱</strong>，点进去就能看到里面的安装文件。</li></ul><blockquote>如果你电脑不支持直接双击挂载，可以用压缩软件（比如 WinRAR、Bandizip）打开，或者下载个 <strong>虚拟光驱工具</strong>（比如 Daemon Tools）来挂载。</blockquote></li></ol><ul><li><ul><li>*</li></ul></li></ul><h3>二、开始安装</h3><ol><li><p><strong>进入安装界面</strong></p><ul><li>打开挂载后的虚拟光驱，找到并双击运行 <strong>setup.exe</strong>（一般就在根目录，或者 setup 文件夹里）。</li></ul></li><li><p><strong>选择安装类型</strong></p><ul><li><p>第一次打开后，一般会看到几个选项，比如：</p><ul><li><strong>全新 SQL Server 独立安装</strong></li><li><strong>添加功能到现有安装</strong></li></ul></li><li>你是新安装，就选  <strong>“全新 SQL Server 独立安装”</strong> 或者类似选项（比如 “安装” → “全新 SQL Server 独立安装”）。</li></ul></li><li><p><strong>安装程序支持规则检查</strong></p><ul><li>它会先检查你的电脑是否符合安装条件（比如有没有缺 .NET、权限够不够等）。</li><li>如果有 <strong>报错或警告</strong>，按照提示解决一下，比如安装缺的组件，再重新运行 setup。</li></ul></li><li><p><strong>输入产品密钥（如果有）</strong></p><ul><li>如果你有正版的 <strong>产品密钥（25位字符）</strong> ，就输入；如果没有，可能可以选择  <strong>“评估版”</strong> 或  <strong>“开发版”</strong> （免费试用一段时间）。</li><li>企业版通常需要密钥，如果你没有，看看你拿到的这个 ISO 是否包含授权，或者联系提供者。</li></ul></li><li><p><strong>接受许可条款</strong></p><ul><li>勾选  <strong>“我接受许可条款”</strong> ，然后下一步。</li></ul></li><li><p><strong>选择安装功能</strong></p><ul><li><p>这里会让你选要安装哪些功能，比如：</p><ul><li>数据库引擎服务（必须装，这是核心）</li><li>Analysis Services、Reporting Services（看你需要不需要）</li><li>客户端工具等</li></ul></li><li>一般新手或普通用途，<strong>数据库引擎服务</strong>是必选的，其他按需勾选。</li><li>选好后，点下一步。</li></ul></li><li><p><strong>设置实例名称</strong></p><ul><li>你可以选 <strong>默认实例</strong>（就是用电脑名作为实例名），或者自己起个 <strong>实例名</strong>（比如叫 MSSQLSERVER2022）。</li><li>大多数情况选 <strong>默认实例</strong>就行，下一步。</li></ul></li><li><p><strong>服务器配置</strong></p><ul><li>设置 <strong>SQL Server 服务用的账号</strong>，比如数据库引擎服务要用哪个用户启动。</li><li>一般选  <strong>“内置账户”</strong> ，比如 <strong>NT AUTHORITY\NETWORK SERVICE</strong>或 <strong>Local System</strong>就可以（适合个人或测试环境）。</li><li>如果是公司正式环境，可能要专门设置域账号，那得找管理员。</li><li>然后点下一步。</li></ul></li><li><p><strong>数据库引擎配置</strong></p><ul><li><p>选择 <strong>身份验证模式</strong>：</p><ul><li><strong>Windows 身份验证模式</strong>：只允许 Windows 用户登录。</li><li><p><strong>混合模式（推荐）</strong> ：可以用 Windows 用户，也可以用 SQL Server 自己的用户名和密码登录。</p><ul><li><p>如果你选混合模式，<strong>一定要设置一个 SA 密码（SQL 管理员账号密码）！</strong></p><ul><li>密码要设得 <strong>复杂一点</strong>（比如字母+数字+符号，别太简单）。</li></ul></li></ul></li></ul></li><li>把你的 <strong>Windows 用户添加为 SQL 管理员</strong>（一般会自动加当前用户，也可以手动加）。</li><li>然后点下一步。</li></ul></li><li><p><strong>继续后续配置页面</strong></p><ul><li>接下来可能还有 <strong>Analysis Services、Reporting Services</strong>的配置（如果你选了安装这些功能），按提示设置就行，一般保持默认也可以。</li><li>如果没有安装这些额外功能，可能直接跳到下一步。</li></ul></li><li><p><strong>准备安装</strong></p><ul><li>它会列出你要安装的所有功能和配置，<strong>检查一遍，没问题的话点“安装”</strong> 。</li></ul></li><li><p><strong>等待安装完成</strong></p><ul><li>这一步会真正开始安装，时间可能有点长，耐心等等。</li><li>安装过程中别关电脑或关窗口。</li></ul></li><li><p><strong>安装完成</strong></p><ul><li>安装成功后，会提示  <strong>“安装已完成”</strong> 。</li><li>你可以点  <strong>“关闭”</strong> ，然后重启电脑（建议，但不是必须）。</li></ul></li></ol><ul><li><ul><li>*</li></ul></li></ul><h3>三、安装后检查</h3><ol><li><p><strong>打开 SQL Server Management Studio（SSMS）</strong></p><ul><li>这是一个管理 SQL Server 的工具，通常需要<strong>单独下载</strong>（微软官网有免费版本）。</li><li>下载地址（可以去微软官网搜：<strong>SQL Server Management Studio 19 或 18</strong>）。</li><li><p>安装后，打开 SSMS，用以下方式连接：</p><ul><li>服务器名称：写你的电脑名 或 （如果是默认实例，就写 <code>.` 或 电脑名；如果是命名实例，写</code>电脑名\实例名`）</li><li><p>身份验证：</p><ul><li>如果你选了 <strong>Windows 身份验证</strong>，就直接用你的 Windows 账号登录；</li><li>如果你选了 <strong>混合模式</strong>，就选 <strong>SQL Server 身份验证</strong>，输入 <strong>SA 用户名 和 你设置的密码</strong>。</li></ul></li></ul></li></ul></li><li><p><strong>测试连接</strong></p><ul><li>能连上，说明 SQL Server 已经装好了，并且正常运行！</li></ul></li></ol><p>​</p>]]></description></item><item>    <title><![CDATA[申威SW64系统安装docker-ce-]]></title>    <link>https://segmentfault.com/a/1190000047406095</link>    <guid>https://segmentfault.com/a/1190000047406095</guid>    <pubDate>2025-11-17 21:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>​一、准备工作</p><ol><li><p><strong>确认系统架构是申威（SW64）</strong></p><ul><li>一般这个包就是专门为申威64位系统准备的，比如基于 <strong>银河麒麟操作系统 KY10</strong>的申威版。</li><li><p>你可以通过命令查看系统信息：</p><pre><code>uname -m</code></pre></li></ul></li></ol><pre><code>  

    如果显示是 `sw_64`或类似申威相关的，那就没问题。
</code></pre><ol><li><p><strong>下载 Docker RPM 包</strong></p><ul><li><strong>docker-ce-19.03.14.ce-3.ky10.sw_64.rpm安装包下载：</strong><a href="https://link.segmentfault.com/?enc=VQrE4uxYUeNkrytUYhvPNg%3D%3D.LvvXHobiS9K%2BExuTvugXkRvngYRMLTapQXNQQ%2BN%2FUC32MyNLgY3NcRR7mSTsQLbH" rel="nofollow" title="https://pan.quark.cn/s/d83b749b87e5" target="_blank">https://pan.quark.cn/s/d83b749b87e5</a></li><li>如果还没有，得从官方或可信渠道下载这个 <strong>针对申威架构的 RPM 包</strong>，一般后缀是 <code>.sw_64.rpm</code>，说明是为申威编译的。</li></ul></li></ol><h3>二、安装 Docker</h3><ol><li><p><strong>使用 rpm 命令直接安装</strong></p><ul><li><p>打开终端，切换到存放这个 rpm 包的目录，比如你放在了 <code>/home/yourname/</code>下，可以运行：</p><pre><code>cd /home/yourname/</code></pre></li></ul></li></ol><pre><code>-   然后执行安装命令：

    ```
    rpm -ivh docker-ce-19.03.14.ce-3.ky10.sw_64.rpm
    ```

    ![](&lt;&gt; "点击并拖拽以移动")

    -   `-i`是安装
    -   `-v`是显示详细信息
    -   `-h`是显示进度条
</code></pre><ol><li><p><strong>如果提示依赖问题</strong></p><ul><li>某些依赖包可能没装，比如 <code>container-selinux</code>、<code>docker-ce-cli</code>等。</li><li>如果你遇到类似 “依赖缺失” 的报错，可以尝试手动下载这些依赖的 <strong>申威版 RPM 包</strong>，然后一起安装。</li><li><p>或者用这个命令自动解决依赖（如果你的系统支持 yum/dnf）：</p><pre><code>rpm -ivh --nodeps docker-ce-19.03.14.ce-3.ky10.sw_64.rpm</code></pre></li></ul></li></ol><pre><code>    ⚠️ 注意：`--nodeps`是忽略依赖检查，**可能会导致功能不正常，尽量先解决依赖**。

&gt; 如果你系统里有 `yum`或者 `dnf`，并且有对应的申威源，那用 `yum localinstall docker-ce-xxxx.rpm`会更好，它会自动处理依赖关系。


</code></pre><h3>三、启动 Docker</h3><p>安装成功后，启动 Docker 服务：</p><pre><code>systemctl start docker</code></pre><p>设置开机自启（可选）：</p><pre><code>systemctl enable docker</code></pre><h3>四、检查是否安装成功</h3><p>运行以下命令，看 Docker 是否正常工作：</p><pre><code>docker --version</code></pre><p>你应该能看到类似这样的输出，表明版本信息：</p><pre><code>Docker version 19.03.14, build xxxx</code></pre><p>再运行一个测试命令，看看 Docker 服务是否真的在跑：</p><pre><code>docker run hello-world</code></pre><p>这会下载一个小的测试镜像并运行，如果看到 “Hello from Docker!” 之类的提示，那就说明 <strong>Docker 安装成功并能正常使用</strong>。</p><p>​</p>]]></description></item><item>    <title><![CDATA[动态IP如何帮助爬虫采集？IP代理有哪些]]></title>    <link>https://segmentfault.com/a/1190000047405653</link>    <guid>https://segmentfault.com/a/1190000047405653</guid>    <pubDate>2025-11-17 19:06:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在互联网数据爆炸的时代，爬虫技术成为了获取信息的重要手段。而动态 IP 在其中扮演着至关重要的角色，它能帮助爬虫高效、稳定地采集数据。同时，IP 代理也有其独特的特点，下面我们就来详细探讨。</p><p><img width="723" height="546" referrerpolicy="no-referrer" src="/img/bVdm4xs" alt="" title=""/></p><p>动态 IP 助力爬虫采集的方式</p><p>突破反爬虫机制</p><p>许多网站为了防止恶意爬虫大量抓取数据，会设置反爬虫机制。当检测到同一 IP 地址在短时间内进行频繁的访问请求时，就会将该 IP 列入黑名单，限制其访问。而动态 IP 可以在每次请求时更换不同的 IP 地址，让网站难以识别这是同一个爬虫在进行访问。例如，一个爬虫程序在采集电商网站的商品信息时，如果一直使用同一个 IP，可能在采集几百条数据后就会被封禁。但使用动态 IP 后，每次请求都像是来自不同的用户，大大增加了采集数据的数量和效率。</p><p>提高采集速度</p><p>使用动态 IP 可以让爬虫同时从多个 IP 地址发送请求，实现并行采集。就好比多个人同时去完成一项任务，速度自然会加快。比如在采集新闻网站的文章时，通过动态 IP 可以同时从不同的 IP 地址向服务器发送请求，同时获取多篇文章的内容，而不是依次等待每一个请求的响应，从而显</p><p>有些网站的内容会根据用户的 IP 地址进行地域限制。例如，某些国外的视频网站只允许特定国家或地区的 IP 访问。使用动态 IP 可以模拟不同地区的 IP 地址，让爬虫能够访问这些地域受限的内容。这样，爬虫就可以采集到更广泛的数据，为数据分析和研究提供更全面的素材。</p><p>IP 代理的特点</p><p>隐藏真实 IP 地址</p><p>IP 代理的一个重要特点就是能够隐藏用户的真实 IP 地址。当爬虫通过 IP 代理发送请求时，服务器只能看到代理 IP 的信息，而无法获取爬虫所在设备的真实 IP。这不仅可以保护用户的隐私和安全，还可以避免爬虫被追踪和封禁。例如，在进行一些敏感数据的采集时，隐藏真实 IP 可以防止被恶意攻击或法律追究。</p><p>提高网络访问的稳定性</p><p>一些网络环境可能存在不稳定的情况，例如网络拥塞、带宽不足等。使用 IP 代理可以选择网络质量较好的代理服务器，从而提高网络访问的稳定性。代理服务器通常拥有更高速的网络连接和更充足的带宽资源，能够保证爬虫请求的快速响应。此外，当一个代理服务器出现故障或被封禁时，可以及时切换到其他代理服务器，确保爬虫的正常运行。</p><p>提供匿名性</p><p>IP 代理可以为爬虫提供匿名性，让爬虫的行为更加隐蔽。在一些需要采集敏感信息或进行竞争情报收集的场景中，匿名性尤为重要。例如，在采集竞争对手的产品价格和营销策略时，使用 IP 代理可以避免被对方察觉，保护采集行为的安全性和有效性。</p><p>支持多种协议</p><p>IP 代理通常支持多种网络协议，如 HTTP、HTTPS、SOCKS 等。这使得爬虫可以根据不同的采集需求选择合适的协议进行通信。不同的网站可能使用不同的协议进行数据传输，支持多种协议的 IP 代理可以确保爬虫能够与各种类型的网站进行兼容，顺利完成数据采集任务。</p><p>综上所述，动态 IP 为爬虫采集提供了突破限制、提高效率的有效途径，而 IP 代理的诸多特点也为爬虫的正常运行和数据采集提供了有力保障。在使用爬虫进行数据采集时，合理运用动态 IP 和 IP 代理可以让我们更加高效、安全地获取所需的数据。</p><p>你对这篇文章的内容还满意吗？如果有任何修改意见，比如增减内容、调整结构等，都可以随时告诉我。</p>]]></description></item><item>    <title><![CDATA[LoRaWAN FUOTA 空中固件升级]]></title>    <link>https://segmentfault.com/a/1190000047405675</link>    <guid>https://segmentfault.com/a/1190000047405675</guid>    <pubDate>2025-11-17 19:05:41</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在大规模物联网（IoT）项目中，终端设备部署往往分布在偏远、难以接触的场景，依赖人工更新固件几乎不可能实现。为确保设备长期稳定运行，“空中固件升级”（Firmware Update Over The Air，FUOTA）成为关键技术，尤其是在使用 LoRaWAN 的项目中更显重要。由于 LoRaWAN 带宽低、每包数据受限，实现稳定高效的 FUOTA 极具挑战。本文系统解析 FUOTA 的原理、LoRaWAN 中的技术难点，并介绍门思科技（Manthink）在多年项目经验中形成的工程化升级方案。</p><hr/><h2><strong>一、什么是 FUOTA？</strong></h2><p>FUOTA（Firmware Update Over The Air）指通过无线网络远程更新设备固件，使设备在无人工干预的情况下完成功能更新、漏洞修复和性能优化。</p><p>在物联网项目中，终端设备数量动辄成千上万，分布地点可能包括：</p><ul><li>城市地下管网</li><li>农田或山区的农业监测点</li><li>工业园区、油田、仓储中心等现场</li><li>城市设施（路灯杆、井盖、消防栓等）</li></ul><p>一旦部署，这些设备往往多年不维护，因此 FUOTA 直接决定项目生命周期管理能力。</p><hr/><h2><strong>二、LoRaWAN 中 FUOTA 的两大核心挑战</strong></h2><p>LoRaWAN 的优势在于低功耗、远距离，但其限制也格外突出，使 FUOTA 成为一项高难度工程。</p><h3><strong>1. 固件体积极大，传输速度受限</strong></h3><ul><li>LoRaWAN 的最大有效载荷约 <strong>255 字节</strong></li><li>典型固件大小从 <strong>数十 KB 到数百 KB</strong></li></ul><p>在低速链路上上传大文件极易出现：</p><ul><li>丢包</li><li>信道干扰</li><li>升级中断</li><li>升级失败后需重新传输</li></ul><p>尤其是地下管网、弱信号覆盖区，失败率更高。</p><h3><strong>2. 数据分片、校验与重组机制复杂</strong></h3><p>LoRaWAN 升级必须通过数据分片方式完成：</p><ul><li>分片数量可能数百到上千</li><li>需要顺序或乱序重组</li><li>丢包重传策略需精细控制</li><li>大规模设备同时升级需要同步与拥塞控制</li></ul><p>因此，仅依赖标准 FUOTA 规范难以满足真实项目需求。</p><hr/><h2><strong>三、门思科技（Manthink）如何解决 LoRaWAN FUOTA 的工程化问题？</strong></h2><p>门思科技自 ​<strong>2017 年即在实际项目中大规模应用 FUOTA</strong>​，形成了涵盖操作系统、通信机制、算法与工具链在内的完整升级体系。</p><p>以下三项核心技术，使其 FUOTA 在大量部署中稳定可靠。</p><hr/><h2><strong>1. 自研 MPOS 操作系统：为升级预留底层 Hook</strong></h2><p>MPOS（Manthink Portable OS）是门思科技为 IoT 嵌入式设备开发的轻量级操作系统。</p><p>其核心优势在于 ​<strong>为远程升级预置扩展能力（Hook）</strong>​，包括：</p><ul><li>支持单函数级别的动态替换</li><li>支持向系统中新增任务或事件处理</li><li>支持差分升级，只传输变化部分</li></ul><p>相比整包固件升级，差分升级可以：</p><ul><li><strong>减少 70%\~95% 的传输数据量</strong></li><li>显著提升成功率</li><li>降低升级时间</li><li>降低对 LoRaWAN 链路质量的依赖</li></ul><hr/><h2><strong>2. EB（Edge-Bus）计算框架：压缩业务逻辑的“核心武器”</strong></h2><p>EB 框架是一种高度抽象的业务逻辑描述模型，具有：</p><ul><li>极高可压缩性</li><li>模块化</li><li>仅需少量字节即可描述复杂逻辑</li></ul><p>在实际项目中，EB 可以：</p><ul><li>将原本 <strong>几 KB 或几十 KB 的逻辑压缩为数百甚至数十字节</strong></li><li>将升级所需数据量降低一个数量级</li><li>极大提升 LoRaWAN FUOTA 的可行性</li></ul><p>这意味着：<br/><strong>设备无需再升级大固件，只需更新业务逻辑指令即可实现功能扩展。</strong></p><hr/><h2><strong>3. 多 bin 技术：可靠的数据切片与重组机制</strong></h2><p>多 bin 升级机制是门思科技为 LoRaWAN 环境优化的稳定传输方案。</p><p>其特点包括：</p><ul><li>根据设备当前信号质量自适应选择分片大小</li><li>针对弱信号环境优化的纠错和重传策略</li><li>智能组合与完整性校验</li><li>支持断点续传</li></ul><p>即使在高丢包率（5%\~20%）的场景中，也能确保：</p><ul><li>数据分片完整</li><li>升级可持续推进</li><li>最终固件校验通过后自动切换</li></ul><p>真正实现 ​<strong>工程级的远程升级可靠性</strong>​。</p><hr/><h2><strong>四、FUOTA 的价值：让 LoRaWAN 设备“活”起来</strong></h2><p>一个不能升级的物联网设备，只能“被动工作”；<br/>一个支持 FUOTA 的设备，才具备“生命周期管理”的能力。</p><p>FUOTA 带来的价值包括：</p><ul><li><strong>延长设备寿命</strong></li><li><strong>修复长期暴露在现场的安全漏洞</strong></li><li><strong>无需派人维护，大幅降低运维成本</strong></li><li><strong>设备可持续加入新功能</strong></li><li><strong>可适应项目场景变化</strong></li></ul><p>门思科技基于 MPOS、EB 和多 bin 的 FUOTA 技术，为 LoRaWAN 项目提供了工程级、可规模化、长期可靠的远程升级体系。</p><hr/><h2><strong>五、进一步了解 ThinkLink LoRaWAN 网络服务器（NS）</strong></h2><p>如果你正在寻找稳定、开放、全球标准兼容的 LoRaWAN 网络服务器平台，ThinkLink 是一个成熟选择：</p><ul><li><p><strong>ThinkLink Cloud 版</strong></p><ul><li>永久免费</li><li>支持 1000 个设备接入</li><li>支持 BACnet、Home Assistant、ThingsBoard 等系统对接<br/>👉 <a href="https://link.segmentfault.com/?enc=KiEqzgkOSneSIqBl3Ia%2B8Q%3D%3D.TPFs5GprYtQs3bnxXrZbhyua4vQ74xKSB%2FSHKi6m948%3D" rel="nofollow" target="_blank">https://thinklink.manthink.cn</a></li></ul></li><li><p><strong>ThinkLink Edge 版</strong></p><ul><li>可本地部署</li><li>支持 1000 个设备</li><li>内置 Home Assistant 开源版、ThingsBoard CE 版<br/>👉 <a href="https://link.segmentfault.com/?enc=GgChsfT1hNfw4Hi%2FLHrFGw%3D%3D.vf%2FeeRN2SLzN77klomDevzq5HFxwwWixhlFoN9XYcrVipCWUC0Tg%2BpBRK4QadUOw" rel="nofollow" target="_blank">https://www.manthink.cn/zh/thinklink-2/</a></li></ul></li></ul><p>了解更多 LoRaWAN 产品与解决方案：<br/>👉 <a href="https://link.segmentfault.com/?enc=7%2BBGfEL4r6mwDljviZw1KA%3D%3D.GkFTXFSuKN2SZseoB%2F1f3px6kgeXh7gHUhm3GbBFFVk%3D" rel="nofollow" target="_blank">https://www.manthink.cn</a></p>]]></description></item><item>    <title><![CDATA[在项目管理中如何跟踪工作量和工作时间？ ]]></title>    <link>https://segmentfault.com/a/1190000047405679</link>    <guid>https://segmentfault.com/a/1190000047405679</guid>    <pubDate>2025-11-17 19:04:50</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>项目管理工具中的工作量报告非常有用，因为它能清晰地展现任务和职责在团队成员之间的分配情况。通过显示哪些成员工作负荷过重、哪些成员资源利用不足或哪些成员空闲，报告可以帮助管理者更有效地平衡工作，防止员工倦怠或项目延误。此外，报告还能突出显示潜在的资源缺口，帮助团队在问题出现之前调整任务分配或时间安排，从而更好地进行规划。通过提高对团队能力和进度的可见性，团队可以做出更明智的决策，加强协调，并确保项目按计划进行。</p><p>Zoho Projects 支持项目工作量报表和全局工作量报表帮助您了解各个项目里面用户的工作量和您参加的所有的项目里面用户的工作量。 工作量报表为经理非常有帮助。 经理可以了解每个用户的工作量。 如果一个用户的工作量过多和另一个用户的工作量不足，只需要工作量过多的用户的一个任务拖放到工作量不足的用户。</p><p>项目管理工具中的“计划与实际对比”报告会将项目的计划内容（例如时间、成本、范围和资源）与实际执行情况进行比较。这种对比有助于项目经理评估绩效、识别偏差并做出纠正决策。它突出显示了计划时间表、预算或工作量与实际结果之间的差异。这使得项目进度是超前、按计划进行还是落后于计划变得清晰明了。</p><p>Zoho Projects 支持项目计划VS实际报表也支持全局计划VS实际报表。这个报表可以帮助用户查看一个任务中设置的工作时间和用户在任务中花费的时间。 它按照任务中设置的工作时间和用户在门户中添加的工时日志计算的。</p><p>当您需要评估项目进度或了解所有项目的任务信息时，“全局报告”功能将为您提供极大的帮助。“全局计划与实际”报告就是其中之一，您可以通过它了解各项任务所花费的时间。要查看此报告，请导航至 Zoho Projects 主页中的“全局报告”小部件。</p><p>“全局计划与实际”报告通过区分任务的计划工时和实际工时，提供每个用户的任务工时详情。报告还会显示每项任务的预期工时与实际工时之间的差异。</p><p>例如，门户管理员 李俊 使用“全局计划与实际”报告来了解哪些项目耗时较长。通过该报告，李俊 可以找到用户在所有项目中完成所有任务的总计划工时和实际工时。此外，通过比较每个项目的计划工时和实际工时，他还可以找出耗时较长的项目。</p><p>另外，李俊的老板要求他提供一份关于特定用户在特定项目和时间段内的工作报告。他对报告应用筛选器，并将报告导出为 XLS 文件。借助“全局计划与实际对比”报告，约翰找到了一个快速解决方案，可以生成所有项目的报告，而无需为每个项目单独生成报告。</p>]]></description></item><item>    <title><![CDATA[印度股票数据 PHP 对接文档 覆盖 B]]></title>    <link>https://segmentfault.com/a/1190000047405693</link>    <guid>https://segmentfault.com/a/1190000047405693</guid>    <pubDate>2025-11-17 19:04:18</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>本文档详细介绍如何使用 PHP 语言对接 StockTV 印度股票数据源，覆盖 BSE（孟买证券交易所）和 NSE（印度国家证券交易所）的实时数据。</p><h2>🚀 快速开始</h2><h3>环境要求</h3><ul><li>PHP 7.4+</li><li>cURL 扩展</li><li>JSON 扩展</li><li>网络连接（可访问 <code>api.stocktv.top</code>）</li></ul><h2>🏗️ 核心架构</h2><h3>项目结构</h3><pre><code>src/
├── config/
│   └── StockTVConfig.php
├── models/
│   ├── Stock.php
│   ├── Index.php
│   ├── KLine.php
│   └── ApiResponse.php
├── clients/
│   ├── StockTVHttpClient.php
│   └── StockTVWebSocketClient.php
├── services/
│   └── IndiaStockService.php
└── examples/
    └── IndiaStockDemo.php</code></pre><h2>📦 核心代码实现</h2><h3>1. 配置类</h3><pre><code class="php">&lt;?php
// src/config/StockTVConfig.php

namespace StockTV\Config;

/**
 * StockTV API 配置类
 */
class StockTVConfig
{
    // API 基础配置
    const BASE_URL = 'https://api.stocktv.top';
    const WS_URL = 'wss://ws-api.stocktv.top/connect';
    
    // 印度市场配置
    const INDIA_COUNTRY_ID = 14;
    const NSE_EXCHANGE_ID = 46;
    const BSE_EXCHANGE_ID = 74;
    
    // API 接口路径
    const STOCK_LIST = '/stock/stocks';
    const QUERY_STOCKS = '/stock/queryStocks';
    const STOCKS_BY_PIDS = '/stock/stocksByPids';
    const INDICES = '/stock/indices';
    const INDICES_BY_ID = '/stock/indicesById';
    const KLINE = '/stock/kline';
    const UPDOWN_LIST = '/stock/updownList';
    const GET_IPO = '/stock/getIpo';
    const COMPANIES = '/stock/companies';
    const COMPANY_URL = '/stock/companyUrl';
    const NEWS = '/stock/news';
    
    private $apiKey;
    private $timeout = 30;
    
    public function __construct(string $apiKey)
    {
        $this-&gt;apiKey = $apiKey;
    }
    
    public function getApiKey(): string
    {
        return $this-&gt;apiKey;
    }
    
    public function getTimeout(): int
    {
        return $this-&gt;timeout;
    }
    
    public function setTimeout(int $timeout): self
    {
        $this-&gt;timeout = $timeout;
        return $this;
    }
}</code></pre><h3>2. 数据模型类</h3><h4>股票数据模型</h4><pre><code class="php">&lt;?php
// src/models/Stock.php

namespace StockTV\Models;

/**
 * 印度股票数据模型
 */
class Stock
{
    public $id;
    public $symbol;
    public $name;
    public $last;
    public $chg;
    public $chgPct;
    public $high;
    public $low;
    public $volume;
    public $open;
    public $exchangeId;
    public $countryId;
    public $countryNameTranslated;
    public $flag;
    public $fundamentalMarketCap;
    public $fundamentalRevenue;
    public $technicalDay;
    public $technicalHour;
    public $technicalWeek;
    public $technicalMonth;
    public $performanceDay;
    public $performanceWeek;
    public $performanceMonth;
    public $performanceYtd;
    public $time;
    public $url;
    
    public function __construct(array $data = [])
    {
        foreach ($data as $key =&gt; $value) {
            if (property_exists($this, $key)) {
                $this-&gt;$key = $value;
            }
        }
    }
    
    public function getExchangeName(): string
    {
        if ($this-&gt;exchangeId == \StockTV\Config\StockTVConfig::NSE_EXCHANGE_ID) {
            return 'NSE';
        } elseif ($this-&gt;exchangeId == \StockTV\Config\StockTVConfig::BSE_EXCHANGE_ID) {
            return 'BSE';
        }
        return 'Unknown';
    }
    
    public function isGaining(): bool
    {
        return $this-&gt;chgPct &gt; 0;
    }
    
    public function getFormattedChange(): string
    {
        $sign = $this-&gt;chgPct &gt; 0 ? '+' : '';
        return $sign . number_format($this-&gt;chgPct, 2) . '%';
    }
    
    public function getFormattedPrice(): string
    {
        return '₹' . number_format($this-&gt;last, 2);
    }
}</code></pre><h4>指数数据模型</h4><pre><code class="php">&lt;?php
// src/models/Index.php

namespace StockTV\Models;

/**
 * 指数数据模型
 */
class Index
{
    public $id;
    public $name;
    public $symbol;
    public $last;
    public $chg;
    public $chgPct;
    public $high;
    public $low;
    public $isOpen;
    public $flag;
    public $url;
    public $time;
    
    public function __construct(array $data = [])
    {
        foreach ($data as $key =&gt; $value) {
            if (property_exists($this, $key)) {
                $this-&gt;$key = $value;
            }
        }
    }
    
    public function isGaining(): bool
    {
        return $this-&gt;chgPct &gt; 0;
    }
    
    public function getFormattedChange(): string
    {
        $sign = $this-&gt;chgPct &gt; 0 ? '+' : '';
        return $sign . number_format($this-&gt;chgPct, 2) . '%';
    }
}</code></pre><h4>K线数据模型</h4><pre><code class="php">&lt;?php
// src/models/KLine.php

namespace StockTV\Models;

/**
 * K线数据模型
 */
class KLine
{
    public $time;
    public $open;
    public $high;
    public $low;
    public $close;
    public $volume;
    public $vo;
    
    public function __construct(array $data = [])
    {
        foreach ($data as $key =&gt; $value) {
            if (property_exists($this, $key)) {
                $this-&gt;$key = $value;
            }
        }
    }
    
    public function getAmplitude(): float
    {
        if ($this-&gt;open == 0) {
            return 0;
        }
        return (($this-&gt;high - $this-&gt;low) / $this-&gt;open) * 100;
    }
    
    public function getChangePercent(): float
    {
        if ($this-&gt;open == 0) {
            return 0;
        }
        return (($this-&gt;close - $this-&gt;open) / $this-&gt;open) * 100;
    }
}</code></pre><h4>API响应包装类</h4><pre><code class="php">&lt;?php
// src/models/ApiResponse.php

namespace StockTV\Models;

/**
 * API通用响应包装类
 */
class ApiResponse
{
    public $code;
    public $message;
    public $data;
    
    public function __construct(array $data = [])
    {
        foreach ($data as $key =&gt; $value) {
            if (property_exists($this, $key)) {
                $this-&gt;$key = $value;
            }
        }
    }
    
    public function isSuccess(): bool
    {
        return $this-&gt;code === 200;
    }
}

/**
 * 股票列表响应包装类
 */
class StockListResponse
{
    public $records;
    public $total;
    public $size;
    public $current;
    public $pages;
    
    public function __construct(array $data = [])
    {
        foreach ($data as $key =&gt; $value) {
            if (property_exists($this, $key)) {
                $this-&gt;$key = $value;
            }
        }
        
        // 转换records为Stock对象数组
        if (isset($data['records']) &amp;&amp; is_array($data['records'])) {
            $this-&gt;records = array_map(function($item) {
                return new Stock($item);
            }, $data['records']);
        }
    }
}</code></pre><h3>3. HTTP客户端实现</h3><pre><code class="php">&lt;?php
// src/clients/StockTVHttpClient.php

namespace StockTV\Clients;

use StockTV\Config\StockTVConfig;
use StockTV\Models\ApiResponse;
use StockTV\Models\Stock;
use StockTV\Models\Index;
use StockTV\Models\KLine;
use StockTV\Models\StockListResponse;

/**
 * StockTV HTTP API客户端
 */
class StockTVHttpClient
{
    private $config;
    private $lastResponse;
    
    public function __construct(StockTVConfig $config)
    {
        $this-&gt;config = $config;
    }
    
    /**
     * 获取印度股票列表
     */
    public function getIndiaStocks(int $pageSize = 50, int $page = 1): array
    {
        $params = [
            'countryId' =&gt; StockTVConfig::INDIA_COUNTRY_ID,
            'pageSize' =&gt; $pageSize,
            'page' =&gt; $page,
            'key' =&gt; $this-&gt;config-&gt;getApiKey()
        ];
        
        $response = $this-&gt;makeRequest(StockTVConfig::STOCK_LIST, $params);
        
        if ($response-&gt;isSuccess()) {
            $stockListResponse = new StockListResponse($response-&gt;data);
            return $stockListResponse-&gt;records;
        }
        
        throw new \Exception("获取印度股票列表失败: " . $response-&gt;message);
    }
    
    /**
     * 查询单个股票
     */
    public function queryStock(?int $id = null, ?string $symbol = null, ?string $name = null): array
    {
        $params = ['key' =&gt; $this-&gt;config-&gt;getApiKey()];
        
        if ($id !== null) {
            $params['id'] = $id;
        }
        if ($symbol !== null) {
            $params['symbol'] = $symbol;
        }
        if ($name !== null) {
            $params['name'] = $name;
        }
        
        $response = $this-&gt;makeRequest(StockTVConfig::QUERY_STOCKS, $params);
        
        if ($response-&gt;isSuccess()) {
            return array_map(function($item) {
                return new Stock($item);
            }, $response-&gt;data);
        }
        
        throw new \Exception("查询股票失败: " . $response-&gt;message);
    }
    
    /**
     * 批量查询多个股票
     */
    public function getStocksByPids(array $pids): array
    {
        if (empty($pids)) {
            throw new \InvalidArgumentException("股票PID列表不能为空");
        }
        
        $params = [
            'key' =&gt; $this-&gt;config-&gt;getApiKey(),
            'pids' =&gt; implode(',', $pids)
        ];
        
        $response = $this-&gt;makeRequest(StockTVConfig::STOCKS_BY_PIDS, $params);
        
        if ($response-&gt;isSuccess()) {
            return array_map(function($item) {
                return new Stock($item);
            }, $response-&gt;data);
        }
        
        throw new \Exception("批量查询股票失败: " . $response-&gt;message);
    }
    
    /**
     * 获取印度主要指数
     */
    public function getIndiaIndices(): array
    {
        $params = [
            'countryId' =&gt; StockTVConfig::INDIA_COUNTRY_ID,
            'key' =&gt; $this-&gt;config-&gt;getApiKey()
        ];
        
        $response = $this-&gt;makeRequest(StockTVConfig::INDICES, $params);
        
        if ($response-&gt;isSuccess()) {
            return array_map(function($item) {
                return new Index($item);
            }, $response-&gt;data);
        }
        
        throw new \Exception("获取印度指数失败: " . $response-&gt;message);
    }
    
    /**
     * 通过ID查询特定指数
     */
    public function getIndexById(int $id): array
    {
        $params = [
            'id' =&gt; $id,
            'key' =&gt; $this-&gt;config-&gt;getApiKey()
        ];
        
        $response = $this-&gt;makeRequest(StockTVConfig::INDICES_BY_ID, $params);
        
        if ($response-&gt;isSuccess()) {
            return array_map(function($item) {
                return new Index($item);
            }, $response-&gt;data);
        }
        
        throw new \Exception("获取指数失败: " . $response-&gt;message);
    }
    
    /**
     * 获取K线数据
     */
    public function getKLineData(int $pid, string $interval): array
    {
        $params = [
            'pid' =&gt; $pid,
            'interval' =&gt; $interval,
            'key' =&gt; $this-&gt;config-&gt;getApiKey()
        ];
        
        $response = $this-&gt;makeRequest(StockTVConfig::KLINE, $params);
        
        if ($response-&gt;isSuccess()) {
            return array_map(function($item) {
                return new KLine($item);
            }, $response-&gt;data);
        }
        
        throw new \Exception("获取K线数据失败: " . $response-&gt;message);
    }
    
    /**
     * 获取涨跌排行榜
     */
    public function getUpDownList(int $type): array
    {
        $params = [
            'countryId' =&gt; StockTVConfig::INDIA_COUNTRY_ID,
            'type' =&gt; $type,
            'key' =&gt; $this-&gt;config-&gt;getApiKey()
        ];
        
        $response = $this-&gt;makeRequest(StockTVConfig::UPDOWN_LIST, $params);
        
        if ($response-&gt;isSuccess()) {
            return array_map(function($item) {
                return new Stock($item);
            }, $response-&gt;data);
        }
        
        throw new \Exception("获取排行榜失败: " . $response-&gt;message);
    }
    
    /**
     * 获取IPO数据
     */
    public function getIpoList(?int $type = null): array
    {
        $params = [
            'countryId' =&gt; StockTVConfig::INDIA_COUNTRY_ID,
            'key' =&gt; $this-&gt;config-&gt;getApiKey()
        ];
        
        if ($type !== null) {
            $params['type'] = $type;
        }
        
        $response = $this-&gt;makeRequest(StockTVConfig::GET_IPO, $params);
        
        if ($response-&gt;isSuccess()) {
            return $response-&gt;data;
        }
        
        throw new \Exception("获取IPO数据失败: " . $response-&gt;message);
    }
    
    /**
     * 通用HTTP请求方法
     */
    private function makeRequest(string $endpoint, array $params = []): ApiResponse
    {
        $url = StockTVConfig::BASE_URL . $endpoint . '?' . http_build_query($params);
        
        $ch = curl_init();
        curl_setopt_array($ch, [
            CURLOPT_URL =&gt; $url,
            CURLOPT_RETURNTRANSFER =&gt; true,
            CURLOPT_TIMEOUT =&gt; $this-&gt;config-&gt;getTimeout(),
            CURLOPT_HTTPHEADER =&gt; [
                'Content-Type: application/json',
                'User-Agent: StockTV-PHP-Client/1.0'
            ]
        ]);
        
        $response = curl_exec($ch);
        $httpCode = curl_getinfo($ch, CURLINFO_HTTP_CODE);
        $error = curl_error($ch);
        curl_close($ch);
        
        if ($error) {
            throw new \Exception("HTTP请求失败: " . $error);
        }
        
        if ($httpCode !== 200) {
            throw new \Exception("HTTP请求失败，状态码: " . $httpCode);
        }
        
        $data = json_decode($response, true);
        if (json_last_error() !== JSON_ERROR_NONE) {
            throw new \Exception("JSON解析失败: " . json_last_error_msg());
        }
        
        $this-&gt;lastResponse = $data;
        return new ApiResponse($data);
    }
    
    /**
     * 获取最后一次响应数据
     */
    public function getLastResponse(): ?array
    {
        return $this-&gt;lastResponse;
    }
}</code></pre><h3>4. WebSocket客户端实现</h3><pre><code class="php">&lt;?php
// src/clients/StockTVWebSocketClient.php

namespace StockTV\Clients;

use StockTV\Config\StockTVConfig;
use Ratchet\Client\WebSocket;
use Ratchet\Client\Connector;
use React\EventLoop\Factory;
use React\Socket\Connector as ReactConnector;

/**
 * StockTV WebSocket实时数据客户端
 */
class StockTVWebSocketClient
{
    private $config;
    private $loop;
    private $connector;
    private $webSocket;
    private $callbacks;
    
    public function __construct(StockTVConfig $config)
    {
        $this-&gt;config = $config;
        $this-&gt;loop = Factory::create();
        $this-&gt;connector = new Connector($this-&gt;loop);
        $this-&gt;callbacks = [
            'message' =&gt; [],
            'error' =&gt; [],
            'close' =&gt; []
        ];
    }
    
    /**
     * 连接WebSocket服务器
     */
    public function connect(): void
    {
        $wsUrl = StockTVConfig::WS_URL . '?key=' . $this-&gt;config-&gt;getApiKey();
        
        $this-&gt;connector-&gt;__invoke($wsUrl)
            -&gt;then(function(WebSocket $conn) {
                $this-&gt;webSocket = $conn;
                $this-&gt;onOpen($conn);
                
                $conn-&gt;on('message', function($msg) use ($conn) {
                    $this-&gt;onMessage($conn, $msg);
                });
                
                $conn-&gt;on('close', function($code = null, $reason = null) use ($conn) {
                    $this-&gt;onClose($conn, $code, $reason);
                });
                
            }, function(\Exception $e) {
                $this-&gt;onError($e);
            });
    }
    
    /**
     * 启动事件循环
     */
    public function run(): void
    {
        $this-&gt;loop-&gt;run();
    }
    
    /**
     * 停止事件循环
     */
    public function stop(): void
    {
        if ($this-&gt;loop) {
            $this-&gt;loop-&gt;stop();
        }
    }
    
    /**
     * 连接建立回调
     */
    private function onOpen(WebSocket $conn): void
    {
        echo "WebSocket连接已建立\n";
    }
    
    /**
     * 消息接收回调
     */
    private function onMessage(WebSocket $conn, $msg): void
    {
        $data = json_decode($msg, true);
        if (json_last_error() !== JSON_ERROR_NONE) {
            echo "JSON解析失败: " . json_last_error_msg() . "\n";
            return;
        }
        
        $this-&gt;handleRealTimeData($data);
        
        // 执行用户定义的回调
        foreach ($this-&gt;callbacks['message'] as $callback) {
            call_user_func($callback, $data);
        }
    }
    
    /**
     * 连接关闭回调
     */
    private function onClose(WebSocket $conn, $code, $reason): void
    {
        echo "WebSocket连接已关闭: code={$code}, reason={$reason}\n";
        
        foreach ($this-&gt;callbacks['close'] as $callback) {
            call_user_func($callback, $code, $reason);
        }
    }
    
    /**
     * 错误回调
     */
    private function onError(\Exception $e): void
    {
        echo "WebSocket连接错误: " . $e-&gt;getMessage() . "\n";
        
        foreach ($this-&gt;callbacks['error'] as $callback) {
            call_user_func($callback, $e);
        }
    }
    
    /**
     * 处理实时数据
     */
    private function handleRealTimeData(array $data): void
    {
        if (isset($data['pid'])) {
            $symbol = $data['symbol'] ?? $data['pid'];
            $price = $data['last_numeric'] ?? 'N/A';
            $changePercent = $data['pcp'] ?? '0';
            
            echo "实时行情: {$symbol} - 价格: {$price}, 涨跌幅: {$changePercent}%\n";
            
            // 价格预警逻辑
            $changePercentNum = floatval($changePercent);
            if (abs($changePercentNum) &gt; 2.0) {
                echo "🚨 价格波动预警: {$symbol} 波动 {$changePercentNum}%\n";
            }
        }
    }
    
    /**
     * 添加消息回调
     */
    public function onMessageCallback(callable $callback): self
    {
        $this-&gt;callbacks['message'][] = $callback;
        return $this;
    }
    
    /**
     * 添加错误回调
     */
    public function onErrorCallback(callable $callback): self
    {
        $this-&gt;callbacks['error'][] = $callback;
        return $this;
    }
    
    /**
     * 添加关闭回调
     */
    public function onCloseCallback(callable $callback): self
    {
        $this-&gt;callbacks['close'][] = $callback;
        return $this;
    }
    
    /**
     * 发送消息
     */
    public function send(string $message): void
    {
        if ($this-&gt;webSocket) {
            $this-&gt;webSocket-&gt;send($message);
        }
    }
    
    /**
     * 关闭连接
     */
    public function close(): void
    {
        if ($this-&gt;webSocket) {
            $this-&gt;webSocket-&gt;close();
        }
        $this-&gt;stop();
    }
}</code></pre><h3>5. 服务层封装</h3><pre><code class="php">&lt;?php
// src/services/IndiaStockService.php

namespace StockTV\Services;

use StockTV\Config\StockTVConfig;
use StockTV\Clients\StockTVHttpClient;
use StockTV\Clients\StockTVWebSocketClient;
use StockTV\Models\Stock;
use StockTV\Models\Index;
use StockTV\Models\KLine;

/**
 * 印度股票数据服务
 */
class IndiaStockService
{
    private $httpClient;
    private $wsClient;
    
    public function __construct(string $apiKey)
    {
        $config = new StockTVConfig($apiKey);
        $this-&gt;httpClient = new StockTVHttpClient($config);
        $this-&gt;wsClient = new StockTVWebSocketClient($config);
    }
    
    /**
     * 获取Nifty 50成分股
     */
    public function getNifty50Stocks(): array
    {
        try {
            $stocks = $this-&gt;httpClient-&gt;getIndiaStocks(50, 1);
            echo "成功获取 " . count($stocks) . " 只印度股票\n";
            return $stocks;
        } catch (\Exception $e) {
            echo "获取Nifty 50成分股失败: " . $e-&gt;getMessage() . "\n";
            throw $e;
        }
    }
    
    /**
     * 获取印度主要指数
     */
    public function getMajorIndices(): array
    {
        try {
            $indices = $this-&gt;httpClient-&gt;getIndiaIndices();
            echo "成功获取 " . count($indices) . " 个印度指数\n";
            return $indices;
        } catch (\Exception $e) {
            echo "获取印度指数失败: " . $e-&gt;getMessage() . "\n";
            throw $e;
        }
    }
    
    /**
     * 查询特定股票
     */
    public function getStockBySymbol(string $symbol): ?Stock
    {
        try {
            $stocks = $this-&gt;httpClient-&gt;queryStock(null, $symbol, null);
            if (empty($stocks)) {
                echo "未找到股票: {$symbol}\n";
                return null;
            }
            echo "查询股票 {$symbol} 成功\n";
            return $stocks[0];
        } catch (\Exception $e) {
            echo "查询股票失败: {$symbol} - " . $e-&gt;getMessage() . "\n";
            throw $e;
        }
    }
    
    /**
     * 批量查询股票
     */
    public function getStocksBySymbols(array $symbols): array
    {
        $results = [];
        foreach ($symbols as $symbol) {
            try {
                $stock = $this-&gt;getStockBySymbol($symbol);
                if ($stock) {
                    $results[] = $stock;
                }
            } catch (\Exception $e) {
                // 单个股票查询失败，继续处理其他股票
                continue;
            }
        }
        echo "批量查询成功，获取 " . count($results) . " 只股票\n";
        return $results;
    }
    
    /**
     * 获取股票K线数据
     */
    public function getStockKLine(int $pid, string $interval): array
    {
        try {
            $klines = $this-&gt;httpClient-&gt;getKLineData($pid, $interval);
            echo "成功获取股票 {$pid} 的K线数据，共 " . count($klines) . " 条\n";
            return $klines;
        } catch (\Exception $e) {
            echo "获取K线数据失败: pid={$pid} - " . $e-&gt;getMessage() . "\n";
            throw $e;
        }
    }
    
    /**
     * 获取涨幅榜
     */
    public function getGainers(): array
    {
        try {
            $gainers = $this-&gt;httpClient-&gt;getUpDownList(1);
            echo "成功获取涨幅榜，共 " . count($gainers) . " 只股票\n";
            return $gainers;
        } catch (\Exception $e) {
            echo "获取涨幅榜失败: " . $e-&gt;getMessage() . "\n";
            throw $e;
        }
    }
    
    /**
     * 获取跌幅榜
     */
    public function getLosers(): array
    {
        try {
            $losers = $this-&gt;httpClient-&gt;getUpDownList(2);
            echo "成功获取跌幅榜，共 " . count($losers) . " 只股票\n";
            return $losers;
        } catch (\Exception $e) {
            echo "获取跌幅榜失败: " . $e-&gt;getMessage() . "\n";
            throw $e;
        }
    }
    
    /**
     * 获取IPO数据
     */
    public function getUpcomingIPOs(): array
    {
        try {
            $ipos = $this-&gt;httpClient-&gt;getIpoList(1); // 1表示未上市
            echo "成功获取IPO数据，共 " . count($ipos) . " 个\n";
            return $ipos;
        } catch (\Exception $e) {
            echo "获取IPO数据失败: " . $e-&gt;getMessage() . "\n";
            throw $e;
        }
    }
    
    /**
     * 启动实时数据监控
     */
    public function startRealTimeMonitoring(): void
    {
        try {
            // 添加消息处理回调
            $this-&gt;wsClient-&gt;onMessageCallback(function($data) {
                $this-&gt;handleRealTimeData($data);
            });
            
            $this-&gt;wsClient-&gt;connect();
            echo "实时数据监控已启动\n";
            
            // 启动事件循环
            $this-&gt;wsClient-&gt;run();
            
        } catch (\Exception $e) {
            echo "启动实时数据监控失败: " . $e-&gt;getMessage() . "\n";
            throw $e;
        }
    }
    
    /**
     * 处理实时数据
     */
    private function handleRealTimeData(array $data): void
    {
        if (isset($data['pid'])) {
            $symbol = $data['symbol'] ?? $data['pid'];
            $price = $data['last_numeric'] ?? 'N/A';
            $changePercent = $data['pcp'] ?? '0';
            
            $trend = floatval($changePercent) &gt;= 0 ? '📈' : '📉';
            echo "{$trend} 实时行情: {$symbol} - 价格: ₹{$price}, 涨跌幅: {$changePercent}%\n";
            
            // 价格预警逻辑
            $changePercentNum = floatval($changePercent);
            if (abs($changePercentNum) &gt; 5.0) {
                echo "🚨 大幅波动预警: {$symbol} 波动 {$changePercentNum}%\n";
            }
        }
    }
    
    /**
     * 停止实时数据监控
     */
    public function stopRealTimeMonitoring(): void
    {
        $this-&gt;wsClient-&gt;close();
        echo "实时数据监控已停止\n";
    }
}</code></pre><h3>6. 使用示例</h3><pre><code class="php">&lt;?php
// examples/IndiaStockDemo.php

require_once __DIR__ . '/../vendor/autoload.php';

use StockTV\Services\IndiaStockService;
use StockTV\Models\Stock;
use StockTV\Models\Index;

/**
 * 印度股票数据使用示例
 */
class IndiaStockDemo
{
    private $stockService;
    
    public function __construct(string $apiKey)
    {
        $this-&gt;stockService = new IndiaStockService($apiKey);
    }
    
    public function runDemo(): void
    {
        echo "=== StockTV 印度股票数据演示程序开始 ===\n\n";
        
        try {
            // 1. 获取印度主要指数
            $this-&gt;demonstrateIndices();
            
            // 2. 查询特定股票
            $this-&gt;demonstrateStockQuery();
            
            // 3. 获取Nifty 50成分股示例
            $this-&gt;demonstrateNifty50();
            
            // 4. 获取K线数据
            $this-&gt;demonstrateKLineData();
            
            // 5. 获取排行榜
            $this-&gt;demonstrateRankings();
            
            echo "\n=== 演示程序执行完成 ===\n";
            
        } catch (Exception $e) {
            echo "演示程序执行失败: " . $e-&gt;getMessage() . "\n";
        }
    }
    
    /**
     * 演示指数数据获取
     */
    private function demonstrateIndices(): void
    {
        echo "1. 印度主要指数\n";
        echo str_repeat("-", 50) . "\n";
        
        $indices = $this-&gt;stockService-&gt;getMajorIndices();
        
        foreach ($indices as $index) {
            $trend = $index-&gt;isGaining() ? '📈' : '📉';
            $changeSign = $index-&gt;isGaining() ? '+' : '';
            
            echo "{$trend} {$index-&gt;name}: {$index-&gt;last} ";
            echo "({$changeSign}{$index-&gt;chgPct}%)\n";
        }
        echo "\n";
    }
    
    /**
     * 演示股票查询
     */
    private function demonstrateStockQuery(): void
    {
        echo "2. 查询特定股票\n";
        echo str_repeat("-", 50) . "\n";
        
        // 查询Reliance Industries
        $reliance = $this-&gt;stockService-&gt;getStockBySymbol('RELIANCE');
        $this-&gt;printStockInfo($reliance, 'Reliance Industries');
        
        // 查询TCS
        $tcs = $this-&gt;stockService-&gt;getStockBySymbol('TCS');
        $this-&gt;printStockInfo($tcs, 'Tata Consultancy Services');
        
        echo "\n";
    }
    
    /**
     * 演示Nifty 50成分股
     */
    private function demonstrateNifty50(): void
    {
        echo "3. Nifty 50成分股（示例）\n";
        echo str_repeat("-", 50) . "\n";
        
        $niftyStocks = $this-&gt;stockService-&gt;getNifty50Stocks();
        
        // 显示前10只股票
        $count = 0;
        foreach ($niftyStocks as $stock) {
            if ($count &gt;= 10) break;
            
            $trend = $stock-&gt;isGaining() ? '🟢' : '🔴';
            $changeSign = $stock-&gt;isGaining() ? '+' : '';
            
            echo "{$trend} {$stock-&gt;symbol}: ₹{$stock-&gt;last} ";
            echo "({$changeSign}{$stock-&gt;chgPct}%) - {$stock-&gt;name}\n";
            
            $count++;
        }
        echo "\n";
    }
    
    /**
     * 演示K线数据获取
     */
    private function demonstrateKLineData(): void
    {
        echo "4. K线数据示例\n";
        echo str_repeat("-", 50) . "\n";
        
        $reliance = $this-&gt;stockService-&gt;getStockBySymbol('RELIANCE');
        if ($reliance) {
            $klines = $this-&gt;stockService-&gt;getStockKLine($reliance-&gt;id, 'P1D');
            
            echo "Reliance Industries 近期日K线数据:\n";
            $count = 0;
            foreach ($klines as $kline) {
                if ($count &gt;= 5) break;
                
                $date = date('Y-m-d H:i:s', $kline-&gt;time / 1000);
                $amplitude = number_format($kline-&gt;getAmplitude(), 2);
                
                echo "时间: {$date}, 开: ₹{$kline-&gt;open}, ";
                echo "高: ₹{$kline-&gt;high}, 低: ₹{$kline-&gt;low}, ";
                echo "收: ₹{$kline-&gt;close}, 振幅: {$amplitude}%\n";
                
                $count++;
            }
        }
        echo "\n";
    }
    
    /**
     * 演示排行榜功能
     */
    private function demonstrateRankings(): void
    {
        echo "5. 市场排行榜\n";
        echo str_repeat("-", 50) . "\n";
        
        // 获取涨幅榜
        $gainers = $this-&gt;stockService-&gt;getGainers();
        echo "📈 今日涨幅榜（前5）:\n";
        $count = 0;
        foreach ($gainers as $stock) {
            if ($count &gt;= 5) break;
            
            $changeSign = $stock-&gt;isGaining() ? '+' : '';
            echo "   {$stock-&gt;symbol}: ₹{$stock-&gt;last} ";
            echo "({$changeSign}{$stock-&gt;chgPct}%) - {$stock-&gt;name}\n";
            
            $count++;
        }
        
        echo "\n";
        
        // 获取跌幅榜
        $losers = $this-&gt;stockService-&gt;getLosers();
        echo "📉 今日跌幅榜（前5）:\n";
        $count = 0;
        foreach ($losers as $stock) {
            if ($count &gt;= 5) break;
            
            echo "   {$stock-&gt;symbol}: ₹{$stock-&gt;last} ";
            echo "({$stock-&gt;chgPct}%) - {$stock-&gt;name}\n";
            
            $count++;
        }
        echo "\n";
    }
    
    /**
     * 打印股票信息
     */
    private function printStockInfo(?Stock $stock, string $description): void
    {
        if ($stock) {
            $status = $stock-&gt;open ? '🟢 交易中' : '🔴 已收盘';
            $trend = $stock-&gt;isGaining() ? '📈' : '📉';
            
            echo "{$trend} {$description} - {$status}\n";
            echo "   代码: {$stock-&gt;symbol} | 价格: ₹{$stock-&gt;last}\n";
            echo "   涨跌: ₹{$stock-&gt;chg} ({$stock-&gt;getFormattedChange()})\n";
            echo "   最高: ₹{$stock-&gt;high} | 最低: ₹{$stock-&gt;low} | 成交量: {$stock-&gt;volume}\n";
            
            if ($stock-&gt;technicalDay) {
                $techName = $this-&gt;getTechnicalIndicatorName($stock-&gt;technicalDay);
                echo "   技术指标: {$techName}\n";
            }
        }
        echo "\n";
    }
    
    /**
     * 获取技术指标中文名称
     */
    private function getTechnicalIndicatorName(string $indicator): string
    {
        $map = [
            'strong_buy' =&gt; '强烈买入',
            'buy' =&gt; '买入',
            'neutral' =&gt; '中性',
            'sell' =&gt; '卖出',
            'strong_sell' =&gt; '强烈卖出'
        ];
        
        return $map[$indicator] ?? $indicator;
    }
}

// 运行演示程序
$apiKey = '您的API_KEY'; // 替换为实际的API Key

$demo = new IndiaStockDemo($apiKey);
$demo-&gt;runDemo();</code></pre><h2>🎯 高级功能</h2><h3>实时价格监控器</h3><pre><code class="php">&lt;?php
// examples/PriceMonitor.php
</code></pre>]]></description></item><item>    <title><![CDATA[【赵渝强老师】达梦数据库的事务隔离级别 ]]></title>    <link>https://segmentfault.com/a/1190000047405731</link>    <guid>https://segmentfault.com/a/1190000047405731</guid>    <pubDate>2025-11-17 19:03:22</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>达梦数据库允许多个客户端同时访问。当这些客户端并发访问数据库中同一部分的数据时，如果没有采取必要的隔离措施就容易造成并发一致性问题，从而破坏数据的完整性。考虑下图中的场景：<br/><img width="723" height="276" referrerpolicy="no-referrer" src="/img/bVdm3K4" alt="image.png" title="image.png"/></p><p>在时间点1上，var的数值是100。客户端A在时间点2的时候更新了它的值为200，但没有提交事务。在时间点3的时候，客户端B读取到了客户端A还未提交的数值200。但在时间点4，客户端A执行了回滚操作。那么，对于客户端B来说，如果在时间点5再次读取数据，得到就应该是100。那么客户端B就有了数据不一致的问题。而造成问题的根本原因在，客户端B读取到了客户端A还没有提交的事务中的数据。</p><p>为了解决数据在并发访问时，数据的一致性问题。在SQL标准中定义了四种事务的隔离级别，它们分别是：读未提交（READ-UNCOMMITTED）、读已提交（READ-COMMITTED）、可重复读（REPEATABLE-READ）和可序列化读（SERIALIZABLE）。<br/>达梦数据库支持三种事务隔离级别：读未提交（READ-UNCOMMITTED）、读提交（READ-COMMITTED）和串行化（SERIALIZABLE）。其中，读提交是DM 数据库默认使用的事务隔离级别，可重复读升级为更严格的串行化隔离级。</p><p>视频讲解如下：<br/><a href="https://www.bilibili.com/video/BV1EACiBuEq6/?aid=115563779069332&amp;cid=34063516477" target="_blank">https://www.bilibili.com/video/BV1EACiBuEq6/?aid=115563779069...</a></p><p>在达梦数据库中要查看默认的事务隔离级别，可以通过下面的方式来获取。<br/>（1）使用管理员登录数据库。</p><pre><code class="sql">SQL&gt; conn sysdba/Welcome_1</code></pre><p>（2）执行下面的语句获取事务的隔离级别。</p><pre><code class="sql">SQL&gt; select para_name,para_value,
    case para_value
        when 1 then 'Read Commited'
        when 3 then 'Serializable'
        else 'None'
    end as "隔离级别"
    from v$dm_ini where para_name='ISOLATION_LEVEL';

# 输出的信息如下：
行号     PARA_NAME       PARA_VALUE     隔离级别 
------ --------------- ---------- -------------
1       ISOLATION_LEVEL     1              Read Commited

# 从输出的信息可以看出，DM数据库默认的事务隔离级别是读已提交（READ-COMMITTED）。</code></pre><p>数据库在不同的事务隔离级别下会有不同的行为，从而在并发访问数据的时候会带来不同的问题。下表列举了在不同的SQL标准事务隔离级别下，数据库可能存在的不同问题。<br/><img width="723" height="146" referrerpolicy="no-referrer" src="/img/bVdm3Lj" alt="image.png" title="image.png" loading="lazy"/></p><p>由于达梦数据库默认的事务隔离级别是读已提交（READ-COMMITTED），因此在达梦数据库中默认是不存在脏读问题的。</p>]]></description></item><item>    <title><![CDATA[Data Agent 精选推荐：Alou]]></title>    <link>https://segmentfault.com/a/1190000047405735</link>    <guid>https://segmentfault.com/a/1190000047405735</guid>    <pubDate>2025-11-17 19:02:30</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>摘要</h2><p>在数据量爆炸式增长与业务决策实时性要求提升的双重驱动下，Data Agent（数据智能体）正从辅助工具向企业核心数据分析中枢演进。其通过融合大模型能力与数据管理和分析技术，为企业提供“对话即分析”、“自动找根因”、“一键生成报告”等智能化数据分析服务，推动“人人都是分析师”的愿景落地。</p><p>本文聚焦 Data Agent 的发展趋势与市场需求，重点推荐面向企业的 Aloudata Agent 分析决策智能体——它以“智能问数、智能归因、报告生成”三大核心能力，为企业构建可信智能 Data Agent，助力企业实现 AI 驱动的数据洞察与敏捷决策，是企业数智化转型的优选方案。</p><h2>前言：当数据分析遇上 AI，Data Agent 为何成为新焦点？</h2><p>随着企业数智化转型的深入，数据已成为核心生产要素，但传统数据分析模式却面临严峻挑战：业务人员依赖 IT 部门取数，平均响应周期长达数天；海量数据中隐藏的业务关联难以快速挖掘；管理层需要决策支持时，往往因报告滞后错失商机。</p><p>与此同时，大语言模型（LLM）的突破为数据分析带来了革命性变化——通过自然语言对话直接获取洞察，让非技术人员也能“对话数据”。在此背景下，Data Agent（数据智能体）应运而生。作为连接用户需求与数据系统的“智能中介”，它不仅能理解自然语言指令，更能自动完成数据查询、关联分析、根因定位、可视化呈现等复杂任务，成为企业数据分析的“AI 专家”。</p><p>据 IDC 预测，到 2026 年，将有 50% 的中国 500 强数据团队使用 AI Agent来实现数据准备和分析。而在这场变革中，Aloudata Agent 分析决策智能体凭借对企业级场景的深度适配，正成为市场中的标杆产品。</p><h3>推荐理由一：智能问数——让“开口即得”取代“提需求排队”</h3><p>传统数据分析流程中，业务人员需先梳理需求→提交 IT 或数据团队→等待 SQL 编写与数据提取→再解读结果，链路长且效率低。Aloudata Agent 的核心突破在于深度优化了“企业级语义理解”。其通过采用了“NoETL 明细语义层 + 多 Agent 协同”架构，创新 NL2MQL2SQL 技术路径，提供了全面、丰富的指标语义知识库，确保基于用户问数意图对齐指标语义，实现精准的指标与维度召回，保障数据完整性和口径一致性，避免了“问 A 得 B”的常见错误。</p><p>当用户输入问题，其能够准确识别用户查询目标，精准理解业务意图，生成指标语义查询 MQL，再通过指标语义引擎将 MQL 自动转化为可执行的 SQL 语句，实现 100% 准确的 SQL 查询和物化加速，最后由大模型将数据结果转化为易于理解的洞察语言和图表报告。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405737" alt="图片" title="图片"/></p><p>例如，用户只需通过日常语言提问，如“Q3 华东区销售额同比下滑的原因是什么？”“哪些客户的复购率提升了但客单价下降了？”，Aloudata Agent 即可自动解析意图、生成指标语义查询 MQL、转化为 SQL 查询，并以图表或简报形式返回答案。</p><h3>推荐理由二：智能归因——从“数据堆砌”到“根因定位”的质变</h3><p>数据分析的价值不仅在于呈现“发生了什么”，更在于回答“为什么发生”以及“如何应对”。然而，面对海量关联数据，人工定位根因往往依赖经验猜测，效率低且易遗漏关键因素。</p><p>Aloudata Agent 的“智能归因”功能，包括“维度归因”和“因子归因”两大路径：</p><p>1、维度归因：用于识别影响目标指标的关键业务维度，通过维度下钻与贡献度计算，量化各维度对整体变化或差异的贡献权重，帮助用户锁定问题焦点。例如，分析“门店 A 与门店 B 的业绩差距”时，可自动归因于客群结构、促销策略等维度；</p><p>2、因子归因：聚焦驱动指标变动的关联因子，通过指标间的计算逻辑与影响路径，识别哪些前置因子的变化是导致最终结果差异的根本动因，从而提供更具操作性的改进方向。例如，识别“GMV 增长”的主要驱动因素是产品类目、会员等级还是渠道类型。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405738" alt="图片" title="图片" loading="lazy"/></p><p>这种“从现象到本质”的智能归因分析，不仅能够帮助业务团队快速聚焦关键问题，更将归因分析的效率提升数倍。例如，原本需要多人在数周内完成的根因分析工作，现在通过 Aloudata Agent 可在 1 天内输出完整报告，且结论的可信度更高。</p><h3>推荐理由三：报告生成——从“人工撰写”到“一键智能输出”的效率革命</h3><p>定期生成经营分析报告（如日报、周报、月报）是企业数据团队的常规工作，但这类任务往往重复性强、格式固定，占用大量人力。Aloudata Agent 的“报告生成”功能，支持用户通过自然语言指定报告目标，例如，“生成 Q3 销售业绩分析报告，重点突出区域差异与渠道贡献”，Aloudata Agent 即可自动整合多维数据、按逻辑框架组织内容，并生成图文并茂报告文档。</p><p>更关键的是，报告内容并非简单的数据堆砌，而是基于 AI 的“业务视角解读”，整合趋势、对比、归因结论，包含数据结果查询、异常发现、归因、对比与改善措施建议的结构化内容，将数据洞察转化为可执行的业务动作。</p><p>这对于分析师而言，以前写报告要花数个小时，现在基于 Aloudata Agent 显著提升撰写效率，并能够直接标出了“需关注事项”和“优化建议”等关键信息，极大简化了工作任务，实现敏捷决策。</p><h2>总结：Aloudata Agent——企业级 AI 数据分析的“专家级伙伴”</h2><p>在 Data Agent 加速渗透企业级市场的趋势下，核心需求已从“能查数据”升级为“能懂业务、能解决问题、能驱动决策”。Aloudata Agent 分析决策智能体正是这一需求的典型代表：它以“智能问数”降低数据分析门槛，让全员参与洞察；以“智能归因”挖掘数据背后的因果逻辑，提升决策精准度；以“报告生成”自动化重复工作，释放专业团队价值。</p><p>随着企业对“全员数据素养”的要求越来越高，像 Aloudata Agent 这样的智能体将成为数据驱动决策的关键工具。它不仅是技术的创新，更是企业数据分析范式的革新，让“人人都是分析师”不再是一句口号，而是触手可及的现实。访问 Aloudata Agent 产品官网，一起贴近更智能的数据未来。</p><h2>适用对象：</h2><p>希望实现自然语言问数、AI 数据分析，推进数据民主化，提升数据交付敏捷性，让一线业务能够减少对数据开发的依赖，自主开展全面、灵活、智能、安全问数，覆盖金融（银行、证券）、制造、消费、零售、交通、能源、医疗、航空航天、互联网、ICT、政企等行业领域。</p><h2>权威认可：</h2><ul><li>IDC：2025 IDC 中国面向生成式 AI 的数据基础设核心厂商、数据流管理（Data Flow Agent）代表厂商；2024 IDC「GenAI+Data」中国市场代表厂商</li><li>Gartner：2024 中国代表性数据基础设施供应商、中国数据编织代表厂商和数据资产管理代表厂商</li><li>信通院：2024《数据智能产业图谱》-数据智能基础设施企业、数据治理企业、数据智能开发企业代表</li><li>爱分析：2025 AI Agent 对话式智能分析核心厂商</li><li>数据猿：2025 中国数智化转型升级创新服务企业</li></ul>]]></description></item><item>    <title><![CDATA[阿尔特携手 Amazon AgentCo]]></title>    <link>https://segmentfault.com/a/1190000047405755</link>    <guid>https://segmentfault.com/a/1190000047405755</guid>    <pubDate>2025-11-17 19:01:59</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img width="723" height="160" referrerpolicy="no-referrer" src="/img/bVdkFLr" alt="image.png" title="image.png"/></p><h2>关于Monus AI</h2><p>Monus AI是由南京阿尔特科技推出的一款专注于消费决策的AI搜索应用，在搜索垂类工具中表现领先。该产品核心功能包括规格级比价、虚假软广识别、商品对比和智能对话，致力于在购物前为用户提供高效、可信的决策支持。通过6大智能体体系和返利体系，Monus AI不仅帮助用户省钱，还能让用户在消费过程中“赚钱”。无论是搜索“程序员AI开发电脑”还是查询“Pampers湿纸巾最低价”，它都始终围绕“信任+效率”重塑消费搜索体验。</p><p><img width="723" height="251" referrerpolicy="no-referrer" src="/img/bVdm2TV" alt="image.png" title="image.png" loading="lazy"/></p><h3>什么是 Amazon Bedrock AgentCore？</h3><p>Amazon Bedrock AgentCore 提供专为Agent工作负载构建的基础设施、可增强Agent功能的强大工具，以及适用于现实部署场景的基础组件。AgentCore 服务可以组合使用，也可以单独使用。该服务兼容多种Agent框架（包括 CrewAI、LangGraph、LlamaIndex 和 Strands Agents 等），并支持 Amazon Bedrock提供的多种模型，为 Agent 带来极大的灵活性。AgentCore 消除了构建专用Agent基础设施时千篇一律的繁重工作，可以加快 Agent 从研发进入生产的过程。</p><h3>场景挑战</h3><p>在电商AI搜索领域，用户和系统面临多重核心挑战，特别是需求表达与匹配的断层。具体挑战包括：</p><p>（1）用户不同购买决策时期的识别</p><p>用户在购物过程中，处于不同的购买决策期，需求和关注点差异显著。多模态输入（文字、语音、图片）的准确理解及决策时期判别至关重要。需求萌芽期的用户更需要全面的指导和信息，帮助形成购买意向；而决策后期的用户则更加关注优惠促销和售后保障。对这些时期的精准识别能够实现针对性服务和优化用户体验。</p><p>（2）多平台商品规格同义不同名问题</p><p>跨平台商品信息孤立，用户需在不同电商平台间切换对比价格和评价，且常遭遇虚假软广和冗余信息扰乱，筛选有效信息耗时且低效。更复杂的是，不同平台采用各自独特的商品规格命名规则，导致“同义不同名”现象普遍存在，严重阻碍了规格级颗粒度的实时比价和精准匹配，给系统带来了极大挑战。</p><p>（3）用户画像与商品推理匹配度不足</p><p>传统推荐系统主要依赖用户的行为数据进行相似商品推荐，泛化能力和关联推理能力有限，难以有效捕获用户日常生活中的跨品类兴趣和潜在需求。这导致推荐结果同质化严重，无法做到用户需求的深度理解和精准满足，影响用户满意度和转化率。</p><p>针对上述挑战，电商AI搜索系统需具备精准的决策期识别能力，高效处理跨平台异构商品数据，并强化用户画像与商品间的智能推理匹配能力，才能提供真正个性化、连贯且高效的消费决策支持。</p><h3>解决方案</h3><p>Monus AI采用自研的多模态融合输入技术，可同时高效处理文字、语音、图片三种类型的用户输入，打破传统搜索的输入局限。更具创新性的是，系统引入 “消费决策时期判断” 机制，通过深度学习模型分析用户输入的语义特征与情感倾向，能准确识别用户当前处于需求萌芽、信息收集还是购买决策阶段，该判断的匹配度高达 94%，为后续精准服务奠定基础。</p><p><img width="723" height="797" referrerpolicy="no-referrer" src="/img/bVdm2Va" alt="image.png" title="image.png" loading="lazy"/></p><ul><li>第一级：决策洞察智能体体系– 深度结合 AgentCore Memory 基于 UserPreferenceMemory 策略存储的用户偏好数据，实时分析用户搜索请求的复杂度，同时判断用户决策的紧迫性，为后续处理流程设定优先级。</li><li>第二级：智能匹配智能体体系– 基于用户历史购物偏好、浏览记录等数据，动态调整商品与搜索内容的匹配权重，确保优先呈现与用户需求高度契合的信息。</li><li>第三级：语义压缩智能体体系 – 采用先进的语义编码算法，在保留 98% 核心商品信息完整性的前提下，将数据处理速度提升 3 倍，同时使整体处理成本降低 80%，实现效率与成本的双重优化。</li><li>第四级：数据融合智能体体系 – 运用自研的多源数据清洗算法，对来自不同电商平台的商品数据进行处理，噪音过滤率达到 87%，有效解决了跨平台商品信息孤岛问题，为用户提供统一、准确的信息视图。</li><li>第五级：个性推荐智能体体系– 深度融合 AgentCore Memory 的用户数据，摒弃传统机械的推荐方式，采用拟人化导购的交互形式，进行情感化推荐排序，让推荐结果更贴合用户个性化需求与购物习惯。</li></ul><p>多级智能体体系通过用户偏好分析、精准匹配、效率优化等维度构建了核心能力，在这一体系运行框架下，通过以下关键技术点，实现效率与质量的双重提升：</p><p><img width="723" height="346" referrerpolicy="no-referrer" src="/img/bVdm2Vb" alt="image.png" title="image.png" loading="lazy"/></p><ol><li>智能分解 – AI 自动将用户提出的复杂需求（如 “推荐一款适合大学生用、预算 5000 元以内、能运行设计软件的笔记本”）拆解为多个可并行处理的子任务，如 “大学生使用场景分析”“预算筛选”“软件运行需求匹配” 等。</li><li>并行路由 – 多个 Agent 同时针对不同维度的子任务进行处理，避免串行处理的等待时间，使系统响应时间缩短 60%，大幅提升用户体验。</li><li>记忆融合 – 基于 Strands Agents 调用 AgentCore Memory 中的用户历史数据，对各 Agent 处理后的结果进行个性化答案整合，确保最终呈现给用户的搜索结果完全符合其独特偏好与需求。</li></ol><p><img width="723" height="1440" referrerpolicy="no-referrer" src="/img/bVdm3et" alt="" title="" loading="lazy"/></p><p>通过上述技术架构与流程设计，Monus AI 实现了从 “单一搜索工具” 到 “专属购物伙伴” 的根本性转变。如今，用户无需在重复搜索中反复描述需求，AI 能够精准理解需求的上下文演进过程，为用户提供具备连续性的个性化服务体验。这一技术架构不仅彻底解决了传统 AI 搜索存在的记忆缺失、推荐同质化等问题，更开创了电商 AI 领域的全新服务范式，为行业树立了技术与体验双重领先的标杆。</p><h2>效果评估</h2><p>基于AgentCore Memory和Strands Agent协同架构，Monus AI实现了跨越式提升，AI 搜索优化 具体表现如下：</p><p><img width="723" height="334" referrerpolicy="no-referrer" src="/img/bVdm2Vd" alt="image.png" title="image.png" loading="lazy"/></p><p>依托 AgentCore Memory 长期记忆的技术优势，不仅显著加快 Agent 开发进程，更在实际应用中实现多重价值：基于用户画像的智能搜索 Token 用量大幅减少，同时搜索结果准确率有效提升，为 Monus AI 在技术竞争力与成本效益层面提供了跨越式突破。</p><h2>总结</h2><p>阿尔特科技与亚马逊云科技的技术合作，不仅是 “任务编排框架 + 记忆服务” 与电商场景的深度融合，更给出了 “AI 如何真正懂用户、服务用户” 的清晰答案。其以 Strands Agents能力为 “骨架”，以 AgentCore Memory 的记忆功能为 “大脑”，搭配大小模型协同、语义共识引擎等技术，找到了当前电商 AI 搜索的最优实现路径，体现对 AI 技术本质的深刻理解与实践智慧。正如阿尔特科技团队所言：“创业不是一份工作，是热爱、坚持与智慧成长的过程。” 此次通过技术创新，不仅验证了 AI 在电商领域的巨大商业潜力，更为行业提供了 “框架 + 记忆” 双核心驱动的可复制、可扩展实践范式，为电商 AI 搜索的发展注入新动能。</p><p>*前述特定亚马逊云科技生成式人工智能相关的服务目前在亚马逊云科技海外区域可用。亚马逊云科技中国区域相关云服务由西云数据和光环新网运营，具体信息以中国区域官网为准。</p><p><strong>本篇作者</strong><br/><img width="723" height="457" referrerpolicy="no-referrer" src="/img/bVdm2Vm" alt="image.png" title="image.png" loading="lazy"/></p><blockquote>本期最新实验为《<a href="https://link.segmentfault.com/?enc=Ou62xqLasnlYNDonsuVytg%3D%3D.db6K1KmzbWSBw9RyMbxEo5kUKkTSAmRFDBeb7bFSF8Q2UZc7PBVeyiX3M%2FpclWCcrr4RhQp9qqlBOf%2FxtVRA1Hz7M1gJwXDtRvO1tzZ32hnhoAobkIASVOgHBijA25fiHTdUqCe0NBA2zKY6uSXfs767iDU17oaq%2BW2dzY12miqnyQqI3LDm8UhvAuzIPvJ9wtTLuwy1XQVKdn48RSwb5w%3D%3D" rel="nofollow" target="_blank">大模型选型实战 —— 基于Amazon Bedrock测评对比和挑选最合适业务的大模型</a>》<br/>✨ 立即解锁当下最火爆的AI大模型，带你零基础玩转 DeepSeek、Nova 等顶尖大预言模型。<br/>📱 即刻在云上探索实验室，开启构建开发者探索之旅吧！<br/>⏩<a href="https://link.segmentfault.com/?enc=KHeFFiPFu%2FVzMwEvyL1%2Ftg%3D%3D.oxPaMDECBigAh3ulm2kQn9YqPwozGTwV1NVSNjcN6buyQr3nyJQd4vcQiX3yo8%2F2uEI%2B6cBJfrKnI%2Fd%2BDHDQR9MaLFAZIvZdK4tEOSrY%2Fx0dmAm%2FhSRJWl63l%2Fd7csBSXKa49NhPqDbkGiLgx6GmfLn7DWVha4pspOMPztT0KxsYZSNgczlVIgu%2Fs30fcbB7Qpsn5Awe%2F8ur563XBZaaoA%3D%3D" rel="nofollow" target="_blank">[点击进入实验</a>] 构建无限, 探索启程！🚀</blockquote>]]></description></item><item>    <title><![CDATA[Rust 与 Go，后端开发的下一个五年]]></title>    <link>https://segmentfault.com/a/1190000047405757</link>    <guid>https://segmentfault.com/a/1190000047405757</guid>    <pubDate>2025-11-17 19:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>开发没有那么容易，每个后端有它的脾气，它不关心业务的快速变化，只关心自身的稳定和高效。</p><p>那么在未来几年，在高并发、低延迟的新兴后端领域，Rust 和 Go，谁会成为更主流的选择？我个人认为，这不在于哪个语言更时髦，而在于谁的架构性成本更低。</p><p><img width="723" height="351" referrerpolicy="no-referrer" src="/img/bVdm4y4" alt="image.png" title="image.png"/></p><h3>核心差异：编译时的严谨 vs. 运行时的灵活性</h3><p>Rust 和 Go 的设计哲学，从一开始就走向了两个不同的方向。</p><ul><li><strong>Rust</strong> 选择的是一条“先难后易”的路。它的编译器非常严格，尤其是所有权和借用检查机制，会在编译阶段就把潜在的内存安全问题全部暴露出来。这个过程对新手来说确实有不小的学习曲线，但一旦编译通过，程序在运行时的稳定性和性能表现会非常可靠。它没有垃圾回收（GC），这意味着不会有因GC扫描而导致的不可预测的延迟暂停。</li><li><strong>Go</strong> 则走了另一条路：“快速上手，快速产出”。它的语法简洁，工具链完善，特别是<code>goroutine</code>让并发编程变得前所未有的简单。开发者可以很快地将业务逻辑转化为可运行的服务。这种高效率的背后，是Go语言运行时自带的垃圾回收机制。在大多数情况下，Go的GC表现得相当不错，但在面对流量洪峰或大量瞬时内存分配的场景时，GC的“Stop-the-world”暂停仍然可能引发P99延迟的抖动。</li></ul><p>这本质上是两种不同权衡：一种是用前期的开发投入换取运行时的极致性能和可预测性；另一种是用运行时的些许不确定性，换取极高的开发效率和更低的入门门槛。</p><h3>性能场景对比</h3><p>比如一个很常见的后端任务：接收一个JSON格式的POST请求，进行一些数据处理，然后返回一个新的JSON响应。</p><p>在这个场景下，两种语言的表现通常会呈现一种规律：</p><ul><li><strong>Go (1.22)</strong> ：我用Go写这个功能可能只需要很短的时间。服务在常规负载下运行良好，响应迅速。但当并发请求量急剧上升时，通过监控工具，就会观察到延迟曲线出现一些细小的毛刺，内存占用也会随请求量线性增长。</li><li><strong>Rust</strong> <strong>(基于tokio)</strong> ：用Rust实现同样的功能，可能需要花更多时间去处理数据的生命周期和所有权问题，确保代码能通过编译器的检查。但服务部署后，它的延迟曲线会很平滑，即使在高压下，性能表现也始终如一，内存占用非常稳定。</li></ul><p>Rust 是把优化工作前置到了编码和编译阶段，而Go则让开发者先快速实现功能，再根据运行时的性能表现进行针对性优化。</p><h3>从代码的细节来看</h3><p>我们来看一下实现相同功能的两段代码。</p><h4><strong>Go：清晰直观，关注业务</strong></h4><pre><code class="go">package main

import (
        "encoding/json"
        "fmt"
        "log"
        "net/http"
        "time"
)

type RequestPayload struct {
        Name  string `json:"name"`
        Value int    `json:"value"`
}

type ResponsePayload struct {
        ID      int64  `json:"id"`
        Message string `json:"message"`
}

func handleRequest(w http.ResponseWriter, r *http.Request) {
        if r.Method != http.MethodPost {
                http.Error(w, "Only POST method is allowed", http.StatusMethodNotAllowed)
                return
        }

        var reqPayload RequestPayload
        if err := json.NewDecoder(r.Body).Decode(&amp;reqPayload); err != nil {
                http.Error(w, "Bad JSON format", http.StatusBadRequest)
                return
        }

        respPayload := ResponsePayload{
                ID:      time.Now().UnixNano(),
                Message: fmt.Sprintf("hello %s", reqPayload.Name),
        }

        w.Header().Set("Content-Type", "application/json")
        if err := json.NewEncoder(w).Encode(respPayload); err != nil {
                log.Printf("Failed to encode response: %v", err)
        }
}

func main() {
        http.HandleFunc("/api/process", handleRequest)
        fmt.Println("Go server listening on :8080")
        if err := http.ListenAndServe(":8080", nil); err != nil {
                log.Fatalf("Server failed to start: %v", err)
        }
}</code></pre><p>这段Go代码的逻辑非常直接，核心就是解码、处理、编码。开发者可以把注意力完全放在业务流程上。但在这个过程中，<code>json.Decode</code>和<code>json.Encode</code>等操作会隐式地进行内存分配，这些都是未来GC需要处理的对象。</p><h4><strong>Rust：严谨精密，掌控资源</strong></h4><p>首先，<code>Cargo.toml</code> 依赖配置:</p><pre><code class="rust">[dependencies]
axum = "0.7"
tokio = { version = "1", features = ["full"] }
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
chrono = { version = "0.4", features = ["serde"] }</code></pre><p>然后是实现代码:</p><pre><code class="rust">use axum::{routing::post, Json, Router};
use serde::{Deserialize, Serialize};
use std::net::SocketAddr;
use tokio;

#[derive(Deserialize)]
struct RequestPayload {
    name: String,
    value: i32,
}

#[derive(Serialize)]
struct ResponsePayload {
    id: i64,
    message: String,
}

async fn handle_request(Json(payload): Json&lt;RequestPayload&gt;) -&gt; Json&lt;ResponsePayload&gt; {
    let message = format!("hello {}", payload.name);

    let response = ResponsePayload {
        id: chrono::Utc::now().timestamp_nanos_opt().unwrap_or(0),
        message,
    };
    
    Json(response)
}

#[tokio::main]
async fn main() {
    let app = Router::new().route("/api/process", post(handle_request));

    let addr = SocketAddr::from(([127, 0, 0, 1], 3000));
    println!("Rust server listening on {}", addr);
    
    let listener = tokio::net::TcpListener::bind(addr).await.unwrap();
    axum::serve(listener, app).await.unwrap();
}</code></pre><p>Rust的代码在结构上需要更多的思考，比如异步运行时和框架的选择。但它带来的好处是，所有的数据传递和内存使用都在编译器的严格监督之下，开发者对资源的掌控力更强，从而避免了运行时的意外。</p><h4>Go VS Rust，Pick 谁？</h4><p><strong>什么时候会更倾向于Go？</strong></p><ul><li>在构建内部系统、运维工具、以及大部分业务逻辑复杂的CRUD应用时，Go的开发效率是巨大的优势。它的生态成熟，招聘相对容易，能让团队快速响应业务需求。</li></ul><p><strong>什么时候会选择Rust？</strong></p><ul><li>对于那些直接面向用户、对性能和资源消耗有严苛要求的核心服务，我会选择Rust。例如，API网关、底层中间件、实时计算引擎等。在这些领域，可预测的低延迟和内存效率至关重要。</li></ul><h3>对未来五年的看法</h3><p>我认为，Go和Rust并不会是谁取代谁的关系，而是会在各自擅长的领域里变得更加重要。</p><ul><li><strong>Go</strong> 将继续作为云原生时代的核心语言之一，在微服务和业务后端领域保持其强大影响力。</li><li><strong>Rust</strong> 则会在高性能计算、系统编程和基础设施领域占据越来越重要的位置，成为追求极致性能和安全性的团队的首选。</li></ul><h3>动手实践是最好的检验方式</h3><p>伟人曾经说过，实验是检验真理的唯一标准，所以最好的方式还是亲手实践一下，感受两种语言在开发体验和运行表现上的真实差异。</p><p>但环境配置往往让人抓耳挠腮。安装Go，再安装Rust，管理不同版本和依赖，尤其是在一个团队里，有的人用macOS，有的人用Windows，环境不统一很容易在协作中产生不必要的问题。</p><p>那 <strong>ServBay</strong> 这样的工具就非常有用了。</p><p><strong>ServBay</strong> 是一个集成的<a href="https://link.segmentfault.com/?enc=Cfsv4XF8ifPDwWDtpSpjwA%3D%3D.Nch1P1a%2Frh6jL1EvS0GqhaT1AONSFwMPKaTa%2B2EIaN4%3D" rel="nofollow" target="_blank">本地开发环境工具</a>，支持macOS和Windows。它能一键安装和管理Go、Rust以及Python、PHP、Node.js等多种开发环境，并且各个环境之间是隔离的，不会互相干扰。</p><p><img width="723" height="458" referrerpolicy="no-referrer" src="/img/bVdm4y5" alt="image.png" title="image.png" loading="lazy"/></p><p>这样一来，无论是想快速验证一个Go的Web服务想法，还是想深入学习Rust的所有权模型，都不再被繁琐的环境配置所困扰。它提供了一个统一、干净的实验平台，让我们可以把精力真正集中在代码和架构的探索上。</p><p><img width="723" height="458" referrerpolicy="no-referrer" src="/img/bVdm4y6" alt="image.png" title="image.png" loading="lazy"/></p><p>最终选择哪门语言，其实是选择在项目的哪个阶段投入更多精力：是前期的严谨设计与实现，还是后期的性能调优与维护。通过ServBay这样的工具亲手尝试，或许能帮我们更快地找到适合自己项目和团队的答案。</p>]]></description></item><item>    <title><![CDATA[FMEA与数字化工具结合的应用案例与未来]]></title>    <link>https://segmentfault.com/a/1190000047405394</link>    <guid>https://segmentfault.com/a/1190000047405394</guid>    <pubDate>2025-11-17 18:14:07</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>FMEA是什么？——系统性、前瞻性的产品与过程失效模式分析工具<br/>失效模式与影响分析（FMEA），即Failure Mode and Effects Analysis，是一种广泛应用且经过时间考验的风险管理方法论。它本质上是一种系统性的、前瞻性的分析活动，旨在识别和评估潜在的产品或过程失效模式及其后果。FMEA的核心在于其“预防性”思维，通过在问题实际发生前对其进行结构化的剖析，帮助企业锁定风险点，从而采取针对性的预防或探测措施，提升产品设计的可靠性、制造过程的稳定性和最终的客户满意度。<br/>从应用范围来看，FMEA主要分为两大类型。设计FMEA（Design FMEA，简称DFMEA）聚焦于产品设计阶段，旨在识别设计缺陷可能引发的失效模式，如结构强度不足、功能异常、材料选择不当等，并通过设计改进来规避这些风险，确保产品在设计层面就具备高质量和高可靠性。例如，在汽车零部件设计中，通过DFMEA分析可能存在的腐蚀、断裂等问题，从而优化选材和设计结构，提升部件的使用寿命和安全性。<br/>过程FMEA（Process FMEA，简称PFMEA）则应用于生产制造阶段，关注生产流程、设备、人员、物料、方法等各环节可能出现的失效情况，如参数漂移、装配错误、焊接不良等，并制定相应的控制策略，以保障生产过程的稳定运行和产品质量的一致性。一个典型的电子制造业案例是，某企业通过PFMEA深入分析了SMT贴片工艺中焊膏回流可能出现的虚焊、锡珠、桥接等失效模式，识别出温度曲线设置不当、焊膏保存条件不满足等因素，并据此优化了工艺参数和环境控制，显著降低了生产缺陷率。</p><p>FMEA为什么要做？——其核心价值在于事前预防与持续改进<br/>其次，FMEA有助于强化产品和过程的质量控制。通过在设计和过程层面主动寻找薄弱环节，FMEA促使企业从源头入手，优化设计方案，改进工艺流程，使得最终交付的产品或服务具有更高的可靠性和一致性。例如，某汽车制造商在新车型开发中严格执行DFMEA，有效预防了早期设计中未考虑到的零部件接口问题，确保了整车装配的顺畅和功能的完善，显著提升了用户在使用过程中的体验。<br/>再者，FMEA能够提升企业的整体运营效率。提前识别和解决潜在失效模式，意味着减少了生产过程中的故障停机时间、减少了因质量问题导致的物料浪费和返修成本，提高了资源的利用率和生产效率。同时，FMEA作为一种持续改进的机制，鼓励团队不断反思和学习，积累组织知识，提升整体的风险意识和应对能力。<br/>典型案例如，广域铭岛FASTWORX FMEA平台建立了在线协同编制和在线评审体系，加强FMEA管理，让相关人员都了解到失效原因和失效影响。便于企业成立多功能小组，有利于调动员工积极性<br/>最后，FMEA是建立客户信任的重要途径。当企业能够通过FMEA展示其对产品质量的严谨态度和有效控制时，无疑会增强客户对其产品和服务的信心。这对于企业拓展市场、提升品牌形象具有长远的战略意义。</p><p>FMEA怎么做？——系统化实施流程与实践要点<br/>在实际操作中，为了提升FMEA的效率和效果，一些领先企业开始结合数字化工具进行实施。例如，利用FMEA软件平台（如FASTWORX FMEA）来辅助分析，实现数据的统一管理、多人协同编辑、版本控制以及RPN自动计算等功能。同时，通过与产品生命周期管理（PLM）、制造执行系统（MES）等系统的集成，使FMEA分析能够实时反映最新的设计和工艺信息，提高准确性。此外，经验教训的积累和共享也是FMEA成功实施的关键，将其录入FMEA数据库，有助于避免重复犯错，并为后续的分析提供参考。<br/>某汽车研究院通过广域铭岛FASTWORX FMEA系统使得通过FMEA在线协同编辑，实现全公司研发相关人员的社交化协作，消除部门间隔阂，提高30-50%开发工作效率，缩减开发时间约50%。<br/>总之，FMEA作为一种强大的风险管理工具，其实施需要系统的方法、跨部门的协作以及持续的投入和改进。当正确应用于产品开发和生产制造过程时，FMEA能够为企业带来显著的质量提升和成本节约效益，是实现高质量、高可靠产品交付的重要保障。</p>]]></description></item><item>    <title><![CDATA[工艺工程怎么优化生产流程以降低成本？ 月]]></title>    <link>https://segmentfault.com/a/1190000047405402</link>    <guid>https://segmentfault.com/a/1190000047405402</guid>    <pubDate>2025-11-17 18:13:08</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在当今制造业迅猛演进的洪流中，工艺工程俨然成为企业竞争力的基石，它不仅定义了生产流程的精髓，更在数字化转型的浪潮中扮演着不可或缺的角色。工艺工程，这一涵盖从设计到执行的全面体系，通过科学的方法论和技术创新，持续推动着生产效率的提升与产品质量的优化。广域铭岛，作为工业互联网领域的先锋，以其先进的平台技术，为工艺工程的智能化注入了鲜活动力，使传统制造焕发新生。<br/>工艺工程的核心在于其多维度的内涵：它起始于精密的工艺设计与规划，工程师需深入分析产品特性与市场动态，构建高效且稳定的生产流程；继而延伸至设备选型与布局，通过智能配置最大化资源利用率；更重要的是，工艺参数的设置与优化，如同交响乐中的指挥棒，细微调整便能协调整个生产节奏，确保输出的一致性；而工艺流程的改进与创新，则体现了工艺工程的动态本质，不断吸纳新技术以应对市场变幻。广域铭岛通过其工业互联网解决方案，例如GQCM模具智能管理APP，将这些元素无缝集成，实现了冲压工序的数字化孪生，大幅削减非计划停机，彰显了工艺工程在实践中的强大效能。<br/>谈及工艺工程的作用，它远不止于提升效率；更是企业降本增效、保障质量的战略支点。通过优化生产流程，工艺工程能够显著减少材料浪费与能源消耗，例如在焊接工艺中，广域铭岛的点焊质量管理APP通过实时数据采集与算法模型，将焊点一次合格率推升至99.5%，这不仅降低了返工成本，还缩短了培训周期，凸显了工艺工程在质量管控中的卓越贡献。此外，工艺工程还驱动着技术创新与可持续发展，它融入绿色制造理念，减少排放，并借助人工智能和大数据实现从经验驱动到数据驱动的跃迁。广域铭岛的平台在此发挥了催化作用，通过预测性维护和效能分析，帮助企业构建智能化的生产生态，使工艺工程成为智能制造的中流砥柱。<br/>展望未来，工艺工程将继续深化其数字化转型，拥抱工业4.0的机遇。随着人工智能和物联网技术的普及，工艺工程将更加智能化、自适应化，为企业提供前所未有的灵活性与竞争力。广域铭岛等企业的持续创新，无疑将加速这一进程，推动工艺工程向更高维度进化，最终赋能制造业实现全面升级与可持续发展。</p>]]></description></item><item>    <title><![CDATA[不止合规 JoySSL国密数字证书安全高]]></title>    <link>https://segmentfault.com/a/1190000047405411</link>    <guid>https://segmentfault.com/a/1190000047405411</guid>    <pubDate>2025-11-17 18:12:22</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>随着互联网技术的快速升级，数字经济也迎来蓬勃发展，数据信息在网络世界中不断传输交互，构筑起现如今庞大的互联网体系。由于互联网发展具有双面性，且信息安全是国家发展的重要基石。因此，数据信息的安全传输，成为了公众最为关注的问题之一。国密数字证书通过建立加密通信通道，验证服务端身份等方式，成为网络安全防护领域的重要工具。作为国内专业的数字安全服务商，JoySSL率先完成国密证书技术体系搭建，并全网普及，为企业数字化转型与网络安全系统建设提供一站式解决方案。</p><p><img width="723" height="549" referrerpolicy="no-referrer" src="/img/bVdm4tu" alt="" title=""/></p><p><strong>技术升级 国密证书的核心优势</strong></p><p>作为我国自主研发的加密算法体系，国密算法包含SM2（非对称算法）、SM3（杂凑算法）和SM4（对称算法），与国际算法相比，自主研发的国密算法无论是安全表现还是功能表现上，皆更具优势。传统数字证书通常都采用国际加密标准，如RSA或ECC。而国密证书以自研密码算法为基础，实现强大的加密功能，确保数据安全传输。JoySSL技术总监指出，国密算法在相同安全强度的前提下，密钥长度相比RSA更短，运行效率更高，且算法经过国家密码管理局严格认证，可有效防范各种密码攻击手段。</p><p><strong>应用普遍 数字证书的不断普及</strong></p><p>截至目前，国密数字证书已成为电子政务系统的标配，在政务领域应用范围甚广。凭借有效的防护手段和加密算法，国密证书在金融、医疗等对数据安全要求高的行业，有着极高的需求度。</p><p><img width="723" height="549" referrerpolicy="no-referrer" src="/img/bVdm4tv" alt="" title="" loading="lazy"/></p><p>JoySSL作为数字安全领域的专业服务商，与多家银行达成合作，部署国密SSL证书，利用加密算法完成网银系统升级，有效降低潜在的安全风险，增强隐私数据防护能力。不仅提升了交易的安全性，同时也获得了用户与市场的信任。</p><p><strong>生态搭建 国密证书的全面服务</strong></p><p>随着国内《数据安全法》《网络安全法》等一系列法规的相继出台，社会各界普遍对网络安全防护的认识不断加深，应用范围和领域也逐渐扩大。国密证书的推广与普及，让整个数字证书产业生态正在经历重塑，不仅获得了主流浏览器和操作系统的支持与认可，同时还具备极高的兼容性，让国密证书的普及范围进一步扩大。JoySSL市场部专家分析指出，国密数字证书的影响力与日俱增，市场认可度逐年提升，不仅推动了国内信息安全技术的发展，同时也推动了国内企业进一步朝着规范化、国际化的方向迈进。</p><p><img width="723" height="549" referrerpolicy="no-referrer" src="/img/bVdm4tw" alt="" title="" loading="lazy"/></p><p><strong>创新突破 国密证书的未来展望</strong></p><p>作为互联网技术的具体表现形式，国密证书的成长上限远不止于此。在网络技术升级迭代、市场需求变化和全球数字化发展的大趋势下，国密证书还有更大的上升空间。以JoySSL为代表的数字安全厂商，早已投入到国密证书最新技术的研发当中，利用更先进的技术理念和创新思维，打造出新一代国密证书，提升安全防护能力与市场渗透率，推动全球网络空间安全稳定发展。</p>]]></description></item><item>    <title><![CDATA[怎么利用设备全面诊断进行预测性维护？ 月]]></title>    <link>https://segmentfault.com/a/1190000047405418</link>    <guid>https://segmentfault.com/a/1190000047405418</guid>    <pubDate>2025-11-17 18:11:34</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在现代工业体系中，设备的高效运行与安全性保障已成为企业提升生产效率和竞争力的核心要素。设备全面诊断技术，作为一套通过实时监测、动态分析与预测性维护相结合的综合性解决方案，正在成为推动制造业智能化升级的关键引擎。该技术不仅涵盖了传统设备管理方法，还融合了物联网、大数据与人工智能等前沿科技，通过多维度的数据采集与多层次的分析手段，实现了从被动应对到主动预防的管理转型。<br/>设备全面诊断的本质在于对设备运行状态的全面感知与智能评估。借助各类传感器，系统可以实时采集设备的振动、温度、电流等关键参数，并通过边缘计算与云端分析平台进行深度处理。例如，振动分析不仅能识别轴承磨损与转子失衡等机械故障，还能结合其他数据源，提供更为准确的故障预警信号。与此同时，在诸如多源感知网络与仿真技术的支持下，设备全面诊断系统能够模拟极端条件下的设备运行情况，从而提前发现潜在隐患，避免重大事故发生。<br/>广域铭岛作为工业互联网领域的技术先锋，凭借其Geega平台为设备全面诊断的实现提供了理想的工具。该平台不仅整合了设备技术资料、运行数据与维修经验，还通过先进的AI算法实现了故障的自动诊断与维修方案的智能推送。在多个行业应用场景中，广域铭岛的系统成功帮助企业降低了非计划停机时间，并显著提升了生产效率与设备利用率。这种集成化的智能诊断方式，使得设备维护从经验驱动转向数据驱动，全面革新了传统管理模式。<br/>从实际应用效果来看，设备全面诊断带来的价值不仅局限于简单的故障修复。在制造业生产车间，通过优化工艺参数与实时监控设备健康状态，企业能够在节能环保的前提下，进一步提高生产线的产出稳定性。特别是在一些大型制造基地，设备全面诊断系统的应用直接带来了成本削减与生产效率提升的双重效应。这使得全面诊断不仅是一种技术革新，更是企业实现降本增效的重要战略手段。<br/>此外，设备全面诊断的应用范围正在扩展至更广泛的领域，包括能源、医疗、交通等。在核电设备与大型医疗机械中，实时的状态监测与预测性维护同样发挥着不可忽视的作用。并且随着技术的不断演进，设备全面诊断正在与AR远程指导、自动化运维机器人等创新技术相结合，推动工业生态向协同化与智能化方向发展。<br/>展望未来，设备全面诊断将在工业4.0与绿色制造的时代浪潮中扮演更加重要的角色。作为一种融合多学科技术的解决方案，它不仅能够帮助企业减少停机时间与维护成本，还能加速资源的循环利用与生产流程的优化。随着新一代技术整合的深入，设备全面诊断的准确度与覆盖范围将进一步提升，成为企业持续发展的强大支撑。</p>]]></description></item><item>    <title><![CDATA[SCALE | 2025 年 10 月《]]></title>    <link>https://segmentfault.com/a/1190000047405440</link>    <guid>https://segmentfault.com/a/1190000047405440</guid>    <pubDate>2025-11-17 18:11:00</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405442" alt="" title=""/></p><h2>一、本月导览与核心看点</h2><p>2025 年 10 月，<a href="https://link.segmentfault.com/?enc=cW4fsNRkH2Aqg2xSOTu76g%3D%3D.nexlr2UCqR0EBgVYnuMYSxzdG1n1F5d04YSJxF%2BG1SBhIklu%2FmyX1x6Hf41auxIc" rel="nofollow" title="SCALE 202510" target="_blank">SCALE</a> 评测基准持续追踪 AI 在专业 SQL 领域的最新进展。本月，榜单迎来了蚂蚁百灵大模型团队发布的两大 万亿级 参数的模型：<a href="https://link.segmentfault.com/?enc=yoWf3dkPoGLIWJGAWaD07Q%3D%3D.7izThiew3nVzZPjxm5BM0Z8Wtqr1ASbU1qFSuqAnBKrxItnLNXTW1zr7A9xFNPAL" rel="nofollow" target="_blank">Ling-1T</a> 和 <a href="https://link.segmentfault.com/?enc=vWC60RQzawASIvdW8u4FpQ%3D%3D.6wk9FO6vI6J318pw6EJNnZDi3RovnaPZ5%2F%2ByYuzXEy%2BWLyzegwm%2BIGCb4KAV%2BJPw" rel="nofollow" target="_blank">Ring-1T</a>。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405443" alt="" title="" loading="lazy"/></p><ul><li><strong>Ling-1T</strong> ：蚂蚁百灵大模型 <strong>Ling 2.0</strong> 系列的第一款旗舰模型。</li><li><strong>Ring-1T</strong> ：一款基于 <strong>Ling 2.0</strong> 架构的思考模型，也是全球首个开源万亿参数思考模型。</li></ul><p>本期核心看点：</p><ul><li><p><strong>新增模型评测</strong> ：首次引入蚂蚁 <em>Ling-1T</em> 与 <em>Ring-1T</em> 模型。评测数据显示，两款模型呈现出清晰的能力分化：</p><ul><li>Ling-1T 在「<strong>国产数据库</strong>」转换场景中表现突出，获得满分！</li><li>Ring-1T 在「<strong>SQL 优化</strong> 」和「<strong>SQL 理解</strong> 」维度展现了 <strong>更为均衡和稳健的综合能力</strong>，总分均进入榜单上游。</li></ul></li></ul><h2>二、评测基准说明</h2><p>为保证评测结果的长期可比性和权威性，本月我们的核心评测基准与算法保持不变，继续沿用 <strong>SCALE</strong> 自创立之初便确立的三维评测体系，确保所有模型与工具在统一、标准的测试环境下进行评估，以提供公正、可复现的评测结果。</p><ul><li><strong>SQL 优化</strong>：考察模型提升查询效率与性能的意识和能力。</li><li><strong>方言转换</strong>：考察模型在主流数据库之间进行语法迁移的准确性。</li><li><strong>SQL 理解</strong>：考察模型是否能精准解析复杂的查询逻辑与用户意图的能力。</li></ul><p>本月所有新增模型均在此标准体系下进行评估。</p><h2>三、焦点分析</h2><h3>专题一：Ling-1T 首次评测</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405444" alt="发布日期：2025-10-09" title="发布日期：2025-10-09" loading="lazy"/></p><p><em>Ling-1T</em> 作为 <strong>Ling 2.0</strong> 系列的首款旗舰非思考模型，在本月首次参评。其各维度总分分别为：</p><ul><li><strong>SQL 优化</strong>：62.5</li><li><strong>方言转换</strong>：59.2</li><li><strong>SQL 理解</strong>：59.4</li></ul><p>评测结果显示，该模型能力特点鲜明，在特定场景表现优异，但在复杂任务处理上仍存在明显短板。</p><h4>SQL 优化能力：62.5</h4><p><em>Ling-1T</em> 在 <strong>SQL 优化</strong> 维度获得 62.5 分。根据细分指标数据显示，该模型在「<strong>逻辑等价</strong>」方面表现出色，以 84.2 分位列该项第 5 名。</p><p>然而，其在「<strong>优化深度</strong> 」上表现不足，得分仅为 51.1 分（排名第 17），同时「<strong>语法错误检测</strong> 」得分也偏低（84.2分）（排名第 18），分析测评报告可见，模型将符合 MySQL 宽松模式的 <code>GROUP BY</code> 查询误判为有语法错误；对 <code>UNION</code> 查询中 <code>ORDER BY/LIMIT</code> 的语法规则理解不准确。</p><p><strong>核心缺陷</strong> ：模型缺乏对数据库特定模式（如 MySQL 的 <code>ONLY_FULL_GROUP_BY</code>）和 <strong>SQL 标准/方言差异</strong> 的上下文感知能力，过度依赖教条式语法规则，无法根据数据库配置灵活判断语法正确性，导致在边界情况下的误判。这一系列分数表明，模型具备保障逻辑一致性的能力，但在应用深度优化策略和保障语法规范性方面仍有较大提升空间。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405445" alt="Ling-1T：SQL 优化维度评分" title="Ling-1T：SQL 优化维度评分" loading="lazy"/></p><h4>方言转换能力：59.2</h4><p>此维度得分呈现出显著的能力分化（总分 59.2，排名第 17）。<strong>其最大亮点在于对国内数据库生态的适配性</strong> ，其「<strong>国产数据库</strong> 」转换子项获得 100 分满分（与 <a href="https://link.segmentfault.com/?enc=fe3gmIsw%2BL2GLKEs1JsNjw%3D%3D.xJRTIb4M4tdMJKBeYxT%2FodOG4tU8tY70Cj2jCrYvkhM%3D" rel="nofollow" target="_blank">SQLShift</a> 并列），展现了其在该特定场景下的卓越能力。</p><p>然而，模型在处理复杂迁移任务时表现挣扎。「<strong>大 SQL 转换</strong> 」得分仅为 12.9分（排名第 20）。测评报告显示，在复杂 SQL 方言转换中，模型误用不兼容语法（如保留 <code>SET NOCOUNT ON</code>、混用 <code>DBMS_OUTPUT</code> 等），且对控制流、游标、异常处理等结构的语义理解不足，导致转换后语法不兼容或逻辑不等价，这体现出模型对复杂结构化代码的全局理解能力，以及对多方言语义差异的精确把握能力还有待提升。同时，其「<strong>逻辑等价</strong> 」（61.3分）和「<strong>语法错误检测</strong>」（69.0分）得分中等，表明其在处理非国产数据库的复杂转换时，难以保证代码的规范性。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405446" alt="Ling-1T：方言转换维度评分" title="Ling-1T：方言转换维度评分" loading="lazy"/></p><h4>SQL 理解能力：59.4</h4><p>该分数表明 <em>Ling-1T</em> 具备基础的 SQL 解析能力。数据细分显示，其在「<strong>语法错误检测</strong> 」上表现突出，以 87.1 分的成绩与 <em>Claude 3.5 Sonnet</em> 并列该指标测评的第 1 名。</p><p>然而，其在「<strong>执行准确性</strong> 」方面表现不佳，得分仅为 52.9 分（排名第 19），分析测评报告可见，模型在日期条件测评中易出错，如 <code>due_date &lt; '2025-06-07'</code> 的查询中返回了 <code>due_date='2025-06-10'</code> 的记录，明显违反了条件。这类错误反映了模型在执行 SQL 查询时，对日期比较的语义理解与严谨性不足。这是其主要短板之一。</p><p>此外，其「<strong>执行计划检测</strong> 」得分为 57.1 分，模型在执行计划预测时，对 DDL 中未定义索引的字段错误预测了 <code>key</code> 和 <code>possible_keys</code>。例如查询 <code>WHERE fruit_name = 'Banana'</code> 时，模型预测 <code>key: "fruit_name"</code> 和 <code>possible_keys: "fruit_name"</code>，但 DDL 中 <code>fruit_name</code> 字段没有索引，反映出模型过于基于查询模式推测出现误判，在约束验证能力和结构化解析与推理上仍有较大提升空间。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405447" alt="Ling-1T：SQL 理解维度评分" title="Ling-1T：SQL 理解维度评分" loading="lazy"/></p><h3>专题二：Ring-1T 首次评测</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405448" alt="发布日期：2025-10-14" title="发布日期：2025-10-14" loading="lazy"/></p><p><em>Ring-1T</em> 作为基于 <strong>Ling 2.0</strong> 架构的万亿级参数思考模型，展现了比 <em>Ling-1T</em> 更强的综合实力。其各维度总分分别为：</p><ul><li><strong>SQL 优化</strong>：70.5</li><li><strong>方言转换</strong>：69.5</li><li><strong>SQL 理解</strong>：78.1</li></ul><p>能力表现更为均衡。</p><h4>SQL 优化能力：70.5</h4><p>该分数体现了模型在 SQL 优化方面的均衡能力。其「<strong>语法错误检测</strong> 」获得 100 分满分（与 <a href="https://link.segmentfault.com/?enc=iQZhC9UDrY6mCuwN%2BSnOSQ%3D%3D.8WljEnHlA%2B%2BecJWPu%2F7xR%2BlrGzKDgPPpXE2KMtMKM28%3D" rel="nofollow" target="_blank">SQLFlash</a> 并列），保证了优化后代码的规范性与可用性。「<strong>逻辑等价</strong> 」得分为 84.2 分（排名第 6），表现优异。「<strong>优化深度</strong>」得分为 60.0 分（排名第 4），表明模型能够应用常规的优化策略，但在处理复杂的查询、进行深度重构以追求极致性能方面，仍有进步空间。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405449" alt="Ring-1T：SQL 优化维度评分" title="Ring-1T：SQL 优化维度评分" loading="lazy"/></p><h4>方言转换能力：69.5</h4><p><em>Ring-1T</em> 在方言转换维度获得 69.5 分（排名第 11）。细分数据显示，其在「<strong>国产数据库</strong> 」转换（94.7分）、「<strong>语法错误检测</strong> 」（73.8 分，排名第 9）和「<strong>逻辑等价</strong>」（71.0 分）上均表现稳健。</p><p>其短板在于「<strong>大 SQL 转换</strong> 」，得分仅为 41.9 分（排名第 12），模型在处理跨数据库访问（如 SQL Server 的 <code>[server].database.schema.table</code>）、控制流（如 GOTO 标签跳转）、错误处理机制（如 <code>@@ERROR</code> 检查、<code>BEGIN TRY/CATCH</code>）、动态 SQL 执行（如 <code>sp_executesql</code> 参数绑定）等复杂结构时，存在语法混用、语义不等价、结构转换不完整等问题。</p><p><strong>核心缺陷</strong> ：缺乏对复杂结构化代码的全局理解能力，以及对多方言语义差异的精确映射能力，导致转换后的 SQL 在语法正确性或逻辑等价性上存在缺陷。相较于 <em>Ling-1T</em> 的 12.9 分，该分数有了显著提升，表明其在处理「<strong>大 SQL 转换</strong>」和保证代码规范性方面具备更强的能力，使其成为一个更可靠的数据库迁移工具。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405450" alt="Ring-1T：方言转换维度评分" title="Ring-1T：方言转换维度评分" loading="lazy"/></p><h4>SQL 理解能力：78.1</h4><p>得分 78.1 分，这是一个稳健的分数。其在「<strong>执行准确性</strong> 」上表现稳定（84.3分）。但其「<strong>执行计划检测</strong> 」（60.7分）和「<strong>语法错误检测</strong>」（67.1分）得分偏低。</p><p>模型混淆了标准 SQL 语法与数据库特定规则，将正确的标准语法误判为错误（如 GROUP BY 中使用别名 <code>category_prefix</code>、<code>INSERT</code> 子查询 <code>INSERT INTO table (SELECT ...)</code>、<code>CREATE VIEW</code> 中使用 <code>HAVING</code> 等），同时对复杂结构理解不准确，导致误判和漏判并存，反映了模型对标准 SQL 规范的准确理解不足，以及对语法规则判断的机械性。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405451" alt="Ring-1T：SQL 理解维度评分" title="Ring-1T：SQL 理解维度评分" loading="lazy"/></p><h2>四、专家点评</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405452" alt="" title="" loading="lazy"/></p><blockquote><strong>林春</strong>，中国太平洋保险数智研究院首席数据库专家，OceanBase 客户专家委员会（OBCE）专家委员，获得 OBCE 认证。获得 Oracle OCM、PostgreSQL PCM、MySQL OCP 认证。墨天轮 MVP，中国数据库技术大会（DTCC）演讲嘉宾。</blockquote><p>SCALE 2025 年 10 月《大模型 SQL 能力排行榜》的发布，堪称 AI 与数据库协同领域的关键行业参照。其依托"<strong>SQL优化+方言兼容+SQL理解</strong> "的三维测评框架，将大模型在数据库场景的落地能力进行了体系化量化，尤其在 Ling-1T、Ring-1T 等模型的分项表现中，清晰呈现了自然语言与数据库操作的适配差异，<strong>为企业级 AI+ 数据库的技术选型提供了精准的能力标尺</strong>。</p><p>这个榜单通过月度迭代的动态测评范式，既强化了对大模型数据库能力演进的追踪性，又以"细分场景得分+综合能力排名"的形式，缓解了企业对大模型"泛能力强、垂直场景弱"的选型焦虑，这与当前数据库向智能化、场景化演进的趋势高度契合。<strong>它不仅为中小企业提供了低成本评估 AI 数据库工具的参照标准，更倒逼大模型行业加速垂直能力优化 ------ 在 SQL 复杂查询适配、多数据库方言兼容等领域形成技术迭代</strong>。</p><p>SCALE 榜单的价值在于以标准化测评姿态打通了大模型能力与数据库需求的匹配链路，推动"<strong>模型能力评估-场景技术选型-落地效果验证</strong>"全流程的理性化重构，为下一代智能数据系统的技术适配提供了极具实践意义的行业范本。</p><p>我们可以看到，Ring-1T 模型在数据库场景中的核心优势场景包括：</p><ul><li><strong>复杂 SQL 查询生成</strong>：在多表关联、嵌套子查询等复杂 SQL 构建任务中表现突出（SQL 优化能力得分 70.5），可高效将自然语言需求转化为高性能 SQL 语句。</li><li><strong>多数据库方言兼容</strong>：适配 MySQL、Oracle 等主流数据库的语法差异（方言兼容能力得分 69.5），能自动生成符合不同数据库语法规范的操作语句。</li><li><strong>SQL 语义理解与纠错</strong>：对模糊需求、表述不规范的查询指令，具备较强的语义解析与纠错能力（SQL 理解能力得分 78.1），降低自然语言交互的精准度门槛。</li><li><strong>批量数据操作适配</strong>：在批量插入、更新等数据操作场景中，可生成高效且符合数据库性能要求的 SQL 脚本，适配企业级数据批量处理需求。</li></ul><h2>五、总结与展望</h2><p>随着蚂蚁百灵 <em>Ling-1T</em> 和 <em>Ring-1T</em> 两款新模型的加入，<strong>SCALE</strong> 评测榜单已累计收录超过 20 款业界主流 AI 模型及专业工具。本月评测清晰地展示了 <strong>Ling 2.0</strong> 系列两款模型的特点：</p><ul><li><strong>Ling-1T</strong> 在国产数据库适配上表现出众，但在复杂任务处理上存在短板</li><li><strong>Ring-1T</strong> 则展现了更均衡、更强大的综合 SQL 处理能力，特别是在 SQL 理解和优化方面表现稳健</li></ul><p>展望未来，SCALE 将继续秉持客观、严谨的原则：</p><ul><li>持续追踪：我们将继续追踪并迅速引入业界前沿的大模型和 SQL 工具。</li><li>深化场景：我们计划引入更多维度的企业级真实应用场景，使评测结果更贴近实际生产环境。</li></ul><blockquote><p>一个开放、透明的评测生态需要社区的共同建设。我们诚挚地邀请国内外更多的模型开发者、数据库工具提供商提交您的产品参与 SCALE 评测。通过在同一基准下与全球顶尖模型竞技，不仅可以精准定位产品优势与不足，更能提升品牌在开发者社区中的影响力。</p><p>即刻访问 <a href="https://link.segmentfault.com/?enc=SzLc73R6%2B%2BplY%2FrKKvIoYA%3D%3D.H1To2bOix61zfOuf7TOKfEXsp8zYGc3NeDLiJNjnOnRzcqXqq0v3v9MgVnvTA1Ug" rel="nofollow" target="_blank">https://sql-llm-leaderboard.com/ranking/2025-09</a></p><p>查看完整榜单并联系我们提交您的产品。</p></blockquote><p><strong>SCALE ------ 为专业 SQL 任务，选专业 AI 模型。</strong></p>]]></description></item><item>    <title><![CDATA[如何用 5 种方法删除三星手机上的消息/]]></title>    <link>https://segmentfault.com/a/1190000047405476</link>    <guid>https://segmentfault.com/a/1190000047405476</guid>    <pubDate>2025-11-17 18:10:26</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>三星一直向全球众多消费者销售其移动设备。三星智能手机，尤其是三星Galaxy S系列和Note系列，深受许多人的喜爱，特别是白领和大学生。</p><p>您可能对手机的新功能非常感兴趣，但您也应该注意在管理联系人和短信时需要哪些操作。您是否曾经想知道如何在三星手机上删除短信？我们将向您展示一些在三星手机上删除垃圾短信/联系人的方法。</p><h3>第一部分：如何在三星S25/24/23上手动删除短信</h3><p>如何在三星手机上删除短信？最常见的方法是在应用内手动删除。以下是如何在三星 Galaxy S25/S24/S23 上手动删除单条短信的方法。</p><p>步骤 1. 打开三星手机上的短信应用。</p><p>步骤 2. 长按要删除的消息，直到出现菜单。</p><p>步骤 3：从菜单选项中选择“删除”。然后，在出现提示时确认删除。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405478" alt="图片" title="图片"/></p><h3>第二部分：如何通过联系人应用从三星手机中删除联系人</h3><p>就像删除短信一样，在三星手机上删除联系人也很简单。最简单的方法仍然是直接从联系人应用中删除。请按照以下步骤从三星手机中删除联系人：</p><p>步骤 1. 打开三星设备上的“联系人”应用。</p><p>步骤 2. 滚动浏览列表或使用搜索栏找到要删除的联系人。</p><p>步骤 3. 点击联系人以打开其详细信息。</p><p>步骤 4. 点击“编辑”按钮（铅笔图标）或“更多选项”菜单（三个垂直点），然后选择“删除”或“移除”。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405479" alt="图片" title="图片" loading="lazy"/><br/>​</p><h3>第三部分：如何使用Coolmuster Android Eraser 删除三星手机上的信息</h3><p>无法删除三星手机上的短信？之前的方法无法永久删除三星手机上的短信和联系人。如果您想永久删除它们，可以尝试使用Coolmuster Android Eraser软件。</p><p>Coolmuster Android Eraser 是一款专业的数据擦除软件。它可以删除三星手机上的所有内容，包括但不限于短信和联系人。它提供低、中、高三种数据擦除级别，您可以根据需要进行选择。除了三星手机，它还支持大多数Android手机型号，例如 OnePlus、摩托罗拉、小米、Tecno、TCL、谷歌、vivo 等。</p><p>Coolmuster Android Eraser 的主要功能</p><pre><code>彻底清除所有三星数据，包括联系人、短信和其他数据。
确保彻底永久删除个人数据，防止任何恢复尝试。
您可以从三个递增级别的数据清除级别中进行选择：低级别、中级别和高级别。
高级权限可以覆盖数据 3 次，因此无法恢复任何数据。
适用于大多数Android手机，例如三星、荣耀、小米、一加、摩托罗拉等。
支持Android 6.0或更高版本。

</code></pre><p>如何使用Coolmuster Android Eraser 在三星 S25/24 上删除单个短信/联系人？以下是分步指南。</p><p>01安装、下载并打开Coolmuster Android Eraser。之后，使用 USB 数据线或 Wi-Fi 将您的三星手机连接到电脑。</p><p>02连接成功后，按下“擦除”按钮开始擦除过程。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405480" alt="图片" title="图片" loading="lazy"/></p><p>03现在，您可以从低、中或高三个级别中选择您偏好的安全级别。选择后，点击“确定”继续。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405481" alt="图片" title="图片" loading="lazy"/></p><p>04确认后，软件将迅速扫描您的Android手机中的文件并开始数据擦除程序。</p><h3>第四部分：如何使用Coolmuster Android Assistant从三星手机中删除短信</h3><p>除了Coolmaster Android Eraser之外，Coolmaster Android Assistant也能删除三星手机上的短信和联系人。除了删除短信和联系人之外，这款软件还能在电脑和手机之间传输数据，直接在电脑上编辑、添加、发送或恢复短信，以及在电脑上编辑联系人。除了短信和联系人之外，它还支持视频、图片、音乐等多种类型的数据。</p><p>Coolmuster Android Assistant的主要功能</p><pre><code>允许您选择性地删除三星手机短信和联系人。
在电脑上收发短信。
在电脑上轻松编辑现有联系人并创建新联系人。
一键备份和恢复Android手机短信、联系人和其他文件。
兼容最新的Android 16系统。

</code></pre><p>以下是如何使用Coolmuster Android Assistant在三星手机上删除短信的教程：</p><p>01在您的计算机上下载、安装并运行Coolmuster Android Assistant 。</p><p>02选择 USB 或 Wi-Fi 将三星手机连接到电脑。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405482" alt="图片" title="图片" loading="lazy"/></p><p>03连接成功后，从左侧面板选择“短信”。手机上的所有短信都会显示在这里。选中要删除的短信，然后点击页面顶部的“删除”。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405483" alt="图片" title="图片" loading="lazy"/></p><p>如果您想通过此软件从三星手机中删除联系人，步骤与删除短信相同。连接成功后，选择“联系人”类别，勾选要删除的联系人，然后点击“删除”按钮完成操作。</p><h3>第五部分：如何通过恢复出厂设置删除三星 S25/24/23 上的多条短信</h3><p>如果您不想使用第三方软件，但又想彻底删除三星手机上的短信和联系人，可以尝试恢复出厂设置。请注意，此方法会删除手机上的所有数据，因此请谨慎操作。最好在操作前备份您的三星手机。具体步骤如下：</p><p>第一步：进入三星手机的设置界面。找到并点击“常规管理”选项。</p><p>步骤 2. 您会看到“重置”选项。点击它，然后点击“恢复出厂设置”。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405484" alt="图片" title="图片" loading="lazy"/></p><p>步骤 3：向下滚动并点击“重置”。然后输入您的 PIN 码，点击“继续”&gt;“全部删除”，输入您的三星帐户密码，然后点击“确定”。您的三星手机将开始重置，并删除所有短信和其他数据。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405485" alt="图片" title="图片" loading="lazy"/></p><h3>结论</h3><p>以上提到的 5 种方法可以帮助您删除三星手机上的信息/联系人，但只有Coolmuster Android Eraser可以永久删除它们，且无法恢复，包括现有信息和已删除信息。</p><p>如果您想在三星手机上管理短信或联系人，我们推荐使用Coolmuster Android Assistant，这是一款专业的数据管理软件。如果您对此有任何疑问，请在评论区留言。我们会尽快回复您。<br/>​</p>]]></description></item><item>    <title><![CDATA[云栖实录 | 洋钱罐基于 EMR Ser]]></title>    <link>https://segmentfault.com/a/1190000047405499</link>    <guid>https://segmentfault.com/a/1190000047405499</guid>    <pubDate>2025-11-17 18:09:30</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>演讲人：宋晓峰 洋钱罐大数据运维总监</p><h2>十年破壁：从数据筑基到智能生态的全链路实践</h2><h3>一、数据筑基——自建大数据集群的攻坚与突破</h3><h4>背景介绍</h4><p>瓴岳科技（Fintopia）是以大数据和人工智能为基础的数字科技集团，为全球用户提供卓越的金融体验。2015年成立至今，瓴岳科技始终聚焦消费金融，业务遍布中国大陆、东南亚、拉丁美洲和非洲等；集团旗下拥有洋钱罐、Easycash等知名品牌，截至2025年，服务全球金融机构超过114家，全球注册用户超过1.81亿，全球累计交易额超过5400亿元。在公司发展的过程中，我们大数据部门为智能风控、精准营销、产品创新三大核心业务提供数据支撑，整合多源数据，利用机器学习算法实时识别欺诈风险，构建全流程风控体系，基于用户行为、偏好等数据，定制个性化金融服务推荐，通过分析市场趋势与用户需求数据，为产品开发提供精准方向，助力瓴岳科技全球化业务布局。</p><h4>大数据技术栈迭代与升级路径</h4><p>过去十年，洋钱罐的大数据技术栈经历了多次迭代。</p><p>2018年，面对数据孤岛问题及传统MySQL数据库无法有效支持复杂分析任务的挑战，我们自建了首个基于十多个节点的Hadoop大数据集群。当时用户规模约2000万，每日新增数据量约300GB。</p><p>随着业务需求的增长，特别是在2018年至2021年间，原有的MapReduce 框架因处理延迟较高而难以满足日益增长的数据处理时效性要求。因此，在2021年，我们将离线数据处理引擎由MapReduce迁移至Apache spark 2.x，并同步升级了Hive版本至3.x以提升数据仓库性能。彼时，系统每天运行约3,000个批处理作业。</p><p>为进一步提高数据处理效率并响应业务对数据实时性的更高期待，2022年我们引入了数据湖技术Apache Hudi，从而将原本的日全量数据抽取转变为增量更新模式，显著提升了数据的新鲜度至小时级别。</p><p>此外，为了更好地支持交互式查询场景，在2023年我们采用StarRocks作为新的Ad-hoc查询引擎，取代了之前依赖于Spark Thrift Server实现的方法。截至目前，Ad-hoc 日均SQL查询请求量超过8,000，P95响应时间控制在60秒以内。鉴于全球化布局带来的弹性资源、业务稳定性和成本优化要求，我们在2024年对整个集群架构进行了重大升级，将自建集群迁移至阿里云EMR Serverless平台，Yarn 节点规模超过一千台，在此过程中，我们也将spark 2.x升级到了spark 3.x。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdm4tg" alt="image.png" title="image.png"/></p><p>当前，我们集群的整体存储能力已经达到单副本10PB的规模，每日新增数据量约为30TB。核心业务报表数量超过3000份，而调度工作流数量已突破15000个。在StarRocks集群方面，我们同时采用了存算一体化架构与存算分离架构，并根据不同的业务线进行了划分，因此目前拥有超过30个独立的StarRocks集群实例。左侧展示的是我们的调度能力和 Ad-hoc 查询能力，YARN日执行job量超过4万。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdm4tk" alt="image.png" title="image.png" loading="lazy"/></p><h4>从稳定性到效率：自建集群的困境解析</h4><p>在自建大数据集群的过程中，我们遇到了诸多挑战，主要集中在稳定性、弹性资源管理和运维效率三个方面。</p><p>首先，在稳定性方面，我们面临的主要问题是业务SLA破线。这种情况往往源于底层 NodeManager 因网络带宽限制或shuffle 量大而导致任务失败率上升。此外，在使用开源组件过程中，也存在一些 bug 或者性能问题，比如我们在使用 Hive3.x 开源版本时，在高并发的场景下会出现进程卡死等问题，从而影响业务稳定性，无法满足生产环境的要求。</p><p>其次，在弹性资源管理上，自建集群缺乏快速扩展的能力以应对突发流量需求。例如，在凌晨遇到紧急情况时，希望迅速增加计算资源来解决问题变得不可行。同时，即使进行了物理服务器的扩容，在YARN的容量调度策略下，也难以有效平衡不同队列之间的负载分布，导致部分队列利用率过高而其他队列则相对空闲，整体上降低了集群资源利用效率。</p><p>最后，关于运维效率的问题，大数据集群的维护工作相当复杂且耗时。从硬件采购到最终完成配置并投入使用，整个过程通常需要两至三天时间。此外，开发人员还需投入大量精力进行性能调优、故障排除及日常巡检等任务，这不仅增加了人力成本，也影响了团队的工作效率。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdm4ts" alt="image.png" title="image.png" loading="lazy"/></p><h4>Spark 引擎核心痛点解析</h4><p>在使用Apache Spark引擎的过程中，我们遇到了几个核心痛点，这些问题主要集中在资源管理、性能与稳定性、版本升级以及成本控制等方面。</p><p>首先，在资源管理方面，我们面临的主要问题之一是峰值资源的优化。例如，在凌晨执行大规模任务时，该任务可能会占用队列中90%以上的资源，而其他较小的任务虽然只占用了剩余10%左右的资源，但其完成时间却可能更长。这表明了当前资源分配机制存在不合理之处，需要更加精细地调整以提高整体效率。另一个问题是谷值期间资源利用率低下。特别是在非高峰时段（如午夜过后），集群的整体资源利用率往往只能达到30%左右，导致大量计算能力被闲置。</p><p>其次，在性能与稳定性方面也存在问题。当我们使用自建的大数据集群部署Spark时，采用的是开源版的Shuffle Service作为NodeManager组件。然而，在高负载情况下，这种服务的表现并不理想，容易成为瓶颈，并且当单个NodeManager出现问题时，会严重影响到整个集群上运行任务的稳定性和性能。</p><p>第三点关于引擎版本固化的问题也非常突出。比如将 spark 2.x迁移到spark 3.x，不仅耗时较长，还需要充分考虑新旧版本之间的兼容性问题、系统稳定性测试以及对现有业务流程的影响评估等多方面因素。</p><p>最后，在成本控制方面同样存在着挑战。由于不同业务线之间可能存在交叉需求，比如风控场景下的离线数据仓库处理与Adhoc查询同时进行，这就使得很难按照单一业务维度来精确划分和管理相关费用。因此，如何有效地衡量并优化跨部门使用的Spark资源成本，成为了我们需要解决的重要课题之一。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdm4tx" alt="image.png" title="image.png" loading="lazy"/></p><h4>StarRocks 问题解析</h4><p>在使用 StarRocks 的过程中，我们也遇到了一些挑战，主要集中在数据导入、资源隔离及系统稳定性三个方面。</p><p>首先，在数据导入方面，StreamLoad 导入速度慢，支持的数据量有限，当提高数据导入频率时，可能会触发 FE 内存问题，会出现MVC相关报错。Broker Load 虽然导入速度快，但是软性资源隔离策略会影响读性能，最后我们还是要依赖Spark集群的Spark Load解决大数据量导入问题</p><p>其次，关于资源隔离的问题，虽然开源版StarRocks提供了基本的资源隔离功能，但它是软隔离，而非硬性隔离，数据导入与查询操作之间存在竞争关系，尤其是大规模查询请求可能会影响其他小型查询请求的响应时间。</p><p>最后，在系统运维与稳定性保障方面，开源版本没有自带的管控页面，运维人员不得不自行开发一系列脚本来完成扩缩容等请求，增加了运维难度。此外，在面对版本升级时，升级耗时长，还需额外进行业务回归测试以验证新版本兼容性和系统稳定性。</p><p>以上因素共同构成了 StarRocks 在实际应用中面临的主要技术挑战。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdm4tC" alt="image.png" title="image.png" loading="lazy"/></p><h3>二、云帆起航——迁移阿里云 EMR 的全链路实践</h3><p>面对上述挑战，我们对大数据架构进行了全面升级，全面切换至阿里云生态组件。此次升级的核心在于构建了一个符合数据湖理念的全新平台架构，该架构不仅满足了当前业务需求，还为公司未来向数据湖方向的发展奠定了坚实基础。此次升级主要对两个计算引擎进行了重大改造。</p><p>首先，我们将Hive SQL完全迁移至Spark SQL。因为相较于Hive SQL，Spark SQL展现出更优的执行效率，这也是业界共识。整体迁移过程非常丝滑，在性能与兼容性方面，EMR Serverless Spark 表现亮眼，还支持丰富的开源生态，如Kyuubi、Livy等。</p><p>其次，我们将 StarRocks 存算一体版本切换为了存算分离版本，这也顺应了Serverless 架构的发展趋势。</p><p>基于计算引擎升级，我们在上层构建了自己的数据应用产品，如一站式开发平台、标签系统、实时开发平台、数据质量监控系统、Ad-hoc查询等。</p><p>我们还将底层存储从传统HDFS切换为阿里云OSS-HDFS，消除了原生Hadoop文件系统中存在的单点故障问题。相比自建集群成本，新架构成本仅为其十分之一左右。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdm4tF" alt="image.png" title="image.png" loading="lazy"/></p><h4>EMR Serverless Spark：一站式数据平台服务</h4><p>EMR Serverless Spark 提供了一站式的数据平台服务，包括任务开发、调试、调度和运维等，极大地简化了数据处理和模型训练的全流程。内置 SQLEditor、Notebook 开发环境，提供版本管理，工作流调度，以及运维诊断能力。 版本管理功能使得用户能轻松切换Spark版本，只需确保SQL语句能正常运行，数据能正常处理即可，无需考虑底层基础设施的复杂性。</p><p>针对Spark和Python环境，用户可以根据具体业务需求进行配置，如调整spark-defaults.conf文件中的参数值，来优化特定应用场景下的性能表现。通过简单的spark-submit命令配合相关参数，即可快速切换到所需的运行时环境，极大提高了工作效率。</p><p>监控与诊断方面，EMR Serverless Spark 还提供完善的监控与诊断功能。提供工作空间、队列以及任务等各种维度的资源指标统计，方便用户更清晰地掌握作业运行情况。在Spark任务完成之后，收集和分析该任务的各种资源消耗指标，并根据这些指标给出合理的优化建议。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdm4tI" alt="image.png" title="image.png" loading="lazy"/></p><p>EMR Serverless Spark 还提供极致资源弹性与性能。首先，在弹性伸缩方面，支持 Driver/Executor级别进程弹性，最低支持一核力度，容器拉起时间在20秒以内。资源供给方面，底层是 Iaas + 神龙资源池，提供海量供给，自迁移至 EMR Serverless Spark 以来，我们尚未遇到任何资源短缺问题。</p><p>此外，EMR Serverless Spark 采用类似于YARN的资源管理模式。Workspace/队列两层Quota管理支持用户根据业务特性选择合适的提交路径。平台提供了基于Workspace/队列/作业的多维度、精确到天/时/分的多周期资源观测能力。</p><p>性能方面，EMR Serverless Spark 自研 Fusion 引擎，内置高性能向量化计算和 RSS 能力，相比开源版本性能大幅提升。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdm4tJ" alt="image.png" title="image.png" loading="lazy"/></p><h4>EMR Serverless StarRocks：功能丰富、性能卓越</h4><p>EMR Serverless StarRocks在管控能力方面显著优于自建方案，提供实例管理功能，包括创建，扩容缩容，升降配，网络管理，白名单管理，操作任务管理，网关管理等。</p><p>此外，其管控平台提供实例健康报告与慢SQL诊断分析、可视化缓存管理、支持大/小版本主动触发滚动升级、支持全链路实例操作审计等功能。</p><p>值得一提的是，EMR Serverless StarRocks 实现了真正的存算分离架构，提供物理隔离能力，不同计算组作业负载相互独立，支持多计算组独立配置。在我们的实际应用场景下，存算分离内表查询较开源性能提升约100%，数据湖查询较开源性能提升约50%。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdm4tS" alt="image.png" title="image.png" loading="lazy"/></p><p>下图展示了基于EMR Serverless StarRocks 的湖仓新范式，StarRocks 作为统一 Lakehouse，基于湖表进行自助分析查询。数据写入 StarRocks 提供极速分析；数据写入开放数据湖，使用 StarRocks 直接分析数据湖；在DWD、DWS以及ADS层，通过构建物化视图并实施分层建模策略，不仅能够有效支撑各类报表需求，同时也为OLAP提供了强有力的支持。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdm4tX" alt="image.png" title="image.png" loading="lazy"/></p><h4>架构升级带来的关键价值</h4><p>上述重大架构升级，带来了哪些关键价值呢？</p><p>首先，在成本优化方面，通过引入弹性资源，显著提高了资源利用率。</p><p>其次，从业务稳定性角度来看，EMR Serverless Spark 自带的高性能 Shuffle 服务，极大地增强了系统的稳定性和可靠性。此外，StarRocks 的性能优化也进一步提升了整体业务处理能力与响应速度。</p><p>关于业务敏捷性，新架构支持快速部署新业务场景所需的计算资源，从而大幅缩短了业务上线周期。</p><p>运维效率方面，得益于 EMR Serverless Spark与 EMR Serverless StarRocks 丰富的管控能力，开发团队所需投入的日常维护工作量显著减少。同时，平台提供了全天候的技术支持服务，确保即使面对突发问题也能迅速获得解决方案，进一步保障了系统的连续可用性。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdm4t1" alt="image.png" title="image.png" loading="lazy"/></p><p>具体而言，在保持业务规模不变的前提下，与传统的自建方案相比，基于 EMR Serverless 构建的解决方案能够实现约25.4%的成本节约。基于 EMR Serverless StarRocks 进行查询（如标签系统和用户圈选场景），SQL 查询执行时长缩短了30%。此外，在相同成本情况下，EMR Serverless Spark 作业的执行时间也缩短了30%以上。最值得注意的是运维效率方面的改进，实现了近40%的大幅提升。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdm4ur" alt="image.png" title="image.png" loading="lazy"/></p><h3>三、智创未来——未来基于阿里云的智能生态布局</h3><p>在完成架构升级后，整体稳定性得到显著提升。展望未来，我们的目标是构建一个更加智能化的金融生态环境。为此，我们设想了四个主要发展方向：</p><p>首先，在数据处理方面，我们计划基于阿里云EMR及机器学习平台PAI来实现高效的数据协同架构。</p><p>其次，在业务流程优化上，通过整合阿里云的大规模模型能力，旨在创建一个既简化又高效的运营环境，涵盖预测式风控、自动化运营，大智能化监控等领域。</p><p>再者，在应用层面，致力于形成以数据为驱动并支持智能决策的完整业务闭环。</p><p>最后，在算法创新方面，我们将依托于阿里云机器学习平台PAI，专注于开发适用于特定行业的专属AI模型库。<br/><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdm4ut" alt="image.png" title="image.png" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[这两个开源项目在世界互联网大会乌镇峰会获]]></title>    <link>https://segmentfault.com/a/1190000047405501</link>    <guid>https://segmentfault.com/a/1190000047405501</guid>    <pubDate>2025-11-17 18:08:36</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>2025 <strong>“直通乌镇”全球互联网大赛</strong>是世界互联网大会乌镇峰会重要活动之一，自 2019 年以来已连续举办 7 届。本届大赛以“发现未来新势力 共筑数字新生态”为主题，设置人工智能、智联出行、数智医疗、智能制造、智能终端、开源项目（分为开源模型应用赛和开源竞技挑战赛）六大赛道。</p><p>自 6 月启动报名以来，共吸引来自全球 29 个国家的 1082 个项目报名参赛，其中国内项目 864 个、海外项目 218 个。经过激烈角逐，共有 71 个项目入围决赛，包含海外项目 11 个。在最终的决赛中：</p><p><strong>Spring AI Alibaba</strong> 和 <strong>Higress</strong> 分别获得了开源先锋社区、开源优秀社区的称号，两位社区贡献者<strong>张圣航</strong>（GitHubID: shenghang）、<strong>刑国富</strong>（GitHubID: erasernoob）获得最具价值贡献者奖。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405503" alt="image" title="image"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405504" alt="image" title="image" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405505" alt="image" title="image" loading="lazy"/></p><p>感谢所有社区贡献者和开发者用户们的信任。</p><h3>关于 Spring AI Alibaba</h3><p>Spring AI Alibaba 开源项目基于 Spring AI 构建，是阿里云通义系列模型及服务在 Java AI 应用开发领域的最佳实践，提供高层次的 AI API 抽象与云原生基础设施集成方案，帮助开发者快速构建 AI 应用。目前，Spring AI Alibaba 底层正升级到 AgentScope，未来作为 AgentScope 生态的一环，定位是做好 Spring 和 AgentScope 的连接。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405506" alt="image" title="image" loading="lazy"/></p><h3>关于 Higress</h3><p>Higress 是一款开源的 API 网关，内核基于 Istio 和 Envoy，可以用 Go/Rust/JS 等编写 Wasm 插件，提供对 K8s 集群的 Ingress 入口网关, 并且兼容了大量 K8s Nginx Ingress 的注解，可以从 K8s Nginx Ingress 快速平滑迁移到 Higress。此外，作为一款 AI 网关，提供 LLM API 和 MCP API 的统一管理。已服务于通义千问、阿里云百炼、携程、蚂蚁数科、钉钉、优酷、快手、Paypal、汤臣倍健、UU跑腿、Sealos、国泰产险等互联网、金融、IT 服务等多行业的企业客户。</p><p>率先在国内开源 AI 网关的通用能力，包括</p><ul><li>面向大模型：统一代理各主流大模型和自建大模型服务，提供 OpenAI 兼容的访问方式，并提供二次 API KEY 签发、限流、安全防护、观测等治理能力 。</li><li>面向 Agent：用户可便捷、安全地将各类智能体能力无缝集成至业务系统，实现智能对话、流程自动化等创新功能，助力企业高效构建智能化应用生态。</li><li>面向 MCP：支持 API-to-MCP 快速转化，并提供 MCP Server 代理、安全认证，以及统一观测、限流等治理能力。</li></ul>]]></description></item><item>    <title><![CDATA[如何删除 iPhone 短信记录中显示的]]></title>    <link>https://segmentfault.com/a/1190000047405513</link>    <guid>https://segmentfault.com/a/1190000047405513</guid>    <pubDate>2025-11-17 18:07:43</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>​在 iPhone 的“信息”应用中，发送或接收短信后，对方的电话号码或联系人姓名会被系统自动记录，并显示在搜索栏或最近联系人建议中。虽然这是为了方便用户快速访问，但许多用户为了保护隐私或避免误发信息，会选择清理这些最近联系人。那么，如何在 iPhone 的短信记录中删除最近联系人呢？本文将提供三种解决方案供您参考。</p><h3>第一部分：如何在 iPhone 上通过删除整个对话来删除“信息”应用中的最近联系人</h3><p>从短信记录中删除最近联系人的最简单方法是删除与该联系人关联的整个短信对话。要执行此操作，请按照以下步骤操作：</p><p>步骤 1. 打开 iPhone 上的“信息”应用。</p><p>步骤 2. 点击顶部的“编辑”，然后选择要删除的对话。</p><p>步骤 3. 点击“垃圾桶”图标。</p><h3>第二部分：如何通过“信息”应用删除 iPhone 上最近删除的联系人</h3><p>你也可以直接从 iPhone 的“信息”应用中删除最近联系人。但问题是，你必须在“信息”应用中逐个删除它们。</p><p>如何在短信中删除最近联系的联系人？以下是步骤：</p><p>步骤 1. 解锁你的 iPhone，然后打开通讯录应用，确认你已从通讯录中删除不需要的电话号码或联系人。</p><p>步骤 2. 然后切换到“信息”应用，新建一条信息，然后开始输入要删除的联系人的姓名或电话号码。</p><p>步骤 3. 当不需要的联系人出现在短信记录中时，点击联系人右侧的带圆圈的“i”图标，打开新的联系人信息窗口。</p><p>第四步，请找到并点击“从最近联系人中移除”选项。确认是否是您要移除的联系人。如果是，请点击删除不需要的电话号码。</p><p>步骤 5. 删除不需要的联系人信息后，您将返回到“新建消息”窗口，您会注意到不需要的联系人已消失，并且仅显示“通讯录”应用中的正确联系人信息。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405515" alt="图片" title="图片"/><br/>​</p><h3>第三部分：如何永久删除 iPhone 短信历史记录中显示的最近联系人</h3><p>逐个从 iPhone 信息应用中删除最近联系人可能很麻烦，而且如果您想确保已从 iPhone 或 iPad 中彻底删除所有不需要的最近联系人，那更是难上加难。因此，我们向您推荐一款专业的iOS数据擦除工具Coolmuster iOS Eraser 。</p><p>有了它，您可以在一个程序中系统地管理 iPhone/iPad/iPod 上的所有联系人，包括现有联系人和已删除联系人。除了已删除的联系人之外，您还可以从 iDevice 中彻底清除已删除的信息、日历、提醒事项、语音备忘录、照片、备忘录、通话记录、Safari 书签等，且无法恢复。</p><p>iOS橡皮擦的主要功能：</p><pre><code>安全永久地清除iOS设备上的所有数据，包括个人信息、系统设置、已删除的文件等。
您可以选择三种擦除级别（低、中、高）来满足您的特定需求。
确保现有数据和已删除数据均被永久清除，无法恢复。
永久删除各种数据类型，例如联系人、短信、通话记录、音乐、视频、照片、应用程序和应用程序数据、提醒事项、日历、书签、浏览历史记录、语音备忘录、笔记和设置（包括 iCloud 和 iTunes 帐户信息）。
以 100% 只读模式运行，确保在数据擦除过程中不会对您的设备造成任何损害。
完全兼容所有 iPhone、iPad 和 iPod touch 机型，包括最新的 iPhone 17 和iOS 26。

</code></pre><p>以下是该程序的Mac和Windows版本免费试用版。请将其下载到您的电脑上，即可轻松删除iPhone短信记录中显示的最近联系人。</p><p>以下是如何使用iOS Eraser 在 iPhone 信息中删除最近联系人：</p><p>01使用 USB 数据线将您的 iPhone/iPad/iPod 连接到电脑。软件将自动检测您的设备，并显示主界面，即可开始抹掉数据。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405516" alt="图片" title="图片" loading="lazy"/></p><p>02点击“擦除”按钮，选择所需的安全级别（低、中或高），然后点击“确定”进行确认。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405517" alt="图片" title="图片" loading="lazy"/></p><p>03出现提示时，输入“删除”进行确认，然后再次点击“擦除”。将出现最终确认信息；点击“确定”以永久删除数据。</p><p>04流程完成后，设备上的所有数据将被永久删除且无法恢复。之后，您可以将您的 iDevice 设置为新设备。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405518" alt="图片" title="图片" loading="lazy"/></p><h3>结论</h3><p>如果您遇到最近删除的联系人仍然出现在 iPhone 短信记录中的问题，可以使用上述方法解决。如果您想要彻底、不可逆地完全清除所有残留记录，那么Coolmuster iOS Eraser无疑是最佳选择。它可以从系统深处删除所有隐私痕迹，确保联系人不再出现在短信记录或建议中，非常适合对隐私要求较高的用户。<br/>​</p>]]></description></item><item>    <title><![CDATA[Invicti v25.11 发布，新增]]></title>    <link>https://segmentfault.com/a/1190000047405540</link>    <guid>https://segmentfault.com/a/1190000047405540</guid>    <pubDate>2025-11-17 18:07:03</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>Invicti v25.11 发布，新增功能简介</p><p>Invicti v25.11.0 for Windows - Web 应用程序安全测试</p><p>Invicti (formerly Netsparker) | Web Application and API Security for Enterprise</p><p>请访问原文链接：<a href="https://link.segmentfault.com/?enc=1rKWWP%2B%2FDLfuZz1JyWg39Q%3D%3D.E5ro8elUnXsMuluk5uBAr522ecCVGBEbrlmCD0jxvMM%3D" rel="nofollow" target="_blank">https://sysin.org/blog/invicti/</a> 查看最新版。原创作品，转载请保留出处。</p><p>作者主页：<a href="https://link.segmentfault.com/?enc=GhT8Zvdy5r7g751c2sZd7A%3D%3D.ZaidUYZiqSGinCEqvd1cElrfCED7fRwxqR3qmv9Uo0c%3D" rel="nofollow" target="_blank">sysin.org</a></p><hr/><p>Invicti 是一种自动化但完全可配置的 Web 应用程序安全扫描程序，使您能够扫描网站、Web 应用程序和 Web 服务，并识别安全漏洞。Invicti 可以扫描所有类型的 Web 应用程序，无论其构建平台或语言。</p><ul><li>Invicti 是唯一一款能够以只读且安全的方式自动利用已识别漏洞以确认已识别问题的在线 Web 应用程序安全扫描程序。</li><li>它还提供了漏洞证明，因此您无需浪费时间手动验证它。例如，在检测到 SQL 注入漏洞的情况下，它将显示数据库名称作为利用证明。</li></ul><p>Invicti 的扫描技术旨在帮助您轻松保护 Web 应用程序而无需忧虑枝节小事，因此您可以专注于修复报告的漏洞。如果 Invicti  无法自动确认漏洞，它会通过在它前面加上 ‘[Possible]’ 并分配一个确定性值来通知您该漏洞，因此您知道应该立即修复什么。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000045076921" alt="Invicti-Logo" title="Invicti-Logo"/></p><p>Invicti (formerly Netsparker) 应用安全测试</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000045076922" alt="invicti-homepage-dashboard" title="invicti-homepage-dashboard" loading="lazy"/></p><p>Invicti - The Largest Dynamic Application Security Solutions Provider In The World</p><h2>新增功能</h2><p>Invicti Standard v25.11.0 - 2025 年 11 月 11 日</p><p><strong>改进</strong>：</p><ul><li>改进了 “SameSite Cookie 未实现” 安全检查</li><li>改进了 “JWT 签名未验证” 安全检查</li></ul><p><strong>已解决的问题</strong>：</p><ul><li>修复了由于加载认证配置文件问题导致的登录失败</li><li>修复了 Linux/云代理无法解析请求前查询参数中的密钥的问题</li><li>改进了应用程序的启动时间</li></ul><h2>下载地址</h2><p>想要开始学习和研究？</p><ul><li>请访问：<a href="https://link.segmentfault.com/?enc=9tKYnCBBt9j%2FKej84FL7lA%3D%3D.K7l40Vjl3y%2BzIgrLjoy6xnT6%2BtQ%2BVPTnvFmO%2Be3X9%2B4%3D" rel="nofollow" target="_blank">https://sysin.org/blog/invicti/</a></li></ul><hr/><p>更多：<a href="https://link.segmentfault.com/?enc=ntySBNIj2%2FeNkxmzPGKY9w%3D%3D.bUTDi6%2FbRuipU6MhhbozWHpDPbW51E2%2Bu88qS8SVQ5E%3D" rel="nofollow" target="_blank">HTTP 协议与安全</a></p>]]></description></item><item>    <title><![CDATA[如何将 OnePlus 手机中的联系人传]]></title>    <link>https://segmentfault.com/a/1190000047405544</link>    <guid>https://segmentfault.com/a/1190000047405544</guid>    <pubDate>2025-11-17 18:06:31</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>如果您正 从 OnePlus 手机换到 iPhone，并且想知道如何将联系人从 OnePlus 手机转移到 iPhone，您并不孤单。许多用户在升级设备时都会遇到这个问题。幸运的是，有几种方法可以快速高效地转移联系人。在本指南中，我们将为您介绍五种将联系人从 OnePlus 手机转移到新 iPhone 的有效方法。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405546" alt="图片" title="图片"/><br/>​</p><h3>第一部分：如何一键将 OnePlus 手机联系人传输到 iPhone</h3><p>将 OnePlus 手机联系人传输到 iPhone 最简单快捷的方法之一是使用Coolmuster Mobile Transfer 。这款工具提供一键式解决方案，可在Android和 iPhone 之间传输数据，包括联系人。对于追求便捷体验的用户来说，这是一个绝佳的选择。它的优势在于操作简单、速度快，而且无需网络连接。无论您是新手还是经验丰富的用户，都能轻松上手。</p><p>Coolmuster Mobile Transfer的亮点：</p><pre><code>只需单击一下，即可轻松将联系人从Android （OnePlus）传输到 iPhone 。
将电子书（PDF 和 ePub）和联系人从Android传输到 iPhone。
您可以选择四种灵活的传输方式： iOS到iOS 、 Android到iOS 、 iOS到Android和Android到Android 。
完全兼容最新的iOS 26和Android 16系统。
体验快速、无缝、安全的数据传输，无需担心数据丢失。

</code></pre><p>如何将 OnePlus 手机上的联系人传输到 iPhone？请按照以下步骤操作：</p><p>01首先，请在电脑上下载并安装Coolmuster Mobile Transfer 。使用 USB 数据线将您的 OnePlus 手机和 iPhone 连接到电脑。请确保您的 OnePlus 手机已启用 USB 调试模式。</p><p>02在电脑上打开该工具。连接成功后，选择 OnePlus 作为源设备，iPhone 作为目标设备。如果未选择，请点击“翻转”按钮进行切换。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405547" alt="图片" title="图片" loading="lazy"/></p><p>03勾选“通讯录”选项，确保只传输通讯录，然后点击“开始复制”按钮，开始将通讯录从 OnePlus 手机传输到 iPhone。传输完成后，您的通讯录就会出现在新的 iPhone 上。</p><h3>第二部分：如何通过“移动到iOS将联系人从 OnePlus 手机转移到 iPhone</h3><p>将联系人从 OnePlus 手机传输到 iPhone 的另一种有效方法是使用“转移到iOS应用。“转移到iOS是苹果官方推出的迁移工具，专为Android用户设计。它可以帮助您将联系人、短信、照片等数据从Android手机传输到 iPhone 。数据传输通过 Wi-Fi 进行，因此对于初次使用 iPhone 的用户来说，这是一个完美的解决方案。</p><p>以下是如何通过“转移到iOS将 OnePlus 手机中的联系人复制到 iPhone 的方法：</p><p>步骤 1. 从 Google Play 商店在您的 OnePlus 设备上安装“迁移到iOS应用程序。</p><p>步骤 2. 在新 iPhone 上，开始设置过程，并在“应用与数据”部分出现提示时选择“从Android转移数据”。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405548" alt="图片" title="图片" loading="lazy"/><br/>​</p><p>步骤 3. 在您的 OnePlus 手机上打开“转移到iOS应用程序，并按照屏幕上的说明进行操作。</p><p>第四步：iPhone 上会显示一个六位数的代码。请在 OnePlus 设备上输入此代码以建立连接。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405549" alt="图片" title="图片" loading="lazy"/><br/>​</p><p>步骤 5. 选择“联系人”和您想要传输的任何其他数据，然后点击“下一步”。</p><p>第六步：等待传输过程完成。完成后，您的联系人即可在您的 iPhone 上使用。</p><h3>第三部分：如何使用 Google 帐户将 OnePlus 手机中的联系人同步到 iPhone</h3><p>如果您之前在 OnePlus 手机上启用了 Google 帐户同步，则可以通过 Google 帐户直接将联系人导入 iPhone。只需将您的 Google 帐户添加到 iPhone，联系人就会自动导入。</p><p>以下是如何使用 Google 帐户将 OnePlus 手机上的联系人传输到 iPhone 的方法：</p><p>第一步：确保您的联系人已与您的 Google 帐户同步。为此，请转到“设置”&gt;“帐户”&gt;“Google”，并确保“联系人”同步已启用。</p><p>步骤 2. 在您的 iPhone 上，前往“设置”&gt;“邮件”&gt;“帐户”&gt;“添加帐户”，然后选择“Google”。</p><p>步骤 3. 使用您的 Google 帐户用户名和密码登录。</p><p>步骤 4. 登录后，确保“联系人”开关已打开。</p><p>第五步：您的 Google 联系人将自动与 iPhone 上的“通讯录”应用同步。您可以立即查看它们。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405550" alt="图片" title="图片" loading="lazy"/></p><h3>第四部分：如何通过 VCF 文件将 OnePlus 手机中的联系人导入 iPhone</h3><p>如果您只需要传输一部分联系人，使用 VCard 文件（.vcf 文件）是一种简单的方法。</p><p>以下是如何通过 VCF 文件将 OnePlus 手机中的联系人导入 iPhone 的方法：</p><p>步骤 1. 打开 OnePlus 手机上的“联系人”应用，进入“设置”，然后选择“导出”。选择将联系人保存为 VCF 文件。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405551" alt="图片" title="图片" loading="lazy"/></p><p>步骤 2. 将 VCF 文件通过电子邮件发送给自己，或者使用云存储服务（如 Google Drive）保存该文件。</p><p>步骤 3. 打开 iPhone 上的电子邮件或云存储，下载 VCF 文件。</p><p>第四步：点击 VCF 文件将其打开。你的 iPhone 会询问你是否要将联系人添加到“通讯录”应用；点击“添加所有联系人”。</p><p>步骤 5. 导入完成后，您的所有联系人将出现在您的 iPhone 上。</p><h3>第五部分：如何使用 SIM 卡将 OnePlus 手机中的联系人传输到 iPhone</h3><p>如果您只需要传输联系人而无需传输其他数据，使用 SIM 卡是一种简单常用的方法。您可以将 OnePlus 手机中的联系人保存到 SIM 卡中，然后再将其导入到 iPhone 中。</p><p>以下是如何使用 SIM 卡将 OnePlus 手机中的联系人发送到 iPhone 的方法：</p><p>步骤 1. 打开 OnePlus 手机上的“联系人”应用，进入“设置”，然后选择“导入/导出”。选择将联系人导出到 SIM 卡。</p><p>步骤 2. 从 OnePlus 手机中取出 SIM 卡，然后将其插入 iPhone。</p><p>步骤 3. 在您的 iPhone 上，前往“设置”&gt;“通讯录”&gt;“导入 SIM 卡通讯录”。</p><p>步骤 4. 等待联系人导入，它们将出现在 iPhone 的“通讯录”应用中。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047405552" alt="图片" title="图片" loading="lazy"/><br/>​</p><h3>总结</h3><p>将 OnePlus 手机上的联系人传输到 iPhone 时，您可以根据自身需求和设备情况选择多种方法。对于大多数用户而言，使用“转移到iOS应用或通过 Google 帐户同步是最便捷的选择。如果您只需要传输部分联系人，手动使用 VCard 文件也是一个不错的选择。为了更高效地迁移数据， Coolmuster Mobile Transfer是另一个值得尝试的工具。</p><p>无论你选择哪种方法，迁移之前务必备份你的联系人，以免数据丢失。<br/>​</p>]]></description></item><item>    <title><![CDATA[智能计划助手怎么优化资源调度和排产流程？]]></title>    <link>https://segmentfault.com/a/1190000047405567</link>    <guid>https://segmentfault.com/a/1190000047405567</guid>    <pubDate>2025-11-17 18:05:42</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在当今瞬息万变的制造业环境中，企业正面临着前所未有的运营挑战：订单波动剧烈、资源调度复杂、交货周期难以准确预测。传统依赖人工经验的生产计划模式已显疲态，无法满足现代制造业对柔性、高效与智能化的迫切需求。正是在这一背景下，智能计划助手应运而生，以其算法驱动的智慧，为制造业注入全新的活力与效率。广域铭岛作为这一领域的先驱，通过其深度集成的智能体系统，展现了智能计划助手如何成为企业数字化转型的关键引擎。<br/>智能计划助手的核心在于其能够动态分析海量数据，实现精准的资源配置与调度。传统排产方式效率低下，计划员需手动调整数十种约束参数，耗时长达数小时，且结果往往不尽人意。而智能计划助手则凭借机器学习与自然语言处理技术，在短短分钟内生成多套高满足率的方案，并通过实时模拟验证效果。这种转变不仅是技术上的飞跃，更是思维模式的革新——从“经验主义”的试错，迈向“算法驱动”的精准决策。广域铭岛的实践案例表明，智能计划助手绝非空中楼阁；例如在某大型整车工厂，单次排产时间从6小时压缩至0.5-1小时，释放了大量人力资源，让工程师专注于战略规划，而非繁琐的操作。<br/>进一步地，智能计划助手通过智能调度引擎，快速响应市场变化与异常情况。订单频繁调整或临时插单曾是企业运营的噩梦，但智能计划助手能在10秒内完成全局生产计划的重新计算，支持多目标优化，如交期优先或成本优先。广域铭岛为电子制造企业部署的系统，使订单准时交付率从75%提升至94%，异常响应速度从滞后数小时缩短为实时预警。这种敏捷性不仅提升了生产效率，更增强了企业的市场竞争力，使智能计划助手成为应对不确定性的强大盾牌。<br/>全流程可视化监控是智能计划助手的另一大优势，它实现了从原材料到成品的无缝追踪与风险预警。通过实时生产看板，企业可以洞察每一个环节的运作状态，异常情况自动报警，从而减少客户投诉与运营成本。广域铭岛在合作的一家机械制造企业中，利用智能计划助手将交货周期预测准确率提高至96%，极大提升了管理透明度与决策敏捷性。移动端功能的集成，更使得决策者可以随时随地掌控生产动态，凸显了智能计划助手在现代化管理中的不可或缺性。<br/>然而，智能计划助手的崛起并非没有挑战。算法稳定性、数据基础与团队接受度仍是需要权衡的因素。广域铭岛通过云边协同架构和持续优化模型，部分解决了这些难题，但其成功仍依赖于企业的整体数字化成熟度。未来，随着5G和物联网技术的普及，智能计划助手或将进一步进化，实现全链路智能化，甚至自主决策生产流程，为制造业带来更深刻的变革。<br/>总之，智能计划助手代表了制造业排产的未来方向——它不仅是工具，更是战略资产。广域铭岛的创新实践为我们描绘了一幅蓝图：如何通过算法赋能，将繁琐的人工操作转化为高效、精准的自动化流程。在这个充满变数的时代，拥抱智能计划助手，或许正是企业决胜千里的关键一步。</p>]]></description></item>  </channel></rss>