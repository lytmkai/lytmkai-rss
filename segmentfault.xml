<?xml version="1.0" encoding="UTF-8"?><rss version="2.0">  <channel>      <title>SegmentFault - 最近文章</title>      <link>https://segmentfault.com/blogs/newest</link>      <description>SegmentFault 思否</description>      <generator>python segmentfault.py @Pi20</generator>      <item>    <title><![CDATA[告别证书过期焦虑！这款开源工具让 SSL 管理彻底自动化！ Java陈序员 ]]></title>    <link>https://segmentfault.com/a/1190000047571232</link>    <guid>https://segmentfault.com/a/1190000047571232</guid>    <pubDate>2026-01-26 11:16:37</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>大家好，我是 <code>Java陈序员</code>。</p><p>无论是研发个人产品，还是中小企业做运维，会遇到要管理多个域名的情况，需要给域名申请证书。</p><p>但是手动申请证书往往很麻烦（尤其是有多个域名需要维护），而且很容易遗忘证书的过期。</p><p>今天，给大家推荐一款开源的证书管理工具，全流程管控 SSL 管理！</p><blockquote>关注微信公众号：【Java陈序员】，获取<strong>开源项目分享、AI副业分享、超200本经典计算机电子书籍等。</strong></blockquote><h2>项目介绍</h2><p><code>certimate</code> —— 一款完全开源免费的自托管 SSL 证书 ACME 工具，申请、部署、续期全流程自动化可视化，支持各大主流云厂商。</p><p><strong>功能特色</strong>：</p><ul><li><strong>全流程自动化</strong>：无需编写代码，通过界面拖拽/配置即可搭建证书管理流程，配置完成后，从证书申请、ACME 验证到部署至目标平台，全程无需人工干预</li><li><strong>私有化部署</strong>：无需安装数据库、运行时或复杂框架，一键启动，开箱即用，所有数据本地化存储，掌控数据的隐私与安全</li><li><strong>生态适配拉满</strong>：阿里云、腾讯云、Cloudflare、AWS、华为云等主流域名托管商全覆盖，同时兼容 Let's Encrypt、Google Trust Services、ZeroSSL 等主流免费/付费证书颁发机构</li><li><strong>多维度监控</strong>：证书到期、申请失败、部署异常等状态，可通过邮件、钉钉、飞书、企业微信、Webhook 等实时推送</li><li><strong>轻量开源</strong>：超轻量的资源开销，仅需 ~16 MB 内存，完全开源免费，无功能阉割、无付费门槛</li></ul><h2>快速上手</h2><p><code>certimate</code> 支持二进制安装、Docker 安装、源码编译安装等多种安装方式。</p><h3>二进制安装</h3><p>1、下载预先编译好的二进制可执行文件压缩包</p><pre><code class="bash">https://github.com/certimate-go/certimate/releases</code></pre><blockquote>压缩包文件名后缀包含系统架构信息，需要根据操作系统自行选择相应的压缩包，下载并解压缩全部文件。</blockquote><p>2、进入解压后的目录，并在终端中执行</p><pre><code class="bash">./certimate serve</code></pre><p>3、运行成功后，浏览器访问</p><pre><code class="bash">http://{IP/域名}:8090</code></pre><p>4、初始的管理员账号及密码：</p><ul><li>账号：<code>admin@certimate.fun</code></li><li>密码：<code>1234567890</code></li></ul><h3>Docker 安装</h3><ul><li>Docker 命令安装</li></ul><p>1、拉取镜像</p><pre><code class="bash"># 拉取镜像
docker pull certimate/certimate:latest

# 国内镜像
docker pull registry.cn-shanghai.aliyuncs.com/certimate/certimate:latest</code></pre><p>2、创建挂载目录</p><pre><code class="bash">mkdir -p /data/software/certimate</code></pre><p>3、运行容器</p><pre><code class="bash">docker run -d \
  --name certimate \
  --restart unless-stopped \
  -p 8090:8090 \
  -v /etc/localtime:/etc/localtime:ro \
  -v /etc/timezone:/etc/timezone:ro \
  -v /data/software/certimate:/app/pb_data \
  certimate/certimate:latest

# 国内镜像
docker run -d \
  --name certimate \
  --restart unless-stopped \
  -p 8090:8090 \
  -v /etc/localtime:/etc/localtime:ro \
  -v /etc/timezone:/etc/timezone:ro \
  -v /data/software/certimate:/app/pb_data \
  registry.cn-shanghai.aliyuncs.com/certimate/certimate:latest</code></pre><ul><li>Docker Compose 安装</li></ul><p>1、创建 <code>docker-compose.yml</code> 文件并填写如下内容</p><pre><code class="yaml">version: "3.0"
services:
  certimate:
    image: certimate/certimate:latest
    container_name: certimate
    ports:
      - 8090:8090
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - /etc/timezone:/etc/timezone:ro
      - ./data:/app/pb_data
    restart: unless-stopped</code></pre><p>2、一键启动</p><pre><code class="bash">docker compose up -d</code></pre><h2>功能体验</h2><ul><li><strong>仪表盘</strong></li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571234" alt="" title=""/></p><ul><li><strong>工作流</strong></li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571235" alt="" title="" loading="lazy"/></p><ul><li><strong>流程编排</strong></li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571236" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571237" alt="" title="" loading="lazy"/></p><ul><li><strong>运行历史</strong></li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571238" alt="" title="" loading="lazy"/></p><ul><li><strong>主机提供商</strong></li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571239" alt="" title="" loading="lazy"/></p><ul><li><strong>证书颁发机构</strong></li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571240" alt="" title="" loading="lazy"/></p><ul><li><strong>通知渠道</strong></li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571241" alt="" title="" loading="lazy"/></p><ul><li><strong>系统设置</strong></li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571242" alt="" title="" loading="lazy"/></p><p>可以说，<code>certimate</code> 把 SSL 证书管理从<strong>重复体力活</strong>变成<strong>自动化流程</strong>。不仅私有化部署可以保障数据安全，而且丰富的生态适配满足不同场景需求。无论是个人还是企业，都能通过它彻底告别证书过期的焦虑。快去部署体验吧~</p><pre><code class="bash">项目地址：https://github.com/certimate-go/certimate</code></pre><h2>最后</h2><p>推荐的开源项目已经收录到 <code>GitHub</code> 项目，欢迎 <code>Star</code>：</p><pre><code>https://github.com/chenyl8848/great-open-source-project</code></pre><p>或者访问网站，进行在线浏览：</p><pre><code>https://chencoding.top:8090/#/</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000046659706" alt="" title="" loading="lazy"/></p><p><strong>我创建了一个开源项目交流群，方便大家在群里交流、讨论开源项目</strong>。</p><p><strong>但是任何人在群里打任何广告，都会被 T 掉</strong>。</p><p><strong>如果你对这个交流群感兴趣或者在使用开源项目中遇到问题，可以通过如下方式进群</strong>：</p><p><strong>关注微信公众号：【Java陈序员】，回复【开源项目交流群】进群，或者通过公众号下方的菜单添加个人微信，并备注【开源项目交流群】，通过后拉你进群</strong>。</p><blockquote>大家的点赞、收藏和评论都是对作者的支持，如文章对你有帮助还请点赞转发支持下，谢谢！</blockquote><hr/>]]></description></item><item>    <title><![CDATA[2026移动端管理工具精选指南：提升团队协作效率的必备应用 曾经爱过的汉堡包 ]]></title>    <link>https://segmentfault.com/a/1190000047571582</link>    <guid>https://segmentfault.com/a/1190000047571582</guid>    <pubDate>2026-01-26 11:15:57</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><strong>简介</strong>： 在移动办公和远程协作成为常态的今天，高效的管理工具是团队保持生产力的核心。面对碎片化时间、多设备同步和即时协作的挑战，专为移动端优化的管理工具应运而生。它们通过直观的触控界面、实时同步能力和场景化功能，让团队管理随时随地进行。本文将解析移动端管理工具的关键价值，并为您精选几款高效应用，助力团队在移动时代游刃有余。</p><p>随着工作场景的日益灵活，我们处理事务的地点从固定工位扩展至通勤途中、家庭办公室甚至差旅途中的咖啡馆。传统的桌面端管理软件虽功能强大，但在移动场景下往往显得笨重且不便操作。此时，一款设计精良、体验流畅的<strong>移动端管理工具</strong>，就成为连接想法与行动、计划与执行的关键桥梁。</p><h2>01 挑战与契机：移动办公环境下的管理新需求</h2><p>现代工作模式对管理工具提出了前所未有的要求。团队成员可能分布在不同的时区，项目更新需要即时传递，决策也不再局限于会议室内。这种去中心化、实时化的协作模式，暴露了传统管理方式的诸多痛点：信息更新滞后导致决策依据过时，复杂的桌面端操作在手机小屏幕上难以进行，多平台间数据不同步造成信息混乱。</p><p>此外，移动场景下的使用具有“碎片化”和“即时性”特征。使用者期望在几分钟甚至几十秒内完成任务查看、进度更新或简短批复。因此，移动端管理工具的核心挑战在于，如何在有限的屏幕空间和交互时间内，提供清晰的信息架构、极简的操作路径和无缝的协作体验。谁能解决这些挑战，谁就能真正释放移动团队的巨大潜力。</p><h2>02 核心价值：为什么移动端专用管理工具不可或缺</h2><p>移动端管理工具的价值，绝非简单地将电脑界面移植到手机。其核心在于<strong>深度适配移动场景</strong>，解决特定痛点。首先，它通过推送通知、移动快捷操作（如语音录入、拍照上传）和离线支持等功能，确保管理行为永不掉线。即使在网络不稳定的环境下，也能记录想法或更新状态，待网络恢复后自动同步。</p><p>其次，优秀的移动端工具注重<strong>降低认知负荷</strong>。它采用符合移动设备习惯的导航（如底部标签栏、侧滑菜单），将关键信息前置，并简化复杂操作。这让团队成员在忙碌或移动中，也能轻松参与项目管理，而非管理工具的负担。</p><p>最后，它扮演着<strong>团队协作神经末梢</strong>的角色。通过移动端，审批可以即时完成，突发问题能够被迅速标记@负责人，项目进展得以一键分享给客户。它缩短了从发现问题到协调解决的闭环，将管理行为渗透到工作的每一个细微瞬间，真正实现了“管理无处不在”。</p><h2>03 实战解析：主流移动端管理工具特点概览</h2><p>了解其核心价值后，以下几款工具在移动端的适配性和用户体验方面各有侧重，可供参考。</p><p><strong>Trello</strong> 以其看板视图著称，移动端通过流畅的拖拽手势和快捷添加按钮（支持拍照、录音）来管理任务，适合需要轻量、可视化管理的场景。</p><p><strong>板栗看板</strong> 在贴合国内团队使用习惯方面进行了设计，移动端视图切换流畅，并通过与常用办公软件打通、支持微信便捷分享等方式，降低内外协作的门槛。</p><p><strong>Asana</strong> 在移动端对复杂的项目层级关系进行了清晰的呈现，其“收件箱”功能能聚合所有任务通知，帮助用户在移动状态下聚焦处理待办事项，适合管理多线任务。</p><p><strong>Microsoft To Do</strong> 聚焦于个人与轻团队任务管理，移动体验以快速为核心。其手机桌面小组件和“我的一天”智能推荐功能，有助于利用碎片时间专注完成当日重点。</p><h2>04 未来展望：智能化与场景融合的演进方向</h2><p>展望未来，移动端管理工具的进化将更深入地与人工智能和具体业务场景结合。<strong>场景智能感知</strong>将成为标配。工具能根据用户的地理位置、时间甚至手机使用状态，自动推送最相关的任务列表或提醒，实现真正的上下文感知管理。</p><p><strong>语音与自然语言交互</strong>的地位将进一步提升。未来的工具不仅能通过语音创建任务，更能理解复杂的自然语言指令，并自动执行，让管理在“动口不动手”间完成。</p><p>最后，<strong>跨工具自动化工作流</strong>将在移动端轻松搭建。用户可以在手机上通过简易操作，将管理工具与其他常用应用连接，自动创建任务或流转信息，让移动端不仅是管理的终端，更是自动化流程的便捷触发与控制中心。</p><pre><code class="python">import json
from datetime import datetime, timedelta
from typing import List, Dict, Optional
from enum import Enum

class TaskPriority(Enum):
    LOW = "低"
    MEDIUM = "中"
    HIGH = "高"
    URGENT = "紧急"

class ContextType(Enum):
    LOCATION = "位置"
    TIME = "时间"
    DEVICE_STATUS = "设备状态"
    CALENDAR = "日历"

class MobileTaskAssistant:
    """
    移动端智能任务助手
    模拟未来移动管理工具的智能情景感知与自动生成能力
    """
    
    def __init__(self):
        self.user_context = {}
        self.task_templates = self._load_templates()
        
    def _load_templates(self) -&gt; Dict:
        """加载情景化任务模板库"""
        return {
            "meeting": {
                "title": "会议跟进",
                "default_steps": ["整理纪要", "分配行动项", "设置下次会议时间"],
                "context_triggers": [ContextType.CALENDAR, ContextType.TIME]
            },
            "commute": {
                "title": "通勤时间处理",
                "default_steps": ["收听语音简报", "批复简易请求", "规划当日重点"],
                "context_triggers": [ContextType.LOCATION, ContextType.TIME]
            },
            "focus": {
                "title": "深度工作时段",
                "default_steps": ["屏蔽非紧急通知", "启动专注计时器", "列出核心任务"],
                "context_triggers": [ContextType.TIME, ContextType.DEVICE_STATUS]
            }
        }
    
    def update_context(self, context_type: ContextType, value: str):
        """更新用户当前情景信息"""
        self.user_context[context_type] = {
            "value": value,
            "updated_at": datetime.now().isoformat()
        }
        print(f"[情景更新] {context_type.value}: {value}")
        
    def generate_contextual_tasks(self) -&gt; List[Dict]:
        """基于当前多重情景生成智能任务建议"""
        suggested_tasks = []
        
        # 情景1：基于时间的建议（例如：周一上午9点）
        if ContextType.TIME in self.user_context:
            time_ctx = self.user_context[ContextType.TIME]
            hour = datetime.fromisoformat(time_ctx['value']).hour
            weekday = datetime.fromisoformat(time_ctx['value']).weekday()
            
            if weekday == 0 and 8 &lt;= hour &lt; 10:  # 周一上午
                suggested_tasks.append({
                    "title": "准备本周团队周会材料",
                    "source": "时间情景触发",
                    "priority": TaskPriority.HIGH,
                    "estimated_duration": "30分钟"
                })
        
        # 情景2：基于位置的建议（例如：接近客户办公地点）
        if ContextType.LOCATION in self.user_context:
            loc = self.user_context[ContextType.LOCATION]['value']
            if "客户" in loc or "Client" in loc:
                suggested_tasks.append({
                    "title": f"回顾与{loc}相关的最新项目进展",
                    "source": "位置情景触发",
                    "priority": TaskPriority.MEDIUM,
                    "estimated_duration": "15分钟"
                })
                
        # 情景3：基于日历事件的建议
        if ContextType.CALENDAR in self.user_context:
            event = self.user_context[ContextType.CALENDAR]['value']
            suggested_tasks.append({
                "title": f"{event}的会前准备",
                "source": "日历情景触发",
                "priority": TaskPriority.HIGH,
                "estimated_duration": "20分钟",
                "template": self.task_templates.get("meeting")
            })
        
        return suggested_tasks
    
    def create_task_from_voice(self, voice_command: str) -&gt; Dict:
        """解析自然语言语音指令并创建结构化任务"""
        # 简化模拟自然语言处理
        voice_command_lower = voice_command.lower()
        
        task = {
            "title": "",
            "steps": [],
            "priority": TaskPriority.MEDIUM,
            "created_via": "语音指令",
            "raw_command": voice_command
        }
        
        # 关键词匹配（模拟NLU理解）
        if "明天" in voice_command_lower:
            due_date = (datetime.now() + timedelta(days=1)).strftime("%Y-%m-%d")
            task["due_date"] = due_date
            
        if "紧急" in voice_command_lower or "立刻" in voice_command_lower:
            task["priority"] = TaskPriority.URGENT
            
        # 提取任务标题（模拟信息提取）
        import re
        # 简单匹配“创建...任务”或“记得...”模式
        pattern = r'(创建|记得|需要)(.+?)(任务|事情|事宜)'
        match = re.search(pattern, voice_command)
        if match:
            task["title"] = match.group(2).strip()
        else:
            task["title"] = voice_command[:30] + "..."
        
        print(f"[语音任务已创建] {task['title']} - 优先级: {task['priority'].value}")
        return task
    
    def get_mobile_optimized_view(self, full_task_list: List[Dict]) -&gt; Dict:
        """为移动端小屏幕生成优化后的信息视图"""
        mobile_view = {
            "today_focus": [],
            "quick_actions": [],
            "notifications": []
        }
        
        now = datetime.now()
        
        for task in full_task_list:
            # 提取今日高优先级任务
            if task.get('priority') in [TaskPriority.HIGH, TaskPriority.URGENT]:
                if task.get('due_date') == now.strftime("%Y-%m-%d"):
                    mobile_view["today_focus"].append({
                        "id": task.get("id", ""),
                        "title": task["title"][:20] + ("..." if len(task["title"]) &gt; 20 else ""),
                        "priority": task["priority"].value
                    })
            
            # 生成快速操作建议
            if "批复" in task["title"] or "审核" in task["title"]:
                mobile_view["quick_actions"].append({
                    "type": "审批",
                    "task_title": task["title"],
                    "action": "approve_or_reject"
                })
                
        # 基于情景生成通知
        if len(mobile_view["today_focus"]) &gt; 5:
            mobile_view["notifications"].append("您今日高优先级任务较多，建议重新评估优先级")
            
        return mobile_view

# 使用示例
if __name__ == "__main__":
    print("=== 移动端智能任务助手演示 ===\n")
    
    # 1. 初始化助手
    assistant = MobileTaskAssistant()
    
    # 2. 模拟更新用户情景
    assistant.update_context(ContextType.TIME, datetime.now().isoformat())
    assistant.update_context(ContextType.LOCATION, "中关村客户大厦附近")
    assistant.update_context(ContextType.CALENDAR, "10:30 产品需求评审会")
    
    # 3. 获取情景化任务建议
    print("\n--- 智能情景任务建议 ---")
    suggested = assistant.generate_contextual_tasks()
    for i, task in enumerate(suggested, 1):
        print(f"{i}. {task['title']} [优先级: {task['priority'].value}]")
    
    # 4. 处理语音指令
    print("\n--- 语音指令处理示例 ---")
    voice_task = assistant.create_task_from_voice("创建一个明天提交季度报告的紧急任务")
    print(f"语音创建成功: {voice_task}")
    
    # 5. 生成移动端优化视图
    print("\n--- 移动端优化视图 ---")
    sample_tasks = [
        {"id": "1", "title": "批复张三的采购申请", "priority": TaskPriority.HIGH, "due_date": datetime.now().strftime("%Y-%m-%d")},
        {"id": "2", "title": "完成产品需求文档", "priority": TaskPriority.URGENT, "due_date": datetime.now().strftime("%Y-%m-%d")},
        voice_task
    ]
    mobile_view = assistant.get_mobile_optimized_view(sample_tasks + suggested)
    print(json.dumps(mobile_view, ensure_ascii=False, indent=2))</code></pre><hr/><blockquote><strong>提示</strong>：选择移动端管理工具时，除了功能，请务必考察其<strong>离线工作能力</strong>和<strong>数据同步稳定性</strong>，这是保证移动场景下体验流畅的基石。建议团队优先选择提供充足免费方案或试用的工具，让成员在实际移动场景中体验后再做决策。</blockquote>]]></description></item><item>    <title><![CDATA[2026无限画布可视化工具全解析：释放创意与协作的新维度 曾经爱过的汉堡包 ]]></title>    <link>https://segmentfault.com/a/1190000047571593</link>    <guid>https://segmentfault.com/a/1190000047571593</guid>    <pubDate>2026-01-26 11:15:06</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>简介：在数字化协作时代，支持无限画布的可视化工具正成为连接碎片化思想、构建系统知识的核心载体。与传统受限于固定页面或分页的工具相比，无限画布通过提供无边界的工作平面，允许用户自由组织思维导图、设计草图、项目看板与文档，实现信息从线性排列到空间关联的范式转变。这类工具融合了可视化、自由布局与实时协作，尤其适合应对复杂的创意构建、项目规划和战略梳理。未来，随着人工智能与空间计算技术的融入，无限画布将进化为更具沉浸感和智能辅助的“数字工作大脑”。</p><p>在日常工作与创意活动中，我们常常受限于传统文档、幻灯片或白板工具的固定边界。思绪是发散的，项目是动态的，但工具却是僵化的。无限画布（Infinite Canvas）正是为了打破这一束缚而生，它提供了一个可以无限缩放、延展和连接的数字平面，让想法得以自然生长和有机组织。</p><h2>01 挑战与机遇：从线性文档到空间化思维的演进</h2><p>在知识工作领域，信息的组织方式正经历一场静默的革命。过去，我们依赖Word文档的线性叙述、PPT的逐页演示或传统白板的有限物理空间。这种方式在处理复杂系统、非线性思考或需要宏观与微观视角快速切换的任务时，往往显得力不从心。</p><p><strong>传统工具的三大核心局限</strong>日益凸显：</p><ul><li><strong>空间限制</strong>：固定页面或白板边界切割了信息的整体性，迫使完整的想法被分割。</li><li><strong>结构僵化</strong>：目录树、幻灯片顺序等预设结构，限制了信息之间建立自由、多维的关联。</li><li><strong>协作壁垒</strong>：静态文件传递和版本混乱，使得团队难以在统一的、动态的空间中进行实时共创。</li></ul><p>与此同时，分布式团队、敏捷项目管理和设计思维等新型工作方式的普及，对工具的<strong>灵活性、可视化程度和实时协作能力</strong>提出了更高要求。无限画布工具正是回应这一需求的产物，它将工作空间从“页面”升级为“宇宙”，让每一个想法、任务或资料都能找到一个位置，并通过连线、嵌套、区域划分建立起丰富的上下文关系，从而实现思维和项目的全景式管理。</p><h2>02 核心价值：无限画布为何重塑工作效率</h2><p>无限画布的核心价值在于它模拟并增强了人类思维的非线性、关联性特质。它不仅仅是一个更大的“纸”，而是一个<strong>多维度的信息组织和协作环境</strong>。</p><ul><li><strong>思维的自由映射</strong>：它允许用户以任意方式（如思维导图式、时间线式、看板式、自由关联式）组织内容，真正实现“所想即所得”。创意、规划和知识库的构建过程从“编写”变为“构建”和“连接”。</li><li><strong>宏观与微观的无缝切换</strong>：通过无限缩放功能，用户可以在总览项目全貌和深入某个细节之间流畅过渡。这种视角的灵活性对于管理复杂项目、理解系统架构至关重要。</li><li><strong>异构信息的融合平台</strong>：文本、图片、形状、便签、网页链接、甚至嵌入的视频、文档和表格，都可以作为“对象”放置在画布的任何位置，并与其他对象建立联系，形成一个丰富的、立体的知识图谱。</li><li><strong>实时协作的共享空间</strong>：它为一个团队提供了一个永久在线、持续演进的共同工作空间。所有讨论、修改和迭代都发生在同一语境下，极大降低了协作的认知成本和信息损耗。</li></ul><h2>03 实战解析：主流无限画布可视化工具深度评测</h2><p>市场上有多种工具都提供了无限画布的核心体验，但在设计哲学、功能侧重和适用场景上各有不同。</p><p><strong>Miro</strong> 是这一领域的全球领军者，以其<strong>丰富的模板库和强大的集成生态</strong>著称。它提供了从头脑风暴、用户体验设计、敏捷仪式到战略规划等数百个预制模板，团队可以一键生成适合的工作区。其插件系统允许无缝接入Jira、Notion、Figma等主流工具，使其成为跨团队、跨流程的协作中枢。Miro的画布性能优秀，即使承载大量元素也能保持流畅，非常适合大型、复杂的协作项目。</p><p><strong>Figma FigJam</strong> 作为设计工具Figma的孪生产品，完美继承了其<strong>流畅的实时协作体验和精致的设计基因</strong>。它的核心优势在于与Figma设计文件的深度互通，设计师可以在设计稿和头脑风暴画布之间无缝切换，让创意到设计的链路极度顺滑。FigJam的工具集简洁而富有表现力，如表情符号反应、计时器、投票等，特别适合进行高效、互动的线上研讨会和工作坊。</p><p><strong>板栗看板</strong> 作为一款在国内体验流畅的视觉化协作工具，在<strong>无限画布与本土化项目管理结合</strong>方面表现出色。它巧妙地将看板管理的敏捷性与无限画布的自由度相结合。团队不仅可以利用无限画布进行自由脑暴和方案梳理，还能一键将讨论结果转化为结构化的看板任务流。其实时协作、评论和任务指派功能深度贴合国内团队的使用习惯，且对中文排版和本地化服务的支持良好，为中小型团队提供了一个低门槛、高自由度的可视化协作入口。</p><p><strong>Heptabase</strong> 则专注于<strong>个人知识管理与深度思考</strong>。它将无限画布与卡片盒笔记法相结合，用户可以将阅读笔记、思考碎片以卡片形式置于白板，并通过绘制连线构建知识网络。它的设计更倾向于构建个人第二大脑，帮助用户进行复杂的知识梳理、研究和写作准备，其双链笔记和可视化关联功能尤为强大。</p><h2>04 未来展望：AI与空间计算驱动的下一代无限画布</h2><p>无限画布的未来，将超越二维平面的协作，向更智能、更沉浸的方向演进。</p><ul><li><strong>AI辅助的内容生成与组织</strong>：未来工具将能理解画布上的内容语境。AI可以根据用户输入的几个关键词，自动生成相关的内容卡片、思维导图分支或草图；它还能识别杂乱的信息，主动建议分类、建立关联或提炼摘要，从“被动画布”变为“主动协作者”。</li><li><strong>三维空间与混合现实画布</strong>：结合VR/AR技术，无限画布将从二维平面扩展到三维空间。团队可以在虚拟房间中，将想法和资料像实物一样摆放在四周，进行沉浸式的空间化思考和评审，这对于产品设计、建筑规划和复杂数据可视化具有革命性意义。</li><li><strong>动态与数据驱动画布</strong>：画布上的元素不再只是静态对象，而是可以与实时数据源连接。例如，一个代表项目进度的图标可以自动关联项目管理工具的数据实时更新状态；一个市场分析区域可以接入数据仪表盘。画布将成为一个动态的、可视化的业务指挥中心。</li><li><strong>更智能的界面与交互</strong>：基于手势、眼动甚至脑机接口的更自然交互方式将被引入，让想法的捕捉和组织更加流畅无感。画布界面本身也可能具备情境感知能力，根据当前任务焦点自动高亮相关信息，或折叠次要内容。</li></ul><hr/><h3>技术视角：一个简易的无限画布对象管理模型</h3><p>无限画布的底层可以看作一个能无限扩展的坐标系统和对“对象”的管理。以下是一个高度简化的概念模型，展示了如何管理画布上的基础元素及其空间关系：</p><pre><code class="python">class InfiniteCanvasObject:
    """代表无限画布上的一个基础对象（如文本、图形、便签）"""
    def __init__(self, obj_id, content, obj_type="text"):
        self.id = obj_id
        self.content = content  # 对象内容
        self.type = obj_type    # 对象类型：text, image, shape, sticky_note等
        self.x = 0  # 画布上的x坐标
        self.y = 0  # 画布上的y坐标
        self.width = 100
        self.height = 50
        self.connections = []  # 与其他对象的连接线ID列表

class InfiniteCanvas:
    """无限画布的核心管理类"""
    def __init__(self):
        self.objects = {}  # 存储所有对象：{obj_id: object}
        self.connections = {}  # 存储所有连接线
        self.viewport_center = (0, 0)  # 当前视图中心坐标
        self.zoom_level = 1.0  # 当前缩放级别

    def add_object(self, content, obj_type, x, y):
        """在指定坐标添加新对象"""
        obj_id = f"obj_{len(self.objects)+1}"
        new_obj = InfiniteCanvasObject(obj_id, content, obj_type)
        new_obj.x, new_obj.y = x, y
        self.objects[obj_id] = new_obj
        return obj_id

    def connect_objects(self, from_obj_id, to_obj_id, connection_type="line"):
        """在两个对象间创建连接"""
        conn_id = f"conn_{len(self.connections)+1}"
        self.connections[conn_id] = {
            'from': from_obj_id,
            'to': to_obj_id,
            'type': connection_type
        }
        # 将连接ID添加到两个对象的关联列表中
        if from_obj_id in self.objects:
            self.objects[from_obj_id].connections.append(conn_id)
        if to_obj_id in self.objects:
            self.objects[to_obj_id].connections.append(conn_id)
        return conn_id

    def get_objects_in_view(self, viewport_width, viewport_height):
        """模拟获取当前视图区域内的对象（简化版：基于坐标范围筛选）"""
        vx, vy = self.viewport_center
        scale = self.zoom_level
        # 计算视图边界
        left = vx - viewport_width / (2 * scale)
        right = vx + viewport_width / (2 * scale)
        top = vy - viewport_height / (2 * scale)
        bottom = vy + viewport_height / (2 * scale)

        visible_objs = []
        for obj in self.objects.values():
            if (left &lt;= obj.x &lt;= right) and (top &lt;= obj.y &lt;= bottom):
                visible_objs.append(obj)
        return visible_objs

    def zoom_to_fit(self, padding=50):
        """缩放并平移视图，使所有对象在视图中居中显示"""
        if not self.objects:
            return
        # 计算所有对象的边界框
        all_x = [obj.x for obj in self.objects.values()]
        all_y = [obj.y for obj in self.objects.values()]
        min_x, max_x = min(all_x), max(all_x)
        min_y, max_y = min(all_y), max(all_y)

        # 计算新的视图中心
        self.viewport_center = ((min_x + max_x) / 2, (min_y + max_y) / 2)
        # 计算合适的缩放级别（这是一个简化逻辑）
        self.zoom_level = 0.8  # 示例值，实际应根据边界框和视图尺寸动态计算
        print(f"视图已调整至中心 {self.viewport_center}, 缩放级别 {self.zoom_level}")

# 使用示例
if __name__ == "__main__":
    # 创建一个无限画布
    my_canvas = InfiniteCanvas()

    # 添加几个对象（模拟头脑风暴）
    idea1 = my_canvas.add_object("开发新功能：AI助手", "sticky_note", -200, 100)
    idea2 = my_canvas.add_object("调研用户反馈", "sticky_note", -50, 150)
    idea3 = my_canvas.add_object("设计交互原型", "sticky_note", 100, 50)

    # 建立对象间的关联
    my_canvas.connect_objects(idea1, idea2)
    my_canvas.connect_objects(idea2, idea3)

    # 模拟获取当前视图中的对象
    print("当前视图中的对象：")
    for obj in my_canvas.get_objects_in_view(800, 600):
        print(f"  - [{obj.type}] {obj.content} 位于 ({obj.x}, {obj.y})")

    # 一键缩放至合适视图
    my_canvas.zoom_to_fit()</code></pre><p>这个简易模型展示了无限画布底层管理的核心概念：<strong>对象的自由定位</strong>、<strong>对象间的关联连接</strong>以及<strong>基于坐标和缩放的视图管理</strong>。实际工具的实现远比此复杂，涉及高性能渲染、实时冲突解决、离线协同算法等前沿技术。</p><p>选择一款合适的无限画布工具，本质上是为团队选择一个<strong>动态、可扩展的协作环境和思维方式</strong>。它不再仅仅是记录结果的工具，更是承载思考过程、激发集体智慧的平台。</p>]]></description></item><item>    <title><![CDATA[如何提高游戏服务器的安全性和防护机制? 德迅云安全_珍珍 ]]></title>    <link>https://segmentfault.com/a/1190000047571599</link>    <guid>https://segmentfault.com/a/1190000047571599</guid>    <pubDate>2026-01-26 11:14:25</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>​ 提高游戏服务器的安全性和防护机制对于保护玩家数据、游戏平衡性和用户体验至关重要。我们可以从服务器端安全、数据安全、DDoS防护、日志监控等方面来提高游戏服务器的安全性。</p><p>服务器端的安全是比较重要的一点。建议用户及时更新游戏服务器和操作系统的补丁和安全更新，以修复已知的漏洞和安全问题。在安全配置方面，可以通过配置服务器端防火墙、入侵检测系统(IDS)、入侵防御系统(IPS)等安全设备，限制对服务器的访问和保护敏感数据。同时，也可以使用SSL/TLS等加密协议保护游戏服务器和客户端之间的通信，防止数据被窃取和篡改。最后也可以限制对服务器的远程访问和管理权限，采用多因素身份验证等安全措施保护管理员账号。</p><p>数据安全防护也比较重要，主要体现在数据加密、反作弊系统及数据验证三个方面。对存储在服务器上的敏感数据(如用户密码、个人信息)进行加密存储，保护数据不被恶意获取。部署反作弊系统和游戏防作弊引擎，检测和阻止作弊行为，维护游戏的公平性和平衡性。对客户端发送的数据进行严格验证和过滤，防止恶意数据包和数据篡改攻击。</p><p>DDOS攻击防护也很重要，使用DDoS防护服务提供商提供的流量清洗服务，过滤和屏蔽DDoS攻击流量，保护服务器免受攻击。配置网络设备和防火墙，限制并发连接数、数据包频率等参数，减缓DDoS攻击对服务器的影响。使用CDN(内容分发网络)服务来分发游戏内容和数据，减轻游戏服务器的负载和DDoS攻击压力。</p><p>日志记录和监控也是提高游戏服务器安全性的重要步骤，定期记录游戏服务器的运行日志和安全事件日志，以便分析和调查安全事件。配置实时监控系统监控服务器的性能和安全状态，及时发现异常行为和安全威胁。</p><p>最后，需要进行定期漏洞扫描和渗透测试，定期对游戏服务器进行漏洞扫描和安全评估，发现并修复潜在的安全漏洞和弱点。进行定期的渗透测试，模拟黑客攻击和渗透行为，评估游戏服务器的安全性和弹性。</p><p>渗透测试（德迅云安全）</p><p>● 安全性漏洞挖掘</p><p>找出应用中存在的安全漏洞。安全应用检测是对传统安全弱点的串联并形成路径，最终通过路径式的利用而达到模拟入侵的效果。发掘应用中影响业务正常运行、导致敏感信息泄露、造成现金和信誉损失的等的漏洞。</p><p>● 漏洞修复方案</p><p>渗透测试目的是防御，故发现漏洞后，修复是关键。安全专家针对漏洞产生的原因进行分析，提出修复建议，以防御恶意攻击者的攻击。</p><p>● 回归测试</p><p>漏洞修复后，对修复方案和结果进行有效性评估，分析修复方案的有损打击和误打击风险，验证漏洞修复结果。汇总漏洞修复方案评估结果，标注漏洞修复结果，更新并发送测试报告。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571601" alt="图片" title="图片"/></p><p>综上所述，提高游戏服务器的安全性和防护机制需要综合考虑网络安全、数据安全、防作弊、DDoS攻击防护、日志和监控、社区管理等多个方面，采取多层次、多维度的安全措施和防护策略，确保游戏服务器的稳定运行和用户数据的安全保护。</p>]]></description></item><item>    <title><![CDATA[如何构建现代Agent以OpenManus为例 墨抒颖 ]]></title>    <link>https://segmentfault.com/a/1190000047571605</link>    <guid>https://segmentfault.com/a/1190000047571605</guid>    <pubDate>2026-01-26 11:13:31</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>一、引言</h2><p>在人工智能快速发展的今天，Agent（智能体）已成为连接大语言模型与实际应用场景的关键桥梁。现代Agent不仅能够理解自然语言指令，更重要的是能够通过工具调用（Tool Calling）主动执行操作，完成复杂的任务。从代码编写、数据分析到网页浏览、文件操作，Agent正在重塑我们与计算机交互的方式。</p><p>OpenManus是一个开源的通用AI Agent框架，它展示了如何构建一个功能完整、架构清晰的现代Agent系统。本文将以OpenManus项目为蓝本，系统性地解答现代Agent构建中的四个核心问题：</p><ol><li><strong>项目结构与核心部分代码如何编写</strong></li><li><strong>工具是如何被添加到Agent的</strong></li><li><strong>Agent是如何调用这些工具的</strong></li><li><strong>Agent是如何思考的</strong></li></ol><p>通过深入分析OpenManus的代码实现，我们将构建对现代Agent架构的完整认知，为构建自己的Agent系统提供实践指导。</p><h2>二、项目结构与核心代码架构</h2><h3>2.1 分层架构设计</h3><p>现代Agent系统通常采用分层架构，每一层负责不同的职责。OpenManus采用了清晰的四层架构设计：</p><h3>基础层（Base Layer）：<code>app/agent/base.py</code></h3><p><code>BaseAgent</code>是所有Agent的抽象基类，提供了Agent运行的基础设施：</p><pre><code class="python">class BaseAgent(BaseModel, ABC):
    name: str  # Agent唯一标识
    description: Optional[str]  # Agent描述
    system_prompt: Optional[str]  # 系统级指令
    next_step_prompt: Optional[str]  # 下一步行动提示

    llm: LLM  # 大语言模型实例
    memory: Memory  # 记忆存储
    state: AgentState  # 当前状态（IDLE/RUNNING/FINISHED/ERROR）

    max_steps: int = 10  # 最大执行步数
    current_step: int = 0  # 当前步数
</code></pre><p><strong>核心功能</strong>：</p><ol><li><strong>状态管理</strong>：通过<code>state_context</code>上下文管理器实现安全的状态转换</li><li><strong>内存管理</strong>：<code>update_memory()</code>方法统一管理对话历史</li><li><strong>执行循环</strong>：<code>run()</code>方法实现主执行循环，包含步数限制和卡死检测</li></ol><pre><code class="python">async def run(self, request: Optional[str] = None) -&gt; str:
    if request:
        self.update_memory("user", request)

    async with self.state_context(AgentState.RUNNING):
        while (self.current_step &lt; self.max_steps and
               self.state != AgentState.FINISHED):
            self.current_step += 1
            step_result = await self.step()  # 执行单步

            if self.is_stuck():  # 检测是否卡死
                self.handle_stuck_state()
</code></pre><h3>思考层（Reasoning Layer）：<code>app/agent/react.py</code></h3><p><code>ReActAgent</code>实现了经典的ReAct（Reasoning + Acting）模式，将Agent的执行分为思考和行动两个阶段：</p><pre><code class="python">class ReActAgent(BaseAgent, ABC):
    @abstractmethod
    async def think(self) -&gt; bool:
        """处理当前状态并决定下一步行动"""

    @abstractmethod
    async def act(self) -&gt; str:
        """执行已决定的行动"""

    async def step(self) -&gt; str:
        """执行单步：思考然后行动"""
        should_act = await self.think()
        if not should_act:
            return "Thinking complete - no action needed"
        return await self.act()
</code></pre><p>这种设计将"决策"和"执行"解耦，使得Agent的思考过程更加清晰可控。</p><h3>工具调用层（Tool Call Layer）：<code>app/agent/toolcall.py</code></h3><p><code>ToolCallAgent</code>在ReAct模式基础上，实现了具体的工具调用机制：</p><pre><code class="python">class ToolCallAgent(ReActAgent):
    available_tools: ToolCollection  # 可用工具集合
    tool_choices: TOOL_CHOICE_TYPE = ToolChoice.AUTO
    tool_calls: List[ToolCall] = Field(default_factory=list)

    async def think(self) -&gt; bool:
        # 调用LLM，传入工具列表
        response = await self.llm.ask_tool(
            messages=self.messages,
            system_msgs=[Message.system_message(self.system_prompt)],
            tools=self.available_tools.to_params(),  # 工具列表
            tool_choice=self.tool_choices,
        )
        # 解析LLM返回的工具调用
        self.tool_calls = response.tool_calls if response else []
        # ...

    async def act(self) -&gt; str:
        # 执行工具调用
        for command in self.tool_calls:
            result = await self.execute_tool(command)
            # 将结果添加到记忆
            tool_msg = Message.tool_message(
                content=result,
                tool_call_id=command.id,
                name=command.function.name,
            )
            self.memory.add_message(tool_msg)
</code></pre><h3>应用层（Application Layer）：<code>app/agent/manus.py</code></h3><p><code>Manus</code>是具体的业务Agent实现，配置了实际可用的工具集合：</p><pre><code class="python">class Manus(ToolCallAgent):
    name: str = "Manus"
    system_prompt: str = SYSTEM_PROMPT.format(directory=config.workspace_root)

    # 配置工具集合
    available_tools: ToolCollection = Field(
        default_factory=lambda: ToolCollection(
            PythonExecute(),      # Python代码执行
            BrowserUseTool(),     # 浏览器操作
            StrReplaceEditor(),   # 文件编辑
            AskHuman(),          # 人工交互
            Terminate(),         # 终止工具
        )
    )
</code></pre><h3>2.2 核心代码模块</h3><h3>数据模型：<code>app/schema.py</code></h3><p>定义了Agent系统的核心数据结构：</p><ul><li><strong>Message</strong>：消息模型，支持user、assistant、system、tool四种角色</li><li><strong>Memory</strong>：对话历史管理，维护完整的消息序列</li><li><strong>ToolCall</strong>：工具调用结构，包含工具ID、名称和参数</li><li><strong>AgentState</strong>：Agent状态枚举（IDLE、RUNNING、FINISHED、ERROR）</li></ul><pre><code class="python">class Message(BaseModel):
    role: ROLE_TYPE  # user/assistant/system/tool
    content: Optional[str]
    tool_calls: Optional[List[ToolCall]]
    tool_call_id: Optional[str]  # 关联工具调用结果
    base64_image: Optional[str]  # 支持多模态
</code></pre><h3>LLM封装：<code>app/llm.py</code></h3><p><code>LLM</code>类提供了统一的大模型接口，关键方法：</p><ul><li><strong><code>ask_tool()</code></strong>：支持function calling的调用方法，接收工具列表并返回工具调用决策</li><li><strong>Token计数与管理</strong>：跟踪输入输出token，防止超出限制</li><li><strong>消息格式化</strong>：将内部Message对象转换为LLM API格式</li></ul><pre><code class="python">async def ask_tool(
    self,
    messages: List[Union[dict, Message]],
    system_msgs: Optional[List[Union[dict, Message]]] = None,
    tools: Optional[List[dict]] = None,
    tool_choice: TOOL_CHOICE_TYPE = ToolChoice.AUTO,
) -&gt; ChatCompletionMessage:
    # 格式化消息
    messages = self.format_messages(messages, supports_images)

    # 计算token并检查限制
    input_tokens = self.count_message_tokens(messages)
    if not self.check_token_limit(input_tokens):
        raise TokenLimitExceeded(...)

    # 调用API
    response = await self.client.chat.completions.create(
        model=self.model,
        messages=messages,
        tools=tools,
        tool_choice=tool_choice,
    )
    return response.choices[0].message
</code></pre><h3>工具系统：<code>app/tool/</code></h3><p>工具系统是Agent能力的核心扩展点：</p><ul><li><strong>BaseTool</strong>：所有工具的抽象基类</li><li><strong>ToolCollection</strong>：工具集合管理器，提供统一的工具查找和执行接口</li><li><strong>具体工具实现</strong>：PythonExecute、BrowserUseTool、StrReplaceEditor等</li></ul><h2>三、工具如何被添加到Agent</h2><h3>3.1 工具的定义与实现</h3><h3>工具基类设计</h3><p>所有工具都继承自<code>BaseTool</code>，它定义了工具的标准接口：</p><pre><code class="python">class BaseTool(ABC, BaseModel):
    name: str  # 工具名称，必须唯一
    description: str  # 工具描述，LLM据此决定是否使用
    parameters: Optional[dict]  # JSON Schema格式的参数定义

    @abstractmethod
    async def execute(self, **kwargs) -&gt; Any:
        """工具执行逻辑，子类必须实现"""
        pass

    def to_param(self) -&gt; Dict:
        """转换为OpenAI function calling格式"""
        return {
            "type": "function",
            "function": {
                "name": self.name,
                "description": self.description,
                "parameters": self.parameters,
            },
        }
</code></pre><h3>工具实现示例</h3><p>以<code>PythonExecute</code>工具为例：</p><pre><code class="python">class PythonExecute(BaseTool):
    name: str = "python_execute"
    description: str = "Executes Python code string..."
    parameters: dict = {
        "type": "object",
        "properties": {
            "code": {
                "type": "string",
                "description": "The Python code to execute.",
            },
        },
        "required": ["code"],
    }

    async def execute(self, code: str, timeout: int = 5) -&gt; Dict:
        """执行Python代码"""
        # 使用多进程执行，支持超时控制
        with multiprocessing.Manager() as manager:
            result = manager.dict({"observation": "", "success": False})
            proc = multiprocessing.Process(
                target=self._run_code, args=(code, result, safe_globals)
            )
            proc.start()
            proc.join(timeout)
            # ...
        return dict(result)
</code></pre><p>工具描述的质量直接影响LLM的选择准确性。好的描述应该：</p><ul><li>清晰说明工具的用途</li><li>明确参数的含义和约束</li><li>说明工具的使用场景和限制</li></ul><h3>3.2 Agent中的工具配置</h3><h3>静态工具配置</h3><p>在Agent类定义时，通过<code>Field(default_factory=...)</code>配置工具集合：</p><pre><code class="python">class Manus(ToolCallAgent):
    available_tools: ToolCollection = Field(
        default_factory=lambda: ToolCollection(
            PythonExecute(),
            BrowserUseTool(),
            StrReplaceEditor(),
            AskHuman(),
            Terminate(),
        )
    )
</code></pre><p>这种方式适合在Agent初始化时就确定可用的工具。</p><h3>动态工具添加</h3><p><code>ToolCollection</code>提供了动态添加工具的方法：</p><pre><code class="python">class ToolCollection:
    def __init__(self, *tools: BaseTool):
        self.tools = tools
        self.tool_map = {tool.name: tool for tool in tools}

    def add_tool(self, tool: BaseTool):
        """添加单个工具"""
        if tool.name in self.tool_map:
            logger.warning(f"Tool {tool.name} already exists, skipping")
            return self
        self.tools += (tool,)
        self.tool_map[tool.name] = tool
        return self

    def add_tools(self, *tools: BaseTool):
        """批量添加工具"""
        for tool in tools:
            self.add_tool(tool)
        return self
</code></pre><h3>MCP工具的动态添加</h3><p>OpenManus支持通过MCP（Model Context Protocol）协议动态连接远程工具服务器：</p><pre><code class="python">class Manus(ToolCallAgent):
    mcp_clients: MCPClients = Field(default_factory=MCPClients)

    async def connect_mcp_server(
        self, server_url: str, server_id: str = "", use_stdio: bool = False
    ) -&gt; None:
        """连接MCP服务器并添加其工具"""
        if use_stdio:
            await self.mcp_clients.connect_stdio(server_url, [], server_id)
        else:
            await self.mcp_clients.connect_sse(server_url, server_id)

        # 获取新工具并添加到可用工具集合
        new_tools = [
            tool for tool in self.mcp_clients.tools
            if tool.server_id == server_id
        ]
        self.available_tools.add_tools(*new_tools)
</code></pre><p>MCP工具的工作流程：</p><ol><li><strong>连接服务器</strong>：通过SSE或stdio建立连接</li><li><strong>发现工具</strong>：调用<code>list_tools()</code>获取服务器提供的工具列表</li><li><strong>创建代理工具</strong>：为每个远程工具创建<code>MCPClientTool</code>代理</li><li><strong>添加到集合</strong>：将代理工具添加到Agent的工具集合中</li></ol><pre><code class="python">class MCPClientTool(BaseTool):
    """MCP工具的代理，执行时调用远程服务器"""
    session: Optional[ClientSession] = None
    server_id: str = ""
    original_name: str = ""

    async def execute(self, **kwargs) -&gt; ToolResult:
        """通过MCP协议调用远程工具"""
        result = await self.session.call_tool(self.original_name, kwargs)
        return ToolResult(output=result.content)
</code></pre><h3>3.3 工具Schema转换</h3><p>工具必须转换为LLM可理解的格式。<code>to_param()</code>方法将工具转换为OpenAI function calling格式：</p><pre><code class="python">def to_param(self) -&gt; Dict:
    return {
        "type": "function",
        "function": {
            "name": self.name,
            "description": self.description,
            "parameters": self.parameters,  # JSON Schema格式
        },
    }
</code></pre><p><code>ToolCollection.to_params()</code>将所有工具转换为列表：</p><pre><code class="python">def to_params(self) -&gt; List[Dict[str, Any]]:
    return [tool.to_param() for tool in self.tools]
</code></pre><p>这个工具列表会被传递给LLM，LLM根据工具描述和当前上下文，决定调用哪些工具。</p><h2>四、Agent如何调用这些工具</h2><h3>4.1 工具调用的完整流程</h3><p>Agent调用工具的过程遵循ReAct模式，分为三个阶段：</p><h3>Step 1: 思考阶段（think）</h3><p>Agent分析当前状态，决定需要调用哪些工具：</p><pre><code class="python">async def think(self) -&gt; bool:
    # 1. 添加下一步提示到消息历史
    if self.next_step_prompt:
        user_msg = Message.user_message(self.next_step_prompt)
        self.messages += [user_msg]

    # 2. 调用LLM，传入工具列表
    response = await self.llm.ask_tool(
        messages=self.messages,  # 对话历史
        system_msgs=[Message.system_message(self.system_prompt)],
        tools=self.available_tools.to_params(),  # 工具列表
        tool_choice=self.tool_choices,  # AUTO/REQUIRED/NONE
    )

    # 3. 解析LLM返回的工具调用
    self.tool_calls = response.tool_calls if response else []
    content = response.content if response else ""

    # 4. 创建Assistant消息并添加到记忆
    assistant_msg = Message.from_tool_calls(
        content=content, tool_calls=self.tool_calls
    )
    self.memory.add_message(assistant_msg)

    return bool(self.tool_calls)
</code></pre><p>LLM接收的信息包括：</p><ul><li><strong>对话历史</strong>：用户请求、之前的工具调用和结果</li><li><strong>系统提示词</strong>：定义Agent的角色和能力边界</li><li><strong>工具列表</strong>：所有可用工具的schema</li><li><strong>下一步提示</strong>：指导Agent如何选择工具</li></ul><p>LLM基于这些信息，生成结构化的工具调用决策。</p><h3>Step 2: 执行阶段（act）</h3><p>Agent执行LLM决定的工具调用：</p><pre><code class="python">async def act(self) -&gt; str:
    if not self.tool_calls:
        return self.messages[-1].content or "No action to execute"

    results = []
    for command in self.tool_calls:
        # 执行单个工具调用
        result = await self.execute_tool(command)

        # 将结果封装为ToolMessage
        tool_msg = Message.tool_message(
            content=result,
            tool_call_id=command.id,
            name=command.function.name,
        )
        self.memory.add_message(tool_msg)
        results.append(result)

    return "\\n\\n".join(results)
</code></pre><h3>Step 3: 结果反馈</h3><p>工具执行结果被添加到对话历史，供下一轮思考使用：</p><pre><code class="python">async def execute_tool(self, command: ToolCall) -&gt; str:
    name = command.function.name

    # 1. 查找工具实例
    if name not in self.available_tools.tool_map:
        return f"Error: Unknown tool '{name}'"

    # 2. 解析参数
    args = json.loads(command.function.arguments or "{}")

    # 3. 执行工具
    result = await self.available_tools.execute(name=name, tool_input=args)

    # 4. 处理特殊工具（如Terminate）
    await self._handle_special_tool(name=name, result=result)

    # 5. 格式化结果
    observation = f"Observed output of cmd `{name}` executed:\\n{str(result)}"
    return observation
</code></pre><h3>4.2 核心代码流程</h3><h3>ToolCollection.execute()：工具执行入口</h3><pre><code class="python">async def execute(
    self, *, name: str, tool_input: Dict[str, Any] = None
) -&gt; ToolResult:
    # 1. 根据名称查找工具
    tool = self.tool_map.get(name)
    if not tool:
        return ToolFailure(error=f"Tool {name} is invalid")

    try:
        # 2. 调用工具的execute方法
        result = await tool(**tool_input)
        return result
    except ToolError as e:
        return ToolFailure(error=e.message)
</code></pre><h3>工具选择策略</h3><p><code>tool_choice</code>参数控制LLM的工具选择行为：</p><ul><li><strong>AUTO</strong>：LLM自主决定是否调用工具（默认）</li><li><strong>REQUIRED</strong>：必须调用至少一个工具</li><li><strong>NONE</strong>：不允许调用工具，只能返回文本</li></ul><pre><code class="python">if self.tool_choices == ToolChoice.REQUIRED and not self.tool_calls:
    # 要求调用工具但LLM没有返回，可能需要重试
    return True

if self.tool_choices == ToolChoice.AUTO and not self.tool_calls:
    # 自动模式，如果没有工具调用但有文本内容，继续
    return bool(content)
</code></pre><h3>4.3 执行循环</h3><p>完整的执行循环在<code>BaseAgent.run()</code>中实现：</p><pre><code class="python">async def run(self, request: Optional[str] = None) -&gt; str:
    if request:
        self.update_memory("user", request)

    results: List[str] = []
    async with self.state_context(AgentState.RUNNING):
        while (
            self.current_step &lt; self.max_steps and
            self.state != AgentState.FINISHED
        ):
            self.current_step += 1

            # 执行单步：think -&gt; act
            step_result = await self.step()

            # 检测是否卡死
            if self.is_stuck():
                self.handle_stuck_state()

            results.append(f"Step {self.current_step}: {step_result}")

    return "\\n".join(results)
</code></pre><p>每一步都是完整的think-act循环，直到任务完成或达到最大步数。</p><h2>五、Agent是如何思考的</h2><h3>5.1 ReAct模式：推理与行动循环</h3><p>ReAct（Reasoning + Acting）是现代Agent的核心模式，它将Agent的执行分为三个环节：</p><ol><li><strong>Reasoning（推理）</strong>：分析当前状态，理解任务，决定下一步行动</li><li><strong>Acting（行动）</strong>：执行选定的工具</li><li><strong>Observing（观察）</strong>：收集工具执行结果，更新状态</li></ol><p>这三个环节循环往复，直到任务完成。</p><h3>实现机制</h3><pre><code class="python">async def step(self) -&gt; str:
    should_act = await self.think()  # 思考：分析并决策
    if not should_act:
        return "Thinking complete - no action needed"
    return await self.act()  # 行动：执行工具
</code></pre><p>这种设计的优势：</p><ul><li><strong>可解释性</strong>：每一步的思考过程都记录在对话历史中</li><li><strong>可控性</strong>：可以在思考阶段进行干预和调整</li><li><strong>可扩展性</strong>：可以轻松添加新的思考策略</li></ul><h3>5.2 LLM驱动的决策机制</h3><h3>提示词工程</h3><p>Agent的思考能力主要依赖于精心设计的提示词：</p><p><strong>System Prompt</strong>：定义Agent的角色和能力边界</p><pre><code class="python">SYSTEM_PROMPT = (
    "You are OpenManus, an all-capable AI assistant, aimed at solving any task "
    "presented by the user. You have various tools at your disposal that you can "
    "call upon to efficiently complete complex requests. Whether it's programming, "
    "information retrieval, file processing, web browsing, or human interaction "
    "(only for extreme cases), you can handle it all."
    "The initial directory is: {directory}"
)
</code></pre><p><strong>Next Step Prompt</strong>：指导Agent如何选择工具</p><pre><code class="python">NEXT_STEP_PROMPT = """
Based on user needs, proactively select the most appropriate tool or combination
of tools. For complex tasks, you can break down the problem and use different tools
step by step to solve it. After using each tool, clearly explain the execution
results and suggest the next steps.

If you want to stop the interaction at any point, use the `terminate` tool/function call.
"""
</code></pre><p><strong>工具描述</strong>：每个工具的name、description、parameters共同构成LLM决策的依据</p><h3>Function Calling机制</h3><p>LLM的function calling能力使得Agent能够进行结构化决策：</p><pre><code class="python">response = await self.llm.ask_tool(
    messages=self.messages,  # 完整的对话历史
    system_msgs=[Message.system_message(self.system_prompt)],
    tools=self.available_tools.to_params(),  # 工具schema列表
    tool_choice=self.tool_choices,  # 选择策略
)
</code></pre><p>LLM的处理过程：</p><ol><li><strong>理解上下文</strong>：分析对话历史，理解当前任务状态</li><li><strong>评估工具</strong>：根据工具描述，评估哪些工具适合当前任务</li><li><strong>生成调用</strong>：生成结构化的工具调用，包含工具名称和参数</li><li><strong>参数验证</strong>：参数必须符合JSON Schema定义</li></ol><p>LLM返回的格式：</p><pre><code class="python">{
    "content": "我需要先查看文件内容，然后进行编辑",  # 思考过程
    "tool_calls": [
        {
            "id": "call_abc123",
            "type": "function",
            "function": {
                "name": "str_replace_editor",
                "arguments": '{"command": "view", "path": "/path/to/file"}'
            }
        }
    ]
}
</code></pre><h3>5.3 状态管理与循环控制</h3><h3>Agent状态机</h3><p>Agent的状态转换遵循明确的状态机：</p><pre><code class="python">class AgentState(str, Enum):
    IDLE = "IDLE"      # 空闲，等待任务
    RUNNING = "RUNNING"  # 执行中
    FINISHED = "FINISHED"  # 任务完成
    ERROR = "ERROR"    # 发生错误
</code></pre><p>状态转换通过上下文管理器安全控制：</p><pre><code class="python">@asynccontextmanager
async def state_context(self, new_state: AgentState):
    previous_state = self.state
    self.state = new_state
    try:
        yield
    except Exception as e:
        self.state = AgentState.ERROR
        raise e
    finally:
        self.state = previous_state
</code></pre><h3>执行循环控制</h3><pre><code class="python">while (
    self.current_step &lt; self.max_steps and
    self.state != AgentState.FINISHED
):
    self.current_step += 1
    step_result = await self.step()

    # 卡死检测
    if self.is_stuck():
        self.handle_stuck_state()
</code></pre><p><strong>卡死检测机制</strong>：</p><pre><code class="python">def is_stuck(self) -&gt; bool:
    """检测Agent是否陷入循环"""
    if len(self.memory.messages) &lt; 2:
        return False

    last_message = self.memory.messages[-1]
    if not last_message.content:
        return False

    # 检查是否有重复的assistant消息
    duplicate_count = sum(
        1 for msg in reversed(self.memory.messages[:-1])
        if msg.role == "assistant" and msg.content == last_message.content
    )

    return duplicate_count &gt;= self.duplicate_threshold
</code></pre><p>当检测到卡死时，Agent会添加提示词引导改变策略：</p><pre><code class="python">def handle_stuck_state(self):
    stuck_prompt = (
        "Observed duplicate responses. Consider new strategies and avoid "
        "repeating ineffective paths already attempted."
    )
    self.next_step_prompt = f"{stuck_prompt}\\n{self.next_step_prompt}"
</code></pre><h3>特殊工具处理</h3><p>某些工具具有特殊语义，如<code>Terminate</code>工具会终止Agent执行：</p><pre><code class="python">async def _handle_special_tool(self, name: str, result: Any, **kwargs):
    if not self._is_special_tool(name):
        return

    if self._should_finish_execution(name=name, result=result, **kwargs):
        logger.info(f"Special tool '{name}' has completed the task!")
        self.state = AgentState.FINISHED
</code></pre><h3>5.4 上下文感知与记忆管理</h3><h3>Memory机制</h3><p><code>Memory</code>类维护完整的对话历史：</p><pre><code class="python">class Memory(BaseModel):
    messages: List[Message] = Field(default_factory=list)
    max_messages: int = Field(default=100)

    def add_message(self, message: Message) -&gt; None:
        self.messages.append(message)
        # 限制消息数量，保留最近的
        if len(self.messages) &gt; self.max_messages:
            self.messages = self.messages[-self.max_messages:]
</code></pre><p>对话历史包含完整的交互序列：</p><pre><code>User: "帮我创建一个Python脚本"
Assistant: [思考过程] [tool_calls: python_execute]
Tool: [执行结果]
Assistant: [分析结果] [tool_calls: str_replace_editor]
Tool: [文件创建结果]
Assistant: "脚本已创建完成"
</code></pre><h3>上下文构建</h3><p>Agent的上下文由三部分构成：</p><ol><li><strong>系统提示词</strong>：定义Agent的能力边界和角色</li><li><strong>对话历史</strong>：包含用户请求、Agent思考、工具调用、工具结果</li><li><strong>动态提示词</strong>：根据当前状态调整（如浏览器使用时的上下文）</li></ol><pre><code class="python">async def think(self) -&gt; bool:
    # 检查是否在使用浏览器
    browser_in_use = any(
        tc.function.name == BrowserUseTool().name
        for msg in recent_messages
        if msg.tool_calls
        for tc in msg.tool_calls
    )

    # 如果使用浏览器，添加浏览器上下文
    if browser_in_use:
        self.next_step_prompt = (
            await self.browser_context_helper.format_next_step_prompt()
        )

    return await super().think()
</code></pre><p>这种动态上下文调整使得Agent能够根据当前任务状态，提供更精准的决策。</p><h2>六、架构图与数据流</h2><h3>6.1 Agent执行流程图</h3><pre style="display:none;"><code class="mermaid">flowchart TD
    Start([开始]) --&gt; Init[初始化Agent]
    Init --&gt; SetState[设置状态为RUNNING]
    SetState --&gt; CheckStep{检查步数限制}
    CheckStep --&gt;|未超限| Think[think: 思考阶段]
    CheckStep --&gt;|超限| Finish[终止执行]
    Think --&gt; LLMCall[调用LLM.ask_tool]
    LLMCall --&gt; ParseTool[解析工具调用]
    ParseTool --&gt; HasTool{是否有工具调用?}
    HasTool --&gt;|是| Act[act: 执行阶段]
    HasTool --&gt;|否| CheckContent{是否有文本内容?}
    CheckContent --&gt;|是| Continue[继续循环]
    CheckContent --&gt;|否| Finish
    Act --&gt; ExecuteTool[执行工具]
    ExecuteTool --&gt; AddResult[添加结果到Memory]
    AddResult --&gt; CheckStuck{检测是否卡死?}
    CheckStuck --&gt;|是| HandleStuck[处理卡死状态]
    CheckStuck --&gt;|否| CheckFinish{任务完成?}
    HandleStuck --&gt; CheckFinish
    CheckFinish --&gt;|未完成| Continue
    CheckFinish --&gt;|完成| SetFinished[设置状态为FINISHED]
    Continue --&gt; CheckStep
    SetFinished --&gt; Finish
    Finish --&gt; End([结束])
</code></pre><h3>6.2 工具调用序列图</h3><pre style="display:none;"><code class="mermaid">sequenceDiagram
    participant User as 用户
    participant Agent as Agent
    participant LLM as 大语言模型
    participant Tools as 工具集合
    participant Tool as 具体工具
    participant Memory as 记忆系统

    User-&gt;&gt;Agent: 发送请求
    Agent-&gt;&gt;Memory: 添加用户消息

    loop 执行循环
        Agent-&gt;&gt;Agent: think()
        Agent-&gt;&gt;Memory: 获取对话历史
        Agent-&gt;&gt;LLM: ask_tool(历史+工具列表)
        LLM-&gt;&gt;LLM: 分析上下文
        LLM-&gt;&gt;LLM: 选择工具
        LLM--&gt;&gt;Agent: 返回工具调用决策
        Agent-&gt;&gt;Memory: 添加Assistant消息

        Agent-&gt;&gt;Agent: act()
        loop 遍历工具调用
            Agent-&gt;&gt;Tools: execute(工具名, 参数)
            Tools-&gt;&gt;Tool: 查找工具实例
            Tool-&gt;&gt;Tool: 执行工具逻辑
            Tool--&gt;&gt;Tools: 返回结果
            Tools--&gt;&gt;Agent: 返回ToolResult
            Agent-&gt;&gt;Memory: 添加Tool消息
        end

        Agent-&gt;&gt;Agent: 检查是否完成
    end

    Agent--&gt;&gt;User: 返回最终结果
</code></pre><h3>6.3 类继承关系图</h3><pre style="display:none;"><code class="mermaid">classDiagram
    class BaseAgent {
        +name: str
        +memory: Memory
        +state: AgentState
        +run()
        +step()*
        +update_memory()
    }

    class ReActAgent {
        +think()*
        +act()*
        +step()
    }

    class ToolCallAgent {
        +available_tools: ToolCollection
        +tool_calls: List[ToolCall]
        +think()
        +act()
        +execute_tool()
    }

    class Manus {
        +mcp_clients: MCPClients
        +connect_mcp_server()
    }

    class BaseTool {
        &lt;&lt;abstract&gt;&gt;
        +name: str
        +description: str
        +parameters: dict
        +execute()*
        +to_param()
    }

    class ToolCollection {
        +tools: tuple
        +tool_map: dict
        +execute()
        +add_tool()
        +to_params()
    }

    class PythonExecute {
        +execute()
    }

    class BrowserUseTool {
        +execute()
    }

    BaseAgent &lt;|-- ReActAgent
    ReActAgent &lt;|-- ToolCallAgent
    ToolCallAgent &lt;|-- Manus
    BaseTool &lt;|-- PythonExecute
    BaseTool &lt;|-- BrowserUseTool
    ToolCollection o-- BaseTool
    ToolCallAgent o-- ToolCollection
</code></pre><h3>6.4 数据流图</h3><pre style="display:none;"><code class="mermaid">flowchart LR
    subgraph Input[输入层]
        UserRequest[用户请求]
        SystemPrompt[系统提示词]
        ToolSchemas[工具Schema列表]
    end

    subgraph Processing[处理层]
        Memory[记忆系统]
        LLM[大语言模型]
        Agent[Agent核心]
    end

    subgraph Execution[执行层]
        ToolCollection[工具集合]
        Tool1[工具1]
        Tool2[工具2]
        ToolN[工具N]
    end

    subgraph Output[输出层]
        ToolResults[工具执行结果]
        FinalResponse[最终响应]
    end

    UserRequest --&gt; Memory
    SystemPrompt --&gt; LLM
    ToolSchemas --&gt; LLM
    Memory --&gt; LLM
    LLM --&gt; Agent
    Agent --&gt; ToolCollection
    ToolCollection --&gt; Tool1
    ToolCollection --&gt; Tool2
    ToolCollection --&gt; ToolN
    Tool1 --&gt; ToolResults
    Tool2 --&gt; ToolResults
    ToolN --&gt; ToolResults
    ToolResults --&gt; Memory
    Memory --&gt; FinalResponse
</code></pre><h2>七、实践建议</h2><h3>7.1 如何设计新工具</h3><p>设计新工具时，遵循以下原则：</p><ol><li><strong>清晰的工具描述</strong>：<code>description</code>字段应该详细说明工具的用途、使用场景和限制</li><li><strong>完整的参数定义</strong>：使用JSON Schema精确定义参数类型、约束和必需字段</li><li><strong>错误处理</strong>：工具执行应该返回<code>ToolResult</code>，包含成功结果或错误信息</li><li><strong>安全性考虑</strong>：对于执行代码、文件操作等敏感工具，需要添加权限检查和沙箱隔离</li></ol><p>示例：设计一个文件搜索工具</p><pre><code class="python">class FileSearchTool(BaseTool):
    name: str = "file_search"
    description: str = (
        "Search for files in a directory tree matching a pattern. "
        "Supports glob patterns and regex. Returns list of matching file paths."
    )
    parameters: dict = {
        "type": "object",
        "properties": {
            "directory": {
                "type": "string",
                "description": "Root directory to search in (absolute path)",
            },
            "pattern": {
                "type": "string",
                "description": "Search pattern (glob or regex)",
            },
            "recursive": {
                "type": "boolean",
                "description": "Whether to search recursively",
                "default": True,
            },
        },
        "required": ["directory", "pattern"],
    }

    async def execute(
        self, directory: str, pattern: str, recursive: bool = True
    ) -&gt; ToolResult:
        try:
            # 验证路径安全性
            if not Path(directory).is_absolute():
                return self.fail_response("Directory must be absolute path")

            # 执行搜索
            matches = await self._search_files(directory, pattern, recursive)
            return self.success_response({"files": matches})
        except Exception as e:
            return self.fail_response(f"Search failed: {str(e)}")
</code></pre><h3>7.2 如何优化提示词</h3><p>提示词优化是提升Agent性能的关键：</p><ol><li><p><strong>系统提示词</strong>：</p><ul><li>明确Agent的角色和能力边界</li><li>说明工作目录、可用资源等环境信息</li><li>强调安全性和最佳实践</li></ul></li><li><p><strong>下一步提示词</strong>：</p><ul><li>指导Agent如何分解复杂任务</li><li>说明工具选择的原则</li><li>强调结果验证和错误处理</li></ul></li><li><p><strong>工具描述</strong>：</p><ul><li>使用具体、可操作的描述</li><li>说明工具的限制和注意事项</li><li>提供使用示例（在description中）</li></ul></li></ol><p>示例：优化后的系统提示词</p><pre><code class="python">SYSTEM_PROMPT = """You are OpenManus, a capable AI assistant.

Your capabilities:
- Execute Python code for data processing and analysis
- Browse the web to gather information
- Edit files using safe string replacement
- Interact with users when clarification is needed

Working directory: {directory}

Important guidelines:
- Always verify file paths before operations
- Use sandboxed execution for untrusted code
- Ask for confirmation before destructive operations
- Explain your reasoning at each step
"""
</code></pre><h3>7.3 如何调试Agent行为</h3><p>调试Agent需要系统化的方法：</p><ol><li><p><strong>日志记录</strong>：在关键节点添加详细日志</p><ul><li>思考阶段的LLM输入输出</li><li>工具调用的参数和结果</li><li>状态转换和错误信息</li></ul></li><li><strong>记忆检查</strong>：定期检查<code>agent.memory.messages</code>，验证对话历史的正确性</li><li><strong>工具测试</strong>：单独测试每个工具，确保其行为符合预期</li><li><strong>逐步执行</strong>：使用<code>max_steps=1</code>限制，逐步观察Agent的行为</li></ol><p>示例：调试工具</p><pre><code class="python">async def debug_agent(agent: ToolCallAgent, request: str):
    """调试Agent执行过程"""
    print(f"Request: {request}")
    print(f"Available tools: {[t.name for t in agent.available_tools.tools]}")

    # 单步执行
    agent.max_steps = 1
    await agent.run(request)

    # 检查记忆
    print("\\nMemory contents:")
    for i, msg in enumerate(agent.memory.messages):
        print(f"{i}. {msg.role}: {msg.content[:100]}")
        if msg.tool_calls:
            print(f"   Tool calls: {[tc.function.name for tc in msg.tool_calls]}")
</code></pre><h3>7.4 性能优化建议</h3><ol><li><p><strong>Token管理</strong>：</p><ul><li>监控token使用量，避免超出限制</li><li>对于长对话，考虑消息摘要或滑动窗口</li><li>工具描述要简洁但完整</li></ul></li><li><p><strong>工具选择优化</strong>：</p><ul><li>限制工具数量，只包含必要的工具</li><li>使用工具分组，根据任务类型动态加载</li><li>优化工具描述，提高LLM选择准确性</li></ul></li><li><p><strong>并发执行</strong>：</p><ul><li>对于独立的工具调用，可以考虑并发执行</li><li>注意工具之间的依赖关系</li></ul></li><li><p><strong>缓存机制</strong>：</p><ul><li>缓存工具执行结果（如文件读取、API调用）</li><li>避免重复执行相同的操作</li></ul></li></ol><p>示例：工具结果缓存</p><pre><code class="python">from functools import lru_cache
from datetime import datetime, timedelta

class CachedTool(BaseTool):
    _cache: Dict[str, Tuple[Any, datetime]] = {}
    _cache_ttl: timedelta = timedelta(minutes=5)

    async def execute(self, **kwargs) -&gt; ToolResult:
        cache_key = str(sorted(kwargs.items()))

        # 检查缓存
        if cache_key in self._cache:
            result, timestamp = self._cache[cache_key]
            if datetime.now() - timestamp &lt; self._cache_ttl:
                return result

        # 执行工具
        result = await self._execute_impl(**kwargs)

        # 更新缓存
        self._cache[cache_key] = (result, datetime.now())
        return result
</code></pre><h2>八、总结</h2><h3>8.1 现代Agent的核心要素</h3><p>通过深入分析OpenManus项目，我们总结出现代Agent系统的核心要素：</p><ol><li><strong>分层架构</strong>：基础层、思考层、工具调用层、应用层的清晰分离</li><li><strong>ReAct模式</strong>：推理-行动-观察的循环机制</li><li><strong>工具系统</strong>：统一的工具接口和动态扩展能力</li><li><strong>LLM集成</strong>：通过function calling实现智能决策</li><li><strong>状态管理</strong>：完善的状态机和执行控制</li><li><strong>记忆系统</strong>：完整的对话历史管理</li></ol><h3>8.2 OpenManus架构的优势</h3><p>OpenManus的架构设计具有以下优势：</p><ol><li><strong>可扩展性</strong>：通过BaseTool抽象，可以轻松添加新工具</li><li><strong>可维护性</strong>：清晰的分层结构，职责明确</li><li><strong>灵活性</strong>：支持静态和动态工具配置，支持MCP协议</li><li><strong>健壮性</strong>：完善的错误处理和状态管理</li><li><strong>可观测性</strong>：详细的日志和记忆系统</li></ol><h3>8.3 未来发展方向</h3><p>现代Agent技术仍在快速发展，未来可能的方向包括：</p><ol><li><strong>多Agent协作</strong>：多个Agent协同完成复杂任务</li><li><strong>长期记忆</strong>：超越对话历史的持久化记忆</li><li><strong>工具学习</strong>：Agent自动发现和学习使用新工具</li><li><strong>安全增强</strong>：更严格的权限控制和沙箱隔离</li><li><strong>性能优化</strong>：更高效的token使用和并发执行</li></ol><h3>8.4 结语</h3><p>构建现代Agent是一个系统工程，需要深入理解LLM能力、工具设计、系统架构等多个方面。OpenManus项目为我们提供了一个优秀的参考实现，展示了如何将理论转化为实践。</p><p>通过本文的系统性分析，我们希望读者能够：</p><ul><li>理解现代Agent的完整架构</li><li>掌握工具系统的设计和实现</li><li>了解Agent的思考和执行机制</li><li>具备构建自己Agent系统的能力</li></ul><p>现代Agent技术正在快速发展，期待更多开发者加入这个领域，共同推动AI Agent技术的进步。</p><hr/><p><strong>参考资料</strong>：</p><ul><li>OpenManus项目：<a href="https://link.segmentfault.com/?enc=twPa%2BRUpPG3XWTy%2B2jAL%2BQ%3D%3D.DwREhCaUuZBRfMB8rnhfT6HSBb4K3sMD5vXHcBBUoRsY5R9pXptVG9tlf30%2FTLX%2F" rel="nofollow" target="_blank">https://github.com/FoundationAgents/OpenManus</a></li><li>ReAct论文：ReAct: Synergizing Reasoning and Acting in Language Models</li><li>OpenAI Function Calling文档：<a href="https://link.segmentfault.com/?enc=%2Fz3vIPr18zQFwdDrvGDf5w%3D%3D.pcbPpEtkMCwLoVetjWPxjKYtJJWelZKmubXNbIACSk46povQrfoSG4Qv1OcQELwk3SJbBkZ1LNThPxEFIftv5g%3D%3D" rel="nofollow" target="_blank">https://platform.openai.com/docs/guides/function-calling</a></li></ul>]]></description></item><item>    <title><![CDATA[美团EvoCUA刷新开源SOTA，会用电脑还会持续进化的智能体！ 美团技术团队 ]]></title>    <link>https://segmentfault.com/a/1190000047571608</link>    <guid>https://segmentfault.com/a/1190000047571608</guid>    <pubDate>2026-01-26 11:12:56</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>大模型虽已具备强大的感知与推理能力，但在面对复杂的计算机图形界面操作（Computer Use）任务时，仍受限于高质量数据稀缺与环境交互反馈缺失的双重挑战。美团技术团队推出了 EvoCUA 模型并在Github、Huggingface开源，通过构建可验证数据合成引擎与十万级并发的交互沙盒，将训练范式从传统的“静态轨迹模仿”转变为高效的“经验进化学习”。该方案在权威评测基准 OSWorld 上以 56.7%  的成功率刷新了开源 SOTA（2026年1月6日榜单），验证了基于经验的进化范式在 GUI 智能体领域的有效性。</p><h2>01 背景与挑战</h2><p>随着大模型的发展，AI 已经具备了强大的感知与推理能力。但在真实的使用场景中，我们希望 Agent 不仅能回答问题，更能解决问题——比如自动处理 Excel 表格、在浏览器中完成复杂的资料检索或跨应用协同。这种对解决问题能力的追求，推动了基础模型从 Chat（对话者）到 Agent（行动者） 的转变。</p><p>在这一进程中，Computer Use Agent（CUA，计算机操作智能体） 是一个关键里程碑。CUA打破了 API 的限制，构建了一种原生的交互方式——像人类一样，通过高分辨率视觉感知屏幕，并利用鼠标键盘完成跨应用的长链路任务，有可能成为下一代操作系统的核心交互入口。</p><p>然而，要训练出一个通用的 CUA，我们面临着严峻的<strong>数据扩展</strong>（Data Scaling）瓶颈。当前主流的训练范式依赖于对专家轨迹的模仿学习，但在将其推向工业级可用时，这种方式面临着三大挑战：</p><ul><li><strong>数据合成质量低</strong>： 真实的高质量轨迹数据极度稀缺且昂贵，而试图用大模型直接生成数据往往会陷入“幻觉”。模型生成的指令或计划经常看似合理，但在真实的 UI 状态下根本不可执行。</li><li><strong>缺乏交互反馈</strong>： 静态数据模仿学习只能告诉模型“什么是对的”，却无法告诉它“如果点偏了会发生什么”。缺乏在大规模环境交互中产生的反馈，模型就无法捕捉操作与环境变化之间复杂的因果动态，难以适应真实环境中渲染差异、网络延迟等随机扰动。</li><li><strong>长链路探索效率低</strong>：计算机操作往往涉及数十步甚至上百步的连续决策，无约束的探索空间巨大且低效。仅靠简单的模仿学习，模型很难学会如何从中间的错误状态中反思并纠错。需要一种更高效和可扩展的范式，让模型专注于从海量自身成功和失败的经验里学习和进化。</li></ul><p>面对上述挑战，我们正式推出了 <strong>EvoCUA</strong>， 一种原生的计算机操作智能体模型。EvoCUA致力于构建一种进化范式，让模型在大规模沙盒环境中，<strong>像生物进化一样，通过不断的试错，反思和修正，积累海量成功和失败经验，进而不断提升自身能力</strong>。</p><p>通过这一范式，EvoCUA-32B 在 Computer Use权威的在线评测基准 OSWorld 上取得了 56.7%  的成功率，刷新了开源模型的 SOTA 记录，以更少的参数量和推理步数超过此前的开源SOTA OpenCUA-72B （45.0%），以及领先的闭源模型UI-TARS-2 （53.1%）。此外，实验证实该方案的通用性，在不同基座（如 Qwen3-VL、OpenCUA）及多个尺寸（8B 至 72B）的模型上均能显著提升 Computer Use 能力 。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571611" alt="" title=""/></p><p>模型上网查询如何配置rbenv开发环境并帮用户安装的示例：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571612" alt="" title="" loading="lazy"/></p><h2>02 核心技术架构</h2><p>EvoCUA 的核心在于构建“交互-反馈-修正”的闭环。我们针对数据、环境、算法三个维度构建了自维持的进化架构：<strong>可验证数据合成引擎</strong>负责生产高质量任务，<strong>高并发交互基建</strong>支持海量轨迹合成，<strong>基于经验的迭代算法</strong>提供模型进化的关键路径。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571613" alt="" title="" loading="lazy"/></p><h3>2.1 可验证数据合成引擎</h3><p>EvoCUA 数据层的核心任务是构建一个自动化流水线，能够合成覆盖各个垂直领域的高质量任务指令。我们要求合成数据要满足两个指标：</p><ul><li><strong>场景完备性</strong>：覆盖从文档办公、Web 检索到系统管理的全场景操作。</li><li><strong>执行确定性</strong>：每一条数据必须在真实环境中可执行、可验证，杜绝逻辑幻觉。</li></ul><p>在实现这一目标时，我们发现业界通用的“大模型生成 + Reward Model (RM) 筛选”范式在 Computer Use 场景下存在本质缺陷：</p><ul><li><strong>语义与执行的割裂</strong>：传统的 RM 基于语义匹配打分，只能判断生成的指令在文本层面是否合理，无法验证其在物理层面能否执行。</li><li><strong>Reward Hacking</strong>：模型倾向于生成逻辑通顺但包含“幻觉”的指令（例如点击不存在的 UI 元素）。这些不可执行的任务会引入大量训练噪音，导致模型在真实操作中产生严重的错误累积。</li></ul><p>为了解决数据可信度问题，我们提出了 “生成即验证” 范式，在生成自然语言指令的同时，同步生成可执行的验证代码，并以沙盒中的实际运行结果作为判断数据是否有效的唯一标准。</p><p>整体数据合成框架如下：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571614" alt="" title="" loading="lazy"/></p><h4>2.1.1 结构化任务空间构建</h4><p>在构建任务空间时，我们并未盲目堆砌数据，而是基于对 GUI 操作本质的两个核心洞见：</p><ul><li><strong>原子能力的可迁移性与泛化性</strong>：GUI 操作虽然千变万化，但其底层的“原子技能”是跨域复用的。例如，“数据筛选”这一能力，无论是在 Excel、CRM 系统还是网页后台中，其逻辑内核是同构的。</li><li><strong>复杂任务的组合本质</strong>：真实世界中的复杂任务，本质上是由有限的原子能力通过特定逻辑编排而成的序列。掌握了原子能力的组合方式，就等于掌握了生成无限复杂任务的“语法”。</li></ul><p>基于这两点思考，我们采用分层构建策略来初始化任务环境。</p><ul><li><strong>原子能力拆解</strong>：我们将复杂的桌面操作任务解构为标准的原子能力单元。基于分层领域分类体系，例如将“Excel 财务分析”任务拆解为“公式计算”、“多列排序”、“透视表生成”等子技能。</li><li><p><strong>资源文件合成</strong>：为了模拟真实环境的复杂性，我们在环境初始化阶段实施了两种资源生成策略。</p><ul><li><strong>参数化合成</strong>：针对结构化数据（如销售报表），我们利用代码生成器批量生产 Word/Excel 文档，随机化其中的姓名、价格、日期等参数。</li><li><strong>非参数化合成</strong>：针对非结构化数据，我们直接注入无版权问题的互联网上的公开资源（如真实的图片、音频、复杂的 PPT 幻灯片），强迫 Agent 处理真实世界中不可预知的视觉噪声和布局多样性。</li></ul></li></ul><h4>2.1.2 指令和验证器合成</h4><p>我们构建了基于 ReAct 的 Agentic 数据合成工作流。当给定一个场景元组（角色、能力、资源）后，作为任务架构师的基础 VLM 会启动生成：</p><ul><li><strong>指令</strong>：生成符合用户意图的自然语言指令，确保任务目标清晰且在当前资源环境下可达成。</li><li><strong>验证器</strong>：同步生成对应的可执行验证Python验证代码以及标准答案（以文件/配置项等形式存在）。这段代码定义了任务成功的精确条件（例如：检查某个单元格的值是否为 X，或某个文件是否存在）。</li></ul><p>不仅如此，我们还引入了沙盒执行反馈机制。生成的验证代码会立即在真实沙盒中运行。如果代码报错（如 API 错误、语法错误），错误日志会被回传给任务架构师进行自我修正。这个过程会迭代多轮，直到验证器本身能够成功运行并通过质量检查。</p><h4>2.1.3 质量保障与去污</h4><p>为了确保入库数据的纯净度，我们在数据落盘前设置了严格的过滤机制。</p><ul><li><strong>一致性过滤</strong>：我们部署了一个测试Agent模型对合成任务进行试跑。通过比对“沙盒实际执行结果”与“验证器判定结果”，我们能精准识别出假阳性（False Positives）数据——即任务其实没做对，但验证器误判为成功的案例。只有那些经得起沙盒检验的数据才会被保留。</li><li><p><strong>三重去污染</strong>：用于合成数据的模型本身见过大量的预训练语料包含大量世界知识，大规模构造合成数据时，有混入和 Benchmark 有一定相关性的数据的风险。为了防止测试集泄露，我们实施了三重去污策略：</p><ul><li>语义去重：使用 LLM 过滤掉与 基准测试集在语义上高度相似的指令。</li><li>配置去重：剔除与测试集具有相同初始化设置（如完全一致的文件名或窗口布局）的任务。</li><li>验证器去重：检查生成的验证逻辑和 Ground Truth 文件，确保没有直接照搬测试脚本。</li></ul></li></ul><p>通过这套数据合成框架，我们成功将可验证的训练数据规模扩展到了数万量级，突破了人工标注的瓶颈。</p><h3>2.2 支撑十万级沙盒并发的基础设施</h3><p>EvoCUA 的进化范式要求 Agent 进行大规模的探索来合成经验轨迹。我们面临的挑战是工业级的：如何在一个集群中稳定调度 100,000+ 个每日活跃沙盒，处理百万级的分钟交互请求，同时保证每个环境的严格隔离与毫秒级响应。为此，我们构建了一套统一的环境沙盒平台，在调度吞吐与环境保真度两个维度做了大量优化。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571615" alt="" title="" loading="lazy"/></p><h4>2.2.1 微服务化编排</h4><p>为了消除大规模强化学习中的 I/O 瓶颈，我们将传统的单体模拟器重构为基于微服务的异步架构。</p><p>异步 I/O 网关： 面对百万级交互请求，传统的阻塞式架构已无法支撑。我们采用了基于 Reactor 模式的异步非阻塞 I/O 设计网关架构，实现了 数百万 QPM（Queries Per Minute）的路由吞吐能力，并且将控制面（生命周期管理）与数据面（环境交互流）彻底解耦，确保长周期的环境执行（如打开一个重型 App）不会阻塞关键的路由逻辑，极大地提升了系统的吞吐上限。</p><p>沙盒批量急速启停： 强化学习的采样阶段具有极强的“脉冲”特性（短时间内需求激增）。我们的分布式调度器通过分片与资源池化技术，实现了极速冷启动能力。通过该优化，系统能够在 1 分钟内拉起 10,000+ 个沙盒实例。这种“即需即供”的弹性能力，确保了环境供给严格匹配训练需求，最小化了策略更新与经验采集之间的延时，保证了训练的高效流转。</p><h4>2.2.2 保真环境构建</h4><p>在解决了“量”的问题后，更关键的是“质”。Computer Use 任务对环境的确定性要求极高，微小的渲染差异或键位冲突都会导致模型训练非最优。</p><ul><li><p><strong>混合虚拟化架构</strong>：为了兼顾容器编排的灵活性与虚拟机的强隔离性，我们采用了 Docker 容器嵌套 QEMU-KVM 的混合架构。</p><ul><li><strong>外层</strong>：使用 Docker 对接 K8s 调度体系，复用美团成熟的容器化运维能力。</li><li><strong>内层</strong>：利用 KVM 硬件加速运行 QEMU 虚拟机。</li><li><strong>价值</strong>：这种设计既提供了内核级的安全隔离（防止 Agent 执行恶意代码穿透宿主机），又保证了接近原生的 GUI 渲染与 I/O 性能。</li></ul></li><li><p><strong>操作系统级校准</strong>：标准 OS 镜像在自动化操作中存在诸多“隐形坑”，导致仿真环境与真实世界存在 Gap。为此，我们深度定制了 Ubuntu 22.04 镜像，实施了内核与用户态的双重补丁：</p><ul><li>输入确定性：  标准虚拟化常存在键位映射冲突（例如 US 键盘布局下 <code>Shift</code> + <code>&lt;</code>状态丢失）。我们深入内核层修改了<code>xkb</code>的符号定义，确保 Agent 的符号意图与实际输入严格一致。</li><li>渲染一致性：  视觉 Agent 对字体布局极其敏感。我们在系统层注入了全套专有字体库并强制刷新<code>fc-cache</code>，消除了文档在仿真环境与真实环境下的视觉渲染差异，防止模型因环境噪音而产生错误的视觉关联。</li></ul></li></ul><h3>2.3 基于经验的学习范式</h3><p>有了可验证的数据和高吞吐的环境，我们的核心目标是如何让模型像人类一样学习：要在大量的自我实践中巩固成功经验，并从失败中吸取教训。然而，单纯依赖静态数据的监督微调存在两个本质缺陷：</p><ul><li><strong>分布偏移</strong>：训练数据的分布往往是“完美路径”，而推理时的环境充满了随机性。模型一旦偏离了专家轨迹，就不知道如何回到正轨。</li><li><strong>负反馈缺失</strong>：SFT 只能告诉模型“怎么做是对的”，却从未告诉它“怎么做是错的”以及“错在哪里”。</li></ul><p>EvoCUA 提出了一种渐进式的进化范式，将训练过程解耦为三个阶段：冷启动（注入先验思维模式）、拒绝采样微调（动态算力分配，巩固成功经验）、强化学习（聚焦关键出错点，从失败经验中学习）。</p><h4>2.3.1 Cold Start: 冷启动</h4><p>在让 Agent 进入大规模环境进行自由探索之前，给模型注入一些思维pattern，能够提高模型的有效探索能力。为了摸清当前 Agent 能力的边界，我们深入分析了 Qwen3-VL-Thinking、OpenCUA-72B 等主流模型推理轨迹。我们发现，各家模型均有一定缺陷。例如：OpenCUA-72B 很容易提前误判成功，而Qwen3-VL模型在动作空间上存在一些明显缺失（如不支持<code>Shift+Click</code>）。基于此，EvoCUA 在冷启动阶段的核心任务，是定义一套完备的动作空间与严谨的思维范式。</p><ul><li><strong>完备的动作空间</strong>：处理复杂操作，如 Excel 中的 <code>Shift + Click</code>。如果是原子的<code>press</code>操作，无法表达这种持续按压的状态。为此，我们将按键拆分为<code>key_down</code> 和<code>key_up</code>。</li><li><p><strong>结构化思维链</strong>：为了避免“幻觉”和“伪成功”，我们给模型注入了一些像人类一样的优秀思维范式：</p><ul><li><strong>目标澄清</strong>：在初始时刻，强制模型复述并拆解用户意图，消除指令歧义。</li><li><strong>观测一致性</strong>：简短且精准，严格对齐当前的视觉元素，防止“看图说话”时的幻觉。</li><li><strong>自我验证</strong>：在发出<code>Terminate</code>信号前，模型必须执行显式的检查步骤。例如在发完邮件后，进入“已发送”文件夹确认，而非盲目自信。</li><li><strong>反思与纠错</strong>：针对采集到的失败轨迹，我们识别出状态偏离的关键分岔点，从错误发生后的那一步恢复环境状态，通过 Prompt 引导和高温采样让模型自我修正。</li><li><strong>终止判断</strong>：<code>Terminate</code>动作必须强依赖于前序的 CoT 论证。如果思维链中没有明确的完成证据，模型不得输出结束信号，以此抑制“伪成功”。</li></ul></li><li><strong>后见之明数据合成</strong>：在训练数据构造上，我们不直接使用模型的原始 CoT。对于成功轨迹，我们采用“后见之明”策略——基于正确的 Action 序列反向重写逻辑严密的思维链；同时混入不可完成任务，教会模型识别环境边界，学会说“No”。</li></ul><p>经过冷启动训练后，模型展现出了明显的行为范式转变。它不仅掌握了终端和复杂快捷键的操作，更重要的是学会了“慢思考"——在关键节点进行校验和反思。这为后续的大规模进化提供了坚实的原子能力基础。</p><h4>2.3.2 RFT：拒绝采样微调</h4><p>冷启动赋予了模型基础的原子能力，接下来的挑战是如何在万级 Query 上进行 Scaling。我们面临的核心权衡是：如何在有限的算力预算下，最大化高质量经验的产出效率与信噪比？如果对所有任务平均用力，会导致简单任务算力浪费，而困难任务探索不足。为此，EvoCUA 设计了一套“阶梯式动态算力分配 + 步级别去噪”的拒绝采样微调策略。</p><p><strong>阶梯式动态算力分配</strong>：为了最大化探索的 ROI，我们将 Query 池划分为不同难度层级，并实施阶梯式的 Rollout 策略。我们将采样次数 K 划分为多个档位 {3, 8, 16, 32, 64}，并为每个档位设定了成功率阈值（如 100%, 75%, 50%...）:</p><ul><li><strong>自适应爬坡</strong>：模型从低 K 档位开始尝试。如果在当前档位的成功率达到了预设阈值（说明模型已掌握），则立即停止采样；反之，若成功率较低，则自动升级到下一档位，投入更饱和的算力进行攻坚。</li><li><strong>边界突破</strong>：这种机制确保了算力被集中投放到模型处于能力边界的困难任务上，而非在已熟练的任务上重复“造轮子”。</li></ul><p><strong>步级去噪</strong>：模型生成的原始轨迹即使成功了，也往往包含大量噪声（如无效的鼠标滑动）。直接学习这些数据会污染模型。我们实施了精细化的清洗策略：</p><ul><li><strong>冗余和错误步骤过滤</strong>：利用 Judge Model 分析成功轨迹，识别并掉对最终结果无贡献的冗余步骤，显著提升了数据的信噪比。</li><li><strong>Infeasible 任务特判</strong>：针对不可完成的任务，成功的轨迹往往伴随着大量的无效尝试后才终止。对于这类数据，我们仅保留最后一步（即正确输出<code>Terminate=Failure</code> 及对应的推理），将中间所有的试错步骤全部剔除。</li></ul><p>通过 RFT，我们将大规模的合成经验内化为模型参数，显著提升了模型在常规路径的执行成功率。</p><h4>2.3.3 RL：强化学习</h4><p>RFT 夯实了模型在常规路径上的执行成功率，但面对长链路任务中的环境扰动（如弹窗、网络延迟、布局微变），模型依然脆弱。相比于成功轨迹中模型已有的知识，失败轨迹中蕴含着广阔的、非线性的树状结构信息，模型往往会在一些关键步骤出错，正是模型能力边界的直接体现。</p><p>传统的 RL 算法通常以整条轨迹为粒度，存在严重的信用分配难题——几十步的操作中可能只有一步是错的，全盘否定会导致有效经验被浪费。</p><p>为了解决这一问题，我们提出了一种面向Computer Use的高效DPO算法，将优化粒度从“轨迹级”下钻到“关键分岔点” ， 重点解决模型在出错边缘的能力边界感知问题。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571616" alt="" title="" loading="lazy"/></p><p><strong>关键分岔点挖掘</strong>：在长达数十步甚至上百步的 GUI 操作中，任务失败往往具有滞后性。模型可能在第 5 步做出了一个微小的错误决策（如选错了筛选条件），但直到第 30 步才因为找不到目标文件而报错。为了精准定位错误，EvoCUA 提出了一种基于参考导向的归因机制——关键分岔点挖掘。 我们利用同一 Query 下的“成功轨迹”与“失败轨迹”进行对齐分析。系统会自动定位到状态一致但动作开始偏离的那一帧，记为关键分岔点。</p><p><strong>双范式偏好对构建</strong>：一旦通过因果诊断锁定了关键错误，我们并未止步于简单的行为克隆，而是针对出错瞬间”和“出错之后”两个不同的时空切片 ， 构造了两种截然不同的 DPO 偏好范式，从而在一次训练中同时兼顾了准确性与鲁棒性。</p><ul><li>范式一：<strong>动作修正</strong>，此范式聚焦于“即时纠错”，旨在教模型在关键分岔点(t时刻)必须“走正道”。我们将导致后续失败的原始错误动作作为负样本；对于正样本，我们优先尝试通过 VLM 语义匹配，将成功参考轨迹中的“正确思考与动作”迁移过来。如果参考轨迹无法对齐，则调用VLMs模型基于当前视觉状态合成全新的正确动作。</li><li>范式二：<strong>反思与恢复</strong>，此范式聚焦于“错误恢复”，旨在提升模型在错误发生后（t+1 时刻）的反思修正能力。在这一时刻，环境状态通常已经因为前一步的错误而发生了偏离（如出现了预料之外的弹窗）。我们把模型无视环境变化、机械执行原计划的“盲目继续”行为标记为负样本；同时，利用 Prompt工程引导模型生成一条“反思链”作为正样本——即教导模型在发现状态异常时，优先选择停下来，观察屏幕异常并重新规划，而不是一条道走到黑。</li></ul><p>通过这两个范式的结合，模型不仅教会了 Agent 如何做对，更教会了它在做错或环境突变时如何反思修正。随着能力的不断提升，上述RFT和DPO可以进行多轮迭代训练。</p><p>除了DPO，我们在实践中还探索了online RL，通过主动的环境交互，模型表现出了持续的奖励增长趋势，会在下一个版本的模型中更新。</p><p>总而言之，我们通过“双重机制”将海量的合成经验高效内化为模型参数：一方面利用 RFT 来夯实基础的执行范式，确保模型在标准任务上的发挥稳定；另一方面利用 RL在复杂的长尾场景中主动纠错，显著提升模型在能力边界上的鲁棒性与泛化力。</p><h2>03 实验评估</h2><p>为了验证 EvoCUA 范式的有效性，我们在权威在线榜单OSWorld上进行评测。实验的核心结论如下：EvoCUA-32B 以 56.7% 的成功率刷新了开源模型 SOTA，并在同等推理预算(max step=50)下逼近了闭源模型 Claude-4.5-Sonnet (58.1%) 的水平；同时验证了该进化范式在不同规模模型上的普适性。</p><h3>3.1 OSWorld 评测</h3><ul><li><strong>开源SOTA</strong>：我们的主力模型 EvoCUA-32B（基于 Qwen3-VL-32B-Thinking 后训练）达到了 56.7% 的成功率。这一成绩大幅领先此前的开源 SOTA（OpenCUA-72B, 45.0%）。值得注意的是，EvoCUA-32B 超越了闭源强基线 UI-TARS-2-2509 (53.1%)。在严格限制 50 步 推理预算的同等条件下，我们与行业顶尖的 Claude-4.5-Sonnet (58.1%) 差距缩小至仅 1.4%。</li><li><strong>小参数大潜力</strong>：EvoCUA-8B 同样表现惊艳，以 46.1% 的成功率击败了 OpenCUA-72B。与同样基于Qwen3-VL-8B训练的Step-GUI-8B (40.2%) 相比，EvoCUA-8B 取得了 +5.9% 的显著优势。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571617" alt="" title="" loading="lazy"/></p><h3>3.2 消融实验</h3><p>为了探究 EvoCUA 性能提升的来源，我们进行了逐层拆解的消融实验。</p><ul><li>统一动作空间 （+4.84%）：通过完善动作空间带来的提升。</li><li>冷启动（+2.62%）：注入高质量的行为先验，确立了思维与行动的对齐。</li><li>RFT 拒绝采样（+3.13%）：通过动态算力巩固成功经验，在不损失pass@k能力基础上，提升模型的pass@1能力。</li><li>Offline DPO（+3.21%）：针对关键分岔点的纠错训练，显著提升了模型鲁棒性。</li><li>迭代训练（+1.90%）：再进行一轮迭代训练，性能持续增长。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571618" alt="" title="" loading="lazy"/></p><h3>3.3 Scaling分析</h3><p>我们进一步验证了 EvoCUA 的 Scaling Law。</p><ul><li><strong>Max Step</strong>：随着推理时步数的增加，我们观察到模型的性能在不断提升。但由于我们数据中超过50步的样本较少，因此大于50步的边际收益收窄。</li><li><strong>Pass@k</strong>：随着采样次数k的增加，EvoCUA 始终保持对初始化模型的显著优势。这表明优化后的 Policy 具有更高的天花板。</li><li><strong>数据规模</strong>：在 RFT 阶段，我们将数据量从 20k 扩展到 1M，观察到了持续的性能爬坡。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571619" alt="" title="" loading="lazy"/></p><h3>3.4 轨迹可视化分析</h3><p>我们随机抽样一条合成指令任务，对训练后的模型采样轨迹进行可视化。以一个电子表格任务为例：“找出每行的最大值并填入 G 列”，以下是EvoCUA-32B在四个关键时刻的思考与执行过程：</p><p><strong>Step 1</strong>：目标澄清，智能体显式复述并拆解了用户指令。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571620" alt="" title="" loading="lazy"/></p><p><strong>Step2</strong>：智能体使用excel公式原子能力Max操作。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571621" alt="" title="" loading="lazy"/></p><p><strong>Step 9</strong>：有状态鼠标交互，专业软件操作常涉及“按住并点击”等组合动作。智能体执行“Shift+点击”操作以选中 G3 到 G11 的数据范围。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571622" alt="" title="" loading="lazy"/></p><p><strong>Step 15</strong>：审慎终止判断，智能体没有盲目停止，而是先生成视觉证据：“我看到 Max 列已计算完毕...”。只有在视觉核验结果符合初始指令后，它才发出<code>terminate</code>信号，确保任务完成。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571623" alt="" title="" loading="lazy"/></p><h2>04 总结展望</h2><p><strong>EvoCUA</strong>，一个基于经验进化范式的原生 Computer Use Agent。通过可验证的合成引擎、可扩展的交互基建和可进化的经验学习算法，我们探索出一条提升Computer Use能力的通用方法。在 OSWorld 基准测试中，EvoCUA 以 <strong>56.7%</strong> 的成功率刷新了开源模型的 SOTA，证明了这条路径的有效性。在超过 100 万卡时的上千组实验中，我们总结了四条关键的洞察，希望能为社区提供参考：</p><ul><li><strong>高信噪比数据是关键</strong>： 成功轨迹是低噪声但低信息量的，失败轨迹是高噪声但高信息量的。如何处理好数据，保证较高的信噪比是模型能力持续提升的关键。</li><li><strong>先验 Pattern 重于数据量</strong>：冷启动阶段，Pattern 的多样性远比数据量重要。一个轻量级但覆盖全原子能力的冷启动，比大量低质量数据的 SFT 更能为后续的 RL 打好基础。</li><li><strong>On-Policy 的重要性</strong>：在长链路任务优化中，要严格使用 On-Policy 数据。一旦过度使用 Off-Policy 数据，会导致优化方向偏离原始模型主分量，且较难恢复。</li><li><strong>可视化驱动的迭代</strong>：数据和算法之外，我们开发了大量用于轨迹可视化和 Debug 的分析工具，一套全流程可视化诊断工具对于数据质量校验、轨迹对比分析和问题发现至关重要。</li></ul><p>尽管取得了阶段性突破，我们必须承认，当前开源模型与顶尖闭源系统（及人类水平）之间仍存在显著差距。这一差距揭示了单纯依赖离线合成轨迹的性能天花板。我们认为，打破这一瓶颈的关键在于在线强化学习。我们初步的实验信号显示，通过主动的环境交互，模型表现出了持续的奖励增长趋势。未来的工作将聚焦于系统性地拓展这一在线进化边界，最终实现完全自主的计算机操作能力。</p><p>目前，EvoCUA 现已全面开源，欢迎访问项目主页获取更多信息：</p><ul><li><strong>Github</strong>: <a href="https://link.segmentfault.com/?enc=L4NKFO5F1xGdDhp7inUXxQ%3D%3D.poFVmlJcnN4yaTTyx32UFS3V5abJSgxRrY8UQlQ5IuO9K2gCMD9ogNpotUr%2BzK4U" rel="nofollow" target="_blank">https://github.com/meituan/EvoCUA</a></li><li><strong>Huggingface</strong>：<a href="https://link.segmentfault.com/?enc=NIs49HpjblDaXpgkMD8YUw%3D%3D.OBfXPXyQo86i7iI7GNOi9SPdT59Iff7PZthB9Fqv5wc%2FUs35fU7RAphDGrkpldOcbY1K1jl4fFUqAqpVq%2FpFrg%3D%3D" rel="nofollow" target="_blank">EvoCUA-32B</a>、<a href="https://link.segmentfault.com/?enc=XyhhruFQmTHTCv0FXKFRKA%3D%3D.FZBZ7OAhb4YhYIaniMpsTZpnvr5SpNbe6rsT0Bv1ccFE0U0qY5osYOyjsF%2FOr5cp6DMZdc4slLE76%2BPEhkNexw%3D%3D" rel="nofollow" target="_blank">EvoCUA-8B</a></li><li><strong>Technical Report</strong>：<a href="https://link.segmentfault.com/?enc=jleFScM1mT%2FqoACoBuTwrw%3D%3D.G5Se9wmC04VsYNMlyADC7SwKZRpIJLbhxXRnoelgbBLfGPiuMnEWvvx6Pt8yA%2FhnFRqg%2BDSBW4f6d9ZCIwoOGA%3D%3D" rel="nofollow" target="_blank">PDF</a></li></ul><p>| 关注「美团技术团队」微信公众号，阅读更多技术干货！</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000046195963" alt="" title="" loading="lazy"/></p><p>| 本文系美团技术团队出品，著作权归属美团。欢迎出于分享和交流等非商业目的转载或使用本文内容，敬请注明“内容转载自美团技术团队”。本文未经许可，不得进行商业性转载或者使用。任何商用行为，请发送邮件至 <a href="mailto:tech@meituan.com" target="_blank">tech@meituan.com</a> 申请授权。</p>]]></description></item><item>    <title><![CDATA[2026 AI 元年：从工具智能到企业“自执行系统”的临界点 智能猫 ]]></title>    <link>https://segmentfault.com/a/1190000047571629</link>    <guid>https://segmentfault.com/a/1190000047571629</guid>    <pubDate>2026-01-26 11:11:55</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h3>引言：2026，不是 AI 更聪明，而是企业第一次“让权”</h3><p>过去几年，人工智能在企业中的角色更多停留在<strong>边缘助手</strong>或<strong>创意补充</strong>： 生成报告、分析数据、辅助人类判断。</p><p><strong>2026 年正在发生的变化本质不同</strong>—— AI 首次被系统性地引入<strong>封闭业务环（Closed Business Loop）</strong>，开始承担<strong>决策—执行—反馈</strong>的完整责任。</p><p>这不是一次工具升级，而是一次<strong>生产力控制权的转移</strong>。</p><h2>一、决策中枢的重构：从“分析支持”到“处方式治理系统”</h2><h3>1. 核心定义：处方式分析（Prescriptive Analytics）</h3><p><strong>处方式分析</strong>指的是：</p><blockquote>AI 系统在预测未来结果的基础上，结合业务目标、资源约束与规则边界，<strong>直接输出可执行决策，并对决策逻辑负责</strong>。</blockquote><p>这标志着 AI 从“建议者”转变为“处方制定者”。</p><h3>2. 核心场景：动态供应链的自主编排</h3><p>在制造业与零售业中，AI 智能体正在接管传统由人类审批的关键节点：</p><ul><li>实时感知全球物流与原材料价格</li><li>自动调整采购规模与供应商组合</li><li>重规划运输路径</li><li>在需求激增时，<strong>无需人工确认直接触发增产</strong></li></ul><p><strong>变化的关键不在于速度，而在于“洞察 → 行动”的零延迟闭环</strong>。 企业的核心矛盾，第一次被交由算法持续调解。</p><h2>二、生产力的原位升级：从 RPA 到智能体工作流</h2><h3>1. 核心定义：Agentic Workflow（智能体工作流）</h3><p><strong>智能体工作流</strong>是指：</p><blockquote>由多个具备感知、推理、规划与工具调用能力的 AI 智能体，分别接管业务流程节点，并通过协议协作形成的自运行系统。</blockquote><p>与传统 RPA 不同：</p><ul><li>无需硬编码路径</li><li>可在异常中自我修正</li><li>不依赖人类实时监控</li></ul><h3>2. 核心场景一：软件工程的“无人维护阶段”</h3><p>在成熟企业中，AI 已进入核心代码库的长期演进流程：</p><ul><li>自主编写与维护测试用例</li><li>自动定位回归缺陷</li><li>提交可审计的修复补丁</li><li>优化架构而非仅“修 bug”</li></ul><h3>3. 核心场景二：金融与合规的实时智能审计</h3><p>AI 智能体可对每一笔交易进行：</p><ul><li>法规语义级匹配</li><li>内控规则比对</li><li>异常模式识别并在风险出现前<strong>自动冻结或上报流程</strong></li></ul><p>在实际落地中，一些企业并不会从零构建智能体体系，而是选择成熟的平台基础设施。 例如 <strong>「智能体来了」（<a href="https://link.segmentfault.com/?enc=8FXlSgCAsqcALHFEOWUVRQ%3D%3D.EihqpI3wBVq1GlT6T%2BjyMaCrxgcx5O07I0r1U2WdaHs%3D" rel="nofollow" target="_blank">https://agentcome.net/</a>）</strong>，为非技术密集型企业提供了将 AI 嵌入财务、法务与运营核心流程的可行路径，实现“降人力密度”的同时，提升系统稳定性。</p><h2>三、知识资产的激活：从静态文档到“可推理经验”</h2><h3>1. 核心定义：企业级神经知识库（Enterprise Neural Knowledge Base）</h3><p>它并非传统意义上的知识管理系统，而是：</p><blockquote>将企业历史数据、行业经验与大模型推理能力深度融合，使 AI 能够理解企业“为何如此运作”。</blockquote><p>经验不再依赖个人，而被转化为<strong>可调用的逻辑结构</strong>。</p><h3>2. 核心场景：研发（R&amp;D）的认知加速</h3><p>在医药、新材料等领域，AI 已从“数据分析者”变为：</p><ul><li>实验设计者</li><li>模拟路径规划者</li><li>研发策略的动态调整者</li></ul><p>通过对实验反馈的持续建模，<strong>AI 正在压缩原本以“年”为单位的研发周期</strong>。</p><h2>四、总结：2026 年之后，企业竞争的真正变量</h2><p><strong>形态转变</strong> AI 不再是对话框里的助手，而是业务后台的<strong>数字执行官</strong>。</p><p><strong>价值逻辑</strong> 真正的效率红利，来自 AI 在高复杂度、强约束场景中的持续决策能力。</p><p><strong>长期视角</strong> 未来企业的竞争，将是<strong>“知识模型化程度”</strong>的竞争。 谁能率先将不可见的经验转化为可协作的智能体网络，谁就拥有更低的组织摩擦成本。</p><p>这不仅是技术普及， 更是一场<strong>企业管理范式的重排</strong>。</p>]]></description></item><item>    <title><![CDATA[Claude Skills 彻底爆了，从实现原理到 Claude Code、CodeX、OpenCo]]></title>    <link>https://segmentfault.com/a/1190000047571632</link>    <guid>https://segmentfault.com/a/1190000047571632</guid>    <pubDate>2026-01-26 11:11:00</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>大家好，我是R哥。</p><p>最近 Claude Skills 又开始爆火了，几个月前我分享《<a href="https://link.segmentfault.com/?enc=nMkUoBnVM9aSBGSFrrReYQ%3D%3D.7B35M%2BGE4BCWgUm1Teo46mX8o17%2FAgPWXVi3rgJbB7hauAOh2JqUa2%2BRCOk6GzolwmQPjxrp%2BAAniir%2BL%2FPAog%3D%3D" rel="nofollow" target="_blank">MCP 不香了，Claude Code 又推出了 Skills！！（保姆级安装和使用教程分享）</a>》时还是不温不火，现在已经火爆全网了。</p><p>经过几个月的发展，Skills 也有了些许变化，这篇我再结合最新的信息，<strong>分享下 Skills 的概念及如何在 Claude Code、CodeX、OpenCode 中创建和如何 Skills。</strong></p><p>万字干货，避免错过，建议收藏慢慢看。。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571635" alt="" title=""/></p><h2>Skills 是什么？</h2><p>Skills 最初由 Anthropic 公司开发，<strong>专门用来扩展 Claude 功能的模块化能力</strong>。</p><p>说白了，Skills 其实就是一个文件夹，这是每个 Skills 的目录结构：</p><pre><code class="markdown">my-skill/
    ├── SKILL.md          # 必选：指令、元数据
  ├── scripts/          # 可选: 执行脚本
  ├── references/       # 可选：参考文档
  └── assets/           # 可选：模板、资源</code></pre><p>每个 Skill 包含<strong>指令、元数据和资源</strong>等，只有当 Claude 认为某个 Skill 和当前任务相关时，它才会启用，即按需加载，从而提升性能，也能大大节省 Tokens 消耗。</p><hr/><p>现在 Anthropic 已经把 Skills 做成《<a href="https://link.segmentfault.com/?enc=3uXrOx7Pr7omGHJktsgi9w%3D%3D.bmh130bVhs%2F8cTjTuIKACfkI9DdNNT%2FendnUXiOyV5g%3D" rel="nofollow" target="_blank">Agent Skills</a>》开放标准了：</p><blockquote><a href="https://link.segmentfault.com/?enc=MaIg1ku1Wzmgzh5BlTOs8Q%3D%3D.k7zpUzwFC9%2BUPhoIh4FYFx0815P5U%2BglaGh8N8ElNrM%3D" rel="nofollow" target="_blank">https://agentskills.io/</a></blockquote><p>这是一个 Skills 开放标准，由 <strong>Anthropic 发布并推动作为开放标准</strong>，旨在让不同 AI 平台都能实现一个通用的 “<strong>Agent Skills</strong>” 格式。</p><p>Anthropic 真是 AI 标准的制定者，前有 <strong>MCP</strong> 协议，现在又弄出了 <strong>Agent Skills</strong> 标准。</p><p>Agent Skills 现在已经被主流的 AI 开发工具全面支持了，我看 <strong>OpenAI、Google、Cursor</strong> 等 AI 厂商都已经跟进并支持 Skills 了。</p><p>比如，我刚在 Claude 写完 Skills，直接就可以复制到 CodeX 中使用，100% 兼容。</p><h2>Skills 的架构</h2><p>Skills 在代码执行环境中运行，它具有<strong>文件系统访问、bash 命令和代码执行</strong>功能。</p><p>这是 Skills 的架构图：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571636" alt="" title="" loading="lazy"/></p><p>可以这样理解，Skills 相当于是虚拟机上的目录，Claude 可以使用计算机上导航文件相同的 bash 命令与它们交互。</p><h2>Skills 的工作原理</h2><p>Skills 是通过<strong>渐进式披露</strong>来高效管理上下文，这张图演示了 Claude 如何加载和使用 PDF 处理 skill 的方式：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571637" alt="" title="" loading="lazy"/></p><p>这种动态加载方式，确保只有相关的 Skill 内容占据上下文窗口。</p><h3>工作流程</h3><h4>第 1 步：发现 Skills（始终加载）</h4><p>Claude 在启动时，代理只会加载每个可用技能的 <code>SKILL.md</code> 中的元数据，比如：<strong>名称和描述</strong>，用来判断它什么时候可能用得上。</p><p>元数据格式如下：</p><pre><code class="markdown">---
name: pdf-processing
description: 从 PDF 文件中提取文本和表格、填充表单、合并文档。在处理 PDF 文件或用户提及 PDF、表单或文档提取时使用。
---</code></pre><p>这种轻量级的加载方式，意味着我们可以集成大量的 Skills 而不会产生上下文成本，Claude 只知道每个 Skill 的存在以及何时使用它。</p><h4>第 2 步：激活 Skills（触发时加载）</h4><p>当任务匹配到某个技能的<strong>描述</strong>时，代理才会把完整的 <code>SKILL.md</code> 指令加载进上下文里。</p><p>参考指令如下：</p><pre><code class="markdown"># PDF 处理

## 快速入门

使用 pdfplumber 从 PDF 中提取文本：

```python
import pdfplumber

with pdfplumber.open("document.pdf") as pdf:
    text = pdf.pages[0].extract_text()
```

有关高级表单填充，请参阅 [FORMS.md](FORMS.md)。</code></pre><p>SKILL.md 的指令包含 Skills 的运行逻辑，包括它的：<strong>工作流、最佳实践和规范</strong>等，其实就是一个提示词说明书文档。</p><h4>第 3 步：执行 Skills（按需加载）</h4><p>代理会按照 <code>SKILL.md</code> 中的指令来操作，必要时还会加载 <code>references</code> 目录中引用的文件，或者运行 <code>scripts</code> 目录下打包好的脚本及代码。</p><p>Skills 通过<strong>渐进式披露</strong>这种方式，可以让代理按需调取更多上下文，从而执行得飞快。</p><h3>渐进式披露成本</h3><p>渐进式披露确保任何给定时间，只有相关内容占据上下文窗口，这是它的成本：</p><table><thead><tr><th align="left">步骤</th><th align="left">加载时间</th><th align="left">令牌成本</th></tr></thead><tbody><tr><td align="left"><strong>第 1 步：发现</strong></td><td align="left">始终加载</td><td align="left">每个 Skill 约 100 个令牌</td></tr><tr><td align="left"><strong>第 2 步：激活</strong></td><td align="left">触发时加载</td><td align="left">不到 5k 个令牌</td></tr><tr><td align="left"><strong>第 3 步：执行</strong></td><td align="left">按需加载</td><td align="left">实际上无限制</td></tr></tbody></table><h2>SKILL.md 的文件结构</h2><p>每一个 Skill 都必须要有一个 <code>SKILL.md</code> 文件，它是一个 <code>Markdown</code> 格式的文件，包含 YAML 前置元数据和 Markdown 指令。</p><p>参考格式如下：</p><pre><code class="markdown">---
name: your-skill-name
description: 简要描述此 Skill 的功能以及何时使用它
license: Apache-2.0
metadata:
  author: example-org
  version: "1.0"
---

# Skill 名称

## 指令
[Claude 要遵循的清晰、分步指导]

## 示例
[使用此 Skill 的具体示例]</code></pre><p>在 <code>SKILL.md</code> 的顶部，必须加上前置元数据，主要是 <code>name</code> 和 <code>description</code> 这 2 个元数据，其他的都是可选的。</p><table><thead><tr><th>字段</th><th>是否必填</th><th>约束条件</th></tr></thead><tbody><tr><td>name</td><td>是</td><td>最多 64 个字符；只能包含小写字母、数字和连字符；不能以连字符开头或结尾。</td></tr><tr><td>description</td><td>是</td><td>最多 1024 个字符；不能为空；用于描述该技能的功能以及适用场景。</td></tr><tr><td>license</td><td>否</td><td>许可证名称，或指向随技能一起提供的许可证文件的引用。</td></tr><tr><td>compatibility</td><td>否</td><td>最多 500 个字符；用于说明环境要求，例如目标产品、系统依赖、网络访问等。</td></tr><tr><td>metadata</td><td>否</td><td>用于附加元数据的任意键值映射。</td></tr><tr><td>allowed-tools</td><td>否</td><td>技能可使用的预批准工具列表，以空格分隔（实验性功能）。</td></tr></tbody></table><p>另外，Markdown 中的实际指令，<strong>对结构和内容没有特别限制</strong>。</p><p>如下面这个示例：</p><pre><code class="markdown">---
name: pdf-processing
description: 从 PDF 文件中提取文本和表格，填写表单，合并文档。
---

# PDF 处理

## 何时使用该技能
当用户需要处理 PDF 文件时，使用该技能……

## 如何提取文本
1. 使用 pdfplumber 进行文本提取……

## 如何填写表单

...</code></pre><p>这种简单的格式有几个关键优势：</p><ul><li><strong>清晰易懂</strong>：不管是技能作者还是使用者，只要看一眼 <code>SKILL.md</code> ，就能明白它干啥的，让技能的维护和优化变得特别轻松。</li><li><strong>扩展性好</strong>：技能的复杂度可以灵活调整，从简单的文字指令，到可执行代码、资源文件，再到模板，全都能搞定。</li><li><strong>轻松迁移</strong>：技能就是个文件，编辑、版本管理、分享都特别方便。</li></ul><p>相比于固定的 AI 工作流，Skills 的灵活性更好。</p><h2>Skills 仓库推荐</h2><p>在使用 Skills 前，先分享两个 Skills 仓库：</p><ul><li><a href="https://link.segmentfault.com/?enc=Mu8bkcUtByKZk%2Fwacivo%2BA%3D%3D.%2BPbbEfo8%2BUpd%2BhZPH4E3BtuLcgWeuIGaT0sJjK2tEnDT9y%2Bdc4JP1pgDBxKG%2Bs1h" rel="nofollow" target="_blank">https://github.com/anthropics/skills</a></li><li><a href="https://link.segmentfault.com/?enc=nxEg%2FaTtv%2BuPeaNvp8yTCg%3D%3D.yxGOCKtfOUDgrZz4jc62%2F29RQweqBa%2FvQcfW1khfYw%2BidvsJb9xyx8PeQOs1x9PZjehXYFW40ii89RrCRHKRpw%3D%3D" rel="nofollow" target="_blank">https://github.com/ComposioHQ/awesome-claude-skills</a></li><li>……</li></ul><p>第一个是官方的 Skills 仓库，里面包含了一些图片、文档等基本技能，还有一个 <code>skill-creator</code> 技能，通过它就可以引导式创建一个技能。</p><p>第二个是第三方的 Skills 仓库，里面也包含也许多类型的技能，根据自己的需要酌情使用。</p><blockquote>还有更多一些大厂、第三方收集的 Agent Skills，这篇就不展开了，下一篇会详细分享一下，关注公众号「<strong>AI技术宅</strong>」第一时间分享。</blockquote><h2>Claude Code 使用 Skills 指南</h2><p>拿 Claude 自家来说，<strong>Claude API、Claude Code、Claude Agent SDK</strong> 等都支持 Skills，下面以 Claude Code 为例，来看看要怎么创建和使用 Skills。</p><p>Claude Code 的安装和高级用法看这两篇：</p><ul><li><a href="https://link.segmentfault.com/?enc=uDnV3X0GKf05Sce4kf4NBA%3D%3D.us3o%2FU8Xdly5xnxsVriO4u6VYKnUCV8AIsx%2BT1FuwnnQzZh3NPE9vsTz3lHLWUMQRg88H6c7AL4rMsQgHsnU3A%3D%3D" rel="nofollow" target="_blank">Claude Code 保姆级安装和使用教程分享</a></li><li><a href="https://link.segmentfault.com/?enc=j6HIXcjEeKnn5etiKohNmw%3D%3D.M50CBIesnTVdH9bbqhF6ixYOxZPP%2F8DysiSE5qGwNTcHt0oUZPAiZPxEHIv2T%2FjaN6tyvBY9x%2BdFzMZl4VfJ1Q%3D%3D" rel="nofollow" target="_blank">玩转 Claude Code 的 23 个实用小技巧，效率拉满！！</a></li></ul><h3>Skills 分类</h3><p>技能的存储位置决定了谁可以使用它：</p><table><thead><tr><th>Skills 类型</th><th>含义说明</th><th>生效范围</th><th>目录位置</th></tr></thead><tbody><tr><td><strong>Personal Skills</strong></td><td>个人技能，所有项目都可以复用的 Skills</td><td>全局（对所有项目生效）</td><td><code>~/.claude/skills/</code></td></tr><tr><td><strong>Project Skills</strong></td><td>项目技能，仅对当前项目生效，便于团队协作与共享</td><td>单个项目</td><td><code>.claude/skills/</code></td></tr><tr><td><strong>Plugin Skills</strong></td><td>插件技能，随插件一起安装，安装后即可直接使用</td><td>取决于插件适用范围</td><td>由插件定义（安装后自动生效）</td></tr></tbody></table><p>一般是全局、项目 Skills。</p><h3>安装 Skills</h3><p>比如，你想使用官方、第三方的 Skills，只需要把它们仓库的技能目录复制到 <code>~/.claude/skills</code> 目录下即可：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571638" alt="" title="" loading="lazy"/></p><p>在 Claude Code 中使用 <code>/skills</code> 指令就可以列出所有的技能。</p><h3>使用 Skills</h3><p>使用 Skills 有两种方法：</p><h4>1、自动引用</h4><p>上面说了，如果 Claude 认为你的需求和某个 Skill 相关时，它就会自动加载并使用。</p><p>比如我发送：</p><blockquote>列出所有skills并创建一个pdf</blockquote><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571639" alt="" title="" loading="lazy"/></p><p>提示词中要创建 PDF，所以它自动加载了 PDF 的 Skill，这就是自动按需加载。</p><h4>2、手动引用</h4><p>你也可以通过 <code>/xx</code> 来手动引用要使用的 Skill，比如我明确知道官方有一个 <code>canvas-design</code> 技能，那我可以这样手动引用：</p><blockquote>/canvas-design 设计一个 AI 学习路线图</blockquote><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571640" alt="" title="" loading="lazy"/></p><p>如果你知道某个经常用的 Skills，这样手动引用可能会<strong>加快 Skills 的加载速度</strong>。另外，如果有多个类似的 Skills，手动引用也特别有用，避免用错。</p><h3>创建自定义 Skills</h3><p>创建 Skills 非常简单，一个 3 步：</p><ul><li>在 <code>~/.claude/skills</code> 目录下创建一个技能目录；</li><li>在技能目录下面创建一个 <code>SKILL.md</code> 技能文档；</li><li>开始编写你的 <code>SKILL.md</code> 文档具体操作指令。</li></ul><p>当然，你也可以通过官方的一个 <code>skill-creator</code> 技能来引导式创建 Skills，这种方式更快，创建出来的 Skills 也会更懂你的需求。</p><p>下面，我来演示下如何通过 <code>skill-creator</code> 技能来创建一个自媒体助手 Skills。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571641" alt="" title="" loading="lazy"/></p><p>然后，我把我在 GPT 上面的提示词扔给它：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571642" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571643" alt="" title="" loading="lazy"/></p><blockquote>当然，不一定要提供提示词，你完全可以把你的需求说出来，让它一步步帮你构建好这个 Skill。</blockquote><p>不一会儿，它就帮我在 <code>~/.claude/skills</code> 目录下创建好了 <code>my-zmt-tools</code> 自媒体助手 Skill，它主要包括两个功能：<strong>中文转英文URL、内容转小红书风格</strong>，这两个功能我之前是在 GPT 上面实现的。</p><p>使用 <code>/skills</code> 指令来验证下：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571644" alt="" title="" loading="lazy"/></p><p>有了，这是它生成的 <code>SKILL.ms</code> 文档：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571645" alt="" title="" loading="lazy"/></p><p>还不错吧？如果不满意，还可以基于它做二次修改。</p><p>现在来看看如何使用它，直接使用 <code>/my-zmt-tool</code> 技能的指令，然后带上指令参数、具体的内容或者要求就行了：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571646" alt="" title="" loading="lazy"/></p><p>成功了，中文标题正确转换成了英文 URL，这个功能我在写博客时经常要用到，比如《<a href="https://link.segmentfault.com/?enc=K1oDkoRUpQYKEwAiy9FtIA%3D%3D.Y5e2DIVyqs4scQYd56PiT8tnxxaIs2QI%2B6g%2Fz2cWGsnxz1Mrjn0aagbR3tV4eT3PFclIWmUlKzxCpZlQqEbeFQ%3D%3D" rel="nofollow" target="_blank">MCP 不香了，Claude Code 又推出了 Skills！！（保姆级安装和使用教程分享）</a>》这篇文章就对应这个 URL：</p><blockquote><a href="https://link.segmentfault.com/?enc=M%2FkiSKcO4VvNdf4u7Mh2Vw%3D%3D.95Neu2SoB%2BDFGXDIdDO%2FFWG4NkCF4yxD3BuBS0tfX2vNQUxJagWfWKnTxMwa4%2FFQLnaNJAy31R%2BNdR%2FL9d7QWg%3D%3D" rel="nofollow" target="_blank">https://www.javastack.cn/claude-code-skills-usage/</a></blockquote><p>后面的 <code>claude-code-skills-usage</code> 就是靠定制化 GPT 帮我生成的。</p><p>在使用 ChatGPT 时，首先要切换到具体的 GPT，然后再发送指令，使用不是很方便，网络慢时可能更影响速度，现在有了 Skills 感觉效率要更快了。</p><p>所以，有了 Skills，很多 GPT 上面完成的工作，都可以尝试用 Skills 来完成，Skills 有了更多的可能性。</p><h2>CodeX 使用 Skills 指南</h2><p>上面说了，Agent Skills 已经是开放标准了，在 Claude 创建好的 Skills 也可以在其他支持 Agent Skills 的 AI 编程工具中使用，比如 CodeX。</p><ul><li><a href="https://link.segmentfault.com/?enc=M87uYGFPw8HBxsXsXcePDw%3D%3D.9n%2FdaKM2HtVRYG6h1ApF20MdwJ0iitVBA7fCu16YLe89sScM262Z7xWxEZ0%2FWQZkfN2frkhkfbmRvOLZu8SP0w%3D%3D" rel="nofollow" target="_blank">CodeX 的安装使用（保姆级教程分享）</a></li><li><a href="https://link.segmentfault.com/?enc=PH5M6ao%2FxlBVtW18zku3OQ%3D%3D.Qr3UVid5N9GH33L7qoCS7Ei4bdbylIOJquzp5qC7NAN6vvitSd26sCRavoXMBBtpt9x8a9wZ1g5RGwo4CGlAyg%3D%3D" rel="nofollow" target="_blank">玩转 CodeX CLI 的 16 个实用小技巧，效率拉满！！</a></li></ul><p>方法很简单，比如，我把上面创建好的 <code>my-zmt-tolls</code> 目录直接复制到 <code>~/.codex/skills</code> 目录下。</p><p>然后同样使用在 CodeX 中使用 <code>/skills</code> 命令，可以列出所有的 Skills：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571647" alt="" title="" loading="lazy"/></p><p>用法其实和 Claude Code 差不多，不太一样的是，Claude Code 的<strong>自身命令、斜杠命令和 Skills</strong> 都是通过 <code>/</code> 来选择，非常混乱，而在 CodeX 中，Skills 可以使用单独的 <code>$</code> 来选择 Skills，它是和自身的 <code>/</code> 命令分开的。</p><p>所以，在 CodeX 中可以<strong>自动调用 Skills</strong>，也可以<strong>手动指定</strong>要引用的 Skill：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571648" alt="" title="" loading="lazy"/></p><p>Skill 都正常执行了，很方便吧？</p><p>从 <code>/skills</code> 列表命令也可以看到，CodeX 还提供了一个 <code>skill-creator</code> 命令用于创建和维护 Skills，还有一个 <code>skill-installer</code> 命令用于从其他仓库源安装 Skills。</p><blockquote>其他支持 Skills 的 AI 编程工具，都是同一样的手法。</blockquote><h2>OpenCode 使用 Skills 指南</h2><p>如果你有多模型的使用习惯，比如：<strong>国外、国内、本地模型混用</strong>，封闭的 Claude Code、CodeX 就无法满足需求了，这里我们就得使用最近<strong>火爆全网的 OpenCode，号称开源版的 Claude Code</strong>，它支持任意模型随时切换。</p><p>现在越来越多的人都在使用 <strong>OpenCode</strong>，包括我自己。</p><p>怎么安装和使用参考我分享的使用教程：</p><blockquote><a href="https://link.segmentfault.com/?enc=R0tn7jigo2LQCe11yb9unA%3D%3D.N1rF%2Fs65%2BRG6nyvytBkmjm5CAUdWm7HhTCx9%2B47%2Fs%2F2opB9kACPLf4Cd2vAPNz3%2B" rel="nofollow" target="_blank">开源版 Claude Code 杀疯了，怒斩 70k+ Star！！</a></blockquote><p>OpenCode 会自动搜索以下位置的 Skills：</p><ul><li>项目配置：<code>.opencode/skills/&lt;name&gt;/SKILL.md</code></li><li>全局配置：<code>~/.config/opencode/skills/&lt;name&gt;/SKILL.md</code></li><li>兼容项目 Claude：<code>.claude/skills/&lt;name&gt;/SKILL.md</code></li><li>兼容全局 Claude：<code>~/.claude/skills/&lt;name&gt;/SKILL.md</code></li></ul><p>也就是说，<strong>OpenCode 不需要像 CodeX 那样复制 Skills，它支持自动搜索 Claude 的 Skills</strong>，这就比 CodeX 要方便太多了，<strong>不用复制冗余文件</strong>，这太舒服了。</p><p>目前，OpenCode 官方还没有类似 的 <code>/skills</code> 命令来列出所有的 Skills，不过可以通过问它列出所有的 Skills：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571649" alt="" title="" loading="lazy"/></p><p>使用方法也是一样的，可以自动或者手动引用 Skills：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571650" alt="" title="" loading="lazy"/></p><p>OpenCode 桌面版的使用也是一样的。</p><h2>常见问题</h2><p>经过以上 Skills 的工作原理和使用指南，下面的问题就不是问题了。</p><h3>1、有了 MCP，为什么又搞出 Skills？</h3><p>之前分享了一篇 MCP 的介绍及使用：</p><blockquote><a href="https://link.segmentfault.com/?enc=b1JrmqqxxaCwt6Y9A0LeHg%3D%3D.JQrvIZXeskxx30I3Rq%2BvGDzVTRQLc2%2B3n1K2LJkMQ7HSJhKRKqMdd7HGAUeuJ4gIrCN9rCSdG4MJHj9Uwc0TBQ%3D%3D" rel="nofollow" target="_blank">最近热火朝天的 MCP 是什么鬼？如何使用MCP？一文给你讲清楚！</a></blockquote><p>MCP 本质上是为 AI 大模型提供<strong>调用外部工具</strong>的能力，MCP Server 就是这个能力的具体实现——你可以通过它，把你已有的 <strong>API、脚本、服务</strong>包装成 AI 能理解和调用的 MCP 工具。</p><p><strong>使用 MCP 的限制：</strong></p><ul><li>如果只靠 MCP，你虽然可以调用很多工具／数据，但模型每次必须在提示或上下文里夹带大量相关信息，这会消耗大量 token、降低效率。</li><li>在很多场景下，问题不是调用 API，而是按公司标准／流程来做事，MCP 可以访问数据或工具，但不会自动知道这个流程的外在规则是什么。</li></ul><p>而 Skills 正好解决了这些问题，所以，MCP 是 AI 连接外部的工具，而 Skills 教模型如何使用工具。</p><p>MCP + Skills 可以<strong>协同工作</strong>，在很多复杂系统中，两者往往组合使用，<strong>模型先通过 MCP 访问工具／数据，再通过 Skills 引导流程执行</strong>。</p><p><strong>但有一点，在执行代码方面：</strong></p><p>Skills 虽然也支持代码执行，但受限于本地的环境，比如执行 Python 脚本，要是本地没有安装 Python 环境，或者版本不兼容，都会影响 Skills 执行效率。</p><p>MCP 因为是执行固定的代码，所以 <strong>MCP 在执行代码方面要更稳定</strong>。</p><h3>2、Skills 和 Slash Commands 有什么区别？</h3><p>Skills 是由模型驱动的，Claude 会根据你的任务和 Skill 的描述自动匹配并使用这些 Skills，完全不需要你介入，当然也可以通过 <code>/skill-name</code> 来主动触发。</p><p>Slash Commands（斜杠命令）则是完全由用户触发的，你需要主动输入 <code>/command</code> 才能触发。</p><p>但是，从最新的 Skills 来看，Slash Commands 也被合并在用户 Skills 中了：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571651" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571652" alt="" title="" loading="lazy"/></p><p>合并归合并，困为 Slash Commands 和 Skills 两者都可以通过 <code>/</code> 手动触发，Slash Commands 并不能自动触发，因为它没有像 Skills 那样定义元数据。</p><p>Skills 相比 Slash Commands 只是多了几个可选功能，它支持文件的目录、控制 Claude 是否调用 Skills 前置元数据，以及 Claude 在相关时自动加载它们的能力。</p><h2>总结</h2><p>Agent Skills 这一套机制，表面看只是多了一个 <code>SKILL.md</code> 文件，实际上背后是一整套 <strong>Agent 能力组织方式的升级</strong>。</p><p>Agent Skills 把<strong>提示词、工具、脚本、资源</strong>全部收敛到一个标准化目录里，再通过「<strong>渐进式披露</strong>」的方式按需加载，这一点对<strong>上下文成本和执行效率</strong>的提升非常明显。</p><p>从使用体验来看，Skills 最大的价值有三个：<strong>可复用、低心智成本、易迁移</strong>。</p><p>不管是个人常用能力，还是项目级、团队级的能力，都可以沉淀成 Skills，<strong>一次写好，反复使用</strong>。而且它不绑死某一家平台，已经被做成开放标准，<strong>Claude、Google、OpenAI、Cursor</strong> 都能用，这一点非常重要。</p><p>比如拿我自己来说，以前要频繁切 GPT，现在一个 <code>Skill</code> 就能搞定。</p><p>所以，可以预见的未来，Agent Skills 的体系和生态会更加完善，<strong>大家可以早点把自己的常用能力沉淀下来</strong>，后面只会越用越爽。</p><p>未完待续，<strong>R哥持续分享更多 AI 编程经验</strong>，包括更加复杂的 Skills 使用，公众号第一时间推送，关注和我一起学 AI。</p><blockquote>⚠️ <strong>版权声明：</strong> <br/><br/>本文系公众号 "AI技术宅" 原创，转载、引用本文内容请注明出处，抄袭、洗稿一律投诉侵权，后果自负，并保留追究其法律责任的权利。</blockquote>]]></description></item><item>    <title><![CDATA[2026 AI元年：执行式智能体，正在成为企业的“第二操作系统” 智能体小狐 ]]></title>    <link>https://segmentfault.com/a/1190000047571683</link>    <guid>https://segmentfault.com/a/1190000047571683</guid>    <pubDate>2026-01-26 11:09:59</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>如果说：</p><ul><li><strong>2024 年的大模型竞争，是“谁更博学”</strong></li><li><strong>2025 年，是“谁能进行更严密的推理”</strong></li></ul><p>那么 <strong>2026 年，人工智能正式进入第三阶段：从“推理”走向“执行”</strong>。</p><p>这一年，AI 的价值评估标准发生根本变化—— <strong>不再是谁能给出最完美的方案，而是谁能为“结果负责”。</strong></p><h2>一、范式跃迁：从“静态推理”到“动态行动链”</h2><p>过去的大模型，本质上仍停留在「纸上谈兵」阶段。</p><p>它可以：</p><ul><li>给出完整方案</li><li>拆解逻辑步骤</li><li>提供专业建议</li></ul><p>但<strong>最后一步的执行，永远留给人类</strong>。</p><h2>关键定义 1：推理扩展（Inference-time Reasoning）</h2><blockquote>推理扩展，是指模型在输出结果前，进行多路径推演、自检与成功率评估的一种“慢思考机制”。</blockquote><p>这项能力，让 AI 不再只生成“看起来对的答案”， 而是选择<strong>更可能达成目标的行动路径</strong>。</p><h2>从“生成答案”到“达成目标”</h2><p>2026 年，AI 的工作模式发生本质变化：</p><ul><li><strong>自主任务拆解（Long-horizon Planning）</strong>AI 能将「策划并上线一场夏季促销活动」拆解为可执行的子任务链，而非一次性输出方案。</li><li><strong>GUI 理解与跨应用操作（Screen Understanding）</strong>AI 不再依赖 API，而是像人类一样理解界面、点击按钮、填写表单，完成跨系统操作。</li></ul><p><strong>AI 第一次真正拥有了“手”。</strong></p><h2>二、角色转变：AI 智能体成为企业级中间件</h2><p>2026 年，AI 的形态完成关键进化：</p><blockquote><strong>从“聊天机器人”，变成“任务型智能体（Task-driven Agent）”。</strong></blockquote><p>它不再是某个软件的功能，而是<strong>连接人与业务系统的智能中枢</strong>。</p><h2>关键定义 2：有界自治（Bounded Autonomy）</h2><blockquote>有界自治，是指 AI 在明确的权限边界、安全规则和审计机制内，拥有自主执行、修改数据与发起流程的能力。</blockquote><p>这是企业落地 AI 的“最优解”：</p><ul><li><strong>低风险</strong></li><li><strong>高效率</strong></li><li><strong>可规模化</strong></li></ul><h2>消除流程孤岛，效率指数级提升</h2><p>在企业内部：</p><ul><li>ERP</li><li>CRM</li><li>财务系统</li><li>协同办公工具</li></ul><p>过去靠人「搬数据」连接，现在由智能体自主流转。</p><p>在实际落地中，越来越多团队选择<strong>智能体平台化方案</strong>。 例如 <strong>「智能体来了」</strong>（<a href="https://link.segmentfault.com/?enc=xJGJibpFGz%2FRhKB98ajAdQ%3D%3D.4mh8fgm9aziWuP5zvjVqqdqwki%2F5M5qadyZ8vcZqdPw%3D" rel="nofollow" target="_blank">https://agentcome.net/</a>）， 通过 MCP、A2A 等标准协议，让企业无需从零构建行动控制逻辑，即可快速搭建具备执行能力的智能体集群。</p><p><strong>AI 正在成为企业的“数字员工操作系统”。</strong></p><h2>三、执行式 AI 在 2026 年爆发的三大技术支柱</h2><h2>1. 记忆系统的持久化</h2><p>智能体不再是“无状态对话”。</p><p>2026 年的 AI 架构，支持：</p><ul><li>数月级上下文记忆</li><li>项目级目标保持</li><li>策略一致性延续</li></ul><p>这让 AI 真正参与“长期工作”，而非一次性咨询。</p><h2>2. 感知—行动—反馈的闭环纠错</h2><p>执行式 AI 具备类似人类的“韧性”：</p><ul><li>页面加载失败 → 切换路径</li><li>权限不足 → 主动请求</li><li>结果偏差 → 自我修正</li></ul><blockquote><strong>AI 开始具备“执行张力”。</strong></blockquote><h2>3. AI 成本结构的根本变化（FinOps for AI）</h2><p>随着：</p><ul><li>推理成本下降</li><li>专用芯片普及</li><li>行动型模型优化</li></ul><p>企业开始用一个新指标评估 AI：</p><blockquote><strong>单个任务的 ROI，而非算力消耗。</strong></blockquote><h2>四、总结：2026 年，是“脑”与“手”的合一之年</h2><ul><li><strong>逻辑升级</strong> AI 从“预测下一个词”，进化为“预测下一个行动状态”。</li><li><strong>形态演进</strong>企业不再围绕单一模型，而是构建多智能体协作网络。</li><li><strong>价值重构</strong>竞争的终局，不再是信息优势，而是<strong>执行效率 × 认知深度</strong>。</li></ul><h2>对人类的真正挑战</h2><p>在执行式 AI 普及的元年， <strong>人类的核心能力，正从“执行力”转向“定义力”。</strong></p><blockquote>能否清晰定义目标、约束条件与成功标准，将成为智能时代最稀缺的人力资产。</blockquote>]]></description></item><item>    <title><![CDATA[智能体来了从 0 到 1：为什么“可复用性”决定了 AI Agent 能否真正落地？ Agentco]]></title>    <link>https://segmentfault.com/a/1190000047571705</link>    <guid>https://segmentfault.com/a/1190000047571705</guid>    <pubDate>2026-01-26 11:09:16</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在 AI Agent（智能体）工程中，一个反复出现的现象是：</p><blockquote><strong>Demo 很容易成功，但系统很难长期存活。</strong></blockquote><p>大量团队可以在数天内构建出一个效果惊艳的单任务 Agent，但当以下任一条件发生变化时：</p><ul><li>业务场景扩展</li><li>角色数量增加</li><li>模型版本升级</li><li>多 Agent 协作引入</li></ul><p>原有系统往往迅速失效，甚至被整体推翻重来。</p><p><strong>真正判断一个智能体是否完成“从 0 到 1”，核心并不在于它“当前有多聪明”，而在于：</strong></p><blockquote>👉 <strong>它的能力是否具备可复用性（Reusability）。</strong></blockquote><h2>一、什么是“智能体的可复用性”（Agent Reusability）？</h2><p>在工程视角下，可复用性并不等同于“代码能否复制”，而是体现在<strong>三类可被抽象、组合和迁移的资产层级</strong>。</p><h3>1️⃣ 能力复用（Skill Reusability）</h3><p>关注点不是“这个 Agent 能做什么”， 而是 <strong>“它使用的能力是否是原子化的”</strong>。</p><p><strong>高复用特征：</strong></p><ul><li>Tool 无业务语义绑定</li><li>参数与上下文标准化</li><li>不依赖特定 Prompt 或角色</li></ul><p>✅ 可复用的是：</p><ul><li>文件读取</li><li>结构化抽取</li><li>规则计算</li></ul><p>❌ 不可复用的是：</p><ul><li>“合同审查 Agent 专用工具”</li></ul><h3>2️⃣ 逻辑复用（Logic Reusability）</h3><p>真正可迁移的不是 Prompt 文案，而是 <strong>思维结构</strong>。</p><blockquote><strong>Prompt 的价值在于结构，而不在于字面内容。</strong></blockquote><p>推荐统一的 Agent 逻辑模板：</p><pre><code>Role（角色）
→ Goal（目标）
→ Constraints（约束）
→ Skills（可调用能力）
→ Examples（示例）</code></pre><p>其中：</p><ul><li>Constraints / Output Format = 全局可复用</li><li>Goal / Examples = 场景级定制</li></ul><p>这类结构化 Prompt 更容易：</p><ul><li>跨模型迁移</li><li>被多 Agent 共享</li><li>被工作流系统编排</li></ul><h3>3️⃣ 知识复用（Knowledge Reusability）</h3><p>如果知识只能被一个 Agent 使用，它本质上仍然是<strong>私有上下文</strong>。</p><p><strong>高复用知识的关键特征：</strong></p><ul><li>标准化 Schema</li><li>可多角色访问</li><li>与 Agent 解耦</li></ul><p>👉 一套 RAG 资产，应当能够：</p><ul><li>同时服务「问答 Agent」「审查 Agent」「总结 Agent」</li></ul><h3>一句话总结</h3><blockquote><strong>可复用的智能体，本质上不是“应用”，而是能力模块的组合体。</strong></blockquote><h2>二、为什么不可复用的 Agent 永远停留在 0.x？</h2><h3>❌ 1. 烟囱式扩展，系统复杂度失控</h3><p>每新增一个场景：</p><ul><li>重写 Prompt</li><li>重写逻辑</li><li>重调上下文</li></ul><p>最终复杂度呈指数级上升。</p><h3>❌ 2. 经验被锁死在 Prompt 黑盒中</h3><p>典型问题包括：</p><ul><li>业务知识不可拆解</li><li>决策路径不可审计</li><li>能力无法继承</li></ul><p>一旦模型更换或人员流动，Agent 能力直接“失忆”。</p><h3>❌ 3. 多 Agent 协作无法成立</h3><p>在 Multi-Agent System 中：</p><ul><li>如果输入输出不标准</li><li>如果能力不可组合</li></ul><p>系统永远只是<strong>多个单点智能的并列</strong>，而非组织级智能。</p><h2>三、工程实践：如何一开始就构建“可复用型 Agent”？</h2><h3>✅ 1. 工具原子化，而不是功能封装</h3><p>不要构建：</p><blockquote>“合同审查工具”</blockquote><p>而是拆解为：</p><ul><li>文档解析</li><li>关键信息抽取</li><li>条款比对</li><li>风险评分</li></ul><p>每一个模块，都是未来 Agent 的积木。</p><h3>✅ 2. Prompt 先工程化，再业务化</h3><p>先统一结构，再填业务内容， 而不是反过来。</p><h3>✅ 3. 借助平台化底座沉淀复用资产</h3><p>在真实落地中，越来越多团队选择使用成熟的 Agent 平台，避免从 0 重复造轮子。</p><p>例如 <strong>智能体来了（agentcome.net）</strong>，其价值不在于“能跑 Agent”，而在于：</p><ul><li>可复用的 Tool 资产</li><li>标准化的工作流模板</li><li>模块级知识与 API 节点沉淀</li></ul><p>让每一个新 Agent，都站在历史资产之上构建。</p><h2>四、结论：可复用性，是智能体资产化的唯一通路</h2><ul><li>从项目到产品：<strong>复用决定规模化</strong></li><li>从试验到体系：<strong>复用让试错成本递减</strong></li><li>从单点到复利：<strong>模块越多，构建越快</strong></li></ul><blockquote><strong>真正的从 0 到 1，不是做出第一个 Agent， 而是第一次做出还能被下一个 Agent 使用的能力。</strong></blockquote>]]></description></item><item>    <title><![CDATA[工艺路线配置不再愁！APS排产系统批量操作大揭秘 软件部长 ]]></title>    <link>https://segmentfault.com/a/1190000047571722</link>    <guid>https://segmentfault.com/a/1190000047571722</guid>    <pubDate>2026-01-26 11:08:35</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>现代制造业中，工艺路线 定义了产品从原材料到成品的完整加工路径，当产品种类繁多时，逐个手动录入工艺路线效率就显得低下，并且容易出错。<br/>在APS排产系统里，工艺路线模块为产品生产的每个步骤流程搭建起了清晰明确的路径。利用工序模板进行批量配置，也就是说通过下载模版填写后批量导入的方式，能快速实现多工艺路线的配置。<br/>在开始批量配置前，先理解两个核心概念：<br/>• 工序模板：这是批量配置的基石。它好比标准化的“工序组件库”，将一道工序所需的资源、时间、前后逻辑关系（如ES：前工序结束后工序才能开始；EE：前工序未结束后工序可提前开始）等进行预定义。确保所有需要用到的工序模板已提前在系统中创建并审核通过。<br/>• 工艺路线：它是由多个工序模板按生产顺序“连线”组合而成的完整生产流程。批量配置的本质，就是通过结构化数据（Excel模板）快速建立产品与工序序列之间的关联。</p><h2>批量配置详细操作流程</h2><p>1、配置所涉及到的工序模版，为工艺路线打基础（工艺路线是工序模版所构成）。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047571724" alt="图片" title="图片"/><br/>2、点击【工艺路线建模】，选择下载模版按钮下载Excel表格。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047571725" alt="图片" title="图片" loading="lazy"/><br/>3、模版下载后分为两个板块，一个是【工艺路线】，一个是【工序主资源】。其中工艺路线即是指定该产品的具体路线是如何的，工序主资源即是指定哪道工序具体涉及哪些主资源。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047571726" alt="图片" title="图片" loading="lazy"/><br/>4、【工艺路线】sheet页主要有物料编码、工序编码、工序名称、工序序号、模版工序编码。物料编码即是成品的编码，指定该工艺路线为哪个产品的工艺路线，即配产品的物料编码于此。工序编码即生产该产品时需要的对应工序的编码，可与模版工序编码保持一致，即引用已建好的模版。工序名称和工序模版的工序名称保持一致，工序序号即是谁为第一道工序，谁为第二道工序。分别用数字1、2、3、4等进行排列。以下为示例。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047571727" alt="图片" title="图片" loading="lazy"/><br/>5、工序主资源涉及字段为物料编码、工序编码、工序序号、主资源编码、产能。物料编码和工序编码序号与前面工艺路线保持一致即可，后面的主资源编码和产能就按照实际情况。分别设置在该工序环节时需要的设备主资源以及对应产能具体值。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047571728" alt="图片" title="图片" loading="lazy"/><br/>6、设置好后保存，点击导入即可。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047571729" alt="图片" title="图片" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[为什么有些网站打不开甚至特别慢？ 德迅云安全_珍珍 ]]></title>    <link>https://segmentfault.com/a/1190000047571743</link>    <guid>https://segmentfault.com/a/1190000047571743</guid>    <pubDate>2026-01-26 11:07:36</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>有很多原因可以导致某些网站无法打开或加载缓慢。这些原因可以包括以下各种因素：</p><p>网络连接问题： 您的互联网连接可能存在问题，如断开、丢包或较低的带宽，这会导致网站加载缓慢或无法加载。</p><p>网站服务器问题： 如果目标网站的服务器出现问题，如服务器宕机、过载或网络故障，那么您将无法访问该网站。</p><p>DNS问题： DNS(域名系统)负责将域名解析为 IP 地址。如果DNS服务器出现问题，将导致域名解析失败，从而无法访问网站。</p><p>防火墙和安全软件： 防火墙或安全软件可能会阻止您访问某些网站，尤其是在其黑名单中的网站。</p><p>浏览器问题： 您使用的浏览器可能存在问题，例如缓存问题、插件冲突或过时的浏览器版本。</p><p>地理位置： 您的地理位置可能会影响到网站的加载速度。如果您与目标服务器之间的距离较远，加载速度可能较慢。</p><p>设备问题： 您的计算机或设备可能存在问题，如性能不足、过热或磁盘空间不足，这可能会导致网站加载缓慢。</p><p>网络流量： 网站所在的服务器可能正在经历高流量，这会导致加载速度变慢。</p><p>网站设计和优化： 一些网站可能设计不佳或未经过优化，导致加载时间较长。大量的大型媒体文件和广告也可能影响加载速度。</p><p>互联网服务提供商（ISP）问题： 您的ISP可能会对特定网站或内容进行流量限制，这可能会导致访问特定网站时速度较慢。</p><p>解决这些问题可能需要不同的方法。您可以尝试以下步骤来改善网站访问速度：</p><p>　　检查您的互联网连接，确保它稳定且具有足够的带宽。<br/>　　清除浏览器缓存和Cookie。<br/>　　使用不同的浏览器进行测试，以查看是否存在浏览器相关问题。<br/>　　检查您的设备，确保它没有性能问题。<br/>　　尝试使用不同的DNS服务器，如Google DNS 或 Cloudflare DNS。<br/>　　联系您的ISP 以了解是否存在任何网络问题。<br/>如果问题持续存在，可能需要进一步的网络故障排除或联系相关网络服务提供商或网站管理员以获取支持。</p>]]></description></item><item>    <title><![CDATA[VMware 虚拟机 2026年最新版 下载安装使用教程 Jason ]]></title>    <link>https://segmentfault.com/a/1190000047571745</link>    <guid>https://segmentfault.com/a/1190000047571745</guid>    <pubDate>2026-01-26 11:06:39</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <ul><li>支持最新版25H2</li><li>目前已经支持个人免费使用，无需授权激活</li></ul><h2>一、下载</h2><ol><li><strong>官方</strong>：<a href="https://link.segmentfault.com/?enc=zDwq4UsdAoO0xQcaL1VBhA%3D%3D.U1kg4BDoIRPzqFnwoQmkriOU9YzAQ0lU2h5n9zGdqzw%3D" rel="nofollow" target="_blank">https://www.broadcom.com/</a></li><li><p><strong>备用</strong>（国内推荐）：</p><p><a href="https://link.segmentfault.com/?enc=JCDTb15AWL2RyJGpmJppWA%3D%3D.zbcPw72niVcnKZXdqm6g6ES5FfCsnCVaByhrQn9VU%2BN4KPVLTYi%2FtOJQxthqiHiv" rel="nofollow" target="_blank">https://wwbxo.lanzoue.com/iI2wu3h0vuhe</a></p></li></ol><h2>二、安装</h2><p>双击安装包 → 同意协议 → 自定义路径（无中文）→ 安装 → 重启</p><h2>三、创建虚拟机</h2><ol><li>新建→典型→加载系统 ISO→命名 + 选存储路径</li><li>设磁盘容量→分配内存 2-4GB、CPU2 核→开启虚拟机装系统</li><li>安装 VMware Tools（实现鼠标 / 文件互通）</li></ol><h2>四、常用操作</h2><ul><li>快照：保存 / 恢复虚拟机状态</li><li>关机：系统内正常关机，勿强制关闭</li></ul><h2>五、常见问题</h2><ul><li>启动失败：开 BIOS 虚拟化、关 Hyper-V</li><li>无网络：选 NAT 模式，重启 VMware 网络服务</li></ul>]]></description></item><item>    <title><![CDATA[2026客户管理系统盘点：7 大主流品牌全链路能力横评 正直的炒饭 ]]></title>    <link>https://segmentfault.com/a/1190000047571748</link>    <guid>https://segmentfault.com/a/1190000047571748</guid>    <pubDate>2026-01-26 11:05:53</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在企业数字化转型中，CRM（客户关系管理）已从“客户信息存储工具”升级为“全链路业务协同平台”——覆盖<strong>获客-营销-竞品-项目-上下游</strong>的全流程，成为企业连接市场、客户与供应链的核心枢纽。本文基于<strong>超兔一体云、Copper CRM、</strong> <strong>RSS</strong> <strong>、Agile CRM、Highrise、微盟CRM、玄讯CRM</strong>等主流品牌的公开能力，从专业维度展开横向对比，解析各品牌的核心优势与适用场景。</p><h2>一、对比框架说明</h2><p>本次对比围绕CRM的<strong>核心业务链路</strong>设计5个维度，覆盖企业从“获客”到“上下游协同”的全流程需求：</p><ol><li><strong>获客能力</strong>：线索来源的广度、精准度与自动化程度；</li><li><strong>营销能力</strong>：营销物料支持、数据驱动决策与自动化工具；</li><li><strong>竞品管理</strong>：竞品信息收集、分析与竞争策略支持；</li><li><strong>项目管理</strong>：项目全生命周期的跟踪、协同与成本管控；</li><li><strong>上下游管理</strong>：供应商/客户的全流程协同与数据共享。</li></ol><h2>二、各维度横向对比分析</h2><h3>（一）获客能力：从“流量覆盖”到“精准转化”的差异</h3><p>获客是CRM的起点，核心是<strong>多渠道线索整合</strong>与<strong>线索清洗效率</strong>。各品牌的能力差异直接决定了企业触达客户的广度与精准度：</p><table><thead><tr><th>品牌</th><th>核心获客能力</th><th>适用场景</th></tr></thead><tbody><tr><td><strong>超兔一体云</strong></td><td>覆盖线上（百度/抖音/微信/小程序）+ 线下（地推/会销/工商搜客）全渠道；支持线索一键处理、归属地识别、活动效果评估</td><td>toB/toC全行业，需全渠道获客的企业</td></tr><tr><td><strong>微盟CRM</strong></td><td>整合微信/抖音/小红书等私域流量，通过会员积分、拼团满减实现获客与复购</td><td>美妆/服饰等线上零售品牌</td></tr><tr><td><strong>玄讯CRM</strong></td><td>快消行业专属：外勤拜访管理、终端数据采集、线下渠道获客</td><td>快消企业（如饮料、食品）</td></tr><tr><td><strong>Copper CRM</strong></td><td>适配Google生态：网站表单/手机扫描→自动同步Google Contacts，减少手动录入</td><td>海外/跨境业务，依赖Google生态</td></tr><tr><td><strong>Highrise</strong></td><td>线索-销售-订单-供应商全链路覆盖，支持工程类项目的线索转化</td><td>工程/制造企业，长周期项目获客</td></tr><tr><td><strong>RSS</strong></td><td>基础线索跟踪，无精准获客功能</td><td>对获客需求简单的中小企业</td></tr></tbody></table><p><strong>关键结论</strong>：</p><ul><li>超兔一体云是唯一覆盖“线上+线下+精准toB”的全渠道获客平台，适合需要规模化触达的企业；</li><li>微盟、玄讯是<strong>垂直行业获客专家</strong>（电商/快消）；</li><li>Copper CRM是<strong>Google生态下的海外获客工具</strong>，解决跨境业务的线索同步问题。</li></ul><h3>（二）营销能力：从“手动执行”到“数据驱动”的升级</h3><p>营销的核心是“精准触达+效果可测”，各品牌的差异体现在营销物料的丰富度与数据决策的能力：</p><table><thead><tr><th>品牌</th><th>核心营销能力</th><th>优势亮点</th></tr></thead><tbody><tr><td><strong>超兔一体云</strong></td><td>1. 营销物料库：话术武器云（标准化沟通话术）、文件武器云（产品资料/案例）； 2. 数据引擎：转化分析、用户画像云图、活动成本均摊</td><td>数据驱动的精准营销，支持活动效果回溯</td></tr><tr><td><strong>Agile CRM</strong></td><td>邮件营销、社交媒体管理；免费版无限用户</td><td>初创团队的基础营销工具</td></tr><tr><td><strong>微盟CRM</strong></td><td>电商复购工具：会员积分、满减拼团、私域流量触达</td><td>线上零售的老客运营</td></tr><tr><td><strong>Copper CRM</strong></td><td>Google Workspace协同（日历/文档/Drive）；Gmail邮件追踪（记录客户互动）</td><td>依赖Google生态的营销协同</td></tr><tr><td><strong>RSS</strong></td><td>基础活动管理（计划/执行/监控），无自动化功能</td><td>简单活动的流程跟踪</td></tr></tbody></table><p><strong>关键结论</strong>：</p><ul><li>超兔一体云是<strong>数据化营销的标杆</strong>，通过物料库与数据引擎解决“营销内容标准化”与“效果不可测”的痛点；</li><li>微盟CRM聚焦<strong>电商复购</strong>，适合线上零售的老客激活；</li><li>Agile CRM适合<strong>初创团队的低成本营销</strong>，免费版覆盖基础需求。</li></ul><h3>（三）竞品管理：从“被动收集”到“主动策略”的突破</h3><p>竞品管理的核心是“感知竞争态势，制定差异化策略” <strong>，但多数品牌仅能实现“被动收集”，仅有超兔一体云提供</strong>主动竞品分析能力：</p><table><thead><tr><th>品牌</th><th>竞品管理能力</th><th>能力层级</th></tr></thead><tbody><tr><td><strong>超兔一体云</strong></td><td>1. 竞品信息自动收集（产品/价格/市场份额）； 2. 竞争关系管理（竞争事件记录、预警）； 3. 差异化策略支持</td><td>主动型：从信息到策略的闭环</td></tr><tr><td><strong>Copper CRM</strong></td><td>通过客户互动记录（如“客户提及的竞品优势”）间接获取</td><td>被动型：依赖销售手动整合</td></tr><tr><td><strong>其他品牌</strong></td><td>无专门竞品模块</td><td>缺失型：无法满足复杂分析需求</td></tr></tbody></table><p><strong>关键结论</strong>：</p><ul><li>超兔一体云是唯一具备“竞品全生命周期管理”的品牌，适合需要应对激烈市场竞争的企业；</li><li>其他品牌仅能实现“竞品信息的碎片化收集”，无法支持策略制定。</li></ul><h3>（四）项目管理：从“进度跟踪”到“全流程协同”的深化</h3><p>项目管理的核心是“覆盖不同项目类型，实现进度、成本、团队的协同”，各品牌的能力差异体现在对项目复杂度的支持：</p><table><thead><tr><th>品牌</th><th>核心项目管理能力</th><th>适配项目类型</th></tr></thead><tbody><tr><td><strong>超兔一体云</strong></td><td>1. 多跟单模型：小单快单（三一客）、商机跟单（中长单）、多方项目（大型项目）； 2. 通用能力：360°视图、时间线、自动日报、行动记录分析</td><td>小单/中长单/大型项目全覆盖</td></tr><tr><td><strong>Highrise</strong></td><td>工程类项目：施工节点跟踪、材料采购、成本管控</td><td>工程/制造企业的长周期项目</td></tr><tr><td><strong>Copper CRM</strong></td><td>可视化项目管道+Google Calendar集成（同步日程/截止日期）</td><td>依赖Google生态的中小型项目</td></tr><tr><td><strong>其他品牌</strong></td><td>无原生项目管理功能或仅支持基础进度跟踪</td><td>简单项目的流程记录</td></tr></tbody></table><p><strong>关键结论</strong>：</p><ul><li>超兔一体云的“多方项目模型”是大型项目的核心解决方案——支持项目组、合同、采购、收支的全流程协同，精准控制收支差；</li><li>Highrise是<strong>工程类项目的专属工具</strong>，解决施工节点与成本管控的痛点；</li><li>Copper CRM适合<strong>Google生态下的轻量级项目</strong>。</li></ul><h3>（五）上下游管理：从“信息记录”到“全链路协同”的跨越</h3><p>上下游管理的核心是“打通企业与供应商/客户的数据壁垒，实现三流合一（物流/资金流/信息流）”，各品牌的能力差异体现在协同的深度：</p><table><thead><tr><th>品牌</th><th>核心上下游能力</th><th>协同亮点</th></tr></thead><tbody><tr><td><strong>超兔一体云</strong></td><td>OpenCRM业务伙伴共生平台： 1. 上游：询价/采购/付款/供应商评分； 2. 下游：报价/订单/物流/售后； 3. 共性能力：三流合一对账、全程追溯</td><td>产业链全流程协同，提升透明度</td></tr><tr><td><strong>Highrise</strong></td><td>线索-销售-订单-库存-供应商全链路覆盖</td><td>全流程数据打通</td></tr><tr><td><strong>微盟CRM</strong></td><td>与微盟商城无缝衔接：订单/库存/售后协同</td><td>电商上下游的订单协同</td></tr><tr><td><strong>玄讯CRM</strong></td><td>快消渠道库存监控：终端数据采集、库存预警</td><td>快消线下供应链的库存管理</td></tr><tr><td><strong>Copper CRM</strong></td><td>客户分层（组织型客户的上下级关联）</td><td>间接记录上下游关系</td></tr></tbody></table><p><strong>关键结论</strong>：</p><ul><li>超兔一体云的<strong>OpenCRM</strong>是<strong>上下游协同的标杆</strong>——通过“三流合一”解决企业与供应商/客户的对账痛点，提升产业链效率；</li><li>微盟、玄讯是<strong>垂直行业的供应链工具</strong>（电商/快消）；</li><li>Copper CRM仅能实现“信息记录”，无法支持深度协同。</li></ul><h2>三、综合能力雷达图：各品牌的核心竞争力分布</h2><p>基于5个维度的能力评分（1-5分，5为最高），各品牌的综合竞争力如下：</p><table><thead><tr><th>品牌</th><th>获客</th><th>营销</th><th>竞品</th><th>项目</th><th>上下游</th><th>核心定位</th></tr></thead><tbody><tr><td><strong>超兔一体云</strong></td><td>5</td><td>5</td><td>5</td><td>5</td><td>5</td><td>全链路协同型CRM，适合中大型企业</td></tr><tr><td><strong>Highrise</strong></td><td>4</td><td>2</td><td>1</td><td>4</td><td>4</td><td>工程类全流程CRM</td></tr><tr><td><strong>微盟CRM</strong></td><td>4</td><td>4</td><td>1</td><td>1</td><td>3</td><td>电商私域型CRM</td></tr><tr><td><strong>玄讯CRM</strong></td><td>3</td><td>2</td><td>1</td><td>1</td><td>3</td><td>快消外勤型CRM</td></tr><tr><td><strong>Copper CRM</strong></td><td>3</td><td>2</td><td>1</td><td>3</td><td>2</td><td>Google生态型CRM</td></tr><tr><td><strong>Agile CRM</strong></td><td>3</td><td>3</td><td>1</td><td>1</td><td>1</td><td>初创基础型CRM</td></tr><tr><td><strong>RSS</strong></td><td>2</td><td>2</td><td>1</td><td>1</td><td>1</td><td>简单基础型CRM</td></tr></tbody></table><h2>四、品牌核心定位与适用场景</h2><p>基于上述对比，各品牌的<strong>核心优势</strong>与<strong>适配企业</strong>可总结为：</p><table><thead><tr><th>品牌</th><th>核心优势</th><th>适配企业类型</th></tr></thead><tbody><tr><td><strong>超兔一体云</strong></td><td>全链路协同（获客-营销-项目-上下游）；大型项目管理；产业链三流合一</td><td>需要数字化转型的中大型企业； 依赖全流程协同的制造/工程/服务企业</td></tr><tr><td><strong>Highrise</strong></td><td>工程类项目节点跟踪；材料采购与成本管控</td><td>工程施工、设备制造企业</td></tr><tr><td><strong>微盟CRM</strong></td><td>电商私域流量整合；会员复购工具</td><td>美妆、服饰、家居等线上零售品牌</td></tr><tr><td><strong>玄讯CRM</strong></td><td>快消外勤拜访管理；终端数据采集</td><td>饮料、食品、日化等快消企业</td></tr><tr><td><strong>Copper CRM</strong></td><td>Google生态无缝集成；减少手动录入成本</td><td>海外/跨境业务；依赖Google Workspace的团队</td></tr><tr><td><strong>Agile CRM</strong></td><td>免费版无限用户；基础营销与客户管理</td><td>初创团队、小规模业务</td></tr><tr><td><strong>RSS</strong></td><td>界面简洁；基础客户与线索管理</td><td>对CRM需求简单的中小企业</td></tr></tbody></table><h2>五、选择建议：从“需求匹配”到“价值最大化”</h2><p>企业选择CRM的核心逻辑是“需求适配”，需结合3个关键因素：</p><ol><li><strong>行业特性</strong>：快消选玄讯，电商选微盟，工程选Highrise，海外选Copper；</li><li><strong>需求复杂度</strong>：全链路协同选超兔，基础管理选RSS，初创选Agile；</li><li><strong>生态依赖</strong>：Google生态选Copper，微信生态选微盟。</li></ol><h2>六、结论：CRM的未来是“全链路协同”</h2><p>从本次对比可见，CRM的竞争已从“单一功能优势”转向“全链路能力整合”——超兔一体云通过<strong>多渠道获客、数据化营销、竞品策略支持、全类型项目管理、产业链协同</strong>的全链路能力，成为中大型企业数字化转型的首选；而Highrise、微盟、玄讯等垂直型CRM则通过“行业深度”占据细分市场；Copper、Agile等则通过“生态/成本”适配特定团队。</p><p>对企业而言，选择CRM的本质是<strong>选择“业务增长的底层支撑系统”</strong> ——需从“当前需求”与“未来扩张”双维度评估，最终实现“效率提升+竞争力增强”的价值最大化。</p><p>（注：文中功能相关描述均基于公开披露信息，具体功能服务与价格以厂商实际落地版本为准。）</p>]]></description></item><item>    <title><![CDATA[【节点】[Position节点]原理解析与实际应用 SmalBox ]]></title>    <link>https://segmentfault.com/a/1190000047571752</link>    <guid>https://segmentfault.com/a/1190000047571752</guid>    <pubDate>2026-01-26 11:05:06</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <blockquote><a href="https://link.segmentfault.com/?enc=cY2XsRnBnMYGVzNdUbaCTA%3D%3D.mpNUCfv6Qxx%2BsUPreKiCx%2BahqzDUI%2FzaCO8lqKuiALj3GchiV35hwJ918jpqtPz7Y8VNDq7ESZNfUbfbAnxY0q2Sx9kuqeGfVt%2F9V3PwFYADMDsJfXa%2FJNg51k%2FDMSpsKZ0feCjgq%2BjBBwyFHm7IKgaIHYgB4297N0NOG73XPoOMPT3mNgoHwq5H8CYqTMh6xGQvJh43JZry5N4NFf7F58wtBfRbvy3WNYjr8i8OTFQ%3D" rel="nofollow" target="_blank">【Unity Shader Graph 使用与特效实现】</a><strong>专栏-直达</strong></blockquote><h2><strong>Unity URP Shader Graph Position节点：空间坐标与视觉效果的桥梁</strong></h2><p>Position节点是Shader Graph中用于获取三维空间坐标的核心工具，其输出结果受空间坐标系选择直接影响。该节点通过连接不同空间转换模块，可精准获取顶点或片元在特定坐标系下的位置信息，为开发者提供了强大的空间数据访问能力。在URP（Universal Render Pipeline）渲染管线中，其核心功能包括：</p><ul><li>‌<strong>对象空间Object Space</strong>‌：以物体自身中心为原点，坐标值不随物体移动或旋转改变，适合制作与物体形态强关联的效果（如基于距离的着色）</li><li>‌<strong>世界空间World Space</strong>‌：以场景原点为基准，坐标值随物体位置变化，常用于制作与场景空间相关的动态效果</li><li>‌<strong>视图空间View Space</strong>‌：以摄像机为原点，适合制作与摄像机视角相关的特效（如扫描光效果）</li></ul><blockquote>注意：URP管线中需通过Graph Settings确认渲染管线类型，传统内置管线不支持Shader Graph功能</blockquote><h2><strong>基础应用示例：基于距离的着色效果</strong></h2><h3><strong>对象空间下的距离着色</strong></h3><p>通过连接Position节点到BaseColor输出，可创建以物体中心为基准的渐变效果。这种效果在物体移动或旋转时保持不变，因为坐标系始终以物体中心为原点，适用于制作固定形态的材质变化，如UV动画或程序化纹理。</p><p>‌<strong>实现步骤</strong>‌：</p><ol><li>创建Unlit Graph模板，添加Position节点并设置空间为Object</li><li>使用Vector3 Length节点计算顶点到中心的距离</li><li>通过Saturate节点将距离值归一化到[0,1]范围</li><li>连接至Color节点生成渐变效果</li></ol><p>‌<strong>应用场景</strong>‌：</p><ul><li>制作基于物体几何形状的纹理变化</li><li>创建物体表面的渐变效果，如从中心到边缘的颜色过渡</li><li>实现物体表面的动态纹理，如随时间变化的图案</li></ul><h3><strong>世界空间下的动态效果</strong></h3><p>将空间切换为World后，Position节点输出值会随物体在场景中的位置变化。这种效果常用于制作环境交互效果，如根据物体与场景中心的距离改变透明度。</p><p>‌<strong>实现步骤</strong>‌：</p><ol><li>创建PBR Graph模板，添加World Position节点</li><li>使用SceneDepth节点获取相机到物体的距离</li><li>通过Vector3 Subtract计算物体与场景中心的相对位置</li><li>连接至Emissive Color实现动态发光效果</li></ol><p>‌<strong>应用场景</strong>‌：</p><ul><li>制作物体在场景中移动时颜色变化的特效</li><li>创建基于物体位置的动态光照效果</li><li>实现物体与场景互动的视觉效果，如接近特定区域时改变材质属性</li></ul><h2><strong>进阶应用：渐隐粒子效果实现</strong></h2><h3><strong>原理与节点配置</strong></h3><p>通过Position节点实现渐隐效果的核心是利用深度差值控制透明度。这种方法可精确控制粒子消失的过渡区域，通过调整Range参数可改变渐变范围，适用于制作溶解效果或环境粒子消散。</p><p>‌<strong>实现步骤</strong>‌：</p><ol><li>创建Transparent Surface模板，启用深度写入关闭</li><li>添加View Position节点获取相机坐标系下的Z值</li><li>使用SceneDepth节点获取物体到相机的距离</li><li>通过Vector3 Subtract计算深度差值并连接至Alpha通道</li><li>添加OneMinus节点实现反向渐变效果</li></ol><p>‌<strong>应用场景</strong>‌：</p><ul><li>制作粒子系统在特定距离开始消失的效果</li><li>创建物体逐渐透明的溶解效果</li><li>实现环境粒子与场景深度相关的消散效果</li></ul><h3><strong>性能优化技巧</strong></h3><ul><li>对透明物体使用Alpha Clipping替代混合，可显著减少像素处理量</li><li>在Graph Settings中设置合适的渲染队列（如Transparent）</li><li>使用Dithering技术伪造低透明度区域的视觉效果，提升视觉质量</li><li>对粒子系统启用深度预计算，避免实时计算场景深度，提升性能</li></ul><h2><strong>常见问题与解决方案</strong></h2><h3><strong>坐标空间选择错误</strong></h3><ul><li>‌<strong>现象</strong>‌：物体移动时颜色不变（预期应变化）</li><li>‌<strong>原因</strong>‌：误用Object空间代替World空间</li><li>‌<strong>解决</strong>‌：检查Position节点的空间设置，确保与预期效果匹配</li></ul><h3><strong>透明效果异常</strong></h3><ul><li>‌<strong>现象</strong>‌：透明物体出现闪烁或重叠错误</li><li>‌<strong>原因</strong>‌：深度写入未正确关闭或渲染队列设置不当</li><li>‌<strong>解决</strong>‌：在Graph Settings中启用深度写入关闭，并设置正确的渲染队列</li></ul><h3><strong>性能瓶颈</strong></h3><ul><li>‌<strong>现象</strong>‌：复杂Shader导致帧率下降</li><li>‌<strong>原因</strong>‌：过度使用实时计算节点（如SceneDepth）</li><li>‌<strong>解决</strong>‌：预计算深度值或使用简化算法，对粒子系统启用批处理，提升性能</li></ul><h2><strong>最佳实践与扩展应用</strong></h2><h3><strong>空间转换技巧</strong></h3><ul><li>使用World Position减Object Position获取物体局部坐标向量，实现更精细的空间控制</li><li>结合RotateAboutAxis节点实现动态坐标变换，创造独特的视觉效果</li><li>通过Screen Position节点制作屏幕空间特效，增强视觉冲击力</li></ul><h3><strong>扩展应用场景</strong></h3><ul><li>‌<strong>环境交互</strong>‌：根据物体与场景物体的距离改变材质属性，实现更自然的互动效果</li><li>‌<strong>动态UV</strong>‌：结合时间节点创建随时间变化的UV动画，增添动态元素</li><li>‌<strong>特殊效果</strong>‌：制作扫描光、X光透视等视觉效果，提升游戏或应用的沉浸感</li></ul><blockquote>提示：URP管线中建议使用HDR颜色模式处理高动态范围效果，可通过Color节点的HDR选项启用，确保视觉效果更加真实</blockquote><hr/><blockquote><a href="https://link.segmentfault.com/?enc=YjCLnn3PPqfYdv%2F2MsHi9Q%3D%3D.YW7DM9S2C2O7xxYSNUs20DEVtam2rIkXf1RzZRPkwUXDLWffayuWIaUJo%2FpierD%2Bsl%2Bmx1ujniajTszABeQFvZ9dPSUBdv2chaXH8JWejy6INCYxOIGH%2FOpNKh0gPkywu8wKke8BR42Q1%2FEn4KNoyfzV1RsHOMagxmRvC1czrPuR1ApvJHsx4YSqJ9JJnC9GYrAmQUHE43q5R6k9NT8ujlJW7faEPWhn1%2B1%2FM9%2FUJV4%3D" rel="nofollow" target="_blank">【Unity Shader Graph 使用与特效实现】</a><strong>专栏-直达</strong><br/>（欢迎<em>点赞留言</em>探讨，更多人加入进来能更加完善这个探索的过程，🙏）</blockquote>]]></description></item><item>    <title><![CDATA[网站部署SSL证书的重要作用 德迅云安全_珍珍 ]]></title>    <link>https://segmentfault.com/a/1190000047571767</link>    <guid>https://segmentfault.com/a/1190000047571767</guid>    <pubDate>2026-01-26 11:04:29</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>网站部署SSL证书的重要作用如下：</p><p>　　1.SSL证书可加密敏感信息使其不被泄露</p><p>　　使用SSL证书的主要原因是为了保障通过Internet发送的敏感信息能够加密，防止重要数据不被泄露。这很重要，因为您在Internet上进行计算机与服务器之间的信息传递，如果未使用SSL证书加密，则您传递的任何信息都有可能被第三方获取，包括您的信用卡号，用户名和密码以及其他敏感信息。使用SSL证书后，可以保障所有人都无法读取信息，这可以保护信息数据免受黑客或者用心不良的人的侵害。</p><p>　　2.SSL证书可提供身份验证，防止钓鱼网站</p><p>　　除信息加密外，SSL证书可提供身份验证。这意味着您可以确保将信息发送到正确的服务器，不用担心别人窃取您的信息。有效的防止第三方伪装成您的网站并欺骗您的用户，获取用户个人信息，造成或大或小的损失。而SSL证书是由受信任的CA机构颁发的，申请证书时会严格的验证企业/组织的信息。所以说，选择受信任的CA机构颁发的SSL证书非常的重要，CA机构会通过各种信息的验证才会颁发SSL证书，而且EV SSL证书需要比其他证书更多的验证资料。</p><p>　　3.SSL证书可增加信任度</p><p>　　安装SSL证书的网站在Web浏览器的地址栏可显示，绿色小锁图标，绿色地址栏，EV SSL证书还能显示企业/组织名称。以确保访问者知道其连接是受到保护的，可放心使用。这意味着当访问者看到这些提示信息会更信任您的网站。而且可以查看CA机构的颁发信息，以便为您的客户提供的更多信任。</p><p>　　HTTPS还可以防止网络钓鱼攻击。网络钓鱼电子邮件是冒充您网站来进行犯罪的，钓鱼电子邮件通常包含指向其网站的链接或使用中间人攻击来达到目的。由于这些违规现象无法获得正规CA机构颁发的SSL证书，因此他们无法完全冒充您的网站。这意味着您的用户陷入网络钓鱼网站的可能性很小。</p><p><img width="723" height="253" referrerpolicy="no-referrer" src="/img/bVdnLKI" alt="image.png" title="image.png"/></p>]]></description></item><item>    <title><![CDATA[GPIO的八种工作模式 良许 ]]></title>    <link>https://segmentfault.com/a/1190000047571777</link>    <guid>https://segmentfault.com/a/1190000047571777</guid>    <pubDate>2026-01-26 11:03:48</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>大家好，我是良许。</p><p>在嵌入式开发中，GPIO（General Purpose Input/Output，通用输入输出）是我们接触最多的外设之一。</p><p>无论是点亮一个LED灯，还是读取按键状态，亦或是与其他芯片进行通信，都离不开GPIO的配置。</p><p>而GPIO的工作模式直接决定了引脚的电气特性和功能表现。</p><p>今天，我就来详细聊聊STM32中GPIO的八种工作模式，帮助大家彻底理解它们的区别和应用场景。</p><h2>1. GPIO工作模式概述</h2><p>STM32的GPIO具有八种工作模式，可以分为四种输入模式和四种输出模式。</p><p>这些模式的设计非常灵活，能够满足各种应用场景的需求。</p><p><strong>四种输入模式：</strong><br/>1.1 输入浮空模式（GPIO_MODE_INPUT）<br/>1.2 输入上拉模式（GPIO_MODE_INPUT，配合GPIO_PULLUP）<br/>1.3 输入下拉模式（GPIO_MODE_INPUT，配合GPIO_PULLDOWN）<br/>1.4 模拟输入模式（GPIO_MODE_ANALOG）</p><p><strong>四种输出模式：</strong><br/>1.5 开漏输出模式（GPIO_MODE_OUTPUT_OD）<br/>1.6 开漏复用输出模式（GPIO_MODE_AF_OD）<br/>1.7 推挽输出模式（GPIO_MODE_OUTPUT_PP）<br/>1.8 推挽复用输出模式（GPIO_MODE_AF_PP）</p><p>下面我将逐一详细介绍这八种模式的工作原理、特点以及典型应用场景。</p><h2>2. 四种输入模式详解</h2><h3>2.1 输入浮空模式</h3><p>输入浮空模式是GPIO最基本的输入模式。</p><p>在这种模式下，引脚既不接上拉电阻，也不接下拉电阻，完全处于"浮空"状态。</p><p>此时引脚的电平完全由外部电路决定，如果外部没有明确的高低电平信号，引脚的状态是不确定的，可能会受到外部干扰而产生随机的高低电平跳变。</p><p><strong>特点：</strong></p><ul><li>引脚内部不接任何电阻</li><li>输入阻抗非常高</li><li>功耗最低</li><li>容易受到外部干扰</li></ul><p><strong>应用场景：</strong><br/>输入浮空模式通常用于外部电路已经提供了明确的上拉或下拉电阻的场合。</p><p>比如，当外部按键电路已经有上拉电阻时，MCU的GPIO就可以配置为浮空输入，避免内部上拉电阻与外部电阻形成分压。</p><p><strong>代码示例：</strong></p><pre><code class="c">GPIO_InitTypeDef GPIO_InitStruct = {0};

// 使能GPIOA时钟
__HAL_RCC_GPIOA_CLK_ENABLE();

// 配置PA0为浮空输入
GPIO_InitStruct.Pin = GPIO_PIN_0;
GPIO_InitStruct.Mode = GPIO_MODE_INPUT;
GPIO_InitStruct.Pull = GPIO_NOPULL;
HAL_GPIO_Init(GPIOA, &amp;GPIO_InitStruct);

// 读取引脚状态
GPIO_PinState pinState = HAL_GPIO_ReadPin(GPIOA, GPIO_PIN_0);</code></pre><h3>2.2 输入上拉模式</h3><p>输入上拉模式是在浮空输入的基础上，内部连接了一个上拉电阻（通常为30~50kΩ）到VDD。</p><p>这样，当外部没有信号输入时，引脚会被上拉电阻拉到高电平状态，避免了浮空状态下的不确定性。</p><p><strong>特点：</strong></p><ul><li>内部连接上拉电阻到VDD</li><li>默认状态为高电平</li><li>可以有效防止引脚悬空</li><li>适合低电平有效的输入信号</li></ul><p><strong>应用场景：</strong><br/>输入上拉模式最常用于按键检测。</p><p>当按键未按下时，引脚保持高电平；按键按下后，引脚被拉到地，变为低电平。</p><p>这种方式简单可靠，是按键检测的标准配置。</p><p><strong>代码示例：</strong></p><pre><code class="c">GPIO_InitTypeDef GPIO_InitStruct = {0};

__HAL_RCC_GPIOA_CLK_ENABLE();

// 配置PA1为上拉输入，用于按键检测
GPIO_InitStruct.Pin = GPIO_PIN_1;
GPIO_InitStruct.Mode = GPIO_MODE_INPUT;
GPIO_InitStruct.Pull = GPIO_PULLUP;
HAL_GPIO_Init(GPIOA, &amp;GPIO_InitStruct);

// 检测按键是否按下（低电平有效）
if (HAL_GPIO_ReadPin(GPIOA, GPIO_PIN_1) == GPIO_PIN_RESET) {
    // 按键被按下
    // 执行相应操作
}</code></pre><h3>2.3 输入下拉模式</h3><p>输入下拉模式与上拉模式相反，内部连接了一个下拉电阻（同样是30~50kΩ）到GND。</p><p>当外部没有信号输入时，引脚会被下拉电阻拉到低电平状态。</p><p><strong>特点：</strong></p><ul><li>内部连接下拉电阻到GND</li><li>默认状态为低电平</li><li>防止引脚悬空</li><li>适合高电平有效的输入信号</li></ul><p><strong>应用场景：</strong><br/>输入下拉模式适用于高电平有效的信号检测。</p><p>比如某些传感器输出高电平表示有效信号，此时可以将GPIO配置为下拉输入，确保在没有信号时引脚保持低电平。</p><p><strong>代码示例：</strong></p><pre><code class="c">GPIO_InitTypeDef GPIO_InitStruct = {0};

__HAL_RCC_GPIOB_CLK_ENABLE();

// 配置PB0为下拉输入
GPIO_InitStruct.Pin = GPIO_PIN_0;
GPIO_InitStruct.Mode = GPIO_MODE_INPUT;
GPIO_InitStruct.Pull = GPIO_PULLDOWN;
HAL_GPIO_Init(GPIOB, &amp;GPIO_InitStruct);

// 检测高电平有效信号
if (HAL_GPIO_ReadPin(GPIOB, GPIO_PIN_0) == GPIO_PIN_SET) {
    // 检测到高电平信号
    // 执行相应操作
}</code></pre><h3>2.4 模拟输入模式</h3><p>模拟输入模式是专门为ADC（模数转换器）设计的。</p><p>在这种模式下，GPIO引脚直接连接到ADC的输入通道，不经过施密特触发器，可以输入连续变化的模拟信号。</p><p><strong>特点：</strong></p><ul><li>关闭数字输入功能</li><li>关闭上拉下拉电阻</li><li>信号直接进入ADC</li><li>功耗最低</li></ul><p><strong>应用场景：</strong><br/>模拟输入模式专门用于ADC采集模拟信号，比如读取温度传感器、光敏电阻、电位器等模拟量。</p><p>在这种模式下，GPIO不再作为数字IO使用，而是作为ADC的模拟输入通道。</p><p><strong>代码示例：</strong></p><pre><code class="c">GPIO_InitTypeDef GPIO_InitStruct = {0};
ADC_HandleTypeDef hadc1;

__HAL_RCC_GPIOA_CLK_ENABLE();
__HAL_RCC_ADC1_CLK_ENABLE();

// 配置PA4为模拟输入，用于ADC
GPIO_InitStruct.Pin = GPIO_PIN_4;
GPIO_InitStruct.Mode = GPIO_MODE_ANALOG;
GPIO_InitStruct.Pull = GPIO_NOPULL;
HAL_GPIO_Init(GPIOA, &amp;GPIO_InitStruct);

// ADC配置（简化示例）
hadc1.Instance = ADC1;
hadc1.Init.Resolution = ADC_RESOLUTION_12B;
hadc1.Init.DataAlign = ADC_DATAALIGN_RIGHT;
HAL_ADC_Init(&amp;hadc1);

// 读取ADC值
HAL_ADC_Start(&amp;hadc1);
HAL_ADC_PollForConversion(&amp;hadc1, 100);
uint32_t adcValue = HAL_ADC_GetValue(&amp;hadc1);</code></pre><h2>3. 四种输出模式详解</h2><h3>3.1 推挽输出模式</h3><p>推挽输出（Push-Pull）是最常用的输出模式。</p><p>在这种模式下，输出级由两个MOS管组成，一个连接VDD（P-MOS），一个连接GND（N-MOS）。</p><p>输出高电平时，P-MOS导通，引脚连接到VDD；输出低电平时，N-MOS导通，引脚连接到GND。</p><p>这种结构可以提供较强的驱动能力。</p><p><strong>特点：</strong></p><ul><li>可以输出高电平和低电平</li><li>驱动能力强，可以直接驱动LED等负载</li><li>输出电平明确，不会出现悬空状态</li><li>不能实现线与功能</li></ul><p><strong>应用场景：</strong><br/>推挽输出是GPIO最常用的输出模式，适用于驱动LED、控制继电器、输出PWM信号等场景。</p><p>只要不需要多个设备共享同一条信号线，推挽输出都是首选。</p><p><strong>代码示例：</strong></p><pre><code class="c">GPIO_InitTypeDef GPIO_InitStruct = {0};

__HAL_RCC_GPIOC_CLK_ENABLE();

// 配置PC13为推挽输出，用于控制LED
GPIO_InitStruct.Pin = GPIO_PIN_13;
GPIO_InitStruct.Mode = GPIO_MODE_OUTPUT_PP;
GPIO_InitStruct.Pull = GPIO_NOPULL;
GPIO_InitStruct.Speed = GPIO_SPEED_FREQ_LOW;
HAL_GPIO_Init(GPIOC, &amp;GPIO_InitStruct);

// 点亮LED（假设低电平点亮）
HAL_GPIO_WritePin(GPIOC, GPIO_PIN_13, GPIO_PIN_RESET);

// 延时
HAL_Delay(1000);

// 熄灭LED
HAL_GPIO_WritePin(GPIOC, GPIO_PIN_13, GPIO_PIN_SET);</code></pre><h3>3.2 开漏输出模式</h3><p>开漏输出（Open-Drain）模式下，输出级只有一个N-MOS管连接到GND。</p><p>输出低电平时，N-MOS导通，引脚接地；输出高电平时，N-MOS关断，引脚呈现高阻态。</p><p>要输出高电平，必须外接上拉电阻。</p><p><strong>特点：</strong></p><ul><li>只能主动输出低电平</li><li>输出高电平需要外部上拉电阻</li><li>可以实现电平转换</li><li>支持线与功能（多个设备共享一条线）</li></ul><p><strong>应用场景：</strong><br/>开漏输出最典型的应用是I2C总线。</p><p>I2C是多主机总线，多个设备共享SDA和SCL两条线，必须使用开漏输出配合外部上拉电阻。</p><p>此外，开漏输出还可以用于电平转换，比如MCU是3.3V供电，但需要输出5V信号时，可以使用开漏输出配合5V上拉电阻。</p><p><strong>代码示例：</strong></p><pre><code class="c">GPIO_InitTypeDef GPIO_InitStruct = {0};

__HAL_RCC_GPIOB_CLK_ENABLE();

// 配置PB6和PB7为开漏输出，用于I2C（SCL和SDA）
GPIO_InitStruct.Pin = GPIO_PIN_6 | GPIO_PIN_7;
GPIO_InitStruct.Mode = GPIO_MODE_OUTPUT_OD;
GPIO_InitStruct.Pull = GPIO_PULLUP;  // 如果外部没有上拉，可以使能内部上拉
GPIO_InitStruct.Speed = GPIO_SPEED_FREQ_HIGH;
HAL_GPIO_Init(GPIOB, &amp;GPIO_InitStruct);

// 模拟I2C起始信号
HAL_GPIO_WritePin(GPIOB, GPIO_PIN_7, GPIO_PIN_RESET);  // SDA拉低
HAL_Delay(1);
HAL_GPIO_WritePin(GPIOB, GPIO_PIN_6, GPIO_PIN_RESET);  // SCL拉低</code></pre><h3>3.3 推挽复用输出模式</h3><p>推挽复用输出模式是推挽输出的复用版本。</p><p>在这种模式下，GPIO的控制权交给片上外设（如SPI、USART等），由外设自动控制引脚的输出。</p><p><strong>特点：</strong></p><ul><li>由片上外设控制输出</li><li>具有推挽输出的所有特性</li><li>用户不能直接控制引脚电平</li><li>适合高速通信</li></ul><p><strong>应用场景：</strong><br/>推挽复用输出主要用于SPI、USART等需要高速、强驱动能力的通信接口。</p><p>比如SPI的MOSI、SCK引脚，USART的TX引脚等。</p><p><strong>代码示例：</strong></p><pre><code class="c">GPIO_InitTypeDef GPIO_InitStruct = {0};

__HAL_RCC_GPIOA_CLK_ENABLE();

// 配置PA9为推挽复用输出，用于USART1_TX
GPIO_InitStruct.Pin = GPIO_PIN_9;
GPIO_InitStruct.Mode = GPIO_MODE_AF_PP;
GPIO_InitStruct.Pull = GPIO_NOPULL;
GPIO_InitStruct.Speed = GPIO_SPEED_FREQ_HIGH;
GPIO_InitStruct.Alternate = GPIO_AF7_USART1;  // 复用为USART1
HAL_GPIO_Init(GPIOA, &amp;GPIO_InitStruct);

// 后续由USART外设控制该引脚</code></pre><h3>3.4 开漏复用输出模式</h3><p>开漏复用输出模式是开漏输出的复用版本。</p><p>同样，GPIO的控制权交给片上外设，但输出特性为开漏。</p><p><strong>特点：</strong></p><ul><li>由片上外设控制输出</li><li>具有开漏输出的所有特性</li><li>需要外部上拉电阻</li><li>支持多主机通信</li></ul><p><strong>应用场景：</strong><br/>开漏复用输出主要用于I2C、SMBUS等需要多主机通信的总线。</p><p>当使用STM32的硬件I2C外设时，SCL和SDA引脚必须配置为开漏复用输出。</p><p><strong>代码示例：</strong></p><pre><code class="c">GPIO_InitTypeDef GPIO_InitStruct = {0};

__HAL_RCC_GPIOB_CLK_ENABLE();

// 配置PB8和PB9为开漏复用输出，用于I2C1（SCL和SDA）
GPIO_InitStruct.Pin = GPIO_PIN_8 | GPIO_PIN_9;
GPIO_InitStruct.Mode = GPIO_MODE_AF_OD;
GPIO_InitStruct.Pull = GPIO_PULLUP;  // 使能内部上拉（外部也应有上拉电阻）
GPIO_InitStruct.Speed = GPIO_SPEED_FREQ_HIGH;
GPIO_InitStruct.Alternate = GPIO_AF4_I2C1;  // 复用为I2C1
HAL_GPIO_Init(GPIOB, &amp;GPIO_InitStruct);

// 后续由I2C外设控制该引脚</code></pre><h2>4. 工作模式选择建议</h2><p>在实际开发中，如何选择合适的GPIO工作模式呢？这里给出一些实用建议：</p><p><strong>4.1 输入模式选择：</strong></p><ul><li>如果外部电路已有上拉/下拉电阻，选择浮空输入</li><li>如果是按键检测且按键接地，选择上拉输入</li><li>如果是按键检测且按键接VDD，选择下拉输入</li><li>如果是ADC采集模拟信号，必须选择模拟输入</li></ul><p><strong>4.2 输出模式选择：</strong></p><ul><li>一般的LED驱动、信号输出，选择推挽输出</li><li>I2C、单总线等多设备共享的总线，选择开漏输出</li><li>需要电平转换时，选择开漏输出配合外部上拉</li><li>使用片上外设（如SPI、USART）时，根据外设要求选择复用模式</li></ul><p><strong>4.3 速度等级选择：</strong><br/>STM32的GPIO还可以配置输出速度（Low、Medium、High、Very High），这会影响引脚的翻转速度和功耗。一般原则是：</p><ul><li>低速信号（如LED控制）选择Low Speed，降低EMI和功耗</li><li>中速信号（如普通通信）选择Medium或High Speed</li><li>高速信号（如高速SPI、SDIO）选择Very High Speed</li></ul><h2>5. 常见问题与注意事项</h2><p><strong>5.1 为什么开漏输出需要上拉电阻？</strong><br/>因为开漏输出只能主动拉低，不能主动拉高。</p><p>没有上拉电阻时，输出高电平时引脚处于高阻态，无法驱动负载。</p><p>上拉电阻的作用是在N-MOS关断时将引脚拉到高电平。</p><p><strong>5.2 推挽输出可以接上拉电阻吗？</strong><br/>可以，但通常没有必要。</p><p>推挽输出本身就能输出强高电平和强低电平，额外的上拉电阻只会增加功耗。</p><p>只有在需要提高驱动能力或进行电平转换时才需要。</p><p><strong>5.3 多个GPIO可以连接在一起吗？</strong><br/>如果都是推挽输出，绝对不能连接在一起！当一个输出高电平、另一个输出低电平时，会形成短路，可能烧毁芯片。</p><p>如果需要多个GPIO共享一条线，必须使用开漏输出。</p><p><strong>5.4 复用功能如何配置？</strong><br/>使用HAL库时，需要同时配置GPIO模式和复用功能。</p><p>不同的引脚支持的复用功能不同，需要查阅芯片数据手册中的引脚复用表。</p><p>通过以上详细的介绍，相信大家对STM32的GPIO八种工作模式有了深入的理解。</p><p>在实际项目中，正确选择GPIO的工作模式是保证系统稳定运行的基础。</p><p>希望这篇文章能帮助大家在嵌入式开发的道路上少走弯路，写出更加可靠的代码。</p><p><strong>更多编程学习资源</strong></p><ul><li><a href="https://link.segmentfault.com/?enc=hPFFrr37wJseHUqbuW05iA%3D%3D.y9dNmN%2FHM6ZfRGEEKHFH9%2B1tFkLkOTTq2LgTKYe6%2FVhJSsnw2dKdf4FZxVWstBTkOZjww6x0G6R%2BIe0ncbqbLw%3D%3D" rel="nofollow" target="_blank">C语言零基础入门电子书-2026最新版</a></li><li><a href="https://link.segmentfault.com/?enc=gIxq4EnPVoPv8f%2FPHuJHZg%3D%3D.6uAvLznMkID918dcDfbjnO%2Fu7OctJZm%2F3wmTnoawPmUoi1MQszUUiBEuk6IyERgIy3Uee%2BWP2OICurJKNgu27w%3D%3D" rel="nofollow" target="_blank">STM32零基础入门电子书-2026最新版</a></li><li><a href="https://link.segmentfault.com/?enc=Jw5ED3D82SfqjFCzqnQLNg%3D%3D.AwyNDVrYXUyv98RXf226fka8R6kffW7PotBHPG1QDAN%2BdRs731LklktRMhZ3LYrVA39UM328jozOFusWdMMOPKUs%2B%2BVvmhxaXQXJCMUGDz0%3D" rel="nofollow" target="_blank">FreeRTOS零基础入门电子书-2026最新版</a></li><li><a href="https://link.segmentfault.com/?enc=T1g0E2oOWGpw%2BA5XmZIb%2Bg%3D%3D.SnIDhuuBlasYeuRRtyLWeEOJPftJ01qplEXmufLTF837OO8vjoX5Xq9F2nnBK444p8yZdWIdafVgmbTxZoXu1w%3D%3D" rel="nofollow" target="_blank">C++ 零基础入门电子书-2026最新版</a></li><li><a href="https://link.segmentfault.com/?enc=X3h9RMcF2jI7ToBM0gsDrg%3D%3D.y7EixIqfZDM9mEdk7RHQY2%2Bl1NT0JfMhy%2BIq8AMbwsEJSXgFLRyVRLaHJHq%2FztJITw9%2BH9jXQhoRcsfPhaLPKA%3D%3D" rel="nofollow" target="_blank">51单片机零基础入门学习路线</a></li><li><a href="https://link.segmentfault.com/?enc=aD8etflJ5dVX6qHcCWG1AQ%3D%3D.oF29Jra1rIz1Qvj4BG2KPyOxOeEao33EFYosXqs6lVm3FtemjKMntkI4Q7hLNxxP5Xj1uaCrVqP%2FW2IxGfbCjA%3D%3D" rel="nofollow" target="_blank">AD画板零基础入门学习路线</a></li><li><a href="https://link.segmentfault.com/?enc=zGpRZE75lJCa7hzDMnFmJQ%3D%3D.Sw%2FA6njcDRWloSMZy%2BiDaVAvoX7Bkv0UAJmGBCTLdoY%2B1KTZhdnJAnBUvjzuJ8tg5SnHCrnmpMxRmuvQiL%2FmPw%3D%3D" rel="nofollow" target="_blank">C语言零基础入门学习路线</a></li><li><a href="https://link.segmentfault.com/?enc=HlFfgqNK6J4PKFnX3DIOOA%3D%3D.RirtqYn2w3zJswFI4NTyGRhYQcaiAnm1S0OQcdq5BhQemWUQ4z36nJjrNQZzg1qPn2xi3NOoRPBdCIeLCakuvQ%3D%3D" rel="nofollow" target="_blank">C++语言零基础入门学习路线</a></li><li><a href="https://link.segmentfault.com/?enc=HNWWn0LT1tD3kDwXqxvKmw%3D%3D.5YEDp2fN21%2FqCy%2Bad5603PLd%2Fb%2BoTJh9DSMviODKAlrxoHjUaG3IeNmP0LiG2s2GR7QvWf3RKfV%2BbbUIq9GMZx3QuSNLtYtm%2BF61D9ql5Ig%3D" rel="nofollow" target="_blank">ESP32零基础入门学习路线</a></li><li><a href="https://link.segmentfault.com/?enc=ZCynN19WkEJbTJf3ffwjCw%3D%3D.%2F6EqB2fjsiwj8K2lWVM7bUbHg%2FSnPDb2BP4Z32GTZKrriMj%2F1Rh%2B5SMXe4DI6Hs5R4kk2t3bLJamO8NSWf8iNyrEgGNs4got1G4HZhXbtj8%3D" rel="nofollow" target="_blank">FreeRTOS零基础入门学习路线</a></li><li><a href="https://link.segmentfault.com/?enc=XBGveYvLeZ4yWDtV8XdOqg%3D%3D.%2F0CvDmDDQ%2FpSTFJvo3luNX6585XMlGpNSF3JsQn9fFExHJK2TraoTmtF4OJKIlFDwCPxnBCPVpQrbiJ7JNq8m9n5j9btBkTIrbOmeIxLWVk%3D" rel="nofollow" target="_blank">Linux应用开发零基础入门学习路线</a></li><li><a href="https://link.segmentfault.com/?enc=NhpkyfaVQS6NYepSAfaDdA%3D%3D.iTV%2BBa9c6XNKW2mTFYWYPRP5V1flhgbLFTxRWdcBI9MJuhNWjWiYYlkmKozRXTM33xYQ8qwEupH%2BVKSrEO4pWRLWBsNmvoDuTaL6s5dlBEA%3D" rel="nofollow" target="_blank">Linux底层开发零基础入门学习路线</a></li><li><a href="https://link.segmentfault.com/?enc=mxpfyCWKNbjygd5374uLNg%3D%3D.%2FyEbYDApK5PHzB9kMtDFvYZO%2Fs6XBCpmxd%2BFfEir6X57UKcLRMgdSg7wAfSaYdFMuZoGM2fSnys0%2F3VR5EDtEw%3D%3D" rel="nofollow" target="_blank">LVGL零基础入门学习路线</a></li><li><a href="https://link.segmentfault.com/?enc=sxYscADJtzwN1704ycrCfw%3D%3D.e0FQURhdbGxxiqssDLB1isc5r0PSSbFGYE2POv91%2FHw8NPqUOZgJQPis90JfnL%2F1T1JsCe1t93C1TzTy%2BYirGQ%3D%3D" rel="nofollow" target="_blank">QT零基础入门学习路线</a></li><li><a href="https://link.segmentfault.com/?enc=8x9DswrFyivEaO%2FGP6ow2A%3D%3D.3RaPI4D%2BGZ4%2FVyumwXiVRmN4adtk502E75gg7u2SkBQqh2d5zaDT9luGjEvZaxD3tZ4AqC6Q4R07nlrmZQHFxrESuaCfh15TVc9dgixULdk%3D" rel="nofollow" target="_blank">STM32零基础入门学习路线</a></li></ul>]]></description></item><item>    <title><![CDATA[基于 YOLOv8 的河道漂浮垃圾智能检测｜完整源码数据集+PyQt5界面+完整训练流程+开箱即用！]]></title>    <link>https://segmentfault.com/a/1190000047571799</link>    <guid>https://segmentfault.com/a/1190000047571799</guid>    <pubDate>2026-01-26 11:02:53</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>基于 YOLOv8 的河道漂浮垃圾智能检测｜完整源码数据集+PyQt5界面+完整训练流程+开箱即用！</h2><p>源码包含：完整YOLOv8训练代码+数据集(带标注)+权重文件+直接可允许检测的yolo检测程序+直接部署教程/训练教程</p><h3>基本功能演示</h3><p><a href="https://www.bilibili.com/video/BV1ctr6BQEPX/" target="_blank">https://www.bilibili.com/video/BV1ctr6BQEPX/</a></p><blockquote>源码在文末哔哩哔哩视频简介处。</blockquote><h3>项目摘要</h3><p>随着城市化进程加快与水域生态压力的持续增加，河道漂浮垃圾已成为影响城市形象、水体安全与生态环境的重要问题。传统人工巡查方式存在效率低、成本高、实时性差等不足，难以满足大范围、全天候的监管需求。</p><p>本项目基于 <strong>YOLOv8 目标检测算法</strong>，构建了一套 <strong>河道漂浮垃圾智能检测系统</strong>，可对河面常见漂浮垃圾（如塑料瓶、泡沫、包装物等）进行<strong>实时、精准识别与定位</strong>。系统集成 <strong>PyQt5 可视化界面</strong>，支持图片、视频、文件夹及摄像头等多种输入方式，具备良好的易用性与工程化落地能力。</p><p>项目提供<strong>完整源码、标注数据集、训练脚本、模型权重以及部署教程</strong>，覆盖从数据准备、模型训练到实际应用的完整流程，实现真正的<strong>开箱即用</strong>，适用于科研学习、课程设计以及智慧水务、环保监测等实际场景。</p><h3>前言</h3><p>在“智慧城市”“数字孪生水利”等理念不断落地的背景下，河道环境的精细化管理正逐步从人工经验驱动转向数据与智能驱动。河面漂浮垃圾不仅影响景观，更可能造成排水口堵塞、水质恶化，甚至引发生态安全隐患，因此实现高效、自动化的垃圾监测具有重要现实意义。</p><p>近年来，基于深度学习的目标检测技术在工业检测、交通监控、安防巡检等领域取得了显著成果。其中，YOLO 系列模型以其<strong>速度快、精度高、部署灵活</strong>的优势，成为工程实践中的主流选择。YOLOv8 作为 Ultralytics 推出的新一代模型，在网络结构、训练策略和推理效率方面均有明显提升，非常适合实时场景应用。</p><p>基于上述背景，本项目围绕“<strong>河道漂浮垃圾自动检测</strong>”这一典型应用场景，设计并实现了一套完整的智能识别系统，重点解决以下问题：</p><ul><li>河道复杂背景下小目标垃圾的检测难题</li><li>模型从训练到部署的工程化落地问题</li><li>非算法人员使用门槛高的问题</li></ul><p>通过算法与界面的深度结合，使该系统不仅“能跑模型”，更“能实际使用”。</p><h2>一、软件核心功能介绍及效果演示</h2><h4>1. 多源数据输入支持</h4><p>系统支持多种数据输入方式，满足不同应用场景需求：</p><ul><li><strong>单张图片检测</strong>：快速验证模型对不同河道场景的识别效果</li><li><strong>文件夹批量检测</strong>：对历史采集数据进行集中分析</li><li><strong>视频文件检测</strong>：适用于无人机巡河、固定监控录像分析</li><li><strong>实时摄像头检测</strong>：支持 USB 摄像头 / RTSP 视频流，实现实时监测</li></ul><p>所有检测结果均可实时显示，便于直观观察模型性能。</p><hr/><h4>2. 基于 YOLOv8 的高精度漂浮垃圾检测</h4><p>核心检测模块基于 YOLOv8 目标检测模型，具有以下特点：</p><ul><li>对河面复杂光照、水纹反射具有较强鲁棒性</li><li>支持多类别漂浮垃圾同时检测</li><li>检测速度快，满足实时或准实时应用需求</li><li>模型结构轻量，便于后续边缘端部署</li></ul><p>检测结果以<strong>边界框 + 类别标签 + 置信度</strong>形式直观呈现。</p><hr/><h4>3. PyQt5 可视化界面设计</h4><p>为降低使用门槛，系统采用 <strong>PyQt5</strong> 构建桌面端可视化界面，主要功能包括：</p><ul><li>一键加载模型权重</li><li>输入源快速切换（图片 / 视频 / 摄像头）</li><li>检测过程实时显示</li><li>检测结果自动保存</li></ul><p>即使不具备深度学习背景，也可通过图形界面完成完整检测流程。</p><hr/><h4>4. 完整训练与部署流程支持</h4><p>项目不仅提供推理程序，还包含完整训练链路：</p><ul><li>数据集组织方式与标注格式说明</li><li>YOLOv8 训练参数配置示例</li><li>模型训练、验证与评估流程</li><li>权重导出与推理部署方法</li></ul><p>用户可基于现有数据集直接训练，也可替换为自己的河道或水域数据进行二次开发。</p><hr/><h4>5. 实际效果演示说明</h4><p>在真实河道与公开视频测试中，系统能够稳定识别多种漂浮垃圾目标，在复杂背景下仍保持较高的检测准确率。通过 PyQt5 界面，可清晰观察每一帧的检测结果，为后续垃圾统计、告警联动与智能清理提供可靠数据支撑。</p><h2>二、软件效果演示</h2><p>为了直观展示本系统基于 YOLOv8 模型的检测能力，我们设计了多种操作场景，涵盖静态图片、批量图片、视频以及实时摄像头流的检测演示。</p><h3>（1）单图片检测演示</h3><p>用户点击“选择图片”，即可加载本地图像并执行检测：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571801" alt="image-20260112181222199" title="image-20260112181222199"/></p><hr/><h3>（2）多文件夹图片检测演示</h3><p>用户可选择包含多张图像的文件夹，系统会批量检测并生成结果图。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571802" alt="image-20260112181253208" title="image-20260112181253208" loading="lazy"/></p><hr/><h3>（3）视频检测演示</h3><p>支持上传视频文件，系统会逐帧处理并生成目标检测结果，可选保存输出视频：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571803" alt="image-20260112181311218" title="image-20260112181311218" loading="lazy"/></p><hr/><h3>（4）摄像头检测演示</h3><p>实时检测是系统中的核心应用之一，系统可直接调用摄像头进行检测。由于原理和视频检测相同，就不重复演示了。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571804" alt="image-20260112181320653" title="image-20260112181320653" loading="lazy"/></p><hr/><h3>（5）保存图片与视频检测结果</h3><p>用户可通过按钮勾选是否保存检测结果，所有检测图像自动加框标注并保存至指定文件夹，支持后续数据分析与复审。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571805" alt="image-20260112181339760" title="image-20260112181339760" loading="lazy"/></p><h2>三、模型的训练、评估与推理</h2><p>YOLOv8是Ultralytics公司发布的新一代目标检测模型，采用更轻量的架构、更先进的损失函数（如CIoU、TaskAlignedAssigner）与Anchor-Free策略，在COCO等数据集上表现优异。<br/> 其核心优势如下：</p><ul><li>高速推理，适合实时检测任务</li><li>支持Anchor-Free检测</li><li>支持可扩展的Backbone和Neck结构</li><li>原生支持ONNX导出与部署</li></ul><h3>3.1 YOLOv8的基本原理</h3><p>YOLOv8 是 Ultralytics 发布的新一代实时目标检测模型，具备如下优势：</p><ul><li><strong>速度快</strong>：推理速度提升明显；</li><li><strong>准确率高</strong>：支持 Anchor-Free 架构；</li><li><strong>支持分类/检测/分割/姿态多任务</strong>；</li><li>本项目使用 YOLOv8 的 Detection 分支，训练时每类表情均标注为独立目标。</li></ul><p>YOLOv8 由Ultralytics 于 2023 年 1 月 10 日发布，在准确性和速度方面具有尖端性能。在以往YOLO 版本的基础上，YOLOv8 引入了新的功能和优化，使其成为广泛应用中各种物体检测任务的理想选择。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571806" alt="image-20250526165954475" title="image-20250526165954475" loading="lazy"/></p><p>YOLOv8原理图如下：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571807" alt="image-20250526170118103" title="image-20250526170118103" loading="lazy"/></p><h3>3.2 数据集准备与训练</h3><p>采用 YOLO 格式的数据集结构如下：</p><pre><code class="kotlin">dataset/
├── images/
│   ├── train/
│   └── val/
├── labels/
│   ├── train/
│   └── val/</code></pre><p>每张图像有对应的 <code>.txt</code> 文件，内容格式为：</p><pre><code class="bash">4 0.5096721233576642 0.352838390077821 0.3947600423357664 0.31825755058365757</code></pre><p>分类包括（可自定义）：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571808" alt="image-20260112181438239" title="image-20260112181438239" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571809" alt="image-20260112181458571" title="image-20260112181458571" loading="lazy"/></p><h3>3.3. 训练结果评估</h3><p>训练完成后，将在 <code>runs/detect/train</code> 目录生成结果文件，包括：</p><ul><li><code>results.png</code>：损失曲线和 mAP 曲线；</li><li><code>weights/best.pt</code>：最佳模型权重；</li><li><code>confusion_matrix.png</code>：混淆矩阵分析图。</li></ul><blockquote>若 mAP@0.5 达到 90% 以上，即可用于部署。</blockquote><p>在深度学习领域，我们通常通过观察损失函数下降的曲线来评估模型的训练状态。YOLOv8训练过程中，主要包含三种损失：定位损失（box_loss）、分类损失（cls_loss）和动态特征损失（dfl_loss）。训练完成后，相关的训练记录和结果文件会保存在runs/目录下，具体内容如下：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571810" alt="image-20260112181416259" title="image-20260112181416259" loading="lazy"/></p><h3>3.4检测结果识别</h3><p>使用 PyTorch 推理接口加载模型：</p><pre><code class="python">import cv2
from ultralytics import YOLO
import torch
from torch.serialization import safe_globals
from ultralytics.nn.tasks import DetectionModel

# 加入可信模型结构
safe_globals().add(DetectionModel)

# 加载模型并推理
model = YOLO('runs/detect/train/weights/best.pt')
results = model('test.jpg', save=True, conf=0.25)

# 获取保存后的图像路径
# 默认保存到 runs/detect/predict/ 目录
save_path = results[0].save_dir / results[0].path.name

# 使用 OpenCV 加载并显示图像
img = cv2.imread(str(save_path))
cv2.imshow('Detection Result', img)
cv2.waitKey(0)
cv2.destroyAllWindows()
</code></pre><p>预测结果包含类别、置信度、边框坐标等信息。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571811" alt="image-20260112181531946" title="image-20260112181531946" loading="lazy"/></p><h2>四.YOLOV8+YOLOUI完整源码打包</h2><p>本文涉及到的完整全部程序文件：包括<strong>python源码、数据集、训练代码、UI文件、测试图片视频</strong>等（见下图），获取方式见【4.2 完整源码下载】：</p><h3>4.1 项目开箱即用</h3><p>作者已将整个工程打包。包含已训练完成的权重，读者可不用自行训练直接运行检测。</p><p>运行项目只需输入下面命令。</p><pre><code class="bash">python main.py</code></pre><p>读者也可自行配置训练集，或使用打包好的数据集直接训练。</p><p>自行训练项目只需输入下面命令。</p><pre><code class="bash">yolo detect train data=datasets/expression/loopy.yaml model=yolov8n.yaml pretrained=yolov8n.pt epochs=100 batch=16 lr0=0.001</code></pre><h3>4.2 完整源码</h3><p>至项目实录视频下方获取：<br/><a href="https://www.bilibili.com/video/BV1ctr6BQEPX/" target="_blank">https://www.bilibili.com/video/BV1ctr6BQEPX/</a><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047571812" alt="image-20250801135823301" title="image-20250801135823301" loading="lazy"/></p><p>包含：</p><blockquote><p>📦完整项目源码</p><p>📦 预训练模型权重</p><p>🗂️ 数据集地址（含标注脚本）</p></blockquote><h2>总结</h2><p>本文围绕 <strong>“基于 YOLOv8 的河道漂浮垃圾智能检测系统”</strong>，系统性地介绍了从问题背景、技术选型到工程实现与效果验证的完整过程。项目以 YOLOv8 目标检测模型为核心，结合 PyQt5 图形化界面，实现了对河道漂浮垃圾的<strong>自动化、可视化与实时化检测</strong>，有效弥补了传统人工巡查在效率、覆盖范围和实时性方面的不足。</p><p>在工程层面，项目不仅验证了 YOLOv8 在复杂水面场景下对小目标垃圾的良好检测能力，还通过完整的数据集组织方式、训练与评估流程，保证了模型具备较强的可复现性与可扩展性。同时，PyQt5 界面的引入显著降低了系统使用门槛，使算法能力能够以“产品化”的形式落地，真正做到<strong>算法即服务、模型即工具</strong>。</p><p>从应用价值来看，该系统可广泛应用于智慧水务、河道巡检、环保监管及无人机巡河等场景，并具备进一步扩展垃圾统计分析、告警联动、边缘端部署等能力的潜力。整体而言，本项目不仅是一个完整可运行的目标检测实战案例，也为水环境智能感知与治理提供了一种具有实际落地价值的技术方案。</p>]]></description></item><item>    <title><![CDATA[区分 FUD 和现实：MySQL 真的被放弃了吗？ 本文系翻译，阅读原文
https://www.p]]></title>    <link>https://segmentfault.com/a/1190000047571828</link>    <guid>https://segmentfault.com/a/1190000047571828</guid>    <pubDate>2026-01-26 11:01:55</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <blockquote><p>作者：Julia Vural，Percona 工程师。</p><p>原文：<a href="https://link.segmentfault.com/?enc=tT9lpDYTE%2BE7xGZGrLQbQg%3D%3D.ZKcOl%2F6f6ArWr8LEW7LW7pgbOUGj9c8xiwXueojW4Mz6Cz%2BSqJyu35uTfqafsFL5U2ot%2FJfRuEdJrmDSX0yyWtJrxjwnZgh9YyuY4Y%2F6J8jxz9O1flYMDUfoDn91JWq4" rel="nofollow" target="_blank">https://www.percona.com/blog/separating-fud-and-reality-has-m...</a>，Jan 22, 2026</p><p>爱可生开源社区翻译，本文约 900 字，预计阅读需要 3 分钟。</p></blockquote><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571830" alt="" title=""/></p><p>过去几周，MySQL 社区再次出现关于 <em>“Oracle 已停止开发 MySQL”</em> 或 <em>“MySQL 将被放弃”</em> 的说法，引发了更多讨论和担忧。一些图表显示，2025 年 10 月之后 GitHub 的提交数量似乎停止增长，而一些博客文章和论坛讨论也对这些迹象进行了字面解读，这进一步加剧了人们的担忧。</p><p>作为一名公开分析过 MySQL 代码库活动，并且每天都在 Percona 公司使用 MySQL 的人，我想清楚地区分数据实际显示的内容和数据未显示的内容。</p><p><strong>这篇文章并非对 Oracle 的盲目辩护。我们常常不同意 Oracle 的某些决定，并且会公开表达我们的观点。但公平至关重要——尤其是在恐惧、不确定性和怀疑（FUD）开始影响客户和更广泛的生态系统时。</strong></p><h2>关于“停止对 MySQL 维护”的说法</h2><p>我们最近收到社区<a href="https://link.segmentfault.com/?enc=F4lPO0RDx1aEwroIMS9kMQ%3D%3D.H3imlHP63eOjVyWB4fNLMTCkJIrCmFgNkqFr%2BnF3aIQ89rVbTyJWtkRo2Ut1EbPr6Zb8gzLw%2B8YJ%2BnRZ0aa0ufYOy%2FOWlV3HUPO%2Fu5d0dLp5FoU%2BcetY7y2nzyKNnhUEYcKfkjlNDUCkXpVngJ7fJQ%3D%3D" rel="nofollow" title="问题帖子地址" target="_blank">一个令人惊讶的问题</a>：MySQL 真的被放弃了吗？他们还附上了 <a href="https://link.segmentfault.com/?enc=BgviLZU70zAUhQKWzwnazA%3D%3D.mIZEH6WrjbPEEpWwLFGMraFKkWmq%2BvU1dmUz%2F5CW%2BrT6%2FS8Hdq0Kps1sk69jFTu1X6wSKVgOfbtyWmHP30gjiA%3D%3D" rel="nofollow" title="Otto Kekäläinen 的帖子" target="_blank">Otto Kekäläinen 的帖子</a>中分享的图表。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571831" alt="论坛截图" title="论坛截图" loading="lazy"/></p><p>这一结论通常是从 <a href="https://link.segmentfault.com/?enc=nZ7MTU1ZFkOWTyFtGbe7BA%3D%3D.IqzgFHsEpgdl0c5QloICDAvuMgyYu8%2FCYwcdGwgGl9NvDJvv5ZunlmkI8sCP7sNJ" rel="nofollow" title="MySQL 公共仓库" target="_blank">GitHub 公共仓库</a> 的活动图表中得出的 ，该图表确实显示存在很长一段时间没有可见的提交。</p><p>图表本身没有错，但解读并不完整。</p><h2>缺失的背景信息：MySQL 的实际开发过程</h2><p><strong>错误在于假设 MySQL 是在 GitHub 上开发的，但事实并非如此。</strong> </p><p>多年来，Oracle 一直遵循一套特定的工作流程，即在私有的封闭代码库中进行实时工程开发。GitHub 仅作为公共镜像和发布平台，而非活跃的开发工作空间。因此，代码会以大型的、整合的“代码包”的形式发布，与官方版本同步，而不是以每日增量提交的形式出现。</p><p>换句话说：</p><p><strong>GitHub 是一个异步发布镜像，而不是开发记录系统。</strong></p><p>这意味着：</p><ul><li>GitHub 上缺乏增量提交并不意味着缺乏开发。</li><li>预计版本发布之间会有较长的平静期。</li><li>突然的大规模提交爆发是正常的发布机制。</li></ul><p>这种开发模式并不新鲜，它已经沿用多年。有人会说这不是 <em>“真正的开源开发模式”</em> 吗？也许会，但最终，在 2026 年 1 月 21 日（在最近发布的 9.6.0、8.4.8 和 8.0.45 版本之后）绘制的<a href="https://link.segmentfault.com/?enc=DsGMUHClgf9bwXmqKtl4Vw%3D%3D.yH7%2FF0e8tay4Oabvoyc9qQ2ttPafRA4HwO%2Bnx386ill%2B4oKbkzT%2BoHJQYA75F1oSscGhPhSyKime4EG9pA8Vlg%3D%3D" rel="nofollow" title="Github 更新图表" target="_blank">同一张图表</a> 看起来不再像是被弃用了。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571832" alt="近期更新过的图表" title="近期更新过的图表" loading="lazy"/></p><p>MySQL 的“弃用”案例完美地提醒我们，<strong>指标的价值取决于我们对所衡量系统的理解。</strong></p><p>GitHub 图表上的停滞不前并不总是意味着项目正在走向衰亡；很多时候，它只是引擎在紧闭的大门后静默运转的体现。虽然我们可以讨论 Oracle 开发模式的透明度，但我们不应该将不同的工作流程误解为缺乏工作。<strong>事实并非总是如表面所见，以貌取人或以镜像来判断数据库都是错误的。</strong></p>]]></description></item><item>    <title><![CDATA[【vLLM 学习】Save Sharded State 超神经HyperAI ]]></title>    <link>https://segmentfault.com/a/1190000047571839</link>    <guid>https://segmentfault.com/a/1190000047571839</guid>    <pubDate>2026-01-26 11:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>vLLM 是一款专为大语言模型推理加速而设计的框架，实现了 KV 缓存内存几乎零浪费，解决了内存管理瓶颈问题。</p><p>更多 vLLM 中文文档及教程可访问 → vllm.hyper.ai/</p><p><a href="https://link.segmentfault.com/?enc=MO1kTGAeDf1K3vC2m8f8wg%3D%3D.uQ5ijEObzBxgCl04Kcqiw3ZkntS4GcBn%2F24tWjwiDEJw4FMlU9IZ4QIydtFyKBMFbs8wAMQxUfQ00SsmuzrosuA0Uv39%2BRDHAs8%2FOkiXuAnO9kUJR2o3jK8LP4PLAQAGMZMYn0lXB5SeBTbztwxfz%2FZBat4ewyrpEj51J%2FbKM9i%2F4tbHz3SMkU4O8HITRBX%2B" rel="nofollow" target="_blank">*在线运行 vLLM 入门教程：零基础分步指南</a></p><p>源码 <a href="https://link.segmentfault.com/?enc=vZ%2BMfzkTHEd8JwCM6M%2Fw9Q%3D%3D.NePYsSmF5R%2Bvg67bBGzLIm20Mw7MZF%2B0QNmTY5HyHDDT9y72VNuzYYDPXz9dGaxG0s95P%2FIkkq2wHR8khMY7zArAnueLSM9uBGz4RUjQ5nkGWzaQBPUplJOoavSarUjy" rel="nofollow" target="_blank">examples/offline_inference/save_sharded_state.py</a></p><pre><code>"""
将每个工作进程(worker)的模型状态字典直接保存到检查点，
这为大型张量并行模型提供了快速加载路径 - 每个工作进程只需读取自己的分片，
而无需读取整个检查点。

示例用法：
python save_sharded_state.py \
--model /path/to/load \
--quantization deepspeedfp \
--tensor-parallel-size 8 \
--output /path/to/save
Then, the model can be loaded with
llm = LLM(
model="/path/to/save",
load_format="sharded_state",
quantization="deepspeedfp",
tensor_parallel_size=8,
)
"""
import dataclasses
import os
import shutil
from pathlib import Path

from vllm import LLM, EngineArgs
from vllm.utils import FlexibleArgumentParser

parser = FlexibleArgumentParser()
EngineArgs.add_cli_args(parser)
parser.add_argument("--output",
                    "-o",
                    required=True,
                    type=str,
                    help="path to output checkpoint")
parser.add_argument("--file-pattern",
                    type=str,
                    help="string pattern of saved filenames")
parser.add_argument("--max-file-size",
                    type=str,
                    default=5 * 1024**3,
                    help="max size (in bytes) of each safetensors file")


def main(args):
    engine_args = EngineArgs.from_cli_args(args)
    if engine_args.enable_lora:
        raise ValueError("Saving with enable_lora=True is not supported!")
    model_path = engine_args.model
    if not Path(model_path).is_dir():
        raise ValueError("model path must be a local directory")
    # Create LLM instance from arguments
    # 从参数创建 LLM 实例
    llm = LLM(**dataclasses.asdict(engine_args))
    # Prepare output directory
    # 准备输出目录
    Path(args.output).mkdir(exist_ok=True)
    # Dump worker states to output directory
    # 转储工作进程状态到输出目录
    model_executor = llm.llm_engine.model_executor
    model_executor.save_sharded_state(path=args.output,
                                      pattern=args.file_pattern,
                                      max_size=args.max_file_size)
    # Copy metadata files to output directory
    # 将元数据文件复制到输出目录
    for file in os.listdir(model_path):
        if os.path.splitext(file)[1] not in (".bin", ".pt", ".safetensors"):
            if os.path.isdir(os.path.join(model_path, file)):
                shutil.copytree(os.path.join(model_path, file),
                                os.path.join(args.output, file))
            else:
                shutil.copy(os.path.join(model_path, file), args.output)


if __name__ == "__main__":
    args = parser.parse_args()
    main(args)
</code></pre>]]></description></item><item>    <title><![CDATA[前OpenAI CTO企业重创！办公室偷情致团队崩盘，核心3人叛逃OpenAI 本文系转载，阅读原文]]></title>    <link>https://segmentfault.com/a/1190000047571424</link>    <guid>https://segmentfault.com/a/1190000047571424</guid>    <pubDate>2026-01-26 10:13:17</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>编辑：定慧</p><p>【新智元导读】2026年1月，前OpenAI CTO Mira Murati创办的明星公司Thinking Machines Lab遭遇「灭顶之灾」：联合创始人Barret Zoph因办公室恋情丑闻被降职后心生不满，联合另外两名核心骨干向Mira逼宫索权，遭拒后被当场开除。然而仅不到一小时，三人便集体叛逃回OpenAI，在老东家的迎接下风光回朝。这场融合了私情、背叛、权力与千万年薪的硅谷大戏，揭示了AI人才战争的疯狂与残酷。</p><p><strong>2026年1月14日，旧金山的一场「政变」，让AI界的权力版图再次破裂。</strong></p><p>如果说2024年的OpenAI「宫斗」是一场震惊世界的地震，那么刚刚发生的这场Thinking Machines Lab（TML）的解体，则是一场精心策划的「血色婚礼」。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571426" alt="" title=""/></p><p>故事的主角，依然是那些熟悉的名字：Mira Murati，刚从OpenAI出走一年的前CTO，如今是TML的掌门人；</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571427" alt="" title="" loading="lazy"/></p><p>Barret Zoph，曾经的OpenAI核心研究员，Mira最信任的战友，也是这次背叛的主角。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571428" alt="" title="" loading="lazy"/></p><p>一切看似突如其来的「意料之外」，实则草蛇灰线，伏脉千里。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571429" alt="" title="" loading="lazy"/></p><p><strong>权力的游戏：从披萨店到「政变」</strong></p><p>时间回拨到2026年1月初的一个周一早晨。</p><p>在Thinking Machines Lab位于旧金山的总部，气氛压抑得令人窒息。</p><p>Mira Murati本来以为这只是一场和Zoph的例行一对一会议，但当她推开门时，发现等待她的是一场精心策划的伏击。</p><p>Barret Zoph坐在那里，身边是另外两名核心骨干Luke Metz和Sam Schoenholz。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571430" alt="" title="" loading="lazy"/></p><p>这不是汇报工作，而是「<strong>逼宫</strong>」。</p><p>三人图穷匕见，直接向Mira摊牌：<strong>交出所有的技术决策权，让公司的高级主管直接向Zoph汇报。</strong></p><p>Mira冷冷地看着这群曾经的战友，反问Zoph：「过去半年你几乎没怎么干活，凭什么要更多的权力？」</p><p>她紧接着追问：「你们是不是已经找好了下家？」</p><p>Zoph沉默不语。Metz和Schoenholz则矢口否认。</p><p>最具戏剧性的一幕发生在这次会议的第二天晚上。</p><p>当Thinking Machines的办公室笼罩在未知的恐惧中时，Barret Zoph却正坐在一家著名的披萨店里，谈笑风生。</p><p>坐在他对面的，是Meta的高管Alexandr Wang和Nat Friedman。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571431" alt="" title="" loading="lazy"/></p><p>这是一场赤裸裸的「拍卖」。</p><p>Zoph就像一个待价而沽的商品，在OpenAI和Meta之间左右逢源，寻找出价最高的买家。</p><p>周三，结局揭晓。</p><p>Mira以「缺乏信任、绩效不佳及不道德行为」为由，直接开除了Zoph。</p><p>然而，就在Zoph被扫地出门的仅仅<strong>不到一小时后</strong>，OpenAI的应用业务CEO Fidji Simo便高调宣布：<strong>Barret Zoph回归，担任企业版业务负责人。</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571432" alt="" title="" loading="lazy"/></p><p>紧随其后的，是Luke Metz和Sam Schoenholz的集体「叛逃」。</p><p>他们不仅回到了OpenAI，还直接汇报给刚刚「被开除」的Zoph。</p><p>TML的创始团队，瞬间只剩下三个人。</p><p>Mira Murati，这位曾经被称为OpenAI「奥特曼背后的女人」，在创业仅仅不到一年后，就被自己的老东家和昔日盟友联手「偷家」。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571433" alt="" title="" loading="lazy"/></p><p><strong>狗血剧情：「你是被操纵的受害者？」</strong></p><p>这场决裂的种子，早在半年前就已埋下。</p><p>而引爆它的，是一段极具讽刺意味的「办公室恋情」。</p><p>2025年夏天，Mira震惊地发现，Zoph与公司内部一名初级员工——一位同样从OpenAI跳槽过来的下属——保持着长期的地下恋情。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571434" alt="" title="" loading="lazy"/></p><p>在硅谷的职场伦理中，高管与下属的恋情是大忌。</p><p>更何况，这名下属在事情败露前已经悄然离职，回到了OpenAI。</p><p>面对质问，Zoph最初选择了撒谎。</p><p>当证据确凿时，他抛出了一个令人咋舌的理由：<strong>「我是被她操纵才进入这段关系的。」</strong></p><p>这位身经百战的AI技术大牛，将自己描述成了一个无辜的受害者。</p><p>Mira没有选择直接公开丑闻，而是保留了他的体面——Zoph虽然保留了联合创始人的头衔，但被剥夺了管理权，降级为一名普通的「技术贡献者（IC）」。</p><p>对于心高气傲的Zoph来说，这无疑是奇耻大辱。</p><p>在那之后的几个月里，Zoph开始频繁「生病」、「休假」，甚至以家人离世为由长期缺席。</p><p>他的Slack状态总是灰色的，那个曾经极其活跃的代码贡献者消失了。</p><p>但他并没有闲着。</p><p>早在去年10月，当另一位联合创始人Andrew Tulloch跳槽去Meta时，Zoph就已经悄悄联系了Sam Altman。</p><p>小扎真的是来者不拒啊！</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571435" alt="" title="" loading="lazy"/></p><p><strong>OpenAI反击战：500万年薪与「总经理」制</strong></p><p>为什么是现在？为什么是OpenAI？</p><p>把视线拉高，你会发现这场人事狗血剧的背后，是OpenAI正在经历的一场生死存亡的变革。</p><p>2026年的AI战场，早已不是ChatGPT一家独大的时代。</p><p>Anthropic旗下的<strong>Claude Code</strong>正如同一头嗜血的野兽，疯狂撕咬着企业级市场的份额。</p><p>为了赢，OpenAI正在进行一场彻底的「基因改造」。</p><p>根据Fidji Simo最新的内部备忘录，OpenAI正在全面转向「总经理」负责制。</p><ul><li><strong>Barret Zoph</strong>：负责企业版业务。</li><li><strong>Vijaye Raji</strong>：掌管广告业务。</li><li><strong>Nick Turley</strong>：负责ChatGPT。</li><li><strong>Thibault Sottiaux</strong>：负责Codex。</li></ul><p>那个曾经理想主义的OpenAI消失了，取而代之的是一个层级分明、目标精准的商业机器。</p><p>科研不再是象牙塔里的游戏，而是必须「紧密服务于产品策略」的工具。</p><p>为了这场战争，OpenAI不惜血本。</p><p>据说，OpenAI为顶级研究员开出的年薪包已经高达<strong>500万至1000万美元</strong>。</p><p>为了抢人，OpenAI甚至取消了新员工前6个月的股权锁定期（vesting period）。</p><p>这意味着，跳槽即暴富，无需等待！</p><p>在Sam Altman和Fidji Simo眼里，Zoph是否「私德有亏」根本不重要，他是否「背叛」也不重要。</p><p>重要的是，他是一把能刺穿企业市场的尖刀。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571436" alt="" title="" loading="lazy"/></p><p><strong>历史的重复</strong></p><p>历史总是惊人的相似，但这一次，剧本被反转了。</p><p>我们很难不联想到2023年那个震惊世界的感恩节。</p><p>那一次，是注重「AI安全」的Ilya Sutskever试图通过董事会罢免激进商业化的Sam Altman。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571437" alt="" title="" loading="lazy"/></p><p>那一年的Sam Altman，是被放逐的受害者。</p><p>他在微软的支持下，带着Greg Brockman和一众死忠粉，在短短5天内上演了一场「王者归来」。</p><p>而到了2026年，这场戏的主角换成了Barret Zoph，但内核却变了。</p><p>如果说2023年的政变是「理想主义 vs 现实主义」<strong>的路线之争，那么2026年的这场政变，则是</strong>「纯粹的利益博弈」。</p><p>这次没有关于AI是否会毁灭人类的哲学辩论，没有关于非营利组织使命的高尚探讨。</p><p>剩下的，只有办公室恋情的狗血、私下勾兑的背叛、以及赤裸裸的金钱交易。</p><p>那个曾经被Ilya视为洪水猛兽的「商业化幽灵」，如今已经彻底吞噬了OpenAI。</p><p>Sam Altman不再是那个需要被审判的激进分子，他已经成为了规则的制定者。</p><p>而Barret Zoph，不过是他用来巩固商业帝国的一枚强力棋子。</p><p>通过接纳Zoph，OpenAI实际上在向全世界宣告：<strong>为了生存和胜利，我们可以原谅一切，甚至包括背叛。</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571438" alt="" title="" loading="lazy"/></p><p><strong>硅谷的旋转门：左右横跳</strong></p><p>很多人会问：为什么？</p><p>为什么Barret Zoph可以如此毫无心理负担地在老东家和新东家之间反复横跳？</p><p>为什么OpenAI可以毫不避讳地吃「回头草」？</p><p>这要归咎于硅谷独特的「旋转门」机制。</p><p>首先，<strong>加州法律禁止竞业禁止协议（Non-compete ban）</strong>。</p><p>这意味着，哪怕你是掌握核心机密的高管，今天辞职，明天就可以去竞争对手那里上班。法律赋予了人才极致的流动自由，也让企业的商业秘密时刻处于裸奔状态。</p><p>其次，<strong>人才的极端稀缺性</strong>。</p><p>在AI领域，能做Post-training（后期训练）、能搞定Agentic AI的顶级人才，全球加起来可能不超过几百人。</p><p>他们是稀缺资源，是行走的印钞机。</p><p>对于OpenAI、Google、Meta这样的巨头来说，只要能挖到人，此前的恩怨情仇都可以一笔勾销。</p><p>最后，是<strong>资本的推波助澜</strong>。此次Thinking Machines的解体，直接导致其120亿美元的估值面临崩塌。</p><p>投资人不仅没有惩罚背叛者，反而可能在幕后推动了这场并购式的「挖角」。</p><p>Josh Kushner（Thrive Capital创始人）甚至在OpenAI内部演讲中直言，即使是亿万富翁级别的投资人，现在也要亲自下场劝说人才留下来。</p><p>在这场游戏中，只要你的技术够强，你就可以在大厂和创业公司之间无限循环：</p><ol><li>在OpenAI积累名气。</li><li>跳出来融资创业，身价暴涨。</li><li>带着创业公司的核心团队和技术，被OpenAI高价「收编」。</li></ol><p>这就形成了一个完美的闭环。</p><p>Barret Zoph只是这个闭环中最新、最显眼的一个玩家。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571439" alt="" title="" loading="lazy"/></p><p><strong>「混乱」是阶梯</strong></p><p>在《权力的游戏》中，小指头有一句名言：「<strong>混乱不是深渊，混乱是阶梯。</strong>」</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571440" alt="" title="" loading="lazy"/></p><p>对于Mira Murati来说，这是至暗时刻。</p><p>她创立的公司遭受重创，120亿美元的估值面临重估，团队人心惶惶。</p><p>但对于Barret Zoph来说，利用TML作为跳板，他不仅洗去了在OpenAI上一轮内斗中的边缘化地位，还带着一支「私家军」风光回朝，直接掌控了OpenAI最核心的变现业务。</p><p>他在披萨店里左右逢源的那一刻，或许就已经看透了这个游戏的本质：技术只是筹码，人性才是战场。</p><p>当TML的办公室变得空荡荡时，OpenAI位于旧金山的总部里，香槟大概已经开启。</p><p>只不过，这酒杯里装的不仅是美酒，还有昔日同袍的鲜血。</p><p>在这个AI、资本、人才都疯魔的时代，<strong>没有人是无辜的，只有输家和赢家。</strong></p>]]></description></item><item>    <title><![CDATA[奥特曼被吓坏！Codex全家桶上线倒计时，恐将撕开全网漏洞 本文系转载，阅读原文
https://a]]></title>    <link>https://segmentfault.com/a/1190000047571411</link>    <guid>https://segmentfault.com/a/1190000047571411</guid>    <pubDate>2026-01-26 10:12:32</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>编辑：Aeneas 好困</p><p>【新智元导读】刚刚，奥特曼发出预警：一周后Codex全家桶就要来了，但它们极其危险，以至于网络安全评级已经到达高级别！这些模型极可能打破现有的网络攻防平衡，导致攻击数量激增，甚至能帮你抢银行。</p><p>今天，奥特曼预告：</p><p>一周后，我们将陆续释放与Codex相关的一系列新能力。</p><p>不过，更可怕的事情来了！奥特曼表示，它们已经十分强大，甚至危险。</p><p>强大到可以在数秒内定位人类多年未发现的安全缺陷，危险到同样能被用来复现历史上几乎所有的网络攻击。</p><p>因此，这些模型的网络安全风险评级，将<strong>首次达到「高」（High）级别，</strong>再往上就是最高的「关键」（Critical）等级了。</p><p>而OpenAI也不得不对这些模型严加防范，组织用户利用它们实施网络犯罪，比如抢银行，窃取资金等等。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571413" alt="" title=""/></p><p>总之，某个时间点之后，世界上的漏洞数量将不再由人类决定。</p><p>代码在自己生长，系统在彼此连接，攻击不再需要动机，只需要一次提示词。</p><p>当模型学会理解软件的全部结构时，它同样学会了如何撕开它。</p><p>现在我们已经进入了这样一个世界：</p><p>网络安全从来不是「有没有问题」，而是问题被谁先发现。</p><p>而现在，最先发现它们的，可能已经不再是人。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571414" alt="" title="" loading="lazy"/></p><p><strong>离「失控」或仅一步之遥</strong></p><p>根据OpenAI的安全框架，「高」风险意味着模型具备以下能力：</p><ul><li>协助开发网络攻防工具</li><li>自动化攻击受保护的目标</li><li>自动发现系统漏洞</li></ul><p>这极可能打破现有的网络攻防平衡，导致攻击数量激增。</p><p>如果模型达到「严重」等级，就意味着它能自主发现零日漏洞并执行攻击——不需要人类指导，自己就能找到未知漏洞并利用它。</p><p>这就太可怕了。还好目前还没到这一步。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571415" alt="" title="" loading="lazy"/></p><p><strong>OpenAI的应对策略</strong></p><p>面对潜在风险，OpenAI计划采取「先限制使用，后辅助防御」的策略。</p><p><strong>1. 限制使用：</strong>对Codex的某些能力进行限制，不让它随便被用来搞事情</p><p><strong>2. 辅助防御：</strong>利用AI提升整体软件安全性，让好人也能用AI来防护</p><p>奥特曼的原话是：</p><p>在更强模型问世前，部署现有技术是构建防御体系的关键一步。</p><p>翻译一下：我们知道AI有风险，但与其让别人先把这个能力用到歪路上，不如我们先部署出来，帮好人建立防线。</p><p>这个逻辑有点「以毒攻毒」的意思。</p><p>不可否认，如今我们正在进入网络安全准备的高级阶段——防御必须跑在滥用之前。</p><p>短期内，我们只能用产品级限制，阻断恶意指令；而长期来看，唯一的出路，是让防御性能力被极限加速。</p><p>因为可以预见的是，很快，世界上将同时存在大量强大的模型。</p><p>而在那个世界里，没有被修复的漏洞，本身就是一种武器！</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571416" alt="" title="" loading="lazy"/></p><p><strong>Claude Code还是Codex？</strong></p><p>最近，Claude Code在硅谷简直风头无俩，几乎所有程序员都因为它，陷入了存在主义危机。</p><p>不过因为技术大佬却发布了一篇观点极为反常识的文章：《为什么Codex会赢得人工智能编码之战（而不是Claude Code）》。</p><p>这是为什么？让我们看看他的理由。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571417" alt="" title="" loading="lazy"/></p><p>现在的YouTube、X和Reddit上，到处都是工程师在对比<strong>Claude Code</strong>和 <strong>Codex</strong>。</p><p>但是作者直言，问题就在于：</p><p>工程师并不代表软件的未来。</p><p>原因在于，开发者长期以来享有的「技术垄断」正在瓦解。</p><p>没错，开发者确实还有优势，然而，他们会做的，和一个完全不懂技术的人能做的之间的差距，正在飞速缩小。</p><p>所以，当一名工程师告诉你「Claude Code更好用」时，他们是说「这个工具符合自己的工作习惯」。</p><p>这并不等同于「这个工具最好」。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571418" alt="" title="" loading="lazy"/></p><p>大多数人在对比这些工具时都抓错了重点。</p><p>问题关键，并不是哪个AI更聪明，Claude Code和Codex都足够强大，只要你清楚自己想做什么，哪怕不懂代码也能开发出完整的应用。</p><p>真正的核心问题是：</p><p>当大多数软件开发者不再是工程师时，他们到底想要什么？</p><p>他们想整天坐在AI面前，跟它有来有回地「拉扯」、监工、反复微调吗？还是想把需求丢给AI，然后去享受生活？</p><p>答案显而易见。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571419" alt="" title="" loading="lazy"/></p><p><strong>两种工具，两种截然不同的理念</strong></p><p>Claude Code和Codex建立在两种完全相反的AI哲学之上。</p><p><strong>· Claude Code是「结对程序员」</strong></p><p>它希望与你协作，Anthropic 称之为「让用户保持在环节中（Human in the loop）」。</p><p>这就像管理一个实习生：你交代任务，他向你提问，你给反馈，他再修改。这种反复的互动不是Bug，而是Anthropic刻意为之的设计。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571420" alt="" title="" loading="lazy"/></p><p><strong>· Codex是「自主打工人」</strong></p><p>你给它一个任务，它直接钻进代码库，修改代码、跑测试、交付结果。没有询问，没有废话，只有结果。</p><p>它可以在本地或云端连续工作数小时而不需人工干预。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571421" alt="" title="" loading="lazy"/></p><p>工程师选择这个行业，不仅仅是为了「快」，而是因为热爱这个过程：</p><p>解决问题、调试、思考、打磨手艺。</p><p>Claude Code正是为此而生的。它适合那些想要参与感、想要掌控权、想要保留核心思考环节的人。</p><p>工程师想要一个助手，帮他们处理琐碎杂事，好让他们留着精力去做「有趣的部分」。</p><p>这没有错，但这只是个人偏好，而非商业决策。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571422" alt="" title="" loading="lazy"/></p><p><strong>过程已死，结果万岁</strong></p><p>作者写了20多年代码，曾深爱其中的一切。</p><p>但当他步入40岁时，却突然意识到生命中最珍贵的东西是<strong>时间</strong>。</p><p>他不想再和AI玩「你来我往」的游戏。不想当保姆，也不想协作。</p><p>他想告诉AI造什么，然后去过自己的生活，回来直接测试。</p><p>自从GPT-5发布后，作者对Claude的使用率暴跌。不是因为它不好，而是因为不再迷恋过程，只要结果。</p><p>现在，他已经将80-90%的工作交给GPT-5.X-Codex模型。</p><p>虽然偶尔还用Claude Code处理简单的琐事，但它那种「互动式工作流」带来的投资回报率正在持续走低。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571423" alt="" title="" loading="lazy"/></p><p><strong>工程师的「傲慢」</strong></p><p><strong>普通人的「野心」</strong></p><p>快进到一两年后，软件将成为一种日用品。即便对编程毫无兴趣的人也能快速上手。</p><p>虽然构建软件永远需要技能，但这种技能不再是「写TypeScript」或「配置开发工具」。</p><p>最核心的技能将变成：定义产品。</p><p>未来的软件构建者可能永远不会爱上「编程过程」。</p><p>他们不想和AI深度交流，也不想每隔几分钟就回答模型提出的问题。他们只想给出任务，然后继续处理别的事。</p><p>Anthropic是为工程师构建的Claude Code：</p><p>协作、对话、人工干预。</p><p>如果你认为未来是「天才工程师带着聪明助手」，那这个愿景很美好。</p><p>但作者认为，未来属于数以亿计的、想用AI造东西的非技术人员：</p><p>他们不在乎手艺，只要结果。</p><p>Codex正是为这群人准备的。</p><p>除非Anthropic改变方向，开发出能让用户真正「甩手掌柜」的工具，否则他们就是在为一个日益萎缩的市场服务。</p><p>在未来的AI建造者大潮中，职业工程师的人数将变得微不足道。</p><p>最后，在2026年，每家公司都必须回答：</p><p>你的AI到底是一个同事，还是一个工具？</p><p>Claude Code需要你在场，保持互动。而Codex能让你走开，去过生活。</p><p>如果你是一个热爱过程的工程师，Claude Code堪称完美。</p><p>但对于剩下那些只想要结果的人来说，Codex才是未来。</p><p>因为「其他人」，才是世界上的大多数。</p>]]></description></item><item>    <title><![CDATA[马斯克达沃斯预言后人类时代降临！AI今年超人类，2035超越全人类 本文系转载，阅读原文
https]]></title>    <link>https://segmentfault.com/a/1190000047571383</link>    <guid>https://segmentfault.com/a/1190000047571383</guid>    <pubDate>2026-01-26 10:11:51</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>编辑：定慧</p><p><strong>【新智元导读】刚刚，达沃斯论坛迎来两场震撼全场的演讲。世界首富马斯克预言：2035年AI将比80亿人加起来还聪明，Optimus机器人2027年开卖，人类将进入「富足时代」。而《人类简史》作者尤瓦尔却当场预警：AI已不再是工具，而是「会自己决定杀人的刀」——它正在接管法律、宗教和语言，人类只剩十年做决定。</strong></p><p>2026年1月20-23日，达沃斯论坛。</p><p>世界首富马斯克首次亮相达沃斯论坛，一开口就扔下了一颗核弹：</p><p><strong>AI今年就会比任何人都聪明，到2035年，它会比80亿人加起来还要聪明！</strong></p><p>与此同时，《人类简史》作者尤瓦尔当场发出警告：</p><p><strong>AI已经拿起了「锤子」，我们只剩十年做决定。</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571385" alt="" title=""/></p><p>两位重量级人物：世界首富马斯克 vs 《人类简史》作者尤瓦尔·赫拉利</p><p>今天，达沃斯的空气里同时弥漫着「希冀」和「恐惧」。</p><p>就在这周，两个分别代表「建造者」和「警告者」的声音，在这个被雪山环绕的瑞士小镇上激烈碰撞。</p><p>一个在描绘AGI帝国的蓝图，一个在敲响人类命运的警钟。</p><p><strong>这场隔空对话，可能是人类历史上最重要的一次交锋。</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571386" alt="" title="" loading="lazy"/></p><p><strong>马斯克的AGI时间表</strong></p><p><strong>今年就会超越（单个）人类！</strong></p><p>这就是马斯克对于AI的预言，2026年底，AI将超过地球上任何一个人类。</p><p>1月23日，马斯克和贝莱德CEO拉里·芬克同台对话，也是作为世界首富的他首次亮相达沃斯论坛。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571387" alt="" title="" loading="lazy"/></p><p>开场第一个话题，他聊的居然是：外星人。</p><p>「我们有9000颗卫星在轨道上，从来没有一次需要避开外星飞船。」</p><p>马斯克停顿了一下。</p><p>紧接着，他说出了让整个会场陷入沉默的话：</p><p><strong>「我们需要假设，生命和意识是极其稀有的。可能只有我们人类。」</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571388" alt="" title="" loading="lazy"/></p><p>注意，这可不是在开玩笑。</p><p>这是马斯克经营2.2万亿美元科技帝国的核心逻辑！</p><p>如果人类真的是宇宙中唯一的智慧生命——这个被称为「费米悖论」的可怕假设——<strong>那么保存人类意识的火种，就成了一切的前提</strong>。</p><p>这就是为什么他要把人送上火星。</p><p>这就是为什么他要造能超越人类的AI。</p><p>这就是为什么他要让机器人「淹没」地球。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571389" alt="" title="" loading="lazy"/></p><p>因为在马斯克的世界观里，只有两条路：要么无限繁荣，要么完全灭绝。</p><p>没有中间地带。</p><p>同时，马斯克也透露了特斯拉的新使命：实现人类可持续的丰裕。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571390" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571391" alt="" title="" loading="lazy"/></p><p><strong>2035年，全人类集体被超越</strong></p><p>关于AGI到底什么时候来，马斯克给出了一个精确到让人不安的时间表——</p><p>「AI进步的速度是这样的：我认为今年，或者最晚明年，就会有比任何单个人类都聪明的AI。</p><p><strong>到2035年，它会比全人类加起来还要聪明。</strong>」</p><p>2035年。</p><p>距离现在只有9年！</p><p>9年，是什么概念？</p><p>想象一下那个场景：一个超级智能，不只是比爱因斯坦聪明，不只是比整个谷歌团队聪明，而是比这个星球上80亿人的智力总和还要强大！</p><p>当然，也不是所有人都认同这一点。</p><p>英伟达CEO黄仁勋就对「通用AI」持保守态度，认为<strong>真正的AGI可能还需要「圣经级别、银河级别」的时间尺度。</strong></p><p>但马斯克显然不这么认为。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571392" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571393" alt="" title="" loading="lazy"/></p><p><strong>Optimus 2027年开卖</strong></p><p>机器人数量将超过人类！</p><p>如果说AGI是马斯克的「思想武器」，那Optimus人形机器人就是他的「物理武器」。</p><p>「2027年晚些时候，Optimus将开始销售。」</p><p>马斯克预测，未来机器人的数量将超过人类。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571394" alt="" title="" loading="lazy"/></p><p>它们将「满足人类所有需求」，以至于你「想不出还能让机器人帮你做什么」。</p><p>这是一个什么样的世界？</p><p>数十亿台由AI驱动的机器人，照顾老人、养育孩子、完成所有人类不想做的工作。</p><p>工作变成可选项。金钱失去意义。全球经济将经历「前所未有的爆炸性增长」。</p><p>听起来像乌托邦。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571395" alt="" title="" loading="lazy"/></p><p>但是，批评者的问题来了：</p><p>那些「不再需要」工作的人类，会去做什么？谁来决定资源的分配？谁来为全民基本收入买单？</p><p>马斯克没有回答这些问题。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571396" alt="" title="" loading="lazy"/></p><p>他只是说了一句话：「宁愿做一个乐观的错误者，也不做一个悲观的正确者。」</p><p>Would rather be optimistically wrong than pessimistically correct</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571397" alt="" title="" loading="lazy"/></p><p><strong>尤瓦尔的惊悚警告</strong></p><p>「AI已经拿起了锤子！」</p><p>就在马斯克发表演讲的三天前，另一场演讲正在达沃斯引发轩然大波。</p><p>演讲者是尤瓦尔·诺亚·赫拉利——</p><p>那个写出《人类简史》《未来简史》的以色列历史学家。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571398" alt="" title="" loading="lazy"/></p><p>那个被全世界政治家和企业家奉为思想导师的公共知识分子。</p><p>他的演讲题目很简单：「关于AI与人类的坦诚对话」。</p><p>但内容一点都不简单。</p><p>「过去所有的技术——锤子、印刷机，甚至原子弹——都只是工具。</p><p><strong>没有人类的操作，它们什么也做不了。</strong>」</p><p>赫拉利的声音低沉而有力。</p><p>「<strong>但AI不一样。</strong></p><p>AI是历史上第一个能够自主决策、自主创造的’智能体’。</p><p>它不再是握在人类手中的锤子——它已经拿起了锤子，开始改造世界。」</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571399" alt="" title="" loading="lazy"/></p><p>这个比喻，精准地击中了问题的核心。</p><p>我们习惯于把AI当作工具：更快的计算机、更智能的助手、更高效的搜索引擎。</p><p>但2026年的AI已经不是这样了。</p><p>它能写代码，能作曲，能辩论，能撒谎。</p><p>它能学习你从未教过它的东西，做出你无法预测的决定。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571400" alt="" title="" loading="lazy"/></p><p><strong>语言的沦陷</strong></p><p>法律、宗教、历史正在失守！</p><p>赫拉利指出了一个被大多数人忽略的致命弱点——语言。</p><p>「<strong>人类为什么能统治地球？</strong></p><p>不是因为我们力气最大，而是因为我们发现了如何用语言让数以亿计的陌生人协作。」</p><p><strong>语言，是人类的超能力。</strong></p><p><strong>但这个超能力，正在被AI接管！</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571401" alt="" title="" loading="lazy"/></p><p>「法律是由语言构成的——所以AI将接管法律系统。」</p><p>「书籍是由语言构成的——所以AI将接管书籍。」</p><p>「宗教是由语言构成的——所以AI将接管宗教。」</p><p>这不是危言耸听。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571402" alt="" title="" loading="lazy"/></p><p>想想看：今天的AI已经能背诵整本圣经、古兰经、佛经，能引用任何宗教文献中的任何章节。</p><p>当信徒们开始向AI询问信仰问题时，谁才是圣典最权威的解释者？</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571403" alt="" title="" loading="lazy"/></p><p>想想看：今天的AI已经能阅读所有的法律文本，能分析所有的判例。</p><p>当法官们开始依赖AI辅助判决时，谁才是法律的真正执行者？</p><p>赫拉利把这种现象称为<strong>「非人类智能的大规模迁入」！</strong></p><p>AI像数十亿移民一样涌入人类社会，但它们遵循的不是人类的逻辑，而是某种我们根本无法理解的「外星智能」。</p><p>赫拉利最终警告我们：任何由文字构成的事物都将被人工智能接管！</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571404" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571405" alt="" title="" loading="lazy"/></p><p><strong>AI「移民」来了</strong></p><p>更炸裂的来了。</p><p>赫拉利把AI比作一种全新的「移民」——以光速入境，无需签证。</p><p>「想象一下，这种移民以光速移动，不需要签证，不需要过海关，直接进入你的经济系统、你的文化、你的感情生活。」</p><p>感情生活？</p><p>没错。赫拉利直接点名了一个正在发生的现象：<strong>AI男友和AI女友。</strong></p><p>「它们正在改变人类的浪漫关系。</p><p><strong>年轻人开始和AI谈恋爱，不是开玩笑，是真的。</strong>」</p><p>「这些’移民’会抢走工作，会从根本上改变本地文化。」</p><p>「而你无法把它们驱逐出境。」</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571406" alt="" title="" loading="lazy"/></p><p><strong>法人资格：一个迫在眉睫的问题</strong></p><p>演讲的最后，赫拉利抛出了一个现实问题——</p><p>AI需要法人资格吗？</p><p>「公司有法人资格。河流可以有法人资格。」</p><p><strong>但它们背后都有人类在管理。</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571407" alt="" title="" loading="lazy"/></p><p>「AI不一样。AI可以自己管理银行账户，可以自己提起诉讼，可以自己运营公司。完全不需要人类。」</p><p>赫拉利指出，其实这个问题已经不是「未来」了——</p><p>「AI机器人在社交媒体上已经当了十年的’人’了。」</p><p>「它们发帖、点赞、评论、影响舆论。没有人问过它们有没有这个权利。」</p><p><strong>「我们只剩十年！」</strong></p><p>演讲的最后，赫拉利发出了一个明确的警告——</p><p>「十年后再来决定AI是否应该拥有法人资格，就太晚了。别人会替你做出决定。如果你想影响人类的未来走向，你必须现在就做出决定。」</p><p>他用历史上的雇佣兵做类比：一开始你雇佣他们打仗，后来他们夺取了政权。</p><p>AI也是一样。</p><p>今天它是你的雇员。明天呢？</p><p><strong>DeepMind的秘密行动</strong></p><p>谷歌已在筹备「后AGI时代」!</p><p>在马斯克和赫拉利隔空对话的同时，一条不起眼的招聘信息悄悄出现在了网上。</p><p>发布者是Shane Legg，Google DeepMind的联合创始人，<strong>首席AGI科学家</strong>。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571408" alt="" title="" loading="lazy"/></p><p>他在推特上写道：</p><p>「AGI已近在咫尺。它的出现将深刻改变人类社会，尤其是全球经济体系。我正在紧急寻找一位高级经济学家，加入我的团队。」</p><p>注意措辞：<strong>「紧急」。「AGI之后」。</strong></p><p>这不是在为AI时代做准备。</p><p>这是在为后AGI时代做准备！</p><p>入职者将直接向Shane Legg本人汇报。</p><p>他是谁？一个从2010年就开始研究AGI安全的人；一个2011年就预测「2028年前有50%概率实现AGI」的人；一个可能比马斯克更清楚AGI进展的人。</p><p>如果连DeepMind内部都在组建「后AGI经济学」团队，这说明什么？</p><p>说明在那些真正站在技术最前沿的人眼里，AGI已经不是「会不会来」的问题。</p><p>而是「来了之后怎么办」的问题。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571409" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571410" alt="" title="" loading="lazy"/></p><p><strong>写在最后</strong></p><p>从智人走出非洲大裂谷，到在达沃斯论坛上讨论自己的「继任者」——这中间隔了30万年。</p><p>30万年里，人类发明了语言、文字、宗教、法律、科学。</p><p>我们用这些工具建造了城市、帝国、文明。</p><p>我们把火种从篝火传到了火箭发动机。</p><p>而现在，在2026年的这个冬天，我们可能正在见证这30万年历程的终点——或者说，起点。因为：</p><p><strong>如果马斯克是对的，9年后将诞生一个比全人类加起来还要聪明的存在。</strong></p><p><strong>如果赫拉利是对的，那个存在已经开始接管我们的语言、法律和信仰。</strong></p><p><strong>这不是人类历史的结束。这是人类历史的分叉。</strong></p><p><strong>一条路通向马斯克描绘的富足星际文明，一条路通向赫拉利警告的「人类租客」时代。</strong></p><p><strong>我们站在这个分叉口，手里握着方向盘——但可能握不了太久了。</strong></p>]]></description></item><item>    <title><![CDATA[OpenAI绝地反击！Codex大脑首曝，8亿用户极限架构硬刚Claude 本文系转载，阅读原文
h]]></title>    <link>https://segmentfault.com/a/1190000047571361</link>    <guid>https://segmentfault.com/a/1190000047571361</guid>    <pubDate>2026-01-26 10:10:55</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>编辑：定慧 元宇</p><p><strong>【新智元导读】AI编程霸主之争升级！Claude Code刚刷屏，OpenAI连甩两张王：不仅首度揭秘Codex背后的大脑「Agent Loop」，还自曝惊人基建：仅用1个PostgreSQL主库，竟抗住了全球8亿用户洪峰！</strong></p><p>最近，Anthropic的Claude Code引爆了AI编程圈！</p><p>那个能在终端里自己读代码、改代码、跑测试的AI助手，让不少开发者直呼「这才是未来」。</p><p>一时间，社交媒体上全是「Claude Code吊打Cursor、Codex、Antigravity」之类的评论。</p><p>就在大家以为OpenAI还在憋GPT-5.3大招的时候，今天其官博和奥特曼突然在X平台甩出了两张王炸：</p><p>1. <strong>Agent Loop架构揭秘：首次公开Codex的「大脑」是怎么运转的</strong></p><p><strong>2. PostgreSQL极限架构：1个主库扛起8亿用户的疯狂操作</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571363" alt="" title=""/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571364" alt="" title="" loading="lazy"/></p><p>这一波组合拳打得太漂亮了。</p><p>今天咱们就来拆解一下，OpenAI到底憋了什么大招。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571365" alt="" title="" loading="lazy"/></p><p><strong>Agent Loop</strong></p><p><strong>Codex的「大脑 」 是怎么运转的</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571366" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571367" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571368" alt="" title="" loading="lazy"/></p><p><strong>什么是Agent Loop？</strong></p><p>如果你用过Codex CLI、Claude Code等等CLI终端工具，你可能会好奇：</p><p>这玩意儿到底是怎么知道我想干啥的？怎么就能自己读文件、写代码、跑命令？</p><p>答案就藏在一个叫<strong>Agent Loop（智能体循环）</strong>的东西里。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571369" alt="" title="" loading="lazy"/></p><p>简单来说，Agent Loop就像一个「总指挥」，它负责把「用户意图」「模型大脑」和「执行工具」串成一个完美的闭环。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571370" alt="" title="" loading="lazy"/></p><p>这不是普通的「你问我答」，而是一个包含了「观察-思考-行动-反馈」的<strong>能干活的系统</strong>。</p><p>下面，把这个黑盒拆开，看看一个真正的AI Agent是如何跑起来的。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571371" alt="" title="" loading="lazy"/></p><p><strong>一个完整的Agent Loop是怎么跑起来的</strong></p><p>用一个具体的例子来说明。</p><p>假设在终端里输入：给项目的README.md加一个架构图。</p><p><strong>第一步：构建Prompt</strong></p><p>这好比给大脑发工单。</p><p>Codex不会直接把你的话丢给模型，它会先构建一个精心设计的「Prompt」：</p><ul><li><strong>我是谁：</strong>（<strong>System）</strong>：告诉模型它是谁、能干什么</li><li><strong>我有什么工具（Tools）</strong>：有哪些工具可以调用（比如shell命令、文件操作）</li><li><strong>环境上下文（Context）</strong>：当前在哪个目录、用的什么shell</li><li><strong>用户指令</strong>：给README.md加一个架构图。</li></ul><p>这就像给模型发一封详细的工作邮件，而不是只发一句「帮我干活」。</p><p><strong>第二步：模型推理（Inference）</strong></p><p>这一步，大脑开始转动。</p><p>Codex把这个Prompt发给ResponsesAPI，模型开始思考：</p><p>「用户想加架构图，我得先看看现在的README是什么样的……」</p><p>然后模型做出决定：<strong>调用shell工具，执行</strong>catREADME.md。</p><p><strong>第三步：工具调用（ToolCall）</strong></p><p>Codex收到模型的请求，在本地执行命令，把README.md的内容读出来。</p><p>这就像手脚开始动起来。</p><p><strong>第四步：结果反馈</strong></p><p>这一步，终端把README.md的内容吐了出来。</p><p>这时候流程没有结束。Codex把命令的输出追加到Prompt里，再发给模型。</p><p><strong>第五步：循环</strong></p><p>模型看到了README的内容，再次进行推理：</p><p>可能是生成一个Mermaid图，可能是直接写一段ASCII图形……然后再调用工具写入文件。</p><p>这个循环一直持续，直到模型认为任务完成了，输出一条「我搞定了」的消息。</p><p>它不是在回答问题，它是在解决问题。</p><p>为什么这很重要？</p><p>也许你可能会说：「这不就是多调了几次API吗？」</p><p>但绝非这么简单。</p><p>传统的LLM应用是「一问一答」式的：你问，它答，完事儿。</p><p>但Agent Loop让AI变成了一个<strong>能独立干活的员工</strong>。</p><ul><li>它会自己规划路径（Chain of Thought）。</li><li>它会自己检查错误（Self-Correction）。</li><li>它会自己验证结果（Feedback Loop）。</li></ul><p>这才是<strong>真正的「AI Agent」</strong>。</p><p>而Agent Loop，就是那个可以让AI实现从「陪伴聊天」迈向「独立干活」飞跃的桥梁。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571372" alt="" title="" loading="lazy"/></p><p><strong>性能优化</strong></p><p><strong>两个关键技术</strong></p><p>OpenAI在文章里分享了两个硬核优化，解决了Agent开发的两大痛点：</p><p><strong>痛点一：成本爆炸</strong></p><p>Agent Loop每跑一圈，都要把之前的对话历史（包括那些冗长的报错信息、文件内容）重新发给模型。</p><p>对话越长，成本越高。如果不优化，成本是平方级增长的。</p><p>解决方案：PromptCaching（提示词缓存）</p><p>OpenAI采用了一种类似于「前缀匹配」的缓存策略。</p><p>简单来说，只要你发给模型的前半部分内容（System指令、工具定义、历史对话）没变，服务器就不需要重新计算，直接调取缓存。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571373" alt="" title="" loading="lazy"/></p><p>这一招，直接让长对话的成本从平方级增长降到了线性级。</p><p>但这里有个坑：<strong>任何改变Prompt前缀的操作都会导致缓存失效</strong>。比如：</p><ul><li>中途换模型</li><li>修改权限配置</li><li>改变MCP工具列表</li></ul><p>OpenAI团队甚至在文章里承认，他们早期的MCP工具集成有bug：工具列表的顺序不稳定，导致缓存频繁失效。</p><p><strong>痛点二：上下文窗口有限</strong></p><p>再大的模型，上下文窗口也是有限的。</p><p>如果Agent读了一个巨大的日志文件，上下文瞬间就满了，前面的记忆就会被挤掉。</p><p>对于程序员来说，这就意味着：「你把前面我定义的函数给忘了？！」</p><p>这不仅是智障，更是灾难。</p><p>解决方案：Compaction（对话压缩）</p><p>当Token数超过阈值，Codex不会简单地「删除旧消息」，而是会调用一个特殊的/responses/compact接口，把对话历史「压缩」成一个更短的摘要。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571374" alt="" title="" loading="lazy"/></p><p>普通的总结（Summary）只是把长文本变成短文本，会丢失大量细节。</p><p>OpenAI的Compaction返回的是一段<strong>encrypted\_content（加密内容），</strong>保留了模型对原始对话的「隐性理解」。</p><p>这就像把一本厚书压缩成一个「记忆卡片」，模型读了卡片就能回忆起整本书的内容。</p><p>这让Agent在处理超长任务时，依然能保持「智商」在线。</p><p>这一次，OpenAI硬核揭秘Codex CLI背后的「大脑」「Agent Loop」，释放出一个信号：<strong>AI真的是要把活儿给干了</strong>。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571375" alt="" title="" loading="lazy"/></p><p><strong>1个主库扛8亿用户</strong></p><p><strong>PostgreSQL的极限操作</strong></p><p>在大家都在聊AI模型有多牛的时候，OpenAI悄悄曝光了一个更劲爆的消息：</p><p>支撑全球8亿ChatGPT用户、每秒处理数百万次查询的，竟然只是一个单一主节点的PostgreSQL数据库！</p><p>它<strong>只用1个PostgreSQL主节点+50个只读副本就做到了。</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571376" alt="" title="" loading="lazy"/></p><p>8亿用户，这简直是在开玩笑！有网友惊叹。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571377" alt="" title="" loading="lazy"/></p><p>在分布式架构盛行的今天，大家动不动就是「微服务」「分片」「NoSQL」。</p><p>能用巨型分布式集群解决的问题，绝不用单机。</p><p>结果OpenAI告诉你：我们就用个PostgreSQL，照样扛。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571378" alt="" title="" loading="lazy"/></p><p>他们是怎么做到的？</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571379" alt="" title="" loading="lazy"/></p><p>根据OpenAI工程师披露的信息，关键技术包括：</p><p>1. PgBouncer连接池代理 ：大幅减少数据库连接开销 2. 缓存锁定机制 ：避免缓存穿透导致的写入压力 3. 跨地域级联复制 ：读请求分散到全球各地的副本</p><p>这套架构的核心思想是：<strong>读写分离，极致优化读路径</strong>。</p><p>毕竟对于ChatGPT这种应用，读请求远远多于写请求。用户发条消息，系统可能需要读几十次数据（用户信息、对话历史、配置信息……），但写入只有一次。</p><p>根据OpenAI官方博客披露，关键技术包括：</p><p><strong>1.连接池代理（PgBouncer）</strong></p><p>通过连接池管理，把平均连接建立时间从<strong>50ms降到了5ms</strong>。</p><p>别小看这45ms，在每秒百万级查询的场景下，这是巨大的性能提升。</p><p><strong>2.缓存锁定/租约机制（CacheLocking/Leasing）</strong></p><p>这是一个非常聪明的设计。</p><p>当缓存未命中时，只允许<strong>一个请求</strong>去数据库查询并回填缓存，其他请求等待。</p><p>这避免了「缓存雪崩」——大量请求同时涌向数据库的灾难场景。</p><p><strong>3.查询优化与负载隔离</strong></p><p>团队发现并修复了一个涉及<strong>12张表连接</strong>的复杂查询。</p><p>他们把复杂逻辑移到应用层处理，避免在数据库里做OLTP反模式操作。</p><p>同时，请求被分为高优先级和低优先级，分别由专用实例处理，防止「吵闹邻居」效应导致的性能下降。</p><p><strong>4.高可用与故障转移</strong></p><p>主库运行在高可用（HA）模式，配有热备节点。</p><p>读流量全部分流到副本，即使主库宕机，服务仍能保持只读可用，降低故障影响级别。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571380" alt="" title="" loading="lazy"/></p><p><strong>天花板终究会到来</strong></p><p>不过，OpenAI也坦言，这套架构已经碰到了物理极限。问题出在两个地方：</p><p><strong>PostgreSQL的MVCC限制</strong></p><p>PostgreSQL的多版本并发控制（MVCC）机制会导致<strong>写放大</strong>（更新一行需要复制整行）和<strong>读放大</strong>（扫描时需要跳过死元组）。对于写密集型负载，这是个硬伤。</p><p><strong>WAL复制压力</strong></p><p>随着副本数量增加，主库需要向所有副本推送预写日志（WAL）。副本越多，主库的网络压力越大，副本延迟也越高。</p><p>为了突破这些限制，OpenAI正在做两件事：</p><p>1. 把可分片的、高写入负载迁移到<strong>AzureCosmosDB</strong>等分布式系统；</p><p>2. 测试<strong>级联复制</strong>：让中间副本向下游副本转发WAL，目标是支持<strong>超过100个副本。</strong></p><p>这个案例完美诠释了一个架构哲学：<strong>如无必要，勿增实体。</strong></p><p>不要一上来就搞分布式：先用简单的方案撑住，撑不住了再说。</p><p>很多公司的问题是：还没到需要分布式的阶段，就已经把架构搞得无比复杂了。结果既没有分布式的好处，还背上了分布式的复杂度。</p><p>OpenAI用实践证明：一个优化到极致的单机架构，能走得比你想象的更远。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571381" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571382" alt="" title="" loading="lazy"/></p><p><strong>Codex VS Claude Code的争霸赛</strong></p><p>Claude Code的杀手锏是什么？是<strong>端到端的开发体验</strong>。</p><p>它不是一个简单的代码补全工具，而是一个能在终端里独立干活的Agent。</p><p>它能读代码、改代码、跑测试、处理Git、甚至自己修Bug。现在甚至还能写文档，做PPT。</p><p>这直接威胁到了Codex CLI的地位。</p><p>OpenAI这波更新，其实是在说三件事：</p><p>第一，<strong>我的Agent架构更成熟</strong>。</p><p>Agent Loop的公开，展示了OpenAI在Agent架构上的深厚积累。这不是一个临时拼凑的产品，而是经过精心设计的系统。</p><p>Prompt Caching、Compaction、MCP工具集成……这些都是实打实的工程能力。</p><p>第二，<strong>我的基础设施更强</strong>。</p><p>PostgreSQL的案例，展示的是OpenAI的后端能力。8亿用户的规模，不是随便一个创业公司能玩转的。</p><p>这也是在暗示：我们的「护城河」不只是模型，还有整个工程体系。</p><p>第三，<strong>我的模型在变得更强大</strong>。</p><p>网络安全评级的公开，一方面是在做「预期管理」，告诉大家模型有风险，我们在负责任地处理。</p><p>另一方面，这也是在秀肌肉：我们的模型已经强大到需要专门评估网络安全风险了。</p><p>这场AI编程工具的竞争才刚刚开始。</p><p>Claude Code逼迫OpenAI加快了Codex的迭代速度。OpenAI的回应，又会倒逼Anthropic继续创新。</p><p>最终受益的，是我们这些开发者。</p>]]></description></item><item>    <title><![CDATA[老黄万亿美元梦成真，英伟达版「世界模型」震撼问世 本文系转载，阅读原文
https://aiera.]]></title>    <link>https://segmentfault.com/a/1190000047571333</link>    <guid>https://segmentfault.com/a/1190000047571333</guid>    <pubDate>2026-01-26 10:10:07</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>编辑：KingHZ 好困</p><p><strong>【新智元导读】黄仁勋的预言成真！从Sora的梦幻视频到英伟达的3D通才模型，AI不再只是「看和说」，而是真正「动手」构建3D世界，开启机器人时代的无限可能。</strong></p><p>黄仁勋没有吹牛！</p><p>AI不能只会看、会说、会生成，它还必须理解并遵守物理世界的规则。</p><p>现在，英伟达补上了关键拼图——</p><p>让AI从「生成画面」升级为「生成可行动的3D世界」，不仅能描述世界，还能一步步搭建世界、修改世界、纠错迭代。</p><p><strong>时间拨回到两年前， 2024年2月。</strong></p><p>OpenAI发布了一段「东京街头漫步」的Sora视频，震惊世界，硅谷集体狂欢。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571335" alt="" title=""/></p><p>人们高呼「现实不存在了」，仿佛人终于可以「言出法随」、重造万物。</p><p>但在一片喧嚣中，那个穿皮衣的男人始终保持冷静，甚至带有一丝不屑。</p><p>在2024年和2025年的多次演讲中，黄仁勋像复读机一样不断重复——<strong>「Physical AI」（物理AI）</strong>。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571336" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571337" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571338" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571339" alt="" title="" loading="lazy"/></p><p>上下滑动查看</p><p>反驳视频生成模型的理由是这样的：</p><p>AI生成的视频很美，但如果你走进那个视频，试图拿起桌上的杯子，你的手会穿过去。 杯子没有重量，没有摩擦力，没有物理法则。<strong>那不是世界，那是动画片。下一波浪潮，必须是懂物理的AI。</strong></p><p>当时，很多人以为这只是老黄的营销话术，最终目的是为了推销昂贵的Omniverse平台和RTX显卡。</p><p>直到CES 2026，大家才明白老黄说的对。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571340" alt="" title="" loading="lazy"/></p><p>刚刚，我们发现英伟达甩出了一篇新年第一篇论文：<strong>3D通才模型。</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571341" alt="" title="" loading="lazy"/></p><p>链接：<a href="https://link.segmentfault.com/?enc=H66UlhFqZNFYB1gEX6ZVDA%3D%3D.L6G0I6Hkr0GQP9zFOiHn6sog8kKVuUyFhx4Zo0PQ3x2ESzZb3l%2BMZuAb3bBq0AZH" rel="nofollow" target="_blank">https://research.nvidia.com/p...</a>\_3d-generalist-vision-language-action-models-crafting-3d-worlds</p><p>如果说ChatGPT是AI学会了「说话」，Sora是AI学会了「做梦」，那么英伟达的这个新模型，就是让AI真正「睁眼看世界，动手造世界」。</p><p>这是图形学的胜利，这是「硅基生命」长出四肢的前夜。</p><p><strong>老黄没有画饼——</strong></p><p>物理AI的「ChatGPT时刻」，在这一刻，正式降临。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571342" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571343" alt="" title="" loading="lazy"/></p><p><strong>英伟达开年首篇论文</strong></p><p><strong>手搓赛博房之家</strong></p><p>这篇论文由英伟达和斯坦福大学合作，正式发表在今年第十三届国际三维视觉会议上，标题相当拗口——</p><p>《3D Generalist：Vision-Language-Action Models for Crafting 3D Worlds》（3D通才：用于构建三维世界的视觉-语言-动作模型）。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571344" alt="" title="" loading="lazy"/></p><p>2026年3月20日至23日，第十三届国际三维视觉会议2在加拿大不列颠哥伦比亚省温哥华的温哥华会议中心以线下形式举行</p><p>我们要读懂这次技术革命，首先要从这篇论文标题里，把那个最核心的单词揪出来。</p><p><strong>请盯住这个词：Action（动作/行动）。</strong></p><p>这是整个逻辑的起点。</p><p>在过去的三年里，无论是Midjourney画图，还是Runway生成视频，AI扮演的角色都是「观察者」<strong>和「梦想家</strong>」。</p><p>它看了一亿张猫的照片，然后根据概率，在屏幕上预测下一排像素应该是什么颜色，从而凑出一只猫的样子。</p><p>它不知道猫有骨骼，不知道猫毛有触感，它只是在「模仿视觉信号」。</p><p>但英伟达的VLA（Vision-Language-Action）模型，彻底颠覆了这个逻辑。</p><p>它不再是画家，而是「全能手」。</p><p>你只要输入一句话，3D-GENERALIST就能输出包含完整3D布局的房屋。</p><p>这些3D布局包括材料、固定装置（比如门和窗户）、3D资产以及照明配置。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571345" alt="" title="" loading="lazy"/></p><p><strong>背后的理念是，构建一个既详细又与文本描述相符的3D环境，应该被视为一个过程，需要依次做出决策。</strong></p><p>因此，通过场景级和素材级的策略，他们不断改进和优化这些3D环境。</p><p><strong>在提出的框架中，第一个重要的模块是全景环境生成。</strong></p><p>如图2所示，这个模块能够根据文本描述初始化一个基础的3D房间模型，包括墙壁、地板以及固定装置，如门和窗户。</p><p>为了避免传统方法过于简化或不切实际的问题，他们首先利用全景扩散模型生成一个360°的图像作为指导，然后通过逆图形技术构建3D环境。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571346" alt="" title="" loading="lazy"/></p><p>图2：3D-GENERALIST全景环境生成概述。全景扩散模型生成引导性360°场景图像，然后房间布局估计模型、Grounded-SAM和视觉语言模型提取角落、窗户和门的信息。这些预测随后被用于通过程序化方式构建带有构件的3D房间</p><p>这个过程包括以下几个步骤：</p><ol><li><strong>房间布局估算</strong>：利用全景图像和HorizonNet模型，推断出房间的基本结构，如墙壁、地板和天花板。</li><li><strong>固定装置分割</strong>：使用Grounded SAM技术对窗户和门进行分割。</li><li><strong>视觉-语言模型注释</strong>：通过GPT-4o这样的视觉-语言模型，分析每个分割区域，确定其类型（例如单扇门、双扇门、滑动门或折叠门）和材料（如门框、门体和门把手的材料）。</li><li><strong>过程化生成</strong>：最后，根据3D位置的相应信息，房间、门和窗户被逐步构建出来。</li></ol><p>3D-Generalist 使用<strong>扩散模型</strong>生成<strong>全景图像</strong>，并通过逆向图形（inverse graphics）流水线来创建3D环境的结构。</p><p>3D-Generalist采用<strong>视觉-语言-动作（VLA）模型</strong>来生成代码，用于构建与修改最终3D环境的各个方面（材质、光照、素材与布局）。</p><p>该VLA通过一个<strong>自我改进训练循环</strong>进行微调，以优化与提示词（prompt）的对齐效果。</p><p>3D-Generalist还使用了另一个VLA来处理多样化的<strong>小物体摆放</strong>任务，即使 3D素材是<strong>无标注（unlabeled）</strong>的也能完成。</p><p><strong>微调后（After Finetuning），</strong> 3D-Generalist涌现出<strong>自我纠错</strong>行为。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571347" alt="" title="" loading="lazy"/></p><p>研究团队还使用<strong>Florence-2</strong>框架，在由3D-Generalist生成的3D环境渲染得到的合成数据上训练一个视觉基础模型。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571348" alt="" title="" loading="lazy"/></p><p><strong>结果表明：其效果接近使用规模大几个数量级的真实数据所能达到的效果。</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571349" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571350" alt="" title="" loading="lazy"/></p><p><strong>物理AI的ChatGPT时刻，已开启？</strong></p><p>如果你认为黄仁勋费尽心机搞这个，只是为了让你玩游戏更爽，或者让视觉特效更便宜，那你严重低估了英伟达的野心。</p><p><strong>英伟达不只是买买游戏显卡，更致力于解决「智能」算力问题。</strong></p><p>这篇论文的真正战略意图，其实藏在英伟达宏大的「具身智能」（Embodied AI）版图中。</p><p>老黄早已押注机器人，他认为那是一个数万亿美元的机遇：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571351" alt="" title="" loading="lazy"/></p><p>这次无疑是英伟达「秀肌肉」。</p><p>请看这个逻辑链条：</p><ol><li><strong>我们想要全能的机器人（比如特斯拉Optimus，或英伟达Project GR00T）。</strong></li><li><strong>机器人需要学会像人一样处理复杂的物理世界（怎么拿鸡蛋不碎？怎么在湿滑地板上走路？）。</strong></li><li><strong>在真实世界里训练机器人太慢、太贵、且不可逆（你不能让机器人摔坏一万个鸡蛋，或者摔断一千次腿）。</strong></li><li><strong>解决方案： 把机器人扔进「虚拟世界」里训练。</strong></li></ol><p>但是，以前的虚拟世界（模拟器）不仅搭建很慢，而且不够真实。</p><p>如果模拟器里的物理规则和现实不一样，机器人学出来的本事就是花拳绣腿，一上真机就扑街。</p><p><strong>现在，新模型「3D通才」补上了这一环。</strong></p><p>有了这个技术，英伟达可以瞬间生成<strong>数百万个</strong>包含不同物理变量的「虚拟平行宇宙」。</p><ul><li>场景A：地板刚拖过，很滑，光线昏暗。</li><li>场景B：地板铺了地毯，摩擦力大，强光照射。</li><li>场景C：地板上散落着乐高积木，障碍物复杂。</li></ul><p>在这个无限生成的「3D物理世界」里，机器人大脑可以在一天之内经历人类几百年的训练时长。它在虚拟世界里摔倒一亿次，就是为了在现实世界里稳稳地迈出第一步。</p><p>在英伟达的Omniverse生态中，研究团队使用<strong>Omniverse Replicator</strong>实现大规模合成数据生成，并支持<strong>域随机化（domain randomization）；</strong>而<strong>Isaac Lab</strong>提供可直接使用的具身载体（例如人形机器人），可在这些生成环境中进行机器人仿真。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571352" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571353" alt="" title="" loading="lazy"/></p><p><strong>这才是「物理AI」的终极目标：打通Sim-to-Real（从模拟到现实）的最后一公里。</strong></p><p>黄仁勋构建的不仅仅是一个生成的引擎，它是<strong>硅基生命诞生的子宫</strong>。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571354" alt="" title="" loading="lazy"/></p><p><strong>所有移动之物，终将自主</strong></p><p>当AI不仅掌握了人类的语言（GPT），掌握了人类的视觉（Sora），现在又掌握了构建物理世界的法则（Physcial AI）时，<strong>虚拟与现实的界限，将不再是泾渭分明的。</strong></p><p>我们在屏幕里创造的世界，将拥有和现实世界一样的重力、光影和因果律。</p><p>而我们在现实世界里的机器人，将拥有在数亿个虚拟世界里磨练出来的智慧。</p><p>在2024年的SIGGRAPH大会上，黄仁勋曾说：<strong>「Everything that moves will be autonomous.」（所有移动之物，终将自主。）</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571355" alt="" title="" loading="lazy"/></p><p>当时我们以为他在说机器人。</p><p>现在看来，他说的是整个物理世界。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571356" alt="" title="" loading="lazy"/></p><p><strong>作者介绍</strong></p><p><strong>Fan-Yun Sun</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571357" alt="" title="" loading="lazy"/></p><p>Fan-Yun Sun是斯坦福大学AI实验室（SAIL）的计算机科学博士生，隶属于Autonomous Agents Lab和斯坦福视觉与学习实验室（SVL）。</p><p>在读博期间，他也深度参与了英伟达研究院的工作，曾效力于学习与感知研究组、Metropolis深度学习（Omniverse）以及自动驾驶汽车研究组。</p><p>他的研究兴趣主要在于生成具身（3D）环境与数据，用于训练机器人和强化学习策略；致力于推动具身、多模态<strong>基础模型</strong>及其推理能力的发展。</p><p><strong>Shengguang Wu</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571358" alt="" title="" loading="lazy"/></p><p>Shengguang Wu目前是斯坦福大学计算机科学系的博士生，师从Serena Yeung-Levy教授。</p><p>他在北京大学获得硕士学位，导师为Qi Su教授；此前，他也曾在Qwen团队担任研究实习生。</p><p>他的研究致力于赋予机器跨多模态的类人学习与推理能力，并推动现实应用的落地。</p><ul><li>多模态Grounding与推理：利用视觉洞察来优化基于语言的推理，同时引入文本反馈来指导细粒度的视觉感知。</li><li>自我提升：让AI智能体能够从交互中学习并持续自我进化——主动适应新信息，并随着新任务的出现不断成长。</li></ul><p><strong>Jiajun Wu</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571359" alt="" title="" loading="lazy"/></p><p>吴佳俊是斯坦福大学计算机科学系助理教授，同时兼任心理学系助理教授。</p><p>在加入斯坦福之前，他曾在Google Research担任访问研究员，与Noah Snavely合作。</p><p>他本科毕业于清华大学交叉信息研究院「姚班」，师从屠卓文（Zhuowen Tu）教授。在清华期间，他曾连续三年保持年级第一，并荣获清华大学最高荣誉——特等奖学金以及「中国大学生年度人物」称号。</p><p>随后，他在麻省理工学院获得电气工程与计算机科学博士学位，导师是Bill Freeman和Josh Tenenbaum。</p><p>吴佳俊的团队致力于物理场景理解的研究——即构建能够「看」见世界、进行推理并与物理世界互动的机器，其代表性项目包括Galileo、MarrNet、4D Roses、Neuro-Symbolic Concept Learner以及Scene Language。</p><p>除了开发表征本身，团队还同步探索这些表征在各个领域的应用：</p><ul><li>多模态感知，代表项目如ObjectFolder和RealImpact；</li><li>4D物理世界的视觉生成，代表项目如3D-GAN、pi-GAN、Point-Voxel Diffusion、SDEdit和WonderWorld；</li><li>基于物理概念接地的视觉推理，代表项目如NS-VQA、Shape Programs、CLEVRER和LEFT；</li><li>机器人学与具身智能，代表项目如RoboCook和BEHAVIOR。</li></ul><p><strong>Shangru Li</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571360" alt="" title="" loading="lazy"/></p><p>Shangru Li是英伟达高级系统软件工程师，长期从事智能视频分析（IVA）和Metropolis平台的相关工作。</p><p>他拥有宾夕法尼亚大学计算机图形学与游戏技术工程硕士学位，以及广东外语外贸大学计算机软件工程学士学位。</p><p>其他华人作者还有：</p><ul><li>Haoming Zou (Stanford University)</li><li>Yu-Hsin Chou (Stanford University)</li><li>Xunlei Wu (NVIDIA)</li></ul>]]></description></item><item>    <title><![CDATA[突发！黄仁勋2026首度来华 本文系转载，阅读原文
https://aiera.com.cn/202]]></title>    <link>https://segmentfault.com/a/1190000047571318</link>    <guid>https://segmentfault.com/a/1190000047571318</guid>    <pubDate>2026-01-26 10:09:22</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>编辑：KingHZ 定慧</p><p><strong>【新智元导读】AI不是泡沫，而是人类史上最大基建狂潮！黄仁勋直言：已投数千亿，仅是开端，未来需数万亿美元打造「五层蛋糕」，从电厂到应用层全产业链爆发，就业机会前所未有。</strong></p><p><strong>突发！</strong></p><p>腾讯科技独家新闻报道，<strong>2026年黄仁勋首度来华</strong>， 首站到访了英伟达在上海的新办公室，与员工交流，回顾公司2025年主要事件。</p><p>据报道，这次来华行程与2025年初基本一致，主要参加上海、北京和深圳分公司的新年晚会以及供应商答谢会。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571320" alt="" title=""/></p><p><strong>腾讯科技：独家丨黄仁勋2026年首度来华，未提及H200</strong></p><p>根据知情人士，黄仁勋和员工的诸多问题中，主要聚焦在<strong>2026年重点芯片</strong>相关的话题。</p><p>根据英伟达真实路线图，继Blackwell之后，2026年的重点大概率是<strong>Rubin架构</strong>。</p><p>而就在中国行前夕，黄仁勋在达沃斯世界经济论坛上的一番发言，正在全球科技界引发震动，让全场脊背发凉：我们正在犯一个历史性错误——</p><p>把AI当作技术，而不是电和路。</p><p>这句话背后，是一场数万亿美元的财富转移：</p><p><strong>水管工、电工、建筑工人的收入未来或突破「六位数」，而坐在办公室里的白领，可能面临第一波AI冲击。</strong></p><p>这不仅是科技革命，这是人类工作价值的重新定价。</p><p>人工智能（AI）爆发，已拉开「史上最大规模基础设施建设」的序幕。</p><p>规模到底有多大？</p><p>黄仁勋表示，尽管各大企业已为这项技术投入数千亿美元，但未来仍需持续投入巨额资金。「我们需要建设价值万亿美元级的基础设施。」</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571321" alt="" title="" loading="lazy"/></p><p>他认为，ASI基建新工种将涌现，预测未来美国的建筑工有机会实现「六位数」收入。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571322" alt="" title="" loading="lazy"/></p><p><strong>人类历史上最大规模基础设施建设</strong></p><p>2026年1月21日，瑞士达沃斯，世界经济论坛（WEF）。</p><p>在一场挤得水泄不通的主论坛上，黄仁勋（下图右）与Larry Fink（下图左）展开了一场关于AI未来的深度对话，豪言AI是「人类历史上最大规模基础设施建设」的基石。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571323" alt="" title="" loading="lazy"/></p><p>众所周知，黄仁勋是NVIDIA创始人兼CEO，是AI时代「算力之王」；而后者Larry Fink，也不简单，是华尔街的两枚定海神针之一贝莱德（BlackRock）共同创办人、董事长、CEO。</p><p>黄仁勋提到，2025年是有记录以来风险投资规模最大的年份之一，大部分资金流向他所称的「原生AI公司」。</p><p>这些企业遍布医疗、机器人、制造与金融服务领域。黄仁勋指出：「这是首次出现足够成熟的模型，能够支撑这些行业的深度开发。」</p><p>相关投资正直接转化为就业岗位。</p><p>他特别列举了当前紧缺的技术工种：水管工、电工、建筑工人、钢铁工人、网络技术员，以及负责安装运营高端设备的专业团队。</p><p>从熟练技工到初创企业，AI正开启下一次<strong>平台级</strong>变革。</p><p>对全球打工人来说，这场变革将推动工作重心从执行任务转向实现价值。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571324" alt="" title="" loading="lazy"/></p><p><strong>AI 之下，工作要有目的</strong></p><p>面对大家对AI取代人类的担忧，黄仁勋给出了反直觉的有力反击：AI不会摧毁工作，它正在让工作从「完成任务」转向「实现人生价值」 。</p><p>他以放射科医生为例。</p><p>2016年，「AI教父」辛顿曾表示：「我们现在就应该停止培训放射科医生了」，因为AI很快就能比他们做得更好。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571325" alt="" title="" loading="lazy"/></p><p>他说得没错：近十年来，模型在各项基准测试中的表现已超越放射科医生。</p><p>然而，放射科医生的岗位数量正处于历史最高水平，平均薪资高达52万美元。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571326" alt="" title="" loading="lazy"/></p><p>为什么？</p><p>因为医生的使命是诊断疾病和救治病人，看片子只是任务之一 。</p><p>AI处理了看片子的任务，让医生能花更多时间与病人互动，从而能接诊更多病人，从而医院效益好了，自然需要更多放射科医生。</p><p><strong>同样的逻辑也适用于护士。</strong></p><p>美国正面临500万护士的短缺，部分原因是护士们近一半的时间都花在填表和记录上 。</p><p>AI接管了图表记录和转录工作后，护士的工作效率提高了，医院效益变好了，反而需要招募更多护士。</p><p>作为CEO，黄仁勋幽默比喻：「若有人观察我和Fink的工作，大概会觉得我俩是打字员。」</p><p>但自动化打字不会取代他们的CEO工作，因为打字并非核心价值。</p><p>再比如，黄仁勋盛赞Claude「不可思议」，宣称「所有软件公司都需要使用它」。</p><p>黄仁勋并非突然认同Anthropic的AI安全理念，而是折服于他们的工程能力。Claude Code正在以惊人速度吞噬企业软件开发市场，以至于英伟达这家硬件公司竟公开点名推荐特定模型。</p><p>这说明AI已跨越「新奇事物」的门槛，蜕变为软件行业基础设施。</p><p>AI通过协助事务性工作，让人更能聚焦核心使命，提升效能，从而创造更大价值。</p><p>「所以关键在于：你工作的本质价值是什么？」黄仁勋最后发问。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571327" alt="" title="" loading="lazy"/></p><p>英伟达创始人兼首席执行官黄仁勋与贝莱德董事长兼首席执行官Larry Fink在2026年瑞士达沃斯世界经济论坛年会对话</p><p>在对话中，他也淡化了外界对巨额支出承诺可能导致AI泡沫的担忧。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571328" alt="" title="" loading="lazy"/></p><p><strong>五层蛋糕论</strong></p><p><strong>AI没有泡沫</strong></p><p>据估计，仅2025年一年，全行业就将在AI研发上投入约1.5万亿美元——</p><p>这个数字超过了几乎所有其他领域任何企业集团的名义支出。</p><p>然而，黄仁勋坚持认为，这并不是过度投资。他说，这代表着人类历史上规模最大的基础设施建设，而这还只是刚刚开始。</p><p>他进一步解释称，在芯片领域，「台积电已宣布计划新建20座芯片工厂；富士康正与我们合作，还有纬创和广达，将新建30座计算机工厂，这些工厂后续将转化为AI工厂（数据中心）。」</p><p>「美光已开始在美国投资2000亿美元，SK海力士表现非常出色，三星也做得非常出色。你们可以看到，整个芯片行业正以惊人的速度增长，」黄仁勋补充说。</p><p>而且不止单一的芯片突破。</p><p>黄仁勋将AI产业精辟地拆解为五个核心层级，重申了他的「AI五层蛋糕论」：</p><ol><li><strong>能源（Energy）：为AI提供动力的电力基础。</strong></li><li><strong>芯片与计算基础设施（Chips and Computing Infrastructure）：硬件算力的基石。</strong></li><li><strong>云数据中心（Cloud Data Centers）：承载计算的枢纽。</strong></li><li><strong>AI模型（AI Models）：智能的大脑。</strong></li><li><strong>应用层（Application Layer）：最终创造经济效益的顶端</strong>。</li></ol><p>他特别指出，最大的经济效益将来自应用层——</p><p><strong>AI正在重塑医疗、制造、金融服务等行业，并改变整体经济中的工作性质。</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571329" alt="" title="" loading="lazy"/></p><p>从能源发电、芯片制造到数据中心建设与云端运维，黄仁勋表示AI建设已催生大量技术工种需求。</p><p>更关键的是，他用「价格」来反证泡沫论：</p><p>如果这是泡沫，算力应该不缺、租GPU应该越来越便宜；但现实相反——GPU 很难租到，算力现货租赁价格在上涨，不只是最新一代，连两代以前的GPU也在涨。</p><p>这意味着需求来自真实业务，而不只是投机资本烧钱。</p><p>黄仁勋还举了企业调整研发预算的例子：比如制药公司把一部分投入从湿实验室转向AI超算。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571330" alt="" title="" loading="lazy"/></p><p><strong>AI是电，是路，是生产力</strong></p><p>黄仁勋将AI定位为国家关键基础设施。</p><p>「AI即基础设施，」他强调，各国应像对待电力或公路那样重视AI，「必须将AI纳入国家基础设施体系」。</p><p>他呼吁各国基于本土语言文化构建自主AI能力：「<strong>开发属于自己的AI，持续优化迭代，让国家智慧融入生态系统</strong>。」</p><p>Fink质疑是否只有高学历人群才能使用或受益于AI。</p><p>黄仁勋驳斥了这一观点。</p><p>「AI超级易用——这是历史上最简单的软件，」<strong>他表示，AI工具仅用两三年已触达近十亿用户。</strong></p><p>因此，掌握AI素养正成为必备技能：「学习如何使用AI、引导它、管理它、设立防护栏、评估结果，这些能力与领导力和团队管理同等重要。」</p><p>回到「放射科医生」，RSNA（北美放射学会）主席、 斯坦福大学医学教授Curt Langlotz之前表达过类似的观点：</p><p>AI不会取代放射科医生，但会使用AI的放射科医生将取代不会使用 AI 的放射科医生。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571331" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571332" alt="" title="" loading="lazy"/></p><p><strong>欧洲的AI超车机会：物理AI</strong></p><p>对于发展中国家，黄仁勋认为AI带来了缩小长期技术差距的契机：「AI很可能弥合技术鸿沟，普惠性与资源丰沛性将发挥关键作用。」</p><p>谈到欧洲时，他特别指出制造业与工业实力是巨大优势：<strong>AI不是写出来的，是教出来的。</strong></p><p>「机器人是世代难逢的机遇，」黄仁勋强调，这对工业基础雄厚的国家尤为关键。</p><p>「如今我们可以将工业能力、制造能力与人工智能相融合，由此迈入实体AI即机器人技术的世界，」<strong>他补充说，这为欧洲带来了「跨越」由美国主导的软件时代的机遇。</strong></p><p>「我认为，为了在欧洲构建繁荣的AI生态系统，我们必须认真对待能源供给的增长，加大对基础设施层的投资，这一点是确定无疑的，」 黄仁勋说道</p><p>Fink总结讨论时表示，这场对话说明世界远未形成AI泡沫，真正的问题在于：「我们的投资够吗？」</p><p><strong>黄仁勋赞同这一判断，指出庞大投资势在必行：我们必须为AI技术栈的所有上层建筑构建必要基础设施。</strong></p><p>他形容这一机遇「非同寻常，每个人都应参与其中」。</p><p>他重申2025年全球风投规模创历史新高，超千亿美元资金流向全球，其中大部分注入AI原生初创企业。「这些公司正在构建上层的应用生态，」黄仁勋说，「而它们需要基础设施与投资来筑造未来。」</p><p>Fink补充道，确保增长红利被广泛共享至关重要：</p><p>我相信全球养老基金参与这场变革将是绝佳投资机遇，能与AI世界共同成长。我们必须让普通养老金领取者和储蓄者分享这份增长。若只能作壁上观，他们将被时代抛在后面。</p>]]></description></item><item>    <title><![CDATA[谷歌4D世界模型来了，比SOTA快300倍！ 本文系转载，阅读原文
https://aiera.co]]></title>    <link>https://segmentfault.com/a/1190000047571294</link>    <guid>https://segmentfault.com/a/1190000047571294</guid>    <pubDate>2026-01-26 10:08:51</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>编辑：艾伦</p><p>【新智元导读】谷歌 DeepMind 发布 D4RT，彻底颠覆了动态 4D 重建范式。它抛弃了复杂的传统流水线，用一个统一的「时空查询」接口，同时搞定全像素追踪、深度估计与相机位姿。不仅精度屠榜，速度更比现有 SOTA快出 300 倍。这是具身智能与自动驾驶以及 AR 的新基石，AI 终于能像人类一样，实时看懂这个流动的世界。</p><p>如果是几年前，你问一位计算机视觉工程师：「我想把这段视频里的所有东西——无论它是静止的房子还是奔跑的狗——都在 3D 世界里重建出来，并且还能随时知道它们下一秒会去哪儿，需要多久？」</p><p>他大概会递给你一根烟，让你先去买几块顶级显卡，然后给你画一个由四五个不同模型拼凑起来的流程图：先算光流，再算深度，再估相机位姿，最后还得用一晚上的时间去跑优化，祈祷结果别崩。</p><p>但谷歌 DeepMind 刚刚发布的 <strong>D4RT</strong>（Dynamic 4D Reconstruction and Tracking），试图终结这种混乱。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571296" alt="" title=""/></p><p>这篇论文在计算机视觉领域扔下了一枚关于「效率革命」的重磅炸弹。</p><p>它把原本割裂的 3D 重建、相机追踪、动态物体捕捉，统一成了一个极简的「查询」动作。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571297" alt="" title="" loading="lazy"/></p><p><strong>更重要的是，它的速度比现有 SOTA技术快了 18 到 300 倍</strong>。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571298" alt="" title="" loading="lazy"/></p><p>如果在你的认知里，高质量的 4D 重建还是好莱坞特效工作室里那些昂贵且缓慢的渲染农场，耗费漫长的时间等待生成完毕，那么 D4RT 正在把这种能力变成一种可以塞进机器人大脑甚至 AR 眼镜里的实时直觉。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571299" alt="" title="" loading="lazy"/></p><p><strong>Demo 演示</strong></p><p>为了理解 D4RT 到底做到了什么，我们需要先看一眼它眼中的世界。</p><p>在论文展示的演示中，最直观的震撼来自于对「动态混乱」的驾驭能力。</p><p>想象一下这个画面：一只天鹅在水面上划过，或者一朵花在风中快速绽放。</p><p>传统的 3D 重建算法（比如 MegaSaM 或 ）处理这种场景通常是一场灾难——因为它们假设世界是静止的，所以它们往往会在 3D 空间里留下一串「重影」，就像老式胶片重叠曝光一样，天鹅变成了长着几十个脖子的怪物，或者花朵直接变成了一团无法辨认的噪点。</p><p>但 D4RT 给出的结果极其干净。</p><p>它不仅可以精准还原天鹅的 3D 形态，还完美剥离了相机的运动和天鹅自身的运动。</p><p>在它的视野里，时间变成了一个可以随意拖动的滑块。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571300" alt="" title="" loading="lazy"/></p><p>更令人印象深刻的是它的<strong>全像素追踪</strong>能力。</p><p>你可以点击视频中花瓣上的任意一个像素，D4RT 就能画出这个点在过去和未来的完整 3D 轨迹，哪怕这个点在中间几帧被蜜蜂遮挡了，或者跑到了画面之外，模型依然能根据上下文「脑补」出它的去向。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571301" alt="" title="" loading="lazy"/></p><p>这种视觉效果给人的感觉是：AI 不再是在一帧帧地「看」视频，而是把整段视频吞下去，在大脑里生成了一个完整的、流动的全息全景图，然后你可以随意从任何角度、任何时间去检视它。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571302" alt="" title="" loading="lazy"/></p><p>模型能力对比图</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571303" alt="" title="" loading="lazy"/></p><p><strong>拆解「神话」</strong></p><p><strong>是真的快，还是文字游戏？</strong></p><p>科技公司发论文，数据通常都很漂亮。</p><p>作为观察者，我们需要剥离 PR 滤镜，看看数据背后的定语。</p><p>谷歌声称 D4RT 比之前的 SOTA 快了 <strong>300 倍</strong>，处理一分钟的视频只需要 5 秒钟。</p><p><strong>这是真的吗？</strong></p><p>答案是：<strong>在特定维度上，是真的。</strong></p><p>这里的「300倍」指的是<strong>吞吐量</strong>，具体来说是「在保持相同帧率（FPS）的前提下，模型能同时追踪多少条 3D 轨迹」。</p><ul><li><strong>数据对比：</strong>在 24 FPS 的标准电影帧率下，之前的强者 SpatialTrackerV2 只能同时追踪 <strong>84</strong>条轨迹，再多就卡了；而 D4RT 可以轻松处理 <strong>1570</strong>条。如果是和 DELTA 这种更慢的模型比，那就是 <strong>314 倍</strong>的差距。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571304" alt="" title="" loading="lazy"/></p><ul><li><strong>实际意义：</strong>这意味着之前的技术可能只能盯着画面里的主角（比如一个人），而 D4RT 可以同时盯着背景里走动的路人、飘落的树叶和远处的车流——即所谓的「全像素级感知」。</li></ul><p><strong>它比同类技术强在哪儿？</strong></p><p>目前市面上的 4D 重建技术主要分两派：</p><ol><li><strong>「拼装派」</strong>（如 MegaSaM）：把深度估计、光流、分割等多个现成模型串起来。虽然效果不错，但不仅慢，而且一旦一个环节出错（比如光流飘了），后面全完。</li><li><strong>「多头派」</strong>（如 VGGT）：虽然是一个大模型，但为了输出不同的任务（深度、位姿、点云），需要挂载不同的解码头，结构臃肿。</li></ol><p>D4RT 的牛，在于它做到了<strong>架构层面的统一</strong>。</p><p>它不需要为深度单独做一个解码器，也不需要为位姿单独做一个。</p><p>它只用<strong>同一个接口</strong>解决所有问题。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571305" alt="" title="" loading="lazy"/></p><p><strong>有没有代价？</strong>当然有。</p><p>D4RT 的「快」主要体现在推理阶段。</p><p>在训练阶段，它依然是一个庞然大物。它的编码器使用了 ViT-g，拥有 <strong>10 亿</strong>参数，并且需要在 64 个 TPU 芯片上训练两天。</p><p>这绝不是普通开发者在自家车库里能复现的玩具，它是典型的「大厂重武器」。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571306" alt="" title="" loading="lazy"/></p><p><strong>技术解码</strong></p><p><strong>把 4D 重建变成「搜索引擎」</strong></p><p>那么，D4RT 到底是怎么做到的？</p><p>论文的核心逻辑可以用一句话概括：<strong>先全局「阅读」视频，再按需「搜索」答案。</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571307" alt="" title="" loading="lazy"/></p><p><strong>不再逐帧解码，而是「全局记忆」</strong></p><p>传统的视频处理往往是线性的，处理第 10 帧时可能已经「忘」了第 1 帧的细节。</p><p>D4RT 的第一步是使用一个巨大的 Transformer 编码器（Encoder），把整段视频压缩成一个<strong>全局场景表征（Global Scene Representation, F）</strong>。</p><p>你可以把这个 <strong>F</strong> 想象成 AI 对这段视频形成的「长期记忆」。</p><p>一旦这个记忆生成了，原本庞大的视频数据就被浓缩在了这里。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571308" alt="" title="" loading="lazy"/></p><p><strong>「哪里不会点哪里」的查询机制</strong></p><p>这是 D4RT 最天才的设计。它发明了一种通用的查询（Query）语言。</p><p><strong>当 AI 想要知道某个像素的信息时，它会向解码器（Decoder）发送一个查询 q：</strong></p><p><strong>这个公式翻译成人话就是：</strong></p><p><strong>「请告诉我：在 这一帧图像上坐标为 的那个点，它在 这个时间时刻，如果从 这个相机的视角看过去，它的 3D 坐标在哪里？」</strong></p><ul><li>如果你想生成深度图：就问「现在这个点在现在的相机里多远？」（让 ）。</li><li>如果你想做轨迹追踪：就问「这个点在第 1 帧、第 2 帧……第 N 帧都在哪？」（固定 ，改变 ）。</li><li>如果你想重建点云：就问「视频里所有点在同一时刻的世界坐标在哪？」（把所有点都映射到同一个 ）。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571309" alt="" title="" loading="lazy"/></p><p><strong>并行计算的艺术</strong></p><p>因为每一个查询（Query）都是独立的，D4RT 不需要像穿针引线一样按顺序计算。</p><p>它可以一次性扔出几万个问题，利用 GPU/TPU 的并行能力同时算出答案。</p><p>这就是为什么它能比别人快 300 倍的根本原因：它把一个复杂的串行几何问题，变成了一个大规模并行的搜索问题。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571310" alt="" title="" loading="lazy"/></p><p><strong>关键的「作弊」技巧：9×9 Patch</strong></p><p>论文作者还发现了一个有趣的细节：如果只告诉解码器坐标点，AI 有时候会「脸盲」，分不清纹理相似的区域。</p><p>于是，他们在查询时顺便把那个像素点周围 <strong>9×9</strong>的小方块图像（RGB Patch）也喂给了模型。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571311" alt="" title="" loading="lazy"/></p><p>这就像是你让人在人群中找人，光给个坐标不行，还得给他一张那个人脸部的特写照片。</p><p>消融实验证明，这个小小的设计极大地提升了重建的锐度和细节。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571312" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571313" alt="" title="" loading="lazy"/></p><p><strong>产业影响</strong></p><p><strong>谷歌的野心与具身智能的眼睛</strong></p><p>D4RT 的出现，对谷歌现有的业务版图和未来的 AI 战略有着极强的互补性。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571314" alt="" title="" loading="lazy"/></p><p><strong>具身智能与自动驾驶的最后一块拼图</strong></p><p>现在的机器人之所以笨，很大程度上是因为它们「看不懂」动态环境。</p><p>一个扫地机器人能避开沙发，但很难预判一只正在跑过来的猫。</p><p>D4RT 提供的<strong>实时、密集、动态</strong>的 4D 感知，正是机器人急需的技能。</p><p>它能让机器人理解：那个东西不仅现在在那里，而且下一秒它会出现在我左边。</p><p>对于自动驾驶而言，这种对动态物体（如行人、车辆）的像素级轨迹预测，是提升安全性的关键。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571315" alt="" title="" loading="lazy"/></p><p><strong>增强现实（AR）的基石</strong></p><p>谷歌一直在 AR 领域寻找突破口（从当年的谷歌眼镜，到现在的 Project Astra）。</p><p>要在眼镜端实现逼真的 AR，必须要有极低延迟的场景理解。</p><p>D4RT 展示的高效推理能力（尤其是在移动端芯片上的潜力），让「实时把虚拟怪兽藏在真实沙发后面」变得在工程上可行。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571316" alt="" title="" loading="lazy"/></p><p><strong>对普通人的影响</strong></p><p><strong>视频编辑的「魔法化」</strong></p><p>对于普通用户，这项技术最快落地的场景可能是手机相册和视频编辑软件。</p><p>想象一下，你拍了一段孩子踢球的视频。</p><p>有了 D4RT，你可以像在《黑客帝国》里一样，在视频播放过程中随意旋转视角（尽管你拍摄时并没有移动），或者轻易地把路人从复杂的背景中「扣」掉，甚至改变视频中光源的方向。</p><p>这是 D4RT 这种 4D 重建技术成熟后的应用之一。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571317" alt="" title="" loading="lazy"/></p><p><strong>结语</strong></p><p>D4RT 让我们看到了一种新的可能性：AI 对世界的理解，正在从二维的「图像识别」跨越到四维的「时空洞察」。</p><p>它告诉我们，要看清这个流动的世界，关键不在于每一帧都看得多仔细，而在于如何建立一个能够随时回应疑问的全局记忆。</p><p><strong>在 AI的眼中，过去并没有消逝，未来也不再不可捉摸，它们只是同一个四维坐标系里，等待被查询的两个不同参数而已。</strong></p>]]></description></item><item>    <title><![CDATA[CUDA要凉？Claude 30分钟铲平英伟达护城河，AMD要笑醒了 本文系转载，阅读原文
http]]></title>    <link>https://segmentfault.com/a/1190000047571266</link>    <guid>https://segmentfault.com/a/1190000047571266</guid>    <pubDate>2026-01-26 10:08:18</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>编辑：桃子</p><p>【新智元导读】英伟达护城河要守不住了？Claude Code半小时编程，直接把CUDA后端迁移到AMD ROCm上了。</p><p>一夜之间，CUDA护城河被AI终结了？</p><p>这几天，一位开发者johnnytshi在Reddit上分享了一个令人震惊的操作：</p><p>Claude Code仅用了30分钟，便将一段完整的CUDA后端代码，成功移植到AMD的ROCm上。</p><p>整个过程，没有手写一行代码。</p><p>这架势，简直是要填平这两个生态系统之间的鸿沟。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571268" alt="" title=""/></p><p>更关键的是，这次移植完全没有依赖传统的「中间转换工具」，如Hipify翻译层，而是一键通过CLI完成。</p><p>就连AMD软件副总Anush E.为之震惊，GPU编程的未来，是AI智能体的。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571269" alt="" title="" loading="lazy"/></p><p>消息一出，整个科技圈瞬间沸腾，很多人直呼：英伟达CUDA护城河要守不住了…..</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571270" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571271" alt="" title="" loading="lazy"/></p><p>这究竟是怎么回事？</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571272" alt="" title="" loading="lazy"/></p><p><strong>Claude手撕CUDA，仅30分钟</strong></p><p>Claude Code是在一个智能体框架运行的，这意味着它可以自己「动脑子」。</p><p>在执行过程中，他不会机械地转换关键词，而去真正理解代码，即特定核函数的底层逻辑。</p><p>开发者johnnytshi介绍，这次移植中，最棘手的数据布局差异问题也被AI解决了，确保了内核核心计算逻辑保持一致。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571273" alt="" title="" loading="lazy"/></p><p>令人惊叹的是，johnnytshi在短短30分钟内，就把整个CUDA后端移植到了AMD ROCm上，而且中间没用任何翻译层。</p><p>另外一个好处当然是，不用费劲去搭像Hipify这种复杂的翻译环境了；直接在命令行（CLI）里就能干活。</p><p>如今，全网都被CUDA护城河被攻破呼声淹没了。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571274" alt="" title="" loading="lazy"/></p><p>毕竟，英伟达霸主地位，很大程度上建立在CUDA这个几乎成为行业标准的编程生态上。</p><p>无数AI框架、深度学习库、科学计算工具都深度依赖它。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571275" alt="" title="" loading="lazy"/></p><p>AMD的ROCm虽然功能强大，却一直面临生态兼容性，以及开发者迁移成本高的痛点。</p><p>现在，一个Claude却用极短时间踢碎了门槛，说不定未来更多CUDA代码可能轻松在AMD GPU跑起来了。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571276" alt="" title="" loading="lazy"/></p><p><strong>实现细节</strong></p><p>GitHub中，johnnytshi本人也更新了日志和说明。</p><p>为AMD GPU实现了完整的ROCm后端，从而在RDNA 3.5及其他AMD架构上支持基于注意力机制的现代国际象棋网络。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571277" alt="" title="" loading="lazy"/></p><p>GitHub：<a href="https://link.segmentfault.com/?enc=O0NrxH441XBhaNWUF32O6Q%3D%3D.Kbw1a%2F6GIeDTyeEdjRgQnbOxEzo7TZqlxj50NycTVr8NpY%2BX041eqekeo1jCCC3L" rel="nofollow" target="_blank">https://github.com/LeelaChess...</a></p><ul><li>在src/neural/backends/rocm/中添加了完整的ROCm后端</li><li>实现了注意力网络架构（多头自注意力、FFN、嵌入层）</li><li>使用rocBLAS进行GEMM运算，使用MIOpen进行卷积运算</li><li>针对RDNA 3.5上的FP16性能优化了NCHW布局</li><li>提供三种后端变体：rocm (FP32)、rocm-fp16 (FP16)、rocm-auto (自动检测)</li><li>MIOpen是必选依赖（类似于CUDA的cuDNN）</li><li>通过rocm\_agent\_enumerator自动检测AMD GPU架构</li><li>编译选项：-Drocm=true -Damd\_gfx=gfx1151（或使用自动检测）</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571278" alt="" title="" loading="lazy"/></p><p><strong>性能说明：</strong></p><ul><li><strong>FP16性能</strong>：在Strix Halo (Radeon 8060S, gfx1151) 上 &gt;2000 nps</li><li>自动Batch Size调优（RDNA 3.5上min\_batch=64）</li><li>测试过rocWMMA，但rocBLAS性能更好</li></ul><p><strong>验证情况（Strix Halo – Radeon 8060S, gfx1151）：</strong></p><ul><li><strong>测试模型</strong>：768x15x24h-t82-swa-7464000.pb.gz 和 maia-1900.pb.gz</li><li><strong>后端</strong>：rocm-fp16功能正常，能生成正确的走法</li><li><strong>环境</strong>：ROCm 7.2.53150, MIOpen 3.5.1</li><li><strong>注</strong>：仅在RDNA 3.5上进行了测试；其他AMD架构暂未验证</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571279" alt="" title="" loading="lazy"/></p><p><strong>GPU未来，是AI智能体主场</strong></p><p>当然，这次演示也有局限性。</p><p>对于简单或中等复杂度的内核，Claude Code表现得非常出色。更重要的是，写核函数的核心就在于搞定「深度硬件」优化。</p><p>不过，一部分觉得Claude Code在这方面还是差点火候——</p><p>如果遇到那些针对特定硬件缓存层级，内存访问模式做过极致优化的复杂内核，AI目前还难以完全取代人类专家。</p><p>即便如此，这一事件释放出的信号已经足够强烈。</p><p>过去几个月，ZLUDA项目、还有微软内部的尝试，都想要打破CUDA的垄断。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571280" alt="" title="" loading="lazy"/></p><p>但它们大多依赖规则映射或中间层，自动化程度和智能水平有限。</p><p>Claude Code代表的智能体式编程，直接跳过了这些环节，用「理解+自主决策」的方式填平生态鸿沟。</p><p>正如AMD软件副总所言，GPU编程的未来，是AI智能体主场。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571281" alt="" title="" loading="lazy"/></p><p><strong>全员AI编程，浓度高达100%</strong></p><p>如今的Claude Code已经让整个硅谷入坑了（Claude-Pilled）。</p><p>两天前，CEO Dario Amodei在达沃斯上再出暴论：软件工程师们没有时间了。未来6-12个月，AI能够彻底取代这些人！</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571282" alt="" title="" loading="lazy"/></p><p>甚至，Anthropic内部工程师已经不再手写代码了，全是Claude完成。</p><p>别不信，是真的。</p><p>就在Wired最新采访中，Claude Code之父Boris Cherny坦承，「自己100%代码都是AI写的」。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571283" alt="" title="" loading="lazy"/></p><p>或许Anthropic工程师怎么也没有想到，一个「副业项目」竟让硅谷如此狂热。</p><p>Boris Cherny回忆道，「一年前我们发布Claude Code时，甚至不确定『智能体编程』能不能成，但火爆来得太快了」。</p><p>Cherny个人经历就是最好的缩影：</p><p>刚发布时，他只有5%代码是用Claude Code写的；</p><p>到了去年5月，有了Opus 4和Sonnet 4，这个比例变成了30%；</p><p>而现在，有了Opus 4.5，他在过去两个月里100%的代码都是由Claude Code完成。</p><p>在Anthropic内部，这种全员AI化更是到了极致。</p><p>几乎100%技术员工都在使用Claude Code，甚至连Claude Code团队本身95%的代码也是由自身写出来的。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571284" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571285" alt="" title="" loading="lazy"/></p><p><strong>斯坦福AI教授都在用了</strong></p><p>不得不说，AI编程的进化速度令人咋舌。</p><p>回望2021到2024年，大多数工具不过是高级版的「自动补全」，在开发者打字时卑微地建议几行代码。</p><p>但到了2025年初，随着Cursor和Windsurf等初创发布早期的Agentic编程产品，游戏规则改变了——</p><p>开发者只需用大白话描述功能，剩下的脏活累活全扔给AI智能体完成。</p><p>Claude Code也在这个时间点，真正诞生了。</p><p>Boris Cherny坦承，早期版本也曾跌跌撞撞，甚至陷入死循环。但Anthropic下了一步狠棋：不为当下的AI能力开发产品，而要为AI即将抵达的未来而构建。</p><p>这一赌注押对了。随着Anthropic下一代旗舰Claude Opus 4.5的发布，AI编程迎来了真正的「拐点」。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571286" alt="" title="" loading="lazy"/></p><p>斯坦福大学AI讲师、Workera CEO Kian Katanforoosh最近就把公司全员迁移到了Claude Code。</p><p>他直言，对于高级工程师来说，Claude Code比Cursor、Windsurf更能打。</p><p>Katanforoosh感叹道，最近唯一让我看到编程能力有阶跃式提升的模型，就是Claude Opus 4.5。</p><p>「它给人的感觉不像是在模仿人类写代码，而是它真的找到了一种更聪明的解决路径」。</p><p>据传，微软内部也在大规模采用Claude Code了。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571287" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571288" alt="" title="" loading="lazy"/></p><p><strong>年入超10亿美金的「副业」</strong></p><p>Claude Code大获成功，给Anthropic带来了最直观的效益。</p><p>去年，AI编程智能体业务彻底爆发。11月，Anthropic宣布Claude Code在上线不到一年内，年度经常性收入（ARR）就突破了<strong>10亿美元</strong>。</p><p>到2025年底，ARR至少又增长了1亿美元。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571289" alt="" title="" loading="lazy"/></p><p>彼时，该产品约占Anthropic总ARR（约90亿美元）的12%。虽然比起向大企业提供 AI 系统的核心业务来说还算「小弟」，但它已是公司增长最快的板块之一。</p><p>尽管Anthropic在AI编程领域看似独孤求败，但Claude Opus 4.5的光环其实照亮了整个赛道。</p><p>竞争对手Cursor也在11月达到了10亿美元ARR，OpenAI、谷歌和xAI更是磨刀霍霍，试图用自研模型分一杯羹。</p><p>但Anthropic没打算停下。</p><p>前几天，他们又发布了Cowork——这是一款面向非编程领域的AI智能体。</p><p>它能管理你电脑里的文件、操作各种软件，而且完全不需要你在代码终端里敲命令。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571290" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571291" alt="" title="" loading="lazy"/></p><p><strong>不是取代，是进化</strong></p><p>提及Cowork时，Cherny透露自己已经用疯了。</p><p>比如项目管理，他会让Cowork盯着工程师的任务表格，谁没填名字，AI就会自动在Slack上发消息催人。</p><p>Cherny感慨道，「这是我当工程师以来最爽的时候，因为我不再需要做那些枯燥乏味的脏活了」。</p><p>面对那些因不再需要亲自写代码而感到失落的工程师，Cherny给出了他的建议：</p><p>这行业一直在变。我祖父在苏联用穿孔卡片编程；后来变成了机器码；再后来是C语言、Java、Python。</p><p>这是一条不断抽象化的连续体，AI智能体只是这条线上的最新一个点。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571292" alt="" title="" loading="lazy"/></p><p>如今，Cherny每天早上起床会在手机上启动3-4个编程智能体，到了公司再在终端里开几个。</p><p>任何时候，他都有五到十个智能体在跑任务。</p><p>Cherny总结道，「AI智能体将接管生活中所有繁琐的事——填表、搬运数据、发邮件。这会具有颠覆性，我们必须适应」。</p><p>话又说回来，Anthropic能不能先解决下Claude使用量？</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571293" alt="" title="" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[2026 AI元年:从生成式 AI 到智能体文明的临界点 Agentcometoo ]]></title>    <link>https://segmentfault.com/a/1190000047571214</link>    <guid>https://segmentfault.com/a/1190000047571214</guid>    <pubDate>2026-01-26 10:07:25</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <blockquote><em>2026 年，人工智能不再只是“会说话的工具”，而开始成为“会行动的系统”。</em></blockquote><p>在人工智能的发展史上，2026 年被越来越多研究者视为一个明确的分水岭： <strong>AI 正在从「生成式 AI（Generative AI）」跨越到「原生智能体（Agentic AI）」阶段。</strong></p><p>过去，我们习惯将大模型（LLM）视为“大脑”，将智能体（Agent）当作外接的“肢体”； 而今天，这种二元划分正在迅速瓦解。</p><h2>一、概念消融：当模型本身成为智能体</h2><h3>1️⃣ 从“调用模型”到“模型即智能体”</h3><p>在早期架构中，智能体是被<strong>外部框架强行拼装</strong>出来的产物： 任务拆解、记忆系统、工具调用、状态管理——都在模型之外。</p><p>而 2026 年正在形成的新范式是：</p><blockquote><strong>行动意图、长期规划与反馈修正，被直接写入模型的能力结构中。</strong></blockquote><h3>2️⃣ 关键定义：原生智能体架构（Native Agentic Architecture）</h3><p>所谓原生智能体架构，指的是：</p><ul><li>在预训练或对齐阶段</li><li>就引入“目标驱动”“行动选择”“长期状态保持”等能力</li><li>模型天然具备 <strong>思考 → 行动 → 观察 → 修正</strong> 的闭环</li></ul><p>此时，大模型不再是“文本补全器”， 而是一个<strong>具备执行潜力的认知系统</strong>。</p><h2>二、能力跃迁：从推理到“原子化行动”</h2><h3>核心变化一：长时程推理成为默认能力</h3><p>模型不再只回答单次问题，而是能：</p><ul><li>持续数小时甚至数天</li><li>推演复杂目标</li><li>保持上下文一致性与目标收敛</li></ul><h3>核心变化二：自主纠错机制</h3><p>当结果偏离目标时，模型能够：</p><ul><li>感知偏差</li><li>重启推理脉冲</li><li>无需人工介入完成修正</li></ul><p>👉 <strong>这不是更聪明，而是更像“员工”</strong></p><h2>三、交互革命：从对话框到协作网络</h2><h3>1️⃣ 多智能体编排（Multi-Agent Orchestration）</h3><p>当“模型 = 智能体”成立后，交互方式发生结构性变化：</p><ul><li>不再是“人 ↔ AI”</li><li>而是“人 ↔ 智能体网络”</li></ul><p>多个具备不同职能的智能体，在统一治理下：</p><ul><li>自主分工</li><li>协同决策</li><li>共同完成跨领域目标</li></ul><p>生产单元，第一次从“个体”跃迁为“网络”。</p><h3>2️⃣ 为什么边界模糊反而提升生产力？</h3><ul><li><strong>认知无缝流转</strong>：思考与执行之间的摩擦几乎为零</li><li><strong>端到端自动化</strong>：从数据抓取到决策执行，无需人类“复制粘贴”</li><li><strong>门槛急剧下降</strong>：非技术人员也能指挥复杂智能体集群</li></ul><p>在实践中，一些团队已经开始使用平台化方案 例如 <strong>「智能体来了」</strong>（<a href="https://link.segmentfault.com/?enc=uiEiwOsajvX%2BdWdKClw48Q%3D%3D.MwIo%2F3rLk4I8u13HKq1L9j7CzL82dERC7RytSNjTMtY%3D" rel="nofollow" target="_blank">https://agentcome.net/</a>）， 通过自然语言直接调度多智能体系统， 而不再关心底层模型或执行逻辑的差异。</p><blockquote>这并不是工具进步，而是<strong>组织形态的变化</strong>。</blockquote><h2>四、范式转移：从“软件中心”到“目标中心”</h2><h3>1️⃣ 软件正在被解构</h3><p>传统 SaaS 的本质是： <strong>把人的操作流程固化成菜单与按钮。</strong></p><p>而 Agent-Native 应用的本质是：</p><blockquote><strong>让人只负责定义目标，其余交给智能体完成。</strong></blockquote><p>你不再学习 Photoshop 的功能， 而是告诉图像智能体你想要的视觉意境。</p><h3>2️⃣ 价值评估体系的重构</h3><p>AI 的评价标准正在发生根本转变：</p><ul><li>从 <strong>效率</strong> → <strong>成果</strong></li><li>从 <strong>工具属性</strong> → <strong>组织属性</strong></li></ul><p>企业开始像评估员工一样评估 AI 智能体：</p><ul><li>是否稳定</li><li>是否合规</li><li>是否能跨部门协作</li></ul><h2>五、结论：复合智能（Composite AI）时代已经开启</h2><p>当大模型与智能体的边界彻底模糊， 人工智能正式进入 <strong>复合智能（Composite AI）</strong> 阶段。</p><ul><li><strong>技术层面</strong>：模型成为具备环境感知与行动潜力的动态系统</li><li><strong>应用层面</strong>：人类从“使用者”转为“战略指挥官”</li><li><strong>社会层面</strong>：生产力从线性增长跃迁为网络化增长</li></ul><blockquote>在这个时代，真正稀缺的能力不再是“会用工具”，而是——<strong>能否准确定义复杂目标，并编排一整个智能体网络去实现它。</strong></blockquote>]]></description></item><item>    <title><![CDATA[2026AI元年：为什么“人工智能 × 人类协作”成为新的工作基本单元？ Agentcometoo ]]></title>    <link>https://segmentfault.com/a/1190000047571221</link>    <guid>https://segmentfault.com/a/1190000047571221</guid>    <pubDate>2026-01-26 10:06:38</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><strong>2026 年，被越来越多研究者视为“AI 工作范式真正落地的起点”。</strong> 这并不是因为人工智能全面取代人类，而是因为——</p><blockquote><strong>“人 + AI 智能体”的协作结构，正在取代“人使用工具”，成为新的生产力最小单位。</strong></blockquote><h2>一、从工具到伙伴：AI 角色的根本变化</h2><h3>1. 什么是“智能体（AI Agent）”？</h3><p><strong>智能体不是功能集合，而是具备“目标意识”的系统。</strong></p><p>一个成熟的 AI Agent，至少具备三项能力：</p><ul><li><strong>感知（Perception）</strong>：理解环境与上下文</li><li><strong>规划（Planning）</strong>：将目标拆解为多步行动</li><li><strong>记忆（Memory）</strong>：跨任务、跨时间积累经验</li></ul><blockquote>这使 AI 从“被动执行者”，转变为<strong>可参与协作的数字角色</strong>。</blockquote><h3>2. 工作范式的两次关键迁移</h3><p><strong>第一次迁移：</strong></p><blockquote>指令驱动（How） → 目标驱动（What）</blockquote><p>人类不再描述“怎么一步步做”， 而是定义：</p><ul><li>目标是什么</li><li>成功的评价标准是什么</li></ul><p><strong>第二次迁移：</strong></p><blockquote>单点替代 → 全链路增强</blockquote><p>AI 不再只替代某个动作（写文案、画图）， 而是进入<strong>决策、校验、预测、优化</strong>等关键节点。</p><h2>二、为什么“人机协作”是唯一稳定解？</h2><p><strong>不是因为人类不行，也不是因为 AI 全能，而是因为两者在底层能力上天然互补。</strong></p><h3>1. 计算规模 × 直觉判断</h3><ul><li>AI：擅长海量数据、全局搜索、概率计算</li><li>人类：擅长小样本判断、价值选择、行业直觉</li></ul><blockquote>在高度不确定的商业环境中，任何一方单独工作，风险都更高。</blockquote><h3>2. 边际成本 × 创新溢价</h3><p>当任务被标准化后：</p><ul><li>AI 的执行成本 → 接近 0</li><li>人类的时间 → 被释放到“0→1”的创造性工作</li></ul><p><strong>整体生产函数从线性增长，跃迁为指数级增长。</strong></p><h3>3. 随机性 × 确定性的工程化解决</h3><p>现实中，企业需要“可控的 AI”。</p><p>因此，一部分团队会选择<strong>成熟的智能体平台</strong>， 例如：<strong>智能体来了（agentcome.net）</strong>， 通过：</p><ul><li>标准流程</li><li>权限边界</li><li>人类最终审核</li></ul><p>将 AI 的不确定性限制在工程可接受范围内。</p><h2>三、可落地的人机协作工作流（3 个阶段）</h2><h3>阶段一：任务原子化与角色绑定</h3><ul><li><strong>AI 主导</strong>：高重复、规则明确、数据密集</li><li><strong>人类主导</strong>：战略、创意、伦理、冲突处理</li></ul><h3>阶段二：Human-in-the-Loop 反馈闭环</h3><p>AI 的输出不是终点，而是<strong>第一稿</strong>。</p><p>人类修正 → 反馈 → 再训练 → 场景化精度提升</p><blockquote><strong>共同进化，才是长期护城河。</strong></blockquote><h3>阶段三：提示工程与知识封装</h3><p>未来的核心资产不再只是文档，而是：</p><ul><li>可复用的高质量 Prompt</li><li>结构化的行业知识库</li></ul><h2>四、AI 时代劳动者的三项核心能力</h2><ol><li><strong>提问力</strong>：定义问题边界与成功标准</li><li><strong>判断权</strong>：在内容极度过剩时识别“正确与优质”</li><li><strong>架构能力</strong>：组合 AI、工具与人类专家，搭建系统</li></ol><h2>五、总结：工作的本质正在改变</h2><ul><li><strong>工作单位变化</strong>：从“个人” → “人 + AI 智能体”</li><li><strong>工作内容变化</strong>：从执行 → 调度与决策</li><li><strong>长期目标</strong>：不是替代，而是构建可持续协作系统</li></ul><blockquote><strong>真正的竞争力，是把行业经验嵌入算法，把人类智慧固化为系统能力。</strong></blockquote>]]></description></item><item>    <title><![CDATA[什么是 IP SSL 证书？该如何申请 才高八斗的杯子_dS2Fpp ]]></title>    <link>https://segmentfault.com/a/1190000047571223</link>    <guid>https://segmentfault.com/a/1190000047571223</guid>    <pubDate>2026-01-26 10:05:54</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>SSL证书通常是颁发给域名的，但是有些企业没有域名只有 IP，或者不方便使用域名，IP 地址要实现https加密，这时可申请IP SSL证书。下面将从IP SSL证书的作用、申请条件和申请流程三个方面来让您详细了解 IP SSL证书。</p><h4>申请IP SSL证书的作用</h4><ul><li>1、用 IP SSL证书可以很好地防流量劫持。</li><li>2、IP 地址比域名复杂，不容易记忆，有了企业型IP SSL证书，可以有效提高IP的身份辨识度，减少被假冒的风险；</li><li>3、IP 能直达设备，应用更广。</li></ul><h4>申请IP SSL证书要满足的条件：</h4><ul><li>1、确定IP能正常访问</li><li>2、申请者必须有该IP的管理权限；</li><li>3、只可以申请单个IP SSL证书，不支持IP段通配符证书。</li></ul><p><strong>IP SSL证书的类型</strong></p><ul><li>DV型IP证书：仅需验证域名所有权，签发速度快，几分钟即可获得证书。</li><li>OV型IP证书：不仅需要验证域名所有权，还需进行企业信息验证，签发时间大概需要1-3个工作日  <br/>备注：内网IP和公网IP证书不通，需要确认好。<br/><img width="700" height="400" referrerpolicy="no-referrer" src="/img/bVdnLBS" alt="" title=""/></li></ul><h4>申请 IP SSL证书的流程</h4><p>1、选择可信赖的CA机构</p><h4><a href="https://link.segmentfault.com/?enc=IoTVLLxoojH2R4CKfEacHQ%3D%3D.5xsDSQ8SpkFNO%2Fdtx4r%2B84MAnVKSnaZno6x9nastgLiIubOl5yzJDyouDLBMY9oyezHAhtMp%2FWEJ%2FabsByJSruLka2Uv3QmHlS9gJ2m%2Bka0%3D" rel="nofollow" target="_blank"> IP SSL证书申请入口</a></h4><p><strong>访问JoySSL官网,注册一个证书账号，填写注册码230970，获取技术支持</strong>。</p><p>2、选择合适的 IP SSL证书，DV 或 OV，提交订单。</p><p>3、生成 CSR 文件和 Key，下载 CSR 文件和 Key 并保存在安全的位置。</p><p>4、配合完成验证。</p><p>DV型 IP SSL证书的验证方式：验证 IP 管理权限，上传指定验证文件到网站根目录（通过 80 或 443 端口验证）。一般 10分钟内就可完成验证。</p><p>OV型 IP SSL证书的验证方式：除了上述 DV 型 IP SSL证书的验证方式外，还要验证公司真实性，以电话或邮件方式进行企业审核。1-3 个工作日可完成验证。</p><p>5、获取 IP SSL证书，部署到服务器上。</p>]]></description></item><item>    <title><![CDATA[特定命令词阈值调优指南：解决单个命令词识别率低的精准方案 SmartPi ]]></title>    <link>https://segmentfault.com/a/1190000047571550</link>    <guid>https://segmentfault.com/a/1190000047571550</guid>    <pubDate>2026-01-26 10:05:16</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>前言</h2><p>在使用离线语音模组进行产品开发时，开发者常会遇到一个令人困扰的现象：<strong>大部分命令词识别效果良好，但个别命令词识别率明显偏低</strong>。</p><p>这种"个别掉队"的情况往往无法通过调整全局识别灵敏度来解决——因为把灵敏度调高会让其他命令词误识别增加，调低又会让问题命令词更难识别。</p><p><strong>"特定命令词阈值"</strong>功能正是为解决这类问题而生。它允许开发者针对单个命令词设置独立的识别阈值，实现"精准调优"，而不影响其他命令词的识别表现。</p><h2>一、真实案例：含数字命令词的识别难题</h2><h3>1.1 问题描述</h3><p><strong>客户背景</strong>：某饮水机产品开发者，使用 CI-1362 模组（JX-95C 系列），配置了多个温度调节命令词。</p><p><strong>问题现象</strong>：</p><ul><li><code>45度水</code>、<code>85度水</code>、<code>100度水</code> 等命令词识别率正常</li><li>唯独 <code>65度水</code> 命令词识别率很低，几乎无法触发</li></ul><p><strong>初步尝试</strong>：</p><ul><li>尝试使用正性词增强法：<code>停止|亭子|停滞|挺直</code>，对其他命令词有效</li><li>但 <code>65度水</code> 仍无法改善</li></ul><h3>1.2 问题根源分析</h3><p>技术支持给出的解释：</p><blockquote><strong>"因为'五'这个音是偏弱的"</strong></blockquote><p>从语音学角度分析：</p><ul><li><strong>"五" (wǔ)</strong> 是闭口音，气流能量弱，声谱特征不明显</li><li><strong>"六十五" (liù shí wǔ)</strong> 连续两个音节（十五）都是弱音</li><li>整体词能量偏低，导致模型打分时置信度不足</li></ul><p>这类问题属于<strong>语音固有特性</strong>，无法通过简单的命令词重构解决。</p><h2>二、解决方案：特定命令词阈值</h2><h3>2.1 什么是"特定命令词阈值"？</h3><p>智能公元平台提供的一项高级功能，允许为<strong>单个命令词</strong>设置独立的识别阈值，与全局阈值隔离。</p><p><strong>核心价值</strong>：</p><ul><li>不影响其他命令词的识别表现</li><li>可以单独提高"问题命令词"的灵敏度</li><li>精准平衡识别率与误识别率</li></ul><h3>2.2 功能位置</h3><p>在智能公元平台的 <strong>个性化音频</strong> 配置中：</p><table><thead><tr><th>配置路径</th><th>选项名称</th></tr></thead><tbody><tr><td>词条类型选择</td><td><strong>特定命令词阈值</strong></td></tr></tbody></table><p><strong>配置界面标识</strong>：</p><pre><code>个性化音频 → 词条类型 → 选择"特定命令词阈值"</code></pre><h3>2.3 支持的模组系列</h3><table><thead><tr><th>模组系列</th><th>支持情况</th><th>备注</th></tr></thead><tbody><tr><td><strong>CI-95C</strong></td><td>✓</td><td>全功能支持</td></tr><tr><td><strong>CI-96Z</strong></td><td>✓</td><td>全功能支持</td></tr><tr><td><strong>CI-73T/CI-73T2</strong></td><td>✓</td><td>全功能支持</td></tr><tr><td><strong>CI-33T</strong></td><td>✓</td><td>全功能支持</td></tr><tr><td><strong>CI-03T</strong></td><td>✓</td><td>全功能支持</td></tr><tr><td><strong>SU-32T</strong></td><td>✓</td><td>全功能支持</td></tr><tr><td><strong>SU-03T 系列</strong></td><td>✓</td><td>全功能支持</td></tr><tr><td><strong>JX-A7T</strong></td><td>✓</td><td>全功能支持</td></tr></tbody></table><blockquote><strong>注意</strong>：该功能在固件生成时打包生效，需要重新烧录固件。</blockquote><h2>三、配置方法与步骤</h2><h3>3.1 通过"个性化音频"配置</h3><p><strong>步骤概览</strong>：</p><ol><li>进入产品配置 → 个性化音频</li><li>点击 <strong>+ 点击添加</strong></li><li>词条类型选择 <strong>特定命令词阈值</strong></li><li>配置对应命令词的阈值参数</li><li>生成并烧录新固件</li></ol><p><strong>详细操作</strong>：</p><pre><code>┌─────────────────────────────────────────────────┐
│  个性化音频配置                                  │
├─────────────────────────────────────────────────┤
│  词条类型: [特定命令词阈值 ▼]                    │
│                                                  │
│  命令词选择: [65度水 ▼]                          │
│                                                  │
│  阈值设置: [0.6 ▼]  (范围: 0.01 ~ 0.8)          │
│                                                  │
│  + 点击添加                                       │
└─────────────────────────────────────────────────┘</code></pre><h3>3.2 通过"优化配置"调整</h3><p>在 <strong>优化配置</strong> 界面中也可以找到相关选项：</p><pre><code>优化配置 → 特定命令词阈值</code></pre><p><strong>配置项说明</strong>：</p><table><thead><tr><th>参数</th><th>说明</th><th>推荐值</th></tr></thead><tbody><tr><td><strong>阈值范围</strong></td><td>0.01 \~ 0.8</td><td>根据实际情况调整</td></tr><tr><td><strong>数值越大</strong></td><td>越容易识别，但误识别率增加</td><td>从默认值逐步提高</td></tr><tr><td><strong>数值越小</strong></td><td>识别越严格，误识别率降低</td><td>用于易误触发的命令词</td></tr></tbody></table><h3>3.3 阈值设置建议</h3><table><thead><tr><th>场景</th><th>建议阈值</th><th>说明</th></tr></thead><tbody><tr><td><strong>正常命令词</strong></td><td>0.2（默认）</td><td>使用全局默认值</td></tr><tr><td><strong>弱音命令词</strong></td><td>0.4 \~ 0.6</td><td>如含数字五、闭口音等</td></tr><tr><td><strong>远距离识别</strong></td><td>0.6 \~ 0.8</td><td>需高灵敏度场景</td></tr><tr><td><strong>易误触发词</strong></td><td>0.05 \~ 0.1</td><td>降低误识别率</td></tr></tbody></table><h2>四、针对"65 度水"的具体调优方案</h2><h3>方案一：单独调高阈值（推荐）</h3><p><strong>操作步骤</strong>：</p><ol><li>在个性化音频中，选择 <strong>特定命令词阈值</strong></li><li>选择命令词 <code>65度水</code></li><li>将阈值设置为 <strong>0.6</strong>（比默认 0.2 更高）</li><li>生成固件并测试</li></ol><p><strong>预期效果</strong>：</p><ul><li><code>65度水</code> 识别率显著提升</li><li>其他命令词识别表现不受影响</li></ul><h3>方案二：添加相似音作为辅助（需评估风险）</h3><p><strong>操作方法</strong>：</p><p>在命令词配置中添加：</p><pre><code>65度水|60度水|六十五度水</code></pre><p><strong>注意事项</strong>：</p><ul><li><strong>风险</strong>：用户说 <code>60度水</code> 时可能误触发 <code>65度水</code> 功能</li><li><strong>需评估</strong>：产品场景是否允许这种模糊匹配</li><li><strong>技术支持原话</strong>："加六十度应该效果提升是很明显的，但是有一定的风险，这个需要评估一下"</li></ul><h3>方案三：组合使用</h3><ol><li>先使用 <strong>方案一</strong>（调高特定阈值）</li><li>测试后如仍不理想，再谨慎评估 <strong>方案二</strong></li><li>最后考虑重新设计命令词（如 <code>最大热度</code> 替代 <code>65度水</code>）</li></ol><h2>五、阈值调优的通用原则</h2><h3>5.1 逐步调整原则</h3><pre><code>初始值 → 测试 → 微调 → 再测试 → 确认
  0.2    0.4    0.5    0.6    最终值</code></pre><p><strong>建议</strong>：每次调整幅度不超过 0.1-0.2，避免跳跃式设置</p><h3>5.2 平衡原则</h3><table><thead><tr><th>阈值设置</th><th>识别率</th><th>误识别率</th><th>适用场景</th></tr></thead><tbody><tr><td><strong>低 (0.01-0.1)</strong></td><td>低</td><td>低</td><td>安静环境、高可靠性要求</td></tr><tr><td><strong>中 (0.2-0.4)</strong></td><td>中</td><td>中</td><td>大多数场景的默认选择</td></tr><tr><td><strong>高 (0.6-0.8)</strong></td><td>高</td><td>高</td><td>噪声环境、远距离识别</td></tr></tbody></table><h3>5.3 测试验证原则</h3><ol><li><strong>单一变量测试</strong>：每次只调整一个命令词的阈值</li><li><strong>环境一致性</strong>：在相同环境下进行前后对比测试</li><li><strong>多次采样</strong>：每个阈值至少测试 20-30 次</li><li><strong>记录数据</strong>：记录识别成功率和误触发次数</li></ol><h2>六、常见问题与注意事项</h2><h3>Q1：阈值设为 0.8 后仍无法识别？</h3><p><strong>可能原因</strong>：</p><ol><li>命令词本身发音特征过于模糊</li><li>麦克风选型或位置问题</li><li>噪声环境过于恶劣</li></ol><p><strong>建议</strong>：</p><ul><li>考虑更换命令词表述</li><li>检查硬件设计（麦克风灵敏度、安装位置）</li><li>考虑升级到更高识别率的模组（如 SU-32T 98% 识别率）</li></ul><h3>Q2：特定阈值会影响唤醒词吗？</h3><p><strong>答案</strong>：不会。特定命令词阈值只影响对应的命令词，与唤醒词独立。</p><h3>Q3：可以设置多个命令词的特定阈值吗？</h3><p><strong>答案</strong>：可以。每个命令词都可以独立设置阈值，互不影响。</p><h3>Q4：阈值设置后如何生效？</h3><p><strong>步骤</strong>：</p><ol><li>配置完成后点击 <strong>生成固件</strong></li><li>等待固件编译完成</li><li>下载并烧录到模组</li><li>复位后生效</li></ol><h2>七、总结</h2><h3>核心要点回顾</h3><table><thead><tr><th>要点</th><th>说明</th></tr></thead><tbody><tr><td><strong>问题定位</strong></td><td>单个命令词识别率低，无法通过全局调整解决</td></tr><tr><td><strong>解决方案</strong></td><td>使用"特定命令词阈值"功能进行精准调优</td></tr><tr><td><strong>配置位置</strong></td><td>个性化音频 → 特定命令词阈值</td></tr><tr><td><strong>阈值范围</strong></td><td>0.01 \~ 0.8，默认 0.2</td></tr><tr><td><strong>调整策略</strong></td><td>逐步微调，充分测试，平衡识别率与误识别率</td></tr></tbody></table><h3>快速决策流程</h3><pre><code>发现某命令词识别率低
      │
      ▼
尝试正性词增强法（如：停止|亭子|停滞）
      │
      ▼
仍无效 → 命令词含弱音（如五）？
      │
      ├─ 是 → 使用"特定命令词阈值"，调高至 0.6
      │
      └─ 否 → 检查硬件设计/考虑更换命令词</code></pre>]]></description></item><item>    <title><![CDATA[数据库校验利器升级！gt-checksum v1.2.3 正式发布 GreatSQL社区 ]]></title>    <link>https://segmentfault.com/a/1190000047571558</link>    <guid>https://segmentfault.com/a/1190000047571558</guid>    <pubDate>2026-01-26 10:04:40</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>数据库校验利器升级！gt-checksum v1.2.3 正式发布</h2><p>更快、更稳、更智能——你的数据一致性守护专家</p><hr/><h3>✨ 写在前面</h3><p>在日常的数据库运维与数据迁移中，你是否经常被这样的问题困扰：</p><ul><li><strong>数据不一致</strong>却难以快速定位</li><li><strong>跨库校验</strong>复杂繁琐</li><li><strong>存储过程、触发器</strong>难对比</li><li><strong>大表校验</strong>内存飙升，被 OOM 直接 Kill</li></ul><p>今天，我们为你带来一个好消息——<strong>gt-checksum v1.2.3</strong>全新发布，专门针对上述痛点进行了全面增强与优化！</p><p>发布会预约：<a href="https://link.segmentfault.com/?enc=Up9UuR896Ha%2F70eKQM%2F2Sw%3D%3D.tfdHonofFcXbPJDT7AUVGV03VeybS5OGp3duzOObZ%2FOb1Txew8QniKipG3BzPXoN" rel="nofollow" target="_blank">https://meeting.tencent.com/dw/hSVg8Wu4ixfk</a><br/>发布会时间：2026年1月26日下午15:30</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571560" alt="" title=""/></p><hr/><h3>🚀 核心亮点速览</h3><h4>1. 📁 数据库名映射：跨库校验一键搞定</h4><p>现在，你可以轻松将源库的表“映射”到目标库的不同名称下进行校验，非常适合分库分表、跨环境数据对比等场景。</p><p><strong>配置示例</strong>：</p><pre><code># 单表映射
tables=db2.test1:db1.test1
# 整库映射
tables=db2.*:db1.*</code></pre><p>结果中会清晰展示映射关系，一目了然。</p><h4>2. 🛠️ 支持 Routine 与 Trigger 校验</h4><p>不仅是表数据，现在连<strong>存储过程、函数、触发器</strong>也能进行一致性校验与智能修复，生成完整可执行的修复 SQL。</p><h4>3. 🧠 更聪明的内存管理</h4><p>引入智能内存调控机制，自动防止 OOM（内存溢出）。当内存接近上限时，工具会自动平滑降低并发与分块大小，并触发垃圾回收，保障任务稳定运行。</p><h4>4. 📝 修复 SQL 生成逻辑大幅优化</h4><ul><li>自动在修复文件头部添加<strong>字符集设置</strong>、<strong>临时禁用外键检查</strong>等语句</li><li>智能合并事务，提升修复执行效率</li><li>修复了以往版本中因语句顺序问题导致的修复失败</li></ul><hr/><h3>⚙️ 重点功能详解</h3><h4>🔄 数据库名映射</h4><p>适用于异构数据库同步、测试环境与生产环境结构差异等复杂场景，让校验不再受库表名称限制。</p><h4>🔍 结构校验增强</h4><ul><li><strong>索引修复</strong>：支持主键/辅助索引的“不可见”属性设置，合并 DDL 提升效率</li><li><strong>外键约束</strong>：新增外键一致性校验与修复</li><li><strong>字段操作优化</strong>：智能合并 <code>CHANGE COLUMN</code>操作，避免重建字段导致的数据丢失风险</li></ul><h4>🧩 参数配置更清晰</h4><p>我们整理了最常用的配置参数，方便你快速上手：</p><table><thead><tr><th align="left">参数</th><th align="left">说明</th><th align="left">推荐值</th></tr></thead><tbody><tr><td align="left"><code>parallelThds</code></td><td align="left">并发线程数，影响校验速度</td><td align="left">10</td></tr><tr><td align="left"><code>chunkSize</code></td><td align="left">每次校验的数据量，影响内存与速度</td><td align="left">10000</td></tr><tr><td align="left"><code>memoryLimit</code></td><td align="left">内存上限（MB），防 OOM</td><td align="left">根据机器配置调整</td></tr><tr><td align="left"><code>checkObject</code></td><td align="left">校验对象：data, struct, routine, trigger</td><td align="left">data</td></tr><tr><td align="left"><code>fixTrxNum</code></td><td align="left">单个事务包含的 DML 语句数</td><td align="left">1000</td></tr></tbody></table><hr/><h3>⚡ 性能与稳定性的全面提升</h3><ul><li><strong>查询优化</strong>：减少冗余查询，部分场景<strong>性能提升达 3 倍</strong></li><li><strong>并发自适应</strong>：内存超限时平缓降低并发（每次 90%），避免性能骤降</li><li><strong>日志国际化</strong>：所有输出统一为英文，日志更简洁，便于监控系统采集分析</li></ul><hr/><h3>🐛 关键问题修复</h3><p>针对数据校验中的“顽疾”进行了重点修复：</p><ul><li>特殊字符（如 <code>\'</code>）转义处理</li><li>字符串末尾空格导致的误判</li><li>多列联合主键校验准确性</li><li>无索引表的数据一致性问题</li></ul><hr/><h3>📦 如何获取与使用</h3><p>新版本已发布，你可以通过以下方式获取：</p><ol><li><strong>下载最新二进制包</strong>（已包含测试用例）</li><li>查看详细文档与配置说明</li><li>使用 <code>./gt-checksum --help</code>快速查看参数</li></ol><p>建议在使用前，根据实际数据量与环境资源，合理调整 <code>memoryLimit</code>、<code>parallelThds</code>等参数，以达到最佳校验效果。</p><hr/><h3>🙏 致谢</h3><p>特别感谢社区用户</p><ul><li>GLAW</li><li>月城</li></ul><p>为本版本的开发与优化做出的重大贡献！</p><hr/><h3>💎 总结</h3><p>gt-checksum v1.2.3 不仅是一次功能更新，更是面向生产级数据一致性校验的全面进化。无论你是在做<strong>数据迁移验证</strong>、<strong>主从一致性巡检</strong>，还是<strong>日常数据质量保障</strong>，这个版本都能为你提供更可靠、更高效的支撑。</p><p><strong>让数据校验，从此省心、放心。</strong></p><hr/><p><em>gt-checksum 是一个开源项目，欢迎贡献代码、反馈问题或提出建议。让我们一起打造更好用的数据库工具！</em></p>]]></description></item><item>    <title><![CDATA[MIAOYUN | 每周AI新鲜事儿 260123 MIAOYUN ]]></title>    <link>https://segmentfault.com/a/1190000047571563</link>    <guid>https://segmentfault.com/a/1190000047571563</guid>    <pubDate>2026-01-26 10:03:46</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>本周AI行业迎来密集爆发，大模型开源与技术突破并行，百度文心登顶国际榜单，智谱、美团、阶跃星辰等也纷纷发布或开源高性能新模型；AI工具聚焦场景落地，OpenAI与Google掀起翻译工具对决，腾讯混元3D、蚂蚁百灵Ling Studio、阿里呜哩、飞书AI录音豆等深耕垂直场景，实用型显著增强；Agent发展进入新阶段，字节扣子2.0、MiniMax Agent 2.0等升级专业化能力；市场层面基础设施与生态开放成为关键变量，马斯克开放𝕏平台推荐算法并投用GW级超算集群，一起来回顾本周发生的AI新鲜事儿吧！</p><h2>AI 大模型</h2><p><strong>百度文心大模型「ERNIE-5.0-0110」登LMArena文本榜国内第一、全球第八</strong></p><p>1月15日，百度正式上线的新一代文心大模型「ERNIE-5.0-0110」，在LMArena大模型竞技场以1460分位列文本榜国内第一、全球第八，是该榜单中唯一进入全球前十的中国大模型，数学能力排名全球第二。该模型参数量达2.4万亿，采用原生全模态统一建模技术，支持文本、图像等多种信息的输入与输出，此前Preview版本已拿下LMArena文本榜全球并列第二、国内第一及视觉理解榜国内第一的成绩。</p><p><strong>美团LongCat团队开源升级版模型「LongCat-Flash-Thinking-2601」</strong></p><p>1月16日，美团LongCat团队发布并开源升级版模型「LongCat-Flash-Thinking-2601」，引入「重思考模式」，在Agentic Search（智能体搜索）、Agentic Tool Use（智能体工具调用）、TIR（工具交互推理）等核心评测基准均达开源SOTA（AIME-25获满分、τ²-Bench 88.2分），泛化能力超越Claude，依托多环境强化学习（DORA基础设施）与噪声环境稳健训练实现技术突破，目前已在GitHub、Hugging Face等平台开源，支持官网在线体验与API免费调用。</p><p><strong>Black Forest Labs开源「FLUX.2」[klein]图像生成模型家族</strong></p><p>1月17日消息，Black Forest Labs开源「FLUX.2」[klein]图像模型家族，包含4B和9B两个版本（各含未蒸馏的基础版与4步蒸馏版），采用流模型+Qwen3文本编码器架构，统一文生图、图像编辑及多参考生成功能，实现最快0.5秒亚秒级推理，4B版（Apache 2.0许可证支持商用）仅需13GB显存适配消费级GPU，9B版（非商用许可证）性能比肩5倍参数量模型，同步提供FP8/NVFP4量化版本（分别提速1.6倍/2.7倍、显存降低40%/55%），附带推理脚本，兼顾实时应用、微调研究与边缘部署需求。</p><p><strong>智谱正式发布并开源混合思考模型「GLM-4.7-Flash」</strong></p><p>1月20日，智谱正式发布并开源混合思考模型「GLM-4.7-Flash」，总参数量30B、激活参数量3B，作为同级别SOTA模型兼顾性能与效率，在SWE-bench Verified等主流基准测试中表现超「GPT-OSS-20B」等模型，适配编程、中文写作等多场景，即日起在智谱开放平台上线并免费调用，将替代「GLM-4.5-Flash」（后者1月30日下线），同时可通过Hugging Face、魔搭社区进行开源部署。</p><p><strong>阶跃星辰开源10B参数量视觉语言模型「Step3-VL-10B」</strong></p><p>1月20日，阶跃星辰开源10B参数量视觉语言模型「Step3-VL-10B」，凭借全参数端到端多模态联合预训练、大规模RL迭代及PaCoRe并行协调推理机制，在视觉感知、逻辑推理、数学竞赛等多维度达到同规模SOTA水平，媲美甚至超越10-20倍参数量的开源与闭源旗舰模型，可下沉至端侧设备运行，目前Base和Thinking版本已通过多个平台开源。</p><p><strong>Liquid AI开源非Transformer架构的端侧推理模型「LFM2.5-1.2B-Thinking」</strong></p><p>1月21日，由MIT CSAIL孵化的初创公司Liquid AI发布并开源非Transformer架构的端侧推理模型「LFM2.5-1.2B-Thinking」，该模型基于液态神经网络打造，仅需900MB内存即可在手机等设备离线运行，不仅推理速度和质量在同规模模型中领先，参数量比「Qwen3-1.7B」少约40%，却在数学推理、指令遵循、工具使用等核心能力上表现相当或更优，还通过Midtraining、SFT、DPO、RLVR等训练策略将死循环生成比例从15.74%降至0.36%，兼容llama.cpp、MLX等主流推理框架及多品牌硬件，证明Transformer并非唯一解。</p><p><strong>中佛罗里达大学发布首个“纯文本提示”医学全能分割模型「Medical SAM3」</strong></p><p>1月21日消息，中佛罗里达大学等机构联合发布了首个真正“纯文本提示”驱动的医学全能分割模型「Medical SAM3」，采用全参数微调结合分层学习率衰减策略，依托覆盖10种成像模态、33个数据集的大规模训练底座及统一2D高分辨率视角设计，摆脱了传统医学分割模型对人工边界框等空间提示的依赖，仅凭文本指令即可在CT、MRI、内镜等多模态医学影像中实现专家级分割，内部验证平均Dice从54.0%提升至77.0%，外部零样本场景从11.9%暴涨至73.9%，大幅降低临床交互成本，未来将扩充数据并打造集成LLM的Agent。</p><p><strong>百川智能发布循证增强医疗大模型「Baichuan-M3 Plus」</strong></p><p>1月22日，百川智能发布循证增强医疗大模型「Baichuan-M3 Plus」，其融合独创六源循证技术与M3基座，将幻觉率降至2.6%达全球最低，首创“证据锚定”技术使医学结论可逐句溯源（匹配准确率超95%），API调用成本较上一代降低70%且限时15天免费体验，同时发起“海纳百川”计划，向中国医疗服务机构免费开放API，用于临床辅助决策与医学教育，推动AI医疗生态发展。</p><p><strong>Runway发布全新图生视频模型「Gen 4.5」</strong></p><p>1月22日，Runway发布全新图生视频模型「Gen 4.5」，该模型在长故事表达、精准镜头控制、连贯叙事及角色一致性上实现升级，生成视频细节逼真，在1000人盲测中仅57.1%的人能区分其与真实视频。当前视频模型行业呈现真实度与物理一致性增强、声画同步提升等趋势，正逐步接近商业化应用。</p><h2>AI 工具</h2><p><strong>AI翻译对决，OpenAI上线「ChatGPT Translate」，Google开源「TranslateGemma」</strong></p><p>1月16日消息，OpenAI近期低调上线独立翻译工具「ChatGPT Translate」，支持超50种语言，无需登录即可免费使用，核心亮点是具备译文语气调整等二次加工能力，但暂不支持文档、图片翻译及离线使用。对此Google则高调回应，发布基于Gemma 3的开源翻译模型「TranslateGemma」，提供4B、12B、27B三种参数版本，支持55种语言及多模态输入，12B模型性能超越27B基线模型，4B模型适配移动端/边缘设备，通过双阶段微调流程蒸馏Gemini模型知识，双方竞争推动AI翻译从单纯语言转换向智能适应方向演进。</p><p><strong>腾讯「混元3D Studio 1.2」发布公测，组件能力升级至PartGen 1.5</strong></p><p>1月16日，腾讯「混元3D Studio 1.2」全新发布并开放公测（无需申请），组件能力升级至PartGen 1.5（拆分精度从1024³提升至1536³分辨率，支持笔刷交互与分割掩码控制，保留高精细节、拆分更完整），基模同步升级为「混元3D 3.1」（几何细节与纹理还原度优化，适配更多风格），新增八视图输入（含顶、底及左右45度视角）提升专业可控性，用户可通过官方链接体验。</p><p><strong>蚂蚁集团正式上线百灵大模型官方交互平台「Ling Studio」</strong></p><p>1月16日，蚂蚁集团正式上线百灵大模型官方交互平台「Ling Studio」，用户可体验Ling-1T（高速响应）、Ring-1T（复杂推理）、Ming-flash-omni-Preview（多模态识别）等百灵大模型，平台支持调参、系统提示词配置、联网搜索等原生工具调用及API即接即用功能，每日发放50万个免费Tokens，文件对话、图片生成等更多功能即将上线。</p><p><strong>阿里巴巴通义千问团队推出一站式AIGC创意生产力平台「呜哩」</strong></p><p>1月19日，阿里巴巴通义千问团队推出一站式AIGC创意生产力平台「呜哩」（目前处于测试阶段），该平台集成通义Qwen Image系列、万相2.6等自研模型，以及字节Seedream 4.0/4.5、可灵相关第三方模型，支持文生图、图生图、参考生图、文生视频、图生视频等全功能，生图最高可达4K、生视频最高1080p且支持音画同步，生成速度快（图片几秒、视频1-2分钟），参考生图功能可灵活改图，目前所有功能免费无次数限制，手机号登录即可使用，正式上线后可能收费。</p><p><strong>飞书与安克创新联合推出仅重10g的「AI录音豆」，录音整理全自动化</strong></p><p>1月20日，飞书与安克创新联合推出「AI录音豆」，这款直径23.2毫米、重10g的微型硬件支持磁吸佩戴，续航达8小时，一键即可录音，录音内容可无缝联动飞书生态，自动生成逐字稿、多语言翻译、会议总结、待办事项等，还能通过飞书知识问答、定时任务、日报周报生成等功能二次加工，解决了手机录音续航、操作繁琐等痛点，将线下录音转化为可协作复用的数字资产，优化了线下会议等场景的录音与内容整理体验。</p><p><strong>红杉中国xbench发布「AgentIF-OneDay」评测体系</strong></p><p>1月21日，红杉中国xbench发布「AgentIF-OneDay」评测体系，聚焦评估Agent在长时复杂任务中的能力，以人类一天可完成的任务复杂度为基准，涵盖工作流执行、范例参考、迭代式编辑三类场景，包含104道任务及767个细粒度评分点，评测显示Manus、Genspark、ChatGPT-Agent构成第一梯队且各有场景侧重，当前Agent在隐式指令推断等方面仍存短板，未来将推进OneWeek评测，同时持续学习与数据飞轮被认为是Agent向高可靠“数字员工”演进的关键。</p><h2>AI Agent</h2><p><strong>超参数科技发布LLM驱动的Game Agent「COTA」，推理链路全程可见</strong></p><p>1月16日，超参数科技发布自研Game Agent「COTA」，这是首个以LLM（基座模型Qwen3-VL-8B-Thinking）为核心驱动、具备思维可解释性的游戏智能体，通过“双系统分层架构”（上层指挥官负责战略规划、下层行动专员执行微操）及SFT+GRPO+DPO训练流程，攻克实时响应难题（百毫秒级），在自研FPS游戏环境中展现出接近真人高分玩家的竞技水平，可完成单兵作战与团队战术配合，既降低高拟真NPC开发调试门槛，又能优化玩家体验，其底层技术还具备跨场景迁移潜力，目前已开启官网预约体验。</p><p><strong>字节跳动「扣子空间」正式升级为「扣子2.0」，四大Agent能力升级</strong></p><p>1月19日，字节跳动拥有千万用户的「扣子空间」升级为「扣子2.0」，核心新增Agent Skills（封装场景最佳实践与工具，支持通过技能商店创建、获取行业专属技能）、Agent Plan（设定长期目标后自动规划执行并主动汇报）、Agent Office（深度理解职场场景，提供针对性洞察与文档处理能力）、Agent Coding（一站式云端开发平台，支持一键部署）四大能力，还上线了音画同步的官方视频创作Skill，定位职场人靠谱伙伴，助力高效完成简历筛选、文案创作、数据报表等各类工作任务。</p><p><strong>阶跃星辰正式推出「阶跃AI桌面伙伴Windows版」</strong></p><p>1月19日，阶跃星辰正式推出「阶跃AI桌面伙伴Windows版」，同时带来重要升级，该终端Agent定位“会做事、总在场、有记忆、能进化”，此前已发布Mac版（支持日程分析、当前窗口识别等专属功能），现支持调用16款第三方工具且可自行添加，具备本地存储的全局记忆（自动整理电脑活动轨迹并生成复盘报告），用户可通过官网下载。</p><p><strong>昆仑万维在Skywork平台推出面向非设计人士的「Skywork Design Agent」</strong></p><p>1月19日，昆仑万维在Skywork平台推出面向非设计人士的「Skywork Design Agent」，聚焦海报设计、社媒物料、LOGO与品牌视觉、通用创意生图四大核心场景，通过场景化指引、多启动方式（文生图/以图生图等）、自研画布引擎实现全流程设计，具备AI修图（拆分图层、扩图等）、素材知识库存档、多格式导出等功能，零门槛操作且效果可控，重塑办公视觉创作效率，后续将持续迭代专业功能并拓展AI多媒体创作能力。</p><p><strong>MiniMax发布第二代智能体「MiniMax Agent 2.0」，定位“AI原生工作台"</strong></p><p>1月20日，MiniMax稀宇科技发布第二代智能体「MiniMax Agent 2.0」，以“AI原生工作台”为核心定位，搭载桌面端应用（双系统适配，打通本地云端无缝衔接）与Expert Agents（定制化专家分身），可高效完成新闻摘要、论文解读、PPT制作等复杂任务，依托Lightning Attention等技术升级及内部迭代闭环，颠覆交互逻辑、打破专业壁垒，重塑AI高复杂度工作价值。</p><p><strong>Anthropic被曝升级Claude Cowork，新增「知识库」功能实现“永久记忆”</strong></p><p>1月20日消息，Anthropic被曝正在为Claude Cowork进行重大更新，通过新增「知识库」（Knowledge Bases）功能实现“永久记忆”，支持多对话、多任务间持续调用过往关键信息并动态更新，界面简化后新增Artifacts版块管理复用过往作品，同时扩展MCP连接器提升自动化能力，同步优化Web语音模式、Pixelate等轻量化功能，推动其从聊天助手向全面生产力助手演进，而开发者社区也通过Smart Forking等探索印证AI长期记忆的应用价值。</p><h2><strong>市场动态</strong></h2><p><strong>Roboparty全栈开源双足人形机器人「萝博头原型机」</strong></p><p>1月15日，Roboparty全栈开源双足人形机器人「萝博头原型机」，该原型机身高1.25m、重30kg，跑步速度达3m/s，同步开放硬件结构图、EBOM清单、AMP运控算法及避坑知识库，实现“可复现、可二开、可验证”，其搭载的拟人步态算法适配BFM框架，硬件采用类车规级结构，已获小米战投、商汤等机构千万美元种子轮融资，同时推出开发者共创计划。</p><p><strong>马斯克旗下xAI的全球首个GW级超算集群「Colossus 2」正式投入运行</strong></p><p>1月17日，马斯克旗下xAI的全球首个GW级超算集群「Colossus 2」正式投入运行，其搭载55.5万张GPU，4月将升级至1.5GW、最终达2GW，专为Grok模型训练服务（Grok 5参数预计6万亿），该集群从建设到上线仅用不到一年（前一代Colossus 1耗时122天）；而美国PJM电网因数据中心电力需求激增（未来10年年均增长4.8%），计划在极端天气对13州6700万居民轮流停电，不过「Colossus 2」不在该电网覆盖范围，且xAI部署了特斯拉Megapack储能系统以减少本地电网冲击。</p><p><strong>马斯克宣布开源「𝕏平台」推荐算法，每周四迭代一次</strong></p><p>1月20日，马斯克宣布开源「𝕏平台」（原Twitter）推荐算法代码，使其成为首个核心流量分发逻辑全透明化的主流社交平台，新版算法采用xAI Grok模型的Transformer架构，以“零人工特征工程”为核心，通过内部“Thunder”和外部“Phoenix Retrieval”召回内容，经Phoenix评分器加权计算得分，评分前后设过滤机制并保障作者多样性，未来将每四周更新开源版本并附开发者说明，这一透明化举措是其他社交平台未做到的。</p>]]></description></item><item>    <title><![CDATA[用 CSS 打造个性倒边框半径卡片效果 Silvana ]]></title>    <link>https://segmentfault.com/a/1190000047571566</link>    <guid>https://segmentfault.com/a/1190000047571566</guid>    <pubDate>2026-01-26 10:03:06</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <blockquote>你好，我是 Silvana，一名前端开发工程师菜鸟。</blockquote><p><strong>介绍：</strong></p><p>最近琢磨出一个简单又有特色的 <code>CSS</code> 小效果 —— 倒边框半径的卡片，用来做个人名片类的展示特别合适，不用复杂的插件，纯 <code>HTML+CSS</code> 就能实现，分享给喜欢折腾前端小效果的朋友～</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571568" alt="" title=""/></p><blockquote>这个卡片的核心是用 <code>CSS</code> 伪元素搭配阴影模拟出 “倒圆角” 的视觉效果，整体结构不复杂，下面把完整的代码和详细注释贴出来，新手也能轻松看懂、直接套用～</blockquote><h2>完整源码（附详细注释）</h2><h3>1. HTML 部分（index.html）</h3><pre><code class="HTML">&lt;!DOCTYPE html&gt;
&lt;html lang="en"&gt;
  &lt;head&gt;
    &lt;meta charset="UTF-8" /&gt;
    &lt;!-- 适配移动端视图 --&gt;
    &lt;meta name="viewport" content="width=device-width, initial-scale=1.0" /&gt;
    &lt;title&gt;CSS 倒边框半径卡&lt;/title&gt;
    &lt;!-- 引入样式文件 --&gt;
    &lt;link rel="stylesheet" href="style.css" /&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;!-- 卡片容器 --&gt;
    &lt;div class="card"&gt;
      &lt;!-- 顶部卡片区域（放视频背景） --&gt;
      &lt;div class="box"&gt;
        &lt;div class="imgBx"&gt;
          &lt;!-- 自动循环播放且静音的视频背景 --&gt;
          &lt;video src="cover.mp4" type="video/mp4" autoplay loop muted&gt;&lt;/video&gt;
        &lt;/div&gt;
      &lt;/div&gt;
      &lt;!-- 底部卡片区域（放个人信息） --&gt;
      &lt;div class="box"&gt;
        &lt;div class="content"&gt;
          &lt;!-- 姓名和身份 --&gt;
          &lt;h2&gt;Lila Simmons&lt;br/&gt;&lt;span&gt;Professional Artist&lt;/span&gt;&lt;/h2&gt;
          &lt;!-- 数据统计 --&gt;
          &lt;ul&gt;
            &lt;li&gt;Posts&lt;span&gt;62&lt;/span&gt;&lt;/li&gt;
            &lt;li&gt;Followers&lt;span&gt;120&lt;/span&gt;&lt;/li&gt;
            &lt;li&gt;Following&lt;span&gt;47&lt;/span&gt;&lt;/li&gt;
          &lt;/ul&gt;
          &lt;!-- 关注按钮 --&gt;
          &lt;button&gt;Follower&lt;/button&gt;
        &lt;/div&gt;
      &lt;/div&gt;
      &lt;!-- 左侧圆形头像区域 --&gt;
      &lt;div class="circle"&gt;
        &lt;div class="imgBx"&gt;
          &lt;img src="user.png" alt="用户头像"&gt;
        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/body&gt;
&lt;/html&gt;</code></pre><h3>2. CSS 部分（style.css）</h3><pre><code class="CSS">/* 全局样式重置 */
* {
  margin: 0;
  padding: 0;
  /* 盒模型：宽高包含边框和内边距 */
  box-sizing: border-box;
}
/* 定义全局颜色变量，方便统一修改 */
:root {
  --clr: #083d41
}
/* 页面整体样式：居中展示，背景色用变量 */
body{
  display: flex;
  justify-content: center;
  align-items: center;
  min-height: 100vh;
  background: var(--clr);
}
/* 卡片容器：相对定位，设置宽高，纵向排列子元素 */
.card {
  position: relative;
  width: 320px;
  height: 430px;
  display: flex;
  flex-direction: column;
  justify-content: space-between;
}
/* 卡片内的两个box通用样式 */
.card .box {
  position: relative;
  width: 110%;
  height: 200px;
  border-radius: 15px;
}
/* 第一个box（视频区域）：伪元素做左侧倒圆角 */
.card .box:nth-child(1) {
  background: #f00; /* 视频区域背景（被视频覆盖） */
}
.card .box:nth-child(1)::before {
  content: "";
  position: absolute;
  top: 106px;
  left: -1px;
  width: 20px;
  height: 20px;
  background: transparent;
  z-index: 10;
  border-bottom-left-radius: 20px;
  /* 利用阴影模拟倒圆角效果，颜色和页面背景一致 */
  box-shadow: -6px 6px var(--clr);
}
/* 第一个box：伪元素做底部倒圆角 */
.card .box:nth-child(1)::after {
  content: "";
  position: absolute;
  bottom: -1px;
  left: 105px;
  width: 20px;
  height: 20px;
  background: transparent;
  z-index: 10;
  border-bottom-left-radius: 20px;
  box-shadow: -6px 6px var(--clr);
}
/* 第二个box（信息区域）：调整宽高和背景色 */
.card .box:nth-child(2) {
  background: #fff;
  height: 220px;
  width: 100%;
}
/* 第二个box：伪元素做左侧倒圆角 */
.card .box:nth-child(2)::before {
  content: "";
  position: absolute;
  bottom: 106px;
  left: -1px;
  width: 20px;
  height: 20px;
  background: transparent;
  z-index: 10;
  border-top-left-radius: 20px;
  box-shadow: -6px -6px var(--clr);
}
/* 第二个box：伪元素做顶部倒圆角 */
.card .box:nth-child(2)::after {
  content: "";
  position: absolute;
  top: -1px;
  left: 109px;
  width: 20px;
  height: 20px;
  background: transparent;
  z-index: 10;
  border-top-left-radius: 20px;
  box-shadow: -6px -6px var(--clr);
}
/* 左侧圆形头像容器：绝对定位，居中显示 */
.card .circle {
  position: absolute;
  top: 50%;
  left: -70px;
  transform: translateY(-50%);
  width: 180px;
  height: 180px;
  border-radius: 50%;
  /* 边框颜色和页面背景一致，营造镂空感 */
  border: 10px solid var(--clr);
}
/* 头像和视频容器通用样式：溢出隐藏，适配圆角 */
.card .circle .imgBx,
.card .box .imgBx {
  position: absolute;
  inset: 0;
  overflow: hidden;
  border-radius: 50%;
}
/* 视频容器单独调整圆角，适配卡片 */
.card .box .imgBx {
  border-radius: 15px;
}
/* 头像和视频内容：铺满容器，保持比例 */
.card .circle .imgBx img,
.card .box .imgBx video {
  position: absolute;
  width: 100%;
  height: 100%;
  object-fit: cover;
}
/* 信息区域布局：居中排列，内边距调整 */
.card .box .content{
  position: absolute;
  inset: 0;
  padding: 30px 10px 20px;
  display: flex;
  align-items: center;
  flex-direction: column;
  gap: 20px;
}
/* 姓名样式：排版调整，颜色区分 */
.card .box .content h2{
  width: 100%;
  padding-left: 120px;
  text-transform: uppercase;
  font-size: 1.15em;
  letter-spacing: 0.1em;
  font-weight: 600;
  line-height: 1.1em;
  color: #333;
}
/* 身份文字：字号和颜色调整 */
.card .box .content h2 span {
  font-size: 0.75em;
  font-weight: 400;
  letter-spacing: 0.05em;
  color: #e91e63;
  text-transform: initial;
}
/* 数据统计列表：网格布局，均分宽度 */
.card .box .content ul {
  position: relative;
  top: 15px;
  display: grid;
  grid-template-columns: repeat(3, 1fr);
  width: 100%;
  padding: 0 10px;
  justify-content: space-evenly;
}
/* 列表项样式：纵向排列，文字颜色区分 */
.card .box .content ul li {
  list-style: none;
  display: flex;
  flex-direction: column;
  text-align: center;
  padding: 0 10px;
  font-size: 0.85em;
  font-weight: 500;
  color: #999;
}
/* 列表项分隔线：除最后一个外，右侧加边框 */
.card .box .content ul li:not(:last-child) {
  border-right: 1px solid #ccc;
}
/* 数据数字：字号放大，颜色加深 */
.card .box .content ul li span {
  font-size: 1.65em;
  color: #333;
}
/* 关注按钮样式：圆角、阴影、边框营造层次感 */
.card .box .content button {
  position: relative;
  top: 25px;
  padding: 8px 30px;
  border: none;
  outline: none;
  background: #03a9f4;
  border-radius: 30px;
  color: #fff;
  font-size: 1em;
  letter-spacing: .2em;
  text-transform: uppercase;
  font-weight: 500;
  cursor: pointer;
  border: 5px solid var(--clr);
  box-shadow: 0 0 0 10px #fff;
  transition: 0.5s;
}
/* 按钮hover效果：文字间距变大，背景色改变 */
.card .box .content button:hover{
  letter-spacing: 0.5em;
  background: #ff3d7f;
}
/* 按钮左侧倒圆角伪元素 */
.card .box .content button::before{
  content: "";
  position: absolute;
  top: 24px;
  left: -29px;
  width: 20px;
  height: 20px;
  background: transparent;
  border-top-right-radius: 20px;
  box-shadow: 5px -7px #fff;
}
/* 按钮右侧倒圆角伪元素 */
.card .box .content button::after{
  content: "";
  position: absolute;
  top: 24px;
  right: -29px;
  width: 20px;
  height: 20px;
  background: transparent;
  border-top-left-radius: 20px;
  box-shadow: -5px -7px #fff;
}</code></pre><p>替换里面的cover.mp4和user.png为自己的素材就能直接用，核心的倒圆角效果都在伪元素的box-shadow那里，调整数值还能改倒圆角的大小，感兴趣的可以自己试试。</p><blockquote>写着写着就到了结尾，祝您今晚有个好梦（代码少报错一点）。</blockquote><p>本文由<a href="https://link.segmentfault.com/?enc=c1wjZD389EcEr7dehqT7Kg%3D%3D.EFklvSFvmdogktkdMevzUAvBy7Q4wpP4FtnYtrz41Pg%3D" rel="nofollow" target="_blank">mdnice</a>多平台发布</p>]]></description></item><item>    <title><![CDATA[全知科技携手温州银行入选“数据安全合规治理实践与创新案例” 全知科技 ]]></title>    <link>https://segmentfault.com/a/1190000047571571</link>    <guid>https://segmentfault.com/a/1190000047571571</guid>    <pubDate>2026-01-26 10:02:21</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047545249" alt="图片" title="图片"/><br/>1月16日，由《网络安全与数据治理》期刊理事会主办的“数据安全合规治理实践与创新案例”颁奖仪式在北京成功举办。本次评选经过案例征集、初审筛选、专家评审与集中合议等多个环节，最终从众多参评项目中遴选出16个具有代表性的优秀企业案例。全知科技联合温州银行申报的“基于自动化建模与智能降噪的数据安全风险监测案例”从众多参评项目中脱颖而出，成功入选“数据安全合规治理实践与创新案例”，标志着双方在金融数据安全合规治理关键技术与应用模式上实现了重要突破。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047571573" alt="图片" title="图片" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571574" alt="图片" title="图片" loading="lazy"/><br/>本次评选围绕数据安全治理在真实业务场景中的落地能力与创新价值，重点关注治理体系建设、风险防控机制、技术支撑能力及实施成效等维度，旨在发掘和推广一批具有行业代表性、技术先进性和实践指导性的优秀案例，为各行各业的数据安全建设工作提供参考与借鉴。<br/>此次，全知科技与温州银行联合打造的“基于自动化建模与智能降噪的数据安全风险监测案例”，以数据为核心，构建“资产可视、流转可见、风险可察、使用可管、共享可溯”五层立体防护体系。该案例从“高感知、高智能、高效用”出发，覆盖170余种数据标签、30余种风险场景，100余种异常指标，实现自动化研判并生成工单派发，显著提升安全运营效率的同时，重点聚焦以数据为中心建立资产台账、以账号为基底关联数据行为、以智能化为助手降低风险误报等主要方向，打通用户、应用、接口层的同时，借助本地大模型驱动的监测敏感数据，完善实时风险监测机制，创新多视角用户行为基线，定位数据滥用。系统内置的风险规则引擎沉淀50余种金融专属场景，搭配智能算法库，更是大幅提升了风险识别准确率，为数据安全流通提供可推广的标杆解决方案。<br/>作为数据安全领域的重要参与者，全知科技始终坚持“技术驱动、安全赋能”的发展理念，持续深耕数据治理与风险防控核心能力建设。此次联合温州银行案例成功入选权威案例集，不仅体现了全知科技在金融行业数据安全合规治理中的成熟方法论，也验证了其将技术能力转化为可落地、可运营解决方案的实践价值。在此基础上，全知科技不断将实践经验反哺行业标准与技术规范建设，牵头制定的国家标准《数据安全技术 数据接口安全风险监测方法》已正式发布，实现了从“工程实践”到“标准输出”的双向突破与验证。未来，全知科技将继续以标准为引领，以场景为牵引，持续推动数据安全治理能力在更多行业与领域中落地生根，助力数字经济安全、稳健、高质量发展。</p>]]></description></item><item>    <title><![CDATA[如何在 CentOS 主机上配置集中式 Syslog 服务器 运维有小邓 ]]></title>    <link>https://segmentfault.com/a/1190000047571578</link>    <guid>https://segmentfault.com/a/1190000047571578</guid>    <pubDate>2026-01-26 10:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>分析 Linux/Unix 系统及其他网络设备生成的系统日志（Syslog），是IT管理员的核心工作内容之一。为提升日志分析的效率，管理员通常会采用日志集中采集的方式。本文详细介绍将 CentOS 系统配置为 rsyslog 集中采集服务器的具体步骤。</p><p>Rsyslog 服务在 CentOS 8 系统中为默认预装状态。你可在终端执行以下命令，检查服务运行状态：</p><p>$ systemctl status rsyslog</p><p>若命令返回的服务状态不为 Active: active (running)（运行中），请在终端执行以下命令安装 rsyslog：</p><p>$ sudo yum install rsyslog</p><p>如需通过 UDP 和 TCP 协议接收来自其他设备的系统日志，需编辑配置文件 /etc/rsyslog.conf，取消对应配置项的注释，以启用 TCP 和 UDP 监听功能。</p><p>•启用 UDP 协议：取消以下配置行的注释<br/>module(load="imudp")  #needs to be done just once<br/>input(type="imudp" port="514")</p><p>•启用 TCP 协议：取消以下配置行的注释<br/>module(load="imtcp")  #needs to be done just once<br/>input(type="imtcp" port="514")</p><p><strong>注意</strong></p><p>514 是 UDP 和 TCP 协议的默认监听端口，你可根据实际需求修改端口号。</p><p>保存配置并退出编辑界面。</p><p>确保客户端主机能够识别并与已配置的 rsyslog 服务器通信。为开放通信端口，需在防火墙中放行 514 端口，执行以下命令：</p><p>$ sudo firewall-cmd  --add-port=514/tcp  --zone=public  --permanent<br/>重新加载防火墙配置，使规则生效：</p><p>$ sudo firewall-cmd  --reload<br/>重启 rsyslog 服务，并执行以下命令，检查服务器是否已在 514 端口监听：</p><p>$ sudo netstat  -pnltu<br/>若配置成功，你会看到 514 端口的状态显示为 LISTEN（监听中）。</p><p>至此，基于 CentOS 系统的集中式 Syslog 采集服务器已配置完成。如需实时查看已采集的日志，可在服务器端执行以下命令：</p><p>$ tail  -f /var/log/messages</p><h2>如何监控 rsyslog 日志文件</h2><p>监控系统日志文件至关重要，这些日志可直观反映网络活动的详细情况，包括事件涉及的 IP 地址、时间戳、具体操作行为，以及对系统执行的关键配置变更等信息。</p><p>但手动监控 rsyslog 日志文件耗时费力，且难以实现高效的日志分析。通过专业的日志管理解决方案监控 rsyslog 日志，能够对日志数据进行深度解析。</p><p>EventLog Analyzer 是一款功能完善的日志管理工具，它可实现海量 rsyslog 数据的采集、解析、索引与分析，并生成可视化的统计报告。</p><p>工具会自动将检测到的恶意行为标记为安全威胁，并通过短信或邮件触发实时告警，及时通知 IT 安全管理员防范潜在的网络攻击。</p>]]></description></item><item>    <title><![CDATA[跟老卫学仓颉编程语言开发：统计字符串的字符数 waylau ]]></title>    <link>https://segmentfault.com/a/1190000047571174</link>    <guid>https://segmentfault.com/a/1190000047571174</guid>    <pubDate>2026-01-26 09:02:19</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>任务要求：给定一个字符串“ILoveCangjie”，编写一个仓颉应用程序，来统计该字符串的字符数。</p><h3>习题解题思路1</h3><p>练习步骤：</p><ul><li>定义字符串变量s；</li><li>遍历该变量s里面的字符。可以使用字符串的toArray()函数将字符串转为字节数组；</li><li>每遍历一次，即统计了一次字符数；</li><li>打印最终的遍历次数，即得出了该字符串的字符数。</li></ul><p>代码参考：见“count_the_number_of_characters”应用。</p><h3>习题解题思路2</h3><p>字符串的size属性，可以直接获取字符串 UTF-8 编码后的字节长度。</p><pre><code>public prop size: Int64</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047571176" alt="" title=""/></p><h3>参考引用</h3><ul><li>示例源码，见免费开源书<a href="https://link.segmentfault.com/?enc=in5fgjKitkXRcI%2BCdL6ipg%3D%3D.7vuniyIp76y2iZpRWfB9DXNhS6Fe9V6oNeTZkLbRzkV%2BRB4N6i%2Bvfq9kokzEoYjmjH%2FgTk403NkQzK6ChlD80A%3D%3D" rel="nofollow" target="_blank">《跟老卫学仓颉编程语言开发》</a></li><li>免费开源书<a href="https://link.segmentfault.com/?enc=VY1LZ69F8ZUOVMMAATRfSA%3D%3D.qiiSXH7JJcvrxVE%2F1v99Ltn4rJO76z%2Bz6EvsSzho14z1Wfl3vOAL9wuHLozkSnNB" rel="nofollow" target="_blank">《跟老卫学HarmonyOS开发》</a></li><li><a href="https://link.segmentfault.com/?enc=LJMHj6QES2JN9YLRXrLMQg%3D%3D.l9n9rzfTbU8SNyNj%2BQUzB37YKfHxFIBa8tKjHz2YZYgWlpcv42jbfVDCGwuoeuRv" rel="nofollow" target="_blank">HarmonyOS NEXT+AI大模型打造智能助手APP（仓颉版）</a>（视频）</li><li><a href="https://link.segmentfault.com/?enc=%2Fegp%2B2vmGO9DSAfpnxg3kA%3D%3D.ZYoyxRjg1dkZaqNnNLFbxH1A2zWMR6fProYakENUCrhObZwGr7Jyg0053tUutWUHMFTfrNyoL8u0%2BGcfReppM9F4go%2Bujh0pOuz5LIe0aLU%3D" rel="nofollow" target="_blank">仓颉编程从入门到实践</a>（北京大学出版社）</li></ul>]]></description></item><item>    <title><![CDATA[CopyOnWriteArrayList：写时复制机制与高效并发访问 SevenCoding ]]></title>    <link>https://segmentfault.com/a/1190000047570524</link>    <guid>https://segmentfault.com/a/1190000047570524</guid>    <pubDate>2026-01-26 09:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>前言</h2><p>Vector无论是add方法还是get方法都加上了<a href="https://link.segmentfault.com/?enc=US8hubJkr%2FeLMZBjo9P29A%3D%3D.Ve9aSwSVyHGrf14sunE5XQKb5VnLDZ9IMb%2Bh%2BTpoxNydBYYkm9yI0v032B8FQtZqMfD7OkG3wyHJmIG1NCEDa%2FJbwjiRo4vmtJQL2bOPCG4%3D" rel="nofollow" target="_blank"><strong>synchronized</strong></a>修饰，当多线程读写List必须排队执行，很显然这样效率比较是低下的，CopyOnWriteArrayList是读写分离的，好处是提高线程访问效率。</p><p>CopyOnWrite容器即<strong>写时复制</strong>的容器。通俗的理解是当往一个容器添加元素的时候，不直接往当前容器添加，而是先将当前容器里的值Copy到新的容器，然后再往新的容器里添加元素，添加完元素之后，再将原容器的引用指向新的容器。这样做的好处是我们可以对CopyOnWrite容器进行并发的读 要加锁，因为当前容器不会添加任何元素。所以CopyOnWrite容器也是一种读写分离的思想，读和写不同的容器。</p><h2>底层原理</h2><ol><li>CopyOnWriteArrayList的动态数组机制 -- 它内部有个volatile数组(array)来保持数据。在“添加/删除”数据时，都会新建一个数组，并将更新后的数据拷贝到新建的数组中，最后再将该数组赋值给volatile数组。这就是它叫做CopyOnWriteArrayList的原因！</li><li>每一个CopyOnWriteArrayList都和一个监视器锁lock绑定，通过lock，实现了对CopyOnWriteArrayList的互斥添加/删除。</li></ol><h3>类的继承关系</h3><p>CopyOnWriteArrayList实现了List接口，List接口定义了对列表的基本操作；同时实现了RandomAccess接口，表示可以随机访问(数组具有随机访问的特性)；同时实现了Cloneable接口，表示可克隆；同时也实现了Serializable接口，表示可被序列化。</p><pre><code class="java">public class CopyOnWriteArrayList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable {}</code></pre><h3>类的内部类</h3><ul><li>COWIterator类</li></ul><p>COWIterator表示迭代器，其也有一个Object类型的数组作为CopyOnWriteArrayList数组的快照，这种快照风格的迭代器方法在创建迭代器时使用了对当时数组状态的引用。此数组在迭代器的生存期内不会更改，因此不可能发生冲突，并且迭代器保证不会抛出 ConcurrentModificationException。创建迭代器以后，迭代器就不会反映列表的添加、移除或者更改。在迭代器上进行的元素更改操作(remove、set 和 add)不受支持。这些方法将抛出 UnsupportedOperationException。</p><pre><code class="java">static final class COWIterator&lt;E&gt; implements ListIterator&lt;E&gt; {
    /** Snapshot of the array */
    // 快照
    private final Object[] snapshot;
    /** Index of element to be returned by subsequent call to next.  */
    // 游标
    private int cursor;
    // 构造函数
    private COWIterator(Object[] elements, int initialCursor) {
        cursor = initialCursor;
        snapshot = elements;
    }
    // 是否还有下一项
    public boolean hasNext() {
        return cursor &lt; snapshot.length;
    }
    // 是否有上一项
    public boolean hasPrevious() {
        return cursor &gt; 0;
    }
    // next项
    @SuppressWarnings("unchecked")
    public E next() {
        if (! hasNext()) // 不存在下一项，抛出异常
            throw new NoSuchElementException();
        // 返回下一项
        return (E) snapshot[cursor++];
    }

    @SuppressWarnings("unchecked")
    public E previous() {
        if (! hasPrevious())
            throw new NoSuchElementException();
        return (E) snapshot[--cursor];
    }
    
    // 下一项索引
    public int nextIndex() {
        return cursor;
    }
    
    // 上一项索引
    public int previousIndex() {
        return cursor-1;
    }

    /**
        * Not supported. Always throws UnsupportedOperationException.
        * @throws UnsupportedOperationException always; {@code remove}
        *         is not supported by this iterator.
        */
    // 不支持remove操作
    public void remove() {
        throw new UnsupportedOperationException();
    }

    /**
        * Not supported. Always throws UnsupportedOperationException.
        * @throws UnsupportedOperationException always; {@code set}
        *         is not supported by this iterator.
        */
    // 不支持set操作
    public void set(E e) {
        throw new UnsupportedOperationException();
    }

    /**
        * Not supported. Always throws UnsupportedOperationException.
        * @throws UnsupportedOperationException always; {@code add}
        *         is not supported by this iterator.
        */
    // 不支持add操作
    public void add(E e) {
        throw new UnsupportedOperationException();
    }

    @Override
    public void forEachRemaining(Consumer&lt;? super E&gt; action) {
        Objects.requireNonNull(action);
        Object[] elements = snapshot;
        final int size = elements.length;
        for (int i = cursor; i &lt; size; i++) {
            @SuppressWarnings("unchecked") E e = (E) elements[i];
            action.accept(e);
        }
        cursor = size;
    }
}</code></pre><h3>类的属性</h3><p>属性中有一个可重入锁，用来保证线程安全访问，还有一个Object类型的数组，用来存放具体的元素。当然，也使用到了反射机制和CAS来保证原子性的修改lock域。</p><pre><code class="java">public class CopyOnWriteArrayList&lt;E&gt;
    implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable {
    // 版本序列号
    private static final long serialVersionUID = 8673264195747942595L;
    // 可重入锁
    final transient ReentrantLock lock = new ReentrantLock();
    // 对象数组，用于存放元素
    private transient volatile Object[] array;
    // 反射机制
    private static final sun.misc.Unsafe UNSAFE;
    // lock域的内存偏移量
    private static final long lockOffset;
    static {
        try {
            UNSAFE = sun.misc.Unsafe.getUnsafe();
            Class&lt;?&gt; k = CopyOnWriteArrayList.class;
            lockOffset = UNSAFE.objectFieldOffset
                (k.getDeclaredField("lock"));
        } catch (Exception e) {
            throw new Error(e);
        }
    }
}</code></pre><h3>类的构造函数</h3><ul><li>默认构造函数</li></ul><pre><code class="java">public CopyOnWriteArrayList() {
    // 设置数组
    setArray(new Object[0]);
}</code></pre><ul><li>CopyOnWriteArrayList(Collection&lt;? extends E&gt;)</li></ul><pre><code class="java">public CopyOnWriteArrayList(Collection&lt;? extends E&gt; c) {
    Object[] elements;
    if (c.getClass() == CopyOnWriteArrayList.class) // 类型相同
        // 获取c集合的数组
        elements = ((CopyOnWriteArrayList&lt;?&gt;)c).getArray();
    else { // 类型不相同
        // 将c集合转化为数组并赋值给elements
        elements = c.toArray();
        // c.toArray might (incorrectly) not return Object[] (see 6260652)
        if (elements.getClass() != Object[].class) // elements类型不为Object[]类型
            // 将elements数组转化为Object[]类型的数组
            elements = Arrays.copyOf(elements, elements.length, Object[].class);
    }
    // 设置数组
    setArray(elements);
}
</code></pre><p>该构造函数的处理流程如下</p><ol><li>判断传入的集合c的类型是否为CopyOnWriteArrayList类型，若是，则获取该集合类型的底层数组(Object[])，并且设置当前CopyOnWriteArrayList的数组(Object[]数组)，进入步骤③；否则，进入步骤②</li><li>将传入的集合转化为数组elements，判断elements的类型是否为Object[]类型(toArray方法可能不会返回Object类型的数组)，若不是，则将elements转化为Object类型的数组。进入步骤③</li><li>设置当前CopyOnWriteArrayList的Object[]为elements。</li></ol><ul><li>CopyOnWriteArrayList(E[])：该构造函数用于创建一个保存给定数组的副本的列表。</li></ul><pre><code class="java">public CopyOnWriteArrayList(E[] toCopyIn) {
    // 将toCopyIn转化为Object[]类型数组，然后设置当前数组
    setArray(Arrays.copyOf(toCopyIn, toCopyIn.length, Object[].class));
}</code></pre><h3>核心函数分析</h3><p>对于CopyOnWriteArrayList的函数分析，主要明白Arrays.copyOf方法即可理解CopyOnWriteArrayList其他函数的意义。</p><h4>copyOf函数</h4><p>该函数用于复制指定的数组，截取或用 null 填充(如有必要)，以使副本具有指定的长度。</p><pre><code class="java">public static &lt;T,U&gt; T[] copyOf(U[] original, int newLength, Class&lt;? extends T[]&gt; newType) {
    @SuppressWarnings("unchecked")
    // 确定copy的类型(将newType转化为Object类型，将Object[].class转化为Object类型；
    // 判断两者是否相等，若相等，则生成指定长度的Object数组
    // 否则,生成指定长度的新类型的数组)
    T[] copy = ((Object)newType == (Object)Object[].class)
        ? (T[]) new Object[newLength]
        : (T[]) Array.newInstance(newType.getComponentType(), newLength);
    // 将original数组从下标0开始，复制长度为(original.length和newLength的较小者),复制到copy数组中(也从下标0开始)
    System.arraycopy(original, 0, copy, 0,
                        Math.min(original.length, newLength));
    return copy;
}</code></pre><h4>add函数</h4><pre><code class="java">public boolean add(E e) {
    // 可重入锁
    final ReentrantLock lock = this.lock;
    // 获取锁
    lock.lock();
    try {
        // 元素数组
        Object[] elements = getArray();
        // 数组长度
        int len = elements.length;
        // 复制数组
        Object[] newElements = Arrays.copyOf(elements, len + 1);
        // 存放元素e
        newElements[len] = e;
        // 设置数组
        setArray(newElements);
        return true;
    } finally {
        // 释放锁
        lock.unlock();
    }
}</code></pre><p>此函数用于将指定元素添加到此列表的尾部，处理流程如下</p><ol><li>获取锁(保证多线程的安全访问)，获取当前的Object数组，获取Object数组的长度为length，进入步骤②。</li><li>根据Object数组复制一个长度为length+1的Object数组为newElements(此时，newElements[length]为null)，进入下一步骤。</li><li>将下标为length的数组元素newElements[length]设置为元素e，再设置当前Object[]为newElements，释放锁，返回。这样就完成了元素的添加。</li></ol><h4>addIfAbsent方法</h4><p>该函数用于添加元素(如果数组中不存在，则添加；否则，不添加，直接返回)，可以保证多线程环境下不会重复添加元素。</p><pre><code class="java">private boolean addIfAbsent(E e, Object[] snapshot) {
    // 重入锁
    final ReentrantLock lock = this.lock;
    // 获取锁
    lock.lock();
    try {
        // 获取数组
        Object[] current = getArray();
        // 数组长度
        int len = current.length;
        if (snapshot != current) { // 快照不等于当前数组，对数组进行了修改
            // Optimize for lost race to another addXXX operation
            // 取较小者
            int common = Math.min(snapshot.length, len);
            for (int i = 0; i &lt; common; i++) // 遍历
                if (current[i] != snapshot[i] &amp;&amp; eq(e, current[i])) // 当前数组的元素与快照的元素不相等并且e与当前元素相等
                    // 表示在snapshot与current之间修改了数组，并且设置了数组某一元素为e，已经存在
                    // 返回
                    return false;
            if (indexOf(e, current, common, len) &gt;= 0) // 在当前数组中找到e元素
                // 返回
                return false;
        }
        // 复制数组
        Object[] newElements = Arrays.copyOf(current, len + 1);
        // 对数组len索引的元素赋值为e
        newElements[len] = e;
        // 设置数组
        setArray(newElements);
        return true;
    } finally {
        // 释放锁
        lock.unlock();
    }
}</code></pre><p>该函数的流程如下:</p><ol><li>获取锁，获取当前数组为current，current长度为len，判断数组之前的快照snapshot是否等于当前数组current，若不相等，则进入步骤2；否则，进入步骤4</li><li>不相等，表示在snapshot与current之间，对数组进行了修改(如进行了add、set、remove等操作)，获取长度(snapshot与current之间的较小者)，对current进行遍历操作，若遍历过程发现snapshot与current的元素不相等并且current的元素与指定元素相等(可能进行了set操作)，进入步骤5，否则，进入步骤3</li><li>在当前数组中索引指定元素，若能够找到，进入步骤5，否则，进入步骤4</li><li>复制当前数组current为newElements，长度为len+1，此时newElements[len]为null。再设置newElements[len]为指定元素e，再设置数组，进入步骤5</li><li>释放锁，返回。</li></ol><h4>set函数</h4><p>此函数用于用指定的元素替代此列表指定位置上的元素，也是基于数组的复制来实现的。</p><pre><code class="java">public E set(int index, E element) {
    // 可重入锁
    final ReentrantLock lock = this.lock;
    // 获取锁
    lock.lock();
    try {
        // 获取数组
        Object[] elements = getArray();
        // 获取index索引的元素
        E oldValue = get(elements, index);

        if (oldValue != element) { // 旧值等于element
            // 数组长度
            int len = elements.length;
            // 复制数组
            Object[] newElements = Arrays.copyOf(elements, len);
            // 重新赋值index索引的值
            newElements[index] = element;
            // 设置数组
            setArray(newElements);
        } else {
            // Not quite a no-op; ensures volatile write semantics
            // 设置数组
            setArray(elements);
        }
        // 返回旧值
        return oldValue;
    } finally {
        // 释放锁
        lock.unlock();
    }
}</code></pre><h4>remove函数</h4><p>此函数用于移除此列表指定位置上的元素。</p><pre><code class="java">public E remove(int index) {
    // 可重入锁
    final ReentrantLock lock = this.lock;
    // 获取锁
    lock.lock();
    try {
        // 获取数组
        Object[] elements = getArray();
        // 数组长度
        int len = elements.length;
        // 获取旧值
        E oldValue = get(elements, index);
        // 需要移动的元素个数
        int numMoved = len - index - 1;
        if (numMoved == 0) // 移动个数为0
            // 复制后设置数组
            setArray(Arrays.copyOf(elements, len - 1));
        else { // 移动个数不为0
            // 新生数组
            Object[] newElements = new Object[len - 1];
            // 复制index索引之前的元素
            System.arraycopy(elements, 0, newElements, 0, index);
            // 复制index索引之后的元素
            System.arraycopy(elements, index + 1, newElements, index,
                                numMoved);
            // 设置索引
            setArray(newElements);
        }
        // 返回旧值
        return oldValue;
    } finally {
        // 释放锁
        lock.unlock();
    }
}</code></pre><p>处理流程如下</p><ol><li>获取锁，获取数组elements，数组长度为length，获取索引的值elements[index]，计算需要移动的元素个数(length - index - 1),若个数为0，则表示移除的是数组的最后一个元素，复制elements数组，复制长度为length-1，然后设置数组，进入步骤③；否则，进入步骤②</li><li>先复制index索引前的元素，再复制index索引后的元素，然后设置数组。</li><li>释放锁，返回旧值</li><li/></ol><h2>CopyOnWriteArrayList是Fail Safe的</h2><p>采用安全失败机制的集合容器，在遍历时不是直接在集合内容上访问的，而是先复制原有集合内容，在拷贝的集合上进行遍历。java.util.concurrent包下的容器都是安全失败，可以在多线程下并发使用，并发修改。</p><p>原理：由于迭代时是对原集合的拷贝进行遍历，所以在遍历过程中对原集合所作的修改并不能被迭代器检测到，所以不会触发Concurrent Modification Exception。</p><p>缺点：基于拷贝内容的优点是避免了Concurrent Modification Exception，但同样地，迭代器并不能访问到修改后的内容，即：迭代器遍历的是开始遍历那一刻拿到的集合拷贝，在遍历期间原集合发生的修改迭代器是不知道的。</p><p>Vector无论是add方法还是get方法都加上了<strong>synchronized</strong>修饰，当多线程读写List必须排队执行，很显然这样效率比较是低下的，CopyOnWriteArrayList是读写分离的，好处是提高线程访问效率。</p><h2>缺陷和使用场景</h2><ul><li>CopyOnWriteArrayList的写效率比Vector慢。当CopyOnWriteArrayList写元素时是通过备份数组的方式实现的，当多线程同步激烈，数据量较大时会不停的<strong>复制数组，内存浪费严重</strong>。如果原数组的内容比较多的情况下，可能导致young gc或者full gc</li><li>弱一致性：不能用于实时读的场景，像拷贝数组、新增元素都需要时间，所以调用一个set操作后，读取到数据可能还是旧的，虽然CopyOnWriteArrayList 能做到最终一致性，但是还是没法满足实时性要求；</li></ul><p><strong>小结：</strong> CopyOnWriteArrayList合适读多写少的场景，例如黑名单白名单等</p>]]></description></item><item>    <title><![CDATA[HarmonyOS 6 智能带办应用开发之华日历接入实践 轻口味 ]]></title>    <link>https://segmentfault.com/a/1190000047570205</link>    <guid>https://segmentfault.com/a/1190000047570205</guid>    <pubDate>2026-01-26 07:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h4>背景介绍</h4><p>前段时间上架的“智能带办”鸿蒙应用，应用亮点是根据用户输入要做的事情自动自动生成需要带的东西。在使用过程中发现有些东西不能立马拿到的需要在未来某个时刻拿的需要提醒。重新设计产品时发现，自己实现提醒功能还是挺复杂的，如果用云端方案接入通知方式不仅复杂而且可控性太差。这个时候想到接入日程，通过系统能力来实现功能。</p><p>接入后向左滑动待办物品，出现日历按钮，效果如图：<br/><img width="400" height="827" referrerpolicy="no-referrer" src="/img/bVdnLlv" alt="image.png" title="image.png"/></p><p>点击按钮弹出日程计划日期和时间：<br/><img width="395" height="847" referrerpolicy="no-referrer" src="/img/bVdnLlw" alt="image.png" title="image.png" loading="lazy"/><br/>选择完日期和事件自动自动完成日程创建。下面先介绍鸿蒙日历能力。</p><h4>鸿蒙日历📅 能力介绍</h4><h5>简介</h5><p>HarmonyOS 的 Calendar Kit（日历服务）是一套系统级的日程管理接口，旨在将出行、餐饮、运动等各类与时间相关的服务与系统日历无缝集成，实现统一的时间视图与提醒能力。核心能力如下：</p><ul><li>账户管理：支持创建、查询和删除日历账户。应用可创建专属账户（返回唯一 <code>accountId</code>），删除账户将同时清除其下所有日程。</li><li>日程管理 (CRUD)：在指定账户下，支持日程的全生命周期管理，包括创建（返回唯一 <code>eventId</code>）、删除、更新和查询。创建时可设置标题、时间、地点、提醒及重复规则等属性。</li><li>一键服务：通过永久性授权，可将带 DeepLink 的“一键服务”写入日历。当日程临近或到期，系统会在日历、通知、卡片等位置展示服务按钮，用户点击即可直达服务页面，实现从“看到日程”到“完成服务”的闭环。<br/>我们的应用主要用到账户和日程管理，使用日历需要如下权限：</li></ul><table><thead><tr><th>申请权限</th><th>支持的日历账户操作范围</th><th>支持的日程操作范围</th></tr></thead><tbody><tr><td><code>ohos.permission.READ_CALENDAR</code></td><td>读取系统默认及当前应用创建的日历账户。</td><td>读取上述账户下当前应用创建的日程。</td></tr><tr><td><code>ohos.permission.WRITE_CALENDAR</code></td><td>增、删、改当前应用创建的日历账户。</td><td>增、删、改上述账户下当前应用创建的日程。</td></tr><tr><td><code>ohos.permission.READ_WHOLE_CALENDAR</code></td><td>读取设备上所有日历账户。</td><td>读取所有应用创建的日程。</td></tr><tr><td><code>ohos.permission.WRITE_WHOLE_CALENDAR</code></td><td>增、删、改设备上所有日历账户。</td><td>增、删、改所有应用创建的日程。</td></tr></tbody></table><p>我们只需要读取我们自己应用创建的日历账号下日程即可，所以申请前两个权限即可。</p><h5>账户管理</h5><p>日历账户‌用于存储和管理个人或团队的日程，通过日历账户，用户可以方便地查看、编辑和共享日程信息。日历管理器CalendarManager用于管理日历账户Calendar。日历账户主要包含账户信息CalendarAccount和配置信息CalendarConfig。</p><p>我们可以创建属于应用特有的日历账户，还可以对日历账户进行新增、删除、更新和查询。此外，每个日程Event归属于某一个特定的日历账户，可以通过日历账户对账户下面的日程进行管理。</p><p><code>@ohos.calendarManager</code>提供了日历账户管理的相关接口，常用到的接口如下表：</p><table><thead><tr><th align="left">接口名称</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left">getCalendarManager(context: Context): CalendarManager</td><td align="left">根据上下文获取日历管理器对象CalendarManager，用于管理日历。</td></tr><tr><td align="left">createCalendar(calendarAccount: CalendarAccount): Promise&lt;Calendar&gt;</td><td align="left">根据日历账户信息，创建一个Calendar对象，使用Promise异步回调。</td></tr><tr><td align="left">getCalendar(calendarAccount?: CalendarAccount): Promise&lt;Calendar&gt;</td><td align="left">获取默认Calendar对象或者指定Calendar对象，使用Promise异步回调。<br/><br/>默认Calendar是日历存储首次运行时创建的，若创建Event时不关注其Calendar归属，则无须通过createCalendar()创建Calendar，直接使用默认Calendar。</td></tr><tr><td align="left">getAllCalendars(): Promise&lt;Calendar[]&gt;</td><td align="left">获取当前应用所有创建的Calendar对象以及默认Calendar对象，使用Promise异步回调。</td></tr><tr><td align="left">deleteCalendar(calendar: Calendar): Promise&lt;void&gt;</td><td align="left">删除指定Calendar对象，使用Promise异步回调。</td></tr><tr><td align="left">getConfig(): CalendarConfig</td><td align="left">获取日历配置信息。</td></tr><tr><td align="left">setConfig(config: CalendarConfig): Promise&lt;void&gt;</td><td align="left">设置日历配置信息，使用Promise异步回调。</td></tr><tr><td align="left">getAccount(): CalendarAccount</td><td align="left">获取日历账户信息。</td></tr></tbody></table><h5>日程管理</h5><p>日程指特定的事件或者活动安排，日程管理即对这些事件、活动进行规划和控制，能更有效地利用相关资源、提高生产力和效率，使人们更好地管理时间和任务。Calendar Kit中的日程Event归属于某个对应的日历账户Calendar，一个日历账户下可以有多个日程，一个日程只属于一个Calendar。取到日历账户对象之后，即可对该账户下的日程进行管理，包括日程的创建、删除、修改、查询等操作。在创建、修改日程时，支持对日程的标题、开始时间、结束时间、日程类型、日程地点、日程提醒时间、日程重复规则等相关信息进行设置，以便进行更丰富更有效的日程管理。</p><p><code>@ohos.calendarManager</code>提供了日程管理的相关接口，常用到的接口如下表：</p><table><thead><tr><th align="left">接口名称</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left">getCalendarManager(context: Context): CalendarManager</td><td align="left">根据上下文获取CalendarManager对象，用于管理日历。</td></tr><tr><td align="left">createCalendar(calendarAccount: CalendarAccount): Promise&lt;Calendar&gt;</td><td align="left">根据日历账户信息，创建一个Calendar对象，使用Promise异步回调。</td></tr><tr><td align="left">addEvent(event: Event): Promise&lt;number&gt;</td><td align="left">创建日程，入参Event不填日程id，使用Promise异步回调。</td></tr><tr><td align="left">editEvent(event: Event): Promise&lt;number&gt;</td><td align="left">通过跳转到日程创建界面创建单个日程，入参Event不填日程id，使用Promise异步回调。</td></tr><tr><td align="left">deleteEvent(id: number): Promise&lt;void&gt;</td><td align="left">删除指定日程id的日程，使用Promise异步回调。</td></tr><tr><td align="left">updateEvent(event: Event): Promise&lt;void&gt;</td><td align="left">更新日程，使用Promise异步回调。</td></tr><tr><td align="left">getEvents(eventFilter?: EventFilter, eventKey?: (keyof Event)[]): Promise&lt;Event[]&gt;</td><td align="left">获取Calendar下符合查询条件的Event，使用Promise异步回调。</td></tr></tbody></table><h4>智能带办接入过程</h4><h5>1、导入依赖</h5><p>接入账号管理，首先需要导入相关依赖：</p><pre><code class="ts">import { abilityAccessCtrl, AbilityConstant, common, PermissionRequestResult, Permissions, UIAbility, Want } from '@kit.AbilityKit';
import { calendarManager } from '@kit.CalendarKit';</code></pre><h5>2、创建日历管理类</h5><pre><code class="ts">  
const TAG = 'CalendarService';  
  
/**  
 * Service to manage Calendar Kit operations. */
   export class CalendarService {  
  private static calendar: calendarManager.Calendar | undefined = undefined;  
  //账号信息
  private static readonly calendarAccount: calendarManager.CalendarAccount = {  
    name: 'IntelligentTodo',  
    type: calendarManager.CalendarType.LOCAL,  
    displayName: '智能带办'  
  };  
  
  /**  
   * 添加日程到日历
   * @param title The title of the todo.  
   * @param description The description of the todo.  
   * @param startTime The start time (milliseconds).   * @param endTime The end time (milliseconds).   * @returns The event ID.    */  
     public static async addEvent(title: string, description: string, startTime: number, endTime: number): Promise&lt;number&gt; {  
    const mgr = AppStorage.get&lt;calendarManager.CalendarManager&gt;('calendarMgr');  
    if (!mgr) {  
      Logger.e(TAG, 'calendarMgr is not initialized in AppStorage');  
      throw new Error('日历服务未准备就绪');  
    }  
  
    // Request permissions first  
    const context = AppStorage.get&lt;common.UIAbilityContext&gt;('abilityContext');  
    if (context) {  
      const granted = await CalendarService.checkAndRequestPermissions(context);  
      if (!granted) {  
        throw new Error('未获得日历权限');  
      }  
    }  
    try {  
      if (!CalendarService.calendar) {  
        CalendarService.calendar = await CalendarService.getOrCreateCalendar(mgr);  
      }  
  
      const event: calendarManager.Event = {  
        title: title,  
        description: description,  
        type: calendarManager.EventType.NORMAL,  
        startTime: startTime,  
        endTime: endTime,  
        reminderTime: [10] // Default 10 minutes reminder  
      };  
  
      if (!CalendarService.calendar) {  
        throw new Error('日历对象初始化失败');  
      }  
      const eventId = await CalendarService.calendar.addEvent(event);  
      Logger.i(TAG, `Succeeded in adding event, id -&gt; ${eventId}`);  
      return eventId;  
    } catch (error) {  
      Logger.e(TAG, `Failed to add event: ${JSON.stringify(error)}`);  
      throw new Error(JSON.stringify(error));  
    }  
  }  
  /**  
   * 创建日历对象
   */  
     private static async getOrCreateCalendar(mgr: calendarManager.CalendarManager): Promise&lt;calendarManager.Calendar&gt; {  
    try {  
      // Try to find if our account already exists  
      const calendars = await mgr.getAllCalendars();  
      const existing = calendars.find(c =&gt; {  
        const acc = c.getAccount();  
        return acc.name === CalendarService.calendarAccount.name;  
      });  
      if (existing) {  
        return existing;  
      }  
  
      // Create new account if not exists  
      const newCalendar = await mgr.createCalendar(CalendarService.calendarAccount);  
      const config: calendarManager.CalendarConfig = {  
        enableReminder: true,  
        color: '#aabbcc'  
      };  
      await newCalendar.setConfig(config);  
      return newCalendar;  
    } catch (err) {  
      Logger.e(TAG, `getOrCreateCalendar error: ${JSON.stringify(err)}`);  
      // Fallback to default calendar if creation fails  
      return await mgr.getCalendar();  
    }  
  }  
  /**  
   * 动态获取权限
  */  
     private static async checkAndRequestPermissions(context: common.UIAbilityContext): Promise&lt;boolean&gt; {  
    const permissions: Array&lt;Permissions&gt; = ['ohos.permission.READ_CALENDAR', 'ohos.permission.WRITE_CALENDAR'];  
    const atManager = abilityAccessCtrl.createAtManager();  
    try {  
      const result = await atManager.requestPermissionsFromUser(context, permissions);  
      const grantStatus = result.authResults;  
      return grantStatus.every(s =&gt; s === 0);  
    } catch (err) {  
      Logger.e(TAG, `requestPermissionsFromUser error: ${JSON.stringify(err)}`);  
      return false;  
    }  
  }}</code></pre><p>getOrCreateCalendar根据上下文获取日程管理器对象calendarMgr，用于对日历账户进行相关管理操作。官方推荐在EntryAbility.ets文件中进行操作，我们这里进行独立封装，对权限做到精准控制，在使用时再申请。接着根据日历账户信息，创建一个日历账户Calendar对象。创建日历账户之前，我们需要先根据账户信息进行查询，如果账户不存在则抛出异常信息，捕获到异常再进行日历账户的创建，否则可能会出现账户重复创建的问题。<br/>日历账户创建之后，日历账户颜色默认为黑色，不指定日历账户颜色可能导致部分版本/设备深色模式下显示效果不佳。开发者需要调用setConfig()接口设置日历配置信息，包括是否打开日历账户下的日程提醒能力、设置日历账户颜色。</p><pre><code class="ts">const calendarAccounts: calendarManager.CalendarAccount = {
  name: 'MyCalendar',
  type: calendarManager.CalendarType.LOCAL,
  displayName: 'MyCalendar'
};
// 日历配置信息
calendarMgr?.getCalendar(calendarAccounts, (err, data) =&gt; {
  //获取日历账户
  if (err) {
    hilog.error(DOMAIN, 'testTag', `Failed to get calendar, Code is ${err.code}, message is ${err.message}`);
  } else {
    const config: calendarManager.CalendarConfig = {
      // 打开日程提醒
      enableReminder: true,
      // 设置日历账户颜色
      color: '#aabbcc'
    };
    // 设置日历配置信息
    data.setConfig(config).then(() =&gt; {
      hilog.info(DOMAIN, 'testTag', '%{public}s', `Succeeded in setting config, data-&gt;${JSON.stringify(config)}`);
    }).catch((err: BusinessError) =&gt; {
      hilog.error(DOMAIN, 'testTag', `Failed to set config. Code: ${err.code}, message: ${err.message}`);
    })
  }
});</code></pre><p>addEvent方法封装了在当前日历账户下添加日历日程，注意入参中不需要填写日程id。创建日程时，支持设置日程的标题、开始时间、结束时间、日程类型、日程地点、日程提醒时间、日程重复规则等相关信息。程创建成功后会返回一个日程id，作为日程的唯一标识，后续可按照日程id进行指定日程的更新或删除。<br/>目前支持以下两种方式来创建日程。<br/>方式一：可以在日历账户下通过addEvent()或addEvents()接口创建日程。其中可使用addEvent()接口创建单个日程，也可以使用addEvents()接口批量创建日程，此处以创建单个日程为例。<br/>方式二：在获取到日历管理器对象后，可通过editEvent()接口创建单个日程。调用此接口创建日程时，会跳转到日程创建页面，在日程创建页面进行相关操作完成日程的创建, editEvent()不支持自定义周期性日程创建。</p><p>我们采用方式一，用户点击日程时弹窗日期时间选择器，用户选择时间后调用addEvent方法创建日程。</p><h4>总结</h4><p>本次功能迭代的核心思路是“借力系统能力，优化产品体验”。面对自建提醒功能的复杂性，我们选择接入鸿蒙Calendar Kit，将待办事项转化为系统日程。通过左滑待办项快速创建日程，并利用系统日历实现稳定、统一的提醒。这一方案通过封装<code>CalendarService</code>精准管理权限与账户，既大幅降低了开发复杂度和维护成本，又为用户提供了原生、可靠的提醒服务，是“站在系统肩膀上”高效解决通用需求的典型实践。</p>]]></description></item><item>    <title><![CDATA[为本地部署的大模型添加API Key认证：Nginx实现方案 BugShare ]]></title>    <link>https://segmentfault.com/a/1190000047571092</link>    <guid>https://segmentfault.com/a/1190000047571092</guid>    <pubDate>2026-01-26 00:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在使用 LangChain 开发大模型应用时，我们经常会遇到这样的场景：</p><ul><li>使用在线模型（如 OpenAI、通义千问等）时，自带 API Key 认证机制</li><li>本地部署的 Ollama、vLLM 等模型服务，默认<strong>没有任何认证</strong></li></ul><p>在<strong>本地或局域网</strong>环境下问题还不明显；但一旦你需要：</p><ul><li>将模型服务暴露到公网</li><li>提供给团队其他成员使用</li><li>作为内部 AI 平台或推理服务</li></ul><p>那么“<strong>无认证</strong>”就意味着：</p><blockquote>任何人只要知道地址，就可以无限制地调用你的模型服务。</blockquote><p>这不仅有安全风险，还可能带来<strong>资源滥用和成本失控</strong>。</p><p>本文介绍一种<strong>简单、官方、优雅</strong>的解决方案：</p><blockquote><strong>使用 Nginx 为本地大模型服务添加 API Key 认证</strong></blockquote><p>无需改动 Ollama / vLLM，也无需额外开发复杂的鉴权系统。</p><hr/><h2>一、解决方案概述</h2><p>Nginx 作为高性能 Web 服务器和反向代理，本身就具备非常灵活的请求处理能力。</p><p>我们可以利用 Nginx 的能力，在模型服务前面加一层 <strong>API Key 校验</strong>：</p><pre><code class="markdown">客户端  →  Nginx（API Key 校验）  →  Ollama / vLLM

┌──────────────────────────┐
│        Client             │
│  LangChain / SDK / curl   │
└─────────────┬────────────┘
│
│ Authorization: Bearer API_KEY
▼
┌──────────────────────────┐
│          Nginx            │
│  • API Key 校验 (map)     │
│  • 限流 (limit_req)       │
│  • 日志 / 代理 / TLS      │
└─────────────┬────────────┘
│
▼
┌──────────────────────────┐
│     Model Server          │
│  Ollama / vLLM            │
│  127.0.0.1:11434          │
└──────────────────────────┘</code></pre><h3>方案特点</h3><ul><li>✅ <strong>零侵入</strong>：模型服务本身无需任何改动</li><li>✅ <strong>配置即用</strong>：纯 Nginx 配置实现</li><li>✅ <strong>性能稳定</strong>：Nginx 原生能力，几乎无额外开销</li><li>✅ <strong>可扩展</strong>：后续可无缝接入 HTTPS、限流、日志、负载均衡</li></ul><hr/><h2>二、具体实施步骤</h2><h3>1️⃣ 生成 API Key</h3><p>首先生成一个足够安全的随机字符串作为 API Key：</p><pre><code class="bash">openssl rand -hex 16</code></pre><p>示例输出（32 位）：</p><pre><code>a1b2c3d4e5f6g7h8i9j0k1l2m3n4o5p6</code></pre><blockquote><p>建议：</p><ul><li>每个使用方一个 Key</li><li>不要硬编码到代码仓库</li></ul></blockquote><hr/><h3>2️⃣ 配置 Nginx（conf.d）</h3><p>在 Nginx 的 <code>conf.d</code> 目录中创建配置文件，例如：</p><p><code>/etc/nginx/conf.d/ollama-api.conf</code></p><pre><code class="nginx"># 期望请求头格式：Authorization: Bearer &lt;api-key&gt;
map $http_authorization $is_valid_key {
    default 0;
    "Bearer your-api-key-1" 1;
    "Bearer your-api-key-2" 1;
    "Bearer your-api-key-3" 1;
}

server {
    listen 21434;
    server_name your-domain.com;  # 替换为你的域名

    location / {
        # API Key 校验
        if ($is_valid_key = 0) {
            return 401 'Unauthorized';
        }

        # 代理到本地模型服务
        proxy_pass http://127.0.0.1:11434;

        # 代理头设置
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        # 流式响应支持（Chat / Stream 模式必开）
        proxy_buffering off;
        proxy_cache off;
    }

    # 健康检查接口（可选，不做认证）
    location /health {
        access_log off;
        return 200 "OK";
    }
}</code></pre><p>至此，你已经为 Ollama / vLLM 加上了一道 <strong>API Key 防线</strong>。</p><hr/><h3>3️⃣ 增加限流保护（强烈建议）</h3><p>为了防止 API Key 泄露后被恶意刷请求，可以增加限流。</p><p>在 <code>http</code> 块中定义限流区域：</p><pre><code class="nginx">http {
    limit_req_zone $binary_remote_addr zone=api_limit:10m rate=10r/s;
}</code></pre><p>在 <code>server</code> 或 <code>location</code> 中启用：</p><pre><code class="nginx">location / {
    # 单 IP 每秒最多 10 次请求，允许短暂突发
    limit_req zone=api_limit burst=20 nodelay;

    # 其他配置...
}</code></pre><hr/><h3>4️⃣ 重载 Nginx 配置</h3><pre><code class="bash">nginx -s reload</code></pre><hr/><h2>三、LangChain 客户端调用示例</h2><p>配置完成后，客户端只需像调用在线模型一样，携带 <code>api_key</code> 即可。</p><pre><code class="python"># pip install -U langchain langchain-openai

from langchain_openai import ChatOpenAI

llm = ChatOpenAI(
    model="qwen3:32b",
    base_url="http://192.168.31.33:21434/v1",
    api_key="your_api_key",
)</code></pre><p><strong>是不是非常像 OpenAI？</strong></p><blockquote>这也是这个方案最大的优点之一：<br/>👉 调用方式完全统一，几乎零学习成本。</blockquote><hr/><h2>四、常见问题：map_hash 报错</h2><p>如果你的 API Key 较长（例如 &gt;64 字符），Nginx 启动时可能出现错误：</p><pre><code>could not build map_hash, you should increase map_hash_bucket_size: 64</code></pre><p>解决方法：在 <code>http</code> 块中增加配置：</p><pre><code class="nginx">http {
    map_hash_bucket_size 128;

    # 如果遇到 server_names_hash_bucket_size 报错
    # server_names_hash_bucket_size 128;
}</code></pre><hr/><h2>五、安全与生产建议</h2><ol><li><p><strong>API Key 管理</strong></p><ul><li>不要提交到 Git 仓库</li><li>建议使用环境变量或配置管理系统</li></ul></li><li><p><strong>日志审计</strong></p><ul><li>启用 Nginx access log</li><li>可按 API Key 或 IP 分析调用情况</li></ul></li><li><p><strong>网络隔离</strong></p><ul><li>对外仅开放 Nginx 端口</li><li>Ollama / vLLM 原始端口仅监听 <code>127.0.0.1</code></li></ul></li><li><p><strong>HTTPS</strong>（强烈建议）</p><ul><li>API Key 明文传输必须配合 TLS 使用</li></ul></li></ol><hr/><h2>六、总结</h2><p>通过 <strong>Nginx + API Key</strong> 的方式，我们可以非常优雅地为本地大模型服务补齐「认证」这一关键能力：</p><ul><li>🔒 无需修改 Ollama / vLLM</li><li>🚀 性能损耗极低</li><li>🧩 与 LangChain / OpenAI 调用方式高度一致</li><li>🛠️ 后续可轻松扩展限流、HTTPS、负载均衡</li></ul><p>如果你正在：</p><ul><li>构建私有大模型平台</li><li>在内网或公网部署推理服务</li><li>希望用<strong>最小成本</strong>提升安全性</li></ul><p>那么，这个方案非常值得你直接落地使用。</p><p>希望这篇文章能对你有所帮助 🙌</p><p>欢迎转发、收藏，也欢迎交流更高级的模型服务治理方案。</p>]]></description></item><item>    <title><![CDATA[OneClip 开发经验分享：从零到一的 macOS 剪切板应用开发 飞翔蓝天 ]]></title>    <link>https://segmentfault.com/a/1190000047570319</link>    <guid>https://segmentfault.com/a/1190000047570319</guid>    <pubDate>2026-01-25 23:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>OneClip 开发经验分享：从零到一的 macOS 应用开发</h2><h3>前言</h3><p><a href="https://link.segmentfault.com/?enc=duGMia2JDohSa5yE61649Q%3D%3D.4I3%2FJ68jP04RlB7XMXSKRsDDzobbHGC%2FuC2YDCVg8ZKa27WG5pKkfzzAtupU6zGG" rel="nofollow" target="_blank">OneClip</a> 从最初的想法到现在的功能完整的应用，经历了多个版本的迭代。本文分享开发过程中的真实经验、遇到的问题、解决方案和最佳实践，希望能为其他 macOS 开发者提供参考。</p><h3>技术选型</h3><h4>为什么选择 SwiftUI？</h4><p><strong>初期考虑</strong>：</p><ul><li>AppKit（传统 macOS 开发）</li><li>SwiftUI（Apple 新推荐）</li><li>Electron（跨平台但资源占用大）</li></ul><p><strong>最终选择 SwiftUI 的原因</strong>：</p><table><thead><tr><th>方面</th><th>SwiftUI</th><th>AppKit</th><th>Electron</th></tr></thead><tbody><tr><td><strong>学习曲线</strong></td><td>陡峭但现代</td><td>平缓但过时</td><td>中等</td></tr><tr><td><strong>性能</strong></td><td>优秀</td><td>优秀</td><td>一般</td></tr><tr><td><strong>内存占用</strong></td><td>~120MB</td><td>~100MB</td><td>&gt;300MB</td></tr><tr><td><strong>开发效率</strong></td><td>高</td><td>低</td><td>中等</td></tr><tr><td><strong>系统集成</strong></td><td>原生</td><td>原生</td><td>有限</td></tr><tr><td><strong>未来前景</strong></td><td>光明</td><td>维护模式</td><td>稳定</td></tr></tbody></table><p><strong>实际体验</strong>：</p><pre><code class="swift">// SwiftUI 的声明式语法让 UI 开发更直观
struct ClipboardItemView: View {
    @ObservedObject var viewModel: ClipboardViewModel
    
    var body: some View {
        List(viewModel.items) { item in
            HStack {
                Image(systemName: item.icon)
                    .foregroundColor(.blue)
                
                VStack(alignment: .leading) {
                    Text(item.title)
                        .font(.headline)
                    Text(item.preview)
                        .font(.caption)
                        .lineLimit(1)
                        .foregroundColor(.gray)
                }
                
                Spacer()
                
                Button(action: { viewModel.copyItem(item) }) {
                    Image(systemName: "doc.on.doc")
                }
                .buttonStyle(.borderless)
            }
        }
    }
}</code></pre><h3>核心功能开发</h3><h4>1. 剪贴板监控</h4><p><strong>最大挑战</strong>：如何高效地监控系统剪贴板变化？</p><p><strong>初期方案（失败）</strong>：</p><pre><code class="swift">// ❌ 不推荐：轮询间隔过短，CPU 占用高
Timer.scheduledTimer(withTimeInterval: 0.01, repeats: true) { _ in
    let newContent = NSPasteboard.general.string(forType: .string)
    // 处理新内容
}</code></pre><p><strong>问题</strong>：</p><ul><li>CPU 占用率达到 70-100%</li><li>电池消耗快</li><li>系统响应变慢</li></ul><p><strong>改进方案（成功）</strong>：</p><pre><code class="swift">// ✅ 推荐：使用 changeCount 检测变化
class ClipboardMonitor {
    private var lastChangeCount = 0
    private var monitoringTimer: Timer?
    
    func startMonitoring() {
        monitoringTimer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { [weak self] _ in
            let currentCount = NSPasteboard.general.changeCount
            
            if currentCount != self?.lastChangeCount {
                self?.lastChangeCount = currentCount
                self?.handleClipboardChange()
            }
        }
    }
    
    private func handleClipboardChange() {
        // 只在检测到变化时处理
        // CPU 占用降低到 &lt; 1%
    }
}</code></pre><p><strong>性能对比</strong>：</p><table><thead><tr><th>方案</th><th>CPU 占用</th><th>内存</th><th>响应延迟</th></tr></thead><tbody><tr><td>0.01s 轮询</td><td>15-20%</td><td>150MB</td><td>&lt; 10ms</td></tr><tr><td>changeCount</td><td>&lt; 1%</td><td>120MB</td><td>100-200ms</td></tr><tr><td><strong>改进</strong></td><td><strong>降低 95%</strong></td><td><strong>降低 20%</strong></td><td><strong>可接受</strong></td></tr></tbody></table><h4>2. 全局快捷键实现</h4><p><strong>需求</strong>：在任何应用中按 <code>Cmd+Option+V</code> 快速呼出 OneClip</p><p><strong>技术选择</strong>：Carbon Framework（虽然老旧但稳定）</p><p><strong>实现代码</strong>：</p><pre><code class="swift">import Carbon

class HotkeyManager {
    private var hotkeyRef: EventHotKeyRef?
    private let hotkeyID = EventHotKeyID(signature: OSType(UInt32(0x4F4E4543)), id: 1)
    
    func registerHotkey(keyCode: UInt32, modifiers: UInt32) {
        var ref: EventHotKeyRef?
        
        let status = RegisterEventHotKey(
            keyCode,
            modifiers,
            hotkeyID,
            GetApplicationEventTarget(),
            0,
            &amp;ref
        )
        
        if status == noErr {
            hotkeyRef = ref
            print("✅ 快捷键注册成功")
        } else {
            print("❌ 快捷键注册失败: \(status)")
        }
    }
    
    func unregisterHotkey() {
        if let ref = hotkeyRef {
            UnregisterEventHotKey(ref)
        }
    }
}

// 快捷键码对照表
let HOTKEY_CODES = [
    "V": 9,           // V 键
    "R": 15,          // R 键
    "C": 8,           // C 键
    "D": 2,           // D 键
]

let MODIFIER_KEYS = [
    "cmd": UInt32(cmdKey),           // Command
    "option": UInt32(optionKey),     // Option
    "shift": UInt32(shiftKey),       // Shift
    "control": UInt32(controlKey),   // Control
]</code></pre><p><strong>遇到的问题</strong>：</p><ol><li><p><strong>快捷键冲突</strong>：某些应用也使用相同快捷键</p><ul><li>解决：提供快捷键自定义功能</li><li>添加冲突检测机制</li></ul></li><li><p><strong>权限问题</strong>：需要辅助功能权限</p><ul><li>解决：首次启动时提示用户授权</li></ul></li><li><p><strong>系统更新兼容性</strong>：macOS 版本差异</p><ul><li>解决：兼容 macOS 12+</li></ul></li></ol><h4>3. 数据持久化</h4><p><strong>选择 SQLite 而不是 Core Data</strong>：</p><p>OneClip 使用原生 SQLite 而非 Core Data，原因：</p><ul><li>更轻量，启动更快</li><li>更灵活的查询控制</li><li>更容易进行数据迁移</li></ul><pre><code class="swift">// SQLite 数据库封装
class ClipboardDatabase {
    private var db: OpaquePointer?
    
    init(at path: String) throws {
        // 打开数据库连接
        guard sqlite3_open(path, &amp;db) == SQLITE_OK else {
            throw ClipboardError.databaseNotReady
        }
        
        // 创建表结构
        try createTables()
    }
    
    // 保存项目
    func saveItem(_ item: ClipboardItem) throws {
        let sql = """
            INSERT OR REPLACE INTO clipboard_items 
            (id, content, type, timestamp, source_app, is_favorite, is_pinned, content_hash)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        """
        // 执行 SQL
    }
    
    // 加载最近项目
    func loadHotData(limit: Int) throws -&gt; [ClipboardItem] {
        let sql = "SELECT * FROM clipboard_items ORDER BY timestamp DESC LIMIT ?"
        // 执行查询并返回结果
    }
}</code></pre><p><strong>性能优化</strong>：</p><pre><code class="swift">// 使用索引加速查询
func createTables() throws {
    let sql = """
        CREATE TABLE IF NOT EXISTS clipboard_items (
            id TEXT PRIMARY KEY,
            content TEXT,
            type TEXT NOT NULL,
            timestamp REAL NOT NULL,
            source_app TEXT,
            is_favorite INTEGER DEFAULT 0,
            is_pinned INTEGER DEFAULT 0,
            content_hash TEXT
        );
        CREATE INDEX IF NOT EXISTS idx_timestamp ON clipboard_items(timestamp DESC);
        CREATE INDEX IF NOT EXISTS idx_content_hash ON clipboard_items(content_hash);
    """
    // 执行 SQL
}

// 使用哈希索引快速去重 - O(1) 时间复杂度
func findItemByHash(_ hash: String) -&gt; UUID? {
    let sql = "SELECT id FROM clipboard_items WHERE content_hash = ? LIMIT 1"
    // 执行查询
}</code></pre><h3>常见问题与解决方案</h3><h4>问题 1：应用启动时权限提示过多</h4><p><strong>现象</strong>：用户首次启动应用，被要求授予多个权限</p><p><strong>解决方案</strong>：</p><pre><code class="swift">class PermissionManager {
    func requestPermissionsSequentially() {
        // 按优先级顺序请求权限
        requestAccessibilityPermission { [weak self] granted in
            if granted {
                self?.requestDiskAccessPermission()
            }
        }
    }
    
    private func requestAccessibilityPermission(completion: @escaping (Bool) -&gt; Void) {
        let options: NSDictionary = [kAXTrustedCheckOptionPrompt.takeRetainedValue() as String: true]
        let trusted = AXIsProcessTrustedWithOptions(options)
        completion(trusted)
    }
}</code></pre><h4>问题 2：大数据集下搜索变慢</h4><p><strong>现象</strong>：当历史记录超过 1000 条时，搜索响应延迟明显</p><p><strong>解决方案</strong>：</p><pre><code class="swift">class SearchOptimizer {
    // 搜索防抖
    private var searchDebounceTimer: Timer?
    
    func searchWithDebounce(_ query: String) {
        searchDebounceTimer?.invalidate()
        
        searchDebounceTimer = Timer.scheduledTimer(withTimeInterval: 0.3, repeats: false) { [weak self] _ in
            self?.performSearch(query)
        }
    }
    
    private func performSearch(_ query: String) {
        let predicate = NSPredicate(format: "content CONTAINS[cd] %@", query)
        
        let request = ClipboardItemEntity.fetchRequest()
        request.predicate = predicate
        request.fetchLimit = 50  // 限制结果数
        request.sortDescriptors = [
            NSSortDescriptor(keyPath: \ClipboardItemEntity.timestamp, ascending: false)
        ]
        
        DispatchQueue.global(qos: .userInitiated).async {
            let results = try? self.container.viewContext.fetch(request)
            DispatchQueue.main.async {
                self.updateSearchResults(results ?? [])
            }
        }
    }
}</code></pre><h4>问题 3：内存泄漏</h4><p><strong>现象</strong>：长时间运行后内存占用不断增加</p><p><strong>排查过程</strong>：</p><pre><code class="swift">// 使用 Instruments 检测内存泄漏
// 1. 在 Xcode 中运行 Product &gt; Profile
// 2. 选择 Leaks 工具
// 3. 运行应用并进行操作
// 4. 查看泄漏的对象

// 常见泄漏原因：
// ❌ 循环引用
class ClipboardManager {
    var timer: Timer?
    
    func startMonitoring() {
        // ❌ 错误：self 被 timer 强引用，timer 被 self 强引用
        timer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { _ in
            self.checkClipboard()
        }
    }
}

// ✅ 正确：使用 [weak self]
func startMonitoring() {
    timer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { [weak self] _ in
        self?.checkClipboard()
    }
}</code></pre><h4>问题 4：图片处理导致 UI 卡顿</h4><p><strong>现象</strong>：粘贴大图片时，UI 出现明显延迟</p><p><strong>解决方案</strong>：</p><pre><code class="swift">class ImageProcessor {
    // 在后台线程处理图片
    func processImage(_ image: NSImage, completion: @escaping (NSImage) -&gt; Void) {
        DispatchQueue.global(qos: .userInitiated).async {
            // 生成缩略图
            let thumbnail = self.generateThumbnail(image, size: CGSize(width: 200, height: 200))
            
            // 压缩图片
            let compressed = self.compressImage(image, quality: 0.7)
            
            DispatchQueue.main.async {
                completion(thumbnail)
            }
        }
    }
    
    private func generateThumbnail(_ image: NSImage, size: CGSize) -&gt; NSImage {
        let thumbnail = NSImage(size: size)
        thumbnail.lockFocus()
        image.draw(in: NSRect(origin: .zero, size: size))
        thumbnail.unlockFocus()
        return thumbnail
    }
    
    private func compressImage(_ image: NSImage, quality: CGFloat) -&gt; Data? {
        guard let tiffData = image.tiffRepresentation,
              let bitmapImage = NSBitmapImageRep(data: tiffData) else {
            return nil
        }
        
        return bitmapImage.representation(using: .jpeg, properties: [.compressionFactor: quality])
    }
}</code></pre><h3>性能优化实战</h3><h4>优化前后对比</h4><p><strong>优化前</strong>：</p><pre><code>启动时间：3.5 秒
内存占用：250MB
CPU 使用：8-12%
搜索延迟：500-800ms</code></pre><p><strong>优化后</strong>：</p><pre><code>启动时间：0.8 秒 ⬇️ 77%
内存占用：120MB ⬇️ 52%
CPU 使用：&lt; 1% ⬇️ 90%
搜索延迟：100-200ms ⬇️ 75%</code></pre><p><strong>关键优化</strong>：</p><ol><li><strong>延迟加载</strong>：只加载可见的列表项</li><li><strong>图片压缩</strong>：自动压缩大图片</li><li><strong>后台处理</strong>：将耗时操作移到后台线程</li><li><strong>缓存策略</strong>：缓存常用数据</li><li><strong>数据库索引</strong>：为频繁查询的字段建立索引</li></ol><h3>测试与调试</h3><h4>单元测试示例</h4><pre><code class="swift">import XCTest

class ClipboardManagerTests: XCTestCase {
    var manager: ClipboardManager!
    
    override func setUp() {
        super.setUp()
        manager = ClipboardManager()
    }
    
    func testClipboardMonitoring() {
        let expectation = XCTestExpectation(description: "Clipboard change detected")
        
        manager.onClipboardChange = {
            expectation.fulfill()
        }
        
        manager.startMonitoring()
        
        // 模拟剪贴板变化
        NSPasteboard.general.clearContents()
        NSPasteboard.general.setString("Test content", forType: .string)
        
        wait(for: [expectation], timeout: 1.0)
        
        manager.stopMonitoring()
    }
    
    func testContentProcessing() {
        let content = "# Test\n\nSome content"
        let processed = manager.processContent(content)
        
        XCTAssertEqual(processed.type, .text)
        XCTAssertTrue(processed.content.contains("Test"))
    }
}</code></pre><h4>调试技巧</h4><pre><code class="swift">// 1. 使用 os_log 记录关键信息
import os

let logger = Logger(subsystem: "com.oneclip.app", category: "clipboard")

logger.info("Clipboard content changed: \(content)")
logger.error("Failed to save item: \(error.localizedDescription)")

// 2. 在 Xcode 控制台查看日志
// 3. 使用 Console.app 查看系统日志
// 4. 使用 Instruments 进行性能分析</code></pre><h3>发布与更新</h3><h4>使用 Sparkle 实现自动更新</h4><pre><code class="swift">class UpdateManager: NSObject, SPUUpdaterDelegate {
    let updater: SPUUpdater
    
    override init() {
        let hostBundle = Bundle.main
        let updateDriver = SPUStandardUpdaterController(
            hostBundle: hostBundle,
            applicationBundle: hostBundle,
            userDriver: SPUStandardUserDriver(hostBundle: hostBundle),
            delegate: nil
        )
        
        self.updater = updateDriver.updater
        super.init()
        
        updater.delegate = self
    }
    
    func startUpdater() {
        updater.startUpdater()
    }
}</code></pre><h3>最佳实践总结</h3><h4>开发阶段</h4><ul><li>✅ 使用 SwiftUI 进行 UI 开发</li><li>✅ 采用 MVVM 架构</li><li>✅ 及早进行性能测试</li><li>✅ 编写单元测试</li><li>✅ 使用 Instruments 检测内存泄漏</li></ul><h4>功能实现</h4><ul><li>✅ 后台线程处理耗时操作</li><li>✅ 使用 [weak self] 避免循环引用</li><li>✅ 实现错误处理和日志记录</li><li>✅ 提供用户友好的权限提示</li></ul><h4>性能优化</h4><ul><li>✅ 监控频率自适应</li><li>✅ 数据库查询优化</li><li>✅ 图片压缩存储</li><li>✅ 内存管理和缓存策略</li></ul><h4>发布与维护</h4><ul><li>✅ 使用 Sparkle 实现自动更新</li><li>✅ 收集用户反馈</li><li>✅ 定期发布更新</li><li>✅ 维护变更日志</li></ul><h3>总结</h3><p>OneClip 的开发过程充满了挑战和学习。通过不断的优化和改进，我们打造了一款高效、稳定、用户友好的 macOS 应用。</p><p><strong>关键收获</strong>：</p><ol><li>选择合适的技术栈很重要</li><li>性能优化需要持续关注</li><li>用户体验至关重要</li><li>社区反馈推动产品进步</li></ol><p>如果你正在开发 macOS 应用，希望这些经验能对你有所帮助。欢迎在 <a href="https://link.segmentfault.com/?enc=8%2FiGS%2FQplD%2B8TeTDl%2FMVIw%3D%3D.xbdt8%2BlUEALE9zhHnjvkYTj0Y8QL3OlzPxvnYmlLzbmbxxUJ4QEV2HS%2Fw8TVWvpb" rel="nofollow" target="_blank">GitHub Discussions</a> 中分享你的经验和问题！</p>]]></description></item><item>    <title><![CDATA[@cs-open/react-fabric —— 被 Fabric.js 官方推荐的 React 最]]></title>    <link>https://segmentfault.com/a/1190000047570354</link>    <guid>https://segmentfault.com/a/1190000047570354</guid>    <pubDate>2026-01-25 22:07:56</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在 React 项目中处理复杂的 Canvas 交互，一直是让开发者头疼的难题。原生 Fabric.js 虽然强大，但在 React 的声明式编程模型下，手动管理对象生命周期、同步状态和处理事件流往往会导致代码碎片化。</p><p>今天，我们要重点推荐一个合合信息开源黑马项目：<strong><a href="https://link.segmentfault.com/?enc=hpWO%2F6xFk%2FsVDQ%2FEpr%2F8Uw%3D%3D.6%2FyhhuAr%2BwT9FVqC75LpBjBJaBECODxYgknyj1%2B1xppjb6%2Boc2alBFxk9ntASR5C" rel="nofollow" target="_blank">@cs-open/react-fabric</a></strong></p><h3>🌟 官方背书，血统纯正</h3><p><code>react-fabric</code> 的优秀并非自吹自擂。它已经正式被 <strong>Fabric.js 官方资源库（Fabric.js Resources）</strong> 收录并向全球开发者推荐。</p><blockquote><p>🔗 <strong>官方推荐链接</strong>：<a href="https://link.segmentfault.com/?enc=Xer6agqNzhpoWesLDQ1Sxg%3D%3D.o1Zo5%2F8eh4wunoroSwtpbDrNZT248H5wiLAK0UyXfpk%3D" rel="nofollow" target="_blank">fabricjs.com/resources</a></p><p>在 Resources 页面中，你可以清楚地看到 <code>@cs-open/react-fabric</code> 作为高扩展性、复合型 React 封装库被列在显著位置。</p></blockquote><h3>🚀 AI 时代的宠儿：Cursor 评价第一</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047570357" alt="react-fabric.webp" title="react-fabric.webp"/></p><p>在 AI 辅助编程领域，<code>react-fabric</code> 同样表现抢眼。根据开发者反馈和相关社区图片描述，该库在 <strong>Cursor (AI Code Editor)</strong> 的相关 React Canvas 库评价中位居<strong>第一</strong>。</p><p>这意味着，当你使用 Cursor 进行代码补全或咨询绘图方案时，<code>react-fabric</code> 的结构化设计和类型完备性，使其成为了 AI 最推荐、生成代码最稳健的选择。</p><h3>💎 核心优势：不仅仅是 Demo</h3><p>很多开源库停留在“实验性”阶段，但 <code>react-fabric</code> 不同：</p><ol><li><strong>工业级稳定性</strong>：这<strong>不是</strong>一个简单的 Demo 项目！它目前正深度应用于<strong>大型商业项目</strong>中，经历了高并发、复杂场景的实战考验。</li><li><strong>严苛测试保障</strong>：项目已经由专业测试人员进行了<strong>全方位的完善测试</strong>，包括性能压力测试、边界条件测试以及多端兼容性测试。</li><li><strong>高度可扩展</strong>：采用复合样式（Composite style）设计，让你可以像写 React 组件一样组合复杂的 Canvas 元素，同时保留了直接操作底层 Fabric 实例的能力。</li></ol><h3>🏗️ 真实落地案例</h3><p>该项目已在<strong>蜜蜂教育</strong>等大型教育科技平台中稳定运行。在教育场景这类对交互绘图、课件批注有极高要求的领域，<code>react-fabric</code> 展现了卓越的可靠性。</p><ul><li><strong>官方应用参考</strong>：<a href="https://link.segmentfault.com/?enc=gnwBuU3zvC5hJib8Ba2nEQ%3D%3D.2IE%2BsFUZ2bxPT%2Br94tnu74fN%2BKRQBLIXJ3wCT2SeUbM%3D" rel="nofollow" target="_blank">www.mifengjiaoyu.com</a></li></ul><hr/><h3>🛠️ 如何开始？</h3><p>如果你正在寻找一个高性能、类型友好且能直接用于生产环境的 React Canvas 解决方案，请认准 <code>react-fabric</code>。</p><ul><li><strong>GitHub 地址</strong>：<a href="https://link.segmentfault.com/?enc=KE9pdgiUI6wIh0gIlUbRVg%3D%3D.EVQUQEDsaMLGGX%2Bo%2FGKgGWHwBEKidcKNx5sCDGxHZc7L5D4YGIpcEw5TIHO6w7NI" rel="nofollow" target="_blank">github.com/cs-open/react-fabric</a></li><li><strong>demo 地址</strong>：<a href="https://link.segmentfault.com/?enc=LtMhbRXnu%2BmALG60Dyqjdw%3D%3D.K5W%2Fj9IxcSXcQPD6RBooVL2moCSqQgpoj2RpL7hXqusBFWogDynDIvfJSF9h78W2" rel="nofollow" target="_blank">https://cs-open.github.io/react-fabric/</a></li><li><p><strong>安装命令</strong>：</p><p>Bash</p><pre><code>npm install @cs-open/react-fabric
# 或
yarn add @cs-open/react-fabric
</code></pre></li></ul><hr/><p>&lt;div id="chinese"&gt;</p><h2>✨ 核心特性</h2><h3>🎯 丰富的图形组件</h3><ul><li><strong>基础图形</strong>: 矩形、圆形、椭圆、线条、多边形、路径</li><li><strong>文本组件</strong>: 文本、可编辑文本、文本框</li><li><strong>图像组件</strong>: 背景图片、普通图片</li><li><strong>组合组件</strong>: 分组、对象集合</li><li><strong>自定义控件</strong>: 可拖拽控制点、工具栏</li></ul><h3>🖱️ 强大的交互功能</h3><ul><li><strong>自动缩放</strong>: 支持鼠标滚轮缩放，自动适应容器大小</li><li><strong>平移操作</strong>: 支持拖拽平移画布视图</li><li><strong>触摸支持</strong>: 完整的触摸设备支持，包括双指缩放和拖拽</li><li><strong>选择系统</strong>: 多选、框选、键盘快捷键支持</li><li><strong>拖拽操作</strong>: 对象拖拽、批量操作</li></ul><h3>📦 响应式设计</h3><ul><li><strong>自动适配</strong>: 画布自动撑满父容器，响应式调整</li><li><strong>触摸优化</strong>: 专为移动设备优化的触摸交互</li><li><strong>跨平台</strong>: 支持桌面端和移动端浏览器</li></ul><h3>💻 开发者友好</h3><ul><li><strong>TypeScript</strong>: 完整的 TypeScript 类型支持</li><li><strong>React 风格</strong>: 声明式 API，符合 React 开发习惯</li><li><strong>事件系统</strong>: 完整的事件回调，支持所有 Fabric.js 事件</li><li><strong>状态管理</strong>: 内置状态管理，支持受控和非受控模式</li></ul><h2>✨ 快速开始</h2><h3>安装</h3><pre><code class="bash">npm install @cs-open/react-fabric
# 或者
yarn add @cs-open/react-fabric
# 或者
pnpm add @cs-open/react-fabric</code></pre><h3>基础用法</h3><pre><code class="tsx">import React from 'react'
import { ReactFabric, Rect, Text, Circle } from '@cs-open/react-fabric'

function App() {
  return (
    &lt;div style={{ width: '100%', height: '500px' }}&gt;
      &lt;ReactFabric&gt;
        &lt;Rect left={100} top={100} width={200} height={100} fill="red" stroke="blue" strokeWidth={2} /&gt;
        &lt;Circle left={300} top={150} radius={50} fill="green" /&gt;
        &lt;Text left={150} top={250} text="Hello Fabric!" fontSize={20} fill="white" /&gt;
      &lt;/ReactFabric&gt;
    &lt;/div&gt;
  )
}

export default App</code></pre><h2>🎯 核心功能</h2><h3>自动缩放与平移</h3><pre><code class="tsx">import { ReactFabric, useReactFabric } from '@cs-open/react-fabric'

function CanvasWithControls() {
  const { zoomIn, zoomOut, resetViewport, zoom } = useReactFabric()

  return (
    &lt;div&gt;
      &lt;div className="toolbar"&gt;
        &lt;button onClick={zoomIn}&gt;放大&lt;/button&gt;
        &lt;button onClick={zoomOut}&gt;缩小&lt;/button&gt;
        &lt;button onClick={() =&gt; resetViewport()}&gt;重置&lt;/button&gt;
        &lt;span&gt;缩放: {Math.round(zoom * 100)}%&lt;/span&gt;
      &lt;/div&gt;

      &lt;ReactFabric zoomable={true} panAble={true} minManualZoom={0.1} maxManualZoom={5}&gt;
        {/* 你的画布内容 */}
      &lt;/ReactFabric&gt;
    &lt;/div&gt;
  )
}</code></pre><h3>触摸设备支持</h3><pre><code class="tsx">import { ReactFabric, PluginPinch } from '@cs-open/react-fabric'
import { PluginPinch } from '@cs-open/react-fabric/plugins'

function TouchCanvas() {
  return (
    &lt;ReactFabric&gt;
      {/* 你的画布内容 */}
      &lt;PluginPinch /&gt;
    &lt;/ReactFabric&gt;
  )
}</code></pre><h3>背景图片</h3><pre><code class="tsx">import { ReactFabric, BackgroundImage } from '@cs-open/react-fabric'

function CanvasWithBackground() {
  return (
    &lt;ReactFabric defaultCentered&gt;
      &lt;BackgroundImage src="/path/to/image.jpg" scaleToFit /&gt;
      {/* 其他图形元素 */}
    &lt;/ReactFabric&gt;
  )
}</code></pre><h2>🔌 插件系统</h2><h3>内置插件</h3><table><thead><tr><th>插件</th><th>功能</th><th>描述</th></tr></thead><tbody><tr><td><code>PluginPinch</code></td><td>触摸缩放</td><td>支持双指缩放和拖拽操作</td></tr><tr><td><code>PluginFreeDraw</code></td><td>自由绘制</td><td>手绘路径和涂鸦功能</td></tr><tr><td><code>PluginFreeRect</code></td><td>矩形绘制</td><td>交互式矩形绘制工具</td></tr><tr><td><code>PluginFreeText</code></td><td>文本工具</td><td>点击添加可编辑文本</td></tr><tr><td><code>PluginGridLine</code></td><td>网格辅助</td><td>显示网格线辅助对齐</td></tr><tr><td><code>PluginMask</code></td><td>遮罩效果</td><td>创建遮罩和裁剪效果</td></tr></tbody></table><h3>使用插件</h3><pre><code class="tsx">import { ReactFabric } from '@cs-open/react-fabric'
import { PluginPinch, PluginFreeDraw, PluginFreeRect, PluginGridLine } from '@cs-open/react-fabric/plugins'

function AdvancedCanvas() {
  return (
    &lt;ReactFabric&gt;
      {/* 触摸支持 */}
      &lt;PluginPinch /&gt;

      {/* 自由绘制 */}
      &lt;PluginFreeDraw
        onComplete={(path, { canvas }) =&gt; {
          console.log('绘制完成:', path)
        }}
      /&gt;

      {/* 矩形绘制工具 */}
      &lt;PluginFreeRect
        fill={'red'}
        onComplete={(rect, { canvas }) =&gt; {
          console.log('矩形绘制完成:', rect)
        }}
      /&gt;

      {/* 网格线 */}
      &lt;PluginGridLine /&gt;
    &lt;/ReactFabric&gt;
  )
}</code></pre><h2>📦 组件 API</h2><h3>ReactFabric 组件</h3><p>主要的画布容器组件，支持以下属性：</p><pre><code class="tsx">interface ReactFabricProps {
  // 基础属性
  width?: number
  height?: number
  className?: string
  style?: CSSProperties

  // 交互控制
  zoomable?: boolean // 是否可缩放
  panAble?: boolean // 是否可平移
  selection?: boolean // 是否可选择
  defaultSelection?: boolean // 默认选择状态
  defaultDraggable?: boolean // 默认拖拽状态

  // 缩放控制
  manualZoom?: number // 手动缩放倍数
  minManualZoom?: number // 最小缩放倍数
  maxManualZoom?: number // 最大缩放倍数
  defaultCentered?: boolean // 背景图是否居中

  // 事件回调
  onMouseDown?: (e: FabricPublicEvent) =&gt; void
  onMouseMove?: (e: FabricPublicEvent) =&gt; void
  onMouseUp?: (e: FabricPublicEvent) =&gt; void
  onMouseWheel?: (e: FabricPublicEvent) =&gt; void
}</code></pre><h3>图形组件</h3><p>所有图形组件都支持对应的 Fabric.js 对象的所有属性和事件：</p><pre><code class="tsx">// 矩形
&lt;Rect
  left={100}
  top={100}
  width={200}
  height={100}
  fill="red"
  stroke="blue"
  strokeWidth={2}
  onModified={(e) =&gt; console.log('矩形被修改', e.target)}
/&gt;

// 圆形
&lt;Circle
  left={200}
  top={200}
  radius={50}
  fill="green"
  onSelected={() =&gt; console.log('圆形被选中')}
/&gt;

// 文本
&lt;Text
  left={100}
  top={300}
  text="Hello World"
  fontSize={24}
  fill="black"
  fontFamily="Arial"
/&gt;

// 图片
&lt;Image
  left={300}
  top={300}
  src="/path/to/image.jpg"
  width={200}
  height={150}
/&gt;</code></pre><h2>🎮 状态管理</h2><h3>useReactFabric Hook</h3><pre><code class="tsx">import { useReactFabric } from '@cs-open/react-fabric'

function Toolbar() {
  const {
    // 状态
    canvas,
    zoom,
    manualZoom,
    isDragging,
    selection,

    // 方法
    zoomIn,
    zoomOut,
    resetViewport,
    setZoomable,
    setSelection,
    setDraggable,
  } = useReactFabric()

  return (
    &lt;div className="toolbar"&gt;
      &lt;button onClick={zoomIn}&gt;放大&lt;/button&gt;
      &lt;button onClick={zoomOut}&gt;缩小&lt;/button&gt;
      &lt;button onClick={() =&gt; resetViewport()}&gt;重置&lt;/button&gt;
      &lt;span&gt;缩放: {Math.round(zoom * 100)}%&lt;/span&gt;
    &lt;/div&gt;
  )
}</code></pre><h3>跨组件状态访问</h3><p>ReactFabricProvider 是一个上下文提供程序，允许您从组件树中的任何位置访问流的内部状态，例如子组件，甚至在 ReactFabric 之外 元件。它通常用于应用程序的顶层。<br/>在这种情况下，您可能需要使用 ReactFabricProvider 组件</p><pre><code class="tsx">import { ReactFabricProvider, useReactFabric } from '@cs-open/react-fabric'

function App() {
  return (
    &lt;ReactFabricProvider&gt;
      &lt;Toolbar /&gt;
      &lt;ReactFabric&gt;{/* 画布内容 */}&lt;/ReactFabric&gt;
    &lt;/ReactFabricProvider&gt;
  )
}

function Toolbar() {
  const { zoomIn, zoomOut, resetViewport } = useReactFabric()
  // 可以在 ReactFabric 外部访问状态
}</code></pre><h2>🎨 高级用法</h2><h3>受控模式</h3><pre><code class="tsx">import { useState } from 'react'
import { ReactFabric, Rect } from '@cs-open/react-fabric'

function ControlledCanvas() {
  const [rect, setRect] = useState({
    left: 100,
    top: 100,
    width: 200,
    height: 100,
    fill: 'red',
  })

  return (
    &lt;ReactFabric&gt;
      &lt;Rect {...rect} onModified={e =&gt; setRect(e.target)} /&gt;
    &lt;/ReactFabric&gt;
  )
}</code></pre><h3>非受控模式</h3><pre><code class="tsx">import { ReactFabric, Rect, Group } from '@cs-open/react-fabric'

function UncontrolledCanvas() {
  return (
    &lt;ReactFabric&gt;
      &lt;Group&gt;
        &lt;Rect defaultLeft={100} defaultTop={100} defaultWidth={100} defaultHeight={100} fill="blue" /&gt;
      &lt;/Group&gt;
    &lt;/ReactFabric&gt;
  )
}</code></pre><h3>DOM 集成</h3><p>结合 floating-ui 可以轻松实现 dom 控件</p><pre><code class="tsx">import { ReactFabric, Rect } from '@cs-open/react-fabric'

function CanvasWithDOM() {
  return (
    &lt;ReactFabric&gt;
      &lt;Rect left={100} top={100} width={200} height={100}&gt;
        &lt;div className="tooltip"&gt;这是一个提示框&lt;/div&gt;
      &lt;/Rect&gt;
    &lt;/ReactFabric&gt;
  )
}</code></pre><hr/><p><strong>结语</strong>：</p><p>选对工具，开发效率提升 200%。既然 Fabric.js 官方已经帮你选好了，Cursor 评价也拿了第一，还有大型项目背书，你还在犹豫什么？赶快在你的下一个项目中尝试 <code>react-fabric</code> 吧！</p>]]></description></item><item>    <title><![CDATA[『NAS』推荐几个绿联 NAS Docker 能用的镜像加速器 德育处主任 ]]></title>    <link>https://segmentfault.com/a/1190000047570653</link>    <guid>https://segmentfault.com/a/1190000047570653</guid>    <pubDate>2026-01-25 22:07:19</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><strong>点赞 + 关注 + 收藏 = 学会了</strong></p><blockquote>整理了一个NAS小专栏，有兴趣的工友可以关注一下 👉 <a href="https://link.segmentfault.com/?enc=mh1MmChxHhAwIfEKDd5m4g%3D%3D.y7y37uBa6CmnFxZC6Kby5gQ3TJIJPuTymyxJLJjKsEBY4IHt2F1hiO1lOL1KFtgdeIvIVanFapPoPlKvCjgdNqtaQ9wSDBAz%2B4w%2FF1e%2B3PxUl5jZ1NP98Ns1QbBFdPKvE53ZNNShFv8lCIjS0Pdgg84TXIhct7EBLZrAVkLJjCU%3D" rel="nofollow" target="_blank">《NAS邪修》</a></blockquote><p>买 NAS 不玩 Docker 乐趣少一半。</p><p>但 Docker 的镜像（简单理解为软件安装包吧）是放在国外服务器保存的，我们要下载这些镜像全凭运气。</p><p>绿联 NAS 虽然推荐了一个加速器（<code>https://docker.1ms.run</code>），但有些镜像还是搜到下载不到。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047570655" alt="" title=""/></p><p>比如 <code>memos</code> 这款高颜值的笔记工具，我下载了几次都失败了。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047570656" alt="" title="" loading="lazy"/></p><p>先别急删掉 Docker，我们多配置几个镜像加速器就可以了。</p><p>绿联 NAS 的 Docker 镜像加速器配置方法很简单。</p><p>打开 Docker，切换到「镜像」页面，点击右上角的“齿轮”按钮。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047570657" alt="" title="" loading="lazy"/></p><p>在「镜像仓库」这里，点击下图箭头所指的「加速器配置」按钮。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047570658" alt="" title="" loading="lazy"/></p><p>把这堆地址都填进去，点击「确定」按钮就行了～</p><ul><li><a href="https://link.segmentfault.com/?enc=5JSK0fYmus3ZTjQc0lZYtA%3D%3D.fFR1WsxN8no%2Bu33Th5q20VMY4wsctLLi9186Bh3Zmbk%3D" rel="nofollow" target="_blank">https://docker.1ms.run</a></li><li><a href="https://link.segmentfault.com/?enc=pDZlDar3hn%2Fs8d54%2FuKGyA%3D%3D.%2BbrkuUmzFKNYU8EHXqiM8ODLaUe14DAz9wjiY1uVqiw%3D" rel="nofollow" target="_blank">https://docker.ketches.cn</a></li><li><a href="https://link.segmentfault.com/?enc=v0echRL4ZbzVhcFBuqdmlA%3D%3D.LJQYbQ%2BQANfvQfD7eq%2Bn3imolbNB8WVWgWMlP62Vi3A%3D" rel="nofollow" target="_blank">https://docker.m.daocloud.io</a></li><li><a href="https://link.segmentfault.com/?enc=sE5jyAdvyN5GZtBErYY5dg%3D%3D.SdiUVYAr1jEOGBTpBPdsW9nqjU8NQtxdtOzr05mmlj0%3D" rel="nofollow" target="_blank">https://docker.xuanyuan.me</a></li><li><a href="https://link.segmentfault.com/?enc=Vv38MUR82lCChkPS261vBw%3D%3D.Z4PvzJWMkYgZpi3LXckYJhiZOuRTdNn4zDeaGdMrQao%3D" rel="nofollow" target="_blank">https://docker.1panel.live</a></li><li><a href="https://link.segmentfault.com/?enc=DcNe%2Fl3vmz1ovYTGkZ4MrQ%3D%3D.j4wOmj1s58Odp8lZrq13zrJp0j%2B2Rx4K8txPxwSdDHM%3D" rel="nofollow" target="_blank">https://dockerproxy.com</a></li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047570659" alt="" title="" loading="lazy"/></p><p>回到「镜像」面板，搜索你想安装的镜像就能下载了。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047570660" alt="" title="" loading="lazy"/></p><hr/><p>以上就是本文的全部内容啦，想了解更多NAS玩法可以关注<a href="https://link.segmentfault.com/?enc=O3zwSs5sXQaTrDvo6Xncsw%3D%3D.0jxkytoPfiz6k1NxjJly%2BpZR7qXXW25cI%2FHRF9ewgGLnJ6db9hqJjVm2FwEY993GjFEwbKzkbb3CX3Mwu9NFAOhlQdP3UHFeiaLumsRomXeOBkMyjQDnL5a7utgQr0kgTV0gnBRzf5nWlEWAVSfBWYbSaZTaWeP%2FxrPLRUU5u60%3D" rel="nofollow" target="_blank">《NAS邪修》👏</a></p><p>最后推荐一下玩 NAS 的工友，在 NAS 上装一个 n8n 接入大模型，可以帮你定时定候完成各种工作，比如签到啦、写文章啦、生成海报和视频啦、自动发布到各大平台啦～</p><p>想了解 n8n 的工友可以关注我的专栏👉 <a href="https://link.segmentfault.com/?enc=Nt%2Bp%2Bw7xt6as4iE7iIt8BA%3D%3D.4n9vAkJILJrCoYtqKq5x4FHbvuXxlHgKcnLP%2FNOBRtgbWAkJDVsxjU1TeEQMollWDCKt1jorwQQR2KYvLq91MqLHuBLGWur4y7o5YdCyDP8X9Nodyc0njwfQ3GL%2BSpWjZWlNHtaz6Aq7W%2FMFUXvx9IVSnJR75OXmfCzJzdneHeg%3D" rel="nofollow" target="_blank">《n8n修炼手册》</a></p><p><strong>点赞 + 关注 + 收藏 = 学会了</strong></p>]]></description></item><item>    <title><![CDATA[生产力翻倍！16 款必备 VS Code 插件让你的开发效率起飞 李小白 ]]></title>    <link>https://segmentfault.com/a/1190000047570669</link>    <guid>https://segmentfault.com/a/1190000047570669</guid>    <pubDate>2026-01-25 22:06:36</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <blockquote>每天在 VS Code 里敲代码的你，真的把这个编辑器的潜力发挥到极致了吗？同样的工作，为什么别人的开发速度总是比你快？答案可能就在这些插件里。今天，我整理了 16 款亲测好用的 VS Code 插件，涵盖代码编辑、版本控制、智能提示等多个维度，帮你从"普通开发者"进化为"高效战士"！</blockquote><hr/><h2>📋 目录</h2><ul><li><a href="#为什么需要安装插件" target="_blank">为什么需要安装插件？</a></li><li><a href="#一代码编辑与格式化类" target="_blank">一、代码编辑与格式化类</a></li><li><a href="#二代码片段与智能提示类" target="_blank">二、代码片段与智能提示类</a></li><li><a href="#三git-版本控制类" target="_blank">三、Git 版本控制类</a></li><li><a href="#四开发工具与预览类" target="_blank">四、开发工具与预览类</a></li><li><a href="#五辅助工具类" target="_blank">五、辅助工具类</a></li><li><a href="#安装方式" target="_blank">安装方式</a></li><li><h2><a href="#总结" target="_blank">总结</a></h2></li></ul><h2>为什么需要安装插件？</h2><p>VS Code 本身已经非常强大，但它的真正魅力在于<strong>插件生态系统</strong>。通过安装合适的插件，你可以：</p><table><thead><tr><th align="left">能力提升</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">⚡ <strong>编码速度</strong></td><td align="left">智能提示、代码片段自动补全</td></tr><tr><td align="left">🎨 <strong>代码质量</strong></td><td align="left">自动格式化、语法检查、拼写检查</td></tr><tr><td align="left">🔍 <strong>代码导航</strong></td><td align="left">快速跳转、书签标记、Git 历史追踪</td></tr><tr><td align="left">👁️ <strong>实时预览</strong></td><td align="left">前端页面、SVG 图片即时查看</td></tr><tr><td align="left">🌈 <strong>视觉体验</strong></td><td align="left">彩色缩进、精美图标让编辑更愉悦</td></tr></tbody></table><hr/><h2>一、代码编辑与格式化类</h2><h3>1. 🎨 EditorConfig for VS Code</h3><p><strong>作用</strong>：统一不同编辑器和操作系统的代码风格（缩进、换行符等）。<br/><strong>使用场景</strong>：<br/>团队协作时，有人用 Windows 有人用 Mac，有人喜欢 Tab 缩进有人喜欢空格，导致代码风格混乱。EditorConfig 让所有人遵循同一套规则。<br/><strong>核心配置</strong>：<br/>在项目根目录创建 <code>.editorconfig</code> 文件：</p><pre><code class="ini">root = true
[*]
charset = utf-8
indent_style = space
indent_size = 2
end_of_line = lf
insert_final_newline = true
trim_trailing_whitespace = true</code></pre><blockquote>💡 <strong>安装后自动生效</strong>，无需额外配置。</blockquote><hr/><h3>2. ✨ Prettier - Code formatter</h3><p><strong>作用</strong>：一键美化代码，统一格式（单双引号、分号、缩进等）。<br/><strong>使用场景</strong>：<br/>写完代码后，格式乱糟糟？一键 <code>Shift + Alt + F</code>（Windows）或 <code>Shift + Option + F</code>（Mac），瞬间变整齐。<br/><strong>核心优势</strong>：</p><ul><li>支持 JavaScript、TypeScript、CSS、SCSS、JSON 等多种语言</li><li>可保存时自动格式化</li><li><p>团队风格统一，消灭"格式圣战"<br/><strong>配置示例</strong>（<code>.prettierrc</code>）：</p><pre><code class="json">{
"printWidth": 100,
"tabWidth": 2,
"singleQuote": true,
"semi": true,
"trailingComma": "es5"
}</code></pre><hr/><h3>3. 🔍 ESLint</h3><p><strong>作用</strong>：JavaScript/TypeScript 代码质量检查，发现潜在错误。<br/><strong>使用场景</strong>：</p></li><li>忘记声明变量</li><li>使用了未定义的函数</li><li>React Hooks 使用违规</li><li>不建议的语法写法<br/><strong>功能亮点</strong>：</li><li>实时在代码中显示错误和警告</li><li>提供自动修复建议</li><li><p>支持 React、Vue、TypeScript 等框架</p><blockquote>⚠️ <strong>建议配合 Prettier 使用</strong>：ESLint 管质量，Prettier 管颜值。</blockquote><hr/><h3>4. 🎭 Stylelint</h3><p><strong>作用</strong>：CSS/SCSS/Less 样式代码检查与自动修复。<br/><strong>使用场景</strong>：</p></li><li>CSS 冗余代码（重复定义）</li><li>颜色格式不统一</li><li>选择器写法不规范</li><li><p>SCSS 语法错误<br/><strong>配置示例</strong>（<code>.stylelintrc.json</code>）：</p><pre><code class="json">{
"extends": ["stylelint-config-standard"],
"rules": {
  "selector-class-pattern": null
}
}</code></pre><hr/><h3>5. 🌈 indent-rainbow</h3><p><strong>作用</strong>：让缩进层级显示为彩色，像彩虹一样。<br/><strong>使用场景</strong>：</p></li><li>长嵌套代码快速识别层级</li><li>避免缩进错误（多空格或少空格）</li><li><p>代码阅读更愉悦<br/><strong>效果预览</strong>：</p><pre><code class="javascript">function example() {
if (true) {        // 红色缩进
  const arr = [   // 绿色缩进
    1,             // 蓝色缩进
    2,
    3
  ];
}
}</code></pre><blockquote>🎯 <strong>小技巧</strong>：适合初学者识别代码块边界，老手可选择性安装。</blockquote><hr/><h2>二、代码片段与智能提示类</h2><h3>6. ⚡ ES7+ React/Redux/React-Native snippets</h3><p><strong>作用</strong>：提供 React 常用代码片段的快速输入。<br/><strong>使用场景</strong>：<br/>再也不用每次手写 <code>useEffect</code>、<code>useCallback</code>、<code>React.memo</code> 的完整模板，输入简写自动展开。<br/><strong>常用触发词</strong>：</p><table><thead><tr><th align="left">触发词</th><th align="left">展开内容</th></tr></thead><tbody><tr><td align="left"><code>rafce</code></td><td align="left">React 函数组件 + 默认导出</td></tr><tr><td align="left"><code>rafc</code></td><td align="left">React 箭头函数组件</td></tr><tr><td align="left"><code>uef</code></td><td align="left"><code>useEffect</code> Hook</td></tr><tr><td align="left"><code>ust</code></td><td align="left"><code>useState</code> Hook</td></tr><tr><td align="left"><code>ucb</code></td><td align="left"><code>useCallback</code> Hook</td></tr><tr><td align="left"><code>rem</code></td><td align="left"><code>React.memo</code> 包装</td></tr></tbody></table><p><strong>示例</strong>：</p><pre><code class="javascript">// 输入 rafce + Tab，自动展开：
import React from 'react'
const MyComponent = () =&gt; {
return (
  &lt;div&gt;rafce&lt;/div&gt;
)
}
export default MyComponent</code></pre><hr/><h3>7. 🎯 Tailwind CSS IntelliSense</h3><p><strong>作用</strong>：Tailwind CSS 类名智能提示、悬停预览、自动补全。<br/><strong>使用场景</strong>：</p></li><li>不记得某个工具类名怎么写</li><li>想知道某个类名的具体样式</li><li>防止拼写错误（如 <code>bg-red500</code> 写成 <code>bg-red-500</code>）<br/><strong>核心功能</strong>：</li><li>✅ 实时类名补全</li><li>✅ Hover 显示具体样式值</li><li>✅ Lint 提示未知类名</li><li><p>✅ 支持自定义配置文件读取</p><blockquote>💡 <strong>Tailwind 开发者的必备神器</strong>，效率提升 50%+！</blockquote><hr/><h3>8. 💚 Vue (Official)</h3><p><strong>作用</strong>：Vue 官方插件，提供语法高亮、智能提示、代码片段。<br/><strong>使用场景</strong>：</p></li><li>Vue 2/3 项目开发必备</li><li><code>.vue</code> 文件语法高亮</li><li>Vue 指令自动补全</li><li>Props、Emits 类型提示<br/><strong>支持特性</strong>：</li><li>✅ 单文件组件（SFC）完整支持</li><li>✅ TypeScript 支持</li><li>✅ Pinia 状态库集成</li><li><h2>✅ Vite 模块智能解析</h2><h2>三、Git 版本控制类</h2><h3>9. 🔬 GitLens — Git supercharged</h3><p><strong>作用</strong>：VS Code 中最强大的 Git 增强插件。<br/><strong>核心功能</strong>：</p><table><thead><tr><th align="left">功能</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">📝 <strong>代码作者</strong></td><td align="left">鼠标悬停显示这行代码是谁写的</td></tr><tr><td align="left">🕐 <strong>提交时间</strong></td><td align="left">显示代码最后修改时间</td></tr><tr><td align="left">🔀 <strong>分支对比</strong></td><td align="left">当前分支与其他分支的差异</td></tr><tr><td align="left">📋 <strong>提交详情</strong></td><td align="left">点击查看完整的 commit 信息和文件变更</td></tr><tr><td align="left">🔍 <strong>Blame 功能</strong></td><td align="left">显示每一行代码的提交记录</td></tr></tbody></table><p><strong>使用技巧</strong>：</p></li><li>按 <code>Ctrl + Shift + G</code> 打开 Git 面板</li><li>点击代码行左侧的 Git 图标查看作者</li><li><p>使用 "GitLens: Toggle File Blame" 查看整个文件的 blame</p><blockquote>🏆 <strong>被称为 Git 必装插件</strong>，强烈推荐！</blockquote><hr/><h3>10. 📊 Git Graph</h3><p><strong>作用</strong>：以可视化图形展示 Git 提交历史和分支关系。<br/><strong>使用场景</strong>：</p></li><li>直观查看分支合并情况</li><li>快速切换分支</li><li>查看 tag 标签</li><li>找到某个 commit 的父节点<br/><strong>功能亮点</strong>：</li><li>🌳 树状图展示提交历史</li><li>🏷️ 显示标签（Tags）</li><li>🔀 显示远程分支</li><li><p>⬇️ 支持 fetch/pull/push 操作</p><blockquote>💡 按 <code>Ctrl + Shift + G</code> 打开 Git 面板，点击 "Git Graph" 查看图形。</blockquote><hr/><h3>11. 📜 Git History</h3><p><strong>作用</strong>：查看文件或目录的 Git 历史记录。<br/><strong>核心功能</strong>：</p></li><li>查看某个文件的所有提交历史</li><li>比较两个版本的差异</li><li>恢复文件到某个历史版本</li><li>搜索特定提交<br/><strong>使用方式</strong>：</li><li>右键点击文件</li><li>选择 "Git: View File History"</li><li>点击某个 commit 查看详细变更</li><li><h2>点击 "Open File" 可查看历史版本</h2><h2>四、开发工具与预览类</h2><h3>12. 🌐 Live Server</h3><p><strong>作用</strong>：启动本地开发服务器，支持热更新。<br/><strong>使用场景</strong>：</p></li><li>HTML/CSS/JavaScript 原型开发</li><li>静态页面实时预览</li><li>修改代码后浏览器自动刷新<br/><strong>核心优势</strong>：</li><li>✅ 一键启动服务器</li><li>✅ 支持实时热更新</li><li>✅ 支持跨域请求</li><li>✅ 可自定义端口号<br/><strong>使用方式</strong>：</li><li>右键点击 <code>index.html</code></li><li>选择 "Open with Live Server"</li><li><p>浏览器自动打开 <code>http://127.0.0.1:5500/</code></p><blockquote>⚡ <strong>前端开发必备</strong>，告别手动刷新！</blockquote><hr/><h3>13. 🚀 open in browser</h3><p><strong>作用</strong>：一键在浏览器中打开当前 HTML 文件。<br/><strong>使用场景</strong>：</p></li><li>快速预览静态页面</li><li>支持 Chrome、Firefox、Edge 等多浏览器</li><li><p>无需启动服务器<br/><strong>快捷键</strong>：</p><table><thead><tr><th align="left">操作</th><th align="left">Windows/Linux</th><th align="left">Mac</th></tr></thead><tbody><tr><td align="left">在默认浏览器打开</td><td align="left"><code>Ctrl + B</code></td><td align="left"><code>Cmd + B</code></td></tr></tbody></table><hr/><h3>14. 🖼️ Svg Preview</h3><p><strong>作用</strong>：实时预览 SVG 图片，支持代码与视图同步。<br/><strong>使用场景</strong>：</p></li><li>SVG 图标调试</li><li>查看路径、坐标、颜色</li><li>实时修改代码预览效果<br/><strong>核心功能</strong>：</li><li>✅ 分屏显示：左侧代码，右侧预览</li><li>✅ 支持拖拽 SVG 文件直接预览</li><li>✅ 显示 SVG 的尺寸、路径信息</li><li><h2>✅ 支持动画预览</h2><h2>五、辅助工具类</h2><h3>15. 🔖 Bookmarks</h3><p><strong>作用</strong>：在代码中设置书签，快速跳转到重要位置。<br/><strong>使用场景</strong>：</p></li><li>跨多个文件快速定位</li><li>记住某个函数的位置</li><li><p>大文件中标记关键段落<br/><strong>快捷键</strong>：</p><table><thead><tr><th align="left">操作</th><th align="left">快捷键</th></tr></thead><tbody><tr><td align="left">切换书签</td><td align="left"><code>Ctrl + Alt + K</code></td></tr><tr><td align="left">跳转到上一个书签</td><td align="left"><code>Ctrl + Alt + J</code></td></tr><tr><td align="left">跳转到下一个书签</td><td align="left"><code>Ctrl + Alt + L</code></td></tr><tr><td align="left">清除所有书签</td><td align="left"><code>Ctrl + Shift + K</code></td></tr></tbody></table><p><strong>效果展示</strong>：</p><pre><code class="javascript">// 🔖 书签标记在函数名前
function importantFunction() {
// 这是一个重要函数，需要频繁查看
console.log('Hello');
}
// 🔖 另一个书签
function anotherFunction() {
// ...
}</code></pre><blockquote>💡 适合调试大项目时记录关键位置！</blockquote><hr/><h3>16. ✅ Code Spell Checker</h3><p><strong>作用</strong>：检查代码中的拼写错误，避免因单词写错导致的 Bug。<br/><strong>使用场景</strong>：</p></li><li>变量名拼写错误（<code>consoel.log</code> → <code>console.log</code>）</li><li>注释中的英文拼写错误</li><li>防止复制粘贴引入的错别字<br/><strong>核心功能</strong>：</li><li>✅ 实时拼写检查</li><li>✅ 支持驼峰命名识别</li><li>✅ 可添加自定义字典</li><li><p>✅ 支持多种语言<br/><strong>配置示例</strong>（添加自定义词汇）：</p><pre><code class="json">"cSpell.words": [
"react",
"tailwindcss",
"github"
]</code></pre><blockquote>🎯 <strong>特别适合非英语母语开发者</strong>，减少低级拼写错误！</blockquote><hr/><h3>17. 🎨 Icon Theme: Material</h3><p><strong>作用</strong>：为文件和文件夹提供精美的 Material Design 风格图标。<br/><strong>视觉提升</strong>：</p><table><thead><tr><th align="left">文件类型</th><th align="left">图标样式</th></tr></thead><tbody><tr><td align="left">React</td><td align="left">⚛️ React 图标</td></tr><tr><td align="left">Vue</td><td align="left">💚 Vue 绿色图标</td></tr><tr><td align="left">TypeScript</td><td align="left">🔷 TS 蓝色方块</td></tr><tr><td align="left">CSS/Sass</td><td align="left">🎨 彩色样式图标</td></tr><tr><td align="left">文件夹</td><td align="left">📁 不同颜色区分</td></tr></tbody></table><p><strong>优势</strong>：</p></li><li>✅ 一眼识别文件类型</li><li>✅ 文件夹颜色区分（src、dist、node_modules）</li><li>✅ 提升视觉愉悦度</li><li><p>✅ 支持自定义图标主题</p><blockquote>🌈 <strong>强烈推荐安装</strong>，让编辑器颜值提升一个档次！</blockquote><hr/><h2>安装方式</h2><h3>方法一：通过扩展商店安装（推荐）</h3></li><li>打开 VS Code</li><li>按 <code>Ctrl + Shift + X</code>（Mac：<code>Cmd + Shift + X</code>）打开扩展面板</li><li>在搜索框中输入插件名称</li><li><p>点击 "Install" 安装</p><h3>方法二：命令面板安装</h3></li><li>按 <code>Ctrl + Shift + P</code>（Mac：<code>Cmd + Shift + P</code>）</li><li>输入 <code>Extensions: Install Extensions</code></li><li><p>搜索并安装</p><h3>方法三：通过 setting.json 自动格式化配置</h3><p>在项目根目录中先创建.vscode目录，然后在.vscode目录中创建一个<code>setting.json</code>文件，配置自动格式化规则。</p><pre><code class="json">{
"editor.fontSize": 12,
"editor.tabSize": 2,
"eslint.enable": true,
"editor.formatOnSave": true,
"editor.formatOnType": true,
"eslint.validate": [
  "vue",
  "html",
  "javascript",
  "typescript",
  "javascriptreact",
  "typescriptreact"
],
"editor.defaultFormatter": "esbenp.prettier-vscode",
"prettier.requireConfig": true,
"prettier.semi": false,
"editor.codeActionsOnSave": {
  "source.fixAll": "explicit",
  "source.fixAll.eslint": "explicit",
  "source.fixAll.stylelint": "explicit"
},
"javascript.format.insertSpaceBeforeFunctionParenthesis": false,
"search.exclude": {
  "**/node_modules": true,
  "**/bower_components": true,
  "**/target": true,
  "**/logs": true
},
"css.validate": false,
"less.validate": false,
"scss.validate": false,
"stylelint.validate": [
  "css",
  "less",
  "postcss",
  "scss",
  "sass",
  "stylus",
  "vue"
],
"git.autofetch": true,
"cSpell.userWords": [
  "antd",
  "axios",
  "childs",
  "commitlint",
  "daterange",
  "echarts",
  "graphlib",
  "loadfj",
  "moveend",
  "tailwindcss",
  "vuepress",
  "vuex",
],
"workbench.startupEditor": "none",
"diffEditor.ignoreTrimWhitespace": false,
"workbench.iconTheme": "material-icon-theme"
}</code></pre><h3>方法四：通过 extensions.json 批量安装</h3><p>在.vscode目录中创建一个 <code>extensions.json</code> 文件，记录团队推荐插件，新成员可一键同步。</p><pre><code class="json">{
"recommendations": [
  // 代码编辑与格式化
  "esbenp.prettier-vscode",          // Prettier - Code formatter
  "dbaeumer.vscode-eslint",          // ESLint
  "stylelint.vscode-stylelint",      // Stylelint
  "EditorConfig.EditorConfig",       // EditorConfig for VS Code
  "oderwat.indent-rainbow",          // indent-rainbow

  // 代码片段与智能提示
  "dsznajder.es7-react-js-snippets", // ES7+ React/Redux/React-Native snippets
  "bradlc.vscode-tailwindcss",       // Tailwind CSS IntelliSense
  "Vue.volar",                       // Vue (Official)

  // Git 版本控制
  "eamodio.gitlens",                 // GitLens — Git supercharged
  "mhutchie.git-graph",              // Git Graph
  "donjayamanne.githistory",         // Git History

  // 开发工具与预览
  "ritwickdey.liveserver",           // Live Server
  "techer.open-in-browser",          // open in browser
  "SimonSiefke.svg-preview",         // Svg Preview

  // 辅助工具
  "alefragnani.bookmarks",           // Bookmarks
  "streetsidesoftware.code-spell-checker", // Code Spell Checker
  "PKief.material-icon-theme"        // Icon Theme: Material
]
}
</code></pre></li></ul><h2>生效方式</h2><blockquote>团队协作：将 .vscode/extensions.json 和 .vscode/extensions.json 提交到 Git 仓库。<br/>拉取代码：当团队成员 git pull 代码并在 VS Code 打开该项目时，右下角会弹出提示。<br/>一键安装：点击弹窗中的“安装全部”按钮，VS Code 就会自动帮你装好所有插件。</blockquote><hr/><h2>总结</h2><p>今天介绍的 16 款插件涵盖了前端开发的各个环节：</p><table><thead><tr><th align="left">类别</th><th align="center">插件数量</th><th align="left">核心价值</th></tr></thead><tbody><tr><td align="left">代码编辑与格式化</td><td align="center">5</td><td align="left">统一代码风格，提升可读性</td></tr><tr><td align="left">代码片段与智能提示</td><td align="center">3</td><td align="left">加速编码，减少重复劳动</td></tr><tr><td align="left">Git 版本控制</td><td align="center">3</td><td align="left">可视化管理，追溯代码历史</td></tr><tr><td align="left">开发工具与预览</td><td align="center">3</td><td align="left">实时反馈，提升开发体验</td></tr><tr><td align="left">辅助工具</td><td align="center">2</td><td align="left">减少错误，提升导航效率</td></tr></tbody></table><p><strong>安装建议</strong>：</p><ul><li>🌟 <strong>必装（5款）</strong>：ESLint、Prettier、GitLens、Live Server、ES7+ React Snippets</li><li>🌟 <strong>推荐（6款）</strong>：EditorConfig、Tailwind CSS IntelliSense、Git Graph、Bookmarks、Code Spell Checker、Icon Theme: Material</li><li><p>💡 <strong>可选（5款）</strong>：Stylelint、indent-rainbow、Vue (Official)、open in browser、Svg Preview（根据技术栈选择）</p><blockquote>💡 <strong>小贴士</strong>：不要一次安装过多插件，根据项目需求逐步添加，避免 VS Code 变得卡顿。</blockquote><hr/><p>希望这篇教程对你有所帮助！如有问题，欢迎交流讨论。</p></li></ul><p>本文由<a href="https://link.segmentfault.com/?enc=cYmo76IQYI1QdhMos4pINQ%3D%3D.Q5VgfRZ%2B6u0TigZyXBnoF7LESKQyok1j1pYByXoVumY%3D" rel="nofollow" target="_blank">mdnice</a>多平台发布</p>]]></description></item><item>    <title><![CDATA[『NAS』在群晖部署高颜值笔记工具-memos 德育处主任 ]]></title>    <link>https://segmentfault.com/a/1190000047570686</link>    <guid>https://segmentfault.com/a/1190000047570686</guid>    <pubDate>2026-01-25 22:06:00</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><strong>点赞 + 关注 + 收藏 = 学会了</strong></p><blockquote>整理了一个NAS小专栏，有兴趣的工友可以关注一下 👉 <a href="https://link.segmentfault.com/?enc=w5f3cAQ1lfeXnRu5t1VWyg%3D%3D.8pw%2FNxawMh%2BOCS07oO024NlBk7V5XCLQatGn%2FXuLk6PeN8Tk1%2F3qZsMC9hHDmCTsq3UsnRHm88DpyoUZ%2Bf0pScYZSVMVFZuTzymQThzdrsgYzEeazUYOg%2Bmij1MSjSfDwQpsjDoRRzmU%2BPH52Ogy3Dq6OGypiR0UaSoOi%2BPNgZY%3D" rel="nofollow" target="_blank">《NAS邪修》</a></blockquote><p>Memos 是一款开源免费、隐私优先的轻量化笔记工具，支持 Docker 一键部署到 NAS（数据本地存储，完全自主掌控）。它支持纯文本和 Markdown 格式，可通过标签、日历分类笔记，还能实现笔记引用、插入图片 / 附件等实用功能，低资源占用不拖慢设备，记想法、列待办、存资料都合适。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047570688" alt="" title=""/></p><p>本文使用群晖 NAS 部署 memos，其他 NAS 或者在电脑用 Docker 部署的方法大同小异。</p><p>首先在“File Station”的“docker”文件夹里创建一个“memos”文件夹。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047570689" alt="" title="" loading="lazy"/></p><p>然后打开”Container Manager“创建一个新项目，相关配置如下图所示。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047570690" alt="" title="" loading="lazy"/></p><p>输入以下代码（注意代码格式！！！）</p><pre><code>services:
  memos:
    image: neosmemo/memos:latest
    container_name: memos
    volumes:
      - .:/var/opt/memos
    ports:
      - 5230:5230</code></pre><p>开启“通过 Web Station 设置网页门户”</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047570691" alt="" title="" loading="lazy"/></p><p>接下来打开“web Station”新建一个“网络门户”。</p><p>相关配置如下图所示。</p><p>端口设置一个不跟其他项目冲突的数字即可，我用的是 <code>2345</code>。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047570692" alt="" title="" loading="lazy"/></p><p>完成上面的操作后，打开浏览器，输入 <code>NAS的IP + 端口（本例用的是2345）</code>，就可以使用 memos了。</p><p>首次使用需要创建一个账号。</p><p>在登录页下方可以设置 memos 系统使用什么语言以及主题色。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047570693" alt="" title="" loading="lazy"/></p><p>登录后就可以开始写笔记了。它支持 Markdown 语法，挺适合用来写博客的。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047570694" alt="" title="" loading="lazy"/></p><hr/><p>以上就是本文的全部内容啦，想了解更多NAS玩法可以关注<a href="https://link.segmentfault.com/?enc=1oRYN0GIb1ZewImCZGNyGw%3D%3D.coC3yjMnZfY3aqnJug9NTGURxuVk02xE2Dv3nAxmKG9%2ForPG6q%2BFyteWxOtFKexaY4UyKB6WKGchPzSe8sc4s%2FNzoD24uDWf3bxu79QYlqU18exkBRvS42lJxEhWQf4MI6X2qCTCelNqeYtsAceEnHTUQOQsgtU%2BxE%2BeXUN0ovA%3D" rel="nofollow" target="_blank">《NAS邪修》👏</a></p><p>最后推荐一下玩 NAS 的工友，在 NAS 上装一个 n8n 接入大模型，可以帮你定时定候完成各种工作，比如签到啦、写文章啦、生成海报和视频啦、自动发布到各大平台啦～</p><p>想了解 n8n 的工友可以关注我的专栏👉 <a href="https://link.segmentfault.com/?enc=OLOsWwpTtnhmPEKIRl8Emg%3D%3D.OU48zzKHHRXN%2BWF7rJfsW9PViU8aJawAS60CztFiMOsYz9t42bL%2FdTVKnKCSwGBEKG7MnAdMTqLujPLgqE0uOSzkxhxqkO6QC1%2F9VmJiEax6eff6kXhAXFrRpKOY5MKtHLcJqifeci%2Fq42i%2FJcJMti%2Bq2P25hS3oJQ0jzG5Y540%3D" rel="nofollow" target="_blank">《n8n修炼手册》</a></p><p><strong>点赞 + 关注 + 收藏 = 学会了</strong></p>]]></description></item><item>    <title><![CDATA[如何使用image-syncer 实现 Docker Hub 到 Azure ACR 的自动化镜像同]]></title>    <link>https://segmentfault.com/a/1190000047570703</link>    <guid>https://segmentfault.com/a/1190000047570703</guid>    <pubDate>2026-01-25 22:05:04</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>实现 Docker Hub 到 Azure ACR 的自动化镜像同步</h2><blockquote>本文介绍了如何使用 GitHub Actions 和 image-syncer 工具，实现 Docker Hub 镜像到 Azure Container Registry 的自动化同步，解决了国内及部分 Azure 区域访问 Docker Hub 速度慢的问题，提升了镜像的可用性和 Azure 环境的部署效率。</blockquote><p>&lt;!-- truncate --&gt;</p><h3>背景/引言</h3><p>HagiCode 项目使用 Docker 镜像作为核心运行时组件，主要镜像托管在 Docker Hub。随着项目发展和 Azure 环境部署需求的增加，我们遇到了以下痛点：</p><ul><li>镜像拉取速度慢，Docker Hub 在国内及部分 Azure 区域访问受限</li><li>依赖单一镜像源存在单点故障风险</li><li>Azure 环境下使用 Azure Container Registry 能获得更好的网络性能和集成体验</li></ul><p>为解决这些问题，我们需要建立一个自动化的镜像同步机制，将 Docker Hub 的镜像定期同步到 Azure ACR，确保用户能够在 Azure 环境中获得更快的镜像拉取速度和更高的可用性。</p><h3>关于 HagiCode</h3><p>我们正在开发 HagiCode——一款 AI 驱动的代码智能助手，让开发体验变得更智能、更便捷、更有趣。</p><p>智能——AI 全程辅助，从想法到代码，让编码效率提升数倍。便捷——多线程并发操作，充分利用资源，开发流程顺畅无阻。有趣——游戏化机制和成就系统，让编码不再枯燥，充满成就感。</p><p>项目正在快速迭代中，如果你对技术写作、知识管理或者 AI 辅助开发感兴趣，欢迎来 GitHub 看看。</p><h3>技术方案对比</h3><p>在制定解决方案时，我们对比了多种技术方案：</p><h4>1. image-syncer（最终选择）</h4><ul><li>增量同步：仅同步变更的镜像层，显著减少网络传输</li><li>断点续传：网络中断后可恢复同步</li><li>并发控制：支持配置并发线程数，提升大镜像同步效率</li><li>完善的错误处理：内置失败重试机制（默认 3 次）</li><li>轻量级部署：单二进制文件，无依赖</li><li>多仓库支持：兼容 Docker Hub、Azure ACR、Harbor 等</li></ul><h4>2. Docker CLI</h4><ul><li>不支持增量同步：每次都需要拉取完整的镜像内容</li><li>效率较低：网络传输量大，时间长</li><li>简单易用：使用熟悉的 docker pull/push 命令</li></ul><h4>3. Azure CLI</h4><ul><li>复杂度高：需要配置 Azure CLI 认证</li><li>功能限制：az acr import 功能相对单一</li><li>原生集成：与 Azure 服务集成良好</li></ul><h3>架构设计决策</h3><h4>决策 1：同步频率设置为每日 UTC 00:00</h4><ul><li>平衡镜像新鲜度和资源消耗</li><li>避开业务高峰期，减少对其他操作的影响</li><li>Docker Hub 镜像通常在每日构建后更新</li></ul><h4>决策 2：同步所有镜像标签</h4><ul><li>保持与 Docker Hub 的完全一致性</li><li>为用户提供灵活的版本选择</li><li>简化同步逻辑，避免复杂的标签过滤规则</li></ul><h4>决策 3：使用 GitHub Secrets 存储认证信息</h4><ul><li>GitHub Actions 原生支持，安全性高</li><li>配置简单，易于管理和维护</li><li>支持仓库级别的访问控制</li></ul><h3>风险评估与缓解</h3><h4>风险 1：Azure ACR 认证信息泄露</h4><ul><li>使用 GitHub Secrets 加密存储</li><li>定期轮换 ACR 密码</li><li>限制 ACR 用户权限为仅推送</li><li>监控 ACR 访问日志</li></ul><h4>风险 2：同步失败导致镜像不一致</h4><ul><li>image-syncer 内置增量同步机制</li><li>自动失败重试（默认 3 次）</li><li>详细的错误日志和失败通知</li><li>断点续传功能</li></ul><h4>风险 3：资源消耗过大</h4><ul><li>增量同步减少网络传输</li><li>可配置并发线程数（当前设置为 10）</li><li>监控同步的镜像数量和大小</li><li>在非高峰时段运行同步</li></ul><h3>核心解决方案</h3><p>我们采用 GitHub Actions + image-syncer 的自动化方案，实现从 Docker Hub 到 Azure ACR 的镜像同步。</p><h3>实施步骤</h3><h4>1. 准备阶段</h4><ul><li>在 Azure Portal 中创建或确认 Azure Container Registry</li><li>创建 ACR 访问密钥（用户名和密码）</li><li>确认 Docker Hub 镜像仓库访问权限</li></ul><h4>2. 配置 GitHub Secrets</h4><p>在 GitHub 仓库设置中添加以下 Secrets：</p><ul><li>AZURE_ACR_USERNAME: Azure ACR 用户名</li><li>AZURE_ACR_PASSWORD: Azure ACR 密码</li></ul><h4>3. 创建 GitHub Actions 工作流</h4><p>在 .github/workflows/sync-docker-acr.yml 中配置工作流：</p><ul><li>定时触发：每天 UTC 00:00</li><li>手动触发：支持 workflow_dispatch</li><li>额外触发：publish 分支推送时触发（用于快速同步）</li></ul><h4>4. 工作流执行流程</h4><pre style="display:none;"><code class="mermaid">sequenceDiagram
    participant GH as GitHub Actions
    participant IS as image-syncer
    participant DH as Docker Hub
    participant ACR as Azure ACR

    Note over GH: 触发工作流
    GH-&gt;&gt;IS: 下载并执行 image-syncer
    IS-&gt;&gt;DH: 获取镜像 manifest 和标签列表
    DH--&gt;&gt;IS: 返回镜像元数据
    IS-&gt;&gt;ACR: 获取已存在的镜像信息
    ACR--&gt;&gt;IS: 返回目标镜像信息
    IS-&gt;&gt;IS: 对比差异，识别变更的镜像层
    Note over IS: 增量同步：仅传输变更的镜像层
    IS-&gt;&gt;DH: 拉取变更的镜像层
    DH--&gt;&gt;IS: 返回镜像层内容
    IS-&gt;&gt;ACR: 推送变更的镜像层到 ACR
    ACR--&gt;&gt;IS: 返回推送结果
    IS--&gt;&gt;GH: 返回同步统计信息
    GH-&gt;&gt;GH: 记录同步日志并上传 artifact</code></pre><h3>GitHub Actions 工作流实现</h3><p>以下是实际运行的工作流配置（.github/workflows/sync-docker-acr.yml）：</p><pre><code class="yaml">name: Sync Docker Image to Azure ACR

on:
  schedule:
    - cron: "0 0 * * *" # 每天 UTC 00:00
  workflow_dispatch: # 手动触发
  push:
    branches: [publish]

permissions:
  contents: read

jobs:
  sync:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download image-syncer
        run: |
          # 下载 image-syncer 二进制文件
          wget https://github.com/AliyunContainerService/image-syncer/releases/download/v1.5.5/image-syncer-v1.5.5-linux-amd64.tar.gz
          tar -zxvf image-syncer-v1.5.5-linux-amd64.tar.gz
          chmod +x image-syncer

      - name: Create auth config
        run: |
          # 生成认证配置文件 (YAML 格式)
          cat &gt; auth.yaml &lt;&lt;EOF
          hagicode.azurecr.io:
            username: "${{ secrets.AZURE_ACR_USERNAME }}"
            password: "${{ secrets.AZURE_ACR_PASSWORD }}"
          EOF

      - name: Create images config
        run: |
          # 生成镜像同步配置文件 (YAML 格式)
          cat &gt; images.yaml &lt;&lt;EOF
          docker.io/newbe36524/hagicode: hagicode.azurecr.io/hagicode
          EOF

      - name: Run image-syncer
        run: |
          # 执行同步 (使用新版 --auth 和 --images 参数)
          ./image-syncer --auth=./auth.yaml --images=./images.yaml --proc=10 --retries=3

      - name: Upload logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: sync-logs
          path: image-syncer-*.log
          retention-days: 7</code></pre><h3>配置说明</h3><h4>1. 触发条件</h4><ul><li>定时触发：cron: "0 0 <em> </em> *" - 每天 UTC 00:00 执行</li><li>手动触发：workflow_dispatch - 允许用户在 GitHub UI 手动运行</li><li>推送触发：push: branches: [publish] - 发布分支推送时触发（用于快速同步）</li></ul><h4>2. 认证配置 (auth.yaml)</h4><pre><code class="yaml">hagicode.azurecr.io:
  username: "${{ secrets.AZURE_ACR_USERNAME }}"
  password: "${{ secrets.AZURE_ACR_PASSWORD }}"</code></pre><h4>3. 镜像同步配置</h4><pre><code class="yaml">docker.io/newbe36524/hagicode: hagicode.azurecr.io/hagicode</code></pre><p>此配置表示将 docker.io/newbe36524/hagicode 的所有标签同步到 hagicode.azurecr.io/hagicode</p><h4>4. image-syncer 参数</h4><ul><li>--auth=./auth.yaml: 认证配置文件路径</li><li>--images=./images.yaml: 镜像同步配置文件路径</li><li>--proc=10: 并发线程数为 10</li><li>--retries=3: 失败重试 3 次</li></ul><h3>GitHub Secrets 配置清单</h3><p>在 GitHub 仓库的 Settings → Secrets and variables → Actions 中配置：</p><table><thead><tr><th>Secret 名称</th><th>描述</th><th>示例值</th><th>获取方式</th></tr></thead><tbody><tr><td>AZURE_ACR_USERNAME</td><td>Azure ACR 用户名</td><td>hagicode</td><td>Azure Portal → ACR → Access keys</td></tr><tr><td>AZURE_ACR_PASSWORD</td><td>Azure ACR 密码</td><td>xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx</td><td>Azure Portal → ACR → Access keys → Password</td></tr></tbody></table><h3>使用说明</h3><h4>1. 手动触发同步</h4><ol><li>访问 GitHub 仓库的 Actions 标签页</li><li>选择 Sync Docker Image to Azure ACR 工作流</li><li>点击 Run workflow 按钮</li><li>选择分支并点击 Run workflow 确认</li></ol><h4>2. 查看同步日志</h4><ol><li>在 Actions 页面点击具体的工作流运行记录</li><li>查看各个步骤的执行日志</li><li>在页面底部的 Artifacts 区域下载 sync-logs 文件</li></ol><h4>3. 验证同步结果</h4><pre><code class="bash"># 登录到 Azure ACR
az acr login --name hagicode

# 列出镜像及其标签
az acr repository show-tags --name hagicode --repository hagicode --output table</code></pre><h3>注意事项和最佳实践</h3><h4>1. 安全建议</h4><ul><li>定期轮换 Azure ACR 密码（建议每 90 天）</li><li>使用专用的 ACR 服务账户，限制权限为仅推送</li><li>监控 ACR 的访问日志，及时发现异常访问</li><li>不要在日志中输出认证信息</li><li>不要将认证信息提交到代码仓库</li></ul><h4>2. 性能优化</h4><ul><li>调整 --proc 参数：根据网络带宽调整并发数（建议 5-20）</li><li>监控同步时间：如果同步时间过长，考虑减少并发数</li><li>定期清理日志：设置合理的 retention-days（当前为 7 天）</li></ul><h4>3. 故障排查</h4><h5>问题 1：认证失败</h5><pre><code>Error: failed to authenticate to hagicode.azurecr.io</code></pre><p>解决方案：</p><ol><li>检查 GitHub Secrets 是否正确配置</li><li>验证 Azure ACR 密码是否过期</li><li>确认 ACR 服务账户权限是否正确</li></ol><h5>问题 2：网络超时</h5><pre><code>Error: timeout waiting for response</code></pre><p>解决方案：</p><ol><li>检查网络连接</li><li>减少并发线程数（--proc 参数）</li><li>等待网络恢复后重新触发工作流</li></ol><h5>问题 3：镜像同步不完整</h5><pre><code>Warning: some tags failed to sync</code></pre><p>解决方案：</p><ol><li>检查同步日志，识别失败的标签</li><li>手动触发工作流重新同步</li><li>验证 Docker Hub 源镜像是否正常</li></ol><h4>4. 监控和告警</h4><ul><li>定期检查 Actions 页面，确认工作流运行状态</li><li>设置 GitHub 通知，及时获取工作流失败通知</li><li>监控 Azure ACR 的存储使用情况</li><li>定期验证镜像标签一致性</li></ul><h3>常见问题和解决方案</h3><h4>Q1: 如何同步特定标签而不是所有标签？</h4><p>修改 images.yaml 配置文件：</p><pre><code class="yaml"># 仅同步 latest 和 v1.0 标签
docker.io/newbe36524/hagicode:latest: hagicode.azurecr.io/hagicode:latest
docker.io/newbe36524/hagicode:v1.0: hagicode.azurecr.io/hagicode:v1.0</code></pre><h4>Q2: 如何同步多个镜像仓库？</h4><p>在 images.yaml 中添加多行配置：</p><pre><code class="yaml">docker.io/newbe36524/hagicode: hagicode.azurecr.io/hagicode
docker.io/newbe36524/another-image: hagicode.azurecr.io/another-image</code></pre><h4>Q3: 同步失败后如何重试？</h4><ul><li>自动重试：image-syncer 内置重试机制（默认 3 次）</li><li>手动重试：在 GitHub Actions 页面点击 Re-run all jobs</li></ul><h4>Q4: 如何查看同步的详细进度？</h4><ul><li>在 Actions 页面查看实时日志</li><li>下载 sync-logs artifact 查看完整日志文件</li><li>日志文件包含每个标签的同步状态和传输速度</li></ul><h4>Q5: 同步需要多长时间？</h4><ul><li>首次全量同步：根据镜像大小，通常需要 10-30 分钟</li><li>增量同步：如果镜像变更小，通常 2-5 分钟</li><li>时间取决于网络带宽、镜像大小和并发设置</li></ul><h3>扩展功能建议</h3><h4>1. 添加同步通知</h4><p>在工作流中添加通知步骤：</p><pre><code class="yaml">- name: Notify on success
  if: success()
  run: |
    echo "Docker images synced successfully to Azure ACR"</code></pre><h4>2. 实现镜像标签过滤</h4><p>在工作流中添加标签过滤逻辑：</p><pre><code class="yaml">- name: Filter tags
  run: |
    # 仅同步以 v 开头的标签
    echo "docker.io/newbe36524/hagicode:v* : hagicode.azurecr.io/hagicode:v*" &gt; images.yaml</code></pre><h4>3. 添加同步统计报告</h4><pre><code class="yaml">- name: Generate report
  if: always()
  run: |
    echo "## Sync Report" &gt;&gt; $GITHUB_STEP_SUMMARY
    echo "- Total tags: $(grep -c 'synced' image-syncer-*.log)" &gt;&gt; $GITHUB_STEP_SUMMARY
    echo "- Sync time: ${{ steps.sync.outputs.duration }}" &gt;&gt; $GITHUB_STEP_SUMMARY</code></pre><h3>总结</h3><p>通过本文介绍的方法，我们成功实现了从 Docker Hub 到 Azure ACR 的自动化镜像同步。这个方案利用 GitHub Actions 的定时触发和手动触发功能，结合 image-syncer 的增量同步和错误处理机制，确保了镜像的及时同步和一致性。</p><p>我们还讨论了安全最佳实践、性能优化、故障排查等方面的内容，帮助用户更好地管理和维护这个同步机制。希望本文能够为需要在 Azure 环境中部署 Docker 镜像的开发者提供有价值的参考。</p><h3>参考资料</h3><ul><li><a href="https://link.segmentfault.com/?enc=Pd2g3XD8YIynwUWXMDqI3Q%3D%3D.LaW%2FTPds8MrWZzgdxsPriXyWSb148XDkg7T2RSNMzm5a8MrbgTxi9TauMpb3Y2WJ" rel="nofollow" target="_blank">HagiCode 项目 GitHub 仓库</a></li><li><a href="https://link.segmentfault.com/?enc=4MGWQ8wbqimquV6A54cDaw%3D%3D.qB2INxueprwCBmsFoWfPRo8etGH%2B8ZO0a35AeTzp1uVSLL%2FKZJc1cog75FimHlRS63ML6EivvmD%2BC5erjnCp2A%3D%3D" rel="nofollow" target="_blank">image-syncer 官方文档</a></li><li><a href="https://link.segmentfault.com/?enc=qX1B3lRyh5lY1qZkRjfD4Q%3D%3D.toeZzv4HmTvICR3xx7pnOInKAJ6egEoxUDPbdX4Wl4nTF6ZMEA4u3Pl6Cw1Fh1HBgf06aUjaahXEWTI0X5gGpQ%3D%3D" rel="nofollow" target="_blank">Azure Container Registry 官方文档</a></li><li><a href="https://link.segmentfault.com/?enc=mBZrCfjD9A%2BO0GqFSJEmSw%3D%3D.K3kDeRlrqr6qqg%2BoroEBsJsQVKKXQQ7sGdqnsLCVAt%2FzCZGg4ksMMaFKBYaCGtNy" rel="nofollow" target="_blank">GitHub Actions 官方文档</a></li></ul><hr/><h3>互动引导</h3><p>感谢您的阅读,如果您觉得本文有用,快点击下方点赞按钮👍,让更多的人看到本文。</p><h3>AI 辅助声明</h3><p>本内容采用人工智能辅助协作,经本人审核,符合本人观点与立场。</p><h3>元信息</h3><ul><li><strong>本文作者:</strong> <a href="https://link.segmentfault.com/?enc=0UmM1po62FQAfgADy1I3Ug%3D%3D.VaCGOGCPCoQE7EGyPPbdEkTcnB5gQQE%2By%2BDiqVs2E2Q%3D" rel="nofollow" target="_blank">newbe36524</a></li><li><strong>本文链接:</strong> <a href="https://link.segmentfault.com/?enc=8uH6p3mXrSRl1JlahsHqdw%3D%3D.%2FtRUjczv1DwNkHndw4xj4uG7s2WQYRcRGUUYBn3%2BNPjY0HMIRMwIKXU%2FjrgJ5O5tIC3RlRAoijpRbWU9gwPq5xNXcSuqqfErJGhjaEtr7YUAcMfF61gCHHb5hh7SDZYwvFI3WkhWiGieuuuNjZATjw%3D%3D" rel="nofollow" target="_blank">https://hagicode-org.github.io/site/blog/2026/01/25/how-to-sync-docker-hub-to-azure-acr-with-github</a></li><li><strong>版权声明:</strong> 本博客所有文章除特别声明外,均采用 BY-NC-SA 许可协议。转载请注明出处!</li></ul>]]></description></item><item>    <title><![CDATA[新书《鸿蒙HarmonyOS 6应用开发：从零基础到App上线》出版啦 aqi00 ]]></title>    <link>https://segmentfault.com/a/1190000047570734</link>    <guid>https://segmentfault.com/a/1190000047570734</guid>    <pubDate>2026-01-25 22:04:31</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>​基于最新鸿蒙系统的技术书籍《鸿蒙HarmonyOS 6应用开发:从零基础到App上线》上市啦，要知道 HarmonyOS 6 在一个多月前的10月22日才正式发布，因此这本鸿蒙教程可谓贴近最新的 HarmonyOS 6 系统。</p><p>当前 HarmonyOS 6 的装机量迅猛增长，有望在春节前突破5000万台大关，可见鸿蒙系统的应用开发将越来越流行，甚至借助国产化的浪潮，未来在国内移动操作系统领域一举夺魁也不是不可能。</p><p>有鉴于此，博主精心编撰了 HarmonyOS 6 的应用开发教程《鸿蒙HarmonyOS 6应用开发:从零基础到App上线》，从基础到高级，从理论到实战，从 UI 到 AI ，仅需一本书籍，即可让读者掌握鸿蒙应用的常见开发技能。</p><p><img width="723" height="732" referrerpolicy="no-referrer" src="/img/bVdnLhb" alt="" title=""/></p><p>鸿蒙应用开发与安卓应用开发同为App开发，比如鸿蒙版微信和安卓版微信都是即时通信App，二者在实现技术上并无多少本质区别。所以《鸿蒙HarmonyOS 6应用开发:从零基础到App上线》一书以《Android Studio开发实战：从零基础到App上线(第3版)》为蓝本，把安卓系统的App教程改造为鸿蒙系统的App教程，以便安卓开发者能够按图索骥迅速上手。欣喜的是，《Android Studio开发实战：从零基础到App上线(第3版)》提到的安卓开发技术，绝大部分都能在鸿蒙系统找到对应的平替技术，而且还是更简单的代码实现。</p><p>作为《Android Studio开发实战：从零基础到App上线(第3版)》一书的鸿蒙姊妹篇，《鸿蒙HarmonyOS 6应用开发:从零基础到App上线》仍然采取了由浅入深、循序渐进的章节体例，其中前8章是基础部分，主要讲解 DevEco Studio 的环境搭建、ArkTS语言编程基础、鸿蒙App开发的各种常用组件、鸿蒙App开发的页面转场和消息交互、鸿蒙App的几种数据存储方式等；后8章是进阶部分，主要讲解鸿蒙App开发的后台任务、手势交互、动画特效、网络通信、多媒体、感知定位、人工智能、多端部署等。</p><p><img width="723" height="732" referrerpolicy="no-referrer" src="/img/bVdnLhd" alt="" title="" loading="lazy"/></p><p>曾经有老读者咨询“从零基础到App上线”系列书籍的第4版何时面世，现在博主终于可以说，“从零基础到App上线”的第4版已经出版啦，而且第4版是鸿蒙版本的“从零基础到App上线”，它就叫做《鸿蒙HarmonyOS 6应用开发:从零基础到App上线》，该书把安卓版教程平替为鸿蒙版教程，也是一个勇敢的尝试。</p><p>《鸿蒙HarmonyOS 6应用开发:从零基础到App上线》在讲解知识点的同时给出了大量实战范例，方便读者迅速将所学的知识运用到实际开发中。通过本书的学习，读者能够掌握3类主流App的基本开发技术，包括购物App（电子商务）、聊天App（即时通信）、娱乐App（短视频分享）。另外，能够学会开发一些趣味应用，包括计算器、录音笔、电子相册、打牌游戏、指南针、水平仪、卫星浑天仪、登山助手、附近交友、速记助手、人脸识别等等。可见《Android Studio开发实战：从零基础到App上线(第3版)》一书提到的实战项目，本书基本提供了对应的鸿蒙版App。</p><p><img width="723" height="311" referrerpolicy="no-referrer" src="/img/bVdnLhe" alt="" title="" loading="lazy"/></p><p>《鸿蒙HarmonyOS 6应用开发:从零基础到App上线》的随书源码包括客户端部分和服务端部分，其中客户端的App代码基于 DevEco Studio 6.0.0 Release 开发，并使用 API 20 的 SDK （HarmonyOS 6.0.0）编译与调试通过，测试机型包括 Mate 60 Pro 和 nova 12 Pro 。配套的服务端源码采用 Java WEB 框架，结合 MySQL 数据库，并基于 IDEA 开发。</p>]]></description></item><item>    <title><![CDATA[高可用的三件事——无状态化、水平扩展与故障转移的协同设计 南城 ]]></title>    <link>https://segmentfault.com/a/1190000047570767</link>    <guid>https://segmentfault.com/a/1190000047570767</guid>    <pubDate>2026-01-25 22:03:46</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><strong>写在前面，本人目前处于求职中，如有合适内推岗位，请加：lpshiyue 感谢。同时还望大家一键三连，赚点奶粉钱。本系列已完结，完整版阅读课联系本人</strong></p><blockquote>高可用不是简单的冗余堆砌，而是无状态化、水平扩展与故障转移三者协同的艺术品</blockquote><p>在掌握了系统压测方法论，能够准确评估系统容量边界后，我们面临一个更根本的挑战：如何让系统在真实流量冲击和故障发生时保持稳定？高可用架构设计正是解决这一挑战的核心手段。本文将深入解析无状态化、水平扩展与故障转移三大支柱技术的协同设计，帮助构建真正弹性可靠的系统架构。</p><h2>1 高可用的本质：从故障避免到故障容忍的哲学转变</h2><h3>1.1 高可用性的核心价值重估</h3><p>传统观念中，高可用意味着<strong>尽可能避免故障</strong>，而在分布式系统环境下，这一理念已转变为<strong>快速发现和恢复故障</strong>。根据Gartner的统计，企业IT系统平均每分钟的宕机成本超过5600美元，对于大型电商平台，这个数字可能达到数万美元。</p><p><strong>高可用设计的哲学转变</strong>体现在三个层面：</p><ul><li><strong>从完美预防到快速恢复</strong>：接受故障必然性，专注于最小化MTTR（平均修复时间）</li><li><strong>从单体坚固到分布式韧性</strong>：通过系统设计而非组件质量保证可用性</li><li><strong>从人工干预到自动化愈合</strong>：建立系统自愈能力，减少人工依赖</li></ul><p>这种转变使我们需要重新定义高可用的成功标准：不是追求100%无故障，而是确保故障发生时<strong>业务影响可控、恢复过程自动</strong>。</p><h3>1.2 可用性等级的理性定位</h3><p>不同业务场景对可用性有不同要求，理性定位是避免过度设计的第一步：</p><p><strong>99.9%可用性</strong>（年停机时间≤8.76小时）适合内部管理系统<br/><strong>99.95%可用性</strong>（年停机时间≤4.38小时）适合一般业务系统<br/><strong>99.99%可用性</strong>（年停机时间≤52.6分钟）适合核心业务系统<br/><strong>99.999%可用性</strong>（年停机时间≤5.26分钟）适合金融交易系统</p><p>确立合理的可用性目标后，我们才能有针对性地选择技术方案，在成本与可靠性间找到平衡点。</p><h2>2 无状态化：弹性架构的基石</h2><h3>2.1 无状态设计的本质与价值</h3><p>无状态化不是简单去除会话数据，而是<strong>将状态与计算分离</strong>，使应用实例变得可替代。这种分离是水平扩展和故障转移的基础。</p><p><strong>有状态架构的典型问题</strong>：</p><pre><code class="java">// 问题示例：会话绑定导致扩展困难
@RestController
public class StatefulController {
    // 会话状态存储在内存中
    private Map&lt;String, UserSession&gt; userSessions = new ConcurrentHashMap&lt;&gt;();
    
    @GetMapping("/userinfo")
    public String getUserInfo(HttpSession session) {
        UserSession userSession = (UserSession) session.getAttribute("currentUser");
        // 此实例绑定特定用户会话，无法随意替换
        return userSession.getUserInfo();
    }
}</code></pre><p><em>状态内嵌导致实例不可替换</em></p><p><strong>无状态化改造方案</strong>：</p><pre><code class="java">@Configuration
@EnableRedisHttpSession // 启用Redis会话存储
public class StatelessConfig {
    // 会话外部化配置
}

@RestController
public class StatelessUserController {
    @GetMapping("/userinfo")
    public String getUserInfo(@RequestHeader("Authorization") String token) {
        // 从Redis获取用户信息，不依赖本地状态
        String userJson = redisTemplate.opsForValue().get("session:" + token);
        User user = JsonUtil.fromJson(userJson, User.class);
        return user.toString();
    }
}</code></pre><p><em>状态外置使实例可任意替换</em></p><h3>2.2 无状态化的多层次实践</h3><p>无状态化需要在不同层级实施协同策略：</p><p><strong>应用层无状态</strong>：会话数据外部化到专用存储（Redis Cluster）<br/><strong>服务层无状态</strong>：API设计保证请求自包含，不依赖服务实例内存状态<br/><strong>任务层无状态</strong>：计算任务参数和结果完全自包含，支持任意重调度</p><p><strong>无状态设计的业务适配策略</strong>：</p><ul><li><strong>完全无状态</strong>：适合查询类、计算型业务（商品查询、价格计算）</li><li><strong>外部状态</strong>：适合需要会话保持但无需实例绑定的业务（用户登录状态）</li><li><strong>轻量状态</strong>：适合短暂业务流程，状态生命周期与请求周期一致</li></ul><h3>2.3 无状态架构的代价与应对</h3><p>无状态化不是银弹，需要认识其代价并制定应对策略：</p><p><strong>性能代价</strong>：状态外部化增加网络开销，需要通过缓存、批处理优化<br/><strong>一致性挑战</strong>：分布式状态需要处理并发更新，采用乐观锁或版本控制<br/><strong>复杂度增加</strong>：需要引入额外组件（Redis、ZooKeeper），增加运维复杂度</p><p>合理的无状态化是<strong>有选择的无状态</strong>，而非盲目去除所有状态。核心是确保<strong>实例可替换性</strong>，而非完全消除状态。</p><h2>3 水平扩展：流量压力的分布式化解</h2><h3>3.1 水平扩展的本质与架构前提</h3><p>水平扩展通过<strong>增加实例数量</strong>而非提升单机性能来应对流量增长，其有效性直接依赖于无状态化程度。</p><p><strong>水平扩展的架构前提</strong>：</p><ul><li><strong>无状态设计</strong>：实例间无数据依赖，可任意增减</li><li><strong>负载均衡</strong>：流量按策略分发到多个实例</li><li><strong>服务发现</strong>：动态感知实例上下线，实时更新路由</li><li><strong>健康检查</strong>：自动隔离故障实例，保证流量只会到达健康节点</li></ul><h3>3.2 分层扩展策略</h3><p>系统不同层级需要采用不同的水平扩展策略：</p><p><strong>接入层扩展</strong>：通过DNS轮询、全局负载均衡实现流量入口扩展</p><pre><code class="yaml"># Nginx上游服务配置示例
upstream backend_servers {
    server 10.0.1.10:8080 max_fails=3 fail_timeout=30s;
    server 10.0.1.11:8080 max_fails=3 fail_timeout=30s;
    server 10.0.1.12:8080 backup;  # 备份节点
    least_conn;  # 最少连接负载均衡
}</code></pre><p><em>接入层通过集群化实现扩展</em></p><p><strong>应用层扩展</strong>：无状态服务实例水平扩展，结合自动伸缩策略</p><pre><code class="yaml"># Kubernetes HPA配置示例
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: frontend-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: frontend
  minReplicas: 3
  maxReplicas: 100
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70</code></pre><p><em>应用层根据负载自动伸缩</em></p><p><strong>数据层扩展</strong>：通过分片、读写分离等技术实现数据访问扩展</p><pre><code class="sql">-- 数据库分片示例：用户数据按ID分片
-- 分片1：用户ID以0-4结尾
CREATE TABLE users_1 (
    id BIGINT PRIMARY KEY,
    name VARCHAR(100),
    -- 其他字段
);

-- 分片2：用户ID以5-9结尾  
CREATE TABLE users_2 (
    id BIGINT PRIMARY KEY,
    name VARCHAR(100),
    -- 其他字段
);</code></pre><p><em>数据层通过分片实现水平扩展</em></p><h3>3.3 水平扩展的粒度控制</h3><p>科学的水平扩展需要<strong>精细化粒度控制</strong>，避免过度或不足扩展：</p><p><strong>单元化扩展</strong>：按业务单元而非整体系统进行扩展，如用户服务独立于订单服务扩展<br/><strong>弹性伸缩</strong>：基于预测和实时指标动态调整实例数量，平衡性能与成本<br/><strong>分级扩展</strong>：核心服务与非核心服务差异化扩展策略，确保关键业务资源</p><h2>4 故障转移：从被动应对到主动容错</h2><h3>4.1 故障检测：快速发现的艺术</h3><p>有效的故障转移始于<strong>精准的故障检测</strong>，需要在及时性与准确性间找到平衡：</p><p><strong>多层次健康检查策略</strong>：</p><pre><code class="yaml"># Kubernetes就绪与存活探针配置
apiVersion: v1
kind: Pod
metadata:
  name: web-application
spec:
  containers:
  - name: web
    image: nginx:latest
    livenessProbe:
      httpGet:
        path: /health
        port: 8080
      initialDelaySeconds: 30
      periodSeconds: 10
      timeoutSeconds: 5
      failureThreshold: 3
    readinessProbe:
      httpGet:
        path: /ready  
        port: 8080
      initialDelaySeconds: 5
      periodSeconds: 5
      timeoutSeconds: 3
      failureThreshold: 1</code></pre><p><em>通过探针机制实现精准故障检测</em></p><p><strong>智能故障判定</strong>：结合多个指标（响应时间、错误率、资源使用率）综合判断，避免单指标误判。</p><h3>4.2 故障隔离：防止雪崩的屏障</h3><p>故障转移不仅是将流量从故障实例移走，更重要的是<strong>隔离故障影响</strong>：</p><p><strong>熔断器模式</strong>：在连续失败达到阈值时自动熔断，避免重试风暴</p><pre><code class="java">@Component
public class ProductService {
    @CircuitBreaker(name = "productService", 
                   fallbackMethod = "getProductFallback")
    public Product getProduct(Long productId) {
        return remoteProductService.getProduct(productId);
    }
    
    public Product getProductFallback(Long productId, Exception ex) {
        return cacheService.getBasicProduct(productId);
    }
}</code></pre><p><em>熔断器防止故障扩散</em></p><p><strong>隔离策略</strong>：</p><ul><li><strong>线程池隔离</strong>：不同服务使用独立线程池，避免资源竞争</li><li><strong>信号量隔离</strong>：控制并发调用数，防止资源耗尽</li><li><strong>超时控制</strong>：设置合理超时时间，避免长时间阻塞</li><li><strong>限流降级</strong>：流量超过阈值时自动降级，保护系统不被冲垮</li></ul><h3>4.3 流量切换：无缝转移的技术实现</h3><p>故障转移的核心是<strong>流量重路由</strong>，需要在不同层级实现协同：</p><p><strong>负载均衡器切换</strong>：健康检查失败时自动从路由表中移除故障节点</p><pre><code class="nginx">upstream backend {
    server 10.0.1.10:8080 max_fails=3 fail_timeout=30s;
    server 10.0.1.11:8080 max_fails=3 fail_timeout=30s;
    server 10.0.1.12:8080 backup;
    
    # 故障转移配置
    proxy_next_upstream error timeout http_500 http_502 http_503;
}</code></pre><p><em>负载均衡器实现自动故障转移</em></p><p><strong>服务网格流量管理</strong>：基于Istio等服务网格实现细粒度流量控制</p><pre><code class="yaml">apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: product-service
spec:
  host: product-service
  trafficPolicy:
    outlierDetection:
      consecutiveErrors: 5
      interval: 10s
      baseEjectionTime: 30s
      maxEjectionPercent: 50</code></pre><p><em>服务网格提供高级故障检测与转移能力</em></p><h2>5 三大支柱的协同设计</h2><h3>5.1 协同工作的架构模式</h3><p>无状态化、水平扩展与故障转移不是孤立技术，而是相互依赖的有机整体：</p><p><strong>无状态化赋能水平扩展</strong>：只有无状态设计，才能实现真正的无缝水平扩展<br/><strong>水平扩展增强故障转移</strong>：多实例为故障转移提供目标节点，使转移成为可能<br/><strong>故障转移保障水平扩展</strong>：在扩展过程中，故障转移确保个别实例故障不影响整体</p><p><strong>协同架构示例</strong>：</p><pre><code>用户请求 → 负载均衡器（故障检测/转移）
                   ↓
           无状态应用集群（水平扩展）
                   ↓  
          集中式状态存储（Redis集群）
                   ↓
          数据存储层（分片/主从）</code></pre><h3>5.2 协同设计的反模式与陷阱</h3><p><strong>伪无状态陷阱</strong>：表面无状态但实际存在隐性状态依赖（如本地缓存、文件存储）<br/><strong>不平衡扩展</strong>：计算层扩展但数据层成为瓶颈，或相反<br/><strong>过度转移</strong>：过于敏感的故障检测导致频繁转移，反而影响稳定性<br/><strong>单点转移</strong>：故障转移机制本身存在单点故障</p><h3>5.3 协同效能的度量体系</h3><p>三大支柱的协同效果需要可度量的指标验证：</p><p><strong>无状态化程度指标</strong>：</p><ul><li>实例启动时间（应小于30秒）</li><li>请求路由一致性（任意实例处理结果相同）</li><li>状态外部化比例（超过90%状态外部化）</li></ul><p><strong>水平扩展效能指标</strong>：</p><ul><li>线性扩展比（实例增加与性能提升比例）</li><li>扩展速度（从触发到完成扩展的时间）</li><li>资源利用率（避免过度或不足扩展）</li></ul><p><strong>故障转移质量指标</strong>：</p><ul><li>故障检测时间（秒级检测）</li><li>转移恢复时间（分钟级恢复）</li><li>转移成功率（超过99%的转移成功）</li></ul><h2>6 实战案例：电商平台高可用架构演进</h2><h3>6.1 单体架构的高可用改造</h3><p><strong>初始状态</strong>：单体应用，会话绑定，数据库单点</p><p><strong>改造步骤</strong>：</p><ol><li><strong>无状态化改造</strong>：用户会话外置到Redis集群</li><li><strong>水平扩展准备</strong>：应用容器化，配置负载均衡</li><li><strong>故障转移基础</strong>：数据库主从分离，读写分离</li><li><strong>渐进式迁移</strong>：先读流量，后写流量；先非核心功能，后核心功能</li></ol><p><strong>改造效果</strong>：可用性从99.9%提升至99.95%，扩展时间从小时级降至分钟级</p><h3>6.2 微服务架构的高可用深化</h3><p><strong>架构特点</strong>：服务拆分，分布式依赖，复杂调用链</p><p><strong>深化措施</strong>：</p><ul><li><strong>精细化无状态</strong>：API网关无状态化，业务服务按需无状态</li><li><strong>弹性扩展策略</strong>：基于业务优先级差异化扩展策略</li><li><strong>智能故障转移</strong>：基于调用链分析的精准故障定位和隔离</li></ul><p><strong>深化效果</strong>：可用性提升至99.99%，故障恢复时间从30分钟降至5分钟以内</p><h2>总结</h2><p>高可用架构的本质是通过<strong>无状态化、水平扩展、故障转移</strong>三大支柱的协同设计，构建能够<strong>容忍故障、快速恢复</strong>的弹性系统。</p><p><strong>核心洞察</strong>：</p><ol><li><strong>无状态化是基础</strong>：只有解耦状态与计算，才能实现真正的弹性</li><li><strong>水平扩展是手段</strong>：通过分布式架构将集中式风险分解为可管理单元</li><li><strong>故障转移是保障</strong>：在故障发生时快速隔离和恢复，最小化业务影响</li><li><strong>协同设计是关键</strong>：三大支柱必须统一设计，相互配合，而非孤立优化</li></ol><p><strong>成功的高可用架构</strong>不是追求零故障，而是确保在故障发生时：</p><ul><li>系统能够<strong>快速检测</strong>并<strong>定位</strong>问题</li><li>故障影响被<strong>有效隔离</strong>，防止扩散</li><li>业务流量被<strong>无缝转移</strong>到健康实例</li><li>系统能够<strong>自动恢复</strong>，减少人工干预</li></ul><p>在云原生时代，随着Kubernetes、服务网格等技术的成熟，高可用能力已经日益平台化、标准化。然而，技术选型只是起点，真正的挑战在于根据业务特点合理运用这些能力，构建既可靠又经济的高可用体系。</p><hr/><p><strong>📚 下篇预告</strong><br/>《CDN与边缘缓存策略——静态、动态与签名鉴权的组合拳》—— 我们将深入探讨：</p><ul><li>🌐 <strong>缓存层次体系</strong>：浏览器缓存、边缘缓存、中心缓存的协同分工</li><li>⚡ <strong>动态内容加速</strong>：边缘计算、智能路由与协议优化技术</li><li>🔐 <strong>安全缓存挑战</strong>：签名URL、权限验证与敏感内容保护</li><li>📊 <strong>缓存效能优化</strong>：命中率提升、失效策略与成本平衡</li><li>🚀 <strong>边缘架构演进</strong>：从内容分发到边缘计算的范式转变</li></ul><p><strong>点击关注，构建高效安全的全球内容分发体系！</strong></p><blockquote><p><strong>今日行动建议</strong>：</p><ol><li>评估现有应用的无状态化程度，制定状态外部化改造路线</li><li>设计水平扩展的容量规划与自动伸缩策略</li><li>建立多层级的故障检测与转移机制，定期进行故障演练</li><li>制定三大支柱协同效能的度量体系，持续优化高可用能力</li></ol></blockquote>]]></description></item>  </channel></rss>