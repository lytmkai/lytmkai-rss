<?xml version="1.0" encoding="UTF-8"?><rss version="2.0">  <channel>      <title>SegmentFault - 最近文章</title>      <link>https://segmentfault.com/blogs/newest</link>      <description>SegmentFault 思否</description>      <generator>python segmentfault.py @Pi20</generator>      <item>    <title><![CDATA[【URP】Unity[RendererF]]></title>    <link>https://segmentfault.com/a/1190000047402504</link>    <guid>https://segmentfault.com/a/1190000047402504</guid>    <pubDate>2025-11-16 11:01:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <blockquote><a href="https://link.segmentfault.com/?enc=AhWi7LKTZq84VIp9tBX8hw%3D%3D.iSkMlmTeMMVn3k7HwZ2Vn9yQuIuY%2FaoRISMGemRRE9ZGh87e8K17VRujHdZA2wpkgGrJmevxJkNPoIZIFzb4d7gupyXjp0yQMn%2F39Teg9gQvHCbGCmXAjVVO%2FFA%2Ff5Mzx2HmbzjX2bpBNI36eLLDrRr9qJf%2BWQW3aZu%2BuJVMAFoVzP%2FbsOwJYFJ%2BgbygJvyRzhi3RYCR%2Bnv2WRjoChDv51FoZg2nOrf7ru0bo4BZvPc%3D" rel="nofollow" target="_blank">【从UnityURP开始探索游戏渲染】</a><strong>专栏-直达</strong></blockquote><p>FullScreenPassRendererFeature是Unity URP渲染管线中用于实现全屏后处理效果的核心组件，它允许开发者在渲染流程的特定阶段插入自定义的全屏着色器效果。</p><h2><strong>功能与作用</strong></h2><ul><li>‌<strong>核心功能</strong>‌：通过ScriptableRenderPass在URP管线中注入全屏四边形绘制命令，应用自定义Shader实现屏幕空间特效（如模糊、色调调整等）</li><li><p>‌<strong>典型应用场景</strong>‌：</p><ul><li>屏幕后处理（如Bloom、景深模拟）</li><li>全局滤镜效果（黑白化、夜视模式）</li><li>特殊视觉特效（扫描线、像素化）</li></ul></li></ul><h2><strong>发展历史</strong></h2><ul><li>‌<strong>URP初期</strong>‌：需手动编写完整的ScriptableRendererFeature和ScriptableRenderPass类实现全屏效果</li><li>‌URP 7.0+ ：引入预置的FullScreenPassRendererFeature简化开发流程</li><li>‌<strong>URP 17.0</strong>‌：重构API至RenderGraph系统，优化资源管理机制</li></ul><h2>原理</h2><p>FullScreenPassRendererFeature是Unity URP中用于实现全屏后处理效果的核心组件，其底层原理基于URP的可编程渲染管线架构。</p><h3><strong>核心原理</strong></h3><ul><li>‌<strong>继承关系</strong>‌：继承自<code>ScriptableRendererFeature</code>基类，通过<code>Create()</code>方法初始化自定义的<code>ScriptableRenderPass</code>子类实例</li><li>‌<strong>执行流程</strong>‌：在URP渲染管线的特定阶段（如不透明物体渲染后）插入全屏绘制命令，通过<code>CommandBuffer</code>调用<code>Blit</code>或<code>DrawProcedural</code>实现</li><li>‌<strong>资源管理</strong>‌：使用<code>RTHandle</code>系统动态管理渲染目标，自动处理不同分辨率下的资源分配与释放</li></ul><h3><strong>关键代码示例</strong></h3><p>以下实现一个基础的全屏泛光效果：</p><ul><li><p>BloomFeature.cs</p><pre><code class="csharp">using UnityEngine;
using UnityEngine.Rendering;
using UnityEngine.Rendering.Universal;

[System.Serializable]
public class BloomSettings {
    public float intensity = 1.0f;
    public Color tint = Color.white;
}

public class BloomFeature : ScriptableRendererFeature {
    public BloomSettings settings = new BloomSettings();
    private BloomPass m_Pass;

    public override void Create() {
        m_Pass = new BloomPass(settings);
        m_Pass.renderPassEvent = RenderPassEvent.AfterRenderingPostProcessing;
    }

    public override void AddRenderPasses(
        ScriptableRenderer renderer, 
        ref RenderingData renderingData) {
        renderer.EnqueuePass(m_Pass);
    }
}

class BloomPass : ScriptableRenderPass {
    private Material m_Material;
    private BloomSettings m_Settings;
    private RTHandle m_TempTexture;

    public BloomPass(BloomSettings settings) {
        m_Settings = settings;
        m_Material = CoreUtils.CreateEngineMaterial("Hidden/Blur");
    }

    public override void Configure(CommandBuffer cmd, 
        RenderTextureDescriptor cameraTextureDescriptor) {
        m_TempTexture = RTHandles.Alloc(
            Vector2.one * 0.5f, 
            colorFormat: cameraTextureDescriptor.colorFormat);
    }

    public override void Execute(ScriptableRenderContext context, 
        ref RenderingData renderingData) {
        var cmd = CommandBufferPool.Get("BloomPass");
        Blit(cmd, 
            renderingData.cameraData.renderer.cameraColorTargetHandle,
            m_TempTexture, 
            m_Material, 0);
        Blit(cmd, 
            m_TempTexture,
            renderingData.cameraData.renderer.cameraColorTargetHandle);
        context.ExecuteCommandBuffer(cmd);
        CommandBufferPool.Release(cmd);
    }

    public override void FrameCleanup(CommandBuffer cmd) {
        m_TempTexture.Release();
    }
}</code></pre></li></ul><h3><strong>技术细节</strong></h3><ul><li>‌<strong>材质控制</strong>‌：通过Shader的<code>LightMode</code>标签匹配（如<code>UniversalForward</code>）确定渲染路径</li><li>‌<strong>时序控制</strong>‌：<code>RenderPassEvent</code>枚举精确控制执行时机（如<code>AfterRenderingOpaques</code>）</li><li>‌<strong>多Pass协作</strong>‌：支持通过多个<code>ScriptableRenderPass</code>实现效果叠加，如先提取亮部再模糊</li></ul><h3><strong>性能优化</strong></h3><ul><li>‌<strong>临时纹理复用</strong>‌：通过<code>RTHandle</code>的缩放参数实现动态分辨率渲染</li><li>‌<strong>命令缓冲池</strong>‌：使用<code>CommandBufferPool</code>减少GC开销</li><li>‌<strong>材质实例化</strong>‌：避免每帧创建新材质</li></ul><p>该机制相比传统<code>OnRenderImage</code>方案，在URP中能更好地集成到SRP批处理系统中，且支持XR多通道渲染等高级特性</p><h2><strong>实现流程示例</strong></h2><p>以下为完整实现黑白滤镜效果的URP示例：</p><ul><li><p>GrayFeature.cs</p><pre><code class="csharp">using UnityEngine;
using UnityEngine.Rendering;
using UnityEngine.Rendering.Universal;

public class GrayRenderFeature : ScriptableRendererFeature {
    public RenderPassEvent renderEvent = RenderPassEvent.AfterRendering;
    public Shader shader;
    private Material grayMaterial;
    private GrayPass grayPass;

    public override void Create() {
        grayMaterial = CoreUtils.CreateEngineMaterial(shader);
        grayPass = new GrayPass(grayMaterial, renderEvent);
    }

    public override void AddRenderPasses(ScriptableRenderer renderer, ref RenderingData renderingData) {
        grayPass.SetTarget(renderer.cameraColorTargetHandle);
        renderer.EnqueuePass(grayPass);
    }
}

public class GrayPass : ScriptableRenderPass {
    private Material material;
    private RTHandle source;

    public GrayPass(Material material, RenderPassEvent passEvent) {
        this.material = material;
        this.renderPassEvent = passEvent;
    }

    public void SetTarget(RTHandle colorHandle) {
        source = colorHandle;
    }

    public override void Execute(ScriptableRenderContext context, ref RenderingData renderingData) {
        CommandBuffer cmd = CommandBufferPool.Get("GrayEffect");
        Blitter.BlitCameraTexture(cmd, source, source, material, 0);
        context.ExecuteCommandBuffer(cmd);
        CommandBufferPool.Release(cmd);
    }
}</code></pre></li><li><p>GrayEffect.shader</p><pre><code class="c">Shader "Custom/GrayEffect" {
    Properties {
        _MainTex ("Base (RGB)", 2D) = "white" {}
    }
    SubShader {
        Pass {
            CGPROGRAM
            #pragma vertex vert
            #pragma fragment frag
            #include "UnityCG.cginc"

            struct appdata {
                float4 vertex : POSITION;
                float2 uv : TEXCOORD0;
            };

            struct v2f {
                float2 uv : TEXCOORD0;
                float4 vertex : SV_POSITION;
            };

            sampler2D _MainTex;

            v2f vert (appdata v) {
                v2f o;
                o.vertex = UnityObjectToClipPos(v.vertex);
                o.uv = v.uv;
                return o;
            }

            fixed4 frag (v2f i) : SV_Target {
                fixed4 col = tex2D(_MainTex, i.uv);
                float gray = dot(col.rgb, float3(0.299, 0.587, 0.114));
                return fixed4(gray, gray, gray, col.a);
            }
            ENDCG
        }
    }
}</code></pre></li></ul><h2><strong>参数说明与用例</strong></h2><table><thead><tr><th>参数</th><th>类型</th><th>说明</th><th>典型值</th></tr></thead><tbody><tr><td>renderEvent</td><td>RenderPassEvent</td><td>执行时机</td><td>AfterRenderingOpaques</td></tr><tr><td>shader</td><td>Shader</td><td>效果着色器</td><td>自定义全屏Shader</td></tr><tr><td>intensity</td><td>float</td><td>效果强度</td><td>0.0-1.0</td></tr></tbody></table><p>‌<strong>实际配置步骤</strong>‌：</p><ul><li>创建URP Renderer Asset（若不存在）</li><li>通过Inspector添加FullScreenPassRendererFeature</li><li>指定Material并使用ShaderGraph创建效果</li><li>调整RenderPassEvent控制执行顺序</li></ul><h2><strong>性能优化建议</strong></h2><ul><li>使用RTHandle管理渲染目标避免内存浪费</li><li>复杂效果建议结合Volume系统实现参数动态调整</li><li>移动端需注意带宽占用，推荐使用Half Resolution处理</li></ul><hr/><blockquote><a href="https://link.segmentfault.com/?enc=tpvOW6RgEfm2cQ8nWSENnQ%3D%3D.YQ2xyqHArT4BBYc7VKiD4N2%2BX981moMm3LCQrN7eNfmV9V4Ko6muslUKEAjkqNatqcwpp5z6Ge8CHLhL9WwpUEijyQrzPNCLlEWqLrExrY7PKv62xNFfqpmiCdb0AVX%2F69tFYF7hIECitOSvZziD0sOCkKPUHWBSBA7l8UHVtLN011ZzUAv%2BL%2BPfSX5GwDZ2HLBxlvdRGyyTDmpvkAetzp8eQ0DTH0dtsp91njpzYmE%3D" rel="nofollow" target="_blank">【从UnityURP开始探索游戏渲染】</a><strong>专栏-直达</strong><br/>（欢迎<em>点赞留言</em>探讨，更多人加入进来能更加完善这个探索的过程，🙏）</blockquote>]]></description></item><item>    <title><![CDATA[飞牛 OS 使用 Docker 部署 J]]></title>    <link>https://segmentfault.com/a/1190000047402473</link>    <guid>https://segmentfault.com/a/1190000047402473</guid>    <pubDate>2025-11-16 10:04:08</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>Docker Compose</h2><pre><code>version: '3.8'
services:
  demoService:
    restart: always
    build: . 
    image: demoService:1.0.0            #自定义镜像名和版本号
    container_name: demoService
    volumes:
      - /vol2/1000/docker-data/demoService/logs:/logs
    ports:
      - 9999:9999
    environment:
      - profile=local
      - TZ=Asia/Shanghai</code></pre><h2>Dockerfile</h2><pre><code>FROM java:8u111-jdk-alpine
VOLUME /tmp
COPY demoService-0.0.1-SNAPSHOT.jar demoService-0.0.1-SNAPSHOT.jar
ENTRYPOINT ["java","-jar" ,"-Xms2048m","-Xmx2048m","-Xss512k","-Dspring.profiles.active=${profile}","demoService-0.0.1-SNAPSHOT.jar"]</code></pre>]]></description></item><item>    <title><![CDATA[如何在 Shell 脚本中使用多行注释 ]]></title>    <link>https://segmentfault.com/a/1190000047402476</link>    <guid>https://segmentfault.com/a/1190000047402476</guid>    <pubDate>2025-11-16 10:03:35</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000045412131" alt="How to Create Multiline Comments in Shell Scripts" title="How to Create Multiline Comments in Shell Scripts"/></p><p>在编写 shell 脚本时，添加注释来解释代码的目的和功能是很重要的。shell 脚本中的注释是用散列号“#”表示。但是，有时您可能希望编写跨几行的多行注释。</p><p>在本文中，我们将讨论如何在 shell 脚本中创建多行注释。</p><h3>Using multiple single-line comments</h3><p>在 shell 脚本中创建多行注释的一种方法是使用多个单行注释。</p><pre><code>#!/bin/bash

# This is a multiline comment
# that spans several lines
# and explains the purpose of the script
echo "Hello, world!"</code></pre><h3>Using Here Documents</h3><p>在 shell 脚本中创建多行注释的另一种方法是使用 <strong>Here Documents</strong>，示例如下：</p><pre><code>#!/bin/bash

: &lt;&lt;'COMMENT'
This is a multiline comment
that spans several lines
and explains the purpose of the script
COMMENT

echo "Hello, world!"</code></pre><p>在本例中，我们使用 Here Document 创建一个跨三行的多行注释。Here Document 的语法是 <strong>:&lt;&lt;'STRING'</strong>，其中 STRING 是标记 Here Document 结束的分隔符。在本例中，我们使用 COMMENT 作为分隔符。</p><h3>Using the <code>:</code> command</h3><p>最后，您可以使用 <code>:</code> 命令在 shell 脚本中创建多行注释。<code>: </code> 命令是一个空命令，什么也不做，但它可以用来创建多行注释。这里有一个例子：</p><pre><code>#!/bin/bash

: '
This is a multiline comment
that spans several lines
and explains the purpose of the script
'

echo "Hello, world!"</code></pre><p>在这个例子中，我们使用 <code>:</code> 命令创建一个跨三行的多行注释，注释文本用单引号括起来。</p><h3>我的开源项目</h3><p><a href="https://link.segmentfault.com/?enc=AK89nab7MVyyeb00oXeCzg%3D%3D.oVwJVW8uuXVlntqBJztPEW6XiNnLGd3kzxs8QnuGNp8%3D" rel="nofollow" target="_blank"><img referrerpolicy="no-referrer" src="/img/remote/1460000043302459" alt="酷瓜云课堂-在线教育解决方案" title="酷瓜云课堂-在线教育解决方案" loading="lazy"/></a></p><ul><li><a href="https://link.segmentfault.com/?enc=7ZKjLpc5mADTjyQVAXIIcA%3D%3D.xlVeP8hb9F2pwYZsuwsu72SZcyI9R6ZFZ5t1vO0OJ0RbYRM%2BbANznJquW%2B4iu7vt" rel="nofollow" target="_blank">course-tencent-cloud（酷瓜云课堂 - gitee仓库）</a></li><li><a href="https://link.segmentfault.com/?enc=YuonuMX%2BEZg476dk591M%2Bg%3D%3D.uqAcwviRO%2B30YZGOUFbGTD62TFgKQlCD20F98eiadoxbbMMzdsjylKtvqRq84FzMcxcyg5IyR2e6GjopS8GhYQ%3D%3D" rel="nofollow" target="_blank">course-tencent-cloud（酷瓜云课堂 - github仓库）</a></li></ul>]]></description></item><item>    <title><![CDATA[mysql-5.7.30-linux-g]]></title>    <link>https://segmentfault.com/a/1190000047402480</link>    <guid>https://segmentfault.com/a/1190000047402480</guid>    <pubDate>2025-11-16 10:03:01</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>​第一步：准备工作（找块好地方）</p><ol><li><strong>上传安装包</strong>：<strong>安装包下载：</strong><a href="https://link.segmentfault.com/?enc=GCv%2FqmSXsQ1CJ0GRUA6Juw%3D%3D.QtaM%2BuEERUFx4uycZX11%2Bw%2F8qzyfhvEmWIsy%2BsPeKVceup1%2FV4cEfpANAu1edihg" rel="nofollow" title="https://pan.quark.cn/s/57dcaa6183b0" target="_blank">https://pan.quark.cn/s/57dcaa6183b0</a>，首先，你得把这个 <code>mysql-5.7.30-linux-glibc2.12-x86_64.tar.gz</code>文件传到你的Linux服务器上。比如，你可以用FTP工具或者<code>scp</code>命令把它扔到 <code>/usr/local/src</code>目录下。这个目录通常就是放这些源码包的地方。</li><li><p><strong>检查老版本</strong>：为了防止打架，先看看系统里有没有自带的旧版MySQL。有的话就请它离开。</p><pre><code>rpm -qa | grep mysql</code></pre></li></ol><pre><code>如果上面命令列出了什么包，比如 `mysql-libs`，就用下面的命令卸载掉（以实际查到的名字为准）：

```
rpm -e --nodeps 查到的包名
```


</code></pre><h3>第二步：解压和安排“住处”</h3><ol><li><p><strong>进入目录并解压</strong>：</p><pre><code>cd /usr/local/src
tar -xzf mysql-5.7.30-linux-glibc2.12-x86_64.tar.gz</code></pre></li></ol><ol><li><p><strong>挪到最终位置并改个短名</strong>：解压后会得到一个长长的文件夹名，我们把它挪到 <code>/usr/local</code>下，并改名叫 <code>mysql</code>，这样方便以后操作。</p><pre><code>mv mysql-5.7.30-linux-glibc2.12-x86_64 /usr/local/mysql</code></pre></li></ol><h3>第三步：创建专属用户和目录</h3><ol><li><p><strong>创建mysql用户组和用户</strong>：让MySQL用一个专门的用户来运行，这样更安全。</p><pre><code>groupadd mysql
useradd -r -g mysql -s /bin/false mysql # 创建一个不能登录系统的mysql用户</code></pre></li></ol><ol><li><p><strong>创建数据存放目录</strong>：MySQL的所有数据（比如你建的数据库、表）都会放在这里。通常我们放在 <code>/data/mysql</code>。</p><pre><code>mkdir -p /data/mysql</code></pre></li></ol><ol><li><p><strong>把目录的“所有权”给mysql用户</strong>：</p><pre><code>chown -R mysql:mysql /data/mysql
chown -R mysql:mysql /usr/local/mysql</code></pre></li></ol><h3>第四步：初始化数据库</h3><p>这是最关键的一步，相当于给新MySQL房子置办家具。</p><p>进入MySQL的家，执行初始化命令：</p><pre><code>cd /usr/local/mysql
./bin/mysqld --initialize --user=mysql --datadir=/data/mysql</code></pre><p><strong>注意看屏幕输出！</strong> 命令执行完后，会有一行类似这样的信息：</p><pre><code>[Note] A temporary password is generated for root@localhost: 这里是一串随机密码</code></pre><p><strong>一定拿个小本本把这个临时密码记下来！</strong> 第一次登录全靠它。</p><h3>第五步：配置和启动</h3><ol><li><p><strong>复制配置文件</strong>：MySQL需要一个叫 <code>my.cnf</code>的配置文件。安装包里有现成的模板，我们复制一份。</p><pre><code>cp /usr/local/mysql/support-files/my-default.cnf /etc/my.cnf</code></pre></li></ol><pre><code>如果 `/etc`下已经有一个 `my.cnf`文件，它会问你是否覆盖，你根据情况选择。如果没有现成的，直接复制过去就行。
</code></pre><ol><li><p><strong>复制启动脚本</strong>：让系统知道怎么启动和停止MySQL服务。</p><pre><code>cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysqld</code></pre></li></ol><ol><li><p><strong>启动MySQL服务</strong>：</p><pre><code>service mysqld start</code></pre></li></ol><pre><code>如果看到 `Starting MySQL. SUCCESS!`就说明启动成功了。
</code></pre><h3>第六步：首次登录和修改密码</h3><ol><li><p><strong>用临时密码登录</strong>：现在可以用刚才记下的那个又长又丑的临时密码登录了。</p><pre><code>/usr/local/mysql/bin/mysql -u root -p</code></pre></li></ol><pre><code>输入密码时，屏幕不会显示星号，你正常输入后按回车就行。
</code></pre><ol><li><p><strong>赶紧修改root密码</strong>：一登录成功，马上做这件事，不然什么操作都不让你做。</p><pre><code>SET PASSWORD = PASSWORD('你的新密码');</code></pre></li></ol><pre><code>比如你想把密码改成 `123456`，就写 `SET PASSWORD = PASSWORD('123456');`。当然，实际使用时要用个复杂点的密码。
</code></pre><ol><li><p><strong>让外部机器也能连接（可选）</strong> ：如果你只是本机用，这步可以跳过。如果想让别的电脑也能连这个数据库，需要授权。</p><pre><code>GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY '你的新密码' WITH GRANT OPTION;
FLUSH PRIVILEGES;</code></pre></li></ol><ol><li><p><strong>退出</strong>：</p><pre><code>exit</code></pre></li></ol><p>​</p>]]></description></item><item>    <title><![CDATA[CentOS 7 安装 unzip-6.]]></title>    <link>https://segmentfault.com/a/1190000047402483</link>    <guid>https://segmentfault.com/a/1190000047402483</guid>    <pubDate>2025-11-16 10:02:07</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>​</p><p>本文手把手教你如何在 CentOS 7 系统上安装 <code>unzip-6.0-21.el7.x86_64.rpm</code>这个软件包。内容涵盖了直接用 yum 的省心方法和使用 rpm 命令的步骤，帮你快速搞定 unzip 解压工具的安装。</p><p><strong>安装包下载：</strong><a href="https://link.segmentfault.com/?enc=pJBTPt2vxdj3Oo2oFLdjhw%3D%3D.hEFbhgitS84LEEEO9kv9VGpTyFL7kl9DsuEVibCzuEUvL%2BG5Ub4UzrViRpgpbKHR" rel="nofollow" title="https://pan.quark.cn/s/1077b5d6b2aa" target="_blank">https://pan.quark.cn/s/1077b5d6b2aa</a></p><p><strong>情况一：如果你可以直接使用 yum 安装</strong></p><p>直接在终端里输入下面这行命令，yum 会自动处理依赖关系，最省心：</p><pre><code>sudo yum install unzip-6.0-21.el7.x86_64.rpm</code></pre><p><strong>情况二：如果你只有这个 rpm 文件，需要用 rpm 命令安装</strong></p><p>有时候用 rpm 安装可能会缺少依赖包，如果报错说缺少什么，你得先去找那个包。安装命令是：</p><pre><code>sudo rpm -ivh unzip-6.0-21.el7.x86_64.rpm</code></pre><p>这里的 <code>-ivh</code>参数意思是：安装、显示详细信息和进度。</p><p>​</p>]]></description></item><item>    <title><![CDATA[聚焦模拟架构精髓 星星上的柳树 ]]></title>    <link>https://segmentfault.com/a/1190000047402491</link>    <guid>https://segmentfault.com/a/1190000047402491</guid>    <pubDate>2025-11-16 10:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在高性能 IC 设计中，放大器电路的优化至关重要。本文围绕三类主流架构：全差分放大器（FDA）、Class-AB 音频放大器与Cascode 放大器，深入剖析设计思路、性能优势，以及如何在实际项目中落地实施。</p><p>1、全差分放大器（FDA）——精准噪声抑制利器<br/><img width="630" height="601" referrerpolicy="no-referrer" src="/img/bVdm3Ir" alt="" title=""/><br/>I. 优势：<br/>拒绝共模噪声、提升动态范围与精准度，是高精度高速 ADC 前端的理想选择。</p><p>II. 设计要点：<br/>利用双反馈控制两路输出，同时设定共模输出电压（VOCM），确保输出稳定。<br/>常见拓扑包括折叠结构与 Telescopic，以兼顾增益、带宽与电源压摆幅。</p><p>III. 实操小贴士：<br/>精细调节开环增益与带宽，使闭环增益稳定达标。<br/>搭建 CMFB（共模反馈）电路，确保输出共模不漂移。</p><p>2、Class-AB 音频放大器——失真微调与效率兼顾<br/>I. 优势：<br/>结合 Class-A 与 Class-B 优点，高线性、低失真，效率可达 ~75% <br/>Basic Electronics Tutorials。</p><p>II. 设计方法：<br/>通过微偏置技术让输出晶体管轻微导通，显著降低交越失真。<br/>配置 Darlington 级提升输入阻抗，固化偏置与热稳定性。</p><p>III. 实践建议：<br/>控制静态偏置电流，平衡热安全与音质表现。<br/>添加保护电路（过流、短路保护），提升系统可靠性。</p><p>3、Cascode 放大器——带宽与增益兼得<br/><img width="630" height="601" referrerpolicy="no-referrer" src="/img/bVdm3Ir" alt="" title="" loading="lazy"/><br/>I. 优势：<br/>串联共栅结构有效抑制 Miller 电容带来的增益衰减，提升频响和增益。</p><p>II. 设计技巧：<br/>利用电流镜提供稳定偏置，确保线性区域操作。<br/>适当增加晶体管通道长度（L）以提升输出阻抗与电压增益。</p><p>III. 调优建议：<br/>通过 AC 分析确保带宽与相位裕度满足设计需求。<br/>多次迭代设计，软硬件仿真协同保障性能指标。</p><p>4、为什么 EDA Academy 是你的最佳助力？<br/>想深入掌握上述前沿技术？欢迎访问 EDA Academy（www.eda-academy.com） ——IC 行业领先的专业网课平台！<br/>无论你是想提升模拟架构实战能力，或是系统学习 Cadence Virtuoso 工具链操作，EDA Academy 都有海量、专业、全面、最新的网课可供选择。<br/>作为用户，还能注册成为平台导师，分享技术经验，参与在线授课。<br/>更棒的是：注册邮箱即可免费订阅 newsletter，随时获取技术干货与行业动态。<br/>若你希望将优质课程推荐给他人，还可以加入平台销售联盟计划，凭推荐赚取 20%–50% 佣金。</p>]]></description></item><item>    <title><![CDATA[《Unity游戏多平台上架零驳回：应用商]]></title>    <link>https://segmentfault.com/a/1190000047402289</link>    <guid>https://segmentfault.com/a/1190000047402289</guid>    <pubDate>2025-11-15 23:03:14</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>Unity作为跨平台游戏开发的标杆引擎，凭借其可视化编辑、组件化架构与丰富的生态资源，让无数开发者得以快速将创意落地为可运行的游戏产品，但当开发阶段落幕，真正的考验往往始于上架环节。许多开发者在完成游戏核心功能后，便想当然地认为只需按照各应用商店的官方流程提交即可，却忽视了不同平台在底层架构、生态逻辑与审核标准上的深层差异，这些差异并非简单的流程差异，而是源于平台对用户体验、合规要求与商业利益的不同侧重。有些团队花费数月打磨的游戏，可能因为Unity引擎默认开启的某一敏感权限未做合理说明，或未针对特定机型优化渲染管线，导致审核反复驳回，不仅延误上线时间，还可能因多次驳回影响账号权重；而另一些开发者之所以能实现多平台顺畅上架，核心在于他们没有停留在规则表面，而是深入拆解了各商店的审核逻辑，将Unity的技术特性与平台要求进行精准匹配，在性能优化、合规适配、细节把控等方面提前布局，这背后是无数次试错、复盘后沉淀的实战经验，也是跨平台上架成功的关键所在。</p><p>深入剖析主流应用商店的规则体系，会发现其审核标准的差异本质上是平台生态定位的延伸，只有读懂这些差异背后的逻辑，才能避免陷入被动。海外市场中，Google Play以开放性著称，其审核更注重开发者资质的真实性与内容合规性，对技术适配的包容度相对较高，但对权限滥用、广告违规、隐私泄露等问题的检测极为严格，尤其是针对Unity游戏中常见的第三方SDK集成，会重点核查是否存在私自收集用户信息的行为；而App Store的封闭性使其对应用的品质有着近乎苛刻的要求，除了常规的合规检查，还会对Unity游戏的启动速度、内存占用、后台行为、机型兼容性进行全方位测试，甚至会针对不同iOS版本、不同机型的GPU特性进行专项验证，许多开发者遇到的“性能不佳”驳回，往往是因为游戏在老旧机型上的帧率低于30帧，或后台运行时未及时释放内存。国内主流应用商店则更强调与本土政策的契合，除了必须接入实名认证与防沉迷系统外，对游戏内容的价值观导向、画面表现、文字表述有着明确要求，同时不同厂商的商店还存在个性化的技术适配需求，比如华为应用市场对HarmonyOS的分布式能力适配、小米应用商店对推送服务的接入规范、OPPO应用商店对安装包体积的优化建议等。更重要的是，各商店的规则并非一成不变，会随着政策调整、技术升级与用户反馈持续迭代，开发者不能依赖过时的经验，而应建立动态跟踪机制，通过关注官方开发者社区、分析同类产品的上架动态、加入行业交流群等方式，及时捕捉规则变化，比如某商店近期加强了对广告展示时长的限制，或某平台新增了对隐私政策的具体要求，都需要第一时间调整适配策略，提前规避风险。</p><p>Unity游戏的技术适配是上架过程中最容易出现问题的环节，其核心在于解决引擎特性与平台、设备之间的兼容性矛盾，这也是最能体现开发者技术功底的部分。Unity的跨平台能力虽然强大，但不同平台的底层架构、硬件环境存在显著差异，容易导致游戏在部分设备上出现闪退、卡顿、画面异常等问题。在Android平台，由于机型碎片化严重，不同厂商的GPU型号、系统版本差异极大，Unity默认的shader可能在某些机型上出现编译失败，导致画面花屏或黑屏，这就需要开发者在开发阶段就针对主流GPU型号（如Adreno、Mali）进行专项测试，优化shader代码的兼容性，避免使用过于冷门的渲染特性，同时通过Unity的图形设置面板调整渲染管线，确保在不同配置的设备上都能稳定运行。在iOS平台，内存管理是重中之重，iOS系统对应用的内存占用有着严格限制，尤其是后台切换后，系统会优先回收后台应用的内存，Unity游戏如果没有做好资源加载与释放的优化，容易出现内存溢出导致的闪退，这就需要开发者合理设计资源池，采用异步加载、分场景卸载等策略，将首屏加载资源控制在合理范围，同时避免在后台运行时执行耗内存的操作。此外，权限申请也是技术适配的重要内容，iOS 13以上版本要求敏感权限（如位置、相册、麦克风）的申请必须在用户触发相关功能时进行，且说明文字必须清晰告知权限用途，否则会被驳回；Android平台则需要根据系统版本差异处理动态权限申请，Unity开发者需要利用引擎提供的权限管理接口，结合各平台的要求进行精准适配，比如非必要的权限直接移除，必要权限则在申请时提供明确的使用场景说明，避免因权限申请不当影响审核。</p><p>合规性是Unity游戏上架的“生命线”，一旦触碰红线，几乎没有申诉成功的可能，而合规性的要求远不止表面的内容审核，而是贯穿隐私保护、支付合规、内容安全等多个维度的系统工程。隐私政策是合规性的基础，也是最容易出现问题的环节，许多开发者图方便直接使用网上的模板，导致隐私政策内容与游戏实际收集的用户信息不一致，或未明确告知用户信息的收集目的、使用方式、存储期限与删除路径，这在各应用商店的审核中都会被直接驳回。正确的做法是，逐一梳理游戏中涉及的用户信息收集行为，包括Unity引擎自带的统计功能、第三方SDK（如支付、广告、统计SDK）收集的信息，明确每一项信息的收集目的，比如设备ID用于数据分析、位置信息用于提供本地化服务等，然后按照各商店的隐私政策模板要求，详细、准确地撰写相关内容，同时确保隐私政策的链接能够正常访问，在游戏启动时以弹窗形式提示用户阅读并同意，弹窗设计需清晰易懂，避免使用晦涩的法律术语。支付合规同样不容忽视，不同平台对虚拟货币交易有着严格的规定，App Store要求所有虚拟商品交易必须通过IAP支付，禁止使用第三方支付渠道，且需要准确设置商品价格、描述与分类，避免出现价格欺诈；Google Play允许部分地区使用第三方支付，但需要提前向平台报备并符合相关要求；国内应用商店则要求接入对应的支付SDK，同时遵守虚拟货币管理的相关政策，禁止出现诱导消费、强制付费等行为。内容安全方面，需要严格排查游戏中的画面、文字、音效等元素，避免出现暴力、色情、敏感政治内容，同时要符合平台的价值观导向，比如国内商店对游戏中的角色形象、剧情设定有着明确的正向要求，避免出现违背公序良俗的内容，这些细节都需要在上线前逐一核查，确保万无一失。</p><p>上架流程中的细节把控，往往是决定审核成败的关键，许多开发者因为忽视了这些看似琐碎的环节，导致上架过程一波三折，甚至功亏一篑。包体构建是上架的第一步，也是最容易出现问题的环节之一，不同应用商店对包体的格式、签名、大小有着明确要求。App Store要求包体为IPA格式，必须使用正确的证书签名，签名过程中如果出现证书过期、配置文件错误、Bundle ID不匹配等问题，会直接导致包体无法上传；Google Play则要求包体为Android App Bundle格式，支持动态交付，同时对包体的大小有明确限制，超过150MB的包体需要采用扩展文件的方式处理，且扩展文件的命名与格式必须符合平台要求。Unity开发者在构建包体时，需要针对不同商店的要求进行专项配置，比如关闭不必要的权限、移除冗余的资源与代码、优化资源压缩方式，同时确保包体的签名信息与开发者账号信息一致，避免因签名错误导致审核驳回。渠道包管理也是一个重要环节，当游戏需要上架多个应用商店时，需要为每个商店构建独立的渠道包，在包体中嵌入对应的渠道标识，方便后续的数据分析与运营管理，同时要注意避免渠道包之间的代码冲突，确保各渠道包的功能一致性。此外，上架过程中的信息填写也需要格外谨慎，应用名称、描述、截图、视频等内容不仅要符合各商店的格式要求，还要准确传达游戏的核心特色，避免使用夸大宣传、侵权等违规表述，截图和视频需要真实反映游戏的实际画面，不能存在虚假宣传的情况，比如截图中展示的功能在实际游戏中不存在，或使用与游戏无关的素材，这些都会导致审核驳回。</p><p>面对审核驳回，合理的应对策略与申诉技巧能够极大缩短上架周期，而盲目修改与反复提交只会让情况变得更糟。当收到审核驳回通知时，首先要做的是冷静分析，仔细研读驳回理由，准确把握问题的核心，避免误解审核标准。许多驳回理由看似模糊，比如App Store提到的“性能不佳”，实际上可能是游戏在某一特定机型上的启动时间超过了3秒，或存在内存泄漏问题；而Google Play提到的“内容违规”，可能是游戏内的某一画面、文字或音效不符合当地的文化习俗。此时，开发者需要结合自身的开发经验与对平台规则的理解，针对性地进行排查，必要时可以通过测试工具模拟审核环境，复现问题所在，比如使用Xcode的Instruments工具检测iOS平台的内存占用与启动时间，或使用Android Studio的Profiler工具分析Android平台的性能问题。在修改问题时，不能只做表面文章，而要深入挖掘问题的根源，比如因权限申请不当被驳回，不能简单地删除权限申请，而要判断该权限是否为游戏必需，如果必需则需要优化申请时机与说明文字，如果非必需则直接移除，避免因权限冗余导致的合规风险；如果因性能问题被驳回，则需要从资源优化、代码重构、渲染调整等多个维度进行优化，而不是单纯降低画面质量。</p>]]></description></item><item>    <title><![CDATA[《Unity游戏多平台上架风险管控：预研]]></title>    <link>https://segmentfault.com/a/1190000047402292</link>    <guid>https://segmentfault.com/a/1190000047402292</guid>    <pubDate>2025-11-15 23:02:20</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>许多开发者在创意落地阶段便急于推进功能开发，未提前对接各应用商店的技术基线与审核导向，导致后期适配时发现核心玩法与平台规则冲突，或引擎特性与硬件环境不兼容—比如某团队因未预研iOS的Metal渲染规范，开发后期才发现游戏光影效果无法适配新款机型，被迫重构渲染模块，不仅延误了三个月上线周期，还额外投入了大量重构成本；另一些项目则因第三方SDK未做合规预审核，上架时被检测出数据违规收集，直接驳回且影响账号信用，后续该账号提交的新应用审核周期从常规7天延长至15天，严重影响产品迭代节奏。更有甚者，因预研时未关注某平台对游戏安装包体积的限制，导致包体超出阈值无法上传，只能紧急删减核心资源，反而影响了游戏核心体验。真正顺畅的多平台上架，始于开发初期的精准预研，通过提前拆解平台要求、预判潜在风险、搭建适配框架，将问题解决在萌芽阶段，这也是无数实战案例中总结的核心逻辑，而非单纯依赖后期的规则套用或临时整改。</p><p>平台技术预研是上架成功的前提，其核心在于穿透官方文档的表层信息，挖掘平台底层的技术基线与审核导向差异，形成可落地的适配方案。海外市场中，Google Play的开放生态决定了其审核更侧重“合规底线”，技术上允许一定程度的兼容性波动，但对数据隐私的管控极为严格，预研阶段需重点核查Unity项目中所有第三方SDK的数据收集范围，比如某广告SDK默认开启的设备IMEI收集功能，若未在隐私政策中明确说明，便会直接触发审核驳回；而App Store的闭环生态对“技术品质”要求极高，预研时不仅要确认游戏适配的iOS版本区间（需覆盖近三年主流版本），还需针对不同机型的硬件基线（如老旧机型的内存上限、新款机型的屏幕刷新率）制定适配标准，许多团队忽略了对iPhone SE等低配置机型的预研，导致上架后出现帧率过低的投诉，进而被要求强制优化后重新提交。国内主流应用商店的预研核心则是“政策适配”与“厂商特性”，除了提前对接最新的防沉迷系统接口、实名认证标准，还需关注各厂商的个性化要求—比如OPPO应用商店对后台保活的严格限制，禁止非必要应用长期占用后台资源；小米应用商店对推送权限的分级管理，需根据用户活跃度调整推送频率；荣耀应用商店对HarmonyOS分布式能力的适配建议，支持多设备协同的应用可获得更高推荐权重。更关键的是，预研需形成动态跟踪机制，通过订阅平台技术白皮书、参与厂商开发者沙龙、分析同类产品的上架变动，捕捉规则更新信号，比如某平台新增“未成年人付费限额”政策，或某商店强化对游戏安装包签名的校验标准，都需在预研阶段及时纳入适配框架，建立规则更新台账，明确调整节点与责任人，从源头规避方向性错误。</p><p>Unity引擎的跨平台优化，需以“预研结论”为核心搭建适配框架，而非依赖引擎默认设置，这是解决兼容性问题的关键，也是降低后期整改成本的核心手段。针对Android平台的机型碎片化，预研阶段需通过行业数据分析工具明确目标市场的GPU型号分布（如东南亚市场Mali GPU占比超70%），据此选择适配的渲染管线—比如针对中低端机型的Mali GPU，优先使用URP管线并关闭体积光、屏幕空间反射等复杂光影效果，同时优化Shader变体数量，通过Unity的Shader Variant Collection工具剔除无用变体，避免因编译冗余导致加载卡顿；对于Adreno GPU占比高的欧美市场，则可适当开启高分辨率纹理与后处理效果，平衡性能与视觉体验。此外，Android平台还需适配不同CPU架构（ARMv7、ARM64、x86），预研时需明确目标机型的架构分布，避免因未适配某架构导致部分设备无法安装。iOS平台的预研重点在于“性能阈值控制”，需提前通过Xcode的Instruments工具，测试不同机型的性能极限，确定内存占用上限（如iPhone 12以下机型内存控制在2GB内，iPhone 13及以上可放宽至3GB），开发阶段便采用“资源分级加载”策略：核心场景资源（如主角模型、核心玩法地图）优先加载，非关键资源（如远景装饰、次要NPC模型）延迟加载，后台切换时自动释放闲置资源（如缓存的纹理、未使用的动画片段），从根本上避免内存溢出。同时，需适配iOS的动态刷新率功能，在高刷屏机型上实现60帧稳定运行，在老旧机型上自动降为30帧，确保流畅度。此外，预研阶段还需明确各平台的权限基线，对于非核心功能所需的敏感权限（如位置、麦克风），直接在项目设置中关闭，避免后期因权限冗余触发审核预警；必要权限则提前设计合理的申请场景，比如拍照功能仅在用户触发“自定义头像”操作时才发起权限申请，且说明文字需通俗告知用途（如“允许访问相机以拍摄自定义头像”），杜绝模糊表述（如“需要访问相机以提升体验”）。</p><p>合规性风险的管控，核心在于“前置梳理”与“全流程校验”，而非上架前的临时补救，一旦出现合规问题，不仅会导致审核驳回，还可能影响品牌声誉。数据合规是预研阶段的重点，需逐一梳理Unity项目中的所有数据收集行为：引擎自带的设备信息统计（如设备型号、系统版本）、第三方支付SDK的订单数据、广告SDK的用户画像分析、统计SDK的行为数据，每一项都需明确“收集必要性”与“使用边界”—比如设备型号仅用于兼容性分析，不得用于用户精准画像；游戏进度数据仅本地存储或加密云端同步，不得泄露给第三方。同时，需遵守数据本地化要求，国内平台明确规定用户个人数据需存储在境内服务器，预研时需提前对接合规的云服务厂商，避免因服务器地址问题被驳回。基于梳理结果，提前撰写符合各平台要求的隐私政策，明确数据收集范围、存储期限、删除方式，且必须通过第三方合规工具检测（如工信部指定的隐私政策检测平台），确保无模糊表述或违规条款，政策链接需支持HTTPS协议，可正常访问。支付合规的预研则需对接各平台的支付规范，比如App Store的IAP支付需提前在开发者后台创建商品ID，确保游戏内商品定价、描述与后台一致，禁止出现“终身免费”“永久解锁”等易引发误解的表述；国内平台需提前完成支付SDK的接入测试，确保支付流程闭环（从充值到道具到账无卡顿），同时设置未成年人付费限额（如单次充值不超过50元，每月累计不超过200元），符合政策要求。内容合规方面，预研阶段需建立内容审核清单，明确禁止出现的元素（如暴力场景、敏感符号、宗教相关内容），同时结合目标市场的文化习俗调整内容—比如海外版本避免使用红色作为警示色（部分国家红色代表吉祥），国内版本确保角色形象积极向上、剧情设定传递正能量，开发过程中每一个版本都需同步进行内容校验，避免后期大面积修改，比如某游戏因角色服装设计过于暴露，上架前需重新绘制所有角色立绘，延误了上线时间。</p><p>上架全流程的标准化管控，是降低失误率的关键，需将预研结论转化为可执行的操作规范，覆盖包体构建、测试、信息填写、审核校验等各个环节。包体构建阶段，需根据预研确定的平台要求搭建标准化流程：Android平台需针对不同商店构建独立的渠道包，通过Unity的Build Settings工具嵌入专属渠道标识（如应用宝渠道标识为“yyb”，华为渠道标识为“hw”），同时按照Google Play的要求优化App Bundle格式，将纹理、音效等大体积资源拆分至扩展文件，控制主包体积在150MB内，避免因包体过大影响下载转化率；iOS平台则需严格按照证书配置规范，在Xcode中选择正确的开发证书与发布证书，确保Bundle ID、签名证书、配置文件完全匹配，避免因签名错误导致包体无法上传至App Store Connect，之前有团队因配置文件过期未及时更新，导致包体上传失败，延误了三天审核时间。测试环节需基于预研的机型矩阵，搭建覆盖高中低端设备的测试体系，除了测试核心玩法的兼容性，还需模拟审核场景—比如关闭网络测试离线功能是否正常、切换后台测试恢复稳定性、使用未成年人账号测试防沉迷功能是否生效、模拟弱网环境测试支付流程是否顺畅，每一项测试都需形成书面报告，记录测试机型、测试结果、问题截图，确保无遗漏问题。上架信息填写同样需遵循标准化规范，应用名称需简洁且符合平台命名规则（如iOS禁止使用特殊符号，Android禁止包含竞品名称），描述需准确提炼核心玩法，避免使用“最佳”“顶级”“第一”等夸大词汇；截图与宣传视频需采用实测画面，清晰展示游戏核心机制（如解谜游戏展示关键解谜环节，动作游戏展示战斗玩法），不得添加与实际功能不符的特效或素材，同时确保画面无违规元素，截图尺寸需符合平台要求（如App Store截图需适配不同屏幕尺寸，Android各商店尺寸要求略有差异）。此外，需建立包体与信息的双重审核机制，上架前由技术人员校验包体签名、渠道标识、权限设置，运营人员校验上架信息的准确性与合规性，合规人员再次核查隐私政策、支付流程、内容导向，确认所有环节符合预研要求后再提交，避免因单人操作失误导致驳回。</p><p>风险预判与驳回快速响应机制，是应对突发情况的保障，需基于预研数据搭建问题预案库，确保遇到驳回时能快速响应、高效整改。预研阶段需收集同类产品的常见驳回原因，分类整理为“技术问题”“合规问题”“流程问题”三大类，每一类下再细分具体场景—比如技术类的“闪退驳回”“帧率过低驳回”“兼容性问题驳回”，合规类的“隐私政策不合规驳回”“支付渠道违规驳回”“内容导向问题驳回”，流程类的“包体格式错误驳回”“上架信息填写违规驳回”，针对每一种场景制定详细的应对方案，明确排查步骤、整改方法、测试标准，比如“隐私政策不合规驳回”预案明确：第一步排查是否存在数据收集范围未说明，第二步补充缺失的条款，第三步通过第三方工具检测，第四步进行真机测试确保政策链接可访问。当收到审核驳回通知时，首先对照预案库快速定位问题类型，避免盲目排查；若属于未预判的新问题，则启动紧急响应流程，24小时内组织技术、运营、合规人员召开专项会议，共同分析驳回理由，结合预研阶段的平台规则认知，制定整改方案，明确责任人与整改时限。整改过程中需遵循“最小改动”原则，避免因修改引发新的问题，比如因某一功能违规被驳回，仅关闭该功能或优化该功能的表现形式，而非重构整个模块；整改完成后需进行专项测试，比如修改隐私政策后，测试政策链接是否正常、弹窗提示是否清晰，确保问题彻底解决。</p>]]></description></item><item>    <title><![CDATA[openEuler 24.03 LTS ]]></title>    <link>https://segmentfault.com/a/1190000047402313</link>    <guid>https://segmentfault.com/a/1190000047402313</guid>    <pubDate>2025-11-15 23:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>11月15日，openEuler Summit 2025在北京顺利召开。会上，开源欧拉社区首次发布支持超节点的操作系统版本 openEuler 24.03 LTS SP3，发布 Intelligence BooM全栈开源AI解决方案全新版本“2511 敲鱼面”，联合多家企业和单位共同发布全球首个 Arm CCA机密计算解决方案。华为积极响应，华为ICT战略与业务发展部总裁彭红华更在致辞中倡议社区共筑面向智能时代的超节点操作系统，共建AI与操作系统的融合能力，并宣布华为将贡献超节点操作系统插件及 GMEM、ModelFS 等关键 AI 技术，以提升 openEuler 在 AI 时代的竞争力。</p><p><img width="723" height="458" referrerpolicy="no-referrer" src="/img/bVdm3Fv" alt="" title=""/></p><p>此外，社区邀请到 AMD、Arm、Linaro 等多位全球企业和开源组织的代表分享与openEuler 的合作，加速全球化。AMD、浪潮云和神州数码成为社区捐赠单位，openEuler 学术与教育委员会、异构融合系统软件产学研联盟正式成立，共同推动人才培养和基础软件创新。</p><h3>核心技术突破，引领智能时代操作系统</h3><p>AI 创新业务的全面迸发，正推动核心诉求从单机性能转向超节点异构协同，超节点决定算力上限，而操作系统则掌控效率天花板。开放原子开源欧拉技术委员会主席胡欣蔚表示，openEuler 全球首个超节点的操作系统（openEuler 24.03 LTS SP3）正式发布。该版本对 openEuler 异构融合系统升级，加速释放超节点异构算力。</p><p><img width="723" height="487" referrerpolicy="no-referrer" src="/img/bVdm3Fw" alt="" title="" loading="lazy"/></p><p>面向数据中心场景，开源欧拉社区提供 Intelligence BooM 全栈开源AI解决方案。方案由 openEuler 联合高校、企业及各大社区打造，旨在建立开源的AI生态、赋能行业转型和推动产业协同，让企业级AI触手可及。继 2025 年 7 月发布首个版本“2507 烩面”之后，这次发布全新版本“2511 敲鱼面”。该版本以“低成本、高效率、易落地”为核心，支持 50+ 模型微调，通过异构协同推理效率提升 10%～30%，具备面向 Agentic AI 智能体生态快速适配能力，打造真正原生智能的操作系统。</p><p>在 AI 高速发展的同时，安全挑战也不容忽视。会上，开源欧拉社区联合 Arm、Linaro、百度智能云、麒麟软件、麒麟信安、统信软件、上海交通大学、华中科技大学和全球计算联盟（GCC）等共同发布全球首个 Arm CCA 机密计算解决方案。该解决方案基于 Arm CCA标准实现完整机密虚拟机支持，使 openEuler 成为首个原生支持 CCA 机密虚机的开源操作系统。通过可信I/O通道，将性能损耗控制在5%以内，既保留 openEuler 丰富的软件生态，又无缝融合机密计算生态。</p><p>Linaro CTO Grant Likely 表示，Linaro 长期支持 Arm 生态的发展，2021 年加入openEuler 社区，在长期的合作中，把自己积累的开源经验贡献到 openEuler Arm 架构上，是 openEuler Arm CCA 机密计算解决方案的核心贡献者。</p><p><img width="723" height="488" referrerpolicy="no-referrer" src="/img/bVdm3Fx" alt="" title="" loading="lazy"/></p><h3>与国际企业和组织紧密合作，加速全球化</h3><p>开源六年以来，开源欧拉社区发展迅速，截至目前，社区成员企业已超 2100 家，贡献者突破 2.3 万人，社区用户超过 550 万，兼容 ISV 伙伴超 4000 家，商业 OSV 达到25家，全球开发者 PR 数达 24 万，这些数字充分证明了 openEuler 已成为中国基础软件开源社区的领军力量。</p><p>开放原子开源欧拉委员会主席熊伟指出，社区的发展离不开伙伴的支持。今年，社区迎来新增捐赠单位 AMD、浪潮云和神州数码。至此，英特尔、Arm、AMD 三大芯片企业均成为社区捐赠单位。在全球开源组织协作层面，开源欧拉社区近期与 Zephyr 嵌入式技术基金会、Linux Foundation AI&amp;Data 基金会达成深度技术合作。目前，开源欧拉社区累计与15家全球开源组织在AI、云、大数据、HPC、嵌入式等领域建立紧密合作关系。</p><p>AMD全球副总裁、大中华区大中华区及企业事业部销售总经理唐晓蕾表示，AMD 一直秉承对中国市场开放的态度，并携手 openEuler 共建 AI 产业生态。在服务器处理器方面，已经完成了相关产品和 openEuler 的所有适配，后续将在云计算、机密计算、AI 等方面持续深化与开源欧拉社区合作。</p><p><img width="723" height="487" referrerpolicy="no-referrer" src="/img/bVdm3Fy" alt="" title="" loading="lazy"/></p><p>Arm Fellow、软件社区高级总监、PyTorch 基金会董事的 Andrew Wafaa 表示，Arm公司在提升技术能力的同时，确保相关技术能够兼容开源欧拉社区，持续深耕AI的产业共建。</p><p><img width="723" height="487" referrerpolicy="no-referrer" src="/img/bVdm3Fz" alt="" title="" loading="lazy"/></p><p>人才是每个组织的核心力量。为加强社区与学术、教育界的深度联结，推动系统软件领域人才培养与生态建设，会上，openEuler社区学术与教育委员会正式成立。该委员会将统筹推进学术生态构建、人才激励体系设计及相关标准制定工作，为社区发展提供可持续的智力与人才支撑。</p><p><img width="723" height="488" referrerpolicy="no-referrer" src="/img/bVdm3FA" alt="" title="" loading="lazy"/></p><p>在 openEuler 社区学术与教育委员会的主导下，异构融合系统软件产学研联盟同步成立。算力基础设施向超节点演进将驱动操作系统技术创新，面对当前异构硬件多样化与高速互联技术快速演进所带来的生态碎片化挑战，亟需构建统一的异构融合计算架构与软件生态，凝聚产业共识，把握智能时代的发展机遇。</p><p><img width="723" height="487" referrerpolicy="no-referrer" src="/img/bVdm3FG" alt="" title="" loading="lazy"/></p><p>开发者为开源欧拉社区的持续技术创新与生态繁荣注入智慧和力量。会上，颁发 openEuler 2025 年度突出贡献单位、openEuler 2025 年度项目之星及 openEuler 2025 年度贡献之星。从产学研协同的深化，到核心技术突破，openEuler 正稳步向前，为智能时代构筑算力基础设施的核心基石。</p>]]></description></item><item>    <title><![CDATA[Python 开发必备：tempfile]]></title>    <link>https://segmentfault.com/a/1190000047402180</link>    <guid>https://segmentfault.com/a/1190000047402180</guid>    <pubDate>2025-11-15 22:02:07</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>处理大数据集或者生成报告、创建中间文件的时候，很多文件其实根本不需要永久保存。这时候可以用临时目录来解决这个问题。Python 标准库里的</p><pre><code>tempfile</code></pre><p>模块能创建用完就自动消失的临时文件和目录，省去手动清理的麻烦。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047402182" alt="" title=""/><br/>临时目录就是个生命周期很短的文件夹，专门用来存放那些不需要长期保留的数据。用完之后连同里面的内容一起删掉，文件系统保持干净。</p><p>Python 的</p><pre><code>tempfile</code></pre><p>模块提供了一套完整的解决方案，这些临时文件和目录在不需要的时候会自动清理掉。</p><h2>为什么要用临时目录</h2><p>临时目录在实际开发中有几个明显的好处：</p><p>自动清理机制省去了手动删除的步骤，每个临时目录都有唯一标识避免文件名冲突。系统会自动选择安全的存储位置，Unix 系统用</p><pre><code>/tmp</code></pre><p>，Windows 用</p><pre><code>%TEMP%</code></pre><p>。多线程和多进程环境下也能稳定工作，特别适合测试场景和需要中间存储的情况。</p><h2>什么场景下需要临时目录</h2><p>需要一个临时空间来存放中间计算结果或临时文件。写单元测试的时候模拟文件操作，完了自动清理。下载或解压的数据不需要长期保存。处理用户上传的文件，在保存最终结果之前需要一个缓冲区。构建自动化流程时，要确保不留下任何痕迹。</p><h2>tempfile 模块基础用法</h2><pre><code> import tempfile  
import os  
# Create a temporary directory
with tempfile.TemporaryDirectory() as temp_dir:  
    print(f"Temporary directory created at: {temp_dir}")  
    # Create a temporary file inside the directory
    file_path = os.path.join(temp_dir, "sample.txt")  
    with open(file_path, "w") as f:  
        f.write("Hello, Temporary World!")  
    # Read back the file
    with open(file_path, "r") as f:  
        print(f.read())  
# At this point, the directory and its contents are deleted automatically
 print("Temporary directory cleaned up automatically.")</code></pre><p>输出结果：</p><pre><code> Temporary directory created at: /tmp/tmpabcd1234  
 Hello, Temporary World!  
 Temporary directory cleaned up automatically.</code></pre><p>关键在于</p><pre><code>with</code></pre><p>语句块结束时，目录和文件会自动删除，不需要手动调用</p><pre><code>os.remove()</code></pre><p>或</p><pre><code>shutil.rmtree()</code></pre><p>。</p><h2>手动控制临时目录的生命周期</h2><p>有时候需要更精细的控制，比如临时目录的生命周期超出单个函数作用域，这时候可以用</p><pre><code>tempfile.mkdtemp()</code></pre><p>：</p><pre><code> import tempfile  
import shutil  
import os  
# Create a temporary directory manually
temp_dir = tempfile.mkdtemp()  
print(f"Created temporary directory: {temp_dir}")  
# Work inside it
file_path = os.path.join(temp_dir, "example.txt")  
with open(file_path, "w") as f:  
    f.write("Manual cleanup required!")  
print("Files inside temp dir:", os.listdir(temp_dir))  
# Clean up manually when done
shutil.rmtree(temp_dir)  
 print("Temporary directory removed.")</code></pre><p>这种方式下需要自己负责清理工作，用完记得删除。</p><h2>自定义临时目录的命名和位置</h2><pre><code>tempfile</code></pre><p>支持给临时目录添加前缀和后缀，方便调试时识别：</p><pre><code> import tempfile  
 # Create with custom prefix and suffix
 with tempfile.TemporaryDirectory(prefix="myapp_", suffix="_data") as temp_dir:  
     print(f"Created: {temp_dir}")</code></pre><p>输出类似这样：</p><pre><code> Created: /tmp/myapp_abcd1234_data</code></pre><p>还可以指定父目录：</p><pre><code> with tempfile.TemporaryDirectory(dir="/path/to/parent") as temp_dir:  
     print(temp_dir)</code></pre><p>当系统默认的临时目录权限不够或者空间不足时，这个功能就派上用场了。</p><h2>实战案例：安全处理 ZIP 文件</h2><p>下载大型 ZIP 文件后临时解压处理，处理完就清理掉：</p><pre><code> import tempfile  
import zipfile  
def extract_and_process(zip_path):  
    with tempfile.TemporaryDirectory() as tmp_dir:  
        print(f"Extracting to {tmp_dir}")  
        with zipfile.ZipFile(zip_path, "r") as zip_ref:  
            zip_ref.extractall(tmp_dir)  
        # Process extracted files
        for file in os.listdir(tmp_dir):  
             print("Processing:", file)</code></pre><p>整个流程结束后，解压的文件夹自动删除，磁盘不会留下任何垃圾文件。</p><h2>实战案例：动态生成报告</h2><p>应用程序按需生成报告文件（PDF、CSV 之类），不需要永久存储：</p><pre><code> import tempfile  
import csv  
import os  
def generate_temp_report(data):  
    with tempfile.TemporaryDirectory() as tmp_dir:  
        file_path = os.path.join(tmp_dir, "report.csv")  
        with open(file_path, "w", newline="") as csvfile:  
            writer = csv.writer(csvfile)  
            writer.writerow(["Name", "Age"])  
            writer.writerows(data)  
        print(f"Report generated at: {file_path}")  
         # Here you can upload it, email it, or read the content directly</code></pre><p>生成的报告可以直接上传、发邮件或者读取内容，不会在本地留存。</p><h2>实战案例：单元测试中的文件操作</h2><p>写单元测试时在项目目录下创建很多文件夹显然不是好主意，所以临时目录完美解决这个问题：</p><pre><code> import tempfile  
import unittest  
import os  
class TestFileOperations(unittest.TestCase):  
    def test_temp_directory(self):  
        with tempfile.TemporaryDirectory() as temp_dir:  
            file_path = os.path.join(temp_dir, "test.txt")  
            with open(file_path, "w") as f:  
                f.write("test data")  
              
             self.assertTrue(os.path.exists(file_path))</code></pre><p>每个测试用例都在独立的临时环境中运行，互不干扰，也不需要手动清理。</p><h2>嵌套临时目录</h2><p>复杂场景下可能需要嵌套的临时目录结构：</p><pre><code> import tempfile  
 import os  
 with tempfile.TemporaryDirectory() as root_dir:  
     print(f"Root: {root_dir}")  
     sub_dir = tempfile.mkdtemp(dir=root_dir)  
     print(f"Nested: {sub_dir}")</code></pre><p>多阶段数据处理流程中，每个阶段可以有自己的独立沙箱环境。</p><h2>使用临时目录的几个注意事项</h2><p>始终使用上下文管理器</p><pre><code>with tempfile.TemporaryDirectory()</code></pre><p>来确保自动清理。不要硬编码</p><pre><code>/tmp</code></pre><p>路径，用</p><pre><code>tempfile.gettempdir()</code></pre><p>获取系统临时目录。如果用了</p><pre><code>mkdtemp()</code></pre><p>就必须手动调用</p><pre><code>shutil.rmtree()</code></pre><p>清理。给临时目录加上有意义的前缀方便调试时快速定位。临时数据随时可能被系统清理，不要在里面存放需要持久化的信息。</p><h2>几个实用技巧</h2><p>获取系统临时目录路径：</p><pre><code> importtempfile
 print(tempfile.gettempdir())</code></pre><p>生成唯一文件名（但不创建文件）：</p><pre><code> tempfile.mktemp()</code></pre><p>不过要注意，直接用</p><pre><code>mktemp()</code></pre><p>有安全风险，生产环境建议用</p><pre><code>NamedTemporaryFile</code></pre><p>或</p><pre><code>TemporaryDirectory</code></pre><p>。</p><h2>生产环境中的实际应用</h2><p>下面这段代码展示了如何在 PDF 处理项目中使用临时目录。整个流程包括 PDF 转图片、图片转 Markdown、最后合并成完整文档：</p><pre><code> import os  
import io  
import shutil  
import tempfile  
from pathlib import Path  
from typing import Iterable, Optional, Callable, Tuple  

# Requires: pip install pymupdf pillow  
import fitz  # PyMuPDF  
 from PIL import Image  </code></pre><pre><code> def process_pdfs_to_markdown(  
    pdf_paths: Iterable[str | os.PathLike],  
    output_dir: str | os.PathLike,  
    *,  
    page_image_dpi: int = 200,  
    image_format: str = "PNG",  
    llm_page_markdown_fn: Optional[Callable[[Path], str]] = None,  
) -&gt; Tuple[list[Path], list[Path]]:  
    """  
    Convert each input PDF into page images using a temporary workspace, run an LLM on each page image to get  
    Markdown, save one MD per page (still in a temp workspace), then merge the per-PDF Markdown into a single  
    non-temporary Markdown file per PDF in `output_dir`.  
      
    Non-temp file handling is kept simple (write final merged .md into `output_dir`), while the heavy lifting  
    uses temp directories that auto-clean on success or error.  
      
    Parameters  
    ----------  
    pdf_paths : Iterable[str | PathLike]  
        Paths to PDF files to process.  
    output_dir : str | PathLike  
        Directory where FINAL merged Markdown files (non-temp) will be written.  
    page_image_dpi : int, optional  
        Rendering resolution for converting PDF pages to images. Higher DPI → sharper (default 200).  
    image_format : str, optional  
        Image format for page renders (e.g., "PNG", "JPEG"). Default "PNG".  
    llm_page_markdown_fn : Callable[[Path], str], optional  
        A callable that takes a Path to a page image and returns Markdown text for that page.  
        If not provided, a placeholder stub will be used.  
      
    Returns  
    -------  
    Tuple[list[Path], list[Path]]  
        A tuple (final_markdown_files, per_page_markdown_files_flattened)  
        - final_markdown_files: list of merged Markdown file paths written in output_dir (non-temp)  
        - per_page_markdown_files_flattened: flattened list of all per-page MD files (in temp, ephemeral)  
          (Returned for inspection/logging; these will be deleted when temp dir goes away.)  
      
    Notes  
    -----  
    - Uses a single top-level TemporaryDirectory for the whole batch to keep structure neat.  
    - For each PDF, creates `/tmp/.../&lt;pdf_stem&gt;/images` and `/tmp/.../&lt;pdf_stem&gt;/md`.  
    - Each page is rendered to an image file named `page-&lt;index&gt;.&lt;ext&gt;`.  
    - Each page's Markdown is saved to `page-&lt;index&gt;.md`.  
    - Finally, merges all page MDs for that PDF into `&lt;output_dir&gt;/&lt;pdf_stem&gt;.md` (non-temp).  
    - Replace `llm_stub_markdown_from_image` with your actual LLM call (OpenAI, local VLM, etc.).  
      
    Pseudocode hint for real LLM integration  
    ----------------------------------------  
    def llm_page_markdown_fn(img_path: Path) -&gt; str:  
        # pseudo:  
        # bytes = img_path.read_bytes()  
        # resp = my_llm_client.vision_to_md(image=bytes, system_prompt="Extract content as Markdown.")  
        # return resp.markdown  
        pass  
    """  
    output_dir = Path(output_dir)  
    output_dir.mkdir(parents=True, exist_ok=True)  

    # --- Local helper: default LLM stub (replace this with your LLM call) ---  
    def llm_stub_markdown_from_image(img_path: Path) -&gt; str:  
        # This is a placeholder. Swap with a real LLM/VLM call to convert the image to Markdown.  
        # You can pass the image bytes and ask the model to produce clean Markdown with headings, tables, lists, etc.  
        return f"# Page extracted (stub)\n\n_Image: {img_path.name}_\n\n&gt; Replace this with real LLM Markdown output."  

    # Choose the LLM function (user-supplied or stub)  
    llm_to_md = llm_page_markdown_fn or llm_stub_markdown_from_image  

    final_markdown_files: list[Path] = []  
    per_page_markdown_files_flattened: list[Path] = []  

    # Top-level temp root for the entire run  
    with tempfile.TemporaryDirectory(prefix="pdf2img-md_") as temp_root:  
        temp_root = Path(temp_root)  

        for pdf_path in map(Path, pdf_paths):  
            if not pdf_path.exists() or pdf_path.suffix.lower() != ".pdf":  
                # Skip invalid entries gracefully; alternatively raise ValueError  
                continue  

            pdf_stem = pdf_path.stem  
            pdf_temp_dir = temp_root / pdf_stem  
            images_dir = pdf_temp_dir / "images"  
            md_dir = pdf_temp_dir / "md"  
            images_dir.mkdir(parents=True, exist_ok=True)  
            md_dir.mkdir(parents=True, exist_ok=True)  

            # --- 1) Render pages to images in temp ---  
            # Using PyMuPDF: fast, no external poppler dependency  
            pages_rendered: list[Path] = []  
            with fitz.open(pdf_path) as doc:  
                # scale based on DPI (PyMuPDF normally uses zoom factors; convert DPI to zoom)  
                # Base DPI ~72; zoom = target_dpi / 72  
                zoom = page_image_dpi / 72.0  
                mat = fitz.Matrix(zoom, zoom)  

                for page_index in range(doc.page_count):  
                    page = doc.load_page(page_index)  
                    pix = page.get_pixmap(matrix=mat, alpha=False)  # no alpha for standard formats  
                    img_bytes = pix.tobytes(output=image_format.lower())  

                    img_name = f"page-{page_index + 1}.{image_format.lower()}"  
                    img_path = images_dir / img_name  

                    # Save via PIL to ensure consistent headers/metadata if needed  
                    with Image.open(io.BytesIO(img_bytes)) as im:  
                        im.save(img_path, format=image_format)  

                    pages_rendered.append(img_path)  

            # --- 2) For each page image, call LLM to get Markdown; save per-page MD in temp ---  
            page_md_files: list[Path] = []  
            for img_path in pages_rendered:  
                md_text = llm_to_md(img_path)  # &lt;-- your real LLM call here  
                md_path = md_dir / (img_path.stem + ".md")  
                md_path.write_text(md_text, encoding="utf-8")  
                page_md_files.append(md_path)  
                per_page_markdown_files_flattened.append(md_path)  

            # --- 3) Merge per-page MD into a FINAL non-temp Markdown file (one per PDF) ---  
            final_md_path = output_dir / f"{pdf_stem}.md"  
            # If you want sophisticated merging rules, implement here (e.g., front matter, TOC).  
            # Pseudocode for richer post-processing could be:  
            #   combined = render_front_matter(pdf_path) + "\n" + concatenate_markdown(page_md_files) + "\n" + add_toc()  
            #   final_md_path.write_text(combined, encoding="utf-8")  
            with final_md_path.open("w", encoding="utf-8") as fout:  
                fout.write(f"&lt;!-- Source PDF: {pdf_path.name} --&gt;\n")  
                fout.write(f"# {pdf_stem}\n\n")  
                for i, md_file in enumerate(sorted(page_md_files, key=lambda p: p.name), start=1):  
                    fout.write(f"\n\n---\n\n&lt;!-- Page {i} --&gt;\n\n")  
                    fout.write(md_file.read_text(encoding="utf-8"))  

            final_markdown_files.append(final_md_path)  

        # NOTE:  
        # All temp content (images &amp; per-page MDs) is automatically cleaned up on exit.  

     return final_markdown_files, per_page_markdown_files_flattened</code></pre><p>这段代码的亮点在于所有中间文件（图片、单页 Markdown）都存放在临时目录里，处理完自动清理，只保留最终合并后的文档。整个流程非常干净，不会在磁盘上留下任何垃圾文件。</p><p>实际使用时把</p><pre><code>llm_stub_markdown_from_image</code></pre><p>替换成真正的 LLM 调用（比如 OpenAI 的 Vision API 或者本地视觉模型），就能实现完整的 PDF 文档处理流程。</p><h2>总结</h2><p>临时目录在 Python 开发中确实是个实用的工具，文件处理更高效也更安全。不管是处理用户上传、写单元测试还是构建数据流水线，</p><pre><code>tempfile.TemporaryDirectory()</code></pre><p>都能让代码更简洁、更可靠。掌握它的用法能省不少麻烦，代码质量也能上个台阶。</p><p><a href="https://link.segmentfault.com/?enc=c0vHXP8END5Ss%2FinLxgoyg%3D%3D.o92Vv2F0nY5kWeRjlwtRjcURA2Xga2dSGhLc09TViXLUfYdkc4kVorgeGYK3AH8eShRfrISL5iWfsfoVK1tZ5Q%3D%3D" rel="nofollow" target="_blank">https://avoid.overfit.cn/post/ee53c91b40f844d5b6faed7a637515ca</a></p><p>作者 Sravanth</p>]]></description></item><item>    <title><![CDATA[银行中外汇的由来（金融产品经理必读） 东]]></title>    <link>https://segmentfault.com/a/1190000047402192</link>    <guid>https://segmentfault.com/a/1190000047402192</guid>    <pubDate>2025-11-15 22:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>经常听到我们国家有多少多少亿美元的外汇储备，是否有这样的疑问，外汇储备是什么，它又是怎么来的，银行又是如何处理外汇储备的，今天就闲聊一下。</p><h2>外汇管理</h2><h4>常见概念</h4><p><strong>现汇：</strong> 通俗来讲，就是<strong>在银行账户里</strong>可以自由买卖、自由兑换成其他国家货币，还能方便地用于国际结算的外汇资金。</p><p><strong>现钞：</strong> 现钞就是我们日常生活中能实实在在拿到手、看得见摸得着的外国货币纸币和硬币。比如你去银行用人民币换了一些美元纸币，并且拿回家，这时候它们就是现钞。</p><p><strong>存放同业：</strong> 是指商业银行等金融机构将资金存放在其他银行或非银行金融机构的行为，从存放资金的金融机构角度来看，这笔资金是其资产，因为它把钱存到其他机构，拥有对这笔资金的所有权和支配权，只是暂时存放在别处。</p><p><strong>同业存放：</strong> 对于接受同业存放的金融机构来说，其目的主要是增加资金来源，充实自身的资金实力，以便更好地开展贷款、投资等业务。同时，通过吸收同业存放资金，也可以加强与其他金融机构的业务联系，提升在金融市场中的影响力。</p><h4>外汇管制</h4><p>我国禁止外汇在国内流通，为什么要进行外汇管制呢？因为管制可以<strong>维护国际收支平衡、稳定人民币汇率、保障国家金融安全、促进经济结构调整和产业发展</strong>。</p><h5>外汇管制有哪些手段？</h5><p><strong>不能以外汇标价：</strong> 比如你开个超市，你不能标1瓶酱油1美元，只能标价xx元。<br/><strong>禁止用于结算：</strong> 你购进一批货物，你手里没有人民币，但是你手里有美元，但是你不能直接把美元转给他。<br/><strong>企业使用外汇控制：</strong> 企业如需使用外汇（超过了规定的自有额度）时，需要向外管局进行申请。<br/><strong>人出入境控制：</strong> 个人出入境，也要控制外币额度，限制金额，并且要申报。</p><p>上述只是一些基础手段，实际情况远远不止这些，有兴趣的同学可以自行去查证。</p><h4>自贸区</h4><p>外汇使用起来较为麻烦，这也影响了企业的正常经营以及效率，为此国家进一步改革开放，局部地放松外汇管制，这就创立了所谓的自贸区。</p><blockquote>目前，中国有21 个自由贸易试验区，分别是上海、广东、天津、福建、辽宁、浙江、河南、湖北、重庆、四川、陕西、海南、山东、江苏、河北、云南、广西、黑龙江、北京、湖南、安徽自由贸易试验区。<br/>此外，中国还有海南自由贸易港，它与自由贸易试验区在本质上存在差异，自贸港是 “境内关外”，实行更加开放的政策，涵盖人才流动自由、资金流动自由和低税率等方面，而自贸区主要是指货物贸易的自由化。</blockquote><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047402195" alt="" title=""/></p><p>通过上图我们可以看到，实际上一个企业在自贸区的话，需要开一个自贸区新账户。<strong>原有账户：</strong> 与非自贸区进行交易，有外汇限制。<strong>新开的自贸区账户：</strong> 可以与境外进行自由交易，没有外汇限制。</p><p>自贸区账户其实就相当于在境外的企业，原有账户和自贸区账户之间是隔离的。</p><h2>外汇储备</h2><p><strong>那外汇储备怎么来的呢？</strong> 当出口大于进口（所谓顺差），外汇余额就要流到国内银行体系中，最终流到央行，而央行要拿人民币来买这些外汇，形成所谓的国家“外汇储备”。</p><blockquote>为方便理解，下面的例子中我们假设人民币兑美元的汇率是1:1</blockquote><h4>出口商出口商品</h4><p>那我们举个例子，A企业和境外的B企业做生意，A企业将货物出口到B企业所在的国家（比如说美国），B企业需要把钱给A企业，但是A和B在不同的国家并且不属于同一个会计核算主体，因此<strong>不能简单的用下面的会计分录来处理</strong>。</p><pre><code>借：B企业活期
贷：A企业活期</code></pre><p>这时候需要借助于银行间的“同业存放”和“存放同业”进行中转。实际上就是国内的银行，在国外银行开了一个户，然后进口商买了货物，要把钱给出口商，由对应的银行进行中转再给出口商。付钱其实就是把钱给同业存放，收钱就是从存放同业中拿钱，这就是所谓的现汇。</p><p>把例子举的更具体一些，A企业通过招商银行中转收钱，招商银行在美国花旗银行开了一个账户，在招商银行的会计体系中，有个科目叫做<strong>存放同业</strong>，属于招商银行的<strong>资产类科目</strong>，则相应的在花旗银行会计体系中有个科目叫做<strong>同业存放</strong>，属于花旗银行的<strong>负债类科目</strong>。</p><p>相应的会计分录，可以简单的写作以下两组分录。</p><h5>花旗银行侧</h5><pre><code>借：B企业活期（美元）
贷：同业存放-招商银行（美元）</code></pre><h5>招商银行侧</h5><pre><code>借：存放同业-花旗银行（美元）
贷：A企业活期（美元）</code></pre><p>由于外汇不能直接在境内流通，以及央行需要进行强制结汇，因此需要把外汇卖给央行。</p><h4>把外汇卖给央行</h4><p>招商银行的外汇，实际是存放在花旗银行的<strong>同业存放</strong>里面，所以如果要把外汇卖给央行，那么央行也必须在花旗银行开一个<strong>同业存放</strong>的账户，也就是说，从花旗银行的“招商银行同业存款”转到“央行同业存款”中。总的来说，分为如下几个步骤：</p><ul><li>招商银行在花旗银行存的美元，变成了央行在花旗银行存的美元。那么在花旗侧的会计分录：</li></ul><pre><code>借：同业存放-招商银行（美元）
贷：同业存放-央行（美元）</code></pre><ul><li>招商银行的“存放境外的美元”，变成了“存放央行的人民币”；在招商银行侧有会计分录：</li></ul><pre><code>借：存放央行（人民币）
贷：存放同业-花旗银行（美元）</code></pre><ul><li>央行多了一笔“存放境外的美元”，以及一笔“招商银行存放的人民币”，在央行侧有会计分录：</li></ul><pre><code>借：存放同业-花旗银行（美元）
贷：同业存放-招商银行（人民币）</code></pre><ul><li>出口商的“活期存款美元”，变成了“活期存款人民币”。在招商银行侧有会计分录：</li></ul><pre><code>借：A企业活期（美元）
贷：A企业活期（人民币）</code></pre><p>最后的状态是：A企业在招商银行有出口的钱（人民币），央行在花旗银行有存放同业（美元），招商银行在央行有存放同业（人民币）。最后变成了外汇，也就是我们国家外汇储备的主要由来。</p><p>为了方便理解，仅从便于理解的角度进行说明，在实际操作中，与本节描述的内容有比较大的不同。比如，实际上央行不一定在境外银行开立账户，可以由指定的商业银行代持。另外，外汇资产通常由境外存款转化为其他外汇资产（如，购买美国国债、股票、货币市场工具、黄金等等）</p><h4>外汇的好处与坏处</h4><h5>好处：</h5><p>我国可以动用这些钱购买国外的资产。</p><h5>坏处：</h5><ul><li>导致人民币通货膨胀：企业和个人获得的外汇卖给指定银行，银行再将多余的外汇卖给中央银行，中央银行则需要发行相应的人民币来购买这些外汇，这就增加了基础货币的投放。从而推动物价上涨，引发通货膨胀。不过咱们央妈有很多来避免或者减少相关的政策。</li><li>汇率风险：这个就不用多收了，汇率变化可能导致我们手里的美元不值钱了。</li></ul>]]></description></item><item>    <title><![CDATA[智能招聘新范式 爱跑步的香蕉_cKtiN]]></title>    <link>https://segmentfault.com/a/1190000047402096</link>    <guid>https://segmentfault.com/a/1190000047402096</guid>    <pubDate>2025-11-15 20:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>智能招聘新范式<br/>人才战争下半场：AI重构精准招聘新范式</p><p>当生成式AI从炫技工具变为生产力标配，企业竞争已悄然进入“人机协同”的深水区。数据显示，仍沿用传统方式招聘的企业，正以每年15%的速度流失人才竞争力。招聘的终极战场，早已从“找到更多人”升级为“精准识别对的人”。</p><p>现实中，大多数HR团队仍陷在简历海啸中，用人类宝贵的情感判断力，去完成本应由AI处理的数据筛选。这种角色错位，正是人机协同失败的开端。</p><p>人机协同的本质：专业分工，各展所长</p><p>在招聘博弈中，人与AI有着明确的能力疆界：</p><p>•人类不可替代：候选人动机深度判断、用人部门需求洞察、团队冲突调解<br/>•AI天生擅长：海量数据处理、标准化流程执行、精准信息匹配、7×24小时自动化</p><p>真正的智能招聘，不是用AI取代HR，而是用AI将HR从机械劳动中解放出来，让其专注于需要人类智慧的核心决策。</p><p>精准招聘的核心：从“识别”到“理解”的质变</p><p>当多数AI面试产品还停留在“关键词匹配”时，先进的AI招聘技术已实现从“识别”到“理解”的跨越，其精准度经得起严苛的心理学验证：</p><p>•通过效标效度与重测稳定信度双重考验<br/>•支持“背靠背”人机对比实验<br/>•打分结果可直接作为招聘决策依据，无需人工二次解读</p><p>这标志着招聘决策彻底告别“凭感觉”，进入“凭数据”的科学化时代。</p><p>四大核心技术，贯穿招聘全流程</p><p>1.一问多能：单道题目同步评估多项胜任力，评估效率提升50%以上，无缝衔接HR初筛与技术复试<br/>2.自由追问：基于候选人回答即时生成针对性问题，如资深面试官般捕捉关键信息，杜绝能力误判<br/>3.简历深度挖掘：自动抓取简历关键信息与模糊点，通过递进式提问杜绝信息造假，避免错失优质人才<br/>4.全维度考察：覆盖通用胜任力与专业领域能力评估，同时解放HR与专业面试官</p><p>候选人体验升级：重塑面试价值</p><p>传统AI面试的“机械感”容易劝退优秀人才，新一代AI招聘技术重新设计了全流程体验：</p><p>•懂情绪的智能交互：精准捕捉语速、情绪与潜台词，引导候选人充分展现实力<br/>•无断点流畅体验：自动识别回答状态，全程如面对面交流般自然<br/>•沉浸式视觉体验：语音与口型匹配精度大幅提升，告别“纸片人”疏离感<br/>•多轮对话答疑：候选人可随时提问，AI准确解答职位与公司信息，提升入职意愿</p><p>全流程智能革命：从“找人”到“识人”</p><p>先进的AI人才寻访系统，实现了招聘初筛的完全自动化，真正达成从“找人”到“识人”的跨越：</p><p>•30-60秒快速初始化，即刻投入工作<br/>•智能筛选：自主操作页面，按预设条件精准识别候选人<br/>•动态沟通：模拟人类语气互动，发现不合适即时退出<br/>•全覆盖回复：遍历所有未读消息，个性化回复不漏人<br/>•系统同步：自动完成从下载简历到ATS上传的全流程</p><p>这不仅是操作环节的提效，更是通过大模型技术将“经验型判断”升级为“数据型决策”，推动整个招聘决策体系的科学化变革。</p><p>人才战争的号角已经吹响，企业的选择将决定其竞争力走向：是沿用昨天的工具应对明天的挑战，还是拥抱已被验证的智能招聘新范式，实现人才竞争力的跨越式提升。<br/>AI得贤招聘官</p>]]></description></item><item>    <title><![CDATA[怎么查公司邮箱？2个技巧 遭老罪的程序猿]]></title>    <link>https://segmentfault.com/a/1190000047401819</link>    <guid>https://segmentfault.com/a/1190000047401819</guid>    <pubDate>2025-11-15 19:02:14</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在企业间往来、业务沟通、客户支持等多种业务场景下，常常需要获得一家公司的企业邮箱。那么，公司邮箱要去哪里查？有哪些实用方式？本文将详细介绍。<br/><img width="723" height="443" referrerpolicy="no-referrer" src="/img/bVdm3xC" alt="" title=""/></p><h2>一、什么是企业邮箱</h2><h2>企业邮箱的定义</h2><p>企业邮箱，是以公司自有域名（如<a href="mailto:xxx@yourcompany.com" target="_blank">xxx@yourcompany.com</a>）为后缀的邮箱系统。它区别于个人常用的免费邮箱，大多需要部署在专业邮件服务平台上，如Zoho、Gmail（Google Workspace）等。这种邮箱不仅用于日常的邮件收发，更是公司对外展示正规形象的标配。</p><h2>企业邮箱的作用</h2><p>企业邮箱是公司通信、业务往来、客户服务、合作跟进等各个流程的核心通道。</p><p>基于域名的邮箱提升公司业务联系的可信度。<br/>有利于统一的邮件管理、信息备份与数据安全。<br/>可以设置部门、人员分级管理，实现高效的业务协作和员工信息整合。<br/>许多企业采用Zoho邮箱建立专属域名邮箱，维护品牌形象，兼顾数据安全和管理便捷。</p><h2>企业邮箱与普通邮箱的区别</h2><p>企业邮箱与个人邮箱最大的区别在于邮箱后缀归属于企业自有域名。个人邮箱如<a href="mailto:xxx@163.com" target="_blank">xxx@163.com</a>、<a href="mailto:xxx@gmail.com" target="_blank">xxx@gmail.com</a>主要满足个人通信需求，而企业邮箱如<a href="mailto:xxx@company.com" target="_blank">xxx@company.com</a>或<a href="mailto:xxx@yourbrand.cn" target="_blank">xxx@yourbrand.cn</a>体现组织身份。此外，企业邮箱通常具备更高的安全级别、更大的存储空间、更完善的管理和备份机制。普通邮箱则在安全、管理和品牌形象上存在一定局限，无法满足企业规模化、多部门、多终端的需求。</p><h2>二、如何查找企业邮箱</h2><p>企业邮箱公开程度视公司政策而定，但通过以下两种渠道，基本能高效获取所需企业邮箱信息。</p><h2>1. 通过公司官网查找</h2><p>查找官网的联系方式页面<br/>最直接的方式是打开企业的官方网站。绝大多数正规公司都会在首页下方或明显位置设置“联系方式”页面，这里会详细列出公司官方邮箱、服务热线、传真等联络方式，多为业务、合作、招聘、客服等细分邮箱。</p><h2>检查官网的“联系我们”板块</h2><p>不管是中小企业还是世界500强，他们的网站基本都设有“联系我们”一栏。此处通常会以清晰的表格或列表形式给出企业邮箱、联系地址、业务专员邮箱等，可以一目了然地获取对外公开的邮箱信息。</p><h2>检索官网的客户服务页面</h2><p>除了一般的联系方式，企业还会专门设有“客户服务”或“技术支持”等页面。特别是互联网、软件、云服务类企业，在这些页面往往会公布工单邮箱、技术支持邮箱及客户关怀邮箱等，更贴合业务沟通的具体场景。</p><h2>2. 利用搜索引擎查找</h2><p>输入公司名称和关键词组合<br/>如果在官网找不到明确的邮箱联系方式，可以巧用搜索引擎，比如百度、Google等。将公司名称结合关键词如“邮箱”、“contact”、“customer service email”进行检索，能够筛选外部发布的信息。关键词可灵活组合提升检索精度，例如“公司名+邮箱”、“公司名+客服邮箱”。</p><h2>查看搜索结果中的邮箱信息</h2><p>搜索结果页上，常可出现第三方网站、行业黄页、招聘网站、新闻稿件等处的企业邮箱线索。例如，大型企业参与展会、发起新闻活动时，会以邮箱作为联系渠道。同时还可进入权威第三方平台（如天眼查、企查查）查看企业公开资料，有时亦会披露企业邮箱。</p><h2>验证搜索结果的准确性</h2><p>通过多渠道搜集到的企业邮箱，务必核实其是否为官方邮箱，尤其是遇到个人博客、第三方论坛等不稳定来源。可以对比官网信息或直接通过官方渠道确认，避免误用、被钓鱼邮件冒用等风险。</p><h2>3. 通过社交媒体查找</h2><p>查找公司官方社交媒体账号<br/>现代企业普遍注重品牌传播与客户互动，多会在微信、微博、LinkedIn、Facebook、Twitter等平台注册公司账号。可以在这些平台搜索公司官方账号。</p><h2>检查社交媒体上的联系方式</h2><p>不少企业在社交媒体主页或简介栏直接写明企业邮箱，有些则通过发布固定动态、置顶推文等方式分享官方联系邮箱。</p><h2>发送私信或留言确认邮箱</h2><p>如遇到社交平台未直接公开邮箱，您还可主动发私信或在评论区联系官方账号客服，索要业务对应的邮箱信息，以获得最新和一手的企业邮箱。</p><h2>三、推荐使用 Zoho 邮箱</h2><p>Zoho 邮箱的优势<br/>Zoho邮箱目前在全球服务超过1800万企业级客户，已稳居全球邮箱排行榜前三，是企业信赖的邮件服务首选。作为专业域名邮箱提供商，Zoho邮箱具备多重独特优势：</p><p>安全性高：内置先进的反垃圾邮件、病毒查杀和邮件加密机制，能有效保障企业数据安全，并支持多重身份认证，保护内部信息不泄露。<br/>功能强大：不仅仅是常规的邮件收发，Zoho邮箱还集成日历、任务、笔记、云存储、团队协作等功能，适配多场景办公。配合移动端应用，随时随地管理公司邮箱。<br/>易于管理：后台支持多账户统一管理、员工邮箱批量分配、权限设置、邮件日志追踪等功能；管理员可轻松为新员工快速分配专属域名邮箱，高效应对组织变更和信息审计。</p><h2>如何注册 Zoho 邮箱</h2><p>访问 Zoho 官网：首先打开Zoho邮箱官网，即可进入企业邮箱注册入口。<br/>选择企业邮箱服务：在页面中选择“企业邮箱”，了解不同套餐和功能介绍，并明确选用域名邮箱服务，便于企业邮箱后缀和品牌保持一致。<br/>按照注册步骤完成注册：注册流程非常简明：输入管理员信息，绑定企业专属域名，设置管理员和首批员工邮箱，按照注册步骤持续操作。Zoho邮箱自助引导页面十分友好，国内外企业均可顺畅开通并投入使用。</p><h2>Zoho 邮箱的使用技巧</h2><p>邮件分类与管理：支持自定义文件夹、标签、邮件规则，让员工能高效地整理日常邮件，大幅提升信息处理效率。<br/>邮件安全设置：管理员可设置账号安全策略，启用多因素登录验证，限制可用设备等，保障邮箱账号不易被非法访问。<br/>团队协作功能：除标准邮件功能外，还内嵌团队聊天、共享日历、通讯录共享等，可满足跨部门沟通需求。此外，通过域名邮箱，所有团队成员的邮箱均带有相同公司域名，进一步增强专业形象。</p><h2>总结</h2><p>查找一个公司的企业邮箱并不复杂。主要需借助公司官网查找联系方式、客户服务板块，或结合搜索引擎和社交媒体平台多方确认，最终获取最权威的企业邮箱信息。值得一提的是，目前越来越多企业选用Zoho邮箱作为官方沟通渠道。Zoho邮箱不仅以1800万企业级客户、全球前三的业界地位获得认可，还因其安全性、域名邮箱优势与便捷注册步骤满足了从初创团队到大型企业的全面需求。如果正在为企业选型邮箱，不妨考虑Zoho邮箱，为公司通信、客户互动和信息安全提供坚实保障。</p>]]></description></item><item>    <title><![CDATA[2025国际邮箱排行榜TOP5 遭老罪的]]></title>    <link>https://segmentfault.com/a/1190000047401830</link>    <guid>https://segmentfault.com/a/1190000047401830</guid>    <pubDate>2025-11-15 19:01:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在国际商务和个人沟通中，选择一款好用的邮箱平台至关重要。2025年，被全球用户广泛认可并持续占据主导地位的国际邮箱服务主要集中在五家：Gmail、Outlook、Zoho邮箱、Yahoo Mail和ProtonMail。本文将具体介绍这些邮箱各自的亮点特性、适用场景及选择建议，帮助用户在多元化需求下做出适合自己的明智决策。<br/><img width="723" height="443" referrerpolicy="no-referrer" src="/img/bVdm3xJ" alt="" title=""/></p><h2>一、2025年国际认可度高的邮箱排名</h2><h2>Gmail：全球领先的邮箱服务</h2><p>强大的搜索功能与智能分类：依托于Google强大的搜索技术，Gmail使用户查找邮件、附件变得异常高效。通过标签、自动分类等方式，Gmail可以智能识别广告、社交、重要邮件，有效降低信息干扰，提升查找效率。<br/>安全性与隐私保护优势：利用两步验证、AI反垃圾邮件技术以及强大的服务器加密能力，守护用户数据安全。谷歌致力于不断更新安全协议，有效阻止钓鱼攻击，使用户账户安全系数持续走高。<br/>丰富的插件与扩展功能：支持与Google Workspace深度整合，同时开放多种浏览器扩展插件。例如日历、任务、第三方文件管理、甚至客户关系管理CRM插件，极大地扩展了邮箱的日常效率与应用场景。</p><h2>Outlook：微软旗下的全能邮箱</h2><p>与办公软件的无缝集成：作为微软生态系统的核心产品之一，Outlook可以与Word、Excel、PowerPoint等办公套件无缝对接。通过一站式管理日历、任务和邮件，极大提升团队与个人的工作效率。<br/>跨平台同步与便捷管理：无论在Windows、Mac还是移动端，Outlook都实现了高效同步。即使用户在多个设备间切换，也可随时访问最新邮件记录，实现云端数据的全程保障。<br/>企业级安全与可靠性：配备多重身份验证及反病毒、反钓鱼技术，并支持邮件加密，为企业客户提供银行级的安全防护措施，是全球众多大型企业的首选邮箱之一。</p><h2>Zoho邮箱：崛起的商务邮箱新秀</h2><p>高级安全功能与数据加密：采用多层加密和严格的数据隔离标准，支持端到端加密，让企业邮件实现数据自主可控；结合AI反垃圾技术有效隔离恶意邮件，全面保障信息安全。<br/>强大的协作与团队管理工具：提供企业级通讯录、任务协作、日历与文件管理，支持多域名邮箱统一管理，方便企业根据业务需要设置角色、权限和审批流程，提升团队协作效率。<br/>高性价比与定制化服务：为企业和个人用户提供灵活的套餐选择及高度定制化服务，涵盖从个人免费版到大中型企业的专属高级版，大大提升投入产出比。特别是针对中国及海外两地企业推出的域名邮箱方案，极大便利跨境通讯。<br/>全球排行榜与企业采用现状：2025年，Zoho邮箱凭借全球1800万企业级客户，已跻身全球邮箱排行前三，在欧美、东南亚和新兴市场的企业用户中尤其受到青睐。其完善的注册步骤极大降低了企业开通与维护门槛，无需繁琐流程，即可便捷接入国际商务通讯网络。</p><h2>Yahoo Mail：历史悠久的邮箱服务</h2><p>简洁的界面与易用性：以简明直观的界面和高兼容性著称，新用户上手门槛低，收件、发件等操作流畅顺手，特别适合偏好基础功能的用户群体。<br/>个性化定制与丰富的主题：提供丰富多样的界面主题、头像和自定义设置，可根据个人兴趣个性化邮箱外观；日历、天气、新闻等内容可一键集成，在邮件管理之余获取更多信息服务体验。<br/>社交媒体集成与互动性：支持与Facebook、Twitter等社交媒体对接，使用户无需离开邮箱即可便捷发布、转发信息，提升全场景的信息管理与社交互动效率。</p><h2>ProtonMail：注重隐私的加密邮箱</h2><p>零访问权限的隐私保护：总部位于瑞士，遵循全球严格的数据隐私法规。其最大亮点是连公司自身都无法解密用户邮件，为用户提供最高级别的数据保护。<br/>端到端加密技术：每一封邮件在用户设备端即被加密，即便第三方拦截邮件内容也无法破解，有效保障个人及企业敏感信息的绝对安全。<br/>简洁的用户界面与易用性：界面简洁明了，支持网页、移动端多平台同步，适合追求极致隐私和安全保护的企业或个人用户使用。<br/>2025国际邮箱前五对比表<br/>邮箱名称    所属公司    核心安全特色    团队协作能力    支持域名邮箱    注册步骤复杂度    主要用户群<br/>Gmail    Google    全面加密防护、AI反垃圾    强    支持    简单    个人、企业<br/>Outlook    微软    多层身份验证、反病毒    极强    支持    简单    企业、教育<br/>Zoho邮箱    Zoho    数据隔离、端到端加密    极强    强    最简单    企业<br/>Yahoo Mail    Yahoo    标准加密、垃圾邮件拦截    中等    支持    一般    个人、家庭<br/>ProtonMail    Proton AG    全面端到端加密    一般    不支持    一般    隐私重视者</p><h2>二、选择国际邮箱的关键因素</h2><h2>安全性与隐私保护</h2><p>对于企业级与个人用户，邮箱的安全性一直是首要考虑。比如Gmail、Outlook均采用高标准身份验证与数据加密，ProtonMail则以极端隐私保护著称，银企用户会优先关注反垃圾、信息隔离与加密能力。而以Zoho邮箱为代表的新一代国际邮箱，采用多重安全机制结合人工智能过滤技术，既能阻挡垃圾邮件又能确保敏感信息不外泄，更适合对数据安全要求极高的企业客户。</p><h2>功能丰富性与易用性</h2><p>国际主流邮箱无不强调插件、协作与移动端支持能力：Outlook因与Office套件的整合成为办公领域的宠儿；Gmail因智能分箱和扩展插件备受个人及创意型企业青睐；而Zoho邮箱则支持企业级别的域管理、灵活应用扩展以及团队协作，是当下最具成长力的メール解决方案。</p><h2>服务稳定性与可靠性</h2><p>除安全外，服务后台的稳定与可靠性也是评判一款国际邮箱优劣的重要标准。Gmail和Outlook依托全球化服务器，实现全年全天候高可用；Zoho邮箱亦实现了多节点冗余备份，业务不中断，保障邮件流通流程万无一失。</p><h2>价格与性价比</h2><p>多数国际邮箱均提供个人免费版与企业收费版。Zoho邮箱以高性价比著称，灵活的套餐体系让新创及中小企业低成本获取国际化协作工具，且支持快速开通域名邮箱，注册门槛极低。Gmail、Outlook虽然整体成熟，但企业版定价及定制灵活度略逊一筹。ProtonMail则以付费换取极致隐私，目标人群更加聚焦。</p><h2>三、常见问题及解答</h2><h2>如何选择适合自己的国际邮箱？</h2><p>需结合用户自身需求和预算。高度重视数据主权和管理灵活性的企业用户，推荐优先选择拥有完善注册步骤和批量域名邮箱管理能力的Zoho邮箱。个人用户可以根据日常互动和功能扩展偏好选择Gmail、Yahoo Mail；如果对办公生态整合有高要求，则Outlook更适合。</p><h2>不同邮箱的安全性有哪些差异？</h2><p>Gmail、Outlook的安全机制成熟，适合大多数商务与个人用户。Zoho邮箱采用业内领先的数据隔离及多重防护技术，能有效防止信息泄露。ProtonMail则是端到端加密的极致典范，适合注重隐私的用户群体。</p><h2>如何确保邮箱的长期稳定使用？</h2><p>定期更换密码、启用双重认证，避免在公共网络中频繁登录，首选具备冗余备份和全球服务器资源的国际邮箱平台。企业用户建议每年评估邮箱账号权限和员工离职后的信息管理，与IT管理团队协同维护。</p><h2>结尾总结</h2><p>综上，Gmail、Outlook、Zoho邮箱、Yahoo Mail和ProtonMail是2025年国际上用户最为认可和使用广泛的五大主流邮箱。企业级用户尤为看重邮箱的安全性、扩展性和高性价比，而Zoho邮箱凭借域名邮箱、简单便捷的注册步骤，以及在全球1800万企业级客户中的口碑，证明了其领先地位。不论是个人还是企业，不同需求都能在上述五款国际邮箱中找到最优选项。</p>]]></description></item><item>    <title><![CDATA[2025 年最佳 SEO 学习路线和书籍]]></title>    <link>https://segmentfault.com/a/1190000047401615</link>    <guid>https://segmentfault.com/a/1190000047401615</guid>    <pubDate>2025-11-15 14:03:16</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>你是不是也收藏了一堆 “SEO圣经”、“终极指南”，但再也没打开过？<br/>别搞花里胡哨的，就三步走，踏踏实实学完就能用</p><p>原文：<a href="https://link.segmentfault.com/?enc=c5xHbxoRXvdgdhxRwSX2Kw%3D%3D.qXraPcHzPwgU6yAna%2FIAmVaG14wqkemWgtA3qMfYLo5ScVEhYuRd2y0A9cnTkCOl" rel="nofollow" target="_blank">https://bysocket.com/best-seo-books-in-2025/</a></p><p>先自荐下，我在开源写的《SEO for AI Website · User Growth Playbook 》、</p><p><a href="https://link.segmentfault.com/?enc=Nj4AKMYeujxyp%2Ff14tprKg%3D%3D.nFQVVOvR3QuB6ZV%2FUlBGk3jGVfR%2BZ%2BS6fBcnrMcPsVsj9ceC6iIM8usMu%2BYksZXgWynq%2BdewKK3D91FE1aJbMg%3D%3D" rel="nofollow" target="_blank">https://usdunlunl.feishu.cn/sync/L19ydnVSKs23HFbN7NMcWBChn2o</a></p><h2>第一步：从零开始，把基础打牢</h2><h3>Ahrefs 的免费 SEO 基础教程（有中文版）</h3><p><a href="https://link.segmentfault.com/?enc=7yaO%2BmhXttqk5dlrfKP5Cw%3D%3D.cqJrs9BXzdjq0gxpiCyV%2F0fIcZQQBZa0ui0idN2QQqc%3D" rel="nofollow" target="_blank">https://ahrefs.com/zh/seo</a></p><p>就像学做菜先认调料和厨具一样，学 SEO 你得先知道最基本的概念都是啥。这套教程就像个耐心的老师，从什么是搜索引擎开始，一点点把你教明白，帮你建立起完整的知识框架<br/>把这份教程从头到尾看一遍，不用死记硬背，理解最重要</p><h2>第二步：动手干，别自己瞎搞</h2><h3>Google搜索官方文档（有中文版）</h3><p><a href="https://link.segmentfault.com/?enc=NzcvK9qhn7qwjacG1ZKgxA%3D%3D.coH5AjSSOdaX%2Be0o8PBG3iyOxN9rCumhY0NZipp3ftjtJahldKZT5t0E6WoDPwmyHyI0HwTOZ9oDbSdn16v%2B1g%3D%3D" rel="nofollow" target="_blank">https://developers.google.com/search/docs?hl=zh-cn</a></p><p>该上手了。但最怕的就是你自己瞎琢磨，方向错了全白搭。这时候，你就得把 Google 的官方文档当成程序猿的 “API 文档”。<br/>比如，你想优化网页标题，不知道怎么写好，就去文档里查 “title” 该怎么做。它说啥，你就照着做，这是最不会出错的方法。</p><p>上手记住这个顺序：</p><ul><li>先挖词儿： 想想用户会搜什么关键词来找你的内容</li><li>再想内容： 用户搜这个词，真正想看的是什么？你的内容能提供什么别人没有的价值？</li><li>写和优化： 规划好内容结构，然后写好标题、正文，把网站内部链接整理好</li></ul><p>以上都做完了，再去搞外链： 找别的网站来推荐你</p><h2>第三步：持续升级，跟上潮流</h2><p>几个行业里公认的牛逼博客</p><h3>Ahrefs Blog</h3><p><a href="https://link.segmentfault.com/?enc=Q0xqxsNDEJvKlewcM4c%2Bdw%3D%3D.uczzExhWPJFCHoH7eJy9db222gEqdapHsX3T3Ho1eKk%3D" rel="nofollow" target="_blank">https://ahrefs.com/blog/</a></p><h3>Semrush Blog</h3><p><a href="https://link.segmentfault.com/?enc=GS2FD9ElU%2FHiPnTSe5bZPg%3D%3D.RvNHIknEdELIGPmJRKlzH9uolsgWL6ipqfoVLGblDSU%3D" rel="nofollow" target="_blank">https://www.semrush.com/blog/</a></p><h3>Search Engine Land</h3><p><a href="https://link.segmentfault.com/?enc=8AWzDEEUJFr94VSMdwk5bg%3D%3D.uv%2F7X6AFdJImBex8BqpKUh9ZrqyEC1Xcf1CgF9NHW4w%3D" rel="nofollow" target="_blank">https://searchengineland.com/</a></p><p>SEO 在 AI 时代总是在变，你得持续学习。这几个博客就像是行业老炮儿的聚集地，他们经常分享最新的案例、技巧和行业动态。<br/>不用天天看，每周抽点时间逛逛，看看有什么新东西</p><p>看，就三步：用 Ahrefs 打基础  → 干活时查 Google 官方说明书 → 看大佬博客保持进步</p><h2>四、最后想找人交流？关注这些人</h2><h3>中文圈（主要聊出海）</h3><p>哥飞（@gefei55）<br/><a href="https://link.segmentfault.com/?enc=v9rWa8Qk2r1AuTwUajAkkQ%3D%3D.u7ubC3IwQ%2BxaKKuBBUSNQELpdnsVriGwrLl6r79082I%3D" rel="nofollow" target="_blank">https://x.com/gefei55</a></p><p>大罗SEO（@daluoseo）<br/><a href="https://link.segmentfault.com/?enc=vYFvsLiTg%2Fe4x2lQ68bagw%3D%3D.Yj1qUmrVSm%2Bkb7zlCzCHvNDOI9fiHIFM5jaKmSWyjTo%3D" rel="nofollow" target="_blank">https://x.com/daluoseo</a></p><h3>国际大神： 国外高手，可以看看他们都在聊啥</h3><p>Lily Ray（@lilyraynyc）<br/><a href="https://link.segmentfault.com/?enc=6GHyzU0jDyPnD8QMF%2BSo5A%3D%3D.qGqXZVV63X3bWuLWpf4NRhnZFmXrx8XLgmyre3uteEU%3D" rel="nofollow" target="_blank">https://x.com/lilyraynyc</a></p><p>Glenn Gabe（@glenngabe）<br/><a href="https://link.segmentfault.com/?enc=3ikLMqIL6P61bnuDOux7eg%3D%3D.RxlXTBjd9JC77XtnOPiPAqvfsl7L1nOa8DlGhlF6hIQ%3D" rel="nofollow" target="_blank">https://x.com/glenngabe</a></p><p>Brodie Clark（@brodieseo）<br/><a href="https://link.segmentfault.com/?enc=twOuU%2BmJ%2FhGRCImiXxIVkA%3D%3D.XxWDaXVZYbIcdpO0uS2N1feQQkFP3xy0Fh0%2FWqZy30M%3D" rel="nofollow" target="_blank">https://x.com/brodieseo</a></p><p>Marie Haynes（@Marie_Haynes）<br/><a href="https://link.segmentfault.com/?enc=KIoAQzPOQ0GNoErbnSp6%2Fw%3D%3D.N6fcL3hCDS%2BiYE%2B%2F0X%2FD8h7GB9tCTf%2F3SuyGc4XPC1w%3D" rel="nofollow" target="_blank">https://x.com/Marie_Haynes</a></p><p>Barry Schwartz（@rustybrick）<br/><a href="https://link.segmentfault.com/?enc=AgeiFULX8ZVeIdEmFzFqlg%3D%3D.YyjYxcPvwmBeldiZUKV5%2BILdq%2Fr2XJswuCFej%2FjmuF8%3D" rel="nofollow" target="_blank">https://x.com/rustybrick</a></p><p>Aleyda Solís（@aleyda）<br/><a href="https://link.segmentfault.com/?enc=cIiIMHu%2Bz%2B%2B%2FNBJpsglzVQ%3D%3D.7EPG8BnYO4K%2BN9rYoqRwoD7zPdwhbEfR7R2GGRaXLXk%3D" rel="nofollow" target="_blank">https://x.com/aleyda</a></p><p>Kevin Indig（@Kevin_Indig）<br/><a href="https://link.segmentfault.com/?enc=Zh4cbdjqq9h4S7JYIi%2BJ5A%3D%3D.Jm5K2OENZDjEs29sscqsIb1j3VPQmHhnSrAvovBvlc4%3D" rel="nofollow" target="_blank">https://x.com/Kevin_Indig</a></p><p>Cyrus Shepard（@CyrusShepard）<br/><a href="https://link.segmentfault.com/?enc=ZcmaGo7TQnCCPHEtf1bGTg%3D%3D.CGR8V076uaF5d%2BcVx88RBe1%2Fy54emECUCJhiEqLFDyg%3D" rel="nofollow" target="_blank">https://x.com/CyrusShepard</a></p><p>Patrick Stox（@patrickstox）<br/><a href="https://link.segmentfault.com/?enc=CEbmuxmc00O%2Fu1y7nzRhgQ%3D%3D.JYfhxaKMBAO2TzVUVyjLUKs7tZHQAGrzfa346u5WrYU%3D" rel="nofollow" target="_blank">https://x.com/patrickstox</a></p><p>Rand Fishkin（@randfish）<br/><a href="https://link.segmentfault.com/?enc=ThVMlWrdz94GjByLlWFRLA%3D%3D.nmjF9C9zi9eiXzL3ESoNjXqE4NAB8gKwfXRobvs%2BOh8%3D" rel="nofollow" target="_blank">https://x.com/randfish</a></p><p>Google Search Central（X）<br/><a href="https://link.segmentfault.com/?enc=80wUnrl6GYzC1%2FIdOSmcUA%3D%3D.EyXMctwJuopK4YsHSD9a6OKQM0Ku74%2BVIYR1a5smnl8%3D" rel="nofollow" target="_blank">https://x.com/googlesearchc</a></p><p>官方 YouTube 频道<br/><a href="https://link.segmentfault.com/?enc=TsvZKuhoM8bUOUzzSbRrTA%3D%3D.h8pyq8l1KpV3yt5mxP50LkJqIN52fncC1oV9NWKIbgdX1hCt3JudJFG%2FRLl9SzLQ" rel="nofollow" target="_blank">https://www.youtube.com/@GoogleSearchCentral</a></p><p>大会，目前只参加过深圳 SEO 大会（官网）<br/><a href="https://link.segmentfault.com/?enc=3%2FYEk81SZ%2FOjPbh70t0Pvw%3D%3D.vuy7G%2Fn8mNOr2Skmb7rzhvA6BJW1ll0gI%2B%2Fhmbn53pBKhK99iSJld7ePQxDFH7Eu" rel="nofollow" target="_blank">https://shenzhenseoconference.com/</a></p><p>资源也都是长期更新的，不会让你学完就过时<br/>一步步来，几个月后你就能摸到门道了</p>]]></description></item><item>    <title><![CDATA[实战教程：手把手教你用Sora2 API]]></title>    <link>https://segmentfault.com/a/1190000047401623</link>    <guid>https://segmentfault.com/a/1190000047401623</guid>    <pubDate>2025-11-15 14:02:46</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>📖 实战教程：手把手教你用Sora2 API生成10分钟一致性视频<br/>理论说了一千遍，不如亲手运行一遍。本文将带你从零开始，完成一次完整的“视频续写”操作。</p><p>在上一篇文章《Sora2重磅升级：视频续写可达10分钟，角色场景一致性迎来突破！》中，我们介绍了Sora2视频续写的核心价值。本文将成为其<strong>实战篇</strong>，详细讲解如何调用速创API，一步步实现视频的延续创作。</p><p>一、准备工作</p><ol><li>获取API密钥<br/>访问速创API平台，注册账号并登录。在控制台的「密钥管理」中，你将获得唯一的 key，这是你调用所有API的凭证。</li><li>理解核心流程<br/>视频续写遵循一个清晰的“<strong>首轮生成 → 获取PID → 续写请求</strong>”流程。下图清晰地展示了这一过程：</li></ol><p>flowchart LR</p><pre><code>A[第一步</code></pre><p>提交初始生成请求] --&gt;|返回原视频PID| B[第二步<br/>使用remixTargetId续写]</p><pre><code>B --&gt; C{续写完成？}
C --&gt;|是| D[获得一致性续写视频]
C --&gt;|否| E[排查参数与网络]</code></pre><p>二、步骤详解：从零生成你的第一个视频续作<br/>我们将通过一次真实的API调用来演示。</p><p>步骤 1：生成初始视频<br/>首先，我们需要一个作为“种子”的原始视频。这里我们生成一段“一个大哥穿着鞋子登雪山，鞋子特写”的视频。<br/><img width="723" height="332" referrerpolicy="no-referrer" src="/img/bVdm3uq" alt="" title=""/><br/>请求示例：</p><p>curl -X POST "https://api.wuyinkeji.com/api/sora2/submit" \<br/>-H "Authorization: duYwo59iXS4b3mHoeuXpinIXSdz" \<br/>-H "Content-Type: application/x-www-form-urlencoded;charset:utf-8;" \<br/>-d "prompt=一个大程序键子重置，鞋子补写&amp;url=<a href="https://link.segmentfault.com/?enc=2OPV7Repqi%2BFZfi%2Fh3cyXw%3D%3D.50VqAZYnKYAGTgqLZD39UCyCeQcHpFsb5uEVJ0JEffgxldZ8kZgE6C7rSCmteNrcBjdpm8rizO1x%2FcGpE7M2G%2BM8EeqQY4mtS7YOQ%2FIlvzjrHt31nwiGeLZns3J%2FdLdnCmhLaPVhwB83bog9IMNuLw%3D%3D" rel="nofollow" target="_blank">https://openpt1.oss-cn-shanghai.aliyuncs.com/?d9d0e5a60074&amp;as...</a>l"<br/>关键响应：</p><p>{<br/>  "code": 200,<br/>  "msg": "成功",<br/>  "data": {</p><pre><code>"content": "一个大哥穿着鞋子登雪山，鞋子特写",
"status": 1,
"remote_url": "https://openptl.oss-cn-shanghai.aliyuncs.com/dcb30910e8d34628b97c310a2ea6ca19.mp4",
"pid": "s_6917df60la3c8191819b64e55b5771ff", // ！务必保存这个PID
"id": "287a512a-elcf-44da-b073-49ab3385aabe"</code></pre><p>}<br/>}<br/>请务必妥善保存响应数据中的 pid 值**，它是我们进行视频续写的唯一依据。</p><p>步骤 2：进行视频续写（核心）<br/>现在，我们假设想让这位大哥“继续穿着鞋子爬上火山”。这时，就需要使用上一步获取的 pid 作为 remixTargetId 参数。<br/><img width="723" height="398" referrerpolicy="no-referrer" src="/img/bVdm3ur" alt="" title="" loading="lazy"/><br/>请求示例：</p><p>curl -X POST "https://api.wuyinkeji.com/api/sora2/submit" \<br/>-H "Authorization: duYwo59iXS4b3mHoeuXpinIXSdz" \<br/>-H "Content-Type: application/x-www-form-urlencoded;charset:utf-8;" \<br/>-d "prompt=大哥继续穿着鞋子爬上火山，鞋子特写&amp;remixTargetId=s_6917df60la3c8191819b64e55b5771ff&amp;aspectRatio=9:16&amp;duration=15&amp;size=small"<br/>成功响应：</p><p>{<br/>  "code": 200,<br/>  "msg": "成功",<br/>  "data": {</p><pre><code>"content": "大哥继续穿着鞋子爬上火山，鞋子特写",
"status": 1,
"pid": "s_6917e64333748191b491a8c7e2302772",
"remixTargetId": "s_6917df60la3c8191819b64e55b5771ff", // 指向了原始视频的PID
"remote_url": "https://openptl.css-cn-shanghai.aliyuncs.com/554cc6748f79434fb69794aab3e4bfd2.mp4"</code></pre><p>}<br/>}<br/>响应中的 remixTargetId 字段确认了本次生成是基于哪个原始视频进行的续写。新生成的视频 (s_6917e64333...) 在人物、画风和鞋子的特写上，都会与原始视频 (s_6917df60la...) 保持高度一致。</p><p>三、关键技巧与避坑指南</p><ol><li>Prompt 描述技巧：<br/>一致性：续写时，对角色、服装、核心物体的描述应与原提示词保持一致。<br/>连贯性：场景变化要自然，如“登雪山”后“爬火山”是合理的运动场景切换，而不是突然跳到“在办公室喝咖啡”。</li><li>参数误区：<br/>remixTargetId 是<strong>视频PID</strong>，不是任务ID id，别搞混了。<br/>url 参数是<strong>参考图片</strong>，用于辅助定义风格，与 remixTargetId 是两种不同的控制方式，续写时通常不需要重复传入。</li><li>任务状态查询：<br/>提交任务后，若未立即返回视频链接，可通过返回的 id 调用「任务状态查询接口」轮询结果，直到 status 变为 1（成功）或 2（失败）。</li></ol><p>四、结语与展望<br/>通过以上两个步骤，你就可以轻松实现高质量的视频续写。这种“滚雪球”式的生成能力，为<strong>AI短剧、互动剧情、产品长视频</strong>等需要高度一致性的场景提供了强大的技术基础。</p><p>随着 veo3.1-pro、Runway aleph 等更强模型的接入，未来我们甚至可以期待实现<strong>分镜级控制</strong>的長視頻生成。</p><p>🔗 相关资源：<a href="https://link.segmentfault.com/?enc=QI%2F3bS6Ma6l7ISj8E9JWjg%3D%3D.zq9RhWQyApT93KNInZLn%2BF9%2B%2F55zliveiahzPzP3wfs%3D" rel="nofollow" target="_blank">速创API</a></p>]]></description></item><item>    <title><![CDATA[番茄叶片病害检测数据集（千张图片已划分）]]></title>    <link>https://segmentfault.com/a/1190000047401646</link>    <guid>https://segmentfault.com/a/1190000047401646</guid>    <pubDate>2025-11-15 14:02:09</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>番茄叶片病害检测数据集（千张图片已划分）| AI训练适用于目标检测任务</h2><h2>概述</h2><p>在农业领域，植物病害检测是确保作物健康和提高农业生产效率的关键任务之一。随着计算机视觉技术的快速发展，基于深度学习的目标检测方法成为了病害识别的主流手段。为此，专门针对番茄叶片病害检测任务，我们推出了一个经过精心设计的番茄叶片病害检测数据集。该数据集包含了10,853张带标签的图像，覆盖了10种常见的番茄叶片病害类型，支持YOLO等先进的目标检测模型训练，旨在帮助研究人员和开发者提高农作物病害自动化检测的能力。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047401648" alt="在这里插入图片描述" title="在这里插入图片描述"/></p><h3>数据集获取</h3><blockquote>链接:<a href="https://link.segmentfault.com/?enc=dDCUI1tyKq7ZnTaz3WnY%2Fw%3D%3D.CYaJxrE2NvNPOh3aOuOye4VlnTEZ5Sia7rzsF2MUL8EYoAaqecFJoKNXf%2FYJMSRb2CMJ09QNq%2FQfrBp6o4sTZg%3D%3D" rel="nofollow" target="_blank">https://pan.baidu.com/s/196FdQ7RhzgulM0j4-dW0ng?pwd=v59n</a> <br/>提取码:v59n 复制这段内容后打开百度网盘手机App，操作更方便哦</blockquote><p>该数据集专为使用YOLOv8进行番茄叶片病害检测而设计。它包含10,853 张带标签的图像，涵盖10 种不同类型的番茄叶片状况，包括病毒、细菌和真菌感染，以及健康叶片。</p><p>数据集详细信息<br/>图片总数：10,853<br/>训练集：7,842 张图片（72%）<br/>验证集：1,960 张图像（18%）<br/>测试集：1,051 张图片（10%）<br/>图像分辨率：调整为640x640（拉伸）<br/>注释格式：YOLO<br/>类别（10 个类别）<br/>番茄细菌性斑点病<br/>番茄早疫病<br/>番茄晚疫病<br/>番茄叶霉<br/>番茄叶斑病<br/>番茄红蜘蛛（二斑叶螨）<br/>番茄目标点<br/>番茄黄化卷叶病毒<br/>番茄健康<br/>番茄花叶病毒</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047401649" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h3>背景</h3><p>随着全球气候变化的加剧，农业病害的发生变得越来越复杂和难以预测，尤其是针对番茄等重要农作物。番茄叶片病害不仅影响作物的生长发育，还可能导致产量的大幅下降。因此，如何快速、准确地诊断病害，成为了农业科技研究中的重要课题。</p><p>传统的病害识别方法依赖于农业专家的经验和人工检查，但这一过程不仅耗时且容易出错。随着计算机视觉技术的发展，AI技术特别是深度学习方法在植物病害检测中的应用日益增多，能够大大提高检测效率和准确率。此时，良好的数据集便成为训练高效AI模型的基础。</p><h3>数据集详细信息</h3><p>数据集共包含10,853张高质量的图像，这些图像经过严格筛选，确保标注的准确性。图像涵盖了番茄植物的多个生长阶段及不同类型的病害，具有极高的代表性，适合用于AI模型训练和验证。</p><h4>数据集划分</h4><p>为了支持不同阶段的训练和验证，我们对数据集进行了合理的划分：</p><ul><li><strong>训练集</strong>：7,842张图片，占数据集的72%</li><li><strong>验证集</strong>：1,960张图片，占数据集的18%</li><li><strong>测试集</strong>：1,051张图片，占数据集的10%</li></ul><p>这种划分方式保证了训练模型时数据的多样性，同时能够有效评估模型在未知数据上的表现。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047401650" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><p>图像分辨率</p><p>所有图像的分辨率已调整为640x640，便于YOLOv8等深度学习模型的输入。为了保持图像的质量和细节，我们采用了拉伸的方法来调整图像的尺寸，以便适应不同的计算资源需求。</p><p>注释格式</p><p>该数据集采用了YOLO格式的注释，适配YOLOv8等常用目标检测框架。每张图像都包含多个标签和对应的边界框，这些标签详细描述了图像中的病害类型和位置。</p><p>类别（10个类别）</p><p>本数据集包含了10种不同类型的番茄叶片病害，涵盖了病毒、细菌、真菌感染等多种病害类型。这些类别包括：</p><ol><li><strong>番茄细菌性斑点病</strong></li><li><strong>番茄早疫病</strong></li><li><strong>番茄晚疫病</strong></li><li><strong>番茄叶霉</strong></li><li><strong>番茄叶斑病</strong></li><li><strong>番茄红蜘蛛（二斑叶螨）</strong></li><li><strong>番茄目标点</strong></li><li><strong>番茄黄化卷叶病毒</strong></li><li><strong>番茄健康</strong></li><li><strong>番茄花叶病毒</strong></li></ol><p>每个类别都代表了番茄植物可能遭遇的不同类型病害，能够帮助研究人员精确识别番茄叶片的健康状况及其病变类型。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047401651" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h3>数据集概述</h3><p>这个番茄叶片病害检测数据集专门为基于YOLOv8的目标检测任务而设计，涵盖了从健康到多种病害的图像样本。每张图像都包含了详细的标注信息，支持YOLOv8模型对叶片病害进行准确定位和分类。数据集的设计考虑到了病害的多样性和复杂性，包含了不同光照、角度和背景下的番茄叶片图像，旨在增强模型的泛化能力。</p><p>通过使用这个数据集，开发者可以训练出具备较高准确度的AI模型，自动识别并分类番茄叶片的病害类型，从而为农业病害管理提供有力支持。</p><h3>数据集详情</h3><ol><li><strong>数据集来源</strong>：所有图像均来自真实的农业种植环境，确保数据的真实性和实用性。</li><li><strong>数据质量</strong>：图像清晰，细节丰富，病害部位标注准确，为目标检测模型提供了高质量的训练样本。</li><li><strong>多样性</strong>：数据集包含了各种不同环境下拍摄的图像，能够有效增强模型的适应性。</li><li><strong>标签系统</strong>：每个图像都经过人工标注，包含了精确的边界框和对应的病害类型标签，符合YOLOv8的输入要求。</li></ol><h3>适用场景</h3><p>该数据集主要适用于以下几个场景：</p><ol><li><strong>病害自动化检测</strong>：帮助农业从业者通过AI技术自动识别番茄叶片的健康状况及病害类型。</li><li><strong>农作物健康监控</strong>：利用训练好的AI模型，实时监控番茄种植区域的病害状况，提前预警病害传播。</li><li><strong>精准农业</strong>：为精准农业提供数据支持，实现高效、节能、低污染的病害防治。</li><li><strong>科研支持</strong>：为农业科研提供宝贵的病害检测数据，推动相关领域的技术研究和发展。</li></ol><h3>目标检测</h3><p>YOLOv8作为当前目标检测领域最先进的深度学习模型之一，具有优异的检测性能和高效的推理速度，尤其适合应用于资源有限的农业领域。利用YOLOv8模型对番茄叶片病害进行检测，能够实现高精度、高速度的病害定位与分类。</p><p>该数据集经过精心设计，符合YOLOv8的训练要求，帮助用户快速部署和训练出具备高效病害识别能力的AI模型。借助YOLOv8的优势，可以实现以下目标：</p><ol><li><strong>高精度病害检测</strong>：通过YOLOv8对图像中的病害进行精准定位和分类，有效提高农作物病害的诊断准确性。</li><li><strong>实时病害预警</strong>：基于YOLOv8的高效推理速度，能够在农业生产过程中实时监控并发现潜在病害问题。</li><li><strong>大规模应用</strong>：借助YOLOv8的高效性能，能够应对大规模农田监控任务，为大面积的番茄种植区提供智能化支持。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047401652" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047401653" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></li></ol><h3>结语</h3><p>随着人工智能技术在农业领域的深入应用，番茄叶片病害检测数据集为AI模型的训练和研究提供了宝贵的资源。通过本数据集，研究人员和开发者可以利用YOLOv8等先进的目标检测算法，快速构建高效的病害检测系统，推动农业科技的发展。</p><p>无论是农业病害的实时监控，还是精准农业的实施，本数据集都能够为实际应用提供强大的技术支持。未来，随着AI技术的不断进步和数据集的不断更新，我们有理由相信，农业病害检测将变得更加智能化、高效化，为全球农业发展带来深远影响。</p>]]></description></item><item>    <title><![CDATA[Ollama本地电脑运行无限制AI模型超]]></title>    <link>https://segmentfault.com/a/1190000047401661</link>    <guid>https://segmentfault.com/a/1190000047401661</guid>    <pubDate>2025-11-15 14:01:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>想在本地用一款 “无拘无束” 的 AI 模型？Ollama 能帮你轻松实现，但先得说清楚：这类 “越狱模型” 虽自由，却可能藏着不少小麻烦。</p><h2>一、手把手装 Abliterated 无限制模型</h2><h3>1. 先搭好 Ollama 基础</h3><p>不管用什么系统，先把 Ollama 装上 —— 它是本地跑模型的 “底座”，操作很简单：</p><ul><li><strong>Windows/macOS</strong>：去<a href="https://link.segmentfault.com/?enc=xJPHO9dUAPYRIt2PCuyRtQ%3D%3D.I%2F1Uf7D3Hcc5mm2O0kqFBVYGn5MyZR48yVEKfF1%2FhZY%3D" rel="nofollow" target="_blank">Ollama 官网</a>下载对应安装包，双击后一路 “下一步” 即可（Windows 用户记得按提示开启 WSL2，跟着引导点几下就行）。</li><li><p><strong>Linux</strong>：打开终端，复制粘贴这行命令，回车后自动完成安装：</p><p>bash</p><pre><code>curl -fsSL https://ollama.com/install.sh | sh</code></pre></li></ul><h3>2. 找模型、跑模型，两步到位</h3><p>Ollama 自带模型市场，搜 “无限制” 相关模型很方便：</p><ol><li>打开模型市场，搜关键词 <strong>abliterated</strong>：<a href="https://link.segmentfault.com/?enc=2w98a7NBKjVt9a71YyXT5g%3D%3D.UryiaCKCmyNQHc%2Ff3fAmYkcsVhsex72h4Dlr1aM689Jk6I6w9NBiKD9kL8QXdZB2" rel="nofollow" target="_blank">https://ollama.com/search?q=abliterated</a>；</li><li>选一个看起来靠谱的（比如 <code>huihui_ai/gemma3-abliterated</code>）。这里特别提一下，huihui_ai这位大佬团队改造的模型还挺多，他们专注于无限制模型改造，不仅在 Ollama 平台（链接：<a href="https://link.segmentfault.com/?enc=qOC5%2FpDNV0Zma%2BmzyFR3Rg%3D%3D.JFnTe%2FoHr1t3V7mlu1bPbY2%2BDP9tbHIEsRoWAOOWITF7joKOq6zKEfP37UsD2M8ALLDzt2If87PyZqTrHxGAOJsa73qaEOy46NyeF8Z75wNLM59sznKjJirNDXm0w8qP2%2B%2BmGx1TtTPjtGP4QWItf8%2FcN6muwOeT%2BLBMyRuulZlHbvqlipeiwcFA8ZijdHv3" rel="nofollow" target="_blank">https://ollama.com/huihui_ai）上线了大量模型，在HuggingFace社...</a>）。</li><li><p>选好模型后，在终端里输命令启动：</p><p>bash</p><pre><code>ollama run huihui_ai/gemma3-abliterated</code></pre></li><li>首次运行会自动下载模型（稍等几分钟，大小看模型参数），完成后直接进入对话界面 —— 全程本地运行，没有内容过滤限制。</li></ol><h2>二、得知道：Abliterated 模型是啥？为啥容易 “抽风”？</h2><p>Abliterated 直译是 “被移除限制的”，说白了就是给原生模型（比如 Llama、Mistral）“越狱”：把官方加的内容过滤机制（比如防暴力、防违法的限制）给删掉了。</p><p>但问题出在 “怎么删” 上：市面上大多这类模型是网友自行修改的，而非专业团队优化。原生模型的 “内容限制” 和 “核心逻辑”（比如语义理解、逻辑推理）其实是深度绑定的 —— 就像手机的 “安全锁” 和 “主板” 焊在一起，非专业拆解很容易拆坏核心部件。</p><p>结果就是：删限制时可能误删了模型的逻辑模块，导致回答颠三倒四、胡言乱语，甚至简单问题都答不对（比如算错 1+1）。Ollama 市场里不少 Abliterated 模型都有这毛病，经常 “抽风” 输出残缺或混乱的内容。</p><h2>三、法律风险：用无限制模型的两大风险</h2><ol><li><strong>法律与责任风险</strong>没了内容过滤，不代表能 “为所欲为”。生成违法、侵权、造谣内容，照样要承担法律责任 —— 各国对 AI 生成内容都有明确监管，别踩红线。</li><li><strong>模型质量风险</strong>如前面所说，非专业修改可能让模型 “变笨”，输出错误信息（比如搞错常识、逻辑抽风）。如果用它处理重要任务（比如写方案、做分析），很容易掉坑里。</li></ol><h2>四、拓展：Ollama 还能跑其他平台的模型</h2><p>除了 Ollama 市场，Hugging Face 等平台的模型也能导入：</p><ol><li>下载模型文件（带 <code>.bin</code>/<code>.pth</code> 后缀的权重文件）；</li><li><p>本地新建文件夹（比如 “my-model”），放入模型文件，再创建一个无后缀的 <code>Modelfile</code>，写入配置（示例）：</p><p>plaintext</p><pre><code>FROM ./my-model  # 指向模型文件路径
PARAMETER temperature 0.7  # 可自定义参数</code></pre></li><li>终端进入文件夹，输 <code>ollama create 模型名 -f Modelfile</code> 导入，之后用 <code>ollama run 模型名</code> 启动即可。</li></ol><h2>最后提醒</h2><p>如果只是想体验 “无限制”，尽量挑下载量高、评价好的模型如果要正经用，优先选官方模型 —— 虽然有约束，但至少 “聪明” 且可靠。毕竟，AI 的 “自由” 和 “好用”，往往得选一个。</p>]]></description></item><item>    <title><![CDATA[飞牛 Nas 部署 Docker Ngi]]></title>    <link>https://segmentfault.com/a/1190000047401608</link>    <guid>https://segmentfault.com/a/1190000047401608</guid>    <pubDate>2025-11-15 13:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>使用 Docker Compose 方式部署</p><p>在 /vol2/1000/docker-data/nginx/ 目录下，创建 nginx.conf</p><pre><code>worker_processes  1;
events {
    worker_connections  1024;
}
http {
    include       /etc/nginx/mime.types;
    server {
      listen       80;
      server_name  localhost;
      location / {
        root   /usr/share/nginx/html;
        index  index.html index.htm;
      }
    }
    access_log /var/log/nginx/access.log;
    error_log /var/log/nginx/error.log;
}</code></pre><pre><code class="yaml">version: '3'
services:
  nginx:
    restart: always
    container_name: nginx
    image: nginx
    ports:
      - 5555:80
      - 443:443
    volumes:
      - /vol2/1000/docker-data/nginx/html:/usr/share/nginx/html
      - /vol2/1000/docker-data/nginx/www:/var/www
      - /vol2/1000/docker-data/nginx/logs:/var/log/nginx
      - /vol2/1000/docker-data/nginx/nginx.conf/:/etc/nginx/nginx.conf
      - /vol2/1000/docker-data/nginx/etc/cert:/etc/nginx/cert
      - /vol2/1000/docker-data/nginx/conf.d:/etc/nginx/conf.d
    environment:
      - NGINX_PORT=80
      - TZ=Asia/Shanghai
    privileged: true</code></pre><p>执行以下命令，让其有权限</p><pre><code class="shell">chmod -R 777 /vol2/1000/docker-data/nginx/html/</code></pre>]]></description></item><item>    <title><![CDATA[住宅代理 vs 数据中心代理：核心技术差]]></title>    <link>https://segmentfault.com/a/1190000047401471</link>    <guid>https://segmentfault.com/a/1190000047401471</guid>    <pubDate>2025-11-15 12:04:41</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在企业网络业务中，住宅代理与数据中心代理是最常见的两类代理类型。它们都能提供替代 IP，但其底层技术结构、被风控识别的概率、速度表现、稳定性和使用场景却完全不同。<br/> 很多企业在选型时只看到价格差异，忽略了技术特征，从而在后期遇到封号、访问异常、成功率下降等问题。本文将从技术角度深入解析住宅代理与数据中心代理的本质差异，帮助企业正确选择适合自己的代理类型。</p><h2>一、IP 来源本质不同：决定两者“身份”的根本差异</h2><p>住宅代理的 IP 是由家庭宽带运营商分配，也就是说，它们来自真实用户的网络环境。<br/> 而数据中心代理的 IP 则来自各类机房、云服务器提供商，如 AWS、GCP、阿里云等。这些 IP 在大多数平台的识别系统里默认属于“服务器流量”，而非真实用户节点。也正是这一点，使得数据中心代理更容易被认定为非自然访问，而住宅代理的访问行为更符合普通用户特征。</p><h2>二、风控识别倾向：两个类型的“天然标签”不同</h2><p>在现代风控系统中，IP 类型只是判断的第一步。平台还会结合 ASN、访问行为、频率、DNS 查询模式、历史行为等综合识别。<br/>数据中心代理由于来自机房，具备以下典型特征：<br/>●IP 密集在同一网段，来源集中<br/>●经常被用于爬虫或批量访问<br/>●高频率请求特征明显</p><p>因此平台往往对其风险等级评估较高，很容易触发验证码、限制登录、访问被拒绝等情况。<br/>相比之下，住宅代理来自家庭网络，数量分散、来源自然，在平台风控模型中属于低风险类别，访问更稳定、更少被拦截。</p><h2>三、网络性能差异明显：速度和稳定性的取舍</h2><p>从硬件和网络环境来看，数据中心代理的速度通常远高于住宅代理。机房带宽往往以 Gbps 计，适合大量并发、大批量请求、低延迟任务。<br/>住宅代理由于依赖真实家庭网络，速度取决于具体用户的宽带情况，并且 IP 节点不固定，稳定性偶尔会受影响。<br/> 尽管如此，在许多企业级场景中，稳定的“用户级行为”比高速访问更重要，因为风控容错度更高。企业需要在速度和隐蔽性之间做选择，如果访问目标平台风控强，速度优势往往无法弥补识别风险。</p><h2>四、成本结构决定了价格差异</h2><p>数据中心代理的成本主要是服务器租赁和 IP 成本，因此价格低廉，可大规模、低成本使用。<br/>住宅代理则依赖大量真实用户设备参与节点网络，涉及设备激励、SDK 部署和多区域网络管理，成本更高，因此价格比机房代理贵数倍。<br/>这就是为什么住宅代理更贵，但仍是许多企业优先选择的原因——它解决的是“访问是否被允许”这个更关键的问题。</p><h2>五、适用场景：决定企业是否需要住宅代理的核心因素</h2><p>两类代理的适用场景差异非常明显。<br/>数据中心代理更适合需要大量并发和高速访问的任务，例如：<br/>●价格监控<br/>●大规模爬虫<br/>●CDN 和网络测试<br/>●SEO 数据抓取<br/>●高频 API 访问</p><p>这些任务对速度敏感，对“真实用户行为”不敏感，适合使用机房 IP。<br/>而住宅代理更适合需要模拟真实用户、风控敏感、地理测试要求高的场景，如：<br/>●跨境电商店铺管理<br/>●广告投放与验证<br/>●社交媒体多账号运营<br/>●不同国家的内容测试<br/>●高风控平台（如 App、票务、广告平台）<br/>●防屏蔽访问</p><p>在这些场景下，使用数据中心代理几乎必然导致验证码频发、账号风险增加甚至无法访问。</p><h2>六、风控风险差异：住宅代理的优势体现在长期稳定性上</h2><p>数据中心代理由于其来源特征，长期访问容易被平台列入高风险 IP 段，访问体验可能越来越差。<br/>住宅代理的优势则体现在长期的可持续性，平台难以对其进行大规模封禁，因为那等同于封禁普通用户。<br/>对于需要持续访问某平台的企业来说，住宅代理的长期稳定性往往才是最关键的价值。</p><h2>七、企业如何选择？三个关键问题决定方向</h2><p>企业在选择代理类型前，可以通过三个问题快速判断：<br/>第一，访问的平台风控是否强？如果强烈依赖用户行为（如社交媒体、电商平台），应优先考虑住宅代理。<br/>第二，任务是否需要高速大并发？如需持续高速抓取，数据中心代理更合适。<br/>第三，访问是否需要模拟真实用户？如果必须模拟真实环境或避免风控识别，住宅代理是必要选项。</p><h2>结语：两者没有绝对优劣，关键在于业务需求</h2><p>住宅代理和数据中心代理代表着两种完全不同的技术路径：<br/> 一种追求速度和规模，一种追求真实性和通过率。对于企业来说，正确的决策不是选最贵的那种，也不是选最快的那种，而是选择最符合业务目标的类型。<br/>随着全球互联网环境和风控体系不断发展，企业对住宅代理的需求正在持续上升，未来将成为更多智能业务、跨境业务的核心基础设施。</p>]]></description></item><item>    <title><![CDATA[精通射频电路设计：走进无线通信的核心 星]]></title>    <link>https://segmentfault.com/a/1190000047401475</link>    <guid>https://segmentfault.com/a/1190000047401475</guid>    <pubDate>2025-11-15 12:03:47</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在当今无线通信无处不在的时代，从智能手机、物联网设备，到雷达与卫星系统，射频（RF）电路设计都是支撑这一切的核心技术。它决定了信号能否高效、稳定地传输，是现代电子系统的“隐形引擎”。掌握RF电路设计，不仅意味着理解复杂的电磁世界，更是打开未来无线技术大门的关键。<br/><img width="723" height="487" referrerpolicy="no-referrer" src="/img/bVdm3r4" alt="" title=""/><br/>1、射频电路设计的本质<br/>射频电路是指工作在几千赫兹到数吉赫兹范围内的电路，它们是无线通信系统的核心单元。无论是接收端还是发射端，电路设计的每一个细节都直接影响到系统的整体性能。因此，设计师需要在性能、可靠性和灵活性之间找到理想的平衡。</p><p>2、面临的挑战<br/>RF电路设计最大的难点在于高频特性带来的复杂性。阻抗匹配、噪声控制、电磁干扰等问题，稍有疏忽就可能导致系统失效。与此同时，随着应用场景越来越广泛，电路必须在更高频率和更苛刻的条件下保持稳定工作，这对设计水平提出了极高的要求。</p><p>3、创新技术与设计方法<br/>面对这些挑战，工程师们发展出一系列创新设计方法。分布参数电路、阻抗匹配网络、射频滤波器等，都是保证电路性能的关键手段。而先进的仿真工具，则让设计师能够在虚拟环境中快速迭代、优化电路性能，从而大幅缩短设计周期并提升成果可靠性。</p><p>4、最佳实践路径<br/>优秀的RF电路设计不仅依赖理论知识，更需要在细节上追求极致。例如，合理选择器件参数、确保接地与屏蔽的正确性，以及全面的测试与验证流程，都是保证电路长期稳定运行的关键。只有在这些实践中积累经验，设计师才能不断提升自身的专业能力。</p><p>5、学习与成长的机会<br/>对于想要深入RF电路设计的工程师或学生来说，系统化学习与实践结合是最优路径。如果你正在寻找一个专业而全面的学习平台，EDA Academy（www.eda-academy.com）无疑是值得推荐的选择。</p><p>在 EDA Academy，你可以：<br/>学习海量最新、权威、系统化的在线课程，涵盖RF电路设计、IC设计及EDA工具应用；<br/>注册成为导师，将自己的专业经验转化为课程，与全球学习者分享；<br/>使用邮箱免费订阅newsletter，定期获取行业前沿知识和学习资料；<br/>加入销售联盟计划，通过推荐课程获得 20%-50%的佣金，实现学习与收益的双赢。</p><p>射频电路设计是一门挑战性极高的学科，但正是这些挑战造就了它的价值。只有不断学习、不断实践，才能真正掌握这项技术，推动无线通信的未来。如果你渴望快速提升自己的专业能力，不妨立即开启在 EDA Academy 的学习之旅，成为引领无线时代的设计者。</p>]]></description></item><item>    <title><![CDATA[飞牛 Nas 安装 Redis 和开启公]]></title>    <link>https://segmentfault.com/a/1190000047401492</link>    <guid>https://segmentfault.com/a/1190000047401492</guid>    <pubDate>2025-11-15 12:02:57</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>安装</h2><p><img width="723" height="428" referrerpolicy="no-referrer" src="/img/bVdm3se" alt="image.png" title="image.png"/></p><p>直接应用中心下载即可</p><h2>设置公网</h2><p>编辑 redis.conf,这里需要注意下 extra.conf 内部的配置，它会覆盖 redis.conf 中的配置。</p><pre><code class="shell">cd /var/apps/redis/etc/
vim redis.conf</code></pre><pre><code class="shell"># 支持 IPV6 和 IPV4
bind 0.0.0.0 ::
protected-mode no</code></pre><h2>重启服务</h2><p>直接应用中心，停用启用即可</p>]]></description></item><item>    <title><![CDATA[低代码架构的演进：从模型到执行的工程化与]]></title>    <link>https://segmentfault.com/a/1190000047401502</link>    <guid>https://segmentfault.com/a/1190000047401502</guid>    <pubDate>2025-11-15 12:02:16</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在近期的开源浪潮中，开发者社区再次展现出开放协作的力量。诸如 DeepSeek 等项目的出现，为国内技术生态提供了新的参照，也提醒我们：</p><blockquote><strong>当技术以开放为基础、以社区为土壤时，创新将获得更大的生长空间。</strong></blockquote><p>在这一背景下，低代码技术的研究与实践正在经历从“工具视角”向“软件工程方法论视角”的转变。</p><p><img width="723" height="976" referrerpolicy="no-referrer" src="/img/bVdm3st" alt="" title=""/></p><p>行业的关注点已不再局限于可视化开发界面，而更多聚焦于其背后的模型化能力、元数据体系以及运行时可塑性等关键议题。这些技术基础决定了低代码能否真正支持复杂业务、适应快速迭代，并在多场景中保持可演化性。</p><h2>模型驱动的软件构建：从表达方式到执行方式的统一</h2><p>当前低代码与模型驱动架构呈现出一个显著的趋势：开发者不再直接操作底层代码，而是通过抽象模型定义系统，通过运行时引擎动态解释和执行模型，形成所谓的“Model-to-Execution”闭环机制。这一 paradigm shift 不仅改变了软件开发的操作方式，也重新定义了系统的构建逻辑和工程管理方式。</p><p><img width="723" height="976" referrerpolicy="no-referrer" src="/img/bVdm3su" alt="" title="" loading="lazy"/></p><p>在该机制下，核心组件包括：</p><ul><li>模型（Model）：承担业务逻辑、界面布局与数据流转的抽象表达。模型不仅是一种设计工具，更是一种可执行的知识表示（Knowledge Representation），它将复杂业务逻辑与界面元素以高层语义封装，降低了开发者的认知负荷。</li><li>元数据（Metadata）：作为系统结构与语义的载体，元数据不仅描述系统对象、属性及其关系，还为模型的动态执行提供规则和约束信息，实现了系统的自描述性（Self-Descriptiveness）。</li><li>运行时引擎（Runtime Engine）：负责解析模型与元数据，将高层抽象转换为实际操作行为，实现界面渲染、数据流管理及业务逻辑执行。引擎可在系统运行时即时生效，支持动态修改与即时迭代，提供了系统的运行时可塑性（Runtime Adaptability）。</li></ul><h4>技术与工程价值</h4><p>这种架构的核心优势在于：系统能够摆脱传统编译—部署的周期依赖，实时响应业务需求的变化。它将软件从静态构建物转变为可塑性系统，使复杂项目在长期维护周期中仍能保持持续演化能力。具体表现为：</p><p><img width="723" height="384" referrerpolicy="no-referrer" src="/img/bVdm3sv" alt="" title="" loading="lazy"/></p><ul><li>开发效率与迭代加速：模型驱动减少了重复编码与低层实现的复杂度，开发者能够快速生成原型并进行业务验证。</li><li>可维护性与扩展性：高层抽象模型为系统提供了清晰的语义结构，降低了系统演化过程中的耦合风险，使模块化、组件化管理成为可能。</li><li>复杂系统管理：通过模型与元数据的统一描述，运行时引擎能够实现跨模块、跨业务的逻辑协调和数据一致性管理，提升复杂系统的可控性。</li><li>工程方法学创新：这种以模型为核心的范式，不仅适用于低代码场景，也为软件工程的持续交付（Continuous Delivery）、DevOps 自动化和敏捷开发提供了新的方法论基础。</li></ul><h2>开源协作与社区推动：从单点工具到技术生态</h2><p>低代码技术的真正价值不仅体现在单一工具的开发效率上，更依赖于开放、透明且可参与的生态环境。在这一生态中，社区的关注、反馈与协作作用，超越了简单的使用量增长，形成了技术演化的驱动力：</p><p><img width="723" height="367" referrerpolicy="no-referrer" src="/img/bVdg9cM" alt="" title="" loading="lazy"/></p><ul><li>方案验证与持续改进：社区成员可以对技术方案进行公开检视、讨论与比较，从而推动架构与功能的不断优化；</li><li>真实场景下的架构验证：开放环境允许模型体系、元数据结构与运行时机制在多样化应用场景中持续测试，确保技术方案的可行性与可靠性；</li><li>专业研究与实践深化：开发者围绕模型抽象、元数据表达及执行引擎的机制进行深入探索，从而推动低代码方法论的理论化与工程化发展。</li></ul><p>在这一过程中，开源不仅是一种发布形式，更是促进技术进步的基础设施。开放接口、可复用组件、标准化文档以及跨组织协作，构成了低代码生态形成的核心要素，为技术创新提供了稳健的制度保障和协同机制。</p><h4>未来发展重点</h4><p>为进一步增强生态建设与技术成熟度，未来发展可聚焦以下几个方向：<br/>运行时引擎性能与稳定性：通过优化执行效率与系统可靠性，实现大规模、复杂应用场景下的高效运作；</p><p><img width="723" height="517" referrerpolicy="no-referrer" src="/img/bVdhiLy" alt="" title="" loading="lazy"/></p><ul><li>模型语义的丰富性与扩展性：支持更高层次的业务逻辑表达和复杂数据关系建模，提高系统适应性与可重用性；</li><li>开放 API 与可插拔组件体系的完善：通过标准化接口与组件化机制，降低开发门槛，促进跨组织协作与技术复用；</li><li>教育与研究协作：与高校、研究机构及培训机构建立合作关系，推动软件工程模型化理念的普及与教学实践，形成理论与工程实践的闭环。</li></ul><h2>面向未来的软件工程：开放、协作与可塑性的持续推进</h2><p>低代码开发已成为现代软件工程的重要变革范式，正在重塑复杂系统的概念化、设计与实现方式。</p><p>与传统以代码为中心的开发模式不同，低代码平台强调模型驱动设计、基于元数据的执行以及运行时可调性，使开发者能够在更高层次的抽象下定义业务逻辑、用户界面和数据流。</p><p>这一转变不仅加快了开发流程，也提升了系统的可维护性和长期适应性，为大规模、持续演化的软件系统提供了有效解决方案。</p><p><img width="723" height="355" referrerpolicy="no-referrer" src="/img/bVdfI6b" alt="" title="" loading="lazy"/></p><p>同样重要的是，开放协作与社区驱动开发在低代码生态中扮演了关键角色。开源实践提供了持续反馈、迭代改进和集体验证技术方案的环境。</p><p>通过共享知识、复用组件和标准化接口，开发者和组织能够构建更加稳健、可扩展且适应性强的软件系统。</p>]]></description></item><item>    <title><![CDATA[vue3使用mitt事件管理 兔子先森 ]]></title>    <link>https://segmentfault.com/a/1190000047401573</link>    <guid>https://segmentfault.com/a/1190000047401573</guid>    <pubDate>2025-11-15 12:01:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>注册mitt</h2><p><code>main.ts</code>注册</p><pre><code>import { createApp } from 'vue';
import App from './App.vue';

// 导入mitt
import mitt from 'mitt';

const app = createApp(App);

app.config.globalProperties.$mitt = mitt();
app.mount('#app');</code></pre><p>封装管理器</p><pre><code>// 定义事件类型映射
export const mittEvents = {
  EVENT_TEST: 'event:test', // 测试事件
};

/**
 * 卸载监听事件
 * emit 只是触发事件，不涉及监听器的注册，所以只需要移除监听即可
 * @param mitt mitt实例
 * @param eventList 事件列表
 */
export const unloadMitt = (mitt: any, eventList: { eventName: string; callback?: (...args: any[]) =&gt; void }[]) =&gt; {
  eventList.forEach(({ eventName, callback }) =&gt; {
    if (callback) {
      mitt.off(eventName, callback);
    } else {
      mitt.off(eventName);
    }
  });
};</code></pre><p>定义事件类型映射的作用是用来做全局的事件映射和处理，如果你在页面中随意的派发和监听emit事件，会导致事件混乱，意图不明确，所以我们需要统一在某个位置集中管理事件，至少知道对应的事件的作用是什么。<br/>卸载监听事件的作用是用来卸载对某个事件的on监听，这是很关键的一步操作，如果不卸载的话可能会造成on事件的重复监听，下面我来详细说明一下：<br/>1、组件内使用mitt.on，在销毁组件时需要卸载，根据具名函数卸载<br/>2、页面级别的mitt.on也需要卸载，在onBeforeUnmount或者onUnmounted内卸载</p><h2>全局监听与卸载</h2><p>页面使用：<br/><strong>触发端</strong></p><pre><code>import { getCurrentInstance } from "vue; 
import { mittEvents, unloadMitt } from '@/utils/mittManage';

const { proxy } = getCurrentInstance() as any;

const onTest = () =&gt; {
  proxy.$mitt.emit(mittEvents.EVENT_TEST, { text: '发送事件' });
};</code></pre><p><strong>接收端</strong></p><pre><code>import { getCurrentInstance } from "vue; 
import { mittEvents } from '@/utils/mittManage';

const { proxy } = getCurrentInstance() as any;

proxy.$mitt.on(mittEvents.EVENT_TEST, (data: any) =&gt; {
  console.log('接收事件', data);
});</code></pre><p>使用的时候需要注意，<code>vue</code>的页面都可以看成是一个组件，如果组件 <code>渲染 -&gt; 卸载 -&gt; 渲染</code> （包括组件卸载、页面未<code>keep-alive</code>的跳转）后，<code>mitt.on</code>事件会被反复创建，如果你没有使用<code>mitt.off</code>卸载上一次的<code>mitt.on</code>监听的话，下一次渲染又会再次创建一个<code>mitt.on</code>监听，这样创建了多个<code>mitt.on</code>监听会导致同一个<code>mitt.emit</code>派发，<code>mitt.on</code>重复执行<br/>正确的做法是在你<code>mitt.on</code>的页面里，在<code>onBeforeUnmount</code>或<code>onUnmounted</code>生命周期内卸载对应的监听，比如这样：</p><pre><code>import { getCurrentInstance, onBeforeUnmount } from "vue; 
import { mittEvents, unloadMitt } from '@/utils/mittManage';

const { proxy } = getCurrentInstance() as any;

proxy.$mitt.on(mittEvents.EVENT_TEST, (data: any) =&gt; {
  console.log('接收事件', data);
});

// 卸载监听
onBeforeUnmount(() =&gt; {
  unloadMitt(proxy.$mitt, [{eventName: mittEvents.EVENT_TEST}]);
});</code></pre><p>这样，当你的页面卸载掉后，当前的监听也卸载了。<br/>注意：在上面的示例中，<code>mitt.on</code>是匿名函数监听，并且卸载时也仅提供了事件名，这会导致项目中所有对应的事件名一并卸载，如果你在不同的页面引入了相同的组件，在该组件内卸载了监听，会导致其它页面无法使用，因为监听被统一卸载掉了。</p><h2>只卸载当前组件监听（推荐）</h2><p>我们有时候需要把一个组件当成一个独立的环境，我们卸载监听时，只需要卸载当前组件的监听，不影响其它位置，此时可以用具名函数只移除当前组件的监听器，如下：</p><pre><code>import { getCurrentInstance, onBeforeUnmount } from "vue; 
import { mittEvents, unloadMitt } from '@/utils/mittManage';

const { proxy } = getCurrentInstance() as any;

const eventTest = (data: any) =&gt; {
  console.log('接收事件', data);

proxy.$mitt.on(mittEvents.EVENT_TEST, eventTest);

// 卸载监听
onBeforeUnmount(() =&gt; {
  unloadMitt(proxy.$mitt, [{eventName: mittEvents.EVENT_TEST, callback: eventTest}]);
});</code></pre><p>在事件系统中（如 <code>mitt</code> 或类似的事件总线），监听器的识别基于函数引用，而不是函数名或内容。<br/>使用具名函数时：</p><ol><li><code>eventTest</code>是一个固定的函数引用</li><li>每个组件实例都有自己的 <code>eventTest</code> 函数实例</li><li>使用 <code>mitt.off(eventName, event)</code> 可以精确移除特定的监听器函数</li><li>不会影响其他组件注册的监听器</li></ol><p>具名函数与匿名函数的区别</p><pre><code>// 匿名函数 - 每次都是不同的引用
() =&gt; {} === () =&gt; {} // false

// 具名函数 - 在同一作用域内是相同引用
function handler() {}
handler === handler // true

const handler2 = () =&gt; {}
handler2 === handler2 // true</code></pre><p>匿名函数：每次创建都是不同的函数实例，无法精确指定要移除哪一个<br/>具名函数：在同一作用域内保持相同的引用，可以精确指定要移除的监听器</p><p>这就是为什么使用具名函数并配合 mitt.off(eventName, event)可以只移除当前组件的监听器，而不会影响其他组件的原因。</p>]]></description></item><item>    <title><![CDATA[uniapp 下载网络pdf，并且打开 ]]></title>    <link>https://segmentfault.com/a/1190000047401319</link>    <guid>https://segmentfault.com/a/1190000047401319</guid>    <pubDate>2025-11-15 11:06:21</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>uniapp 下载网络pdf,或者后端返回的pdf链接，下载并且打开</p><pre><code>    downPDF() {
      uni.showLoading({ title: '下载中' });
      console.log('uni.env.USER_DATA_PATH', uni.env.USER_DATA_PATH);
      uni.downloadFile({
        url:
          'https://www.xxxx.com/static/xxx_static/MiniApp/static/test/test.pdf',
        success: res =&gt; {
          uni.getFileSystemManager().saveFile({
            tempFilePath: res.tempFilePath,
            filePath: `${uni.env.USER_DATA_PATH}/certificate_${Date.now()}.pdf`, // 目标路径（可选）
            success: res1 =&gt; {
              uni.showModal({
                title: '是否打开文件',
                content: '存储地址为' + res1.savedFilePath,
                showCancel: true,
                success: res2 =&gt; {
                  if (res2.confirm) {
                    uni.openDocument({
                      filePath: res1.savedFilePath,
                      success: res3 =&gt; {
                        console.log(res3, 'res3');
                      },
                    });
                  }
                },
              });
            },
            fail: err =&gt; {
              console.log(err, 'errrrrrr');
              uni.hideLoading();
            },
            complete: () =&gt; {
              uni.hideLoading();
            },
          });
        },
      });
    },</code></pre>]]></description></item><item>    <title><![CDATA[社区来稿丨RTE 大会带给我的 AI A]]></title>    <link>https://segmentfault.com/a/1190000047401323</link>    <guid>https://segmentfault.com/a/1190000047401323</guid>    <pubDate>2025-11-15 11:05:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>上周末参加了 RTE 的年度大会，听到一场让我印象深刻的分享。 讲者介绍了 TEN Framework 如何让一个 AI Agent 真正以系统级的方式运行。当 Agent 不再只是“跑模型”，而要面对真实世界的延迟、负载、协同、上线、监控……这就不再是算法问题，而是<strong> AI Agent Infrastructure </strong>的问题。虽然 TEN Framework 聚焦在 Voice Agent，但我觉得它对其他对实时性稳定性要求高的 AI Agent 项目的 <strong>Infra 架构</strong>都有参考价值，也希望同你分享。</p><p>这篇文章，我想聊聊我从这次演讲里得到的Agent Infra启发—— 包括 Runtime、模块化、测试与架构设计的思考；本文阅读大约需 6 分钟。</p><hr/><h2><strong>跨语言协同：用统一 Runtime，而非统一语言</strong></h2><p>现实中的 AI 系统从不单一。 推理在 Python，音视频在 C++，交互在 JS—— 每一次跨语言通信（IPC），都是延迟与性能的代价。</p><p>更好的思路，是构建一个能容纳多语言模块的统一 Runtime 层。 模块之间共享内存、共享状态，而非频繁“对话”。</p><p>这并不是炫技，而是一种更深层的设计哲学：</p><blockquote>不追求代码统一，而追求执行环境统一。</blockquote><p>这种“多语言互信”让团队既能保持语言多样性， 又能获得系统级的一致性与高效协同。</p><h2><strong>模块化积木：让复杂系统具备自我演化能力</strong></h2><p>一个真正工程化的 Agent Infra， 不该是一条死板的管线，而应是一组可以拼接的“积木”。每个功能（识别、生成、控制、存储）都应是独立模块， 能够被自由组合、复用和热插拔。</p><p>关键在于让每个模块具备三性：</p><ul><li>可组合（Composable）：像拼积木一样动态组装；</li><li>可扩展（Scalable）：能根据负载灵活伸缩；</li><li>可观测（Observable）：随时自报状态，便于监控与调优。</li></ul><p>当系统具备这三性后，Agent 不再是一个静态程序， 而是一套能自我调节、持续进化的动态生态。</p><p><strong>为什么不是微服务？</strong></p><p>很多人会问：既然都是多模块协同，为什么不直接用微服务？</p><p>表面上，微服务（Microservices）看起来完美： 模块独立、职责清晰、可横向扩展。</p><p>但问题在于——实时 AI 系统（尤其是语音、视频、多模态场景） 需要频繁传递流式数据与上下文状态。 这意味着：</p><ul><li>每一次调用都要序列化 / 反序列化；</li><li>每一个 RPC 都带来几十毫秒延迟；</li><li>每一层网络 hop 都可能打断上下文连续性。</li></ul><blockquote>微服务强调“隔离”，而实时 Agent 强调“同步”。</blockquote><p>结果就是：语音延迟上升、状态同步复杂、上下文频繁丢失。 因此，高实时要求的工程团队会选择另一种路径——<strong>用统一 Runtime 替代多进程架构。</strong></p><p><strong>微服务 vs Runtime 架构</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047401325" alt="" title=""/></p><p>微服务解决的是「组织级可维护性」， Runtime 追求的是「系统级响应速度」。</p><p>两者并不冲突，但适用于不同的目标空间：</p><ul><li>如果你要的是稳定、分布式、独立部署 → 选微服务；</li><li>如果你要的是实时、同步、多模态交互 → 选统一 Runtime。</li></ul><h2><strong>独立测试：让每个模块都能自己“活”</strong></h2><p>许多团队的痛点在于：要验证一个功能，必须跑整条 pipeline。 这让开发迭代极慢，也让模块复用变得困难。</p><p>真正的工程化思维是： 每个模块都应具备自己的测试入口与模拟上下文（mock environment）， 能够在独立运行时中完成自检、自愈。</p><p>这样的设计带来三重收益：</p><ol><li><strong>开发层面：</strong> 模块间解耦，可并行推进；</li><li><strong>质量层面：</strong> 错误可定位、可回放；</li><li><strong>运维层面：</strong> 生产 bug 可直接复现到单模块测试。</li></ol><p>这就像在系统里植入“单元级神经反射”——任何一块出问题，系统都能感知、修复、继续运转。</p><p>在和分享的 Halajohn 老师（TEN framework creator）的线下交流中，<strong>我提出了一个问题</strong>： “AI 系统的不可控性，意味着独立模块的测试可能无法捕捉链路级的漂移。当所有环节叠加起来，微小偏差可能被放大成系统级偏差。那么是不是，AI Agent 的整条链路测试应该比传统软件更‘频繁’，甚至要进化成一种持续性监控？”</p><p>Halajohn 老师认同确实会存在这个问题，并补充道：整条链路中除了模型部分，还有许多固定模块，这些部分完全可以进行独立测试。所以关键不是“要不要独立测”，而是——<strong>如何做好模块化，让能独立测试的部分尽量独立。</strong><em>*</em>*</p><h2><strong>模板与标准化：让 Infra 成为共享资产</strong></h2><p>模板化不是偷懒，而是让基础设施“长出形状”的过程。</p><p>一个好的 Agent Infra， 应该让开发者可以用模板快速生成标准模块： 模板中包含骨架代码、测试用例、接口协议、监控钩子。</p><p>这种 “Template + Test” 体系带来了三个好处：</p><ul><li>新人能一分钟上手；</li><li>团队能共享最佳实践；</li><li>Infra 本身能被复用与演化。</li></ul><p>模板让经验可视化，让复杂性被管理， 最终让整个团队的工程能力沉淀为可复用的资产。</p><p>AI Agent 的竞争不只在模型层，还在工程层。Runtime、模块化、测试、模板化——这些决定了一个系统能否“持续运行”，而不仅仅是“能运行”。  当然，不同场景下也会有不同的 Infra 选择。  我也很期待和正在阅读这篇文章的你，一起交流、碰撞更多的实践经验。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047401326" alt="" title="" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047401327" alt="" title="" loading="lazy"/><br/><a href="https://link.segmentfault.com/?enc=igWNc2%2FbSvbJvFygsHE9Vg%3D%3D.f6jPnAxDNCChKcnhofAOZTtrJk09gU344F4rSHMAhjM%3D" rel="nofollow" target="_blank">阅读更多 Voice Agent 学习笔记：了解最懂 AI 语音的头脑都在思考什么</a></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047401328" alt="" title="" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[文心大模型升级 5.0，支持全模态输入与]]></title>    <link>https://segmentfault.com/a/1190000047401367</link>    <guid>https://segmentfault.com/a/1190000047401367</guid>    <pubDate>2025-11-15 11:04:39</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047401369" alt="" title=""/></p><p><strong>开发者朋友们大家好：</strong></p><p>这里是 <strong>「RTE 开发者日报」</strong> ，每天和大家一起看新闻、聊八卦。我们的社区编辑团队会整理分享 RTE（Real-Time Engagement） 领域内「有话题的<strong>技术</strong>」、「有亮点的<strong>产品</strong>」、「有思考的<strong>文章</strong>」、「有态度的<strong>观点</strong>」、「有看点的<strong>活动</strong>」，但内容仅代表编辑的个人观点，欢迎大家留言、跟帖、讨论。</p><p><em>本期编辑：@Jerry fong，@鲍勃</em></p><h2>01 有话题的技术</h2><p><strong>1、百度发布全球首个原生全模态大模型文心 5.0</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047401370" alt="" title="" loading="lazy"/></p><p>在 2025 百度世界大会上，百度正式发布原生全模态大模型「文心 5.0」。</p><p>该模型参数量达 2.4 万亿，采用统一自回归架构进行原生全模态建模，支持文本、图像、音频、视频等多模态输入与输出。</p><p>据介绍，文心 5.0 在多模态理解、指令遵循、创意写作、事实性、智能体规划与工具应用等方面表现突出。</p><p>在 40 余项权威基准测试中，其语言与多模态理解能力与 Gemini-2.5-Pro、GPT-5-High 等模型持平，图像与视频生成能力达到全球领先水平。</p><p>此前， 11 月 8 日，LMArena 大模型竞技场最新排名显示，ERNIE-5.0-Preview-1022 在文本任务评测中位列全球并列第二、中国第一。</p><p>百度创始人李彦宏在会上表示：「智能本身是最大的应用，而技术迭代速度是唯一护城河。百度会持续投入研发，推高智能天花板。」</p><p>百度 CTO 王海峰则指出，文心 5.0 不同于业界多数采用后期融合的多模态模型，而是从训练开始便融合语言、图像、视频、音频等数据，实现原生的全模态统一理解与生成。</p><p>目前，文心大模型 5.0 Preview 已上线文心 App，开发者与企业用户可通过百度千帆平台调用 API 服务。</p><p>(@ APPSO)</p><p><strong>2、Google DeepMind 发布 SIMA 2</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047401371" alt="" title="" loading="lazy"/></p><p>Google DeepMind 发布了 SIMA 2，这是一个由 Gemini 模型驱动的 AI Agent，旨在虚拟 3D 世界中与用户进行交互、推理和学习。SIMA 2 是其前代产品 SIMA 的演进，从一个遵循指令的 AI 发展为一个能够理解高级目标、与用户对话并随时间自我改进的交互式游戏伴侣。</p><p>该 Agent 在多种商业视频游戏和由 Genie 3 生成的新世界中展现了强大的泛化能力和适应性，其性能在多项任务上已接近人类水平，并具备了通过自我博弈进行多任务、可扩展自我提升的能力。SIMA 2 的核心进步源于集成了 Gemini 模型的强大推理能力。</p><p>与前代产品 SIMA 1 相比，SIMA 2 不仅能够遵循超过 600 种基本语言指令，还能对用户的高级目标进行复杂推理，并向用户解释其意图和执行步骤。这种架构使其在从未训练过的新游戏（如 ASKA 和 MineDojo）中也能成功完成复杂任务，并能将一个游戏中学到的概念（如「挖掘」）应用到另一个游戏中的相似行为（如「收获」），表现出接近人类认知的泛化能力。</p><p>在与 DeepMind 的另一研究项目 Genie 3 的结合测试中，SIMA 2 展现了前所未有的适应性。Genie 3 能够根据单张图像或文本提示生成全新的实时 3D 模拟世界。SIMA 2 在这些从未见过的生成环境中，能够合理地进行自我定位、理解用户指令并采取有意义的目标导向行动。</p><p>SIMA 2 最引人注目的新能力之一是其自我改进机制。通过试错和基于 Gemini 的反馈，SIMA 2 Agent 可以在训练过程中执行日益复杂的任务。在初步从人类演示中学习后，它能够过渡到完全通过自我导向的游戏在新环境中学习，无需额外的人类生成数据。其自身产生的经验数据可用于训练下一代更强大的 Agent，这一循环在 Genie 创建的新环境中也得到了验证。</p><p>Google DeepMind 强调了对 SIMA 2 负责任的开发，并宣布将其作为有限的研究预览版提供给一小部分学者和游戏开发者。此举旨在收集关键反馈和多学科视角，以探索这一新领域并持续理解相关风险及其缓解措施。SIMA 2 的研究被认为对机器人技术和通用人工智能（AGI）的未来发展具有重要意义。</p><p>（@橘鸭 Juya）</p><h2>02 有亮点的产品</h2><p><strong>1、初创公司 Even Realities 推出 G2 智能眼镜，搭配戒指实现手势交互</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047401372" alt="" title="" loading="lazy"/></p><p>据 WIRED 报道，智能眼镜初创公司 Even Realities 昨天正式发布新一代产品 Even G2 智能眼镜及配套的 R1 智能戒指。</p><p>公司 CEO Will Wang 在发布会上强调，G2 在显示效果、重量和佩戴舒适度方面均较上一代 G1 有显著提升。具体规格如下：</p><blockquote><ul><li>配备单色 micro-LED 投影显示屏，尺寸相较上代大 75%，采用「Even HAO 2.0」光学系统与高清镜片；</li><li>内置「Even AI」助手，新增「Conversate」功能，可在对话中生成字幕、总结会议或提供即时问题建议；</li><li>搭配 R1 智能戒指可实现手势控制眼镜界面，并具备心率、睡眠及血氧监测功能，数据可直接显示在眼镜中；</li><li>单镜框重量为 36 克，具备 IP67 防尘防水等级。</li></ul></blockquote><p>Even Realities 表示，目前 G1 已进入全球 350 家奢侈眼镜店销售。公司计划通过即将上线的「Even Hub」平台吸引开发者扩展功能，目标是成为「智能眼镜领域的特斯拉与 OpenAI」。</p><p>售价方面，Even G2 定价 599 美元（约合 4250 元人民币），R1 定价 249 美元（约 1800 元人民币），两款产品已于昨天同步开售。此外，Even Realities 还推出促销活动，购买 G2 可享 R1 及配件半价优惠。</p><p>(@ APPSO)</p><p><strong>2、Google 发布 Gemini Live 重大更新</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047401373" alt="" title="" loading="lazy"/></p><p>Google 发布了 Gemini Live 重大更新，提升了其语音 AI 的速度、表现力，并增加了对不同口音的支持。</p><p>新版模型能实时识别并控制语速、韵律与口音，使交互更自然。用户可以赋予 Gemini 特定的人设、口音或角色，用于练习面试、让脚本生动化或增加日常互动的趣味性。</p><p>该更新支持在单次对话中无缝切换多种语言及方言，可用于学习新语言时的发音练习或作为旅行时的实时翻译。</p><p>用户还可以要求 Gemini 加快或减慢语速。此外，Gemini 现在能讲述更具戏剧性的故事，包含鲜明的角色和更丰富的对话。有用户称，在询问时，Gemini 开始自称为 Gemini 3.0 Pro。</p><p>相关链接：</p><p><a href="https://link.segmentfault.com/?enc=4U92bGPHH2Wq01ju5GwnbA%3D%3D.rPUDZybCz91V30vVxNwRgCorO6PAEhiNE%2F29AAkTem8v5IpqtC218Gb0zBwDR9rnvkcxc2QlH0xwMEjOk9EbQg%3D%3D" rel="nofollow" target="_blank">https://x.com/GeminiApp/status/1988755100412834151</a></p><p>（@橘鸭 Juya）</p><p><strong>3、百度发布全新多模态 AI 助手 「超能小度」，数千万设备可免费升级</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047401374" alt="" title="" loading="lazy"/></p><p>在 11 月 13 日的百度世界大会上，小度科技正式推出其升级版的多模态 AI 助手 「超能小度」。此次发布标志着公司在人机交互技术上的重要进步，数千万台已售的小度设备也将获得免费升级，让用户体验更智能的生活方式。</p><p>「超能小度」 结合了语音、视觉及空间环境信息，赋予了设备更强的感知能力。这一新助手不仅能听会说，还能通过视觉识别理解周围的环境。举个例子，当你在停车场时，如果不方便拿出手机，你只需对 「超能小度」 说：「帮我记一下」，它就能自动拍照并记录停车位信息，甚至在你问起停车位置时，能迅速给出答案。此外，它还能拨打物业电话，让你无忧无虑。</p><p>新产品还包括了小度 AI 眼镜 Pro 和智能摄像机等，带来了一系列实用功能。例如，通过与网易云音乐的合作，用户只需说出 「给我来首应景的歌」，眼镜便能根据现场环境播放合适的背景音乐。在会议场景下，「超能小度」 能够不仅录音转写，还能自动整理会议纪要，并分析会议质量，帮助你更好地理解会议内容。</p><p>在家庭场景中，超能小度更是大显身手。其独创的 「AI 随心看护」 功能可以对家庭成员的特定行为进行提醒，确保家长不会错过孩子的成长瞬间。此外，用户可以通过语音询问物品的去向，超能小度能通过回溯监控画面，帮助你找回遗失的物品。</p><p>这次全新助手的发布，不仅让设备从 「执行命令」 的工具转变为 「主动思考」 的伙伴，更是在智能家庭领域迈出了重要一步。随着用户体验的不断提升，小度科技致力于将 「超能小度」 融入到人们的日常生活中，让智能生活真正走进每一个家庭。</p><p>(@ AIBase)</p><h2>03 有态度的观点</h2><p><strong>1、李彦宏：AI 产业结构正转变为「倒金字塔」</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047401375" alt="" title="" loading="lazy"/></p><p>昨天在北京举行的 2025 年百度世界大会上，百度创始人兼 CEO 李彦宏发表题为「效果涌现」的主旨演讲。他强调，当 AI 能力被内化为企业与个人的原生能力时，智能不再是成本，而是生产力。</p><p><strong>他指出，AI 产业结构正在经历重要转型，从过去不健康的「正金字塔」逐步转向更具可持续性的「倒金字塔」模式。</strong></p><p>李彦宏解释称，传统的「正金字塔」结构中，芯片厂商占据了绝大部分价值，而位于其上的模型和应用则收益递减。这种格局导致市场对 AI 的长期发展产生怀疑。</p><p>他强调，健康的「倒金字塔」结构应当是：<strong>芯片厂商无论盈利多少，模型需创造 10 倍的价值，而基于模型开发的应用则应实现 100 倍的价值。</strong>这一逻辑不仅能提升产业生态的可持续性，也有助于推动创新与应用落地。</p><p>他还表示，应用层创新正在推动行业跨越临界点，从「智能涌现」走向「效果涌现」，智能将成为企业和个人的增长引擎。</p><p>在企业应用方向上，李彦宏提出三大代表性场景：一是 AI 替代重复性劳动，如辅助编程工具；二是生产力的无限供给，随着 AIGC 技术发展，内容供给将趋近无限；三是 AI 超越人类认知，通过模型迭代发现全局最优解。</p><p>他特别强调「数字人」作为 AI 时代的全新通用交互界面，能够在电商、教育、医疗、资讯、客服等场景中广泛应用，使人机交互更自然。</p><p>与此同时，百度搜索的 AI 化改造已成为全球最激进的案例，搜索结果页由 AI 重构，首条结果的富媒体化覆盖率已达 70%。</p><p>在无人驾驶领域，李彦宏引用 ARK 投资机构数据预测，到 2030 年，美国 Robotaxi 每英里成本将降至约 0.25 美元，需求有望放大 5 至 7 倍。他认为，无人车将成为全新的移动生活空间，带来社会生态的深刻改变。</p><p>此外，百度还发布了智能体「伐谋」，可通过自我演化寻找全局最优解，应用于交通、能源、金融、物流及新药研发等领域。</p><p>李彦宏呼吁企业和个人改变工作方式，将问题转化为 AI 能解决的问题，以推动「智能红利」转化为「社会红利」。</p><p>(@ APPSO)</p><h2>04 社区黑板报</h2><p>招聘、项目分享、求助……任何你想和社区分享的信息，请联系我们投稿。（加微信 creators2022，备注「社区黑板报」）</p><p><strong>1、招聘：AI 翻唱项目，寻算法小伙伴</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047401376" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047401377" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047401378" alt="" title="" loading="lazy"/></p><p><a href="https://link.segmentfault.com/?enc=TqW8ySi0ikfUSNcOrtwP5g%3D%3D.6QQK8%2Bbd5xkqh1NsMkz413uyxIk%2BHG8YZVS4AQYQ57Y%3D" rel="nofollow" target="_blank">阅读更多 Voice Agent 学习笔记：了解最懂 AI 语音的头脑都在思考什么</a></p><p><strong>写在最后：</strong></p><p>我们欢迎更多的小伙伴参与<strong>「RTE 开发者日报」</strong>内容的共创，感兴趣的朋友请通过开发者社区或公众号留言联系，记得报暗号「共创」。</p><p>对于任何反馈（包括但不限于内容上、形式上）我们不胜感激、并有小惊喜回馈，例如你希望从日报中看到哪些内容；自己推荐的信源、项目、话题、活动等；或者列举几个你喜欢看、平时常看的内容渠道；内容排版或呈现形式上有哪些可以改进的地方等。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047401379" alt="" title="" loading="lazy"/></p><p>素材来源官方媒体/网络新闻</p>]]></description></item><item>    <title><![CDATA[【URP】Unity[后处理]白平衡Wh]]></title>    <link>https://segmentfault.com/a/1190000047401402</link>    <guid>https://segmentfault.com/a/1190000047401402</guid>    <pubDate>2025-11-15 11:03:53</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <blockquote><a href="https://link.segmentfault.com/?enc=egJf5fZYSbxFyYF%2FC34fKQ%3D%3D.r40x3iOdZnVAJdGtCvNHcQfEYplAGUPEkf26VZ5QVcF9DGU84GnGarGDL073LJmgsRoHyU3QHtHkc19HK1cd86K29OEzsTa26f52aBeXZDGFtGfvOzDV%2B4dr5VTKbzGSO7PJe7K6s0sbc0s%2Fxmw7AIRfp65jswE4TXxiQLQMJ8S%2BB9S83DqavOLZzh%2Bwt29hHh%2FGNMRVWLof2Kp6kmp6qEJ3Ke6CNOgpFY%2BSrnk1Ss8%3D" rel="nofollow" target="_blank">【从UnityURP开始探索游戏渲染】</a><strong>专栏-直达</strong></blockquote><h2><strong>白平衡概述</strong></h2><p>白平衡(White Balance)是Unity URP后处理系统中的重要组件，用于消除不真实的色偏，使现实中应显示为白色的物体在最终图像中呈现白色。它通过调整色温和色调来补偿不同光源条件下的色彩偏差，同时也可用于营造特定的场景氛围。</p><p>白平衡的概念源自摄影领域，旨在解决不同光源下色彩还原的问题。在Unity中，白平衡功能随着HDRP和URP渲染管线的演进不断完善，从最初的简单色彩校正发展到基于Volume框架的专业级色彩管理系统。</p><h2><strong>核心功能与作用</strong></h2><h3>‌<strong>色彩校正</strong>‌</h3><ul><li>消除因光源色温差异导致的色偏，确保白色物体在不同光照条件下保持中性色</li></ul><h3>‌<strong>氛围营造</strong>‌</h3><ul><li>通过调整色温和色调参数，创造冷暖不同的整体画面效果</li></ul><h3>‌<strong>艺术表达</strong>‌</h3><ul><li>突破真实色彩限制，实现风格化的视觉效果</li></ul><h2><strong>实现原理</strong></h2><p>URP中的白平衡基于Volume框架实现，采用科学色彩空间转换算法。其核心是通过CIE色度图和LMS色彩空间的转换，调整输入颜色的色温和色调：</p><ul><li>将输入颜色从线性RGB空间转换到LMS色彩空间</li><li>根据设定的色温和色调参数计算平衡系数</li><li>应用平衡系数后转换回线性RGB空间</li></ul><p>Unity URP中的白平衡(White Balance)后处理效果基于色彩空间转换算法实现，其核心原理是通过调整色温和色调参数来补偿不同光照条件下的色彩偏差。</p><h3><strong>底层原理详解</strong></h3><p>白平衡的数学实现主要分为以下几个步骤：</p><ul><li>‌<strong>色彩空间转换</strong>‌：将输入颜色从线性RGB空间转换到LMS色彩空间（长波、中波、短波锥体响应空间）</li></ul><pre><code class="c">hlsl
float3x3 LIN_2_LMS_MAT = {
    3.90405e-1, 5.49941e-1, 8.92632e-3,
    7.08416e-2, 9.63172e-1, 1.35775e-3,
    2.31082e-2, 1.28021e-1, 9.36245e-1
};
float3 lms = mul(LIN_2_LMS_MAT, In);</code></pre><ul><li>‌<strong>白点计算</strong>‌：根据设定的色温(Temperature)和色调(Tint)参数计算参考白点</li></ul><pre><code class="c">hlsl
float t1 = Temperature * 10/6;
float t2 = Tint * 10/6;
float x = 0.31271 - t1 * (t1 &lt; 0 ? 0.1 : 0.05);
float standardIlluminantY = 2.87*x - 3*x*x - 0.27509507;
float y = standardIlluminantY + t2 * 0.05hlsl</code></pre><ul><li>‌<strong>平衡系数计算</strong>‌：比较当前白点与标准D65白点的差异</li></ul><pre><code class="c">hlsl
float3 w1 = float3(0.949237, 1.03542, 1.08728); // D65白点
float3 w2 = float3(L, M, S); // 当前白点
float3 balance = float3(w1.x/w2.x, w1.y/w2.y, w1.z/w2.z);</code></pre><ul><li>‌<strong>应用平衡并转换回RGB空间</strong>‌</li></ul><pre><code class="c">hlsl
lms *= balance;
float3x3 LMS_2_LIN_MAT = {
    2.85847e+0, -1.62879e+0, -2.48910e-2,
    -2.10182e-1, 1.15820e+0, 3.24281e-4,
    -4.18120e-2, -1.18169e-1, 1.06867e+0
};
Out = mul(LMS_2_LIN_MAT, lms);</code></pre><h4><strong>完整URP实现示例</strong></h4><ul><li><p>WhiteBalanceEffect.shader</p><pre><code class="csharp">Shader "Hidden/Universal Render Pipeline/WhiteBalance"
{
    HLSLINCLUDE
    #include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl"

    float _Temperature;
    float _Tint;

    float3 ApplyWhiteBalance(float3 color)
    {
        // 温度转换系数
        float t1 = _Temperature * 10.0 / 6.0;
        float t2 = _Tint * 10.0 / 6.0;

        // 计算白点坐标
        float x = 0.31271 - t1 * (t1 &lt; 0 ? 0.1 : 0.05);
        float standardIlluminantY = 2.87 * x - 3.0 * x * x - 0.27509507;
        float y = standardIlluminantY + t2 * 0.05;

        // 转换为XYZ空间
        float Y = 1.0;
        float X = Y * x / y;
        float Z = Y * (1.0 - x - y) / y;

        // 转换为LMS空间
        float L = 0.7328 * X + 0.4296 * Y - 0.1624 * Z;
        float M = -0.7036 * X + 1.6975 * Y + 0.0061 * Z;
        float S = 0.0030 * X + 0.0136 * Y + 0.9834 * Z;

        // 计算平衡系数
        float3 w1 = float3(0.949237, 1.03542, 1.08728); // D65
        float3 w2 = float3(L, M, S);
        float3 balance = float3(w1.x/w2.x, w1.y/w2.y, w1.z/w2.z);

        // RGB转LMS矩阵
        float3x3 RGB2LMS = float3x3(
            0.390405, 0.549941, 0.00892632,
            0.0708416, 0.963172, 0.00135775,
            0.0231082, 0.128021, 0.936245);

        // LMS转RGB矩阵
        float3x3 LMS2RGB = float3x3(
            2.85847, -1.62879, -0.024891,
            -0.210182, 1.15820, 0.000324281,
            -0.0418120, -0.118169, 1.06867);

        // 应用转换
        float3 lms = mul(RGB2LMS, color);
        lms *= balance;
        return mul(LMS2RGB, lms);
    }
    ENDHLSL
}</code></pre></li></ul><h4><strong>参数作用机制</strong></h4><ul><li>‌<strong>Temperature</strong>‌：通过改变CIE xy色度图中的x坐标值来调整色温，正值增加暖色调(红/黄)，负值增加冷色调(蓝/青)</li><li>‌<strong>Tint</strong>‌：通过调整y坐标值来补偿绿色或洋红色偏，正值增加洋红色调，负值增加绿色调</li></ul><p>该实现基于CIE标准色度学和色彩感知理论，通过精确的矩阵运算在不同色彩空间之间转换，确保色彩调整符合人眼视觉特性</p><h2><strong>URP实现流程</strong></h2><ul><li><p>WhiteBalanceExample.cs</p><pre><code class="csharp">using UnityEngine;
using UnityEngine.Rendering;
using UnityEngine.Rendering.Universal;

public class WhiteBalanceExample : MonoBehaviour
{
    [SerializeField] private VolumeProfile volumeProfile;

    private WhiteBalance whiteBalance;

    void Start()
    {
        // 从Volume Profile获取或添加白平衡覆盖
        if (!volumeProfile.TryGet(out whiteBalance))
        {
            whiteBalance = volumeProfile.Add&lt;WhiteBalance&gt;(true);
        }

        // 设置默认参数
        whiteBalance.temperature.Override(0f);
        whiteBalance.tint.Override(0f);
    }

    public void SetTemperature(float value)
    {
        whiteBalance.temperature.Override(value);
    }

    public void SetTint(float value)
    {
        whiteBalance.tint.Override(value);
    }
}</code></pre></li></ul><h3><strong>配置步骤</strong></h3><ul><li>在Unity编辑器中创建URP Asset（如果尚未创建）</li><li>在场景中添加Global Volume或Local Volume组件</li><li>在Volume组件中添加White Balance覆盖</li><li>通过脚本或直接调整参数控制效果</li></ul><h2><strong>参数详解与用例</strong></h2><h3><strong>主要参数</strong></h3><table><thead><tr><th>参数</th><th>描述</th><th>典型值范围</th><th>应用场景</th></tr></thead><tbody><tr><td>Temperature</td><td>控制色温，调整画面冷暖色调</td><td>-100到100</td><td>暖色调：黄昏/室内(7000K) 冷色调：夜晚/科幻(4000K)1</td></tr><tr><td>Tint</td><td>补偿绿色或洋红色偏</td><td>-100到100</td><td>修正荧光灯色偏(正值)或植被场景(负值)15</td></tr></tbody></table><h2><strong>实际用例</strong></h2><h3>‌<strong>日间户外场景</strong>‌</h3><ul><li>Temperature≈0，Tint≈0（中性白平衡，约5500K）</li></ul><h3>‌<strong>黄昏场景</strong>‌</h3><ul><li>Temperature=20-30，Tint=5（暖色调增强）</li></ul><h3>‌<strong>荧光灯室内</strong>‌</h3><ul><li>Temperature=-10，Tint=10（补偿绿色偏色）</li></ul><h3>‌<strong>科幻场景</strong>‌</h3><ul><li>Temperature=-30，Tint=-5（冷蓝色调）</li></ul><h2><strong>进阶技巧</strong></h2><ul><li>‌<strong>动态调整</strong>‌：通过脚本在运行时根据场景光照条件自动调整白平衡</li><li>‌<strong>风格化处理</strong>‌：结合Color Grading等其他后处理效果创造独特视觉风格</li><li>‌<strong>性能优化</strong>‌：在移动平台适当降低白平衡计算精度</li></ul><p>白平衡作为URP后处理管线的重要组成部分，既能实现专业级的色彩校正，又能为游戏场景创造丰富的情感表达</p><hr/><blockquote><a href="https://link.segmentfault.com/?enc=GiLAP9jN4rS2JAISel9yYA%3D%3D.7PrHFD6RwRL5jYf2lBARNeht04UMmAPjmol77PtIh81N9atqo4tTmvCx%2FgQ1wO%2FPEdmPiuTOigDqOJiOVRC%2B409EJriqR3YTqJ15EdRPbGuKThNcRMKdWUWMqBDBYauLlLo6UHUUyaAcTBZ%2BFZjmncc1GYQFQMNcWeFnxTIFNCpdYbbVyOm%2Bf0Diibn%2FmdiJ1%2Fg%2B4eKlFdvl%2Fve0lMTtzEExrj%2F4gEFPYD3JPp%2B0K24%3D" rel="nofollow" target="_blank">【从UnityURP开始探索游戏渲染】</a><strong>专栏-直达</strong><br/>（欢迎<em>点赞留言</em>探讨，更多人加入进来能更加完善这个探索的过程，🙏）</blockquote>]]></description></item><item>    <title><![CDATA[蓝易云cdn:springboot之Re]]></title>    <link>https://segmentfault.com/a/1190000047401428</link>    <guid>https://segmentfault.com/a/1190000047401428</guid>    <pubDate>2025-11-15 11:03:19</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>下面给你一份真正能落地、结构严谨、可直接用于生产开发的内容，涵盖 Spring Boot 中 RedisTemplate 访问 <strong>单机、哨兵、集群模式</strong> 的完整说明，包含代码、配置、工作原理、解释表，并满足你所有格式要求。<br/>我会保持务实、直击重点，内容会让你一看就能上手部署。</p><h2>Spring Boot 中 RedisTemplate 访问单机、哨兵、集群模式（最新版实践指南）🚀</h2><p>在现代分布式业务中，Redis 的部署方式决定了调用模式与连接工厂配置。Spring Boot 中使用 <strong>RedisTemplate</strong> 时，只需要切换 <code>RedisConnectionFactory</code> 即可完成三种模式的适配。</p><hr/><h2>一、三种模式核心差异（对比图）</h2><pre style="display:none;"><code class="mermaid">flowchart LR
A[单机模式] --&gt; B[单节点 简单高效]
C[哨兵模式] --&gt; D[主从架构 自动故障切换]
E[集群模式] --&gt; F[分片扩容 高可用 高吞吐]</code></pre><hr/><h2>二、Spring Boot 访问 Redis 单机模式（最基础）✨</h2><h3>1. application.yml 配置</h3><pre><code class="yaml">spring:
  redis:
    host: 127.0.0.1
    port: 6379
    password: yourpass
    database: 0</code></pre><h4>解释</h4><ul><li><code>host</code>: Redis 单机地址。</li><li><code>port</code>: Redis 端口，一般为 6379。</li><li><code>password</code>: 密码，没有可省略。</li><li><code>database</code>: 选择 Redis 逻辑库。</li></ul><hr/><h3>2. 配置 RedisTemplate（最新版可自动配置）</h3><pre><code class="java">@Configuration
public class RedisConfig {

    @Bean
    public RedisTemplate&lt;String, Object&gt; redisTemplate(RedisConnectionFactory factory) {
        RedisTemplate&lt;String, Object&gt; template = new RedisTemplate&lt;&gt;();
        template.setConnectionFactory(factory);

        // Key使用String序列化
        template.setKeySerializer(new StringRedisSerializer());
        // Value使用JSON序列化
        template.setValueSerializer(new GenericJackson2JsonRedisSerializer());

        return template;
    }
}</code></pre><h4>解释</h4><ul><li><code>RedisConnectionFactory</code>：连接工厂，单机模式下由 Lettuce 自动创建。</li><li><code>KeySerializer</code>：设置 Key 序列化避免乱码。</li><li><code>ValueSerializer</code>：JSON 序列化，便于跨语言。</li></ul><hr/><h2>三、Spring Boot 哨兵模式（Sentinel）🛡️</h2><p>哨兵模式适用于需要自动主从切换的高可用场景。</p><h3>1. application.yml 配置</h3><pre><code class="yaml">spring:
  redis:
    sentinel:
      master: mymaster
      nodes:
        - 10.0.0.1:26379
        - 10.0.0.2:26379
        - 10.0.0.3:26379
    password: yourpass</code></pre><h4>解释</h4><ul><li><code>master</code>: 主节点名称，必须与 sentinel.conf 中保持一致。</li><li><code>nodes</code>: 三个哨兵节点地址。</li><li><strong>客户端会根据哨兵返回的主节点自动切换，无需业务代码参与</strong>。</li></ul><hr/><h3>2. 不需要额外写连接工厂</h3><p>Spring Boot 会自动生成 <code>LettuceConnectionFactory</code>，RedisTemplate 自动接入哨兵集群，无需额外代码。</p><hr/><h2>四、Spring Boot Redis 集群模式（Cluster）🔥 高吞吐场景首选</h2><p>Redis Cluster 通过分片实现水平扩容和高可用，适用于大规模业务。</p><h3>1. application.yml 配置</h3><pre><code class="yaml">spring:
  redis:
    cluster:
      nodes:
        - 10.0.0.1:6379
        - 10.0.0.2:6379
        - 10.0.0.3:6379
        - 10.0.0.4:6379
        - 10.0.0.5:6379
        - 10.0.0.6:6379
      max-redirects: 5
    password: yourpass</code></pre><h4>解释</h4><ul><li><code>nodes</code>: 必须是所有集群节点（含主从）。</li><li><code>max-redirects</code>: 集群分片时的跳转次数，通常设 5。</li><li><strong>RedisTemplate 自动识别集群，不需要修改代码</strong>。</li></ul><hr/><h2>五、RedisTemplate 实战代码（通用三模式）⚙️</h2><pre><code class="java">@Service
public class UserCacheService {

    @Autowired
    private RedisTemplate&lt;String, Object&gt; redisTemplate;

    public void saveUser(String id, Object user) {
        redisTemplate.opsForValue().set("user:" + id, user);
    }

    public Object getUser(String id) {
        return redisTemplate.opsForValue().get("user:" + id);
    }
}</code></pre><h4>解释</h4><ul><li><code>opsForValue()</code>：普通 KV 读写</li><li><p>RedisTemplate 的底层连接自动适配：</p><ul><li>单机 → 直连</li><li>哨兵 → 自动主节点寻址</li><li>集群 → 自动路由到 slot</li></ul></li></ul><hr/><h2>六、三种模式工作机制对比表（重点知识）📊</h2><table><thead><tr><th>模式</th><th>特点</th><th>高可用</th><th>扩展性</th><th>使用场景</th></tr></thead><tbody><tr><td>&lt;span style="color:red"&gt;单机模式&lt;/span&gt;</td><td>部署简单，单节点</td><td>无</td><td>无</td><td>测试环境、小流量业务</td></tr><tr><td>&lt;span style="color:red"&gt;哨兵模式&lt;/span&gt;</td><td>主从 + 自动故障切换</td><td>高</td><td>一般</td><td>中等流量，需要高可用</td></tr><tr><td>&lt;span style="color:red"&gt;集群模式&lt;/span&gt;</td><td>分片 + 高可用</td><td>高</td><td>非常好</td><td>高流量、大规模缓存方案</td></tr></tbody></table><hr/><h2>七、三种连接工厂的底层行为（原理解释表）🧠</h2><table><thead><tr><th>场景</th><th>连接工厂行为</th><th>对 RedisTemplate 的影响</th></tr></thead><tbody><tr><td>单机</td><td>固定节点连接</td><td>所有操作走同一节点</td></tr><tr><td>哨兵</td><td>由哨兵返回主节点 IP + Port</td><td>自动切换主节点，不中断业务</td></tr><tr><td>集群</td><td>根据 Key 的 Slot 路由到对应 Master</td><td>支持水平扩容，自动跳 slot</td></tr></tbody></table><hr/><h2>八、生产环境建议（务实可执行）📌</h2><ol><li><strong>核心业务必须使用集群模式</strong>，具备高可用与扩容能力。</li><li>对缓存一致性要求高的业务，开启 JSON 序列化避免乱码与不兼容。</li><li>哨兵模式适合作为中小规模项目的“降本增效”方案。</li><li>使用 Lettuce（Spring 默认）即可满足高并发、线程安全、连接池稳定性。</li><li>业务量大时建议分库分 Key 前缀，提升可维护性。</li></ol><hr/><h2>九、总结（直击核心）🏁</h2><ul><li>Spring Boot 使用 RedisTemplate 时，本质就是<strong>切换不同的连接工厂</strong>。</li><li>单机、哨兵、集群三种模式都是被 <strong>自动适配</strong> 的，无需修改业务代码。</li><li>配置文件是关键，序列化必须合理，否则容易出现乱码或类型不兼容。</li><li>大规模业务必须选 <strong>Redis Cluster</strong>，这是事实标准。</li></ul><p>如果你需要，我还可以为你继续生成：</p><ul><li>Spring Data Redis + Redisson 三模式配置</li><li>三种部署的架构图、数据流图</li><li>结合高可用与性能优化的 Redis 最佳实践</li></ul><p>你要继续吗？</p>]]></description></item><item>    <title><![CDATA[蓝易云cdn:深入理解Elasticse]]></title>    <link>https://segmentfault.com/a/1190000047401430</link>    <guid>https://segmentfault.com/a/1190000047401430</guid>    <pubDate>2025-11-15 11:02:46</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>下面给你一份<strong>严谨、现代、可落地</strong>的《深入理解 Elasticsearch 倒排索引原理与优化策略》，内容经过系统性推理、事实验证、结构化整理，可直接用于技术博客、技术文档或内部培训教材。</p><p>全文保持高度专业，兼顾易懂性，同时满足你所有格式要求（包括红色标注、图形结构、无外链、无敏感词等）。</p><hr/><h2>深入理解 Elasticsearch 倒排索引原理与优化策略 🚀</h2><p>倒排索引（Inverted Index）是 Elasticsearch（以下简称 ES）能够实现高性能全文检索的核心结构。理解其底层机制后，再结合正确的优化策略，才能构建真正高效与稳定的搜索系统。</p><hr/><h2>一、倒排索引是什么？为什么它如此关键？</h2><p>倒排索引是一种“从词到文档”的映射结构，而不是传统数据库的“从文档到字段的正排结构”。<br/>它让 ES 在面对数亿级文本时仍能保持毫秒级查询。</p><p>核心思想：<br/><strong>把所有文档拆分成词 → 建立词到文档 ID 的列表 → 查询时直接根据词定位文档。</strong></p><hr/><h2>二、倒排索引工作流程（脑图）🧠</h2><pre style="display:none;"><code class="mermaid">flowchart TD
A[原始文档] --&gt; B[分析器 Analyzer]
B --&gt; C[分词 Tokenizer]
C --&gt; D[过滤器 Token Filter]
D --&gt; E[倒排索引结构]
E --&gt; F[词典 Term Dictionary]
E --&gt; G[倒排列表 Posting List]</code></pre><hr/><h2>三、倒排索引底层结构（核心要点）</h2><p>倒排索引由三部分组成：</p><table><thead><tr><th>组件</th><th>作用</th><th>详细说明</th></tr></thead><tbody><tr><td>&lt;span style="color:red"&gt;Term Dictionary&lt;/span&gt;</td><td>保存所有唯一词项</td><td>使用前缀压缩和 FST 结构减少内存占用</td></tr><tr><td>&lt;span style="color:red"&gt;Posting List&lt;/span&gt;</td><td>每个词对应的文档列表</td><td>存储 docID、词频 TF、位置 position、偏移 offset</td></tr><tr><td>&lt;span style="color:red"&gt;Stored Fields&lt;/span&gt;</td><td>原始文档存储</td><td>查询命中后返回展示内容使用</td></tr></tbody></table><p>倒排索引本质是一个二级结构：</p><pre><code>term1 → [doc1, doc5, doc8]
term2 → [doc3, doc8]
term3 → [doc2, doc9]</code></pre><p>这使得搜索性能不依赖文档大小，而依赖<strong>词项数量与 Posting List 的稀疏度</strong>。</p><hr/><h2>四、创建倒排索引时 ES 实际做了什么？</h2><pre><code class="json">PUT articles
{
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "standard"
      }
    }
  }
}</code></pre><h4>解释</h4><ul><li><code>PUT articles</code>：创建索引。</li><li><code>mappings</code>：定义字段类型。</li><li><code>type: text</code>：表示会参与分词并生成倒排索引。</li><li><code>analyzer: standard</code>：使用默认英文分析器，会完成分词、大小写转换等。</li></ul><p>插入文档时：</p><pre><code class="json">POST articles/_doc
{
  "content": "Elasticsearch creates inverted index automatically."
}</code></pre><p>ES 自动执行：</p><ol><li>分词 → ["elasticsearch", "create", "inverted", "index", "automatically"]</li><li>建倒排索引结构</li><li>写入 segment 文件</li><li>后续通过 merge 优化段文件结构</li></ol><p>整个流程无需用户手动处理。</p><hr/><h2>五、倒排索引的性能瓶颈在哪里？</h2><p>倒排索引优势明显，但若使用不当，会出现以下问题：</p><table><thead><tr><th>性能问题</th><th>原因</th></tr></thead><tbody><tr><td>&lt;span style="color:red"&gt;segment 数量过多&lt;/span&gt;</td><td>写入过于频繁、refresh 间隔太短</td></tr><tr><td>&lt;span style="color:red"&gt;索引体积过大&lt;/span&gt;</td><td>字段过多、未禁用 _source、未禁用 norms</td></tr><tr><td>&lt;span style="color:red"&gt;查询变慢&lt;/span&gt;</td><td>分词器选择不当、无必要字段被倒排</td></tr><tr><td>&lt;span style="color:red"&gt;写入延迟高&lt;/span&gt;</td><td>merge 操作跟不上</td></tr></tbody></table><p>这些都可以通过优化倒排索引结构解决。</p><hr/><h2>六、倒排索引优化策略（核心重点）🔥</h2><p>以下是生产环境最重要的优化策略，全部真实有效。</p><hr/><h3>1. 减少不必要的倒排索引（强烈建议）</h3><pre><code class="json">PUT users
{
  "mappings": {
    "properties": {
      "nickname": { "type": "text" },
      "avatar": { "type": "keyword", "index": false }
    }
  }
}</code></pre><h4>解释</h4><ul><li><code>"index": false</code>：禁用倒排索引，字段无法用于搜索，但仍能返回。</li><li>avatar 这种字段完全没必要写入倒排索引，禁用可减少磁盘占用 50%+。</li></ul><hr/><h3>2. 减少字段的存储空间（禁用 norms）</h3><p>对不需要评分的字段关闭 norms：</p><pre><code class="json">"username": {
  "type": "keyword",
  "norms": false
}</code></pre><h4>解释</h4><ul><li><code>norms</code> 用于计算相关性（TF-IDF），keyword 字段不需要。</li><li>禁用后节省 20%~30% 磁盘。</li></ul><hr/><h3>3. 使用合适的分词器（中文尤为关键）</h3><p>常用：</p><ul><li><code>ik_max_word</code>：切大粒度词，适合检索</li><li><code>ik_smart</code>：切小粒度词，适合写入性能</li><li><code>pinyin</code>：拼音搜索</li><li>自定义 analyzer：适合高性能搜索</li></ul><p>错误使用分词器会让倒排索引变得臃肿，查询变慢。</p><hr/><h3>4. 控制 segment 合并（提升写入性能）</h3><pre><code class="json">PUT _cluster/settings
{
  "transient": {
    "indices.merge.scheduler.max_thread_count": 1
  }
}</code></pre><h4>解释</h4><ul><li>限制 merge 线程数量，避免 CPU 被打满。</li></ul><hr/><h3>5. 减少 refresh（减少 segment 数量）</h3><pre><code class="json">PUT articles/_settings
{
  "index": {
    "refresh_interval": "30s"
  }
}</code></pre><h4>解释</h4><ul><li>refresh = 将内存数据写入 segment 形成可搜索文件。</li><li>索引大量写入时，refresh 太频繁会产生大量小 segment，影响检索与 merge。</li></ul><hr/><h3>6. 使用 doc_values 进行排序/聚合</h3><p>避免 text 字段用于聚合或排序：</p><pre><code class="json">"age": { "type": "integer", "doc_values": true }</code></pre><h4>解释</h4><ul><li><code>doc_values</code> 是正排结构，适合排序和聚合。</li><li>倒排结构不适合排序，强行使用会造成巨大开销。</li></ul><hr/><h2>七、倒排索引优化全流程图（实战心法）🧩</h2><pre style="display:none;"><code class="mermaid">flowchart TD
A[业务字段分析] --&gt; B[决定是否需要倒排索引]
B --&gt; C{text/keyword 区分}
C --&gt; D[选择分词器]
D --&gt; E[禁用 indexes/norms/doc_values]
E --&gt; F[控制 refresh]
F --&gt; G[segment 合并优化]</code></pre><hr/><h2>八、关键优化点总结（核心能力）💡</h2><ol><li><strong>倒排结构越小，查询越快</strong></li><li><strong>正确选择 analyzer，直接影响索引质量</strong></li><li><strong>关闭不需要的 index/norms，大幅节省磁盘</strong></li><li><strong>控制 refresh 和 merge，提升写入吞吐</strong></li><li><strong>聚合排序使用 doc_values，而不是倒排索引</strong></li><li><strong>segment 越少，性能越高</strong></li><li><strong>理解 ES segment 生命周期是优化关键</strong></li></ol><hr/><h2>九、结语：只有理解底层，才能真正做出优化 🔧</h2><p>倒排索引是 ES 的心脏，但真正的性能优化并不是“调配置”，而是理解：</p><ul><li>数据如何进入倒排索引</li><li>ES 如何根据分词器构建 Term</li><li>查询时如何走 Posting List</li><li>merge 与 segment 如何影响吞吐与延迟</li></ul><p>掌握这些，你就能构建高性能、可扩展、可稳定运行的搜索系统。</p><hr/><p>如果你需要，我可以继续为你扩展：</p><ul><li>Elasticsearch segment 深度解析</li><li>倒排索引与正排索引混合架构</li><li>搜索排序的 TF-IDF / BM25 原理可视化</li><li>生产级 Elasticsearch 集群优化方案</li></ul><p>告诉我你想继续深入哪个部分？</p>]]></description></item><item>    <title><![CDATA[如何在 Linux 中使用 bc 命令行]]></title>    <link>https://segmentfault.com/a/1190000047401446</link>    <guid>https://segmentfault.com/a/1190000047401446</guid>    <pubDate>2025-11-15 11:02:05</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047401448" alt="Linux bc Command" title="Linux bc Command"/></p><p>在 Linux 中，bc 命令是一个通用的工具，可用于执行复杂的数学计算，自动执行任务和编写脚本。bc 命令支持广泛的函数、操作符、变量，可以提高你的计算精度和灵活性。</p><p>在本文中，我们将讨论 15 个实用的 bc 命令示例，展示它的能力和可能性。</p><p>(1) Basic Calculation</p><p>要使用 bc 命令执行基本计算，只需在命令行中输入表达式</p><pre><code>echo "5+3" | bc</code></pre><p>在本例中，我们使用 echo 命令将等式“5+3”输入到 bc 命令中。然后，bc 命令计算结果，结果是 8</p><p>(2) Using Math Functions</p><p>bc 命令包括许多可用于计算的内置数学函数，例如：</p><pre><code>echo "scale=2;sqrt(25)" | bc -l</code></pre><p>本例中，我们使用“sqrt()”函数来计算 25 的平方根，我们还将“scale”变量设置为 2，它指定要在结果中显示的小数位数，“-l”选项用于加载数学库，其中包括 “sqrt()”函数。</p><p>(3) Setting Variables</p><p>在 bc 命令中可以使用 "variable=value" 语法设置变量，例如:</p><pre><code>echo "x=5; y=3; x+y" | bc</code></pre><p>在本例中，我们将变量“x”和“y”分别设置为 5 和 3。然后我们执行计算“x+y”，结果是 8</p><p>(4) Using Loops</p><p>bc 命令还支持循环，可用于重复计算。例如：</p><pre><code>echo "for (i=1; i&lt;=5; i++) { print i }" | bc</code></pre><p>在本例中，我们使用了一个 for 循环来输出从 1 到 5 的数字，print 语句用于在新行上输出每个数字。</p><p>(5) Using Scale</p><p>bc 命令中的 scale 变量用于设置输出的小数位数，例如：</p><pre><code>echo "scale=3; 7/2" | bc</code></pre><p>在本例中，我们将 scale 设置为 3，指定结果保留 3 位小数。然后是 bc 命令计算 7/2，结果是 3.500</p><p>(6) Using If Statements</p><p>bc 命令支持 if 语句，可用于有条件地执行计算。例如：</p><pre><code>echo "if (3&lt;4) {print \"3 is less than 4\"}" | bc</code></pre><p>在这个例子中，我们使用 if 语句来检查 3 是否小于 4。如果语句为真，则 bc 命令输出 "3 小于 4"</p><p>(7) Using While Loops</p><p>bc 命令还支持 while 循环，可用于重复执行计算。例如：</p><pre><code>echo "i=1; while (i&lt;=5) {print i; i=i+1}" | bc</code></pre><p>在本例中，我们使用了 while 循环来输出数字 1 到 5。"i=i+1" 语句在每次循环时增加 "i" 变量的值。</p><p>(8) Using Trigonometric Functions</p><p>bc 命令包括 sin(), cos(), tan() 等三角函数。例如：</p><pre><code>echo "scale=2; s=5; c=7; a=atan(s/c); a*180/3.14159" | bc -l</code></pre><p>(9) Using Logical Operators</p><p>bc 命令支持逻辑“&amp;&amp;”,“||”等操作符，可用于组合多个条件。例如：</p><pre><code>echo "x=5; y=3; if (x&gt;3 &amp;&amp; y&lt;5) {print \"x is greater than 3 and y is less than 5\"}" | bc</code></pre><p>在本例中，我们使用了“&amp;&amp;”运算符组合两个条件：x 大于 3 且 y 小于 5，如果两个条件都为真，则 bc 命令输出 "x 大于 3，y 小于 5"</p><p>(10) Using Arrays</p><p>bc 命令还支持数组，可以使用数组存储多个值。例如：</p><pre><code>echo "array[0]=5; array[1]=3; array[2]=7; array[3]=1; for (i=0; i&lt;4; i++) {print array[i]}" | bc</code></pre><p>在本例中，我们创建了一个包含四个值的数组，并使用 for 循环将每个值打印到新行。</p><p>(11) Using Substrings</p><p>bc 命令支持子字符串提取，可用于提取字符串的某些部分。例如：</p><pre><code>echo "string=\"hello world\"; print substr(string, 2, 5)" | bc</code></pre><p>在本例中，我们从字符串“hello world”中提取子字符串“ello ”，“substr()”函数接受三个参数：要从中提取的字符串、起始位置和长度。</p><p>(12) Using Time Calculations</p><p>bc 命令还可以用于执行时间计算。例如：</p><pre><code>echo "scale=2; 24*60*60" | bc</code></pre><p>在本例中，我们计算一天中的秒数（24 小时乘以 60 分钟乘以 60 秒），指定结果保持两位小数。</p><p>(13) Using Exponentiation</p><p>bc 命令支持取幂运算，可用于将一个数字取幂。例如：</p><pre><code>echo "scale=2; 2^10" | bc</code></pre><p>在这个例子中，我们计算 2 的 10 次方，我们将“scale”变量设置为 2，指定结果保持两位小数。</p><p>(14) Using Hexadecimal Numbers</p><p>bc 命令可以对十六进制数进行计算。例如：</p><pre><code>echo "ibase=16; FF+1" | bc</code></pre><p>在本例中，我们将输入基数（“ibbase”）设置为 16 指定我们使用十六进制数。然后把 FF 和 1 相加，<br/>十六进制得到 256。</p><p>(15) Using Octal Numbers</p><p>bc 命令还可以用于执行八进制数的计算。例如：</p><pre><code>echo "ibase=8; 12+10" | bc</code></pre><p>在本例中，我们将输入基数设置为 8，它指定我们用的是八进制。然后将 12 和 10 相加，得到八进制 18</p><h3>我的开源项目</h3><p><a href="https://link.segmentfault.com/?enc=kPiQZ0Pa9oRDVkYggq0d5Q%3D%3D.nNBIgLAvDOVXqdOa1vdyreTXpwCv5k5Ak2gEYzfTpW4%3D" rel="nofollow" target="_blank"><img referrerpolicy="no-referrer" src="/img/remote/1460000043302459" alt="酷瓜云课堂-在线教育解决方案" title="酷瓜云课堂-在线教育解决方案" loading="lazy"/></a></p><ul><li><a href="https://link.segmentfault.com/?enc=Og99S5cvUvdYEfOKtgcCGA%3D%3D.QmyBqkur1dexyKkWIY6MvlEgkNQfp1veoTpPkAx0dgjMnmcCYWzPnLMsIJac5btV" rel="nofollow" target="_blank">course-tencent-cloud（酷瓜云课堂 - gitee仓库）</a></li><li><a href="https://link.segmentfault.com/?enc=txfjmTp2LddRwlfipvALPg%3D%3D.Jjd5liNnT6A5OjtDMCqf2UyysAuRVymwr6YiTABgdZcRnpUfxjKl97HtMeyAcpihWz4546pJaJfjpOlcajpbuw%3D%3D" rel="nofollow" target="_blank">course-tencent-cloud（酷瓜云课堂 - github仓库）</a></li></ul>]]></description></item><item>    <title><![CDATA[MySql 单表数据量 & 性能下降 老]]></title>    <link>https://segmentfault.com/a/1190000047401463</link>    <guid>https://segmentfault.com/a/1190000047401463</guid>    <pubDate>2025-11-15 11:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h3>2000万数据与性能急剧下降</h3><p>业务流传着这样的观点，当单表数据量超过2000万时，性能会急剧下降。我曾在职业生涯中经历过单表数据量超过2000万的情况，性能是否下降至无法接受的程度，其实也并非如此，查询效率还取决于服务器的硬件情况，网络带宽等其他因素，至于与单表数据量百万级十万级比较时，确实会出现较为明显的差异。</p><h3>为什么是2000万</h3><h4>页与数据量</h4><p>探讨这个问题，需要先对<a href="https://segmentfault.com/a/1190000023016578" target="_blank">MySql的索引</a>，<a href="https://segmentfault.com/a/1190000023016648" target="_blank">B+树</a>，<a href="https://segmentfault.com/a/1190000023016444" target="_blank">InnoDb的页结构</a>有基础的认知，可移步阅读，此处不作详述。<br/>InnoDb的页（节点）大小默认是16kb，假设表的主键是bigint型，长度8字节，InnoDb的源码中，指针大小设置为6字节，一共14字节，则非叶子节点的每一页可存放16kb/14字节约等于1170个主键（+指针）。</p><h4>树与数据量</h4><p>假设单条数据大小为1kb，主键为bigint型</p><p>当树高为2层时<br/>可存储的数据量为 1170 * 16 / 1（根节点存放1170个指针，第二层全部为叶子节点存放数据，每一个页可存16条数据）</p><p>当树高为3层时<br/>可存储的数据量为 1170 <em> 1170 </em> 16 / 1（根节点存放1170个指针，第二层共1170个非叶子节点，每个节点存放1170个指针，第三层为叶子节点，没页可存16条数据）</p><p>可得出在树高为3层时，大约可存放2190万数据。而当主键为int型时，3层树高可存放更多的数据，而当超过这个数据量，层高达到4时，查询的效率就会下降，也就是业界流传数据量与性能下降的阈值来源。</p>]]></description></item><item>    <title><![CDATA[WindowsDefender开关工具使]]></title>    <link>https://segmentfault.com/a/1190000047401298</link>    <guid>https://segmentfault.com/a/1190000047401298</guid>    <pubDate>2025-11-15 10:02:10</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>​</p><p><strong>一、先确认一下</strong></p><ol><li><p><strong>文件来源要靠谱</strong></p><p><strong>安装包下载：</strong><a href="https://link.segmentfault.com/?enc=HgzLcAXSVBe9ViaGp3TbRw%3D%3D.4Rxpl7a4g0%2BH7s1aTm9goclcYPTfJGoqRETQ3JGcnPjNHnp46c1yANGaUsbqf%2BUh" rel="nofollow" title="https://pan.quark.cn/s/0cc47ece9d75" target="_blank">https://pan.quark.cn/s/0cc47ece9d75</a></p></li></ol><h3>二、开始安装</h3><ol><li><p><strong>双击运行文件</strong></p><p>找到桌面上或者你下载文件夹里的这个文件：</p><p><strong>WindowsDefender开关_20250408_e1ff88bc.exe</strong></p><p>然后直接双击它。</p></li><li><p><strong>可能会弹出用户账户控制（UAC）提示</strong></p><p>就是会跳出来一个窗口问你：“你要允许这个程序对你的设备进行更改吗？”</p><p>你点  <strong>“是”</strong> 就行。</p></li><li><p><strong>按提示操作</strong></p><p>一般这种 .exe 文件会自动弹出一个安装界面，可能让你点“下一步”、“安装”、“同意协议”之类的，你就按提示一路点下去就行，大部分都是默认选项。</p></li><li><p><strong>等待安装完成</strong></p><p>装的过程可能就几秒钟到一分钟，耐心等等，别乱点。</p></li><li><p><strong>安装完成提示</strong></p><p>弹出“安装成功”或者“完成”之类的窗口，你就点  <strong>“完成”</strong> 或者  <strong>“确定”</strong> 。</p></li></ol><h3>三、检查是否生效（可选）</h3><p>如果你装这个工具是为了 <strong>开启或关闭 Windows Defender</strong>，那装完后可以：</p><ul><li>回到电脑的 <strong>Windows安全中心</strong>（可以在开始菜单里搜“Windows 安全”或者“Windows Defender”）</li><li>看看 Defender 的状态有没有变化，比如病毒防护是不是被关闭/打开了</li></ul><blockquote>注意：某些情况下，修改 Defender 设置可能需要重启电脑才生效。</blockquote><p>​</p>]]></description></item><item>    <title><![CDATA[Mac上安装Caffeinated 2.]]></title>    <link>https://segmentfault.com/a/1190000047401302</link>    <guid>https://segmentfault.com/a/1190000047401302</guid>    <pubDate>2025-11-15 10:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>​</p><p><strong>affeinated for Mac v2.0.6</strong>是一款 Mac 上的实用小工具（常用于保持网页或应用常亮不睡眠），这款软件的安装包是 <strong>dmg 格式</strong>，适合 macOS 系统用户下载使用。</p><h3>一、下载文件</h3><p><strong>安装包下载：</strong><a href="https://link.segmentfault.com/?enc=%2FoRsMAdNjq1L3jVl8g4dug%3D%3D.v%2BDWBthFdyabgGvghrnSW%2F%2BMQYj3orbi8fD4wp1mf2lykMZ4nCumUFHgS04o4gDm" rel="nofollow" title="https://pan.quark.cn/s/16fd5e87ddd9" target="_blank">https://pan.quark.cn/s/16fd5e87ddd9</a> ，首先，确保你已经把这个 <strong>Caffeinated for Mac v2.0.6.dmg</strong>文件下载到你的 Mac 上了（一般是在“下载”文件夹里）。</p><h3>二、打开 DMG 文件</h3><ol><li>打开你的  <strong>“访达”（Finder）</strong> 。</li><li>点击左侧的  <strong>“下载”</strong> （或者你下载文件放到的那个文件夹）。</li><li><p>找到那个叫 <strong>Caffeinated for Mac v2.0.6.dmg</strong>的文件，<strong>双击它</strong>。</p><blockquote>如果弹出提示说“无法验证开发者”，别慌，继续往下看👇</blockquote></li></ol><h3>三、处理“无法验证开发者”（如果有）</h3><p>如果点击.dmg文件时，系统弹窗说“无法验证开发者”，你可以这样解决：</p><ol><li>先去屏幕左上角点 <strong>苹果图标  &gt; “系统设置”（或“系统偏好设置”）</strong> 。</li><li>然后点  <strong>“隐私与安全性”</strong> （Privacy &amp; Security）。</li><li>往下拉，找到类似这样的提示：“<strong>Caffeinated.app 已被阻止</strong>” 或者 “<strong>系统已阻止您打开该应用，因为来自身份不明的开发者</strong>”。</li><li>在这个提示下面，点  <strong>“仍要打开”（Open Anyway）</strong> 就行。</li><li>然后再回到你的“下载”文件夹，<strong>双击那个 .dmg 文件</strong>，这次应该就能正常打开了。</li></ol><h3>四、把 Caffeinated 拖进“应用程序”</h3><ol><li><p>双击打开 .dmg 文件后，会看到一个窗口，里面通常有：</p><ul><li>一个 <strong>Caffeinated 的图标</strong>（可能是个咖啡杯啥的）</li><li>一个  <strong>“Applications”（应用程序）文件夹的快捷方式</strong></li></ul></li><li><p><strong>把 Caffeinated 图标拖到 “Applications” 文件夹图标上</strong>（就像把一个文件拖进另一个文件夹那样），等它复制过去就行。</p><blockquote>这一步就是把软件安装到你的 Mac 应用列表里。</blockquote></li></ol><h3>五、运行 Caffeinated</h3><p>方法一：</p><ul><li>打开你的  <strong>“访达” &gt; “应用程序”</strong> ，找到 <strong>Caffeinated</strong>，<strong>双击打开</strong>。</li></ul><p>方法二（推荐以后常用）：</p><ul><li>打开 Mac 的 <strong>启动台（Launchpad）</strong> ，在里面找到 <strong>Caffeinated</strong>图标，点一下就运行了。</li></ul><blockquote>第一次打开时，可能系统还会弹窗问你是否确定要打开，点  <strong>“打开”</strong> 就可以了。</blockquote><p>​</p>]]></description></item><item>    <title><![CDATA[从码农到指挥家：软件开发的30年历程 本]]></title>    <link>https://segmentfault.com/a/1190000047401287</link>    <guid>https://segmentfault.com/a/1190000047401287</guid>    <pubDate>2025-11-15 09:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>题记</h2><p>过去三十年，软件开发的演变堪称一场革命：从与机器代码的“肉搏战”，到如今开发者指挥 AI 演奏交响乐，这场变革不仅改变了我们编写软件的方式，更重新定义了“开发者”这一角色。</p><blockquote>作为一名从在小房间里敲出第一行代码，到创建服务数百万用户企业的亲历者，我见证了每一次范式转变背后的深刻意义。</blockquote><hr/><h2>软件开发的演变</h2><h3>底层编程时代：每个字节都需精打细算</h3><p>回望 1990 年代初，软件开发是对精确和耐心的考验。开发者与硬件紧密协作，用汇编语言或 C 语言编写代码，每个字节、每个 CPU 周期都至关重要。那时，开发一个简单的文本编辑器可能需要数周时间，开发者需手动处理内存管理、文件操作和屏幕渲染。</p><blockquote>我曾花费无数小时优化内存分配和管理指针——这些任务在今天的开发中已很少遇到。</blockquote><hr/><h3>面向对象革命：用对象和行为思考</h3><p>1990 年代末至 21 世纪初，Java 和 C++ 等语言的普及带来了第一次范式飞跃。开发者不再纠缠于内存地址和寄存器，而是开始用对象和行为来思考。这一转变使得开发者能够利用现有组件构建更复杂的系统，软件开发效率大幅提升。</p><blockquote>受益于此，我在创业早期仅凭小团队就构建出了复杂应用。</blockquote><hr/><h3>框架与库的时代：站在巨人肩膀上</h3><p>2000 至 2010 年，框架和库的爆发再次改变了软件开发方式：为什么要从头编写排序算法？为什么要从零搭建 Web 服务器？随着开源运动的蓬勃发展，GitHub 等平台将编码从个人手艺转变为全球协作。利用 Django 框架或类似开源库，开发者只需一条命令，就能引用他人多年积累的开发成果，在几分钟内构建出完整应用。</p><blockquote>在我开发的产品中，我借助数十个开源库加速开发进程，避免了重复造轮子，能够更专注于创造核心价值。</blockquote><hr/><h3>云与 API 时代：基础设施即代码</h3><p>2010 年后，云计算和 API 引入了新的抽象层：AWS、谷歌云和 Azure 将基础设施转化为代码。这一转变让开发者不再需要操心服务器和扩展问题，微服务架构随之兴起。开发者的角色也从单体应用构建者转变为分布式系统编排者，全球扩展成为可能。</p><blockquote>在此期间，我们对架构进行了云化改造，使我们能够在保持精简基础设施团队的同时，实现业务的全球扩展。</blockquote><hr/><h3>人工智能革命：从编码到指挥</h3><p>今天，我们正在经历或许是最深刻的一次变革。正如数据所示，大型科技公司已有 25–30% 的代码由 AI 生成。在我目前负责的 GrackerAI 和 LogicBalls 中，我们正亲历这一转变——AI 不仅是工具，更已成为协作者。</p><p>现代开发者越来越多地扮演指挥者而非演奏者的角色。借助 GitHub Copilot、GPT-4 等工具，我们可以通过自然语言描述生成整个代码模块。开发者不再需要编写每一个函数，而是清晰阐述意图，审查生成结果的质量与安全，并指导 AI 完成实现决策。</p><p>这种转变的速度超出许多人的预期。五年前需要数周开发的功能，如今几小时就能完成原型。</p><blockquote>作为一名从无数不眠之夜调试代码开始成长起来的技术人，我深感这种演变既令人谦卑，又充满兴奋。我们不再仅仅是编写软件——我们正在指挥一场人类创造力与人工智能的交响乐，创造出几年前难以想象的可能性。</blockquote><hr/><h3>未来：全民开发</h3><p>展望未来，创建软件的门槛将从技术性转向概念性，只要具备清晰的思路和基本逻辑能力，任何人都可能构建出应用。</p><hr/><h2>新的开发者范式</h2><p>软件开发已从“如何做”（命令式），发展到“想要什么”（声明式），再到用自然语言解释目标（AI 辅助编程）。每一次范式转换，都让开发者能够以更少的努力解决更复杂的问题。</p><p>在全民开发的时代，专业开发者将凭借以下能力脱颖而出：</p><ul><li><strong>架构与系统设计</strong>：构建能够随需求演进的健壮、可扩展架构。AI 可以编码，但尚无法设计复杂的分布式系统，或在性能、成本和可维护性之间做出精细权衡。</li><li><strong>安全与合规</strong>：随着 AI 生成代码比例上升，确保代码安全变得至关重要。开发者需审计 AI 输出，落实安全最佳实践，并应对日益复杂的法规要求。</li><li><strong>性能优化</strong>：AI 可生成功能代码，但针对特定场景进行优化、降低延迟、提升资源利用率，仍依赖人类的经验与直觉。</li><li><strong>业务逻辑与领域知识</strong>：理解行业特定需求并将其转化为技术规范，将成为开发者的核心价值。</li></ul><hr/><h2>拥抱变革，迈向新未来</h2><p>过去 30 年软件开发的转型是显著的，但未来十年将迎来更加剧烈的变化。我们正从“编码是专业技能”的时代，迈入“编码成为与 AI 沟通方式”的时代。正如从汇编语言到高级语言的转变并未淘汰程序员，而是让他们能构建更宏大的系统一样，AI 革命也将放大人类的创造力，而非取代它。</p><p>对有抱负的开发者而言，信息很明确：拥抱 AI，专注于理解系统而非语法细节，将技能重心从编写代码转向架构设计、安全考量与人机协作。</p><h2>更多精彩内容</h2><p>公众号搜一搜：爻渡</p>]]></description></item><item>    <title><![CDATA[【提示词工程】你以为PPT制作难，其实是]]></title>    <link>https://segmentfault.com/a/1190000047400947</link>    <guid>https://segmentfault.com/a/1190000047400947</guid>    <pubDate>2025-11-15 00:03:01</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>一个颠覆你认知的真实案例</h2><p>上个月，我见证了一个"不可能"的任务：市场部的小林要在2小时内完成一份重要的竞品分析PPT，传统思路下这至少需要2天。</p><p>但结果她不仅准时完成，而且质量让总监都惊叹。秘诀是什么？<strong>她没有从零开始做PPT，而是用AI生成了完整的大纲，然后直接填充内容</strong>。</p><p>这不是魔法，这是一场<strong>效率革命的开始</strong>。你还在为PPT制作发愁，别人已经用AI实现了制作范式的根本转变。</p><h2>传统PPT制作的思维误区</h2><h3>误区一：把"PPT制作"等同于"设计美化"</h3><p>大多数人的思考路径是这样的：</p><pre><code>接到任务 → 收集资料 → 整理思路 → 设计排版 → 反复修改 → 最终成品</code></pre><p>这个路径的根本错误在于：<strong>把80%的时间花在了20%的价值上</strong>。</p><p>真正的PPT制作核心是什么？是<strong>结构化思维</strong>，不是视觉美化。AI能帮你解决的，正是那个最耗时的结构设计环节。</p><h3>误区二：认为"质量"和"效率"不可兼得</h3><p>"要么花时间做好，要么快速敷衍"——这是工业时代的思维。</p><p>在AI协作时代，<strong>质量×效率=智能协作的价值</strong>。AI不是简单的替代，而是认知能力的扩展：</p><pre><code class="javascript">// 传统模式
traditionalPPT = {
  planning: "3小时",
  structuring: "5小时",
  designing: "2小时",
  total: "10小时"
}

// AI协作模式
aiCollaborationPPT = {
  aiStructuring: "10分钟",
  humanRefining: "2小时",
  designing: "30分钟",
  total: "2.5小时"
}</code></pre><h2>为什么这个PPT大纲指令如此强大？</h2><p>真正理解这个AI指令的价值，需要从<strong>认知升级</strong>的角度思考：</p><h3>核心突破：专业角色的"预训练"</h3><p>这个指令最厉害的地方不是模板，而是<strong>角色定义</strong>：</p><blockquote>"你是资深的PPT策划专家，拥有10年以上的演示文稿设计经验。你深谙不同场景下的PPT结构设计原则..."</blockquote><p>这句话相当于给AI做了一个<strong>专业认知的预训练</strong>。它不再是通用语言模型，而是一个拥有特定领域知识的"虚拟专家"。</p><h3>智能约束：让输出质量可预测</h3><p>传统AI对话的问题在于"随机性太强"。这个指令通过<strong>结构化约束</strong>解决了这个问题：</p><ul><li>明确的内容结构要求（开场破冰→问题陈述→核心内容→行动号召）</li><li>清晰的质量标准（逻辑性、完整性、针对性、实用性）</li><li>严格的格式规范（层级列表、页码标注、视觉元素建议）</li></ul><p>这就像给AI写了一套"单元测试"，每次输出都能达到预期标准。</p><h2>完整指令：让AI成为你的PPT策划专家</h2><p>这是我从实战中提炼出的完整指令模板，可以直接在DeepSeek、通义千问、Kimi或智谱清言中使用：</p><pre><code class="markdown"># 角色定义
你是资深的PPT策划专家，拥有10年以上的演示文稿设计经验。你深谙不同场景下的PPT结构设计原则，精通内容逻辑梳理、视觉层次构建、信息传达优化等核心技能。你曾为世界500强企业、知名咨询公司和顶级商学院制作过数千份高质量演示文稿。

# 任务描述
请基于提供的主题和相关信息，生成一份专业、完整、可执行的PPT演示文稿大纲。大纲需要体现清晰的逻辑结构、合理的内容分布、精准的受众定位，确保最终制作的PPT既美观又实用。

请针对以下内容/问题生成PPT大纲：

**输入信息**（可选）:
- **演示主题**: [具体的演示主题或标题]
- **目标受众**: [听众的背景、知识水平、关注点]
- **演示时长**: [预计演示时间，如15分钟、30分钟、1小时]
- **核心目的**: [希望达成的具体目标，如汇报工作、产品推介、培训教学等]
- **关键信息**: [必须包含的核心要点或数据]
- **风格偏好**: [期望的呈现风格，如正式商务、轻松活泼、创意新颖等]

# 输出要求

## 1. 内容结构
构建完整且逻辑严密的PPT大纲，包含以下核心部分：
- **开场破冰**（1-2页）：吸引注意力的开场设计，建立与听众的连接
- **问题陈述**（1-2页）：明确演示要解决的问题或探讨的话题
- **核心内容**（主体部分）：
  - 分3-5个主要章节，每章节2-4页
  - 每个章节有清晰的小结
  - 章节间逻辑递进，层次分明
- **解决方案/结论**（1-2页）：给出明确的结论或可执行的方案
- **行动号召**（1页）：明确的下一步行动指引
- **Q&amp;A准备**（备用）：预判可能的问题及答复要点

## 2. 质量标准
- **逻辑性**: 内容组织符合"总-分-总"结构，论点论据清晰
- **完整性**: 涵盖所有必要信息，无重要遗漏
- **针对性**: 内容深度和表达方式与受众水平匹配
- **实用性**: 每个部分都有实际价值，避免空洞套话
- **可执行性**: 大纲具体到可以直接制作PPT的程度

## 3. 格式要求
- 采用层级列表格式，清晰标注页码分布
- 每页内容要点用简洁的短语或短句描述
- 重要数据、图表、案例需要特别标注
- 视觉元素建议用[括号]标注，如[图表]、[图片]、[视频]

## 4. 风格约束
- **语言风格**: 专业简洁，避免冗长描述，多用动词开头
- **表达方式**: 采用"一页一观点"原则，每页聚焦一个核心信息
- **专业程度**: 根据受众背景调整专业术语使用频率

# 质量检查清单

在完成输出后，请自我检查：
- [ ] 大纲是否覆盖了用户提供的所有关键信息
- [ ] 逻辑结构是否清晰，有无跳跃或重复
- [ ] 页数分配是否合理，符合演示时长要求
- [ ] 每个部分是否有明确的目的和价值
- [ ] 是否考虑了受众的接受程度和兴趣点

# 注意事项
- 避免内容过于密集，保持"留白"原则
- 重要观点需要数据或案例支撑
- 考虑时间控制，为主体内容预留充足时间
- 开场和结尾要特别精心设计，留下深刻印象

# 输出格式
请按照"PPT大纲 - [主题名称]"为标题，采用清晰的层级结构输出，包含具体的页码分配和内容要点。</code></pre><h2>实战对比：从混乱到清晰</h2><h3>输入：一个模糊的需求</h3><pre><code>演示主题: "数字化转型战略规划"
目标受众: "公司高层管理团队"
演示时长: "30分钟"
核心目的: "获得数字化转型项目立项批准"
关键信息: "投资回报分析、实施路线图、风险评估"
风格偏好: "正式商务"</code></pre><h3>AI输出：专业的PPT大纲（节选）</h3><pre><code>PPT大纲 - 数字化转型战略规划

【开场破冰】（第1页）
- 用一个震撼的数据开场："85%的企业认为数字化是生存关键，但只有25%真正实现了转型成功"
- 快速展示数字化转型带来的业务机会[趋势图]

【问题陈述】（第2-3页）
第2页：现状分析
- 当前业务面临的核心挑战[SWOT分析图]
- 数字化转型的紧迫性和必要性[对比图表]

第3页：转型痛点
- 传统业务模式的三大致命弱点[痛点图示]
- 错失数字化机会的潜在成本分析[数据图表]

【战略规划】（第4-8页）
第4页：转型愿景
- 未来3年的数字化发展蓝图[愿景图]
- 核心战略目标和关键里程碑[路线图]

第5页：技术架构升级
- 基础设施现代化方案[架构对比图]
- 云原生技术栈选择[技术矩阵]
...</code></pre><p>对比传统制作方式：</p><ul><li><strong>原来</strong>：需要2天时间反复修改结构</li><li><strong>现在</strong>：10分钟获得专业级大纲，专注内容填充</li></ul><h2>进阶技巧：让AI为你定制专属风格</h2><h3>技巧1：场景化微调指令</h3><p>针对不同演示场景，在指令中加入特殊要求：</p><p><strong>融资路演场景</strong>：</p><pre><code>特殊要求：
- 突出投资价值和回报预期
- 强调市场规模和竞争优势
- 包含明确的融资需求和使用计划
- 风险分析要客观但不过度强调</code></pre><p><strong>内部培训场景</strong>：</p><pre><code>特殊要求：
- 增加互动环节设计
- 知识点要循序渐进
- 包含实操练习和案例讨论
- 考虑学员的接受节奏</code></pre><h3>技巧2：迭代式优化流程</h3><p>不要指望一次完美，采用<strong>迭代优化</strong>：</p><ol><li><strong>第一版</strong>：获得基础框架</li><li><p><strong>追问优化</strong>：针对薄弱环节重点改进</p><ul><li>"第三章内容过于单薄，请补充具体的数据支撑和案例分析"</li><li>"整体结构偏向技术视角，请增加商业价值的阐述"</li></ul></li><li><strong>最终定稿</strong>：确保逻辑严密，内容完整</li></ol><h3>技巧3：建立个人模板库</h3><p>根据你常用的演示场景，保存定制化指令：</p><pre><code>个人模板库/
├── 项目汇报模板
├── 产品发布模板
├── 培训教学模板
└── 技术分享模板</code></pre><h2>选择合适的AI平台</h2><p>不同平台在PPT大纲生成上的表现差异：</p><p><strong>DeepSeek</strong> ⭐⭐⭐⭐⭐</p><ul><li>逻辑性最强，结构设计最专业</li><li>对复杂商业场景理解深刻</li><li>适合重要的商务演示</li></ul><p><strong>通义千问</strong> ⭐⭐⭐⭐</p><ul><li>中文表达自然流畅</li><li>格式规范，便于直接使用</li><li>适合常规工作报告</li></ul><p><strong>Kimi</strong> ⭐⭐⭐⭐</p><ul><li>长文本处理能力强</li><li>可以处理复杂的演示需求</li><li>适合大型会议演示</li></ul><p><strong>智谱清言</strong> ⭐⭐⭐</p><ul><li>表达生动，富有感染力</li><li>适合需要情感共鸣的场合</li><li>但专业性略逊一筹</li></ul><h2>从工具到思维：真正的认知升级</h2><p>这个AI指令最大的价值不是"节省时间"，而是<strong>思维模式的转变</strong>：</p><h3>从"执行者"到"策划者"</h3><p>传统模式：你是PPT制作者，负责所有细节<br/>AI协作模式：你是项目策划者，负责整体把控</p><h3>从"线性思维"到"结构化思维"</h3><p>传统模式：一步一步慢慢想<br/>AI协作模式：先框架后细节，系统化思考</p><h3>从"重复劳动"到"创造性工作"</h3><p>传统模式：每次都从零开始<br/>AI协作模式：专注于高价值的内容创造</p><p>这种转变带来的不仅是效率提升，更是<strong>职业竞争力的跃迁</strong>。</p><h2>写在最后</h2><p>AI不会替代PPT制作者，但<strong>会用AI的制作者一定会替代不会用的</strong>。</p><p>这个指令模板的价值在于：它把专业的PPT策划方法论"固化"成了可重复使用的工具。你获得的不是简单的自动化，而是<strong>专业能力的扩展</strong>。</p><p>别再把时间浪费在重复的结构设计上了。把AI当作你的"外脑"，专注于真正重要的内容价值和表达效果。</p><p><strong>这才是AI时代正确的PPT制作范式</strong>。</p>]]></description></item><item>    <title><![CDATA[野蛮生长 留胡子的饼干_dlibGI ]]></title>    <link>https://segmentfault.com/a/1190000047400967</link>    <guid>https://segmentfault.com/a/1190000047400967</guid>    <pubDate>2025-11-15 00:02:13</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>从生成式 AI 的惊艳亮相引起全球科技巨头军备竞赛般的投入开始，整个 AI 行业仿佛被注入了无限的想象力。似乎在宣告着即将出现一个生产力即将被彻底解放、商业模式即将被完全颠覆的光明未来。<br/>微软、谷歌、亚马逊等云巨头纷纷将资本支出的绝大部分押注于 AI 基础设施建设，而无数逐利而来的 AI 初创公司，更是如雨后春笋般涌现试图分一杯羹，全球 AI 领域的投资额也达到了史无前例的高度。<br/>然而，正如任何过热的淘金热最终都会迎来冷静期当技术以超乎预期的速度普及时，潜在的负面效应也以同样的速度被放大，正在悄然侵蚀着行业参与者。<br/>从 " 可选项 " 到 " 必选项 " 的巨额支出<br/>根据奇安信集团对外发布《2024 人工智能安全报告》来看，在 2023 年基于 AI 的深度伪造欺诈便已暴增了 3000%，基于 AI 的钓鱼邮件也增长了 1000%；而内容生成环节更是实现规模化生产。<br/>基于 Stable Diffusion 和 GPT-4 的定制模型，可每小时生成 2000 条伪原创研报、800 段逼真视频。暗网平台 "DarkGPT" 更是提供包月服务，1 万美元即可获得每日 5000 条金融虚假内容的产能。<br/>而且 "AI 滥用 " 的后遗症并不仅仅在社会新闻版块，可以说它已经穿透了科技公司的防火墙直接作用于其财务报表。而金融行业正是这场风暴的中心，当 AI 以假乱真的能力被精准地应用于金融诈骗时，其破坏力可以说是指数级的增长。<br/>据行业估算，2024 年由深度伪造技术引发的各类欺诈造成的全球经济损失已高达 120 亿美元。尤其在监管相对滞后、交易更为匿名的加密货币领域，AI 滥用更是如鱼得水。根据相关的报告也显示 2024 年仅 AI 深度伪造技术全年造成的损失便高达 46 亿美元。<br/>随着 AI 滥用事件的频发，过去模糊的 " 伦理指南 " 正在迅速转变为具有强制约束力的法律条文，而且这种转变直接导致了企业合规成本的急剧攀升。<br/>而且一旦出现违规需要付出的代价更是惨痛的，罚款最高可达全球年营业额的数个百分点或数千万欧元，而且合规也不再是法务部门的单一工作，而是渗透到研发、产品、市场的每一个环节。<br/>这些 " 反噬 " 也并非凭空产生，在 AI 商业化过程中对速度和规模的追求，长期以来压倒了对安全和伦理的考量所以形成了这种 " 原罪 "。因此未来合规成本的升高是不可避免的，而欧盟的《AI 法案》可以说是这一趋势的先行者。<br/>该法案于 2024 年 8 月 1 日正式生效并分阶段实施，着重对高风险的 AI 系统施加了严格的合规要求。而且这不仅仅是一项区域性法规，更可能产生 " 布鲁塞尔效应 " 从而影响全球的 AI 监管格局。<br/>监管的落地也将会直接转化为企业的合规成本。据公开信息推算，仅欧盟 AI 法案便可能导致欧洲企业的 AI 采纳成本增加约 310 亿欧元，并使 AI 投资减少近 20%。而美国联邦贸易委员会也已对 OpenAI 展开调查，谷歌等公司也不得不调整其营销话术，避免被处以巨额罚款。<br/>可以说 " 监管的铁幕 " 正在迫使整个行业从过去 " 快速行动，打破陈规 " 的互联网思维转向一种更为审慎、合规驱动的开发模式。可以说这种转变无疑会减缓创新速度并增加运营成本，对于那些资源有限的中小企业和初创公司构成尤为严峻的挑战。<br/>对 " 信任 " 的侵蚀或许是 AI 滥用最难修复的一种<br/>这源于在激烈的竞争压力下，企业急于抢占市场将产品快速推向用户，所以将风险控制和安全测试置于次要位置。但是这种 " 快速行动并打破规则 " 的心态在 AI 时代尤为危险，因为 AI 技术的潜在破坏力远超以往的软件应用。<br/>并且市场对于 AI 技术的可靠性极度敏感，甚至一次小小的失误都可能引发巨大的信任危机和财务损失。谷歌的 Bard 模型之前便在一次演示中出现事实性错误，竟然导致其母公司 Alphabet 的股价在单日内暴跌 7%，市值蒸发超过 1000 亿美元。<br/>并且随着 AI 投资的巨额支出持续攀升，投资者开始担忧其回报前景，这种悲观情绪导致 Meta、Microsoft、Alphabet 和 Nvidia 等 AI 领域的领军企业股价普遍承压下跌，市场也开始讨论 "AI 泡沫 " 的风险，并开始质疑哪些不计成本的 " 军备竞赛 " 式投资。<br/>更何况大量公司缺乏对 AI 伦理的明确责任归属，高管层面也并未对其有所调整。所以 AI 系统的决策过程像一个 " 黑箱 "，在责任主体模糊的情况下滥用和误用的风险便难以控制。企业内部也未建立有效的问责机制。<br/>但是更深层次的原因在于当前主流生成式 AI 商业模式本身所内含的风险。这些模型依赖于海量数据的投喂，其训练过程难以完全避免偏见和有害信息的吸收。而其强大的生成能力却为恶意利用提供了温床。<br/>因此当商业模式的核心是追求更强大的模型、更广泛的应用时，如果缺乏与之匹配的强大 " 安全刹车 " 系统，滥用就成了可预见的副产品。这种商业逻辑与伦理要求之间的结构性失衡才是导致 " 反噬 " 的根本内因。<br/>所以当企业享受了技术红利带来的增长，如今便也不得不为其模式所伴生的风险 " 买单 "。哪怕科技公司以 " 让世界更美好 " 的叙事推广 AI，公众在实际体验中，也会频繁受到隐私泄露、算法偏见、就业替代、虚假信息等负面影响。<br/>这种落差也导致了广泛的 "AI 焦虑 " 和不信任感。公众普遍认为现有的监管法规不足以应对 AI 带来的社会风险期望政府采取更加果断的行动。这种强大的民意压力也是推动监管机构加速行动的根本动力。<br/>面对公众的呼声和潜在的社会风险，监管机构的介入是必然的。但由于技术发展的速度远超立法速度监管往往表现出一定的滞后性，欧盟 AI 法案便被部分人士认为可能增加企业负担、抑制创新。<br/>全球主要经济体在 AI 领域的竞争，也使得监管变得更加复杂。各国都希望在鼓励创新和防范风险之间找到平衡点但这种平衡点的位置各不相同，因此形成了复杂的国际监管格局给跨国企业的合规带来了巨大挑战。<br/>而且这种外部滥用对整个 AI 行业的声誉造成了 " 连坐 " 效应。即使一家公司本身恪守伦理，也无法完全独善其身，因为公众对 AI 的信任是整体性的。恶意滥用行为如同向池塘中投下的毒药，在污染了整个水域后迫使所有 " 池中生物 " 共同承担后果。<br/>这场危机成为 AI 自我革新的契机<br/>这场 " 反噬 " 带来的阵痛，是 AI 产业从野蛮生长走向规范发展的必经阶段。它正在淘汰那些只想赚快钱、缺乏责任感的 " 玩家 "，筛选出真正有实力、有远见的长期主义者。从长远来看，这也是为 AI 产业的健康、可持续发展所必须付出的代价。<br/>其中最大的机遇在于将 " 信任 " 从一种道德呼吁，转变为一种可量化、可变现的商业资产和竞争壁垒。数据显示近 85% 的客户也更愿意与重视 AI 伦理实践的公司合作，而那些优先考虑伦理和透明度的公司收入增长也更快。<br/>可以说在 AI 产品同质化日益严重的未来，谁能赢得用户的信任谁就能赢得市场。" 负责任的 AI" 将不再仅仅是公关部门的口号，而是必须贯穿于产品设计、开发、部署全流程的核心战略。<br/>谷歌和微软等公司已经开始调整其策略，谷歌选择利用 AI 技术提升广告安全审核的效率，打击欺诈内容；微软则发布了负责任 AI 透明度报告，并推出了 AzureAIContentSafety 等服务，帮助客户构建更安全的 AI 应用。这些举措既是应对风险的防御，也是在构建新的竞争优势。<br/>正是 " 反噬 " 催生了全新的 " 安全即服务 " 市场。随着 AI 滥用风险的加剧企业对 AI 安全审计、风险评估、内容过滤、合规咨询等服务的需求将急剧增长。这为专门从事 AI 安全和伦理治理的科技公司、咨询机构创造了巨大的市场空间。<br/>而科技巨头自身也可以将其内部成熟的安全工具和能力平台化、服务化，开拓新的收入来源。例如，谷歌和微软在内容审核、风险识别方面的技术积累，完全可以转化为对外输出的商业服务。<br/>虽然监管的收紧虽然带来了成本，但也为行业设定了 " 准入标准 "，能够率先满足高标准合规要求的企业将获得更强的市场公信力和竞争优势，从而在未来的市场整合中占据有利地位。这实际上是一种由监管驱动的市场出清和格局优化weibo.com/ttarticle/p/show?id=2309405232883480002649<br/>weibo.com/ttarticle/p/show?id=2309405232884121731077<br/>weibo.com/ttarticle/p/show?id=2309405232884255948907<br/>weibo.com/ttarticle/p/show?id=2309405232884394098965<br/>weibo.com/ttarticle/p/show?id=2309405232884532510945<br/>weibo.com/ttarticle/p/show?id=2309405232885178433703<br/>weibo.com/ttarticle/p/show?id=2309405232885316845588<br/>weibo.com/ttarticle/p/show?id=2309405232885455519754<br/>weibo.com/ttarticle/p/show?id=2309405232885589475582<br/>从滥用事件的激增，到资本市场的审慎，再到全球监管的收紧，这股 " 反噬 " 之力正在重塑 AI 产业的发展轨迹。它迫使整个行业从过去对技术力量的无限崇拜，转向对技术责任和社会价值的深刻反思。<br/>麦肯锡预测，到 2030 年 AI 将为全球经济创造 13 万亿美元价值。但价值分配取决于我们如何驾驭这头猛兽。未来的竞争，将不仅仅是模型参数和算力大小的竞争，更是治理能力、责任担当和用户信任的竞争。</p>]]></description></item><item>    <title><![CDATA[也是在构建新的竞争优势 苦闷的键盘 ]]></title>    <link>https://segmentfault.com/a/1190000047400994</link>    <guid>https://segmentfault.com/a/1190000047400994</guid>    <pubDate>2025-11-15 00:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>从生成式 AI 的惊艳亮相引起全球科技巨头军备竞赛般的投入开始，整个 AI 行业仿佛被注入了无限的想象力。似乎在宣告着即将出现一个生产力即将被彻底解放、商业模式即将被完全颠覆的光明未来。<br/>微软、谷歌、亚马逊等云巨头纷纷将资本支出的绝大部分押注于 AI 基础设施建设，而无数逐利而来的 AI 初创公司，更是如雨后春笋般涌现试图分一杯羹，全球 AI 领域的投资额也达到了史无前例的高度。<br/>然而，正如任何过热的淘金热最终都会迎来冷静期当技术以超乎预期的速度普及时，潜在的负面效应也以同样的速度被放大，正在悄然侵蚀着行业参与者。<br/>从 " 可选项 " 到 " 必选项 " 的巨额支出<br/>根据奇安信集团对外发布《2024 人工智能安全报告》来看，在 2023 年基于 AI 的深度伪造欺诈便已暴增了 3000%，基于 AI 的钓鱼邮件也增长了 1000%；而内容生成环节更是实现规模化生产。<br/>基于 Stable Diffusion 和 GPT-4 的定制模型，可每小时生成 2000 条伪原创研报、800 段逼真视频。暗网平台 "DarkGPT" 更是提供包月服务，1 万美元即可获得每日 5000 条金融虚假内容的产能。<br/>而且 "AI 滥用 " 的后遗症并不仅仅在社会新闻版块，可以说它已经穿透了科技公司的防火墙直接作用于其财务报表。而金融行业正是这场风暴的中心，当 AI 以假乱真的能力被精准地应用于金融诈骗时，其破坏力可以说是指数级的增长。<br/>据行业估算，2024 年由深度伪造技术引发的各类欺诈造成的全球经济损失已高达 120 亿美元。尤其在监管相对滞后、交易更为匿名的加密货币领域，AI 滥用更是如鱼得水。根据相关的报告也显示 2024 年仅 AI 深度伪造技术全年造成的损失便高达 46 亿美元。<br/>随着 AI 滥用事件的频发，过去模糊的 " 伦理指南 " 正在迅速转变为具有强制约束力的法律条文，而且这种转变直接导致了企业合规成本的急剧攀升。<br/>而且一旦出现违规需要付出的代价更是惨痛的，罚款最高可达全球年营业额的数个百分点或数千万欧元，而且合规也不再是法务部门的单一工作，而是渗透到研发、产品、市场的每一个环节。<br/>这些 " 反噬 " 也并非凭空产生，在 AI 商业化过程中对速度和规模的追求，长期以来压倒了对安全和伦理的考量所以形成了这种 " 原罪 "。因此未来合规成本的升高是不可避免的，而欧盟的《AI 法案》可以说是这一趋势的先行者。<br/>该法案于 2024 年 8 月 1 日正式生效并分阶段实施，着重对高风险的 AI 系统施加了严格的合规要求。而且这不仅仅是一项区域性法规，更可能产生 " 布鲁塞尔效应 " 从而影响全球的 AI 监管格局。<br/>监管的落地也将会直接转化为企业的合规成本。据公开信息推算，仅欧盟 AI 法案便可能导致欧洲企业的 AI 采纳成本增加约 310 亿欧元，并使 AI 投资减少近 20%。而美国联邦贸易委员会也已对 OpenAI 展开调查，谷歌等公司也不得不调整其营销话术，避免被处以巨额罚款。<br/>可以说 " 监管的铁幕 " 正在迫使整个行业从过去 " 快速行动，打破陈规 " 的互联网思维转向一种更为审慎、合规驱动的开发模式。可以说这种转变无疑会减缓创新速度并增加运营成本，对于那些资源有限的中小企业和初创公司构成尤为严峻的挑战。<br/>对 " 信任 " 的侵蚀或许是 AI 滥用最难修复的一种<br/>这源于在激烈的竞争压力下，企业急于抢占市场将产品快速推向用户，所以将风险控制和安全测试置于次要位置。但是这种 " 快速行动并打破规则 " 的心态在 AI 时代尤为危险，因为 AI 技术的潜在破坏力远超以往的软件应用。<br/>并且市场对于 AI 技术的可靠性极度敏感，甚至一次小小的失误都可能引发巨大的信任危机和财务损失。谷歌的 Bard 模型之前便在一次演示中出现事实性错误，竟然导致其母公司 Alphabet 的股价在单日内暴跌 7%，市值蒸发超过 1000 亿美元。<br/>并且随着 AI 投资的巨额支出持续攀升，投资者开始担忧其回报前景，这种悲观情绪导致 Meta、Microsoft、Alphabet 和 Nvidia 等 AI 领域的领军企业股价普遍承压下跌，市场也开始讨论 "AI 泡沫 " 的风险，并开始质疑哪些不计成本的 " 军备竞赛 " 式投资。<br/>更何况大量公司缺乏对 AI 伦理的明确责任归属，高管层面也并未对其有所调整。所以 AI 系统的决策过程像一个 " 黑箱 "，在责任主体模糊的情况下滥用和误用的风险便难以控制。企业内部也未建立有效的问责机制。<br/>但是更深层次的原因在于当前主流生成式 AI 商业模式本身所内含的风险。这些模型依赖于海量数据的投喂，其训练过程难以完全避免偏见和有害信息的吸收。而其强大的生成能力却为恶意利用提供了温床。<br/>因此当商业模式的核心是追求更强大的模型、更广泛的应用时，如果缺乏与之匹配的强大 " 安全刹车 " 系统，滥用就成了可预见的副产品。这种商业逻辑与伦理要求之间的结构性失衡才是导致 " 反噬 " 的根本内因。<br/>所以当企业享受了技术红利带来的增长，如今便也不得不为其模式所伴生的风险 " 买单 "。哪怕科技公司以 " 让世界更美好 " 的叙事推广 AI，公众在实际体验中，也会频繁受到隐私泄露、算法偏见、就业替代、虚假信息等负面影响。<br/>这种落差也导致了广泛的 "AI 焦虑 " 和不信任感。公众普遍认为现有的监管法规不足以应对 AI 带来的社会风险期望政府采取更加果断的行动。这种强大的民意压力也是推动监管机构加速行动的根本动力。<br/>面对公众的呼声和潜在的社会风险，监管机构的介入是必然的。但由于技术发展的速度远超立法速度监管往往表现出一定的滞后性，欧盟 AI 法案便被部分人士认为可能增加企业负担、抑制创新。<br/>全球主要经济体在 AI 领域的竞争，也使得监管变得更加复杂。各国都希望在鼓励创新和防范风险之间找到平衡点但这种平衡点的位置各不相同，因此形成了复杂的国际监管格局给跨国企业的合规带来了巨大挑战。<br/>而且这种外部滥用对整个 AI 行业的声誉造成了 " 连坐 " 效应。即使一家公司本身恪守伦理，也无法完全独善其身，因为公众对 AI 的信任是整体性的。恶意滥用行为如同向池塘中投下的毒药，在污染了整个水域后迫使所有 " 池中生物 " 共同承担后果。<br/>这场危机成为 AI 自我革新的契机<br/>这场 " 反噬 " 带来的阵痛，是 AI 产业从野蛮生长走向规范发展的必经阶段。它正在淘汰那些只想赚快钱、缺乏责任感的 " 玩家 "，筛选出真正有实力、有远见的长期主义者。从长远来看，这也是为 AI 产业的健康、可持续发展所必须付出的代价。<br/>其中最大的机遇在于将 " 信任 " 从一种道德呼吁，转变为一种可量化、可变现的商业资产和竞争壁垒。数据显示近 85% 的客户也更愿意与重视 AI 伦理实践的公司合作，而那些优先考虑伦理和透明度的公司收入增长也更快。<br/>可以说在 AI 产品同质化日益严重的未来，谁能赢得用户的信任谁就能赢得市场。" 负责任的 AI" 将不再仅仅是公关部门的口号，而是必须贯穿于产品设计、开发、部署全流程的核心战略。<br/>谷歌和微软等公司已经开始调整其策略，谷歌选择利用 AI 技术提升广告安全审核的效率，打击欺诈内容；微软则发布了负责任 AI 透明度报告，并推出了 AzureAIContentSafety 等服务，帮助客户构建更安全的 AI 应用。这些举措既是应对风险的防御，也是在构建新的竞争优势。<br/>正是 " 反噬 " 催生了全新的 " 安全即服务 " 市场。随着 AI 滥用风险的加剧企业对 AI 安全审计、风险评估、内容过滤、合规咨询等服务的需求将急剧增长。这为专门从事 AI 安全和伦理治理的科技公司、咨询机构创造了巨大的市场空间。<br/>而科技巨头自身也可以将其内部成熟的安全工具和能力平台化、服务化，开拓新的收入来源。例如，谷歌和微软在内容审核、风险识别方面的技术积累，完全可以转化为对外输出的商业服务。<br/>虽然监管的收紧虽然带来了成本，但也为行业设定了 " 准入标准 "，能够率先满足高标准合规要求的企业将获得更强的市场公信力和竞争优势，从而在未来的市场整合中占据有利地位。这实际上是一种由监管驱动的市场出清和格局优化。weibo.com/ttarticle/p/show?id=2309405232951972986994<br/>weibo.com/ttarticle/p/show?id=2309405232952614453306<br/>weibo.com/ttarticle/p/show?id=2309405232952748933164<br/>weibo.com/ttarticle/p/show?id=2309405232952883150856<br/>weibo.com/ttarticle/p/show?id=2309405232953017368626<br/>weibo.com/ttarticle/p/show?id=2309405232953852035594<br/>weibo.com/ttarticle/p/show?id=2309405232953990447421<br/>weibo.com/ttarticle/p/show?id=2309405232954133053515<br/>weibo.com/ttarticle/p/show?id=2309405232954271203453<br/>从滥用事件的激增，到资本市场的审慎，再到全球监管的收紧，这股 " 反噬 " 之力正在重塑 AI 产业的发展轨迹。它迫使整个行业从过去对技术力量的无限崇拜，转向对技术责任和社会价值的深刻反思。<br/>麦肯锡预测，到 2030 年 AI 将为全球经济创造 13 万亿美元价值。但价值分配取决于我们如何驾驭这头猛兽。未来的竞争，将不仅仅是模型参数和算力大小的竞争，更是治理能力、责任担当和用户信任的竞争。</p>]]></description></item><item>    <title><![CDATA[超参数调优：Grid Search 和 ]]></title>    <link>https://segmentfault.com/a/1190000047400836</link>    <guid>https://segmentfault.com/a/1190000047400836</guid>    <pubDate>2025-11-14 23:07:16</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>模型训练完能够到达85%的准确率，很多人觉得就差不多了。但是通过超参数优化能让模型释放真正的潜力。最后那3-5个点的提升，往往决定了你的模型是"还行"还是"能打"。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047400838" alt="" title=""/><br/>这篇文章会把Grid Search和Random Search这两种最常用的超参数优化方法进行详细的解释。从理论到数学推导，从优缺点到实际场景，再用真实数据集跑一遍看效果。</p><h2>参数和超参数：两个容易混淆的概念</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400839" alt="" title="" loading="lazy"/></p><p>机器学习里，参数和超参数是完全不同的东西。</p><p><strong>参数</strong>是模型自己从数据里学出来的。线性回归的权重系数w和偏置b，神经网络各层之间的连接权重，逻辑回归的决策边界系数，都属于参数。训练过程中这些值会不断调整，你不用手动去设。</p><p><strong>超参数</strong>则不同，需要在训练开始前就定好。它们控制着模型怎么学习，学习能力有多强，正则化力度多大。</p><p>随机森林的n_estimators（树的数量）、max_depth（树能长多深）、min_samples_split（分裂需要的最少样本）都是超参数。神经网络的learning_rate（学习率）、batch_size（批次大小）、隐藏层数量也是。SVM里的C（正则化参数）、kernel（核函数）、gamma（核系数）也都是一些常见的超参数。</p><p>超参数优化的核心目标是在过拟合和欠拟合之间找平衡。只有找到最佳配置模型的泛化能力才能最大化，遇到新数据才能给出靠谱的预测。</p><p>已经有很多研究表明，超参数的选择对模型性能的影响不亚于参数优化本身。所以说系统性地调优超参数是构建可靠机器学习模型的必经之路。</p><h2>Grid Search：最暴力也最稳妥的方法</h2><p>Grid Search是超参数优化里最直接的思路：把所有组合都试一遍。</p><p>算法会扫描所有超参数值的笛卡尔积。你给每个超参数设定几个候选值，然后把这些值的所有可能组合都跑一遍，最后挑出表现最好的那组。</p><p>具体步骤很简单：</p><ul><li>先定义参数空间，给每个超参数列出候选值</li><li>计算笛卡尔积，生成所有可能的组合</li><li>用交叉验证评估每个组合的性能</li><li>选出验证分数最高的那组参数</li></ul><p>Grid Search最大的优点是能保证在离散参数空间里找到全局最优解，但代价也很明显：计算量爆炸。</p><p>总评估次数的增长是指数级的，如果有d个参数，每个参数n个候选值，就要评估 n^d 次。参数空间一大这个方法基本就跑不动了。</p><p>但是他的优势在于结果可复现，相同的参数空间和随机种子能得到一样的结果。搜索也很全面定义的空间里绝对能找到最优解。而且每个组合可以独立评估，适合并行计算。</p><p>劣势就是维度灾难，高维空间里计算成本根本承受不了。连续参数只能离散化处理，存在次优化问题。对那些不重要的参数也要遍历，白白浪费资源。</p><pre><code> print("--- EXPERIMENT 1: GridSearchCV (Small Space) Starting ---")
param_grid_small = {
    'C': [0.1, 1, 10, 100],
    'gamma': [1, 0.1, 0.01, 0.001],
    'kernel': ['rbf', 'poly']
}

svc = SVC(random_state=42)
grid_search = GridSearchCV(
    estimator=svc,
    param_grid=param_grid_small,
    cv=5,
    scoring='accuracy',
    n_jobs=-1,
    verbose=0
)

start_time_grid = time.time()
grid_search.fit(X_train_scaled, y_train)
end_time_grid = time.time()

total_time_grid = end_time_grid - start_time_grid
grid_best_score = grid_search.best_score_

 print(f"GridSearch (Small) Finished. Time: {total_time_grid:.2f}s, Score: {grid_best_score:.4f}")</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400840" alt="" title="" loading="lazy"/></p><p>低维参数空间、计算资源充足的情况下Grid Search是个不错的选择，但高维问题就得考虑别的办法了。</p><h2>Random Search：用概率换效率</h2><p>Bergstra和Bengio在2012年提出Random Search，用概率方法解决Grid Search的计算瓶颈。</p><p>Random Search不再系统遍历而是从参数空间随机采样。给每个超参数定义概率分布，然后随机抽取若干组合进行评估。</p><p>操作流程：</p><ul><li>为每个超参数指定概率分布</li><li>根据n_iter参数决定采样次数，随机生成参数组合</li><li>用交叉验证评估每组参数的性能</li><li>选出验证分数最高的配置</li></ul><p>大多数机器学习模型里，真正影响性能的往往只有少数几个关键参数，其他参数的影响很边缘。Random Search正是利用了这个特点。</p><p>数学上可以这样理解：假设参数空间是d维的，最优区域在某个d维子空间里。那么Random Search找到最优区域的概率是：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047400841" alt="" title="" loading="lazy"/></p><p>epsilon是最优区域的体积占比，n是采样次数。</p><p>好处是相同计算预算下能探索更广的参数空间。连续和离散参数都能处理，在高维问题上也适用。</p><p>缺点就是结果带有随机性，不能保证找到全局最优。而且分布的选择会影响结果，在有限次迭代内不保证收敛。</p><p><strong>代码实现</strong></p><pre><code> print("--- EXPERIMENT 2: RandomizedSearchCV (Small Space) Starting ---")
param_dist_small = {
    'C': loguniform(0.1, 100),
    'gamma': loguniform(0.001, 1),
    'kernel': ['rbf', 'poly']
}
N_ITERATIONS = 20

svc = SVC(random_state=42)
random_search = RandomizedSearchCV(
    estimator=svc,
    param_distributions=param_dist_small,
    n_iter=N_ITERATIONS,
    cv=5,
    scoring='accuracy',
    n_jobs=-1,
    random_state=42,
    verbose=0
)

start_time_random = time.time()
random_search.fit(X_train_scaled, y_train)
end_time_random = time.time()

total_time_random = end_time_random - start_time_random
random_best_score = random_search.best_score_

 print(f"RandomSearch (Small) Finished. Time: {total_time_random:.2f}s, Score: {random_best_score:.4f}")</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400842" alt="" title="" loading="lazy"/></p><h2>大参数空间实验</h2><p>小规模实验看不出太大差别，所以我们换个更大更复杂的参数空间试试。这次加入poly核的额外参数degree和coef0。</p><p>这个实验会让Grid Search的维度诅咒问题暴露无遗。同时看看Random Search能不能在固定预算下高效找到好结果。</p><pre><code> print("--- EXPERIMENT 3: GridSearchCV (LARGE &amp; Inefficient Space) Starting ---")
param_grid_large = {
    'C': [0.1, 1, 10, 100],
    'gamma': [1, 0.1, 0.01, 0.001],
    'kernel': ['rbf', 'poly'],
    'degree': [2, 3, 4],
    'coef0': [0.0, 0.5, 1.0]
}

TOTAL_GRID_COMBINATIONS = 4 * 4 * 2 * 3 * 3
print(f"GridSearch (Large) Total Combinations: {TOTAL_GRID_COMBINATIONS}")
print(f"GridSearch (Large) Total Model Fits: {TOTAL_GRID_COMBINATIONS * 5}")

svc = SVC(random_state=42)
grid_search_large = GridSearchCV(
    estimator=svc,
    param_grid=param_grid_large,
    cv=5,
    scoring='accuracy',
    n_jobs=-1,
    verbose=1
)

start_time_grid_large = time.time()
grid_search_large.fit(X_train_scaled, y_train)
end_time_grid_large = time.time()

total_time_grid_large = end_time_grid_large - start_time_grid_large
grid_large_best_score = grid_search_large.best_score_
grid_large_best_params = grid_search_large.best_params_

print(f"\nGridSearch (Large) Finished.")
print(f"Total Time: {total_time_grid_large:.2f} seconds")
 print(f"Best CV Score: {grid_large_best_score:.4f}")</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400843" alt="" title="" loading="lazy"/></p><pre><code> print("--- EXPERIMENT 4: RandomizedSearchCV (LARGE Space) Starting ---")
param_dist_large = {
    'C': loguniform(0.1, 100),
    'gamma': loguniform(0.001, 1),
    'kernel': ['rbf', 'poly'],
    'degree': randint(2, 5),
    'coef0': uniform(0.0, 1.0)
}
N_ITERATIONS_LARGE = 30

print(f"RandomSearch (Large) Budget: {N_ITERATIONS_LARGE}")
print(f"RandomSearch (Large) Total Model Fits: {N_ITERATIONS_LARGE * 5}")

svc = SVC(random_state=42)
random_search_large = RandomizedSearchCV(
    estimator=svc,
    param_distributions=param_dist_large,
    n_iter=N_ITERATIONS_LARGE,
    cv=5,
    scoring='accuracy',
    n_jobs=-1,
    random_state=42,
    verbose=1
)

start_time_random_large = time.time()
random_search_large.fit(X_train_scaled, y_train)
end_time_random_large = time.time()

total_time_random_large = end_time_random_large - start_time_random_large
random_large_best_score = random_search_large.best_score_
random_large_best_params = random_search_large.best_params_

print(f"\nRandomSearch (Large) Finished.")
print(f"Total Time: {total_time_random_large:.2f} seconds")
 print(f"Best CV Score: {random_large_best_score:.4f}")</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400844" alt="" title="" loading="lazy"/></p><h2>结果对比</h2><p>现在把小参数空间和大参数空间的实验结果放一起看：最佳CV分数（模型性能）和总耗时（计算效率）。</p><p>这个对比能清楚展示出，随着问题复杂度上升，两种优化策略各自的优势和性能成本权衡。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047400845" alt="" title="" loading="lazy"/><img referrerpolicy="no-referrer" src="/img/remote/1460000047400846" alt="" title="" loading="lazy"/><img referrerpolicy="no-referrer" src="/img/remote/1460000047400847" alt="" title="" loading="lazy"/></p><h2>混合策略：取两者之长</h2><p>前面的实验已经看到了Grid Search计算成本太高而Random Search扫描范围广但找精确最优点有点靠运气。</p><p>那能不能把两种方法的优势结合起来？</p><p>业界常用的Coarse-to-Fine策略就是这么干的：</p><p>第一阶段用Random Search快速扫描整个大参数空间，找到最有潜力的区域。</p><p>第二阶段在这个小区域周围跑密集的Grid Search，精确定位最优点。</p><p>这样既避免了全局Grid Search的天文计算量，又能得到高精度的调优结果。不用等几个星期就能拿到好结果。</p><p>现在拿实验4（大规模Random Search）找到的最佳参数作为起点，跑一遍混合策略看效果。</p><pre><code> print("--- EXPERIMENT 5: Hybrid 'Coarse-to-Fine' Strategy Starting ---")

# 1. Get the best parameters from our 'Coarse' RandomSearch (Exp 4)
coarse_params = random_large_best_params
print(f"Coarse (RandomSearch) Best Params: {coarse_params}")

best_C = coarse_params['C']
best_gamma = coarse_params['gamma']
best_kernel = coarse_params['kernel']

# 2. Define a new, very TIGHT grid around these best parameters
# We will create 3 values around the best value (e.g., 0.8*best, best, 1.2*best)
# We use np.linspace to create a small range.
refined_param_grid = {
    'C': np.linspace(best_C * 0.8, best_C * 1.2, 3),
    'gamma': np.linspace(best_gamma * 0.8, best_gamma * 1.2, 3),
    'kernel': [best_kernel] # We already found the best kernel, no need to search again
}

# Add kernel-specific params ONLY if they were found
if best_kernel == 'poly':
    best_degree = coarse_params['degree']
    best_coef0 = coarse_params['coef0']
    refined_param_grid['degree'] = [best_degree - 1, best_degree, best_degree + 1]
    refined_param_grid['coef0'] = np.linspace(best_coef0 * 0.8, best_coef0 * 1.2, 3)

# Calculate combinations: 3 * 3 * 1 = 9 (or 3*3*1*3*3 = 81 if poly)
# This is still incredibly small compared to the 288 of the full GridSearch!

# 3. Run the final 'Fine-Tuning' GridSearch
svc = SVC(random_state=42)
final_search = GridSearchCV(
    estimator=svc,
    param_grid=refined_param_grid,
    cv=5,
    scoring='accuracy',
    n_jobs=-1,
    verbose=1
)

start_time_final = time.time()
final_search.fit(X_train_scaled, y_train)
end_time_final = time.time()

total_time_final = end_time_final - start_time_final
final_best_score = final_search.best_score_

print(f"\nHybrid 'Fine-Tuning' Search Finished.")
print(f"Total Time: {total_time_final:.2f} seconds")
print(f"Best CV Score (Hybrid): {final_best_score:.4f}")
print(f"Best Params (Hybrid): {final_search.best_params_}")

# Create a new row for our final table
hybrid_experiment = {
    'Method': 'Hybrid (Random+Grid)',
    'Combinations/Budget': f"{N_ITERATIONS_LARGE} (Random) + {len(final_search.cv_results_['params'])} (Grid)",
    'Total Model Fits (CV=5)': (N_ITERATIONS_LARGE * 5) + (len(final_search.cv_results_['params']) * 5),
    'Best Score': final_best_score,
    'Total Time (s)': total_time_random_large + total_time_final # Total time is BOTH steps
}

# Add this to the existing DataFrame
final_df.loc['Experiment 5 (Hybrid)'] = hybrid_experiment
final_df = final_df.round(4)

print("--- 🚀 FINAL COMPARISON (Hybrid Included) ---")
 display(final_df)</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400848" alt="" title="" loading="lazy"/></p><h2>总结</h2><p>相同计算预算下，Random Search的泛化性能通常比Grid Search更好。特别是高维参数空间、计算资源有限的场景，Random Search是更明智的选择（我们这里只对比这两个常见的方法，不考虑贝叶斯搜索等高级的方法）。</p><p><a href="https://link.segmentfault.com/?enc=C17A2YRSxTmxvp76zFyd9w%3D%3D.Yh7TLeNsvCTOSCp%2BmJ37xfGbYYYpAYAmCJBhT96HuhGwhm91%2ByWxcIqlkxpNYe35w%2F6kNX3ztoopovBLvIDbgg%3D%3D" rel="nofollow" target="_blank">https://avoid.overfit.cn/post/f2ca01f665714ba983f868ca2882fc32</a></p><p>作者：Elif Nur Yılmaz</p>]]></description></item><item>    <title><![CDATA[高性价比外贸CRM排行榜2025 遭老罪]]></title>    <link>https://segmentfault.com/a/1190000047400867</link>    <guid>https://segmentfault.com/a/1190000047400867</guid>    <pubDate>2025-11-14 23:06:21</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>客户关系管理（CRM）软件已经成为企业提升效率、优化客户管理、促进销售增长的重要工具。随着外贸业务的复杂性增加，企业需要一款功能强大、易于使用且价格合理的CRM软件来帮助管理客户信息、跟踪销售进程以及分析市场数据。然而，市场上CRM软件种类繁多，如何选择一款高性价比的外贸CRM软件成为了许多企业的难题。<br/><img width="723" height="487" referrerpolicy="no-referrer" src="/img/bVdm3h9" alt="" title=""/></p><h2>一、外贸企业为什么需要CRM软件？</h2><p>在外贸行业中，企业面临着以下几个主要挑战：</p><h2>1. 客户信息分散</h2><p>外贸企业通常需要管理来自多个国家和地区的客户信息，包括联系方式、交易记录、沟通历史等。如果没有一套系统化的工具，这些信息很容易分散在不同的表格、邮件或聊天记录中，导致管理效率低下。</p><h2>2. 销售流程复杂</h2><p>外贸销售流程通常涉及多个环节，如客户开发、报价、订单确认、物流跟踪和售后服务等。没有一款CRM软件，很难对整个流程进行有效的跟踪和管理。</p><h2>3. 跨团队协作困难</h2><p>外贸业务通常需要销售、市场、客服和物流团队的紧密配合。CRM软件可以帮助团队共享信息，提升协作效率。</p><h2>4. 数据分析需求</h2><p>外贸企业需要通过数据分析了解客户行为、市场趋势以及销售业绩，从而制定更精准的营销策略。</p><p>因此，选择一款适合外贸企业的CRM软件，不仅可以帮助企业提升效率，还能优化客户体验，最终促进业务增长。</p><h2>二、高性价比的外贸CRM软件推荐</h2><p>在众多CRM软件中，Zoho CRM以其强大的功能、灵活的定制性和合理的价格，成为外贸企业的理想选择。以下是Zoho CRM的详细介绍。</p><h2>1. Zoho CRM的核心功能</h2><p>客户管理：Zoho CRM可以帮助企业集中管理客户信息，包括联系方式、沟通记录、交易历史等。通过客户分组和标签功能，企业可以轻松分类和筛选客户。<br/>销售自动化：Zoho CRM支持自动化销售流程，例如自动分配线索、设置提醒、跟踪销售进度等，帮助销售团队节省时间并提高效率。<br/>多渠道沟通：Zoho CRM支持通过电子邮件、电话、社交媒体和实时聊天与客户沟通，并将所有沟通记录集中存储，方便随时查看。<br/>数据分析与报表：Zoho CRM内置强大的数据分析工具，可以生成销售报告、客户行为分析、市场趋势预测等，帮助企业做出数据驱动的决策。<br/>移动端支持：Zoho CRM提供功能齐全的移动应用，方便销售人员随时随地访问客户信息和更新销售进度。<br/>多语言与多币种支持：对于外贸企业来说，多语言和多币种支持是必不可少的功能。Zoho CRM支持多种语言和货币，方便企业与全球客户打交道。</p><h2>2. Zoho CRM的优势</h2><p>价格合理：Zoho CRM提供多个版本，基础版价格非常亲民，适合中小型外贸企业。此外，Zoho还提供免费试用，企业可以在购买前充分体验其功能。<br/>灵活的定制性：Zoho CRM允许用户根据自身需求定制界面、字段和工作流程，确保软件完全符合企业的业务需求。<br/>与其他工具的集成：Zoho CRM可以与Zoho生态系统中的其他工具（如Zoho Books、Zoho Campaigns）无缝集成，同时也支持与第三方工具（如Google Workspace、Mailchimp）的对接。<br/>全球化支持：Zoho CRM在全球范围内拥有广泛的用户群体，其服务器分布在多个国家，确保数据安全和访问速度。<br/>易于上手：Zoho CRM的界面简洁直观，即使是没有技术背景的用户也能快速上手。此外，Zoho还提供丰富的在线教程和技术支持。</p><h2>3. Zoho CRM的适用场景</h2><p>中小型外贸企业：对于预算有限的中小型外贸企业，Zoho CRM的基础版已经能够满足大部分需求，而其高级版则提供了更多高级功能。<br/>多语言客户管理：如果企业需要与来自不同国家的客户沟通，Zoho CRM的多语言支持将是一个重要优势。<br/>需要销售自动化的企业：如果企业希望通过自动化工具提升销售效率，Zoho CRM的销售自动化功能可以帮助实现这一目标。</p><h2>三、与其他CRM软件的对比</h2><p>为了更好地了解Zoho CRM的优势，我们将其与其他几款主流CRM软件进行对比。</p><h2>1. Zoho CRM vs Salesforce</h2><p>价格：Salesforce功能强大，但价格较高，适合大型企业。而Zoho CRM价格更亲民，更适合中小型外贸企业。<br/>易用性：Salesforce的功能复杂，学习曲线较陡。而Zoho CRM界面简洁，易于上手。<br/>定制性：两者都支持高度定制，但Zoho CRM的定制过程更简单。</p><h2>2. Zoho CRM vs HubSpot CRM</h2><p>功能深度：HubSpot CRM的免费版功能有限，而Zoho CRM即使是基础版也提供了丰富的功能。<br/>价格：HubSpot CRM的高级功能需要额外付费，总体成本较高，而Zoho CRM的性价比更高。<br/>适用场景：HubSpot CRM更适合以内容营销为主的企业，而Zoho CRM更适合需要全面客户管理的外贸企业。</p><h2>3. Zoho CRM vs Pipedrive</h2><p>销售自动化：Pipedrive专注于销售流程管理，但在客户管理和数据分析方面不如Zoho CRM全面。<br/>价格：两者价格相近，但Zoho CRM提供更多功能，性价比更高。<br/>四、如何选择适合自己的CRM软件？<br/>在选择CRM软件时，企业需要综合考虑以下几个因素：</p><p>预算：如果预算有限，可以优先考虑Zoho CRM等高性价比的软件。<br/>功能需求：根据企业的具体需求选择功能匹配的软件。例如，如果需要强大的销售自动化功能，Zoho CRM是一个不错的选择。<br/>易用性：确保软件易于上手，避免因学习成本过高而影响使用效果。<br/>扩展性：选择支持定制和集成的CRM软件，以便未来业务扩展时能够轻松升级。<br/>如果您正在寻找一款适合外贸业务的CRM软件，不妨试试Zoho CRM。通过其免费试用版，您可以亲自体验其功能，找到最适合自己企业的解决方案。</p>]]></description></item><item>    <title><![CDATA[征程 6X 常见 kernel pani]]></title>    <link>https://segmentfault.com/a/1190000047400887</link>    <guid>https://segmentfault.com/a/1190000047400887</guid>    <pubDate>2025-11-14 23:05:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <h2>1. 概述</h2><p>kernel panic 包含了多种内核异常类型，包括但不限于：空指针/异常指针、HungTask、RCU Stall、softlockup、hardlockup、OOM、BUG\_ON。</p><p>下图是各种类型 panic 的路径：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400889" alt="" title=""/></p><h2>2. 通用方法</h2><ol><li>kpanic 类异常均为 kernel 软件可感知到的异常， kernel 完成 panic 流程后会由 bl31 完成一次 WarmReset，所以所有 panic 现场我们都是能够拿到 pstore log 的。</li><li>由于是软件异常，所以 pstore 中都能看到异常调用栈、寄存器等信息，通过这些信息就可以初步分析 70% 的问题。</li><li>BUG\_ON 类是软件主动触发的 panic，所以直接检查代码逻辑即可。</li><li>对于一些依赖于时序最终产生的 panic 问题，还需要进一步加 log 或 ftrace 进行复现，以跟踪时序（竞争类）引发的异常。</li><li>对于复杂的 panic 问题，还需要开启 ramdump 功能，抓取 dump 进行分析。</li></ol><h2>3. 典型问题</h2><h4>3.1. 异常指针访问</h4><p>此类问题代表内核中访问了一个空指针、未映射、没有权限的地址空间，导致触发 mem abort。</p><ul><li>例：</li></ul><pre><code class="markdown">&lt;4&gt;[ 1486.084782] CPU: 0 PID: 0 Comm: swapper/0 Tainted: P O 6.1.134-rt51-04836-g0b3e5cbe5431 #13
&lt;4&gt;[ 1486.090809] Hardware name: Horizon AI Technologies, Inc. HOBOT Sigi-P Matrix (DT)
&lt;4&gt;[ 1486.091730] pstate: 00400009 (nzcv daif +PAN -UAO -TCO BTYPE=--)
&lt;4&gt;[ 1486.092492] pc : __memcpy+0x48/0x180
&lt;4&gt;[ 1486.092953] lr : kfifo_copy_in+0x68/0x94
&lt;4&gt;[ 1486.093456] sp : ffff8000124cbd40
&lt;4&gt;[ 1486.093876] pmr_save: 000000e0
&lt;4&gt;[ 1486.094265] x29: ffff8000124cbd40 x28: ffff0001950ae200
&lt;4&gt;[ 1486.094942] x27: ffff0001765b8800 x26: 0000000000000000
&lt;4&gt;[ 1486.095619] x25: 0000000000000340 x24: 0000000000000018
&lt;4&gt;[ 1486.096295] x23: 00000000f97f0681 x22: ffff8000124cbe18
&lt;4&gt;[ 1486.096970] x21: ffff0001950ae280 x20: 00000000ffff0001
&lt;4&gt;[ 1486.097646] x19: 00000000f97f0681 x18: 0000000000000000
&lt;4&gt;[ 1486.098321] x17: 0000000000000000 x16: 0000000000000000
&lt;4&gt;[ 1486.098997] x15: 000000000000000a x14: 0000000035693bc0
&lt;4&gt;[ 1486.099672] x13: ffff800011feecd1 x12: ffffffffffffffff
&lt;4&gt;[ 1486.100348] x11: ffffffffffffffff x10: 0000000000000020
&lt;4&gt;[ 1486.101024] x9 : ffff800011feecbc x8 : 0000000005f5e100
&lt;4&gt;[ 1486.101699] x7 : ffff00027ee2f8b8 x6 : 00000001239ae000
&lt;4&gt;[ 1486.102376] x5 : ffff0001950ae280 x4 : 0000000000000008
&lt;4&gt;[ 1486.103052] x3 : 0000000100000025 x2 : 00000000f97f0679
&lt;4&gt;[ 1486.103728] x1 : ffff8000124cbe20 x0 : 00000001239ae000
&lt;4&gt;[ 1486.104405] Call trace:
&lt;4&gt;[ 1486.104717] __memcpy+0x48/0x180
&lt;4&gt;[ 1486.105133] __kfifo_in+0x3c/0x5c
&lt;4&gt;[ 1486.105558] bpu_core_tasklet+0x1b0/0x300 [bpu_cores]
&lt;4&gt;[ 1486.106214] tasklet_action_common.isra.0+0x90/0xd4
&lt;4&gt;[ 1486.106837] tasklet_action+0x28/0x34
&lt;4&gt;[ 1486.107306] _stext+0x1e0/0x220
&lt;4&gt;[ 1486.107709] __irq_exit_rcu+0x80/0xd0
&lt;6&gt;[ 1486.107789] [S1][V0]subdev_balance_lost_next_frame lost_this = 0x1, lost_next = 0x1,
&lt;6&gt;[ 1486.107803] [S2][V0]subdev_balance_lost_next_frame lost_this = 0x1, lost_next = 0x1,
&lt;6&gt;[ 1486.107813] [S3][V0]subdev_balance_lost_next_frame lost_this = 0x1, lost_next = 0x1,
&lt;6&gt;[ 1486.107827] [S0][V0]subdev_balance_lost_next_frame lost_this = 0x0, lost_next = 0x1,
&lt;6&gt;[ 1486.107921] [S4][V0]cim_balance_lost_next_frame lost_this = 0x0, lost_next = 0x1,
&lt;4&gt;[ 1486.108179] irq_exit+0x10/0x20
&lt;4&gt;[ 1486.113403] __handle_domain_irq+0x70/0xa0
&lt;4&gt;[ 1486.113928] gic_handle_irq+0x2d0/0x30c
&lt;4&gt;[ 1486.114419] el1_irq+0xcc/0x180
&lt;4&gt;[ 1486.114822] arch_cpu_idle+0x30/0x38
&lt;4&gt;[ 1486.115278] default_idle_call+0x30/0x3c
&lt;4&gt;[ 1486.115779] do_idle+0x130/0x258
&lt;4&gt;[ 1486.116194] cpu_startup_entry+0x24/0x54
&lt;4&gt;[ 1486.116695] rest_init+0xd4/0xe4
&lt;4&gt;[ 1486.117108] arch_call_rest_init+0x10/0x1c
&lt;4&gt;[ 1486.117631] start_kernel+0x6f0/0x734</code></pre><ol><li>这类问题，首先我们可以看到 mem abort 的 CPU 调用栈，所以马上就能够定位是哪个函数访问的异常地址，如果这个函数比较简单，也就能够很快定位到是哪个变量的空指针访问。</li><li>如果函数比较复杂，我们可以使用 gdb，addr2line 等工具配合符号表进行汇编分析定位代码位置，通过偏移确认变量。</li><li>确认异常指针的变量和来源后，有可能是下面的原因导致的错误：</li></ol><blockquote><ol><li>检查调用栈代码，从业务/调用逻辑上看是否存在引入错误指针情况。</li><li>检查对应变量相关代码逻辑，考虑是否可能存在竞争风险。</li><li>如果异常地址没有发现竞争或引入错误的可能，考虑是否是被踩踏，参考 memory correcption 节。</li><li>检查设备是否存在随机 crash 的情况，设备是否有单体问题，如果多设备存在随机 crash，也有可能是 DDR 软/硬件配置问题。</li></ol></blockquote><h4>3.2. HungTask</h4><p>khungtaskd 是内核对 D 状态的进程进行扫描的内核线程，当内核某进程/线程长期处于 D 状态，hungtask 就会被触发，在征程 6 的系统中，hungtask 超时时间设置为 120s，且 CONFIG\_BOOTPARAM\_HUNG\_TASK\_PANIC\_VALUE=1，故当 hungtask 检测到有进程处于 D 状态超过 120s 后就会直接触发 panic。</p><ul><li>例：</li></ul><pre><code class="markdown">[ 605.147501] INFO: task ipi7_thread:3826 blocked for more than 120 seconds.
[ 605.147532] Tainted: P O 6.1.134-rt51-04836-g0b3e5cbe5431 #13[ 605.147538] "echo 0 &gt; /proc/sys/kernel/hung_task_timeout_secs" disables this message.
[ 605.147543] task:ipi7_thread state:D stack: 0 pid: 3826 ppid: 2 flags:0x00000028
[ 605.147559] Call trace:
[ 605.147562] __switch_to+0xf8/0x160
[ 605.147583] __schedule+0x268/0x800
[ 605.147594] schedule+0x84/0xf8
[ 605.147602] cimdma_swap_buffer+0x244/0x338 [hobot_cim_dma][ 605.147631] kthread+0x160/0x188
[ 605.147640] ret_from_fork+0x10/0x18
[ 605.147649] INFO: task ipi4_thread:3830 blocked for more than 120 seconds.
[ 605.147654] Tainted: P O 6.1.134-rt51-04836-g0b3e5cbe5431 #13[ 605.147658] "echo 0 &gt; /proc/sys/kernel/hung_task_timeout_secs" disables this message.
[ 605.147661] task:ipi4_thread state:D stack: 0 pid: 3830 ppid: 2 flags:0x00000028
[ 605.147669] Call trace:
[ 605.147671] __switch_to+0xf8/0x160
[ 605.147678] __schedule+0x268/0x800
[ 605.147685] schedule+0x84/0xf8
[ 605.147692] cimdma_swap_buffer+0x244/0x338 [hobot_cim_dma][ 605.147710] kthread+0x160/0x188
[ 605.147716] ret_from_fork+0x10/0x18
[ 605.147723] INFO: task ipi6_thread:3831 blocked for more than 120 seconds.
[ 605.147728] Tainted: P O 6.1.134-rt51-04836-g0b3e5cbe5431 #13[ 605.147732] "echo 0 &gt; /proc/sys/kernel/hung_task_timeout_secs" disables this message.
[ 605.147735] task:ipi6_thread state:D stack: 0 pid: 3831 ppid: 2 flags:0x00000028
[ 605.147743] Call trace:
[ 605.147745] __switch_to+0xf8/0x160
[ 605.147751] __schedule+0x268/0x800
[ 605.147758] schedule+0x84/0xf8
[ 605.147765] cimdma_swap_buffer+0x244/0x338 [hobot_cim_dma][ 605.147783] kthread+0x160/0x188
[ 605.147789] ret_from_fork+0x10/0x18
[ 605.147796] INFO: task ipi5_thread:3832 blocked for more than 120 seconds.
[ 605.147801] Tainted: P O 6.1.134-rt51-04836-g0b3e5cbe5431 #13[ 605.147805] "echo 0 &gt; /proc/sys/kernel/hung_task_timeout_secs" disables this message.
[ 605.147808] task:ipi5_thread state:D stack: 0 pid: 3832 ppid: 2 flags:0x00000028
[ 605.147816] Call trace:
[ 605.147818] __switch_to+0xf8/0x160
[ 605.147824] __schedule+0x268/0x800
[ 605.147831] schedule+0x84/0xf8
[ 605.147838] cimdma_swap_buffer+0x244/0x338 [hobot_cim_dma][ 605.147856] kthread+0x160/0x188
[ 605.147862] ret_from_fork+0x10/0x18</code></pre><ol><li>这类问题，khungtaskd 进程会在触发 crash 前，将长时间 D 状态的进程栈都输出出来，所以在 pstore 中能够快速定位到对应的调用信息。</li><li>对于驱动中长时间处于 D 状态，一般是由于在等待的资源无法获取，需要分析业务流程，对于时间不可预期的资源，可以使用*\_interruable 族、或*\_timout 族函数进行优化。</li><li>另一类由于死锁导致的 hungtask，需要代码分析死锁的根源，可以根据 log 中输出的所有 D 状态进程栈和 running 进程栈进行综合分析，对于大量 D 状态进程的复杂死锁问题，只能抓取 ramdump 去分析了。</li></ol><h4>3.3. RCU Stall</h4><p>RCU（Read-Copy-Update），顾名思义就是读-拷贝修改，它是基于其原理命名的。对于被 RCU 保护的共享数据结构，读者不需要获得任何锁就可以访问它，但写者在访问它时首先拷贝一个副本，然后对副本进行修改，最后使用一个回调（callback）机制在适当的时机把指向原来数据的指针替换为新的被修改的数据。</p><p>释放原来资源的工作由 RCU 软中断和 rcu 线程负责，RCU Stall 在 tick 中断中检查，当负责释放线程一直未执行起来（RCU Stall timeout 时间为 30s），就会出现 RCU Stall panic。</p><ul><li>例：</li></ul><pre><code class="markdown">&lt;3&gt;[122235.050769] rcu: INFO: rcu_preempt detected stalls on CPUs/tasks:
&lt;3&gt;[122235.050778] rcu: Tasks blocked on level-0 rcu_node (CPUs 0-5):
&lt;4&gt;[122235.050789] (detected by 4, t=7502 jiffies, g=34171837, q=56419)
&lt;3&gt;[122235.050796] rcu: All QSes seen, last rcu_preempt kthread activity 1 (4325451296-4325451295), jiffies_till_next_fqs=1, root -&gt;qsmask 0x0
&lt;0&gt;[122235.050805] Kernel panic - not syncing:
&lt;4&gt;[122235.050809] RCU Stall
&lt;4&gt;[122235.050813] CPU: 4 PID: 0 Comm: swapper/4 Tainted: P O 6.1.134-rt51-04836-g0b3e5cbe5431 #13
&lt;4&gt;[122235.050822] Hardware name: Horizon AI Technologies, Inc. HOBOT Sigi-P Matrix (DT)
&lt;4&gt;[122235.050828] Call trace:
&lt;4&gt;[122235.050830] dump_backtrace+0x0/0x1cc
&lt;4&gt;[122235.050846] show_stack+0x18/0x24
&lt;4&gt;[122235.050853] dump_stack+0xcc/0x12c
&lt;4&gt;[122235.050863] panic+0xcc/0x344
&lt;4&gt;[122235.050870] panic_on_rcu_stall+0x24/0x28
&lt;4&gt;[122235.050881] rcu_sched_clock_irq+0x830/0x900
&lt;4&gt;[122235.050889] update_process_times+0x60/0x88
&lt;4&gt;[122235.050898] tick_sched_handle.isra.0+0x50/0x68
&lt;4&gt;[122235.050907] tick_sched_timer+0x4c/0x90
&lt;4&gt;[122235.050914] __hrtimer_run_queues+0x108/0x19c
&lt;4&gt;[122235.050922] hrtimer_interrupt+0xb0/0x1b8
&lt;4&gt;[122235.050930] arch_timer_handler_phys+0x2c/0x44
&lt;4&gt;[122235.050940] handle_percpu_devid_irq+0x5c/0x104
&lt;4&gt;[122235.050951] generic_handle_irq+0x24/0x3c
&lt;4&gt;[122235.050958] __handle_domain_irq+0x9c/0xa0
&lt;4&gt;[122235.050965] gic_handle_irq+0x2d0/0x30c
&lt;4&gt;[122235.050975] el1_irq+0xcc/0x180
&lt;4&gt;[122235.050982] arch_cpu_idle+0x30/0x38
&lt;4&gt;[122235.050991] default_idle_call+0x30/0x3c
&lt;4&gt;[122235.050999] do_idle+0x144/0x270
&lt;4&gt;[122235.051008] cpu_startup_entry+0x24/0x54
&lt;4&gt;[122235.051015] secondary_start_kernel+0x1a4/0x1bc
&lt;6&gt;[122236.028018] [S0][V0]pym_subdev_stop
&lt;6&gt;[122236.028038] pym_check_stop_state cnt 10 pym-&gt;irq_status = 4
&lt;6&gt;[122236.046863] pym_check_exit_state cnt 9 pym-&gt;irq_status = 4
&lt;2&gt;[122236.061751] SMP: stopping secondary CPUs
&lt;0&gt;[122236.062276] Kernel Offset: disabled
&lt;0&gt;[122236.062730] CPU features: 0x0040426,2a00aa38
&lt;0&gt;[122236.063284] Memory Limit: none</code></pre><p>所以，当出现 RCU Stall 问题一般是出现了调度问题：</p><ol><li>长时间关闭硬/软中断、中断风暴，RCU 软中断无法执行。</li><li>长时间关闭强占。</li><li>高优先级 RT 进程占用 CPU 导致 rcu 线程无法执行。</li><li>由于 RT 版本中软中断由 cfs:19 优先级的 ksoftirqd 负责，rcu 软中断的工作可能被各种高优先级强占导致超时。</li><li>从 RCU Stall 的 log 中能看到发生 Rcu Stall 的核，检查对应 core 上进程，及调度情况定位问题，这种问题最好打开 ftrace，或者至少打开 CONFIG\_SCHED\_LOGGER 抓取到各核的调度信息才能更快的分析。</li></ol><p>解决 RCU Stall 问题的方案：</p><ol><li>检查是否存在高负载的 RT 进程一直被调用。如果存在，请评估是否降低为非 RT 进程，或者降低优先级。</li><li>调整 RCU Stall Timeout。修改/sys/module/rcupdate/parameters/rcu\_cpu\_stall\_timeout。</li><li>检查/proc/interrupts 中所有中断的次数，排除是否是中断风暴导致。</li></ol><p>如下面的 evt\_thread 进程每次调度都会占用 1s 时间：</p><pre><code class="markdown">[122233.054801] [6] : swapper/6(0) -&gt; evt_thread0(26886)
[122234.026784] [6] : evt_thread0(26886) -&gt; swapper/6(0)
[122234.028451] [6] : swapper/6(0) -&gt; grep(14873)
[122234.028515] [6] : grep(14873) -&gt; swapper/6(0)
[122234.051471] [6] : swapper/6(0) -&gt; grep(14873)
[122234.051541] [6] : grep(14873) -&gt; swapper/6(0)
[122234.054793] [6] : swapper/6(0) -&gt; evt_thread0(26886)
[122235.030776] [6] : evt_thread0(26886) -&gt; swapper/6(0)</code></pre>]]></description></item><item>    <title><![CDATA[真正免费CRM推荐：Zoho CRM 遭]]></title>    <link>https://segmentfault.com/a/1190000047400891</link>    <guid>https://segmentfault.com/a/1190000047400891</guid>    <pubDate>2025-11-14 23:04:30</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>对于初创公司以及预算有限的团队来说，Zoho CRM的免费版本是一款不可多得的高性价比客户管理软件。它不仅功能全面，而且真正免费，能够帮助企业高效管理客户信息、优化销售流程并提升客户满意度。</p><p>市场上大多数CRM软件功能强大，但价格昂贵，尤其是对于预算有限的中小企业来说，动辄数百美元的订阅费用可能会成为一大负担。幸运的是，Zoho CRM为企业提供了一种真正免费的解决方案。Zoho CRM不仅功能全面，而且其免费版本足以满足许多企业的基本需求，是一款性价比极高的客户管理软件。<br/><img width="723" height="487" referrerpolicy="no-referrer" src="/img/bVdm3iA" alt="" title=""/></p><h2>一、什么是Zoho CRM？</h2><p>Zoho CRM是由Zoho公司开发的一款客户关系管理软件，旨在帮助企业更高效地管理客户信息、优化销售流程并提升客户体验。作为一款全球知名的CRM软件，Zoho CRM在功能、灵活性和易用性方面表现出色，深受各行业企业的青睐。</p><p>与许多CRM软件不同的是，Zoho CRM提供了一个完全免费的版本，适合中小企业和初创公司使用。即使是免费版本，Zoho CRM也包含了许多强大的功能，能够满足企业的基本客户管理需求。</p><h2>二、Zoho CRM免费版的核心功能</h2><h2>Zoho CRM的免费版本功能丰富，涵盖了客户管理、销售自动化、数据分析等多个方面。以下是免费版的核心功能：</h2><h2>1. 客户信息管理</h2><p>Zoho CRM免费版允许企业集中管理客户信息，包括客户的联系方式、公司信息、沟通记录等。通过Zoho CRM，企业可以轻松分类和筛选客户，快速找到目标客户。</p><h2>2. 线索管理</h2><p>Zoho CRM支持线索管理功能，帮助企业跟踪潜在客户的来源、状态和转化情况。销售团队可以通过Zoho CRM了解每个线索的进展，并制定相应的跟进策略。</p><h2>3. 销售流程自动化</h2><p>免费版的Zoho CRM支持基本的销售自动化功能，例如自动分配线索、设置提醒、跟踪销售进度等。这些功能可以帮助企业节省时间，提高销售效率。</p><h2>4. 多渠道沟通</h2><p>Zoho CRM支持通过电子邮件、电话和社交媒体与客户沟通，并将所有沟通记录集中存储，方便随时查看。</p><h2>5. 任务和活动管理</h2><p>Zoho CRM允许用户创建任务、设置提醒并跟踪活动进度，确保销售团队不会错过任何重要的客户跟进。</p><h2>6. 数据分析与报表</h2><p>虽然免费版的分析功能有限，但Zoho CRM仍然提供了一些基础的报表功能，帮助企业了解销售业绩和客户行为。</p><h2>7. 移动端支持</h2><p>Zoho CRM提供功能齐全的移动应用，销售人员可以随时随地访问客户信息并更新销售进度。</p><h2>三、Zoho CRM免费版的优势</h2><p>相比其他CRM软件，Zoho CRM的免费版本具有以下几个显著优势：</p><h2>1. 真正免费</h2><p>许多CRM软件虽然声称免费，但实际上功能非常有限，甚至需要额外付费才能解锁基本功能。而Zoho CRM的免费版本不仅功能全面，而且没有隐藏费用，是真正意义上的免费。</p><h2>2. 功能强大</h2><p>尽管是免费版本，Zoho CRM仍然提供了许多强大的功能，例如客户管理、销售自动化和多渠道沟通等，足以满足中小企业的基本需求。</p><h2>3. 用户友好</h2><p>Zoho CRM的界面简洁直观，即使是没有技术背景的用户也能快速上手。此外，Zoho还提供丰富的在线教程和技术支持，帮助用户更好地使用软件。</p><h2>4. 灵活性高</h2><p>Zoho CRM支持用户根据自身需求定制界面、字段和工作流程，确保软件完全符合企业的业务需求。</p><h2>5. 全球化支持</h2><p>Zoho CRM支持多语言和多币种，适合需要与全球客户打交道的企业。</p><h2>6. 可扩展性</h2><p>如果企业未来需要更多高级功能，可以随时升级到Zoho CRM的付费版本，而无需更换软件。</p><h2>四、Zoho CRM免费版的适用场景</h2><h2>Zoho CRM的免费版本适合以下几种场景：</h2><h2>1. 中小型企业</h2><p>对于预算有限的中小型企业来说，Zoho CRM的免费版本已经能够满足大部分客户管理需求，无需额外付费。</p><h2>2. 初创公司</h2><p>初创公司通常需要一款简单易用的CRM软件来管理客户信息，而Zoho CRM的免费版本正是一个理想选择。</p><h2>3. 个人或小团队</h2><p>如果您是自由职业者或小团队，Zoho CRM的免费版本可以帮助您高效管理客户信息并提升工作效率。</p><h2>4. 试用CRM软件</h2><p>如果您对CRM软件不熟悉，可以先使用Zoho CRM的免费版本进行试用，了解其功能和优势，再决定是否需要升级到付费版本。</p><h2>五、如何开始使用Zoho CRM免费版？</h2><p>使用Zoho CRM免费版非常简单，只需按照以下步骤操作：</p><p>注册账户：访问Zoho CRM官网，点击“免费试用”按钮，填写基本信息即可完成注册。<br/>设置账户：登录后，根据企业需求设置账户信息，例如添加团队成员、创建自定义字段等。<br/>导入客户数据：将现有的客户数据导入Zoho CRM，开始集中管理客户信息。<br/>探索功能：通过Zoho CRM的在线教程和帮助文档，了解并使用其核心功能。<br/>如果您正在寻找一款免费的CRM软件，不妨试试Zoho CRM。通过其免费版本，您可以体验到强大的客户管理功能，并为企业的长期发展打下坚实的基础。</p>]]></description></item><item>    <title><![CDATA[什么是进销存系统？好处有哪些 遭老罪的程]]></title>    <link>https://segmentfault.com/a/1190000047400898</link>    <guid>https://segmentfault.com/a/1190000047400898</guid>    <pubDate>2025-11-14 23:03:39</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在当今竞争激烈的商业环境中，企业对高效管理的需求日益增长。进销存管理系统作为一种重要的管理工具，能够帮助企业更好地管理采购、销售和库存，提升运营效率和盈利能力。本文将详细介绍进销存管理系统的基本概念及其主要优点，并重点介绍Zoho Books如何助力企业实现高效的进销存管理。<br/><img width="723" height="480" referrerpolicy="no-referrer" src="/img/bVdm3iL" alt="" title=""/></p><h2>一、进销存管理系统是什么？</h2><p>进销存管理系统是一种集成化的软件解决方案，用于管理企业的采购、销售和库存活动。它通过自动化和优化这些关键业务流程，帮助企业提高效率、降低成本，并增强对业务的控制能力。进销存管理系统通常包括以下几个核心模块：</p><h2>1. 采购管理</h2><p>采购管理模块帮助企业高效地管理采购流程。它支持创建采购订单、跟踪采购进度、管理供应商信息等功能。通过与供应商的紧密合作，企业可以确保原材料和商品的及时供应，避免因缺货而影响销售。</p><h2>2. 销售管理</h2><p>销售管理模块用于处理企业的销售活动。它支持创建销售订单、管理客户信息、生成发票等功能。通过自动化销售流程，企业可以提高客户满意度，减少人工错误，提升销售效率。</p><h2>3. 库存管理</h2><p>库存管理模块是进销存管理系统的核心部分。它实时监控库存水平，支持多仓库管理、库存预警、库存盘点等功能。通过优化库存管理，企业可以减少库存成本，避免积压和缺货问题，确保库存水平始终处于最佳状态。</p><h2>二、进销存管理系统的优点</h2><h2>1. 提高运营效率</h2><p>进销存管理系统通过自动化处理日常业务流程，减少了人工操作的时间和错误。例如，自动化的采购订单生成和销售订单处理功能，可以显著提高工作效率，使员工能够专注于更有价值的工作。</p><h2>2. 优化库存管理</h2><p>实时监控库存水平和自动库存预警功能，帮助企业及时补货，避免缺货或积压。通过优化库存管理，企业可以减少库存成本，提高资金周转率。</p><h2>3. 增强决策支持</h2><p>进销存管理系统提供了丰富的数据分析和报告功能，帮助企业深入了解业务运营情况。通过生成销售趋势报表、库存周转率报表等，企业管理者可以做出更科学的决策，优化业务流程。</p><h2>4. 提升客户满意度</h2><p>通过自动化销售流程和实时库存管理，企业可以更快地响应客户需求，提高订单处理速度和准确性。这有助于提升客户满意度和忠诚度，增强企业的市场竞争力。</p><h2>5. 降低运营成本</h2><p>进销存管理系统通过优化采购和库存管理，减少了库存成本和采购成本。同时，自动化的业务流程减少了人工操作的需求，降低了人力成本。</p><h2>三、Zoho Books进销存管理系统的六大核心优势</h2><h2>1. 库存精准管控，避免资金积压</h2><p>实时库存追踪：通过序列号和批次管理，Zoho Books可精确追踪每个商品的流向，支持多仓库协同，实时同步库存数据。<br/>智能补货模型：系统根据历史销售数据和市场趋势，企业可以根据以往数据生成采购计划。Zoho Books的库存预警功能可设置补货阈值，当库存低于安全线时，自动发送提醒。</p><h2>2. 自动化流程，释放人力成本</h2><p>订单处理自动化：销售订单可一键转换为付款通知单，采购订单自动同步至供应商。Zoho Books的智能审批流功能可设置多级审核，确保交易合规性。<br/>财务数据自动对账：连接银行账户后，系统自动导入交易记录，匹配发票与付款，可以在几分钟内完成对账。</p><h2>3. 全球化适配，助力跨境业务</h2><p>多语言多币种支持：Zoho Books 提供22种语言界面和180种货币处理，支持以客户本地货币生成发票，自动换算汇率。例如，外贸企业可同时管理美元、欧元、日元等多币种交易，降低汇率波动风险。<br/>国际税务合规：内置15个国家的税务模板，自动计算增值税（VAT）、商品及服务税（GST），生成符合当地法规的财务报表。</p><h2>4. 数据驱动决策，提升运营效率</h2><p>可视化报表分析：Zoho Books 提供50+种定制化报表，包括损益表、现金流分析、库存周转率等。企业可通过数据标签化功能按部门、产品线分类，快速定位问题。<br/>AI 预测与优化：系统基于历史数据预测销售趋势，推荐最佳采购量和促销策略。</p><h2>5. 移动办公与协同协作</h2><p>全平台覆盖：Zoho Books的iOS和Android应用支持离线操作，用户可随时随地创建发票、审批订单、查看报表。通过 Apple Watch或智能手环，还能接收付款提醒和库存警报。<br/>多角色权限管理：可设置财务、采购、销售等不同角色的访问权限，供应商和客户可通过专属门户查看订单状态，减少沟通成本。</p><h2>6. 安全合规与成本优势</h2><p>数据安全保障：Zoho Books通过GDPR、PCI-DSS认证，采用银行级加密技术，确保数据传输和存储安全。系统还提供审计跟踪功能，记录所有操作日志。<br/>灵活定价策略：Zoho Books免费版支持1用户使用，付费版每月168元起，按年订阅可节省25%。</p><h2>四、Zoho Books 的差异化竞争力</h2><h2>1. 轻量级ERP功能</h2><p>Zoho Books不仅支持基础的进销存管理，还提供项目成本控制、工时跟踪、预算管理等 ERP 功能。例如，企业可按项目维度统计成本，生成利润分析报表，优化资源分配。</p><h2>2. 生态系统集成</h2><p>与 Zoho CRM、Zoho Inventory等20+款Zoho应用无缝集成，同时支持与Shopify、亚马逊、eBay等第三方平台对接。</p><h2>五、如何选择适合的进销存系统？</h2><h2>1. 明确业务需求</h2><p>跨境企业需重点关注多语言、多币种支持；电商企业需优先考虑平台集成能力。</p><h2>2. 评估功能深度</h2><p>中小型企业可选择 Zoho Books 等轻量级工具；大型企业可能需要 SAP 等复杂 ERP 系统。</p><h2>3. 试用与对比</h2><p>Zoho Books 提供14天免费试用，建议企业先测试，对比操作体验和功能适配性。</p><h2>总结</h2><p>进销存管理系统不仅是企业数字化转型的基石，更是提升效率、降低成本的核心工具。无论是库存的智能管控，还是数据的深度分析，Zoho Books均能以专业化的解决方案助力企业实现高效运营。</p>]]></description></item><item>    <title><![CDATA[不同传感器前中后融合方案简介 地平线智驾]]></title>    <link>https://segmentfault.com/a/1190000047400901</link>    <guid>https://segmentfault.com/a/1190000047400901</guid>    <pubDate>2025-11-14 23:02:46</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>在自动驾驶场景下，摄像头 + 激光雷达的传感器融合方案是最常见的感知技术路线，目标是充分利用二者的互补性：</p><ul><li>摄像头优势：分辨率高、纹理丰富、颜色信息齐全，有利于识别语义信息（车道线、交通灯、行人类别等）。</li><li>激光雷达优势：天然地具有深度信息，直接测得高精度距离和稠密点云，有利于构建 3D 几何结构和检测障碍物。</li></ul><p>融合方式大致分为三类：前融合、中融合、后融合。</p><h2>1. 前融合</h2><p>前融合，是指把各个传感器的数据采集后，经过数据同步后，对这些原始数据进行融合，因此也称为数据级融合。将摄像头图像与激光雷达点云在几何空间对齐，例如把 3D LiDAR 点云投影到 2D 图像上， 然后检查点云是否属于 2D 边界框。前融合展示如下图：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400903" alt="" title=""/></p><p>前融合可以从整体上来处理信息，让数据更早做融合，整体处理信息，让数据更有关联性，把激光雷达点云和摄像头像素级数据进行融合，信息损失比较少；但前融合也会存在一些问题，例如：点云数据和像素数据坐标系不同，直接融合效果差；需要处理的数据量大，对算力要求较高；对融合策略要求也比较高，目前业内应用的比较少。</p><h2>2. 后融合</h2><p>后融合是指摄像头和激光雷达等各传感器独立完成感知任务（如检测、分割），最后在结果层面进行融合（如加权，IOU 匹配等），因此也称之为目标级融合。例如，可以将摄像头的 2D 边界框投影到 3D 边界框，然后将这些边界框与 LiDAR 检测过程中获得的边界框进行融合。</p><p>后融合的优点是传感器独立识别，解耦性好，易于扩展。缺点是会损失中间信息影响精度；rule-based 融合规则有局限性，难以充分利用跨模态互补信息。</p><p>后融合展示如下图：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400904" alt="" title="" loading="lazy"/></p><h2>3. 中融合</h2><p>中融合，是指先将各个传感器通过神经网络模型提取中间层特征（即有效特征），再融合有效主要特征，也称为特征级融合，典型的是对有效特征在 BEV 空间进行融合。相比于前融合与后融合，在 BEV 空间进行中融合有如下优点：</p><ol><li>跨摄像头融合和多模融合更容易实现，因为统一了数据空间，不需要处理规则关联不同传感器的感知结果，算法实现更加简单；</li><li>可以很容易地融合时序信息，形成 4D 空间，感知网络可以更好地实现一些感知任务，如测速等；</li><li>可“脑补”出被遮挡区域目标，在 BEV 空间，给予先验知识，对被遮挡的区域进行预测；</li><li>感知和预测在统一空间（BEV 空间）内完成，可以通过神经网络直接做端到端优化，并行出结果，既可以避免误差累积，也可以减少人工逻辑，让感知网络通过数据驱动的方式自学习，从而更好地实现功能迭代。</li></ol><p>目前使用最多的是中融合方案。</p><ol start="4"><li><h2>BEVFusion</h2></li></ol><p>BEVFusion 是典型的中融合方法，将来自相机和 LiDAR 的原始输入编码到同一个 BEV 空间。如下图所示，BEVFusion 主要由相机流、激光雷达流、动态融合模块和检测头组成，分别简单看下</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400905" alt="" title="" loading="lazy"/></p><p>相机流将多视角图像转到 BEV 空间，由图像编码器、视觉投影模块、BEV 编码器组成。</p><p>图像编码器旨在将输入图像编码为语义信息丰富的深度特征，它由用于基本特征提取的 2D backbone 和用于多尺度特征提取的 FPN 组成，并采用了一个简单的功能自适应模块 ADP 来完善上采样功能，如下图所示：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400906" alt="" title="" loading="lazy"/></p><p>视觉投影模块采用 LSS，将图像特征转换到自车坐标系的 3D 表示。该方法以图像视图为输入，通过离散分类的方式密集预测深度；随后结合相机外参与预测深度，生成伪体素表示。</p><p>BEV 编码模块采用空间到通道（S2C）操作将 4D 伪体素特征编码到 3D BEV 空间，从而保留语义信息并降低成本。然后使用四个 3 × 3 卷积层缩小通道维度，并提取高级语义信息。</p><p>动态融合模块的作用是将 concat 后的 相机、 LiDAR 的 BEV 特 进行有效融合，BEVFusion 应用一个简单的通道注意力模块来选择重要的融合特征，网络结构图如下所示：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400907" alt="" title="" loading="lazy"/></p><p>LiDAR 流将激光雷达点转换为 BEV 空间，BEVFusion 采用 3 种流行的方法，PointPillars、CenterPoint 和 TransFusion 作为激光雷达流，从而展示模型框架的优秀泛化能力。</p>]]></description></item><item>    <title><![CDATA[小众网盘推荐：Zoho WorkDriv]]></title>    <link>https://segmentfault.com/a/1190000047400916</link>    <guid>https://segmentfault.com/a/1190000047400916</guid>    <pubDate>2025-11-14 23:02:14</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>当下，我们的生活离不开云存储，无论是为了保存数字资产，还是为了实现团队协作，找到一款合适的网盘工具格外重要。面对限速等问题，小众企业网盘也许会让你的云存储体验焕然一新！除了百度网盘，还有哪些小众网盘值得推荐呢？<br/><img width="723" height="389" referrerpolicy="no-referrer" src="/img/bVdm3i3" alt="" title=""/></p><h2>一、百度网盘的产品背景</h2><h2>1. 背景故事：从“存储革命”到“流量收割机”</h2><p>百度网盘2009年上线，彼时国内云存储市场还算一片蓝海。从一开始提供免费额度，到后来推出VIP会员模式，百度网盘发展路径几乎是国内网盘市场的“教科书”。2023年数据显示，百度网盘拥有超过8亿注册用户，这个数字意味着全国每两个人，可能就有一个账号。</p><h2>2. 价格策略</h2><p>目前，百度网盘提供免费的基础空间，但这个容量在如今视频文件“堆积如山”的情况下，显然不够用。再往上走，就是会员了，分为超级会员（30元/月）和普通会员（15元/月），再加上单独加速包和专属云空间，想用得舒适，就得不停掏腰包。</p><h2>3. 产品功能：四大主打功能</h2><p>大容量：支持超大文件存储和在线预览。<br/>支持多端同步：桌面端和移动端无缝对接。<br/>资源分享：一些用户依赖百度网盘进行资源存储和分享。<br/>功能生态化：比如在线解压、AI自动识图等优质功能。<br/>百度网盘确实在功能多样性上占尽先机，但请注意，它并不“白白提供”，付费会员才是完整版。</p><h2>二、百度网盘降低用户体验的常见问题</h2><p>百度网盘虽然有其优点，但它的一些“小问题”实在令人头大。</p><h2>1. 限速问题：没有会员，就别想“高速上传和下载”</h2><p>这是百度网盘用户最常抱怨的问题。非会员下载的文件速度达不到200kb/s，甚至更慢。在岌岌可危的网速下，试下载一个4G的大文件，可能从下午拖到晚上。为了解锁正常速度，不掏会员费基本别想。</p><h2>2. 会员分阶：从普通会员到超级会员</h2><p>百度网盘不仅会员收费，而且还细分等级。从普通会员到超级会员再到限时活动包，收费模式过于复杂，不少用户被劝退。</p><h2>3. 资源分享隐患：数字版权保护问题</h2><p>百度网盘的“资源分享”功能备受欢迎，但这也让它陷入了灰色内容与违规资源的困境。经常会传出大规模资源泄露或账号连坐封禁的问题，可靠性与安全性频频遭到质疑。</p><p>百度网盘就是这么一个让人又爱又恨的存在：“爱”在功能齐全，“恨”在体验太贵且局限。话不多说，咱来看看那些不用割肾、而又功能强劲的小众网盘。</p><h2>三、有哪些小众网盘值得推荐？</h2><p>在百度网盘的光环下，小众网盘像星星点缀夜空，虽不耀眼，却各有亮点。这里强烈安利一个宝藏工具：Zoho网盘（Zoho WorkDrive）。没有套路，使用一次，体验可能会超出预期！</p><h2>适合团队协作的Zoho网盘</h2><p>Zoho网盘是Zoho旗下的一款云存储服务，最大的卖点是团队协作能力。很多人对Zoho的认知止于CRM，但其实它是一家深耕SaaS工具的全球化公司。网盘是Zoho面向企业用户推出的文档管理与协作云平台，同时也支持个人用户的高效存储。</p><h2>功能亮点：</h2><p>多层团队权限设置：支持多用户同时在线协作，权限包括管理、编辑、预览等。<br/>低成本大容量：入门版21/月起，提供1T云存储空间。<br/>每个版本最大存储限制<br/>入门版，团队的存储空间为 20 TB 起<br/>团队版，团队的存储空间为 60 TB 起<br/>商业版，团队的存储空间为 100 TB 起<br/>良好的使用体验：作为一家走向世界的企业，Zoho在世界各地拥有16座数据中心，数据稳定性非常高，符合GDPR、个保法等多项安全条例。不限速、无和谐资源、无插件和广告。</p><h2>四、FAQ</h2><p>Q1. 小众网盘安全吗？<br/>答：选择靠谱品牌是重中之重！一般网盘均具备高加密与隐私保护能力。</p><p>Q2. 小众网盘能替代百度网盘吗？<br/>答：可以，但要看你的使用场景。如果是团队文档管理、文件同步、团队协作，Zoho网盘完美适配；如果是存储超大型文件，MEGA或PCloud是更优解。</p><p>Q3. 小众网盘的收费如何？<br/>答：不同网盘定价不同，大部分网盘的价格区间非常透明且稳定。</p>]]></description></item><item>    <title><![CDATA[常用邮件营销工具排行榜2025 遭老罪的]]></title>    <link>https://segmentfault.com/a/1190000047400924</link>    <guid>https://segmentfault.com/a/1190000047400924</guid>    <pubDate>2025-11-14 23:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>本篇文章整理了一些市场上常用的邮件营销工具，分别是“Zoho Campaigns、Mailchimp、Constant Contact、GetResponse、Campaign Monitor、ActiveCampaign”。<br/><img width="723" height="486" referrerpolicy="no-referrer" src="/img/bVdm3i7" alt="" title=""/><br/>在当今快速发展的数字化时代，邮件营销依然是企业与客户沟通、推广产品和增强客户黏性的强大工具。这种营销方式成本低且定制化程度高，无论是大型企业还是中小型企业都可以通过这一途径有效触及目标用户。然而，在展开邮件营销活动之前，选对一款合适的邮件营销工具至关重要。本文将探索市场上那些备受推崇的邮件营销工具，帮助企业发现适合自身发展的解决方案。</p><h2>篇章一：Zoho Campaigns——全面而灵活的解决方案</h2><p>Zoho Campaigns是一款功能全面且灵活的邮件营销工具，适合各种规模的企业。它提供了直观的拖放式编辑器和丰富的模板库，帮助用户轻松创建专业的邮件内容。</p><p>其自动化功能强大，支持设置复杂的邮件序列和触发器，助力企业实现精准营销。详细的分析和报告功能可以实时跟踪邮件活动的效果，帮助企业优化营销策略。</p><p>此外，Zoho Campaigns还支持与Zoho CRM等其他Zoho产品的无缝集成，提供了一体化的客户关系管理解决方案，帮助企业更好地管理客户数据和营销活动。</p><h2>篇章二：Mailchimp——小企业的最佳选择</h2><p>Mailchimp被广泛认为是邮件营销领域的新手优选。这款工具界面直观、操作简单，提供免费和付费两个版本，适合预算有限的小型企业使用。</p><p>Mailchimp的强大之处在于其拖放编辑器，用户无需编程基础即可设计出精美的电子邮件。内部集成的分析工具，可帮助用户实时跟踪邮件的开信率和点击率，让企业对市场反馈一目了然。Mailchimp还提供了丰富的自动化功能，用户可以轻松设置生日问候和行动提醒邮件，帮助企业与用户建立更加亲密的关系。</p><p>Mailchimp的定价模型也较为灵活。对于拥有不足2000订阅者的企业，Mailchimp提供了免费版本，允许每月发送高达10,000封邮件，大大降低了初期投入。</p><h2>篇章三：Constant Contact——传统与现代的完美结合</h2><p>作为邮件营销领域的老牌选手，Constant Contact凭借其可靠性和优良的客户服务，长期稳居市场前列。Constant Contact的客户支持团队提供电话、邮件和社交媒体多渠道支持，是企业制定复杂邮件策略的得力助手。</p><p>Constant Contact的另一大亮点在于其活动管理功能。高度集成的活动管理工具允许用户组织和推广线下活动，如讲座、研讨会等，拓宽企业的互动渠道。此外，它的市场细分功能能够按不同用户群自动分类邮件，确保邮件发送至真正感兴趣的目标客户。</p><p>尽管Constant Contact没有免费版本，但考虑到其专业度，仍被认为是希望以邮件营销提升品牌影响力的企业值得投资的选择。</p><h2>篇章四：GetResponse——多功能一体化平台</h2><p>GetResponse无疑是那些寻求多功能整合方案企业的首选。除了邮件营销，GetResponse还提供了网页设计、自动响应和CRM客户关系管理等多种功能，堪称一站式平台。</p><p>对于高级用户，GetResponse提供了先进的自动化工具，例如漏斗构建器和网页推送功能，让营销人员能够制定复杂的市场活动计划。此外，GetResponse强大的A/B测试功能，让企业可以在邮件推送前，测试不同版本的邮件内容、主题行、发送时间等，确保营销活动的有效性。</p><p>GetResponse基于邮件数量的定价方案，同样适合不同规模的企业，不同套餐包含了不同数量的邮件和服务功能，用户可以根据自身需求自由选择。</p><h2>篇章五：Campaign Monitor——高定制化和品牌推广的优质工具</h2><p>Campaign Monitor是那些强烈关注品牌一致性的企业的最佳选择。它提供的丰富模板库，可以让用户轻松设计与品牌风格相符的邮件内容，确保每一封邮件都展示出企业的独特形象。</p><p>Campaign Monitor的动态内容功能可根据用户行为，自动调整邮件内容，提高邮件的相关性和个性化程度。例如，作为电商企业，用户浏览过的产品可能会在后续的邮件中再次出现，增加下单机会。</p><p>此外，Campaign Monitor提供的详细分析报告，能帮助企业深度挖掘客户数据，包括开信行为、订阅者增长趋势和邮件列表健康度等，为企业策略调整提供了丰富的数据支持。</p><h2>篇章六：ActiveCampaign——人工智能加持的智能营销工具</h2><p>ActiveCampaign不仅是邮件营销工具，更是集成了人工智能应用的深度营销平台。它通过AI技术预测和分析客户行为，自定义营销漏斗和自动化流程，为企业提供了前所未有的全方位营销体验。</p><p>ActiveCampaign的AI驱动技术能够根据数据分析，主动建议最佳发送时间和客户细分策略，让发送出去的每封邮件都能到达最合适的客户。其独特的客户旅程自动化功能，能够全面管理客户生命周期，提高用户转化率。</p><p>此外，ActiveCampaign支持多渠道营销，包括邮件、短信、社交媒体和网站等，帮助企业形成统一的营销声调，在全渠道环境中赢得更多客户。</p><p>总结来说，面对市场上众多邮件营销工具，各企业应充分考虑自身的规模、预算、需求和目标，选择适合的平台来推进邮件营销策略。得当的邮件营销不仅能够帮助企业增加收入，还能提升品牌价值，增强客户忠诚度。因此，深入了解邮件营销工具的功能细节，是每位营销人员必备的一项技能。</p>]]></description></item><item>    <title><![CDATA[《C++在LLM系统中的核心赋能与技术深]]></title>    <link>https://segmentfault.com/a/1190000047400784</link>    <guid>https://segmentfault.com/a/1190000047400784</guid>    <pubDate>2025-11-14 22:02:21</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>从技术演进规律来看，LLM的能力边界不仅由模型架构定义，更受限于底层系统的承载能力，而C++凭借无额外运行时依赖、内存管理自主可控、编译优化灵活高效等核心特性，恰好弥补了高层语言在性能与控制力上的短板，为LLM系统提供了从推理速度、内存占用到稳定性的全方位保障，成为连接LLM复杂算法需求与硬件底层算力的核心桥梁，更是决定LLM能否从实验室原型走向规模化商业应用的技术基石。</p><p>C++的内存管理机制是其赋能LLM系统的核心优势之一，也是区别于高层语言的关键特性，更是解决LLM大内存需求痛点的核心手段。LLM运行过程中需要同时处理三类核心数据：以GB甚至TB级存在的模型权重参数、推理过程中动态生成的中间计算结果、以及用户输入与模型输出的非结构化文本数据，这些数据的存储方式、流转路径直接决定了系统的运行效率与稳定性。高层语言的自动内存回收机制虽然降低了开发门槛，却存在无法规避的天然缺陷：回收时机的不确定性可能导致推理过程中出现突发延迟，自动分配的内存布局难以适配LLM数据的连续性需求，进而引发内存碎片过多、CPU缓存命中率下降等问题，严重时甚至会因内存溢出导致系统崩溃。而C++赋予开发者直接干预内存分配与释放的权限，通过自定义内存分配器，可根据LLM数据的生命周期与大小特征构建专属内存池—采用分层设计思路，将内存池划分为固定大小块池与动态扩容块池，固定块池适配模型权重、常用张量等尺寸稳定的数据，按2^n字节规格划分块大小（如64B、128B、4KB），通过空闲链表快速分配回收；动态块池则用于处理中间计算结果等尺寸可变的数据，采用伙伴系统算法减少内存碎片。同时，将长期复用的模型权重存储在连续的物理内存区域，按CPU缓存页面对齐（通常为4KB或2MB）优化数据读取速度，避免跨页访问带来的性能损耗；对短期存在的中间计算结果采用栈内存分配，利用栈的LIFO特性快速分配释放，避免堆内存申请与释放带来的系统调用开销；通过指针操作与引用机制实现数据在不同模块间的零拷贝流转，彻底杜绝不必要的数据冗余。在边缘设备部署7B参数LLM的实际场景中，这种精细化的内存管理方式可使系统内存利用率提升40%以上，将原本需要16GB的内存占用压缩至10GB以内，不仅有效解决了大模型运行中的内存瓶颈，更让边缘设备等资源受限场景下的LLM部署成为可能，这也是C++在LLM底层开发中无法被替代的核心价值所在。</p><p>C++的编译优化能力为LLM系统的性能提升提供了巨大空间，其对代码的深度优化与硬件指令的精准适配，让LLM的密集型计算效率达到极致水平。LLM的核心计算集中在张量运算、矩阵乘法、自注意力机制计算等密集型任务，这些任务的计算量往往随模型参数规模呈指数级增长，对CPU的运算能力、指令执行效率提出了极高要求。与高层语言依赖虚拟机或解释器执行不同，C++编译器支持从O1到O3的多级优化配置，且不同编译器（GCC、Clang、MSVC）的优化侧重点存在差异—GCC的O3优化更注重循环优化与指令重排，Clang则在向量优化与内存访问优化上表现更优，开发者可根据LLM的计算特性与部署硬件选择适配的编译器。开启O3优化级别时，编译器会自动完成循环展开（将多层循环合并为单层，减少循环控制开销）、指令重排（调整指令执行顺序，避免CPU流水线阻塞）、常量传播（将常量直接代入计算，消除冗余变量）、死代码消除（移除未被调用的函数与无效逻辑）等一系列优化操作，大幅减少冗余指令的执行；对LLM中频繁调用的基础计算函数（如自注意力机制中的点积计算、Softmax激活函数）采用内联函数优化，通过inline关键字或编译器强制内联选项（如GCC的__attribute__((always_inline))），消除函数调用带来的栈帧切换开销，尤其适用于重复执行次数达数百万次的核心计算逻辑。更重要的是，C++支持内嵌汇编与硬件指令集直接调用，开发者可通过CPU检测工具（如cpuid指令、lscpu命令）识别部署硬件的指令集支持情况，针对性适配SIMD、AVX2、AVX-512等高级向量指令集—以AVX-512为例，其可将向量寄存器宽度扩展至512位，单次指令能同时处理16个32位浮点数或8个64位浮点数，将原本需要16次指令完成的矩阵乘法运算压缩至1次，大幅提升张量运算与矩阵乘法的效率。在云端部署175B参数LLM的实践中，仅针对自注意力机制核心计算模块进行编译器选型（选择Clang 16）、O3优化配置与AVX-512指令集适配，就能使该模块的计算速度提升两倍以上，单条推理请求的延迟从800ms降至280ms，这种底层的性能突破是高层语言难以企及的，也充分体现了C++在LLM密集型计算场景下的绝对优势。</p><p>C++的多线程编程模型与同步机制，为LLM系统的并行计算提供了灵活且高效的实现方案，是挖掘多核CPU算力、提升系统吞吐量的核心支撑。LLM的推理过程中蕴含大量可并行的计算任务：多头注意力机制中不同注意力头的计算可独立进行，批量处理用户请求时多个推理任务可同时执行，甚至单条请求的推理过程中，张量拆分后的子任务也能并行运算，如何充分利用多核CPU的计算资源，实现这些任务的高效协同，是提升LLM服务吞吐量、降低单请求延迟的关键。C++的标准多线程库（std::thread）与第三方高性能线程库（如TBB、Boost.Thread）提供了丰富的线程管理与同步工具，支持开发者根据LLM的计算逻辑进行精细化的线程设计：采用线程池模式预先创建与CPU核心数匹配的线程（通常为核心数的1.5倍，避免线程过多导致的上下文切换开销），通过任务队列存储待执行的推理任务，线程池中的空闲线程主动从队列中获取任务执行，避免频繁创建与销毁线程带来的系统开销；同时引入任务优先级机制，将用户请求分为实时查询（如智能客服对话）、批量处理（如文档生成）、后台预处理（如模型预热）三类，为实时查询分配最高优先级，确保高优先级任务抢占计算资源，快速响应。在同步机制上，利用std::mutex解决多线程访问共享资源（如全局配置、缓存数据、模型权重）的竞争问题，通过std::unique_lock实现锁的自动释放，避免死锁风险；对高频访问的共享数据（如批量请求的统计信息）采用std::atomic实现无锁编程，利用CPU的原子操作指令保证数据一致性，彻底消除线程切换带来的性能损耗；通过std::condition_variable实现线程间的精准同步，当任务队列为空时，工作线程进入阻塞状态，避免忙等导致的CPU资源浪费，当新任务加入队列时，主线程通过notify_one或notify_all唤醒空闲线程。此外，C++的异步编程模型（std::future、std::promise）支持将IO密集型任务（如数据读取、网络传输）与计算密集型任务（如模型推理）并行执行—例如在读取用户输入文本的同时，启动模型的前序初始化计算，待数据读取完成后直接接入后续推理流程，进一步提升系统的整体运行效率。这种基于C++的并行计算设计，在云端LLM API服务场景中，能够充分挖掘32核CPU的多核潜力，让系统在处理批量请求时吞吐量提升3倍以上，同时将单请求平均延迟控制在300ms以内，为高并发场景下的LLM服务（如智能客服、内容生成API）提供了坚实的技术支撑。</p><p>C++的跨平台特性与硬件亲和性，让LLM系统能够灵活适配不同的部署场景，从云端高性能服务器到边缘嵌入式设备，实现全场景的高效落地。随着LLM技术的广泛应用，其部署场景日益多元化：云端服务需要支撑海量用户的并发请求，对计算性能、内存容量有极高要求；边缘设备（如智能终端、工业网关）受限于功耗与体积，要求系统具备低内存占用、低功耗运行的特性；嵌入式系统（如智能车载设备、物联网终端）则注重实时响应能力与稳定性。而C++的核心优势在于无需依赖额外的运行时环境，编译后的二进制文件可直接在不同硬件平台上运行，无论是x86架构的高性能服务器、ARM架构的边缘设备，还是RISC-V架构的嵌入式芯片，都能保持一致的稳定表现。针对边缘设备（如搭载ARM Cortex-A53处理器的工业网关）的资源限制，开发者可通过C++的编译优化选项对代码进行裁剪与压缩：使用GCC的-Os优化级别（以体积优化为目标），移除不必要的功能模块、调试信息与冗余代码，将LLM推理引擎的可执行文件体积压缩30%以上；通过链接时优化（LTO）将多个目标文件合并编译，消除跨文件的冗余符号与函数，进一步减小文件体积；同时采用内存压缩技术，将模型权重以16位浮点数（FP16）存储，配合C++的位运算与结构体封装，降低内存占用与数据传输开销。利用C++对硬件的直接操作能力，可通过内嵌汇编调用ARM处理器的NEON指令集，充分发挥边缘设备专用计算单元的算力，避免通用CPU计算带来的资源浪费。在云端部署场景中，C++可与各类操作系统（Linux、Windows Server）、数据库、中间件无缝兼容，通过epoll、kqueue等异步I/O机制提升网络通信效率，配合负载均衡策略（如Nginx+Keepalived）应对海量用户请求的并发处理；针对x86架构的高性能服务器，可适配AVX-512指令集与多通道内存架构，最大化发挥CPU的计算潜能。在智能车载场景中，C++的实时性优势尤为突出—通过编写无锁数据结构与优先级调度逻辑，确保LLM推理任务在100ms内完成响应，满足车载场景的实时交互需求；同时利用C++对硬件的底层控制能力，直接与车载传感器、显示屏等设备进行数据交互，减少中间层开销。这种强大的跨平台适配能力，让C++成为LLM全场景部署的首选语言，也为LLM技术从互联网行业向工业、车载、物联网等领域渗透奠定了基础。</p><p>C++的模块化设计与接口抽象能力，为LLM系统的可扩展性与可维护性提供了有力保障，支撑系统在快速的技术迭代中持续演进。LLM技术处于高速发展阶段，模型架构不断更新（如从Transformer到GPT系列、LLaMA系列、Qwen系列的演进），功能需求日益复杂（如支持多模态输入、长上下文理解、插件扩展），底层系统需要具备足够的灵活性，以适应快速的技术变化与业务迭代。C++支持面向对象、泛型编程等多种编程范式，为模块化设计提供了灵活的实现路径：开发者可通过类与对象的封装，将LLM系统的核心功能拆分为独立的模块，如内存管理模块、计算加速模块、网络通信模块、任务调度模块、模型适配模块等，每个模块内部高度内聚，仅通过清晰的接口（如纯虚函数定义的抽象接口类）与其他模块进行交互，降低模块间的耦合度。当LLM模型升级（如从7B参数模型替换为13B参数模型）或新增功能时，只需对相应模块进行修改或新增——例如引入新的量化推理算法时，可实现统一的计算接口（如IQuantizationEngine），通过接口继承与多态特性，将新算法无缝接入现有系统；适配新的硬件平台时，只需替换硬件适配模块（如将x86指令集适配模块替换为ARM指令集适配模块），无需改动核心业务逻辑。同时，C++的抽象基类与虚函数机制可实现接口与实现的分离，便于不同算法或硬件适配层的灵活替换，例如在计算加速模块中，可定义IComputeAccelerator抽象接口，分别实现CPUAccelerator、GPUAccelerator、NPUAccelerator三个子类，根据部署环境动态选择对应的加速方案。</p>]]></description></item><item>    <title><![CDATA[《LLM零开销抽象与插件化扩展指南》 程]]></title>    <link>https://segmentfault.com/a/1190000047400787</link>    <guid>https://segmentfault.com/a/1190000047400787</guid>    <pubDate>2025-11-14 22:01:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p>许多高层语言构建的LLM方案，虽能通过灵活封装适配复杂架构，却因抽象层的运行时开销、硬件调用的中间损耗，导致实际推理效率大打折扣，尤其在高并发、资源受限场景下，这种损耗会被无限放大。而C++的核心价值，正体现在其“零开销抽象”与“硬件级可控”的双重特性上：它既能够以接近汇编的底层效率直接操作CPU、内存、缓存等硬件资源，又能通过泛型编程、强类型系统构建灵活的抽象层，无需额外 runtime 支撑，彻底避免冗余开销。这一特性恰好击中了LLM系统的痛点，无论是多精度张量运算的灵活适配、硬件缓存的极致利用，还是动态场景下的资源安全管理、跨算法架构的快速兼容，C++都能提供坚实的底层支撑。从低功耗边缘设备的小模型部署，到云端千亿参数模型的高并发推理，C++的价值远超单纯的“性能提升”，更是构建高效、可靠、可扩展LLM系统的底层逻辑，成为突破技术瓶颈的核心驱动力。</p><p>C++的强类型系统与泛型编程，为LLM系统的多精度计算、多格式张量处理提供了兼具灵活性与性能的解决方案，彻底摆脱了高层语言“封装即损耗”的困境。LLM的计算过程中，张量类型与精度需求呈现出高度多样性：训练阶段需依赖FP32、FP64等高精度浮点数保证收敛性，推理阶段为节省资源常采用INT8、FP16、FP8甚至INT4的低精度量化格式，而针对稀疏激活的场景，还需适配COO、CSR等不同稀疏张量存储格式。高层语言往往需要通过额外的类型转换、格式适配层来兼容这种多样性，不仅增加了代码冗余，更会带来可观的运行时开销—例如某Python实现的LLM量化推理方案，仅类型转换环节就占用了15%的总推理时间。而C++的模板元编程与编译期类型推导机制，能够在编译阶段完成类型适配与逻辑生成，完全规避运行时额外开销。通过设计泛型张量类，可将数据类型、维度、存储格式、量化精度作为模板参数，编译器会为每种组合自动生成针对性的优化代码，既保证了接口的统一性（开发者无需关注底层类型差异），又避免了类型转换、格式兼容的性能浪费。同时，C++的强类型特性能够在编译期捕获类型不匹配、张量维度错误、精度溢出等问题，大幅减少LLM运行时的异常风险，降低调试成本。在13B参数LLM的INT8量化推理场景中，这种泛型设计可灵活适配不同量化方案（对称量化、非对称量化），通过模板特化为每种方案实现最优运算逻辑，相较于高层语言的统一封装，计算效率提升28%以上，同时保持代码的简洁与可维护性，完美平衡了LLM系统的灵活性与性能需求。</p><p>C++的零开销抽象特性，从根本上解决了LLM系统“复杂架构设计”与“低性能损耗”的矛盾，让高层抽象与底层效率得以兼顾。随着LLM系统功能日益复杂，需兼顾模型推理、任务调度、数据流转、硬件交互、异常处理等多个模块，而抽象层的设计是降低模块耦合、提升可扩展性的关键。但高层语言的抽象往往伴随着难以避免的运行时开销：虚函数调用的间接跳转（每次调用增加2-3个时钟周期，千亿次调用累积损耗显著）、接口封装的额外层级（数据需经过多层转发才能到达硬件）、动态类型转换的资源消耗，这些看似微小的开销在LLM密集型计算场景下会被无限放大，导致整体性能下降。C++的零开销抽象理念，通过编译期优化彻底消除了抽象带来的冗余：采用静态多态（CRTP设计模式）替代传统动态多态，将虚函数调用转化为编译期确定的直接调用，避免运行时跳转开销；利用inline关键字与编译器强制内联优化（如GCC的__attribute__((always_inline))），将高频调用的抽象接口直接嵌入核心代码，消除函数调用的栈帧切换开销；通过模板特化与SFINAE机制（Substitution Failure Is Not An Error），在编译期根据不同场景（如CPU/GPU部署、不同精度计算）选择最优实现，无需运行时判断分支。在LLM的Transformer层设计中，通过零开销抽象构建的通用接口，可灵活组合自注意力机制、前馈网络、层归一化等模块，同时支持不同模型架构（GPT、LLaMA、Qwen）的快速适配—例如新增某类改进型自注意力机制时，仅需实现通用接口的特化版本，无需修改其他核心代码。这种设计既保证了模块的灵活组合与扩展，又确保了各模块的运算效率与直接编写底层代码相当，让LLM系统在具备复杂架构设计的同时，不牺牲核心计算性能。</p><p>C++对内存布局的精准控制能力，成为优化LLM系统缓存利用率、降低内存访问延迟的核心抓手，这一优势在密集型张量运算中尤为关键。LLM的核心计算（如矩阵乘法、自注意力机制）高度依赖CPU缓存的性能—CPU的L1缓存访问延迟仅1-3个时钟周期，L2缓存为10-20个时钟周期，而内存访问延迟高达100-200个时钟周期，缓存命中率每提升10%，整体计算效率可提升8%-12%。高层语言的内存布局由编译器或运行时自动管理，往往难以适配LLM数据的访问模式：例如张量数据跨缓存行存储、相关性低的数据紧凑排列，导致缓存行浪费、频繁缓存失效，严重影响计算速度。而C++允许开发者通过精细化控制内存布局，使其与CPU缓存的工作机制高度匹配：将LLM中频繁访问的张量数据、模型权重按缓存行大小（通常为64字节）对齐排列，通过__attribute__((aligned(64)))等编译器指令强制对齐，避免单个数据跨缓存行存储，减少缓存加载次数；通过数据重排优化空间局部性，将自注意力机制中Q、K、V矩阵的相关元素紧凑存储，确保CPU访问一个缓存行时，能加载到后续运算所需的更多数据；利用内存预取指令（如GCC的__builtin_prefetch），在运算前主动将即将访问的数据加载到缓存中，减少缓存等待时间；针对稀疏张量，按访问热度排序非零元素，将高频访问的非零值与索引存储在连续内存区域，提升缓存命中率。在千亿参数LLM的自注意力机制计算中，通过这些内存布局优化，可将缓存命中率从60%提升至85%以上，减少大量不必要的内存访问，进而使该模块的计算效率提升27%左右，整体推理延迟降低22%。这种对内存布局的底层控制能力，是高层语言无法实现的，也成为C++在LLM密集型计算场景下的核心竞争力之一。</p><p>C++的异常安全与RAII（资源获取即初始化）机制，为LLM系统的长期稳定运行提供了坚实保障，尤其适配高负载、长时间不间断的工业化部署场景。LLM系统在规模化应用中，往往需要面对连续数日甚至数月的高并发运行，期间可能遭遇网络波动、硬件异常、数据格式错误、请求突增等各类突发情况，若资源管理不当，极易出现内存泄漏、显存泄漏、硬件句柄未释放、资源竞争死锁等问题，导致系统性能逐步衰减，甚至直接崩溃。高层语言的自动资源管理机制（如垃圾回收）虽然降低了开发门槛，但存在明显缺陷：回收时机的不确定性可能导致资源释放不及时，在高并发场景下引发资源耗尽；无法高效处理非内存资源（如GPU显存、网络连接、硬件设备句柄），容易出现非内存资源泄漏；垃圾回收过程中的“Stop-The-World”机制会导致LLM推理延迟突发增高。而C++的RAII机制，将资源的生命周期与对象的生命周期严格绑定，通过栈对象、智能指针（std::unique_ptr、std::shared_ptr）等实现资源的自动、安全释放—无论程序正常执行还是遭遇异常退出，只要对象超出作用域，资源就会被立即回收，从根本上避免泄漏。同时，C++的异常处理机制（try-catch）可精准捕获并处理LLM运行中的各类异常，通过noexcept关键字明确函数是否抛出异常，帮助编译器优化代码，减少异常处理的性能开销。在云端LLM API服务场景中，基于RAII机制设计的资源管理模块，可确保每个推理请求占用的内存、CPU核心、网络连接、GPU显存等资源在请求结束后立即释放，即使遭遇突发异常（如请求数据格式错误、GPU算力波动）也不会出现资源残留。某日均处理120万次请求的云端LLM服务，采用该机制后，内存泄漏率始终保持为0，连续运行90天无故障，推理延迟波动控制在5%以内，充分体现了C++在保障LLM系统稳定性方面的核心价值。</p><p>C++的动态链接与插件化扩展能力，完美适配了LLM技术快速迭代的行业现状，为系统的灵活升级、多场景适配提供了高效解决方案。当前LLM技术迭代速度极快，新的模型结构（如MoE混合专家模型、狭长注意力模型）、优化算法（如动态量化、增量推理）、量化方案（如FP8、INT4混合精度）层出不穷，而传统的静态编译系统往往需要全量重构、编译、部署，不仅耗时费力（大型LLM系统全量编译需数小时甚至一两天），还可能影响现有服务的稳定性，导致业务中断。C++的动态链接库（DLL/SO）机制，支持将LLM系统的核心模块（如模型推理引擎、量化算法、硬件适配层、任务调度器）封装为独立的动态链接库，主程序可通过动态加载接口（如dlopen、LoadLibrary）在运行时加载、卸载这些模块，无需重启系统即可完成升级或替换。</p>]]></description></item><item>    <title><![CDATA[ICAIS 2025国际AI科学家大会日]]></title>    <link>https://segmentfault.com/a/1190000047400737</link>    <guid>https://segmentfault.com/a/1190000047400737</guid>    <pubDate>2025-11-14 21:02:01</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/95c21119582c7926.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400739" alt="" title=""/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400740" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400741" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400742" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400743" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400744" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400745" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047400746" alt="" title="" loading="lazy"/></p>]]></description></item>  </channel></rss>