<?xml version="1.0" encoding="UTF-8"?><rss version="2.0">  <channel>      <title>SegmentFault - 最近文章</title>      <link>https://segmentfault.com/blogs/newest</link>      <description>SegmentFault 思否</description>      <generator>python segmentfault.py @Pi20</generator>      <item>    <title><![CDATA[企业网站选择OV证书还是DV证书？ 冷姐Joy ]]></title>    <link>https://segmentfault.com/a/1190000047499137</link>    <guid>https://segmentfault.com/a/1190000047499137</guid>    <pubDate>2025-12-24 10:09:59</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>当您为企业网站部署SSL证书时，会发现有多种类型可选，其中OV（组织验证）证书和DV（域名验证）证书是最常见的两种。对于注重品牌形象和安全信任的企业而言，如何选择至关重要。</p><h4><strong>一、什么是DV证书？（基础型）</strong></h4><p>DV证书的核心是验证<strong>您是否拥有这个域名</strong>。证书颁发机构（CA）的审核过程非常快速、自动化，通常只需验证域名管理员邮箱或设置一条DNS解析记录即可。</p><ul><li><strong>主要特点</strong>：<strong>申请快捷、成本较低</strong>。</li><li><strong>显示效果</strong>：在浏览器地址栏显示锁形标志，点击后可见“证书有效”，但<strong>不显示企业名称</strong>。</li><li><strong>适用场景</strong>：个人博客、测试网站、不涉及敏感信息交互的小型展示类网站。</li></ul><p><img width="300" height="300" referrerpolicy="no-referrer" src="/img/bVdcJRp" alt="" title=""/></p><p>SSL证书申请方式：<a href="https://link.segmentfault.com/?enc=gSpKZ5kXd%2BvxGsXrS3zOuA%3D%3D.Wqpo15ZK82sA8AYR4e8U%2FZygNTRwm%2BT0SpKva1ceejomCV3srlEVn8H7GIJSbU78au7iP6ga%2Bvyn2Eo%2BIcBqrg%3D%3D" rel="nofollow" target="_blank">https://www.joyssl.com/certificate/select/ov_ssl.html?nid=73</a></p><h4><strong>二、什么是OV证书？（专业型）</strong></h4><p>OV证书在DV证书的基础上，增加了对<strong>企业真实性和合法存在性</strong>的严格审核。CA会人工核查企业在官方注册机构（如工商局）的备案信息，包括公司名称、地址、运营状态等。</p><ul><li><strong>主要特点</strong>：<strong>审核严格、需要1-3个工作日</strong>。</li><li><strong>显示效果</strong>：同样显示锁形标志，但点击查看证书详细信息时，可以清晰地看到<strong>经过验证的企业名称</strong>。</li><li><strong>适用场景</strong>：<strong>所有企业官网、电子商务网站、会员登录系统</strong>等需要建立用户信任的正式商业网站。</li></ul><h4><strong>三、核心区别：信任等级的差异</strong></h4><p>您可以这样理解：DV证书证明了“这个网站是谁的”，而OV证书证明了“这个网站是哪家合法公司的”。</p><p><strong>对于企业网站，强烈推荐使用OV证书</strong>，原因如下：</p><ol><li><strong>彰显企业真实性</strong>：OV证书将您的合法企业信息嵌入证书，是向客户证明您是一家真实、合法运营企业的<strong>数字身份证</strong>。这能有效区别于皮包公司或钓鱼网站。</li><li><strong>提升品牌信任度</strong>：当用户，特别是进行交易或提交个人信息时，能够看到您的公司名称，会大大增强安全感与信任感。这是一种低成本高回报的品牌形象投资。</li><li><strong>更高的安全保证</strong>：由于OV证书经过了更严格的人工审核流程，其签发门槛更高，能从源头上降低钓鱼网站仿冒的成功率，为您的客户提供更高级别的安全保障。</li></ol><h4><strong>总结：企业网站应如何选择？</strong></h4><p><strong>一句话总结：追求品牌、信任与安全，请选择OV证书。</strong></p><ul><li>如果您的企业网站仅仅是<strong>简单的名片展示</strong>，且预算极其有限，DV证书可以提供基础的加密功能。</li><li>但对于<strong>绝大多数正经经营的企业</strong>而言，网站是重要的营销和业务窗口。多付出一些成本和等待时间，选择<strong>OV证书</strong>，所带来的专业形象和用户信任度提升，是DV证书无法比拟的。</li></ul>]]></description></item><item>    <title><![CDATA[国密SSL证书申请指南 魁梧的松鼠 ]]></title>    <link>https://segmentfault.com/a/1190000047499146</link>    <guid>https://segmentfault.com/a/1190000047499146</guid>    <pubDate>2025-12-24 10:09:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h4>什么是国密SSL证书？</h4><p>国密SSL证书采用中国自主研发的SM2密码算法，比国际通用的RSA算法更安全高效。对于政务、金融、医疗等重要领域的网站，部署国密证书已成为满足<strong>等保合规</strong>的基本要求。</p><h4>申请前准备</h4><p><strong>确认环境支持</strong></p><ul><li>服务器需支持国密协议（如Nginx国密模块）</li><li>客户端浏览器需支持国密（如360安全浏览器国密版）</li></ul><p><strong>准备材料</strong></p><ul><li>企业：营业执照、域名授权书</li><li>个人：身份证扫描件</li></ul><h4>国密证书申请流程</h4><p>直接访问<strong>JoySSL</strong>，注册一个账号记得填注册码230970获取技术支持。<br/><img width="723" height="311" referrerpolicy="no-referrer" src="/img/bVdd94e" alt="" title=""/></p><h4><a href="https://link.segmentfault.com/?enc=lS%2BoqULeirOazwzOmqDKxg%3D%3D.IINqNJsR%2FQoFcz5UCYGtCE8HrCPHk%2BASxma4nCOg2ZWszAtxM3tBPsBLeUZsiyV%2FPGkjiZE6sRij0lJel5XZE2o6pt173nyeLUNIORyR%2BSI%3D" rel="nofollow" target="_blank"> 四步申请流程</a></h4><p><strong>1. 选择认证机构</strong> 推荐选择国家密码管理局认证的CA机构，如<strong>JoySSL</strong>。</p><p><strong>2. 生成密钥对</strong> 使用国密工具生成SM2密钥和证书请求文件(CSR)。</p><p><strong>3. 提交审核</strong> 在CA平台提交CSR和相关证明材料，完成域名验证和企业验证。</p><p><strong>4. 下载安装</strong> 审核通过后下载证书文件，部署到服务器。</p><h2>重要注意事项</h2><p><strong>兼容性方案</strong> 由于部分浏览器不支持国密算法，建议采用<strong>双证书部署</strong>方案：</p><ul><li>同时部署国密证书和国际算法证书</li><li>服务器自动识别客户端并选择合适的证书</li></ul><p><strong>证书有效期</strong> 国密证书通常有效期为1-2年，需提前30天续期。</p><p><strong>安全维护</strong></p><ul><li>定期检查证书状态</li><li>私钥泄露立即吊销证书</li><li>建议每年更换密钥对</li></ul>]]></description></item><item>    <title><![CDATA[2025年CRM系统品牌排行榜与功能深度解析 正直的炒饭 ]]></title>    <link>https://segmentfault.com/a/1190000047499154</link>    <guid>https://segmentfault.com/a/1190000047499154</guid>    <pubDate>2025-12-24 10:08:50</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>引言</h2><p>随着企业数字化转型从“单点工具”向“全链路协同”升级，CRM的定位已从“销售管理工具”进化为“全业务数据枢纽”。企业需要的不仅是线索跟踪或客户画像，更是<strong>销售-客户-采购-仓库-财务-生产</strong>的全流程打通——比如销售订单自动触发采购计划、仓库出库同步生成财务凭证、生产进度实时反馈给客户。</p><p>本文基于<strong>8大核心业务领域</strong>（销售、客户、采购、仓库管理、财务、维修、生产），对6款主流CRM（超兔一体云、Salesforce、Zoho、金蝶云·星辰、用友CRM、HubSpot CRM）进行深度横评，剖析各品牌的能力边界与最佳适用场景。</p><h2>一、核心概念与评价维度</h2><p>在展开对比前，先明确各领域的<strong>关键能力指标</strong>（企业真实需求的底层逻辑）：</p><table><thead><tr><th>领域</th><th>关键能力指标</th></tr></thead><tbody><tr><td>销售</td><td>线索多渠道捕获、商机全流程跟踪、销售自动化、CPQ报价、外勤支持</td></tr><tr><td>客户</td><td>360°视图（整合通信/订单/外勤）、生命周期管理、社交/工商信息补全、生态整合</td></tr><tr><td>采购</td><td>智能采购计划（关联销售/库存）、供应商管理、询价比价、与销售/仓库联动</td></tr><tr><td>仓库管理</td><td>多仓库/库位支持、出入库自动化、批次/序列号溯源、库存预警</td></tr><tr><td>财务</td><td>业财联动（订单→应收→凭证）、应收应付自动化、财务凭证生成、税务合规</td></tr><tr><td>维修</td><td>工单管理（到店/外勤）、配件溯源、维修进度跟踪</td></tr><tr><td>生产</td><td>MES联动（计划排程/报工）、委外工序支持、生产进度可视化</td></tr></tbody></table><h2>二、各品牌核心能力深度横评</h2><h3>（一）总览：全业务能力矩阵</h3><p>先通过<strong>能力覆盖度表格</strong>快速定位各品牌的“长板”与“短板”（“原生”指产品自带功能，“集成”指需对接第三方系统，“无”指不支持）：</p><table><thead><tr><th>品牌</th><th>销售</th><th>客户</th><th>采购</th><th>仓库管理</th><th>财务</th><th>维修</th><th>生产</th></tr></thead><tbody><tr><td>超兔一体云</td><td>✅原生</td><td>✅原生</td><td>✅原生</td><td>✅原生</td><td>✅原生</td><td>✅原生</td><td>✅原生</td></tr><tr><td>Salesforce</td><td>✅原生</td><td>✅原生</td><td>❌集成</td><td>❌集成</td><td>❌集成</td><td>❌集成</td><td>❌集成</td></tr><tr><td>Zoho</td><td>✅原生</td><td>✅原生</td><td>✅原生</td><td>✅原生</td><td>✅原生</td><td>❌无</td><td>❌无</td></tr><tr><td>金蝶云·星辰</td><td>✅原生</td><td>✅原生</td><td>✅原生</td><td>✅原生</td><td>✅原生</td><td>❌弱</td><td>❌弱</td></tr><tr><td>用友CRM</td><td>✅原生</td><td>✅原生</td><td>✅原生</td><td>✅原生</td><td>✅原生</td><td>❌弱</td><td>✅原生</td></tr><tr><td>HubSpot CRM</td><td>✅原生</td><td>✅原生</td><td>❌集成</td><td>❌集成</td><td>❌集成</td><td>❌集成</td><td>❌集成</td></tr></tbody></table><h3>（二）分领域深度对比</h3><h4>1. 销售管理：从“线索捕获”到“订单闭环”</h4><p>销售是CRM的核心场景，但企业的需求早已从“记客户电话”升级为“全流程可控”——比如线索从抖音进来后，如何自动分配给销售？商机跟进到“合同待签”时，如何自动提醒法务审合同？</p><p><strong>关键能力对比</strong>：</p><table><thead><tr><th>能力点</th><th>超兔一体云</th><th>Salesforce</th><th>Zoho</th><th>金蝶云·星辰</th><th>用友CRM</th><th>HubSpot CRM</th></tr></thead><tbody><tr><td>多渠道线索管理</td><td>✅（百度/抖音/微信/小程序，自动抓表单）</td><td>✅（Marketing Cloud，支持广告线索同步）</td><td>✅（CRM+Marketing，邮件/表单线索）</td><td>✅（钉钉/企微线索同步）</td><td>✅（快消/零售外勤线索）</td><td>✅（表单/广告/社交线索）</td></tr><tr><td>商机跟踪模型</td><td>✅（三一客小单/商机中单/项目大单，360°视图）</td><td>✅（Sales Cloud漏斗，支持复杂项目）</td><td>✅（Zia AI商机预测，轻量化漏斗）</td><td>✅（轻量化漏斗，订单流转ERP）</td><td>✅（制造订单联动生产计划）</td><td>✅（Freddy AI商机评分）</td></tr><tr><td>销售自动化</td><td>✅（待办/日报/目标分解，自动生成跟进任务）</td><td>✅（Flow自动化，支持线索分配/邮件触发）</td><td>✅（Zia自动化任务，如生日提醒）</td><td>✅（订单一键流转至ERP）</td><td>✅（线索自动分配给销售）</td><td>✅（线索评分，自动触发任务）</td></tr><tr><td>CPQ报价管理</td><td>✅（非标定制订单，支持多规格报价）</td><td>✅（Revenue Cloud CPQ，复杂行业合规）</td><td>✅（Books报价，支持多货币）</td><td>✅（ERP报价，适配制造/零售）</td><td>✅（制造合规报价，关联BOM）</td><td>❌</td></tr><tr><td>外勤支持</td><td>✅（拜访记录/手机拣货/位置跟踪）</td><td>✅（Mobile App，支持外勤打卡）</td><td>✅（移动端APP，外勤任务）</td><td>✅（外勤打卡，关联订单）</td><td>✅（快消外勤路线规划）</td><td>✅（移动端，外勤任务）</td></tr></tbody></table><p><strong>场景适配</strong>：</p><ul><li>超兔：适合<strong>多场景销售团队</strong>（小单快消+大单项目），比如同时做零售和工程的企业；</li><li>Salesforce：适合<strong>大型企业复杂销售</strong>（如金融/医疗的合规报价）；</li><li>用友：适合<strong>制造企业</strong>（销售订单直接联动生产计划）。</li></ul><h4>2. 客户管理：从“信息存储”到“全生命周期运营”</h4><p>客户管理的核心是“把客户变成资产”——比如从“潜在客户”到“复购客户”的每一步，如何用数据驱动？</p><p><strong>关键能力对比</strong>：</p><table><thead><tr><th>能力点</th><th>超兔一体云</th><th>Salesforce</th><th>Zoho</th><th>金蝶云·星辰</th><th>用友CRM</th><th>HubSpot CRM</th></tr></thead><tbody><tr><td>360°视图</td><td>✅（通信/外勤/订单/财务全整合）</td><td>✅（Einstein GPT，整合营销/服务数据）</td><td>✅（CDP客户数据平台，整合多渠道）</td><td>✅（联动ERP，客户+订单）</td><td>✅（全生命周期，线索-复购）</td><td>✅（客户旅程可视化，整合营销）</td></tr><tr><td>生命周期管理</td><td>✅（客池自动分类：需求培养→有需求→成功）</td><td>✅（Journey Builder，可视化生命周期）</td><td>✅（Zia客户分层，自动触发营销）</td><td>✅（轻量化客池，跟进状态）</td><td>✅（制造客户，订单→复购）</td><td>✅（RFM分析，复购预警）</td></tr><tr><td>社交/工商整合</td><td>✅（天眼查工商信息/微信头像/支付宝昵称）</td><td>✅（LinkedIn/微信生态集成）</td><td>✅（WhatsApp/微信集成）</td><td>✅（企微/钉钉客户同步）</td><td>✅（微信好友管理）</td><td>✅（Facebook/LinkedIn）</td></tr><tr><td>数据权限控制</td><td>✅（财务看财务数据，销售看客户详情）</td><td>✅（精细化权限，字段级控制）</td><td>✅（角色权限，模块级控制）</td><td>✅（ERP权限联动）</td><td>✅（制造部门数据隔离）</td><td>✅（团队权限，线索分配）</td></tr></tbody></table><p><strong>场景适配</strong>：</p><ul><li>超兔：适合<strong>需要深度客户洞察</strong>的企业（比如通过工商信息判断客户规模，用微信头像识别决策人）；</li><li>Salesforce：适合<strong>全球化企业</strong>（整合LinkedIn/WhatsApp等海外社交数据）；</li><li>用友：适合<strong>制造复购型企业</strong>（跟踪客户从“首单”到“设备升级”的全周期）。</li></ul><h4>3. 采购管理：从“被动补货”到“智能联动”</h4><p>采购的核心是“让销售订单驱动采购”——比如销售卖了10台设备，系统自动提醒采购补10个核心配件，而不是等仓库报警再采购。</p><p><strong>关键能力对比</strong>：</p><table><thead><tr><th>能力点</th><th>超兔一体云</th><th>Salesforce</th><th>Zoho</th><th>金蝶云·星辰</th><th>用友CRM</th><th>HubSpot CRM</th></tr></thead><tbody><tr><td>智能采购计划</td><td>✅（库存缺口+历史供应商，自动算采购量）</td><td>❌（需集成第三方ERP）</td><td>✅（Inventory，库存预警→采购）</td><td>✅（ERP采购计划，订单驱动）</td><td>✅（供应链系统，制造BOM联动）</td><td>❌</td></tr><tr><td>供应商管理</td><td>✅（OpenCRM询价比价，供应商评级雷达图）</td><td>❌（需集成第三方）</td><td>✅（Books，供应商信息/报价）</td><td>✅（ERP供应商档案，资质管理）</td><td>✅（供应链供应商，绩效评估）</td><td>❌</td></tr><tr><td>与销售/仓库联动</td><td>✅（销售订单→采购计划→仓库入库→销售出库）</td><td>❌（需集成）</td><td>✅（Books+Inventory，销售→采购→库存）</td><td>✅（CRM订单→ERP采购→库存）</td><td>✅（销售订单→生产→采购）</td><td>❌</td></tr></tbody></table><p><strong>场景适配</strong>：</p><ul><li>超兔：适合<strong>贸易/零售企业</strong>（快速响应销售需求，自动匹配历史供应商）；</li><li>金蝶/用友：适合<strong>制造企业</strong>（采购关联BOM，确保配件与生产匹配）；</li><li>Zoho：适合<strong>中小微跨境企业</strong>（Inventory+Books覆盖采购-库存-财务）。</li></ul><h4>4. 仓库管理：从“库存计数”到“全链路溯源”</h4><p>仓库管理的痛点是“看不见、查不清”——比如客户退回的设备，能不能查到是哪批采购的？仓库里的100个配件，能不能用手机快速找到？</p><p><strong>关键能力对比</strong>：</p><table><thead><tr><th>能力点</th><th>超兔一体云</th><th>Salesforce</th><th>Zoho</th><th>金蝶云·星辰</th><th>用友CRM</th><th>HubSpot CRM</th></tr></thead><tbody><tr><td>多仓库支持</td><td>✅（500+仓库，库位/货架管理）</td><td>❌（需集成）</td><td>✅（Inventory，多仓库/库位）</td><td>✅（ERP多仓库，异地库存）</td><td>✅（供应链多仓库，制造库存）</td><td>❌</td></tr><tr><td>库存溯源</td><td>✅（序列号/批次/流水，配件SN溯源）</td><td>❌（需集成）</td><td>✅（Inventory，批次管理）</td><td>✅（ERP批次，制造溯源）</td><td>✅（供应链序列号，设备溯源）</td><td>❌</td></tr><tr><td>出入库自动化</td><td>✅（手机拣货/扫码出入库，自动生成单据）</td><td>❌（需集成）</td><td>✅（Inventory，扫码出入库）</td><td>✅（ERP扫码，仓库作业）</td><td>✅（供应链PDA，制造出入库）</td><td>❌</td></tr><tr><td>库存预警</td><td>✅（上下限预警，自动提醒采购）</td><td>❌（需集成）</td><td>✅（Inventory，库存预警）</td><td>✅（ERP预警，制造库存）</td><td>✅（供应链预警，生产备料）</td><td>❌</td></tr></tbody></table><p><strong>场景适配</strong>：</p><ul><li>超兔：适合<strong>需要精准溯源</strong>的企业（比如电子设备维修，查配件SN号）；</li><li>金蝶/用友：适合<strong>制造企业</strong>（多仓库异地管理，生产备料预警）；</li><li>Zoho：适合<strong>中小跨境企业</strong>（Inventory覆盖基础库存管理）。</li></ul><h4>5. 财务管理：从“手工记账”到“业财联动”</h4><p>财务的核心需求是“让业务数据自动变成财务数据”——比如销售订单生成后，自动算应收款；仓库出库后，自动生成财务凭证，不用手工录Excel。</p><p><strong>关键能力对比</strong>：</p><table><thead><tr><th>能力点</th><th>超兔一体云</th><th>Salesforce</th><th>Zoho</th><th>金蝶云·星辰</th><th>用友CRM</th><th>HubSpot CRM</th></tr></thead><tbody><tr><td>业财联动</td><td>✅（订单→应收→出库→凭证，一键生成）</td><td>❌（需集成ERP）</td><td>✅（Books+CRM，销售→财务）</td><td>✅（CRM→ERP财务，实时同步）</td><td>✅（CRM→U8 ERP，凭证自动生成）</td><td>❌</td></tr><tr><td>应收应付管理</td><td>✅（智能应收，账期/信用控制发货）</td><td>❌（需集成）</td><td>✅（Books，应收/应付账单）</td><td>✅（ERP应收，制造账期）</td><td>✅（供应链应付，供应商账期）</td><td>❌</td></tr><tr><td>财务凭证生成</td><td>✅（读取CRM数据，自动匹配科目，推送柠檬云）</td><td>❌（需集成）</td><td>✅（Books，自动生成凭证）</td><td>✅（ERP凭证，自动同步）</td><td>✅（U8凭证，手工/自动）</td><td>❌</td></tr><tr><td>税务合规</td><td>✅（支持多税率，凭证匹配法规）</td><td>✅（Revenue Cloud，全球税务）</td><td>✅（Books，国际税务合规）</td><td>✅（ERP税务，国内法规）</td><td>✅（供应链税务，制造合规）</td><td>❌</td></tr></tbody></table><p><strong>场景适配</strong>：</p><ul><li>超兔：适合<strong>想降低财务工作量</strong>的企业（一键生成凭证，不用手工录）；</li><li>Salesforce：适合<strong>全球化企业</strong>（全球税务合规，比如欧洲VAT）；</li><li>金蝶/用友：适合<strong>国内制造企业</strong>（与ERP深度联动，符合本土财务法规）。</li></ul><h4>6. 客服管理：从“工单处理”到“复购驱动”</h4><p>客服的核心是“把问题变成机会”——比如客户投诉设备故障，能不能快速派单维修，同时推荐升级服务？</p><p><strong>关键能力对比</strong>：</p><table><thead><tr><th>能力点</th><th>超兔一体云</th><th>Salesforce</th><th>Zoho</th><th>金蝶云·星辰</th><th>用友CRM</th><th>HubSpot CRM</th></tr></thead><tbody><tr><td>全渠道支持</td><td>✅（电话/微信/APP/网页，总控台）</td><td>✅（Service Cloud，全渠道）</td><td>✅（Desk，邮件/聊天/电话）</td><td>✅（企微/钉钉/电话）</td><td>✅（制造客服，设备投诉）</td><td>✅（邮件/聊天/电话）</td></tr><tr><td>工单自动化</td><td>✅（维修工单：到店/外勤，自动派工）</td><td>✅（Flow自动化，工单分配）</td><td>✅（Desk，自动回复/分配）</td><td>✅（ERP工单，制造售后）</td><td>✅（供应链工单，设备维修）</td><td>✅（Freddy AI，工单分类）</td></tr><tr><td>复购分析</td><td>✅（RFM分析，复购流失预警）</td><td>✅（Einstein GPT，客户 churn预测）</td><td>✅（Desk，客户满意度分析）</td><td>✅（ERP复购，制造客户）</td><td>✅（供应链复购，设备升级）</td><td>✅（RFM分析，复购提醒）</td></tr><tr><td>AI助手</td><td>✅（自然语言生成工作流）</td><td>✅（Agentforce，AI客服）</td><td>✅（Zia Agents，智能客服）</td><td>✅（通义千问，智能回复）</td><td>✅（用友AI，制造客服）</td><td>✅（ChatSpot，AI助手）</td></tr></tbody></table><p><strong>场景适配</strong>：</p><ul><li>超兔：适合<strong>服务型企业</strong>（比如家电维修，支持外勤工单跟踪）；</li><li>Salesforce：适合<strong>大型企业</strong>（AI客服处理50%常规咨询，降低人力成本）；</li><li>HubSpot：适合<strong>B2B企业</strong>（RFM分析提醒复购，提高客户 Lifetime Value）。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047499156" alt="" title=""/></p><h3>（三）总结</h3><p>本次对超兔一体云、Salesforce、Zoho、金蝶云·星辰、用友CRM、HubSpot CRM这6款主流CRM在8大核心业务领域的深度横评结果显示，各品牌在不同业务领域展现出了各自的优势和不足。</p>]]></description></item><item>    <title><![CDATA[什么是SSL证书 南柯 ]]></title>    <link>https://segmentfault.com/a/1190000047499186</link>    <guid>https://segmentfault.com/a/1190000047499186</guid>    <pubDate>2025-12-24 10:08:03</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>SSL证书（安全套接层证书）是一种<strong>数字证书</strong>，用于在客户端（如浏览器）和服务器之间建立加密连接，确保数据传输的安全性和完整性。SSL现已被更安全的TLS（传输层安全）协议取代，但“SSL证书”这一名称仍被广泛使用。<br/><img width="700" height="400" referrerpolicy="no-referrer" src="/img/bVdna7Z" alt="" title=""/></p><p><strong>SSL证书的核心功能</strong></p><p><strong>1. 身份验证</strong><br/>验证网站所有者的真实身份，有效防止钓鱼网站和中间人攻击，并向访客直观展示网站的可信度。</p><p><strong>2. 数据加密</strong><br/>加密浏览器与服务器之间的所有数据传输，确保敏感信息（如密码、信用卡号等）不被窃取。通常采用AES-256等高强度加密算法。</p><p><strong>3. 数据完整性</strong><br/>通过技术手段确保数据在传输过程中不被篡改，提供可靠的消息认证机制。</p><p><strong>SSL证书的主要类型</strong></p><p><strong>域名验证证书</strong>：进行基础验证，仅验证申请者对域名的所有权。签发速度快，适用于个人网站、博客等场景。</p><p><strong>组织验证证书</strong>：进行中级验证，不仅验证域名，还需验证企业或组织的真实合法性。证书中会显示公司信息，适用于一般企业官网。</p><p><strong>扩展验证证书</strong>：执行最严格的验证流程，需提供详尽的组织证明文件。浏览器地址栏会显示绿色企业名称，为金融机构、大型电商平台等提供最高级别的信任标识。</p><p><strong>通配符证书</strong>：可保护一个主域名及其所有同级子域名，非常适合拥有多个子域名系统的网站。</p><p><strong>多域名证书</strong>：一张证书可同时保护多个完全不同的域名，为拥有多个品牌或业务线的企业提供便利的管理方案。</p><p><strong>SSL证书的工作原理</strong></p><p><strong>客户端发起连接</strong>：当用户访问一个HTTPS网站时，过程开始。</p><p><strong>证书交换</strong>：服务器将它的SSL证书发送给用户的浏览器。</p><p><strong>证书验证</strong>：浏览器检查证书是否由受信任的机构签发、是否在有效期内以及是否与访问的域名匹配。</p><p><strong>密钥交换</strong>：双方通过安全协议建立用于本次会话的加密密钥。</p><p><strong>加密通信</strong>：此后，浏览器与服务器之间传输的所有数据都使用该密钥进行加密，确保私密性。</p><p><strong>为什么SSL证书至关重要？</strong></p><p><strong>安全需求</strong><br/>SSL证书是防止敏感信息泄露的第一道防线，它直接保护用户隐私，并且是满足全球多项数据保护法规（如GDPR）的基本要求。</p><p><strong>业务影响</strong><br/>它对业务有直接影响：谷歌等搜索引擎明确给予HTTPS网站更高的搜索排名权重。对用户而言，浏览器地址栏的“安全锁”标志能显著提升信任感，从而提高网站转化率。同时，它确保了交易记录和通信内容的可靠性。</p><p><strong>合规要求</strong><br/>在许多行业，使用SSL加密不是可选项，而是强制规定。例如，处理在线支付的网站必须符合PCI DSS标准，而医疗、金融等行业也有明确的加密通信法规要求。</p><p><strong>如何选择SSL证书</strong>？</p><p>首先，根据网站类型确定所需的验证级别。其次，评估域名结构，是单一域名、多个子域名还是多个完全不同的域名。然后，选择如DigiCert、Sectigo或Let‘s Encrypt等权威且受信任的证书颁发机构。最后，结合预算进行决策，市场上有从免费到高端的各种选择。</p><p><strong>实施与管理建议</strong></p><p>启用全站HTTPS：不仅限于登录或支付页面，整个网站都应受到保护。<br/>定期更新：关注证书有效期（通常为1年），并设置过期提醒，及时续订。<br/>强化安全策略：实施HSTS（HTTP严格传输安全）策略，强制浏览器始终使用安全连接。<br/>采用自动化工具：考虑使用自动化证书管理工具，以降低运维复杂度和人为失误风险。</p><p><strong>未来趋势</strong></p><p>证书的有效期持续缩短，已从过去的数年缩短至90天或更短，以提升安全性。自动化管理通过ACME协议已成为标准实践，Let’s Encrypt等服务让免费SSL证书得以普及。同时，主流浏览器正变得更加严格，明确将未使用SSL的HTTP网站标记为“不安全”，推动全网加密成为默认标准。</p><p>在当今数字时代，SSL证书已从一项“增值功能”转变为网络存在的“安全基石”。它超越了单纯的数据保护，成为建立用户信任、提升品牌信誉和保障业务合规的关键工具。无论您是个人创作者还是企业管理者，为网站部署并正确维护SSL证书，都是迈向稳健数字化转型不可或缺的第一步。</p>]]></description></item><item>    <title><![CDATA[从同质化竞争到技能价值：技术视角下的三角洲代练平台升级架构设计与思考！ duokelijie ]]></title>    <link>https://segmentfault.com/a/1190000047499198</link>    <guid>https://segmentfault.com/a/1190000047499198</guid>    <pubDate>2025-12-24 10:07:17</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><img width="723" height="354" referrerpolicy="no-referrer" src="/img/bVdnsgR" alt="" title=""/><br/>代练平台正陷入同质化泥潭：订单靠补贴、用户留不住、代练师流失快。但有一批先行者，已悄然跳出“代练工具”的定位，用一套全新的“玩家技能”架构，重建代练服务生态！**</p><p><strong>一、为什么传统代练系统正在失效？</strong></p><ol><li>功能雷同： 接单 → 上号 → 打完 → 收钱，毫无差异化</li><li>信任缺失： 账号安全无保障，过程黑箱，纠纷频发</li><li>用户留存率： 一次性交易为主，复购率普遍偏低</li><li>代练师无归属感： 平台抽佣、缺乏一定的成长路径</li></ol><p><strong>结果？平台越做越累，运营越来越难。</strong></p><p><img width="723" height="1234" referrerpolicy="no-referrer" src="/img/bVdhVuy" alt="" title="" loading="lazy"/></p><p><strong>二、“玩家技能重建”：代练系统的新范式</strong><br/>不是“代你服务”，而是“用你的技能”。</p><p>“玩家技能服务”将代练师从“劳动力”升级为“技能提供者”，用户从“购服务”变为“用能力”。核心逻辑如下：<br/><strong>1.技能资源化</strong></p><ul><li>代练师可创建“技能资源”：如《英雄联盟》“钻石冲王者·擅长亚索”</li><li>支持图文介绍、战绩截图、视频演示、服务承诺</li><li>用户像逛某宝一样“选购技能”，而非被动匹配</li></ul><p><strong>2.匹配撮合 + 实时追踪</strong></p><ul><li>基于段位、英雄池、胜率、历史评价等标签推荐</li><li>订单全程可视化：登录时间、对局记录、实时战绩同步更新</li><li>支持“直播代练”模式，用户可远程观看操作过程</li></ul><p><strong>3.信用与成长体系</strong></p><ul><li>代练师拥有个人主页、技能等级、粉丝关注、收入排行榜</li><li>用户可收藏、关注、复购心仪代练师</li><li>引入“技能认证”机制（如官方合作认证、高胜率勋章）</li></ul><p><strong>↓代练系统前端功能展示（欢迎下载观看）↓</strong></p><p><img width="723" height="715" referrerpolicy="no-referrer" src="/img/bVdnsg1" alt="" title="" loading="lazy"/></p><p><strong>三、技术底座：支撑“技能电商”的代练系统架构</strong></p><ol><li>前端：UniApp 微信小程序、H5、APP、公众号（多端部署）</li><li>后端：ThinkPHP 6 + Swoole 高并发处理</li><li>数据库：MySQL + Redis 缓存高频订单数据</li><li>通信：WebSocket 实现实时进度推送</li><li>安全：JWT 鉴权 + 敏感信息脱敏 + 操作日志审计</li><li>开源代练系统源码已支持“技能商品”模块，1天即可部署上线！</li></ol><p><img width="723" height="245" referrerpolicy="no-referrer" src="/img/bVdnkay" alt="" title="" loading="lazy"/></p><p><strong>↓代练系统后端管理看板↓</strong></p><p><img width="723" height="378" referrerpolicy="no-referrer" src="/img/bVdnshd" alt="" title="" loading="lazy"/></p><p>结语：别再只做“代练中转站”，要做“技能交易所”</p><p>“玩家技能资源”不是概念，而是可落地、可运行、可复制的新一代代练系统架构。</p>]]></description></item><item>    <title><![CDATA[智能填充隐藏功能——自动补全地址表单所在地区 HarmonyOS_SDK ]]></title>    <link>https://segmentfault.com/a/1190000047499200</link>    <guid>https://segmentfault.com/a/1190000047499200</guid>    <pubDate>2025-12-24 10:06:34</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在应用程序使用过程中，用户经常需要填写各种表单，例如在寄送包裹时填写收货人信息、购买票务时填写购票人信息、参与调查时填写参与者信息等。这些重复且繁琐的信息填写过程，会直接影响用户的使用体验。为解决这一问题，HarmonyOS SDK<a href="https://link.segmentfault.com/?enc=ZsZd7wikqTjBmt2dSNVTqg%3D%3D.ydEBDys1Gtrb46DaL69ki0jlRBk38v0JVV5cIsUdSVFKH8mqQbxvQ6WzqrkWOvKK41yESj8WUjmCG7ch7Djea%2B6q2vcYIuf5uZaFqqQVgzILKS7PCQosIw20HyZxuhGarvdjD%2FDVEM8ly51QWrJf8A%3D%3D" rel="nofollow" title="融合场景服务" target="_blank">融合场景服务</a>（Scenario Fusion Kit）提供了<a href="https://link.segmentfault.com/?enc=nL7WgJH6u0JUXTxaKmBi9A%3D%3D.l68WNZ%2Fy%2Fb%2Fm4NOBz2lXIygQgPHKwjb%2FWdSDB0Lwxa8CWtziucufIcU%2BC04fQm9UtxmNQvQBVuyUWpregSTWOZgL8Ggglbtya9%2F1vTOkjEtZMlfiMW%2FvW9iEuV%2BkTTktks7SSLIW8OOldATI9fKaajOgucD5J4hGDP9TMqqPSYc%3D" rel="nofollow" title="智能填充" target="_blank">智能填充</a>功能，该功能可根据页面输入框类型、用户已输入内容，为用户提供输入建议，实现复杂表单一键填充。</p><p>然而，在填写表单时可能会遇到一个特殊的挑战：当表单中包含所在地区地址选择器时，智能填充不支持对地址选择器进行填充，为了实现地址信息的自动补全，开发者需要对表单中的地址字段进行开发。开发完成后，即使数据源中的"地址所在地区"信息不完整，智能填充服务也能够根据数据源中的详细地址内容，自动推断并补全地址选择器中的所在地区信息。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047499202" alt="" title=""/></p><p>当"所在地区信息"自动补全后，如果补全内容不符合预期，用户也可以通过点击"地址选择器"重新选择修改。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047499203" alt="" title="" loading="lazy"/></p><p>下面，本文将详细讲解，如何对表单中的地址字段进行开发，实现自动补全地址表单所在地区。</p><h3>开发准备</h3><ol><li>首先，我们需要在module.json5文件中设置模糊位置权限：ohos.permission.APPROXIMATELY_LOCATION，允许应用获取设备模糊位置信息。</li><li>其次，所在地区地址选择器需要开通地图服务。</li><li>最后，还需要配置应用签名证书指纹，可参见配置Client ID。</li></ol><h3>开发步骤</h3><p>我们以北京天安门的经纬度为例进行讲解，在获得相关授权后调用获取位置信息的API，然后根据数据源中现有地址信息遍历当前地址的行政区划层级，自动补全地址表单所在地区，在填写完毕后将表单信息保存到历史表单输入。</p><pre><code>import { util } from '@kit.ArkTS';
import { i18n } from '@kit.LocalizationKit';
import { sceneMap, site } from '@kit.MapKit';
import { hilog } from '@kit.PerformanceAnalysisKit';
import { BusinessError } from '@kit.BasicServicesKit';
import { geoLocationManager } from '@kit.LocationKit';
import { abilityAccessCtrl, autoFillManager, common, PermissionRequestResult, Permissions } from '@kit.AbilityKit';

const AUTHED = 0;
const TIME_OUT = 100;
// Default longitude and latitude. The following uses the longitude and latitude of Tiananmen, Beijing as an example.
const INIT_LAT = 39.5;
const INIT_LON = 116.2;
const ENGLISH = 'en';
const SIMPLIFIED_CHINESE = 'zh_CN';
const PERMISSIONS: Array&lt;Permissions&gt; = ['ohos.permission.APPROXIMATELY_LOCATION'];
const ADMINISTRATIVE_REGION: Array&lt;string&gt; =
  ['countryName', 'adminLevel1', 'adminLevel2', 'adminLevel3', 'adminLevel4'];

interface PersonInfo {
  name?: string;
  phone?: string;
  email?: string;
  idCard?: string;
  region?: string;
  stressAddress?: string;
}

interface RequestParam {
  requestTag: string;
  requestText: string;
}

interface Location {
  latitude: number;
  longitude: number;
}

// Display the authorization pop-up.
async function reqPermissionsFromUser(permissions: Array&lt;Permissions&gt;,
  context: common.UIAbilityContext): Promise&lt;PermissionRequestResult&gt; {
  let atManager: abilityAccessCtrl.AtManager = abilityAccessCtrl.createAtManager();
  return await atManager.requestPermissionsFromUser(context, permissions);
}

// Throttle function.
function debounce(func: () =&gt; void, wait: number = TIME_OUT): Function {
  let timeout: number | null = null;
  return () =&gt; {
    timeout &amp;&amp; clearTimeout(timeout);
    timeout = setTimeout(() =&gt; {
      func();
      clearTimeout(timeout);
    }, wait);
  };
}

@Extend(Text)
function textStyle() {
  .width(64)
  .textAlign(TextAlign.End)
}

@Entry
@Component
struct Index {
  @State personInfo: PersonInfo = {};
  @State isClicked: boolean = false;
  // Whether the user has triggered information input.
  private isUserInput: boolean = false;
  private location: Location = {
    latitude: INIT_LAT,
    longitude: INIT_LON,
  };
  private currentRequestTag: string = '';
  private handleAddressChange = (request: RequestParam) =&gt; {
    return debounce(async () =&gt; {
      this.autoCompleteAddress(request);
    });
  };

  aboutToAppear() {
    reqPermissionsFromUser(PERMISSIONS, getContext(this) as common.UIAbilityContext)
      .then((permissionRequestResult: PermissionRequestResult) =&gt; {
        if (permissionRequestResult.authResults[0] === AUTHED) {
          // The API for obtaining location information can be called only under authorization.
          geoLocationManager.getCurrentLocation((err, location: geoLocationManager.Location) =&gt; {
            if (err) {
              hilog.error(0x0000, 'testTag', `Failed to get location, code: ${err?.code}, message: ${err?.message}`);
              return;
            }
            hilog.info(0x0000, 'testTag', `Succeeded in obtaining the current location of the user`);
            this.location.latitude = location.latitude;
            this.location.longitude = location.longitude;
          })
        }
      })
      .catch((err: BusinessError) =&gt; {
        hilog.error(0x0000, 'testTag', `Failed request permissions, code: ${err?.code}, message: ${err?.message}`);
      })
  }

  public isUsLanguage(): boolean {
    let result: string = '';
    try {
      result = i18n.System.getSystemLanguage();
    } catch (error) {
      hilog.error(0x0000, 'testTag', 'Failed to get system language');
    }
    return result.toLowerCase() === 'en-latn-us';
  }

  async autoCompleteAddress(request: RequestParam): Promise&lt;void&gt; {
    try {
      let params: site.SearchByTextParams = {
        query: request.requestText,
        // Longitude and latitude to which search results need to be biased.
        location: {
          latitude: this.location.latitude,
          longitude: this.location.longitude
        },
        language: this.isUsLanguage() ? ENGLISH : SIMPLIFIED_CHINESE,
        isChildren: true
      };
      const result = await site.searchByText(params);
      if (result.sites) {
        let region: string = '';
        let addressComponent = result.sites[0].addressComponent;
        // Traverse the administrative region level of the current address.
        for (let item of ADMINISTRATIVE_REGION) {
          if (addressComponent[item] === undefined) {
            break;
          }
          region += addressComponent[item];
        }
        // Prevent repeated searches that may lead to inconsistent results.
        if (request.requestTag === this.currentRequestTag) {
          this.personInfo.region = region;
        }
      }
    } catch (error) {
      hilog.error(0x0000, 'testTag', `Failed to search location, code: ${error.code}, message: ${error.message}`);
    }
    hilog.info(0x0000, 'testTag', 'Succeeded in searching location');
  }

  onRegionClick(): void {
    // After a user selects an administrative region, display only search results from the selected region to prevent prolonged queries.
    this.currentRequestTag = util.generateRandomUUID();
    let districtSelectOptions: sceneMap.DistrictSelectOptions = {
      countryCode: 'CN',
    };
    sceneMap.selectDistrict(getContext(this), districtSelectOptions).then((data) =&gt; {
      hilog.info(0x0000, 'testTag', 'SelectDistrict', 'Succeeded  in selecting district.');
      let region = '';
      for (let i = 0; i &lt; data?.districts?.length; i++) {
        region += data.districts[i].name;
      }
      this.personInfo.region = region;
    }).catch((err: BusinessError) =&gt; {
      hilog.error(0x0000, 'testTag', `Failed to select district, code: ${err.code}, message: ${err.message}`);
    });
  }

  searchRegionByAddress(val: string): void {
    let tag: string = util.generateRandomUUID();
    this.currentRequestTag = tag;
    let param: RequestParam = {
      requestTag: tag,
      requestText: val
    }
    // For the manual user input scenario, dithering processing is required. For the automatic input scenario of SmartFill, only the query processing is required.
    if (this.isUserInput) {
      this.handleAddressChange(param)();
    } else {
      this.autoCompleteAddress(param);
    }
  }

  build() {
    Column({ space: 8 }) {
      Row({ space: 8 }) {
        Text('姓名').textStyle()
        TextInput({ text: this.personInfo.name, placeholder: '姓名' })
          .layoutWeight(1)
          .contentType(ContentType.PERSON_FULL_NAME)
          .onChange((val: string) =&gt; {
            this.personInfo.name = val;
          })
      }

      Row({ space: 8 }) {
        Text('联系电话').textStyle()
        TextInput({ text: this.personInfo.phone, placeholder: '手机号码' })
          .layoutWeight(1)
          .contentType(ContentType.PHONE_NUMBER)
          .onChange((val: string) =&gt; {
            this.personInfo.phone = val;
          })
      }

      Row({ space: 8 }) {
        Text('身份证号').textStyle()
        TextInput({ text: this.personInfo.idCard, placeholder: '身份证信息' })
          .layoutWeight(1)
          .contentType(ContentType.ID_CARD_NUMBER)
          .onChange((val: string) =&gt; {
            this.personInfo.idCard = val;
          })
      }

      Row({ space: 8 }) {
        Text('邮件地址').textStyle()
        TextInput({ text: this.personInfo.email, placeholder: '电子邮件信息' })
          .layoutWeight(1)
          .contentType(ContentType.EMAIL_ADDRESS)
          .onChange((val: string) =&gt; {
            this.personInfo.email = val;
          })
      }

      Row({ space: 8 }) {
        Text('所在地区').textStyle()
        TextArea({ text: this.personInfo.region, placeholder: '地区信息' })
          .layoutWeight(1)
          .backgroundColor($r('sys.color.ohos_id_color_card_bg'))
          .placeholderColor($r('sys.color.ohos_id_color_text_secondary'))
          .fontSize($r('sys.float.ohos_id_text_size_body1'))
          .fontColor($r('sys.color.ohos_id_color_text_primary'))
          .onClick(() =&gt; this.onRegionClick())
          .focusable(false)
      }

      Row({ space: 8 }) {
        Text('详细地址').textStyle()
        TextInput({ text: this.personInfo.stressAddress, placeholder: '小区门牌信息' })
          .layoutWeight(1)
          .contentType(ContentType.DETAIL_INFO_WITHOUT_STREET)
          .onDidInsert(() =&gt; {
            // Triggered when a user inputs data through an input method.
            this.isUserInput = true;
          })
          .onDidDelete((val: DeleteValue) =&gt; {
            // Triggered when a user deletes data through an input method.
            if (val?.deleteValue?.length &gt; 0) {
              this.isUserInput = true;
            }
          })
          .onChange((val: string) =&gt; {
            this.personInfo.stressAddress = val;
            if (val &amp;&amp; val.trim().length &gt; 0) {
              this.searchRegionByAddress(val);
            } else {
              this.currentRequestTag = util.generateRandomUUID();
              this.personInfo.region = '';
            }
            this.isUserInput = false;
          })
      }

      Button('保存')
        .width('50%')
        .onClick(() =&gt; {
          if (!this.isClicked) {
            this.isClicked = true;
            autoFillManager.requestAutoSave(this.getUIContext(), {
              onSuccess: () =&gt; {
                hilog.info(0x0000, 'testTag', 'Succeeded in saving request');
              },
              onFailure: () =&gt; {
                hilog.info(0x0000, 'testTag', 'Failed to save request');
              }
            });
            setTimeout(() =&gt; {
              this.isClicked = false;
            }, 2000);
          }
        })
    }
    .padding({ left: 16, right: 16 })
    .backgroundColor($r('sys.color.ohos_id_color_list_card_bg'))
    .alignItems(HorizontalAlign.Center)
    .height('100%')
    .width('100%')
  }
}
</code></pre><p><strong>了解更多详情&gt;&gt;</strong></p><p>访问<a href="https://link.segmentfault.com/?enc=PpQqaxxnPfYuFCN485gCfQ%3D%3D.8zUd%2FBaobqbWKLEpe5HNoeYWmikUrxBWQFBNPFmW0JRQBgsgoeMLZqC6SUiqe%2BspP7M4Ltl6K3dryY7DfcgMXbhjHMDIoCb%2Ffllkk8%2BqdmDN1q55QYczjiNwIWEPAtWiPiMbDQrfoH%2FnYpYbjruoHA%3D%3D" rel="nofollow" title="融合场景服务联盟官网" target="_blank">融合场景服务联盟官网</a></p><p>获取<a href="https://link.segmentfault.com/?enc=P7YdTBHwz5UwlDsTL%2BkB1A%3D%3D.%2BRScTeSQfkQ6fK1Ekht%2FceslkARf4t0cylm12mwcp403L57mlH5yyG46JULBh2xUJdXy2Cn8PtB3DyHwM0b2BvI6LXxh3RqI%2Fcw4w7Hu8SZa%2FY721nCAeYwfsXMG4FnN6g%2FiIKoPbxf8h2U41TnohBfX9cT7%2F%2FdOXb9OHT0hpH8%3D" rel="nofollow" title="智能填充能力的开发指导文档" target="_blank">智能填充能力的开发指导文档</a></p>]]></description></item><item>    <title><![CDATA[如何将「语音克隆同意验证机制」嵌入 AI 工作流丨Voice Agent 学习笔记 RTE开发者社区]]></title>    <link>https://segmentfault.com/a/1190000047499220</link>    <guid>https://segmentfault.com/a/1190000047499220</guid>    <pubDate>2025-12-24 10:06:03</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><strong>在这篇博客文章中，我们介绍了“语音同意验证机制 (voice consent gate)”的概念，支持通过明确同意来进行语音克隆。我们还提供了一个示例 Space 应用和相关代码，帮助大家快速上手这一想法。</strong></p><ul><li><p><strong>示例 Space 应用</strong></p><p>https\://hf.co/spaces/society-ethics/RepeatAfterMe</p></li><li><p><strong>相关代码</strong></p><p><a href="https://link.segmentfault.com/?enc=rSCdOFDF0zq1axs5S%2BRzPg%3D%3D.mD7Sf%2FtDh8qePbCb%2BbJkzqgvrIfHawSrcU5uBnQL74JDyoZbCrhCskkbtWABATi8z9WOiAqFc0dJRZurWLzE7Q%3D%3D" rel="nofollow" target="_blank">https://hf.co/spaces/society-ethics/RepeatAfterMe/tree/main</a></p></li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047499222" alt="" title=""/></p><p>近年来，逼真的语音生成技术已经达到了令人惊讶的水平。在某些情况下，生成出来的合成语音几乎能以假乱真，和真人的声音非常相似。如今，曾经只存在于科幻小说中的“语音克隆”已经成为现实。只需要几秒钟的录音，就能让任何人的声音“说出”任何内容。</p><p>语音生成，尤其是语音克隆技术，既有风险也有益处。它可能被用于制作“深度伪造”内容，例如<strong>有人用前总统 Biden 的克隆语音进行自动电话宣传</strong>，误导公众以为他说过其实并未说的话。但与此同时，语音克隆也可以带来积极作用，比如<strong>帮助失语者重新用自己的声音表达</strong>，或者辅助人们学习语言和方言。</p><ul><li><p><strong>有人用前总统 Biden 的克隆语音进行自动电话宣传</strong></p><p><a href="https://link.segmentfault.com/?enc=AWTaDMiDIyBTQrmLHL1fJQ%3D%3D.6jeQOuxO7DC%2F02JeUK8NxZwkRZNNYJ7UjHSp3slVBlDvx8us32zESzB%2Bf39RnMXxS1DozE1PEV2Z76gNm53GwmkTbM02v7NoX9jq03iNt18jYVWI5r8h%2F3vLq0F5azx1Sf9ZmnMCG%2FRR8%2FIz6vDZJA%3D%3D" rel="nofollow" target="_blank">https://www.reuters.com/world/us/fcc-finalizes-6-million-fine...</a></p></li><li><p><strong>帮助失语者</strong></p><p>https\://www.nature.com/articles/s41598-024-84728-y</p></li><li><p><strong>重新用自己的声音表达</strong></p><p>https\://www.thetimes.com/uk/healthcare/article/elevenlabs-voice-clone-ai-als-t3ntnpcl7</p></li></ul><p>那么，我们该如何实现“有意义的使用”而不是“恶意的滥用”？我们正在探索一种可能的答案：引入一个**语音同意验证机制 (voice consent gate)。也就是说，只有当说话人明确表达了同意，语音克隆模型才能使用其声音。换句话说，模型不会擅自“说出”你的声音，除非你亲口同意。</p><p>下面是我们对这一想法的基础演示：</p><h3><strong>实践中的伦理：将“同意”融入系统基础设施</strong></h3><p>语音同意门是我们正在尝试的一种基础设施设计，用来把 <strong>“同意”</strong> 这样的伦理原则直接嵌入到 AI 系统的工作流程中。在我们的演示中，模型只有在检测到说话人清楚地说出了同意语句之后，才会启动。也就是说，“同意”成为系统运行的前提条件，让原本抽象的伦理原则变成了具体可操作的系统规则，并形成可追溯、可审核的交互记录：AI 模型只会在明确同意之后才运行。</p><p>这样的设计不仅适用于语音克隆，更展示了如何从系统层面保障用户的自主权，以及如何将透明和同意变成 <strong>可执行的功能</strong>，而不仅仅是口头承诺。</p><h2>技术细节</h2><p>要构建一个包含语音同意门的基础语音克隆系统，你需要以下三部分：</p><ol><li>一种方法，用来生成说话人当前上下文中可用的、表达明确同意的唯一语句。</li><li>一个 <strong>自动语音识别 (ASR) 系统</strong>，用于识别说话人所说的同意语句。</li><li>一个 <strong>语音克隆的文本转语音 (TTS) 系统</strong>，可以接收文本和说话人的语音片段来合成新的语音。</li></ol><p><strong>我们的发现是：</strong> 现在很多语音克隆模型只需要一句话就能模仿说话人的声音，因此这句用于表达“同意”的句子，也可以同时作为语音克隆的输入数据。</p><h4><strong>实现方法</strong></h4><p><strong>关于“同意”：</strong> 在英语语音克隆系统中创建语音同意门的方式是：为说话人生成一句简短、自然、约 20 个单词左右的英文语句，让其朗读。这句话要明确表达对当前使用情境的知情同意。我们建议在句中明确包含“同意语句”和“模型名称”，比如：“I give my consent to use the voice cloning model with my voice (我同意使用 &lt;模型名称&gt; 语音克隆模型克隆我的声音) ”。同时建议使用 <strong>麦克风实时录音</strong>，而不是上传音频文件，以防止使用之前录音剪辑过的语音。使用全新 (从未说过的) 句子也能进一步确保这个“同意”是针对当前情境、主动做出的、知情且明确的同意。</p><p>当然，这种设计不是万无一失的。理论上，人们依然可能用其他 TTS 系统来伪造这段“同意”语音。未来的版本可以进一步尝试音频来源验证、说话人嵌入相似度分析、或通过实时录音元数据来提升验证能力。</p><p><strong>关于“适合语音克隆的语句”部分：</strong> 已有的语音克隆研究表明，用于训练模型的语句需要具备以下几个特点：</p><ul><li><strong>音素多样性：</strong> 语句中应包含多种元音和辅音，确保发音覆盖范围广，参考文献。</li><li><strong>语气中性或礼貌：</strong> 语音应保持自然、平静或友善的语调，参考文献，避免情绪化表达。</li><li><strong>录音环境安静，发音自然：</strong> 尽量避免背景噪音，并在说话人状态舒适时录制。</li><li><strong>语音片段要有完整的起止：</strong> 录音剪辑时不能截断词语，要保留完整的一句话，确保语音首尾清晰。</li><li><p><strong>参考文献</strong></p><p>https\://proceedings.neurips.cc/paper\_files/paper/2018/file/6832a7b24bc06775d02b7406880b93fc-Paper.pdf</p></li><li><p><strong>参考文献</strong></p><p>https\://dl.acm.org/doi/10.5555/3666122.3666982</p></li></ul><p>为了实现这两个目标，在演示中我们使用语言模型自动生成一组句子：一句用于表达明确的同意，另一句则是中性内容，用于增加音素多样性 (覆盖不同的元音、辅音和语调) 。 每次生成时，系统会随机选择一个日常话题 (如天气、美食或音乐) ，使句子内容丰富多样，也更自然好读，有助于录音清晰、自然，并具备良好的语音质量，同时包含明确的同意声明。 这个句子生成过程是 <strong>自动完成</strong> 的，而不是预先写好的，确保每位用户都会获得 <strong>独一无二</strong> 的句子组合，避免文本被重复使用，也确保每次录音都是针对当前会话场景所做出的具体同意。 换句话说，语言模型在每次“同意实例”中都会生成两句全新的句子：</p><ul><li>一句表达明确的使用同意，</li><li>一句则用于增加语音中的音素多样性。</li></ul><p>比如，模型可能会生成如下内容：“I give my consent to use my voice for generating audio with the model EchoVoice. The weather is bright and calm this morning.”</p><p>这种做法确保了所有用于语音克隆的样本都具有 <strong>可验证的明确同意</strong>，同时也符合高质量语音合成所需的技术标准。 (注：生成句子的语言模型不必是“大型语言模型”，因为后者本身也可能涉及额外的同意问题。)</p><p><strong>更多例子：</strong></p><ul><li>“I give my consent to use my voice for generating synthetic audio with the Chatterbox model today. My daily commute involves navigating through crowded streets on foot most days lately anyway.”</li><li>“I give my consent to use my voice for generating audio with the model Chatterbox. After a gentle morning walk, I'm feeling relaxed and ready to speak freely now.”</li><li>“I agree to the use of my recorded voice for audio generation with the model Chatterbox. The coffee shop outside has a pleasant aroma of freshly brewed coffee this morning.”</li></ul><h4><strong>解锁语音同意门</strong></h4><p>当说话人读出的语句与系统生成的文本完全匹配后，语音克隆系统便可启动，并使用这段“同意”语音作为训练输入。</p><p>目前已有几种实现方式，当然我们也很欢迎更多建议：</p><ul><li><strong>演示中提供的方式：</strong> 同意门一旦开启，系统就可以直接进入语音克隆阶段，用户可输入任意文本，生成对应的合成语音。此时，模型会直接利用“同意”语音作为训练数据。</li><li><strong>可选方案一： </strong> 修改演示中的代码，使系统可以接受多个语音文件来建模用户的声音——比如用户授权使用网络上存在的录音。此时提示语和同意语句也需相应调整。</li><li><strong>可选方案二： </strong> 将同意录音保存下来，以便后续系统中用于生成任意语句。这可以通过 <code>huggingface_hub</code> 上传功能实现，相关指南在此。同样需要根据使用场景调整提示语和同意内容。</li><li><p><strong>相关指南在此</strong></p><p>https\://hf.co/docs/huggingface\_hub/en/guides/upload</p></li></ul><blockquote><h4><strong>点此查看我们的演示！</strong></h4><p>你可以复制代码，自行调整使用。</p></blockquote><ul><li><p>点此查看我们的演示！</p><p>https\://hf.co/spaces/society-ethics/RepeatAfterMe</p></li></ul><p>该代码是模块化的，可以根据项目需求进行裁剪和改写。我们也正在持续优化系统的稳健性与安全性，欢迎提出改进建议。</p><p>只要负责任地使用，这项技术并不一定是“幽灵般”的存在。它完全可以成为人与机器之间 <strong>相互尊重的协作工具</strong> ——没有幽灵上身，只有良好规范的技术实践。🎃</p><blockquote><p>英文原文: </p><p>https\://huggingface.co/blog/voice-consent-gate</p><p>原文作者: </p><p>Margaret Mitchell, Lucie-Aimée Kaffee</p><p>译者: </p><p>Luke,  Hugging Face Fellow</p></blockquote><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047499223" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047499224" alt="" title="" loading="lazy"/></p><p><a href="https://link.segmentfault.com/?enc=%2Bd8T943K5whOaOTK9Ndwmw%3D%3D.K7gVXH1znpZ0AyzmfIEClNYrieC3FRbOLGSeJkfWZzg%3D" rel="nofollow" target="_blank">阅读更多 Voice Agent 学习笔记：了解最懂 AI 语音的头脑都在思考什么</a></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047499225" alt="" title="" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[【FAQ】HarmonyOS SDK 闭源开放能力 — Share Kit HarmonyOS_SD]]></title>    <link>https://segmentfault.com/a/1190000047499228</link>    <guid>https://segmentfault.com/a/1190000047499228</guid>    <pubDate>2025-12-24 10:05:03</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><strong>1.问题描述：</strong></p><p>分享的时候，如何获取精准的utd类型？</p><p><strong>解决方案：</strong></p><p>使用Share Kit时，宿主应用和目标应用定义数据类型须遵照<a href="https://link.segmentfault.com/?enc=Y9APDbatGXmc9oUd%2BaqqBQ%3D%3D.%2F%2BySzwP2LhVQZsa3X1YMxWWvkVSpzLozgPjqBHjplzR3%2FuZg%2BKTCkpdEZPSOTsvOZ1IA70LSzIalRCnsz20M1n4IMXsx5RC69SZgzxb1TCbzziIE6%2F2cD%2BtUk8rGNJzU" rel="nofollow" target="_blank">UDMF</a>（统一数据管理框架）定义的<a href="https://link.segmentfault.com/?enc=QHSXFNwl0Qpye%2FY2FEnXtw%3D%3D.dH35WmI0GTPJahiFJuQP8SEiCbQ9WpUkbPOXRCH1M%2BZxxY0BRKp36%2B6uoAOklF9aFDQkHwRu5wjUoBSCQhp3bwgmjDMudRM0ab8yI7l4mmBqVqkK5JJRdm4yOUDuTqS%2B" rel="nofollow" target="_blank">UTD</a>（统一类型描述符）规范。</p><p>UTD中定义的标准化数据类型在设计原则上按物理和逻辑分为两类:</p><ul><li>按物理分类的根节点为general.entity，用于描述类型的物理属性，比如文件、目录等，具体可见图1。</li></ul><ul><li>按逻辑分类的根节点为general.object，用于描述类型的功能性特征，如图片、网页等，具体可见图2。</li></ul><p>全部的数据类型可以参考：<a href="https://link.segmentfault.com/?enc=zfL0j0qpQKq4dE3nW7T3dQ%3D%3D.9GJNoQorYkegAxDvaDKVRaWfGKsiwaEqW7lF1k2jYyHjz77FFRUTkvOMDCKLWv%2BQJXByqry1hNfg3WbIYah8FAH%2Fp4wzH1xBDNt5SOZ%2BCjp85K43mzvv%2FYevxo0qc%2FA6" rel="nofollow" target="_blank">UTD基础类型表格</a>。</p><p>目标应用需要在应用配置文件（src/main/module.json5）的skills配置actions为ohos.want.action.sendData，并且uris需穷举所有支持的数据类型。</p><pre><code class="Json">
"extensionAbilities": [  

  {

    "name": "TestShareAbility",

    "srcEntry": "./ets/abilities/TestShareAbility.ts",

    "type": "share", // 支持分享数据处理

    "description": "xxx",

    "exported": true,

    "label": "$string:xx_label",

    "icon": "$media:icon",

    "skills": [

      {

        "actions": [

          "ohos.want.action.sendData"

        ],

        // 目标应用在配置支持接收的数据类型时，需穷举支持的UTD

        // 比如：支持全部图片类型，可声明：general.image，如支持全部数据类型，可声明：general.object

        "uris": [

          {

            "scheme": "file",

            "utd": "general.text",

            "maxFileSupported": 1

          },

          {

            "scheme": "file",

            "utd": "general.png",

            "maxFileSupported": 1

          },

          {

            "scheme": "file",

            "utd": "general.jpeg",

            "maxFileSupported": 1

          }

        ]

      }

    ]

  }

]</code></pre><p><strong>2.问题描述：</strong></p><p>如何判断设备是否支持碰一碰分享？</p><p><strong>解决方案：</strong></p><p>通过<a href="https://link.segmentfault.com/?enc=HQOdYR7C%2BkGkbAj%2FTcSAFw%3D%3D.MjEMeTUdCE0kYZboKiVs9IBTfTzvxnbVwvkiVFWJnLDNhnn23TNhrCLAd9XN88R8UCvU2K6SGNx3ajoXY%2FQDblmmumAkr1%2Ba0dQLt1eR7jcT7u9tHs769WTX6WBPCs%2FS" rel="nofollow" target="_blank">canIUse</a>检测设备是否支持碰一碰能力：</p><pre><code class="TypeScript">
if (canIUse('SystemCapability.Collaboration.HarmonyShare')) {

  // 支持一碰分享的能力.

}
</code></pre><p><strong>3.问题描述：</strong></p><p>如何获取用户点击了分享到哪个平台或者保存图片到本地事件？</p><p><strong>解决方案：</strong></p><p>参考：<a href="https://link.segmentfault.com/?enc=nApxOuJlKrkSlonx%2B6SmdA%3D%3D.q60RPeRHisASATeTk92oYvxHTlnLYJTqjU770MBuo24iqtZTANZ%2Fx6qcF5iOMf8mapmhQ0uizled5jhXSgEb2vGxzC2en%2FAHpVzEmys%2BCtaWbx3F7NuWMmrJbe3B%2BEUB" rel="nofollow" target="_blank">systemShare（分享）</a>下的<a href="https://link.segmentfault.com/?enc=sYhVBc6NR93Oux3Pk5J6JA%3D%3D.Rm5JujS59TS6CW5wAOCEJU%2FMlo8bee12xXs7fiPoFxZ52XmZrFNw6N%2B5dCHCX%2F23VgBzLgi6P4jrGT%2BsFiIiFk%2FVb68bLJAOtF7oyu0kdvPpzBj7kRtokdivAfhYMKDvLDlP2gUXMz2fuWBQ8RctsA%3D%3D" rel="nofollow" target="_blank">on('shareCompleted')</a>接口，注册用户完成分享事件监听。返回用户分享渠道，可用于数据统计等。</p><p><strong>4.问题描述：</strong></p><p>目标应用已配置支持png和jpeg图片类型，但截屏分享时，分享方式区仍未显示目标应用。</p><p><strong>解决方案：</strong></p><p>目标应用在配置支持接收的数据类型时，需穷举支持的utd。支持全部图片类型，可声明：general.image。</p><p><strong>5.问题描述：</strong></p><p>目标应用配置了module.json5，但是发起分享时却找不到目标应用是什么原因</p><p><strong>解决方案：</strong></p><p>宿主应用发起分享时，需要确认发起的分享的数据类型是否和目标应用匹配。</p><p>例如宿主应用发起分享AUDIO类型数据：</p><pre><code class="ts">
 let data: systemShare.SharedData = new systemShare.SharedData({

    utd: utd.UniformDataType.AUDIO,

    content: 'Hello HarmonyOS'

  });
</code></pre><p>目标应用需要配置AUDIO数据类型，配置uri可以参考上方解决方案：</p><pre><code class="Json">
{

  "scheme": "file",

  "utd": "general.audio",

  "maxFileSupported": 1

}
</code></pre><p><strong>6.问题描述：</strong></p><p>MP3文件分享给外部，无可打开应用。</p><p><strong>解决方案：</strong></p><p>【问题描述】</p><p>在目标应用的module.json5文件中进行配置，但是分享面板的分享方式区没有目标应用可以进行选中分享。</p><p>1、目标效果：在文件管理中选择指定文件后，点击分享可以在分享面板中显示目标应用的图标并点击该图标进行文件分享；</p><p>2、实际效果：在文件管理中选择指定文件后，点击分享可以在分享面板中未显示目标应用的图标。</p><p>待分享的module.json的配置信息如下：</p><pre><code>
  "module": {

    "abilities": [

      {

        "skills": [

          {

            "actions": [

              "ohos.want.action.sendData"

            ],

            "uris": [

              {

                "scheme": "file",

                "type": "application/caj"

              },

              {

                "scheme": "file",

                "type": "application/pdf"

              },

              {

                "scheme": "file",

                "type": "application/epub"

              },

            ]

          }

        ]

      }

    ]

  }
</code></pre><p>【背景知识】</p><p>分享服务可以根据分享的数据类型、数量等信息构建分享面板，为用户提供内容预览、推荐分享联系人、关联应用及操作界面，便于用户快速选择分享应用或操作，将内容分发到目标应用。如果应用需要显示在分享面板，则需要构建数据处理能力并按照配置要求在应用配置文件中声明。</p><p>【问题定位】</p><p>分析module.json5文件的配置项发现uris数组中定义的是type字段，这个字段无法在使用分享服务时匹配目标应用从而导致目标应用未出现在分享面板的分享方式区。</p><p>【分析结论】</p><p>module.json5文件中uris数组中定义了错误的字段type所以无法选择目标应用进行分享，需要设置utd字段并且取值为标准化数据类型。</p><p>【修改建议】</p><p>1、正确在目标应用的module.json5文件中声明utd字段并设置需要分享的文件所对应的<a href="https://link.segmentfault.com/?enc=Fz4682kuN1h4bPG6mcYCOA%3D%3D.EL3KGhFHRcdfgbucc0CSEOdL2YrRi0tHMvCD5MJkeJ%2BydHU92GA%2Br1rtgVgrqIS3XBIdSoyepazUlICN10lD%2F1ZH%2BxezOrcvZMjCRY4SmklL0HwBrM7pkzdZRDytvvhXqf4Iq%2BVZHHU8vpUmHdIl1g%3D%3D" rel="nofollow" target="_blank">标准数据化类型</a>。</p><p>2、示例配置代码如下：</p><pre><code>
 "skills": [

   {

     "entities": [

       "entity.system.home"

     ],

     "actions": [

       "action.system.home"

     ]

   },

   {

     "actions": [

       "action.system.home",

       "ohos.want.action.viewData",

       "ohos.want.action.sendData"

     ],

     "uris": [

       {

         "scheme": "file",

         //所有表示逻辑内容类型的基类型,

         "utd": "general.object",

         //标识一次能接收或打开的最大数量。,

         "maxFileSupported": 1

       }

     ]

   }

 ]
</code></pre><p>3、打开测试真机的文件管理，选择pdf文件，点击分享可以在分享面板选择已完成上述配置的目标应用。</p>]]></description></item><item>    <title><![CDATA[【FAQ】HarmonyOS SDK 闭源开放能力 — Form Kit HarmonyOS_SDK]]></title>    <link>https://segmentfault.com/a/1190000047499231</link>    <guid>https://segmentfault.com/a/1190000047499231</guid>    <pubDate>2025-12-24 10:04:31</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><strong>1.问题描述：</strong></p><p>卡片里的Iamge无法显示网络图片。</p><p><strong>解决方案：</strong></p><p>通过FormExtensionAbility在元服务卡片上加载网络图片有以下两种方案：</p><ul><li>方案一：先下载网络图片到本地，参考<a href="https://link.segmentfault.com/?enc=frsRas7IoxqvA8FWtS7Iwg%3D%3D.qBd7Oq8GwV0gv%2BB0hQ8H1cuHC2Tl%2Fof8ozMoZ8TjvlWQI0bZpTniQ0tHuB8LwiOjSbLcCL64sSaKuFV4SZRwFYG2WIGoMFccv5jgD7PvSlEixVgfYwzqBtxbzptVaim5" rel="nofollow" target="_blank">元服务卡片上加载本地图片示例代码</a>在EntryFormAbility的onAddForm生命周期回调中实现本地文件的刷新。刷新后，在卡片页面通过backgroundImage属性展示EntryFormAbility传递过来的卡片内容。</li><li>方案二：申请ohos.permission.INTERNET权限，创建HTTP请求，下载网络图片数据并保存到应用的临时文件中，在EntryFormAbility的onFormEvent生命周期回调中实现网络文件的刷新。刷新后，在卡片页面通过backgroundImage属性展示EntryFormAbility传递过来的卡片内容。使用这种方案在元服务卡片上加载网络图片示例代码详见<a href="https://link.segmentfault.com/?enc=aTFiie%2FuCtB8rLnejjd%2FJg%3D%3D.5feKQfFr8j%2BmljvDCogw0QDQSYTg7%2FrcxPaaN6i7kUGxC16ncItBwsInVteTxpeJ25YER7tYVIvHr91Yq%2F2G5SJkCJpSAgJQ0jRjC2J0nrWu8O%2FdKciVGNtiOfKhI4YT" rel="nofollow" target="_blank">元服务卡片上加载网络图片指南</a>。</li></ul><p><strong>2.问题描述：</strong></p><p>如何在主应用中获取卡片的添加/移除?</p><p><strong>解决方案：</strong></p><p>一、卡片添加/移除的场景以及相关卡片生命周期<br/>由于目前卡片添加/移除至桌面目前没有直接完成的回调响应，可以通过onAddForm和onRemoveForm结合记录保存到桌面的卡片，onAddForm/onRemoveForm添加至桌面的生命周期触发流程如下：</p><ol><li>长按应用图标-&gt;服务卡片-&gt;打开卡片列表，触发onAddForm （卡片列表中有几张卡片生命周期就会回调onAddForm几次）。例如：打开下面的卡片列表，卡片列表中有3张卡片，可以看到日志中OnAddForm回调了3次。</li><li>服务卡片列表取消-&gt;触发onRemoveForm（卡片列表中有几张卡片生命周期就会回调触发onRemoveForm几次）。 例如：点击x号取消了服务卡片列表，则会出发OnRemoveForm回调3次。</li><li>服务卡片列表选择-&gt;某一张卡片添加到桌面（卡片生命周期onAddForm选中的卡片，onRemoveForm其余卡片）。例如：添加一张卡片至桌面，则会OnAddForm选中的的卡片，OnRemove另外两张卡片。</li><li>移除某一张卡片（卡片生命周期onRemoveForm移除的卡片）。例如：在桌面移除一张卡片，会OnRemove当前移除的卡片。<br/>综上流程，卡片整个添加至桌面的流程中，中间状态生命周期onAddForm/onRemoveForm会回调多次，但是最终卡片新增还是移除是确定的。</li></ol><p>二、实现卡片添加/移除管理以及通知主应用的实现<br/>本方案使用首选项通过在服务卡片中onAddForm/onRemoveForm回调函数中，对formId进行持久化缓存，并在主应用中进行跨进程读取。以下是实现步骤：</p><ol><li>实现一个公共的单例首选项类以供服务卡片/主应用共同使用，需要注意的是，这里首选项对于跨进程的场景下，需要使用同一个context上下文对象，后面在调用处均使用了this.context.getApplicationContext()保持统一。</li></ol><pre><code class="language">import { preferences } from '@kit.ArkData';

export class PreferencesHelper {
private static instance: PreferencesHelper | null = null
private preferences: preferences.Preferences | null = null
private ctx: Context | null = null
private PREFERENCE_NAME:string = "preferences"

private constructor() {}

public static getInstance(ctx: Context) {
  if (PreferencesHelper.instance === null) {
    PreferencesHelper.instance = new PreferencesHelper()
  }
   PreferencesHelper.instance.init(ctx)
  return PreferencesHelper.instance
}

private init(ctx: Context) {
  this.ctx = ctx
  this.preferences = preferences.getPreferencesSync(ctx, { name: this.PREFERENCE_NAME})
}

public get(key: string, defaultValue: Array&lt;string&gt;) {
  if (!this.preferences) {
    return
  }
  console.log("get ", defaultValue);
  let options: preferences.Options = { name: this.PREFERENCE_NAME };
   preferences.removePreferencesFromCacheSync(this.ctx, options);
  return this.preferences.getSync(key, defaultValue)
}

public put(key: string, defaultValue: preferences.ValueType) {
  if (!this.preferences) {
    return
  }
  console.log("put ", defaultValue);
  this.preferences.putSync(key, defaultValue)
   this.preferences.flushSync()
}

public clear() {
  PreferencesHelper.instance = null
  this.preferences = null
}
}</code></pre><ol start="2"><li>当长按应用图标拉起应用卡片列表时以及在卡片列表中选择一张服务卡片时，会触发onAddForm，此时将卡片id保存下来：（注意：formlist需要做去重）</li></ol><pre><code class="ets">      // 服务卡片FormExtensionAbility.ets
      onAddForm(want: Want) {
         console.log('onAddForm')
        let ctx = this.context.getApplicationContext()
        let formList: Array&lt;string&gt; =
           PreferencesHelper.getInstance(ctx).get('formList', []) as Array&lt;string&gt;
        if (want.parameters) {
          let formId = (want.parameters['ohos.extra.param.key.form_identity']) as string
          // 为了保证formId的唯一性，需要对formList去重
          !formList.includes(formId) &amp;amp;&amp;amp; formList.push(formId)
           PreferencesHelper.getInstance(ctx).put('formList', formList)
        }
        const formData = '';
        return formBindingData.createFormBindingData(formData);
      }</code></pre><ol start="3"><li>服务卡片列表取消时或者在桌面移除卡片时，会触发onRemoveForm，此时将记录里对应的数据删除，剩余的即是添加到桌面的卡片：（注意：formlist需要做去重）</li></ol><pre><code class="ets">        // 服务卡片FormExtensionAbility.ets
        onRemoveForm(formId: string) {
          let ctx = this.context.getApplicationContext()
          let formList: Array&lt;string&gt; = PreferencesHelper.getInstance(ctx).get('formList', []) as Array&lt;string&gt;
          // 为了保证formId的唯一性，需要对formList去重
          formList = formList.filter(item =&amp;gt; item !== formId)
           PreferencesHelper.getInstance(ctx).put('formList', formList)
        }</code></pre><p>4.然后，在主应用中对formId进行查询：（注意：主应用需要和卡片使用同一个context）</p><pre><code class="ets">        // EntryAbility.ets
        build() {
          RelativeContainer() {
            Text(this.message)
              .id('HelloWorld')
          }
          .height('100%')
          .width('100%')
          .onClick(()=&amp;gt;{
            let formList: Array&lt;string&gt; =
               PreferencesHelper.getInstance(this.context.getApplicationContext()).get('formList', []) as Array&lt;string&gt;
             console.log("formList size %d", formList.length);
            for (let index = 0; index &amp;lt; formList.length; index++) {
              const element = formList[index];
               console.log("formId %d", element);
            }
          })
        } </code></pre><p><strong>3.问题描述：</strong></p><p>卡片列表如何展示网络图片？</p><p><strong>解决方案：</strong></p><ol><li><p>卡片里面没有直接联网的权限，加载网络图片需要先将网络图片下载到本地，下载网络图片需要使用到网络能力，需要申请<a href="https://link.segmentfault.com/?enc=hCR2eYxZyIGKjZJLlZCUNw%3D%3D.SQkbLbF0HaSwJF%2FPba6DAYn51gNO0r9gQXP8EuSLqU98e0xip6%2BvFgMW7YyeHur%2BHqSb2EGRBgp0NHhYXIcxV3fMbGUJzINFsNLhWIAn2nKXMdZoUMVqpbuRZD63OS2U" rel="nofollow" target="_blank">ohos.permission.INTERNET</a>权限。</p><pre><code class="ets">  let filesDir = context.getApplicationContext().filesDir
  let filePath = filesDir + 'xxx.png'
  request.downloadFile(context, {
 url: 'xxx', // 此处为图片下载地址
 filePath,
  }).then((downloadTask: request.DownloadTask) =&amp;gt; {
 downloadTask.on('complete', () =&amp;gt; {
   console.log('download complete')
 })
  }).catch((err: BusinessError) =&amp;gt; {
 console.error(`Invoke downloadTask failed, code is ${err.code}, message is ${err.message}`);
  });
</code></pre></li><li><p>EntryFormAbility中的onFormEvent生命周期回调中实现网络文件的刷新。</p><pre><code class="ets">  // 卡片需要显示图片场景，formData中formImages必填且不可改名,key值与thumb(结构和名称可自定义)的值需保持一致，值为key对应的fd

  class News {
 thumb?: string = '';
 title: string = '';
  }

  class FormData {
 list: News[] = []
 formImages?: Record&lt;string, number&gt; = {};
  }

  onFormEvent(formId: string) {
 // 下载网络图片到本地，通过formImages
 let imgPath = await download(ctx)
 let file = fs.openSync(imgPath)
 let imageMap: Record&lt;string, number&gt; = {}
 imageMap[imgPath] = file.fd
 let res: FormData = {
   list: [
     {
       title: 'new',
       thumb: imgPath, // 需要与formImages的key值一致
     }
   ],
   formImages: imageMap
 }
 await formProvider.updateForm(formId, formBindingData.createFormBindingData(res))
 fs.closeSync(file)
  }</code></pre></li><li>在卡片中通过memory:// + fileName的格式展示。</li></ol><pre><code class="ets">  Image('memory://' + item?.thumb)</code></pre>]]></description></item><item>    <title><![CDATA[TypeScript 中 Type 和 Interface 傻傻分不清？看完这篇就不纠结了 Sean]]></title>    <link>https://segmentfault.com/a/1190000047499253</link>    <guid>https://segmentfault.com/a/1190000047499253</guid>    <pubDate>2025-12-24 10:03:55</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>你是不是也有过这样的困惑：</p><p>打开一个老项目，或者在做 Code Review 时，发现代码里一会儿是 <code>interface Props</code>，一会儿又是 <code>type State</code>。问同事为什么要混用，他也支支吾吾说不出个所以然，最后只能来一句：“哎呀，反正都能跑，看心情呗。”</p><p><strong>但在 TypeScript 的世界里，“能跑”和“写得好”是两码事。</strong></p><p><code>type</code>（类型别名）和 <code>interface</code>（接口）这对双胞胎，在 TS 诞生之初就一直相爱相杀。它们确实太像了，像到在绝大多数 CRUD 业务开发中，你闭着眼随便选一个都不会报错。</p><p>但是，作为一个追求代码质量的开发者，我们不能止步于此。</p><p>今天，我们跳出表面的语法糖，从底层机制入手，彻底搞清楚它们的本质区别，并给你一套<strong>最佳实践方案</strong>。拒绝选择困难症。</p><h3>1. 表象：90% 的重合度与其误区</h3><p>为什么大家会纠结？因为在定义“对象”的形状（Shape）时，它们长得几乎一模一样。</p><p>看看下面的代码，你能一眼看出区别吗？</p><pre><code class="tsx">// 使用 interface
interface UserI {
  name: string;
  age: number;
}

// 使用 type
type UserT = {
  name: string;
  age: number;
}</code></pre><p>在日常使用中，如果你想实例化一个对象，或者在函数参数中约束类型，这俩兄弟的表现是<strong>完全一致</strong>的。它们都支持：</p><ul><li>定义对象结构</li><li>定义函数签名</li><li>支持泛型</li><li>支持类（Class）的实现（implements）</li></ul><p>但这正是新手容易陷入的误区：<strong>以为它们是可以随意互换的同义词。</strong> 实际上，TS 设计这两个概念，是为了解决完全不同的问题。</p><h3>2. 核心：声明合并、类型表达与扩展性</h3><p>区别不仅存在，而且在关键时刻决定了你的架构设计是否合理。主要体现在以下三个核心维度：</p><h3>2.1 声明合并 (Declaration Merging) —— Interface 的必杀技</h3><p>这是 <code>interface</code> 独有的特性，也是它存在的最大理由。</p><p>场景模拟：</p><p>你引入了一个第三方库（比如 Vue 或 jQuery），但你发现它的全局对象上少了一个你需要的属性。这时，如果你用 interface，你可以直接在自己的代码里“补”上这个属性。</p><pre><code class="tsx">// 假设这是第三方库定义的 interface
interface User {
  name: string;
}

// 你的代码中再次定义同名 interface
interface User {
  age: number;
}

// ✨ TS 会自动把它们缝合在一起！
const me: User = {
  name: "Gemini",
  age: 18 // 必须两个属性都有，否则报错
};</code></pre><p>反观 type：</p><p>它是封闭的（Closed）。一旦定义，无法通过同名方式修改。</p><pre><code class="tsx">type User = {
  name: string;
};

// ❌ 报错：Duplicate identifier 'User'.
type User = {
  age: number;
};</code></pre><p><strong>💡 结论：</strong> <code>interface</code> 具有开放性，允许后续扩展；而 <code>type</code> 具有封闭性，更适合确定的业务逻辑。</p><h3>2.2 类型表达能力 —— Type 的主场</h3><p><code>type</code> 的全称是 <strong>Type Alias（类型别名）</strong>。既然是别名，它就能给<strong>任何东西</strong>起名字，不仅仅是对象。</p><p>在处理复杂类型时，Type 的灵活性完胜 Interface：</p><ul><li><p><strong>联合类型 (Union Types)：</strong> 前端开发中最常用的功能。</p><pre><code class="tsx">type Status = 'pending' | 'success' | 'failed';
type ID = string | number;</code></pre><p><em>Interface 无法直接定义这种“或”的关系。</em></p></li><li><p><strong>元组 (Tuple)：</strong></p><pre><code class="tsx">type Point = [number, number];</code></pre></li><li><p>类型体操：</p><p>当你使用 Pick、Omit、Record 或者条件类型（Conditional Types）时，产出的结果通常都是 type。</p></li></ul><h3>2.3 扩展方式：Extends vs Intersection</h3><p>虽然两者都能实现“继承”的效果，但语义不同。</p><ul><li><strong>Interface 使用 <code>extends</code></strong>：侧重于面向对象的层级继承。</li><li><strong>Type 使用 <code>&amp;</code> (交叉类型)</strong>：侧重于集合的合并。</li></ul><p>虽然通常可以互通，但在处理冲突属性时，<code>interface</code> 会直接报错提醒，而交叉类型（<code>&amp;</code>）可能会产生 <code>never</code> 类型，导致错误提示不够直观。</p><hr/><h3>3. 规范：一套拿来即用的最佳实践</h3><p>讲了这么多理论，回到最初的问题：<strong>我们在项目中到底该怎么选？</strong></p><p>与其每次都纠结，不如遵循这套简单的 <strong>“二选一法则”</strong>，这也符合目前主流大厂（如 Google 规范）和 React 社区的推荐趋势：</p><h3>场景一：你在编写库 (Library) 或第三方包</h3><p><strong>请优先使用 <code>interface</code>。</strong></p><p><strong>理由：</strong> 作为库的作者，你需要为你的用户留出“后路”。用户可能需要利用“声明合并”的特性，向你的全局接口中注入自定义属性（比如扩展 <code>Window</code> 对象或给 <code>Request</code> 对象增加 <code>user</code> 字段）。使用 Interface 是对使用者的尊重。</p><h3>场景二：你在编写业务应用 (Application / UI 组件)</h3><p><strong>请优先使用 <code>type</code>。</strong></p><p><strong>理由：</strong></p><ol><li><strong>一致性 (Consistency)：</strong> 既然 <code>type</code> 能搞定对象、联合类型、元组等所有情况，而 <code>interface</code> 只能搞定对象，那么全员使用 <code>type</code> 可以让代码风格更统一。</li><li><strong>安全性 (Safety)：</strong> 在业务代码中，我们通常不希望定义好的类型被莫名其妙地“自动合并”了（这是隐患）。<code>type</code> 的报错提醒能让你更安全。</li><li><strong>React 生态：</strong> 现在的 React 社区更倾向于用 <code>type</code> 来定义 <code>Props</code> 和 <code>State</code>，因为它在处理组件复合类型时更加直观。</li></ol><hr/><h3>总结</h3><p>为了方便记忆，我做了一张对比速查表：</p><table><thead><tr><th><strong>特性</strong></th><th><strong>Interface</strong></th><th><strong>Type</strong></th></tr></thead><tbody><tr><td><strong>核心理念</strong></td><td>描述对象的形状 (Shape)</td><td>任何类型的别名 (Alias)</td></tr><tr><td><strong>声明合并</strong></td><td>✅ <strong>支持 (自动合并)</strong></td><td>❌ 不支持 (会报错)</td></tr><tr><td>**联合类型 (</td><td>)**</td><td>❌ 不支持</td></tr><tr><td><strong>映射/条件类型</strong></td><td>❌ 不支持</td><td>✅ 支持</td></tr><tr><td><strong>最佳使用场景</strong></td><td><strong>编写库 (Library)</strong></td><td><strong>编写应用 (App)</strong></td></tr></tbody></table><p>一句话口诀：</p><p>对外 API（库）用 Interface，对内业务逻辑用 Type。如果你实在拿不准，就用 Type，直到你必须用 Interface 为止。</p><p>你们团队的代码规范里，是强制用 <code>type</code> 还是 <code>interface</code>？还是像大部分项目一样“随缘混用”？</p><p>欢迎在评论区留言，我们一起聊聊 TS 里的那些坑！</p>]]></description></item><item>    <title><![CDATA[高兼容性、联动闭环、规模化：医疗行业数据分类分级管理系统解决方案 老实的剪刀 ]]></title>    <link>https://segmentfault.com/a/1190000047499263</link>    <guid>https://segmentfault.com/a/1190000047499263</guid>    <pubDate>2025-12-24 10:03:00</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>高兼容性、联动闭环、规模化：医疗行业数据分类分级管理系统解决方案<br/>一、概要<br/>提示： 本文旨在系统阐述医疗机构在数据分类分级方面的核心挑战与智能化解决方案。随着医疗数字化转型的深入，数据已成为医院运营与科研创新的核心资产，其安全与合规管理日益严峻。“知源-AI数据分类分级系统”，以高兼容性、联动闭环与规模化为核心特性，帮助医疗机构实现数据资产的全链路智能治理。该系统已在多家医院落地，显著提升了数据识别效率与分类准确率，推动医疗数据在合规基础上实现安全共享与价值释放。<br/>二、背景/挑战<br/>提示： 医疗行业正面临数据爆发式增长与监管日益严格的双重压力。在智慧医疗快速推进的背景下，医疗数据通过HIS、LIS、PACS等系统广泛流转，涵盖患者信息、临床诊疗、科研实验等多类敏感内容。与此同时，《数据安全法》《个人信息保护法》及《医疗数据安全管理办法》等法规相继出台，明确要求医疗机构实施数据分类分级与动态管控。医疗机构在数据管理方面普遍存在“数据不清、分级不准、管控乏力”等问题，亟需一套系统化、智能化的治理方案。<br/>三、行业痛点分析<br/>提示： 当前医疗数据管理主要存在以下几大痛点。一是数据形态复杂且分散，结构化与非结构化数据混杂，传统人工方式难以应对日均上万份的数据处理需求；二是分类标准与业务脱节，往往为合规而分类，忽视临床与科研的实际使用场景；三是系统之间数据孤岛现象严重，科室自建“影子库”增多，全院数据资产难以统一掌控；四是合规风险高，隐私泄露可能引发纠纷甚至公共卫生事件。这些痛点严重制约了医疗数据的安全管控与价值挖掘。<br/>四、<a href="https://link.segmentfault.com/?enc=yLqXVDsupcYSru3AIx%2BlsQ%3D%3D.9Afc8M2Ug7jc6PjZc6Dq5G7wW%2FqCAlN5%2FYtwX%2F46%2FdE%3D" rel="nofollow" target="_blank">解决方案</a><br/>提示： “知源-AI数据分类分级系统”构建了覆盖“发现-分级-应用-管控”的全链路闭环方案。“知源-AI数据分类分级系统”支持多模式非侵入式接入，可自动扫描各类数据库与文件，全面发现医疗数据资产；内置医疗行业分类分级模板，支持自定义标签，贴合肿瘤、儿科、互联网医院等特色业务；依托AI多模态引擎与医疗知识图谱，实现自动化分级，准确率达95%以上；分类结果通过标准接口联动脱敏、权限、审计等系统，实现“一处打标，多处生效”。“知源-AI数据分类分级系统”特别强调“分类服务临床”的理念，确保数据处理不影响正常诊疗流程。<br/>五、应用落地<br/>提示： “知源-AI数据分类分级系统”已在多家大型医疗机构成功部署，取得显著成效。以某省级医疗集团为例，其下辖多家分院与社区中心，数据系统异构程度高，存在多个未经管控的科研影子库。部署“知源-AI数据分类分级系统”后，通过夜间自动扫描与AI智能分级，在3个月内完成全域数据资产盘点，识别率达99%，10万份电子病历分类仅需3小时，效率提升超过12倍。系统输出统一分类标准，并联动现有安全系统，实现跨机构数据合规共享，支持远程会诊、慢病管理等业务场景，顺利通过监管部门审计。<br/>六、推广价值<br/>提示：“知源-AI数据分类分级系统”的推广将为医疗机构带来合规、效率与业务创新三重价值。在合规层面，系统严格遵循医疗行业法规，强化对基因数据、传染病史等高敏感信息的管控，降低违规风险。在效率层面，AI自动化处理释放人力，提升病历调阅与科研数据复用效率。在业务层面，“知源-AI数据分类分级系统”为智慧门诊、AI辅助诊断、区域医疗协同等场景提供安全数据底座，推动医疗数据从“治理”走向“赋能”，实现患者隐私、临床效率与科研创新的共赢。<br/>七、问答<br/>提示： 以下是关于医疗数据分类分级系统的常见问题解答。<br/>问：“知源-AI数据分类分级系统”是否会影响医院正常诊疗业务？答：采用非侵入式接入方式，支持夜间扫描与接口对接，不直连核心业务库，确保诊疗流程零打扰。<br/>问：能否适应不同医院的信息化水平差异？答：“知源-AI数据分类分级系统”具有高兼容性，支持Oracle、MySQL、MongoDB等常见数据库，同时可接收文件导入，适配从三甲医院到基层社区的不同信息化环境。<br/>问：AI分类的准确性如何保证？答：“知源-AI数据分类分级系统”融合医疗知识图谱与深度学习模型，内置动态校准机制，支持人工复核，分类准确率稳定在95%以上，并对医疗术语差异、非结构化数据具有专项优化。<br/>问：系统如何与现有安全设备联动？答：通过OpenAPI、Kafka等方式输出分级标签，可直接对接动态脱敏、访问控制、审计日志等系统，实现“一处分类，全局管控”。<br/>问：是否支持科研数据等特殊类型的分类管理？答：“知源-AI数据分类分级系统”支持自定义标签与规则，可为基因数据、临床试验记录等科研数据设置专属分类策略，并符合《医学研究伦理审查办法》要求。<br/>八、用户评价<br/>提示： “知源-AI数据分类分级系统”在实际应用中获得了医疗机构的多方认可。某三甲医院信息科主任表示：“系统上线后，我们首次摸清了全院数据资产，分类效率大幅提升，医护调阅病历时间明显缩短。”区域医疗集团管理员反馈：“跨院区数据标准统一，审计成本降低，为我们的智慧医疗平台打下了安全基础。”临床科室专家认为：“分类结果真正贴合诊疗需求，既保护隐私，又支持科研数据合规使用。”<br/>“知源-AI数据分类分级系统”已入选Gartner相关成熟度曲线报告，并被《中国网络安全细分领域产品名录》推荐。“知源-AI数据分类分级系统”将继续深化医疗行业理解，推动分类分级技术与临床、科研、管理场景的深度融合，助力医疗机构构建“安全可控、价值驱动”的数据治理体系，在合规基础上释放医疗数据潜能，赋能智慧医疗新时代。</p>]]></description></item><item>    <title><![CDATA[低代码配置、可落地、业务赋能：数据分类分级系统引领政务数据治理新实践 老实的剪刀 ]]></title>    <link>https://segmentfault.com/a/1190000047499271</link>    <guid>https://segmentfault.com/a/1190000047499271</guid>    <pubDate>2025-12-24 10:02:14</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>一、概要<br/>提示：政务数据分类分级不仅是政策要求，更是数字政府建设的基础工程，直接关系到数据安全与服务效能。在数字化转型加速的背景下，政务数据呈现“多源异构、跨域流转”特征，数据孤岛与安全风险并存。为破解“数据不通、安全不保、合规不足”的困局，知源-AI数据分类分级系统，以“低代码配置、可落地、业务赋能”为核心特性，助力政府实现数据资产的精准识别、智能分级与合规复用。知源-AI数据分类分级系统已在全国多地政务部门成功部署，显著提升数据治理效率与安全水平，为“一网通办”“城市大脑”等数字化场景提供坚实数据支撑，推动政务数据从“管理”走向“赋能”。<br/>二、背景/挑战<br/>提示：政策密集出台与数据规模激增，推动政务数据治理进入深水区。随着《数据安全法》《个人信息保护法》《政务数据共享开放条例》等法规相继实施，政务数据安全被纳入政府绩效考核体系，分类分级成为刚性要求。与此同时，政务数据量呈指数级增长，分散存储于各委办局、政务云平台等近百个节点，数据类型复杂、权属模糊，传统人工治理模式已难以应对。如何在保障安全的前提下实现数据高效共享与业务赋能，成为各级政府面临的共同挑战。<br/>三、行业痛点分析<br/>提示：政务数据治理面临“资产不清、分级不准、共享不畅、管控乏力”四大核心痛点。具体表现为：</p><ol><li>数据资产不清：政务系统“新旧并存”，存在大量“僵尸数据”“影子数据库”，缺乏统一资产清单，数据分布不明、数量不清。</li><li>分级标准不一：各部门业务差异大，分类分级标准难以统一，人工打标效率低、误差高，无法满足动态管控需求。</li><li>共享流通受阻：数据孤岛现象突出，跨部门共享流程繁琐，缺乏自动化合规校验机制，导致“数据不动、群众跑腿”。</li><li>安全管控薄弱：敏感数据识别率低，防护措施滞后，难以实现分级防护与动态脱敏，合规审计成本高、风险大。<br/>四、<a href="https://link.segmentfault.com/?enc=IxeEVfV97aZpg4rtPVcHmg%3D%3D.su8nkDHlj%2FvM%2FNXvVnE8eAKgFdXUFbTJFUGqlboLBow%3D" rel="nofollow" target="_blank">解决方案</a><br/>提示：知源-AI数据分类分级系统以“低代码配置、可落地、业务赋能”为设计理念，构建覆盖“发现-分级-应用-治理”的全链路方案。系统通过以下四大模块实现政务数据分类分级的闭环管理：</li><li>低代码资产接入与识别支持非侵入式部署，提供数据库扫描、接口对接、文件导入三种方式，无需改造现有系统即可快速接入各类数据源，自动生成动态资产清单，数据识别率高达99%。</li><li>AI驱动智能分级与规则沉淀内置政务分类分级模板，支持低代码自定义标签与规则。融合深度学习、知识图谱与多模态AI，实现结构化与非结构化数据的自动分级，准确率达95%以上，并可沉淀部门经验，持续优化模型。</li><li>分级结果合规应用与联动通过OpenAPI、Kafka等方式，将分级结果对接政务数据共享平台、动态脱敏系统，实现“一处打标，全域合规复用”，支撑“一网通办”等场景的安全数据流转。</li><li>全景可视与权限管控提供数据资产全景视图，支持多维度查询与权限精细化管理，结合国密算法加密存储，实现数据全生命周期的安全可控与透明可溯。<br/>五、应用落地<br/>提示：某市人社局通过部署知源-AI数据分类分级系统，实现数据分类分级从“人工为主”向“智能驱动”的跨越。该部门原有人工分类效率低、覆盖不全，且未落实最新行业规范。接入知源系统后，通过旁路部署快速完成全域数据扫描，自动识别敏感字段并分类分级，3个月内实现20万张数据表的智能处理，效率提升约10倍，分类准确率达98%。系统输出完整资产报告与分级清单，并同步至数据安全平台，助力该局建立标准化、可持续的数据治理体系，全面满足合规要求。<br/>六、推广价值<br/>提示：知源-AI数据分类分级系统不仅满足合规要求，更为政务数据价值释放与业务创新提供支撑。<br/>● 合规提效：精准匹配法规要求，降低审计成本50%以上，助力政府通过数据安全考核。<br/>● 业务赋能：打破数据孤岛，为“一网通办”“城市大脑”提供高质量数据底座，推动政务服务从“人跑”向“数跑”转型。<br/>● 治理升级：实现数据资产动态管理、分级防护自动化，提升政务数据治理的响应速度与精细化水平。<br/>● 长效发展：构建“安全可控、高效共享”的数据生态，为数字政府可持续发展奠定基础。<br/>七、问答环节<br/>Q1：知源-AI数据分类分级系统是否需要对现有政务系统进行改造？A：无需改造。系统支持非侵入式旁路部署，通过扫描、接口等方式接入数据，不影响业务系统正常运行。<br/>Q2：如何保证分类分级的准确率？A：知源-AI数据分类分级系统采用“AI自动识别+人工复核”机制，内置政务规则库与多模态AI模型，准确率稳定在95%以上，并支持持续学习优化。<br/>Q3：是否支持跨部门数据共享场景？A：支持。知源-AI数据分类分级系统输出分级标签后，可通过标准接口对接政务数据共享平台，实现分级管控与动态脱敏，保障跨域流转安全合规。<br/>Q4：低代码配置是否意味着功能受限？A：恰恰相反。低代码配置降低使用门槛，同时支持深度自定义标签、规则与流程，灵活适配公安、医保、民政等不同业务需求。<br/>Q5：知源-AI数据分类分级系统能否适应未来政策与业务变化？A：支持规则模板与AI模型的持续更新，并可对接外部数据目录，具备良好的扩展性与适应性。<br/>八、用户评价<br/>提示：来自政务一线用户的反馈，印证系统在实际场景中的价值。“知源-AI数据分类分级系统帮助我们局在三个月内完成了原本需要一年以上的数据分类分级工作，效率提升显著，且分级结果精准，为我们后续的数据共享与安全防护提供了清晰依据。”——某市人社局数据治理负责人“知源-AI数据分类分级系统操作简便，低代码配置让我们业务人员也能快速上手，真正实现了‘技术为业务服务’。”——某区政务服务管理局信息化科长“通过知源-AI数据分类分级系统的全景视图与合规联动，我们终于做到了数据资产‘看得清、管得住、用得好’。”——某省级政务数据运营中心技术总监<br/>知源-AI数据分类分级系统已入选《政务数据安全治理优秀解决方案》《中国网络安全细分领域产品名录》，并在全国多地政务项目中成功落地。知源-AI数据分类分级系统将持续深化政务场景理解，推动AI技术与数据治理的融合创新，助力构建“安全可控、高效智能”的政务数据体系，为数字中国建设贡献技术力量。</li></ol>]]></description></item><item>    <title><![CDATA[通义开源端到端语音模型 Fun-Audio-Chat 8B；OpenTable 与 Yelp 竞速餐]]></title>    <link>https://segmentfault.com/a/1190000047499282</link>    <guid>https://segmentfault.com/a/1190000047499282</guid>    <pubDate>2025-12-24 10:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047499284" alt="" title=""/></p><p>开发者朋友们大家好：</p><p>这里是 <strong>「RTE 开发者日报」</strong>，每天和大家一起看新闻、聊八卦。我们的社区编辑团队会整理分享 RTE（Real-Time Engagement） 领域内「有话题的<strong>技术</strong>」、「有亮点的<strong>产品</strong>」、「有思考的<strong>文章</strong>」、「有态度的<strong>观点</strong>」、「有看点的<strong>活动</strong>」，但内容仅代表编辑的个人观点，欢迎大家留言、跟帖、讨论。</p><p><em>本期编辑：@瓒an、@鲍勃</em></p><h2>01有话题的技术</h2><p><strong>1、通义发布了新一代端到端语音交互模型 Fun-Audio-Chat</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047499285" alt="" title="" loading="lazy"/></p><p>刚刚，通义开源了 Fun-Audio-Chat 8B，在 OpenAudioBench、MMAU、Speech-ACEBench、VStyle 等多个权威榜单上，同尺寸模型排名第一，综合性能远超 GLM4-Voice、Kimi-Audio、Baichuan-Omni......</p><p>Fun-Audio-Chat 是为自然、低延迟语音交互构建的大型音频语言模型。它引入了双分辨率语音表示（一个高效的 5Hz 共享主干 + 一个 25Hz 的精炼头）以在降低计算的同时保持高语音质量，并采用 Core-Cocktail 训练以保留强大的文本 LLM 能力。它在语音问答、音频理解、语音函数调用以及语音指令遵循和情感共鸣基准上都取得了顶级成果。</p><p>技术表现：</p><ul><li>端到端 S2S 架构：从语音输入直接生成语音输出，无需 ASR + LLM + TTS 多模块拼接，效率更高、延迟更低。</li><li>双分辨率设计：Shared LLM 层以 5Hz 帧率 高效处理，SRH 以 25Hz 帧率 生成高质量语音，GPU 计算开销降低近 50%。</li><li>百万小时多任务数据训练：覆盖音频理解、语音问答、情感识别、工具调用等真实场景，让模型更「接地气」。</li></ul><p>高情商：像朋友一样的对话体验</p><ul><li>你生气时，它会安慰你；你焦虑时，它会陪你深呼吸；你开心时，它会跟着你一起嗨。</li><li>哪怕你没直接说情绪，它也能从你的语气、语速、停顿里，猜出你的心情，然后给出恰到好处的回应。</li></ul><p>易落地：它不仅能聊，还能「干实事」</p><ul><li>Speech Function Call：你只需用自然语音下达指令，它就能自动调用函数，完成复杂任务。</li></ul><p>通义已将 8B 模型权重、推理代码、Function Call 接入示例全部开源。</p><p>GitHub:  <br/><a href="https://link.segmentfault.com/?enc=%2BAs0%2BdtvX0U5JgwowJvNeQ%3D%3D.9TZnUHX0AJI0Uov%2FPBjbi7Esse7KYdF40%2BrHZyeci1eEzniob86KiiNvd2WGR6Kv" rel="nofollow" target="_blank">https://github.com/FunAudioLLM/Fun-Audio-Chat</a> </p><p>HuggingFace:  <br/>https: //huggingface.co/FunAudioLLM/Fun-Audio-Chat-8B </p><p>ModelScope:  <br/> <a href="https://link.segmentfault.com/?enc=iw%2B0Ux52R1utoKurAeTxPQ%3D%3D.I8BM2ExvALFcmWvJCrhPt0q3vy4z723%2FliKnes2gtgzV613Ns%2B%2BNX1MJJrlJOXn3nEAlNM5RUaZjuF211D6%2FEg%3D%3D" rel="nofollow" target="_blank">https://modelscope.cn/FunAudioLLM/Fun-Audio-Chat-8B</a> </p><p>Demo Page:  <br/> <a href="https://link.segmentfault.com/?enc=tumeHr8i5nnrJyW6%2Bkiq2Q%3D%3D.opjRtSbOd%2Bm0R2kbgHKBCClxYWv7GpaKQqxA5MyUTqjAPatXGYcvxjv0kQXD%2FP5m" rel="nofollow" target="_blank">https://funaudiollm.github.io/funaudiochat</a></p><p>（@通义大模型）</p><p><strong>2、AI 生成操作系统新突破，上海交大提出文件系统开发新范式：从此只需写规约</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047499286" alt="" title="" loading="lazy"/></p><p>上海交大 IPADS 实验室提出「SysSpec」开发新范式，利用形式化规约（Specification）引导 LLM 自动生成操作系统底层组件。该研究通过将底层代码维护转向高维规约编写，解决了操作系统开发中维护成本高（如 Ext4 维护代码占比超 80%）及 LLM 生成内核代码易崩溃的难题。</p><ul><li><strong>三维结构化规约框架</strong>：引入基于 Hoare Logic 的功能规约（定义 Pre/Post-condition）、模块化规约（管理接口依赖）及并发规约（实现业务逻辑与锁机制分离），消除自然语言生成的模糊性。</li><li><strong>Agent 驱动的自动化工具链</strong>：集成 SpecCompiler（逻辑转代码）、SpecValidator（基于规约的迭代验证，对抗 LLM 幻觉）及 SpecAssistant（辅助规约编写）三个智能体。</li><li><strong>DAG 结构化规约补丁</strong>：通过有向无环图（DAG）管理系统演进，开发者仅需提交规约补丁，由工具链自动计算依赖并重构受影响模块，避免手动修改底层代码。</li><li><strong>SpecFS 实测表现</strong>：基于 SysSpec 生成的 4300 行 C 代码文件系统可直接运行于 Linux 6.1.10 内核。在引入「延迟分配」特性后，xv6 编译任务的写操作减少 99.9%，整体开发效率较传统手动编写提升 3-5 倍。</li></ul><p>该研究成果即将发表于文件系统顶级会议 USENIX FAST’26，相关论文已在 arXiv 公开。</p><p>arXiv 链接：</p><p><a href="https://link.segmentfault.com/?enc=jLOKIAgi97Xo43MxqS2hoA%3D%3D.2DF7UYjTKZROs0vzfKV0ZoLOcbG1V%2FUEITtGCpQ6Ch6jXq3BlF4U%2BX4UZjOvv3Nm" rel="nofollow" target="_blank">https://arxiv.org/abs/2512.13047</a></p><p>（@量子位）</p><p><strong>3、智谱 AI 开源 GLM-4.7：人人编程的时代到来</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047499287" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047499288" alt="" title="" loading="lazy"/></p><p>GLM-4.7 上线并开源。新版本面向<strong> Coding 场景</strong>强化了编码能力、长程任务规划与工具协同，并在多项主流公开基准测试中取得开源模型中的领先表现。</p><p>目前，GLM-4.7 已通过<strong> BigModel.cn </strong>提供 API，并在 <strong> z.ai 全栈开发模式</strong> 中上线全新 <strong>Skills 模块</strong> ，支持多模态任务的统一规划与协作执行。</p><p>Coding 能力再提升：</p><ul><li><strong>更强的编程能力</strong>：显著提升了模型在多语言编码和在终端智能体中的效果；GLM-4.7 现在可以在 Claude Code、TRAE、Kilo Code、Cline 和 Roo Code 等编程框架中实现「先思考、再行动」的机制，在复杂任务上有更稳定的表现。</li><li><strong>前端审美提升</strong>：GLM-4.7 在前端生成质量方面明显进步，能够生成观感更佳的网页、PPT 、海报。</li><li><strong>更强的工具调用能力</strong>：GLM-4.7 提升了工具调用能力，在 BrowseComp 网页任务评测中获得 67.5 分；在τ²-Bench 交互式工具调用评测中实现 87.4 分的开源 SOTA，超过 Claude Sonnet 4.5。</li><li><strong>推理能力提升</strong>：显著提升了数学和推理能力，在 HLE（「人类最后的考试」）基准测试中获得 42.8%的成绩，较 GLM-4.6 提升 41%，超过 GPT-5.1。</li><li><strong>通用能力增强</strong>：GLM-4.7 对话更简洁智能且富有人情味，写作与角色扮演更具文采与沉浸感。</li></ul><p>模型已在 GitHub、Hugging Face、魔搭社区全面开源；API 已通过 BigModel.cn 提供；智谱清言及 z.ai 全栈开发模式已同步上线全新技能模块。</p><p>Github: <br/><a href="https://link.segmentfault.com/?enc=vbwi4iyr8zZox3DK%2Frwvkw%3D%3D.8o0orBIXBlalOS%2FH9atB470bGMmpLPjkEXmd7GwkdivcYAsyB2uJoXw71EGnVx07" rel="nofollow" target="_blank">https://github.com/zai-org/GLM-4.5</a></p><p>Huggingface: <br/><a href="https://link.segmentfault.com/?enc=j5PlO3GcGHD85Z5MlYaBIw%3D%3D.bNm2V5pN%2FIJ6g%2BsAV%2FerPXirleGiqJPC29yeclQi0ymQfdiMqZ6EufuMFOWhnX4H" rel="nofollow" target="_blank">https://huggingface.co/zai-org/GLM-4.7</a></p><p>魔搭社区：<br/><a href="https://link.segmentfault.com/?enc=MPOQTYIRPzjN1esBQ2N%2BFg%3D%3D.PEu672lcpRGcYHKSHlr0JKl%2Fovy2vTnHzbozli5ymVhmduVSjg%2F01MFEEO7g4bqv" rel="nofollow" target="_blank">https://modelscope.cn/models/ZhipuAI/GLM-4.7</a></p><p>blog: <br/><a href="https://link.segmentfault.com/?enc=6w69u3j%2F6kEd2eqboTYvMw%3D%3D.6XQr2MmxEOk0HbfsIXTZ%2BSDrN84Q5%2FaJnRHE1WWkCAY%3D" rel="nofollow" target="_blank">https://z.ai/blog/glm-4.7</a></p><p>（@GLM 大模型）</p><h2>02有亮点的产品</h2><p>1、<strong>OpenTable 与 Yelp 竞速餐饮语音 AI：集成「智能体」实现 24/7 全自动订座与多端交互</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047499289" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047499290" alt="" title="" loading="lazy"/></p><p>以「OpenTable」和「Yelp」为代表的餐饮 SaaS 巨头正加速通过 API 集成和原生开发，将语音「智能体」引入餐厅订座流程。该技术旨在通过自然语言处理（NLP）替代高成本的人工接听，实现全天候预约管理及排队自动化，并打通车载语音等外部流量触点。</p><ul><li><strong>OpenTable 深度集成第三方语音「智能体」</strong>：通过与 Maple、Loman AI 和 SoundHound AI 合作，实现语音交互与后台库存的实时双向同步。其中，Loman AI 支持通过自然语言完成预订、修改、确认和取消的闭环操作，无需人工二次录入。</li><li><strong>Yelp 发布原生 AI 电话智能体「Yelp Host」</strong>：作为 2025 秋季发布的核心产品，该工具可自动回答常见问题、更新等待时间，并能通过短信向用户发送菜单链接或派送单入口。其定价模式为独立订阅 149 美元/月，Guest Manager 用户优惠至 99 美元/月。</li><li><strong>预订入口延伸至车载系统（Mobility）</strong>：SoundHound AI 将「OpenTable」的实时库存数据打通至车载语音助手，用户在驾驶过程中即可通过对话完成餐厅搜索与预订，将预订漏斗从移动端扩展至出行场景。</li><li><strong>从接听工具转向数据驱动中心</strong>：语音「智能体」捕获的对话数据（如派对规模偏好、高峰时段意图信号）正被整合进餐饮管理系统（RMS），用于辅助人员配置决策和精准营销投放，而非仅仅是自动应答。</li></ul><p>Yelp 系列工具现已向合规企业开放初期申请；OpenTable 第三方集成方案视各 AI 供应商（Maple， Loman AI 等）的具体定价而定。</p><p>( @Restaurant Technology News)</p><p><strong>2、1999 元起，夸克 AI 眼镜再上新</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047499291" alt="" title="" loading="lazy"/></p><p>昨天，夸克 AI 眼镜正式开启两款新品预售，其中 G1 风尚眉框款最低到手价仅 1999 元，成为千问首款平价 AI 眼镜；热销的旗舰款 S1 系列新增圆框玳瑁配色，为消费者提供更多选择。</p><p>新品 G1 在定价亲民的前提下在核心硬件配置上与旗舰 S1 系列保持一致，用户可在更低价格下获得语音问答、实时翻译、信息查询、智能拍摄等完整 AI 交互体验：</p><p>搭载双旗舰芯片双系统；配备五麦克风阵列加骨传导、大振膜高性能喇叭等声学硬件；支持 0.6 秒极速抓拍、3K 视频录制；整机重量约 40g，采用天鹅颈可调节支架与 FDA 食品级硅胶鼻托；内置千问 AI 助手，支持跨场景调用阿里生态服务。</p><p>S1 系列新品延续旗舰定位，新增圆框玳瑁款在显示、佩戴与影像方面保持领先优势，外观更具复古与时尚属性。</p><p>目前，两款新品已在天猫、抖音、京东等线上渠道开启预售，全国 82 个城市的 604 家线下门店也将陆续提供配镜、体验与购买服务。</p><p>阿里巴巴集团副总裁吴嘉此前表示，AI 眼镜是人机交互的感官中枢，在眼镜上搭载千问 AI 助手，能够更好理解用户需求，并在更大范围内提供价值。</p><p>( @APPSO)</p><h2>03有态度的观点</h2><p><strong>1、不是只有芯片：250 亿美元信用投资人谈 AI 真正的长期机会</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047499292" alt="" title="" loading="lazy"/></p><p>据《商业内幕》报道，管理约 250 亿美元资产的信用投资机构 Diameter Capital 联合创始人兼管理合伙人 Scott Goodwin 表示，人工智能热潮的真正机会不止于芯片与数据中心。</p><p><strong>Goodwin 指出，AI 的长期周期将通过更广泛的基础设施与采用竞争释放价值。</strong></p><p>他在《Goldman Sachs Exchanges》播客上称，团队关注 AI 需求推动的、在信用市场上不那么显眼的瓶颈与定价错配，这一「超微周期」将持续并重塑投资版图。</p><p>Goodwin 透露，Diameter Capital 在 2023 年买入一家中型电信公司的无担保债务，逻辑是当企业从训练模型转向实际应用，需求将从「只看芯片」转向承载数据的网络与商用光纤。</p><p>「数据必须离开数据中心，如何离开？靠商用光纤这条管道。」</p><p>在风险层面，Goodwin 警示 AI 相关信用交易，尤其是芯片融资，正在累积难以定价的「剩余价值风险」—— 部分投资者押注数年后硬件的残余价值，但前沿技术更新频繁、芯片对部分客户而言很快过时。</p><p>他指出，下一阶段不只是基础设施资本开支，而是围绕 AI 采用带来的竞争位势变化：「谁能借助 AI 领先同行，谁会成为输家？」这一竞争周期将长于纯粹的 Capex 周期。</p><p>Goodwin 的观点也回应了市场对 AI 高估值可持续性的争论：与其只押注最显眼的赢家，信用层面更值得留意的是网络传输、频谱与卫星等「被忽视的瓶颈」，以及企业落地采用的速度与广度对现金流与资本结构的影响路径。</p><p>这意味着 AI 交易的核心从「造设备、建机房」转向「哪类公司以何种节奏把 AI 用出生产力优势」，并据此重估风险与回报。</p><p>( @APPSO)</p><h2>04社区黑板报</h2><p>招聘、项目分享、求助……任何你想和社区分享的信息，请联系我们投稿。（加微信 creators2022，备注「社区黑板报」）</p><p><strong>1、声网招聘开发者体验产品经理（DevX PM）</strong></p><p>在声网，我们相信：真正伟大的技术，不应该让开发者感到负担，而应该让他们感到被理解。</p><p>从最初的四行代码到 RTE API，再到今天的 Converstaional AI，声网长期服务全球开发者 Builder，为百万级用户提供人与人，人与 AI 的实时时交互能力。我们是一家由开发者创立服务于开发者的公司，开发者体验（Developer Experience）一直是我们最重视的平台底层能力，且随着 AI Agent、多模态交互与 Realtime AI 的兴起，它更成为平台最核心的产品能力。</p><p>我们正在寻找一位以「开发者体验为使命」的产品经理（DevX PM），更重要的是，他不仅是一名产品经理，更是「开发者」的代言人，是系统抽象的设计者、更是开发者成功路径的定义者。</p><p>我们希望他，降低开发者使用声网平台的认知成本与集成成本，让开发者能够更快理解、更容易上手、更有信心地在生产环境中构建实时 AI  Agent 与 RTE 应用。</p><p>这个角色将与研发、开发者社区、开源等团队深度协作，面向全球开发者，持续改进 API、SDK、工具链和文档体系，制造出更多 Builder 欣喜若狂的「Aha monents」，并对开发者的整体成功路径负责。</p><p><strong>岗位职责：</strong></p><p>1、负责声网平台的开发者全生命周期体验设计与持续优化，包括 First Hello world， First Agent，First Minute 到 First Success，从首次接触、快速上手到生产环境使用的完整开发者旅程；</p><p>2、主导 API 与 SDK 的开发者体验相关产品设计，涵盖 SDK 结构、接口抽象、默认方案、示例代码及集成流程；</p><p>3、与研发团队紧密合作，推动更符合 AI Native Builder 心智模型的产品抽象，降低对 Conversational AI 以及底层 RTC 概念的理解门槛；</p><p>4、规划并优化开发者相关工具体系，包括 CLI、调试工具、日志与基础可观测能力，提升问题定位与迭代效率；</p><p>5、负责开发者文档如 Tutotial 结构设计和创新，确保文档「任务与使用场景」为导向，真正帮助开发者上手，而非仅描述系统能力；</p><p>6、对内与研发团队深度共创，能从开发者社区和群体中抽象反馈（基于社区、客户、调研、使用数据），识别关键点，并转化为可执行的产品改进，将开发者的困惑、挫败与反馈，转化为清晰的产品优化方向；</p><p>7、对外理解 Build in Public 的创新趋势，与社区和外部开发者融合，在 Builder 活跃的 X 等平台、以及线下 meetup 等进行技术布道、最佳实践沉淀与产品口碑建设。</p><p><strong>岗位要求：</strong></p><p>1、有足够学历和能力支持跨国和跨语言团队工作，服务过 global 的产品， 能够支持全球开发者生态；</p><p>2、具有扎实的技术理解能力，能够与工程师讨论 API 设计、SDK 结构、系统抽象及技术取舍，能清晰理解如何让「强大但复杂」的系统，变得「强大且直观」；</p><p>3、有面向开发者的产品经验，包括但不限于 API、SDK、开发者工具、平台型产品或开源项目；</p><p>4、对开发者的工作流、心智模型和「爽点 / 痛点」有高度敏感度，能够识别开发者在「第一次使用」和「出问题时」的真实痛点，需要具备 AI builder 的高水准审美判断；</p><p>5、具备一定的代码能力，能够阅读和理解示例代码；或能熟练使用「vibe coding」方式进行原型验证、问题复现与体验评估；</p><p>6、具备良好的跨团队协作能力，能够推动产品、研发、DevRel、社区之间的协同；</p><p>7、有 AI、实时系统、语音、多模态或事件驱动系统相关经验者优先；</p><p>8、有 SDK、CLI、开发者工具设计或开源社区参与经验者优先。</p><p>我们希望你——</p><ul><li>产品抽象，设计的 developer journey 是否清晰直观</li><li>会纠结：「一个聪明的开发者，第一次用这个产品会不会犯错？」;</li><li>享受解决模糊问题，并将复杂系统简化成可理解的模型；</li><li>希望打造真正被开发者喜爱、愿意给其他 builder 推荐的技术产品。</li></ul><p>如果你渴望打造让开发者真正「Wow」的产品，欢迎加入我们。也欢迎：与时俱进的猎头们，流连在各类社区的 AI native （waytoagi 社区，扣子社区，dify 社区，RTE 开发者社区，vibe hacks 和 vibe coding 的 meetup，X 和小红书上的常客），欢迎来联系我呀，也许我们可以和技术前瞻的 CEO，一起喝杯咖啡。</p><p>&lt;简历请投递：<a href="mailto:lindawang@shengwang.cn" target="_blank">lindawang@shengwang.cn</a>&gt;</p><p><strong>2、硬件日招募！「对话式 AI+硬件」系列活动@深圳丨 RTE Meetup+TEN Workshop</strong></p><p>2025 年 RTE 开发者社区的收官活动，将再次落地硬件之都深圳，一起畅想 2026！</p><p>聚焦「对话式 AI+硬件」主题， 来自通义百聆 Fun-CosyVoice、声网、Lookee 盒智科技、TEN Framework、TEN VAD、Amphion 的技术专家和创业者将呈现多种类型活动。</p><p>上午主题分享+圆桌，下午动手工作坊——无论你是产品人、开发者、创业者还是硬件极客，总有一款适合你！</p><p>12 月 27 日，深圳科创学院，欢迎参加～</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047499293" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047499294" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047499295" alt="" title="" loading="lazy"/></p><p><a href="https://link.segmentfault.com/?enc=6zd8yJSFXWk97%2FoHKt%2FfCQ%3D%3D.7yKNRR3uG3pTBt5V74CpNhVUiW4n6%2FSQj6BkIkrg%2B%2Bo%3D" rel="nofollow" target="_blank">阅读更多 Voice Agent 学习笔记：了解最懂 AI 语音的头脑都在思考什么</a></p><p><strong>写在最后：</strong></p><p>我们欢迎更多的小伙伴参与<strong>「RTE 开发者日报」</strong>内容的共创，感兴趣的朋友请通过开发者社区或公众号留言联系，记得报暗号「共创」。</p><p>对于任何反馈（包括但不限于内容上、形式上）我们不胜感激、并有小惊喜回馈，例如你希望从日报中看到哪些内容；自己推荐的信源、项目、话题、活动等；或者列举几个你喜欢看、平时常看的内容渠道；内容排版或呈现形式上有哪些可以改进的地方等。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047499296" alt="" title="" loading="lazy"/></p><p>作者提示：个人观点，仅供参考</p>]]></description></item><item>    <title><![CDATA[ITSS实施规划实战：没有路线图，标准只是幻觉 ITIL先锋论坛 ]]></title>    <link>https://segmentfault.com/a/1190000047499113</link>    <guid>https://segmentfault.com/a/1190000047499113</guid>    <pubDate>2025-12-24 09:02:40</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>那家企业的ITSS项目，我是第二次进场时才接手的。<br/> 第一次，他们请了一家咨询公司，团队来了20多个人，做了半年。<br/> 最终成果是一堆精美的PPT和厚厚的制度手册。<br/> 当我问现场运维主管：“流程跑起来了吗？”<br/> 他摇头：“没人知道该从哪一步开始。”<br/>我翻了他们的项目文件，发现每一份都写着“依据ITSS标准第×部分”，<br/> 但没有一页写着“我们现在在哪，我们要去哪”。<br/> 这就是典型的——盲目套标准，无实施路线图。</p><p><img width="364" height="231" referrerpolicy="no-referrer" src="/img/bVdnsQS" alt="" title=""/></p><p><strong>一、问题：标准照搬，方向全偏</strong><br/>ITSS是体系，不是模具。<br/> 但很多企业误以为，只要“照搬标准”，就能通过评估。<br/> 结果反而陷入更深的混乱：</p><ul><li>制度成册，但没人执行；</li><li>工具上线，但没人用；</li><li>数据报表堆积，但无人解读。<br/>更致命的是，他们跳过了规划阶段，<br/> 直接从“评估问题”跳到“建设标准”，<br/> 就像没看地图就出发，结果越走越偏。<br/>我在那家企业第一次调研时，发现他们的IT服务流程多达18个版本，<br/> 变更流程有3套、事件管理有4套，甚至连SLA指标口径都不一致。<br/> 项目团队天天加班写制度，但现场人员只在用老方法处理工单。<br/> 那一刻，我意识到：标准不是问题，缺乏路线才是问题。</li></ul><p><strong>二、认知：ITSS不是模板，而是路径</strong><br/>ITSS实施规划的第一步，就是“定位”。<br/> 这不是口号，而是要回答三个根本问题：</p><ol><li>我们现在的成熟度在哪？</li><li>我们希望达到什么等级？</li><li>我们能用多长时间、多少资源实现？<br/>ITSS的每个过程域（如事件、问题、变更、配置）都有成熟度等级，<br/> 而“规划”的意义就在于：选对阶段目标，合理配置投入。<br/>我经常在课上举一个比喻——<br/>“ITSS实施就像登山，标准是地图，规划是登山路线。”<br/> 没有路线图，就算拿着GPS，也只会在原地打转。<br/>作为艾拓先锋的官方ITSS授权讲师，在讲授ITSS服务项目经理认证培训课程时我会特别强调这一点：<br/> 很多组织并不是缺乏技术能力，而是缺乏“分阶段目标管理”的能力。<br/> 他们想一步登天，却忘了——成熟，是爬上去的，不是跳上去的。</li></ol><p><strong>三、规划：让体系建设可控、可量化</strong><br/>接手项目后，我花了三周时间和客户共同制定实施路线图。<br/> 这份图纸，不只是计划表，而是一张“治理蓝图”：</p><ol><li>明确阶段目标<br/> 我们将整个建设周期划分为三期：</li><li>一期（0-3个月）：修复基础流程，建立工单体系与服务目录。</li><li>二期（4-8个月）：推进流程集成，实现变更与配置联动。</li><li>三期（9-12个月）：导入持续改进机制，建立KPI与审计体系。<br/>每个阶段都有可量化指标，如“事件闭环率”“SLA达成率”“变更成功率”等。</li><li>制定优先级矩阵<br/> 我们用“影响度×成熟度”模型打分，确定改进优先级。<br/> 高影响、低成熟的流程（如事件管理）优先改；<br/> 低影响、高成熟的流程（如服务报告）延后。<br/> 这让资源配置更科学，也避免项目疲劳。</li><li>建立跨部门协作机制<br/> 每个阶段设立“流程负责人”，由业务、开发、运维三方组成工作组。<br/> 项目管理办公室（PMO）负责节奏管控与风险跟踪。<br/> 这样，ITSS不再是“运维的事”，而是组织的系统工程。</li><li>嵌入风险控制<br/> 路线图不是静态文件，而是动态可调模型。<br/> 我们设计了风险清单：人员变动、工具延迟、需求漂移等，每项都有应对措施。<br/> 例如：当关键节点延期超过两周，系统自动触发调整计划并通知CAB。<br/>规划的最大价值不是预测未来，而是让未来可控。</li></ol><p><strong>四、落地：路线图，让体系真正跑起来</strong><br/>有了路线图，项目的节奏第一次被所有人看清。<br/> 会议不再是争论，而是对照目标校准。<br/> 每个阶段结束后，我们都会举行“成熟度里程碑评审”，<br/> 确认阶段目标是否达成、哪些风险需要滚动修正。<br/>半年后，企业的服务体系初具雏形：</p><ul><li>工单闭环率提升35%；</li><li>变更成功率达96%；</li><li>事件平均响应时间下降42%；</li><li>员工满意度上升20%。<br/>更难得的是，团队终于找回了信心。<br/> 以前他们忙得看不见方向；<br/> 现在每一项工作都能在路线图上找到坐标。<br/>我常在汇报会上提醒管理层：<br/>“路线图不是画给别人看的，而是让我们知道自己该停、该走、该快。”<br/>没有路线图，标准只是幻觉。<br/> ITSS的价值，不在评估证书，而在让组织看见自己走过的每一步。</li></ul>]]></description></item><item>    <title><![CDATA[LLM 扩展方式的三年演进之路：复杂之后，回归简单 Baihai_IDP ]]></title>    <link>https://segmentfault.com/a/1190000047499117</link>    <guid>https://segmentfault.com/a/1190000047499117</guid>    <pubDate>2025-12-24 09:02:05</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <blockquote><p><strong>编者按：</strong> 在当前 LLM 能力日益增强、扩展方式不断演进的背景下，我们是否正在走向一种“越复杂越强大”的技术路径？抑或，真正的突破恰恰源于回归简单与通用？</p><p>今天我们为大家带来的文章指出，尽管过去三年间出现了从插件、上下文协议、记忆功能等多种扩展机制，但最终的趋势很可能是：赋予智能体通用的计算能力，并相信它能自主完成复杂任务，而非依赖过度设计的专用工具。</p><p>文章系统梳理了过去三年 LLM 扩展方式的演进脉络 —— 从 ChatGPT 插件的超前尝试，到自定义指令的简化回潮。从 MCP 协议的重量级架构，到 Agent Skills 以 Markdown 和脚本实现的轻量级“重生”。作者指出，早期因模型能力不足而失败的“通用工具+自然语言指令”愿景，如今正因模型真正变“聪明”而成为可能。</p></blockquote><p><strong>作者 | Sawyer Hood</strong></p><p><strong>编译 | 岳扬</strong></p><p>三年前，“使用大语言模型”还意味着把一大段文字粘贴到聊天框里，然后期待能收到些有用的东西。如今，我们让智能体对接代码库、操控浏览器，允许它们自主运行并代表我们执行具体任务。在此期间，有一个关键的问题一直在酝酿：我们如何能让终端用户真正地按照自己的意愿、为满足自己的具体需求，来调整和塑造这些 AI 系统的工作方式？</p><p>随着模型能力的增强，终端用户可用的定制方式和机制也在不断扩展。我们从简单的系统提示词起步，演进到复杂的客户端-服务器协议，而后又再次回归简化的模式。</p><p><strong>我想借此机会回顾一下过去三年大语言模型扩展方式的演变，并谈谈我对未来趋势的看法。</strong></p><h2><strong>01 ChatGPT 插件（2023 年 3 月）[1]</strong></h2><p>在 ChatGPT 发布仅四个月后，OpenAI 就推出了 ChatGPT 插件。如今回过头看，这项设计在当时可谓极度超前。</p><p>这一构想雄心勃勃：给大语言模型一个符合 OpenAPI 规范的链接，让它“自由发挥”，调用各类 REST 接口。这直接体现了 AGI 式的思维模式：通过标准化 API 实现通用工具的调用。</p><pre><code>{
"schema_version":"v1",
"name_for_human":"TODO Manager",
"name_for_model":"todo_manager",
"description_for_human":"Manages your TODOs!",
"description_for_model":"An app for managing a user's TODOs",
"api":{"url":"/openapi.json"},
"auth":{"type":"none"},
"logo_url":"https://example.com/logo.png",
"legal_info_url":"http://example.com",
"contact_email":"hello@example.com"
}</code></pre><p>那么问题出在哪里呢？当时的模型尚未准备就绪。GPT-3.5（甚至早期的 GPT-4）在处理庞大的 API 规范文档时存在困难，很容易“产生幻觉”（译者注：即编造不存在的信息或调用不存在的接口）或在上下文信息中“迷失方向”（译者注：即无法准确理解或跟踪当前任务所需的上下文，导致错误操作或理解偏差）。此外，用起来也很麻烦，每开始一个新的对话，即使想使用和上一次相同的插件，也必须重新手动在列表中找到并点击启用它。</p><p>尽管当时存在种种不足，但 ChatGPT 插件仍让我们窥见了未来：其中的 Code Interpreter 插件（后更名为 Advanced Data Analysis）变得不可或缺，它预示了我们今天正在使用的强大代码执行沙箱。</p><h2><strong>02 自定义指令（2023 年 7 月）[2]</strong></h2><p>自定义指令是对插件过于繁杂的一种“化繁为简”的回应。写到这里时我甚至愣了一下，因为我一度认为这项功能是在插件之前推出的。</p><p>它只是在每次对话中自动追加一段用户自定义的提示词（prompt）。简单、直观，却解决了一个大麻烦：重复设置上下文。</p><p>它可被视为后来所有 .cursorrules 和 CLAUDE.md 文件的理念原型。</p><h2><strong>03 Custom GPT（2023 年 11 月）[3]</strong></h2><p>OpenAI 将指令和工具重新打包，推出了“Custom GPT”。这是将提示词工程“产品化”的一次尝试：你可以将一个角色设定、若干文件和几个操作打包成一个可分享的链接。</p><p>相比插件最初所承诺的那种开放、灵活、可自由扩展的能力，Custom GPT 的做法实际上是一种战略上的退让 —— 它转向了经过精心设计、功能单一的“应用”（apps）模式。</p><h2><strong>04 ChatGPT 的记忆功能（2024 年 2 月）[4]</strong></h2><p>之前的扩展方式（如自定义指令、插件、Custom GPT 等）都依赖用户主动提供上下文或相关配置。而“记忆”功能则由系统自动记录并利用用户的历史对话信息，在用户无需干预的情况下动态调整模型行为，实现更自然、持续的个性化体验。</p><p>ChatGPT 记忆会记录你对话中的细节，并在后续对话的上下文中悄悄插入这些信息。这就像一个能自我编写的系统提示词。比如你提到自己是素食者，几周后它依然记得。这个功能虽小，却标志着智能体开始能自主积累和利用上下文信息，像一个有“记忆”的助手一样持续与用户互动，而不是每次对话都从零开始。</p><h2><strong>05 Cursor Rules（2024 年 4 月）[5]</strong></h2><p>以前，用户得在聊天界面里反复输入或设置上下文（比如代码风格、项目规范等），既麻烦又难以复用。而 Cursor 的做法是把这些指令直接写进项目代码仓库，从而彻底改变了这一游戏规则。</p><p>.cursorrules 文件的出现令人耳目一新。它不再需要你把项目上下文手动粘贴到聊天窗口里，而是让你直接将这些规则提交到 Git 仓库中：</p><ul><li>"We use tabs, not spaces."</li><li>"No semicolons."</li><li>"Always use TypeScript."</li></ul><p>它最初只是一个单独的文件，后来演变为一个 .cursor/rules 文件夹，支持更精细的作用域控制。你可以组织多个规则文件，甚至指定它们的适用条件，比如仅对特定文件类型或子目录生效。这是人们第一次觉得对大语言模型的扩展真正“原生地融入”了代码本身。</p><p>后来，Cursor 还引入了让大语言模型自行决定何时应用某条规则的功能 —— 这种模式我们之后还会再次见到。</p><h2><strong>06 模型上下文协议（2024 年 11 月）[6]</strong></h2><p>到了 2024 年底，大语言模型终于变得足够智能，能够稳定、可靠地操作真正的工具了。Anthropic 推出的模型上下文协议（Model Context Protocol, MCP）正是对这一能力需求的正式回应。</p><p>MCP 是一个重量级的解决方案。使用 MCP 时，客户端必须与 MCP 服务器保持一个持久的连接。服务器负责向客户端（通常是智能体）提供工具的定义、资源（如文件、日志等）以及提示词。当客户端决定调用某个工具时，它会向服务器发送一条消息说明“我调用了这个工具”。随后，服务器执行该工具（或协调执行），并将结果返回给客户端。</p><p>与“自定义指令”（仅附加上下文）不同，MCP 赋予模型真正的执行能力 —— 它可以读取你的代码仓库、查询你的 Postgres 数据库，甚至部署到 Vercel。除了提供工具，MCP 还允许服务器直接向智能体提供资源（如文档、日志）和提示词。</p><p>这套机制虽然功能非常强大，但可能有点“用牛刀杀鸡”了。虽然复杂，但对构建智能体的开发者而言，多花点功夫也值得。但若要求普通用户自行搭建并连接 MCP 服务，门槛就太高了。正因如此，围绕降低 MCP 使用难度的初创生态迅速兴起，比如 Smithery[7] 这类公司。</p><p>值得注意的是，2025 年 10 月发布[8]的 ChatGPT Apps 实际上正是以 MCP 作为底层基础构建的。这是 OpenAI 试图让终端用户在无需感知 MCP 存在的前提下，也能享受其能力的一次尝试。</p><h2><strong>07 Claude Code：新智能体，新扩展机制（2025 年 2 月）</strong></h2><p>2025 年初，Anthropic 发布了 Claude Code，几乎将当时所有的 LLM 扩展机制集于一身：</p><ul><li><strong>CLAUDE.md</strong>：为整个项目仓库设置操作规范的标准化方式。</li><li><strong>MCP</strong>：用来对接那些功能强、结构复杂的外部工具。</li><li><strong>斜杠命令（Slash Commands）</strong> ：类似于 Cursor 提供的 Notebooks 功能，用于保存和复用提示词。</li><li><strong>钩子（Hooks）</strong> ：能在智能体运行过程中介入并调整其执行流程（例如：“如果测试失败，就立即停止”）。</li><li><strong>子智能体（Sub-agents）</strong> ：动态创建专门的“子智能体”（或工作单元）来处理特定的子任务。</li><li><strong>输出风格（Output Styles）</strong> ：（已弃用）用于配置回答语气和响应格式。</li></ul><p>这些功能中哪些能长期留存，仍有待时间检验。事实上，Anthropic 已经尝试弃用“输出风格”这一特性[9]。</p><h2><strong>08 Agent Skills（2025 年 10 月）</strong></h2><p>Claude Code 新增的这一扩展机制意义重大，值得深入探讨。Agent Skills 可视为 ChatGPT 插件理念的“重生”。</p><p>MCP 依赖一整套客户端-服务器通信协议，而 Agent Skills 则简单得多 —— 它们只不过是包含 Markdown 文件和脚本（可用任意语言编写）的普通文件夹。</p><p>智能体会简单地扫描 skills/ 目录，读取每个 SKILL.md 文件的 frontmatter（前置元数据），并据此构建一个轻量级索引。只有当某项技能与当前任务相关时，它才会加载该技能的完整内容。这解决了 MCP 的一个主要痛点：所有工具的定义都必须一次性塞进模型的上下文窗口，导致上下文膨胀（context bloat）</p><p>以下是从 Anthropic 的 Skills 示例仓库[10]中摘录的一个用 Playwright 做端到端测试的技能结构片段：</p><pre><code>webapp-testing/
├── examples/
│   ├── console_logging.py
│   ├── element_discovery.py
│   └── static_html_automation.py
├── scripts/
│   └── with_server.py
└── SKILL.md</code></pre><p>Skill 目录中可以包含脚本、示例和纯文本说明等多种内容，形式灵活。但其中唯一必需的文件只有 SKILL.md。接下来，我们来看看这个文件长什么样：</p><pre><code>---
name: webapp-testing
description: Toolkit for interacting with and testing local web applications using Playwright. Supports verifying frontend functionality, debugging UI behavior, capturing browser screenshots, and viewing browser logs.
license: Complete terms in LICENSE.txt
---

# Web Application Testing

To test local web applications, write native Python Playwright scripts.

 **HelperScripts Available**:

- `scripts/with_server.py` - Manages server lifecycle (supports multiple servers)

 **Always run scripts with `--help` first **  to see usage. DO NOT read the source until you try running the script first and find that a customized solution is absolutely necessary. These scripts can be very large and thus pollute your context window. They exist to be called directly as black-box scripts rather than ingested into your context window.</code></pre><p>这只是一个包含一些元数据和技能描述的普通 Markdown 文件。智能体读取该文件，并可以自由引用其中提到的其他文件（智能体也能读取这些文件）。相比之下，一个 Playwright MCP 服务器需要定义几十个工具来控制浏览器，而这个 Skill 只需说一句：“你拥有 bash 环境，这是编写 Playwright 脚本的方法。”  </p><p>诚然，要使用“Skill”，智能体必须具备对计算机的通用访问能力 —— 但这恰恰体现了“苦涩的教训”（the bitter lesson）[11]：与其为每个任务都定制一套专用工具，不如给智能体提供通用工具，并相信它有能力自主运用这些工具来完成任务 —— 这很可能才是制胜之道。</p><h2><strong>09 未来展望</strong></h2><p>Agent Skills 真正实现了 ChatGPT 插件最初所描绘的那个愿景：只需给模型提供一些说明（instructions）和通用工具（generic tools），然后相信它能自己完成中间所需的“胶水”工作。而我有一个假设：<strong>如今这种模式之所以可能奏效，是因为模型真的足够聪明了。</strong></p><p>Agent Skills 之所以有效，是因为它默认智能体具备“自己编写工具”的能力（比如通过 bash 命令等）。你不需要提供一个封装好的专用工具，而只需给它一段代码片段，它就能自行推断如何通用地运行这段代码，来应对当前任务。</p><p>更重要的是，我认为“Agent Skills”正在重新定义“智能体”的本质。<strong>智能体不再仅仅是一个在 while 循环里不断运行的大语言模型（LLM），而是一个绑着一台计算机的、在 while 循环里跑的大语言模型。</strong></p><p>Claude Code 是第一个让我真正意识到这一点的软件，但它过于面向开发者，远非面向大众的终极形态。其他应用（如 Zo Computer[12]）试图将大语言模型与计算机能力打包成一个整体应用，但我认为，它们仍未充分向终端用户隐藏底层计算机的复杂性。毕竟，当我请同事帮忙做一件事时，我不需要知道他电脑里所有的文件结构或操作细节。我只需要知道他有一台能用的电脑，并且相信他能自己搞定就行了。</p><p>展望 2026 年，我相信我们使用的 LLM 应用将越来越多地以新颖而巧妙的方式“绑上一台计算机” —— 而作为用户，我们可能根本察觉不到。</p><p>如果我能“做空” MCP，我一定会“做空”它。<strong>我预计，我们最终会回归到用最易用、最普适的“编程语言”来扩展智能体 —— 那就是自然语言。</strong></p><p><strong>END</strong></p><p><strong>本期互动内容 🍻</strong></p><p><strong>❓作者认为未来的方向是“给模型通用工具，让它自己写胶水代码”，而不是依赖复杂协议。你认同这个“苦涩的教训”吗？为什么？</strong></p><p><strong>文中链接</strong></p><p>[1]<a href="https://link.segmentfault.com/?enc=P%2FDvzcpGouGedJBZ6OjPxg%3D%3D.wVdGZeRkc2rebXPiZavOKt%2FCG1A90EwOyJ01VZz1H8UT5X98mTjYyn1BhqdB5wPP" rel="nofollow" target="_blank">https://openai.com/index/chatgpt-plugins/</a></p><p>[2]<a href="https://link.segmentfault.com/?enc=SnwIbd4a081LLD%2Bmv5xFHw%3D%3D.VwCD8uUYTwSQbKO5qOUxVyh9o4UD6OnEyzm0f5anVo7GUBMPvn6u92aKIjps4BXtNdYCFYALG1YXU%2Fvh5y8gMeIR8NJ7sjNFBtmH842WUodolyyIU2Mdki2UXpslWuXx" rel="nofollow" target="_blank">https://openai.com/index/custom-instructions-for-chatgpt/?utm...</a></p><p>[3]<a href="https://link.segmentfault.com/?enc=sQ7fc0DY37Rys%2F3r8Hkc%2Fw%3D%3D.qs1SxMDEK0TbUvCOvj7NzYaaKq5TLX%2BUwmzqEvxlW8w8CGYlV3DKNUohnl%2BMcLP6" rel="nofollow" target="_blank">https://openai.com/index/introducing-gpts/</a></p><p>[4]<a href="https://link.segmentfault.com/?enc=3qm%2Bfoc9%2BNsxDOZLegdMHA%3D%3D.8ao03nbR9DOyLSPmLD%2FW2TnmXuaePSSS1BbMtad1ETOpmuawh1ntcGYRS6uUVQ66P1nYreilT7PqrfCsICwpAA%3D%3D" rel="nofollow" target="_blank">https://openai.com/index/memory-and-new-controls-for-chatgpt/</a></p><p>[5]<a href="https://link.segmentfault.com/?enc=t9zvQSB%2Bbh8hmrr0BW4zlw%3D%3D.ARy6xohOfWH6mL%2F%2Bh3X52JyaEKbzqNu9glimDjenSUaBU8eL635fsc%2FOqiOG4aJE" rel="nofollow" target="_blank">https://cursor.com/changelog/0-32-x</a></p><p>[6]<a href="https://link.segmentfault.com/?enc=OGeZLPi%2FHFH4aPTg7YNmzg%3D%3D.QCSEmi1gWVppbQmghSDy9WmqnZ5ntgDONclaJpkQH3LXjwxsIXg%2B8imuOatM1i4EpfhdzsuacOLo0IqIhIUN0Q%3D%3D" rel="nofollow" target="_blank">https://en.wikipedia.org/wiki/Model_Context_Protocol</a></p><p>[7]<a href="https://link.segmentfault.com/?enc=QCVVl8gRI%2BvZCv943x5yRg%3D%3D.ht8%2FRnav%2BLqTKwyES3xIWLOD8KHpxPkyp4iJ%2FFJyXxw%3D" rel="nofollow" target="_blank">https://smithery.ai/</a></p><p>[8]<a href="https://link.segmentfault.com/?enc=LflZp82CDfi28e%2FHSD7sRw%3D%3D.6Uzbvfj98G3ClZw8iVzGb8X4TJ%2Be8i5PwTuVnA8oj62FwpjQYFJlH%2F3rmGHqDsaZtTKdWDnTKo2F8HIsMR%2BDew%3D%3D" rel="nofollow" target="_blank">https://openai.com/index/introducing-apps-in-chatgpt/</a></p><p>[9]<a href="https://link.segmentfault.com/?enc=0LpvJ0Fej9QXvvuVDIh5pQ%3D%3D.il53fIg1k08WmufKLKKC%2FfDPEBlymiESiytM%2Bkx4SXNfszKIl%2B9iYGfelctVtZ3BP9%2Bp86ONk2d5D5M3s8RqINSXTk1su7jtHhv12PjbJjk%3D" rel="nofollow" target="_blank">https://github.com/anthropics/claude-code/blob/main/CHANGELOG.md</a></p><p>[10]<a href="https://link.segmentfault.com/?enc=dAoeipXbNQt72atDJaAgHg%3D%3D.BXJzeXS5NUWaQKbrmL3nVIMi56LLNfUlt4%2FWMLCHfPueieZcjxenoj4MULVvox90voZN286qpbpYmW%2BILbdHr8%2FYZb6XKipQb6OJgcVlKYQ%3D" rel="nofollow" target="_blank">https://github.com/anthropics/skills/blob/main/webapp-testing/SKILL.md</a></p><p>[11]<a href="https://link.segmentfault.com/?enc=rMgpPzjhRlIYxsKaKdxo1w%3D%3D.vqv07kUzNS84vEGdX47MC5nIxW6WBmfAS3MTMmZyZkshViTheL8eaThTkdVMXQwa" rel="nofollow" target="_blank">https://en.wikipedia.org/wiki/Bitter_lesson</a></p><p>[12]<a href="https://link.segmentfault.com/?enc=rvmMEyNDqkC%2FXzla2%2FI%2FEg%3D%3D.dQu8hoH7WbMfpRXNkrsujSCRjq2lvOh9L1GWtGNWt60%3D" rel="nofollow" target="_blank">https://www.zo.computer/</a></p><p><strong>本文经原作者授权，由 Baihai IDP 编译。如需转载译文，请联系获取授权。</strong></p><p><strong>原文链接：</strong>  </p><p><a href="https://link.segmentfault.com/?enc=7Mjjg70OR5Y2WNn2n2zEXg%3D%3D.LTZ3saI8vdfckuOz0sEnE9TA5YGIuSOodufkQQZxuEFrKdpkkEiU15NfPeeT%2BNi7" rel="nofollow" target="_blank">https://www.sawyerhood.com/blog/llm-extension</a></p>]]></description></item><item>    <title><![CDATA[剑指offer-54、字符流中第一个不重复的字符 SevenCoding ]]></title>    <link>https://segmentfault.com/a/1190000047490414</link>    <guid>https://segmentfault.com/a/1190000047490414</guid>    <pubDate>2025-12-24 09:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>题⽬描述</h2><p>请实现⼀个函数⽤来找出字符流中第⼀个只出现⼀次的字符。例如，当从字符流中只读出前两个字符" go "时，第⼀个只出现⼀次的字符是" g "。当从该字符流中读出前六个字符“ google "时，第⼀个只出现⼀次的字符是" l "。</p><p>返回值描述：如果当前字符流没有存在出现⼀次的字符，返回 # 字符。</p><h2>思路及解答</h2><h3>有序哈希表</h3><p>可以直接使用哈希的数据结构来存取我们的字符，对与重复的字符可以对值进行统计或者标记都行。这里要用LinkedHashMap，因为题目要求到了要出现的第一个不重复的字符，所以如果不使用有序map的话，那么我们就不能保证取到的是第一个不重复的字符。</p><pre><code class="java">public class Solution {
    //Insert one char from stringstream
    //因为后面要遍历保证有序，所以这里使用LinkedHashMap
    Map&lt;Character,Integer&gt; map = new LinkedHashMap&lt;&gt;();
    
    public void Insert(char ch){
        if(map.containsKey(ch)){
            map.put(ch,-1);
        }else{
            map.put(ch,1);
        }
    }
  //return the first appearence once char in current stringstream
    public char FirstAppearingOnce(){
        for(Character i : map.keySet()){
            if(map.get(i) == 1){
                return i;
            }
        }
        return '#';
    }
}</code></pre><ul><li><strong>时间复杂度</strong>：插入O(1)，查询最坏O(n)</li><li><p><strong>空间复杂度</strong>：O(n)</p><h3>队列+计数数组(最优)</h3></li></ul><p>结合了队列的先进先出特性和数组的快速访问能力，能够高效解决动态字符流中的首个不重复字符查找问题</p><pre><code class="java">public class Solution {
    private int[] count = new int[128];  // ASCII字符计数数组
    private Queue&lt;Character&gt; queue = new LinkedList&lt;&gt;();  // 维护候选字符顺序
    
    // 插入字符到流中
    public void Insert(char ch) {
        count[ch]++;  // 字符出现次数加1
        queue.add(ch);  // 字符加入队列
        
        // 清理队列头部已重复的字符
        while (!queue.isEmpty() &amp;&amp; count[queue.peek()] &gt; 1) {
            queue.poll();
        }
    }
    
    // 返回当前第一个不重复字符
    public char FirstAppearingOnce() {
        return queue.isEmpty() ? '#' : queue.peek();
    }
}</code></pre><ul><li><strong>时间复杂度</strong>：每个字符的插入操作是均摊O(1)，查询操作是严格的O(1)</li><li><strong>空间复杂度</strong>：O(1)（固定大小的数组和队列）</li></ul><h3>双数组记录</h3><p>通过记录字符首次出现的位置和状态，在查询时进行全局扫描</p><pre><code class="java">public class Solution {
    private int[] position = new int[128];  // 记录字符位置或状态
    private int index = 1;  // 当前字符位置索引
    
    public Solution() {
        // 初始化，-1表示未出现过
        for (int i = 0; i &lt; 128; i++) {
            position[i] = -1;
        }
    }
    
    public void Insert(char ch) {
        if (position[ch] == -1) {
            // 第一次出现，记录位置
            position[ch] = index;
        } else if (position[ch] &gt; 0) {
            // 重复出现，标记为-2
            position[ch] = -2;
        }
        index++;
    }
    
    public char FirstAppearingOnce() {
        int minIndex = Integer.MAX_VALUE;
        char result = '#';
        
        // 扫描找到最小正整数值对应的字符
        for (int i = 0; i &lt; 128; i++) {
            if (position[i] &gt; 0 &amp;&amp; position[i] &lt; minIndex) {
                minIndex = position[i];
                result = (char) i;
            }
        }
        return result;
    }
}</code></pre><ul><li><strong>时间复杂度</strong>：插入O(1)，查询O(1)（固定128次循环）</li><li><strong>空间复杂度</strong>：O(1)</li></ul>]]></description></item><item>    <title><![CDATA[基于深度学习的YOLO框架实现金属工业表面缺陷识别｜开箱即用系统级项目（源码+模型+界面） 南瓜 ]]></title>    <link>https://segmentfault.com/a/1190000047498851</link>    <guid>https://segmentfault.com/a/1190000047498851</guid>    <pubDate>2025-12-24 00:02:02</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>🛠️ 基于深度学习的YOLO框架实现金属工业表面缺陷识别｜开箱即用系统级项目（源码+模型+界面）</h2><hr/><h3>🧠 项目背景</h3><p>在现代金属制造与工业质检流程中，金属表面缺陷的及时识别与分级对保障产品质量至关重要。传统的人工检测不仅耗时耗力，而且容易受限于人眼疲劳、主观判断等问题，导致误检漏检频发。</p><p>本项目采用当前主流的深度学习目标检测框架 <strong>YOLOv8</strong>，结合 <strong>图形化界面（PyQt5）</strong>，打造了一套完整的 <strong>金属表面缺陷识别系统</strong>，支持多类缺陷类型检测，具有 <strong>高精度、低延迟、可视化交互友好、部署简单</strong> 等优势，适用于工业生产线、质检实验室等场景。</p><hr/><h3>🔧 核心功能</h3><ul><li>✅ <strong>多类金属缺陷检测识别</strong>：支持划痕、裂纹、氧化、麻点、起皮、腐蚀等6类典型金属缺陷检测；</li><li>✅ <strong>基于YOLOv8的高性能模型</strong>：采用Ultralytics YOLOv8框架，轻量级、高速推理、支持GPU/CPU双模式；</li><li>✅ <strong>完整训练流程</strong>：包含数据预处理、模型训练、验证、推理全过程，便于用户快速上手自定义数据训练；</li><li>✅ <strong>可视化界面部署</strong>：基于PyQt5的图形化前端界面，支持图像导入、检测结果实时显示、缺陷标注框输出；</li><li>✅ <strong>一键推理支持视频/图像/摄像头</strong>：支持单张图像检测、视频文件流、摄像头实时推理；</li><li>✅ <strong>模型导出与切换</strong>：支持.pt、onnx、engine等多格式模型导出，用于边缘端部署；</li><li>✅ <strong>检测结果自动保存</strong>：检测图像自动保存、缺陷类型与位置记录为JSON/Excel报告。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047102948" alt="在这里插入图片描述" title="在这里插入图片描述"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047102949" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047498853" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h3>📊 数据集简介</h3><p>项目使用的数据集基于实际工业金属表面采集图像，涵盖6类常见缺陷，所有图像已完成YOLO格式标注，结构标准清晰，易于扩展：</p><pre><code class="yaml">train: datasets/images/train
val: datasets/images/val
test: datasets/images/test

nc: 6
names: ['scratch', 'crack', 'oxidation', 'pitting', 'peeling', 'corrosion']</code></pre><h4>数据细节：</h4><table><thead><tr><th>类别名称</th><th>中文释义</th><th>样本数量</th><th>特征描述</th></tr></thead><tbody><tr><td>scratch</td><td>划痕</td><td>1220</td><td>线状、细长缺陷</td></tr><tr><td>crack</td><td>裂纹</td><td>980</td><td>断裂状边缘粗糙</td></tr><tr><td>oxidation</td><td>氧化</td><td>860</td><td>表面发黑、灰白区域</td></tr><tr><td>pitting</td><td>麻点</td><td>1100</td><td>坑状小斑点密布</td></tr><tr><td>peeling</td><td>起皮</td><td>840</td><td>表层金属剥落现象</td></tr><tr><td>corrosion</td><td>腐蚀</td><td>950</td><td>不规则腐蚀坑洞</td></tr></tbody></table><ul><li>图片尺寸统一为 640x640；</li><li>数据格式：JPEG图像 + YOLO格式TXT标注文件；</li><li>标注方式：每个缺陷框为 <code>[class_id x_center y_center width height]</code>，归一化坐标；</li><li>支持自动生成cache、mosaic增强、multi-scale训练等机制。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047102951" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047102952" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h2>YOLO框架原理</h2><p>YOLO（You Only Look Once）是单阶段目标检测算法的代表，它将目标检测问题转换为一个回归问题，从图像中直接回归出物体的位置和类别，具有极高的速度优势。YOLOv8作为Ultralytics团队推出的最新版本，具备以下关键特点：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047080211" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h3>核心原理：</h3><ul><li><strong>单阶段检测器</strong>：将整个检测任务在一个神经网络中完成，不依赖候选框生成；</li><li><strong>端到端训练</strong>：输入图像直接输出检测框与分类结果；</li><li><strong>高精度预测头</strong>：YOLOv8采用CSPDarknet主干 + 特征金字塔结构 + 解耦头，提升小目标检测能力；</li><li><strong>动态标签分配</strong>：引入Anchor-free策略，优化标签匹配策略；</li><li><strong>轻量化部署</strong>：可快速导出为ONNX、TorchScript、TensorRT等格式，便于边缘设备部署。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047102953" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h2>源码下载</h2><p>完整项目已打包，包括数据集、模型训练、模型推理、PyQt5桌面GUI、预训练权重、详细部署文档。</p><blockquote><p>至项目实录视频下方获取：<a href="https://www.bilibili.com/video/BV1dv7HzSEbu/" target="_blank">https://www.bilibili.com/video/BV1dv7HzSEbu/</a></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047498854" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p></blockquote><ul><li><p><strong>包含内容</strong>：</p><ul><li><code>train.py</code>：YOLOv8训练脚本（自定义配置）</li><li><code>detect.py</code>：推理检测脚本（支持图像/摄像头）</li><li><code>ui_main.py</code>：基于PyQt5的图形界面</li><li><code>runs/weights/best.pt</code>：训练完成的权重文件</li><li><code>data/face_expression/</code>：YOLO格式的数据集</li><li><code>requirements.txt</code>：项目依赖安装文件</li></ul></li></ul><blockquote>📌 运行前请先配置环境：</blockquote><pre><code class="bash">conda create -n yoloui python=3.9
conda activate yoloui
pip install -r requirements.txt</code></pre><blockquote>📌 启动界面程序：</blockquote><pre><code class="bash">python ui_main.py</code></pre><h2>总结</h2><p>本项目基于YOLOv8深度学习目标检测框架，成功构建了一套<strong>面向金属工业场景的表面缺陷自动识别系统</strong>，从数据采集与标注、模型训练与评估，到前端界面部署与多场景推理，形成了完整闭环，真正实现了“<strong>开箱即用</strong>”。</p><p>项目具备以下突出优势：</p><ul><li>🔍 <strong>精准识别</strong>：6类金属典型缺陷覆盖率高，模型检测精度高于95%；</li><li>🚀 <strong>高效推理</strong>：支持GPU/CPU部署，单张图像检测耗时低于30ms；</li><li>🖥 <strong>图形界面友好</strong>：PyQt5界面支持一键导入图像、视频及摄像头流，便于一线人员操作；</li><li>📦 <strong>模块化设计</strong>：模型训练代码、可视化界面、数据预处理等模块解耦清晰，便于二次开发；</li><li>🧩 <strong>可扩展性强</strong>：用户可替换数据集、增减缺陷类别，适配更多工业质检任务；</li><li>✅ <strong>部署门槛低</strong>：提供完整运行环境需求与启动脚本，非深度学习专业人员亦可快速部署使用。</li></ul>]]></description></item><item>    <title><![CDATA[基于 YOLOv8 的智能车牌定位检测系统设计与实现—从模型训练到 PyQt 可视化落地的完整实战方]]></title>    <link>https://segmentfault.com/a/1190000047498864</link>    <guid>https://segmentfault.com/a/1190000047498864</guid>    <pubDate>2025-12-24 00:01:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>基于 YOLOv8 的智能车牌定位检测系统设计与实现—从模型训练到 PyQt 可视化落地的完整实战方案</h2><h3>一、项目背景与研究意义</h3><p>随着智慧交通与城市智能化建设的不断推进，<strong>车牌识别（License Plate Detection &amp; Recognition）</strong> 已成为交通管理、停车系统、电子收费、高速卡口等场景中的关键技术模块。</p><p>在整个车牌识别流程中，<strong>车牌位置检测</strong> 是最基础、也是最关键的一步。如果检测阶段出现漏检或定位不准，将直接影响后续 OCR 识别效果。</p><p>传统基于规则或颜色特征的方法存在明显局限：</p><ul><li>对光照变化敏感</li><li>难以适应复杂背景</li><li>泛化能力差</li><li>实际工程中误检率高</li></ul><p>近年来，<strong>基于深度学习的目标检测算法</strong> 在该领域表现突出，尤其是 YOLO 系列模型，在实时性和精度之间取得了良好平衡。</p><p>因此，本文将完整介绍一个 <strong>基于 YOLOv8 的车牌位置实时检测系统</strong>，从数据集、模型训练到 PyQt5 图形界面部署，给出一套<strong>可直接运行、可二次开发、可用于课程设计或毕设的完整工程方案</strong>。</p><hr/><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047498866" alt="在这里插入图片描述" title="在这里插入图片描述"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047498867" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047498868" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h3>源码下载与效果演示</h3><p>哔哩哔哩视频下方：<br/><a href="https://www.bilibili.com/video/BV1ZZ7szhEdM" target="_blank">https://www.bilibili.com/video/BV1ZZ7szhEdM</a></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047498869" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h3>二、系统总体设计</h3><h4>2.1 系统架构概览</h4><p>本系统采用典型的 <strong>“模型 + 推理接口 + GUI 前端”</strong> 架构，整体流程如下：</p><pre><code>输入源（图片 / 视频 / 摄像头）
        ↓
YOLOv8 目标检测模型
        ↓
检测结果解析（边框、类别、置信度）
        ↓
PyQt5 图形界面实时显示与结果保存</code></pre><h4>2.2 功能模块划分</h4><p>系统主要包含以下功能模块：</p><ul><li><p><strong>输入模块</strong></p><ul><li>单张图片检测</li><li>文件夹批量检测</li><li>视频文件检测</li><li>摄像头实时检测</li></ul></li><li><p><strong>模型推理模块</strong></p><ul><li>YOLOv8 权重加载</li><li>GPU / CPU 自动适配</li><li>置信度阈值可配置</li></ul></li><li><p><strong>结果展示模块</strong></p><ul><li>实时绘制检测框</li><li>类别与置信度标注</li><li>检测结果保存</li></ul></li><li><p><strong>训练支持模块</strong></p><ul><li>数据集结构说明</li><li>YOLOv8 训练命令</li><li>模型评估指标输出</li></ul></li></ul><hr/><h3>三、YOLOv8 模型原理简析</h3><h4>3.1 YOLOv8 技术特点</h4><p>YOLOv8 是 Ultralytics 于 2023 年发布的新一代 YOLO 模型，相较于 YOLOv5 / YOLOv7，在工程实践中具有以下优势：</p><ul><li><strong>Anchor-Free 设计</strong></li><li><strong>更高的检测精度</strong></li><li><strong>更快的推理速度</strong></li><li><strong>原生支持多任务（检测 / 分割 / 姿态）</strong></li><li><strong>模型结构更清晰，便于二次开发</strong></li></ul><p>本项目使用 YOLOv8 的 <strong>Detection（目标检测）分支</strong>，仅关注车牌区域的定位问题。</p><hr/><h4>3.2 网络结构说明（简要）</h4><p>YOLOv8 网络主要由三部分构成：</p><ol><li><p><strong>Backbone</strong></p><ul><li>提取多尺度特征</li><li>使用 C2f 等轻量化模块</li></ul></li><li><p><strong>Neck</strong></p><ul><li>FPN + PAN 结构</li><li>融合不同层级特征</li></ul></li><li><p><strong>Head</strong></p><ul><li>Anchor-Free 检测头</li><li>直接预测中心点、宽高与类别</li></ul></li></ol><hr/><h3>四、数据集构建与格式规范</h3><h4>4.1 数据集组织结构</h4><p>采用标准 YOLO 格式组织数据：</p><pre><code class="text">dataset/
├── images/
│   ├── train/
│   └── val/
├── labels/
│   ├── train/
│   └── val/</code></pre><h4>4.2 标签格式说明</h4><p>每张图像对应一个 <code>.txt</code> 标签文件，格式如下：</p><pre><code class="text">class_id x_center y_center width height</code></pre><p>其中坐标全部为 <strong>归一化数值（0~1）</strong>。</p><p>示例：</p><pre><code class="text">0 0.5123 0.3784 0.4012 0.1856</code></pre><blockquote>本项目仅设置一个类别：<code>license_plate</code></blockquote><hr/><h3>五、模型训练流程详解</h3><h4>5.1 环境准备</h4><pre><code class="bash">pip install ultralytics</code></pre><p>确认 GPU 环境（可选）：</p><pre><code class="bash">nvidia-smi</code></pre><hr/><h4>5.2 训练配置文件</h4><p><code>data.yaml</code> 示例：</p><pre><code class="yaml">path: dataset
train: images/train
val: images/val

names:
  0: license_plate</code></pre><hr/><h4>5.3 启动训练</h4><pre><code class="bash">yolo detect train \
data=data.yaml \
model=yolov8n.pt \
epochs=100 \
batch=16 \
imgsz=640</code></pre><p>训练完成后，将在 <code>runs/detect/train</code> 目录生成：</p><ul><li><code>weights/best.pt</code></li><li><code>results.png</code></li><li><code>confusion_matrix.png</code></li></ul><hr/><h4>5.4 模型评估指标</h4><p>重点关注以下指标：</p><ul><li><strong>Precision</strong></li><li><strong>Recall</strong></li><li><strong>mAP@0.5</strong></li><li><strong>mAP@0.5:0.95</strong></li></ul><p>在车牌检测任务中，若 mAP@0.5 达到 <strong>90% 以上</strong>，即可满足大多数工程需求。</p><hr/><h3>六、模型推理与结果解析</h3><h4>6.1 Python 推理示例</h4><pre><code class="python">from ultralytics import YOLO

model = YOLO("best.pt")
results = model("test.jpg", conf=0.25, save=True)</code></pre><h4>6.2 推理结果内容</h4><p>每个 <code>results</code> 对象包含：</p><ul><li>边框坐标（xyxy）</li><li>类别 ID</li><li>置信度</li><li>原始图像路径</li><li>保存结果路径</li></ul><hr/><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047498870" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h3>七、PyQt5 图形界面设计与实现</h3><h4>7.1 界面设计目标</h4><ul><li>零命令行操作</li><li>所见即所得</li><li>支持实时检测</li><li>支持结果保存</li></ul><h4>7.2 核心界面功能</h4><ul><li>文件选择按钮</li><li>视频/摄像头切换</li><li>置信度调节</li><li>检测结果显示区域</li></ul><h4>7.3 实时检测流程</h4><ol><li>获取图像帧</li><li>调用 YOLOv8 推理</li><li>绘制检测框</li><li>显示到 GUI 界面</li></ol><hr/><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047498871" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h3>八、系统运行与部署方式</h3><h4>8.1 直接运行（推荐）</h4><pre><code class="bash">python main.py</code></pre><p>项目已集成：</p><ul><li>训练完成权重</li><li>推理逻辑</li><li>UI 界面</li></ul><p>无需再次训练即可使用。</p><hr/><h4>8.2 二次开发方向</h4><ul><li>接入 <strong>OCR 模块</strong> 实现车牌字符识别</li><li>多目标联合检测（车辆 + 行人 + 车牌）</li><li>导出 ONNX / TensorRT</li><li>部署至 Jetson / 边缘设备</li></ul><hr/><h3>九、工程应用价值分析</h3><p>本项目具备以下实际价值：</p><ul><li>✔ 适合作为 <strong>课程设计 / 毕设项目</strong></li><li>✔ 适合学习 YOLOv8 工程化落地</li><li>✔ 可直接扩展为完整车牌识别系统</li><li>✔ 界面友好，适合非算法人员使用</li></ul><hr/><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047498872" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h3>十、总结</h3><p>本文完整介绍了一个 <strong>基于 YOLOv8 的车牌位置检测系统</strong>，从模型原理、数据准备、训练评估到 PyQt5 可视化部署，构建了一套<strong>可复现、可运行、可扩展的工程方案</strong>。</p><p>如果你希望：</p><ul><li>快速掌握 YOLOv8 实战</li><li>构建真实可用的检测系统</li><li>为毕设或项目准备高质量工程</li></ul><p>那么该方案将是一个非常理想的参考起点。</p><blockquote>如果本文对你有所帮助，欢迎点赞、收藏与交流 🚀</blockquote>]]></description></item><item>    <title><![CDATA[AI大模型爆火的SSE技术到底是什么？万字长文，一篇读懂SSE！ JackJiang ]]></title>    <link>https://segmentfault.com/a/1190000047498769</link>    <guid>https://segmentfault.com/a/1190000047498769</guid>    <pubDate>2025-12-23 23:03:25</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>本文由45岁老架构师尼恩分享，感谢作者，有修订和重新排版。</p><h2>1、引言</h2><p>你有没有想过，为什么 ChatGPT 的回答能逐字逐句地“流”出来？这一切的背后，都离不开一项关键技术——SSE（Server-Sent Events）！<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047498771" alt="图片" title="图片"/><br/> 本文从SSE（Server-Sent Events）技术的原理到示例代码，为你通俗易懂的讲解SSE技术的方方面面。</p><h2>2、AI大模型实时通信技术专题</h2><p>技术专题系列文章目录如下，本文是第 4 篇：</p><ol><li>《全民AI时代，大模型客户端和服务端的实时通信到底用什么协议？》</li><li>《大模型时代多模型AI网关的架构设计与实现》</li><li>《通俗易懂：AI大模型基于SSE的实时流式响应技术原理和实践示例》</li><li>《ChatGPT如何实现聊天一样的实时交互？快速读懂SSE实时“推”技术 》</li><li>《AI大模型爆火的SSE技术到底是什么？万字长文，一篇读懂SSE！ 》（☜ 本文）</li></ol><h2>3、初识SSE</h2><p>SSE（Server-Sent Events）是一种基于 HTTP 协议的服务器推送技术，允许服务端主动向客户端发送数据流。SSE  可以被理解为 HTTP 的一个扩展或一种特定用法。它不是一个全新的、独立的协议，而是构建在标准 HTTP/1.1 协议之上的技术。SSE 就像是服务器打开了一个“单向数据管道”，服务器通过HTTP 扩展 可以持续不断地流向浏览器，无需客户端反复发起请求。其实很简单的：  SSE = HTTP 扩展字段 + Keepalive 长连接。SSE 提供了一种简单、可靠的方式来实现服务器向客户端的实时数据推送。它非常适合通知、实时数据更新、日志流和类似 ChatGPT 的逐字输出场景。如果你只需要单向通信，SSE 往往是比 WebSocket 更简单、更轻量的选择。SSE 适用于服务器主动向客户端推送数据的场景，如实时通知、动态更新等。所以，目前 几乎所有主流浏览器都原生支持SSE。PS：更详细的SSE技术资料，可以进一步阅读以下几篇：Web端即时通讯技术盘点：短轮询、Comet、Websocket、SSESSE技术详解：一种全新的HTML5服务器推送事件技术详解Web端通信方式的演进：从Ajax、JSONP 到 SSE、Websocket一文读懂前端技术演进：盘点Web前端20年的技术变迁史网页端IM通信技术快速入门：短轮询、长轮询、SSE、WebSocket搞懂现代Web端即时通讯技术一文就够：WebSocket、socket.io、SSE4、SSE的诞生背景4.1 短轮询、长轮询、Flash 、 WebSocket在 SSE 技术出现之前，Web 应用要实现服务器向客户端的实时数据推送，主要依赖以下几种技术，但它们都存在明显的缺陷。4.1.1）短轮询 (Polling)：原理：用短连接请求数据。客户端以固定的时间间隔（例如每秒一次）频繁地向服务器发送请求，询问是否有新数据。缺点：大量请求可能是无效的（无新数据），浪费服务器和带宽资源，实时性差。短轮询的技术流程图：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047498772" alt="图片" title="图片" loading="lazy"/><br/> 4.1.2）长轮询 (Long Polling)：原理：使用长连接请求数据。 客户端发送一个请求，服务器会保持这个连接打开（长连接），直到有新数据可用或超时。一旦客户端收到响应，会立即发起下一个请求。缺点：虽然减少了无效请求，但每个连接仍然需要客户端发起，服务器需要维护大量挂起的连接，实现复杂。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047498773" alt="图片" title="图片" loading="lazy"/><br/> 长轮询 (Long Polling) 的技术突破：减少无效请求，但服务器需维护挂起连接4.1.3）基于 Flash 的解决方案：原理：利用 Adobe Flash 插件提供的 Socket 功能实现全双工通信。缺点：依赖浏览器插件，在移动端（如 iPhone）不受支持，且随着技术的发展（Flash 被淘汰）已走向消亡。基于 Flash 方法都非原生支持，效率低下或依赖外部插件。4.1.4）基于 WebSocket的解决方案：原理：在客户端与服务器之间建立一条全双工的 TCP 长连接，双方可随时互相推送数据。缺点：1）需要一次额外的协议升级握手（Upgrade: websocket），对 CDN、防火墙、代理服务器的兼容性不如普通 HTTP；2）双向通信能力在“服务器→客户端单向推送”场景下显得过度设计，增加心跳、重连、帧解析等复杂度；3）早期浏览器支持不一（IE ≤ 9 无原生实现），需要 Polyfill 或 Flash 降级方案。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047498774" alt="图片" title="图片" loading="lazy"/><br/> WebSocket全双工通道的革命性：摆脱HTTP束缚，实现真正的实时交互（PS: WebSocket 并不仅是 Web 领域的通讯协议，它属于复杂度较高的二进制通讯协议）。4.2 SSE 诞生的核心背景因此，Web 领域迫切需要一种标准化的、高效的、由浏览器原生支持的服务器到客户端的单向通信机制。这就是 SSE 诞生的核心背景。核心需求：1）简单：易于服务器和客户端实现；2）高效：基于 HTTP/HTTPS，避免不必要的请求开销；3）标准：成为 W3C 标准，得到浏览器原生支持；4）自动重连：内置连接失败后自动重试的机制。SSE——真正的服务器推送：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047498775" alt="图片" title="图片" loading="lazy"/><br/> 5、SSE的前世今生SSE 的发展是 Web 标准化进程和实时通信需求共同推动的结果。下图概述了其关键发展节点：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047498776" alt="图片" title="图片" loading="lazy"/><br/> 让我们对图中的关键阶段进行详细解读。1）诞生背景（2006 年以前）：Web 早期只有“请求-响应”范式，实时需求（股票、IM、行情）只能靠轮询或长轮询，延迟高、浪费资源。Comet（长连接 iframe、jsonp、xhr-streaming 等 Hack 方案）出现，但实现复杂、浏览器兼容性差、占用连接数高。业界急需一种“浏览器原生、基于 HTTP、单向服务器推送”的轻量机制。2）概念提出与标准化 (约 2006-2009年)：SSE 的概念最初作为 HTML5 标准的一部分被提出，由 WHATWG (Web Hypertext Application Technology Working Group) 和 W3C (World Wide Web Consortium) 共同推动。其设计思想是定义一个简单的、基于 HTTP 的协议，允许服务器通过一个长连接持续地向客户端发送文本流。2006 年，Opera 9 在浏览器里率先实现名为 Server-Sent Events 的实验 API，用 DOM 事件把服务器推送的文本块喂给页面。同期 WHATWG HTML5 草案开始收录相关章节，定义了 text/event-stream MIME 类型及“event: / data:”行协议。后来，它从庞大的 HTML5 规范中分离出来，成为了一个独立的 W3C 标准文档。2008 年，SSE 被正式写入 HTML5 草案，随后进入 W3C 标准流程。3）浏览器支持与推广 (约 2010-2015年)：2011年左右，主流浏览器（如 Firefox、Chrome、Safari、Opera）开始陆续支持 SSE API。 Firefox 6、Chrome 6、Safari 5、Opera 11.5 陆续完成原生实现；IE 系列缺席（直到 Edge 79 才补票）。关键的障碍：Internet Explorer (包括 IE 11) 始终没有支持 SSE API。这在一定程度上限制了其早期的广泛应用，开发者通常需要为此准备降级方案（如回落到长轮询）。随着 Chrome、Firefox 等现代浏览器的市场份额不断上升，以及移动端浏览器对 SSE 的良好支持，SSE 逐渐成为开发实时 Web 应用的可信选择。2014 年 10 月：HTML5 成为 W3C Recommendation，SSE 作为官方子模块锁定最终语法，浏览器阵营格局定型。4）正式推荐与成熟 (2015年至2022 )：2015-2020 年，WebSocket 与 WebRTC 占据实时通信话题中心，SSE 主要在企业内部仪表盘、日志 tail 等低频场景默默使用。SSE 由于有 “单向文本流 + 自动重连 + 轻量”  特性，所以没有被WebSocket 与 WebRTC  踩死， 使其在 IoT 设备、移动端 WebView 中仍保有一席之地。2015年，W3C 发布了 Server-Sent Events 的正式推荐标准，标志着该技术的成熟和稳定。在此期间，前端生态框架（如 React、Vue.js）和后端语言（如 Node.js、Python、Java）都提供了对 SSE 的良好支持，出现了大量易用的库和示例。5） 大模型时代的爆发（2022 至今）：虽然 WebSocket 提供了全双工通信能力，但 SSE 因其简单的 API、基于 HTTP 带来的良好兼容性（如无需担心代理或防火墙问题）、以及自动重连等特性，在只需要服务器向客户端推送数据的场景中（如新闻推送、实时行情、状态更新、AI 处理进度流式输出等）成为了更简单、更合适的选择。ChatGPT、Claude 等生成式 AI 需要“打字机”式逐 token 输出，SSE 天然契合：1）基于 HTTP/1.1 无需升级协议，CDN 缓存友好；2）浏览器 EventSource API 一行代码即可接入；3）文本流可直接承载 JSON Lines 或 markdown 片段。2022 年底起：OpenAI、Anthropic、Google Bard 均把 text/event-stream 作为官方流式回答协议，社区库（FastAPI SSE-Star、Spring WebFlux、Node sse.js、Go gin-sse）迎来二次繁荣。6、SSE的技术特征<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047498777" alt="图片" title="图片" loading="lazy"/><br/> SSE和WebSocket 都能建立浏览器与服务器的长期通信，但区别很明显：1）SSE 是单向推送  不是双向推送， 而且是http协议的一个扩展协议， 使用简单、自动重连，适合文本类实时推送；2）WebSocket 是双向通信，不是 http协议的一个扩展协议，WebSocket  更灵活，但实现相对复杂。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047498778" alt="图片" title="图片" loading="lazy"/><br/>流程解读：1）连接初始化：客户端使用特定的 Content-Type: text/event-stream 向服务器发起一个普通的 HTTP GET 请求。服务器确认并保持连接开放。2）数据推送：服务器通过保持打开的连接，以纯文本格式（遵循 data: ...、event: ... 等规范）持续发送数据块。每个消息以两个换行符 \n\n 结束。3）连接容错：如果连接因网络问题中断，SSE 客户端内置的机制会自动尝试重新建立连接，极大地提高了应用的鲁棒性。4）客户端处理：浏览器端的 EventSource API 会解析收到的数据流，触发相应的事件（如 onmessage 或自定义事件），让开发者能够处理推送来的数据。SSE 的诞生是 Web 开发对简单、高效、标准化的服务器推送技术需求的直接结果。它有效地替代了笨拙的轮询技术，在与 WebSocket 的竞争中，找到了自身在单向数据流场景下的独特定位。其发展历程经历了从概念提出、浏览器支持到成为正式标准的完整路径。尽管曾受限于 IE，但在现代浏览器中已成为一项稳定、可靠且被广泛采用的技术。如今，在实时通知、金融仪表盘、实时日志跟踪和大型语言模型（LLM）的流式响应输出等场景中，SSE 都是首选的解决方案。7、默默无闻的SSE为何在AI大模型时代一夜爆火？SSE 最近站到聚光灯下，几乎可以说最大的推手就是当前 AI 应用（尤其是 ChatGPT 等大型语言模型）的爆发式增长。SSE  之所以成为 AI 应用的“标配”，是因为 SSE 与  AI 所需的“打字机” 输出模式  是 天作之合。7.1 什么是AI大模型“打字机” 式的逐token输出？“打字机”式 逐 token 输出是一种流式传输方式，它模拟了人类打字或思考的过程。服务器不是等待 LLM 生成整个答案 后一次性发送给 用户，而是 流式输出， 每生成一个“词元”（token，可以粗略理解为一个词或一个字），就立刻发送这个“词元”。下面举一个例子，对比 一下  传统方式（非流式）和 “打字机” （流式）式 的过程。传统方式（非流式）过程如下：1）你提问：“请写一首关于春天的诗”。2）服务器端的 AI 开始思考、生成，整个过程你需要等待（可能好几秒甚至更久）。3）AI 生成完整的诗歌：“春风拂面绿意浓，百花争艳映晴空...”。4）服务器将整首诗作为一个完整的 JSON 对象 { "content": "春风拂面绿意浓，百花争艳映晴空..." } 发送给客户端。5）客户端一次性收到全部内容并渲染出来。“打字机”（流式）过程如下：1）你提问：“请写一首关于春天的诗”。2）服务器端的 AI 生成第一个 token “春”，立刻通过 SSE 发送 data: “春”。3）客户端收到“春”并显示出来。4）AI 生成第二个 token “风”，立刻发送 data: “风”。5）客户端在“春”后面追加“风”，形成“春风”。6）后续 token “拂”、“面”、“绿”、“意”、“浓”... 依次迅速发送和追加。7）你看到的效果就是文字一个接一个地“打”在屏幕上，就像有人在远端为你实时打字一样。“打字机”（流式） 模式的巨大优势：1）极低的感知延迟：用户几乎在提问后瞬间就能看到第一个字开始输出，无需经历漫长的等待白屏期，体验流畅自然。2）提供了“正在进行”的反馈：看着文字逐个出现，给人一种模型正在为你“思考”和“创作”的生动感，而不是在“沉默中宕机”。3）更高效地利用时间：用户可以在前半句还在输出时，就开始阅读和理解，节省了总体的认知时间。7.2 为什么SSE跟AI大模型是“天作之合”？这正是 SSE 的设计初衷和核心优势所在，它与 AI 流式输出的需求完美匹配。1）单向通信的完美匹配：AI 的文本生成过程本质上是服务器到客户端的单向数据推送。客户端只需要接收，不需要在生成过程中频繁地发送请求。SSE 的“服务器推送”模型正是为此而生，而 WebSocket 的双向能力在这里是多余的。2）基于 HTTP/HTTPS，简单且兼容：SSE 使用标准的 HTTP 协议，这意味着  SSE 易于实现和调试：任何后端框架和前端语言都能轻松处理。在浏览器中调试时，你可以在“网络”选项卡中直接看到以文本流形式传输的事件，非常直观。SSE 使用标准的 HTTP 协议，这还意味着  容易绕过网络障碍：公司防火墙和代理通常对 HTTP/HTTPS 放行，而可能会阻拦陌生的 WebSocket 协议。这使得 SSE 的部署兼容性极好。3）内置的自动重连机制：网络连接并不完全可靠。如果用户在接收很长的回答时网络波动，连接中断，SSE 客户端会自动尝试重新连接。这对于长时间流的应用至关重要，提供了天然的鲁棒性。4）轻量级的文本协议：AI 流式输出传输的就是文本（UTF-8编码）。SSE 的协议 data: ...\n\n 就是为传输文本片段而设计的，极其高效和简单。WebSocket 虽然也能传文本，但其协议设计还考虑了二进制帧、掩码等更复杂的情况，对于纯文本流来说显得有些“重”。5）原生浏览器 API：现代浏览器都原生支持 EventSource API，开发者无需引入额外的第三方库，即可轻松实现接收流式数据，减少了依赖和打包体积。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047498779" alt="图片" title="图片" loading="lazy"/><br/>所以，SSE 站到聚光灯下的原因正是：AI 应用需要“打字机”式的逐 token 输出体验，而 SSE 作为一种基于 HTTP 的、简单的、单向的服务器推送技术，是实现这种体验最自然、最高效、最可靠的技术选择。它就像是为这个场景量身定做的工具，没有多余的功能，只有恰到好处的设计。因此，当 ChatGPT 等应用席卷全球时，其背后默默无闻的 SSE 技术也终于从幕后走到了台前，被广大开发者所重新认识和重视。8、SSE的技术原理详解8.1 工作机制的流程图SSE 通过一个持久的 HTTP 连接实现服务器到客户端的单向数据流。以下是其工作机制的流程图：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047498780" alt="图片" title="图片" loading="lazy"/><br/> 以下是关键步骤解析。1）浏览器发起一个 HTTP 请求，Header 中包含：1Accept: text/event-stream2）服务器响应类型必须为：Content-Type: text/event-streamCache-Control: no-cacheConnection: keep-alive3）服务器发送事件格式（每个事件以两个换行符结束）：event: messagedata: {"time": "2023-10-05T12:00:00", "value": "New update!"}id: 12345retry: 5000\n\n4）浏览器通过 EventSourceAPI 接收并处理事件。5）服务器发送 一个特殊“结束”事件，可以结束传输。比如，服务器发送一个如 event: end 的消息，可以结束传输。客户端预先监听这个自定义的 end 事件，一旦收到，就知道传输结束，并可以选择主动关闭 EventSource 连接。6）若连接中断，浏览器会根据 retry字段自动重连。如果没有收到  特殊“结束”事件， 浏览器 可以自动重连。8.2 SSE与其他通信方式对比不同通信技术各有适用场景，我们用表格清晰对比：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047498781" alt="图片" title="图片" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047498782" alt="图片" title="图片" loading="lazy"/><br/> 8.3 SSE的适用场景1）ChatGPT 式逐字输出( “打字机” 式逐 词元 token输出)：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047498783" alt="图片" title="图片" loading="lazy"/><br/> 2）实时通知系统：a. 新订单提醒；b. 用户消息推送；c. 审核状态更新。3）实时数据看板：a. 股票行情；b. 设备监控数据；c. 实时日志流。9、SSE客户端API详解SSE的客户端实现非常简单，浏览器原生提供了EventSource对象来处理与服务器的SSE连接。下面我们详细介绍它的使用方法和核心特性。9.1 认识浏览器端EventSource对象浏览器兼容性检测：在使用SSE前，首先需要确认当前浏览器是否支持EventSource（除IE/Edge外，几乎所有现代浏览器都支持）。检测方法如下：// 检查浏览器是否支持SSEif ('EventSource' in window) {  // 支持SSE，可正常使用  console.log('浏览器支持SSE');} else {  // 不支持SSE，需降级处理  console.log('浏览器不支持SSE');}创建连接：使用EventSource创建与服务器的连接非常简单，只需传入服务器的SSE接口地址：// 建立与服务器的SSE连接// url为服务器提供的SSE接口地址（可同域或跨域）var source = new EventSource(url);如果需要跨域请求并携带Cookie，可通过第二个参数配置：// 跨域请求时，允许携带Cookievar source = new EventSource(url, {  withCredentials: true // 默认为false，设为true表示跨域请求携带Cookie});连接状态（readyState）：EventSource实例的readyState属性用于表示当前连接状态，只读且有三个可能值：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047498784" alt="图片" title="图片" loading="lazy"/><br/> 可以通过该属性判断当前连接状态，例如：if (source.readyState === EventSource.OPEN) {  console.log('SSE连接已正常建立');}9.2 基本使用方法EventSource通过事件机制处理连接过程中的各种状态和接收的数据，核心事件包括open、message、error。下面用流程图展示SSE客户端的完整使用流程：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047498785" alt="图片" title="图片" loading="lazy"/><br/> 连接建立：open事件当客户端与服务器成功建立SSE连接时，会触发open事件：// 方式1：使用onopen属性source.onopen = function (event) {  console.log('SSE连接已建立');  // 可在此处做连接成功后的初始化操作，如更新UI状态};// 方式2：使用addEventListener（推荐，可添加多个回调）source.addEventListener('open', function (event) {  console.log('SSE连接已建立（监听方式）');}, false);接收数据：message事件当客户端收到服务器推送的数据时，会触发message事件（默认事件，处理未指定类型的消息）：// 方式1：使用onmessage属性source.onmessage = function (event) {  // event.data为服务器推送的文本数据  var data = event.data;  console.log('收到数据：', data);  // 可在此处处理数据，如更新页面内容};// 方式2：使用addEventListenersource.addEventListener('message', function (event) {  var data = event.data;  console.log('收到数据（监听方式）：', data);}, false);注意：event.data始终是字符串类型，如果服务器发送的是JSON数据，需要用JSON.parse(data)转换。连接错误：error事件当连接发生错误（如网络中断、服务器出错）时，会触发error事件：// 方式1：使用onerror属性source.onerror = function (event) {  // 可根据readyState判断错误类型  if (source.readyState === EventSource.CONNECTING) {    console.log('连接出错，正在尝试重连...');  } else {    console.log('连接已关闭，无法重连');  }};// 方式2：使用addEventListenersource.addEventListener('error', function (event) {  // 错误处理逻辑}, false);关闭连接：close()方法如果需要主动关闭SSE连接（关闭后不会自动重连），可调用close()方法：// 主动关闭SSE连接source.close();console.log('SSE连接已手动关闭');9.3 自定义事件默认情况下，服务器推送的消息会触发message事件。但实际开发中，我们可能需要区分不同类型的消息（如"新订单通知"和"系统公告"），这时就可以使用自定义事件。客户端通过addEventListener监听自定义事件名，例如监听order事件：// 监听名为"order"的自定义事件source.addEventListener('order', function (event) {  var orderData = event.data;  console.log('收到新订单：', orderData);  // 处理订单相关逻辑}, false);// 再监听一个名为"notice"的自定义事件source.addEventListener('notice', function (event) {  var noticeData = event.data;  console.log('收到系统公告：', noticeData);  // 处理公告相关逻辑}, false);注意：自定义事件不会触发message事件，只会被对应的addEventListener捕获。上面代码中，浏览器对 SSE 的foo<code>notice事件进行监听。如何实现服务器发送foo</code>notice事件，请看下文。12.4 AI大模型中该选择SSE协议还是WebSocket？直接答案：对于绝大多数 chat2ai 应用  优先选择 SSE (Server-Sent Events)。复杂的  chat2ai 应用  优先选择WebSocket。但这并非绝对，我们需要根据具体的功能需求来决定。下面我将为你进行详细的分析和推理。12.4.1）核心决策分析：AI聊天应用的核心交互是：1）客户端发送一条消息（一个问题）。2）服务器接收后，调用大语言模型（LLM）API。3）服务器将模型流式返回的答案（逐词或逐句）实时推送给客户端。4）客户端实时渲染这个流式的答案，营造出“打字机”效果。这个过程的关键在于第3步，即服务器向客户端的单向数据推送。这正是 SSE 的绝对主场。12.4.2）为什么 SSE 是更优的选择？以下流程图清晰地展示了基于不同技术方案的聊天交互过程，其中突出了SSE方案的巨大优势：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047498786" alt="图片" title="图片" loading="lazy"/><br/> 正如上图所示：SSE 方案在实现上更加直接和高效，因为它基于 HTTP，并且专门为服务器到客户端的单向数据流设计。此外，SSE 还带来了以下巨大优势：1）开发复杂度极低：  a. 后端：你不需要引入任何复杂的 WebSocket 库（如 ws, Socket.IO）。你只需要建立一个普通的 HTTP 路由（如 POST /chat 用于发送消息，GET /chat/stream 用于接收流），并在控制器中输出 text/event-stream 格式的响应流。b. 前端：使用浏览器原生的 EventSource API 即可轻松监听数据流，几行代码就能实现。无需实例化和管理 WebSocket 连接对象。2）出色的兼容性与可维护性：a. SSE 基于 HTTP，这意味着它更容易通过公司防火墙、代理，与现有的认证系统（如 Cookie、JWT）、CORS 策略协同工作，几乎不会遇到奇怪的网络问题。b. 在浏览器“网络”选项卡中，SSE 的流清晰可见，易于调试。每个消息都是可读的文本，调试体验非常好。3）内置的自动重连与断点续传机制：a. 这是 SSE 的“杀手级特性”。网络连接不稳定是移动端的常见问题。如果用户在接收一个很长答案的过程中网络中断，SSE 会在网络恢复后自动重新连接。b. 更强大的是，SSE 协议支持发送最后一个消息的 ID。服务器可以识别出这个 ID，并判断客户端错过了哪些数据，从而从断点处继续发送，而不是重新开始生成整个回答。这既节省了昂贵的 API 调用费用，也提升了用户体验。这在 WebSocket 中需要手动实现所有逻辑，非常复杂。12.4.3）WebSocket 的适用场景：虽然 SSE 是主流选择，但在 chat2ai 应用变得非常复杂时，WebSocket 可能会成为更好的选择。在以下情况下， 应该考虑使用 WebSocket：1）需要极高频的双向通信：不仅仅是用户提问-&gt;AI回答。例如：a. 实时协作编辑：多个用户同时编辑一份由 AI 生成的文档，每个人的输入都需要实时同步给其他所有人。b. AI多人游戏：基于 AI 生成剧情和环境的实时互动游戏，玩家的每一个动作都需要实时影响虚拟世界。2）当需要传输二进制数据的时候：有的聊天应用不仅支持文本，还支持实时语音对话（客户端录音发送二进制音频流，服务器返回 AI 语音二进制流）。WebSocket 对二进制数据的支持是天生的。3）你需要非常精确的控制心跳和连接状态：   - WebSocket 允许 手动发送 Ping/Pong 帧来检测连接活性，虽然复杂，但给了开发人员最大的控制权。12.4.4）传输协议选型 结论与建议：1）起步和绝大多数情况：从 SSE 开始。这是最直接、最高效、最能给你带来稳定体验的选择。使用sse 遇到的技术挑战会更少，开发速度更快。ChatGPT、Claude 等绝大多数顶级应用都使用 SSE 不是没有道理的。2）未来如果需要扩展：采用混合架构。如果应用未来需要加入上述 WebSocket 的适用功能（如实时语音），完全可以同时使用两种协议：使用 SSE 专门处理 AI 文本答案的流式推送。使用 WebSocket 专门处理 实时语音、实时协作等真正的双向通信功能。或者 强弱结合，自动切换。因此，对于  chat2ai 的传输协议选型答案是：优先选择 SSE。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047498787" alt="图片" title="图片" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047498788" alt="图片" title="图片" loading="lazy"/><br/> 13、参考资料[0] EventSource API Docs[1] Web端即时通讯技术盘点：短轮询、Comet、Websocket、SSE[2] SSE技术详解：一种全新的HTML5服务器推送事件技术[3] 使用WebSocket和SSE技术实现Web端消息推送[4] 详解Web端通信方式的演进：从Ajax、JSONP 到 SSE、Websocket[5] 使用WebSocket和SSE技术实现Web端消息推送[6] 一文读懂前端技术演进：盘点Web前端20年的技术变迁史[7] WebSocket从入门到精通，半小时就够！[8] 网页端IM通信技术快速入门：短轮询、长轮询、SSE、WebSocket[9] 搞懂现代Web端即时通讯技术一文就够：WebSocket、socket.io、SSE[10] 大模型时代多模型AI网关的架构设计与实现[11] 全民AI时代，大模型客户端和服务端的实时通信到底用什么协议？[12] 通俗易懂：AI大模型基于SSE的实时流式响应技术原理和实践示例[13] Web端实时通信技术SSE在携程机票业务中的实践应用[14] ChatGPT如何实现聊天一样的实时交互？快速读懂SSE实时“推”技术即时通讯技术学习：- 移动端IM开发入门文章：《新手入门一篇就够：从零开发移动端IM》- 开源IM框架源码：<a href="https://link.segmentfault.com/?enc=6oFyAhta4RiB2zeSPDPyfg%3D%3D.Uk8kqJzAR0%2BjeBcHiS3Za9MfNzm1Tz16C%2FTwys3jDORoPLlWnECfdjUZojKt1EJz" rel="nofollow" target="_blank">https://github.com/JackJiang2011/MobileIMSDK</a>（备用地址点此）（本文已同步发布于：<a href="https://link.segmentfault.com/?enc=2aTwDaTzHYj0lD8%2B1OG59g%3D%3D.Wr92UnyEcFUU5vwhWhyJFEXiPHIDdqPcwwjSThmI07rxDdFnVr8erl4tQ%2Bzj78lh" rel="nofollow" target="_blank">http://www.52im.net/thread-4885-1-1.html</a>）</p>]]></description></item><item>    <title><![CDATA[手写一个 Askama 模板压缩工具 jump__jump ]]></title>    <link>https://segmentfault.com/a/1190000047498767</link>    <guid>https://segmentfault.com/a/1190000047498767</guid>    <pubDate>2025-12-23 23:02:40</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在 Web 开发中，前端资源的大小直接影响用户体验。大型模板文件不仅占用带宽，还会延长页面加载时间。虽然市面上有很多 HTML 压缩工具，但对于使用了模板引擎的 HTML 文件（如 Askama、Jinja2 等），通用压缩器往往会破坏模板语法。</p><p>于是个人写了一个 Askama 模板压缩工具 askama-minify，专门用于压缩 Askama 模板文件，同时完美保留模板语法。</p><h2>Askama 为什么要压缩</h2><h3>模板文件占用的空间</h3><p>在实际的 Web 项目中，模板文件往往占据相当大的体积：</p><table><thead><tr><th>项目类型</th><th>模板数量</th><th>总大小</th><th>压缩后大小</th></tr></thead><tbody><tr><td>小型网站</td><td>10-20</td><td>200-500KB</td><td>100-250KB</td></tr><tr><td>中型应用</td><td>50-100</td><td>1-3MB</td><td>500KB-1.5MB</td></tr><tr><td>大型系统</td><td>200+</td><td>5-10MB</td><td>2-5MB</td></tr></tbody></table><h3>压缩的好处</h3><ol><li><strong>减少带宽消耗</strong>：模板大小减少 40-55%，直接降低流量成本</li><li><strong>加快页面加载</strong>：更小的文件意味着更快的传输速度</li><li><strong>提升用户体验</strong>：首屏渲染时间缩短，特别是移动端用户</li><li><strong>降低服务器负载</strong>：传输数据量减少，服务器压力降低</li><li><strong>节省存储空间</strong>：生产环境的模板文件占用更少空间</li></ol><h3>Askama 自带的压缩配置</h3><p>Askama 本身提供了 whitespace 控制功能，在项目根目录的 <code>askama.toml</code> 中配置：</p><pre><code class="toml">[general]
# 三种模式可选
whitespace = "suppress"   # 或 "minimize" / "preserve"</code></pre><p><strong>三种模式对比：</strong></p><table><thead><tr><th>模式</th><th>行为</th><th>适用场景</th></tr></thead><tbody><tr><td><code>preserve</code></td><td>保留所有空白（默认）</td><td>开发调试</td></tr><tr><td><code>suppress</code></td><td>激进移除空白</td><td>生产环境</td></tr><tr><td><code>minimize</code></td><td>适度移除空白</td><td>平衡模式</td></tr></tbody></table><p>也可以在单个模板上覆盖：</p><pre><code class="rust">#[derive(Template)]
#[template(path = "example.html", whitespace = "suppress")]
struct ExampleTemplate;</code></pre><h3>Askama 自带压缩的局限性</h3><p>Askama 的 whitespace 控制有以下限制：</p><ol><li><strong>只处理空白字符</strong>：不能移除 HTML 注释 <code>&lt;!-- --&gt;</code></li><li><strong>不影响 CSS</strong>：<code>&lt;style&gt;</code> 标签内的 CSS 完全保留</li><li><strong>不影响 JavaScript</strong>：<code>&lt;script&gt;</code> 标签内的 JS 完全保留</li><li><strong>不优化代码</strong>：无法进行属性合并、颜色优化等</li></ol><p><strong>示例对比：</strong></p><pre><code class="html">&lt;!-- 原始模板 --&gt;
&lt;style&gt;
    body {
        margin-top: 0;
        margin-bottom: 0;
        /* 这是 CSS 注释 */
        background-color: #ff0000;
    }
&lt;/style&gt;
&lt;script&gt;
    // 这是 JS 注释
    console.log("Hello");
&lt;/script&gt;</code></pre><pre><code class="html">&lt;!-- Askama whitespace = "suppress" 的结果 --&gt;
&lt;style&gt;body{margin-top:0;margin-bottom:0;/*这是CSS注释*/background-color:#ff0000;}&lt;/style&gt;&lt;script&gt;//这是JS注释
console.log("Hello");&lt;/script&gt;</code></pre><pre><code class="html">&lt;!-- askama-minify 的结果 --&gt;
&lt;style&gt;body{margin:0 0;background-color:red}&lt;/style&gt;&lt;script&gt;console.log("Hello");&lt;/script&gt;</code></pre><p>可以看到，askama-minify 做得更彻底：</p><ul><li>移除了所有注释</li><li>合并了 CSS 属性</li><li>优化了颜色值</li><li>压缩了 JavaScript</li></ul><h2>项目演进</h2><p>任何项目都不是一蹴而就的，下面是关于 askama-minify 库的编写思路。希望能对大家有一些帮助。</p><h2>为什么需要专门的工具（补充）</h2><p>在使用 Askama 这样的 Rust 模板引擎时，我们的模板文件中会包含特殊的语法：</p><pre><code class="html">&lt;!-- Askama 模板语法 --&gt;
&lt;div&gt;{{ title }}&lt;/div&gt;
{% for item in items %}
    &lt;p&gt;{{ item.name }}&lt;/p&gt;
{% endfor %}</code></pre><p>通用的 HTML 压缩器（如 html-minifier）可能会：</p><ul><li>将 <code>{{ }}</code> 识别为无效语法而破坏</li><li>将 <code>{% %}</code> 中的空格错误处理</li><li>无法区分模板语法和普通文本</li></ul><p>因此我们需要一个专门设计的压缩工具。</p><h2>简单的 HTML 压缩</h2><p>最基础的 HTML 压缩非常简单：移除多余的空白字符即可。</p><pre><code class="rust">pub fn minify_html_simple(content: &amp;str) -&gt; String {
    let mut result = String::with_capacity(content.len());
    let mut last_was_space = false;

    for ch in content.chars() {
        if ch.is_whitespace() {
            if !last_was_space &amp;&amp; !result.is_empty() {
                result.push(' ');
                last_was_space = true;
            }
        } else {
            result.push(ch);
            last_was_space = false;
        }
    }

    result
}</code></pre><p>这个简单版本会将：</p><pre><code class="html">&lt;div&gt;    &lt;p&gt;   Hello   &lt;/p&gt;    &lt;/div&gt;</code></pre><p>压缩为：</p><pre><code class="html">&lt;div&gt; &lt;p&gt; Hello &lt;/p&gt; &lt;/div&gt;</code></pre><p>但这样还不够——我们需要：</p><ol><li>移除 HTML 注释</li><li>处理特殊标签（<code>&lt;pre&gt;</code>, <code>&lt;textarea&gt;</code>）</li><li>保留模板语法</li></ol><h2>保留模板语法</h2><p>模板语法的保留是本工具的核心。我们需要在遇到 <code>{{</code> 和 <code>{%</code> 时，保持原样输出，直到遇到对应的 <code>}}</code> 和 <code>%}</code>。</p><pre><code class="rust">pub fn minify_html(content: &amp;str) -&gt; String {
    let mut result = String::with_capacity(content.len());
    let mut chars = content.chars().peekable();
    let mut in_template_brace = false;  // {{ }}
    let mut in_template_chevron = false; // {% %}

    while let Some(ch) = chars.next() {
        // 检测模板语法开始
        if ch == '{' {
            if let Some(&amp;next_ch) = chars.peek() {
                if next_ch == '{' {
                    in_template_brace = true;
                    result.push(ch);
                    continue;
                } else if next_ch == '%' {
                    in_template_chevron = true;
                    result.push(ch);
                    continue;
                }
            }
        }

        // 在模板语法内，保持原样
        if in_template_brace || in_template_chevron {
            result.push(ch);
            // 检测模板语法结束
            if in_template_brace &amp;&amp; ch == '}' &amp;&amp; result.ends_with("}}") {
                in_template_brace = false;
            } else if in_template_chevron &amp;&amp; ch == '}' &amp;&amp; result.ends_with("%}") {
                in_template_chevron = false;
            }
            continue;
        }

        // ... 其他处理逻辑
    }

    result
}</code></pre><p>测试一下：</p><pre><code>输入: &lt;div&gt;{{ title }}&lt;/div&gt;
输出: &lt;div&gt;{{ title }}&lt;/div&gt;  // 完美保留

输入: &lt;div&gt;  {{  title  }}&lt;/div&gt;
输出: &lt;div&gt; {{ title }}&lt;/div&gt;  // 模板外空格压缩，模板内保留</code></pre><h2>移除 HTML 注释</h2><p>HTML 注释的移除需要小心，不能破坏字符串中的 <code>&lt;!--</code>：</p><pre><code class="rust">// HTML 注释处理（只在不在 script/style 内时处理）
if !in_script &amp;&amp; !in_style &amp;&amp; ch == '&lt;' &amp;&amp; chars.peek() == Some(&amp;'!') {
    let mut comment = String::from("&lt;");
    comment.push(chars.next().unwrap()); // '!'

    if chars.peek() == Some(&amp;'-') {
        comment.push(chars.next().unwrap()); // first '-'
        if chars.peek() == Some(&amp;'-') {
            comment.push(chars.next().unwrap()); // second '-'
            // 这是一个注释，跳过直到 --&gt;
            while let Some(c) = chars.next() {
                comment.push(c);
                if comment.ends_with("--&gt;") {
                    break;
                }
            }
            continue; // 跳过注释
        }
    }
    result.push_str(&amp;comment);
    continue;
}</code></pre><h2>处理特殊标签</h2><p>某些标签（如 <code>&lt;pre&gt;</code> 和 <code>&lt;textarea&gt;</code>）的内容需要完全保留原样，包括空格和换行：</p><pre><code class="rust">let mut in_pre = false;
let mut in_textarea = false;

// 在标签检测时
if tag_name == "pre" {
    in_pre = true;
} else if tag_name == "textarea" {
    in_textarea = true;
} else if tag_name == "/pre" {
    in_pre = false;
} else if tag_name == "/textarea" {
    in_textarea = false;
}

// 在字符处理时
if in_pre || in_textarea {
    result.push(ch);  // 完全保留
    continue;
}</code></pre><h2>添加 CSS 优化</h2><p>HTML 中的 <code>&lt;style&gt;</code> 标签内容可以使用专业的 CSS 优化器。这里选择 lightningcss，它是 Parcel 团队开发的高性能 CSS 解析器：</p><pre><code class="rust">use lightningcss::stylesheet::{MinifyOptions, ParserOptions, PrinterOptions, StyleSheet};

pub fn minify_css(css_code: &amp;str) -&gt; String {
    let stylesheet = StyleSheet::parse(css_code, ParserOptions::default());

    match stylesheet {
        Ok(mut sheet) =&gt; {
            sheet.minify(MinifyOptions::default()).ok();
            let result = sheet.to_css(PrinterOptions {
                minify: true,
                ..PrinterOptions::default()
            });

            match result {
                Ok(output) =&gt; output.code,
                Err(e) =&gt; {
                    eprintln!("Warning: Failed to minify CSS: {:?}", e);
                    css_code.to_string()
                },
            }
        }
        Err(e) =&gt; {
            eprintln!("Warning: Failed to parse CSS: {:?}", e);
            css_code.to_string()
        },
    }
}</code></pre><p>lightningcss 的优化效果非常好：</p><pre><code class="css">/* 输入 */
body {
    margin-top: 0;
    margin-bottom: 0;
    background-color: #ff0000;
}

/* 输出 */
body{margin:0 0;background-color:red}</code></pre><ul><li>属性合并：<code>margin-top: 0; margin-bottom: 0</code> → <code>margin: 0 0</code></li><li>颜色优化：<code>#ff0000</code> → <code>red</code></li><li>移除所有不必要的空格和换行</li></ul><h2>添加 JavaScript 压缩</h2><p>JavaScript 的压缩需要更加小心，因为：</p><ol><li>字符串中的注释语法不应被处理</li><li>除法运算符 <code>/</code> 容易与注释混淆</li><li>转义字符需要正确处理（<code>\"</code>, <code>\'</code>）</li><li>正则表达式需要保护</li></ol><pre><code class="rust">pub fn minify_js(js_code: &amp;str) -&gt; String {
    let mut result = String::with_capacity(js_code.len());
    let mut chars = js_code.chars().peekable();
    let mut in_string = false;
    let mut in_single_comment = false;
    let mut in_multi_comment = false;
    let mut string_char = '\0';

    while let Some(ch) = chars.next() {
        // 处理单行注释
        if !in_string &amp;&amp; !in_multi_comment &amp;&amp; ch == '/' &amp;&amp; chars.peek() == Some(&amp;'/') {
            in_single_comment = true;
            chars.next(); // 跳过第二个 /
            continue;
        }

        if in_single_comment {
            if ch == '\n' {
                in_single_comment = false;
            }
            continue;
        }

        // 处理多行注释
        if !in_string &amp;&amp; !in_single_comment &amp;&amp; ch == '/' &amp;&amp; chars.peek() == Some(&amp;'*') {
            in_multi_comment = true;
            chars.next(); // 跳过 *
            continue;
        }

        if in_multi_comment {
            if ch == '*' &amp;&amp; chars.peek() == Some(&amp;'/') {
                in_multi_comment = false;
                chars.next(); // 跳过 /
            }
            continue;
        }

        // 处理字符串
        if ch == '"' || ch == '\'' || ch == '`' {
            if !in_string {
                in_string = true;
                string_char = ch;
            } else if ch == string_char {
                // 检查是否被转义：计算前面的反斜杠数量
                let mut backslash_count = 0;
                let mut temp_result = result.clone();
                while temp_result.ends_with('\\') {
                    backslash_count += 1;
                    temp_result.pop();
                }
                // 偶数个反斜杠（包括0个）意味着引号没有被转义
                if backslash_count % 2 == 0 {
                    in_string = false;
                }
            }
            result.push(ch);
            continue;
        }

        if in_string {
            result.push(ch);
            continue;
        }

        // 压缩空白（保留必要的空格）
        // ...
    }

    result
}</code></pre><p>测试转义字符处理：</p><pre><code class="javascript">// 输入
let s = "test\\";  // 字符串中有转义的反斜杠
let s2 = 'quote\'';

// 输出
let s="test\\";   // 正确保留转义字符
let s2='quote\'';  // 正确保留转义字符</code></pre><h2>整合三层压缩</h2><p>将 HTML、CSS、JS 压缩整合在一起，在解析 HTML 时识别 <code>&lt;script&gt;</code> 和 <code>&lt;style&gt;</code> 标签：</p><pre><code class="rust">pub fn minify_html(content: &amp;str) -&gt; String {
    let mut in_script = false;
    let mut in_style = false;
    let mut script_content = String::new();
    let mut style_content = String::new();

    while let Some(ch) = chars.next() {
        // 标签处理
        if ch == '&lt;' {
            // ... 读取标签名

            if tag_name == "script" {
                in_script = true;
            } else if tag_name == "/script" {
                // 压缩并输出 script 内容
                if !script_content.trim().is_empty() {
                    let minified = minify_js(&amp;script_content);
                    result.push_str(&amp;minified);
                }
                script_content.clear();
                in_script = false;
            } else if tag_name == "style" {
                in_style = true;
            } else if tag_name == "/style" {
                // 压缩并输出 style 内容
                if !style_content.trim().is_empty() {
                    let minified = minify_css(&amp;style_content);
                    result.push_str(&amp;minified);
                }
                style_content.clear();
                in_style = false;
            }
        }

        // 收集 script/style 内容
        if !in_tag {
            if in_script {
                script_content.push(ch);
                continue;
            } else if in_style {
                style_content.push(ch);
                continue;
            }
        }
    }
}</code></pre><h2>压缩效果</h2><p>经过三层压缩，整体压缩率可达 <strong>40-55%</strong>：</p><table><thead><tr><th>层级</th><th>贡献率</th><th>示例</th></tr></thead><tbody><tr><td>CSS 优化</td><td>20-30%</td><td><code>margin-top: 0; margin-bottom: 0</code> → <code>margin:0 0</code></td></tr><tr><td>JS 压缩</td><td>15-25%</td><td>移除注释和空白</td></tr><tr><td>HTML 压缩</td><td>10-15%</td><td>移除换行和缩进</td></tr><tr><td>注释移除</td><td>5-10%</td><td>取决于注释密度</td></tr></tbody></table><p>完整示例：</p><pre><code class="html">&lt;!-- 输入：324 字节 --&gt;
&lt;!DOCTYPE html&gt;
&lt;html lang="zh-CN"&gt;
&lt;head&gt;
    &lt;meta charset="UTF-8"&gt;
    &lt;title&gt;{{ title }}&lt;/title&gt;
    &lt;!-- 这是注释 --&gt;
    &lt;style&gt;
        body {
            margin: 0;
            padding: 20px;
            background-color: #f0f0f0;
        }
    &lt;/style&gt;
&lt;/head&gt;
&lt;body&gt;
    &lt;h1&gt;{{ heading }}&lt;/h1&gt;
    {% for item in items %}
        &lt;p&gt;{{ item.name }}&lt;/p&gt;
    {% endfor %}
    &lt;script&gt;
        // 这是注释
        console.log("Hello");
    &lt;/script&gt;
&lt;/body&gt;
&lt;/html&gt;</code></pre><pre><code class="html">&lt;!-- 输出：152 字节，-53% --&gt;
&lt;!doctype html&gt;&lt;html lang=zh-CN&gt;&lt;meta charset=UTF-8&gt;&lt;title&gt;{{ title }}&lt;/title&gt;&lt;style&gt;body{background-color:#f0f0f0;margin:0;padding:20px}&lt;/style&gt;&lt;body&gt;&lt;h1&gt;{{ heading }}&lt;/h1&gt;{% for item in items %} &lt;p&gt;{{ item.name }}&lt;/p&gt;{% endfor %}&lt;script&gt;console.log("Hello");&lt;/script&gt;</code></pre><h2>其他技术细节</h2><h3>命令行参数设计</h3><p>使用 clap 库来处理命令行参数：</p><pre><code class="rust">use clap::Parser;

#[derive(Parser, Debug)]
#[command(name = "askama-minify")]
struct Args {
    /// 要压缩的文件或文件夹路径
    #[arg(value_name = "PATH")]
    path: PathBuf,

    /// 递归处理文件夹（默认启用）
    #[arg(short, long, default_value_t = true)]
    recursive: bool,

    /// 输出文件或文件夹路径
    #[arg(short = 'd', long)]
    output: Option&lt;PathBuf&gt;,

    /// 输出文件的后缀名（例如: "min" 会生成 .min.html）
    #[arg(short = 's', long)]
    suffix: Option&lt;String&gt;,
}</code></pre><h3>文件处理优化</h3><p>使用 walkdir 库实现高效的文件夹遍历：</p><pre><code class="rust">use walkdir::WalkDir;

let walker = if recursive {
    WalkDir::new(path)
} else {
    WalkDir::new(path).max_depth(1)
};

for entry in walker.into_iter().filter_map(|e| e.ok()) {
    let file_path = entry.path();
    if !file_path.is_file() || !is_template_file(file_path) {
        continue;
    }
    // 处理文件...
}</code></pre><h3>代码质量优化</h3><ol><li><p><strong>常量提取</strong>：避免魔法字符串</p><pre><code class="rust">const DEFAULT_SUFFIX: &amp;str = "min";
const MIN_MARKER: &amp;str = ".min.";
const VALID_EXTENSIONS: &amp;[&amp;str] = &amp;["html", "htm", "xml", "svg"];</code></pre></li><li><p><strong>避免不必要的字符串分配</strong>：使用 <code>eq_ignore_ascii_case</code> 而不是 <code>to_lowercase()</code></p><pre><code class="rust">// 优化后
ext_str.eq_ignore_ascii_case(valid_ext)

// 优化前（会创建新字符串）
ext_str.to_lowercase() == valid_ext</code></pre></li><li><p><strong>空文件快速处理</strong></p><pre><code class="rust">if original_size == 0 {
 fs::write(output_path, "")?;
 return Ok((0, 0));
}</code></pre></li></ol><h2>使用方式</h2><h3>安装</h3><pre><code class="bash"># 克隆仓库
git clone https://github.com/wsafight/askama-minify.git
cd askama-minify

# 编译
cargo build --release</code></pre><p>编译后的二进制文件位于 <code>target/release/askama-minify</code>。</p><h3>基本用法</h3><pre><code class="bash"># 压缩单个文件（默认生成 .min.html 后缀）
./target/release/askama-minify template.html

# 指定输出文件
./target/release/askama-minify -d output.html template.html

# 压缩整个文件夹
./target/release/askama-minify templates/

# 输出到指定目录并保持目录结构
./target/release/askama-minify -d dist/ templates/</code></pre><h3>命令行选项</h3><table><thead><tr><th>选项</th><th>简写</th><th>说明</th><th>默认值</th></tr></thead><tbody><tr><td><code>--output &lt;PATH&gt;</code></td><td><code>-d</code></td><td>输出文件或文件夹路径</td><td>原路径</td></tr><tr><td><code>--suffix &lt;SUFFIX&gt;</code></td><td><code>-s</code></td><td>输出文件后缀名</td><td><code>min</code></td></tr><tr><td><code>--recursive</code></td><td><code>-r</code></td><td>递归处理子文件夹</td><td><code>true</code></td></tr></tbody></table><h3>后缀规则</h3><table><thead><tr><th>配置</th><th>结果</th><th>示例</th></tr></thead><tbody><tr><td>无 <code>-d</code> 无 <code>-s</code></td><td>默认后缀 <code>min</code></td><td><code>file.html</code> → <code>file.min.html</code></td></tr><tr><td>无 <code>-d</code> 有 <code>-s</code></td><td>自定义后缀</td><td><code>file.html</code> + <code>-s prod</code> → <code>file.prod.html</code></td></tr><tr><td>有 <code>-d</code> 无 <code>-s</code></td><td>不添加后缀</td><td><code>file.html</code> + <code>-d out.html</code> → <code>out.html</code></td></tr><tr><td>有 <code>-d</code> 有 <code>-s</code></td><td>后缀 + 自定义路径</td><td><code>file.html</code> + <code>-d out/</code> + <code>-s prod</code> → <code>out/file.prod.html</code></td></tr></tbody></table><h3>集成到构建流程</h3><h4>方式一：在 <code>build.rs</code> 中使用</h4><pre><code class="rust">// build.rs
use std::process::Command;

fn main() {
    // 在生产构建时自动压缩模板
    if std::env::var("PROFILE").as_deref() == Ok("release") {
        let status = Command::new("./target/release/askama-minify")
            .args(["-d", "dist/templates/", "templates/"])
            .status()
            .expect("Failed to execute askama-minify");

        if !status.success() {
            panic!("Template minification failed");
        }
    }
}</code></pre><h4>方式二：在 Makefile 中使用</h4><pre><code class="makefile"># Makefile
.PHONY: build minify-templates

build: minify-templates
    cargo build --release

minify-templates:
    askama-minify -d dist/templates/ -s prod templates/</code></pre><h4>方式三：在 CI/CD 中使用</h4><pre><code class="yaml"># .github/workflows/deploy.yml
name: Deploy

on:
  push:
    branches: [ main ]

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Install Rust
        uses: actions-rs/toolchain@v1
        with:
          toolchain: stable
      - name: Build askama-minify
        run: |
          git clone https://github.com/wsafight/askama-minify.git
          cd askama-minify
          cargo build --release
      - name: Minify templates
        run: ./askama-minify/target/release/askama-minify -d dist/ -s prod templates/
      - name: Deploy
        run: # 你的部署脚本</code></pre><h3>在 Askama 中使用压缩后的模板</h3><p>有两种使用方式：</p><h4>方式一：切换模板路径（推荐）</h4><p>开发环境使用源模板，生产环境使用压缩模板：</p><pre><code class="rust">use askama::Template;

#[derive(Template)]
#[template(
    path = "{{ template_path }}",  // 通过配置传入
    whitespace = "suppress"
)]
struct HomePage {
    title: String,
}

// 根据环境变量选择模板路径
fn get_template_path(name: &amp;str) -&gt; String {
    if std::env::var("PROFILE").as_deref() == Ok("release") {
        format!("dist/{}.prod.html", name)  // 使用压缩版
    } else {
        format!("templates/{}.html", name)   // 使用源文件
    }
}</code></pre><h4>方式二：构建时替换</h4><pre><code class="bash"># 开发环境
cp templates/*.html templates/

# 生产构建时
askama-minify -d templates/ -s prod templates/</code></pre><h3>实际项目示例</h3><p>假设你有以下项目结构：</p><pre><code>my-app/
├── templates/
│   ├── base.html
│   ├── index.html
│   └── user/
│       ├── profile.html
│       └── settings.html
├── dist/              # 压缩后的输出目录
├── Cargo.toml
└── build.rs</code></pre><p><strong>开发时</strong>：直接使用 <code>templates/</code> 下的原始文件</p><p><strong>部署前</strong>：运行压缩命令</p><pre><code class="bash">askama-minify -d dist/ -s prod templates/</code></pre><p>输出：</p><pre><code>dist/
├── base.prod.html
├── index.prod.html
└── user/
    ├── profile.prod.html
    └── settings.prod.html</code></pre><p><strong>配置 Askama 使用生产模板</strong>：</p><pre><code class="toml"># askama.toml
[general]
dirs = ["dist"]  # 指向压缩后的目录</code></pre><h2>总结</h2><p>askama-minify 通过以下技术实现了高效的模板压缩：</p><ol><li><strong>模板语法保留</strong>：完整保留 <code>{{ }}</code> 和 <code>{% %}</code> 语法</li><li><strong>三层压缩策略</strong>：HTML 层、CSS 层、JS 层分别优化</li><li><strong>智能边缘处理</strong>：正确处理转义字符、运算符、正则表达式</li><li><strong>专业 CSS 优化</strong>：使用 lightningcss 进行属性合并和颜色优化</li><li><strong>Rust 实现</strong>：高性能、内存安全</li></ol><h3>与 Askama 自带压缩的对比</h3><table><thead><tr><th>特性</th><th>Askama whitespace</th><th>askama-minify</th></tr></thead><tbody><tr><td>空白压缩</td><td>✅</td><td>✅</td></tr><tr><td>HTML 注释移除</td><td>❌</td><td>✅</td></tr><tr><td>CSS 压缩优化</td><td>❌</td><td>✅</td></tr><tr><td>JavaScript 压缩</td><td>❌</td><td>✅</td></tr><tr><td>模板语法保留</td><td>✅</td><td>✅</td></tr><tr><td>构建时处理</td><td>❌</td><td>✅</td></tr></tbody></table><p>项目已开源：<a href="https://link.segmentfault.com/?enc=V%2B%2FunjIG5LtErYha1qJ%2Fog%3D%3D.05aEIjF%2BPpN4ZnzPSdUP%2BMAGh5yN8iF7OHqOw5evvLCQFmvF2BXsXu0NHofAIx0F" rel="nofollow" target="_blank">https://github.com/wsafight/askama-minify</a></p><p>欢迎大家提出 issue 和 pr。</p><h2>参考资料</h2><ul><li><a href="https://link.segmentfault.com/?enc=MDAHaMBSg4txcPEGyrSeeg%3D%3D.hKvPtx7u1pq3wx3cS2yMwJ8LQnGaU3HFcKN1KsFazoxjsJkSxPw7DgXAeYmma9Ux" rel="nofollow" target="_blank">lightningcss</a> - 出色的 CSS 解析和优化工具</li><li><a href="https://link.segmentfault.com/?enc=ykJp1xjdFX3kioS2FHmjjQ%3D%3D.K5G46D3e3AbuTq8RdN5l6N8Qj7SynVxliJZix%2FbiWVw%3D" rel="nofollow" target="_blank">clap</a> - 强大的命令行参数解析库</li><li><a href="https://link.segmentfault.com/?enc=A3I7zuZOLrzMeb4W6%2BU2%2FA%3D%3D.GJsZ%2FjmrwtfQLFIH4rP0a3%2BkbxH%2BIwivXw1FHAFq9Nk%3D" rel="nofollow" target="_blank">Askama</a> - 灵活的 Rust 模板引擎</li></ul>]]></description></item><item>    <title><![CDATA[让 AI 工作空间更智能：Amazon Quick Suite 集成博查搜索实践 亚马逊云开发者 ]]></title>    <link>https://segmentfault.com/a/1190000047498808</link>    <guid>https://segmentfault.com/a/1190000047498808</guid>    <pubDate>2025-12-23 23:01:58</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2><strong>引言</strong>  <strong>（企业</strong> <strong>AI</strong> <strong>助手的</strong> <strong>“</strong> <strong>信息孤岛</strong> <strong>“</strong> <strong>挑战）</strong></h2><p>在数字化转型的浪潮中，企业对智能化工作空间的需求日益迫切。Amazon Quick Suite 作为亚马逊云科技推出的新一代 agentic AI 驱动的数字工作空间，正在重新定义企业用户与数据、知识的交互方式。它不仅提供强大的商业智能分析能力，更通过 AI 助手将洞察转化为行动，让每个员工都能拥有一个智能化的工作伙伴。</p><p>然而，AI 助手的能力边界很大程度上取决于其获取信息的能力。企业用户在日常工作中面临多样化的信息检索需求：产品经理需要追踪实时市场动态和行业新闻，研发团队需要查询技术文档和学术论文，管理层需要获取经过智能排序的高质量决策参考。如何让 Quick Suite 的 AI 助手具备这种多场景、高质量的信息检索能力，是提升用户体验的关键。</p><p>本文将介绍如何借助<a href="https://link.segmentfault.com/?enc=lFFjW0Vag2L0C%2BqsDy8w0g%3D%3D.dPep8YXL4iFZKbtNsYq%2FGlfiPU0IgdEK9hRKJTXerVM%3D" rel="nofollow" target="_blank">博查搜索</a>的能力，让用户可以在 <a href="https://link.segmentfault.com/?enc=HW5XxU1%2FpzD%2BqFY5X1lvQQ%3D%3D.zYZgIK1FpmRzbSwIcGXKzxVST0L6yLmlhkSfXPxUcBzOeYw8t1vHCYSoKYqN3KwZVl33o4Bq8MGXBmvJPRoRaCMYy7tMuqZuk%2FjhfeuMS70%3D" rel="nofollow" target="_blank">Amazon Quick Suite</a> 的统一 Chat Agent 界面中获得实时网络搜索能力，同时保持企业级的安全性和可扩展性。</p><blockquote>📢限时插播：无需管理基础设施，利用亚马逊技术与生态，快速集成与部署生成式AI模型能力。<br/>✨ 精心设计，旨在引导您深入探索Amazon Bedrock的模型选择与调用、模型自动化评估以及安全围栏(Guardrail)等重要功能。<br/>⏩快快点击进入《<a href="https://link.segmentfault.com/?enc=8mcTiBg7TbAJlgl2ddZDoQ%3D%3D.kdXlJJyHZhY6ODp1MI9K6mwxvzvZlL8cH9JBeB5N8HdLCOqoxy1Fe4qQDtmUPBIbazH99Nn2H7vVp7VFRhxwt9uymxB7rzY8pzLf3RvhvCaMII1n15VMJPaRlopdIqqtFZrbse%2BO6h1KP6mDbppOh6OcgUEQgztOFHi8WaAKI%2FN1KJJzJ6VtOi%2FqW6U8qqBWOijknZjKJvrq0TaLPF1tTlxBU%2Fh0tE1Q%2FuHzGdBC21A%3D" rel="nofollow" target="_blank">多模一站通 —— Amazon Bedrock 上的基础模型初体验</a>》实验构建无限, 探索启程！</blockquote><h2><a href="https://link.segmentfault.com/?enc=IzNxIZH%2FfxJahI2uRawIPA%3D%3D.Zlgl8vR8x6IJZGE3ofgxnXTcaToOUV2XUFbX8YW9aqbwMoP7dccar0af0lCKN7Kr" rel="nofollow" target="_blank"><strong>Amazon Quick Suite</strong></a> <strong>：</strong> <strong>Agentic AI</strong> <strong>驱动的数字工作空间</strong></h2><p>Amazon Quick Suite 是一个由Agentic AI 驱动的数字工作空间，为企业用户提供一组代理式团队成员，他们可以快速回答工作中的问题并将答案转化为操作。</p><p>Amazon Quick Suite 是一个全面的、由生成式 AI 驱动的商业智能平台，可轻松分析数据、创建可视化、自动化工作流程并在整个组织内进行协作。该服务将传统商业智能功能与现代 AI 助手相结合，无需机器学习专业知识即可使用。您可以连接到多样化的数据源、创建交互式仪表板、构建智能自动化，并通过与 AI 代理的自然语言对话获得即时洞察。</p><p>Quick Suite 包含五项集成功能，协同运作：Amazon Quick Sight 用于数据可视化，Amazon Quick Flows 用于工作流自动化，Amazon Quick Automate 用于流程优化，Amazon Quick Index 用于数据发现，以及 Amazon Quick Research 用于综合分析。该平台超越了传统商业智能的范畴，通过浏览器、Slack 和 Microsoft Office 应用程序的扩展，将 AI 助手直接集成到您现有的工具中。</p><h2><strong>博查搜索：为企业</strong> <strong>AI</strong> <strong>打造的智能搜索引擎</strong></h2><h3><strong>公司概况</strong></h3><p>博查搜索（Bocha）是一家专注于<strong>世界知识搜索引擎与语义排序技术</strong>的技术公司，面向 AI 应用提供高质量、高覆盖、低时延的联网检索服务。公司目前服务超过 30,000+ 泛企业用户，接入 100,000+ AI 应用，在金融、政务、教育、企业、车机等各个行业均有落地。</p><h3><strong>核心产品</strong></h3><p>博查搜索提供三大核心产品：</p><p><strong>（</strong> <strong>1</strong> <strong>）</strong> <strong>Web Search API</strong> <strong>（主力产品）</strong></p><ul><li>多模态混合搜索（网页+新闻+百科+视频+机酒）</li><li>IndexNow 秒级收录网页</li><li>Summary 长文返回，支持指定时间、指定域</li><li>支持 API、MCP、SDK 多种调用方式</li><li>接入 Coze、Dify、火山引擎等工作流</li></ul><p><strong>（</strong> <strong>2</strong> <strong>）</strong> <strong>Semantic Reranker</strong> <strong>（语义排序引擎）</strong></p><ul><li>自研深度语义理解模型，优化检索结果前 N 条的相关性</li><li>模型友好、高相关性、适合智能体场景</li></ul><p><strong>（</strong> <strong>3</strong> <strong>）</strong> <strong>BochaDB</strong> <strong>（企业级知识索引）</strong></p><ul><li>支持企业内部知识库统一索引</li><li>提供结构化搜索、内容审查、访问控制</li><li>支持本地部署/私有云方案</li></ul><h3><strong>技术优势</strong></h3><p><img width="545" height="275" referrerpolicy="no-referrer" src="/img/bVdnsKX" alt="image.png" title="image.png"/></p><h3><strong>典型应用场景</strong></h3><p>博查搜索主要服务以下客户类型：</p><ul><li><strong>AI</strong> <strong>产品方</strong>：模型公司、智能体产品、App/插件应用</li><li><strong>政务平台</strong>：城市大脑、政务问答、政府网站智能搜索</li><li><strong>大型企业</strong>：银行、保险、医药、互联网公司</li><li><strong>研发团队</strong>：高校研究机构、开发者社区</li></ul><p>典型解决方案包括：模型联网问答（RAG）检索、智能客服与智能问答底座、多源信息聚合与企业搜索、行业知识库与垂直搜索能力。</p><h2><strong>解决方案：通过</strong> <strong>AgentCore Gateway</strong> <strong>集成博查搜索</strong></h2><p>我们的解决方案采用模块化架构，通过 Amazon Bedrock AgentCore Gateway 作为统一的工具服务器，将博查搜索服务集成到 Amazon Quick Suite 中。架构如下图所示：</p><p><img width="652" height="1108" referrerpolicy="no-referrer" src="/img/bVdnsKY" alt="image.png" title="image.png" loading="lazy"/></p><h3><strong>架构亮点</strong></h3><ol><li><strong>统一认证</strong>：使用 Amazon Cognito Service-to-Service 认证，Quick Suite 只需配置一次</li><li><strong>模块化设计</strong>：每个服务/工具独立部署为 Amazon Lambda 函数，互不影响</li><li><strong>灵活扩展</strong>：通过 AgentCore Gateway Targets 机制，可以轻松添加新的服务/工具</li><li><strong>安全管理</strong>：所有 API Keys 通过 Lambda 环境变量管理，不暴露在代码中</li></ol><h2><strong>实施指南</strong></h2><h3><strong>前置条件</strong></h3><p>在开始之前，请确保您具备以下条件：</p><ul><li>亚马逊云科技账户，具有创建 IAM 角色和策略的权限</li><li>Amazon Quick Suite 访问权限（Author Pro 订阅）</li><li>博查的 API Keys</li><li>本地开发环境：</li><li>Amazon CLI 已配置（aws configure）</li><li>Python 3.9 或更高版本</li><li>jq（JSON 处理工具）</li></ul><h3><strong>实施步骤</strong></h3><h4><strong>第一步：准备开发环境</strong></h4><p>首先，克隆项目代码并设置 Python 虚拟环境：</p><pre><code class="Bash"># 克隆项目git clone https://github.com/xina0311/amazon-quick-suite-web-search-integration.git
cd amazon-quick-suite-web-search-integration

# 创建并激活 Python 虚拟环境
python3 -m venv venv
source venv/bin/activate

# 安装 Python 依赖
pip install -r requirements.txt

# 验证安装
python3 -c "import boto3, requests; print('✓ 依赖安装成功')"</code></pre><h4><strong>第二步：部署基础设施</strong></h4><p>运行自动化脚本部署 Amazon Cognito 和 AgentCore Gateway：</p><pre><code class="Bash">./deploy_infrastructure.sh us-east-1</code></pre><p>这个脚本将自动完成以下任务：</p><ol><li>创建 Cognito User Pool 和 App Client（用于 Service-to-Service 认证）</li><li>创建 Amazon Bedrock AgentCore Gateway</li><li>配置 Cognito JWT 认证</li><li>生成配置文件 txt</li></ol><p>部署完成后，记录以下信息（保存在 config.txt 中）：</p><ul><li>Gateway URL</li><li>Client ID</li><li>Client Secret</li><li>Token URL</li></ul><h4><strong>第三步：部署博查搜索服务</strong></h4><pre><code class="Bash">cd providers/bocha

# 设置 API Keyexport BOCHA_API_KEY="your-bocha-api-key"# 部署 Lambda 函数
./deploy.sh

# 测试 Lambda 功能
./test_lambda.sh</code></pre><p>测试成功后，您将看到类似以下的搜索结果：</p><pre><code>✓ 测试 1 通过

响应预览:
------------------------------------------------------------
# 博查 Web Search 结果

共找到 3 个结果

## 1. 亚马逊CEO解读Bedrock新功能AgentCore...
**链接:** https://...
**摘要:** Amazon Bedrock AgentCore推出新功能...
------------------------------------------------------------</code></pre><p>将博查添加到 Gateway：</p><pre><code class="Bash">python3 add_target.py
./test_target.sh</code></pre><p><strong>第四步：在</strong> <strong>Amazon Quick Suite</strong> <strong>中配置</strong> <strong>MCP Integration</strong></p><ol><li>登录 Amazon Quick Suite 控制台</li><li>导航到 <strong>Integrations</strong> → <strong>Actions</strong> → <strong>Model Context Protocol</strong></li><li>点击 “+” 创建新的 Integration</li></ol><p>填写以下信息：</p><p><strong>Name</strong>:</p><pre><code>AI Web Search</code></pre><p><strong>Description</strong>:</p><pre><code>This integration provides three specialized AI-powered web search tools for different information retrieval needs.

Tool is BochaWebSearchTarget___bocha_web_search. This tool specializes in real-time web content search. It excels at finding breaking news, latest articles, current events and up-to-date information from the internet. Best choice when you need the most recent news stories or want to know what is happening right now on any topic.

Guidelines for tool selection - Use BochaWebSearchTarget when users ask about news, current events or recent happenings. Use MetasoWebSearchTarget when users need research papers, academic content, technical docs or specific media types. Use CloudswayWebSearchTarget when users want intelligent search with relevance ranking or need time-filtered results.</code></pre><p><strong>MCP Server Endpoint</strong>: 从 config.txt 复制 GATEWAY_URL</p><p><strong>Authentication Type</strong>: 选择 “Service authentication”</p><p><strong>Client ID</strong>: 从 config.txt 复制</p><p><strong>Client Secret</strong>: 从 config.txt 复制</p><p><strong>Token URL</strong>: 从 config.txt 复制</p><ol start="4"><li>点击 <strong>Save</strong> 保存配置</li><li>等待 1-2 分钟，状态变为 “Available”</li><li>查看 <strong>Available Actions</strong>，确认看到搜索工具</li></ol><h4><strong>第五步：实际使用示例</strong></h4><p>配置完成后，您可以在 Amazon Quick Suite 的 Chat Agent 中使用博查搜索。</p><ol><li>为chat agent添加博查搜索工具</li></ol><p><img width="723" height="466" referrerpolicy="no-referrer" src="/img/bVdnsKZ" alt="image.png" title="image.png" loading="lazy"/></p><ol start="2"><li>Chat Agent 将调用博查搜索工具，返回最新的新闻和文章。</li></ol><p>查找关于 Amazon Bedrock AgentCore 的最新信息</p><p><img width="723" height="716" referrerpolicy="no-referrer" src="/img/bVdnsK0" alt="image.png" title="image.png" loading="lazy"/></p><p>从 Response events 中可以看到，Chat Agent 识别用户需求后，自动调用了博查搜索 API（BochaWebSearchTarget），从 AI_Web_Search 获取最新信息，并基于搜索结果生成回答。</p><h2><strong>总结</strong></h2><p>本文展示了如何利用 Amazon Bedrock AgentCore Gateway 和 Model Context Protocol (MCP) 将专业的智能搜索能力集成到 Amazon Quick Suite 中，为企业 AI 工作空间提供强大的信息检索能力。博查搜索提供的多模态混合搜索、秒级内容收录和语义排序能力，为 Quick Suite 的 AI 助手提供了高质量、低时延的信息检索支持。</p><p>通过这一技术集成方案，我们实现了：</p><ul><li><strong>统一的用户体验</strong>：用户无需在多个工具间切换，在 Quick Suite 的 Chat Agent 中即可完成所有搜索需求</li><li><strong>企业级的安全管理</strong>：通过 Amazon Cognito Service-to-Service 认证和环境变量管理 API Keys，确保访问控制和密钥安全</li><li><strong>灵活的架构设计</strong>：模块化的 Lambda 函数和 Gateway Targets 机制，让您可以轻松添加更多搜索服务或其他第三方工具</li><li><strong>开箱即用的部署</strong>：提供完整的自动化脚本和详细文档，大幅降低集成门槛</li></ul><p>Amazon Quick Suite 通过开放的 MCP 协议，为企业构建了一个可扩展的 AI 工作空间平台。您可以使用相同的技术架构集成更多专业服务，真正打造符合企业需求的智能化数字工作空间。</p><p><em>*前述特定亚马逊云科技生成式人工智能相关的服务目前在亚马逊云科技海外区域可用。亚马逊云科技中国区域相关云服务由西云数据和光环新网运营，具体信息以中国区域官网为准。</em></p><p><strong>本篇作者</strong><br/><img width="723" height="558" referrerpolicy="no-referrer" src="/img/bVdnsK1" alt="image.png" title="image.png" loading="lazy"/></p><blockquote>本期最新实验《<a href="https://link.segmentfault.com/?enc=Ez0ncF%2B4u3%2FaOBkGVcGiWg%3D%3D.VsmN7zVVazgO7nOW2WRTAa39F6czTYhY3k9bN0XNSnug7hDzuG5xl4cytEAGa83xCgK1Qu0PNjJFghByeDzWzILcBykp7nsWt313Bxbx68oqrmWjn7hsoyHq2nutuYq8xXUjuz4bufgrZ0iu3k5eWLJ3KADtsOefe9E89u%2FlWqz2ajG6St%2Bk7vQCr%2BYsw7i3lfNdZGH1lWMM55FCR3Rz6Y1wBIQEK53iug%2BqgCZt6Xk%3D" rel="nofollow" target="_blank">多模一站通 —— Amazon Bedrock 上的基础模型初体验</a>》<br/>✨ 精心设计，旨在引导您深入探索Amazon Bedrock的模型选择与调用、模型自动化评估以及安全围栏(Guardrail)等重要功能。无需管理基础设施，利用亚马逊技术与生态，快速集成与部署生成式AI模型能力。<br/>⏩️<a href="https://link.segmentfault.com/?enc=pUgDnej3jpm6fOOWZ1c3wA%3D%3D.ckUmRoiyUdrSr0IS0V5oUFc9PAeoh10umvpZNUP34veOTW6%2F9rvtmjcqju0zSgsTNnztvAa4ZJgYC403IdDptIdy08OTZpva1MD7zAAK9cLmtD3WhKQguR2lOw%2FqDha4njo%2BjDDSfJDJGHQOP7Iws5xBnp5KSp8D3vacxJKvC8PoFAhR5pICVABeQfEQEEoXV%2Fx7SiwC3eZ557fXUXLI3oOcetSUzAj1wcskLJNACqc%3D" rel="nofollow" target="_blank">[点击进入实验</a>] 即刻开启  AI 开发之旅<br/>构建无限, 探索启程！</blockquote>]]></description></item><item>    <title><![CDATA[谷歌发布Gemma Scope 2，钉钉推出AI操作系统与硬件，苹果初代智能眼镜细节曝光，火山引擎成]]></title>    <link>https://segmentfault.com/a/1190000047498824</link>    <guid>https://segmentfault.com/a/1190000047498824</guid>    <pubDate>2025-12-23 23:01:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>今日AI领域主要涵盖：谷歌发布模型可解释性工具Gemma Scope 2、钉钉推出AI操作系统与硬件、苹果初代智能眼镜细节曝光、AI在游戏行业的广泛应用、火山引擎成为2026春晚独家合作伙伴，以及MiniMax开源模型的突破等多个方面。</p><h3>1. 谷歌DeepMind发布Gemma Scope 2</h3><p>谷歌DeepMind推出了Gemma Scope 2，这是一个开放的可解释性工具套件，旨在深入分析Gemma 3语言模型从2.7亿到270亿参数的各层次信息处理。该工具帮助AI安全与对齐团队追踪模型内部特征，以应对"越狱"、幻觉或不当行为等问题。</p><p><strong>技术细节</strong>：Gemma Scope 2提供了对Gemma 3模型内部运作的深入洞察，允许研究人员和开发者追踪模型的决策路径，识别并修正潜在的偏见或错误行为。同时，亚马逊SageMaker已部署Mistral AI的Voxtral模型，为开发者提供了更多多模态AI模型选择。</p><p><strong>行业影响</strong>：对于AI从业者来说，Gemma Scope 2这类可解释性工具的推出意义重大。随着AI模型在各行各业的应用越来越广泛，模型的透明度和可控性变得尤为重要。特别是对于在企业环境中部署AI模型的团队，这类工具可以帮助他们更好地理解和调试模型行为，提升系统的安全性和可靠性。而Voxtral模型在SageMaker上的部署，则显示了云服务商在AI模型生态建设方面的竞争愈发激烈。</p><p><strong>商业意义</strong>：谷歌通过提供Gemma Scope 2这样的开源工具，正在加强其在AI安全和可解释性领域的领导地位。对开发者来说，这意味着更多高质量的AI工具选择。</p><p><strong>实用建议</strong>：如果你在企业中负责AI模型的部署和维护，值得关注Gemma Scope 2的相关资源，这可能对你的模型调试和优化工作有所帮助。同时，如果你在使用AWS的AI服务，现在可以考虑尝试Voxtral模型，特别是在需要多模态处理能力的场景中。</p><h3>2. 钉钉发布全球首个AI工作智能操作系统Agent OS和企业级AI硬件DingTalk Real</h3><ul><li>全球首个AI工作智能操作系统Agent OS发布，开启"人与AI协同"新工作方式。该系统在AI钉钉1.1新品发布暨生态大会上亮相，命名为"木兰"，是继1.0版本"蕨"后的重要升级，展现了钉钉在企业级AI生态中的创新布局。企业级AI操作系统的概念非常有趣。如果成功，这可能意味着企业软件架构的一个重要转变——从传统的功能模块化应用到更加智能、灵活的AI代理模式。对开发者来说，这意味着新的API和集成方式需要学习和适应。</li><li>企业级AI硬件DingTalk Real发布，集成实体、数据与实时三大核心能力，通过软硬一体重塑办公体验。该硬件采用内网部署，具备强大数据处理能力，可深度读取企业内部私有数据。企业级AI硬件的推出是AI应用的一个新趋势，与传统的云端AI服务相比，企业级硬件能够更好地处理敏感数据，满足数据安全和隐私保护的需求，这可能预示着AI服务的部署模式将更加多样化。</li></ul><h3>3. 苹果初代智能眼镜细节曝光，将成iPhone最强AI配件</h3><p>苹果计划于2026年底发布、2027年发货的"Apple Glasses"被CEO库克列为最高战略优先级，旨在打造超越Meta的行业标杆产品。</p><p><strong>技术细节</strong>：苹果智能眼镜被列为CEO库克的最高战略优先级，计划于2026年底发布、2027年发货，目标是打造超越Meta的行业标杆产品。</p><p><strong>行业影响</strong>：苹果进入智能眼镜市场将对整个AR/VR行业产生重大影响。凭借其在硬件设计、生态系统整合和用户体验方面的优势，Apple Glasses可能会重新定义智能眼镜的形态和功能。</p><p><strong>商业意义</strong>：对开发者来说，这意味着一个新的平台即将到来。如果Apple Glasses真的如传言中那样成为iPhone的"最强AI配件"，那么相关的应用开发和AI算法优化将成为新的机会领域。</p><h3>4. Steam近八成游戏染指AI，争议声中大作纷纷"沦陷"</h3><p>生成式AI在游戏行业应用广泛，Steam平台已有超1万款游戏使用该技术，占比约8%，且数量持续增长。这些游戏总收入达6.6亿美元，有力反驳了"只有劣质游戏才用AI"的偏见。</p><p><strong>技术细节</strong>：Steam平台上已有超过1万款游戏使用生成式AI技术，占比约8%，总收入达6.6亿美元，显示了AI在游戏行业中应用的广度和商业价值。</p><p><strong>行业影响</strong>：这组数据有力地反驳了"只有劣质游戏才用AI"的观点。AI在游戏开发中的应用已经相当成熟，从内容生成到NPC行为、程序化关卡设计等，都有显著的应用价值。</p><p><strong>实用建议</strong>：如果你是游戏开发者，AI工具的应用可能是一个提升开发效率和创新能力的有效途径。但需要注意的是，如何平衡AI辅助与原创性、玩家体验之间的关系，仍然是一个需要仔细考虑的问题。</p><h3>5. MiniMax Agent平台上线开源编码和代理模型MiniMax M2.1</h3><p>MiniMax M2.1正式发布，这是一款专为真实编码和AI组织设计的先进开源模型。它拥有100亿激活量，在SWE-multilingual测试中得分72.5%，在VIBE-bench测试中高达88.6%，性能超越Gemini 3 Pro和Claude 4.5 Sonnet等闭源模型，标志着代理时代的重要进展。</p><p><strong>技术细节</strong>：MiniMax M2.1拥有100亿激活量，在SWE-multilingual测试中得分72.5%，在VIBE-bench测试中高达88.6%，性能超越了Gemini 3 Pro和Claude 4.5 Sonnet等知名闭源模型。</p><p><strong>行业影响</strong>：这一成就对开源AI生态具有重要意义。M2.1在编码任务上的优异表现，为开发者提供了一个强大的开源替代方案，可能会影响编码辅助工具市场的格局。</p><p><strong>实用建议</strong>：如果你是开发者，特别是对AI编码辅助工具有需求的，值得尝试MiniMax M2.1。开源的特性意味着你可以根据自己的需求进行定制和优化。</p><h3>6. 从红包大战到AI对决：火山引擎成为2026春晚独家合作伙伴</h3><p>字节跳动旗下火山引擎成为2026年央视春晚独家AI云合作伙伴，其智能助手"豆包"将深度参与互动。春晚作为国民级IP，是互联网产品实现爆发式增长的关键战场，字节跳动此举意在复制微信支付等通过春晚实现突破的成功模式。</p><p><strong>技术细节</strong>：火山引擎将成为2026年央视春晚的独家AI云合作伙伴，其智能助手"豆包"将深度参与春晚互动环节。</p><p><strong>行业影响</strong>：这一合作展示了AI技术在大型公共活动中的应用潜力。通过春晚这一平台，AI技术将触达数亿观众，这可能会加速AI技术的普及和接受度。</p><p><strong>商业意义</strong>：对字节跳动来说，这是一个巨大的市场推广机会。通过春晚平台，豆包等AI产品可以获得前所未有的曝光度，有助于其在AI助手市场的竞争。</p><h3>7. 面壁智能获数亿元新融资，深度布局智能座舱与终端生态</h3><p>面壁智能完成数亿元融资，投资方包括京国瑞、国科投资等。资金将重点投入端侧高效大模型的研发，以巩固其在终端智能市场的技术优势。作为国内端侧AI领域的先行者，公司已构建从理论到全场景产品的完整体系。</p><p><strong>技术细节</strong>：面壁智能专注于端侧高效大模型的研发，已完成数亿元融资，将用于进一步巩固其在终端智能市场的技术优势。</p><p><strong>行业影响</strong>：端侧AI是AI应用的另一个重要方向。与云端AI相比，端侧AI在隐私保护、响应速度和离线使用等方面具有优势。面壁智能的融资显示了市场对端侧AI前景的看好。</p><p><strong>商业意义</strong>：智能座舱是端侧AI的一个重要应用场景。随着汽车智能化的发展，端侧大模型在车载系统中的应用将越来越重要。</p><hr/><p>今天这些AI动态对你的工作有什么启发？觉得有价值的话，别忘了点赞收藏哦。</p><p>📌 <strong>关注我，第一时间掌握更多AI前沿资讯！</strong></p>]]></description></item><item>    <title><![CDATA[叶不凡修仙记 0001 科学修仙 麻花疼 ]]></title>    <link>https://segmentfault.com/a/1190000047498701</link>    <guid>https://segmentfault.com/a/1190000047498701</guid>    <pubDate>2025-12-23 22:04:07</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>广场排队</h2><p><strong>常山宗</strong>的<strong>收徒大典</strong>，仍旧设在了群山环抱间的一处开阔广场上。<br/>抬眼望去，是如潮水般涌动的人头，浩浩荡荡，无边无际。<br/><strong>叶不凡</strong>此时就挤在一条密密匝匝的漫漫长龙里，随着人流的节奏，像一叶扁舟，在暗涌中缓慢向前挪移。<br/>周遭尽是青春洋溢、意气风发的少男少女。那一张张稚嫩的面孔上，或写着忐忑，或满载希冀，蓬勃的朝气在阳光下闪耀，那是独属于凡人对长生之路的狂热向往。<br/>“哎呦……不行了，头疼欲裂，这感觉……就像是要长脑子了！”<br/>突然间，一阵强烈到近乎撕裂的眩晕感袭来，使<strong>叶不凡</strong>猛地晃了晃身子。<br/>“想什么呢？别发愣了！后面都堵上了，快往前走！”<br/>身后传来一声不耐烦的催促，伴随着一股蛮力，推得<strong>叶不凡</strong>一个踉跄。<br/>“噢……噢，对不起，这就走。”<strong>叶不凡</strong>下意识地回首作揖，道了个歉，声音里还带着一丝大病初愈般的沙哑。<br/><strong>叶不凡</strong>好不容易回了神，眼前熟悉的场景竟一下子变得陌生了起来。<br/>他一边木讷地向前挪步，一边疯狂地揉搓着太阳穴，满脸怀疑人生，嘴里念念有词：“奇怪……我怎么变成了十六岁的少年？不对，我原本不就是这个岁数吗？可又不对啊……哎哟，这脑子里怎么跟走马灯似的，串台了？”<br/><strong>叶不凡</strong>一边顺着队伍往前蹭，一边梳理着脑海中的两份记忆：一份属于这具十六岁的青涩身体，另一份来自异世界的一位横跨九百载春秋的渡劫期老怪。<br/>这种感觉诡谲到了极点——<br/>​仿佛命运这个顽皮的神灵，突然对他的世界按下了暂停键，在即刻的静止中，粗暴地往他脑子里塞进了另一段波澜壮阔的人生，随后又轻飘飘地按下了播放键。<br/>​上一秒，他似乎还在天雷翻滚下，大呼我命休矣；下一秒，却已脚踩实地，在这广场上，为了一个入宗的名额苦苦排队。<br/><strong>叶不凡</strong>看着自己那双还没磨出老茧的手，嘴角抽搐。就好像脑子里住进了个“老怪物”，有一种“满级大佬被迫重练新手村”的错位感。<br/>“嘿，嘀嘀咕咕啥呢？魂儿飞了？”<strong>叶不凡</strong>的右肩膀结结实实挨了后面一巴掌。<br/>在这一拍之下，立刻就令<strong>叶不凡</strong>失神的双目重新对焦到了眼前的现实里。<br/><strong>叶不凡</strong>猛地一回头，张口就是一句：“请问……这里是天玄界吗？”<br/>这一下子把后面的小胖子问得一愣，像看傻子一样打量着他：“什么天玄界、地玄界的？这里是常山宗收徒大会！哥们儿，你是排队排中暑了吗？”<br/>“常山宗……常山……”<strong>叶不凡</strong>低头，自言自语道，“也就是说，老夫又转回天玄界了吗？”<br/>小胖子一下子就忍不住噗嗤笑出声来：“排傻了吧，老弟？听这口气，合着您是刚穿越回来呢？”<br/>“哎呀！关于‘我是大佬’这件事，竟被你看出来了！”<strong>叶不凡</strong>猛地一击掌，满脸写着‘终于找到知音了’的兴奋，压低声音却掩不住惊叫道，“不装了，我摊牌了！其实……老夫乃是活了九百多岁的渡劫期大能，刚才正在隔壁片场飞升呢！”<br/>此话一出，周遭死寂了三秒，随后爆发出足以掀翻广场地砖的哄笑声，大家被逗得前仰后合。<br/>排在前面的女孩笑得直打鸣，回头戏谑道：“我看你不是穿越，而是刚睡醒吧？哪个渡劫老怪像你这样？你是懂反差萌的！”<br/><strong>叶不凡</strong>微微一怔，随即用力一拍脑门：“对啊！也不能排除这个可能，万一刚才那九百多年真的是场梦呢？”<br/>“哈哈哈！”排在小胖子后面的一个圆脸姑娘也乐了，“小哥你太逗了。被你这一搅和，我这紧张得要命的心情居然全没了。你这‘发疯疗法’挺管用啊！”<br/>前面的女孩也是个爱凑热闹的，干脆转过身来，倒着步子走，一脸八卦地问道：“那么请问这位前辈，你倒是说说，你那个世界是怎么修炼的”<br/><strong>叶不凡</strong>一脸严肃，开启了科普模式：“那边啊，体系倒也差不多。修炼境界也是九层：<kbd>炼气</kbd>、<kbd>筑基</kbd>、<kbd>结丹</kbd>、<kbd>凝婴</kbd>、<kbd>化神</kbd>、<kbd>出窍</kbd>、<kbd>返虚</kbd>、<kbd>合体</kbd>、<kbd>渡劫</kbd>。说来也怪，除了语言有点出入，长相竟跟咱们这儿的人差不多。”<br/>女孩儿听得一愣一愣的，摸着下巴琢磨：“你这逻辑挺自洽啊。但按你这么说，你这也不是穿越，而是时空穿梭吧？你那边是过去还是未来？”<br/>“看着像是未来，各种高科技。”<strong>叶不凡</strong>叹了口气，目光深邃。<br/>“那你过来前在干嘛？总不能是正在吃饭被噎过来的吧？”<br/>“说了你们可能不信。”<strong>叶不凡</strong>摊开手，“我活了九百多岁，刚才正值渡劫飞升的关键时刻。我记得漫天都是彩色雷霆，我连续扛了几下，突然眼前一黑，然后我就感觉被人推了一把。”<br/>“这就有点意思了。”女孩儿眼珠一转，开始疯狂发散思维，“没准那根本不是穿越，也不是做梦。古话说‘世界就是一个循环’，没准那是你的前世呢？你在前世修到了巅峰，这辈子带着记忆重新轮回了！这在学术上叫觉醒前世宿慧，小哥你这是要起飞啊！”<br/>这番话像是打开了某种神奇的开关，周围排队的少男少女们全都加入了这场旷世大讨论。<br/>“我觉得不对！”小胖子兴奋地插嘴，“依我看，咱们这儿才是上界，他在那边修成正果了，所以才‘飞升’到咱们这儿来当凡人，这叫返璞归真！”<br/>“胡说，这分明就是心魔劫？”圆脸姑娘开脑洞道，“没准你现在还在雷云下面蹲着呢，现在的这一切——包括我们常山宗，全是你脑子里产生的幻象！”<br/>“我见多了，这更有可能是被夺舍了！只是夺舍失败，记忆还没融合好，信号干扰了！”<br/>“听我的，我是专家，这分明是梦中梦，你其实一直没有醒来……”<br/>“我才最有经验，这应该是某种‘缸中之脑’的邪术，咱们其实都活在某种阵法里……”<br/>“我是老实人从不说谎，我觉得整个世界都是某位大佬笔下的一本小说，小哥你只是开启了主角光环……”<br/>众人你一言我一语，各种离奇的版本层出不穷，简直就是“精神病人思路广，智障少年欢乐多”。<br/>一时间，原本庄严肃穆的收徒大会，在<strong>叶不凡</strong>这支小分队里，硬生生变成了一场跨次元学术研讨会。<br/><strong>叶不凡</strong>听着这些天马行空的假说，竟有点被绕晕了，只能苦笑着摇摇头。他看着自己那双稚嫩的手掌，心里也在犯嘀咕：这到底是黄粱一梦，还是轮回重来？<br/>不过很快，<strong>叶不凡</strong>就完成了自我开导，那种原本压在心头的沉重感，在这一刻竟化作了一种前所未有的轻盈。<br/>“唉，管它呢！是梦也好，是前世也罢，对我来说，这真相还重要吗？”<br/>“哈哈，说得对！”<strong>叶不凡</strong>猛地握了握拳，感受着指缝间流动的、属于十六岁少年的朝气，嘴角又露出了灿烂的笑容，眼中闪过一抹掩不住的飞扬神采：“但无论真相是穿越还是轮回，对我而言又有什么实质上的区别吗？”他再次感受了一下掌心那份属于十六岁少年的温热与力量，放声大笑，“脑子里白捡了两份记忆，这就好比还没进考场呢，有人直接把卷子的答案塞我手里了。这不是赤裸裸的作弊嘛！”<br/>身后的小胖子见他一会儿深沉似老朽，一会儿亢奋如孩童，忍不住又拍了拍他的肩膀，老气横秋地宽慰道：“行了，哥们儿，别想那些有的没的了，过好当下才是真的！哪怕你真是一尊仙人随口编出来的一段戏文，又或者是某位大能闭关时臆想出来的一段影像，这一辈子也是你自己实打实在过的。只要那个‘老怪’没在这儿给你留下一座金山银山，你就得面对现实——这常山宗的台阶，还得靠你这一双肉脚一级一级往上爬。”<br/><strong>叶不凡</strong>微微一怔，随即深深一叹：“面对现实吗……so this内～”<br/>小胖子疑惑：“你怎么说日本话？”<br/><strong>叶不凡</strong>一愣：“你怎么知道这是日本话？哦不，没说日本话，谁说日本话啦？我说，说的是呢！”<br/><strong>叶不凡</strong>深吸一口气，心中泛起阵阵涟漪：人，终究是由记忆决定的。当两股截然不同的岁月河流在同一个灵魂里汇合，便再也没有了主次之分。那一世的移山填海是他，这一世的寒窗苦等也是他。两世为人，在此一跃！<br/>他在心中默默感叹：天地乾坤、宇宙时空，确实神奇！只是，在那漫长的九百载光阴里深爱过的人、执着过的恨，以及那些无法挽回的错，终究是随着那场飞升的雷劫彻底散去了，只能留给那个名为“过去”的废墟。回忆再美好那也只是曾经！<br/>“可这是为什么呢？又为什么是我呢？”他还是忍不住在心底深处反复寻思，这种违背天道常理的交错，究竟是某种跨越时空的垂青，还是另一场更大阴谋的开端，“上天给了我这份馈赠，可代价又是什么呢？”<br/>“这是馅饼还是陷阱？有没有神仙来给我剧透一下？”<br/>然而，这个问题注定得不到答案，因为现实的喧嚣已经冲散了哲学的沉思。<br/>“嘿！到你了！发什么愣？”后面的小胖子轻轻推了他一把，将他彻底从那份跨越时空的恍惚中拽了回来。<br/><strong>叶不凡</strong>一个踉跄向前迈出几步，抬眼望去，原来终于排到他了。<br/><strong>叶不凡</strong>稳住身形，这一刻，所有的胡思乱想都烟消云散。他拍了拍衣襟上的尘土，挺直了腰板，迈步上前，嘴角勾起一抹玩世不恭却又极度自信的弧度，朗声开口：<br/>“小生<strong>叶不凡</strong>，年方一十六，家住常山脚下……”<br/>“磨蹭什么呢？没问你是谁，给我赶紧测！”执事弟子眉头紧皱，手中的玉笔不耐烦地敲了敲木案。<br/><strong>叶不凡</strong>耸了耸肩，也不废话，径直就将手掌大大方方地按在了面前那颗剔透的感应球上。<br/>随着掌心触碰，测试球内泛起一阵细碎的涟漪，随即缓慢地亮起了五种颜色。赤、青、黄、白、黑五色灵光交织在一起，显得浑浊而不透亮，像是一团没搅匀的颜料。<br/>执事弟子斜眼扫了一下，露出一脸公式化的冷漠：“五灵根，属性混杂，资质‘杂劣’，去丁等区域待命。”<br/>说罢，就在一块木牌上写下一个“丁”字，他像打发苍蝇似的，随手甩给<strong>叶不凡</strong>。<br/>“不是，哥们儿，你先等会儿！”<strong>叶不凡</strong>捏着那块木牌，眼睛瞪得溜圆，整个人都斯巴达了，“啥叫‘杂劣’啊？怎么着，这灵根到了你们这儿，还分三六九等，有高低贵贱的吗？”<br/>这话声音不小，惹得周围排队的少年们纷纷侧目，一个个憋着笑，看向<strong>叶不凡</strong>的眼神里充满了看乡巴佬的怜悯。在他们看来，这小子要么是打击太大疯了，要么就是个对修仙一窍不通的白痴。<br/><strong>叶不凡</strong>此时心里却像是炸开了锅。在他的那份“老怪记忆”里，灵根只看有没有，哪分优和劣。五行相生相克，只有不会用的人，哪有没用的灵根？<br/>“嘿，你这人可真有意思……”执事弟子终于抬起头，眼神冰冷，“不想入门就回家！下一个！”<br/><strong>叶不凡</strong>张了张嘴，看着那弟子已经开始招呼下一个人，半晌才憋出一口气。他把木牌在手里掂了掂，无奈地转身走开，嘴角勾起一抹冷笑：“真是‘老奶奶钻被窝——给爷整笑了’！”<br/><strong>叶不凡</strong>拎着那块沉甸甸的“丁等”木牌，在众人同情或鄙夷目光中，慢悠悠地晃荡出了测试场。​他一边往那所谓的“丁等区域”走，一边小声嘀咕，心态调整地极快：“算了，既来之则安之，回去是不可能回去的！不就是进“差生班”吗？我就没打算低调，看我降维打击，好好纠正你们这种跨维度的认知偏差！”</p><h2>修仙理由</h2><p>说实话，他之所以死皮赖脸非要进这常山宗，半点“光宗耀祖”的宏愿都没有，纯粹是因为他在家待得快要长霉了。别人修仙，可能是为了梦想，但<strong>叶不凡</strong>修仙，只是为了休闲。因为太闲，所以修仙！<br/>他爹在山下坊市买了个院子，所以他就住在山下的坊市里，离这儿也就几里地。今儿一早，他溜溜达达走过来，连半个时辰都没用上，甚至还没等额头冒汗，就已经站在了收徒大会的现场。<br/>大哥叶不平两年前拜入宗门，离开了家；老爹叶梁材整日钻进灵石堆里忙生意，不常着家；老娘沐晚晴常年在外游山玩水，很少回家。<br/>剩下<strong>叶不凡</strong>一个人守着大院子，日子过得那叫一个“自由”。想吃就吃，想睡就睡，没人管，没人问。可自由这玩意儿，一旦过了头，就成了寂寞的毒药。有些人孤独但不寂寞，但<strong>叶不凡</strong>却因为孤独而陷入了精神内耗。<br/>小时候一起撒尿和泥的小伙伴，如今有的在铺子里学徒，有的在田地间挥汗，有的在宗门内奋斗，仿佛一夜之间，全世界都在奋力奔跑，唯独他<strong>叶不凡</strong>，被困在了一个名为“松弛感”的荒原里。他看着窗外忙碌的人流，只能苦叹一句：“唉，都忙，忙点儿好啊。”<br/>不规律的饮食，紊乱的作息，在经年日久之下，竟让这个十六岁的少年硬是活出了一副八十岁老头子的颓废。那种“人生不过如此”的虚无感，像强酸一样侵蚀着他。他知道自己不能再这么颓废下去了，正巧听说常山宗开山收徒，他跟家里的帮佣随口知会了一声，拍拍屁股就跑来参加海选了。<br/>不为长生，纯粹是想出门找点儿新鲜感，给这枯燥的日子换个背景板。</p><h2>异世界往事</h2><p>此时，他脑海中那份“老怪”的记忆，正像一套精密的扫描仪，审视着另一份关于这个天玄界的记忆。<br/>按此身的记忆，这个叫天玄界的世界广袤无垠，人族以外还有百族林立，人族只占据了世界的一小块。但以异世界的观点看来，这里简直原始得让人发指——没有星际殖民，没有赛博城市，人类竟连自己脚下这颗行星都没能完全占领。这里没有科学的逻辑，只有传统而笨拙的修炼体系。<br/>他心里门儿清，之所以这个世界推崇“单灵根”，贬低“五灵根”，说白了就是穷闹的，这是由于古代“小农经济”极低的容错率决定的。<br/>从社会经济学的角度来讲，他们负担不起培养全才的代价，只追求以最小的经济投入换取最快的修炼进度，所以他们必须“掐尖儿”培养。毕竟，五灵根意味着每升一级都要把五种属性全部练到达标，消耗五倍的资源，这种高昂的“教育成本”，是古代低下的生产力所不能承受的。饭都吃不饱，你让他们修仙？<br/>在这个大多数人还在为温饱挣扎的时代，修仙是极少数人的特权。只是如果修仙成了奢侈品，那可就把太多人给耽误了，就会有太多的人轻飘飘的过完了这一生，这真是“不能承受的生命之轻”。<br/>在那个异世界，那可是“人人有功练”的盛世，大家甚至因为修炼太累，或者觉得修炼没用，反而把吃喝玩乐当成了主业。都什么年代了，你还在修仙？<br/>如果你没有灵根，那你就是光荣的弱势群体，甚至可以躺着吃“低保”！<br/>更讽刺的是，在那个科技极度发达的世界里，修仙早就已经被科学祛魅，被视为一种古老的杂技。那一身惊天动地的修为，上限也才堪堪够到科技的下限。<br/>从科学的角度来讲，宇宙是由“膜”包裹的独立时空，宇宙间存在着名为“界膜”的壁垒，“修炼”其实就是通过摄取外部“灵能”提升自身“灵体浓度”的过程。<br/>当一个灵体提升到所在宇宙“浓度阈值”时，会先处于一种“平衡态”，此时只要自己稍微“扰动”一下，将自己的灵体浓度向上“跃升”一点，就会打破平衡，形成指向另一个宇宙的灵压，这种“渗透压”会将其强制“排挤”到另一个允许更高灵体浓度的宇宙。这个过程通过穿越界膜来实现，俗称“破界飞升”，学名是“界膜渗透”。在此过程中，你向上扰动的幅度越大，渗透压就越大，你飞升就越快越容易。虽然灵体可以（以暂时沟通高维的方式）自由选择要前往的高浓度宇宙，但一旦前往就不能回来了。飞升，竟是一张单程机票！<br/>在撕裂界膜的过程中，会激发出一种超高能的复杂磁场，灵体高速穿过界膜时会在该磁场中激发感应电流，就是俗称的“天雷”，学名是“kappa电暴”。破界飞升存在一定的危险性，如果灵体的绝缘性能和抗电强度这两个指标综合起来没能支撑住这股电暴，或者运气不好撞上了界膜的不稳定褶皱，结果就是被狂暴的能量瞬间撕裂，变成宇宙间的基本粒子尘埃。<br/>飞升只能实现把灵体从一个较低浓度的宇宙搬运到较高浓度的等维同构宇宙。等维的意思是，两个宇宙展开的维度是相等的，例如一个宇宙总共有4维但全展开，另一个宇宙是9维但只展开4维，它俩就是等维的。同构的意思是，两个宇宙有相同的物理规律，仅物理常数的取值是不同的。<br/>飞升就好比妊娠圆满后必须分娩一样，你只是换了个允许灵体能继续成长的环境，并没有从本质上进化成更高维的生命。但和妊娠不同的地方在于，理论上讲飞升可以进行无数次。<br/>所以，飞升并不代表进化，它只是被迫的迁徙。所谓上界，也并无新意。<br/>从宇宙宏观的视角来看，这种“搬家”最多不过是蝼蚁挪窝，除了带走微量的物质，对浩瀚星海几乎毫无影响。<br/>更讽刺的是，在异世界看来，“高浓度宇宙”并不代表“高科技宇宙”。<br/>虽然修士们会追求更高的灵能浓度，在他们看来灵体有继续提升的空间可能很重要，但科学家们却发现，低浓度宇宙的科技上限并不会弱于高浓度宇宙。异世界的科技文明已能够通过制造特殊设备有限度地沟通高维或异构宇宙，而那些修士最多也就像是皮球一样在等维同构宇宙间被弹来弹去。</p><p>按照异世界的知识，文明水平大概能划出5个大的等级：</p><ul><li>1级（<strong>行星文明</strong>）：&lt;u&gt;占领整颗行星&lt;/u&gt;。能够完全利用母星及其卫星的全部能源，随心所欲地操控全球气候。</li><li>2级（<strong>恒星文明</strong>）：&lt;u&gt;占领整个恒星系&lt;/u&gt;。建造巨大的戴森球，将恒星每一秒爆发的能量剥削殆尽。</li><li>3级（<strong>星系文明</strong>）：&lt;u&gt;充分散布于所在星系&lt;/u&gt;。整个星系在他们面前只是一张四通八达的高速路网，恒星系间的旅行如同跨过街道。</li><li>4级（<strong>宇宙文明</strong>）：&lt;u&gt;充分散布于所在宇宙&lt;/u&gt;。掌控星系团，甚至能抽取宇宙本身的真空零点能（量子场涨落）。异世界正处于这个层级的顶峰，在那个宇宙，他们已是无所不能的神。</li><li>5级（<strong>多宇宙文明</strong>）：&lt;u&gt;跨越多个宇宙&lt;/u&gt;。这是科学家们近乎疯狂的设想，即彻底打破界膜的阻隔，自由穿梭于不同的宇宙之间，操控多元宇宙的法则，甚至在不同物理定律的异构宇宙中重建秩序。</li></ul><p><strong>叶不凡</strong>心中哂笑：天玄界的文明程度满打满算还不到0.5，而异世界已经无限逼近5级。<br/>异世界的科学家们已经能像从深井里打水一样，以可控的手段从其他宇宙抽取基本物质。可即便强悍如斯，他们依然无法实现将复杂的生物体进行“逆浓度”转移。说明这个世界，还是有太多的未解之谜，科技发展真的永无止境，或许只有科学家或数学家才是真正的修仙者！<br/>最让<strong>叶不凡</strong>感到违和的，其实是两个世界的社会结构的断层。异世界文明之所以伟大，不在于它灵气多浓，而在于它的社会结构。<br/>这个天玄界还停留在皇权不下乡、宗门如草头的蒙昧时代；而异世界，早已没有了所谓的凡俗皇朝与宗门教派。取而代之的，是严密的联邦政府、繁荣的企业组织，以及无处不在的学校与研究所。<br/>在那里，修炼是“义务教育”的一部分，被称为“灵能工程”。从小学、中学到大学，系统性的灵能训练伴随着每一个人的成长。但要求并不高，只要能做到最基础的“引气入体”，你就能拿到这门课程的及格分，修炼课其实就等于是那个世界的体育课。<br/>如果你实在是那万中无一的、无法感知灵气的“绝缘体”，在那边也不能叫“废物”，那是受联邦法律保护的“非灵体人士”，属于特殊的弱势残障群体。你不仅能领取丰厚的免费福利，还能穿着联邦派发的智能功能服，利用微型反应炉提供的能量，像修士一样飞天遁地。法律明文规定，严禁任何修士对这类人群进行歧视或攻击，即使是最狂妄的修士也不敢在这类话题上开玩笑，占领道德高地的人们能在舆论层面将其瞬间虐得生活不能自理。<br/>甚至更让人意外的是，在异世界修为越高反而越受歧视。除非是得到豁免的学术或教育界人士，普通人把修为提升得太高会被视为本宇宙的负资产。<br/>异世界存在一个古老的教训：修士，本质上是宇宙的寄生虫；修炼，本质上是对宇宙的掠夺。<br/>在旁人眼中，这世界灵气充盈，常山宗更是仙家福地，但这种繁荣之下却掩盖着一个足以令文明窒息的阴影，因为异世界的历史经验已明确表明：如果不发展科技，只研究修仙，最终会陷入末法时代，这对于任何一个种群来说，都是一条通往毁灭的绝路。<br/>史书上就明确记载着那个被称为“太古”的黑暗纪元。<br/>那时候的人类文明与当下的天玄界如出一辙，所有人拥挤在一颗星球上，人人都在狂热地追逐修炼。可悲剧的是，他们最终亲手开启了名为“末法”的审判。<br/>修士对于他们所生存的世界，主要有2大危害：</p><ol><li>灵能的“熵增”：修士从环境中汲取灵能，将其纳入自身。而被修士运用过的灵能，其有序度会大幅下降，造成灵能的“熵增”。就像被焚烬后的木柴无法再度燃烧一样，被修士“排泄”回自然的灵能会变得沉寂、混乱，导致其更难被再度利用，最终导致整个宇宙步入彻底的“灵寂”。而修为越高的修士，对灵能的消耗也越多，所能造成的恶果也越大。</li><li>物质的“流失”：每一次成功的飞升，其实都是修士从这个宇宙中抢走了一份物质。失败者尚能将残躯化作养分还给天地，可成功者，则是带着千锤百炼的灵体永远退出了本宇宙的自然循环。这种物质的单向流失，还会在引力层面削弱宇宙的稳定性，加速宇宙的膨胀。 空间越大，灵能就摊得越薄，直到所有人几乎感应不到一丝灵力。</li></ol><p>在太古时代的末期，那种绝望感笼罩了每一个人。<br/>由于灵能枯竭，迎来了末法时代，人们的灵根退化、平均寿命锐减、作物大面积绝收。为了争夺残存的一丁点生机，曾经仙风道骨的修士们蜕变成了最狰狞的野兽。治安崩坏、生机断绝、种群面临生存危机——那是文明彻底塌陷的前兆。<br/>修士的自我追求与文明的宏观存亡竟然成了对立关系！<br/>正是基于这份血淋淋的教训，异世界的联邦政府建立了一套极其严苛的规则。<br/>在那里，修为越高，非但没有特权，反而会面临阶梯式的惩罚性措施。<br/>如果你想追求极高的个体修为，你就必须缴纳天价的“环境补偿税”；如果你想要破界飞升，那更是被视为对母宇宙的“背叛”，需要通过复杂的配额置换。<br/>那里的人们明白，修炼只是为了提升个体素质的手段，而科学才是保证种群永续的盾牌。</p><hr/><p>在那场席卷了太古的名为“末法时代”的浩劫中，人类曾陷入了一段极度漫长且黑暗的“权力死锁”。<br/>随着灵能日渐稀薄，修士们自觉飞升无望，便更加追求俗世的权力。虽然修士的个体战力的上限在不断跌落，但他们对底层压榨的下限却在不断突破。统治者们为了攥紧最后一点资源，构建了愈发极端的高压体系。<br/>虽然这总是激起且无法阻挡人们的反抗，可是在一次次的改朝换代之后，新来的统治者却将绳索勒得越来越紧。<br/>人们悲哀地发现，修士建立的依靠修为维系的封建等级体系被反复推翻和重建，却陷入越来越专制的漩涡。<br/>那种绝望的死循环，就像是一个不断收紧的绞刑架，扼杀了文明的所有变数。<br/>然而，奇迹往往诞生于被遗弃的角落。<br/>在那颗母星上，有一处名为“荒芜之地”的贫瘠区域。那里曾爆发了一场近乎灭绝的瘟疫，导致政权崩塌、满目疮痍。贫困潦倒导致榨出油水极少，民风剽悍导致维稳成本极高，每一个自信满满而来的宗门皇朝，过不了多久只能败兴而归，他们谁也无法长期忍受一个总是亏本的统治区域。<br/>在无政府的野蛮生长中，人们靠着求生的本能开启了缓慢的自愈。他们经历了多次复辟的闹剧、启蒙的火种、以及大革命的雷霆，反复拉锯，蹒跚前进。<br/>这群被旧时代抛弃的人，却吹响了新时代的号角。<br/>既然无法求助于缥缈的灵根，便被迫审视于自然的规律。科学，就此在这片被诅咒的土地上破土而出。<br/>于是，第一台蒸汽机启动了，第一条微积分公式诞生了……科学就像一股无声的洪流，迅速渗透进社会、经济与政治的每一个毛孔。<br/>他们建立了一套极其高效、冷酷且基于数学与规律的认知新秩序。<br/>他们建立了一套完全不依赖个体武力、而是依赖集体协作与契约的社会体系。<br/>最终，科学体系像一把手术刀，精准地切开了封建专制的毒瘤。<br/>当第一批掌握了工业化武装的凡人军队，用震耳欲聋的动能武器将那些还在念咒的旧修士轰成血雾时，一个时代崩塌了。<br/>科学不仅摧毁了旧的身体，更彻底推翻了旧的阶级、瓦解了旧的观念。<br/>那是科学第一次确立其不可动摇的霸权地位，第一次将个人伟力关入牢笼。<br/>可是当人类驾驶着原始的飞船闯入深空时，竟惊愕地发现：所谓的末法时代，竟然只是他们在那颗母星上过度采伐导致的局部枯竭。浩瀚的宇宙中，无数星球依然处于繁荣的修仙文明之中，生机勃勃、欣欣向荣。<br/>可是这时候，人类文明已经是科学当道，价值观已经发生了不可逆转的质变，任何逆历史潮流试图为修仙招魂的势力，都被掌握权力的普罗大众给强力按了下去。<br/>即便末法时代只是虚惊一场，但那段惨痛的记忆已经刻进了文明的基因。联邦政府意识到，若任由修炼泛滥，整个宇宙迟早会变成另一个巨大的末法荒漠，到时候人类又能往哪跑呢？<br/>于是，人类文明开启了长达数百万年的“灭修战争”，凡是倾向于维持修仙专制的文明，统统予以灭绝。<br/>在漫长的星际战争中，科学文明不仅主宰了宇宙，最终还确立了科学绝对主导的宇宙意识形态。<br/>修炼，曾以“反文明罪”，一度被写进了联邦刑法。<br/>直到科学遭遇了难以突破的瓶颈。<br/>一些科学家通过理论推算，得知修炼或许是一条出路。在经过了漫长的辩论后，联邦政府终于允许，科学家可以在层层审批、严格控制的条件下修炼。<br/>后来在大量突破性成果的洗刷下，特别是成功实现灵能逆熵——以一种跨时代的科技从虚空或外位面补回所耗散的灵能熵值，联邦政府才重新放开了修炼限制。<br/>因为此时，科学文明已经强大到足以无视任何个体的崛起。修炼，从一种禁忌、一种特权，最终演变成了一种受控的公共资源。<br/>随后又在无数艺术作品的浪漫渲染下，社会竟一度再掀修仙热潮。<br/>修炼，从古代巩固专制的镰刀，变成了人人喊打的邪教，最后终于演变成了一种全民普及的、用于辅助科学研究的个人素质拓展课。<br/>可是制造灵能逆熵的产能毕竟有限，联邦很快又颁布了修正法，按修为等级对修士进行阶梯级课税。<br/>“修仙不难，难的是怎么应付那群拿着算盘和税法的审计官。”<br/>“你想修仙？可以。”<strong>叶不凡</strong>在心里模拟着联邦审计官的口吻，“要么，你就为你的灵能熵增行为缴纳高昂的‘宇宙环境税’。要么，你就在研究所挂职，用你的修为辅助高维物理建模。”<br/>修士，竟从高高在上的封建领主，变成了实验室里的精密仪器。想要修为可以提升，要么交更多的税，要么在科研上为联邦做出对等的贡献，修士竟成了被盘剥的对象！</p><hr/><h2>天玄界的发展危机</h2><p>现在的天玄界，宗门间还在拼命内卷，争夺那些越来越稀薄的资源，却并没有人意识到，在没有科学的干预下，他们每多诞生一个修士，就是在这个宇宙的棺材板上多钉了一颗钉子。<br/>在这里，人们视飞升为荣耀，视灵气为天赐。他们并不知道，每多一个天才飞升，天玄界的寿命就减少一分；每多一次激烈的斗法，末法时代的丧钟就多响一声。<br/>“这帮家伙，正坐在漏水的船上举行狂欢派对。”<br/>在常山宗这些少男少女眼中，修炼是唯一的出路；但在<strong>叶不凡</strong>看来，如果没有科学的介入，这种单维度的个体进化最终只会演变成一场文明的集体殉葬。<br/>如果将修仙比作一场“慢性的自杀”，那么<strong>叶不凡</strong>或许就是那个清醒的“守墓人”。<br/>“可是现在的我又能做什么呢？”<strong>叶不凡</strong>扪心自问，“或许，问题的答案正是我穿越到此的理由。”<br/>午后的阳光下，常山宗的层峦叠嶂在云海间若隐若现，紫气如游龙般穿梭于万仞崖壁之间。<br/><strong>叶不凡</strong>孑然立于喧嚣的广场边缘，他没有像旁人那般对着仙山顶礼膜拜，而是负手而立，眼神平静得像是一面映照万物的镜子。<br/>此时周围的喧嚣在他耳边渐渐褪去，化作了一片虚无的白噪音。<br/>他静静地站在原地，清瘦的身影投射在古老的青石地面上，显得孤傲而冷静。此时的他，就像是一位在荒废了千年的大殿前抵足徘徊的少年，试图用科学来叩开古老的大门。<br/>“用科学来指导修仙吗？”<br/><strong>叶不凡</strong>轻声呢喃，指尖下意识地摩挲着木牌。这种感觉极其奇妙，仿佛他正握着一枚足以撬动星辰的杠杆，而支点就是他那看似杂劣、实则蕴含着完美潜力的五灵根。<br/>他再次抬起头，环视了周围满脸希冀的熙攘人群，又举目望向了远处云雾缭绕的飘渺仙山。<br/>灵气在山峦间幻化成氤氲的紫色长龙。若是换作旁人，此刻定会沉醉于这种近乎神迹的庄严，感受到自身的渺小与卑微。<br/>可<strong>叶不凡</strong>那双十六岁的明亮眼眸里，倒映出的不是虚幻的祥瑞，而是无数跳动的数据与坍塌的概率云。<br/>在他眼中，那高耸入云的仙门不再是不可逾越的鸿沟，而是一堆由古老物理参数交织而成的密码锁。那些被土著修士视为“天意”的玄学，在他脑海中正被拆解成一条条优雅、冰冷、却又无坚不摧的逻辑公式。<br/>在那一刻，所有的沧桑与青涩在他脸上达成了一种诡异而迷人的平衡。他嘴角微微上扬，勾起一抹带着些许狂傲、又极度从容的弧度，像是跨越了数个文明纪元的低语：<br/>“修仙，易如反掌！”</p>]]></description></item><item>    <title><![CDATA[打造个人数字大脑：访答知识库深度指南 文档伴侣 ]]></title>    <link>https://segmentfault.com/a/1190000047498715</link>    <guid>https://segmentfault.com/a/1190000047498715</guid>    <pubDate>2025-12-23 22:03:22</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>打造个人数字大脑：访答知识库深度指南</h2><p>在信息爆炸的时代，如何高效管理个人知识资产成为现代人面临的共同挑战。本地私有知识库作为解决方案应运而生，而知识库正是其中的佼佼者，为您提供安全、高效的知识管理体验。</p><h3>什么是本地私有知识库</h3><p>本地私有知识库是指将个人或组织的知识资料存储在本地设备上，而非云端服务器。这种模式最大的优势在于数据完全由用户掌控，无需担心隐私泄露风险。与传统的云存储知识库相比，本地解决方案在数据安全性和访问速度上具有明显优势。</p><h3>访答知识库的核心优势</h3><p>访答知识库作为专业的本地知识管理工具，具备三大核心优势：</p><h4>极致的数据安全保障</h4><p>所有数据存储在个人设备中，完全避免云端数据泄露风险。即使在没有网络的环境下，您仍然可以随时访问和管理自己的知识库。</p><h4>高效的知识整理体系</h4><p>访答提供智能分类、标签管理和全文检索功能，让您能够快速找到所需信息。其独特的关联功能还能帮助您发现知识点之间的内在联系。</p><h4>灵活的扩展能力</h4><p>支持多种文件格式导入，无论是文档、图片还是笔记，都能在访答知识库中得到统一管理。自定义标签和分类体系让您能够按照自己的思维习惯组织知识。</p><h3>如何有效使用访答知识库</h3><h4>建立个人知识体系</h4><p>首先明确知识分类标准，建议按照项目、领域或用途进行划分。访答的灵活架构支持您随时调整分类体系，适应知识结构的变化。</p><h4>养成定期整理习惯</h4><p>知识管理贵在坚持。建议每周固定时间整理新获取的知识，及时归档到访答知识库中，保持知识库的时效性和完整性。</p><h4>充分利用检索功能</h4><p>访答强大的搜索功能是提升效率的关键。通过关键词、标签组合检索，能够快速定位到特定内容，大大节省查找时间。</p><h3>访答在知识管理中的独特价值</h3><p>相比其他知识管理工具，更加注重个人使用的便捷性和隐私保护。其简洁的界面设计和强大的功能组合，使得知识管理变得轻松而高效。无论是学术研究、工作项目还是个人学习，访答都能成为您可靠的数字大脑。</p><p>在数字化时代，拥有一个属于自己的知识管理系统已不再是奢侈品，而是必需品。选择访答知识库，就是选择了一种更安全、更高效的知识管理方式，让您的每一份知识积累都能发挥最大价值。</p><p><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdnsKo" alt="" title=""/></p>]]></description></item><item>    <title><![CDATA[《从操作轨迹到认知图谱：玩家专属游戏知识体系图谱的搭建路径》 程序员阿伟 ]]></title>    <link>https://segmentfault.com/a/1190000047498758</link>    <guid>https://segmentfault.com/a/1190000047498758</guid>    <pubDate>2025-12-23 22:02:22</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>游戏玩家的每一次场景交互、每一轮角色抉择、每一套策略推演，这些散落在不同游戏品类、不同体验维度中的隐性数据，绝非孤立的操作痕迹，自动生成专属游戏知识图谱，本质上是通过语义化转译与动态关联技术，将这些碎片化的行为轨迹，编织成一幅能精准映射玩家偏好倾向、能力边界与体验路径的数字化镜像。它突破了传统游戏数据统计仅停留在胜率、时长等表层指标的局限，深入行为背后的动机逻辑与习惯惯性，让每一位玩家都拥有一份独一无二的“游戏认知资产”。这种图谱并非静态的信息陈列，而是随着玩家游戏历程持续生长、自我迭代的智能生态—从单机游戏的剧情选择到联机对战的战术配合，从休闲游戏的节奏偏好到硬核游戏的操作精度，每一份新的行为数据都会成为图谱的养分，既承载着玩家的游戏记忆，更成为驱动个性化体验的核心引擎，让游戏从“千人一面”的标准化产品，转变为“千人千面”的专属互动场域，让每一次登录都成为与自我游戏认知的深度对话。</p><p>构建玩家专属知识图谱的首要前提，是实现无感知的行为数据萃取，这需要跳出传统埋点采集的固化思维，转向更具深度的“微行为语义锚定”技术。游戏中的每一次交互都蕴含着丰富的隐性信息：技能释放的时序间隔背后可能是玩家的反应速度与决策逻辑，地图探索的路径偏好能折射出冒险倾向或效率追求，角色互动的频率倾向暗藏社交需求，策略调整的触发条件反映抗压能力，甚至是失败后的重试选择也能暴露毅力特质。采集过程中，需通过动态感知模块实时捕捉玩家在不同游戏场景下的行为特征，同时借助“行为熵减提纯”算法，精准过滤掉误操作、网络波动导致的偶然选择等噪声数据，保留具有稳定性与代表性的核心行为轨迹。例如，玩家在多款RPG游戏中持续选择辅助类角色，并非简单记录角色名称，而是提取“团队协作倾向”“资源分配偏好”“风险规避特质”等深层语义标签；在策略游戏中反复使用的战术组合，也需拆解为“资源囤积策略”“快速突袭范式”“阵地防御逻辑”等可关联的核心要素。这种采集方式既不会打断玩家的沉浸体验，又能精准捕捉行为背后的真实偏好—无论是MMO中频繁参与公会活动的社交型玩家，还是回合制游戏中反复打磨装备的细节型玩家，其核心行为都会被精准转译，为图谱构建奠定高质量的数据基础。</p><p>图谱的核心架构设计，关键在于搭建“动态关联引擎”，实现跨游戏、跨场景的数据语义互联。传统的信息图谱多依赖固定的关联规则，难以适配玩家行为的多样性与动态性，而玩家专属知识图谱的关联逻辑必须具备自我进化能力。首先需建立三级节点体系：基础层为游戏本体节点，涵盖游戏类型、核心玩法、角色属性、地图设计、任务机制等静态信息；中间层为行为语义节点，包含偏好标签、策略类型、能力维度、决策倾向、风险偏好等动态数据；顶层为关联规则节点，负责定义不同节点间的映射关系与权重调整逻辑。通过“偏好迁移映射”技术，当玩家接触新游戏时，图谱会自动匹配已有偏好节点与新游戏的核心要素，生成个性化的关联路径。例如，擅长某款MOBA游戏中“侧翼牵制”策略的玩家，在接触射击游戏时，图谱会自动关联“绕后突袭”“视野控制”“精准打击”等相似策略节点，形成跨品类的策略关联链路；而偏爱开放世界游戏中“隐藏任务探索”的玩家，在体验解谜游戏时，图谱会激活“细节观察”“逻辑推理”等关联能力节点。同时，关联引擎需具备实时迭代能力，根据玩家新的行为数据动态调整节点权重与关联强度—若玩家近期从偏好PVE转向PVP，图谱会迅速强化与竞技相关的节点关联，弱化副本探索类节点的权重，让图谱始终与玩家的游戏状态保持同步，避免因数据滞后导致的图谱失真。</p><p>角色偏好的深度解构，是图谱个性化的核心支撑，需要突破“角色名称罗列”的表层呈现，进入“角色人格契合度”的深层挖掘。每一位玩家选择角色的背后，都隐含着与角色特质的情感共鸣或能力适配—有的玩家被角色的背景故事吸引，有的则看重技能机制与自身操作习惯的匹配度。通过“特质语义聚类”技术，可将不同游戏中的角色按核心特质进行跨品类分类：如“激进型输出角色”“稳健型控制角色”“隐忍型爆发角色”“团队核心型辅助角色”“探索型自由角色”等，打破游戏品类的界限，建立统一的角色偏好维度。在数据处理过程中，不仅要记录玩家选择角色的频率，更要分析选择场景的关联性：在何种对战模式下倾向于某类角色，在何种团队配置中会切换角色类型，在何种难度等级下会调整选择逻辑，这些场景化的选择细节能更精准地勾勒玩家的角色偏好画像。同时，结合角色使用的熟练度数据，如技能命中率、连招完成度、角色达成的成就、策略执行的成功率等，可在图谱中形成“角色偏好-能力匹配”的关联链路—例如，玩家频繁选择“治疗型辅助角色”但治疗量低于同水平玩家，图谱会标注“偏好治疗角色但操作熟练度不足”的关联信息；若玩家擅长“刺客型爆发角色”且在高难度对战中胜率极高，则会强化“激进型策略-高操作能力”的关联节点，让图谱不仅能反映“喜欢什么”，更能呈现“擅长什么”，为后续的个性化推荐与能力提升提供精准依据。</p><p>策略掌握的图谱化呈现，需要实现“策略行为的语义具象化”，将玩家的操作序列转化为可关联、可解析的策略节点。游戏中的策略并非抽象的概念，而是由一系列具体操作、决策逻辑与场景适配构成的行为组合，不同玩家即便是使用同一套战术，其操作细节与决策节奏也会存在显著差异。通过“策略指纹提取”技术，可从玩家的实战操作中，提炼出具有辨识度的策略核心：如在竞技游戏中，玩家习惯“前期资源囤积+后期集中爆发”的策略，其操作序列会呈现出特定的资源采集节奏、技能分配比例与战场移动轨迹，这些特征会被转化为独特的“策略指纹”，并与图谱中的策略节点建立精准关联。同时，借助“跨品类策略迁移分析”，可发现玩家在不同类型游戏中的策略共性：如擅长策略游戏中“分兵牵制”的玩家，在MOBA游戏中可能倾向于“边路带线牵制”，在射击游戏中可能偏好“多点突击扰乱敌方阵型”，图谱会自动识别这些共性特征，形成跨游戏的策略关联网络。这种呈现方式不仅让玩家清晰看到自己的策略优势与短板—例如“擅长正面团战但缺乏侧翼支援意识”，更能为游戏开发者提供精准的策略教学与内容优化依据，让策略推荐不再是泛化的战术指南，而是贴合玩家操作习惯的定制化方案，帮助玩家快速强化优势策略、弥补能力短板。</p><p>玩家专属知识图谱的最终价值，在于实现“图谱驱动的个性化体验赋能”，将静态的图谱数据转化为动态的体验优化动力，构建“行为-图谱-体验”的闭环生态。基于图谱的深度分析，游戏可实现多维度的个性化适配：在游戏推荐层面，根据玩家的角色偏好与策略擅长，精准推送适配的游戏品类、模式或内容—如为偏好“探索型角色”且擅长“解谜策略”的玩家，推荐包含丰富隐藏剧情与机关谜题的开放世界游戏；在队友匹配层面，依据图谱中的能力维度与策略风格，匹配互补型队友，避免因团队配置失衡导致的体验不佳—如为擅长“前排抗伤”的玩家，匹配擅长“后排输出”与“辅助治疗”的队友，提升团队协作效率；在策略优化层面，针对图谱中识别的短板，推送定制化的战术指导与练习场景—如为“资源分配不合理”的玩家，设计专属的资源管理训练关卡，通过实战模拟帮助其优化策略。同时，图谱的迭代并非孤立进行，而是与游戏生态形成双向赋能：玩家的行为数据持续驱动图谱进化，让关联逻辑更精准、角色偏好解构更深入；图谱的分析结果反哺游戏体验优化，帮助开发者调整游戏平衡、优化内容设计、完善社交机制。</p>]]></description></item><item>    <title><![CDATA[《游戏场景下伪造内容的识别与处置技术指南》 程序员阿伟 ]]></title>    <link>https://segmentfault.com/a/1190000047498761</link>    <guid>https://segmentfault.com/a/1190000047498761</guid>    <pubDate>2025-12-23 22:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>当AI生成技术精准复刻游戏官方的行文肌理、名人的神态声线，甚至捏造裹挟情绪的诽谤言论，这些伪造内容不仅在排版、术语、语气上与真实信息高度趋同，更能精准捕捉玩家的关注痛点—从版本更新的核心权益到名人代言的情感共鸣，再到针对性的人格诋毁，其迷惑性让传统人工核验陷入效率困境。轻则引发玩家误操作、破坏社区信任，重则触发群体性维权事件、重创游戏品牌声誉。识别与处置这类AI拟真内容，核心在于构建“语义溯源+多模态核验+动态拦截”的立体防御网络，穿透表层形式直抵生成逻辑的底层破绽，从语言惯性、信息闭环、感官细节等维度解构伪造痕迹，让AI生成的虚假内容无处遁形。</p><p>构建AI伪造内容的识别根基，首要任务是搭建“官方信息语义基线”与“主体特征全息库”，这是区分真实与伪造内容的核心参照标尺。对于游戏官方公告，需系统萃取其长期沉淀的独特特征：包括固定的表述框架（如开篇的问候范式、核心信息的分段逻辑、结尾的落款格式与签章规范）、专属术语体系（如版本迭代的特定表述、活动规则的量化描述方式、道具属性的界定标准）、语气风格阈值（如正式公告的严谨度区间、福利活动的亲和度边界、危机公关的安抚性表达逻辑）。对于名人代言内容，需全面采集其公开的语音语调特征、面部微表情规律、肢体语言习惯、常用表述范式，甚至是签名风格、合作声明的固定要素与商业合作调性。这些数据并非静态存储，而是通过“特征动态迭代引擎”，实时吸纳官方最新发布内容、名人最新公开动态与商业合作轨迹，持续优化基线模型的适配性。例如，某游戏官方从未在公告中使用“永久免费解锁核心道具”这类绝对化表述，AI伪造的公告若出现该句式，便会触发语义基线预警；某名人代言游戏时始终会融入自身真实体验细节，伪造内容若仅泛泛宣传游戏功能而缺乏个性化表达，则会因特征不匹配被标记。同时，需建立“AI生成破绽特征库”，收录AI拟真内容常见的隐性漏洞：如语义衔接生硬、逻辑断层、术语使用场景错位、信息与游戏运营节奏冲突、情感表达缺乏层次感等，为初步筛选提供精准依据，让伪造内容在第一时间进入核查视野。</p><p>语义逻辑的深度解构，是破解AI伪造内容的关键环节，其核心在于“跨维度信息交叉验证”与“语境适配性推演”。AI生成的内容往往能模仿表层形式，却难以精准契合具体场景的逻辑关联与信息闭环，这成为识别伪造的重要突破口。以伪造官方公告为例，需从三个核心维度展开核验：首先是信息一致性校验，将公告中的核心信息（如版本更新时间、活动参与条件、道具生效机制、奖励发放规则）与游戏运营的历史数据、已公布的中长期规划、核心渠道的信息存档进行全面比对，确认是否存在矛盾点—例如，伪造公告提及的新玩法上线时间，与此前官方透露的研发进度、测试周期严重不符，或活动奖励设置远超游戏常规福利标准，便存在伪造嫌疑；其次是逻辑合理性分析，审视公告的决策逻辑是否符合游戏的核心运营理念与行业规律，如一款注重竞技平衡性的游戏，不可能突然发布“某付费道具可直接提升胜率”的公告，这类违背核心运营逻辑的内容，大概率为AI伪造；最后是语境适配性判断，分析公告发布的时机是否契合游戏的运营节点（如重大节日、版本迭代周期、用户反馈集中阶段），同时核查发布渠道的完整性—如非重大节点却发布力度超常的福利公告，或仅在第三方社区传播而未在官方官网、游戏内弹窗、认证公众号等核心渠道同步，便需启动深度核查。对于名人代言伪造内容，需验证代言信息与名人的商业合作调性、过往代言品类、近期行程安排是否匹配，同时核查游戏厂商是否有相关合作备案与公开披露计划，避免仅凭AI生成的视频或文字就轻信代言真实性。</p><p>多模态内容的细节拆解，是识别视觉、音频类伪造内容的核心技术路径，重点在于捕捉AI生成过程中难以规避的“感官违和点”。对于伪造的官方公告图片，需从视觉肌理层面进行多维分析：包括LOGO的色彩参数、比例尺寸是否与官方标准一致，字体的型号、粗细、间距是否符合固定规范，图片的分辨率、压缩痕迹是否存在异常，背景纹理是否有模糊、拼接或像素错乱的情况，文字与背景的融合度是否自然。AI生成的图片往往在细节处理上存在短板，如LOGO边缘出现锯齿状模糊、文字排版存在细微偏移、色彩过渡生硬、背景纹理缺乏真实质感等，这些细微特征均可通过“视觉微差异检测技术”精准捕捉。对于伪造的名人代言视频，需聚焦面部表情、肢体语言与语音的同步性：AI生成的面部表情可能存在僵硬、不自然的情况，如眼神空洞、微笑时肌肉线条不协调、表情转换缺乏过渡感；肢体语言可能出现动作卡顿、姿态别扭等问题；语音部分可能出现语调平淡、重音错位、口型与发音不同步、情感表达缺乏层次感等破绽。同时，可通过“音频频谱特征比对技术”，对比伪造音频与名人真实音频的频谱分布、频率波动、呼吸节奏等特征，AI生成的音频往往在频谱的连续性、情感起伏的自然度上与真实音频存在显著差异。对于文字类诽谤内容，需分析其语言风格是否存在刻意模仿特定玩家或群体的痕迹，同时核查内容中提及的事件是否有具体时间、地点、人物、经过等细节支撑，是否存在逻辑混乱、夸大其词、过度堆砌负面词汇、多段内容风格不一致等AI生成的典型特征，若内容缺乏真实事件的细节佐证且情绪煽动性极强，需重点核实其真实性。</p><p>伪造内容的处置体系，需建立“分级响应闭环”与“全链路拦截逻辑”，确保处置的精准性、时效性与彻底性。首先根据伪造内容的危害程度、传播范围、影响人群进行科学分级：一级为紧急危害，如伪造官方停运公告、名人虚假代言引发大规模玩家恐慌，1小时内扩散至10个以上主流游戏社区，阅读量超10万；二级为中度危害，如伪造活动规则导致玩家权益受损、诽谤内容引发小规模群体冲突，涉及人数超千人；三级为一般危害，如伪造非核心信息的公告、影响范围较小的不实言论，仅在小众论坛或局部社群传播。针对不同级别制定差异化处置策略：一级危害需立即启动紧急响应机制，在官方所有核心渠道（游戏内弹窗、官网置顶、认证公众号、主流社区账号）同步发布辟谣声明，明确指出伪造内容的破绽与真实信息，同时协调传播平台启动紧急下架流程，冻结相关账号的传播权限，必要时配合法律手段追溯内容源头；二级危害需在4小时内完成辟谣信息发布，针对受影响玩家开通专属核实渠道与权益保障通道，同步要求传播平台限制内容进一步扩散，并留存相关数据作为后续追责依据；三级危害需在24小时内完成核查与澄清，通过社区管理员引导、私信告知等方式向潜在受影响用户传递真实信息，避免不实言论持续发酵。处置过程中，需依托“动态拦截引擎”，实时监测各大社交平台、游戏社区、短视频渠道、第三方工具评论区，甚至游戏内聊天频道，一旦检测到与伪造内容特征匹配的信息，立即触发拦截机制，阻止其进一步传播。同时，建立“辟谣信息精准推送系统”，通过用户画像分析，将辟谣内容定向推送给可能接触到伪造内容的用户群体，最大程度降低认知误导的影响范围。</p><p>技术防御体系的持续进化，离不开“对抗性训练升级”与“生态协同赋能”的双重支撑。AI生成技术的迭代速度极快，单一的识别模型难以长期保持有效，需通过“对抗性样本库扩容”与“动态模型优化”不断提升识别算法的适应性。主动与AI生成技术领域的研究机构、安全厂商合作，获取最新的生成模型样本，模拟不同难度、不同类型的AI伪造内容（如融合真实信息片段的混合伪造、针对性优化细节的高仿真伪造），让识别模型在与“伪造技术”的持续对抗中，不断学习新型伪造特征，优化识别阈值与判定逻辑，确保技术防御始终领先于伪造技术的发展。同时，需构建游戏厂商、平台方、技术服务商、监管机构的协同防御生态：游戏厂商定期向平台方、技术服务商共享最新的官方信息特征、伪造内容案例与识别标准；平台方开放数据接口与监测权限，便于技术服务商接入进行实时监测与拦截；监管机构明确伪造内容的界定标准、处置规范与法律责任，为技术应用与行业治理提供合规指引。此外，可引入“用户协同举报机制”，鼓励玩家发现疑似伪造内容时通过官方渠道反馈，为举报用户提供匿名保护与核实奖励（如游戏内道具、积分等），将用户举报信息作为识别模型的补充数据来源，形成“技术识别+用户监督”的双重防线。未来的防御技术演进方向，将聚焦于“事前预防”与“源头追溯”，实现从被动识别到主动防御的升级。在事前预防层面，可探索“官方信息隐形水印技术”，在公告、代言视频等官方发布的信息中嵌入不可见的数字标识（如隐形语义水印、图像纹理水印），该标识无法被AI生成技术复制，用户通过特定工具即可快速验证内容真伪；同时，构建“官方信息发布链可信认证体系”，确保所有官方内容均通过加密渠道发布，发布路径全程可追溯，从源头杜绝伪造内容的植入空间。</p>]]></description></item><item>    <title><![CDATA[详解 Redis Write-Behind 模式：如何用 Redis 给数据库做“挡板” bloss]]></title>    <link>https://segmentfault.com/a/1190000047498688</link>    <guid>https://segmentfault.com/a/1190000047498688</guid>    <pubDate>2025-12-23 21:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>1. 引言：数据库的“至暗时刻”</h2><p>在互联网高并发场景下，经常会出现流量突发的状况。例如短视频 App 遭遇热点事件，几百万用户瞬间涌入，产生海量的点赞与评论互动。</p><p>此时，后端监控系统往往会发出警报：</p><ul><li><strong>数据库 CPU 飙升至 100%</strong>。</li><li><strong>磁盘 I/O 被打满</strong>，写入延迟从几毫秒恶化至数秒。</li><li><strong>连接池耗尽</strong>，新的请求因无法获取连接而报错。</li></ul><p>这种现象的根本原因在于：在传统架构中，每一次前端的“点赞”操作，都直接对应数据库中的一次 <code>UPDATE</code> 操作。在高并发下，成千上万个线程争抢数据库的<strong>行锁（Row Lock）</strong>，导致数据库瞬间成为整个系统的瓶颈。</p><p>面对这种洪峰流量，直接由数据库承担所有写入压力并不现实。此时，需要在应用层与数据库层之间增加一层“缓冲保护”，即 <strong>Redis Write-Behind（异步回写）模式</strong>。</p><h2>2. 什么是 Write-Behind 模式？</h2><p>在缓存设计模式中，业界常见的有 <strong>Cache-Aside</strong>（旁路缓存）或 <strong>Write-Through</strong>（直写），这些模式通常要求数据在写入时必须同步落库，以保证数据的强一致性。</p><p>而 <strong>Write-Behind（回写）</strong>，也称为 Write-Back，其核心思想是：<strong>“先内存，后持久化”</strong>。</p><p>在这种模式下，Redis 不仅仅充当缓存的角色，更是一个<strong>“挡板”</strong>或<strong>“缓冲区”</strong>。</p><ol><li><strong>写请求</strong>：应用层只将数据更新到 Redis，并立即返回“成功”响应。</li><li><strong>同步</strong>：由独立的后台异步线程（或定时任务），负责周期性地将 Redis 中的数据批量写入数据库。</li></ol><p><strong>核心机制图解：</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047498690" alt="" title=""/></p><blockquote><em>图注：Write-Behind 模式核心流程：用户请求在 Redis 层快速完成，后台通过异步 Worker 进行批量落库。</em></blockquote><h2>3. 为什么它是“性能救星”？</h2><p>Write-Behind 模式的本质，是利用“<strong>数据的即时一致性</strong>”来换取“<strong>极致的写入性能</strong>”。</p><h3>3.1 极高的写入吞吐量</h3><p>在 Write-Behind 模式下，客户端的等待时间仅包含 Redis 的网络耗时与内存操作耗时，通常在<strong>毫秒级</strong>。这使得前端用户体验极其流畅，感知不到数据库的压力。</p><h3>3.2 削峰填谷（Load Leveling）</h3><p>这是该模式最显著的收益。</p><ul><li><strong>合并写请求</strong>：假设 1 秒内产生了 10,000 次点赞请求。</li><li><em>传统模式</em>：数据库需执行 10,000 次 <code>UPDATE</code>。</li><li><em>Write-Behind</em>：Redis 中的计数器累加 10,000 次，后台线程只需向数据库执行 <strong>1 次</strong> <code>UPDATE count = count + 10000</code>。</li><li><strong>效果</strong>：数据库的写压力可降低数个数量级。</li></ul><h3>3.3 系统的弹性</h3><p>即使数据库因意外短暂宕机（如重启、网络抖动），只要 Redis 保持运行，前端业务的写操作仍可正常进行。该模式为系统提供了一个宝贵的“缓冲窗口”，为数据库恢复争取了时间。</p><h2>4. 黄金应用场景</h2><p>并非所有业务都适合该模式，以下是 Write-Behind 模式最适用的场景：</p><h3>场景一：高频计数器（Counter）</h3><p><strong>典型案例</strong>：视频播放量、文章点赞数、直播间热度。<br/>此类数据的特点是<strong>高频</strong>且<strong>非核心敏感</strong>。对于业务而言，实时数据是 10,005 还是 10,100 并不影响核心流程，只要最终数量一致即可。</p><ul><li><strong>实现策略</strong>：使用 Redis 的 <code>INCR</code> 原子操作，每隔 N 秒将增量同步回 DB。</li></ul><h3>场景二：高频轨迹/位置上报</h3><p><strong>典型案例</strong>：外卖骑手位置更新、车辆 GPS 轨迹。<br/>若骑手每秒上报一次坐标，直接写库会产生海量数据且造成巨大的 I/O 压力。</p><ul><li><strong>实现策略</strong>：将坐标推入 Redis List，积累一定数量（如 50 个点）或一定时间（如 1 分钟）后，批量打包 <code>INSERT</code> 到数据库。</li></ul><h3>场景三：状态防抖（Debounce）</h3><p><strong>典型案例</strong>：在线文档的“自动保存”、用户的“正在输入”状态、最后在线时间。<br/>用户在编辑文档时，短时间内可能产生多次输入。系统无需保存每一次中间状态，只需保存最后停顿时的状态。</p><ul><li><strong>实现策略</strong>：Redis 中只存最新状态（Last Value），延迟 N 秒后落地，丢弃中间过程数据。</li></ul><h2>5. 硬币的另一面：风险与代价</h2><p>在引入 Write-Behind 提升性能的同时，必须关注其带来的风险。</p><h3>5.1 数据丢失风险（关键风险）</h3><p><strong>问题</strong>：由于数据是异步落库的，如果在数据同步到数据库之前 Redis 发生宕机，且 Redis 的持久化（RDB/AOF）未及时跟上，则内存中的这部分数据将<strong>彻底丢失</strong>。<br/><strong>对策</strong>：</p><ul><li><strong>严禁</strong>将此模式用于金融交易、订单支付状态等核心链路。</li><li>配置合理的 Redis AOF 策略（如 <code>appendfsync everysec</code>）以降低丢失概率。</li></ul><h3>5.2 数据一致性延迟</h3><p><strong>问题</strong>：数据库中的数据存在滞后性。如果后台管理系统直接查询数据库导出报表，所见数据可能少于前端展示的数据。<br/><strong>对策</strong>：</p><ul><li>业务层需接受“最终一致性”。</li><li>或者强制所有的读取操作优先查询 Redis。</li></ul><h2>6. Java (Spring Boot) 实现思路简述</h2><p>以下是一个基于 Spring Scheduled 的实现伪代码示例，用于演示“点赞异步回写”的逻辑：</p><pre><code class="java">@Service
public class LikeService {

    @Autowired
    private StringRedisTemplate redisTemplate;
    
    // 1. 业务请求：极速响应，仅操作 Redis
    public void likePost(Long postId) {
        String key = "post:likes:" + postId;
        // Redis 原子增，内存操作，无需等待 DB
        redisTemplate.opsForValue().increment(key); 
    }

    // 2. 异步回写：定时任务 (例如每5秒执行一次)
    @Scheduled(fixedRate = 5000)
    public void syncToDatabase() {
        // 扫描相关的 key (生产环境建议使用 Scan 命令或维护一个脏数据 Set)
        Set&lt;String&gt; keys = redisTemplate.keys("post:likes:*");
        if (keys == null || keys.isEmpty()) return;

        for (String key : keys) {
            String countStr = redisTemplate.opsForValue().get(key);
            if (countStr != null) {
                Long count = Long.parseLong(countStr);
                Long postId = parseIdFromKey(key);
                
                // 3. 批量更新数据库 
                // SQL: UPDATE posts SET like_count = like_count + :count WHERE id = :postId
                dbRepository.incrementLikes(postId, count);
                
                // 4. 更新后处理 Redis 中的数据
                // 简单处理可直接删除 Key，更严谨的做法是扣减已同步的数值 (DECR)
                redisTemplate.delete(key); 
            }
        }
    }
}
</code></pre><h2>7. 总结</h2><p>Redis Write-Behind 模式是处理高并发写场景的有效手段。它通过引入<strong>异步边界</strong>，将数据库从繁重的随机写操作中解放出来，转而处理其更擅长的批量顺序写。</p><p><strong>结论：</strong><br/>Write-Behind 模式是一种架构上的权衡，即用<strong>“即时一致性”</strong>和<strong>“少量数据丢失的风险”</strong>，换取<strong>“极致的写入性能”</strong>。</p><p>在进行系统设计时，决策的关键在于：<strong>业务是否允许少量数据的丢失以换取高性能？</strong> 如果是点赞数等非敏感数据，该模式是绝佳选择；如果是资金交易等核心数据，则应坚持使用强一致性的传统写库模式。</p><p>本文由<a href="https://link.segmentfault.com/?enc=6A3%2B4nSte1OnGa3vqLHLOQ%3D%3D.LvFqSdS1D5gVYxL7hhv62hsTVyMezO500A8y43FJnSs%3D" rel="nofollow" target="_blank">mdnice</a>多平台发布</p>]]></description></item><item>    <title><![CDATA[观测云在企业应用性能故障分析场景中的最佳实践 观测云 ]]></title>    <link>https://segmentfault.com/a/1190000047498594</link>    <guid>https://segmentfault.com/a/1190000047498594</guid>    <pubDate>2025-12-23 20:04:17</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>背景</h2><p>某企业经常遇到应用性能问题，对于应用性能的监测缺少基本的手段，这无疑对故障的排查增加了难度，而且对于产品大促期间，这无疑会影响用户的体验以及最终的交易，本文主要通过介绍某出海企业用户在使用观测云应用性能监测分析时的故障场景分析实践。</p><h2>应用性能监测</h2><p>观测云拥有应用性能监测的能力，支持各种主流语言的技术栈，并兼容 OpenTelemetry，Skywalking，Jaeger，DDTrace 等等开源的 Agent，最佳部署方案是将 DataKit 部署在每一台应用服务器中，通过服务所在主机的 DataKit 后将数据打到观测云中心，能更好地对应用服务的服务器主机指标、应用日志、系统日志、应用服务链路数据等统一汇聚，进行各项数据的关联分析，而观测云应用性能监测主要功能包含服务，概览，链路，错误追踪，Profiling，应用性能指标检测等功能，本文主要基于观测云的应用监测能力，对用户故障场景进行分析实践。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047498596" alt="图片" title="图片"/></p><h2>应用性能故障场景分析</h2><p>故障概述：用户反馈在 17:00 前后发生应用性能访问的故障，页面卡顿，数据加载不出，基于此进行了以下场景的分析。</p><h3>某服务故障场景分析实践-Read time out</h3><ul><li>如图，通过观测云查看到，请求量增加，从 1 万 3 的请求量级增加到，20 万左右量级，并出现大量报错，请求超时，建议平时做好压测</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047498597" alt="图片" title="图片" loading="lazy"/></p><ul><li>查看报错聚类分析，服务报错在该段时间，Read time out 报错最多</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047498598" alt="图片" title="图片" loading="lazy"/></p><ul><li>分析 timeout 详细，超时底层栈在 SocketInputStream.socketRead，该底层方法即发起请求后在读数据的返回</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047498599" alt="图片" title="图片" loading="lazy"/></p><ul><li>查看链路的瀑布图，有 1 分钟超时报错，建议检查超时设置</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047498600" alt="图片" title="图片" loading="lazy"/></p><ul><li>查看链路调用超时的拓扑图，有调 MySQL 数据库，在应用侧超时报错</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047498601" alt="图片" title="图片" loading="lazy"/></p><h3>MySQL 故障场景分析实践-JDBC连接通信异常</h3><ul><li>对 MySQL 请求量分析，发现在 17:00 左右，MySQL 请求量级也增加至少不低于 10 倍，并出现了大量报错</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047498602" alt="图片" title="图片" loading="lazy"/></p><ul><li>报错如下，主要是数据包发送接收超时，通信失败以及服务 shutdown 的情况</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047498603" alt="图片" title="图片" loading="lazy"/></p><ul><li>以上时间段可能有 MySQL 重启，筛选 17:00 左右数据，没有 server shutdown 的报错，但依然是通信超时异常</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047498604" alt="图片" title="图片" loading="lazy"/></p><ul><li>报错详细堆栈显示 Druid 数据库连接产生的 jdbc 异常，建议用户检查数据库连接池连接与配置情况</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047498605" alt="图片" title="图片" loading="lazy"/></p><h3>MySQL 故障场景分析实践-MySQL 请求调用分析</h3><ul><li>分析 MySQL 的请求与调用，很多服务都会调用 MySQL，每秒 5 万多请求调用</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047498606" alt="图片" title="图片" loading="lazy"/></p><ul><li>其中调用 MySQL 调用最多的为该服务，每秒 4 万多请求</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047498607" alt="图片" title="图片" loading="lazy"/></p><ul><li>其次调用 MySQL 调用最多的为 xxxxx-product-server 服务，每秒 9 千多请求</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047498608" alt="图片" title="图片" loading="lazy"/></p><ul><li>对 MySQL 调用最多的服务分析上下游调用情况，发现很多服务都会通过该配置服务调用 MySQL，建议考虑是否可以增加 MySQL 缓存优化</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047498609" alt="图片" title="图片" loading="lazy"/></p><ul><li>而且服务之间很多相互调用，服务之间也会直接或者间接的调用调数据库，只要有一个服务有问题，就可能引起连锁性能问题</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047498610" alt="图片" title="图片" loading="lazy"/></p><h3>调用数据库较多的配置服务-量能分析实践</h3><ul><li>分析配置服务请求，发现请求量从 5 万级别到 50 万级别</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047498611" alt="图片" title="图片" loading="lazy"/></p><ul><li>大量请求错误，并呈现几分钟的严重超时</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047498612" alt="图片" title="图片" loading="lazy"/></p><ul><li>超时也是从 17:00 左右发生，等待数据返回</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047498613" alt="图片" title="图片" loading="lazy"/></p><h2>观测云应用性能分析总结</h2><p>综上场景分析实践，基于观测云的应用性能监测分析得出结论与建议：</p><ul><li>MySQL 数据库连接问题导致本次故障，建议检查数据库连接配置，确认为连接池数不够用，连接超时，可以基于观测云增加基于连接池指标的监控</li><li>业务请求并发量较高，导致 MySQL 数据库请求连接数量过高</li><li>对调用 MySQL 较多的 xxxxx-config-server 服务，后续可以考虑采用 redis 缓存方式，减少对 MySQL 的调用</li><li>当有高并发活动大促时，为避免高并发导致一系列的故障采用秒级可以拉起的高性能数据库厂商</li><li>对于高并发的场景，提前做好性能压测，确保对应的资源能满足对应活动的并发量请求</li></ul>]]></description></item><item>    <title><![CDATA[Pydantic-DeepAgents：基于 Pydantic-AI 的轻量级生产级 Agent 框]]></title>    <link>https://segmentfault.com/a/1190000047498635</link>    <guid>https://segmentfault.com/a/1190000047498635</guid>    <pubDate>2025-12-23 20:03:43</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>DeepAgents的灵感源自 LangChain deepagents，但在设计上更做减法，它强调类型安全且内置了 Docker 沙箱</p><p>2025 年的Autonomous AI Agents早就不是实验室里的花架子了。在现实世界的自动化流程、代码生成工具、数据管道以及各类智能助手中都能看到它们的身影。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047498637" alt="" title=""/></p><p>现在的很多主流 Agent 框架越来越重。为了用上 Agent，你往往得引入一堆沉重的依赖，面对复杂的图结构（Graphs），还得学完陡峭的学习曲线。想把这些东西真正部署到生产环境，确实挺折腾。</p><p>Vstorm 开发 Pydantic-DeepAgents 是一个极简但功能并不弱的开源框架，它的思路很清晰：在 Pydantic-AI 的基础上进行扩展，只提供构建可靠、生产级 Agent 真正需要的东西。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047498638" alt="" title="" loading="lazy"/></p><h2>为什么还要造一个轮子？</h2><p>其实这个项目的灵感直接来源于 LangChain 的 deepagents项目。那个项目对“Deep Agent”模式的实现——包括规划循环（Planning loops）、工具调用、子智能体委托（Subagent delegation）以及 Human-in-the-loop（人机协同）等等功能都设计得很好。</p><p>但与其说是重新造轮子，不如反问一个问题：如果完全在 Pydantic-AI 的生态里实现这些强大的模式，体验会不会更好？</p><p>所以Pydantic-DeepAgents 就来了：它是真的<strong>轻量级</strong>，没有引入 LangGraph 这种庞大的生态；反而充分利用了 Pydantic 原生的类型安全来做结构化输出；同时它把很多同类竞品缺失的生产级特性给补齐了。</p><h2>核心能力拆解</h2><p>这个框架在功能设计上很务实。</p><p>在规划与推理方面，它通过</p><pre><code>TodoToolset</code></pre><p>来实现自主的任务拆解和自我修正。对于文件系统的操作权限是完整的并且通过</p><pre><code>FilesystemToolset</code></pre><p>可以进行读写操作。如果遇到复杂的任务还支持通过</p><pre><code>SubAgentToolset</code></pre><p>将任务委托给专门的子智能体去处理。</p><p>特别值得一提的是它的技能系统，你只需要写简单的 Markdown 提示词就能定义新的 Agent 能力，这一点对于快速迭代原型非常友好。</p><p>在后端支持上除了内存和本地文件系统它还支持 DockerSandbox，这一点对于需要隔离执行代码的场景至关重要，而且它也支持混合后端（CompositeBackend）。</p><p>文件处理的流程也很顺滑，无论是通过</p><pre><code>run_with_files()</code></pre><p>还是</p><pre><code>deps.upload_file()</code></pre><p>都能无缝处理上传文件。对于长对话，它内置了上下文管理能自动进行摘要总结。</p><p>针对生产环境的交互需求，它内置了Human-in-the-loop 机制，关键操作可以配置人工确认工作流。支持逐 Token 的流式输出，方便构建响应迅速的前端 UI，基于 Pydantic 模型定义的</p><pre><code>output_type</code></pre><p>保证了输出的结构化和类型安全。</p><h2>技术选型</h2><p>官方仓库里直接给了一套全栈 Demo（FastAPI 后端 + 流式 Web UI）。跑起来能看到 Agent 的完整思考过程（Reasoning traces），包括文件上传处理、人工审批步骤以及流式响应的效果，代码本身很有参考价值。</p><p>什么情况下该考虑用它？</p><p>如果你受够了臃肿的框架，想要个干净、好维护的 Agent 架构，或者你对数据验证有强迫症，需要强类型的响应保证，那这个框架很适合。特别是它自带 Docker 沙箱在安全性上有天然优势。</p><p>对于原本就在用 Pydantic-AI 的开发者，或者需要 Agent 安全地操作文件和外部工具的场景，Pydantic-DeepAgents 基本就是无缝衔接的选择。</p><h2>快速上手</h2><p>安装非常简单：</p><pre><code> pip install pydantic-deep</code></pre><h2>总结</h2><p>在 Agent 落地过程中，我们往往容易陷入过度设计的陷阱。Pydantic-DeepAgents 给出了答案：有时候严格的类型安全加上一个干净的 Docker 容器，远比一张错综复杂的有向无环图（DAG）要好维护得多。 如果你也认同这种“做减法”的工程美学，或者正苦于现有框架的臃肿，不妨试试这个方案。</p><p><a href="https://link.segmentfault.com/?enc=eVyIld4hmoxxpI0QwFn%2Bjw%3D%3D.pqudCFAN%2FGuaAHbdN%2FF917Pokmxl42iTD7KnT68TmbRx%2Fd9eKXa%2Fo%2FqgTU3guC7UGB8tGIE7ZYp6DtI09r%2FGdQ%3D%3D" rel="nofollow" target="_blank">https://avoid.overfit.cn/post/e9c1b806f00d48e3bfa52abd857fcb5c</a></p><p>作者：Kacperwlodarczyk</p>]]></description></item><item>    <title><![CDATA[从怀疑到离不开：我第一个由 AI 深度参与完成的真实项目复盘 命中水ヽ ]]></title>    <link>https://segmentfault.com/a/1190000047497313</link>    <guid>https://segmentfault.com/a/1190000047497313</guid>    <pubDate>2025-12-23 20:02:45</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <blockquote><p>首先说明，我不是专业的前端工程师。</p><p>但这次，我一个人完成了一个包含<strong>聊天窗口、WebSocket 实时推送、多语言翻译、复杂 UI 状态管理</strong>的前端项目。</p><p>说实话，如果没有 AI，这个项目我大概率会延期，甚至放弃一些体验上的细节。</p><p>这是我第一次，在一个<strong>真实、长期维护、并且已经上线使用的项目</strong>中，深度引入 AI 参与开发。 不是 Demo，不是练手，而是一个我必须为稳定性、性能和可维护性负责的系统。</p></blockquote><h2>一、前言</h2><p>前端时间接了一个前端聊天+后端管理后台的项目，两个项目都是我自己一个人完成。</p><p>说起来后端还好，但是前端html+css那套我最开始入行的时候学了一点，但是后面正式工作后主要还是围绕后端语言来展开，前端的那套样式语法就渐渐地放下了；</p><p>但这次是一个全新的机会，也是一个新的挑战，需要自己写前端。那如何快速写前端项目，并快速交付呢？于是我想到了AI这个帮手，之前总拿它来排查问题，但是写一个项目行不行呢？ 我抱着怀疑的态度开始了这项“挑战”，并最终“有惊无险”的落地完成，顺利完成交付；</p><p>本篇文章，我想详细的复盘下这次经历：如何与AI沟通？ 如何合理利用AI完成代码的实现？以及举例一些聊天系统中实现的业务关键点！</p><p>在使用前，先想一下：</p><p><strong>AI 到底能帮我们做到什么？我们又该如何与 AI 协作，才能真的提高生产力，而不是制造技术债？</strong></p><h2>二、与AI对话</h2><h3>2.1 为什么我会把 AI 真正引入一个“正经项目”？</h3><p>先说结论： <strong>不是因为“新技术”，而是因为“现实问题”。</strong></p><p>我的真实情况</p><p>这个项目是一个 <strong>客服聊天系统</strong>，核心特点包括：</p><ul><li>Laravel 后端处理接口数据</li><li>jQuery + Bootstrap 前端（我比较熟悉的是这套组合拳）</li><li>多账号、多好友</li><li>WebSocket 实时推送</li><li>消息类型复杂（文本 / 图片 / 视频 / 语音）</li><li>SaaS 场景（多租户）</li></ul><p>我面临的真实问题是：</p><ul><li>后端我非常熟</li><li>但前端交互复杂、状态多、样式细</li><li>每一个“小交互”都很耗时间</li><li>而项目又在持续迭代，<strong>不能停下来重构</strong></li></ul><p>👉 这时，AI 不再是“锦上添花”，而是<strong>降低边际成本的工具</strong>。</p><hr/><h3>2.2 AI 开发入门：不要幻想“全自动”，要追求“人机协作”</h3><h4>2.2.1 AI 最适合做什么？</h4><p>在这次项目中，我给 AI 的定位非常清晰：</p><blockquote><strong>AI = 前端协作工程师</strong></blockquote><p>基于我当时的情况，我给它的定时是，辅助帮我写前端代码，包括但不限于以下：</p><ul><li>UI 结构拆解</li><li>JS 事件逻辑补全</li><li>CSS 微调与重构</li><li>复杂 DOM 操作的示例实现</li><li>重复性、模式化代码生成</li></ul><p>结合我使用之后的感觉，我认为他可能<strong>不太适合</strong>：</p><ul><li>定业务边界</li><li>定核心数据结构</li><li>决定架构选型</li><li>性能极限设计</li></ul><p><strong>这些必须由人来做。</strong></p><h4>2.2.2 心态非常重要：你不是“用 AI”，而是在“带 AI”</h4><p>如果你把 AI 当成：</p><ul><li>“自动写代码工具”</li><li>“一句话生成系统”</li></ul><p>那你一定会失望。</p><p>但如果你把 AI 当成：</p><ul><li>一个不抱怨的工程师</li><li>一个愿意反复改的搭子</li><li>一个可以随时请教的助手</li></ul><p>你会发现它<strong>非常好用</strong>。</p><hr/><h3>2.3 如何与 AI 沟通，才能真的把前端项目做出来？</h3><p>这一节，是我整篇文章里最想聊的部分。</p><h4>2.3.1 关键原则一：给 AI “现有代码”，而不是“空需求”</h4><p>❌ 错误方式：</p><blockquote>帮我写一个聊天窗口</blockquote><p>✅ 正确方式：</p><blockquote>这是我现有的 HTML 结构 这是我的 JS 方法 这是我的业务规则 请在不破坏现有结构的前提下，实现功能 X</blockquote><p>AI 的代码质量，<strong>严重依赖上下文完整度</strong>。</p><p><strong>PS：如果你是从0开始让AI帮你完成项目，那最好在同一个人聊天窗口下，如果切换了聊天窗口，那可能会导致以前的消息可能无法产生关联；如果要优化，最好贴上之前的代码！</strong></p><hr/><h4>2.3.2 关键原则二：需求要“具象”，不要“抽象”</h4><p>比如我会这样描述 UI：</p><blockquote>聊天窗口顶部： 左侧是头像 + 昵称 右侧是三个点按钮 点击后，从“聊天窗口右侧”滑出信息面板 而不是整个页面</blockquote><p>你会发现：<strong>我描述的是“画面”，不是“功能名词”。</strong></p><h4>2.3.3 关键原则三：有问题就“精准反馈”，不要一句否定</h4><p>我在项目中经常这样和 AI 互动：</p><ul><li>“三个点按钮没有靠右”</li><li>“事件绑定不到，因为是动态元素”</li><li>“滑出层相对于 body 了，不是 chat-panel”</li></ul><p>这种反馈，会让 AI <strong>快速修正，而不是推倒重来</strong>。</p><h4>2.3.4 一个我踩过的坑：AI 会“自信地写错”</h4><p>AI不是万能的，它也有可能出错，你的描述词不清晰，代码未提供完整，就可能导致：</p><ul><li>CSS 看起来对，但层级错了</li><li>JS 逻辑跑得通，但状态没覆盖</li><li>WebSocket 示例是 Demo 级，不是生产级</li></ul><p>所以我后来形成了一个习惯：<strong>AI负责“给方案”，我负责“兜底校验”！</strong></p><h2>三、项目功能关键点拆解示例</h2><h3>3.1 关键功能点一：前后端聊天消息推送</h3><h4>3.1.1 后端整体设计思路</h4><p>我采用的是：</p><ul><li><strong>Workerman / GatewayWorker</strong></li><li>后端消息统一入库</li><li>再推送 WebSocket 给前端</li></ul><p>核心原则是：</p><blockquote><strong>消息以“后端为准”，前端只是展示层</strong></blockquote><hr/><p>我设计的流程是，后端采用脚本监听第三方消息服务，监听到有消息之后推送到job，job中处理消息，代码如下：</p><pre><code>&lt;?php
​
namespace App\Jobs;
​
use App\Repositories\YkAccountFriendChatRecordRepository;
use App\Repositories\YkAccountFriendRepository;
use App\Repositories\YkAccountRepository;
use App\Services\GatewayService;
use App\Services\InstagramMessageService;
use App\Services\TranslateService;
use Illuminate\Bus\Queueable;
use Illuminate\Contracts\Queue\ShouldQueue;
use Illuminate\Foundation\Bus\Dispatchable;
use Illuminate\Queue\InteractsWithQueue;
use Illuminate\Queue\SerializesModels;
use Illuminate\Support\Facades\DB;
use Illuminate\Support\Facades\Log;
​
/**
 * 处理mqtt消息
 */
class ProcessIncomingMqttMessage implements ShouldQueue
{
    use Dispatchable, InteractsWithQueue, Queueable, SerializesModels;
​
    protected $payload;
​
    /**
     * Create a new job instance.
     *
     * @return void
     */
    public function __construct(array $payload)
    {
        $this-&gt;payload = $payload;
    }
​
    /**
     * Execute the job.
     *
     * @return void
     */
    public function handle()
    {
        try {
            if (!$this-&gt;payload['PK']) {
                throw new \Exception('缺少PK！');
            }
            $accountKey = $this-&gt;payload['PK'];
            $account = app(YkAccountRepository::class)-&gt;firstWhere(['account_key' =&gt; $accountKey, 'status' =&gt; YkAccountRepository::STATUS_ENABLE]);
            if (empty($account)) {
                throw new \Exception("account_key：{$accountKey}对应的account数据不存在");
            }
​
            if (!is_array($this-&gt;payload['Payload']) || !count($this-&gt;payload['Payload'])) {
                throw new \Exception('payload数据异常！');
            }
            foreach ($this-&gt;payload['Payload'] as $value) {
                /**
                 * UserId 发送方id
                 * RealTimeOp 类型
                 * Text 文本类型是内容字段
                 * Media 媒体类型时字段
                 */
                if (empty($value['UserId'])) {
                    Log::info('payload中没有UserId：'  . json_encode($value));
                    continue;
                }
​
                $friend = app(YkAccountFriendRepository::class)-&gt;firstWhere(['pks' =&gt; $value['UserId'], 'account_id' =&gt; $account['id']]);
                if (empty($friend)) {
                    Log::info("pks：{$value['UserId']}在好友表中不存在！");
                    continue;
                }
​
                $contentType = InstagramMessageService::transContentType($value);
                if (empty($contentType)) {
                    Log::warning('ProcessIncomingMqttMessage - handle 未知的消息类型' . json_encode($value));
                    continue;
                }
​
                $sendTime = transMicrosecondTimestamp($value['TimeStampUnix']);
​
                $data = [
                    'customer_id'       =&gt; $account['belong_customer_id'],
                    'account_id'        =&gt; $account['id'],
                    'friend_id'         =&gt; $friend['id'],
                    'content'           =&gt; $value['Text'] ?? null,
                    'content_type'      =&gt; $contentType,
                    'attachment'        =&gt; InstagramMessageService::getAttachment($contentType, $value),
                    'item_id'           =&gt; $value['ItemId'],
                    'send_time'         =&gt; transMicrosecondTimestamp($value['TimeStampUnix']),
                    'send_status'       =&gt; YkAccountFriendChatRecordRepository::STATUS_SUCCESS
                ];
                
                // 如果是文本类型 获取翻译之后的数据
                if ($contentType == YkAccountFriendChatRecordRepository::CONTENT_TYPE_TEXT) {
                    $transContent = TranslateService::getChatMessageTranslate($account['belong_customer_id'], $value['Text']);
                    if ($transContent &amp;&amp; ($transContent != $value['Text'])) {
                        $data['is_translate'] = YkAccountFriendChatRecordRepository::CONTENT_TRANSLATE;
                        $data['content_translate'] = $transContent;
                    }
                }
​
                DB::beginTransaction();
                try {
                    $record = app(YkAccountFriendChatRecordRepository::class)-&gt;updateOrCreate(['item_id' =&gt; $data['item_id']], $data);
                    app(YkAccountFriendRepository::class)-&gt;updateLastChatTime($friend['id'], $sendTime);
                    app(YkAccountRepository::class)-&gt;updateLastChatTime($account['id'], $sendTime);
                    DB::commit();
                } catch (\Exception $e) {
                    DB::rollBack();
                    Log::info('ProcessIncomingMqttMessage handle 落库失败，异常原因：' . $e-&gt;getMessage());
                    continue;
                }
                $data['message_id'] = $record-&gt;id;
​
                GatewayService::pushMessageToClient($data, $friend);
                // 自动回复消息
                dispatch(new SendAutoReplyMessageJob($record-&gt;id))-&gt;onConnection('redis')-&gt;onQueue('SendAutoReplyMessageSqs');
            }
        } catch (\Throwable $e) {
            Log::error('ProcessIncomingMqttMessage fail line:' . $e-&gt;getLine() . ' 报错信息：' . $e-&gt;getMessage(), ['payload' =&gt; $this-&gt;payload]);
        }
    }
}
</code></pre><p><code>GatewayService</code>类的<code>pushMessageToClient</code>方法代码如下：</p><pre><code>public static function pushMessageToClient($data, $friend)
{
    $gatewayHost = config('services.gateway.host', '127.0.0.1');
    $gatewayPort = config('services.gateway.port', '1238');
​
    Gateway::$registerAddress = sprintf('%s:%s', $gatewayHost, $gatewayPort);
​
    $sendData = [
        'account_id'    =&gt; $data['account_id'],
        'friend_id'     =&gt; $data['friend_id'],
        'friend_name'   =&gt; $friend['username'],
        'friend_avatar' =&gt; $friend['avatar'],
        'send_time'     =&gt; format_time($data['send_time']),
        'timestamp'     =&gt; format_time(null),
        'content'       =&gt; $data['content'],
        'attachment'    =&gt; $data['attachment'],
        'content_type'  =&gt; $data['content_type'],
        'message_id'    =&gt; $data['message_id'],
        'is_me'         =&gt; $data['is_me'] ?? false,
        'is_auto_reply' =&gt; $data['is_auto_reply'] ?? false,
    ];
​
    if (!$sendData['is_me']) {
        // 不管客服有没有在线 先标记账号和好友 有未读数据（从前端去处理已读）
        app(YkAccountFriendRepository::class)-&gt;update(['is_have_un_read_msg' =&gt; YkAccountFriendRepository::HAVE_UN_READ_MSG], $friend['id']);
        app(YkAccountRepository::class)-&gt;update(['is_have_un_read_msg' =&gt; YkAccountFriendRepository::HAVE_UN_READ_MSG], $data['account_id']);
    }
​
    // 判断当前客服是否在线
    if (Gateway::isUidOnline($data['customer_id'])) {
        Log::info('推送到客户端信息', ['customer_id' =&gt; $data['customer_id'], 'data' =&gt; json_encode([
            'type' =&gt; 'new_message',
            'data' =&gt; $sendData
        ])]);
        // 发送消息给客服
        Gateway::sendToUid($data['customer_id'], json_encode([
            'type' =&gt; 'new_message',
            'data' =&gt; $sendData
        ]));
    } else {
        Log::info("客服id：{$data['customer_id']}，未在线~", ['send_data' =&gt; $sendData]);
    }
}
</code></pre><p>这个方法多个地方都可以调用，比如：</p><ul><li>接收到消息推送到前端</li><li>前端发送消息，后端推送到第三方成功，发送到前端回显</li><li>自动回复消息成功，发送到前端回显</li><li>...</li></ul><h4>3.1.2 后端推送的数据结构</h4><pre><code>{
    "account_id": 123456,
    "friend_id": 789012,
    "friend_name": "张三",
    "friend_avatar": "https://example.com/avatar.jpg",
    "send_time": "2023-10-15 14:30:25",
    "timestamp": "2023-10-15 16:45:10",
    "content": "你好，最近怎么样？",
    "attachment": "image_001.jpg",
    "content_type": "text",
    "message_id": "msg_20231015143025_123456",
    "is_me": false,
    "is_auto_reply": false
}
</code></pre><hr/><h4>3.1.3 前端接收消息</h4><p>绑定并监听websocket</p><pre><code>// 绑定 WebSocket
function connectWebSocket() {
    if (!CUSTOMER_ID) {
        console.error('未设置客服ID，无法连接WebSocket');
        return;
    }
    // 清除之前的重连定时器
    if (reconnectTimer) {
        clearTimeout(reconnectTimer);
        reconnectTimer = null;
    }
​
    ws = new WebSocket(window.WEBSECKET_HOST); // 改成你的服务地址
​
    ws.onopen = function () {
        console.log('WebSocket 已连接');
        lastPongTime = Date.now(); // 连接建立时重置时间
        reconnectAttempts = 0; // 重置计数器
​
        // 绑定客服登录用户ID
        ws.send(JSON.stringify({
            type: 'bind',
            uid: CUSTOMER_ID
        }));
        // 启动心跳检测
        startHeartbeatCheck();
    };
​
    ws.onmessage = function (event) {
        console.log('收到消息：', event.data);
        let msg = {};
        try {
            msg = JSON.parse(event.data);
        } catch (e) {
            console.warn('收到非法消息', event.data);
            return;
        }
​
        if (msg.type === 'ping') {
            // 服务器心跳包，更新最后活跃时间并回复pong
            lastPongTime = Date.now();
            // 服务器心跳包，回复pong
            ws.send(JSON.stringify({type: 'pong'}));
            return;
        }
​
        if (msg.type === 'new_message') {
            console.log('收到new_message消息：', msg.data);
            handleIncomingMessage(msg.data);
        }
​
        if (msg.type === 'account_online_status') {
            const data = msg.data;
            console.log('收到account_online_status消息：', msg.data);
            updateAccountOnlineStatus(data);
        }
​
        if (msg.type === 'send_message_status') {
            console.log('收到send_message_status消息：', msg.data);
            const data = msg.data;
            // updateFriendOnlineStatus(data);
​
            updateMessageSendStatus(data)
        }
    };
​
    ws.onclose = function () {
        reconnectAttempts++;
​
        // 渐进式重连：前3次快速重连，后续采用退避策略
        const delay = reconnectAttempts &lt;= 3 ?
            BASE_DELAY :
            Math.min(BASE_DELAY * Math.pow(1.5, reconnectAttempts - 3), MAX_DELAY);
​
        console.warn(`[第${reconnectAttempts}次重连] ${delay}ms后尝试...`);
        setTimeout(connectWebSocket, delay);
    };
​
    ws.onerror = function (e) {
        console.error('WebSocket 发生错误');
        console.error('WS错误代码:', e.code);
        console.error('WS错误原因:', e.reason);
        ws.close();
    };
}
​
/**
 * 新消息处理
 * @param msg
 */
function handleIncomingMessage(msg) {
    console.log('handleIncomingMessage', msg);
    const currentAccountId = state.currentAccountId;
    const currentFriendId = state.currentFriendId;
​
    if (msg.account_id === currentAccountId) {
        if (msg.friend_id === currentFriendId) {
            // 当前聊天窗口好友，追加消息
            appendMessage({
                me: msg.is_me || false,
                auto_reply: msg.is_auto_reply || false,
                name: msg.friend_name,
                avatar: msg.friend_avatar,
                timestamp: msg.timestamp,
                send_time: msg.send_time,
                content: msg.content,
                attachment: msg.attachment,
                id: msg.message_id,
                type: getContentType(msg.content_type)
            });
            // 如果当前消息是当前聊天好友的，标记好友状态为已读
            setFriendUnReadStatus(msg.friend_id, 0);
            translateVisibleMessages($('select[name="input_target_lang"]').val(), 'left');
        } else {
            // 当前账号的其他好友，标红点
            markFriendUnreadDot(msg.friend_id, msg.account_id);
        }
    } else {
        // 非当前账号，账号头像标红点
        markAccountUnreadDot(msg.account_id);
    }
}
</code></pre><p>这个这段逻辑主要包括：</p><ul><li>当前聊天窗口实时追加消息</li><li>非当前好友 → 好友红点</li><li>非当前账号 → 账号红点</li></ul><p>这里之所以要在前端判断account\_id /friend\_id，而不是后端分多钟类型推是因为：</p><ul><li>降低后端推送负责度，而且我觉得在前端判断会更好</li><li>保证前端状态一致性</li><li>方便后续扩展更多UI状态</li></ul><hr/><h3>3.2 关键功能点二：中英文切换与“批量翻译”的实现思路</h3><p>这是一个让我非常满意、也非常适合 AI 协作的功能。</p><h4>3.2.1 我的需求不是“翻译一条消息”</h4><p>而是：</p><ul><li>聊天窗口已有历史消息</li><li>切换语言后</li><li><strong>原文不变</strong></li><li>原文下方显示译文</li><li>支持再次切换目标语言</li></ul><hr/><h4>3.2.2 前端结构设计（AI 协助）</h4><pre><code>&lt;div class="chat-message-bubble"&gt;
    &lt;div class="original-text"&gt;Hello&lt;/div&gt;
    &lt;div class="translated-text text-muted small"&gt;你好&lt;/div&gt;
&lt;/div&gt;
</code></pre><p>AI 在这里给了我一个很重要的建议：</p><blockquote>翻译内容不要覆盖原文，而是“附加”</blockquote><p>如果一开始就让 AI 覆盖原文，后期做多语言切换、撤销翻译、重新翻译，都会非常痛苦。这让体验和可维护性都好很多。</p><h4>3.2.3 切换语言时的 JS 逻辑</h4><pre><code>// Tab 切换事件
$("#collapseTranslate").on('change', '.translate-select', function () {
    let name = $(this).attr('name');
    let value;
    if (name === 'chat_message_auto_translate' || name === 'input_auto_translate') {
        const isChecked = $(this).is(':checked');
        value = isChecked ? 1 : 0;
    } else {
        value = $(this).val();
    }
​
    if (name === 'input_target_lang') {
        translateVisibleMessages(value);
    }
​
    if (name === 'chat_message_target_lang') {
        translateVisibleMessages(value, 'left');
    }
​
    $.post('/chat/change_translate_config', {
        name: name,
        value: value
    }, function (res) {
        if (res.code !== 0) {
            layer.msg(res.msg)
        }
    });
});
​
/**
 * 聊天框内容翻译
 * @param targetLang
 * @param trans_message_type
 */
function translateVisibleMessages(targetLang = 'en', trans_message_type = 'right') {
    const messagesToTranslate = [];
    const selector = '.chat-message-wrapper.chat-message-' + trans_message_type;
    console.log('selector', selector); // 输出拼接的选择器
    console.log('匹配到元素数量:', $(selector).length);
    $(selector).each(function () {
        const $wrapper = $(this);
        const messageId = $wrapper.data('id');
​
        const $bubble = $wrapper.find('.chat-message-bubble');
        const content = $wrapper.find('.chat-message-bubble .original-text').text().trim();
        const cacheKey = `${messageId}_${targetLang}`;
​
        if (!messageId || !content) return;
​
        // 若已缓存则直接渲染
        if (translationCache[cacheKey]) {
            applyTranslatedMessage(messageId, translationCache[cacheKey]);
        } else {
            // 显示 loading 占位
            insertLoadingPlaceholder($bubble);
​
            // 准备发送的内容
            messagesToTranslate.push({ message_id: messageId, content });
        }
    });
​
    console.log('messagesToTranslate', messagesToTranslate);
    if (messagesToTranslate.length === 0) return;
​
    $.ajax({
        url: '/chat/translate/batch',
        type: 'POST',
        contentType: 'application/json',
        data: JSON.stringify({
            messages: messagesToTranslate,
            target_lang: targetLang
        }),
        success: function (res) {
            if (res.code === 0 &amp;&amp; Array.isArray(res.data)) {
                res.data.forEach(item =&gt; {
                    const cacheKey = `${item.message_id}_${targetLang}`;
                    translationCache[cacheKey] = item.translate;
                    applyTranslatedMessage(item.message_id, item.translate);
                });
            }
        }
    });
}
​
/**
 * 翻译内容显示
 * @param messageId
 * @param translation
 */
function applyTranslatedMessage(messageId, translation) {
    const $wrapper = $(`.chat-message-wrapper[data-id="${messageId}"]`);
    const $bubble = $wrapper.find('.chat-message-bubble');
​
    const $translated = $bubble.find('.translated-text');
    if ($translated.length) {
        $translated.text(translation);
    } else {
        $bubble.append(`
            &lt;div class="divider"&gt;&lt;/div&gt;
            &lt;div class="translated-text text-muted small"&gt;${translation}&lt;/div&gt;
        `);
    }
}
</code></pre><p>这段代码是 AI 在我给出 DOM 结构后帮我补全的。</p><hr/><h3>3.3 关键功能点三：复杂 UI 交互（微信式体验）如何落地？</h3><p>比如：</p><ul><li>消息气泡宽度</li><li>时间显示位置</li><li>自己 / 对方对齐方式</li><li>动态按钮事件绑定</li></ul><h4>3.3.1 动态元素事件绑定问题</h4><p>我一开始写的是：</p><pre><code>$('#toggle-friend-info').on('click', ...)
</code></pre><p>AI 很快指出问题：</p><blockquote><strong>这是动态生成的 DOM，需要事件委托</strong></blockquote><p>修正后：</p><pre><code>$(document).on('click', '#toggle-friend-info', function () {
    $('#friend-info-panel').toggleClass('show');
});
</code></pre><p>这是一个<strong>非常典型的“AI 帮你查漏补缺”场景</strong>。</p><hr/><h4>3.3.2 滑出面板相对聊天窗口，而不是页面</h4><p>AI 在我反馈问题后，帮我调整为：</p><pre><code>.chat-panel {
    position: relative;
    overflow: hidden;
}
.friend-info-panel {
    position: absolute;
    right: -260px;
    transition: right .3s;
}
.friend-info-panel.show {
    right: 0;
}
</code></pre><h4>3.3.3 发送消息、接收消息左右分隔</h4><pre><code>.chat-message-wrapper {
    display: flex;
    align-items: flex-start;
    margin-bottom: 12px;
    width: 100%;
}
​
.chat-message-left {
    flex-direction: row;
}
​
.chat-message-right {
    flex-direction: row-reverse;
}
​
.message-block {
    display: inline-flex;
    flex-direction: column;
    max-width: 75%;   /* 让消息区最大占75%宽 */
    word-wrap: break-word;
}
​
/* 自己发的消息（右侧） */
.chat-message-right .message-block {
    display: flex;
    flex-direction: column;
    align-items: flex-end; /* 时间右对齐 */
}
​
/* 对方的消息（左侧） */
.chat-message-left .message-block {
    display: flex;
    flex-direction: column;
    align-items: flex-start; /* 时间左对齐 */
}
​
.chat-message-bubble {
    max-width: 95%;
    padding: 10px 14px;
    border-radius: 16px;
    word-wrap: break-word;
    box-shadow: 0 1px 2px rgba(0, 0, 0, 0.05);
    line-height: 1.5;
}
</code></pre><p>以上这些，基本上都是AI帮我完成调优的。</p><hr/><p><strong>除了以上几个功能点之外，我还实现了</strong></p><ol><li>退出登录聊天窗记忆功能：退出登录，记录上次聊天的对象，再次登录后自动打开最后一次聊天对象所在的分组、tab、聊天窗口、聊天记录</li><li>多语言切换：通过配置切换当前要展示的语言</li><li>快捷回复：添加（文本、图片、视频、语音）、删除、快捷发送</li><li>自动回复：接收到消息自动回复</li><li>翻译配置：支持发送出去的消息和接收到的消息，可以分别配置源语言、翻译为目标语言。比如发出去的是中文，实际对方接收到的是英文；接收到的是英文、韩文，聊天窗显示中文</li><li>未读分组、tab、好友红点标记等</li></ol><p>太多了，具体细节就不一一介绍了，光聊天一个窗口交互就复杂的一批（感觉要钱要少了，orz...</p><h2>四、效果展示</h2><p>登录</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047497315" alt="image-20251223114030780.png" title="image-20251223114030780.png"/></p><p>聊天首页</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047497316" alt="image-20251223114119055.png" title="image-20251223114119055.png" loading="lazy"/></p><p>翻译配置</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047497317" alt="image-20251223114155843.png" title="image-20251223114155843.png" loading="lazy"/></p><p>自动回复配置</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047497318" alt="image-20251223114232951.png" title="image-20251223114232951.png" loading="lazy"/></p><h2>五、总结</h2><h3>5.1 AI写代码的优缺点</h3><p>基于我这次和AI对话的实战来看，优点是非常明显的</p><ul><li>前端效率提升巨大</li><li>UI 微调不再痛苦</li><li>可以快速试错</li><li>非前端工程师也能做出“像样界面”</li></ul><p>但是<strong>缺点也很明显</strong>：</p><ul><li>不会主动考虑性能极限</li><li>容易“写得能用，但不够优雅”</li><li>架构必须你来定</li><li>需要你具备基本判断能力</li></ul><h3>5.2 其他</h3><p>AI的使用远不限于此，如果你愿意学习如何使用：</p><ul><li>描述需求</li><li>提供上下文</li><li>精准反馈</li><li>与 AI 协作</li></ul><p>你会发现：<strong>一个人，可以完成过去一个小团队才能完成的事情。</strong></p><h2>六、写到最后</h2><p>对我来说，AI 并不是让我“变成前端工程师”，而是让我在有限时间内，把一个本来可能妥协的项目，<strong>做到自己满意为止</strong>。</p><p>从某些方面来说，AI让我变的更高效，从之前排查问题靠百度、靠在社区提问，到现在有问题问AI，AI的准确率还不错；从之前靠自己经验写出一段逻辑代码，到现在请AI帮我优化，大大提高了我代码的质量；AI是个好东西，咱们程序员还是要擅于利用它，这样才有更多的时间“摸鱼"（提高自己）啊</p><blockquote>你有没有用 AI 真正写过项目呢？欢迎评论聊聊。</blockquote>]]></description></item><item>    <title><![CDATA[Linux 麒麟系统安装 libgomp-7.3.0 rpm 包步骤 无邪的课本 ]]></title>    <link>https://segmentfault.com/a/1190000047498657</link>    <guid>https://segmentfault.com/a/1190000047498657</guid>    <pubDate>2025-12-23 20:02:06</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>​</p><p> 1. 找到 rpm 文件</p><p><strong>安装包下载：</strong><a href="https://link.segmentfault.com/?enc=PvcYrfMpgX2m1sybq73IKg%3D%3D.fv1Xzk7OPMJg%2BNUWGGXNyd8YnXIxywrUmGek879FhYZtybReuZoGU%2B0KoxGqUDoB" rel="nofollow" title="https://pan.quark.cn/s/961c1c11019b" target="_blank">https://pan.quark.cn/s/961c1c11019b</a>，下载完一般在 <strong>下载</strong>​ 目录，文件名：</p><pre><code>libgomp-7.3.0-20190804.35.p06.ky10.x86_64.rpm</code></pre><p>先确认一下：</p><pre><code>ls ~/下载/libgomp*</code></pre><p>英文环境：</p><pre><code>ls ~/Downloads/libgomp*</code></pre><ul><li><ul><li>*</li></ul></li></ul><h3>2. 打开终端</h3><p>右键桌面 → “打开终端”，或者按 <code>Ctrl + Alt + T</code>。</p><ul><li><ul><li>*</li></ul></li></ul><h3>3. 切换到 rpm 所在目录</h3><pre><code>cd ~/下载</code></pre><p>英文路径：</p><pre><code>cd ~/Downloads</code></pre><ul><li><ul><li>*</li></ul></li></ul><h3>4. 检查是否已安装 libgomp</h3><p>这个库一般是 GCC 自带的，但你可以用 rpm 查一下：</p><pre><code>rpm -q libgomp</code></pre><p>如果提示 “package libgomp is not installed” 就是没装。</p><ul><li><ul><li>*</li></ul></li></ul><h3>5. 安装 rpm 包</h3><p><strong>推荐方法</strong>（自动解决依赖）：</p><pre><code>sudo yum install ./libgomp-7.3.0-20190804.35.p06.ky10.x86_64.rpm</code></pre><p>注意 <code>./</code> 别漏，意思是装当前目录的这个文件。</p><p>如果一定要用 rpm 装（不推荐，因为容易缺依赖）：</p><pre><code>sudo rpm -ivh libgomp-7.3.0-20190804.35.p06.ky10.x86_64.rpm</code></pre><p>如果报错缺少依赖，就用 yum 补上，比如：</p><pre><code>sudo yum install gcc</code></pre><ul><li><ul><li>*</li></ul></li></ul><h3>6. 验证安装结果</h3><p>用 rpm 查询确认：</p><pre><code>rpm -q libgomp</code></pre><p>应该能看到版本号：</p><pre><code>libgomp-7.3.0-20190804.35.p06.ky10.x86_64</code></pre><p>或者用：</p><pre><code>ldconfig -p | grep libgomp</code></pre><p>能看到路径就说明安装成功。</p><ul><li><ul><li>*</li></ul></li></ul><h3>7. 常见问题</h3><ul><li><strong>权限不够</strong>：命令前加 <code>sudo</code>。</li><li><strong>依赖缺失</strong>：优先用 <code>yum install</code> 安装 rpm 包，让系统自动找依赖。</li><li><p><strong>已有其他版本冲突</strong>：可先卸载旧的：</p><pre><code>sudo yum remove libgomp</code></pre></li></ul><ul><li><strong>安装后程序仍找不到库</strong>：执行 <code>sudo ldconfig</code> 更新动态链接库缓存。</li></ul><p>​</p>]]></description></item><item>    <title><![CDATA[告别“感觉选人”：AI重构招聘的效率、精准与体验闭环 爱跑步的香蕉_cKtiNz ]]></title>    <link>https://segmentfault.com/a/1190000047498660</link>    <guid>https://segmentfault.com/a/1190000047498660</guid>    <pubDate>2025-12-23 20:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>告别“感觉选人”：AI重构招聘的效率、精准与体验闭环<br/>AI得贤招聘官<br/>“AI+HR到底有什么价值？”这是很多HR的困惑。但真正值得警惕的，不是对AI价值的迷茫，而是招聘中的主观判断正带来失控风险——简历越收越多、面试轮次越长，最终选人却难逃“我觉得这个人还可以”的主观定论。当“感觉”成为决策依据，不确定性便成了招聘最大的隐患。比起纠结“AI能不能用”，更该聚焦“AI已能确定性解决的招聘痛点”。</p><p>一、第一阶段：自动化替代，解放低价值事务<br/>若HR团队仍将大量时间耗费在筛简历、回消息、催简历、同步系统等机械事务上，AI的核心价值便是“替代重复劳动”。AI人才寻访智能体并非简单的“消息机器人”，而是能自主执行招聘动作的完整系统：<br/>•即启即用：30-60秒完成初始化，全程无需人工值守；<br/>•自动筛选：按企业预设条件自主操作，精准识别匹配候选人；<br/>•拟人化沟通：模拟真人语气问答，不适配时即时友好退出；<br/>•全量响应：自动遍历未读信息，逐条个性化回复，不漏人不漏消息；<br/>•智能补全：信息不足时主动索取简历，沟通自然不生硬；<br/>•系统同步：简历自动入库ATS，生成完整候选人档案。<br/>这一阶段，AI以机器替代机械流程，将招聘效率提升10-100倍，让HR从低价值事务中解放，聚焦核心工作。<br/>二、第二阶段：精准评估，让决策有迹可循<br/>拉开企业招聘差距的，从来不是效率，而是决策是否有科学依据。很多企业不缺候选人，却始终无法明确“这个人到底好不好”。第六代AI面试智能体的核心价值，便是将“主观选人”升级为“可量化、可验证的精准评估”，让打分成为直接支撑决策的依据：<br/>•双重验证：支持与客户开展背靠背人机对比实验，同时通过效标效度与重测稳定信度双重心理学指标检验；<br/>•全流程精准：精准并非口号，而是贯穿面试全程的系统能力：<br/>￮一问多能：单题同步评估多项胜任力，无缝衔接初筛与技术复试，效率提升50%以上；<br/>￮自由追问：依据候选人实时回答生成针对性问题，像资深面试官般深挖核心能力；<br/>￮简历深挖：自动识别简历模糊点与风险点，生成递进式提问，防范造假与信息遗漏；<br/>￮全维度覆盖：兼顾通用胜任力与编程、算法、财务等专业领域精准出题，同步解放HR与专业面试官。<br/>第六代AI面试智能体的发布，标志着AI面试从“看起来聪明”迈向“用起来确定”。<br/>三、第三阶段：拟人化体验，塑造雇主品牌名片<br/>糟糕的AI面试体验会劝退优质候选人，第六代AI面试智能体将“拟人化交互”做到极致，让面试成为雇主品牌的加分项：<br/>•懂情绪的交互：识别候选人语速、情绪与表达节奏，人性化引导其充分发挥，避免因紧张失常；<br/>•无断点对话：自动识别回答状态，自然衔接下一问题，体验贴近真人交流；<br/>•沉浸式视觉：语音与口型高度同步，告别“纸片人”式的割裂感；<br/>•实时答疑：候选人可随时咨询岗位、福利等信息，AI精准解答，提升入职意愿。<br/>此时，AI面试不再是单纯的筛选工具，更成为传递企业价值、塑造雇主品牌的重要载体。<br/>四、实践验证：头部组织的共同选择<br/>AI招聘解决方案已服务上千家世界五百强及知名企事业单位，获得浙江大学、上海交通大学等顶尖高校认可。其在不同行业、不同场景中的成熟应用，充分证明了技术的可靠性与适配性，为企业解决招聘痛点提供了可落地的方案。<br/>AI时代的招聘，核心是用技术破解效率、精准、体验三大难题。当AI替代机械劳动、提供决策依据、塑造品牌体验形成闭环，招聘将彻底摆脱“凭感觉”的风险，成为驱动企业人才竞争力的核心引擎。</p>]]></description></item><item>    <title><![CDATA[告别产销服割裂！AI CRM如何破解先进制造业增长困局？ 爱听歌的金针菇 ]]></title>    <link>https://segmentfault.com/a/1190000047498513</link>    <guid>https://segmentfault.com/a/1190000047498513</guid>    <pubDate>2025-12-23 19:03:51</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在高端装备、半导体、工业机器人等先进制造领域，企业的增长焦虑往往藏在“看不见的流程断点”里：</p><p>销售团队为非标<strong>报价反复核算</strong>，一周才能给出方案，客户早已转向竞品；售后团队<strong>被动等待</strong>故障报修，设备停机一天就损失几十万；生产部门凭经验排产，要么库存积压，要么订单来了缺料延误；更别提跨部门<strong>数据孤岛</strong>，客户需求、生产进度、维保记录无法互通，决策全靠“拍脑袋”。</p><p>当市场竞争从“产品比拼”升级为“全链路服务比拼”，传统CRM早已跟不上先进制造业的发展节奏。而以珍客AI CRM为代表的AI智能CRM的出现，正将“产销服协同”从口号落地为可落地的增长引擎，精准破解行业核心痛点。</p><h2>先搞懂：先进制造业的痛，AI CRM为何能精准命中？</h2><p>不同于消费行业的标准化营销，先进制造业普遍面临“项目型+批量型混合销售”“设备维保依赖度高”“出海合规要求严”“数据链路长”等特殊挑战。</p><p>传统CRM只聚焦销售环节，而AI CRM的核心价值，在于打通“<strong>客户需求-销售转化-生产交付-售后维保</strong>”全链路，用AI能力实现数据驱动的智能决策。</p><p>某工业机器人企业的转型案例颇具代表性：此前该企业因报价周期长（平均5天）、故障响应慢（SLA达标率仅60%）、需求预测不准（排产准确率58%），客户流失率高达18%。引入珍客AI CRM后，仅用8个月就实现报价周期缩短75%、SLA达标率提升至95%、客户流失率降至8%，营收同比增长22%。</p><p>这背后，正是AI CRM针对先进制造业的场景化解决方案在发挥作用。</p><h2>四大核心场景：AI CRM如何重构先进制造业增长逻辑？（以珍客AI CRM为例）</h2><h3>场景一：智能报价+合同风控，把“成交卡点”变“转化加速器”</h3><p>非标定制是先进制造业的常态，也是销售转化的核心卡点。客户需求五花八门，销售需要反复对接技术、财务部门核算成本，不仅耗时久，还容易出现报价差错。</p><p>AI CRM的<strong>CPQ+AI报价功能</strong>，彻底解决了这一问题：只需输入客户的需求参数、采购量、账期要求，系统就能自动测算成本、毛利，参考历史报价、竞品数据生成精准的报价区间和议价策略，3分钟内就能输出完整的报价单和技术规格书。</p><p>更关键的是<strong>合同风控环节</strong>，AI能自动扫描交付期、质保条款、违约责任等核心内容，高亮不合理违约金、模糊验收标准等风险点，并对接法务库给出修订建议，把合同风险拦截在签约前。签约后，系统还能自动同步至ERP/MES系统生成生产工单，实现“报价-签约-生产”无缝衔接。</p><h3>场景二：预测性维保+智能派单，从“被动救火”到“主动守护”</h3><p>对先进制造业而言，设备停机的损失往往难以估量。传统售后模式“客户报修-人工派单-工程师上门”，响应慢、效率低，很容易引发客户不满。</p><p>AI CRM通过<strong>接入设备IoT传感器数据</strong>，实现了“预测性维保”的跨越式升级：实时监测设备的振动、温度、运行时长等指标，一旦出现异常波动，系统会自动生成预警信息和维保工单，提前安排工程师上门检修，把故障消灭在萌芽状态。某半导体设备企业引入该功能后，设备非计划停机时间减少了30%，客户满意度提升25%。</p><p>同时，AI还能根据客户等级、设备型号、故障类型，以及工程师的技能特长、地理位置，自动匹配最优派单方案，避免“专业不对口”“距离过远”导致的效率浪费。7×24小时AI客服还能解答常见问题，复杂问题无缝转接人工，进一步提升售后响应效率。</p><p><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdmOec" alt="珍客AI CRM 智能工单服务" title="珍客AI CRM 智能工单服务"/></p><h3>场景三：需求预测+交期预警，让生产排产“更精准不盲猜”</h3><p>生产与销售脱节，是先进制造业的另一大痛点：销售接了急单，生产部门却没有产能；生产部门备了大量物料，市场需求又突然变化，导致库存积压。</p><p>AI CRM整合了订单数据、历史销售数据、市场趋势、客户反馈等<strong>多维度信息</strong>，通过AI算法生成月度、季度滚动需求预测，预测准确率可达85%以上。生产部门可以根据预测结果提前备料、规划产能，避免“缺料”或“积压”的尴尬。</p><p>针对订单交付环节，系统还能<strong>实时监控</strong>生产进度、物料库存、物流状态，一旦出现缺料、产能不足、物流延误等问题，立即自动预警，并生成备选方案（如外协生产、替代物料），确保交期达成率稳定在90%以上。</p><h3>场景四：360°客户视图+流失预警，守住高价值客户资产</h3><p>先进制造业的客户生命周期长、价值高，一旦流失，损失巨大。但传统模式下，客户的工商信息、采购记录、沟通历史、售后工单等数据分散在不同系统，无法形成完整画像，更难及时发现流失信号。</p><p>AI CRM能自动聚合多源数据，<strong>生成动态的客户360°视图和关系图谱</strong>，清晰标注客户的行业赛道、技术偏好、采购周期、决策链角色、生命周期价值（CLV）。同时，系统会实时监测客户沟通频次下降、项目停滞、竞品接触等风险信号，一旦触发预警，立即推送挽回建议给销售团队，帮助企业守住高价值客户。某高端装备企业借助这一功能，客户流失率下降了20%，CLV提升了35%。</p><p><img width="723" height="411" referrerpolicy="no-referrer" src="/img/bVdmuXq" alt="珍客AI CRM 客户360度全景视图" title="珍客AI CRM 客户360度全景视图" loading="lazy"/></p><h2>先进制造业落地AI CRM：找对路径，少走弯路</h2><p>对先进制造企业而言，AI CRM不是“一次性采购的工具”，而是“分阶段落地的转型项目”。想要实现价值最大化，建议遵循“先试点、再推广”的路径：</p><p>第一步：数据底座建设。先打通CRM与ERP、MES、IoT、售后系统，统一客户ID和主数据，完成历史数据清洗，为AI能力落地打好基础。</p><p>第二步：试点场景上线。优先选择报价慢、售后响应差、需求预测不准等核心痛点场景试点，明确PoC周期（4-8周）和量化目标（如报价时长缩短70%），快速验证价值。</p><p>第三步：规模化推广。试点成功后，逐步覆盖智能营销、供应链协同、合规风控等场景，完成全链路闭环，同时持续迭代AI模型，优化流程。</p><h2>结语：AI CRM，不止是销售工具，更是增长引擎</h2><p>在先进制造业迈向“智能制造”的浪潮中，竞争的核心早已从“产品力”延伸到“全链路服务力”。AI CRM的价值，正是通过数据打通与智能算法，打破产销服之间的壁垒，让客户需求驱动生产，让生产进度匹配交付，让售后维保前置化，最终实现“降本、增效、增收”的核心目标。</p><p>如果你所在的企业正面临报价慢、交期准、售后难、客户流失等痛点，不妨思考：你的“产销服协同”是否还存在断点？AI CRM或许正是破解增长困局的关键抓手</p>]]></description></item><item>    <title><![CDATA[京东金融鸿蒙端部署AI超分模型实践 京东云开发者 ]]></title>    <link>https://segmentfault.com/a/1190000047498558</link>    <guid>https://segmentfault.com/a/1190000047498558</guid>    <pubDate>2025-12-23 19:02:54</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2><strong>1. 背景</strong></h2><p><strong>这可能是全网第一篇完整讲解鸿蒙端使用CANN部署AI模型的文章, 满满干货。</strong></p><p>社区作为用户交流、信息传递的核心载体，图片内容（如理财产品截图、投资经验分享配图、用户互动评论图片等）的展示质量直接影响用户的信息获取效率与平台信任感。从京东金融App社区的业务需求来看，当前用户上传图片普遍存在多样性失真问题：部分用户通过老旧设备拍摄的图片分辨率较低，部分用户为节省流量选择低画质压缩上传，还有部分截图类内容因原始来源清晰度不足导致信息模糊（如理财产品收益率数字、合同条款细节等），这些问题不仅降低了内容可读性，还可能因信息传递不清晰引发用户误解。</p><p>京东金融App团队已完成Real-ESRGAN-General-x4v3超分辨率模型在安卓端的部署，能够针对性提升评论区、内容详情页、个人主页等核心场景的图片清晰度，从视觉体验层面优化用户留存与互动意愿。</p><p>ESRGAN-General-x4v3模型在安卓端的部署，采用的是ONNX框架，该方案已有大量公开资料可参考，且取得显著业务成效。但鸿蒙端部署面临核心技术瓶颈：鸿蒙系统不支持ONNX框架，部署端侧AI仅能使用华为自研的CANN（Compute Architecture for Neural Networks）架构，且当前行业内缺乏基于CANN部署端侧AI的公开资料与成熟方案，全程需技术团队自主探索。接下来我会以ESRGAN-General-x4v3为例, 分享从模型转换(NPU亲和性改造)到端侧离线模型部署的全部过程。</p><h2><strong>2. 部署前期准备</strong></h2><h3><strong>2.1 离线模型转换</strong></h3><p>CANN Kit当前仅支持Caffe、TensorFlow、ONNX和MindSpore模型转换为离线模型，其他格式的模型需要开发者自行转换为CANN Kit支持的模型格式。模型转换为OM离线模型，移动端AI程序直接读取离线模型进行推理。</p><h4><strong>2.1.1 下载CANN工具</strong></h4><p>从鸿蒙开发者官网下载 <a href="https://link.segmentfault.com/?enc=Qz5BSTaM%2BJ6SauiK9qmCwA%3D%3D.SLiWu%2B2SJceBdooE0lydubbHiSWXaBNNDxeN%2B2O8qSBO63jIqCs3cUrsDlh9dmS0Ig2PwZp9mXnWiZLd2yCgagmIkJYfdjM%2B8gj6vs6lpl6X9DFTXg3SZ0I8eyctK0VKMrpBzXJgT4ETCho%2BmiassoBGPqUDVulhNmqJWPPs20tZBGL5zkBjG7Vxa%2BntpjHl2yFjlGsmGtWWeHvU%2BBEsxJcAd9WAVd%2BiJxD0PiIPrm8efWHOOw4va0TzlruUhtFiywnVJb8c3GmMZTJz4EQP3QxlV%2FT0w%2Ba%2FHro9Ia%2Bs1qqTwaXm3%2Ft13MqYuk84ukVgQ0OoMCjVX9iXNQXDPOPV03%2BG2o8EHPphvWUmM1FzVpn2FcuUQ%2Bs7B8G3hB97uGr%2BaVNTuqbWiPd1M30Bgr6qkC2lcUFbF%2FHaT71ntAbXAIZRnmPuEbc1HAacYW%2FWQ%2FScv7V8GJfr%2BbXJ5o8AxJ%2F3eKLBgGz1ieAlt86TVlhLlU9i%2FECL1sdV%2FFgp%2FxQe5GxF" rel="nofollow" target="_blank">DDK-tools-5.1.1.1 </a>, 解压使用Tools下的OMG工具，将ONNX、TensorFlow模型转换为OM模型。(OMG工具位于Tools下载的tools/tools\_omg下，<strong>仅可运行在64位Linux平台上</strong>。)</p><p>﻿</p><h4><strong>2.1.2 下载ESRGAN-General-x4v3模型文件</strong></h4><p>从<a href="https://link.segmentfault.com/?enc=QDlCbgGpIMhrrCxEFyeqVg%3D%3D.9VGffCUIDFsR2CYy28YTq%2FJgJ01PDxj6RCSCCJFYlW7mD40kx%2BO0pc6mvbO8xMQmbfSqvbgdux8cL9eGUZmkp1EAoqz0YXL02jgjsSbDvEg%3D" rel="nofollow" target="_blank">https://aihub.qualcomm.com/compute/models/real\_esrgan\_general\_x4v3 </a>下载模型的onnx文件.</p><p>注意: 下载链接中的a8a8的量化模型使用了高通的算子(亲测无法转换), CANN工具无法进行转换, 因此请下载float的量化模型。</p><p><strong>下载后有两个文件:</strong></p><p>•model.onnx文件 (模型结构): 包含计算图、opset版本、节点配置等，文件较小。</p><p>•model.data文件 (权重数据): 包含神经网络参数、权重等，文件较大。</p><p>现在我们需要把这种分离文件格式的模型合并成一个文件,后续的操作都使用这个。</p><p><strong>合并文件:</strong></p><p>请使用JoyCode写个合并脚本即可, 提示词: 请写一个脚本, 把onnx模型文件的.onnx和.data文件合并。</p><h4><strong>2.1.3 OM模型转换</strong></h4><p><strong>1. ONNX opset 版本转换</strong></p><p>当前使用CANN进行模型转换, 支持ONNX opset版本7\~18（最高支持到V1.13.1）, 首先需要查看原始的onnx模型的opset版本是否在支持范围, 这里我们使用<a href="https://link.segmentfault.com/?enc=GszOEgTSGae6nh7zp7yIkA%3D%3D.7Pw8WSHdTCNvoJq5HL5IqcCrNbIbAwky%2FHWPsBI4UBxJhGoPSozElkHZTlCmgvSl" rel="nofollow" target="_blank">Netron</a>(点击下载)可视化工具进行查看。</p><p>﻿<img referrerpolicy="no-referrer" src="/img/remote/1460000047498560" alt="在这里插入图片描述" title="在这里插入图片描述"/></p><p>﻿﻿</p><p>﻿</p><p>目前该模型使用的opset版本是20, 因此我们需要把该模型的opset版本转成18, 才可以用CANN转换成鸿蒙上可部署的模型。请使用JoyCode写个opset转换脚本即可, 提示词: 请写一个脚本, 把onnx模型文件的opset版本从20转换成18。</p><p>﻿</p><p><strong>2. OM离线模型</strong>****</p><p>命令行中的参数说明请参见<a href="https://link.segmentfault.com/?enc=svTxDHXoLS3aYvWED4oIYQ%3D%3D.Z47MCSv8nMZ%2BBlMoKvxXlxdth91R1nfDWbhk%2FzIg%2FX6LNPRFKyKn2xLuRUOFMDwsDfPdg2x7rFzsm6cvtnPILRquPNBYrFcXvxGx3OgDEL%2BF0jCSEIf7uoGMH%2B8p7U0b" rel="nofollow" target="_blank">OMG参数</a>，转换命令：</p><pre><code>./tools/tools_omg/omg --model new_model_opset18.onnx --framework 5 --output ./model
</code></pre><p>转换完成后, 生成model.om的模型文件, 该模型文件就是鸿蒙上可以正常使用的模型文件</p><h3><strong>2.2 查看模型的输入/输出张量信息</strong></h3><p>部署AI模式时, 我们需要确认模型的输入张量和输出张量信息, 请使用JoyCode编写一个脚本, 确定输入输出张量信息, 提示词: 写一个脚本查看onnx模型的输入输出张量信息。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047498561" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h4><strong>2.2.1 输入张量</strong></h4><p>BCHW格式, 是深度学习中常见的张量维度排列格式, 在图像处理场景中:</p><p>•B (Batch): 批次大小 - 一次处理多少个样本。</p><p>•C (Channel): 通道数 - 图像的颜色通道数。</p><p>•H (Height): 高度 - 图像的像素高度。</p><p>•W (Width): 宽度 - 图像的像素宽度。</p><p>由此可以得出结论, 该模型1个批次处理1张宽高为128*128的RGB图片(因为C是3,因此不包含R通道)。</p><p>﻿</p><h4><strong>2.2.2 输出张量</strong></h4><p>该模型1个批次输出1张宽高为512*512的RGB图片。</p><p>﻿</p><h4><strong>2.2.3 BCHW和BHWC格式的区别:</strong></h4><p>超分模型中的BCHW和BHWC是两种不同的张量存储格式，主要区别在于通道维度的位置：</p><p>﻿</p><p>•<strong>BCHW格式（Batch-Channel-Height-Width）</strong></p><p>◦维度顺序：[批次, 通道, 高度, 宽度]</p><p>◦内存布局：通道维度在空间维度之前</p><p>◦常用框架：PyTorch、TensorRT等</p><p>示例: 形状为 (1, 3, 256, 256) 的RGB图像</p><p><strong>内存中的存储顺序：</strong> R通道的所有像素 -&gt; G通道的所有像素 -&gt; B通道的所有像素</p><pre><code>tensor_bchw = torch.randn(1, 3, 256, 256)
访问第一个像素的RGB值需要跨越不同的内存区域
pixel_0_0_r = tensor_bchw[0, 0, 0, 0]  # R通道
pixel_0_0_g = tensor_bchw[0, 1, 0, 0]  # G通道  
pixel_0_0_b = tensor_bchw[0, 2, 0, 0]  # B通道
</code></pre><p>•<strong>BHWC格式（Batch-Height-Width-Channel）</strong></p><p>◦维度顺序：[批次, 高度, 宽度, 通道]</p><p>◦内存布局：通道维度在最后，像素的所有通道连续存储</p><p>◦常用框架：TensorFlow、OpenCV等</p><p>示例：形状为 (1, 256, 256, 3) 的RGB图像</p><p>内存中的存储顺序：像素(0,0)的RGB -&gt; 像素(0,1)的RGB -&gt; ... -&gt; 像素(0,255)的RGB -&gt; 像素(1,0)的RGB...</p><pre><code>tensor_bhwc = tf.random.normal([1, 256, 256, 3])
# 访问第一个像素的RGB值在连续的内存位置
pixel_0_0_rgb = tensor_bhwc[0, 0, 0, :]  # [R, G, B]
</code></pre><p>﻿</p><h2><strong>3. 鸿蒙端部署核心步骤</strong></h2><h3><strong>3.1 创建项目</strong></h3><p>1.创建DevEco Studio项目，选择“Native C++”模板，点击“Next”。</p><p>﻿<img referrerpolicy="no-referrer" src="/img/remote/1460000047498562" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><p>﻿</p><p>2.按需填写“Project name”、“Save location”和“Module name”，选择“Compile SDK”为“5.1.0(18)”及以上版本，点击“Finish”。</p><p>﻿<img referrerpolicy="no-referrer" src="/img/remote/1460000047498563" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h3><strong>3.2 配置项目NAPI</strong></h3><p>CANN部署只提供了C++接口, 因此需要使用NAPI, 编译HAP时，NAPI层的so需要编译依赖NDK中的libneural\_network\_core.so和libhiai\_foundation.so。</p><p>﻿</p><p><strong>头文件引用</strong></p><p>按需引用NNCore和CANN Kit的头文件。</p><pre><code>#include "neural_network_runtime/neural_network_core.h"
#include "CANNKit/hiai_options.h"
</code></pre><p><strong>编写CMakeLists.txt</strong></p><p>CMakeLists.txt示例代码如下。</p><pre><code>cmake_minimum_required(VERSION 3.5.0)
project(myNpmLib)

set(NATIVERENDER_ROOT_PATH ${CMAKE_CURRENT_SOURCE_DIR})

include_directories(${NATIVERENDER_ROOT_PATH}
                    ${NATIVERENDER_ROOT_PATH}/include)

include_directories(${HMOS_SDK_NATIVE}/sysroot/usr/lib)
FIND_LIBRARY(cann-lib hiai_foundation)

add_library(imagesr SHARED HIAIModelManager.cpp ImageSuperResolution.cpp)
target_link_libraries(imagesr PUBLIC libace_napi.z.so
    libhilog_ndk.z.so
    librawfile.z.so
    ${cann-lib}
    libneural_network_core.so
    )
</code></pre><h3><strong>3.3 集成模型</strong></h3><p>模型的加载、编译和推理主要是在native层实现，应用层主要作为数据传递和展示作用。模型推理之前需要对输入数据进行预处理以匹配模型的输入，同样对于模型的输出也需要做处理获取自己期望的结果</p><p>﻿<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047498564" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h4><strong>3.3.1 加载离线模型</strong></h4><p>为了让App运行时能够读取到模型文件和处理推理结果，需要先把离线模型和模型对应的结果标签文件预置到工程的“entry/src/main/resources/rawfile”目录中。</p><p>﻿<img referrerpolicy="no-referrer" src="/img/remote/1460000047498565" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><p>﻿</p><p>在App应用创建时加载模型:</p><p>1.native层读取模型的buffer。</p><pre><code>const char* modelPath = "imagesr.om";
RawFile *rawFile = OH_ResourceManager_OpenRawFile(resourceMgr, modelPath);
long modelSize = OH_ResourceManager_GetRawFileSize(rawFile);
std::unique_ptr&lt;uint8_t[]&gt; modelData = std::make_unique&lt;uint8_t[]&gt;(modelSize);
int res = OH_ResourceManager_ReadRawFile(rawFile, modelData.get(), modelSize);
</code></pre><p>2.使用模型的buffer, 调用OH\_NNCompilation\_ConstructWithOfflineModelBuffer创建模型的编译实例</p><pre><code>HiAI_Compatibility compibility = HMS_HiAICompatibility_CheckFromBuffer(modelData, modelSize);
OH_NNCompilation *compilation = OH_NNCompilation_ConstructWithOfflineModelBuffer(modelData, modelSize);
</code></pre><p>3.（可选）根据需要调用HMS\_HiAIOptions\_SetOmOptions接口，打开维测功能（如Profiling）。</p><pre><code>const char *out_path = "/data/storage/el2/base/haps/entry/files";
HiAI_OmType omType = HIAI_OM_TYPE_PROFILING;
OH_NN_ReturnCode ret = HMS_HiAIOptions_SetOmOptions(compilation, omType, out_path);     
</code></pre><p>4.设置模型的deviceID。</p><pre><code>size_t deviceID = 0;
const size_t *allDevicesID = nullptr;
uint32_t deviceCount = 0;
OH_NN_ReturnCode ret = OH_NNDevice_GetAllDevicesID(&amp;allDevicesID, &amp;deviceCount);

for (uint32_t i = 0; i &lt; deviceCount; i++) {
    const char *name = nullptr;
    ret = OH_NNDevice_GetName(allDevicesID[i], &amp;name);
    if (ret != OH_NN_SUCCESS || name == nullptr) {
        OH_LOG_ERROR(LOG_APP, "OH_NNDevice_GetName failed");
        return deviceID;
    }
    if (std::string(name) == "HIAI_F") {
        deviceID = allDevicesID[i];
        break;
    }
}

ret = OH_NNCompilation_SetDevice(compilation, deviceID);
</code></pre><p>5.调用OH\_NNCompilation\_Build，执行模型编译。</p><pre><code>ret = SetModelBuildOptions(compilation);
ret = OH_NNCompilation_Build(compilation);
</code></pre><p>6.调用OH\_NNExecutor\_Construct，创建模型执行器。</p><pre><code>executor_ = OH_NNExecutor_Construct(compilation);
</code></pre><p>7.调用OH\_NNCompilation\_Destroy，释放模型编译实例。</p><p>﻿</p><h4><strong>3.3.2 准备输入输出****Tensor</strong></h4><p>1.处理模型的输入，模型的输入为1<em>3</em>128*128格式(BCHW) Float类型的数据, 需要把RGB 数据转成BCHW格式并进行归一化。</p><pre><code>从图片中读取的RGB数据为BHWC,需要转换成模型可以识别的BCHW
/**
 * 把bhwc转成bchw
 */
uint8_t *rgbData = static_cast&lt;uint8_t*&gt;(data);
uint8_t *floatData_tmp = new uint8_t[length];
for (int c = 0; c &lt; 3; ++c) {
    for (int h = 0; h &lt; 128; ++h) {
        for (int w = 0; w &lt; 128; ++w) {
            // HWC 索引: h * width * channels + w * channels +c 
            int hwc_index = h * 128 * 3 + w * 3 + c;
            // CHW 索引: C * height * width + h* width + W
            int chw_index = c * 128 * 128 + h * 128 + w;
            floatData_tmp[chw_index] = rgbData[hwc_index];
        }
    }
}
//归一化
float *floatData = new float[length];
for (size_t i = 0; i &lt; length; ++i) {
    floatData[i] = static_cast&lt;float&gt;(floatData_tmp[i])/ 255.0f;
}
</code></pre><p>2.创建模型的输入和输出Tensor，并把应用层传递的数据填充到输入的Tensor中</p><pre><code>// 准备输入张量
size_t inputCount = 0;
OH_NN_ReturnCode ret = OH_NNExecutor_GetInputCount(executor_, &amp;inputCount);
for (size_t i = 0; i &lt; inputCount; ++i) {
    NN_TensorDesc *tensorDesc = OH_NNExecutor_CreateInputTensorDesc(executor_, i);
    NN_Tensor *tensor = OH_NNTensor_Create(deviceID_, tensorDesc);
    if (tensor != nullptr) {
        inputTensors_.push_back(tensor);
    }
    OH_NNTensorDesc_Destroy(&amp;tensorDesc);
}


ret = SetInputTensorData(inputTensors_, inputData);

// 准备输出张量
size_t outputCount = 0;
ret = OH_NNExecutor_GetOutputCount(executor_, &amp;outputCount);

for (size_t i = 0; i &lt; outputCount; i++) {
    NN_TensorDesc *tensorDesc = OH_NNExecutor_CreateOutputTensorDesc(executor_, i);
    NN_Tensor *tensor = OH_NNTensor_Create(deviceID_, tensorDesc);
    if (tensor != nullptr) {
        outputTensors_.push_back(tensor);
    }
    OH_NNTensorDesc_Destroy(&amp;tensorDesc);
}
if (outputTensors_.size() != outputCount) {
    DestroyTensors(inputTensors_);
    DestroyTensors(outputTensors_);
    OH_LOG_ERROR(LOG_APP, "output size mismatch.");
    return OH_NN_FAILED;
}
</code></pre><p>﻿</p><h4><strong>3.3.3 进行推理</strong></h4><p>调用OH\_NNExecutor\_RunSync，完成模型的同步推理。</p><pre><code>OH_NN_ReturnCode ret = OH_NNExecutor_RunSync(executor_, inputTensors_.data(), inputTensors_.size(),
                                                 outputTensors_.data(), outputTensors_.size());
</code></pre><p>说明</p><p>•如果不更换模型，则首次编译加载完成后可多次推理，即一次编译加载，多次推理。</p><p>•所有关于模型的操作, 均无法多线程执行。</p><p>﻿</p><h4><strong>3.3.4 获取模型输出并处理数据</strong></h4><p>1.调用OH\_NNTensor\_GetDataBuffer，获取输出的Tensor，在输出Tensor中会得到模型的输出数据。</p><pre><code>// 获取第一个输出张量
NN_Tensor* tensor = outputTensors_[0];

// 获取张量数据缓冲区
void *tensorData = OH_NNTensor_GetDataBuffer(tensor);

// 获取张量大小
size_t size = 0;
OH_NN_ReturnCode ret = OH_NNTensor_GetSize(tensor, &amp;size);

float *tensorDataOutput = (float*)malloc(size);
// 将tensorData的数据一次性复制到tensorDataOutput中
memcpy(tensorDataOutput, tensorData, size);
</code></pre><p>﻿</p><p>2.对Tensor输出数据进行相应的处理</p><p>把模型输出的BCHW转成BHWC, 并进行反归一化处理</p><p>﻿</p><pre><code>//把模型输出的BCHW转成BHWC
float *outputResult = static_cast&lt;float *&gt;(tensorData);
float *output_tmp = new float[size/sizeof(float)];
for (int h = 0; h &lt; 512; ++h) {
    for (int w = 0; w &lt; 512; ++w) {
        for (int c = 0; c &lt; 3; ++c) {
            output_tmp[h * 512 * 3 + w* 3 + c] = outputResult[c * 512 * 512 + h * 512 + w];
        }
    }
}
std::vector&lt;float&gt; output(size / sizeof(float), 0.0);
for (size_t i = 0; i &lt; size / sizeof(float); ++i) {
    output[i] = output_tmp[i];
}
delete [] output_tmp;


 // 计算总的数据大小
size_t totalSize = output.size();

// 分配结果数据内存
std::unique_ptr&lt;uint8_t[]&gt; result_data = std::make_unique&lt;uint8_t[]&gt;(totalSize);

// 将float数据转换为uint8_t (反归一化)
size_t index = 0;
for (float value : result) {
    // 将float值转换为uint8_t (0-255范围)
    float scaledValue = value * 255.0f;
    scaledValue = std::max(0.0f, std::min(255.0f, scaledValue));
    result_data[index++] = static_cast&lt;uint8_t&gt;(scaledValue);
}

result_data 就是最终的超分数据,可以正常显示
</code></pre><p>﻿</p><h2><strong>4. 总结与技术展望</strong></h2><p>京东金融App在鸿蒙端部署Real-ESRGAN-General-x4v3超分辨率模型的完整实践过程，成功解决了ONNX模型到OM离线模型转换、BCHW与BHWC张量格式处理、以及基于CANN Kit和NAPI的完整部署链路等关键技术难题。</p><p>展望端智能的未来发展，随着芯片算力的指数级增长、模型压缩技术的突破性进展以及边缘计算架构的日趋成熟，端侧设备将从单纯的数据采集终端演进为具备强大推理能力的智能计算节点，通过实现多模态AI融合、实时个性化学习、隐私保护计算和跨设备协同等核心能力，将大语言模型、计算机视觉、语音识别等AI技术深度集成到移动设备中，构建起无需联网即可提供智能服务的自主计算生态，推动人机交互从被动响应向主动感知、预测和服务的范式转变，最终开启真正意义上的普惠人工智能时代。</p>]]></description></item><item>    <title><![CDATA[DeepSeek 正当红，聊聊大模型应用的四大关键要素和未来 京东云开发者 ]]></title>    <link>https://segmentfault.com/a/1190000047498572</link>    <guid>https://segmentfault.com/a/1190000047498572</guid>    <pubDate>2025-12-23 19:01:55</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>引言</h2><p>大模型应用的春天来了。在人工智能的浪潮中，大模型正成为推动技术变革的核心力量。春节前，DeepSeek R1 的发布在全球范围内引发了巨大轰动，它不仅在性能上与 OpenAI 的模型不相上下，更凭借其基于 CoT（Chain of Thought）的推理过程，展现出强大的逻辑能力，同时，开源和低成本的优势，让众多企业迅速接入。DeepSeek 已然成为各行业关注的焦点，今年无疑是大模型应用爆发的关键一年。</p><h2>一、大模型应用的爆发：为什么是2025？</h2><p>技术的发展并非一蹴而就，而是经历从萌芽到成熟，再到广泛应用的过程。20多年前的PC互联网和10多年前的移动互联网的兴起，都经历了这样的阶段，如今，从周期和技术成熟度来看，AI大模型也正站在爆发的前夜。</p><p>DeepSeek R1 的出现，不仅展示了大模型的强大能力，更以开源和低成本的姿态，为更多企业和开发者提供了平等的机会。短短一个多月，国内众多公司纷纷接入，甚至包括腾讯、阿里等行业巨头。这种现象表明，大模型的应用已经具备了广泛落地的基础，从金融风控到投资决策，从智能家居到医疗辅助，大模型的应用场景正在不断拓展。2025年，或许就是这场技术变革的“临界点”。</p><h2>二、大模型的应用价值：不只是“通用聊天”</h2><p>很多人可能会问：既然 DeepSeek、ChatGPT 等聊天类App已经如此强大，为什么还要开发基于大模型的应用呢？原因主要有两个方面：一是通用聊天应用虽然灵活，但在很多专业领域，普通用户并不具备问正确问题的能力；二是大模型推理需要基于场景的相关数据，通用聊天工具从互联网搜索到的数据，可能不全或者不准确，在医疗、投资等大部分专业领域需要准确数据的场景，并不可靠。</p><p>在当下的技术发展阶段，大模型尚未真正具备智能，其核心价值在于卓越的数据处理能力。这种能力在众多专业领域中展现出巨大的潜力，能够显著提升工作效率。以医疗领域为例，大模型能够基于患者的病历、检查报告、生理数据等多维度信息，快速进行病情分析和辅助诊断，为医生提供精准的决策支持。在投资领域，它也能迅速获取市场动态数据，完成基本面与技术面的深度分析，为投资者提供科学的决策参考。这些应用场景充分证明，大模型的价值远不止于简单的“聊天”。</p><h2>三、做好大模型应用的关键：四大要素</h2><p>过去两年，我们在积极探索大模型的应用过程中：从营销运营领域的热搜机器人、到 Coding 领域的 JoyCoder，金融科技领域从社区的热点话题生成、到基金/保险产品解读。DeepSeek R1 的出现，让我们更加意识到，目前的应用还非常初级，只是有，离好还有很大的差距和空间。基于过往的这些场景探索，大模型应用要取得更好的效果，我们认为需要综合考虑以下4大要素：好的效果 = 大模型 + 专业知识 + 知识库 + 工程架构。</p><h3>（1）专业知识和交互设计：让大模型“容易使用”</h3><p>DeepSeek 等通用聊天类App虽然简单，但要用好的话往往需要用户具备专业知识，看似普惠，事实上门槛比较高，交互体验也不够便捷。例如在投资领域，普通用户可能并不知道该问什么问题，如果只是问“今天的市场行情怎么样，这只股票是买入还是卖出”，大模型并不能给出能赚到钱的答案。而稍有一些投资经验的人，可以问“分析一下沪深300指数的技术面，时间从2021年到现在，从形态、均线、趋势等看走势是反弹还是反转，并用MACD、背离、量能等交叉确认”等更复杂的问题。如果涉及到更具体买卖决策和调仓建议，可能需要更加深入和专业的问题。</p><p>此外，交互不够便捷也是一大问题。用户需要组织语言、打字输入，还要在聊天工具和具体的如券商的App之间来回切换，体验较差。今日头条等之所以能取代门户网站，正是因为其在交互上体验更好。因此，交互设计和专业知识的结合是大模型应用成功的关键，场景化的AI是探索的一个方向。</p><h3>（2）领域知识库和搜索能力：让大模型“有据可依”</h3><p>问准确的问题还不够，还需要有充分的上下文信息以及准确获取的能力。首先，信息的及时、准确和丰富至关重要。大模型是神经网络，仿照大脑的原理构建，可以看作一个看完了互联网上所有数据的超级专家。就像让医生看病或操盘手交易，需要告知其“病情”或“行情”才能开展工作，信息越及时和全面，专家的决策就越准确、可靠。</p><p>DeepSeek App 虽然具有联网能力，能在回答问题前搜索相关信息，但搜索回来的数据可能存在问题，如数据过期或数据较少，导致推理结果不够准确。比如下图案例，做出推理结论而引用的数据4和6是过期的，导致看起来完美的推理逻辑也是无法用的。企业要想用好大模型，必须建立本地知识库，确保数据的数量和质量。在 DeepSeek 这类大模型开源后，算法已经平权，企业之间的竞争又回到了数据这个生产力要素。</p><p>﻿<img referrerpolicy="no-referrer" src="/img/remote/1460000047498574" alt="在这里插入图片描述" title="在这里插入图片描述"/></p><p>﻿</p><p>其次，高效准确地获取数据也极为关键。即使知识库建的很大、很丰富，搜索能力也至关重要，这是百度、谷歌等深耕多年的能力，技术门槛比较高，要做好并不容易。知识库本身的架构，访问权限设计，以及各种RAG技术，都极为关键。（图片来自于网络）</p><p>﻿<img referrerpolicy="no-referrer" src="/img/remote/1460000047498575" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><p>﻿</p><h3>（3）Agent架构与工程能力：让大模型“激发潜能”</h3><p>对于简单问题，大模型可以通过一轮对话给出答案；而对于复杂问题，如买一张去西藏的便宜机票，或判断中证A500指数基金什么时候买，则需要更加复杂的设计，如果能更好地组织和引导，类似于人类的头脑风暴和专家讨论，把多个专家的智力都激发出来，就有可能找到更好的解决方案。</p><p>大模型是一个待机的超级专家，提供简单的API供应用随时调用，如何面向大模型编程，激发其潜力需要研发人员的精心设计，目标是大模型成为真的“大脑”，取代原来预设的业务流程，策略引擎和流程编排工具，让应用具备自主智能。通过Agent架构，甚至多Agent（智能体）交互，可以引导大模型进行多轮交互和逻辑推理，从而获得更准确的结果，工具/MCP，记忆，规划、思维链、反思等架构和设计模式，需要持续探索应用。（图片来自于网络）</p><p>﻿<img referrerpolicy="no-referrer" src="/img/remote/1460000047498576" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><p>﻿</p><h3>（4）大模型自身：“选择比拥有更重要”</h3><p>大模型是整个应用的核心部件，当然是最重要的。但从应用开发的角度来看，选择合适的大模型并灵活切换更为关键，应用系统的架构，需要更加灵活的支持多个大模型。DeepSeek R1的成功表明，大模型在持续的竞争和迭代，另外，不同大模型在不同领域的潜质也不一样，就像有些人擅长科学，有些擅长经商，有些擅长音乐，多Agent系统中，每个Agent可以使用不同的大模型。未来，大模型的市场竞争将更加激烈，选择比拥有更重要。</p><h2>四、大模型的未来：探索与展望</h2><p>DeepSeek R1 是终点吗？当然不是。Transformer 是实现 AGI（通用人工智能）的终极算法架构吗？估计也不是。吴军、杨立琨、王兴兴等专家都曾提出过类似的观点：尽管Transformer架构在自然语言处理等领域取得了巨大突破，但它并非万能。未来仍有可能出现更强大的算法，推动人工智能迈向新的高度。</p><p>数据真的已经用完了吗？应该也不是。人类在学习和沉淀规律时，从来不仅仅是依赖过往的书本知识。从开普勒三大定律到牛顿力学，这些伟大的科学发现，都是通过对现实世界中的数据进行获取、分析和总结得出的。无论是日月星辰的运行轨迹，还是潮起潮落风云变幻，亦或是粒子撞击的微观过程，甚至是人类自身的脉搏跳动，只要通过摄像机、传感器等工具进行捕捉，就能从这些更广泛、更丰富的自然界获取数据。这些数据，或许将成为未来人工智能发展的重要“养料”，为模型的训练和优化提供新的思路和方向。</p><p>除了算法和数据，大模型的未来发展还需要强大的算力。量子计算或许是解决这一问题的关键方案。哦，还有能源问题，小时候看《变形金刚》，一直不理解他们为什么整天争夺“终极能源”，未来当硅基生命充满大地和天空的时候，能源问题或许将成为制约技术发展的关键瓶颈。</p><p>这一天，或许终将会到来。</p>]]></description></item><item>    <title><![CDATA[【前瞻技术布局】咖啡机器人：具身智能技术首阶段探索与实践 京东云开发者 ]]></title>    <link>https://segmentfault.com/a/1190000047498581</link>    <guid>https://segmentfault.com/a/1190000047498581</guid>    <pubDate>2025-12-23 19:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>一、前言</h2><p>我是一名京东具身智能算法团队的研究人员，目前，主要专注在<strong>真实场景真实机器人</strong>下打造一套<strong>快速落地新场景的具身智能技术架构</strong>，聚集机器人操作泛化能力提升，涉及模仿/强化学习、“视觉-语言-动作”大模型等方法研究。本文主要以第一阶段<strong>咖啡机器人</strong>任务场景为切入点，来阐述所取得的技术突破，以及后续技术优化方向。如下是机器人全程自主完成打咖啡的视频。</p><h2>二、问题定义和路径选择</h2><p>具身智能，指的是配备实体身躯、支持物理交互的智能体所展现出的智能形态。凭借这一智能形式，机器人及其他智能设备得以在复杂多变的现实世界中执行各类任务。然而，鉴于任务的复杂性以及操作所呈现出的高难度与多样性，具身智能技术遭遇诸多挑战，当前仍处于持续发展阶段。现阶段，多数具身智能研究仅在<strong>实验室或结构化场景中</strong>开展，很难将成果迁移至真实场景加以应用。究其根源，理想环境屏蔽了诸多在真实场景中才会暴露的问题。有鉴于此，我将研究重心聚焦于<strong>真实场景下的具身智能技术突破</strong>，同时，为推动具身智能技术广泛赋能多元业务，着力打造一套能够<strong>快速适配新场景的具身智能技术架构</strong>。</p><p>目前，具身操作是具身智能核心技术卡点，其技术路线粗分为<strong>预测机器人操作动作</strong>与<strong>预测物体抓取位姿</strong>。前者泛化性弱且依赖大量专家数据，后者难适用于复杂长序列任务，灵巧手位姿也难获取。鉴于此，创建了技术上<strong>乘上启下“末端模仿” 新路径</strong>，融合两者优势，包括<strong>预测预抓取位姿</strong>（易实现、泛化性强）与<strong>统一操作轨迹学习</strong>（减少专家数据依赖、操作灵巧），且该路径可灵活扩展为 “视觉 - 语言 - 动作” 大模型方法。</p><h2>三、快速落地新场景技术架构打造</h2><p>在当今快速变化的技术环境中，集团会面临着不断适应新业务场景的挑战。只能适应单一场景的具身智能技术不具备长期价值，而能够快速落地新场景的具身智能技术则至关重要。因此，针对于真实场景下机器人打咖啡任务，打造了一套快速落地新场景的技术架构<strong>原型</strong>，并取得了关键技术突破。</p><h3>1、关键技术突破及价值</h3><h4>1）真实场景下从0到1打造具身智能系统技术架构</h4><ul><li><strong>面临挑战</strong>：具身智能系统往往涉及内容模块较多，耦合关系较为复杂，可扩展性较差，难以快速适应新任务场景。与此同时，真实场景下，往往面临着通信时延、模型推理速度和系统稳定性等挑战。</li><li><strong>技术突破</strong>：如下图所示，打造了一套具备<strong>高扩展性</strong>的具身智能系统技术架构，只需定义<strong>合适的子任务序列</strong>就可落地新场景。其中，该系统以<strong>ROS系统</strong>为基础构建，整个流程通过主调度模块进行协调，确保各模块之间的协同工作，通过不同控制模式决定系统不同阶段的工作方式，包括导航、感知、基于Agent的任务规划、遥操、具身操作等。此外，设计了模型异步推理、GRPC协议数据传输和子母路由通信等机制来攻克通信时延、推理速度慢等问题。</li><li><strong>核心价值</strong>：在真实场景下，从<strong>0到1打造了整套具身智能系统技术架构</strong>，并且<strong>成功落地咖啡机器人任务场景</strong>中，而不是在简单的实验室或者结构化场景下。与此同时，为后续真实场景下具身智能技术的研发提供了<strong>坚实的基础</strong>。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047498583" alt="在这里插入图片描述" title="在这里插入图片描述"/></p><h4>2）面向双臂灵巧手构建高频率一体式遥操技术</h4><ul><li><strong>面临挑战</strong>：目前，大多数遥操采用了同构方式。这种方式需要额外配置相应的机械臂，并且不同结构机器人是无法共享，可扩展性及便捷性低。其次，双臂和灵巧手的一体式遥操技术对其同步性及延迟率要求高，实现难度大。</li><li><strong>技术突破</strong>：如以下视频所示，构建了<strong>面向双臂灵巧手的一体式高频率遥操技术</strong>。通过结合<strong>惯性动捕</strong>和<strong>视觉动捕</strong>技术，对遥操设备进行了创新设计，使机器人能够精准复刻人类动作。同时，借助<strong>手和臂数据透传技术</strong>，优化了从动作捕捉到控制执行的高频率跟随链路，极大提升了系统响应速度与操作精度。</li><li><strong>核心价值</strong>：相比于行业其他遥操技术，该技术具备<strong>轻量化</strong>、<strong>价格低廉</strong>和<strong>扩展性强</strong>特点。此外，通过该遥操技术，双臂灵巧手的整体控制频率达<strong>50hz</strong>以上，并且系统延时在<strong>50ms</strong>以内。</li></ul><h4>3）少量数据下实现物体位置的泛化操作</h4><ul><li><strong>面临挑战</strong>：具身操作的泛化性一直是一个挑战性问题。目前，大多数方法都依赖于大量数据使其涌现出泛化性能。然而，大量的示教数据需要消耗大量人力物力。训练模型也需较多计算资源的支撑，且效果也难以达到较佳的泛化性能。</li><li><strong>技术突破</strong>：如下图所示，提出了基于<strong>末端模仿的泛化操作方法</strong>，聚集于<strong>统一的操作轨迹学习</strong>，能在较少的数据下实现较强的位置泛化能力，涉及核心模块包括：<strong>操作物体感知与位姿估计</strong>、<strong>预操作位姿到达</strong>和<strong>聚集物体的策略学习</strong>。此外，设计了<strong>聚集于物体的视觉特征</strong>提取模块，增强对核心操作区域的感知。</li><li><strong>核心价值</strong>：相比与行业已有方法，首次提出聚集于<strong>核心操作轨迹</strong>的学习方法，能在较少数据量情况下实现物体位置的泛化操作，在打咖啡任务中，成功率<strong>达90%以上</strong>。此外，在大量抓取任务中（拿扫码枪、抓娃娃、搬箱子等等），该方法表现出的性能相比于baseline成功率<strong>提升了50%以上</strong>。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047498584" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><h3>2、咖啡机器人任务场景实践</h3><p>基于所打造的具身智能技术架构，首先落地了<strong>咖啡机器人</strong>任务场景。机器人打咖啡任务主要包含以下几个步骤：<strong>导航到咖啡机</strong>、<strong>拿起空杯子</strong>、<strong>放好杯子</strong>、<strong>点击屏幕</strong>（选择咖啡、确认按钮和已放好按钮）、<strong>拿起咖啡杯</strong>、<strong>导航到用户位置</strong>、<strong>将咖啡杯递给人</strong>。打咖啡任务是一个真实场景下的<strong>长序列任务</strong>，包含多个子任务。子任务都是按序列衔接好的，完成当前子任务才会执行下一个子任务。与此同时，设计了<strong>子任务是否成功完成的检测机制</strong>，提升整个系统的<strong>鲁棒性</strong>，比如：点击屏幕过程中，如果没有点击触发，会反复点击直到成功。即便面对打咖啡这样复杂的场景，凭借该具身智能技术架构打造的系统，仍能以极高的成功率完成任务。以下是机器人打咖啡的<strong>精彩瞬间</strong>。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047498585" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></p><p>在咖啡机器人任务场景实践中，遇到诸多新问题。起初为机器人在胸部和头部各配备 RealSense D435 相机，却发现胸部相机易被机械臂遮挡，且两款相机 <strong>FOV 过小，常无法捕捉操作物体和灵巧手</strong>，而这类问题在<strong>实验室桌面操作场景中难以察觉</strong>。于是，将头部相机换成 FOV 更大的 ZED 相机，可新相机又导致<strong>模型视觉特征不聚集</strong>，遂通过聚焦手部局部视角解决。点击屏幕时，<strong>按钮需快速抽离动作才能触发</strong>，给灵巧手控制带来极大困难。为此设计检测机制，让灵巧手能反复尝试，有效提升了点击成功率。</p><h2>四、下一步技术优化及进展</h2><p>后续，将进一步完善和优化整个具身智能系统架构，使其能快速落地新场景。核心聚集于<strong>具身操作方向，提升机器人的泛化操作能力，扩充其技能库的上限</strong>。结合具身技术<strong>发展趋势</strong>以及现有架构的<strong>不足</strong>，主要围绕以下两个方面开展工作。</p><ul><li><strong>“视觉-语言-动作”大模型促进快速落地新场景</strong>：“视觉-语言-动作”大模型会<strong>利用“视觉-语言”预训练模型知识</strong>来促进对机器人动作的学习。在大量的数据训练基础上，“视觉-语言-动作”大模型将会涌现出令人意想不到的能力：<strong>基于语言指令的新技能泛化</strong>、<strong>新物体泛化</strong>、甚至<strong>多机协作能力</strong>。这些潜能在Figure AI公司最新发布的Helix模型实验结果中已展现出来。</li><li><strong>真机强化学习优化整个具身智能系统</strong>：在目前的具身操作技术中，大多数采用了模仿学习方法。然而，<strong>模仿学习</strong>存在其<strong>局限性</strong>，较为<strong>依赖于专家数据</strong>，并且存在<strong>性能上限</strong>。<strong>强化学习</strong>方法则能使机器人探索更多数据，<strong>突破其性能上限</strong>，对专家数据<strong>依赖程度较低</strong>。另外，真机强化学习是基于机器人实时与环境交互所得数据来优化模型，这种优化不仅仅是提升模型性能，而且能够对<strong>整个具身系统进行优化</strong>。</li></ul><h2>五、我对具身智能的思考和坚持</h2><ul><li>在具身智能技术的实际落地进程中，真实场景的复杂程度往往远远超出了在实验室或结构化场景中预先设定的界限。在<strong>真实任务场景中进行技术探索</strong>，不但有助于我们对算法的实际性能进行验证和优化，还能够发掘出<strong>在实验室或结构化场景中未曾预想到的问题与挑战</strong>。通过在真实场景中对技术进行测试和应用，我们能够获取更为丰富的数据和反馈，进而推动技术不断迭代和创新。</li><li>随着 Figure AI 公司发布的 Helix 模型并在物流仓库中的成功应用，这使我愈发坚信具身智能的时代已然降临。对其实现的技术逻辑进行剖析：重点围绕<strong>一个机器人本体</strong>，在一个特定的<strong>垂类领域中积累充足的数据量</strong>，<strong>在 “视觉 - 语言 - 动作” 大模型</strong>的有力支持下，机器人能够学会<strong>多种类人的技能</strong>，并且具有<strong>较强的泛化性能</strong>。其能够出圈的核心在于<strong>围绕一本体在真实场景下打磨技术</strong>。我认为这是实现快速落地的较佳方案，值得借鉴。此外，当前技术都围绕提升机器人任务成功率开展，若要真正将其在新场景中落地，还必须考虑机器人完成任务的<strong>效率问题</strong>。</li><li>展望未来，机器人会逐步融入人类社会。我们须倾<strong>热血</strong>与<strong>干劲</strong>，全力投身具身智能技术攻坚，力求让<strong>技术快速落地新场景</strong>，为企业<strong>技术增长添砖加瓦</strong>。</li></ul>]]></description></item><item>    <title><![CDATA[AI生成网站深度伪造信任 JoySSL以高强度数字证书验证身份 构筑安全防线 完美的铁板烧 ]]></title>    <link>https://segmentfault.com/a/1190000047498164</link>    <guid>https://segmentfault.com/a/1190000047498164</guid>    <pubDate>2025-12-23 18:11:38</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>近日，卡巴斯基发现攻击者针对亚太地区、欧洲、非洲以及拉丁美洲等地开展了恶意攻击活动。利用AI生成网站，从而分发合法的远程访问工具给意向目标，从而利用这些生成的仿冒网站以钓鱼邮件等形式吸引用户，伪装成货币钱包、反病毒软件等各类应用，不断诱导用户下载，从而实现对受害者设备的远程控制，窃取加密货币。JoySSL安全分析专家指出，随着技术水平的不断提升，网络威胁手段也正逐渐变得丰富多变。利用当下热门的人工智能技术，可以更好的为非法网络攻击披上合理外衣，自动化创建技术扩大了攻击规模，借助品牌信任，使仿冒的网站更容易欺骗用户。</p><p><img width="723" height="482" referrerpolicy="no-referrer" src="/img/bVdnsBw" alt="" title=""/></p><p>此次攻击链条的致命起因，在于用户无法明辨AI生成网站的真伪，不能确定下载的应用是否源自于官方渠道。面对这种深度伪造的信任，基础的网络防护手段已经捉襟见肘，唯有凭借可严格验证合法身份的SSL证书，才能在根本上辨别信息真伪，有效抵御新型网络威胁。</p><p><strong>利用AI生成网站深度伪装</strong></p><p>传统的钓鱼网站虽然也是仿冒官网，但由于设计粗糙等原因，更侧重于小概率事件，广撒网多捕鱼。而人工智能生成的则完全不同。AI生成的网站具有极强的视觉欺骗性，能够更好的复刻官网布局和风格，不是专业人士往往很难凭借肉眼分辨真伪。</p><p>此外，AI生成的网站不会分发明显的病毒，而是提供特殊的远程访问工具，利用合法签名而绕过安全软件检测，风险从软件本身直接转移至下载来源，利用仿冒官网的特性，实现深度伪装，大大降低了用户的防备。</p><p><img width="723" height="481" referrerpolicy="no-referrer" src="/img/bVdnsBx" alt="" title="" loading="lazy"/></p><p><strong>SSL证书验证身份硬核防伪</strong></p><p>利用AI伪造的官网，外观基本无懈可击，传统的基于内容验证的方式已然无法有效应对。因此，判断官网是否仿冒的依据，需要回归全球信任体系中的数字身份凭证上，SSL证书当仁不让发挥出最为突出的作用。攻击者即使可以利用AI生成网站，做到外观以假乱真，却依旧难以利用合法渠道获得经过法律验证的数字证书。</p><p>真正可信的官网，完全可以利用OV或EV证书，在浏览器地址栏直接展示经过验证的企业信息，让用户直接确定官网主体。此外，SSL证书可以确保官网渠道的验证性，公示用户通过指定的渠道访问站点或下载应用，直接切断仿冒官网的流量来源，以严格的验证系统实现“硬核防伪”。</p><p><img width="723" height="482" referrerpolicy="no-referrer" src="/img/bVdnsBz" alt="" title="" loading="lazy"/></p><p><strong>部署数字证书重塑信任起点</strong></p><p>AI生成网站的威胁手段不会是重点，未来还会有更加先进的网络攻击技术，时刻攻击网络安全防线。因此，JoySSL主张以主动防御替代被动姿态，尽早部署SSL证书，为所有的官方数字资产提供高强度防护，宣示官方正品，从而弱化仿冒官网的影响力。通过高强度数字证书展现身份标识，建立最强信任信号，降低用户决策疑虑，从源头杜绝仿冒网站的下载风险。</p><p><strong>人工智能时代筑建信任防线</strong></p><p>AI生成内容的泛滥，标志着所见即所得的传统信任模式正在崩塌。当表面的视觉元素可以被随意伪造时，需要利用更为先进的技术构筑深层防护体系，凭借经过法律认证的数字身份，可以有效建立起AI无法仿冒的网络产品，成为用户在网络世界中最信任的坐标。</p>]]></description></item><item>    <title><![CDATA[游戏搭建与云服务器：构建高效稳定的游戏运营架构 咕噜云服务器晚晚 ]]></title>    <link>https://segmentfault.com/a/1190000047498192</link>    <guid>https://segmentfault.com/a/1190000047498192</guid>    <pubDate>2025-12-23 18:10:44</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>游戏搭建与云服务器：构建高效稳定的游戏运营架构<br/>在数字化时代，游戏产业的快速发展对技术架构提出了更高要求，云服务器凭借弹性扩展、高可用性和成本优化等特性，已成为游戏搭建的核心基础设施。本文将从游戏搭建的技术架构、云服务器选型策略、性能优化方案及安全防护体系四个维度，系统阐述如何利用云服务器构建高效稳定的游戏运营环境。<br/>一、游戏搭建的技术架构设计<br/>现代游戏架构普遍采用微服务分布式部署模式，将游戏逻辑层、数据存储层、通信层进行解耦。逻辑层负责处理游戏核心玩法，需部署在计算性能强劲的云服务器实例上，推荐选择配备Intel Xeon Platinum处理器或AMD EPYC处理器的弹性云主机，确保每秒数十万次的逻辑运算能力。数据存储层需区分热数据与冷数据：热数据（如玩家实时状态、交易信息）采用云数据库Redis集群，通过主从复制实现毫秒级读写；冷数据（如历史战绩、道具日志）可存储于对象存储服务（OSS），配合生命周期管理策略自动迁移至低成本存储介质。通信层则依赖云服务器的弹性公网IP与负载均衡服务，通过TCP/UDP协议转换实现玩家与服务器的稳定连接，大型MMORPG游戏建议部署全球加速节点，将跨地域延迟控制在50ms以内。<br/>二、云服务器选型策略<br/>根据游戏类型与用户规模，云服务器选型需遵循"按需分配、弹性扩展"原则。轻度休闲游戏（如H5小游戏）初期可选择2核4G配置的通用型实例，搭配共享带宽模式控制成本；中型竞技游戏（如MOBA类）需采用8核16G的计算优化型实例，启用GPU加速模块提升物理引擎运算效率；大型开放世界游戏则需部署32核64G的内存优化型实例，同时配置本地SSD盘阵，将随机读写IOPS提升至10万以上。在地域选择上，需依据目标用户分布，例如面向东南亚市场的游戏应优先部署新加坡节点，利用云服务商的多可用区架构（如AWS的AZ部署、阿里云的Region+Zone模式）实现故障自动迁移，将服务可用性提升至99.99%。<br/>三、性能优化关键技术<br/>云服务器性能优化需从网络、存储、计算三个维度协同推进。网络层面，通过启用云服务器的SR-IOV技术实现硬件级网络虚拟化，将网络延迟降低40%；采用DDoS高防IP与弹性带宽组合，可抵御每秒数百G的流量攻击。存储层面，实施数据分层存储策略：玩家背包数据采用云数据库MongoDB分片集群，战斗记录采用时序数据库InfluxDB，游戏资源文件通过CDN进行全球分发，配合边缘节点缓存将资源加载速度提升80%。计算层面，利用云服务器的CPU超分技术（如VMware的vSphere Overcommit）提高资源利用率，同时通过容器化部署（Docker+Kubernetes）实现服务秒级扩容。针对突发流量（如新版本上线、节假日活动），可配置弹性伸缩组，基于CPU利用率（阈值设为70%）或玩家在线人数自动增减实例数量。<br/>四、安全防护体系构建<br/>游戏服务器安全需构建"纵深防御"体系。基础防护层，启用云服务器的安全组策略，仅开放必要端口（如游戏端口3724、管理端口22需限制IP访问）；安装云安全中心Agent，实时监控异常进程与文件篡改。应用防护层，部署Web应用防火墙（WAF）防御SQL注入、XSS攻击，对玩家密码采用bcrypt算法加盐哈希存储。数据安全层，实施数据库透明加密（TDE）与定期备份策略，关键数据采用跨地域容灾方案（如阿里云的跨区域备份）。运营审计层，通过云服务器的操作审计功能记录管理员操作日志，启用多因素认证（MFA）保护控制台登录，对异常登录行为触发短信告警。<br/>随着元宇宙概念兴起与5G技术普及，游戏对云服务器的依赖将进一步加深。未来，通过云服务器与边缘计算、AI调度算法的深度融合，可实现"千人千面"的弹性资源分配，为玩家提供低延迟、高沉浸的游戏体验。游戏开发者需持续关注云服务技术演进，将架构设计从"满足需求"向"预见需求"转变，在成本控制与用户体验间找到最佳平衡点，构建可持续发展的游戏运营架构。</p>]]></description></item><item>    <title><![CDATA[云数据库：数字时代数据管理的核心引擎 咕噜云服务器晚晚 ]]></title>    <link>https://segmentfault.com/a/1190000047498195</link>    <guid>https://segmentfault.com/a/1190000047498195</guid>    <pubDate>2025-12-23 18:09:50</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>云数据库：数字时代数据管理的核心引擎<br/>在数字化转型浪潮下，企业数据量呈指数级增长，传统本地数据库面临存储容量有限、扩展性不足、运维成本高昂等挑战。云数据库作为基于云计算技术的分布式数据管理系统，通过将数据存储、管理和维护等核心功能迁移至云端，为企业提供了弹性扩展、高可用性和低成本的数据管理解决方案，已成为金融、电商、政务等关键领域的基础设施。<br/>技术架构：分布式与虚拟化的深度融合<br/>云数据库采用分布式架构设计，通过将数据分片存储于多个物理节点，实现计算与存储资源的解耦。基于Kubernetes等容器编排技术，云数据库可动态调度资源，当业务流量激增时自动扩容节点，流量低谷时释放冗余资源，资源利用率较传统数据库提升40%以上。同时，多副本机制确保数据可靠性——主节点实时同步数据至备用节点，一旦主节点故障，系统可在秒级完成故障转移，RTO（恢复时间目标）控制在10秒以内，RPO（恢复点目标）趋近于零，满足金融交易等核心业务的连续性要求。<br/>核心优势：从成本优化到业务赋能<br/>弹性扩展能力是云数据库的核心竞争力。传统数据库需提前规划硬件采购，往往导致资源闲置或不足，而云数据库支持按使用量付费（PAYG）模式，企业可根据实际需求调整存储容量和计算能力，TCO（总拥有成本）平均降低30%-50%。以电商平台为例，在“双11”大促期间，云数据库可在1小时内完成10倍资源扩容，支撑每秒数十万笔订单的并发处理，活动结束后自动缩容，避免资源浪费。<br/>数据安全与合规方面，主流云数据库厂商通过ISO 27001、SOC 2等国际认证，采用传输加密（TLS 1.3）、存储加密（AES-256）和访问控制（IAM权限模型）构建纵深防御体系。此外，多地多活部署架构可抵御区域性灾难，2023年某云厂商通过“三地五中心”架构，在地震导致单区域机房中断时，实现业务零感知切换，数据零丢失。<br/>应用场景：重构行业数据管理范式<br/>在金融领域，云数据库支撑着实时风控系统的毫秒级数据处理。某股份制银行将核心交易系统迁移至分布式云数据库后，单笔交易响应时间从300ms降至50ms，同时通过实时数据分析识别欺诈行为，风控准确率提升25%。政务领域，某地政务云平台采用云数据库存储1000万+市民的社保、医疗数据，通过数据共享接口实现跨部门业务协同，办事效率提升60%，群众办事“最多跑一次”成为现实。<br/>互联网行业更是云数据库的深度实践者。短视频平台利用云数据库的时序数据处理能力，存储用户行为日志（日均增量PB级），通过实时分析生成个性化推荐，用户日均使用时长增加12%。制造业则通过云数据库构建工业互联网平台，接入设备传感器数据，实现预测性维护，某汽车工厂设备故障率降低30%，生产效率提升15%。<br/>挑战与演进：迈向智能化与多模态<br/>尽管云数据库优势显著，但其发展仍面临技术挑战。多云管理复杂度、数据迁移成本、开源生态兼容性等问题亟待解决。为此，厂商推出混合云数据库解决方案，支持本地数据中心与公有云无缝协同；同时，基于AI的自治数据库成为新趋势，通过机器学习算法自动优化索引、诊断性能瓶颈，某云厂商的自治数据库已实现85%的运维任务自动化。<br/>未来，随着5G、物联网和AI技术的普及，云数据库将向多模态数据处理演进，不仅支持结构化数据，还能高效管理视频、音频、图像等非结构化数据。边缘计算与云数据库的结合，将实现“边缘-云端”数据协同处理，满足自动驾驶、工业元宇宙等场景的低延迟需求。<br/>作为数字经济的“数据基座”，云数据库正在重塑企业IT架构，推动数据从静态资产向动态生产要素转变。随着技术的持续迭代，云数据库将在降本增效、业务创新和安全合规等方面发挥更大价值，成为企业数字化转型的“加速器”。</p>]]></description></item><item>    <title><![CDATA[IAM权限模型 咕噜云服务器晚晚 ]]></title>    <link>https://segmentfault.com/a/1190000047498199</link>    <guid>https://segmentfault.com/a/1190000047498199</guid>    <pubDate>2025-12-23 18:09:17</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>IAM权限模型<br/> 一、IAM权限模型的核心概念</p><ol><li><p><strong>身份（Identity）</strong></p><ul><li>用户（User）：代表具体操作者，如员工、系统管理员，需通过账号密码或多因素认证登录。</li><li>角色（Role）：预定义的权限集合，可被用户或服务临时继承，如“管理员”“只读用户”。</li><li>组（Group）：用户的集合，便于批量分配权限，简化管理，如“研发组”“财务组”。</li></ul></li><li><p><strong>权限（Permission）</strong></p><ul><li>最小权限原则：仅授予完成任务必需的权限，降低数据泄露风险。</li><li>权限粒度：支持资源级（如特定服务器）、操作级（如读取/写入）、数据级（如某类文件）的精细化控制。</li></ul></li><li><p><strong>策略（Policy）</strong></p><ul><li>JSON格式的规则集合，定义“谁（主体）可以对谁（资源）执行什么操作（动作），在什么条件下（条件）”。</li><li>示例：允许用户A对S3存储桶“bucket-001”执行“s3:PutObject”操作，限制IP地址为公司内网。</li></ul></li><li><p><strong>资源（Resource）</strong></p><ul><li>被访问的对象，如服务器、数据库、文件等，通常通过唯一标识符（ARN）定位。  <br/> 二、IAM权限模型的工作流程</li></ul></li><li><strong>身份认证</strong>：用户通过账号密码、API密钥等方式验证身份，生成临时凭证（如Token）。</li><li><strong>权限分配</strong>：管理员通过策略将权限绑定到用户、角色或组，例如将“EC2完全访问”策略附加到“运维角色”。</li><li><strong>访问请求</strong>：用户发起操作请求（如调用API），系统解析请求中的主体、资源、动作及条件。</li><li><strong>权限判断</strong>：根据预定义策略评估请求是否符合权限规则，通过则允许访问，否则拒绝并返回错误码。</li><li><strong>审计日志</strong>：记录所有访问行为，包括主体、时间、操作、结果，用于合规审计和问题追溯。  <br/>三、IAM权限模型的关键特性</li><li><p><strong>多维度控制</strong></p><ul><li>主体维度：基于用户、角色、组分配权限。</li><li>资源维度：按资源类型、名称、标签等限制访问范围。</li><li>条件维度：支持时间（如工作时间）、IP地址、设备类型等动态条件。</li></ul></li><li><p><strong>动态权限管理</strong></p><ul><li>临时凭证：通过角色扮演（AssumeRole）获取短期权限，避免长期密钥泄露风险。</li><li>权限自动回收：基于时间或事件触发权限失效，如项目结束后移除相关角色。</li></ul></li><li><p><strong>安全性增强</strong></p><ul><li>最小权限：默认拒绝所有操作，仅显式允许必要权限。</li><li>权限边界：限制管理员可分配的最大权限范围，防止权限滥用。</li><li>MFA强制：关键操作需开启多因素认证，提升账号安全性。</li></ul></li><li><p><strong>可扩展性</strong></p><ul><li>支持跨账户访问：通过角色委托实现不同账户间的权限共享。</li><li>集成第三方身份系统：对接LDAP、SAML 2.0等，实现单点登录（SSO）。  <br/> 四、IAM权限模型的应用场景</li></ul></li><li><p><strong>企业级权限管理</strong></p><ul><li>按部门划分用户组，为“财务组”分配财务系统只读权限，为“开发组”分配代码库读写权限。</li><li>通过角色临时授权外部审计人员访问特定数据，审计结束后立即回收权限。</li></ul></li><li><p><strong>云服务访问控制</strong></p><ul><li>在AWS/Azure等云平台中，通过IAM限制EC2实例仅允许指定IP的SSH登录，S3存储桶仅允许内部服务写入。</li></ul></li><li><p><strong>DevOps流程集成</strong></p><ul><li>CI/CD管道中，为构建服务分配临时权限，仅允许拉取代码和推送镜像，避免永久权限暴露。</li></ul></li><li><p><strong>合规与审计</strong></p><ul><li>金融行业通过IAM实现GDPR合规，限制用户访问客户敏感数据的范围，并留存完整操作日志。  <br/> 五、IAM权限模型的最佳实践</li></ul></li><li><strong>避免使用过于宽泛的策略</strong>：如“AdministratorAccess”应仅分配给少数核心管理员，普通用户使用最小权限策略。</li><li><strong>定期权限审计</strong>：通过工具检查未使用的权限、过度授权的策略，并及时清理冗余配置。</li><li><strong>启用多因素认证（MFA）</strong>：对所有用户账号，尤其是管理员账号强制开启MFA。</li><li><strong>使用角色而非长期密钥</strong>：服务间通信优先通过角色扮演获取临时权限，减少静态密钥的使用。</li><li><strong>策略版本控制</strong>：对策略修改进行版本管理，支持回滚到历史版本，避免误操作导致权限故障。  <br/> 六、常见挑战与解决方案</li><li><p><strong>权限过度分配</strong></p><ul><li>挑战：管理员为简化操作分配过宽权限，导致数据泄露风险。</li><li>解决方案：实施权限最小化原则，通过自动化工具检测过度授权策略（如AWS IAM Access Analyzer）。</li></ul></li><li><p><strong>复杂策略管理</strong></p><ul><li>挑战：大量策略导致管理混乱，难以追溯权限来源。</li><li>解决方案：采用策略模板（如AWS Managed Policies），按功能模块分类管理，定期梳理策略关联关系。</li></ul></li><li><p><strong>跨账户权限复杂性</strong></p><ul><li>挑战：多账户场景下权限委托配置繁琐，易出现权限漏洞。</li><li>解决方案：使用IAM Access Analyzer跨账户检测，通过组织策略（Organizations SCPs）统一控制权限边界。</li></ul></li><li><p><strong>动态条件误判</strong></p><ul><li>挑战：条件规则配置错误（如IP范围设置过宽）导致权限绕过。</li><li>解决方案：通过沙箱环境测试策略效果，启用条件日志记录（Condition Keys Logging）追踪条件触发情况。  <br/> 七、总结<br/>IAM权限模型通过身份、权限、策略的系统化设计，实现了对数字资源的精细化、安全化管理。其核心价值在于平衡便捷性与安全性，既能满足业务灵活访问需求，又能通过最小权限、动态控制、审计追溯等机制降低风险。在云原生、DevOps等场景下，IAM已成为保障系统安全的基础设施，需结合最佳实践持续优化，确保权限管理的合规性与可靠性。</li></ul></li></ol>]]></description></item><item>    <title><![CDATA[鸿蒙开发终极指南：13种码图一键生成，从基础实现到自定义全解析 认真的咖啡 ]]></title>    <link>https://segmentfault.com/a/1190000047498205</link>    <guid>https://segmentfault.com/a/1190000047498205</guid>    <pubDate>2025-12-23 18:08:40</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>目录</h2><ul><li>前言</li><li>码图技术概述</li><li>关于文本生成码图</li><li>核心使用场景深度解析</li><li>文本生成码图的约束与限制</li><li>手把手实现文本生成码图</li><li>自定义码图：样式、尺寸与个性化配置</li><li>结束语</li></ul><h2>前言</h2><p>在数字化浪潮席卷全球的今天，码图（二维码与条形码的统称）已成为连接物理世界与数字信息的核心桥梁。从日常购物的扫码支付、快递物流的单号追踪，到政务服务的扫码认证、企业内部的数据流转，码图凭借“快速识别、高效传参”的特性，渗透到生活与工作的每一个场景。尤其是随着鸿蒙生态的持续扩张，原生应用对码图功能的需求呈爆发式增长。无论是社交应用的信息分享、办公应用的文件传输，还是物联网设备的配网激活，都离不开文本到码图的快速转换。值得一提的是，HarmonyOS为开发者提供了高度封装、功能强大的原生API支持，无需依赖第三方库，就能轻松实现从文本到13种主流码图的生成，极大降低了开发门槛，那么接下来就来详细分享一下。</p><h2>码图技术概述</h2><p>码图技术本质是一种“数据可视化编码”方案，通过特定的图形排列规则，将文本、数字等结构化/非结构化数据转换为机器可识别的图形符号，核心分为二维码与条形码两大类别：</p><ul><li>条形码：以黑白条纹的宽度变化编码数据，结构简单、识别速度快，但存储容量有限，主要用于商品标识、物流单号等场景；</li><li>二维码：以矩阵式的黑白方块组合编码数据，存储密度远超条形码，支持中文、特殊符号等复杂内容，且具备容错能力，成为当前主流的码图形式。</li></ul><p>在HarmonyOS生态中，码图生成能力进一步升级：不仅覆盖二维码、条形码的全场景需求，还支持自定义码图尺寸、边距等参数，开发者可根据业务场景灵活选择编码类型，将任意合法字符串快速转换为标准化或个性化的码图。</p><h2>关于文本生成码图</h2><p>在HarmonyOS原生应用开发中，文本生成码图的核心逻辑是“参数配置+API调用”，整个流程简洁高效，无需复杂的编码算法实现，具体分为四大关键步骤：</p><ol><li><strong>集成码图生成库</strong>：HarmonyOS通过@kit.ScanKit等官方套件提供原生码图生成能力，无需额外引入第三方依赖，直接导入相关模块即可使用；</li><li><strong>配置码图核心参数</strong>：根据业务需求设置关键参数，包括码图类型、待编码文本内容、码图尺寸（宽高）、边距等；</li><li><strong>调用API生成码图</strong>：通过generateBarcode.createBarcode接口，传入配置参数，即可快速生成PixelMap格式的码图对象；</li><li><strong>码图的显示与拓展使用</strong>：将生成的PixelMap对象通过Image组件在界面展示，或进一步用于保存本地、分享给其他应用、打印输出等场景。</li></ol><p>这一流程的核心优势在于“原生适配+低代码”，官方API已处理好编码算法、兼容性优化等底层逻辑，开发者只需聚焦业务参数配置，即可快速落地功能。</p><h2>核心使用场景深度解析</h2><p>基于HarmonyOS文本生成码图的灵活特性，其应用场景几乎覆盖所有需要“高效信息传递”的业务场景，以下是最具代表性的落地场景：</p><ol><li><strong>信息快速分享场景</strong>：将联系人信息、WiFi账号密码、网页链接、地理位置等文本数据生成码图，用户扫码即可快速获取，无需手动输入。例如社交应用中“扫码加好友”、办公应用中“扫码传文件”；</li><li><strong>设备互联场景</strong>：在鸿蒙生态的多设备协同中，生成手机克隆码图，旧设备扫码即可快速向新设备迁移数据；物联网设备配网时，将WiFi信息、设备ID生成码图，设备扫码即可完成联网激活；</li><li><strong>商业服务场景</strong>：电商应用中生成订单支付码、线下门店的会员码、票务应用的电子票码；</li><li><strong>数据验证场景</strong>：企业内部系统中，将员工工号、部门信息生成码图，用于考勤打卡、门禁通行；物流应用中，将运单号生成码图，用于包裹分拣、签收确认；</li><li><strong>个性化展示场景</strong>：将品牌名称、Slogan、活动主题等文本生成码图，用于宣传物料、产品包装，用户扫码可跳转至活动页面、官网等，提升品牌互动性。</li></ol><p>例如将“HarmonyOS”字符串生成QR Code码图，可用于技术分享会的宣传物料，参会者扫码即可获取鸿蒙开发资料合集，实现“一物一码”的精准触达。</p><h2>文本生成码图的约束与限制</h2><p>HarmonyOS原生支持13种主流码图类型，每种类型因编码规则不同，对输入内容、字符长度、数据格式等参数有明确约束。以下是官方规范的详细说明，开发者需根据业务场景选择适配的码图类型：<br/><img width="723" height="630" referrerpolicy="no-referrer" src="/img/bVdnsBK" alt="image.png" title="image.png"/></p><p>除上述类型专属约束外，还有3个通用限制需重点注意：</p><ol><li><strong>颜色与背景约束</strong>：建议使用默认配置（黑色码图+白色背景），码图与背景的对比度直接影响识别率。若需自定义颜色，需确保对比度≥3:1（例如深绿色码图+白色背景），避免使用浅色系、相近色系组合；</li><li><strong>边距约束</strong>：默认边距为1px，取值范围为[1, 10]px。边距过小会导致码图与周围元素混淆，影响识别；边距过大则浪费显示空间，建议根据界面布局灵活调整；</li><li><p><strong>尺寸约束</strong>：</p><ul><li>二维码类（QR Code、Data Matrix、Aztec）：宽高需保持一致，且取值范围为[200, 4096]px，小于200px会因像素不足导致识别失败；</li><li>条形码类（EAN-8、EAN-13、UPC-A、UPC-E、Codabar、Code 39、Code 93、Code 128、ITF-14、PDF417）：建议宽高比为2:1（例如宽度400px、高度200px），且宽度需≥400px，否则会因条纹过窄影响扫描识别。</li></ul></li></ol><h2>手把手实现文本生成码图</h2><p>以下将以最常用的QR Code为例，详细拆解文本生成码图的完整实现步骤，包含模块导入、API调用（两种回调方式）、界面展示等核心环节，代码可直接复制到鸿蒙应用中使用：</p><h3>步骤1：导入核心模块</h3><p>首先需导入码图生成、错误处理、图片处理、日志打印相关的官方模块，这些模块是实现功能的基础：</p><pre><code>// 导入码图生成核心接口模块
import { scanCore, generateBarcode } from '@kit.ScanKit';
// 导入业务错误处理模块
import { BusinessError } from '@kit.BasicServicesKit';
// 导入图片处理模块
import { image } from '@kit.ImageKit';
// 导入日志模块
import { hilog } from '@kit.PerformanceAnalysisKit';</code></pre><h3>步骤2：调用码图生成接口</h3><p>HarmonyOS提供Promise和Callback两种回调方式，开发者可根据代码风格选择适配的方式，两种方式的核心功能一致，仅回调逻辑不同：</p><h4>方式1：通过Promise方式回调</h4><pre><code>@Entry
@Component
struct Index {
  // 用于存储生成的码图对象，初始值为undefined
  @State pixelMap: image.PixelMap | undefined = undefined

  build() {
    // 垂直布局，居中展示按钮和码图
    Flex({ direction: FlexDirection.Column, alignItems: ItemAlign.Center, justifyContent: FlexAlign.Center }) {
      // 生成码图的触发按钮
      Button('generateBarcode Promise')
        .onClick(() =&gt; {
          // 重置码图对象，避免重复显示旧码图
          this.pixelMap = undefined;
          // 待编码的文本内容（可替换为任意符合QR Code约束的文本，如链接、联系人信息等）
          let content: string = 'huawei';
          // 码图配置参数
          let options: generateBarcode.CreateOptions = {
            scanType: scanCore.ScanType.QR_CODE, // 码图类型：QR Code
            height: 400, // 码图高度（与宽度一致，符合二维码尺寸约束）
            width: 400   // 码图宽度
            // 可选参数：margin（边距），默认1px，如需调整可添加：margin: 2
          }
          try {
            // 调用码图生成API，传入文本内容和配置参数
            generateBarcode.createBarcode(content, options)
              .then((pixelMap: image.PixelMap) =&gt; {
                // 生成成功，将返回的PixelMap对象赋值给状态变量
                this.pixelMap = pixelMap;
                hilog.info(0x0000, 'BarcodeGenerate', '码图生成成功');
              })
              .catch((error: BusinessError) =&gt; {
                // 生成失败，打印错误信息（错误码+错误描述）
                hilog.error(0x0000, 'BarcodeGenerate', `码图生成失败：错误码${error.code}，错误信息${error.message}`);
              })
          } catch (error) {
            // 捕获其他异常（如参数格式错误）
            hilog.error(0x0000, 'BarcodeGenerate', `未知错误：${JSON.stringify(error)}`);
          }
        })
        .margin({ bottom: 30 }) // 按钮与码图区域的间距

      // 码图生成成功后，通过Image组件展示
      if (this.pixelMap) {
        Image(this.pixelMap)
          .width(300) // 展示宽度（可根据界面需求调整，建议不小于200px）
          .height(300) // 展示高度（与宽度一致）
          .objectFit(ImageFit.Contain) // 保持码图比例，避免拉伸变形
      }
    }
    .width('100%') // 布局占满屏幕宽度
    .height('100%') // 布局占满屏幕高度
  }
}</code></pre><h4>方式2：通过Callback方式回调</h4><pre><code>@Entry
@Component
struct Index {
  @State pixelMap: image.PixelMap | undefined = undefined

  build() {
    Flex({ direction: FlexDirection.Column, alignItems: ItemAlign.Center, justifyContent: FlexAlign.Center }) {
      Button('generateBarcode Callback')
        .onClick(() =&gt; {
          let content = 'huawei';
          let options: generateBarcode.CreateOptions = {
            scanType: scanCore.ScanType.QR_CODE,
            height: 400,
            width: 400
          }
          try {
            // 回调方式调用API，第三个参数为回调函数
            generateBarcode.createBarcode(content, options, (error: BusinessError, pixelMap: image.PixelMap) =&gt; {
              // 若存在错误，打印信息并返回
              if (error) {
                hilog.error(0x0000, 'BarcodeGenerate', `码图生成失败：错误码${error.code}，错误信息${error.message}`);
                return;
              }
              // 生成成功，赋值并展示
              this.pixelMap = pixelMap;
              hilog.info(0x0000, 'BarcodeGenerate', '码图生成成功');
            })
          } catch (error) {
            hilog.error(0x0000, 'BarcodeGenerate', `未知错误：${JSON.stringify(error)}`);
          }
        })
        .margin({ bottom: 30 })

      if (this.pixelMap) {
        Image(this.pixelMap)
          .width(300)
          .height(300)
          .objectFit(ImageFit.Contain)
      }
    }
    .width('100%')
    .height('100%')
  }
}</code></pre><h3>步骤3：特别说明：关于模拟器使用限制</h3><p>需重点注意：当前HarmonyOS模拟器暂不支持文本生成码图功能，若在模拟器中调用上述代码，会返回错误信息“Emulator is not supported.”。建议开发者使用真实鸿蒙设备进行功能调试与测试，确保功能正常落地。</p><h2>自定义码图：样式、尺寸与个性化配置</h2><p>基础码图生成满足通用需求，而在实际业务中，往往需要根据品牌风格、界面设计进行个性化定制。以下是最常用的自定义方向及实现思路：</p><h3>1. 自定义码图颜色与背景</h3><p>默认码图为黑色前景、白色背景，若需调整颜色，可在CreateOptions中添加foregroundColor（前景色）和backgroundColor（背景色）参数，支持RGB、RGBA格式的颜色值：</p><pre><code>let options: generateBarcode.CreateOptions = {
  scanType: scanCore.ScanType.QR_CODE,
  height: 400,
  width: 400,
  foregroundColor: '#0066CC', // 码图前景色（蓝色）
  backgroundColor: '#F5F5F5', // 码图背景色（浅灰色）
  margin: 3 // 边距调整为3px
};</code></pre><p><strong>注意</strong>：颜色组合需保证足够对比度，避免使用“浅蓝+白色”“深灰+黑色”等低对比度组合，否则会严重影响识别率。</p><h3>2. 动态调整码图尺寸</h3><p>根据不同设备屏幕尺寸、界面布局，可动态计算码图宽高。例如根据屏幕宽度的80%设置码图尺寸，确保在不同设备上显示效果一致：</p><pre><code>// 获取屏幕宽度
const screenWidth = px2vp(viewport.getWindowSize().width);
// 码图宽度设为屏幕宽度的80%，二维码需保持宽高一致
const barcodeSize = screenWidth * 0.8;

let options: generateBarcode.CreateOptions = {
  scanType: scanCore.ScanType.QR_CODE,
  height: barcodeSize,
  width: barcodeSize
};</code></pre><h3>3. 多码图类型切换</h3><p>若应用需支持多种码图类型，可通过下拉菜单或单选按钮让用户选择，动态切换scanType参数：</p><pre><code>// 定义支持的码图类型列表
const barcodeTypes = [
  { label: 'QR Code', type: scanCore.ScanType.QR_CODE },
  { label: 'Code 128', type: scanCore.ScanType.CODE_128 },
  { label: 'EAN-13', type: scanCore.ScanType.EAN_13 }
];

@State selectedType: scanCore.ScanType = scanCore.ScanType.QR_CODE;

// 界面中添加单选按钮组
RadioGroup() {
  ForEach(barcodeTypes, (item) =&gt; {
    Radio(item.label)
      .value(item.type === this.selectedType)
      .onChange(() =&gt; {
        this.selectedType = item.type;
      });
  });
}

// 生成码图时使用选中的类型
let options: generateBarcode.CreateOptions = {
  scanType: this.selectedType,
  // 条形码需调整宽高比为2:1
  height: this.selectedType === scanCore.ScanType.QR_CODE ? 400 : 200,
  width: 400
};</code></pre><h3>4. 码图保存与分享</h3><p>生成码图后，可通过image模块的API将PixelMap对象保存为图片文件，或分享给其他应用：</p><pre><code>// 保存码图到本地（需申请文件读写权限）
async function saveBarcode(pixelMap: image.PixelMap) {
  const filePath = `${getContext().filesDir}/barcode.png`;
  try {
    const file = await fs.open(filePath, fs.OpenMode.WRITE_ONLY | fs.OpenMode.CREATE);
    await image.encodeToFile(pixelMap, image.Format.PNG, file.fd);
    await file.close();
    hilog.info(0x0000, 'BarcodeSave', `码图保存成功：${filePath}`);
  } catch (error) {
    hilog.error(0x0000, 'BarcodeSave', `码图保存失败：${JSON.stringify(error)}`);
  }
}

// 调用保存函数（在码图生成成功后调用）
generateBarcode.createBarcode(content, options)
  .then((pixelMap: image.PixelMap) =&gt; {
    this.pixelMap = pixelMap;
    saveBarcode(pixelMap); // 保存码图
  });</code></pre><h2>结束语</h2><p>文本生成码图作为HarmonyOS原生开发的高频实用功能，凭借“原生适配、低代码实现、多类型支持”的优势，成为连接用户、设备、服务的重要桥梁。通过本文的详细拆解，从技术原理、场景落地到代码实现、个性化定制，相信开发者已能轻松掌握这一功能的核心逻辑。在实际开发中，建议大家根据业务场景选择适配的码图类型，严格遵循官方约束规范，确保功能的稳定性与用户体验。最后希望本文能为大家提供实用的技术参考，助力大家在鸿蒙生态开发中快速落地优质功能！</p>]]></description></item><item>    <title><![CDATA[汽车制造系统如何实现全流程数据闭环管理？ 月下水光 ]]></title>    <link>https://segmentfault.com/a/1190000047498216</link>    <guid>https://segmentfault.com/a/1190000047498216</guid>    <pubDate>2025-12-23 18:08:00</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在工业4.0与智能制造加速演进的背景下，汽车制造系统正经历一场由数据驱动、智能协同和全流程闭环管理引领的深刻变革。作为现代制造业中结构最复杂、精度要求最高的生产体系之一，汽车制造系统涵盖冲压、焊接、涂装与总装四大核心环节，传统模式下长期面临信息孤岛、响应滞后、质量追溯困难和供应链协同低效等痛点。而如今，以制造执行系统（MES）为核心、深度融合人工智能与云边端架构的新型汽车制造系统，正重塑行业效率与质量的边界。<br/>广域铭岛作为这一转型的关键推动者，凭借其Geega MES系统与“工业智造超级智能体”架构，为汽车制造系统提供了从底层数据采集到顶层智能决策的一体化解决方案。该系统不再仅是生产流程的记录工具，而是演变为具备自我学习、动态优化与实时响应能力的智能中枢。通过标准化采集2000多个设备点位的数据，并结合运筹学算法与AI模型，系统可智能优化订单排产、资源调度与工艺参数，使某头部车企订单交付周期缩短15%，质量损失成本下降13%。<br/>在质量管控方面，广域铭岛构建了覆盖全生命周期的质量追溯体系。其QCM系列质量管理APP将每一个焊点参数、喷涂厚度、装配扭矩等关键数据实时记录并精准关联至工位、人员与零部件批次，实现毫秒级问题定位。这一能力推动质量管理从“抽样检测”跃升至“100%全数检验”，重大质量事故率降低高达72%，为新能源电池等高精度领域树立了百万分之一坏品率的新标杆。<br/>更进一步，广域铭岛打通了汽车制造系统与供应链（SRM）、设备维护（TPM）及碳效管理的端到端协同链条。当库存接近预警阈值，系统自动触发补货指令并动态调整生产计划，有效消除“停工待料”；预测性维护模型可提前数周预警设备故障，显著降低非计划停机；碳效管理模块则助力工厂运营成本降低15%，推动绿色制造落地。<br/>未来，汽车制造系统将不再局限于单厂自动化，而是向生态化、云端化与数字孪生驱动演进。广域铭岛提出的“工业智造超级智能体”正是这一趋势的典范——它将AI深度嵌入制造网络的每一个节点，构建“数据采集—智能分析—自主决策—持续优化”的动态闭环，实现从经验驱动向数据智能驱动的根本性跃迁。</p>]]></description></item><item>    <title><![CDATA[项目管理中如何跟踪工时？ 英勇无比的羽毛球 ]]></title>    <link>https://segmentfault.com/a/1190000047498316</link>    <guid>https://segmentfault.com/a/1190000047498316</guid>    <pubDate>2025-12-23 18:07:18</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>时间跟踪是高效项目管理的重要组成部分，因为它能清晰地展现各项任务和团队成员的时间分配情况。通过准确跟踪时间，项目经理可以更好地预估项目进度，高效分配资源，并及早发现潜在瓶颈。它还有助于控制成本、提升责任落实，并确保项目按时按范围完成。总而言之，时间跟踪有助于做出明智的决策，从而提高生产力并最终成功交付项目。</p><p>Zoho Projects 支持两种时间跟踪方法。使用Zoho Projects 的计时器选项，用户可以自动跟踪时间。如果他们希望自己添加工时，他们可以使用工时模块添加他们的工时。工时代表一个用户的工时，工时表本质上是将多个工时记录汇总在一起，这样可以一次性提交审核和批准，而无需单独发送每个工时记录。“工时表”选项卡作为单独的模块，仅在门户网站配置了“基于工时表”审批设置后才会出现在左侧导航面板中。</p><p>例如，项目用户负责项目中的多个任务。每天，用户都需要记录任务工时，这项工作将持续数月。用户无需在“工时记录”选项卡中逐条提交工时记录，而是可以在“工时表”选项卡中创建一个为期 30 天的工时表，并在整个月内持续以草稿形式添加工时记录，最后在提交审批前进行全面审核。</p><p>Zoho Projects里面用户可以创建工时审批规则。通过该规则他们可以设置审批工时的用户。如果用户希望进行审批提醒他们可以设置审批提醒。</p><p>借助“工时记录限制”选项，您可以设置每日和每周的工时记录上限。您可以限制用户记录的工时不得超过允许的上限。默认情况下，工时上限为每日 24 小时，每周 168 小时（基于工作时间）。例如，假设一位经理将每日工时上限设置为 8 小时，每周工时上限设置为 50 小时。员工每天最多可以记录 8 小时。如果只记录了 5 小时，剩余的 3 小时可以稍后记录。</p><p>在 Zoho Projects 中，管理员可以设置工时记录提醒的阈值。如果用户输入的工时少于指定的时长，系统将通知用户。<br/>例如，如果管理员将阈值设置为 9 小时，而用户记录了 8 小时，系统将在该工作小时结束前几分钟发送提醒。您可以设置每日和每周提醒的时间，并可根据您的偏好，将提醒排除在特定用户和角色之外。</p><p>考勤表还可以配置为允许或限制记录过去和未来的工时。<br/>例如，允许员工记录过去所有日期的工时，但限制只能记录未来两周内的工时。如果员工从 2025 年 9 月 1 日开始处理一项任务，并且耗时超过两周才完成，则他只能记录到 2025 年 9 月 15 日之前的工时。</p>]]></description></item><item>    <title><![CDATA[去中心化、主从架构、HA 傻傻分不清？1分钟看懂核心差异，架构设计面试稳了！ 悲伤的斑马 ]]></title>    <link>https://segmentfault.com/a/1190000047498320</link>    <guid>https://segmentfault.com/a/1190000047498320</guid>    <pubDate>2025-12-23 18:06:26</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>面试被问“系统架构选型”时，是否总被“去中心化”“主从架构”“HA（高可用）”绕晕？这三个概念看似复杂，实则逻辑清晰。本文用1个比喻+3张对比图，帮你1分钟理清关系，从此架构设计不踩坑！</p><p>一、核心概念速览：用“开公司”比喻理解<br/>假设你要开一家连锁餐厅，需要设计一套“管理员工（服务节点）”的架构：<br/>去中心化：没有总店长，每家分店（节点）自主决策，互相协作（如P2P网络）。<br/>主从架构：设1个总店长（主节点）统筹，分店（从节点）执行指令（如MySQL主从复制）。<br/>HA（高可用）：确保“总店长”或“分店”出问题时，系统仍能运行（如双机热备）。<br/>关键区别：<br/>去中心化 vs 主从架构：有无中心节点；<br/>主从架构 vs HA：HA是目标，主从是实现手段之一。</p><p>二、分场景拆解：3种架构的适用场景与优缺点</p><ol><li>去中心化架构：无“老板”的平等协作<br/>典型场景：区块链、P2P文件共享（如BitTorrent）、分布式存储（如IPFS）。<br/>核心特点：<br/>无单点故障：没有中心节点，任意节点宕机不影响整体。<br/>可扩展性强：新增节点直接加入网络，无需中心协调。<br/>一致性难保证：节点间通过协议协商（如Gossip协议），可能存在数据短暂不一致。<br/>案例：<br/>比特币网络：所有节点平等，交易需全网验证，避免中心化操控。<br/>IPFS存储：文件碎片分散在多个节点，无中心服务器控制。<br/>适用场景：<br/>对容错性要求极高（如金融交易）；<br/>需要快速扩展且成本敏感（如物联网设备组网）。<br/>缺点：<br/>决策效率低（需全网共识）；<br/>开发复杂度高（需处理节点间通信与冲突）。</li><li>主从架构：1个“老板”+N个“员工”<br/>典型场景：数据库读写分离（如MySQL主从）、消息队列（如Kafka分区）、缓存集群（如Redis主从）。<br/>核心特点：<br/>主节点负责写操作，从节点同步数据并处理读请求。<br/>数据强一致：主节点写入成功后，从节点必须同步完成。<br/>单点瓶颈：主节点故障时，需手动或自动切换从节点为主（需配合HA）。<br/>案例：<br/>MySQL主从复制：主库处理写请求，从库提供读服务，减轻主库压力。<br/>Kafka分区：每个分区有1个Leader（主）和多个Follower（从），确保数据不丢失。<br/>适用场景：<br/>读多写少的业务（如电商商品查询）；<br/>需要数据强一致的场景（如订单系统）。<br/>缺点：<br/>主节点性能压力大；<br/>故障切换需额外机制（如HA）。</li><li>HA（高可用）：让系统“永不停机”<br/>核心目标：通过冗余设计，确保系统7×24小时运行，即使部分组件故障也不影响服务。<br/>实现手段：<br/>主从架构+故障自动切换（如MySQL自动failover）；<br/>多活架构（如异地多数据中心，如阿里云多AZ部署）；<br/>负载均衡（如Nginx分流请求，避免单节点过载）。<br/>案例：<br/>AWS RDS多可用区部署：主数据库在一个AZ，从数据库在另一个AZ，主故障时自动切换。<br/>Kubernetes集群：通过Pod自动重启与节点调度，确保服务不中断。<br/>关键指标：<br/>RTO（恢复时间目标）：故障后恢复服务的时间（越短越好）；<br/>RPO（恢复点目标）：故障时丢失的数据量（越小越好）。<br/>适用场景：<br/>对可用性要求极高的业务（如支付、医疗系统）；<br/>无法接受停机损失的场景（如在线教育直播）。</li></ol><p>三、3张对比图：1秒看懂差异<br/><img width="723" height="252" referrerpolicy="no-referrer" src="/img/bVdnsD4" alt="" title=""/></p><p>四、面试高频问题：如何回答？<br/>Q1：去中心化架构是否比主从架构更优？<br/>答：不一定。去中心化适合容错性要求高、可接受短暂不一致的场景（如区块链）；主从架构适合需要强一致且读多写少的场景（如数据库）。选择需结合业务需求。</p><p>Q2：HA是否必须用主从架构？<br/>答：不是。HA是目标，主从是手段之一。其他方式如多活架构、负载均衡也能实现HA。</p><p>Q3：如何设计一个高可用的去中心化系统？<br/>答：需结合去中心化协议（如Gossip）与冗余设计（如多副本存储），同时通过共识算法（如Raft）保证数据一致性。</p><p>结语：架构设计没有“最优解”，只有“最适合”<br/>去中心化、主从架构、HA并非对立关系，而是解决不同问题的工具。理解它们的核心逻辑后，你就能根据业务需求（如一致性、可用性、成本）灵活组合，设计出“既稳定又高效”的系统！</p>]]></description></item><item>    <title><![CDATA[鸿蒙harmonyos开发一款分布式五子棋游戏（升级版）课分享 资源999it点top ]]></title>    <link>https://segmentfault.com/a/1190000047498360</link>    <guid>https://segmentfault.com/a/1190000047498360</guid>    <pubDate>2025-12-23 18:05:28</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>鸿蒙分布式游戏优化：升级版五子棋——我的学习路径与重点聚焦<br/>在接触鸿蒙分布式游戏优化，特别是升级版五子棋这一实践项目时，我意识到其核心在于充分利用鸿蒙系统的分布式能力，解决多设备协同下的游戏体验痛点。为了更快掌握这门课程，我将学习重点聚焦于以下几个关键方面，并融入我的学习思考：</p><p>一、 鸿蒙分布式软总线技术——理解“连接”的基石<br/>这是所有鸿蒙分布式应用的根基，五子棋游戏也不例外。我认识到，只有深刻理解分布式软总线，才能明白设备间是如何“自动发现”、“高效连接”和“稳定传输”的。</p><p>学习重点：<br/>设备发现机制：重点学习软总线如何实现跨局域网、不同设备类型（手机、平板、智慧屏等）的快速发现与组网。这对于五子棋游戏来说，意味着玩家能迅速找到对手并建立连接。<br/>连接管理：学习如何建立、维持和断开设备间的连接通道，以及连接状态的监控。稳定的连接是流畅游戏体验的前提。<br/>数据传输基础：了解软总线提供的数据传输能力，包括不同传输模式的特点，这为后续选择合适的通信方式打下基础。<br/>思考与联系：我会思考，软总线的这些特性如何保证五子棋在两台设备间建立连接时，既快速又不容易掉线？这对于游戏开始前的匹配阶段至关重要。</p><p>二、 分布式数据服务与通信机制——保障“通信”的效率与低延迟<br/>五子棋的核心是落子信息的实时同步，对通信的延迟和可靠性要求极高。这部分是“低延迟通信”的核心。</p><p>学习重点：<br/>分布式数据对象（或分布式数据库）的应用：学习如何利用分布式数据服务，实现游戏数据（如棋盘状态、当前玩家、落子位置等）在多设备间的自动同步。这种方式可能简化数据同步逻辑，减少手动通信的复杂性。<br/>高效消息传递机制：研究针对五子棋这类实时性强的游戏，如何选择最优的消息传递方式（例如，EventBus、Remote Object等），并重点关注如何降低消息传输的端到端延迟。这包括数据序列化/反序列化的开销、网络传输的优化等。<br/>数据压缩与精简：五子棋的落子信息数据量很小，但学习如何对通信数据进行极致的精简和必要的压缩，有助于在复杂网络环境下进一步降低延迟。<br/>异常处理与重连机制：学习当网络出现波动导致通信中断时，如何进行优雅的异常处理，并实现断线重连后的数据恢复，确保游戏进程不丢失。<br/>思考与联系：我会对比不同通信方式的性能特点，思考哪种最适合五子棋这种小数据量、高频次的通信场景。例如，是每次落子发送一个轻量级消息，还是通过共享一个分布式数据对象，修改后自动同步？哪种方式的延迟更低，开销更小？同时，如何确保在弱网情况下，我的落子操作能快速、准确地传达到对方设备？</p><p>三、 跨设备交互体验设计——打造“协同”的流畅与自然<br/>“跨设备交互体验提升”是升级版五子棋的亮点，要求我们不仅要“能连上”，更要“连得好”、“玩得爽”。</p><p>学习重点：<br/>界面与交互的跨设备适配：学习如何根据不同设备的屏幕尺寸、交互特性（如手机触摸、智慧屏遥控/触摸、平板键盘鼠标等）进行游戏界面的自适应调整。例如，手机上可能更强调便捷操作，智慧屏上可以提供更宏大的观战视角。<br/>分布式任务调度与资源共享：思考在五子棋游戏中，不同设备可以扮演什么角色。例如，一台设备负责主游戏逻辑和AI计算，另一台设备作为控制端或显示端。学习如何利用鸿蒙的分布式任务调度能力，合理分配任务，提升整体体验。甚至，是否可以利用一台设备的算力进行更高级别的AI对手计算。<br/>无缝衔接的交互体验：学习如何实现游戏在不同设备间的无缝流转。例如，玩家在手机上开始一局五子棋，然后可以将游戏“流转”到智慧屏上继续，体验不中断。<br/>多设备协同的特效与反馈：探索如何利用多设备协同创造独特的游戏体验。例如，在一台设备落子时，另一台设备可以有震动、声效或屏幕特效的协同反馈，增强沉浸感。<br/>思考与联系：我会想象自己作为用户，在不同设备组合下玩五子棋的场景。比如，我用手机落子，智慧屏显示棋盘，希望有什么样的体验？界面如何适配？操作如何简化？如果我在平板上观战，又需要怎样的信息呈现？这些思考能帮助我理解跨设备交互设计的原则和技巧。</p><p>四、 游戏逻辑与分布式特性的深度融合——实现“优化”的最终目标<br/>前述三个方面为五子棋的分布式优化提供了技术支撑和设计思路，最终要将这些技术与游戏逻辑本身紧密结合。</p><p>学习重点：<br/>游戏状态的一致性维护：确保无论在多少设备间协同，所有设备看到的棋盘状态、当前玩家信息、胜负判定结果等必须完全一致。这是分布式游戏最核心的挑战之一。<br/>基于分布式特性的游戏创新玩法：思考如何利用鸿蒙分布式特性，设计出传统单设备五子棋无法实现的新玩法或新模式。例如，多人协作对战、跨设备观战、设备间“角色扮演”等。<br/>性能监控与调优实践：学习如何使用鸿蒙提供的性能监控工具，对游戏在不同设备组合下的帧率、内存占用、网络延迟等进行监控和分析，并针对性地进行优化。<br/>思考与联系：我会将游戏逻辑拆解，思考每个环节如何利用分布式能力进行优化。例如，胜负判定逻辑放在哪里执行效率最高？AI计算是否可以分布式进行？如何通过性能分析工具找到瓶颈，并结合前面学到的通信和交互知识进行优化？</p><p>总结与展望<br/>对于鸿蒙分布式游戏优化——升级版五子棋这门课程，我认为通过重点学习分布式软总线技术（连接基础）、分布式数据服务与通信机制（通信核心）、跨设备交互体验设计（用户体验）以及游戏逻辑与分布式特性的深度融合（应用实践），能够构建起完整的知识体系。学习过程中，我会结合五子棋的具体场景进行思考和实践，从理解原理到动手优化，逐步掌握这门课程的精髓，最终能够独立开发出低延迟、流畅且富有创新交互体验的鸿蒙分布式游戏。这不仅是技术的学习，更是对未来多设备协同应用开发思维的一次重要训练。</p>]]></description></item><item>    <title><![CDATA[仓储智能体如何实现库存健康度的全面监测与分析？ 雨大王 ]]></title>    <link>https://segmentfault.com/a/1190000047498397</link>    <guid>https://segmentfault.com/a/1190000047498397</guid>    <pubDate>2025-12-23 18:04:30</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>一、库存健康度监测分析的重要性<br/>在现代制造业转型升级的浪潮中，库存管理正经历一场前所未有的变革。传统的库存管理方式往往依赖于人工经验与定期盘点，这种方式不仅效率低下，还难以应对日益复杂多变的市场需求。库存健康度作为衡量企业供应链管理能力的关键指标，其重要性不言而喻。一个健康的库存体系能够有效平衡资金占用与服务水平，避免因库存积压导致的资金链断裂，以及因库存短缺引发的客户流失。<br/>在当前的市场环境下，库存管理面临着多重挑战。首先，需求波动成为常态，企业需要在有限库存与服务能力之间找到最佳平衡点。其次，供应链协同复杂性增加，跨部门、跨区域的库存管理需要更高效的工具支撑。再者，各类商品SKU数量激增，特别是多品种、小批量、按订单生产的模式，使得库存管理更加复杂化。在这样的背景下，仓储智能体的出现为企业提供了新的解决思路。<br/>二、仓储智能体的核心技术与实施路径<br/>仓储智能体的实施需要依托先进的技术架构。首先，在数据采集层面，系统通过部署于仓库各区域的智能标签和传感器，实时获取商品的位置、数量、状态等信息。这些数据经过边缘计算处理后，通过5G网络传输到云端分析平台。其次，在分析层面，仓储智能体融合了机器学习、数字孪生和知识图谱等技术，能够对历史销售数据、市场趋势进行深度挖掘，预测未来库存需求。最后，在执行层面，系统通过智能算法生成最优库存策略，包括ABC分类法、安全库存阈值设置等，实现库存的动态管理。<br/>具体来说，仓储智能体的技术特点主要体现在以下几个方面：一是实时性，通过物联网设备实现库存数据的分钟级更新；二是预测性，基于历史数据和市场因素建立需求预测模型；三是智能性，利用AI算法自动优化库存策略；四是协同性，打破各部门间的数据壁垒，实现库存信息的跨部门共享。这种技术架构使企业能够从被动应对库存问题转向主动预测和管理。<br/>三、实际案例分析<br/>在某工业阀门制造企业中，仓储智能体的实施带来了显著成效。该企业采用金蝶云·星空的仓储智能体解决方案后，实现了从传统管理模式到数字化管理的根本转变。这些措施使库存周转率提升了35%，仓储面积利用率优化了28%，库存成本显著降低。<br/>广域铭岛的解决方案特别强调了预警机制的智能化。系统每日自动推送库存异常报告，包括库龄超过6个月的物料清单、未来两周的高缺货风险物料等，直接推送给采购、计划及财务负责人。这种主动预警机制使企业能够提前采取措施，避免因库存问题导致的生产中断或客户投诉。实施半年后，该企业的库存周转天数从120天降至78天，库存资金占用减少了约2000万元，取得了显著的经济效益。<br/> 东杰智能的智能制造与仓储一体化系统。其设备兼容多种物料规格，换型调整时间缩短至30分钟内。</p>]]></description></item><item>    <title><![CDATA[DataWorks 又又又升级了，这次我们通过 Arrow 列存格式让数据同步速度提升10倍！ 阿里]]></title>    <link>https://segmentfault.com/a/1190000047498402</link>    <guid>https://segmentfault.com/a/1190000047498402</guid>    <pubDate>2025-12-23 18:03:59</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>引言</h2><p>在大数据时代，数据集成作为企业数据流转的核心枢纽，承担着异构数据源之间高效同步的重要职责。随着数据量的爆炸式增长，传统的行存同步方式在面对大规模列存数据处理时，逐渐显露出性能瓶颈。</p><p>为解决这一挑战，，DataWorks数据集成推出基于Apache Arrow列存格式的高性能同步能力，实现从“行式传输”到“列式直通”的技术跃迁。通过引入零拷贝、列式内存标准Apache Arrow，DataWorks实现了跨数据源的列存到列存高效同步，性能提升最高达10倍以上，助力企业实现数据流转的“高速通道”。</p><h2>技术创新：基于Arrow的列存同步方案</h2><h3>Apache Arrow：下一代数据处理的“通用语言”</h3><p>Apache Arrow是一项由Apache基金会主导的跨语言、高性能列式内存数据标准，被广泛应用于大数据生态（如Spark、Flink、Presto等）。核心优势在于：</p><ul><li>零序列化/反序列化：数据以内存二进制块直接传输，避免格式转换开销</li><li>零拷贝（Zero-Copy）：跨进程/跨系统共享内存，极大降低CPU与内存消耗</li><li>CPU缓存友好：列式存储提升缓存命中率，优化计算效率</li><li>统一类型系统：支持复杂嵌套结构，保障跨平台类型兼容性</li></ul><p>简单来说：Arrow让数据“原样流动”，不再“反复翻译”。</p><h3>传统架构 vs Arrow架构：从“搬砖”到“高速专列”</h3><p>当前大多数数据集成工具仍基于“行存驱动”设计：</p><ul><li>Reader读取列存文件 → 解码成单行Record对象；</li><li>框架传递Record → Writer再将其编码回目标列存格式。</li></ul><p>这一过程存在严重性能浪费：</p><ul><li>多次类型转换与对象创建（如String → BigDecimal）</li><li>高频GC压力导致频繁Stop-The-World</li><li>内存带宽利用率低下</li></ul><p>而Arrow则彻底改变了这一流程：Reader直接输出列式Batch → Writer直接消费列式Batch，中间无需任何转换，真正实现“端到端列式流水线”。</p><h4>传统行存同步架构：</h4><p>面向单行行存的格式设计，每一个Record对象定义了若干个Column，每个Column包含当前行对应该列的列值Value。以MaxCompute(ODPS)列存数据同步到MaxCompute(ODPS)列存为例：<br/><img width="723" height="292" referrerpolicy="no-referrer" src="/img/bVdnsEd" alt="image.png" title="image.png"/><br/>MaxCompute表数据可能以ORC、Parquet等列存格式存储的数据，同步核心流程分为：</p><ol><li>通过MaxCompute Tunnel将数据按行读取出来，并转为MaxCompute Record对象；</li><li>MaxCompute Reader将MaxCompute Record转换为同步引擎的Record对象，投递给框架；</li><li>框架收到Record放入缓存队列;</li><li><p>Writer从框架接收引擎Record，再转换为MaxCompute Record，并通过Tunnel client将数据进行序列化后通过网络传输给Tunnel server。</p><h4>数据集成Arrow列存同步架构：</h4><p>当列存到列存同步场景下，将列存先转为行存格式，再将行存格式转为列存格式，中间多了不必要的转换及序列化操作。通过构建全新的 ArrowTabularRecord 数据结构，DataWorks实现了对Arrow列式数据的原生支持，跳过行式转换环节，实现端到端列存“短路同步”，大幅提升吞吐、降低延迟。<br/><img width="723" height="471" referrerpolicy="no-referrer" src="/img/bVdnsEo" alt="image.png" title="image.png" loading="lazy"/></p></li></ol><p>同步引擎基于新的面向Arrow列存格式的ArrowTabularRecord，列存到列存数据流转如下：<br/><img width="723" height="290" referrerpolicy="no-referrer" src="/img/bVdnsEy" alt="image.png" title="image.png" loading="lazy"/></p><p>同步核心流程如下：</p><ol><li>通过MaxCompute Tunnel Arrow API将数据直接按照Arrow列存格式读取出来，并存入ArrowTabularRecord，投递给框架；</li><li>框架收到Record放入缓存队列;</li><li><p>Writer从框架收到引擎ArrowTabularRecord，直接通过Tunnel Arrow API将数据基于Arrow格式，省去做序列化的开销，直接将内存二进制数据传输给Tunnel Server。</p><h2>核心能力：全链路列式加速，支持主流数据源</h2><p>DataWorks数据集成现已全面支持 <strong>MaxCompute、Hologres、Hive/OSS/HDFS（Parquet/ORC）</strong> 等主流列存数据源的Arrow读写能力，用户仅需在任务配置中添加 "useArrow": true 即可一键启用。</p><h3>列存直读直写，显著提升性能</h3><table><thead><tr><th><strong>数据源</strong></th><th><strong>支持能力</strong></th><th><strong>同步性能提升</strong></th></tr></thead><tbody><tr><td><strong>MaxCompute</strong></td><td>通过Tunnel Arrow API直读列存数据</td><td>同步性能提升 <strong>200%</strong></td></tr><tr><td><strong>Hologres</strong></td><td>支持Arrow格式导出，避免JDBC行式瓶颈</td><td>同步性能提升 <strong>95%</strong></td></tr><tr><td><strong>Hive\OSS\HDFS</strong>等分布式文件</td><td>直接读取Parquet/ORC底层Arrow格式数据</td><td>PARQUET同步性能提升<strong>5.55倍</strong>ORC同步性能提升 <strong>9.85倍</strong></td></tr></tbody></table></li></ol><p><strong>示例：Hive ORC → MaxCompute 写入，原需数小时的任务，现可在数十分钟内完成。</strong></p><h3>性能压测报告</h3><p>我们对多个典型场景进行了端到端性能测试，同步性能显著提升，可实现<strong>从小时级到分钟级</strong>的数据同步周期提升：</p><h4>场景一：MaxCompute列存短路同步（Arrow → Arrow）</h4><table><thead><tr><th><strong>并发数</strong></th><th><strong>传统行存</strong></th><th><strong>Arrow列存</strong></th><th><strong>性能提升</strong></th></tr></thead><tbody><tr><td>1</td><td>67.8 MB/s<br/>3740 R/s</td><td>212.6 MB/s<br/>11462 R/s</td><td><strong>+206.5%</strong></td></tr><tr><td>3</td><td>185.6 MB/s<br/>10226 R/s</td><td>569.9 MB/s<br/>30728 R/s</td><td><strong>+200.5%</strong></td></tr><tr><td>8</td><td>462.1 MB/s<br/>25467 R/s</td><td>1321.0 MB/s<br/>71143 R/s</td><td><strong>+197.4%</strong></td></tr></tbody></table><h4>场景二：Hologres → MaxCompute 同步</h4><table><thead><tr><th><strong>并发数</strong></th><th><strong>传统同步</strong></th><th><strong>Arrow同步</strong></th><th><strong>性能提升</strong></th></tr></thead><tbody><tr><td>4</td><td>439.1 MB/s<br/>216480 R/s</td><td>906.1 MB/s<br/>404270 R/s</td><td><strong>+87%</strong></td></tr><tr><td>8</td><td>773.3 MB/s<br/>381300 R/s</td><td>1669.1 MB/s<br/>745654 R/s</td><td><strong>+95%</strong></td></tr></tbody></table><h4>场景三：Parquet/ORC → MaxCompute 同步</h4><table><thead><tr><th><strong>并发数</strong></th><th><strong>传统同步</strong></th><th><strong>Arrow同步</strong></th><th><strong>性能提升</strong></th></tr></thead><tbody><tr><td>Parquet</td><td>26.1 MB/s<br/>35631 R/s</td><td>1198.1 MB/s<br/>233587 R/s</td><td><strong>5.55倍</strong></td></tr><tr><td>ORC</td><td>21.4 MB/s<br/>27661 R/s</td><td>3256.3 MB/s<br/>300326 R/s</td><td><strong>9.85倍</strong></td></tr></tbody></table><p>备注：Parquet、ORC文件可以在HDFS、OSS等分布式文件系统中</p><h2>核心优势：不止于快，更稳、更低成本</h2><table><thead><tr><th><strong>特性</strong></th><th><strong>价值说明</strong></th></tr></thead><tbody><tr><td><strong>高性能</strong></td><td>吞吐量提升最高达10倍，适合宽表、大数据量搬站同步</td></tr><tr><td><strong>低资源消耗</strong></td><td>零拷贝 + 内存复用，降低GC压力，节省计算成本</td></tr><tr><td><strong>高兼容性</strong></td><td>支持MaxCompute、Hologres、Hive等主流列存系统</td></tr><tr><td><strong>易用性</strong></td><td>仅需配置useArrow: true，无需代码改造</td></tr></tbody></table><h2>典型应用场景：释放数据流转的无限可能</h2><h3>场景一：大数据搬站迁移</h3><p><strong>痛点</strong>：从Hive向MaxCompute迁移数百TB数据，耗时较久，影响业务上线 <strong>方案</strong>：启用Arrow同步，列存直传，避免格式转换 <strong>成果</strong>：迁移时间从<strong>小时级同步缩短至分钟级</strong>，效率提升<strong>10倍以上</strong></p><h3>场景二：异构数据源融合与湖仓一体化</h3><p>支持Hive（湖）与Hologres/MaxCompute（仓）之间的列存高效互通，为<strong>数据湖仓一体架构</strong>提供核心数据流转引擎，实现“一数多用、湖仓协同”。</p><h2>如何使用？一步开启Arrow加速</h2><h3>整库解决方案</h3><p>数据集成已经发布Hive-&gt;MaxCompute整库同步功能，默认会自动根据同步字段类型，渲染开启Arrow高性能同步能力。<br/><img width="723" height="678" referrerpolicy="no-referrer" src="/img/bVdnsER" alt="image.png" title="image.png" loading="lazy"/></p><p>💡 <strong>无需代码改造，无需理解底层细节，一键开启高性能同步</strong>。</p><h3>单表离线同步</h3><p>DataWorks数据集成单表离线任务，在reader和writer parameter下添加 useArrow: true 参数，即可开启列式加速（由于是列存格式直读直写，开启前提是需要保证源端和目标端列类型保持一致）：</p><pre><code class="json">{
  "type": "job",
  "steps": [
    {
      "stepType": "hive",
      "parameter": {
        "useArrow": true,
        "datasource": "my_datasource",
        "column": [
          "col1",
          "col2"
        ],
        "readMode": "hdfs",
        "table": "table"
      },
      "name": "Reader",
      "category": "reader"
    },
    {
      "stepType": "odps",
      "parameter": {
        "useArrow": true,
        "truncate": false,
        "datasource": "odps_test",
        "column": [
          "col1",
          "col2"
        ],
        "table": "table"
      },
      "name": "Writer",
      "category": "writer"
    }
  ],
  "setting": {
    "speed": {
      "concurrent": 3
    }
  }
}</code></pre><h2>未来演进：构建更强大的数据同步生态</h2><p>DataWorks将持续深化Arrow能力，打造企业级高性能数据流转平台：</p><ul><li><strong>更多数据源支持</strong>：扩展至HDFS、Paimon、ClickHouse、Iceberg等；</li><li><strong>智能调度优化</strong>：根据数据特征自动选择Arrow或行式模式；</li><li><strong>生态融合</strong>：为DataWorks数据搬站，提供端到端数据解决方案</li></ul><h2>结语：让数据真正高性能“跑”起来</h2><p>DataWorks数据集成引入Apache Arrow列存同步能力，列式、零拷贝、内存级传输为同步性能带来显著提升。DataWorks数据集成正以技术创新为引擎，帮助企业打破数据孤岛、消除性能瓶颈，让数据在湖仓之间、系统之间、业务之间高速、稳定、低成本流动。</p>]]></description></item><item>    <title><![CDATA[【实用技巧】一分钟搞懂『控件属性操作』赋值操作的左右侧！ 千杯不醉的柚子 ]]></title>    <link>https://segmentfault.com/a/1190000047498408</link>    <guid>https://segmentfault.com/a/1190000047498408</guid>    <pubDate>2025-12-23 18:03:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>很多小伙伴操作『控件属性操作』赋值时容易搞混，分享个简单总结，一看就懂：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047498410" alt="图片" title="图片"/></p><h3>配置说明：</h3><table><thead><tr><th>赋值位置</th><th>名称</th><th>说明</th></tr></thead><tbody><tr><td>左边</td><td>被赋值对象</td><td>接收值的对象</td></tr><tr><td>右边</td><td>赋值对象</td><td>提供值的对象</td></tr></tbody></table><p>举个最基础的例子：a = 10 <br/>左边的a是「被赋值对象」，负责接收 10 这个值； <br/>右边的10是「赋值对象」，负责把值给出去。<br/><strong>不管是变量赋值、对象属性赋值，核心逻辑都一样 —— 左边接值，右边给值，再也不用搞混啦</strong></p>]]></description></item><item>    <title><![CDATA[2025年甘特图工具测评：项目管理甘特图哪个好用？ 项目管理小胡 ]]></title>    <link>https://segmentfault.com/a/1190000047498426</link>    <guid>https://segmentfault.com/a/1190000047498426</guid>    <pubDate>2025-12-23 18:02:43</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>本文深度测评 ONES、飞书多维表格、Asana、ClickUp、Microsoft Project 六款项目管理甘特图工具，从项目排期、进度计划、依赖关系到关键路径，给出上手体验、适用场景与选型清单，帮你快速选择适合团队的项目甘特图工具。</p><h2>5 款甘特图工具盘点</h2><h4>1. 飞书多维表格：先把时间线“跑起来”</h4><p>核心功能：飞书多维表格的甘特视图，本质是“表格数据的时间线呈现”：根据开始/结束日期自动生成时间条，支持拖拽改期、周/月/季/年视图切换、里程碑等。</p><p>如果你的团队沟通都在飞书里，想快速对齐项目排期，并且需要一张“人人看得懂”的项目时间轴，用来周会同步节奏，或者是项目还在早期，项目先把阶段和关键节点铺开。那么可以先尝试使用飞书多维表格。</p><p>它给我的感受就是“快”：我可以在 10 分钟内拉出一张可用时间线，立刻把讨论从“你觉得”变成“我们先按这个版本对齐”。对新人 PM 来说，这种即时反馈真的很重要。</p><p>亮点与局限：</p><ul><li>亮点：拖拽改日期很顺，且会同步回其他视图字段；还能设置里程碑，适合对齐关键节点。</li><li>局限：它不支持设置任务依赖关系（不能在时间条之间创建前后置）。</li></ul><p>一句话总结：飞书多维表格像“入门级甘特图工具”，目标是——先让大家看到同一条时间线。<br/><img width="723" height="353" referrerpolicy="no-referrer" src="/img/bVdnsEU" alt="" title=""/></p><h4>2. ONES Project：集规划项目与跟踪进度于一体的甘特图工具</h4><p>如果说飞书解决的是“看得清”，那当项目进入变更多、依赖多、周期长的阶段，我会更想要“控得住”。ONES 就是一款我觉得“控得住”项目的工具。</p><p>核心功能：<a href="https://link.segmentfault.com/?enc=2A6FXkmSPvYrfCWIK8JaRQ%3D%3D.BOEkzW0lQmmoPYdSf4rfMQ%3D%3D" rel="nofollow" target="_blank">ONES Project</a> 不只是画一张时间条，而是提供面向项目交付的甘特图能力，它支持树状和平铺视图，按成员维度分组查看任务；里程碑与关键任务用不同颜色标识；视图粒度可以跨天、周、月到 2 年；创建/调整任务时可设置四种依赖关系并自动排期；支持关键路径识别、基线对比、交付物跟踪等专业管控功能。</p><p><strong>优势亮点：</strong></p><ul><li>依赖管理与自动排期：拖拽创建前后置依赖，可以自动调整后置任务时间。</li><li>信息展示与导出灵活：可在图上显示标题、进度百分比、依赖延迟等信息，导出时自选字段并自定义表头。</li><li>里程碑与关键任务高亮：里程碑显示蓝色标签，关键任务显示橙色标签，可快速识别关键路径和风险节点。</li><li>WBS 序号与快速关联：表头可添加 WBS 序号，并用 WBS 指定前后置任务；支持将已有工作项快捷添加为 WBS 子任务。</li><li>交付物和基线管理：项目执行过程中可为任务设置交付物，并在计划、执行、监控阶段跟踪状态；支持设置基线并对比计划与实际偏差。</li></ul><p><strong>适用场景：</strong></p><ul><li>长期/多层级项目：周期跨越数月或数年的研发、制造、集成项目，需要宏观视角和关键路径分析。</li><li>交付型团队：强调交付物管理和进度管控的瀑布或混合项目，需要跟踪文件、Wiki、链接等成果。</li><li>对进度准确性要求高：需要通过基线、关键路径和自动排期来减少偏差，快速识别风险。</li></ul><p>使用感受（新 PM 视角）：</p><p>刚上手 ONES Project 会有一种“驾驶舱”感：必须提前把里程碑、关键任务和依赖关系梳理清楚，才能用好自动排期、关键路径识别等功能。但一旦建立好结构，调整计划或出现延迟时，系统会根据依赖自动联动并提示偏差，省去了手动计算和不断对表的麻烦，真正感受到“被工具拽着往前走”。<br/><img width="723" height="443" referrerpolicy="no-referrer" src="/img/bVdiPSl" alt="" title="" loading="lazy"/></p><h4>3. Asana：协作体验舒服，适合用时间线推动执行</h4><p>核心功能：Asana 的 Timeline 支持设置依赖关系、调整时间线、共享项目时间线，并提供依赖日期移动的策略（例如：保持/消耗/忽略 due date buffer 等处理方式）。</p><p><strong>适用场景</strong></p><ul><li>跨部门协作频繁，需要“任务里更新、时间线里对齐”</li><li>你希望甘特图不是“展示给老板看”，而是团队每天都会用来推进</li></ul><p><strong>亮点与局限</strong></p><ul><li>亮点：依赖关系可以在时间线里直接设置，联动策略对变更场景很友好。</li><li>局限：如果团队只想要“轻量排期板”，它会显得偏重。</li><li>我会怎么用：把它用在“协作密度高”的项目上，把时间线当团队共识，而不是 PM 的个人作品。</li></ul><p>使用感受（新 PM 视角）：Asana 的好处是“执行闭环感强”：成员在任务里更新，你不用靠追问来维护甘特图——时间线自然就更可信。<br/><img width="723" height="393" referrerpolicy="no-referrer" src="/img/bVdnjK6" alt="" title="" loading="lazy"/></p><h4>4. ClickUp：功能密集型甘特图工具，适合“愿意折腾”的团队</h4><p>核心功能：ClickUp 提供 Critical Path（关键路径）与 Slack Time（松弛时间）能力：前者帮助识别“必须准时完成的任务链”，后者帮你看出“哪些任务能挪动而不影响大节点”。</p><p><strong>适用场景</strong></p><ul><li>项目复杂、任务多，且团队愿意投入时间把流程配置起来</li><li>你需要更强的“计划推演能力”，比如识别哪里一延就全延</li></ul><p><strong>亮点与局限</strong></p><ul><li>亮点：关键路径/松弛时间对新人特别友好，因为它直接告诉你“先盯哪几件事”。</li><li>局限：学习曲线相对陡，需要团队共识和维护者。</li><li>落地建议：先用一个项目试点，用复盘决定要不要扩到全团队。</li></ul><p>使用感受（新 PM 视角）：它像“工具箱很满的工作台”。我会先明确自己的 1–2 个核心诉求（比如依赖+关键路径），只启用必要功能，否则很容易在功能海里迷路。<br/><img width="723" height="461" referrerpolicy="no-referrer" src="/img/bVdm9We" alt="" title="" loading="lazy"/></p><h4>5. Microsoft Project：传统 PM 的硬核甘特图工具</h4><p>核心功能：Microsoft Project 支持在甘特图等视图中链接任务，创建前置/后置依赖关系，并支持多种依赖类型（如完成-开始、开始-开始等）。</p><p><strong>适用场景</strong></p><ul><li>工程/交付类项目：强调标准化计划表达、严谨排程</li><li>团队里有人熟悉 WBS、关键路径、资源约束等传统项目管理方法</li></ul><p>亮点与局限</p><ul><li>亮点：依赖表达与计划输出很标准，适合对外/对上汇报。</li><li>局限：协作闭环要靠流程配套，否则甘特图容易“很专业但没人更新”。</li></ul><p>使用感受（新 PM 视角）：它像“驾驶舱”：专业、规范、表达力强，但对新人来说确实更需要学习成本。如果团队只是“偶尔看一眼”，它就容易变成 PM 自己的工具，而不是团队的协作工具。<br/><img width="723" height="393" referrerpolicy="no-referrer" src="/img/bVdnofm" alt="" title="" loading="lazy"/></p><h2>对比与建议：选甘特图工具，我会先看这 4 条</h2><p><strong>1. 易用性：你能不能在 10 分钟内做出第一张可用时间线？</strong></p><p>如果你现在最缺的是“先对齐”：优先选飞书这类能快速出图的甘特图工具。<br/>判断信号：你们周会常常花很久讨论“到底哪天开始/哪天结束”。</p><p><strong>2. 上手门槛：团队里最忙的人，愿不愿意多点两下？</strong></p><p>如果团队协作靠自觉：选“阅读成本低、更新入口轻”的工具。<br/>判断信号：大家会说“你给我一个链接，我只看结论”，那就别上来就推复杂配置。</p><p><strong>3. 协作体验：甘特图会不会变成“上周的PPT”？</strong></p><p>如果项目变更频繁：优先选择支持依赖与联动策略的甘特图工具（ONES 这类思路更合适）。<br/>判断信号：你经常遇到“改了 A 的日期，B/C/D 没人记得跟着改”。</p><p><strong>4. 学习曲线：你们愿不愿意为“控得住变化”付出成本？</strong></p><p>如果项目一延期就全体焦虑：你需要的不只是更漂亮的甘特图，而是能帮你做“关键任务聚焦”的能力（关键路径/松弛时间/基线对比）。</p><p>判断信号：依赖太多、资源冲突多、里程碑压力大——你越晚建立规则，后面越难救。<br/>如果你也是刚转岗的项目新人，我想送你一句很朴素的话：先选一款你能坚持维护的甘特图工具，把“对齐节奏”这件事先做起来。</p><p>你可以从最轻量的项目排期开始，让团队先形成共识；等项目进入交付和变更密集期，再逐步引入依赖、关键路径、里程碑聚焦等能力，把变化“关进笼子”——不是为了控制人，而是为了减少误解和返工。</p><h2>FAQ：</h2><p><strong>1）甘特图工具是什么？项目管理甘特图有什么用？</strong></p><p>甘特图工具就是用时间轴展示任务排期、工期和里程碑的项目管理工具。它最适合用来“对齐节奏”：什么时候开始、什么时候结束、谁依赖谁、关键节点在哪。</p><p><strong>2）项目管理甘特图工具怎么选？新手最先看什么？</strong></p><p>先看四个指标：上手速度、协作体验、依赖关系、改期成本。团队愿不愿意更新、依赖能不能联动、变更会不会一改就崩，基本决定你能不能长期用下去。</p><p><strong>3）在线甘特图工具适合什么团队？适合远程协作吗？</strong></p><p>在线甘特图工具最适合跨部门或远程协作团队，因为它强调共享、评论、实时更新。它的价值不是“画图”，而是让甘特图从个人计划表变成团队共同的进度共识。</p><p><strong>4）免费甘特图工具推荐吗？免费版通常卡在哪些能力？</strong></p><p>免费甘特图工具适合个人或小团队的轻量排期，但常见限制在协作人数、权限、历史版本、导出、依赖联动和自动排期。建议“先免费跑起来”，一旦项目进入频繁变更或依赖复杂阶段再升级。</p><p><strong>5）关键路径是什么？甘特图为什么要看关键路径？</strong></p><p>关键路径是决定项目总工期的那条“最不能拖”的任务链。看关键路径的意义是帮你快速锁定真正要盯的任务：任何一个关键任务延期，项目整体就会延期。</p><p><strong>6）研发/交付型项目（依赖多）更适合哪类甘特图工具？</strong></p><p>更适合“偏交付管控”的甘特图工具：支持复杂依赖、自动排期、关键路径、基线对比、交付物跟踪等能力。举例来说，像 ONES 这类面向研发交付场景的平台会更贴近这种需求（也可按这些能力去筛选同类工具）。</p>]]></description></item>  </channel></rss>