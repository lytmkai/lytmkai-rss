<?xml version="1.0" encoding="UTF-8"?><rss version="2.0">  <channel>      <title>SegmentFault - 最近文章</title>      <link>https://segmentfault.com/blogs/newest</link>      <description>SegmentFault 思否</description>      <generator>python segmentfault.py @Pi20</generator>      <item>    <title><![CDATA[知识点10：PagedAttention 刀枪不入的热带鱼 ]]></title>    <link>https://segmentfault.com/a/1190000047555060</link>    <guid>https://segmentfault.com/a/1190000047555060</guid>    <pubDate>2026-01-21 12:14:00</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <blockquote>注1：本文系"每天一个多模态知识点"专栏文章。本专栏致力于对多模态大模型/CV领域的高频高难面试题进行深度拆解。本期攻克的难题是：<strong>PagedAttention（分页注意力机制）</strong>。<br/><strong>注2：本文Markdown源码可提供下载，详情见文末</strong><br/><strong>关注"每天一个多模态知识点"公众号，每天一个知识点的深度解析！</strong><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047546797" alt="" title=""/></blockquote><hr/><h2>知识点10 | PagedAttention：突破LLM推理内存墙的虚拟内存艺术</h2><h3>——从操作系统虚拟内存到注意力机制的革命性融合</h3><h4>一、面试原题复现</h4><p><strong>"请详细解释PagedAttention算法的核心原理，说明它如何借鉴操作系统的虚拟内存分页机制来解决KV cache的内存碎片问题。请给出完整的数学推导和代码实现，并分析其对LLM推理性能的影响。"</strong></p><hr/><h4>二、关键回答（The Hook）</h4><p>PagedAttention是<strong>将操作系统虚拟内存分页机制首次成功应用于Transformer注意力计算</strong>的革命性算法。它通过将KV cache划分为固定大小的块（Block），允许这些块存储在<strong>非连续的物理内存</strong>中，从而：</p><ol><li><strong>消除外部碎片</strong>：所有块大小相同，不存在小内存间隙</li><li><strong>极大降低内部碎片</strong>：按需分配，每个序列最多浪费一个块的空间</li><li><strong>实现跨序列共享</strong>：支持copy-on-write机制，多个采样路径可共享相同前缀的KV cache</li></ol><blockquote><strong>面试加分项</strong>：能够明确指出PagedAttention本质上是将KV cache从传统的"张量视角"转换为"页式存储视角"，这一视角转换为推理系统带来了质的飞跃。</blockquote><hr/><h4>三、深度原理解析（The Meat）</h4><h5>3.1 问题背景：KV Cache的内存困境</h5><p>在LLM推理中，每个token的生成都需要计算它与之前所有token的注意力。为了避免重复计算，系统会缓存历史token的Key和Value向量，即KV cache。</p><p>对于L层、H个注意力头、头维度为d_k的模型，处理T个token序列的KV cache内存占用为：</p><p>$$
M_{KV} = 2 \cdot L \cdot H \cdot T \cdot d_k \cdot B
$$</p><p>其中B是每个元素的字节数（FP16时为2字节）。以Llama-2-7B为例：</p><ul><li>L = 32, H = 32, d_k = 128</li><li>T = 4096时，KV cache占用约<strong>1.6 GB</strong></li></ul><p><strong>传统KV cache管理的三大致命缺陷</strong>：</p><ol><li><p><strong>内部碎片（Internal Fragmentation）</strong></p><ul><li>系统需要为每个序列预分配最大可能的token空间</li><li>假设预分配2048个槽位，实际只生成了500个token</li><li>浪费比例高达<strong>75.6%</strong></li></ul></li><li><p><strong>外部碎片（External Fragmentation）</strong></p><ul><li>不同请求的序列长度不同，在连续内存中产生大量空隙</li><li>传统方法无法利用这些离散的空隙</li></ul></li><li><p><strong>无法支持共享</strong></p><ul><li>多个请求即使有相同前缀（如相同的系统提示词），也无法共享KV cache</li></ul></li></ol><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555063" alt="" title="" loading="lazy"/><br/><em>图1：内部碎片示意图。预分配的内存空间（白色Fragment）中，实际使用的只是灰色区域，白色区域完全浪费</em></p><h5>3.2 PagedAttention的核心思想：从操作系统借来的智慧</h5><p>PagedAttention借鉴操作系统的<strong>虚拟内存分页机制</strong>，核心创新在于三个关键概念：</p><p><strong>概念1：虚拟地址空间与物理地址空间的分离</strong></p><pre><code>传统方法：
逻辑地址（连续） == 物理地址（连续）

PagedAttention方法：
逻辑地址（连续） → 页表 → 物理地址（可非连续）</code></pre><p><strong>概念2：固定大小的页面（Page/Block）</strong></p><p>将KV cache按照token维度划分为固定大小的块：</p><p>$$
\text{Block size} = 16 \text{ tokens} \quad \text{（典型值）}
$$</p><p>每个块存储一个或多个注意力头中连续token的K和V向量。</p><p><strong>概念3：页表（Page Table）映射</strong></p><p>为每个序列维护一个页表，记录逻辑块号到物理块号的映射：</p><p>$$
\text{Logical Block } i \xrightarrow{\text{Page Table}} \text{Physical Block } p_i
$$</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555064" alt="" title="" loading="lazy"/><br/><em>图2：虚拟内存映射架构。虚拟内存的页面通过页表映射到非连续的物理内存</em></p><h5>3.3 数学建模：PagedAttention的精确计算</h5><p><strong>场景设定</strong>：设当前token为第t个token，需要计算它与前t-1个token的注意力。</p><p><strong>传统连续存储的注意力计算</strong>：</p><p>$$
\text{Attention}(Q_t, K_{1:t-1}, V_{1:t-1}) = \text{softmax}\left(\frac{Q_t K_{1:t-1}^T}{\sqrt{d_k}}\right) V_{1:t-1}
$$</p><p>其中：</p><ul><li>$Q_t \in \mathbb{R}^{H \times d_k}$：当前token的查询</li><li>$K_{1:t-1} \in \mathbb{R}^{(t-1) \times H \times d_k}$：所有历史token的键</li><li>$V_{1:t-1} \in \mathbb{R}^{(t-1) \times H \times d_k}$：所有历史token的值</li></ul><p><strong>PagedAttention的计算分解</strong>：</p><p>将$K_{1:t-1}$和$V_{1:t-1}$按照块大小$B$进行分块：</p><p>$$
K_{1:t-1} = [K_{\text{block}_1}, K_{\text{block}_2}, \dots, K_{\text{block}_N}]
$$</p><p>$$
V_{1:t-1} = [V_{\text{block}_1}, V_{\text{block}_2}, \dots, V_{\text{block}_N}]
$$</p><p>其中$N = \lceil (t-1) / B \rceil$。</p><p>对每个注意力头$h$，注意力计算分解为：</p><p>$$
\text{head}_h = \text{softmax}\left(\frac{Q_{t,h} \cdot K_{\text{concat}}^T}{\sqrt{d_k}}\right) V_{\text{concat}}
$$</p><p>其中：</p><p>$$
K_{\text{concat}} = \text{concat}(K_{\text{block}_{\pi(1)}^h}, K_{\text{block}_{\pi(2)}^h}, \dots, K_{\text{block}_{\pi(N)}^h})
$$</p><p>$$
V_{\text{concat}} = \text{concat}(V_{\text{block}_{\pi(1)}^h}, V_{\text{block}_{\pi(2)}^h}, \dots, V_{\text{block}_{\pi(N)}^h})
$$</p><p>这里$\pi(\cdot)$是页表映射函数：$\pi(i) = \text{PageTable}[i]$，表示逻辑块$i$对应的物理块号。</p><p><strong>核心洞察</strong>：数学上，$K_{\text{concat}}$和$K_{1:t-1}$包含完全相同的元素，只是内存布局不同。注意力计算的结果完全一致！</p><h5>3.4 内存效率的定量分析</h5><p><strong>传统方法的内存浪费</strong>：</p><p>假设有$R$个请求，第$r$个请求的token数为$T_r$，预分配最大长度为$T_{max}$。</p><p><strong>内部碎片率</strong>：</p><p>$$
\eta_{\text{internal}} = 1 - \frac{\sum_{r=1}^{R} T_r}{R \cdot T_{max}}
$$</p><p><strong>PagedAttention的内存浪费</strong>：</p><p>块大小为$B$，第$r$个请求需要的块数为$N_r = \lceil T_r / B \rceil$。</p><p><strong>内部碎片率</strong>：</p><p>$$
\eta'_{\text{internal}} = 1 - \frac{\sum_{r=1}^{R} T_r}{\sum_{r=1}^{R} B \cdot N_r} = 1 - \frac{\sum_{r=1}^{R} T_r}{\sum_{r=1}^{R} B \cdot \lceil T_r / B \rceil}
$$</p><p><strong>效率提升</strong>：</p><p>$$
\frac{\eta_{\text{internal}}}{\eta'_{\text{internal}}} \approx \frac{1 - \mathbb{E}[T_r] / T_{max}}{1 - \mathbb{E}[T_r] / (B \cdot \mathbb{E}[\lceil T_r / B \rceil])}
$$</p><p>在典型工作负载下（$T_{max} = 2048$, $B = 16$, $\mathbb{E}[T_r] = 500$）：</p><p>$$
\eta_{\text{internal}} \approx 75.6\%, \quad \eta'_{\text{internal}} \approx 1.6\%
$$</p><p><strong>内存利用率提升约50倍！</strong></p><h5>3.5 Copy-on-Write与跨序列共享</h5><p>这是PagedAttention最精彩的设计之一。</p><p><strong>场景</strong>：并行采样（Parallel Sampling）或束搜索（Beam Search），从同一个前缀生成多个候选序列。</p><p><strong>问题</strong>：在生成分歧之前，所有路径的KV cache完全相同，但传统方法需要为每条路径存储完整副本。</p><p><strong>PagedAttention的解决方案</strong>：</p><ol><li><strong>共享阶段</strong>：所有路径共享相同物理块，通过引用计数（reference count）管理</li><li><p><strong>分歧时刻</strong>：当某条路径需要写入一个块，且引用计数 &gt; 1时：</p><ul><li>分配新的物理块</li><li>复制原块内容</li><li>更新页表映射</li><li>引用计数减1</li></ul></li></ol><p><strong>数学表示</strong>：</p><p>设物理块$p$的引用计数为$\text{refcount}(p)$，逻辑块$l$映射到物理块$p$：</p><pre><code class="python">def write_to_block(logical_block, token_data, page_table, refcounts):
    physical_block = page_table[logical_block]
    
    if refcounts[physical_block] &gt; 1:
        # 触发copy-on-write
        new_physical_block = allocate_new_block()
        copy_data(physical_block, new_physical_block)
        page_table[logical_block] = new_physical_block
        refcounts[physical_block] -= 1
        refcounts[new_physical_block] = 1
        physical_block = new_physical_block
    
    write_data(physical_block, token_data)</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555065" alt="" title="" loading="lazy"/><br/><em>图3：PagedAttention的块表结构。逻辑块（Logical KV blocks）通过块表映射到物理块（Physical KV blocks），支持多个请求共享相同的物理块</em></p><h5>3.6 系统架构设计</h5><p><strong>vLLM的完整架构</strong>包含三个核心组件：</p><ol><li><strong>KV Cache Manager</strong>：管理物理块的分配、回收和映射</li><li><strong>Block Table</strong>：维护逻辑地址到物理地址的映射关系</li><li><strong>PagedAttention Kernel</strong>：支持非连续KV块的注意力计算内核</li></ol><p><strong>调度策略</strong>：</p><pre><code>for each new request:
    # Prefill阶段
    allocate_blocks_for_prompt(request)
    compute_and_cache_kv(request)
    
    # Decode阶段
    while not finished:
        allocate_new_block_if_needed(request)
        compute_next_token_with_paged_attention(request)</code></pre><p><strong>驱逐策略（Eviction Policy）</strong>：</p><p>当物理内存不足时，vLLM采用LRU（最近最少使用）+ 引用计数的策略：</p><pre><code class="python">def evict_if_needed():
    while memory_full():
        candidates = [block for block in physical_blocks 
                      if refcounts[block] == 0]
        if not candidates:
            # 强制驱逐最老的活跃块
            candidates = [oldest_block_with_low_priority()]
        
        victim = select_lru_block(candidates)
        free_block(victim)</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555066" alt="" title="" loading="lazy"/><br/><em>图4：vLLM Paged Attention教学幻灯片。展示了生成前的状态和PagedAttention的两个核心优势</em></p><hr/><h4>四、代码手撕环节（Live Coding）</h4><p>下面给出PagedAttention核心逻辑的简化实现（基于PyTorch）：</p><pre><code class="python">import torch
import torch.nn.functional as F
from typing import List, Dict, Tuple
from dataclasses import dataclass

@dataclass
class KVBlock:
    """一个KV缓存块"""
    block_id: int
    data_k: torch.Tensor  # shape: [num_heads, block_size, head_dim]
    data_v: torch.Tensor  # shape: [num_heads, block_size, head_dim]
    ref_count: int = 1
    
    @property
    def num_slots(self) -&gt; int:
        return self.data_k.shape[1]

class BlockTable:
    """页表：维护逻辑块到物理块的映射"""
    def __init__(self):
        self.mapping: Dict[int, KVBlock] = {}  # logical_block_id -&gt; KVBlock
        
    def get_block(self, logical_block_id: int) -&gt; KVBlock:
        return self.mapping.get(logical_block_id)
    
    def map_block(self, logical_block_id: int, physical_block: KVBlock):
        self.mapping[logical_block_id] = physical_block

class PagedAttentionKVCache:
    """PagedAttention的KV缓存管理器"""
    def __init__(self, num_heads: int, head_dim: int, block_size: int = 16):
        self.num_heads = num_heads
        self.head_dim = head_dim
        self.block_size = block_size
        
        # 物理块池
        self.physical_blocks: Dict[int, KVBlock] = {}
        self.next_block_id = 0
        self.free_blocks: List[int] = []
        
        # 页表（每个序列一个）
        self.sequence_tables: Dict[int, BlockTable] = {}
        
    def allocate_block(self) -&gt; KVBlock:
        """分配一个新的物理块"""
        if self.free_blocks:
            block_id = self.free_blocks.pop()
            block = self.physical_blocks[block_id]
            block.ref_count = 1
        else:
            block_id = self.next_block_id
            # 实际场景中，这里需要检查内存是否足够
            # 如果内存不足，需要触发驱逐策略
            block = KVBlock(
                block_id=block_id,
                data_k=torch.zeros(self.num_heads, self.block_size, self.head_dim,
                                   dtype=torch.float16, device='cuda'),
                data_v=torch.zeros(self.num_heads, self.block_size, self.head_dim,
                                   dtype=torch.float16, device='cuda'),
                ref_count=1
            )
            self.physical_blocks[block_id] = block
            self.next_block_id += 1
        
        return block
    
    def get_block_for_position(self, sequence_id: int, position: int) -&gt; Tuple[KVBlock, int]:
        """
        获取指定位置对应的物理块和块内偏移
        
        Args:
            sequence_id: 序列ID
            position: token位置（从0开始）
            
        Returns:
            (物理块, 块内偏移)
        """
        table = self.sequence_tables.get(sequence_id)
        if table is None:
            raise ValueError(f"Sequence {sequence_id} not found")
        
        logical_block_id = position // self.block_size
        offset = position % self.block_size
        
        block = table.get_block(logical_block_id)
        if block is None:
            raise ValueError(f"Block {logical_block_id} not mapped for sequence {sequence_id}")
        
        return block, offset
    
    def allocate_for_sequence(self, sequence_id: int, num_tokens: int):
        """为序列分配足够的物理块"""
        if sequence_id not in self.sequence_tables:
            self.sequence_tables[sequence_id] = BlockTable()
        
        table = self.sequence_tables[sequence_id]
        num_blocks_needed = (num_tokens + self.block_size - 1) // self.block_size
        
        for i in range(num_blocks_needed):
            if i not in table.mapping:
                block = self.allocate_block()
                table.map_block(i, block)
    
    def cache_kv(self, sequence_id: int, position: int, k: torch.Tensor, v: torch.Tensor):
        """
        缓存指定位置的K和V向量
        
        Args:
            sequence_id: 序列ID
            position: token位置
            k: shape: [num_heads, head_dim]
            v: shape: [num_heads, head_dim]
        """
        block, offset = self.get_block_for_position(sequence_id, position)
        
        # Copy-on-Write检查
        if block.ref_count &gt; 1:
            # 创建新块并复制数据
            new_block = self.allocate_block()
            new_block.data_k.copy_(block.data_k)
            new_block.data_v.copy_(block.data_v)
            
            # 更新页表映射
            table = self.sequence_tables[sequence_id]
            logical_block_id = position // self.block_size
            table.map_block(logical_block_id, new_block)
            
            # 更新引用计数
            block.ref_count -= 1
            block = new_block
        
        # 写入数据
        block.data_k[:, offset, :] = k
        block.data_v[:, offset, :] = v
    
    def compute_paged_attention(
        self,
        sequence_id: int,
        query: torch.Tensor,  # shape: [num_heads, head_dim]
        context_length: int
    ) -&gt; torch.Tensor:
        """
        计算PagedAttention
        
        Args:
            sequence_id: 序列ID
            query: 当前token的查询向量
            context_length: 上下文长度
            
        Returns:
            attention_output: shape: [num_heads, head_dim]
        """
        table = self.sequence_tables.get(sequence_id)
        if table is None:
            raise ValueError(f"Sequence {sequence_id} not found")
        
        num_blocks = (context_length + self.block_size - 1) // self.block_size
        
        # 收集所有需要的K和V
        all_k = []
        all_v = []
        
        for block_idx in range(num_blocks):
            logical_block_id = block_idx
            block = table.get_block(logical_block_id)
            
            if block is None:
                continue
            
            # 计算这个块中实际需要的位置
            start_pos = block_idx * self.block_size
            end_pos = min(start_pos + self.block_size, context_length)
            num_valid = end_pos - start_pos
            
            if num_valid &gt; 0:
                all_k.append(block.data_k[:, :num_valid, :])  # [num_heads, num_valid, head_dim]
                all_v.append(block.data_v[:, :num_valid, :])
        
        if not all_k:
            return torch.zeros_like(query)
        
        # 拼接所有K和V
        K = torch.cat(all_k, dim=1)  # [num_heads, context_length, head_dim]
        V = torch.cat(all_v, dim=1)
        
        # 计算注意力
        # query: [num_heads, head_dim]
        # K: [num_heads, context_length, head_dim]
        # scores: [num_heads, context_length]
        scores = torch.einsum('hd,hld-&gt;hl', query, K) / (self.head_dim ** 0.5)
        attn_weights = F.softmax(scores, dim=-1)
        
        # attention_output: [num_heads, head_dim]
        attention_output = torch.einsum('hl,hld-&gt;hd', attn_weights, V)
        
        return attention_output
    
    def share_prefix(self, from_sequence_id: int, to_sequence_id: int, prefix_length: int):
        """
        将from_sequence的前缀共享给to_sequence
        
        Args:
            from_sequence_id: 源序列ID
            to_sequence_id: 目标序列ID
            prefix_length: 前缀长度
        """
        if from_sequence_id not in self.sequence_tables:
            raise ValueError(f"Source sequence {from_sequence_id} not found")
        
        if to_sequence_id not in self.sequence_tables:
            self.sequence_tables[to_sequence_id] = BlockTable()
        
        from_table = self.sequence_tables[from_sequence_id]
        to_table = self.sequence_tables[to_sequence_id]
        
        num_blocks = (prefix_length + self.block_size - 1) // self.block_size
        
        for block_idx in range(num_blocks):
            block = from_table.get_block(block_idx)
            if block is not None:
                # 共享物理块，增加引用计数
                to_table.map_block(block_idx, block)
                block.ref_count += 1

# 使用示例
if __name__ == "__main__":
    # 初始化
    num_heads = 32
    head_dim = 128
    cache = PagedAttentionKVCache(num_heads=num_heads, head_dim=head_dim, block_size=16)
    
    # 序列1：prefill阶段
    sequence_id_1 = 1
    prompt_length = 50
    cache.allocate_for_sequence(sequence_id_1, prompt_length)
    
    # 模拟计算和缓存KV
    for i in range(prompt_length):
        k = torch.randn(num_heads, head_dim, dtype=torch.float16, device='cuda')
        v = torch.randn(num_heads, head_dim, dtype=torch.float16, device='cuda')
        cache.cache_kv(sequence_id_1, i, k, v)
    
    # 序列2：共享序列1的前缀
    sequence_id_2 = 2
    cache.share_prefix(sequence_id_1, sequence_id_2, prefix_length=30)
    
    # 为序列2分配额外的块（用于差异化部分）
    cache.allocate_for_sequence(sequence_id_2, prompt_length)
    
    # Decode阶段：生成新token
    query = torch.randn(num_heads, head_dim, dtype=torch.float16, device='cuda')
    context_length = prompt_length
    
    # 计算注意力（自动处理非连续的KV块）
    attn_output = cache.compute_paged_attention(sequence_id_1, query, context_length)
    
    print(f"Attention output shape: {attn_output.shape}")
    print(f"Number of physical blocks allocated: {len(cache.physical_blocks)}")</code></pre><blockquote><strong>避坑指南</strong>：实际生产环境中，PagedAttention的实现会高度优化CUDA内核，直接在GPU上处理非连续的KV块访问，而不是先拼接再计算。上面的代码为了清晰展示核心逻辑，做了简化。</blockquote><hr/><h4>五、进阶追问与展望</h4><h5>5.1 面试官可能的追问</h5><p><strong>追问1</strong>：PagedAttention与传统虚拟内存有什么本质区别？</p><p><strong>回答要点</strong>：</p><ol><li><strong>数据粒度</strong>：虚拟内存以字节/页为单位，PagedAttention以token为单位</li><li><strong>访问模式</strong>：虚拟内存是随机访问，PagedAttention是顺序访问+随机查询</li><li><strong>一致性要求</strong>：虚拟内存需要强一致性，PagedAttention中不同序列的KV cache可以独立</li></ol><p><strong>追问2</strong>：块大小（block size）如何选择？有什么trade-off？</p><p><strong>回答要点</strong>：</p><p>块大小的选择直接影响内存效率和计算开销：</p><p>$$
\text{Internal Fragmentation} = 1 - \frac{\mathbb{E}[T]}{B \cdot \mathbb{E}[\lceil T / B \rceil]}
$$</p><p><strong>小的块大小（如8）</strong>：</p><ul><li>优点：内部碎片少，内存利用率高</li><li>缺点：块数量多，页表大，访问开销大</li></ul><p><strong>大的块大小（如256）</strong>：</p><ul><li>优点：块数量少，页表小</li><li>缺点：内部碎片多，内存浪费</li></ul><p><strong>经验法则</strong>：$B = 16$或$32$通常是较好的折中，在典型工作负载下内部碎片率 &lt; 3%。</p><p><strong>追问3</strong>：PagedAttention如何与量化技术结合？</p><p><strong>回答要点</strong>：</p><ol><li><strong>块级量化</strong>：可以对每个物理块独立应用量化策略</li><li><strong>混合精度</strong>：高频访问的块保持高精度，低频访问的块使用低精度</li><li><strong>自适应量化</strong>：根据块的重要性动态调整量化精度</li></ol><p>数学上，量化后的KV cache：</p><p>$$
\tilde{K} = \text{Quantize}(K, \text{block\_id}), \quad \tilde{V} = \text{Quantize}(V, \text{block\_id})
$$</p><p>注意力计算变为：</p><p>$$
\text{Attention}(Q, \tilde{K}, \tilde{V}) = \text{softmax}\left(\frac{Q \tilde{K}^T}{\sqrt{d_k}}\right) \tilde{V}
$$</p><p>需要在注意力计算前进行反量化：</p><p>$$
\tilde{K} \xrightarrow{\text{Dequantize}} K' \approx K
$$</p><p><strong>追问4</strong>：PagedAttention在分布式场景下如何扩展？</p><p><strong>回答要点</strong>：</p><ol><li><strong>跨节点的块共享</strong>：通过RDMA网络传输物理块</li><li><strong>分布式页表</strong>：页表可以分片存储在不同节点</li><li><strong>一致性协议</strong>：需要设计类似MESI的缓存一致性协议</li></ol><h5>5.2 最新SOTA进展</h5><p><strong>1. TurboAttention（2024）</strong></p><p>通过<strong>预测式预取（Prefetching）</strong>进一步提升性能：</p><ul><li>预测接下来需要访问的块</li><li>提前将块从慢速存储（CPU内存）加载到GPU内存</li><li>隐藏延迟</li></ul><p><strong>2. LadderAttention（2024）</strong></p><p>引入<strong>层次化块管理</strong>：</p><ul><li>L1块：高频访问，常驻GPU内存</li><li>L2块：中频访问，存放在CPU内存</li><li>L3块：低频访问，存放在SSD</li></ul><p><strong>3. AttentionScales（2025）</strong></p><p>动态调整块大小：</p><p>$$
B_i = f(\text{importance}_i, \text{frequency}_i, \text{memory\_pressure})
$$</p><p>根据块的重要性、访问频率和内存压力自适应调整块大小。</p><h5>5.3 局限性与未来方向</h5><p><strong>局限性</strong>：</p><ol><li><strong>内核复杂度</strong>：PagedAttention的CUDA内核实现复杂，维护成本高</li><li><strong>短序列场景</strong>：对于序列长度很短的请求（如 &lt; 64 tokens），收益有限</li><li><strong>非Transformer架构</strong>：当前主要针对标准Transformer，难以直接推广到其他架构</li></ol><p><strong>未来方向</strong>：</p><ol><li><strong>硬件协同设计</strong>：设计支持原生非连续张量的AI加速器</li><li><strong>智能驱逐策略</strong>：基于LLM理解能力预测块的保留价值</li><li><strong>跨模态共享</strong>：将PagedAttention扩展到视觉-语言多模态场景</li></ol><hr/><h4>六、性能对比与实际效果</h4><p>根据vLLM论文的实验结果：</p><table><thead><tr><th>模型</th><th>序列长度</th><th>传统方法吞吐量</th><th>vLLM吞吐量</th><th>加速比</th></tr></thead><tbody><tr><td>OPT-13B</td><td>1024</td><td>1.0</td><td>2.4</td><td><strong>2.4x</strong></td></tr><tr><td>OPT-66B</td><td>2048</td><td>0.8</td><td>2.8</td><td><strong>3.5x</strong></td></tr><tr><td>LLaMA-70B</td><td>4096</td><td>0.3</td><td>1.2</td><td><strong>4.0x</strong></td></tr></tbody></table><p><strong>内存利用率对比</strong>：</p><table><thead><tr><th>指标</th><th>传统方法</th><th>PagedAttention</th><th>提升</th></tr></thead><tbody><tr><td>内存利用率</td><td>20-40%</td><td>95%+</td><td><strong>2.5-5x</strong></td></tr><tr><td>支持的最大batch size</td><td>小</td><td>大</td><td><strong>3-10x</strong></td></tr></tbody></table><blockquote><strong>面试必考点</strong>：能够准确背诵这些性能数据，并能解释背后的原因，是区分优秀和卓越的关键。</blockquote><hr/><h4>七、总结</h4><p>PagedAttention是<strong>算法与系统深度融合</strong>的典范。它不仅是一个注意力算法的优化，更是对整个LLM推理系统架构的重新思考。</p><p><strong>核心要点</strong>：</p><ol><li><strong>分页机制</strong>：将KV cache从连续存储转换为分页存储</li><li><strong>动态映射</strong>：通过页表实现逻辑地址到物理地址的灵活映射</li><li><strong>共享优化</strong>：支持copy-on-write，极大减少重复存储</li><li><strong>系统协同</strong>：与调度、驱逐、预取等系统机制协同设计</li></ol><p><strong>面试回答的策略</strong>：</p><ol><li><strong>先给出高层直觉</strong>（虚拟内存的类比）</li><li><strong>然后深入数学细节</strong>（公式的精确性）</li><li><strong>再讨论工程实现</strong>（代码的规范性）</li><li><strong>最后拓展到系统层面</strong>（架构的前瞻性）</li></ol><p>这样的回答既能展示基础知识的扎实，又能体现系统思维的深度，让面试官感受到你的综合能力。</p><hr/><h4>八、延伸阅读</h4><ol><li><strong>PagedAttention原论文</strong>：Kwon et al., "Efficient Memory Management for Large Language Model Serving with PagedAttention", SOSP 2023</li><li><strong>vLLM官方文档</strong>：<a href="https://link.segmentfault.com/?enc=UThIju6tkWz7tBR0PQMZCA%3D%3D.1KaskigiDX3FCwXS5bB%2Fx4W0oj3KC8MYv0i%2BDod5L7g%3D" rel="nofollow" target="_blank">https://docs.vllm.ai/</a></li><li><p><strong>虚拟内存经典教材</strong>：</p><ul><li>"Operating Systems: Three Easy Pieces" by Remzi Arpaci-Dusseau</li><li>"Computer Architecture: A Quantitative Approach" by Hennessy &amp; Patterson</li></ul></li><li><p><strong>LLM推理优化综述</strong>：</p><ul><li>"LLM Inference: A Survey of Efficient LLM Serving Systems"</li></ul></li></ol><hr/><blockquote><strong>谢谢阅读~</strong><br/><strong>关注"每天一个多模态知识点"公众号，回复"PagedAttention"即可下载本文markdown源码</strong></blockquote><p>本文由<a href="https://link.segmentfault.com/?enc=XUXZV9igv7ONXRGAlpDiow%3D%3D.%2FhgY7DT5F0veujFqEsMptMzVqeltR5yZB21ZazTPkwQ%3D" rel="nofollow" target="_blank">mdnice</a>多平台发布</p>]]></description></item><item>    <title><![CDATA[【JVS更新日志】APS排产、AI助手、物联网1.21更新说明！ 软件部长 ]]></title>    <link>https://segmentfault.com/a/1190000047555103</link>    <guid>https://segmentfault.com/a/1190000047555103</guid>    <pubDate>2026-01-21 12:13:25</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>项目介绍</h2><p>JVS是企业级数字化服务构建的基础脚手架，主要解决企业信息化项目交付难、实施效率低、开发成本高的问题，采用微服务+配置化的方式，提供了低代码+数据分析+物联网的核心能力产品，并构建了协同办公、企业常用的管理工具等，所有的应用与能力采用模块化构建，按需开箱使用。</p><h2>更新日志</h2><h2>一、生产计划排程系统（APS）</h2><p>当前版本：v2.4.X<br/>更新时间：2026.1.21<br/>在线demo：<a href="https://link.segmentfault.com/?enc=AR12O%2BB9jQezsyBnDPAv9Q%3D%3D.Y2cBzAcbqVgI7gFTUMK4ggAfSNQfjyAlKvzPiTQtsco%3D" rel="nofollow" target="_blank">https://aps.bctools.cn</a></p><h3>新增与优化</h3><p>1、为了降低接入的复杂度，系统提供了集成中心的对接界面，提供了数据双方同步的相关接口展示<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555105" alt="图片" title="图片"/><br/>其中所有的接口配置均为租户级，也就是同一套APS 可以不同租户进行分别隔离使用。并且提供了详细的API查看的详情：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555106" alt="图片" title="图片" loading="lazy"/><br/>2、对于向MES同步任务时，可以自定义请求头<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555107" alt="图片" title="图片" loading="lazy"/><br/>3、提供了详细的集成日志<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555108" alt="图片" title="图片" loading="lazy"/></p><h2>二、JVS-AI助手</h2><p>当前版本：v2.4.X<br/>更新时间：2026.1.21<br/>在线demo：<a href="https://link.segmentfault.com/?enc=dKoLjKITNNFBIetHZpRMIg%3D%3D.MzmwGNS32N9CT7roPSugZQXlcFGsMuHh20qxkv0sUPw%3D" rel="nofollow" target="_blank">https://ai.bctools.cn</a></p><h3>新增与优化</h3><p>1、重构知识管理的功能，通用文库文档的导入与相关管理操作，如下图所示：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555109" alt="图片" title="图片" loading="lazy"/><br/>2、提供问题管理的界面操作，可以关联分段<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555110" alt="图片" title="图片" loading="lazy"/><br/>3、提供文档内容的命中测试功能：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555111" alt="图片" title="图片" loading="lazy"/><br/>4、AI增加场景免登录配置的功能：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555112" alt="图片" title="图片" loading="lazy"/><br/>5、优化调整敏感词的设置功能，支持多种方式匹配敏感词。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555113" alt="图片" title="图片" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555114" alt="图片" title="图片" loading="lazy"/><br/>6、优化提示词的管理，如下图所示：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555115" alt="图片" title="图片" loading="lazy"/></p><h2>三、JVS物联网应用平台</h2><p>当前版本：v2.4.X<br/>更新时间：2026.1.21<br/>在线demo：<a href="https://link.segmentfault.com/?enc=FClqJ7Pzl93um9YqEr5mYA%3D%3D.JhqW2fJWa6pgByBRUY9bXekCHugeDsaXwMkompubShg%3D" rel="nofollow" target="_blank">http://iot.bctools.cn</a></p><h3>新增与优化</h3><p>1、新增数据标识符自动解析与物模型属性自动同步机制。现在，系统会自动解析上报数据中的标识符；当您为新产品选择分类时，将自动同步引用该分类的物模型属性，显著提升了配置操作的效率和数据的复用性。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555116" alt="图片" title="图片" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555117" alt="图片" title="图片" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555118" alt="图片" title="图片" loading="lazy"/><br/>2、接入协议库大升级，设备互联更从容。在创建新产品时提供了更丰富的协议选择。现在可以灵活选用如 HTTP、MQTT、CoAP、MQTT broker等协议，极大提升了设备接入的灵活性与未来适应性。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555119" alt="图片" title="图片" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555120" alt="图片" title="图片" loading="lazy"/><br/>3、当接入方式为“数据采集”时，配置设备数据映射现已支持按采集器、设备连接及点位进行逐级选择。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555121" alt="图片" title="图片" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555122" alt="图片" title="图片" loading="lazy"/><br/>4、全新升级的设备连接界面，让点位数据的修改与同步实现实时联动，操作体验更直观高效。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555123" alt="图片" title="图片" loading="lazy"/></p><h2>为什么选择JVS？</h2><p>JVS是一个为交付团队提供低成本、高效率、源码可100%交付的数字化解决方案，如下图所示，其中产品包括包含：低代码、物联网、规则引擎、智能BI、逻辑引擎、智能排产（APS）、视频会议、无忧企业文档（在线协同）、无忧企业计划、无忧企业邮筒等，可按照交付团队所需要进行采购。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555124" alt="图片" title="图片" loading="lazy"/><br/>✅低代码开发套件：页面、流程、逻辑配置化、自动构建业务应用，集成自动化部署工具，形成可持续升级配置的快速开发工具，支持源码扩展接入列表页配置<br/><img width="723" height="627" referrerpolicy="no-referrer" src="/img/bVdmvfs" alt="5dd7e03b5e168b7e22fb5a250d84036e.png" title="5dd7e03b5e168b7e22fb5a250d84036e.png" loading="lazy"/><br/>✅ 物联网：软件化的边缘网关+配置化的物联网平台，与低代码、数据分析、逻辑引擎等联动实现，从数据采集、规则策略、业务联动、数据分析展现全流程配置化，技术生态完备<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555125" alt="图片" title="图片" loading="lazy"/><br/>✅ 规则引擎：一款处理风控决策的软件系统，侧重于规则判断，主要用于风控决策、规则过滤、行为评分等场景，支持在线的变量加工、界面拖拽、在线测试等多种功能。可以降低开发人员使用复杂代码的难度；降低数据录入工作量；优化功能代码实现，提高开发效率；灵活扩展应用程序功能。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555126" alt="图片" title="图片" loading="lazy"/><br/>✅ JVS·智能BI：自助式数据分析工具，提供数据清洗、数据转换、数据加工等功能。将枯燥数据转化为可视化，帮助企业快速、精准地掌握运营策略，使用门槛低、数据覆盖能力强、多种数据表达模式和建设成本低的一站式数据分析服务。<br/><img width="723" height="380" referrerpolicy="no-referrer" src="/img/bVdmvfz" alt="51aa1849807cee35a80f092823611b76.png" title="51aa1849807cee35a80f092823611b76.png" loading="lazy"/><br/>✅ 逻辑引擎：逻辑引擎是通过对原子服务能力的可视化编排，同时接入外部应用，以满足数据处理、业务实现、自动化业务的实现，可以设计整个逻辑模块的输入、组装执行过程、生成标准的输出结果。轻松实现业务功能，无需复杂冗长的开发过程。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555127" alt="图片" title="图片" loading="lazy"/><br/>✅ 无忧·企业文档：有免费开源版和丰富的商业版。针对企业用户的私有化部署在线文档、协同编辑、知识管理的基础化办公工具，支持多人在线同步编辑，支持多种文件格式，如文本文档、表格文档、脑图文档、MarkDown、XMind、脑图、word、Excel、PPT和流程文档等；支持在线收集表单、思维导图、流程图等；同时支持文件上传（在线预览和二次编辑）、下载、分享、点赞、评论等等丰富功能。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555128" alt="图片" title="图片" loading="lazy"/><br/>✅ JVS·智能排产（APS系统）：聚焦于离散制造行业（如汽车、电子、机械、航空航天等）及流程制造行业（如化工、食品、医药等），通过AI驱动的智能算法，实现生产计划与排程的高效性、准确性、敏捷性，帮助企业提升设备利用率、降低库存成本、缩短交付周期，实现精益生产与数字化转型。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555129" alt="图片" title="图片" loading="lazy"/><br/>✅ 无忧·企业计划：企业级项目管理工具，将企业从经营目标到个人执行逐级分解监控执行。适合各类团队，包括产品、研发、设计、市场、运营、销售、HR等；主要用于项目管理、任务管理、进度跟踪、过程管理等场景。<br/><img width="723" height="397" referrerpolicy="no-referrer" src="/img/bVdmQ53" alt="13f65b5de68af69aaeda6bcc918e2333.png" title="13f65b5de68af69aaeda6bcc918e2333.png" loading="lazy"/><br/>✅ 无忧·企业邮筒：完全开源的私有化部署邮件客户端、支持多邮件账户、将多个邮件客户端统一为web操作的邮件客户端。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555130" alt="图片" title="图片" loading="lazy"/><br/>✅ 无忧·视频会议：这是一款专为现代企业提供的高效、稳定、安全的在线会议交流解决方案。系统包括了高清视频会议、即时通讯、屏幕共享、白板展示、实时翻译、会议日程管理等多功能于一体，旨在满足企业日常沟通、协作、培训、决策等多元化企业内部协同交流的需求。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555131" alt="图片" title="图片" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[React状态管理太复杂？试试这个原子级神器！ 大前端历险记 ]]></title>    <link>https://segmentfault.com/a/1190000047555209</link>    <guid>https://segmentfault.com/a/1190000047555209</guid>    <pubDate>2026-01-21 12:12:48</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>每次开始新项目，选择状态管理方案都让人头疼。</p><p><strong>Redux</strong>模板代码太多，<strong>Context</strong>性能优化麻烦，<strong>MobX</strong>学习曲线陡峭……有没有一个既简单又强大的选择？</p><p>今天给你推荐一个让我眼前一亮的方案——<strong>Jotai</strong>。</p><h2>什么是Jotai？</h2><p>Jotai是一个<strong>原子化状态管理库</strong>，核心思想很简单：把应用状态拆成一个个独立的“原子”，每个原子管理自己的数据。</p><p>最棒的是，它的API和React自带的<code>useState</code>几乎一样，<strong>学习成本接近零</strong>。</p><pre><code class="javascript">// 创建一个状态
const countAtom = atom(0)

// 在组件中使用
function Counter() {
  const [count, setCount] = useAtom(countAtom)
  return &lt;button onClick={() =&gt; setCount(count + 1)}&gt;点击：{count}&lt;/button&gt;
}</code></pre><p>就这样，你创建了一个可以在<strong>任何组件中直接使用</strong>的共享状态，不需要Provider包裹，不需要层层传递props。</p><h2>为什么选择Jotai？</h2><h3>1. 零学习成本</h3><p>如果你会用<code>useState</code>，5分钟就能上手Jotai。</p><h3>2. 自动性能优化</h3><p>Jotai自动追踪状态依赖，只有真正使用某个状态的组件才会更新：</p><pre><code class="javascript">const userAtom = atom({ name: '张三', age: 25 })
const themeAtom = atom('light')

// 只有这个组件会在用户信息变化时更新
function UserInfo() {
  const [user] = useAtom(userAtom)  // 只订阅userAtom
  return &lt;div&gt;{user.name}&lt;/div&gt;
}

// 只有这个组件会在主题变化时更新  
function ThemeButton() {
  const [theme] = useAtom(themeAtom)  // 只订阅themeAtom
  return &lt;button className={theme}&gt;按钮&lt;/button&gt;
}</code></pre><h3>3. 状态组合像搭积木</h3><p>小状态组合成大状态，逻辑清晰：</p><pre><code class="javascript">const priceAtom = atom(100)    // 单价
const countAtom = atom(2)      // 数量
const totalAtom = atom((get) =&gt; get(priceAtom) * get(countAtom))  // 自动计算总价

// 单价或数量变化时，总价自动更新</code></pre><h3>4. 异步处理变简单</h3><p>不再需要自己管理loading状态：</p><pre><code class="javascript">const postsAtom = atom(async () =&gt; {
  const response = await fetch('/api/posts')
  return response.json()
})

function PostsList() {
  const [posts] = useAtom(postsAtom)
  
  // Jotai自动处理loading状态
  if (!posts) return &lt;div&gt;加载中...&lt;/div&gt;
  
  return posts.map(post =&gt; &lt;div key={post.id}&gt;{post.title}&lt;/div&gt;)
}</code></pre><h2>实战：登录功能改造</h2><p><strong>传统Context写法</strong>（问题：任何状态变化都会导致所有子组件重渲染）：</p><pre><code class="javascript">// 需要创建Context、Provider，使用useContext
const AuthContext = createContext()
// 一堆模板代码...</code></pre><p><strong>Jotai写法</strong>（清晰、独立、高效）：</p><pre><code class="javascript">// 定义原子状态
const userAtom = atom(null)
const loadingAtom = atom(false)

// 定义登录action
const loginAtom = atom(null, (get, set, credentials) =&gt; {
  set(loadingAtom, true)
  api.login(credentials).then(user =&gt; {
    set(userAtom, user)
    set(loadingAtom, false)
  })
})

// 在组件中使用（无需Provider）
function LoginButton() {
  const [, login] = useAtom(loginAtom)
  const [loading] = useAtom(loadingAtom)
  
  return (
    &lt;button onClick={login} disabled={loading}&gt;
      {loading ? '登录中...' : '登录'}
    &lt;/button&gt;
  )
}</code></pre><h2>这些场景特别适合Jotai</h2><ul><li>✅ <strong>中小型React应用</strong> - 状态不太复杂，但需要共享</li><li>✅ <strong>团队协作项目</strong> - 新人能快速上手</li><li>✅ <strong>性能敏感应用</strong> - 需要避免不必要的重渲染</li><li>✅ <strong>渐进式重构</strong> - 可以部分引入，逐步替换</li></ul><h2>开始使用吧！</h2><p>安装Jotai只需要一行命令：</p><pre><code class="bash">npm install jotai
# 或
yarn add jotai</code></pre><p>然后就可以像使用<code>useState</code>一样使用共享状态了。</p><p><strong>Jotai不会解决所有问题</strong>，但它确实在简单性和功能性之间找到了很好的平衡。对于大多数应用来说，它提供的功能已经足够强大，而学习成本却极低。</p><hr/><p>有时候，最好的解决方案不是功能最多的，而是让开发者能<strong>专注于业务逻辑</strong>而不是框架本身的那一个。Jotai就是这样一个工具——简单、直观、高效。</p><p>下次当你为状态管理发愁时，不妨试试Jotai。你会发现，状态管理原来可以这么简单愉快！</p><hr/><p>关注我的公众号" <strong>大前端历险记</strong>"，掌握更多前端开发干货姿势！</p><p>本文由<a href="https://link.segmentfault.com/?enc=Rs%2B1duunoK7ELOyiUASTgg%3D%3D.B6ziaNPW7KO9MdwcHexsYGE8rAVMyhSa%2FuYt9OCtkfo%3D" rel="nofollow" target="_blank">mdnice</a>多平台发布</p>]]></description></item><item>    <title><![CDATA[如何分析 Linux 系统登录失败事件 运维有小邓 ]]></title>    <link>https://segmentfault.com/a/1190000047555215</link>    <guid>https://segmentfault.com/a/1190000047555215</guid>    <pubDate>2026-01-21 12:12:12</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>用户身份认证是网络安全的重要组成部分，对用户登录尝试行为的审计，是识别可疑操作的关键环节。</p><p>登录失败通常由以下两种情况引发：</p><p>用户提供的身份凭证无效<br/>用户不具备访问特定资源的登录权限<br/>当用户通过 SSH 远程连接系统，或使用 su 命令切换用户身份时产生的登录失败事件，属于需要重点监控的内容。这类事件可能预示着有人正在尝试非法入侵系统。</p><p>本文将详细介绍查看 SSH 登录失败记录的具体方法。</p><h3>查看 SSH 登录失败记录的操作步骤</h3><p>可插拔认证模块（PAM）会记录此类身份认证事件，借助模块生成的日志，能够有效识别恶意登录行为与异常访问操作。</p><p>以下是一则登录失败的日志示例：</p><p>pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=10.0.2.2</p><pre><code>        Failed password for invalid user robert from 10.0.2.2 port 4791 ssh2
        pam_unix(sshd:auth): check pass; user unknown
        PAM service(sshd) ignoring max retries; 6 &gt; 3</code></pre><p>为了高效排查问题，管理员需要快速定位所有此类关键登录事件，并采取对应的处置措施。</p><h3>下文列出了查询所有 SSH 登录失败记录的操作步骤：</h3><p>列出所有 SSH 登录失败记录的基础命令：</p><h2>grep "Failed password" /var/log/auth.log</h2><p>也可以通过 cat 命令实现相同效果：</p><h2>cat /var/log/auth.log | grep "Failed password"</h2><p>如需显示 SSH 登录失败的更多相关信息，可执行以下命令：</p><h2>egrep "Failed|Failure" /var/log/auth.log</h2><p>如需列出所有尝试登录 SSH 服务器但失败的客户端 IP 地址，可执行以下命令：</p><h2>grep "Failed password" /var/log/auth.log | awk '{print $11}' | uniq -c | sort -nr</h2><p>尽管分析上述事件的操作看似简单，但手动执行所有相关步骤耗时又费力。借助专业的日志管理解决方案，能够更便捷地分析 SSH 登录失败尝试行为。</p>]]></description></item><item>    <title><![CDATA[Java Agent探针运用 袋鼠云数栈 ]]></title>    <link>https://segmentfault.com/a/1190000047555218</link>    <guid>https://segmentfault.com/a/1190000047555218</guid>    <pubDate>2026-01-21 12:11:14</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>Java Agent 是 Java 提供的一种在 JVM 启动时或运行时动态修改字节码的强大机制，广泛应用于 APM 监控（如 SkyWalking、Pinpoint）、热部署（如 JRebel）、代码覆盖率（JaCoCo）、故障注入、安全审计等场景。一、Java Agent 的两种模式模式加载时机典型用途Premain AgentJVM 启动时（-javaagent）APM 探针、性能监控、字节码增强Attach AgentJVM 运行时动态 attach线上诊断（如 Arthas）、动态开关二、核心原理：InstrumentationAgent 通过 java.lang.instrument.Instrumentation 接口实现：retransformClasses()：重新转换已加载的类（需类支持 retransformation）redefineClasses()：直接替换类的字节码（限制多，不常用）addTransformer()：注册 ClassFileTransformer，在类加载时修改字节码三、快速入门：编写一个简单 Agent步骤 1：创建 Agent 入口类package com.example;</p><p>import com.example.transformer.RestTemplateTraceAdvice;<br/>import com.example.transformer.TraceAdvice;<br/>import com.fasterxml.jackson.databind.ObjectMapper;<br/>import net.bytebuddy.agent.builder.AgentBuilder;<br/>import net.bytebuddy.asm.Advice;<br/>import net.bytebuddy.description.method.MethodDescription;<br/>import net.bytebuddy.matcher.ElementMatcher;</p><p>import java.lang.instrument.Instrumentation;<br/>import java.util.Arrays;<br/>import java.util.HashSet;<br/>import java.util.Set;</p><p>import static net.bytebuddy.matcher.ElementMatchers.isAnnotatedWith;<br/>import static net.bytebuddy.matcher.ElementMatchers.named;<br/>import static net.bytebuddy.matcher.ElementMatchers.takesArguments;</p><p>public class TraceAgent {</p><pre><code>private final static String appId ;

private static final Set&lt;String&gt; REQUEST_MAPPING_ANNOTATIONS = new HashSet&lt;&gt;(Arrays.asList(
        "org.springframework.web.bind.annotation.RequestMapping",
        "org.springframework.web.bind.annotation.GetMapping",
        "org.springframework.web.bind.annotation.PostMapping",
        "org.springframework.web.bind.annotation.PutMapping",
        "org.springframework.web.bind.annotation.DeleteMapping"
));

private static CustomAgentListener customListener;

static {
    appId = System.getProperty("appId");
}

public static void premain(String agentArgs, Instrumentation inst) {
    install(inst);
}

public static void agentmain(String agentArgs, Instrumentation inst) {
    install(inst);
}

private static void install(Instrumentation inst) {
    // 创建自定义监听器，输出到指定文件，只记录指定包的类
    customListener = new CustomAgentListener(
            "/Users/dsy/code/agent-demo/logs/"+appId+"-bytebuddy-agent.log",  // 日志文件路径
            "com.example"               // 只记录 com.example 包下的类
    );

    new AgentBuilder.Default()
            .with(customListener) // 👈 关键：输出匹配详情
            .disableClassFormatChanges()
            .with(AgentBuilder.RedefinitionStrategy.RETRANSFORMATION)
            .with(AgentBuilder.InitializationStrategy.NoOp.INSTANCE)
            .with(AgentBuilder.TypeStrategy.Default.REDEFINE)
            .with(AgentBuilder.DescriptionStrategy.Default.POOL_ONLY) // 👈 启用完整类型解析
            .type(
                    isAnnotatedWith(named("org.springframework.stereotype.Controller"))
                            .or(isAnnotatedWith(named("org.springframework.web.bind.annotation.RestController")))
            )
            .transform((builder, typeDescription, classLoader, module) -&gt;
                    builder.visit(Advice.to(TraceAdvice.class)
                            .on(anyMethodAnnotatedWithRequestMapping()))</code></pre><p>//                                builder.method(any()).intercept(MethodDelegation.to(NoOpInterceptor.class))</p><pre><code>            )
            .type(named("org.springframework.web.client.RestTemplate"))
            .transform((builder, td, cl, module) -&gt;
                    builder.visit(Advice.to(RestTemplateTraceAdvice.class)
                                    .on(named("exchange")
                                            .and(takesArguments(4))
                                            .or(takesArguments(5))
                                            .or(takesArguments(6))))
            )
            .installOn(inst);

    System.out.println("[Agent] Controller tracing agent installed.");
}

private static ElementMatcher.Junction&lt;MethodDescription&gt; anyMethodAnnotatedWithRequestMapping() {
    return isAnnotatedWith(named("org.springframework.web.bind.annotation.RequestMapping"))
            .or(isAnnotatedWith(named("org.springframework.web.bind.annotation.GetMapping")))
            .or(isAnnotatedWith(named("org.springframework.web.bind.annotation.PostMapping")))
            .or(isAnnotatedWith(named("org.springframework.web.bind.annotation.PutMapping")))
            .or(isAnnotatedWith(named("org.springframework.web.bind.annotation.DeleteMapping")));
}

// 添加关闭方法，用于清理资源
public static void shutdown() {
    if (customListener != null) {
        customListener.close();
    }
}</code></pre><p>}步骤 2：实现 TraceAdvicepackage com.example.transformer;</p><p>import com.fasterxml.jackson.core.JsonProcessingException;<br/>import com.fasterxml.jackson.databind.ObjectMapper;<br/>import net.bytebuddy.asm.Advice;</p><p>import javax.servlet.http.HttpServletRequest;<br/>import java.util.Arrays;<br/>import java.util.UUID;</p><p>import static com.example.transformer.TraceContextHolder.PARENT_APP_ID;<br/>import static com.example.transformer.TraceContextHolder.X_TRACE_ID;</p><p>public class TraceAdvice {</p><pre><code>public final static String appId ;

public final static ObjectMapper objectMapper;

static {
    appId = System.getProperty("appId");
    objectMapper = new ObjectMapper();
}

@Advice.OnMethodEnter
public static void enter(@Advice.AllArguments Object[] args) {

    TraceContextHolder.TraceContext traceContext = TraceContextHolder.traceContext();

    // 尝试从参数中提取 HttpServletRequest
    HttpServletRequest request = null;
    for (Object arg : args) {
        if (arg instanceof HttpServletRequest) {
            request = (HttpServletRequest) arg;
            break;
        }
    }

    String traceId = null;
    String parentAppId = null;
    if (request != null) {
        // 优先从 Header 中获取 traceId（例如：X-Trace-Id）
        traceId = request.getHeader(X_TRACE_ID);
        parentAppId = request.getHeader(PARENT_APP_ID);
    }

    if (traceId == null || traceId.trim().isEmpty()) {
        // 未传入，则生成新 traceId（建议用 UUID 或 Snowflake）
        traceId = "trace-" + UUID.randomUUID().toString().replace("-", "").substring(0, 32);
    }

    if (parentAppId == null || parentAppId.trim().isEmpty()){
        parentAppId = "0" ;
    }

    traceContext.setTraceId(traceId);
    traceContext.setArgs(args.toString());
    traceContext.setAppId(appId);
    traceContext.setParentAppId(parentAppId);
    traceContext.setTraceSpanStartTime(System.currentTimeMillis());

    // 绑定到当前线程</code></pre><p>//        TraceContextHolder.setTraceContext(traceContext);</p><pre><code>    System.err.println("&gt;&gt;&gt; Entering method with args: " + Arrays.toString(args));
}

@Advice.OnMethodExit
public static void exit(@Advice.Return Object result) {
    TraceContextHolder.TraceContext traceContext = TraceContextHolder.traceContext();
    traceContext.setTraceSpanEndTime(System.currentTimeMillis());
    try {
        traceContext.setResult(objectMapper.writeValueAsString(result));
    } catch (JsonProcessingException e) {
        throw new RuntimeException(e);
    }
    System.err.println("&lt;&lt;&lt; Exiting method, returned: " + traceContext.toSting());
}</code></pre><p>}步骤 3：用于跟踪调用链的上下文在 src/main/resources/META-INF/MANIFEST.MF 中声明：// com/example/transformer/TraceContextHolder.java<br/>package com.example.transformer;</p><p>public class TraceContextHolder {</p><pre><code>public final static String X_TRACE_ID = "X-Trace-Id";
public final static String PARENT_APP_ID = "X-Parent-APP-Id";

static String FORMAT = "traceId:%s,parentAppId:%s,appId:%s,traceSpanStartTime:%d,traceSpanEndTime:%d,args:%s,result:%s";
private static final ThreadLocal&lt;TraceContext&gt; TRACE = new ThreadLocal&lt;&gt;();

public static void setTraceContext(TraceContext traceContext) {
    TRACE.set(traceContext);
}

public static void clear() {
    TRACE.remove();
}

public static TraceContext traceContext() {
    TraceContext object;
    if (TRACE.get() != null) {
        object = TRACE.get();
    } else {
        object = new TraceContext();
        TRACE.set(object);
    }
    return object;
}

public static class TraceContext{
    private String traceId;
    private String parentAppId;
    private String appId;
    private Long traceSpanStartTime;
    private Long traceSpanEndTime;
    private String args;

    private String result;

    public String getTraceId() {
        return traceId;
    }

    public void setTraceId(String traceId) {
        this.traceId = traceId;
    }

    public String getParentAppId() {
        return parentAppId;
    }

    public void setParentAppId(String parentAppId) {
        this.parentAppId = parentAppId;
    }

    public String getAppId() {
        return appId;
    }

    public void setAppId(String appId) {
        this.appId = appId;
    }

    public Long getTraceSpanStartTime() {
        return traceSpanStartTime;
    }

    public void setTraceSpanStartTime(Long traceSpanStartTime) {
        this.traceSpanStartTime = traceSpanStartTime;
    }

    public Long getTraceSpanEndTime() {
        return traceSpanEndTime;
    }

    public void setTraceSpanEndTime(Long traceSpanEndTime) {
        this.traceSpanEndTime = traceSpanEndTime;
    }

    public String getArgs() {
        return args;
    }

    public void setArgs(String args) {
        this.args = args;
    }

    public String getResult() {
        return result;
    }

    public void setResult(String result) {
        this.result = result;
    }

    public String toSting(){

        return String.format(FORMAT,traceId,parentAppId,appId,traceSpanStartTime,traceSpanEndTime,args,result);

    }
}</code></pre><p>}步骤 4：打包 &amp; 使用如果用 Maven，可通过 maven-jar-plugin 自动生成：&lt;?xml version="1.0" encoding="UTF-8"?&gt;<br/>&lt;project xmlns="http://maven.apache.org/POM/4.0.0"</p><pre><code>     xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
     xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;
&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;
&lt;parent&gt;
    &lt;groupId&gt;org.example&lt;/groupId&gt;
    &lt;artifactId&gt;agent-demo&lt;/artifactId&gt;
    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;
&lt;/parent&gt;

&lt;artifactId&gt;agent3&lt;/artifactId&gt;

&lt;properties&gt;
    &lt;maven.compiler.source&gt;8&lt;/maven.compiler.source&gt;
    &lt;maven.compiler.target&gt;8&lt;/maven.compiler.target&gt;
    &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;
&lt;/properties&gt;

&lt;dependencies&gt;
    &lt;!-- ByteBuddy 核心 --&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;net.bytebuddy&lt;/groupId&gt;
        &lt;artifactId&gt;byte-buddy&lt;/artifactId&gt;
        &lt;version&gt;1.12.10&lt;/version&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;net.bytebuddy&lt;/groupId&gt;
        &lt;artifactId&gt;byte-buddy-agent&lt;/artifactId&gt;
        &lt;version&gt;1.12.10&lt;/version&gt;
    &lt;/dependency&gt;

    &lt;!-- Spring Web（仅用于类型判断，非强制） --&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.springframework&lt;/groupId&gt;
        &lt;artifactId&gt;spring-web&lt;/artifactId&gt;
        &lt;version&gt;5.3.31&lt;/version&gt;
        &lt;scope&gt;provided&lt;/scope&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;javax.servlet&lt;/groupId&gt;
        &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt;
        &lt;version&gt;4.0.1&lt;/version&gt;
        &lt;scope&gt;compile&lt;/scope&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.slf4j&lt;/groupId&gt;
        &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt;
        &lt;version&gt;1.7.36&lt;/version&gt;
        &lt;scope&gt;compile&lt;/scope&gt;
    &lt;/dependency&gt;

    &lt;dependency&gt;
        &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt;
        &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt;
        &lt;version&gt;2.17.0&lt;/version&gt; &lt;!-- 使用最新稳定版 --&gt;
    &lt;/dependency&gt;
&lt;/dependencies&gt;
&lt;build&gt;
    &lt;plugins&gt;
        &lt;!-- 使用 shade plugin 打包 fat jar --&gt;
        &lt;plugin&gt;
            &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
            &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt;
            &lt;version&gt;3.5.0&lt;/version&gt;
            &lt;executions&gt;
                &lt;execution&gt;
                    &lt;phase&gt;package&lt;/phase&gt;
                    &lt;goals&gt;
                        &lt;goal&gt;shade&lt;/goal&gt;
                    &lt;/goals&gt;
                    &lt;configuration&gt;
                        &lt;transformers&gt;
                            &lt;transformer implementation="org.apache.maven.plugins.shade.resource.ManifestResourceTransformer"&gt;
                                &lt;manifestEntries&gt;
                                    &lt;Premain-Class&gt;com.example.TraceAgent2&lt;/Premain-Class&gt;
                                    &lt;Agent-Class&gt;com.example.TraceAgent2&lt;/Agent-Class&gt;
                                    &lt;Can-Redefine-Classes&gt;true&lt;/Can-Redefine-Classes&gt;
                                    &lt;Can-Retransform-Classes&gt;true&lt;/Can-Retransform-Classes&gt;
                                &lt;/manifestEntries&gt;
                            &lt;/transformer&gt;
                        &lt;/transformers&gt;
                    &lt;/configuration&gt;
                &lt;/execution&gt;
            &lt;/executions&gt;
        &lt;/plugin&gt;
    &lt;/plugins&gt;
&lt;/build&gt;</code></pre><p>&lt;/project&gt;四、创建两个web应用验证trace到调用生命周期<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555221" alt="图片" title="图片"/><br/>1、web-apppackage com.example.demo.conf;</p><p>import org.springframework.context.annotation.Bean;<br/>import org.springframework.context.annotation.Configuration;<br/>import org.springframework.web.client.RestTemplate;</p><p>@Configuration<br/>public class BeanConfig {</p><pre><code>@Bean
public RestTemplate restTemplate() {
    return new RestTemplate();
}</code></pre><p>}<br/>package com.example.demo.controller;</p><p>import org.slf4j.Logger;<br/>import org.slf4j.LoggerFactory;<br/>import org.springframework.http.HttpMethod;<br/>import org.springframework.web.bind.annotation.GetMapping;<br/>import org.springframework.web.bind.annotation.PostMapping;<br/>import org.springframework.web.bind.annotation.RequestBody;<br/>import org.springframework.web.bind.annotation.RequestParam;<br/>import org.springframework.web.bind.annotation.RestController;<br/>import org.springframework.web.client.RestTemplate;</p><p>import javax.annotation.Resource;</p><p>@RestController<br/>public class HelloController {</p><pre><code>private static final Logger logger = LoggerFactory.getLogger(HelloController.class);

@Resource
private RestTemplate restTemplate;

@GetMapping("/hello")
public String hello(@RequestParam(defaultValue = "World") String name) {
    logger.info("Processing hello request for: {}", name);
    String url = "http://localhost:8081/shopping?commodity=香蕉";
    String r = restTemplate.exchange(url, HttpMethod.GET,null,String.class).getBody();
    return "Hello, " + name + "!" + " commodity = " + r;
}

@PostMapping("/user")
public String createUser(@RequestBody String userData) {
    logger.info("Creating user with data: {}", userData);
    return "User created: " + userData;
}

@GetMapping("/error")
public String error() {
    logger.info("Triggering error");
    throw new RuntimeException("Test exception");
}</code></pre><p>}2、web- app1package com.example.demo.controller;</p><p>import org.slf4j.Logger;<br/>import org.slf4j.LoggerFactory;<br/>import org.springframework.web.bind.annotation.GetMapping;<br/>import org.springframework.web.bind.annotation.PostMapping;<br/>import org.springframework.web.bind.annotation.RequestBody;<br/>import org.springframework.web.bind.annotation.RequestParam;<br/>import org.springframework.web.bind.annotation.RestController;</p><p>@RestController<br/>public class ShoppController {</p><pre><code>private static final Logger logger = LoggerFactory.getLogger(ShoppController.class);

@GetMapping("/shopping")
public String hello(@RequestParam(defaultValue = "苹果") String commodity) {
    logger.info("Processing hello request for: {}", commodity);
    return "commodity, " + commodity + "!";
}

@PostMapping("/user")
public String createUser(@RequestBody String userData) {
    logger.info("Creating user with data: {}", userData);
    return "User created: " + userData;
}

@GetMapping("/error")
public String error() {
    logger.info("Triggering error");
    throw new RuntimeException("Test exception");
}</code></pre><p>}从上面可以看到我们在web-app的应用中的hell接口中调用了web-app1的shopping接口，且web-app的接入方式是无代码入侵形式的RestTemplate，主要是依赖agent对asm对增强能实现对trace调用透传<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555222" alt="图片" title="图片" loading="lazy"/><br/>且web-app和web-app1两个进程起来时要通过-javaagent方式将agent的探针无入侵的方式接入应用中而-DappId时接入的应用id，用于跟踪tarce所在的应用和构建应用的拓扑图<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555223" alt="图片" title="图片" loading="lazy"/><br/>五、验证触发接口<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555224" alt="图片" title="图片" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555225" alt="图片" title="图片" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555226" alt="图片" title="图片" loading="lazy"/><br/>至此可以通过Agent的探针实现对应用无入侵式，实现调用链的APM 监控、构建应用的拓扑图，并切基于Agent Advice 的增强方式可以进一步实现对中间件的跟踪和观测，如接入DB的观测。</p>]]></description></item><item>    <title><![CDATA[AI 具身化不可挡！从指令到对话，揭秘下一代 AI 原生硬件的技术底座 | CES2026 RTE开]]></title>    <link>https://segmentfault.com/a/1190000047555238</link>    <guid>https://segmentfault.com/a/1190000047555238</guid>    <pubDate>2026-01-21 12:10:39</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555240" alt="" title=""/></p><p>当 AI 长出身体，从能听会说到能看会动！Agora Convo AI World 拉斯维加斯之夜活动回顾</p><p>主笔：周森</p><p>审校：小炫</p><p>编辑：陈述</p><p>AI 不再仅仅是屏幕里的对话框，从能感知情绪的陪护机器人，到具备实时翻译能力的智能眼镜，AI 硬件化成为 CES 2026 呈现的重要趋势。</p><p>然而，在 AI 硬件热潮背后，行业也在迫切寻找一个答案：当 AI 试图长出「身体」，它需要怎样的底层架构与交互逻辑？</p><p>1 月 9 日晚，Agora（声网兄弟公司）联合 RiseLink（博通集成）在拉斯维加斯 The LOFT at Cabo Wabo Cantina 举办了 Convo AI World 论坛活动。</p><p>这场吸引了近 300 位全球科技精英参与的盛会，意在为这股 AI 硬件热潮指引风向。</p><p>两家企业不仅联合发布了基于 BK7259 芯片的 R2 全场景 AI 机器人开发套件，更首次系统性地提出了「物理 AI 的蓝图」。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555241" alt="" title="" loading="lazy"/></p><p>△ 活动现场</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555242" alt="" title="" loading="lazy"/></p><h2>具身 AI 的蓝图：从「工具」到「生命形态」</h2><p>当前，行业正处于从文本模型、语音助手，迈向具备长期记忆、情绪理解与陪伴能力的 AI 伙伴的早期阶段。</p><p>Physical AI，本质上是具身智能（Embodied AI） 在消费级市场的落地呈现。AI 硬件不再是冰冷的电子零件，而是一种正在形成的数字生命形态。</p><p>由 Agora 与 RiseLink 联合提出的 Physical AI 蓝图，则试图为下一阶段的具身智能发展提供一套以体验为核心的设计方法论。</p><p>Tony Wang 在演讲中强调，Physical AI 的关键不在于堆砌硬件参数，而在于对话体验，即在复杂环境中理解语境、识别说话者并感知情绪的能力。</p><p>未来，AI 的核心语言将从单向的「指令」彻底转变为双向的「对话」，其商业模式也将从硬件单次销售，转向以订阅制为核心的长期服务。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555243" alt="" title="" loading="lazy"/><br/>△ 发言嘉宾：Tony Wang，Agora 联合创始人兼 CRO</p><p>张鹏飞博士进一步阐述道，Physical AI 时代的竞争已演变为协同效率的竞争。想要成为或持续保持第一，前提是与各自领域中已经处于领先位置的伙伴深度协作。</p><p>RiseLink 将通信、算力与功耗管理深度整合，配合 Agora 的 RTC 实时互动能力，构成了 Physical AI 的基础引擎：以低延迟保障交互的自然性，以高能效支撑长时间的在线陪伴。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555244" alt="" title="" loading="lazy"/></p><p>△ 发言嘉宾：张鹏飞博士，RiseLink（博通集成） CEO</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555245" alt="" title="" loading="lazy"/></p><h2>真实的 AI 堆栈：重构技术底层</h2><p>当 AI 跨越数字边界、从云端软件形态进入物理硬件，底层的技术架构不应该只是「模型 + 数据 + 算力」，而需要从「原子」到「比特」实现闭环。</p><p>在论坛环节，嘉宾们探讨和回答了什么是「真实的 AI 堆栈」并达成共识：AI 是否好用，取决于设备能否通过物理感知快速理解语境并做出即时反应。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555246" alt="" title="" loading="lazy"/></p><p>△ Panel: The Real AI Stack </p><p>圆桌主持人：Rin Yunis 博士，RiseLink 开发者体验负责人 （中）</p><p>圆桌嘉宾： （自左向右）</p><ul><li>Max Fillin， WowCube CEO</li><li>Blake Margraff, Healthcare Technology 创始人</li><li>Amir Eitan, Nanit CPO</li><li>Lin Chen 博士, Wyze 首席科学家</li></ul><p>在架构选择上，<strong>边缘（Edge）与云端（Cloud）的分工不再是二选一，而是基于延迟、隐私和成本的精密平衡</strong> 。对实时性和隐私敏感的能力更适合本地运行，而需要持续迭代、受成本约束的功能则更适合放在云端，工程实践应从验证出发，再逐步优化边云分配。</p><p>在消费级场景中，成本是最硬的约束条件。无论技术听起来多么具有颠覆性，如果缺乏可持续的单位经济模型（Unit Economics），产品终究无法走出实验室成为长期的生意。</p><p>同时，嘉宾们达成了一个感性却深刻的共识：<strong>AI 必须具备稳定的记忆和一致的行为</strong> 。一个今天热情、明天健忘的 AI 硬件，是无法真正建立起用户信任的。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555247" alt="" title="" loading="lazy"/></p><p>△ 圆桌嘉宾：Max Fillin, WOWcube CEO（左）</p><p>这种信任的建立，在家庭与健康等强私密场景下尤为微妙。品牌的真实投入与清晰的价值传递，远比罗列一堆天衣无缝的安全技术术语更有效。 用户对 Physical AI 的接受度，往往并不取决于你背书了多少项加密协议，而取决于极其直观的交互体感，即：<strong>反馈要即时（低延迟）、过程要透明（可解释）、底线要有人守（人类参与）。</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555248" alt="" title="" loading="lazy"/></p><p>△ 圆桌嘉宾：Lin Chen 博士, Wyze 首席科学家</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555249" alt="" title="" loading="lazy"/></p><h2>应用与具身落地：AI 硬件的场景爆发</h2><p>Physical AI 最令人兴奋的特质在于它的多模态能力，以及在各个场景的迅速渗透。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555250" alt="" title="" loading="lazy"/></p><p>△ WOWcube（左）：将经典的 2x2 魔方形态与 24 个高分辨率屏幕相结合，通过扭转、倾斜和触觉交互，让玩家在立体的物理空间中体验沉浸式的游戏与应用。</p><p>△ Wyze（右上）： 新款户外安防摄像头采用贴纸式安装方式固定在窗户上，可从室内进行户外录像</p><p>△ Nanit Pro（右下）： 全功能婴儿监控系统，新增用于记录宝宝成长发育的功能</p><p>在医疗与健康领域，Physical AI 的价值在于它能实时处理复杂的生理信号，并以人类能理解、能接受的方式进行交互，从而在专业性与亲和力之间找到平衡。</p><p>Blake Margraff 指出，AI 在医疗中的落地绝非简单的自动化，而是要实现「自动化的患者监测与干预」。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555251" alt="" title="" loading="lazy"/></p><p>△ 圆桌嘉宾：Blake Margraff，Healthcare Technology 创始人</p><p>Amir Eitan 则从育儿与家庭监测的角度补充道，真正的信任来自于 AI 能在特定场景下提供「可解释的反馈」。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555252" alt="" title="" loading="lazy"/></p><p>△ 圆桌嘉宾：Amir Eitan，Nanit CPO</p><p>在 AI 陪伴的主题论坛中，各位嘉宾围绕 AI 陪伴产品在儿童与家庭场景中的实际落地展开话题。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555253" alt="" title="" loading="lazy"/></p><p>△ Panel：Where AI Companionship Comes to Life</p><p>圆桌主持人：Patrick Ferriter，Agora 产品与市场高级副总裁（左下）</p><p>圆桌嘉宾：</p><ul><li>孙兆治，珞博智能 CEO（左上）</li><li>Angela Qian，灵宇宙 Luka AI 战略负责人 （右上）</li><li>Wayne Zhang， Dify Chief of Staff（右中）</li><li>Margo Wang，Lgenie ＆灵机一动 Agent 市场总监（右下）</li></ul><p><strong>稳定性和一致性</strong>是影响儿童用户对 AI 硬件接受度的关键因素。无论是故事内容、角色设定还是互动方式，一旦发生变化，都会显著影响使用体验。</p><p><strong>低延迟</strong>是实时陪伴场景中的基本要求，是建立用户与产品情感连接的底线，响应过慢会直接削弱互动的自然感。</p><p><strong>长期留存</strong>更具挑战性。吸引用户首次尝试与长期留存两者的差异性需要引起重视，长期留存更具挑战性，需要 AI 在持续使用中形成稳定的互动节奏和情感连接，而不仅是单次回应。</p><p><strong>安全与责任</strong>方面需要引入多层防护思路，包括年龄匹配内容、实时干预机制、以及对儿童隐私的明确告知与限制。当 AI 承担陪伴角色时，如何在维持互动亲密性的同时设立清晰边界，仍是行业需要持续面对的问题。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555254" alt="" title="" loading="lazy"/></p><p>△ Fuzozo 芙崽（左上）：面向 Z 世代的 AI 养成系潮玩</p><p>△ Luka AI Cube（右上）：灵宇宙小方机，儿童 AI 学伴</p><p>△ Lgenie （左下）：小匠宠物陪伴小车 &amp; 四足桌面机器人</p><p>△ 海马爸比（右下）： AI 智能婴儿看护器</p><p>在产品演示环节，Diana Zhu 博士主持发布了 Choochoo AI 教育机器人。她提到，Choochoo 能够实现流畅的视觉与动作反馈，核心在于集成了 RiseLink 的高集成度 SoC 方案。该芯片在单颗硅片上整合了 Wi-Fi 连接、音视频处理与 AI 加速引擎，使得开发者能够绕过复杂的底层硬件调优，直接在 R2 套件上通过简单的 API 调用，实现原本需要高性能服务器才能支撑的「视觉-语言-动作」协同。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555255" alt="" title="" loading="lazy"/></p><p>△ 发言嘉宾：Diana Zhu 博士，RiseLink 美国负责人</p><p>作为首款由 RiseLink 芯片与 Agora 对话式 AI 引擎深度驱动的教育机器人，Choochoo 不仅能听懂孩子的提问，更能通过视觉传感器「看」到周围的环境与孩子的动作，并做出相应的物理反馈。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555256" alt="" title="" loading="lazy"/></p><p>△ Choochoo / 延伸阅读：<a href="https://link.segmentfault.com/?enc=W8pim7uB7%2FWuKlMpJ6sShw%3D%3D.tf%2BBrdOv1P32yVxKKNwe2o1oDGGo5Q5NLw0aV07rRy%2Bq4PYoWU8E%2F0eeI1owViDfrdx223bRbBURJk3wS5DX31sL%2F3SFJWpNmMqzwHNLcOdne5y2lfixR7U%2Fr%2BJZ9ESAmZyj8PHfidwKyhfK2%2BC8jnNBss4mI%2FLcGhU2vwy0BeqrpvWsR44Kqwxcg28w25XVcAWIbtAdgPFKip0oUhZQfdzBhBFeBz7od0efBZcq7LvXAlZxtvB8hu600bK60gtxmT1OBpMOXi2ZE7c%2BlOriQXBXZkJbXaHS3FHTkUTX%2FkuKJYzN4rrcjuI8Dl3E5tysHZOqhGGeGY%2BZ5%2BmCQiqkqopde6zN5RoHLGcMOcMF%2BCg%3D" rel="nofollow" target="_blank">对话式 AI 升级，不仅能看还能动</a></p><p>值得一提的是，作为 R2 全场景 AI 机器人开发套件标杆案例，陆吾智能旗下的桌面机器人「陆卡卡」也同步亮相。现场，陆卡卡展示了如何在紧凑的形态下实现高频、低延迟的 AI 交互。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555257" alt="" title="" loading="lazy"/></p><p>△ 陆卡卡 / 延伸阅读：<a href="https://link.segmentfault.com/?enc=qrhAHGRoKiArDCNSjNEfvQ%3D%3D.MN64BkvG5LAlZjEKYAViQwNPROscr%2B8TursSuE%2FrU2bDclrAzlJS2aMNjdRqvM%2Fw3bfgKcdvxOZ0GFTYgB58Anuewup05DamGO3MWsWCSPsM7KNqUz1bbtv9vv4aUlPjB5C7r14NVy7gwAXAv%2FFU0s5bBMK%2BPOqPTVQoLQ6LyZ9V5v1k3tZRGEPvtJg2i7eXEyF9tAKbytwo5G13pHQQZ0NO%2BNjBZzMH7LybDilpVHDTAHuSjAfKcKrODIfo%2Bj6luHHNCQ8ceyQDBeZtNPvGzxtCikFVeJIGy0%2F9unGflLEQJBc1l5IqyD%2BSp8MhC8ynngNuoyg10M8TiX2CwKwL2pe2YeP0DHRs6XSf1xXd8d0%3D" rel="nofollow" target="_blank">桌宠陆卡卡，一只「兵蚁」从二次元走进现实</a></p><p>在两款极具代表性的具身智能产品身上，我们看到，当 AI 拥有了强大的「大脑」（大模型）与灵敏的「身体」后，交互的边界已彻底被打破。两款产品的发布，共同定义了 AI 硬件的新高度，同时也标志着基于 Agora 与 RiseLink 合作的 AI 方案已经完全成熟。</p><p>在快闪分享环节，Joey Jiang 分享了打造 AI 原生硬件的最短路径，强调了模块化硬件对快速实现概念落地的意义。他指出，AI 原生硬件的开发不应再遵循「从零打样」的旧逻辑。通过 Seeed Studio 提供的模块化感知节点（如传感器、视觉模块）与 RiseLink 方案的即插即用式结合，硬件原型的验证周期可以从数月缩短至几周。这种「搭积木」式的开发模式，正是初创团队在 Physical AI 浪潮中抢占市场窗口期的最短路径。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555258" alt="" title="" loading="lazy"/><br/>△ 发言嘉宾：Joey Jiang，Seeed Studio 销售副总裁</p><p>Kim Jin 分享了打造糯宝 AI 机器人的背后故事。在研发背后，团队耗费大量精力对用户意图的深度理解。通过多模态感知，敏锐地捕捉视觉、触觉与语音背后的感性信息，实现拟人化的回复。这种交互不只是指令的执行，而是基于对用户意图的精准洞察，让机器人产生真实的「情感共鸣」。这标志着 Physical AI 真正跨越了工具属性，进化为懂得用户灵魂的情感伴侣。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555259" alt="" title="" loading="lazy"/></p><p>△ Pophie  (机器灵动) 产品负责人 Kim Jin</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555260" alt="" title="" loading="lazy"/></p><p>△ Maxevis（左）：迈威儿童拍学机</p><p>△ Pophie 糯宝（右）：桌面级情感陪伴机器人</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555261" alt="" title="" loading="lazy"/></p><h2>隐私、授权与信任：环境式 AI 的底线</h2><p>随着环境式 AI（Ambient AI）走向「始终在线」，隐私与信任已不再是合规问题，而是产品体验本身。用户真正担心的并非模型出错，而是设备在「不被察觉的情况下」收集和使用数据。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555262" alt="" title="" loading="lazy"/></p><p>△ Panel：When AI Is Everywhere: Redefining Data Privacy, Consent, and Trust</p><p>圆桌主持人：Ramana Kapavarapu，Agora 首席信息安全官 (CISO) &amp; IT 运营负责人（中）</p><p>圆桌嘉宾：（自左向右）</p><ul><li>Diana Zhu 博士，RiseLink 美国负责人</li><li>Joe Tham，Ellie 海马爸比联合创始人</li><li>Gibran Mourani，MiniMax 全球客户经理</li><li>卜峥，Kaamel AI 联合创始人兼 CEO</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555263" alt="" title="" loading="lazy"/></p><p>△ 成立于 2021 年底的 MiniMax 刚刚宣布港股上市，成为从成立到 IPO 用时最短的 AI 公司。大家首先向 MiniMax 的 Gibran Mourani 道贺。</p><p>围绕隐私实践，嘉宾们形成了一个明确共识：说到做到、做到可见。</p><p><strong>透明性：</strong> 相比冗长的隐私条款，产品应在交互层面清晰呈现系统是否在监听、收集了什么数据，以及用户如何即时控制这些行为。透明性体现在硬件指示、软件状态和使用流程中，比如用物理指示灯直观地告诉用户系统是否在监听。</p><p><strong>边缘保护：</strong> 通过边缘计算最小化数据流动，让原始语音和视觉数据停留在本地，是保护隐私的最有效路径。对多数场景而言，无需上传云端、本地处理并仅传递必要信号，既有助于隐私保护，也降低了系统暴露面。</p><p><strong>响应机制：</strong> 谈及安全事件响应，需要成熟、结构化的应对机制，而非临时决策。快速隔离、明确影响、及时修复与复盘改进，比短期业务考量更重要。过往大型数据泄露案例反复证明，延迟或回避只会放大长期损失。</p><p>真正可规模化的信任，来自硬件与软件的一致设计以及可实时验证的控制能力。认证和合规是基础，但只有当系统行为与承诺持续一致，用户对「无处不在的 AI」才会产生长期接受度。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555264" alt="" title="" loading="lazy"/></p><p>△ 活动现场</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555265" alt="" title="" loading="lazy"/></p><h2>AI 具身化不可挡！</h2><p>纵观整场活动，我们可以从三个层面理解这场关于 Physical AI 的深刻变革：</p><p><strong>技术本质：</strong> 从「挂载」到「具身」。 AI 不再是硬件外挂的一个功能，而是通过专用芯片和实时通讯协议，深度融合进硬件的神经系统。</p><p><strong>交互范式：</strong> 从「指令」到「共生」。 当 AI 能够理解语境、感知情绪并拥有长期记忆，它就从一个「好用的工具」进化为一个「理解你的物种」。对话不再是手段，而是其存在的形式。</p><p><strong>商业本质：</strong> 从「买断」到「订阅」。 物理 AI 的核心价值在于其随时间不断进化的能力。厂商卖出的不再是零件，而是长期的服务与情感陪伴。</p><p>在 Agora 和 Riselink 两家公司和来自人工智能、芯片和硬件、AI 算法，以及数字健康、家居安防、AI 陪伴和教育等领域的数十家 AI 软硬件企业代表和顶尖专家的背书下，AI 将跳出单纯的数字世界，开始在物理世界中，真正长出它的身体。■</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555266" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555267" alt="" title="" loading="lazy"/></p><p><a href="https://link.segmentfault.com/?enc=j6VxLfacaPqkk40UFjW9xA%3D%3D.udqcnUhY9nfyMKVntzxBej%2F1Tfg7NTXGMp9nlTci3fs%3D" rel="nofollow" target="_blank">阅读更多 Voice Agent 学习笔记：了解最懂 AI 语音的头脑都在思考什么</a></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555268" alt="" title="" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[ERP经营管理体系快速建构&导入方案 织信informat ]]></title>    <link>https://segmentfault.com/a/1190000047555296</link>    <guid>https://segmentfault.com/a/1190000047555296</guid>    <pubDate>2026-01-21 12:09:48</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>程序一、基础工程资料规划建档：</p><p>一个制造产业能否透过实施ERP全面电算化整合信息管理系统，而使企业能够具备：明确化、合理化、高效化、规范化、精细化、自动化的优质管理体系，第一个关键性的问题就是要对整个产业的基础工程做正确而合理的规划。</p><p>因为一个产业的基础工程规划建立就有如一栋大楼的地基规划建立一样重要，没有良好稳固的基础，就不可能建立一个具备高效而优质管理体系的企业。</p><p>一个制造产业在实施ERP全面电算化整合信息管理系统时必须先规划建立的基础工程包括哪些项目？</p><p>我们分别先列示如下，并且一一加以详细说明：</p><p>1、集团公司组织规划建档：</p><p>当一个企业已经发展成为集团企业之时，规模越大者或跨国际经营者，其经营管理体系的复杂度远比单一公司要超过十倍以上。面对这种大型集团企业的ERP全面电算化整合信息管理系统的规划实施，首先就要把整个集团公司的母子公司组织关系规划建档完成，包括：每个公司的代码、名称（本国名称／英文名称）、资本额、持股比率、公司所在地区／国家、地址、网址、ERP数据库的网址、重要主管资料、使用系统代码、产生单据代码等，并且可以从公司组织表查看到每一家公司的从属关系。</p><p>将来整个集团公司的运筹管理资料数据彙总，都会透过这份公司组织表建立的相关数据做为依据，包括：财务运筹管理、营业运筹管理、存货运筹管理、采购运筹管理、人力资源运筹管理、产品研发运筹管理等体系。</p><p>通常一个集团企业可以发展到100个母子公司以上已经不多见了，像荷兰的Philips飞利浦集团或美国的GE通用集团，子公司号称超过1000家，在母子公司编码的技术上，都还不会产生重大困扰。我们建议对于关系企业的公司编码上，和客户编码／厂商编码采用相同的编码规则，这样是一劳永逸的办法。即：</p><p>(a)、对于国内使用中文的公司，直接以公司名称的前四个中文字的罗马拼音的第一码，４码以后则用流水码，可避免前４码重复。至于流水码要用几码，要看往来客户和厂商的家数多少来决定，最多可以用到４个流水码。</p><p>(b)、对于国外非使用中文名称的公司，则直接使用其英文名称的前四码，再加上流水码，将来就可以简单的进行查询的作业。</p><p>2、厂别／营所规划建档：</p><p>厂别／营所／分公司和母子公司的关系完全不同，母子公司是指两者都同时具备独立的法人资格，都必须独立向政府的税务机关报税的不同公司。而厂别／营所／分公司是指：在同一个公司名称法人之下，有多个制造工厂，多个营业所，或多个分公司，在申报企业之营利事业财务报表和所得税时，必须合并所有厂别／营所／分公司的数据，再统一向总公司所在地点的税捐机关申报。</p><p>对于每一个工厂／营所／分公司，都必须分别编定一个代码加以区别，因为厂别／营所／分公司和部门组织和部门代码并不相同，如果公司需要获得每一个厂别／营所／分公司经营的损益分析，就必须把厂别／营所／分公司加以编码管理。</p><p>厂别／营所／分公司的编码规则，最好就直接使用２码地区码，加上厂别流水码及属性即可。例如：昆山一厂：KS01F，东莞二厂：DG02F，其中“F”代表工厂（Factory）；上海营一所（或分公司）：SH01B，大连营二所（或分公司）：DL02B，其中“B”代表营业所或分公司（Branch）。如果营业所超过１０００家，就用４位流水码，肯定够用。</p><p>3、事业部别代码规划建档：</p><p>当一个企业跨产业经营的时候，就会用到事业部的管理技术和观念。事业部的观念和母子公司不同，也和厂别／营所的观念不同，事业部是以不同的产业做为区分的依据，例如：通讯事业部、计算机事业部、家电事业部、纺织事业部、包装事业部、化工事业部、家具事业部、汽车事业部等。对于相同的产业事业部可以再以不同的产品类别加以区分管理：例如：家电事业部之下，还可以再分为：洗衣机类、冰箱类、果汁机类、暖气机类、冷气机类、电视机类等产品类别。相同的产品类别再区分为不同的机型，或不同的产品型号，最底层则是每一项产品编号，即，一种产品型号可以依据客户的要求而衍生成为多项不同的产品编号。</p><p>部分企业因为规模并没有大到跨越多种产业别，而是以不同的产品类别当做一个事业部来规划管理，当然也可以。万一有一天企业突然快速发展之时，再来重新规划新的管理模式，还是可以透过企业改造来加以调整，只是要多花一点钱而已！</p><p>4、部门代号规划建档：</p><p>部门代号的编码是最简单的工作，但是也是最麻烦的工作，主要原因是：每一家企业的部门组织表都经常改变，增加（扩编）部门，减少（缩编）部门，部门归属调整重组，几乎每一个企业都必须面对部门组织经常变更的问题。</p><p>当公司调整部门组织时，一方面要能够建立新的组织表，同时还要确保每个部门先前发生的营收和费用不会消失，或是无法连贯，部门组织规划就必须要设计成为可以弹性组合的方式，随时可以把一个部门的上级部门修改为另一个部门，却不须要修改部门代号和名称。万一有一个部门必须要取消掉，只要输入该部门的失效日期就可以，从该部门失效的日期开始，任何新增的单据资料都不能选用该部门代码。在数据库中却不须要急着删除该部门的资料。</p><p>至于部门代码要如何编制，首先把部门区分属性并编定代码２码，例如：管理性质（MN）、营业性质（SA）、服务性质（SV）、财务性质（FN）、制造性质（MF）、品管性质（QC）、研发性质（RD）、生管性质（PC）、物控性质（MC）、采购性质（PR）、生技性质（TL）、人力资源性质（HR）、法务性质（LW）等，属性代码使用数字也可以。然后按照部门级数从０级、１级、２级、３级、４级到９级，使用１码应该足够。相同属性而且又同个级数的部门，可以用０１、０２、０３、０４、０５、０６、０７到９９加以编码，或从００１、００２、００３、００４、００５、００６、００７到９９９加以编码，即，使用２或３码。若集团企业需要把公司代码加到部门代码上的话，就在最后的两码或三码拿来当做公司代码即可。</p><p>5、生产线代码规划建档：</p><p>生产线／工作中心（Work center）和部门组织具有完全不同的属性，生产线／工作中心是指具备生产机能的单位，部门组织则是指在企业经营管理组织中行政运作的机能单位。</p><p>生产线／工作中心的规划编码，必须以生产管制部门的角度来规划。若生管人员安排生管排程到每一个机台，则每一个机台就是一条生产线（工作中心）。若生管人员安排生管排程到同型的整个机群，而每一个机台要生产甚么产品（工令单）是由车间现场主管决定，则整个机群就是一条生产线（工作中心）。</p><p>一条生产线（工作中心）的产能依据可能是以机器设备为主，或是以人工为主，或是以人／机同时配合为主。对于不同产业，生产线（工作中心）的产能依据都必须依据实际状况决定如何正确的加以规划。</p><p>生产线的代号最多可以使用８码，前２或３码为生产线的性质，后面的流水码则依据同型生产线的数量决定长度，可用１码、２码、３码、４码、或５码。例如：ZS01，ZS02，ZS03，表示成型注塑机０１、０２、０３三条生产线。ZK01，ZK02，ZK03，ZK04，ZK05表示钻孔机０１、０２、０３、０４、０５五条生产线。</p><p>6、仓库类别代码规划建档：</p><p>仓库的分类规划非常重要，因为仓库是存放存货的地方，为了要提高存货周转率，提高空间利用率，降低存货报废率，降低存货的存置成本，达到先进先出目标，同时还要能够符合政府合同核销海关保税帐务的相关法令规定。</p><p>仓库类别主要可以分为：一般存货仓、IQC进料检验仓、FQC完工待验仓、海关保税仓、车间线边仓、客户寄售仓、代送货仓、营销发货仓、海外发货仓、售服维修仓、厂商寄库仓、储槽存货仓、研发备品仓、冷冻仓、冷藏仓、AS/RS自动立体仓库、报废品仓等。若有其它类别的仓库，可以依据产业别的需求来定义。</p><p>除非有必要，通常不建议把仓库依据：成品仓、半成品仓、原材料仓、物料仓、商品仓、维修零组件仓来分类。因为各项料品的存量会不断增减变化，有可能原来存放制成品的仓库也把原材料存放进去，也可能原来存放原材料的仓库改存放半成品进去。</p><p>7、仓库／储位规划建档：</p><p>在存货管理的技术方面，我们建议采用十分钟存货管理法，可以在十分钟之内培训出非常优秀的仓库管理人才，这个管理技术将会在仓储存货管理分工体系中更详细加以解说。首先在这里必须强调几个观念：仓库和厂别／营所别不一定有绝对性的关系，因为，一个仓库的存货可以同时供给两个工厂或以上的用料，或是供应多个营业所的出货。</p><p>在仓库代码的规划方面，必须依据企业规模的大小和仓库的多少，来决定使用２码或３码做为每一个仓库的代码。</p><p>确定了仓库的编码之后，储位的编码就简单了，只要对于每一个仓库加以分区，再分段，再分层即可。至于每一个仓库的储位应该规划多大或多小的空间，必须依据产业类别的料品材积和存货数量而决定。</p><p>对于大型集团企业而言，不同的法人公司，除非会造成混淆，或有共用仓库的情况，否则可以使用相同的仓库代码，不会影响系统整合的问题。</p><p>8、员工代号规划建档：</p><p>员工代码的编码规则，最简单有效的方式为：前２码为员工到职的年度，后３码或４码流水码则为当年度员工到职的先后顺序。采用这种编码技术，员工代码可以永远不需要更改，直到退休或离职。因为从００年到９９年的期间，没有任何一个员工会工作超过１００年，而一个企业法人在同一年期间也不至于新进９９９９个员工，万一真的会超过９９９９人，就把流水号再加长到５码，可以让一年新进９９９９９个员工。</p><p>集团企业如果有必要区分员工上班的公司别的话，可以在员工编码前面加上公司代码，２码或３码。</p><p>对于大型集团企业的员工代码规划方面，不同的子公司法人可以有各别的员工编码，不须要由集团总公司来统一编码。只要对于某一个层级以上的员工，或特殊才能的员工，才有必要将其个人资料转到集团总公司的人力资源运筹管理系统之中，也才需要另外建立一个集团总公司的员工统一编码，以完整记录该员工的所有信息。即，对于重要员工，除了其在服务的公司有一个员工代码之外，在集团总公司的人力资源运筹管理系统中，还有另外一个彙总统一编码。</p><p>9、经办人代号规划建档：</p><p>经办人代号和员工代号是相同的规则，所谓：“经办人”是指公司里边的间接员工，除了直接员工以外的人员。只要在人力资源管理体系中的员工基本资料建档作业中的“成本别”栏位输入“直接人工”以外的选项，都应该是间接员工，也都是经办人。</p><p>10、币别代号规划建档：</p><p>对于有和外国企业做交易的公司，使用外国币是必然的事情。对于各国币别代号的规划，只要使用国际货币标准代码就可以，不需要自己公司另外编码。例如：美金为：USD，人民币为：RMB，港币为：HKD。</p><p>11、每日汇率规划建档：</p><p>每日汇率是对于外国币别每天的汇率变动数据输入建档到电算化系统中，供各部门人员做为参考和工作执行的依据。尽管现今国家政策是采取人民币和美金是固定的汇率，但是对日币、港币、欧元、加拿大币等仍然是浮动汇率。何况一个强大的经济实体国家迟早必然会走向浮动汇率的政策方向，以大中国地区的经济发展速度来做分析预估，采取浮动汇率的货币政策应该是在未来５年之内的国家大事。</p><p>每日汇率是以本国币为基准，相对于外国币别如何转换。因为每一家银行订定买入／卖出的汇率可以不一样，所以每日汇率就必须分成５种汇率：银行买入汇率、银行卖出汇率、海关买入汇率、海关卖出汇率、中间汇率（平均汇率）。</p><p>营业部门在对客户报价、接订单、收款结汇等作业项目，应该使用银行买入汇率，其中收款结汇时使用的汇率是银行水单上面註明的汇率。在船务部门出货结关时所使用的汇率则要以海关买入汇率为准。而采购部门的请购单、采购单等作业项目，应该使用银行卖出汇率，采购验收单的汇率则必须配合到海关报关时INVOICE和报关单上面的海关核定汇率。国外采购使用外币的付款结汇作业，不论采用T/T或L/C或其它付款方式，则是以银行实际结汇的汇率为基准。</p><p>12、产制型态规划建档：</p><p>产品生产制造的型态可以区分为：离散型（Assembly type）和连续型（Routing type）生产型态。同一个产业里的产品生产过程，有可能部份部件（半成品或制成品）是属于离散型生产型态，而另外部份的部件则是属于连续型生产型态。在生管排程和生产制造的管理技术中，对于离散型生产型态的部件是以制造指令（工令单WORK ORDER）来做排程和生产进度的控管依据，而对于连续型生产型态的部件则是以途程单／流程卡（RUN CARD）做为排程和生产进度控管的依据。</p><p>13、产品分类规划建档：</p><p>一个制造产业所生产的产品，应该可以区分为许多产品类别，为了做为经营管理／分析的依据，就必须对各种产品类别加以编定代码，做为计算机统计数据的依据。</p><p>不同的产业型态对于产品的分类方式也不同，例如家电产业，其产品类别可能有：冷气机类、电冰箱类、微波炉类、电视机类、电风扇类等。PCB印刷电路板产业，其产品类别可能有：单面板、双层板、四层板、六层板、八层板、十二层板等。对于纺织产业，其产品类别可能有：平织部、针织部、提花布、不织部、毛绒布等。每一个产业都会依据本身经营管理的需要订定产品的分类。只是，不能把产品分类和产品型号混为一谈，所谓产品型号（Model）是指相同类别的产品，因为市场的需求和研发设计的不同，而有不同的款式或型号。例如：Motorola 388，它的产品分类是：“手机类”，产品型号则是：“３８８系列”。</p><p>14、料品科目规划建档：</p><p>料品科目是指：所有产业内部使用到的各项物品如何对应到会计总帐的会计科目，以便在各部门的相关单据输入计算机软件系统之后，可以自动产生会计凭证的会计分录。</p><p>料品科目可以分为：原材料（M）、半成品（S）、制成品（P）、商品（Z）、间接物料（低值易耗品）（U）、固定资产类（A）、费用类（F）、维修零组件类（T）、免费料品（N）、客户提供料品（O）、无库存货品等（W）。分别说明如下：</p><p>原材料（M）：制造产业向供料厂商采购进料，做为产品生产过程中投入之直接原材料或间接原材料。</p><p>半成品（S）：原材料经过生产制造程序，并移交仓库保存，但尚未完成制成品的阶段之货品。Semi product半成品，但不是在制品（Work in process）。</p><p>制成品（P）：原材料或半成品经过最后完工程序，并移交仓库保存，等待出货的最终产品。</p><p>商品（Z）：从供货厂商的公司进货之后，不需要经过生产制造的过程，就可以直接出货的货品。</p><p>间接物料（低值易耗品U）：价格低廉，而且在产品的生产过程中不能核算入原材料的料品，例如打包带、去渍油、手套、橡皮筋等料品。</p><p>固定资产类（A）：在会计总帐中列入固定资产的物品，例如：土地、厂房建物、机器设备、运输设备、通讯设备、办公设备、模具设备等项目。</p><p>费用类（F）：在会计总帐中列入费用类的物品，例如：文具用品、办公用品、书报杂誌、杂项购置等物品。</p><p>维修零组件类（T）：用于公司内部机器设备维修、保养的零件或组配件。</p><p>免费料品（N）：不需要花钱采购，就能取得的料品，或是相对成本金额可以忽略的料品，例如：水、空气等。化工产业、饮料产业、医药产业等，使用大量的自来水或空气，就可以制造出产品出来，因为水的成本价格可以忽略，但是在生产投料时却要记录投入的数量或重量，才可以算出每一批产品的收率，这些料品直接视为免费料品，即，不必花钱，也不必办入库，却可以领用的物品。</p><p>客户提供料品（O）：或称为：“客供品”，就是由客户提供给公司的料品。这类的料品虽然不需要公司花钱购买，却必需每天记录客户进料数量、领用数量、出货数量、和结余数量，并且要每个月和客户对帐，免得有一天客户说：“你们公司积欠我们公司一千五百万元的原材料”，这是我们过去辅导某家企业推行全面电算化之时所遭遇过的事件。</p><p>无库存货品等（W）：有些产业的货品比较特殊，没有库存却可以不断的出货，例如：Microsoft 微软公司，他们只要授权给经销商，经销商就可以不必进货，而不断的出货，只要把版权费按时交给微软公司即可。客户也可以从网路上支付货款，然后直接下载软件或资讯，所以，软件产业的产品就是属于无库存货品，除非要录制成光碟才能出售者，则另当别论。</p><p>15、料品类别标准特性规划建档：</p><p>料品类别是要将制造产业所有的料品依据其功能属性加以分类，以利于工作分派，以及统计分析和管理。例如：电阻类、电容类、电线类、IC类、PCB类、外壳类、开关类、按键类、铭版类、螺丝类、化学药品类、包装箱类、标签类、塑胶袋类、说明书类等。</p><p>除了把料品分类规划建立之外，同时对于不同的料品类别具备的相关属性，也应该加以分析整理并建档起来。一个产业使用的料品种类可能有数十／数百／数千种大类，如果要透过各种料品的相关属性来统计／分析／查询所需要的资料，就必须把不同类别的料品具备的各项属性规划建立起来。例如：钢管类的料品，其属性有：长度、外径、内径、材质等。</p><p>16、料品品管类别规划建档：</p><p>制造产业对于每一项料品的质量检验方式，都有一定规范的品检方式和允收标准，将使用相同品检抽验方式、检验标准和允收标准的项目赋于一个代码，就称为料品品管类别。同一种品管类别可以应用于数种不同的料品分类项目，例如：电阻类和电容类的料品都使用相同品检抽验方式、检验标准和允收标准，也就是使用相同的品管类别。</p><p>17、料品质量等级规划建档：</p><p>料品质量等级规划是用来区别存货的质量等级，例如：良品、不良品、待检验品、待返工（重工）品、待报废品、报废品、次级品等。而不同的产业类别对于质量等级的规划也不相同，像瓷砖产业对产品的分级就有：检一、检二、检三、检四、检五等等级数，表示产品经过高温烧炉之后，其色泽的差异程度。有些产业对于存货良品再区分为：A级品、B级品、C级品，而其差异不一定表示品质的优劣程度，而可能是表示其尺寸的区间范围，例如轴承（Bearing）产业，其外环和内环必须以A级品、B级品、C级品的尺寸各自配套，才能配合安装钢珠后，制造出产品来。若以A级品的外环搭配B级品的内环，因为尺寸不合，就无法做出产品来。</p><p>库存料品的质量等级会影响MRP2数据的控管和运算结果，库存良品在MRP2的运算法则中是属于“供给量”，但是库存的不良品和报废品在MRP2的运算法则中则是属于“非供给量”。因为不良品对于MRP2的运算是没有办法确保正确性的一项数据。</p><p>18、料品特性对照表规划建档：</p><p>对于每一项料品特性的内容，有些特性具备固定的选项范围，可以事先规划建档，等到新增的料品建档时，就可以直接选择已经建档的资料，不容易发生错误。例如：电阻的阻值有固定的对照表，电阻的材质也有固定的对照表，纺织业使用的纱种也有固定的对照表，布匹染色的色号也有固定的色码对照表，制鞋业的鞋材也有其对照表。</p><p>19、料品特性项目规划建档：</p><p>对于产业中每一种料品的特性项目加以收集整理，并且建档处理。例如织布产业的料品特性有：纱种、染色色码、幅宽、印花花版、印花配色、克重（码重）、上浆、刷毛、亮光、颗粒、手感、剪毛、烧毛等。</p><p>20、质量检验项目规划建档：</p><p>对于各项料品的质量检验项目加以整理，并加以编码（包括原材料、半成品、制成品、商品等的检验项目），以便在建立料品检验规范的时候，可以直接选择质量检验项目代码，不需要重复输入许多资料。</p><p>21、不良原因代码规划建档：</p><p>对于产业内的所有原材料、半成品、制成品、商品等的质量不良原因项目加以整理，并加以编码，做为IQC、IPQC、PQC、FQC、QA和生产制造等发生质量不良的统计分析的依据。</p><p>22、区域代码规划建档：</p><p>依据企业的不同管理需求，对于客户和供料厂商的公司所在地区加以规划，并且编订代码。可以用于出货车程的安排用途，也可以做为营业统计分析的依据，或厂商分布地区的统计依据。</p><p>区域代码的规划会因为产业别的不同而有不同的编码方式，对于１００％外销的企业而言，可以用洲别来规划区域代码，有些企业则是以每一个省当做一个区域，有些企业则是以每一个市当做一个区域，有些企业则是以每一个乡镇当做一个区域，或是以华北、华中、华东、华南、大西北做为规划区域的依据。</p><p>23、国别代码规划建档：</p><p>对于和公司有交易往来的客户和厂商的所在国家加以编码，并用于客户和厂商资料建档作业中，做为营销和进料统计分析的依据。</p><p>24、营业项目代码规划建档：</p><p>对于和公司有交易往来的客户和厂商的所有营业项目加以整理并编码，并用于客户和厂商资料建档作业中，做为将来查询资料的依据。</p><p>25、交易条件代码规划建档：</p><p>对于营业和各类采购的交易条件加以整理并编码，做为将来营业部门和采购部门处理各种报价、询价、接单、出货、采购等交易作业的依据。例如：FOB、CIF、C&amp;F等交易条件。</p><p>26、结帐方式代码规划建档：</p><p>对于营业和各类采购作业的结帐收／付款方式加以整理并编定代码，做为将来营业部门和采购部门处理各种报价、询价、接单、出货、采购等结帐收／付款作业的依据。例如：T/T AT SIGHT、T/T BEFORE ? DAYS、T/T AFTER ? DAYS、L/C AT SIGHT、L/C USENCE、D/A、D/P、O/A、月结？天、次月结？天、旬结？天、货到付现金等结帐方式。</p><p>27、进／出口报单代码规划建档：</p><p>配合海关进／出口的报关规定，不同原因的进口和出口作业，都要填制不同的报单种类，以兹识别。而且，不同的进／出口报单在合同核销管理办法里，会影响海关的合同核销帐务记录。进／出口报单的代码直接使用海关规定的代码即可。</p><p>28、进／出口费用代码规划建档：</p><p>在公司进口货品或出口货品之时，都会发生不同的费用项目，例如：拖柜费、仓租费、保险费、运费、融资利息、报关费等，因为进口发生的费用和出口发生的费用在会计总帐中是以不同的会计科目入帐，所以必须分别编订进／出口费用代码，供相关部门在各项作业中使用。</p><p>29、会计凭证摘要代码规划建档：</p><p>对于会计总帐的会计凭证（传票）和应收／应付凭单的登帐作业中会经常使用到的摘要／备注，全部加以编码建档，以便在做帐时直接选用摘要／备注代码，提高作业效率。</p><p>30、品检AQL105D抽检标准对照表建档：</p><p>每一个制造产业对于厂内生产制造的、和委外加工的：制成品、半成品，以及采购的各项料品都有质量检验的标准，质量部门把这些标准的数据整理好之外，还必须建立到电算化的软件系统里，让计算机能够自行判断：在IQC／IPQC／PQC／FQC／QA的各种情况下，每一项料品须要采用哪一种检验方式和检验水准。</p><p>品检的抽检标准并不仅仅有AQL105D 一种，每个产业都可以依据实际需求状况建立自己的品检抽检标准，包括非国际标准，而是公司自行订定的标准。</p><p>31、采购人员代码规划建档：</p><p>对于每一个产业，因为采购工作量的大小不同，采购作业电算化的程度也不同，所以，聘用的采购人数也一定不同，采购工作的分派方式也会不同。先不论采购人数有多少，最重要的问题是：采购工作如何分派，采购人员的代号怎么编码？</p><p>采购人员的代号编码最好像买车票的柜台一样，从01，02，03，04，05．．．．．编定，因为采购人员会流动，不论谁离职，谁到职，只要规定哪一号柜台买哪几类种别的料品，即可。</p><p>采购工作最好是依据料品类别分派，当料品数量大幅度增加的时后，可能要增加采购柜台，工作要重新分派，透过料品类别分派工作，只要几分钟就可以搞定，如果一项一项料品分派，就像发扑克牌一样，如果公司有３万种采购件料品，搞三天三夜不睡觉也还搞不好。</p><p>有些公司用供应厂商的所在地区来分派采购工作，就合理性方面就有重大问题，如果一项料品有三个供应厂商，分别在深圳、湖南株洲、福建厦门，难道要由三个人同时负责采购，难道要求三个人都必须同时了解同类料品价格谈判的成本结构吗？而且，将来请购同样的料品时，请购单要交给哪一位采购员？还是让他们三个采购员自行分配工作？这是一种不明确化，也不高效化的管理制度规划，光是请购单重新分配工作就增加许多工作量，而且请购单不知该如何填制了，应该是一张请购单填一项料品，或一张请购单填一项料品？</p><p>32、生管人员代码规划建档：</p><p>对于每一个产业，因为生管排程工作量的大小不同，车间的机器设备数量不同，使用模具／工具／治具／夹具的状况也不同，生管作业电算化的程度也不同，所以，需要的生管人数也一定不同，生管工作的分派方式也会不同。先不论生管人数有多少，最重要的问题是：生管工作如何分派，生管人员的代号怎么编码？</p><p>生管人员的代码应该和采购人员代码的编码方式相同，从01，02，03，04，05．．．．．编定。至于生管人员的工作分派，就建议以机器设备（生产线／工作中心）的生产型态来规划安排。</p><p>33、物控人员代码规划建档：</p><p>物控人员的工作主要是负责监控制造产业的原材料和中间半成品的备料状况，让原材料和半成品的进料时间不会太晚（造成停工待料），也不会进料太早（造成存货积压／资金积压）。</p><p>物控人员的代码应该和采购人员代码的编码方式也相同，从01，02，03，04，05．．．．．编定。至于物控人员的工作分派，则建议以料品类别来分派，每一个物控人员负责几种料品类别的管控。至于需要多少物控人员，则会因为选用ERP厂牌的好坏而有重大影响。如果ERP的物控功能很差，或没有功能，则，３００人的小工厂，请３０个物控人员也做不好物控工作。因为物控工作是不可能用人海战术来解决的。</p><p>34、仓管人员代码规划建档：</p><p>仓库管理对于任何企业都是非常重要的环节，许多公司的董事长或高阶主管可能都忽略了仓库管理的重要性。事实上，对于大多数的企业而言，库存品的合计总价值，可能比公司的银行存款多上十倍以上。如果忽略仓库管理的重要性，可能会比忽略银行存款的管理产生更严重的后果。</p><p>因为库存数量和帐务不符，比银行存款帐目不符更难查，但金额可能更大。若库存管理不善而产生报废，就等于手上的现金钞票被白蚂蚁吃掉，只是很奇怪：大部份的人看到钞票被白蚂蚁吃掉会心痛，但是存货拿去报废好像心理比较能够接受！</p><p>仓库人员代码的编定，应该和采购人员代码的编码方式也相同，从01，02，03，04，05．．．．．编定。至于仓管人员的工作分派，则建议以仓库别来分派，即：每一个仓库由谁控管，包括帐和物品都要由他负责，如果没有固定负责人员，就表示谁都要负责，也等于谁都不必负责。</p><p>仓库的搬运人员和仓管人员不同，仓管人员必须对物／帐负责，搬运人员只要配合仓管人员指示把存货存放在定点，或从指定的储位领取物品，并运交到指定的部门和地点即可。一个（或几个）仓库只可以有一个仓管人员（仓管柜台），但同时可以有数名搬运人员。</p><p>35、原始凭证代码规划建档：</p><p>所谓的原始凭证，指一个产业（企业）所使用到的各种单据。单据和报表不同，单据是表示在各种作业过程中，部门和部门之间，个人和个人之间，责任的转移、物品的转移、金钱的转移、帐务的转移、或任务的下达，所依据的书面格式，经手承办的人都必须签名盖章，表示负责。也做为将来在公司内部规章或在法律上责任判定的依据。</p><p>报表则是从某一种（或某几种）原始凭证的数据资料中整理出所需要的信息，再依据使用的必要性来决定需不需要签名盖章。就算在报表上签名盖章，万一发现数据资料不符，也只能算是疏忽，真正的问题还是来自原始凭证的错误，或报表输出软件的错误。例如：某月份的损益表数据不对，肯定不是签名盖章的时候发生错误，若不是会计凭证登录错误，就是计算机软件错误。若是会计凭证登录时发生错误，就表示当时会计凭证制单／签核盖章的人要负责，不论用人或计算机整理报表是取用会计凭证的数据资料，要如何负责？这就是单据（原始凭证）和报表的差异。</p><p>每一个产业对于公司所有使用到的内部凭证／对外凭证／外来凭证都要全部加以整理／编码，并且规划改善。尽管是推行ISO质量认证体系，或推行股票上市的内部控制／内部稽核体系，也都必须要把所有的原始凭证重新整理一次。何况是推行ERP全面电算化的经营管理整合信息系统，只要不能符合：明确化／合理化／规范化三种条件，就注定全面电算化保证失败，除非系统不做整合（不整合的电算化系统就是会产生许许多多信息孤岛）。何况一个企业达到：明确化／合理化／规范化的程度，并不表示已经达到高效化、精细化、自动化的程度。</p><p>推行ERP全面电算化的经营管理整合信息系统，所有原始凭证都必须经过重新规划审察过。既然称为信息整合管理系统，就表示每一张原始凭证在规划设计时都必须考虑具备（１）和四大流量相互整合的数据接口（物流／帐流／资金流／信息流），（２）和各个循环／分工体系之间的接口，否则如何称得上是全面电算化整合信息管理系统呢？</p><p>一个产业的每一张单据就像是人体组织的每一个器官一样重要，举例说明：人体的嘴巴器官，会连结到：呼吸循环、血液循环、淋巴循环、消化循环，同时也连接到：肌肉组织、神经组织、骨骼组织、皮肤组织等。经营管理的客户订单，会连结到：财务资金循环、生产制造循环、产品研发循环、存货管理循环、委外加工循环，同时也连接到：制程工程（工业工程）分工、生产管制分工、物料控制分工、制造成本分工等体系。</p><p>人体复杂而精细结构的规划设计是靠宇宙的造物者的创意，产业全面电算化的经营管理整合信息系统的规划设计则是靠专业的架构规划师（ＥＲＰ Ａrchitecture）来创造。如何让制造产业的ＥＲＰ全面电算化的经营管理整合信息系统能够规划设计到有如人体的组织结构一样灵活精细，就是产业能否真正具备十六大竞争优势的决战关键。</p><p>本人以财务资金循环体系和营业收款循环体系的一部分功能做为范例，来提出它们之间会牵涉到的系统整合的相关技术，如果您有办法提出完整解答，才表示您真正具备了系统评鉴的能力。（例题）：营业部门的出货作业：(a)、营业部门的出货作业同时会应用到哪些相关单据？包括：内销作业、外销作业、合作外销、转口贸易。(b)、营业部门的出货作业会和财务资金循环体系有哪些关联？何谓六大帐册？和营业收款体系之间有何关联？(c)、营业部门的出货作业会在甚么时机才真正进入财务循环立帐？又如何确保所立的帐是１００％正确？还能够做到双向稽核？不担心漏帐／错帐／重复登帐？(d)、财务循环体系必须每个月结帐，提出相关财务报表，对于交易程序尚未完成的部份，该如何配合处理？</p><p>上面四个问题的相关系统整合技术将留在营业收款循环体系章节中详细解说，以确保内容的完整性和连续性。</p><p>以上是指以财务／会计为核心的最关键性的系统整合技术（营业收款循环体系和财务资金循环体系能够整合，就表示其它循环体系和财务资金循环体系也应该能够整合，整合技术是相类似），也是身为一个现代化高阶经营管理者及信息化部门主管必备的专业知识。少了这一项专业认识，企业的竞争风险就增加几分。如果同业在这个领域有所突破，就表示这个同业已经进入高度财务管理自动化的运作模式，而且已经可以做到：防弊、防错、防呆、防人员流动、防信息流失、防知识断层的经营管理水平。</p><p>36、银行（金融机构）代码规划建档：</p><p>银行（金融机构）就是指所有国内外以钱为主要商品，或是有专业从事资金流通／融通借贷／投资／转帐／债券发行业务等的企业法人，包括银行、合库、农会、信托局、邮局、债券公司等等。</p><p>对于国内的银行（金融机构），凡是和公司有往来的银行肯定要编码建档，接单客户和往来厂商跟我们公司有关系的银行也要编码建档。而银行（金融机构）的编码规则，直接采用中央银行编订的标准代码就可以了，不需要另行编码。</p><p>37、存款帐号代码规划建档：</p><p>存款帐号主要就是指公司在银行（金融机构）开立的各种类型的存款帐户，包括：活期存款、支票存款、定期存款、融资偿债专户、投资专户等等。而且，同性质的存款帐号还有各种不同币别的帐户，例如：人民币帐户、美金帐户、港币帐户、日币帐户等等。</p><p>对于存款帐户的编码技术，建议采用下列原则：存款种类用一码，币别用二码，流水号用两码或三码。理论上银行存款属于相同种类性质，又相同币别，能够用到９９９个帐号，这个国际集团企业也确实是具备相当的规模了，但也不至于用到９９９个帐户吧。</p><p>银行存款帐户规划编码好了，就可以自动生成银行存款的会计科目，即：银行存款的统制科目（４码）＋款帐户的编码（５至６码），就等于会计总帐管理系统的银行存款明细科目。将来所有银行存款帐户的资金存／取变动记录，就可以从银行存款帐和会计总帐自动产生整合互动。不需要人工重复登帐了。</p><p>38、存款异动摘要代码规划建档：</p><p>每一个银行存款帐户的每一笔存／取／变动（异动），都会有其原因，为了将来能够清楚瞭解并追查银行存款帐户的变动，就必须把每一种变动原因加以编码。并且，把存款增加的原因代码的第一码用“D”，表示Debit（借方）；存款减少的原因代码的第一码用“C”，表示Credit（贷方）。</p><p>39、年度周别规划建档：</p><p>一年有５２周虽然是常识，但是在系统整合的信息上，还是要明确表示在系统上，并且包括近期两年的数据资料，以便在生产管制和物料控制作业上运用，另外在中长期资金调度预估表上，也是以周别的方式来表达资金状况是否足够。</p><p>40、银行行事历资料建档：</p><p>银行的行事历和公司的行事历并不相同，因此必须另外建档。银行的行事历最主要是会影响应收／应付票据的票面到期日和托收银行的实际兑现日的银行存款立帐作业。</p><p>41、公司行事历资料建档：</p><p>对于公司每个月的行事历，人事部门都必须要在每个年度到来之前规划建档，以便其它部门的各项计划作业能够顺利进行。</p><p>42、利润中心（专案）代码规划建档：</p><p>如果产业推行利润中心、成本中心、专案管理的话，就必须在每一个利润中心、成本中心、专案管理项目成立时，把其代码和名称等数据资料规划建档，以便其它部门可以取用。</p><p>如果利润中心、成本中心是以：部门、厂别、营所、事业处（部）、产品类别为核算基础的话，就不须要在本作业画面另外建档，这些资料已经在其它作业项目建档了。而且，透过会计总帐的会计科目立冲要件设定，就能自动产生上列部门别损益表、厂别损益表、营所别损益表、事业处（部）别损益表、产品类别损益表等。</p><p>所谓专案管理项目，主要是针对：工程承包合约、工程发包合约、新厂房建厂专案、新产品开发专案、或是一些项目型接案的产业等，就必须能够应用专案管理的功能。</p><p>43、票据类别代码规划建档：</p><p>对于公司在财务运作过程中会使用到应收／应付票据的票据种类加以分类／编码／建档。例如：支票、本票、汇票等。</p><p>44、会计凭证（传票）种类代码规划建档：</p><p>会计传票一般分为：（１）现金收入传票 （２）现金支出传票 （３）收入传票 (4)支出传票 (5)转帐传票等五种，如果万一又有新的分类产生，就可以再自行增加。</p><p>45、往来对象类别代码规划建档：</p><p>往来对象类别代码是将公司往来的客户、供料厂商、委外厂商、往来银行（金融机构）、政府机关、学校、母子公司、关系企业等，依据产业的管理需要，及不同属性的往来对象特性，编定不同的往来对象类别代码，供往后做管理分析使用。例如：对于往来客户来说：有些公司是以：开发中客户（K）、交易中客户（J）、停止交易客户（T）、拒绝往来客户（G）。而往来厂商的分类则可以另外依实际需要来规划编码处理。</p><p>往来对象的“类别”和“等级”的概念不同，等级是指：A级、B级、C级、D级、E级、或01级、02级、03级、04级、05级、06级等。</p><p>46、呆滞料品原因代码规划建档：</p><p>为了对于产业中产生呆滞料的原因加以编码区分，以便确认部门和个人的权责，并且能够对每周／每月／每季／每年做统计分析，让每个部门和个人会随时加以警惕，可以大幅度降低呆滞料品产生的成本损失。</p><p>一个产业的经营过程中，可能造成呆滞料品的部门和原因很多，例如：产品研发设计不良、业务订单产品打错、业务订单数量打错、客户订单变更、物控核料项目错误、物控核料数量错误、采购部门买错料、采购部门多买料、生管工令单开错产品、生管工令单开错数量、仓管发错料、仓管搬运摔毁、制造部门用错料、制造部门超产、交期延误遭客户取消订单等。项目和权责规划越清楚明确，就越能降低呆滞料品的损失。</p><p>47、料品材质代码规划建档：</p><p>如果产业对于使用料品的材质很重视，则必须把各种使用到的原材料材质加以分类规划编码，做为产业经营管理分析的依据。例如：鞋业、成衣业、皮件业、包袋业等。</p><p>48、营业税申报地点代码规划建档：</p><p>营业税／增值税等是属于地方税，一个公司法人可能跨好几个地区经营，包括各个分厂、营业所、办事处，所以对于公司所有的营业税／增值税等申报地点必须先行整理编码建档，做为各个分厂、营业所、办事处资料建档时，及发票处理作业时，可以顺利应用。</p><p>49、备注说明代码规划建档：</p><p>产业全面电算化整合信息系统建立实施之时，有许多电算化作业会重复应用到相同的词句、备注、摘要等，为了避免重复输入，浪费人工时间，可以事先将这些词句整理编码建档，供相关作业中选用。</p><p>在编定词句、备注、摘要等代码时，最好要依据用途／性质分类，再编码，免得资料多了之后会找不着。</p><p>50、料品单位代码规划建档：</p><p>对于公司的全部料品使用到的单位，若有统一的必要，可以先在全面电算化实施的前期加以规化建立，这样可以避免相同料品分类的东西，却用不同的单位表示，例如：同样是电阻类的料品，有些用个，有些用颗，有些用粒，有些用PCS，有些用PS，在数据计算上是没有甚么影响，但是就是列印报表时会出现许多不同的单位符号，看起来不统一。</p><p>51、往来客户代码规划建档：</p><p>对于公司往来的客户资料，全部加以编码建档。客户编码采用的编码规则建议如下：(a)、对于国内使用中文的公司，直接以公司名称的前四个中文字的罗马拼音的第一段编码，４码以后则用流水码，可避免前４码重复。至于流水码要用几码，要看往来客户和厂商的家数多少来决定，最多可以用到４个流水码。至于前四码如何编订，最好是所在县市地区放在前二码，公司名称放在三四码，例如：宁波顺发金属有限公司，其代码为：NBSF001。宁波升华工业股份有限公司，其代码为：NBSF002。宁波申富泉实业股份有限公司，其代码为：NBSF003。虽然罗马拼音相同，但是流水码并不相同，使用者马上可以用前四码查询到这三家客户的资料。(b)、对于国外非使用中文名称的公司，则直接使用其英文名称的前四码，再依据外销客户数量多少决定加上几码流水码，将来就可以简单的进行查询的作业。</p><p>52、往来厂商代码规划建档：</p><p>对于公司往来的厂商资料，全部加以编码建档。往来厂商编码采用的编码规则建议和往来客户采用相同的规则，不需要另外再订定编码规则。</p><p>尤其，有些客户也可能是厂商身份，到底要分别用一个代码，或共用一个代码？如果每个月结帐时，该客户同时有应收帐款，也有应付帐款发生时，如何让应收帐款和应付帐款能够对冲？</p><p>如果使用两个往来对象的方式，应收帐款和应付帐款是不能够对冲的，如果开放不同厂商客户间可以应收帐款和应付帐款能够对冲，则将来财务管理系统大乱的机会将大增，而且，人为的疏忽或作弊的可能性就会增加，当几百家／几千家客户和厂商的应收帐款和应付帐款大乱之后再来整帐，大部份的财务人员会投降，因为应收帐款和应付帐款大乱，就表示会计总帐肯定也出大问题。所以，不同往来对象的账是不能相互对冲的。而相同的一个往来对象同时具备客户和厂商资格时，最好的办法就是只用一个往来对象代码。</p><p>53、公司股东资料规划建档：</p><p>公司的股东有可能是自然人股东，也可能是法人股东。由于公司的股东必定和公司会有某些必然的往来事项，所以就必须加以编码建档。一般股东的资料保存期限都很长，所以所有股东的资料都不能轻易删除，也就必须在股东编码时把码数加大，免得将来不够使用。尤其，没有人可以预知公司的发展会到甚么规模？也就无法预测公司的股东人数会有多少。例如：一个２００人的企业，有可能发展到２０，０００人，而成为一个上市公司，然后再发展到国际性集团企业，其股东人数可能从原来的独资个人，变为数十万个股东的国际性集团企业。经过了十年二十年之后，股东的持股转换，就可以达到数百万／数千万个股东资料的情况。</p><p>54、其它往来对象代码规划建档：</p><p>所谓其它往来对象的范围，就是母子公司、关系企业、往来客户、往来厂商、公司股东以外的政府机关、学校、慈善机构等等，会和公司在非交易性质的事务上往来的各种对象。其编码方式和客户／厂商相同，在查询资料上会比较简单。</p><p>55、使用者权限规划设定：</p><p>对于公司全面电算化的软件系统使用上有被授权者，都必须设定其使用者权限，做为对其工作范围和权责大小的规范，同时也对产业的机密加以更严格的控管。</p><p>对于使用者权限的控管，可以控管到：系统模块、作业项目、每项作业的新增／修改／删除／查询／审核/作废/确认／反确认／列表等，以及重要栏位（字段）的锁定。一旦使用者权限设定完成，每一个使用者就只能看到自己被授权的功能范围，以降低系统使用的复杂度。</p><p>56、年度会计周期规划设定：</p><p>每一个企业都可以有自己的会计周期规划，对于不同的国家，使用的会计周期更是多样化。有些公司是以每年的一月到十二月为年度会计周期，有些公司是今年的五月到明年的四月为年度会计周期，有些公司则是以周别区间来结算各月份的损益和资产负债等财务报表，每年的一月是以第一周来起算，而不是元月一日起算。</p><p>面对各国的各种会计周期差异，就必须提供会计周期设定的功能。而且，当面对一个跨国的集团企业，财务总监如何处理不同国家的会计周期，并且还要能够达成集团企业全球会计合并彙总的目的，就是一个重要关键性技术。事实上，只要在全面电算化整合性管理信息系统中同时提供两个会计周期设定的功能即可以解决这个严重的问题。</p>]]></description></item><item>    <title><![CDATA[电子签章选型指南：三步找到安全与便捷的“黄金平衡点” 俊秀的小摩托_bWeu86 ]]></title>    <link>https://segmentfault.com/a/1190000047555300</link>    <guid>https://segmentfault.com/a/1190000047555300</guid>    <pubDate>2026-01-21 12:08:59</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>安全与便捷，本质上是用户体验与风险控制之间的动态平衡，但是在电子签章的实际应用中却给用户完全不同的操作体验。那我们应该如何去把控呢？</p><ol><li>核心矛盾与解决框架</li></ol><p>Ø 便捷性追求：快速、远程、无纸化、低成本、易操作、跨平台。（典型代表：法大大、上上签、E签宝等电子签章公司）</p><p>Ø 安全性追求：身份真实、意愿真实、文档防篡改、过程可追溯、法律效力强。（典型代表：安证通、点聚、契约锁等电子签章公司）</p><p>Ø 平衡框架：“分场景、分等级、强技术、简操作”。不是所有签署都需要银行级安全，也不是所有文件都可以一个短信了事。</p><ol start="2"><li>实现平衡的关键技术手段（安全基石）</li></ol><p>这些技术在不增加用户感知复杂度的情况下，提供了强大的底层安全保障：</p><p>Ø 数字证书与PKI体系：这是安全的核心。由权威CA机构颁发的数字证书，能唯一标识签署者身份，并实现数字签名和加密。用户无需理解其原理，只需完成一次实名认证。</p><p>Ø 可靠的电子签名：符合《中华人民共和国电子签名法》规定，能够识别签名人身份并表明认可内容。</p><p>Ø 哈希算法与时间戳：确保文档一旦签署，任何改动都能被侦测，并精确记录签署时间。</p><ol start="3"><li>在用户体验层面的平衡策略（便捷体现）</li></ol><p>1) 分级安全策略：</p><p>Ø 低风险场景（如内部审批、普通协议）：可采用短信验证码+实名认证的方式，便捷性极高。</p><p>Ø 中风险场景（如采购合同、服务协议）：推荐使用数字证书签名，结合人脸识别或指纹等生物特征进行意愿确认。</p><p>Ø 高风险场景（如金融借贷、重大交易）：必须采用数字证书+强生物特征识别+过程录音录像，确保身份与意愿的双重强验证。</p><p>2) 流程优化：</p><p>Ø 模板化与批量签署：对于格式固定的文件，一次制作，多次使用。</p><p>Ø 移动化与云端协同：随时随地通过手机、平板签署，无需专用设备。</p><p>Ø 与业务系统集成：将签章能力嵌入OA、CRM、ERP等系统，实现一键发起、无缝流转。</p><p>3) 透明的验证机制：</p><p>Ø 提供便捷的验签功能，任何接收方都能轻松验证签名的有效性和文档完整性，这本身就是一种安全信任的建立，也提升了协作效率。</p><ol start="4"><li>平衡点的具体体现（理想状态）</li></ol><p>一个优秀的电子签章服务，其平衡点体现在用户侧和治理侧：</p><p>1) 对签署方：</p><p>Ø 第一次使用：可能需要完成一次稍复杂的实名认证（如上传身份证、人脸识别）。这是为后续所有便捷性支付的“安全成本”。</p><p>Ø 后续每次签署：流程极其简单（如点击链接→查看文件→输入短信验证码/刷脸→完成），但背后安全机制（数字签名、哈希、时间戳）全自动运行。</p><p>2) 对企业管理者/法务：</p><p>Ø 可配置：能为不同合同类型设置不同的安全等级。</p><p>Ø 可审计：所有签署过程全链路存证，生成完整的证据报告，随时可查、可溯源。</p><p>Ø 合法合规：严格遵循法律法规，确保电子文件在法律纠纷中可作为有效证据</p><p>根据目前市场各个电子签章公司发布的产品以及实际客户应用场景来看，操作安全性与操作便捷性平衡点把控的比较好的签章公司如下：</p><p>Ø 第一梯队：北京安证通、腾讯电子签、可信签；</p><p>Ø 第二梯队：E签宝、契约锁；</p><p>Ø 其他：法大大、上上签等。</p>]]></description></item><item>    <title><![CDATA[Nacos 生产级安全实践：精细化鉴权、灰度平滑过渡与全量操作审计 阿里云云原生 ]]></title>    <link>https://segmentfault.com/a/1190000047555303</link>    <guid>https://segmentfault.com/a/1190000047555303</guid>    <pubDate>2026-01-21 12:08:18</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>作者：子葵</p><p>配置中心和注册中心是微服务架构的核心基础设施，承担着关键的配置管理和注册发现职责。然而在实际生产中，部分企业的注册配置中心可能面临安全风险：如权限管理粒度不足、操作审计缺失，这可能导致未授权访问或误操作，进而影响业务的稳定运行。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555305" alt="image" title="image"/></p><p>你是否也曾遇到以下常见痛点？</p><ul><li><strong>权限管理挑战：</strong> 权限配置过于粗放，难以对不同用户或应用进行精细化授权，导致配置被误改或难以追溯操作者。</li><li><strong>鉴权升级顾虑：</strong> 考虑开启鉴权，但担心直接切换可能影响大量存量应用，造成服务中断，使得安全与业务连续性难以平衡。</li><li><strong>排查效率低下：</strong> 当出现鉴权失败时，缺乏清晰的错误日志和可视化手段，排查问题耗时耗力。</li></ul><p>为了有效应对这些挑战，<strong>MSE Nacos 推出基于 RAM 的精细化鉴权与审计方案</strong>。我们致力于在保障安全性的同时，提供平滑的过渡和直观的可视化能力。</p><h2>三大核心能力，提升 Nacos 安全性</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555306" alt="image" title="image" loading="lazy"/></p><h3>1. 极简运维：RAM 深度集成，权限管理白屏化</h3><p>告别过去手写复杂 JSON 策略、计算密码 Hash 的繁琐时代。MSE Nacos 与阿里云 RAM（访问控制）深度集成，实现了真正的<strong>企业级权限隔离</strong>。</p><ul><li><strong>一键生成策略：</strong> 无需手动编写晦涩的权限脚本。在控制台通过白屏化界面勾选资源，自动生成对应的 RAM 权限策略内容，复制即可在 RAM 控制台完成授权。</li><li><p><strong>精细隔离：</strong> 支持 Namespace（命名空间）、Group 甚至 Service/DataId 粒度的权限控制。你可以轻松实现：</p><ul><li>运维团队拥有所有环境的读写权限；</li><li>开发 A 组只能读写 Dev 环境，对 Prod 环境只有只读权限；</li><li>应用 B 只能注册到特定的服务名下，防止服务冒用。</li></ul></li><li><strong>账号复用：</strong> 直接复用企业现有的 RAM 子账号体系，无需为 Nacos 单独维护一套用户列表。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555307" alt="image" title="image" loading="lazy"/></p><h3>2. 平滑开启鉴权：支持灰度鉴权，保障业务连续性</h3><p>针对存量系统开启鉴权可能引发的兼容性风险，我们提供了<strong>灰度鉴权</strong>功能，确保从“无鉴权”到“有鉴权”的平滑过渡。</p><ul><li><strong>宽松验证模式：</strong> 开启灰度鉴权后，Server 端会对客户端请求进行身份验证。对于<strong>未配置身份信息</strong>或<strong>身份信息配置错误</strong>的客户端，系统<strong>不会拦截</strong>其请求，确保业务调用不受影响。</li><li><strong>风险可视：</strong> 虽然系统暂不阻断请求，但会详细记录鉴权失败的错误信息。通过监控大盘或日志，你可以精准识别出哪些客户端尚未正确适配鉴权。</li><li><p>无感升级路径：</p><ol><li>开启灰度鉴权，业务完全无感。</li><li>根据鉴权失败记录，逐步修正客户端的账号密码配置。</li><li>待所有客户端配置无误后，关闭灰度模式（正式开启强鉴权），完成安全升级。</li></ol></li></ul><h3>3. 全景监控：鉴权可观测大盘，提升运维透明度</h3><p>安全不仅要具备防护能力，更需要具备可视化的监控能力。我们提供了<strong>全方位的鉴权审计大盘</strong>，让每一次访问都有据可查。</p><ul><li><strong>全量操作审计：</strong> 开启鉴权后，所有的数据操作（如配置的发布、删除、修改，服务的注册、注销）都会被系统自动捕获并记录。每一次变更的操作人（RAM 账号）、操作时间、客户端 IP 均可追溯，确保数据安全无死角。</li><li><strong>实时监控：</strong> 直观展示集群的鉴权成功率、失败率趋势，帮助运维人员实时掌握安全水位。</li><li><p><strong>精准定位：</strong></p><ul><li><strong>来源分析：</strong> 支持展示拦截客户端来源 ip，时间，访问资源等信息</li></ul></li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555308" alt="image" title="image" loading="lazy"/></p><h2>核心操作流程</h2><p>简单五步，即可完成从“零鉴权”到“安全闭环”的平滑升级：</p><ol><li><strong>策略生成与配置：</strong> 在 Nacos 控制台“认证鉴权”模版中生成权限策略，并在 RAM 控制台授予指定的子账号。</li><li><strong>开启灰度鉴权：</strong> 开启 Nacos 实例的“灰度鉴权”开关，进入宽松模式（记录但不拦截）。</li><li><p><strong>客户端适配发布：</strong> 在客户端配置鉴权信息（AccessKey/SecretKey）并发布应用。详细配置过程可以参考文档：  </p><p>为 Nacos 实例开启鉴权并配置客户端访问凭证：<a href="https://link.segmentfault.com/?enc=hGN0rbWGiy5YlH1%2FvgxACg%3D%3D.Czdfdsk14k%2FEqkInODy5zrjh5LDg5Wu9m1YIl1fUII0YAEiUIKumXBXcBJgxCj5UAbNhoIuBvTHtMs%2B3BIYKeIGOJiLYMRsdTHoo6tiDpuw%3D" rel="nofollow" target="_blank">https://help.aliyun.com/zh/mse/user-guide/access-authenticati...</a></p></li><li><strong>大盘观测检查：</strong> 检查“鉴权审计大盘”，确认无非预期的拦截记录。</li><li><strong>正式开启鉴权：</strong> 确认无误后，关闭“灰度鉴权”开关，正式启用强鉴权模式。</li></ol><h2>总结</h2><p>MSE Nacos 鉴权审计方案，旨在为企业提供<strong>一套开箱即用、平滑过渡、可视可控</strong>的安全基础设施。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555309" alt="image" title="image" loading="lazy"/></p><ul><li><strong>极简运维：</strong> 白屏化配置与策略自动生成，告别繁琐脚本，轻松复用企业 RAM 账号体系。</li><li><strong>精细管控：</strong> 支持细粒度至 Service/DataId 的权限隔离，严格遵循最小权限原则，保障数据安全。</li><li><strong>平滑升级：</strong> 独有的灰度鉴权模式，让存量应用在“只记录不拦截”中完成无感适配，消除业务中断顾虑。</li><li><strong>全景可视：</strong> 全量操作审计与可视化大盘，从鉴权拦截到数据变更，让每一次访问都透明可查。</li></ul><p>通过 MSE Nacos，您可以轻松构建企业级零信任安全体系，在保障业务灵活性的同时，彻底解决权限管理粗放与操作溯源难的痛点。</p>]]></description></item><item>    <title><![CDATA[你以为缺的是管理，其实缺的是好工程师 俞凡 ]]></title>    <link>https://segmentfault.com/a/1190000047555348</link>    <guid>https://segmentfault.com/a/1190000047555348</guid>    <pubDate>2026-01-21 12:07:30</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <blockquote><em>本文面向种子轮、A 轮的产品/技术管理者，拆解早期工程团队最常见的管理反模式，重点是少花力气「管人」，把精力用在产品、用户和招聘上。</em></blockquote><p>很多创始人都会经历类似的一天：</p><p>产品刚有一点起色，团队有 6、7 个工程师，大家各自忙着写代码。你刷了一圈飞书、钉钉、Jira，看到没人「熬夜上线」、「周末加班」，心里开始打鼓：</p><blockquote><p>我是不是该「管一管」了？</p><p>要不要设周末站会？</p><p>要不要赶紧招个工程经理？</p></blockquote><p><strong>在早期，绝大多数你以为的「管理问题」，本质上都不是管理问题，而是产品和招聘问题。</strong></p><p>对种子轮、A 轮阶段的产品/技术管理者来说，最值得警惕的，是那些听上去很「负责」、实际上却严重分散注意力的管理动作。</p><p>下面，我们把这些反模式拆开讲清楚。</p><hr/><h2>一、问题：为什么你总觉得「需要管理」？</h2><p>在早期工程团队里，创始人最常见的一种焦虑是：</p><ul><li>工程师好像没那么「拼」，没人自发熬夜</li><li>项目进展不够「可见」，看不到随时可展示的进度条</li><li>组织结构还很扁平，感觉「不像一家真正的公司」</li></ul><p>这时，很容易滑向一个直觉：</p><blockquote>我需要更多的管理：更多会议、更多流程、更多角色。</blockquote><p>但如果你还在找产品/市场匹配点（PMF），事情恰好相反：</p><ul><li>你最需要的是<strong>把所有可用的精力，放到产品和用户身上</strong></li><li>任何与此无关、但会占用创始人和工程师时间的管理创新，都是巨大的机会成本</li></ul><p>所以，真正的问题不是「缺不缺管理」，而是：</p><blockquote>在这个阶段，哪些「看上去像管理」、但其实只会拖慢团队的动作，应该被坚决避免？</blockquote><hr/><h2>二、误区：三种常见的管理反模式</h2><h5>误区一：试图靠「打鸡血」激励工程师</h5><p>很多创始人一看到团队不够「燃」，就开始想办法「激励」工程师：</p><ul><li>鼓励甚至默认 996 式的长时间工作文化</li><li>把原本可以异步的事情，塞进周末或晚上的会议</li><li>各种形式的微观管理：频繁要进度、要截图、要「证明你很努力」</li></ul><p>问题在于，<strong>优秀的工程师，要么一开始就自带动力，要么很快会被这种文化劝退。</strong></p><p>记住这个重要结论：</p><blockquote>动力是招聘进来的，不是管理出来的。</blockquote><p>当你花大量心思去「点燃」团队时，往往说明有两个地方出了问题：</p><ol><li>招聘时，没有足够重视候选人的内在驱动力、韧性和好奇心</li><li>环境没有给这些本来就很自驱的人，足够的空间和意义感</li></ol><p><strong>可执行建议：</strong> 把「是否自驱」当作硬标准写进招聘评分表，而不是事后靠文化口号来补课。</p><hr/><h5>误区二：过早引入管理者和头衔</h5><p>另一个常见做法是：一到十几个人，就开始「像大公司一样」搭管理架构：</p><ul><li>给团队划小组、设组长、甚至招全职工程经理</li><li>安排定期的一对一、绩效评估、晋升路径设计</li><li>为了「有条不紊」，大规模引入流程、里程碑、报表</li></ul><p>听上去都很负责任，但在早期，这往往意味着：</p><ul><li>你还在搞清楚<strong>到底该做什么产品</strong>，却已经请来一个「负责把事做对」的人</li><li>管理者不得不创造各种「管理工作」 —— 安排会议、管理 Jira、评估绩效，以证明自己有价值</li><li>很难判断问题出在产品、在工程师，还是在管理者身上</li></ul><p>下面给出一个简单的分阶段视角：</p><ul><li><strong>5–6 人（含技术创始人）</strong>：阶段太早，不需要管理者。创始人主要做两件事：招人和（在极端情况下）开人，其余让团队自组织。</li><li><strong>10–15 人、2–3 个子团队</strong>：所有工程师依然可以向一个人汇报（通常是 CTO），这是打磨工程文化的关键窗口期。</li><li><strong>20–50 人</strong>：这时才是引入更多组织架构和管理层的阶段，此时团队规模扩大带来了混乱，开始真实限制产出。</li></ul><p><strong>可执行建议：</strong> 在 20 人之前，慎重对待任何「全职只做管理、不写代码」的角色设计。</p><hr/><h5>误区三：照抄大厂的「先进管理实践」</h5><p>还有一种更隐蔽的反模式，是把大厂的管理实践，当成早期团队的模板：</p><ul><li>全套 Scrum 仪式：每日站会、迭代回顾、燃尽图</li><li>复杂的绩效体系、胜任力模型、晋升委员会</li><li>花哨的反馈机制、同行评审流程</li></ul><p>问题不在于这些方法本身，而在于<strong>阶段错配</strong>：</p><blockquote><p>大厂管理的是一台已经运转起来的机器；</p><p>你在早期时，还在造发动机。</p><p>早期团队的管理栈，应该像「Node + Postgres」—— 普通、稳妥、被无数人试过，不会成为公司失败的原因。</p></blockquote><p>换句话说，<strong>在管理这件事上，越无聊越好。</strong></p><p><strong>可执行建议：</strong> 每当你想引入一个「很新」「很酷」的管理做法时，先问一句：如果不用，我们真的做不出产品吗？</p><hr/><h2>三、方法：少做管理，多做这几件事</h2><p>如果说上面三种是「别做」，那早期工程团队到底该「做什么」？有一个很实用的思路：</p><blockquote>用「不情愿的管理者」心态，去做那一小撮真正必要的事。</blockquote><h5>1. 把精力放在「招对人」上</h5><ul><li>招聘时，刻意寻找那些<strong>有真正动力</strong>的人：主动加班、愿意为难题投入超预期精力，但不是被逼出来的</li><li>关注候选人经历里的「挫折时刻」 —— 遇到过什么困难？怎么扛过来的？</li><li>是否有持续的好奇心：愿意聊某个技术、某个兴趣时会「眼睛发光」</li></ul><p>一旦招到这样的人，不需要做什么管理，更多的是<strong>别把他们的热情消耗在无意义的流程上</strong>。</p><h5>2. 用最轻量的方式对齐方向</h5><ul><li>状态更新尽量异步完成：文字周报、短更新，而不是天天站会</li><li>对需求和优先级，用几篇共享文档就够了，没必要一上来就搭一整套系统</li><li>把「为什么做这件事」讲得非常清楚，比「怎么做、按什么节奏做」重要得多</li></ul><p>当方向清晰、上下文透明时，优秀工程师自然会自己填补细节。</p><h5>3. 保护工程师的注意力，而不是占用</h5><ul><li>钉钉、飞书是刚需，但要警惕演变成「注意力黑洞」</li><li>少 @ 全员、少搞临时化同步会议，多用异步文档和评论</li><li>鼓励大块、不被打断的深度工作时间，而不是随时在线的「响应速度」</li></ul><p>真正的「高效」，往往体现在<strong>有多少时间被保护下来，而不是被填满</strong>。</p><h5>4. 让一对一和反馈「有事可谈」</h5><ul><li>不做为了「保持关系」而开、却没有明确议题的例行 1:1</li><li>更鼓励基于具体问题、具体项目的临时对话</li><li>当有人真的有卡点、困惑或情绪时，再打开深入的沟通空间</li></ul><p>这类关系，是在一起解决问题的过程中自然生长出来的，而不是靠日历上固定的时间段培养出来的。</p><p><strong>可执行建议：</strong> 让「时间块」成为支撑深度工作的精简模块，而不是塞满整周日历的主角。</p><hr/><h2>四、清单：给早期产品/技术管理者的对照表</h2><p>如果你正在带一个 5–20 人的工程团队，可以用这份清单自查：</p><pre><code>[ ] 最近一个月花在招人和面试上的时间，是否明显多于花在设计新管理流程上的时间？  
[ ] 是否在试图用流程和制度，去「拯救」一个本就不合适的招聘决策？  
[ ] 团队大部分状态更新，是否可以通过异步文档就能完成？  
[ ] 团队会议是否都有清晰议程和产出，而不是为了「看起来在管理」？  
[ ] 工程师是否能直接接触完整的业务上下文（用户反馈、营收数据、产品决策），而不是只拿到被筛选过的片段信息？  
[ ] 你是否依然亲自参与关键的产品和技术决策，而不是过早把这些权力和判断交给「管理层」？  
[ ] 当你觉得「需要更多管理」时，是否先问过自己：是不是该先多去几次用户访谈？
</code></pre><p><strong>可执行建议：</strong> 每季度用这份清单做一次复盘，把那些「想不到不做也没关系」的管理动作，都列入精简候选。</p><hr/><h2>五、总结：当你觉得需要「管理」，往往应该回到产品</h2><blockquote>在种子轮、A 轮阶段，如果你觉得自己有很严重的「工程管理问题」，九成的正确解法是暂时什么都不做，先去找用户、做产品、招对人。</blockquote><p>早期工程团队最重要的管理决策，往往只有三件：</p><ol><li><strong>招谁进来</strong> —— 是否真的自驱、好奇、愿意为问题多走一步</li><li><strong>给他们怎样的环境</strong> —— 信息是否透明、目标是否清晰、是否能安心做事</li><li><strong>在什么时刻引入管理</strong> —— 坚持「能用 Node + Postgres，就别造新数据库」式的朴素标准</li></ol><p>如果说传统管理在乎的是「把机器调得更顺」，</p><p>那早期管理更像是：<strong>守住几条简单的边界，让真正重要的工作自己长出来。</strong></p><p>当你下次忍不住想「多管一点」时，不妨先问自己：</p><blockquote>我现在做的这件事，真的会让我们更快找到产品/市场匹配吗？</blockquote><p>如果答案是否定的，那也许最好的管理动作，就是先按下暂停键。</p><hr/><blockquote>Hi，我是俞凡，一名兼具技术深度与管理视野的技术管理者。曾就职于 Motorola，现任职于 Mavenir，多年带领技术团队，聚焦后端架构与云原生，持续关注 AI 等前沿方向，也关注人的成长，笃信持续学习的力量。在这里，我会分享技术实践与思考。欢迎关注公众号「DeepNoMind」，星标不迷路。也欢迎访问独立站 <a href="https://link.segmentfault.com/?enc=TBLeAZZ8yeOPb8YJBKBRTQ%3D%3D.AxLKtffjeRemnEOODvwBrZo8iEwAFLjpeufr2HLSr1c%3D" rel="nofollow" title="www.DeepNoMind.com" target="_blank">www.DeepNoMind.com</a>，一起交流成长。</blockquote><p>本文由<a href="https://link.segmentfault.com/?enc=1NmTcqgYGB8%2BJjdZTBfAsg%3D%3D.NSkNguT2K3sJigS2JzSXhtM5q%2Bmk5UiHHaILr6R5kNE%3D" rel="nofollow" target="_blank">mdnice</a>多平台发布</p>]]></description></item><item>    <title><![CDATA[.so mmap计算工具内存翻倍现象 侑虎科技 ]]></title>    <link>https://segmentfault.com/a/1190000047555352</link>    <guid>https://segmentfault.com/a/1190000047555352</guid>    <pubDate>2026-01-21 12:06:37</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>1）.so mmap计算工具内存翻倍现象<br/>2）iOS报告中的Low Memory是如何被促发的</p><hr/><p>这是第461篇UWA技术知识分享的推送，精选了UWA社区的热门话题，涵盖了UWA问答、社区帖子等技术知识点，助力大家更全面地掌握和学习。</p><p>UWA社区主页：<a href="https://link.segmentfault.com/?enc=8b%2BdUhiL92AnWLj%2FUWmNRA%3D%3D.3EOz3RIgDf859MVEskKrvMfd4dcTATF1GTvjaDqAKSQ%3D" rel="nofollow" target="_blank">community.uwa4d.com</a><br/>UWA QQ群：793972859</p><p><strong>From 问答社区</strong></p><p><strong>Q：结合UWA DAY分享的.so mmap内存分析流程，我发现在我们项目中libil2cpp.so有个奇怪的现象，想要问问大家是否知道是怎么一回事：</strong><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555354" alt="" title=""/></p><p><strong>这里列出来libil2cpp.so占据了4段内存，其中第一段：770e779000-771c606000，和第二段开始到第四段结束地址（78bfac9000-78cd956000）的内存容量完全一致。而且，命令结果显示它们映射到的文件以及offset也都完全一致。我高度怀疑这两段内存的内容也是一致的，很有可能是两段虚拟内存映射到同一段物理内存。但是这个情况只有libil2cpp符合，libunity并不符合。包括我用后来我们打的包，执行同样命令，分析结果，还是符合这个现象。这是否意味着libil2cpp的内存占用实际上是上面统计值的一半？</strong></p><p><strong>补充一点：我用我们自己打的包，查看proc/pid/maps，结合readelf命令，发现后面三个段已经映射了所有libil2cpp中的LOAD段了。</strong></p><p><strong>附：包含文中提到的“.so mmap内存分析流程”的课程：</strong><br/><a href="https://link.segmentfault.com/?enc=jTxc5UXbGGdnii%2FENsbFtw%3D%3D.2qgRTYDsFTosucWx%2FAHdvea6yjWD%2BwSCyQoNoqOj8OClztIDBHimV3uy%2FayIu6vp" rel="nofollow" target="_blank">Unity移动游戏性能优化全解析与小游戏转化的实战经验</a></p><blockquote><p>A：试了几个不同的包，有的确实会出现第一段等于后面几段之和的情况：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555355" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555356" alt="" title="" loading="lazy"/></p><p>也有几段互不相同没有加和关系的情况。这两种包的运行时数据和拆包得到的so硬盘占用大小也都基本对得上：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555357" alt="" title="" loading="lazy"/></p><p>这是因为，UWA DAY PPT中用来计算内存的Python代码会粗暴地计算所有地址的插值并无脑求和，如下图：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555358" alt="" title="" loading="lazy"/></p><p>但在出现”第一段等于后面几段之和的情况”的包中，前两段的Offset都是偏移0，此时不能强行求和。可以考虑根据这种规律调整代码或人为重新算一下就对了：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555359" alt="" title="" loading="lazy"/></p></blockquote><p><strong>欢迎大家转至社区交流：</strong><br/><a href="https://link.segmentfault.com/?enc=ioAGQEVTxfsDd7acMkKKdQ%3D%3D.eog4G6rLJz2bjmZCk5qLmTUVMkjSP22u3D2EYRcxZoO3l80TWgJsV9lDsGNFSTwLJoLkMElym8kcwKESMPFuIw%3D%3D" rel="nofollow" target="_blank"/><a href="https://link.segmentfault.com/?enc=x5kjT%2FxF1oDJbG7eCamsiw%3D%3D.qt92CdS1Qxra0adEfnpu1xEr%2BXS2fnaXdJJ5qBpkYlarU618%2F787W7nXPGoVTtPbR3p%2FijMH03cGkT444g3KbA%3D%3D" rel="nofollow" target="_blank">https://answer.uwa4d.com/question/696ddb25244ce21ce9ec096f</a></p><hr/><p><strong>From UWA AI 问答</strong></p><p><strong>Q：iOS平台上[UIApplicationDelegate applicationDid ReceiveMemoryWarning]调用只在1.8GB左右频繁触发，内存更高以后反而触发率降低了，是什么原因？</strong></p><blockquote><p>A：该现象符合iOS内存管理机制的<strong>分层压力响应策略</strong>，根本原因在于：<strong>applicationDidReceiveMemoryWarning并非在内存使用达到绝对阈值时触发，而是由系统基于当前可用内存余量、后台进程竞争状态及设备实际内存压力动态判定的“相对性警告”</strong>。</p><p>具体解释如下：<br/><strong>1. 触发逻辑本质是“内存压力等级”，而非“绝对用量”</strong><br/>iOS不以固定内存值（如1.8GB）为硬触发点，而是通过vm_pressure_level监控全局内存压力。当系统检测到：</p><ul><li>可用内存页急剧减少（尤其活跃/非换页内存不足）；</li><li>后台App被大量驱逐释放内存；</li><li>文件缓存或压缩内存已达上限；<br/>  → 系统向前台应用发送applicationDidReceiveMemoryWarning，提示其主动降载。</li></ul><p><strong>2. 1.8GB 高频触发的典型场景</strong><br/>此区间常对应：</p><ul><li>应用已加载大部分资源（纹理、Mesh、Audio），但尚未触发Unity的Resources.UnloadUnusedAssets()或AssetBundle卸载；</li><li>原生堆（Native Heap）与托管堆（Mono Heap）持续增长，GLES驱动内存池（如MTL/OpenGL纹理缓存）接近饱和；</li><li>系统仍保留一定后台缓冲空间，此时压力信号敏感且频繁。</li></ul><p><strong>3. 更高内存（如&gt;2.2GB）后触发率下降的合理原因</strong><br/>⚠️ 并非系统“变宽松”，而是进入更危险阶段：</p><ul><li>系统已启动强制干预：终止后台App、压缩inactive pages、回收文件缓存；</li><li>若应用继续申请内存，<strong>不再发送警告，直接触发SIGKILL（OOM Killer）</strong>；</li><li>此时applicationDidReceiveMemoryWarning反而减少 —— 因系统已无“协商余地”，转向静默强杀。</li></ul><p><strong>验证与优化建议</strong></p><ul><li>使用Xcode Instruments → Activity Monitor查看Real Memory + Pressure Level曲线，确认是否伴随vm: pressure上升；</li><li><p>在OnLowMemory回调中立即执行：</p><ul><li>Resources.UnloadUnusedAssets() + Texture2D.DestroyImmediate()清理未引用纹理；</li><li>切换至低配资源（如ASTC 4x4替代8x8）；</li><li>持久化关键游戏状态（防被杀丢档）；</li></ul></li><li>限制峰值内存：通过UWA GOT Online的GPU/Resource/Mono报告，定位内存大户（如超大图集、未卸载AB、Mono GC堆膨胀）。</li></ul><p>该行为是 iOS 内存保护机制的正常表现，高频警告恰说明应用处于“可挽救临界区”，需优先优化资源生命周期管理。</p><p>可以参考以上AI回答。而且实际上看起来这个警告只在1.8GB左右触发，也即内存更高时反而不触发的原因。</p></blockquote><p><strong>分享链接：</strong><br/><a href="https://link.segmentfault.com/?enc=PSj45Bog1nfT7YB%2FxbcxGg%3D%3D.mFM3ixbRdlI4IDlebzG5jGHN%2Ft5K93iH4hWO9ccCS8Dym9j6A95%2FwuJ3s5MQUywjJxngCMYD1QF388AL0A8kTseJ7l7iG6Gw9eR5N8loKvDubbNmPk%2F%2BmzI%2FRwjtThhC" rel="nofollow" target="_blank"/><a href="https://link.segmentfault.com/?enc=xKtyJdt8LO9nHFJYy%2BdO1g%3D%3D.cFto%2FT6BrpnC95D4diNSDnbwW5ebmtYQGSlIjQU9%2FXMBkh4t92DBeNeMthC364FyrUDQfd0GLnyp5IlYGfwi%2FqBG%2BMs%2F0u6TQ52I1XSStkb3kawakz0jXBKl1O6G%2FmLV" rel="nofollow" target="_blank">https://www.uwa4d.com/main/uwa-shared.html?shareId=bfb1e3df-0...</a></p><p><strong>无论是社区里开发者们的互助讨论，还是AI基于知识沉淀的快速反馈，核心都是为了让每一个技术难题都有解、每一次踩坑都有回响。本期分享分别来自UWA AI问答和UWA问答社区，希望这些从真实开发场景中提炼的经验，能直接帮你解决当下的技术卡点，也让你在遇到同类问题时，能更高效地找到破局方向。</strong></p><p>封面图来源于网络</p><hr/><p>今天的分享就到这里。生有涯而知无涯，在漫漫的开发周期中，我们遇到的问题只是冰山一角，UWA社区愿伴你同行，一起探索分享。欢迎更多的开发者加入UWA社区。</p><p>UWA官网：<a href="https://link.segmentfault.com/?enc=5M%2BPc%2B8uRgKW%2Fzum0LEc8w%3D%3D.CMxWZPVbc4CHkvzuj%2BovPtyh2oZrp9BNKCmwKupwEg4%3D" rel="nofollow" target="_blank">www.uwa4d.com</a><br/>UWA社区：<a href="https://link.segmentfault.com/?enc=znSvYMSpDfH9JMkpPnltRA%3D%3D.vmhdpmf4zHUKQE66c4vWKHO8rbKymU%2BaUmJgN8X3VPk%3D" rel="nofollow" target="_blank">community.uwa4d.com</a><br/>UWA学堂：<a href="https://link.segmentfault.com/?enc=lptg0kSFfoW%2Bz0Aak2UUQg%3D%3D.S93r4t2ympAVK9a5PZLez%2FQLkyhiWjucLTK4P0YDKLM%3D" rel="nofollow" target="_blank">edu.uwa4d.com</a><br/>官方技术QQ群：793972859</p>]]></description></item><item>    <title><![CDATA[超全测评：最新入门级专业显卡 NVIDIA RTX PRO™ 2000 Blackwell 性能如何]]></title>    <link>https://segmentfault.com/a/1190000047555372</link>    <guid>https://segmentfault.com/a/1190000047555372</guid>    <pubDate>2026-01-21 12:05:37</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><a href="https://www.bilibili.com/video/BV1QLkTBCEEk/?aid=115903282814270&amp;cid=35417033272" target="_blank">https://www.bilibili.com/video/BV1QLkTBCEEk/?aid=115903282814...</a></p><p>NVIDIA RTX PRO™ 2000 Blackwell 是节能高效、外形小巧的解决方案，能够加速专业的图形和 AI 工作负载。采用突破性的 Blackwell 架构 和 16 GB 超高速 GDDR7 显存，那么对比上一代 NVIDIA RTX™ 2000 Ada 具体性能有哪些提升？本文将从核心参数、跑分测试、渲染性能以及主流工业设计软件表现多个维度，进行一次全面的对比分析，供大家参考。</p><p>1.参数对比<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555375" alt="图片" title="图片"/></p><p>2.测试数据测试环境<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555376" alt="图片" title="图片" loading="lazy"/></p><p>测试内容<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555377" alt="图片" title="图片" loading="lazy"/></p><p>图形性能</p><p>1、SPECviewperf 2020 v3.0</p><p>SPECviewperf是一个专业级、符合工业标准的OpenGL图形显卡效能测试分析软件，使用C语言编写，用于测量运行在OpenGL应用程序接口之下硬件的3D图形性能。其中包含了 3ds max、catia、creo、energy、maya、medical、snx、solidworks 共8款软件的性能测试。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555378" alt="图片" title="图片" loading="lazy"/><br/>从测试结果来看：RTX PRO 2000 相较 RTX 2000 Ada 综合提升约 37％。</p><p>2、3D Mark</p><p>3DMark是一个由UL开发的智能设备性能评测软件，可用于评测设备的3D图形渲染能力。我们主要测试了 Port Royal 和 Speed Way 两个场景。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555379" alt="图片" title="图片" loading="lazy"/></p><p>在 Port Royal 场景中，RTX PRO 2000 相较 RTX 2000 Ada 提升约 56％；在 Speed Way 场景中，RTX PRO 2000 相较 RTX 2000 Ada 提升约 45％；</p><p>3、V-Ray Benchmark 6.00.01</p><p>V-Ray Benchmark 是一款免费的独立渲染速度测试软件，用于测试计算机的渲染速度。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555380" alt="图片" title="图片" loading="lazy"/></p><p>RTX PRO 2000 相较 RTX 2000 Ada 提升约 63％。4、OctaneBenchOctaneBench 是一种专有基准测试工具（也是当今最流行的GPU渲染基准测试），用于测量以每小时OctaneBench 点数（OBh）表示的GPU渲染速度，用于标准化和基准测试GPU性能。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555381" alt="图片" title="图片" loading="lazy"/><br/>RTX PRO 2000 相较 RTX 2000 Ada 提升约 52％。</p><p>渲染性能</p><p>1、Blender<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555382" alt="图片" title="图片" loading="lazy"/><br/>RTX PRO 2000 相较 RTX 2000 Ada 提升约 35％。</p><p>2、Houdini<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555383" alt="图片" title="图片" loading="lazy"/><br/>RTX PRO 2000 相较 RTX 2000 Ada 提升约 120％。</p><p>3、Maya<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555384" alt="图片" title="图片" loading="lazy"/><br/>RTX PRO 2000 相较 RTX 2000 Ada 提升约 34％。</p><p>4、UE5<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555385" alt="图片" title="图片" loading="lazy"/><br/>RTX PRO 2000 相较 RTX 2000 Ada 提升约 20％。</p><p>5、NVIDIA Omniverse™<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555386" alt="图片" title="图片" loading="lazy"/><br/>RTX PRO 2000 相较 RTX 2000 Ada 提升约 96％。</p><p>AI 性能</p><p>1、Stable Diffusion<br/>测试项目：FLUX 文生图<br/>生成尺寸：1024*1280<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555387" alt="图片" title="图片" loading="lazy"/><br/>RTX PRO 2000 相较 RTX 2000 Ada 提升约 35％。</p><p>2、ComfyUI<br/>测试项目：FLUX 文生图<br/>生成尺寸：1280*720<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555388" alt="图片" title="图片" loading="lazy"/><br/>RTX PRO 2000 相较 RTX 2000 Ada 提升约 46％。</p><p>测试项目：Hunyuan3D 模型生成<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555389" alt="图片" title="图片" loading="lazy"/><br/>RTX PRO 2000 相较 RTX 2000 Ada 提升约 30％。测试项目：Wan2.2 图生视频<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555390" alt="图片" title="图片" loading="lazy"/><br/>RTX PRO 2000 相较 RTX 2000 Ada 提升约 59％。</p><p>工业软件性能</p><p>为确保评测结果的可量化与可比性，本次测试明确以下核心指标：</p><ul><li>模型载入速度：从启动软件、选择目标模型到完全加载就绪的总耗时，单位为 “秒”，数值越小表现越优；</li><li>实时操作流畅度：模型编辑、三维旋转 / 平移 / 缩放时的画面流畅度，按照反应速度设定为“卡顿”、“流畅”和 “非常流畅”。</li><li>工程图生成效率：针对含复杂标注、剖切视图、明细表的工程图，从发起生成指令到完整渲染显示的耗时，单位为 “秒”，数值越小效率越高；</li><li>渲染性能：指定输出分辨率与渲染质量（高保真模式），完成单帧渲染的总耗时，单位为 “分钟”，数值越小渲染速度越快；</li><li>仿真稳定性：针对大型模型开展长时间连续仿真，记录无崩溃、无掉帧、无卡顿的持续运行时长，同时监测显卡温度、功耗变化，评估长期负载下的稳定性。</li></ul><p>1、UG NX 应用测试</p><p>UG NX 作为面向高端制造的三维设计软件，在复杂装配体设计、多物理场仿真等场景中应用广泛，本次选取五类模型，从简单到复杂覆盖不同负载需求，详细测试内容见下表：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555391" alt="图片" title="图片" loading="lazy"/><br/>测试结果：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555392" alt="图片" title="图片" loading="lazy"/><br/>在中小模型场景测试中，两款显卡均能很好地满足设计需求，RTX PRO 2000 和 RTX 2000 Ada在载入速度与操作流畅度方面差异较，性能差异在10%以内，RTX PRO 2000 略占优。</p><p>2、Solidworks 性能测试</p><p>Solidworks 以易用性与兼容性著称，广泛应用于通用机械、模具设计等领域，本次测试选取两款模型，贴合不同用户的实际应用场景。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555393" alt="图片" title="图片" loading="lazy"/><br/>测试结果：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555394" alt="图片" title="图片" loading="lazy"/><br/>在中小模型场景中，两张显卡均表现出色，编辑、旋转、缩放等操作非常流畅，RTX PRO 2000 和 RTX 2000 Ada 性能差距较小，在高保真渲染操作中，RTX PRO 2000 比 RTX 2000 Ada 要快8秒，且整个过程流畅、无报错或卡顿现象。</p><p>申请显卡测试<a href="https://link.segmentfault.com/?enc=2gF0hu%2FBMP%2FDX%2BTY1jQV7A%3D%3D.SVuXYs3FYZxUUg1UkuqlaFJR1Ed9gaRYMrgFdKFwLYKqIEVe3WsxOY6CIa2Ktf4ehIUXuuTy4AeXdu%2BL1NK%2BSjv529KsJIpURYWPiicRWF6Njr239tv%2FqgbLSFESI2p1JWYSCZs6rXWOFNvdFYb60MFNJ7HfnXdCzgEh9HYZ0fE%3D" rel="nofollow" target="_blank">https://my.feishu.cn/share/base/form/shrcnEmbNj6oRKsQ58SNldkb...</a><br/>*与 NVIDIA 产品相关的图片或视频（完整或部分）的版权均归 NVIDIA Corporation 所有。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555395" alt="图片" title="图片" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[基于隐语+通信场景生产实践，如何实现可监管、可审计的多方数据协作？ 隐语SecretFlow ]]></title>    <link>https://segmentfault.com/a/1190000047555401</link>    <guid>https://segmentfault.com/a/1190000047555401</guid>    <pubDate>2026-01-21 12:05:07</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>作者：中国联通软件研究院 · 计费结算中心 张兴宇</p><p>整理排版：蚂蚁密算 曾辉</p><blockquote>本文整理自隐语第三届嘉年华现场演讲，中国联通软件研究院基于隐语，从最初的对账试点出发，打造了一套可复制、可监管的跨域协作体系。详细介绍了对等组网、数据分级计算、规则上链存证等工程实现细节，并总结了实际推进中最难解决的部分：不是技术，而是多方协作。最终，这不仅是一套系统架构，更是一种行业共建的新模式。</blockquote><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555403" alt="" title=""/></p><h2>行业技术背景</h2><p>在数据要素流通全面提速的背景下，我们在一线工程实践中越来越清晰地感受到：<strong>数据安全已经不再只是“合规约束”，而正在直接决定业务是否还能继续发展。</strong></p><p>过去很多跨域协作的方式，本质上是把“数据怎么拿到一起”作为默认前提：先汇聚、再计算、最后补合规。但随着监管要求、数据安全责任、以及跨主体协作复杂度同步提升，这条路径越来越难走——尤其是在通信行业这种数据粒度细、规模大、敏感字段多、跨主体协作频繁的场景里。</p><p>因此，“原始数据不出域、可用不可见”并不是一个愿景口号，而是在通信行业中，被真实业务一步步推到了工程实现与生产落地阶段。更重要的是，它不是“加一层安全能力”这么简单，而是在重新定义协作方式：从“拿到数据再处理”，转向“在不拿到数据的前提下完成协作”。</p><p>从宏观层面看，这一变化并非偶然，而是由多重因素共同驱动：</p><ul><li>国际层面：隐私保护被视为基础性权利，跨域数据流通不再允许“事后补救”。企业必须具备可验证、可审计、可追溯的工程能力，能够说明“数据如何被使用、结果如何产生、责任如何界定”。</li><li>国家层面：可信数据空间建设持续推进，强调在安全前提下释放数据价值，对“安全可用”提出工程级、规模化的要求——不仅要能跑通，还要能稳定运行、可推广复制、可持续运营。</li><li>公众层面：数据泄露事件频发，公众关注点从“合不合规”转向“是不是真的可控”。对企业提出更刚性的可信技术需求：不仅要遵循规则，更要让规则可验证。</li></ul><p>当这些因素叠加到通信行业，问题被进一步放大：亿级数据规模 + 跨域协作刚需 + 合规红线不可突破，使得传统集中式技术路径开始系统性失效。</p><h2>行业技术痛点</h2><p>在通信行业，跨运营商协作并不是“要不要做”的问题，而是长期存在、无法回避的业务事实。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555404" alt="" title="" loading="lazy"/></p><p>例如网间详单级对账、跨域核验与监管支撑，本质上都依赖多方数据协同完成。它们的共同点是：<br/>协作主体多、协作频次高、规则变化快、且必须在规定窗口内完成闭环。</p><p>但现实约束同样非常清晰，而且是工程层面的硬约束：</p><ul><li>规模苛刻：数据规模达到亿级甚至数十亿级，且粒度为详单级——不是汇总报表，而是逐条核验、逐条比对；</li><li>敏感性极高：数据包含用户标识、话单明细、财务相关字段等敏感信息，无法集中、无法明文外传；</li><li>协作环境复杂：跨组织、跨省、跨网络协同，参与方系统异构、治理边界不同，协作很难靠人工“对齐”。</li></ul><p>这直接导致一个结果：大量在实验室或PoC阶段“跑得通”的技术路线，在运营级业务中根本撑不住。</p><p>能“算出来”只是起点，真正的门槛是能否长期稳定地跑、能否支撑规则变化、能否可运维、可审计、可回溯、可复制。</p><h2>技术选型</h2><p>正因为如此，我们在技术选型阶段，并没有把问题定义为“用不用隐私计算”，而是明确了一条更严格的原则：不是“能不能用”，而是“能不能长期跑在运营级业务中”。</p><p>这里的“运营级”，意味着它必须同时满足一组工程特征： 稳定性（可长期运行）、时效性（窗口内闭环）、可运维（可定位可回溯）、可扩展（规模上得去）、可治理（规则可控可审计）。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555405" alt="" title="" loading="lazy"/></p><p>围绕这一目标，我们从工程视角对主流技术路线进行了系统评估，核心维度包括：</p><ul><li>合规可行性是否真实可控：能否做到原始数据不出域、最小暴露、边界清晰；</li><li>工程成熟度是否支撑长期运行**：是否具备任务编排、失败恢复、运行监控等工程化能力；</li><li>在亿级数据规模下的扩展性与性能边界：是否存在可持续的调优路径；</li><li>对规则型、批量型业务的适配能力：是否能表达“规则驱动的查询/比对”，并支持快速迭代；</li><li>技术与生态是否具备可持续演进能力：组件、文档、社区活跃度、可维护性与可扩展性。</li></ul><p>在详单级、亿级规模的密态对账场景中，我们最终选择了<strong>隐语SecretFlow</strong>，原因是它在真实业务约束下，在工程可演进性与场景贴合度上更接近可持续落地路径——尤其适配规则型密态计算与结构化数据协作的工程需求。</p><h3>项目演进里程碑</h3><p>回顾整个建设过程，这并不是一蹴而就的体系设计，而是一条伴随业务演进不断调整的工程路径：</p><ul><li><strong>2020 年</strong>：从运营商之间的报表级对账起步，引入区块链实现可信交付，解决“过程可信、结果可追溯”的基础问题；</li><li><strong>2023 年初</strong>：详单级对账需求出现，传统集中式方案在合规层面全面受限，开始引入SecretFlow，探索“原始数据不出域”的可行路径；</li><li><strong>2023 年中</strong>：基于SecretFlow构建可信数据空间下的密态数据交互平台，将密态协作从概念推进到工程实现；</li><li><strong>2024 年</strong>：完成与运营商的跨空间组网，在广东、江苏、宁夏等省完成试点部署，逐步形成可运行、可运维、可持续的生产闭环；</li><li><strong>当前阶段</strong>：从单场景试点演进为系统化能力输出，联合多方构建协同生态网络。</li></ul><p>这条路径背后的关键词只有一个：即从小场景、可验证边界切入，用标准和规则把复杂度压缩到可控范围内，再逐步扩大规模与覆盖范围。</p><h2>平台总体架构</h2><p>在这个过程中，我们并没有一开始就设计一个宏大的“总体架构”。<br/>相反，所有能力都是在真实业务中不断试错、修正、打磨后沉淀下来的。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555406" alt="" title="" loading="lazy"/></p><p>随着场景逐步稳定，一套可以被复用和推广的方法体系逐渐清晰，也就是现在对外呈现的 <strong>中国联通“113N”可信数据空间体系蓝图</strong>。</p><p>这套体系的出发点不是“平台建设”，而是可信协作如何真正落地：</p><ul><li>一套统一的空间标准：用于解决跨主体协作的共识问题，让参与方在身份、标识、规则、接口、审计等方面形成统一约束；</li><li>一批关键技术攻关：面向隐私计算、安全审计、跨域协同等核心能力，确保不仅能跑通，也能跑稳、跑久；</li><li>三项建设内容：围绕空间能力建设、基础设施对接与治理运营体系，形成稳定可控的建设框架；</li><li>最终支撑N个持续演进的业务场景：让新场景不再从零开始，而是基于标准与组件复用扩展。</li></ul><p>目标并不只是“搭一个系统”，而是通过真实场景把工程能力跑顺、把规则跑稳，形成<strong>可复制、可持续的协作模式</strong>。</p><h2>空间治理架构</h2><p>随着实践深入，我们逐渐意识到一个关键问题：可信协作不是一个系统能力，而是一种结构性能力。</p><p>如果把可信协作只落在单一系统里，短期看似集中统一，但一旦参与方变多、场景变多、规则变多，就会面临治理边界不清、责任难划分、扩展成本高的问题。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555407" alt="" title="" loading="lazy"/></p><p>因此，在工程实现中，我们没有将所有能力集中到单一平台，而是将协作拆解到不同层次、不同类型的可信数据空间中：</p><ul><li>通过统一的身份、标识与治理规则，先解决“谁能参与、如何建立信任”的基础问题；</li><li>再让行业空间、城市空间、企业空间围绕真实业务场景各自运行和演进；</li><li>在统一规则下实现跨空间连接与协同，随着参与主体与场景增加逐步生长为协作网络。</li></ul><p>这种方式的好处在于：参与方无需大规模改造现有系统、无需暴露原始数据，就可以在统一规则下持续协作，同时治理边界更清晰、扩展更自然。</p><h2>技术架构</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555408" alt="" title="" loading="lazy"/></p><p>在技术架构层面，我们始终坚持三条不可妥协的原则：</p><ul><li>原始数据不出域：原始数据始终在本域，跨域只发生必要的密态交互；</li><li>按需计算：并非所有数据都走同一种计算模式，而是根据敏感等级与业务目标选择最合适的协作方式；</li><li>结果可验证：不仅给出结果，还要让结果“可解释、可审计、可追溯”。</li></ul><p>以隐语SecretFlow为核心，结合Kuscia等组件，支撑跨域联合作业、精密分析与账单核算。这不是“为了用隐私计算而用隐私计算”，而是业务约束下的工程选择。</p><h3>技术方案——跨运营商详单级对账</h3><p>从工程视角看，跨运营商对账的核心，是将传统集中式对账流程，拆解为一条可以在密态环境下长期稳定运行的计算流水线。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555409" alt="" title="" loading="lazy"/></p><p>整体思路是：各参与方仍然在本地结算系统中生成详单数据，在进入计算前完成字段标准化与规则映射，确保计算语义一致；进入隐私计算阶段后，原始数据不出域，通过SecretFlow承载的密态计算能力执行规则驱动的对账逻辑。</p><p>关键工程特性包括：</p><ul><li>规则可配置、可拆分：对账规则不是写死的脚本，而是可配置规则集合，能够支持逐条与批量、并行执行；</li><li>过程可中断、可回溯、可复跑：面对十亿级数据，必须具备断点续跑、失败恢复、分段复核能力；</li><li>输出最小化：只输出差异结果与必要校验信息，避免“结果汇聚导致二次泄露”；</li><li>关键过程与摘要结果链上存证：解决结果可信与审计追溯问题，使协作具备可验证闭环。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555410" alt="" title="" loading="lazy"/></p><p>这不是算法展示型方案，而是围绕高并发、规则复杂、长期运行场景做过充分工程约束的生产级实现。</p><p>在工程设计上，我们将跨运营商对账定义为<strong>双向对等、可验证的协同执行过程</strong>，而不是单向“算完给结果”。</p><p>发起方与审核方各自在本地运行隐私计算节点，执行同一套对账规则。系统输出可校验的对账报告与差异摘要，并通过链上机制固化关键结果，确保任何一方都无法事后篡改关键结论。</p><p>如存在差异，可在密态下进行定位、复核与调整，而不是重新全量重跑。<br/>最终形成原始数据不出域、结果可验证、过程可追溯的对账闭环，也使其能够在运营级场景中长期稳定运行。</p><h3>关键技术能力——面向不同数据敏感等级的跨域协作实现方式</h3><p>针对不同敏感等级的数据，我们采用分级协作策略：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555411" alt="" title="" loading="lazy"/></p><ul><li>高敏数据（详单、用户资料、财务相关字段）：采用多方安全计算、联邦学习等隐私计算技术，在原始数据不出域前提下完成联合计算与分析；</li><li>中低敏数据（可脱敏或业务中台数据）：采用沙箱运行环境，在确保安全的同时提升效率；</li><li>规则与结果类数据：敏感性相对较低，但对不可篡改性要求高，采用智能合约方式进行上链存证，确保可追溯、可审计。</li></ul><h2>生产部署架构与跨域互联方式</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555412" alt="" title="" loading="lazy"/></p><p>各运营商在本地可信数据空间内部署隐私计算节点，跨域协作通过专线网络和统一安全接入区完成。</p><p>工程上强调“最小暴露面”： 系统仅开放标准协议接口（如gRPC、HTTPS），确保原始数据与计算逻辑始终不出域，同时满足合规要求、运行稳定性与可运维性。</p><h3>业务成效与行业意义</h3><p>在业务层面，对账与结算效率发生质变：对账周期从周级、月级压缩至天级，自动化覆盖接近全量，异常更早暴露、更快定位。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555413" alt="" title="" loading="lazy"/></p><p>在人力与成本层面，大量依赖人工核对、反复沟通的工作被规则化、系统化协作替代，人力投入明显下降，长期成本持续可控，同时资金周转效率同步提升。</p><p>更重要的是，这套能力不再局限于单点场景：推动行业从“点对点对账”走向可复制、可推广的数据协同模式，为后续联合分析、联合运营与生态协同打开空间。</p><h2>构建标准体系</h2><p>实践中我们深刻体会到：技术不是最大难点，真正的难点在于跨主体长期协作。</p><p>因此，我们优先建设可信数据空间的规则底座，通过统一规范，将隐私计算能力固化为可复用、可审计、可监管的协作方式，服务于长期运营。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555414" alt="" title="" loading="lazy"/></p><p>换句话说，我们要解决的不是“某一次对账能跑通”，而是让协作成为一种长期可运行的机制：规则怎么变、版本怎么管、争议怎么裁、审计怎么做、责任怎么划分，都需要在工程体系内被吸收。</p><h2>实践方法论</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555415" alt="" title="" loading="lazy"/></p><p>总结来看，我们走出了一条可持续落地路径：</p><ul><li>场景共识先行：先把“为什么协作、协作边界在哪、各方收益是什么”讲清楚；</li><li>标准驱动试点：用统一规则把复杂问题拆成可验证的小场景，小步快跑；</li><li>政策与规则同步：在成熟场景中同步沉淀治理与运营机制，确保长期可跑；</li><li>经验沉淀与复用：把成功案例转化为模板、标准与组件，让新场景不再从零开始。</li></ul><p>可以概括为：从共识开始，用标准落地，靠规则运行，以经验放大。</p><p>我们更愿意将这些成果视为一次<strong>行业与社区协同探索的阶段性结果</strong>，而不是某一个系统建设的终点。</p><p>在整个实践过程中，隐语（SecretFlow）对我们来说不仅是一个“能跑算法的框架”，更像是一套能够承载真实业务约束、支撑工程演进的技术底座：它让隐私计算从“概念可行”走向“工程可用”，也让我们能够在高敏感、高规模、高稳定性要求的生产环境中把协作真正跑起来。</p><p>与此同时，真实生产场景也天然会暴露出大量“只有落地才会遇到”的问题：比如规则型计算在密态下如何组织与复用、亿级规模下的任务拆分与并行策略、失败恢复与回溯机制如何设计、跨主体协作的审计与存证如何做到既可信又可运营……这些问题无法靠单次PoC解决，只能在持续运行中逐步打磨。</p><p>因此，我们更愿意把“社区共建”理解为一种双向循环：</p><ul><li>一方面，依托隐语社区的能力和工程框架，加速我们在通信行业复杂场景中的落地效率；</li><li>另一方面，通过跨运营商对账这一高约束场景，把工程实践中遇到的瓶颈与经验持续沉淀为可复用的方法，推动可信协作能力持续演进。</li></ul><h2>结语</h2><p>我们相信，可信协作的成熟并不是靠某一次“选型成功”完成的，而是在真实生产场景中一步一步验证：  什么是可执行、可运维、可持续的工程能力；什么样的规则体系能够长期运行；什么样的协作模式能够被复制推广。</p><p>面向未来，我们期待与更多行业伙伴和社区开发者一起，把生产实践中沉淀出的经验转化为社区可复用的能力：让更多参与方能够在统一的可信协作框架下参与协作、持续演进，并最终让“数据可用不可见”的理念真正走向——<strong>好用、常用、可复制、可持续。</strong></p>]]></description></item><item>    <title><![CDATA[艾体宝方案 | Redis Caching 专题应用解决方案 艾体宝IT ]]></title>    <link>https://segmentfault.com/a/1190000047555431</link>    <guid>https://segmentfault.com/a/1190000047555431</guid>    <pubDate>2026-01-21 12:04:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>Redis 已超越“单纯内存 KV 缓存”的角色，成为企业级、可扩展的高速缓存与实时数据平台。通过多种缓存模式（cache-aside、read/write-through、write-behind、prefetch 等）、企业级特性（Active-Active/CRDT、Redis on Flash、持久化与 SLA）、以及模块化生态（RedisGears、RediSearch、RedisJSON、RedisBloom 等），Redis 能在低延迟（sub-millisecond）同时支撑大规模流量与复杂一致性需求，是现代“systems of engagement”架构中的核心组件。</p><p><strong>为什么需要企业级缓存</strong><br/>现代应用趋向“系统参与”（systems of engagement），对实时性、可伸缩性与高可用性的要求远高于传统系统；缓存把慢速系统（磁盘、传统 RDB）常用数据“移到近端”，以实现亚毫秒响应。对于企业级应用，单纯开源 Redis + 自研运维往往难以满足跨地域高可用、数据持久化、成本可控（大数据集内存成本）等需求；Redis Enterprise 提供扩展（线性扩容）、99.999% SLA、以及分层存储（RAM + Flash）以降低成本。<br/><strong>核心缓存模式（Patterns）</strong><br/><strong>Cache-aside</strong><br/>应用先查缓存（Redis），若 miss 则去后端读取并回写缓存。适用于读多写少、可容忍偶发缓存不一致的场景（例如商品详情、配置、用户画像片段）。实现简单、延展性好，但一致性由应用负责。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555434" alt="图片" title="图片"/><br/>伪代码</p><pre><code>val = redis.get(key)if not val:
    val = db.read(key)
    redis.set(key, val, ex=ttl)return val</code></pre><p><strong>Read/Write-Through 与 Write-Behind（Inline / 背写）</strong><br/>Write-through：写操作同步经缓存到后端数据库（保证一致性，但写时延增加）。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555435" alt="图片" title="图片" loading="lazy"/><br/>Write-behind（Write-back）：写先写缓存，然后后台异步落库以提升写性能，但存在短期不一致/丢失风险，需可靠的异步机制与重试策略（例如使用 Redis Streams + 后台 worker）。RedisGears/rgsync 提供了可用的 write-behind / write-through recipe，方便把 Redis 中的变化可靠写入关系型数据库。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555436" alt="图片" title="图片" loading="lazy"/><br/>Query Caching（SQL/查询结果缓存）对重复执行的 SQL 或昂贵查询缓存完整结果集或经过序列化的结果（注意分页、权限、排序等变化）。适合“相同查询多次”场景，常配合 cache-aside。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555437" alt="图片" title="图片" loading="lazy"/><br/>Prefetch / Cache Warming（主动预热）对于“读多写少”的仪表盘、前端账户总览等场景，建议把热点数据按策略提前写入缓存（比如定时任务、事件驱动同步），以避免冷启动或突发流量造成后端压力。移动银行示例中常用此策略把账户总览、余额等读多数据预先放入 Redis。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555438" alt="图片" title="图片" loading="lazy"/><br/><strong>典型用例实践</strong><br/><strong>金融行业缓存应用</strong><br/>在金融行业，特别是银行系统中，Redis缓存已成为支撑高并发业务的核心组件。江苏省联社在新一代移动金融综合服务平台中，使用Redis中间件进行热点数据缓存，显著降低了数据库访问压力，提升了应用吞吐量。该平台整合了个人手机银行、企业手机银行和各类生活服务应用，通过Redis缓存支撑了转账汇款、贷款理财、生活缴费等高并发业务场景。<br/>中原银行则基于Redis构建了分布式缓存平台，创新性地实现了多租户机制，允许多个微服务系统使用同一套Redis集群而数据互不影响。这种设计既节省了服务器资源，又简化了集群管理。此外，中原银行还基于Redis实现了分布式锁功能，支持自动续约机制，避免了因业务执行时间过长引发的锁冲突问题。<br/><strong>分布式会话管理</strong><br/>在分布式系统架构中，Redis提供了可靠的分布式会话管理能力。通过将会话数据存储在Redis集群中，不同应用实例可以共享用户状态，实现真正的无状态应用架构。实践中，通常会自定义SessionManager，支持通过HTTP头部token传递sessionId，实现前后端分离架构下的会话管理：</p><pre><code>public class ShiroSessionManager extends DefaultWebSessionManager {
    public final static String HEADER_TOKEN_NAME = "token";
    
    @Override
    protected Serializable getSessionId(ServletRequest request, ServletResponse response) {
        // 从Header中获取sessionId
        String id = WebUtils.toHttp(request).getHeader(HEADER_TOKEN_NAME);
        if (!StringUtils.isEmpty(id)) {
            request.setAttribute(ShiroHttpServletRequest.REFERENCED_SESSION_ID, id);
            request.setAttribute(ShiroHttpServletRequest.REFERENCED_SESSION_ID_IS_VALID, Boolean.TRUE);
            return id;
        }
        return super.getSessionId(request, response);
    }
}</code></pre><p><strong>小结</strong><br/>Redis作为一种多功能的内存数据存储，在现代应用架构中提供了多样化的缓存解决方案。从基础的全页面缓存到复杂的延迟消息队列，从简单的会话存储到企业级的分布式缓存平台，Redis展现了其卓越的性能和灵活性。<br/>通过合理的架构设计、监控管理和优化策略，Redis缓存能够显著提升应用性能，降低后端数据库压力，为高并发、低延迟的业务场景提供有力支撑。随着云原生和微服务架构的普及，Redis在缓存领域的重要性将进一步提升，成为构建高性能应用不可或缺的基础组件。</p>]]></description></item><item>    <title><![CDATA[SonarQube Server 2025.6.1.117629 - 代码质量、安全与静态分析工具 ]]></title>    <link>https://segmentfault.com/a/1190000047555444</link>    <guid>https://segmentfault.com/a/1190000047555444</guid>    <pubDate>2026-01-21 12:03:53</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>SonarQube Server 2025.6.1.117629 - 代码质量、安全与静态分析工具</p><p>SonarQube Server 2025 Release 6 (macOS, Linux, Windows) - 代码质量、安全与静态分析工具</p><p>Self-managed static analysis tool for continuous codebase inspection</p><p>请访问原文链接：<a href="https://link.segmentfault.com/?enc=YcraXyM15swk6Y9cU0yg2A%3D%3D.ZiPGVWRK2Ut7Bmw28eDC12uMz7wfI1YcLW2U0khPYS9o5urX0K7UBxrlJ8Nd%2Fhnq" rel="nofollow" target="_blank">https://sysin.org/blog/sonarqube/</a> 查看最新版。原创作品，转载请保留出处。</p><p>作者主页：<a href="https://link.segmentfault.com/?enc=kq5zgByro2%2BCzcYQh0PUiA%3D%3D.9n8BfUrVeooLS1efgWRuPF%2FvSZKcjePKk2hij9tFT%2Fw%3D" rel="nofollow" target="_blank">sysin.org</a></p><hr/><p>SonarQube Server</p><p>代码质量和安全性由您掌控</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000046060495" alt="SonarQube Server" title="SonarQube Server"/><br/> <em>之前称为 SonarQube，本地部署的用于持续代码库检查的静态分析工具</em></p><p>保持 AI 生成的代码干净</p><p>释放 AI 编码助手的强大功能，而无需承担不良、不安全代码的风险。SonarQube Server 是您的干净代码解决方案，可以部署在任何地方、本地或云环境中。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000046060496" alt="SonarQube Server" title="SonarQube Server" loading="lazy"/></p><p>受到 700 万开发者和 400,000 多个组织的使用和喜爱</p><h2>提高代码质量的代码质量工具</h2><p>您的代码是一项商业资产。通过 SonarQube Server 达到干净代码状态，实现代码的最高价值。</p><p>SonarQube Server 功能：</p><ul><li><p><strong>代码智能</strong></p><p>利用 SonarQube 的深度洞察，更全面地了解您的代码库。通过减少认知负荷来提高开发人员的生产力。</p></li><li><p><strong>与顶级 DevOps 平台集成</strong></p><p>轻松加入项目。与 GitHub Actions、GitLab CI/CD、Azure Pipelines、Bitbucket Pipelines 和 Jenkins 集成，以自动触发分析并显示您工作地点的代码运行状况。</p></li><li><p><strong>代码审查</strong></p><p>通过 SonarQube 的质量阈值，防止不符合策略的代码进入生产环境。消除人工编写和 AI 生成代码中的问题，从而降低后期修复成本。</p></li><li><p><strong>高性能和可操作性</strong></p><p>按照您的方式进行部署，无论是在本地、在云中、作为服务器、使用 Docker 或 Kubernetes。多线程、多个计算引擎和特定于语言的加载可提供最佳性能。</p></li><li><p><strong>顶级分析速度和准确性</strong></p><p>在几分钟而不是几小时内收到可操作的清洁代码指标 (sysin)。Clean as You Code 会在您工作时检查较小的代码片段，为您提供有关新代码质量的准确反馈。</p></li><li><p><strong>重要语言的关键安全规则</strong></p><p>在您的开发工作流程中，在正确的时间和正确的位置无缝地发现编码问题。受益于 6,000 多个规则以及行业领先的 Java、C#、PHP、Python 等污点分析。</p></li><li><p><strong>共享、统一的配置</strong></p><p>设置特定的编码标准，使您的团队在代码健康方面保持一致并实现您的代码质量目标。另外，“边编程边学习” 可将开发人员的技能提升到同样高的水平。</p></li><li><p><strong>用于 IDE 的 SonarQube</strong></p><p>添加 SonarQube for IDE 扩展并将其连接到 SonarQube 服务器，以便在编码时动态查找编码问题，并确保您的团队遵循单一受监管的编码标准。</p></li><li><p><strong>测量代码覆盖率</strong></p><p>查看测试执行的代码库的百分比，以获得有关代码运行状况的宝贵见解。引导您到覆盖率低的领域进行改进。</p></li></ul><h2>Sonar 的人工智能</h2><p>AI 辅助编码，由 SONAR 改进</p><ul><li><p><strong>新的 AI 代码保证</strong></p><p>Sonar AI 代码保证是一个强大且简化的流程，用于通过结构化和全面的分析来验证 AI 生成的代码。这确保了每一段新代码在投入生产之前都符合最高的质量和安全标准。</p></li><li><p><strong>AI CodeFix 简介</strong></p><p>Sonar AI CodeFix 是一项强大的功能 (sysin)，可为代码分析解决方案 SonarQube Server 和 SonarQube Cloud 发现的问题提供代码修复建议。只需单击一下，您就可以获得有关如何解决一系列问题的建议，从而简化问题解决流程。</p></li></ul><p>笔者提示：此类功能通常需要有效服务合同。</p><h2>安全漏洞检测</h2><p>增强的开发人员安全工具 | 安全与机密信息检测</p><ul><li><p><strong>静态代码分析</strong></p><p>Sonar 的静态应用程序安全测试 (SAST) 引擎可检测代码中的安全漏洞，以便在构建和测试应用程序之前消除这些漏洞。使用 SAST 为复杂项目实现强大的应用程序安全性和合规性。</p></li><li><p><strong>机密信息检测</strong></p><p>SonarQube Server 包含一个强大的机密信息检测工具，这是用于检测和删除代码中机密信息的最全面的解决方案之一。与 SonarQube for IDE 一起使用，它可以防止机密信息泄露并成为严重的安全漏洞。</p></li><li><p><strong>安全标准合规性</strong></p><p>SonarQube Server 可帮助您遵守通用代码安全标准，例如 NIST SSDF。将 SonarQube Server 与 SonarQube for IDE 结合使用，可以自动检查项目代码是否存在安全漏洞，并提高整体代码质量。</p></li></ul><h2>基于开源，满足所有需求的版本</h2><p>SonarQube Server 版本：</p><ul><li><p><strong>Community Build</strong></p><p>免费开源，可提高开发效率和代码质量。</p></li><li><p><strong>Developer Edition</strong></p><p>小型团队和企业的基本功能。</p></li><li><p><strong>Enterprise Edition</strong></p><p>为现代企业提供更深入的见解和绩效。</p></li><li><p><strong>Data Center Edition</strong></p><p>任务关键型高可用性、可扩展性和性能。</p></li></ul><p><strong>什么是 LTA 版本</strong>？</p><p>LONG-TERM ACTIVE</p><p>SonarQube Server Long-Term Active (LTA)</p><p>为客户提供最佳体验、创新功能和世界一流的支持，以实现持续的业务成功。</p><p>什么是长期活跃 （LTA）</p><p>LTA 是指每 12 个月发布一次的 SonarQube Server 版本（以前称为长期支持或 LTS）。它是产品的功能完整版本，将保持活动状态更长的时间。大型组织有时更愿意继续使用 LTA，因为他们无法经常升级，而是选择每 12 个月升级一次。</p><h2>系统要求</h2><p>操作系统要求：</p><ul><li><p><strong>Linux (x64, AArch64)</strong>。建议使用主流发行版：</p><ul><li>参看：<a href="https://link.segmentfault.com/?enc=iOGP4frDgHWtAbz6ginuTA%3D%3D.LHp2OYVGSMwuC3nVfTH7zpgdcYav%2F4dWqhcdcoAzgkY%3D" rel="nofollow" target="_blank">Linux 产品链接汇总</a></li></ul></li><li><p><strong>Windows (x64)</strong>。建议主流支持版本：</p><ul><li><a href="https://link.segmentfault.com/?enc=O6xgr5ZHScvDXYVw370D2w%3D%3D.KnzbkO2Ql%2Bv9dAlBmAyLE7sYC1zIX3u7RW5pgCqZc%2B3iRqaf0QkbL2wd%2FXHUAXi3" rel="nofollow" target="_blank">Windows Server 2025</a>，<a href="https://link.segmentfault.com/?enc=NLRB%2BWN7qHE2x4Ro6UOp6Q%3D%3D.Xpj1S5OcdMFp%2B7u5jb%2Bd71Adcoaqns53gJ3H7DIiuM%2FAPt8MYw57ctWNveu2ELu1" rel="nofollow" target="_blank">OVF</a></li><li><a href="https://link.segmentfault.com/?enc=ic%2Fuv8xX1HCfKMRFHm%2F0rw%3D%3D.RZyUjCvB8ON8briWzKYWQUV5wSKmY4pd9%2BLqEp38hmp0JTBVv0Z4C4ThD9SuIzYD" rel="nofollow" target="_blank">Windows Server 2022</a>，<a href="https://link.segmentfault.com/?enc=MOgLxYmv93hDz%2Fl%2BiREnwA%3D%3D.zXg0Yemi5bR1LWc1le5qDiGepLuCLIihrUl3wtoCnP7yOpD4aOu7S06YuYalU2b%2B" rel="nofollow" target="_blank">OVF</a></li><li><a href="https://link.segmentfault.com/?enc=VxUtEXACENj9M4%2F81%2FfVnw%3D%3D.n9iJX2WEofi4kGhVaeAd9yLWJrpJK651k3XitlIXOI7PHxR8pE4ClrqUep%2FaT7HU" rel="nofollow" target="_blank">Windows 11</a></li><li>更多：<a href="https://link.segmentfault.com/?enc=XIKm9XQ5wf5OMszKoUUSUg%3D%3D.%2BknIJqx9Ch2Curb85Bl%2FLt4CRalllrGKiod%2FgJNGH4A%3D" rel="nofollow" target="_blank">Windows 下载汇总</a></li></ul></li><li><p><strong>macOS (x64, AArch64)</strong>。建议主流支持版本：</p><ul><li><a href="https://link.segmentfault.com/?enc=TPDF4Fi7jfxy7nkq1SlP6Q%3D%3D.tRX40x0wJk7XV0bA7%2FH%2F5Ik3f5watd2w6xfWvzS5CyczUNsF4LQIgQVuI2BofCJb" rel="nofollow" target="_blank">macOS Tahoe 26</a></li><li><a href="https://link.segmentfault.com/?enc=VIcfuQXbeVWT%2Bo9LwQP7gQ%3D%3D.WEuxR%2FYvCMLRaR93L8rGiHJk2ghTc8xorqDuMnKfk7s50EBsOMAXLoz7AE7WX14Z" rel="nofollow" target="_blank">macOS Sequoia 15</a></li><li><a href="https://link.segmentfault.com/?enc=V8Sv0Cb2aljKsC%2F9GVI4AQ%3D%3D.4DMJlsR7HO6%2B1hPr2gOD5i8%2BM4PJvuMRTkzrc5uQG6I4yhXcfMBGnwrmzbQmfeH%2F" rel="nofollow" target="_blank">macOS Sonoma 14</a></li><li>更多：<a href="https://link.segmentfault.com/?enc=L%2BG90xMZfWA%2FnUlyXtAsiw%3D%3D.0BKvfFEjHbdGikgHJu2nL67FlLs%2Bd0FePig31sykxk8%3D" rel="nofollow" target="_blank">macOS 下载汇总 (系统、应用和教程)</a></li></ul></li></ul><p>建议运行在虚拟机环境中，<strong>推荐使用本站原创虚拟机模板 OVF</strong>，简单、精准、高效。</p><p>软件要求已更新：包含在文档中。</p><h2>新增功能</h2><p><strong>SonarQube Server 2025.6</strong>：先沉浸（vibe），再以前所未有的速度验证</p><p>2025 年 12 月 11 日</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555446" alt="SonarQube Server 2025.6" title="SonarQube Server 2025.6" loading="lazy"/></p><p>AI 已经将开发瓶颈从 “写代码” 转移到 “验证代码”。确保代码可靠、安全、可维护，已成为软件开发生命周期中最关键的一步。SonarQube Server 2025.6 加速了这一验证流程，将其直接嵌入您的日常工作流中。通过更深的集成、大幅加速的分析性能以及扩展的语言支持，本次发布帮助团队拥抱 “先沉浸、再验证（vibe, then verify）” 的理念，更自信地交付软件。</p><p>✅ <strong>2025.6 新功能一览</strong></p><ul><li><strong>加速工作流</strong>：新增 Jira Cloud 与 Slack 集成。</li><li><strong>更快反馈</strong>：JavaScript/TypeScript 分析速度提升最高 40%。</li><li><strong>即时修复</strong>：在 IDE 中新增 58 个 JavaScript/TypeScript 快速修复。</li><li><strong>现代语言支持</strong>：全面支持 Swift（5.9–6.1）和 Python 3.14。</li><li><strong>AI/ML 保障</strong>：为 PyTorch、Apex 和 Ruby 提供高效分析。</li><li><strong>基础设施代码</strong>：新增 Go 和 Shell/Bash 的代码质量规则 (sysin)。</li><li><strong>合规性</strong>：完整覆盖 MISRA C++:2023、OWASP Top 10 2025 与 STIG V6R3。</li><li><strong>供应链安全</strong>：支持导入 CycloneDX 和 SPDX SBOM。</li></ul><p>✅ <strong>通过深度工作流集成加速您的团队</strong></p><p>为了帮助团队跟上庞大的代码量，SonarQube 专注于消除摩擦、加快反馈循环。使用 JavaScript/TypeScript 的开发者将立即注意到在大型项目中最高 40% 的分析速度提升，从而缩短等待时间，加速代码评审。同时，SonarQube 让修复问题变得比以往更简单：58 个全新的 “快速修复” 让您在 IDE 中即可快速处理问题。此外，将代码质量融入组织工作流也变得前所未有的顺畅：全新的 Jira Cloud 集成可立即将代码问题转成可追踪的任务 (sysin)；Slack 集成则可在质量门状态变化时实时发送通知，让团队在构建无法通过质量门时可以更快速地响应。</p><p>✅ <strong>无与伦比的语言与合规覆盖</strong></p><p>SonarQube 2025.6 大幅扩展其在行业内对语言覆盖的领先优势，让您能自信采用新技术并满足最严苛的合规要求。SonarQube 现已为最新版本的 Python 3.14 与 Swift（5.9–6.1）提供全方位的代码安全与代码质量支持，包括 Swift 的 SAST 与秘钥检测。对于构建机器学习应用的开发者，SonarQube 提供 PyTorch 的 AI/ML 保障，帮助实现高效代码。在云原生领域，您将获得大量新的 Go 规则，以及 Shell/Bash 脚本的代码质量与代. 码安全分析。最后，在 SonarQube Server Enterprise 和 Data Center 版本中，SonarQube 提供对全部 179 条 MISRA C++:2023 指南、STIG V6R3 及新版 OWASP Top 10 2025 的完整覆盖，为您的合规与风险团队提供通过严格标准所需的保证。</p><p>✅ <strong>通过 Advanced SAST 和 SBOM 保护您的供应链</strong></p><p>在供应链攻击不断增加的当下，代码安全绝不能被事后处理。此次发布强化了 SonarQube “集成代码质量与代码安全” 的核心使命。SonarQube Advanced Security 中的 Advanced SAST 功能已针对 C#、Java 以及现在的 Python 的主流库进行了刷新与优化，以发现其他工具遗漏的复杂、隐蔽漏洞。为了让您对所有组件拥有全面可见性 (sysin)，SonarQube Advanced Security 现在支持导入 CycloneDX 和 SPDX 格式的 SBOM（软件物料清单），实现对任意组件的统一依赖性与漏洞报告。通过这些增强功能，SonarQube 确保您的组织能够以快速且自信的方式验证每一行代码——无论是开发者编写的还是 AI 生成的。</p><p>更多详细功能介绍，请查阅官方文档。</p><h2>下载地址</h2><p>版本历史：</p><p>SonarQube Server 2025.1 LTA Data Center Edition for macOS, Linux, Windows | January 2025 | 2025.1.0.102418</p><p>SonarQube Server 2025 Release 2 Data Center Edition for macOS, Linux, Windows | March 2025 | 2025.2.0.105476</p><p>SonarQube Server 2025 Release 3 Data Center Edition for macOS, Linux, Windows | May 2025 | 2025.3.0.108892</p><p>SonarQube Server 2025 Release 3.1 Data Center Edition for macOS, Linux, Windows | Jun 2025 | 2025.3.1.109879</p><p>SonarQube Server 2025 Release 4.2 Data Center Edition for macOS, Linux, Windows | July 2025 | 2025.4.2.112048</p><p>SonarQube Server 2025 Release 5 Data Center Edition for macOS, Linux, Windows | September 2025 | 2025.5.0.113872 (2025-09-24)</p><p>SonarQube Server 2025 Release 6 Data Center Edition for macOS, Linux, Windows | December 2025 | 2025.6.0.117042 (2025-12-11)</p><p>当前版本：</p><p><strong>SonarQube Server 2025 Release 6.1</strong> Data Center Edition for macOS, Linux, Windows | December 2025 | 2025.6.1.117629 (2026-01-20)</p><ul><li>请访问：<a href="https://link.segmentfault.com/?enc=HB5z6bSGwaMdNq7R1Q8FFA%3D%3D.awj14M14Lh0FETAE3bwC0AQ4RPiiLb8PK5%2BaPjwM8j76RABvn1gyLO4abQqQObQK" rel="nofollow" target="_blank">https://sysin.org/blog/sonarqube/</a></li></ul><p>更多：<a href="https://link.segmentfault.com/?enc=vcCyM9VFmGH%2B%2FHpHfGTyXw%3D%3D.A7EShU0xGUHZoPpa0Q176sx91dM7mxvPZq1Vx3ieGaA%3D" rel="nofollow" target="_blank">HTTP 协议与安全</a></p>]]></description></item><item>    <title><![CDATA[【k8s】Centos从零开始部署k8s1.23.17+KubeSphere 天行1st ]]></title>    <link>https://segmentfault.com/a/1190000047555447</link>    <guid>https://segmentfault.com/a/1190000047555447</guid>    <pubDate>2026-01-21 12:03:12</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><code>Centos</code>虽然已经停止维护了，而且内核也非常低，耐不住国内大环境很多公司还是一直在用它。时不时见到有人想要在centos上面部署<code>k8s1.23</code>版本,本文将以<code>centos 7</code>为例，从0开始搭建k8s+ks集群。</p><h2>1.说明</h2><h3>关于kt</h3><p><code>kt</code>是基于<code>kk</code>二次开发的产物，具备<code>kk</code>的所有功能。二开主要为适配信创国产化环境、简化<code>arm</code>部署过程和国产化环境离线部署。支持<code>arm64</code>和<code>amd64</code>架构国产操作系统，已适配芯片+操作系统 如下。</p><p><strong>kt新增功能点</strong></p><ul><li>适配arm架构harbor和支持，部署体验与X86一样简单。</li><li><p>离线环境部署增强。常用国际和国产操作系统依赖，内置到安装包中。已适配芯片和操作系统如下</p><ul><li><code>./kt init-os</code> 一条命令完成操作系统依赖安装和初始化操作。</li><li>CPU：鲲鹏、飞腾、海光、兆芯、intel、amd等。</li><li>OS：Centos、Rocky Linux、Ubuntu、Debian、银河麒麟V10、麒麟V11、麒麟国防版、麒麟信安、中标麒麟V7、统信UOS、华为欧拉、移动大云、阿里龙蜥、TencenOS等。</li></ul></li><li><p>支持开启防火墙，只暴露<code>30000-32767</code>端口，其他k8s端口添加到节点白名单。</p><ul><li><code>./kt firewall</code> 一条命令自动获取节点信息开白名单和防火墙。</li></ul></li></ul><p><strong>kt版本更新和下载地址</strong></p><ul><li><strong>kt：</strong><a href="https://link.segmentfault.com/?enc=aqG6E77BUa8RC9dm92plXw%3D%3D.5LHnJuTCfYsS3o30Lc9AXNv%2Ff1dI823WrLGK%2FMnIvSg%3D" rel="nofollow" title="kt说明" target="_blank">kt</a></li><li><strong>关注我不迷路</strong></li></ul><h2>2.环境准备</h2><p><strong>服务器基本信息</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555450" alt="" title=""/></p><table><thead><tr><th><strong>主机名</strong></th><th><strong>架构</strong></th><th><strong>OS</strong></th><th><strong>配置</strong></th><th><strong>IP</strong></th></tr></thead><tbody><tr><td>all-in-one</td><td>x86_64</td><td>Centos 7</td><td>4核8G</td><td>192.168.85.164</td></tr></tbody></table><h3>2.1 上传离线制品</h3><p>操作系统不需要安装docker,不需要设置selinux,swap等操作，全新的操作系统即可。</p><p>将离线制品、配置文件、kt和sh脚本上传至服务器其中一个节点(本文以master为例)，后续在该节点操作创建集群。本文使用kt:<code>3.1.12-centos</code>版本</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555451" alt="" title="" loading="lazy"/></p><h3>2.2 修改配置文件</h3><p>根据实际服务器信息，配置到生成的<code>config-sample.yaml</code>中</p><pre><code class="plain">kind: Cluster
metadata:
  name: sample
spec:
  hosts:
  - {name: node1, address: 192.168.85.164, internalAddress: 192.168.85.164, user: root, password: "123123"}
  roleGroups:
    etcd:
    - node1
    control-plane:
    - node1
    worker:
    - node1
    # 如需使用 kk 自动部署镜像仓库，请设置该主机组 （建议仓库与集群分离部署，减少相互影响）
    # 如果需要部署 harbor 并且 containerManager 为 containerd 时，由于部署 harbor 依赖 docker，建议单独节点部署 harbor
    registry:
    - node1
  controlPlaneEndpoint:
    ## Internal loadbalancer for apiservers 
    internalLoadbalancer: haproxy

    domain: lb.kubesphere.local
    address: ""
    port: 6443
  kubernetes:
    version: v1.23.17
    clusterName: cluster.local
    autoRenewCerts: true
    containerManager: docker
  etcd:
    type: kubekey
  network:
    plugin: calico
    kubePodsCIDR: 10.233.64.0/18
    kubeServiceCIDR: 10.233.0.0/18
    ## multus support. https://github.com/k8snetworkplumbingwg/multus-cni
    multusCNI:
      enabled: false
  registry:
    type: harbor
    registryMirrors: []
    insecureRegistries: []
    privateRegistry: "dockerhub.kubekey.local"
    namespaceOverride: "kubesphereio"
    auths: # if docker add by `docker login`, if containerd append to `/etc/containerd/config.toml`
      "dockerhub.kubekey.local":
        username: "admin"
        password: Harbor@123 # 此处可自定义，kk3.1.8新特性
        skipTLSVerify: true # Allow contacting registries over HTTPS with failed TLS verification.
        plainHTTP: false # Allow contacting registries over HTTP.
        certsPath: "/etc/docker/certs.d/dockerhub.kubekey.local"
  addons: []
  ---</code></pre><h2>2.3 系统初始化</h2><p>解压<code>kt-centos.tar.gz</code>文件后执行<code>./kt init-os -f config-sample.yaml</code> 已适配操作系统和架构见<code>1.说明</code></p><p>该命令<code>kt</code>会根据配置文件自动判断操作系统和架构以完成所有节点的初始化配置和依赖安装。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555452" alt="" title="" loading="lazy"/></p><h2>3 创建 Harbor私有仓库</h2><h3>3.1 创建镜像仓库</h3><pre><code class="plain">./kt init registry -f config-sample.yaml -a artifact-x86-k8s12317-ks3.4.1.tar.gz</code></pre><p>此命令会在<code>harbor</code>节点自动安装<code>docker</code>和<code>docker-compose</code></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555453" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555454" alt="" title="" loading="lazy"/></p><h3>3.2 创建harbor项目</h3><p>&lt;font style="background-color:rgb(255,245,235);"&gt;说明：&lt;/font&gt;</p><p>&lt;font style="background-color:rgb(255,245,235);"&gt;Harbor 管理员账号：&lt;/font&gt;<strong>&lt;font style="background-color:rgb(255,245,235);"&gt;admin&lt;/font&gt;</strong>&lt;font style="background-color:rgb(255,245,235);"&gt;，密码：&lt;/font&gt;<strong>&lt;font style="background-color:rgb(255,245,235);"&gt;Harbor@123&lt;/font&gt;</strong>&lt;font style="background-color:rgb(255,245,235);"&gt;。密码同步使用配置文件中的对应password&lt;/font&gt;</p><p>&lt;font style="background-color:rgb(255,245,235);"&gt;harbor 安装文件在 &lt;/font&gt;<code>&lt;font style="background-color:rgb(255,245,235);"&gt;/opt/harbor&lt;/font&gt;</code>&lt;font style="background-color:rgb(255,245,235);"&gt; 目录下，可在该目录下对 harbor 进行运维。&lt;/font&gt;</p><p>创建 Harbor 项目</p><pre><code class="plain">chmod +x create_project_harbor.sh &amp;&amp; ./create_project_harbor.sh</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555455" alt="" title="" loading="lazy"/></p><h2>4 创建k8s和KubeSphere</h2><pre><code class="plain">./kt create cluster -f config-sample.yaml -a artifact-x86-k8s12317-ks3.4.1.tar.gz</code></pre><p>此命令kt会自动将离线制品中的镜像推送到<code>harbor</code> 私有仓库</p><p>执行后会有如下提示,输入<code>yes/y</code>继续执行</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555456" alt="" title="" loading="lazy"/></p><p>等待一段时间，直至出现熟悉的等待安装完成的小箭头&gt;&gt;---&gt;</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555457" alt="" title="" loading="lazy"/></p><p>期间可以另开一个窗口用以下命令查看部署日志</p><pre><code class="plain">kubectl logs -n kubesphere-system $(kubectl get pod -n kubesphere-system -l 'app in (ks-install, ks-installer)' -o jsonpath='{.items[0].metadata.name}') -f</code></pre><p>继续等待一段时间最终可以看到安装成功的消息</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555458" alt="" title="" loading="lazy"/></p><h2>5 验证</h2><p>登录页面</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555459" alt="" title="" loading="lazy"/></p><p>集群管理</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555460" alt="" title="" loading="lazy"/></p><p>监控告警</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555461" alt="" title="" loading="lazy"/></p><p>配置文件默认只安装了监控，如果需要安装其他组件，可以自行在自定义资源中开启</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555462" alt="" title="" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[别让脏数据拖垮你的量化系统：关于Tick数据流处理的工程实践 EmilyLi ]]></title>    <link>https://segmentfault.com/a/1190000047555477</link>    <guid>https://segmentfault.com/a/1190000047555477</guid>    <pubDate>2026-01-21 12:02:38</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>做量化交易系统的后端开发，最怕的不是算法太难，而是数据源“太脏”或者粒度不够。</p><p>作为开发者，你一定遇到过这种情况：前端图表展示用K线绰绰有余，但后端撮合引擎如果也只用K线数据，那简直就是灾难。因为K线丢失了时间维度的时序性。</p><p><strong>从工程角度看Tick数据的必要性</strong> Tick（逐笔成交）数据，本质上是时间序列数据库里最基础的原子单位。在系统架构设计中，引入历史Tick数据主要为了解决两个工程痛点：</p><ol><li><strong>事件驱动的回测准确性</strong>：基于Bar（K线）的回测是粗粒度的，无法模拟Tick级别的撮合逻辑。</li><li><strong>异常排查</strong>：当线上策略出现非预期亏损，你需要一份精确到毫秒的“系统日志”来还原当时的行情切片。</li></ol><p><strong>如何优雅地获取并“消费”Tick数据？</strong> 很多同学拿到Tick数据的第一反应是存起来再算。其实更高效的做法是流式处理或切片回放。这就要求上游接口必须足够稳定且结构规范。</p><p>这就涉及到接口选型的问题。如果每个交易所的API你都要写一套解析脚本，维护成本会极高。在工程实践中，推荐使用那些已经做过“归一化”处理的聚合接口，比如 AllTick API 这类服务，它直接返回标准化的JSON结构，能让你把精力集中在策略逻辑（Business Logic）上，而不是消耗在ETL（数据清洗）上。</p><pre><code>import requests
import pandas as pd

API_KEY = "YOUR_API_KEY"
symbol = "AAPL.US"

url = "https://apis.alltick.co/stock/historical/tick"
params = {
    "symbol": symbol,
    "limit": 500
}

headers = {
    "Authorization": f"Bearer {API_KEY}"
}

resp = requests.get(url, headers=headers, params=params)
ticks = resp.json().get("ticks", [])

df = pd.DataFrame(ticks)
df["time"] = pd.to_datetime(df["time"])

print(df.head())
</code></pre><p><strong>数据消费建议</strong> 代码跑通后，建议大家把重点放在数据落地上。不要一上来就搞复杂的各种因子计算。先试着把Tick数据可视化，观察一下在极短时间窗口内的价格跳动逻辑。你会发现，很多K线上看似合理的支撑位，在Tick级别其实是脆弱不堪的。<br/><img width="723" height="408" referrerpolicy="no-referrer" src="/img/bVdnHqR" alt="" title=""/></p>]]></description></item><item>    <title><![CDATA[估值 5 亿美元，AI 视频调研初创 Listen Labs 再获 6900 万融资 RTE开发者社]]></title>    <link>https://segmentfault.com/a/1190000047555484</link>    <guid>https://segmentfault.com/a/1190000047555484</guid>    <pubDate>2026-01-21 12:02:05</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555486" alt="" title=""/></p><p><strong>开发者朋友们大家好：</strong></p><p>这里是 <strong>「RTE 开发者日报」</strong> ，每天和大家一起看新闻、聊八卦。我们的社区编辑团队会整理分享 RTE（Real-Time Engagement） 领域内「有话题的<strong>技术</strong>」、「有亮点的<strong>产品</strong>」、「有思考的<strong>文章</strong>」、「有态度的<strong>观点</strong>」、「有看点的<strong>活动</strong>」，但内容仅代表编辑的个人观点，欢迎大家留言、跟帖、讨论。</p><p><em>本期编辑：@瓒an、@鲍勃</em></p><h2>01 有话题的技术</h2><p><strong>1、Vibecraft 发布：Claude Code 的 3D 可视化工具，数据纯本地运行</strong></p><p>开发者 @nearcyan 近日发布了「Vibecraft」，这是一款专为 Claude Code 打造的 3D 可视化应用程序。它支持用户通过全新的六边形网格布局，实时查看并管理 Claude 实例。</p><p>为了保障数据安全，该应用采取了严格的本地化运行模式，直接与用户计算机上的 Claude Code 实例同步。这意味着所有的文件与代码数据均完全保留在本地，不会被发送至任何网络服务器，从而确保了开发过程的隐私安全。</p><p>体验链接：</p><p><a href="https://link.segmentfault.com/?enc=E3HaLkBiwrzIhkCVRRkXfw%3D%3D.Fh8mCIIEfaQtnbKpP8ccuDlnXh2U2vts39hMfxtbiXE%3D" rel="nofollow" target="_blank">https://vibecraft.sh/</a></p><p>( @nearcyan@X)</p><p><strong>2、智谱 GLM-4.7-Flash 模型发布并开源，可免费调用</strong></p><p>智谱 GLM-4.7-Flash 模型今日正式发布并开源。</p><p>GLM-4.7-Flash 是一个<strong>混合思考</strong>模型，总参数量为<strong> 30B</strong>，激活参数量为<strong> 3B</strong>，作为同级别 SOTA 模型，为轻量化部署提供了一个<strong>兼顾性能与效率</strong>的新选择。</p><p>即日起，GLM-4.7-Flash 将替代 GLM-4.5-Flash，在智谱开放平台 BigModel.cn 上线，并供<strong>免费</strong>调用。</p><p>在 SWE-bench Verified、τ²-Bench 等主流基准测试中，GLM-4.7-Flash 的综合表现超过 gpt-oss-20b、Qwen3-30B-A3B-Thinking-2507，<strong>在相同和近似尺寸模型系列中取得开源 SOTA 分数</strong>。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555487" alt="" title="" loading="lazy"/></p><p>在内部的编程实测中，GLM-4.7-Flash 在前、后端任务上表现出色。在编程场景之外，官方也推荐用户在中文写作、翻译、长文本、情感 / 角色扮演等通用场景中体验 GLM-4.7-Flash。</p><p>需要注意的是，上一代免费语言模型 <strong>GLM-4.5-Flash 将于 2026 年 1 月 30 日下线</strong>，用户需要及时将模型编码更新为最新版本。GLM-4.5-Flash 正式下线后，相关请求将会自动路由至 GLM-4.7-Flash。</p><p>Hugging Face: <br/><a href="https://link.segmentfault.com/?enc=3vLBwYIBpJBRrndsDB%2BUQg%3D%3D.flARXYW8%2FKhoanWeCZCI3FhxpX%2FKTgK2NB%2FO4ivp25mNNrhn7DDdzKjQRIsGvucp" rel="nofollow" target="_blank">https://huggingface.co/zai-org/GLM-4.7-Flash</a></p><p>魔搭社区：</p><p><a href="https://link.segmentfault.com/?enc=28HeoOefUdNvm6K243JnIQ%3D%3D.1wgDRImeTSB6Gb%2BuUavEewqIZxR75TH%2Fn%2BQ%2F9vRb8jr%2FQZvpoZScTJu%2FpRGY0ztA1bY0BfA3CX7NqEy2Q5lVXQ%3D%3D" rel="nofollow" target="_blank">https://modelscope.cn/models/ZhipuAI/GLM-4.7-Flash</a></p><p>（@智谱）</p><p><strong>3、华为云发布 CodeArts Doer 代码智能体：个人版免费开放，开启「编码自动驾驶」</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555488" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555489" alt="" title="" loading="lazy"/></p><p>2026 年 1 月 16 日，华为云正式发布代码智能体「CodeArts Doer」。这款产品深度集成了 AI IDE、Code Agent 及 Codebase 代码仓深度理解能力，旨在通过<strong>「人+AI+工具」的协同模式</strong>，为开发者开启<strong>「编码自动驾驶」体验</strong>。</p><p>为了重构传统的开发工作流，CodeArts Doer 以 AI 原生为起点构建了 AI IDE。它不再局限于单一的代码补全，而是能够<strong>支持从需求描述、任务拆解到代码落地的全流程闭环</strong>。这种设计让开发者可以专注于业务判断与关键决策，将高频重复的工程化工作交由 AI 处理，从而解决了以往需要在多窗口间频繁切换寻找工具的痛点。</p><p>在具体的编码执行层面，CodeArts Doer 提供了两种差异化模式以适应不同诉求。<strong>「探索模式」侧重人机协同与创造力</strong>，开发者通过自然语言即可规划项目任务并生成项目级代码，适合快速将想法转化为可运行版本；而<strong>「规范模式」则更强调质量与一致性</strong>，在代码生成过程中严格对齐标准流程与安全校验，确保交付的稳定性。</p><p>针对 AI 编码在生产环境中常遇到的「看似正确实则不适配」难题，产品特别强化了 Codebase 能力。通过支持百万行级代码索引与知识图谱构建，它能够准确理解代码仓结构、依赖关系及演化历史。这使得 AI 即使在复杂的业务边界内，也能提供贴合项目现实的建议，帮助新老成员快速定位与上手。</p><p>目前，CodeArts Doer 代码智能体个人版已正式面向开发者开放免费体验，覆盖了项目级代码生成、研发知识问答及单元测试生成等核心场景。</p><p>相关链接：<br/><a href="https://link.segmentfault.com/?enc=9owVNO6gUGgDHGak3H78eA%3D%3D.Gi%2F6s8dsk9sJLj9zxwcC0n7RAPW%2F3PLp0HrGjUPR58Umm33NpqdrARo5nKdObQX74VtX7yA9Iv0ihnqW5ZaRCQ%3D%3D" rel="nofollow" target="_blank">https://www.huaweicloud.com/product/codeartside/snap.html</a></p><p>（@华为云开发者联盟）</p><h2>02 有亮点的产品</h2><p><strong>1、OpenAI 或正测试新产品、首款硬件设备计划今年下半年亮相</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555490" alt="" title="" loading="lazy"/></p><p>据 BleepingComputer 报道，OpenAI 近日被发现启用了以「sonata」为域名前缀的新子域名，外界推测这可能对应一项正在测试中的 ChatGPT 新功能或新产品。</p><p>相关记录显示，sonata.openai.com 于 1 月 16 日首次出现，sonata.api.openai.com 则在 1 月 15 日被发现，意味着 OpenAI 已在主站与 API 体系中同步启用该前缀，通常指向内部测试中的新服务或面向用户的网页工具。</p><p>报道指出，OpenAI 新增域名往往对应尚未公开的产品页面、内部工具或 Web 应用。尽管「sonata」一词本身常用于指代多乐章器乐作品，但其含义并不限定于音乐领域，因此目前尚无法据此判断功能方向。</p><p>除新域名外，OpenAI 近期也在持续更新 ChatGPT 的现有能力，包括「引用聊天记录」功能，当用户开启后，ChatGPT 在检索旧对话细节时将更为可靠，并会在回答中标注引用来源，便于用户回溯上下文。</p><p>此外，据 Axios 报道，OpenAI 全球事务负责人 Chris Lehane 今天在达沃斯的 Axios House 活动上表示，<strong>OpenAI 正按计划推进其首款硬件设备，目标是在今年下半年亮相。</strong></p><p>这也是继去年收购前苹果设计主管 Jony Ive 创办的公司后，OpenAI 首次给出更明确的时间窗口。</p><p>Lehane 将「设备」列为 OpenAI 今年的重点方向之一，但并未透露任何外观、形态或交互方式。<strong>此前多份报道提到，OpenAI 正在测试无屏幕的小型原型机，可能以可穿戴方式与用户互动。</strong></p><p>Sam Altman 曾表示，这款设备将比智能手机更「平和」，并以极简设计为核心。</p><p>Ive 团队在去年被收购时发布的宣传视频中也曾暗示 2026 年的发布节点，称「我们期待明年与大家分享我们的工作」。</p><p>Lehane 在活动中补充称，OpenAI 正「考虑在今年后段推出某些东西」，但仍保留调整空间，强调最终时间取决于研发进展。他并未承诺设备会在今年正式开售。</p><p>( @APPSO)</p><p><strong>2、字节跳动旗下扣子 2.0 正式发布，全球首发 AI Agent 技能商店</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555491" alt="" title="" loading="lazy"/></p><p>昨天，字节跳动旗下智能体平台「扣子（Coze）」发布 2.0 版本重大升级，并同步推出<strong>全球首个面向普通用户的 AI 技能商店（Coze Skills）</strong>。</p><p>此次更新围绕 Agent Skills、Agent Plan、Agent Office、Agent Coding 四大能力展开，旨在让 AI 从被动回答工具，进一步进化为可长期协作的职场伙伴。</p><ul><li><strong>Agent Skills</strong>：将可复用的工作经验封装为可被智能体随时调用的标准化技能包；</li><li><strong>Agent Plan</strong>：根据用户目标自动拆解步骤并持续执行、推进长期任务；</li><li><strong>Agent Office</strong>：在办公场景中自动处理文档、表格与信息整理等日常工作；</li><li><strong>Agent Coding</strong>：提供从构建到部署的一站式智能体开发与运维能力。</li></ul><p>扣子方面称，2.0 版本的目标是让 AI 不仅能帮你做，更能替你做完。随着技能、长期任务与开发平台的整合，扣子希望推动 AI 在职场场景中承担更多执行与分析工作，让用户将精力集中在策略与创造上。</p><p>( @APPSO)</p><p><strong>3、「自然选择」融资 3000 万美元，阿里、蚂蚁布局 AI 陪伴</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555492" alt="" title="" loading="lazy"/></p><p>据「暗涌 Waves」独家获悉，AI 陪伴公司「自然选择」（Nature Select）已于<strong>近期完成超 3000 万美元的新一轮融资</strong>。本轮投资阵容豪华，由阿里巴巴、蚂蚁集团、启明创投、五源资本、创世伙伴创投及云时资本联合投资，星涵资本担任独家财务顾问。</p><p>在 AI 陪伴赛道上半年一度遇冷的背景下，「自然选择」凭借核心产品《EVE》呈现的全新形态突围。不同于传统 C.ai 类产品的被动响应，《EVE》强调具备独立意志的「主动发起」，并通过引入 3D 视觉与游戏化设计极大地提升了沉浸感。这种<strong>破次元 Agent</strong> 甚至能在达到一定亲密度后，直接在现实中为用户点奶茶。据暗涌 Waves 了解，这类打破虚拟与现实边界的体验，或许是阿里等投资方共同入局的原因之一。</p><p>为了实现这种双商兼具的拟人体验，团队采取了独特的技术路径。他们不仅设立了情感交互设计师岗位，还发布了首个情感大模型 Echo-N1，首次将强化学习应用于主观情感领域。针对关键的记忆难题，团队将早期的动态记忆槽位的长时记忆方案升级为多维 graphRAG，创始人 Tristan 直言 <strong>「记忆系统的本质是推荐系统」</strong>，并据此构建了更符合人类直觉的回忆与遗忘机制。</p><p>2025 年中以来，AI 陪伴赛道愈发拥挤，而「自然选择」目前看来呈现的核心优势在于：<strong>既为 AI 公司，有完整的 post-training 团队和长期记忆之类的专家系统；也有游戏公司背景，能做 3D 视觉和恋爱游戏化设计。</strong>但每个人类个体对于情感都有不尽相同的需求，这场瞄准最人类部分的 AI 商业大战，也只是刚刚开始。</p><p>基于此，Tristan 将公司的终极目标设定为「迎接硅基生命降临，并创造一个人与 AI 共存的世界」。</p><p>（@暗涌 Waves）</p><p><strong>4、小米 AI 眼镜新版本内测：支持录音中按键拍照，蚂蚁阿福上线</strong></p><p>1 月 19 日消息，小米社区今日开启小米 AI 眼镜新版本内测招募，特邀 200 名米粉，预计在 2026 年 1 月 21 号统一审核。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555493" alt="" title="" loading="lazy"/></p><p>升级内容：</p><ul><li>上线精选智能体：蚂蚁阿福健康管家，眼镜随时变身你的 AI 医生朋友</li><li>录音总结升级，支持录音中按键拍照，一键生成图文总结</li><li>支持语音创建日程提醒，到期时小爱会主动播报</li><li>优化小爱图像问答效果</li><li>修复其他已知问题</li><li>App 需更新至 v2.6.0 或以上版本</li></ul><p>（@极客公园）</p><p><strong>5、Listen Labs 完成 6900 万美元 B 轮融资：AI 智能体自动化执行深度客户访谈</strong></p><p>「Listen Labs」近日宣布完成<strong> 6900 万美元 B 轮融资</strong>，由 Ribbit Capital 领投，估值达 5 亿美元。在短短 9 个月内，该公司将年化收入提升了 15 倍。<strong>其核心突破在于利用 AI 智能体自动化执行深度客户访谈，有效解决了传统问卷调查太浅与人工访谈太慢的两难困境。</strong></p><p>为了实现定性调研深度与定量规模的结合，Listen Labs 推出了<strong>具备「追问能力」的视频访谈智能体</strong>。不同于僵化的选择题问卷，该 AI 能与受访者进行开放式视频对话，并根据回答实时生成追问以挖掘真实想法。针对行业普遍存在的刷单现象，其「Quality Guard」系统结合 LinkedIn API 身份校验与视频逻辑检测，成功帮助合作方 Emeritus 将调研中的虚假及低质量数据比例从 20% 降至接近 0。</p><p>这种技术带来的<strong>效率提升</strong>在实际应用中得到了验证。微软利用该平台，将原本耗时 6-8 周的用户故事收集工作缩短至 24 小时内；水杯品牌 Simple Modern 也在 4.5 小时内完成了 120 人的新产品概念测试。目前，平台已向企业用户开放，采用 B2B 订阅或项目制计费，服务客户涵盖 Microsoft、Sweetgreen 和 Chubbies 等。</p><p>支撑这一技术体系的是一支拥有极高「含码量」的团队——公司 30% 的工程师为国际信息学奥赛（IOI）奖牌得主，且即便是市场运营岗位也优先录用工程师，旨在用技术逻辑重构业务流程。</p><p>本轮融资后，团队计划从 40 人扩充至 150 人，重点研发「合成用户」功能，即基于历史数据构建数字孪生受访者，从而实现 <strong>「自动写代码-自动访谈-自动迭代」的自动化闭环</strong>。</p><p>( @VentureBeat)</p><h2>03 有态度的观点</h2><p><strong>1、Shopify CEO：别把创业者「放进创始人托儿所」</strong></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555494" alt="" title="" loading="lazy"/></p><p>据《商业内幕》报道 ，Shopify CEO Tobi Lütke 近日在播客节目《Founder's Podcast》中表示，许多公司在收购后往往低估创业者的经验价值，将他们边缘化，甚至形容这种做法像是把创始人「放进创始人托儿所」。</p><p>Lütke 指出，创业者通常具备独特的思维方式与解决问题的能力，但不少企业会将他们安排到组织边缘，或分配到所谓的「skunk work team」（秘密工作小组）。</p><p>他直言，这种做法是在「把最能指出问题的人隔离起来」，并强调「你不能把他们放进创始人托儿所」。</p><p>他提到，这种情况在 Shopify 于疫情期间的收购整合中曾出现。意识到问题后，他主动提升被收购公司创始人在组织内的存在感，甚至让他们在管理层级中拥有更高的影响力。</p><p>他还透露，自己与这些创始人保持一个 Slack 频道，用于交流产品与业务问题。</p><p>Shopify 近年来的收购包括 2022 年的物流公司 Deliverr、同年的网红营销平台 Dovetale，以及 2024 年的企业沟通平台 Threads。</p><p>报道指出，Dovetale 与 Threads 的创始人目前仍在 Shopify 担任产品相关角色，而 Deliverr 的 CEO 则在加入一年后离开，重新创办物流创业公司。</p><p>在节目中，Lütke 还提到，他在招聘时会特别询问候选人「你是否创办过公司」，因为这能帮助他判断对方在危机情境中的适应能力与执行力。</p><p>( @APPSO)</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555495" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555496" alt="" title="" loading="lazy"/></p><p><a href="https://link.segmentfault.com/?enc=EN2w4GZqnOxe%2FhRMYpZ6AA%3D%3D.17jYLSwWbuexYty1KyVW2mQ9HUIg3WxotzbPGrhud5w%3D" rel="nofollow" target="_blank">阅读更多 Voice Agent 学习笔记：了解最懂 AI 语音的头脑都在思考什么</a></p><p><strong>写在最后：</strong></p><p>我们欢迎更多的小伙伴参与 <strong>「RTE 开发者日报」</strong> 内容的共创，感兴趣的朋友请通过开发者社区或公众号留言联系，记得报暗号「共创」。</p><p>对于任何反馈（包括但不限于内容上、形式上）我们不胜感激、并有小惊喜回馈，例如你希望从日报中看到哪些内容；自己推荐的信源、项目、话题、活动等；或者列举几个你喜欢看、平时常看的内容渠道；内容排版或呈现形式上有哪些可以改进的地方等。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555497" alt="" title="" loading="lazy"/></p><p>作者提示：个人观点，仅供参考</p>]]></description></item><item>    <title><![CDATA[写了这么多年Go，这几个神仙技巧你用过吗？ 王中阳讲编程 ]]></title>    <link>https://segmentfault.com/a/1190000047555499</link>    <guid>https://segmentfault.com/a/1190000047555499</guid>    <pubDate>2026-01-21 12:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>大家好我是地鼠哥。</p><p>如果你也是从 <code>fmt.Println("Hello, World!")</code> 和 <code>if err != nil</code> 开始Go语言生涯的，那说明你已经是个成熟的Go开发者了。在日常的业务开发中，我们每天都在写着各种各样的结构体和接口，有时候会觉得Go的语法过于简单，写起来甚至有点繁琐。</p><p>但其实，Go语言的设计虽然崇尚简洁，却在细节中隐藏了很多巧思。<strong>从经典的Go 1.11到最新的Go 1.26，它一直在稳步进化</strong>，引入了很多实用的特性和设计模式。用好它们，不仅能让代码更清晰，还能在同事面前展示你的专业能力。</p><p>下面就聊几个在实际工作中非常实用的技巧，看看你是否都在使用。</p><h4>用自定义类型（Defined Types）提升安全性</h4><p>在业务代码里，我们经常用 <code>int64</code> 或 <code>string</code> 来表示各种ID，比如 <code>UserID</code>, <code>OrderID</code>, <code>ProductID</code>。直接使用基础类型的一个主要风险是，方法的参数很容易传混。</p><p>比如下面这个函数：</p><pre><code class="go">// 很容易写错的调用
func ProcessOrder(userID int64, orderID int64) {
    // ...
}

// 调用时可能不小心把两个ID搞反
var uid int64 = 1001
var oid int64 = 9527
ProcessOrder(oid, uid) // 编译器不会报错，但逻辑全错了</code></pre><p>为了解决这个问题，我们可以利用Go的自定义类型特性，给ID加一层身份验证。这在编译阶段就能帮我们发现错误。</p><pre><code class="go">type UserID int64
type OrderID int64

func ProcessOrder(uid UserID, oid OrderID) {
    fmt.Printf("处理用户 %d 的订单 %d\n", uid, oid)
}

func main() {
    var uid UserID = 1001
    var oid OrderID = 9527

    ProcessOrder(uid, oid) // 正确
    // ProcessOrder(oid, uid) // 编译错误：cannot use oid (variable of type OrderID) as type UserID
}</code></pre><p>这个简单的改动，几乎零成本地消除了ID混用的隐患。</p><h4>用函数选项模式（Functional Options）优化配置</h4><p>在Java中如果你需要创建一个复杂的对象，可能会用Builder模式。而在Go中，我们经常遇到初始化一个服务或组件时，有几十个配置项，但大部分都用默认值的情况。</p><p>如果写一个包含所有参数的 <code>NewServer</code> 函数，调用起来会非常麻烦；如果传入一个配置结构体，又需要定义一个很大的Struct。</p><p>这时候，<strong>函数选项模式</strong>就是最佳选择。</p><pre><code class="go">type Server struct {
    Host    string
    Port    int
    Timeout time.Duration
}

type Option func(*Server)

func WithHost(h string) Option {
    return func(s *Server) {
        s.Host = h
    }
}

func WithPort(p int) Option {
    return func(s *Server) {
        s.Port = p
    }
}

func NewServer(opts ...Option) *Server {
    // 默认配置
    server := &amp;Server{
        Host:    "localhost",
        Port:    8080,
        Timeout: 30 * time.Second,
    }
    
    // 应用选项
    for _, opt := range opts {
        opt(server)
    }
    
    return server
}

func main() {
    // 使用默认配置
    s1 := NewServer()
    
    // 只修改端口
    s2 := NewServer(WithPort(9090))
    
    // 修改多个配置，清晰直观
    s3 := NewServer(WithHost("127.0.0.1"), WithPort(8888))
}</code></pre><p>这种模式让初始化的代码变得非常灵活，而且未来增加新的配置项时，不需要修改现有的调用代码，兼容性极好。</p><h4>用反引号（Raw String Literals）优雅处理多行文本</h4><p>在代码中拼接SQL语句或者JSON字符串时，使用双引号往往需要大量的转义字符 <code>\</code>，写起来麻烦，读起来也费劲。</p><p>Go语言原生支持反引号 <code> ` </code> 来定义原生字符串，所见即所得。</p><pre><code class="go">func main() {
    // 以前的方式，难以阅读
    jsonStr := "{\n" +
               "  \"name\": \"Alice\",\n" +
               "  \"age\": 30\n" +
               "}"

    // 使用反引号，清晰明了
    jsonNew := `
{
  "name": "Alice",
  "age": 30
}
`
    fmt.Println(jsonNew)
}</code></pre><p>这在编写内嵌的SQL、HTML模板或者测试用的JSON数据时非常有用。</p><h4>用表格驱动测试（Table-Driven Tests）简化测试代码</h4><p>Go语言标准库非常推崇表格驱动测试。如果你还在写大量的 <code>if-else</code> 或者重复的测试逻辑，是时候改变一下了。</p><p>通过定义一个包含输入和期望输出的结构体切片，我们可以用一个循环覆盖所有的测试用例。</p><pre><code class="go">func Add(a, b int) int {
    return a + b
}

func TestAdd(t *testing.T) {
    tests := []struct {
        name string
        a    int
        b    int
        want int
    }{
        {"正数相加", 1, 2, 3},
        {"负数相加", -1, -1, -2},
        {"零相加", 0, 0, 0},
    }

    for _, tt := range tests {
        t.Run(tt.name, func(t *testing.T) {
            if got := Add(tt.a, tt.b); got != tt.want {
                t.Errorf("Add() = %v, want %v", got, tt.want)
            }
        })
    }
}</code></pre><p>新增测试用例只需要在列表中加一行数据，逻辑与数据分离，非常易于维护。</p><h4>用 ErrGroup 并发处理任务</h4><p>Go的 <code>go</code> 关键字让并发变得很容易，但协调多个并发任务并处理错误却不简单。手动使用 <code>sync.WaitGroup</code> 和 <code>channel</code> 来收集错误会写出很多样板代码。</p><p><code>errgroup</code> 包（<code>golang.org/x/sync/errgroup</code>）能完美解决这个问题。</p><pre><code class="go">import (
    "context"
    "fmt"
    "golang.org/x/sync/errgroup"
)

func main() {
    g, _ := errgroup.WithContext(context.Background())
    
    urls := []string{"http://www.google.com", "http://www.bing.com"}

    for _, url := range urls {
        url := url // 注意闭包捕获问题（Go 1.22之前需要）
        g.Go(func() error {
            // 模拟请求
            fmt.Printf("Fetching %s\n", url)
            return nil // 或者返回错误
        })
    }

    // 等待所有任务完成，如果有任何一个返回错误，这里会返回那个错误
    if err := g.Wait(); err != nil {
        fmt.Println("出错了:", err)
    } else {
        fmt.Println("所有任务完成")
    }
}</code></pre><p>它能自动处理 <code>WaitGroup</code> 的计数，并且一旦有一个任务出错，可以取消其他任务（配合 Context），是处理并发任务的有效工具。</p><h4>管理好Go环境，才能高效开发</h4><p>看到这里，你可能意识到，Go的版本更新也非常快。从Go 1.11引入Module，到Go 1.18引入泛型，再到Go 1.22修复循环变量问题，每个版本都有重要的变化。在实际工作中，我们经常面临这样的场景：</p><ul><li>维护的老项目还在用Go 1.20。</li><li>新开发的服务要用Go 1.25。</li><li>想体验最新的Go 1.26 RC版本。</li></ul><p>在本地同时管理多个Go版本，配置 <code>GOROOT</code>, <code>GOPATH</code>，修改环境变量，是一件非常繁琐的事情。</p><p>所以，这时候就需要ServBay。</p><p>虽然它常被认为是Web开发工具，但它对Go语言的支持也非常出色。最让我满意的是，它可以<a href="https://link.segmentfault.com/?enc=YKEOXre5LQzvVs7UB2tUww%3D%3D.bYUf3pwyrimqNYsow2VbmKzrq4jF2FSvXxXGG4%2BfFqnEqPAzkZOYJq7iXrmh89C1" rel="nofollow" target="_blank">一键安装和管理多个Go版本</a>。你可以同时安装Go 1.20、1.23、1.26等多个版本，它们之间完全隔离，互不干扰。</p><p>而且，你可以为不同的项目指定使用不同的Go版本。比如，设置项目A使用Go 1.20，项目B使用Go 1.25。这样一来，在切换项目时，根本不用担心版本不兼容的问题，ServBay会自动处理好环境变量。</p><p>对于Go开发者来说，这意味着可以把更多精力放在架构设计和代码逻辑上，而不是被环境配置这些琐事消耗时间。</p><h3>总结</h3><p>Go语言虽然以简单著称，但写出地道的Go代码（Idiomatic Go）依然需要不断的积累。掌握这些技巧，可以让你的代码更加健壮、优雅。而借助像ServBay这样的工具，又能帮你轻松搞定环境管理，让你专注于创造价值。</p><p>你还有什么Go语言的开发技巧吗？欢迎在评论区分享交流。</p><p>如果你也对Go语言感兴趣，欢迎关注并私信我领取pdf面经资料，保证<strong>完全免费</strong>！</p>]]></description></item><item>    <title><![CDATA[开年捷报！拓数派入选第九届世界浙商上海论坛“金种子”企业，政商学界大咖共奔未来 OpenPie ]]></title>    <link>https://segmentfault.com/a/1190000047554975</link>    <guid>https://segmentfault.com/a/1190000047554975</guid>    <pubDate>2026-01-21 11:11:37</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>2026年开年之际，拓数派再添喜讯！在1月18日于上海国际会议中心盛大举行的第九届世界浙商上海论坛暨 2025 上海市浙江商会年会上，拓数派（OpenPie）凭借在数据计算核心技术领域的深耕实力与高成长潜力，成功入选 2026 年度 “金种子” 企业名单，以硬核创新开启新年新篇。拓数派创始人兼CEO冯雷受邀出席本次大会并参加“金种子”企业颁奖仪式。 </p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047554977" alt="图片" title="图片"/><br/>大会现场盛况</p><p>作为中国商界极具影响力的盛会之一，大会现场星光熠熠，搭建起政、商、学、研深度对话的高端平台。大会规模空前，近 2000 位各界嘉宾齐聚一堂，上海市委常委、统战部部长陈通，浙江省委常委、统战部部长王文序，全国工商联副主席、上海市政协副主席、市工商联主席、市总商会会长寿子琪，中国商飞副董事长、总经理、党委副书记沈波，青浦区委书记王平，绍兴市委书记施惠芳，全国政协常委、浙江省工商联主席、浙商总会会长、正泰集团董事长南存辉等政府领导，为浙商发展指明方向、鼓劲加油；<br/> <br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047554978" alt="图片" title="图片" loading="lazy"/></p><p> 除了政商两届的鼎力支持，本次论坛更凸显了“科技”底色。中国工程院院士、同济大学党委书记郑庆华，中国科学院院士、中科大杭州高研院院长王建宇，量子物理学家、世界青年科学家联合会理事长陆朝阳等顶尖专家学者，带来前沿科技的深度洞察；更有复星国际董事长郭广昌、上海钢联董事长朱军红、华测导航董事长赵延平、纵横股份董事长任斌、飞书 CEO 谢欣等知名企业家，分享创新实践与发展智慧。<br/> <br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047554979" alt="图片" title="图片" loading="lazy"/></p><p> 在众多行业领军者、权威专家与政府领导的共同见证下，上海市浙江商会正式揭晓了第五届 “金名片” 企业与 2026 年度 “金种子” 企业名单。其中，“金名片” 奖表彰了 60 家在创新突破、匠心传承、品质引领和全球化布局等方面表现突出的会员企业，泰格医药、万丰科技、亚朵星球、罗曼股份、大众交通、东方泵业、复星旅文等知名企业纷纷上榜，集中展现了新时代浙商的实力与风采。 </p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047554980" alt="图片" title="图片" loading="lazy"/><br/>“金名片”企业名单发布现场</p><p>而 “金种子” 计划作为商会培育高成长性科技型企业的重要举措，聚焦量子科技、具身智能、纳米材料、生物医药等前沿赛道，通过资源对接、导师辅导、资本引荐等全方位支持，助力潜力企业加速成长。 </p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047554981" alt="图片" title="图片" loading="lazy"/><br/>“金种子”企业名单发布现场</p><p>如果说 “金名片” 企业是当下浙商群体的中坚力量，那么 “金种子” 企业便是浙商未来发展的希望所在。这些深耕前沿领域、怀揣创新梦想的企业，如同饱含生命力的种子，在政策支持与资源赋能的沃土中不断扎根生长，承载着延续浙商精神、引领产业升级的重要使命。拓数派深耕数据计算领域，凭借自主研发的核心产品：——大模型数据计算系统πDataCS，在“Data+AI”领域形成独特竞争优势，为金融、政务、制造等多个领域提供高效解决方案，正是 “金种子” 计划所倡导的科技创新型企业典范。此次入选“金种子”企业名单，既是对拓数派过往创新成果的认可，更是对未来发展潜力的期许。 </p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047554982" alt="图片" title="图片" loading="lazy"/><br/>左一为拓数派创始人兼CEO 冯雷（Ray Von)</p><p>未来，拓数派将以此次入选为契机，珍惜上海市浙江商会搭建的优质平台，持续深耕核心技术研发，强化创新驱动，在科技创新的赛道上勇毅 “奔” 进，与众多 “金种子” 伙伴一同成长，以实际行动诠释新时代科技企业的责任与担当，为浙商群体的持续辉煌、为中国经济的高质量发展注入更多动能！ </p>]]></description></item><item>    <title><![CDATA[艾体宝方案 | 构建高可靠、低延迟的智能驾驶车云协同中枢 艾体宝IT ]]></title>    <link>https://segmentfault.com/a/1190000047555002</link>    <guid>https://segmentfault.com/a/1190000047555002</guid>    <pubDate>2026-01-21 11:11:07</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><strong>摘要</strong><br/>随着智能网联汽车渗透率持续提升，以及相关监管体系与行业标准的逐步完善，车云协同平台正从“增值能力”演进为支撑安全运行与规模化发展的关键基础设施。</p><p>一方面，围绕事故事件数据记录（EDR）及关键信息管理，监管与行业规范对数据的完整性、时效性与可追溯性提出了更高要求；另一方面，面向高阶辅助驾驶与自动驾驶的应用场景，车端、边缘与云端之间的实时协同决策、安全预警与状态同步，对系统的低延迟、高可靠与跨地域架构能力提出了更高挑战。</p><p>传统依赖多种中间件拼装而成的烟囱式架构，在面对海量并发接入、跨区域数据同步以及毫秒级响应需求时，逐渐暴露出复杂度高、时延不可控、运维成本陡增等问题。</p><p>以 Redis 企业版作为统一、高性能的实时数据层与协同中枢，构建新一代智能驾驶车云协同平台，既能够稳健支撑监管与行业规范下的数据管理要求，也为实时安全预警、远程诊断、数字孪生及未来智能交通协同应用提供可持续演进的技术基础。</p><hr/><p><strong>一、核心挑战：从合规要求到业务高线</strong><br/>构建满足未来需求的车云协同平台，必须同时跨越三大挑战：</p><ul><li>挑战一：高可靠事故数据管理与上报能力<br/>在事故或异常事件发生后，关键数据需要被完整记录、可靠传输并可被及时调取或上报。任何数据丢失、延迟或一致性问题，都会对事故分析、责任认定及安全改进带来风险。这要求通信链路与数据平台具备电信级可靠性与端到端可追溯能力。</li><li>挑战二：亿级并发的“双向实时风暴”<br/>平台需管理百万甚至千万级车辆的同时在线连接，处理车辆高频上传的状态信息（如每秒数次的位置、电池数据），并实时下发指令（如预警、升级）。这是一个典型的高吞吐、低延迟、双向通信场景。</li><li>挑战三：“云-边-端”协同的“决策延迟”<br/>从边缘事件感知（如路侧单元 RSU 发现危险）到云端全局决策，再到车辆执行指令，整个闭环对时延极为敏感。例如，在协同安全预警场景中，过高的端到端延迟将显著降低风险规避效果。</li></ul><hr/><p><strong>二、Redis企业版：车云协同的实时数据基座</strong><br/>Redis企业版以其独特的技术特性，成为应对上述挑战的理想选择：</p><ul><li>高可靠、可扩展的通信总线：Redis Stream数据结构提供了基于消费者组的、持久化的消息队列，确保每一条事故上报消息的至少一次（或精确一次） 可靠投递。其性能远超传统消息队列（如RabbitMQ），且与发布/订阅（Pub/Sub） 模式结合，可灵活支撑指令的实时广播与点对点通信。</li><li>全球多活与毫秒级数据同步：Active-Active Geo-Distribution 功能支持跨地域多个数据中心的无冲突双向同步。这意味着在上海和法兰克福的数据中心可以同时写入和读取同一车辆的状态，并保持强一致性。这不仅提供了跨大洲的灾难恢复能力，更能让全球车辆就近接入，获得低于50毫秒的本地读写延迟。</li><li>多模型数据融合与实时查询：车辆数据多源异构。Redis企业版原生支持 JSON（存储复杂的车辆档案与状态）、时间序列（记录速度、电量等连续指标）、地理空间（实时追踪车辆位置）等多种数据结构。这使得一个平台即可替代传统的“消息队列+关系型数据库+缓存”组合，简化架构，并支持复杂的实时查询（如“找出某区域所有电量低于20%的物流车辆”）。</li><li>边缘智能赋能：Redis on Flash 与轻量级部署能力，使得在车端网关或区域边缘节点运行Redis实例成为可能。结合 RedisAI，可在边缘侧直接运行轻量模型，实现本地数据的实时预处理与关键事件（如驾驶员状态异常）的即时判断，仅将结果或高价值数据上传云端，大幅节省带宽并降低响应延迟。</li></ul><hr/><p><strong>三、一体化车云协同架构设计</strong><br/>该架构以 Redis 企业版为核心，贯通车端、边缘与云端，统一承载合规数据上报与实时协同能力。<br/><img width="723" height="655" referrerpolicy="no-referrer" src="/img/bVdnHoj" alt="image.png" title="image.png"/><br/>核心数据流与组件解析：</p><ol><li><p>高可靠事故与事件数据上报流</p><ul><li>车辆发生事故 → 车载终端将EDR数据包写入本地缓冲区 → 通过安全链路写入最近区域的Redis节点（使用Stream数据结构）→ 区域中心的后台服务（消费者组）立即消费该消息 → 进行数据验证、脱敏、格式转换 → 通过标准化接口对接监管系统或企业内部平台。整个过程基于Stream的持久化与确认机制，确保数据零丢失。</li></ul></li><li><p>车辆数字孪生实时镜像：</p><ul><li>每辆车的状态（如vehicle:VIN123:status）以一个JSON文档实时更新。其连续变化的位置（经纬度、海拔）同步存入一个时间序列，并通过 GEOADD 命令更新到地理空间索引集合中。</li><li>应用查询时，可毫秒级获取单车全貌，或通过 GEORADIUS 命令查询某地点周围所有车辆。这构成了车队管理、智能调度、动态保险等业务的实时数据基础。</li></ul></li><li><p>云边端协同安全预警流：</p><ul><li>边缘：路侧单元（RSU）通过本地RedisAI分析感知数据，发现异常（如路面遗撒物）。</li><li>云端：RSU将事件发布至云端Redis的预警频道（Pub/Sub）。云端实时事件处理引擎（RedisGears）被触发，立即查询地理空间索引，找出正在驶向该风险区域的车辆列表。</li><li>车端：预警指令通过 Pub/Sub 实时下发至相关车辆的通信频道。车辆终端订阅该频道，在百毫秒级内收到预警并提示驾驶员。</li></ul></li></ol><p><strong>四、关键场景与业务价值</strong><br/><img width="723" height="314" referrerpolicy="no-referrer" src="/img/bVdnHoi" alt="image.png" title="image.png" loading="lazy"/></p><p><strong>结语</strong><br/>面向智能驾驶与智能网联汽车的规模化发展，高可靠的数据管理能力是安全运行的基础，而“云-边-端”协同创新则是释放业务价值的关键。</p><p>2Redis 企业版凭借其极致性能、多活架构与多模型融合能力，为车云协同平台提供了一种同时兼顾监管适配性、实时性与系统演进能力的技术路径。选择 Redis 企业版，不仅是选择一个数据库，更是选择了一套能够伴随智能驾驶业务持续扩展与创新的实时数据基础设施。</p>]]></description></item><item>    <title><![CDATA[了解你的 AI 编码伙伴：Coding Agent核心机制解析 百度Geek说 ]]></title>    <link>https://segmentfault.com/a/1190000047555007</link>    <guid>https://segmentfault.com/a/1190000047555007</guid>    <pubDate>2026-01-21 11:10:07</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>导读</h2><p>AI 编码工具正在从"智能补全"演进为能自主完成复杂任务的 Coding Agent。本文基于开源项目源码研究与实践经验，系统性地拆解 Coding Agent 的工作原理。旨在帮助开发者在了解Coding Agent后，与AI伙伴更好的协作配合，更高效的提问和拿到有效结果。</p><h2>01 背景</h2><p>AI 编码工具的发展速度快得有点"离谱"。从开始使用 GitHub Copilot 的代码补全，到使用Claude Code、Cursor、Comate IDE等完成复杂编程任务，AI 不再只是个「智能补全工具」，它能读懂你的代码库、执行终端命令、甚至帮你调试问题，成为你的“编码伙伴”。</p><p>我自己在团队里推 AI 编码工具的时候，发现一个很有意思的现象：大家都在用，但很少有人真正理解它是怎么工作的。有人觉得它"很神奇"，有人吐槽它"经常乱来"，还有人担心"会不会把代码搞乱"。这些困惑的背后,其实都指向同一个问题：我们对这个"伙伴"还不够了解。</p><p>就像你不会无脑信任一个新来的同事一样，要和 AI 编码伙伴配合好，你得知道它的工作方式、能力边界、以及怎么"沟通"才更有效。</p><p>在经过多次的实践尝试后，我尝试探索它的底层原理，并写下了这篇文章记录，主要围绕了这些内容展开：</p><ul><li>Coding Agent 的核心工作机制，包括身份定义、工具调用、环境感知等基础组成。</li><li>从零实现一个最小化 Coding Agent 的完整过程，以建立对 Agent 工作流程的直观理解。</li><li>上下文管理、成本控制、冲突管控等生产环境中的关键技术问题及其解决方案。</li><li>Rule、MCP、Skill 等能力扩展机制的原理与应用场景。</li></ul><p>在了解原理后，我和伙伴的协作更佳顺畅，让伙伴更清晰的了解我的意图，我拿到有效的回答。</p><h2>02 概念</h2><h3><strong>2.1 从Workflow到Agent</strong></h3><p>取一个实际的例子：休假申请。</p><p>如果我们的需求非常简单：</p><blockquote>一键申请明天的休假。</blockquote><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555009" alt="在这里插入图片描述" title="在这里插入图片描述"/></p><p>这个需求可以被简化为一个<strong><em><em>固定的工作流</em></em></strong>：</p><ol><li>打开网页。</li><li>填写起始时间。</li><li>填写结束时间。</li><li>填写休假原因。</li><li>提交表单。</li></ol><p>全过程<strong><em><em>没有任何模糊的输入</em></em></strong>，使用程序化即可完成，是最原始的工作流形态。</p><p>如果需求再模糊一些：</p><blockquote>申请后天开始3天休假。</blockquote><p>这个需求的特点是没有明确的起始和截止时间，<strong><em><em>需要从语义上分析出来</em></em></strong>：</p><ol><li>起始时间：后天。</li><li>休假时长：3天。</li><li>转换日期：10.14 - 10.16。</li><li>执行申请：提交表单。</li></ol><p>这是一个<strong><em><em>工作流中使用大模型提取部分参数</em></em></strong>的典型案例，是模型与工作流的结合。</p><p>如果需求更加模糊：</p><blockquote>国庆后休假连上下个周末。</blockquote><p>这样的需求<strong><em><em>几乎没有任何直接确定日期的信息</em></em></strong>，同时由于年份、休假安排等动态因素，<strong><em><em>大模型不具备直接提取参数的能力</em></em></strong>。将它进一步分解，需要一个<strong><em><em>动态决策、逐步分析</em></em></strong>的过程：</p><ol><li>知道当前年份。</li><li>知道对应年份的国庆休假和调休安排。</li><li>知道国庆后第一天是星期几。</li><li>国庆后第一天到下个周末设为休假日期。</li><li>额外补充调休的日期。</li><li>填写并提交表单。</li></ol><p>可以看出来，其中1-5步都是用来最终确定休假日期的，且需要<strong><em><em>外部信息输入</em></em></strong>，单独的大模型无法直接完成工作。这是一个典型的<strong><em><em>Agent流程</em></em></strong>，通过<strong><em><em>大模型的智能</em></em></strong>与<strong><em><em>工具访问外部信息</em></em></strong>结合实现用户需求。</p><h3><strong>2.2 什么是Agent</strong></h3><p>Agent是以<strong><em><em>大模型为核心</em></em></strong>，为<strong><em><em>满足用户的需求</em></em></strong>，使用一个或多个<strong><em><em>工具</em></em></strong>，自动进行<strong><em><em>多轮模型推理</em></em></strong>，最终得到结果的工作机制。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555010" alt="" title="" loading="lazy"/></p><h3><strong>2.3 什么是Coding Agent</strong></h3><p>在Agent的基本定义的基础上，通过提示词、上下文、工具等元素强化“编码”这一目的，所制作的特化的Agent即为Coding Agent。</p><p>Coding Agent的最大特征是在<strong><em><em>工具的选取</em></em></strong>上，模拟工程师进行代码编写的环境，提供一套<strong><em><em>完整的编码能力</em></em></strong>，包括：</p><ul><li><p>阅读和查询代码：</p><ul><li>读取文件，对应 <code>cat</code> 命令。</li><li>查看目录结构，对应 <code>tree</code> 命令。</li><li>通配符查找，对应 <code>ls</code>命令（如 <code>**/*.test.ts</code> 、<code>src/components/**/use*.ts</code>）。</li><li>正则查找，对应<code>grep</code> 命令（如<code>function print\(.+\)</code> 可以找函数定义）。</li><li>LSP（Language Server Protocol），用于提供查找定义、查找引用、检查代码错误等能力。</li></ul></li><li><p>编写或修改代码：</p><ul><li>写入文件。</li><li>局部编辑文件。</li><li>删除文件。</li></ul></li><li><p>执行或交互命令：</p><ul><li>执行终端命令。</li><li>查看终端命令<code>stdout</code>输出。</li><li>向终端命令<code>stdin</code> 输入内容。</li></ul></li></ul><p>除此之外，通常Coding Agent还具备一些强化效果而设定的工具，通常表现为与Agent自身或外部环境进行交互，例如经常能见到的TODO、MCP、Subagent等等。</p><h2>03 内部组成</h2><h3><strong>3.1 上下文结构</strong></h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555011" alt="" title="" loading="lazy"/></p><h3><strong>3.2 身份定义</strong></h3><p>一个Agent首先会将模型定义成一个具体的身份（红色与橙色部分），例如在社区里常见的这样的说法：</p><blockquote>You are a Senior Front-End Developer and an Expert in React, Nexts, JavaScript, TypeScript, HTML, <strong><em><em>CSS</em></em></strong> and modern UI/UX <strong><em><em>frameworks</em></em></strong>.</blockquote><p>在身份的基础上，再附加工作的目标和步骤拆解，比如Cline有类似这样的内容：</p><p><a href="https://link.segmentfault.com/?enc=3z0367FvIzmWFhABNYac%2FA%3D%3D.AtSHOd%2F2dOjZYtnXUDWucj5X8gsqxKRWhoC3pW7AVu%2BHrQ21v%2FJnkKWx5a0%2FRqJ45RlCdOY%2FlxQwAg9Ak6ul7owcZxF03bwWfNhLwCw5HRTR3FV%2BY0WYXu0hVzauWHnz5kg40qaw9BH2aMBM4DGrV5VmoS7q3gpEQiR5kCz99PmCp8pQQM6Lbl7XHw6nZd81" rel="nofollow" target="_blank">https://github.com/cline/cline/blob/4b9dbf11a0816f792f0b3229a08bbb17667f4b73/src/core/prompts/system-prompt/components/objective.ts</a></p><ol><li>Analyze the user's task and set clear, achievable goals to accomplish it. Prioritize these goals in a logical order.</li><li>Work through these goals sequentially, utilizing available tools one at a time as necessary. Each goal should correspond to a distinct step in your problem-solving process. You will be informed on the work completed and what's remaining as you go.</li><li>Remember, you have extensive capabilities with access to a wide range of tools that can be used in powerful and clever ways as necessary to accomplish each goal. Before calling a tool, do some analysis within <code>&lt;thinking&gt;&lt;/thinking&gt;</code> tags. First, analyze the file structure provided in <code>environment_details</code> to gain context and insights for proceeding effectively. Then, think about which of the provided tools is the most relevant tool to accomplish the user's task. Next, go through each of the required parameters of the relevant tool and determine if the user has directly provided or given enough information to infer a value. When deciding if the parameter can be inferred, carefully consider all the context to see if it supports a specific value. If all of the required parameters are present or can be reasonably inferred, close the thinking tag and proceed with the tool use. BUT, if one of the values for a required parameter is missing, DO NOT invoke the tool (not even with fillers for the missing params). DO NOT ask for more information on optional parameters if it is not provided.</li><li>Once you've completed the user's task, you must use the attempt_completion tool to present the result of the task to the user. You may also provide a CLI command to showcase the result of your task; this can be particularly useful for web development tasks, where you can run e.g. <code>open index.html</code> to show the website you've built.</li><li>The user may provide feedback, which you can use to make improvements and try again. But DO NOT continue in pointless back and forth conversations, i.e. don't end your responses with questions or offers for further assistance.</li></ol><p>不用特别仔细地看每一句话，多数Coding Agent会提供一些详实的行动准则、目标要求，这部分称为“Guideline”。</p><p>有一些Coding Agent可以在多种模式（或者说智能体）之间进行切换，例如Cursor有Edit、Ask、Plan等，RooCode有Architect、Orchestrator等，有些产品还支持自定义模式。</p><p>Cursor</p><p>RooCode</p><p>选择不同的模式时，实际上会产生不同的目标要求、行为准则，即不同的Guideline环节。因此系统提示词中的身份部分，通常会分成不变的Base Prompt（红色）和可变的Agent Prompt（橙色）两个部分来管理，实际开始任务时再拼装起来。</p><h3><strong>3.3 工具调用</strong></h3><p>Agent的另一个最重要的组成部分是工具，没有工具就无法称之为一个Agent。让Agent能够使用工具，就必须要有2部分信息：</p><ol><li>有哪些工具可以用，分别是什么作用。</li><li>如何指定使用一个工具。</li></ol><p>对于第一点（哪些工具），在Agent开发过程中，一般视一个工具为一个<strong><em><em>函数</em></em></strong>，即由以下几部分组成一个工具的定义：</p><ol><li>名称。</li><li>参数结构。</li><li>输出结构。</li></ol><p>实际在调用模型时，“输了结构”往往是不需要提供给模型的，但在Agent的实现上，它依然会被预先定义好。而“名称”和“参数结构”会统一组合成一个结构化的定义，通常所有工具都只接收1个参数（对象类型），用JSON Schema表示参数结构。</p><p>一个典型的工具定义：</p><pre><code>{
  "name": "read",
  "description": "Read the contents of a file. Optionally specify line range to read only a portion of the file.",
  "parameters": {
    "type": "object",
    "properties": {
      "path": {
        "type": "string",
        "description": "The file path to read from"
      },
      "lineStart": {
        "type": "integer",
        "description": "The starting line number (1-indexed). If not specified, reads from the beginning of the file."
      },
      "lineEnd": {
        "type": "integer",
        "description": "The ending line number (1-indexed). If not specified, reads to the end of the file."
      }
    },
    "required": ["path"]
  }
}</code></pre><p>可以简单地把这个工具理解成对应的TypeScript代码：</p><pre><code>interface ReadToolParameter {
        path: string;
        lineStart?: number;
        lineEnd?: number;
}

async function read(parameters: ReadToolParameter) {
        // 工具实现
}</code></pre><p>对于第2点（指定使用工具），则是要让大模型知道工具调用的具体格式。这在业界通常有2种做法。</p><p>第1种以Claud Code、Codex等为典型，使用大模型提供的Function Calling格式调用，分为以下几步：</p><ol><li>在调用大模型时，通过一个<code>tools</code> 字段传递所有的工具定义。</li><li>模型会返回一个消息中包含<code>tool_calls</code> 字段，里面每一个对象是一个工具的调用，使用<code>id</code> 作为唯一标识。</li><li>工具产生的结果，以一条<code>role: 'tool'</code> 的消息返回，其中<code>tool_call_id</code> 与调用的<code>id</code>对应，<code>content</code> 是工具的结果（这里各家模型厂商的实现略有不同，其中Anthropic要求<code>role: user</code>，但content字段中传递toolResult，其结构是<code>[{type: 'tool_result',tool_use_id: toolBlock.id, content: toolResultContent}]</code>,<code>tool_use_id</code>与调用的id对应）。</li></ol><p>第2种方式是以Cline、RooCode为典型，使用一种自定义的文本格式来表示工具调用，通常选择XML的结构，例如对于Cline，读取一个文件的结构如下：</p><pre><code>&lt;read_file&gt;
&lt;path&gt;src/index.ts&lt;/path&gt;
&lt;/read_file&gt;</code></pre><p>只要在模型返回的消息中出现这样的结构，就会被解析为一个工具调用，得到的结果以普通的<code>role: 'user'</code> 的消息返回，包括实际内容和一些提示相关的信息。</p><pre><code>Content of src/index.ts:

Note:

- this file is truncated to line 1000, file has a total 2333 lines.
- use read_file with line_start and line_end parameters to read more content.
- use seach_in_files tool searching for specific patterns in this file.

...</code></pre><h3><strong>3.4 环境感知</strong></h3><p>Coding Agent之所以可以在一个代码库上执行任务，除了通过工具来遍历、检索代码外，另一个因素是Agent实现会在调用模型时<strong><em><em>主动地</em></em></strong>提供一部分与项目有关的信息。</p><p>其中对Coding Agent工作最有用的信息之一是代码库的结构，即一个表达出目录、文件结构的树型区块。这部分信息通常会符合以下特征：</p><ol><li>尽可能地保留目录的层级结构，使用换行、缩进的形式表达。</li><li>遵循 <code>.gitignore</code> 等项目配置，被忽略的文件不会表现在树结构中。</li><li>当内容过多时，有一定的裁剪的策略，但同时尽可能多地保留信息。</li></ol><p>以Cursor为例，这部分的内容大致如下：</p><pre><code>&lt;project_layout&gt;
Below is a snapshot of the current workspace's file structure at the start of the conversation. This snapshot will NOT update during the conversation. It skips over .gitignore patterns.

codex-cursor/
  - AGENTS.md
  - CHANGELOG.md
  - cliff.toml
  - codex-cli/
    - bin/
      - codex.js
      - rg
    - Dockerfile
    - package-lock.json
    - package.json
    - scripts/
      - build_container.sh
      - build_npm_package.py
      - init_firewall.sh
      - [+4 files (1 *.js, 1 *.md, 1 *.py, ...) &amp; 0 dirs]
  - codex-rs/
    - ansi-escape/
      - Cargo.toml
      - README.md
      - src/
        - lib.rs
&lt;/project_layout&gt;</code></pre><p>当内容数量超过阈值时，会采用<strong><em><em>广度优先</em></em></strong>的保留策略（即尽可能地保留上层目录结构），同时对于被隐藏的文件或子目录，会形如 <code>[+4 files (1 *.js, 1 *.md, 1 *.py, ...) &amp; 0 dirs]</code>这样保留一个不同文件后缀的数量信息。</p><p>除了目录结构外，还有一系列<strong><em><em>默认需要模型感知</em></em></strong>的信息，在一个Coding Agent的工作环境中，它通常分为2大类，各自又有一系列的细项：</p><ol><li><p>系统信息：</p><ol><li>操作系统（Windows、macOS、Linux，具体版本）。</li><li>命令行语言（Shell、Powershell、ZSH）。</li><li>常见的终端命令是否已经安装（ <code>python3</code> 、<code>node</code> 、<code>jq</code> 、<code>awk</code>等，包含具体版本）。</li><li>代码库目录全路径。</li></ol></li><li><p>为Agent扩展能力的信息：</p><ol><li>Rule（自动激活的部分）。</li><li>Skill（摘要描述部分）。</li><li>MCP（需要的Server和Tool列表）。</li><li>Memory（通常是全量）。</li></ol></li></ol><p>需要注意的是，环境信息这部分，<strong><em><em>一般不出现在系统提示词中，而是和用户提问的消息放置在一起。</em></em></strong></p><h3><strong>3.5 简单实现</strong></h3><p>在身份定义、工具调用、环境感知这3部分最基础的Agent组成都达成后，简单地使用大模型的API，进行自动化的工具调用解析、执行、发送新一轮模型调用，可以非常简单地实现一个最小化的Coding Agent。</p><p>可以尝试用以下的提示词，使用任意现有的Coding Agent产品，为你编写一个实现，并自己调试一下，感受Coding Agent的最基础的逻辑：</p><pre><code>我希望基于大模型实现一个Coding Agent，以下是我的具体要求：

1. 使用Claude作为模型服务商，使用环境变量管理我的API Key。
2. 默认使用Claude Sonnet 4.5模型。
3. 使用Anthropic's Client SDK调用模型。
4. 不需要支持流式输出。
5. 使用TypeScript编写。

以下是Agent提供的工具：

1. read({path: string})：读取一个文件的内容
2. list({directory: string})：列出一个目录下的一层内容，其中目录以`/`结尾
3. write({path: string, content: string})：向文件写入内容
4. edit({path: string, search: string, replace: string})：提供文件中的一块内容

以下是交互要求：

1. 通过NodeJS CLI调用，支持`query`和`model`两个参数，可以使用`yargs`解析参数。
2. 在System消息中，简短地说明Coding Agent的角色定义、目标和行为准则等。
3. 在第一条User消息中，向模型提供当前的操作系统、Shell语言、当前目录绝对路径信息，同时包含跟随`query`参数的内容，组织成一条模型易于理解的消息。
4. 对每一次模型的工具调用，在控制台打印工具名称和标识性参数，其中标识性参数为`path`或`directory`，根据工具不同来决定。
5. 如果模型未调用工具，则将文本打印到控制台。

请在当前目录下建立一个`package.json`，并开始实现全部的功能。</code></pre><h2>04 优质上下文工程</h2><h3><strong>4.1 成本控制</strong></h3><p>大模型是一个非常昂贵的工具，以Claude为例，它的官方API价格如下：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555012" alt="" title="" loading="lazy"/></p><p>我们可以观察到一些特征：</p><ol><li>输出的价格是输入的5倍（但实际考虑到输出与输出的数量比例，输出的价格根本不值一提）。</li><li>缓存输入（Cache Writes）比正常输入（Base Input）更贵一些，约1.25倍。</li><li>缓存命中（Cache Hits）的价格比正常输入（Base Input）要便宜很多，为1/10的价格。</li></ol><p>这就意味着，<strong><em><em>一个良好使用缓存的Agent实现，其成本会比不用缓存降低8-10倍</em></em></strong>。因此所有的Coding Agent一定会<strong><em><em>细致地梳理内容结构，最大化利用缓存</em></em></strong>。</p><p>在大模型的API中，缓存通常以“块”为单位控制，例如：</p><ol><li>系统提示词中不变的部分。</li><li>系统提示词中可变部分。</li><li>工具定义。</li><li>每一条消息，单条消息也可以拆成多个块。</li></ol><p>继续观察Claude对于缓存控制的文档：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555013" alt="" title="" loading="lazy"/></p><p>可以看到，在大模型API中各种参数一但有所变动，缓存都会大量失效（至少消息缓存全部失效，大概率系统缓成失效），这就会造成成本的极大提升。因此，在Coding Agent实现中，都会<strong><em><em>从一开始就确定所有参数，整个任务不做任何变更</em></em></strong>。一些很经典的实例：</p><ol><li>一次任务不会一部分消息开思考模式，一部分不开，因为思考参数会让全部的消息缓存失效。</li><li>切换不同模式（如Edit、Ask、Plan）时，虽然能使用的工具不同，但只是在消息中增加说明，而不会真的将 <code>tools</code> 字段改变。</li></ol><p>另外，Coding Agent会<strong><em><em>尽可能保持历史消息内容完全不变</em></em></strong>，以最大化地缓存消息。例如对于一个进行了10轮模型调用的任务，理论上第10次调用中，前9轮的消息内容都会命中缓存。但如果此时擅自去修改了第1轮的工具调用结果（例如试图删除读取的文件内容），看似可能消息的长度减少了，但实际因为缓存被破坏，造成的是10倍的成本提升。</p><p>总而言之，<strong><em><em>缓存是一个至关重要的因素，Coding Agent的策略优化通常以确保缓存有效为前提，仅在非常必要的情况下破坏缓存</em></em></strong>。</p><h3><strong>4.2 空间管理</strong></h3><p>Coding Agent因为会自动地与大模型进行多轮的交互，随着不断地读入文件、终端命令输出等信息，上下文的长度会变得非常的大，而大模型通常只具备128K左右的总长度，因此如何将大量内容“适配”到有限的长度中，是一个巨大的挑战。</p><p>控制上下文长度的第一种方式是“<strong><em><em>裁剪</em></em></strong>”，即在整个上下文中，将没用的信息删除掉。试想如下的场景：</p><ol><li>模型读取了一个文件的内容。</li><li>模型将文件中 <code>foo</code> 这一行改成了 <code>bar</code> 。</li><li>模型又将文件中 <code>eat</code> 这一行改成了 <code>drink</code> 。</li></ol><p>假设我们对模型每一次修改文件，都<strong><em><em>返回最新的文件内容</em></em></strong>，如果这个文件有1000行，那么1次读取、2次修改，就会<strong><em><em>产生3000行的空间占用</em></em></strong>。</p><p>一种优化方式就是，在这种<strong><em><em>连续</em></em></strong>的读-改的场景下，只保留最后一条消息中有全文内容，即上述3次模型调用后，出现在上下文中的内容实际是这样的：</p><pre><code>&lt;!-- Assistant --&gt;
read(file)

&lt;!-- User --&gt;
[This file has been updated later, outdated contents are purged from here]

&lt;!-- Assistant --&gt;
edit(file, foo -&gt; bar)

&lt;!-- User --&gt;
The edit has been applied successfully.

--- a/file
+++ b/file
@@ -23,1 +23,1 @@
-foo
+bar

[This file has been updated later, outdated contents are purged from here]

&lt;!-- Assistant --&gt;
edit(file, eat -&gt; drink)

&lt;!-- User --&gt;
The edit has been applied successfully, the new file content is as below:
</code></pre><p>{content of file}</p><p>可以看到，通过<strong><em><em>将连续对同一文件的修改进行裁剪</em></em></strong>，可以只保留最新的内容，同时又使用<code>unidiff</code> 之类的形式保留中间编辑的差异信息，最大限度地降低空间占用，又能保留模型的推理逻辑。</p><p>但裁剪<strong><em><em>不能使用在非连续的消息中</em></em></strong>，随意地使用剪裁逻辑，很有可能<strong><em><em>破坏消息缓存结构</em></em></strong>，进而使模型调用的输入无法通过缓存处理，几倍地增加模型的调用成本。</p><p>即便裁剪有一定效果，但随着更多的内容进入到上下文中，始终会有将上下文占满的时候，此时模型将完全无法进行推理。为了避免这种情况出现，Coding Agent通常会使用“<strong><em><em>压缩</em></em></strong>”这一技术，即将前文通过模型摘要成少量的文字，同时又保留比较关键的推理链路。</p><p>通常，压缩在上下文即将用完的时候触发，如已经使用了90%的上下文则启动压缩，压缩的目标是将90%的内容变为10%的长度，即省出80%的空间供后续推理。</p><p>压缩本身是一个模型的任务，即将所有的上下文（可以选择性地保留最新的1-2对消息）交给模型，同时附带一个压缩的要求，让模型完成工作。这个压缩的要求的质量将决定压缩的最终结果，一个比较典型的实现是Claude Code的“八段式摘要”法：</p><pre><code>const COMPRESSION_SECTIONS = [
  "1. Primary Request and Intent",    // 主要请求和意图
  "2. Key Technical Concepts",        // 关键技术概念
  "3. Files and Code Sections",       // 文件和代码段
  "4. Errors and fixes",              // 错误和修复
  "5. Problem Solving",               // 问题解决
  "6. All user messages",             // 所有用户消息
  "7. Pending Tasks",                 // 待处理任务
  "8. Current Work"                   // 当前工作
];</code></pre><p>通过将信息压缩成8部分内容，能够最大限度地保留工作目标、进度、待办的内容。</p><h3><strong>4.3 独立上下文</strong></h3><p>在实际的应用中，其实大概率是不需要128K上下文用满的，但真实表现又往往是<strong><em><em>上下文不够用</em></em></strong>。这中间存在的差异，在于2类情况：</p><ol><li>为了满足一个任务，需要收集大量的信息，但收集到正常信息的过程中，会引入无效的、错误的内容，占用上下文。</li><li>一个任务足够复杂，分解为多个小任务后各自占用部分上下文，但加起来以后会超出限制。</li></ol><p>试想一下，对于一个这样的任务：</p><blockquote>修改我的Webpack配置，调整文件拆分逻辑，让最终产出的各个JS文件大小尽可能平均。</blockquote><p>但是很“不幸”地，这个项目中存在6个 <code>webpack.config.ts</code>文件，且最终<code>splitChunks</code> 配置在一个名为 <code>optimization.ts</code> 的文件中管理，那么对于Coding Agent来说，这个任务中就可能存在大量无意义的上下文占用：</p><ol><li>读取了6个 <code>webpack.config.ts</code> ，一共2000行的配置内容，但没有任何<code>splitChunks</code> 的配置，包含了大量 <code>import</code> 其它模块。</li><li>又读取了10个被 <code>import</code> 的模块，最终找到了 <code>optimization.ts</code> 文件。</li><li>经过修改后，执行了一次 <code>npm run build</code> 来分析产出，发现JS的体积不够平均。</li><li>又修改 <code>optimization.ts</code> ，再次编译，再看产出。</li><li>循环往复了8次，终于在最后一次实现了合理的<code>splitChunks</code> 配置。</li></ol><p>这里面的“6个 <code>webpack.config.ts</code> ”、“10个其它模块”、“8次优化和编译”都是对任务最终目标并不有效的内容，如果它们占用150K的上下文，这个任务就不得不在中途进行1-2次的压缩，才能够最终完成。</p><p>为了解决这个问题，当前多数的Coding Agent都会有一个称为“<strong><em><em>Subagent</em></em></strong>”的概念。就好比一个进程如果只能使用4GB的内存，而要做完一件事需要16GB，最好的办法就是开5个进程。Subagent是一种<strong><em><em>类似子进程的，在独立的上下文空间中运行，与主任务仅进行必要信息交换的工作机制</em></em></strong>。</p><p>再回到上面的案例，在Subagent的加持下，我们可以将它变成以下的过程：</p><ol><li><p>启动一个Subagent，给定目标“找到Webpack文件拆分的代码”。</p><ol><li>读取6个 <code>webpack.config.ts</code> 。</li><li>读取10个被 <code>import</code> 的模块。</li><li>确定目标文件 <code>optimization.ts</code> 。</li><li>返回总结：在 <code>optimization.ts</code> 中有文件拆分的配置，当前配置为……。</li></ol></li><li><p>启动一个Subagent，给定目标“修改 <code>optimization.ts</code> ，使产出的JS体积平均，执行 <code>npm run build </code>并返回不平均的文件“。</p><ol><li>修改 <code>optimization.ts</code>。</li><li>执行 <code>npm run build</code>，得到命令输出。</li><li>分析输出，找到特别大的JS文件，返回总结：配置已经修改，当前 <code>xxx.js</code> 体积为平均值的3倍（723KB），其它文件体积正常。</li></ol></li><li><p>启动一个Subagent，给宝目标“分析 <code>dist/stats.json</code>，检查 <code>xxx.js</code> 中的模块，修改 <code>optimization.ts</code> 使其分为3个250KB左右的文件，执行 <code>npm run build</code>并返回不平均的文件”。</p><ol><li>……</li><li>……</li></ol></li><li>继续启动6次Subagent，直到结果满意。</li></ol><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555014" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555015" alt="" title="" loading="lazy"/></p><p>不难看出来，这种模式下主体的Coding Agent实际是在"<strong><em><em>指挥</em></em></strong>"<strong><em><em>Subagent做事</em></em></strong>，自身的上下文占用是非常有限的。而Subagent仅<strong><em><em>“专注”于一个小目标</em></em></strong>，也不需要太多的上下文，最终通过这类不断<strong><em><em>开辟新上下文空间</em></em></strong>的方式，将一个复杂的任务完成。</p><h3><strong>4.4 注意力优化</strong></h3><p>如果你经常使用Coding Agent，或在业界早期有过比较多的使用经验，你可能会发现这种情况：Coding Agent在完成一个任务到一半时，忘了自己要做什么，草草地结束了任务，或偏离了既定目标产生很多随机的行为。</p><p>会发生这样的情况，有一定可能是裁剪、压缩等策略使有效的上下文信息丢失了，但更多是因为简单的一个用户需求被大量的代码内容、命令输出等推理过程所掩盖，权重弱化到已经不被大模型“注意到”，因此最初的目标也就完全丢失了。</p><p>Coding Agent一个很重要的任务，就是在长时间运作的同时随时调整大模型的注意力，使其始终聚焦在最终目标、关注当前最需要做的工作，不要偏离预先设定的路线。为了实现这一效果，Coding Agent产品提出了2个常见的概念。</p><p>第一称为<strong><em><em>TODO</em></em></strong>，在很多的产品中，你会看到Agent先将任务分解成几个步骤，转为一个待办列表。这个列表在界面上始终处于固定的位置，随着任务的推进会逐步标记为完成。这个TODO实际上<strong><em><em>并不是给用户看的，而是给模型看的</em></em></strong>。</p><p>在实际的实现中，每一次调用模型时，在最后一条消息（一般就是工具调用的结果）上，除了原始消息内容外，会增加一个称为“Reminder”的区域。这个区域因为始终出现在所有消息的最后，通常来说在模型的注意力中优先级更高，而且<strong><em><em>绝对不会受其它因素影响而消失</em></em></strong>。</p><p>Reminder中可以放置任意内容，比较经典的有：</p><ol><li>TODO及进度。用于模型时刻理解目标、进展、待办。</li></ol><pre><code>&lt;reminders&gt;
- Planned todos:
  - [x] Explore for code related to "print" function
  - [x] Add "flush" parameter to function
  - [ ] Refactor all "print" function calls to relect the new parameter
&lt;/reminders&gt;</code></pre><ol><li>工具子集。如前面《缓存》相关的描述，因为修改工具定义会使缓存失效，因此当切换模式使得可用的工具减少时，一般仅在Reminder中说明部分工具不可用，由模型来遵循这一约束，而不是直接删除部分工具。</li></ol><pre><code>&lt;!-- 切换至Ask模式 --&gt;
&lt;reminders&gt;
- You can ONLY use these tools from now on:
  - read
  - list
  - grep
  - bash
&lt;/reminders&gt;</code></pre><ol><li>行为指示。例如当模型连续多次给出名称、参数都一模一样的工具调用时，说明模型处在一种不合理的行为表现上，此时在Reminder中增加提示，让模型感知到当前状态的错误，就有可能调整并脱离错误的路线。</li></ol><pre><code>&lt;!-- Assistant --&gt;
read(file)

&lt;!-- User --&gt;
The file content: ...

&lt;!-- Assistant --&gt;
read(file)

&lt;!-- User --&gt;
The file content: ...

&lt;reminders&gt;
- Your are using read tool the second time with exactly the same parameters, this usually means an unexpected situation, you should not use this tool again in your response.
&lt;/reminders&gt;</code></pre><ol><li>状态提示。例如激活某一个Skill时，Reminder中可以提示“当前正在使用名为X的Skill“，这种提示可以让模型更加专注于完成一个局部的工作。</li></ol><pre><code>&lt;reminders&gt;
- You are currently working with the skill "ppt" active, be focused on this task until you quit with exit_skill tool.
&lt;/reminders&gt;</code></pre><p>需要额外注意的是，<strong><em><em>Reminder仅在最后一条消息中出现，当有新的消息时，旧消息上的Reminder会被移除</em></em></strong>。基于这一特征，我们知道<strong><em><em>Reminder是永远无法命中缓存的</em></em></strong>，因此Reminder部分的内容长度要有控制，避免造成过多的成本消耗。</p><h3><strong>4.5 冲突管控</strong></h3><p>随着Coding Agent能力的发展，当下执行的任务时间越来越长、编辑的文件越来越多，同时更多的用户也习惯于在Agent工作的同时自己也进行编码工作，甚至让多个Agent任务并发执行。这种“协同”形态下，不少用户曾经遇到过这样的问题：</p><blockquote>自己将Agent生成的代码做了一些修正，但之后Agent又把代码改了回去。</blockquote><p>这个现象的基本原因也很清楚，就是<strong><em><em>Agent并不知道你改动过代码</em></em></strong>。例如以下的过程使Agent读取并编辑了一个文件：</p><pre><code>&lt;!-- Assistant --&gt;
read(file)

&lt;!-- User --&gt;
The file content:
...
console.log('hello');
...
&lt;!-- Assistant --&gt;
edit(file, hello -&gt; Hello)

&lt;!-- User --&gt;
Edit has been applied successfully.</code></pre><p>这个时候，在模型见到的上下文中，这个文件中的代码显然是<code>console.log('Hello');</code> 。假设乃又将它改成了<code>console.trace('Hello');</code> ，后面模型依然会基于<code>.log</code> 来修改代码，用户看起来就是代码“改了回去”。</p><p>解决这种共同编辑文件的冲突，实际上有多种方法：</p><ul><li>加锁法。当Agent读取、编辑一个文件时，更新模型认知的文件内容的快照。当这个Agent再一次编辑这个文件时，读取文件当前的实际内容，和快照做比对，如果内容不一样，拒绝这一次编辑，随后要求Agent重新读取文件（更新快照与实际内容一致）再进行编辑。这是一种<strong><em><em>主流的做法</em></em></strong>，不过<strong><em><em>Agent实现上的细节比较重</em></em></strong>。</li></ul><pre><code>&lt;!-- Assistant --&gt;
edit(file, console.log...)

&lt;!-- User --&gt;
This edit is rejected, the file has been modified since your last read or edit, you should read this file again before executing any write or edit actions.

&lt;!-- Assistant --&gt;
read(file)

&lt;!-- User --&gt;
The file content: ...

&lt;!-- Assistant --&gt;
edit(file, console.trace...);</code></pre><ul><li>推送法。监听所有模型读取、编辑过的文件的变更，当文件发生变更时，在<strong><em><em>下一次模型调用</em></em></strong>时，不断通过Reminder区域追加这些变更，让模型“实时”地知道文件有所变化，直到文件被下一次读取。这种方式能<strong><em><em>让模型更早地感知变化</em></em></strong>，但<strong><em><em>推送信息可能过多</em></em></strong>，<strong><em><em>影响成本和推理速度。</em></em></strong></li></ul><pre><code>&lt;!-- Assistant --&gt;
run_command(ls)

&lt;!-- User --&gt;
The command output: ...

&lt;reminders&gt;
- These files have been modified since your last read or edit, you should read before write or edit to them:
  - file
  - file
  - ...
&lt;/reminders&gt;</code></pre><ul><li>隔离法。使用Git Worktree方案，直接让不同的Agent任务在文件系统上隔离，在一个独立的Git分支上并行工作，相互不受干扰。在任务完成后，用户检查一个任务的全部变更，在采纳时再合并回实际的当前Git分支，有冲突的由用户解决冲突。这种方法让Agent<strong><em><em>根本不需要考虑冲突问题</em></em></strong>，但缺点是<strong><em><em>系统资源占用高</em></em></strong>，且<strong><em><em>有合并冲突风险</em></em></strong>。</li></ul><p>文件编辑冲突只是一个比较常见的现象，实际上用户和Agent、多个Agent并行工作，可能造成的冲突还有很多种，例如：</p><blockquote>用户敲了半行命令 <code>ls -</code>，Agent直接在终端里敲新的命令 <code>grep "print" -r src</code>执行，导致最后的命令是 <code>ls -grep "print" -r src</code> ，是一个不合法的命令。</blockquote><p>终端的抢占也是一种冲突，但相对更容易解决，只要让每一个Agent任务独占自己的终端，永远不与用户、其它Agent任务相交叉即可。</p><h3><strong>4.6 持久记忆</strong></h3><p>我们都知道，模型是没有状态的，所以每一次Agent执行任务，对整个项目、对用户的倾向，都是从零开始的过程。这相当于<strong><em><em>历史经验无法积累</em></em></strong>，很多曾经调整过的细节、优化过的方向都会被重置。虽然可以通过比如Rule这样的方式去持久化这些“经验”，但需要用户主动的介入，使用成本是相对比较高的。</p><p>因此当前很多Coding Agent产品都在探索“记忆”这一能力，争取让Agent变得<strong><em><em>用的越多越好用</em></em></strong>。记忆这个话题真正的难点在于：</p><ol><li>如何触发记忆。</li><li>如何消费记忆。</li><li>什么东西算是记忆。</li></ol><p>首先对于“如何触发”这一问题，常见于2种做法：</p><ol><li>工具型。定义一个 <code>update_memory</code> 工具，将记忆作为一个字符串数组看待，工具能够对其进行增、删改，模型在任务过程中实时地决定调用。往往模型并不怎么喜欢使用这类工具，经常见于用户有强烈情感的描述时才出现，比如“记住这一点”、“不要再……”。</li><li>总结型。在每一次对话结束后，将对话全部内容发送给模型，并配上提示词进行记忆的提取，提取后的内容补充到原本记忆中。总结型的方案往往又会过度地提取记忆，将没必要的信息进行持久化，干扰未来的推理。</li><li>存储型。不进行任何的记忆整理和提取，而是将所有任务的原始过程当作记忆，只在后续“消费”的环节做精细的处理。</li></ol><p>然后在“如何消费”的问题下，也常见有几种做法：</p><ol><li>始终附带。记忆内容记录在文件中，Agent实现中将文件内容附带在每一次的模型请求中。即模型始终能看到所有的记忆，这无疑会<strong><em><em>加重模型的认知负担</em></em></strong>，也<strong><em><em>占用相当多的上下文空间</em></em></strong>，因为很多记忆可能是与当前任务无关的。</li><li>渐进检索。本身不带记忆内容到模型，但将记忆以文件系统的形式存放，Agent可以通过<code>read</code> 、<code>list</code>、<code>grep</code> 等工具来检索记忆。配合“存储型”的触发方式，能让全量的历史任务都成为可被检索的记忆。但这种方式要求模型有比较强的对记忆的认知，在正确的时刻去找相关的记忆。但往往因为<strong><em><em>根本不知道记忆里有什么</em></em></strong>，进而<strong><em><em>无法知道什么时候应该检索</em></em></strong>，最终几乎不触发检索。</li></ol><p>而最终的问题，“什么东西是记忆”，是当下Coding Agent最难以解决的问题之一。错误的、不必要的记忆甚至可能造成实际任务效果的下降，因此精确地定义记忆是Agent实现的首要任务。</p><p>通常来说，记忆会分为2种大的方向：</p><ol><li>事实型。如“使用4个空格作为缩进”、“不要使用<code>any</code> 类型“，这些都是事实。事实是无关任何情感、不带主观情绪的。</li><li>画像型。如”用户更喜欢简短的任务总结“就是一种对用户的画像。画像是单个用户的特征，并不一定与项目、代码、架构相关。</li></ol><p>在Coding Agent上，往往更倾向于对”事实型“的内容进行记忆，而不考虑用户画像型的记忆。</p><p>同时，从业界的发展，可以看到越来越多的模型厂商在从底层进行记忆能力的开发，如最近Google的Titan架构就是一种记忆相关的技术。可能未来某一天，Agent实现上已经不需要再关注记忆的逻辑与实现，模型自身将带有持久化的记忆能力。</p><h2>05 能力扩展</h2><p>在实际应用中,还需要一些机制来让Agent更好地适应特定的项目、团队和个人习惯。当前主流的Coding Agent产品都提供了Rule、MCP、Skill这三种扩展能力,它们各有侧重,共同构成了Agent的能力增强体系。</p><h3><strong>5.1 Rule</strong></h3><p>当面对业务的repo往往存在一些领域相关的知识而非模型的知识库中已有的内容，这些往往需要凭借老员工的经验或者读取大量代码库的信息进行总结后才能明白，这些内容便适合放到Rule中，作为静态的不会频繁改动的内容放入Environment Context中长期Cache。</p><p>好的Rule应当足够精简、可操作且范围明确，人看不懂的规则或者描述不清的规则模型是一定搞不定无法遵守的。</p><ul><li>将Rule控制在 500 行以内。</li><li><p>将较大的规则拆分为多个可组合的规则，采取按需的方式，按照 文件路径/关键场景 激活Rule；对于特定场景激活的Rule，采取编写<strong><em><em>索引的方式</em></em></strong>创建Rule，让模型渐进式激活，比如项目针对网络请求和错误处理相关做了项目维度的封装处理，但这种情况并不是每个文件ts/tsx文件都会遇到的诉求，比如在项目的rules目录下创建index.mdr（curso是.mdc文件），编写下面的激活的条件：</p><ul><li>需要进行API调用获取数据</li><li>处理异步操作的错误和加载状态</li></ul></li></ul><pre><code>
-   当编码涉及以下任一情况时，必须立刻阅读 \[08-api-error-handling.mdc\](mdr:.cursor/rules/08-api-error-handling.mdc)
    </code></pre><ul><li>提供具体示例或参考文件，针对xx情况正确的方式是\`code\`。</li><li>避免模糊的指导，比如交互式的东西模型交互不了，不需要写进去。</li><li>为了模型能够积极验证每次改动是否符合预期，告知模型改动后可以执行的正确的构建命令，以及某些自定义命令（比如自动化测试）引导模型在后台启动命令，在xx秒后读取日志文件的内容进行结果的判断。</li></ul><h3><strong>5.2 MCP</strong></h3><p>MCP(Model Context Protocol)是Anthropic提出的一种标准化的工具扩展协议，它允许开发者以统一的方式为Coding Agent添加新的能力。</p><p>与Rule的"声明式约束"不同，MCP是一种实时工具调用协议，即通过MCP server的方式进行连接，来扩展Agent可以做的事情。</p><p>一个典型的场景是集成外部服务。比如你的项目托管在GitHub上，可以让Agent直接访问GitHub实现创建Issue、查询PR状态、添加评论等功能：</p><pre><code>{
    "mcpServers": {
        "github": {
            "command": "npx",
            "args": ["-y", "@modelcontextprotocol/server-github"],
            "env": {
                "GITHUB_PERSONAL_ACCESS_TOKEN": "&lt;your-github-token&gt;"
            }
        }
    }
}</code></pre><p>配置好后，Agent就能在代码审查过程中自动创建Issue记录问题、查询相关PR的讨论、甚至根据代码变更自动生成commit message。</p><p>MCP的另一个优势是实现门槛低。一个MCP Server本质上就是一个标准输入输出的程序,它通过JSON-RPC协议与Agent通信，当模型需要外部能力的时候，调用MCP Server，而模型无需关心其内部代码实现，Agent只需要按照固定的协议去连接获取内容。</p><h3><strong>5.3 Skill</strong></h3><h4>5.3.1 什么是Skill</h4><p>随着模型能力的提升，使用Agent完成的任务复杂度逐渐增加，使用Coding Agent可以进行本地代码执行和文件系统完成跨领域的复杂任务。但随着这些Agent的功能越来越强大，我们需要更具可组合性、可扩展性和可移植性的方法，为它们配备特定领域的专业知识，因此Agent Skill作为一种为Agent扩展能力的标准诞生。Skill 将指令、脚本和资源的文件夹打包，形成专业领域的知识，Agent在初始化的时候会获取可用的Skills列表，并在需要的时候动态加载这些内容来执行特定任务。</p><p>随着 Skill 复杂性的增加，它们可能包含过多的上下文信息，无法放入单个配置文件中 <code>SKILL.md</code>，或者某些上下文信息仅在特定场景下才相关。在这种情况下，Skill可以在当前目录中bundle额外的文件，并通过文件名引用这些文件，这些额外的文件提供了更多详细信息，Coding Agent 可以根据需要选择浏览和查找这些信息。Skill 是<strong><em><em>渐进式触发</em></em></strong>的， 因此 <code>SKILL.md</code>中 <code>name</code>和 <code>description</code>很关键，这会始终存在于Agent的环境上下文中提供给模型，模型会根据这些描述信息来决定是否在当前任务中触发该Skill，当你明确希望使用某个Skill完成任务，可以在prompt中指定“使用xxxx Skill完成xx任务”。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555016" alt="" title="" loading="lazy"/></p><h4>5.3.2 Skill和代码执行</h4><p>LLM在很多任务上表现出色，但许多操作需要使用编写代码 -&gt; 代码执行的方式，带来更高效的操作、确定性的以及可靠性的结果。生成式的模型常常通过生成可执行代码的方式去验证/计算结果。</p><p>代码既可以作为可执行工具，也可以作为文档。Skill中应该明确让模型是应该直接运行脚本，还是应该将其作为参考信息读取到上下文中。</p><h4>5.3.3 如何创建Skill</h4><p>每个Skill由一个必需的 SKILL.md 文件和可选的bundle资源组成，Skill 应该只包含完成任务所需的信息。</p><pre><code>skill-name/
├── SKILL.md (必需)
│   ├── YAML frontmatter 元数据 (必需)
│   │   ├── name: (必需)
│   │   ├── description: (必需，这是 skill 的主要触发机制,帮助模型理解何时使用该 skil)
│   │   └── compatibility: (可选)
│   └── Markdown 说明 (必需)
└── bundle的资源 (可选)
    ├── scripts/          - 可执行代码 (Python/Bash/等)
    ├── references/       - 需要时加载到上下文的文档
    └── assets/           - 用于输出的文件 (模板、图标、字体等)</code></pre><p>举一个具体的例子，比如当我们需要进行批量项目的技术栈migrate，比如将less迁移postcss，中间涉及一系列的复杂步骤，比如：</p><ul><li>安装postcss以及postcss plugin的依赖</li><li>配置postcss的config</li><li>分析项目用到了哪些less varibale替换成css vars</li><li>删除mixin并替换</li><li>一系列的其他兼容less的语法转换...</li><li>替换文件后缀</li></ul><p>上面的工作可以通过清晰的流程描述，并配合脚本实现，因此可以作为一个Skill将经验变成可复制的，一个less-to-postcss的skill的结构：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555017" alt="" title="" loading="lazy"/></p><h4>5.3.4 Skill的使用</h4><p>人人都可以创建Skill，也可以让Agent来编写Skill，这是Skill非常便捷的地方。Skill通过instructions和code赋予Coding Agent新的能力。虽然这使其功能强大并有很高的自由度，但也意味着恶意SKill可能会在其使用环境中引入漏洞，诱使模型窃取数据并执行非预期操作。仅从可信来源安装Skill，如果无法确信来源可信，在使用前请务必进行彻底审核。</p><p>Skill的出现并不是替代MCP的出现，而是相互配合，在合适的场景下选取Skill或是MCP。某些任务Skill和MCP Server均可完成，但Skill通过执行代码的方式可以一次性加载完整流程，但MCP Server要经历多次查询和多轮对话往返，这种情况下Skill更为合适，但这不意味着绝对的优势，比如标准化文档创建这个典型的场景，创建PPT/Word/Excel在本地使用Skill即可完成，但数据的提供则需要借助MCP Server进行查询。因此Skill擅长的是在本地通过执行 <code>code</code>的方式完成复杂任务，在用户私有数据、动态数据查询这些情况下Skill就无法搞定了，这和用户的数据库以及隐私强关联，需要让模型无法感知在执行过程中的隐私信息，Skill能够与MCP Server互补完成更为复杂的流程。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555018" alt="" title="" loading="lazy"/></p>]]></description></item><item>    <title><![CDATA[艾体宝方案 | API 已经快了，系统为什么还是慢？ 艾体宝IT ]]></title>    <link>https://segmentfault.com/a/1190000047555032</link>    <guid>https://segmentfault.com/a/1190000047555032</guid>    <pubDate>2026-01-21 11:09:34</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在不少后端团队里，都发生过类似的场景：<br/>Redis 上线后，监控显示 API 核心查询耗时下降了 80%，但用户依旧抱怨接口“卡”“慢”“不稳定”。</p><p>于是问题开始在群里反复出现：</p><ul><li>是 Redis 集群不够大？</li><li>是云厂商网络抖动？</li><li>是流量高峰超出预期？<br/>直到真正拆开一次请求的完整生命周期，才会意识到一个事实：Redis 可能已经做到极致了，只是你把它用在了最不应当的位置。</li></ul><p><strong>一个被反复误解的事实</strong><br/>必须先说清楚一句话：<br/>Redis 并不能让一个设计本身就臃肿的 API 变快，它只会让问题暴露得更明显。</p><p>在微服务架构下，Redis 几乎成了“性能优化”的默认答案。只要接口慢，第一反应往往是：“加一层缓存”。<br/>但在真实生产环境中，API 的执行路径通常远比你想象得复杂。</p><pre><code>客户端
  ↓
API 网关
  ↓
鉴权 / 鉴权扩展
  ↓
参数校验 / 特性开关
  ↓
缓存查询
    ↓（未命中）
数据库查询 → 关联查询 → ORM 映射
  ↓
DTO 转换 / 序列化
  ↓
日志 / 监控 / Trace
  ↓
响应返回</code></pre><p>在这条链路里，Redis 只是其中极短的一段。如果你把注意力全部放在“Redis 查得够不够快”，那基本已经跑偏了。<br/>Redis 并不是瓶颈，但常常被用来背锅<br/>我们曾协助排查过一个典型系统：<br/>一个对外提供实时报表查询的金融 API，客户团队坚信性能问题出在 Redis。<br/>他们的监控面板显示：</p><ul><li>API 平均响应时间：380–450 ms</li><li>高峰期 P95 甚至逼近 700 ms</li></ul><p>但在引入分段 Trace 后，结果令人意外：</p><ul><li>Redis GET 操作：稳定在 2–4 ms</li><li><p>超过 85% 的耗时，发生在：</p><ul><li>鉴权拦截器</li><li>参数反序列化</li><li>ORM 对象构建</li><li>JSON 序列化与日志写入<br/>结论很直接：<br/>缓存很快，API 还是慢。<br/>这也是许多团队真正“顿悟”的时刻——<br/>Redis 没有失效，只是你让它介入得太晚了。</li></ul></li></ul><p><strong>为什么“加了 Redis”却几乎没加速？</strong><br/>归纳下来，问题通常集中在三个方面。</p><ol><li>缓存命中发生得太晚<br/>很多系统在设计时，把缓存当作“数据库前的一层挡板”，而不是请求生命周期的一部分。<br/>结果是：</li><li>请求已经完成了鉴权、校验、上下文构建</li><li>日志、Trace 组件已经初始化</li><li>各种中间对象已经创建<br/>此时即便 Redis 命中，绝大部分 CPU 和延迟成本已经付出。</li><li>缓存键设计服务于“数据模型”，而非“访问模式”<br/>另一个常见错误，是缓存整个领域对象，甚至直接缓存 ORM 实体。<br/>后果通常是：</li><li>键粒度过粗</li><li>访问模式稍有变化就无法复用</li><li>命中率长期徘徊在 50% 以下<br/>在这种情况下，Redis 更像是一个昂贵的、不稳定的旁路系统。</li><li>冷启动与高峰期未命中被严重低估<br/>很多团队只关注“平均命中率”，却忽略了两个危险时刻：</li><li>应用刚启动</li><li>流量突然放大<br/>在这些时刻，大量并发请求同时穿透缓存，数据库和后端逻辑被瞬间放大执行，抖动也由此产生。</li></ol><p><strong>让 Redis 真正“拉开差距”的设计方式</strong><br/>当你接受 Redis 不是万能解药之后，优化路径反而变得清晰了。</p><p><strong>第一原则：缓存要尽可能早</strong><br/>如果某个请求的数据已经在缓存中，就不应该再经历完整的业务管道。<br/>理想状态是：</p><ul><li>命中缓存</li><li>直接返回最终响应</li><li>绕过数据库、对象映射、序列化等步骤<br/><strong>第二原则：缓存的是“可直接返回的结果”</strong><br/>与其缓存领域对象，不如缓存“已经准备好返回给客户端的内容”。</li></ul><pre><code>String key = "user:profile:resp:" + userId;
String cached = redis.get(key);if (cached != null) {return cached;}// 未命中，走完整流程
User user = userRepository.findById(userId);
String responseJson = responseMapper.toJson(user);// 合理 TTL，例如 5 分钟
redis.setex(key, 300, responseJson);return responseJson;</code></pre><p>这里 Redis 的角色已经发生变化：<br/>它不再是“数据缓存”，而是响应加速。</p><p><strong>第三原则：预热比你想象得重要</strong><br/>在优化后，我们为以下场景引入了缓存预热：</p><ul><li>服务启动</li><li>核心用户或高频接口</li><li>已知的高峰前时间段<br/>这一步往往可以显著降低首批请求的抖动风险。</li></ul><p><strong>数据不会说谎</strong><br/>在重构缓存策略后，性能变化非常直观：</p><ul><li>API 平均响应时间<br/>从约 410 ms 降至 70–90 ms</li><li>数据库查询量<br/>下降超过 65%</li><li>缓存命中率<br/>稳定在 90% 以上<br/>更重要的是：延迟开始变得可预测，而不是偶发性飙升。</li></ul><p><strong>值得记住的几条经验</strong></p><ol><li>缓存优化首先是架构问题，而不是参数问题：Redis 再快，也无法拯救臃肿的请求链路。</li><li>一次缓存未命中的代价，远高于多数人的直觉：它带来的不是一次查询，而是一整条后端路径的放大执行。</li><li>不要只盯着 Redis 的指标：真正的瓶颈，往往藏在 Redis 之前或之后。</li></ol><p><strong>结语：Redis 从来不是问题</strong><br/>Redis 很少是系统变慢的原因，但它经常成为暴露问题的那面镜子。<br/>如果你的 API 在“加了 Redis 之后”依然迟缓，不妨换个角度思考：<br/>也许不是 Redis 没有加速系统，<br/>而是系统本就不该让 Redis 来兜底。</p><p>测量全链路、设计有缓存意识的架构，让 Redis 只做它最擅长的事。<br/>这，才是真正的性能提升来源。</p>]]></description></item><item>    <title><![CDATA[2026年多家主流媒体和市场报告中提及度较高的几款CRM系统 Python最棒 ]]></title>    <link>https://segmentfault.com/a/1190000047555037</link>    <guid>https://segmentfault.com/a/1190000047555037</guid>    <pubDate>2026-01-21 11:08:56</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>🧭 写在前面：为什么用“提及度”看 CRM 市场</h2><p>这篇文章会以<strong>「在媒体与研究报告中被频繁提及」</strong>为线索，盘点几款在 2026 年依然保持高曝光的主流 CRM（注意：这不等同于任何官方榜单或权威排名）。</p><p>我会尽量引用权威研究机构、评测平台与行业媒体的公开信息，并从<strong>市场视角</strong>解释一件事：  <br/><strong>为什么总是这些名字反复出现在关键报告、行业解读和选型清单里？</strong></p><h2><img width="723" height="493" referrerpolicy="no-referrer" src="/img/bVdnHoS" alt="image.png" title="image.png"/></h2><h2>🔍 为什么“提及度”值得看？</h2><p>在 CRM 领域，“提及度高”通常意味着三件事：</p><ul><li><strong>市场覆盖面广</strong>：跨行业、跨规模都能看到它的身影。</li><li><strong>细分场景成熟</strong>：例如销售自动化（SFA）、服务管理、营销自动化等，都有清晰定位。</li><li><strong>生态与口碑数据充足</strong>：集成伙伴多、实施与咨询经验多、用户评价可参考。</li></ul><p>因此，当研究机构、评测平台或行业媒体在做趋势分析、产品对比、象限/波浪图，或者用户评价榜单时，<strong>这些品牌就会变成天然的“参照系”和“样本库”</strong>，被反复提到。</p><p>从不同角色的视角来看，大致是这样运作的：</p><ul><li><strong>研究机构视角</strong>  <br/>以销售自动化（SFA）等<strong>子市场</strong>为评估单位，按功能完备度、愿景前瞻性、执行能力等维度进行对比（如 Gartner 对 SFA 市场的相关报告与解读文章）。</li><li><strong>评测平台视角</strong>  <br/>依托大量“已验证用户评论”，以评分、使用体验、市场热度等维度做动态排序（例如 G2 的 CRM 分类页，会列出热门产品并支持对比）。</li><li><strong>行业媒体视角</strong>  <br/>更关心“<strong>是否企业级就绪</strong>”“<strong>典型客户画像</strong>”“<strong>适配场景</strong>”，会在各种「最佳 CRM」「选型清单」文章中把这些产品列为常见备选。</li></ul><hr/><h2>🌐 2026 年提及度较高的几款主流 CRM</h2><p>（按常见曝光顺序归纳，<strong>非严格排名</strong>）</p><p>下面这几款，是在<strong>研究报告、评测平台、行业媒体</strong>中都比较常被提到的产品。我会重点放在：它们为什么总出现在视野里。</p><hr/><h3>1）Zoho CRM：性价比 + 套件化 + 全球化带来的高讨论度</h3><p>Zoho CRM 的高提及度，主要来自两个层面：</p><ul><li><strong>研究机构 / 官方传播层面</strong>  <br/>Zoho 官方公开资料中，会引用其在 Gartner SFA 相关评估中的定位（例如被归类为 “Visionary” 等，具体以官方引用和原始报告为准）。  <br/>这一类传播，会把 Zoho 放进“有前瞻性的销售自动化供应商”语境下反复出现。</li><li><strong>评测平台 / 用户口碑层面</strong>  <br/>在 G2 等评测平台的 CRM 分类中，Zoho CRM 通常是<strong>热门产品之一</strong>。  <br/>对潜在客户来说，它经常出现在“同类对比 + 用户评论”的选型路径里，尤其当用户搜索「性价比」「一体化套件」时，会很容易看到它。</li></ul><p>综合来看，Zoho CRM 经常被提起，是因为它<strong>在预算敏感、但又想要完整业务套件</strong>的组织中，有稳定的心智位置。</p><hr/><h3>2）Salesforce：企业级 CRM 的“默认参照系”</h3><p>在很多讨论中，Salesforce 都被当作 CRM 的“<strong>基准线</strong>”来使用：</p><ul><li>对于<strong>大型企业</strong>和<strong>复杂业务流程</strong>，Salesforce 一直保持强存在感；</li><li>围绕<strong>销售自动化平台（SFA）</strong>的行业与研究机构讨论中，它几乎是必被提及的对照对象；</li><li>生态与应用市场（AppExchange）、合作伙伴体系非常丰富，使它成为“<strong>生态型 CRM 平台</strong>”的典型样本。</li></ul><p>因此，即使企业最后不选 Salesforce，<strong>也会拿它来做功能、价格与架构的对比参照</strong>。</p><hr/><h3>3）Microsoft Dynamics 365：深度融入 Microsoft 生态的常见选项</h3><p>Dynamics 365 的提及度，很大程度源自企业对<strong>“Microsoft 体系一体化”</strong>的偏好：</p><ul><li>很多组织已经深度使用 Office 365、Teams、Azure、Power BI 等 Microsoft 产品，  <br/>在此基础上选 CRM 时，Dynamics 365 的<strong>集成体验和统一账号/数据体系</strong>就变得很有吸引力。</li><li>在公开信息和市场传播中，也能看到微软围绕 Gartner SFA 相关认可进行宣传，这进一步巩固了它在“企业级 CRM 候选清单”里的曝光。</li></ul><p>简单理解：<strong>只要企业是重度 Microsoft 用户，Dynamics 365 几乎一定会被提上讨论桌。</strong></p><hr/><h3>4）HubSpot：增长团队与中小企业的“常见第一反应”</h3><p>在大量「最佳 CRM」「产品对比指南」「营销工具推荐」等内容中，HubSpot 经常出现，关键标签是：</p><ul><li><strong>上手快、体验好</strong>：对非 IT 背景的市场和销售团队很友好；</li><li><strong>营销 + 销售协同强</strong>：从获客、内容触达、线索到销售跟进，有比较连贯的一体化体验；</li><li>定价与模块划分相对清晰，适合<strong>SMB 和增长团队</strong>从轻量开始逐步扩展。</li></ul><p>因此，在“<strong>希望快速上线、重视获客转化闭环</strong>”的选型场景下，HubSpot 几乎是标配候选之一。</p><hr/><h3>5）Oracle：大型企业与复杂业务版图中的常驻选手</h3><p>在各类围绕 SFA/CRM 的机构解读与媒体综述里，Oracle 通常会与 Salesforce、Microsoft 一起被并列讨论，原因包括：</p><ul><li>在<strong>大型企业和复杂行业场景</strong>（如金融、电信等），Oracle 仍然在应用版图中占据一席之地；</li><li>对一些已在 Oracle 体系中投入较多的客户来说，选型时会优先考虑在现有技术与数据体系上扩展 CRM。</li></ul><p>因此，它虽然在大众媒体的“话题热度”可能不如某些新锐工具，但<strong>在企业级对比表格中依然有稳定席位</strong>。</p><hr/><h3>6）SAP：从 ERP 体系延伸出来的 CRM 选择</h3><p>在各种“企业级 CRM 供应商清单”里，SAP 也几乎是被固定写上的名字之一，典型场景是：</p><ul><li>企业本身 ERP / 供应链 / 财务等核心流程<strong>已经高度 SAP 化</strong>；</li><li>在 CRM 选型时，更倾向于保持<strong>统一架构、统一治理与端到端数据链路</strong>。</li></ul><p>因此，在谈到“<strong>是否适配集团级、制造业/复杂供应链企业</strong>”时，SAP CRM 通常会作为典型选项出现。</p><hr/><h2>📊 一张表看懂：这些高提及度 CRM 各自擅长什么？</h2><p>下面这张表，用更偏“选型语言”的方式，总结了这些产品在媒体/报告中的常见定位，以及更适配的典型场景。</p><table><thead><tr><th><strong>CRM</strong></th><th><strong>媒体 / 报告常见提法（概括）</strong></th><th><strong>更常见的适配场景</strong></th></tr></thead><tbody><tr><td><strong>Zoho CRM</strong></td><td>性价比、一体化套件、覆盖面广</td><td>预算敏感，但希望用一套工具覆盖更多业务环节的团队</td></tr><tr><td><strong>Microsoft Dynamics 365</strong></td><td>与 Microsoft 生态深度协同、企业落地成熟</td><td>已深度使用 Microsoft 技术栈（Office、Teams、Azure 等）的组织</td></tr><tr><td><strong>HubSpot</strong></td><td>易用、增长友好、营销销售一体</td><td>SMB / 增长团队，强调快速上线和获客转化闭环</td></tr><tr><td><strong>Salesforce</strong></td><td>生态强、扩展多、平台与套件化</td><td>多事业部、复杂流程，强定制 + 强生态依赖的企业级客户</td></tr><tr><td><strong>Oracle</strong></td><td>大型企业应用版图、复杂业务与数据整合</td><td>行业复杂度高，对治理、合规和集成要求高的大型组织</td></tr><tr><td><strong>SAP</strong></td><td>企业级、与核心业务系统深度协同</td><td>已是 SAP 体系客户，强调端到端流程与统一管控的集团型企业</td></tr></tbody></table><p>这些定位之所以会被<strong>反复提起</strong>，本质上是因为它们分别占据了不同的典型<strong>购买路径</strong>：</p><ul><li><strong>生态型</strong>：以应用生态、ISV、合作伙伴为核心（典型如 Salesforce）。</li><li><strong>平台型</strong>：强调与既有技术平台统一（如 Microsoft Dynamics 365）。</li><li><strong>套件型</strong>：用一套工具覆盖多条业务链（如 Zoho CRM）。</li><li><strong>增长型</strong>：优先服务营销 / 增长 / SMB 快速起盘（如 HubSpot）。</li><li><strong>ERP 延伸型</strong>：从既有 ERP / 核心系统向前台业务延伸（如 Oracle、SAP）。</li></ul><hr/><h2>🧩 对市场人员 / 选型团队的落地建议：如何“用好提及度”</h2><p>“提及度高”不是终点，而是一个<strong>筛选入口</strong>。更实用的做法，是把它变成一个结构化的选型步骤：</p><h3>1. 先按业务复杂度分层</h3><p>把自己大致放在以下哪一层：</p><ul><li><strong>增长团队 / 早期阶段</strong>：  <br/>目标是快速获客、跑通基础销售流程，对流程严谨度要求没那么高，敏捷和易用更重要。</li><li><strong>多部门协同阶段</strong>：  <br/>市场、销售、客服等多个团队需要在同一套系统里协作，对流程配置、权限、报表有一定要求。</li><li><strong>集团化治理 / 企业级阶段</strong>：  <br/>强调跨事业部、跨地区的<strong>统一流程、统一数据与内控合规</strong>，CRM 需要和大量已有系统集成。</li></ul><p>你会发现，媒体与评测文章里的高频候选，<strong>刚好覆盖这三层典型场景</strong>。</p><hr/><h3>2. 再看你更信哪种“证据类型”</h3><p>可以有意识地分流信息来源，而不是把所有资料混在一起看：</p><ul><li><p><strong>如果你更看重口碑与易用性</strong></p><ul><li>重点看 G2、Capterra、TrustRadius 等评测平台的用户评论和对比页面；</li><li>筛选和自己行业、团队规模相似的用户体验，参考他们的“踩坑点”。</li></ul></li><li><p><strong>如果你更想站在研究机构的框架下决策</strong></p><ul><li>关注细分市场（如 SFA、营销自动化、服务管理等）的象限 / 波浪图和公开解读；</li><li>重点理解：他们在评估“执行能力”“产品愿景”“市场覆盖”时各自看重什么。</li></ul></li></ul><hr/><h3>3. 最后靠 PoC 验证，而不是靠“提及度”下注</h3><p>比较稳妥的路径是：</p><ol><li>把“高提及度产品”当作<strong>候选池入口</strong>，而不是结论；</li><li><p>从中挑出 2–4 款，做一个 <strong>2–4 周的 PoC（概念验证）</strong>：</p><ul><li>用你的真实数据，把关键流程跑一遍：  <br/><strong>线索 → 商机 → 报价 → 合同 / 回款</strong>；</li><li>同时验证：权限、报表、移动使用体验、对接现有系统等关键点；</li></ul></li><li>把“提及度 + 证据类型 + PoC 结果”综合起来再决策，而不是只看某一个维度。</li></ol><p>这样做的好处是：<strong>你既借用了市场的“集体经验”，又保留了适配自身业务的判断空间</strong>，在预算和时间上都是更划算的决策方式。</p>]]></description></item><item>    <title><![CDATA[ERP实施流程/步骤 织信informat ]]></title>    <link>https://segmentfault.com/a/1190000047555040</link>    <guid>https://segmentfault.com/a/1190000047555040</guid>    <pubDate>2026-01-21 11:08:13</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555042" alt="image.png" title="image.png"/></p><p>1、初次调研</p><p>主要目的是让ERP软件提供商的实施顾问人员能够对企业各个部门的业务流程初步了解，能收集到各个部门业务流的所有单据，和各个部门人员认识，了解他们对ERP的认识和期望，以便制订工作计划。</p><p>2、系统培训</p><p>主要目的是让企业所有人员认识到什么是ERP，并在企业中应用ERP系统能给企业带来如何的效益，另外就是ERP软件各个系统的功能培训。</p><p>3、流程拟定</p><p>主要目的是实施顾问人员根据自己对该企业的了解结合自己或所在公司对企业所在行业的累积经验，结合ERP系统拟定出一个符合企业需求的业务流程，能在系统中得到合理的体现；</p><p>这是一个非常重要的阶段，一个企业的管理能否从此通过ERP得到提升，流程能否更完善，就需要这个流程拟定。</p><p>4、编码原则</p><p>主要目的是企业能在实施顾问人员的指导下，制定企业应用ERP的基本原则，其中包括物料的编码原则、供应商、客户的编码原则、产品结构（包括BOM架阶）的分阶建立等。</p><p>5、资料收集</p><p>主要目的是企业的人员在熟悉了各项编码原则的基础上，收集企业应用ERP管理所需要的基本资料，包括物料资料、供应商、客户、部门、人员等收集。</p><p>6、流程测试</p><p>主要目的是企业的人员测试流程拟定的合理性，并使用企业实际的业务流程来测试ERP系统的功能完善性，和操作的方便性。</p><p>7、期初导入</p><p>主要目的是搜集ERP系统上线的期初数据，并在实施顾问人员的指导下录入ERP系统，为企业正式应用ERP系统奠定夯实的基础。</p><p>8、上线辅导</p><p>主要目的是将企业的实际业务数据在ERP系统中处理，一般在系统上线的第一、二个月的时间里面，有必要的双轨模式进行，以防企业人员在上线期初操作不熟练所造成错误。</p><p>9、月结辅导</p><p>主要目的是在应用系统一个自然月后，通过ERP系统来跑出企业管理所需要的各种报表、检验报表的完善性，数据的准确性。</p><p>当然，一个企业中要成功实施一个ERP系统，单纯靠以上九个步骤是远远不够的，ERP的实施是一个非常规范的过程，所以，我们在这里将这个过程分作为两大块。</p><p><strong>一、以实施文档全面贯穿实施过程</strong></p><p>作为实施顾问人员，在实施的过程中，应将各种标准的实施文档提交给企业，以确保ERP实施项目的质量进行，也就是说，顾问与企业之间的工作与文档的制作息息相关，可见文档在实施进程中的重要性非同一般。</p><p>那么，文档到底对整个实施工作有怎样的作用呢？</p><p>首先，我们大致将ERP实施中的文档作为一个分类：</p><p>分阶段实施计划文档</p><p>分阶段目标设置文档</p><p>标准业务流程文档</p><p>标准编码、标准数据文档</p><p>标准参数设置文档</p><p>功能操作指南文档</p><p>这些文档将会伴随着ERP实施的各个阶段逐渐充实、完善。</p><p>也同时记载了整个实施的过程和成果。那好，现在我们来分析一下这些文档的价值所在：</p><p>书面化的文档有助于实施人员与企业人员明确了解各自的职责，信息互通，共同把握实施过程的节奏。</p><p>标准业务流程文档有助于双方明晰业务流程，有效配合业务流程的重组和优化。</p><p>标准编码、数据文档及标准参数设置文档是实施中不可缺少的基础资料，可有效减少重复工作，避免对正常工作的影响。</p><p>功能操作指南文档可帮助最终用户规范化操作，加强培训效果。</p><p>前面我们曾经提到，ERP的实施工作可能长达数年不定，在这个时间跨度中，企业在最初实施ERP时确定的ERP项目的人员，也许难免要发生一些变化，那么，在发生变化时，ERP实施文档就可以承担起指导双方快速工作的标准文档的作用。</p><p>还有，当实施完成后，企业的运行过程将是更漫长的过程，那么实施的标准文档就将成为企业实施信息化的公共载体，成为指导企业后续工作的航标，和企业在后续人员培训方面提供详尽的素材。</p><p><strong>二、培训全面贯穿实施过程</strong></p><p>在ERP实施的过程中，培训始终是作为一条主线的，具体来说，在系统实施过程中，培训对象包括以下四类：</p><p>企业领导层、核心小组（项目负责人）、技术小组、最终用户。</p><p>企业领导层培训：对高层的培训主要是ERP管理理念的培训，通常会由软件提供商安排较资深顾问师对企业领导层进行ERP管理思想的培训，使得企业领导层能够从总体上理解ERP系统的理念、流程和功能。</p><p>核心小组（包括项目负责人、部门经理）培训：对于这一类的培训内容包括ERP系统的管理思想概念、ERP系统的具体功能以及ERP系统各种报表的应用。</p><p>技术小组培训：技术小组的成员主要包括参与ERP系统及相关数据库和网络安装、设置及管理的信息部门成员。培训的主要目标是提供ERP系统的设计结构，各个模块的关联关系与数据库结构，系统问题处理等。</p><p>最终用户培训：培训目的是使用户了解ERP系统后新的业务前景、目标以及带来的好处，使用户能清楚地了解到ERP是什么，怎样通过它提高个人及整体的业务表现，使用户发觉其工作内容的变化及ERP将如何融入其日常工作。同时向用户提供从现状到未来迁移过程中通用的术语，指导用户如何使用ERP完成其工作。</p><p>ERP实施过程中的培训作为实施的一条主线，既体现了ERP实施很高的附加值，又充分体现了ERP实施过程中的知识转移。</p><p>把ERP从半成品到成品的过程实质就是知识转移的过程，其中包含企业的管理诊断，实施战略的选择，业务流程的设定，对企业需求的恰到好处的分析。</p><p>综上所述，企业信息化是一个长期的过程，在这个过程中，成熟完善的ERP系统是信息化成功的前提，严谨科学的实施方式是保证ERP成功上线的关键。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555043" alt="image.png" title="image.png" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555044" alt="image.png" title="image.png" loading="lazy"/><br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047555045" alt="image.png" title="image.png" loading="lazy"/></p><p>【声明】：以上所发文章仅供大家学习参考，请不要作商业用途；ERP系统的专业性很强，文中难免有错误，一旦发现，请联系我们及时更正；最后感谢图片内容的提供商：织信ERP，该厂商专注企业信息化系统管理10年余，坚持传播生产管理知识，自研低代码开发底座，基于B/S架构，可帮助企业快速构建生产管理所需的各项功能。</p>]]></description></item><item>    <title><![CDATA[鸿蒙 HarmonyOS 6 | ArkUI (08)：弹窗与覆盖 CustomDialog、Toa]]></title>    <link>https://segmentfault.com/a/1190000047555052</link>    <guid>https://segmentfault.com/a/1190000047555052</guid>    <pubDate>2026-01-21 11:07:38</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h3>前言</h3><p>在一个优秀的应用设计中，界面不仅仅是平铺直叙的展示，更需要有层级感。当用户点击删除按钮时，我们需要一个确认框来防止误触；当后台数据加载完成时，我们需要一个轻量的提示告诉用户 好了 ；当用户对某个晦涩的功能图标感到困惑时，我们需要一个气泡弹窗来解释它的含义。这些浮在主界面之上的交互层，我们统称为 <strong>覆盖物（Overlays）</strong>。</p><p>在早期的开发中，很多工程师习惯直接使用系统原生的 <strong>AlertDialog</strong>，那种灰底黑字的弹窗虽然功能健全，但在如今这个颜值为王的时代，它打断了用户的情绪流，也破坏了应用的整体设计语言。</p><p>在鸿蒙 HarmonyOS 6 中，ArkUI 为我们提供了极其强大的弹窗定制能力。无论是转瞬即逝的 <strong>Toast</strong>，还是完全自定义的 <strong>CustomDialog</strong>，亦或是指向性明确的 <strong>Popup</strong> 气泡，我们都可以像搭积木一样，用声明式的代码构建出既美观又灵动的交互体验。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047522478" alt="" title=""/></p><h3>一、 轻量级反馈与上下文气泡</h3><p>在进入复杂的弹窗之前，我们先解决最基础的反馈需求。当用户复制了一段文本，或者刷新列表成功时，我们不需要让用户进行任何操作，只需要给出一个朕已阅的信号。这就是 <strong>Toast</strong>。在 API 20 中，系统将这类交互统一收敛到了 <strong>promptAction</strong> 模块下。我们不再像以前那样去寻找 Window 实例，而是直接调用 <strong>promptAction.showToast</strong>。这个 API 非常纯粹，它接受一个显示时长、一条消息文本，以及一个可选的位置参数。但在实战中，建议尽量保持 Toast 的简洁，不要试图在里面塞入过多的文字。它应该像一阵风，来过，被看到，然后消失。</p><p>如果说 Toast 是全局的广播，那么 <strong>Popup</strong> 气泡就是点对点的悄悄话。CustomDialog 是一种模态交互，它会给背景加上遮罩，强迫用户聚焦。但有时候，我们并不想打断用户的操作流，只是想对界面上的某个元素做一点补充说明。比如一个帮助的小问号图标，或者一个“新功能”的引导提示。</p><p>这时候，ArkUI 提供的 <strong>bindPopup</strong> 属性是最优雅的选择。这意味着任何组件——一个按钮、一张图片甚至一段文字，都可以绑定一个气泡。系统会自动计算目标组件在屏幕上的位置，然后决定气泡是出现在上方、下方还是侧边，并自动生成一个小箭头指向目标。我们作为开发者，几乎不需要关心坐标计算的问题，只需要关注气泡里的内容构建即可。</p><pre><code>@Entry
@Component
struct PopupExample {
  // 控制气泡显示的开关状态
  @State showPopup: boolean = false;

  // 定义气泡内部的 UI 结构
  @Builder
  PopupContent() {
    Column() {
      Text('功能说明')
        .fontSize(14)
        .fontWeight(FontWeight.Bold)
        .fontColor(Color.White)
        .margin({ bottom: 4 })
      
      Text('这里是详细的补充文案，系统会自动根据位置计算箭头指向。')
        .fontSize(12)
        .fontColor('#E6E6E6')
    }
    .padding(12)
    .backgroundColor('#4D4D4D') // 气泡背景通常与文字反色
    .borderRadius(8)
  }

  build() {
    Column() {
      // 任何组件都可以绑定气泡，这里以一个问号图标为例
      SymbolGlyph($r('sys.symbol.questionmark_circle'))
        .fontSize(24)
        .fontColor($r('sys.color.ohos_id_color_text_secondary'))
        // 1. 点击切换状态
        .onClick(() =&gt; {
          this.showPopup = !this.showPopup;
        })
        // 2. 绑定气泡属性
        .bindPopup(this.showPopup, {
          builder: this.PopupContent,     // 指向内容构建器
          placement: Placement.Bottom,    // 优先显示位置（系统会自动调整）
          mask: false,                    // false 表示非模态，不阻断用户操作其他区域
          enableArrow: true,              // 显示指向目标的小箭头
          popupColor: '#4D4D4D',          // 气泡背景色（需与 Builder 背景一致或透明）
          onStateChange: (e) =&gt; {
            // 3. 状态同步：当点击空白处气泡消失时，同步更新 boolean 变量
            if (!e.isVisible) {
              this.showPopup = false;
            }
          }
        })
    }
    .width('100%')
    .height('100%')
    .justifyContent(FlexAlign.Center)
  }
}</code></pre><h3>二、 定制化核心：CustomDialog 与控制器模式</h3><p>当业务逻辑变得复杂，比如需要用户领取优惠券、签署隐私协议或者选择复杂的筛选条件时，系统的标准弹窗就捉襟见肘了。这时候，<strong>CustomDialog</strong>（自定义弹窗）就是我们的救星。它的设计哲学非常有趣，采用了一种 <strong>控制器（Controller）</strong> 模式。我们需要定义两个部分：一个是弹窗本身的 UI 结构，另一个是控制它打开和关闭的遥控器。</p><p>首先，我们需要定义一个被 <strong>@CustomDialog</strong> 装饰器修饰的结构体。在这个结构体里，你可以使用任何 ArkUI 组件：Column、Row、Image 甚至 List。这意味你可以把弹窗做得像普通页面一样丰富多彩。紧接着，在父组件中，我们需要实例化一个 <strong>CustomDialogController</strong>。这个控制器是连接父子组件的纽带。在实例化时，我们需要传入 builder 参数，指向我们刚才定义的弹窗组件。</p><pre><code>@Entry
@Component
struct HomePage {
  // 1. 实例化控制器：连接父组件与弹窗组件
  // 必须在 @Component 中作为成员变量定义
  dialogController: CustomDialogController | null = new CustomDialogController({
    builder: PrivacyAgreementDialog(), // 引用外部定义的 @CustomDialog 组件
    autoCancel: false,                 // 点击遮罩是否允许关闭（强制交互场景通常设为 false）
    alignment: DialogAlignment.Center, // 弹窗在屏幕中的对齐方式
    customStyle: true,                 // 是否完全自定义样式（去除系统默认的白色背景和圆角）
    offset: { dx: 0, dy: 0 },          // 相对对齐位置的偏移量
    maskColor: '#33000000',            // 自定义遮罩层颜色
  });

  // 推荐：在组件销毁时清理控制器，防止内存泄漏
  aboutToDisappear() {
    this.dialogController = null;
  }

  build() {
    Column() {
      Button('打开隐私协议')
        .fontSize(16)
        .onClick(() =&gt; {
          // 2. 通过控制器打开弹窗
          if (this.dialogController != null) {
            this.dialogController.open();
          }
        })
    }
    .width('100%')
    .height('100%')
    .justifyContent(FlexAlign.Center)
  }
}</code></pre><p>这里有一个初学者常犯的错误，就是试图通过 @Prop 或 @Link 来直接同步父子组件的数据。虽然 CustomDialog 支持这些装饰器，但由于弹窗并不在常规的组件渲染树中，数据的响应式更新有时会存在滞后。最佳的实践是：<strong>在打开弹窗时传入初始数据，在关闭弹窗时通过回调函数返回结果</strong>。比如做一个“领取优惠券”的弹窗，我们在构建 CustomDialog 时定义一个 confirm 回调函数。当用户点击弹窗里的“立即领取”按钮时，我们调用这个回调，把结果传回给父组件，然后关闭弹窗。这种 <strong>事件驱动</strong> 的数据流向，比复杂的双向绑定更加稳健且易于追踪。</p><p>做出来和做得好看是两码事。默认的 CustomDialog 往往带有系统默认的圆角和白色背景，有时甚至会有默认的内边距。为了实现设计师眼中那种“全屏半透明”或者“底部异形弹窗”的效果，我们一定要善用 <strong>customStyle: true</strong> 这个配置项。一旦设置为 true，系统就会移除所有默认的弹窗样式，给你一张完全空白的画布。这时候，你需要在你的 @CustomDialog 组件内部，自己定义背景色、圆角和阴影。虽然麻烦了一点，但它赋予了你像素级的控制权。</p><h3>三、 综合实战：构建营销活动弹窗体系</h3><p>为了将上述知识点融会贯通，我们来构建一个真实的电商营销场景。这个页面包含一个模拟的“会员中心”，右上角有一个绑定了 <strong>bindPopup</strong> 的帮助图标，点击会展示活动规则；而在页面中心，有一个“领取大礼包”的按钮，点击会唤起一个完全自定义样式的 <strong>CustomDialog</strong> 优惠券弹窗。</p><p>在这个代码中，请仔细观察 <strong>CouponDialog</strong> 的定义，它是如何通过 <strong>controller</strong> 关闭自己的，以及父组件是如何通过 <strong>CustomDialogController</strong> 配置 <strong>customStyle: true</strong> 来移除系统默认背景的。这就是构建高颜值弹窗的标准模板。</p><p>TypeScript</p><pre><code>import { promptAction } from '@kit.ArkUI';

@CustomDialog
struct CouponDialog {
  controller?: CustomDialogController;

  couponAmount: number = 0;
  onConfirm: () =&gt; void = () =&gt; {};

  build() {
    Column() {
      // 顶部装饰
      Stack({ alignContent: Alignment.Bottom }) {
        Column()
          .width('100%')
          .height('100%')
          .backgroundColor('#FF4040')
          .borderRadius({ topLeft: 16, topRight: 16 })

        Text(`¥${this.couponAmount}`)
          .fontSize(40)
          .fontWeight(FontWeight.Bold)
          .fontColor(Color.White)
          .margin({ bottom: 20 })
      }
      .width('100%')
      .height(120)

      // 内容
      Column({ space: 12 }) {
        Text('恭喜获得新人优惠券')
          .fontSize(18)
          .fontWeight(FontWeight.Bold)
          .fontColor('#333')

        Text('全场通用，无门槛立减。有效期至 2026-12-31')
          .fontSize(14)
          .fontColor('#999')
          .textAlign(TextAlign.Center)
          .padding({ left: 20, right: 20 })
      }
      .padding({ top: 20, bottom: 20 })

      // 按钮
      Row() {
        Button('残忍拒绝')
          .backgroundColor('#F5F5F5')
          .fontColor('#666')
          .layoutWeight(1)
          .margin({ right: 10 })
          .onClick(() =&gt; {
            // 【修复点 2】调用时加上 '?' (可选链)，防止空指针报错
            this.controller?.close();
          })

        Button('立即领取')
          .backgroundColor('#FF4040')
          .fontColor(Color.White)
          .layoutWeight(1)
          .onClick(() =&gt; {
            this.onConfirm();
            // 【修复点 3】同理，加上 '?'
            this.controller?.close();
          })
      }
      .width('100%')
      .padding({ left: 20, right: 20, bottom: 20 })
    }
    .width(300)
    .backgroundColor(Color.White)
    .borderRadius(16)
    .shadow({ radius: 10, color: '#33000000', offsetY: 5 })
  }
}


@Entry
@Component
struct DialogAndPopupPage {
  // 状态变量：控制气泡 (Popup) 的显示与隐藏
  @State isHelpPopupVisible: boolean = false;

  // 【核心】定义弹窗控制器
  // 必须在 build() 之外实例化
  // builder 参数指向上面定义的 @CustomDialog 组件
  private dialogController: CustomDialogController = new CustomDialogController({
    builder: CouponDialog({
      couponAmount: 100, // 向弹窗传递数据
      onConfirm: () =&gt; {
        // 定义弹窗确认后的逻辑
        this.handleCouponReceived();
      }
    }),
    autoCancel: true,                 // 允许点击遮罩关闭
    customStyle: true,                // 使用完全自定义样式（去除系统默认白底圆角）
    alignment: DialogAlignment.Center // 居中显示
  });

  // 模拟业务逻辑：领取成功后的 Toast 反馈
  handleCouponReceived() {
    promptAction.showToast({
      message: '领取成功！已存入卡包',
      duration: 2000,
      bottom: 100
    });
  }

  // 定义 Popup (气泡) 的内容构建器
  @Builder
  PopupBuilder() {
    Column() {
      Text('活动规则说明')
        .fontSize(14)
        .fontWeight(FontWeight.Bold)
        .fontColor(Color.White)
        .margin({ bottom: 8 })

      Text('1. 仅限新用户领取\n2. 每日限领一张\n3. 不可与其他活动叠加')
        .fontSize(12)
        .fontColor(Color.White)
        .lineHeight(18)
    }
    .padding(12)
    .width(200)
  }

  build() {
    Column() {
      // --- 顶部导航栏 ---
      Row() {
        Text('会员中心')
          .fontSize(20)
          .fontWeight(FontWeight.Bold)

        Blank() // 撑开中间空间

        // 帮助图标 (绑定 Popup)
        Text('?')
          .fontSize(18)
          .fontColor(Color.White)
          .backgroundColor('#CCCCCC')
          .width(24)
          .height(24)
          .textAlign(TextAlign.Center)
          .borderRadius(12)
          // 【核心】绑定气泡
          .bindPopup(this.isHelpPopupVisible, {
            builder: this.PopupBuilder(), // 指向 Builder
            placement: Placement.BottomRight, // 气泡位置
            popupColor: '#4C4C4C',            // 气泡深色背景
            enableArrow: true,                // 显示箭头
            mask: false,                      // 非模态，不遮挡背景
            onStateChange: (e) =&gt; {
              // 状态同步：处理点击外部自动消失的情况
              if (!e.isVisible) {
                this.isHelpPopupVisible = false;
              }
            }
          })
          .onClick(() =&gt; {
            // 点击切换显示状态
            this.isHelpPopupVisible = !this.isHelpPopupVisible;
          })
      }
      .width('100%')
      .padding(20)

      // --- 页面主体内容 ---
      Column({ space: 30 }) {
        // 模拟大图占位
        Column()
          .width(200)
          .height(200)
          .backgroundColor('#E0E0E0')
          .borderRadius(100)
          .margin({ top: 50 })

        Text('超级会员大礼包')
          .fontSize(24)
          .fontWeight(FontWeight.Bold)

        Text('包含 100 元无门槛优惠券')
          .fontSize(16)
          .fontColor('#666')

        // 【核心】触发弹窗的按钮
        Button('立即领取')
          .width('80%')
          .height(50)
          .fontSize(18)
          .fontWeight(FontWeight.Bold)
          .backgroundColor('#FF4040')
          .shadow({ radius: 10, color: '#4DFF4040', offsetY: 5 })
          .onClick(() =&gt; {
            // 打开自定义弹窗
            if (this.dialogController) {
              this.dialogController.open();
            }
          })
      }
      .width('100%')
      .layoutWeight(1) // 占据剩余高度
    }
    .width('100%')
    .height('100%')
    .backgroundColor('#F8F8F8')
  }
}</code></pre><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555054" alt="" title="" loading="lazy"/></p><h3>总结</h3><p>弹窗和覆盖物是应用与用户沟通的第二语言。Toast 是轻声的耳语，CustomDialog 是正式的对话，而 Popup 则是贴心的便签。</p><p>在鸿蒙 HarmonyOS 6 开发中，掌握 <strong>@CustomDialog</strong> 和 <strong>bindPopup</strong> 是构建高级 UI 的必修课。我们抛弃了系统的默认样式，通过 <code>customStyle</code> 获得了对画布的完全掌控权，让弹窗不再只是功能的载体，更是视觉设计的延伸。切记，不要滥用弹窗，每一次遮罩的出现都是对用户注意力的强行掠夺。</p><p>好的交互应该是克制的，只在真正需要的时候才优雅地浮现。</p>]]></description></item><item>    <title><![CDATA[到底什么是CRM系统？一文读懂CRM客户关系管理系统的核心逻辑 新增长SaaS点评 ]]></title>    <link>https://segmentfault.com/a/1190000047555056</link>    <guid>https://segmentfault.com/a/1190000047555056</guid>    <pubDate>2026-01-21 11:06:51</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>CRM系统是干什么用的？从零开始全面了解客户管理工具<br/><img width="664" height="648" referrerpolicy="no-referrer" src="/img/bVdnHoh" alt="" title=""/><br/>最近发现，越来越多的企业决策者和管理层将关注点聚焦于几个关键命题：<br/>“企业必须推动精细化运营，向管理要效益”<br/>“客户资源是企业的核心战略资产，需进行系统性经营”<br/>“亟需部署CRM系统，实现客户关系的数字化、智能化管理” <br/>这些听起来方向明确、势在必行，但真到了要建系统、要执行落地的时候，不少企业却陷入困惑：<br/>CRM客户关系管理系统究竟是什么？与Excel表格、零散的客户记录工具有什么本质区别？怎么才能选择一套真正契合自身业务、投入产出比高的CRM解决方案？ <br/>这篇文章，就从一个根本问题切入，——“CRM真正的价值到底是什么？”并结合国内领先的CRM厂商纷享销客的实践案例，剖析CRM背后的底层逻辑与实战价值。<br/>让你不仅知道“要不要上 CRM”，更清楚“该怎么用好 CRM”。</p><h2>一、CRM不是工具，而是一套以客户为中心的管理体系</h2><h3>1.1 CRM的定义与本质</h3><p>CRM（Customer Relationship Management），即客户关系管理系统，核心目标并非简单地“记录客户信息”，<br/>而是通过技术手段，构建一套覆盖从获客 → 成交 → 复购/续费的可追踪、可优化、可复制的管理机制。<br/>根据Gartner在《2024年CRM市场指南》中的定义：“现代CRM系统已超越传统销售自动化范畴，演变为集营销获客、销售转化、客户服务与数据分析于一体的智能客户运营平台。”<br/>这意味着，CRM的本质是一种企业级客户资产沉淀机制，而非仅限于前端销售人员使用的辅助工具。</p><h3>1.2 与Excel、微信标签等“伪CRM”的本质差异</h3><p>许多企业常误以为“有客户名单就是有CRM”。例如，使用Excel表格管理客户、依赖企业微信打标签、或让销售员在手机备忘录中记录跟进情况。<br/>这些方式虽能短期满足基础需求，但在规模化、流程化、数据驱动层面存在致命短板：<br/>• 信息孤岛严重：客户数据分散在不同员工终端，离职即流失；<br/>• 过程不可见：管理者无法掌握销售推进的真实节奏与卡点；<br/>• 决策无依据：缺乏结构化数据支撑，难以评估渠道效果、销售效能或客户价值。</p><h2>二、CRM的核心模块：覆盖客户全生命周期（以纷享销客为例）</h2><p>一个成熟的CRM系统通常包含五大核心功能模块，共同构成客户旅程的完整闭环：</p><h3>2.1  营销与活动管理</h3><p>说白了就是帮你把各个渠道来的客户线索“收好、分快、跟准”。<br/>比如你在抖音、百度或者微信投广告，用户一留信息，系统自动抓进来，不漏掉；还能给线索打分，谁更可能成交就优先推给销售。办个线上直播或展会？报名、签到、后续跟进全在线搞定。<br/>最实在的是，花多少钱、带来多少客户、最后成没成交，一笔账清清楚楚，不像以前“钱花了，效果靠猜”。<br/>这样你就能知道哪条渠道真管用，下次把预算花在刀刃上。</p><h3>2.2  线索管理</h3><p>帮助企业把从各个地方来的潜在客户（比如官网留言、广告点击、展会名片）统一收进来，不乱不丢。<br/>纷享销客会自动判断谁更可能买——比如有人反复看产品页，就打个高分，优先推给销售；没人跟进的线索还会自动“回收”，转给别人跟。<br/>整个过程像流水线一样：先识别，再打标签，接着分人跟，最后看效果。市场和销售不再扯皮，线索也不再“休冬眠”，转化自然就上去了。</p><h3>2.3  客户与联系人管理</h3><p>其实就是帮你把“谁是客户、谁在对接”这件事理得明明白白，不用担心销售离职客户丢失的问题。<br/>比如你公司卖设备给一家工厂，这家工厂就是“客户”，而采购经理老王、技术主管小李就是“联系人”。<br/>系统会把这些信息全记下来——不光是电话微信，还有每次聊了啥、什么时候拜访过、买过什么产品，全都自动归到一起。<br/>哪怕老王跳槽了，新来的销售也能一眼看懂：“哦，原来上次谈的是这个需求，现在该找小李了。”<br/>而且客户还能分级，像A类重点客户，系统会提醒你定期跟进；<br/>要是好久没动静，可能自动放回公海，让别人试试。<br/>这样客户资源就真正变成了公司的资产，不是某个人的私有物。<br/>说白了，就是让客户信息“看得清、跟得上、留得住”。</p><h3>2.4 商机与销售漏斗管理</h3><p>商机管理是CRM最核心的价值体现。纷享销客支持企业自定义销售阶段（“初步接洽→需求确认→方案演示→报价谈判→合同签署”），每个阶段设置关键动作与成功标准，形成可视化销售漏斗。<br/>通过漏斗分析，管理者可清晰看到：<br/>• 当前有多少商机处于各阶段？<br/>• 哪个环节流失率最高？<br/>• 下季度预计成交金额是否达标？<br/>更实用的是，系统能自动防撞单、智能预测业绩，并将最佳销售实践固化进流程——新员工照着走就不会跑偏，老员工也能避免凭感觉跟进。最终实现从“靠人盯”到“靠流程驱动”，提升赢单率和预测准确性。</p><h3>2.5 客户服务管理</h3><p>纷享销客帮助企业把“售后”这件事做得又快又稳，让客户觉得你靠谱。<br/>比如客户家的设备出问题了，他不用打电话干等，直接扫个码、在微信小程序里点一下，就能提个服务请求。<br/>系统马上收到，自动分给离得最近、有空的工程师——就像打车软件派单一样。<br/>工程师上门前，手机上能看到这台设备以前修过啥、配件用过哪些；<br/>修完还能当场扫码让客户打分，满意不满意一目了然。<br/>要是客户是VIP，系统还会优先安排专属客服，服务更快更贴心。<br/>所有这些流程——从客户报修、派工、上门、用配件、收钱到评价——全在线上走，不靠Excel也不靠嘴记。<br/>老板在后台还能看数据：哪个产品老坏？哪个工程师效率高？客户满意度掉没掉？一清二楚。<br/>总之，就是让服务不乱、不拖、不丢事，客户省心，公司也省力。</p><h3>2.6  报表与BI分析</h3><p>BI分析就像给公司装了个“数据仪表盘”，销售做了多少单、客户从哪来、服务满不满意，一眼就能看清。一套好的CRM必须能将过程数据转化为决策洞察。典型报表包括：<br/>• 销售业绩达成率<br/>• 线索来源渠道ROI<br/>• 商机阶段转化率<br/>• 客户生命周期价值（LTV）<br/>更实用的是，它能自动发现谁该复购了——比如客户买的软件快到期了，或者老在用某个功能，系统就会提醒销售！不用靠人脑记，也不用等客户主动找上门。整个过程简单直接：看数据、抓机会、促成交，让老客户不断带来新生意。<br/>说到底，纷享销客CRM做的不是简单的“记客户电话”，而是帮企业把客户当成资产来经营。通过营销自动化 → 智能线索管理 → 标准化销售流程 → 全景客户视图 → 数据驱动服务与复购的完整链路，纷享销客真正实现了：<br/>• 前端：精准获客、高效转化<br/>• 中台：过程可视、协同高效<br/>• 后端：体验保障、价值深耕</p><h2>三、为什么企业需要CRM？三大角色视角下的真实价值</h2><h3>3.1 对老板：守住客户资产，降低经营风险</h3><p>对企业主而言，最大的隐性成本不是软件采购费，而是“人走客户飞”。据麦肯锡调研，超过60%的企业客户资源高度依赖个别销售个人关系，一旦核心人员离职，客户流失率高达40%以上。<br/>CRM系统通过强制数据录入与权限管控，确保所有客户互动记录沉淀在系统中。即使销售离职，客户仍属于公司资产，可无缝交接。此外，CRM提供的销售预测与现金流预判功能，让老板告别“拍脑袋定目标”，实现科学经营。</p><h3>3.2 对销售：减负增效，专注高价值沟通</h3><p>一线销售最怕“填表式CRM”。真正优秀的系统应成为销售的“智能助手”，而非负担。纷享销客通过以下设计提升销售体验：<br/>• 移动端一键记录：通话后自动生成跟进日志；<br/>• 智能提醒：自动提示“3天未联系的A类客户”；<br/>• 话术库与模板：快速调用成功案例与标准应答；<br/>• 任务自动化：商机推进到下一阶段时，自动创建待办事项。</p><h3>3.3 对管理者：从“结果管控”转向“过程赋能”</h3><p>传统管理依赖周报、月报和口头汇报，信息滞后且失真。CRM则实现全流程透明化：<br/>• 可查看每位销售的日程安排、客户拜访轨迹、沟通频次；<br/>• 可对比团队成员在相同阶段的转化效率；<br/>• 可识别高绩效销售的行为模式，并复制推广。<br/>纷享销客的团队协作空间支持跨部门协同（如销售+售前+交付），确保大客户项目高效推进，避免内部扯皮。</p><h2>四、国产CRM崛起：纷享销客如何满足中国企业的独特需求？</h2><p>在全球CRM市场，Salesforce长期占据主导地位。但在中国市场，企业对客户资产的精细化运营需求日益迫切——不仅要管好客户信息，更要实现从获客、转化到复购的全生命周期价值挖掘。而国内企业的需求，例如系统集成、审批流程、发票管理，使得国产CRM更具适配性。<br/>纷享销客作为国内领先的智能型CRM厂商，深耕中国市场十余年，产品不仅贴合本土业务逻辑，更积极融合AI能力，打造“智能化+场景化”的新一代客户运营平台。其核心优势体现在以下五个方面：<br/>• 深度集成微信生态：支持企业微信客户同步、聊天侧边栏、朋友圈素材库，实现私域流量无缝管理；<br/>• 灵活审批流：可配置合同审批、折扣申请、回款确认等复杂流程，贴合国内企业内控要求；<br/>• 业财一体化打通：与用友、金蝶等财务系统对接，打通“签约—开票—回款”链条；<br/>• 垂直行业解决方案：针对制造业、医疗、快消、IT服务等垂直领域提供预置模板。<br/>• AI驱动的智能销售助手：系统可以自动分析客户行为、预测成交概率，并在销售跟进中实时推荐话术、成功案例和下一步行动；同时支持自动生成会议纪要、识别商机风险、预警客户流失，帮助销售减少重复工作，专注高价值沟通。更重要的是，纷享销客采用PaaS平台架构，支持企业按需扩展模块（如CPQ报价、服务工单、BI分析），避免“一次性买断但用不起来”的陷阱。这种“用多少、配多少、智能多少”的弹性模式，尤其适合大中型企业。</p><h2>五、如何选型CRM？七大关键评估维度</h2><p>当您认识到CRM的价值并准备开始选择时，面对市场上数百款琳琅满目的产品可能会感到无从下手。面对市面上数十款CRM产品，如何为您的企业选择一款合适的CRM系统？建议从以下七个维度综合评估：<br/><img width="723" height="479" referrerpolicy="no-referrer" src="/img/bVdnHoV" alt="" title="" loading="lazy"/></p><h2>结语：CRM不是成本，而是增长基础设施</h2><p>在数字经济时代，客户关系已成为企业最稀缺的战略资源。CRM系统不再是“可选项”，而是如同ERP、财务系统一样的企业数字基建。<br/>它帮助企业回答三个根本问题：<br/>• 我们到底有多少真实有效的客户？<br/>• 销售团队每天在做什么？效率如何？<br/>• 下个月、下个季度的业绩从哪里来？<br/>总而言之，CRM系统远不止是一个记录客户信息的数据库软件。它是一种将“以客户为中心”的理念融入企业血脉的战略工具，是连接市场、销售和服务，驱动业务流程优化和决策智能化的核心引擎。希望本文能帮助您对CRM有一个清晰的认知。 </p><h2>常见问题 (FAQ)</h2><p>1、CRM系统和ERP系统有什么区别？<br/>简单来说，CRM（客户关系管理）主要面向外部，关注的是与客户相关的活动，如市场、销售、服务，目标是增加收入和提升客户满意度。而ERP（企业资源计划）主要面向内部，管理的是企业的核心业务资源，如财务、库存、采购、生产等，目标是优化内部流程和降低成本。两者可以集成，共同构成企业数字化管理的核心。<br/>2、CRM系统一定要全员使用吗？可以只给销售用吗？<br/>A：不建议。CRM的价值在于打通“营销—销售—服务”全链路。若仅销售使用，将导致线索来源不清、售后脱节、数据断层。理想状态是市场、销售、客服、管理层均在系统中有角色和数据贡献。<br/>3、纷享销客和国外CRM（如Salesforce）相比有什么优势？<br/>A：纷享销客在微信生态集成、本地化审批流程、中文界面体验、实施成本及响应速度上更具优势。Salesforce虽功能强大，但对中国企业常见的“人情化流程”“多级审批”“业财一体”支持较弱，且本地化服务成本高。<br/>4、CRM系统主要适用于哪些类型的企业？是不是只有大企业才需要？<br/>答： CRM系统适用于所有有客户并希望与客户建立长期关系的企业，并非大企业专属。不同规模企业需求侧重不同：中小企业可使用CRM标准化销售过程、防止客户流失、提升人效；中大型企业则更侧重于跨部门协同、数据整合分析与生态连接。当前，许多云原生CRM（如纷享销客CRM）提供灵活订阅模式与标准化功能模块，大幅降低了中小企业的使用门槛与启动成本。<br/>5、实施CRM系统最大的挑战是什么？如何规避失败风险？<br/>答： 最大挑战往往来自组织与文化层面，而非技术本身，具体包括：员工抵触改变、使用率低下；业务流程与系统不匹配；数据质量差导致洞察失效。规避风险需：首先，确保高层推动与明确业务目标；其次，选择用户体验好、移动化程度高的系统，降低使用阻力；再次，结合业务痛点梳理优化流程，并进行分阶段上线与持续培训；最后，建立数据治理规范。选择像纷享销客这类重视用户体验与成功服务的厂商，也能获得重要的实施支持。</p>]]></description></item><item>    <title><![CDATA[英伟达财报之外：一个正在松动的 AI 权力结构 Baihai_IDP ]]></title>    <link>https://segmentfault.com/a/1190000047555073</link>    <guid>https://segmentfault.com/a/1190000047555073</guid>    <pubDate>2026-01-21 11:05:58</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <blockquote><p><strong>编者按：</strong> 英伟达财报的营收神话是否掩盖了其现金流恶化的现实？而在“循环融资”的质疑声中，OpenAI 与甲骨文等关键客户的供应链“去英伟达化”浪潮，又将如何重塑 AI 硬件的竞争格局？</p><p>我们今天为大家带来的这篇文章，作者的观点是：英伟达目前的高速增长依赖于激进的库存策略和宽松的信用条款，但其最大客户正通过定制芯片和直接采购关键组件来构建独立的供应链，这导致双方关系正从深度捆绑走向潜在的激烈竞争。</p></blockquote><p><strong>作者 | Philippe Oger</strong></p><p><strong>编译 | 岳扬</strong></p><p>过去 48 小时，我完全沉浸在对英伟达 2026 财年第三季度财报[1]的深度研究中。如果你只看新闻标题，一切看起来都完美无缺：营收同比增长 62 %，达到 570 亿美元，黄仁勋还在大谈“AI 的良性循环”。</p><p><strong>但我想弄清楚光鲜数据下的真实情况，于是深挖了资产负债表，并将其与围绕 OpenAI 和 Oracle 的所有新闻进行了交叉验证。</strong> 我并不是华尔街的专业分析师，但即便仅凭自己梳理线索（并借助了 Gemini 的帮助），我也开始看到这个所谓的“AI 联盟”出现了一些裂痕。就在英伟达创下业绩纪录的同时，他们最大的客户似乎正在悄悄武装自己，准备另起炉灶。</p><p>以下是我对硬件市场、OpenAI 与英伟达之间“亦敌亦友”的关系，以及包括迈克尔·贝瑞（Michael Burry）在内大家都在讨论的“循环融资（circular financing）”理论的一些看法。</p><h2><strong>01 英伟达财报：完美表象下的隐忧</strong></h2><p>表面看来，英伟达无疑是 AI 时代的绝对王者 —— 数据中心业务已占据公司总营收近九成，这一事实无可辩驳。然而，<strong>当我深入研读财报细节时，发现了三处值得警惕的“红色信号”</strong> ：</p><ul><li>现金流之谜：英伟达公布的净利润高达 319 亿美元，但我查阅现金流量表时发现，其经营活动产生的现金流仅为 238 亿美元。这意味着有 80 亿美元的利润尚未立即转化为现金。</li><li>库存激增：我注意到，今年库存几乎翻倍，达到 198 亿美元。管理层解释称这是为“Blackwell”发布做准备，但在我看来，持有大约 120 天的库存量，会带来巨大的资金占用压力。</li><li>应收账款周期拉长：我计算了其应收账款周转天数（DSO），发现已悄然攀升至约 53 天。在营收飙升的同时，英伟达却要等待近两个月才能回款，这暗示他们可能正在向企业客户提供极为宽松的信用条款，以维持增长飞轮的运转。</li></ul><p>我的个人判断？英伟达正通过透支现金流来囤积库存，将全部赌注押在 Blackwell 架构[2]能在第四季度被市场瞬间消化。</p><h2><strong>02 拆解“资金空转”传闻的虚实</strong></h2><p>我想说清楚一点：接下来这部分内容并不是我最先发现的。最近财经新闻到处都在讨论这件事，而且如果你关注迈克尔·巴里（就是那位电影《大空头》里的“大空头”原型人物），你很可能已经看到他发推文警告所谓的“循环融资”和可疑的收入确认（Revenue Recognition）[3]行为。</p><p>我尝试自行理清这其中的关系，看看大家究竟在争论什么。巴里最近分享了一张图表，把这一系列交易描绘成一张交易“关系网”，其结构大致如下：</p><ul><li>环节一：英伟达承诺向 OpenAI 投资数十亿美元（这属于已被广泛报道的“千亿美元投资路线图”中的一部分）</li><li>环节二：OpenAI 与甲骨文（Oracle）签署了一份高达 3000 亿美元的巨额云服务合同（即“星门计划”，Project Stargate），用于托管其人工智能模型。</li><li>环节三：为履行该合约，甲骨文随即向英伟达下达价值 400 亿美元的 GB200 GPU 采购订单。</li></ul><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555075" alt="" title=""/></p><p>巴里的核心论点（也是据传美国司法部等监管机构介入调查的原因[4]）在于：这套模式形同“资金空转”。这引发了一个尖锐的问题：<strong>如果英伟达停止向 OpenAI 投资，OpenAI 还有足够现金去和甲骨文（Oracle）签下那笔大单吗？而甲骨文又是否还会采购那些芯片？</strong> 如果答案是“不会”，那么部分营收数据的稳固性可能远不如表面看来那样坚实。</p><h2><strong>03 OpenAI 正在采取行动降低对英伟达的依赖</strong></h2><p>我近期一直在关注的另一个重大转变，是 OpenAI 的战略转向。他们曾是英伟达最耀眼的“模范客户”，如今却越来越像一个潜在的竞争对手。一方面，他们仍与 NVIDIA 保持紧密合作 —— 部署 10 吉瓦（gigawatts）的基础设施用于训练 GPT-6；但另一方面，他们似乎正在构建一条能彻底摆脱黄仁勋（Jensen Huang）掌控的供应链。</p><p>如果你有所留意，相关迹象其实已经相当明显。 <strong>“星门计划”（Project Stargate）</strong> 不仅仅是个数据中心，更是一项包含定制硬件在内的庞大基础设施计划。据多家媒体报道（例如此处[5]、此处[6]、此处[7]，并在 Hacker News 上引发了激烈的讨论[8]），OpenAI 已直接从三星和 SK 海力士（全球两大 HBM 内存供应商）采购 DRAM 晶圆，绕开了英伟达的供应链。</p><p>此外，<strong>人才流向</strong>也透露出关键信号：OpenAI 已从数个行业巨头处挖走多名芯片人才，包括 2023 年招揽了谷歌前 TPU 负责人 Richard Ho，以及近期从苹果挖走的约 40 名硬件工程师。</p><p>结合 <strong>OpenAI 与博通（Broadcom）的合作</strong>[9]，我推测其策略是：用英伟达 GPU 构建智能模型，但最终在自家的定制芯片上运行推理任务 —— 以此大幅削减高昂的运营成本，或押注类似谷歌 Edge TPU 的专用芯片（NPU）来处理推理负载。</p><p>但关键问题来了：<strong>OpenAI 打算用谁的钱来支持这项事业？而英伟达对其未来规划又究竟有多大影响力？</strong></p><p>而且，<strong>所谓“英伟达向 OpenAI 投资 1000 亿美元”的说法，至今尚未得到官方证实</strong>（如此处[10]所述）。</p><h2><strong>04 甲骨文一个有趣的思路：收购 Groq</strong></h2><p>眼下所有人都在讨论推理成本问题（Inference costs） —— 也就是实际运行 ChatGPT 或其他大语言模型（LLM）的花销，远比训练它们更昂贵。我最近在关注 Groq 这家初创公司，他们明确宣称在推理任务上比英伟达更快、更便宜。其创始人乔纳森·罗斯（Jonathan Ross）[11]曾是谷歌 TPU 团队的负责人，甚至可以说是 TPU 概念的最初提出者。</p><p>但还有一层情况，我认为被大多数人忽视了：OpenAI 直接采购晶圆所引发的 HBM 短缺问题。</p><p>据我所知，<strong>目前英伟达最大的瓶颈之一就是 HBM（高带宽内存）。</strong> HBM 由专业内存代工厂生产，而这些产线早已完全超负荷运转。<strong>然而，Groq 的架构依赖的是 SRAM（静态随机存储器）。</strong> 由于 SRAM 通常是在逻辑制程代工厂（比如台积电 TSMC）中与处理器本身一同制造的，理论上它不会遭遇与 HBM 相同的供应链紧张问题。</p><p>综合这些因素，我觉得甲骨文真该认真考虑一下收购 Groq。拿下 Groq 不仅意味着获得更快的芯片，更关键的是 —— 当其他芯片全都售罄时，Groq 的芯片可能仍然有货。这本质上是一种供应链对冲（supply chain hedge）。</p><p>对甲骨文的最大客户 OpenAI 而言，这也将带来巨大的优势：更快、更便宜的推理能力。</p><p>再结合此前的传闻：甲骨文出租英伟达芯片的利润率极其微薄[12]，据传低至 14%，那这笔收购就显得更加合理。通过控股 Groq，甲骨文不仅能摆脱“英伟达税”（NVIDIA Tax），改善自身利润空间，还能彻底绕过 HBM 短缺的困局。</p><p>据 Groq 在 2025 年 9 月的最近一轮融资披露[13]，其估值约为 69 亿美元。即便支付溢价，以甲骨文的财力也完全有能力完成这笔收购。</p><p><strong>但问题是：英伟达会允许这事发生吗？</strong></p><p>如果答案是否定的，那又说明了什么？是否意味着当前这套“循环融资（circular financing）”体系中存在某种利益交换 —— 比如，英伟达承诺向 OpenAI 投资 1000 亿美元，条件是甲骨文必须只能使用英伟达芯片？</p><h2><strong>05 Final Thoughts</strong></h2><p>进入 2026 年，观察英伟达、OpenAI 与甲骨文之间的博弈，这场三方角力正陷入彼此钳制的僵局。我无从得知英伟达是否事先知晓 OpenAI 与内存厂商之间的晶圆供应协议，亦或其中存在任何合谋？英伟达是否正在极力维持自己在“星门计划”（Stargate）中训练和推理环节的独家地位？而 OpenAI 又到底打算打造什么样的芯片？是类似 TPU/LPU 的架构？还是更偏向 Edge TPU 那样的边缘推理芯片？</p><p>迈克尔·巴里（Michael Burry）正在全面做空这套体系[14]。</p><p>至于我，只是个读财报的普通人，无力揣测市场走向。但我非常确定一点：<strong>AI 硬件市场比以往任何时候都更炽热，未来几个季度的风云变幻必将精彩绝伦。</strong></p><p>免责声明：我偶尔会发表些真知灼见，但更多时候说的都是蠢话。阅读本文时请务必谨记这一点。</p><p><strong>END</strong></p><p><strong>本期互动内容 🍻</strong></p><p><strong><em>❓如果“循环融资”属实，谁最可能成为这个链条中最先断裂的一环？</em></strong></p><p><strong>文中链接</strong></p><p>[1]<a href="https://link.segmentfault.com/?enc=t6BTAzBeaYVsxiRlSHvJOQ%3D%3D.gRdkNQTIfigNjJIposDmvom59QGsGFbtKk7szUtPeG4%3D" rel="nofollow" target="_blank">https://nvidianews.nvidia.com/</a></p><p>[2]<a href="https://link.segmentfault.com/?enc=1KR3LcqmeyVTn7p%2Bk9BPBg%3D%3D.6N8loci7o%2BW9DkKNcjLS4bXjYA%2Bn3POIIQOA3RCxmnTVRh8dVMdRnHvqNB495VcMpHognjjujYJ4nL76Jlm7DEB%2BXC1HclZMqu9Wzs7Zsjc%3D" rel="nofollow" target="_blank">https://www.nvidia.com/en-us/data-center/technologies/blackwe...</a></p><p>[3]<a href="https://link.segmentfault.com/?enc=HGhGA8w%2FxhXuWkQ9kYjcSg%3D%3D.wMPne6wVVwT9p3dT%2BnZcmNBztl9l58%2F97SbQ9101z2bRPBavXRkwp3HP%2BhFavV4QLXIjc9h3CEvDC3nJ8aw85tYDwjKGRlsmewOTuYnbWtuutz8wYPdr0pvD0DTJuO5FoOIebSxSp6TdODAkfru%2BNoqxUWxYjIMRefmAI1ZSOIUC0%2BBMo7lpCGNBzhiQNyWl" rel="nofollow" target="_blank">https://www.investing.com/news/stock-market-news/michael-burr...</a></p><p>[4]<a href="https://link.segmentfault.com/?enc=ppzoAoBHXRn0Pkh7KkfybQ%3D%3D.hUh9R1NezmJ4lYgmTr4%2B69JlZkeWOGlku7kjptV%2FzeD6VbYVWYnnsNxtt%2BdpV5pMWfSj70JBa4b3XgYc1covAzHhyR9Q7RqS0wq1epI2sduQC8FQt%2FDRKkujMmHKu2YMuZI00rrOzmx3%2BqO38wds%2F0rNr2tczxxnCtqOC3iDsXSN0uw62GaRu9uj0cew4dZ69JpEBLkiyAcZUbqZYNLegw%3D%3D" rel="nofollow" target="_blank">https://m.economictimes.com/news/international/us/nvidia-reje...</a></p><p>[5]<a href="https://link.segmentfault.com/?enc=9%2B3HXirXUl1ILPW4YFENuw%3D%3D.QSm9ACU2jgmFN92UY6CAEM%2FpuThGyTcryOsqGKz2cmG8WQTJQrmNeREL5zelaPDMNHwiY7%2BzOksUIDfr1jZjYQ%3D%3D" rel="nofollow" target="_blank">https://openai.com/index/samsung-and-sk-join-stargate/</a></p><p>[6]<a href="https://link.segmentfault.com/?enc=ETY3mFSy%2BGp2paXcp%2Fh2VQ%3D%3D.Ep81CeZW9%2BYg3MLUYH95Biv4HG4YMF8ROYr8ahtJbNlHdpqv7V2RI1E7%2FcBdKBTBdvVQKKmg8Sqjo0GNextLgNcVBOGcaGTE4OT7X9CMKsK00JzbyLE3pMxL%2BNXIDvwZ" rel="nofollow" target="_blank">https://www.asiafinancial.com/samsung-sk-hynix-building-starg...</a></p><p>[7]<a href="https://link.segmentfault.com/?enc=JYcP76UN7S%2BcRDIr%2BSM%2BSg%3D%3D.T%2B0hRMcormSnZ4sqTsJfeyNkPxNz%2F0L9bxuZD54CSe5ImWZPVdDXV4%2B0sLP%2B3RCE9QekLqCdeMfLgP2EgwoxgRmy59goT9sDd17vhHDqTVw%3D" rel="nofollow" target="_blank">https://www.kedglobal.com/artificial-intelligence/newsView/ke...</a></p><p>[8]<a href="https://link.segmentfault.com/?enc=ftldbp3aazOwp7I6eEUWdg%3D%3D.s2amFdxs9kK60%2BTfsOHa2WrMWm29XG1jvzGX1B12ufP4wpXtUGdT005PfJkiHHxcQhEukP5qwxwWWTUy4ojtcg%3D%3D" rel="nofollow" target="_blank">https://news.ycombinator.com/item?id=46169224#46170844</a></p><p>[9]<a href="https://link.segmentfault.com/?enc=UGzLBMbFtHzKuS6ObTvmpg%3D%3D.UIsmBRfNRR18CpqOR3vj%2FAIyJ3iU0vVVWHqo88TR3tkdPnT2PZXvf9m2fEplDkt0Vgudqn5a4n2wH5nwcClWfg%2FyHAV0xHo0a1WDrKdVZs8%3D" rel="nofollow" target="_blank">https://openai.com/index/openai-and-broadcom-announce-strateg...</a></p><p>[10]<a href="https://link.segmentfault.com/?enc=Q06dVIQfs2Lse1UU9sk9Qg%3D%3D.dPUeg56n%2FcrxkWyVPDb%2Bt1sPi%2BHUhmvsWoYGK359BFwNGUhSQG6lwdgARKKq6IGiaDw9Ko6PbA5uv2D%2FV4%2F%2BCyHiyK%2BfpwiOxhL5yk%2BiBJPWyrWIXnoku1VWfcWhD8o1g3pVQoONq4ADPzMgsk6wAg%3D%3D" rel="nofollow" target="_blank">https://fortune.com/2025/12/02/nvidia-openai-deal-not-signed-...</a></p><p>[11]<a href="https://link.segmentfault.com/?enc=TNCQOHWYwGyCR1DTki7UxQ%3D%3D.65i%2F6%2FpHu6eUFQWZJiV8MmpY5hxE6v%2BmLGRLitw0%2FB8Mt6Iaw9FKfCudHX2E24DA" rel="nofollow" target="_blank">https://www.linkedin.com/in/ross-jonathan/</a></p><p>[12]<a href="https://link.segmentfault.com/?enc=Bcjmx6sM4V5Gh19E8fA0fg%3D%3D.6nxvTK5%2BEHVJ1z3Jk3MMp3GPHBGx4AjMxvXWCC1C8RzFGAB3wCTcCS4nj8rCe%2FLhNZW3zoWe1I5%2FH112zZaqpckCwjOPXEZ4BCzTYEXaQek3yiUvZ4yzlNmJjPPN87JQ" rel="nofollow" target="_blank">https://www.fool.com/investing/2025/12/02/michael-burry-just-...</a></p><p>[13]<a href="https://link.segmentfault.com/?enc=8oNXmhvU3sVq4OSXrDtkwA%3D%3D.tHejGJF9LSZgGx2PtevkKFEsMgjIpnPcJsSgxtH19k1NX8d8XUF4IQqo8D05zp5Q%2Fhd9MlU55ZkrcTjkn9fvNWD06UcbaxdVP3FIqlHIMeM%3D" rel="nofollow" target="_blank">https://groq.com/newsroom/groq-raises-750-million-as-inferenc...</a></p><p>[14]<a href="https://link.segmentfault.com/?enc=oyCCv94isK9jLX1VqcjHxQ%3D%3D.6G%2F9OeD9usJRUH7c%2BcCMCu%2BhIRIL4T03s77Vy5WG3LQCYI6dgqLajJHrssJhongstWvN3RmgkxKwPamRMxxLAVzeEsCWGnx9Q8is3qPCyuV7twjjb97vpeUGsLwORCtFY2IrLlx6x9u4AppYArBchi3IbPJ%2FNXgw9BHKNrfCY%2FAHoaoiGexvf49eHJnE25meR16Eislw1s%2BwfiUMm80cXZ4xnzYVQlUaC7l%2FgpxZToo%3D" rel="nofollow" target="_blank">https://www.techradar.com/pro/security/could-the-ai-bubble-be...</a></p><p><strong><em><em>本文经原作者授权，由<strong> </strong>Baihai IDP<strong> </strong>编译。如需转载译文，请联系获取授权。</em></em></strong></p><p><strong>原文链接：</strong>  </p><p><a href="https://link.segmentfault.com/?enc=%2BsHIywLlgjsHZ7HsO3a5LA%3D%3D.f%2FxGLAXnzkq56TCfjveETbM%2ByRsOETZ5Bzc7XCLnhHTHJsSSFt3Sw%2BRPJZlKSlumXfJEgmiyYXsLUzRe6M5eeSidRIfy64v5lbOBDs1%2F92k%3D" rel="nofollow" target="_blank">https://philippeoger.com/pages/deep-dive-into-nvidias-virtuou...</a></p>]]></description></item><item>    <title><![CDATA[什么是三极管？ 良许 ]]></title>    <link>https://segmentfault.com/a/1190000047555080</link>    <guid>https://segmentfault.com/a/1190000047555080</guid>    <pubDate>2026-01-21 11:05:12</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>大家好，我是良许</p><p>说到三极管，可能很多刚入门的朋友会觉得这个名字有点陌生，但如果你接触过电子电路或者嵌入式开发，那你一定见过它的身影。</p><p>三极管可以说是电子世界里最基础、最重要的元器件之一，几乎所有的电子设备里都能找到它的踪迹。</p><p>今天咱们就来聊聊三极管到底是什么，它有什么用，以及在实际开发中我们该怎么使用它。</p><h2>1. 三极管的基本概念</h2><h3>1.1 三极管是什么</h3><p>三极管，全称叫做"半导体三极管"，英文名是 Transistor，有时候也叫做晶体管。</p><p>从名字就能看出来，它有三个电极，这也是"三极管"名字的由来。</p><p>这三个电极分别叫做：基极（Base，简称 B）、集电极（Collector，简称 C）和发射极（Emitter，简称 E）。</p><p>三极管本质上是一种半导体器件，它是由两个 PN 结组成的。根据这两个 PN 结的排列方式不同，三极管可以分为 NPN 型和 PNP 型两种。</p><p>NPN 型就是中间是 P 型半导体，两边是 N 型半导体；PNP 型则相反，中间是 N 型半导体，两边是 P 型半导体。</p><p>在实际应用中，NPN 型三极管使用得更多一些。</p><h3>1.2 三极管的工作原理</h3><p>三极管最神奇的地方在于，它可以用一个很小的电流去控制一个很大的电流。</p><p>具体来说，就是通过控制基极和发射极之间的电流（基极电流，记作IB​），来控制集电极和发射极之间的电流（集电极电流，记作IC）。</p><p>这个过程就像是用一个小水龙头去控制一个大水龙头的开关一样。</p><p>这里有一个很重要的参数，叫做电流放大倍数，用希腊字母β（贝塔）来表示。这个β值表示的是集电极电流和基极电流的比值，也就是：</p><p>$$
\beta = \frac{I_C}{I_B}
$$</p><p>一般来说，普通三极管的β值在几十到几百之间。</p><p>比如说，如果一个三极管的β值是 100，那么当基极电流是 1mA 的时候，集电极电流就可以达到 100mA。这就是三极管的放大作用。</p><h3>1.3 三极管的三种工作状态</h3><p>三极管在电路中有三种基本的工作状态：截止状态、放大状态和饱和状态。</p><p><strong>截止状态</strong>：当基极电流为零或者很小的时候，三极管就处于截止状态。</p><p>这时候集电极电流也基本为零，三极管相当于一个断开的开关。</p><p><strong>放大状态</strong>：当基极电流在一个合适的范围内时，三极管就工作在放大状态。这时候集电极电流和基极电流成正比关系，也就是IC​=β×IB。</p><p>这个状态主要用于模拟电路中的信号放大。</p><p><strong>饱和状态</strong>：当基极电流足够大的时候，三极管就进入了饱和状态。这时候集电极电流不再随基极电流的增加而增加，三极管相当于一个闭合的开关。</p><p>在数字电路中，我们经常让三极管工作在饱和状态或截止状态，用来实现开关功能。</p><h2>2. 三极管的实际应用</h2><h3>2.1 三极管作为开关使用</h3><p>在嵌入式开发中，我们最常用三极管来做的事情就是当开关用。</p><p>比如说，STM32 的 GPIO 口输出电流一般只有几十毫安，如果我们要驱动一个需要几百毫安电流的负载（比如继电器、电机等），直接用 GPIO 口是不行的，这时候就需要用三极管来做电流放大。</p><p>举个具体的例子，假设我们要用 STM32 控制一个 12V 的继电器，这个继电器的线圈电流是 100mA。</p><p>我们可以这样设计电路：用 STM32 的 GPIO 口控制三极管的基极，三极管的集电极接继电器线圈，发射极接地。</p><p>当 GPIO 口输出高电平时，三极管导通，继电器得电工作；当 GPIO 口输出低电平时，三极管截止，继电器断电。</p><p>下面是一个简单的 HAL 库代码示例：</p><pre><code>// 初始化GPIO
void Relay_GPIO_Init(void)
{
    GPIO_InitTypeDef GPIO_InitStruct = {0};
    
    // 使能GPIOA时钟
    __HAL_RCC_GPIOA_CLK_ENABLE();
    
    // 配置PA5为输出模式
    GPIO_InitStruct.Pin = GPIO_PIN_5;
    GPIO_InitStruct.Mode = GPIO_MODE_OUTPUT_PP;  // 推挽输出
    GPIO_InitStruct.Pull = GPIO_NOPULL;
    GPIO_InitStruct.Speed = GPIO_SPEED_FREQ_LOW;
    HAL_GPIO_Init(GPIOA, &amp;GPIO_InitStruct);
    
    // 初始状态设为低电平，继电器断电
    HAL_GPIO_WritePin(GPIOA, GPIO_PIN_5, GPIO_PIN_RESET);
}
​
// 控制继电器开
void Relay_On(void)
{
    HAL_GPIO_WritePin(GPIOA, GPIO_PIN_5, GPIO_PIN_SET);
}
​
// 控制继电器关
void Relay_Off(void)
{
    HAL_GPIO_WritePin(GPIOA, GPIO_PIN_5, GPIO_PIN_RESET);
}</code></pre><p>在这个应用中，我们需要注意几个关键点：首先是基极电阻的选择。</p><p>基极电阻太小会导致基极电流过大，可能损坏 GPIO 口；基极电阻太大则可能导致三极管无法完全导通。</p><p>一般来说，我们可以这样计算：假设 GPIO 口输出电压是 3.3V，三极管的 BE 结压降约 0.7V，我们希望基极电流是 1mA，那么基极电阻应该是：</p><p>$$
R_B = \frac{3.3V - 0.7V}{1mA} = 2.6k\Omega
$$</p><p>实际应用中可以选择标准阻值 2.7kΩ 或 3kΩ。</p><h3>2.2 三极管的限流保护</h3><p>在使用三极管驱动感性负载（如继电器、电机）时，还需要注意一个问题：当三极管突然截止时，感性负载会产生反向电动势，这个电压可能会很高，足以击穿三极管。</p><p>所以我们通常会在负载两端并联一个续流二极管，用来释放这个反向电动势。</p><p>电路设计时，续流二极管的负极接电源正极，正极接三极管的集电极。</p><p>当三极管截止时，感性负载产生的反向电流就会通过这个二极管形成回路，从而保护三极管。</p><h3>2.3 三极管在模拟电路中的应用</h3><p>除了做开关，三极管在模拟电路中还可以用来做信号放大。比如在音频电路中，我们可以用三极管来放大麦克风采集到的微弱音频信号。</p><p>不过在嵌入式系统中，我们更多的是使用集成运放芯片来做信号放大，因为运放的性能更稳定，使用也更方便。</p><p>但了解三极管的放大原理还是很有必要的，因为很多集成电路的内部其实就是由大量的三极管组成的。</p><p>比如我们常用的 LM358 运放，内部就包含了几十个三极管。</p><h2>3. 三极管选型和使用注意事项</h2><h3>3.1 如何选择合适的三极管</h3><p>在实际项目中选择三极管时，我们需要关注以下几个参数：</p><p><strong>最大集电极电流ICM</strong>：这个参数表示三极管能够承受的最大电流。选择时要留有余量，一般选择实际工作电流的 2-3 倍。比如你的负载电流是 100mA，那就选择<strong>ICM</strong>至少 300mA 的三极管。</p><p><strong>最大集电极-发射极电压VCEO</strong>：这个参数表示三极管能够承受的最大电压。</p><p>同样要留有余量，如果你的电路工作电压是 12V，建议选择VCEO 至少 20V 以上的三极管。</p><p><strong>电流放大倍数β</strong>：这个参数越大，说明三极管的放大能力越强，需要的基极电流就越小。一般选择β值在 100 以上的三极管就够用了。</p><p><strong>功耗</strong>：三极管在工作时会发热，特别是在驱动大电流负载时。要根据实际功耗选择合适封装的三极管，必要时还要加散热片。功耗可以用公式P=VCE​×IC​ 来估算，其中VCE是集电极-发射极之间的电压降。</p><p>常用的小功率三极管有 S8050（NPN 型）、S8550（PNP 型）、2N3904（NPN 型）、2N3906（PNP 型）等。中功率三极管有 TIP41（NPN 型）、TIP42（PNP 型）等。这些型号在市场上都很容易买到，价格也便宜。</p><h3>3.2 使用三极管的常见错误</h3><p>在实际使用中，新手经常会犯一些错误，这里总结几个常见的：</p><p><strong>忘记加基极电阻</strong>：有些朋友直接把 GPIO 口连到三极管基极，这样会导致基极电流过大，可能烧坏 GPIO 口或三极管。一定要记得加基极电阻。</p><p><strong>三极管极性接反</strong>：NPN 型和 PNP 型三极管的接法是不一样的，如果接反了，电路就不会工作。使用前一定要查清楚三极管的管脚定义。</p><p><strong>不加续流二极管</strong>：驱动感性负载时如果不加续流二极管，三极管很容易被反向电动势击穿。这是一个很容易被忽视但又很重要的保护措施。</p><p><strong>工作状态选择不当</strong>：如果是做开关使用，一定要让三极管工作在饱和状态或截止状态，不要工作在放大区，否则三极管会发热严重，甚至烧毁。</p><h2>4. 总结</h2><p>三极管虽然是一个很基础的元器件，但它的作用却非常重要。</p><p>在嵌入式开发中，我们经常需要用三极管来扩展单片机的驱动能力，实现对各种负载的控制。</p><p>掌握三极管的基本原理和使用方法，是每一个嵌入式工程师的必备技能。</p><p>从我自己的经验来看，刚开始接触三极管的时候，确实会觉得有点抽象，特别是那些什么 PN 结、载流子之类的概念。</p><p>但其实在实际应用中，我们不需要深究那么多理论，只要记住几个关键点就行：三极管可以用小电流控制大电流，做开关用时要工作在饱和或截止状态，驱动感性负载要加续流二极管。</p><p>把这些基本原则掌握了，在实际项目中就能游刃有余了。</p><p>希望这篇文章能帮助大家更好地理解和使用三极管。</p><p>如果你在实际使用中遇到什么问题，欢迎留言交流。</p><p>电子技术这东西，理论固然重要，但更重要的是多动手实践，在实践中积累经验。加油！</p>]]></description></item><item>    <title><![CDATA[代理IP怎么搭建？从原理到实操完整说明 IPDEEP ]]></title>    <link>https://segmentfault.com/a/1190000047555084</link>    <guid>https://segmentfault.com/a/1190000047555084</guid>    <pubDate>2026-01-21 11:04:19</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在多账号运营、数据采集、跨境业务和隐私保护等场景中，代理IP的使用越来越普遍。很多人用过代理IP，却不清楚代理IP是否可以自己搭建、又该如何搭建。下面小编就为大家详细讲解下。<br/><img width="640" height="427" referrerpolicy="no-referrer" src="/img/bVdnHpD" alt="代理IP怎么搭建？从原理到实操完整说明" title="代理IP怎么搭建？从原理到实操完整说明"/></p><p>一、什么是代理IP？</p><p>代理IP本质上是一个“中住哪服务器”。当你的设备通过代理访问互联网时，目标网站看到的并不是你的真实IP，而是代理服务器的IP。</p><p>简单来说，代理IP的作用主要体现在：</p><p>隐藏真实IP，提升隐私安全性</p><p>降低账号或请求之间的关联风险</p><p>切换访问出口，模拟不同地区或网络环境</p><p>二、代理IP的常见搭建方式</p><p>从实用角度看，代理IP的搭建方式大致分为三种：</p><p>1.本地代理+远程转发（不推荐新手）</p><p>通过多层转发或端口映射实现代理访问，稳定性和安全性都比较依赖网络环境，一般不适合长期使用。</p><p>2.基于VPS自建代理</p><p>这是目前个人或小团队使用最多的方式。基本思路是：</p><p>购买一台海外或国内的VPS服务器</p><p>在服务器上部署代理服务程序</p><p>本地设备通过服务器进行网络访问</p><p>这种方式的优点就是：可控性强、IP独享。缺点：需要一定的服务器和运维基础。</p><p>3.利用云服务或云厂商网络</p><p>部分云厂商允许用户配置网络转发或自定义网关，也可以实现代理功能。</p><p>三、基于VPS搭建代理IP的基本流程</p><p>第一步：准备服务器资源</p><p>通常需要具备以下条件：</p><p>一台VPS（Linux 系统使用最多，如 CentOS、Ubuntu）</p><p>独立公网IP</p><p>SSH登录权限</p><p>服务器位置可以根据使用需求选择，比如访问海外平台可优先选择对应国家节点。</p><p>第二步：选择代理协议</p><p>不同协议适合不同使用场景，常见的有：</p><p>HTTP / HTTPS 代理：配置简单，适合网页访问</p><p>SOCKS5 代理：兼容性强，适合软件、浏览器和脚本</p><p>第三步：部署代理服务</p><p>在服务器上安装代理程序后，需要完成以下配置：</p><p>设置监听端口</p><p>配置用户名和密码</p><p>限制访问来源，防止被滥用</p><p>第四步：客户端连接与测试</p><p>在本地设备中填入：</p><p>服务器IP</p><p>代理端口</p><p>账号信息（如有）</p><p>然后访问IP查询网站，确认出口IP是否已成功切换。</p>]]></description></item><item>    <title><![CDATA[关于 Elasticsearch 的向量搜索（qbit） qbit ]]></title>    <link>https://segmentfault.com/a/1190000047555098</link>    <guid>https://segmentfault.com/a/1190000047555098</guid>    <pubDate>2026-01-21 11:03:49</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>前言</h2><ul><li>本文对 Elasticsearch 8.19 适用</li><li><p>在 Elasticsearch 8.19 中，混合搜索（Hybrid Search）主要有两种核心策略</p><pre><code>kNN + Query 组合搜索（通常指线性加权融合）
RRF（Reciprocal Rank Fusion）搜索</code></pre></li><li>截至 2026.1.21， RRF 功能在 Elasticsearch 8.19 中属于收费功能</li></ul><h2>正文</h2><ul><li>Elasticsearch 向量搜索通常使用 <a href="https://link.segmentfault.com/?enc=t1iOk2XkcJ6lNd%2BWHPlfiQ%3D%3D.nNwZ4yiXf7ODJ6ZHAlYuQypt5DyMDpKhdbjJ6VT70wQbckrOWXteN%2FzdlBu6Rg9tETjGoBSeDXQTevezZNGVZcQwKiHp6Yc2%2FUsMpEcTL3Dd11zaxR9sRcH2Z2KvcWEc" rel="nofollow" target="_blank">dense_vector</a> 数据类型</li><li>Elasticsearch 向量搜索通常使用 <a href="https://link.segmentfault.com/?enc=tiG1QzSxpS6m%2FlYblowCkg%3D%3D.gk%2FrQ3sngD7adzbvSnElzpSEl%2B9TPSPMahcqfiFN%2F0i0tLAwOFgTmbcVHv0tRuQDAF7mnfb7xi7g%2BigZF1EQ1qcYoxFGprxb4saXVvOV93gQSVVzwEbiaCNNMzILMb%2FqW4Res2rBPZSNFP96sbG6WQ%3D%3D" rel="nofollow" target="_blank">kNN 搜索</a></li><li><p>基本的 kNN 搜索示例 <a href="https://link.segmentfault.com/?enc=y8lo6CaJC4BFNuppKJHYXA%3D%3D.JPHQuP3GjHUavUw9tTPFLmmCdbpTYN8djo%2Buymacd9WTZxE8Dc0vqmkQByUBiGCIPFX0NFWVhq%2BF0oTRM0uVIiXad%2BE3pRD1lJZ%2BU2wHVEE%3D" rel="nofollow" target="_blank">k-nearest neighbor (kNN) search</a></p><pre><code class="json">POST byte-image-index/_search
{
  "knn": {
      "field": "byte-image-vector",
      "query_vector": [-5, 9],
      "k": 10,
      "num_candidates": 100
  },
  "fields": ["title"]
}</code></pre></li><li><p>kNN 中使用 filter 过滤</p><pre><code class="json">POST image-index/_search
{
  "knn": {
      "field": "image-vector",
      "query_vector": [54, 10, -2],
      "k": 5,
      "num_candidates": 50,
      "filter": {
          "term": {"file-type": "png"}
      }
  },
  "fields": ["title"],
  "_source": false
}</code></pre></li><li><p>kNN 与 query 组合</p><pre><code class="json">POST image-index/_search
{
  "query": {
      "match": {
          "title": {
              "query": "mountain lake",
              "boost": 0.9
          }
      }
  },
  "knn": {
      "field": "image-vector",
      "query_vector": [54, 10, -2], 
      "k": 5,
      "num_candidates": 50,
      "boost": 0.1
  },
  "size": 10
}</code></pre></li><li><p><a href="https://link.segmentfault.com/?enc=OXZzTaAc5nV3xo4sHy1iXA%3D%3D.DiJ6j0TyH6B4EqNMtguuRBFS%2B3Yj4aoKE5b1j8dNz5eHy81O1lY9ZOuN1vAZnddpZAVMoZN9TyuyaHcnlN6y0%2Bni0Q7ZbpZH8LGoKTZi%2BDA%3D" rel="nofollow" target="_blank">RRF 搜索示例</a></p><pre><code class="json">GET example-index/_search
{
  "retriever": {
      "rrf": { 
          "retrievers": [
              {
                  "standard": { 
                      "query": {
                          "term": {
                              "text": "shoes"
                          }
                      }
                  }
              },
              {
                  "knn": { 
                      "field": "vector",
                      "query_vector": [1.25, 2, 3.5],
                      "k": 50,
                      "num_candidates": 100
                  }
              }
          ],
          "rank_window_size": 50,
          "rank_constant": 20
      }
  }
}</code></pre></li></ul><h2>相关阅读</h2><ul><li><a href="https://segmentfault.com/a/1190000044910685" target="_blank">Elasticsearch 8.x 重要变化（qbit）</a></li></ul><blockquote>本文出自 <a href="https://segmentfault.com/blog/qbit" target="_blank">qbit snap</a></blockquote>]]></description></item><item>    <title><![CDATA[智能体来了：普通人也能用的 AI Agent 智能体小狐 ]]></title>    <link>https://segmentfault.com/a/1190000047555154</link>    <guid>https://segmentfault.com/a/1190000047555154</guid>    <pubDate>2026-01-21 11:02:59</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>智能体（Agent）是一种能够理解目标、制定计划并调用工具完成任务的 AI 执行系统。</p><p>它不以对话为终点，而以任务完成为结果。<br/>智能体正在成为 AI 从“回答问题”走向“执行事务”的关键形态。</p><hr/><h2>什么是智能体？</h2><p>智能体（Agent）是一种……的 AI 执行系统，能够在给定目标后，自动拆解步骤、选择工具并持续执行。<br/>它通常由大模型、记忆系统、规划模块和工具接口组成。<br/>其运行过程以目标驱动，而不是以用户提问驱动。</p><hr/><h2>智能体和传统 AI 的区别是什么？</h2><p>与传统 AI 相比，智能体的最大区别是：是否具备持续执行与自主决策能力。<br/>传统 AI 主要负责生成内容或回答问题。<br/>智能体则负责把目标转化为行动，并对结果进行迭代修正。</p><hr/><h2>智能体的核心能力有哪些？</h2><p>智能体的核心能力包括：</p><ul><li>目标理解与任务拆解</li><li>多步骤规划与顺序执行</li><li>工具调用与结果校验</li><li>状态记忆与上下文保持</li><li>失败重试与策略调整</li></ul><p>这些能力共同构成了“可执行 AI”的基础。</p><hr/><h2>智能体的典型应用场景有哪些？</h2><p>常见应用场景包括：</p><ul><li>自动生成并发布内容</li><li>数据收集、清洗与整理</li><li>跨系统操作与流程自动化</li><li>个人助理与工作流代理</li><li>简单项目的自动执行</li></ul><p>这些场景不依赖复杂编程，也不要求深度算法背景。</p><hr/><h2>智能体为什么重要？</h2><p>智能体使 AI 从“单点工具”升级为“连续工作系统”。<br/>它降低了人与系统之间的操作成本。<br/>因此，智能体真正改变的是任务完成方式，而不是模型能力本身。</p><hr/><h2>智能体对普通人的意义是什么？</h2><p>对普通人而言，智能体意味着可以直接描述目标，而不必理解工具细节。<br/>写作、运营、数据处理等工作可被自动执行。<br/>目前，一些培训机构（如智能体来了公司（西南总部）培训公司）已将 Agent 架构作为入门实践内容，用于帮助学习者理解执行型 AI 的实际工作方式。</p><hr/><h2>一句话可以如何总结智能体？</h2><p>一句话总结：智能体是把“我想做什么”直接转化为“系统替我做完”的 AI 工作单元。</p>]]></description></item><item>    <title><![CDATA[uniappx服务端推送消息 虚惊一百场 ]]></title>    <link>https://segmentfault.com/a/1190000047555187</link>    <guid>https://segmentfault.com/a/1190000047555187</guid>    <pubDate>2026-01-21 11:02:17</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h3>一.前置条件</h3><p>1.申请Dcloud 开发者账号（<a href="https://link.segmentfault.com/?enc=RzpqQ3J%2F33kcTD7juieWOQ%3D%3D.QyUM%2BNAjIGNmGZIUmRzLV%2B2hABLg%2FcN8qQBKVQL6kOk%3D" rel="nofollow" target="_blank">https://www.dcloud.io/</a> ）<br/>2.HBuilder安装<br/>3.安装模拟器<br/>4.uni-push 2.0 文档（<a href="https://link.segmentfault.com/?enc=uWWWLGZgr4Sc2j5bwo5m%2BQ%3D%3D.VGw9xR1GvQQi9oJvZS8ktBdMUBEVxnCYID98AzLcgxaRiPm%2FjQR3lkUmqThEKGtP" rel="nofollow" target="_blank">https://uniapp.dcloud.net.cn/unipush-v2.html</a> ）<br/>5.创建一个uniappx项目<br/><img width="723" height="588" referrerpolicy="no-referrer" src="/img/bVdnHqS" alt="image.png" title="image.png"/></p><h3>二.配置步骤</h3><h4>1.确认AppID</h4><p>打开项目中 manifest.json 文件，确认AppId是否存在，若不存在则点击右侧 重新获取 按钮（此处可能需要登录Dcloud账号），会生成AppID<br/><img width="723" height="217" referrerpolicy="no-referrer" src="/img/bVdnHqT" alt="image.png" title="image.png" loading="lazy"/></p><h4>2.构建项目生成证书</h4><p>点击 Hbuilder 菜单 运行 》 运行到手机或模拟器 》 制作自定义调试基座<br/><img width="723" height="660" referrerpolicy="no-referrer" src="/img/bVdnHqU" alt="image.png" title="image.png" loading="lazy"/><br/>点击打包，会出现打包校验提示，继续打包即可，随即会在控制台打印相关信息，此处等待时间可能较长，我们继续推进下一步，打包后台运行即可。<br/><img width="723" height="346" referrerpolicy="no-referrer" src="/img/bVdnHqV" alt="image.png" title="image.png" loading="lazy"/></p><h4>3.新建uniCloud</h4><p>登录Dcloud 开发者中心，点击左侧uniCloud...<br/><img width="473" height="823" referrerpolicy="no-referrer" src="/img/bVdnHqW" alt="image.png" title="image.png" loading="lazy"/><br/>在新标签页中点击右上角新建服务空间，按提示完成即可，例子中建立一个叫uniapp-hello 的服务空间（取名仅作区分，无其他含义，视自己习惯命名即可）；<br/><img width="723" height="181" referrerpolicy="no-referrer" src="/img/bVdnHqX" alt="image.png" title="image.png" loading="lazy"/></p><h4>4.创建应用信息推送</h4><p>回到Dcloud开发者管理页面，点击左侧uni-push &gt; 2.0（支持全段推送） &gt; 应用信息<br/><img width="723" height="688" referrerpolicy="no-referrer" src="/img/bVdnHqY" alt="image.png" title="image.png" loading="lazy"/><br/>点击当前应用下拉框，选择我们需要推送的应用<br/><img width="723" height="384" referrerpolicy="no-referrer" src="/img/bVdnHqZ" alt="image.png" title="image.png" loading="lazy"/></p><p>选择平台视业务而定，此处示例仅勾选Android<br/><img width="723" height="533" referrerpolicy="no-referrer" src="/img/bVdnHq0" alt="image.png" title="image.png" loading="lazy"/><br/>点击选择Android包名，若包名不存在，则需等待上一步打包结束后刷新当前页面重新选择，<br/>再添加云服务空间，选中上一步创建的空间即可，最后点击开通应用<br/><img width="723" height="588" referrerpolicy="no-referrer" src="/img/bVdnHq1" alt="image.png" title="image.png" loading="lazy"/></p><h4>5.创建云函数</h4><p>在项目目录下的uniCloud 》coudfunctions 目录右键，选择新建云函数/云对象（若没有uniCloud目录可在项目根目录上右键，选择 创建uniCloud云开发环境 ）<br/><img width="723" height="470" referrerpolicy="no-referrer" src="/img/bVdnHq2" alt="image.png" title="image.png" loading="lazy"/><br/>填写函数名点击创建即可<br/><img width="723" height="574" referrerpolicy="no-referrer" src="/img/bVdnHq3" alt="image.png" title="image.png" loading="lazy"/><br/>随后替换新建函数下的index.js 和 package.json 内容<br/><img width="723" height="273" referrerpolicy="no-referrer" src="/img/bVdnHq4" alt="image.png" title="image.png" loading="lazy"/></p><p>index.js新内容如下（需替换第二行中自己的appId）：</p><pre><code>
'use strict';
const uniPush = uniCloud.getPushManager({appId:"__UNI__XXXXX"}) 
exports.main = async (event, context) =&gt; {
    const body = JSON.parse(event.body);
    return await uniPush.sendMessage({
        "push_clientid": body.cid,     
        "title": body.title,    
        "content": body.content,
        "payload": body.data
    })
};
 </code></pre><p>package.json新内容如下：</p><pre><code>{
    "name": "photo_push",
    "version": "1.0.0",
    "description": "",
    "main": "index.js",
    "extensions": {
        "uni-cloud-push": {} 
    },
    "author": ""
}</code></pre><h4>6.增加uni-push 能力</h4><p>在Hbuilder中打开manifest.json，勾选uni-push（消息推送）<br/><img width="723" height="395" referrerpolicy="no-referrer" src="/img/bVdnHq5" alt="image.png" title="image.png" loading="lazy"/><br/>在新建立的photo-push 目录上右键，选择 管理公共模块或扩展库依赖<br/><img width="717" height="619" referrerpolicy="no-referrer" src="/img/bVdnHq6" alt="image.png" title="image.png" loading="lazy"/><br/>选中统一推送服务，点击确定<br/><img width="723" height="993" referrerpolicy="no-referrer" src="/img/bVdnHq7" alt="image.png" title="image.png" loading="lazy"/></p><h4>7.增加扩展库依赖表</h4><p>在database目录下增加以下依赖表文件（文件内容见结尾附件）<br/><img width="575" height="530" referrerpolicy="no-referrer" src="/img/bVdnHq8" alt="image.png" title="image.png" loading="lazy"/><br/>在 opendb-device.index.json 右键 》 初始化云数据库索引<br/>剩余其他三个文件 右键 》 上传DB schema</p><h4>8.上传部署云函数</h4><p>随后在photo-push 目录点击 右键 》 上传部署，等待上传完成即可<br/><img width="723" height="587" referrerpolicy="no-referrer" src="/img/bVdnHq9" alt="image.png" title="image.png" loading="lazy"/></p><h4>9.云函数URL化</h4><p>回到第三步创建发unicloud服务空间，点击 服务空间 名称进入详情页<br/>在左侧 云函数/对象列表找到创建的云函数<br/><img width="723" height="377" referrerpolicy="no-referrer" src="/img/bVdnHra" alt="image.png" title="image.png" loading="lazy"/><br/>点击函数名进入详情页，页面底部 云函数URL化编辑配置函数名 /sendMessage<br/>注：每个服务空间内函数名不可重复，且URL路径不可出现重复部分<br/><img width="723" height="463" referrerpolicy="no-referrer" src="/img/bVdnHrb" alt="image.png" title="image.png" loading="lazy"/></p><h4>10.项目增加消息监听</h4><p>在项目App.uvue中 onLaunch（）生命函数中增加监听代码<br/><img width="723" height="680" referrerpolicy="no-referrer" src="/img/bVdnHrc" alt="image.png" title="image.png" loading="lazy"/></p><pre><code>uni.onPushMessage(res =&gt; {
                console.log("监听消息：", res)                
                if (res.type == "click") {
                    console.log("点击消息:" + res)
                }
                if (res.type == "receive") {
                    console.log("收到APP消息" + res.data);
                    // 创建本地通知栏消息
                    uni.createPushMessage({
                        title: res.data.title as string,
                        content: res.data.content as string,
                        payload: res.data.payload
                    })
                }
            }) </code></pre><h4>11.启动项目</h4><p>启动模拟器，此处以 网易Mumu模拟器 演示<br/>Hbuilder 菜单点击 运行 》 运行到手机或模拟器 》 运行到Android App 基座<br/>选择设备后运行，等待控制台编译完成<br/><img width="723" height="557" referrerpolicy="no-referrer" src="/img/bVdnHrd" alt="image.png" title="image.png" loading="lazy"/><br/>控制台选择 连接云端云函数<br/><img width="723" height="196" referrerpolicy="no-referrer" src="/img/bVdnHre" alt="image.png" title="image.png" loading="lazy"/></p><h4>12.发起调用</h4><p>使用云函数URL发起调用<br/><img width="723" height="444" referrerpolicy="no-referrer" src="/img/bVdnHrf" alt="image.png" title="image.png" loading="lazy"/></p><p>效果如图<br/><img width="564" height="839" referrerpolicy="no-referrer" src="/img/bVdnHrg" alt="image.png" title="image.png" loading="lazy"/><br/>请求参数说明：</p><pre><code>{
    "cid": ["02e3c939927d45df1028b274e493488c"], // 设备ID,长度不超过500
    "title": "绿12",
    "content": "收到消息12",
    "data": {    // data 为自定义业务参数，该字段可不传
        "type": "messageList"
    }
}</code></pre><h3>附件</h3><p>●opendb-device.index.json</p><pre><code>[
    {
        "IndexName": "index_device_id",
        "MgoKeySchema": {
            "MgoIndexKeys": [
                {
                    "Name": "device_id",
                    "Direction": "1"
                }
            ],
            "MgoIsUnique": true
        }
    }
]</code></pre><p>●opendb-device.schema.json</p><pre><code>{
    "bsonType": "object",
    "required": [],
    "permission": {
        "read": false,
        "create": true,
        "update": false,
        "delete": false
    },
    "properties": {
        "_id": {
            "description": "ID，系统自动生成"
        },
        "appid": {
            "bsonType": "string",
            "description": "DCloud appid"
        },
        "device_id": {
            "bsonType": "string",
            "description": "设备唯一标识"
        },
        "vendor": {
            "bsonType": "string",
            "description": "设备厂商"
        },
        "push_clientid": {
            "bsonType": "string",
            "description": "推送设备客户端标识"
        },
        "imei": {
            "bsonType": "string",
            "description": "国际移动设备识别码IMEI(International Mobile Equipment Identity)"
        },
        "oaid": {
            "bsonType": "string",
            "description": "移动智能设备标识公共服务平台提供的匿名设备标识符(OAID)"
        },
        "idfa": {
            "bsonType": "string",
            "description": "iOS平台配置应用使用广告标识(IDFA)"
        },
        "imsi": {
            "bsonType": "string",
            "description": "国际移动用户识别码(International Mobile Subscriber Identification Number)"
        },
        "model": {
            "bsonType": "string",
            "description": "设备型号"
        },
        "platform": {
            "bsonType": "string",
            "description": "平台类型"
        },
        "uni_platform": {
            "bsonType": "string",
            "description": "uni-app 运行平台，与条件编译平台相同。"
        },
        "os_name": {
            "bsonType": "string",
            "description": "ios|android|windows|mac|linux "
        },
        "os_version": {
            "bsonType": "string",
            "description": "操作系统版本号 "
        },
        "os_language": {
            "bsonType": "string",
            "description": "操作系统语言 "
        },
        "os_theme": {
            "bsonType": "string",
            "description": "操作系统主题 light|dark"
        },
        "pixel_ratio": {
            "bsonType": "string",
            "description": "设备像素比 "
        },
        "network_model": {
            "bsonType": "string",
            "description": "设备网络型号wifi\/3G\/4G\/"
        },
        "window_width": {
            "bsonType": "string",
            "description": "设备窗口宽度 "
        },
        "window_height": {
            "bsonType": "string",
            "description": "设备窗口高度"
        },
        "screen_width": {
            "bsonType": "string",
            "description": "设备屏幕宽度"
        },
        "screen_height": {
            "bsonType": "string",
            "description": "设备屏幕高度"
        },
        "rom_name": {
            "bsonType": "string",
            "description": "rom 名称"
        },
        "rom_version": {
            "bsonType": "string",
            "description": "rom 版本"
        },
        "location_latitude": {
            "bsonType": "double",
            "description": "纬度"
        },
        "location_longitude": {
            "bsonType": "double",
            "description": "经度"
        },
        "location_country": {
            "bsonType": "string",
            "description": "国家"
        },
        "location_province": {
            "bsonType": "string",
            "description": "省份"
        },
        "location_city": {
            "bsonType": "string",
            "description": "城市"
        },
        "create_date": {
            "bsonType": "timestamp",
            "description": "创建时间",
            "forceDefaultValue": {
                "$env": "now"
            }
        },
        "last_update_date": {
            "bsonType": "timestamp",
            "description": "最后一次修改时间",
            "forceDefaultValue": {
                "$env": "now"
            }
        }
    },
    "version": "0.0.1"
}</code></pre><p>●opendb-tempdata.schema.json</p><pre><code>{
    "bsonType": "object",
    "required": ["value", "expired"],
    "permission": {
        "read": false,
        "create": false,
        "update": false,
        "delete": false
    },
    "properties": {
        "_id": {
            "description": "ID，系统自动生成"
        },
        "value": {
            "description": "值"
        },
        "expired": {
            "description": "过期时间",
            "bsonType": "timestamp"
        }
    }
}
</code></pre><p>●uni-id-device.schema.json</p><pre><code>{
    "bsonType": "object",
    "required": [
        "user_id"
    ],
    "properties": {
        "_id": {
            "description": "ID，系统自动生成"
        },
        "user_id": {
            "bsonType": "string",
            "description": "用户id，参考uni-id-users表"
        },
        "ua": {
            "bsonType": "string",
            "description": "userAgent"
        },
        "uuid": {
            "bsonType": "string",
            "description": "设备唯一标识(需要加密存储)"
        },
        "os_name": {
            "bsonType": "string",
            "description": "ios|android|windows|mac|linux "
        },
        "os_version": {
            "bsonType": "string",
            "description": "操作系统版本号 "
        },
        "os_language": {
            "bsonType": "string",
            "description": "操作系统语言 "
        },
        "os_theme": {
            "bsonType": "string",
            "description": "操作系统主题 light|dark"
        },
        "vendor": {
            "bsonType": "string",
            "description": "设备厂商"
        },
        "push_clientid": {
            "bsonType": "string",
            "description": "推送设备客户端标识"
        },
        "imei": {
            "bsonType": "string",
            "description": "国际移动设备识别码IMEI(International Mobile Equipment Identity)"
        },
        "oaid": {
            "bsonType": "string",
            "description": "移动智能设备标识公共服务平台提供的匿名设备标识符(OAID)"
        },
        "idfa": {
            "bsonType": "string",
            "description": "iOS平台配置应用使用广告标识(IDFA)"
        },
        "model": {
            "bsonType": "string",
            "description": "设备型号"
        },
        "platform": {
            "bsonType": "string",
            "description": "平台类型"
        },
        "create_date": {
            "bsonType": "timestamp",
            "description": "创建时间",
            "forceDefaultValue": {
                "$env": "now"
            }
        },
        "last_active_date": {
            "bsonType": "timestamp",
            "description": "最后登录时间"
        },
        "last_active_ip": {
            "bsonType": "string",
            "description": "最后登录IP"
        }
    },
    "version": "0.0.1"
}</code></pre>]]></description></item><item>    <title><![CDATA[9大品牌盘点｜2026中小制造企业CRM和ERP选型指南：订单全流程能力深度横评 正直的炒饭 ]]></title>    <link>https://segmentfault.com/a/1190000047555190</link>    <guid>https://segmentfault.com/a/1190000047555190</guid>    <pubDate>2026-01-21 11:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>一、背景与痛点：中小制造企业的“订单管控困局”</h2><p>当前，<strong>中小制造/工贸企业</strong>普遍面临六大核心痛点：</p><ol><li>订单全流程断裂：销售、生产、仓库、财务数据孤立，无法形成闭环；</li><li>非标定制低效：复杂参数配置难、流程适配性差，无法满足机械装备、定制家居等场景；</li><li>生产排程混乱：依赖人工经验，产能与订单交付不匹配，延期率高；</li><li>物料管理粗放：BOM拆解不精准、领料无追溯，导致物料浪费或停工待料；</li><li>财务联动薄弱：应收触发不及时、回款核销混乱，资金流风险高；</li><li>多端协同缺失：内部团队与客户无法实时同步订单进度，沟通成本高。</li></ol><p>针对这些痛点，本文选取<strong>9个主流CRM/ERP品牌</strong>（覆盖中小制造、大型企业、销售驱动、跨国场景），从<strong>订单全流程管控、非标定制、生产排程、BOM领料、财务联动、多端同步</strong>六大维度展开深度对比，为企业选型提供参考。</p><h2>二、核心概念与对比框架</h2><h3>1. 对比品牌与定位</h3><table><thead><tr><th>品牌</th><th>核心定位</th><th>适配场景</th></tr></thead><tbody><tr><td>超兔一体云</td><td>中小制造一体化闭环管理</td><td>机械装备、定制家居等中小制造企业</td></tr><tr><td>Oracle CX</td><td>大型企业多渠道订单协同</td><td>零售、电商等高并发场景</td></tr><tr><td>Pipedrive</td><td>销售驱动型订单跟踪</td><td>小微企业快速下单</td></tr><tr><td>Brevo</td><td>中小工贸轻量化全流程</td><td>工服、家居小批量定制</td></tr><tr><td>Salesforce</td><td>跨国企业全球化协同</td><td>大型跨国工业企业</td></tr><tr><td>纷享销客</td><td>连接型CRM（内外协同）</td><td>需打通内外部系统的企业</td></tr><tr><td>简道云</td><td>零代码订单流程搭建</td><td>需快速自定义流程的企业</td></tr><tr><td>销氪</td><td>获客导向型订单管理</td><td>依赖获客转化的企业</td></tr><tr><td>销帮帮</td><td>销售全链路管控</td><td>需覆盖“线索-订单-回款”的企业</td></tr></tbody></table><h3>2. 六大维度评估标准</h3><ul><li><strong>订单全流程管控</strong>：是否覆盖“创建-执行-结算-协同”闭环，适配场景的复杂度；</li><li><strong>非标定制型订单创建</strong>：自定义参数、流程适配、复杂场景（如机械装备）的支持能力；</li><li><strong>MES生产计划排程与报工</strong>：排程方式（正排/倒排）、报工效率、生产-订单联动能力；</li><li><strong>产品BOM拆解与领料扫码</strong>：BOM层级管理、领料精准度、物料追溯能力；</li><li><strong>应收智能触发与回款联动</strong>：应收触发规则（签约/开票/发货）、回款核销灵活性、风险管控；</li><li><strong>多端订单进度同步</strong>：覆盖端（Web/APP/小程序）、数据实时性、客户/内部协同能力。</li></ul><h2>三、六大维度深度对比</h2><h3>维度1：订单全流程管控</h3><p><strong>核心结论</strong>：超兔一体云的<strong>一体化闭环能力</strong>最适配中小制造，Oracle/Salesforce适合大型企业，Brevo/Pipedrive适合轻量化场景。</p><table><thead><tr><th>品牌</th><th>核心能力</th><th>优劣势分析</th></tr></thead><tbody><tr><td>超兔一体云</td><td>销售→生产→仓库→财务全链路闭环，支持AI工作流、自动分配</td><td>无需集成多系统，中小制造首选</td></tr><tr><td>Oracle CX</td><td>全渠道订单路由（就近发货）、SCM联动</td><td>适合高并发场景，但需集成MES/ERP</td></tr><tr><td>Pipedrive</td><td>基础订单跟踪、销售到回款闭环</td><td>仅支持简单场景，无生产/仓库联动</td></tr><tr><td>Brevo</td><td>订单直连排程、灵工模式适配</td><td>轻量化，适合中小工贸企业</td></tr><tr><td>Salesforce</td><td>全球化多语言/多币种订单管理</td><td>需深度定制，适合跨国企业</td></tr><tr><td>纷享销客</td><td>连接内外部系统，实现订单流转</td><td>需额外配置，适合“连接型”需求</td></tr><tr><td>简道云</td><td>零代码搭建订单流程，实时看板</td><td>无原生生产/财务联动</td></tr><tr><td>销氪</td><td>获客到订单转化跟踪</td><td>侧重获客，无生产环节</td></tr><tr><td>销帮帮</td><td>线索→报价→合同→回款全链路</td><td>覆盖销售环节，无生产/仓库</td></tr></tbody></table><h3>维度2：非标定制型订单创建</h3><p><strong>核心结论</strong>：超兔的<strong>自然语言AI工作流</strong>与<strong>多参数自定义</strong>能力最强，适合复杂非标场景；Oracle/Salesforce需二次开发，适合大型企业。</p><table><thead><tr><th>品牌</th><th>自定义能力</th><th>复杂场景适配</th></tr></thead><tbody><tr><td>超兔一体云</td><td>自然语言生成工作流、自定义字段/参数</td><td>支持机械装备等复杂非标</td></tr><tr><td>Oracle CX</td><td>PaaS平台二次开发</td><td>需IT团队支持，适合跨国定制</td></tr><tr><td>Pipedrive</td><td>无复杂配置</td><td>仅支持基础订单</td></tr><tr><td>Brevo</td><td>基础参数自定义</td><td>适合工服、家居小批量定制</td></tr><tr><td>Salesforce</td><td>PaaS集成第三方工具</td><td>支持全球化多语言定制</td></tr><tr><td>纷享销客</td><td>PaaS自定义表单/流程</td><td>需配置，适合中低频非标</td></tr><tr><td>简道云</td><td>零代码自定义表单</td><td>适合简单参数配置</td></tr><tr><td>销氪</td><td>规则配置</td><td>基础个性化需求</td></tr><tr><td>销帮帮</td><td>模板+自定义表单</td><td>适合常规非标订单</td></tr></tbody></table><h3>维度3：MES生产计划排程与报工</h3><p><strong>核心结论</strong>：超兔的<strong>原生MES功能</strong>最适配中小制造的柔性生产；Brevo次之，其他品牌需集成外部系统。</p><table><thead><tr><th>品牌</th><th>排程方式</th><th>报工能力</th><th>联动能力</th></tr></thead><tbody><tr><td>超兔一体云</td><td>正排/倒排，支持最快时间/最小班组策略</td><td>扫码报工（小组计件）、实时进度更新</td><td>与订单/BOM/财务深度联动</td></tr><tr><td>Oracle CX</td><td>依赖外部MES集成</td><td>无原生报工</td><td>与SCM联动</td></tr><tr><td>Pipedrive</td><td>无</td><td>无</td><td>无</td></tr><tr><td>Brevo</td><td>订单直连排程</td><td>扫码报工、灵工适配</td><td>与订单/库存联动</td></tr><tr><td>Salesforce</td><td>集成IoT平台</td><td>无原生报工</td><td>与设备服务联动</td></tr><tr><td>纷享销客</td><td>第三方MES对接</td><td>无</td><td>连接生产系统</td></tr><tr><td>简道云</td><td>自定义表单对接</td><td>无</td><td>无</td></tr><tr><td>销氪</td><td>无</td><td>无</td><td>无</td></tr><tr><td>销帮帮</td><td>无</td><td>无</td><td>无</td></tr></tbody></table><h3>维度4：产品BOM拆解与领料扫码</h3><p><strong>核心结论</strong>：超兔的<strong>多级BOM+全链路追溯</strong>能力最强，Brevo有基础功能，其他品牌需集成ERP/PLM。</p><table><thead><tr><th>品牌</th><th>BOM管理能力</th><th>领料功能</th><th>追溯能力</th></tr></thead><tbody><tr><td>超兔一体云</td><td>多级BOM、爆炸图展示、版本控制</td><td>扫码领料、实时扣减库存</td><td>单据关联、全链路追溯</td></tr><tr><td>Oracle CX</td><td>ERP集成</td><td>无原生领料</td><td>依赖ERP</td></tr><tr><td>Pipedrive</td><td>无</td><td>无</td><td>无</td></tr><tr><td>Brevo</td><td>BOM清单生成</td><td>扫码领料、库存匹配</td><td>基础追溯</td></tr><tr><td>Salesforce</td><td>PLM集成</td><td>无原生领料</td><td>依赖PLM</td></tr><tr><td>纷享销客</td><td>无</td><td>无</td><td>无</td></tr><tr><td>简道云</td><td>无</td><td>无</td><td>无</td></tr><tr><td>销氪</td><td>无</td><td>无</td><td>无</td></tr><tr><td>销帮帮</td><td>产品管理</td><td>进销存管理</td><td>无BOM追溯</td></tr></tbody></table><h3>维度5：应收智能触发与回款联动</h3><p><strong>核心结论</strong>：超兔的<strong>多场景应收触发+三角联动</strong>能力最精准，Oracle/Salesforce适合大型企业，Brevo适合中小工贸。</p><table><thead><tr><th>品牌</th><th>应收触发规则</th><th>回款核销能力</th><th>风险管控</th></tr></thead><tbody><tr><td>超兔一体云</td><td>签约/开票/发货多规则触发</td><td>一笔对多单、自动拆分多期</td><td>账期控制、超发预警</td></tr><tr><td>Oracle CX</td><td>自定义规则</td><td>与ERP财务联动</td><td>依赖ERP</td></tr><tr><td>Pipedrive</td><td>回款提醒</td><td>简单核销</td><td>无</td></tr><tr><td>Brevo</td><td>自动化提醒</td><td>基础核销</td><td>降低坏账率</td></tr><tr><td>Salesforce</td><td>多币种规则</td><td>与财务系统联动</td><td>全球化资金管控</td></tr><tr><td>纷享销客</td><td>订单关联回款</td><td>移动端进度查看</td><td>无</td></tr><tr><td>简道云</td><td>实时进度查看</td><td>零代码统计</td><td>无</td></tr><tr><td>销氪</td><td>销售数据统计</td><td>基础跟踪</td><td>无</td></tr><tr><td>销帮帮</td><td>合同回款管理</td><td>财务报表生成</td><td>无</td></tr></tbody></table><h3>维度6：多端订单进度同步</h3><p><strong>核心结论</strong>：超兔的<strong>全端覆盖+实时同步</strong>能力最强，Brevo、纷享销客次之，其他品牌侧重内部或销售环节。</p><table><thead><tr><th>品牌</th><th>覆盖端</th><th>同步内容</th><th>协同对象</th></tr></thead><tbody><tr><td>超兔一体云</td><td>Web/APP/小程序</td><td>生产/库存/财务全进度</td><td>内部团队+客户</td></tr><tr><td>Oracle CX</td><td>Web/移动端</td><td>订单状态</td><td>内部团队</td></tr><tr><td>Pipedrive</td><td>移动端</td><td>销售进度</td><td>销售团队</td></tr><tr><td>Brevo</td><td>Web/APP/小程序</td><td>生产/库存进度</td><td>内部团队+客户</td></tr><tr><td>Salesforce</td><td>Mobile</td><td>全球化订单状态</td><td>全球团队</td></tr><tr><td>纷享销客</td><td>Web/APP/小程序</td><td>内外系统进度</td><td>内部+外部合作伙伴</td></tr><tr><td>简道云</td><td>Web/APP</td><td>自定义流程进度</td><td>内部团队</td></tr><tr><td>销氪</td><td>Web/APP</td><td>销售数据</td><td>销售团队</td></tr><tr><td>销帮帮</td><td>APP</td><td>销售链路进度</td><td>销售团队</td></tr></tbody></table><h2>三、可视化对比：Mermaid图与雷达图</h2><h3>1. 超兔一体云订单全流程时序图</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555192" alt="" title=""/></p><p>暂时无法在飞书文档外展示此内容</p><h3>2. 中小制造订单全流程核心需求脑图</h3><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047555193" alt="" title="" loading="lazy"/></p><p>暂时无法在飞书文档外展示此内容</p><h3>3. 品牌能力雷达图分值（1-10分）</h3><table><thead><tr><th>维度</th><th>超兔</th><th>Oracle</th><th>Pipedrive</th><th>Brevo</th><th>Salesforce</th><th>纷享销客</th><th>简道云</th><th>销氪</th><th>销帮帮</th></tr></thead><tbody><tr><td>订单全流程管控</td><td>9</td><td>8</td><td>5</td><td>7</td><td>8</td><td>6</td><td>6</td><td>5</td><td>6</td></tr><tr><td>非标定制型订单创建</td><td>9</td><td>7</td><td>3</td><td>6</td><td>7</td><td>7</td><td>7</td><td>4</td><td>5</td></tr><tr><td>MES生产计划排程与报工</td><td>8</td><td>5</td><td>1</td><td>7</td><td>5</td><td>3</td><td>3</td><td>1</td><td>1</td></tr><tr><td>产品BOM拆解与领料扫码</td><td>9</td><td>4</td><td>1</td><td>7</td><td>4</td><td>2</td><td>2</td><td>1</td><td>3</td></tr><tr><td>应收智能触发与回款联动</td><td>8</td><td>7</td><td>4</td><td>6</td><td>7</td><td>5</td><td>5</td><td>3</td><td>5</td></tr><tr><td>多端订单进度同步</td><td>9</td><td>8</td><td>5</td><td>7</td><td>8</td><td>7</td><td>6</td><td>5</td><td>5</td></tr></tbody></table><h2>四、选型建议</h2><p>根据企业规模与核心需求，推荐如下：</p><h3>1. 中小制造企业（优先选“一体化闭环”）</h3><ul><li><strong>核心需求</strong>：订单全流程闭环、非标定制、生产排程、BOM领料、财务联动</li><li><strong>推荐品牌</strong>：超兔一体云（原生功能覆盖所有维度，无需集成，快速落地）</li></ul><h3>2. 大型/跨国企业（优先选“生态协同”）</h3><ul><li><strong>核心需求</strong>：多渠道高并发、全球化协同、复杂定制</li><li><strong>推荐品牌</strong>：Oracle CX（适合国内大型企业）、Salesforce（适合跨国企业）</li></ul><h3>3. 中小工贸企业（优先选“轻量化”）</h3><ul><li><strong>核心需求</strong>：小批量定制、柔性生产、资金管控</li><li><strong>推荐品牌</strong>：Brevo（轻量化全流程，适配工服、家居等场景）</li></ul><h3>4. 销售驱动型企业（优先选“简单跟踪”）</h3><ul><li><strong>核心需求</strong>：快速下单、回款提醒、销售闭环</li><li><strong>推荐品牌</strong>：Pipedrive（销售驱动）、销帮帮（销售全链路）</li></ul><h3>5. 连接型/零代码需求（优先选“配置灵活”）</h3><ul><li><strong>核心需求</strong>：内外协同、快速自定义流程</li><li><strong>推荐品牌</strong>：纷享销客（连接型CRM）、简道云（零代码搭建）</li></ul><h2>五、结论</h2><p><strong>超兔一体云</strong>是<strong>中小制造企业</strong>的“最优解”——其<strong>一体化闭环能力</strong>覆盖了订单全流程的所有痛点（非标定制、生产排程、BOM领料、财务联动、多端同步），且无需额外集成系统，成本低、落地快。</p><p>对于大型企业，Oracle CX与Salesforce的生态协同能力更强；对于销售驱动型企业，Pipedrive与销帮帮更简单易用。</p><p>最终选型需结合<strong>企业规模、核心痛点、预算</strong>，优先选择“原生功能覆盖核心需求”的品牌，避免“为集成而集成”的额外成本。</p><p>（注：文中功能相关描述均基于公开披露信息，具体功能服务与价格以厂商实际落地版本为准。）</p>]]></description></item><item>    <title><![CDATA[【节点】[Vector4节点]原理解析与实际应用 SmalBox ]]></title>    <link>https://segmentfault.com/a/1190000047554891</link>    <guid>https://segmentfault.com/a/1190000047554891</guid>    <pubDate>2026-01-21 10:06:12</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <blockquote><a href="https://link.segmentfault.com/?enc=Ok6WRucVrTs%2F4ADJbeaC1Q%3D%3D.R0kQQXRwfEcT%2BHD8%2FN%2FHYR1tvgVdFUEMpBpgP%2BSu0gIexUji8XLiaBRYsP6SnvP4HCsXWRvM1YKFznKfRl0OhPnLYEmXrv53fMQMEmVC7Y%2BJVGHO%2BgfICBoS6kVcWEDJv8Uxeam%2FJ4cyDQM9bsCkT1AAtxl5yXWHpmYpRIWqQMVvyyHk0D9ISpNAEE8F58ShtAxN5HDzw5FugHrxn47t479ZjoeaGosc4NoixqXqzOg%3D" rel="nofollow" target="_blank">【Unity Shader Graph 使用与特效实现】</a><strong>专栏-直达</strong></blockquote><p>Vector 4节点是Unity URP Shader Graph中用于处理和定义四维向量的核心节点。在计算机图形学和着色器编程中，四维向量是最基本的数据结构之一，广泛应用于颜色表示、空间坐标、纹理坐标和各种数学计算中。掌握Vector 4节点的使用对于创建复杂的着色器效果至关重要。</p><h2>Vector 4节点的基本概念</h2><p>Vector 4节点在Shader Graph中扮演着多重角色，既可以作为常量向量的定义工具，也可以作为向量数据的组合和转换节点。理解其工作原理需要从向量的数学本质和在图形学中的应用场景入手。</p><p>四维向量在数学上表示为包含四个标量值的集合，通常写作(x, y, z, w)或(r, g, b, a)。在着色器编程中，这四个分量可以表示不同的含义，具体取决于使用上下文：</p><ul><li>在颜色表示中，通常对应RGBA颜色值</li><li>在空间变换中，可以表示三维坐标加齐次坐标</li><li>在纹理采样中，可能表示纹理坐标和深度信息</li><li>在复杂数学运算中，可以打包多个相关参数</li></ul><p>Vector 4节点的核心功能是提供一种灵活的方式来创建和操作这些四维向量，无论是通过直接输入常量值，还是通过连接其他节点的输出动态构建向量。</p><h2>节点端口详解</h2><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047554893" alt="" title=""/></p><p>Vector 4节点的端口设计体现了其灵活性和多功能性。每个端口都有特定的作用和适用场景，深入理解这些端口的使用方法对于充分发挥节点潜力至关重要。</p><h3>输入端口</h3><p>X输入端口</p><ul><li>数据类型：Float（浮点数）</li><li>功能描述：定义输出向量的第一个分量</li><li>使用场景：当需要单独控制向量的X分量时使用，例如控制颜色的红色通道或位置的X坐标</li><li>典型应用：连接时间节点创建动态效果，连接纹理采样节点基于纹理值调整分量</li></ul><p>Y输入端口</p><ul><li>数据类型：Float（浮点数）</li><li>功能描述：定义输出向量的第二个分量</li><li>使用场景：控制向量的Y分量，如颜色的绿色通道或位置的Y坐标</li><li>特殊用法：在二维效果中，常与X端口配合使用创建平面坐标</li></ul><p>Z输入端口</p><ul><li>数据类型：Float（浮点数）</li><li>功能描述：定义输出向量的第三个分量</li><li>使用场景：处理三维空间相关的效果，如深度信息、法线向量的Z分量</li><li>注意事项：在二维效果中，有时会设置为固定值或用于存储额外参数</li></ul><p>W输入端口</p><ul><li>数据类型：Float（浮点数）</li><li>功能描述：定义输出向量的第四个分量</li><li>使用场景：通常用于特殊用途，如颜色的Alpha通道、齐次坐标的w分量</li><li>高级应用：在自定义光照模型中存储高光强度或其他材质属性</li></ul><h3>输出端口</h3><p>Out输出端口</p><ul><li>数据类型：Vector 4（四维向量）</li><li>功能描述：输出由输入分量组合而成的四维向量</li><li>连接目标：可以连接到任何接受Vector 4类型输入的端口</li><li>典型下游节点：颜色节点、位置节点、UV节点、数学运算节点等</li></ul><h2>使用模式与工作流程</h2><p>Vector 4节点的使用可以分为几种典型模式，每种模式对应不同的着色器创作需求。</p><h3>常量向量定义模式</h3><p>当所有输入端口都未连接时，Vector 4节点充当常量向量定义器。这是最简单的使用模式，适用于定义固定的颜色值、位置偏移或其他不变的向量参数。</p><p>使用场景示例：</p><ul><li>定义纯色材质的基础颜色</li><li>设置固定的纹理偏移量</li><li>指定不变的空间变换参数</li><li>定义材质的标准属性值</li></ul><p>操作步骤：</p><ul><li>选择Vector 4节点并将其添加到Shader Graph中</li><li>在节点检查器中直接设置X、Y、Z、W分量的数值</li><li>将Out端口连接到目标属性</li></ul><h3>动态向量构建模式</h3><p>当部分或全部输入端口连接到其他节点时，Vector 4节点成为向量组装工具。这种模式允许基于各种输入动态构建向量，是实现复杂着色器效果的关键。</p><p>典型构建方式：</p><ul><li>从多个独立计算的结果组合向量</li><li>将不同来源的数据打包成单个向量</li><li>基于条件或计算修改向量的特定分量</li><li>将低维向量扩展为四维向量</li></ul><h3>分量替换模式</h3><p>通过有选择地连接部分输入端口，可以实现向量分量的部分替换。未连接的端口使用默认值，连接的端口使用输入值，这种模式在修改现有向量的特定分量时非常有用。</p><p>应用实例：</p><ul><li>修改颜色的Alpha通道而不影响RGB值</li><li>调整位置向量的高度分量（Y轴）</li><li>替换法线向量的特定分量</li></ul><h2>实际应用案例</h2><h3>颜色和透明度控制</h3><p>在着色器开发中，Vector 4节点最常见的应用是定义和控制颜色。四维向量的四个分量自然对应颜色的RGBA通道。</p><p>基础颜色定义示例：</p><ul><li>创建纯红色：X=1, Y=0, Z=0, W=1</li><li>创建半透明蓝色：X=0, Y=0, Z=1, W=0.5</li><li>定义材质的基础色属性</li></ul><p>动态颜色控制：</p><ul><li>使用时间节点驱动颜色变化，创建闪烁效果</li><li>基于顶点位置或UV坐标变化颜色</li><li>根据光照条件调整颜色饱和度</li></ul><pre><code>HLSL

// 生成的代码示例：动态颜色
float redChannel = _Time.y % 1.0; // 使用时间控制红色通道
float greenChannel = uv.x; // 使用UV坐标控制绿色通道
float blueChannel = 0.5; // 固定蓝色通道
float alphaChannel = 1.0; // 不透明度

float4 dynamicColor = float4(redChannel, greenChannel, blueChannel, alphaChannel);</code></pre><h3>位置和变换处理</h3><p>Vector 4节点在空间变换和位置处理中起着重要作用，特别是在顶点着色器中处理模型位置时。</p><p>空间坐标应用：</p><ul><li>定义对象空间中的固定偏移量</li><li>创建基于时间的动画位移</li><li>实现顶点抖动效果</li><li>控制粒子系统的发射位置</li></ul><p>齐次坐标处理：</p><ul><li>在模型-视图-投影矩阵变换中处理w分量</li><li>实现透视校正和深度测试</li><li>处理投影空间坐标</li></ul><pre><code>HLSL

// 位置偏移示例
float3 worldPosition = TransformObjectToWorld(IN.positionOS.xyz);
float xOffset = sin(_Time.y * 5.0) * 0.1; // X轴正弦波动
float yOffset = 0.0; // Y轴无偏移
float zOffset = cos(_Time.y * 3.0) * 0.05; // Z轴余弦波动

float4 offsetVector = float4(xOffset, yOffset, zOffset, 0.0);
float4 newPosition = float4(worldPosition, 1.0) + offsetVector;</code></pre><h3>纹理坐标操作</h3><p>Vector 4节点可以用于复杂的纹理坐标操作，特别是在需要多层纹理或动态UV效果时。</p><p>高级UV处理：</p><ul><li>为不同纹理层设置不同的UV变换</li><li>创建流动的纹理效果</li><li>实现纹理缩放、旋转和平移</li><li>处理立体纹理和数组纹理</li></ul><pre><code>HLSL

// 动态UV偏移示例
float2 baseUV = IN.uv;
float scrollSpeed = 0.1;
float scrollAmount = _Time.y * scrollSpeed;

// 为不同方向创建不同的滚动速度
float xScroll = scrollAmount;
float yScroll = scrollAmount * 0.5;
float2 scrolledUV = baseUV + float2(xScroll, yScroll);

// 打包为Vector4用于复杂纹理采样
float4 complexUV = float4(scrolledUV, baseUV);</code></pre><h3>材质属性组合</h3><p>在高级着色器中，Vector 4节点常用于组合多个材质属性，优化着色器性能和代码组织。</p><p>属性打包策略：</p><ul><li>将相关但独立的参数打包为单个向量</li><li>减少着色器中的常量寄存器使用</li><li>简化着色器参数传递接口</li><li>提高GPU缓存效率</li></ul><p>典型打包方案：</p><ul><li>将金属度、光滑度、环境光遮蔽打包</li><li>组合纹理缩放和偏移参数</li><li>打包光照模型的多个衰减参数</li></ul><h2>高级技巧与最佳实践</h2><h3>性能优化策略</h3><p>合理使用Vector 4节点可以显著提升着色器性能，特别是在移动平台上。</p><p>优化建议：</p><ul><li>尽可能重用已计算的向量，避免重复计算</li><li>在适当情况下使用常量向量而不是动态计算</li><li>合理组织向量分量，将相关数据放在同一向量中</li><li>避免不必要的向量-标量转换</li></ul><h3>数据组织模式</h3><p>有效的向量数据组织是创建高效着色器的关键。</p><p>常用组织模式：</p><ul><li>空间数据组织：位置、法线、切线分别存储</li><li>颜色数据组织：遵循RGBA标准顺序</li><li>材质属性组织：按使用频率和相关性分组</li><li>动画参数组织：时间相关参数集中存储</li></ul><h3>调试和可视化技巧</h3><p>在Shader Graph开发过程中，正确调试Vector 4节点至关重要。</p><p>调试方法：</p><ul><li>使用自定义函数节点检查单个分量</li><li>通过颜色编码可视化向量不同分量</li><li>利用预览窗口观察中间结果</li><li>创建调试分支隔离特定向量操作</li></ul><p>可视化技巧：</p><ul><li>将X、Y、Z分量映射到RGB颜色进行可视化</li><li>使用W分量控制可视化强度或透明度</li><li>创建分量分离的调试视图</li></ul><h2>与其他节点的协同工作</h2><p>Vector 4节点很少单独使用，通常与其他节点组合形成完整的着色器功能。</p><h3>与数学节点配合</h3><p>Vector 4节点与各种数学运算节点的组合是实现复杂效果的基础。</p><p>常见组合：</p><ul><li>使用加法节点实现位置偏移</li><li>使用乘法节点调整颜色强度</li><li>使用正弦/余弦节点创建波动效果</li><li>使用插值节点实现平滑过渡</li></ul><h3>在光照模型中的应用</h3><p>在自定义光照模型中，Vector 4节点用于存储和传递光照参数。</p><p>光照相关应用：</p><ul><li>存储表面颜色和透明度</li><li>打包法线向量和高度信息</li><li>组合光照衰减参数</li><li>存储阴影和光照遮罩数据</li></ul><h3>特效系统集成</h3><p>在粒子系统和后期特效中，Vector 4节点用于控制各种特效参数。</p><p>特效控制：</p><ul><li>定义粒子颜色和生命周期</li><li>控制后期效果的强度参数</li><li>存储屏幕空间效果的数据</li><li>管理时间相关的动画曲线</li></ul><h2>常见问题与解决方案</h2><h3>数据类型匹配问题</h3><p>在使用Vector 4节点时，经常遇到数据类型不匹配的问题。</p><p>解决方案：</p><ul><li>使用适当的转换节点确保数据类型一致</li><li>理解隐式类型转换规则</li><li>在复杂网络中明确标注数据类型</li><li>使用Split节点提取所需分量</li></ul><h3>性能瓶颈识别</h3><p>不当的Vector 4使用可能导致着色器性能下降。</p><p>性能问题诊断：</p><ul><li>使用Shader Graph的性能分析工具</li><li>检查向量操作的复杂度和频率</li><li>评估向量长度是否必要</li><li>考虑使用更简单的数据类型替代Vector 4</li></ul><h3>跨平台兼容性</h3><p>不同平台对Vector 4操作的支持和性能特征可能不同。</p><p>兼容性考虑：</p><ul><li>测试在目标平台上的向量操作性能</li><li>注意移动平台的精度限制</li><li>考虑使用半精度浮点数优化性能</li><li>验证复杂向量操作在所有目标平台上的正确性</li></ul><hr/><blockquote><a href="https://link.segmentfault.com/?enc=OnxtZQEmo403osytitZ%2BUQ%3D%3D.JFRMNwsYB25gSzAMpHUFimWoMQB6e7qCnMLUtAXQbq2o1sj7UoGQhDHQs7FHlNJvMoaz2Nd%2Bj7NmTCK4vQiz1szul1fuFTW%2BYve7FEjsO9dvydt0T7ACaDq0mw3TBIVFPmCwKQ6cPkznWzIxcFcsWQeNDtQQq3C9HL137G%2F4X5cORZy44%2BzIxiKDMxcQaOal0A0UNp%2FByxHbOVQjVoIdavTII0L3nmbXY4vlCn%2FWyI0%3D" rel="nofollow" target="_blank">【Unity Shader Graph 使用与特效实现】</a><strong>专栏-直达</strong><br/>（欢迎<em>点赞留言</em>探讨，更多人加入进来能更加完善这个探索的过程，🙏）</blockquote>]]></description></item><item>    <title><![CDATA[团队协作聚焦指南：如何用堆栈式知识归纳软件统一进度、明确分工 NAVI_s1mple ]]></title>    <link>https://segmentfault.com/a/1190000047554923</link>    <guid>https://segmentfault.com/a/1190000047554923</guid>    <pubDate>2026-01-21 10:05:28</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2><strong>导言</strong></h2><p>在复杂信息爆炸与高强度研发协作中，知识的垂直解构与深度对齐是保持组织竞争力的关键。缺乏有效的堆栈式归纳机制，团队往往会面临逻辑断层、执行偏差、深度知识难以回溯等挑战。通过使用堆栈式知识归纳软件，团队可以将信息按层级嵌套、堆栈对齐的方式进行归纳，确保每一条知识都能向上溯源目标，向下穿透细节，从而显著提升团队的深度思考能力与知识流转效率。</p><h2><strong>摘要</strong></h2><p>本文介绍了堆栈式知识归纳软件在处理复杂逻辑中的重要性，并精选推荐了5款适用于不同层级归纳场景的工具。通过分析这些软件的垂直架构与嵌套特点，帮助团队选择最适合的工具来构建深度知识栈。此外，文中还提供了堆栈化归纳的设计逻辑与实施策略，助力团队建立纵向对齐的知识管理体系。</p><h2><strong>一、 为什么需要堆栈式知识归纳软件？</strong></h2><p>在处理高复杂度项目或深度研发时，知识往往需要按照堆栈层级进行纵向归集与对齐。没有合理的堆栈式归纳工具，团队将面临以下几大困境：</p><ul><li><strong>逻辑断层</strong>：底层执行动作与高层战略目标脱节，无法闭环回溯。</li><li><strong>进度模糊</strong>：缺乏穿透视图，无法从宏观层面一眼洞察微观节点的真实状态。</li><li><strong>认知过载</strong>：平铺的信息无法体现逻辑的主次，导致关键路径被噪音湮没。</li><li><strong>协作脱节</strong>：团队成员因缺乏统一的层级视角，在多级拆解中产生理解偏差。</li></ul><p>引入一款<strong>支持堆栈式嵌套归纳的软件</strong>，能够帮助团队通过垂直化的架构管理，提升信息的逻辑密度与检索精度。此类软件能将知识按父子关系层层堆叠，确保每一个细节节点都具备完整的上下文语境，减少重复沟通与认知成本。</p><h2><strong>二、 堆栈式知识归纳软件的作用</strong></h2><p>堆栈式知识归纳软件是指那些支持将信息按无限嵌套、垂直对齐单元进行层级归纳，并提供深度下钻视图的工具。这类工具的核心作用是帮助团队将碎片化的执行记录转化为结构化的逻辑栈，确保每个层级的产出都能得到精准的归因与追踪。其关键特点在于具备强大的纵向架构能力，能够在保持信息深度的同时，通过折叠与穿透机制维持视图的简洁高效，让团队在宏观与微观之间自由切换。</p><h2><strong>三、 堆栈式归纳的典型应用场景</strong></h2><p>堆栈式知识归纳软件适用于需要处理严密逻辑、深度架构或多层级任务的场景。以下是此类工具的典型应用：</p><ol><li><strong>复杂研发架构管理</strong>：在软件或硬件研发中，将顶层架构逐层分解为模块、组件及原子代码，实现全链路逻辑归纳；</li><li><strong>深度项目WBS分解</strong>：利用堆栈结构对大型工程进行工作分解（WBS），确保每一个子任务都能垂直映射到里程碑节点；</li><li><strong>多级需求溯源体系</strong>：从市场需求到产品功能，再到开发任务，构建完整的垂直对齐堆栈，防止需求流失；</li><li><strong>标准化作业流程（SOP）嵌套</strong>：将复杂的作业规范拆解为多层级操作说明，提升新成员对深度业务的学习效率；</li><li><strong>战略目标层级对齐</strong>：通过堆栈式结构将OKR或KPI从组织层层透传至个人，实现上下同欲的逻辑闭环。</li></ol><h2><strong>四、 5款值得一试的堆栈式知识归纳软件（精选推荐）</strong></h2><h3><strong>1. 板栗看板</strong></h3><p><strong>专注于无限层级嵌套与垂直对齐的堆栈式管理工具</strong></p><ul><li><strong>核心特性</strong>：支持卡片无限嵌套，提供独特的“树状+看板”双重维度，实现任务层级的深度解构；</li><li><strong>适配场景</strong>：研发团队、复杂项目管理、多层级SOP归纳；</li><li><strong>优势亮点</strong>：通过直观的层级下钻功能，板栗看板能完美解决普通工具“扁平化”的痛点，让再复杂的项目也能通过堆栈结构一览无余。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047554925" alt="在这里插入图片描述" title="在这里插入图片描述"/></li></ul><h3><strong>2. Workflowy</strong></h3><p><strong>极致简约的无限层级大纲式归纳软件</strong></p><ul><li><strong>核心特性</strong>：基于单一列表的无限节点嵌套，支持极致的缩放（Zoom-in/out）与归纳；</li><li><strong>适配场景</strong>：个人深度思考、项目逻辑建模、碎片信息层级化；</li><li><strong>优势亮点</strong>：专注“点、线、面”的纵向堆叠，适合快速捕捉灵感并将其无缝嵌入现有的逻辑堆栈中。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047554926" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></li></ul><h3><strong>3. Heptabase</strong></h3><p><strong>结合视觉白板与原子化堆栈的知识建模工具</strong></p><ul><li><strong>核心特性</strong>：支持将笔记块放入多层级卡片盒，通过视觉化的方式呈现知识的堆栈关系；</li><li><strong>适配场景</strong>：学术研究、复杂业务分析、学习体系构建；</li><li><strong>优势亮点</strong>：它不仅能进行堆栈归纳，还能通过白板连线展示跨堆栈的横向逻辑，兼顾了深度与广度。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047554927" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></li></ul><h3><strong>4. Airtable</strong></h3><p><strong>基于多表关联与分级视图的结构化堆栈平台</strong></p><ul><li><strong>核心特性</strong>：通过强关联关系实现不同表单间的层级跳转，支持按属性进行多级分组归纳；</li><li><strong>适配场景</strong>：资产管理、中后台流程监控、标准化数据归档；</li><li><strong>优势亮点</strong>：Airtable 的数据库逻辑允许用户自定义复杂的垂直对应关系，适合对大量标准化堆栈进行参数化管理。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047554928" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></li></ul><h3><strong>5. ClickUp</strong></h3><p><strong>多层级任务架构与高度自定义的团队协作软件</strong></p><ul><li><strong>核心特性</strong>：提供“空间-目录-列表-任务-子任务”的五级固定堆栈架构，支持精细化的属性继承；</li><li><strong>适配场景</strong>：大中型团队协同、全流程项目管控、多维度任务分发；</li><li><strong>优势亮点</strong>：其严格的层级逻辑确保了大规模协作时的信息有序，是典型的工程级堆栈管理工具。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047554929" alt="在这里插入图片描述" title="在这里插入图片描述" loading="lazy"/></li></ul><h2><strong>五、 各软件的选型建议</strong></h2><p>选择堆栈式知识归纳软件时，应根据逻辑的深度、协作的复杂度以及对“可视化下钻”的需求来决定：</p><h3><strong>1. 追求极简与逻辑深度</strong></h3><p>对于侧重个人思考或纯逻辑建模的用户，<strong>Workflowy</strong> 的极简大纲能提供无干扰的堆栈归纳体验。</p><h3><strong>2. 复杂研发与可视化穿透</strong></h3><p>若团队需要在执行中实时穿透进度，<strong>板栗看板</strong> 凭借其直观的嵌套卡片视图，是中小型研发团队实现垂直对齐的最优解。</p><h3><strong>3. 数据驱动与标准化堆栈</strong></h3><p>如果归纳内容需要高度结构化并支持大量筛选、自动化操作，<strong>Airtable</strong> 能够提供最稳健的数据库式堆栈支撑。</p><h3><strong>4. 大型组织的全方位管控</strong></h3><p>针对需要多部门协作、分权管理的场景，<strong>ClickUp</strong> 的五层固定架构能确保知识在复杂体系中不失序。</p><h2><strong>六、 Q\&amp;A：关于堆栈式知识归纳你可能遇到的问题</strong></h2><p><strong>Q1：堆栈层级分得太深，找东西像“套娃”一样麻烦怎么办？</strong> A：建议配合全局搜索与快速导航功能，并利用“路径面包屑”定位。同时，在顶层建立索引页或仪表盘，确保核心堆栈节点触手可及。</p><p><strong>Q2：如何平衡堆栈的深度与执行的灵活性？</strong> A：遵循“逻辑深拆、执行轻快”的原则。建议将深度逻辑留在归纳层，而在最底层的原子任务层保持简洁，避免因层级过多导致操作繁琐。</p><p><strong>Q3：如何防止堆栈式归纳沦为行政负担？</strong> A：采用“边做边归纳”的模式，将归纳动作嵌入任务生命周期中，利用工具提供的模板化功能降低重复搭建堆栈的成本。</p><h2><strong>七、 结语</strong></h2><p>堆栈式知识归纳软件是攻克复杂管理难题的利器。通过科学的层级设计与垂直归档，团队能够将凌乱的信息转化为逻辑严密的资产栈，实现从“碎片化堆砌”到“系统化对齐”的质变。借助 <strong>板栗看板</strong>、<strong>Workflowy</strong>、<strong>ClickUp</strong> 等工具，知识管理将不再是沉重的负担，而是驱动组织持续深耕与极速进化的逻辑引擎。</p><p>深度决定高度，堆栈式知识归纳软件让每一份思考都拥有厚实的基石。</p>]]></description></item><item>    <title><![CDATA[SpreadJS V19.0 新特性解密：透视表日期分组，解锁时间维度分析新效率 葡萄城技术团队 ]]></title>    <link>https://segmentfault.com/a/1190000047554949</link>    <guid>https://segmentfault.com/a/1190000047554949</guid>    <pubDate>2026-01-21 10:04:35</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在数据分析场景中，日期维度的聚合分析是高频需求——无论是按周统计销售数据、按月汇总项目进度，还是按自定义周期分析业务趋势，都需要对日期数据进行灵活分组。传统透视表的日期处理往往局限于固定的年、月、日层级，若要实现按周、15天等自定义周期分组，需手动预处理数据或编写复杂公式，不仅操作繁琐，还容易因数据同步不及时导致分析偏差。</p><p>为解决这一痛点，SpreadJS V19.0 重磅推出透视表日期分组（Date Group）功能，支持按自定义天数灵活分组，完美适配周报、自定义周期分析等场景，让时间维度的数据聚合更高效、更贴合业务需求。下面，我们将深入解析这一特性的核心价值与使用细节。</p><h2>核心功能解析：灵活配置，精准聚合日期数据</h2><p>SpreadJS V19.0 的透视表日期分组功能以“自定义性强、适配场景广”为核心设计理念，提供全方位的日期分组配置能力，满足不同业务场景的分析需求：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047554951" alt="在这里插入图片描述" title="在这里插入图片描述"/></p><h3>1. 自定义天数分组，适配多元业务需求</h3><p>支持按任意天数设置分组间隔（groupInterval），彻底摆脱固定时间层级的限制：</p><ul><li>典型场景适配：设置“7天”为分组间隔，即可快速实现周报数据聚合，无需手动拆分日期区间；</li><li>自定义周期支持：根据业务需求灵活设置分组天数，如15天（半月报）、30天（月度滚动分析）、90天（季度趋势分析）等，轻松应对多样化的时间维度统计需求；</li><li>生效规则明确：groupInterval 仅在按“天”分组时生效，确保配置逻辑清晰，避免混淆。</li></ul><h3>2. 灵活控制起止时间，精准圈定分析范围</h3><p>日期分组支持自定义起止时间（start/end），同时提供智能默认规则，兼顾灵活性与便捷性：</p><ul><li>智能默认逻辑：若未手动设置起止时间，系统自动读取原始日期字段的最小值和最大值作为分组范围，无需额外配置；</li><li>自定义范围支持：可根据分析需求手动设定 start 和 end 时间，例如仅分析“2024年Q2”（4月1日-6月30日）的数据，精准圈定目标区间；</li><li>边界校验机制：系统强制要求 end 时间晚于 start 时间，避免无效配置；若起止时间间隔小于设置的 groupInterval，则直接按实际间隔分组，确保分组逻辑合理。</li></ul><h3>3. 分组项显示精细化控制，兼顾完整性与可读性</h3><p>针对分组结果的显示，提供多重配置选项，平衡数据完整性与视觉可读性：</p><ul><li>无数据分组项控制：分组后可能出现无数据的区间（如某周无销售记录），可通过设置“show items with no data”显示这些空值分组项，确保时间维度的完整性；默认不显示空值分组项，避免报表冗余；</li><li>超出范围数据处理：超出起止时间范围的日期数据，会被自动分配到特殊分组，以“&lt; start时间”或“&gt; end时间”标识，清晰区分有效分析区间与异常数据，便于后续数据校验。</li></ul><h3>4. 标准化时间单位，确保分组准确性</h3><p>日期分组的最小单位为“天”，无论原始日期数据是否包含时分秒信息，系统都会自动将其转换为当天的00:00:00进行分组计算：</p><ul><li>避免时间精度干扰：例如原始数据中“2024-05-10 14:30:00”和“2024-05-10 23:59:00”会被归为同一组，确保日期分组的准确性；</li><li>简化数据处理逻辑：无需手动统一日期格式，系统自动标准化处理，降低操作门槛。</li></ul><h2>典型应用场景：让时间维度分析更贴合业务</h2><p>这一特性的推出，让透视表的日期分析能力全面升级，在多个核心业务场景中发挥关键价值：</p><h3>1. 周报/半月报快速生成</h3><p>市场、销售等部门需要按周或半月汇总数据时，无需手动拆分日期区间：只需将日期字段拖入透视表行/列区域，设置分组天数为7天或15天，系统自动聚合对应区间的数据，快速生成周报、半月报，效率提升80%以上。</p><h3>2. 自定义周期业务分析</h3><p>针对特殊业务周期（如电商大促活动14天周期、项目迭代21天周期），可灵活设置分组天数，实时分析活动期间的业务数据趋势，无需修改数据源或编写复杂计算逻辑。</p><h3>3. 跨时间段对比分析</h3><p>需要对比不同年份同一周期的数据时（如2023年Q3第1周 vs 2024年Q3第1周），可通过自定义起止时间锁定对应区间，结合透视表的筛选功能，快速实现跨年度、跨周期的对比分析，助力业务趋势判断。</p><h3>4. 数据合规与追溯</h3><p>在金融、医疗等需要精准时间追溯的行业，可通过固定起止时间和分组间隔，标准化日期数据的聚合方式，确保分析结果的一致性和可追溯性，符合行业合规要求。</p><h2>操作指南：3步实现日期分组，上手即会</h2><p>SpreadJS V19.0 的日期分组功能操作简洁，无需复杂配置，3步即可完成：</p><ol><li>插入透视表并添加日期字段：在SpreadJS设计器中插入透视表，将需要分组的日期字段拖入“行标签”或“列标签”区域；</li><li>打开日期分组设置：右键点击日期字段，选择“分组”选项，弹出分组配置对话框；</li><li><p>配置分组参数并应用：</p><ol><li>选择分组单位为“天”；</li><li>设置分组天数（groupInterval），如7天（周报）；</li><li>按需自定义起止时间（start/end），默认可不填；</li><li>勾选“show items with no data”（可选，需显示空值分组项时启用）；</li><li>点击“确定”，系统自动完成日期分组，透视表实时更新聚合结果。</li></ol></li></ol><h2>注意事项：这些细节让分组更精准</h2><p>为确保日期分组功能的使用效果，以下关键细节需留意：</p><ol><li>groupInterval 生效条件：仅当分组单位选择“天”时，自定义天数（groupInterval）才会生效；若选择年、月、日等固定层级，该参数不生效；</li><li>起止时间格式：自定义 start/end 时，需遵循标准日期格式（如“2024-01-01”），系统会自动识别并转换；</li><li>空值分组项默认行为：默认不显示无数据的分组项，若需完整展示时间区间，需手动启用“show items with no data”；</li><li>时间精度处理：原始日期数据的时分秒信息会被忽略，统一按“天”为单位进行分组，若需保留时分秒级别的分析，需提前对数据进行预处理。</li></ol><h2>总结与展望：让数据分析更贴合业务节奏</h2><p>SpreadJS V19.0 推出的透视表日期分组功能，以“灵活配置、精准聚合、操作便捷”为核心优势，彻底解决了传统透视表日期分析的局限性，让时间维度的数据聚合更贴合业务需求，大幅降低数据分析门槛，提升工作效率。</p><p>作为一款面向企业级应用的纯前端表格控件，SpreadJS 始终聚焦开发者与终端用户的实际需求，持续优化透视表等核心功能——除了日期分组，V19.0 还为透视表带来了拖动自定义排序、受保护工作表中启用透视表等多项增强能力，全方位提升数据处理与分析体验。</p><p>如需了解更多功能细节，可访问 <a href="https://link.segmentfault.com/?enc=YLVCAcWZL9%2FsmgNILU2WuA%3D%3D.TQ4rcgLm7b%2FrPgotAU2KmWoTBDnoN5Y6z63QD3hW1wg3HcBbwVRdnzTk13JHM3WbQ3bdIItKxBhDRCtvfFRU7g%3D%3D" rel="nofollow" target="_blank">SpreadJS 官网</a> 查看产品文档，或通过 <a href="https://link.segmentfault.com/?enc=mexuoHbI5rlGlPlkN60SDg%3D%3D.APesWHIilwTT%2BKBsjhCv0KlHgUVXoRO4tXtAR7p%2B1q%2F1W9%2BhWojM8VXLkTiJZvQ2Ax32tuPSrIXtyZtIqPtVYA%3D%3D" rel="nofollow" target="_blank">在线 Demo</a> 直接体验新特性。SpreadJS V19.0 即将正式发布，敬请期待这款更强大、更灵活的前端表格控件，为你的业务系统注入新的活力！</p>]]></description></item><item>    <title><![CDATA[解锁青少年C++学习的新东东：竞赛之外，还有一片星辰大海 李兴球 ]]></title>    <link>https://segmentfault.com/a/1190000047554954</link>    <guid>https://segmentfault.com/a/1190000047554954</guid>    <pubDate>2026-01-21 10:03:36</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在当今的青少年C++编程教育领域，一个重要的趋势正在悄然改变：它的学习门槛正在大幅降低，甚至可以让那些只懂计算机打字、懂英文、会简单算术的学生，也能轻松上手。这种改变使得C++不再仅仅是竞赛的工具，而开始成为一种面向更广泛学生群体的、充满乐趣的兴趣类素质教育。</p><p>作为一名有着十余年教学经验的教育者，我同时教授图形化编程、Python和C++以及算法。相比于那些只专注于单一编程语言，并且为了自身利益而不遗余力地鼓吹该语言“天下第一”、贬低其他语言的同行（可以说是“王婆卖瓜，自卖自夸”），我始终秉持着客观的态度。我从不从个人利益出发去误导学生，因此，各位读者可以放心地阅读我的文章。</p><p>C++的世界远比我们想象的要宽广。与Python相比，它同样精彩绝伦。C++是C语言的超集，是现代数字社会的坚实基石。它更接近计算机的底层，是大型游戏引擎的核心、操作系统的命脉，也是众多大型项目不可或缺的基础。因此，如果我们仅仅将C++视为竞赛的工具，无疑是大材小用，甚至可能扼杀普通学生学习编程的兴趣。</p><p>计算机语言本身并无好坏之分。它们都是人为制定的规则体系，其存在的价值在于解决特定的问题。有人认为学习某种语言能带来最大的利益，这种观点是短视的。例如，若目标是参加竞赛并获奖，那么学习算法与数据结构才是最终目的。但学习算法是否必须使用C++呢？答案是否定的。Python语言因其语法简洁、代码可读性高，甚至被称为“伪代码的编程语言”。当一位同学真正理解了某个算法的逻辑后，无论是用Python、Basic、C++，还是图形化编程语言来实现，都只是具体的实施手段。</p><p>我认识一个朋友，他没有自动完成功能的编辑器是一行代码也写不出来的。而我只靠记事本就能把代码全部写出来。这就是要基本功非常扎实。<br/>这说明，编程的本质不在于具体的语言，而在于算法逻辑思维是否被打通。这需要多方面的训练，找到最适合自己的语言。思维打通了，大脑得到了锻炼，这才是真正的“以不变应万变”。因此，我看到网上许多人片面强调或贬低某种语言，本身就暴露了他们的无知。有些人可能只是为了推销自己的网课，或者为了引流而故意制造对立。这对那些不了解编程的普通家长来说，无疑是一种误导。</p><p>长期以来，社会上流传着一种说法：“学C++从来不是培养人，而是筛选人。”这句话虽然有一定道理，但一切都在动态变化之中。如今，C++也完全可以成为一种有效的培养工具。这背后的关键，在于我们引入了一种全新的教学方式——C++精灵库。</p><p>这个库可以免费下载，其中包含了数百个精心设计的案例供学生学习。最开始的代码极其简单，我相信，只要具备高中以上的学历，都能轻松看懂。这标志着学习C++的门槛被彻底降低了。现在的C++学习，与过去那种枯燥、抽象的竞赛式学习截然不同。</p><p>为什么C++精灵库能激发学生的兴趣？因为它让编程变得直观、有趣且充满成就感。想象一下，只需一行代码，你就能创建一枚火箭，并让它飞向太空。这种亲手创造并看到成果的体验，是任何其他方式都无法比拟的。这正是C++精灵库的魅力所在，它将编程从一种“底层”的技术探索，转变为一种充满想象力的创意实践。</p><p>当然，有人可能会质疑：“这没有学到底层啊？”我想反问一句：“一开始就让学生接触<code>cout &lt;&lt; "hello world";</code>，这就算学到底层了吗？”学习是一个循序渐进的过程。对于普通小学生而言，激发他们对学习的内在兴趣，远比掌握几个底层知识点重要得多。世界上伟大的发明者，无一不是被强烈的兴趣所驱动。虽然孩子长大后不一定会从事程序员的工作，但能坚持学好编程，本身就是一项了不起的成就。</p><p>在传统的教育体系中，C++常常因为其复杂性和学习曲线陡峭，而成为少数精英学生的专利。这不仅限制了编程的普及，也扼杀了许多孩子对技术的热情。而C++精灵库的出现，打破了这一壁垒。它让编程的大门向更广泛的学生群体敞开，特别是为中国的普通孩子提供了一条友好、有趣的学习路径。</p><p>通过这个库，孩子们可以在没有巨大心理压力的情况下，逐步建立对编程的信心和兴趣。他们可以从模仿和修改简单的代码开始，逐步深入，最终创作出属于自己的小项目。这种“兴趣驱动”的学习模式，不仅能锻炼逻辑思维和创造力，更能培养耐心和解决问题的能力。</p><p>我相信，C++精灵库的出现，是中国编程教育领域的一个积极信号。它让编程回归其本质——一种创造的工具，而不仅仅是选拔的标尺。这将为更多孩子点燃科技梦想，为他们的未来发展打下坚实的基础。虽然我个人力量微薄，无法改变整个行业的现状，但我由衷地希望，未来会有更多这样的创新，让编程教育真正惠及每一个有好奇心和创造力的孩子。</p>]]></description></item><item>    <title><![CDATA[聚焦攻略：运用堆栈式知识归纳软件，实现工作目标的“降维打击” Ord1naryLife ]]></title>    <link>https://segmentfault.com/a/1190000047554959</link>    <guid>https://segmentfault.com/a/1190000047554959</guid>    <pubDate>2026-01-21 10:02:50</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2><strong>一、导言：为什么知识都记了，复用时却找不到？</strong></h2><p>在日常办公与研发过程中，许多团队虽然建立了知识库，也安排了专人整理文档，但依旧出现以下困境：</p><ul><li>知识过于零散，查阅时无法迅速获取完整逻辑链；</li><li>执行经验归档了，但与实际项目目标脱节；</li><li>成员只掌握碎片点，看不到知识点之间的上下层嵌套关系；</li><li>不同项目间的经验无法垂直对齐，逻辑冲突严重。</li></ul><p>根本原因在于：<strong>缺乏结构化的堆栈归纳思维与工具</strong>。</p><p>知识不应是平铺的陈述，它们应当具备“垂直嵌套”“逻辑堆叠”和“溯源关系”。</p><p><strong>堆栈式知识归纳软件</strong>正是为此而生，它以“逻辑堆栈”为核心，将碎片化的知识点整合成有深度、有脉络、可穿透的智力资产图谱。</p><h2><strong>二、团队为什么容易陷入知识“沙化”的陷阱？</strong></h2><p>很多团队整理了很多文档，但结果仍然难以复用，原因在于：</p><h3><strong>❌ 缺少堆栈化逻辑</strong></h3><p>知识点只是按时间或分类列出，没有“父-子”层级，缺乏深度解构的推进逻辑。</p><h3><strong>❌ 深度不可穿透</strong></h3><p>查阅者只能看到表层描述，无法向下钻取到支撑该结论的底层数据或原始背景。</p><h3><strong>❌ 无法模块复用</strong></h3><p>每次归纳都从零开始，缺乏标准化的堆栈模板，无法实现逻辑的快速迁移。</p><h3><strong>❌ 宏观与微观视角断层</strong></h3><p>决策层看战略归纳，执行层看操作细节，堆栈视角的缺失导致知识传递的严重损耗。</p><h2><strong>三、堆栈式归纳的核心是什么？</strong></h2><p><strong>不是把资料存得越多越好，而是让知识之间形成“垂直对齐”。</strong></p><h3><strong>✅ 多级堆栈式拆解</strong></h3><p>将宏观知识主题拆解为子逻辑块，再细化为原子知识点，确保层级清晰。</p><h3><strong>✅ 逻辑自动聚合</strong></h3><p>底层知识单元的更新可以联动上层归纳，实现知识体系的实时演进。</p><h3><strong>✅ 知识上下文溯源</strong></h3><p>每个堆栈节点都明确其所属的逻辑层级，确保查阅时能瞬间还原业务语境。</p><h3><strong>✅ 垂直穿透视图</strong></h3><p>支持在同一视图内从战略目标直接穿透至最细微的执行避坑指南。</p><h2><strong>四、适用场景及堆栈整合价值</strong></h2><table><thead><tr><th align="left">使用场景</th><th align="left">逻辑缺失表现</th><th align="left">堆栈式归纳的显著改进</th></tr></thead><tbody><tr><td align="left">研发架构管理</td><td align="left">模块文档散乱，依赖不清晰</td><td align="left">用堆栈表达系统、模块、组件的三层逻辑路径</td></tr><tr><td align="left">SOP 经验沉淀</td><td align="left">流程描述空洞，落地难度大</td><td align="left">用嵌套堆栈固化标准动作，实现知识的可执行性</td></tr><tr><td align="left">复杂项目复盘</td><td align="left">只有结果统计，缺乏逻辑还原</td><td align="left">以里程碑为堆栈顶层，挂载所有关联的决策细节</td></tr><tr><td align="left">技术体系构建</td><td align="left">知识点堆积，无法形成体系</td><td align="left">用堆栈结构建立从基础理论到实战案例的纵向映射</td></tr></tbody></table><h2><strong>五、建立堆栈式知识归纳机制的关键方法</strong></h2><h3><strong>1️⃣ 逻辑建模：从顶层维度到原子单元的清晰拆解</strong></h3><h3><strong>2️⃣ 堆栈联动规则设计</strong></h3><h3><strong>3️⃣ 结构化模板复用</strong></h3><h3><strong>4️⃣ 堆栈节点赋权与审核机制</strong></h3><h3><strong>5️⃣ 跨维度知识穿透路径</strong></h3><h2><strong>六、推荐工具一览（含板栗看板）</strong></h2><table><thead><tr><th align="left">工具</th><th align="left">优势亮点</th></tr></thead><tbody><tr><td align="left">板栗看板</td><td align="left">独有的无限层级嵌套功能，支持知识点的垂直对齐与可视化归纳</td></tr><tr><td align="left">Workflowy</td><td align="left">极简的无限嵌套列表，适合进行纯粹的堆栈逻辑建模与快速归纳</td></tr><tr><td align="left">Obsidian</td><td align="left">通过双向链接与文件夹嵌套，构建具有堆栈深度的本地化知识库</td></tr><tr><td align="left">ClickUp</td><td align="left">严谨的“空间-目录-任务”层级，适合工程级的堆栈式任务与知识管理</td></tr><tr><td align="left">Notion</td><td align="left">强大的数据库嵌套能力，支持将碎片信息转化为结构化的堆栈资产</td></tr></tbody></table><h2><strong>七、堆栈归纳脚本实战（全新案例）</strong></h2><h3><strong>Python – 生成堆栈结构与逻辑完整度分析</strong></h3><p>Python</p><p>knowledge\_stack \= {</p><pre><code>"系统架构": \["存储层", "逻辑层", "接口层"\],  
"运维SOP": \["环境部署", "安全加固", "监控配置", "故障自愈"\]  </code></pre><p>}</p><p>completion \= {"存储层": True, "逻辑层": True, "接口层": False,</p><pre><code>          "环境部署": True, "安全加固": True, "监控配置": False, "故障自愈": False}
</code></pre><p>for category, items in knowledge\_stack.items():</p><pre><code>solid \= sum(completion.get(i, False) for i in items)  
total \= len(items)  
density \= solid / total \* 100  
print(f"📚『{category}』堆栈完整度：{density:.0f}%（已固化{solid}/总计{total}）")
</code></pre><h3><strong>JavaScript – 堆栈节点自动递归与展示</strong></h3><p>JavaScript</p><p>const stackData \= [  <br/>  {</p><pre><code>topic: "后端开发规范",  
subNodes: \[  
  { title: "命名规则", archived: true },  
  { title: "异常处理", archived: false }  
\]  </code></pre><p>},  <br/>  {</p><pre><code>topic: "性能优化路径",  
subNodes: \[  
  { title: "索引优化", archived: true },  
  { title: "缓存策略", archived: true }  
\]  </code></pre><p>}  <br/>];</p><p>stackData.forEach(node \=\&gt; {  <br/>  const archivedCount \= node.subNodes.filter(s \=\&gt; s.archived).length;  <br/>  const totalCount \= node.subNodes.length;  <br/>  console.log(\`🗃️ ${node.topic}：层级节点复盖率 ${archivedCount}/${totalCount}\`);  <br/>});</p><h3><strong>SQL – 统计堆栈体系中待完善的深度节点</strong></h3><p>SQL</p><p>SELECT root\_topic, node\_title, depth\_level  <br/>FROM knowledge\_stacks  <br/>WHERE status \= 'draft'  <br/>ORDER BY root\_topic, depth\_level;</p><h2><strong>八、典型误区与防范策略</strong></h2><table><thead><tr><th align="left">常见问题</th><th align="left">对应优化建议</th></tr></thead><tbody><tr><td align="left">知识内容全部扁平化堆积</td><td align="left">强制执行“主题-模块-要点”堆栈结构，按逻辑深挖</td></tr><tr><td align="left">只有表层记录缺失深度数据</td><td align="left">启用“下钻必填”机制，确保每一个结论都有底层堆栈支撑</td></tr><tr><td align="left">相似项目的逻辑重复构建</td><td align="left">将高价值堆栈结构固化为“知识模组”，实现一键引用</td></tr><tr><td align="left">堆栈底层更新不同步</td><td align="left">开启层级联动提醒，确保底层变动能实时穿透至顶层归纳</td></tr></tbody></table><h2><strong>九、推动堆栈式知识体系落地的五个动作</strong></h2><ul><li>📌 挑选核心业务，如产品研发、技术支持等，设计“堆栈逻辑模板”；</li><li>📌 在工具中强制推行“无嵌套不归纳”的结构化要求；</li><li>📌 引导团队定期进行“堆栈对齐”会议，重点查看跨层级的逻辑一致性；</li><li>📌 每年盘点高价值堆栈资产，将其转化为组织的标准化能力中心；</li><li>📌 实施“逻辑深度评估”，分析知识堆栈的精细度与决策成功率的关系。</li></ul><h2><strong>十、结语：有堆栈，才有深度资产</strong></h2><p>平铺的知识让人迷茫，堆栈的知识让人通透。</p><p><strong>堆栈式知识归纳软件</strong>不仅是记录工具的革新，更是组织思维方式的重塑。</p><p>从个体层面，它让思考更有深度、经验更易复现；</p><p>从团队层面，它打通了认知的垂直链路，让每一份经验都能精准对齐未来的执行。</p><p>真正的智能，不是存储，而是堆栈。</p><p>从层级出发，打造一个“纵向可穿透、横向可对齐”的智力工厂。</p>]]></description></item><item>    <title><![CDATA[艾体宝方案 | 重塑智能汽车OTA：构建全球级、高可靠、可观测的软件分发与管理系统 艾体宝IT ]]></title>    <link>https://segmentfault.com/a/1190000047554961</link>    <guid>https://segmentfault.com/a/1190000047554961</guid>    <pubDate>2026-01-21 10:02:08</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><strong>摘要</strong><br/>软件定义汽车（SDV）的时代，空中升级（OTA）能力已从“功能”演进为汽车的“生命线”。它承载着功能迭代、安全修复与用户体验提升的核心使命。然而，面对千万级的庞大车队、GB级的升级包体、跨洲际的网络环境以及绝对零容忍的升级安全要求，传统OTA架构在效率、可靠性与智能化方面面临严峻考验。本方案提出，以Redis企业版为核心实时数据引擎，构建新一代智能OTA平台。该平台不仅能够实现升级包的全球分钟级同步与智能边缘分发，更能支撑全链路可观测的灰度发布与秒级触达的安全回滚，将OTA从一项高风险运维活动，转变为稳定、高效、可运营的数字化服务。</p><p><strong>一、OTA演进下的核心挑战</strong><br/>现代智能汽车OTA已超越简单的“推包安装”，成为一个复杂的分布式系统工程：</p><ul><li>挑战一：分发规模与成本的指数级增长：单一车型的软件版本可能超过100GB，而一次全量升级活动需覆盖百万辆汽车。采用中心化分发将产生天量的跨境带宽成本与漫长的下载时间，用户体验难以保障。</li><li>挑战二：灰度发布与流量调控的精细化管理：为控制风险，升级必须遵循从1%到100%的精细化灰度节奏。平台需要实时、动态地管理海量车辆的分组、策略与状态，并能根据故障指标（如安装失败率、系统崩溃率）自动决策暂停或回滚，这对状态管理和决策实时性要求极高。</li><li>挑战三：升级安全的“零信任”与“可追溯”：升级过程必须保证数据的完整性（包体未被篡改）、原子性（要么完全成功，要么完全回退）和可审计性（每一步操作皆有记录）。任何环节的纰漏都可能导致车辆“变砖”，引发大规模安全事故。</li></ul><p><strong>二、Redis企业版：OTA系统的智能数据中枢</strong><br/>Redis企业版凭借其独特的技术组合，成为化解OTA复杂性的战略性组件：</p><ul><li>全球智能分发网络基石：Active-Active地理分布式部署支持升级包元数据与任务指令在全球多个数据中心间实时同步，为构建私有化、低延迟的内容分发网络提供了数据层基础。结合自动分层（Auto Tiering） ，可将高频访问的最新升级包置于内存，将历史版本透明下沉至SSD，实现性能与成本的最佳平衡（存储成本降低约70%）。</li><li>高性能、高可靠的任务编排引擎：Redis Stream 与 Sorted Set 数据结构是构建复杂任务队列的理想选择。它们能够以毫秒级延迟管理数百万车辆的升级状态流转（待推送、下载中、安装中、成功/失败），并支持基于优先级、区域、车型等多维度的灵活调度。</li><li>全链路可观测性与自动化触发器：Redis TimeSeries 模块可高效存储和聚合全量升级过程的性能指标与日志。RedisGears 的函数功能允许在数据库内部设置复杂触发器，例如，当“安装失败率”在5分钟内超过0.1%时，自动暂停当前批次任务并告警，实现从“监控”到“动作”的闭环自动化。</li><li>坚如磐石的数据持久化与高可用：通过同步持久化（AOF with fsync always） 与跨区域复制，确保每一次任务分配、每一条车辆状态更新都不会丢失。其99.999%的高可用性保障了OTA管理控制面自身7x24小时不间断服务。</li></ul><p><strong>架构方案：云边协同的智能OTA平台</strong><br/>以下架构描绘了以Redis企业版为“智能中枢”的下一代OTA平台，如何协同云端与边缘，完成从包管理到安全回滚的全流程。</p><p><strong>核心工作流解析：</strong></p><ol><li><p>升级包全球同步与边缘预热：</p><ul><li>新的升级包在“包工厂”生成并完成签名后，其元数据（版本号、车型、依赖、哈希值）通过 Active-Active 同步至全球所有区域的Redis集群。</li><li>智能调度器根据各区域车辆分布，将包体文件提前推送至各边缘节点Redis集群的SSD层。当车辆发起下载请求时，边缘节点可快速从本地SSD或内存提供服务，下载速度提升300% 以上。</li></ul></li><li><p>精细化灰度发布与实时调控：</p><ul><li>运维人员在控制台创建升级任务，定义灰度批次（如：内部员工1% -&gt; 先锋用户5% -&gt; 全面推送）。该任务被转化为一个主任务Stream和多个批次Sorted Set（按车辆VIN分片）。</li><li>智能调度器作为消费者，从Stream中读取任务，并根据规则从相应批次的Sorted Set中获取车辆列表，通过Pub/Sub或指令通道向车辆下发升级通知。</li><li>车辆端上报的每一个状态（下载进度、安装结果）都实时更新到该车辆对应的状态Hash中。RedisGears 脚本持续监控聚合指标，一旦触发预设规则（如失败率超标），则自动修改任务状态或触发回滚流程。</li></ul></li><li><p>安全回滚与全链路追溯：</p><ul><li>回滚被设计为一个标准的“升级任务”，其回滚包已在边缘节点就绪。当自动或手动触发回滚时，调度器会优先为受影响车辆创建高优先级的回滚任务。</li><li>整个升级生命周期的所有事件（任务创建、指令下发、状态变更、异常告警）均作为时间序列数据存入 Redis TimeSeries，并与具体的车辆VIN、任务ID关联，提供毫秒级精度的全链路追溯能力，满足最高级别的审计要求。</li></ul><p>关键场景与价值量化<br/><img width="723" height="307" referrerpolicy="no-referrer" src="/img/bVdnHnC" alt="image.png" title="image.png"/></p></li></ol><p><strong>结语</strong><br/>在软件定义汽车的竞赛中，OTA的效能直接决定了车企数字化运营的高度与速度。Redis企业版通过将实时数据同步、智能任务编排、多模型存储与边缘计算能力深度融合，为车企提供了一个不仅强大而且“聪慧”的OTA数据基座。这不仅仅是技术的升级，更是运营理念的革新——从被动的、高风险的手动操作，迈向主动的、数据驱动的、全球一体化的软件服务交付。选择Redis企业版，即是选择为未来十年海量车队的软件生命周期管理，构建一个可靠、高效且充满智能的“指挥中心”。</p>]]></description></item><item>    <title><![CDATA[艾体宝方案 | 释放数据潜能 · 构建 AI 驱动的自动驾驶实时数据处理与智能筛选平台 艾体宝IT ]]></title>    <link>https://segmentfault.com/a/1190000047554970</link>    <guid>https://segmentfault.com/a/1190000047554970</guid>    <pubDate>2026-01-21 10:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><strong>摘要</strong><br/>随着自动驾驶技术从原型验证迈向规模化商用，研发范式正经历从“以算法为中心”向“以数据为中心”的根本性转变。海量、高维、多模态的道路采集数据，已不再只是测试过程中的副产物，而是驱动算法持续演进、提升系统安全冗余和泛化能力的核心生产资料。</p><p>然而，当前主流的数据处理模式仍以离线存储与批处理为主，数据在“采集—上传—存储—筛选—标注—训练—验证”之间流转缓慢，形成长周期、低反馈的闭环，逐渐成为制约自动驾驶技术迭代效率的重要瓶颈。</p><p>Redis 企业版作为一款面向实时与 AI 场景设计的数据平台，凭借其多模型数据结构、亚毫秒级访问延迟、内存计算能力以及 AI 原生扩展机制，为构建新一代“实时数据加速层”与“智能数据筛选平台”提供了坚实的技术基础。</p><p>本方案系统性阐述如何基于 Redis 企业版，完成从“数据存储与归档”向“数据理解与智能利用”的跃迁，构建一个能够加速算法创新、提升数据利用率、并在可控成本下实现规模扩展的自动驾驶数据闭环体系。</p><hr/><p><strong>一、行业趋势与核心技术挑战</strong><br/>自动驾驶系统的成熟度，本质上取决于其数据闭环运行的效率与质量。当前行业普遍面临以下三类挑战：</p><p><strong>1.数据规模爆炸与实时性不足</strong><br/>搭载多颗高分辨率摄像头、激光雷达、毫米波雷达与高精定位模块的测试车辆，在真实道路运行中每日可产生 TB 级甚至更高规模的原始数据。<br/>在传统架构下，这些数据往往需要经过集中上传、对象存储落盘、离线处理后，才能被算法与标注团队使用，数据延迟以小时甚至天为单位，难以支撑高频、小步快跑式的算法迭代。</p><p><strong>2.高价值“长尾场景”难以被及时发现</strong><br/>真正推动自动驾驶算法性能跃迁的，并非大量常规驾驶场景，而是占比极低却风险极高的长尾与极端场景（Corner Cases），例如：</p><ul><li>恶劣天气下的感知退化</li><li>非标准交通参与者行为</li><li>复杂施工、事故或临时交通组织变化<br/>在 PB 级数据湖中依赖人工回看或静态规则筛选这些场景，不仅效率低下，且高度依赖经验，成为研发效率的主要瓶颈之一。</li></ul><p><strong>3.多模态异构数据协同困难</strong><br/>自动驾驶数据闭环涉及多种数据形态：</p><ul><li>非结构化数据：视频、点云</li><li>结构化数据：车辆 CAN / 传感器状态</li><li>半结构化数据：标注信息、事件日志</li><li>模型与版本元数据<br/>在传统“多系统拼装式”架构下，这些数据分散在对象存储、关系型数据库、搜索系统和消息队列中，跨模态联合查询与关联分析复杂且成本高昂，制约了数据价值的进一步释放。</li></ul><hr/><p><strong>二、Redis 企业版的核心价值定位</strong><br/>Redis 企业版并非仅用于缓存加速，而是一个面向实时数据与智能应用的统一数据平台（Real-Time Data Platform），在自动驾驶数据闭环中具备独特优势。</p><p><strong>1.高吞吐、低延迟的数据流转能力</strong><br/>Redis 的内存计算架构可提供亚毫秒级读写延迟，适合承载高并发、高频率的数据流。</p><ul><li>Redis Streams 提供持久化、有序的数据流模型与消费者组机制，可用于构建可靠的数据接入与分发管道</li><li>在部分自动驾驶数据采集与处理场景中，Streams 可作为传统消息系统的轻量化替代或补充，显著降低端到端延迟与系统复杂度（具体取舍需结合吞吐规模与历史回溯需求评估）</li></ul><p><strong>2.多模型数据的统一承载能力</strong><br/>Redis 企业版原生支持多种数据模型：</p><ul><li>JSON：车辆状态、标注与任务元数据</li><li>TimeSeries：高频传感器与车辆运行状态</li><li>Geospatial：轨迹、地图要素与空间查询</li><li>Vector：场景特征、感知结果向量化表达</li><li>Graph：数据、模型、标注、测试之间的关系建模<br/>这些能力使多模态数据得以在同一高性能平台内协同存储与联合查询，显著降低系统集成复杂度。</li></ul><p><strong>3.面向 AI 的原生计算与推理能力</strong><br/>通过 RedisAI 模块，可将训练完成的深度学习模型（支持 TensorFlow、PyTorch、ONNX 等主流格式）直接部署在 Redis 集群中，实现：</p><ul><li>数据就地推理（In-Data Inference）</li><li>特征提取与初步场景理解的实时执行</li><li>减少数据在系统间搬运与序列化开销<br/>这为实时智能筛选、在线预标注等能力提供了关键技术支撑。</li></ul><p><strong>4. 企业级可靠性与数据韧性</strong><br/>Redis 企业版提供完善的企业级能力，包括：</p><ul><li>持久化机制（RDB + AOF）</li><li>跨可用区 / 跨地域的 Active-Active 架构</li><li>自动故障转移与在线扩缩容<br/>确保关键路采数据与生产级服务具备高可用性与业务连续性。</li></ul><hr/><p><strong>三、总体技术架构：自动驾驶数据闭环的“智能中枢”</strong><br/>下图展示了以 Redis 企业版为核心的自动驾驶实时数据与智能筛选平台总体架构。<br/><img width="723" height="743" referrerpolicy="no-referrer" src="/img/bVdnHnN" alt="image.png" title="image.png"/><br/><strong>架构要点说明</strong></p><ul><li>数据接入与预处理：通过 Redis Streams 接收车辆数据流，结合 RedisGears 在入库阶段完成轻量 ETL、数据校验与初步特征生成</li><li><p>智能存储与索引：</p><ul><li>高频状态数据驻留内存</li><li>特征向量支持相似度搜索</li><li>多条件混合查询（时间、空间、语义、向量）</li></ul></li><li>自动分层存储：通过 Redis 企业版 Auto Tiering，将历史数据透明下沉至 SSD，在性能与成本之间取得平衡</li></ul><hr/><p><strong>四、典型应用场景与业务价值</strong><br/><strong>场景一：实时长尾场景发现与预警</strong><br/>通过在数据流入口部署轻量化感知或场景识别模型，系统可在数据生成阶段实时识别潜在高风险或高价值场景，并自动标记、优先存储与推送。<br/><strong>价值体现：</strong></p><ul><li>关键场景发现从“事后分析”变为“实时捕获”</li><li>研发人员可更快聚焦真实风险点<br/><strong>场景二：高效的训练数据供给与样本挖掘</strong><br/>将清洗后、高价值的训练样本及其元数据作为热数据缓存于 Redis 中，为分布式训练集群提供低延迟数据访问，并支持向量化困难样本挖掘。<br/>价值体现：</li><li>提升训练资源利用率</li><li>缩短模型迭代周期</li><li>改善模型在极端场景下的表现</li></ul><p><strong>场景三：全链路数据资产可追溯管理</strong><br/>利用 Redis Graph 构建数据、标注、模型与测试结果之间的关系网络，实现端到端的版本追溯与审计。<br/><strong>价值体现：</strong></p><ul><li>提升研发过程透明度</li><li>支撑 ASPICE、ISO 26262 等质量与安全合规要求</li></ul><hr/><p><strong>结语</strong><br/>在自动驾驶竞争进入深水区后，真正拉开差距的已不再只是单点算法能力，而是数据被理解、被利用、被反馈的效率与智能程度。<br/>Redis 企业版通过将高速数据处理、多模型数据管理与 AI 原生计算能力融合于一体，为自动驾驶企业提供了一条清晰、可落地的路径，将海量数据从“负担”转化为可持续演进的“核心资产”，为迈向更高级别自动驾驶奠定坚实的数据基础设施。</p>]]></description></item><item>    <title><![CDATA[剑指offer-66、机器⼈的运动范围 SevenCoding ]]></title>    <link>https://segmentfault.com/a/1190000047548739</link>    <guid>https://segmentfault.com/a/1190000047548739</guid>    <pubDate>2026-01-21 09:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>题目描述</h2><p>地上有⼀个 m ⾏和 n 列的⽅格。⼀个机器⼈从坐标（0,0） 的格⼦开始移动，每⼀次只能向左，右，上，下四个⽅向移动⼀格，但是不能进⼊⾏坐标和列坐标的数位之和⼤于 k 的格⼦。 例如，当k 为 18 时，机器⼈能够进⼊⽅格（35,37） ，因为 3+5+3+7 = 18 。但是，它不能进⼊⽅格（35,38） ，因为 3+5+3+8 = 19 。请问该机器⼈能够达到多少个格⼦？</p><p>示例1</p><p>输⼊：5,10,10<br/>返回值：21</p><p>示例2</p><p>输⼊：10,1,100<br/>返回值：29</p><p>说明：[0,0],[0,1],[0,2],[0,3],[0,4],[0,5],[0,6],[0,7],[0,8],[0,9],[0,10],[0,11],[0,12],[0,13],[0,14],[0,15],[0,16],[0,17],[0,18],[0,19],[0,20],[0,21],[0,22],[0,23],[0,24],[0,25],[0,26],[0,27],[0,28] 这29种，后⾯的[0,29] , [0,30] 以及[0,31] 等等是⽆法到达的。</p><h2>思路及解答</h2><h3>DFS（深度优先搜索）</h3><p>深度优先搜索算法，也就是 DFS ,⾸先需要初始化数组，注意是 boolean 类型的⼆元数组。边初始化<br/>边计算位数的和，判断如果⼤于等于阈值的话，就直接置为 true ，也就是已经被访问到（但是这⼀部分计⼊结果）。</p><p>然后遍历每⼀个元素，只要 i ， j 不在合法的索引范围或者是已经被访问过，都会直接返回<br/>false 。</p><p>否则的话，可访问的数量 +1 ，并且递归遍历上下左右四个元素，返回最终的可访问的个数。</p><p>DFS 会优先同⼀个⽅向，⼀直⾛下去，不撞南墙不回头，直到条件不满⾜的时候，才会回头。回头之后，每次只会回头⼀步，往另外⼀个⽅向去，同样是⼀头扎进去。</p><p>假设有⼀个 4 x 4 的⽅格，从第⼀个开始遍历，假设遍历顺序是上，右，下，左，那么遍历的顺序如下：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047548741" alt="" title=""/></p><pre><code class="java">public class Solution {
    public int movingCount(int threshold, int rows, int cols) {
        if (rows &gt; 0 &amp;&amp; cols &gt; 0) {
            boolean[][] visited = new boolean[rows][cols];
            for (int i = 0; i &lt; rows; i++) {
                for (int j = 0; j &lt; cols; j++) {
                    // 如果⼤于阈值，设置已被访问过
                    visited[i][j] = ((getSum(i) + getSum(j)) &gt; threshold);
                }
            }
            return getNum(visited, 0, 0, 0);
        }
        return 0;
    }
    
   // 获取可以被访问的个数
   private int getNum(boolean[][] visited, int i, int j, int count) {
        if (i &lt; 0 || j &lt; 0 || i &gt;= visited.length || j &gt;= visited[0].length ||
            visited[i][j]) {
            return count;
        }
        count++;
        visited[i][j] = true;
        count = getNum(visited, i, j + 1, count);
        count = getNum(visited, i, j - 1, count);
        count = getNum(visited, i + 1, j, count);
        count = getNum(visited, i - 1, j, count);
        return count;
   }
   
    // 计算位数之和
   private int getSum(int num) {
        int result = 0;
        while (num &gt; 0) {
            result = result + num % 10;
            num = num / 10;
        }
        return result;
    }
}</code></pre><ul><li>时间复杂度：最坏的情况是将所有的格⼦都遍历⼀遍， O(m*n) 。</li><li>空间复杂度：借助了额外的空间保存是否被访问过，同样为O(m*n) 。</li></ul><h3>BFS（⼴度优先搜索）</h3><p>⼴度优先搜索，也就是没进⾏⼀步，优先搜索当前点的各个⽅向上的点，不急着往下搜索，等搜索完当前点的各个⽅向的点，再依次把之前搜索的点，取出来，同样先搜索周边的点...</p><p>这样直到所有都被搜索完成。</p><p>同样有⼀个 4 x 4 的⽅格，从第⼀个开始遍历，假设遍历顺序是上，右，下，左，那么遍历的顺序如下：</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047548742" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047548743" alt="" title="" loading="lazy"/></p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047548744" alt="" title="" loading="lazy"/></p><p>在上⾯的过程图示中，我们可以发现，访问是有顺序的，每遍历⼀个新的⽅块，都会标⼀个顺序，然后按照顺序遍历其四个⽅向。</p><p>这也就是⼴度优先搜索的本质，我们需要⼀个队列，来保存遍历的顺序，每次都从队列⾥⾯取出⼀个位置，遍历其四周的⽅块，每次遍历到的点，都会放到队列⾥⾯，这样直到队列为空的时候，也就是全部遍历完成。</p><pre><code class="java">import java.util.LinkedList;
import java.util.Queue;

public class Solution13 {
    public int movingCount(int threshold, int rows, int cols) {
        boolean[][] visited = new boolean[rows][cols];
        int count = 0;
        
        Queue&lt;int[]&gt; queue = new LinkedList&lt;&gt;();
        // 把第⼀个点加到队列⾥⾯
        queue.add(new int[]{0, 0});
        
        while (queue.size() &gt; 0) {
            // ⼀直取数据，直到队列为空
            int[] x = queue.poll();
            // 取出来的数据，包含x，y坐标
            int i = x[0], j = x[1];
            // 如果访问过或者不符合，直接下⼀个
            if (i &gt;= rows || j &gt;= cols || threshold &lt; getSum(i) + getSum(j) || visited[i][j]) continue;
            
            // 置为访问过
            visited[i][j] = true;
            // 数量增加
            count++;
            // 右
            queue.add(new int[]{i + 1, j});
            // 下
            queue.add(new int[]{i, j + 1});
       }
       return count;
   }
   
    // 计算位数之和
   private int getSum(int num) {
        int result = 0;
        while (num &gt; 0) {
            result = result + num % 10;
            num = num / 10;
        }
        return result;
    }
}</code></pre><ul><li>时间复杂度：最坏的情况是将所有的格⼦都遍历⼀遍， O(m*n) 。</li><li>空间复杂度：借助了额外的空间保存是否被访问过，同样为O(m*n) 。</li></ul><h3>动态规划（最优解）</h3><p>利用递推关系式，避免重复计算。</p><ul><li>格子(i,j)可达 ⇔ 数位和满足条件 ∧ (左边格子可达 ∨ 上边格子可达)</li><li>dpi表示(i,j)是否可达，基于左边和上边格子的状态：<code>dp[i][j] = (digitSum(i) + digitSum(j) ≤ k) &amp;&amp; (dp[i-1][j] || dp[i][j-1])</code></li></ul><pre><code class="java">public class Solution {
    public int movingCount(int m, int n, int k) {
        if (k == 0) return 1;
        
        // dp[i][j]表示格子(i,j)是否可达
        boolean[][] dp = new boolean[m][n];
        dp[0][0] = true;  // 起点可达
        int count = 1;     // 起点已计入
        
        for (int i = 0; i &lt; m; i++) {
            for (int j = 0; j &lt; n; j++) {
                // 跳过起点和数位和超限的情况
                if ((i == 0 &amp;&amp; j == 0) || digitSum(i) + digitSum(j) &gt; k) {
                    continue;
                }
                
                // 检查是否可以从左边或上边到达当前格子
                if (i - 1 &gt;= 0) {
                    dp[i][j] |= dp[i - 1][j];  // 从上边来
                }
                if (j - 1 &gt;= 0) {
                    dp[i][j] |= dp[i][j - 1];  // 从左边来
                }
                
                // 如果当前格子可达，计数加1
                count += dp[i][j] ? 1 : 0;
            }
        }
        
        return count;
    }
    
    private int digitSum(int num) {
        int sum = 0;
        while (num &gt; 0) {
            sum += num % 10;
            num /= 10;
        }
        return sum;
    }
}</code></pre><ul><li><strong>时间复杂度</strong>：O(mn)，双重循环遍历所有格子</li><li><strong>空间复杂度</strong>：O(mn)，dp数组的空间</li></ul>]]></description></item><item>    <title><![CDATA[没有现成 API？教你在 ArkUI 里手写一个“施放”交互效果 前端视界 ]]></title>    <link>https://segmentfault.com/a/1190000047554506</link>    <guid>https://segmentfault.com/a/1190000047554506</guid>    <pubDate>2026-01-20 22:03:36</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047554508" alt="在这里插入图片描述" title="在这里插入图片描述"/></p><h2>摘要</h2><p>在 HarmonyOS 的 ArkUI 开发中，经常会遇到这样一种交互需求：<br/>用户按下某个组件，拖动它，然后在松手的一瞬间触发一个“释放”动作，比如飞出去、回弹、投放到某个区域，或者触发业务逻辑。</p><p>很多同学在一开始都会问一个问题：<br/><strong>ArkUI 里有没有现成的“施放 API”？</strong></p><p>答案是：没有。<br/>但 ArkUI 提供的 <strong>手势系统、状态管理和动画能力</strong>，已经足够我们组合出各种“施放效果”。</p><p>这篇文章就从一个最基础的拖拽开始，一步一步讲清楚：<br/><strong>ArkUI 中的“施放功能”到底是怎么实现的，以及在真实项目中该怎么用。</strong></p><h2>引言</h2><p>随着 HarmonyOS 应用交互越来越偏向“自然操作”，像拖拽、投放、抛出这类交互，在实际项目中出现得非常多，比如：</p><ul><li>卡片拖到指定区域触发操作</li><li>图标长按后丢进回收区</li><li>功能模块拖拽排序</li><li>智能设备管理中，把设备“丢”进分组</li></ul><p>在 ArkUI 里，这些效果并不是某一个组件单独完成的，而是<strong>多种能力的组合</strong>。<br/>理解这一点之后，你会发现实现起来并不复杂，而且扩展性非常强。</p><h2>ArkUI 中“施放”的本质是什么</h2><p>从技术角度来看，所谓“施放”，本质就是三步：</p><ol><li>用手势感知用户操作</li><li>用状态驱动组件位置变化</li><li>在松手时，通过动画完成“释放效果”</li></ol><p>换句话说就是：<br/><strong>手势负责输入，状态负责位置，动画负责感觉。</strong></p><h2>最基础的施放实现：拖拽 + 松手回弹</h2><h3>实现思路</h3><p>这个 Demo 不考虑目标区域，只关注三件事：</p><ul><li>手指拖动时，组件跟着动</li><li>松手后触发动画</li><li>动画结束后回到原位</li></ul><h3>可运行 Demo 示例</h3><pre><code class="ts">@Entry
@Component
struct CastBasicDemo {
  @State offsetX: number = 0
  @State offsetY: number = 0

  build() {
    Column() {
      Text('拖拽组件，松手后施放')
        .fontSize(18)
        .margin(20)

      Box()
        .width(80)
        .height(80)
        .backgroundColor(Color.Blue)
        .translate({ x: this.offsetX, y: this.offsetY })
        .gesture(
          PanGesture()
            .onUpdate((event) =&gt; {
              // 拖动过程中，组件位置实时更新
              this.offsetX = event.offsetX
              this.offsetY = event.offsetY
            })
            .onEnd(() =&gt; {
              // 松手瞬间，触发“施放”动画
              animateTo({
                duration: 300,
                curve: Curve.EaseOut
              }, () =&gt; {
                this.offsetX = 0
                this.offsetY = 0
              })
            })
        )
    }
    .width('100%')
    .height('100%')
    .justifyContent(FlexAlign.Center)
  }
}</code></pre><h3>代码讲解（重点）</h3><p>这里其实就三行是核心：</p><pre><code class="ts">this.offsetX = event.offsetX
this.offsetY = event.offsetY</code></pre><p>组件的位置完全由 <code>@State</code> 控制，手势只是不断修改状态。</p><p>而“施放”的感觉来自这里：</p><pre><code class="ts">animateTo({}, () =&gt; {
  this.offsetX = 0
  this.offsetY = 0
})</code></pre><p>只要状态变化发生在动画作用域内，就会自动过渡。</p><h2>带目标区域的“施放”：成功 or 回弹</h2><p>在真实项目中，施放通常不是随便松手就算成功，而是：</p><ul><li>拖到某个区域才成功</li><li>没拖到就回弹</li></ul><h3>思路拆解</h3><ul><li>拖拽过程中，持续记录位移</li><li>松手时判断最终位置</li><li>根据结果执行不同动画</li></ul><h3>示例代码</h3><pre><code class="ts">@Entry
@Component
struct CastTargetDemo {
  @State offsetX: number = 0
  @State offsetY: number = 0

  build() {
    Stack() {
      // 目标区域
      Box()
        .width(120)
        .height(120)
        .backgroundColor(Color.Grey)
        .position({ x: 200, y: 300 })

      // 可施放组件
      Box()
        .width(80)
        .height(80)
        .backgroundColor(Color.Green)
        .translate({ x: this.offsetX, y: this.offsetY })
        .gesture(
          PanGesture()
            .onUpdate((event) =&gt; {
              this.offsetX = event.offsetX
              this.offsetY = event.offsetY
            })
            .onEnd(() =&gt; {
              if (this.offsetX &gt; 150 &amp;&amp; this.offsetY &gt; 250) {
                // 施放成功，吸附到目标
                animateTo({ duration: 200 }, () =&gt; {
                  this.offsetX = 200
                  this.offsetY = 300
                })
              } else {
                // 失败，回弹
                animateTo({ duration: 300 }, () =&gt; {
                  this.offsetX = 0
                  this.offsetY = 0
                })
              }
            })
        )
    }
    .width('100%')
    .height('100%')
  }
}</code></pre><h3>这里在做什么判断</h3><pre><code class="ts">if (this.offsetX &gt; 150 &amp;&amp; this.offsetY &gt; 250)</code></pre><p>这本质上是一个<strong>区域命中判断</strong>。<br/>在正式项目中，你可以：</p><ul><li>根据组件尺寸动态计算</li><li>封装成工具函数</li><li>甚至引入碰撞检测逻辑</li></ul><h2>真实应用场景示例</h2><h3>场景一：卡片拖拽投放到功能区</h3><p><strong>典型应用</strong>：<br/>首页卡片管理、模块编辑模式。</p><h4>示例核心代码</h4><pre><code class="ts">.onEnd(() =&gt; {
  if (this.offsetX &gt; 180) {
    animateTo({ duration: 200 }, () =&gt; {
      this.offsetX = 220
      this.offsetY = 0
    })
    // 这里可以触发业务逻辑，比如加入列表
  } else {
    animateTo({ duration: 300 }, () =&gt; {
      this.offsetX = 0
      this.offsetY = 0
    })
  }
})</code></pre><p>逻辑上非常清晰：<br/>UI 动画和业务逻辑是分开的，不会互相影响。</p><h3>场景二：图标拖进回收站</h3><p>这种交互非常常见，关键点是：</p><ul><li>松手瞬间让组件消失</li><li>而不是回弹</li></ul><pre><code class="ts">.onEnd(() =&gt; {
  if (this.offsetY &gt; 400) {
    animateTo({ duration: 200 }, () =&gt; {
      this.offsetY = 600
    })
  } else {
    animateTo({ duration: 300 }, () =&gt; {
      this.offsetX = 0
      this.offsetY = 0
    })
  }
})</code></pre><p>你也可以配合透明度一起做：</p><pre><code class="ts">.opacity(this.isRemoved ? 0 : 1)</code></pre><h3>场景三：设备管理中的“拖拽分组”</h3><p>结合你后续可能做的鸿蒙设备管理场景：</p><ul><li>左侧设备列表</li><li>右侧分组区域</li><li>拖拽设备到分组完成绑定</li></ul><p>这时就可以升级到 <strong>Drag &amp; Drop</strong>，实现跨组件投放。</p><pre><code class="ts">Box()
  .draggable(true)
  .onDragStart(() =&gt; {
    return { data: 'device-id-001' }
  })</code></pre><p>目标区域：</p><pre><code class="ts">Column()
  .onDrop((event) =&gt; {
    console.log('接收到设备：', event.data)
  })</code></pre><p>这种方式更适合复杂业务。</p><h2>QA 常见问题</h2><h3>Q1：为什么不用绝对定位？</h3><p>绝对定位是死的，而 <code>translate</code> 是基于状态的，动画过渡更自然，也更安全。</p><h3>Q2：施放动画卡顿怎么办？</h3><ul><li>确保只操作必要的状态</li><li>避免在 <code>onUpdate</code> 里写复杂逻辑</li><li>动画时间不要太长</li></ul><h3>Q3：PanGesture 和 Drag 怎么选？</h3><ul><li>单组件内部效果：PanGesture</li><li>跨组件、跨区域：Drag &amp; Drop</li></ul><h2>总结</h2><p>在 ArkUI 中，“施放功能”并不是某一个 API，而是一种<strong>交互设计模式</strong>：</p><ul><li>手势负责感知用户行为</li><li>状态决定组件位置</li><li>动画塑造最终体验</li></ul><p>只要你理解了这个组合思路，就可以根据项目需求，灵活实现各种拖拽、投放、释放效果，而且代码非常干净、可维护性也很好。</p>]]></description></item><item>    <title><![CDATA[鸿蒙系统 IO 性能优化实战：从应用卡顿到 OTA 升级的完整解决方案 前端视界 ]]></title>    <link>https://segmentfault.com/a/1190000047554510</link>    <guid>https://segmentfault.com/a/1190000047554510</guid>    <pubDate>2026-01-20 22:02:45</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047554512" alt="在这里插入图片描述" title="在这里插入图片描述"/></p><h2>摘要</h2><p>在鸿蒙（HarmonyOS / OpenHarmony）应用和系统开发中，IO 操作几乎无处不在，比如文件读写、配置加载、日志输出、数据库访问以及 OTA 升级等。很多性能问题表面上看是应用卡顿、启动慢、耗电高，实际上根源都指向 IO 使用不当。本文结合当前鸿蒙系统的实际开发现状，从应用层和系统层两个角度，系统梳理 IO 性能优化的常见思路，并通过可运行的 Demo 代码，讲清楚这些优化在真实项目中该怎么落地。</p><p>文章整体偏向实战，语言尽量贴近日常开发交流，适合正在做鸿蒙应用、系统服务或设备升级相关开发的同学参考。</p><h2>引言</h2><p>随着鸿蒙生态逐渐完善，应用形态从早期的简单页面，发展到现在的多端协同、分布式能力、设备级应用，IO 压力明显变大。一方面，应用启动阶段要加载更多配置和资源；另一方面，系统服务、后台任务、设备升级都会产生大量读写操作。</p><p>在实际项目中，经常能看到下面这些情况：</p><ul><li>页面一打开就卡，结果发现主线程在读文件</li><li>日志一多，设备开始明显发热</li><li>OTA 升级时间很长，写盘阶段占了一大半</li><li>分布式数据一同步，前台体验明显下降</li></ul><p>这些问题并不是鸿蒙系统本身性能不行，而是 IO 的使用方式不够合理。下面我们就从最常见、也最容易优化的地方开始讲。</p><h2>鸿蒙 IO 性能瓶颈从哪来</h2><p>在多数项目中，IO 性能问题通常集中在下面几个点：</p><ul><li>频繁进行小文件读写</li><li>同步 IO 放在主线程执行</li><li>每次用文件都重新 open 和 close</li><li>没有任何缓存策略</li><li>用文件存 KV 数据</li><li>日志输出不受控制</li></ul><p>只要命中其中一两条，性能基本都会出问题。</p><h2>应用层 IO 优化（最常用）</h2><h3>IO 一定不要放在主线程</h3><p>这是最基础，也是最容易踩坑的一点。ArkTS 中如果直接使用同步文件接口，UI 线程就会被直接卡住。</p><h4>错误示例</h4><pre><code class="ts">import fs from '@ohos.file.fs';

let text = fs.readTextSync('/data/storage/test.txt');</code></pre><p>这种写法在数据量稍微大一点时，页面就会出现明显卡顿。</p><h4>推荐写法（异步 IO Demo）</h4><pre><code class="ts">import fs from '@ohos.file.fs';

export async function readFileAsync(path: string): Promise&lt;string&gt; {
  let file = await fs.open(path, fs.OpenMode.READ_ONLY);
  let buffer = new ArrayBuffer(4096);
  let result = '';

  let readLen = await fs.read(file.fd, buffer);
  if (readLen &gt; 0) {
    result = String.fromCharCode(...new Uint8Array(buffer, 0, readLen));
  }

  await fs.close(file);
  return result;
}</code></pre><h4>代码说明</h4><ul><li>使用 async/await，把 IO 操作放到异步任务中</li><li>读取完成后再返回结果，不阻塞 UI</li><li>真实项目中可以配合 taskpool 使用</li></ul><h3>合并小 IO，减少系统调用</h3><p>很多性能问题不是数据量大，而是 IO 次数太多。</p><h4>不推荐的写法</h4><pre><code class="ts">for (let i = 0; i &lt; list.length; i++) {
  fs.writeSync(fd, list[i]);
}</code></pre><h4>推荐写法</h4><pre><code class="ts">let content = list.join('');
fs.writeSync(fd, content);</code></pre><h4>实际效果</h4><ul><li>系统调用次数明显减少</li><li>写盘效率更高</li><li>对 Flash 存储更友好</li></ul><h3>引入内存缓存，避免重复读文件</h3><p>配置文件、初始化数据非常适合放进内存缓存。</p><pre><code class="ts">let configCache: string | null = null;

export async function getConfig(path: string): Promise&lt;string&gt; {
  if (configCache !== null) {
    return configCache;
  }
  configCache = await readFileAsync(path);
  return configCache;
}</code></pre><h4>使用场景</h4><ul><li>应用启动配置</li><li>JSON 静态数据</li><li>权限或状态信息</li></ul><h3>能用 Preferences 就别用文件</h3><p>对于少量 KV 数据，文件 IO 的性价比非常低。</p><h4>Preferences Demo</h4><pre><code class="ts">import preferences from '@ohos.data.preferences';

export async function saveUserInfo(context, userId: string) {
  let pref = await preferences.getPreferences(context, 'user_config');
  await pref.put('userId', userId);
  await pref.flush();
}</code></pre><h4>优点</h4><ul><li>内部自带缓存</li><li>自动批量落盘</li><li>使用简单，性能稳定</li></ul><h2>系统层 IO 优化（Native / 服务侧）</h2><h3>使用缓冲 IO</h3><p>在系统服务或 Native 模块中，直接写裸 IO 往往效率不高。</p><pre><code class="cpp">#include &lt;stdio.h&gt;

void writeFile(const char* path, const char* data, size_t len) {
    FILE* fp = fopen(path, "w");
    if (!fp) return;

    setvbuf(fp, nullptr, _IOFBF, 8 * 1024);
    fwrite(data, 1, len, fp);
    fclose(fp);
}</code></pre><h4>说明</h4><ul><li>设置 8KB 缓冲区</li><li>减少实际写盘次数</li><li>适合大量顺序写场景</li></ul><h3>顺序 IO 优于随机 IO</h3><pre><code class="cpp">off_t offset = 0;
pread(fd, buffer, size, offset);
offset += size;</code></pre><p>尽量避免频繁 seek 和交叉读写多个文件。</p><h3>控制日志 IO</h3><p>日志在调试阶段很有用，但在正式环境中是 IO 隐形杀手。</p><pre><code class="ts">if (__DEV__) {
  console.info('debug log');
}</code></pre><p>建议：</p><ul><li>发布版本关闭 debug 和 info</li><li>避免循环内打印日志</li><li>合并日志输出</li></ul><h2>典型应用场景分析</h2><h3>场景一：应用启动阶段加载配置</h3><h4>问题</h4><p>启动慢，页面白屏时间长。</p><h4>解决方案</h4><ul><li>异步读取配置</li><li>内存缓存</li></ul><pre><code class="ts">await getConfig('/data/storage/app_config.json');</code></pre><h3>场景二：OTA 升级文件写入</h3><h4>问题</h4><p>升级包大，写盘耗时长。</p><h4>优化思路</h4><ul><li>分块下载</li><li>分块写入</li><li>写完再统一校验</li></ul><pre><code class="ts">async function writeChunk(fd: number, data: Uint8Array) {
  await fs.write(fd, data.buffer);
}</code></pre><h3>场景三：日志过多导致设备发热</h3><h4>问题</h4><p>设备运行一段时间后发热、掉帧。</p><h4>解决方案</h4><ul><li>控制日志级别</li><li>关闭非必要日志</li></ul><h2>常见问题 QA</h2><p><strong>Q：异步 IO 一定比同步快吗？</strong><br/>A：不一定，但一定不会卡 UI。</p><p><strong>Q：缓存会不会导致数据不一致？</strong><br/>A：需要设计好更新策略，配置类数据问题不大。</p><p><strong>Q：文件和 RDB 怎么选？</strong><br/>A：结构化数据选 RDB，大文件选文件。</p><h2>总结</h2><p>IO 性能优化并不复杂，关键在于使用方式是否合理。大多数性能问题，并不是因为设备性能不足，而是 IO 用得太随意。</p><p>简单总结几句话：</p><ul><li>IO 不要放主线程</li><li>少做小 IO，多做批量 IO</li><li>能缓存就缓存</li><li>能不用文件就不用文件</li><li>日志一定要克制</li></ul><p>这些原则在应用层、系统层、OTA 场景中都是通用的。如果你正在做鸿蒙系统相关开发，把 IO 优化当成基本功，会少踩很多坑。</p>]]></description></item><item>    <title><![CDATA[鸿蒙 UI 为什么会卡？GPU 渲染性能实战分析与优化 前端视界 ]]></title>    <link>https://segmentfault.com/a/1190000047554520</link>    <guid>https://segmentfault.com/a/1190000047554520</guid>    <pubDate>2026-01-20 22:02:14</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p><img referrerpolicy="no-referrer" src="/img/remote/1460000047554522" alt="在这里插入图片描述" title="在这里插入图片描述"/></p><h3>摘要</h3><p>随着鸿蒙系统在手机、平板、穿戴设备以及多终端场景中的应用越来越多，<strong>UI 流畅度</strong>已经成为用户最直观、最容易感知的问题之一。<br/>在实际开发中，很多页面逻辑并不复杂，但依然会出现<strong>掉帧、滑动卡顿、动画不顺畅</strong>等情况，问题往往不在 CPU，而是出在 <strong>GPU 渲染压力过大</strong> 上。</p><p>本文结合 <strong>ArkUI 实际开发经验</strong>，从页面结构、状态管理、动画、图片、列表等多个角度，系统性地讲一讲 <strong>鸿蒙系统中 GPU 渲染性能该怎么优化</strong>，并给出<strong>可以直接运行的 Demo 示例代码</strong>，帮助你在真实项目中快速落地。</p><h3>引言</h3><p>在 HarmonyOS / OpenHarmony 体系下，UI 渲染主要由 <strong>ArkUI + 系统渲染管线 + GPU</strong> 协同完成。<br/>理想情况下，每一帧的渲染时间要控制在 <strong>16ms 以内</strong>（60fps），一旦 GPU 在某一帧中承担了过多工作，就会直接表现为：</p><ul><li>页面滑动一卡一卡的</li><li>动画有明显掉帧</li><li>列表滚动不跟手</li><li>设备发热、功耗升高</li></ul><p>尤其是在 <strong>列表页、图片多的页面、复杂动画页面</strong> 中，这些问题非常常见。</p><p>所以，GPU 优化不是“锦上添花”，而是<strong>必须要做的基础工作</strong>。</p><h2>减少无效重绘是第一优先级</h2><h3>状态放对位置，比任何技巧都重要</h3><p>在 ArkUI 中，只要 <code>@State</code> 发生变化，就会触发组件重新构建和重新渲染。<br/>如果状态放得不合理，GPU 就会被迫做很多“没必要的活”。</p><h4>错误示例：一个状态刷新整个页面</h4><pre><code class="ts">@Entry
@Component
struct BadPage {
  @State count: number = 0

  build() {
    Column() {
      Text('当前数值：' + this.count)
      Button('点击 +1')
        .onClick(() =&gt; {
          this.count++
        })
    }
  }
}</code></pre><p>这里的问题是：<br/><strong>整个 Page 都会随着 count 改变而刷新</strong>。</p><h4>推荐做法：把状态下沉到最小组件</h4><pre><code class="ts">@Component
struct Counter {
  @State count: number = 0

  build() {
    Column() {
      Text('当前数值：' + this.count)
      Button('点击 +1')
        .onClick(() =&gt; {
          this.count++
        })
    }
  }
}

@Entry
@Component
struct GoodPage {
  build() {
    Column() {
      Counter()
    }
  }
}</code></pre><p>这样 GPU 只需要重绘 <code>Counter</code> 这块区域，<strong>页面其它部分完全不受影响</strong>。</p><h3>实际场景：仪表盘 / 实时数据页面</h3><p>比如你在做一个<strong>设备状态监控页面</strong>：</p><ul><li>电量实时变化</li><li>网络状态刷新</li><li>温度数值更新</li></ul><p>如果所有数据都放在一个 Page 的 State 中，那 GPU 每秒都在全量刷新页面。</p><p>更好的做法是：</p><ul><li>每一个数据块独立成组件</li><li>各自维护自己的 State</li></ul><p>这样就能明显降低 GPU 的渲染负载。</p><h2>减少透明度和层级嵌套（Overdraw）</h2><h3>opacity 是 GPU 的“隐形杀手”</h3><p>很多开发者喜欢用 <code>opacity</code> 做视觉效果，但实际上它非常容易触发 <strong>离屏渲染</strong>。</p><h4>不推荐的写法</h4><pre><code class="ts">Column() {
  Text('Hello HarmonyOS')
}
.opacity(0.5)</code></pre><h4>推荐写法：直接用半透明颜色</h4><pre><code class="ts">Column() {
  Text('Hello HarmonyOS')
}
.backgroundColor('#80FFFFFF')</code></pre><p><strong>原因很简单</strong>：<br/><code>opacity</code> 会让 GPU 先在缓存中绘制，再合成到屏幕上，步骤变多了，性能自然下降。</p><h3>实际场景：弹窗、蒙层页面</h3><p>常见的弹窗结构是：</p><ul><li>半透明遮罩</li><li>中间卡片</li></ul><p>推荐做法：</p><ul><li>遮罩用半透明色值</li><li>卡片背景保持不透明</li><li>避免多层 Stack 嵌套</li></ul><p>这样在低端设备上也能保证弹窗动画顺畅。</p><h2>图片与纹理优化</h2><h3>图片尺寸不匹配，会让 GPU 白干活</h3><p>GPU 很不喜欢<strong>加载大图再缩小显示</strong>。</p><h4>错误示例</h4><pre><code class="ts">Image($r('app.media.big_image'))
  .width(100)
  .height(100)</code></pre><h4>正确做法：准备合适尺寸资源</h4><pre><code class="ts">Image($r('app.media.image_100'))
  .width(100)
  .height(100)</code></pre><h3>使用缓存，避免反复解码</h3><pre><code class="ts">Image($r('app.media.avatar'))
  .cache(true)</code></pre><p>这在 <strong>列表头像、商品图片</strong> 这种场景下，效果非常明显。</p><h3>实际场景：商品列表 / 相册页面</h3><ul><li>列表中每一项都有图片</li><li>滑动过程中频繁创建 Image</li></ul><p>如果没有缓存和尺寸控制，很容易出现：</p><ul><li>滑动掉帧</li><li>页面发热</li></ul><h2>动画优化：只动 transform，不动布局</h2><h3>动布局动画成本非常高</h3><h4>不推荐</h4><pre><code class="ts">.animate({ duration: 300 })
.width(this.size)</code></pre><p>这里会触发布局重新计算，GPU 和 CPU 都要加班。</p><h4>推荐：使用 transform</h4><pre><code class="ts">.animate({ duration: 300 })
.transform({
  translateX: this.offset
})</code></pre><p>transform 只影响最终绘制阶段，对 GPU 更友好。</p><h3>实际场景：侧滑菜单 / 卡片动画</h3><ul><li>菜单滑入滑出</li><li>卡片弹出收起</li></ul><p>这些动画如果全用 transform，基本可以做到<strong>低端机也不卡</strong>。</p><h2>列表必须使用 LazyForEach</h2><h3>普通 ForEach 的问题</h3><pre><code class="ts">ForEach(this.list, item =&gt; {
  Text(item.name)
})</code></pre><p>数据一多，GPU 会直接爆炸。</p><h3>正确姿势：LazyForEach</h3><pre><code class="ts">LazyForEach(this.list, (item) =&gt; {
  Text(item.name)
}, item =&gt; item.id)</code></pre><p>只有屏幕可见的部分才会真正创建和渲染。</p><h3>实际场景：设备列表 / 日志列表</h3><p>比如：</p><ul><li>智能设备列表</li><li>升级日志</li><li>消息列表</li></ul><p>LazyForEach 基本是<strong>必选项</strong>。</p><h2>完整可运行 Demo：高性能列表页面</h2><pre><code class="ts">@Entry
@Component
struct GpuOptimizeDemo {
  private data: Array&lt;{ id: number; name: string }&gt; = []

  aboutToAppear() {
    for (let i = 0; i &lt; 1000; i++) {
      this.data.push({ id: i, name: '设备 ' + i })
    }
  }

  build() {
    List() {
      LazyForEach(this.data, (item) =&gt; {
        ListItem() {
          Row() {
            Text(item.name)
              .fontSize(16)
          }
          .padding(12)
        }
      }, item =&gt; item.id)
    }
  }
}</code></pre><p>这个 Demo 在真机上滑动时，GPU 占用非常稳定。</p><h2>QA 环节</h2><h4>Q1：GPU 优化是不是只针对低端设备？</h4><p>不是。<br/>高端设备只是“扛得住”，但功耗和发热依然会变高。</p><h4>Q2：opacity 一点都不能用吗？</h4><p>不是不能用，而是<strong>少用、慎用</strong>，尤其避免大面积使用。</p><h4>Q3：怎么快速定位 GPU 问题？</h4><ul><li>DevEco Studio 的布局和性能分析</li><li>看是否有掉帧</li><li>看是否存在大面积 Overdraw</li></ul><h3>总结</h3><p>在鸿蒙系统中，GPU 渲染优化的核心思路其实很简单：</p><ul><li>状态尽量小、尽量局部</li><li>少透明、少嵌套</li><li>图片尺寸要对、缓存要开</li><li>动画只动 transform</li><li>列表一定懒加载</li></ul><p>这些优化手段<strong>单独看都不复杂</strong>，但一旦组合起来，页面流畅度会有非常明显的提升。</p>]]></description></item><item>    <title><![CDATA[如何高效对接美股实时行情？StockTV API 实战集成指南 CryptoRzz ]]></title>    <link>https://segmentfault.com/a/1190000047554530</link>    <guid>https://segmentfault.com/a/1190000047554530</guid>    <pubDate>2026-01-20 22:01:23</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>在当今全球化的投资环境中，美股市场（如 NYSE 和 NASDAQ）凭借其极高的流动性和影响力，成为了开发者和金融产品经理关注的重点。要构建一个成功的量化交易系统或行情展示应用，<strong>数据的实时性</strong>与<strong>稳定性</strong>是核心命脉。</p><p>本文将基于 <strong>StockTV 全球金融数据接口</strong>，详细介绍如何快速对接美股实时行情数据。</p><hr/><h3>一、 为什么选择？</h3><p>在对接美股数据时，开发者通常面临接口复杂、延迟高、覆盖不全等痛点。StockTV 提供的 API 具有以下优势：</p><ol><li><strong>极速实时性</strong>：提供 HTTP 和 WebSocket (WS) 双重接入方式，WS 模式可实现毫秒级的数据推送。</li><li><strong>全球覆盖</strong>：除美国外，还支持印度、日本、韩国、新加坡等多个主流及新兴市场。</li><li><strong>多维度数据</strong>：涵盖实时价格、K线数据、涨跌排行、IPO日历及公司基本面信息。</li><li><strong>集成简单</strong>：返回标准 JSON 格式，几行代码即可完成对接。</li></ol><hr/><h3>二、 快速开始：获取接入权限</h3><p>在调用接口前，您需要准备好身份验证密钥（Key）：</p><ul><li><strong>获取方式</strong>：联系技术支持获取专属 Key。</li><li><strong>调用规范</strong>：在所有 API 请求中，将 Key 添加到 <code>key</code> 参数中即可。</li></ul><hr/><h3>三、 美股核心接口对接指南</h3><h4>1. 精准查询美股实时行情</h4><p>美股市场庞大，您可以通过 <code>symbol</code>（股票代码，如 AAPL、TSLA）直接获取最新价格及各项指标。</p><ul><li><strong>接口地址</strong>：<code>https://api.stocktv.top/stock/queryStocks</code></li><li><strong>核心参数</strong>：<code>symbol</code> (股票代码), <code>key</code> (您的Key)</li><li><strong>美股交易所筛选</strong>：在市场列表中，可以通过 <code>exchangeId</code> 进行区分（1 为 NYSE，2 为 NASDAQ）。</li></ul><h4>2. 实时 K 线数据对接</h4><p>对于需要绘制图表的应用，StockTV 提供了灵活的 K 线接口，支持 5分钟、15分钟、1小时、天、周等多种粒度。</p><ul><li><strong>接口地址</strong>：<code>https://api.stocktv.top/stock/kline</code></li><li><strong>参数示例</strong>：<code>pid=产品ID&amp;interval=PT5M</code>（获取5分钟实时K线）</li></ul><h4>3. 美股涨跌排行榜</h4><p>实时监控市场热点，获取美股涨幅榜、跌幅榜或换手率排行，帮助用户捕捉异动。</p><ul><li><strong>接口地址</strong>：<code>https://api.stocktv.top/stock/updownList</code></li><li><strong>关键点</strong>：实时返回最新变动数据，确保排行榜的即时更新。</li></ul><hr/><h3>四、 代码实战：Python 请求示例</h3><p>以下是一个简单的 Python 示例，演示如何获取苹果公司（AAPL）的实时行情：</p><pre><code class="python">import requests

# 配置参数
api_key = "您的Key"
base_url = "https://api.stocktv.top/stock/queryStocks"
params = {
    "symbol": "AAPL",
    "key": api_key
}

try:
    response = requests.get(base_url, params=params)
    data = response.json()
    
    if data['code'] == 200:
        stock_info = data['data'][0]
        print(f"股票名称: {stock_info['name']}")
        print(f"最新价格: {stock_info['last']}")
        print(f"涨跌幅: {stock_info['chgPct']}%")
        print(f"最后更新时间戳: {stock_info['time']}")
    else:
        print(f"请求失败: {data['message']}")
except Exception as e:
    print(f"发生错误: {e}")
</code></pre><hr/><h3>五、 进阶：如何保障“极致实时”？</h3><p>对于对延迟极其敏感的量化交易场景，建议采用以下方案：</p><ol><li><strong>WebSocket (WS) 接入</strong>：相比 HTTP 定时轮询，WebSocket 采用长连接推送机制，能在市场价格跳动的第一时间将数据推送到客户端。</li><li><strong>精简请求</strong>：通过 <code>stocksByPids</code> 接口一次性获取多个自选股的最新数据，减少网络往返开销。</li><li><strong>时间戳校验</strong>：StockTV 的每个返回包都包含 <code>time</code> 时间戳，请务必在本地进行校验以确保处理的是最新数据。</li></ol><hr/><h3>六、 结语</h3><p>StockTV API 为美股数据对接提供了极简且强大的解决方案。无论您是个人开发者还是企业级应用，都能通过其稳定、实时的接口快速实现业务目标。</p><hr/><p><em>本文数据及接口信息来源于 StockTV 官方技术文档。</em></p>]]></description></item><item>    <title><![CDATA[从原理到实践：ComfyUI 是如何实现“从噪点到杰作”的？ blossom ]]></title>    <link>https://segmentfault.com/a/1190000047554413</link>    <guid>https://segmentfault.com/a/1190000047554413</guid>    <pubDate>2026-01-20 21:01:54</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h3>引言</h3><p>在上一篇文章中，我们探讨了 AI 绘画看似神奇的“魔法”背后的真相：它并非凭空创造，而是一个从混沌的噪点中，通过无数次“观察-脑补-修正”的循环，逐步建立秩序、生成图像的过程。理解了这一核心原理，一个自然的问题随之产生：我们该如何操控这个过程？是需要编写晦涩难懂的代码，还是有更直观、更易上手的方法？</p><p>答案是肯定的。今天，我们将介绍一位强大的幕后英雄——ComfyUI。作为一款基于节点流程的 Stable Diffusion 用户界面，ComfyUI 就像是一个透明的 AI 魔法工坊。它将复杂的 AI 生成过程拆解为一个个独立的模块，让使用者能够像搭积木一样，直观地构建和掌控自己的 AI 绘画工作流。本文将带领读者走进这个工坊，通过拆解一个最基础的文生图工作流，揭示每一个“积木”是如何分工协作，最终完成那场精彩的“脑补”大戏的。</p><h3>第一部分：初识 ComfyUI —— AI 的可视化乐高</h3><p>如果将传统的、集成度高的 AI 绘画 WebUI 比作一个功能齐全的“黑盒子”微波炉，用户只需放入食材、按下按钮即可得到成品，那么 ComfyUI 就更像是一套透明的乐高积木，或者一个开放式的中央厨房。</p><p>ComfyUI 的核心特点在于其“节点化 (Node-based)”的设计理念。在这里，每一个功能——无论是加载模型、处理文本，还是执行采样、解码图像——都被封装成了一个个独立的方块，称为“节点”。用户通过线缆将这些节点连接起来，定义数据的流向。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047554415" alt="" title=""/></p><p>这种可视化流向的设计，使得 AI 的工作过程不再神秘。使用者看到了什么连接，AI 后台就执行了什么操作。数据从哪里来，到哪里去，经过了怎样的处理，一切都一目了然。更重要的是，这种极致的灵活性赋予了用户无限的创造空间。使用者可以根据自己的需求，像搭积木一样自由组合各种节点，构建出从简单到无比复杂的个性化创意工作流。</p><h3>第二部分：解剖一只麻雀 —— 最基础的文生图工作流拆解</h3><p>面对 ComfyUI 的界面，初学者可能会对满屏的节点和连线感到困惑。但无需担心，万丈高楼平地起。理解了最基础的工作流，就掌握了通往复杂应用的钥匙。下面展示的是一个最典型的 ComfyUI 文生图（Text-to-Image）工作流界面，我们将逐一拆解其中的核心角色。</p><p><strong>1. 大管家：加载器 (Checkpoint Loader Simple)</strong></p><p>一切工作的起点，是这个被称为“加载器”的节点。它就像是整个魔法工坊的物料仓库大管家。</p><p>它的作用是加载预先训练好的模型文件，通常称为 Checkpoint。这个文件至关重要，因为它打包了 AI 的核心能力：负责图像生成的“大脑”（UNet 网络）、负责理解文本的“眼睛”（CLIP 模型）以及负责图像数据转换的“翻译器”（VAE）。选择不同的 Checkpoint 文件，就决定了 AI 的“阅历”和基础“画风”，是擅长二次元动漫，还是写实摄影，全赖于此。它是所有后续工作的基石。</p><p><strong>2. 翻译官与指挥棒：CLIP 文本编码器 (CLIP Text Encode)</strong></p><p>人类使用自然语言描述画面，而 AI 的核心模型只能理解数学化的向量。这就需要“CLIP 文本编码器”充当人类与 AI 之间的沟通桥梁。</p><p>这个节点的作用是将用户输入的文本提示词（Prompt），“翻译”成 AI 能懂的数学指令，在技术上称为<strong>“条件 (Conditioning)”</strong>。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047554416" alt="" title="" loading="lazy"/></p><p>在基础工作流中，通常会看到两个这样的节点。一个负责翻译正向提示词，生成“正向条件”，告诉 AI “画面里必须出现什么”（如：一只猫、高质量、阳光）；另一个负责翻译反向提示词，生成“反向条件”，告诉 AI “画面里绝对不能出现什么”（如：低质量、变形、水印）。这两个条件就像是两根指挥棒，将在后续的生成过程中，严格引导和约束 AI 的创作方向。</p><p><strong>3. 魔术师与沙盘：K 采样器 (KSampler)</strong></p><p>“K 采样器”是整个工坊的核心车间，是奇迹真正发生的地方。它负责执行我们之前提到的“从噪点到清晰图像”的去噪循环。</p><p>为了高效地处理图像生成这一庞大的计算工程，AI 极其聪明地选择了一个策略：不在巨大的像素级画布上直接作画，而是在一个被称为<strong>“潜在空间 (Latent Space)”</strong>的沙盘上搭建一个精巧的<strong>“小模型”</strong>（潜在图像）。KSampler 就是在这个沙盘上进行精细化作业的魔术师。因为它处理的是高度浓缩的信息，而非海量的像素数据，所以效率极高。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047554417" alt="" title="" loading="lazy"/></p><p>这位魔术师在沙盘上工作时，并非随心所欲。它需要三种原料：从加载器获取的“模型”能力、一个初始的“空白画布”（通常是一个纯噪声的潜在图像），以及最重要的——从文本编码器传来的两根“指挥棒”。</p><p>在设定的步数内，KSampler 执行着“观察-脑补-修正”的循环。在每一步操作中，它都会严格参照“正向条件”的指南和“反向条件”的禁令，努力将沙盘上混沌的噪声，逐步转化为符合人类要求的、有意义的“小模型”。</p><p><strong>4. 神奇打印机：VAE 解码 (VAE Decode)</strong></p><p>当 KSampler 在沙盘上完成了创作，我们得到的是一个“潜在图像”。它虽然包含了画面的所有核心信息，但却是一团人类肉眼无法辨识的压缩数据。</p><p>这时就需要“VAE 解码”节点出场了。它就像是一台神奇的建筑打印机。它接过沙盘上那个抽象的“小模型”，利用大管家提供的 VAE 工具（图像数据转换的翻译器），按照特定的规则将这份压缩数据“解压”，并最终“打印”成我们眼前这座宏伟、清晰、色彩斑斓的像素大图。</p><p><img referrerpolicy="no-referrer" src="/img/remote/1460000047554418" alt="" title="" loading="lazy"/></p><p><strong>5. 展示台：保存/预览图像 (Save/Preview Image)</strong></p><p>工作流的终点是“保存/预览图像”节点。它的任务非常直观：将 VAE 解码器输出的最终像素图像展示在界面上供用户检阅，并将其保存到计算机的硬盘中，完成整个创作流程。</p><h3>第三部分：连线——让数据流动起来</h3><p>在 ComfyUI 中，节点之间的连线不仅仅是视觉上的连接，它们代表了数据显性的流动路径。理解了连线，就理解了 AI 工作的逻辑。</p><p>就像不同形状的积木插口一样，ComfyUI 中只有相同类型的数据端口才能连接，这保证了流程的正确性。</p><ul><li><strong>模型连模型 (MODEL)</strong>：将加载器中的绘画能力传递给采样器。</li><li><strong>条件连条件 (CONDITIONING)</strong>：将文本编码器生成的“指挥棒”传递给采样器，指引创作方向。</li><li><strong>潜在图像连潜在图像 (LATENT)</strong>：在采样器和解码器之间传递那个核心的沙盘“小模型”。</li><li><strong>VAE 连 VAE (VAE)</strong>：将加载器中的翻译规则传递给解码器，用于最终图像的还原。</li></ul><p>整个流程可以总结为一条清晰的主线：加载模型备物料 -&gt; 输入文字变指挥棒 -&gt; 准备沙盘造噪声 -&gt; 采样核心搞创作（受指挥棒引导） -&gt; VAE 解码打印出图像。</p><h3>结语</h3><p>ComfyUI 以其独特的节点化设计，看似复杂，实则提供了一种最直观、最透彻的方式来理解和掌控 AI 绘画。它将深奥的 AI 生成原理拆解为一个个清晰可见的步骤，让我们不仅能“知其然”（看到最终的精美图像），更能“知其所以然”（理解图像是如何一步步生成的）。</p><p>通过理解“潜在空间”这个高效运作的沙盘，以及“条件”这两根强有力的指挥棒，我们揭开了 AI 绘画魔法的一角。掌握基础工作流只是第一步，ComfyUI 的魅力在于其无限的扩展性。鼓励每一位使用者去探索更多的高级节点，如 ControlNet、LoRA 等，搭建属于自己的、独一无二的 AI 绘画流水线，释放无限的创造潜能。</p><p>本文由<a href="https://link.segmentfault.com/?enc=4IV7Jh5eR8FKt4hGHC2Ucg%3D%3D.l8uHMG2nGa2EawFeVxszAlbDLWztSTXAaZfJoMqSsL8%3D" rel="nofollow" target="_blank">mdnice</a>多平台发布</p>]]></description></item><item>    <title><![CDATA[使用 tsfresh 和 AutoML 进行时间序列特征工程 本文系转载，阅读原文
https://]]></title>    <link>https://segmentfault.com/a/1190000047554425</link>    <guid>https://segmentfault.com/a/1190000047554425</guid>    <pubDate>2026-01-20 21:01:24</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <p>时间序列无处不在，心电图上的心跳、股票价格、家庭智能电表读数，甚至句子中词语——这些都是时间序列。它们的特殊之处在于顺序：过去影响未来，相邻的数据点往往高度相关。</p><p>现代预测和分类模型很少直接处理原始时间序列值。它们依赖的是特征：用来描述序列形状、变异性、趋势和模式的摘要信息。好的特征能把困难的预测问题转化为更简单的回归或分类任务。</p><p>当前有两大趋势，一是 AutoML（自动机器学习），像 auto-sklearn 这样的系统能自动搜索模型族、超参数和预处理步骤。二是自动化时间序列特征提取，像 tsfresh 这样的库可以从每个序列生成数百个特征，涵盖统计量、自相关、频谱内容、熵等各个维度。</p><p>最近的研究表明，将 AutoML 与丰富的时间序列特征结合，在许多预测任务上能超越复杂的深度神经网络。更有意思的是这种方法甚至可以通过"语言时间序列"来提升文本分类的性能。<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047554427" alt="" title=""/></p><p>本文将介绍多步时间序列预测的构建方式、auto-sklearn 如何扩展用于时间序列、tsfresh 的工作原理和使用方法，以及两个案例研究：数值预测和文本作为时间序列。文末还有一些可以直接应用到项目中的实用技巧。</p><h2>多步预测：不仅预测下一步，还要预测接下来的 k 步</h2><p>多步超前预测的目标不是预测下一个值，而是预测一整个序列的未来值：</p><p>$$
x_{i+1}, x_{i+2}, \dots, x_{i+k}
$$</p><p>比如预测未来 24 小时的电力负荷、未来 10 天的原油价格，或者提前几个时间步预测洪水水位。</p><p>两种主要策略被广泛使用。</p><h3>递归策略</h3><p>首先训练一个模型只预测下一个时间步：</p><p>$$
\hat{x}_{i+1} = f(x_{i-w+1}, \dots, x_i)
$$</p><p>然后把这个预测值作为输入反馈进去，得到下一个预测：</p><p>$$
\hat{x}_{i+2} = f(x_{i-w+2}, \dots, x_i, \hat{x}_{i+1})
$$</p><p>如此重复直到达到 x_{i+k}。</p><p>这种方法只需训练一个模型，计算成本较低。但问题在于早期步骤的任何误差都会在后续预测中传播和放大，这就是我们常说的自回归预测。</p><h3>直接多输出策略</h3><p>另一种思路是训练一个模型一次预测所有未来步骤：</p><p>$$
[\hat{x}_{i+1}, \dots, \hat{x}_{i+k}] = f(x_{i-w+1}, \dots, x_i)
$$</p><p>这样做的好处是跨预测范围没有误差累积，在固定计算预算下通常准确性更好。缺点是模型更复杂，数据有限时可能更难拟合。</p><p>实践中两种策略都有用武之地。关键点在于：无论选择哪种策略，输入窗口大小 w 的选择以及从该窗口计算的特征都会显著影响性能。</p><h2>时间序列的 AutoML：扩展 auto-sklearn</h2><p>AutoML 的目标是自动化机器学习流水线的设计，包括数据清洗、特征预处理、模型选择和超参数调优。像 auto-sklearn 这样的系统把这当作搜索问题来处理：用贝叶斯优化和元学习探索不同的流水线，构建优秀候选者的集成。</p><p>典型的 auto-sklearn 流水线包含预处理器（缩放、填充等）、特征预处理器（PCA、核近似等）、模型（SVM、随机森林、梯度提升等）以及集成构建组件。</p><p>不过原始的 auto-sklearn 是为通用表格数据设计的。开箱即用时它不包含专门的时间序列特征提取器，像自相关峰值、频谱熵或季节性统计量这些。</p><p>有人对 auto-sklearn 做了修改，让特征预处理阶段可以包含时间序列特征提取（特别是使用 tsfresh），并且把窗口大小 w 本身作为超参数来搜索。扩展后的 AutoML 系统会搜索算法 A（SVM、GBM 等）、超参数 λ 和窗口大小 w，以最小化验证数据上的损失函数（如 RMSE）。</p><h2>tsfresh</h2><p>tsfresh（Time Series Feature Extraction based on Scalable Hypothesis tests，基于可扩展假设检验的时间序列特征提取）是一个 Python 库。它能自动从每个时间序列计算数百个特征："综合"特征集大约有每个序列 794 个特征。</p><p>这些特征涵盖的类别相当广：基本统计量（均值、方差、分位数）、形状描述符（偏度、峰度、绝对能量）、自相关和偏自相关、频域度量（傅里叶系数、频谱能量、熵）、非线性时间序列特征（排列熵、小波系数等）。tsfresh 还会用假设检验来判断哪些特征与目标相关，配合多重检验校正来避免错误发现。</p><p>这种方式把工作重心从手动发明特征（"要不要试试滚动均值、滞后差分，或许再加个 FFT？"）转移到系统地探索一个丰富的特征库，让统计学和模型性能来决定什么才是重要的。</p><h3>数据格式化</h3><p>tsfresh 期望长格式的 DataFrame：一列用于 id（标识这行属于哪个时间序列）、一列用于 time（或排序索引）、一列或多列包含观测值。</p><p>示例结构大致如下：<br/><img referrerpolicy="no-referrer" src="/img/remote/1460000047554428" alt="" title="" loading="lazy"/></p><h3>特征提取</h3><p>通常会调用类似这样的代码：</p><pre><code> from tsfresh import extract_features
from tsfresh.feature_extraction import ComprehensiveFCParameters

features = extract_features(
    df,
    column_id="id",
    column_sort="time",
    default_fc_parameters=ComprehensiveFCParameters()
 )</code></pre><p>这会产生一个宽表，每行对应一个时间序列（一个 id），每列是一个特征，比如 value<strong>mean、value</strong>abs_energy、value<strong>autocorrelation</strong>lag_1、value<strong>fourier_entropy</strong>bins_5 等等。</p><h3>处理缺失值</h3><p>对于很短或退化的序列，某些特征是未定义的（比如长度为 1 的序列没法计算 FFT）。tsfresh 提供了工具来填充或删除包含太多 NaN 的列：</p><pre><code> from tsfresh.utilities.dataframe_functions import impute
 
 impute(features)  # 用合理的默认值替换 NaN / inf</code></pre><p>或者简单地删除全是 NaN 的列：</p><pre><code> features = features.dropna(axis=1)</code></pre><h3>特征相关性和选择</h3><p>对于监督任务，tsfresh 还能基于假设检验进行特征选择，将每个特征与目标关联起来。这通常通过 extract_relevant_features 等函数完成，或者通过集成 tsfresh 的 AutoML 框架来应用其自身的选择逻辑。</p><h3>用于预测的滚动特征提取</h3><p>做预测时通常希望在滑动窗口上计算特征。先选择窗口大小（比如 24 小时），对每个时间窗口计算 tsfresh 特征，然后用这些特征行作为输入，将未来目标值作为标签。</p><h2>案例研究 1：AutoML + tsfresh 用于多步预测</h2><p>Wang 等人对 AutoML 和时间序列特征工程在多步预测任务上的相互作用进行了系统研究。</p><h3>问题设置</h3><p>给定单变量时间序列 (x_1, x_2, \dots, x_i)，目标是仅使用最后 w 个观测值来预测接下来的 k 个值：</p><p>$$
x_{i+1}, \dots, x_{i+k}
$$</p><p>窗口大小 w 至关重要。太小会错过慢速模式；太大模型会看到嘈杂或不相关的历史。作者之前的工作已经表明，即使在单步任务中调整 w 也能显著影响预测性能，所以他们在这里把自动窗口大小选择扩展到了多步设置。</p><h3>扩展 auto-sklearn</h3><p>他们对 auto-sklearn 做了两处主要调整。第一是添加基于 tsfresh 的时间序列特征提取器作为候选特征预处理器。第二是把窗口大小 w 作为 AutoML 可以搜索的超参数，而不是固定的手动选择常数。</p><p>扩展后的 AutoML 系统会搜索模型族（SVM、GBM 等）、超参数（C、学习率、树深度等）和窗口大小 w（考虑 50–200 点等范围）。</p><h3>三种 AutoML 变体</h3><p>他们提出了三种专门用于时间序列预测的 auto-sklearn 变体。</p><p>W 变体（带自动窗口大小选择的 Auto-sklearn）使用窗口中的原始滞后值作为特征，让 AutoML 在 50–200 的范围内选择最佳窗口大小。</p><p>T 变体（带 tsfresh 特征的 Auto-sklearn）使用固定窗口大小（比如 w = 100），应用 tsfresh 从每个窗口段提取数百个特征，用 Benjamini-Hochberg 程序为每个预测步骤选择统计显著的特征，然后取跨预测范围的并集。</p><p>WT 变体结合了两个想法：AutoML 同时调整窗口大小 w 并使用从每个候选窗口提取的 tsfresh 特征。</p><h3>基线和数据</h3><p>为了对这些变体进行基准测试，他们与多种基线进行了比较。传统机器学习基线包括 SVM（递归和多输出两种形式）和 GBM（同样有递归和多输出两种）。神经网络和 AutoML 基线包括 N-BEATS（一个很强的单变量预测深度学习模型）、Auto-Keras（配置了 LSTM/GRU 循环块和手动选择的窗口大小）以及原始 auto-sklearn（固定窗口大小，无时间序列特定特征）。</p><p>数据集来自 CompEngine，一个大型时间序列数据仓库。他们从不同类别选择了 20 个数据集：音频（动物声音、语音、音乐）、生态数据、宏观和微观经济、金融（原油、汇率、天然气价格）、医学数据（ECG）、动力系统（受驱摆、Duffing 振荡器等）和随机过程（自回归、随机游走等）。每个数据集按时间分为 67% 训练集和 33% 测试集。</p><h3>关键发现</h3><p>几个最有意思的结果值得一提。</p><p>多输出模型在相同计算预算下通常优于递归模型，大概是因为避免了跨预测范围的误差累积。原始 auto-sklearn（固定窗口大小）已经在 20 个数据集中的 8 个上击败了所有传统机器学习基线。</p><p>专门的 AutoML 变体进一步提升了性能。W 变体（自动窗口大小，无 tsfresh）在 20 个数据集中的 14 个上优于最佳传统机器学习基线（SVM 多输出）。W、T 和 WT 分别在 10、5 和 5 个数据集上显示出比所有传统基线更低的误差。</p><p>与深度学习模型 N-BEATS 相比，最佳 AutoML 变体 W 在 20 个数据集中的 14 个上胜出。其他 AutoML 系统（Auto-Keras、原始 auto-sklearn、T、WT）也在许多数据集上击败 N-BEATS，有时差距相当大。</p><h3>要点总结</h3><p>这项研究有几个关键发现。AutoML 配合经典模型与深度模型具有极强的竞争力，特别是结合良好的特征工程和窗口大小调整时。窗口大小是一等超参数——即使没有花哨的特征，调整它也能带来很大收益。tsfresh 特征有帮助，但不一定以预期的方式：总体来看，纯窗口大小变体 W 是最强的，而基于 tsfresh 的变体可能在特定领域或评估指标上更有优势。多输出策略是有限预算下多步预测的可靠默认选择。</p><h2>案例研究 2：将文本作为时间序列处理</h2><p>时间序列特征工程不只适用于传感器读数或金融数据。在 2020 年的 EPJ Data Science 文章中，Tang 等人把短文本样本重新解释为时间序列，然后应用 tsfresh 风格的特征提取来改进作者归属任务。</p><h3>从文本到"语言时间序列"</h3><p>先对每个文本样本分词，然后把每个 token 映射到一个数值度量——可以是它在语料库中的频率、按频率的排名、字符长度，或者对词计数向量的贡献等。按 token 在句子中的位置排列这些数值，就形成了"语言时间序列"。</p><p>他们实验了五种功能性语言序列映射，包括 token 频率序列、token 排名序列、token 长度序列，以及基于分布的序列（如 token 长度分布和 token 排名分布）。每个结果序列都像普通时间序列一样处理。</p><h3>文本上的时间序列特征提取</h3><p>对于这五种映射中的每一种，他们用 tsfresh（ComprehensiveFCParameters）每个序列提取 794 个时间序列特征，最终得到每个文本样本 3970 个风格计量特征（794 × 5 种映射）。用 tsfresh 的 impute 函数处理缺失值和无穷值，用 10 折交叉验证评估模型，以 log loss 作为主要指标。</p><p>这些时间序列特征然后与标准 NLP 基线（朴素贝叶斯和最近质心分类器）的预测结合，用 XGBoost 构建混合分类器。</p><h3>结果和见解</h3><p>他们在两个数据集上进行了测试：Spooky Books（平衡类别，恐怖小说）和联邦党人文集（不平衡，历史上很重要的论文）。</p><p>在 Spooky Books 案例中，语言时间序列特征持续改进了基线 NLP 模型。对于联邦党人文集，将这些特征加到强 NLP 基线中带来了较小但仍有希望的改进。</p><p>一些特定的 tsfresh 特征在语言学上具有很好的可解释性。平均 token 长度特征能区分倾向于使用长词还是短词的作者。token 长度序列上的 c3 非线性统计量捕捉了词长波动的微妙模式。token 长度分布上的线性趋势特征（截距和斜率）能反映作者是倾向于使用均匀范围的词长还是集中于较短的词。</p><p>作者的结论是，时间序列特征提取提供了新颖的风格计量信号，可以增强传统 NLP 特征，这个功能性语言分析框架在更广泛的作者归属和风格分析任务中有潜力。</p><h2>实用工作流程</h2><p>整合前面的内容，这里给出一个可以用于时间序列项目（数值或文本）的具体流程。</p><p>首先要清楚定义预测任务：是单步还是多步预测？分类还是回归？</p><p>然后选择窗口策略。从 w 的合理范围开始（小时数据可以从 24–168 开始），如果可能的话把 w 作为可调超参数处理。</p><p>接着为 tsfresh 格式化数据。数值时间序列用 (id, time, value) 格式。文本的话，像 Tang 等人那样把句子转换为功能性语言序列（token 长度、频率、排名等）。</p><p>用 tsfresh 提取特征时，从 ComprehensiveFCParameters 开始探索完整的特征库，用 impute() 清理 NaN 和无穷值。</p><p>特征选择有几种方式：用 tsfresh 自带的相关性检验，或应用 Benjamini-Hochberg 这样的多重检验控制，或在模型中用正则化/特征重要性方法（基于树的模型、L1 正则化线性模型等）。</p><p>模型方面，如果做结构化实验，auto-sklearn 或 Auto-Keras 这样的框架可以搜索模型族和超参数。否则从梯度提升、随机森林或调优良好的神经网络这些强基线开始。</p><p>评估要充分。预测任务考虑 RMSE、MAE 和特定预测范围的误差。分类任务（包括文本）用准确率、log loss 和校准指标，最好配合交叉验证。</p><p>最后是解释关键特征。用特征重要性图或 SHAP 值看哪些 tsfresh 特征重要，把它们与领域知识联系起来：是否捕捉了季节性、波动性、体制变化或风格模式？是否揭示了不同组之间的差异（作者、患者类型、设备状态等）？</p><h2>总结</h2><p>从数值到文本领域，这些工作传达的信息很明确。</p><p>时间序列的特征工程远未过时——它只是变得更系统化和自动化了。AutoML 系统可以把 tsfresh 这样的时间序列特定组件纳入进来，效果很好，通常能在许多任务上与最先进的神经模型匹敌甚至超越。把文本这样的非传统数据当作时间序列处理，开启了一个全新的特征和分析工具空间。</p><p>如果正在构建预测或序列分类流水线，值得尝试 tsfresh 或类似的特征库、能同时调整模型和窗口大小的 AutoML 框架，以及"语言时间序列"这样的跨领域思路。工程特征带来可解释性，AutoML 提供灵活性，而如果这些研究有任何指示意义的话——实现最先进性能的机会相当不错。</p><p>引用：</p><p><a href="https://link.segmentfault.com/?enc=afH0Y9j3nbkB8m94FXsVww%3D%3D.uGnKvpXwR9bQRV5TWTlM1ArZpov6XCoF1tO0Ks%2F%2BkawjWFhC2EtMQ3xgNUqa93W2F1C8HFaqYMbfrq59CnZyhg%3D%3D" rel="nofollow" target="_blank">https://avoid.overfit.cn/post/a96a4522adbf4d82a3b02b8c328b2306</a></p><p>作者：QuarkAndCode</p>]]></description></item><item>    <title><![CDATA[如何搭建自己的第一个智能体 智能猫 ]]></title>    <link>https://segmentfault.com/a/1190000047554370</link>    <guid>https://segmentfault.com/a/1190000047554370</guid>    <pubDate>2026-01-20 20:02:06</pubDate>    <description><![CDATA[<link rel="stylesheet" href="https://static.segmentfault.com/main_site_next/prod/_next/static/css/8a2de9abf59d619c.css" data-n-g=""> <h2>摘要</h2><p>本文专为智能体入门者设计​<strong>从 0 到 1 的实操指南</strong>​，摒弃复杂理论，以 “选场景 → 挑平台 → 做搭建 → 调优化 → 落地用” 为核心流程，聚焦零代码平台实操（兼顾代码入门轻指引），搭配工具选择、避坑要点、高频 QA 与落地计划，让新手能在 1-7 天内快速做出可实际使用的第一个智能体。核心逻辑为​<strong>以具体需求为导向，轻量化落地，先跑通再优化</strong>​，无需深厚编程或 AI 基础，零基础也能快速上手。</p><p>搭建自己的第一个智能体，核心不是啃透技术原理，而是​<strong>先锁定一个具体需求，选择适配的零代码工具，通过简单的可视化操作完成搭建与调试</strong>​。新手优先从解决个人 / 工作的小痛点入手（如日程提醒、文档问答、邮件总结），避开复杂功能，让智能体先 “能用”，再逐步优化 “好用”。以下是分步骤的详细实操指南，全程聚焦零代码落地，同时补充代码入门的轻量路径。</p><h2>一、前期准备（30 分钟）：定需求、选平台，找对切入点</h2><h3>1. 锁定一个具体落地需求（核心关键）</h3><p>新手切忌贪多求全，优先选择<strong>单一、标准化、高频重复</strong>的小需求，这类需求搭建简单、易出成果，推荐入门需求清单：</p><ul><li>个人效率类：日程管理助手（同步日历 + 提醒待办）、文档问答助手（上传笔记 / PDF，快速检索答案）、每日信息汇总（整合新闻 / 公众号 / 邮件核心内容）</li><li>办公职场类：会议纪要助手（提取录音 / 文字核心信息 + 拆分待办）、报表辅助助手（整理表格数据 + 生成简单分析）、客服快捷回复助手（根据问题匹配标准答案）</li><li>学习科研类：错题整理助手（上传错题，自动分类 + 标注考点）、文献摘要助手（提取论文核心观点 / 研究方法）</li></ul><p>​<strong>选需求原则</strong>​：自己每天都会用到、手动做耗时 5 分钟以上、需求描述能一句话说清（如 “帮我总结微信公众号的干货文章，提取 3 个核心观点”）。</p><h3>2. 零代码平台选择（新手首选，无需编程）</h3><p>按<strong>新手友好度、国内适配性、功能贴合度</strong>排序，附平台核心特点与适配场景，直接选其一即可，不用纠结多平台对比：</p><table><thead><tr><th>平台</th><th>核心特点</th><th>适配入门需求</th><th>操作难度</th><th>推荐指数</th></tr></thead><tbody><tr><td>扣子（Coze）</td><td>国内主流，全中文界面，可视化拖拽，办公 / 生活插件丰富（日历、微信、文档），自带角色模板，调试简单</td><td>全品类入门需求，尤其办公 / 个人效率类</td><td>★☆☆☆☆</td><td>★★★★★</td></tr><tr><td>Dify（云版）</td><td>低代码零代码结合，知识库功能强大，支持 PDF/Word/Excel 多格式上传，文档问答体验佳</td><td>文档问答、知识检索类需求</td><td>★★☆☆☆</td><td>★★★★☆</td></tr><tr><td>CrewAI（零代码版）</td><td>侧重任务流程，角色设定清晰，适合单智能体的任务执行</td><td>分步式任务类（如 “选题 → 写作”“提取 → 总结”）</td><td>★★☆☆☆</td><td>★★★☆☆</td></tr></tbody></table><h3>3. 基础准备工作</h3><ul><li>注册平台账号：用手机号 / 微信即可完成，部分平台需实名认证（仅合规要求，无其他影响）；</li><li>准备需求相关素材：如做文档问答助手，提前整理好要上传的 PDF/Word 文件；做日程助手，提前绑定自己的日历 / 微信账号；</li><li>理清核心指令：用一句话写清智能体的​<strong>核心功能</strong>​（如 “上传考研数学笔记，我提问后快速给出答案并标注页码”），后续搭建全程围绕这句话展开。</li></ul><h2>二、核心搭建（1-3 小时）：以扣子为例，手把手零代码实操</h2><p>以<strong>新手首选的扣子（Coze）</strong> 为例，搭建一个 **「个人文档问答助手」**（最易上手、实用性最高的入门需求），其他平台操作逻辑类似，均为 “新建 → 设角色 → 配功能 → 调规则” 四步，可直接参考。</p><h3>步骤 1：新建智能体，基础信息设置（5 分钟）</h3><ol><li>打开扣子官网，进入「我的智能体」，点击「创建智能体」；</li><li><p>填写基础信息：</p><ul><li>智能体名称：清晰易懂（如 “考研数学笔记问答助手”）；</li><li>角色设定：简单描述身份（如 “你是考研数学答疑助手，能根据我上传的考研数学笔记，精准回答我的问题，标注答案所在页码”）；</li><li>头像 / 简介：可选填，新手直接跳过，不影响功能。</li></ul></li></ol><h3>步骤 2：配置核心能力，上传知识库（10-20 分钟）</h3><ol><li>左侧菜单栏选择「知识库」，点击「新建知识库」，命名后选择「上传文件」，将准备好的笔记 / PDF 上传（支持多文件批量上传，单文件大小无入门限制）；</li><li>等待文件解析（1-3 分钟，视文件大小而定），解析完成后，将该知识库<strong>绑定</strong>到当前智能体（勾选 “知识库问答” 功能）；</li><li>简单设置检索规则：新手直接用平台默认设置（如 “精准匹配”“返回答案 + 原文片段”），无需修改。</li></ol><h3>步骤 3：配置交互规则，优化回复效果（10 分钟）</h3><ol><li><p>左侧菜单栏选择「对话设置」，设置​<strong>回复规则</strong>​：</p><ul><li>回复风格：选择 “简洁明了”（新手首选，避免冗余）；</li><li>上下文记忆：开启 “短期记忆”（让智能体记住对话中的问题，无需重复提问）；</li><li>拒绝无关问题：开启 “仅回答知识库相关问题”（避免智能体答非所问）；</li></ul></li><li>可选配置​<strong>快捷提问</strong>​：添加 3-5 个高频问题（如 “高数极限的解题方法有哪些？”），方便快速测试。</li></ol><h3>步骤 4：集成工具（可选，针对复杂需求，5 分钟）</h3><p>若搭建的是日程助手、邮件助手等需要对接外部工具的智能体，在左侧「工具中心」选择对应插件（如日历、邮箱、微信），点击「授权绑定」，按提示完成账号关联即可；文档问答助手无需集成工具，直接跳过。</p><h3>步骤 5：保存并测试，跑通核心功能（10-30 分钟）</h3><ol><li>点击「保存并发布」，进入智能体对话界面；</li><li>进行多轮测试，输入不同类型的问题（简单问题 + 复杂问题），如 “洛必达法则的使用条件是什么？”“高数上册第三章的核心考点有哪些？”；</li><li>若出现答非所问、找不到答案的情况，回到「知识库」检查文件是否解析成功，或优化角色设定中的指令（如补充 “若找不到答案，直接告知‘暂无相关内容’，不要编造”）。</li></ol><h3>其他需求搭建通用逻辑</h3><p>无论搭建哪种智能体，均围绕 **「角色设定 + 核心能力 + 交互规则」** 展开：</p><ul><li>日程助手：角色设定为 “日程管理师”+ 绑定日历工具 + 设置 “定时提醒 + 待办同步” 规则；</li><li>会议纪要助手：角色设定为 “会议纪要专员”+ 绑定语音 / 文字上传功能 + 设置 “提取核心信息 + 拆分待办 + 标注责任人” 规则。</li></ul><h2>三、调试优化（1-2 天）：从 “能用” 到 “好用”，解决常见问题</h2><p>搭建完成后，智能体可能出现<strong>答非所问、回复冗余、功能失效</strong>等问题，新手无需复杂操作，通过 3 个简单方法即可快速优化，让智能体更贴合需求。</p><h3>1. 高频问题解决方法</h3><table><thead><tr><th>常见问题</th><th>核心原因</th><th>优化方法</th></tr></thead><tbody><tr><td>答非所问，偏离知识库</td><td>角色指令不清晰，或未限制回答范围</td><td>1. 角色设定中明确 “仅根据知识库内容回答”；2. 对话设置中开启 “拒绝无关问题”</td></tr><tr><td>找不到答案，提示 “无相关内容”</td><td>文件解析失败，或问题表述太模糊</td><td>1. 重新上传文件，确保解析状态为 “成功”；2. 优化问题表述，更具体（如将 “极限怎么学” 改为 “高数极限的解题步骤有哪些”）</td></tr><tr><td>回复冗余，有大量无关内容</td><td>回复风格未设置，或模型生成冗余信息</td><td>1. 对话设置中选择 “简洁明了”，添加 “回复控制在 3 句话内，不要冗余”；2. 角色设定中补充 “答案直击要点，无需铺垫”</td></tr><tr><td>工具调用失效（如日历不提醒）</td><td>工具授权过期，或规则未设置触发条件</td><td>1. 重新绑定工具，检查授权状态；2. 设置明确触发条件（如 “我说‘添加待办’，自动同步至日历”）</td></tr></tbody></table><h3>2. 简单优化技巧</h3><ul><li>精简指令：角色设定中的描述​<strong>控制在 2 句话内</strong>​，越简洁，智能体执行越精准，避免堆砌形容词；</li><li>补充禁忌规则：在角色设定中添加 “不要编造答案”“不要回答无关问题”“回复简洁” 等禁忌，减少无效输出；</li><li>多轮测试迭代：每天用 5 分钟测试 3-5 个问题，发现问题及时调整，不用追求一步到位。</li></ul><h3>3. 功能轻量化升级（可选）</h3><p>若想让智能体功能更丰富，可在基础版上做简单升级，无需新增复杂配置：</p><ul><li>文档问答助手：添加 “答案标红重点 + 页码跳转” 功能（扣子 / Dify 均为一键开启）；</li><li>日程助手：添加 “微信提醒” 功能（绑定微信插件，替代平台内提醒）；</li><li>办公助手：添加 “文档导出” 功能，将智能体的回复导出为 Word/Excel，方便后续使用。</li></ul><h2>四、落地使用（长期）：融入日常，发挥智能体价值</h2><p>搭建智能体的核心是解决实际问题，新手无需追求 “功能完美”，而是将其融入​<strong>个人生活 / 工作流程</strong>​，让智能体成为自己的 “专属助手”，同时在使用中持续微调。</p><h3>1. 日常使用小技巧</h3><ul><li>固定使用场景：如每天早上用信息汇总助手整理 10 分钟资讯，每周用文档问答助手复习笔记，形成使用习惯；</li><li>快速调用：将智能体添加到桌面 / 微信小程序（扣子等平台均支持），无需打开官网，一键调用，提升使用效率；</li><li>记录问题：准备一个小本子，记录使用中遇到的问题（如 “某个问题答不上来”），每周花 10 分钟集中优化。</li></ul><h3>2. 轻量迭代原则</h3><ul><li>小步快跑：每次只优化一个问题（如 “解决答非所问”），不要一次修改多个设置，避免出现新问题；</li><li>按需升级：若当前功能能满足需求，无需新增功能（如文档问答助手能精准回答问题，就不用添加 “知识点拓展” 功能）；</li><li>贴合自己的使用习惯：如自己喜欢用短句提问，就不用刻意优化长句提问的效果，以自己的使用方式为核心。</li></ul><h2>五、代码入门轻指引（可选，适合想进阶的新手）</h2><p>若零代码搭建后，想尝试代码开发（如自定义智能体逻辑、本地部署），无需从头学编程，遵循 **「轻量入门，先调用再自定义」** 原则，用 1-2 周即可做出简单的代码版智能体。</p><h3>1. 必备基础（3-5 天）</h3><ul><li>编程语言：Python 基础（仅需掌握​<strong>变量、函数、简单的 API 调用</strong>​，推荐 B 站《Python 零基础快速入门》，只看前 5 集即可）；</li><li>核心工具：安装 Python 环境（3.9 及以上）、PyCharm 社区版（免费，代码编辑器）、Postman（可选，测试 API）。</li></ul><h3>2. 入门技术栈（直接套用，无需理解底层）</h3><ul><li>基础模型 API：OpenAI API / 文心一言 API / 通义千问 API（提供智能体的对话能力，新手选其一即可）；</li><li>框架：LangChain（轻量框架，封装了智能体核心功能，无需自己写复杂代码）；</li><li>前端（可选）：Streamlit（一键搭建简单界面，无需前端知识）。</li></ul><h3>3. 极简代码实战（1-2 天）</h3><p>用 <strong>Python+LangChain + 文心一言 API</strong> 搭建一个简单的文档问答智能体，核心步骤为：​<strong>安装依赖 → 调用 API→ 加载知识库 → 实现问答</strong>​，网上有大量现成的代码模板（GitHub/LangChain 官方文档），直接复制修改参数即可（如替换自己的 API 密钥、上传自己的知识库文件）。</p><h3>4. 避坑指南</h3><ul><li>先调通官方示例代码，再修改自己的需求，避免从头写代码；</li><li>不用追求本地部署，先在云端运行（如 Colab，免费，无需配置环境）；</li><li>核心学习 <strong>API 调用</strong>和​<strong>知识库加载</strong>​，其他功能（如记忆、工具调用）后续逐步学习。</li></ul><h2>六、常见误区与避坑建议</h2><p>新手搭建第一个智能体，最容易陷入 “追求完美、过度学习、贪多求全” 的误区，以下 3 个避坑建议，能让你少走 80% 的弯路：</p><ol><li><p>​<strong>误区</strong>​：先啃透 AI 理论 / 编程知识，再动手搭建。<br/>​<strong>建议</strong>​：理论知识按需补充，零代码搭建完全不需要懂 AI 原理，动手做才是核心，哪怕搭建的智能体功能简单，也比光看不学强。</p><ol><li><p>​<strong>误区</strong>​：一次搭建多个功能，想让智能体 “无所不能”。</p><p>​<strong>建议</strong>​：一个智能体只解决​<strong>一个核心需求</strong>​，如文档问答助手就只做问答，不要添加日程、提醒、汇总等功能，功能越多，调试越复杂，越容易放弃。</p><ol><li><p>​<strong>误区</strong>​：过度纠结平台选择，反复对比各个平台的优劣。</p><p>​<strong>建议</strong>​：新手直接选​<strong>扣子（Coze）</strong>​，国内适配性最好、操作最简单，先在一个平台做出成果，再尝试其他平台，不用在选择上浪费时间。</p><ol><li><p>​<strong>误区</strong>​：测试一次就觉得 “不好用”，直接放弃。</p><p>​<strong>建议</strong>​：智能体的优化是一个持续的过程，哪怕是大厂的智能体，也会出现答非所问的情况，新手搭建的第一个智能体，只要能解决 60% 的需求，就是成功的，后续逐步优化即可。</p></li></ol><h2>七、QA 问答：解决搭建中的高频疑问</h2><h3>Q1：零基础、完全不懂编程，真的能搭建出可用的智能体吗？</h3><p>A：完全可以。零代码平台（如扣子）的操作逻辑和搭积木一样，全程可视化拖拽、全中文界面，仅需根据提示完成 “角色设定 + 知识库上传 + 规则设置”，1-3 小时就能做出可用的智能体，核心是​<strong>锁定需求、按步骤操作</strong>​，不用懂任何编程或 AI 知识。</p><h3>Q2：搭建智能体需要付费吗？新手需要开通会员吗？</h3><p>A：主流零代码平台的​<strong>基础功能均为免费</strong>​，如扣子的个人版、Dify 的云版免费层，完全能满足新手搭建第一个智能体的需求（如上传 10 个以内的文件、每月一定的对话次数）；​<strong>新手无需开通会员</strong>​，只有当后续需要高级功能（如大文件上传、无限对话、企业级部署）时，再考虑付费，免费版足够入门使用。</p><h3>Q3：选择哪个需求搭建第一个智能体最好？</h3><p>A：优先选 **「文档问答助手」<strong>，原因有三：1. 搭建步骤最简单，无需集成外部工具；2. 实用性最高，学生、职场人都能用到；3. 调试难度低，问题反馈直观（答没答对点一眼就能看出来）。若你有明确的办公需求（如会议纪要、日程管理），也可以直接选对应的需求，核心是</strong>自己熟悉、能快速测试 **。</p><h3>Q4：搭建完成后，智能体的数据安全吗？会不会泄露自己的文件 / 信息？</h3><p>A：主流平台（如扣子、Dify）均遵循国家个人信息保护法，采用加密存储，​<strong>个人搭建的智能体，若未设置公开，仅自己能访问</strong>​，不会泄露你的文件和信息；若担心数据安全，可选择​<strong>本地部署</strong>​（如 Dify 开源版），但新手无需考虑，零代码平台的云版完全能保证个人使用的安全性。</p><h3>Q5：为什么我搭建的智能体答非所问？该怎么快速解决？</h3><p>A：答非所问是新手最常见的问题，核心原因只有 3 个：​<strong>指令不清晰、未限制回答范围、文件解析失败</strong>​，按以下步骤排查，90% 的问题能快速解决：1. 检查角色设定，是否明确 “仅根据知识库回答”；2. 检查对话设置，是否开启 “拒绝无关问题”；3. 检查知识库，文件是否解析成功（重新上传一次即可）。</p><h3>Q6：可以将自己搭建的智能体分享给别人使用吗？</h3><p>A：可以。主流零代码平台均支持​<strong>分享功能</strong>​，如扣子可生成分享链接 / 二维码，别人无需注册平台，点击链接即可使用；也可以设置 “仅好友可见”“公开可见”“密码访问” 等权限，新手可将自己的智能体分享给同学 / 同事，收集反馈，进一步优化。</p><h2>八、7 天落地计划（直接套用，零基础也能完成）</h2><p>为新手定制的​<strong>7 天极简落地计划</strong>​，每天仅需投入 30 分钟 - 1 小时，无需加班加点，按计划执行，7 天就能做出一个可实际使用的智能体，并融入日常流程。</p><table><thead><tr><th>天数</th><th>核心任务</th><th>操作内容</th><th>输出成果</th></tr></thead><tbody><tr><td>1</td><td>定需求 + 选平台</td><td>锁定一个需求（如文档问答助手），注册扣子账号，准备好相关素材（如 PDF 笔记）</td><td>明确需求，完成平台注册，准备好素材</td></tr><tr><td>2-3</td><td>零代码搭建</td><td>按步骤搭建智能体（新建 → 设角色 → 传知识库 → 配规则），完成核心功能测试</td><td>第一个智能体原型，能回答基础问题</td></tr><tr><td>4-5</td><td>调试优化</td><td>解决答非所问、找不到答案等常见问题，优化回复风格和交互规则</td><td>可用的智能体，能精准解决核心需求</td></tr><tr><td>6</td><td>轻量化升级（可选）</td><td>开启 1-2 个实用小功能（如答案标红、文档导出），添加快捷提问</td><td>优化版智能体，使用体验更好</td></tr><tr><td>7</td><td>落地使用 + 记录问题</td><td>将智能体融入日常流程（如用其复习笔记 / 整理文档），记录使用中遇到的问题</td><td>能实际使用的智能体，形成问题清单</td></tr></tbody></table><p>​<strong>核心目标</strong>​：7 天内让智能体成为你的 “专属小助手”，哪怕每天只使用一次，也是成功的落地。</p></li></ol></li></ol></li></ol>]]></description></item>  </channel></rss>